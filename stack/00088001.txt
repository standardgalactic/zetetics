208 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
Combining Multiple Knowledge Bases 
Chitta Baral, Sarit Kraus, and Jack Minker, Fellow, ZEEE 
Abstmct- Knowledge present in multiple knowledge bases 
might need to be reviewed to make decisions based on the com- 
bined knowledge. We define the concept of combining knowledge 
present in a set of knowledge bases and present algorithms to 
maximally combine them SQ that the combination is consistent 
with respect to the integrity constraints associated with the 
knowledge bases. For this we define the concept of maximality 
and prove that the algorithms presented combine the knowledge 
bases to generate a maximal theory. We also discuss the relation- 
ships between combining multiple knowledge bases and the view 
update problem. 
Index Terms- Consistent, integrity constraints, knowledge 
bases, logic programs, maximally combining theories. 
I. INTRODUCIION 
HE main concern in this paper is to combine knowledge 
T 
present in multiple knowledge base systems into a single 
knowledge base. A knowledge based system can be considered 
an extension of a deductive database in that it permits func- 
tion symbols as part of the theory. We consider alternative 
knowledge bases that deal with the same subject matter. Each 
knowledge base consists of a set normal clauses and a set of 
integrity constraints. The set of integrity constraints (IC) is 
assumed to be the same for all knowledge bases, but the sets 
of normal clauses may differ. We assume that each knowledge 
base is consistent with respect to the integrity constraints when 
considered alone. 
While combining multiple knowledge bases we have to 
ensure that the combination is consistent with respect to 
the integrity constraints. Such a problem might arise in a 
large company with branches overseas. Each branch manages 
its own knowledge base. A consistent combination of the 
knowledge bases is required while trying to make a decision 
about the overall company. 
In Section 11, we discuss problems that may arise in com- 
bining alternative knowledge bases. Basic definitions are pre- 
sented in Section 111. In Section IV, we present algorithms to 
combine multiple knowledge bases. In Section V, we compare 
this problem to the view update problem in databases [7], [6], 
~ 4 1 .  
Manuscript received September 14, 1989; revised March 21, 1990. This 
work was supported by the National Science Foundation under Grant IRI-86- 
09170 and the Army Research Office under Grant DAAL-03-88-KW87. 
C. Baral is with the Department of Computer Science, University of 
Maryland, College Park, MD 20742. 
S. Kraus and J. Minker are with the Department of Computer Science and 
Institute for Advanced Computer Studies, University of Maryland, College 
Park, MD 20742. 
IEEE Log 9144308. 
11. COMBINING 
KNOWLEDGE BASES 
We assume the knowledge bases to be logic programs with 
integrity constraints associated with the program. A logic 
program consists of a finite set of clauses of the form 
where the expression on the left-hand side of the implication 
is a disjunction of atoms and the expression on the right-hand 
side is a conjunction of literals. When n is 1, we call it a 
normal logicprogram and we call a normal logic program, a 
Horn logic program when the literals in the right-hand side are 
all atoms. When n is greater than 1, we call it a disjunctive 
logic program. 
A. Combining Logic Programs 
Suppose we consider the problem of combining several 
logic programs without integrity constraints. In order to com- 
bine the logic programs one may take their union, i.e., all 
information available from all of the logic programs are 
combined into a single program. It is easy to see that this 
union is consistent. 
Theorem 1: If T I ,  . . . , ‘Tk are general Horn logic programs 
then TI U . . U Tk is consistent. 
U 
Consider two logic programs TI and T2 that contradict each 
other, i.e., using one we can derive P(u) while in the other we 
may derive l P ( u ) .  (Note: By “derive’’ we refer to an SLDNF 
derivation [13].) As shown in Theorem 1, TI UT2 is consistent, 
and therefore even in such a case it is reasonable to combine 
them by taking their union. In the union of the two theories we 
might derive P(u) or we might derive -P(u). This is because 
the minimal model of TI U T2 is not necessarily the union of 
the minimal models of 
and P2, due to nonmonotonicity of 
the semantics. We explain this by the following example. 
Example 2.1: Consider the following logic programs PI and 
P2 : 
PI : 
abnormal(tweety) 
bird(tweety) 
bird(char1i) 
a bnormal(0strich) 
bird(tweety) 
flys(X) + bird(X), labnormal(X) 
P2 : 
We can derive Tflys(tweety) from PI and flys(tweety) from P2. 
But from PI U P2 we can derive lflys(tweety). On the other 
hapd, from both PI and P2 we can derive Tflys(char1i) but 
from PI U P2 we can derive flys(char1i). 
1041-4347/91/0600-0208$01.00 0 1991 IEEE 

BARAL et al.: COMBINING MULTIPLE KNOWLEDGE BASES 
209 
B. Handling Integrity Constraints 
In real world applications, integrity constraints restrict a 
knowledge base to a particular meaning [16]. In the presence 
of integrity constraints, the union of a set of logic programs 
can violate an integrity constraint, even though each individual 
logic program does not violate it. Hence, in the presence 
of integrity constraints, the union of logic programs may 
not always be the correct way to combine the theories. For 
example if we have fatherof(ken,nick) in TI, where fatherof& 
Y) denotes that Y is the father of X, and futherof(ken,george) 
in T2, and we take the union of the two theories, then although 
the union is consistent, it violates an integrity constraint that 
characterizes fatherhood, which states that, “one person cannot 
have two fathers,” even though both TI and T2 individually 
satisfy the integrity constraint. To combine theories TI and T2, 
we can choose one of them and include it in the combination, 
we can partially favor one theory and combine them as 
fatherof(ken,nick)+ lfatherof(ken,george) or we can combine 
them as futherof(ken,nick)V fatherof(ken,george). In the last 
situation we do not prefer any theory, and give the user the 
freedom to choose the appropriate model from the various 
models suggested by the combined theory. A normal clause 
representation of the last approach would be the unstratified 
clauses 
futherof (ken, nick) + Tfatherof(ken, george) 
futherof (ken, george) + lfutherof (ken. nick) 
Semantics of such unstratified logic programs, have been 
proposed in [3], [26], [22], and [lo]. We do not explore this 
possibility in this paper. 
C. Possible Solutions 
As noted in the previous section there are different options 
available to combine alternative theories. The following are 
the major possible alternatives. 
1) An Oracle exists which knows everything. Whenever 
a contradiction between theories exists, a decision as 
to what to include in the combination is determined 
according to the Oracle, which may support one of the 
theories or neither. 
2) A partial order exists between all possible pairs of <the- 
ory, concept>. In case of a contradiction between two 
theories relative to a specific concept, in the combination 
we may always select data from the preferable theory 
with respect to this concept. For example, <cardiologist, 
cancer> 5 <oncologist, cancer>. That is, the cancer 
specialist (called ‘‘oncologist’’) knows at least as much 
as the cardiologist about cancer and so we might trust 
his beliefs about cancer rather than the cardiologist’s 
view. A syntactic method based on this is discussed in 
Section IV-C. 
3) In the extreme case we might define a fact to be unknown 
when the facts in the two knowledge bases contradict 
one another. We want to remark that to define a concept 
as unknown is different than not to include it in the 
4) 
combination. If we do not include it in the knowledge 
base, in logic programs we will be able to derive the 
concept’s negation. In order to be able to implement 
such an approach one needs to move to three-valued 
logic [22], [3], [8], [9] or to protected circumscription 
A maximal amount of consistent information could 
be combined from alternative theories. In case of a 
contradiction, the information could be combined to 
make the knowledge base consistent by converting it into 
a disjunctive knowledge base. This knowledge base may 
be presented to the user and he might choose among the 
disjunctive facts. 
[ 171-[ 19 1. 
Creating an Oracle, as suggested in the first approach, is 
almost impossible, especially while dealing with distributed 
knowledge bases. There are some technical problems, but there 
are also some essential problems, such as who knows the 
truths to supply to the Oracle. We may not have the priority 
information available so that the second approach might not 
be possible. When we define a concept as unknown we lose 
information that existed in the original knowledge bases; so 
the third option may be questionable. 
In this paper, we take the last approach, where we maxi- 
mally combine the set of knowledge bases subject to consis- 
tency with the integrity constraints. We also note that there 
is another option possible, where the user decides what is to 
be done. 
111. BASIC DEFINITIONS 
Recently, several different semantics have been given to 
logic programs [26], [22], [lo], [3]. In the case of Horn logic 
programs without negation, it is well known [25], [2] that 
there exists a unique minimal model. This model is used as 
the meaning of the program. In the case of stratified general 
Horn programs, there is a single perfect model [23], [l] and 
this model is used as the meaning of the program. In the case 
of stratified disjunctive logic programs we use its set of perfect 
models as its meaning. We call the set of perfect models of a 
stratified disjunctive program P, as MlNSET(P). In this paper, 
we only consider stratified programs and further assume that 
the union of the theories to be combined is also stratified. 
Definition 3.1: Given a program P, HERB(P) 
denotes the 
(possibly infinite) set of clauses which are ground instances of 
The definition of perfect model is based on a partial order 
between minimal models. The partial order between minimal 
models is based on a partial order between elements of the 
Herbrand base of the program P, dictated by the position of 
literals in HERB(P). We now define this partial order formally. 
Definition 3.2: Definition of < and 5, from [21]: The 
< and 5 relation between atoms of the Herbrand base of a 
program P ,  are defined based on their position in HERB(P). 
1) G < B, if 4 3  is a negative literal in the body of a 
2) C 5 B, if B is a positive literal in the body of a clause 
program clauses in P. 
0 
clause in HERB(P), with C in the head. 
in HERB(P), with C in its head. 

210 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
3) C 5 B and B 5 C, if B and C are in the head of the 
same clause in HERB(P). 
4) A L B , B i C + A 5 C .  
5 ) A 5 B , B < C + A < C C .  
6) A < B + A 5 B. 
7) Nothing else satisfies < or 5. 
0 
Since, we are considering only stratified programs, the relation 
< is a partial order. 
Definition 3.3: Relation between minimal models [21]: Let 
M and N be two distinct models. We say N << M (N is 
preferable to M) if, VA(a ground atom) in N - M, 3 a ground 
atom B in M - N, such that A < B. 
0 
Example 3.1: Consider the program 
A e i B  
C e TD. 
It has four minimal models {A,C}, {A,D}, {B,C}, and 
Using the definition for the relation <, we have A < B and 
C < D  
Consider the models {A, C} and {A, D}. Since C < D, hence 
o 
Definition 3.4: Definition of MZNSET(P): The MINSET(P) 
1) Vx (x is a minimal model of P + 3y, y E MINSET(P) 
2) Vx, y (x, y E MINSET(P) and z # y + x # y, y 
x). 
Example 3.2: In the last example we have {A, C} << 
{A,D}, {A,C} << {B,C}, {A,C} << { B , D } .  Hence, 
MINSET(P) = { {A,C} }. 
0 
The syntax of integrity constraints we use is similar to 
that used by Sadri and Kowalski [12] and Chakravarthy, 
Grant, and Minker [4]. Integrity constraints are of the form 
c L1,. . . , L,, 
m > 0, where the Li are literals and all 
variables are assumed to be universally quantified in front 
of the constraint in which they occur. Such clauses are 
called denials. When Li are restricted to be only atoms 
we call it a positive integrity constraint. Denials have to 
be range restricted, that is, any variable that occurs in a 
negative literal of the constraint must also have an occurrence 
in a positive literal of the constraint. Sadri and Kowalski 
[12] show that integrity constraints of this form are general 
enough to represent any closed first-order formula using the 
transformations suggested in [12] and [14]. 
There are several different definitions of integrity constraint 
satisfaction in a database or knowledge base [12]. The two 
main definitions are the theoremhood definition and the con- 
sistency definition. Let P be a program and Sem(P) be the 
semantics of the program. According to the theoremhood 
definition, program P satisfies an integrity constraint I iff I 
is true in Sem(P). According to the consistency definition P 
satisfies I iff Sem(P) U I is consistent. The two approaches 
are the same when the program is complete. A program P 
is said to be complete with respect to a semantics, Sem(P), 
when for any formula W, either W is true in Sem(P) or W is 
false in Sem(P). Most papers that deal with the theoremhood 
{ B ,  D}. 
we have {A, C} << {A, D}. 
of a program P is a set of minimal models of P, such that 
and y << x). 
0 
approach use Comp(P), Clark's completion of a program [5], 
as Sem(P). 
We use Sem(P) as the perfect model of the program, if 
the program is a normal program and, as we are dealing 
with stratified programs, they have a unique perfect model. 
When the program is a disjunctive program we use the set 
of minimal models defined as MINSET(P) as Sem(P). In 
the case of normal programs, P is complete with respect 
to Sem(P), and hence there is no difference between the 
consistency and the theoremhood definition with respect to 
our definition of Sem(P). In the case of disjunctive programs 
we use the consistency definition. 
Definition 3.5 Consistency: A theory T ,  where T may be 
disjunctive, is said to be consistent with respect to a set of 
integrity constraints IC, iff every minimal model of T that is 
present in MINSET(P) satisfies the integrity constraints. 0 
Definition 3.6: The 5 relationship between theories: Let TI 
and T2 be two theories (possibly disjunctive). We say TI 5 T2 
iff Vx : x E MINSET(Tl), 3y : y E MINSET(T2) and 
x G Y. 
o 
Definition 3.7 Maximality: A theory T, is said to be maximal 
among a set of theories {TI . . Tn}, iff there does not exist j, 
such that 1 5 i,j 5 n and T, 5 Tj. 
0 
Definition 3.8 Correctness: A theory T is said to be correct 
withrespecttotheoriesT1,...,Tk,ifT5T1U...UTk 
. 0 
Definition 3.9 Combination of Theories: Let TI, . +  , Tk be 
a set of theories and IC be a set of integrity constraints, where 
each T, satisfies IC. The combination function C maps from a 
set of theories and a set of integrity constraints into a theory. 
It should satisfy the following four properties. 
1) (identity) C(T, IC) = T .  
2) (commutativity) C(T1,. . . , Tz-1, T,, . . , Tj, T,+i, . . . , 
Tk, IC) = C(T', .. . , Z - 1 ,  Tj, 
..* >Ta,Tj+1, 
IC). 
3) (consistency) C(T1, . . . , Tk, IC) is consistent with re- 
4) (correctness) C(T1, . . . , Tk, IC) is correct with respect 
Another useful property is associativity, which is defined 
as follows. C(Tl,. . , T3, C(Tj+l,. . . , Tk, IC), IC) =,, 
C(Ti, 
* . . , TjC(T'+i,. . * ,  Tk), IC, IC) =mm 
c ( T i , .  . . , Tk, 
IC), where P =,, 
Q means MINSET(P) = MINSET(Q). 0 
Our goal is to combine a set of theories such that 
C(Tl,. . . , Tk, IC) is maximal among all consistent and 
correct combinations of TI, . . , T,,. The intuition behind the 
maximality property is that we would like the combination of 
the theories to include as much information as possible from 
all theories. The intuition behind the correctness is that the 
combination will not include new information that does not 
have a basis in the union. Consider the following example. 
Example 3.3: Consider two theories TI = {A} and T2 = 
{B} and the integrity constraint c A, B. In the absence of 
any priority information, there are three consistent and correct 
combinations of TI and Tz. 
1) The combination whose only minimal model is {A}. 
2) The combination whose only minimal model is {B}. 
spect to IC. 
to the theories TI, . . . , Tk. 

B A R K  et al.: COMBINING MULTIPLE KNOWLEDGE BASES 
211 
3) The combination that has two minimal models {A} and 
By definition of maximality the third combination is the 
maximal combination. Our goal is to develop algorithms to 
Theorem 2: Let TI, . . . . Tk be a set of theories and IC be 
a set of positive integrity constraints. There exists a maximal 
combination of 7’1, . . . , Tk. All such combinations have the 
same set of minimal models. 
Proof: Consider the set of minimal models in MINSET(Tl 
U . . . U Tk). Let them be ml. . . . . m,. Divide these minimal 
models so as to obtain a set of maximal models, such that 
none of the maximal models violate any integrity constraints 
in IC. For example, if m, = {A1 . . . A,} is one of the original 
minimal models, and t 
A1 . . . A, where T 5 n is an integrity 
constraint in IC, then m is divided to the set of maximal 
mod e 1 s : 
A,} . . . {A2.. . . , A,+1 . . . A,}. After dividing the original set 
of minimal models so as to be consistent with respect to all 
the integrity constraints, suppose we obtain M = mi, . . . m: 
as the set of maximal models. We claim that any theory which 
has its minimal models as M ,  is a maximal combination of 
Suppose this is false, i.e., 3M‘: M 5 M‘, and M‘ is a 
combination of TI, . . . , Tk. Since, M 5 M‘, 32. y : x E M 
and y E M‘ and x c y. Since M’ is correct (a property of 
all combinations), 3i 1 5 i 5 s : y E m,. Since, x c y, 
x 
m,, i.e., x is obtained from m,, while dividing m, to 
make it consistent with respect to the integrity constraints. 
Since the division creates a set of maximal consistent models, 
x c y implies y is not consistent with respect to the integrity 
constraints. Hence, M’ is not consistent with respect to the 
integrity constraints and hence it is not a combination. This 
contradicts our initial assumption that M’ is a Combination 
of TI.. . 
+ . Tk, and hence M is the maximal combination of 
{B}. 
combine theories maximally. 
0 
{Al,...,A,-l,Ar+l 
.‘.A,}, { A l , . . .  .Ar-2,Ar,Ar+l ” ‘  
Ti, . * * , Tk. 
Ti,. . ’ ,  T k .  
0 
Iv. COMBINING A SET OF BELIEF SYSTEMS 
In this section we give algorithms to maximally combine 
a set of normal logic programs. First we give algorithms to 
combine theories that contain only facts, then we allow rules 
without negation in their body and finally we consider normal 
logic programs. 
Throughout the rest of the paper we assume that the 
SLDNF-proof tree when an integrity constraint is considered 
as a query, with respect to the union of the theories, is finite. A 
sufficient restriction for having finite SLDNF proof trees is that 
the theory be function-free and hierarchical. By hierarchical, 
we mean that the theory does not have any recursion. We also 
assume that integrity constraints do not have negation in their 
body. 
A. Combining Theories Consisting Only of Facts 
Our initial assumption is that theories consist only of 
facts. Consider a simple case where TI consists of P(a) 
and T2 consists of P(b), and the integrity constraint is t 
P ( X ) ,  P(Y), X # Y .  In the absence of any information about 
preferences we can combine these two theories, without the 
combination (T) violating the integrity constraint and without 
preferring one theory over the other, by placing only P(a) V 
P(b) in the combination T ,  of the two theories. The theory 
T has two minimal models: one is {P(n)} and the other is 
Before presenting our algorithm we first show, through an 
example, how a combination is achieved. 
Example 4.1: Let TI def {P(a): P(b)},T* def {P(c)}, and 
the integrity constraint be +-- P(a). P(b), P(c). The combined 
theory has to satisfy the logically equivalent integrity con- 
straint, +(U) 
V +(b) 
V -P(c). To be maximal, we want 
the least number of atoms to be false in the combination. In 
other words, we want the least number of negative literals 
to be true. We rename the negative literals in the clauses 
obtained by transferring atoms to the left in each of the 
integrity constraints. We rename ~ P ( u )  
as P’(u) and others 
in a similar manner. After renaming we obtain the clause 
P’(u) V P’(b) V P’(c). This clause has three minimal models, 
{{P’(u)}, {P’(b)}, {P’(c)}}. The minimal model {P’(u)} 
means P’(u) is true, and others are false; that means +(U) is 
true and all other negative literals are false, which means P(a) 
is false, and all other atoms are true. Each minimal model of 
the renamed clauses corresponds to a maximal model. 
Hence, we take the integrity constraints and form clauses by 
transferring the atoms to the left. Next we rename the atoms 
in the clauses. We find the set of minimal models for the 
renamed clauses. Since each minimal model corresponds to a 
maximal model, we collect the set of these maximal models. 
We then construct a theory whose minimal models are the set 
of maximal models. The theory constructed is the maximally 
combined theory. 
In this example, the minimal models of the renamed theory 
are {{P’(a)}. {P’(b)}, {P’(c)}}. The maximal model corre- 
sponding to {P’(u)} is {P(b), P(c)}; the maximal model 
corresponding to {P’(b)} is {P(u), P(c)} and the maximal 
model corresponding to {P’(c)} is {P(u),P(b)}. 
The the- 
ory, whose minimal models are {{P(b), P(c)}, {P(a). P(c)}, 
{P(a),P(b)}} 
is P(u) v P(b), P(a) v P(c), P(b) v P(cL 
and is the combined theory which is consistent with respect to 
the integrity constraints. 
0 
It should be noted that the combined theory is disjunctive 
in the above example. An answer to the query t P ( X )  with 
respect to the combined theory is P(u) V P(b), while the 
answer to the query t P(a) is “unknown.” 
We now give an algorithm to combine a set of theories 
consisting only of facts, such that the resultant theory is correct 
with respect to the original theories, consistent with respect to 
the integrity constraints and is a maximal combination. 
Algorithm 4.1 (To combine theories consisting only of facts): 
INPUT: 
1. A set of k Horn theories {TI . . .Tk} which have to be 
combined, where each T; consists only of facts. 
2. A set of s integrity constraints, IC = (IC1, . . . , IC,} where 
each integrity constraint is satisfied by each of the theories. 
OUTPUT: 
A theory T ,  which is the maximal combination of the input set 
{W)}. 

212 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
of theories, such that T is also satisfied by each of the integrity 
constraints. The combined theory T can be disjunctive. 
STEP 1: [Find S, the set of instances of integrity constraints 
that violate the union of the theories.] 
s = 0; 
For i = 1 to s do 
begin 
Let IC, be of the form +- Pl;.-,Pk, where Pl,-..,Pk 
are atoms. 
Solve IC, with respect to TI U . . . U Tk. 
(Note that, in the beginning of this section we assume this 
to be decidable.) If there are no solutions then continue 
with the next i, else: 
Let 01 
.01, be all the ground answer substitutions when 
the IC, is satisfied as a query to the union of the knowl- 
edge bases, meaning that ICi violates the union of the 
knowledge bases 
s = su{+ ( P l , * ‘ . P k ” l ; * ’ ’ ; +  
(Pl,”’Pk)61z} 
end 
S is the set of instantiated integrity constraints which violates 
the combined theory TI U . . . U Tk. If S is empty, then the 
combined theory TI U. U Tk is consistent with respect to the 
integrity constraints and the algorithm terminates. 
If S is not empty, continue with STEP 2. 
STEP 2: [Obtain the set of minimal models of the transformed 
and renamed clauses in S and their corresponding maximal 
model.] 
Let S be {Cl,. - e
,
 Cn}, 
where each C, (1 5 i 5 n) is defined 
Let { A l ,  . . . A,} be all ground atoms present in S. We call 
this set the interfering facts. 
The set of facts that is present in TI U .. U Tk but not in 
{ A I ,  . Ap} are called noninte@ering facts. 
Construct the set of clauses ( 4 1 1  V lC12 V . . lClkl, . . . , 
+nk,} 
by transferring the atoms in the 
instantiated integrity constraints to the left of the arrow. 
Rename the negative literals 1Ct3 
by C[3 in the above set of 
clauses. 
Find all minimal models of the renamed set of clauses given 
Let the minimal models be mE,, . . - , mi 
For i = 1 to 1 do 
m: = m: withCi, replaced byC,,. 
STEP 3: [Obtain the theory whose only minimal models are 
the maximal models found in STEP 2.1 
For i = 1 to 1 do 
Construct a theory T (possibly disjunctive) whose only mini- 
mal models are ml - . - ml by doing the following. 
T = {x : x = fact(A1 V A2. 
V AI), where for all i 5 1, A, 
is in mi}, 
where fact is a function that removes all but one 
occurrence of repeated atoms in a disjunction. 
STEP 4: [Obtain the combined theory, by augmenting the 
noninterfering facts.] 
Add all the atoms in TI U T2 U . - U Tk that do not appear in 
{Al, . . . A,} from STEP 2 to T, and call it C(T1, . , Tk, IC). 
0 
by 
til, c z 2 ,  * 
’ 7 c z k l *  
V 1Cn2 V 
by { Cil v ci2 v . . 
+ Cik,, . 
* * , CL1 v CL2 v . . cLkn 
} 
m, = { A 1 , . - * A p }  
-mT 
The intuition behind this algorithm is as follows; in order 
for the combination of the theories to be consistent with the 
integrity constraints, at least one negative literal of each clausal 
form of the integrity constraint has to be true in each minimal 
model of the combination. On the other hand, in order to 
make the combination maximal one needs to minimize those 
negations. 
We demonstrate this algorithm by some examples. 
Example 4.2: We first show Example 4.1 with respect to 
this algorithm. 
Let TI %?f {P(u);P(b)}, T2 ef {P(c)}, and the integrity 
constraint be t P(u), P(b), P(c). 
STEP 1: We find that the integrity constraint t P(u),P(b), 
P(c) violates the union of the theories. 
STEP 2: We transfer the atoms in the integrity constraint to 
the left and rename the negative literals. The resulting clause 
is {P’(u) V P’(b) V P‘(c)}. We find the minimal models of 
P’(u) V P’(b) V P’(c) to be {{P’(u)}, {P’(b)], {P’(c)}}. 
STEP 3: For all minimal models found in STEP 2 the corre- 
sponding maximal models are {{P(b), P(c)}, {P(u), P(c)}, 
{P(u), P(b)}}. This is because for the minimal model {P’(u)} 
in STEP 2 the corresponding maximal model {P(b), P(c)}. 
This is further explained in Example 4.1. We find the the- 
ory, whose minimal models are {{P(b),P(c)}, 
{P(a), P(c)}, 
{P(a), P(b)}} to be P(a)V P(b), P(u) V P(c), P(b) V P(c). 
STEP 4: The combined theory is the theory found in STEP 
3. 
0 
Example4.3: Let TI !Zf 
{P(u)}, T2 sf {P(b)}, T3 $?if 
{P(c)}, and the integrity constraint be + P ( X ) ,  P(Y), X # 
Y. 
STEP 1: After solving the constraint we find t P(u), P(b); t 
P(a), P(c) and t P(b), P(c) to be the instantiated integrity 
constraints that violate the union of the theories. 
STEP 2: We find the minimal models of {P’(u) V 
P’(b),P’(u) v P’(c),P’(b) v P’(c)} to be {{P’(u),P’(b)}, 
STEP 3: We find the theory, whose minimal models are 
STEP 4: The combined theory is the theory found in STEP 
3. 
0 
The following proves the correctness of our algorithm. 
Theorem 3: C(T1, . Tk, IC), as given by Algorithm 4.1 is 
{P’(.)> P W } ,  {P’(b), P‘(c>}}. 
{{P(c)}, {P(b)}, {P(a)}} to be P(,) v P(b) v P(c>. 
a maximal combination of “1 . . . Tk. 
Proofi 
a) C(Tl, . . . , Tk, IC) is correct because all atoms in its 
clauses are satisfied by TI U 
b) C(T1, . . , Tk, IC) is consistent because all its minimal 
models, by virtue of its construction in STEP 3, do not 
violate the integrity constraints. 
c) Let C be all the facts in TI U 
U Th. Let B = 
{ A1 , . . . , Ap} be the ground atoms present in S in STEP 
From STEP 1 of the algorithm, we find that the atoms in B 
cannot be all true in the same model of C(T1 U . . . U Tk, IC), 
because they violate the integrity constraints. 
In STEP 2 of the algorithm we find a set of minimal sets, 
where each minimal set has the minimal number of atoms 
. U Tk. 
2. Let A = C - B. 

BARAL er al.: COMBINING MULTIPLE KNOWLEDGE BASES 
213 
false for the integrity constraints to be satisfied. 
Thus, each minimal set of fake atoms is equivalent to a 
maximal set of true atoms that can be true, while still not 
violating the integrity constraints. 
Thus, in STEP 3 of the algorithm we split B into a set 
{ml,. . . , rnr) of maximal models, and we construct T ,  which 
has {mi, 
. . . , mr} as the only minimal models. 
In STEP 4 we have C(T1 U . .  . U Tk, IC) = T U A. 
Now assume that our combination is not maximal, 
i.e., 3T’ : C(T1 U . . . U Tk, IC) 5 T’ 5 TI U ‘ .  . U Tk. 
==+ 3 a model m of c : m c m’ and rn’ 
a 
rn = A+ mi, where 1 5 i 5 1. 
==+ mi c m’ - A  
a 
But since mi is one of the maximal 
in STEP 3), the above cannot be true. 
a 
Such a T‘ cannot exist and hence 
maximal. 
S’ 
contains the instantiated integrity constraints that are vio- 
lated by Ti U . . . U T k  and a set of rules for each, that has to 
be restricted. 
The set of rules present in 5’‘ is called interfering rules. 
The set of rules present in TI U . .  . U Tk but not in S/ are 
called noninterfering rules. 
If S is empty, then the combined theory TI U ... U Tk is 
consistent with respect to the integrity constraints and the 
algorithm terminates. If S is not empty, continue with STEP 2. 
STEP 2: [Find the set of minimal models of the transformed 
is a model of T’. 
and renamed clauses in S and their corresponding maximal 
models.] 
S := the first element of each tuple of S’. (S contains the set 
of instantiated integrity constraints of S’ in step 1). Do STEP 
2 of Algorithm 4.1. 
STEP 3: [Find the theory whose only minimal models are the 
maximal models found in STEP 2 
Do STEP 3 of Algorithm 4.1 and let the theory generated be 
set (by construction 
our combination is 
0 
- 1  
B. Combining Theories with Rules Without Negation in their Body 
We now extend Algorithm 4.1 to the case where we have 
rules in the theories. We do not allow negative literals in the 
body of the rules. 
Algorithm 4.2: (To combine theories with Horn rules). 
INPUT: 
1. A set of k Horn theories {TI . . . T k }  which have to be 
combined. (Note that Horn theories do not have negative 
literals in the body of their rules.) 
2. A set of s integrity constraints, IC = { IC1. . . . 
~ IC,} where 
each integrity constraint is satisfied by each of the theories. 
OUTPUT: 
A theory T ,  which is the maximal combination of the input set 
of theories, such that T is also satisfied by each of the integrity 
constraints. The combined theory T can be disjunctive. 
ASSUMPTIONS: 
Each of the theories in TI . . . Tk is Horn and consists of facts 
and rules without negation in their body. 
STEP 1: [Find S’ the set of instances of integrity constraints 
that violate the union of the theories and for each such instance 
find the set of interfering rules.] 
For i = 1 to s do 
begin 
s/ := 0; 
Let IC, be of the form + PI.. . . , Pk, where PI,. . . , P k  
are atoms. 
Solve IC; with respect to TI U . . . U Tk. 
(Note that we assume this to be decidable, in the beginning 
of the section.) If there are no solutions continue with the 
next i, else: 
Let 01 , . . . ,6j, be the ground answer substitutions for the 
IC,; and for each ground answer substitution 03, 
Let R j  = {Rjl,. . . , Rjk} be the set of rules, which were 
used to obtain the ground answer substitution B j ,  where 
their heads unify with one of the Pi’s. 
Let Rji be the rule whose head unifies with Pi. 
(Pi , . . . , pk)&, , RlZ , 01, >>. 
S’ := S’ U {<+- (Pl,...,Pk)01,R1,81 >:..,<+ 
end 
1 .1 
STEP 4: [Find the resultant theory by augmenting the nonin- 
terfering facts.] 
T := T U all facts in TI U . . .  U Tk that do not appear in 
{Al. . . . Ap} (see Algorithm 4.1). 
STEP 5: [Find the resultant theory, by augmenting the re- 
stricted version of the interfering rules.] 
function Restrict(R: a set of rules, 0,: a variable substitution): 
a set of rules; 
begin 
Restrict(R, 19,) := 0 
If Oz is empty then STOP 
else 
For all rules R, in R do 
Consider the variables in the head of R, and the sub- 
stitution given by 0,. Let X,1, . . . , X,k, be variables in 
the head of R, and t,l,. . . , t&, be the corresponding 
variable substitutions. 
Let R, be head t tail. 
Restrict(R,Q,) := Restrict(R,B,) U 
{head t tail, X,1 # t,l; . . .; head 
tail, Xzk, # tzk,) 
end 
{This function restricts rules with respect to a variable substi- 
tution.} 
Obtain from S’ 
the pairs < R, I9 > and call it ruleset. 
The ruleset is {< R I , &  >,...,< Rt,0t >}. 
Let R = {RI, . . . , Rt}. We call this set of rules the interfering 
rules. 
Since there might be multiple instances of the same rule in R, 
for each rule T in R do Restrict(Restrict(. . . Restrict(r, dv1) . . . 
0Ts-l)19Ts) where OT1 . . . OvS are the various variable substitu- 
tions associated with the rule T ,  in ruleset. 
T := T U the collection of the above restricted rules. 
STEP 6: Find the combined theory, by augmenting the nonin- 
terfering rules. T := T U all the rules in Ti U . . . U Tk that do 
not appear in R. 
0 
One may ask why we restrict the rules and do not, for 
example, remove the facts that are used in order to solve the 
c(T1 U . . . U T k ,  IC) := T .  

214 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
- 
integrity constraints. This is because we want to gain maxi- 
mality. Taking out the facts will restrict the combined theory. 
On the other hand, by restricting the rules, and minimizing the 
negations of the facts of the integrity constraints, and leaving 
as much information as possible from the original theories, 
we obtain a maximally combined theory consistent with the 
integrity constraints. 
The following example illustrates the above algorithm. 
Example 4.4: Consider the integrity constraint t P ( X ) ,  
P ( Y ) , X  # Y ,  and the theories TI and T2. 
Step 1: When we solve the integrity constraint as a query 
we find that it is violated when x = U and y = b. So the 
instantiated integrity constraint is t P(a), P(b) and the two 
rules that are used are P ( X )  t R ( X )  and P ( Y )  t Q(Y). 
In the representation given in STEP 1 of Algorithm 4.2 we 
obtain S' = {<e 
P(u),P(b),{P(X) c R ( X ) , P ( Y )  t 
Step 2 and 3 gives us T = P(u) V P(b). 
In Step 4 we do not have any noninterfering facts to be added. 
In Step 5 we add the restricted rules P ( Y )  t Q ( Y ) , Y  # b 
and P ( X )  t R ( X ) , X  # a to T. After we add the facts in 
T1U T2 that are absent in T, we get C(Tl, T2, IC) as 
Q(Y>}, 
{ X / a 7 Y / b )  >I. 
P(a) " P(b) 
R(a) 
Q(b) 
P ( Y )  + Q(Y),Y # b 
P ( X )  + R ( X ) , X  # a. 
The above combined theory has the minimal models 
{P(a), R(a), Q(b)} and {P(b), R(a), Q(b)}. The union of the 
original theories has the minimal model { P( a) , P( b) ) R( a), 
Q(b)} and since the instantiated integrity constraint is t 
P(a), P(b), we observe that indeed this algorithm gives a 
maximal and consistent combination of the theories. 
0 
Theorem 4: C(T1 , . . , T k ,  IC) as given by Algorithm 4.2 is 
a maximal combination of TI , . , Tk. 
Proof: 
a) C(T1 , . . , T k )  IC) is consistent because, for all satisfiable 
instances of integrity constraints t (PI, . , Pk)@ we restrict 
the rules (in STEP 5) which expand PI@, . , Pke, and add a 
set of disjunctive facts in STEP 3, to make sure they are not 
satisfied by the resulting combination. 
b) C(T1, . . , T k  , IC) is correct because, besides restricting 
the rule, the disjunctive fact we add has all its minimal models 
as a subset of TI U . 
c) (maximality) 
Let C be the minimal model of Tl U a
-
.
 U Tk. (Note that 
2'1 U . U Tk is a Horn theory.) 
Let B = {AI, . , Ak} be the ground atoms present in S in 
STEP 2. 
In STEP 5 by restricting the rules we make sure that 
atoms in B cannot be proven using those rules. Also it 
is clear that atoms in C - B belong to all models in 
U Tk. 
MINSET(C(T1, 
* * ) Tk, IC). 
Let A =  B - C  
Similar to Algorithm 4.1 we split B into a set {rnl, . , r n l }  
of maximal models and construct T in STEP 3 which has 
{rnl,... , rnr} as the only minimal models. The rest of the 
U 
proof is the same as in the proof of Theorem 3. 
C. A Syntactic Approach 
Several syntactic methods have been suggested to compile 
integrity constraints into a deductive database [ll], [4]. In 
these approaches, the integrity constraints are embedded as 
part of the deductive rules and the integrity constraints are 
no longer needed. Normal clauses result in the theory com- 
bined with the integrity constraints. It would then appear 
that multiple knowledge bases might be combined syntac- 
tically by compiling the integrity constraints to their union 
using the methods suggested in [ll] and [4]. We show by 
a counterexample that this approach does not provide the 
desired result. We first describe Kowalski and Sadri's method 
[ll] and then give counterexamples to show why such a 
syntactic approach cannot be used to combine knowledge 
bases. However, applying Algorithm 4.2 to the union of the 
theories provides the desired result. 
Kowalski and Sadri in [ll] give a method to compile 
integrity constraints inside a theory. They assume that one 
atom in every integrity constraint is more preferable than the 
rest of the atoms. They call it the retractable atom of the theory. 
Algorithm 4.3 (Kowalskidadri algorithm) 
INPUT: A theory T, and a set of s integrity constraints, IC = { 
IC1, . . , IC, } where for each integrity constraint a retractable 
atom is specified. 
OUTPUT: Revised theory that satisfies all the integrity con- 
straints in IC. 
MAIN STEP: For i =1 to s, Call Eliminate(T, IC,). 
Procedure Eliminate(T: Theory, IC: an integrity constraint 
with its retractable atom specified); 
{Comments: T is the input theory and also the revised theory 
that is output.} 
begin 
If t A(t),Conj is the integrity constraint, where A(t) is 
retractable, to eliminate it by compiling it into the rules, 
replace each deductive rule in T of the form A(t') t Conj' 
1. A@')@ t 
Conj'B, TConjB, where B is the mgu of A(t) and 
A(t'). 
2. A(t') t Conj', t # t', where t' is an instant of t. 
end 
0 
The following example explains this technique. 
Example 4.5: Let the theory be P ( X )  c Q ( X )  and the 
by 
integrity constraints be 
IC1 : t P ( Y ) , R ( Y )  
IC2 : + P(b),S(c). 
When we eliminate IC1, the retractable atom P ( Y )  in IC1 
unifies with the head of the rule P(X) t Q ( X )  and after 
elimination we obtain the rule P ( X )  t Q ( X ) ,  i R ( X ) ,  using 
STEP 1 of the procedure Eliminate. When we eliminate IC2, 
we have 
P(b) t 
Q(b), iR(b), lS(c), by STEP 1 of the method and 
P ( X )  t Q ( X ) ,  i R ( X ) ,  X # b, by STEP 2 of the method. 
0 

BARAL et al.: COMBINING MULTIPLE KNOWLEDGE BASES 
215 
If we are given a preference relation between atoms through 
retractable atoms in each integrity constraint, we can use 
Kowalski and Sadri’s syntactic method. We initially assumed 
that we are not given any such information. In that case, 
one may think that to compile the integrity constraint t 
P(u),Q(b),R(c) when the retractable atom is not given, 
we compile three integrity constraints t P(u)? Q(b). R(c), 
+ Q(b), P(u), R(c), and + R(c), Q(b). P(a) where the 
first atom in each is the retractable atom. We show by a 
counterexample that such a syntactic method of compiling 
each integrity constraint a multiple number of times, each time 
assuming a different atom as retractable does not necessarily 
provide a consistent combination. 
Example 4.6: Consider combining four theories each con- 
sisting of a single fact, A; B; C; D, respectively, and the set 
of integrity constraints IC = { +- B, D ; t A. B ; t A, C}. 
After eliminating all versions of the integrity constraints from 
the union of the theories, we obtain P = {A +- -B. 4’; 
B t 
1 D .  TA; C t TA; D t -B}. 
One of the minimal models in 
MINSET(P), {A, B}, 
violates the integrity constraint. Hence, 
the syntactic approach does not provide the desired result. 
Using Algorithm 4.2 we generate the theory { A  V C; D V 
C ; D  V B} whose minimal models are {A.D}, {C.D}, and 
{B. C} and they all agree with the integrity constraint. 
0 
D. Incremental Combination of Theories 
In the previous sections we gave algorithms to maximally 
combine a set of theories, which do not have negation in the 
body of the rules of the theory, so that the combination of the 
theories is correct and consistent. Consider the case when we 
have combined the theories TI, . . . , Tk to obtain a possibly 
disjunctive theory T ,  and we obtain another set of theories 
Tk+1,. . . . T, to be combined with the initial set of theories. 
We would like to combine the partially combined theory T 
with the new set of theories so as to obtain an equivalent theory 
to the one we would have obtained if we had started with the 
theories TI, . . . . T,. But now we cannot use the combining 
algorithm given in the previous sections. They can only be 
used to combine Horn theories without negation; and in this 
case T could be a disjunctive theory. We consider this problem 
in the following subsection. 
I )  Integrity Constraints and Disjunctive Theories: A dis- 
junctive theory has multiple minimal models. As defined 
before, we say a disjunctive theory satisfies an integrity con- 
straint if it is satisfied in all minimal models of the disjunctive 
theory. To combine theories we have to first determine whether 
or not the naive union of the theories violates the integrity 
constraints. Note that although the algorithms in previous 
sections generated a disjunctive theory, they made sure that 
the integrity constraints were satisfied. 
Definition 4. I Semantic Definition: A disjunctive theory is 
said to violate an integrity constraint, iff it is violated in some 
minimal model. 
0 
Let IC : t PI.. . . . Pk be an integrity constraint and 
T be a theory. If T is a Horn theory then T violates IC 
if t PI. . . . , P k  has a solution with respect to T, 
i.e., T 
j 3(P1,. . . , Pk). But if T has more than one minimal model 
or it is a disjunctive theory this is not the case. If T is a 
disjunctive theory t PI, . . . , P k  will have a solution with 
respect to T iff t PI, . . . . P k  has a solution in all minimal 
models of T ;  while t P I ,  . . - . Pk violates T iff 
P I ,  . . . , Pk 
has a solution in at least one minimal model of T. It may 
therefore be seen that, determining if an IC is violated by a 
disjunctive theory is not trivial. 
Definition 4.2 Syntactic Definition: A query t Q is true in 
at least one minimal model of a theory T iff 3K, where K is 
0 
The proof of the equivalence of the syntactic and seman- 
tic definition of a disjunctive theory violating an integrity 
constraint is similar to the proof of the equivalence of the 
syntactic and semantic definition of Minker’s GCWA [ 151. 
The algorithm to determine if a disjunctive theory violates an 
integrity constraint can easily be constructed using the above 
syntactic definition and Minker and Rajasekar’s [20] algorithm 
to solve a negative ground query with respect to a disjunctive 
theory. 
But even after finding all instances of the integrity con- 
straints that violate the disjunctive theory, we do not know 
which particular minimal model is violated. Without knowing 
the particular minimal model violated, it is difficult to subdi- 
vide those particular minimal models violated, into a set of 
maximal nonviolating models. This is not a problem in the 
case of Horn theories as there is only a single minimal model. 
The following algorithm explains semantically what we 
mean by a combination of disjunctive theories. In this algo- 
rithm we start with the set of minimal models of the union 
of the theories, and start dividing these minimal models such 
that we get a set of maximal models, such that none of these 
maximal models violate the integrity constraints. We call this 
algorithm a semantic algorithm because we do not have an 
algorithm to find which integrity constraints are violated by 
which minimal model. With the hope that such an algorithm 
can be found later, we present the following algorithm. We 
also hope the following algorithm will be used as a guideline 
to a more practical algorithm. 
Algorithm 4.4 (Semantic Combination of disjunctive theories) 
INPUT: A set S = {TI. . . . . Tk} of IC disjunctive theories and 
IC = { I C l , .  . . . IC,}, a set of n integrity constraints. 
OUTPUT: A combined theory of the k disjunctive theories, 
such that it satisfies all the integrity constraints and is maximal. 
STEP 1: Find all minimal models of TI U . . . U Tk. 
Let the set of minimal models be m = { m l ,  . . . . mt}. 
For L =1 to iz (there are n integrity constraints) Do 
Begin 
newm := 0; 
For j =1 to t, DO 
Begin 
Solve IC, with respect to m3. 
Divide 7 n J  into a set of minimal models as follows. 
Apply Algorithm 4.1 to (m3,1Cz) up to STEP 3 and let 
m; := be the set of minimal models . 
newm := newm U my. 
end 
clause (possibly nil) and T k Q V K and T y K. 
STEP 2: ti := t; 

216 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
m := newm 
t;+l := number of elements in newm. 
end 
STEP 3: 
Let m = { m l , .  , mtn+l 1; 
Remove all models from m which are subsets of some other 
model and let the resultant set be m’. Construct a theory whose 
only minimal models are the models in m‘. 
0 
We illustrate the above algorithm by the following example. 
Example 4.7: Consider the combined disjunctive theory (T): 
A V B  t C 
C V D  
E 
F 
which is inconsistent with respect to the integrity constraint 
+ B,C. 
The minimal models of the theory are ml = {D, 
E ,  F}, m2 = 
{C, B, E, F }  and mg = {C, A, E ,  F}. m2 violates the integrity 
constraint and therefore in STEP 2 of the algorithm it is split to 
m21 = {C, E, F }  and m22 = {B, E ,  F}, so that each of them 
satisfy the integrity constraint. In STEP 3 of the algorithm we 
have m = {m~,m3,m21,m2~}. 
Since m21 c m3, and only 
the maximal sets should be present in m, we remove m21 
from m. Hence, the consistent combined theory should have 
0 
Theorem 5: Algorithm 4.4 generates a maximal combination 
of theories. 
Proofi (Using Theorem 2 and Theorem 3): By Theorem 
3, STEP 2 of Algorithm 4.4 divides minimal models to 
a maximal set of minimal models. Hence, by Theorem 2, 
0 
2) Incremental Combination Using Partial Backtracking: 
Let S = {T1,...,Tk,.--,Tn} 
be a set of Horn theories, IC 
be a set of integrity constraints, and T = C(T1, - . , Tk, IC). 
T could be a disjunctive theory. We assume that we are given 
the first IC theories of S and subsequently, we need to combine 
the rest of the theories in S. If T is a disjunctive theory, 
we cannot use the previous algorithms. We now provide a 
method to combine the remaining theories with the previously 
combined theories. Our method takes advantage of the fact that 
T is a maximal and consistent combination of Horn theories. 
By virtue of the combining algorithm of Horn theories the 
clauses in T are of two major types. The first type is the set 
of disjunctive facts and the second type is the restricted rules 
and the unaffected rules and facts. We take the atoms in the 
disjunctive facts and combine these atoms with the remaining 
clauses of the theory T ,  to obtain a new theory TI. The theory 
TI is addition equivalent to the union of the original theories 
Tl , . . . , Tk, where addition equivalence of Horn theories is 
defined as follows: 
Definition 4.3: We say two Horn theories TI and TZ are 
addition equivalent to each other (denoted by TI G T2) iff 
VS, where S is a set of Horn clauses (possibly empty), the 
minimal model of Tl U S is same as the minimal model of 
0 
the minimal models as {ml, m3, mzz}. 
Algorithm 4.4 generates a maximal combination. 
Tz U S and vice versa. 
P ( X )  + Q ( X )  
&(a) 
Example 4.8: Consider the theory T :  
Q(b)* 
P(X> + Q(X),X # a,X # b 
P(a> 
P(b) 
&(a) 
Q(b)* 
A theory which is addition equivalent to this theory is 
The theory T’ = P(a);P(b);Q(b);Q(a) 
is not addition 
equivalent to T ,  even though their minimal models are same. 
This is because P(c) is in the minimal model of TU {Q(c)}, 
while it is not in the minimal model of TI U {Q(c)}. 
0 
Algorithm 4.5: The incremental combination algorithm 
INPUT: T I ,  . . . , T, are Horn theories. T = C(T1, . . . , Tk); and 
Tk+1,. , T, are to be combined with T .  IC is the set of 
integrity constraints satisfied by each Ti, i = 1 . . . n and T .  
OUTPUT The combined theory of T and Tk+1,. 
STEP 1: By virtue of construction of T using Algorithm 4.2, 
T = Gens U Gen4 U Gens where Geni is the theory added 
in the STEP i of Algorithm 4.2. Gens consists of a set of 
disjunctive clauses. Gens consists of the noninterfering facts 
and Gens consists of the restricted rules and the noninterfering 
rules. 
STEP 2: FACTS := The set of atoms present in the clauses 
of Gens. Let TI := FACTS U Gen4 U Gens. By virtue of 
the construction of T using Algorithm 4.2 and as proved in 
Theorem 6, TI 
TI U ... U Tk Now use Algorithm 4.2 to 
U .  . .UTk. 
Proof: The difference between TI and TI U . . . U Tk is 
, T,. 
combine T’, Tk+1,. . , T,. 
0 
Theorem 6: In STEP 2 of Algorithm 4.5, T’ G 
that some clause (C) like: 
in TI U . . . U Tk is replaced by the set of clauses: 
Ci : P(a11, . . . , ai,), 
P(X1, . . , X,) + Body, 
Cm : P(a,l,...,a,n) 
and 
Cm+l : P ( X l , . . . , X n )  + Body,X11 # all,...,Xln # 
ai,, . . . , Xmn # am, in TI. 
Since for all such cases C 
i.e., for any set of clauses S, C U S has the same minimal 
model as C1 U-. .U Cm+l U S ;  we have TI 
TI U .  . .UTk. 0 
Theorem 7: If Ti = Ti then C(T:,Tl,...,Tk) and 
C(Ti, TI, . . , Tk) have the same minimal models. 
Ti, Ti U TI U ...Tk and Ti U 
TI U . . . Tk have the same minimal models. Hence, the same 
integrity constraints violate them and since the combination 
is a maximal combination and the set of minimal models of 
the combinations are unique, the maximal combination of the 
above two sets of the theories have the same minimal models. 
0 
Theorem 8: Associativity of the combination: C(T’, Tk+1, 
C1 U * . U Cm+l, 
- 
Proof: Since Ti 
, T,) has the same minimal models as C(T1, . , Tk, 
, 
0 
In the above algorithm we decompose T into a Horn theory 
TI, strongly equivalent to the initial theory component of T .  
But this does not mean that we are starting all over again. That 
Tn). 
Proof: From the previous two theorems. 

BARAL et al.: COMBINING MULTIPLE KNOWLEDGE BASES 
217 
is because any integrity constraint that violates TI U . . . U Tk 
will also violate T’, but we can determine its violation with 
respect to T’ very easily as we only use the facts (not any 
rules) when we try to solve it as a query. Hence, we call 
our algorithm a partial backtracking algorithm. The following 
example explains the incremental combination algorithm. 
Example4.9: Let TI def { P ( X )  +- 
Q ( X ) : Q ( X )  +- 
R ( X ) ;  R(u)}, T2 ef {P(b)}, T3 %if {P(c)}, and the integrity 
constraint be t P ( X ) , P ( Y ) ,  X # Y .  
If we combine Tl and T2 first we obtain C(T1,T.) = 
{ P ( X )  + Q ( X ) . X  # u : Q ( X )  +- R(X);R(a):P(u) 
V 
P(b) 1. 
T’ = { P ( X )  + Q ( X ) , X  # u ; & ( X )  
+- 
R ( X ) : R ( a ) ; P ( a ) ;  
P(b)l. 
C(T’,T3) = { P ( X )  + Q ( X ) , X  # 
a : Q ( x )  + 
R ( X ) ;  R(a): P(u) v P(b) v P(c)}. 
If we had combined all of the theories together as in Example 
4.3 we would have obtained C(Tl,T2.T3) = { P ( X )  t 
& ( X ) , X  # U: Q ( X )  t R ( X ) :  R(a): P(n) v P(b) v P(c)} 
which is the same as C(T’, T3). 
Notice that when we solve the integrity constraint + 
P ( X ) ,  P(Y), X # Y with respect to T’ U T3 we do not use 
any rules in T‘ while when we solve the integrity constraint 
t P ( X ) .  P(Y), X # Y with respect to TI U T2 U T3 we use 
the rules in TI. 
0 
E. Normal Theories 
We now allow negative literals in the body of rules of a 
theory. In general such theories have multiple minimal models. 
As explained in the previous subsection, it is extremely diffi- 
cult to combine theories that have multiple minimal models. 
We shall assume that our theories are stratified. In that case, 
such a theory has a single preferred model [21] among its 
minimal models, called the perfect model. If we combine 
theories, T I ,  . . . , Tk all of which are stratified, it does not 
necessarily mean that T = TI U . . . U Tk is also stratified. If T 
is not stratified it is again very difficult to restrict it with the 
integrity constraints. We further assume that T is stratified. If 
T is stratified then we need an algorithm similar to Algorithm 
4.2 to combine the theories appropriately. Since T has negated 
atoms in the body of the rules, the combined theory might also 
have negated atoms in the body of its rules. 
The combined theory, which will be a disjunctive theory 
with negated atoms in the body of its rules, will have multiple 
minimal models. But, as in stratified Horn theories, where we 
consider only the perfect model among all minimal models, 
here we want to consider a subset of the set of minimal models, 
i.e., the set of minimal models present in MINSET(P) (defined 
in Definition 3.4). 
We now give an example and show why Algorithm 4.2 is 
not sufficiently powerful to combine normal theories. 
Example 4.10: Consider the following theories. 
Ti : 
T2 : 
P ( X )  t- T Q ( X )  
R(a) 
&(a). 
Let the integrity constraints be +P(n),R(u) and t- 
Step 1 of Algorithm 4.2 gives us 5’ =<+ Q(u), R(u), {&(a). 
STEPS 2 and 3 give T = & ( U )  V R(a). 
STEP 5 adds the rule as it is. 
The combined theory is 
Q(u) V R(a) 
P ( X )  
+- i Q ( X ) .  
Q(a), R(a). 
R(a)}. {I >. 
The integrity constraint + P(u), R(a) is violated in one 
minimal model of the combined theory even though it did not 
violate the original union of the two theories. This is because 
before the combination, &(U) was true and P(a) was false in 
all minimal models, but after the combination Q(u) became 
false in some minimal models and P(u) became true in those 
minimal models. Also, the new combination is not correct 
according to Definition 3.8. That is because {P(u), R(u)}, 
a minimal model of the combination is not a subset of any 
minimal model of the union of the original theorems. 
In order to solve these problems one needs to restrict 
rules with negative literals in their body that are added as 
disjunctions to the combined theory. In this example, since 
&(a) is added as a disjunction we would like to restrict rules 
with - Q ( X )  in their bodies. Hence, we restrict P ( X )  +- 
l Q ( X )  as P ( X )  e l Q ( X ) . X  # n and the combined theory 
becomes 
&(a) ” W a )  
P ( X )  t- i & ( X ) ,  X # a 
which does not violate any of the integrity constraints. 
4.2 
Algorithm 4.6: The General Combination Algorithm 
INPUT: 
1. A set of k normal theories {TI . . . Tk} which have to be 
combined. Each of the T, is stratified. The union of the TZ’s 
is also stratified. 
2. A set of s integrity constraints, IC = {ICl, . . . , IC,} where 
each integrity constraint is satisfied by each of the theories. 
OUTPUT: A theory T ,  which is the maximal combination of 
the input set of theories, such that T is also satisfied by each 
of the integrity constraints. The combined theory T can be 
disjunctive. 
STEP 1 to STEP 5 are same as in Algorithm 4.2. 
STEP 6: For each rule R in the union of the theories, that has 
a negative literal in its body, say 1 P ( X 1 .  . . . . Xl), if there 
exists a substitution H such P(X1, . . . , Xl)H is a member of 
{Al.. . . . Ap} defined in STEP 2 of Algorithm 4.2, then add 
Restrict(R, 0) to the combined theory. (Restrict is defined in 
Algorithm 4.2.) 
end 
STEP 7: T := T U all the rules in TI U . . . U Tk that do not 
appear in R (defined in STEP 5 of Algorithm 4.2) and are not 
restricted in STEP 6 of this algorithm. 
0 
Theorem 9: Let Tl . . . Tk be stratified Horn theories that 
consist of general Horn clauses and let Tl U . . . U Tk also be 
stratified. Then C(Tl, . . . . Tk, IC), obtained by Algorithm 4.6 
is a maximal combination with respect to TI U . . . U Tk. 
0 
We now give the combination algorithm that uses Algorithm 
C(T1 U . . . U Tk, IC) := T .  

218 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
Proofi Consistency and Correctness: In Step 1 to Step 5 
of the algorithm, the resulting theory is made consistent with 
the integrity constraints. In Step 6, by restricting the rules with 
negative literals in their body that are added as disjunctions to 
the combined theory we have correctness. Steps 6 and 7 do 
not affect the fact that the resulting theory is made consistent 
with respect to the integrity constraints. 
Maximality: The only difference between Algorithm 4.6 and 
Algorithm 4.2 is that in the former we restrict the rules with 
negative literals in their body that are added as disjunctions 
to the combined theory. A particular ground instance of the 
head of these rules is not present in any minimal model of 
TI U .  UTk, using the unrestricted form of the rule. Therefore, 
0 
In the case of theories with negated atoms in the body of its 
rules, the incremental combination of theories is not effective. 
The reason is that the combination is not associative. The 
following example illustrates what might happen. 
by restricting the rule, we do not loose maximality. 
Example 4.11: Consider the theories 
Tl 
T2 
T3 
P(X) + iQ(W R(a) 
Q(a) 
Let the integrity constraint be t P(u), R(a). 
C(Ti,T’) = {P(X) 
+ l Q ( X ) ;  &(a)). 
C(C(Ti, T3), Tz) = { P ( X )  
+ i Q ( x ) Q ( a ) ;  
R(a);). 
c(Ti,T2) = {P(X) + -Q(X),X # a; P(a)v R(a)} 
C(C(T1, T2), T3) = C(T1, T2)U {&(a)). 
0 
The nonmonotonic nature of negation is the reason the com- 
bination is not associative. One way to deal with this is to 
consider the preference relation dictated by the syntax of the 
program. In the above example, when we combine TI and Tz, 
its union has a perfect model {P(a),R(a)), which violates 
the integrity constraint. Since R(a) is a fact and P(u) is 
obtained using default reasoning in the union of TI and Tz, 
we might assume that R(a) is preferable to P(u). In that case, 
we can eliminate P(u) to make the combination consistent. To 
eliminate P(u), we restrict the rule with P(X) in the head by 
adding X # a to the body. We then obtain the combined 
theory to be {P(X) t -Q(X),X # a; R(a)}. But this 
approach is not general enough. If we have R(X) t -Q(X) 
instead of R(a) in T2, then we can obtain both P(u) and R(a) 
using default reasoning and we cannot decide how to choose 
between P(u) and R(a). 
v. COMBINING THEORIES 
AND THE VIEW UPDATE PROBLEM 
The problem of view update in databases has been discussed 
by Fagin et al. [7], [6], Rossi and Naqvi [24], and others. 
They deal with the ambiguity that arises from translating a 
view update to an update over the underlying base relations. 
Consider the database D = {P(X) t bl(X),P(X) + 
b2(X)}, where P ( X )  can only be defined intensionally. When 
P(u) is to be inserted to this database, by only changing 
base facts (the basic requirement of the view update problem) 
there are two possible updated theories TI = D U {bl(a)} 
and T2 = D U {bz(a)}. Fagin et al. want the update to 
reflect both these theories and to have the updated theory a 
disjunctive theory which has multiple models (in this case 
two), each reflecting a possible updated theory. Rossi and 
Naqvi [24] give algorithms to deal with a general sequence of 
updates in an efficient way (both time and space). In the above 
example, the updated theory obtained by Rossi and Naqvi [24] 
is { P ( X )  c bl(X); P(X) t bz(X); bl(a) Vbz(u)}, which is 
a disjunctive theory. In this paper, we dealt with the problem 
of combining a set of theories represented by logic programs, 
where we do not prefer any one theory over the others. 
In the view update problem, rules are considered to be 
universal and hence unchangeable. In the case of combining 
theories, rules are part of individual theories. Since they 
lose their individuality when we combine them, we permit 
restrictions to them in the modified theory. 
The insertion problem in view updates as discussed in [24] 
is different than combining the facts to be inserted with the 
original theory. In the case of combining multiple knowledge 
bases, the combined theory has to be consistent with respect 
to a set of integrity constraints. 
Fagin et al. in section 3 of [7] consider the case of 
updating databases in the presence of integrity constraints. 
Their approach requires giving priorities to sentences of the 
theory. In the case of combining theories, we are concerned 
with the situation where priorities are not available. 
If the integrity constraints are considered part of the original 
theory and facts are inserted, then in the updated theory the 
inserted facts have to be true. In the case of combining 
multiple theories, the combination is affected by the integrity 
constraints and the facts to be combined may become disjuncts 
in the combined theory. 
On the other hand, the integrity constraints could be con- 
sidered as deletions followed by insertions. In that case, a 
deletion is forced after any insertion. We deal with this case 
later, when we discuss deletions. 
Even in the absence of integrity constraints, while combin- 
ing theories we can modify rules. This is not allowed during 
insertion in the view update problem. The following example 
shows the differences in the two approaches: 
Example 5.1: Let the initial theory T be 
P(X) 
b l ( X )  
P ( X )  
bz(X) 
bl (a). 
P(X) + b l ( X )  
P ( X )  
bz(X) 
bl (a) 
bl(b) v b2(b). 
If we want to insert the fact P(b) to the theory T we obtain 
TI to be 
If we want to accomplish the insertion of fact P(b) by 
combining T with the theory {P(b)} we obtain the theory 
T2 to be 
P(X) 4.- 
b l ( X )  
P(X) + b2(X) 
bl (a) 
P(b). 
Note that TI is not correct according to our definition of 
correctness as bl(b) is present in a minimal model of TI, even 
though it is absent in the minimal model of T U {P(b)}. 0 
The deletion in the view update problem is similar to making 
a theory consistent with respect to an integrity constraint. 

BARAL et al.: COMBINING MULTIPLE KNOWLEDGE BASES 
219 
When we combine a set of theories we essentially try to 
make the union of the theories consistent with respect to the 
integrity constraints. The deletion of P(u) A &(a) from a 
theory T is equivalent to making T consistent with respect 
to the integrity constraint +- P(u), &(a). The updated theory 
TI in the view update problem neither changes nor deletes 
rules. When we make a theory consistent with respect to an 
integrity constraint we might change the rules. Let this theory 
be called T2. Because of this T1 is not necessarily maximal, 
while T2 is always maximal. The following example illustrates 
this situation. 
Example 5.2: Let the original theory T be 
P ( X )  + b l ( W  
P ( X )  + b2(X) 
b l  ( a )  
b2(a). 
P ( X )  + h ( X )  
P ( X )  + b2(X) 
-b1(a) 
+(a). 
If we want to delete P(u) from T ,  the updated theory TI is 
If we treat deleting P(u) as making T consistent with 
respect to the integrity constraint +- P(u) we obtain the theory 
T2 to be 
P ( X )  + bl(X).X # a 
P ( X )  + bZ(X).X # a 
b l  ( a )  
b2(a). 
Since bl(u) and b2(u) are in the minimal model of T2 and 
0 
not in the minimal model of TI, TI is not maximal. 
VI. CONCLUSION AND FURTHER 
WORK 
In this paper, we presented algorithms to combine knowl- 
edge contained in Horn theories. We did so in such a manner 
as to achieve a maximal theory. We defined the concept of 
a maximal theory, and we proved the maximality of our 
algorithms. We gave methods to combine different positive 
theories written in the same language such that the combi- 
nation does not violate the integrity constraints and yet they 
are a maximal combination. We defined what it means for an 
integrity constraint to violate a disjunctive knowledge base and 
defined the notion of strong equivalence of logic programs, 
and used them in our algorithms and proofs. We also gave 
algorithms to combine them incrementally. Finally, we gave 
an algorithm to combine normal theories (i.e., theories with 
negation in their body) maximally, when the theories and their 
union are stratified. 
We used a a restricted syntax for integrity constraints. We 
are presently working on generalizing the approach given in 
this paper to general integrity constraints. 
Although we have given a semantic algorithm to combine 
disjunctive theories, a more practical algorithm is desirable. 
Practical algorithms to combine normal theories that are not 
stratified are also needed. 
ACKNOWLEDGMENT 
We wish to express our appreciation to the National Science 
Foundation for their support of our work under Grant IRI-86- 
09170 and the Army Research Office under Grant DAAL-03- 
88-K0087. We would also like to thank V. S. Subrahmaniar, 
for insightful comments on an earlier draft of the paper. 
REF ER EN c E s 
K. R. Apt, H. A. Blair, and A. Walker, “Toward a theory of declarative 
knowledge,” in Foundations of Deductive Databases and Logic Pro- 
gramming, J. Minker, Ed. Los Altos, CA: Morgan-Kaufmann, 1988, 
pp. 89-148. 
K. R. Apt and M. H. van Emden, “Contributions to the theory of logic 
programming,” J. ACM, vol. 29, no. 3, pp. 841-862, 1982. 
C. Baral, J. Lobo, and J. Minker, “Generalized well-founded semantics 
for logic programs,” Tech. Rep. CS-TR-2330, Dep. Comput. Sci., Univ. 
of Maryland, College Park, MD 20742, 1989. A shorter version appears 
in Proc. CADE ’90. 
U. S. Chakravarthy, J. Grant, and J. Minker, “Foundations of semantic 
query optimization for deductive databases,” in Proc. Workshop Foun- 
dations Deductive Databases and Logic Programming, J. Minker, Ed., 
Washington, DC, Aug. 18-22, 1986, pp. 67-101. 
K. L. Clark, “Negation as failure,” in Logic and Data Bases, H. Gallaire 
and J. Minker, Eds. 
R. Fagin, G. Kuper, J. Ullman, and M. Vardi, “Updating logical 
databases,” in Advances in Computing Research, Vol. 3, 1986, pp. 1-18. 
R. Fagin, J. D. Ullman, and M. Y. Vardi, “On the semantics of updates 
in databases,” in ACM SIGACTISIGMOD Symp. Principles Database 
Syst., 1983, pp. 352-365. 
M. Fitting, “A Kripke-Kleene, Semantics for logic programs,” J. Logic 
Programming, vol. 3, pp. 93-114, 1986. 
M. Fitting and M. Ben-Jacob, “Stratified and three-valued logic pro- 
gramming semantics,” in Proc. 5th Int. Conf Symp. Logic Programming, 
R. A. Kowalski and K. A. Bowen, Eds., Seattle, WA, Aug. 15-19, 1988, 
pp. 1054-1069. 
M. Gelfond and V. Lifschitz, “The stable model semantics for logic 
programming,” in Proc. 5th Int. Conf Symp. Logic Programming, R. A. 
Kowalski and K. A. Bowen, Eds., Seattle, WA, Aug. 15-19, 1988, pp. 
1070-1080. 
R. Kowalski and F. Sadri, “Knowledge representation without integrity 
constraints, draft manuscript, Dec. 1988. 
-, 
“An application of general purpose theorem proving to database 
integrity,” in Proc. Workshop Foundations Deductive Databases Logic 
Programming, J. Minker, Ed., Washington, DC, Aug. 18-22, 1986, pp. 
477-5 17. 
J. W. Lloyd, Foundations of Logic Programming, second ed. Berlin, 
Germany: Springer-Verlag, 1987. 
J. W. Lloyd and R. W. Topor, “Making Prolog more expressive,”/. Logic 
Programming, vol. 1, no. 3, pp. 225-240, Oct. 1984. 
J. Minker, “On indefinite databases and the closed world assumption,” 
in Lecture Notes in Computer Science 138. Berlin, Germany: Springer- 
Verlag, 1982, pp. 292-308. 
J. Minker and J. Grant, “Integrity constraints in knowledge based 
systems,” in Knowledge Engineering, Vol. II, Applications, H. Adeli, 
Ed. New York: McGraw-Hill, 1990, pp. 1-25. Also CS-TR-2223 of 
Univ. of Maryland, College Park. 
J. Minker and D. Perlis, “Computing protected circumscription,”J. Logic 
Programming, vol 2, no. 4, pp. 235-249, Dec. 1985. 
-, 
“Applications of protected circumscription” in Lecture Notes on 
Computer Science, Vol. 170, 7th Conf: Automat. Deduction, May 1984, 
pp. 414425. 
.-, 
“Protected circumscription,” in Proc. Workshop Non-Monotonic 
Reasoning, Oct. 17-19, 1984, pp. 337-343. 
J. Minker and A. Rajasekar, “Procedural interpretation of non-Horn logic 
programs,” in Proc. 9th Int Conf Automat. Deduction, E. Lusk and R. 
Overbeek, Eds., Argonne, IL, May 23-26, 1988, pp. 278-293. 
T. C. Przymusinski, “On the declarative semantics of deductive 
databases and logic programming,” in Foundations of Deductive 
Databases and Logic Programming, J. Minker, Ed. Los Altos, CA: 
Morgan-Kaufmann, 1988, pp. 193-216. 
-, 
“Every logic program has a natural stratification and an iterated 
fixed point model,” in Proc. 8th ACM SIGACT-SIGMOD-SIGART Symp 
Principle Database Syst., 1989, pp. 11-21. 
-, 
“Perfect model semantics,” in Proc. 5th Int. Conf and Symp. 
Logic Programming, R. A. Kowalski and K. A. Bowen, Eds., Seattle, 
F. Rossi and S. Naqvi, “Contributions to the view update problem,” in 
Proc. Int. Conf Logic Programming Lisbon, 1989, pp. 398415. 
New York: Plenum, 1978, pp. 293-322. 
WA, Aug. 15-19, 1988, pp. 1081-1096. 

220 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 3, NO. 2, JUNE 1991 
[25] M. H. van Emden and R. A. Kowalski, “The semantics of predicate logic 
as a programming language,” J. ACM, vol. 23, no. 4, pp. 733-742,1976. 
[26] A. Van Gelder, K. Ross, and J. S. Schlipf, “Unfounded sets and well- 
founded semantics for general logic programs,” in P m .  7th Symp 
Principles Database Syst., 1988, pp, 221-230. 
Chitta Baral received the B.Tech. (hons) degree in 
computer science and engineering from the Indian 
Institute of Technology, Kharagpur, in 1987, and the 
M.S. degree in computer science from the Univer- 
sity of Maryland, College Park, in 1990 
He is currently a graduate student pursuing the 
Ph.D. degree in computer science at the University 
of Maryland. He will join the University of Texas at 
El Paso in the Fall of 1991. His current research in- 
terests include nonmonotonic reasoning, knowledge 
representation, logic programming, databases, and 
data structures. 
Sarit Kraus received the B.Sc. degree in mathe- 
matics and computer science (with distinction), the 
M.Sc. degree (with distinction), and Ph.D. degree 
in computer science from the Hebrew University, 
Jerusalem, Israel, in 1982, 1983, and 1989, respec- 
tively. 
She was a Visiting Assistant Professor at the 
institute for Advanced Computer Studies and the 
Department of Computer Science, University of 
Maryland, College Park in 1989-1990. She joined 
the Hebrew University in the Fall of 1990. Her 
current research interests include automated negotiations, programs capable 
of intelligent interaction with other agents, logic programming, planning, and 
nonmonotonic logics. 
Jack Minker (M’76SM’8&F’91) received the 
B.A. degree (cum laude with honors) in mathematics 
from Brooklyn College in 1949, the M.S. degree in 
mathematics from the University of Wisconsin, in 
1950, and the Ph.D. degree in mathematics from 
the University of Pennsylvania, in 1959. 
He is a Professor of Computer Science in the 
Department of Computer Science and the Institute 
for Advanced Computer Studies. 
Dr. Minker serves on the Editorial Boards of a 
number of journals such as the Journal ofLogic 
Programming, IEEE EXPERT, and Information System Journal. He also served 
as Chairman of the Advisory Committee on Computing to the National Science 
Fouqdation (1979-1982). In 1985, he received the Association for Computing 
Machinery’s Outstanding Contribution Award for his work in human rights. 
He was also elected Fellow of the American Association for the Advancement 
of Science based on his work in artificial intelligence, database theory, and 
his efforts on behalf of human rights. He is also a fellow of the AAAI. 

