Symplectic 
Difference Systems: 
Oscillation and 
Spectral Theory
OndrÀáej Do≈°l√Ω
Julia Elyseeva
Roman ≈†imon Hilscher
Pathways in Mathematics

Pathways in Mathematics
Series Editors
T. Hibi
Toyonaka, Japan
W. K√∂nig
Berlin, Germany
J. Zimmer
Bath, United Kingdom

Each ‚ÄúPathways in Mathematics‚Äù book offers a roadmap to a currently well devel-
oping mathematical research Ô¨Åeld and is a Ô¨Årst-hand information and inspiration
for further study, aimed both at students and researchers. It is written in an
educational style, i.e., in a way that is accessible for advanced undergraduate and
graduate students. It also serves as an introduction to and survey of the Ô¨Åeld for
researchers who want to be quickly informed about the state of the art. The point of
departure is typically a bachelor/masters level background, from which the reader
is expeditiously guided to the frontiers. This is achieved by focusing on ideas and
concepts underlying the development of the subject while keeping technicalities to
a minimum. Each volume contains an extensive annotated bibliography as well as a
discussion of open problems and future research directions as recommendations for
starting new projects
More information about this series at http://www.springer.com/series/15133

OndÀárej Do≈°l√Ω ‚Ä¢ Julia Elyseeva ‚Ä¢
Roman ≈†imon Hilscher
Symplectic Difference
Systems: Oscillation
and Spectral Theory

OndÀárej Do≈°l√Ω (deceased)
Department of Mathematics and Statistics
Faculty of Science
Masaryk University
Brno, Czech Republic
Julia Elyseeva
Department of Applied Mathematics
Moscow State Technological University
‚ÄúSTANKIN‚Äù
Moscow, Russia
Roman ≈†imon Hilscher
Department of Mathematics and Statistics
Faculty of Science
Masaryk University
Brno, Czech Republic
ISSN 2367-3451
ISSN 2367-346X
(electronic)
Pathways in Mathematics
ISBN 978-3-030-19372-0
ISBN 978-3-030-19373-7
(eBook)
https://doi.org/10.1007/978-3-030-19373-7
Mathematics Subject ClassiÔ¨Åcation (2010): 39A21, 39A12, 47B39
¬© Springer Nature Switzerland AG 2019
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciÔ¨Åcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microÔ¨Ålms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciÔ¨Åc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, express or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afÔ¨Åliations.
This book is published under the imprint Birkh√§user, www.birkhauser-science.com, by the registered
company Springer Nature Switzerland AG.
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
The principal concern of the book is the qualitative theory of symplectic difference
systems. These are the Ô¨Årst-order systems
yk+1 = Skyk,
(SDS)
where yk ‚ààR2n and Sk ‚ààR2n√ó2n are symplectic matrices, i.e.,
ST
k J Sk = J ,
J =
 0 I
‚àíI 0

.
Symplectic difference systems are natural discrete counterparts of the linear Hamil-
tonian differential systems
y‚Ä≤ = J H(t) y,
(LHS)
where the coefÔ¨Åcient H(t) ‚ààR2n√ó2n is a piecewise continuous and symmetric
matrix, i.e., HT (t) = H(t). A common feature of (SDS) and (LHS) is that
their fundamental matrix is symplectic whenever it has this property at an initial
condition. Therefore, (SDS) and (LHS) are the most general linear difference and
differential systems, which have symplectic fundamental matrices.
Referring to the linear Hamiltonian differential system (LHS), the classical
qualitative theory of (LHS) is deeply developed; basic as well as advanced results of
this theory can be found, for example, in the monographs [70, 205, 248, 250, 328]
by Coppel, Kratz, Reid, and Yakubovich and in the recent monograph [203]
by Johnson, Obaya, Novo, N√∫√±ez, and Fabbri. Regarding symplectic difference
systems (SDS), the basic theory of (SDS) is presented in the monograph [16] from
1996 by Ahlbrandt and Peterson. As far as we know, there is no book or a survey
paper presenting in a uniÔ¨Åed way the results of the qualitative theory of (SDS),
which were obtained in this rapidly developing area in the last more than 20 years.
This book represents an attempt to Ô¨Åll in this gap by providing numerous results,
methods, and citations, which are till now scattered only in journal papers. Our aim
v

vi
Preface
is to cover both the traditional and the most current topics in the oscillation and
spectral theory of symplectic systems, which are in the heart of the present research
work.
The book is divided into six chapters. The Ô¨Årst one is motivating and contains the
results concerning the oscillation properties of the second-order Sturm-Liouville
difference equations (being the simplest symplectic difference systems) and linear
Hamiltonian differential systems (LHS). It also contains the elements of the discrete
calculus of variations and optimal control theory, in which symplectic systems arise
in very natural way as Jacobi systems in the second-order optimality conditions.
Another motivating factor for studying symplectic difference systems originates in
the classical Hamiltonian mechanics. In addition, for an easier reference, we present
in this chapter an overview of the main tools from matrix analysis needed in the
book, in particular about symplectic matrices, the Moore-Penrose pseudoinverse
matrices, and certain orthogonal projectors.
Chapter 2 starts with an introduction to the theory of symplectic difference
systems. We present the main notions and basic methods for the investigation of
symplectic difference systems. We introduce the concept of a conjoined basis, the
notion of the nonexistence of focal points, the Riccati difference equation and
inequality, and the Picone formula and relate these concepts to the positivity and
nonnegativity of a discrete quadratic functional. These results are easily connected
to the necessary and sufÔ¨Åcient optimality conditions presented in Chap. 1. We
also investigate the existence of extremal solutions of (SDS) at inÔ¨Ånity, called the
recessive and dominant solutions of (SDS) at inÔ¨Ånity, under a certain controllability
assumption and present basic transformation theory of symplectic systems. We
explain in details the role of these concepts in the oscillation theory of system (SDS).
In Chap. 3, we present one of the main tools of the modern oscillation theory of
(SDS), namely, a concept of the comparative index of two matrices (which can be
regarded as conjoined bases of (SDS)). It turned out to be very useful tool for solving
several open problems in the oscillation theory of (SDS). This chapter summarizes
basic properties of the comparative index, which will be needed in the subsequent
chapters.
In Chap. 4, we introduce the second main concept used in this book, a concept
of the multiplicity of a focal point of a conjoined basis of (SDS). During the past
years, it was a central problem of the oscillation theory of (SDS), how to count
the numbers of focal point of a conjoined basis between two consecutive integers.
This problem was resolved in [208] and opened a new area for the investigation
of (SDS). The next parts of this chapter relate the multiplicities of focal points
with the comparative index. This can be regarded as an essential contribution to
the oscillation theory of (SDS). The main results in this chapter also include, among
others, the Sturmian separation and comparison theorems and the transformation
theory for symplectic systems, which are presented in the form of explicit relations
between the multiplicities of focal points. These results now serve as an inspiration
for the progress in the investigation of the oscillation theory for continuous time
linear Hamiltonian systems (LHS).

Preface
vii
Chapter 5 concentrates on the second main topic of the book, the eigenvalue and
spectral theory of (SDS). We investigate the distribution of the (Ô¨Ånite) eigenvalues
of various boundary value problems associated with system (SDS). The main
essence of this chapter is that we consider the nonlinear dependence on the spectral
parameter in the coefÔ¨Åcient matrix, as well as in the boundary conditions. We
prove the oscillation theorems for discrete symplectic eigenvalue problems with
various boundary conditions (Dirichlet, separated, jointly varying), which relate
the number of Ô¨Ånite eigenvalues with the number of focal points of a speciÔ¨Åc
conjoined basis of the system. As a special case, we then obtain traditional results, in
which the dependence on the spectral parameter is linear, including the variational
characterization of the Ô¨Ånite eigenvalues and the Rayleigh principle. We also present
extensions of the basic theory to the case, when the coefÔ¨Åcients in (SDS) and/or in
the boundary conditions may oscillate with respect to the spectral parameter.
In Chap. 6, we collect various additional topics from the oscillation and spectral
theory of (SDS). We present the relative oscillation theory for symplectic difference
systems, as well as the inequalities and interlacing properties for (Ô¨Ånite) eigenvalues
of symplectic boundary value problems. We also investigate a nonoscillatory system
(SDS) on an unbounded interval without any eventual controllability assumption.
This leads to an extensive theory of conjoined bases of (SDS) and, in particular,
to a new theory of recessive and dominant solutions of (SDS) at inÔ¨Ånity. This
yields‚Äîtogether with a suitable application of the comparative index theory‚Äîto
a new singular Sturmian theory for symplectic systems.
The last section in each chapter contains notes about the presented results and
additional references regarding the studied topics. The bibliography includes also
several references for further reading about related topics, in particular from the
oscillation and spectral theory of linear Hamiltonian differential system (LHS).
The intended readership of the book includes the researchers and graduate
students in pure and applied mathematics, who are interested in topics related
to discrete symplectic and Hamiltonian systems, discrete oscillation theory, and
spectral theory of difference equations and systems, covering also Sturm-Liouville
difference equations of higher order. Researchers and students in matrix analysis
will also beneÔ¨Åt from this book by understanding new applications of the theory of
matrices in this Ô¨Åeld, in particular of the Moore-Penrose pseudoinverse matrices (or
the generalized inverses), orthogonal projectors, and (symplectic) matrix factoriza-
tions. The educational aim of the book is covered by including a variety of methods
from the discrete oscillation and eigenvalue theory, which are particularly useful in
the theory of symplectic and Hamiltonian systems. We demonstrate the utility of
the presented methods by including different proofs of the same result at several
occasions. We also support the understanding of the main results and important
notions by illustrating examples. The methods can be followed from a relatively
simple introduction to advanced constructions and applications, which are on the
edge of the current research in this Ô¨Åeld. Therefore, this book may be used as
a reference literature for a graduate course in the methods of the discrete oscillation
and spectral theory.

viii
Preface
This monograph is written by three experts in the oscillation and spectral theory
of symplectic difference systems, who follow the development of this theory since
its Ô¨Årst steps more than 20 years ago. The original idea about this book came
from O. Do≈°l√Ω and J. Elyseeva in December 2013, who initiated the translation of
Chapters 1‚Äì4 of her monograph [121], which in revised and extended form became
constituent parts of this book. In July 2014, they invited R. ≈†imon Hilscher to join
the author team with the aim to prepare a monograph covering the state of the art
of the oscillation and spectral theory of symplectic difference systems. It is sad to
know that Professor Do≈°l√Ω suddenly passed away in November 2016. The remaining
two authors wish to acknowledge the fundamental contribution of Professor Do≈°l√Ω
of this monograph by completing it under his coauthorship (Fig. 1).
The authors wish to thank the Czech Science Foundation for the support of this
work provided through the grant 16‚Äì00611S. This support allowed J. Elyseeva to
enjoy friendly environment and hospitality of the Department of Mathematics and
Statistics (Faculty of Science of Masaryk University) during the years 2017‚Äì2018
to write substantial parts of Chaps. 5 and 6 and to prepare the Ô¨Ånal version of
this monograph. The second author thanks the management of the Moscow State
University of Technology Stankin, in particular the chief of the Department of
Applied Mathematics Professor Ludmila Uvarova, for their invaluable assistance
in solving organizational issues related to the work on the monograph. We also
thank our colleagues from the team of Mathematical Analysis at the Department
Fig. 1 Professor Do≈°l√Ω lecturing on Sturm-Liouville difference equations and symplectic systems
on a seminar on differential equations (P√°lava, 2002)

Preface
ix
of Mathematics and Statistics for creating a constant positive environment for
our work. We thank especially Peter ≈†epitka for his useful comments about parts
of Chaps. 1 and 6. We cordially thank Clemens Heine and Luca Sidler from
Birkh√§user Verlag for their editorial help and for promoting the book to Pathways
in Mathematics. We also thank Rajeswari Rajkumar from Springer for professional
typesetting of the Ô¨Ånal version of the book. Finally, our very special thanks belong
to Zuzana Do≈°l√° for her continuous support and encouragement to complete this
monograph.
Brno, Czech Republic
OndÀárej Do≈°l√Ω (deceased)
Moscow, Russia
Julia Elyseeva
Brno, Czech Republic
Roman ≈†imon Hilscher
December 2018

Contents
1
Motivation and Preliminaries...............................................
1
1.1
Short History of Symplectic Difference Systems......................
1
1.2
Sturm-Liouville Difference Equation ..................................
3
1.2.1
Generalized Zeros .............................................
4
1.2.2
Reid Roundabout Theorem ...................................
7
1.2.3
Recessive and Dominant Solutions ...........................
11
1.2.4
Discrete Pr√ºfer Transformation ...............................
14
1.2.5
Sturm-Liouville Eigenvalue Problems .......................
16
1.3
Discrete Variational Theory ............................................
25
1.3.1
Discrete Calculus of Variations ...............................
25
1.3.2
Discrete Optimal Control Theory.............................
29
1.4
Symplectic Structure of Phase Flow in Hamiltonian Mechanics .....
35
1.5
Linear Hamiltonian Differential Systems ..............................
40
1.5.1
Basic Properties of Solutions of Hamiltonian Systems......
40
1.5.2
Symplectic Transformations ..................................
44
1.5.3
Riccati Equation and Reid Roundabout Theorem ...........
45
1.5.4
Trigonometric and Pr√ºfer Transformations ..................
49
1.5.5
Principal and Nonprincipal Solutions ........................
51
1.5.6
Nonlinear Dependence on Spectral Parameter ...............
53
1.6
Linear Algebra and Matrix Analysis ...................................
54
1.6.1
Symplectic Matrices...........................................
55
1.6.2
Moore-Penrose Pseudoinverse ................................
58
1.6.3
Symplectic Matrices and Generalized LU Factorization....
62
1.6.4
Symplectic Matrices Depending on Parameter ..............
67
1.6.5
Monotone Matrix-Valued Functions..........................
73
1.6.6
Miscellaneous Topics from Matrix Analysis.................
75
1.7
Notes and References ...................................................
78
xi

xii
Contents
2
Basic Theory of Symplectic Systems .......................................
83
2.1
Symplectic Systems and Their Particular Cases .......................
83
2.1.1
Conjoined Bases and Wronskian .............................
84
2.1.2
Special Symplectic Difference Systems......................
86
2.2
Focal Points .............................................................
92
2.2.1
Focal Points of Conjoined Bases .............................
92
2.2.2
Backward Focal Points ........................................
95
2.3
Riccati Equation and Quadratic Functional............................
97
2.3.1
Riccati Matrix Difference Equation ..........................
97
2.3.2
Energy Quadratic Functional .................................
99
2.3.3
Picone Identity................................................. 102
2.3.4
Reid Roundabout Theorem ................................... 103
2.3.5
Nonnegative Quadratic Functional ........................... 109
2.3.6
Quadratic Functionals with General Endpoints .............. 116
2.4
Riccati-Type Inequalities ............................................... 120
2.4.1
Inequalities for Riccati-Type Quotients ...................... 120
2.4.2
Discrete Riccati Inequality .................................... 124
2.5
Recessive and Dominant Solutions..................................... 128
2.5.1
DeÔ¨Ånitions and Basic Properties.............................. 128
2.5.2
Minimal Solution of Riccati Equation........................ 134
2.6
Transformations of Symplectic Systems ............................... 135
2.6.1
General Symplectic Transformation.......................... 135
2.6.2
Trigonometric or Bohl Transformation....................... 139
2.6.3
Hyperbolic Transformation ................................... 141
2.6.4
Pr√ºfer Transformation......................................... 144
2.7
Notes and References ................................................... 146
3
Comparative Index Theory ................................................. 149
3.1
Comparative Index and Its Properties .................................. 149
3.1.1
DeÔ¨Ånition of Comparative Index ............................. 150
3.1.2
Dual Comparative Index ...................................... 152
3.1.3
Basic Properties of Comparative Index....................... 153
3.1.4
Duality Principle for Comparative Index..................... 159
3.1.5
Proof of Properties (i)‚Äì(vii), (ix) of Comparative Index..... 161
3.2
Comparative Index and Symmetric Operators ......................... 166
3.2.1
Index of Block Symmetric Matrices.......................... 166
3.2.2
Symmetric Operator [V ] and Proof of Property (viii) ..... 169
3.3
Comparative Index for Symplectic Matrices........................... 173
3.3.1
Basic Properties ............................................... 173
3.3.2
General Case................................................... 179
3.3.3
Invertible Block B ............................................. 183
3.3.4
Invertible Block A............................................. 184
3.3.5
Additional Properties of Comparative Index ................. 190
3.3.6
Comparative Index for Symplectic Matrices: Proofs ........ 196
3.4
Notes and References ................................................... 199

Contents
xiii
4
Oscillation Theory of Symplectic Systems ................................ 201
4.1
Multiplicity of Focal Points ............................................ 201
4.1.1
DeÔ¨Ånition and Main Properties ............................... 202
4.1.2
Multiplicity of a Focal Point and Comparative Index ....... 205
4.2
Sturmian Separation Theorems and Its Corollaries.................... 211
4.2.1
Separation Theorem: First Step ............................... 211
4.2.2
Separation Theorems and Comparative Index ............... 216
4.2.3
Number of Focal Points and Principal Solutions ............ 222
4.2.4
Separation Results on Singular Intervals ..................... 227
4.3
Comparison Theorems and Its Corollaries............................. 229
4.3.1
Sturmian Comparison Theorems ............................. 230
4.3.2
Comparison Theorems for Principal Solutions .............. 241
4.3.3
Singular Comparison Theorems .............................. 245
4.4
Focal Points and Symplectic Transformations......................... 248
4.4.1
Focal Points and General Symplectic Transformation....... 248
4.4.2
Focal Points and Special Symplectic Transformations ...... 251
4.4.3
Generalized Reciprocity Principle............................ 253
4.4.4
Applications and Examples ................................... 255
4.5
Notes and References ................................................... 257
5
Discrete Symplectic Eigenvalue Problems................................. 261
5.1
Nonlinear Dependence on Spectral Parameter......................... 261
5.1.1
Finite Eigenvalues ............................................. 262
5.1.2
Finite Eigenfunctions ......................................... 266
5.1.3
Oscillation Theorems for Constant Rank of Bk(Œª) .......... 270
5.1.4
Construction of Auxiliary Conjoined Basis .................. 273
5.1.5
Construction of Auxiliary Symplectic System ............... 282
5.1.6
Application of the Index Theorem............................ 294
5.1.7
Applications and Examples ................................... 298
5.2
Eigenvalue Problems with General Boundary Conditions ............ 303
5.2.1
Transformations of Boundary Conditions.................... 304
5.2.2
Transformation of Quadratic Functionals .................... 311
5.2.3
Oscillation Theorems for General Endpoints ................ 316
5.3
Linear Dependence on Spectral Parameter ............................ 322
5.3.1
Transformation of Boundary Conditions ..................... 323
5.3.2
Quadratic Functionals ......................................... 328
5.3.3
Finite Eigenvalues and Finite Eigenfunctions................ 331
5.3.4
Global Oscillation Theorem .................................. 337
5.4
Variational Description of Finite Eigenvalues ......................... 339
5.4.1
Extended Picone Identity ..................................... 340
5.4.2
Rayleigh Principle............................................. 342
5.5
Applications of Oscillation Theorems ................................. 346
5.5.1
Sturmian Comparison and Separation Theorems ............ 346
5.5.2
ModiÔ¨Åcations of Global Oscillation Theorem ............... 351

xiv
Contents
5.6
Oscillation Theorems for Variable Rank of Bk(Œª)..................... 352
5.6.1
Statement of Main Results .................................... 354
5.6.2
Monotonicity and the Comparative Index.................... 362
5.6.3
Monotonicity and the Cayley Transform ..................... 368
5.6.4
Proofs of the Main Results.................................... 373
5.6.5
Weighted Focal Points ........................................ 376
5.6.6
General Endpoints and Nonconstant Rank ................... 382
5.7
Notes and References ................................................... 394
6
Miscellaneous Topics on Symplectic Systems ............................. 397
6.1
Relative Oscillation Theory ............................................ 397
6.1.1
Sturm-Liouville Difference Equations ....................... 399
6.1.2
Dirichlet Boundary Value Problems .......................... 400
6.1.3
Lower Block-Triangular Perturbation ........................ 404
6.1.4
Matrix Sturm-Liouville Eigenvalue Problems ............... 411
6.1.5
Examples....................................................... 418
6.1.6
Separated Boundary Conditions .............................. 423
6.1.7
General Boundary Conditions ................................ 428
6.2
Inequalities for Finite Eigenvalues ..................................... 433
6.2.1
Comparison of Finite Eigenvalues............................ 434
6.2.2
Interlacing of Eigenvalues for Joint Endpoints .............. 438
6.2.3
Interlacing of Eigenvalues for Separated Endpoints ......... 449
6.3
Symplectic Systems Without Controllability .......................... 460
6.3.1
Order of Abnormality ......................................... 461
6.3.2
Nonoscillatory Symplectic System ........................... 462
6.3.3
Conjoined Bases with Given Rank ........................... 482
6.3.4
Minimal Conjoined Bases .................................... 495
6.3.5
Asymptotics of S-Matrices ................................... 501
6.3.6
Recessive Solutions at InÔ¨Ånity ................................ 509
6.3.7
Dominant Solutions at InÔ¨Ånity................................ 517
6.3.8
Genus Conjoined Bases ....................................... 523
6.3.9
Limit Properties of Recessive and Dominant Solutions ..... 532
6.3.10
Reid‚Äôs Construction of Minimal Recessive Solution ........ 538
6.3.11
Additional Properties of Minimal Recessive Solution....... 543
6.3.12
Further Examples.............................................. 545
6.4
Singular Sturmian Separation Theorems............................... 548
6.4.1
Multiplicity of Focal Point at InÔ¨Ånity ........................ 550
6.4.2
Singular Separation Theorems I .............................. 554
6.4.3
Singular Separation Theorems II ............................. 561
6.5
Notes and References ................................................... 569
References......................................................................... 573
Index ............................................................................... 589

List of Figures
Fig. 1
Professor Do≈°l√Ω lecturing on Sturm-Liouville difference
equations and symplectic systems on a seminar on differential
equations (P√°lava, 2002) ...............................................
viii
Fig. 5.1
The graphs of Example 5.116 ......................................... 381
Fig. 6.1
The graphs of the sign of the Wronskian and the relative
oscillation numbers in Example 6.19 for the values a = ‚àí0.8
and b = 1.8 ............................................................. 420
Fig. 6.2
The graphs of the functions y1,2(Œª) of the number of Ô¨Ånite
eigenvalues below or equal to Œª for Œª ‚ààR for problems 1
and 2 in Example 6.20 ................................................. 420
Fig. 6.3
The graphs of the signs of the Wronskian,
Ck(a, b) = qk(a) ‚àíÀÜqk(b), Bk(a, b) = ÀÜr‚àí1
k (b) ‚àír‚àí1
k (a),
and the relative oscillation numbers in Example 6.20 for the
values a = b = ‚àí4..................................................... 422
Fig. 6.4
The graphs of the signs of the Wronskian,
Ck(a, b) = qk(a) ‚àíÀÜqk(b), Bk(a, b) = ÀÜr‚àí1
k (b) ‚àír‚àí1
k (a),
and the relative oscillation numbers in Example 6.20 for the
values a = ‚àí10 and b = 10 ........................................... 422
xv

Chapter 1
Motivation and Preliminaries
In this chapter we describe main motivating factors for the investigation of
symplectic difference systems in this book. This motivation comes from several
sources, mainly from (i) a generalization of the theory of second-order Sturm-
Liouville difference equations, (ii) discrete variational analysis, (iii) (classical and
discrete) Hamiltonian mechanics, (iv) discrete analogy of the theory of linear Hamil-
tonian differential systems, and (v) numerical methods for Hamiltonian differential
systems preserving the symplectic structure. Some of these topics are covered in
the next sections in order to motivate the subsequent detailed study of symplectic
difference systems. Some results (in particular those about Hamiltonian mechanics
and linear Hamiltonian differential systems) are presented without proofs, as they
serve mainly for comparison with the corresponding discrete-time theory. At the end
of this chapter, we also provide an overview of matrix analysis needed for this work,
in particular about symplectic matrices, the Moore-Penrose pseudoinverse matrices,
and symplectic matrix valued functions.
1.1
Short History of Symplectic Difference Systems
Symplectic difference systems (SDS) originate, to our knowledge, in two main
branches of mathematics. The Ô¨Årst one is the numerical analysis of Hamiltonian dif-
ferential systems in the works [140, 142, 143, 220] by K. Feng and his collaborators.
According to [140, pg. 18], symplectic difference systems ‚Äúrepresent a proper way,
i.e., the Hamiltonian way, for computing the Hamiltonian dynamics.‚Äù The research
in this area has been recently summarized in the book [141]. The second source of
symplectic difference systems can be identiÔ¨Åed in the representation of continued
fractions in the works [8, 10] by C. D. Ahlbrandt; see also the references about
continued fractions in [16].
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7_1
1

2
1
Motivation and Preliminaries
The concept of a symplectic difference system, as we consider in this work,
was introduced in 1996 in the book [16] by C. D. Ahlbrandt and A. Peterson.
During that time M. Bohner created in [39] the theory of general linear Hamiltonian
difference systems, which then essentially led to the Ô¨Ånal establishment of the
symplectic systems theory as an independent subject in the theory of difference
equations. An extension of the concepts from [39], such as disconjugacy and
implicit Riccati equations and their relationship to the positivity of discrete quadratic
functionals, was given in [45] by M. Bohner and O. Do≈°l√Ω. That paper can be
regarded as a starting point of the efforts of many mathematicians to develop the
theory of symplectic difference systems in a parallel way to the theory of linear
Hamiltonian differential systems (LHS). From this time we mention the results
on the positivity and nonnegativity of discrete quadratic functionals with various
boundary conditions, including explicit and implicit Riccati matrix equations, by
R. ≈†imon Hilscher and V. Zeidan [100, 178, 180‚Äì182, 186, 188], discrete Riccati
inequality [173, 174], trigonometric and hyperbolic systems [24, 46‚Äì48, 85, 108],
and Ô¨Ånally the theory of Weyl disks and their limit point and limit circle behavior
(the Weyl-Titchmarsh theory) by S. Clark, R. ≈†imon Hilscher, and P. Zem√°nek
[67, 308‚Äì313]. In this context we wish to emphasize the contributions of O. Do≈°l√Ω to
the transformation theory of symplectic difference systems and linear Hamiltonian
difference systems, including the trigonometric (Bohl), Pr√ºfer, and hyperbolic
transformations for symplectic systems [46, 47, 83, 85, 93, 96, 98, 108], which
became a basic reference for further studies in the discrete oscillation theory.
As a breaking point in the development of the theory of symplectic systems
(SDS) in the last 20 years, we can consider the paper [208] by W. Kratz, where
the concept of the multiplicity of focal points for conjoined bases of (SDS) was
introduced. This paper led to the development of the Sturmian and eigenvalue theory
for symplectic systems in [56, 102] by M. Bohner, O. Do≈°l√Ω, and W. Kratz. Since
then the discrete-time theory became a strong motivation for the development of
the linear Hamiltonian differential systems. Another important contribution, which
changed rapidly the study of symplectic difference systems, is represented by the
papers [114, 115, 117] by J. Elyseeva, who introduced the concept of a comparative
index for conjoined bases of (SDS); see also [121]. Due to its close relations
with the multiplicities of focal points, this turned out to be a very powerful tool
which allowed to derive several deep and perhaps unexpected results not only for
discrete symplectic systems‚Äîfor example, the discrete Sturmian theory, the relative
oscillation theory, the spectral theory, and the revisited transformation theory [94‚Äì
96, 116‚Äì120, 122, 123, 125, 126] by J. Elyseeva and partly by O. Do≈°l√Ω. Finally,
among recent important contributions to this theory, we consider the introduction
of the nonlinear dependence on the spectral parameter in symplectic difference
systems in [297] by R. ≈†imon Hilscher and the theory of recessive and dominant
solutions of (SDS) at inÔ¨Ånity for possibly uncontrollable symplectic systems in
[284, 290] by P. ≈†epitka and R. ≈†imon Hilscher. The Ô¨Årst mentioned topic initiated
the study of advanced topics in the spectral theory of symplectic systems, such
as the Weyl-Titchmarsh theory, the concept of weighted focal points, oscillation
theory for nonconstant rank, etc. The second mentioned topic leads, among others,

1.2
Sturm-Liouville Difference Equation
3
to a completely new singular Sturmian theory for symplectic difference systems
[292].
The current research in oscillation and spectral theory of symplectic difference
systems includes, for example, the topics from the spectral theory of linear
relations associated with symplectic systems, relative oscillation theory, recessive
and dominant solutions, Riccati equations and inequalities, or the uniÔ¨Åcation of the
theory of symplectic systems with linear Hamiltonian differential systems in the
theory of time scales.
In the traditional setting, such as in [16], the theory of symplectic difference
systems was developed in a parallel way to the known continuous time theory of
linear Hamiltonian systems. Starting from the milestone papers [39] by M. Bohner
and [208] by W. Kratz, the inspiration moved in favor of the discrete-time
theory, i.e., since then the symplectic difference systems motivate the progress in
the continuous time theory. A typical example of this process can be found in
[127, 129, 130, 207, 289, 295]. In current research the inspiration of continuous
and discrete theories is mutual, and, roughly speaking, the results for symplectic
difference systems and linear Hamiltonian differential systems are ‚Äúcooked‚Äù in the
same pot. This process then gives weight and credit to both of these theories.
1.2
Sturm-Liouville Difference Equation
The simplest and most frequently studied special case of symplectic difference
systems is the second-order Sturm-Liouville difference equation
(rkxk) + pkxk+1 = 0,
rk Ã∏= 0.
(1.1)
In this section we present essentials of the oscillation theory of (1.1), for a more
extended treatment of this topics, we refer to [4, 110, 204]. The comparison of
the results for the case of equation (1.1) with those for symplectic difference
systems (SDS) should help the reader better understand the general qualitative
theory presented in the subsequent chapters.
According to some historical investigations, Sturm in his famous paper [279]
from 1836 originally wanted to formulate the results for a difference equation but
eventually decided to formulate them for a continuous counterpart of (1.1), i.e., for
the differential equation
r(t) x‚Ä≤‚Ä≤ + p(t) x = 0,
r(t) > 0.
(1.2)
Consider, for a moment, that r(t) ‚â°1 in (1.2). We want to ‚Äúdiscretize‚Äù this
equation. Suppose that (1.2) is considered on an interval [a, b] and we want to Ô¨Ånd
an approximate solution of this equation using the Euler discretization scheme. We
take the equidistant partition of [a, b] with the discretization stepsize h = (b‚àía)/n,
and we denote tk = a + kh, xk = x(tk), pk‚àí1 = p(tk)h2 for k = 0, . . . , n. We

4
1
Motivation and Preliminaries
approximate the second derivative x‚Ä≤‚Ä≤(tk) by the second difference, where the values
xk‚àí1, xk, xk+1 occur, i.e., x‚Ä≤‚Ä≤(tk) ‚âà2xk‚àí1/h2 = (xk+1 ‚àí2xk + xk‚àí1)/h2. Hence,
we obtain the difference equation 2xk‚àí1 + pk‚àí1xk = 0, which after relabeling k
to k + 1 gives the equation
2xk + pkxk+1 = 0.
These considerations justify why the shift k + 1 appears in the second term of
(1.1). Another reason is purely mathematical‚Äîwithout this shift we have no discrete
analog of the Wronskian identity, and also some other important formulas would be
missing when there is no shift at x in (1.1).
1.2.1
Generalized Zeros
Consider the second-order recurrence relation
xk+2 ‚àíxk+1 ‚àíxk = 0,
(1.3)
which deÔ¨Ånes the Fibonacci sequence. Upon looking for its solutions in the form
xk = Œªk, we Ô¨Ånd that (1.3) has a pair of linearly independent solutions
x[1]
k
=

1 +
‚àö
5
2
k
,
x[2]
k
=

1 ‚àí
‚àö
5
2
k
.
(1.4)
Clearly, x[1] is a monotonically increasing sequence, while x[2] is an oscillating
sequence. From this point of view, it seems that the standard Sturmian theory, which
eliminates the coexistence of oscillatory and nonoscillatory solutions of a second-
order linear differential equation, is not valid in the discrete case.
Fortunately, this is not the case, and there exists a deeply developed Sturmian
theory for (1.1) when the concept of a generalized zero (sometimes also called
a focal point by analogy with the symplectic systems theory) is properly deÔ¨Åned.
To motivate this deÔ¨Ånition, consider the continuous counterpart of (1.1), i.e.,
the second-order Sturm-Liouville differential equation (1.2). Together with this
equation, consider its energy functional
F(y) =
 b
a
[r(t) y‚Ä≤2(t) ‚àíp(t) y2(t)] dt
(1.5)
and the associated Riccati equation (which related to (1.2) by the substitution w =
r(t) x‚Ä≤/x)
w‚Ä≤ + p(t) + w2
r(t) = 0.
(1.6)

1.2
Sturm-Liouville Difference Equation
5
If w is a solution of (1.6) deÔ¨Åned on the whole interval [a, b] and y ‚ààC1[a, b], then
computing (wy2)‚Ä≤ (we add and subtract the term r(t) y‚Ä≤2 in the resulting formula)
and then integrating the obtained formula from a to b, we obtain the so-called Picone
identity
 b
a
(ry‚Ä≤2 ‚àípy2)(t) dt = w(t) y2(t)
			
b
a +
 b
a
1
r(t)

r(t) y‚Ä≤(t) ‚àíw(t) y(t)2 dt.
(1.7)
This means that the energy functional is positive for a nontrivial y with y(a) = 0 =
y(b). In other words, the functional can be ‚Äúcompleted to a square‚Äù whenever there
exists a solution of the Riccati equation (1.6) deÔ¨Åned on the whole interval [a, b].
Now we will follow the previous considerations in the discrete case. The Riccati
difference equation, which is related to (1.1) by the substitution wk = rkxk/xk,
has the form
wk + pk +
w2
k
rk + wk
= 0
(1.8)
or equivalently,
wk+1 + pk ‚àí
rkwk
wk + rk
= 0.
(1.9)
Indeed, we have
wk = 
rkxk
xk

= (rkxk) xk ‚àírk(xk)2
xkxk+1
= ‚àípk ‚àír2
k (xk)2
rkxkxk+1
= ‚àípk ‚àír2
k (xk)2
x2
k
xk
rkxk+1
= ‚àípk ‚àí
w2
k
rk (xk + xk)/xk
= ‚àípk ‚àí
w2
k
rk + wk
.
Now, for y = {yk}N+1
k=0 with y0 = 0 = yN+1, we have
(wky2
k) = wk+1y2
k+1 ‚àíwky2
k
=

‚àípk +
wkrk
rk + wk

y2
k+1 ‚àíwky2
k + rk(yk)2 ‚àírk(yk)2
= rk(yk)2 ‚àípky2
k+1
‚àí
1
rk + wk

‚àírkwky2
k+1 + (rk + wk) wky2
k + rk(rk + wk) (yk)2

6
1
Motivation and Preliminaries
= rk(yk)2 ‚àípky2
k+1
‚àí
1
rk + wk

r2
k (yk)2 + w2
ky2
k + rkwk(‚àíy2
k+1 + y2
k + (yk)2)

= rk(yk)2 ‚àípky2
k+1 ‚àí
1
rk + wk
(rkyk ‚àíwkyk)2.
The summation of the last formula and using the endpoints condition y0 = 0 =
yN+1 give the discrete Picone identity
N

k=0
[rk(yk)2 ‚àípky2
k+1] =
N

k=0
1
wk + rk
(rkyk ‚àíwkyk)2.
(1.10)
Therefore, to get the positivity of the energy functional for a nontrivial y with y0 =
0 = yN+1, we need rk + wk > 0. Using the Riccati substitution, we then have
rk + wk = rk + rkxk
xk
= rk
xk + xk
xk
= rkxk+1
xk
.
Now we can formulate the deÔ¨Ånition of a generalized zero of a nontrivial solution
of (1.1).
DeÔ¨Ånition 1.1 Let x be a nontrivial solution of (1.1). We say that this solution has
a generalized zero (equivalently, a focal point) in the interval (k, k + 1] if xk Ã∏= 0
and rkxkxk+1 ‚â§0. More precisely, we say that the generalized zero is at k + 1 if
xk+1 = 0, while it is in the interval (k, k + 1) if rkxkxk+1 < 0.
This means that in contrast with the continuous case, where we normally assume
r(t) > 0, in the discrete case, we only need the condition rk Ã∏= 0. Returning back to
the Fibonacci equation (1.3), it can be written in the Sturm-Liouville form as


(‚àí1)kxk

+ (‚àí1)kxk+1 = 0,
i.e., rk = (‚àí1)k which changes its sign between each k and k + 1. Applying
DeÔ¨Ånition 1.1, where also the sequence rk is incorporated into the notion of
a generalized zero, both solutions x[1] and x[2] of (1.3) are actually oscillating
solutions (they have inÔ¨Ånitely many generalized zeros).
We Ô¨Ånish this subsection with the Wronskian identity and with the so-called
d‚ÄôAlembert formula (an alternative terminology is the reduction of order for-
mula). Let x and y be solutions of (1.1). Then substituting from (1.1), we have
(rkxkyk ‚àírkykxk) = 0, i.e., the quantity w(x, y)k := rk(xkyk ‚àíykxk) is
constant in k. Moreover, if xk Ã∏= 0 in some discrete interval, then

yk
xk

= rkxkyk ‚àírkykxk
xkxk+1
= w(x, y)
rkxkxk+1
.

1.2
Sturm-Liouville Difference Equation
7
The summation of this formula gives the so-called d‚ÄôAlembert formula
yk = xk
k‚àí1

j=0
w(x, y)
rjxjxj+1
.
(1.11)
This enables to express the second linearly independent solution of (1.1), when
a solution (being nonzero in some interval) is known.
1.2.2
Reid Roundabout Theorem
The next statement, usually referred to as the Reid roundabout theorem, describes
a relationship between the basic notions from the discrete oscillation theory of
equation (1.1). We present this result including its proof so that it can be compared
with that of the Reid roundabout theorem for symplectic difference systems, which
we present in Sect. 2.3. For discrete intervals we will use the notation
[a, b]Z := {a, a + 1, . . . , b ‚àí1, b},
a, b ‚ààZ, a < b.
(1.12)
Theorem 1.2 Assume rk Ã∏= 0 for all k ‚àà[0, N]Z. The following statements are
equivalent.
(i) Equation (1.1) is disconjugate in the discrete interval [0, N + 1]Z, i.e., the
solution x of (1.1) given by the initial conditions x0 = 0 and x1 = 1/r0 has
no generalized zero in the interval (0, N + 1].
(ii) There exists a solution x of (1.1) such that rkxkxk+1 > 0 for k ‚àà[0, N]Z.
(iii) There exists a solution w of (1.8) deÔ¨Åned for k ‚àà[0, N + 1]Z which satisÔ¨Åes
rk + wk > 0 for all k ‚àà[0, N]Z.
(iv) The discrete quadratic functional
F(y) =
N

k=0

rk(yk)2 ‚àípky2
k+1
 > 0
(1.13)
for every nontrivial y = {yk}N+1
k=0 with y0 = 0 = yN+1.
Proof
(i)
	‚áí
(ii): Consider the solution x[Œµ] of (1.1) given by the initial conditions
x[Œµ]
0
= Œµ > 0 and x[Œµ]
1
= 1/r0. Then, according to the continuous dependence
of solutions on the initial condition, we have x[Œµ]
k
‚Üíxk as Œµ ‚Üí0+ for k ‚àà
[0, N + 1]Z, where x is the solution from (i). Then rkx[Œµ]
k x[Œµ]
k+1 > 0, k ‚àà[1, N]Z,
if Œµ is sufÔ¨Åciently small and also r0x[Œµ]
0 x[Œµ]
1
= Œµ > 0.
(ii) 	‚áí(iii): This is just the Riccati substitution wk = rkx[Œµ]
k /x[Œµ]
k
for k ‚àà[0, N]Z.

8
1
Motivation and Preliminaries
(iii)
	‚áí
(iv): This implication follows immediately from the Picone identity
(1.10).
(iv)
	‚áí
(i): By contradiction, suppose that the solution x given by the initial
condition x0 = 0, x1 = 1/r0 has a generalized zero in (m, m + 1], i.e., xm Ã∏= 0
and rmxmxm+1 ‚â§0 for some m ‚àà[1, N]Z. DeÔ¨Åne the test sequence y by the
formula
yk =

xk,
k ‚àà[0, m]Z,
0
k ‚àà[m + 1, N + 1]Z.
Denote by L[x]k the left-hand side of (1.1), i.e., L[x]k = (rkxk) + pkxk+1.
Then ym = xm Ã∏= 0 (i.e., y is nontrivial) and y0 = x0 = 0 = yN+1 and by the
summation by parts of the Ô¨Årst term in F, we obtain
F(y) = rkykyk
		N+1
0
‚àí
N

k=0
yk+1L[y]k
= ‚àí
 m‚àí2

k=0
xk+1L[x]k

‚àíxmL[y]m‚àí1 ‚àíym+1L[y]m
= xm[(rm + rm‚àí1 ‚àípm‚àí1) xm ‚àírm‚àí1xm‚àí1] = xmrmxm+1 ‚â§0,
which yields a contradiction. In the previous computation, we have used the
construction of y as a solution of (1.1) for k ‚àà[0, m ‚àí2]Z and the fact that
(1.1) can be written as the three-term symmetric recurrence relation
rk+1xk+2 + skxk+1 + rkxk = 0,
sk = ‚àírk+1 ‚àírk + pk,
(1.14)
where we applied (1.14) at k = m ‚àí1.
‚äì‚äî
In the oscillation theory of (1.1), the equivalence (i)
‚áê‚áí
(iii) is called the
Riccati technique, while the equivalence (i)
‚áê‚áí
(iv) is called the variational
principle. As a consequence of the roundabout theorem, we get that (1.1) can be
classiÔ¨Åed as oscillatory or nonoscillatory, similarly as in the case of its continuous
counterpart, the second-order Sturm-Liouville differential equation. This follows
from the next statement.
Theorem 1.3 Let x be a solution of (1.1) with generalized zeros in the intervals
(m, m + 1] and (n, n + 1], where m, n ‚àà[0, N]Z with m < n. Then any other
solution of this equation has a generalized zero in the interval (m, n + 1].

1.2
Sturm-Liouville Difference Equation
9
Proof The idea of the proof is the following. The existence of a nontrivial solution
without any generalized zero in (m, n + 1] implies that the functional
F(y) =
n

k=m

rk(yk)2 ‚àípky2
k+1

> 0
for every nontrivial y = {yk}n+1
k=m with ym = yn+1 = 0, by Theorem 1.2. On the
other hand, a construction similar to the one in the proof of the implication (vi)
	‚áí(i) in Theorem 1.2 yields a test sequence y, for which F(y) ‚â§0. This way we
obtain a contradiction.
‚äì‚äî
We say that a nontrivial solution x of (1.1) is oscillatory (at ‚àû) if there exists
a sequence of integers nk ‚Üí‚àûas k ‚Üí‚àûsuch that interval (nk, nk + 1]
contains a generalized zero of x for every k. In the opposite case, the solution x
of (1.1) is said to be nonoscillatory. Equation (1.1) is said to be oscillatory, if it
possesses an oscillatory solution, and it is said to be nonoscillatory, when there
exists a nonoscillatory solution. The previous theorem eliminates the coexistence of
oscillatory and nonoscillatory solutions of (1.1); hence it justiÔ¨Åes the classiÔ¨Åcation
of (1.1) as being oscillatory or nonoscillatory.
In the literature there exist numerous oscillation and nonoscillation criteria
for equation (1.1). As an example, we give here the so-called Leighton-Wintner
oscillation criterion.
Theorem 1.4 Suppose that ‚àû1/rk = ‚àû= ‚àûpk. Then equation (1.1) is
oscillatory.
Proof It can be veriÔ¨Åed that for any K ‚ààN, there exist integers K < L < M < N
such that for the sequence
yk =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0
for k < K,
k‚àí1
j=K 1/rj
 L‚àí1
j=K 1/rj
‚àí1
for k ‚àà[K, L]Z,
1
for k ‚àà[L + 1, M ‚àí1]Z,
N‚àí1
j=k 1/rj
 N‚àí1
j=M 1/rj
‚àí1
for k ‚àà[M, N ‚àí1]Z,
0
for k ‚â•N,
we have F(y) = M
k=K[rk(yk)2 ‚àípky2
k+1] ‚â§0 if M is sufÔ¨Åciently large.
To verify it, one needs to apply the second mean value theorem of summation
calculus (see [80, Lemma 3.2]) in computing the sum N‚àí1
k=M pky2
k+1. Other than
that the computation is straightforward. Note that the second mean value theorem
of summation calculus is not needed under the additional assumption that pk ‚â•0
for large k.
‚äì‚äî

10
1
Motivation and Preliminaries
Let us recall that recurrence (1.14) (considered for k ‚àà[0, ‚àû)Z) and for x =
{xk}‚àû
k=0 with x0 = 0) can be rewritten using the so-called Jacobi matrix. This is
deÔ¨Åned to be an (inÔ¨Ånite) three-diagonal symmetric matrix
J =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
s0 r1 0 0 0 . . . 0 . . .
r1 s1 r2 0 0 . . . 0 . . .
0 r2 s2 r3 0 . . . 0 . . .
0 0 r3 s4 r4 . . . 0 . . .
...
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
as (1.1) is equivalent with the equality Jx = 0. We note that the (mainly spectral)
theory of these matrices is deeply developed; see, e.g., [315].
The following transformation formula represents another important tool in the
qualitative theory of (1.1).
Theorem 1.5 Let hk Ã∏= 0 in some discrete interval. Then the transformation xk =
hkyk transforms equation (1.1) into the equation of the same form, i.e., to
(ÀÜrkyk) + ÀÜpkyk+1 = 0,
(1.15)
where ÀÜrk and ÀÜpk are given by the formulas
ÀÜrk = rkhkhk+1,
ÀÜpk = rkhk
 + pkhk+1.
(1.16)
Proof We have
hk+1

(rkxk) + pkxk+1

= hk+1

(rkhk+1yk + rkhkyk) + pkhk+1yk+1

= hk+1(rkhk+1yk) + hk+1(rkhkyk) + pkh2
k+1yk+1
= (rkhkhk+1yk) ‚àíhkrkhk+1yk + hk+1(rkhk)yk+1
+ hk+1rkhkyk + pkh2
k+1yk+1
= (rkhkhk+1yk) + hk+1[(rkhk) + pkhk+1] yk+1.
Hence, (1.1) is indeed transformed into (1.15) with ÀÜrk and ÀÜpk given by (1.16).
‚äì‚äî
If the sequence h is a solution of equation (1.1), then ÀÜpk = 0, and (1.15)
becomes the equation (rkhkhk+1yk) = 0. The summation of this equation gives
an alternative proof of the d‚ÄôAlembert formula (1.11) (with h instead of x).
We Ô¨Ånish this subsection by the so-called oscillation theorem, which concerns the
discrete Sturm-Liouville eigenvalue problem with the Dirichlet boundary conditions
(the statement remains to hold also for general self-adjoint boundary conditions, but
for simplicity we formulate the statement only for the Dirichlet conditions). The

1.2
Sturm-Liouville Difference Equation
11
proof of this statement can be found in [204, Theorem 7.6]. Note that this reference
deals with the case of rk > 0 only, but the presented proof essentially works also
when rk Ã∏= 0. Alternatively, this result follows from the more general statement for
nonlinear dependence on Œª (Theorem 1.19) or for symplectic difference systems
(Corollary 5.79).
Theorem 1.6 Consider the eigenvalue problem
‚àí(rkxk)+qkxk+1 = Œªwkyk+1,
k ‚àà[0, N‚àí1]Z,
x0 = 0 = xN+1
(1.17)
with rk Ã∏= 0 and wk > 0 for all k ‚àà[0, N]Z. Then the number of eigenvalues of
(1.17), which are less than or equal to a given Œª0 ‚ààR, is equal to the number of
generalized zeros in (0, N + 1] of the solution x(Œª0) of the difference equation in
(1.17) with Œª = Œª0, which satisÔ¨Åes the initial conditions x0(Œª0) = 0 and x1(Œª0) =
1/r0.
1.2.3
Recessive and Dominant Solutions
In this subsection we will suppose that equation (1.1) is nonoscillatory. This means
that there exists M ‚ààN such that the solution x[M] given by the initial condition
xM = 0 and xM+1 = 1/rM has no generalized zero in the interval (M, ‚àû), i.e.,
rkx[M]
k
x[M]
k+1 > 0 for all k ‚â•M. We claim that under these conditions, there exists
a solution Àúx of (1.1) with the property that
lim
k‚Üí‚àû
Àúxk
xk
= 0
(1.18)
for every solution x of (1.1), which is linearly independent of Àúx. The solution Àúx is
called a recessive solution (at ‚àû). Any solution linearly independent of the recessive
solution is called a dominant solution (at ‚àû).
In order to show the existence of a recessive solution of (1.1), we consider two
linearly independent solutions x and y of (1.1) such that x has no generalized zero
in (N, ‚àû) for some N ‚ààN. Then their Wronskian c := w(x, y)k is constant on
[N, ‚àû), and hence (yk/xk) = c/rkxkxk+1 is of constant sign (equal to the sign
of c); see Sect. 1.2.1. Therefore, the sequence yk/xk is monotone, and hence there
exists (Ô¨Ånite or inÔ¨Ånite) limk‚Üí‚àûyk/xk = L. If L = 0, then we put Àúx = y. Then
every solution linearly independent of Àúx is of the form Œ± Àúx + Œ≤x with Œ≤ Ã∏= 0 and
lim
k‚Üí‚àû
Àúxk
Œ± Àúxk + Œ≤xk
= lim
k‚Üí‚àû
Àúxk/xk
Œ± (Àúxk/xk) + Œ≤ = 0.

12
1
Motivation and Preliminaries
If 0 Ã∏= L ‚ààR, then the principal solution is Àúx = x ‚àíLy, and similarly as above,
we have limk‚Üí‚àûÀúxk/xk = 0 for every solution linearly independent of Àúx. Finally, if
L = ¬±‚àû, we put Àúx = x. Therefore we have just proved the following statement.
Theorem 1.7 A recessive solution of (1.1) exists whenever (1.1) is nonoscillatory.
Moreover, the recessive solution is unique up to a constant nonzero multiplicative
factor. Finally, a solution x of (1.1) is recessive if and only if
‚àû

k=N
1
rkxkxk+1
= ‚àû,
(1.19)
where N is sufÔ¨Åciently large.
Another characterization of the recessive solution is closely connected with
the concept of eventually minimal solution (an equivalent terminology is the
distinguished solution) of the Riccati equation (1.8).
Theorem 1.8 Let Àúx be a solution of (1.1) with Àúxk Ã∏= 0 for k sufÔ¨Åciently large. Let
Àúwk = (rkÀúxk)/Àúxk be the corresponding solution of the associated Riccati equation
(1.8). Then Àúx is the recessive solution of (1.1) if and only if for any other solution w
of (1.8) we have wk > Àúwk for all k sufÔ¨Åciently large.
Proof Let Àúx be the recessive solution of (1.1) and deÔ¨Åne Àúw as in the theorem. Let
wk be any other solution of the Riccati equation (1.8). By the Reid roundabout
theorem (Theorem 1.2), we may assume that rk + wk > 0 for large k and that
wk = (rkxk)/xk for large k for some solution x of (1.1) with xk Ã∏= 0 for large k.
Then we have
wk ‚àíÀúwk = rkxk
xk
‚àírkÀúxk
Àúxk
= rk(Àúxkxk ‚àíxkÀúxk)
xk Àúxk
=
d
xk Àúxk
,
(1.20)
where d = w(Àúx, x)k is the constant Wronskian of Àúx and x. Since rkxkxk+1 > 0 and
rk Àúxk Àúxk+1 > 0 for large k, we have
xkxk+1
Àúxk Àúxk+1
> 0
i.e.,
xk
Àúxk
¬∑ xk+1
Àúxk+1
> 0.
This means that xk/Àúxk, and hence also xk Àúxk, does not change its sign for large k.
Replacing x by ‚àíx if necessary, we may suppose without loss of generality that
xk Àúxk > 0, i.e., Àúxk/xk > 0. Since Àúxk/xk ‚Üí0 as k ‚Üí‚àûand (Àúxk/xk) =
c/(rkxkxk+1) with positive denominator of the right-hand side, it follows that
c = w(x, Àúx)k < 0 for large k. Hence, d = ‚àíc > 0 and from (1.20) we obtain
that wk ‚àíÀúwk > 0 for large k.
Conversely, suppose that Àúw is the eventually minimal solution of equation (1.8),
i.e., we have for large k
wk = rkxk
xk
> Àúwk = rkÀúxk
Àúxk
,
i.e.,
d
xk Àúxk
= wk ‚àíÀúwk > 0,

1.2
Sturm-Liouville Difference Equation
13
where d = rk(Àúxkxk ‚àíxkÀúxk). Using the same argument as in the Ô¨Årst part of the
proof, we have xk Àúxk > 0 for large k, hence d > 0. We have
(Àúxk/xk) = ‚àí
d
rkxkxk+1
< 0.
for large k. This means that Àúxk/xk is a monotonically decreasing sequence of
positive numbers; hence it tends to some limit L ‚â•0 as k ‚Üí‚àû. Suppose that
L > 0 and put ÀÜxk = Àúxk ‚àíLxk. Then we have
rkÀÜxk
ÀÜxk
‚àírkÀúxk
Àúxk
= rk Àúxk(Àúxk ‚àíLxk) ‚àí(Àúxk ‚àíLxk) rkÀúxk
ÀÜxkxk
= ‚àíL rk(Àúxkxk ‚àíxkÀúxk)
ÀÜxkxk
= ‚àíL
c
ÀÜxkxk
< 0
and we get a contradiction with the assumption that Àúwk < wk for large k for any
other solution w of (1.8). Hence L = 0, and Àúx is then the recessive solution.
‚äì‚äî
Finally, the last statement of this subsection states that the largest generalized
zero of the recessive solution (if any) has a certain extremal property.
Theorem 1.9 Let the interval (N, N +1] contain the largest generalized zero of the
recessive solution Àúx of (1.1). Then any linearly independent solution has at least one
generalized zero in the interval (N, ‚àû).
Proof We outline the proof only. Suppose that N is the largest integer such that the
interval (N, N + 1] contains a generalized zero of Àúx, i.e., ÀúxN Ã∏= 0 and rN ÀúxN ÀúxN+1 ‚â§
0. We will deal with the case rN ÀúxN ÀúxN+1 < 0 (in case of the equality, the proof needs
minor a modiÔ¨Åcation, which we will not present here). Hence we have rN + ÀúwN < 0,
where Àúwk = (rkÀúxk)/Àúxk. Suppose, by contradiction, that there exists a solution
x of (1.1) with rkxkxk+1 > 0 for all k ‚àà[N, ‚àû)Z. Then rk + wk > 0, where
wk = (rkxk)/xk, in particular, rN + wN > 0. This implies ÀúwN > wN. We have
(we use (1.9))
Àúwk+1 ‚àíwk+1 =
r2
k
(rk + wk)(rk + Àúwk)( Àúwk ‚àíwk).
Substituting k = N, we have ÀúwN+1 > wN+1. Since rk + wk > 0, rk + Àúwk > 0,
k ‚àà[N +1, ‚àû)Z, we have Àúwk > wk for all k ‚àà[N +1, ‚àû)Z. This is a contradiction
with the fact that the recessive solution of (1.1) generates the eventually minimal
solution of (1.8), by Theorem 1.8.
‚äì‚äî

14
1
Motivation and Preliminaries
1.2.4
Discrete Pr√ºfer Transformation
The Pr√ºfer transformation is an important tool in the investigation of the oscillatory
properties of conjoined bases of system (1.103). In this subsection we introduce
the Pr√ºfer transformation for the self-adjoint difference equation (1.1) and use it to
obtain the so-called reciprocity principle for this equation.
Let x be a nontrivial solution of (1.1). Then x2
k + (rkxk)2 Ã∏= 0 for all k
(otherwise x would be identically zero) and we can Ô¨Ånd real numbers œ±k > 0 and
œïk with 0 ‚â§œïk < 2œÄ such that the equations
xk = œ±k sin œïk,
(1.21)
rkxk = œ±k cos œïk
(1.22)
are satisÔ¨Åed for all k. That is, we set
œ±k :=

x2
k + (rkxk)2,
œïk := arccot rkxk
xk
.
We call (1.21) and (1.22) the discrete Pr√ºfer transformation.
Theorem 1.10 Let x be a nontrivial solution of (1.1), and let œ± and œï be deÔ¨Åned
by (1.21) and (1.22). Then we have the equations
œ±k = œ±k
 1
rk
cos œïk sin œïk+1 ‚àípk sin œïk cos œïk+1
‚àípk
rk
cos œïk cos œïk+1 ‚àí1
2

( sin œïk)2 + ( cos œïk)2
,
(1.23)
sin œïk = 1
rk
cos œïk cos œïk+1 + pk sin œïk sin œïk+1 + pk
rk
cos œïk sin œïk+1.
(1.24)
Proof Use of the discrete product rule for (1.21) yields
sin œïk+1 œ±k + œ±k  sin œïk = (œ±k sin œïk) = xk
= 1
rk
(rkxk) = 1
rk
œ±k cos œïk,

1.2
Sturm-Liouville Difference Equation
15
while doing the same for (1.22) implies
cos œïk+1 œ±k + œ±k  cos œïk = (œ±k cos œïk) = (rkxk)
= ‚àípkxk+1 = ‚àípk
rk
(rkxk) ‚àípkxk
= ‚àípk
rk
œ±k cos œïk ‚àípkœ±k sin œïk,
where we have also used that x is a solution of (1.1). Hence we obtain
sin œïk+1 œ±k + œ±k  sin œïk = œ±k
rk
cos œïk,
(1.25)
cos œïk+1 œ±k + œ±k  cos œïk = ‚àípk
rk
œ±k cos œïk ‚àípkœ±k sin œïk.
(1.26)
We now multiply (1.25) by sin œïk+1 and (1.26) by cos œïk+1 and add the resulting
equations to obtain (1.23). To verify (1.24), we multiply (1.25) by cos œïk+1 and
(1.26) by ‚àísin œïk+1 and add the resulting equations. Dividing the obtained equation
by œ±k > 0 directly yields (1.24).
‚äì‚äî
As an application of Theorem 1.10, we derive the reciprocity principle for
equation (1.1), which relates the oscillatory properties of a solution x of (1.1) with
the oscillatory properties of the quasi-difference rx. For this we assume that
rk > 0
and
pk > 0
for all k.
(1.27)
First we need an auxiliary result.
Lemma 1.11 Assume (1.27), let x be a solution of (1.1), and deÔ¨Åne œï by (1.21)‚Äì
(1.22). If xkxk+1 > 0 for some integer k, then 0 < œïk < œÄ.
Proof First of all use equations (1.1), (1.21), and (1.22) to obtain
cos œïk+1+pk sin œïk+1 = rk+1xk+1 + pkxk+1
œ±k+1
= rkxk
œ±k+1
= œ±k cos œïk
œ±k+1
.
(1.28)
This is implied by (1.21) and (1.24)
sin œïk = pk sin œïk sin œïk+1 + cos œïk
rk
(cos œïk+1 + pk sin œïk+1)
= pkxkxk+1
œ±kœ±k+1
+ œ±k cos2 œïk
rkœ±k+1
> 0
and hence (observe that by deÔ¨Ånition 0 ‚â§œïk < 2œÄ), we have 0 < œïk < œÄ,
which is the conclusion.
‚äì‚äî

16
1
Motivation and Preliminaries
Theorem 1.12 (Reciprocity Principle) Assume (1.27) and let x be a solution of
(1.1). Then xk is eventually of one sign if and only if rkxk is eventually of one sign.
Proof Let x be a solution of (1.1) and deÔ¨Åne œï by the (1.21)‚Äì(1.22) as before. Let
N be an integer such that xkxk+1 > 0 for all k ‚â•N. Then the points (rkxk, xk) are
either in the upper half plane for all k ‚â•N or in the lower half plane for all k ‚â•N.
This and Lemma 1.11 imply that œïk ‚â§œïN + œÄ for all k ‚â•N. By deÔ¨Ånition, œïk ‚â§
œïk+1 for all k ‚â•N, so that limk‚Üí‚àûœïk must exist. But then also limk‚Üí‚àûcos œïk
exists, and hence (observe also that cos œïk ‚â•cos œïk+1 for all k ‚â•N or cos œïk ‚â§
cos œïk+1 for all k ‚â•N), there exists an integer M such that cos œïk cos œïk+1 > 0 for
all k ‚â•M. This together with (1.22) proves the result. The converse follows from
the fact that the sequence Àúxk = rkxk satisÔ¨Åes the so-called reciprocal equation

 1
pk
Àúxk

+
1
rk+1
Àúxk+1 = 0,
as can be easily veriÔ¨Åed by direct calculations. One can use then the same
argumentation as in the Ô¨Årst part of the proof.
‚äì‚äî
1.2.5
Sturm-Liouville Eigenvalue Problems
In this section we consider the second-order Sturm-Liouville difference equation
(rk(Œª) xk) + qk(Œª) xk+1 = 0,
k ‚àà[0, N ‚àí1]Z,
(SLŒª)
where rk : R ‚ÜíR for k ‚àà[0, N]Z and qk : R ‚ÜíR for k ‚àà[0, N ‚àí1]Z are given
differentiable functions of the spectral parameter Œª such that
rk(Œª) Ã∏= 0 and Àôrk(Œª) ‚â§0,
k ‚àà[0, N]Z,
Àôqk(Œª) ‚â•0,
k ‚àà[0, N ‚àí1]Z.
(1.29)
Here N ‚ààN is a Ô¨Åxed number with N ‚â•2 and [a, b]Z := [a, b] ‚à©Z, and the dot
denotes the differentiation with respect to Œª. With equation (SLŒª) we consider the
Dirichlet boundary conditions, that is, we study the eigenvalue problem
(SLŒª),
Œª ‚ààR,
x0 = 0 = xN+1.
(E0)
We recall Ô¨Årst the classical setting of Sturm-Liouville difference equations; see,
e.g., [16, 23, 28, 204], in which the function rk(¬∑) is constant (nonzero) in Œª and the
function qk(¬∑) is linear and increasing in Œª. That is, the traditional assumptions for
the oscillation and spectral theory of equation (SLŒª) are the following:
rk(Œª) ‚â°rk Ã∏= 0,
for all k ‚àà[0, N]Z,
qk(Œª) = qk + Œª wk,
wk > 0,
for all k ‚àà[0, N ‚àí1]Z.

(1.30)

1.2
Sturm-Liouville Difference Equation
17
In some publications, such as in [28, 204], the authors also impose the sign condition
rk > 0 for all k ‚àà[0, N]Z, but it is well-known nowadays that rk Ã∏= 0 is sufÔ¨Åcient
to develop the oscillation and spectral theory of these equations; see Sect. 1.2.1 and,
e.g., [315, pg. 5] or [304]. The explanation of this phenomenon also follows from
the analysis of the general equation (SLŒª) discussed below.
Assume for a moment that (1.30) holds. Following [204, Chapter 7] or [28,
Chapter 4], a number Œª0 ‚ààC is an eigenvalue of (E0) if there exists a nontrivial
solution x = x(Œª0) of equation (SLŒª0) satisfying the Dirichlet endpoints x0(Œª0) =
0 = xN+1(Œª0). By the uniqueness of solutions of equation (SLŒª0), it follows that
the eigenvalues of (E0) are characterized by the condition ÀÜxN+1(Œª0) = 0, where
ÀÜx(Œª) is the principal solution of equation (SLŒª), i.e., it is the solution starting with
the initial values ÀÜx0(Œª) = 0 and ÀÜx1(Œª) = 1/r0. If x(Œª) is a solution of (SLŒª) with
(1.30), then the functions xk(Œª) are polynomials in Œª for every k ‚àà[0, N + 1]Z.
Therefore, the zeros of xk(Œª) are isolated, showing that the eigenvalues of (E0) are
simple (with the multiplicity equal to one) and isolated. Furthermore, by a standard
argument from linear algebra, it follows that the eigenvalues of (E0) with Œª ‚ààC
are indeed real and that the eigenfunctions corresponding to different eigenvalues
are orthogonal with respect to the inner product ‚ü®x, y‚ü©w := N
k=0 wk xk+1 yk+1.
The oscillation theorem for (E0) then says that the j-th eigenfunction has exactly j
generalized zeros in the interval (0, N + 1]; see DeÔ¨Ånition 1.1.
In this subsection we show that some of the above properties can be extended to
the eigenvalue problem (E0) in which the coefÔ¨Åcients depend on the spectral param-
eter Œª in general nonlinearly and they satisfy the monotonicity assumption (1.29). In
particular, we discuss the notions of Ô¨Ånite eigenvalues and Ô¨Ånite eigenfunctions for
such problems which are appropriate generalizations of the corresponding notions
for the case of (1.30).
First we show how certain solutions of (SLŒª) behave with respect to Œª. Assump-
tion (1.29) implies that the solutions of (SLŒª) are differentiable, hence continuous,
in Œª on R. We will consider the solutions whose initial values
x0(Œª),
r0(Œª) x0(Œª)
do not depend on Œª.
(1.31)
This condition is satisÔ¨Åed, for example, by the principal solution ÀÜx(Œª), for which
ÀÜx0(Œª) = 0,
ÀÜx1(Œª) = 1/r0(Œª)
for all Œª ‚ààR.
(1.32)
The following result shows that under the monotonicity assumption (1.29), the
oscillation behavior in Œª is not allowed for the above type of solutions near any
Ô¨Ånite value of Œª.
Lemma 1.13 Assume that (1.29) holds and let x(Œª) = {xk(Œª)}N+1
k=0 be a nontrivial
solution of (SLŒª) satisfying (1.31). Then for each k ‚àà[0, N +1]Z and Œª0 ‚ààR, there
exists Œ¥ > 0 such that xk(Œª) is either identically zero or never zero on (Œª0, Œª0 + Œ¥),
resp. on (Œª0 ‚àíŒ¥, Œª0).

18
1
Motivation and Preliminaries
Proof Let Œª0 ‚ààR and k ‚àà[0, N + 1]Z be Ô¨Åxed. If k = 0, then the result follows
trivially. Also, if xk(Œª0) Ã∏= 0, then the statement is a consequence of the continuity
of xk(Œª) in Œª. Therefore, further on we assume that k ‚àà[1, N +1]Z and xk(Œª0) = 0.
First we construct another solution y(Œª) = {yj(Œª)}N+1
j=0 whose initial conditions
do not depend on Œª as in (1.31) such that yk(Œª0) Ã∏= 0 and such that the Casorati
determinant
C[y(Œª), x(Œª)]j := rj(Œª)
				
yj(Œª)
xj(Œª)
yj(Œª) xj(Œª)
				 = 1
for all j ‚àà[0, N + 1]Z, Œª ‚ààR.
This means that the solutions y(Œª) and x(Œª) form a normalized pair of solutions of
(SLŒª). The solution y(Œª) can be constructed from the initial conditions
y0(Œª) = r0(Œª) x0(Œª)/œâ0,
r0(Œª) y0(Œª) = ‚àíx0(Œª)/œâ0,
where œâ0 := x2
0(Œª) + r2
0(Œª) [x0(Œª)]2 is independent of Œª. By the continuity of
yk(Œª) in Œª, there exists Œµ > 0 such that yk(Œª) Ã∏= 0 on (Œª0 ‚àíŒµ, Œª0 + Œµ). For these
values of Œª, a direct calculation shows the formula
d
dŒª
xk(Œª)
yk(Œª)

=
1
y2
k(Œª)
k‚àí1

j=0

Àôqj(Œª)
				
xj+1(Œª) xk(Œª)
yj+1(Œª) yk(Œª)
				
2
‚àíÀôrk(Œª)
				
xj(Œª) xk(Œª)
yj(Œª) yk(Œª)
				
2  
.
Therefore, under the assumption (1.29) the function zk(Œª) := xk(Œª)/yk(Œª) is
nondecreasing in Œª on (Œª0 ‚àíŒµ, Œª0 + Œµ). This means that once zk(Œª0) = 0, then
zk(Œª) is either identically zero on (Œª0, Œª0 + Œ¥) for some Œ¥ ‚àà(0, Œµ), or zk(Œª) is
positive on (Œª0, Œª0 + Œµ). Similar argument applies also on the left side of Œª0. And
since the zeros of zk(Œª) in (Œª0 ‚àíŒµ, Œª0 + Œµ) are exactly those of xk(Œª), the result
follows.
‚äì‚äî
Remark 1.14 The statement of Lemma 1.13 says that for a nontrivial solution
x(Œª) = {xk(Œª)}N+1
k=0 of (SLŒª) satisfying (1.31), the quantity
hk(Œª) := rank xk(Œª)
(1.33)
is piecewise constant in Œª on R for every given k ‚àà[0, N + 1]Z.
Remark 1.15 If a solution x(Œª) of (SLŒª) satisÔ¨Åes xk(Œª0) Ã∏= 0 at some index k ‚àà
[0, N + 1]Z and Œª0 ‚ààR, then there exists Œ¥ > 0 such that xk(Œª) Ã∏= 0 on the interval
(Œª0 ‚àíŒ¥, Œª0 + Œ¥). Moreover, as in the proof of Lemma 1.13, we can derive for all
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) the formula
Àôpk(Œª) = ‚àíÀôrk(Œª) x2
k(Œª)
r2
k (Œª) x2
k+1(Œª) +
1
r2
k (Œª)
k‚àí1

j=0
!
Àôqj(Œª) x2
j+1(Œª) ‚àíÀôrj(Œª) [xj(Œª)]2"
,
(1.34)

1.2
Sturm-Liouville Difference Equation
19
where
pk(Œª) :=
xk(Œª)
rk(Œª) xk+1(Œª).
(1.35)
Identity (1.34) shows that the function pk(Œª) is nondecreasing in Œª whenever it is
deÔ¨Åned, i.e., whenever xk+1(Œª) Ã∏= 0. This monotonicity of pk(Œª) in Œª is essential for
deriving the oscillation theorem below. Note also that according to DeÔ¨Ånition 1.1,
we have pk(Œª) < 0 if and only if the solution x(Œª) has a generalized zero in (k, k +
1).
Remark 1.16 The uniqueness of solutions of (SLŒª) implies that a nontrivial solution
x(Œª) of (SLŒª) cannot vanish at any two consecutive points k and k + 1. Therefore,
if xk(Œª) = 0, then xk+1(Œª) Ã∏= 0, while if xk+1(Œª) = 0, then xk(Œª) Ã∏= 0.
Let x(Œª) = {xk(Œª)}N+1
k=0 be a nontrivial solution of (SLŒª) and denote by mk(Œª)
the number of its generalized zeros in (k, k + 1]. Then mk(Œª) ‚àà{0, 1}. Our aim is
to prove the following local oscillation theorem.
Theorem 1.17 (Local Oscillation Theorem I) Assume that (1.29) holds. Consider
a nontrivial solution x(Œª) = {xk(Œª)}N+1
k=0 of (SLŒª) satisfying (1.31). Fix an index k ‚àà
[0, N]Z and denote by mk(Œª) the number of generalized zeros of x(Œª) in (k, k + 1].
Then mk(Œª‚àí) and mk(Œª+) exist and for all Œª ‚ààR
mk(Œª+) = mk(Œª) ‚â§1,
(1.36)
mk(Œª+) ‚àímk(Œª‚àí) = hk(Œª) ‚àíhk(Œª‚àí) + hk+1(Œª‚àí) ‚àíhk+1(Œª),
(1.37)
where hk(Œª) and hk+1(Œª) are given in (1.33).
In the above formula, the value of the function hj(Œª) is 1 if xj(Œª) Ã∏= 0, and it is 0
if xj(Œª) = 0, for j ‚àà{k, k + 1}. Moreover, the notation hj(Œª‚àí) means the left-hand
limit of the function hj(Œª) at the given point Œª. Similarly, the notation mk(Œª‚àí) and
mk(Œª+) stands, respectively, for the left-hand and right-hand limits of the function
mk(Œª) at the point Œª.
Proof of Theorem 1.17 Let k ‚àà[0, N]Z and Œª0 ‚ààR be given. By Remark 1.14, the
limits hk(Œª‚àí
0 ) and hk+1(Œª‚àí
0 ) exist. We will show that the left-hand and right-hand
limits of the function mk(Œª) at Œª0 also exist and equations (1.36) and (1.37) are
satisÔ¨Åed. We split the proof into two parts depending on the rank of xk+1(Œª0).
Part I. Assume Ô¨Årst that xk+1(Œª0) Ã∏= 0. Then there exists Œµ > 0 such that
xk+1(Œª) Ã∏= 0 for all Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ). This means that for these values of Œª, the
point k+1 is not a generalized zero of the solution x(Œª). According to Remark 1.15,
the function pk(Œª) in (1.35) is nondecreasing on (Œª0 ‚àíŒµ, Œª0 + Œµ), and we have on
this interval either mk(Œª) = 1 if pk(Œª) < 0 or mk(Œª) = 0 if pk(Œª) ‚â•0. We further
distinguish the following three subcases:
(I-a)
pk(Œª0) < 0,
(I-b)
pk(Œª0) > 0, and
(I-c)
pk(Œª0) = 0.

20
1
Motivation and Preliminaries
In subcase (I-a), in which pk(Œª0) < 0, we have pk(Œª) < 0 and xk(Œª) Ã∏= 0 for
all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) for some Œ¥ ‚àà(0, Œµ), so that in this case mk(Œª0) =
mk(Œª‚àí
0 ) = mk(Œª+
0 ) = 1, hk(Œª0) = hk(Œª‚àí
0 ) = 1, and hk+1(Œª0) = hk+1(Œª‚àí
0 ) = 1.
Therefore, the equations in (1.36) and (1.37) hold as the identities 1 = 1 and
0 = 0, respectively. Similarly in subcase (I-b), in which pk(Œª0) > 0, there is
Œ¥ ‚àà(0, Œµ) such that pk(Œª) > 0 and xk(Œª) Ã∏= 0 for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥), so
that in this case mk(Œª0) = mk(Œª‚àí
0 ) = mk(Œª+
0 ) = 0, hk(Œª0) = hk(Œª‚àí
0 ) = 1, and
hk+1(Œª0) = hk+1(Œª‚àí
0 ) = 1. Therefore, both equations (1.36) and (1.37) now hold
as the identity 0 = 0. In subcase (I-c), in which pk(Œª0) = 0, we have xk(Œª0) = 0.
By Lemma 1.13, there is Œ¥ ‚àà(0, Œµ) such that one of the additional four subcases
applies for the behavior of xk(Œª) near Œª0:
(I-c-i)
xk(Œª) Ã∏= 0 on (Œª0 ‚àíŒ¥, Œª0) and on (Œª0, Œª0 + Œ¥),
(I-c-ii)
xk(Œª) Ã∏= 0 on (Œª0 ‚àíŒ¥, Œª0) and xk(Œª) ‚â°0 on (Œª0, Œª0 + Œ¥),
(I-c-iii)
xk(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0) and xk(Œª) Ã∏= 0 on (Œª0, Œª0 + Œ¥), and
(I-c-iv)
xk(Œª) ‚â°0 both on (Œª0 ‚àíŒ¥, Œª0) and on (Œª0, Œª0 + Œ¥).
In subcase (I-c-i), the function pk(Œª) must be nondecreasing on (Œª0 ‚àíŒ¥, Œª0 + Œ¥),
which implies that pk(Œª) < 0 on (Œª0 ‚àíŒ¥, Œª0) and pk(Œª) > 0 on (Œª0, Œª0 + Œ¥).
Therefore, in this case mk(Œª‚àí
0 ) = 1, mk(Œª+
0 ) = mk(Œª0) = 0, hk(Œª‚àí
0 ) = 1, hk(Œª0) =
0, and hk+1(Œª‚àí
0 ) = hk+1(Œª0) = 1. This means that the equations in (1.36) and (1.37)
now hold as the identities 0 = 0 and ‚àí1 = ‚àí1, respectively. In subcase (I-c-ii), the
function pk(Œª) is nondecreasing on (Œª0 ‚àíŒ¥, Œª0], which implies that pk(Œª) < 0 on
(Œª0 ‚àíŒ¥, Œª0) and pk(Œª) ‚â°0 on (Œª0, Œª0 +Œ¥). Thus, as in subcase (I-c-i), we now have
mk(Œª‚àí
0 ) = 1, mk(Œª+
0 ) = mk(Œª0) = 0, hk(Œª‚àí
0 ) = 1, hk(Œª0) = 0, and hk+1(Œª‚àí
0 ) =
hk+1(Œª0) = 1, so that the equations in (1.36) and (1.37) hold as the identities 0 = 0
and ‚àí1 = ‚àí1, respectively. In subcase (I-c-iii), the situation is similar with the
result that pk(Œª) is nondecreasing on [Œª0, Œª0 + Œ¥), so that pk(Œª) ‚â°0 in (Œª0 ‚àíŒ¥, Œª0]
and pk(Œª) > 0 on (Œª0, Œª0+Œ¥). Thus, in this case mk(Œª‚àí
0 ) = mk(Œª+
0 ) = mk(Œª0) = 0,
hk(Œª‚àí
0 ) = hk(Œª0) = 0, and hk+1(Œª‚àí
0 ) = hk+1(Œª0) = 1, so that both equations
(1.36) and (1.37) hold as the identity 0 = 0. In the last subcase (I-c-iv), we have
pk(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0 + Œ¥) and in this case mk(Œª‚àí
0 ) = mk(Œª+
0 ) = mk(Œª0) = 0,
hk(Œª‚àí
0 ) = hk(Œª0) = 0, and hk+1(Œª‚àí
0 ) = hk+1(Œª0) = 1, so that (1.36) and (1.37)
hold as the identity 0 = 0.
Part II. Assume that xk+1(Œª0) = 0. Then by Remark 1.16, we have xk(Œª0) Ã∏= 0,
and there exists Œµ > 0 such that xk(Œª) Ã∏= 0 for all Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ). By
Lemma 1.13, there is Œ¥ ‚àà(0, Œµ) such that one of the following four subcases applies
for the behavior of xk+1(Œª) near the point Œª0:
(II-a)
xk+1(Œª) Ã∏= 0 on (Œª0 ‚àíŒ¥, Œª0) and on (Œª0, Œª0 + Œ¥),
(II-b)
xk+1(Œª) Ã∏= 0 on (Œª0 ‚àíŒ¥, Œª0) and xk+1(Œª) ‚â°0 on (Œª0, Œª0 + Œ¥),
(II-c)
xk+1(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0) and xk+1(Œª) Ã∏= 0 on (Œª0, Œª0 + Œ¥), and
(II-d)
xk+1(Œª) ‚â°0 both on (Œª0 ‚àíŒ¥, Œª0) and on (Œª0, Œª0 + Œ¥).
In subcase (II-a), the function pk(Œª) is well deÔ¨Åned on (Œª0 ‚àíŒ¥, Œª0) and (Œª0, Œª0 +Œ¥),
so that it is nondecreasing on each of these two intervals, by Remark 1.15. Since
xk(Œª0) Ã∏= 0, it follows that pk(Œª‚àí
0 ) = +‚àûand pk(Œª+
0 ) = ‚àí‚àû, which shows

1.2
Sturm-Liouville Difference Equation
21
that mk(Œª‚àí
0 ) = 0 and mk(Œª+
0 ) = 1. Since in this case we also have mk(Œª0) =
1 (by the deÔ¨Ånition of a generalized zero at k + 1) and hk(Œª‚àí
0 ) = hk(Œª0) = 1,
hk+1(Œª‚àí
0 ) = 1, and hk+1(Œª0) = 0, it follows that the equations in (1.36) and (1.37)
hold as the identity 1 = 1. In subcase (II-b), the function pk(Œª) is well deÔ¨Åned and
nondecreasing on (Œª0 ‚àíŒ¥, Œª0), so that pk(Œª‚àí
0 ) = +‚àû, and hence mk(Œª‚àí
0 ) = 0.
Moreover, hk(Œª‚àí
0 ) = hk(Œª0) = 1, hk+1(Œª‚àí
0 ) = 1, hk+1(Œª0) = 0, and mk(Œª+
0 ) =
mk(Œª0) = 1, by the deÔ¨Ånition of a generalized zero at k + 1. This shows that in this
case, (1.36) and (1.37) hold again as the identity 1 = 1. In subcase (II-c), we have
mk(Œª‚àí
0 ) = mk(Œª0) = 1 (by the deÔ¨Ånition of a generalized zero at k + 1), hk(Œª‚àí
0 ) =
hk(Œª0) = 1, and hk+1(Œª‚àí
0 ) = hk+1(Œª0) = 0. Moreover, the function pk(Œª) is
well deÔ¨Åned and nondecreasing on (Œª0, Œª0 + Œ¥), so that pk(Œª+
0 ) = ‚àí‚àû, and hence
mk(Œª+
0 ) = 1. In this case (1.36) and (1.37) hold as the identities 1 = 1 and 0 = 0,
respectively. Finally, in subcase (II-d), we have mk(Œª‚àí
0 ) = mk(Œª0) = mk(Œª+
0 ) (by
the deÔ¨Ånition of a generalized zero at k + 1), while hk(Œª‚àí
0 ) = hk(Œª0) = 1 and
hk+1(Œª‚àí
0 ) = hk+1(Œª0) = 0. Thus, both (1.36) and (1.37) now hold as the identity
0 = 0. This completes the proof.
‚äì‚äî
The above result (Theorem 1.17) now leads to further oscillation theorems for
the problem (E0). Denote by
n1(Œª) := the number of generalized zeros of x(Œª) in (0, N + 1].
(1.38)
Theorem 1.18 (Local Oscillation Theorem II) Assume that (1.29) holds. Con-
sider a nontrivial solution x(Œª) = {xk(Œª)}N+1
k=0 of (SLŒª) satisfying (1.31). Then
n1(Œª‚àí) and n1(Œª+) exist and for all Œª ‚ààR
n1(Œª+) = n1(Œª) ‚â§N + 1,
(1.39)
n1(Œª+) ‚àín1(Œª‚àí) = hN+1(Œª‚àí) ‚àíhN+1(Œª) ‚àà{0, 1}.
(1.40)
Hence, the function n1(Œª) is nondecreasing in Œª on R; the limit
m :=
lim
Œª‚Üí‚àí‚àûn1(Œª)
(1.41)
exists with m ‚àà[0, N + 1]Z, so that for a suitable Œª0 < 0, we have
n1(Œª) ‚â°m
and
hN+1(Œª‚àí) ‚àíhN+1(Œª) ‚â°0
for all Œª ‚â§Œª0.
(1.42)
Proof The number of generalized zeros of the solution x(Œª) in (0, N + 1] is by
deÔ¨Ånition
n1(Œª) =
N

k=0
mk(Œª),
Œª ‚ààR,

22
1
Motivation and Preliminaries
where, as in Theorem 1.17, mk(Œª) is the number of generalized zeros of x(Œª) in
(k, k + 1]. The statement in (1.39) follows directly from (1.36). The expression in
(1.40) is calculated by the telescope sum of the expression in (1.37). This yields that
n1(Œª+) ‚àín1(Œª‚àí) = hN+1(Œª‚àí) ‚àíhN+1(Œª) ‚àíh0(Œª‚àí) + h0(Œª),
Œª ‚ààR.
But since by (1.31) the initial conditions of x(Œª) do not depend on Œª, we have
h0(Œª‚àí) = h0(Œª) for all Œª ‚ààR, which shows (1.40). From the two conditions (1.39)
and (1.40), we then have that the function n1(Œª) is nondecreasing in Œª on R. Since
the values of n1(Œª) are nonnegative integers, the limit in (1.41) exists with m ‚àà
N ‚à™{0}. Consequently, n1(Œª) ‚â°m for Œª sufÔ¨Åciently negative, say for all Œª ‚â§Œª0 for
some Œª0 < 0. Hence, n1(Œª+) ‚àín1(Œª‚àí) ‚â°0 for Œª ‚â§Œª0. Applying (1.40) once more
then yields the second equation in (1.42). This completes the proof.
‚äì‚äî
Now we relate the above oscillation results with the eigenvalue problem (E0).
We say that a number Œª0 ‚ààR is a Ô¨Ånite eigenvalue of (E0), provided there exists a
nontrivial solution x(Œª) = {xk(Œª)}N+1
k=0 of (E0) such that xN+1(Œª0) = 0 and
xN+1(Œª) Ã∏= 0 for Œª in some left neighborhood of Œª0.
(1.43)
Note that such a requirement is justiÔ¨Åed by Lemma 1.13. We observe that every
Ô¨Ånite eigenvalue of (E0) is also a traditional eigenvalue, for which the ‚Äúnondegen-
eracy condition‚Äù (1.43) is dropped. From the uniqueness of solutions of equation
(SLŒª), it then follows that Œª0 is a Ô¨Ånite eigenvalue of (E0) if and only if the principal
solution ÀÜx(Œª) (see (1.32)) satisÔ¨Åes ÀÜxN+1(Œª0) = 0 and ÀÜxN+1(Œª) Ã∏= 0 for Œª in some left
neighborhood of Œª0. Or equivalently, the principal solution ÀÜx(Œª) has hN+1(Œª‚àí
0 ) = 1
and hN+1(Œª0) = 0. This shows that the difference hN+1(Œª‚àí
0 )‚àíhN+1(Œª0), whenever
it is positive, indicates a Ô¨Ånite eigenvalue of problem (E0).
From Lemma 1.13 we obtain that under the assumption (1.29), the Ô¨Ånite
eigenvalues of (E0) are isolated. This property was also proven for the classical
eigenvalues of (SLŒª) in [44] under the strict monotonicity of rk(Œª) and qk(Œª). Such
a strict monotonicity assumption is not required in this subsection.
Thus, we Ô¨Ånally arrive at the following global oscillation theorem. Denote by
n2(Œª) := the number of Ô¨Ånite eigenvalues of (E0) in (‚àí‚àû, Œª].
(1.44)
Then from this deÔ¨Ånition, we have
n2(Œª+) = n2(Œª),
n2(Œª) ‚àín2(Œª‚àí) = hN+1(Œª‚àí) ‚àíhN+1(Œª)
for all Œª ‚ààR,
(1.45)
i.e., the positivity of the difference n2(Œª)‚àín2(Œª‚àí) indicates a Ô¨Ånite eigenvalue at Œª.

1.2
Sturm-Liouville Difference Equation
23
Theorem 1.19 (Global Oscillation Theorem) Assume (1.29). Then for all Œª ‚ààR
n2(Œª+) = n2(Œª) ‚â§1,
(1.46)
n2(Œª+) ‚àín2(Œª‚àí) = n1(Œª+) ‚àín1(Œª‚àí) ‚àà{0, 1},
(1.47)
and there exists m ‚àà[0, N + 1]Z such that
n1(Œª) = n2(Œª) + m
for all Œª ‚ààR.
(1.48)
Moreover, for a suitable Œª0 < 0, we have
n2(Œª) ‚â°0
and
n1(Œª) ‚â°m
for all Œª ‚â§Œª0.
(1.49)
Proof The result follows directly from Theorem 1.18.
‚äì‚äî
Corollary 1.20 Under the assumption (1.29), the Ô¨Ånite eigenvalues of (E0) are
isolated and bounded from below.
Proof From Lemma 1.13 we know that the Ô¨Ånite eigenvalues of (E0) are isolated.
The second statement follows from condition (1.49) of Theorem 1.19, since n2(Œª) ‚â°
0 for all Œª ‚â§Œª0 means that there are no Ô¨Ånite eigenvalues of (E0) in the interval
(‚àí‚àû, Œª0].
‚äì‚äî
It remains to connect the above global oscillation theorem with the traditional
statement saying that the j-th eigenfunction has exactly j generalized zeros in the
interval (0, N+1]. We will see that under some additional assumption, the statement
of this result remains exactly the same when we replace the eigenfunctions of (E0)
by its Ô¨Ånite eigenfunctions. This additional assumption is formulated in terms of the
associated discrete quadratic functional (1.13)
F(Œ∑, Œª) :=
N

k=0
!rk(Œª) (Œ∑k)2 ‚àíqk(Œª) Œ∑2
k+1
",
where Œ∑ = {Œ∑k}N+1
k=0 is a sequence such that Œ∑0 = 0 = Œ∑N+1. The functional F(¬∑, Œª)
is positive; we write F(¬∑, Œª) > 0, if F(Œ∑, Œª) > 0 for every sequence Œ∑ with Œ∑0 =
0 = Œ∑N+1 and Œ∑ Ã∏= 0.
Theorem 1.21 (Oscillation Theorem) Assume (1.29). Then
n1(Œª) = n2(Œª)
for all Œª ‚ààR
(1.50)
if and only if there exists Œª0 < 0 such that F(¬∑, Œª0) > 0. In this case, if Œª1 <
Œª2 < ¬∑ ¬∑ ¬∑ < Œªr (where r ‚â§N + 1) are the Ô¨Ånite eigenvalues of (E0) with the
corresponding Ô¨Ånite eigenfunctions x(1), x(2), ..., x(r), then for each j ‚àà{1, . . . , r}
the Ô¨Ånite eigenfunction x(j) has exactly j generalized zeros in (0, N + 1].

24
1
Motivation and Preliminaries
Remark 1.22
(i) Note that since the Ô¨Ånite eigenfunction x(j) has x(j)
N+1 = 0, it satisÔ¨Åes x(j)
N Ã∏= 0,
by Remark 1.16. Therefore, the point N + 1 is one of the generalized zeros of
x(j), and consequently the remaining j ‚àí1 generalized zeros of x(j) are in the
open interval (0, N + 1). This complies with the traditional continuous time
statement.
(ii) Conditions of Theorem 1.21 are automatically satisÔ¨Åed for the classical Sturm-
Liouville problem (1.30), i.e., (1.50). Indeed, for the case qk(Œª) = qk + wkŒª
and wk > 0, we can estimate
F(Œ∑, Œª) :=
N

k=0
!
rk (Œ∑k)2 ‚àíqk Œ∑2
k+1
"
‚àíŒª
N

k=0
wkŒ∑2
k+1 = F0(Œ∑, Œª)‚àíŒª
N

k=0
wkŒ∑2
k+1
such that
pk = rk (Œ∑k)2 ‚àíqk Œ∑2
k+1 =

Œ∑k Œ∑k+1)
 rk
‚àírk
‚àírk rk ‚àíqk
  Œ∑k
Œ∑k+1

obeys the inequality |pk| ‚â§c (Œ∑2
k + Œ∑2
k+1) for some c > 0, and then introducing
the notation d = mink‚àà[0,N]Z wk > 0, we see that there exists Œª0 < 0 such that
for all Œª < Œª0
F(Œ∑, Œª) = F0(Œ∑, Œª) ‚àíŒª
N

k=0
wkŒ∑2
k+1 ‚â•‚àí2c‚à•Œ∑‚à•2 ‚àíŒªd‚à•Œ∑‚à•2 > 0,
where we use that ‚à•Œ∑‚à•Ã∏= 0 (see also [206, Theorem 3]).
Proof of Theorem 1.21 If n1(Œª) = n2(Œª) for all Œª ‚ààR, then the number m in
equation (1.48) of Theorem 1.19 is zero. This implies through condition (1.49)
that n1(Œª) ‚â°0 for all Œª ‚â§Œª0 with some Œª0 < 0. By Theorem 1.2, the latter
condition is equivalent to the positivity of the functional F(¬∑, Œª) for every Œª ‚â§Œª0,
in particular for Œª = Œª0. Conversely, assume that F(¬∑, Œª0) > 0 for some Œª0 < 0.
Then n1(Œª0) = 0, by Theorem 1.2, and since the function n1(¬∑) is nondecreasing
in Œª on R (see Theorem 1.18), it follows that n1(Œª) ‚â°0 for all Œª ‚â§Œª0. From this
we see that m = 0 in (1.49) and hence also in (1.48). Equality (1.50) is therefore
established. Finally, assume that (1.50) holds and let Œªj (where j ‚àà{1, . . . , r}) be
the j-th Ô¨Ånite eigenvalue of (E0) with the corresponding Ô¨Ånite eigenfunction x(j).
Then n2(Œªj) = j, and from (1.50), we get n1(Œªj) = j, i.e., x(j) has exactly j
generalized zeros in (0, N + 1]. The proof is complete.
‚äì‚äî
In the last part of this section, we present certain results on the existence of Ô¨Ånite
eigenvalues of (E0), in particular a necessary condition and a sufÔ¨Åcient condition
for the existence of a Ô¨Ånite eigenvalue and a characterization of the smallest Ô¨Ånite
eigenvalue. The proofs of these results are also based on Theorem 1.2 (see also more
general Theorems 5.32‚Äì5.34 for symplectic systems).

1.3
Discrete Variational Theory
25
Theorem 1.23 Assume (1.29). If (E0) has a Ô¨Ånite eigenvalue, then there exist
Œª0, Œª1 ‚ààR with Œª0 < Œª1 and m ‚ààN ‚à™{0} such that n1(Œª) ‚â°m for all Œª ‚â§Œª0 and
F(¬∑, Œª1) Ã∏> 0.
Theorem 1.24 Assume (1.29). If there exist Œª0, Œª1 ‚ààR with Œª0 < Œª1 such that
F(¬∑, Œª0) > 0 and F0(¬∑, Œª1) Ã∏> 0, then (E0) has at least one Ô¨Ånite eigenvalue.
Theorem 1.25 Assume (1.29). Let there exist Œª0, Œª1 ‚ààR with Œª0 < Œª1 such that
F(¬∑, Œª0) > 0 and F(¬∑, Œª1) Ã∏> 0. Then the eigenvalue problem (E0) possesses the
smallest Ô¨Ånite eigenvalue Œªmin, which is characterized by any of the conditions:
Œªmin = sup{Œª ‚ààR, F(¬∑, Œª) > 0},
Œªmin = min{Œª ‚ààR, F(¬∑, Œª) Ã∏> 0}.
1.3
Discrete Variational Theory
In this section we explain the motivation and origin of the symplectic difference
systems (SDS) in the discrete variational theory, in particular in the discrete calculus
of variations and discrete optimal control theory. We shall see that in both cases
symplectic difference systems arise in these variational problems naturally as the
second-order systems (i.e., as the Jacobi systems). Moreover, in Theorems 1.29
and 1.34, we justify the fact that the theory of symplectic difference systems, rather
than the theory linear Hamiltonian difference systems, is the proper platform for
studying the second-order optimality conditions in the discrete variational theory.
1.3.1
Discrete Calculus of Variations
Given an index N ‚ààN, we consider the classical nonlinear discrete calculus of
variations problem
minimize
F(x) := K(x0, xN+1) +
N

k=0
L(k, xk+1, xk)
(1.51)
subject to sequences x = {xk}N+1
k=0 satisfying the endpoints constraint
œï(x0, xN+1) = 0.
(1.52)
Here x : [0, N +1]Z ‚ÜíRn is the state variable, K : R2n ‚ÜíR is the endpoints cost,
L : [0, N]Z√óRn√óRn ‚ÜíR is the Lagrangian, and œï : R2n ‚ÜíRr with r ‚â§2n is the
constraint function. We assume that the data are sufÔ¨Åciently smooth, i.e., C1 for the
Ô¨Årst-order optimality conditions and C2 for the second-order optimality conditions.

26
1
Motivation and Preliminaries
A sequence x = {xk}N+1
k=0 is feasible if it satisÔ¨Åes the boundary condition (1.52).
A feasible sequence ÀÜx is called a local minimum for (1.51) if there exists Œµ > 0 such
that F(ÀÜx) ‚â§F(x) for all feasible x satisfying ‚à•xk ‚àíÀÜxk‚à•< Œµ for all k ‚àà[0, N +1]Z,
where ‚à•¬∑‚à•is any norm in Rn. Moreover, a local minimum ÀÜx is strict if F(ÀÜx) < F(x)
for all feasible x Ã∏= ÀÜx with ‚à•xk ‚àíÀÜxk‚à•< Œµ for all k ‚àà[0, N + 1]Z. Note that the
concepts of a weak and strong local extremum now coincide, since problem (1.51)
is Ô¨Ånite dimensional.
In the next two theorems, we present the Ô¨Årst- and second-order necessary and
sufÔ¨Åcient optimality conditions for problem (1.51). The proofs of these results can
be found, e.g., in [16, 178, 204]; see also the comments in Sect. 1.7. In the sequel,
we shall denote by Lx and Lu the gradients of L (i.e., the row vectors of partial
derivatives of L) with respect to the second and third variables. Similarly, we denote
by Lxx, Lxu, Luu the matrices containing the corresponding second-order partial
derivatives of L. We note that in contrast with the exposition in [16, Chapter 4], the
gradients Lx and Lu are here the row vectors. The gradient of the functions K and
œï will be denoted by the symbol ‚àá.
Linearizing the problem (1.51) along a feasible sequence ÀÜx, we deÔ¨Åne the r √ó 2n
matrix
M := ‚àáœï(ÀÜx0, ÀÜxN+1).
(1.53)
A sequence Œ∑ = {Œ∑k}N+1
k=0 is called admissible if it satisÔ¨Åes the endpoints constraint
M
 Œ∑0
Œ∑N+1

= 0.
(1.54)
The second variation of the functional F at a feasible sequence ÀÜx is the discrete
quadratic functional
F‚Ä≤‚Ä≤(ÀÜx, Œ∑) :=
 Œ∑0
Œ∑N+1
T

 Œ∑0
Œ∑N+1

+
N

k=0
Œ∑k+1
Œ∑k
T  Pk Qk
QT
k Rk
 Œ∑k+1
Œ∑k

,
(1.55)
where the symmetric 2n √ó 2n matrix  and the n √ó n matrices Pk, Qk, Rk are given
by
Pk := ÀÜLxx(k),
Qk := ÀÜLxu(k),
Rk := ÀÜLuu(k),
(1.56)
 := ‚àá2KT (ÀÜx0, ÀÜxN+1) + Œ≥ T ‚àá2œïT (ÀÜx0, ÀÜxN+1)
(1.57)
with some Œ≥ ‚ààRr and with the partial derivatives of L evaluated at (k, ÀÜxk+1, ÀÜxk).
Note that the matrices Pk and Rk are symmetric, as the Lagrangian L is assumed to
be C2 in the second and third variables.
We say that the second variation F‚Ä≤‚Ä≤ is nonnegative at ÀÜx if F‚Ä≤‚Ä≤(ÀÜx, Œ∑) ‚â•0 for
all admissible sequences Œ∑ = {Œ∑k}N+1
k=0 . An alternative terminology is nonnegative

1.3
Discrete Variational Theory
27
deÔ¨Ånite or positive semideÔ¨Ånite at ÀÜx. The quadratic functional is positive at ÀÜx if
F(ÀÜx, Œ∑) > 0 for all admissible sequences Œ∑ = {Œ∑k}N+1
k=0 satisfying Œ∑ Ã∏‚â°0. An
alternative terminology is positive deÔ¨Ånite at ÀÜx.
Theorem 1.26 Let {ÀÜxk}N+1
k=0 be a local minimum for problem (1.51) and assume
that the matrix M in (1.53) has full rank r. Then there exists a vector Œ≥ ‚ààRr such
that the following conditions hold:
(i) the Euler-Lagrange difference equation
 ÀÜLu(k) = ÀÜLx(k),
k ‚àà[0, N ‚àí1]Z,
(1.58)
where the partial derivatives of L are evaluated at (k, ÀÜxk+1, ÀÜxk),
(ii) the transversality condition
 ÀÜLu(0), ‚àíÀÜLu(N) ‚àíÀÜLx(N)

= ‚àáK(ÀÜx0, ÀÜxN+1) + Œ≥ T M,
(1.59)
(iii) the second variation F‚Ä≤‚Ä≤ with the data from (1.56) and (1.57) evaluated at
(k, ÀÜxk+1, ÀÜxk) is nonnegative at ÀÜx.
Remark 1.27 If we deÔ¨Åne ÀÜLu at k = N + 1 by ÀÜLu(N + 1) := ÀÜLu(N) + ÀÜLx(N),
then the Euler-Lagrange difference equation (1.58) is satisÔ¨Åed for all k ‚àà[0, N]Z,
and the transversality condition in (1.59) can be written in the form known in the
continuous time theory, i.e.,
 ÀÜLu(0), ‚àíÀÜLu(N + 1)

= ‚àáK(ÀÜx0, ÀÜxN+1) + Œ≥ T M.
Next we formulate sufÔ¨Åcient optimality conditions for problem (1.51).
Theorem 1.28 Suppose that a feasible sequence ÀÜx = {ÀÜxk}N+1
k=0 satisÔ¨Åes, for some
Œ≥ ‚ààRr, the Ô¨Årst-order optimality conditions (i) and (ii) in Theorem 1.26 with
the matrix M in (1.53) having full rank r. Furthermore, suppose that the second
variation F‚Ä≤‚Ä≤ is positive at ÀÜx. Then ÀÜx is a strict local minimum for problem (1.51).
If the second variation F‚Ä≤‚Ä≤ is nonnegative or even positive at ÀÜx, then the zero
sequence is its minimum. Applying Theorem 1.26 to this situation, we obtain the
Jacobi equation for problem (1.51), which is the Euler-Lagrangedifference equation
for the functional F‚Ä≤‚Ä≤. Thus, from (1.58) we get the second-order difference equation
(RkŒ∑k + QT
k Œ∑k+1) = PkŒ∑k+1 + QkŒ∑k,
k ‚àà[0, N ‚àí1]Z.
(1.60)
Note that when n = 1 and Qk = 0 for all k ‚àà[0, N ‚àí1]Z, equation (1.60) becomes
the Sturm-Liouville difference equation (1.1) studied in Sect. 1.2.
It is well-known in the literature that equation (1.60) can be written as a special
symplectic difference system (SDS) when the matrices
Rk and Rk + QT
k are invertible for all k ‚àà[0, N]Z.
(1.61)

28
1
Motivation and Preliminaries
More precisely, in [16, Example 3.17] it is shown that under (1.61) the substitution
xk := Œ∑k,
k ‚àà[0, N + 1]Z,
uk := RkŒ∑k + QT
k Œ∑k+1,
k ‚àà[0, N]Z,
uN+1 := uN + PNŒ∑N+1 + QNŒ∑N
‚é´
‚é™‚é¨
‚é™‚é≠
(1.62)
transforms equation (1.60) into the linear Hamiltonian difference system
xk = Akxk+1 + Bkuk,
uk = Ckxk+1 ‚àíAT
k uk,
k ‚àà[0, N]Z,
(1.63)
with symmetric Bk and Ck and invertible I ‚àíAk. In turn, it is shown in [16,
Example 3.10] that system (1.63) is a special symplectic system (SDS) with
invertible Ak = (I ‚àíAk)‚àí1 for all k ‚àà[0, N]Z; see also Sect. 2.1.2.
In the next result, we present an alternative method, which transforms the Jacobi
equation (1.60) directly into the symplectic system (SDS). This method uses the
weaker assumption that only the matrix
Rk + QT
k is invertible for all k ‚àà[0, N]Z.
(1.64)
Therefore, in comparison with the result in [16, Section 3.6], we allow the matrices
Rk to be singular.
Theorem 1.29 Assume that (1.64) holds and deÔ¨Åne for k ‚àà[0, N]Z the 2n √ó 2n
matrices Sk :=

Ak Bk
Ck Dk

by
Ak = (Rk + QT
k )‚àí1Rk, Ck = Pk(Rk + QT
k )‚àí1Rk ‚àíQk(Rk + QT
k )‚àí1QT
k ,
Bk = (Rk + QT
k )‚àí1,
Dk = (Rk + Qk + QT
k + Pk) (Rk + QT
k )‚àí1.
Then Sk is a symplectic matrix for all k ‚àà[0, N]Z. Consequently, the Jacobi
equation (1.60) is a special symplectic system (SDS), in which yk := (xT
k , uT
k )T
is deÔ¨Åned by (1.62). In addition, the resulting symplectic system (SDS) is a Hamil-
tonian system (1.63) if and only if the matrix Rk is invertible for all k ‚àà[0, N]Z.
Proof By direct calculations and with the aid of the symmetry of Rk and Pk, one
can easily verify that ST
k J Sk = J , which proves the statement. Alternatively, see
Theorem 1.34 in combination with Remark 1.35.
‚äì‚äî
Remark 1.30 Analogously to problem (1.51), we now consider the discrete calculus
of variations problem without the shift in xk+1 in the Lagrangian L, i.e.,
minimize
F(x) := K(x0, xN+1) +
N

k=0
L(k, xk, xk)
(1.65)

1.3
Discrete Variational Theory
29
subject to sequences x = {xk}N+1
k=0 satisfying the endpoints constraint (1.52). Then
a similar analysis as in Theorem 1.26 yields the Euler-Lagrange difference equation
 ÀÜLu(k) = ÀÜLx(k + 1),
k ‚àà[0, N ‚àí1]Z,
(1.66)
or equivalently
[ ÀÜLu(k) ‚àíÀÜLx(k)] = ÀÜLx(k),
k ‚àà[0, N ‚àí1]Z,
(1.67)
where the partial derivatives of L are evaluated at (k, ÀÜxk, ÀÜxk) and the transversality
condition
 ÀÜLu(0) ‚àíÀÜLx(0), ‚àíÀÜLu(N)  = ‚àáK(ÀÜx0, ÀÜxN+1) + Œ≥ T M.
(1.68)
In fact, these results for problem (1.65) can also be obtained from problem (1.51)
upon writing xk = xk+1 ‚àíxk and considering the Lagrangian L(k, x, u) :=
L(k, x ‚àíu, u) in (1.51). Applying (1.67) to the second variation F‚Ä≤‚Ä≤, the resulting
Jacobi difference equation then has the form
[(Rk‚àíQk) Œ∑k+(QT
k ‚àíP k) Œ∑k] = P kŒ∑k+QkŒ∑k,
k ‚àà[0, N‚àí1]Z.
(1.69)
Equation (1.69) can be written as the symplectic system (SDS) when the matrix
Rk ‚àíQT
k (and not necessarily Rk) is invertible for all k ‚àà[0, N]Z. These systems
are studied in more detail in [294, Section 2].
1.3.2
Discrete Optimal Control Theory
We now extend the considerations in the previous subsection to discrete optimal
control setting. Thus, for a Ô¨Åxed index N ‚ààN, we consider the discrete optimal
control problem
minimize
G(x, u) := K(x0, xN+1) +
N

k=0
L(k, xk+1, uk)
(1.70)
subject to the pairs (x, u) of sequences x = {xk}N+1
k=0 and u = {uk}N
k=0 satisfying the
difference equation
xk = f (k, xk+1, uk),
k ‚àà[0, N]Z,
(1.71)
and the endpoints constraint (1.52). Here x : [0, N +1]Z ‚ÜíRn is the state variable,
u : [0, N]Z ‚ÜíRm with m ‚â§n is the control variable, K : R2n ‚ÜíR is the endpoints
cost, L : [0, N]Z √óRn √óRm ‚ÜíR is the Lagrangian, f : [0, N]Z √óRn √óRm ‚ÜíRn

30
1
Motivation and Preliminaries
is the dynamics, and œï : R2n ‚ÜíRr with r ‚â§2n is the constraint function. We
assume that the functions K, L, f , œï are sufÔ¨Åciently smooth, i.e., C1 for the Ô¨Årst-
order optimality conditions and C2 for the second-order optimality conditions. In
order to be able to solve equation (1.71) for xk+1 in terms of xk and uk, we assume
that the n √ó n matrix
I ‚àífx(k, x, u) is invertible for every k ‚àà[0, N]Z, x ‚ààRn, u ‚ààRm.
(1.72)
A pair (x, u) of sequences x = {xk}N+1
k=0 and u = {uk}N
k=0 is feasible if it satisÔ¨Åes
(1.71) and (1.52). A feasible pair (ÀÜx, ÀÜu) is called a local minimum for (1.70) if there
exists Œµ > 0 such that G(ÀÜx, ÀÜu) ‚â§G(x, u) for all feasible pairs (x, u) satisfying
‚à•xk ‚àíÀÜxk‚à•< Œµ for all k ‚àà[0, N + 1]Z and ‚à•uk ‚àíÀÜuk‚à•< Œµ for all k ‚àà[0, N]Z. Here
‚à•¬∑ ‚à•is any norm in Rn, resp., in Rm. Moreover, a local minimum (ÀÜx, ÀÜu) is strict if
G(ÀÜx, ÀÜu) < G(x, u) for all such feasible pairs (x, u) Ã∏= (ÀÜx, ÀÜu).
The Hamiltonian H : [0, N]Z √ó Rn √ó Rm √ó Rn √ó R ‚ÜíR corresponding to
problem (1.70), (1.71) is deÔ¨Åned by
H(k, x, u, p, Œª) := pT f (k, x, u) + Œª L(k, x, u).
(1.73)
Denote the gradients of the function f along a feasible pair (ÀÜx, ÀÜu) by
Ak := fx(k, ÀÜxk+1, ÀÜuk),
Bk := fu(k, ÀÜxk+1, ÀÜuk)
(1.74)
and deÔ¨Åne the r √ó 2n matrix M by (1.53). Then we have A : [0, N]Z ‚ÜíRn√ón and
B : [0, N]Z ‚ÜíRn√óm, and, according to (1.72), the matrix I ‚àíAk is invertible for
all k ‚àà[0, N]Z. We say that the linear system
Œ∑k = AkŒ∑k+1 + Bkvk,
k ‚àà[0, N]Z,
(1.75)
is M-controllable if for every d ‚ààRr there exists a vector Œ± ‚ààRn and a sequence
v = {vk}N
k=0 such that the solution Œ∑ = {Œ∑k}N+1
k=0 of the initial value problem (1.75)
with Œ∑0 = Œ± satisÔ¨Åes
M
 Œ∑0
Œ∑N+1

= d.
In [192, Proposition 4.5] it is proved that if the matrix M has full rank r and I ‚àí
Ak is invertible for all k ‚àà[0, N]Z, then the M-controllability of system (1.75) is
equivalent with the following normality condition on problem (1.70): the system
pk = ‚àíAT
k pk,
Bkpk = 0,
k ‚àà[0, N]Z,
 ‚àíp0
pN+1

= MT Œ≥,
(1.76)
where Œ≥ ‚ààRr possesses only the trivial solution pk ‚â°0 on [0, N + 1]Z (and then
also Œ≥ = 0).

1.3
Discrete Variational Theory
31
A pair (Œ∑, v) with Œ∑ = {Œ∑k}N+1
k=0 and v = {vk}N
k=0 is said to be admissible if it
satisÔ¨Åes equation (1.75) and the boundary condition (1.54). For a normal problem,
(1.70) we deÔ¨Åne the second variation of the functional G at a feasible pair (ÀÜx, ÀÜu) as
the discrete quadratic functional
G‚Ä≤‚Ä≤(ÀÜx, ÀÜu, Œ∑, v) :=
 Œ∑0
Œ∑N+1
T

 Œ∑0
Œ∑N+1

+
N

k=0
Œ∑k+1
vk
T  Pk Qk
QT
k Rk
 Œ∑k+1
vk

.
(1.77)
The 2n √ó 2n matrix  is given in (1.57), and the n √ó n, n √ó m, m √ó m matrices Pk,
Qk, Rk, respectively, are deÔ¨Åned by
Pk := pT
k ÀÜfxx(k) + ÀÜLxx(k),
Qk := pT
k ÀÜfxu(k) + ÀÜLxu(k),
Rk := pT
k ÀÜfuu(k) + ÀÜLuu(k),
‚é´
‚é™‚é¨
‚é™‚é≠
(1.78)
for some sequence p = {pk}N+1
k=0 , see Theorem 1.32. The partial derivatives of f
and L are evaluated at (k, ÀÜxk+1, ÀÜuk). Note that Pk and Rk are symmetric.
Remark 1.31 When the endpoints in problem (1.70) or in problem (1.60) are Ô¨Åxed,
i.e., x0 = A and xN+1 = B with some given A, B ‚ààRn, we have r = 2n and
M = I2n in (1.53). In this case the endpoints cost K(x0, xN+1) = K(A, B) is
constant; the variations Œ∑ = {Œ∑k}N+1
k=0 satisfy Œ∑0 = 0 = Œ∑N+1, and  = 02n in
(1.57).
We say that the functional G‚Ä≤‚Ä≤ is nonnegative (or nonnegative deÔ¨Ånite or positive
semideÔ¨Ånite) at (ÀÜx, ÀÜu) if G‚Ä≤‚Ä≤(ÀÜx, ÀÜu, Œ∑, v) ‚â•0 for every admissible pair (Œ∑, v). We
say that G‚Ä≤‚Ä≤ is positive (or positive deÔ¨Ånite) at (ÀÜx, ÀÜu) if G‚Ä≤‚Ä≤(ÀÜx, ÀÜu, Œ∑, v) > 0 for every
admissible pair (Œ∑, v) Ã∏= (0, 0).
Necessary and sufÔ¨Åcient optimality conditions for problem (1.70) are formulated
in terms of the weak Pontryagin (maximum) principle and the deÔ¨Åniteness of the
second variation G‚Ä≤‚Ä≤.
Theorem 1.32 Assume that (ÀÜx, ÀÜu) is a local minimum for problem (1.70) and deÔ¨Åne
the matrices Ak, Bk, M by (1.74) and (1.53) and suppose that M has full rank r.
Then there exist a constant Œª0 ‚â•0, a vector Œ≥ ‚ààRr and a sequence p : [0, N +
1]Z ‚ÜíRn such that Œª0 + N+1
k=0 ‚à•pk‚à•Ã∏= 0 and satisfying:
(i) the adjoint equation ‚àípk = Hx(k, ÀÜxk+1, ÀÜuk, pk, Œª0), i.e.,
‚àípk = AT
k pk + Œª0 ÀÜLT
x (k),
k ‚àà[0, N]Z,
(1.79)
(ii) the stationarity condition Hu(k, ÀÜxk+1, ÀÜuk, pk, Œª0) = 0, i.e.,
BT
k pk + Œª0 ÀÜLT
u (k) = 0,
k ‚àà[0, N]Z,
(1.80)

32
1
Motivation and Preliminaries
(iii) the transversality condition
 ‚àíp0
pN+1

= Œª0 ‚àáKT (ÀÜx0, ÀÜxN+1) + MT Œ≥.
(1.81)
If, in addition, system (1.75) is M-controllable, then we may take Œª0 = 1, the
sequence p = {pk}N+1
k=0 and the vector Œ≥ are unique, and
(iv) the second variation G‚Ä≤‚Ä≤ is nonnegative at (ÀÜx, ÀÜu).
Theorem 1.33 Assume that (ÀÜx, ÀÜu) is a feasible pair for problem (1.70); the matrix
M in (1.53) has full rank r, and assume that there exist a vector Œ≥ ‚ààRr and
a sequence p : [0, N +1]Z ‚ÜíRn satisfying the conditions (i)‚Äì(iii) in Theorem 1.32
with Œª0 := 1. Furthermore, suppose that the second variation G‚Ä≤‚Ä≤ is positive at
(ÀÜx, ÀÜu). Then (ÀÜx, ÀÜu) is a strict local minimum for problem (1.70).
We now proceed in deriving the main result of this section. By Theorem 1.32, the
second variation G‚Ä≤‚Ä≤ is a nonnegative functional at a local minimum (ÀÜx, ÀÜu) with the
minimum value zero. Thus, applying the weak Pontryagin principle, i.e., equations
(1.79) and (1.80), to the second variation G‚Ä≤‚Ä≤, we obtain for k ‚àà[0, N]Z the Jacobi
system (here we substitute qk := ‚àípk)
qk = ‚àíAT
k qk + PkŒ∑k+1 + Qkvk,
‚àíBT
k qk + QT
k Œ∑k+1 + Rkvk = 0.
(1.82)
Our aim is to show that system (1.75) and (1.82) has a natural symplectic structure.
More precisely, we will show that under a natural invertibility assumption, the pair
(Œ∑, q) solves a symplectic difference system associated with (1.75) and (1.82). For
that we need to solve the second equation in (1.82) for vk, which of course can
be done if, e.g., Rk is invertible. However, similarly to treatment of the discrete
calculus of variations in Theorem 1.29, we wish to avoid the invertibility of Rk and
use a more natural invertibility condition.
Following assumption (1.72) and the notation in (1.74), we deÔ¨Åne the n √ó n
matrix ÀúAk and the m √ó m matrix Sk by
ÀúAk := (I ‚àíAk)‚àí1,
Sk := Rk + QT
k ÀúAkBk.
(1.83)
Note that Ak and ÀúAk commute. We impose the following structural assumption that
the matrix
Sk in (1.83) is invertible for all k ‚àà[0, N]Z.
(1.84)
We will discuss the connection of condition (1.84) with the invertibility of Rk in
Lemma 1.36 and Corollary 1.37 below. Whenever the matrix Rk is invertible and
whenever the matrix Sk is invertible, we deÔ¨Åne the n √ó n matrices Tk and Vk by
Tk := I + ÀúAkBkR‚àí1
k QT
k ,
Vk := I ‚àíÀúAkBkS‚àí1
k QT
k .
(1.85)

1.3
Discrete Variational Theory
33
The next result shows that under (1.84), the Jacobi system (1.82) is a symplectic
difference system.
Theorem 1.34 Assume that the matrices ÀúAk, Sk, Vk are deÔ¨Åned in (1.83) and (1.85)
and that condition (1.84) holds. DeÔ¨Åne for k ‚àà[0, N]Z the 2n √ó 2n matrix Sk :=

Ak Bk
Ck Dk

by
Ak = Vk ÀúAk,
Ck = (PkVk ‚àíQkS‚àí1
k QT
k ) ÀúAk,
Bk = ÀúAkBkS‚àí1
k BT
k , Dk = (Qk + Pk ÀúAkBk) S‚àí1
k BT
k + I ‚àíAT
k .

(1.86)
Then Sk is a symplectic matrix for all k ‚àà[0, N]Z. Consequently, the Jacobi system
(1.75) and (1.82) is a special symplectic system (SDS), in which yk := (Œ∑T
k , qT
k )T .
In addition, the resulting symplectic system (SDS) is a Hamiltonian system (1.63) if
and only if the matrix Vk (or equivalently Rk) is invertible for all k ‚àà[0, N]Z.
Remark 1.35 In the discrete calculus of variations setting, we have xk = uk for
all k ‚àà[0, N]Z, i.e., f (k, x, u) = u. In this case m = n and (1.74) and (1.83)
imply that Ak = 0, Bk = I, ÀúAk = I, and Sk = Pk + QT
k . Therefore, we see that
the statement of Theorem 1.34 reduces exactly to the statement of Theorem 1.29,
and that in both cases, the invertibility of Rk is not needed in order to reveal the
symplectic structure of the corresponding Jacobi system.
The proof of Theorem 1.34 is displayed at the end of this section. First we clarify
the relationship between the invertibility conditions on Rk, Sk, Tk, and Vk.
Lemma 1.36 Assume that the matrices ÀúAk, Sk, Tk, Vk are deÔ¨Åned in (1.83) and
(1.85). Then the following statements are equivalent:
(i) the matrices Rk and Tk are invertible,
(ii) the matrices Rk and Sk are invertible,
(iii) the matrices Sk and Vk are invertible.
Proof For the proof we adopt a known matrix inversion formula. Given any matrices
A, B, C, D such that the products below are deÔ¨Åned, then the invertibility of A, D,
and D ‚àíCA‚àí1B implies the invertibility of A ‚àíBD‚àí1C with
(A ‚àíBD‚àí1C)‚àí1 = A‚àí1 + A‚àí1B (D ‚àíCA‚àí1B)‚àí1CA‚àí1.
(1.87)
Based on this fact, we prove the implications
Rk and Tk invertible 	‚áíSk invertible,
(1.88)
Rk and Sk invertible 	‚áíVk and Tk invertible,
(1.89)
Sk and Vk invertible 	‚áíRk invertible.
(1.90)

34
1
Motivation and Preliminaries
Indeed, for (1.88) we set A := Rk, B := ‚àíQT
k , C := Bk, D := ÀúA‚àí1
k , which yields
by (1.87) that the matrix Sk is invertible. For (1.89) we set A := I, B :=
ÀúAkBk,
C := QT
k , D := Sk, and then (1.87) yields the invertibility of Vk with the inverse
V ‚àí1
k
= Tk. For (1.90) we set A := Sk, B := QT
k , C := ÀúAkBk, D := I, and then by
(1.87), we obtain the invertibility of Rk.
Suppose now that condition (i) holds. Then (1.88) yields that Sk is invertible,
so that condition (ii) holds. Next, assuming (ii), we have from (1.89) that Vk is
invertible, i.e., condition (iii) holds. Finally, if we assume (iii), then (1.90) implies
Rk invertible, and then in turn (1.89) yields the invertibility of Tk. Therefore,
condition (i) holds, which completes the proof.
‚äì‚äî
Corollary 1.37 Assume that the matrices ÀúAk, Sk, Tk, Vk are deÔ¨Åned in (1.83) and
(1.85).
(i) Assume that Rk is invertible. Then Tk is invertible if and only if Sk is invertible.
In this case the matrix Vk is also invertible and V ‚àí1
k
= Tk.
(ii) Assume that Sk is invertible. Then Vk is invertible if and only if Rk is invertible.
In this case the matrix Tk is also invertible and T ‚àí1
k
= Vk.
Note that the invertibility of the matrix Sk alone (without assuming the invertibil-
ity of Rk) in general does not imply the invertibility of Vk or Rk.
Proof of Theorem 1.34 Let the triple (Œ∑, v, q) with Œ∑ = {Œ∑k}N+1
k=0 , v = {vk}N
k=0,
q = {qk}N+1
k=0 solve the Jacobi system (1.75) and (1.82). We solve equation (1.75)
for Œ∑k+1 to get Œ∑k+1 = ÀúAkAkŒ∑k + ÀúAkBkvk. We insert this expression into the second
equation in (1.82), which we solve for vk. Then we get vk = S‚àí1
k (BT
k qk‚àíQT
k ÀúAkŒ∑k).
Substituting this into the Ô¨Årst equation in (1.82) and into the above formula for Œ∑k+1,
we obtain that the pair (Œ∑, q) solve the equations Œ∑k+1 = AkŒ∑k + Bkqk and qk+1 =
CkŒ∑k + Dkqk, whose coefÔ¨Åcients are given by (1.86). Upon verifying condition
(1.145) from Sect. 1.6.1 below, we show that the coefÔ¨Åcient matrix Sk of this system
is indeed symplectic. Since Rk is symmetric, from the deÔ¨Ånition of Sk in (1.83), we
have
Sk ‚àíQT
k ÀúAkBk = Rk = ST
k ‚àíBT
k ÀúAT
k Qk.
(1.91)
By using the deÔ¨Ånition of Vk in (1.85), it follows that the matrices
CT
k Ak = ÀúAT
k (V T
k Pk ‚àíQkST ‚àí1
k
QT
k ) Vk ÀúAk
(1.91)
=
ÀúAT
k V T
k PkVk ÀúAk ‚àíÀúAT
k QkST ‚àí1
k
RkS‚àí1
k QT
k ÀúAk,
DT
k Bk = [BkST ‚àí1
k
(QT
k + BT
k ÀúAT
k Pk) + I ‚àíAk] ÀúAkBkS‚àí1
k BT
k
(1.91)
=
BkST ‚àí1
k
(Sk + ST
k ‚àíRk + BT
k ÀúAT
k Pk ÀúAkBk) S‚àí1
k BT
k

1.4
Symplectic Structure of Phase Flow in Hamiltonian Mechanics
35
are symmetric and that
AT
k Dk ‚àíCT
k Bk = ÀúAT
k V T
k [(Qk + Pk ÀúAkBk) S‚àí1
k BT
k + ÀúAT ‚àí1
k
]
‚àíÀúAT
k (V T
k Pk ‚àíQkST ‚àí1
k
QT
k ) ÀúAkBkS‚àí1
k BT
k
= ÀúAT
k (I ‚àíQkST ‚àí1
k
BT
k ÀúAT
k ) (QkS‚àí1
k BT
k + ÀúAT ‚àí1
k
)
+ ÀúAT
k QkST ‚àí1
k
QT
k ÀúAkBkS‚àí1
k BT
k
= I + ÀúAT
k QkST ‚àí1
k
(ST
k ‚àíBT
k ÀúAT
k Qk + QT
k ÀúAkBk ‚àíSk) S‚àí1
k BT
k
(1.91)
=
I.
Therefore, by (1.145) the matrix Sk in Theorem 1.34 with the block entries in (1.86)
is indeed a symplectic matrix. This shows that the Jacobi system (1.75) and (1.82)
is a symplectic difference system (SDS), in which yk := (Œ∑T
k , qT
k )T . Moreover, this
symplectic difference system is a Hamiltonian system (1.63) if and only if the matrix
Ak is invertible for all k ‚àà[0, N]Z, i.e., if and only if the matrix Vk (or equivalently
Rk by Corollary 1.37) is invertible for all k ‚àà[0, N]Z. The proof is complete.
‚äì‚äî
Remark 1.38 Similarly to Remark 1.30, we may consider an alternative discrete
optimal control problem, in which the dynamics f and the Lagrangian L have no
shift in the state variable, i.e., they are evaluated at (k, xk, uk). Such a problem
leads to a dual Jacobi system, where there is no shift in Œ∑k, but the adjoint variable
appears with the shift as pk+1 (and hence also as qk+1). More precisely, the resulting
equations in the discrete weak Pontryagin principle have the form
‚àípk = AT
k pk+1 + Œª0 ÀÜL
T
x (k),
k ‚àà[0, N]Z,
(1.92)
BT
k pk+1 + Œª0 ÀÜL
T
u (k) = 0,
k ‚àà[0, N]Z,
(1.93)
compare with equations (1.79) and (1.80) in Theorem 1.32. Here the matrices Ak
and Bk are given by the formulas
Ak := f x(k, ÀÜxk, ÀÜuk),
Bk := f u(k, ÀÜxk, ÀÜuk).
(1.94)
Similarly to Theorem 1.34, the associated Jacobi system also has the symplectic
structure. More details in this direction can be found in the paper [303].
1.4
Symplectic Structure of Phase Flow in Hamiltonian
Mechanics
The attention concentrated to linear symplectic systems as well as to simple models
of discrete Hamiltonian mechanics was initiated in the paper [8] of C. D. Ahlbrandt.
This paper was devoted to basic equations of discrete Lagrangian and Hamiltonian

36
1
Motivation and Preliminaries
mechanics and to Ô¨Årst applications of the discrete oscillation theory in the discrete
calculus of variations. Ahlbrandt also formulated some open problems in oscilla-
tion theory associated with this topic. The fundamental theorem of the classical
Hamiltonian mechanics states that the evolution of a Hamiltonian system in time is
a symplectic transformation. From this point of view, every Hamiltonian system has
the symplectic structure; see [27].
Let us consider a system consisting of l-mass points with masses mi and
coordinates ri = (xi, yi, zi), i = 1, . . . , l. Suppose that the potential energy of
the system is determined by the function U(r1, . . . , rl), then the evolution of the
system in the potential Ô¨Åeld is described by the Newton equations of motion (see
[27, Section 10])
d
dt (mi Àôri) + ‚àÇU
‚àÇri
= 0,
i = 1, . . ., l,
(1.95)
together with associated initial conditions ri(t0) = r0
i and Àôri(t0) = Àôr0
i for i ‚àà
{1, . . ., l}. According to the principle of least action, equation of motion (1.95) of
a given mechanical system complies with extremals of the functional
(r) =
 t1
t0
L(t, q, Àôq) dt,
where L = T ‚àíU and T = 1
2
l
i=1 mi(Àôx2
i + Àôy2
i + Àôz2
i ) is the kinetic energy of the
system. Extremals of this functional are given by its Euler-Lagrange equation
d
dt
‚àÇL
‚àÇÀôq

‚àí‚àÇL
‚àÇq = 0,
(1.96)
where q = (q1, . . . , qn) are the generalized coordinates, Àôq = (Àôq1, . . . , Àôqn) are the
generalized velocities, n := 3l, and
L(t, q, Àôq) = T ‚àíU = 1
2
n

i=1
mi Àôq2
i ‚àíU(q1, . . . , qn)
is the Lagrangian of the system. Under the strict convexity assumption on the
Lagrangian with respect to the vector variable Àôq, i.e., that the matrix of second
derivatives
‚àÇ2L
‚àÇÀôqi‚àÇÀôqj , i, j ‚àà{1, . . . , n}, is positive deÔ¨Ånite, it is known (see, e.g., [27,
pg. 65]) that (1.96) is equivalent with the system of 2n Ô¨Årst-order equations
Àôq = ‚àÇH
‚àÇp ,
Àôp = ‚àí‚àÇH
‚àÇq ,
(1.97)

1.4
Symplectic Structure of Phase Flow in Hamiltonian Mechanics
37
where the Hamiltonian H(t, p, q) is the Legendre (sometimes also called Fenchel
or conjugate) transformation of the Lagrange function with respect to Àôq, i.e.,
H(t, p, q) = sup
Àôq

p Àôq ‚àíL(t, q, Àôq)

,
where p Àôq is the scalar product of p and Àôq. Introducing the variable y =
p
q

‚ààR2n,
system (1.97) can be written in the form
Àôy = J ‚àÇH
‚àÇy (t, y).
(1.98)
In particular, if the Hamiltonian is quadratic with
H(y, t) = 1
2 yT H(t) y,
H(t) = HT (t),
then system (1.98) takes the form of the linear Hamiltonian differential system
y‚Ä≤ = J H(t) y,
H(t) =
‚àíC(t) AT (t)
A(t)
B(t)

,
H(t) = HT (t).
(1.99)
Recall (see [147, Chapter 4]) that the transformation Àúy = R(t, y) of solutions of
system (1.98) is called canonical if the transformation carries Hamiltonian system
(1.98) again into a Hamiltonian system
ÀôÀúy = J ‚àÇÀúH
‚àÇÀúy (t, Àúy).
(1.100)
The importance of studying canonical transformations is due to the fact that these
transformations permit replacing the Hamiltonian system (1.98) by another Hamil-
tonian system (1.100), in which the Hamiltonian ÀúH is of a simpler structure than
H. If in a phase space we perform successively two canonical transformations, then
the resulting transformation will again be canonical. Furthermore, a transformation
that is inverse to a certain canonical transformation will always be canonical, and the
identical transformation is again canonical. Therefore, all canonical transformations
taken together form a group.
Next we recall two basic statements from the Hamiltonian mechanics (see [27,
147]).
Theorem 1.39 For a certain transformation Àúy = R(t, y) to be canonical, it
is necessary and sufÔ¨Åcient that the Jacobian matrix S corresponding to this
transformation is a generalized-symplectic matrix with constant valence c, i.e.,
STJ S = cJ , c Ã∏= 0.

38
1
Motivation and Preliminaries
In particular, in the case of a univalent transformation with c = 1, the matrix S
is a symplectic matrix. Then, the condition of the symplectic nature of (1.98) must
hold identically relative to all the variables t, q, p.
If in addition R(t, y) is linear, i.e., R(t, y) = S(t)y, then in a given basis in R2n
this mapping can be identiÔ¨Åed with its matrix S(t).
For system (1.100) consider the evolution operator gt
H mapping each point y ‚àà
R2n regarded as the initial value y := y(0) to the point y(t) = gt
H (y(0)) on the
corresponding trajectory through y. This operator is called the Hamiltonian phase
Ô¨Çow of (1.100). We have the following basic property of the Hamiltonian phase Ô¨Çow
(see [147, p.139] and [27]).
Theorem 1.40 A transformation of phase space (from the variables y(0) to the
variables y(t)) carried out by the Hamiltonian phase Ô¨Çow
!
gt
H
"
of (1.100) is
canonical and univalent, and its Jacobian matrix is symplectic.
Basic properties of symplectic matrices will be recalled in Sect. 1.6.1, in particu-
lar, symplectic matrices form a group with respect to the matrix multiplication. This
group of 2n-dimensional symplectic matrices is usually denoted by Sp(2n).
In the particular case when H(y) =
1
2 yT Hy is autonomous, i.e., the matrix
H is constant in t, the phase Ô¨Çow can be expressed in the form y(t) = gt
H y(0),
where gt
H = exp(J H t), and the phase Ô¨Çow exp(J H t) is a symplectic matrix
for every t. In other words, the inÔ¨Ånitesimal generator of a symplectic Ô¨Çow is the
matrix J H with symmetric H. The matrix A := J H is called a Hamiltonian matrix
in the literature, as the Hamiltonian matrices of order 2n are deÔ¨Åned by the property
ATJ + J A = 0.
The study of the symplectic structure of the phase Ô¨Çow of a discrete Hamiltonian
system
qk = ‚àÇH(k, qk+1, pk)
‚àÇp
,
pk = ‚àí‚àÇH(k, qk+1, pk)
‚àÇq
,
(1.101)
where pk, qk ‚ààRn, was motivated by the investigation of discrete models of
various mechanical systems (see [145, 162] and the comprehensive references given
therein) and also by the construction of symplectic algorithms in the Hamiltonian
mechanics (see [141, 163, 164, 232] and the references therein). In particular, the
central difference scheme
yk = J hHz
yk+1 + yk
2

for the autonomous system in (1.98) is symplectic (see [140, 141, 163]). The
symplectic structure of the phase Ô¨Çow for the discrete linear Hamiltonian system
xk
uk

= J Hk
xk+1
uk

,
Hk = HT
k ,
(1.102)

1.4
Symplectic Structure of Phase Flow in Hamiltonian Mechanics
39
with
Hk =
‚àíCk AT
k
Ak
Bk

,
det (I ‚àíAk) Ã∏= 0,
was investigated under the assumption that Bk > 0 (i.e., Bk is positive deÔ¨Ånite) in
[134‚Äì137]. The proof of the symplecticity of the discrete Ô¨Çow follows easily from
the fact that system (1.102) can be written as symplectic system (see Sect. 2.1.2).
The following theorem concerning symplectic structure of the phase Ô¨Çow of
(1.101) was proved in [263, Theorem 2.1]; see also [8, Theorem 3] and [13,
Theorem 11].
Theorem 1.41 Let the Hamiltonian H(t, q, p) be twice continuously differentiable
with respect to p, q ‚ààRn and
det

I ‚àí
 ‚àÇ2H
‚àÇq‚àÇp

Ã∏= 0
in some domain D ‚äÜR2n. Then the phase Ô¨Çow (f k, gk) : R2n ‚ÜíR2n of (1.101),
written in the form
qk+1 = f (k, qk, pk),
pk+1 = g(k, qk, pk),
where
(f k+1, gk+1)(p, q) := (f, g)(k, (f k, gk)(p, q)),
f k0, gk0(p, q) := (p, q)
for some Ô¨Åxed k0, is a discrete one-parametric group of symplectic transformations.
Observe that one of the important consequences of the existence of the sym-
plectic structure of the phase Ô¨Çow of continuous and discrete Hamiltonian systems
(1.98) and (1.101) is the volume-preserving property of a bounded domain of
the phase space R2n (see [27, Liouville theorem, pg. 69], [263, Theorem 2.2]).
Concerning autonomous system (1.98), also the energy-preserving law (see [27,
pg. 207]) is satisÔ¨Åed, which says that the Hamiltonian H(p(t), q(t)) is constant
along the solutions p(t), q(t) of (1.98) (i.e., the Hamiltonian H is the Ô¨Årst integral of
system (1.98)). However, for autonomous discrete system (1.101), this energy law is
no longer satisÔ¨Åed in general; see [8, Example 4]. Various examples of conservative
and nonconservative symplectic difference schemes for (1.98) can be found in [163,
Chap. II.16].

40
1
Motivation and Preliminaries
1.5
Linear Hamiltonian Differential Systems
Linear Hamiltonian differential systems (LHS) represent a natural continuous
counterpart of symplectic difference systems (SDS), in the sense that they are
the most general Ô¨Årst-order linear differential systems, whose fundamental matrix
(i.e., the phase Ô¨Çow) is symplectic, whenever it has this property at an initial
condition. The purpose of this section is to present some basic results from the
oscillation theory of linear Hamiltonian differential systems (LHS), which will be
later compared with corresponding results for the symplectic difference systems
(SDS). In order to keep the content clear and compact, the results in this section are
presented without the proofs. For a comprehensive treatment of linear Hamiltonian
differential systems, we refer to the books [70, 203, 205, 248, 250].
1.5.1
Basic Properties of Solutions of Hamiltonian Systems
In this section we consider the self-adjoint linear differential system (1.99), i.e.,
y‚Ä≤ = J H(t) y,
J =
 0 I
‚àíI 0

, H(t) =
‚àíC(t) AT (t)
A(t)
B(t)

,
(1.103)
with H(t)
=
HT (t)
‚àà
R2n√ó2n. Sometimes it is suitable to write (1.103)
componentwise, i.e., we split y =
x
u

with x, u ‚ààRn, and then (1.103) can be
written as
x‚Ä≤ = A(t) x + B(t) u,
u‚Ä≤ = C(t) x ‚àíAT (t) u.
(1.104)
When referring to the Hamiltonian system (1.104), we always assume that the real
n √ó n matrices A(t), B(t), C(t) are piecewise continuous on the interval I (by
I we always denote a nondegenerate interval of the real line which may be open,
closed, or half-open) although integrability on I would sufÔ¨Åce for most results. We
will start with the notion of a conjoined basis of system (1.104). A 2n √ó n matrix
solution Y =
X
U

is said to be the conjoined basis if
Y T (t) J Y(t) = XT (t) U(t) ‚àíUT (t) X(t) = 0,
rank
X(t)
U(t)

= n.
(1.105)
An alternative terminology for solutions satisfying the Ô¨Årst condition in (1.105) is
an isotropic solution [70] or a prepared solution [168].
Bases, which are not conjoined, play in the oscillation theory of (1.103) a similar
‚Äúdestroying‚Äù role as the complex solutions in the oscillation theory of the Sturm-
Liouville differential equation (being a special case of system (1.103))

r(t)x‚Ä≤‚Ä≤ + p(t)x = 0.
(1.106)

1.5
Linear Hamiltonian Differential Systems
41
More precisely, the function x(t) = eit is a never vanishing solution of the
oscillatory equation x‚Ä≤‚Ä≤ + x = 0, i.e., it ‚Äúviolates‚Äù the Sturmian theory of (1.106).
In the higher dimension, we consider the Hamiltonian system consisting of two
‚Äúcopies‚Äù of the differential equation x‚Ä≤‚Ä≤ + x = 0, i.e.,
x1
x2
‚Ä≤‚Ä≤
+
x1
x2

= 0,
which is ‚Äúevidently‚Äù oscillatory, as the determinant of the X-component of the
conjoined basis
X(t) =
sin t
0
0
cos t

,
U(t) =
cos t
0
0
‚àísin t

oscillates; see the deÔ¨Ånition of the (non)oscillation of (1.103) given below. But at
the same time,
X(t) =
 cos t
sin t
‚àísin t cos t

,
U(t) =
‚àísin t
cos t
‚àícos t ‚àísin t

(1.107)
is a 2n √ó n matrix solution, whose Ô¨Årst component is everywhere nonsingular. Note
that Y =
X
U

in (1.107) is not a conjoined solution, as can be veriÔ¨Åed by a direct
computation.
Other particular cases of linear Hamiltonian systems (1.103) include the 2n-order
Sturm-Liouville differential equation
n

k=0
(‚àí1)krk(t) x(k)(k) = 0,
rn(t) > 0,
(1.108)
and the Jacobi matrix differential equation

R(t) x‚Ä≤ + QT (t) x
‚Ä≤ = Q(t) x‚Ä≤ + P(t) x
(1.109)
with symmetric R(t) and P(t) and positive deÔ¨Ånite R(t); see, e.g.,[250]. Equation
(1.108) can be written as (1.103) with
A(t) ‚â°(Ai,j)n
i,j=1 =

1
if j = i + 1,
0
otherwise,
B(t) = diag

0, . . . , 0,
1
rn(t)
 
and
C(t) = diag{r0(t), . . . , rn‚àí1(t)}.

42
1
Motivation and Preliminaries
Concerning equation (1.109), substituting u = R(t) x‚Ä≤ + QT (t) x we obtain system
(1.103) with
A(t) = ‚àíR‚àí1(t) QT (t),
B(t) = R‚àí1(t),
C(t) = P(t) ‚àíQ(t) R‚àí1(t) QT (t).
If Y = X
U
 and ÀúY =  ÀúX
ÀúU
 are 2n √ó n (not necessarily conjoined) solutions of
(1.103), then we have the Wronskian identity
Y T (t) J ÀúY(t) = XT (t) ÀúU(t) ‚àíUT (t) ÀúX(t) ‚â°M,
(1.110)
where M ‚ààRn√ón is a constant matrix. Every conjoined basis of (1.103) can
be completed to a fundamental symplectic matrix of this system. To show this,
let Y =
X
U

be a conjoined basis (1.103) and let ÀúY =
 ÀúX
ÀúU

to be a solution
of (1.103) given by the initial condition ÀúY(t0) = ‚àíJ Y(t0) K‚àí1, where K :=
Y T (t0) Y(t0). Then by a direct computation, one can verify that Z(t) := (Y(t) ÀúY(t))
is a symplectic fundamental matrix of (1.103), because it is symplectic at t = t0 (see
Lemma 1.58(v)). From this point of view, any conjoined basis of (1.103) generates
a one half of the solution space of (1.103).
Throughout this section we suppose that system (1.103) is identically normal
on an interval I (an alternative terminology is completely controllable), i.e., if
a solution z =
x
u

of (1.103) satisÔ¨Åes x(t) ‚â°0 on a nondegenerate subinterval
of I, then u(t) ‚â°0 for t ‚ààI as well. Note that there is a recent theory of focal
points for linear Hamiltonian differential systems (1.103) without the assumption
of identical normality; see [127, 129, 130, 201, 207, 283, 285‚Äì289, 291, 295, 321],
but for our motivation, it is suitable to consider identically normal systems. We
also suppose throughout this section (without mentioning it later) that the so-called
Legendre condition is satisÔ¨Åed
the matrix B(t) is nonnegative deÔ¨Ånite for t ‚ààI
(1.111)
In the matrix notation introduced in Sect. 1.6 below, the Legendre condition is
written as B(t) ‚â•0. Next we introduce the concept of a focal point of a conjoined
basis of (1.103).
DeÔ¨Ånition 1.42 Suppose that (1.103) is identically normal and the Legendre
condition (1.111) holds on I. We say that a conjoined basis Y =
X
U

has a focal
point at t0 ‚ààI if det X(t0) = 0. Its multiplicity is then deÔ¨Åned as
m(t0) = def X(t0) = dim Ker X(t0) = n ‚àírankX(t0),
(1.112)
where Ker is the kernel of the indicated matrix.

1.5
Linear Hamiltonian Differential Systems
43
Note that this deÔ¨Ånition implies that the focal points of conjoined bases of (1.103)
are isolated. Moreover, under assumption (1.111) system (1.103) is completely
controllable on I if and only if the focal points of Y(t) are isolated in I (see [205,
Theorem 4.1.3]). Based on this property, we introduce the notion of an oscillatory
conjoined basis of (1.103) at ‚àû.
DeÔ¨Ånition 1.43 A conjoined basis Y(t) of (1.103) is called oscillatory at ‚àûif
lim
b‚Üí‚àûP(Y, a, b) = lim
b‚Üí‚àû

t‚àà(a,b)
m(t) = ‚àû,
(1.113)
where P(Y, a, b) is the total number of focal points in (a, b). In opposite case Y(t)
is called nonoscillatory at ‚àû.
Let us recall Ô¨Årst some results of the Sturmian theory for conjoined bases of
a completely controllable linear Hamiltonian differential systems; see [250]. We
note that all focal points are counted including their multiplicities.
Theorem 1.44 (Sturmian Separation Theorem) Let Y = X
U
 and ÀÜY =  ÀÜX
ÀÜU
 be
conjoined bases of linear Hamiltonian differential system (1.103). Then the numbers
of their focal points in an interval I ‚äÇR differ by at most n. In particular if Ya =
Xa
Ua
 and Yb = Xb
Ub
 are the conjoined bases of (1.103) given by the initial conditions
Xa(a) = 0, Ua(a) = I and Xb(b) = 0, Ub(b) = ‚àíI, then the number of focal
points of Ya in the interval (a, b] is the same as the number of focal point of Yb in
the interval [a, b).
In particular, Theorem 1.44 implies that the existence of a (non)oscillatory
conjoined basis of (1.103) at ‚àûis equivalent to the property that all conjoined bases
of this system are (non)oscillatory at ‚àû. In this case we say that system (1.103) is
(non)oscillatory at ‚àû.
We have also Sturmian comparison theorem for a completely controllable system
(1.103), which reads as follows.
Theorem 1.45 Along with (1.103) consider another system of the same form
y‚Ä≤ = J ÀúH(t) y
(1.114)
and suppose that this system is minorant to (1.103), i.e., H(t) ‚â•ÀúH(t) for t ‚àà[a, b].
Let Ya =
Xa
Ua

and ÀúY =
 ÀúXa
ÀúXb

be the solutions of (1.103) and (1.114), respectively,
given by the initial condition Ya(a) = 0
I
 = ÀúYa(a). If ÀúYa has m ‚ààN focal points in
the interval (a, b], then Ya has at least m focal points in this interval.

44
1
Motivation and Preliminaries
1.5.2
Symplectic Transformations
Let R(t) be a symplectic matrix with differentiable entries in some interval I ‚äÜR.
Consider the transformation
y = R(t) w.
(1.115)
Then w is a solution of the system
w‚Ä≤ = J ÀÜH(t) w,
ÀÜH(t) := J R‚àí1(t) [R‚Ä≤(t) ‚àíJ H(t) R(t)].
(1.116)
We claim that system (1.116) is again a linear Hamiltonian system. Indeed, we
need to prove that the matrix
ÀÜH(t) is symmetric. By Lemma 1.58(ii) we note
that R‚àí1(t) = ‚àíJ RT (t) J , since R(t) is symplectic. Moreover, (suppressing the
argument t in the calculations below)
(RT )‚Ä≤J R + RT J R‚Ä≤ = 0
i.e.,
J R‚àí1R‚Ä≤ = ‚àí(RT )‚Ä≤ RT ‚àí1J .
This implies that the matrix J R‚àí1R‚Ä≤ is symmetric. Moreover,
J R‚àí1J HR = RT J J HR = ‚àíRT HR
is also symmetric, which yields that ÀÜH is symmetric.
In the oscillation theory of linear Hamiltonian differential systems, an important
role is played by the lower block-triangular symplectic transformations. Thus, we
consider the matrix R in the form
R =
H
0
G H T ‚àí1

(1.117)
with H T G = GT H. Then the block entries of the matrix ÀÜH in (1.116) are
ÀÜA = H ‚àí1(‚àíH ‚Ä≤ + AH + BG),
ÀÜB = H ‚àí1BH T ‚àí1,
(1.118)
ÀÜC = ‚àíGT (‚àíH ‚Ä≤ + AH + BG) + H T (‚àíG‚Ä≤ + CH ‚àíAT G)
as can be veriÔ¨Åed by a direct computation.
Remark 1.46 Recall that for any Hamiltonian system (1.103), there exist a block
diagonal transformation matrix
R(t) =
H(t)
0
0
H T ‚àí1(t)

(1.119)

1.5
Linear Hamiltonian Differential Systems
45
which transforms (1.103) into (1.116) with
ÀÜA(t) ‚â°0. Indeed, it is sufÔ¨Åcient to
assume that H(t) is a fundamental matrix of the differential system
H ‚Ä≤ = A(t) H,
(1.120)
then according to (1.118), we have ÀÜA(t) ‚â°0.
Suppose that Y =
X
U

is a conjoined basis of (1.103) with X(t) invertible for
t ‚ààI ‚äÜR and consider the (symplectic) transformation matrix
R(t) =
X(t)
0
U(t) XT ‚àí1(t)

.
Then ÀÜA(t) = 0, ÀÜB(t) = X‚àí1(t) B(t) XT ‚àí1(t), and ÀÜC(t) = 0, i.e., the resulting
system for w =
w1
w2

, w1, w2 ‚ààRn, has the form
w‚Ä≤
1 = X‚àí1(t) B(t) XT ‚àí1(t) w2,
w‚Ä≤
2 = 0.
If we replace vectors w1, w2 by n √ó n matrices W1, W2, we get a solution
W2(t) = M,
W1(t) =
 t
a
X‚àí1(s) B(s) XT ‚àí1(s) ds M + N,
a ‚ààI,
(1.121)
where M, N are constant n√ón matrices. Substituting t = a, we see that this solution
is a conjoined basis if and only if MT N = NT M and rank
M
N

= n. If we denote
S(t) :=
& t
a X‚àí1(s) B(s) XT ‚àí1(s) ds in (1.121) and we take M = I and N = 0,
then substituting into the transformation formula ÀúY =
 ÀúX
ÀúU

= R(t)
W1
W2

we see by
a direct computation that
ÀúX(t) = X(t) S(t),
ÀúU(t) = U(t) S(t) + XT ‚àí1(t)
(1.122)
is a conjoined basis of (1.103). Moreover, we have Y TJ ÀúY = XT ÀúU ‚àíUT ÀúX = I, so
that Z = (Y, ÀúY) is a symplectic fundamental matrix of (1.103).
1.5.3
Riccati Equation and Reid Roundabout Theorem
Suppose that Y =
X
U

is a conjoined basis of (1.103) with X(t) invertible in some
interval I ‚äÜR. Then Q = UX‚àí1 is a symmetric solution of the Riccati matrix
differential equation
Q‚Ä≤ ‚àíC(t) + AT (t) Q + QA(t) + QB(t) Q = 0.
(1.123)

46
1
Motivation and Preliminaries
Another important object associated with (1.103) is its quadratic energy func-
tional. We say that a pair of functions x(t), u(t) for t ‚àà[a, b] is admissible for the
quadratic functional
F(x, u) =
 b
a

uT (t) B(t) u(t) + xT (t) C(t) x(t)

dt
(1.124)
if x and u satisfy x‚Ä≤(t) = A(t) x(t) + B(t) u(t) on I, i.e., the Ô¨Årst equation in the
Hamiltonian system (1.103). This equation is again called the equation of motion
or the admissibility equation. For an admissible pair y = (x, u) such that u is
differentiable, we then have
F(y) =
 b
a

uT (x‚Ä≤ ‚àíAx) + xT Cx

(t) dt
=
 b
a

uT x‚Ä≤ + (uT )‚Ä≤x ‚àíxT u‚Ä≤ ‚àíuTAx + xT Cx

(t) dt
= xT u
			
b
a +
 b
a

xT (‚àíu‚Ä≤ ‚àíAT u + Cx)(t) dt.
Consequently, if y satisÔ¨Åes also second equation in (1.103), called the Euler-
Lagrange equation, then we have F(y) = xT (t) u(t)
		b
a.
Now we show how (1.124) transforms under lower block-triangular symplectic
transformation with transformation matrix given in (1.117). Substituting (1.118)
into the admissibility equation for the quadratic functional associated with the
transformed system, we see by a short computation that
w1
w2

= R‚àí1(t)
x
u

is
admissible for this functional, i.e., w‚Ä≤
1(t) = ÀÜA(t) w1(t) + ÀÜB(t) w2(t), where ÀÜA(t)
and ÀÜB(t) are given by (1.118). Further, again substituting ÀÜA(t), ÀÜB(t), ÀÜC(t) from
(1.118) and using that w1 = H ‚àí1(t) x and w2 = ‚àíGT (t) x + H T (t) u, we derive
the identity
wT
2 ÀÜB(t) w2 + wT
1 ÀÜC(t) w1 ‚àí(wT
1 w2)‚Ä≤ = uT B(t) u + xT C(t) x ‚àí(xT u)‚Ä≤,
which upon integration yields the transformation formula
 b
a
[uT Bu + xT Cx](t) dt = (wT
1 GT Hw1)(t)
			
b
a +
 b
a
[wT
2 ÀÜBw2 + wT
1 ÀÜCw1](t) dt.
If the transformation matrix is R(t) =

I
0
Q(t) I

, where Q(t) is a symmetric solution
of Riccati equation (1.123), then ÀÜA = A + BQ, ÀÜB = B, ÀÜC = 0, and we obtain the
so-called Picone identity
F(x, u) = xT (t) Q(t) x(t)
			
b
a +
 b
a

(u ‚àíQx)T B(u ‚àíQx)

(t) dt.
(1.125)

1.5
Linear Hamiltonian Differential Systems
47
In particular, this means that F(x, u) > 0 for admissible x, u with x(a) = 0 = x(b)
and x(t) Ã∏‚â°0, t ‚àà[a, b], whenever there exists a conjoined basis Y =
X
U

with X(t)
invertible for t ‚àà[a, b].
The previous considerations are summarized in the next statement, the so-
called Reid roundabout theorem for completely controllable linear Hamiltonian
differential systems (1.103), see [250, Theorem V.6.3]. We recall that we assume
the standing hypothesis (1.111) about the matrix B(t).
Theorem 1.47 The following statements are equivalent.
(i) System (1.103) is disconjugate on [a, b], i.e., the solution Y =
X
U

of (1.103)
given by the initial condition X(a) = 0, U(a) = I has no focal point in (a, b],
i.e., it satisÔ¨Åes det X(t) Ã∏= 0 for t ‚àà(a, b].
(ii) There exists a conjoined basis Y =
X
U

of (1.103) with X(t) invertible for
t ‚àà[a, b].
(iii) Riccati equation (1.123) has a symmetric solution Q(t) deÔ¨Åned in the whole
interval [a, b].
(iv) The quadratic functional F is positive deÔ¨Ånite, i.e., F(x, u) > 0 for every
admissible y = (x, u) with x(a) = 0 = x(b) and x(t) Ã∏‚â°0 for t ‚àà[a, b].
(v) The Riccati inequality
Q‚Ä≤ ‚àíC(t) + AT (t) Q + QA(t) + QB(t) Q ‚â§0,
t ‚àà[a, b],
(1.126)
has a symmetric solution Q(t) deÔ¨Åned in the whole interval [a, b].
The following classical result (see [205, Theorem 5.1.2]) concerning solvability
and inequalities for solutions of Riccati equation (1.123) play an important role in
the consideration of their discrete analogs in Chap. 4.
Theorem 1.48 (Riccati Inequality) With the linear Hamiltonian system (1.103),
consider another linear Hamiltonian system
ÀÜy‚Ä≤ = J ÀÜH(t) ÀÜy,
ÀÜH(t) =

‚àíÀÜC(t) ÀÜAT (t)
ÀÜA(t)
ÀÜB(t)

,
ÀÜH(t) = ÀÜHT (t),
t ‚ààI
(1.127)
with the piecewise continuous blocks ÀÜA(t), ÀÜB(t), ÀÜC(t) for t ‚ààI = [a, b). Suppose
that system (1.127) is controllable on I,
ÀÜB(t) ‚â•0 for t
‚ààI, and for the
Hamiltonians H(t) and ÀÜH(t), the majorant condition
H(t) ‚àíÀÜH(t) ‚â•0,
t ‚àà[a, b)
(1.128)
holds, where A ‚â•0 means that the symmetric matrix A is nonnegative deÔ¨Ånite.
Consider conjoined bases Y =
X
U

and ÀÜY =
 ÀÜX
ÀÜU

of systems (1.103) and (1.127)
and assume that the initial values Y(a) and ÀÜY(a) obey the conditions
ÀÜXT (a) ÀÜU(a) ‚â•DT XT (a) U(a) D

48
1
Motivation and Preliminaries
for some matrix D such that ÀÜX(a) = X(a) D. Assume that Y does not have focal
points in (a, b) and Q(t) = QT (t) = U(t) X‚àí1(t) solves (1.123) on (a, b). Then
the solution ÀÜQ(t) = ÀÜQT (t) of
ÀÜQ‚Ä≤ ‚àíÀÜC(t) + ÀÜAT (t) ÀÜQ + ÀÜQ ÀÜA(t) + ÀÜQ ÀÜB(t) ÀÜQ = 0,
where ÀÜQ(t) = ÀÜU(t) ÀÜX‚àí1(t) exists on (a, b) and
ÀÜQ(t) ‚â•Q(t),
t ‚àà(a, b).
Note that when formulating Theorem 1.48, we do not assume that det X(a) Ã∏=
0 in the initial point t = a. One of the principal tools we use in the proofs of
our results in oscillation theory of symplectic difference systems is the notion of
a comparative index of conjoined bases; see Sect. 3.1. The following statement,
proved in [205, Theorem 7.3.1], can be regarded as a continuous analog of the most
important results of the comparative index theory.
Theorem 1.49 Let Y
=
X
U

and ÀÜY
=
 ÀÜX
ÀÜU

be conjoined bases of systems
(1.103) and (1.127) under the majorant condition (1.128), and system (1.127) is
controllable. Then for the numbers P(Y, a, b) and P( ÀÜY , a, b) of focal points in
(a, b) of Y(t) and ÀÜY(t), we have
P( ÀÜY , a, b) ‚àíP(Y, a, b) ‚â§ind [Q(b‚àí) ‚àíÀÜQ(b‚àí)] ‚àíind [Q(a+) ‚àíÀÜQ(a+)],
P( ÀÜY , a, b) ‚àíP(Y, a, b) ‚â§ind [ ÀÜQ(a+) ‚àíQ(a+)] ‚àíind [ ÀÜQ(b‚àí) ‚àíQ(b‚àí)],
(1.129)
where Q(t) = U(t) X‚àí1(t) and ÀÜQ(t) = ÀÜU(t) ÀÜX‚àí1(t) and ind denotes the index,
i.e., the number of negative eigenvalues of a symmetric matrix.
For a symmetric matrix valued function M(t), the notation ind M(t+
0 ) and
ind M(t‚àí
0 ) mean the right-hand and left-hand limits of the piecewise constant
quantity ind M(t) for t ‚Üít+
0 and t ‚Üít‚àí
0 .
According to [205, Theorem 7.3.1], inequalities (1.129) turn into equalities for
H(t) ‚â°ÀÜH(t), and then we derive from Theorem 1.49 the following separation result
(see [205, Theorem 5.2.1]).
Theorem 1.50 Let Y and ÀÜY be conjoined bases of a controllable linear Hamil-
tonian system (1.103) with condition (1.111). DeÔ¨Åne Q(t) := U(t)X(t)‚àí1 and
ÀÜQ(t) := ÀÜU(t) ÀÜX(t)‚àí1. Then for all t ‚àà(a, b), we have
m(t) ‚àíÀÜm(t) = ind [Q(t‚àí) ‚àíÀÜQ(t‚àí)] ‚àíind [Q(t+) ‚àíÀÜQ(t+)],
m(t) ‚àíÀÜm(t) = ind [ ÀÜQ(t+) ‚àíQ(t+)] ‚àíind [ ÀÜQ(t‚àí) ‚àíQ(t‚àí)],
(1.130)

1.5
Linear Hamiltonian Differential Systems
49
where m(t) and ÀÜm(t) are the multiplicities of focal points of Y and ÀÜY given by
(1.112). Moreover, instead of inequalities (1.129), we have
P( ÀÜY , a, b) ‚àíP(Y, a, b) = ind [Q(b‚àí) ‚àíÀÜQ(b‚àí)] ‚àíind [Q(a+) ‚àíÀÜQ(a+)],
P( ÀÜY , a, b) ‚àíP(Y, a, b) = ind [ ÀÜQ(a+) ‚àíQ(a+)] ‚àíind [ ÀÜQ(b‚àí) ‚àíQ(b‚àí)].
(1.131)
As a direct consequence of Theorem 1.50, we derive the estimate
|P( ÀÜY , a, b) ‚àíP(Y, a, b)| ‚â§n,
(1.132)
which holds for any conjoined bases Y and ÀÜY of (1.103). In particular, Theorem 1.50
implies the Ô¨Årst statement of Theorem 1.44.
Next we have a look at the difference between positivity and nonnegativity of
(1.124). As we have shown, positivity is equivalent to disconjugacy of (1.103) in
the closed interval [a, b]. A slightly modiÔ¨Åed considerations prior to Theorem 1.47
show that a necessary and sufÔ¨Åcient condition for the nonnegativity of the functional
F in (1.124) over admissible pairs y =
x
u

and the Dirichlet boundary conditions at
a and b is invertibility of X(t) in the open interval (a, b). Here the system (1.103)
is again assumed to be identically normal, and Y =
X
U

is the conjoined basis of
(1.103) given by X(a) = 0 and U(a) = I as in Theorem 1.47. Hence, the difference
between the positivity and nonnegativity of F is just in the possible noninvertibility
of X(b). We have mentioned this topic because later we will show that conditions for
the positivity or nonnegativity of quadratic functionals associated with symplectic
difference systems considerably differ.
Finally, we note that the concept of disconjugacy of (1.103) can be equivalently
deÔ¨Åned using the concept of conjugate points of vector solutions of (1.103). We say
that two points t1 < t2 are conjugate relative to (1.103) if there exists a solution
y =
x
u

‚ààR2n such that x(t1) = 0 = x(t2) and x(t) Ã∏‚â°0 for t ‚àà(t1, t2). Now,
we can deÔ¨Åne the disconjugacy of system (1.103) in [a, b] (equivalently to item (i)
of Theorem 1.47) as follows. System (1.103) is disconjugate on [a, b] if there is no
solution of this system with two or more conjugate points in [a, b].
1.5.4
Trigonometric and Pr√ºfer Transformations
The trigonometric transformation (an alternative terminology is the Bohl transfor-
mation) and the Pr√ºfer transformation for classical Sturm-Liouville equation (1.106)
present formulas, where either a pair of linearly independent solutions (for the case
of the trigonometric transformation) or a solution and its quasiderivative (for the
case of the Pr√ºfer transformation) are expressed via the sine and cosine functions.

50
1
Motivation and Preliminaries
To formulate a similar result for Hamiltonian systems, we need the concept of
trigonometric Hamiltonian system. Consider the special Hamiltonian system
S‚Ä≤ = Q(t) C,
C‚Ä≤ = ‚àíQ(t) S
(1.133)
with symmetric and nonnegative deÔ¨Ånite coefÔ¨Åcient matrix Q(t) ‚ààRn√ón. This
system is called a trigonometric system (see [32, 245]), and its solution are the
sine and cosine matrices. This terminology is motivated by the fact that in the
scalar case n = 1, the functions S(t) = sin ‚à´t Q(s) ds, C(t) = cos ‚à´t Q(s) ds
are solutions of (1.133). Also, if S
C
 is a conjoined basis of (1.133), then  C
‚àíS
 is
a conjoined basis of this system as well. Moreover, if the initial condition (say at
t = a) is such that the matrix Z =

C(a) ‚àíS(a)
S(a) C(a)

is orthogonal (i.e., ZT Z = I, e.g.,
S(a) = 0, C(a) = I), then this matrix is orthogonal everywhere, and we have the
‚Äútrigonometric‚Äù identities
ST (t) S(t) + CT (t) C(t) = I = S(t) ST (t) + C(t) CT (t),
(1.134)
ST (t) C(t) = CT (t) S(t),
S(t) CT (t) = C(t) ST (t).
In this subsection we will denote the block entries of H by the calligraphic letters
A, B, C, since the letter C will be reserved for the cosine matrix function.
Theorem 1.51 (Matrix Pr√ºfer Transformation) Let Y =
X
U

be a conjoined
basis of (1.103). There exist a nonsingular matrix H(t) and a symmetric matrix
Q(t) on I such that
X(t) = ST (t) H(t),
U(t) = CT (t) H(t),
(1.135)
where S
C
 is a conjoined basis of (1.133) with
Q(t) =
ST (t)
CT (t)
T
H(t)
ST (t)
CT (t)

and H(t) solves the Ô¨Årst-order differential system
H ‚Ä≤ =
ST (t)
CT (t)
T
J H(t)
ST (t)
CT (t)

H.
Recall that the ‚Äúangular‚Äù equation in the Pr√ºfer transformation for (1.106) (x =
œÅ sin œï, rx‚Ä≤ = œÅ cos œï) is
œï‚Ä≤ =
1
r(t) cos2 œï + p(t) sin2 œï =
sin œï
cos œï
T p(t)
0
0
1/r(t)
 sin œï
cos œï

.

1.5
Linear Hamiltonian Differential Systems
51
Therefore, Q plays the role of œï‚Ä≤ when (1.103) is rewritten Sturm-Liouville equation
(1.106). This is in a good agreement with the fact that S(t) = sin ‚à´t Q(s) ds and
C(t) = cos ‚à´t Q(s) ds is a solution of (1.133) in this scalar case.
The trigonometric (Bohl) transformation expresses a normalized pair of con-
joined bases via trigonometric matrices; see [77]. Recall that conjoined bases
Y =
X
U

, ÀúY =
 ÀúX
ÀúU

form a normalized pair of conjoined bases if Y TJ ÀúY =
XT ÀúU ‚àíUT ÀúX = I.
Theorem 1.52 Let Y =
X
U

and ÀúY =
 ÀúX
ÀúU

be a pair of normalized conjoined
bases of (1.103). There exist continuously differentiable n√ón matrix functions H(t)
and G(t) such that H T (t) G(t) = GT (t) H(t) and the transformation (1.115) with
R(t) given by (1.117) transforms system (1.103) into (1.133). In particular, the Ô¨Årst
components of Y, ÀúY can be expressed as X(t) = H(t) S(t) and ÀúX(t) = H(t) C(t).
Moreover, the matrices H(t) and G(t) are given by the formulas (suppressing the
argument t)
HH T = XXT + ÀúX ÀúXT ,
G = (UXT + ÀúU ÀúXT ) H T ‚àí1,
and the matrix Q(t) in (1.133) is given by the formula
Q(t) = H ‚àí1(t) B(t) H T ‚àí1(t).
Next we show some applications of this transformation in oscillation theory
of differential Hamiltonian systems. It is known (see [250]) that an eventually
controllable trigonometric differential system (1.133) is oscillatory if and only if
 ‚àû
TrQ(s) ds = ‚àû,
(1.136)
where Tr denotes the trace, i.e., the sum of the diagonal elements of a matrix.
Combining this result with the transformation given in Theorem 1.52, we have the
following oscillation criterion for (1.103).
Theorem 1.53 Suppose that B(t) is nonnegative deÔ¨Ånite for large t, system (1.103)
is eventually controllable,
& ‚àûTr B(s) ds = ‚àû, and there exists a constant M such
that eventually ‚à•X(t)‚à•‚â§M for any conjoined basis (X, U) of (1.103). Then system
(1.103) is oscillatory.
1.5.5
Principal and Nonprincipal Solutions
Recall that we suppose throughout this section that (1.103) is identically normal. In
this subsection we suppose that this assumption is satisÔ¨Åed in an interval of the form
[t0, ‚àû). We also suppose that system (1.103) is nonoscillatory, i.e., this system is

52
1
Motivation and Preliminaries
disconjugate on [t0, ‚àû) if t0 is sufÔ¨Åciently large. These assumptions imply that X(t)
is invertible for large t for any conjoined basis Y =
X
U

of (1.103).
A conjoined basis ÀúY =
 ÀúX
ÀúU

of (1.103) is said to be a principal solution (at ‚àû) if
lim
t‚Üí‚àûX‚àí1(t) ÀúX(t) = 0
(1.137)
for any conjoined basis Y =
X
U

such that the (constant) matrix
Y T (t) J ÀúY(t) = XT (t) ÀúU(t) ‚àíUT (t) ÀúX(t)
is nonsingular.
(1.138)
Any conjoined basis Y satisfying (1.138) is then said to be a nonprincipal solution
of (1.103) (at ‚àû); an alternative terminology is an antiprincipal solution (at ‚àû).
Principal and nonprincipal solutions of Hamiltonian systems can be characterized
equivalently as conjoined bases whose Ô¨Årst component satisÔ¨Åes
lim
t‚Üí‚àû
 t
t0
X‚àí1(s) B(s) XT ‚àí1(s) ds
‚àí1
= 0
(1.139)
for the principal solution, while
lim
t‚Üí‚àû
 t
t0
X‚àí1(s) B(s) XT ‚àí1(s) ds
‚àí1
= T,
where T is an invertible matrix, for the nonprincipal solution. A principal solution
of a nonoscillatory and identically normal system (1.103) is unique up to a constant
right nonsingular multiple (see Theorem 1.54 below).
Theorem 1.54 The principal solution of (1.103) exists whenever this system is
nonoscillatory and eventually identically normal. This solution is unique up to
a right multiplication by a constant invertible n √ó n matrix.
Another equivalent characterization of the principal solution of (1.123) is via the
associated Riccati matrix equation. A conjoined basis  ÀúX
ÀúU
 is the principal solution
if and only if ÀúQ = ÀúU ÀúX‚àí1 is the eventually minimal solution of (1.123) in the sense
that for any other symmetric solution Q of this equation, we have Q(t) ‚â•ÀúQ(t).
The largest focal point of the principal solution at ‚àû, if any, has the following
extremal property; see [105].
Theorem 1.55 Let T be the largest focal point of the principal solution ÀúY =  ÀúX
ÀúU
 of
(1.103) at ‚àû. Then any other conjoined basis Y =
X
U

has a focal point in [T, ‚àû).
More precisely, denote by ÀúP(T ) and P(T ) the number of focal points in [T, ‚àû) of
ÀúY and of Y (including multiplicities), respectively. Then
P(T ) ‚â•ÀúP(T ).

1.6
Linear Algebra and Matrix Analysis
53
1.5.6
Nonlinear Dependence on Spectral Parameter
In this Ô¨Ånal subsection, we consider linear Hamiltonian systems with generally
nonlinear dependence on a spectral parameter. The presented results are taken from
the book [205]. We consider the linear Hamiltonian system
y‚Ä≤ = J H(t, Œª) y,
H(t, Œª) =
‚àíC(t, Œª) AT (t, Œª)
A(t, Œª)
B(t, Œª)

,
(1.140)
on the interval [a, b] with symmetric H(t, Œª) and the Dirichlet boundary conditions
x(a) = 0 = x(b).
(1.141)
We suppose that the matrices A, B, C are piecewise continuous with respect to t
on [a, b], that system (1.140) is identically normal, and that the Legendre condition
B(t) ‚â•0 for t ‚àà[a, b] holds. Furthermore, we suppose the following.
(i) For every t ‚àà[a, b] the Hamiltonian H(t, Œª) is nondecreasing on R with
respect to the spectral parameter Œª, i.e., H(t, Œª1) ‚â§H(t, Œª2) for Œª1 < Œª2.
(ii) System (1.140) is strictly normal, i.e., if y(t, Œª) is a solution of (1.140) on [a, b]
for two different values Œª1 and Œª2 of the spectral parameter, then y(t, Œªi) ‚â°0
for t ‚àà[a, b] and i ‚àà{1, 2}.
(iii) There exists Œª0 such that for all Œª ‚â§Œª0 the associated quadratic functional is
positive deÔ¨Ånite, i.e.,
F(y, Œª) =
 b
a
[xT (t) C(t, Œª) x(t) + uT (t) B(t, Œª) u(t)] dt > 0
for all admissible y = (x, u) with x(a) = 0 = x(b) and x(t) Ã∏‚â°0 on [a, b].
Note that these assumptions imply that focal points of any conjoined basis of system
(1.140) are isolated (this we have already recalled earlier) and also that the spectrum
of (1.140), (1.141) is discrete and bounded below. The following statement, which
can be found in [205, Theorem 7.2.1], we will partially ‚Äúdiscretize‚Äù in the later parts
of the book.
Theorem 1.56 (Global Oscillation Theorem) Let the above assumptions be sat-
isÔ¨Åed. Then the number of eigenvalues of (1.140), (1.141), which are less than or
equal to a given value Œª ‚ààR, is equal to the number of focal points in (a, b] of the
solution Y(t, Œª) of (1.140) satisfying Y(a, Œª) = (0 I)T .

54
1
Motivation and Preliminaries
1.6
Linear Algebra and Matrix Analysis
In this section we present basic notions and results from linear algebra needed for
our treatment. Naturally, we concentrate on symplectic matrices but also on the
Moore-Penrose pseudoinverse matrices, which play important role in the discrete
oscillation theory. We also discuss some results related to the LU factorization for
symplectic matrices.
We use a standard matrix notation. The transpose and inverse of a matrix M
are denoted by MT and M‚àí1. Instead of (MT )‚àí1 we will write MT ‚àí1. By M‚àówe
denote the conjugate transpose of M, i.e., M‚àó= (M)T , where M is the matrix,
whose entries are complex conjugate of entries of M. Similarly as above, the
notation M‚àó‚àí1 means (M‚àó)‚àí1. If M is a symmetric matrix, then the inequalities
M > 0, M ‚â•0, M < 0, M ‚â§0 mean that M is positive deÔ¨Ånite, positive
semideÔ¨Ånite, negative deÔ¨Ånite, and negative semideÔ¨Ånite, respectively. If M and N
are symmetric matrices, then the inequalities M > N, M ‚â•N, M < N, M ‚â§N
mean that M ‚àíN > 0, M ‚àíN ‚â•0, M ‚àíN < 0, M ‚àíN ‚â§0. By ind M we
denote the index of M, i.e., the number of negative eigenvalues of M (including the
algebraic multiplicities of the eigenvalues).
If M is an m √ó n matrix with real entries, we will write M ‚ààRm√ón. By Ker M
and Im M, we denote the kernel and image of M, i.e.,
Ker M = {c ‚ààRn : Mc = 0},
Im M = {d ‚ààRm : ‚àÉc ‚ààRn with d = Ac}.
By def M and rank M, we denote the defect and the rank of M, i.e., the dimension of
Ker M and Im M, respectively. If M ‚ààRn√ón, then def M = n ‚àírank M. Moreover,
for any matrices M and N of suitable dimensions, we have the formula
rank(MN) = rank N ‚àídim (Ker M ‚à©Im N).
(1.142)
If M(t) is a matrix valued function, then we will use the notation
rank M(t¬±
0 ),
ind M(t¬±
0 ),
defM(t¬±
0 )
for the right-hand and left-hand limits at the point t0 of the piecewise constant
quantities rankM(t), ind M(t), def M(t). In agreement with the above, the notation
Œº(Y1(t¬±
0 ), Y2(t¬±
0 )) involving the comparative index (see Sect. 3.1.1) means the one-
sided limits of the piecewise constant quantity Œº(Y1(t), Y2(t)). In a similar way, we
will use the notation Ker M(t¬±
0 ) for the constant subspace Ker M(t) in the right and
left neighborhoods of t0.
If a1, . . . , an ‚ààR, we denote by diag{a1, . . . , an} the diagonal matrix A =
{Aij}n
i,j=1 with Aij = 0 for i Ã∏= j and Aii = ai for i = 1, . . . , n. A similar notation
will be used for block diagonal matrices. If some additional matrix notation will be
used only in a particular place in this book, we will explain it at that place where it
is used.

1.6
Linear Algebra and Matrix Analysis
55
In Sect. 1.6.2 we will recall the concept of the Moore-Penrose generalized inverse
(or the pseudoinverse) of a matrix M. This will be denoted by M‚Ä†.
We will also use a standard notation for matrix groups. By GL(n) we denote
the group of invertible n √ó n matrices with real entries; O(n) denotes the group
of n √ó n orthogonal matrices, i.e., square matrices M with MT = M‚àí1. Finally,
Sp(2n) denotes the group of 2n√ó2n symplectic matrices, whose deÔ¨Ånition is given
below in Sect. 1.6.1.
1.6.1
Symplectic Matrices
In this subsection we provide the deÔ¨Ånition and basic properties of symplectic
matrices, which are of course fundamental for the theory of symplectic difference
systems.
DeÔ¨Ånition 1.57 A real 2n √ó 2n matrix S is symplectic, we write S ‚ààSp(2n), if
STJ S = J ,
J =
 0 I
‚àíI 0

.
(1.143)
In (1.143), the matrix I is the n√ón identity matrix. The matrix J is the canonical
skew-symmetric 2n √ó 2n matrix, and of course J is symplectic, i.e., J ‚ààSp(2n)
with J ‚àí1 = J T = ‚àíJ . If we write the matrix S in the block form
S =
A B
C D

(1.144)
with n √ó n matrices A, B, C, D, then substituting into (1.143), we get the identities
AT D ‚àíCT B = I,
AT C = CT A,
BT D = DT B.
(1.145)
The following lemma summarizes basic properties of symplectic matrices.
Lemma 1.58 Symplectic matrices have the following properties.
(i) The product of two symplectic matrices is also a symplectic matrix, i.e., if
S1, S2 ‚ààSp(2n), then also the product S1S2 ‚ààSp(2n).
(ii) Every symplectic matrix is invertible with determinant equal to 1, and the
inverse of a symplectic matrix is also symplectic, i.e., for S ‚ààSp(2n) we
have det S = 1 and S‚àí1 ‚ààSp(2n). In the block notation (1.144), this means
that
S‚àí1 = J T ST J =
 DT ‚àíBT
‚àíCT
AT

.

56
1
Motivation and Preliminaries
(iii) The transpose of a symplectic matrix is also symplectic, i.e., for S ‚ààSp(2n),
we have ST ‚ààSp(2n). This means in terms of the blocks of S that
BAT = ABT ,
CDT = DCT ,
ADT ‚àíBCT = I.
(1.146)
(iv) If P is a matrix such that P TJ P = J T , then S ‚ààSp(2n) if and only if
PSP ‚àí1 ‚ààSp(2n).
(v) If S = (Y
ÀúY) with 2n √ó n matrices Y and ÀúY, then S ‚ààSp(2n) if and only if
Y and ÀúY satisfy
Y TJ Y = 0,
ÀúY TJ ÀúY = 0,
rank Y = n = rank ÀúY
(1.147)
and
w(Y, ÀúY ) := Y TJ ÀúY = I.
(1.148)
(vi) If a 2n √ó n matrix Y =
X
U

satisÔ¨Åes conditions in (1.147), then there exist
symplectic matrices Z and ÀúZ such that Z =

ÀÜX X
ÀÜU U

and ÀúZ =

X ÀúX
U ÀúU

, i.e.,
i.e., Z
0
I

= Y and ÀúZ
I
0

= Y.
(vii) If the 2n √ó n matrix Y satisÔ¨Åes (1.147), then we have
Ker Y T = Im(J Y).
(1.149)
If M ‚ààRn√ón is invertible, and S ‚ààSp(2n), then the matrix S YM also
satisÔ¨Åes (1.147).
(viii) For any 2n √ó n matrix Y =
X
U

satisfying (1.147) there exists œÉ ‚ààR such
that
det(X + œÉ U) Ã∏= 0.
(1.150)
Proof The properties (i)‚Äì(iii) and (vii) are well-known properties of symplectic
matrices which are proved, e.g., in [74, 205, 328, 332]. To prove the property (iv),
we use the deÔ¨Ånition of the group Sp(2n) and the arguments
S ‚ààSp(2n) ‚áê‚áíST J S = J ‚áê‚áíST J T S = J T
‚áê‚áíST P T J PS = P T J P ‚áê‚áíP T ‚àí1ST P T J PSP ‚àí1 = J
‚áê‚áíPSP ‚àí1 ‚ààSp(2n).
The property (v) follows from the deÔ¨Ånition of Sp(2n) and property (ii). The proof
of the property (vi) can be found in [205, Corollary 3.3.9]. To construct the matrix
Z, we set K := (Y T Y)‚àí1 = (XT X + UT U)‚àí1. The matrix K is invertible because

1.6
Linear Algebra and Matrix Analysis
57
of the rank condition in (1.147). Then
Z =
 UK X
‚àíXK U

,
ÀúZ =
X ‚àíUK
U
XK

.
The matrices Z and ÀúZ are really symplectic in view of property (v).
The proof of (viii) about the existence of œÉ such that (1.150) holds, which we
present here, can be found in [1, pg. 41] or [205, Lemma 3.3.1, pg. 86]. Consider
the polynomial q(œÉ) = det(X + œÉU), œÉ ‚ààC. Then for the choice of œÉ = i, the
matrix (X + iU)‚àó(X + iU) = XT X + UT U is nonsingular in view of the third
condition in (1.147). This implies that q(œÉ) Ã∏‚â°0 and q(œÉ) = 0 only for a Ô¨Ånite
number of its roots. Hence there exists œÉ ‚ààR such that (1.150) holds.
‚äì‚äî
Particular cases of the matrix P from (iv) of the previous lemma which will be
used later in this book are
P1 =
0 I
I 0

,
P2 = diag{I, ‚àíI},
P3 = diag{‚àíI, I}.
(1.151)
None of these matrices is symplectic, but they satisfy the assumptions of property
(iv), as one can easily verify.
Examples of symplectic matrices, which we will frequently use in this book, are
the lower block-triangular matrix
L =
H
0
G H T ‚àí1

,
H T G = GT H,
with H invertible,
(1.152)
and its special case (unit lower block-triangular matrix)
L =
 I 0
Q I

,
with Q symmetric.
(1.153)
Analogically, given (1.152) or (1.153), then the matrices
R1 =
H
G
0 H T ‚àí1

,
R2 =
I Q
0 I

(1.154)
are also symplectic (unit upper block triangular in the case of R2), as a result of
Lemma 1.58(iv) with P := P1 from (1.151).
We will also need matrices which are symplectic and orthogonal at the same
time. Recall that an invertible matrix M is orthogonal if M‚àí1 = MT . Orthogonal
matrices form a group with respect to the matrix multiplication; this group is for
matrices with dimension 2n denoted by O(2n). If S ‚ààSp(2n) ‚à©O(2n), then the

58
1
Motivation and Preliminaries
matrix S has the block form
S =
 P Q
‚àíQ P

,
(1.155)
where P and Q are n √ó n matrices satisfying
PT P + QTQ = I = PPT + QQT ,
PTQ = QT P, PQT = QPT .
(1.156)
The structure in (1.155) and the properties in (1.156) follow from the structure in
(1.144) and from (1.145) and (1.146).
Remark 1.59 If Q ‚ààRn√ón is orthogonal, then the matrix diag{Q, Q} is orthogonal
and symplectic, i.e., the matrices diag{Q, Q} and J commute.
1.6.2
Moore-Penrose Pseudoinverse
Pseudoinverse matrices play an important role in the analysis of symplectic
difference systems. A comprehensive treatment of pseudoinverse matrices can be
found, e.g., in the book [34]; further references are given in Sect. 1.7. Here we
present only the results, which we need in this book.
Let A ‚ààRm√ón. Then there exists a uniquely determined matrix B ‚ààRn√óm
satisfying the following four properties
BAB = B,
ABA = A,
BA and AB are symmetric.
(1.157)
The matrix B is called the pseudoinverse (or the Moore-Penrose generalized inverse)
of A, and it is denoted by A‚Ä†. It can be explicitly given by the formula
A‚Ä† = lim
t‚Üí0+(AT A + tI)‚àí1AT = lim
t‚Üí0+ AT (AAT + tI)‚àí1.
Remark 1.60
(i) For a matrix A ‚ààRm√ón, we have (AT )‚Ä† = (A‚Ä†)T , (A‚Ä†)‚Ä† = A, and Im A‚Ä† =
Im AT , Ker A‚Ä† = Ker AT .
(ii) If A ‚ààRm√ón and if P and Q are orthogonal matrices of suitable dimensions,
then the formula (QAP)‚Ä† = P TA‚Ä† QT holds.
(iii) If A ‚ààRm√ón, then Ker AT = Ker(AA‚Ä†).
(iv) For matrices A ‚ààRm√ón and B ‚ààRn√óp, we have Ker (AB) = Ker (A‚Ä†AB).
(v) If {Aj}‚àû
j=1 is a sequence of m √ó n matrices such that Aj ‚ÜíA for j ‚Üí‚àû,
then the limit of A‚Ä†
j as j ‚Üí‚àûexists, i.e., A‚Ä†
j ‚ÜíB for j ‚Üí‚àû, if and only
if there exists j0 ‚ààN such that rankAj = rankA for all j ‚â•j0. And in this
case B = A‚Ä†.

1.6
Linear Algebra and Matrix Analysis
59
(vi) Let A and B be symmetric and positive semideÔ¨Ånite matrices such that A ‚â§
B. Then AB‚Ä†A ‚â§A or equivalently A‚Ä†AB‚Ä†A‚Ä†A ‚â§A‚Ä†. Furthermore, the
inequality B‚Ä† ‚â§A‚Ä† is equivalent with Im A = Im B or with rank A = rank B.
(vii) For matrices A, B ‚ààRm√ón satisfying AT B = 0 and BAT = 0, we have
(A + B)‚Ä† = A‚Ä† + B‚Ä† and rank (A + B) = rankA + rank B.
The following result will also be useful in Sect. 6.3.5.
Lemma 1.61 Let {Aj}‚àû
j=1 be a sequence of matrices. Assume that
(i) Aj ‚ÜíA for j ‚Üí‚àû,
(ii) there exists an index j0 ‚ààN such that Im Aj ‚äÜIm A and Im AT
j ‚äÜIm AT for
all j ‚â•j0.
Then there exists an index j1 ‚ààN such that Im Aj = Im A and Im AT
j = Im AT for
all j ‚â•j1 and A‚Ä†
j ‚ÜíA‚Ä† for j ‚Üí‚àû.
The Moore-Penrose pseudoinverse is closely related with constructing orthogo-
nal projectors. If V is a linear subspace in Rn, then we denote by PV the n √ó n
corresponding orthogonal projector onto V .
Remark 1.62 For any A ‚ààRm√ón the matrix AA‚Ä† is the orthogonal projector
onto Im A, and the matrix A‚Ä†A is the orthogonal projector onto Im AT . Moreover,
rankA = rankAA‚Ä† = rankA‚Ä†A. In addition, for matrices A and B, we have
(AB)‚Ä† = (PIm AT B)‚Ä† (APIm B)‚Ä† = (A‚Ä†AB)‚Ä†(ABB‚Ä†)‚Ä†.
(1.158)
One of the main reasons why pseudoinverse matrices appear in oscillation
theory of discrete symplectic systems is that if V, W ‚ààRn√ón, then we have the
equivalences
Ker V ‚äÜKer W
‚áê‚áí
W = WV ‚Ä†V,
(1.159)
Im W ‚äÜIm V
‚áê‚áí
V V ‚Ä†W = W.
(1.160)
In our later treatment, we will also need the following properties of pseudoinverse
matrices. The next lemma can be found in [34, Theorem 8 and Lemma 3]. This
result also follows from the facts that the matrix XX‚Ä† is the orthogonal projector
onto Im X and the matrix X‚Ä†X is the orthogonal projector onto Im XT .
Lemma 1.63 Let X, ÀúX ‚ààRm√ón. If Im X = Im ÀúX, then XX‚Ä† = ÀúX ÀúX‚Ä†. Analogously,
if Ker X = Ker ÀúX, then X‚Ä†X = ÀúX‚Ä† ÀúX.
As a corollary to Lemma 1.63, we derive the following result which plays an
important role in the proofs of Chap. 3.
Lemma 1.64 Suppose that the square matrices X, ÀúX, A, B satisfy
ÀúX = AXB,
det A Ã∏= 0, det B Ã∏= 0.

60
1
Motivation and Preliminaries
Then
I ‚àíÀúX ÀúX‚Ä† = T (I ‚àíXX‚Ä†) A‚àí1,
I ‚àíÀúX‚Ä† ÀúX = B‚àí1(I ‚àíX‚Ä†X) ÀúT ,
(1.161)
where T and ÀúT are invertible matrices independent of B and A, respectively, such
that T = I for A = I and ÀúT = I for B = I.
Proof Suppose that the singular value decomposition (SVD, see [157, p.70]) of X
is of the form X = V UT , where  is the diagonal matrix containing the singular
values of X, and U and V are orthogonal matrices. Then
I ‚àíXX‚Ä† = V GV T ,
I ‚àíX‚Ä†X = UGUT ,
G := I ‚àíF,
F := ‚Ä†.
(1.162)
Observe that according to Lemma 1.63 applied to the particular case A = I (in this
case Im ÀúX = Im X), we have I ‚àíÀúX ÀúX‚Ä† = I ‚àíXX‚Ä†. Applying this result to the
matrices ÀúX and ÀúXB‚àí1U, we obtain
I ‚àíÀúX ÀúX‚Ä† = I ‚àí(AV ) (AV )‚Ä†
= [I ‚àí(AV ) (AV )‚Ä†] (AV F + AV G) (AV )‚àí1
= [I ‚àí(AV ) (AV )‚Ä†] AV GV T A‚àí1
= AV [I ‚àíF (AV )‚Ä†AV G] GV T A‚àí1
= T V GV T A‚àí1 = T (I ‚àíXX‚Ä†) A‚àí1,
T = AV [I ‚àíF (AV )‚Ä†AV G] V T ,
where (1.162) has been used. Observe that the matrix T is invertible, since it is
a product of the matrices A, V , and I ‚àíF (AV )‚Ä†AV G, the last matrix being
invertible by the (easily to verify) implication
PR = 0
	‚áí
(I ‚àíRUP) (I + RUP) = I
(1.163)
with P := G, R := F, U :=  (AV )‚Ä†AV . Using Remark 1.60 (ii) it is easy
to verify that T = I if A = I. Hence, the Ô¨Årst statement in (1.161) is proved.
Applying this result in computing I ‚àíÀúXT ( ÀúXT )‚Ä† = I ‚àíÀúX‚Ä† ÀúX, we obtain also the
second identity in (1.161).
‚äì‚äî
Next we consider results on solvability of the matrix equations
XT QX = XT U.
(1.164)
associated with the n √ó n blocks X, U of the matrix Y =
X
U

with conditions
(1.105).

1.6
Linear Algebra and Matrix Analysis
61
Lemma 1.65 Assume that the matrix Y ‚ààR2n√ón satisÔ¨Åes the Ô¨Årst condition in
(1.147), then equation (1.164) is solvable, and the general solution of (1.164) is of
the form
Q = XX‚Ä†UX‚Ä† + E ‚àíXX‚Ä†EXX‚Ä†,
(1.165)
where E ‚ààRn√ón is arbitrary.
Proof According to [215, Theorem 6.11] the matrix equation
A Q C = B
(1.166)
has a solution Q if and only if AA‚Ä†BC‚Ä†C = B. In this case the general solution of
(1.166) is of the form
Q = A‚Ä†BC‚Ä† + E ‚àíA‚Ä†AECC‚Ä†,
where E ‚ààRn√ón is arbitrary. Putting A := XT , C := X, B := XT U and using
(1.147), we see that the relation XT (XT )‚Ä†XT UX‚Ä†X = XT U does hold and the
general solution of (1.164) has the form (1.165).
‚äì‚äî
Remark 1.66 In the oscillation theory, we use symmetric solutions of (1.164).
Applying (1.147) we see that the Ô¨Årst addend XX‚Ä†UX‚Ä† = (X‚Ä†)T XT UX‚Ä† in (1.165)
is symmetric. Then, to construct the general symmetric solution of (1.164), we
demand the symmetry of the last addends in (1.165)
E = E ‚àíXX‚Ä†EXX‚Ä†
= XX‚Ä†E (I ‚àíXX‚Ä†) + (I ‚àíXX‚Ä†) EXX‚Ä† + (I ‚àíXX‚Ä†) E (I ‚àíXX‚Ä†)
= ET .
(1.167)
Finally, the general symmetric solution of (1.164) is of the form
Q = XX‚Ä†UX‚Ä† + E,
E = ET ,
XT EX = 0.
(1.168)
We complete this section by the following important complement of properties
(vi) and (viii) in Lemma 1.58.
Lemma 1.67 Under assumptions and the notation of Lemma 1.58(vi), there exists
œÉ ‚ààR such that the symplectic matrix Z
 I
0
œÉI I

=
 ÀÜX+œÉX X
ÀÜU+œÉU U

obeys the condition
det( ÀÜX + œÉX) Ã∏= 0. Moreover, the number œÉ ‚ààR can be chosen in such a way that
( ÀÜX + œÉX)‚àí1X ‚â•0,
(1.169)

62
1
Motivation and Preliminaries
or
( ÀÜX + œÉX)‚àí1X ‚â§0.
(1.170)
The same assertion holds for ÀúZ
 I œÉI
0 I

=

X ÀúX+œÉX
U ÀúU+œÉU

.
Proof Putting Y := ( ÀÜX X)T in (1.150) of Lemma 1.58(viii), we derive det( ÀÜXT +
œÉXT ) = det( ÀÜX + œÉX) Ã∏= 0. For the proof of (1.169) (or (1.170)), we note that this
condition is equivalent to
X( ÀÜX + œÉX)T = X(Q + œÉI)XT ‚â•0
(X(Q + œÉI)XT ‚â§0),
where Q = QT solves the matrix equation XQXT = X ÀÜXT (see Remark 1.66).
So we see that for œÉ ‚â•‚àímin1‚â§i‚â§n Œªi (or œÉ ‚â§‚àímax1‚â§i‚â§n Œªi), where Œªi for i ‚àà
{1, . . ., n} are the eigenvalues of Q, condition (1.169) (or (1.170)) holds. The proof
is complete.
‚äì‚äî
1.6.3
Symplectic Matrices and Generalized LU Factorization
In this subsection we prove some results concerning the representation of a sym-
plectic matrix in the form of a product of lower (upper) block-triangular matrices
and orthogonal symplectic matrices. Matrices in Y ‚ààR2n√ón satisfying (1.147)
frequently appear in the proofs of statements in this subsection. These matrices are
expressed in the form of a product of a lower block-triangular matrix, an orthogonal
matrix, and an invertible matrix. The results of this section play an important role in
the proofs of some properties of the comparative index introduced in Chap. 3
In the Ô¨Årst auxiliary statement, we present necessary and sufÔ¨Åcient conditions for
a matrix Y ‚ààR2n√ón to satisfy (1.147).
Lemma 1.68 A 2n √ó n matrix Y =
X
U

satisÔ¨Åes (1.147) if and only if
XX‚Ä†U(I ‚àíX‚Ä†X) = 0,
(1.171)
Q = QT ,
Q := XX‚Ä†UX‚Ä†,
(1.172)
rank[(I ‚àíXX‚Ä†) U(I ‚àíX‚Ä†X)] = rank (I ‚àíX‚Ä†X).
(1.173)
Moreover, if (1.147) holds, then we have
det L Ã∏= 0,
L := X ‚àí(I ‚àíXX‚Ä†) U(I ‚àíX‚Ä†X),
(1.174)
det M Ã∏= 0,
M := X ‚àí(I ‚àíXX‚Ä†) U.
(1.175)

1.6
Linear Algebra and Matrix Analysis
63
Proof
(i) SufÔ¨Åciency. Let (1.171)‚Äì(1.173) hold. We will show that (1.173) implies
(1.174), (1.175). In fact, using Remark 1.60(vii) we obtain
rank L = rankX + rank [(I ‚àíXX‚Ä†) U(I ‚àíX‚Ä†X)] = n,
which proves the invertibility of L in (1.174). As for the matrix M, we have
M = X ‚àí(I ‚àíXX‚Ä†) U = X ‚àí(I ‚àíXX‚Ä†) U(I ‚àíX‚Ä†X) ‚àí(I ‚àíXX‚Ä†) U(X‚Ä†X)
= [I ‚àí(I ‚àíXX‚Ä†) UX‚Ä†] L,
where the matrix I ‚àí(I ‚àíXX‚Ä†) UX‚Ä† is invertible. This conclusion follows
from (1.163) with P := X‚Ä† and R := (I ‚àíXX‚Ä†). Hence, (1.175) holds. Now
by (1.171) we have
X = XX‚Ä† M,
U = XX‚Ä†U + (I ‚àíXX‚Ä†) U = XX‚Ä†UX‚Ä†X + (I ‚àíXX‚Ä†) U
(1.176)
= [XX‚Ä†UX‚Ä† ‚àí(I ‚àíXX‚Ä†)] M.
Hence,
XT U = MT XX‚Ä†UX‚Ä† M = MT Q M.
(1.177)
Therefore, (1.172) implies that XT U = UT X, which is the same as Y TJ Y =
0. Furthermore,
Y T Y = XT X + UT U = MT [XX‚Ä† + (I ‚àíXX‚Ä†) + (XX‚Ä†UX‚Ä†)2] M
= MT (I + Q2) M.
The last matrix is invertible in view of (1.172). Indeed, Q2 = X‚Ä†T UT XX‚Ä†UX‚Ä†
‚â•0 and hence, rankY = n, which completes the sufÔ¨Åciency part of the proof.
(ii) Necessity. The condition Y TJ Y = 0, i.e., XT U = UT X, implies
(X‚Ä†)T XT U(I ‚àíX‚Ä†X) = (X‚Ä†)T UT X(I ‚àíX‚Ä†X) = 0,
which means that (1.171) holds. Further,
Q = XX‚Ä†UX‚Ä† = (X‚Ä†)T XT UX‚Ä† = (X‚Ä†)T UT XX‚Ä† = (XX‚Ä†UX‚Ä†)T = QT ,

64
1
Motivation and Preliminaries
which implies that (1.172) holds. Concerning (1.173), we have
rank(XT X + UT U) (I ‚àíX‚Ä†X) = rank(I ‚àíX‚Ä†X) = rankUT U(I ‚àíX‚Ä†X)
= rankUT (I ‚àíXX‚Ä†) U(I ‚àíX‚Ä†X)
‚â§rank(I ‚àíX‚Ä†X) U(I ‚àíX‚Ä†X) ‚â§rank(I ‚àíX‚Ä†X),
where we have used that rank Y
= n = rank(XT X + UT U) and that
for a product of matrices rank AB ‚â§min{rankA, rankB}. Thus, we proved
(1.171), and the proof is completed.
‚äì‚äî
Remark 1.69 Recall (see Remark 1.66) that if Y ‚ààR2n√ón satisÔ¨Åes (1.147), then the
matrix Q given in (1.172) is a symmetric solution of the equation
XT QX = XT U.
(1.178)
In particular, if X is invertible, then we have Q = UX‚àí1.
We mentioned at the end of Sect. 1.6.1 the matrices, which belong to Sp(2n) ‚à©
O(2n). In the results of this subsection, we will need special matrices of this class,
which are constructed as follows. Let P ‚ààRn√ón. Then P is an orthogonal projector
(i.e., P is symmetric and P 2 = P) if and only if the 2n √ó 2n matrix
NP :=

P
I ‚àíP
‚àí(I ‚àíP)
P

(1.179)
is orthogonal. In this case the matrix NP is also symplectic, i.e., it belongs to
Sp(2n) ‚à©O(2n).
In the theorem below, we will use the matrix NXX‚Ä† deÔ¨Åned in (1.179) via the
projector P := XX‚Ä†. It concerns a factorization of Y satisfying conditions (1.147)
and plays crucial role in proofs of Chap. 3.
Theorem 1.70 Let Y =
X
U

‚ààR2n√ón satisfy (1.147), the matrix NXX‚Ä† be given by
(1.179), and Q be a symmetric matrix satisfying (1.178). Then Y can be expressed
in the form
Y = L NXX‚Ä†
M
0

,
L :=
 I 0
Q I

,
det M Ã∏= 0,
(1.180)
where
M := X ‚àí(I ‚àíXX‚Ä†) (U ‚àíQX).
(1.181)

1.6
Linear Algebra and Matrix Analysis
65
Proof Observe that if a matrix Y satisÔ¨Åes (1.147), then in view of property (vii)
of Lemma 1.58, the matrix ÀúY = L‚àí1Y =

X
U‚àíQX

also satisÔ¨Åes (1.147). Then
it sufÔ¨Åces to apply Lemma 1.68 to ÀúY. Using (1.175), the matrix M in (1.181) is
invertible, X = XX‚Ä†M, and by (1.178), we get
U ‚àíQX = (I ‚àíXX‚Ä†) (U ‚àíQX) = ‚àí(I ‚àíXX‚Ä†) M.
Then ÀúY = NXX‚Ä†
M
0
, i.e., Y = L NXX‚Ä†
M
0
, what we needed to prove.
‚äì‚äî
Remark 1.71 Formula (1.180) implies the representation for the blocks X and U in
the form
X = XX‚Ä†M
(1.182)
U = [QXX‚Ä† ‚àí(I ‚àíXX‚Ä†)] M,
(1.183)
and
XT U = MT XX‚Ä†UX‚Ä†M,
(1.184)
where det M Ã∏= 0. In particular,
rankU = rankXT U + n ‚àírankX,
(1.185)
because for the matrix Q := XX‚Ä†UX‚Ä† (see Remark 1.66), we have
UM‚àí1 = XX‚Ä†UX‚Ä† ‚àí(I ‚àíXX‚Ä†)
and then it follows that
rank U = rank(XX‚Ä†UX‚Ä†) + n ‚àírankX,
rank XX‚Ä†UX‚Ä† = rankXT U.
Theorem 1.70 leads also to the following statement concerning a factorization of
symplectic matrices.
Lemma 1.72 Let Z =

X ÀúX
U ÀúU

‚ààSp(2n) and Q be a symmetric solution of (1.178).
Then the matrix Z can be expressed in the form
Z = L NXX‚Ä† diag{M, MT ‚àí1} H,
H :=
I ÀúQ
0 I

,
(1.186)
where the matrices L, M, NXX‚Ä† are given in Theorem 1.70 and
ÀúQT = ÀúQ,
ÀúQ := ÀúXT XX‚Ä†( ÀúU ‚àíQ ÀúX) ‚àí( ÀúU ‚àíQ ÀúX)T (I ‚àíXX‚Ä†) ÀúX,
(1.187)
with ÀúQ solving the equation X ÀúQXT = X ÀúXT .

66
1
Motivation and Preliminaries
Proof Using factorization (1.180) for Y =
X
U

, being the Ô¨Årst column of the matrix
Z, one can verify by a direct computations that
NT
XX‚Ä† L‚àí1Z =
M XX‚Ä† ÀúX ‚àí(I ‚àíXX‚Ä†) ( ÀúU ‚àíQ ÀúX)
0
MT ‚àí1

= diag{M, MT ‚àí1} H,
where the matrices M and H are determined by (1.181) and (1.186) and
MT ‚àí1 = (I ‚àíXX‚Ä†) ÀúX + XX‚Ä†( ÀúU ‚àíQ ÀúX).
(1.188)
Then, by (1.188), we have ÀúQ = M‚àí1[XX‚Ä† ÀúX ‚àí(I ‚àíXX‚Ä†) ( ÀúU ‚àíQ ÀúX)], i.e., (1.187)
holds. Consequently, from the last equality, we get X ÀúQ = XX‚Ä†M ÀúQ = XX‚Ä† ÀúX, so
that X ÀúQXT = X ÀúXT follows by the symmetry of ÀúXXT ; see Lemma 1.58(iii).
‚äì‚äî
Under the additional assumption regarding the invertibility of the matrix X, we
obtain the following result concerning the n √ó n block LU-factorization of a sym-
plectic matrix. This result was for the Ô¨Årst time proved in [219, Proposition 2.36].
Corollary 1.73 Consider the symplectic matrix Z =

X ÀúX
U ÀúU

with invertible matrix
X. Then the factorization in (1.186) takes the form
Z =

I
0
UX‚àí1 I
 X
0
0 XT ‚àí1
 I X‚àí1 ÀúX
0
I

.
(1.189)
The result in Corollary 1.73 justiÔ¨Åes that (1.180) and (1.189) can be called
a generalized block LU-factorization of Y and Z, respectively. Note that the
matrices L and NXX‚Ä† in these formulas generally do not commute (they commute
if a solution of (1.178) is taken in the form (1.172)).
As a consequence of Corollary 1.73 and Lemma 1.58(viii), we obtain the next
statement concerning the factorization of a symplectic matrix. The proof (different
from ours) can be found in [332, Theorem 6.2].
Theorem 1.74 Every symplectic matrix Z ‚ààSp(2n) can be expressed as the
product
Z = H1 L2 H3 = J L1 J L2 J L3 J ,
where H1 and H3 are upper block-triangular symplectic matrices and L1, L2, and
L3 are lower block-triangular symplectic matrices.
Proof Put H1 =
 I ‚àíœÉI
0
I

. Then by Lemma 1.58(viii) for Y := Z
I
0

=:
X
U

one
can choose œÉ ‚ààR such hat (1.150) holds. Hence, the matrix (I 0)H ‚àí1
1 Z
I
0

is
invertible, and by Corollary 1.73, there exists a block LU-factorization of the matrix
H ‚àí1
1 Z = L2H3. The multiplication of this equality by H1 proves the theorem.
‚äì‚äî

1.6
Linear Algebra and Matrix Analysis
67
1.6.4
Symplectic Matrices Depending on Parameter
In this section we consider symplectic matrices W(Œª) depending on a parameter
Œª ‚ààR. We assume that W(Œª) is piecewise continuously differentiable in Œª ‚ààR,
i.e., it is continuous on R with the piecewise continuous derivative. Then we can
introduce the following matrix
(W(Œª)) = ‚àíJ d
dŒª(W(Œª)) W ‚àí1(Œª) = J d
dŒª(W(Œª)) J W T (Œª) J
(1.190)
deÔ¨Åned for any piecewise continuously differentiable symplectic matrix W(Œª). The
Ô¨Årst result concerning the matrix (W(Œª)) is the following proposition.
Proposition 1.75 A matrix function W : R ‚ÜíR2n√ó2n of the real variable Œª is
symplectic for all Œª ‚ààR if and only if W(0) is symplectic and
ÀôW(Œª) = J H(Œª) W(Œª),
Œª ‚ààR,
(1.191)
with a symmetric matrix H(Œª) for all Œª ‚ààR.
Proof The proof can be found in [216, pg. 229]. First note that (1.191) is the
Hamiltonian differential system (1.103), where we replace the variable t by the
variable Œª. It is well known (see [328] or [205]) that under the assumption that
W(0) is symplectic for the fundamental matrix W(t) of (1.191), it follows that
W(Œª) ‚ààSp(2n) for Œª ‚ààR. In the opposite direction, differentiating the identity
W T (Œª)J W(Œª) = J with respect to Œª, we get
d
dŒª(W T (Œª) J W(Œª)) = 0 = ÀôW T (Œª) J W(Œª) + W T (Œª) J ÀôW(Œª),
then, multiplying the previous identity by W ‚àí1 T (Œª) from the left side and by
W ‚àí1(Œª) from the right side, we derive the desired identity
H(Œª) = J T ÀôW(Œª) W ‚àí1(Œª) = W T ‚àí1(Œª) ÀôW T (Œª) J = (W(Œª)).
(1.192)
One can now see the symmetry of H(Œª) = (W(Œª)) directly from (1.192).
‚äì‚äî
In particular, in terms of the blocks A(Œª), B(Œª), C(Œª), D(Œª) of the symplectic
matrix W(Œª) =

A(Œª) B(Œª)
C(Œª) D(Œª)

the operator (1.190) takes the form
(W(Œª)) =
 ÀôD(Œª) CT (Œª) ‚àíÀôC(Œª) DT (Œª) ÀôC(Œª) BT (Œª) ‚àíÀôD(Œª) AT (Œª)
ÀôA(Œª) DT (Œª) ‚àíÀôB(Œª) CT (Œª) ÀôB(Œª) AT (Œª) ‚àíÀôA(Œª) BT (Œª)

.
(1.193)

68
1
Motivation and Preliminaries
The proof is based on direct computations incorporating the identities
AT (Œª) C(Œª) = CT (Œª) A(Œª),
BT (Œª) D(Œª) = DT (Œª) B(Œª),
A(Œª) BT (Œª) = B(Œª) AT (Œª),
D(Œª) CT (Œª) = C(Œª) DT (Œª),
AT (Œª) D(Œª) ‚àíCT (Œª) B(Œª) = I,
D(Œª) AT (Œª) ‚àíC(Œª) BT (Œª) = I.
‚é´
‚é™‚é¨
‚é™‚é≠
which hold due to the symplecticity of W(Œª). Then upon differentiating the above
formulas with respect to Œª, we get
ÀôAT (Œª) C(Œª) + AT (Œª) ÀôC(Œª) = ÀôCT (Œª) A(Œª) + CT (Œª) ÀôA(Œª),
ÀôBT (Œª) D(Œª) + BT (Œª) ÀôD(Œª) = ÀôDT (Œª) B(Œª) + DT (Œª) ÀôB(Œª),
ÀôAT (Œª) D(Œª) + AT (Œª) ÀôD(Œª) = ÀôCT (Œª) B(Œª) + CT (Œª) ÀôB(Œª),
ÀôD(Œª) CT (Œª) + D(Œª) ÀôCT (Œª) = ÀôC(Œª) DT (Œª) + C(Œª) ÀôDT (Œª),
ÀôA(Œª) BT (Œª) + A(Œª) ÀôBT (Œª) = ÀôB(Œª) AT (Œª) + B(Œª) ÀôAT (Œª),
ÀôD(Œª) AT (Œª) + D(Œª) ÀôAT (Œª) = ÀôC(Œª) BT (Œª) + C(Œª) ÀôBT (Œª).
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(1.194)
Now we are prepared to formulate the main results of this section concerning
properties of the symmetric operator (1.190).
Proposition 1.76 The following statements hold.
(i) For arbitrary piecewise continuously differentiable symplectic matrices W(Œª)
and V (Œª), we have
(V (Œª)W(Œª)) = (V (Œª)) + V T ‚àí1(Œª) (W(Œª)) V ‚àí1(Œª).
(1.195)
(ii) If W(Œª) is piecewise continuously differentiable, then
(W ‚àí1(Œª)) = ‚àíW T (Œª) (W(Œª)) W(Œª).
(1.196)
(iii) For arbitrary constant symplectic matrices R and P, we have
(R‚àí1W(Œª)P) = RT (W(Œª)) R.
(1.197)
(iv) For arbitrary piecewise continuously differentiable symplectic matrix W(Œª)
and constant symplectic matrices R and P, we have
(W(Œª)) ‚â•0 ‚áî(R‚àí1W(Œª) P) ‚â•0 ‚áî(W ‚àí1(Œª)) ‚â§0
‚áî(W T (Œª)) ‚â§0
‚áî(W T ‚àí1(Œª)) ‚â•0.

(1.198)

1.6
Linear Algebra and Matrix Analysis
69
Proof Applying (1.192) to the product V (Œª)W(Œª), we have
(V (Œª) W(Œª)) = J T d
dŒª(V (Œª) W(Œª)) (V (Œª) W(Œª)))‚àí1
= J T ( ÀôV (Œª) W(Œª) + V (Œª) ÀôW(Œª)) W ‚àí1(Œª) V ‚àí1(Œª)
= J T ÀôV (Œª) V ‚àí1(Œª) + J T V (Œª) ÀôW(Œª) W ‚àí1(Œª) V ‚àí1(Œª)
= (V (Œª)) + V T ‚àí1(Œª) (W(Œª)) V ‚àí1(Œª),
where we used J T V (Œª) = V T ‚àí1(Œª) J T according to Lemma 1.58(ii). So we have
proved (i). For the proof of property (ii), we put V (Œª) := W ‚àí1(Œª) in property (i)
and then use that (W ‚àí1(Œª) W(Œª)) = (I) = 0. The proof of (iii) is based on the
subsequent application of property (i). So we have
((R‚àí1W(Œª)) P) = (R‚àí1W(Œª)) = RT (W(Œª))R.
Property (iv) is the direct consequence of (iii), (ii), and Lemma 1.58(ii), when
property (iii) is applied to the cases W T = J T W ‚àí1J and W T ‚àí1 = J T WJ .
‚äì‚äî
Another important consequence from Proposition 1.76 are presented by the
following lemma.
Lemma 1.77 Assume that for a piecewise continuously differentiable symplectic
matrix W(Œª), there exist constant symplectic matrices R and P such that
W(Œª) = R ÀúW(Œª) P ‚àí1, ÀúW(Œª) =
 ÀúA(Œª) ÀúB(Œª)
ÀúC(Œª) ÀúD(Œª)

, det ÀúB(Œª) Ã∏= 0, Œª ‚ààR.
(1.199)
Then we have (omitting the argument Œª)
( ÀúW) = ‚àíJ
 ÀúB 0
ÀúD I
 d
dŒª
 ÀúB‚àí1 ÀúA ‚àíÀúB‚àí1
‚àíÀúBT ‚àí1 ÀúD ÀúB‚àí1
  ÀúB 0
ÀúD I
T
J T ,
(1.200)
and then the condition
(W(Œª)) ‚â•0,
Œª ‚ààR
(1.201)
is equivalent to
d
dŒª
ÀúQ(Œª) ‚â§0,
ÀúQ(Œª) =
 ÀúB‚àí1(Œª) ÀúA(Œª)
‚àíÀúB‚àí1(Œª)
‚àíÀúBT ‚àí1(Œª)
ÀúD(Œª) ÀúB‚àí1(Œª)

,
Œª ‚ààR.
(1.202)
Proof By Proposition 1.76(iv) we see that ( ÀúW(Œª)) ‚â•0, and one can verify
by direct computations (applying Proposition 1.76(i)) that representation (1.200)

70
1
Motivation and Preliminaries
holds. Then, using the nonsingularity of ÀúB(Œª), we prove that (1.201) is equivalent
to (1.202). The proof is completed.
‚äì‚äî
In the following results, we will use Lemma 1.77 locally, i.e., in a sufÔ¨Åciently
small neighborhood of Œª0 ‚ààR. So we have the following property.
Corollary 1.78 Assume that a piecewise continuously differentiable symplectic
matrix W(Œª) =

A(Œª) B(Œª)
C(Œª) D(Œª)

obeys (1.201) and for some Œª0 ‚ààR, we have
det A(Œª0) Ã∏= 0.
(1.203)
Then there exists Œµ > 0 such that det A(Œª) Ã∏= 0 for Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ) and
d
dŒª(A‚àí1(Œª) B(Œª)) ‚â•0,
d
dŒª(C(Œª) A‚àí1(Œª)) ‚â§0,
Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ).
(1.204)
Similarly, if for some Œª0 ‚ààR
det D(Œª0) Ã∏= 0,
(1.205)
then there exists Œµ > 0 such that det D(Œª) Ã∏= 0 for Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ) and
d
dŒª(B(Œª) D‚àí1(Œª)) ‚â•0,
d
dŒª(D‚àí1(Œª) C(Œª)) ‚â§0,
Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ).
(1.206)
Proof Putting R := I and P := J in Lemma 1.77, we see that ÀúW(Œª) = W(Œª) J
has the form
ÀúW(Œª) =

‚àíB(Œª) A(Œª)
‚àíD(Œª) C(Œª)

, and then by (1.202), we derive (1.204).
Similarly, if R := J T and P = I in Lemma 1.77, then ÀúW(Œª) = J W(Œª) =

C(Œª)
D(Œª)
‚àíA(Œª) ‚àíB(Œª)

. Substituting the blocks of ÀúW(Œª) into (1.202), we derive (1.206).
‚äì‚äî
The following theorem is the most important result of this section.
Theorem 1.79 Assume that W(Œª) =

A(Œª) B(Œª)
C(Œª) D(Œª)

is piecewise continuously differ-
entiable on R and obeys assumption (1.201). Then Ker B(Œª) is piecewise constant
in Œª, i.e., for any Œª0 ‚ààR there exists Œ¥ > 0 such that
Ker B(Œª) ‚â°Ker B(Œª‚àí
0 ) ‚äÜKer B(Œª0)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(1.207)
Ker B(Œª) ‚â°Ker B(Œª+
0 ) ‚äÜKer B(Œª0)
for all Œª ‚àà(Œª0, Œª0 + Œ¥),
(1.208)

1.6
Linear Algebra and Matrix Analysis
71
Proof The proof is based on Corollary 1.78 and Lemma 1.67. Putting Z := W(Œª0)
in Lemma 1.67, we have that there exist œÉ > 0 such that for the blocks of
ÀúW := W(Œª0)
 I 0
œÉI I

=
A(Œª0) + œÉB(Œª0) B(Œª0)
C(Œª0) + œÉD(Œª0) D(Œª0)

we have det [A(Œª0) + œÉB(Œª0)] Ã∏= 0 and
(A(Œª0) + œÉB(Œª0))‚àí1B(Œª0) ‚â§0.
(1.209)
Then we apply Corollary 1.78 to the matrix ÀúW(Œª) = W(Œª)
 I
0
œÉI I

=
 ÀúA(Œª) B(Œª)
ÀúC(Œª) D(Œª)

.
Since W(Œª) obeys (1.201), i.e., (W(Œª)) ‚â•0, then the same condition holds for
ÀúW(Œª) by Proposition 1.76(iv). Moreover, the matrix ÀúW(Œª) obeys the assumption
det ÀúA(Œª0) Ã∏= 0. Applying Corollary 1.78 we see that there exist Œµ > 0 such that
ÀúA‚àí1(Œª) B(Œª) is nondecreasing matrix function for Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ). Choose
c ‚ààKer B(Œª) for some Œª ‚àà(Œª0 ‚àíŒµ, Œª0). Then the monotonicity of ÀúA‚àí1(Œª) B(Œª)
and (1.209) imply
0 = cT ÀúA‚àí1(Œª) B(Œª) c ‚â§cT ÀúA‚àí1(ŒΩ) B(ŒΩ) c ‚â§cT ÀúA‚àí1(Œª0) B(Œª0) c ‚â§0
for all ŒΩ ‚àà[Œª, Œª0]. Hence, cT ÀúA‚àí1(ŒΩ) B(ŒΩ) c = 0 and so c ‚ààKer B(ŒΩ) for every
ŒΩ ‚àà[Œª, Œª0]. Therefore, Ker B(Œª) ‚äÜKer B(ŒΩ) for all Œª, ŒΩ ‚àà(Œª0 ‚àíŒµ, Œª0] with Œª ‚â§ŒΩ.
This means that the set Ker B(Œª) is nondecreasing in Œª on (Œª0 ‚àíŒµ, Œª0]. This implies
that condition (1.207) is satisÔ¨Åed for some sufÔ¨Åciently small Œ¥ ‚àà(0, Œµ). For (1.208)
we proceed in the same way except that we choose œÉ according to Lemma 1.67 such
that
(A(Œª0) + œÉB(Œª0))‚àí1B(Œª0) ‚â•0.
(1.210)
So we have proved that Ker B(Œª) is piecewise constant in Œª ‚ààR.
‚äì‚äî
Remark 1.80 The assertions of Theorem 1.79 hold true if we replace (1.201) by the
monotonicity assumption
(W(Œª)) ‚â§0, Œª ‚ààR.
(1.211)
Indeed, in the proof of Theorem 1.79, we used Proposition 1.76(iv) and Corol-
lary 1.78, where the replacement of (1.201) by (1.211) derives the respective
replacements of all signs ‚â•and ‚â§by the opposite signs ‚â§and ‚â•. In particular, in
this case we have (see the proof of Theorem 1.79) that ÀúA‚àí1(Œª) B(Œª) is nonincreasing
matrix function for Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ). Then, under assumption (1.211) we prove
(1.208) repeating the proof of (1.207) under assumption (1.201). Similarly, we use
the proof of (1.208) under assumption (1.201) to prove (1.207) using (1.211).
Based on Remark 1.80, we prove another important fact connected with (1.201).

72
1
Motivation and Preliminaries
Theorem 1.81 Assume that W(Œª) =

A(Œª) B(Œª)
C(Œª) D(Œª)

is piecewise continuously differ-
entiable on R and obeys assumption (1.201). Then Im B(Œª) is piecewise constant in
Œª, i.e., for any Œª0 ‚ààR there exists Œ¥ > 0 such that
Im B(Œª0)‚äÜIm B(Œª) ‚â°Im B(Œª‚àí
0 )
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(1.212)
Im B(Œª0)‚äÜIm B(Œª) ‚â°Im B(Œª+
0 )
for all Œª ‚àà(Œª0, Œª0 + Œ¥).
(1.213)
Proof To prove the result, we note that (1.201) is equivalent to
(W ‚àí1(Œª)) ‚â§0,
Œª ‚ààR,
(1.214)
by Proposition 1.76(iv) and by Lemma 1.58(ii)
W ‚àí1(Œª) =
 DT (Œª) ‚àíBT (Œª)
‚àíCT (Œª) AT (Œª)

.
Then, by Remark 1.80 we can apply Theorem 1.79 to W ‚àí1(Œª) which implies that
Ker BT (Œª) is piecewise constant in Œª, i.e., for any Œª0 ‚ààR there exists Œ¥ > 0 such
that
Ker BT (Œª) ‚â°Ker BT (Œª‚àí
0 ) ‚äÜKer BT (Œª0)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(1.215)
Ker BT (Œª) ‚â°Ker BT (Œª+
0 ) ‚äÜKer BT (Œª0)
for all Œª ‚àà(Œª0, Œª0 + Œ¥).
(1.216)
Conditions (1.215), (1.216) are equivalent to (1.212), (1.213), because Ker BT (Œª) is
the orthogonal complement to Im B(Œª).
‚äì‚äî
Now we formulate several corollaries to Theorems 1.79, and 1.81.
Theorem 1.82 Assume (1.201) (or (1.211)). Then the following three conditions
are equivalent:
rank B(Œª) is constant for Œª ‚ààR,
(1.217)
Ker B(Œª) is constant for Œª ‚ààR,
(1.218)
Im B(Œª) is constant for Œª ‚ààR.
(1.219)
Proof It is clear that the constancy of Ker B(Œª) in Œª ‚ààR (or Im B(Œª) in Œª ‚ààR)
implies condition (1.217). Conversely, assume (1.217). Then, by Theorem 1.79 we
have Ker B(Œª¬±
0 ) ‚äÜKer B(Œª0), which implies Ker B(Œª¬±
0 ) = Ker B(Œª0) for any Œª0 ‚àà
R. Similarly, by Theorem 1.81, (1.217) and the inclusion Im B(Œª0) ‚äÜIm B(Œª¬±
0 )
implies the equality Im B(Œª0) = Im B(Œª¬±
0 ) for any Œª0 ‚ààR.
‚äì‚äî
Based on Theorems 1.79 and 1.81 and by Lemma 1.63, we also have the
following corollary.

1.6
Linear Algebra and Matrix Analysis
73
Corollary 1.83 Assume (1.201) (or (1.211)). Then, for any Œª0 ‚ààR there exists
Œ¥ > 0 such that the matrices B‚Ä†(Œª) B(Œª) and B(Œª) B‚Ä†(Œª) are constant for Œª ‚àà
(Œª0 ‚àíŒ¥, Œª0). A similar assertion holds also for Œª ‚àà(Œª0, Œª0 + Œ¥).
Remark 1.84 We note that by Proposition 1.76(iv), all the monotonicity properties
of (W(Œª)) formulated in Theorems 1.79, 1.81, and 1.82 and in Corollary 1.83 hold
also for (R‚àí1W(Œª) P), where R and P are constant symplectic matrices. These
properties are satisÔ¨Åed for all blocks of W(Œª) and their linear combinations.
1.6.5
Monotone Matrix-Valued Functions
In this subsection we present two useful results about the behavior of symmetric
monotone matrix-valued functions. The Ô¨Årst theorem describes the change in the
index (i.e., the number of negative eigenvalues) of a monotone matrix-valued
function when its argument crosses a singularity. This result will be utilized in
Sect. 5.1 in order to derive oscillation theorems for discrete eigenvalue problems
for symplectic difference systems.
We use a standard monotonicity deÔ¨Ånition for symmetric matrix-valued func-
tions, i.e., a matrix-valued function A
:
(0, Œµ)
‚Üí
Rn√ón is nonincreasing
(nondecreasing) on (0, Œµ), if the scalar function dT A(t) d is nonincreasing (non-
decreasing) on (0, Œµ) for every d ‚ààRn. Moreover, the notation f (0+) and f (0‚àí)
stands for the right-hand and left-hand limits of the function f (t) at t = 0.
Theorem 1.85 (Index Theorem) Let X(t), U(t), R1(t), R2(t) be given real m√óm-
matrix-valued functions on [0, Œµ) such that
R1(t) RT
2 (t) and XT (t) U(t) are symmetric,
rank(R1(t), R2(t)) = rank(XT (t), UT (t)) = m

for t ‚àà[0, Œµ),
(1.220)
and assume that X(t), U(t), R1(t), and R2(t) are continuous at 0, i.e.,
lim
t‚Üí0+ R1(t) = R1 := R1(0), lim
t‚Üí0+ X(t) = X := X(0),
lim
t‚Üí0+ R2(t) = R2 := R2(0), lim
t‚Üí0+ U(t) = U := U(0),
‚é´
‚é¨
‚é≠
(1.221)
and that X(t) is invertible for t ‚àà(0, Œµ). Moreover, denote
M(t) := R1(t) RT
2 (t) + R2(t) U(t) X‚àí1(t) RT
2 (t),
(t) := R1(t) X(t) + R2(t) U(t),
 := (0)
S(t) := X‚Ä†RT
2 (t),
S := S(0),
S‚àó(t) := RT
2 (t) ‚àíXS(t) = (I ‚àíXX‚Ä†) RT
2 (t),
S‚àó:= S‚àó(0),
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(1.222)

74
1
Motivation and Preliminaries
and suppose that the functions U(t) X‚àí1(t) and M(t) are either both nonincreasing
or both nondecreasing on (0, Œµ) and that
rankR2(t) ‚â°rankR2
and
rankS‚àó(t) ‚â°rankS‚àó=: m ‚àír
(1.223)
are constant on [0, Œµ). Finally, let T ‚ààRm√ór be such that
rankT = r, T T T = Ir√ór, Im T = Ker S‚àó, and Q := T T ST ‚ààRr√ór.
(1.224)
Then the matrix Q is symmetric, and ind M(0+), ind M(0‚àí), and def (0+) exist
with
ind M(0+) = ind Q + m ‚àírank T + def  ‚àídef (0+) ‚àídef X
(1.225)
if M(t) and U(t) X‚àí1(t) are nonincreasing on (0, Œµ) and
ind M(0+) = ind Q + m ‚àírankT
(1.226)
if M(t) and U(t) X‚àí1(t) are nondecreasing on (0, Œµ).
Proof We refer to [210, Theorem 2.1].
‚äì‚äî
The most signiÔ¨Åcant disadvantage of condition (1.223) is that it depends also on
the matrix X = X(0), which makes it ‚Äúnot really‚Äù suitable in practical applications.
The following special case of Theorem 1.85 removes this disadvantage, since the
crucial assumption is formulated only in terms of R2(t).
Corollary 1.86 (Index Theorem) With the notation (1.220)‚Äì (1.222) and the
assumptions of Theorem 1.85, suppose that
Im RT
2 (t) ‚â°Im RT
2
is constant on [0, Œµ)
(1.227)
instead of (1.223). Then the assertions (1.225) and (1.226) of Theorem 1.85 hold.
Proof If Im RT
2 (t) is constant on [0, Œµ), then (1.223) is trivially satisÔ¨Åed. The
statement then follows from Theorem 1.85. Observe that this constant image
assumption does not depend on X, while of course (1.223) depends in general on
R2(t) and also on X.
‚äì‚äî
Next we discuss a limit theorem for symmetric monotone matrix-valued func-
tions, which concerns invertible matrices.
Proposition 1.87 (Limit Theorem) Let S(t) be a real, symmetric, positive deÔ¨Ånite,
and increasing m √ó m matrix-valued function on [a, ‚àû). Then the limit X :=
limt‚Üí‚àûS‚àí1(t) exists; X is symmetric and positive semideÔ¨Ånite, and
lim
t‚Üí‚àûXS(t) X = X.
(1.228)

1.6
Linear Algebra and Matrix Analysis
75
Proof The result follows from a general Limit Theorem in [205, Theorem 3.3.7], in
which we take X(t) := S(1/t) and U(t) ‚â°I on (0, Œµ] with Œµ := 1/a (without loss
of generality, we assume that a > 0).
‚äì‚äî
We extend the above result to noninvertible matrices S(t).
Theorem 1.88 (Limit Theorem) Let S(t) be a real symmetric, positive semideÔ¨Å-
nite, and nondecreasing m √ó m matrix-valued function on the interval [a, ‚àû). Then
the limit X := limt‚Üí‚àûS‚Ä†(t) exists; X is symmetric and positive semideÔ¨Ånite, and
equality (1.228) holds.
Proof The monotonicity of S(t) implies that Ker S(t) is constant on some interval
[Œ±, ‚àû) with Œ± ‚â•a. Let ‚Ñì:= rank S(t) and k := def S(t) for t ‚àà[Œ±, ‚àû), so that
‚Ñì+k = m. Choose K ‚ààRm√ók and L ‚ààRm√ó‚Ñìsuch that Ker S(t) ‚â°Im K on [Œ±, ‚àû)
and the matrix V := (K, L) ‚ààRm√óm is orthogonal. Then for all t ‚àà[Œ±, ‚àû)
V T S(t) V =
0
0
0 ÀúS(t)

,
S(t) = V
0
0
0 ÀúS(t)

V T,
(1.229)
where the ‚Ñì√ó ‚Ñìmatrix-valued function ÀúS(t) := LT S(t) L is symmetric, positive
deÔ¨Ånite, and increasing on [Œ±, ‚àû). By Remark 1.60(ii) we get from (1.229) that
S‚Ä†(t) = V
0
0
0 ÀúS‚àí1(t)

V T,
X := V
0 0
0 ÀúX

V T,
(1.230)
where X = limt‚Üí‚àûS‚Ä†(t) and where the matrix ÀúX := limt‚Üí‚àûÀúS‚àí1(t) exists
by Proposition 1.87. Moreover, the matrices ÀúX and X are symmetric and positive
semideÔ¨Ånite, and limt‚Üí‚àûÀúX ÀúS(t) ÀúX = ÀúX holds. From (1.229) and (1.230), we get
lim
t‚Üí‚àûXS(t) X = lim
t‚Üí‚àûV
0
0
0 ÀúX ÀúS(t) ÀúX

V T = V
0 0
0 ÀúX

V T = X,
which completes the proof.
‚äì‚äî
1.6.6
Miscellaneous Topics from Matrix Analysis
In this subsection we collect various result from matrix analysis, which will be
needed in the subsequent chapters of this book. The Ô¨Årst result is a generalization
of the statement that every symmetric matrix G is a limit of a sequence of invertible
symmetric matrices GŒΩ; compare with [70, pg. 40]. In the present context, the
matrices GŒΩ are no longer invertible, but their image is equal to the image of some
Ô¨Åxed orthogonal projector.

76
1
Motivation and Preliminaries
Lemma 1.89 Let G ‚ààRn√ón be a symmetric matrix, and let Q be an orthogonal
projector with Im G ‚äÜIm Q. Then there exists a sequence {GŒΩ}‚àû
ŒΩ=1 of symmetric
matrices such that Im GŒΩ = Im Q for all ŒΩ ‚ààN and GŒΩ ‚ÜíG as ŒΩ ‚Üí‚àû.
Proof Let g := rankG and q := rankQ, so that g ‚â§q. If g = q, then Im G =
Im Q, and we may take the constant sequence GŒΩ := G for all ŒΩ ‚ààN. Suppose
now that g < q. Then there exists an orthogonal matrix V ‚ààRn√ón such that its
Ô¨Årst g columns form an orthonormal basis of Im G and at the same time its Ô¨Årst q
columns form an orthonormal basis of Im Q. This means that we have the equalities
V T GV = diag{g, 0n‚àíg} and V T Q V = diag{q, 0n‚àíq}, where g ‚ààRg√óg and
q ‚ààRq√óq are symmetric and nonsingular. Since Q is an orthogonal projector,
Q2 = Q. It follows that 2
q = q, which implies that q = Iq. Therefore, we have
G = V diag{g, 0n‚àíg}V T and Q = V diag{Iq, 0n‚àíq}V T . Consider the sequence
{GŒΩ}‚àû
ŒΩ=1 of matrices, where
GŒΩ := V
‚éõ
‚éù
g
0
0
0
1
ŒΩ Iq‚àíg
0
0
0
0n‚àíq
‚éû
‚é†V T
for all ŒΩ ‚ààN.
(1.231)
It is obvious that for each ŒΩ ‚ààN, the matrix GŒΩ is symmetric and QGŒΩ = GŒΩ. And
since rank GŒΩ = q, we have Im GŒΩ = Im Q. Moreover, from (1.231) it follows that
limŒΩ‚Üí‚àûGŒΩ = G, which completes the proof.
‚äì‚äî
Next we present some special properties of orthogonal projectors. We recall that
every orthogonal projector is a diagonalizable matrix (being symmetric) with the
spectrum consisting of only two values 0 and 1. More precisely, if P ‚ààRn√ón is
an orthogonal projector and p := rank P, then there exists an n √ó n orthogonal
matrix V such that
P = V diag{Ip, 0n‚àíp} V T .
(1.232)
Lemma 1.90 Let P‚àó‚ààRn√ón be an orthogonal projector with p‚àó:= rank P‚àó, and
let V‚àó‚ààRn√ón be the corresponding orthogonal matrix from (1.232), i.e.,
P‚àó= V‚àódiag{Ip‚àó, 0n‚àíp‚àó} V T
‚àó.
(1.233)
Let p ‚ààN satisfy p‚àó‚â§p ‚â§n. Then P ‚ààRn√ón is an orthogonal projector with
Im P‚àó‚äÜIm P
and
rankP = p
(1.234)
if and only if P has the form
P = V‚àódiag{Ip‚àó, R‚àó} V T
‚àó,
(1.235)
where R‚àó‚ààR(n‚àíp‚àó)√ó(n‚àíp‚àó) is an orthogonal projector with rank equal to p ‚àíp‚àó.

1.6
Linear Algebra and Matrix Analysis
77
Proof It is easy to see that every matrix P of the form (1.235) is symmetric
and idempotent (i.e., it is an orthogonal projector) and (1.234) holds. Conversely,
suppose that P ‚ààRn√ón is an orthogonal projector satisfying (1.234). Then we may
write
P = V‚àó
K‚àóL‚àó
LT
‚àóR‚àó

V T
‚àó,
(1.236)
where K‚àó‚ààRp‚àó√óp‚àóand R‚àó‚ààR(n‚àíp‚àó)√ó(n‚àíp‚àó) are symmetric and L‚àó‚ààRp‚àó√ó(n‚àíp‚àó).
The Ô¨Årst condition in (1.234) is equivalent with the equality PP‚àó= P‚àó, from which
we obtain by using the representations in (1.233) and (1.236) that K‚àó= Ip‚àóand
L‚àó= 0p‚àó√ó(n‚àíp‚àó). Thus, P has the form in (1.235), where rank R‚àóis equal to
rankP ‚àíp‚àó= p ‚àíp‚àóaccording to (1.234). Finally, the idempotence of P now
implies the idempotence of R‚àó, showing that R‚àóis an orthogonal projector.
‚äì‚äî
Theorem 1.91 Let P‚àó, P, ÀúP ‚ààRn√ón be orthogonal projectors satisfying
Im P‚àó‚äÜIm P,
Im P‚àó‚äÜIm ÀúP ,
rankP = rank ÀúP .
(1.237)
Then there exists an invertible matrix E ‚ààRn√ón such that
EP‚àó= P‚àó
and
Im EP = Im ÀúP .
Proof Let p‚àó:= rankP‚àóand p := rankP = rank ÀúP. Then obviously p ‚â•p‚àó.
Let V‚àó‚ààRn√ón be the orthogonal matrix in (1.232) associated with projector P‚àó,
that is, (1.233) holds. According to Lemma 1.90, there exist orthogonal projectors
R‚àó, ÀúR‚àó‚ààR(n‚àíp‚àó)√ó(n‚àíp‚àó) such that
P = V‚àódiag{Ip‚àó, R‚àó} V T
‚àó,
ÀúP = V‚àódiag{Ip‚àó, ÀúR‚àó} V T
‚àó,
(1.238)
and rank R‚àó= rank ÀúR‚àó= p ‚àíp‚àó. Let Z‚àó, ÀúZ‚àó‚ààR(n‚àíp‚àó)√ó(n‚àíp‚àó) be orthogonal
matrices in (1.232) associated with the projectors R‚àóand ÀúR‚àó, that is, we have R‚àó=
Z‚àódiag{Ip‚àíp‚àó, 0n‚àíp} ZT
‚àóand ÀúR‚àó= ÀúZ‚àódiag{Ip‚àíp‚àó, 0n‚àíp} ÀúZT
‚àó. It follows that
ÀúZ‚àóZT
‚àóR‚àó= ÀúZ‚àódiag{Ip‚àíp‚àó, 0n‚àíp} ZT
‚àó= ÀúR‚àóÀúZ‚àóZT
‚àó.
(1.239)
We set E := V‚àódiag{Ip‚àó, ÀúZ‚àóZT
‚àó} V T
‚àó
‚ààRn√ón. Then E is nonsingular and from
(1.233) it follows that EP‚àó= P‚àó. Finally, by (1.238) and (1.239), we obtain
EP = V‚àódiag{Ip‚àó, ÀúZ‚àóZT
‚àóR‚àó} V T
‚àó= V‚àódiag{Ip‚àó, ÀúR‚àóÀúZ‚àóZT
‚àó} V T
‚àó= ÀúP E,
which shows that Im EP = Im ÀúP E = Im ÀúP. The proof is complete.
‚äì‚äî

78
1
Motivation and Preliminaries
1.7
Notes and References
Concerning the oscillatory and spectral properties of Sturm-Liouville difference
equations (1.1), this topic is treated in detail in [204]. A comprehensive treat-
ment of oscillation theory of various difference equations and systems, including
an introduction to oscillation theory of symplectic difference systems, is presented
in [4]. In particular, [4, Section 2.9] contains a relevant list of references for the
oscillation theory of the second-order Sturm-Liouville difference equation (1.1).
Other monographs devoted to various aspects of linear difference equations are
[2, 110] and also the paper [169]. The Leighton-Wintner oscillation criterion
(Theorem 1.4) is based on the second mean value theorem of summation calculus
(a discrete analog of the second mean value theorem of integral calculus) proven
in [80, Lemma 3.2]. Applications of this technique were developed, e.g., in [82,
Theorem 2] and [259, Theorem 4]. The discrete Pr√ºfer transformation presented in
Sect. 1.2.4 was obtained in [47], and the oscillation theorems in Sect. 1.2.5 were
derived in [298].
The Ô¨Årst-order optimality conditions in Theorem 1.26 can be proven via the
mathematical programming approach as presented in [62, 178, 179, 223] or via the
variational approach as in [3, 177] and [16, Chapter 4]; see also the scalar case (i.e.,
n = 1) in [204, Chapter 8]. An overview of the second-order optimality conditions
for discrete calculus of variations problem (1.51), including a historical development
of these conditions, is presented in the survey paper [186]. Further necessary
and sufÔ¨Åcient conditions for discrete calculus of variations problems with variable
endpoints in terms of coupled intervals are derived in [180]. In the discrete optimal
control setting, such conditions are presented in [177‚Äì179, 184, 225‚Äì227, 330].
The symplectic structure of the Jacobi equations (1.63) and (1.69) discussed in
Theorems 1.29 and Remark 1.30 is derived in [294]; see also [303, Corollaries 5.2
and 5.8]. The discrete calculus of variations problem (1.65) without the shift in the
state variable is analyzed in [294, Section 2].
The discrete weak Pontryagin (maximum) principle in Theorem 1.32 can be
proven via the mathematical programming method (i.e., the Lagrange multipliers
rule) as presented in [178, 181, 223] or via a variational method (based on a general-
ized DuBois-Reymond lemma) as presented in [192]. These references also contain
a more general optimal control problem (1.70) involving the pointwise equality
control constraints. Problems with state inequality constraints are considered, e.g.,
in [225‚Äì227]. The symplectic structure of the Jacobi system for the discrete optimal
control problem (1.70), in which only the matrix Sk in (1.83) is invertible while Rk
may be singular, is proven in [303]. The matrix inversion formula (1.87) is from
[146]. Optimal control problems with and without a shift in the state variable are
studied in [192], where it is also shown that they can transformed one to another by
using the implicit function theorem. Symplectic difference systems were recently
applied in [331] to study constrained linear-quadratic control problems with and
without shift in their data.

1.7
Notes and References
79
The literature related to the symplectic phase Ô¨Çow in Hamiltonian mechanics is
given at particular places Sect. 1.4. Let us mention here at least the books [16, 27]
and the paper [8].
Classical qualitative theory of linear Hamiltonian differential systems (1.103)
is developed in the books [28, 70, 205, 248, 250]. The trigonometric and Pr√ºfer
transformations for linear Hamiltonian systems are discussed in [32, 77, 92, 93,
245, 247, 250]. In particular, Theorem 1.51 is the Ô¨Årst part of [247, Theorem 4.1],
while Theorems 1.52, 1.53 are proved in [77, Theorems 1, 3]. Properties of
principal and nonprincipal solutions for completely controllable system (1.103) are
proven in [6, 7, 78, 79, 246], as well as in the above general references on linear
Hamiltonian systems. An overview of applications of principal solutions of (1.103)
at inÔ¨Ånity is also presented in [283]. The oscillation and eigenvalue theory of these
systems without the complete controllability (or identical normality assumption)
was initiated in [207] and further developed in [209, 295, 296, 321]. In particular,
the theory of principal and antiprincipal solutions of possibly abnormal linear
Hamiltonian systems (1.103) is developed in [283, 285‚Äì290, 293]. Uncontrollable
systems (1.103) were also considered in [138, 200‚Äì203] in the relation with
the notion of a weak disconjugacy of (1.103) and dissipative control processes.
Applications of the theory of comparative index to linear Hamiltonian systems are
derived in [127, 129, 130, 289, 293]. A generalization of the oscillation theorem
(Theorem 1.56) for linear Hamiltonian systems (1.140) under no strict normality
assumption is proven in [57]. A theory of Riccati matrix differential equations
for linear Hamiltonian systems without the controllability assumption was recently
developed in [282].
As we mentioned in Sect. 1.6.1, properties of symplectic matrices are discussed,
e.g., in [27, 139, 216, 328, 332] and in the papers [35, 74, 75, 219, 222, 224, 326,
327]. We note that there is also a notion of a complex symplectic matrix (symplectic
matrix with complex entries), which is sometimes called a conjugate symplectic
matrix. In the complex case, some of the properties of symplectic matrices remain
the same, but some other are slightly different. We refer to the abovementioned
literature for a comparison. The theory of Moore-Penrose pseudoinverses and its
properties is presented, e.g., in the books [34, 36, 64, 205]. In particular, the
limit result for sequences of Moore-Penrose pseudoinverses in Remark 1.60(v)
is from [64, Theorem 10.4.1]. The inequality in Remark 1.60(vi) is proven in
[170, Lemma 1]; see also [36, Facts 8.15.7 and 8.15.5]. For the properties in
Remark 1.60(vii), we refer to [36, Facts 6.4.32 and 2.10.8]. The statement in
Lemma 1.61 is proven in [283, Corollary 10.5 and Lemma 10.4]; Lemma 1.64 is
derived in [113, Lemma 2.4 and Remark 2.5]. The Moore-Penrose pseudoinverses
are efÔ¨Åciently used in the relation with orthogonal projectors. Applications of
this type in symplectic difference systems are contained in the recent papers
[284, 290, 292].
The results of the auxiliary Lemma 1.67 also follow from [205, Theorem 3.1.2
and Corollary 3.3.9].
Much of matrix factorization theory comes from numerical linear algebra.
Results concerning factorization of symplectic matrices play an important role in

80
1
Motivation and Preliminaries
applications; see [35, 74, 75, 139, 219, 222, 224, 234, 239] and the references given
therein. Several special types of symplectic factorizations are highly important for
Sturmian theory of discrete symplectic systems as well. For example, the solvability
of the discrete matrix Riccati equation (2.52) is equivalent to the existence the
symplectic block LU factorization for fundamental solution matrices Zk of (SDS),
see [219]. The trigonometric transformations considered in Sect. 2.6 are based on
the symplectic block QR factorization from [63] for ZT
k , where Q is a symplectic
orthogonal matrix and R is a symplectic upper block-triangular matrix of the
form (1.154). The symplectic singular value decomposition (SVD), see [239,
Theorem 2.1], is a basic tool of the oscillation theory for discrete trigonometric
systems (2.146) in [96]. The results of Sect. 1.6.3 related to the so-called generalized
LU factorizations of symplectic matrices present another example of applications
of the factorization methods in the discrete oscillation theory.
Several statements of Lemma 1.68 were proven originally in [114, Lemma 2.1].
In particular, it was shown that the conditions in (1.147) are sufÔ¨Åcient for (1.171) and
(1.173)‚Äì(1.175). The result of Theorem 1.70 is a special case of [114, Theorem 3.1],
which is proved under more general assumptions. Consider symplectic and orthog-
onal matrices NP given by (1.179). Then [114, Theorem 3.1] states that a 2n √ó n
matrix Yk is a conjoined basis of (SDS) if and only if there exists an orthogonal
projector Pk, a lower block-triangular symplectic matrix Lk, and a nonsingular n√ón
matrix Mk such that
Yk = LkNPk
Mk
0

,
L‚àí1
k+1SkLk = NPk+1HkNT
Pk,
where Hk(I 0)T =
Mk+1M‚àí1
k
0

. In particular, the matrix Pk can be chosen in the
form Pk = I ‚àíXkX‚Ä†
k assumed in Theorem 1.70. Other special cases of the matrices
NPk are considered in [112, 113]. Also, it should be pointed out that the results of
Lemma 1.68 and Theorem 1.70 imply some special properties of matrices Y with
conditions (1.147) proved in [205]. For instance, formula (1.185) was derived for
the Ô¨Årst time in [205, Theorem 3.1.2(iii)].
The results of Sect. 1.6.4 are closely related to the oscillation theory of the
differential Hamiltonian systems (1.99) where t := Œª. This relation is illustrated
by Proposition 1.75. In this connection, a part of the results in Sect. 1.6.4 are well-
known from [205, 207], where the oscillation properties of (1.99) are investigated
under the Legendre condition (1.111). Under the notation of Sect. 1.6.4, condition
(1.111) coincides with
(0 I) (W(Œª)) (0 I)T ‚â•0.
(1.240)
Remark that (1.240) and (1.203) imply the Ô¨Årst inequality in (1.204) and then the
statements of Theorem 1.79, see the proof of [207, Theorem 3], where t := Œª
and (X(t) U(t)) := W(Œª)(0 I)T . The operator (1.190) and monotonicity condition
(1.201) for the symplectic coefÔ¨Åcient matrix Sk(Œª) were introduced by the third

1.7
Notes and References
81
author in [297] as the main basic tool for the investigation of discrete symplectic
eigenvalue problems with the nonlinear dependence on Œª. This notion is closely
related to the so-called multiplicative derivative for the matrix functions X(t)
deÔ¨Åned as DtX = X‚Ä≤(t)X‚àí1(t) (see [148, Chapter 15] and the references therein).
In Sect. 1.6.4 we unify the monotonicity results from [55, 57, 102, 205, 207, 297]
using the factorization approach; see [125, Lemma 3.3] and the proof of [125,
Lemma 4.3]. In particular, we derive that (1.201) implies also the piecewise constant
image of B(Œª) (see Theorem 1.81) and other results based on the equivalence of
(1.201) and (1.214); see the parts of Theorem 1.82 and Corollary 1.83 related to the
properties of Im B(Œª). This connection points out that the ‚Äúimage properties‚Äù can be
derived from the restricted monotonicity condition (compare also with (1.214))
(0 I) (W ‚àí1(Œª)) (0 I)T ‚â§0,
(1.241)
while the ‚Äúkernel properties‚Äù follow from (1.240).
Index theorems for monotone matrix-valued functions are often utilized in
the oscillation theory of symplectic and Hamiltonian systems; see, e.g., [205,
Section 3.4] and [297, Proposition 2.5]. In these references the index theorems are
considered with the constant matrix R2(t) ‚â°R2 on [0, Œµ). The generalized versions
in Theorem 1.85 and Corollary 1.86 with variable R2(t) are from the paper [210,
Theorem 2.1 and Corollary 2.3]. The dependence of R2(t) on t is crucial for the
applications in the oscillation theorems in Sect. 5.1. The extended limit theorem
(Theorem 1.88) and its proof were communicated to the authors by Werner Kratz in
June 2014.
The statement in Lemma 1.89 about symmetric matrices is proven in [283,
Lemma 10.2]. The results in Lemma 1.90 and Theorem 1.91 about orthogonal
projectors are from [285, Lemma 9.1 and Theorem 9.2].
We recommend the following additional related references for further reading
about the topics presented in this chapter: [5, 31, 76, 83, 199] for the Sturm-Liouville
difference equations, [30, 241, 249, 255, 336] for the Sturm-Liouville differential
equations, [65, 236, 256] for integration of Hamiltonian systems and variational
analysis, and [110, 204, 214] for general theory of difference equations.

Chapter 2
Basic Theory of Symplectic Systems
In this chapter we present basic theory of symplectic difference systems. We show
that these systems incorporate as special cases many important equations or systems,
such as the Sturm-Liouville difference equations, symmetric three-term recurrence
equations, Jacobi difference equations, linear Hamiltonian difference systems,
or trigonometric and hyperbolic systems. We investigate the deÔ¨Åniteness of the
associated discrete quadratic functional and its relationship with the nonexistence
of focal points of conjoined bases and with the solvability of the Riccati matrix
difference equation. We pay special attention to recessive and dominant solutions
of a nonoscillatory and eventually controllable symplectic systems. We study
general and special symplectic transformations, such as the trigonometric and Pr√ºfer
transformations.
2.1
Symplectic Systems and Their Particular Cases
The central concept of our book is the symplectic difference system
yk+1 = Skyk
(SDS)
where yk ‚ààR2n and the matrices Sk ‚ààR2n√ó2n are symplectic, i.e.,
ST
k J Sk = J ,
J :=
 0 I
‚àíI 0

.
If we write the matrix Sk in the block form
Sk =
Ak Bk
Ck Dk

,
(2.1)
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7_2
83

84
2
Basic Theory of Symplectic Systems
and yk as yk = xk
uk
 with xk, uk ‚ààRn, then system (SDS) can be written as
xk+1 = Akxk + Bkuk,
uk+1 = Ckxk + Dkuk.
(2.2)
In analogy with the terminology for linear Hamiltonian differential systems (see
Sect. 1.5), we call the Ô¨Årst equation in (2.2) as the equation of motion while the
second equation as the Euler-Lagrange equation.
Basic property of (SDS) is that its fundamental matrix (sometimes also called the
discrete phase Ô¨Çow) is symplectic whenever it is symplectic at an initial condition,
say at k = 0. This easily follows from the fact that we have for the fundamental
matrix Z of (SDS) the expression
Zk = Sk‚àí1Sk‚àí2 ¬∑ ¬∑ ¬∑ S1S0Z0 =
 k‚àí1
'
i=0
Sk‚àí1‚àíi

Z0,
(2.3)
since the symplectic matrices form a group with respect to the matrix multiplication
(see Lemma 1.58). Here we use the convention that the matrices under the matrix
product sign are ordered from the left to the right, i.e., the matrix staying on the left
in the product corresponds to the lower index in the product, and the matrix staying
in the right corresponds to the upper index in the product operator. Also, if the upper
index is less than the lower one, we take the product equal to the identity matrix I.
2.1.1
Conjoined Bases and Wronskian
Next we deÔ¨Åne basic concepts of the theory of symplectic systems as presented
in [45]. If Y =
X
U

and ÀÜY =
 ÀÜX
ÀÜU

are two 2n √ó n solutions of (SDS), then their
Wronskian
Y T
k J ÀÜYk = XT
k ÀÜUk ‚àíUT
k ÀÜXk ‚â°L
(2.4)
is constant with respect to k, where L is a constant n√ón matrix. We will denote this
constant matrix by w(Y, ÀÜY ).
DeÔ¨Ånition 2.1 A 2n √ó n solution Y =
X
U

of (SDS) is a conjoined basis if
w(Y, Y) = XT
k Uk ‚àíUT
k Xk = 0
and
rank Yk = n.
(2.5)
The Ô¨Årst condition in (2.5) means that the matrix XT
k Uk is symmetric. A special
case of a conjoined basis is the so-called principal solution of (SDS) at the point
k = j.

2.1
Symplectic Systems and Their Particular Cases
85
DeÔ¨Ånition 2.2 For a Ô¨Åxed index j, let Y [j] =
X[j]
U[j]

be the solution of (SDS) given
by the initial conditions X[j]
j
= 0 and U[j]
j
= I. Then this solution is said to be
the principal solution at k = j.
Remark 2.3 If condition (2.5) holds at one particular index k, then it holds for all
indices. Indeed, suppose that (2.5) holds for k = 0. Denote by K := Y T
0 Y0 and
consider the 2n √ó n solution ÀúY =  ÀúX
ÀúU
 of (SDS) given by the initial condition
ÀúY0 = ‚àíJ Y0K‚àí1. Then Zk := (Yk
ÀúYk) is symplectic for k = 0, see the proof
of Lemma 1.58(vi). It follows by (2.3) that Zk is symplectic for all k, in particular
(2.5) holds for every index k.
Throughout the book we will concentrate on the conjoined bases of (SDS) only,
since 2n √ó n solutions of (SDS) which are not conjoined play a ‚Äúdestructive‚Äù role
in the oscillation theory of (SDS) similarly as their continuous counterparts in the
theory of linear Hamiltonian differential systems. This reasoning has been explained
in more details in Sect. 1.5
If w(Y, ¬ØY ) = I, then we say that Y and ¬ØY form a pair of normalized conjoined
bases. In this case, see Lemma 1.58(v),
Zk :=

Yk ¬ØYk

=
Xk ¬ØXk
Uk ¬ØUk

is a symplectic fundamental matrix of (SDS). By equations (1.145) and (1.146) in
Lemma 1.58, we then have the properties
XT
k ¬ØUk ‚àíUT
k ¬ØXk = I,
XT
k Uk = UT
k Xk,
¬ØXT
k ¬ØUk = ¬ØUT
k ¬ØXk,
(2.6)
Xk ¬ØUT
k ‚àí¬ØXkUT
k = I,
Xk ¬ØXT
k = ¬ØXkXT
k ,
Uk ¬ØUT
k = ¬ØUkUT
k .
(2.7)
We note that given a conjoined basis Y of (SDS), there always exists another
conjoined basis ÀÜY, which together with Y forms a pair of normalized conjoined
bases. The proof of this claim is essentially contained in Remark 2.3.
Lemma 2.4 For any conjoined bases Y, ¬ØY, ÀúY of (SDS) such that w(Y, ¬ØY ) = I the
n √ó n matrix w( ÀúY, Y) [w( ÀúY, ¬ØY)]T is symmetric.
Proof The proof follows from the properties in (2.7) by direct calculation of the
product (suppressing the index k)
w( ÀúY , Y) [w( ÀúY, ¬ØY)]T
= ‚àíÀúY T J Y ¬ØY T J ÀúY
(2.7)
=
 ÀúUT ‚àíÀúXT  
X ¬ØXT
X ¬ØUT
¬ØUXT ‚àíI U ¬ØUT
  ÀúU
‚àíÀúX

= ÀúUTX ¬ØXT ÀúU ‚àí( ÀúUTX ¬ØUT ÀúX + ÀúXT ¬ØUXT ÀúU) + ÀúXT ÀúU + ÀúXT U ¬ØUT ÀúX.
(2.8)

86
2
Basic Theory of Symplectic Systems
By (2.5) and (2.7), we know that the matrices ÀúXT ÀúU, X ¬ØXT , and U ¬ØUT are symmetric.
Therefore, the sum in (2.8) above is also a symmetric matrix.
‚äì‚äî
2.1.2
Special Symplectic Difference Systems
In this subsection we present several important examples of symplectic difference
systems. We start this subsection with a system which is equivalent with (SDS).
Example 2.5 We consider the time-reversed symplectic difference system
yk = S‚àí1
k yk+1.
(2.9)
In [45] an alternative terminology‚Äîa reciprocal system‚Äîis used. Using the formula
for the inverse of a symplectic matrix from Lemma 1.58(ii), system (2.9) can be
written as
xk = DT
k xk+1 ‚àíBT
k uk+1,
uk = ‚àíCkxk+1 + AT uk+1.
(2.10)
All results obtained for (SDS) can be ‚Äútranslated‚Äù in a natural way to system (2.9)
by reversing the direction of the independent variable. Indeed, for S‚àó
k := S‚àí1
N‚àík for
k ‚àà[0, N]Z and y‚àó
k := yN+1‚àík for k ‚àà[0, N + 1]Z, we obtain from (2.9) the
equivalent system
y‚àó
k+1 = yN‚àík = S‚àí1
N‚àíkyN‚àík+1 = S‚àó
k y‚àó
k,
where the matrix S‚àó
k is symplectic.
Example 2.6 Next we consider the so-called trigonometric symplectic difference
systems. The trigonometric system is a system (SDS) where the matrix S satisÔ¨Åes
the additional condition
J T SkJ = Sk,
(2.11)
which says that if y =
x
u

is a solution of (SDS), then Àúy = ‚àíJ y =
‚àíu
x

is
a solution of (SDS) as well. Again, substituting into (2.11), we have that (SDS) is
a trigonometric symplectic system if and only if
Dk = Ak,
Ck = ‚àíBk.
Consequently, combining this with (1.145) and (1.146), we see that a trigonometric
symplectic system is a system of the form
xk+1 = Akxk + Bkuk,
uk+1 = ‚àíBkxk + Akuk,
(2.12)

2.1
Symplectic Systems and Their Particular Cases
87
where
AT
k Ak + BT
k Bk = I,
AT
k Bk = BT
k Ak,
(2.13)
which is equivalent to
AkAT
k + BkBT
k = I,
AkBT
k = BkAT
k .
(2.14)
The terminology ‚Äútrigonometric system‚Äù is justiÔ¨Åed by the fact that in the scalar
case n = 1, the equalities in (2.13) imply that Ak = cos œïk and Bk = sin œïk for
some œïk and then solutions of (2.12) are
(xk, uk) =

cos
k‚àí1

œïj

, sin
k‚àí1

œïj

,
(Àúxk, Àúuk) =

‚àísin
k‚àí1

œïj

, cos
k‚àí1

œïj

.
Basic properties of solutions of trigonometric symplectic systems with nonsingular
Bk are established in [25].
Example 2.7 Next we consider the linear Hamiltonian difference system

xk
uk

= J Hk
xk+1
uk

,
(2.15)
where
Hk = HT
k ,
Hk =
‚àíCk AT
k
Ak
Bk

,
det(I ‚àíAk) Ã∏= 0.
(2.16)
System (2.15) can be equivalently written as
xk = Akxk+1 + Bkuk,
uk = Ckxk+1 ‚àíAT
k uk.
(2.17)
Expanding the forward differences in (2.17), we obtain the system
xk+1
uk+1

= S[H]
k
xk
uk

,
where
S[H]
k
=
 (I ‚àíAk)‚àí1
(I ‚àíAk)‚àí1Bk
Ck(I ‚àíAk)‚àí1 Ck(I ‚àíAk)‚àí1Bk + I ‚àíAT
k

.
(2.18)
By direct substitution into (1.145), we see that the matrix S[H]
k
is symplectic.

88
2
Basic Theory of Symplectic Systems
The exact relationship between symplectic and Hamiltonian systems is described
in the next statement.
Theorem 2.8 A symplectic system (SDS) with the matrix Sk in (2.1) is a rewritten
Hamiltonian system (2.15) if and only if the matrix Ak is invertible for all k.
Proof It sufÔ¨Åces to prove that invertibility of Ak implies that (SDS) can be written
as (2.15). DeÔ¨Åne
Ak := I ‚àíA‚àí1
k ,
Bk := A‚àí1
k Bk,
Ck := CkA‚àí1
k .
(2.19)
Then (1.145) and (1.146) imply that the matrices Bk and Ck are symmetric and that
Dk = AT ‚àí1
k
(I + CT
k Bk) = AT ‚àí1
k
+ CkA‚àí1
k Bk = I ‚àíAT
k + Ck(I ‚àíAk)‚àí1Bk.
Then, in view of (2.18), symplectic system (SDS) can be written as a linear
Hamiltonian system (2.15).
‚äì‚äî
Sometimes, when the matrix Ak in a symplectic system is invertible, we say that
this system has a Hamiltonian structure.
Example 2.9 As an example of discrete symplectic systems with the Hamiltonian
structure, consider the so-called hyperbolic systems in the form (SDS), where Sk
obeys the additional condition
P1SkP1 = Sk,
P1 =
0 I
I 0

.
(2.20)
Here the matrix P1 introduced in Sect. 1.6.1 (see (1.151)) obeys all assumptions of
Lemma 1.58(iv); in particular, we have that P1SkP1 ‚ààSp(2n). Relation (2.20) says
that if y =
x
u

is a solution of (SDS), then
u
x

is a solution as well. By analogy with
the trigonometric case, we have that (SDS) is a hyperbolic symplectic system if and
only if
Dk = Ak,
Ck = Bk.
Consequently, combining this with (1.145) and (1.146), we see that a hyperbolic
symplectic system is a system of the form
xk+1 = Akxk + Bkuk,
uk+1 = Bkxk + Akuk,
(2.21)
with n √ó n matrices Ak and Bk satisfying
AT
k Ak ‚àíBT
k Bk = I = AkAT
k ‚àíBkBT
k ,
AT
k Bk ‚àíBT
k Ak = 0 = AkBT
k ‚àíBkAT
k .
(2.22)

2.1
Symplectic Systems and Their Particular Cases
89
The Ô¨Årst equality in (2.22) implies that matrix Ak is nonsingular (use AT
k Ak =
I + BT
k Bk, where BT
k Bk ‚â•0), and then according to Theorem 2.8 system (2.21) is
a special case of the discrete Hamiltonian system (2.15) with the blocks (see (2.19))
Ak := I ‚àíA‚àí1
k ,
Bk := A‚àí1
k Bk,
Ck := BkA‚àí1
k .
Moreover, since
(AT
k + BT
k )(Ak ‚àíBk) = AT
k Ak + BT
k Ak ‚àíAT
k Bk ‚àíBT
k Bk = I,
the matrices Ak + Bk and Ak ‚àíBk are nonsingular, too. Furthermore, we have
(Ak ‚àíBk)‚àí1 = AT
k + BT
k ,
(Ak + Bk)‚àí1 = AT
k ‚àíBT
k .
(2.23)
The terminology ‚Äúhyperbolic system‚Äù is justiÔ¨Åed by the fact that in the scalar case
n = 1, the equalities in (2.22) imply that A2
k ‚àíB2
k = 1 and the solution of (2.21)
deÔ¨Åned by the initial condition x0 = 0 and u0 = 1 is
xk =
 k‚àí1
'
i=0
sgn Ai

sinh
 k‚àí1

i=0
ln |Ai + Bi|

,
uk =
 k‚àí1
'
i=0
sgn Ai

cosh
 k‚àí1

i=0
ln |Ai + Bi|

.
Basic properties of solutions of hyperbolic symplectic systems are established in
[108].
Example 2.10 Another special case of (SDS) is the symmetric three-term recur-
rence equation and the equivalent Jacobi matrix difference equation (1.60). Consider
the equation
(Rkxk + QT
k xk+1) ‚àí(Qkxk + Pkxk+1) = 0
(2.24)
with Pk, Qk, Rk ‚ààRn√ón, Rk and Pk symmetric and Rk + QT
k invertible, and its
particular case, the matrix Sturm-Liouville equation
(Rkxk) ‚àíPkxk+1 = 0.
(2.25)
Expanding the forward difference in (2.24), we obtain equivalent three-term matrix
recurrence equation
Kk+1xk+2 ‚àíLk+1xk+1 + KT
k xk = 0,
(2.26)

90
2
Basic Theory of Symplectic Systems
where
Kk := Rk + QT
k ,
Lk := Rk + Rk‚àí1 + QT
k‚àí1 + Qk‚àí1 + Pk‚àí1,
i.e., Kk is an invertible matrix and Lk is symmetric.
Example 2.11 Consider now equation (2.26) with Kk invertible, and assume that
Rk are any symmetric matrices. Then, following [304, Theorem 3.1, Corollary 3.4]
(compare also with Theorem 1.29) system (2.26) can be written as a symplectic
difference system (SDS) with the matrices
Ak = K‚àí1
k Rk, Ck = (Lk+1 ‚àíRk+1) K‚àí1
k Rk ‚àíKT
k ,
Bk = K‚àí1
k ,
Dk = (Lk+1 ‚àíRk+1) K‚àí1
k .
Indeed, if we deÔ¨Åne uk := Kkxk+1 ‚àíRkxk for all k ‚àà[0, N]Z together with the
additional value uN+1 := (LN+1 ‚àíRN+1) xN+1 ‚àíKT
NxN, then
xk+1 = K‚àí1
k Rkxk + K‚àí1
k uk = Akxk + Bkuk,
uk+1 = Kk+1xk+2 ‚àíRk+1x + k + 1 = (Lk+1 ‚àíRk+1) xk+1 ‚àíKT
k xk
= Ckxk + Dkuk,
for all k ‚àà[0, N]Z. Conversely, if the matrices Bk for k ‚àà[0, N]Z in (2.2) are
invertible, then this system can be written as (2.26) with
Kk := B‚àí1
k ,
Lk := B‚àí1
k Ak + Dk‚àí1Bk‚àí1.
Special choices of the matrices Rk (such as Rk := 0 or Rk := Kk when Kk is
also symmetric) yield different representations of (2.26) as a symplectic difference
system (SDS). For a more detailed treatment of the relationship between (SDS) and
(2.24), we refer to [304].
Example 2.12 Consider the 2n-order Sturm-Liouville difference equation
n

ŒΩ=0
(‚àí1)ŒΩŒΩr[ŒΩ]
k ŒΩyk+n‚àíŒΩ
 = 0,
r[n]
k
Ã∏= 0.
(2.27)
We put
xk =
‚éõ
‚éú‚éú‚éú‚éù
yk+n‚àí1
yk+n‚àí2
...
n‚àí1yk
‚éû
‚éü‚éü‚éü‚é†,
uk =
‚éõ
‚éú‚éú‚éú‚éú‚éù
n
j=1(‚àí)j‚àí1
r[j]
k jyk+n‚àíj

...
‚àí

r[n]
k nyk

+ r[n‚àí1]
k
n‚àí1yk+1
r[n]
k nyk
‚éû
‚éü‚éü‚éü‚éü‚é†
.
(2.28)

2.1
Symplectic Systems and Their Particular Cases
91
Then y = x
u
 is a solution of the Hamiltonian system (2.17) with
Ak ‚â°A = {aij} =

1
if j = i + 1,
0
otherwise
,
Bk = diag

0, . . . , 0, 1
r[n]
k
 
,
(2.29)
Ck = diag
(
r[0]
k , r[1]
k , . . . , r[n‚àí1]
k
)
,
(2.30)
with I ‚àíAk upper triangular and det (I ‚àíAk) = 1. Hence I ‚àíAk is invertible with
(I ‚àíAk)‚àí1 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
1 1 . . . 1 1
0 1 . . . 1 1
... ... ... ... ...
0 0 . . . 1 1
0 0 . . . 0 1
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
.
(2.31)
Therefore, equation (2.27) is also a special case of system (SDS), in which according
to (2.18) and (2.31), the coefÔ¨Åcients are
Ak =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
1 1 . . . 1 1
0 1 . . . 1 1
...
... ... ...
...
0 0 . . . 1 1
0 0 . . . 0 1
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
Bk =
1
r[n]
k
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
0 . . . 0 1
0 . . . 0 1
... ... ...
...
0 . . . 0 1
0 . . . 0 1
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
(2.32)
Ck =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
r[0]
k
r[0]
k
. . . r[0]
k
r[0]
k
0 r[1]
k
. . . r[1]
k
r[1]
k
...
...
...
...
0
0 . . . r[n‚àí2]
k
r[n‚àí2]
k
0
0 . . .
0
r[n‚àí1]
k
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
(2.33)
Dk =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1
0 0 . . . 0
0
r[0]
k /r[n]
k
‚àí1 1 0 . . . 0
0
r[1]
k /r[n]
k
0 ‚àí1 1 . . . 0
0
r[2]
k /r[n]
k
...
...
... ...
...
...
...
0
0 0 . . . 1
0
r[n‚àí3]
k
/r[n]
k
0
0 0 . . . ‚àí1 1
r[n‚àí2]
k
/r[n]
k
0
0 0 . . . 0 ‚àí1 1 + r[n‚àí1]
k
/r[n]
k
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
(2.34)

92
2
Basic Theory of Symplectic Systems
Example 2.13 Finally, consider the classical second-order Sturm-Liouville differ-
ence equation


rkxk

+ pkxk+1 = 0,
rk Ã∏= 0.
(2.35)
The symplectic system corresponding to this equation (with uk := rkxk) is
xk+1
uk+1

=
 1
1/rk
‚àípk 1 ‚àípk/rk
 xk
uk

,
(2.36)
as can be veriÔ¨Åed by a direct computation after expanding the forward differences
in the system xk = (1/rk) uk and uk = ‚àípkxk+1.
Let us summarize that the above-described particular cases of (SDS) are equiva-
lent to the invertibility of certain blocks in the matrix Sk. If Ak are invertible, then
(SDS) is equivalent to the linear Hamiltonian difference system (2.15), while if Bk
are invertible, then (SDS) is equivalent to the Jacobi equation (2.24), which is in
turn equivalent to a symmetric three-term recurrence equation (2.26). Finally, if Bk
are invertible and symmetric, then (SDS) is equivalent to a matrix Sturm-Liouville
equation (2.25).
2.2
Focal Points
The central concept of the oscillation theory of symplectic difference systems (SDS)
is the concept of a focal point of a conjoined basis of this system and the concept
of its multiplicity. The concept of a focal point is treated here, while its multiplicity
will be discussed later.
2.2.1
Focal Points of Conjoined Bases
The following notion is motivated by the work [39] and [45] by Bohner and Do≈°l√Ω.
DeÔ¨Ånition 2.14 We say that a conjoined basis Y =
X
U

of symplectic difference
system (SDS) has no (forward) focal point in (k, k + 1] if the following conditions
hold
Ker Xk+1 ‚äÜKer Xk,
Pk := XkX‚Ä†
k+1Bk ‚â•0.
(2.37)
The Ô¨Årst condition in (2.37) is usually called the kernel condition, while the
second condition in (2.170) is called the P-condition. This means that a conjoined
basis Y does have a focal point in the interval (k, k + 1] if one of the conditions
in (2.170) is violated. The term ‚Äúforward‚Äù focal point refers to the direction of the
kernel condition in (2.37). The following lemma provides equivalent formulations
of the kernel condition in (2.37).

2.2
Focal Points
93
Lemma 2.15 Let Y =
X
U

be a conjoined basis of (SDS). Then
Ker Xk+1 ‚äÜKer Xk
‚áê‚áí
Ker XT
k+1 ‚äÜKer BT
k
‚áê‚áí
Im Bk ‚äÜIm Xk+1
(2.38)
‚áê‚áí
Xk+1X‚Ä†
k+1Bk = Bk.
(2.39)
Proof The equivalence of the second and third condition in (2.38) with (2.39)
follows from (1.159) and (1.160). We will show the equivalence of the Ô¨Årst two
conditions in (2.38). Suppose that the Ô¨Årst inclusion holds. Let c ‚ààKer XT
k+1 and
ÀúY =
 ÀúX
ÀúU

be the conjoined basis which together with Y =
X
U

forms a normalized
pair of conjoined bases, i.e., Xk ÀúUT
k ‚àíÀúXkUT
k = I. Then Xk ÀúXT
k = ÀúXkXT
k by (1.146)
for the block entries of a symplectic matrix so that Xk+1 ÀúXT
k+1c = ÀúXk+1XT
k+1c = 0.
This means that ÀúXT
k+1c ‚ààKer Xk+1 ‚äÜKer Xk. Therefore,
BT
k c = ÀúXkXT
k+1c + BT
k c = ÀúXkXT
k AT
k c + (I + ÀúXkUT
k ) BT
k c
= Xk ÀúXT
k AT
k c + Xk ÀúUT
k BT
k c = Xk ÀúXT
k+1c = 0.
Conversely, let c ‚ààKer Xk+1. By (2.39), we have BT
k = BT
k (X‚Ä†
k+1)T XT
k+1. Then
using (2.10), we get
Xkc = (DT
k Xk+1 ‚àíBT
k Uk+1) c = ‚àíBT
k (X‚Ä†
k+1)T XT
k+1Uk+1c
= ‚àíBT
k (X‚Ä†
k+1)T UT
k+1Xk+1c = 0,
hence c ‚ààKer Xk. The proof is complete.
‚äì‚äî
Remark 2.16 Note that if the kernel condition in (2.37) holds, then the matrix Pk
is really symmetric. Indeed, let Qk be a symmetric matrix satisfying the equality
QkXk = UkX‚Ä†
kXk. Such a matrix really exists, e.g., it is the matrix
Qk := UkX‚Ä†
k + (UkX‚Ä†
k ÀúXk ‚àíÀúUk)(I ‚àíX‚Ä†
kX) UT
k ,
(2.40)
where ÀúY =
 ÀúX
ÀúU

is a conjoined basis which together with Y =
X
U

forms a pair
of normalized conjoined bases. Substituting for Xk from (2.10), and using formula
(2.39) in Lemma 2.15, we have
Pk = XkX‚Ä†
k+1Bk = (DT
k Xk+1 ‚àíBT
k Uk+1)X‚Ä†
k+1Bk
= DT
k Xk+1X‚Ä†
k+1Bk ‚àíBT
k Uk+1X‚Ä†
k+1Xk+1X‚Ä†
k+1Bk
= DT
k Bk ‚àíBT
k Qk+1Bk,
which is symmetric.

94
2
Basic Theory of Symplectic Systems
Observe that DeÔ¨Ånition 2.14 is in good agreement with the deÔ¨Ånition of a focal
point of a solution of the second- order equation (2.35), when this equation is written
as a symplectic system. Since by (2.36) the matrix Bk = 1/rk Ã∏= 0 in this case, no
focal point of a solution x of (2.35) in the interval (k, k + 1] means that rkxkxk+1 >
0. This implies that if xk Ã∏= 0, then xk+1 Ã∏= 0 as well (the kernel condition), and
rkxkxk+1 > 0 is the P-condition taking into account that rk Ã∏= 0.
As we will show later in this section, oscillatory properties of (SDS) can be
equivalently deÔ¨Åned via generalized zeros of vector solutions. We conclude this
subsection with the deÔ¨Ånition of this concept.
DeÔ¨Ånition 2.17 We say that a solution y =
x
u

‚ààR2n of (SDS) has a generalized
zero in the interval (k, k + 1] if
xk Ã∏= 0,
xk+1 ‚ààIm Bk,
and
xT
k B‚Ä†
kxk+1 ‚â§0.
(2.41)
DeÔ¨Ånition 2.18 Symplectic system (SDS) is said to be disconjugate on the interval
[0, N + 1] if no solution of (SDS) has more than one generalized zero in (0, N + 1]
and the solution y =
x
u

with x0 = 0 has no generalized zero in (0, N + 1].
DeÔ¨Ånition 2.19 Symplectic system (SDS) is said to be nonoscillatory at ‚àûif there
exists M such that this system is disconjugate on [M, N +1] for any N ‚â•M. In the
opposite case, system (SDS) is called oscillatory at ‚àû.
Remark 2.20 Let y =
x
u

be a vector solution of (SDS), and suppose that xk+1 =
Bkc for some c ‚ààRn, i.e., xk+1 ‚ààIm Bk. Then xT
k B‚Ä†
kxk+1 = xT
k c. To see this, note
that xk+1 = Bkc implies
xk = DT
k xk+1 ‚àíBT
k uk+1 = DT
k Bkc ‚àíBT
k uk+1 = BT
k (Dkc ‚àíuk+1)
and
xT
k B‚Ä†
kxk+1 = (Dkc ‚àíuk+1)T BkB‚Ä†
kBkc = xT
k c.
Remark 2.21 Consider now that (SDS) a rewritten even order Sturm-Liouville
difference equation (2.27), i.e., a rewritten linear Hamiltonian system (2.15) with
xk and uk given by (2.28) and Ak, Bk, Ck, Dk given by (2.32)‚Äì(2.34). Then by
a direct computation (verifying the four properties in (1.157)), we have
B‚Ä†
k = r[n]
k
n
‚éõ
‚éú‚éú‚éú‚éù
0 . . . 0
... ... ...
0 . . . 0
1 . . . 1
‚éû
‚éü‚éü‚éü‚é†.
(2.42)
Taking into account formulas (2.28) and expanding the higher-order difference in
the formula for x, we see that xk+1 = Bkc ‚ààIm Bk with c = (c1, . . . , cn)T ‚ààRn if

2.2
Focal Points
95
and only if xk+1 = cn/r[n]
k
 (1, . . . , 1)T . This means that all the entries of xk+1 in
(2.28) are equal and hence
yk+1 = yk+2 = ¬∑ ¬∑ ¬∑ = yk+n‚àí1 = 0,
cn = r[n]
k yk+n.
(2.43)
We then obtain that
xk =
‚éõ
‚éú‚éú‚éú‚éù
0
...
0
(‚àí1)n‚àí1yk
‚éû
‚éü‚éü‚éü‚é†,
xk+1 = yk+n
‚éõ
‚éú‚éù
1
...
1
‚éû
‚éü‚é†,
(2.44)
and
xT
k B‚Ä†
kxk+1 = xT
k c = (‚àí1)n‚àí1r[n]
k ykyk+n.
(2.45)
Therefore, combining (2.43), (2.44), and (2.45), we can see that a solution
 xu

of
(SDS) has a forward focal point in the interval (k, k+1] according to DeÔ¨Ånition 2.17
if and only if the solution y of (2.27) satisÔ¨Åes
yk Ã∏= 0,
yk+1 = yk+2 = ¬∑ ¬∑ ¬∑ = yk+n‚àí1 = 0,
(‚àí1)n‚àí1r[n]
k ykyk+n ‚â§0.
(2.46)
Condition (2.46) agrees with the notion of a generalized zero in (k, k + n] for
a solution y of (2.27) introduced by Hartman in [169, pg. 2] or by Bohner in
[41, Remark 3(iii)]. Also, when n = 1, then the second condition in (2.46) is
vacuous, and the Ô¨Årst and third conditions yield the deÔ¨Ånition of a generalized zero
in (k, k + 1] for a solution y of (2.35) (or (1.1); see DeÔ¨Ånition 1.1).
2.2.2
Backward Focal Points
The adjective ‚Äúforward‚Äù focal point is used in the previous subsection to distinguish
this concept from the concept of a backward focal point which is deÔ¨Åned below. We
will use the convention that ‚Äúfocal point‚Äù without any adjective means by default
a forward focal point.
As we have mentioned in the previous section, symplectic system (SDS) is
equivalent to the so-called time-reversed symplectic system
zk = S‚àí1
k zk+1,
S‚àí1 =

DT
k
‚àíBT
k
‚àíCT
k
AT
k

,
(2.47)
and this system motivates the deÔ¨Ånition of the backward focal point as follows.

96
2
Basic Theory of Symplectic Systems
DeÔ¨Ånition 2.22 Let Y =
X
U

be a conjoined basis of (SDS). We say that Y has no
backward focal point in [k, k + 1) if
Ker Xk ‚äÜKer Xk+1
and
Xk+1X‚Ä†
kBT
k ‚â•0.
(2.48)
We can also deÔ¨Åne the concept of a generalized zero of a vector solution in the
interval [k, k + 1) which is associated with the concept of backward focal point and
it is deÔ¨Åned as follows.
DeÔ¨Ånition 2.23 Let y =
x
u

‚ààR2n be a solution of (SDS). This solution has
a generalized zero in the interval [k, k + 1) if
xk+1 Ã∏= 0,
xk ‚ààIm BT
k ,
and
xT
k B‚Ä†
kxk+1 ‚â§0.
(2.49)
Then, similarly to generalized zeros in (k, k + 1], we have for xk = BT
k c
xk+1 = Akxk + Bkuk = AkBT
k c + Bkuk = Bk(Akc + uk)
and
xT
k B‚Ä†
kxk+1 = cT BkB‚Ä†
kBk(Akc + uk) = cT Bk(AT
k c + uk)
= cT xk+1 = xT
k+1c.
Remark 2.24 Returning to the 2n-th order Sturm-Liouville difference equation
(2.27), the concept of a backward focal point in [k, k + 1) for a solution y of (2.27)
in DeÔ¨Ånition 2.22 translates as follows: according to (2.49) and (2.32), we have
xk = BT
k c ‚ààIm BT
k for some c = (c1, . . . , cn)T ‚ààRn if and only if
xk =
1
r[n]
k
(0, . . . , 0, c0)T ,
c0 :=
n

j=1
cj.
This means in view of the deÔ¨Ånition of xk in (2.28) that
yk+1 = ¬∑ ¬∑ ¬∑ = yk+n‚àí1 = 0,
xk = (0, . . . , 0, (‚àí1)n‚àí1yk)T ,
c0 = (‚àí1)n‚àí1r[n]
k yk,
xk+1 = yk+n (1, . . ., 1)T .
Therefore, xk+1 Ã∏= 0 if and only if yk+n Ã∏= 0, and
xT
k B‚Ä†
kxk+1 = xT
k c = yk+nc0 = (‚àí1)n‚àí1r[n]
k ykyk+n.

2.3
Riccati Equation and Quadratic Functional
97
This shows that a solution  xu
 of (SDS) has a backward focal point in the interval
[k, k +1) according to DeÔ¨Ånition 2.23 if and only if the solution y of (2.27) satisÔ¨Åes
yk+n Ã∏= 0,
yk+1 = yk+2 = ¬∑ ¬∑ ¬∑ = yk+n‚àí1 = 0,
(‚àí1)n‚àí1r[n]
k ykyk+n ‚â§0.
(2.50)
This is what we deÔ¨Åne as a generalized zero in the interval [k, k + n) for a solution
y of (2.27). For the second-order Sturm-Liouville difference equation (2.35) (or
(1.1)), we then obtain from (2.50) the deÔ¨Ånition of a generalized zero of a solution
y of (2.35) in [k, k + 1), which reads as yk+1 Ã∏= 0 and rkykyk+1 ‚â§0.
2.3
Riccati Equation and Quadratic Functional
In this section, we treat two basic concepts which are associated with symplectic
difference systems, namely, the Riccati matrix difference equation and the associ-
ated (energy) quadratic functional. Picone‚Äôs identity is then an identity which relates
these two concepts and shows that, similarly to the scalar case, the existence of
a symmetric solution of Riccati equation enables to ‚Äúcomplete to the square‚Äù the
energy functional, and hence it implies its positivity for any nontrivial admissible
sequence. The main result of this section is formulated in Theorem 2.36 (the Reid
roundabout theorem). We also discuss the nonnegativity of the energy quadratic
functional.
2.3.1
Riccati Matrix Difference Equation
Let us recall that in Sect. 1.5, we have supposed that the considered linear
Hamiltonian differential system is identically normal, which implied (together with
the Legendre condition (1.111)) that focal points of any conjoined basis are isolated.
In the discrete case, all the points in underlaying set Z (or its subsets) are isolated
by themselves, so the assumption of identical normality is of different character.
We start with the simple case. Consider a conjoined basis Y =
X
U

with Xk
invertible for all k ‚àà[0, N + 1]Z. Then by a direct computation we verify that
Qk := UkX‚àí1
k
is a symmetric solution of the Riccati matrix difference equation
Qk+1 = (Ck + DkQk)(Ak + BkQk)‚àí1,
(2.51)
see also Theorem 2.28 below. In some cases, we will need this equation in a slightly
different form with the so-called Riccati operator
Rk[Q] = 0,
Rk[Q] := Qk+1(Ak + BkQk) ‚àí(Ck + DkQk).
(2.52)

98
2
Basic Theory of Symplectic Systems
Another important quantity associated with the matrix Q and used frequently in the
later parts is the matrix
Pk[Q] := (DT
k ‚àíBT
k Qk+1) Bk.
(2.53)
When no identical normality is supposed, it may happen that the Ô¨Årst component
Xk of a conjoined basis is noninvertible on some discrete interval. A typical example
is the symplectic system corresponding to the 2n-th order difference equation
2nyk = 0. Then for the conjoined basis of this system given by the initial condition
Y0 = (0 I)T , we have rank Xk = k for all k = [0, n]Z, as can be veriÔ¨Åed by a direct
computation. Nevertheless, also in this case, we can exhibit a kind of Riccati-type
difference equation, sometimes called an implicit Riccati equation. Another form of
the implicit Riccati equation appears later in Theorem 2.36. In this respect equation
(2.51) is called the explicit Riccati equation.
Lemma 2.25 Let Y =
X
U

be a conjoined basis of (SDS) with Ker Xk+1 ‚äÜKer Xk
for k ‚àà[0, N]Z and suppose that Qk is a symmetric matrix with QkXk = UkX‚Ä†
kXk.
Then we have
Rk[Q] Xk = 0
and
Pk[Q] = XkX‚Ä†
k+1Bk.
Proof From (1.159) we have XkX‚Ä†
k+1Xk+1 = Xk and Xk+1X‚Ä†
k+1Bk = Bk, which
yields
Rk[Q] Xk =

I
Qk+1
T
J T Sk
Xk
Uk

X‚Ä†
kXk =
Qk+1
‚àíI
TXk+1
Uk+1

X‚Ä†
kXk = 0.
The second claim is shown in Remark 2.16.
‚äì‚äî
The following identity relates the matrix Ak +BkQk from (2.51) with the matrix
DT
k ‚àíBT
k Qk+1 in (2.53).
Lemma 2.26 Assume that the matrices Qk and Qk+1 are symmetric. Then
(Dk ‚àíQk+1Bk) (AT
k + QkBT
k ) = I ‚àíRk[Q] BT
k .
(2.54)
Proof By (1.146) we know that DkAT
k = I + CkBT
k and AkBT
k is symmetric. Then
(Dk ‚àíQk+1Bk) (AT
k + QkBT
k ) = DkAT
k + DkQkBT
k ‚àíQk+1BkAT
k ‚àíQk+1BkQkBT
k
= I + [(Ck + DkQk) ‚àíQk+1(Ak + BkQk)] BT
k
= I ‚àíRk[Q] BT
k ,
which shows the result.
‚äì‚äî

2.3
Riccati Equation and Quadratic Functional
99
When the matrices Qk and Qk+1 solve the Riccati equation (2.51), we obtain
from Lemma 2.26 the following important property.
Corollary 2.27 Assume that Qk and Qk+1 are symmetric. Then they satisfy the
implicit Riccati equation Rk[Q]BT
k = 0 if and only if the matrices Ak + BkQk and
DT
k ‚àíBT
k Qk+1 are invertible and they are inverses of each other, i.e.,
(Ak + BkQk)‚àí1 = DT
k ‚àíBT
k Qk+1.
(2.55)
In particular, property (2.55) holds when Qk and Qk+1 satisfy the explicit Riccati
equation (2.51).
Proof The result follows from (2.54) with Rk[Q] BT
k = 0, resp. with Rk[Q] = 0.
‚äì‚äî
The following results connects the symmetric solutions of the explicit Riccati
equation (2.52) with conjoined bases Y of (SDS) with Xk invertible.
Theorem 2.28 The Riccati equation (2.52) on [0, N]Z has a symmetric solution
Qk deÔ¨Åned on [0, N + 1]Z if and only if there exists a conjoined basis Y of (SDS)
with Xk invertible on [0, N + 1]Z. In this case Qk = UkX‚àí1
k
on [0, N + 1]Z and
Ak + BkQk = Xk+1X‚àí1
k
is invertible on [0, N]Z.
Proof Assume that Y is a conjoined (SDS) with Xk invertible on [0, N + 1]Z. We
deÔ¨Åne Qk := UkX‚àí1
k
on [0, N + 1]Z. Then it easily follows that Qk is symmetric
on [0, N + 1]Z and that it solves equation (2.52) on [0, N]Z . Conversely, if Qk
is symmetric solution of (2.52) on [0, N]Z, then by Corollary 2.27, we know that
Ak + BkQk is invertible on [0, N]Z. Consider the solution Xk on [0, N + 1]Z of the
linear system Xk+1 = (Ak + BkQk) Xk for k ‚àà[0, N]Z with the initial condition
X0 = I. Then Xk is invertible on [0, N + 1]Z, and we set Uk := QkX‚àí1
k
on [0, N +
1]Z. It then follows from (2.52) that Y =
 X
U

is a conjoined basis of (SDS), which
completes the proof.
‚äì‚äî
2.3.2
Energy Quadratic Functional
In this subsection we will study the quadratic functional, for which the symplectic
system (SDS) is the associated Jacobi system in the spirit of Sect. 1.3.2. Denote
K :=
0 0
I 0

and consider the quadratic functional
F(y) =
N

k=0
yT
k
ST
k KSk ‚àíK yk,
yk =
xk
uk

‚ààR2n.
(2.56)

100
2
Basic Theory of Symplectic Systems
If we write the matrix Sk in the block form, we have
ST
k KSk ‚àíK =
CT
k Ak CT
k Bk
BT
k Ck DT
k Bk

,
and hence we can write the energy functional equivalently as
F(y) =
N

k=0
{xT
k CT
k Akxk + 2xT
k CT
k Bkuk + uT
k BT
k Dkuk}.
(2.57)
DeÔ¨Ånition 2.29 We say that the sequence y = {yk}N+1
k=0 with yk =
xk
uk

‚ààR2n is
admissible for the quadratic functional F if
xk+1 = Akxk + Bkuk,
k ‚àà[0, N]Z.
(2.58)
The admissibility of y =
x
u

means that the pair (x, u) satisÔ¨Åes the Ô¨Årst equation
in symplectic system (the equation of motion). The admissibility of y can be also
characterized as follows. DeÔ¨Åne the so-called controllability matrices by
Gk :=
‚éõ
‚éù
k‚àí1
'
j=1
Ak‚àíjB0
k‚àí2
'
j=1
Ak‚àíjB1
. . .
Ak‚àí1Bk‚àí2
Bk‚àí1
‚éû
‚é†‚ààRn√ókn.
(2.59)
It follows by induction that y =
x
u

with x0 = 0 is admissible if and only if
xk = Gk
‚éõ
‚éú‚éù
u0
...
uk‚àí1
‚éû
‚éü‚é†
for all k ‚àà[1, N + 1]Z.
(2.60)
Lemma 2.30 Let y =
x
u

be admissible for (2.57). Then this functional can be
expressed in the form
F(x, u) = xT
k uk
			
N+1
k=0 +
N

k=0
xT
k+1(‚àíuk+1 + Ckxk + Dkuk).
(2.61)
Proof Using the admissibility of y = x
u
, we have
F(x, u) =
N

k=0
{xT
k CT
k (Akxk + Bkuk) + (xT
k CT
k + uT
k DT
k ) Bkuk}
=
N

k=0
{xT
k CT
k (Akxk + Bkuk) + xT (AT
k Dk ‚àíI) uk + uT
k DT
k (xk+1 ‚àíAkxk)}

2.3
Riccati Equation and Quadratic Functional
101
=
N

k=0
{xT
k+1Ckxk ‚àíxT
k uk + xT
k+1Dkuk + xT
k+1uk+1 ‚àíxT
k+1uk+1}
=
N

k=0
(xT
k uk) +
N

k=0
xT
k+1(‚àíuk+1 + Ckxk + Dkuk)
= xT
k uk
			
N+1
k=0 +
N

k=0
xT
k+1(‚àíuk+1 + Ckxk + Dkuk),
which shows the result.
‚äì‚äî
The quadratic functional (2.56) is given by the symmetric bilinear form
F( Àúy, y) =
N

k=1
ÀúyT
k (ST
k KSk ‚àíK) yk
=
N

k=0
{ÀúxT
k CT
k Akxk + ÀúxT
k CT
k Bkuk + ÀúuT
k BT
k Ckxk + ÀúuT
k BT
k Dkuk}.
Similarly as in the previous lemma, we have
F( Àúy, y) = ÀúxT
k uk
			
N+1
k=0 +
N

k=0
ÀúxT
k+1(‚àíuk+1 + Ckxk + Dkuk).
(2.62)
By a direct computation, one can verify that for admissible y, Àúy
F(y + Àúy) = F(y) + 2F(y, Àúy) + F( Àúy),
which has the following consequence frequently used in the discrete calculus of
variations and optimal control.
Theorem 2.31 Suppose that F(y) ‚â•0 for any admissible y =
x
u

with x0 =
0 = xN+1. Let Àúy =
Àúx
Àúu

be a solution of (SDS) for which Àúx0 = p ‚ààRn and
ÀúxN+1 = q ‚ààRn. Then for any admissible y = x
u
 with x0 = p and xN+1 = q, we
have F(y) ‚â•F( Àúy).
Proof Denote Œ¥yk := Àúyk ‚àíyk, i.e., Àúyk = yk + Œ¥yk. Then Œ¥y is also admissible and
Œ¥x0 = 0 = Œ¥xN+1, where Œ¥yk =
Œ¥xk
Œ¥uk

, i.e., F(Œ¥y) ‚â•0. We have
F( Àúy) = F(y + Œ¥y) = F(y) + 2F(Œ¥y, y) + F(Œ¥y) ‚â•F(y),
since according to (2.62), we have F(Œ¥y, y) = 0.
‚äì‚äî

102
2
Basic Theory of Symplectic Systems
Finally, note that another way how to write F(y) for an admissible y is to replace
Bkuk in the last two terms in (2.57) by xk+1 ‚àíAkxk. Using this approach, one can
eliminate the variable u in the functional, and this functional can be written in the
form
F(y) =
N

k=0
 xk
xk+1
T
Gk
 xk
xk+1

,
(2.63)
where the symmetric 2n √ó 2n matrix Gk and the symmetric n √ó n matrix Ek are
deÔ¨Åned by
Gk :=
AT
k EkAk ‚àíAT
k Ck CT
k ‚àíAT
k Ek
CT
k EkAk
Ek

,
Ek := BkB‚Ä†
kDkB‚Ä†
k.
(2.64)
This elimination of u turned to be useful in proving the Sturmian theorems for
symplectic difference systems in Chaps. 4 and 5.
2.3.3
Picone Identity
The next lemma presents the so-called Picone identity, which is used in establishing
conditions for positivity of the energy functional F in the class of admissible pairs
(x, u) with x0 = 0 = xN+1.
Lemma 2.32 Let y =
x
u

be an admissible pair for F and put zk := uk ‚àíQkxk,
where Qk ‚ààRn√ón is a symmetric matrix. Then we have the identities
(xT
k Qkxk) ‚àíxT
k CT
k Akxk ‚àí2xT
k CT
k Bkuk ‚àíuT
k BT
k Dkuk + zT
k Pk[Q] zk
= 2 uT
k BT
k Rk[Q] xk + xT
k {RT
k [Q] Ak ‚àíQkBT
k Rk[Q]} xk,

(2.65)
and
(DT
k ‚àíBT
k Qk+1) xk+1 = xk + Pk[Q] zk ‚àíBT
k Rk[Q] xk.
(2.66)
In particular, if Q is a solution of Riccati equation (2.52), i.e., Rk[Q] = 0, and
x0 = 0 = xN+1, we have the Picone identity
F(y) =
N

k=0
zT
k Pk[Q] zk.
(2.67)
Proof Formula (2.65), the so-called Picone identity in difference form, can be
derived by direct calculations, which are however rather technical. We will present

2.3
Riccati Equation and Quadratic Functional
103
a more elegant proof of (2.65) at the end of Sect. 2.6. As for identity (2.66), we
prove it as follows. Denote the left-hand side of this identity by L. Then we have
L = (DT
k ‚àíBT
k Qk+1) (Akxk + Bkuk)
= DT
k Akxk ‚àíBT
k Qk+1Akxk + DT
k Bkuk ‚àíBT
k Qk+1Bkuk
= (I + BT
k Ck) xk ‚àíBT
k Qk+1Akxk + Pk[Q] (uk ‚àíQkxk)
+ (BT
k Dk ‚àíBT
k Qk+1Bk) Qkxk
= xk + Pk[Q] zk ‚àíBT
k Rk[Q] xk,
which is the right-hand side of (2.66). Formula (2.67) is obtained by the summation
of (2.65) from k = 0 to k = N by using Rk[Q] = 0 and x0 = 0 = xN+1.
‚äì‚äî
2.3.4
Reid Roundabout Theorem
Now we are ready to formulate and prove the Reid roundabout theorem for
symplectic difference system. This theorem plays the fundamental role in the
oscillation theory of these systems. In the proof we will need the following auxiliary
result, which shows that the kernel condition (2.37) implies the so-called image
condition for admissible pairs.
Lemma 2.33 Let Y = X
U
 be a conjoined basis of (SDS) satisfying the kernel
condition in (2.37). Then for any admissible sequence y =
x
u

with x0 ‚ààIm X0, we
have xk ‚ààIm Xk for all k ‚àà[0, N + 1]Z.
Proof Suppose that xk ‚ààIm Xk, i.e., xk = Xkc for some c ‚ààRn and k ‚àà[0, N]Z.
The admissibility of y means that
xk+1 = Axk + Bkuk = Xk+1c + Bk(Ukc + uk) ‚ààIm Xk+1,
since Im Bk ‚äÜIm Xk+1 by Lemma 2.15.
‚äì‚äî
As we will see later, in the investigation of the positivity or nonnegativity of the
quadratic functional F associated with a symplectic difference system, an important
role is played by the principal solution at k = 0 given in DeÔ¨Ånition 2.2.
Lemma 2.34 Suppose that for all solutions y = x
u
 of (SDS) with x0 = 0, we have
that xT
k c > 0 whenever xk Ã∏= 0 and xk+1 = Bkc hold for k ‚àà[0, N]Z, i.e., y has no
generalized zero in (0, N + 1]. Then the principal solution of (SDS) at k = 0 has
no focal points in (0, N + 1].
Proof Let Y =
X
U

be the principal solution of (SDS) at k = 0. First, let Œ± ‚àà
Ker Xm+1 for some m ‚àà[0, N]Z and put yk := YkŒ± on [0, N + 1]Z. Then y solves

104
2
Basic Theory of Symplectic Systems
(SDS) with x0 = 0 and xm+1 = 0 ‚ààImBm, so that xm = 0 as well. Otherwise
we would have xT
mc > 0 with c = 0 by the assumptions of the lemma. Hence
Ker Xm+1 ‚äÜKer Xm holds. Now, let c ‚ààRn, Œ± := X‚Ä†
m+1Bmc, and deÔ¨Åne again
yk := YkŒ± on [0, N + 1]Z. Then y solves (SDS) with x0 = 0, xm+1 = Bmc, and
xT
mc = cT XmX‚Ä†
m+1Bmc. Therefore, XmX‚Ä†
m+1Bm ‚â•0 holds as well, and Y =
X
U

has no focal points in (0, N + 1].
‚äì‚äî
Lemma 2.35 If F(y) > 0 for all admissible pairs y = x
u
 with x0 = 0 = xN+1
and x Ã∏‚â°0, then (SDS) is disconjugate on the interval [0, N + 1].
Proof Suppose that (SDS) is not disconjugate. Then by Remark 2.20, there exist
a solution y =
x
u

of (SDS), the indices m, p ‚àà[0, N]Z with m < p, and vectors
cm, cp ‚ààRn such that
xm Ã∏= 0, xm+1 = Bmcm, xT
mcm ‚â§0,
xp Ã∏= 0, xp+1 = Bpcp, xT
p cp ‚â§0.
This means that the solution y has generalized zeros in the intervals (m, m + 1] and
(p, p + 1]. DeÔ¨Åne
Àúxk :=

xk, m + 1 ‚â§k ‚â§p,
0
otherwise,
Àúuk :=
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
cm,
k = m,
uk,
m + 1 ‚â§k ‚â§p ‚àí1,
up ‚àícp, k = p,
0,
otherwise.
Then Àúx0 = 0 = ÀúxN+1 and Àúx Ã∏‚â°0 hold. Moreover, Àúy =
Àúx
Àúu

is easily checked to be
admissible on [0, N + 1]Z, and by Lemma 2.30 (with y := Àúy), we get
F( Àúy) = ÀúxT
k Àúuk
		N+1
0
+
N

k=0
ÀúxT
k+1{Ck Àúxk + Dk Àúuk ‚àíÀúuk+1}
=

k‚àà{m,p‚àí1}
ÀúxT
k+1{Ck Àúxk + Dk Àúuk ‚àíÀúuk+1} +
p‚àí2

k=m+1
ÀúxT
k+1{Ck Àúxk + Dk Àúuk ‚àíÀúuk+1}
= xT
m+1(Dmcm ‚àíum+1) + xT
p (Cp‚àí1xp‚àí1 + Dp‚àí1up‚àí1 + cp ‚àíup)
(2.10)
=
(xT
m + uT
m+1Bm) cm ‚àíxT
m+1um+1 + xT
p cp
= xT
mcm + xT
p cp ‚â§0.
Thus F(y) Ã∏> 0, which completes the proof.
‚äì‚äî
We are now ready to prove our main result of this section, the Reid roundabout
theorem for symplectic systems (SDS), which states several conditions which are
equivalent to the positivity of the functional F deÔ¨Åned in (2.56). We recall that
the Riccati operator Rk[Q] is given by (2.52), Pk[Q] is given by (2.53), and the
controllability matrix Gk is deÔ¨Åned in (2.59).

2.3
Riccati Equation and Quadratic Functional
105
Theorem 2.36 (Reid Roundabout Theorem) The following statements are equiv-
alent.
(i) The quadratic functional F(y) > 0 for all admissible sequences y =
x
u

with
x0 = 0 = xN+1 and x Ã∏‚â°0.
(ii) System (SDS) is disconjugate on [0, N + 1] according to DeÔ¨Ånition 2.18.
(iii) No solution y =
x
u

of (SDS) with x0 = 0 has any generalized zero in the
interval (0, N + 1].
(iv) The principal solution Y [0] =
X[0]
U[0]

of (SDS) has no focal points in the interval
(0, N + 1], i.e., condition (2.37) holds for all k ‚àà[0, N]Z.
(v) The implicit Riccati equation Rk[Q] Gk = 0, k ‚àà[0, N]Z, has a symmetric
solution Q deÔ¨Åned on [0, N + 1]Z such that Pk[Q] ‚â•0 for all k ‚àà[0, N]Z.
Proof The statement (i) implies (ii) by Lemma 2.35, while (iii) follows from (ii)
trivially, and condition (iii) implies (iv) by Lemma 2.34. Now, assume that (iv)
holds. Let Y := Y [0] be the principal solution at k = 0 and let ÀúY =
 ÀúX
ÀúU

be the
associated solution of (SDS) at k = 0, i.e., ÀúX0 = I and ÀúU0 = 0. The matrix
Qk deÔ¨Åned by (2.40) is symmetric and satisÔ¨Åes the assumptions of Lemma 2.25,
so that Pk[Q] ‚â•0 holds. Moreover, Lemma 2.39 and condition (2.60) imply that
Rk[Q] Gk = 0, which completes the proof of (v). Suppose now that (v) is true
with some symmetric Q. Let y =
x
u

be admissible with x0 = 0 = xN+1. Then
Rk[Q] xk = 0 for all k ‚àà[0, N]Z by (2.60). From (2.67) in Lemma 2.32 we obtain
F(y) =
N

k=0
zT
k Pk[Q] zk ‚â•0.
To show positive deÔ¨Åniteness, assume that F(y) = 0 for some admissible y =
x
u

with x0 = 0 = xN+1. Then Pk[Q] zk = 0 for all k ‚àà[0, N]Z and (2.66) shows
that x ‚â°0. Thus F(y) > 0, showing (i). In conclusion, we have proven that the
statements (i) through (v) are equivalent.
‚äì‚äî
Remark 2.37 The proof of the implications (iv) ‚áí(v) ‚áí(i) shows that the
following more general result is true. The functional F is positive deÔ¨Ånite if and
only if there exists a conjoined basis Y = X
U
 of (SDS) with no focal points in the
interval (0, N + 1]. Indeed, for such a conjoined basis Y =
X
U

of (SDS) and the
corresponding symmetric Q in (2.40) we have Rk[Q] Xk = 0 for k ‚àà[0, N]Z. Then
for any admissible y =
x
u

with x0 = 0 = xN+1 we have by Lemma 2.33 that
xk ‚ààIm Xk for all k ‚àà[0, N + 1]Z. The positivity of the functional F now follows
from the Picone formula (Lemma 2.32) as in the proof of (v) ‚áí(i) in Theorem 2.36.
Conversely, the positivity of F implies condition (iv); hence, there indeed exists
a conjoined basis Y =
X
U

of (SDS) with no focal points in (0, N + 1], as we claim
in this remark.

106
2
Basic Theory of Symplectic Systems
Next we present a construction of an admissible pair for (2.57) for which F Ã∏‚â•0,
when kernel condition or P-condition in (2.37) are violated (compare with the
proof of Theorem 2.44 in Sect. 2.3.5). This result also shows a direct proof of the
implication (i) ‚áí(iv) in Theorem 2.36 above.
Proposition 2.38 Let Y =
X
U

be a conjoined basis of (SDS).
(i) If there exists m ‚àà[0, N]Z such that Ker Xm+1 Ã∏‚äÜKer Xm, i.e., there exists
Œ± ‚ààKer Xm+1 \ Ker Xm, then the pair y =
x
u

deÔ¨Åned by
xk :=

XkŒ±
0 ‚â§k ‚â§m,
0
m + 1 ‚â§k ‚â§N + 1,
uk :=

UkŒ±
0 ‚â§k ‚â§m,
0
m + 1 ‚â§k ‚â§N + 1,
is admissible on [0, N + 1]Z, x Ã∏‚â°0, and we have F(y) = ‚àíŒ±T X0U0Œ±.
(ii) If there exists m ‚àà[0, N]Z such that Ker Xm+1 ‚äÜKer Xm and Pm Ã∏‚â•0, i.e.,
there exists c ‚ààRn such that cT Pmc < 0, then for d := X‚Ä†
m+1Bmc the pair
y =
x
u

deÔ¨Åned by
xk :=

Xkd
0 ‚â§k ‚â§m,
0
m + 1 ‚â§k ‚â§N + 1,
uk :=
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
Ukd
0 ‚â§k ‚â§m ‚àí1,
Ukd ‚àíc
k = m,
0
m + 1 ‚â§k ‚â§N + 1,
is admissible on [0, N + 1]Z, x Ã∏‚â°0, and F(y) = ‚àíŒ±T X0U0Œ± + cT Pmc.
(iii) In particular, if Y = Y [0] is the principal solution of (SDS) at k = 0, then
F(y) = 0 holds in case (i), and F(y) < 0 holds in case (ii).
Proof We prove the statement (ii), the proof of (i) is similar. We have x0 = xN+1 =
0, xk+1 = Akxk + Bkuk for 0 ‚â§k ‚â§N with k Ã∏= m and
Amxm + Bmum = Xm+1d ‚àíBmc = 0 = xm+1,
because Xm+1X‚Ä†
m+1Bm = Bm by (4.1) and (4.2). Hence y =
x
u

is admissible.
Moreover, xm = Xmd = Pmc Ã∏= 0, which shows that x Ã∏‚â°0 (in case (i) we use
xm = XmŒ± Ã∏= 0, since Œ± Ã∏‚ààKer Xm). Using Lemma 2.30 and
Cm‚àí1xm‚àí1 + Dm‚àí1um‚àí1 = Umd = um + c,

2.3
Riccati Equation and Quadratic Functional
107
we obtain
F(y) =
N

k=0
xT
k+1{Ckxk + Dkuk ‚àíuk+1}
= xT
m{Cm‚àí1xm‚àí1 + Dm‚àí1um‚àí1 ‚àíum} = cT Xmd = cT Pmc < 0.
Hence F Ã∏‚â•0 and the proof is complete.
‚äì‚äî
The following result is a direct extension of the equivalence of conditions (i) and
(iv) in Theorem 2.36.
Theorem 2.39 Let Y be any conjoined basis of (SDS). Then Y has no forward
focal points in (0, N + 1] if and only if F(y) + dT XT
0 U0d > 0 for all admissible
y =
 xu

with x0 = X0d, xN+1 = 0, and x Ã∏‚â°0.
Proof The necessity follows from the Picone identity (Lemma 2.32) similarly as
the proof of the corresponding parts in Theorem 2.36. The sufÔ¨Åciency is a direct
consequence of Proposition 2.38.
‚äì‚äî
We conclude this subsection with a statement completing Theorem 2.36 with
further conditions equivalent to the positivity of the functional F in (2.57). In
contrast with conditions (iv) and (v) in the previously mentioned result, we now
consider a conjoined basis Y with Xk invertible on the whole interval [0, N + 1]Z
and the explicit Riccati equation (2.52).
Theorem 2.40 The following statements are equivalent.
(i) The quadratic functional F is positive deÔ¨Ånite, i.e., condition (i) in Theo-
rem 2.36 holds.
(ii) There exists a conjoined basis Y of (SDS) with no forward focal points in
(0, N +1] such that Xk is invertible for all k ‚àà[0, N +1]Z, i.e., XkX‚àí1
k+1Bk ‚â•0
for k ‚àà[0, N]Z.
(iii) The explicit Riccati equation (2.52), k ‚àà[0, N]Z, has a symmetric solution Qk
on [0, N + 1]Z such that
Ak + BkQk is invertible and (Ak + BkQk)‚àí1Bk ‚â•0,
k ‚àà[0, N]Z.
(2.68)
Proof Assume that (i) holds. It follows by a perturbation argument in [258,
Theorem 2(iii‚Äô)] or by [172, Theorem 7] that there exists Œ±
> 0 such that
F(y) + Œ± ‚à•x0‚à•2 > 0 for all admissible y =
x
u

with xN+1 = 0 and x Ã∏‚â°0.
Then, by Theorem 2.39, the conjoined basis Y of (SDS) starting with the initial
conditions X0 = (1/Œ±) I and U0 = I has no forward focal points in (0, N + 1].
Since X0 is invertible, the kernel condition in (2.37) implies that Xk is invertible
on [0, N + 1]Z and XkX‚àí1
k+1Bk ‚â•0 on [0, N]Z, as we claim in part (ii). Next,
if (ii) holds then we set Qk := UkX‚àí1
k
on [0, N + 1]Z, which satisÔ¨Åes condition

108
2
Basic Theory of Symplectic Systems
(iii) by the Riccati equivalence in Theorem 2.28. Finally, if (iii) holds, then
Pk[Q] = (Ak + BkQk)‚àí1Bk ‚â•0 on [0, N]Z and the Picone formula (2.67) in
Lemma 2.32 implies that the functional F is nonnegative deÔ¨Ånite, i.e., F(y) ‚â•0
for any admissible y =
x
u

with x0 = 0 = xN+1. If now F(y) = 0 for such
an admissible y, then Pk[Q] zk = 0 with zk := uk ‚àíQkxk on [0, N]Z, so that
(DT
k ‚àíBT
k Qk+1) xk+1 = xk on [0, N]Z by (2.66). From xN+1 = 0 we then get
xk = 0 for all k ‚àà[0, N + 1]Z, showing that the functional F is actually positive
deÔ¨Ånite, i.e., condition (i) holds.
‚äì‚äî
The Reid roundabout theorem has its analogy for the time-reversed symplectic
system (2.9).
Theorem 2.41 (Reid Roundabout Theorem for Time-Reversed System) The
following statements are equivalent:
(i) The quadratic functional
FR(y) :=
N

k=0
yT
k+1{ST ‚àí1
k
KS‚àí1
k
‚àíK} yk+1
(2.69)
=
N

k=0
{‚àíxk+1CkDT
k xk+1 + 2xT
k+1CkBT
k uk+1 ‚àíuT
k+1AkBT
k uk+1} < 0
for all y =
x
u

such that xk = DT
k xk+1 ‚àíBT
k uk+1 for k ‚àà[0, N]Z and such
that x0 = 0 = xN+1 and x Ã∏‚â°0.
(ii) System (2.9) is disconjugate on [0, N + 1], i.e., no solution of (2.9) has
more than one and no solution y =
x
u

of (2.9) with xN+1 = 0 has any
generalized zeros in the interval [0, N + 1). Here the interval [m, m + 1)
contains a generalized zero of a solution y =
x
u

of (2.9) if
xm+1 Ã∏= 0,
xm ‚ààIm BT
m,
and
xT
mB‚Ä†
mxm+1 ‚â§0.
(iii) No solution y =
x
u

of (2.9) with xN+1 = 0 has any generalized zero in the
interval [0, N + 1).
(iv) The solution Y =
X
U

of (2.9) with YN+1 =
 0
‚àíI

has no backward focal points
in the interval [0, N + 1), i.e., condition (2.48) holds for all k ‚àà[0, N]Z.
(v) The equation ÀúRk[Q] ÀúGk = 0, k ‚àà[0, N]Z, has a symmetric solution Q deÔ¨Åned
on on [0, N + 1]Z such that ÀúPk[Q] ‚â•0 for all k ‚àà[0, N]Z, where
ÀúRk[Q] := (QkBT
k ‚àíAT
k ) Qk+1 + (QkDT
k ‚àíCT
k ),
ÀúPk[Q] := BkAT
k ‚àíBkQkBT
k ,
ÀúGk :=
‚éõ
‚éù
N‚àí1
'
j=k+1
DT
j BT
N
N‚àí2
'
j=k+1
DT
j BT
N‚àí1 . . . DT
k+1BT
k+2 BT
k+1
‚éû
‚é†.

2.3
Riccati Equation and Quadratic Functional
109
Proof The proof is based on the transformation of the time-reversed system to
a standard symplectic system according to Example 2.5, to which Theorem 2.36
is applied.
‚äì‚äî
Remark 2.42 Similarly to Remark 2.37, condition (i) in Theorem 2.41 is equivalent
with the existence of a conjoined basis Y =
X
U

of (2.9) with no backward focal
points in the interval [0, N + 1).
Actually, all the statements in Theorems 2.36 and 2.41 are mutually equivalent,
as we show in the last statement of this subsection.
Theorem 2.43 The statements (i) of Theorem 2.36 and (i) of Theorem 2.41 are
equivalent.
Proof Assume that (i) of Theorem 2.36 holds and let y = x
u
 be admissible for
the functional FR in (2.69) corresponding to (2.9), i.e., xk = DT
k xk+1 ‚àíBT
k uk+1
for k ‚àà[0, N]Z, x0 = 0 = xN+1, and x Ã∏‚â°0. Put y‚àó
k =
x‚àó
k
u‚àó
k

:= S‚àí1
k yk+1 for
k ‚àà[0, N]Z and x‚àó
N+1 := 0. Then x‚àó
k = DT
k xk+1 ‚àíBT
k uk+1 = xk for all k ‚àà[0, N]Z
and x‚àó
N+1 = 0 = xN+1. It follows that x‚àó
k+1 = xk+1 = Akx‚àó
k + Bku‚àó
k holds for all
k ‚àà[0, N]Z and (i) of Theorem 2.36 implies 0 < F(y‚àó) = ‚àíFR(y). This shows
that (i) of Theorem 2.41 is satisÔ¨Åed. Conversely, if (i) of Theorem 2.41 is true, then
for an admissible y =
x
u

for F such that x0 = 0 = xN+1 and x Ã∏‚â°0, we put
y‚àó
k+1 := Skyk for k ‚àà[0, N]Z and y‚àó
0 := 0. Similarly as above, it follows by (i) of
Theorem 2.41 that 0 > FR(y‚àó) = ‚àíF(y), so that (i) of Theorem 2.36 holds, which
completes the proof.
‚äì‚äî
2.3.5
Nonnegative Quadratic Functional
In Sect. 1.3, we discussed the importance of the nonnegativity and positivity of
discrete quadratic functionals in the second-order necessary and sufÔ¨Åcient optimal-
ity conditions for discrete calculus of variations and optimal control problems (in
particular, Theorems 1.26 and 1.32 contain necessary optimality conditions and
Theorems 1.28 and 1.33 contain sufÔ¨Åcient optimality conditions). Along with the
results on the positivity of the discrete quadratic functional F in (2.57) associated
with symplectic system (SDS) in Sect. 2.3.4, we now present conditions, which
are equivalent with the nonnegativity of F. We recall the deÔ¨Ånition of the matrix
Pk := XkX‚Ä†
k+1Bk in (2.37), and also deÔ¨Åne the new matrices
Mk := (I ‚àíXk+1X‚Ä†
k+1) Bk,
Tk := I ‚àíM‚Ä†
k Mk.
(2.70)
Note that Tk is symmetric. By Lemma 2.15 we know that Mk = 0 (and hence
Tk = I) on [0, N]Z if and only if the kernel condition
Ker Xk+1 ‚äÜKer Xk,
k ‚àà[0, N]Z,
(2.71)

110
2
Basic Theory of Symplectic Systems
holds. We note that the matrices Mk and Tk will be used in Sect. 4.1 in the deÔ¨Ånition
of the multiplicities of forward focal points of Y (see DeÔ¨Ånition 4.1).
Theorem 2.44 The quadratic functional F is nonnegative, i.e., F(y) ‚â•0 for every
admissible y =
x
u

with x0 = 0 = xN+1 if and only if the principal solution
Y [0] =
X[0]
U[0]

of (SDS) satisÔ¨Åes the image condition
xk ‚ààIm X[0]
k ,
k ‚àà[0, N + 1]Z,
(2.72)
for every admissible y =
x
u

with x0 = 0 = xN+1 and the P-condition
TkPkTk ‚â•0,
k ‚àà[0, N]Z.
(2.73)
The main difference between the statements of Theorem 2.36 (condition (iv))
and the above theorem lies in the relationship between the kernel condition in (2.71)
and the image condition (2.72). Of course, (2.71) implies (2.72), which follows
from Lemma 2.33. The converse is not in general true, however. Furthermore, under
(2.71) the P-condition (2.73) reduces to the one in (2.37).
Before presenting the proof of Theorem 2.44, we state several additional
properties of the matrices Pk, Mk, and Tk and derive a version of the Picone formula
(see Lemma 2.32) under the image condition (2.72). The properties of Moore-
Penrose inverses (see Sect. 1.6.2) imply that
XT
k+1Mk = 0,
M‚Ä†
k Xk+1 = 0,
MkTk = 0,
BkTk = Xk+1X‚Ä†
k+1BkTk.
(2.74)
With a given conjoined basis Y = X
U
 we associate on [0, N + 1]Z the matrix
Qk := UkX‚Ä†
k + (UkX‚Ä†
k)T (I ‚àíXkX‚Ä†
k).
(2.75)
Lemma 2.45 Let Y =
X
U

be a conjoined basis of (SDS), Qk be deÔ¨Åned by (2.75),
and let y =
x
u

be an admissible pair satisfying the image condition (2.72). Then
Y, Q, and y satisfy the following conditions.
(i) The matrix Qk is symmetric and QkXk = UkX‚Ä†Xk on [0, N + 1]Z.
(ii) The matrix TkPkTk is symmetric for all k ‚àà[0, N]Z.
(iii) If zk := uk ‚àíQkxk, then Mkzk = 0 (i.e., zk = Tkzk) on [0, N]Z.
(iv) We have the Picone identity
xT
k CT
k Akxk + 2 xT
k CT
k Bkuk + uT
k DT
k Bkuk = (xT
k Qkxk) + zT
k Pkzk,
(2.76)
{DT
k ‚àíBT
k Qk+1} xk+1 = xk + Pk zk,
(2.77)

2.3
Riccati Equation and Quadratic Functional
111
for all k ‚àà[0, N]Z, and consequently
F(y) =
N

k=0
zT
k Pkzk =
N

k=0
zT
k TkPkTkzk.
(2.78)
Proof The matrix Qk in (2.75) is symmetric by the symmetry of XT
k Uk and XkX‚Ä†
k.
The identity QkXk = UkX‚Ä†Xk follows from (2.75) trivially. By using the time-
reversed symplectic system (2.10) and the fourth identity in (2.74), we obtain
PkTk = (DT
k ‚àíBT
k Qk+1) BkTk.
(2.79)
Since DT
k Bk is symmetric, it follows that the matrix TkPkTk is symmetric on [0, N]Z
as well. Since xk ‚ààIm Xk, we have xk = XkX‚Ä†
kxk on [0, N + 1]Z. Then we have
Mkuk = (I ‚àíXk+1X‚Ä†
k+1) (xk+1 ‚àíAkxk)
= (I ‚àíXk+1X‚Ä†
k+1) (Xk+1X‚Ä†
k+1xk+1 ‚àíAkXkX‚Ä†
kxk)
= (I ‚àíXk+1X‚Ä†
k+1) (BkUk ‚àíXk+1) X‚Ä†
kxk
= MkUkX‚Ä†
kxk = MkUkX‚Ä†
kXkX‚Ä†
kxk = MkQkxk
on [0, N]Z. This shows that Mkzk = 0 on [0, N]Z. Finally, formulas (2.76) and
(2.77) follow from the Picone formula in Lemma 2.32; since for the matrix Qk in
(2.75) we have XT
k+1Rk[Q] Xk = 0 on [0, N]Z by Lemma 2.58(ii).
‚äì‚äî
Proof of Theorem 2.44 Let Y := Y [0] be the principal solution of (SDS) at k = 0,
i.e., X0 = 0 and U0 = I. First we show that conditions (2.72) and (2.73) are
necessary for the nonnegativity of the functional F. Thus, assume that F(y) ‚â•0
for every admissible y =
x
u

with x0 = 0 = xN+1. Assume that there exists
an admissible y =
x
u

with x0 = 0 = xN+1 and m ‚àà[1, N ‚àí1]Z such that
xk ‚ààIm Xk for all k ‚àà[0, m]Z but xm+1 Ã∏‚ààIm Xm+1. First we observe that the n√ón
matrices
K := XT
m+1Xm+1 + UT
m+1Um+1 > 0,
S‚Ä≤ := K‚àí1UT
m+1Mm+1
satisfy the equations
Xm+1S‚Ä≤ = 0,
Um+1S‚Ä≤ = Mm.
(2.80)
Indeed, for the 2n √ó 2n matrix, Z deÔ¨Åned below has the property
Z :=

K‚àí1XT
m+1 K‚àí1UT
m+1
‚àíUT
m+1
XT
m+1

,
Z‚àí1 =
Xm+1 ‚àíUm+1K‚àí1
Um+1 Xm+1K‚àí1

,

112
2
Basic Theory of Symplectic Systems
so that
Z
 0
Mm

=
S‚Ä≤
0

,
 0
Mm

= Z‚àí1
S‚Ä≤
0

=
Xm+1S‚Ä≤
Um+1S‚Ä≤

.
Next we prove that MT
mxm+1 Ã∏= 0. Assume that MT
mxm+1 = 0. Then
0 = MT
mxm+1 = BT
m(I ‚àíXm+1X‚Ä†
m+1) xm+1
= BT
m(I ‚àíXm+1X‚Ä†
m+1) (AmXmŒ± + Bmum)
= BT
m(I ‚àíXm+1X‚Ä†
m+1) [(Xm+1 ‚àíBmUm) Œ± + Bmum]
= BT
m(I ‚àíXm+1X‚Ä†
m+1)2Bm(um ‚àíUmŒ±) = MT
mMm(um ‚àíUmŒ±).
This implies that ‚à•Mm(um ‚àíUmŒ±)‚à•2 = 0, i.e., Mm(um ‚àíUmŒ±) = 0. Then in turn
0 = Mm(um ‚àíUmŒ±) = (I ‚àíXm+1X‚Ä†
m+1) (Bmum ‚àíBmUmŒ±)
= (I ‚àíXm+1X‚Ä†
m+1) [ xm+1 ‚àíAmXmŒ± ‚àí(Xm+1 ‚àíAmXm) Œ± ]
= (I ‚àíXm+1X‚Ä†
m+1) (xm+1 ‚àíXm+1Œ±) = (I ‚àíXm+1X‚Ä†
m+1) xm+1.
Therefore, xm+1
= Xm+1X‚Ä†
m+1xm+1
‚ààIm Xm+1, which is a contradiction.
Therefore, MT
mxm+1 Ã∏= 0 must hold. Now we deÔ¨Åne the sequence Àúy =
Àúx
Àúu

as
follows:
Àúxk :=

Xk(Œ± + ÀúŒ±), k ‚àà[0, m]Z,
xk,
k ‚àà[m + 1, N + 1]Z,
Àúuk :=
‚éß
‚é™‚é®
‚é™‚é©
Uk(Œ± + ÀúŒ±), k ‚àà[0, m ‚àí1]Z,
um + Um ÀúŒ±, k = m,
uk,
k ‚àà[m + 1, N + 1]Z,
where ÀúŒ± := t S‚Ä≤MT
mxm+1 with t ‚ààR, t Ã∏= 0. Now Àúx0 = X0(Œ± + ÀúŒ±) = 0 and
ÀúxN+1 = xN+1 = 0. For k ‚àà[0, m ‚àí1]Z we have
Ak Àúxk + Bk Àúuk = (AkXk + BkUk) (Œ± + ÀúŒ±) = Xm+1(Œ± + ÀúŒ±) = Àúxk+1,
for k ‚àà[m + 1, N]Z we have
Ak Àúxk + Bk Àúuk = Akxk + Bkuk = xk+1 = Àúxk+1,

2.3
Riccati Equation and Quadratic Functional
113
and for k = m we have
Ak Àúxk + Bk Àúuk = AmXm(Œ± + ÀúŒ±) + Bm(um + Um ÀúŒ±)
= Amxm + Bmum + (AmXm + BmUm) ÀúŒ±
= xm+1 + Xm+1 ÀúŒ± = xm+1 = Àúxm+1,
because Xm+1 ÀúŒ± = t Xm+1S‚Ä≤MT
mxm+1 = 0 by (2.80). Therefore, Àúy is admissible
with Àúx0 = 0 = ÀúxN+1. It follows by Lemma 2.30 and by splitting the total sum over
[0, N]Z into four sums over the sets [0, m ‚àí2]Z, {m ‚àí1}, {m}, [m + 1, N]Z that
F( Àúy) =
 m‚àí2

k=0
+
m‚àí1

k=m‚àí1
+
m

k=m
+
N

k=m+1
 
ÀúxT
k+1(Ck Àúxk + Dk Àúuk ‚àíÀúuk+1)
= ÀúxT
m(Cm‚àí1 Àúxm‚àí1 + Dm‚àí1 Àúum‚àí1 ‚àíÀúum) + ÀúxT
m+1(Cm Àúxm + Dm Àúum ‚àíÀúum+1)
+
N

k=m+1
ÀúxT
k+1(Ck Àúxk + Dk Àúuk ‚àíÀúuk+1)
= F1(Œ±) + F2(Œ±, ÀúŒ±),
where
F1(Œ±) := xT
m+1(CmXmŒ± + Dmum ‚àíum+1) + Œ±T XT
m(UmŒ± ‚àíum)
+
N

k=m+1
xT
k+1(Ckxk + Dkuk ‚àíuk+1),
F2(Œ±, ÀúŒ±) := ÀúŒ±T XT
m(UmŒ± ‚àíum) + xT
m+1Um+1 ÀúŒ±,
i.e., the term F1(Œ±) does not depend on ÀúŒ± (and hence on t), while the term F2(Œ±, ÀúŒ±)
does depend on ÀúŒ± (and hence on t). Since Xm+1 ÀúŒ± = 0, Xm = DT
mXm+1 ‚àíBT
mUm+1
by (2.10), and UT
m+1Xm+1 is symmetric, the Ô¨Årst term in F2(Œ±, ÀúŒ±) is equal to
ÀúŒ±T XT
m(UmŒ± ‚àíum) = ÀúŒ±T (XT
m+1Dm ‚àíUT
m+1Bm) (UmŒ± ‚àíum)
= ÀúŒ±T UT
m+1(Bmum ‚àíBmUmŒ±)
= ÀúŒ±T UT
m+1[ xm+1 ‚àíAmXmŒ± ‚àí(Xm+1 ‚àíAmXm) Œ±]
= ÀúŒ±T UT
m+1(xm+1 ‚àíXm+1Œ±) = ÀúŒ±T UT
m+1xm+1.

114
2
Basic Theory of Symplectic Systems
Hence, by (2.80) we get the expression
F2(Œ±, ÀúŒ±) = ÀúŒ±T UT
m+1xm+1 + xT
m+1Um+1 ÀúŒ± = 2t xT
m+1UT
m+1S‚Ä≤MT
mxm+1
= 2t xT
m+1MmMT
mxm+1 = 2t ‚à•MT
mxm+1‚à•2,
as well as
F( Àúy) = F1(Œ±) + F2(Œ±, ÀúŒ±) = F1(Œ±) + 2t ‚à•MT
mxm+1‚à•2.
But since MT
mxm+1 Ã∏= 0, it follows that F( Àúy) ‚Üí‚àí‚àûas t ‚Üí‚àí‚àû, which
contradicts the assumed nonnegativity of the functional F.
Next we prove that the P-condition (2.73) is necessary for the nonnegativity of
F. Suppose that there exists c ‚ààRn, c Ã∏= 0, such that cT TmPmTmc < 0 for some
m ‚àà[0, N]Z. Set d := X‚Ä†
m+1BmTmc and deÔ¨Åne the pair y =
x
y

by
xk :=
‚éß
‚é®
‚é©
Xkd,
k ‚àà[0, m ‚àí1]Z,
PmTmc, k = m,
0,
k ‚àà[m + 1, N + 1]Z,
uk :=
‚éß
‚é®
‚é©
Ukd,
k ‚àà[0, m ‚àí1]Z,
‚àíAT
m(Dm ‚àíQm+1Bm) Tmc, k = m,
0,
k ‚àà[m + 1, N]Z,
where Qm+1 is deÔ¨Åned by (2.75). Then y is admissible for k ‚àà[0, m ‚àí2]Z as well
as for k ‚àà[m + 1, N]Z. For k = m ‚àí1 we have
Am‚àí1xm‚àí1 + Bm‚àí1um‚àí1 = (Am‚àí1Xm‚àí1 + Bm‚àí1Um‚àí1) d = Xmd
= XmX‚Ä†
m+1BmTmc = PmTmc = xm,
while for k = m we use (1.145) and (2.79) to obtain
Amxm + Bmum = AmPmTmc ‚àíBmAT
m(Dm ‚àíQm+1Bm) Tmc
= Am(PmTm ‚àíPmTm) c = 0 = xm+1.
Thus, y is admissible for F. Moreover, x0 = X0d = 0 and xN+1 = 0. To compute
the value of F(y) we use Lemma 2.30, (2.79), and (2.74) to obtain
F(y) =
N

k=0
xT
k+1(Ckxk + Dkuk ‚àíuk+1)
=
m‚àí1

k=0
xT
k+1(Ckxk + Dkuk ‚àíuk+1) = xT
m(Cm‚àí1xm‚àí1 + Dm‚àí1um‚àí1 ‚àíum)

2.3
Riccati Equation and Quadratic Functional
115
= dT XT
m
!(Cm‚àí1Xm‚àí1 + Dm‚àí1Um‚àí1) d + AT
m(Dm ‚àíQm+1Bm) Tmc"
= dT XT
mUmd + cT TmP T
m AT
m(Dm ‚àíQm+1Bm) Tmc
= dT XT
mUmd + cT TmBT
m(X‚Ä†
m+1)T (XT
m+1 ‚àíUT
mBT
m) (Dm ‚àíQm+1Bm) Tmc
= dT XT
mUmd + cT Tm(BT
mDm ‚àíBT
mQm+1Bm) Tmc ‚àídT UT
mPmTmc
= cT TmPmTmc < 0.
This contradicts the assumed nonnegativity of the functional F.
The remaining part of the proof is devoted to showing that (2.72) and (2.73) are
sufÔ¨Åcient conditions for the nonnegativity of F. Thus, let y =
x
u

be admissible
with x0 = 0 = xN+1. Then by (2.72) the sequence y satisÔ¨Åes xk ‚ààIm Xk for all
k ‚àà[0, N + 1]Z. In turn, the Picone formula (2.78) in Lemma 2.45 together with
condition (2.73) imply that
F(y) =
N

k=0
zT
k Pkzk ‚â•0.
The proof of Theorem 2.44 is complete.
‚äì‚äî
Remark 2.46 In view of the notion of multiplicities of focal points introduced in
DeÔ¨Ånition 4.1 in Sect. 4.1, the statement in Theorem 2.44 says that the functional
F is nonnegative if and only if the principal solution Y [0] of (SDS) at k = 0 has no
forward focal points in the intervals (k, k + 1) for every k ‚àà[0, N]Z and the image
condition (2.72) holds.
We conclude this subsection with the analysis of the image condition (2.72). It
will be further utilized in Sects. 5.4.1 and 5.4.2. We recall the deÔ¨Ånition of the matrix
Mk in (2.70) and its properties in (2.74).
Lemma 2.47 Suppose that Y is a conjoined basis of system (SDS) and Ô¨Åx an index
k ‚àà[0, N]Z. Then we have
(i) the condition xk+1 ‚ààIm Xk+1 implies that MT
k xk+1 = 0,
(ii) the equalities xk+1 = Akxk + Bkuk, MT
k xk+1 = 0, and xk ‚ààIm Xk imply that
xk+1 ‚ààIm Xk+1.
Proof First, the condition xk+1 = Xk+1c ‚ààIm Xk+1 implies by (2.74) that
MT
k xk+1 = MT
k Xk+1c = 0. Hence, (i) is true. Next, if xk+1 = Akxk + Bkuk
holds together with conditions xk = Xkc ‚ààIm Xk and MT
k xk+1 = 0, then
0 = MT
k xk+1 = MT
k (AkXkc + Bkuk) = MT
k [Xk+1c + Bk(uk ‚àíUkc)]
= MT
k Bk(uk ‚àíUkc) = BT
k (I ‚àíXk+1X‚Ä†
k+1)T (I ‚àíXk+1X‚Ä†
k+1) Bk(uk ‚àíUkc)
= MT
k Mk(uk ‚àíUkc),

116
2
Basic Theory of Symplectic Systems
so that
0 = Mk(uk ‚àíUkc) = (I ‚àíXk+1X‚Ä†
k+1) Bk(uk ‚àíUkc).
Therefore, the equality
xk+1 = Xk+1c + Bk(uk ‚àíUkc) = Xk+1c + Xk+1X‚Ä†
k+1Bk(uk ‚àíUkc) ‚ààIm Xk+1
holds, which proves part (ii).
‚äì‚äî
The following result provides a characterization of the image condition in terms
of the matrices Mk. The importance of this condition is highlighted in Theorem 2.44,
where we discuss the nonnegativity of the quadratic functional F. Note that for
x0 = 0 = xN+1, the two inclusions x0 ‚ààIm X0 and xN+1 ‚ààIm XN+1 are satisÔ¨Åed
trivially.
Lemma 2.48 Suppose that Y is a conjoined basis of the symplectic system (SDS)
and let y = (x, u) be admissible with x0 = 0 = xN+1. Then
xk ‚ààIm Xk
for all k ‚àà[1, N]Z
(2.81)
holds if and only if
MT
k xk+1 = 0
for all k ‚àà[0, N ‚àí1]Z.
(2.82)
Proof First, (2.81) implies (2.82) by Lemma 2.47(i). Next, suppose that y = (x, u)
is admissible, x0 = 0 = xN+1, and (2.82) holds. Then x0 = 0 ‚ààIm X0, and
inductively we get by Lemma 2.47(ii) that xk+1 ‚ààIm Xk+1 for all k ‚àà[0, N ‚àí1]Z,
i.e., (2.81) is satisÔ¨Åed.
‚äì‚äî
2.3.6
Quadratic Functionals with General Endpoints
In this subsection we present extensions of the equivalence (i) and (iv) in Theo-
rem 2.36 (positivity of F) and of Theorem 2.44 (nonnegativity of F) to quadratic
functionals with separated and jointly varying (or coupled) boundary conditions.
Thus, we consider the matrices R0, R‚àó
0, RN+1, R‚àó
N+1, 0, N+1 ‚ààRn√ón satisfying
R‚àó
0RT
0 = R0(R‚àó
0)T ,
rank (R‚àó
0, R0) = n,
R‚àó
N+1RT
N+1 = RN+1(R‚àó
N+1)T ,
rank(R‚àó
N+1, RN+1) = n,
0 := ‚àíR‚Ä†
0R‚àó
0R‚Ä†
0R0,
N+1 := R‚Ä†
N+1R‚àó
N+1R‚Ä†
N+1RN+1,
‚é´
‚é™‚é¨
‚é™‚é≠
(2.83)

2.3
Riccati Equation and Quadratic Functional
117
where the matrices 0 and N+1 are symmetric. We will investigate the deÔ¨Åniteness
of the quadratic functional
G(y) := xT
0 0 x0 + xT
N+1 N+1 xN+1 + F(y),
(2.84)
over admissible sequences y = (x, u) satisfying the separated boundary conditions
x0 ‚ààIm RT
0 ,
xN+1 ‚ààIm RT
N+1,
(2.85)
where F(y) is the quadratic functional deÔ¨Åned in (2.57). We will also utilize
a special conjoined basis ¬ØY =

¬ØX
¬ØU

of (SDS), called the natural conjoined basis,
which is given by the initial conditions ¬ØY0 = (‚àíR0, R‚àó
0)T , i.e.,
¬ØX0 = ‚àíRT
0 ,
¬ØU0 = (R‚àó
0)T .
(2.86)
Note that for R0 = 0 = RN+1 and R‚àó
0 = I = R‚àó
N+1 the separated boundary
conditions (2.85) reduce to the Dirichlet boundary conditions x0 = 0 = xN+1, and
the natural conjoined basis ¬ØY reduces to the principal solution Y [0] at k = 0.
Theorem 2.49 (Nonnegativity for Separated Endpoints)
Assume that the con-
ditions in (2.83) hold. Then the following statement are equivalent.
(i) The quadratic functional G in (2.84) is nonnegative over the separated end-
points (2.85), i.e., G(y) ‚â•0 for all admissible sequences y = (x, u) satisfying
(2.85).
(ii) The natural conjoined basis ¬ØY of (SDS), given by the initial conditions (2.86),
satisÔ¨Åes the following three conditions: the image condition
xk ‚ààIm ¬ØXk,
k ‚àà[0, N + 1]Z,
(2.87)
for every admissible y = (x, u) satisfying (2.85), the P-condition (2.73), and
the Ô¨Ånal endpoint inequality
N+1 + ¬ØUN+1 ¬ØX‚Ä†
N+1 ‚â•0
on Im RT
N+1 ‚à©Im ¬ØXN+1.
(2.88)
Proof The result is proven by a matrix diagonalization argument in [50, Theorem 2].
Alternatively, we can use the Picone identity (Lemma 2.45) or the transformation
of this problem to the Dirichlet endpoints described in Sect. 5.2.2 and apply
Theorem 2.44.
‚äì‚äî
For the positivity of the functional G, we use the appropriate strengthening of the
conditions in Theorem 2.49.
Theorem 2.50 (Positivity for Separated Endpoints)
Assume that the conditions
in (2.83) hold. Then the following statement are equivalent.

118
2
Basic Theory of Symplectic Systems
(i) The quadratic functional G in (2.84) is positive over the separated endpoints
(2.85), i.e., G(y) > 0 for all admissible sequences y = (x, u) satisfying (2.85)
and x Ã∏‚â°0.
(ii) The natural conjoined basis ¬ØY of (SDS), given by the initial conditions (2.86),
has no forward focal points in the interval (0, N + 1] and satisÔ¨Åes the Ô¨Ånal
endpoint inequality
N+1 + ¬ØUN+1 ¬ØX‚Ä†
N+1 > 0
on Im RT
N+1 ‚à©Im ¬ØXN+1.
(2.89)
Proof The result is proven by using the Picone formula (Lemma 2.32) in [50,
Theorem 2]. Alternatively, we can use the transformation of this problem to the
Dirichlet endpoints described in Sect. 5.2.2 and apply the equivalence of conditions
(i) and (iv) in Theorem 2.36.
‚äì‚äî
Remark 2.51 The Ô¨Ånal endpoint inequality in (2.88) is equivalent to
¬ØXT
N+1(N+1 ¬ØXN+1 + ¬ØUN+1) ‚â•0
on Ker [(I ‚àíR‚Ä†
N+1RN+1) ¬ØXN+1].
(2.90)
Similarly, the Ô¨Ånal endpoint inequality in (2.89) is equivalent to (2.90) together with
the condition
Ker [R‚Ä†
N+1RN+1(N+1 ¬ØXN+1 + ¬ØUN+1)]
‚à©Ker [(I ‚àíR‚Ä†
N+1RN+1) ¬ØXN+1] ‚äÜKer ¬ØXN+1.

(2.91)
These conditions are used in [174, Theorem 2] and [181, Theorem 5] (with the
matrix M := I ‚àíR‚Ä†
N+1RN+1).
For the case of joint (or coupled) boundary conditions, we consider the matrices
R1, R2,  ‚ààR2n√ó2n satisfying
R1RT
2 = R2RT
1 ,
rank(R1, R2) = 2n,
 := R‚Ä†
2R1R‚Ä†
2R2,

(2.92)
where the matrix  is symmetric. We will investigate the deÔ¨Åniteness of the
quadratic functional
G(y) :=
 x0
xN+1
T

 x0
xN+1

+ F(y),
(2.93)
over admissible sequences y = (x, u) satisfying the joint boundary conditions
 x0
xN+1

‚ààIm RT
2 ,
(2.94)

2.3
Riccati Equation and Quadratic Functional
119
where F(y) is the quadratic functional deÔ¨Åned in (2.57). We note that for the choice
of R1 = diag{R‚àó
0, R‚àó
N+1} and R2 = diag{R0, RN+1} the joint boundary conditions
(2.94) reduce to the separated boundary conditions (2.85). Also, for the choice of
R1 = I2n and R2 = 02n, the joint boundary conditions (2.94) reduce to the Dirichlet
boundary conditions x0 = 0 = xN+1.
The results below are formulated in terms of the principal solution Y [0] (SDS) at
k = 0 and the associated conjoined basis ÀúY, which are given by the initial conditions
Y [0]
0
= (0, I)T ,
ÀúY0 = (I, 0)T ,
(2.95)
and which form the symplectic fundamental matrix Z = ( ÀúY, Y [0]) of (SDS) with
Z0 = I2n. Then we deÔ¨Åne the 2n √ó 2n matrices
Xk :=

0
I
X[0]
k
ÀúXk

,
Uk :=

‚àíI
0
U[0]
k
ÀúUk

,
k ‚àà[0, N + 1]Z.
(2.96)
Theorem 2.52 (Nonnegativity for Joint Endpoints)
Assume that the conditions
in (2.92) hold. Then the following statement are equivalent.
(i) The quadratic functional G in (2.93) is nonnegative over the joint endpoints
(2.94), i.e., G(y) ‚â•0 for all admissible sequences y = (x, u) satisfying (2.94).
(ii) The principal solution Y [0] of (SDS) together with the associated conjoined
basis ÀúY, given by the initial conditions (2.95), satisÔ¨Åes the following three
conditions: the image condition
xk ‚àíÀúXkx0 ‚ààIm X[0]
k ,
k ‚àà[0, N + 1]Z,
(2.97)
for every admissible y = (x, u) satisfying (2.94), the P-condition (2.73), and
the Ô¨Ånal endpoint inequality
 + UN+1X ‚Ä†
N+1 ‚â•0
on Im RT
2 ‚à©Im XN+1,
(2.98)
where XN+1 and UN+1 are deÔ¨Åned in (2.96).
Proof The result is proven in [174, Theorem 2] by transforming this problem to the
separated endpoints (see Sect. 5.2.2) and applying Theorem 2.49.
‚äì‚äî
Theorem 2.53 (Positivity for Joint Endpoints)
Assume that the conditions in
(2.83) hold. Then the following statement are equivalent.
(i) The quadratic functional G in (2.93) is positive over the joint endpoints (2.94),
i.e., G(y) > 0 for all admissible sequences y = (x, u) satisfying (2.94) and
x Ã∏‚â°0.
(ii) The principal solution Y [0] of (SDS) has no forward focal points in the interval
(0, N + 1] and satisÔ¨Åes together with the associated conjoined basis ÀúY, given

120
2
Basic Theory of Symplectic Systems
by the initial conditions (2.95), the Ô¨Ånal endpoint inequality
 + UN+1X ‚Ä†
N+1 > 0
on Im RT
2 ‚à©Im XN+1,
(2.99)
where XN+1 and UN+1 are deÔ¨Åned in (2.96).
Proof The result is proven in [181, Theorem 10] by transforming this problem to
the separated endpoints (see Sect. 5.2.2) and applying Theorem 2.50.
‚äì‚äî
Further conditions, which are equivalent to the positivity and nonnegativity of
the quadratic functionals G over the separated or joint endpoints (2.85) or (2.94),
are discussed in Sect. 2.7.
2.4
Riccati-Type Inequalities
In this section we present the results concerning inequalities involving solutions
of the Riccati difference equation (2.52) or solutions of a discrete time inequality
involving the Riccati operator Rk[Q].
2.4.1
Inequalities for Riccati-Type Quotients
This subsection contains a comparison result for solutions of two discrete symplec-
tic systems and the corresponding Riccati-type quotients. It is a generalization of
the corresponding result for linear Hamiltonian difference systems (2.15) known in
[51, Theorem 1]. Therefore, with system (2.15) we consider another system of the
same form

xk
uk

= J Hk
xk+1
uk

,
(2.100)
where
Hk = HT
k ,
Hk =
‚àíCk AT
k
Ak
Bk

,
det(I ‚àíAk) Ã∏= 0.
(2.101)
Theorem 2.54 (Riccati Inequality for Two Hamiltonian Systems) Let us assume
that the coefÔ¨Åcients of systems (2.15) and (2.100) satisfy (2.16) and (2.101) and
Hk ‚â•Hk,
Bk ‚â•BkB‚Ä†
k Bk,
Ker Bk ‚äÜKer Bk,
k ‚àà[0, N]Z.
(2.102)
Let Y and Y be conjoined bases of systems (2.15) and (2.100), respectively, and
that Qk and Qk are symmetric with XT
k QkXk = UT
k Xk and XT
k QkXk = UT
k Xk

2.4
Riccati-Type Inequalities
121
for k ‚àà[0, N + 1]Z. If Im X0 ‚äÜIm X0 and XT
0 (Q0 ‚àíQ0) XT
0 ‚â•0, and if the
conjoined basis Y has no forward focal points in (0, N + 1], then Y has no forward
focal points in (0, N + 1] either and
Im Xk ‚äÜIm Xk,
XT
k (Qk ‚àíQk) XT
k ‚â•0,
k ‚àà[0, N + 1]Z.
Below we present an extension of Theorem 2.54 to symplectic systems. Hence,
with system (SDS) we consider another discrete symplectic system
yk+1 = Sk yk,
(2.103)
where
ST
k J Sk = J ,
Sk =
Ak Bk
Ck Dk

.
Let F be the discrete quadratic functional, as in (2.57) and (2.63), corresponding to
symplectic system (2.103) with the associated symmetric matrices Ek and Gk, which
are deÔ¨Åned in a parallel way as the matrices Ek and Gk in (2.64). Admissible pairs
(x, u) are now deÔ¨Åned by the equation xk+1 = Akxk + Bkuk for k ‚àà[0, N]sZ,
and we shall emphasize this fact by saying that (x, u) is admissible with respect to
(A, B).
Theorem 2.55 (Riccati Inequality for Two Symplectic Systems) Let Y and Y be
any conjoined bases of (SDS) and (2.103), respectively. Furthermore, let Qk and
Qk be symmetric matrices such that XT
k QkXk = XT
k Uk and XT
k QkXk = XT
k Uk on
[0, N + 1]Z, and conditions
Im

Ak ‚àíAk Bk

‚äÜIm Bk
k ‚àà[0, N]Z,
(2.104)
Im X0 ‚äÜIm X0,
XT
0 (Q0 ‚àíQ0) X0 ‚â•0,
(2.105)
Gk ‚â§Gk
k ‚àà[0, N]Z,
(2.106)
hold. If Y has no forward focal points in (0, N + 1], then Y has no forward focal
points in (0, N + 1] either, and
Im Xk ‚äÜIm Xk,
XT
k (Qk ‚àíQk) Xk ‚â•0,
k ‚àà[0, N + 1]Z.
(2.107)
Before presenting the proof of Theorem 2.55, we need some preparatory
considerations. If Y is a conjoined basis of (SDS) satisfying kernel condition in
(2.37), then for any admissible (x, u) with x0 ‚ààIm X0, we have xk ‚ààIm Xk for all
k ‚àà[0, N + 1]Z and, by Lemma 2.32,
xT
k CT
k Akxk + 2 xT
k CT
k Bkuk + uT
k DT
k Bkuk = (xT
k ¬ØQkxk) + ¬ØwT
k Pk ¬Øwk,
(2.108)

122
2
Basic Theory of Symplectic Systems
where the symmetric matrix ¬ØQk := XkX‚Ä†
kUkX‚Ä†
k on [0, N +1]Z and the vector ¬Øwk :=
uk ‚àí¬ØQkxk. It is interesting to observe that once formula (2.108) is established, then
it is satisÔ¨Åed with any symmetric Qk such that XT
k QkXk = XT
k ¬ØQkXk. In order to
see this, we let xk = Xkck for k ‚àà[0, N + 1]Z and some ck ‚ààRn, and then
xT
k ¬ØQkxk = cT
k XT
k ¬ØQkXkck = cT
k XT
k QkXkck = xT
k Qkxk.
(2.109)
Proof of Theorem 2.55 Let Y be a conjoined basis of (SDS) with no focal points in
(0, N + 1]. We proceed in the proof by showing the following steps.
Claim 1 For all k ‚àà[0, N]Z, we have the inclusions
Im(Xk+1 ‚àíAkXk) ‚äÜIm Bk ‚äÜIm Xk+1.
The Ô¨Årst inclusion follows from the identity
Xk+1 ‚àíAkXk = (Ak ‚àíAk) Xk + BkUk
and from assumption (2.104). The second inclusion is equivalent to the kernel
condition Ker Xk+1 ‚äÜKer Xk, by Lemma 2.15, hence it is satisÔ¨Åed.
Claim 2 For all k ‚àà[0, N + 1]Z we have the inclusion
Im Xk ‚äÜIm Xk.
(2.110)
We shall prove it by induction. By assumption (2.105), the statement holds for
k = 0. Suppose that condition (2.110) holds for some k ‚àà[0, N]. In this case
Xk = XkX‚Ä†
kXk by (1.160), and then we have
Xk+1 = Xk+1 ‚àíAkXk + AkXkX‚Ä†
kXk
= Xk+1X‚Ä†
kXk + (Xk+1 ‚àíAkXk) ‚àí(Xk+1 ‚àíAkXk)X‚Ä†
kXk
= Xk+1X‚Ä†
kXk + (Xk+1 ‚àíAkXk) ‚àíBkUkX‚Ä†
kXk.
(2.111)
The inclusion Im Xk+1 ‚äÜIm Xk+1 then follows from Claim 1, since each of the
three terms in (2.111) above is contained in Im Xk+1.
Claim 3 If (x, u) is admissible with respect to (A, B), then xk+1 ‚àíAkxk ‚ààIm Bk
for all k ‚àà[0, N]Z, i.e., there exist vectors {uk}N
k=0 such that (x, u) is admissible
with respect to (A, B).

2.4
Riccati-Type Inequalities
123
This is a consequence of assumption (2.104), since
xk+1 ‚àíAkxk = (Ak ‚àíAk) xk + Bkuk ‚ààIm Bk.
Claim 4 If Y is a solution of (2.103), then
XT
k CT
k AkXk + 2 XT
k CT
k BkUk + UT
k DT
k BkUk = (XT
k Uk) = (XT
k QkXk).
(2.112)
This follows by a direct calculation.
Claim 5 For all k ‚àà[0, N] we have XT
k (Qk ‚àíQk) Xk ‚â•0, i.e., condition (2.107)
holds.
We will show that [XT
k (Qk ‚àíQk) Xk] ‚â•0 for k ‚àà[0, N]Z, which together
with initial condition (2.105) imply the statement. Let c ‚ààRn be arbitrary and put
xk := Xkc and uk := Ukc on [0, N + 1]Z. Then (x, u) is admissible with respect to
(A, B) and
cT [XT
k (Qk ‚àíQk) Xk] c = cT (XT
k Uk) c ‚àícT (XT
k QkXk) c
(2.112), (2.63)
=
 xk
xk+1
T
Gk
 xk
xk+1

‚àí(xT
k Qkxk).
(2.113)
By Claim 3, there exists u = {uk}N
k=0 such that (x, u) is admissible with respect to
(A, B), while Claim 2 yields that xk ‚ààIm Xk for k ‚àà[0, N + 1]Z. Hence, we get
(xT
k Qkxk)
(2.109)
=
(xT
k ¬ØQkxk)
(2.108)
=
 xk
xk+1
T
Gk
 xk
xk+1

‚àí¬ØwT
k Pk ¬Øwk.
Using this identity in formula (2.113) and using assumption (2.106), we obtain
cT [XT
k (Qk ‚àíQk) Xk] c =
 xk
xk+1
T
(Gk ‚àíGk)
 xk
xk+1

+ ¬ØwT
k Pk ¬Øwk ‚â•0,
where we used the fact that Pk = Pk = XkX‚Ä†
k+1Bk ‚â•0, since Y is assumed to have
no focal points in (0, N + 1].
Claim 6 The conjoined basis Y has no focal points in (0, N + 1].
We shall prove this via Theorem 2.39. Let (x, u) be admissible with respect to
(A, B) with x0 = X0d for some d ‚ààRn, xN+1 = 0, and x Ã∏‚â°0. Then, by Claim 3,
there is u = {uk}N
k=0 such that (x, u) is admissible with respect to (A, B) and, by

124
2
Basic Theory of Symplectic Systems
assumption (2.105), x0 = X0d for some d ‚ààRn. Hence, we have
F(x, u) + dT XT
0 U0d
(2.63)
=
N

k=0
 xk
xk+1
T
Gk
 xk
xk+1

+ dT XT
0 Q0X0d
(2.106), (2.105)
‚â•
N

k=0
 xk
xk+1
T
Gk
 xk
xk+1

+ dT XT
0 Q0X0d
(2.63)
= F(x, u) + dT XT
0 U0d > 0,
since Y is assumed to have no focal points in (0, N + 1]. Thus, by Theorem 2.39,
the conjoined basis Y has no focal points in (0, N +1]. This theorem is now proven.
‚äì‚äî
When the two systems (SDS) and (2.103) are the same, we obtain from
Theorem 2.55 the following Riccati inequality.
Corollary 2.56 (Inequality for One Symplectic System) Let Y and Y be conjoi-
ned bases of (SDS), and let Qk and Qk be symmetric n √ó n matrices such that
XT
k QkXk = XT
k Uk and XT
k QkXk = XT
k Uk on [0, N + 1]Z, and conditions (2.105)
hold. If Y has no forward focal points in (0, N + 1], then Y has no forward focal
points in (0, N + 1] either, and inequality (2.107) is satisÔ¨Åed.
2.4.2
Discrete Riccati Inequality
In Theorems 2.36 and 2.40, we presented several conditions which are equivalent to
the positivity of the discrete quadratic functional F in (2.57), which are analogous
to the continuous time conditions (i)‚Äì(iv) in Theorem 1.47. However, in contrast
with (1.123), the discrete Riccati operator Rk[Q] deÔ¨Åned in (2.52) is not symmetric
even when Qk is symmetric. This creates a difÔ¨Åculty in understanding what should
be the discrete version of the Riccati inequality in condition (v) of Theorem 1.47. In
this subsection, we answer this question and derive a complete discrete time analog
of the latter result.
Theorem 2.57 (Discrete Riccati Inequality) The functional F is positive deÔ¨Ånite
if and only if either of the following equivalent conditions is satisÔ¨Åed.
(i) The system
Xk+1 = AkXk + BkUk,
Nk := XT
k+1(Uk+1 ‚àíCkXk ‚àíDkUk) ‚â§0,

(2.114)
k ‚àà[0, N]Z, has a solution Y = X
U
 such that XT
k Uk is symmetric and Xk is
invertible for all k ‚àà[0, N + 1]Z and XkX‚àí1
k+1Bk ‚â•0 on [0, N]Z.

2.4
Riccati-Type Inequalities
125
(ii) The discrete Riccati inequality
Rk[Q] (Ak + BkQk)‚àí1 ‚â§0,
(2.115)
k ‚àà[0, N]Z, has a symmetric solution Qk deÔ¨Åned on [0, N + 1]Z satisfying the
conditions in (2.68), i.e., Ak + BkQk is invertible and (Ak + BkQk)‚àí1Bk ‚â•0
for all k ‚àà[0, N]Z.
The proof of Theorem 2.57 is shown below after the following auxiliary result.
Lemma 2.58 Let k ‚àà[0, N]Z be Ô¨Åxed and assume that Xj and Uj are n √ó n
matrices for j ‚àà[k, k + 1]Z such that Xk+1 = AkXk + BkUk. Then the following
conditions hold.
(i) If XT
j Uj is symmetric for j ‚àà[k, k + 1]Z, then the matrix
XT
k+1(Uk+1 ‚àíCkXk ‚àíDkUk)
= (XT
k Uk) ‚àí(XT
k CT
k AkXk + 2 XT
k CT
k BkUk + UT
k DT
k BkUk)
is symmetric as well.
(ii) If XT
k+1Uk+1 is symmetric and if Qj is symmetric with QjXj = UjX‚Ä†
jXj for
j ‚àà[k, k + 1]Z, then
XT
k+1Rk[Q] Xk = XT
k+1(Uk+1 ‚àíCkXk ‚àíDkUk) X‚Ä†
kXk.
(2.116)
(iii) If XT
j Uj and Qj are symmetric with QjXj = UjX‚Ä†
jXj for j ‚àà[k, k + 1]Z
and if Xk is invertible, then the matrix
XT
k+1Rk[Q] Xk = XT
k+1(Uk+1 ‚àíCkXk ‚àíDkUk)
(2.117)
is symmetric.
Proof Part (i) is a simple calculation. For part (ii), we Ô¨Årst derive
Rk[Q] Xk = [Qk+1Xk+1 ‚àí(CkXk + DkUk)] X‚Ä†
kXk
= [Uk+1 ‚àíCkXk ‚àíDkUk ‚àíUk+1(I ‚àíX‚Ä†
k+1Xk+1)] X‚Ä†
kXk.
Then, after multiplying by XT
k+1 from the left and by using the symmetry of
XT
k+1Uk+1, we obtain (2.116). Identity (2.117) in part (iii) then follows directly
from (i) and (ii).
‚äì‚äî
Proof of Theorem 2.57 If not speciÔ¨Åed otherwise, conditions (i) and (ii) refer to
Theorem 2.57. By Theorem 2.40, the positivity of F implies condition (i) trivially
with Nk ‚â°0. Condition (i) implies (ii) by the Riccati substitution Qk := UkX‚àí1
k
on

126
2
Basic Theory of Symplectic Systems
[0, N + 1]Z. Next, we show that condition (ii) implies (i). Let
Fk := Rk[Q] (Ak + BkQk)‚àí1 ‚â§0
be the matrix deÔ¨Åning the inequality (2.115), where Qk satisÔ¨Åes condition (ii). Let
X be the solution of the equation Xk+1 = (Ak + BkQk) Xk, k ‚àà[0, N]Z, given
by the initial condition X0 = I. Then Xk is invertible on [0, N + 1]k. If we set
Uk := QkXk on [0, N + 1]Z, then (X, U) satisÔ¨Åes Xk+1 = AkXk + BkUk and
Nk = XT
k+1[Qk+1 ‚àí(Ck + DkQk) XkX‚àí1
k+1] Xk+1 = XT
k+1FkXk+1 ‚â§0
for all k ‚àà[0, N]sZ, that is, (X, U) solves system (2.114). Note that the matrices
Nk and Fk = XT ‚àí1
k+1 NkX‚àí1
k+1 are symmetric, by Lemma 2.58(iii).
The rest of the proof is about showing that condition (i) implies the positivity of
the functional F. With Nk as in (2.114) we put Fk := XT ‚àí1
k+1 NkX‚àí1
k+1 ‚â§0. DeÔ¨Åne
Ak := Ak, Bk := Bk, Ck := Ck + FkAk, Dk := Dk + FkBk, and
Sk :=
Ak Bk
Ck Dk

= Sk + Rk
with Rk :=

0
0
FkAk FkBk

.
(2.118)
The proof will be Ô¨Ånished by showing the following claims.
Claim 1 The matrix Sk is symplectic.
This follows from the observation that ST
k J Rk = 
Ak Bk
T Fk

Ak Bk
 is
symmetric, RT
k J Rk = 0, and from the calculation
ST
k J Sk = (Sk + Rk)TJ (Sk + Rk) = ST
k J Sk + ST
k J Rk + RT
k J Sk + RT
k J Rk
= J + RT
k J T Sk + RT
k J Sk = J .
Claim 2 The pair (X, U) solves the system (2.103); hence it is a conjoined basis of
(2.103) with no focal points in (0, N + 1]. This follows from the invertibility of Xk
on [0, N + 1]Z, the calculations
AkXk + BkUk = AkXk + BkUk = Xk+1
CkXk + DkUk = CkXk + DkUk + Fk(AkXk + BkUk)
= CkXk + DkUk + XT ‚àí1
k+1 Nk = Uk+1,
and from P k := XkX‚àí1
k+1Bk = XkX‚àí1
k+1Bk ‚â•0.
Claim 3 The functional F is positive deÔ¨Ånite. We have by Theorem 2.40 applied
to (2.103) that the functional F is positive deÔ¨Ånite. Next, the deÔ¨Ånition of Ak and
Bk implies that Im

Ak ‚àíAk Bk

= Im Bk = Im Bk. Furthermore, the symmetric

2.4
Riccati-Type Inequalities
127
matrix Ek := Ek + Fk satisÔ¨Åes
DT
k Bk = DT
k Bk + BT
k FkBk = BT
k (Ek + Fk) Bk = BT
k EkBk,
Gk ‚àíGk =
AT
k EkAk ‚àíAT
k Ck CT
k ‚àíAT
k Ek
Ck ‚àíEkAk
Ek

‚àí
AT
k (Ek + Fk) Ak ‚àíAT
k (Ck + FkAk) CT
k + AT
k Fk ‚àíAT
k (Ek + Fk)
Ck + FkAk ‚àí(Ek + Fk) Ak
Ek + Fk

=
0
0
0 ‚àíFk

‚â•0.
Consequently, the conditions
Im 
Ak ‚àíAk Bk
 ‚äÜIm Bk,
Gk ‚â§Gk,
k ‚àà[0, N]Z,
are satisÔ¨Åed, compare with conditions (2.104)‚Äì(2.106) in which the roles of systems
(SDS) and (2.103) are interchanged. Therefore, by Theorem 2.55 in this latter
context with Y k := Yk and Qk = Qk = UkX‚àí1
k
on [0, N + 1]Z, we obtain that Y is
a conjoined basis of (SDS) with no forward focal points in (0, N +1]. Consequently,
by Theorem 2.40, the positivity of F follows, and the proof of this theorem is now
complete.
‚äì‚äî
Remark 2.59 In the proof above, we used a matrix Sk of the form Sk = Sk + Rk
with Rk =
 0
0
Gk Hk

. This matrix Sk is symplectic if and only if GT
k Ak and H T
k Bk
are symmetric, and the identity H T
k Ak = BT
k Gk holds. The choice Gk := FkAk
and Hk := FkBk with symmetric Fk is then natural, which was Ô¨Årst observed in
[55] in connection with an eigenvalue problem associated with system (SDS), see
Sect. 5.3.
Riccati inequality is often used in nonoscillation criteria for differential and
difference equations, since it is easier to Ô¨Ånd a solution of the inequality (which
corresponds to a solution of some majorant equation) than a solution to the equality.
In the following examples, we show a situation when a symmetric Qk solves the
Riccati inequality (2.115) and satisÔ¨Åes condition (ii) in Theorem 2.57, but it does
not solve the Riccati equation (2.52) so that condition (iii) in Theorem 2.40 is not
satisÔ¨Åed with this Qk.
Example 2.60
(i) Let Ak ‚â°0, Bk ‚â°‚àíCT ‚àí1, Ck ‚â°C, Dk ‚â°‚àíCT ‚àí1‚àíC‚àíK, where C is a constant
nonsingular matrix, K Ã∏= 0, and CKT = KCT ‚â•0. Then Qk ‚â°I satisÔ¨Åes
condition (ii) in Theorem 2.57, since Ak +BkQk = ‚àíCT ‚àí1 is invertible, (Ak +
BkQk)‚àí1Bk ‚â°I > 0, and Rk[Q] (Ak + BkQk)‚àí1 = ‚àíKCT ‚â§0, while the
Riccati equation is Rk[Q] = K Ã∏= 0. Another (more speciÔ¨Åc) example can

128
2
Basic Theory of Symplectic Systems
be obtained when we take, e.g., C = K = I. Note also that since Ak is not
invertible, the Hamiltonian Riccati inequality in [176, Corollary 4.1] cannot be
applied to this setting.
(ii) Let Ak and Ck be invertible, Bk ‚â°0, and Dk = AT ‚àí1
k
, with CT
k Ak > 0. Then
Qk ‚â°0 satisÔ¨Åes condition (ii) in Theorem 2.57, since Ak + BkQk = Ak is
invertible, (Ak+BkQk)‚àí1Bk ‚â°0, and Rk[Q] (Ak+BkQk)‚àí1 = ‚àíCkA‚àí1
k
< 0,
while the Riccati equation is Rk[Q] = ‚àíCk Ã∏= 0.
2.5
Recessive and Dominant Solutions
In this section we develop the notions of a recessive and dominant solution
for a nonoscillatory symplectic system (SDS) under the eventual controllability
condition. These concepts extend to the matrix case the corresponding notions for
the second-order equation (1.1) in Sect. 1.2. We note that the exposition in this
subsection differs from the presentation of recessive and dominant solutions in [16,
Sections 3.11‚Äì3.16]. For controllable systems, these two approaches are however
equivalent (see Remark 2.68).
2.5.1
DeÔ¨Ånitions and Basic Properties
First we note that the nonoscillation of (SDS) at ‚àû(DeÔ¨Ånition 2.19) means that
every conjoined basis Y of (SDS) does not have eventually any focal points, i.e.,
there exists N ‚àà[0, ‚àû)Z such that condition (2.37) holds for every k ‚àà[N, ‚àû)Z.
This implies that for every conjoined basis Y of a nonoscillatory system (SDS),
the kernel of Xk is eventually constant.
(2.119)
System (SDS) is said to be (completely) controllable on some discrete interval
[N, ‚àû)Z if for any subinterval [N1, N2]Z of [N, ‚àû)Z with at least two points the
trivial solution (x, u) ‚â°(0, 0) is the only solution of (SDS) for which xk ‚â°0
on [N1, N2]Z. System (SDS) is eventually (completely) controllable if there exists
N ‚àà[0, ‚àû)Z such that it is (completely) controllable on [N, ‚àû)Z.
The eventual controllability of (SDS) in combination with property (2.119)
means the matrix Xk is eventually invertible. That is, if the system (SDS) is
nonoscillatory at ‚àûand eventually controllable, then for every conjoined basis Y,
there exists N ‚ààZ such that
Xk is invertible and XkX‚àí1
k+1Bk ‚â•0 for all k ‚àà[N, ‚àû)Z.
(2.120)

2.5
Recessive and Dominant Solutions
129
Remark 2.61
(i) The above condition of eventual controllability is satisÔ¨Åed, for example, by
systems (SDS) with Bk invertible for large k, such as equation (1.1). Other types
of such systems are discussed in Sect. 2.1.2. Equation (2.27) is an example of
a controllable system with singular Bk.
(ii) On the other hand, system (SDS) with Bk ‚â°0 is not eventually controllable.
In this case we have by (1.146) that Ak and Dk = AT ‚àí1
k
are invertible and
the Ô¨Årst equation of (SDS) has the form xk+1 = Akxk. This means that if Y is
a conjoined basis with singular XN, then Xk is singular for all k ‚àà[N, ‚àû)Z.
Under (2.120) we may associate with the conjoined basis Y the symmetric matrix
Sk :=
k‚àí1

j=N
X‚àí1
j+1BjXT ‚àí1
j
,
k ‚àà[N + 1, ‚àû)Z,
SN := 0.
(2.121)
The matrix Sk is symmetric, positive semideÔ¨Ånite, and nondecreasing in k, since
Sk = X‚àí1
k+1BkXT ‚àí1
k
= X‚àí1
k
(XkX‚àí1
k+1Bk) XT ‚àí1
k
‚â•0,
k ‚àà[N, ‚àû)Z.
(2.122)
In fact, we shall prove a stronger result under the complete controllability assump-
tion on [N, ‚àû)Z.
Lemma 2.62 Assume that system (SDS) is nonoscillatory at ‚àûand eventually
completely controllable. Then for any conjoined basis Y of (SDS), there exists
N ‚àà[0, ‚àû)Z such that the matrix Sk deÔ¨Åned in (2.121) is positive deÔ¨Ånite for all
k ‚àà[N + 2, ‚àû)Z.
Proof The assumptions imply that for some N ‚àà[0, ‚àû)Z, condition (2.120) holds.
Assume that Skd = 0 for some k ‚àà[N + 2, ‚àû)Z. Then X‚àí1
j+1BjXT ‚àí1
j
d ‚â°0 for
all j ‚àà[N, k ‚àí1]Z, i.e., BjXT ‚àí1
j
d ‚â°0 for all j ‚àà[N, k ‚àí1]Z. We now deÔ¨Åne
xj := 0, uj := XT ‚àí1
j
d, and Qj := UjX‚àí1
j
for j ‚àà[N, k]Z. It follows that for every
j ‚àà[N, k ‚àí1]Z we have Bjuj = 0 and, by (2.55) in Corollary 2.27,
uj+1 = XT ‚àí1
j+1 d = (AjXj + BjUj)T ‚àí1d = (AT
j + QjBT
j ) XT ‚àí1
j
d
(2.55)
=
(Dj ‚àíQj+1Bj) uk = Djuj.
This implies that the pair (x ‚â°0, u) solves system (SDS) on the interval [N, k‚àí1]Z.
By the complete controllability assumption, we obtain that uj ‚â°0 on [N, k]Z, i.e.,
d = 0. This shows that the matrix Sk is invertible, hence positive deÔ¨Ånite.
‚äì‚äî

130
2
Basic Theory of Symplectic Systems
The result in Lemma 2.62 yields that for any conjoined basis Y of a nonoscilla-
tory and eventually controllable system (SDS), the matrix S‚àí1
k
eventually exists as
a positive deÔ¨Ånite matrix, which is nonincreasing in k. Therefore, there exists the
limit
T := lim
k‚Üí‚àûS‚àí1
k ,
T ‚â•0.
(2.123)
Depending on the form of the limiting matrix T , we make the following deÔ¨Ånition:
DeÔ¨Ånition 2.63 A conjoined basis ÀúY of a nonoscillatory and eventually controllable
system (SDS) is called a recessive solution at ‚àûif the matrix T deÔ¨Åned in (2.123)
satisÔ¨Åes T = 0, while it is called a dominant solution at ‚àûif T > 0.
Remark 2.64 One can easily see from the limit properties of invertible matrices that
Y is a dominant solution at ‚àûif and only if the limit of Sk itself exists as k ‚Üí‚àû,
and in this case
lim
k‚Üí‚àûSk = T ‚àí1.
The following reduction of order theorem will be useful for the construction and
properties of recessive and dominant solutions of (SDS).
Theorem 2.65 Assume that Y is a conjoined basis of (SDS) such that Xk is
invertible on some interval [N, M]Z. Then ÀúY is a solution of (SDS) if and only
if for some constant matrices K and L, we have
ÀúXk = Xk (K+SkL),
ÀúUk = Uk (K+SkL)+XT ‚àí1
k
L,
k ‚àà[N, M]Z,
(2.124)
where the matrix Sk is deÔ¨Åned in (2.121). In this case K = X‚àí1
N ÀúXN and L =
Y TJ ÀúY. Moreover, ÀúY is also a conjoined basis of (SDS) if and only if KT L is
symmetric.
Proof The proof is rather straightforward in both implications. The details can be
found in [16, Theorem 3.32, pp. 105‚Äì109].
‚äì‚äî
The following two results justify the existence of recessive and dominant
solutions at ‚àûfor a nonoscillatory system (SDS), as well as the uniqueness of the
recessive solution at ‚àû. They provide an extension of Theorem 1.7 to symplectic
systems.
Theorem 2.66 Assume that system (SDS) is nonoscillatory at ‚àûand eventually
controllable. Then there exists a recessive solution of (SDS) at ‚àû. In addition, the
recessive solution is unique up to a right constant nonsingular multiple.
Proof Consider the principal solution ÀÜY at k = 0, i.e., ÀÜX0 = 0 and ÀÜU0 = I. Then for
some N ‚àà[1, ‚àû)Z, the matrix ÀÜXk satisÔ¨Åes (2.120), and we may deÔ¨Åne the matrices
ÀÜSk and ÀÜT by (2.121) and (2.123) through ÀÜXk. Let ¬ØY be the conjoined basis of (SDS)

2.5
Recessive and Dominant Solutions
131
given by the initial conditions ¬ØXN = 0 and ¬ØUN = ÀÜXT ‚àí1
N
. Then ÀÜY T
N J ¬ØYN = I, so
that the conjoined bases ÀÜY and ¬ØY are normalized. We will show that the sequence
 ÀúXk
ÀúUk

:=
 ÀÜXk ¬ØXk
ÀÜUk ¬ØUk
  I
‚àíÀÜT

,
k ‚àà[0, ‚àû)Z,
(2.125)
is a conjoined basis of (SDS) and that ÀúY is a recessive solution of (SDS) at ‚àû. By
Theorem 2.65 (with K = 0 and L = I) we know that
¬ØXk = ÀÜXk ÀÜSk,
¬ØUk = ÀÜUk ÀÜSk + ÀÜXT ‚àí1
k
,
k ‚àà[N, ‚àû)Z.
(2.126)
Then, substituting (2.126) into (2.125), we obtain that
ÀúXk = ÀÜXk(I ‚àíÀÜSk ÀÜT ),
ÀúUk = ÀÜUk(I ‚àíÀÜSk ÀÜT ) ‚àíÀÜXT ‚àí1
k
ÀÜT ,
k ‚àà[N, ‚àû)Z,
(2.127)
so that by Theorem 2.65 (with Y := ÀÜY, K = I, and L = ‚àíÀÜT ), we conclude that
ÀúY is a conjoined basis of (SDS). The assumptions of the theorem imply that ÀúXk is
invertible for all k ‚àà[L, ‚àû)Z for some index L ‚àà[N, ‚àû)Z. Then by (2.127) we
know that also I ‚àíÀÜSk ÀÜT is invertible for k ‚àà[L, ‚àû)Z. Therefore, for the symmetric
matrices Gk := ÀÜT (I ‚àíÀÜSk ÀÜT ), k ‚àà[N, ‚àû)Z, we have
Gk ‚â•0,
k ‚àà[N, ‚àû)Z,
{Gk}‚àû
k=N is nonincreasing on[N, ‚àû)Z,
(2.128)
Im Gk = Im [ ÀÜT (I ‚àíÀÜSk ÀÜT )] = Im ÀÜT ,
k ‚àà[L, ‚àû)Z.
(2.129)
But from the deÔ¨Ånition of Gk, we also have
Im Gk = Im [ ÀÜT (I ‚àíÀÜSk ÀÜT )] ‚äÜIm ÀÜT ,
k ‚àà[N, L ‚àí1]Z.
(2.130)
Hence, from (2.128)‚Äì(2.130) we obtain that Im Gk = Im ÀÜT for all k ‚àà[N, ‚àû)Z. By
taking the orthogonal complements (using the symmetry of Gk and ÀÜT ), we get
Ker [ ÀÜT (I ‚àíÀÜSk ÀÜT )] = Ker Gk = Ker ÀÜT ,
k ‚àà[N, ‚àû)Z.
(2.131)
Assume now that ÀúXkd = 0 for some k ‚àà[N, ‚àû)Z and d ‚ààRn. It follows by (2.127)
and by the invertibility of ÀÜXk that (I ‚àíÀÜSk ÀÜTk) d = 0, i.e., d = ÀÜSk ÀÜTkd. At the same
time, Gkd = ÀÜT (I ‚àíÀÜSk ÀÜTk) d = 0, so that d ‚ààKer Gk = Ker ÀÜT by (2.131). Therefore,
d = ÀÜSk ÀÜTkd = 0. This shows that the matrix ÀúXk is invertible for all k ‚àà[N, ‚àû)Z.
DeÔ¨Åne the associated matrix ÀúSk as in (2.121) through ÀúXk in [N, ‚àû)Z. Since
ÀúY T
N J ¬ØYN = I, we get by Theorem 2.65 (with K = 0 and L = I again) that
¬ØXk = ÀúXk ÀúSk,
¬ØUk = ÀúUk ÀúSk + ÀúXT ‚àí1
k
,
k ‚àà[N, ‚àû)Z.
(2.132)

132
2
Basic Theory of Symplectic Systems
Combining the Ô¨Årst equations in (2.126) and (2.132) yields the equality ÀÜXk ÀÜSk =
ÀúXk ÀúSk on [N, ‚àû)Z. Therefore, together with the expression for ÀúXk in (2.127), we
obtain that (note that ÀÜSk and ÀúSk are invertible for k ‚â•N + 2 by Lemma 2.62)
ÀúS‚àí1
k
= ÀÜS‚àí1
k
ÀÜX‚àí1
k
ÀúXk = ÀÜS‚àí1
k (I ‚àíÀÜSk ÀÜT ) = ÀÜS‚àí1
k
‚àíÀÜT ,
k ‚àà[N + 2, ‚àû)Z.
Thus, the matrix ÀúT deÔ¨Åned in (2.121) through ÀúSk satisÔ¨Åes
ÀúT = lim
k‚Üí‚àû
ÀúS‚àí1
k
= lim
k‚Üí‚àû( ÀÜS‚àí1
k
‚àíÀÜT ) = 0,
which shows that ÀúY is a recessive solution of (SDS) at ‚àûaccording to DeÔ¨Åni-
tion 2.63.
Now we prove the essential uniqueness of the recessive solution ÀúY. Let ÀúY (0)
be another recessive solution of (SDS) at ‚àû. Let N ‚àà[0, ‚àû)Z be an index such
that (2.120) holds for ÀúXk and ÀúX(0)
k . Let ÀúSk and ÀúS(0)
k
be the associated matrices
deÔ¨Åned in (2.121) through ÀúXk and ÀúX(0)
k , respectively, and let ÀúT and ÀúT (0) be the
matrices in (2.123), which according to DeÔ¨Ånition 2.63 satisfy ÀúT = 0 = ÀúT (0). By
Theorem 2.65, we know that
ÀúX(0)
k
= ÀúXk(K + ÀúSkL),
ÀúU(0)
k
= ÀúUk(K + ÀúSkL) + ÀúXT ‚àí1
k
L,
k ‚àà[N, ‚àû)Z,
(2.133)
where K = ÀúX‚àí1
N ÀúX(0)
N is regular and L = ÀúY TJ ÀúY (0) is the Wronskian of ÀúY and ÀúY (0).
By [284, Proposition 4.20], the matrices ÀúSk and ÀúS(0)
k
are related by the formula
 ÀúS(0)
k
‚àí1 = KT ÀúS‚àí1
k K + KT L,
which means upon taking the limit as k ‚Üí‚àûthat
0 = ÀúT (0) = KT ÀúT K + KT L = KT L.
Since K is regular, it follows that L = 0, and hence by (2.133) we obtain ÀúY (0)
k
=
ÀúYkK on [N, ‚àû)Z. Thus, the recessive solution ÀúY (0) is a regular constant multiple
of the recessive solution ÀúY. Conversely, if ÀúY is a recessive solution of (SDS) at ‚àû,
satisfying (2.120), and if K is a regular n √ó n matrix, then we deÔ¨Åne the conjoined
basis ÀúY (0) by ÀúY (0)
k
:= ÀúYkK on [N, ‚àû)Z. Then ÀúX(0)
k
is invertible on [N, ‚àû)Z and
 ÀúX(0)
k+1
‚àí1Bk
 ÀúX(0)
k
T ‚àí1 = K‚àí1 ÀúX‚àí1
k+1B ÀúXT ‚àí1
k
KT ‚àí1 ‚â•0
ÀúS(0)
k
= K‚àí1 ÀúSk KT ‚àí1,

k ‚àà[N, ‚àû)Z,

2.5
Recessive and Dominant Solutions
133
so that
ÀúT (0) = lim
k‚Üí‚àû
 ÀúS(0)
k
‚àí1 = lim
k‚Üí‚àûKT ÀúS‚àí1
k
K = KT ÀúT K = 0.
Hence, ÀúY (0) is also a recessive solution of (SDS) according to DeÔ¨Ånition 2.63. The
proof is complete.
‚äì‚äî
The next result shows that the recessive solution at ‚àûis the smallest solution
among all conjoined bases Y of (SDS) which are linearly independent with ÀúY,
measured in terms of their Ô¨Årst components ÀúXk and Xk. This property extends the
limit (1.18) to symplectic systems.
Theorem 2.67 Assume that system (SDS) is nonoscillatory at ‚àûand eventually
controllable. Let ÀúY and Y be two conjoined bases of (SDS) such that the Wronskian
W := w( ÀúY, Y) = ÀúY TJ Y is invertible. Then ÀúY is the recessive solution of (SDS) at
‚àûif and only if
lim
k‚Üí‚àûX‚àí1
k
ÀúXk = 0.
(2.134)
In this case Y is a dominant solution of (SDS) at ‚àû.
Proof Let N ‚àà[0, ‚àû)Z be an index such that ÀúXk and Xk satisfy (2.120). Let ÀúSk,
ÀúT and Sk, T be the matrices in (2.121) and (2.123) associated with ÀúXk and Xk,
respectively. Then by Theorem 2.65 (with the invertible matrix K := X‚àí1
N ÀúXN and
with L := ‚àíW T ), we have
ÀúXk = Xk(K ‚àíSkW T ),
Xk = ÀúXk(K‚àí1+ ÀúSkW),
k ‚àà[N, ‚àû)Z.
(2.135)
Assume that ÀúY is the recessive solution of (SDS) at ‚àû, i.e., ÀúT = 0. Then (2.135)
implies that K‚àí1 + ÀúSkW =
ÀúX‚àí1
k Xk is invertible on [N, ‚àû)Z, as well as ÀúSk is
invertible on [N + 2, ‚àû)Z by Lemma 2.62. Hence,
lim
k‚Üí‚àûX‚àí1
k
ÀúXk = lim
k‚Üí‚àû(K‚àí1 + ÀúSkW)‚àí1 = lim
k‚Üí‚àû( ÀúS‚àí1
k K‚àí1 + W)‚àí1 ÀúS‚àí1
k
= ( ÀúT K‚àí1 + W)‚àí1 ÀúT = 0.
Conversely, assume that (2.134) holds. The second equation in (2.135) implies that
ÀúSk = ( ÀúX‚àí1
k Xk ‚àíK‚àí1) W ‚àí1 on [N, ‚àû)Z, so that
ÀúT = lim
k‚Üí‚àû
ÀúS‚àí1
k
= lim
k‚Üí‚àûW( ÀúX‚àí1
k Xk ‚àíK‚àí1)‚àí1
= lim
k‚Üí‚àûW(I ‚àíX‚àí1
k
ÀúXkK‚àí1)‚àí1X‚àí1
k
ÀúXk
(2.134)
=
0.

134
2
Basic Theory of Symplectic Systems
This proves that ÀúY is the recessive solution of (SDS) at ‚àû. Finally, knowing that ÀúY
is the recessive solution of (SDS) at ‚àû, then from (2.135), we obtain
K ‚àíSkW T = X‚àí1
k
ÀúXk = (K‚àí1+ ÀúSkW)‚àí1,
k ‚àà[N, ‚àû)Z,
so that
Sk = [K ‚àí( ÀúS‚àí1
k K‚àí1 + W)‚àí1 ÀúS‚àí1
k ] W T ‚àí1,
k ‚àà[N + 2, ‚àû)Z.
Upon taking the inverse and using that ÀúT = 0, we get
T = lim
k‚Üí‚àûS‚àí1
k
= lim
k‚Üí‚àûW T [K ‚àí( ÀúS‚àí1
k K‚àí1 + W)‚àí1 ÀúS‚àí1
k ]‚àí1
= W T [K ‚àí( ÀúT K‚àí1 + W)‚àí1 ÀúT ]‚àí1 = W T K‚àí1.
Therefore, the matrix T is invertible. At the same time, we know that T ‚â•0 by
(2.123), so that T > 0 follows. Hence, Y is a dominant solution of (SDS) at ‚àû
according to DeÔ¨Ånition 2.63. The proof is complete.
‚äì‚äî
Remark 2.68 The result in Theorem 2.67 shows that the notions of a recessive
solution at ‚àûfor a nonoscillatory and completely controllable system (SDS) in
DeÔ¨Ånition 2.63 and in [16, pg. 115] are equivalent.
Remark 2.69 The results in Theorems 2.66 and 2.67 show that, under the eventual
controllability assumption, the nonoscillation of (SDS) implies the existence of the
recessive solution of (SDS) at ‚àû, as well as the existence of a dominant solution of
(SDS) at ‚àû. However, from the quantitative results on focal points (i.e., Sturmian
separation theorems) presented later in Sects. 4.2.4 and 5.5.1, it follows that also
the converse to Theorem 2.66 holds. Namely, the existence of a nonoscillatory
conjoined basis of (SDS) at ‚àûimplies that every conjoined basis of (SDS) is also
nonoscillatory at ‚àû, i.e., system (SDS) is nonoscillatory at ‚àû.
2.5.2
Minimal Solution of Riccati Equation
The recessive solution of (SDS) gives rise to a minimal solution of the associated
Riccati difference equation (2.51). This statement extends Theorem 1.8 to symplec-
tic systems.
Theorem 2.70 Assume that (SDS) is nonoscillatory and eventually controllable,
and let ÀúY be its recessive solution at ‚àû. Then the solution ÀúQk := ÀúUk ÀúX‚àí1
k
of the
Riccati equation (2.51) is eventually minimal, i.e., if Qk is any symmetric solution
of (2.51) such that (Ak + BkQk)‚àí1Bk ‚â•0 for all k in some interval [N, ‚àû)Z, then
Qk ‚â•ÀúQk
for all k ‚àà[N, ‚àû)Z.
(2.136)

2.6
Transformations of Symplectic Systems
135
Proof Let ÀúQk and Qk be as in the theorem. Then the matrices Ak + ÀúQkBk and
Ak + QkBk are invertible on [N, ‚àû)Z by Corollary 2.27. By Theorem 2.28 we
associate with Qk a conjoined basis Y of (SDS) such that Xk is invertible and Qk =
UkX‚àí1
k
on [N, ‚àû)Z. Then Y satisÔ¨Åes condition (2.120) by the assumptions in the
theorem. Denote by W := w( ÀúY, Y) = ÀúY TJ Y the (constant) Wronskian of ÀúY and
Y. Then for k ‚àà[N, ‚àû)Z we have
Qk ‚àíÀúQk = UkX‚àí1
k
‚àíÀúUk ÀúX‚àí1
k
= ÀúXT ‚àí1
k
WX‚àí1
k
= ÀúXT ‚àí1
k
(WX‚àí1
k
ÀúXk) ÀúX‚àí1
k .
(2.137)
Consider now the symmetric matrix function WX‚àí1
k
ÀúXk on [N, ‚àû)Z. Then
(WX‚àí1
k
ÀúXk) = W(X‚àí1
k+1 ÀúXk+1 ‚àíX‚àí1
k
ÀúXk)
= W [X‚àí1
k+1(Ak ÀúXk + Bk ÀúUk) ‚àíX‚àí1
k+1(AkXk + BkUk) X‚àí1
k
ÀúXk]
= WX‚àí1
k+1Bk( ÀúUk ‚àíUkX‚àí1
k
ÀúXk) = ‚àíWX‚àí1
k+1BkXT ‚àí1
k
W T ‚â§0,
so that the function WX‚àí1
k
ÀúXk is nonincreasing on [N, ‚àû)Z. At the same time,
we know from Theorem 2.67 that WX‚àí1
k
ÀúXk ‚Üí0 as k ‚Üí‚àû. This implies that
WX‚àí1
k
ÀúXk ‚â•0 on [N, ‚àû)Z and hence, equation (2.137) yields that Qk ‚àíÀúQk ‚â•0
for all k ‚àà[N, ‚àû)Z. Therefore, (2.136) is satisÔ¨Åed.
‚äì‚äî
2.6
Transformations of Symplectic Systems
Transformation approach to various differential and difference equations is histori-
cally a very effective method. The basic idea is simple. An equation is transformed
into an ‚Äúeasier‚Äù equation, this equation is then investigated, and Ô¨Ånally the obtained
results are transformed back to the original equation. Of course, important are
invariants of the applied transformations. In the investigation of symplectic systems,
the situation is similar, and naturally the main role will be played by symplectic
transformations.
2.6.1
General Symplectic Transformation
Our Ô¨Årst result shows that symplectic transformations preserve the type (i.e., the
symplectic property) of the underlying system.
Lemma 2.71 Let Rk ‚ààR2n√ó2n for k ‚àà[0, N + 1]Z be a sequence of symplectic
matrices, and consider the transformation
yk = Rkwk.
(2.138)

136
2
Basic Theory of Symplectic Systems
Then (2.138) transforms system (SDS) into another symplectic system
wk+1 = ÀúSkwk,
ÀúSk := R‚àí1
k+1SkRk = ‚àíJ RT
k+1J SkRk,
(2.139)
where the matrix ÀúSk is symplectic for k ‚àà[0, N]Z. Moreover, Yk is a conjoined basis
of (SDS) if and only if ÀúYk = R‚àí1
k Yk is a conjoined basis of (2.139).
Proof By (2.138) we have
yk+1 = Rk+1wk+1 = Skyk = SkRkwk.
Hence, the new variable w is a solution of the system (2.139). Moreover, the matrix
ÀúSk is symplectic, being a product of symplectic matrices (see Lemma 1.58(i)).
Recall that the multiplication by a symplectic (hence invertible) matrix preserves
both conditions, which deÔ¨Åne a conjoined basis (i.e., the rank condition and the
symmetry of ÀúXT
k ÀúUk), see Lemma 1.58(vii). This property proofs the last statement
of the lemma.
‚äì‚äî
Sometimes we will need to know the block structure of the matrix ÀúSk in the
transformed system (2.139). Hence, consider the transformation matrix Rk in the
form
Rk =
Hk Mk
Gk Nk

,
(2.140)
and denote by
ÀúAk, ÀúBk, ÀúCk, ÀúDk the block in the matrix
ÀúSk. Then by a direct
computation, we have the formulas
ÀúAk = NT
k+1(AkHk + BkGk) ‚àíMT
k+1(CkHk + DkGk),
ÀúBk = NT
k+1(AkMk + BkNk) ‚àíMT
k+1(CkMk + DkNk),
ÀúCk = ‚àíGT
k+1(AkHk + BkGk) + H T
k+1(CkHk + DkGk),
ÀúDk = ‚àíGT
k+1(AkMk + BkNk) + H T
k+1(CkMk + DkNk).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(2.141)
Summarizing, a linear transformation with a symplectic transformation matrix
transforms a symplectic system again into a symplectic systems. In our treatment,
we will mainly concentrate on oscillatory properties of symplectic systems, and the
above-described transformation generally does not preserve an oscillatory nature
of the transformed systems. The oscillatory properties are preserved, when the
transformation matrix is lower block triangular, i.e., when Mk = 0 (see Lemma 2.72
below). In this case, the transformation matrix has the form
Rk =
Hk
0
Gk H T ‚àí1
k

,
(2.142)

2.6
Transformations of Symplectic Systems
137
and the formulas for ÀúAk, ÀúBk, ÀúCk, ÀúDk in (2.141) simplify to
ÀúAk = H ‚àí1
k+1(AkHk + BkGk),
ÀúBk = H ‚àí1
k+1BkH T ‚àí1
k
,
ÀúCk = ‚àíGT
k+1(AkHk + BkGk) + H T
k+1(CkHk + DkGk),
ÀúDk = ‚àíGT
k+1BkH T ‚àí1
k
+ H T
k+1DkH T ‚àí1
k
.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(2.143)
Lemma 2.72 Suppose that Y is a conjoined basis of (SDS) and ÀúYk =
 ÀúXk
ÀúUk

=
R‚àí1
k Yk, where Rk is a lower block-triangular symplectic matrix. Then Y has no
focal point in (k, k + 1] if and only if ÀúY has no focal point in this interval.
Proof Obviously, we have Ker Xk+1 ‚äÜKer Xk if and only if Ker ÀúXk+1 ‚äÜKer ÀúXk
and, by (2.39), Bk = Xk+1X‚Ä†
k+1Bk or ÀúBk = H ‚àí1
k+1Xk+1X‚Ä†
k+1BkH T ‚àí1
k
according to
(2.143). Substituting the last representation for ÀúBk into ÀúPk := ÀúXk ÀúX‚Ä†
k+1 ÀúBk and using
Lemma 1.63, we have
ÀúPk = ÀúXk ÀúX‚Ä†
k+1 ÀúBk = H ‚àí1
k Xk(H ‚àí1
k+1Xk+1)‚Ä†H ‚àí1
k+1Xk+1X‚Ä†
k+1BkH T ‚àí1
k
= H ‚àí1
k XkX‚Ä†
k+1BkH T ‚àí1
k
= H ‚àí1
k
PkH T ‚àí1
k
,
i.e., Pk ‚â•0 if and only if ÀúPk ‚â•0. This completes the proof.
‚äì‚äî
Note that a symplectic transformation with a lower block-triangular transforma-
tion matrix preserves also the so-called multiplicity of a focal point. We will present
and prove this statement later in this book (see Sect. 4.4.2).
In the next statement, we prove that the quadratic functional associated with
(SDS) transforms under a transformation with lower block-triangular symplectic
transformation matrix (2.142) essentially in the same way as the corresponding
symplectic system.
Lemma 2.73 Let y =
x
u

be an admissible pair for functional (2.57) and let
Àúyk = R‚àí1
k yk with Àúy =
Àúx
Àúu

, where Rk is a lower block-triangular transformation
matrix given in (2.142). Denote by ÀúF( Àúy) the quadratic functional corresponding to
transformed system (2.139), i.e., to the symplectic system with block entries given in
(2.143). Then we have
F(y) = ÀúxT
k GT
k Hk Àúxk
		N+1
k=0 + ÀúF( Àúy).
(2.144)
Proof Following (2.57), denote by Fk and  ÀúFk the expressions
Fk(y) := xT
k CT
k Akxk + 2xT
k CT
k Bkuk + uT
k BT
k Dkuk,
 ÀúFk( Àúy) := ÀúxT
k ÀúCT
k ÀúAk Àúxk + 2 ÀúxT
k ÀúCT
k ÀúBk Àúuk + ÀúuT
k ÀúBT
k ÀúDk Àúuk.

138
2
Basic Theory of Symplectic Systems
By using Lemma 2.30, we then prove that
 ÀúFk( Àúy) ‚àí(ÀúxT
k Àúuk) = Fk(y) ‚àí(xT
k uk)
or
Fk(y) = (ÀúxT
k GT
k Hk Àúxk) +  ÀúFk( Àúy).
(2.145)
Indeed
 ÀúFk( Àúy) ‚àí(ÀúxT
k Àúuk)
= ÀúxT
k+1(‚àíÀúuk+1 + ÀúCk Àúxk + ÀúDk Àúuk)
= ÀúxT
k+1(‚àíÀúuk+1 + (0 I) ÀúSk Àúyk)
= xT
k+1H T ‚àí1
k+1

GT
k+1xk+1 ‚àíH T
k+1uk+1 + (‚àíGT
k+1, H T
k+1)Skyk

= xT
k+1H T ‚àí1
k+1

GT
k+1xk+1 ‚àíH T
k+1uk+1 ‚àíGT
k+1(I 0) Skyk + H T
k+1(0 I) Skyk

= xT
k+1

‚àíuk+1 + (0 I) Skyk

= xT
k+1(‚àíuk+1 + Ckxk + Dkuk)
= Fk(y) ‚àí(xT
k uk).
Finally, using the connection Àúyk = R‚àí1
k yk, we derive (2.145). Summing this identity
for k ‚àà[0, N]Z, we prove (2.144).
‚äì‚äî
We Ô¨Ånish this section with the proof of formula (2.65) in Lemma 2.32.
Alternative proof of Lemma 2.32 Consider the transformation
xk
uk

=
 I
0
Qk I
 Àúxk
zk

,
i.e.,
Àúxk = xk, zk = uk ‚àíQkxk.
Then by (2.143) we have
ÀúAk = Ak + BkQk,
ÀúBk = Bk,
ÀúCk = ‚àíRk[Q],
ÀúDk = ‚àíQk+1Bk + Dk.
Then the summand in the transformed quadratic functional is
 ÀúFk(Àúx, z) = ‚àíÀúxT
k RT
k [Q] (Ak + BkQk) Àúxk ‚àí2 ÀúxT
k RT
k [Q] Bkzk
+ zT
k BT
k (‚àíQk+1Bk + Dk) zk
= ‚àíxT
k RT
k [Q] (Ak + BkQk) xk ‚àí2 xT
k RT
k [Q] Bk(uk ‚àíQkxk)

2.6
Transformations of Symplectic Systems
139
+ zT
k Pk[Q] zk
= xT
k RT
k [Q] (BkQk ‚àíAk) xk ‚àí2 xT
k RT
k [Q] Bkuk + zT
k Pk[Q] zk.
Substituting the last expression into (2.145), we derive (2.65).
‚äì‚äî
2.6.2
Trigonometric or Bohl Transformation
Now, consider the trigonometric symplectic system (2.12) in the matrix form
Sk+1 = PkSk + QkCk,
Ck+1 = ‚àíQkSk + PkCk
(2.146)
with Pk and Qk satisfying (see (2.13))
PT
k Pk + QT
k Qk = I,
PT
k Qk = QT
k Pk.
The fact that trigonometric systems are self-reciprocal, i.e., transformation (2.138)
with Rk = J transforms this system into itself, implies that if (S, C) is a solution
of (2.146), then (C, ‚àíS) solves this system as well. Consequently, if the matrix

Sk
Ck
Ck ‚àíSk

is symplectic for some k, then it is symplectic everywhere and the
following identities hold:
CT
k Ck + ST
k Sk = I,
CT
k Sk = ST
k Ck,
(2.147)
CkCT
k + SkST
k = I,
SkCT
k = CkST
k .
(2.148)
The following theorem presents the discrete analog of Theorem 1.52.
Theorem 2.74 There exist n √ó n-matrices Hk and Kk such that Hk is nonsingular
and H T
k Kk = KT
k Hk for k ‚àà[0, N + 1]Z, and the transformation
sk
ck

=
 H ‚àí1
k
0
‚àíKT
k H T
k
 xk
uk

(2.149)
transforms the symplectic system (SDS) into the trigonometric system (2.146)
without changing the oscillatory behavior. Moreover, the matrices Pk and Qk from
(2.146) may be explicitly given by
Pk = H ‚àí1
k+1AkHk + H ‚àí1
k+1BkKk,
Qk = H ‚àí1
k+1BkH T ‚àí1
k
.
(2.150)
Proof We let ÀúY = ( ÀúX, ÀúU) and Y = (X, U) be normalized conjoined bases of (SDS).
Then they form the symplectic fundamental solution matrix Z = ( ÀúY, Y), and then

140
2
Basic Theory of Symplectic Systems
ZkZT
k > 0 because Zk is nonsingular. In particular, the matrix XkXT
k + ÀúXk ÀúXT
k is
positive deÔ¨Ånite, and there exists a nonsingular n √ó n-matrix Hk with
HkH T
k = XkXT
k + ÀúXk ÀúXT
k ,
k ‚àà[0, N + 1]Z.
(2.151)
We put
Kk :=

UkXT
k + ÀúUk ÀúXT
k

H T ‚àí1
k
,
(2.152)
so that the following identity hold
ZkZT
k = RkRT
k ,
Rk :=
Hk
0
Kk H T ‚àí1
k

.
(2.153)
Indeed, since ZkZT
k
is symplectic, we have that the matrix HkH T
k KkH T
k
is
symmetric, and then, due to nonsingularity of Hk, so is H T
k Kk, i.e., H T
k Kk =
KT
k Hk. Moreover, UUT + ÀúU ÀúUT = KkKT
k + (HkH T
k )‚àí1.
So we have proved that the block lower triangular matrix Rk in the right-hand
side of (2.153) is symplectic, and then the product of two symplectic matrices ÀúZk =

H ‚àí1
k
0
‚àíKT
k H T
k

Zk satisÔ¨Åes the condition ÀúZk ÀúZT
k = I, i.e.,
ÀúZk =
 Ck Sk
‚àíSk Ck

= R‚àí1
k Zk
(2.154)
is symplectic and orthogonal matrix. Moreover since ÀúSk = ÀúZk+1 ÀúZ‚àí1
k
is also sym-
plectic and orthogonal, we have that ÀúZk solves trigonometric system (2.146) with
the blocks given by (2.150) according to formulas (2.143) for the transformation
matrix Rk in (2.153). The proof is completed.
‚äì‚äî
Remark 2.75 Observe that every trigonometric system (2.146) can be transformed
into another trigonometric system with symmetric and positive semideÔ¨Ånite matri-
ces ÀúQk at the position of the matrices Qk, using the transformation
Àúsk
Àúck

=
H ‚àí1
k
0
0
H T
k
 sk
ck

,
where the matrices Hk are recursively deÔ¨Åned by H0 = I and Hk+1 = G‚àí1
k Hk
with orthogonal matrices Gk, i.e., GT
k Gk = I, such that GkQk are symmetric and
positive semideÔ¨Ånite. Such matrices Gk exist according to the well-known principle
of polar decomposition (see, e.g., [195, Theorem 3.1.9(c)]). This setting implies
that all matrices Hk are orthogonal and hence that the transformation matrices

2.6
Transformations of Symplectic Systems
141
diag{H ‚àí1
k , H T
k } are symplectic and orthogonal. The transformed system then reads
ÀúSk+1 = ÀúPk ÀúSk + ÀúQk ÀúCk,
ÀúCk+1 = ‚àíÀúQk ÀúSk + ÀúPk ÀúCk,
where
ÀúPk = H ‚àí1
k+1PkHk,
ÀúQk = H ‚àí1
k+1QkHk = H ‚àí1
k
GkQkH T ‚àí1
k
so that indeed all matrices ÀúQk are symmetric and positive semideÔ¨Ånite.
By analogy with the continuous case (see Sect. 1.5.4), we formulate a necessary
and sufÔ¨Åcient condition of oscillation of (2.146) (see formula (1.136)).
Theorem 2.76 Assume that the matrices Qk in the trigonometric system (2.146)
are symmetric and positive deÔ¨Ånite. Then this system is nonoscillatory at ‚àûif and
only if
‚àû

k=0
arccot Œª(1)(Q‚àí1
k Pk) < ‚àû,
(2.155)
where Œª(1)(¬∑) denotes the minimal eigenvalue of the matrix indicated.
Proof The proof of this result can be found in [46].
‚äì‚äî
Remark 2.77 The previous theorem requires the matrices Qk in (2.146) to be posi-
tive deÔ¨Ånite. By the trigonometric transformation of (SDS) given in Theorem 2.74,
the matrices Qk are given by Qk = H ‚àí1
k+1BkH T ‚àí1
k
, hence a necessary condition for
positive deÔ¨Åniteness of Qk is nonsingularity of Bk. However, symplectic systems
(SDS) with Bk nonsingular do not cover a relatively large class of equations and
systems, e.g., the higher-order Sturm-Liouville difference equations (2.27), which
can be written in the form (SDS) with (see Example 2.21)
Bk =
1
r(n)
k
‚éõ
‚éú‚éù
0 . . . 0 1
...
...
...
0 . . . 0 1
‚éû
‚éü‚é†.
The extension of Theorem 2.74 to trigonometric systems with arbitrary Qk is given
in [96].
2.6.3
Hyperbolic Transformation
In this section we prove that any symplectic difference systems (SDS) satisfying
certain additional condition can be transformed into a hyperbolic system (see

142
2
Basic Theory of Symplectic Systems
Sect. 2.1.2). Consider the hyperbolic system (2.21) in the matrix form
Sk+1 = PkSk + QkCk,
Ck+1 = QkSk + PkCk,
(2.156)
with Pk and Qk satisfying (see (2.22))
PT
k Pk ‚àíQT
k Qk = I = PkPT
k ‚àíQkQT
k ,
PT
k Qk ‚àíQT
k Pk = 0 = PkQT
k ‚àíQkPT
k .
The fact that transformation (2.138) with Rk = P1 (see (2.20)) transforms this
system into itself implies that if (S, C) is a solution of (2.156), then (C, S) solves
this system as well. Consequently, if the matrix

Sk Ck
Ck Sk

is symplectic for some k,
then it is symplectic everywhere and the following identities hold:
ST
k Ck ‚àíCT
k Sk = 0 = SkCT
k ‚àíCkST ,
(2.157)
CT
k Ck ‚àíST
k Sk = I = CkCT
k ‚àíSkST
k .
(2.158)
Theorem 2.78 Suppose that symplectic system (SDS) possesses normalized con-
joined bases Y =
X
U

, ÀúY =
 ÀúX
ÀúU

such that Xk ÀúXT
k is positive deÔ¨Ånite in a given
discrete interval. Then, in this interval, there exist n √ó n-matrices Hk and Kk such
that Hk is nonsingular, H T
k Kk = KT
k Hk, and the transformation
sk
ck

=
 H ‚àí1
k
0
‚àíKT
k H T
k
 xk
uk

(2.159)
transforms symplectic system (SDS) into the hyperbolic system (2.156) without
changing the oscillatory behavior, i.e., a conjoined basis Yk of (SDS) has a focal
point in (k, k + 1] if and only if

H ‚àí1
k
Xk
‚àíKT
k Xk+H T
k Uk

has a focal point there. Moreover,
the matrices Pk and Qk are given by the formulas
Pk = H ‚àí1
k+1AkHk + H ‚àí1
k+1BkKk,
Qk = H ‚àí1
k+1BkH T ‚àí1
k
.
(2.160)
Proof Let Y =
X
U

and ÀúY =
 ÀúX
ÀúU

be normalized conjoined bases of (SDS) such that
Xk ÀúXT
k is positive deÔ¨Ånite, H be any n √ó n matrix satisfying
HkH T
k = 2Xk ÀúXT
k
(2.161)
and let
Kk := (Uk ÀúXT
k + ÀúUkXT
k ) H T ‚àí1
k
.
(2.162)

2.6
Transformations of Symplectic Systems
143
Then Hk is nonsingular by the assumption in Theorem 2.78. Consider the symplectic
fundamental solution matrix of system (SDS) of the form
Zk =
1
‚àö
2
( ÀúYk, Yk)
I ‚àíI
I
I

, and
then, by analogy with the proof of Theorem 2.74, we prove the identity
ZkP2ZT
k P2 = RkP2RT
k P2,
Rk :=
Hk
0
Kk H T ‚àí1
k

,
P2 = diag{I, ‚àíI},
(2.163)
where Hk and Kk are given by (2.161) and (2.162). Indeed, using that the matrix in
the left-hand side of this relation is symplectic (see Lemma 1.58 (iv)), we have by
(2.161) and (2.162) that HkH T
k KkH T
k is symmetric together with H T
k Kk. Moreover,
Uk ÀúUT
k + ÀúUkUT
k = 2Uk ÀúUT
k = KkKT
k ‚àí(HkH T
k )‚àí1. Then we have proved (2.163)
and the symplecticity of the transformation matrix Rk. Identity (2.163) implies the
relation
ÀúZkP2 ÀúZT
k P2 = I, ÀúZk = R‚àí1
k Zk
for the symplectic matrix ÀúZ, then
ÀúZk = P2 ÀúZT ‚àí1
k
P2 = P2 J ÀúZkJ T P2 = P1 ÀúZkP1,
where P1 :=
0 I
I 0

,
that is,
ÀúZk =
Ck Sk
Sk Ck

= R‚àí1
k Zk
(2.164)
is a symplectic and hyperbolic matrix. Moreover, since ÀúSk =
ÀúZk+1 ÀúZ‚àí1
k
is also
symplectic and hyperbolic, we have that ÀúZk solves hyperbolic system (2.156) with
the blocks given by (2.160) according to formulas (2.143) for the transformation
matrix Rk in (2.153). The proof is completed.
‚äì‚äî
Remark 2.79 By the same arguments as in Remark 2.75, one can transform any
hyperbolic system (2.156) into another hyperbolic system with symmetric and
positive semideÔ¨Ånite matrices ÀúQk at the position of the matrices Qk, using the
transformation
 Àúxk
Àúuk

=
H ‚àí1
k
0
0
H T
k
 xk
uk

,

144
2
Basic Theory of Symplectic Systems
where the matrices Hk are recursively deÔ¨Åned by H0 = I and Hk+1 = G‚àí1
k Hk
with orthogonal matrices Gk, i.e., GT
k Gk = I, such that GkQk are symmetric and
positive semideÔ¨Ånite. The transformed system then reads
Àúxk+1 = ÀúPk Àúxk + ÀúQk Àúuk,
Àúuk+1 = ÀúQk Àúxk + ÀúPk Àúuk,
where
ÀúPk = H ‚àí1
k+1PkHk
and
ÀúQk = H ‚àí1
k+1QkHk = H ‚àí1
k GkQkH T ‚àí1
k
,
so that indeed all matrices ÀúQk are symmetric and positive semideÔ¨Ånite.
Remark 2.80 This remark concerns the assumption of the existence of a pair of
normalized conjoined bases Y = X
U
 and ÀúY =  ÀúX
ÀúU
 such that Xk ÀúXT
k is positive
deÔ¨Ånite. If (SDS) is nonoscillatory at ‚àû(and eventually controllable), then this
system possesses the recessive and dominant solutions ¬ØY =  ¬ØX
¬ØU
 and ÀÜY =  ÀÜX
ÀÜU
 at ‚àû,
respectively, such that w( ¬ØY, ÀÜY ) = I. Then
Yk =
Xk
Uk

=
1
‚àö
2
( ÀÜYk + ¬ØYk),
ÀúYk =
 ÀúXk
ÀúUk

=
1
‚àö
2
( ¬ØYk ‚àíÀÜYk),
is a normalized pair of conjoined bases for which Xk ÀúXT
k = 1
2 ( ÀÜXk ÀÜXT
k ‚àí¬ØXk ¬ØXT
k ) is
positive deÔ¨Ånite eventually, since
lim
k‚Üí‚àû
ÀÜX‚àí1
k
¬ØXk = 0.
Consequently, any nonoscillatory symplectic difference system (SDS) at ‚àûcan be
transformed into a hyperbolic symplectic system.
2.6.4
Pr√ºfer Transformation
In this section, we present a discrete analog of Theorem 1.51 for systems (SDS)
which in turn generalizes results of Sect. 1.2.4 for the scalar Sturm-Liouville
equations.
Theorem 2.81 Let Y =
X
U

be a conjoined basis of (SDS). There exist nonsingular
matrices Hk and n √ó n matrices Sk and Ck such that
Xk = ST
k Hk,
Uk = CT
k Hk,
(2.165)

2.6
Transformations of Symplectic Systems
145
where
S
C

is a conjoined basis of (2.146) with
Pk = H T ‚àí1
k+1 Y T
k ST
k YkH ‚àí1
k ,
Qk = H T ‚àí1
k+1 Y T
k ST
k J YkH ‚àí1
k ,
(2.166)
and Hk solve the Ô¨Årst order difference system
Hk+1 = ÀúY T
k+1Sk ÀúYkHk,
ÀúYk =
ST
k
CT
k

.
(2.167)
Proof Let Y = X
U
 be a conjoined basis of (SDS), and let Hk be nonsingular
matrices satisfying H T
k Hk = XT
k Xk + UT
k Uk > 0. Introduce the 2n √ó 2n matrix
Zk = P1 (J YkH ‚àí1
k , YkH ‚àí1
k ) P1 =
CT
k ‚àíST
k
ST
k
CT
k

,
where P1 =
 0 I
I 0

. Then, according to properties (iv), (v), and (vii) in Lemma 1.58,
we have that Zk is symplectic and orthogonal (see Sect. 1.6.1), where we used the
fact
w(J YkH ‚àí1
k , YkH ‚àí1
k
) = H T ‚àí1
k
Y T
k YkH ‚àí1
k
= I.
Moreover, it is easy to verify directly that
ZT
k+1Zk = ÀúSk =
 Pk
Qk
‚àíQk Pk

,
(2.168)
where Pk and Qk are given by (2.166). Indeed, from (2.168) we have
(Ck+1 Sk+1)
CT
k
ST
k

= (Sk+1 Ck+1)
ST
k
CT
k

= H T ‚àí1
k+1 Y T
k+1YkH ‚àí1
k
= H T ‚àí1
k+1 Y T
k ST
k YkH ‚àí1
k
= Pk.
Similarly,
(Ck+1 Sk+1)
‚àíST
k
CT
k

= (Sk+1 Ck+1)
 CT
k
‚àíST
k

= H T ‚àí1
k+1 Y T
k ST
k J YkH ‚àí1
k
= Qk.

146
2
Basic Theory of Symplectic Systems
Certainly the matrix in the right-hand side of (2.168) is also symplectic and
orthogonal. Equation (2.168) implies
Sk+1
Ck+1

=
ÀúSk
Sk
Ck

, i.e., the matrix
Sk
Ck

is
a conjoined basis of (2.146). Finally, from (SDS), we have
ST
k+1
CT
k+1

Hk+1 = Sk
ST
k
CT
k

Hk, and
(2.169)
then, using the property SkST
k + CkCT
k
= I, we derive (2.167) by multiplying
(2.169) from the left by (Sk+1 Ck+1).
‚äì‚äî
2.7
Notes and References
Main references for various special symplectic systems are the books [4, 16]. In
addition, Jacobi matrix difference equations and symmetric three-term recurrence
equations are studied from the point of view of symplectic systems in [304]. For
properties of discrete linear Hamiltonian systems, we refer to the survey paper [3]
and to the book [4, Sections 2.3‚Äì2.7]. Basic properties of solutions of trigonometric
symplectic systems with nonsingular Bk are established in [25] and of hyperbolic
symplectic systems in [108].
To deÔ¨Åne properly the concept of a focal point in a given interval (more precisely,
the concept of ‚Äúno focal points‚Äù in this interval) of a conjoined basis of linear
Hamiltonian difference systems was a difÔ¨Åcult problem, which resisted its solution
for rather long time. The paper [39] of M. Bohner from 1996 constitutes a breaking
point in this direction, in which he presented the deÔ¨Ånition of this notion for the
linear Hamiltonian systems (2.15). More precisely, a conjoined basis Y =
X
U

of
(2.15) has no focal point in the interval (k, k + 1] if
Ker Xk+1 ‚äÜKer Xk,
Pk := XkX‚Ä†
k+1(I ‚àíAk)‚àí1Bk ‚â•0.
(2.170)
In earlier works, oscillatory properties of linear Hamiltonian difference systems
were studied only under the assumption that the matrix Bk is positive deÔ¨Ånite (see
the papers of Erbe and Yan [134‚Äì137]). This situation corresponds, in some sense,
to a controllable system (2.15). The notion of ‚Äúno (forward) focal points‚Äù in the
interval (k, k+1] for conjoined bases of symplectic system (SDS) in DeÔ¨Ånition 2.14
was introduced in [45] by M. Bohner and O. Do≈°l√Ω, and it was motivated by the
corresponding notion in (2.170) from [39]. In addition, the notion of ‚Äúno backward
focal points‚Äù in [k, k + 1) is also from [45]. A transformation between the notions
of no forward and backward focal points is presented in [300].
Identities in Lemma 2.26 and Corollary 2.27 were established in [189]. In this
respect it is surprising that the solvability of the explicit Riccati equation (2.52)
implies the invertibility of the matrices Ak + BkQk and DT
k ‚àíBT
k Qk+1. This fact is
not very very well known, and it brings the result in Theorem 2.28 to the same form
as in the continuous case‚Äîparts (ii) and (iii) of Theorem 1.47.

2.7
Notes and References
147
The importance of the study of equivalent conditions for the positivity and
nonnegativity of discrete quadratic functionals is justiÔ¨Åed by the results in Theo-
rems 1.26, 1.28, 1.32, and 1.33. The results on the nonnegativity of the functional
F (Theorem 2.44 in Sect. 2.3.5) is essentially from [54]. However, the latter
reference uses the necessity of the P-condition (2.73) for the nonnegativity of
F from [100, Theorem 1]. The results on discrete Reid roundabout theorems
(Theorems 2.36 and 2.41) are from [45]. A different proof of the equivalence
of parts (i), (ii), and (iv) in Theorem 2.36, based on a matrix diagonalization
technique, is presented in [171]. Extension of this technique to separated endpoints
and to the nonnegativity of a quadratic functional (Theorem 2.49) is presented in
[50, Theorem 2]. The extension of this nonnegativity result to the jointly varying
endpoints (Theorem 2.52) is derived in [174, Theorem 2]. The corresponding results
regarding the positivity of a quadratic functional (Theorems 2.50 and 2.53) are
from [181, Theorems 5 and 10]. We note that the latter paper contains also further
equivalent conditions for the positivity of the functional G in (2.84) in terms of
a conjoined basis Y of (SDS) with no forward focal points in (0, N + 1] and with
invertible Xk for all k ‚àà[0, N + 1]Z. This then yields an additional initial equality
or inequality at k = 0 (see [181, Theorems 6, 7, and 11]). First results on the
positivity of G with joint endpoints are proven in [42, Theorem 1]. A survey of these
conditions for continuous and discrete case is presented in [306]. In the literature
one can Ô¨Ånd additional conditions, which are equivalent to the positivity of discrete
quadratic functional F and G, such as the nonexistence of conjugate intervals [181],
the nonexistence of coupled intervals [180, 184, 188], the solvability of implicit
Riccati equations [173, 174, 181], or the positivity and nonnegativity of perturbed
quadratic functionals [175, 258]. Various Picone-type identities for symplectic
systems are derived in [191, 302]. Transformations which reduce the problem with
separated endpoints into a problem with zero endpoints on an extended interval,
and a problem with general jointly varying endpoints into a problem with separated
endpoints in the double dimension 2n (see Sect. 5.2.1 for more details) are known in
[39, 42, 53, 103] due to Bohner, Do≈°l√Ω, and Kratz, or earlier in [109] due to Dwyer
and Zettl. These techniques are also used in [173, 174, 181, 185]. Recently, another
transformation of this type was developed in [196, 308]. In this respect the statement
in Theorem 2.40 is a special case of [181, Theorem 7].
The inequalities for the Riccati-type quotients for symplectic systems presented
in Sect. 2.4.1 are from [173]. The results on discrete Riccati inequality (2.115)
in Sect. 2.4.2 are from [174]. For the discrete linear Hamiltonian system (1.102),
the Riccati inequality was derived in [176]. Further inequalities between symmetric
solutions of two Riccati equations (2.52) or Riccati inequalities (2.115) in the spirit
of Theorem 2.55 are proven in [300].
The results on recessive and dominant solutions of (SDS) at inÔ¨Ånity are
essentially from [81], with some small adjustments from the recent work [284].
In particular, the recessive and dominant solutions are introduced in Sect. 2.5.1
through the summation property (2.123) with (2.121), which was not the case
in [16, Section 3.11] and [25, 81]. In the latter references, the limit property in
Theorem 2.67 was used for this purpose as the deÔ¨Ånition. We refer to Remark 6.117

148
2
Basic Theory of Symplectic Systems
for more discussion on this subject. Recently, a theory of recessive and dominant
solutions of (SDS) was initiated in [284, 290] without the controllability assumption.
We will discuss these more general concepts in Sect. 6.3. Observe that the
arguments in the construction of the recessive solution at ‚àûof an eventually
controllable symplectic system (in the proof of Theorem 2.66) follow the more
general considerations presented in Sect. 6.3.5 (see the proof of Theorem 6.103).
This explicit construction of the recessive solution of (SDS) at ‚àûis also new in the
controllable case.
Transformation theory of symplectic systems was initiated by Bohner and Do≈°l√Ω
in [45]. The results on trigonometric, Pr√ºfer, and hyperbolic transformations in
Sects. 2.6.2‚Äì2.6.4 were obtained in [46, 47, 108]. Applications of trigonometric
and hyperbolic transformations in the oscillation theory of symplectic system
are derived in [48, 85, 106, 107]. Discrete matrix trigonometric and hyperbolic
functions, as solutions of discrete trigonometric and hyperbolic symplectic systems,
are deÔ¨Åned in [24, 194, 333].
We recommend the following additional related references for further reading
about the topics presented in this chapter: [9, 14, 40, 111, 237] for discrete Riccati
equations, [11, 15] for recessive and dominant solutions of special symplectic
systems, and [17, 84, 86, 88, 183, 266, 323, 324] for general theory of symplectic
difference systems. Moreover, results about more general theory of dynamic equa-
tions on time scales, in particular on Hamiltonian or symplectic dynamic systems
on time scales, are presented in [12, 49, 58, 59, 97, 99, 187, 190, 299, 307, 334].

Chapter 3
Comparative Index Theory
In this chapter we introduce the comparative index as a main mathematical tool for
the results in the subsequent chapters of this book. Recall from [27] that a subspace
span{u1, . . . , un} ‚äÜR2n is a Lagrangian subspace if it has dimension n and
uT
i J uj = 0 for all i and j. We introduce a notion of the comparative index Œº(Y, ÀÜY )
for a pair of Lagrangian subspaces represented by 2n √ó n matrices Y and ÀÜY with
conditions
Y TJ Y = 0,
rank Y = n,
(3.1)
(and similarly for ÀÜY). Depending on the formulation of the problem (see Chaps. 4
and 5), the matrices Y and ÀÜY can represent Lagrangian subspaces associated with
conjoined bases of system (SDS) or with symplectic coefÔ¨Åcient matrices Sk and ÀÜSk
of two symplectic systems (SDS) or with their fundamental solution matrices. For
the special case of Y := Yk+1 and ÀÜY := Sk(0 I)T , the comparative index Œº(Y, ÀÜY )
represents the main concept of the discrete oscillation theory‚Äîthe multiplicity of
a focal point (see Chap. 4). Because of this connection, algebraic properties of the
comparative index turned out to be an essential effective tool for solving several
important problems in the discrete oscillation theory.
3.1
Comparative Index and Its Properties
In this section we deÔ¨Åne one of the fundamental concepts of the oscillation theory of
symplectic difference systems, the concept of a comparative index of two matrices
satisfying (3.1).
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7_3
149

150
3
Comparative Index Theory
3.1.1
DeÔ¨Ånition of Comparative Index
Consider two 2n √ó n matrices Y =
X
U

and ÀÜY =
 ÀÜX
ÀÜU

satisfying (3.1) and let
w := w(Y, ÀÜY ) = Y TJ ÀÜY
(3.2)
be their Wronskian.
DeÔ¨Ånition 3.1 (Comparative Index) Let
Œº1(Y, ÀÜY ) := rankM,
M := (I ‚àíX‚Ä†X) w,
(3.3)
and
Œº2(Y, ÀÜY) := ind P,
P := T T (wT X‚Ä† ÀÜX) T ,
T := I ‚àíM‚Ä†M,
(3.4)
where M is deÔ¨Åned in (3.3). The quantity
Œº(Y, ÀÜY ) = Œº1(Y, ÀÜY ) + Œº2(Y, ÀÜY )
is called the comparative index of the matrices Y and ÀÜY.
The next result will be important in proving the properties of the comparative
index.
Theorem 3.2 The following statements hold.
(i) The matrix M in (3.3), (3.4) can be replaced by the matrix
Àú
M := (I ‚àíXX‚Ä†) ÀÜX,
(3.5)
i.e., rankM = rank Àú
M and
T = I ‚àíM‚Ä†M = I ‚àíÀú
M‚Ä† Àú
M.
(3.6)
(ii) The condition Œº1(Y, ÀÜY ) = 0 is equivalent to the condition Im ÀÜX ‚äÜIm X. In
this case T = I and
Œº(Y, ÀÜY) = Œº2(Y, ÀÜY ) = ind [ ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX],
(3.7)
where Q and ÀÜQ are symmetric matrices such that
XT QX = XT U,
ÀÜXT ÀÜQ ÀÜX = ÀÜXT ÀÜU.
(3.8)

3.1
Comparative Index and Its Properties
151
In particular, if X and ÀÜX are invertible, then
Œº(Y, ÀÜY ) = Œº2(Y, ÀÜY ) = ind( ÀÜQ ‚àíQ),
Q := UX‚àí1,
ÀÜQ := ÀÜU ÀÜX‚àí1.
(3.9)
(iii) The matrix P in (3.4) is symmetric and can be presented in the form
P = T T [ ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX] T ,
(3.10)
where Q and ÀÜQ are any symmetric matrices satisfying (3.8) and T is deÔ¨Åned
by (3.6) with M and
Àú
M given by (3.3) and (3.5).
(iv) The equality Œº(Y, ÀÜY) = 0 holds if and only if
Im ÀÜX ‚äÜIm X
and
ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX ‚â•0,
(3.11)
where Q = QT and ÀÜQ = ÀÜQT are again given by (3.8).
Proof
(i) By (3.3) we have
M = (I ‚àíX‚Ä†X) w = (I ‚àíX‚Ä†X) (XT ÀÜU ‚àíUT ÀÜX)
= ‚àí(I ‚àíX‚Ä†X) UT ÀÜX = ‚àí(I ‚àíX‚Ä†X) UT (I ‚àíXX‚Ä†) ÀÜX
= LT (I ‚àíXX‚Ä†) ÀÜX = LT Àú
M,
where we have used (1.171) and where the (invertible) matrix L is deÔ¨Åned in
(1.174). Then rank M = rank Àú
M. Furthermore, the equality M‚Ä†M =
Àú
M‚Ä† Àú
M
holds by Lemma 1.63. Hence, we proved (3.6), and the matrix M in (3.3) and
(3.4) can be replaced by
Àú
M.
(ii) By the previous part of the proof, we have Œº1(Y, ÀÜY) = 0 if and only if M =
0 =
Àú
M. Then ÀÜX = XX‚Ä† ÀÜX, which is equivalent by (1.160) to the condition
Im ÀÜX ‚äÜIm X. In this case T = I ‚àíM‚Ä†M = I and the matrix
P = wT X‚Ä† ÀÜX = ( ÀÜUT X ‚àíÀÜXT U) X‚Ä† ÀÜX = ÀÜUT ÀÜX ‚àíÀÜXT (XT )‚Ä†XT UX‚Ä† ÀÜX
are symmetric, since we suppose (3.1). In addition, if symmetric matrices Q
and ÀÜQ satisfy (3.8), then
P = ÀÜXT ÀÜQ ÀÜX ‚àíÀÜXT (XT )‚Ä†XT QXX‚Ä† ÀÜX = ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX,
where we have again used that
Àú
M = 0, i.e., ÀÜX = XX‚Ä† ÀÜX. In this case we
have Œº(Y, ÀÜY) = Œº1(Y, ÀÜY ) + Œº2(Y, ÀÜY ) = Œº2(Y, ÀÜY ) = ind P. In particular, for
invertible X and ÀÜX, obviously Œº1(Y, ÀÜY ) = 0 holds, and, hence, Q = UX‚àí1,
ÀÜQ = ÀÜU ÀÜX‚àí1, and (3.9) follows from (3.7).

152
3
Comparative Index Theory
(iii) In the general case, we have MT = 0, i.e., Im( ÀÜXT ) ‚äÜIm X. Then the matrix
wT X‚Ä† ÀÜX in (3.4) is symmetric, when restricted to the subspace Im T . Indeed,
repeating the arguments from part (ii) of this proof, we obtain
P = T T [ ÀÜUT ÀÜX ‚àíÀÜXT (XT )‚Ä†XT UX‚Ä† ÀÜX] T = T XT ( ÀÜQ ‚àíQ) ÀÜXT = PT ,
so that P is symmetric. Recall that we proved (3.6) in part (i).
(iv) This statement is a direct consequence of part (ii).
‚äì‚äî
Remark 3.3 Observe that the comparative index is not a commutative function of
Y and ÀÜY. Later, in Theorem 3.5(v) we present the connection between Œº(Y, ÀÜY) and
Œº( ÀÜY, Y).
Remark 3.4 We now evaluate the comparative index for some special cases.
(i) As it was already mentioned in Theorem 3.2(ii), when det X Ã∏= 0 and det ÀÜX Ã∏=
0, then M =
Àú
M = 0, and Q = UX‚àí1, ÀÜQ = ÀÜU ÀÜX‚àí1, so that we get Œº(Y, ÀÜY ) =
ind( ÀÜQ ‚àíQ).
(ii) If ÀÜX = 0, then Œº(Y, ÀÜY ) = 0 for any Y according to (3.5) and (3.10).
(iii) If X = 0, then Œº2(Y, ÀÜY ) = 0 by (3.4) and Œº(Y, ÀÜY ) = Œº1(Y, ÀÜY ) = rank ÀÜX.
(iv) If U = 0, then det X Ã∏= 0, and Œº1(Y, ÀÜY ) = 0, Œº2(Y, ÀÜY ) = ind ÀÜXT ÀÜU.
3.1.2
Dual Comparative Index
In this subsection we introduce the so-called dual comparative index Œº‚àó(Y, ÀÜY ),
whose deÔ¨Ånition is very similar to that of the standard comparative index (DeÔ¨Å-
nition 3.1), only the matrix J in (3.3) and (3.4), and in particular in the deÔ¨Ånition
of the Wronskian (3.2), is replaced by the matrix J T = ‚àíJ . We deÔ¨Åne
Œº‚àó
1(Y, ÀÜY ) := Œº1(Y, ÀÜY ),
Œº‚àó
2(Y, ÀÜY ) := ind(‚àíP)
(3.12)
with P given in (3.4). The dual comparative index Œº‚àó(Y, ÀÜY ) is deÔ¨Åned as
Œº‚àó(Y, ÀÜY ) := Œº‚àó
1(Y, ÀÜY ) + Œº‚àó
2(Y, ÀÜY ).
Observe that if the 2n √ó n matrices Y and ÀÜY satisfy (3.1), then the matrices P2Y
and P2 ÀÜY with P2 = diag{I, ‚àíI} given in (1.151) satisfy the same condition, because
the matrix P2 is invertible and
P T
2 J P2 = ‚àíJ ,
(P2Y)TJ (P2Y) = Y T P T
2 J P2Y = ‚àíY TJ Y = 0.

3.1
Comparative Index and Its Properties
153
Consequently, the dual comparative index can be determined by the formula
Œº‚àó
i (Y, ÀÜY ) = Œºi(P2Y, P2 ÀÜY),
i ‚àà{1, 2},
(3.13)
with P2 given by (1.151). Observe also that the dual comparative index as introduced
in (3.12) makes it possible to compute the signature and the rank of P, which are
the difference and the sum of the numbers of positive and negative eigenvalues of
P, see [148, Chapter 10]. Indeed, we have the formulas
sgn P = Œº‚àó
2(Y, ÀÜY ) ‚àíŒº2(Y, ÀÜY ) = Œº‚àó(Y, ÀÜY ) ‚àíŒº(Y, ÀÜY),
rankP = Œº‚àó
2(Y, ÀÜY ) + Œº2(Y, ÀÜY ).
The terminology ‚Äúdual‚Äù comparative index will be explained later in this section.
3.1.3
Basic Properties of Comparative Index
Let Z and ÀÜZ be symplectic matrices, and let Y and ÀÜY be 2n √ó n matrices given by
the formulas
Y =
X
U

= Z
0
I

,
ÀÜY =
 ÀÜX
ÀÜU

= ÀÜZ
0
I

.
(3.14)
Then, by Lemma 1.58(v), the matrices Y and ÀÜY obey condition (3.1). Conversely, as
we showed in Lemma 1.58(vi), given a 2n√ón matrix Y satisfying (3.1), there exists
another 2n√ón matrix ÀúY satisfying (3.1) such that Z = ( ÀúY Y) is a symplectic matrix,
for which (3.14) holds. Moreover, in this case the matrices ÀúY and Y are normalized
in the sense that w( ÀúY , Y) = I, by Lemma 1.58(v).
In the next theorem, we present basic properties of the comparative index.
Theorem 3.5 Let Y =
X
U

and ÀÜY =
 ÀÜX
ÀÜU

be 2n √ó n matrices satisfying (3.1),
and let w(Y, ÀÜY ) be their Wronskian deÔ¨Åned in (3.2). The comparative index has the
following properties.
(i) Œºi(YC1, ÀÜYC2) = Œºi(Y, ÀÜY ), i ‚àà{1, 2}, where C1, C2 are invertible n √ó n
matrices. This property can be reformulated for Z and ÀÜZ given by (3.14) as
Œºi

Z(0 I)T , ÀÜZ(0 I)T 
= Œºi

ZL1(0 I)T , ÀÜZL2(0 I)T 
,
i ‚àà{1, 2},
where L1, L2 are arbitrary 2n √ó 2n lower block-triangular symplectic
matrices.

154
3
Comparative Index Theory
(ii) Œºi(LY, L ÀÜY ) = Œºi(Y, ÀÜY ), i ‚àà{1, 2}, and hence Œº(LY, L ÀÜY ) = Œº(Y, ÀÜY), where
L is any 2n √ó 2n lower block-triangular symplectic matrix.
(iii) For any symplectic matrices Z and ÀÜZ, we have
Œºi

Z(0 I)T , ÀÜZ(0 I)T 
= Œº‚àó
i

Z‚àí1(0 I)T , Z‚àí1 ÀÜZ(0 I)T 
,
i ‚àà{1, 2}.
(iv) Œº2(Y, ÀÜY) = Œº‚àó
2( ÀÜY, Y).
(v) Œº(Y, ÀÜY) + Œº( ÀÜY, Y) = rank w(Y, ÀÜY ). This property can be reformulated for
the matrices Z and ÀÜZ given by (3.14) as
Œº

Z(0 I)T , ÀÜZ(0 I)T 
+Œº

ÀÜZ(0 I)T , Z(0 I)T 
= Œº

(0 I)T , Z‚àí1 ÀÜZ(0 I)T 
.
(vi) Œº1(Y, ÀÜY) = rank ÀÜX ‚àírankX + Œº1( ÀÜY, Y). In view of (iv), this is equivalent to
Œº(Y, ÀÜY) = rank ÀÜX ‚àírank X + Œº‚àó( ÀÜY, Y).
(vii) 0 ‚â§Œº(Y, ÀÜY ) ‚â§p and 0 ‚â§Œº‚àó(Y, ÀÜY ) ‚â§p, where p = p(Y, ÀÜY ) is deÔ¨Åned by
p := min {rankw(Y, ÀÜY ), rank ÀÜX, rank ÀÜX ‚àírankX + rank w(Y, ÀÜY )}.
(3.15)
In particular,
Œº(Y, ÀÜY ) = rank ÀÜX
‚áî

Œº1(Y, ÀÜY ) = rank w(Y, ÀÜY ) ‚àírankX,
Œº2(Y, ÀÜY ) = rank ÀÜX + rank X ‚àírankw(Y, ÀÜY ),
‚áîŒº( ÀÜY, Y) = rankw(Y, ÀÜY ) ‚àírank ÀÜX,
‚áî
Œº1( ÀÜY, Y) = rankw(Y, ÀÜY ) ‚àírank ÀÜX,
Œº2( ÀÜY, Y) = 0,
‚áîŒº‚àó(Y, ÀÜY ) = rankw(Y, ÀÜY ) ‚àírank X,
‚áî
Œº‚àó
1(Y, ÀÜY ) = rankw(Y, ÀÜY ) ‚àírank X,
Œº‚àó
2(Y, ÀÜY ) = 0,
‚áîŒº‚àó( ÀÜY, Y) = rank X,
‚áî

Œº‚àó
1( ÀÜY, Y) = rank w(Y, ÀÜY ) ‚àírank ÀÜX,
Œº‚àó
2( ÀÜY, Y) = rank X + rank ÀÜX ‚àírank w(Y, ÀÜY ),

3.1
Comparative Index and Its Properties
155
and
Œº(Y, ÀÜY ) = rankw(Y, ÀÜY )
‚áî

Œº1(Y, ÀÜY ) = rank ÀÜX ‚àírankX,
Œº2(Y, ÀÜY ) = rankw(Y, ÀÜY ) ‚àírank ÀÜX + rankX,
‚áîŒº( ÀÜY, Y) = 0,
‚áîŒº‚àó( ÀÜY, Y) = rank X ‚àírank ÀÜX + rank w(Y, ÀÜY ),
‚áî

Œº‚àó
1( ÀÜY, Y) = 0,
Œº‚àó
2( ÀÜY, Y) = rank X ‚àírank ÀÜX + rank w(Y, ÀÜY ),
‚áîŒº‚àó(Y, ÀÜY ) = rank ÀÜX ‚àírankX,
‚áî
Œº‚àó
1(Y, ÀÜY ) = rank ÀÜX ‚àírankX,
Œº‚àó
2(Y, ÀÜY ) = 0,
and
Œº(Y, ÀÜY ) = rank ÀÜX ‚àírank X + rankw(Y, ÀÜY )
‚áî

Œº1(Y, ÀÜY ) = 0,
Œº2(Y, ÀÜY ) = rank ÀÜX ‚àírank X + rankw(Y, ÀÜY ),
‚áîŒº‚àó(Y, ÀÜY ) = 0,
‚áîŒº‚àó( ÀÜY, Y) = rank w(Y, ÀÜY ),
‚áî

Œº‚àó
1( ÀÜY, Y) = rank X ‚àírank ÀÜX,
Œº‚àó
2( ÀÜY, Y) = rank ÀÜX ‚àírankX + rank w(Y, ÀÜY ),
‚áîŒº( ÀÜY, Y) = rankX ‚àírank ÀÜX,
‚áî
Œº1( ÀÜY, Y) = rankX ‚àírank ÀÜX,
Œº2( ÀÜY, Y) = 0.
(viii) It holds
Œº

J Y, J ÀÜY

= Œº(Y, ÀÜY) + Œº

J Y, (I 0)T 
‚àíŒº

J ÀÜY, (I 0)T 
.
(ix) For arbitrary symplectic matrices W, Z, ÀÜZ, we have
Œº

WZ(0 I)T , W(0 I)T 
‚àíŒº

W ÀÜZ(0 I)T , W(0 I)T 
= Œº

ÀÜZ(0 I)T , W ‚àí1(0 I)T 
‚àíŒº

Z(0 I)T , W ‚àí1(0 I)T 
.

156
3
Comparative Index Theory
The proof of the previous theorem is postponed for later (see Sects. 3.1.5
and 3.2.2).
At this moment we present a result which plays a key role in the comparative
index theory. In particular it shows how the comparative index behaves under
a symplectic transformation.
Theorem 3.6 (Main Theorem on the Comparative Index) Let Z, ÀÜZ, W be
arbitrary 2n √ó 2n symplectic matrices. Then
Œº

WZ(0 I)T , W ÀÜZ(0 I)T 
‚àíŒº

Z(0 I)T , ÀÜZ(0 I)T 
= Œº

WZ(0 I)T , W(0 I)T 
‚àíŒº

W ÀÜZ(0 I)T , W(0 I)T 
.
(3.16)
Proof First of all, observe that properties (ii) and (viii) of the the previous theorem
are particular cases of (3.16) with W = L or W = J , since it is not difÔ¨Åcult to
verify that
Œº

LZ(0 I)T , L(0 I)T 
= Œº

L ÀÜZ(0 I)T , L(0 I)T 
= 0
for a lower block-triangular matrix L (see (ii) of Remark 3.4). Then, to prove the
statement of theorem, it sufÔ¨Åces to apply Theorem 1.74 concerning the represen-
tation of a symplectic matrix W as a product W = H1L2H3 = J L1J L2J L3J ,
where H1, H2 are upper block-triangular symplectic matrices and L1, L2, L3 are
lower block-triangular symplectic matrices. We prove that if (3.16) holds for
symplectic matrices W1, W2 (instead of W) for arbitrary symplectic matrices Z, ÀÜZ,
then this formula holds also for their product W = W1W2. To show this, we use Ô¨Årst
(3.16) for W = W2 and then for W = W1. So we have
Œº

W2 Z(0 I)T , W2 ÀÜZ(0 I)T 
‚àíŒº

Z(0 I)T , ÀÜZ(0 I)T 
= Œº

W2 Z(0 I)T , W2(0 I)T 
‚àíŒº

W2 ÀÜZ(0 I)T , W2(0 I)T 
= Œº

W ‚àí1
1 W2 Z(0 I)T , W ‚àí1
1 W2(0 I)T 
+ Œº

W2 Z(0 I)T , W1(0 I)T 
‚àíŒº

W ‚àí1
1 W2 ÀÜZ(0 I)T , W ‚àí1
1 W2(0 I)T 
‚àíŒº

W2 ÀÜZ(0 I)T , W1(0 I)T 
.
On the other hand, by using the assumption that (3.16) holds for W = W1 and
arbitrary symplectic Z and ÀÜZ, we obtain
Œº

W2 Z(0 I)T , W2 ÀÜZ(0 I)T 
= Œº

W1(W ‚àí1
1 W2 Z)(0 I)T , W1(W ‚àí1
1 W2 ÀÜZ)(0 I)T 
= Œº

W ‚àí1
1 W2 Z(0 I)T , W ‚àí1
1 W2 ÀÜZ(0 I)T 
+ Œº

W2 Z(0 I)T , W1(0 I)T 
‚àíŒº

W2 ÀÜZ(0 I)T , W1(0 I)T 
.

3.1
Comparative Index and Its Properties
157
If we compare the obtained expressions and cancel the same terms, then we get
Œº

W ‚àí1
1 W2 Z(0 I)T , W ‚àí1
1 W2 ÀÜZ(0 I)T 
‚àíŒº

Z(0 I)T , ÀÜZ(0 I)T 
= Œº

W ‚àí1
1 W2 Z(0 I)T , W ‚àí1
1 W2(0 I)T 
‚àíŒº

W ‚àí1
1 W2 ÀÜZ(0 I)T , W ‚àí1
1 W2(0 I)T 
.
Consequently, formula (3.16) holds for W = W ‚àí1
1 W2. In particular, if (3.16) holds
for W1, then it holds also for W ‚àí1
1 . Now it sufÔ¨Åces to apply the already proved
statement to the pair of matrices W ‚àí1
1
and W2. Hence, we obtain validity of (3.16)
for W = W1W2. Applying the proved ‚Äúmultiplicative‚Äù rule to the product W =
J L1J L2J L3J , we obtain that (3.16) holds for any symplectic matrix W.
‚äì‚äî
Remark 3.7 Given that formula (3.16) holds with W = J and W = L (where
L is a lower block-triangular symplectic matrix), we can use the factorization of
a symplectic matrix W into the product W = J L1J L2J L3J (where L1, L2, L3
are lower block-triangular symplectic matrices) to show that (3.16) holds for any
symplectic matrix W. This yields another proof of Theorem 3.6. Indeed, it sufÔ¨Åces
to prove that if (3.16) holds for a symplectic W, then it holds also for J W and LW.
However, the validity of (3.16) for J W and LW follows by a double application of
properties (viii) and (ii) of Theorem 3.5, respectively.
By using (ix) of Theorem 3.5, formula (3.16) can be restated as
Œº

WZ(0 I)T , W ÀÜZ(0 I)T 
‚àíŒº

Z(0 I)T , ÀÜZ(0 I)T 
= Œº

ÀÜZ(0 I)T , W ‚àí1(0 I)T 
‚àíŒº

Z(0 I)T , W ‚àí1(0 I)T 
.
(3.17)
From (3.17) we derive the following property, which we call the ‚Äútriangle
inequality‚Äù for the comparative index.
Theorem 3.8 (Triangle Inequality) For arbitrary symplectic matrices W1, W2,
and W3 of dimension 2n, we have
ŒºW1(0 I)T , W3(0 I)T 
‚â§Œº

W1(0 I)T , W2(0 I)T 
+ Œº

W2(0 I)T , W3(0 I)T 
.
(3.18)
Moreover, the equality in (3.18) holds if and only if
ŒºW ‚àí1
3 W1(0 I)T , W ‚àí1
3 W2(0 I)T 
= Œº‚àó
W ‚àí1
1 W3(0 I)T , W ‚àí1
1 W2(0 I)T 
= 0.
(3.19)

158
3
Comparative Index Theory
Proof From (3.17) we have
Œº

Z(0 I)T , ÀÜZ(0 I)T 
+ Œº
 ÀÜZ(0 I)T , W ‚àí1(0 I)T 
= Œº

WZ(0 I)T , W ÀÜZ(0 I)T 
+ Œº

Z(0 I)T , W ‚àí1(0 I)T 
.
Putting Z := W1, ÀÜZ := W2 and W ‚àí1 := W3, we derive
Œº

W1(0 I)T , W2(0 I)T 
+ Œº

W2(0 I)T , W3(0 I)T 
= Œº

W ‚àí1
3 W1(0 I)T , W ‚àí1
3 W2(0 I)T 
+ Œº

W1(0 I)T , W3(0 I)T 
.
Using that Œº

W ‚àí1
3 W1(0 I)T , W ‚àí1
3 W2(0 I)T 
‚â•0, we derive (3.18). From the last
identity, we have (3.19), where we also used Theorem 3.5(iii).
‚äì‚äî
The following lower bounds of the comparative index complement the upper
bounds in Theorem 3.5(vii).
Lemma 3.9 Let Y and ÀúY be 2n √ó n matrices satisfying (3.1). Then
min{Œº(Y, ÀÜY), Œº‚àó(Y, ÀÜY )}
‚â•max{0, rank ÀÜX ‚àírankX, rank w(Y, ÀÜY ) ‚àírankX}.
(3.20)
Proof We know from property (vi) in Theorem 3.5 and from Œº‚àó( ÀÜY, Y) ‚â•0 that
the inequality Œº(Y, ÀÜY ) ‚â•rank ÀÜX ‚àírankX holds. Similarly from property (vi) in
Theorem 3.5 applied to Œº( ÀÜY, Y) ‚â•0, we get Œº‚àó(Y, ÀÜY) ‚â•rank ÀÜX ‚àírankX. Next,
the properties (iii) and (vi) in Theorem 3.5 imply that
Œº(Y, ÀÜY) = Œº‚àó(Z‚àí1(0 I)T , Z‚àí1 ÀÜY)
= rankw(Y, ÀÜY ) ‚àírank X + Œº(Z‚àí1 ÀÜY, Z‚àí1(0 I)T )
(3.21)
= rankw(Y, ÀÜY ) ‚àírank X + Œº‚àó( ÀÜZ‚àí1Y, ÀÜZ‚àí1(0 I)T )
(3.22)
and then Œº(Y, ÀÜY ) ‚â•rank w(Y, ÀÜY ) ‚àírank X. In a similar way, we obtain from
the properties (iii) and (vi) in Theorem 3.5 for the dual comparative index (see
also Theorem 3.11 below) that Œº‚àó(Y, ÀÜY ) ‚â•rankw(Y, ÀÜY ) ‚àírank X. Therefore, the
estimates in (3.20) are proved.
‚äì‚äî

3.1
Comparative Index and Its Properties
159
Remark 3.10
(i) From Lemma 3.9 and property (vii) in Theorem 3.5, we have the estimates
r ‚â§Œº(Y, ÀÜY) ‚â§p,
r ‚â§Œº‚àó(Y, ÀÜY ) ‚â§p,
r := max{0, rank ÀÜX ‚àírank X, rankw(Y, ÀÜY ) ‚àírankX},
p := min{rankw(Y, ÀÜY ), rank ÀÜX, rank ÀÜX ‚àírankX + rankw(Y, ÀÜY )},
‚é´
‚é™‚é¨
‚é™‚é≠
(3.23)
where the lower and upper bounds r and p are such that
r + p = rank ÀÜX ‚àírankX + rank w(Y, ÀÜY ).
(3.24)
Identity (3.24) can be easy veriÔ¨Åed by direct computations.
(ii) It follows from property (vii) of Theorem 3.5 that Œº(Y, ÀÜY) achieves the upper
bound p if and only if the dual index Œº‚àó(Y, ÀÜY ) coincides with the lower
bound r in (3.23). Replacing the roles of Y and ÀÜY in the formulation of
Theorem 3.5 (vii), we see that the condition Œº‚àó(Y, ÀÜY ) = p is equivalent to
Œº(Y, ÀÜY) = r.
(iii) Putting a := rankX, b := rank ÀÜX, and c := rank w(Y, ÀÜY ), we see from (3.23)
that the quantities a ‚â•0, b ‚â•0, c ‚â•0 obey the triangle inequalities a ‚â§b+c,
c ‚â§a + b, b ‚â§a + c. This fact can be proved independently using the
well-known inequalities rank(AB) ‚â§min{rankA, rank B} and rank(A+B) ‚â§
rankA + rankB.
3.1.4
Duality Principle for Comparative Index
Observe that the properties of Œº(Y, ÀÜY) displayed in the previous subsection can be
reformulated for the dual comparative Œº‚àó(Y, ÀÜY ). This reformulation is given in the
next theorem.
Theorem 3.11 Concerning the dual comparative index the following holds.
(i) The properties (i)‚Äì(ix) of Theorem 3.5 hold also for the dual comparative index
Œº‚àó.
(ii) Any formula, proved using properties (i)‚Äì(ix) of Theorem 3.5, holds also for
the dual comparative index in the ‚Äúdual form‚Äù; the comparative index Œº is
replaced by the dual comparative index Œº‚àóand vice versa.
Proof We will use the matrices P2 given in (1.151). In view of (3.12) and (3.13),
we have
Œº‚àó‚àó
i (Y, ÀÜY ) = (Œº‚àó
i (Y, ÀÜY))‚àó= (Œºi(P2Y, P2 ÀÜY))‚àó= Œºi(Y, ÀÜY ),
i ‚àà{1, 2}.

160
3
Comparative Index Theory
Since property (i) of Theorem 3.5 holds for any matrices satisfying (3.1), we have
Œºi(P2YC1, P2 ÀÜYC2) = Œºi(P2Y, P2 ÀÜY), i ‚àà{1, 2}. Consequently, this property holds
also for the dual comparative index. Then obviously
Œº
‚éõ
‚éù
k'
i=1
Wi(0 I)T ,
l'
j=1
Vj(0 I)T
‚éû
‚é†= Œº
‚éõ
‚éù
k'
i=1
Wi(0 ‚àíI)T ,
l'
j=1
Vj(0 ‚àíI)T
‚éû
‚é†
= Œº
‚éõ
‚éùP2
k'
i=1
(P2WiP2)(0 I)T , P2
l'
j=1
(P2VjP2)(0 I)T
‚éû
‚é†
= Œº‚àó
‚éõ
‚éù
k'
i=1
(P2WiP2)(0 I)T ,
l'
j=1
(P2VjP2)(0 I)T
‚éû
‚é†
(3.25)
for the products *k
i=1 Wi and *l
j=1 Vj of arbitrary symplectic matrices Wi and Vj.
Since P2J P2 = ‚àíJ in view of property (iv) of Lemma 1.58, we have
Wi, Vj ‚ààSp(2n) ‚áîP2WiP2, P2VjP2 ‚ààSp(2n),
i ‚àà{1, . . . , k}, j ‚àà{1, . . . , l}.
Consequently, since each of the properties (i)‚Äì(vii), (ix) holds for any symplectic
matrices Z, ÀÜZ, W, it holds also for the matrices P2ZP2, P2 ÀÜZP2, P2WP2. Therefore,
because of (3.25), these properties hold for Œº‚àó. Further, a matrix L ‚ààSp(2n)
is lower block-triangular if and only if P2LP2 ‚ààSp(2n), where P2LP2 is also
lower block-triangular. This means in view of (3.25) that property (ii) for the dual
comparative index is proved. Now we prove property (viii) for the dual comparative
index. It follows from property (i) and J T = ‚àíJ that the matrix J in (viii) can be
replaced by J T . Then we have
Œº

J TZ(0 I)T , J T ÀÜZ(0 I)T 
= Œº

Z(0 I)T , ÀÜZ(0 I)T 
+ Œº

J TZ(0 I)T , J T(0 I)T 
‚àíŒº

J T ÀÜZ(0 I)T , J T(0 I)T 
for any symplectic matrices Z and ÀÜZ. Upon taking P2ZP2 and P2 ÀÜZP2 instead of Z
and ÀÜZ and using that J T = P2J P2, we derive
Œº

P2J Z(0 ‚àíI)T , P2J ÀÜZ(0 ‚àíI)T 
= Œº

P2Z(0 ‚àíI)T , P2 ÀÜZ(0 ‚àíI)T 
+ Œº

P2J Z(0 ‚àíI)T , P2J (0 ‚àíI)T 
‚àíŒº

P2J ÀÜZ(0 ‚àíI)T , P2J (0 ‚àíI)T 
,

3.1
Comparative Index and Its Properties
161
or the same formula in the dual form
Œº‚àó
J Z(0 ‚àíI)T , J ÀÜZ(0 ‚àíI)T 
= Œº‚àó
Z(0 ‚àíI)T , ÀÜZ(0 I)T 
+ Œº‚àó
J Z(0 ‚àíI)T , J (0 ‚àíI)T 
‚àíŒº‚àó
J ÀÜZ(0 ‚àíI)T , J (0 ‚àíI)T 
.
Since property (i) holds for the dual comparative index, we derive property (viii) for
the dual index as well. This completes the proof of the Ô¨Årst part of theorem. The
proof of the second part is obvious.
‚äì‚äî
In particular, the following ‚Äúdual‚Äù reformulation of (3.17) holds:
Œº‚àó
Z(0 I)T , ÀÜZ(0 I)T 
‚àíŒº‚àó
WZ(0 I)T , W ÀÜZ(0 I)T 
= Œº‚àó
Z(0 I)T , W ‚àí1(0 I)T 
‚àíŒº‚àó
ÀÜZ(0 I)T , W ‚àí1(0 I)T 
.
(3.26)
And for further reference, we also present the dual version of the main theorem for
the comparative index (Theorem 3.6).
Corollary 3.12 Let Z, ÀÜZ, W be arbitrary 2n √ó 2n symplectic matrices. Then
Œº‚àó
WZ(0 I)T , W ÀÜZ(0 I)T 
‚àíŒº‚àó
Z(0 I)T , ÀÜZ(0 I)T 
= Œº‚àó
WZ(0 I)T , W(0 I)T 
‚àíŒº‚àó
W ÀÜZ(0 I)T , W(0 I)T 
.
(3.27)
3.1.5
Proof of Properties (i)‚Äì(vii), (ix) of Comparative Index
As we have already mentioned before, the proof of Theorem 3.5 substantially uses
the results of Sect. 1.6.3. The proof of the Ô¨Årst two properties uses Lemmas 1.63
and 1.64.
Proof of Property (i) According to Theorem 3.2,
Œº1(YC1, ÀÜYC2) = rank [(I ‚àí(XC1) (XC1)‚Ä†] ÀÜXC2
= rank (I ‚àíXX‚Ä†) ÀÜXC2 = Œº1(Y, ÀÜY ),
where we have used Lemma 1.63. Applying Lemma 1.64 in computing the
comparative index Œº2(YC1, ÀÜYC2) by (3.10), we have
T = I ‚àí[(I ‚àíXX‚Ä†) ÀÜXC2]‚Ä†(I ‚àíXX‚Ä†) ÀÜXC2
= C‚àí1
2

I ‚àí[(I ‚àíXX‚Ä†) ÀÜX]‚Ä†(I ‚àíXX‚Ä†) ÀÜX
 ÀúT ,
det ÀúT Ã∏= 0.

162
3
Comparative Index Theory
Since det C1 Ã∏= 0, then
CT
1 XT QXC1 = CT
1 XT UC1 ‚áîXT QX = XT U,
so that in the computation of Œº2(YC1, ÀÜYC2) by using (3.10), one can take any
symmetric matrices Q and ÀÜQ satisfying (3.8). Hence, we obtain
Œº2(YC1, ÀÜYC2) = indT T CT
2 ÀÜXT ( ÀÜQ ‚àíQ) ÀÜXC2T  = Œº2(Y, ÀÜY),
where we have used the above formula for T and the fact that the matrix ÀúT is
invertible. This proves property (i).
‚äì‚äî
Proof of Property (ii) Recall that any symplectic lower block-triangular matrix L is
of the form L =

K
0
P KT ‚àí1

, where PK‚àí1 = (PK‚àí1)T . Then obviously
w(LY, L ÀÜY ) = Y T LTJ L ÀÜY = Y TJ ÀÜY = w(Y, ÀÜY ),
and I ‚àí(KX)‚Ä†(KX)
=
I ‚àíX‚Ä†X because of Lemma 1.63. According to
DeÔ¨Ånition 3.1, Œº1(LY, L ÀÜY ) = Œº1(Y, ÀÜY ) and the multiplication of Y and ÀÜY by L
do not change the matrix T . Consequently, it is sufÔ¨Åcient to prove that
P = T T 
wT (KX)‚Ä†K ÀÜX

T = T T 
wT X‚Ä† ÀÜX

T .
Observe that by Theorem 3.2, the matrix M in (3.3) can be replaced by the matrix
Àú
M = (I ‚àíXX‚Ä†) ÀÜX and that
Àú
MT = 0, which is equivalent to ÀÜXT = XX‚Ä† ÀÜXT or
K ÀÜXT = KXX‚Ä† ÀÜXT . Consequently,
(KX)‚Ä†K ÀÜX T = (KX)‚Ä†KXX‚Ä† ÀÜX T = X‚Ä†XX‚Ä† ÀÜXT = X‚Ä† ÀÜX T ,
and hence Œº2(LY, L ÀÜY ) = Œº2(Y, ÀÜY ). The property (ii) is now proved.
‚äì‚äî
Proof of Property (iii) The proof is based on Theorem 3.2. Indeed,
‚àíw

Z‚àí1(0 I)T , Z‚àí1 ÀÜZ (0 I)T 
= (0 I) ZT ‚àí1J T Z‚àí1 ÀÜZ (0 I)T
= (0 I) J T ÀÜZ (0 I)T = ÀÜX,
(3.28)
where we have used that ZT ‚àí1J T Z‚àí1 = J T . Further, (I 0) Z‚àí1(0 I)T = ‚àíXT ,
and hence the number Œº‚àó
1 in the right-hand side of property (iii) computed according
to (3.12), (3.3) complies with Œº1(Y, ÀÜY ), computed using the Ô¨Årst statement of
Theorem 3.2. It is not difÔ¨Åcult to verify that (I 0) Z‚àí1 ÀÜZ(0 I)T = ‚àíw(Y, ÀÜY ), and,
hence, the index Œº‚àó
2, computed in the right-hand side of property (iii), is Œº2(Y, ÀÜY ),
where we also used the symmetry of the matrix P in (3.4).
‚äì‚äî

3.1
Comparative Index and Its Properties
163
The proof of properties (iv) and (v) is based on the results of Lemma 1.68 and
Theorem 1.70.
Proof of Property (iv) We will use Theorem 1.70 applying factorizations (1.180) to
Y and ÀÜY. Using the already proved properties (i) and (ii),
Œº(Y, ÀÜY) = ŒºN(I 0)T , L‚àí1 ÀÜL ÀÜN (I 0)T ,
(3.29)
where the symplectic matrices L and N := NXX‚Ä† are determined by (1.180) and
(1.179) with Y, and the symplectic matrices ÀÜL and ÀÜN := N ÀÜX ÀÜX‚Ä† are determined in
a similar way with ÀÜY. In order to shorten the notation, we deÔ¨Åne the matrices
F := XX‚Ä†,
G := I ‚àíXX‚Ä†,
ÀÜF := ÀÜX ÀÜX‚Ä†,
ÀÜG := I ‚àíÀÜX ÀÜX‚Ä†.
Then, evaluating (3.29) according to formulas (3.5) and (3.10), we have M = G ÀÜF,
P = T ÀÜF( ÀÜQ ‚àíQ) ÀÜFT , and
ÀÜFT = ÀÜF(I ‚àíM‚Ä†M) = (F + G) ÀÜF(I ‚àíM‚Ä†M) = F ÀÜF(I ‚àíM‚Ä†M).
(3.30)
The matrix NT ÀÜN (0 I)T satisÔ¨Åes (3.1), and then using (1.171) for NT ÀÜN (0 I)T and
Remark 1.60(vii), we obtain
F ÀÜF(I ‚àíM‚Ä†M) = F(F ÀÜF + G ÀÜG) [I ‚àíM‚Ä†M ‚àí(M‚àóT )‚Ä†M‚àóT ]
= F [I ‚àíMM‚Ä† ‚àíM‚àóT (M‚àóT )‚Ä†] (F ÀÜF + G ÀÜG) √ó
√ó [I ‚àíM‚Ä†M ‚àí(M‚àóT )‚Ä†M‚àóT ]
= ‚àíF(I ‚àíM‚àó‚Ä†M‚àó) L,
where M‚àó= ÀÜGF and the invertible matrix L are determined for NT ÀÜN (0 I)T by
formula (1.174). Therefore, we have proved that
ÀÜFT = ‚àíFT ‚àóL,
T = I ‚àíM‚Ä†M, T ‚àó= I ‚àíM‚àó‚Ä†M‚àó,
M = G ÀÜF,
M‚àó= ÀÜGF,
det L Ã∏= 0,

(3.31)
or T ÀÜF( ÀÜQ ‚àíQ) ÀÜFT = LT T ‚àóF( ÀÜQ ‚àíQ) FT ‚àóL. Therefore, we have
Œº2(Y, ÀÜY ) = ind T ÀÜF( ÀÜQ‚àíQ) ÀÜFT = ind T ‚àóF( ÀÜQ‚àíQ) FT ‚àó= Œº‚àó
2( ÀÜY, Y),
(3.32)
which shows that the property (iv) holds.
‚äì‚äî

164
3
Comparative Index Theory
Proof of Property (v) We Ô¨Årst substitute factorization (1.180) for Y and ÀÜY into
w(Y, ÀÜY ). Using the notation of Theorem 1.70, we obtain
w(Y, ÀÜY ) = MT [G ÀÜF ‚àíF ÀÜG + F( ÀÜQ ‚àíQ) ÀÜF] ÀÜM
= MT M1[M ‚àíM‚àóT + T ‚àóF( ÀÜQ ‚àíQ) ÀÜFT ] M2 ÀÜM,
where the invertible matrices M and ÀÜM are determined by (1.180) via Y and ÀÜY, the
matrices M and M‚àóare given by (3.31), and the matrices
M1 := I + FT ‚àó( ÀÜQ ‚àíQ) M‚Ä†G, M2 = I ‚àíÀÜGM‚àóT ‚Ä†( ÀÜQ ‚àíQ) ÀÜF
are obviously also invertible in view of (1.163) and the orthogonality of the
projectors F, G, ÀÜF, ÀÜG. Using Lemma 1.68 again for the matrix NT ÀÜN (0 I)T (see
the proof of the property (iv)) and using (3.31), we have
w(Y, ÀÜY ) = ‚àíMT M1[M M‚Ä† + M‚àó‚Ä†M‚àó+ T ‚àóF( ÀÜQ ‚àíQ) FT ‚àó] L M2 ÀÜM.
Consequently,
rankw(Y, ÀÜY ) = rank [MM‚Ä† + M‚àó‚Ä†M‚àó+ T ‚àóF( ÀÜQ ‚àíQ) FT ‚àó]
= rank M + rankM‚àó+ rankT ‚àóF( ÀÜQ ‚àíQ) FT ‚àó
= Œº1(Y, ÀÜY ) + Œº1( ÀÜY, Y) + ind T ‚àóF( ÀÜQ ‚àíQ) FT ‚àó
+ ind T ‚àóF(‚àíÀÜQ + Q) FT ‚àó= Œº(Y, ÀÜY) + Œº( ÀÜY, Y),
where we have used (3.32), and in computing the rank of a sum of two matrices,
we have used that rank(A + B) = rank A + rankB if AT B = ABT = 0 (see
Remark 1.60(vii)). This completes the proof of property (v).
‚äì‚äî
Proof of Property (vi) This property is a consequence of formula (1.142) for the
rank of a product of two matrices. But it can also be obtained from the proofs of the
previous properties. In fact, using properties (iii) and (v), we obtain
Œº(Y, ÀÜY) = Œº‚àó
Z‚àí1(0 I)T , Z‚àí1 ÀÜZ(0 I)T 
= rank ÀÜX ‚àíŒº‚àó
Z‚àí1 ÀÜZ(0 I)T , Z‚àí1(0 I)T 
,
(3.33)
where, in addition, it is used in formula (3.28). Further
Œº‚àó
Z‚àí1 ÀÜZ(0 I)T , Z‚àí1(0 I)T 
= Œº

ÀÜZ‚àí1Z(0 I)T , ÀÜZ‚àí1(0 I)T 
= rank X ‚àíŒº

ÀÜZ‚àí1(0 I)T , ÀÜZ‚àí1Z(0 I)T 
= rank X ‚àíŒº‚àó
ÀÜZ(0 I)T , Z(0 I)T 
,

3.1
Comparative Index and Its Properties
165
where we have again used properties (iii) and (v). Finally, using property (iv), we
conclude the proof of property (vi).
‚äì‚äî
Proof of Property (vii) Observe that Œº(Y, ÀÜY ) ‚â§min{rankw, rank ÀÜX} follows from
property (v) and (3.33). Combining properties (v) and (vi), we also have the identity
Œº(Y, ÀÜY ) + Œº‚àó(Y, ÀÜY ) = rank ÀÜX ‚àírankX + rank w(Y, ÀÜY ) ‚â•0,
(3.34)
which means that Œº(Y, ÀÜY ) ‚â§p(Y, ÀÜY ), where p(Y, ÀÜY ), is given by (3.15). A similar
estimate holds also for Œº‚àó(Y, ÀÜY ). In view of the property (v) and the dual form of
the properties (vi) and (v), it is also obvious that
Œº(Y, ÀÜY ) = rank ÀÜX
(v)
‚áîŒº( ÀÜY, Y) = rankw(Y, ÀÜY ) ‚àírank ÀÜX
(vi)
‚áîŒº‚àó(Y, ÀÜY ) = rankw(Y, ÀÜY ) ‚àírankX
(v)
‚áîŒº‚àó( ÀÜY, Y) = rank X.
(3.35)
Further, by (3.33) we have
Œº(Y, ÀÜY) = rank ÀÜX
‚áî
Œº‚àó
Z‚àí1 ÀÜZ(0 I)T , Z‚àí1(0 I)T 
= 0,
so that
Œº‚àó
1

Z‚àí1 ÀÜZ(0 I)T , Z‚àí1(0 I)T 
= rank[I ‚àíw(Y, ÀÜY ) w(Y, ÀÜY )‚Ä†] XT = 0.
Using the properties (iii) and (vi) with Z‚àí1(0 I)T and Z‚àí1 ÀÜZ(0 I)T , we obtain
Œº1(Y, ÀÜY ) = Œº‚àó
1

Z‚àí1(0 I)T , Z‚àí1 ÀÜZ(0 I)T 
= rank w(Y, ÀÜY ) ‚àírankX.
(3.36)
Hence, we showed that the equality Œº(Y, ÀÜY ) = rank ÀÜX is necessary and sufÔ¨Åcient
for the identities
Œº1(Y, ÀÜY ) = rankw(Y, ÀÜY ) ‚àírankX,
Œº2(Y, ÀÜY ) = rank ÀÜX + rank X ‚àírankw(Y, ÀÜY )

(3.37)
Applying the property (vi), we see that (3.36) is equivalent with
Œº1( ÀÜY, Y) = rankw(Y, ÀÜY ) ‚àírank ÀÜX.
(3.38)
Combining conditions (3.36), (3.38) with (3.35), we derive all equalities referred to
the case Œº(Y, ÀÜY) = rank ÀÜX. Similar equivalences hold also for the case Œº‚àó(Y, ÀÜY ) =
rank ÀÜX because of the duality principle (see Sect. 3.1.4). The remaining cases of

166
3
Comparative Index Theory
Œº(Y, ÀÜY) = rankw(Y, ÀÜY ) and Œº(Y, ÀÜY) = rank ÀÜX ‚àírankX + rankw(Y, ÀÜY ) can be
treated analogously.
‚äì‚äî
Proof of Property (ix) Applying properties (v), (iii), and Ô¨Ånally (vi), we obtain
Œº

WZ(0 I)T , W(0 I)T 
‚àíŒº

W ÀÜZ(0 I)T , W(0 I)T 
= Œº

(0 I)T , Z(0 I)T 
‚àíŒº

(0 I)T , ÀÜZ(0 I)T 
‚àíŒº

W(0 I)T , WZ(0 I)T 
+ Œº

W(0 I)T , W ÀÜZ(0 I)T 
= Œº

(0 I)T , Z(0 I)T 
‚àíŒº

(0 I)T , ÀÜZ(0 I)T 
‚àíŒº‚àó
W ‚àí1(0 I)T , Z(0 I)T 
+ Œº‚àó
W ‚àí1(0 I)T , ÀÜZ(0 I)T 
= Œº

ÀÜZ(0 I)T , W ‚àí1(0 I)T 
‚àíŒº

Z(0 I)T , W ‚àí1(0 I)T 
.
This completes the proofs of properties (i)‚Äì(vii) and (ix) in Theorem 3.5.
‚äì‚äî
Concerning the proof of the property (viii), this proof requires results about index
of a block symmetric operator. The connection of the comparative index and the
index of some symmetric operators is the subject of the next section.
3.2
Comparative Index and Symmetric Operators
This section is devoted to establishing a connection between the comparative index
and the negative inertia index of some symmetric operator. In the next chapter, we
will show that the multiplicity of a focal point in the interval (k, k + 1] is fully
determined by a suitable comparative index, and, hence, there is a deep connection
between the (non)oscillation and the (non)existence of negative eigenvalues of
a symmetric operator associated with (SDS).
3.2.1
Index of Block Symmetric Matrices
In this subsection we prove results concerning the index of symmetric 2n √ó 2n
matrices consisting of four n √ó n matrices.
Let B
A‚àºC mean that the matrices B and C are congruent, i.e., B = AT CA with
det A Ã∏= 0. An important role in our treatment is played by the next lemma.

3.2
Comparative Index and Symmetric Operators
167
Lemma 3.13 Let D, X ‚ààRn√ón, where D is symmetric. Then
ind
 0 X
XT D

= rankX + ind (I ‚àíX‚Ä†X) D (I ‚àíX‚Ä†X).
Proof Suppose that the singular value decomposition of X is of the form V UT ,
where  is the diagonal matrix having the singular values of X on the diagonal, and
U and V are orthogonal matrices. Then
K :=
 0 X
XT D

A‚àº
 0
F
F GUTDUG

,
A :=
(G + ) V T
S
0
UT

,
where F := ‚Ä†, G := I ‚àíF and S := 1
2 UT DU(I + G) UT . Then
ind K = ind
0 F
F 0

+ diag{0, GUTDUG}

= ind
0 F
F 0

+ ind (GUTDUG)
and
ind
0 F
F 0

= rankF = rankX,
and, in view of Remark 1.60 (ii),
ind (GUTDUG) = ind (I ‚àíX‚Ä†X)TD (I ‚àíX‚Ä†X).
The proof is complete.
‚äì‚äî
An important consequence of Lemma 3.13 and of Theorem 3.2 is formulated in
the next statement.
Lemma 3.14 Let Y and ÀÜY satisfy (3.1). Then, using the notation of Theorem 3.2,
we have
Œº(Y, ÀÜY) = i‚àí(),
Œº‚àó(Y, ÀÜY ) = i+(),
 =

0
(I ‚àíXX‚Ä†) ÀÜX
ÀÜXT (I ‚àíXX‚Ä†)
ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX

,
Y =
X
U

,
ÀÜY =
 ÀÜX
ÀÜU

,
‚é´
‚é™‚é¨
‚é™‚é≠
(3.39)
where i‚àí() = ind(Œ¶) is the number of negative eigenvalues, and i+() is the
number of positive eigenvalues of the (symmetric) matrix .

168
3
Comparative Index Theory
Proof The result follows directly from Lemma 3.13, Theorem 3.2, and (3.12).
‚äì‚äî
In particular, for the cases mentioned in Remark 3.4, the corresponding matrices
have the following form.
(i) If det X Ã∏= 0 and det ÀÜX Ã∏= 0, then  = diag{0, ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX} and
Œº(Y, ÀÜY ) = i‚àí( ÀÜQ ‚àíQ),
Œº‚àó(Y, ÀÜY ) = i+( ÀÜQ ‚àíQ).
(ii) If X = 0, it follows that
 =
 0
ÀÜX
ÀÜXT
ÀÜXT ( ÀÜQ ‚àíQ) ÀÜX

,
Œº(Y, ÀÜY) = Œº‚àó(Y, ÀÜY ) = rank ÀÜX.
(iii) If U = 0, then det X Ã∏= 0 and hence
 = diag{0, ÀÜXT ÀÜQ ÀÜX},
Œº(Y, ÀÜY) = i‚àí( ÀÜXT ÀÜU),
Œº‚àó(Y, ÀÜY ) = i+( ÀÜXT ÀÜU).
The next statement is a generalization of Lemma 3.13.
Lemma 3.15 Let AT = A, DT = D, and X be square matrices. Then
ind
 A X
XT D

= ind A + ind

0
(I ‚àíAA‚Ä†) X
[(I ‚àíAA‚Ä†)X]T D ‚àíXT A‚Ä†X

= ind A + rank M
+ ind (I ‚àíM‚Ä†M) (D ‚àíXT A‚Ä†X) (I ‚àíM‚Ä†M)
= ind D + ind
A ‚àíXD‚Ä†XT XT (I ‚àíDD‚Ä†)
(I ‚àíDD‚Ä†) X
0

= ind D + rank ÀúM
+ ind (I ‚àíÀúM‚Ä† ÀúM) (A ‚àíXD‚Ä†XT ) (I ‚àíÀúM‚Ä† ÀúM),
where ÀúM := (I ‚àíDD‚Ä†) XT and M := (I ‚àíAA‚Ä†) X.
Proof Using the congruent transformation, we obtain
K =
 A X
XT D

P‚àº

A
(I ‚àíAA‚Ä†) X
[(I ‚àíAA‚Ä†) X]T D ‚àíXT A‚Ä†X

, P =
I A‚Ä†X
0
I

.

3.2
Comparative Index and Symmetric Operators
169
Consequently, in view of Lemma 3.13,
ind K = ind

diag{A, 0} +

0
(I ‚àíAA‚Ä†) X
[(I ‚àíAA‚Ä†) X]T D ‚àíXT A‚Ä†X

= ind A + ind

0
(I ‚àíAA‚Ä†) X
[(I ‚àíAA‚Ä†) X]T D ‚àíXT A‚Ä†X

= ind A + rankM + ind [(I ‚àíM‚Ä†M) (D ‚àíXT A‚Ä†X) (I ‚àíM‚Ä†M)],
where M = (I ‚àíAA‚Ä†) X. Observe that
K
P1‚àº
D XT
X A

= ÀúK,
P1 =
0 I
I 0

.
Consequently, applying the just proved result to the congruent matrix ÀúK, we obtain
ind K = ind ÀúK = ind D + rank ÀúM + ind [(I ‚àíÀúM‚Ä† ÀúM) (A ‚àíXD‚Ä†XT ) (I ‚àíÀúM‚Ä† ÀúM)],
where ÀúM = (I ‚àíDD‚Ä†) XT . The statement is proved.
‚äì‚äî
The following corollary to Lemma 3.15 was used in the formulation of a compar-
ison theorem for differential and difference Hamiltonian systems; see [43, 51, 205].
Corollary 3.16 The symmetric matrix

A X
XT D

is nonnegative deÔ¨Ånite if and only
if
A ‚â•0,
D ‚àíXT A‚Ä†X ‚â•0,
Im X ‚äÜIm A,
(3.40)
which is equivalent to
D ‚â•0,
A ‚àíXD‚Ä†XT ‚â•0,
Ker D ‚äÜKer X.
(3.41)
3.2.2
Symmetric Operator [V ] and Proof of Property (viii)
In the deÔ¨Ånition of the quadratic functional (2.56), we have used the symmetry of
the operator
[Sk] := ST
k
0 I
0 0

Sk ‚àí
0 I
0 0

acting on the group of symplectic matrices determining (SDS). Recall that according
to property (v) of Lemma 1.58, the 2n √ó n blocks of Sk satisfy (1.147) and (1.148).

170
3
Comparative Index Theory
A generalization of [Sk] is the operator, acting on pairs of matrices Y, ÀÜY
satisfying only (3.1). Let a 2n √ó 2n matrix V consist of 2n √ó n matrices
V = (Y ÀÜY),
Y =
X
U

,
ÀÜY =
 ÀÜX
ÀÜU

.
(3.42)
Then under the assumption
XT U = UT X,
ÀÜXT ÀÜU = ÀÜUT ÀÜX,
(3.43)
the operator
[V ] := diag{UT , ÀÜXT } V =
UT X UT ÀÜX
ÀÜXT U ÀÜXT ÀÜU

= V T
0 I
0 0

V ‚àí

0 w(Y, ÀÜY )
0
0

(3.44)
is symmetric (here w(Y, ÀÜY ) = Y TJ ÀÜY). Next we prove some properties of this
operator.
Lemma 3.17
(i) Let W be a symplectic matrix, and V be determined by (3.42) and (3.43). Then
[WV ] = V T [W] V + [V ],
(3.45)
(ii) It holds
[J V J T ] = ‚àíJ [V ] J T .
(3.46)
Proof
(i) By the deÔ¨Ånition of the operator , we have
[WV ] = V T W T
0 I
0 0

WV ‚àí
0 w(WY, W ÀÜY )
0
0

= V T

W T
0 I
0 0

W ‚àí
0 I
0 0
 
V + V T
0 I
0 0

V ‚àí
0 w(Y, ÀÜY )
0
0

= V T [W] V + [V ].
where we have used (1.148) for W and
w(WY, W ÀÜY ) = Y T W TJ W ÀÜW = Y TJ ÀÜY = w(Y, ÀÜY ).
This proves (3.45).

3.2
Comparative Index and Symmetric Operators
171
(ii) Again, by the deÔ¨Ånition of , we have
‚àíJ [V ]J T = ‚àíJ
UT X UT ÀÜX
ÀÜXT U ÀÜXT ÀÜU

J T
=
‚àíÀÜXT ÀÜU
ÀÜXT U
UT ÀÜX ‚àíUT X

= [J ÀÜY, ‚àíJ Y] = [J VJ T ],
which proves (3.46).
‚äì‚äî
An important role in our treatment is played by the following results describing
the relationship between [V ] and the comparative index; see [115, Lemma 4.4].
Proposition 3.18 If V = (Y, ÀÜY) and Y, ÀÜY satisfy (3.1), then
ind [V ] = ind XT U + Œº(Y, ÀÜY) = ind ÀÜXT ÀÜU + Œº‚àó(J ÀÜY, J Y),
(3.47)
hence, the comparative index Œº(Y, ÀÜY) can be expressed as
Œº(Y, ÀÜY ) = ind [V ] ‚àíind XT U.
(3.48)
Proof To compute ind [V ], we use (1.180) for Y and ÀÜY. Using the same notation
as in the proof of property (iv) in Theorem 3.5, it is possible to verify that
[V ] = AT
FQF
‚àíG ÀÜF
‚àíÀÜFG
2 ÀÜFG ÀÜF + ÀÜF ÀÜQ ÀÜF ‚àíÀÜFFQF ÀÜF

A,
A =
(I ‚àíGQF) M
ÀÜF ÀÜM
0
ÀÜM

,
where det M Ã∏= 0, det ÀÜM Ã∏= 0, det(I ‚àíGQF) Ã∏= 0 and, hence, the matrix A is
invertible. Consequently, by Lemma 3.15, we have
ind [V ] = ind FQF + ind

0
‚àíG ÀÜF
‚àíÀÜFG
2 ÀÜFG ÀÜF + ÀÜF ÀÜQ ÀÜF ‚àíÀÜF FQF ÀÜF

= ind MT FQFM + rankM + ind T ÀÜF( ÀÜQ ‚àíQ) ÀÜFT
= ind XT QX + Œº(Y, ÀÜY ) = ind XT U + Œº(Y, ÀÜY),
where we have used (3.31), (3.32), and (3.30). This proves the Ô¨Årst part of formula
(3.47). To prove the second part, we use property (ii) of Lemma 3.17. Then
ind [V ] = ind (‚àíŒõ[J V J T ]) = ind (‚àíŒõ[J ÀÜY, ‚àíJ Y])
= ind ÀÜXT ÀÜU + Œº‚àó(J ÀÜY, J Y),

172
3
Comparative Index Theory
where ind (‚àí[J ÀÜY, ‚àíJ Y]) is computed analogously as ind [V ] in the proof of
the Ô¨Årst equality in (3.47). The proof is now complete.
‚äì‚äî
As a corollary to Proposition 3.18, we have a similar result for the dual
comparative index Œº‚àó(Y, ÀÜY).
Corollary 3.19 Under the assumptions of Proposition 3.18, we have
ind (‚àí[V ]) = ind (‚àíXT U) + Œº‚àó(Y, ÀÜY ) = ind (‚àíÀÜXT ÀÜU) + Œº(J ÀÜY, J Y).
(3.49)
Hence, the comparative index Œº‚àó(Y, ÀÜY ) can be expressed as
Œº‚àó(Y, ÀÜY ) = ind (‚àí[V ]) ‚àíind (‚àíXT U),
(3.50)
and then
Œº(Y, ÀÜY) + Œº‚àó(Y, ÀÜY ) = rank [V ] ‚àírank XT U
= rank ÀÜX ‚àírankX + rankw(Y, ÀÜY ).
(3.51)
Proof We apply Proposition 3.18 to the case P2Y, P2 ÀÜY, where P2 = diag{I, ‚àíI}
(see Lemma 1.58). It is easy to verify that [ ÀúV ] = ‚àí[V ], where ÀúV := (P2Y P2 ÀÜY)
and V := (Y
ÀÜY). Then the proof of (3.49) and (3.50) is completed. Formula
(3.51) follows from (3.34). Note that for the case of w(Y, ÀÜY ) = I, we have
rank([V ]) = rankU + rank ÀÜX, where the nonsingularity of V is used. For this
special case, formula (3.51) takes the form
Œº(Y, ÀÜY) + Œº‚àó(Y, ÀÜY ) = rankU + rank ÀÜX ‚àírank(XT U) = rank ÀÜX ‚àírank X + n,
which can also be derived from (1.185).
‚äì‚äî
We conclude this section with a statement, which yields the proof of property
(viii) of Theorem 3.5.
Proposition 3.20 Formula (3.47) and property (viii) of Theorem 3.5 are equivalent.
Proof By property (vi) of Theorem 3.5, we obtain the equality
Œº‚àó(J ÀÜY, J Y) = rank U ‚àírank ÀÜU + Œº(J Y, J ÀÜY).
Consequently, (3.47) equivalent to
Œº‚àó(J ÀÜY, J Y) = Œº(Y, ÀÜY ) + ind XT U ‚àíind ÀÜXT ÀÜU,
and this is equivalent to
Œº(J Y, J ÀÜY) = Œº(Y, ÀÜY ) + p,
p := ind XT U ‚àírankU + rank ÀÜU ‚àíind ÀÜXT ÀÜU.

3.3
Comparative Index for Symplectic Matrices
173
On the other hand, it is possible to prove that p = Œº

J Y, (I 0)T 
‚àíŒº

J ÀÜY, (I 0)T 
.
Indeed, if we compute the above comparative indices by using Theorem 3.2, we
obtain
Œº

J Y, (I 0)T 
= rank (I ‚àíUU‚Ä†) + ind XT U = n ‚àírankU + ind XT U,
Œº

J ÀÜY, (I 0)T 
= rank (I ‚àíÀÜU ÀÜU‚Ä†) + ind ÀÜXT ÀÜU = n ‚àírank ÀÜU + ind ÀÜXT ÀÜU.
The proof is complete.
‚äì‚äî
3.3
Comparative Index for Symplectic Matrices
In this section we introduce the comparative index for a pair of matrices determined
by the blocks of symplectic matrices W, ÀÜW ‚ààR2n√ó2n. The comparative index
for symplectic matrices plays a fundamental role in comparison theorems for
symplectic systems. It enables to formulate an exact relationship between the
number of focal points of conjoined bases of two symplectic systems. Another
problem, where we apply the results of this section, is the theory of boundary value
problems associated with (SDS).
3.3.1
Basic Properties
We introduce the following notation. For any matrix W =
 A B
C D

‚ààR2n√ó2n, we
deÔ¨Åne the 4n √ó 2n matrix
‚ü®W‚ü©:=
‚éõ
‚éú‚éú‚éù
I
0
A B
0 ‚àíI
C D
‚éû
‚éü‚éü‚é†.
(3.52)
For easier application of the identities below, we note that when W is a symplectic
matrix, then its inverse satisÔ¨Åes W ‚àí1 =

DT
‚àíBT
‚àíCT
AT

; see Lemma 1.58(ii).
Lemma 3.21 Let W, ÀÜW ‚ààR2n√ó2n be symplectic matrices. Then the matrices ‚ü®W‚ü©
and ‚ü®ÀÜW‚ü©deÔ¨Åned in (3.52) have the following properties.
(i) The matrix ‚ü®W‚ü©satisÔ¨Åes (3.1), i.e., rank‚ü®W‚ü©= 2n, ‚ü®W‚ü©TJ ‚ü®W‚ü©= 0.
(ii) For the Wronskian of ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©, we have the relations
w(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = ‚ü®W‚ü©TJ ‚ü®ÀÜW‚ü©= ‚àíJ (I ‚àíW ‚àí1 ÀÜW),
rankw(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = rank(W ‚àíÀÜW),

174
3
Comparative Index Theory
and the comparative index for ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©obeys the estimate
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©)
‚â§min
!
rank(W ‚àíÀÜW), n + rank ÀÜB, rank(W ‚àíÀÜW) + rank ÀÜB ‚àírankB
"
.
(3.53)
(iii) The comparative index of ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©satisÔ¨Åes
Œºi(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº‚àó
i (‚ü®W ‚àí1‚ü©, ‚ü®ÀÜW ‚àí1‚ü©), i ‚àà{1, 2}.
(iv) The comparative index of ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©satisÔ¨Åes
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = rank ÀÜB ‚àírankB + Œº‚àó(‚ü®ÀÜW‚ü©, ‚ü®W‚ü©).
(v) The comparative index of ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©satisÔ¨Åes
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº

W(0 I)T , ÀÜW(0 I)T 
+ Œº

‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©

(3.54)
= Œº‚àó
W ‚àí1(0 I)T , ÀÜW ‚àí1(0 I)T 
+ Œº

‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©

.
(3.55)
(vi) We have the identity
Œº

W(0 I)T , ÀÜW(0 I)T 
‚àíŒº‚àó
W ‚àí1(0 I)T , ÀÜW ‚àí1(0 I)T 
= Œº

‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©

‚àíŒº

‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©

.
Proof of Parts (i)‚Äì(iv) For part (i) we have that rank‚ü®W‚ü©= rank W = 2n and
I 0
A B
T 0 ‚àíI
C D

=
CT A CT B
BT C BT D

=
AT C CT B
BT C DT B

=
0 ‚àíI
C D
T I 0
A B

,
where we have used property (1.145) of a symplectic matrix.
For part (ii) we have
‚ü®W‚ü©TJ ‚ü®ÀÜW‚ü©=
I 0
A B
T 0 ‚àíI
ÀÜC
ÀÜD

‚àí
0 ‚àíI
C D
T I 0
ÀÜA ÀÜB

=J T (I ‚àíW ‚àí1 ÀÜW).
Consequently, we obtain the identity
rank‚ü®W‚ü©TJ ‚ü®ÀÜW‚ü© = rank (I ‚àíW ‚àí1 ÀÜW) = rank [W ‚àí1(W ‚àíÀÜW)]
= rank (W ‚àíÀÜW).

3.3
Comparative Index for Symplectic Matrices
175
Estimate (3.53) follows from the upper bound for the comparative index in property
(vii) of Theorem 3.5, where we evaluate
rank
I 0
A B

= rank
I 0
A I

diag{I, B}
= rank diag{I, B} = n + rank B.
By a similar way, we evaluate the rank of the 2n √ó 2n upper block of ‚ü®ÀÜW‚ü©.
For the proof of property (iii), we note that by Theorem 3.5(i)‚Äì(ii), we obtain
Œºi

‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©

= Œºi

L‚ü®W‚ü©W ‚àí1, L‚ü®ÀÜW‚ü©ÀÜW ‚àí1
= Œºi

P2‚ü®W ‚àí1‚ü©, P2‚ü®ÀÜW ‚àí1‚ü©

for i ‚àà{1, 2}, where
L := diag
0 I
I 0

,
0 I
I 0
 
,
P2 = diag{I2n, ‚àíI2n},
and, in view of (3.13), Œºi(P2Y, P2 ÀÜY) = Œº‚àó
i (Y, ÀÜY) for any Y =
X
U

and ÀÜY =
 ÀÜX
ÀÜU

satisfying (3.1).
Property (iv) is a consequence of Theorem 3.5(vi). Obviously, for our particular
case, we evaluate the ranks of the upper blocks of ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©by analogy with the
proof of (ii) and substitute them into Theorem 3.5(vi). This then yields the proof of
part (iv) of this lemma.
‚äì‚äî
The proof of properties (v) and (vi) will be given in Sect. 3.3.6. Here we point
out that this rather technical proof is based on a generalization of Theorem 3.6
(see Lemma 3.23 below) and on additional algebraic properties of the comparative
indices for (3.52) (see Proposition 3.37).
The main result of this section is the generalization of Theorem 3.6 to the case
where instead of Z, ÀÜZ, W, four matrices Z, ÀÜZ, W, ÀÜW are used. For this purpose
introduce the notation
L(Y, ÀÜY , W, ÀÜW) := Œº( ÀÜW ÀÜY, ÀÜW(0 I)T ) ‚àíŒº(WY, W(0 I)T )
+Œº(WY, ÀÜW ÀÜY) ‚àíŒº(Y, ÀÜY),

(3.56)
where Y = Z(0 I)T and ÀÜY = ÀÜZ(0 I)T are 2n √ó n matrices satisfying conditions
(3.1). We prove the following properties of operator (3.56).
Lemma 3.22 Let Y and ÀÜY be 2n √ó n matrices satisfying (3.1). Then the following
properties of operator in (3.56) hold.
(i) For any symplectic matrix W, we have L(Y, ÀÜY , W, W) = 0.
(ii) For p ‚ààN and symplectic matrices W1, . . . , Wp and ÀÜW1, . . . , ÀÜWp, we deÔ¨Åne
Z(r) :=
r'
k=1
Wr‚àík+1 = WrWr‚àí1 . . . W1, ÀÜZ(r) :=
r'
k=1
ÀÜWr‚àík+1, r = 1, . . . , p,

176
3
Comparative Index Theory
and Z(0) := I, ÀÜZ(0) := I. Then we have the following ‚Äúmultiplicative
property‚Äù of operator (3.56):
L(Y, ÀÜY , Z(p), ÀÜZ(p)) =
p

r=1
L

Z(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY, Wr, ÀÜWr

+
p

r=1

Œº

Z(r) (0 I)T , Wr(0 I)T 
‚àíŒº
 ÀÜZ(r) (0 I)T , ÀÜWr(0 I)T 
.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(3.57)
Proof For the proof of (i), we use Theorem 3.6, which is equivalent to property (i).
For the proof of (ii), we note that by the deÔ¨Ånition in (3.56), we have on the left-hand
side of (3.57) that
L(Y, ÀÜY , Z(p), ÀÜZ(p))
= Œº
 ÀÜZ(p) ÀÜY , ÀÜZ(p) (0 I)T 
‚àíŒº

Z(p) Y, Z(p) (0 I)T 
+Œº

Z(p) Y, ÀÜZ(p) ÀÜY

‚àíŒº(Y, ÀÜY ).
‚é´
‚é™‚é¨
‚é™‚é≠
(3.58)
Similarly, for the operator L

Z(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY, Wr, ÀÜWr

on the right-hand side
of (3.57), we derive
L

Z(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY, Wr, ÀÜWr

= Œº
 ÀÜZ(r) ÀÜY , ÀÜWr(0 I)T 
‚àíŒº(Z(r) Y, Wr(0 I)T ) + Œº(Z(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY ),
and then
LZ(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY , Wr, ÀÜWr
 ‚àíŒº( ÀÜZ(r) (0 I)T , ÀÜWr(0 I)T )
+ Œº(Z(r) (0 I)T , Wr(0 I)T )
= ‚àíŒº
 ÀÜZ(r) (0 I)T , ÀÜWr(0 I)T 
+ Œº
 ÀÜZ(r) ÀÜY , ÀÜWr(0 I)T 
+ Œº

Z(r) (0 I)T , Wr(0 I)T 
‚àíŒº

Z(r) Y, Wr(0 I)T 
+ ŒºZ(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY 
= ‚àíL ÀÜZ(r ‚àí1) ÀÜY , ÀÜZ(r ‚àí1) (0 I)T , ÀÜWr, ÀÜWr
 + Œº ÀÜZ(r ‚àí1) ÀÜY , ÀÜZ(r ‚àí1) (0 I)T 
+ LZ(r ‚àí1) Y, Z(r ‚àí1) (0 I)T , Wr, Wr
 ‚àíŒºZ(r ‚àí1) Y, Z(r ‚àí1) (0 I)T 
+ Œº

Z(r ‚àí1) Y, ÀÜZ(r ‚àí1) ÀÜY

.
(3.59)
By property (i) we have
L( ÀÜZ(r ‚àí1) ÀÜY, ÀÜZ(r ‚àí1) (0 I)T , ÀÜWr, ÀÜWr) = 0,
L(Z(r ‚àí1) Y, Z(r ‚àí1) (0 I)T , Wr, Wr) = 0.

3.3
Comparative Index for Symplectic Matrices
177
Then summing (3.59) from r = 1 to r = p, we derive equality (3.57). The proof is
complete.
‚äì‚äî
Using notation (3.56) we begin with the following auxiliary result, which turns
out to be highly important for future applications.
Lemma 3.23 Let W, Z,
ÀÜW, ÀÜZ be symplectic matrices. Then for the operator
L(Y, ÀÜY , W, ÀÜW) given by (3.56) with Y = Z(0 I)T and ÀÜY = ÀÜZ(0 I)T , we have
L(Y, ÀÜY , W, ÀÜW)
= Œº

W(0 I)T , ÀÜW(0 I)T 
+ Œº

ÀÜW ‚àí1WZ(0 I)T , Z(0 I)T 
‚àíŒº

ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T , ÀÜZ‚àí1Z(0 I)T 
‚àíŒº

ÀÜW ‚àí1WZ(0 I)T , ÀÜW ‚àí1W(0 I)T 
,
(3.60)
and
L(Y, ÀÜY , W, ÀÜW)
= Œº

W(0 I)T , W ÀÜW ‚àí1(0 I)T 
+ Œº

ÀÜZ‚àí1Z(0 I)T , ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T 
‚àíŒº

ÀÜWZ(0 I)T , WZ(0 I)T 
‚àíŒº

WZ(0 I)T , W ÀÜW ‚àí1(0 I)T 
.
(3.61)
Proof For the proof of equality (3.60), we apply Lemma 3.22(ii) to the case p = 2,
W1 := ÀÜW ‚àí1W, W2 := ÀÜW, ÀÜW1 := I, ÀÜW2 := ÀÜW, and then by (3.57), we have
L(Y, ÀÜY , W, ÀÜW) = L(Y, ÀÜY , ÀÜW ‚àí1W, I) + Œº(W(0 I)T , ÀÜW(0 I)T ),
(3.62)
where we have used that L( ÀÜW ‚àí1WY, ÀÜY , ÀÜW, ÀÜW) = 0 by Lemma 3.22(i). By (3.56),
L(Y, ÀÜY , ÀÜW ‚àí1W, I) = ‚àíŒº( ÀÜW ‚àí1WZ(0 I)T , ÀÜW ‚àí1W(0 I)T )
+ Œº( ÀÜW ‚àí1WZ(0 I)T , ÀÜZ(0 I)T ) ‚àíŒº(Z(0 I)T , ÀÜZ(0 I)T ),
and by Theorem 3.6 for the last two addends in the previous formula, we have
Œº( ÀÜW ‚àí1WZ(0 I)T , ÀÜZ(0 I)T ) ‚àíŒº(Z(0 I)T , ÀÜZ(0 I)T )
= Œº( ÀÜW ‚àí1WZ(0 I)T , Z(0 I)T ) ‚àíŒº( ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T , ÀÜZ‚àí1Z(0 I)T ).

178
3
Comparative Index Theory
Finally, for the operator L(Y, ÀÜY , ÀÜW ‚àí1W, I) in (3.62), we have the representation
L(Y, ÀÜY , ÀÜW ‚àí1W, I) = ‚àíŒº( ÀÜW ‚àí1WZ(0 I)T , ÀÜW ‚àí1W(0 I)T )
+ Œº( ÀÜW ‚àí1WZ(0 I)T , Z(0 I)T ) ‚àíŒº( ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T , ÀÜZ‚àí1Z(0 I)T )
which completes the proof of (3.60).
Similarly, the proof of (3.61) is derived by using Lemma 3.22(ii) with p = 2,
W1 :=
ÀÜW, W2 := W ÀÜW ‚àí1,
ÀÜW1 :=
ÀÜW,
ÀÜW2 := I, and then by (3.57) and
Lemma 3.22(i), we have
L(Y, ÀÜY , W, ÀÜW) = L( ÀÜWY, ÀÜW ÀÜY, W ÀÜW ‚àí1, I) + Œº(W(0 I)T , W ÀÜW(0 I)T ).
(3.63)
By (3.56), we get
L( ÀÜWY, ÀÜW ÀÜY, W ÀÜW ‚àí1, I) = ‚àíŒº(WZ(0 I)T , W ÀÜW ‚àí1(0 I)T )
+ Œº(WZ(0 I)T , ÀÜW ÀÜZ(0 I)T ) ‚àíŒº( ÀÜWZ(0 I)T , ÀÜW ÀÜZ(0 I)T ),
and by Theorem 3.6 for the last two addends in the previous formula we have
Œº( ÀÜWZ(0 I)T , ÀÜW ÀÜZ(0 I)T ) ‚àíŒº(WZ(0 I)T , ÀÜW ÀÜZ(0 I)T )
= Œº( ÀÜWZ(0 I)T , WZ(0 I)T ) ‚àíŒº( ÀÜZ‚àí1Z(0 I)T , ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T ).
Finally, the operator L( ÀÜWY, ÀÜW ÀÜY, W ÀÜW ‚àí1, I) takes the form
L( ÀÜWY, ÀÜW ÀÜY, W ÀÜW ‚àí1, I) = ‚àíŒº(WZ(0 I)T , W ÀÜW ‚àí1(0 I)T )
‚àíŒº( ÀÜWZ(0 I)T , WZ(0 I)T ) + Œº( ÀÜZ‚àí1Z(0 I)T , ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T ).
Substituting the last formula into (3.63), we complete the proof of (3.61).
‚äì‚äî
Using Lemma 3.23 and the comparative index for a pair of symplectic matrices,
we can now approach the main result of this section, which generalizes Theorem 3.6
to the case of two different matrices W and ÀÜW.
Theorem 3.24 Let W, Z, ÀÜW, ÀÜZ be symplectic matrices. Then for the operator
L(Y, ÀÜY , W, ÀÜW) given by (3.56) with Y = Z(0 I)T and ÀÜY = ÀÜZ(0 I)T , we have
L(Y, ÀÜY , W, ÀÜW) = Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) ‚àíŒº

‚ü®ÀÜZ‚àí1 ÀÜW ‚àí1WZ‚ü©, ‚ü®ÀÜZ‚àí1Z‚ü©

,
(3.64)
and
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) ‚àíŒº

‚ü®ÀÜZ‚àí1 ÀÜW ‚àí1WZ‚ü©, ‚ü®ÀÜZ‚àí1Z‚ü©

= Œº

‚ü®ÀÜZ‚àí1Z‚ü©, ‚ü®ÀÜZ‚àí1 ÀÜW ‚àí1WZ‚ü©

‚àíŒº(‚ü®ÀÜW‚ü©, ‚ü®W‚ü©).
(3.65)

3.3
Comparative Index for Symplectic Matrices
179
Proof To prove (3.64) we show that this identity is equivalent to (3.60). Using
successively formulas (3.54) and (3.55), we obtain the following representation for
the comparative indices on the right-hand side of (3.60):
Œº

W(0 I)T , ÀÜW(0 I)T 
= Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) ‚àíŒº(‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©),
Œº

ÀÜW ‚àí1WZ(0 I)T , Z(0 I)T 
= Œº

‚ü®ÀÜW ‚àí1WZ‚ü©, ‚ü®Z‚ü©

‚àíŒº

‚ü®Z‚àí1 ÀÜW ‚àí1WZ‚ü©, ‚ü®I‚ü©

= Œº

ÀÜW ‚àí1WZ(0 I)T , ÀÜW ‚àí1W(0 I)T 
+ Œº(‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©) ‚àíŒº

‚ü®Z‚àí1 ÀÜW ‚àí1WZ‚ü©, ‚ü®I‚ü©

,
and
Œº

ÀÜZ‚àí1 ÀÜW ‚àí1WZ(0 I)T , ÀÜZ‚àí1Z(0 I)T 
= Œº

‚ü®ÀÜZ‚àí1 ÀÜW ‚àí1WZ‚ü©, ‚ü®ÀÜZ‚àí1Z‚ü©

‚àíŒº

‚ü®Z‚àí1 ÀÜW ‚àí1WZ‚ü©, ‚ü®I‚ü©

.
Substituting the obtained equalities into (3.60) and canceling the same summands,
we get (3.64). To prove (3.65) it is sufÔ¨Åcient to observe that by Lemma 3.21(ii)
rank(‚ü®W‚ü©T J ‚ü®ÀÜW‚ü©) = rank(W ‚àíÀÜW),
(3.66)
and similarly
rank‚ü®ÀÜZ‚àí1 ÀÜW ‚àí1WZ‚ü©TJ ‚ü®ÀÜZ‚àí1Z‚ü©= rank( ÀÜZ‚àí1 ÀÜW ‚àí1WZ ‚àíÀÜZ‚àí1Z)
= rank ÀÜZ‚àí1 ÀÜW ‚àí1(W ‚àíÀÜW) Z
= rank(W ‚àíÀÜW).
(3.67)
Consequently, using property (v) of Theorem 3.5, we obtain (3.65).
‚äì‚äî
3.3.2
General Case
Next we apply the properties of the comparative index established in Sects. 3.1.2‚Äì
3.1.4 to the comparative index of a pair of symplectic matrices. We also present
particular cases of the comparative index for matrices appearing in discrete linear
Hamiltonian systems and Sturm-Liouville difference equations.
Applying Theorem 3.2 to matrices (3.52), we obtain the following result.

180
3
Comparative Index Theory
Lemma 3.25 Let W and
ÀÜW be symplectic matrices. The comparative index
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) can be computed by the following formulas
Œº1(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = rankM,
(3.68)
Œº2(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = ind T

I
ÀÜAT
0 ÀÜBT


Q‚ü®ÀÜW‚ü©‚àíQ‚ü®W‚ü©
 I 0
ÀÜA ÀÜB

T ,
(3.69)
M := (I ‚àíBB‚Ä†) ( ÀÜA ‚àíA, ÀÜB),
T := I2n ‚àíM‚Ä†M,
(3.70)
where the symmetric matrices Q‚ü®ÀÜW‚ü©and Q‚ü®W‚ü©satisfy
I AT
0 BT

Q‚ü®W‚ü©
I 0
A B

= [W],
[W] :=
CT A CT B
BT C BT D

and are determined by the formulas (analogously for Q‚ü®ÀÜW‚ü©)
Q‚ü®W‚ü©:=
I ‚àíAT
0
I
 + CTA
CT BB‚Ä†
BB‚Ä†C BB‚Ä†DB‚Ä†

+ C
,  I
0
‚àíA I

,
(3.71)
C = CT ,
diag{I, BT } C diag{I, B} = 0.
(3.72)
Proof By a direct computation, one can verify that
‚ü®W‚ü©= diag
I 0
A I

,
I ‚àíAT
0
I
 
diag {I, B, CT , I}
I2n
W

.
(3.73)
The Ô¨Årst matrix on the right-hand side of (3.73) is a symplectic block diagonal
matrix; hence by (ii) of Theorem 3.5, we obtain
Œº1(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº1(D‚ü®W‚ü©, D‚ü®ÀÜW ‚ü©) = rank M,
D := diag
 I
0
‚àíA I

,
I AT
0 I
 
,
where M is given in (3.70). Hence, formula (3.68) is proved. Further, using (3.73),
it is not difÔ¨Åcult to obtain general solution of Riccati-type relation (3.8) according
to (1.168). A general solution of relation (3.8) for
Y = diag {I, B, CT , I}
I2n
W

=
‚éõ
‚éú‚éú‚éù
I
0
0
B
CTA CT B
C
D
‚éû
‚éü‚éü‚é†

3.3
Comparative Index for Symplectic Matrices
181
has the form, in view of (1.168),
ÀúQ = diag {I, BB‚Ä†}
CTA CT B
C
D

diag {I, B‚Ä†} + C,
where the matrix C satisÔ¨Åes (3.72). Then the general solution of (3.8) for ‚ü®W‚ü©is of
the form (3.71). One particular solution of (3.8) for ‚ü®W‚ü©which coincides with the
matrix Gk given by (2.64) is
Q‚ü®W‚ü©=
I ‚àíAT
0
I
 CTA
CT
C
BB‚Ä†DB‚Ä†
  I
0
‚àíA I

=
AT BB‚Ä†DB‚Ä†A ‚àíAT C CT ‚àíAT BB‚Ä†DB‚Ä†
C ‚àí(AT BB‚Ä†DB‚Ä†)T
BB‚Ä†DB‚Ä†

,
(3.74)
which we obtain from (3.71) with
C :=

0
CT (I ‚àíBB‚Ä†)
(I ‚àíBB‚Ä†) C
0

.
This proves the statement of this lemma.
‚äì‚äî
Corollary 3.26 Let V be a symplectic matrix, and then for W := V and ÀÜW := I,
the formulas in Lemma 3.25 take the form
Œº(‚ü®V ‚ü©, ‚ü®I‚ü©) = rank M + ind T [(D ‚àíI) B‚Ä†(A ‚àíI) ‚àíC] T ,
(3.75)
V =
A B
C D

,
M := (I ‚àíBB‚Ä†) (A ‚àíI),
T := I ‚àíM‚Ä†M.
Proof Observe that by (3.53), we have the estimate
Œº(‚ü®V ‚ü©, ‚ü®I‚ü©) ‚â§n,
because ÀÜB = 0. The formulas of Lemma 3.25 for this case reduce to determining
the rank and the index of n √ó n matrices. The solution Q ÀÜW can be taken to be equal
to zero. Using QW in the form (3.71) with C = 0 leads to the formula
Œº2(‚ü®V ‚ü©, ‚ü®I‚ü©) = ind
+
‚àíT (I, I ‚àíAT )
 CTA
CT BB‚Ä†
BB‚Ä†C BB‚Ä†DB‚Ä†
 
I
I ‚àíA

T
,
,
from which we derive the second addend in (3.75) because of
M T = 0
‚áî
BB‚Ä†(A ‚àíI) T = (A ‚àíI) T
and (1.145). The proof is complete.
‚äì‚äî

182
3
Comparative Index Theory
From the previous computations and Lemma 3.21(v), we obtain another way of
determining the comparative index Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©).
Lemma 3.27 Let W and ÀÜW be symplectic matrices. We have the formula
Œº

‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©

= Œº
B
D

,
 ÀÜB
ÀÜD

+ Œº

‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©

,
(3.76)
where Œº(‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©) is determined by (3.75) with V := ÀÜW ‚àí1W. Analogously,
Œº

‚ü®W‚ü©, ‚ü®ÀÜW‚ü©

= Œº‚àó
‚àíBT
AT

,
‚àíÀÜBT
ÀÜAT

+ Œº

‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©

,
(3.77)
where Œº(‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©) is given by (3.75) with V := W ÀÜW ‚àí1.
In the particular cases, when the matrices ÀÜW ‚àí1W and W ÀÜW ‚àí1 are unit lower (or
unit upper) block triangular (see Sect. 1.6.1), the formulas in Corollary 3.26 and
Lemma 3.27 reduce as follows.
Corollary 3.28 Let W and ÀÜW be symplectic matrices. If ÀÜW ‚àí1W or W ÀÜW ‚àí1 is a unit
lower block-triangular matrix of the form
 I 0
Q I

,
Q = QT ,
(3.78)
then
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = ind (‚àíQ).
If ÀÜW ‚àí1W is unit upper block-triangular matrix of the form
I Q
0 I

,
Q = QT ,
(3.79)
then
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº
B
D

,
 ÀÜB
ÀÜD

.
If the analogical assumption (3.79) holds for W ÀÜW ‚àí1, then
Œº(‚ü®W‚ü©, ‚ü®ÀÜW‚ü©) = Œº‚àó
‚àíBT
AT

,
‚àíÀÜBT
ÀÜAT

.

3.3
Comparative Index for Symplectic Matrices
183
Proof The Ô¨Årst terms on the right-hand side of (3.76) and (3.77) in Lemma 3.27
equal to zero for the matrices of the form (3.78) in view of Remark 3.4(ii). For
the second terms in (3.76) and (3.77), we obtain according to (3.75) the Ô¨Årst
statement of the corollary. Concerning the second statement for the upper block-
triangular matrices, Œº(‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©) = 0 and Œº(‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©) = 0, by (3.75).
Consequently, computing Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) by Lemma 3.27, we obtain the proof of the
second statement of this corollary.
‚äì‚äî
3.3.3
Invertible Block B
Suppose that the blocks B and ÀÜB in the matrices W =
 A B
C D

and ÀÜW =
 ÀÜA
ÀÜB
ÀÜC
ÀÜD

are
invertible. Since
I 0
A B

=
I 0
A I
 I 0
0 B

,
(3.80)
then the upper blocks of the matrices ‚ü®W‚ü©and ‚ü®ÀÜW‚ü©are invertible as well. Then
obviously Œº1(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = 0, and by Remark 3.4(i), the comparative index is given
by Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº2(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©). Consequently,
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = ind
-0 ‚àíI
ÀÜC
ÀÜD
I 0
ÀÜA ÀÜB
‚àí1
‚àí
0 ‚àíI
C D
I 0
A B
‚àí1.
= ind

ÀÜB‚àí1 ÀÜA ‚àíB‚àí1A
B‚àí1 ‚àíÀÜB‚àí1
(B‚àí1 ‚àíÀÜB‚àí1)T
ÀÜD ÀÜB‚àí1 ‚àíDB‚àí1

.
(3.81)
Observe that that the above formula can also be obtained from Lemma 3.25. Now
we consider simple examples of computations of the comparative index for a pair of
symplectic matrices
Example 3.29 Consider a pair of Sturm-Liouville difference equations (compare
with Sect. 1.2)


r[1]
k xk

‚àír[0]
k xk+1 = 0,


ÀÜr[1]
k xk

‚àíÀÜr[0]
k xk+1 = 0.
According to Example 2.13, these equations can be written as 2 √ó 2 symplectic
systems with the matrices Sk and ÀÜSk of the form
Sk =

1
1/r[1]
k
r[0]
k
1 + r[0]
k /r[1]
k

,
ÀÜSk =

1
1/ÀÜr[1]
k
ÀÜr[0]
k
1 + ÀÜr[0]
k /ÀÜr[1]
k

.

184
3
Comparative Index Theory
Computing Œº(‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü©) according to (3.81), we obtain
Œº(‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü©) = ind ( ÀÜUk ÀÜX ‚àí1
k
‚àíUkX ‚àí1
k
)
= ind
 1 0
‚àí1 1
 
ÀÜr[1]
k
‚àír[1]
k
0
0
ÀÜr[0]
k
‚àír[0]
k
 1 ‚àí1
0 1

= ind (ÀÜr[1]
k
‚àír[1]
k ) + ind (ÀÜr[0]
k
‚àír[0]
k ).
In particular, Œº(‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü©) = 0 if and only if ÀÜr[i]
k
‚â•r[i]
k
for i ‚àà{0, 1}.
Next we present a generalization of the previous example to the comparative
index for a pair of matrices of the symplectic system corresponding to the vector
Sturm-Liouville equation (2.25), i.e.,
(Rkxk) ‚àíPkxk+1 = 0.
Example 3.30 Consider a pair of equations (2.25) with the corresponding symplec-
tic matrices (see Sect. 2.1)
Sk =
 I
R‚àí1
k
Pk I + PkR‚àí1
k

,
ÀÜSk =

I
ÀÜR‚àí1
k
ÀÜPk I + ÀÜPk ÀÜR‚àí1
k

.
The invertibility of the blocks Bk := R‚àí1
k
and ÀÜBk :=
ÀÜR‚àí1
k
enables to compute
Œº(‚ü®Wk‚ü©, ‚ü®ÀÜWk‚ü©) by (3.81)
Œº(‚ü®Wk‚ü©, ‚ü®ÀÜWk‚ü©) = ind
 I
0
‚àíI I
 
ÀÜRk ‚àíRk
0
0
ÀÜPk ‚àíPk
 I ‚àíI
0 I

= ind ( ÀÜRk ‚àíRk) + ind ( ÀÜPk ‚àíPk).
In particular, Œº(‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü©) = 0 if and only if ÀÜRk ‚â•Rk and ÀÜPk ‚â•Pk.
3.3.4
Invertible Block A
In this subsection we consider the situation when the matrices W =
 A B
C D

and
ÀÜW =
 ÀÜA
ÀÜB
ÀÜC
ÀÜD

have A and ÀÜA invertible. In this case we can recover a Hamiltonian
structure from the symplectic matrices W and ÀÜW; see Example 2.7 in Sect. 2.1.2.

3.3
Comparative Index for Symplectic Matrices
185
Lemma 3.31 Suppose that symplectic matrices W and ÀÜW satisfy
det A Ã∏= 0,
det ÀÜA Ã∏= 0.
(3.82)
Then
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

,
(3.83)
‚ü®W‚ü©H :=
‚éõ
‚éú‚éú‚éù
I
0
I ‚àíA‚àí1
A‚àí1B
CA‚àí1
‚àí(I ‚àíAT ‚àí1)
0
I
‚éû
‚éü‚éü‚é†,
(3.84)
where
‚ü®W‚ü©T
H J ‚ü®ÀÜW‚ü©H = H ‚àíÀÜH,
H :=
 ‚àíCA‚àí1 I ‚àíAT ‚àí1
I ‚àíA‚àí1
A‚àí1B

(3.85)
and where ÀÜH is deÔ¨Åned similarly through ÀÜW.
Proof Assumption (3.82) implies the block LU-factorization of W and ÀÜW (compare
with Corollary 1.73)
W =

I
0
CA‚àí1 I

diag
(
A,
AT ‚àí1) I A‚àí1B
0
I

(3.86)
and an analogical factorization holds for ÀÜW. Using the factorization (3.86), proper-
ties (i) and (ii) in Theorem 3.5, we obtain
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº

L‚ü®W‚ü©C1, L‚ü®ÀÜW‚ü©C2

= Œº

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

,
where
L := diag
 0 I
‚àíI I

,
 I
I
‚àíI 0
 
,
C1 =
A‚àí1 ‚àíA‚àí1B
0
I

, C2 =
 ÀÜA‚àí1 ‚àíÀÜA‚àí1 ÀÜB
0
I

.
Hence, formula (3.83) is proved. Identity (3.85) follows by direct computations.
‚äì‚äî
Now we present how to compute the comparative index Œº

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

.

186
3
Comparative Index Theory
Lemma 3.32 Let W and ÀÜW be symplectic matrices satisfying (3.82). Then
Œº

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

= ind (H ‚àíÀÜH) + ind ( ÀÜA‚àí1 ÀÜB) ‚àíind (A‚àí1B),
(3.87)
where H = H T and ÀÜH = ÀÜH T are given by (3.85).
Proof Observe that ‚ü®W‚ü©H = NT  I2n
‚àíH

holds, where
N :=
‚éõ
‚éú‚éú‚éù
I
0 0 0
0 0 0 I
0 0 I 0
0 ‚àíI 0 0
‚éû
‚éü‚éü‚é†.
Applying (3.17) to the matrices Z(0 I)T =
 I2n
‚àíH

, ÀÜZ(0 I)T =
 I2n
‚àíÀÜH

, and W = N,
we obtain
Œº

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

= Œº
 I2n
‚àíH

,
 I2n
‚àíÀÜH

+ Œº
 I2n
‚àíÀÜH

, NT (02n I2n)T

‚àíŒº
 I2n
‚àíH

, NT (02n I2n)T

.
Computing the comparative indices on the right-hand side of the above formula, we
obtain (3.87).
‚äì‚äî
Another method of computing Œº

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

is based on Theorem 3.2 and
Lemma 3.25.
Lemma 3.33 Let W and ÀÜW be symplectic matrices satisfying (3.82). Then the
comparative index (3.83) can be computed in the following way
Œº1

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

= rank M,
M := [I ‚àí(A‚àí1B)(A‚àí1B)‚Ä†]

A‚àí1‚àíÀÜA‚àí1,
ÀÜA‚àí1 ÀÜB

,
Œº2

‚ü®W‚ü©H , ‚ü®ÀÜW‚ü©H

= ind
+
T

I I ‚àíÀÜAT ‚àí1
0
ÀÜA‚àí1 ÀÜB
 
ÀÜG ‚àíG
 
I
0
I ‚àíÀÜA‚àí1 ÀÜA‚àí1 ÀÜB

T
,
,
where T := I ‚àíM‚Ä†M. The matrix G is a symmetric solution of the matrix equation
I I ‚àíA‚àíT
0
A‚àí1B

G

I
0
I ‚àíA‚àí1 A‚àí1B

=
CA‚àí1
0
0
A‚àí1B

,
(3.88)

3.3
Comparative Index for Symplectic Matrices
187
and it is determined by the formula
G =
I ‚àíI + AT ‚àí1
0
I
 +CA‚àí1
0
0
(A‚àí1B)‚Ä†

+ C
, 
I
0
‚àíI + A‚àí1 I

,
(3.89)
C = CT ,
diag{I, A‚àí1B} C diag{I, A‚àí1B} = 0.
Similar formulas to (3.88) and (3.89) hold also for the matrix ÀÜG.
Proof We use the representation
‚ü®W‚ü©H = diag

I
0
I ‚àíA‚àí1 I

,
I ‚àí(I ‚àíAT ‚àí1)
0
I
 
‚éõ
‚éú‚éú‚éù
I
0
0
A‚àí1B
CA‚àí1
0
0
I
‚éû
‚éü‚éü‚é†
and follow the idea of the proof of Lemma 3.25.
‚äì‚äî
Example 3.34 We analyze the comparative index for matrices associated with
discrete linear Hamiltonian systems. Consider the system (2.15), i.e.,

xk
uk

= J Hk
xk+1
uk

,
Hk =
‚àíCk AT
k
Ak
Bk

,
J =
 0 I
‚àíI 0

and

xk
uk

= J ÀÜHk
xk+1
uk

,
ÀÜHk =
‚àíÀÜCk ÀÜAT
k
ÀÜAk
ÀÜBk

.
(3.90)
Using (3.87), it is easy to see that
Œº
/
S[H]
k
0
H ,
/ ÀÜS[H]
k
0
H

= ind (Hk ‚àíÀÜHk) + ind ÀÜBk ‚àíind Bk,
(3.91)
where S[H]
k
is the symplectic matrix given in (2.18), with ÀÜS[H]
k
being deÔ¨Åned
analogously. From (3.47) it follows that
ind Bk + Œº
Bk
I

,
 ÀÜBk
I

= ind ÀÜBk + Œº‚àó

J
 ÀÜBk
I

, J
Bk
I

,
or in other terms,
ind ÀÜBk ‚àíind Bk = Œº
Bk
I

,
 ÀÜBk
I

‚àíind (Bk ‚àíÀÜBk).
(3.92)

188
3
Comparative Index Theory
Substituting the last formula into (3.91), we obtain
Œº
/S[H]
k
0
H, / ÀÜS[H]
k
0
H

= Œº
Bk
I

,
 ÀÜBk
I

+
(
ind (Hk ‚àíÀÜHk) ‚àíind (Bk ‚àíÀÜBk)
)
.
(3.93)
Observe that by Lemma 3.15, the expression in braces in the last computation is
nonnegative and represents the index of a symmetric operator with the zero block
on the main diagonal. Simplifying formula (3.77) for the ‚ÄúHamiltonian‚Äù case, it is
possible to show that the expression in braces is equal to the comparative index
Œº
1
S[H]
k
( ÀÜS[H]
k
)‚àí12
, ‚ü®I‚ü©

.
Analogously, the formulas in Lemma 3.33 for the pair of systems (2.15) and
(3.90) have the form
Œº1
/
S[H]
k
0
H,
/ ÀÜS[H]
k
0
H

= rank Mk,
(3.94)
Œº2
/S[H]
k
0
H, / ÀÜS[H]
k
0
H

= ind
+
Tk
I ÀÜAT
k
0 ÀÜBk
 
Gk ‚àíÀÜGk
  I
0
ÀÜAk ÀÜBk

Tk
,
,
(3.95)
where
Mk := (I ‚àíBkB‚Ä†
k ) ( ÀÜAk ‚àíAk, ÀÜBk),
Tk := I ‚àíM‚Ä†
kMk,
and where Gk is a symmetric solution of the equation
I AT
k
0 Bk

Gk
 I
0
Ak Bk

=
Ck 0
0 Bk

,
(3.96)
i.e., Gk is given by the formula
Gk =
I ‚àíAT
k
0
I
 +Ck 0
0 B‚Ä†
k

+ Ck
,  I
0
‚àíAk I

,
(3.97)
Ck = CT
k ,
diag{I, Bk} Ck diag{I, Bk} = 0.
Similar formulas to (3.96) and (3.97) hold also for the matrix ÀÜGk.
Remark 3.35 Note that formula (3.92) generalizes Remark 1.60(vi) to the case
when A = AT and B = BT are indeÔ¨Ånite by sign. Indeed, under the assumptions
A ‚â•0 and B ‚â•0, we have from (3.92) that
Œº
B
I

,
A
I

= ind (B ‚àíA).
(3.98)

3.3
Comparative Index for Symplectic Matrices
189
Then ind (B ‚àíA) = 0 is equivalent to Œº
B
I
, A
I

= 0, and the last condition
coincides with
Im A ‚äÜIm B,
A ‚àíAB‚Ä†A ‚â•0,
by Theorem 3.2(iv). By a similar way, the condition B‚Ä† ‚â§A‚Ä† is equivalent to
Œº
A‚Ä†
I

,
B‚Ä†
I

= 0 or to
Im B‚Ä† ‚äÜIm A‚Ä†,
B‚Ä† ‚àíB‚Ä†AB‚Ä† ‚â•0.
Using these equivalences it is possible to prove easily the last assertion in
Remark 1.60(vi).
Example 3.36 In this example we turn our attention to the 2n-th order Sturm-
Liouville difference equation (2.27), i.e.,
n

ŒΩ=0
(‚àí1)ŒΩŒΩ
r[ŒΩ]
k ŒΩyk+n‚àíŒΩ

= 0,
where r[n]
k
Ã∏= 0 for all k. This equation can be written as the Hamiltonian system
(2.15) with the coefÔ¨Åcient matrices Ak, Bk, and Ck given in (2.29) and (2.30).
Together with (2.27) we consider the equation of the same form with the coefÔ¨Åcients
ÀÜr[j]
k
for j = 0, . . . , n, i.e.,
n

ŒΩ=0
(‚àí1)ŒΩŒΩ
ÀÜr[ŒΩ]
k ŒΩyk+n‚àíŒΩ

= 0
(3.99)
with ÀÜr[n]
k
Ã∏= 0 for all k. In this particular case, Ak =
ÀÜAk and Mk = 0, so that
Œº1

‚ü®S[H]
k
‚ü©H , ‚ü®ÀÜS[H]
k
‚ü©H

= 0. Simplifying equation (3.95), we obtain
Œº

‚ü®S[H]
k
‚ü©H , ‚ü®ÀÜS[H]
k
‚ü©H

= ind diag
(
ÀÜr[0]
k
‚àír[0]
k , . . . , ÀÜr[n]
k
‚àír[n]
k
)
=
n

ŒΩ=0
ind (ÀÜr[ŒΩ]
k
‚àír[ŒΩ]
k ).
(3.100)
The same result follows directly from (3.93) and (2.29), (2.30). In particular,
Œº

‚ü®S[H]
k
‚ü©H, ‚ü®ÀÜS[H]
k
‚ü©H

= 0 if and only if ÀÜr[j]
k
‚â•r[j]
k
for all j = 0, . . . , n.

190
3
Comparative Index Theory
3.3.5
Additional Properties of Comparative Index
In this section we derive additional properties of the comparative index, which we
will use in subsequent chapters when dealing with boundary value problems for
symplectic system with general (nonseparated) boundary conditions.
We introduce the following notation. Let WandV be matrices separated into
n √ó n blocks
W =
A B
C D

,
V =

ÀÜA ÀÜB
ÀÜC ÀÜD

.
Introduce the notation
{W, V } :=
‚éõ
‚éú‚éú‚éù
A 0 ‚àíB 0
0
ÀÜA 0
ÀÜB
‚àíC 0 D
0
0
ÀÜC
0
ÀÜD
‚éû
‚éü‚éü‚é†,
{W} := {I, W} =
‚éõ
‚éú‚éú‚éù
I 0 0 0
0 A 0 B
0 0 I 0
0 C 0 D
‚éû
‚éü‚éü‚é†,
(3.101)
and
S0 :=
‚éõ
‚éú‚éú‚éù
0 0 I
0
0 I I
0
‚àíI 0 0 ‚àíI
0 0 0 I
‚éû
‚éü‚éü‚é†.
(3.102)
Then one can directly verify that S0 ‚ààSp(4n) and under the additional assumption
W, V ‚ààSp(2n), the 4n √ó 4n matrices {W, V } and {W} are symplectic as well, i.e.,
{W, V }, {W} ‚ààSp(4n).
We have the multiplicative property
{WV, ÀÜW ÀÜV } = {W, ÀÜW} {V, ÀÜV },
(3.103)
in particular, {W, ÀÜW}‚àí1 = {W ‚àí1, ÀÜW ‚àí1}. We also derive the following relations
{W, ÀÜW} S0 =
‚éõ
‚éú‚éú‚éù
B
0 A
B
0
ÀÜA
ÀÜA
ÀÜB
‚àíD 0 ‚àíC ‚àíD
0
ÀÜC
ÀÜC
ÀÜD
‚éû
‚éü‚éü‚é†,
{W} S0 (02n, I2n)T = ‚ü®W‚ü©,
(3.104)
which can be easily veriÔ¨Åed by direct computations. Moreover, by (3.104) for any
symplectic 2n √ó 2n matrices P and R, we have
‚ü®R‚àí1WP‚ü©= {P ‚àí1, R‚àí1} ‚ü®W‚ü©P,
(3.105)

3.3
Comparative Index for Symplectic Matrices
191
where the matrix ‚ü®W‚ü©is deÔ¨Åned in (3.52). Using the properties of the comparative
index, we can prove the following result.
Proposition 3.37 Let W, V, R, P ‚ààSp(2n) and S0 be given by (3.102). Then,
using the notation in (3.101) and (3.52), we have
Œº

‚ü®W‚ü©, {W} (02n I2n)T 
= 0,
(3.106)
Œº

‚ü®W‚ü©, {V } (02n I2n)T 
= Œº

{W} (02n I2n)T , {V } (02n I2n)T 
(3.107)
= Œº

W(0 I)T, V (0 I)T 
,
(3.108)
Œº (‚ü®{W}‚ü©, ‚ü®{V }‚ü©) = Œº (‚ü®W‚ü©, ‚ü®V ‚ü©) .
(3.109)
Proof Using (3.104), properties (i), (iii) of Theorem 3.5 and (3.13), we obtain
Œº

‚ü®W‚ü©, {W} (02n I2n)T 
= Œº

{W} S0 (02n I2n)T , {W} (02n I2n)T 
= Œº‚àó
({W}S0)‚àí1(02n I2n)T , S‚àí1
0 (02n I2n)T 
= Œº
‚éõ
‚éú‚éú‚éù
‚éõ
‚éú‚éú‚éù
I AT
0 BT
0 0
0 AT
‚éû
‚éü‚éü‚é†,
‚éõ
‚éú‚éú‚éù
I I
0 0
0 0
0 I
‚éû
‚éü‚éü‚é†
‚éû
‚éü‚éü‚é†
= Œº
‚éõ
‚éú‚éú‚éù
‚éõ
‚éú‚éú‚éù
I
0
0 BT
0 0
0 AT
‚éû
‚éü‚éü‚é†
I AT
0 I

,
‚éõ
‚éú‚éú‚éù
I 0
0 0
0 0
0 I
‚éû
‚éü‚éü‚é†
I I
0 I

‚éû
‚éü‚éü‚é†= Œº
‚éõ
‚éú‚éú‚éù
‚éõ
‚éú‚éú‚éù
I
0
0 BT
0 0
0 AT
‚éû
‚éü‚éü‚é†,
‚éõ
‚éú‚éú‚éù
I 0
0 0
0 0
0 I
‚éû
‚éü‚éü‚é†
‚éû
‚éü‚éü‚é†.
The last comparative index can be easily computed as being equal to zero. Thus,
we have proved (3.106). Now we proceed with the proof of formula (3.107). By
Theorem 3.6,
Œº

‚ü®W‚ü©, {V } (02n I2n)T 
‚àíŒº

{W} (02n I2n)T , {V } (02n I2n)T 
= Œº

‚ü®W‚ü©, {W} (02n I2n)T 
‚àíŒº

‚ü®V ‚àí1W‚ü©, {V ‚àí1W} (02n I2n)T 
.
From (3.106) it follows that the right-hand side of the last formula equals to zero,
and then (3.107) follows. Since the 2n √ó 2n blocks of the matrices {W} (02n I2n)T
and {V } (02n I2n)T have a block diagonal structure, then by the deÔ¨Ånition of the
comparative index
Œº

{W} (02n I2n)T , {V } (02n I2n)T 
= Œº

W(0 I)T, V (0 I)T 
,

192
3
Comparative Index Theory
which proves formula (3.108). Finally, formula (3.109) can be veriÔ¨Åed by direct
computations by using the block diagonal structure of the 2n √ó 2n blocks of the
matrices {W} and {V } in (3.101).
‚äì‚äî
Remark 3.38 Note that we have the identity
diag{P1, P1}{W, I} diag{P1, P1} = {I, P2WP2} := {P2WP2},
(3.110)
where P1 and P2 are given by (1.151), and the block diagonal matrix diag{P1, P1}
is symplectic. Using (3.110) and Theorem 3.5(i), (ii), one can prove that the
comparative indices associated with {W, I} have properties similar to (3.106),
(3.107), (3.108). In particular, we obtain
Œº

{W, I}‚ü®I‚ü©, {W, I} (02n I2n)T 
= 0,
(3.111)
Œº

{W, I}‚ü®I‚ü©, {V, I} (02n I2n)T 
= Œº

{W, I} (02n I2n)T , {V, I} (02n I2n)T 
= Œº

P2WP2(0 I)T, P2V P2(0 I)T 
= Œº‚àó
W(0 I)T, V (0 I)T 
.
(3.112)
The statements in Proposition 3.37 and Remark 3.38 are used in the proof of the
following result, which will be further applied in the subsequent chapters.
Lemma 3.39 Let W, V, R, P be symplectic matrices and deÔ¨Åne ÀúW := R‚àí1WP
and ÀúV := R‚àí1V P. . Then
Œº(‚ü®ÀúW‚ü©, ‚ü®ÀúV ‚ü©) ‚àíŒº(‚ü®W‚ü©, ‚ü®V ‚ü©)
= Œº

‚ü®ÀúW‚ü©, {P ‚àí1, R‚àí1} (02n I2n)T 
‚àíŒº

‚ü®ÀúV ‚ü©, {P ‚àí1, R‚àí1} (02n I2n)T 
(3.113)
= Œº

‚ü®V ‚ü©, {P, R} (02n I2n)T 
‚àíŒº

‚ü®W‚ü©, {P, R} (02n I2n)T 
.
(3.114)
Moreover, each term in (3.114) can be computed by using the formulas
Œº

‚ü®W‚ü©, {P, R} (02n I2n)T 
= Œº

W (0 I)T, WP (0 I)T 
+ Œº

WP (0 I)T, R (0 I)T 
(3.115)
= Œº‚àó
W ‚àí1R (0 I)T, P (0 I)T 
+ Œº

W (0 I)T, R (0 I)T 
.
(3.116)

3.3
Comparative Index for Symplectic Matrices
193
In particular, we have
Œº(‚ü®ÀúW‚ü©, ‚ü®ÀúV ‚ü©) ‚àíŒº(‚ü®W‚ü©, ‚ü®V ‚ü©)
= Œº

ÀúW (0 I)T, R‚àí1 (0 I)T 
‚àíŒº

ÀúV (0 I)T, R‚àí1 (0 I)T 
+ Œº‚àó
V ‚àí1 (0 I)T, P (0 I)T 
‚àíŒº‚àó
W ‚àí1 (0 I)T, P (0 I)T 
,
(3.117)
or
Œº(‚ü®ÀúW‚ü©, ‚ü®ÀúV ‚ü©) ‚àíŒº(‚ü®W‚ü©, ‚ü®V ‚ü©)
= Œº

R‚àí1 (0 I)T, ÀúV (0 I)T 
‚àíŒº

R‚àí1 (0 I)T, ÀúW (0 I)T 
+ Œº‚àó
P (0 I)T, W ‚àí1 (0 I)T 
‚àíŒº‚àó
P (0 I)T, V ‚àí1 (0 I)T 
.
(3.118)
The proof of this lemma is postponed to Sect. 3.3.6.
Based on the results in Lemma 3.39, we derive the next corollary, which will be
used in the subsequent chapters.
Corollary 3.40 We have the following statements.
(i) Let R, P ‚ààSp(2n) be lower block-triangular. Then
Œº

‚ü®R‚àí1WP‚ü©, ‚ü®R‚àí1V P‚ü©

= Œº (‚ü®W‚ü©, ‚ü®V ‚ü©) .
(ii) Let R = I and P = J . Then
Œº (‚ü®W‚ü©, ‚ü®V ‚ü©) = Œº‚àó(‚ü®V J ‚ü©, ‚ü®WJ ‚ü©) + Œº‚àó
(I 0)T , V ‚àí1 (0 I)T 
‚àíŒº‚àó
(I 0)T , W ‚àí1 (0 I)T 
.
(iii) Let ÀúV := R‚àí1V P = I. Then
Œº

‚ü®ÀúW‚ü©, ‚ü®I‚ü©

‚àíŒº

‚ü®W‚ü©, ‚ü®RP ‚àí1‚ü©

= Œº

ÀúW(0 I)T, R‚àí1(0 I)T 
‚àíŒº‚àó
W ‚àí1(0 I)T, P(0 I)T 
‚àíŒº

P ‚àí1(0 I)T, R‚àí1(0 I)T 
(3.119)

194
3
Comparative Index Theory
= Œº‚àó
P(0 I)T, W ‚àí1(0 I)T 
‚àíŒº

R‚àí1(0 I)T, ÀúW(0 I)T 
‚àíŒº

P ‚àí1(0 I)T, R‚àí1(0 I)T 
.
(3.120)
(iv) If W =  I
0
‚àíQ I
, where Q = QT and Q ‚â•0, then for arbitrary R ‚ààSp(2n),
we have
Œº

‚ü®R‚àí1WR‚ü©, ‚ü®I‚ü©

= 0.
(3.121)
(v) For any R ‚ààSp(4n) we have
Œº

‚ü®R‚àí1 {W} S0‚ü©, ‚ü®R‚àí1 {V } S0‚ü©

= Œº

R‚àí1 ‚ü®W‚ü©, R‚àí1 ‚ü®V ‚ü©

.
(3.122)
Proof Particular cases (i) and (iii), formula (3.120) follows immediately from
(3.117) and (3.118), respectively, where by Theorem 3.5(iii), we have
Œº‚àó(P(0 I)T , PR‚àí1(0 I)T ) = Œº(P ‚àí1(0 I)T , R‚àí1(0 I)T ).
(3.123)
For the proof of formula (3.119) in (iii), we apply (3.117), where
Œº

(0 I)T, R‚àí1 (0 I)T 
‚àíŒº‚àó
P R‚àí1 (0 I)T, P (0 I)T 
= Œº‚àó
P (0 I)T , P R‚àí1 (0 I)T 
according to Theorem 3.5(v). Then, using (3.123), we derive (3.119).
We turn our attention to the proof of (ii). From (3.118) we obtain
Œº (‚ü®WJ ‚ü©, ‚ü®V J ‚ü©) ‚àíŒº (‚ü®W‚ü©, ‚ü®V ‚ü©)
= Œº

(0 I)T, V J (0 I)T 
‚àíŒº

(0 I)T, WJ (0 I)T 
+ Œº‚àó
(I 0)T , W ‚àí1(0 I)T 
‚àíŒº‚àó
(I 0)T , V ‚àí1(0 I)T 
.
Putting the Ô¨Årst two summands on the right-hand side of the last computation to the
left and then using Lemma 3.21(iv), we obtain the proof of (ii).
Property (iv) follows from (3.120) with R = P, since on the right-hand side
of (3.120) we have in our case Œº‚àó
P(0 I)T, W ‚àí1(0 I)T 
= 0, as W ‚àí1 is lower
block-triangular, and
Œº

R‚àí1(0 I)T, ÀúW(0 I)T 
= Œº‚àó(R (0 I)T, WR (0 I)T ) = ind RT
12QR12 = 0,

3.3
Comparative Index for Symplectic Matrices
195
where R12 is the right upper block of R, and Œº

R‚àí1(0 I)T, R‚àí1(0 I)T 
= 0.
Further, Œº(‚ü®W‚ü©, ‚ü®RR‚àí1‚ü©) = Œº(‚ü®W‚ü©, ‚ü®I‚ü©) = ind Q = 0 by Corollary 3.28. The
property (iv) is proved.
Finally, we prove (v). By (3.114) with P := S0, we have
Œº

‚ü®R‚àí1{W}S0‚ü©, ‚ü®R‚àí1{V }S0‚ü©

= Œº (‚ü®{W}‚ü©, ‚ü®{V }‚ü©) + Œº

‚ü®{V }‚ü©, {S0, R} (02n I2n)T 
‚àíŒº

‚ü®{W}‚ü©, {S0, R} (02n I2n)T 
= Œº (‚ü®W‚ü©, ‚ü®V ‚ü©) + Œº

‚ü®{V }‚ü©, {S0, R} (02n I2n)T 
‚àíŒº

‚ü®{W}‚ü©, {S0, R} (02n I2n)T 
,
where we have used (3.109). In addition, applying formula (3.115), we obtain
Œº

‚ü®{V }‚ü©, {S0, R} (02n I2n)T 
= Œº

{V } (02n I2n)T , {V }S0 (02n I2n)T 
+ Œº

{V } S0 (02n I2n)T , R (02n I2n)T 
.
Using the notation ‚ü®V ‚ü©= {V } S0 (02n I2n)T , we obtain
Œº

{V } (02n I2n)T , ‚ü®V ‚ü©

= n ‚àíŒº

‚ü®V ‚ü©, {V } (02n I2n)T 
= n,
where we have used property (v) of Theorem 3.5 and (3.106). Applying similar
computations for Œº

‚ü®{W}‚ü©, {S0, R} (02n I2n)T 
, we obtain
Œº

‚ü®{V }‚ü©, {S0, R} (02n I2n)T 
‚àíŒº

‚ü®{W}‚ü©, {S0, R} (02n I2n)T 
= Œº

‚ü®V ‚ü©, R (02n I2n)T 
‚àíŒº

‚ü®W‚ü©, R (02n I2n)T 
,
and, hence,
Œº

‚ü®R‚àí1{W} S0‚ü©, ‚ü®R‚àí1{V } S0‚ü©

= Œº (‚ü®W‚ü©, ‚ü®V ‚ü©) + Œº

‚ü®V ‚ü©, R (02n I2n)T 
‚àíŒº

‚ü®W‚ü©, R (02n I2n)T 
= Œº

R‚àí1‚ü®W‚ü©, R‚àí1‚ü®V ‚ü©

,
where we have used Theorem 3.6. This proves (3.122).
‚äì‚äî

196
3
Comparative Index Theory
Remark 3.41 Note that for the comparative indices associated with {W, ÀÜW} and
{W, ÀÜW}S0 and their special cases with W := I or ÀÜW := I, the duality principle
holds (see Sect. 3.1.4). Introduce the matrix P2 := diag{I2n, ‚àíI2n}, which is an
analog of P2 = diag{I, ‚àíI} deÔ¨Åned by (1.151). According to (3.13), the dual
comparative index can be deÔ¨Åned using P2. Similarly, we have
Œº‚àó(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº(P2‚ü®W‚ü©, P2‚ü®ÀÜW‚ü©)
= Œº(P2‚ü®W‚ü©P2, P2‚ü®ÀÜW‚ü©P2)
= Œº(‚ü®P2WP2‚ü©, ‚ü®P2 ÀÜWP2‚ü©),
where we have applied Theorem 3.5(i). By a similar way, using the relations
P2{W, ÀÜW}P2 = {P2WP2, P2 ÀÜWP2},
P2S0 diag{‚àíP2, P2} = S0,
Theorem 3.5(i), and representation (3.13) for the dual comparative index associated
with P2 ‚ààR4n, one can prove that all results of Sect. 3.3 hold for the dual indices
as well.
3.3.6
Comparative Index for Symplectic Matrices: Proofs
In this section we present the proofs of properties of the comparative index, which
we displayed earlier in Sect. 3.3. In particular, we present the proofs of properties
(v) and (vi) of Lemma 3.21 and the proof of Lemma 3.39.
Proof of Properties (v) and (vi) of Lemma 3.21 The proof of the property (v) in
Lemma 3.21 is based on Proposition 3.37; see formulas (3.106) and (3.108).
Applying identity (3.60) from Lemma 3.23 to the case W := {W}, ÀÜW := { ÀÜW},
Z = ÀÜZ = S0 with S0 given by (3.102), we have Y = ÀÜY := ‚ü®I‚ü©, and using (3.106)
for the matrices W, ÀÜW, ÀÜW ‚àí1W, we obtain
L(‚ü®I‚ü©, ‚ü®I‚ü©, {W}, { ÀÜW }) = Œº

{W}‚ü®I‚ü©, { ÀÜW} ‚ü®I‚ü©

= Œº

{W} (0 I)T, { ÀÜW} (0 I)T 
+ Œº

{ ÀÜW ‚àí1W}‚ü®I‚ü©, ‚ü®I‚ü©

= Œº

W (0 I)T, ÀÜW (0 I)T 
+ Œº

‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©

,
(3.124)
where we also incorporate the last equality in (3.108). Hence, equality (3.54) is
proved. Using property (iii) of Lemma 3.21 and repeating the proof of (3.124) for

3.3
Comparative Index for Symplectic Matrices
197
Œº‚àó(‚ü®W ‚àí1‚ü©, ‚ü®ÀÜW ‚àí1‚ü©), we obtain
Œº

‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©

= Œº‚àó
‚ü®W ‚àí1‚ü©, ‚ü®ÀÜW ‚àí1‚ü©

= Œº‚àó
W ‚àí1 (0 I)T, ÀÜW ‚àí1 (0 I)T 
+ Œº‚àó
‚ü®ÀÜWW ‚àí1‚ü©, ‚ü®I‚ü©

,
i.e., equality (3.55) holds as well. Using part (iii) of Lemma 3.21 again, we get
Œº‚àó(‚ü®ÀÜWW ‚àí1‚ü©, ‚ü®I‚ü©) = Œº(‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©). Finally, part (iii) of Theorem 3.5 yields
the identity Œº‚àó(W ‚àí1 (0 I)T, ÀÜW ‚àí1 (0 I)T ) = Œº(W (0 I)T, W ÀÜW ‚àí1 (0 I)T ), which
Ô¨Ånishes the proof of (3.55). The proof of property (vi) follows directly from (3.54)
and (3.55).
‚äì‚äî
Proof of Lemma 3.39 Remark that by (3.105) and part (i) of Theorem 3.5, the
invertible matrices P in the comparative index
Œº(‚ü®ÀúW‚ü©, ‚ü®ÀúV ‚ü©) = Œº

{P ‚àí1, R‚àí1} ‚ü®W‚ü©P, {P ‚àí1, R‚àí1} ‚ü®V ‚ü©P

can be neglected. Now, using Theorem 3.6, we obtain the proof of (3.113). Formula
(3.114) follows from (3.17) or from property (ix) of Theorem 3.5.
Now we prove (3.116). By (i) of Theorem 3.5, we have
Œº

‚ü®W‚ü©, {P, R} (02n I2n)T 
= Œº

‚ü®W‚ü©P, {P, R} (02n I2n)T 
,
and further, using (3.105) for the case R := I and (3.103), we derive
Œº

‚ü®W‚ü©P, {P, R} (02n I2n)T 
= Œº

{P, I} ‚ü®WP‚ü©, {P, R} (02n I2n)T 
= Œº

{P, I} ‚ü®WP‚ü©, {P, I} {I, R} (02n I2n)T 
= Œº

‚ü®WP‚ü©, {I, R} (02n I2n)T 
+ Œº

{I, R} (02n I2n)T, {P ‚àí1, I} (02n I2n)T 
‚àíŒº

‚ü®WP‚ü©, {P ‚àí1, I} (02n I2n)T 
,
where the last sum is obtained via (3.17). By (3.108),
Œº

‚ü®WP‚ü©, {I, R} (0 I)T 
= Œº

‚ü®WP‚ü©, {R} (0 I)T 
= Œº

WP (0 I)T, R (0 I)T 
,
which yields the second summand on the right-hand side of (3.115). Further, by
(3.101) and DeÔ¨Ånition 3.1 of the comparative index, we have
Œº

{I, R} (02n I2n)T, {P ‚àí1, I} (02n I2n)T 
= Œº

(0 I)T, P ‚àí1 (0 I)T 
.

198
3
Comparative Index Theory
To determine the last comparative index, we use again Theorem 3.5(i) and (3.105).
We obtain
Œº

‚ü®WP‚ü©, {P ‚àí1, I} (02n I2n)T 
= Œº

‚ü®WP‚ü©(WP)‚àí1, {P ‚àí1, I} (02n I2n)T 
= Œº

{P ‚àí1W ‚àí1, I} ‚ü®I‚ü©, {P ‚àí1, I} (02n I2n)T 
.
Using Remark 3.38 we have by (3.112) that
Œº

{P ‚àí1W ‚àí1, I} ‚ü®I‚ü©, {P ‚àí1, I}(02n I2n)T 
= Œº‚àó
P ‚àí1W ‚àí1(0 I)T, P ‚àí1(0 I)T 
.
Finally, we derive
Œº

(0 I)T, P ‚àí1(0 I)T 
‚àíŒº‚àó
P ‚àí1W ‚àí1(0 I)T, P ‚àí1(0 I)T 
= Œº‚àó
W ‚àí1(0 I)T, P(0 I)T 
= Œº

W (0 I)T, WP(0 I)T 
,
where we have used properties (ix) and (iii) of Theorem 3.5. This proves formula
(3.115). Applying Theorem 3.6 to just proved formula, we have
Œº

W (0 I)T, WP (0 I)T 
+ Œº

WP(0 I)T, R (0 I)T 
= Œº

R‚àí1W (0 I)T, R‚àí1WP (0 I)T 
+ Œº

W (0 I)T, R (0 I)T 
= Œº‚àó
W ‚àí1R (0 I)T, P (0 I)T 
+ Œº

W (0 I)T, R (0 I)T 
.
This proves formula (3.116).
The proof of (3.117) we get from (3.113) in the following way:
Œº

‚ü®ÀúW‚ü©, ‚ü®ÀúV ‚ü©

‚àíŒº (‚ü®W‚ü©, ‚ü®V ‚ü©)
= Œº

‚ü®ÀúW‚ü©, {P ‚àí1, R‚àí1} (02n I2n)T 
‚àíŒº

‚ü®ÀúV ‚ü©, {P ‚àí1, R‚àí1} (02n I2n)T 
,
where, on the right-hand side, we twice apply formula (3.116) obtaining
Œº

‚ü®ÀúW‚ü©, {P ‚àí1, R‚àí1} (02n I2n)T 
‚àíŒº

‚ü®ÀúV ‚ü©, {P ‚àí1, R‚àí1} (02n I2n)T 
= Œº

ÀúW (0 I)T, R‚àí1 (0 I)T 
‚àíŒº

ÀúV (0 I)T, R‚àí1 (0 I)T 
+ Œº‚àó
P ‚àí1W ‚àí1 (0 I)T, P ‚àí1(0 I)T 
‚àíŒº‚àó
P ‚àí1V ‚àí1 (0 I)T, P ‚àí1 (0 I)T 
.

3.4
Notes and References
199
Applying property (ix) of Theorem 3.5 to the difference of last summands completes
the proof of (3.117).
To prove (3.118), we apply twice property (v) of Theorem 3.5 on the right-hand
side of the just proved formula (3.117) obtaining the identities
Œº

ÀúW (0 I)T, R‚àí1 (0 I)T 
= Œº

(0 I)T, P ‚àí1W ‚àí1 (0 I)T 
‚àíŒº

R‚àí1 (0 I)T, ÀúW (0 I)T 
,
Œº‚àó
W ‚àí1 (0 I)T, P(0 I)T 
= Œº

(0 I)T, WP (0 I)T 
‚àíŒº‚àó
P (0 I)T, W ‚àí1 (0 I)T 
.
Consequently, we have
Œº

ÀúW (0 I)T, R‚àí1 (0 I)T 
‚àíŒº‚àó
W ‚àí1 (0 I)T, P (0 I)T 
= Œº‚àó
P (0 I)T, W ‚àí1 (0 I)T 
‚àíŒº

R‚àí1 (0 I)T, ÀúW (0 I)T 
.
An analogous identity holds also for the matrix V . Substituting the obtained
differences into (3.117), we obtain the proof of (3.118). The proof of this lemma
is completed.
‚äì‚äî
3.4
Notes and References
The concept of a comparative index was introduced in [114]. The origin of this
notion is twofold. On one hand, Œº(Y, ÀÜY) gives the possibility to compare matrices Y
and ÀÜY with (3.1) presenting a quantitative measure of violation of conditions (3.11).
On the other hand, according to the results of Sect. 3.2, the quantity Œº(Y, ÀÜY ) is
equal to the index, i.e., the number of negative eigenvalues of a symmetric matrix
associated with Y and ÀÜY.
The results in Theorem 3.2 were proven in [114], while Theorem 3.6 and
the properties of the comparative index in the form presented in the book (see
Theorem 3.5) are from the paper [115]. The lower bounds for the comparative index
in Lemma 3.9 are improved versions of the lower bounds derived in [289].
The statement in Lemma 3.13 was proven in [113, Lemma 2.7] and then used
together with Lemma 3.14 in the proofs of the properties of the comparative index in
[115, Lemma 4.4]. The proof of Corollary 3.16 is presented in [205, Lemma 3.1.10].
Finally, let us note that generalizations of Lemmas 3.13 and 3.14 for blocks of
different dimensions can be found in [316, Theorem 2.3] and [317, Lemma 1.4].
In Sect. 3.2.2 we constructed a symmetric operator [V ] associated with V =
(Y, ÀÜY), where Y, ÀÜY satisfy (3.1). Computing the index of [V ], we prove the key

200
3
Comparative Index Theory
property (viii) of Theorem 3.5 which is basic for the proof of the main theorem on
the comparative index (see Theorem 3.6). For the special case w(Y, ÀÜY ) = Y T J ÀÜY =
I, the matrix V is symplectic. Note that one can construct other symmetric operators
associated with V ‚ààSp(2n). For example, in [154, 155] the symmetric operator
J (V ‚àíV ‚àí1) and its generalizations are used for the classiÔ¨Åcation of eigenvalues of
symplectic matrices; other examples can be found in [163, 164], where symplectic
difference schemes are constructed using the symmetry of the Hamiltonian matrix
in (1.103). In [132] we offered an algorithm for the computation of focal points
based on Proposition 3.18.
The main results of Sect. 3.3 can be found in [117, 121], while Lemma 3.22(ii) is
proven in [124, Lemma 2.3]. We point out that 4n√ó2n matrices in the form of (3.52)
are well known and often used for different purposes in the discrete and continuous
Sturmian and spectral theory; see, for example, [39, 42, 54, 205, 248, 250].
Symmetric matrices (3.74) were originally derived in [44, 171, 172]. They were
used in comparison results for (SDS), e.g., in [56, 173, 258]. In the present work,
we derive (3.74) as a particular solution of matrix equation (3.8) associated with the
4n √ó 2n matrix ‚ü®S‚ü©. The result in Lemma 3.32 and formula (3.91) was proven for
the Ô¨Årst time in [128, Lemma 1]. Majority of the result in Sect. 3.3.5 can be found
in [121, Chapter 2].
Note also that the comparative index theory itself as based on the notion of
the Moore-Penrose generalized inversion and index results for block symmetric
matrices can be considered as a new perspective tool in the matrix linear algebra. In
this connection we mention the index results in Proposition 3.18, Lemma 3.22, and
Remark 3.35 and other results of this chapter which deserve future investigations.

Chapter 4
Oscillation Theory of Symplectic Systems
In this chapter we present the oscillation theory of symplectic difference system
(SDS). In particular, we show that it is possible to develop this theory in a similar
way to the oscillation theory of linear Hamiltonian systems or their special cases, the
Sturm-Liouville differential and difference equations. A crucial role in these results
plays the notion of a multiplicity of a focal point for conjoined bases of (SDS),
which allows to describe in quantitative way the behavior of the solutions. We deÔ¨Åne
this notion in Sect. 4.1 for the case of forward focal points in the interval (k, k + 1]
and backward focal points in the interval [k, k + 1) and connect these notions with
the comparative index from Chap. 3. The algebraic properties of the comparative
index, in particular Theorems 3.6 and 3.24, make it possible to present a completely
new approach to the oscillation theory of (SDS) by deriving classical separation
and comparison results in the form of explicit relations between the multiplicities
of focal points. In Sects. 4.2 and 4.3, we provide the Sturmian separation and
comparison theory for symplectic difference systems (SDS). In Sect. 4.4 we study
symplectic transformations and their effect on focal points on conjoined bases of
(SDS) by presenting explicit relations between their multiplicities.
4.1
Multiplicity of Focal Points
In this section we introduce the multiplicity of focal points of conjoined bases
of (SDS) as the main notion of the modern oscillation theory. We also present
results, which relate two basic concepts of the oscillation theory of discrete
symplectic systems, namely, the concepts of the multiplicity of a focal point and
the comparative index. Among others, we also establish basic relationship between
forward and backward focal points.
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7_4
201

202
4
Oscillation Theory of Symplectic Systems
4.1.1
DeÔ¨Ånition and Main Properties
The notion of the nonexistence of a focal point for a conjoined basis of (SDS) solved
the problem of positivity of the associated quadratic functional (see Sect. 2.3).
But the problem of the Sturmian separation and comparison theory for symplectic
difference systems remained untouched. In the deÔ¨Ånition of the multiplicity of
a focal point in the discrete case, the problem was how to ‚Äúmeasure‚Äù the violation
of the kernel condition and the P-condition in (2.37). In particular, the problem was
that if the kernel condition is violated, then the matrix P is no longer symmetric,
hence to count something like its negative eigenvalues or so had no meaning. This
problem was Ô¨Ånally resolved in the fundamental paper of W. Kratz [208] in 2003,
where the multiplicity of a focal point of a conjoined basis of (SDS) was deÔ¨Åned as
follows.
DeÔ¨Ånition 4.1 Let Y =
X
U

be a conjoined basis of (SDS), and consider the
following matrices
Mk := (I ‚àíXk+1X‚Ä†
k+1) Bk,
Tk := I ‚àíM‚Ä†
k Mk,
(4.1)
Pk := T T
k XkX‚Ä†
k+1BkTk,
(4.2)
The multiplicity of a forward focal point (or a left focal point) of the conjoined basis
Y in the interval (k, k + 1] is deÔ¨Åned as the number
m(Yk) = m(k) := rank Mk + ind Pk.
(4.3)
Recall that ind denotes the index of the matrix indicated, i.e., the number of its
negative eigenvalues. This deÔ¨Ånition is correct, since the matrix P in (4.2) is really
symmetric (see Proposition 4.4 or Lemma 2.45(ii) with a slightly different notation
of Pk). In the next treatment, we will denote
m1(Yk) = m1(k) := rankMk,
m2(Yk) = m2(k) := ind Pk.
The quantity m1(k) characterizes ‚Äúhow much‚Äù the kernel condition is violated (it
is also called the multiplicity of a focal point at k + 1), and the quantity m2(k)
‚Äúmeasures‚Äù violation of P-condition; it is also called the multiplicity of a focal
point in the interval (k, k + 1); compare also with Remark 2.46.
Remark 4.2 There are equivalent deÔ¨Ånitions of the multiplicity of a focal point. For
example, the multiplicity of a focal point at k + 1 can be deÔ¨Åned as
m1(k) = rankMk,
Mk := (I ‚àíX‚Ä†
k+1Xk+1) XT
k ,
and the multiplicity of a focal point in (k, k + 1) can be deÔ¨Åned as
m2(k) = ind Pk,
Pk := Tk (BT
k Dk ‚àíBT
k Qk+1Bk) Tk,
Tk := I ‚àíM‚Ä†
kMk,

4.1
Multiplicity of Focal Points
203
where Q is a symmetric matrix satisfying XT
k QkXk = XT
k Uk. The equivalence
of the above given formula with those given in DeÔ¨Ånition 4.1 can be proved by
a direct computation; see [193]. However, we prefer to postpone the proof to the
next subsection, where we obtain the equivalence of the two deÔ¨Ånitions of the
multiplicity of a focal point from the equivalence of various deÔ¨Ånitions of the
comparative index and from a formula connecting the comparative index with the
multiplicity of a focal point.
The adjective ‚Äúforward‚Äù focal point is used here to distinguish this concept
from the concept of a backward focal point which is given below. We will use
the convention that when no adjective by ‚Äúfocal point‚Äù is used, we actually mean
a forward focal point.
Consider the time-reversed symplectic system (2.47), i.e., the system
Yk = S‚àí1
k Yk+1,
S‚àí1 =
 DT ‚àíBT
‚àíCT
AT

.
Recall that this system motivates DeÔ¨Ånition 2.22 of a backward focal point,
which can be generalized as follows.
DeÔ¨Ånition 4.3 Let Y =
X
U

be a conjoined basis of (SDS), and consider the
following matrices:
ÀúMk := (I ‚àíXkX‚Ä†
k) BT
k ,
ÀúTk := I ‚àíÀúM‚Ä†
k ÀúMk,
(4.4)
ÀúPk := ÀúT T
k Xk+1X‚Ä†
kBT
k ÀúTk.
(4.5)
The multiplicity of a backward focal point (or a right focal point) of the conjoined
basis Y =
X
U

in the interval [k, k + 1) is deÔ¨Åned as the number
m‚àó(Yk) = m‚àó(k) = rank ÀúMk + ind ÀúPk.
(4.6)
In the next treatment, we will denote
m‚àó
1(Yk) = m‚àó
1(k) := rank ÀúMk,
m‚àó
2(Yk) = m‚àó
2(k) := ind ÀúPk.
The quantity m‚àó
1(k) is called the multiplicity in the point k, while m‚àó
2(k) is called
the multiplicity in the interval (k, k + 1). The main properties of m(k) and m‚àó(k)
are the following.
Proposition 4.4 Let m(k) and m‚àó(k) be the multiplicities of forward and backward
focal points of a conjoined basis Y =
X
U

of (SDS) in (k, k + 1] and [k, k + 1),
respectively. Then we have the following properties :
(i) The matrices Pk and ÀúPk in (4.2) and (4.5) are always symmetric.
(ii) We have m1(k) = 0 if and only if the kernel condition in (2.37) holds, i.e.,
Ker Xk+1 ‚äÜKer Xk.

204
4
Oscillation Theory of Symplectic Systems
Similarly, m1(k) = 0 if and only if the image condition
Im Bk ‚äÜIm Xk+1
holds. In this case Tk = I, Pk = XkX‚Ä†
k+1Bk, and m(k) = m2(k) = ind Pk.
(iii) We have m‚àó
1(k) = 0 if and only if the reversed kernel condition in (2.48) holds,
i.e.,
Ker Xk ‚äÜKer Xk+1.
Similarly, m‚àó
1(k) = 0 if and only if the image condition
Im BT
k ‚äÜIm Xk
holds. In this case ÀúTk = I, ÀúPk = Xk+1X‚Ä†
kBT
k , and m‚àó(k) = m‚àó
2(k) = ind ÀúPk.
(iv) We have m(k) = 0 if and only if the conjoined basis Y has no forward focal
points in (k, k + 1], i.e., the conditions in (2.37) hold. Similarly, m‚àó(k) = 0 if
and only if Y has no backward focal points in [k, k + 1), i.e., the conditions in
(2.48) are satisÔ¨Åed.
(v) The following inequalities are satisÔ¨Åed:
0 ‚â§rk ‚â§m(k) ‚â§Rk ‚â§n,
rk + Rk = rank Bk ‚àí rankXk,
rk := max{0, ‚àí rankXk, rankBk ‚àírank Xk+1},
Rk := min{rank Bk, rank Xk, rankBk ‚àí rankXk},
and similarly
0 ‚â§r‚àó
k ‚â§m‚àó(k) ‚â§R‚àó
k ‚â§n,
r‚àó
k + R‚àó
k = rankBk +  rankXk,
r‚àó
k := max{0,  rankXk, rank Bk ‚àírankXk},
R‚àó
k := min{rankBk, rank Xk+1, rankBk +  rankXk}.
(vi) The multiplicities m(k) and m‚àó(k) are connected by the formulas
m‚àó
1(k) ‚àím1(k) = rankXk+1 ‚àírankXk,
(4.7)
m‚àó
2(k) = m2(k),
(4.8)
m‚àó(k) ‚àím(k) = rankXk+1 ‚àírankXk.
(4.9)
The proof of Proposition 4.4 follows from the comparative index properties and
will be postponed later in Sect. 4.1.2.
Remark 4.5 Recall that the second summands m2(k) and m‚àó
2(k) in DeÔ¨Ånitions 4.1
and 4.3 of m(k) and m‚àó(k) are called the multiplicity of a focal point in the open

4.1
Multiplicity of Focal Points
205
interval (k, k + 1) (or between k and k + 1). Formula (4.8) says that these quantities
are really the same justifying the terminology used in DeÔ¨Ånitions 4.1 and 4.3.
DeÔ¨Åne the number of (forward) focal points of a conjoined basis Y =
X
U

in the
interval (M, N + 1] by the formula
l(Y, M, N + 1) :=
N

k=M
m(k).
(4.10)
Analogously, the number of backward focal points in [M, N + 1) is deÔ¨Åned by
l‚àó(Y, M, N + 1) :=
N

k=M
m‚àó(k).
(4.11)
From Proposition 4.4(vi), it immediately follows
Corollary 4.6 We have for the conjoined basis Y =
X
U

l‚àó(Y, M, N + 1) ‚àíl(Y, M, N + 1) = rank XN+1 ‚àírankXM,
(4.12)
in particular
		l‚àó(Y, M, N + 1) ‚àíl(Y, M, N + 1)
		 ‚â§max{rankXN+1, rank XM} ‚â§n.
(4.13)
4.1.2
Multiplicity of a Focal Point and Comparative Index
The Ô¨Årst statement of this subsection presents a basic formula relating the multiplic-
ity of a focal point in (k, k + 1] and the comparative index.
Lemma 4.7 Let Z be a symplectic fundamental matrix of (SDS), and let Y =
Z(0 I)T . Then
mi(k) = Œºi

Yk+1, Sk(0 I)T 
= Œº‚àó
i

Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T 
,
i ‚àà{1, 2},
(4.14)
where m(k) = m1(k) + m2(k) is the number of focal points of Y in (k, k + 1],
Œº = Œº1 +Œº2 is the comparative index of the matrices indicated, and Œº‚àó= Œº‚àó
1 +Œº‚àó
2
is the dual comparative index.
Proof In view of property (iii) of Theorem 3.5 and that Z‚àí1
k
= Z‚àí1
k+1Sk, the second
equality in (4.14) is obvious. Now we prove the Ô¨Årst equality. To this end, it is
sufÔ¨Åcient to apply the statement of Theorem 3.2(i) as follows
Œº1

Yk+1, Sk(0 I)T 
= rank(I ‚àíXk+1X‚Ä†
k+1) Bk = m1(k),

206
4
Oscillation Theory of Symplectic Systems
and also the Wronskian identity (2.4)
w

Yk+1, Sk(0 I)T 
= w

Yk, (0 I)T 
= XT
k
(4.15)
when computing
Œº2

Yk+1, Sk(0 I)T 
= ind Tk(XkX‚Ä†
k+1Bk) Tk = m2(k),
Tk = I ‚àíÀú
M‚Ä†
k Àú
Mk,
Àú
Mk = (I ‚àíXk+1X‚Ä†
k+1)Bk.
This proves the lemma.
‚äì‚äî
Similarly as in Lemma 4.7, we can prove the following statement.
Lemma 4.8 Let Z be a symplectic fundamental matrix of (SDS) (which is also
a fundamental matrix of (2.9)), and Y = Z(0 I)T . Then
m‚àó
i (k) = Œº‚àó
i

Yk, S‚àí1
k (0 I)T 
= Œºk

Z‚àí1
k (0 I)T , Z‚àí1
k+1(0 I)T 
,
i ‚àà{1, 2},
(4.16)
where m‚àó(k) = m‚àó
1(k) + m‚àó
2(k) is the number of backward focal points of Y in
[k, k + 1).
Proof The second equality in (4.16) follows from property (iii) of Theorem 3.5 and
the duality principle (Theorem 3.11), where the equality Z‚àí1
k S‚àí1
k
= Z‚àí1
k+1 has been
used. As for the Ô¨Årst equality in (4.16), using the deÔ¨Ånition of the dual comparative
index (3.12), we have by (i) of Theorem 3.5
Œº‚àó
1

Yk, S‚àí1
k (0 I)T 
= Œº1

Yk, S‚àí1
k (0 I)T 
= Œº1
Xk
Uk

,
‚àíBT
k
AT
k

= rank(I ‚àíXkX‚Ä†
k) BT
k = m‚àó
1(k).
Using the Wronskian identity (2.4)
w

Yk, S‚àí1
k (0 I)T 
= w

Yk+1, (0 I)T 
= XT
k+1
(4.17)
and the deÔ¨Ånition of Œº‚àó
2, we obtain
Œº‚àó
2

Yk, S‚àí1
k (0 I)T 
= ind [‚àíÀúTkXk+1X‚Ä†
k(‚àíBT
k ) ÀúTk] = m‚àó
2(k).
This lemma is proved.
‚äì‚äî

4.1
Multiplicity of Focal Points
207
Proof of Proposition 4.4
(i): By Lemma 4.7,
m2(k) = Œº2(Yk+1, Sk(0 I)T ) = ind P,
where the matrix P, evaluated by the deÔ¨Ånition of the comparative index (see
DeÔ¨Ånition 3.1), coincides with Pk given by (4.2). Then, Pk is symmetric
by Theorem 3.2(iii). Similarly, by Lemma 4.8, Theorem 3.2(iii), and the
deÔ¨Ånition of the dual comparative index (3.12), we prove the symmetry of
ÀúPk.
(ii): By Lemma 4.7, we have
m1(k) = Œº1(Yk+1, Sk(0 I)T ) = Œº‚àó
1(Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T )
= Œº1(Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T ),
and by Theorem 3.2(ii) the equality Œº1(Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T ) = 0 holds if
and only if Im XT
k ‚äÜIm XT
k+1 or if and only if Ker Xk+1 ‚äÜKer Xk. Similarly,
Œº1(Yk+1, Sk(0 I)T ) = 0 is equivalent to Im Bk
‚äÜIm Xk+1 by Theo-
rem 3.2(ii). In both cases Tk = I and m(k) = m2(k) = Œº2(Yk+1, Sk(0 I)T ) =
ind Pk, again by Theorem 3.2(ii).
(iii): Applying Lemma 4.8 we have
m‚àó
1(k) = Œº‚àó
1(Yk, S‚àí1
k (0 I)T ) = Œº1(Yk, S‚àí1
k (0 I)T )
= Œº1(Z‚àí1
k (0 I)T , Z‚àí1
k+1(0 I)T ).
By Theorem 3.2(ii), the equality Œº1(Z‚àí1
k (0 I)T , Z‚àí1
k+1(0 I)T ) = 0 holds
if and only if Im XT
k+1 ‚äÜIm XT
k or if and only if Ker Xk ‚äÜKer Xk+1.
Similarly, condition Œº1(Yk, S‚àí1
k (0 I)T ) = 0 is equivalent to Im BT
k ‚äÜIm Xk.
In both vases, by Theorem 3.2(ii), we have Tk = I and m‚àó(k) = m‚àó
2(k) =
Œº‚àó
2(Yk, S‚àí1
k (0 I)T ) = ind ÀúPk.
(iv): The proof follows from (ii) and (iii).
(v): According to Lemma 4.7, m(k) = Œº(Y, ÀÜY) holds, where Y := Yk+1 and
ÀÜY := Sk(0 I)T , and then w(Y, ÀÜY ) = XT
k (see (4.15)) and ÀÜX := Bk. We
see that the Ô¨Årst estimate follows from Theorem 3.5(vii), Lemma 3.9, and
Remark 3.10. In a similar way, the second estimate follows from Lemma 4.8
(4.17) and again from Theorem 3.5(vii), Lemma 3.9, and Remark 3.10.
(vi): By Lemma 4.8, we have m‚àó
i (k) = Œºi

Z‚àí1
k (0 I)T , Z‚àí1
k+1(0 I)T 
for i ‚àà
{1, 2}. Using property (vi) of Theorem 3.5 in the right-hand side of the last
formula, we obtain
Œº1

Z‚àí1
k (0 I)T , Z‚àí1
k+1(0 I)T 
= rank Xk+1‚àírank Xk+Œº‚àó
1

Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T 
.

208
4
Oscillation Theory of Symplectic Systems
Using the identity Œº‚àó
1

Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T 
= m1(k) from Lemma 4.7,
we obtain (4.7). Analogously, from (iv) of Theorem 3.5, it follows that
m‚àó
2(k) = Œº2

Z‚àí1
k (0 I)T , Z‚àí1
k+1(0 I)T 
= Œº‚àó
2

Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T 
= m2(k),
which proves (4.8). Formula (4.9) now follows from the deÔ¨Ånition of m‚àó(k) as
the sum of m‚àó
1(k) and m‚àó
2(k) (analogously for m(k)) and from (4.7) and (4.8).
‚äì‚äî
Note that by Theorems 3.2 and 3.5(iii), it is possible to formulate six equivalent
deÔ¨Ånitions of the comparative index Œº(Y, ÀÜY ); as for any choice of M or
Àú
M given
by (3.3) or (3.5), there exist three different representations of P deÔ¨Åned by (3.4),
(3.10), and the similar representation for the second component of the comparative
index Œº(Z‚àí1(0 I)T , Z‚àí1 ÀÜZ(0 I)T ). By Lemmas 4.7 and 4.8, these deÔ¨Ånitions of the
comparative index imply equivalent deÔ¨Ånitions of the multiplicity of a focal point
in (k, k + 1] and [k, k + 1), as we have already mentioned in Remark 4.2. Now
we formulate some of them and leave it to the reader to show how other deÔ¨Ånitions
follow from the properties of the comparative index.
DeÔ¨Ånition 4.9 The number of forward focal points m(k) = m1(k) + m2(k) in
(k, k + 1] of a conjoined basis Y =
X
U

of (SDS) is given by the formula
m1(k) = rank Mk,
Mk := (I ‚àíX‚Ä†
k+1Xk+1) XT
k ,
Tk := I ‚àíM‚Ä†
kMk,
(4.18)
m2(k) = ind Pk,
Pk = TkXkX‚Ä†
k+1BkTk,
(4.19)
where the matrix Pk in (4.19) can be expressed as
Pk = Tk (BT
k Dk ‚àíBT
k Qk+1Bk) Tk,
(4.20)
and Qk is any symmetric matrix satisfying
XT
k QkXk = XT
k Uk.
(4.21)
DeÔ¨Ånition 4.10 Let Z = ( ÀúY Y) be the fundamental symplectic matrix of (SDS),
where ÀúY =
 ÀúX
ÀúU

and Y =
X
U

are conjoined bases of (SDS). Then the number of
focal points m(k) = m1(k) + m2(k) in (k, k + 1] of the conjoined basis Y is given
by the formula (4.18) and
m2(k) = ind TkXk( ÀúQk) XT
k Tk,
(4.22)

4.1
Multiplicity of Focal Points
209
where the symmetric matrix ÀúQk satisÔ¨Åes
Xk ÀúQkXT
k = ‚àíÀúXkXT
k .
(4.23)
In a similar way, for the multiplicity of backward focal points, one can formulate
the following deÔ¨Ånitions.
DeÔ¨Ånition 4.11 The number of backward focal points m‚àó(k) = m‚àó
1(k) + m‚àó
2(k) in
[k, k + 1) of a conjoined basis Y =
X
U

of (SDS) is given by the formula
m‚àó
1(k) = rank Àú
Mk,
Àú
Mk := (I ‚àíX‚Ä†
kXk) XT
k+1,
ÀúTk := I ‚àíÀú
M‚Ä†
k Àú
Mk,
(4.24)
m‚àó
2(k) = ind ÀúPk,
ÀúPk = ÀúT T
k Xk+1X‚Ä†
kBT
k ÀúTk,
(4.25)
where the matrix ÀúPk in (4.25) can be expressed as
ÀúPk = ÀúTk (BkQkBT
k + BkAT
k ) ÀúTk,
(4.26)
and Qk is any symmetric matrix satisfying
XT
k QkXk = XT
k Uk.
(4.27)
DeÔ¨Ånition 4.12 Let Z = ( ÀúY Y) be the fundamental symplectic matrix of (SDS),
where ÀúY =
 ÀúX
ÀúU

and Y =
X
U

are conjoined bases of (SDS). Then the number of
backward focal points m‚àó(k) = m‚àó
1(k) + m‚àó
2(k) in [k, k + 1) of the conjoined basis
Y is given by the formula (4.24) for m‚àó
1(k) and m‚àó
2(k) = m2(k) with m2(k) given
by (4.22), (4.23).
Proposition 4.13 DeÔ¨Ånitions 4.1, 4.9, and 4.10 are equivalent. Similarly, DeÔ¨Åni-
tions 4.3, 4.11, and 4.12 are equivalent.
Proof The equivalence of DeÔ¨Ånitions 4.1 and 4.9 follows from Lemma 4.7. Indeed,
the computation of Œº Yk+1, Sk(0 I)T  by DeÔ¨Ånition 3.1, using (4.15), gives (4.18)
and (4.19). Formulas (4.20) and (4.21) follow from (iii) of Theorem 3.2. The proof
of the equivalence of DeÔ¨Ånitions 4.1 and 4.10 follows from the second formula in
Lemma 4.7. Indeed, we compute the quantity Œº‚àó
Z‚àí1
k+1(0 I)T , Z‚àí1
k (0 I)T 
by (i)
and (iii) of Theorem 3.2, using the formula Z‚àí1
k (0 I)T = ‚àíXT
k
ÀúXT
k
 and the deÔ¨Ånition
of the dual comparative index (see (3.12)). This proves (4.18) and (4.22). In a similar
way, based on Lemma 4.8 and the properties of the comparative index, we prove the
equivalence of DeÔ¨Ånitions 4.3, 4.11, and 4.12.
‚äì‚äî

210
4
Oscillation Theory of Symplectic Systems
Remark 4.14
(i) A consequence of the just proved Proposition 4.13 was already mentioned
in Lemma 2.15, where we have proved the equivalence of the inclusions
Ker Xk+1 ‚äÜKer Xk and Im Bk ‚äÜIm Xk+1, which is the consequence of
the fact that m1(k) = 0. Proposition 4.13 also implies the equivalence of
the inequalities XkX‚Ä†
k+1Bk ‚â•0, BT
k Dk ‚àíBT
k Qk+1Bk ‚â•0, and Xk( ÀúQk+1 ‚àí
ÀúQk) XT
k ‚â•0 when m2(k) = 0.
(ii) The properties of the matrix
ÀúQ in DeÔ¨Ånition 4.10 satisfying (4.23) have
an interesting relationship with the analogously deÔ¨Åned matrix for linear
Hamiltonian differential system (1.103). Under certain assumptions (see
Sect. 1.5), the invertibility of the upper entry X of a conjoined basis Y =
X
U

of (1.103) implies the strict monotonicity of the matrix ÀúQ(t) = ‚àíX‚àí1(t) ÀúX(t),
i.e., ÀúQ1(t1) <
ÀúQ(t2) for t1 < t2, where ÀúY =  ÀúX
ÀúU
 and Y are normalized
conjoined bases of (1.103); see [205, pg. 125]. Note that the assumption of
invertibility of the matrix X(t) in the continuous case corresponds to the
absence of focal points of Y = X
U
 in the discrete case, i.e., to m(k) = 0 for all
k ‚àà[0, N]Z. For this case and under the additional assumption det Xk Ã∏= 0, we
have det Xl Ã∏= 0 and  ÀúQl‚àí1 ‚â•0 for l ‚àà[k + 1, N + 1]Z with ÀúQl := ‚àíX‚àí1
l
ÀúXl
for l ‚àà[k, N +1]Z (see Remark 4.14(i)), and the strict monotonicity  ÀúQk > 0
holds if and only if det Bk Ã∏= 0. This fact follows from (iii) of Theorem 3.2 and
from the equivalence of DeÔ¨Ånitions 4.1 and 4.10. It is interesting to note that
this strict monotonicity does not require Bk > 0.
(iii) Consider symplectic system (SDS) for the scalar case (n = 1)
xk+1
uk+1

=
ak bk
ck dk
 xk
uk

,
akdk ‚àíckbk = 1.
(4.28)
We will show that the number m(yk), resp., m‚àó(yk), evaluated for a solution
yk
= (xk, uk)T with x2
k + u2
k
Ã∏= 0, takes the maximal value 1 if and
only if yk has a generalized zero in (k, k + 1], resp., in [k, k + 1) (see
DeÔ¨Ånitions 2.17, 2.23). First of all let us note that the case bk = 0 is excluded
from the consideration. Indeed, condition bk = 0 implies that m(yk) = 0, resp.
m‚àó(yk) = 0, by the estimates in Proposition 4.4(v). In a similar way, if bk = 0,
then yk has no generalized zero in (k, k + 1], resp., in [k, k + 1), indeed, for
this case the conditions xk Ã∏= 0 and xk+1 = 0 in (2.41), resp., xk+1 Ã∏= 0 and
xk = 0 in (2.49), are impossible by (4.28), where akdk ‚àíckbk = akdk = 1.
Next assume that m(yk) = 1. Then, by DeÔ¨Ånition 4.9 we have
m1(yk) = 1 ‚áîrank [(1 ‚àíxk+1x‚Ä†
k+1) xk] = 1 ‚áîxk Ã∏= 0, xk+1 = 0,
m2(yk) = 1 ‚áîxkx‚àí1
k+1bk < 0.

4.2
Sturmian Separation Theorems and Its Corollaries
211
The last conditions constitute DeÔ¨Ånition 2.17 for n = 1 (compare also with
DeÔ¨Ånition 1.1). Similarly, assuming that m‚àó(yk) = 1, we have by DeÔ¨Ånition 4.11
that
m‚àó
1(yk) = 1 ‚áîrank[(1 ‚àíxkx‚Ä†
k) xk+1] = 1 ‚áîxk+1 Ã∏= 0, xk = 0,
m‚àó
2(yk) = 1 ‚áîxk+1x‚àí1
k bk < 0.
The last conditions constitute DeÔ¨Ånition 2.23 for n = 1.
Remark 4.15 In Remark 6.60 we will present additional formulas for the multiplici-
ties of forward and backward focal points m(k) and m‚àó(k) by using the comparative
index.
4.2
Sturmian Separation Theorems and Its Corollaries
In this section we present discrete analogs of classical Sturmian separation theorems
(see Theorem 1.44) and its generalizations (see Theorem 1.50). The consideration
is based on the fundamental notion of the multiplicity of a focal point.
4.2.1
Separation Theorem: First Step
In this subsection we present the results of the paper [101], where the Ô¨Årst step
toward separation theorem which counts focal points including multiplicities has
been made. The construction in the proof of the main result of this subsection shows
that if the principal solution Y [0] of (SDS) at k = 0 has m ‚ààN (forward) focal points
in the interval (0, N+1], then there exist m admissible pairs y = (x, u) with linearly
independent components x = {xk}N
k=1 ‚ààRNn with x0 = 0 = xN+1, such that the
associated quadratic functional F(y) ‚â§0.
Theorem 4.16 (Sturmian Separation Theorem) Suppose that the principal solu-
tion Y [0] of (SDS) at 0 has no forward focal points in (0, N + 1]. Then any other
conjoined basis of (SDS) has at most n focal points in (0, N + 1].
The general idea of the proof is simple. The assumptions of theorem imply
that F(y) > 0 for every nontrivial admissible y with x0 = 0 = xN+1 (see
Theorem 2.36). We show that the existence of a conjoined basis with more than
n focal points enables the construction of an admissible y for which F(y) < 0.
In Proposition 2.38 we presented a construction of an admissible pair for (2.57)
for which F Ã∏‚â•0, when kernel condition or P-condition in (2.37) are violated. In the
following result we discuss this construction in the framework of the multiplicities

212
4
Oscillation Theory of Symplectic Systems
of forward focal points. The next lemma is a consequence of [205, Lemmas 3.1.5
and 3.1.6]; see also [208, pg. 142].
Lemma 4.17 Let Y =
X
U

be a conjoined basis of (SDS), Mk be given by (4.1)
and k ‚àà[0, N]Z. Then there exists an n √ó n matrix Sk such that
rank Sk = rankMk,
Xk+1Sk = 0,
Ker Xk ‚à©Im Sk = {0}.
(4.29)
In the next two lemmas, the matrices Mk, Pk, Tk are deÔ¨Åned by (4.1) and (4.2).
Lemma 4.18 Let rank Mk = p. Then there exist linearly independent vectors
Œ±1, . . . , Œ±p ‚ààRn such that
Xk+1Œ±j = 0,
XkŒ±j Ã∏= 0,
j = 1, . . . , p.
Proof Let Sk be the n √ó n matrix for which (4.29) holds, and let Œ±1, . . . , Œ±p be
a basis of Im Sk. Then Im Sk ‚äÜKer Xk+1 implies Xj+1Œ±j = 0, and in addition
Ker Xk ‚à©Im Sk = {0} implies XjŒ±j Ã∏= 0 for j ‚àà{1, . . ., p}.
‚äì‚äî
Lemma 4.19 Let (k, k + 1] contain a focal point of multiplicity p + q ‚â§n of
a conjoined basis Y =
X
U

of (SDS), where p = rank Mk and q = ind Pk. Further,
let Œ±1, . . . , Œ±p be the same as in the Lemma 4.18 and Œ≤1, . . . , Œ≤q be orthogonal
vectors corresponding to the negative eigenvalues of Pk, i.e., Œ≤T
j PkŒ≤j < 0 for j ‚àà
{1, . . ., q}. Denote Œ≥j := X‚Ä†
k+1BkTkŒ≤j. Then the vectors Œ±1, . . . Œ±p, Œ≥1, . . . , Œ≥q are
linearly independent.
Proof First we prove that Œ≥1, . . . , Œ≥q are linearly independent. Suppose that this is
not the case, i.e., there exists a nontrivial linear combination q
j=1 ŒºjŒ≥j = 0, and
let Œ≤ = q
j=1 ŒºjŒ≤j. Then
0 > Œ≤T PkŒ≤ = Œ≤T T T
k Xk
‚éõ
‚éù
q

j=1
ŒºjX‚Ä†
k+1BkTkŒ≤j
‚éû
‚é†= Œ≤T T T
k Xk
‚éõ
‚éù
q

j=1
ŒºjŒ≥j
‚éû
‚é†= 0,
which is a contradiction. Now suppose that Œ≥ = q
j=1 ŒºjŒ≥j = p
j=1 ŒªjŒ±j Ã∏= 0,
and let Œ≤ = q
j=1 ŒºjŒ≤j be as before. Then
0 > Œ≤T PkŒ≤ = Œ≤T T T
k XkX‚Ä†
k+1BkTkŒ≤ = Œ≤T T T
k XkX‚Ä†
k+1Xk+1Œ≥ = 0,
which is a contradiction.
‚äì‚äî
Recall that if (k, k + 1] contains a focal point of multiplicity p + q, where p =
rankMk, q = ind Pk, we say that p focal points are at k + 1, and q focal points are
in the open interval (k, k + 1).

4.2
Sturmian Separation Theorems and Its Corollaries
213
Proof of Theorem 4.16 Let Y =
X
U

be a conjoined basis of (SDS), and let the
intervals
(ki, ki + 1] ‚äÜ(0, N + 1],
i ‚àà{1, . . ., l}, 0 ‚â§k1 < k2 < ¬∑ ¬∑ ¬∑ < kl ‚â§N,
contain focal points of Y of multiplicities mi, i ‚àà{1, . . . , l}. Let mi = pi+qi, where
pi = rank Mki, qi = ind Pki. For each interval (ki, ki+1] deÔ¨Åne the admissible pairs
y[i,j] as follows. For j ‚àà{1, . . . , pi} we set
x[i,j]
k
=

XkŒ±[i]
j ,
0 ‚â§k ‚â§ki,
0,
ki + 1 ‚â§k ‚â§N + 1,
u[i,j]
k
=

UkŒ±[i]
j ,
0 ‚â§k ‚â§ki,
0,
ki + 1 ‚â§k ‚â§N + 1,
(4.30)
where Œ±[i]
j
‚ààKer Xki+1 \ Ker Xki are linearly independent n-dimensional vectors
(see Lemma 4.19). For j ‚àà{pi + 1, . . . , pi + qi} we deÔ¨Åne
x[i,j]
k
=

XkŒ≥ [i]
j ,
0 ‚â§k ‚â§ki,
0,
ki + 1 ‚â§k ‚â§N + 1,
u[i,j]
k
=
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
UkŒ≥ [i]
j ,
0 ‚â§k ‚â§ki ‚àí1,
UkŒ≥ [i]
j
‚àíTkŒ≤[i]
j ,
k = ki,
0,
ki + 1 ‚â§k ‚â§N + 1,
(4.31)
where Œ≤[i]
j , j ‚àà{1, . . ., qi} are orthogonal eigenvectors corresponding to the nega-
tive eigenvalues of the matrix Pki and Œ≥ [i]
j
= X‚Ä†
ki+1BkiŒ≤[i]
j . By Proposition 2.38, we
have for any i ‚àà{1, . . . , l}
F(y[i,j]) = (x[i,j]
0
)T u[i,j]
0
,
j ‚àà{1, . . ., pi},
F(y[i,j]) = (x[i,j]
0
)T u[i,j]
0
+ (Œ≤[i]
j )T Pk1Œ≤[i]
j , j ‚àà{pi + 1, . . . , pi + qi}.
To simplify some of the next computations, we relabel occasionally the quantities
x[i,j], u[i,j], Œ±[i]
j , . . . as follows. We introduce the index ‚Ñì‚àà{1, . . . , l
i=1 mi} by
[i, j] !‚àí‚Üí‚Ñì= i‚àí1
s=0 ms + j, m0 := 0.
Now suppose, by contradiction, that the number of focal points of Y in (0, N +
1] exceeds n, i.e., m := l
i=1 mi > n. In order to make the idea of the proof
more understandable, we will Ô¨Årst suppose that qi = 0 for i ‚àà{1, . . ., l}, i.e., all
focal points are at ki + 1 (the kernel condition is violated but all Pki ‚â•0). Since

214
4
Oscillation Theory of Symplectic Systems
l
i=1 mi = l
i=1 pi = m > n, there exists a nontrivial linear combination
m

‚Ñì=1
Œº‚Ñìx[‚Ñì]
0
= 0,
(4.32)
i.e., the admissible pair y =
x
u

given by
xk :=
m

‚Ñì=1
Œº‚Ñìx[‚Ñì]
k ,
uk :=
m

‚Ñì=1
Œº‚Ñìu[‚Ñì]
k ,
k ‚àà[1, N + 1]Z,
(4.33)
satisÔ¨Åes x0 = 0 = xN+1. Moreover, the Nn-dimensional vector x = {xk}N
k=1 is
nonzero. Indeed, consider Ô¨Årst the largest focal point kl +1 in (0, N +1]. According
to the construction of x[i,j] (returning to the original labeling), we have
x[i,j]
kl
= 0,
i ‚àà{1, . . ., l ‚àí1}, j ‚àà{1, . . . , pi},
so if x = 0, i.e., in particular, xkl = 0, we have
pl

j=1
Œºl,jx[l,j]
kl
=
pl

j=1
Œºl,jXklŒ±[l]
j = Xkl
‚éõ
‚éù
pl

j=1
Œºl,jŒ±[l]
j
‚éû
‚é†= 0.
(4.34)
Since the vectors Œ±[l]
j , j ‚àà{1, . . ., pl} form the basis of the space Im Skl, where Skl
is the same as Sk in the proof of Lemma 4.18 (here with k = kl) and at the same
time by (4.34)
pl

j=1
Œºl,jŒ±[l]
j
‚ààKer Xkl,
we have pl
j=1 Œºl,jŒ±[l]
j = 0 because of Lemma 4.17, which means that the numbers
Œºl,j = 0, j ‚àà{1, . . ., pl}, since the vectors Œ±[l]
j , are linearly independent. Repeating
the previous argument for k ‚àà{kl‚àí1, . . . , k = k1}, we Ô¨Ånd that Œºi,j = 0 for i ‚àà
{1, . . ., l} and j ‚àà{1, . . . , pi}, which contradicts our assumption that the linear
combination (4.32) is nontrivial. Therefore, x Ã∏= 0 in the admissible pair given by
(4.33).
Now, let y[Œ∫] = (x[Œ∫], u[Œ∫]) and y[‚Ñì] = (x[‚Ñì], u[‚Ñì]) for Œ∫, ‚Ñì‚àà{1, . . . , m} be two
admissible pairs constructed by (4.30). Then using (2.62) we obtain
F(y[Œ∫]; y[‚Ñì]) =

0,
Œ∫ Ã∏= ‚Ñì,
(x[‚Ñì]
0 )T u[‚Ñì]
0 ,
Œ∫ = ‚Ñì.
(4.35)

4.2
Sturmian Separation Theorems and Its Corollaries
215
Consequently, for y = x
u
 given by (4.33), we have
F(y) = F m

‚Ñì=1
Œºly[‚Ñì] =
m

Œ∫,‚Ñì=1
ŒºŒ∫Œº‚ÑìF(y[Œ∫]; y[‚Ñì])
=
 m

‚Ñì=1
Œº‚Ñìx[‚Ñì]
0
T  m

‚Ñì=1
Œº‚Ñìu[‚Ñì]
0

= xT
0 u0 = 0,
since x0 = 0 by (4.32). This contradicts the positivity of F.
Suppose now that at least one of the qi, i ‚àà{1, . . ., l} is positive. Then we have
for this index and for j ‚àà{1, . . . , pi}
F(y[i,j]) = (x[i,j]
0
)T u[i,j]
0
+ (Œ≤[i]
j )T PkiŒ≤[i]
j ,
and we have admissible pairs deÔ¨Åned both by (4.30) and (4.31). In the previous
part of the proof, we have already computed F(z[Œ∫]; z[‚Ñì]) for admissible pairs given
by (4.30). It remains to compute this bilinear form if one or both admissible pairs
are of the form (4.31). We will perform the computation in the latter case. In the
former case (i.e., one of the admissible pairs is given by (4.30) and the second one
by (4.31)), substituting into the formula into (2.62), we get again (4.35). So, let
y[Œ∫] and y[‚Ñì] be two admissible pairs given (4.31). If they are associated with the
different focal intervals (i.e., the integers ki in (4.31) are different for y[Œ∫] and y[‚Ñì]),
using (2.62) we Ô¨Ånd again that (4.35) holds. Therefore, suppose Ô¨Ånally that y[Œ∫] and
y[‚Ñì] correspond to the same focal interval (ki, ki + 1). Then
F(y[Œ∫]; y[‚Ñì]) = (x[Œ∫]
0 )T u[‚Ñì]
0 + (x[Œ∫]
ki )T {Cki‚àí1x[‚Ñì]
ki‚àí1 + Dki‚àí1u[‚Ñì]
ki‚àí1 ‚àíu[‚Ñì]
ki }
= (x[Œ∫]
0 )T u[‚Ñì]
0 + (Œ≥ [Œ∫])T XkiTkiŒ≤[‚Ñì]
= (x[Œ∫]
0 )T u[‚Ñì]
0 + (Œ≤[Œ∫])T PkiŒ≤[‚Ñì].
If Œ∫ Ã∏= ‚Ñì, then the vectors Œ≤[Œ∫] and Œ≤[‚Ñì] are orthogonal eigenvectors of the matrix
Pki, and thus (Œ≤[Œ∫])T Pki Œ≤[‚Ñì] = 0.
Summarizing our previous computations, for z = (x, u) given by (4.33) (i.e.,
x0 = 0 by (4.32)), we have (again with the two-indices labeling)
F(y) =
l
i=1
qi

j=1
(Œ≤[i]
j )T PkiŒ≤[i]
j
< 0,
which again contradicts the positivity of F. Note that x = {xk}N
k=1 is again
nontrivial, since for each i ‚àà{1, . . ., l} the vectors Œ±[i]
j
and Œ≥ [i]
s
for j ‚àà{1, . . ., pi}
and s ‚àà{1, . . . , qi} are linearly independent (by Lemma 4.19) and one can repeat

216
4
Oscillation Theory of Symplectic Systems
the same argument as used in that part of the proof where we supposed that qi = 0
for i ‚àà{1, . . . , l}.
‚äì‚äî
4.2.2
Separation Theorems and Comparative Index
In this section we present a discrete version of Theorem 1.50 and derive corollaries
of this result, in particular we prove a discrete version of Theorem 1.44. We prove
these results using the relationship between the concept of a focal point and the
comparative index elaborated in Sect. 4.1.2. This relationship gives the possibility
to apply algebraic properties of the comparative index, in particular Theorem 3.6,
which is crucial for the results of this section. We start with a discrete version of
Theorem 1.50.
Theorem 4.20 Let Y and ÀÜY be conjoined bases of (SDS). Then
Œº(Yk, ÀÜYk) = m(k) ‚àíÀÜm(k),
(4.36)
where Œº(Yk, ÀÜYk) is the comparative index of Yk and ÀÜYk and where m(k) and ÀÜm(k)
are the multiplicities of forward focal points of Y and ÀÜY, respectively, in the interval
(k, k + 1].
Proof The proof easily follows from Theorem 3.6 and Lemma 4.7. We put Z := Zk,
ÀÜZ := ÀÜZk, W := Sk in (3.16), where Z and ÀÜZ are symplectic fundamental matrices
of (SDS) such that Y = Z(0 I)T and ÀÜY = ÀÜZ(0 I)T . Then
WZ = Zk+1 = SkZk,
W ÀÜZ = ÀÜZk+1 = Sk ÀÜZk,
and using Lemma 4.7 and (3.16), we have
Œº(Yk+1, ÀÜYk+1) ‚àíŒº(Yk, ÀÜYk) = m(k) ‚àíÀÜm(k)
which is equality (4.36).
‚äì‚äî
Similarly, using (3.26) and Lemma 4.8, we obtain the ‚Äúdual‚Äù identity
Œº‚àó(Yk, ÀÜYk) ‚àíŒº‚àó(Yk+1, ÀÜYk+1) = m‚àó(k) ‚àíÀÜm‚àó(k),
which is essentially a formula (4.36) for reversed symplectic system (2.47). This
result is formulated in the next theorem.
Theorem 4.21 Let Y and ÀÜY be conjoined bases of (SDS) (which are also conjoined
bases of (2.47)). Then
‚àíŒº‚àó(Yk, ÀÜYk) = m‚àó(k) ‚àíÀÜm‚àó(k),
(4.37)

4.2
Sturmian Separation Theorems and Its Corollaries
217
where Œº‚àó(Yk, ÀÜYk) is the dual comparative index of Y and ÀÜY and where m‚àó(k) and
ÀÜm‚àó(k) are the numbers of backward focal points of Y and ÀÜY in the interval [k, k+1).
Remark 4.22 In Theorems 4.20 and 4.21, the conjoined bases Y and ÀÜY play the
same role. It means that interchanging them in (4.36), (4.37), we obtain
‚àíŒº( ÀÜYk, Yk) = m(k) ‚àíÀÜm(k),
(4.38)
and
Œº‚àó( ÀÜYk, Yk) = m‚àó(k) ‚àíÀÜm‚àó(k).
(4.39)
Note that comparing left-hand sides of (4.36) and (4.38) (analogously for (4.37) and
(4.39)), we obtain
‚àíŒº( ÀÜYk, Yk) = Œº(Yk, ÀÜYk),
resp.
‚àíŒº‚àó( ÀÜYk, Yk) = Œº‚àó(Yk, ÀÜYk).
The last equalities, taking into account property (v) of Theorem 3.5, are conse-
quences of the Wronskian identity (2.4) for conjoined bases Yk, ÀÜYk of (SDS).
The Ô¨Årst important consequence of (4.36) is a discrete version of Theorem 1.44
for linear Hamiltonian differential systems. It says, among others, that the numbers
of focal points of any two conjoined bases of (SDS) in a given interval differ by at
most n.
Theorem 4.23 Let the number of (forward) focal points of Y and ÀÜY in the interval
(M, N + 1] be given by (4.10). Then
l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1) = Œº(YN+1, ÀÜYN+1) ‚àíŒº(YM, ÀÜYM),
(4.40)
and
Œº(YN+1, ÀÜYN+1) ‚àíŒº(YM, ÀÜYM)
= Œº(YN+1, Y [M]
N+1) ‚àíŒº( ÀÜYN+1, Y [M]
N+1)
(4.41)
= Œº( ÀÜYM, Y [N+1]
M
) ‚àíŒº(YM, Y [N+1]
M
),
(4.42)
where Y [M] and Y [N+1] are the principal solutions of (SDS) at M and N + 1,
respectively.
Proof The summation of both sides of (4.36) from k = M to k = N yields equality
(4.40). Formula (4.41) follows from Theorem 3.6 with W := ZN+1Z‚àí1
M , Y := YM,
and ÀÜY := ÀÜYM, where Zk is a fundamental solution matrix of (SDS). Formula (4.42)
is derived from (4.41), applying property (ix) in Theorem 3.5, where we also use the
obvious relations Y [M]
N+1 = ZN+1Z‚àí1
M (0 I)T and Y [N+1]
M
= ZMZ‚àí1
N+1(0 I)T .
‚äì‚äî
Quite analogously we derive similar results for the backward focal points.

218
4
Oscillation Theory of Symplectic Systems
Theorem 4.24 Let the number of backward focal points of conjoined bases Y and
ÀÜY of (SDS) in [M, N + 1) be given by (4.11). Then
l‚àó(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1) = Œº‚àó(YM, ÀÜYM) ‚àíŒº‚àó(YN+1, ÀÜYN+1),
(4.43)
and
Œº‚àó(YM, ÀÜYM) ‚àíŒº‚àó(YN+1, ÀÜYN+1)
= Œº‚àó( ÀÜYN+1, Y [M]
N+1) ‚àíŒº‚àó(YN+1, Y [M]
N+1)
(4.44)
= Œº‚àó(YM, Y [N+1]
M
) ‚àíŒº‚àó( ÀÜYM, Y [N+1]
M
),
(4.45)
where Y [M] and Y [N+1] are the principal solutions of (SDS) at M and N + 1,
respectively.
Proof By the summation of both sides of (4.37) from k = M to k = N, we
obtain (4.43). Formula (4.45) follows from the dual version of Theorem 3.6 (see
formula (3.26)) for the case W := ZN+1Z‚àí1
M , Y := YM, ÀÜY := ÀÜYM, where Zk
is a fundamental solution matrix of (SDS). Formula (4.44) is derived from (4.45)
applying the dual version of property (ix) in Theorem 3.5.
‚äì‚äî
In the remaining part of this subsection, we present important corollaries to
Theorems 4.23 and 4.24. In particular, applying property (vii) of Theorem 3.5,
it is possible to derive a new set of inequalities for the difference l(Y, M, N + 1) ‚àí
l( ÀÜY, M, N + 1) of the multiplicities of focal points. The Ô¨Årst result in this direction,
based on (4.40), is presented below.
Corollary 4.25 Let Y and ÀÜY be two conjoined bases of (SDS). Then the following
estimate holds
		l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		
‚â§min
!
rank w(Y, ÀÜY ), rM,N+1, ÀÜrM,N+1
"
‚â§n,
(4.46)
where n is the dimension of block entries of the matrix Sk in (SDS), w(Y, ÀÜY ) is the
(constant) Wronskian of Y and ÀÜY, and
rM,N+1 := max{rankXM, rank XN+1},
ÀÜrM,N+1 := max{rank ÀÜXM, rank ÀÜXN+1}.

(4.47)
Proof Estimate (4.46) follows from (vii) of Theorem 3.5 and from the Wron-
skian identity w(YM, ÀÜYM) = w(YN+1, ÀÜYN+1) in (2.4). More speciÔ¨Åcally, the
left-hand side of (4.46) is equal to |ŒºN+1 ‚àíŒºM|, where Œºk is the abbrevia-
tion for Œº(Yk, ÀÜYk). From property (vii) in Theorem 3.5, we know that ŒºM ‚â§
min{rankw(Y, ÀÜY ), rank ÀÜXM} and ŒºN+1 ‚â§min{rankw(Y, ÀÜY ), rank ÀÜXN+1}, which

4.2
Sturmian Separation Theorems and Its Corollaries
219
yields that
|ŒºN+1 ‚àíŒºM| ‚â§min{rankw(Y, ÀÜY ), ÀÜrM,N+1},
(4.48)
where ÀÜrM,N+1 is given in (4.47). If we now switch the roles of the conjoined bases
Y and ÀÜY, abbreviate Œº
 ÀÜYk, Yk

as ÀÜŒºk, and use that the Wronskian of ÀÜY and Y is
equal to ‚àíwT (Y, ÀÜY ), then the formula Œºk + ÀÜŒºk = rankw(Y, ÀÜY ) in property (v) of
Theorem 3.5 yields
|ŒºN+1 ‚àíŒºM| = | ÀÜŒºN+1 ‚àíÀÜŒºM|
(4.48)
‚â§
min{rankw(Y, ÀÜY ), rM,N+1}
(4.49)
with rM,N+1 given again in (4.47). By combining (4.48) and (4.49), we obtain the
estimate in (4.46).
‚äì‚äî
By a similar way, we derive estimates for the backward focal points.
Corollary 4.26 Let Y and ÀÜY be two conjoined bases of (SDS). Then we have
		l‚àó(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1)
		
‚â§min
!
rankw(Y, ÀÜY ), rM,N+1, ÀÜrM,N+1
"
‚â§n,
(4.50)
where rM,N+1 and ÀÜrM,N+1 are given in (4.47).
Quite analogously we obtain the next statement, based on (4.41), (4.42), (4.44),
and (4.45). In contrast with Corollaries 4.25 and 4.26, we obtain the estimates,
which deal with conjoined bases of (SDS) taken in the same point M or N + 1.
Corollary 4.27 For any conjoined bases Y and ÀÜY of (SDS), we have the estimates
		 l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		 ‚â§min
!
qM, qN+1, rankX[N+1]
M
"
‚â§n,
(4.51)
		 l‚àó(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1)
		 ‚â§min
!
qM, qN+1, rankX[N+1]
M
"
‚â§n,
(4.52)
where
qk := max{rankXk, rank ÀÜXk}.
(4.53)
Proof From formula (4.41) we get the estimate
		l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		 ‚â§max
!
Œº(YN+1, Y [M]
N+1), Œº( ÀÜYN+1, Y [M]
N+1)
"

220
4
Oscillation Theory of Symplectic Systems
and by a similar way, from (4.42) we have
		l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		 ‚â§max
!
Œº( ÀÜYM, Y [N+1]
M
), Œº(YM, Y [N+1]
M
)
"
.
Then, applying property (vii) in Theorem 3.5 to the comparative indices in these
inequalities and using the Wronskian identity (2.4) when computing
rankw(Yk, Y [i]
k ) = rank Xi,
rank w( ÀÜYk, Y [i]
k ) = rank ÀÜXi, i ‚àà{M, N + 1},
we derive
		 l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		
‚â§max
!
min{rankXM, rankX[M]
N+1}, min{rank ÀÜXM, rankX[M]
N+1}
"
,
and
		 l(Y, M, N + 1) ‚àíl( ÀÜY , M, N + 1)
		
‚â§max ! min{rankXN+1, rankX[N+1]
M
}, min{rank ÀÜXN+1, rank X[N+1]
M
} ".
Formula (4.51) now follows from
rankw(Y [N+1]
k
, Y [M]
k
) = rankX[N+1]
M
= rank X[M]
N+1
and from the fact that for any real numbers x, y, z we have the equality
max{min{x, z}, min{y, z}} = min{max{x, y}, z}.
In a similar way we obtain (4.52) from (4.44), (4.45), and from property (vii) in
Theorem 3.5.
‚äì‚äî
Remark 4.28
(i) The results in Corollary 4.27 have interesting consequences. In particular, it
is possible to obtain an estimate for the difference of the forward focal points
of two conjoined bases Y and ÀÜY in the interval (M, N + 1], which does not
depend on the values at the right (or left) endpoint k = N + 1 (or k = M).
More precisely, inequality (4.51) implies that
		 l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		 ‚â§max{rankXM, rank ÀÜXM} ‚â§n,
(4.54)
		 l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		 ‚â§max{rankXN+1, rank ÀÜXN+1} ‚â§n.
(4.55)

4.2
Sturmian Separation Theorems and Its Corollaries
221
(ii) Analogously, inequality (4.52) yields similar estimates for the quantity
		l‚àó(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1)
		. The results in (4.54)‚Äì(4.55) allow
to compare the numbers of focal points of Y and ÀÜY in unbounded intervals,
when the system (SDS) is nonoscillatory.
(iii) It also follows from Corollary 4.27 that we can compare the numbers of focal
points of Y and ÀÜY using estimates which do not depend on Y and ÀÜY. In more
details we have from (4.51) and (4.52)
		 l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1)
		 ‚â§rankX[M]
N+1 = rankX[N+1]
M
‚â§n,
(4.56)
		 l‚àó(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1)
		 ‚â§rankX[N+1]
M
= rank X[M]
N+1 ‚â§n.
(4.57)
The next group of corollaries to Theorems 4.20 and 4.21 is connected with
inequalities for the Riccati type quotients, which are partly considered in Sect. 2.4.1.
We begin with the shortest proof of Corollary 2.56. Recall that we assumed in this
corollary (we use the notation of this subsection) that the two conjoined bases Y and
ÀÜY of (SDS) satisfy
Im ÀÜXk ‚äÜIm Xk,
ÀÜXT
k ( ÀÜQk ‚àíQk) ÀÜXk ‚â•0
(4.58)
for k = 0, i.e., Œº(Y0, ÀÜY0) = 0 according to Theorem 3.2(iv), and Y has no focal point
in (0, N +1], i.e., m(k) = 0 for k ‚àà[0, N]Z. Then ÀÜY has no focal point in (0, N +1]
either, and (4.58) holds for all k ‚àà[0, N + 1]Z. The symmetric matrices Q and ÀÜQ
solve the equations XT
k QkXk = XT
k Uk and ÀÜXT
k ÀÜQk ÀÜXk = ÀÜXT
k ÀÜUk for k ‚àà[0, N +1]Z.
Proof of Corollary 2.56 We use formula (4.36) and the fact that all four numbers
involved in this identity are nonnegative. Then the equalities m(k) = 0 and
Œº(Yk, ÀÜYk) = 0 are equivalent to ÀÜm(k) = 0 and Œº(Yk+1, ÀÜYk+1) = 0. Consequently,
the proof follows from the fact that m(k) = 0 and Œº(Yk, ÀÜYk) = 0 imply ÀÜm(k) = 0
and Œº(Yk+1, ÀÜYk+1) = 0.
‚äì‚äî
The following result concerning the condition Œº(YN+1, ÀÜYN+1) = 0 can be
proved quite analogically.
Corollary 4.29 Suppose that two conjoined bases Y and ÀÜY of (SDS) satisfy (4.58)
for k = N + 1 and ÀÜY does not have any forward focal point in (M, N + 1]. Then
Y has no forward focal point in (M, N + 1] either, and (4.58) holds for all k ‚àà
[M, N + 1]Z.
Proof See the proof of Corollary 2.56 above, where we showed that the conditions
ÀÜm(k) = 0, Œº(Yk+1, ÀÜYk+1) = 0 are equivalent to m(k) = 0, Œº(Yk, ÀÜYk) = 0 by
formula (4.36).
‚äì‚äî
Note that analogical statements can be obtained from (4.39) for the backward
focal points.

222
4
Oscillation Theory of Symplectic Systems
Corollary 4.30 Suppose that
Im Xk ‚äÜIm ÀÜXk,
XT
k ( ÀÜQk ‚àíQk) Xk ‚â•0
(4.59)
holds for k = N + 1. If ÀÜY has no backward focal point in [M, N + 1), then Y has
no backward focal in this interval either, and (4.59) holds for all k ‚àà[M, N + 1]Z.
Proof We use formula (4.39), i.e.,
m‚àó(k) ‚àíÀÜm‚àó(k) = Œº‚àó( ÀÜYk, Yk).
Then conditions ÀÜm‚àó(k) = 0 and Œº‚àó( ÀÜYk+1, Yk+1) = 0 are equivalent to the
conditions m‚àó(k) = 0 and Œº‚àó( ÀÜYk, Yk) = 0. The proof now follows from the fact
that ÀÜm‚àó(k) = 0 and Œº‚àó( ÀÜYk+1, Yk+1) = 0 imply m‚àó(k) = 0 and Œº‚àó( ÀÜYk, Yk) = 0.
‚äì‚äî
Certainly the proof the the previous result also implies a similar statement
connected with the condition (4.59) given at the initial point k = 0. We leave the
formulation of this result to the reader.
4.2.3
Number of Focal Points and Principal Solutions
In this subsection we derive optimal bounds for the numbers of forward and
backward focal points of any conjoined basis Y in (M, N + 1] and [M, N + 1),
respectively. These bounds are optimal in a sense that they are formulated in terms
of quantities, which do not depend on the chosen conjoined basis Y. More precisely,
they are formulated in terms of the numbers of forward and backward focal points
of principal solutions Y [M] and Y [N+1].
Important consequences of formulas (4.36) and (4.37) are related to properties
of the principal solutions of symplectic system (SDS) and its reversed system (2.9).
Recall that the principal solution of (SDS) at k is the solution satisfying the condition
Y [k]
k
= (0 I)T . Note that Œº(Yk, Y [k]
k ) = 0 for any conjoined basis Y. In particular,
from (4.40) it follows
l(Y, M, N + 1) ‚àíl(Y [M], M, N + 1) = Œº(YN+1, Y [M]
N+1),
(4.60)
where Y [M] is the principal solution at k = M. Analogously,
l(Y, M, N + 1) ‚àíl(Y [N+1], M, N + 1) = ‚àíŒº(YM, Y [N+1]
M
),
(4.61)

4.2
Sturmian Separation Theorems and Its Corollaries
223
where Y [N+1] is the principal solution at k = N + 1. As a consequence of (4.60)
and (4.61), we have the estimate
l(Y [M], M, N + 1) ‚â§l(Y, M, N + 1) ‚â§l(Y [N+1], M, N + 1),
(4.62)
l(Y [N+1], M, N + 1) = l(Y [M], M, N + 1) + rank X[M]
N+1
(4.63)
for the number of forward focal points of any conjoined basis Y of (SDS) in (0, N +
1]. Similarly, for the number of backward focal points, we have
l‚àó(Y, M, N + 1) ‚àíl‚àó(Y [M], M, N + 1) = ‚àíŒº‚àó(YN+1, Y [M]
N+1),
(4.64)
l‚àó(Y, M, N + 1) ‚àíl‚àó(Y [N+1], M, N + 1) = Œº‚àó(YM, Y [N+1]
M
),
(4.65)
where Œº‚àó(Y, ÀÜY ) is the dual comparative index. Then we also have
l‚àó(Y [N+1], M, N + 1) ‚â§l‚àó(Y, M, N + 1) ‚â§l‚àó(Y [M], M, N + 1),
(4.66)
l‚àó(Y [M], M, N + 1) = l‚àó(Y [N+1], M, N + 1) + rankX[N+1]
M
(4.67)
for the number of backward focal points of any conjoined basis Y of (SDS) in the
interval [M, N + 1).
Remark 4.31 In Theorems 4.34 and 4.35, we will show that the lower bounds in
(4.62) and (4.66) are the same, as well as the upper bounds in (4.62) and (4.66).
Moreover, these lower and upper bounds are independent on the conjoined basis
Y. Since these bounds are attained for the speciÔ¨Åc choices of Y := Y [M] and Y :=
Y [N+1], the inequalities in (4.62) and (4.66) are universal and cannot be improved‚Äî
in the sense that the estimates (4.62) and (4.66) are satisÔ¨Åed for all conjoined bases
Y of (SDS).
In (4.60) and (4.65), we derived the exact formulas
l(Y, M, N + 1) = l(Y [M], M, N + 1) + Œº(YN+1, Y [M]
N+1),
(4.68)
l‚àó(Y, M, N + 1) = l‚àó(Y [N+1], M, N + 1) + Œº(YM, Y [N+1]
M
),
(4.69)
which show how to calculate the number of forward or backward focal points of
an arbitrary conjoined basis Y of (SDS) as a sum of a quantity which does not
depend on Y and the comparative index of Y with Y [M] at k = N + 1 or the dual
comparative index of Y with Y [N+1] at k = M. For practical purposes, e.g., in the
oscillation theory on unbounded intervals, it is convenient to have estimates for the
numbers l(Y, M, N + 1) and l‚àó(Y, M, N + 1), which do not explicitly involve the
possible complicated evaluation of the comparative index. In Theorem 4.32 below,
we present such estimates of l(Y, M, N + 1) and l‚àó(Y, M, N + 1). At the same
time, we show that the universal lower and upper bounds for l(Y, M, N + 1) and

224
4
Oscillation Theory of Symplectic Systems
l‚àó(Y, M, N + 1) in (4.62) and (4.66) can be improved for some particular choice of
the conjoined basis Y.
Theorem 4.32 For any conjoined basis Y of (SDS), we have the inequalities
rN ‚â§l(Y, M, N + 1) ‚àíl(Y [M], M, N + 1) ‚â§RN,
r‚àó
N ‚â§l‚àó(Y, M, N + 1) ‚àíl‚àó(Y [N+1], M, N + 1) ‚â§R‚àó
N,
where
rN = max{0, rankX[M]
N+1 ‚àírankXN+1, rankXM ‚àírank XN+1},
(4.70)
RN = min{rankXM, rank X[M]
N+1, rankX[M]
N+1 ‚àírank XN+1 + rankXM},
(4.71)
r‚àó
N = max{0, rankX[N+1]
M
‚àírank XM, rank XN+1 ‚àírankXM},
(4.72)
R‚àó
N = min{rankXN+1, rankX[N+1]
M
, rank XN+1 ‚àírank XM + rankX[N+1]
M
}.
(4.73)
Moreover, we have
rN + RN = rank X[M]
N+1 ‚àírank XN+1 + rankXM,
(4.74)
r‚àó
N + R‚àó
N = rank X[N+1]
M
+ rankXN+1 ‚àírank XM.
(4.75)
Proof The values of the lower and upper bounds in (4.70), (4.71), and equality
(4.74) follow from (4.60) and Remark 3.10(i) (see (3.23), (3.24)), in which we take
Y := YN+1, ÀÜY := Y [M]
N+1, and w(Y, ÀÜY ) = XT
M being the Wronskian of Y and Y [M]. In
a similar way we obtain (4.72), (4.73), and (4.75) from (4.65) and Remark 3.10(i)
for the dual comparative index, in which we take Y := YM, ÀÜY := Y [N+1]
M
, and
w(Y, ÀÜY ) = XT
N+1 being the Wronskian of Y and Y [N+1].
‚äì‚äî
Now we present a discrete version of the second part of Theorem 1.44. This result
is concerned with the numbers of forward focal points of the principal solution Y [M]
in (M, N + 1] and the number of backward focal points of the principal solution
Y [N+1] in [M, N + 1). We begin with the result in a more general form.
Lemma 4.33 Let Y and ÀÜY be conjoined bases of (SDS) and Z and ÀÜZ be symplectic
fundamental matrices of (SDS), such that Y = Z(0 I)T and ÀÜY = ÀÜZ(0 I)T . Then
the number m(k) of forward focal points of Y and the number ÀÜm‚àó(k) of backward
focal points of ÀÜY are connected by the formula
ÀÜm‚àó(k) ‚àím(k) = Œº( ÀÜZ‚àí1
k Yk, ÀÜZ‚àí1
k (0 I)T ),
(4.76)

4.2
Sturmian Separation Theorems and Its Corollaries
225
where
Œº( ÀÜZ‚àí1
k Yk, ÀÜZ‚àí1
k (0 I)T ) = Œº‚àó(Z‚àí1
k
ÀÜYk, Z‚àí1
k (0 I)T ).
(4.77)
Moreover,
l‚àó( ÀÜY, M, N + 1) ‚àíl(Y, M, N + 1)
= Œº( ÀÜZ‚àí1
N+1YN+1, ÀÜZ‚àí1
N+1(0 I)T ) ‚àíŒº( ÀÜZ‚àí1
M YM, ÀÜZ‚àí1
M (0 I)T ),
(4.78)
and
Œº( ÀÜZ‚àí1
N+1YN+1, ÀÜZ‚àí1
N+1(0 I)T ) ‚àíŒº( ÀÜZ‚àí1
M YM, ÀÜZ‚àí1
M (0 I)T )
= Œº(YM, Y [N+1]
M
) ‚àíŒº‚àó( ÀÜYN+1, Y [M]
N+1)
(4.79)
= Œº‚àó( ÀÜYM, Y [N+1]
M
) ‚àíŒº(YN+1, Y [M]
N+1),
(4.80)
where Y [M] and Y [N+1] are the principal solutions of (SDS) at M and N + 1,
respectively.
Proof The proof is based on Theorem 4.20 and formula (4.9). Substituting the value
ÀÜm(k) = ÀÜm‚àó(k) ‚àí rank ÀÜXk into (4.36), we have
m(k) ‚àíÀÜm‚àó(k) = Œº(Yk, ÀÜYk) ‚àí rank ÀÜXk.
(4.81)
Then we replace Œº(Yk, ÀÜYk) ‚àírank ÀÜXk by Œº(Yk, ÀÜZk(0 I)T ) ‚àíŒº((0 I)T , ÀÜZk(0 I)T )
on the right-hand side of the last identity and derive (4.76) by application of property
(ix) of Theorem 3.5. Formula (4.77) is based on the application of property (iii) of
Theorem 3.5; see also (3.33). Summing (4.76) from k = M to k = N, we derive
(4.78). Formulas (4.80) and (4.79) follow from (4.41) and (4.42) by subtracting
the substitution rank ÀÜXk|N+1
M
from both sides according to (4.81), and then using
formula (3.22) applied to Œº( ÀÜYN+1, Y [M]
N+1) in (4.41) and Œº( ÀÜYM, Y [N+1]
M
) in (4.42),
respectively.
‚äì‚äî
From Lemma 4.33 we derive the main results of this subsection.
Theorem 4.34 Let l(Y [M], M, N + 1) be the number of forward focal points of
Y [M] in (M, N + 1] and l‚àó(Y [N+1], M, N + 1) be the number of backward focal
points of Y [N+1] in [M, N + 1). Then
l(Y [M], M, N + 1) = l‚àó(Y [N+1], M, N + 1).
(4.82)
Proof Putting Y := Y [M] and ÀÜY := Y [N+1] in (4.78), we see that the substitution
on the right-hand side of (4.78) equals to zero.
‚äì‚äî

226
4
Oscillation Theory of Symplectic Systems
Similarly we prove the next statement, which illustrates the duality principle in
the comparative index theory.
Theorem 4.35 Let l‚àó(Y [M], M, N + 1) be the number of backward focal points of
Y [M] in [M, N +1), and l(Y [N+1], M, N +1) be the number of forward focal points
of Y [N+1] in (0, N + 1]. Then
l‚àó(Y [M], M, N + 1) = l(Y [N+1], M, N + 1).
(4.83)
Proof Putting ÀÜY := Y [M] and Y := Y [N+1] in (4.78), we see that the substitution
on the right-hand side of (4.78) equals to zero.
‚äì‚äî
The next group of corollaries to Lemma 4.33 is connected with estimates for the
difference l‚àó( ÀÜY, M, N + 1) ‚àíl(Y, M, N + 1), which we derive by analogy with
a similar results in Sect. 4.2.2.
Lemma 4.36 We have the following estimates
		 l(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1)
		
‚â§max
!
min{rankXM, rank ÀÜXM}, min{rankXN+1, rank ÀÜXN+1}
"
‚â§n.
(4.84)
and
		 l(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1)
		 ‚â§rankX[N+1]
M
= rankX[M]
N+1 ‚â§n
(4.85)
In particular, for one conjoined basis Y of (SDS), we have
		 l(Y, M, N + 1) ‚àíl‚àó(Y, M, N + 1)
		
‚â§min
!
max{rankXM, rankXN+1}, rankX[M]
N+1
"
‚â§n.
(4.86)
Proof Estimate (4.84) follows from (4.78) and property (vii) in Theorem 3.5.
Indeed, by (4.78) we have
		 l‚àó( ÀÜY, M, N + 1) ‚àíl(Y, M, N + 1)
		
‚â§max{Œº( ÀÜZ‚àí1
N+1YN+1, ÀÜZ‚àí1
N+1(0 I)T ), Œº( ÀÜZ‚àí1
M YM, ÀÜZ‚àí1
M (0 I)T )},
then it is sufÔ¨Åcient to apply Theorem 3.5(vii), taking into account that
rankw( ÀÜZ‚àí1
k Yk, ÀÜZ‚àí1
k (0 I)T ) = rank Xk.

4.2
Sturmian Separation Theorems and Its Corollaries
227
Note also that according to distributivity of the operation max with respect to min
we have that the right-hand side in (4.84) less than or equal to each of the num-
bers max{rankXl, rank Xp}, max{rankXl, rank ÀÜXp}, and max{rank ÀÜXl, rank ÀÜXp}
for p, l ‚àà{M, N + 1}, p Ã∏= l.
Estimate (4.85) follows from (4.79) using the inequality
		 l‚àó( ÀÜY, M, N + 1) ‚àíl(Y, M, N + 1)
		
‚â§max{Œº(YM, Y [N+1]
M
), Œº‚àó( ÀÜYN+1, Y [M]
N+1)} ‚â§rankX[N+1]
M
= rankX[M]
N+1
derived by Theorem 3.5 (vii).
‚äì‚äî
4.2.4
Separation Results on Singular Intervals
In this subsection we apply the separation results of the previous sections to the case
of symplectic systems (SDS), which are nonoscillatory near ¬±‚àû.
DeÔ¨Ånition 4.37 System (SDS) is said to be nonoscillatory at ‚àûif there exists M ‚àà
N such that the principal solution of (SDS) at M, i.e., the conjoined basis Y [M]
given by the initial condition Y [M]
M
= (0 I)T , has no forward focal points in the
interval (M, ‚àû). Similarly, (SDS) is nonoscillatory at ‚àí‚àûif there exists M such the
principal solution at M has no backward focal points in (‚àí‚àû, M). In the opposite
case system, (SDS) is said to be oscillatory at ‚àû, resp., at ‚àí‚àû.
An equivalent deÔ¨Ånition of the (non)oscillation of system (SDS) at ¬±‚àûin
terms of arbitrary conjoined bases of (SDS) is presented in Sect. 6.3.2 (see
Proposition 6.61).
Lemma 4.38 Assume that the system (SDS) is nonoscillatory at ‚àû. Then for any
conjoined basis Y of (SDS) and for arbitrary M ‚ààZ, there exist the Ô¨Ånite limits
l(Y, M, ‚àû) =
‚àû

k=M
m(k),
l‚àó(Y, M, ‚àû) =
‚àû

k=M
m‚àó(k),
lim
k‚Üí‚àûrank Xk
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(4.87)
for the numbers of forward focal points in (M, ‚àû) and backward focal points in
[M, ‚àû) connected by the equality
l‚àó(Y, M, ‚àû) ‚àíl(Y, M, ‚àû) = lim
k‚Üí‚àûrankXk ‚àírankXM.
(4.88)

228
4
Oscillation Theory of Symplectic Systems
Similarly, if the system (SDS) is nonoscillatory at ‚àí‚àû, then for any conjoined basis
Y of (SDS) and for any N ‚ààZ, there exist the Ô¨Ånite limits
l(Y, ‚àí‚àû, N + 1) =
N

k=‚àí‚àû
m(k),
l‚àó(Y, ‚àí‚àû, N + 1) =
N

k=‚àí‚àû
m‚àó(k),
lim
k‚Üí‚àí‚àûrankXk
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(4.89)
for the numbers of forward focal points of Y in (‚àí‚àû, N + 1] and backward focal
points in (‚àí‚àû, N + 1), and
l‚àó(Y, ‚àí‚àû, N + 1) ‚àíl(Y, ‚àí‚àû, N + 1) = rank XN+1 ‚àí
lim
k‚Üí‚àí‚àûrankXk.
(4.90)
Proof Note that by (4.60)
0 ‚â§l(Y, M, N + 1) ‚àíl(Y [M], M, N + 1) = Œº(YN+1, Y [M]
N+1) ‚â§n
for arbitrary M ‚ààZ, then the Ô¨Årst Ô¨Ånite limit in (4.87) does exist for any conjoined
basis Y of nonoscillatory system (SDS). Next, according to (4.13)
|l‚àó(Y, M, N + 1) ‚àíl(Y, M, N + 1)| ‚â§max(rank XN+1, rank XM) ‚â§n,
then the second limit in (4.87) exists as well. The existence of the limit of rank Xk
as k ‚Üí‚àûcan be proved directly using the kernel condition Ker Xk+1 ‚äÜKer Xk
in (2.37), which implies 0 ‚â§rankXk ‚â§rank Xk+1 ‚â§n and then rank Xk is
bounded nondecreasing function of the index k. However the existence of the limit
limk‚Üí‚àûrankXk also follows from identity (4.12), which says that the existence of
the Ô¨Årst two limits in (4.87) implies that the third one does exist as well, and then
taking the limit in the above identity as N ‚Üí‚àûwe derive (4.88). The proof of the
second claim of Lemma 4.38 is similar.
‚äì‚äî
Next we present a singular version of Theorems 4.23 and 4.24.
Theorem 4.39 (Singular Separation Theorem)
Assume that (SDS) is nonoscil-
latory at ‚àû. Then for any two conjoined bases Y and ÀÜY of this system, there exists
the Ô¨Ånite limit of the comparative index
Œº‚àû(Y, ÀÜY ) := lim
k‚Üí‚àûŒº(Yk, ÀÜYk)
(4.91)
connecting the numbers of forward focal points of these conjoined bases in (M, ‚àû)
l(Y, M, ‚àû) ‚àíl( ÀÜY, M, ‚àû) = Œº‚àû(Y, ÀÜY ) ‚àíŒº(YM, ÀÜYM).
(4.92)

4.3
Comparison Theorems and Its Corollaries
229
Similarly, there exists the Ô¨Ånite limit of the dual comparative index
Œº‚àó
‚àû(Y, ÀÜY ) := lim
k‚Üí‚àûŒº‚àó(Yk, ÀÜYk)
(4.93)
such that the numbers of backward focal points in [M, ‚àû) are connected by the
identity
l‚àó(Y, M, ‚àû) ‚àíl‚àó( ÀÜY, M, ‚àû) = Œº‚àó(YM, ÀÜYM) ‚àíŒº‚àó
‚àû(Y, ÀÜY ).
(4.94)
Proof The proof follows immediately from Lemma 4.38 and from Theorems 4.23
and 4.24, where we evaluate the limits of the summands in (4.40) and (4.43) as N
tends to ‚àû.
‚äì‚äî
We note that a similar theorem can be formulated for the case when system (SDS)
is nonoscillatory at ‚àí‚àû.
Remark 4.40 Assume that system (SDS) is nonoscillatory at ‚àû, then for arbitrary
conjoined bases of this system, we have the following connections for the Ô¨Ånite
limits (4.91) and (4.93):
Œº‚àû(Y, ÀÜY ) + Œº‚àû( ÀÜY, Y) = rankw(Yk, ÀÜYk),
(4.95)
Œº‚àó
‚àû(Y, ÀÜY ) + Œº‚àó
‚àû( ÀÜY, Y) = rankw(Yk, ÀÜYk),
(4.96)
Œº‚àû(Y, ÀÜY ) = lim
k‚Üí‚àûrank ÀÜXk ‚àílim
k‚Üí‚àûrankXk + Œº‚àó
‚àû( ÀÜY, Y).
(4.97)
Indeed, all limits in (4.95)‚Äì(4.97) exist by Lemma 4.38 and Theorem 4.39, and
then we derive identities (4.95)‚Äì(4.97) using the properties of the comparative index
according to Theorem 3.5(v), (vi) by taking limits as k ‚Üí‚àû.
Remark 4.41 Further singular separation theorems on unbounded intervals, e.g., of
the form [M, ‚àû)Z as in this subsection, will be presented in Sect. 6.4. They are
based on comparison with the numbers of focal points of the principal solution
Y [M] and the (minimal) recessive solution Y [‚àû] of (SDS) at ‚àûfrom Sect. 6.3. As
we shall see, the latter approach also allows to evaluate the limits of the comparative
indices Œº‚àû(Y, ÀÜY ) and Œº‚àó
‚àû(Y, ÀÜY ) from Remark 4.40 explicitly; see Corollaries 6.174
and 6.186.
4.3
Comparison Theorems and Its Corollaries
In this section we consider together with (SDS) another system of the same form
(which we write now in the 2n √ó n matrix form)
ÀÜYk+1 = ÀÜSk ÀÜYk,
ÀÜST
k J ÀÜSk = J .
(4.98)

230
4
Oscillation Theory of Symplectic Systems
If Y and ÀÜY are conjoined bases of (SDS) and (4.98), respectively, then we can
introduce the Wronskian of Y and ÀÜY using notation (3.2) as
w(Yk, ÀÜYk) := Y T
k J ÀÜYk,
but, generally speaking, the Wronskian identity (2.4) is lost due to the formula
w( ÀÜYk, Yk) = ÀÜY T
k ( ÀÜST
k J Sk ‚àíJ ) Yk = ÀÜY T
k+1(J ‚àíÀÜST ‚àí1
k
J S‚àí1
k ) Yk+1.
(4.99)
Note also that by the properties of symplectic matrices (see Lemma 1.58(ii)), for
any symplectic fundamental matrices Z and ÀÜZ of (SDS) and (4.98) such that Y =
Z(0 I)T , ÀÜY = ÀÜZ(0 I)T , we have the important connection
w( ÀÜYk, Yk) = ÀÜY T
k J Yk = ‚àí(I 0) ÀÜZ‚àí1
k Zk(0 I)T = ‚àí(I 0) ÀÜZ‚àí1
k Yk
(4.100)
between the matrix ÀÜZ‚àí1
k Yk and the Wronskian (3.2) of two conjoined bases ÀÜY and
Y of systems (4.98) and (SDS). This fact will be used in the subsequent results. For
example, identity (4.99) is a direct consequence of the relation
( ÀÜZ‚àí1
k Zk) = ÀÜZ‚àí1
k+1Zk+1 ‚àíÀÜZ‚àí1
k Zk = ÀÜZ‚àí1
k ( ÀÜS‚àí1
k Sk ‚àíI) Zk
= ÀÜZ‚àí1
k+1(I ‚àíÀÜSkS‚àí1
k ) Zk+1.
(4.101)
The results of this section show that there exists a deep connection between numbers
of focal points of conjoined bases of (SDS), (4.98), and ÀúYk = ÀÜZ‚àí1
k Yk.
4.3.1
Sturmian Comparison Theorems
We start with some auxiliary statements. The Ô¨Årst one is based on Lemma 3.23.
Lemma 4.42 Let Z and ÀÜZ be symplectic fundamental matrices of (SDS) and
(4.98), respectively, Y = Z(0 I)T , ÀÜY = ÀÜZ(0 I)T , and
L(Yk, ÀÜYk, Sk, ÀÜSk) := ÀÜm(k) ‚àím(k) + Œº(Yk, ÀÜYk).
(4.102)
Then
L(Yk, ÀÜYk, Sk, ÀÜSk)
= Œº

Sk(0 I)T, ÀÜSk(0 I)T 
+ Œº
 ÀÜS‚àí1
k SkYk, Yk

‚àíŒº
 ÀÜZ‚àí1
k+1Zk+1(0 I)T, ÀÜZ‚àí1
k Zk(0 I)T 
‚àíŒº
 ÀÜS‚àí1
k SkYk, ÀÜS‚àí1
k Sk(0 I)T 
,
(4.103)

4.3
Comparison Theorems and Its Corollaries
231
or
L(Yk, ÀÜYk, Sk, ÀÜSk)
= ŒºSk(0 I)T, Sk ÀÜS‚àí1
k (0 I)T  + Œº ÀÜZ‚àí1
k Zk(0 I)T, ÀÜZ‚àí1
k+1Zk+1(0 I)T 
‚àíŒº
 ÀÜSkS‚àí1
k Yk+1, Yk+1

‚àíŒº

Yk+1, Sk ÀÜS‚àí1
k (0 I)T 
.
(4.104)
Proof We put Z := Zk, ÀÜZ := ÀÜZk, W := Sk, ÀÜW := ÀÜSk in Lemma 3.23. Since
Zk+1 = SkZk, ÀÜZk+1 =
ÀÜSk ÀÜZk, using the formula for the relationship between
the number of focal points and the comparative index in Lemma 4.7, we have the
required statement.
‚äì‚äî
Now we turn our attention to two particular cases of (4.103) and (4.104), which
will be important in applications.
Lemma 4.43 Suppose that
ÀÜS‚àí1
k Sk =
 I
0
Qk I

(4.105)
holds. Then
L(Yk, ÀÜYk, Sk, ÀÜSk)
= ind(‚àíXT
k QkXk) ‚àíŒº ÀÜZ‚àí1
k+1Zk+1(0 I)T, ÀÜZ‚àí1
k Zk(0 I)T 
= Œº
 ÀÜZ‚àí1
k Zk(0 I)T, ÀÜZ‚àí1
k+1Zk+1(0 I)T 
‚àíind(XT
k QkXk).
(4.106)
Similarly, if
Sk ÀÜS‚àí1
k
=
 I
0
Rk I

,
(4.107)
then
L(Yk, ÀÜYk, Sk, ÀÜSk)
= Œº ÀÜZ‚àí1
k Zk(0 I)T , ÀÜZ‚àí1
k+1Zk+1(0 I)T  ‚àíind(XT
k+1RkXk+1)
(4.108)
= ind(‚àíXT
k+1RkXk+1) ‚àíŒº
 ÀÜZ‚àí1
k+1Zk+1(0 I)T , ÀÜZ‚àí1
k Zk(0 I)T 
.

232
4
Oscillation Theory of Symplectic Systems
Proof Recall that the matrices Qk and Rk in (4.105) and (4.107) are symmetric by
(1.153). If (4.105) holds, then obviously by (iii) of Theorem 3.5, we have
Œº

Sk(0 I)T, ÀÜSk(0 I)T 
= Œº‚àó
S‚àí1
k (0 I)T, S‚àí1
k
ÀÜSk(0 I)T 
= Œº‚àó
S‚àí1
k (0 I)T, (0 I)T 
= 0,
Œº
 ÀÜS‚àí1
k SkYk, ÀÜS‚àí1
k Sk(0 I)T 
= Œº
 ÀÜS‚àí1
k SkYk, (0 I)T 
= 0,
Œº( ÀÜS‚àí1
k SkYk, Yk) = Œº
 
Xk
QkXk + Uk

,
Xk
Uk
 
= ind (‚àíXT
k QkXk).
Substituting these formulas for comparative indices into the right-hand side of
(4.103), we prove the Ô¨Årst part of (4.106). Note that by Theorem 3.5(v), we obtain
Œº ÀÜS‚àí1
k SkYk, Yk
 = Œº(0 I)T , Z‚àí1
k S‚àí1
k
ÀÜSkYk
 ‚àíŒºYk, ÀÜS‚àí1
k SkYk
,
and analogously
Œº
 ÀÜZ‚àí1
k+1Zk+1(0 I)T , ÀÜZ‚àí1
k Zk(0 I)T 
= Œº

(0 I)T , Z‚àí1
k S‚àí1
k
ÀÜSkYk

‚àíŒº
 ÀÜZ‚àí1
k Zk(0 I)T , ÀÜZ‚àí1
k+1Zk+1(0 I)T 
.
Consequently,
Œº
 ÀÜS‚àí1
k SkYk, Yk

‚àíŒº
 ÀÜZ‚àí1
k+1Zk+1(0 I)T , ÀÜZ‚àí1
k Zk(0 I)T 
= Œº
 ÀÜZ‚àí1
k Zk(0 I)T , ÀÜZ‚àí1
k+1Zk+1(0 I)T 
‚àíŒº

Yk, ÀÜS‚àí1
k SkYk

,
where Œº(Yk, ÀÜS‚àí1
k SkYk) = ind(XT
k QkXk). This proves (4.106). Formula (4.108) can
be proved analogously using (4.104).
‚äì‚äî
The representation for the operator L in (4.102) of Lemma 4.42 can be simpliÔ¨Åed
if we apply Theorem 3.24 to this operator. Recall that in the previous chapter, we
have introduced notation (3.52) for a symplectic matrix W, i.e.,
‚ü®W‚ü©=
‚éõ
‚éú‚éú‚éù
I
0
A B
0 ‚àíI
C D
‚éû
‚éü‚éü‚é†,
W =
A B
C D

.
Using notation (3.52) we introduce the notion of the relative oscillation numbers.

4.3
Comparison Theorems and Its Corollaries
233
DeÔ¨Ånition 4.44 For the pair of symplectic difference systems (SDS) and (4.98)
and their symplectic fundamental matrices Z and ÀÜZ, respectively, we deÔ¨Åne the
relative oscillation number #k( ÀÜZ, Z) at index k of these fundamental matrices by
the formula
#k( ÀÜZ, Z) := Œº

‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü©

‚àíŒº

‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©

= Œº

‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©

‚àíŒº

‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©


(4.109)
and the relative oscillation number of Z and ÀÜZ in the interval [M, N] by the formula
#( ÀÜZ, Z, M, N) :=
N

k=M
#k( ÀÜZ, Z).
(4.110)
Now we formulate the Sturmian comparison theorem for the pair of symplectic
difference systems (SDS), (4.98).
Theorem 4.45 (Sturmian Comparison Theorem) Let Z and ÀÜZ be symplectic
fundamental matrices of (SDS) and (4.98), respectively, and Y = Z(0 I)T and
ÀÜY = ÀÜZ(0 I)T . Then the operator L from (4.102) can be expressed as
L(Yk, ÀÜYk, Sk, ÀÜSk) = #k( ÀÜZ, Z),
(4.111)
where #k( ÀÜZ, Z) is the relative oscillation number given by (4.109).
Proof The proof is similar to that of Lemma 4.42. We put Z = Zk, ÀÜZ = ÀÜZk,
W = Sk, ÀÜW = ÀÜSk in Theorem 3.24. Then Zk+1 = SkZk, ÀÜZk+1 = ÀÜSk ÀÜZk, and using
Lemma 4.7, we obtain the proof of (4.111) with (4.109).
‚äì‚äî
Remark 4.46 Consider the meaning of the addends in the deÔ¨Ånition of the relative
oscillation numbers in details.
(i) The comparative index
Œº(‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©) = Œº‚àó(‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, ‚ü®Z‚àí1
k
ÀÜZk‚ü©)
in the Ô¨Årst equality of (4.109) describes the multiplicity of a forward focal
point of a conjoined basis of a symplectic 4n √ó 4n system associated with
(SDS) and (4.98). Indeed, by (3.101)‚Äì(3.104), the 4n √ó 2n matrix Yk =
S‚àí1
0 { ÀÜZ‚àí1
k Zk}(02n I2n)T = Zk(02n I2n)T is a conjoined basis of the symplectic
system
Yk+1 = S‚àí1
0 { ÀÜZ‚àí1
k
ÀÜS‚àí1
k Sk ÀÜZk}S0 Yk.
(4.112)

234
4
Oscillation Theory of Symplectic Systems
Then, according to (4.14) in Lemma 4.7 and by (3.104), the multiplicity m(Yk)
of a forward focal point of this basis in (k, k + 1] is given by the comparative
index
Œº‚àó(Z‚àí1
k+1(02n I2n)T , Z‚àí1
k (02n I2n)T ) = Œº‚àó(‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, ‚ü®Z‚àí1
k
ÀÜZk‚ü©).
(ii) Applying Lemma 3.21(v) to the comparative index Œº(‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©)
in the Ô¨Årst equation of (4.109), we have the representation
Œº(‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©)
= Œº‚àó(Z‚àí1
k+1 ÀÜZk+1(0 I)T , Z‚àí1
k
ÀÜZk(0 I)T ) + Œº(‚ü®ÀÜZ‚àí1
k
ÀÜS‚àí1
k Sk ÀÜZk‚ü©, ‚ü®I‚ü©),
(4.113)
where the Ô¨Årst addend is the multiplicity of a forward focal point of the
conjoined basis ÀúYk = ÀÜZ‚àí1
k Yk of the symplectic system
ÀúYk+1 = ÀÜZ‚àí1
k
ÀÜS‚àí1
k Sk ÀÜZk ÀúYk
(4.114)
by (4.14) in Lemma 4.7. Recall that the upper block of ÀúYk is associated with
the Wronskian of Yk and ÀÜYk; see (4.100).
(iii) Similarly, the comparative index Œº(‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©) in the second
formula of (4.109) represents the multiplicity m‚àó(Yk) of a backward focal point
in the interval [k, k+1) of the conjoined basis Yk = S‚àí1
0 {Z‚àí1
k
ÀÜZk}(02n I2n)T =
Zk(02n I2n)T of the symplectic system
Yk+1 = S‚àí1
0 {Z‚àí1
k S‚àí1
k
ÀÜSkZk}S0Yk,
(4.115)
according to (4.16) in Lemma 4.8. The Ô¨Årst addend in the formula
Œº(‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©)
= Œº( ÀÜZ‚àí1
k Zk(0 I)T , ÀÜZ‚àí1
k+1Zk+1(0 I)T ) + Œº(‚ü®Z‚àí1
k S‚àí1
k
ÀÜSkZk‚ü©, ‚ü®I‚ü©),
(4.116)
derived by Lemma 3.21(v) is the multiplicity of a backward focal point of the
conjoined basis ÀúYk = Z‚àí1
k
ÀÜYk of the symplectic system
ÀúYk+1 = Z‚àí1
k S‚àí1
k
ÀÜSkZk ÀúYk.
(4.117)
Using the results of Sects. 3.3 and 3.3.5, we can prove the following properties
of the relative oscillation numbers.

4.3
Comparison Theorems and Its Corollaries
235
Lemma 4.47 Let Z and ÀÜZ be symplectic fundamental matrices of (SDS) and
(4.98), respectively. Then we have the following properties for their relative
oscillation numbers:
(i) If Y = Z(0 I)T and ÀÜYi = ÀÜZ(0 I)T , then
#k( ÀÜZ, Z) + #k(Z, ÀÜZ) = rankw(Yk, ÀÜYk),
w(Yk, ÀÜYk) = Y T
k J ÀÜYk,
(4.118)
(ii) We have the estimate
|#k( ÀÜZ, Z)| ‚â§rank(Sk ‚àíÀÜSk).
(4.119)
(iii) Let Z and  be symplectic fundamental matrices of (SDS), and let ÀÜZ and ÀÜ
be symplectic fundamental matrices of (4.98). Then we have the formula
#k( ÀÜZ, Z) ‚àí#k( ÀÜ, ) = Œº

‚ü®ÀÜ‚àí1
k k‚ü©, {W, V }(02n, I2n)T 
,
W = ‚àí1
k Zk,
V = ÀÜ‚àí1
k
ÀÜZk.
(4.120)
Consequently
#( ÀÜZ, Z, M, N) ‚àí#( ÀÜ, , M, N)
= Œº

‚ü®ÀÜ‚àí1
k k‚ü©, {W, V }(02n, I2n)T 			
N+1
M
,
(4.121)
where {W, V } is deÔ¨Åned by (3.101).
(iv) If W and V are lower block-triangular matrices, then
#k( ÀÜZ, Z, M, N) = #k(, ÀÜ, M, N).
Proof
(i) Using (4.109) and Lemma 3.21 (iii), (iv) we obtain
#k(Z, ÀÜZ) = Œº(‚ü®Z‚àí1
k
ÀÜZk‚ü©, ‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©) ‚àíŒº(‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü©)
= Œº(‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©) ‚àíŒº(‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, ‚ü®Z‚àí1
k
ÀÜZk‚ü©)
= Œº(‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©) ‚àíŒº‚àó(‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©)
= Œº(‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©) ‚àíŒº(‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©) + rankw(Yk, ÀÜYk),
where in the last equality, we have also incorporated equation (4.100)
when applying Lemma 3.21(iv). Consequently, #k(Z, ÀÜZ) = ‚àí#k( ÀÜZ, Z) +
 rankw(Yk, ÀÜYk) holds, which is the same as (4.118).

236
4
Oscillation Theory of Symplectic Systems
(ii) The proof follows from Lemma 3.21 (ii) (see (3.53)) and equation (4.101),
which implies
Œº(‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©) ‚â§rank( ÀÜZ‚àí1
k Zk) = rank(Sk ‚àíÀÜSk)
and
Œº(‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©) ‚â§rank(Sk ‚àíÀÜSk).
(iii) Note that the matrix W in (4.120) is constant for two fundamental matrices
Z,  of the same system (SDS) (similarly for V and ÀÜZ and ÀÜ), then ‚àí1
l
l =
V ÀÜZ‚àí1
l
ZlW ‚àí1, l = k, k + 1. Using Lemma 3.39 we obtain
Œº

‚ü®ÀÜ‚àí1
k k‚ü©, ‚ü®ÀÜ‚àí1
k+1k+1‚ü©

= Œº‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü© ‚àíŒº‚ü®ÀÜ‚àí1
k k‚ü©, {W, V }(02n, I2n)T .
Consequently,
Œº

‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©

‚àíŒº

‚ü®ÀÜ‚àí1
k k‚ü©, ‚ü®ÀÜ‚àí1
k+1k+1‚ü©

= Œº

‚ü®ÀÜ‚àí1
k k‚ü©, {W, V }(02n, I2n)T 
.
Hence the last formula implies (4.120) and its summation from k = M to
k = N yields (4.121).
(iv) The proof follows from the elementary fact that if W and V are symplectic
lower block-triangular matrices, then {W, V }(0 I)T deÔ¨Åned by (3.101) has
upper block equal to zero, and hence, we have Œº(‚ü®ÀÜ‚àí1
i i‚ü©, {W, V }(02n, I2n)T )
= 0.
‚äì‚äî
Note that part (iv) of the previous lemma shows that the results based on
Theorem 4.45 depend really only on the second block column of the considered
fundamental matrices, while the Ô¨Årst matrix column (which is not determined by
the second matrix column uniquely) is disregarded.
Remark 4.48 Note also that the operator L in (4.102), in view of properties (v) and
(vi) of Theorem 3.5, can be expressed in various forms as
L(Yk, ÀÜYk, Sk, ÀÜSk) = ÀÜm(k) ‚àím(k) +  rankw(Yk, ÀÜYk) ‚àíŒº( ÀÜYk, Yk),
(4.122)
L(Yk, ÀÜYk, Sk, ÀÜSk) = ÀÜm‚àó(k) ‚àím‚àó(k) + Œº‚àó( ÀÜYk, Yk),
(4.123)
L(Yk, ÀÜYk, Wk, ÀÜWk) = ÀÜm‚àó(k) ‚àím‚àó(k) +  rankw(Yk, ÀÜYk) ‚àíŒº‚àó(Yk, ÀÜYk).
(4.124)

4.3
Comparison Theorems and Its Corollaries
237
Using property (4.118) of the numbers #k( ÀÜZ, Z), we obtain from (4.122) a general-
ization of formula (4.38) for the case of conjoined bases of two different systems
ÀÜm(k) ‚àím(k) ‚àíŒº( ÀÜYk, Yk) = ‚àí#k(Z, ÀÜZ),
(4.125)
Analogously, from (4.123) it follows a generalization of (4.39):
ÀÜm‚àó(k) ‚àím‚àó(k) + Œº‚àó( ÀÜYk, Yk) = #k( ÀÜZ, Z).
(4.126)
Finally, from (4.124) it follows the generalization of (4.37)
ÀÜm‚àó(k) ‚àím‚àó(k) ‚àíŒº‚àó(Yk, ÀÜYk) = ‚àí#k(Z, ÀÜZ).
(4.127)
Now we formulate a consequence of Theorem 4.45. We use there the concept of
the number of (forward) focal points of the conjoined bases of (SDS) in (M, N + 1]
deÔ¨Åned by (4.10) and
l( ÀÜY, M, N + 1) =
N

i=M
ÀÜm(i).
(4.128)
The next theorem extends formula (4.40) in Theorem 4.23 and Corollary 4.25 to the
case when Y and ÀÜY are conjoined bases of two different symplectic systems.
Theorem 4.49 Suppose that Y and ÀÜY are conjoined bases of (SDS) and (4.98),
respectively, their numbers of focal points in (M, N + 1] are deÔ¨Åned by (4.10),
(4.128). Further suppose that the relative oscillation number in [M, N] of symplec-
tic fundamental matrices Z and ÀÜZ is given by (4.110) and these matrices are related
to Y and ÀÜY by the relations Y = Z (0 I)T and ÀÜY = ÀÜZ (0 I)T . Then
l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1) + #( ÀÜZ, Z, M, N)
= Œº(YN+1, ÀÜYN+1) ‚àíŒº(YM, ÀÜYM),
(4.129)
in particular,
		l(Y, M, N + 1) ‚àíl( ÀÜY, M, N + 1) + #( ÀÜZ, Z, M, N)
		
‚â§min !ÀÜrM,N+1, ¬ØrM,N+1
" ‚â§n,
(4.130)
where ÀÜrM,N+1 is given by (4.47),
¬ØrM,N+1 = max{rankw(YM, ÀÜYM), rankw(YN+1, ÀÜYN+1)},
and n is dimension of blocks of Sk in (SDS).

238
4
Oscillation Theory of Symplectic Systems
Proof The summation of (4.111) from k = M to k = N gives (4.129). The estimate
(4.130) is derived by analogy with the proof of (4.46) in Corollary 4.25, where we
cannot use that the Wronskian w(Y, ÀÜY ) is constant.
‚äì‚äî
The next theorems extend Corollaries 2.56 and 4.30 to the case of two symplectic
systems (SDS) and (4.98). The Ô¨Årst result is a discrete counterpart of Theorem 1.48
(Riccati inequality) and generalizes Theorem 2.54 to two discrete Hamiltonian
systems and Theorem 2.55 to two symplectic systems.
Theorem 4.50 Suppose that conjoined bases Y =
X
U

and ÀÜY =
 ÀÜX
ÀÜU

of (SDS)
and (4.98) satisfy (4.58) for k = M, the relative oscillation number (4.109) for
symplectic fundamental matrices Z and ÀÜZ of these systems associated with Y and
ÀÜY such that Y = Z (0 I)T and ÀÜY = ÀÜZ (0 I)T satisÔ¨Åes
#k( ÀÜZ, Z) ‚â§0,
k ‚àà[M, N]Z,
(4.131)
and that Y has no forward focal points in (M, N + 1]. Then ÀÜY has no forward focal
points in this interval either,
#( ÀÜZ, Z, M, N) = 0,
(4.132)
and condition (4.58) holds for all k ‚àà[M, N + 1]Z.
Proof Rewrite formula (4.111) in the form
ÀÜm(k) + Œº(Yk+1, ÀÜYk+1) + (‚àí#k( ÀÜZ, Z)) = Œº(Yk, ÀÜYk) + m(k).
Because all summands in the left-hand side are nonnegative, the fact that the right-
hand side equals zero by assumptions implies that all three summands also equal
zero for all indices k ‚àà[M, N]Z.
‚äì‚äî
Remark 4.51
(i) The comparative indices for the symplectic coefÔ¨Åcient matrices of (SDS) and
(4.98) in (4.109) are traditionally assumed to be zero in the classical oscillation
theory. In this case we will call the conditions
Œº‚ü®Sk‚ü©, ‚ü®ÀÜSk‚ü© = 0
(4.133)
and
Œº

‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©

= 0
(4.134)
as the (Sturmian) majorant conditions for the pair of symplectic systems (SDS)
and (4.98). These conditions can be rewritten in terms of the blocks of Sk and
ÀÜSk according to the results in Sect. 3.3.2. For example, the majorant condition

4.3
Comparison Theorems and Its Corollaries
239
(4.134) is equivalent to the conditions
Im (Ak ‚àíÀÜAk,
Bk) ‚äÜIm ÀÜBk,

I AT
k
0 BT
k


Q‚ü®Sk‚ü©‚àíQ‚ü®ÀÜSk‚ü©
  I
0
Ak Bk

,
‚é´
‚é™‚é¨
‚é™‚é≠
(4.135)
where the symmetric matrix Q‚ü®Sk‚ü©is deÔ¨Åned by (3.71) with W := Sk and
Q‚ü®ÀÜSk‚ü©is deÔ¨Åned similarly for system (4.98) (see Lemma 3.25). In particular,
these matrices can be taken in form (3.74), which is equivalent to (2.64), and
one can replace the second condition in (4.135) by the more strict majorant
condition
Gk ‚àíÀÜGk ‚â•0,
(4.136)
where Gk is deÔ¨Åned by (2.64) and ÀÜGk is deÔ¨Åned similarly for system (4.98).
Note that (4.136) is sufÔ¨Åcient for the second condition in (4.135).
(ii) Consider linear Hamiltonian difference system (2.15) and another system of
the same form with the Hamiltonian ÀÜH =

‚àíÀÜC ÀÜAT
ÀÜA
ÀÜB

. Then using Example 3.34
and formula (3.93), we see that (4.133) is equivalent to the conditions
Ker Bk ‚äÜKer ÀÜBk,
ÀÜBk ‚â•ÀÜBkB‚Ä†
k ÀÜBk,
(4.137)
Im(Ak ‚àíÀÜAk) ‚äÜIm(Bk ‚àíÀÜBk),
ÀÜCk ‚àíCk ‚àí(Ak ‚àíÀÜAk)T (Bk ‚àíÀÜBk)‚Ä†(Ak ‚àíÀÜAk) ‚â•0.

(4.138)
Then, (4.137) is equivalent to the Ô¨Årst summand in (3.93) being zero, while
(4.138) is equivalent to the fact that the second summand in (3.93) takes the
value zero. Let us now examine the relationship of (4.137) and (4.138) with
conditions (2.102) in Theorem 2.54, which read as follows:
Hk ‚àíÀÜHk ‚â•0,
Ker Bk ‚äÜKer ÀÜBk,
ÀÜBk ‚â•ÀÜBkB‚Ä†
k ÀÜBk.
(4.139)
The conditions in (4.139) represent a discrete counterpart of conditions (1.128)
for linear Hamiltonian differential systems (1.99), i.e., of the conditions
H(t) ‚àíÀÜH(t) ‚â•0,
ÀÜB(t) ‚â•0.
Note that by Corollary 3.16, the condition Hk‚àíÀÜHk ‚â•0 in (4.139) is equivalent
to three conditions, namely, to (4.138) and the additional condition Bk ‚àíÀÜBk ‚â•
0. In this way, all three conditions in (4.139) are sufÔ¨Åcient for (4.137) and
(4.138) and, in turn, also for (4.133). The last fact conÔ¨Årms that Corollary 4.50
is a generalization of Theorem 2.54. Note, however, that (4.137) and (4.138)
do not imply the inequality Bk ‚àíÀÜBk ‚â•0. Moreover, if (4.137) and Bk ‚â•ÀÜBk

240
4
Oscillation Theory of Symplectic Systems
simultaneously hold, then ind Bk = ind ÀÜBk, which follows from (3.92) (see also
Remark 3.35). In particular, for a pair of 2n-th order Sturm-Liouville difference
equations (2.27), the leading coefÔ¨Åcients r[n]
k
and ÀÜr[n]
k
must have in this case the
same sign; see also Example 3.36. For the continuous time case, the conditions
in (1.128) imply the Legendre condition (1.111) for system (1.103), and then
in this case ind ÀÜB(t) = ind B(t) = 0. In the discrete case, we need neither
the Legendre condition ind ÀÜBk = ind Bk = 0 nor the more general assumption
ind ÀÜBk = ind Bk. Hence, the sufÔ¨Åcient conditions of Theorem 2.54 are slightly
overdeÔ¨Åned by the condition Bk ‚àíÀÜBk ‚â•0, which is included in Hk ‚àíÀÜHk ‚â•
0. On the other hand, the last condition is convenient for applications of this
theorem in some particular cases.
(iii) Concerning special cases of the majorant condition in (4.133) for the scalar
and matrix Sturm-Liouville difference equations and for the 2n-th order
Sturm-Liouville difference equations, see, respectively, Examples 3.29, 3.30,
and 3.36.
Note the majorant condition (4.133) represents a simple assumption, which
implies (4.131). This follows from (4.109). In this case the results of Theorem 4.50
can be strengthened in the following direction.
Corollary 4.52 Suppose that all assumptions of Theorem 4.50 hold and (4.131) is
replaced by majorant condition (4.133) for k ‚àà[M, N]Z. Then all statements of
Theorem 4.50 are true, and we have instead of (4.132) the equality
Œº

‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©

= 0,
k ‚àà[M, N]Z,
(4.140)
i.e., the conjoined bases Y and ÀúY of systems (4.112) and (4.114) do not have any
forward focal points in the interval (M, N + 1].
In a similar way, in order to present an extension of Corollary 4.30, we use
formula (4.126), which connects the multiplicities of backward focal points of
conjoined bases of (SDS) and (4.98).
Theorem 4.53 Suppose that for conjoined bases Y and ÀÜY of systems (SDS) and
(4.98) condition (4.59) holds at k = N + 1, ÀÜY has no backward focal points in the
interval [M, N +1), and the relative oscillation number for symplectic fundamental
matrices Z and ÀÜZ associated with Y and ÀÜY obeys the condition
#k( ÀÜZ, Z) ‚â•0,
k ‚àà[M, N]Z.
(4.141)
Then the conjoined basis Y has no backward focal points in this interval either
#k( ÀÜZ, Z, M, N) = 0,
(4.142)
and (4.59) holds for all k ‚àà[M, N + 1].

4.3
Comparison Theorems and Its Corollaries
241
Proof We rewrite (4.126) in the form
ÀÜm‚àó(k) + Œº‚àó( ÀÜYk+1, Yk+1) = #k( ÀÜZ, Z) + m‚àó(k) + Œº‚àó( ÀÜYk, Yk).
Then taking into account the assumptions of the theorem, we have that the condition
ÀÜm‚àó(k) = Œº‚àó( ÀÜYk+1, Yk+1) = 0 implies #k( ÀÜZ, Z) = m‚àó(k) = Œº‚àó( ÀÜYk, Yk) = 0.
‚äì‚äî
In view of formula (4.109), the majorant condition (4.134) is a simplest sufÔ¨Åcient
condition for (4.141).
Corollary 4.54 Suppose that instead of (4.141) the majorant condition (4.134)
holds for k ‚àà[M, N]Z, while all the other assumptions of Theorem 4.53 are
satisÔ¨Åed. Then all statements of this theorem are true, and, additionally, we have
that the conjoined bases Y and ÀúY of systems (4.115) and (4.117) do not have any
backward focal points in the interval [M, N + 1).
4.3.2
Comparison Theorems for Principal Solutions
We have proved in Theorem 4.34 the equality for the numbers of forward and
backward focal points of principal solutions at k = M and k = N + 1, i.e.,
l

Y [M], M, N + 1

= l‚àó
Y [N+1], M, N + 1

.
Now we will turn our attention to the situation, when the conjoined bases in the
previous formula are solutions of different symplectic systems. For the proof we
need the following auxiliary result on a representation of the relative oscillation
numbers for the special case of the principal solutions.
Lemma 4.55 Let Z[M] and ÀÜZ[N+1] be fundamental symplectic matrices of (SDS)
and (4.98) such that Y [M] = Z[M] (0 I)T and ÀÜY [N+1] = ÀÜZ[N+1] (0 I)T are the
principal solutions of these systems at k = M and k = N + 1, respectively. We
deÔ¨Åne the relative oscillation number of these matrices by formula (4.109), i.e.,
#k( ÀÜZ[N+1], Z[M]) := Œº(‚ü®Gk‚ü©, ‚ü®Gk+1‚ü©) ‚àíŒº(‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©),
k ‚àà[M, N]Z,
(4.143)
where
Gk := ( ÀÜZ[N+1]
k
)‚àí1Z[M]
k
.

242
4
Oscillation Theory of Symplectic Systems
Then, for the endpoints k = M and k = N of the interval, the formula in (4.143) is
speciÔ¨Åed as
#M( ÀÜZ[N+1], Z[M]) = Œº‚àó ÀÜY [N+1]
M
, ÀÜS‚àí1
M SM (0 I)T 
‚àíŒº ÀÜSM(0 I)T , SM(0 I)T ,
(4.144)
#N( ÀÜZ[N+1], Z[M]) = Œº ÀÜSNY [M]
N
, ÀÜSNS‚àí1
N (0 I)T 
‚àíŒº‚àó ÀÜS‚àí1
N (0 I)T , S‚àí1
N (0 I)T 
.
(4.145)
Proof The speciÔ¨Åcation of the values #k
 ÀÜZ[N+1], Z[M]
for k = M and k = N
follows from Lemma 3.21. In fact, using the condition Z[M]
M (0 I)T = (0 I)T , we
obtain that
Œº‚ü®GM‚ü©, ‚ü®GM+1‚ü© = ŒºGM(0 I)T , GM+1(0 I)T  + Œº‚ü®G‚àí1
M+1GM‚ü©, ‚ü®I‚ü©
= Œº

GM(0 I)T , GM+1(0 I)T 
+ Œº

‚ü®S‚àí1
M ÀÜSM‚ü©, ‚ü®I‚ü©

,
where we have used Lemma 3.21(v). Analogously
Œº

‚ü®ÀÜSM‚ü©, ‚ü®SM‚ü©

= Œº
 ÀÜSM(0 I)T , SM(0 I)T 
+ Œº

‚ü®S‚àí1
M ÀÜSM‚ü©, ‚ü®I‚ü©

.
Consequently, by Theorem 3.5(iii),
Œº

‚ü®GM‚ü©, ‚ü®GM+1‚ü©

‚àíŒº

‚ü®ÀÜSM‚ü©, ‚ü®SM‚ü©

= Œº

GM(0 I)T , GM+1(0 I)T 
‚àíŒº
 ÀÜSM(0 I)T , SM(0 I)T 
= Œº

( ÀÜZ[N+1]
M
)‚àí1(0 I)T , ( ÀÜZ[N+1]
M+1 )‚àí1SM(0 I)T 
‚àíŒº
 ÀÜSM(0 I)T , SM(0 I)T 
= Œº‚àó ÀÜZ[N+1]
M
(0 I)T , ÀÜS‚àí1
M SM(0 I)T 
‚àíŒº
 ÀÜSM(0 I)T , SM(0 I)T 
,
which proves (4.144). Analogously, by Lemma 3.21(v), we have
Œº

‚ü®GN‚ü©, ‚ü®GN+1‚ü©

= Œº‚àó
G‚àí1
N (0 I)T , G‚àí1
N+1(0 I)T 
+ Œº

‚ü®GNG‚àí1
N+1‚ü©, ‚ü®I‚ü©

= Œº‚àóG‚àí1
N (0 I)T , G‚àí1
N+1(0 I)T  + Œº‚ü®ÀÜSNS‚àí1
N ‚ü©, ‚ü®I‚ü©,
and similarly
Œº

‚ü®ÀÜSN‚ü©, ‚ü®SN‚ü©

= Œº‚àó ÀÜS‚àí1
N (0 I)T , S‚àí1
N (0 I)T 
+ Œº

‚ü®ÀÜSNS‚àí1
N ‚ü©, ‚ü®I‚ü©

.

4.3
Comparison Theorems and Its Corollaries
243
Consequently, by Theorem 3.5(iii) we have proved that
Œº

‚ü®GN‚ü©, ‚ü®GN+1‚ü©

‚àíŒº

‚ü®ÀÜSN‚ü©, ‚ü®SN‚ü©

= Œº‚àó
G‚àí1
N (0 I)T , G‚àí1
N+1(0 I)T 
‚àíŒº‚àó ÀÜS‚àí1
N (0 I)T , S‚àí1
N (0 I)T 
= Œº‚àó
(Z[M]
N )‚àí1 ÀÜS‚àí1
N (0 I)T , (Z[M]
N+1)‚àí1(0 I)T 
‚àíŒº‚àó ÀÜS‚àí1
N (0 I)T , S‚àí1
N (0 I)T 
= Œº
 ÀÜSNZ[M]
N (0 I)T , ÀÜSNS‚àí1
N (0 I)T 
‚àíŒº‚àó ÀÜS‚àí1
N (0 I)T , S‚àí1
N (0 I)T 
.
The proof is complete.
‚äì‚äî
Now we present a generalization of Theorems 4.34 and 4.35 to two symplectic
systems.
Theorem 4.56 (Sturmian Comparison Theorem) Consider the symplectic fun-
damental matrices Z[M], Z[N+1] and ÀÜZ[M], ÀÜZ[N+1] of systems (SDS) and (4.98),
which are associated with the principal solutions Y [M], Y [N+1] and ÀÜY [M], ÀÜY [N+1]
of these systems via (3.14). Then
l‚àó( ÀÜY [N+1], M, N + 1) ‚àíl(Y [M], M, N + 1)
= l( ÀÜY [M], M, N + 1) ‚àíl(Y [M], M, N + 1) = #( ÀÜZ[N+1], Z[M], M, N),
(4.146)
and
l( ÀÜY [N+1], M, N + 1) ‚àíl‚àó(Y [M], M, N + 1)
= l‚àó( ÀÜY [M], M, N + 1) ‚àíl‚àó(Y [M], M, N + 1) = #( ÀÜZ[M], Z[N+1], M, N),
(4.147)
where the quantities l‚àó(Y, M, N + 1), l(Y, M, N + 1), and #( ÀÜZ, Z, M, N) are
given by formulas (4.10), (4.11), and (4.109), (4.110). Moreover, for the relative
oscillation numbers in the right-hand sides of (4.146), (4.147) we have the relations
#( ÀÜZ[N+1], Z[M], M, N) = ‚àí#(Z[N+1], ÀÜZ[M], M, N),
(4.148)
#( ÀÜZ[M], Z[N+1], M, N) = ‚àí#(Z[M], ÀÜZ[N+1], M, N).
(4.149)
Proof For the proof of (4.146), we use Theorem 4.49 for the particular case when
ÀÜY := ÀÜY [N+1] is the principal solution of (4.98) at k = N + 1 and Y := Y [M] is the
principal solution of (SDS) at k = M. We rewrite (4.129) into the form
l( ÀÜY [N+1], M, N + 1) ‚àíl(Y [M], M, N + 1) ‚àírank ÀÜX[N+1]
M
= #( ÀÜZ[N+1], Z[M], M, N),
(4.150)

244
4
Oscillation Theory of Symplectic Systems
where we have used that Œº

Y [M]
M , ÀÜY [N+1]
M

= rank ÀÜX[N+1]
M
and Œº

Y [M]
N+1, ÀÜY [N+1]
N+1

=
0, according to the deÔ¨Ånition of the comparative index. We modify the summands
in the left-hand side of (4.150) as
l( ÀÜY [N+1], M, N +1)‚àírank ÀÜX[N+1]
M
= l‚àó( ÀÜY [N+1], M, N +1) = l( ÀÜY [M], M, N +1),
where we have used (4.12) for ÀÜY [N+1]
k
and (4.82) for l‚àó( ÀÜY [N+1], M, N + 1) and
l( ÀÜY [M], M, N + 1). This proves formula (4.146).
In a similar way, by putting ÀÜY := ÀÜY [M] and Y := Y [N+1] in Theorem 4.49, we
have (4.129) in the form
l( ÀÜY [M], M, N + 1) ‚àíl(Y [N+1], M, N + 1) + rank ÀÜX[M]
N+1
= #( ÀÜZ[M], Z[N+1], M, N).
(4.151)
Applying (4.12) we have l( ÀÜY [M], M, N + 1) + rank ÀÜX[M]
N+1 = l‚àó( ÀÜY [M], M, N + 1),
and by (4.83) we get l(Y [N+1], M, N + 1) = l‚àó(Y [M], M, N + 1). Substituting the
last representations into (4.151), we complete the proof of (4.147). Relations (4.148)
and (4.149) follow from interchanging the roles of Y [M] and ÀÜY [M] in the proof of
(4.146) and (4.147). Note that they can also be derived independently by using parts
(i) and (iii) of Lemma 4.47.
‚äì‚äî
The result in Theorem 4.56 plays a fundamental role in the relative oscillation
theory of eigenvalue problems in Chap. 6. As a consequence of Theorem 4.56, we
have the following corollary.
Corollary 4.57 The condition
#( ÀÜZ[N+1], Z[M], M, N) ‚â•0
(4.152)
for the relative oscillation number at the right-hand side of (4.146) is necessary and
sufÔ¨Åcient for the inequality
l( ÀÜY [M], M, N + 1) ‚â•l(Y [M], M, N + 1)
(4.153)
concerning the number of (forward) focal points of the principal solutions at k = M
of (SDS) and (4.98), respectively.
Remark 4.58 The above corollary implies the statements of Theorems 5.89
and 5.90 in the next chapter, which are there proved by using a relationship of
the investigated eigenvalue problems to their quadratic energy functionals. Formula
(4.153) together with (4.62) implies the statements of Theorems 5.89 and 5.90 as
follows:

4.3
Comparison Theorems and Its Corollaries
245
(i) The difference between the number of focal points of any conjoined basis of
(SDS) and the number of focal points of the principal solution at k = M of
(4.98) in (M, N + 1] is at most n, proven in [56, Theorem 1.2].
(ii) The number of focal points in (M, N + 1] of any conjoined basis of (4.98) is
greater or equal to the number of focal points of the principal solution of (SDS)
at k = M, proven in [56, Theorem 1.3].
Note that statements (i) and (ii) are simple consequences of (4.153) and (4.60), resp.
of (4.62). Indeed, using (4.60) and
l(Y [M], M, N + 1) = l(Y, M, N + 1) ‚àíŒºYN+1, Y [M]
N+1

we obtain from (4.153) that
l( ÀÜY [M], M, N + 1) ‚àíl(Y, M, N + 1) + Œº(YN+1, Y [M]
N+1) ‚â•0,
or
l(Y, M, N + 1) ‚àíl( ÀÜY [M], M, N + 1) ‚â§Œº(YN+1, Y [M]
N+1) ‚â§n.
The last equality implies the statement (i). As for (ii), from (4.60) it follows that
l( ÀÜY, M, N + 1) ‚â•l( ÀÜY [M], M, N + 1) and then inequality (4.153) proves that
l( ÀÜY, M, N +1) ‚â•l(Y [M], M, N +1) for any conjoined basis ÀÜY of (4.98). Note also
that according to (4.143) the majorant condition (4.134) is the simplest sufÔ¨Åcient
condition for (4.152).
4.3.3
Singular Comparison Theorems
Now we turn our attention to Theorem 4.45 and its corollaries for the singular case
presenting a generalization of Theorem 4.39 for two symplectic systems (SDS) and
(4.98). We introduce the following notation
#( ÀÜZ, Z, M, +‚àû) :=
‚àû

k=M
#k( ÀÜZ, Z)
(4.154)
for the inÔ¨Ånite series of the relative oscillation numbers #k( ÀÜZ, Z) given by (4.109)
and introduce a similar notation for the case of ‚àí‚àû, i.e.,
#( ÀÜZ, Z, ‚àí‚àû, N) =
N

k=‚àí‚àû
#k( ÀÜZ, Z).
(4.155)
The singular version of Theorem 4.39 is the following.

246
4
Oscillation Theory of Symplectic Systems
Theorem 4.59 (Singular Sturmian Comparison Theorem) Assume that the
majorant condition (4.133) holds for all k ‚â•M0 for some M0 ‚ààZ and system
(SDS) is nonoscillatory at ‚àû. Then system (4.98) is nonoscillatory at ‚àûas well,
for arbitrary symplectic fundamental matrices Z and ÀÜZ of (SDS) and (4.98) such
that Y = Z (0 I)T and ÀÜY = ÀÜZ (0 I)T and for arbitrary M ‚ààZ there exist Ô¨Ånite
limits (4.154), (4.87), (4.91), (4.93), which are connected by the identities
#( ÀÜZ, Z, M, +‚àû) = l( ÀÜY, M, +‚àû) ‚àíl(Y, M, +‚àû)
+ Œº+‚àû(Y, ÀÜY ) ‚àíŒº(YM, ÀÜYM),
#(Z, ÀÜZ, M, +‚àû) = l‚àó(Y, M, +‚àû) ‚àíl‚àó( ÀÜY, M, +‚àû)
+ Œº‚àó
+‚àû(Y, ÀÜY ) ‚àíŒº‚àó(YM, ÀÜYM).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(4.156)
Proof If system (SDS) is nonoscillatory at ‚àû, then applying Corollary 4.52 for the
pair of the principal solutions Y [M] and ÀÜY [M] of (SDS) and (4.98) at k = M such
that l(Y [M], M, +‚àû) = 0, we see that l( ÀÜY [M], M, +‚àû) = 0, i.e., system (4.98) is
nonoscillatory as well. By Lemma 4.38, there exist Ô¨Ånite limits (4.87) for arbitrary
conjoined bases Y and ÀÜY of (SDS) and (4.98), and then, by identity (4.129) and by
a similar identity
l‚àó(Y, M, N + 1) ‚àíl‚àó( ÀÜY, M, N + 1) + Œº‚àó(YN+1, ÀÜYN+1) ‚àíŒº‚àó(YM, ÀÜYM)
= #(Z, ÀÜZ, M, N)
(4.157)
derived from (4.127), we see that the relative oscillation numbers are bounded, i.e.,
for some positive C1 and C2, we have
|#( ÀÜZ, Z, M, N)| ‚â§C1,
|#(Z, ÀÜZ, M, N)| ‚â§C2,
i ‚àà{1, 2}.
(4.158)
Moreover, the relative oscillation numbers are monotonic with respect to N ‚â•M0,
by the majorant condition (4.133), which holds for all k ‚â•M0. Then the sum in
(4.154) and the similar deÔ¨Åned sum #(Z, ÀÜZ, M, +‚àû) are Ô¨Ånite, and, by taking the
limits as N ‚Üí+‚àûin (4.129) and (4.157), we prove that there exist Ô¨Ånite limits of
the comparative index (4.91) and (4.93) for conjoined bases Y and ÀÜY of (SDS) and
(4.98). In this way we derive (4.156), which completes the proof.
‚äì‚äî
Remark 4.60 Note that according to Remark 4.46 and Corollary 4.52, systems
(4.112) and (4.114) are nonoscillatory at +‚àû, i.e., condition (4.140) for the mul-
tiplicities of forward focal points of their conjoined bases holds for all sufÔ¨Åciently
large k. Then, by Lemma 4.38 and by Theorem 4.59, the multiplicities of backward
focal points of these conjoined bases also equal zero for all sufÔ¨Åciently large k, i.e.,
Œº(‚ü®Z‚àí1
k
ÀÜZ‚àí1
k ‚ü©, ‚ü®Z‚àí1
k+1 ÀÜZ‚àí1
k+1‚ü©) = 0,
k ‚â•M1.

4.3
Comparison Theorems and Its Corollaries
247
Moreover, by (4.118) in Lemma 4.47, we have the relation
#( ÀÜZ, Z, M, +‚àû) + #(Z, ÀÜZ, M, +‚àû) = lim
k‚Üí‚àûw(Yk, ÀÜYk) ‚àíw(YM, ÀÜYM)
(4.159)
between the Ô¨Ånite limits in (4.156), where limk‚Üí‚àûw(Yk, ÀÜYk) is the Ô¨Ånite limit of
the Wronskian. Note also that under the assumptions of Theorem 4.59 for arbitrary
conjoined bases of systems (SDS) and (4.98), we have the following generalization
of relations (4.95)‚Äì(4.97):
Œº+‚àû(Y, ÀÜY ) + Œº+‚àû( ÀÜY, Y) = lim
k‚Üí‚àûrank w(Yk, ÀÜYk),
(4.160)
Œº‚àó
+‚àû(Y, ÀÜY ) + Œº‚àó
+‚àû( ÀÜY, Y) = lim
k‚Üí‚àûrank w(Yk, ÀÜYk),
(4.161)
Œº+‚àû(Y, ÀÜY ) = lim
k‚Üí‚àûrank ÀÜXk ‚àílim
k‚Üí‚àûrankXk + Œº‚àó
+‚àû( ÀÜY, Y).
(4.162)
Recall that all quantities Œº(Yk, ÀÜYk), Œº‚àó(Yk, ÀÜYk), rank Xk, and rank w(Yk, ÀÜYk) take
their values from the set {0, 1, . . ., n} and then the existence of the limits of these
quantities for k ‚Üí‚àûmeans that they are constant for sufÔ¨Åciently large k.
Obviously, Theorem 4.59 holds when Y and ÀÜY are conjoined bases of the same
system (SDS). In this case Theorem 4.59 turns into Theorem 4.39. For the case of
the nonoscillation at ‚àí‚àû, we have the following analog of Theorem 4.59.
Theorem 4.61 (Singular Sturmian Comparison Theorem) Suppose that the
majorant condition (4.134) holds for all k ‚â§M0 for some M0 ‚ààZ and system
(4.98) is nonoscillatory at ‚àí‚àû. Then system (SDS) is nonoscillatory at ‚àí‚àûas
well, for arbitrary symplectic fundamental matrices Z and ÀÜZ of (SDS) and (4.98)
such that Y = Z (0 I)T and ÀÜY = ÀÜZ (0 I)T and for arbitrary N ‚ààZ there exist
Ô¨Ånite limits (4.155), (4.89), and
Œº‚àí‚àû( ÀÜY, Y) :=
lim
k‚Üí‚àí‚àûŒº( ÀÜYk, Yk),
Œº‚àó
‚àí‚àû( ÀÜY, Y) :=
lim
k‚Üí‚àí‚àûŒº‚àó( ÀÜYk, Yk),
which are connected by the identities
#(Z, ÀÜZ, ‚àí‚àû, N) = l(Y, ‚àí‚àû, N + 1) ‚àíl( ÀÜY, ‚àí‚àû, N + 1)
+ Œº( ÀÜYN+1, YN+1) ‚àíŒº‚àí‚àû( ÀÜY, Y)
#( ÀÜZ, Z, ‚àí‚àû, N) = l‚àó( ÀÜY, ‚àí‚àû, N + 1) ‚àíl‚àó(Y, ‚àí‚àû, N + 1)
+ Œº‚àó( ÀÜYN+1, YN+1) ‚àíŒº‚àó
‚àí‚àû( ÀÜY, Y).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(4.163)
Proof Assuming that system (4.98) is nonoscillatory at ‚àí‚àû, we see that sys-
tem (SDS) is nonoscillatory at ‚àí‚àûas well by Corollary 4.54. Then applying
Lemma 4.38 to the case ‚àí‚àû, we obtain that the limits (4.89) exist for arbitrary
conjoined bases Y and ÀÜY of (SDS) and (4.98). By (4.125) and (4.126), the relative

248
4
Oscillation Theory of Symplectic Systems
oscillation numbers are then bounded, i.e., (4.158) holds as M ‚Üí‚àí‚àû. Using
majorant condition (4.134) for all sufÔ¨Åciently negative k, we see that these numbers
are also monotonic with respect to M ‚â§M0. Then there exist Ô¨Ånite limits (4.155)
and #(Z, ÀÜZ, ‚àí‚àû, N), and we derive (4.163) from (4.125) and (4.126) by analogy
with the proof of Theorem 4.59.
‚äì‚äî
4.4
Focal Points and Symplectic Transformations
In Sect. 2.6 we presented basic elements of the theory of symplectic transformations
of symplectic difference system. Recall that if Rk are symplectic 2n √ó 2n matrices,
then transformation (2.138), i.e., yk = Rkwk, transforms (SDS) into another
symplectic system (2.139), i.e., wk+1 = ÀúSkwk. We rewrite the latter system in the
matrix form as
ÀúYk+1 = ÀúSk ÀúYk,
ÀúSk = R‚àí1
k+1SkRk
(4.164)
for the transformed conjoined basis ÀúY given by
Yk = Rk ÀúYk.
(4.165)
An important question is what are the invariants of transformation (4.165).
In particular, what additional assumptions on Rk imply that (4.165) preserves
oscillatory nature of the transformed systems (e.g., the number of focal points,
deÔ¨Åniteness of the associated quadratic functionals, etc.).
4.4.1
Focal Points and General Symplectic Transformation
We start with the formula relating the number of focal points of a conjoined basis Y
of (SDS) and the conjoined basis ÀúY := R‚àí1Y of (4.164).
Theorem 4.62 Suppose that the conjoined bases Y and ÀúY of (SDS) and of (4.164),
respectively, are related by (4.165). Then we have
m( ÀúYk) ‚àím(Yk) ‚àíŒº ÀúYk, R‚àí1
k (0 I)T  = uk,
(4.166)
where
uk = Œº

R‚àí1
k+1(0 I)T, ÀúSk(0 I)T 
‚àíŒº‚àó
Rk(0 I)T, S‚àí1
k (0 I)T 
(4.167)
= Œº‚àó
S‚àí1
k (0 I)T, Rk(0 I)T 
‚àíŒº
 ÀúSk(0 I)T, R‚àí1
k+1(0 I)T 
,
(4.168)

4.4
Focal Points and Symplectic Transformations
249
and where m(Yk) and m( ÀúYk) are the numbers of focal points of the indicated
conjoined bases in (k, k + 1].
Proof Let Z and ÀúZ = R‚àí1Z be symplectic fundamental matrices of (SDS) and
(4.164), respectively, such that Y = Z (0 I)T and ÀúY = ÀúZ (0 I)T . We introduce the
symplectic difference system for the transformation matrix Rk as
Rk+1 = ÀÜSkRk,
ÀÜSk := Rk+1R‚àí1
k .
(4.169)
Now we apply Theorem 4.45 to systems (SDS) and (4.169) by putting ÀÜZk := Rk
and ÀÜY := Rk (0 I)T and then derive the formula
m( ÀÜYk) ‚àím(Yk) + Œº(Yk, Rk(0 I)T ) = #(Rk, Zk),
(4.170)
where
#(Rk, Zk) = Œº(‚ü®Sk‚ü©, ‚ü®Rk+1R‚àí1
k ‚ü©) ‚àíŒº(‚ü®ÀúZk+1‚ü©, ‚ü®ÀúZk‚ü©).
Evaluating the relative oscillation number #(Rk, Zk) according to Remark 4.46(ii),
we have by (4.113) the formula
#(Rk, Zk) = Œº(‚ü®Sk‚ü©, ‚ü®Rk+1R‚àí1
k ‚ü©) ‚àíŒº(‚ü®ÀúSk‚ü©, ‚ü®I‚ü©) ‚àím( ÀúYk).
Applying Corollary 3.40(iii) to the difference Œº(‚ü®Sk‚ü©, ‚ü®Rk+1R‚àí1
k ‚ü©) ‚àíŒº(‚ü®ÀúSk‚ü©, ‚ü®I‚ü©)
on the right-hand side of the last identity, we derive the representation
#(Rk, Zk) = uk + m‚àó( ÀÜYk) ‚àím( ÀúYk),
(4.171)
where uk is given by (4.167), (4.168) and m‚àó( ÀÜYk) = Œº(R‚àí1
k (0 I)T, R‚àí1
k+1(0 I)T )
is the multiplicity of a backward focal point of ÀÜYk = Rk (0 I)T in [k, k + 1).
Substituting (4.171) into (4.170) and using the connection m‚àó( ÀÜYk) ‚àím( ÀÜYk) =
Œº((0 I)T, Rk (0 I)T ) between the multiplicities of backward and forward focal
points, we derive (4.166) in the form
m( ÀúYk) ‚àím(Yk) + Œº

Yk, Rk (0 I)T 
= uk + Œº

(0 I)T, Rk(0 I)T 
.
(4.172)
The Ô¨Ånal representation (4.166) now follows from the formula
ŒºYk, Rk (0 I)T  = Œº(0 I)T, Rk (0 I)T  ‚àíŒº ÀúYk, R‚àí1
k (0 I)T ,
(4.173)
which is derived according to Theorem 3.5(ix). The proof is complete.
‚äì‚äî
Note that we can interchange systems (SDS) and (4.164). Then Rk and R‚àí1
k
also change their role, and as a result of this approach, we obtain another formulas

250
4
Oscillation Theory of Symplectic Systems
expressing the difference Àúm(k) ‚àím(k). The results are summarized in the next
corollary.
Corollary 4.63 Suppose that the assumptions of Theorem 4.62 hold. Then
m( ÀúYk) ‚àím(Yk) + ŒºYk, Rk (0 I)T  = Àúuk,
(4.174)
where
Àúuk = Œº‚àó
R‚àí1
k (0 I)T, ÀúS‚àí1
k (0 I)T 
‚àíŒº

Rk+1(0 I)T, Sk(0 I)T 
(4.175)
= ŒºSk (0 I)T, Rk+1 (0 I)T  ‚àíŒº‚àó ÀúS‚àí1
k (0 I)T, R‚àí1
k (0 I)T 
(4.176)
and where the sequences Àúuk and uk given by (4.167) are connected by the formula
Àúuk ‚àíuk = 

rank(I 0) Rk (0 I)T 
.
(4.177)
Proof As it was mentioned above, we derive (4.174) and (4.175) just by inter-
changing the roles of (SDS) and (4.164) in (4.166). Formula (4.177) follows from
(4.172) and (4.173), where we evaluate the comparative index Œº

(0 I)T, Rk (0 I)T 
according to Remark 3.4(iii).
‚äì‚äî
Summation of formulas (4.166) and (4.174) from k = M to k = N gives the
fundamental result relating the number of (forward) focal points in (M, N + 1] by
a general symplectic transformation which is formulated in the next theorem.
Theorem 4.64 The numbers l(Y, M, N + 1) and l( ÀúY, M, N + 1) of forward focal
points of Y and ÀúY related by (4.165) in (M, N + 1] satisfy the formulas
l( ÀúY, M, N + 1) ‚àíl(Y, M, N + 1)
‚àíŒº
 ÀúYk, R‚àí1
k (0 I)T 			
N+1
M = S(M, N),
S(M, N) = ÀúS(M, N) ‚àírank

(I 0) Rk (0 I)T 		N+1
M
,
S(M, N) :=
N
k=M
uk,
ÀúS(M, N) :=
N
k=M
Àúuk,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(4.178)
where uk and Àúuk are the sequences given in (4.167) and (4.175).
Remark 4.65
(i) Note that for the partial sums S(M, N) and ÀúS(M, N) in (4.178), we have by
(4.177) the estimate
|S(M, N) ‚àíÀúS(M, N)|
‚â§max
!
rank(I 0)T RN+1 (0 I)T, rank (I 0)T RM (0 I)T "
‚â§n.
(4.179)

4.4
Focal Points and Symplectic Transformations
251
In particular, S(M, N) = ÀúS(M, N) for the case when the transformation matrix
Rk is constant, i.e., Rk ‚â°R. It follows from (4.179) that either the partial
sums S(M, N) and ÀúS(M, N) are simultaneously bounded for a Ô¨Åxed M ‚ààZ as
N ‚Üí‚àû, i.e., the inequalities
|S(M, N)| ‚â§C(M),
| ÀúS(M, N)| ‚â§ÀúC(M),
N ‚â•M,
(4.180)
hold for some positive constants C(M) and ÀúC(M), or these sums are simulta-
neously unbounded.
(ii) The left-hand side of (4.166) can be written in the equivalent form
m( ÀúYk) ‚àím(Yk) ‚àíŒº
 ÀúYk, R‚àí1
k
(0 I)T 
= m‚àó( ÀúYk) ‚àím‚àó(Yk) ‚àíŒº‚àó
Yk, Rk (0 I)T 
,
(4.181)
where m‚àó(Yk) and m‚àó( ÀúYk) are the multiplicities of backward focal points of
Y and ÀúY in [k, k + 1). The proof of (4.181) is based on Proposition 4.4(vi)
and formulas (4.173), (3.34). Identity (4.181) implies that the numbers of focal
points l‚àó(Y, M, N + 1) and l‚àó( ÀúY, M, N + 1) can be expressed by a formula
similar to (4.178), i.e., by
l‚àó( ÀúY, M, N + 1) ‚àíl‚àó(Y, M, N + 1) ‚àíŒº‚àó
Yk, Rk (0 I)T 			
N+1
M
= S(M, N).
(4.182)
4.4.2
Focal Points and Special Symplectic Transformations
We consider now formula (4.166) in the particular case when the transformation
matrix is Rk = J .
Corollary 4.66 When Rk ‚â°J , formulas (4.166) and (4.167) read as
m(J T Yk) ‚àím(Yk) ‚àíŒº

J T Yk, J T (0 I)T 
= ind (‚àíAT
k Ck) ‚àíind (AkBT
k ),
ŒºJ T Yk, J T (0 I)T  = rank(I ‚àíUkU‚Ä†
k ) + ind (XT
k Uk),
‚é´
‚é™‚é¨
‚é™‚é≠
(4.183)
and formulas (4.174) and (4.175) can be written as
m(J T Yk) ‚àím(k) + Œº

Yk, J (0 I)T 
= ind (‚àíCT
k Dk) ‚àíind (BT
k Dk),
Œº

Yk, J (0 I)T 
= rank(I ‚àíXkX‚Ä†
k) + ind (‚àíXT
k Uk).

(4.184)

252
4
Oscillation Theory of Symplectic Systems
and
uk = ind (‚àíAT
k Ck)‚àíind (AkBT
k ) = ind (‚àíCT
k Dk)‚àíind (BT
k Dk) = Àúuk.
(4.185)
Proof In the particular case Rk = J , we obtain from (4.167) the formulas
Œº

R‚àí1
k+1(0 I)T, ÀúSk(0 I)T 
= Œº

(‚àíI 0)T , J T SkJ (0 I)T 
= Œº2

(‚àíI 0)T , (‚àíCT
k , AT
k )T 
= ind (‚àíAT
k Ck),
Œº‚àó
Rk(0 I)T, S‚àí1
k (0 I)T 
= Œº‚àó
(I 0)T , (‚àíBk, Ak)T 
= Œº‚àó
2
(I 0)T , (‚àíBk, Ak)T  = ind (AkBT
k ).
Further, (4.175) implies
Œº

Rk+1(0 I)T, Sk(0 I)T 
= Œº

(I 0)T , Sk(0 I)T 
= Œº2

(I 0)T , (BT
k , DT
k )T 
= ind (BT
k Dk),
Œº‚àó
R‚àí1
k (0 I)T, ÀúS‚àí1
k (0 I)T 
= Œº‚àó
(‚àíI 0)T , (Ck, Dk)T 
= ind (‚àíCkDT
k ),
and
Œº

R‚àí1
k Yk, R‚àí1
k (0 I)T 
= Œº

J T Yk, (‚àíI 0)T 
= rank (I ‚àíUkU‚Ä†
k ) + ind (XT
k Uk),
Œº

Yk, Rk(0 I)T 
= Œº(Yk, (0 I)T ) = rank(I ‚àíXkX‚Ä†
k) + ind (‚àíXT
k Uk),
where in all previous computations we have used Remark 3.4(iv) and the deÔ¨Ånitions
of the comparative index and the dual comparative index. Relation (4.185) follows
from formula (4.177) for the case when the transformation matrix does not depend
on k.
‚äì‚äî
Formula (4.166) also implies that multiplicity of a focal point is preserved under
transformation with lower block-triangular symplectic matrix, as it is formulated in
the next corollary. This is the problem that we have already mentioned in Sect. 2.6.
Corollary 4.67 Let Rk = Lk, where Lk is a symplectic lower block-triangular
matrix. Then for any conjoined basis Y of (SDS), we have m(Yk) = m(L‚àí1
k Yk).
Proof In our particular case Œº
 ÀúYk, L‚àí1
k (0 I)T 
= 0, consequently, the left-hand
side of (4.166) takes the form m( ÀúYk) ‚àím(Yk). Further, using deÔ¨Ånition of uk in
Theorem 4.62 by (4.168), we obtain
Œº‚àóS‚àí1
k (0 I)T, Lk(0 I)T  = Œº ÀúSk(0 I)T, L‚àí1
k+1(0 I)T  = 0,
which follows directly from Remark 3.4(ii). Consequently, the right-hand side of
(4.166) equals zero.
‚äì‚äî

4.4
Focal Points and Symplectic Transformations
253
4.4.3
Generalized Reciprocity Principle
Recall from DeÔ¨Ånition 4.37 that symplectic system (SDS) is nonoscillatory (at ‚àû)
if there exists M ‚ààN such that the principal solution Y [M] of (SDS) at k = M has
no forward focal point in (M, ‚àû). In the opposite case, (SDS) is oscillatory (at ‚àû).
The inequality
		l(Y, M, N + 1) ‚àíl(Y [M], M, N + 1)
		 ‚â§n,
N ‚â•M,
from Corollary 4.25 implies that one can take any conjoined basis Y in the
deÔ¨Ånition of (non)oscillation of (SDS) at ‚àûinstead of the principal solution Y [M].
In the following result, we present the most general statement in this context. It is
a consequence of Theorem 4.64.
Theorem 4.68 (Generalized Reciprocity Principle for Symplectic Systems) Let
us deÔ¨Åne the sequences S(M, N) and ÀúS(M, N) by (4.178).
(i) Assume that at least one of the sequences S(M, N) or ÀúS(M, N) is bounded as
N ‚Üí‚àû, i.e., there exist constants C(M) or ÀúC(M) such that
|S(M, N)| ‚â§C(M)
or
| ÀúS(M, N)| ‚â§ÀúC(M),
N ‚â•M.
(4.186)
Then systems (SDS) and (4.164) have the same oscillatory nature at ‚àû, i.e.,
they are oscillatory or nonoscillatory at ‚àûat the same time.
(ii) If (SDS) and (4.164) are simultaneously nonoscillatory at ‚àû, then the
sequences S(M, N) and ÀúS(M, N) are bounded as N ‚Üí‚àû.
(iii) If at least one of the sequences S(M, N) and ÀúS(M, N) is unbounded, then at
least one of systems (SDS) and (4.164) is oscillatory at ‚àû.
Proof Recall that the sequences S(M, N) and ÀúS(M, N) are both bounded or both
unbounded (see Remark 4.65).
(i) Condition (4.186), formula (4.178), and property (vii) of Theorem 3.5 imply
that
‚àíC(M) ‚â§l( ÀúY, M, N + 1) ‚àíl(Y, M, N + 1) ‚àíŒº( ÀúYk, R‚àí1
k )
		N+1
M
= S(M, N) ‚â§C(M),
‚àíC(M) ‚àín ‚â§‚àíC(M) ‚àíŒº( ÀúYM, R‚àí1
M ) ‚â§l( ÀúY, M, N + 1) ‚àíl(Y, M, N + 1)
‚â§C(M) + Œº( ÀúYN+1, R‚àí1
N+1) ‚â§C(M) + n.
Consequently,
		l( ÀúY, M, N +1)‚àíl(Y, M, N +1)| ‚â§C(M)+n
for all N ‚â•M.
(4.187)

254
4
Oscillation Theory of Symplectic Systems
Obviously, if we replace the integer M by M1, the last estimate remains to
hold with some other constant C(M1). Suppose that (SDS) is nonoscillatory
at ‚àû, i.e., for any conjoined basis Y, there exists M1 (depending on the
conjoined basis Y) such that l(Y, M1, N) = 0 for every N > M1. Then
from (4.187) we obtain that l(R‚àí1Y, M, N + 1) is bounded as N ‚Üí‚àû.
Since l(R‚àí1Y, M1, N + 1) is the partial sum of a series formed by integers
or zeros, then its boundedness is possible only if l(Y, M2, N +1) = 0 for some
M2 > M1 and every N ‚â•M2. Hence, (4.164) is nonoscillatory at ‚àûas well.
Quite similarly we prove that the nonoscillation of (4.164) at ‚àûimplies the
nonoscillation of (SDS) at ‚àû.
(ii) If both systems (SDS) and (4.164) are nonoscillatory at ‚àû, then there exists
M1 (sufÔ¨Åciently large) such that l(Y, M1, N +1) = l( ÀúY, M1, N +1) = 0. Then
by (4.178) we have |S(M1, N)| ‚â§n, because of property (vii) of Theorem 3.5.
Hence, by (4.179) the sequence ÀúS(M1, N) is also bounded.
(iii) This statement follows immediately from part (ii).
‚äì‚äî
The result in Theorem 4.68 implies that only the case of unboundedness
of sequences S(M, N) and ÀúS(M, N) (case (iii) in the previous theorem) and
the oscillation of one of systems (SDS) and (4.164) at ‚àûneeds an additional
investigation to answer the question about the (non)oscillation of the other system at
‚àû. In all the remaining cases and under the additional assumption on the oscillatory
nature of one of systems (SDS) or (4.164) at ‚àû, Theorem 4.68 provides the answer
about the (non)oscillation of the other one at ‚àû.
A simple sufÔ¨Åcient condition for the boundedness of S(M, N) is given in the
next theorem.
Theorem 4.69 Systems (SDS) and (4.164) oscillate or do not oscillate simultane-
ously at ‚àû, if at least one of the sequences uk or Àúuk given by (4.167), (4.168), and
(4.175), (4.176) tends to zero as k ‚Üí‚àû, i.e., there exists M > 0 such that for all
k ‚â•M we have
uk = 0
‚áî
ŒºR‚àí1
k+1(0 I)T, ÀúSk(0 I)T  = Œº‚àóRk(0 I)T, S‚àí1
k (0 I)T 
(4.188)
or
Àúuk = 0
‚áî
Œº‚àó(R‚àí1
k (0 I)T, ÀúS‚àí1
k (0 I)T ) = Œº(Rk+1(0 I)T, Sk(0 I)T ).
(4.189)
Proof Under assumption (4.188) we have S(M, N) = 0 for all M ‚â•N, and then
the Ô¨Årst statement follows directly from Theorem 4.68(i). Similarly, (4.189) implies
ÀúS(M, N) = 0 for all M ‚â•N, and then, again by Theorem 4.68(i) both systems
oscillate or do not oscillate simultaneously at ‚àû.
‚äì‚äî
In particular, for Rk = J T , we have the following corollary to Theorem 4.69.

4.4
Focal Points and Symplectic Transformations
255
Corollary 4.70 Systems (SDS) and (4.164) oscillate or do not oscillate simultane-
ously at ‚àûif there exists M > 0 such that
ind (‚àíAT
k Ck) = ind (AkBT
k ),
k ‚â•M,
(4.190)
and (4.190) is equivalent to
ind (‚àíCkDT
k ) = ind (BT
k Dk),
k ‚â•M.
(4.191)
Remark 4.71
(i) Note that for the case when rank[(I 0) Rk(0 I)T ] is constant for k ‚â•M,
conditions (4.188) and (4.189) are equivalent according to (4.177). In particular,
rank[(I 0) Rk(0 I)T ] = n for the case Rk = J T (see Corollary 4.70).
(ii) Conditions (4.188), (4.189) will be satisÔ¨Åed if we assume for all k ‚â•M
Œº(R‚àí1
k+1(0 I)T, ÀúSk(0 I)T ) = Œº‚àó(Rk(0 I)T, S‚àí1
k (0 I)T ) = 0,
(4.192)
or
Œº‚àó(R‚àí1
k (0 I)T, ÀúS‚àí1
k (0 I)T ) = Œº(Rk+1(0 I)T, Sk(0 I)T ) = 0.
(4.193)
In particular, for the case Rk = J T by (4.190), (4.191), we have that (4.192)
are equivalent to the conditions
AT
k Ck ‚â§0,
AkBT
k ‚â•0,
k ‚â•M,
(4.194)
while (4.193) implies
CkDT
k ‚â§0,
BT
k Dk ‚â•0.
(4.195)
Note that in some special cases, to verify (4.193) (or (4.195)) may be easier than
to verify (4.192) (or (4.194)). An illustrating example supporting this idea is given
in Sect. 4.4.4 (see Example 4.73).
4.4.4
Applications and Examples
In this subsection we present several examples, which illustrate the applicability of
the above results.
Example 4.72 Let Sk =  1 0
3 1
 be the coefÔ¨Åcient matrix of a (nonoscillatory)
symplectic system (SDS) at ‚àû. The transformation (4.165) with the matrix Rk = J
satisÔ¨Åes condition (iii) of Theorem 4.68, since S(M, N) = N
k=M 1 = N ‚àíM + 1

256
4
Oscillation Theory of Symplectic Systems
is unbounded. Then, by (iii) of Theorem 4.68, the transformed system (4.164) with
the matrix
ÀúS = J T SJ =
1 ‚àí3
0 1

is oscillatory at ‚àû. Indeed, the conjoined basis ÀúYk = (1 0)T of this system has
exactly
l( ÀúY, M, N + 1) =
N

k=M
Œº

(1 0)T , (‚àí3 1)T 
= N ‚àíM + 1
forward focal points in the interval (M, N + 1].
Example 4.73 The symplectic difference system corresponding to the equation
determining the Fibonacci numbers xk+1 = xk+1 + xk, which can be written in
the self-adjoint form as 

(‚àí1)kxk

+ (‚àí1)k+1 = 0, has the coefÔ¨Åcient matrix
Sk =

1
(‚àí1)k
(‚àí1)k+1
0

.
This system is oscillatory at ‚àû, since the Ô¨Årst component x of the principal solution
at k = 0 is x0 = 0, x1 = 1, and xk+2 = xk+1 + xk for k ‚â•0. Consequently, we
have m(k) = m2(k) = ind (‚àí1)k for all k ‚â•1. Obviously, condition (4.194) is not
satisÔ¨Åed, but condition (4.190) is satisÔ¨Åed for all k. Consequently, system (4.164)
with the transformation matrix Rk = J is also oscillatory at ‚àû. Remark also that
this system satisÔ¨Åes (4.195), since Dk = 0. Then, for the given example to verify,
(4.195) is easier than to verify (4.190).
Example 4.74 Here we present an example, in which condition (4.190) is not
satisÔ¨Åed, but condition (4.186) holds. Consider the nonoscillatory system with the
coefÔ¨Åcient matrix
Sk =

1
0
‚àí(‚àí2)k+1 1
 1 1
0 1
 
1
0
(‚àí2)k 1

=

1 + (‚àí2)k
1
(‚àí2)k(3 ‚àí(‚àí2)k+1) 1 ‚àí(‚àí2)k+1

.
(4.196)
This system is nonoscillatory at ‚àû, since it is constructed from the nonoscillatory
symplectic system Yk+1 =
 1 1
0 1

Yk by a symplectic transformation with the lower
triangular transformation matrix Rk :=

1
0
‚àí(‚àí2)k 1

. Note that the latter system is
a rewritten Sturm-Liouville difference equation 2xk = 0. Concerning the matrix

4.5
Notes and References
257
Sk deÔ¨Åned in (4.196), we have
ind (BkAT
k ) = ind [1 + (‚àí2)k] =
 0, k = 2m,
1, k = 2m + 1,
and
ind (‚àíAT
k Ck) = ind [(1 + (‚àí2)k)(‚àí2)k(‚àí3 + (‚àí2)k+1)] =
 1, k = 2m,
0, k = 2m + 1.
Consequently, the sequence S(M, N) = N
k=M(‚àí1)k is bounded, and by Theo-
rem 4.178 the system with the matrix J T SkJ is also nonoscillatory at ‚àû.
Example 4.75 Consider the coefÔ¨Åcient matrix
Sk =

1
0
‚àí(‚àí1)k+1 1
 1 1
0 1
 
1
0
(‚àí1)k 1

=

1 + (‚àí1)k
1
(‚àí1)k(2 + (‚àí1)k) 1 + (‚àí1)k

.
(4.197)
The system with the matrix (4.197) is again nonoscillatory at ‚àû, by using the same
arguments as in Example 4.74. It is not difÔ¨Åcult to verify that
ind (‚àíAT
k Ck) = ind [(1 + (‚àí1)k)(‚àí1)k+1(2 + (‚àí1)k)] =
1, k = 2m,
0, k = 2k + 1,
and ind (BkAT
k ) = ind [1 + (‚àí1)k] = 0. Hence, S(M, N) is unbounded and
therefore the system with the matrix J T SkJ is oscillatory at ‚àû.
4.5
Notes and References
As it was mentioned above, the results of this chapter present discrete analogs of
well-known classical oscillation results for linear Hamiltonian differential systems
(1.103). The basic concept in both of the theories is the multiplicity of focal points of
conjoined bases of (1.103) and (SDS). Point out that this notion for the continuous
case is based on two assumptions. The Ô¨Årst one is the Legendre condition (1.111),
while the second one (the identical normality assumption) is completely omitted in
the modern consideration of oscillation theory of (1.103); see, for example, [127,
207, 283, 289, 321]). The notion of the multiplicities of focal points of conjoined
bases of (SDS) and (1.103) (without the controllability assumption) was for the
Ô¨Årst time introduced by W. Kratz in his two outstanding papers [208] and [207].
In Sect. 4.1.1 we used the deÔ¨Ånition of the multiplicity (see DeÔ¨Ånition 4.3) and the
main terminology concerning the numbers m1 and m2 from [208].

258
4
Oscillation Theory of Symplectic Systems
The notion of a backward focal point, or more precisely the notion of ‚Äúno
backward focal points‚Äù in [k, k + 1), for conjoined bases of (SDS) was introduced
in [45]. The deÔ¨Ånition of the multiplicities of backward focal points (see DeÔ¨Å-
nition 4.3) was introduced in [87] and [115], [119]. Properties (i), (ii), and (iv)
of Proposition 4.4 concerning the multiplicities of forward focal points and the
estimate m(k) ‚â§rank Bk from Proposition 4.4(v) were for the Ô¨Årst time proved in
[208, Lemma 1]. Property (vi) in Proposition 4.4, which connects the multiplicities
of forward and backward focal points, was derived in and [115] and [119]. Point out
that a similar relation for the multiplicities of right (backward) and left (forward)
proper focal points holds for the continuous case as well (see the resent result [289,
Theorem 5.1]). The main difference in the proofs of these results is based on the
absence of the Legendre condition (1.111) in the discrete case. Because of this, the
leading role in the proof of (4.9) is played by relation (4.8). On the other hand, in
the continuous case, we have that (4.8) is trivially satisÔ¨Åed because of the Legendre
condition; see [127, Lemma 3.2], where it is proven that the second component of
the comparative index associated with the multiplicity of proper focal points is zero.
Finally, we note that the main result in Corollary 4.6 coincides with [115, formula
(3.12)].
The connection of the comparative index with the multiplicities of focal points
in Lemma 4.7 was established in [114, Lemmas 2.2 and 2.3] and then presented
together with Lemma 4.8 in [115, Lemmas 3.1 and 3.2]. Among other important
consequences, this lemma states the equivalences of different deÔ¨Ånitions of the
multiplicity of forward focal points, in particular, the equivalences of DeÔ¨Ånitions 4.1
and 4.9; see also [193]. The equivalence with DeÔ¨Ånition 4.9 stated in Proposi-
tion 4.13 is from [121].
Regarding Sect. 4.2.1, the result in Theorem 4.16 is proven in [101, Theorem 1].
An analog of Theorem 4.16 concerning the multiplicities of backward focal points
was proven in [87, Theorem 1]. The main results of Sect. 4.2.2 were derived
in [114] and [115]. The reÔ¨Ånement of the discrete oscillation theory offered by
the comparative index theory is based on the possibility to present the relations
between focal points in the form of explicit equalities instead of inequalities.
Such a possibility is based on the algebraic properties of the comparative index,
in particular, on the connection between the comparative index and the negative
inertia of some symmetric matrix (see Sect. 3.2.1). Sect. 4.2.2 presents the Ô¨Årst
results in this direction. The result in Theorem 4.20 (see [115, Theorem 1.1])
can be viewed as a discrete version of Theorem 1.50 (see [205, Theorem 5.2.1]),
which was recently generalized to the abnormal differential Hamiltonian systems
in [127, Theorem 2.3] and [289, Theorem 4.1] via the comparative index approach.
Similarly, Theorem 4.21 for the multiplicity of backward focal points (see [115,
formula (3.4)]) is a discrete counterpart of the same result for the right proper
focal points in [289, Theorem 4.1]. The result in Theorem 4.23 and estimate
(4.46) in Corollary 4.25 concerning rankw(Y, ÀÜY ) are from [115, Corollary 3.1].
Formulas (4.41) and (4.45) were derived in the continuous time settings in [289,
Proposition 4.2] via the comparative index approach. The new estimates technique
for the numbers of focal points based on the upper bounds for the comparative index

4.5
Notes and References
259
in part (vii) of Theorem 3.5 was for the Ô¨Årst time applied to discrete eigenvalue
problems in [123, Corollary 7]. This new technique is illustrated by the results
of Corollaries 4.25, 4.26, and 4.27. Some parts of these results are formulated by
analogy with [289, Theorem 5.2 and Corollaries 5.8 and 5.10]. Recall from Sect. 2.7
that Corollary 2.56 was proven in [173] but then again in [115, Theorem 1.2] by
the comparative index approach. The result in Corollary 4.30 follows from [94,
Corollary 3.6] applied to the case Sk ‚â°ÀÜSk.
The question about a possible coincidence of the numbers of forward and
backward focal points of the principal solutions of (SDS) was Ô¨Årst posed as an open
problem in [101, Section 4]. The main result of Sect. 4.2.3 (see Theorem 4.34)
solves this problem, and it is proven in [115, Lemma 3.3]. Here we present another
proof of this result, which follows from Lemma 4.33. Based on the latter lemma,
on property (vii) of Theorem 3.5 and Remark 3.10, we present some estimates (see
Lemma 4.36 and Theorem 4.32) from [289] in the more complete and improved
form.
The consideration in Sect. 4.2.4 is based on results of [94] applied to the case
Sk ‚â°ÀÜSk. Further singular Sturmian separation theorems involving the (minimal)
recessive solution of (SDS) at ‚àûwere derived in [292]; see Sect. 6.4. The results of
Sect. 4.3.1 are from the paper [117] and from the monograph [121]. The main result
(Theorem 4.45) was proven for the Ô¨Årst time in [117, Theorem 2.1]; the notion
of the relative oscillation numbers (in slightly different notation) was introduced
in [124, Theorem 2.1] and then in [94, DeÔ¨Ånition 3.2]. The comparison results
in Theorem 4.45 in terms of the relative oscillation numbers can be viewed as
a discrete generalization of Theorem 1.49 (proved in [205, Theorem 7.3.1]), because
we now deal with explicit equalities for the multiplicities of focal points instead
of inequalities. Point out that a generalization of [205, Theorem 7.3.1] to abnormal
Hamiltonian differential systems (1.103) was recently proven in [127, Theorem 2.2],
which also deals with equalities for the multiplicities of proper focal points. In both
cases (discrete and continuous), the difference between inequalities and equalities
is based on incorporating the focal points of conjoined bases of some transformed
‚ÄúWronskian‚Äù system associated with two discrete symplectic (or two differential
Hamiltonian) systems. From this point of view, the main results of this section may
also belong to the relative oscillation theory for discrete symplectic systems. For
controllable linear Hamiltonian differential systems, the relative oscillation theory is
developed in the recent paper [92]. For the second-order Sturm-Liouville difference
equations (which are a special case of (SDS)), the renormalized and more general
relative oscillation theory is established in [22, 314]. The results in Theorems 4.50
and 4.53 were proven in [121]; a special case of these theorems (Corollaries 4.52
and 4.54) is presented in [94, Corollaries 3.4 and 3.6]; see also [117, Corollaries 2.1
and 2.2].
The main result of Sect. 4.3.2 (Theorem 4.56) was proven in [117, Corol-
lary 2.4]. The results of Sect. 4.3.3 are from [94, Section 4]. The statement in
Lemma 4.55 is from [121]. Together with Theorem 4.56, it opened the door to
the relative oscillation theory for symplectic eigenvalue problems developed in
[118, 120, 123, 124]; see also Sect. 6.1. The considerations in Sect. 4.4 about the

260
4
Oscillation Theory of Symplectic Systems
effect of symplectic transformations on multiplicities of focal points are based on
the papers [116, 117, 126]. The results in Theorem 4.62 and Corollary 4.66 (in
a slightly different notation) and a part of Theorem 4.64 associated with uk were
proven in [116, Lemma 3.1, Corollary 3.2, Theorem 3.3]. The reciprocity principle
in the restricted form based on assumptions (4.192) and (4.194) was proven in
[116, Theorem 3.5 and Corollary 3.6]. Then the same result was proven under the
more general assumptions (4.188) and (4.190) in [117, Theorem 3.2] for the case
of constant transformation matrices. The generalized reciprocity principle in the
form presented in this book was proven in [121, 126]. Let us note that condition
(4.194) covers as a particular case the reciprocity principle for linear Hamiltonian
difference systems in [45, Theorem 3], where this principle is formulated for
Hamiltonian systems (2.15) with Ak = 0, Ck ‚â§0, Bk ‚â•0 and under the identical
normality assumption. The proof of this special statement is based on properties
of the recessive solution of (2.15) at ‚àû. Similarly, conditions (4.192) cover the
results of [98, Theorem 3.4]. In particular, there is an interesting interpretation
of the numbers uk given by (4.167) under the assumptions of [98, Theorem 3.4]
(see also [116, Remark (ii)]). It is necessary to point out that the recently proven
continuous analogs of Theorems 4.62 and 4.64 were derived for abnormal linear
differential Hamiltonian systems in [129],[130], [131] based on the comparative
index approach.
Important applications of Theorem 4.62 to the special trigonometric transforma-
tions
Rk =
 cos(Œ±k) I
sin(Œ±k) I
‚àísin(Œ±k) I cos(Œ±k) I

can be found in [96, 122].

Chapter 5
Discrete Symplectic Eigenvalue Problems
In this chapter we investigate eigenvalue problems associated with symplectic
system (SDS), where the coefÔ¨Åcient matrix depends on a spectral parameter, i.e.,
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N]Z.
(5.1)
Here Œª ‚ààR is the eigenvalue parameter, and the 2n √ó 2n matrix Sk(Œª) is
symplectic for every Œª ‚ààR. First we study in Sect. 5.1 problem (5.1) with a general
nonlinear dependence on Œª and with the coefÔ¨Åcient matrix Bk(Œª) having constant
rank. Here we assume a natural monotonicity assumption on the behavior of the
coefÔ¨Åcient matrix Sk(Œª) in Œª. This type of monotonicity condition was discussed
in details in Sect. 1.6.4. In Sect. 5.2, we present transformations between various
boundary conditions for system (5.1), in particular a transformation of separated
endpoints into Dirichlet boundary conditions and a transformation of general joint
boundary conditions into separated ones. These boundary conditions may depend
nonlinearly on the spectral parameter Œª (under a certain monotonicity condition). In
Sects. 5.3‚Äì5.5, we proceed with the study of problem (5.1) with a special linear
dependence on Œª, as these systems have important applications in the Sturmian
theory for system (SDS). Finally, in Sect. 5.6, we also present some extensions
of the oscillation theorems from Sect. 5.1 to symplectic systems, whose coefÔ¨Åcient
Bk(Œª) has nonconstant rank.
5.1
Nonlinear Dependence on Spectral Parameter
In this section we consider a general eigenvalue problem with symplectic difference
system depending nonlinearly on the spectral parameter Œª. We develop the notions
of (Ô¨Ånite) eigenvalues and (Ô¨Ånite) eigenfunctions and their multiplicities and prove
the corresponding oscillation theorem for Dirichlet boundary conditions. Consider
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7_5
261

262
5
Discrete Symplectic Eigenvalue Problems
the system (5.1) in the form
xk+1(Œª) = Ak(Œª) xk(Œª) + Bk(Œª) uk(Œª),
uk+1(Œª) = Ck(Œª) xk(Œª) + Dk(Œª) uk(Œª),

k ‚àà[0, N]Z,
(SDSŒª)
and the corresponding eigenvalue problem with the Dirichlet boundary conditions
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N]Z,
Œª ‚ààR,
x0(Œª) = 0 = xN+1(Œª),
(E)
where y = (x, u). The coefÔ¨Åcient matrix Sk(Œª) of system (SDSŒª) is assumed to be
symplectic, i.e., for all k ‚àà[0, N]Z and Œª ‚ààR
ST
k (Œª) J Sk(Œª) = J ,
Sk(Œª) :=
Ak(Œª) Bk(Œª)
Ck(Œª) Dk(Œª)

,
J :=
 0 I
‚àíI 0

.
(5.2)
The same property is then satisÔ¨Åed by the fundamental matrix of system (SDSŒª). In
addition, we assume that the matrix Sk(Œª) piecewise continuously differentiable,
i.e., it is continuous on R and the derivative ÀôSk(Œª) :=
d
dŒªSk(Œª) is piecewise
continuous in the parameter Œª ‚ààR for all k ‚àà[0, N]Z. Given the above symplectic
matrix Sk(Œª), we consider the monotonicity assumption
(Sk(Œª)) = k(Œª) := J ÀôSk(Œª) J ST
k (Œª) J ‚â•0,
k ‚àà[0, N]Z,
Œª ‚ààR.
(5.3)
Recall that the matrix k(Œª) = (Sk(Œª)) is symmetric for any k ‚àà[0, N]Z and
Œª ‚ààR (see Proposition 1.75).
5.1.1
Finite Eigenvalues
In this subsection, we derive some monotonicity results based on the assump-
tion (5.3), which lead to the deÔ¨Ånition of Ô¨Ånite eigenvalues for problem (E). Recall
that in Sect. 1.6.4 we proved important properties of (Sk(Œª)) and corollaries
to (5.3) applied to arbitrary piecewise continuously differentiable symplectic matrix
W(Œª). Putting W(Œª) := Sk(Œª) in Theorems 1.79, 1.81, 1.82 and in Corollary 1.83,
we derive the following important properties of the symplectic coefÔ¨Åcient matrix
Sk(Œª) under assumption (5.3).

5.1
Nonlinear Dependence on Spectral Parameter
263
Theorem 5.1 Assume (5.3) for Sk(Œª) given by (5.2). Then for any k ‚àà[0, N]Z, the
following assertions hold:
(i) The set Ker Bk(Œª) is piecewise constant in Œª, i.e., for any Œª0 ‚ààR, there exists
Œ¥ > 0 such that
Ker Bk(Œª) ‚â°Ker Bk(Œª‚àí
0 ) ‚äÜKer Bk(Œª0)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.4)
Ker Bk(Œª) ‚â°Ker Bk(Œª+
0 ) ‚äÜKer Bk(Œª0)
for all Œª ‚àà(Œª0, Œª0 + Œ¥).
(5.5)
(ii) The set Im Bk(Œª) is piecewise constant in Œª, i.e., for any Œª0 ‚ààR, there exists
Œ¥ > 0 such that
Im Bk(Œª0)‚äÜIm Bk(Œª) ‚â°Im Bk(Œª‚àí
0 )
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.6)
Im Bk(Œª0)‚äÜIm Bk(Œª) ‚â°Im Bk(Œª+
0 )
for all Œª ‚àà(Œª0, Œª0 + Œ¥).
(5.7)
(iii) The following three conditions are equivalent:
rank Bk(Œª) is constant for Œª ‚ààR,
(5.8)
the set Ker Bk(Œª) is constant for Œª ‚ààR,
(5.9)
the set Im Bk(Œª) is constant for Œª ‚ààR.
(5.10)
(iv) The matrices Bk(Œª) B‚Ä†
k(Œª) and B‚Ä†
k(Œª) Bk(Œª) are piecewise constant in Œª.
Next we show that similar properties hold also for arbitrary symplectic fun-
damental matrix Zk(Œª) of (SDSŒª) such that Z0(Œª) is piecewise continuously
differentiable and (Z0(Œª) ‚â•0 for Œª ‚ààR. In this case, since the matrix Sk(Œª)
is piecewise continuously differentiable with respect to Œª, it follows that the funda-
mental matrix Zk(Œª) is piecewise continuously differentiable for all k ‚àà[0, N +1]Z.
As a corollary to the multiplicative property (1.195) in Proposition 1.76(i), we have
the following important result.
Proposition 5.2 Assume that Zk(Œª) is a symplectic fundamental matrix of (5.3)
such that Z0(Œª) is piecewise continuously differentiable. Then under the assumption
(Zk(Œª)) ‚â•0,
Œª ‚ààR
(5.11)
for the index k = 0, we have that (5.11) holds for any k ‚àà[0, N + 1]Z.
Proof Applying Proposition 1.76(i), we have
(Zk+1(Œª)) = (Sk(Œª) Zk(Œª)) = ST ‚àí1
k
(Œª) (Zk(Œª)) S‚àí1
k (Œª) + (Sk(Œª)),
or by Proposition 1.76(ii)
(Z‚àí1
k (Œª)) = ‚àíZT
k+1(Œª) (Sk(Œª) Zk+1(Œª)).

264
5
Discrete Symplectic Eigenvalue Problems
Then we derive
ZT
k+1(Œª) (Zk+1(Œª)) Zk+1(Œª)
= ZT
0 (Œª) (Z0(Œª)) Z0(Œª) +
k

i=0
ZT
i+1(Œª) (Si(Œª)) Zi+1(Œª),
(5.12)
and therefore (5.11) holds for any k ‚àà[0, N + 1]Z.
‚äì‚äî
Putting W(Œª) := Zk(Œª) for k ‚àà[0, N + 1]Z in Theorems 1.79, 1.81, 1.82 and in
Corollary 1.83, we now formulate the most important result of this section.
Theorem 5.3 Assume (5.3) and (Z0(Œª)) ‚â•0 for Œª ‚ààR for a symplectic
fundamental matrix Zk(Œª) of (SDSŒª) in the form
Zk(Œª) =
 ÀÜYk(Œª) Yk(Œª)

=
 ÀÜXk(Œª) Xk(Œª)
ÀÜUk(Œª) Uk(Œª)

.
Then for every k ‚àà[0, N + 1]Z, we have
(i) The set Ker Xk(Œª) is piecewise constant in Œª, i.e., for any Œª0 ‚ààR, there exists
Œ¥ > 0 such that
Ker Xk(Œª) ‚â°Ker Xk(Œª‚àí
0 ) ‚äÜKer Xk(Œª0)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.13)
Ker Xk(Œª) ‚â°Ker Xk(Œª+
0 ) ‚äÜKer Xk(Œª0)
for all Œª ‚àà(Œª0, Œª0 + Œ¥).
(5.14)
(ii) The set Im Xk(Œª) is piecewise constant in Œª, i.e., for any Œª0 ‚ààR, there exists
Œ¥ > 0 such that
Im Xk(Œª0)‚äÜIm Xk(Œª) ‚â°Im Xk(Œª‚àí
0 )
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.15)
Im Xk(Œª0)‚äÜIm Xk(Œª) ‚â°Im Xk(Œª+
0 )
for all Œª ‚àà(Œª0, Œª0 + Œ¥).
(5.16)
(iii) The following three conditions are equivalent:
rankXk(Œª) is constant for Œª ‚ààR,
(5.17)
the set Ker Xk(Œª) is constant for Œª ‚ààR,
(5.18)
the set Im Xk(Œª) is constant for Œª ‚ààR.
(5.19)
(iv) The matrices Xk(Œª) X‚Ä†
k(Œª) and X‚Ä†
k(Œª) Xk(Œª) are piecewise constant in Œª.

5.1
Nonlinear Dependence on Spectral Parameter
265
Remark 5.4 We remark that one can associate Zk(Œª) with a given conjoined basis
Y(Œª) =

X(Œª)
U(Œª)

of (SDSŒª); see Lemma 1.58(iv). In particular cases, we will assume
in addition that the initial conditions of the conjoined basis Y(Œª) do not depend on
Œª, i.e.,
Y0(Œª) ‚â°Y0
for all Œª ‚ààR.
(5.20)
It then follows from the proof of Lemma 1.58(iv) that the symplectic fundamental
matrix Zk(Œª) such that Y(Œª) = Z(Œª)(0 I)T also does not depend on Œª for k = 0,
i.e., Z0(Œª) ‚â°Z0. In this special case, the condition (Z0(Œª)) ‚â•0 for Œª ‚ààR is
trivially satisÔ¨Åed, and we derive all assertions of Theorem 5.3 for the block Xk(Œª)
of a conjoined basis Yk(Œª) = Xk(Œª)
Uk(Œª)
 of (SDSŒª) with initial conditions (5.20).
In Theorem 5.3, we showed that for every Ô¨Åxed Œª0 ‚ààR, the quantity rank Xk(Œª)
is constant on some left and right neighborhoods of Œª0. This allows to deÔ¨Åne
correctly the notion of a Ô¨Ånite eigenvalue of problem (E). Let Y [0](Œª) =

X[0](Œª)
U[0](Œª)

be the principal solution of (SDSŒª) at k = 0, that is, the solution starting with the
initial values
X[0]
0 (Œª) ‚â°0,
U[0]
0 (Œª) ‚â°I
for all Œª ‚ààR,
so that these initial conditions are independent of Œª, and Theorem 5.3 works for this
special case (see Remark 5.4).
The result in Theorem 5.3 justiÔ¨Åes the introduction of the following notion.
DeÔ¨Ånition 5.5 (Finite Eigenvalue) Under (5.3), a number Œª0 ‚ààR is a Ô¨Ånite
eigenvalue of problem (E) if
Œ∏(Œª0) := rank X[0]
N+1(Œª‚àí
0 ) ‚àírankX[0]
N+1(Œª0) ‚â•1.
(5.21)
In this case the number Œ∏(Œª0) is called the algebraic multiplicity of Œª0.
Remark 5.6
(i) The deÔ¨Ånition of a Ô¨Ånite eigenvalue of (E) is one-sided, that is, it only depends
on the behavior of X[0]
N+1(Œª) in a left neighborhood of Œª0.
(ii) By (5.13), the Ô¨Ånite eigenvalues are well deÔ¨Åned, since the number Œ∏(Œª0) is
always nonnegative. Moreover,
Œ∏(Œª0) = defX[0]
N+1(Œª0) ‚àídef X[0]
N+1(Œª‚àí
0 )
= dim

[Ker X[0]
N+1(Œª‚àí
0 )]‚ä•‚à©Ker X[0]
N+1(Œª0)

.
(5.22)
(iii) When X[0]
N+1(Œª) is invertible except at isolated values of Œª (which is the case of
‚Äúcontrollable‚Äù systems), then def X[0]
N+1(Œª‚àí
0 ) = 0 for every Œª0 ‚ààR. Therefore,

266
5
Discrete Symplectic Eigenvalue Problems
in this case a Ô¨Ånite eigenvalue reduces to the classical eigenvalue, which is
determined by the condition def X[0]
N+1(Œª0) ‚â•1, i.e., by the singularity of
X[0]
N+1(Œª0). The algebraic multiplicity is then equal to defX[0]
N+1(Œª0); see, e.g.,
[44, Corollary 1].
(iv) When the dependence in Œª is linear as in (5.238) or (5.241), we will discuss
the special features of the Ô¨Ånite eigenvalues in Sect. 5.3.3.
The following is a simple consequence of Theorem 5.3 and DeÔ¨Ånition 5.5.
Corollary 5.7 Under (5.3), the Ô¨Ånite eigenvalues of (E) are isolated.
5.1.2
Finite Eigenfunctions
In this subsection, we develop a geometric notion corresponding to the Ô¨Ånite
eigenvalues from DeÔ¨Ånition 5.5. First observe that if Œª0 is a Ô¨Ånite eigenvalue of (E)
and c ‚ààKer X[0]
N+1(Œª0), then y := Y [0](Œª0) c is a vector solution satisfying both
(SŒª0) and x0 = 0 = xN+1, i.e., y solves the problem (E) with Œª = Œª0. It remains to
describe which of these solutions are in a sense ‚Äúdegenerate,‚Äù that is, which of them
do not correspond to a Ô¨Ånite eigenvalue Œª0. This procedure has a parallel strategy in
the classical eigenvalue theory, where only the nontrivial solutions of (E) count as
the eigenfunctions for the eigenvalue Œª0.
DeÔ¨Ånition 5.8 (Degenerate Solution) Let Œª0 ‚ààR be given. A solution y of system
(SŒª0) is said to be degenerate at Œª0 (or it is a degenerate solution), if there exists
Œ¥ > 0 such that for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], the solution y(Œª) of (SDSŒª) given by the
initial conditions y0(Œª) = y0 satisÔ¨Åes
k(Œª) yk+1(Œª) = 0
for all k ‚àà[0, N]Z.
(5.23)
In the opposite case, we say that the solution y is nondegenerate at Œª0.
A degenerate solution at Œª0 represents in fact a family of solutions y(Œª) for Œª ‚àà
(Œª0‚àíŒ¥, Œª0], which includes the solution y itself for Œª = Œª0. Moreover, this family of
solutions is independent of Œª with respect to the semi-norm induced by the positive
semideÔ¨Ånite matrix k(Œª), i.e.,
33 y(Œª)
332
Œª :=
N

k=0
yT
k+1(Œª) k(Œª) yk+1(Œª)
for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
Remark 5.9
(i) Since the matrix k(Œª) is symmetric and since Sk(Œª) and J are invertible, it
follows from (5.3) that condition (5.23) can be written in the equivalent form
ÀôST
k (Œª) J yk+1(Œª) = 0
for all k ‚àà[0, N]Z.

5.1
Nonlinear Dependence on Spectral Parameter
267
(ii) When the dependence on Œª is linear as in (5.238) and (5.241), a degenerate
solution y = (x, u) at Œª0 is a solution of (SŒª0) satisfying
Wk xk+1 = 0
for all k ‚àà[0, N]Z.
(5.24)
Condition (5.24) is indeed equivalent to (5.23) where Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], since
under (5.241) any solution of (SŒª0) satisfying (5.24) is at the same time a solution
of (SDSŒª) for every Œª ‚ààR. Hence, degeneracy condition (5.23) is a local property
when (SDSŒª) depends on Œª nonlinearly, but it is a global property for the linear
dependence on Œª.
Consider the following spaces of solutions of system (SŒª0):
E(Œª0) :=
!
y = (x, u) solves system (SŒª0) with x0 = 0 = xN+1
"
,
W(Œª0) := !y = (x, u) ‚ààE(Œª0), y is degenerate at Œª0
".
Then it follows that
E(Œª0) =
!
Y [0](Œª0) c, c ‚ààKer X[0]
N+1(Œª0)
"
.
(5.25)
Indeed, the inclusion ‚äáin (5.25) follows from the considerations at the beginning
of this section, while the inclusion ‚äÜin (5.25) is obtained from the uniqueness of
solutions of system (SŒª0)‚Äîevery solution y ‚ààE(Œª0) is of the form y = Y [0](Œª0) c,
where c = u0 and where X[0]
N+1(Œª0) c = 0. Our aim is to prove that the degenerate
solutions at Œª0 correspond to those vectors c ‚ààKer X[0]
N+1(Œª0) which are in
Ker X[0]
N+1(Œª‚àí
0 ), i.e., we will prove in Theorem 5.11 below that
W(Œª0) =
!
Y [0](Œª0) c, c ‚ààKer X[0]
N+1(Œª‚àí
0 )
"
.
(5.26)
In turn, the Ô¨Ånite eigenfunctions are exactly the nondegenerate solutions at Œª0.
DeÔ¨Ånition 5.10 (Finite Eigenfunction) Under (5.3), every nondegenerate solution
y at Œª0 of (E) with Œª = Œª0 is called a Ô¨Ånite eigenfunction corresponding to the Ô¨Ånite
eigenvalue Œª0, and the number
œâ(Œª0) := dim E(Œª0) ‚àídim W(Œª0)
(5.27)
is called the geometric multiplicity of Œª0.
The following result is a characterization of the Ô¨Ånite eigenvalues of (E) with the
nonlinear dependence on Œª.
Theorem 5.11 (Geometric
Characterization
of
Finite
Eigenvalues) Let
assumption (5.3) be satisÔ¨Åed. A number Œª0 is a Ô¨Ånite eigenvalue of (E) with
algebraic multiplicity Œ∏(Œª0) ‚â•1 deÔ¨Åned in (5.21) if and only if there exists

268
5
Discrete Symplectic Eigenvalue Problems
a corresponding Ô¨Ånite eigenfunction y. In this case, the geometric multiplicity
of Œª0 deÔ¨Åned in (5.27) is equal to its algebraic multiplicity, i.e., œâ(Œª0) = Œ∏(Œª0).
For the proof of Theorem 5.11, we need the following auxiliary result.
Lemma 5.12 Let Y(Œª) = (X(Œª), U(Œª)) and ÀúY(Œª) = ( ÀúX(Œª), ÀúU(Œª)) be normalized
conjoined bases of (SDSŒª) such that they form the symplectic fundamental matrix
ÀúZk(Œª) =
Xk(Œª) ÀúXk(Œª)
Uk(Œª) ÀúUk(Œª)

(5.28)
of (SDSŒª). Assume that ÀúZ0(Œª) ‚â°
ÀúZ0, i.e., it does not depend on Œª, and that
Xk+1(Œª0) is invertible for some k ‚àà[0, N]Z and Œª0 ‚ààR. Then there exists Œµ > 0
such that
d
dŒª [X‚àí1
k+1(Œª) ÀúXk+1(Œª)] =
k

j=0
Œ∂ T
k+1,j+1(Œª) j(Œª) Œ∂ k+1,j+1(Œª),
(5.29)
for all Œª ‚àà(Œª0 ‚àíŒµ, Œª0 + Œµ), where
Œ∂ k,j(Œª) := ÀúZj(Œª)
‚àíX‚àí1
k (Œª) ÀúXk(Œª)
I

.
(5.30)
Proof Using the assumption ÀúZ0(Œª) ‚â°ÀúZ0, Proposition 1.76(ii), and the deÔ¨Ånition of
( ÀúZk+1(Œª)), we derive from (5.12) that
( ÀúZ‚àí1
k+1(Œª)) = ÀúZT
k+1(Œª) J ÀôÀúZk+1(Œª) = ‚àík(Œª),
k ‚àà[0, N]Z,
Œª ‚ààR,
(5.31)
where
k(Œª) :=
k

j=0
ÀúZT
j+1(Œª) j(Œª) ÀúZj+1(Œª).
(5.32)
Since Xk+1(Œª0) is invertible, it follows that Xk+1(Œª) is invertible on (Œª0 ‚àíŒµ, Œª0 +Œµ)
for some Œµ > 0, and then one can apply Lemma 1.77 with W(Œª) := ÀúZ‚àí1
k+1(Œª),
R := ‚àíJ , P := I, and ÀúW(Œª) := J ÀúZ‚àí1
k+1(Œª). By (1.200) and Proposition 1.76(i),
we derive (suppressing the argument Œª and index k + 1)
J T ( ÀúW(Œª)) J =( ÀúZ‚àí1
k+1(Œª))=‚àí
XT 0
ÀúXT I
 d
dŒª
‚àíUX‚àí1 ‚àíXT ‚àí1
‚àíX‚àí1
X‚àí1 ÀúX
X ÀúX
0 I

.
Substituting the above representation for ( ÀúZ‚àí1
k+1(Œª)) into formula (5.31), we derive
identity (5.29).
‚äì‚äî

5.1
Nonlinear Dependence on Spectral Parameter
269
Proof of Theorem 5.11 If we prove that equality (5.26) holds, then the result will
follow since the Ô¨Ånite eigenfunctions y for Œª0 will be of the form y = Y [0](Œª0) c
with c ‚ààKer X[0]
N+1(Œª0) \ Ker X[0]
N+1(Œª‚àí
0 ).
Let y = (x, u) be a solution of (E) with Œª = Œª0, and assume that y is degenerate
at Œª0. Let Œ¥ > 0 and y(Œª) = (x(Œª), u(Œª)) for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] be the constant
and the corresponding family of solutions from DeÔ¨Ånition 5.8. By the uniqueness of
solutions of (SDSŒª), we get
yk(Œª) = Y [0]
k (Œª) c
for all k ‚àà[0, N + 1]Z and Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
(5.33)
for some c ‚ààRn, in fact for c = u0. From xN+1 = 0, we must necessarily
have c ‚ààKer X[0]
N+1(Œª0). By Theorem 5.3, we may assume that Ker X[0]
N+1(Œª) ‚â°
Ker X[0]
N+1(Œª‚àí
0 ) is constant on (Œª0 ‚àíŒ¥, Œª0). Then for every k ‚àà[0, N]Z and every
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], we have
yk+1(Œª) = Sk(Œª) yk(Œª),
yk(Œª) = ‚àíJ ST
k (Œª) J yk+1(Œª).
(5.34)
By taking the derivative of this equation at Œª ‚àà(Œª0 ‚àíŒ¥, Œª0), resp., the left derivative
of this equation at Œª = Œª0, we obtain
Àôyk+1(Œª) = Sk(Œª) Àôyk(Œª) + ÀôSk(Œª) yk(Œª)
(5.34)
= Sk(Œª) Àôyk(Œª) + J k(Œª) yk+1(Œª)
(5.23)
=
Sk(Œª) Àôyk(Œª),
k ‚àà[0, N]Z, Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.35)
In addition, since y0(Œª) = y0 for every Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], the initial conditions
of y(Œª) do not depend on Œª. Hence, Àôy0(Œª) = 0 for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. By the
uniqueness of solutions of system (SDSŒª), it follows from (5.35) that Àôyk(Œª) = 0 for
all k ‚àà[0, N + 1]Z and Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. This means that the functions y(Œª) do not
depend on Œª on (Œª0 ‚àíŒ¥, Œª0], i.e.,
yk(Œª) ‚â°yk(Œª0)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] and all k ‚àà[0, N + 1]Z.
(5.36)
Therefore, for every Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] and k ‚àà[0, N + 1]Z, we have
Y [0]
k (Œª) c
(5.33)
= yk(Œª)
(5.36)
=
yk(Œª0) = yk = (xk, uk).
The endpoint condition xN+1 = 0 then yields X[0]
N+1(Œª) c = 0 for all Œª ‚àà(Œª0 ‚àí
Œ¥, Œª0], i.e., c ‚ààKer X[0]
N+1(Œª) for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. And since Ker X[0]
N+1(Œª) is
constant on (Œª0 ‚àíŒ¥, Œª0), it follows that c ‚ààKer X[0]
N+1(Œª‚àí
0 ).
Conversely, let c ‚ààKer X[0]
N+1(Œª‚àí
0 ). Then c ‚ààKer X[0]
N+1(Œª) for all values
Œª ‚àà(Œª0 ‚àíŒµ, Œª0] for some Œµ > 0. Let ÀúY(Œª0) be a conjoined basis of (SŒª0) such
that ÀúY(Œª0) and Y(Œª0) are normalized and ÀúXN+1(Œª0) is invertible (similar to the

270
5
Discrete Symplectic Eigenvalue Problems
proof of Theorem 5.3). For each Œª ‚ààR, let ÀúY(Œª) be the conjoined basis of (SDSŒª)
starting with the initial conditions ÀúY0(Œª) = ÀúY0(Œª0), so that these initial conditions
are independent of Œª. Then ÀúXN+1(Œª) is invertible for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] for some
Œ¥ ‚àà(0, Œµ). For j ‚àà[0, N + 1]Z and Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], we now deÔ¨Åne the functions
yj(Œª) := Y [0]
j (Œª) c ‚àíÀúYj(Œª) ÀúX‚àí1
N+1(Œª) X[0]
N+1(Œª) c = Y [0]
j (Œª) c,
compared with Œ∂N+1,j(Œª) in (5.30). Then for every Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], the function
z(Œª) solves the system (SDSŒª) with z0(Œª) = (0, c). Since
cT ÀúX‚àí1
N+1(Œª) X[0]
N+1(Œª) c = 0
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.37)
differentiating equation (5.37) at any Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], we get from Lemma 5.12, in
which Y(Œª) := ÀúY(Œª) and ÀúY(Œª) := Y [0](Œª), that
0
(5.37)
=
d
dŒª cT ÀúX‚àí1
N+1(Œª) X[0]
N+1(Œª) c
(5.29)
=
N

j=0
yT
j+1(Œª) j(Œª) yj+1(Œª)
for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. Therefore, by (5.3), j(Œª) yj+1(Œª) = 0 for all j ‚àà[0, N]Z and
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], showing that y(Œª0) = Y [0](Œª0) c is a degenerate solution at Œª0.
The proof is complete.
‚äì‚äî
Remark 5.13 The proof of Theorem 5.11 shows that, under (5.3), for any Ô¨Åxed k ‚àà
[0, N]Z and any c ‚ààKer Xk+1(Œª‚àí
0 ), there exists Œ¥ > 0 such that the function Yj(Œª) c
is independent of Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] for all j ‚àà[0, k + 1]Z, where Y(Œª) is a conjoined
basis of (SDSŒª) satisfying (5.20).
Remark 5.14 Of course, similar statements as above can be proven for functions
deÔ¨Åned in the right neighborhood of Œª0, say for Œª ‚àà[Œª0, Œª0 + Œ¥). For example,
when c ‚ààKer Xk+1(Œª+
0 ), there exists Œ¥ > 0 such that Yj(Œª) c is independent of
Œª ‚àà[Œª0, Œª0 + Œ¥) for all j ‚àà[0, k + 1]Z.
5.1.3
Oscillation Theorems for Constant Rank of Bk(Œª)
In this section we establish the main results on the oscillation properties of
system (SDSŒª) under the additional restriction (5.8), i.e.,
rankBk(Œª) is constant for Œª ‚ààR.
(5.38)
Later, in Sect. 5.6 we completely omit this assumption using the comparative index
tools presented in Chaps. 3 and 4.
Recall the deÔ¨Ånition of focal points and their multiplicities for conjoined bases
of (SDSŒª). According to DeÔ¨Ånition 4.1, a conjoined basis Y(Œª) = (X(Œª), U(Œª))

5.1
Nonlinear Dependence on Spectral Parameter
271
of (SDSŒª) has a focal point in the real interval (k, k + 1] provided
mk(Œª) := rankMk(Œª) + ind Pk(Œª) ‚â•1
(5.39)
and then the number mk(Œª) is its multiplicity, where
Mk(Œª) := [I ‚àíXk+1(Œª) X‚Ä†
k+1(Œª)] Bk(Œª),
Tk(Œª) := I ‚àíM‚Ä†
k (Œª) Mk(Œª),
Pk(Œª) := Tk(Œª) Xk(Œª) X‚Ä†
k+1(Œª) Bk(Œª) Tk(Œª),
‚é´
‚é™‚é¨
‚é™‚é≠
(5.40)
and the matrix Pk(Œª) is symmetric. By this deÔ¨Ånition, all algebraic properties of the
multiplicities of focal points mk formulated in Sect. 4.1.1 remain true for mk(Œª) and
Œª ‚ààR. For example, in the subsequent proofs, we will use that the matrix Mk(Œª)
deÔ¨Åned in (5.40) satisÔ¨Åes
rank Mk(Œª) = rankNk(Œª),
Nk(Œª) := [I ‚àíX‚Ä†
k+1(Œª) Xk+1(Œª)] XT
k (Œª),
(5.41)
which gives the number of focal points of the conjoined basis Y(Œª) located at k + 1
in terms of Xk(Œª) and Xk+1(Œª) only, i.e., without explicitly appearing Bk(Œª) (see
DeÔ¨Ånition 4.9 and Proposition 4.13).
Theorem 5.15 (Local Oscillation Theorem I) Assume (5.3). Let Y(Œª) be a con-
joined basis of (SDSŒª) with (5.20). Fix k ‚àà[0, N]Z and suppose (5.38). As in (5.39),
let mk(Œª) denote the number of focal points of Y(Œª) in (k, k + 1]. Then mk(Œª‚àí) and
mk(Œª+) exist and for all Œª ‚ààR
mk(Œª+) = mk(Œª) ‚â§n,
(5.42)
mk(Œª+) ‚àímk(Œª‚àí) = 

rank Xk(Œª‚àí) ‚àírankXk(Œª)

.
(5.43)
The proof of Theorem 5.15 will be presented in Sect. 5.1.6. Next we establish
further results based on Theorem 5.15. Denote by, including the multiplicities,
n1(Œª) := the number of focal points of Y(Œª) in (0, N + 1],
(5.44)
i.e., n1(Œª) = l(Y(Œª), 0, N + 1) according to the notation in (4.10).
Theorem 5.16 (Local Oscillation Theorem II) Assume that conditions (5.3)
and (5.38) hold for all k ‚àà[0, N]Z. Let Y(Œª) be a conjoined basis of (SDSŒª) such
that (5.20) holds. Then n1(Œª‚àí) and n1(Œª+) exist and for all Œª ‚ààR
n1(Œª+) = n1(Œª) ‚â§(N + 1) n < ‚àû,
(5.45)
n1(Œª+) ‚àín1(Œª‚àí) = rank XN+1(Œª‚àí) ‚àírankXN+1(Œª) ‚â•0.
(5.46)

272
5
Discrete Symplectic Eigenvalue Problems
Hence, the function n1(¬∑) is nondecreasing on R, the limit
m :=
lim
Œª‚Üí‚àí‚àûn1(Œª)
(5.47)
exists with m ‚àà[0, (N + 1) n]Z, so that for a suitable Œª0 < 0 we have
n1(Œª) ‚â°m,
rankXN+1(Œª‚àí) ‚àírank XN+1(Œª) ‚â°0,
Œª ‚â§Œª0.
(5.48)
Proof Since n1(Œª) = N
k=0 mk(Œª) for all Œª ‚ààR with mk(Œª) given in (5.39), the
statement in (5.45) follows directly from (5.42). The expression in (5.46) is then
a telescope sum of the expression in (5.43). This yields for all Œª ‚ààR
n1(Œª+) ‚àín1(Œª‚àí) = rankXN+1(Œª‚àí) ‚àírankXN+1(Œª) ‚àírank X0(Œª‚àí) + rank X0(Œª).
But since by (5.20) the initial conditions of Y(Œª) do not depend on Œª, we have
rankX0(Œª‚àí) = rank X0(Œª) for all Œª ‚ààR, so that the statement in (5.46) follows.
From the two conditions (5.45) and (5.46), we then have that the function n1(¬∑) is
nondecreasing on R. Since the values of n1(Œª) are nonnegative integers, the limit
in (5.47) exists and m ‚ààN ‚à™{0}. Consequently, n1(Œª) ‚â°m for all Œª sufÔ¨Åciently
negative, say for all Œª ‚â§Œª0 for some Œª0 < 0, so that n1(Œª+) ‚àín1(Œª‚àí) ‚â°0 for
Œª ‚â§Œª0. Applying (5.46) once more then yields the second equation in (5.48).
‚äì‚äî
Now we apply the above local oscillation theorem to the principal solution
Y [0](Œª) = (X[0](Œª), U[0](Œª)) of (SDSŒª) at k = 0. In this case we have from
system (SDSŒª) and (5.40) that
Y [0]
0 (Œª) =
0
I

,
Y [0]
1 (Œª) =
B0(Œª)
D0(Œª)

,
M0(Œª) = 0,
T0(Œª) = I,
P0(Œª) = 0.
This means that the principal solution Y [0](Œª) has no forward focal points in the
interval (0, 1] for all Œª ‚ààR, and hence, according to (5.44), we have
n1(Œª) = the number of focal points of Y [0](Œª) in (1, N + 1],
(5.49)
i.e., n1(Œª) = l(Y [0](Œª), 0, N + 1) according to (4.10). We also denote by, including
the multiplicities,
n2(Œª) := the number of Ô¨Ånite eigenvalues of (E) in (‚àí‚àû, Œª].
(5.50)
Then from this deÔ¨Ånition, we have
n2(Œª+) = n2(Œª),
n2(Œª) ‚àín2(Œª‚àí) = Œ∏(Œª)
for all Œª ‚ààR,
(5.51)
i.e., the difference n2(Œª) ‚àín2(Œª‚àí) gives the number of Ô¨Ånite eigenvalues at Œª.

5.1
Nonlinear Dependence on Spectral Parameter
273
Theorem 5.17 (Global Oscillation Theorem) Assume that (5.3) and (5.38) hold
for all k ‚àà[0, N]Z. Then with the notation (5.44) and (5.50), we have for all Œª ‚ààR
n1(Œª+) = n1(Œª) ‚â§Nn,
(5.52)
n2(Œª+) = n2(Œª) < ‚àû,
(5.53)
n2(Œª+) ‚àín2(Œª‚àí) = n1(Œª+) ‚àín1(Œª‚àí) ‚â•0,
(5.54)
and there exists m ‚àà[0, Nn]Z such that
n1(Œª) = n2(Œª) + m
for all Œª ‚ààR.
(5.55)
Moreover, for a suitable Œª0 < 0, we have
n2(Œª) ‚â°0
and
n1(Œª) ‚â°m
for all Œª ‚â§Œª0.
(5.56)
Proof Conditions (5.53) and (5.54) follow directly from (5.51) and (5.46). Since
both functions n1(¬∑) and n2(¬∑) are right-continuous and (5.54) holds, then they must
differ on R by a constant l ‚ààR. But by (5.48), we have n1(Œª) ‚â°m for all Œª ‚â§Œª0
with m given in (5.47). Taking into account (5.49), we see that m ‚â§Nn and the
statement in (5.55) follows. From (5.55) we obtain in turn that n2(Œª) ‚â°0 for all
Œª ‚â§Œª0.
‚äì‚äî
Corollary 5.18 Under the assumptions of Theorem 5.17, the Ô¨Ånite eigenvalues
of (E) are bounded from below and from above.
Proof This result follows from (5.56), since n2(Œª) ‚â°0 for all Œª ‚â§Œª0 means that
there are no Ô¨Ånite eigenvalues of (E) in the interval (‚àí‚àû, Œª0].
‚äì‚äî
We note that the boundedness of the Ô¨Ånite eigenvalues of (E) from above follows
from equation (5.55) and estimate (5.52), which is a consequence of the discreteness
of the problem. In the continuous time case, the number of focal points (and hence
the number of Ô¨Ånite eigenvalues) can be unbounded from above; see, e.g., [205,
Theorems 7.6.3 and 7.7.1].
The next three subsections are devoted to the proof of Theorem 5.15. This
proof is based on a construction of suitable partitioned matrices and an auxiliary
symplectic system between the indices k and k +1. Note that the entire construction
is valid for an arbitrary coefÔ¨Åcient Bk(Œª). Only at the end assumption (5.38) is
invoked in order to apply the index theorem in Corollary 1.86.
5.1.4
Construction of Auxiliary Conjoined Basis
In the construction below, we assume that Y(Œª) is a given conjoined basis
of (SDSŒª) whose initial conditions do not depend on Œª, i.e., satisfying (5.20), and

274
5
Discrete Symplectic Eigenvalue Problems
condition (5.3) holds. We also Ô¨Åx an index k ‚àà[0, N]Z and a number Œª0 ‚ààR. By
Theorem 5.3, we know that (5.13) holds, so that
r := rank Xk+1(Œª‚àí
0 ) ‚â°rank Xk+1(Œª)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0)
(5.57)
exists for some Œ¥ > 0. The number Œ¥ will also appear in the construction below.
Lemma 5.19 There exist orthogonal matrices P, Q ‚ààRn√ón such that
Q Xk+1(Œª) P =
X11(Œª) 0r√ó(n‚àír)
0
0n‚àír

, Q Uk+1(Œª) P =
U11(Œª)
0
U21(Œª) U22

,
(5.58)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], and the matrix
XT
11(Œª) U11(Œª)
is symmetric for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.59)
Here X11(Œª) ‚ààRr√ór is invertible for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0), and U22 ‚ààR(n‚àír)√ó(n‚àír)
is invertible.
Proof Let P1 ‚ààRn√ór and P2 ‚ààRn√ó(n‚àír) be matrices whose columns form
orthonormal bases for Im XT
k+1(Œª‚àí
0 ) and Ker Xk+1(Œª‚àí
0 ), respectively. Then since
[Ker Xk+1(Œª‚àí
0 )]‚ä•
= Im XT
k+1(Œª‚àí
0 ), the matrix P
:= (P1, P2) ‚ààRn√ón is
orthogonal,
Im P2 = Ker Xk+1(Œª‚àí
0 ) ‚â°Ker Xk+1(Œª)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0).
(5.60)
Xk+1(Œª) P =

Xk+1(Œª) P1, 0n√ó(n‚àír)

for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.61)
Note that (5.61) indeed holds also at Œª = Œª0 by the continuity of Xk+1 in Œª. Let
Q1 ‚ààRr√ón and Q2 ‚ààR(n‚àír)√ón be matrices whose columns form orthonormal bases
for Im Xk+1(Œª1) and Ker XT
k+1(Œª1), respectively, for some Ô¨Åxed Œª1 ‚àà(Œª0 ‚àíŒ¥, Œª0).
Then the matrix Q :=

Q1
Q2

‚ààRn√ón is orthogonal, Im QT
2 = Ker XT
k+1(Œª1), and
Q Xk+1(Œª1) P =
Q1
Q2

Xk+1(Œª1)

P1, P2

=
X11 0r√ó(n‚àír)
0
0n‚àír

,
(5.62)
where X11 := Q1Xk+1(Œª1) P1 ‚ààRr√ór has rank X11 = r, i.e., X11 is invertible.
DeÔ¨Åne now
X11(Œª) X12(Œª)
X21(Œª) X22(Œª)

:= Q Xk+1(Œª) P,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.63)
U11(Œª) U12(Œª)
U21(Œª) U22(Œª)

:= Q Uk+1(Œª) P,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.64)

5.1
Nonlinear Dependence on Spectral Parameter
275
so that by (5.61) and (5.62)
X12(Œª) ‚â°0,
X22(Œª) ‚â°0
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
X11(Œª1) = Q1Xk+1(Œª1) P1 = X11 is invertible,
X21(Œª1) = Q2Xk+1(Œª1) P1 = 0.
Moreover, since the matrices P and Q are orthogonal, we have for all Œª ‚àà(Œª0 ‚àí
Œ¥, Œª0]
Xk+1(Œª) = QT
X11(Œª) 0
X21(Œª) 0

PT, Uk+1(Œª) = QT
U11(Œª) U12(Œª)
U21(Œª) U22(Œª)

PT.
(5.65)
Since Y(Œª) is a conjoined basis of (SDSŒª), the matrix XT
k+1(Œª) Uk+1(Œª) symmetric
and rank Yk+1(Œª) = n for all Œª ‚ààR. Hence, with Œª = Œª1, we have
XT
k+1(Œª1) Uk+1(Œª1) = P
XT
11U11(Œª1) XT
11U12(Œª1)
0
0

PT .
This implies that XT
11U12(Œª1) = 0 and since X11 is invertible, U12(Œª1) = 0. Now
from (5.64), we have U12(Œª) = Q1Uk+1(Œª) P2 and U22(Œª) = Q2Uk+1(Œª) P2 for
all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], which implies by Remark 5.13 that the functions U12(Œª) and
U22(Œª) do not depend on Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. Thus, since U12(Œª1) = 0, we get
U12(Œª) ‚â°0,
U22(Œª) ‚â°U22(Œª‚àí
0 ) =: U22 ‚ààR(n‚àír)√ó(n‚àír)
for all Œª ‚àà(Œª0‚àíŒ¥, Œª0].
This proves the second formula in (5.58). Moreover, since
n = rank

XT
k+1(Œª1), UT
k+1(Œª1)

= rank
XT
11 0r√ó(n‚àír) UT
11(Œª1) UT
21(Œª1)
0
0n‚àír
0(n‚àír)√ór
UT
22

,
it follows that rank U22 = n‚àír, that is, U22 is invertible. Next, for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
the matrix
XT
k+1(Œª) Uk+1(Œª)=P
XT
11(Œª) U11(Œª)+XT
21(Œª) U21(Œª) XT
21(Œª) U22
0
0

PT
(5.66)
is symmetric, so that XT
21(Œª) U22 ‚â°0 on (Œª0 ‚àíŒ¥, Œª0]. But since U22 is invertible, we
get X21(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0], showing through (5.65) that also the Ô¨Årst formula
in (5.58) holds. In addition, since rank Q Xk+1(Œª) P = rank Xk+1(Œª) ‚â°r for all
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0) and rank X11(Œª1) = rankX11 = r, we get from (5.58) that
rankX11(Œª) ‚â°r on (Œª0 ‚àíŒ¥, Œª0), and so X11(Œª) is invertible for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0).
Finally, from (5.66) we obtain that
XT
k+1(Œª) Uk+1(Œª) = P
XT
11(Œª) U11(Œª) 0
0
0

PT

276
5
Discrete Symplectic Eigenvalue Problems
is symmetric for all Œª ‚àà(Œª0‚àíŒ¥, Œª0]. From this we conclude that (5.59) holds, which
completes the proof.
‚äì‚äî
Corollary 5.20 In addition to Theorem 5.3(iv), we have
Xk+1(Œª) X‚Ä†
k+1(Œª) ‚â°QT
Ir
0
0 0n‚àír

Q,
X‚Ä†
k+1(Œª) Xk+1(Œª) ‚â°P
Ir
0
0 0n‚àír

PT
(5.67)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0)
Proof By Lemma 5.19 and Remark 1.60(ii), we have for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
Xk+1(Œª) = QT
X11(Œª) 0
0
0

PT ,
X‚Ä†
k+1(Œª) = P

X‚Ä†
11(Œª) 0
0
0

Q.
And since by Lemma 5.19 the matrix X11(Œª) is invertible on (Œª0 ‚àíŒ¥, Œª0), we
get (5.67). The proof is complete.
‚äì‚äî
Based on the result of Lemma 5.19, we deÔ¨Åne the matrices
ÀúXk+1(Œª) :=
X11(Œª) 0r√ó(n‚àír)
0
0r

,
ÀúUk+1(Œª) :=
U11(Œª)
0
U21(Œª) U22

,
Œª ‚ààR.
(5.68)
Then by (5.59) the matrix ÀúXT
k+1(Œª) ÀúUk+1(Œª) is symmetric for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
In addition, by (5.58) we have
ÀúXk+1(Œª) = Q Xk+1(Œª) P,
ÀúUk+1(Œª) = Q Uk+1(Œª) P,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.69)
which yields that
rank
 ÀúXT
k+1(Œª), ÀúUT
k+1(Œª)
 (5.69)
= rank

XT
k+1(Œª), UT
k+1(Œª)

= n,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
Next we construct for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] suitable matrices ÀúXk(Œª) and ÀúUk(Œª). First
we observe that by Remark 5.13 with j = k, the functions
Xk(Œª) P2 and Uk(Œª) P2 do not depend on Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
because Im P2 = Ker Xk+1(Œª‚àí
0 ). This implies that the number
œÅ := rankXk(Œª‚àí
0 ) P2 ‚â°rankXk(Œª) P2
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0)
(5.70)

5.1
Nonlinear Dependence on Spectral Parameter
277
is well deÔ¨Åned. Note that by (1.142) and (5.41), the deÔ¨Ånition of œÅ yields
œÅ = rankP2 ‚àídim

Ker Xk(Œª) ‚à©Im P2

= def Xk+1(Œª) ‚àídim  Ker Xk(Œª) ‚à©Ker Xk+1(Œª)
= rankNk(Œª)
(5.41)
=
rankMk(Œª)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0). Later in this section, we will prove directly that the
number œÅ = rankMk(Œª‚àí
0 ). In addition, the deÔ¨Ånition of Mk(Œª), formula (5.67)(i),
and (1.142) yield that
œÅ = rank MT
k (Œª) = rank BT
k (Œª) [I ‚àíXk+1(Œª) X‚Ä†
k+1(Œª)]
= rank [I ‚àíXk+1(Œª) X‚Ä†
k+1(Œª)] ‚àídim

Ker BT
k (Œª) ‚à©Im [I ‚àíXk+1(Œª) X‚Ä†
k+1(Œª)]

= n ‚àír ‚àídim

Ker BT
k (Œª) ‚à©Ker XT
k+1(Œª)

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0).
(5.71)
Remark 5.21 From equation (5.71), we can see that œÅ ‚â§n ‚àír and that œÅ = n ‚àír
if and only if Ker BT
k (Œª) ‚à©Ker XT
k+1(Œª) = {0} on (Œª0 ‚àíŒ¥, Œª0). This latter condition
is satisÔ¨Åed, e.g., when Bk(Œª) or Xk+1(Œª) is invertible on (Œª0 ‚àíŒ¥, Œª0).
We now reÔ¨Åne the structure of the above matrices to partition Xk(Œª) and Uk(Œª).
Since œÅ ‚â§rankXk(Œª‚àí
0 ), we may put
Àúr := rk ‚àíœÅ,
where rk := rank Xk(Œª‚àí
0 ).
(5.72)
Then since rank Xk(Œª‚àí
0 ) P2 = œÅ, we must have rank Xk(Œª‚àí
0 ) P1 = rk ‚àíœÅ = Àúr.
But the matrix Xk(Œª‚àí
0 ) P1 ‚ààRn√ór, which implies Àúr ‚â§r. The block structure of the
matrices below is such that their total dimension n is partitioned as
n = Àúr + (r ‚àíÀúr) + (n ‚àír ‚àíœÅ) + œÅ.
Lemma 5.22 There are orthogonal matrices P, Q, ÀúQ satisfying Lemma 5.19 and
ÀúQ Xk(Œª) P =
‚éõ
‚éú‚éú‚éù
ÀúX11(Œª)
0
0
0Àúr√óœÅ
0
0r‚àíÀúr
0
0
0
0
0n‚àír‚àíœÅ
0
ÀúX41(Œª) ÀúX42
0
ÀúX44
‚éû
‚éü‚éü‚é†,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.73)
where ÀúX11(Œª) ‚ààRÀúr√óÀúr is invertible for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0) and ÀúX44 ‚ààRœÅ√óœÅ is
invertible.

278
5
Discrete Symplectic Eigenvalue Problems
Proof Let the matrices P and Q be from Lemma 5.19. Since Xk(Œª) P2 ‚ààRn√ó(n‚àír)
and rank Xk(Œª) P2 = œÅ for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0), there are orthogonal matrices ÀúQ ‚àà
Rn√ón and ¬ØP2 ‚ààR(n‚àír)√ó(n‚àír) such that
ÀúQ Xk(Œª) P2 ¬ØP2 =
‚éõ
‚éú‚éú‚éú‚éù
0Àúr
0Àúr√óœÅ
0
0(r‚àíÀúr)√óœÅ
0 0(n‚àír‚àíœÅ)√óœÅ
0
ÀúX44
‚éû
‚éü‚éü‚éü‚é†,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.74)
where
ÀúX44
‚àà
RœÅ√óœÅ is invertible. Let Œª1
‚àà
(Œª0 ‚àíŒ¥, Œª0) be Ô¨Åxed. Since
ÀúQ Xk(Œª1) P1 ‚ààRn√ór, there are orthogonal matrices ¬ØQ1 ‚ààR(n‚àíœÅ)√ó(n‚àíœÅ) and
¬ØP1 ‚ààRr√ór such that
¬ØQ ÀúQ Xk(Œª1) P1 ¬ØP1 =
‚éõ
‚éú‚éú‚éú‚éù
ÀúX11(Œª1)
0Àúr√ó(r‚àíÀúr)
0
0r‚àíÀúr
0
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr)
ÀúX41(Œª1)
ÀúX42(Œª1)
‚éû
‚éü‚éü‚éü‚é†,
¬ØQ :=
 ¬ØQ1 0
0 IœÅ

‚ààRn√ón,
where ÀúX11(Œª1) ‚ààRÀúr√óÀúr is invertible, ÀúX41(Œª1) ‚ààRœÅ√óÀúr, and ÀúX42(Œª1) ‚ààRœÅ√ó(r‚àíÀúr).
Note that the multiplication of equation (5.74) by the orthogonal matrix ¬ØQ from
the left does not change the structure of (5.74). Therefore, since the product ¬ØQ ÀúQ is
an orthogonal matrix, we may assume without loss of generality that the matrix ÀúQ
in (5.74) is such that
ÀúQ Xk(Œª1) P1 ¬ØP1 =
‚éõ
‚éú‚éú‚éú‚éù
ÀúX11(Œª1)
0Àúr√ó(r‚àíÀúr)
0
0r‚àíÀúr
0
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr)
ÀúX41(Œª1)
ÀúX42(Œª1)
‚éû
‚éü‚éü‚éü‚é†,
ÀúQ Xk(Œª) P2 ¬ØP2 =
‚éõ
‚éú‚éú‚éú‚éù
0Àúr
0Àúr√óœÅ
0
0(r‚àíÀúr)√óœÅ
0 0(n‚àír‚àíœÅ)√óœÅ
0
ÀúX44
‚éû
‚éü‚éü‚éü‚é†
for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0) with both ÀúX11(Œª1) ‚ààRÀúr√óÀúr and ÀúX44 ‚ààRœÅ√óœÅ invertible,
ÀúX41(Œª1) ‚ààRœÅ√óÀúr, and ÀúX42(Œª1) ‚ààRœÅ√ó(r‚àíÀúr). Next we observe that the multiplication
of the equations in (5.58) by the orthogonal matrix
¬ØP :=

¬ØP1
0r√ó(n‚àír)
0(n‚àír)√ór
¬ØP2

‚ààRn√ón

5.1
Nonlinear Dependence on Spectral Parameter
279
from the right does not change the structure of the formulas in (5.58). Therefore,
since the matrix P ¬ØP is orthogonal, we may assume without loss of generality that
the matrix P is such that
ÀúQ Xk(Œª1) P1 =
‚éõ
‚éú‚éú‚éú‚éù
ÀúX11(Œª1)
0Àúr√ó(r‚àíÀúr)
0
0r‚àíÀúr
0
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr)
ÀúX41(Œª1)
ÀúX42(Œª1)
‚éû
‚éü‚éü‚éü‚é†,
ÀúQ Xk(Œª) P2 =
‚éõ
‚éú‚éú‚éú‚éù
0Àúr
0Àúr√óœÅ
0
0(r‚àíÀúr)√óœÅ
0 0(n‚àír‚àíœÅ)√óœÅ
0
ÀúX44
‚éû
‚éü‚éü‚éü‚é†
(5.75)
for all Œª ‚àà(Œª0‚àíŒ¥, Œª0) with ÀúX11(Œª1) ‚ààRÀúr√óÀúr and ÀúX44 ‚ààRœÅ√óœÅ invertible, ÀúX41(Œª1) ‚àà
RœÅ√óÀúr, and ÀúX42(Œª1) ‚ààRœÅ√ó(r‚àíÀúr). Therefore, for Œª = Œª1 we have from (5.75)
ÀúQ Xk(Œª1) P =
‚éõ
‚éú‚éú‚éú‚éù
ÀúX11(Œª1)
0Àúr√ó(r‚àíÀúr)
0Àúr
0Àúr√óœÅ
0
0r‚àíÀúr
0
0(r‚àíÀúr)√óœÅ
0
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr) 0n‚àír‚àíœÅ 0(n‚àír‚àíœÅ)√óœÅ
ÀúX41(Œª1)
ÀúX42(Œª1)
0
ÀúX44
‚éû
‚éü‚éü‚éü‚é†
(5.76)
with ÀúX11(Œª1) ‚ààRÀúr√óÀúr and ÀúX44 ‚ààRœÅ√óœÅ invertible. We now calculate the sets
Im K := Ker ÀúQ Xk(Œª1) P,
Im ÀúK := Ker PT XT
k (Œª1) ÀúQT
(5.77)
for some matrices K and ÀúK. Since rank ÀúQ Xk(Œª1) P = rankX(Œª1) = rk =
Àúr + œÅ, we have def ÀúQ Xk(Œª1) P = n ‚àíÀúr ‚àíœÅ. And since rank ÀúQ Xk(Œª1) P =
rankPT XT
k (Œª1) ÀúQT , we have def PT XT
k (Œª1) ÀúQT = n ‚àíÀúr ‚àíœÅ as well. Therefore,
the matrices K, ÀúK ‚ààRn√ó(n‚àíÀúr‚àíœÅ). Denote within the reÔ¨Åned block structure
K =

Kij

,
ÀúK =
 ÀúKij

,
where i ‚àà{1, 2}, j ‚àà{1, 2, 3, 4}.
Then the Ô¨Årst equality in (5.77) yields through (5.76) that K11 = 0 and K12 = 0.
Then with the choice K21 := I, we get K41 = ‚àíÀúX‚àí1
44 ÀúX42(Œª1). With the additional
choice K22 := 0, K31 := 0, K32 := I, and K44 := 0, we obtain
K =
‚éõ
‚éú‚éú‚éú‚éù
0Àúr√ó(r‚àíÀúr)
0Àúr√ó(n‚àír‚àíœÅ)
Ir‚àíÀúr
0(r‚àíÀúr)√ó(n‚àír‚àíœÅ)
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr)
In‚àír‚àíœÅ
‚àíÀúX‚àí1
44 ÀúX42(Œª1)
0œÅ√ó(n‚àír‚àíœÅ)
‚éû
‚éü‚éü‚éü‚é†.

280
5
Discrete Symplectic Eigenvalue Problems
But since Im K = Ker ÀúQ Xk(Œª1) P is independent on Œª ‚àà(Œª0‚àíŒ¥, Œª0), it follows that
the matrix ÀúX42(Œª) ‚â°ÀúX42 is constant on (Œª0 ‚àíŒ¥, Œª0). Similarly, the second equality
in (5.77) yields ÀúK41 = 0, ÀúK42 = 0, and then ÀúK11 = 0 and ÀúK12 = 0. We then choose
ÀúK21 := I, ÀúK22 := 0, ÀúK31 := 0, and ÀúK32 := I. Therefore we proved
K=
‚éõ
‚éú‚éú‚éú‚éù
0Àúr√ó(r‚àíÀúr)
0Àúr√ó(n‚àír‚àíœÅ)
Ir‚àíÀúr
0(r‚àíÀúr)√ó(n‚àír‚àíœÅ)
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr)
In‚àír‚àíœÅ
‚àíÀúX‚àí1
44 ÀúX42
0œÅ√ó(n‚àír‚àíœÅ)
‚éû
‚éü‚éü‚éü‚é†, ÀúK=
‚éõ
‚éú‚éú‚éù
0Àúr√ó(r‚àíÀúr)
0Àúr√ó(n‚àír‚àíœÅ)
Ir‚àíÀúr
0(r‚àíÀúr)√ó(n‚àír‚àíœÅ)
0(n‚àír‚àíœÅ)√ó(r‚àíÀúr)
In‚àír‚àíœÅ
0œÅ√ó(r‚àíÀúr)
0œÅ√ó(n‚àír‚àíœÅ)
‚éû
‚éü‚éü‚é†.
Now from Theorem 5.3, the sets Ker Xk(Œª) and Ker XT
k (Œª) are constant on the
interval (Œª0 ‚àíŒ¥, Œª0), then also the sets Ker ÀúQ Xk(Œª) P and Ker PT XT
k (Œª) ÀúQT are
constant on (Œª0‚àíŒ¥, Œª0), which together with (5.76) implies the equality in (5.73) for
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0). And by the continuity of Xk(¬∑), we also have the formula in (5.73)
at Œª = Œª0. Finally, from rk = rankXk(Œª) = rank ÀúQ Xk(Œª) P, equation (5.76), and
the invertibility of ÀúX44, we get rank ÀúX11(Œª) = Àúr for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0), i.e., ÀúX11(Œª)
is invertible on (Œª0 ‚àíŒ¥, Œª0).
‚äì‚äî
Within the reÔ¨Åned block structure, we deÔ¨Åne for any Œª ‚ààR the matrices
ÀúXk(Œª) := ÀúQ Xk(Œª) P =  ÀúXij (Œª)
 ,
ÀúUk(Œª) := ÀúQ Uk(Œª) P =  ÀúUij(Œª)
 ,
(5.78)
where i, j ‚àà{1, 2, 3, 4} and ÀúQ, P ‚ààRn√ón are from Lemma 5.22. Then for Œª ‚àà
(Œª0 ‚àíŒ¥, Œª0], the matrix ÀúXk(Œª) is given by formula (5.73).
Lemma 5.23 There are orthogonal matrices P, Q,
ÀúQ satisfying Lemmas 5.19
and 5.22 and
ÀúQ Uk(Œª) P =
‚éõ
‚éú‚éú‚éú‚éú‚éù
ÀúU11(Œª) ÀúU12(Œª)
0
ÀúU14
ÀúU21(Œª) ÀúU22(Œª)
0
ÀúU24
ÀúU31(Œª) ÀúU32(Œª) ÀúU33 ÀúU34
ÀúU41(Œª)
ÀúU42
0
ÀúU44
‚éû
‚éü‚éü‚éü‚éü‚é†
,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.79)
where ÀúU33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ) is invertible.
Proof Since Uk(Œª) P2 is independent of Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] by Remark 5.13 with
j = k, the third and fourth block columns of ÀúUk(Œª) are constant in Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
i.e., ÀúUij(Œª) ‚â°ÀúUij on (Œª0 ‚àíŒ¥, Œª0] for i ‚àà{3, 4} and j ‚àà{1, 2, 3, 4}. Since
ÀúXT
k (Œª) ÀúUk(Œª)
(5.78)
=
PT XT
k (Œª) Uk(Œª) P,
Œª ‚ààR,

5.1
Nonlinear Dependence on Spectral Parameter
281
the matrix ÀúXT
k (Œª) ÀúUk(Œª) is symmetric for all Œª ‚ààR. From this and (5.73), we
conclude that with ÀúF1j(Œª) := ÀúXT
11(Œª) ÀúU1j(Œª) + ÀúXT
41(Œª) ÀúU4j(Œª), j ‚àà{1, 2, 3, 4},
the matrix
‚éõ
‚éú‚éú‚éú‚éú‚éù
ÀúF11(Œª)
ÀúF12(Œª)
ÀúF13(Œª)
ÀúF14(Œª)
ÀúXT
42 ÀúU41(Œª) ÀúXT
42 ÀúU42(Œª) ÀúXT
42 ÀúU43 ÀúXT
42 ÀúU44
0
0
0
0
ÀúXT
44 ÀúU41(Œª) ÀúXT
44 ÀúU42(Œª) ÀúXT
44 ÀúU43 ÀúXT
44 ÀúU44
‚éû
‚éü‚éü‚éü‚éü‚é†
is symmetric for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
Then since ÀúX44 is invertible, we obtain ÀúU43 = 0, and in turn since ÀúX11(Œª) is
invertible for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0), we have ÀúU13 = 0. Next, the equality ÀúXT
44 ÀúU42(Œª) =
( ÀúXT
42 ÀúU44)T yields that ÀúU42(Œª) ‚â°ÀúXT ‚àí1
44
ÀúUT
44 ÀúX42 =: ÀúU42 is constant on (Œª0 ‚àíŒ¥, Œª0].
Next, for every Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
n=rank

XT
k (Œª), UT
k (Œª)

= rank
 ÀúXT
k (Œª), ÀúUT
k (Œª)

=rank
‚éõ
‚éú‚éú‚éú‚éú‚éù
ÀúXT
11(Œª)
0
0
ÀúXT
41(Œª) ÀúUT
11(Œª) ÀúUT
21(Œª) ÀúUT
31(Œª) ÀúUT
41(Œª)
0
0r‚àíÀúr
0
ÀúXT
42
ÀúUT
12(Œª) ÀúUT
22(Œª) ÀúUT
32(Œª)
ÀúUT
42
0
0
0n‚àír‚àíœÅ
0
0
ÀúUT
23
ÀúUT
33
0
0
0
0
ÀúXT
44
ÀúUT
14
ÀúUT
24
ÀúUT
34
ÀúUT
44
‚éû
‚éü‚éü‚éü‚éü‚é†
,
where ÀúU23 ‚ààR(r‚àíÀúr)√ó(n‚àír‚àíœÅ), ÀúU33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ), and rank( ÀúUT
23,
ÀúUT
33) =
n ‚àír ‚àíœÅ. Hence, there exists an orthogonal matrix ¬ØR2 ‚ààR(n‚àíÀúr‚àíœÅ)√ó(n‚àíÀúr‚àíœÅ) with
¬ØR2
 ÀúU23
ÀúU33

=

0(r‚àíÀúr)√ó(n‚àír‚àíœÅ)
¬ØU33

,
where ¬ØU33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ) is invertible. Now the multiplication of ÀúXk(Œª) and
ÀúUk(Œª) by the orthogonal matrix
¬ØR :=
‚éõ
‚éù
IÀúr 0
0
0 ¬ØR2 0
0 0 IœÅ
‚éû
‚é†‚ààRn√ón
from the left does not change the structure of ÀúXk(Œª) and ÀúUk(Œª) in (5.78). Therefore,
since the matrix ¬ØR ÀúQ is orthogonal, we may assume without loss of generality that
the matrix ÀúQ in (5.78) is such that equation (5.79) holds. The proof of this lemma is
complete.
‚äì‚äî

282
5
Discrete Symplectic Eigenvalue Problems
Finally, we Ô¨Ånish the construction of ÀúUk+1(Œª) within the reÔ¨Åned matrix block
structure.
Lemma 5.24 There are orthogonal matrices P, Q,
ÀúQ satisfying Lemmas 5.19
and 5.22 and 5.23, and such that the matrix U22 ‚ààR(n‚àír)√ó(n‚àír) in (5.58) satisÔ¨Åes
U22 =
 ¬ØU33 ¬ØU34
0
¬ØU44

,
U‚àí1
22 =
 ¬ØU‚àí1
33 ‚àí¬ØU‚àí1
33
¬ØU34 ¬ØU‚àí1
44
0
¬ØU‚àí1
44

,
(5.80)
where the matrices ¬ØU33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ) and ¬ØU44 ‚ààRœÅ√óœÅ are invertible.
Proof There exists an orthogonal matrix ¬ØS2 ‚ààR(n‚àír)√ó(n‚àír) such that the matrix
¬ØS2 U22 is upper block-triangular, i.e., we have
¬ØS2 U22 =
 ¬ØU33 ¬ØU34
0
¬ØU44

with ¬ØU33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ) and ¬ØU44 ‚ààRœÅ√óœÅ invertible, because U22 is invertible.
The multiplication of the formulas in (5.68) by the orthogonal matrix
¬ØS :=

Ir 0
0 ¬ØS2

‚ààRn√ón
from the left does not change the structure of (5.68), and the matrix ¬ØSQ is
orthogonal. Hence, we may assume without loss of generality that the matrix Q
in Lemmas 5.19, 5.22, and 5.23 satisÔ¨Åes the Ô¨Årst equation in (5.80). The formula for
the inverse of U22 is then veriÔ¨Åed by a direct calculation.
‚äì‚äî
5.1.5
Construction of Auxiliary Symplectic System
Recall that the fact that Sk(Œª) is symplectic implies by Lemma 1.58(iii) that ST
k (Œª)
is symplectic as well. Therefore, the coefÔ¨Åcients of system (SDSŒª) satisfy for every
k ‚àà[0, N]Z and Œª ‚ààR the identities
AT
k (Œª) Ck(Œª) = CT
k (Œª) Ak(Œª),
BT
k (Œª) Dk(Œª) = DT
k (Œª) Bk(Œª),
Ak(Œª) BT
k (Œª) = Bk(Œª) AT
k (Œª),
Dk(Œª) CT
k (Œª) = Ck(Œª) DT
k (Œª),
AT
k (Œª) Dk(Œª) ‚àíCT
k (Œª) Bk(Œª) = I,
Dk(Œª) AT
k (Œª) ‚àíCk(Œª) BT
k (Œª) = I.
‚é´
‚é™‚é¨
‚é™‚é≠
(5.81)

5.1
Nonlinear Dependence on Spectral Parameter
283
Upon differentiating the above formulas with respect to Œª, we get
ÀôAT
k (Œª) Ck(Œª) + AT
k (Œª) ÀôCk(Œª) = ÀôCT
k (Œª) Ak(Œª) + CT
k (Œª) ÀôAk(Œª),
ÀôBT
k (Œª) Dk(Œª) + BT
k (Œª) ÀôDk(Œª) = ÀôDT
k (Œª) Bk(Œª) + DT
k (Œª) ÀôBk(Œª),
ÀôAT
k (Œª) Dk(Œª) + AT
k (Œª) ÀôDk(Œª) = ÀôCT
k (Œª) Bk(Œª) + CT
k (Œª) ÀôBk(Œª),
ÀôDk(Œª) CT
k (Œª) + Dk(Œª) ÀôCT
k (Œª) = ÀôCk(Œª) DT
k (Œª) + Ck(Œª) ÀôDT
k (Œª),
ÀôAk(Œª) BT
k (Œª) + Ak(Œª) ÀôBT
k (Œª) = ÀôBk(Œª) AT
k (Œª) + Bk(Œª) ÀôAT
k (Œª),
ÀôDk(Œª) AT
k (Œª) + Dk(Œª) ÀôAT
k (Œª) = ÀôCk(Œª) BT
k (Œª) + Ck(Œª) ÀôBT
k (Œª).
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(5.82)
For the matrix k(Œª) in (5.3), we have
k(Œª) =
 ÀôDk(Œª) CT
k (Œª) ‚àíÀôCk(Œª) DT
k (Œª) ÀôCk(Œª) BT
k (Œª) ‚àíÀôDk(Œª) AT
k (Œª)
ÀôAk(Œª) DT
k (Œª) ‚àíÀôBk(Œª) CT
k (Œª) ÀôBk(Œª) AT
k (Œª) ‚àíÀôAk(Œª) BT
k (Œª)

.
(5.83)
One can now see the symmetry of k(Œª) directly from (5.82).
With the aid of the orthogonal matrices P, Q, and ÀúQ from Lemma 5.24, we now
construct an auxiliary symplectic system between the indices k and k + 1. For every
Œª ‚ààR, we deÔ¨Åne the n √ó n matrices
ÀúAk(Œª) := Q Ak(Œª) ÀúQT =
A11(Œª) A12(Œª)
A21(Œª) A22(Œª)

=
‚éõ
‚éú‚éú‚éú‚éú‚éù
¬ØA11(Œª) ¬ØA12(Œª) ¬ØA13(Œª) ¬ØA14(Œª)
¬ØA21(Œª) ¬ØA22(Œª) ¬ØA23(Œª) ¬ØA24(Œª)
¬ØA31(Œª) ¬ØA32(Œª) ¬ØA33(Œª) ¬ØA34(Œª)
¬ØA41(Œª) ¬ØA42(Œª) ¬ØA43(Œª) ¬ØA44(Œª)
‚éû
‚éü‚éü‚éü‚éü‚é†
and similarly
ÀúBk(Œª) := Q Bk(Œª) ÀúQT = 
Bij (Œª)

i,j‚àà{1,2} =  ¬ØBij (Œª)

i,j‚àà{1,2,3,4} ,
ÀúCk(Œª) := Q Ck(Œª) ÀúQT = 
Cij(Œª)

i,j‚àà{1,2} =  ¬ØCij (Œª)

i,j‚àà{1,2,3,4} ,
ÀúDk(Œª) := Q Dk(Œª) ÀúQT = 
Dij (Œª)

i,j‚àà{1,2} =  ¬ØDij(Œª)

i,j‚àà{1,2,3,4} ,
where the matrices Aij(Œª), Bij(Œª), Cij (Œª), Dij (Œª) are formed within the block
structure with n = r + (n ‚àír) as in Lemma 5.19 and the matrices ¬ØAij(Œª),
¬ØBij(Œª), ¬ØCij(Œª), ¬ØDij (Œª) are formed within the reÔ¨Åned block structure with n =
Àúr + (r ‚àíÀúr) + (n ‚àír ‚àíœÅ) + œÅ as in Lemmas 5.22 and 5.23. Then the 2n √ó 2n
matrix
ÀúSk(Œª) :=
 ÀúAk(Œª) ÀúBk(Œª)
ÀúCk(Œª) ÀúDk(Œª)

=
Q 0
0 Q

Sk(Œª)
 ÀúQT
0
0
ÀúQT

(5.84)

284
5
Discrete Symplectic Eigenvalue Problems
is symplectic as a product of three symplectic matrices; see Lemma 1.58(i) and
Remark 1.59. Consequently, the matrices ÀúXk(Œª), ÀúUk(Œª), ÀúXk+1(Œª), ÀúUk+1(Œª) given
in (5.78) and (5.68) satisfy for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] the symplectic system
ÀúXk+1(Œª) = ÀúAk(Œª) ÀúXk(Œª) + ÀúBk(Œª) ÀúUk(Œª),
ÀúUk+1(Œª) = ÀúCk(Œª) ÀúXk(Œª) + ÀúDk(Œª) ÀúUk(Œª),

(5.85)
as well as, by (2.10), the time-reversed equations
ÀúXk(Œª) = ÀúDT
k (Œª) ÀúXk+1(Œª) ‚àíÀúBT
k (Œª) ÀúUk+1(Œª),
ÀúUk(Œª) = ‚àíÀúCT
k (Œª) ÀúXk+1(Œª) + ÀúAT
k (Œª) ÀúUk+1(Œª).

(5.86)
It follows that
 ÀúYj(Œª)

j‚àà{k,k+1} = ( ÀúXj(Œª), ÀúUj(Œª))j‚àà{k,k+1} is a conjoined basis of
system (5.85). Next, we deÔ¨Åne for Œª ‚ààR the symmetric 2n √ó 2n matrix
Àúk(Œª) := J
d
dŒª [ ÀúSk(Œª)] J ÀúST
k (Œª) J
(5.84)
=
Q 0
0 Q

k(Œª)
QT
0
0 QT
 (5.3)
‚â•0.
(5.87)
Now we analyze the structure of the coefÔ¨Åcients of system (5.85).
Lemma 5.25 Given the above coefÔ¨Åcients
ÀúAk(Œª), ÀúBk(Œª), ÀúCk(Œª), ÀúDk(Œª) and the
matrices ÀúXk(Œª), ÀúUk(Œª) in (5.78) and ÀúXk+1(Œª), ÀúUk+1(Œª) in (5.68), we have for all
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
ÀúBk(Œª)=
 B11(Œª) B12(Œª)
0(n‚àír)√ór
B22

, B12(Œª)=
0 ¬ØB14(Œª)
0 ¬ØB24(Œª)

, B22 =
0n‚àír‚àíœÅ 0
0
¬ØB44

,
(5.88)
where ¬ØB44 ‚ààRœÅ√óœÅ is invertible,
ÀúDk(Œª)=
D11(Œª)D12(Œª)
D21(Œª)D22(Œª)

, D12(Œª)=
0 ¬ØD14(Œª)
0 ¬ØD24(Œª)

, D22(Œª)=
 ¬ØD33 ¬ØD34(Œª)
0
¬ØD44(Œª)

,
(5.89)
where ¬ØD33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ) is invertible,
ÀúAk(Œª)=
A11(Œª)A12(Œª)
A21
A22

, A21 =
 0
0
¬ØA41 ¬ØA42

, A22(Œª)=
 ¬ØA33 0
¬ØA43 ¬ØA44

,
(5.90)
and where ¬ØA33 ‚ààR(n‚àír‚àíœÅ)√ó(n‚àír‚àíœÅ) and ¬ØA44 ‚ààRœÅ√óœÅ are invertible. Moreover,
Y11(Œª) :=
 ÀúX11(Œª)
0
0
0r‚àíÀúr

= DT
11(Œª) X11(Œª) ‚àíBT
11(Œª) U11(Œª),
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.91)

5.1
Nonlinear Dependence on Spectral Parameter
285
and the matrices B11(Œª), D11(Œª) ‚ààRr√ór satisfy for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
BT
11(Œª) D11(Œª) is symmetric and rank
BT
11(Œª), DT
11(Œª)
 = r.
(5.92)
Proof The Ô¨Årst equation in (5.86) for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] yields in its diagonal blocks
and in the right upper block, respectively, the equations
 ÀúX11(Œª) 0
0
0

= DT
11(Œª) X11(Œª) ‚àí

BT
11(Œª) U11(Œª) + BT
21(Œª) U21(Œª)

,
0
0
0 ÀúX44

= ‚àíBT
22(Œª) U22,
0 = ‚àíBT
21(Œª) U22.
Since U22 is invertible, we obtain B21(Œª)
‚â°
0 on (Œª0 ‚àíŒ¥, Œª0], and then
equation (5.91) is satisÔ¨Åed. Next, by (5.80), for every Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], we have
0
0
0 ÀúX44

= ‚àí
 ¬ØBT
33(Œª) ¬ØBT
43(Œª)
¬ØBT
34(Œª) ¬ØBT
33(Œª)
  ¬ØU33 ¬ØU34
0
¬ØU44

.
Since ¬ØU33 is invertible, this yields that ¬ØB33(Œª) ‚â°0 and ¬ØB34(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0],
and then since ¬ØU44 is invertible, ¬ØB43(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0]. Finally, the equation
ÀúX44 = ‚àí¬ØBT
44(Œª) ¬ØU44 on (Œª0 ‚àíŒ¥, Œª0] implies that ¬ØB44(Œª) ‚â°‚àí¬ØUT ‚àí1
44
ÀúXT
44 =: ¬ØB44 ‚àà
RœÅ√óœÅ is constant and invertible on (Œª0 ‚àíŒ¥, Œª0] and B22(Œª) ‚â°B22 is constant on
(Œª0 ‚àíŒ¥, Œª0]. Next, the Ô¨Årst equation in (5.85), in particular its third column in the
reÔ¨Åned block structure, yields through (5.68), (5.73), and (5.79) that ¬ØB13(Œª) ÀúU33 = 0
and ¬ØB23(Œª) ÀúU33 = 0 hold on (Œª0 ‚àíŒ¥, Œª0]. Since ÀúU33 is invertible, we get ¬ØB13(Œª) ‚â°0
and ¬ØB23(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0]. Therefore, we showed that for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
equation (5.88) holds with the matrix ¬ØB44 ‚ààRœÅ√óœÅ invertible.
Next, from the second equation in (5.85), in particular from its third column
in the reÔ¨Åned block structure, we get via (5.68), (5.73), (5.79), and (5.80) that
¬ØD13(Œª) ÀúU33 = 0, ¬ØD23(Œª) ÀúU33 = 0, ¬ØD33(Œª) ÀúU33 = ¬ØU33, and ¬ØD43(Œª) ÀúU33 = 0 on
(Œª0 ‚àíŒ¥, Œª0]. And since ÀúU33 is invertible, it follows that ¬ØD13(Œª) ‚â°0, ¬ØD23(Œª) ‚â°0,
¬ØD33(Œª) ‚â°¬ØU33 ÀúU‚àí1
33
=:
¬ØD33, and ¬ØD43(Œª) ‚â°0 on (Œª0 ‚àíŒ¥, Œª0]. This shows that
equality (5.89) holds.
Since the matrix ÀúSk(Œª) is symplectic, we have from (1.145) that
ÀúBT
k (Œª) ÀúDk(Œª) =

BT
11(Œª) D11(Œª)
BT
11(Œª) D12(Œª)
BT
12(Œª) D11(Œª) + BT
22 D21(Œª) BT
12(Œª) D12(Œª) + BT
22 D22(Œª)

is symmetric for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. This implies that BT
11(Œª) D11(Œª) is symmetric
for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] and that
BT
11(Œª) D12(Œª) =

BT
12(Œª) D11(Œª) + BT
22 D21(Œª)
T ,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.93)

286
5
Discrete Symplectic Eigenvalue Problems
By extracting the second column of (5.93) in the reÔ¨Åned block structure, we get
BT
11(Œª)
 ¬ØD14(Œª)
¬ØD24(Œª)

= DT
11(Œª)
 ¬ØB14(Œª)
¬ØB24(Œª)

+
 ¬ØDT
41(Œª)
¬ØDT
24(Œª)

¬ØB44,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
And since ¬ØB44 is invertible, it follows that
 ¬ØDT
41(Œª)
¬ØDT
24(Œª)

‚ààIm 
BT
11(Œª), DT
11(Œª)
 ,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.94)
From the identity
ÀúAT
k (Œª) ÀúDk(Œª) ‚àíÀúCT
k (Œª) ÀúBk(Œª) = I for all Œª ‚ààR, compare
with (5.81), we have rank ÀúBT
k (Œª),
ÀúDT
k (Œª) = n, so that by (5.88) and (5.89) and
the invertibility of ¬ØB44 and ¬ØD33
n = rank
‚éõ
‚éú‚éú‚éú‚éú‚éù
¬ØBT
11(Œª) ¬ØBT
21(Œª) 0 0
¬ØDT
11(Œª) ¬ØDT
21(Œª) ¬ØDT
31(Œª)
¬ØDT
41(Œª)
¬ØBT
12(Œª) ¬ØBT
22(Œª) 0 0
¬ØDT
12(Œª) ¬ØDT
22(Œª) ¬ØDT
32(Œª)
¬ØDT
42(Œª)
0
0
0 0
0
0
¬ØDT
33
0
¬ØBT
14(Œª) ¬ØBT
24(Œª) 0 ¬ØBT
44 ¬ØDT
14(Œª) ¬ØDT
24(Œª) ¬ØDT
34(Œª) ¬ØDT
441(Œª)
‚éû
‚éü‚éü‚éü‚éü‚é†
= rank
‚éõ
‚éú‚éú‚éú‚éú‚éù
¬ØBT
11(Œª) ¬ØBT
21(Œª) 0 0
¬ØDT
11(Œª) ¬ØDT
21(Œª)
0
¬ØDT
41(Œª)
¬ØBT
12(Œª) ¬ØBT
22(Œª) 0 0
¬ØDT
12(Œª) ¬ØDT
22(Œª)
0
¬ØDT
42(Œª)
0
0
0 0
0
0
In‚àír‚àíœÅ
0
0
0
0 IœÅ
0
0
0
0
‚éû
‚éü‚éü‚éü‚éü‚é†
.
(5.95)
for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]. If we now interchange in (5.95) the third and seventh columns
and use condition (5.94), we obtain from (5.95) that for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
n = rank

BT
11(Œª) 0r√ó(n‚àír) DT
11(Œª) 0r√ó(n‚àír)
0(n‚àír)√ór
In‚àír
0(n‚àír)√ór
0n‚àír

= rank 
BT
11(Œª), DT
11(Œª)
 + n ‚àír.
Therefore, rankBT
11(Œª), DT
11(Œª) = r and condition (5.92) is established.
It remains to prove (5.90). From the second equation in (5.86), in particular from
its third and fourth columns in the reÔ¨Åned block structure, we have
AT
21(Œª) U22 =

0 ÀúU14
0 ÀúU24

,
AT
22(Œª) U22 =
 ÀúU33 ÀúU34
0
ÀúU44

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
Since by Lemma 5.24 the matrix U22 is invertible, it follows from (5.80) that
A21(Œª) ‚â°A21 and A22(Œª) ‚â°A22 are constant on (Œª0 ‚àíŒ¥, Œª0] and that on this

5.1
Nonlinear Dependence on Spectral Parameter
287
interval ¬ØA31(Œª) ‚â°0, ¬ØA32(Œª) ‚â°0, ¬ØA41(Œª) ‚â°
¬ØUT ‚àí1
44
ÀúUT
14 =:
¬ØA41, ¬ØA42(Œª) ‚â°
¬ØUT ‚àí1
44
ÀúUT
24 =:
¬ØA42, ¬ØA33(Œª) ‚â°
¬ØUT ‚àí1
33
ÀúUT
33 =:
¬ØA33 is invertible, ¬ØA34(Œª) ‚â°0,
¬ØA43(Œª) ‚â°
¬ØA43 is constant, and ¬ØA44(Œª) ‚â°
¬ØUT ‚àí1
44
ÀúUT
44 =:
¬ØA44 is invertible. The
proof is complete.
‚äì‚äî
Following Lemma 5.25, let us now analyze the structure of the matrix Àúk(Œª)
in (5.87). By (5.83) we have for any Œª ‚ààR
Àúk(Œª) =
 ÀôÀúDk(Œª) ÀúCT
k (Œª) ‚àíÀôÀúCk(Œª) ÀúDT
k (Œª) ÀôÀúCk(Œª) ÀúBT
k (Œª) ‚àíÀôÀúDk(Œª) ÀúAT
k (Œª)
ÀôÀúAk(Œª) ÀúDT
k (Œª) ‚àíÀôÀúBk(Œª) ÀúCT
k (Œª) ÀôÀúBk(Œª) ÀúAT
k (Œª) ‚àíÀôÀúAk(Œª) ÀúBT
k (Œª)

=:
 ÀúHk(Œª) ÀúGk(Œª)
ÀúFk(Œª) ÀúEk(Œª)

,
(5.96)
and Àúk(Œª) is symmetric. Then the matrices ÀúHk(Œª) and ÀúEk(Œª) are symmetric as well.
For brevity, we introduce the following notation for the row block columns of the
matrices ÀúAk(Œª), ÀúBk(Œª), ÀúCk(Œª), ÀúDk(Œª) as
A1(Œª) :=

A11(Œª), A12(Œª)

,
A2(Œª) :=

A21(Œª), A22(Œª)

,
B1(Œª) :=

B11(Œª), B12(Œª)

,
B2(Œª) :=

B21(Œª), B22(Œª)

,
C1(Œª) :=

C11(Œª), C12(Œª)

,
C2(Œª) :=

C21(Œª), C22(Œª)

,
D1(Œª) :=

D11(Œª), D12(Œª)

,
D2(Œª) :=

D21(Œª), D22(Œª)

.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.97)
Then A1(Œª) ‚ààRr√ón and A2(Œª) ‚ààR(n‚àír)√ón and similarly for the other matrices
above. Then, by the form of the coefÔ¨Åcients ÀúAk(Œª), ÀúBk(Œª), ÀúDk(Œª) in (5.88)‚Äì(5.90),
we obtain
ÀúHk(Œª) =
H11(Œª) H12(Œª)
H21(Œª) H22(Œª)

,
ÀúGk(Œª) =
G11(Œª)
0
G21(Œª) 0n‚àír

,
ÀúFk(Œª) =
F11(Œª) F12(Œª)
0
0n‚àír

,
ÀúEk(Œª) =
E11(Œª)
0
0
0n‚àír

,
‚é´
‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é≠
(5.98)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], where
Hij(Œª) := ÀôDi(Œª) CT
j (Œª) ‚àíÀôCi(Œª) DT
j (Œª),
Gij(Œª) := ÀôCi(Œª) BT
j (Œª) ‚àíÀôDi(Œª) AT
j (Œª),
Fij(Œª) := ÀôAi(Œª) DT
j (Œª) ‚àíÀôBi(Œª) CT
j (Œª),
Eij(Œª) := ÀôBi(Œª) AT
j (Œª) ‚àíÀôAi(Œª) BT
j (Œª),
‚é´
‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é≠
i, j ‚àà{1, 2},
(5.99)
and where Hii(Œª) and Eii(Œª) are symmetric and GT
ij(Œª) = Fji(Œª) for i, j ‚àà{1, 2}.

288
5
Discrete Symplectic Eigenvalue Problems
Our next aim is to analyze the behavior of the r √ó r matrix P11(Œª) deÔ¨Åned by
P11(Œª) := BT
11(Œª) D11(Œª) ‚àíBT
11(Œª) Q11(Œª) B11(Œª),
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.100)
Q11(Œª) := U11(Œª) X‚àí1
11 (Œª),
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.101)
where X11(Œª) and U11(Œª) are from (5.58) and B11(Œª), D11(Œª) are from (5.88),
(5.89). For this we need to know Ô¨Årst the behavior of the function Q11(Œª) on
(Œª0 ‚àíŒ¥, Œª0). We deÔ¨Åne the n √ó n matrix
ÀúLk(Œª) := PT Lk(Œª) P,
Lk(Œª) :=

In, 0n

k(Œª)

In, 0n
T ,
(5.102)
where k(Œª) is deÔ¨Åned in (5.32).
Lemma 5.26 The symmetric matrix Q11(Œª) deÔ¨Åned in (5.101) satisÔ¨Åes
ÀôQ11(Œª) = ‚àí
XT ‚àí1
11
(Œª), 0r√ó(n‚àír)
 ÀúLk(Œª)
 X‚àí1
11 (Œª)
0(n‚àír)√ór

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0).
(5.103)
Consequently, under (5.3), the function Q11(¬∑) is nonincreasing on (Œª0 ‚àíŒ¥, Œª0).
Proof We suppress the argument Œª. First note that by (5.31)
XT
k+1 ÀôUk+1 ‚àíUT
k+1 ÀôXk+1 =

I 0
 ÀúZT
k+1 J ÀôÀúZk+1

I 0
T = ‚àíLk(Œª)
(5.104)
on R. From this and from
d
dŒª X‚àí1
11 = ‚àíX‚àí1
11 ÀôX11X‚àí1
11 , we conclude that on (Œª0 ‚àí
Œ¥, Œª0)
ÀôQ11
(5.59)
=
XT ‚àí1
11
(XT
11 ÀôU11 ‚àíUT
11 ÀôX11) X‚àí1
11
(5.68)
=

XT ‚àí1
11 , 0r√ó(n‚àír)
 
 ÀúXT
k+1
d
dŒª ÀúUk+1 ‚àíÀúUT
k+1
d
dŒª ÀúXk+1
 
XT ‚àí1
11 , 0r√ó(n‚àír)
T
(5.69)
=

XT ‚àí1
11
, 0

PT [XT
k+1 ÀôUk+1 ‚àíUT
k+1 ÀôXk+1] P

XT ‚àí1
11
, 0
T
(5.104)
=
‚àí
XT ‚àí1
11
, 0
 ÀúLk

XT ‚àí1
11
, 0
T ,
which shows the result in (5.103). Under (5.3) we then get ÀôQ11(Œª) ‚â§0 for all
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0). Hence, the function Q11(¬∑) is nonincreasing on (Œª0 ‚àíŒ¥, Œª0).
‚äì‚äî

5.1
Nonlinear Dependence on Spectral Parameter
289
Remark 5.27 If Xk+1(Œª) is invertible on (Œª0 ‚àíŒ¥, Œª0), then r = n, and so no
construction of the matrices P and Q in Lemma 5.19 is needed. In this case we
get from (5.103), (5.102), and (5.31) the following identity for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0)
ÀôQk+1(Œª) = ‚àíXT ‚àí1
k+1 (Œª)
+
k

j=0
Y T
j+1(Œª) j(Œª) Yj+1(Œª)
,
X‚àí1
k+1(Œª),
where Qk+1(Œª) := Uk+1(Œª) X‚àí1
k+1(Œª).
We will see in Lemma 5.28 that the behavior of the matrix P11(Œª) is determined
by the behavior of Q11(Œª). Namely, since Q11(Œª) is nonincreasing, and hence the
function ‚àíBT
11(Œª) Q11(Œª) B11(Œª) appearing in P11(Œª) is nondecreasing, then this
behavior is not destroyed by the additional term BT
11(Œª) D11(Œª). This is similar as in
the linear case in (5.238) with (5.241), in which Q11(Œª) is (of course) nonincreasing
and
P11(Œª) = BT
11D11 ‚àíŒª BT
11W11B11 ‚àíBT
11 Q11(Œª) B11
is nondecreasing, even though W11 ‚â•0, see [102, pg. 601] and [211, Proposi-
tion 4.1].
Lemma 5.28 The symmetric matrix P11(Œª) deÔ¨Åned in (5.100) satisÔ¨Åes
ÀôP11(Œª) = BT
11(Œª) œí11(Œª) B11(Œª) + RT
11(Œª) E11(Œª) R11(Œª),
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.105)
where the matrix E11(Œª) ‚ààRr√ór is deÔ¨Åned in (5.99) and
œí11(Œª) :=

XT ‚àí1
11
(Œª), 0
 ÀúLk‚àí1(Œª)

XT ‚àí1
11
(Œª), 0
T ‚ààRr√ór,
(5.106)
R11(Œª) := Q11(Œª) B11(Œª) ‚àíD11(Œª) ‚ààRr√ór,
(5.107)
and where the matrix ÀúLk‚àí1(Œª) is given by (5.102) with the index k‚àí1. Consequently,
under (5.3) the function P11(¬∑) is nondecreasing on (Œª0 ‚àíŒ¥, Œª0).
Proof We suppress the argument Œª in this proof. First note that by (5.96), (5.98),
and the form of ÀúXk+1 and ÀúUk+1 in (5.68)
11 :=

XT ‚àí1
11
, 0
 ÀúY T
k+1 Àúk ÀúYk+1

XT ‚àí1
11
, 0
T
(5.68)
=

Ir, 0(n‚àír)√ór, Q11, QT
21
 Àúk

Ir, 0(n‚àír)√ór, Q11, QT
21
T
(5.96), (5.98)
=

I, Q11
 H11 G11
F11 E11
  I
Q11

,
(5.108)

290
5
Discrete Symplectic Eigenvalue Problems
where Q11 = U11X‚àí1
11 as above, Q21 := U21X‚àí1
11 , and H11, G11, F11, E11 are given
in (5.99), implying that H11 and E11 are symmetric and F11 = GT
11. Now we use
Lemma 5.26 to get
‚àíÀôQ11
(5.103)
=

XT ‚àí1
11 , 0
  ÀúLk‚àí1 + ÀúY T
k+1 Àúk ÀúYk+1
 
XT ‚àí1
11 , 0
T
(5.106), (5.108)
=
œí11 + 11
on (Œª0 ‚àíŒ¥, Œª0).
(5.109)
After these preparatory calculations, we have from (5.100)
ÀôP11 = ÀôBT
11 D11 + BT
11 ÀôD11 ‚àíÀôBT
11 Q11 B11 ‚àíBT
11 ÀôQ11 B11 ‚àíBT
11 Q11 ÀôB11
(5.109)
=
BT
11 œí11 B11 + S11,
(5.110)
where the matrix S11 is deÔ¨Åned by
S11 := ÀôBT
11 D11+BT
11 ÀôD11‚àíÀôBT
11 Q11 B11‚àíBT
11 Q11 ÀôB11+BT
11 11 B11.
(5.111)
If we show that S11 = RT
11 E11 R11 with R11 given in (5.107), then the required
identity in (5.105) will follow from equation (5.110). Consider now the identities
in (5.81) written for the auxiliary symplectic system (5.85) with the coefÔ¨Åcients ÀúAk,
ÀúBk, ÀúCk, ÀúDk and with their block structure (5.97). From the symmetry of the matrices
ÀúDk ÀúCT
k and ÀúAk ÀúBT
k and from the identity ÀúDk ÀúAT
k ‚àíÀúCk ÀúBT
k = In, we obtain
D1 CT
1 = C1 DT
1 , A1 BT
1 = B1 AT
1 , D1 AT
1 ‚àíC1 BT
1 = Ir, A2 BT
1 = B2 AT
1 ,
(5.112)
and from the symmetry of the matrix ÀúBT
k ÀúDk and from ÀúAT
k ÀúDk ‚àíÀúCT
k ÀúBk = In, we get
BT
11 D11 = DT
11 B11,
BT
12 D11 + BT
22 D21 ‚àíDT
12 B11 = 0(n‚àír)√ór,
(5.113)
AT
11 D11 + AT
21 D21 ‚àíCT
11 B11 = Ir,
AT
12 D11 + AT
22 D21 ‚àíCT
12 B11 = 0(n‚àír)√ór.
(5.114)
Consider the identities in (5.82) written in terms of ÀúAk, ÀúBk, ÀúCk, ÀúDk. By (5.82)(vi),
ÀôD1 AT
2 = ÀôC1 BT
2 ,
(5.115)
while from (5.82)(ii), we have
ÀôBT
11 D1 + BT
11 ÀôD1 = ÀôDT
11 B1 + DT
11 ÀôB1 + ÀôDT
21 B2,
(5.116)

5.1
Nonlinear Dependence on Spectral Parameter
291
and Ô¨Ånally from (5.82)(iii), we obtain
DT
11 ÀôA1 + ÀôDT
11 A1 + ÀôDT
21 A2 = BT
11 ÀôC1 + ÀôBT
11 C1.
(5.117)
Then we calculate by using the deÔ¨Ånitions of G11 and E11 in (5.99)
BT
11 G11
(5.116), (5.117)
=
DT
11 ( ÀôA1 BT
1 ‚àíÀôB1 AT
1 ) + ÀôDT
11 (A1 BT
1 ‚àíB1 AT
1 )
+ ÀôBT
11 (D1 AT
1 ‚àíC1 BT
1 ) + ÀôDT
21 (A2 BT
1 ‚àíB2 AT
1 )
(5.99), (5.112)
=
ÀôBT
11 ‚àíDT
11 E11.
(5.118)
Therefore, by using the identity
ÀôA1 DT
1 ‚àíÀôB1 CT
1
(5.99)
= F11 = GT
11 = B1 ÀôCT
1 ‚àíA1 ÀôDT
1
and formulas (5.108) and (5.118), we obtain from expression (5.111) that
S11
(5.118)
=
BT
11 H11 B11 + ( ÀôBT
11 ‚àíDT
11 E11) Q11 B11 + BT
11 Q11 ( ÀôB11 ‚àíE11 D11)
+ BT
11 Q11 E11 Q11 B11 ‚àíÀôBT
11 Q11 B11 ‚àíBT
11 Q11 ÀôB11
+ ÀôBT
11 D11 + BT
11 ÀôD11
= (BT
11 Q11 ‚àíDT
11) E11 (Q11 B11 ‚àíD11) + Z11,
(5.119)
where
Z11 := BT
11 H11 B11 ‚àíDT
11 E11 D11 + ÀôBT
11 D11 + BT
11 ÀôD11.
We evaluate the matrix Z11 by using identities (5.113), (5.114), (5.115) as follows
Z11 (5.99)
=
BT
11 ( ÀôD1 CT
1 ‚àíÀôC1 DT
1 ) B11 ‚àíDT
11 ( ÀôB1 AT
1 ‚àíÀôA1 BT
1 ) D11
+ ÀôBT
11 D11 + BT
11 ÀôD11
(5.116), (5.117)
=
BT
11 ( ÀôD1 CT
1 ‚àíÀôC1 DT
1 ) B11
‚àí( ÀôBT
11 D1 + BT
11 ÀôD1 ‚àíÀôDT
11 B1 ‚àíÀôDT
21 B2) AT
1 D11
+ (BT
11 ÀôC1 + ÀôBT
11 C1 ‚àíÀôDT
11 A1 ‚àíÀôDT
21 A2) BT
1 D11
+ ÀôBT
11 D11 + BT
11 ÀôD11
(5.113), (5.114)
=
BT
11 ( ÀôD1 CT
1 ‚àíÀôC1 DT
1 ) B11

292
5
Discrete Symplectic Eigenvalue Problems
+ BT
11
+
ÀôC1

DT
11 B11
DT
12 B11 ‚àíBT
22 D21

‚àíÀôD1

CT
11 B11 ‚àíAT
21 D21 + Ir
CT
12 B11 ‚àíAT
22 D21
 ,
+ ÀôBT
11 (C1 BT
1 ‚àíD1 AT
1 ) D11 + ÀôDT
11 (B1 AT
1 ‚àíA1 BT
1 ) D11
+ ÀôDT
21 (B2 AT
1 ‚àíA2 BT
1 ) D11 + ÀôBT
11 D11 + BT
11 ÀôD11
(5.112)
=
BT
11 ( ÀôD1 CT
1 ‚àíÀôC1 DT
1 ) B11 + BT
11 ÀôD11 + BT
11

 ÀôC1 DT
1 B11 ‚àíÀôC1 BT
2 D21
‚àíÀôD1 CT
1 B11 + ÀôD1 AT
2 D21 ‚àíÀôD1

I, 0
T 
= BT
11 ÀôD11 + BT
11 ( ÀôD1 AT
2 ‚àíÀôC1 BT
2 ) D21 ‚àíBT
11

ÀôD11, ÀôD12
 
I, 0
T
(5.115)
=
BT
11 ÀôD11 ‚àíBT
11 ÀôD11 = 0.
Therefore, upon inserting Z11 = 0 into equation (5.119) and then expression (5.119)
into formula (5.110), we see that the matrix ÀôP11 has the form displayed in (5.105).
If now assumption (5.3) holds, then Àúk ‚â•0 by (5.87), as well as E11 ‚â•0 by (5.96)
with (5.98). And since in this case ÀúLk‚àí1 ‚â•0 by (5.102) and (5.31), formula (5.105)
implies that ÀôP11 ‚â•0 on (Œª0 ‚àíŒ¥, Œª0). This shows that the function P11(¬∑) is
nondecreasing on the interval (Œª0 ‚àíŒ¥, Œª0). The proof is complete.
‚äì‚äî
Remark 5.29 If Xk+1(Œª) is invertible on (Œª0 ‚àíŒ¥, Œª0), then r = n, and similar to
Remark 5.27, we get from (5.105), (5.102), and (5.31) the following identity for
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0)
ÀôPk(Œª) = BT
k (Œª)
+ k‚àí1

j=0
Y T
j+1(Œª) j(Œª) Yj+1(Œª)
,
Bk(Œª),
+ [Qk+1(Œª) Bk(Œª) ‚àíDk(Œª)]T Ek(Œª) [Qk+1(Œª) Bk(Œª) ‚àíDk(Œª)],
where the matrix Qk+1(Œª) is from Remark 5.27, and
Pk(Œª) := BT
k (Œª) Dk(Œª) ‚àíBT
k (Œª) Qk+1(Œª) Bk(Œª),
Ek(Œª) := ÀôBk(Œª) AT
k (Œª) ‚àíÀôAk(Œª) BT
k (Œª).
The above formula is an extension of the discrete version of [211, Lemma 4.3] to
the nonlinear dependence on Œª. Note that when the dependence on Œª is linear as
in (5.241), the matrices Ak(Œª) ‚â°Ak and Bk(Œª) ‚â°Bk are constant on R, so that in
this case Ek(Œª) ‚â°0.
DeÔ¨Åne now for Œª ‚ààR the auxiliary n √ó n matrices
ÀúMk(Œª) := Q Mk(Œª) ÀúQT ,
ÀúTk(Œª) := ÀúQ Tk(Œª) ÀúQT ,
ÀúPk(Œª) := ÀúQ Pk(Œª) ÀúQT ,
(5.120)

5.1
Nonlinear Dependence on Spectral Parameter
293
where Mk(Œª), Tk(Œª), Pk(Œª) are deÔ¨Åned in (5.40). Then
rank ÀúMk(Œª) = rank Mk(Œª),
ind ÀúPk(Œª) = ind Pk(Œª),
Œª ‚ààR.
(5.121)
Since by (5.69) and Remark 1.60(ii), we have for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
ÀúX‚Ä†
k+1(Œª) = PT X‚Ä†
k+1(Œª) QT ,
ÀúXk+1(Œª) ÀúX‚Ä†
k+1(Œª) = Q Xk+1(Œª) X‚Ä†
k+1(Œª) QT ,
it follows that
ÀúMk(Œª) =

I ‚àíÀúXk+1(Œª) ÀúX‚Ä†
k+1(Œª)
 ÀúBk(Œª),
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.122)
Again by Remark 1.60(ii), we have ÀúM‚Ä†
k (Œª) = ÀúQ M‚Ä†
k (Œª) QT , so that for Œª ‚àà(Œª0 ‚àí
Œ¥, Œª0]
ÀúTk(Œª) = I ‚àíÀúM‚Ä†
k (Œª) ÀúMk(Œª),
ÀúPk(Œª) = ÀúTk(Œª) ÀúXk(Œª) ÀúX‚Ä†
k+1(Œª) ÀúBk(Œª) ÀúTk(Œª).
(5.123)
From the form of ÀúXk+1(Œª), ÀúBk(Œª), ÀúMk(Œª) in (5.68), (5.88), (5.122), we get
ÀúMk(Œª) =

I ‚àíX11(Œª) X‚Ä†
11(Œª)
0
0
In‚àír
 B11(Œª) B12(Œª)
0
B22

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.124)
with the matrices B12(Œª) and B22 as in (5.88). This implies that
Mk(Œª) ‚â°QT
0r
0
0 B22

ÀúQ,
B22 =
0n‚àír‚àíœÅ
0
0
¬ØB44

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
with invertible ¬ØB44 ‚ààRœÅ√óœÅ. This shows that rankMk(Œª) ‚â°œÅ on (Œª0 ‚àíŒ¥, Œª0),
compared with the paragraph preceding Remark 5.21. Now since the Ô¨Årst block
column of B12(Œª) in (5.88) is zero and ¬ØB44 is invertible, (5.124) yields that
Ker ÀúMk(Œª) = Ker
M11(Œª) 0
0
B22

(5.125)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], where the matrix M11(Œª) ‚ààRr√ór is deÔ¨Åned by
M11(Œª) :=

I ‚àíX11(Œª) X‚Ä†
11(Œª)

B11(Œª),
Œª ‚ààR.
(5.126)
Consequently, by Lemma 1.63, for any Œª ‚àà(Œª0 ‚àíŒ¥, Œª0], we have
ÀúM‚Ä†
k (Œª) ÀúMk(Œª) =

M‚Ä†
11(Œª) 0
0
B‚Ä†
22
 M11(Œª)
0
0
B22

=

M‚Ä†
11(Œª) M11(Œª)
0
0
B‚Ä†
22 B22

.

294
5
Discrete Symplectic Eigenvalue Problems
Therefore, by the form of ÀúTk(Œª) in (5.123),
ÀúTk(Œª) =
T11(Œª)
0
0
I ‚àíB‚Ä†
22 B22

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.127)
where the matrix T11(Œª) ‚ààRr√ór is deÔ¨Åned by
T11(Œª) := I ‚àíM‚Ä†
11(Œª) M11(Œª),
Œª ‚ààR,
I ‚àíB‚Ä†
22 B22 =
In‚àír‚àíœÅ 0
0
0œÅ

.
(5.128)
Finally, from the form of the matrices ÀúXk(Œª), Y11(Œª), ÀúPk(Œª), and ÀúTk(Œª) in (5.73),
(5.91), (5.123), and (5.127), we get
ÀúPk(Œª) =
P11(Œª)
0
0
0n‚àír

,
Œª ‚àà(Œª0 ‚àíŒ¥, Œª0],
(5.129)
where the matrix P11(Œª) is given in (5.100)‚Äì(5.101) for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0) and
P11(Œª0) := T11(Œª0) Y11(Œª0) X‚Ä†
11(Œª0) B11(Œª0) T11(Œª0).
(5.130)
In addition, since X11(Œª) is invertible for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0), we have
M11(Œª) ‚â°0, T11(Œª) ‚â°I, P11(Œª) = Y11(Œª) X‚àí1
11 (Œª) B11(Œª), Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.131)
and the matrix P11(Œª) is nondecreasing on (Œª0 ‚àíŒ¥, Œª0), by Lemma 5.28. Thus, we
are now ready for the Ô¨Ånal step in the proof of the Ô¨Årst local oscillation theorem
(Theorem 5.15).
5.1.6
Application of the Index Theorem
In this subsection we utilize the above construction in order to apply the index
theorem (Theorem 1.85 and Corollary 1.86) to the reduced quantities in the
dimension r on the left neighborhood of Œª0 and to similarly reduced quantities
in the appropriate dimension on the right neighborhood of Œª0. Here we need to
assume that the matrix B11(Œª) has constant image in Œª, as the matrix RT
2 (t) in
Corollary 1.86 is assumed to have constant image in t. But under monotonicity
assumption (5.3), conditions (5.38) and (5.10) are equivalent (see Theorem 5.1 (iii)),
and then condition (5.38) can be used instead of (5.10).

5.1
Nonlinear Dependence on Spectral Parameter
295
Proof of Theorem 5.15 Assume that (5.38) holds, then the matrix Bk(Œª) has con-
stant image in Œª on R (see Theorem 5.1 (iii)); hence the matrix ÀúBk(Œª) has constant
image in Œª with B11(Œª) ‚ààRr√ór having constant image in Œª, too. For t ‚àà(0, Œ¥), we
deÔ¨Åne the matrices
X(t) := X11(Œª0 ‚àít),
(t) := Y11(Œª0 ‚àít),
U(t) := ‚àíU11(Œª0 ‚àít),
M(t) := P11(Œª0 ‚àít),
R1(t) := DT
11(Œª0 ‚àít),
R2(t) := BT
11(Œª0 ‚àít),
S1(t) := 1
2

D11(Œª0 ‚àít) B‚Ä†
11(Œª0 ‚àít) + B‚Ä†T
11 (Œª0 ‚àít) DT
11(Œª0 ‚àít)

,
S2(t) := 1
2

DT
11(Œª0 ‚àít) [I ‚àíB11(Œª0 ‚àít) B‚Ä†
11(Œª0 ‚àít)]
+[I ‚àíB‚Ä†
11(Œª0 ‚àít) B11(Œª0 ‚àít)] DT
11(Œª0 ‚àít)

,
S1 := 1
2

D11(Œª0) B‚Ä†
11(Œª0) + B‚Ä†T
11 (Œª0) DT
11(Œª0),
S2 := 1
2

DT
11(Œª0) [I ‚àíB11(Œª0) B‚Ä†
11(Œª0)]
+[I ‚àíB‚Ä†
11(Œª0) B11(Œª0)] DT
11(Œª0),
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(5.132)
and the matrices
X := X11(Œª0),
 := Y11(Œª0),
S‚àó:= M11(Œª0),
U := ‚àíU11(Œª0),
R2 := BT
11(Œª0)
T := T11(Œª0),
R1 := DT
11(Œª0),
S := X‚Ä†
11(Œª0) B11,
Q := P11(Œª0),
‚é´
‚é™‚é¨
‚é™‚é≠
(5.133)
where the matrices Y11(Œª), P11(Œª), M11(Œª), T11(Œª) are given in (5.91), (5.100),
(5.130), (5.126), and (5.128). We now verify the assumptions of the index theorem
(Corollary 1.86).
By Lemma 5.19 and (5.92), the matrices XT (t) U(t), R1(t) RT
2 (t), and S1(t) are
symmetric, rank(XT (t), UT (t)) = r, as well as rank(R1(t), R2(t)) = r for all t ‚àà
[0, Œ¥). Moreover, the symmetry of B‚Ä†
11(Œª) B11(Œª) and DT
11(Œª) B11(Œª) in (5.92) yields
that R1(t) = R2(t) S1(t)+S2(t) and S2(t) RT
2 (t) = 0 for t ‚àà[0, Œ¥), i.e., Im RT
2 (t) ‚äÜ
Ker S2(t) for t ‚àà[0, Œ¥). The opposite inclusion Ker S2(t) ‚äÜIm RT
2 (t) for t ‚àà[0, Œ¥)
is a consequence of the relation Ker(DT
11(Œª), BT
11(Œª)) = Im(BT
11(Œª), ‚àíDT
11(Œª))T
obtained from (5.92). Hence, Ker S2(t) = Im RT
2 (t) for t ‚àà[0, Œ¥). Furthermore,
by Lemma 5.19, the matrix X(t) is invertible for t ‚àà(0, Œ¥). Next, from (5.132)‚Äì
(5.133), we have X(t) ‚ÜíX, U(t) ‚ÜíU, S1(t) ‚ÜíS1, S2(t) ‚ÜíS2, R1(t) ‚ÜíR1,
R2(t) ‚ÜíR2 for t ‚Üí0+. Equations (5.100), (5.101), (5.91), (5.126), (5.128),
and (5.130) imply that the matrices M(t), (t), , S, S‚àó, T , Q deÔ¨Åned in (5.132)‚Äì
(5.133) are equal to their corresponding deÔ¨Åning expressions in Theorem 1.85.
Finally, Im R2(t) is constant for t ‚àà[0, Œ¥) by assumption (5.38). By Lemma 5.26,
the matrix U(t) X‚àí1(t) is nonincreasing on (0, Œ¥), as X(t) and U(t) are deÔ¨Åned
in (5.132) through X11(Œª) and U11(Œª) with the argument Œª = Œª0‚àít and U(t) has the
opposite sign to U11(Œª0‚àít), while by Lemma 5.28 the matrix M(t) is nonincreasing
on (0, Œ¥), as M(t) is deÔ¨Åned in (5.132) through P11(Œª) with the argument Œª = Œª0‚àít.

296
5
Discrete Symplectic Eigenvalue Problems
This means that equality (1.225) of Theorem 1.85 (Corollary 1.86) holds, in which
we take m = r. From the construction in Sects. 5.1.4 and 5.1.5, we calculate
ind M(0+)
(5.132)
=
ind P11(Œª‚àí
0 )
(5.129)
=
ind ÀúPk(Œª‚àí
0 )
(5.120)
=
ind Pk(Œª‚àí
0 ),
def (0+)
(5.132)
=
defY11(Œª‚àí
0 )
(5.91)
= r ‚àíÀúr
(5.72)
= r + œÅ ‚àírankXk(Œª‚àí
0 ),
def
(5.132)
=
defY11(Œª0)
(5.91)
=
r ‚àírank ÀúX11(Œª0)
(5.73)
= r + œÅ ‚àírank ÀúXk(Œª0)
(5.78)
=
r + œÅ ‚àírankXk(Œª0),
def X
(5.133)
=
defX11(Œª0) = r ‚àírank X11(Œª0)
(5.58)
=
r ‚àírank ÀúXk+1(Œª0)
(5.69)
=
r ‚àírankXk+1(Œª0),
ind Q
(5.133)
=
ind P11(Œª0)
(5.129)
=
ind ÀúPk(Œª0)
(5.120)
=
ind Pk(Œª0),
rankT
(5.133)
=
rankT11(Œª0)
(5.128)
=
r ‚àírankM11(Œª0)
(5.125)
=
r ‚àí[rank ÀúMk(Œª0) ‚àíœÅ]
(5.121)
=
r + œÅ ‚àírank M(Œª0).
When we insert the above data into equation (1.225) and if we recall the deÔ¨Ånitions
of r = rankXk+1(Œª‚àí
0 ) and œÅ = rankMk(Œª‚àí
0 ), we get
ind Pk(Œª‚àí
0 ) = ind M(0+) (1.225)
=
ind Q + m ‚àírank T + def  ‚àídef (0+) ‚àídef X
= ind Pk(Œª0) + r ‚àí[r + œÅ ‚àírank Mk(Œª0)] + [r + œÅ ‚àírank Xk(Œª0)]
‚àí[r + œÅ ‚àírank Xk(Œª‚àí
0 )] ‚àí[r ‚àírank Xk+1(Œª0)]
= ind Pk(Œª0) + rank Mk(Œª0) + rank Xk(Œª‚àí
0 ) ‚àírank Xk(Œª0)
+ rank Xk+1(Œª0) ‚àírank Xk+1(Œª‚àí
0 ) ‚àírank Mk(Œª‚àí
0 ).
(5.134)
In view of the deÔ¨Ånition of mk(Œª) in (5.39) as the number of focal points in (k, k+1],
we have from (5.134) the identity
mk(Œª‚àí
0 ) = mk(Œª0) + rankXk(Œª‚àí
0 ) ‚àírankXk(Œª0)
+ rankXk+1(Œª0) ‚àírank Xk+1(Œª‚àí
0 ).
(5.135)
Now we need to consider the construction in Sects. 5.1.4 and 5.1.5 in the right
neighborhood of Œª0, i.e., for Œª ‚àà[Œª0, Œª0 + Œ¥). The analysis of this construction
shows that exactly the same principles in obtaining the partitioned auxiliary
matrices ÀúXk+1(Œª), ÀúUk+1(Œª), the reÔ¨Åned partitioned matrices ÀúXk(Œª), ÀúUk(Œª), and the
coefÔ¨Åcients ÀúAk(Œª), ÀúBk(Œª), ÀúCk(Œª), ÀúDk(Œª) hold when the dimensions r and œÅ in (5.57)

5.1
Nonlinear Dependence on Spectral Parameter
297
and (5.70) are replaced by the dimensions
s := rank Xk+1(Œª+
0 )
and
œÉ := rank Xk(Œª+
0 ) P2 = rankMk(Œª+
0 ),
respectively, and at the same time the intervals (Œª0 ‚àíŒ¥, Œª0] and (Œª0 ‚àíŒ¥, Œª0) are
replaced by the intervals [Œª0, Œª0 +Œ¥) and (Œª0, Œª0 +Œ¥). Therefore, we now deÔ¨Åne for
t ‚àà(0, Œ¥) the s √ó s matrices
X(t) := X11(Œª0 + t),
(t) := Y11(Œª0 + t),
U(t) := ‚àíU11(Œª0 + t),
M(t) := P11(Œª0 + t),
R1(t) := DT
11(Œª0 + t),
R2(t) := BT
11(Œª0 + t),
S1(t) := 1
2

D11(Œª0 + t) B‚Ä†
11(Œª0 + t) + B‚Ä†T
11 (Œª0 + t) DT
11(Œª0 + t),
S2(t) := 1
2

DT
11(Œª0 + t) [I ‚àíB11(Œª0 + t) B‚Ä†
11(Œª0 + t)]
+[I ‚àíB‚Ä†
11(Œª0 + t) B11(Œª0 + t)] DT
11(Œª0 + t)

,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(5.136)
and the matrices S1, S2, X, U, R1, , R2, S, S‚àó, T , Q by the equations in (5.132)
and (5.133). It follows by Lemmas 5.26 and 5.28 that the matrices U(t) X‚àí1(t)
and M(t) are now nondecreasing on (0, Œ¥), as they are deÔ¨Åned in (5.136) through
X11(Œª), U11(Œª), P11(Œª) with the argument Œª = Œª0+t and U(t) has the opposite sign
to U11(Œª0 + t). This means that equality (1.226) of Theorem 1.85 (Corollary 1.86)
now holds, in which we take m = s. We now calculate
ind M(0+)
(5.136)
=
ind P11(Œª+
0 ) = ind ÀúPk(Œª+
0 ) = ind Pk(Œª+
0 ),
ind Q
(5.133)
=
ind P11(Œª0) = ind ÀúPk(Œª0) = ind Pk(Œª0),
rankT
(5.133)
=
rankT11(Œª0) = s ‚àírankM11(Œª0) = s ‚àí[rank ÀúMk(Œª0) ‚àíœÉ]
= s + œÉ ‚àírankM(Œª0).
When we insert the above data into equation (1.226), we obtain
ind Pk(Œª+
0 ) = ind M(0+)
(1.226)
=
ind Q + m ‚àírank T
= ind Pk(Œª0) + s ‚àí[s + œÉ ‚àírank Mk(Œª0)]
= ind Pk(Œª0) + rankMk(Œª0) ‚àírank Mk(Œª+
0 ).
(5.137)
In view of the deÔ¨Ånition of mk(Œª) in (5.39), we get from (5.137) that mk(Œª+
0 ) =
mk(Œª0), which proves the equality in (5.42). By combining (5.42) with equa-
tion (5.135), we can see that the equality in (5.43) is also satisÔ¨Åed. The proof of
Theorem 5.15 is now complete.
‚äì‚äî

298
5
Discrete Symplectic Eigenvalue Problems
5.1.7
Applications and Examples
In this subsection we show some applications of the oscillation theorems from
Sect. 5.1.3. For this purpose we deÔ¨Åne the associated quadratic functional, compare
with (2.56),
F(y, Œª) :=
N

k=0
yT
k
ST
k (Œª) K Sk(Œª) ‚àíK yk,
K :=
0n 0n
In 0n

,
(5.138)
where y = (x, u) is an admissible pair, i.e., xk+1 = Ak(Œª) xk + Bk(Œª) uk for all
k ‚àà[0, N]Z, satisfying the Dirichlet endpoints x0 = 0 = xN+1. We say that the
functional F(¬∑, Œª) is positive, if F(z, Œª) > 0 for every admissible z = (x, u) with
x0 = 0 = xN+1 and x Ã∏‚â°0. Conversely, the functional F(¬∑, Œª) is not positive, if
F(z, Œª) ‚â§0 for some admissible z = (x, u) with x0 = 0 = xN+1 and x Ã∏‚â°0. These
two properties will be denoted by F(¬∑, Œª) > 0 and F(¬∑, Œª) Ã∏> 0, respectively. The
following result is from Theorem 2.36.
Proposition 5.30 Let Œª0 ‚ààR be Ô¨Åxed. Then the functional F(¬∑, Œª0) > 0 if and
only if n1(Œª0) = 0, i.e., the principal solution Y [0](Œª0) of system (SŒª0) has no focal
points in (0, N + 1].
Additional conditions which are equivalent to the positivity of F(¬∑, Œª0) can be
found in the literature, such as the solvability of the explicit and implicit Riccati
equations and inequalities, conjugate and coupled intervals, perturbed quadratic
functionals, etc.; see, e.g., Theorem 2.36.
From (5.55) and (5.56), it follows that the constant m ‚ààN ‚à™{0} in Theorem 5.17
is actually zero, if and only if n2(Œª) = n1(Œª) ‚â°m = 0 for all or for some Œª ‚ààR.
Combining this observation with Proposition 5.30 yields the following.
Theorem 5.31 Assume (5.3) and (5.38) for all k ‚àà[0, N]Z. Then
n1(Œª) = n2(Œª)
for all Œª ‚ààR
(5.139)
if and only if there exists Œª0 < 0 such that F(¬∑, Œª0) > 0.
Proof If F(¬∑, Œª0) > 0, then n1(Œª0) = 0, by Proposition 5.30. Since the function
n1(¬∑) is nondecreasing on R by Theorem 5.16, it follows that n1(Œª) ‚â°0 for all
Œª ‚â§Œª0, i.e., m = 0 in (5.55), showing (5.139). Conversely, if (5.139) holds, then
m = 0, and so, by (5.56), we have n1(Œª) ‚â°m = 0 for Œª ‚â§Œª0 with Œª0 from
Theorem 5.17. From Proposition 5.30, we then get F(¬∑, Œª0) > 0.
‚äì‚äî
Next we present conditions in terms of F(¬∑, Œª) > 0 which are closely related to
the existence of Ô¨Ånite eigenvalues of (E).
Theorem 5.32 (Existence of Finite Eigenvalues: Necessary Condition) Let the
assumptions (5.3) and (5.38) be satisÔ¨Åed for all k ‚àà[0, N]Z. If (E) has a Ô¨Ånite

5.1
Nonlinear Dependence on Spectral Parameter
299
eigenvalue, then there exist Œª0, Œª1 ‚ààR with Œª0 < Œª1 and m ‚ààN ‚à™{0} such that
n1(Œª) ‚â°m for all Œª ‚â§Œª0 and F(¬∑, Œª1) Ã∏> 0.
Proof The fact that (E) has a Ô¨Ånite eigenvalue of (E) means that n2(Œª1) ‚â•1 for
some Œª1 ‚ààR. By Theorem 5.17, we know that equality (5.55) is satisÔ¨Åed for some
m ‚ààN ‚à™{0} and n1(Œª) ‚â°m for all Œª ‚â§Œª0 for some Œª0 < 0. Without loss of
generality, we may take Œª0 < Œª1, so that the Ô¨Årst part of this theorem is proven.
Next, from (5.55) with Œª = Œª1, we obtain n1(Œª1) = n2(Œª1) + m ‚â•n2(Œª1) ‚â•1,
showing that the principal solution of (SŒª1) has at least one focal point in (0, N +1].
In turn, Proposition 5.30 shows that F(¬∑, Œª1) Ã∏> 0.
‚äì‚äî
Theorem 5.33 (Existence of Finite Eigenvalues: SufÔ¨Åcient Condition) Let the
assumptions (5.3) and (5.38) be satisÔ¨Åed for all k ‚àà[0, N]Z. If there exist Œª0, Œª1 ‚ààR
with Œª0 < Œª1 such that F(¬∑, Œª0) > 0 and F(¬∑, Œª1) Ã∏> 0, then (E) has at least one
Ô¨Ånite eigenvalue.
Proof The positivity of F(¬∑, Œª0) implies by Theorem 5.31 that equality (5.139)
holds. If we assume that there is no Ô¨Ånite eigenvalue of (E) at all, i.e., if n2(Œª) ‚â°0
for every Œª ‚ààR, then n1(Œª) ‚â°0 for all Œª ‚ààR as well. In particular, n1(Œª1) = 0. This
means by Proposition 5.30 that F(¬∑, Œª1) > 0, which contradicts our assumption.
Therefore, under the given conditions, the eigenvalue problem (E) must have at least
one Ô¨Ånite eigenvalue.
‚äì‚äî
The following result characterizes the smallest Ô¨Ånite eigenvalue of (E).
Theorem 5.34 Assume that (5.3) and (5.38) hold for all k ‚àà[0, N]Z. If there
exist Œª0, Œª1 ‚ààR with Œª0 < Œª1 such that F(¬∑, Œª0) > 0 and F(¬∑, Œª1) Ã∏> 0, then
the eigenvalue problem (E) possesses a smallest Ô¨Ånite eigenvalue Œªmin, which is
characterized by any of the following conditions:
Œªmin = sup P,
P := {Œª ‚ààR, F(¬∑, Œª) > 0},
(5.140)
Œªmin = min N,
N := {Œª ‚ààR, F(¬∑, Œª) Ã∏> 0}.
(5.141)
Moreover, the algebraic multiplicity of Œªmin is then equal to n1(Œªmin), i.e., to the
number of focal points of the principal solution of (SŒªmin) in (0, N + 1].
Proof From Theorem 5.33, we know that the eigenvalue problem (E) has at least
one Ô¨Ånite eigenvalue. Since F(¬∑, Œª0) > 0 is assumed, then Œª0 ‚ààP and the set
P is nonempty. Moreover, by Proposition 5.30 we have n1(Œª0) = 0. Since the
function n1(¬∑) is nondecreasing on R, it follows that n1(Œª) ‚â°0 for Œª ‚â§Œª0, i.e.,
F(¬∑, Œª) > 0 for Œª ‚â§Œª0. This implies that (‚àí‚àû, Œª0] ‚äÜP. In addition, Œª1 Ã∏‚ààP,
so that P is bounded from above and therefore P = (‚àí‚àû, œâ), where œâ = sup P
exists. It follows that n1(œâ) ‚â•1, because by Theorem 5.16, the function n1 is
right-continuous on R. We will show that Œªmin = œâ is the smallest Ô¨Ånite eigenvalue
of (E). From Theorem 5.31, we know that n1(Œª) = n2(Œª) for all Œª ‚ààR. Hence,
n2(Œª) ‚â°0 for all Œª < œâ and n2(œâ) = n1(œâ) ‚â•1, proving that œâ is the smallest
Ô¨Ånite eigenvalue of (E) with the algebraic multiplicity n1(œâ). As for (5.141), we

300
5
Discrete Symplectic Eigenvalue Problems
note that the set N is nonempty, because Œª1 ‚ààN, and the interval (‚àí‚àû, Œª0] is not
contained in N. Therefore, N is bounded from below. Let ŒΩ ‚ààN, i.e., n1(ŒΩ) ‚â•1.
Then n2(ŒΩ) = n1(ŒΩ) ‚â•1. Since we know from Theorem 5.17 and Corollary 5.7 that
the function n2 is right-continuous on R and the Ô¨Ånite eigenvalues are isolated and
bounded from below, it follows that Œ∫ := min{ŒΩ ‚ààR, n2(ŒΩ) ‚â•1} = min N exists
and satisÔ¨Åes Œª0 < Œ∫. Furthermore, by the deÔ¨Ånition of Œ∫, we have n2(Œª) ‚â°0 for all
Œª < Œ∫ and n2(Œ∫) ‚â•1. This yields that Œªmin = Œ∫ is the smallest Ô¨Ånite eigenvalue
of (E) with multiplicity n2(Œ∫) = n1(Œ∫).
‚äì‚äî
Finally, we discuss the applicability of our results to some special discrete
symplectic systems (SDSŒª).
Example 5.35 Consider the second-order Sturm-Liouville difference equation; see
Sect. 1.2, which can also be viewed as the Jacobi matrix,
rk(Œª) xk(Œª) + qk(Œª) xk+1(Œª) = 0,
k ‚àà[0, N ‚àí1]Z,
(5.142)
where the coefÔ¨Åcients rk, qk : R ‚ÜíR satisfy
rk(Œª) Ã∏= 0,
Àôrk(Œª) ‚â§0,
Àôqk(Œª) ‚â•0,
k ‚àà[0, N]Z, Œª ‚ààR.
In this case the matrices Sk(Œª) and k(Œª) have the form (see Example 2.13)
Sk(Œª) =

1
1/rk(Œª)
‚àíqk(Œª) 1 ‚àíqk(Œª)/rk(Œª)

,
k(Œª) =
1
r2
k (Œª)
rk(Œª) qk(Œª)
0
1
  Àôqk(Œª)
0
0
‚àíÀôrk(Œª)
 rk(Œª) 0
qk(Œª) 1

.
The square of rk(Œª) in the matrix k(Œª) above shows that the oscillation and
spectral theory of the second-order Sturm-Liouville difference equations, even in
the classical setting where rk(Œª) ‚â°rk Ã∏= 0 and qk(Œª) = qk+Œª wk with wk > 0, does
not depend on the sign of the coefÔ¨Åcient rk(Œª) but rather on its monotonicity. The
principal solution ÀÜx(Œª) of (5.142) is the solution starting with the initial conditions
ÀÜx0(Œª) ‚â°0 and ÀÜx1(Œª) = 1/r0(Œª) for all Œª ‚ààR. The result in Theorem 5.3
yields that if x(Œª) is a nontrivial solution of (5.142) and xk(Œª0) = 0 for some
k ‚àà[0, N + 1]Z and Œª0 ‚ààR, then either xk(Œª) is identically zero or never zero in
some left and right neighborhoods of Œª0. This implies, according to DeÔ¨Ånition 5.5,
that a number Œª0 ‚ààR is a Ô¨Ånite eigenvalue of (E) provided there exists Œ¥ > 0 such
that ÀÜxN+1(Œª0) = 0 and ÀÜxN+1(Œª) Ã∏= 0 for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0). The degeneracy
condition in (5.23) of DeÔ¨Ånition 5.8 at Œª0 then means that the solutions x(Œª)
of (5.142) with Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] starting with the initial conditions x0(Œª) = x0(Œª0)
and x1(Œª) = x0(Œª) + r0(Œª0) x0(Œª0)/r0(Œª) satisfy
Àôrk(Œª) xk(Œª) ‚â°0,
Àôqk(Œª) xk+1(Œª) ‚â°0
for all k ‚àà[0, N]Z and Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].

5.1
Nonlinear Dependence on Spectral Parameter
301
Since rank Bk(Œª) = rank 1/rk(Œª) ‚â°1 is constant in Œª, the results in Theorems 5.15
and 5.16 and 5.17 and in Corollary 5.18 hold without any additional assumption.
Similar analysis can also be done for the higher-order Sturm-Liouville difference
equations; see Example 5.38.
Example 5.36 Similar to Example 5.35, we consider the second-order matrix
Sturm-Liouville equation (see Example 2.10)
Rk(Œª) xk(Œª) + Qk(Œª) xk+1(Œª) = 0,
k ‚àà[0, N ‚àí1]Z,
(5.143)
where Rk, Qk : R ‚ÜíRn√ón are symmetric matrix functions such that Rk(Œª) is
invertible, ÀôRk(Œª) ‚â§0, and ÀôQk(Œª) ‚â•0 for all k ‚àà[0, N]Z and Œª ‚ààR. In this case
Sk(Œª) =

I
R‚àí1
k (Œª)
Qk(Œª) I ‚àíQk(Œª) R‚àí1
k (Œª)

,
k(Œª) =
I Qk(Œª) R‚àí1
k (Œª)
0
R‚àí1
k (Œª)
  ÀôQk(Œª)
0
0
‚àíÀôRk(Œª)
 
I
0
R‚àí1
k (Œª) Qk(Œª) R‚àí1
k (Œª)

.
A number Œª0 ‚ààR is a Ô¨Ånite eigenvalue of (E) if the principal solution ÀÜX(Œª)
of (5.143), i.e., the solution starting with ÀÜX0(Œª) ‚â°0 and ÀÜX1(Œª) = R‚àí1
0 (Œª) for
all Œª ‚ààR, has ÀÜXN+1(Œª0) singular and
ÀÜXN+1(Œª) is invertible for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0)
for some Œ¥ > 0. Since in this case rank Bk(Œª) = rankR‚àí1
k (Œª) ‚â°n is constant in
Œª, the results in Theorems 5.15 and 5.16 and 5.17 and in Corollary 5.18 then hold
without any additional assumption.
Example 5.37 Consider the linear Hamiltonian system (see Example 2.7)
xk(Œª) = Ak(Œª) xk+1(Œª) + Bk(Œª) uk(Œª),
uk(Œª) = Ck(Œª) xk+1(Œª) ‚àíAT
k (Œª) uk(Œª),

k ‚àà[0, N]Z,
(5.144)
where the coefÔ¨Åcients Ak, Bk, Ck : R ‚ÜíRn√ón are such that Bk(Œª) and Ck(Œª) are
symmetric, I ‚àíAk(Œª) is invertible with ÀúAk(Œª) := [I ‚àíAk(Œª)]‚àí1, and
ÀôHk(Œª) ‚â•0,
Hk(Œª) :=
‚àíCk(Œª) AT
k (Œª)
Ak(Œª) Bk(Œª)

,
k ‚àà[0, N]Z, Œª ‚ààR.
The matrices Sk(Œª) and k(Œª) have the form
Sk(Œª) =

ÀúAk(Œª)
ÀúAk(Œª) Bk(Œª)
Ck(Œª) ÀúAk(Œª) Ck(Œª) ÀúAk(Œª) Bk(Œª) + I ‚àíAT
k (Œª)

,
(5.145)
k(Œª) =
I ‚àíCk(Œª) ÀúAk(Œª)
0
ÀúAk(Œª)

ÀôHk(Œª)

I
0
‚àíÀúAT
k (Œª) Ck(Œª) ÀúAT
k (Œª)

.
(5.146)

302
5
Discrete Symplectic Eigenvalue Problems
The results in Theorems 5.15 and 5.16 and 5.17 and in Corollary 5.18 then hold
under the assumption that the matrix Bk(Œª) has constant rank in Œª for every k ‚àà
[0, N]Z. In Sect. 5.6 we completely omit this restriction.
Example 5.38 For a Ô¨Åxed n ‚ààN, we consider the 2n-th order Sturm-Liouville
difference equation (see Example 2.12)
n

j=0
(‚àí1)jjr[j]
k (Œª) jyk+n‚àíj(Œª) = 0,
k ‚àà[0, N ‚àín]Z,
(5.147)
where r[i]
k
: R ‚ÜíR are piecewise continuously differentiable for all i
‚àà
{0, 1 . . ., n} and k ‚àà[0, N]Z such that
r[n]
k (Œª) Ã∏= 0,
Àôr[i]
k (Œª) ‚â§0
for all i ‚àà{0, 1, . . ., n}.
Equation (5.147) can be written as a special linear Hamiltonian system (5.144),
whose coefÔ¨Åcients are given in (2.29) and (2.30). In particular Ak(Œª) ‚â°A is
constant in Œª. In turn by Example 5.37, system (5.144) is a special symplectic
difference system (SDSŒª) with
Ak(Œª) ‚â°
‚éõ
‚éú‚éú‚éú‚éù
1 1 . . . 1
0 1 . . . 1
... ... ... ...
0 0 . . . 1
‚éû
‚éü‚éü‚éü‚é†,
Bk(Œª) =
1
r[n]
k (Œª)
‚éõ
‚éú‚éú‚éú‚éù
0 . . . 0 1
0 . . . 0 1
... ... ... ...
0 . . . 0 1
‚éû
‚éü‚éü‚éü‚é†,
(5.148)
Ck(Œª) =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
r[0]
k (Œª) r[0]
k (Œª) . . . r[0]
k (Œª)
0
r[1]
k (Œª) . . . r[1]
k (Œª)
...
...
...
...
0
0
. . . r[n‚àí1]
k
(Œª)
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
(5.149)
Dk(Œª) =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1
0 0 . . . 0
0
r[0]
k (Œª)/r[n]
k (Œª)
‚àí1 1 0 . . . 0
0
r[1]
k (Œª)/r[n]
k (Œª)
0 ‚àí1 1 . . . 0
0
r[2]
k (Œª)/r[n]
k (Œª)
...
...
... ...
...
...
...
0
0 0 . . . 1
0
r[n‚àí3]
k
(Œª)/r[n]
k (Œª)
0
0 0 . . . ‚àí1 1
r[n‚àí2]
k
(Œª)/r[n]
k (Œª)
0
0 0 . . . 0 ‚àí1 1 + r[n‚àí1]
k
(Œª)/r[n]
k (Œª)
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
(5.150)

5.2
Eigenvalue Problems with General Boundary Conditions
303
The matrix k(Œª) is now given in (5.146), where
ÀôHk(Œª) = diag{‚àíÀôCk(Œª), ÀôBk(Œª)}
= ‚àídiag

Àôr[0]
k (Œª), . . . , Àôr[n‚àí1]
k
(Œª), 0, . . . , 0,
Àôr[n]
k (Œª)

r[n]
k (Œª)
2
 
‚â•0.
Since the rank of the matrix Bk(Œª) in (5.148) is constant in Œª, it follows that the
results in Theorems 5.15 and 5.16 and 5.17 and in Corollary 5.18 then hold without
any additional assumption.
Example 5.39 Assume that the symplectic matrix Sk(Œª) in (5.2) is linear in Œª, that
is, we have Sk(Œª) := Sk +Œª Vk for all k ‚àà[0, N]Z and Œª ‚ààR. Then Lemma 1.58(iii)
yields that ST
k (Œª) = ST
k + Œª VT
k ‚ààSp(2n), i.e.,
(Sk + Œª Vk) J (Sk + Œª Vk)T = Sk J ST
k + Œª (VkJ ST
k + SkJ VT
k ) + Œª2VkJ VT
k = J
for all Œª ‚ààR. It follows that the matrix Sk is symplectic, VkJ VT
k
= 0, and
VkJ ST
k
= SkJ T VT
k . Using this fact we prove that the symmetric matrix k(Œª)
in (5.3) is constant in Œª and it has the form
k(Œª) ‚â°k := J Vk J ST
k J ‚â•0
for all k ‚àà[0, N]Z.
In this case we can actually prove that the Ô¨Ånite eigenvalues of (E) are real and that
the Ô¨Ånite eigenfunctions corresponding to different Ô¨Ånite eigenvalues are orthogonal
with respect to the semi-inner product
‚ü®z, Àúz‚ü© :=
N

k=0
zT
k+1 k Àúzk+1.
The proof follows standard arguments from linear algebra. The results in Theo-
rems 5.15, 5.16, and 5.17 and in Corollary 5.18 then hold under the assumption that
the matrix Bk(Œª) = Bk + Œª ÀúBk has constant rank in Œª for every k ‚àà[0, N]Z. We note
that in Sect. 5.6 we completely omit this restriction.
5.2
Eigenvalue Problems with General Boundary Conditions
In this section we present the theory of eigenvalues for system (5.1) with general
boundary conditions, i.e., with separated and jointly varying endpoints.

304
5
Discrete Symplectic Eigenvalue Problems
5.2.1
Transformations of Boundary Conditions
In this subsection we consider system (SDSŒª) together with the so-called self-
adjoint boundary conditions
R1(Œª)
 x0(Œª)
xN+1(Œª)

+ R2(Œª)
 ‚àíu0(Œª)
uN+1(Œª)

= 0,
(5.151)
where R1(Œª) and R2(Œª) are piecewise continuously differentiable matrix-valued
functions such that (compare with (2.92))
R1(Œª), R2(Œª) ‚ààR2n√ó2n,
rank(R1(Œª) R2(Œª)) = 2n,
R1(Œª) RT
2 (Œª) = R2(Œª) RT
1 (Œª),
Œª ‚ààR.

(5.152)
Moreover, with the notation R(Œª) := (R1(Œª) R2(Œª)) ‚ààR2n√ó4n, we impose the
following monotonicity restriction
ÀôR1(Œª) RT
2 (Œª) ‚àíÀôR2(Œª) RT
1 (Œª) = ÀôR(Œª) J4nRT (Œª) ‚â§0.
(5.153)
As a particular case of matrices R1(Œª) and R2(Œª) in (5.151), we consider their block
diagonal form
R1(Œª) = diag{R‚àó
0(Œª), R‚àó
N+1(Œª)},
R2(Œª) = diag{‚àíR0(Œª), RN+1(Œª)}.
(5.154)
Here Ri(Œª), R‚àó
i (Œª) ‚ààRn√ón, i ‚àà{0, N + 1} and ‚àóis just a notation without
any connection to the conjugate transpose of a matrix. In this case the boundary
conditions are separated, i.e.,
R‚àó
0(Œª) x0(Œª) + R0(Œª) u0(Œª) = 0,
R‚àó
N+1(Œª) xN+1(Œª) + RN+1(Œª) uN+1(Œª) = 0,

(5.155)
and conditions (5.152) translate as (compared with (2.83))
R‚àó
0(Œª) RT
0 (Œª) = R0(Œª) R‚àóT
0 (Œª),
rank(R‚àó
0(Œª), R0(Œª)) = n,
R‚àó
N+1(Œª) RT
N+1(Œª) = RN+1(Œª) R‚àóT
N+1(Œª),
rank (R‚àó
N+1(Œª), RN+1(Œª)) = n,

(5.156)
while the monotonicity condition (5.153) is rewritten in the form
ÀôR‚àó
0(Œª) RT
0 (Œª) ‚àíÀôR0(Œª) R‚àóT
0 (Œª) = ÀôÀúR(Œª) J ÀúRT (Œª) ‚â•0,
(5.157)
ÀôR‚àó
N+1(Œª) RT
N+1(Œª) ‚àíÀôRN+1(Œª) R‚àóT
N+1(Œª) = ÀôR(Œª) J RT (Œª) ‚â§0,
(5.158)

5.2
Eigenvalue Problems with General Boundary Conditions
305
where
ÀúR(Œª) := (R‚àó
0(Œª) R0(Œª)),
R(Œª) := (R‚àó
N+1(Œª) RN+1(Œª)).
(5.159)
In particular, if R1(Œª) ‚â°R1 and R2(Œª) ‚â°R2 are independent on Œª, then the
monotonicity conditions in (5.153), (5.157), (5.158) are automatically satisÔ¨Åed.
Moreover, for R‚àó
0 = I, R0 = 0, R‚àó
N+1 = I, and RN+1 = 0, we obtain the Dirichlet
boundary conditions used in problem (E).
The discreteness of the underlaying set N or (Z) enables a construction, which
transforms general boundary condition (5.151) to the Dirichlet condition.
Lemma 5.40 The eigenvalue problem (SDSŒª) with separated boundary condi-
tions (5.155) on [0, N + 1]Z can be extended to an eigenvalue problem of the same
form (the so-called extended system) on the interval [‚àí1, N +2]Z with the Dirichlet
boundary conditions
Àúx‚àí1(Œª) = 0 = ÀúxN+2(Œª).
(5.160)
Proof The reduction of separated boundary conditions on [0, N + 1]Z to the
Dirichlet conditions on [‚àí1, N + 2]Z is realized by the following construction.
Consider separated boundary conditions (5.155). We construct the extended system,
where we extend the original eigenvalue problem (5.1), (5.155) considered for
k ‚àà[0, N]Z to a system for k ‚àà[‚àí1, N +1]Z, where we transform general separated
boundary conditions (5.155) at k = 0 and k = N + 1 to the Dirichlet boundary
condition at k = ‚àí1 and k = N + 2.
Step 1 Firstly, we deÔ¨Åne the symplectic matrices S‚àí1(Œª) and SN+1(Œª) according to
Lemma 1.58(vi) such that
S‚àí1(Œª) (0 I)T = J T ÀúRT (Œª) Q0(Œª),
det Q0(Œª) Ã∏= 0,
S‚àí1
N+1(Œª) (0 I)T = J T RT (Œª) QN+1(Œª),
det QN+1(Œª) Ã∏= 0,

Œª ‚ààR,
(5.161)
where the n√ó2n matrices ÀúR(Œª) and R(Œª) are given by (5.159). Note that the matrices
S‚àí1(Œª) and SN+1(Œª) are not deÔ¨Åned uniquely by conditions (5.161). For S‚àí1(Œª) and
SN+1(Œª) given by (5.161), we introduce the extended problem
Àúyk+1(Œª) = Sk(Œª) Àúyk(Œª),
k ‚àà[‚àí1, N + 1]Z,
Àúx‚àí1(Œª) = 0 = ÀúxN+2(Œª).
(5.162)
One can show that for any choice of piecewise continuously differentiable Q0(Œª)
and QN+1(Œª), if a vector function yk(Œª) = (xk(Œª), uk(Œª)) for k ‚àà[0, N + 1]Z
obeys (SDSŒª) and (5.155) under assumption (5.156), then Àúyk = (Àúxk(Œª), Àúuk(Œª)) for

306
5
Discrete Symplectic Eigenvalue Problems
k ‚àà[‚àí1, N + 2]Z solves the extended problem (5.162), where Àúyk(Œª) ‚â°yk(Œª) for
k ‚àà[0, N + 1]Z. The proof is based on Lemma 1.58(vii); see formula (1.149).
Indeed, assume that yk(Œª) solves (SDSŒª) and (5.155). Then y0(Œª) ‚ààKer ÀúR(Œª) and
yN+1(Œª) ‚ààKer R(Œª), where ÀúR(Œª) and R(Œª) are deÔ¨Åned in (5.159). Note that in
this step we do not impose any monotonicity conditions (5.3), (5.157), (5.158).
Then, by (1.149), y0(Œª) ‚ààIm J ÀúRT (Œª) and yN+1(Œª) ‚ààIm J RT (Œª), compared
with the deÔ¨Ånition of S‚àí1(Œª) and SN+1(Œª) in (5.161). The last conditions mean
that Àúyk = (Àúxk(Œª), Àúuk(Œª)) for k ‚àà[‚àí1, N + 2]Z obeys (5.160), i.e., it solves the
extended problem (5.162), where Àúyk(Œª) ‚â°yk(Œª) for k ‚àà[0, N + 1]Z. Conversely, if
a vector function Àúyk(Œª) = (Àúxk(Œª), Àúuk(Œª)) for k ‚àà[‚àí1, N + 2]Z solves the extended
problem (5.162), then conditions (5.160) imply Àúy0(Œª) ‚ààIm J ÀúRT (Œª) and ÀúyN+1(Œª) ‚àà
Im J RT (Œª) or, again by (1.149), Àúy0(Œª) ‚ààKer ÀúR(Œª) and ÀúyN+1(Œª) ‚ààKer R(Œª). This
shows that Àúy0(Œª) and ÀúyN+1(Œª) obey (5.155).
Step 2 Secondly, we present the construction of S‚àí1(Œª) and SN+1(Œª) in such a way
that conditions (5.157), (5.158) imply
(S‚àí1(Œª)) ‚â•0,
(SN+1(Œª)) ‚â•0.
(5.163)
According to (5.161) and the proof of Lemma 1.58(vi), we introduce the n √ó n
matrices
K0(Œª) = [ ÀúR(Œª) ÀúRT (Œª)]‚àí1,
KN+1(Œª) = [R(Œª) RT (Œª)]‚àí1
(5.164)
and deÔ¨Åne the Ô¨Årst 2n √ó n blocks of S‚àí1(Œª) and S‚àí1
N+1(Œª) in (5.161) according to
the proof of Lemma 1.58(vii) as
S‚àí1(Œª) (I 0)T = ÀúRT (Œª) K0(Œª) Q‚àí1 T
0
(Œª),
S‚àí1
N+1(Œª) (I 0)T = RT (Œª) KN+1(Œª) Q‚àí1 T
0
(Œª),

(5.165)
where the matrices ÀúR(Œª) and R(Œª) are deÔ¨Åned in (5.159). Then, by (5.161), (5.165),
and (1.193), we have
(S‚àí1
‚àí1(Œª)) = LT
0 (Œª)

‚àíÀôÀúR(Œª) J ÀúRT (Œª)
ÀúP(Œª)
ÀúP T (Œª)
‚àíÀôÀúR(Œª) J ÀúRT (Œª)

L0(Œª),
ÀúP (Œª) = K‚àí1
0 (Œª) ÀôQ0(Œª) Q‚àí1
0 (Œª) + R‚àó
0(Œª) ÀôR‚àóT
0 (Œª) + R0(Œª) ÀôRT
0 (Œª),
L0(Œª) = diag{K0(Œª) QT ‚àí1
0
(Œª), Q0(Œª)}
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(5.166)

5.2
Eigenvalue Problems with General Boundary Conditions
307
and in a similar way
(SN+1(Œª)) = LT
N+1(Œª)
‚àíÀôR(Œª) J RT (Œª)
P(Œª)
P T (Œª)
‚àíÀôR(Œª) J RT (Œª)

LN+1(Œª),
P(Œª) = K‚àí1
N+1(Œª) ÀôQN+1(Œª) Q‚àí1
N+1(Œª)
+R‚àó
N+1(Œª) ÀôR‚àóT
N+1(Œª) + RN+1(Œª) ÀôRT
N+1(Œª),
LN+1(Œª) = diag{KN+1(Œª) QT ‚àí1
N+1(Œª), QN+1(Œª)}.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(5.167)
Then, under the assumption that Q0(Œª) and QN+1(Œª) are the fundamental matrices
of the differential equations (compared with Remark 1.46)
ÀôQ0(Œª) = ‚àíK0(Œª) [R‚àó
0(Œª) ÀôR‚àóT
0 (Œª) + R0(Œª) ÀôRT
0 (Œª)] Q0(Œª),
ÀôQN+1(Œª) = ‚àíKN+1(Œª) [R‚àó
N+1(Œª) ÀôR‚àóT
N+1(Œª) + RN+1(Œª) ÀôRT
N+1(Œª)] QN+1(Œª),

(5.168)
we have in (5.166) and (5.167) that ÀúP (Œª) = P(Œª) = 0. Then by (5.157) and (5.158),
we obtain
(S‚àí1
‚àí1(Œª)) = LT
0 (Œª)

‚àíÀôÀúR(Œª) J ÀúRT (Œª)
0
0
‚àíÀôÀúR(Œª) J ÀúRT (Œª)

L0(Œª) ‚â§0,
(5.169)
which yields by using Proposition 1.76(iv) that (S‚àí1(Œª)) ‚â•0. Similarly,
(SN+1(Œª)) = LT
N+1(Œª)
‚àíÀôR(Œª) J RT (Œª)
0
0
‚àíÀôR(Œª) J RT (Œª)

LN+1(Œª) ‚â•0.
(5.170)
Thus, we have proved that monotonicity conditions (5.157) and (5.158) really
imply (5.169) and (5.170) with the matrices S‚àí1(Œª) and SN+1(Œª) given by (5.161),
(5.165), and (5.168).
Step 3 Lastly, We remark that according to the above construction, the block
diagonal matrices L0(Œª) and LN+1(Œª) are nonsingular, so that conditions (5.169),
(5.170), (5.168) imply (5.157), (5.158).
‚äì‚äî
As a direct consequence of the proof of Lemma 5.40, we formulate the main
result of this section.
Theorem 5.41 Under assumptions (5.2), (5.3), (5.156), (5.157), and (5.158) with
all coefÔ¨Åcient matrices being piecewise continuously differentiable (with respect to
Œª ‚ààR), the problem (SDSŒª), (5.155) is equivalent to the extended problem (5.162),

308
5
Discrete Symplectic Eigenvalue Problems
where the matrices S‚àí1(Œª) and SN+1(Œª) obey monotonicity conditions (5.163) and
are deÔ¨Åned as
S‚àí1(Œª) =
A‚àí1(Œª) B‚àí1(Œª)
C‚àí1(Œª) D‚àí1(Œª)

:= V‚àí1(Œª) diag{QT ‚àí1
0
(Œª), Q0(Œª)},
V‚àí1(Œª) :=
R‚àóT
0 (Œª) K0(Œª) ‚àíRT
0 (Œª)
RT
0 (Œª) K0(Œª) R‚àóT
0 (Œª)

,
(5.171)
K0(Œª) := [R‚àó
0(Œª) R‚àóT
0 (Œª) + R0(Œª) RT
0 (Œª)]‚àí1
(5.172)
and
SN+1(Œª) =
AN+1(Œª) BN+1(Œª)
CN+1(Œª) DN+1(Œª)

:= diag{QT
N+1(Œª), Q‚àí1
N+1(Œª)}VN+1(Œª),
VN+1(Œª) :=

R‚àó
N+1(Œª)
RN+1(Œª)
‚àíKN+1(Œª) RN+1(Œª) KN+1(Œª) R‚àó
N+1(Œª)

,
(5.173)
KN+1(Œª) := [R‚àó
N+1(Œª) R‚àóT
N+1(Œª) + RN+1(Œª) RT
N+1(Œª)]‚àí1.
(5.174)
Here Q0(Œª) and QN+1(Œª) are the fundamental matrices of the differential equations
in (5.168). In particular, if R‚àó
i (Œª) and Ri(Œª) do not depend on Œª, then one can put
Qi(Œª) ‚â°I for i ‚àà{0, N + 1}.
Remark 5.42 Formulas (5.171) and (5.173) yield that the coefÔ¨Åcients B‚àí1(Œª) and
BN+1(Œª) of the extended system are
B‚àí1(Œª) = ‚àíRT
0 (Œª) Q0(Œª),
BN+1(Œª) = QT
N+1(Œª) RN+1(Œª),
Œª ‚ààR.
(5.175)
Remark 5.43 Remark that the principal solution of the extended system in (5.162)
at k = ‚àí1 takes the value
Y [‚àí1]
0
(Œª) = S‚àí1(Œª) (0 I)T = J T ÀúRT (Œª) Q0(Œª),
det Q0(Œª) Ã∏= 0,
(5.176)
where Q0(Œª) is the fundamental matrix of (5.168). Similarly, the principal solution
of the extended system in (5.162) at k = N + 2 takes the value
Y [N+2]
N+1 (Œª) = S‚àí1
N+1(Œª) (0 I)T = J T RT (Œª) QN+1(Œª),
det QN+1(Œª) Ã∏= 0,
(5.177)
where QN+1(Œª) is the fundamental matrix of the second equation in (5.168).
We point out that in the subsequent formulations of the oscillation theorems
for (5.162), the nonsingular matrices Q0(Œª) and QN+1(Œª) can be omitted because
of Theorem 3.5(i), which says that the comparative index is invariant with respect to

5.2
Eigenvalue Problems with General Boundary Conditions
309
multiplication by nonsingular matrices, i.e., Œº(YC, ÀÜY ÀÜC) = Œº(Y, ÀÜY) with det C Ã∏= 0
and det ÀÜC Ã∏= 0.
In the theorem below, we present a similar result on the equivalence of
problem (SDSŒª), (5.151) with the general (nonseparated) boundary conditions and
some 4n √ó 4n augmented problem with the separated boundary conditions. The
consideration is based on the notation in Sect. 3.3. Recall that in Sect. 3.3.5, we
introduced the notation
{W, V } :=
‚éõ
‚éú‚éú‚éù
A 0 ‚àíB 0
0
ÀÜA 0
ÀÜB
‚àíC 0 D
0
0
ÀÜC
0
ÀÜD
‚éû
‚éü‚éü‚é†,
{W} := {I, W} =
‚éõ
‚éú‚éú‚éù
I 0 0 0
0 A 0 B
0 0 I 0
0 C 0 D
‚éû
‚éü‚éü‚é†,
where
W =
A B
C D

,
V =

ÀÜA ÀÜB
ÀÜC ÀÜD

are 2n √ó 2n matrices; see formula (3.101). We also use the 4n √ó n matrices; see
formula (3.52),
‚ü®W‚ü©=
‚éõ
‚éú‚éú‚éù
I
0
A B
0 ‚àíI
C D
‚éû
‚éü‚éü‚é†.
Theorem 5.44 Under the assumptions (5.2), (5.3), (5.152), (5.153), the prob-
lem (SDSŒª) with (5.151) is equivalent to the augmented eigenvalue problem with
the separated boundary conditions
Àúyk+1(Œª) = {Sk(Œª)} Àúyk(Œª),
k ‚àà[0, N]Z,
 0 0
‚àíI I

Àúx0(Œª) +
‚àíI ‚àíI
0
0

Àúu0(Œª) = 0,
R1(Œª) ÀúxN+1(Œª) + R2(Œª) ÀúuN+1(Œª) = 0
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.178)
where
4n({Sk(Œª)}) := J4n{ ÀôSk(Œª)} J4n{ST
k (Œª)} J4n = {0, (Sk(Œª))} ‚â•0.
(5.179)
Proof Let Z[0](Œª) = ( ÀúY(Œª), Y(Œª)) be the fundamental symplectic matrix of (5.1)
given by the initial condition Z[0]
0 (Œª) = I. Then the general solution of (5.1) is of
the form yk(Œª) = Z[0]
k (Œª) c with c ‚ààR2n. Substituting this solution into (5.151), we

310
5
Discrete Symplectic Eigenvalue Problems
obtain
R1(Œª)

I
0
ÀúXN+1(Œª) XN+1(Œª)

c + R2(Œª)

0
‚àíI
ÀúUN+1(Œª) UN+1(Œª)

c
= R(Œª) /Z[0]
N+1(Œª)0 c = 0,
where R(Œª) = (R1(Œª) R2(Œª)) as in the beginning of this subsection and where
/Z[0]
N+1(Œª)0 = !Z[0]
N+1(Œª)"S0(0 I)T according to (3.104) and the notation introduced
in (3.101) and (3.102). Observe that matrices {W} and {V } deÔ¨Åned by (3.101) satisfy
{W}{V } = {WV } (see (3.103)). Consequently, the 4n √ó 2n matrix
/
Z[0]
k (Œª)
0
is
a conjoined basis (see Lemma 3.21(i)) of a symplectic system with the coefÔ¨Åcient
matrix {Sk(Œª)}, and it obviously satisÔ¨Åes (5.178) for k = 0. Then yk(Œª) = Z[0]
k (Œª) c
is a solution of (5.1) with (5.151) if and only if Àúyk(Œª) =
/
Z[0]
k (Œª)
0
c is a solution of
problem (5.178).
‚äì‚äî
At the end of this section, we formulate an analog of Theorem 5.44 for the case
when boundary conditions (5.151) are transformed into the left endpoint k = 0.
Theorem 5.45 Under the assumptions (5.2), (5.3), (5.152), (5.153), the prob-
lem (SDSŒª) with (5.151) is equivalent to the eigenvalue problem with the separated
boundary conditions
Àúyk+1(Œª) = {Sk(Œª)} Àúyk(Œª),
k ‚àà[0, N]Z,
ÀúR1(Œª) Àúx0(Œª) + ÀúR2(Œª) Àúu0(Œª) = 0,
 0 0
‚àíI I

ÀúxN+1(Œª) +
‚àíI ‚àíI
0
0

ÀúuN+1(Œª) = 0,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(5.180)
where we have monotonicity condition (5.179) for {Sk(Œª)} and where
ÀúR1(Œª) = R1(Œª) P1,
ÀúR2(Œª) = ‚àíR2(Œª) P1,
P1 :=
0 I
I 0

.
(5.181)
Here ÀúR(Œª) J4n ÀúRT (Œª) = 0 and rank ÀúR(Œª) = 2n with ÀúR(Œª) := ( ÀúR1(Œª) ÀúR2(Œª)) and,
moreover, instead of (5.153), we have (compare with (5.157))
ÀôÀúR1(Œª) ÀúRT
2 (Œª) ‚àíÀôÀúR2(Œª) ÀúRT
1 (Œª) = ÀôÀúR(Œª) J4n ÀúRT (Œª) ‚â•0.
(5.182)
Proof Let Z[N+1](Œª) = ( ÀúY(Œª), Y(Œª)) be the fundamental symplectic matrix
of (5.1) given by the initial condition Z[N+1]
N+1 (Œª) = I. Then the general solution
of (5.1) is of the form yk = Z[N+1]
k
(Œª) c with c ‚ààR2n. Substituting this solution

5.2
Eigenvalue Problems with General Boundary Conditions
311
into (5.151), we obtain
R1(Œª)
 ÀúX0(Œª) X0(Œª)
I
0

c + R2(Œª)
‚àíÀúU0(Œª) ‚àíU0(Œª)
0
I

c
= 
R1(Œª) P1 ‚àíR2(Œª) P1
 /Z[N+1]
0
(Œª)0 c = 0,
where
/
Z[N+1]
k
(Œª)
0
is a conjoined basis of the symplectic system in (5.180),
and it obviously satisÔ¨Åes (5.180) for k = N + 1. Then yk(Œª) = Z[N+1]
k
(Œª) c
is a solution of (5.1) with (5.151) if and only if Àúyk(Œª)
=
/Z[N+1]
k
(Œª)0 c
is a solution of (5.180). Recall also that the transformation of R(Œª)
=
(R1(Œª) R2(Œª)) =
ÀúR(Œª) diag{P1, ‚àíP1} with the matrix P1 deÔ¨Åned in (1.151)
(see also Lemma 1.58(iv)) completely preserves the symplectic structure of the
boundary conditions, i.e.,
ÀúRT (Œª) again obeys (1.147) and in the monotonicity
condition for ÀúR(Œª) the sign is opposite according to the demands for the separated
boundary conditions for k = 0; see (5.157).
‚äì‚äî
Remark 5.46 Assume for the moment that we construct extended problem (5.162)
for (5.178), and then the principal solution Y[‚àí1](Œª) of this problem obeys the
condition
Y[‚àí1]
0
(Œª) = ‚ü®I‚ü©,
(5.183)
i.e., instead of this principal solution, one can consider the conjoined basis /Z[0](Œª)0
of the augmented system in (5.178). Here Z[0](Œª) is the fundamental matrix of (5.1)
such that Z[0]
0 (Œª) = I; see the proof of Theorem 5.44. In a similar way, the
principal solution Y[N+2](Œª) at k = N +2 of extended problem (5.162) constructed
for (5.180) satisÔ¨Åes the condition
Y[N+2]
N+1 (Œª) = ‚ü®I‚ü©,
(5.184)
and then the conjoined basis
/
Z[N+1](Œª)
0
of the augmented system in (5.180) can be
used instead of Y[N+2](Œª). Here Z[N+1](Œª) is the fundamental matrix of (5.1) such
that Z[N+1]
N+1 (Œª) = I; see the proof of Theorem 5.45.
5.2.2
Transformation of Quadratic Functionals
In this subsection we extend the transformations from the previous subsection
to include the associated quadratic functionals. Following (2.56) and (5.138), we
consider the associated quadratic functional for admissible functions y = (x, u),
i.e., xk+1 = Ak(Œª) xk +Bk(Œª) uk for k ‚àà[0, N]Z. Given the 2n√ó2n matrices R1(Œª)

312
5
Discrete Symplectic Eigenvalue Problems
and R2(Œª) satisfying (5.152), we deÔ¨Åne the symmetric 2n √ó 2n matrix (see (2.92))
(Œª) := R‚Ä†
2(Œª) R1(Œª) R‚Ä†
2(Œª) R2(Œª)
(5.185)
and the quadratic functional
G(y, Œª) := F(y, Œª) +
 x0
xN+1
T
(Œª)
 x0
xN+1

,
(5.186)
where F(y, Œª) is deÔ¨Åned in (5.138) and where y is admissible and satisÔ¨Åes the
general boundary conditions
 x0
xN+1

‚ààIm RT
2 (Œª).
(5.187)
The functional G(¬∑, Œª) is said to be positive if G(y, Œª) > 0 for every admissible
y = (x, u) satisfying (5.187) and x Ã∏‚â°0. In this case we write G(¬∑, Œª) > 0. Similarly,
the functional G(¬∑, Œª) is said to be nonnegative if G(y, Œª) ‚â•0 for every admissible
y = (x, u) satisfying (5.187), we write G(¬∑, Œª) ‚â•0.
When the boundary conditions are separated, i.e., when (5.154) holds with
n √ó n matrices R0(Œª), R‚àó
0(Œª), RN+1(Œª), R‚àó
N+1(Œª) satisfying (5.156), the functional
G(y, Œª) in (5.186) takes the form
G(y, Œª) = F(y, Œª) + xT
0 0(Œª) x0 + xT
N+1 N+1(Œª) xN+1,
(5.188)
where the symmetric n √ó n matrices 0(Œª) and N+1(Œª) are deÔ¨Åned by (see (2.83))
0(Œª) := ‚àíR‚Ä†
0(Œª) R‚àó
0(Œª) R‚Ä†
0(Œª) R0(Œª),
N+1(Œª) := R‚Ä†
N+1(Œª) R‚àó
N+1(Œª) R‚Ä†
N+1(Œª) RN+1(Œª),

(5.189)
so that (Œª) = diag{0(Œª), N+1(Œª)}. The boundary conditions in (5.187) are then
also separated and have the form
x0 ‚ààIm RT
0 (Œª),
xN+1 ‚ààIm RT
N+1(Œª).
(5.190)
First we consider the quadratic functional G(y, Œª) in (5.188) with separated end-
points (5.190). We deÔ¨Åne the extended quadratic functional Fext(y, Œª) in (5.191),
compared with (5.138), by
Fext(y, Œª) :=
N+1

k=‚àí1
yT
k

ST
k (Œª) K Sk(Œª) ‚àíK

yk,
(5.191)
= F(y, Œª) + Œ≥‚àí1(Œª) + Œ≥N+1(Œª),
(5.192)

5.2
Eigenvalue Problems with General Boundary Conditions
313
for an admissible y on [‚àí1, N + 2]Z satisfying x‚àí1 = 0 = xN+2. Here the matrices
S‚àí1(Œª) and SN+1(Œª) are deÔ¨Åned by (5.171) and (5.173) and
Œ≥k(Œª) := yT
k

ST
k (Œª) K Sk(Œª) ‚àíK

yk,
k ‚àà{‚àí1, N + 1}.
Lemma 5.47 Assume that the matrices R0(Œª), R‚àó
0(Œª), RN+1(Œª), R‚àó
N+1(Œª) sat-
isfy (5.156) and 0(Œª), N+1(Œª) are deÔ¨Åned by (5.189). If y is admissible on
[‚àí1, N +2]Z with x‚àí1 = 0 = xN+2, then y is admissible on [0, N +1]Z with (5.190)
and G(y, Œª) = Fext(y, Œª). Conversely, if y is admissible on [0, N +1]Z with (5.190),
then it can be extended to be admissible on [‚àí1, N +2]Z with x‚àí1 = 0 = xN+2 and
Fext(y, Œª) = G(y, Œª). In particular, we have G(¬∑, Œª) > 0 over (5.190) if and only if
Fext(¬∑, Œª) > 0 over x‚àí1 = 0 = xN+2 and G(¬∑, Œª) ‚â•0 over (5.190) if and only if
Fext(¬∑, Œª) ‚â•0 over x‚àí1 = 0 = xN+2.
Proof First we assume that y is admissible on [‚àí1, N + 2]Z with x‚àí1 = 0 = xN+2.
Then y is admissible on [0, N + 1]Z as well and
x0 = A‚àí1(Œª) x‚àí1 + B‚àí1(Œª) u‚àí1 = ‚àíRT
0 (Œª) Q0(Œª) u‚àí1 ‚ààIm RT
0 (Œª),
see (5.175). Moreover, we have
0 = xN+2 = AN+1(Œª) xN+1 + BN+1(Œª) uN+1
= QT
N+1(Œª) [R‚àó
N+1(Œª) xN+1 + RN+1(Œª) uN+1],
which implies that, see Lemma 1.58(vii) and (5.156),
yN+1 =
xN+1
uN+1

‚ààKer R‚àó
N+1(Œª), RN+1(Œª) = Im

‚àíRT
N+1(Œª)
R‚àóT
N+1(Œª)

.
Therefore, for some d ‚ààRn, we get
xN+1 = ‚àíRT
N+1(Œª) d ‚ààIm RT
N+1(Œª),
uN+1 = R‚àóT
N+1(Œª) d.
(5.193)
Then by using x‚àí1 = 0, B‚àí1(Œª) B‚Ä†
‚àí1(Œª) = R‚Ä†
0(Œª) R0(Œª), and the symmetry of the
matrix BT
‚àí1(Œª) D‚àí1(Œª), we obtain
Œ≥‚àí1(Œª) = uT
‚àí1BT
‚àí1(Œª) D‚àí1(Œª) u‚àí1 = xT
0 0(Œª) x0.
(5.194)
Moreover, following the proof of Lemma 2.30 and using (5.193), we have (sup-
pressing the argument Œª by the coefÔ¨Åcients of SN+1(Œª))
Œ≥N+1(Œª) = xT
N+1CT
N+1(AN+1xN+1 + BN+1uN+1)
+ uT
N+1(DT
N+1AN+1 ‚àíI) xN+1 + uT
N+1DT
N+1BN+1uN+1

314
5
Discrete Symplectic Eigenvalue Problems
= (xT
N+1CT
N+1 + uT
N+1DT
N+1) xN+2 ‚àíuT
N+1xN+1
= xT
N+1 N+1(Œª) xN+1.
(5.195)
This shows that G(y, Œª) = Fext(y, Œª). Conversely, if y is admissible on [0, N + 1]Z
with (5.190), i.e., x0 = RT
0 (Œª) c and xN+1 = RT
N+1(Œª) d for some c, d ‚ààRn, then
we deÔ¨Åne
x‚àí1 := 0,
u‚àí1 := B‚Ä†
‚àí1(Œª) x0,
uN+1 := R‚àóT
N+1(Œª) d,
xN+2 := 0.
Then we get
A‚àí1(Œª) x‚àí1 + B‚àí1(Œª) u‚àí1
= B‚àí1(Œª) B‚Ä†
‚àí1(Œª) x0 = R‚Ä†
0(Œª) R0(Œª) RT
0 (Œª) c = RT
0 (Œª) c = x0,
AN+1(Œª) xN+1 + BN+1(Œª) uN+1
= QT
N+1(Œª) [R‚àó
N+1(Œª) RT
N+1(Œª) ‚àíRN+1(Œª) R‚àóT
N+1(Œª)] d = 0 = xN+2.
Therefore, y is admissible on [‚àí1, N + 2]Z with x‚àí1 = 0 = xN+2. The same
calculations as in (5.194) and (5.195) then show that also in this case Fext(y, Œª) =
G(y, Œª). Finally, since we extend the x component of an admissible y at k = ‚àí1 and
k = N + 2 by the zero values x‚àí1 = 0 and xN+2 = 0, it follows that G(¬∑, Œª) > 0
over (5.190) if and only if Fext(¬∑, Œª) > 0 over x‚àí1 = 0 = xN+2, and G(¬∑, Œª) ‚â•0
over (5.190) if and only if Fext(¬∑, Œª) ‚â•0 over x‚àí1 = 0 = xN+2. The proof is
complete.
‚äì‚äî
Next we consider the general quadratic functional G(y, Œª) in (5.186) over the
jointly varying endpoints (5.187). Given the 2n √ó 2n matrices R1(Œª), R2(Œª), and
(Œª) satisfying (5.152) and (5.185), we deÔ¨Åne the auxiliary 2n √ó 2n matrices
ÀúR‚àó
0(Œª) :=
 0 0
‚àíI I

,
ÀúR0(Œª) :=
‚àíI ‚àíI
0
0

,
ÀúR‚àó
N+1(Œª) := R1(Œª),
ÀúRN+1(Œª) := R2(Œª),
Àú0(Œª) := 0,
ÀúN+1(Œª) := (Œª).
‚é´
‚é™‚é¨
‚é™‚é≠
(5.196)
In addition, we deÔ¨Åne the the augmented quadratic functional
ÀúFaug( Àúy, Œª) := ÀúF( Àúy, Œª) + ÀúxT
0 Àú0 Àúx0 + ÀúxT
N+1 ÀúN+1 ÀúxN+1
(5.197)
over the separated endpoints
Àúx0 ‚ààIm ÀúRT
0 (Œª),
ÀúxN+1 ‚ààIm ÀúRT
N+1(Œª),
(5.198)

5.2
Eigenvalue Problems with General Boundary Conditions
315
where the functional ÀúF( Àúy, Œª) is deÔ¨Åned by, compared with (5.138),
ÀúF( Àúy, Œª) :=
N

k=0
ÀúyT
k
 ÀúST
k (Œª) ÀúK ÀúSk(Œª) ‚àíÀúK

Àúyk,
ÀúK :=
02n 02n
I2n 02n

,
(5.199)
and where the 4n √ó 4n matrix ÀúSk(Œª) is the coefÔ¨Åcient matrix of the symplectic
system in (5.178), i.e., for k ‚àà[0, N]Z, we set
ÀúSk(Œª) =
 ÀúAk(Œª) ÀúBk(Œª)
ÀúCk(Œª) ÀúDk(Œª)

:= {Sk(Œª)} =
‚éõ
‚éú‚éú‚éù
I
0
0
0
0 Ak(Œª) 0 Bk(Œª)
0
0
I
0
0 Ck(Œª) 0 Dk(Œª)
‚éû
‚éü‚éü‚é†.
(5.200)
It is easy to verify by a direct calculation that
ÀúST
k (Œª) ÀúK ÀúSk(Œª) ‚àíÀúK = {0, ST
k (Œª) K Sk(Œª) ‚àíK},
(5.201)
where we use the notation given by (3.101).
The following result describes the connection between the functionals G(y, Œª)
in (5.186) and ÀúFaug( Àúy, Œª) in (5.197).
Lemma 5.48 Assume that the matrices R1(Œª), R2(Œª) satisfy (5.152) and (Œª) is
deÔ¨Åned by (5.185). If y is (A(Œª), B(Œª))-admissible with (5.187), then Àúy = (Àúx, Àúu)
deÔ¨Åned by
Àúxk :=
x0
xk

,
k ‚àà[0, N + 1]Z,
Àúuk :=
‚àíu0
uk

,
k ‚àà[0, N]Z,
(5.202)
is ( ÀúA(Œª), ÀúB(Œª))-admissible with (5.198) and ÀúFaug( Àúy, Œª) = G(y, Œª). Conversely, if Àúy
is ( ÀúA(Œª), ÀúB(Œª))-admissible with (5.198), then y = (x, u) given by
xk := (0 I) Àúxk,
k ‚àà[0, N + 1]Z,
uk := (0 I) Àúuk,
k ‚àà[0, N]Z,
(5.203)
is (A(Œª), B(Œª))-admissible with (5.187) and G(y, Œª) = ÀúFaug( Àúy, Œª). In particular,
we have G(¬∑, Œª) > 0 over (5.187) if and only if ÀúFaug(¬∑, Œª) > 0 over (5.198) and
G(¬∑, Œª) ‚â•0 over (5.187) if and only if ÀúFaug(¬∑, Œª) ‚â•0 over (5.198)
Proof Assume that y is (A(Œª), B(Œª))-admissible with (5.187) and deÔ¨Åne Àúy = (Àúx, Àúu)
by (5.202). Then Àúy is ( ÀúA(Œª), ÀúB(Œª))-admissible, (5.198) holds, and the equality
ÀúFaug( Àúy, Œª) = G(y, Œª) follows by (5.201). Conversely, assume that Àúy = (Àúx, Àúu)
is ( ÀúA(Œª), ÀúB(Œª))-admissible with (5.198). Then Àúxk has the form in (5.202) for
k ‚àà[0, N + 1]Z, while Àúuk = (Œ≤T
k , uT
k )T for some Œ≤k ‚ààRn for k ‚àà[0, N]Z,
where y := (x, u) is (A(Œª), B(Œª))-admissible and satisÔ¨Åes (5.187). The equality
G(y, Œª) = ÀúFaug( Àúy, Œª) again follows by (5.201).
‚äì‚äî

316
5
Discrete Symplectic Eigenvalue Problems
5.2.3
Oscillation Theorems for General Endpoints
In this subsection we derive the oscillation theorem for the eigenvalue problem (5.1)
with general boundary conditions. First we consider the separated endpoints (5.155).
Let ¬ØY(Œª) = ( ¬ØX(Œª), ¬ØU(Œª)) be the so-called natural conjoined basis of system (5.1),
i.e., it the conjoined basis satisfying the initial conditions
¬ØX0(Œª) = ‚àíRT
0 (Œª),
¬ØU0(Œª) = R‚àóT
0 (Œª),
Œª ‚ààR.
(5.204)
Then we deÔ¨Åne for Œª ‚ààR the auxiliary matrices
(Œª) := R‚àó
N+1(Œª) ¬ØXN+1(Œª) + RN+1(Œª) ¬ØUN+1(Œª),
M(Œª) := [I ‚àí(Œª) ‚Ä†(Œª)] RN+1(Œª),
T (Œª) := I ‚àíM‚Ä†(Œª) M(Œª),
P(Œª) := T (Œª) ¬ØXN+1(Œª) ‚Ä†(Œª) RN+1(Œª) T (Œª).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.205)
We will see in the proof of the main result below (Theorem 5.50) that under
assumptions (5.156)‚Äì(5.158) the quantity rank (Œª) is piecewise constant on R.
This fact allows to make the following deÔ¨Ånition.
DeÔ¨Ånition 5.49 We say that Œª0
‚ààR is a Ô¨Ånite eigenvalue of problem (5.1)
with (5.155) if
Œ∏(Œª0) := rank(Œª‚àí
0 ) ‚àírank(Œª0) ‚â•1.
(5.206)
In this case the number Œ∏(Œª0) is called an algebraic multiplicity of Œª0 as a Ô¨Ånite
eigenvalue of (5.1), (5.155).
As in Sect. 5.1.3, we will count the Ô¨Ånite eigenvalues including their multiplici-
ties. We will also use the notation:
n1(Œª) := number of forward focal points of ¬ØY(Œª) in (0, N + 1],
(5.207)
n2(Œª) := number of Ô¨Ånite eigenvalues of (5.1), (5.155) in (‚àí‚àû, Œª],
(5.208)
p(Œª) := rankM(Œª) + ind P(Œª),
(5.209)
that is, n1(Œª) = l( ¬ØY(Œª), 0, N + 1) according to notation (4.10). The next result is
a generalization of Theorem 5.17 from Dirichlet boundary conditions x0(Œª) = 0 =
xN+1(Œª) to general separated boundary conditions (5.155). Namely, the choice of
R‚àó
0(Œª) = I = R‚àó
N+1(Œª) and R0(Œª) = 0 = RN+1(Œª) yields Theorem 5.17 from
Theorem 5.50.

5.2
Eigenvalue Problems with General Boundary Conditions
317
Theorem 5.50 (Global Oscillation Theorem for Separated Endpoints) Let us
assume that the matrices R0(Œª), R‚àó
0(Œª), RN+1(Œª), R‚àó
N+1(Œª) are piecewise con-
tinuously differentiable on R and satisfy conditions (5.156)‚Äì(5.158). Furthermore,
suppose that
rankBk(Œª) is constant for Œª ‚ààR for all k ‚àà[0, N]Z
rankR0(Œª) and rank RN+1(Œª) are constant for Œª ‚ààR.

(5.210)
Then with the notation (5.207)‚Äì(5.209), we have for every Œª ‚ààR the identities
n1(Œª+) = n1(Œª) ‚â§(N + 1) n,
p(Œª+) = p(Œª),
(5.211)
n2(Œª+) = n2(Œª),
(5.212)
n2(Œª+) ‚àín2(Œª‚àí) = n1(Œª+) ‚àín1(Œª‚àí) + p(Œª+) ‚àíp(Œª‚àí),
(5.213)
and there exists ‚Ñì‚àà[0, (N + 2) n]Z such that
n1(Œª) + p(Œª) = n2(Œª) + ‚Ñì,
Œª ‚ààR.
(5.214)
Moreover, for a suitable Œª0 < 0, we have
n2(Œª) ‚â°0,
n1(Œª) + p(Œª) ‚â°‚Ñì,
Œª ‚â§Œª0.
(5.215)
Remark 5.51 Under the assumptions of Theorem 5.50, it follows by Theorem 5.3
that the Ô¨Ånite eigenvalues of (5.1), (5.155) are isolated and bounded from below and
from above. The Ô¨Årst condition in (5.215) then means that these Ô¨Ånite eigenvalues
are bounded from below, while conditions (5.214) and (5.211) imply that the Ô¨Ånite
eigenvalues are bounded from above.
Proof of Theorem 5.50 The method is to transform (by Lemma 5.40) the prob-
lem (5.1), (5.155) into the extended problem (5.162) on the interval [‚àí1, N + 2]Z,
to which the result in Theorem 5.17 can be applied. Consider the principal solution
Y [‚àí1](Œª) at k = ‚àí1 of the extended symplectic system in (5.162). Then by
Remark 5.43 (see (5.176)), we have Y [‚àí1]
0
(Œª) = ¬ØY0(Œª) Q0(Œª), so that
Y [‚àí1]
k
(Œª) = ¬ØYk(Œª) Q0(Œª),
k ‚àà[0, N + 1]Z,
ÀÜY [‚àí1]
N+2(Œª) = Q(Œª) VN+1(Œª) ¬ØYN+1(Œª) Q0(Œª),
Q(Œª) := diag{QT
N+1(Œª), Q‚àí1
N+1(Œª)},
‚é´
‚é™‚é¨
‚é™‚é≠
(5.216)
where the symplectic matrix VN+1(Œª) is given by (5.173). Then we can write
X[‚àí1]
N+2(Œª) = QT
N+1(Œª) (Œª) Q0(Œª) by the deÔ¨Ånition of (Œª) in (5.205). This implies
by Theorems 1.81 and 1.82 that the image of X[‚àí1]
N+2(Œª) and the rank of (Œª) are
piecewise constant on R. Moreover, by (5.216) the multiplicities of focal points of

318
5
Discrete Symplectic Eigenvalue Problems
Y [‚àí1]
k
(Œª) and ¬ØYk(Œª) are connected as follows:
m(Y [‚àí1]
‚àí1 (Œª)) = 0,
m(Y [‚àí1]
k
(Œª)) = ŒºY [‚àí1]
k+1 (Œª), Sk(Œª) (0 I)T  = Œº ¬ØYk+1(Œª) Q0(Œª), Sk(Œª) (0 I)T 
= Œº
 ¬ØYk+1(Œª), Sk(Œª) (0 I)T 
= m( ¬ØYk(Œª)),
k ‚àà[0, N]Z,
where we used Lemma 4.7 (see (4.14)) and Theorem 3.5(i). Moreover, for k =
N + 1, we have (see (5.216))
m(Y [‚àí1]
N+1(Œª)) = Œº

Y [‚àí1]
N+2(Œª), SN+1(Œª) (0 I)T 
= Œº

Q(Œª) VN+1(Œª) ¬ØYN+1(Œª) Q0(Œª), Q(Œª) VN+1(Œª) (0 I)T 
= Œº

VN+1(Œª) ¬ØYN+1(Œª), VN+1(Œª) (0 I)T 
= p(Œª),
where we again used Lemma 4.7 (see (4.14)), Theorem 3.5(i)‚Äì(ii), the deÔ¨Ånition
of the comparative index ŒºVN+1(Œª) ¬ØYN+1(Œª), VN+1(Œª) (0 I)T  according to The-
orem 3.2(i), and (5.205) for p(Œª). Note that by Theorem 5.15, we have that the
multiplicities m(Y [‚àí1]
k
(Œª)) of focal points of the principal solution Y [‚àí1]
k
(Œª) of the
extended problem (5.162) on the interval [‚àí1, N + 2]Z are right-continuous in Œª for
k ‚àà[0, N + 1]Z, and then the same property holds for m( ¬ØYk(Œª)) for k ‚àà[0, N]Z and
p(Œª). Therefore, we have proved (5.211).
Moreover, the Ô¨Ånite eigenvalues of the extended problem (5.162) according to
DeÔ¨Ånition 5.5 coincide with the Ô¨Ånite eigenvalues of (5.1), (5.155) according to
DeÔ¨Ånition 5.49. By (5.175) and (5.210), we guarantee that assumption (5.38) is
satisÔ¨Åed for all k ‚àà[‚àí1, N + 1]Z, and hence, the results in (5.213)‚Äì(5.215) follow
from the corresponding statements in Theorems 5.16 and 5.17. We remark that the
number ‚Ñìin (5.214) denotes the number of forward focal points of Y [‚àí1](Œª) in
(‚àí1, N + 2] for Œª sufÔ¨Åciently negative, and it is estimated, according to (5.47)
and (5.56), as
‚Ñì=
lim
Œª‚Üí‚àí‚àû[n1(Œª) + p(Œª)] ‚â§(N + 1) n + n = (N + 2) n.
(5.217)
The proof is complete.
‚äì‚äî
Remark 5.52 In the proof of Theorem 5.50, we have shown that the function p(Œª)
given by (5.205) can be presented in terms of the comparative index as follows
p(Œª) = Œº(VN+1(Œª) ¬ØYN+1(Œª), VN+1(Œª) (0 I)T ),
(5.218)
where VN+1(Œª) is given by (5.173).

5.2
Eigenvalue Problems with General Boundary Conditions
319
The following result is a generalization of Theorem 5.31 from the Dirichlet
endpoints to the case of separated endpoints. We utilize the quadratic functional
G(y, Œª) deÔ¨Åned in (5.188), which is considered over the separated endpoints (5.190).
Theorem 5.53 Assume that the matrices R0(Œª), R‚àó
0(Œª), RN+1(Œª), R‚àó
N+1(Œª) are
piecewise continuously differentiable on R and satisfy conditions (5.156)‚Äì(5.158)
and (5.210). Then with the notation (5.207)‚Äì(5.209), we have
n1(Œª) + p(Œª) = n2(Œª),
Œª ‚ààR,
(5.219)
if and only if there exists Œª0 < 0 such that the quadratic functional G(y, Œª) in (5.188)
obeys the condition G(¬∑, Œª0) > 0.
Proof The result follows from the application of Theorem 5.31 to the extended
problem (5.162) on the interval [‚àí1, N + 2]Z, once we take into account the
connection between the quadratic functional G(y, Œª) in (5.188) over (5.190) and
the extended quadratic functional Fext(y, Œª) in (5.191) over x‚àí1 = 0 = xN+2 in
Lemma 5.47.
‚äì‚äî
Next we consider the eigenvalue problem (5.1) with general jointly varying
endpoints (5.151). Under the notation of Theorem 5.44, consider the symplectic
fundamental matrix Z[0](Œª) of (5.1) such that Z[0]
0 (Œª) = I and for k ‚àà[0, N + 1]Z
deÔ¨Åne the augmented 4n √ó 2n matrix Y(Œª) = ‚ü®Z[0](Œª)‚ü©with the 2n √ó 2n blocks
Xk(Œª) :=

I
0
ÀúXk(Œª) X[0]
k (Œª)

,
Uk(Œª) :=

0
‚àíI
ÀúUk(Œª) U[0]
k (Œª)

,
(5.220)
where Y [0](Œª) =

X[0](Œª)
U[0](Œª)

is the principal solution of (5.1) at k = 0. We note
that the pair Y(Œª) := (X(Œª), U(Œª)) constitutes a conjoined basis of the augmented
system in (5.178). Finally, following (5.205), we deÔ¨Åne the 2n √ó 2n matrices
L(Œª) := R1(Œª) XN+1(Œª) + R2(Œª) UN+1(Œª),
M(Œª) := [I ‚àíL(Œª) L‚Ä†(Œª)] R2(Œª),
T (Œª) := I ‚àíM‚Ä†(Œª) M(Œª),
P(Œª) := T (Œª) XN+1(Œª) L‚Ä†(Œª) R2(Œª) T (Œª).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.221)
We will see as before that under assumptions (5.152) and (5.153), the quantity
rankL(Œª) is piecewise constant on R. Therefore, we make the following deÔ¨Ånition.
DeÔ¨Ånition 5.54 We say that Œª0
‚ààR is a Ô¨Ånite eigenvalue of problem (5.1)
with (5.151) if
Œ∂(Œª0) := rank L(Œª‚àí
0 ) ‚àírank L(Œª0) ‚â•1.
(5.222)

320
5
Discrete Symplectic Eigenvalue Problems
In this case the number Œ∂(Œª0) is called an algebraic multiplicity of Œª0 as a Ô¨Ånite
eigenvalue of (5.1), (5.151).
We will again count the Ô¨Ånite eigenvalues including their multiplicities. We will
use the notation:
n1(Œª) := number of forward focal points of Y [0](Œª) in (0, N + 1],
(5.223)
n2(Œª) := number of Ô¨Ånite eigenvalues of (5.1), (5.151) in (‚àí‚àû, Œª],
(5.224)
q(Œª) := rankM(Œª) + ind P(Œª),
(5.225)
that is, n1(Œª) = l(Y [0](Œª), 0, N + 1) according to (4.10). The next result is
a generalization of Theorem 5.17 from Dirichlet boundary conditions x0(Œª) = 0 =
xN+1(Œª) to general jointly varying boundary conditions (5.151). Namely, the choice
of R1(Œª) = I and R1(Œª) = 0 yields Theorem 5.17 from Theorem 5.55.
Theorem 5.55 (Global Oscillation Theorem for Joint Endpoints)
Suppose that
the matrices R1(Œª) and R2(Œª) are piecewise continuously differentiable on R and
satisfy conditions (5.152)‚Äì(5.153). Furthermore, suppose that
rankBk(Œª) is constant for Œª ‚ààR for all k ‚àà[0, N]Z
rankR2(Œª) is constant for Œª ‚ààR.

(5.226)
Then with the notation (5.223)‚Äì(5.225), we have for every Œª ‚ààR the identities
n1(Œª+) = n1(Œª) ‚â§Nn, q(Œª+) = q(Œª),
(5.227)
n2(Œª+) = n2(Œª),
(5.228)
n2(Œª+) ‚àín2(Œª‚àí) = n1(Œª+) ‚àín1(Œª‚àí) + q(Œª+) ‚àíq(Œª‚àí),
(5.229)
and there exists ‚Ñì‚àà[0, (N + 2)n]Z such that
n1(Œª) + q(Œª) = n2(Œª) + ‚Ñì,
Œª ‚ààR.
(5.230)
Moreover, for a suitable Œª0 < 0, we have
n2(Œª) ‚â°0,
n1(Œª) + q(Œª) ‚â°‚Ñì,
Œª ‚â§Œª0.
(5.231)
Proof We make the transformation of problem (5.1) with the joint boundary
conditions (5.151) to the augmented problem (5.178) with separated boundary
conditions, which is described in Theorem 5.44. We deÔ¨Åne the 2n √ó 2n matrices
ÀúR‚àó
0(Œª), ÀúR0(Œª), ÀúR‚àó
N+1(Œª), ÀúRN+1(Œª) by (5.196) and the augmented problem
Àúyk+1(Œª) = ÀúSk(Œª) Àúyk(Œª),
k ‚àà[0, N]Z,
ÀúR‚àó
0(Œª) Àúx0(Œª) + ÀúR0(Œª) Àúu0(Œª) = 0,
ÀúR‚àó
N+1(Œª) ÀúxN+1(Œª) + ÀúRN+1(Œª) ÀúuN+1(Œª) = 0.
‚é´
‚é™‚é¨
‚é™‚é≠
(5.232)

5.2
Eigenvalue Problems with General Boundary Conditions
321
with the 4n √ó 4n symplectic coefÔ¨Åcient matrix ÀúSk(Œª) = {Sk(Œª)} in (5.200). Then
the monotonicity assumption (5.157) for the augmented problem (5.232) is trivially
satisÔ¨Åed, since the matrices ÀúR‚àó
0(Œª) and ÀúR0(Œª) do not depend on Œª, as well as
rank ÀúR0(Œª) ‚â°n is constant for Œª ‚ààR. Assumption (5.158) for the augmented
problem (5.232) is also satisÔ¨Åed by condition (5.153). Note the correct inequality
‚Äú‚â§0‚Äù in the assumptions (5.158) and (5.153). Finally,
rank ÀúBk(Œª) = rank diag{0, Bk(Œª)} = rankBk(Œª)
is constant for Œª ‚ààR
for all k ‚àà[0, N]Z. Regarding the natural conjoined basis of the augmented problem,
by the uniqueness of solutions, we obtain that the augmented conjoined basis
ÀúY(Œª) = ( ÀúX (Œª), ÀúU(Œª)) of the system in (5.232) satisfying the initial conditions,
compared with (5.204),
ÀúX0(Œª) = ‚àíÀúRT
0 (Œª) =
I 0
I 0

,
ÀúU0(Œª) = ÀúR‚àóT
0 (Œª) =
0 ‚àíI
0 I

,
is equal to Y(Œª) = (X(Œª), U(Œª)) given in (5.220). Thus, the Ô¨Ånite eigenvalues
of problem (5.232) according to DeÔ¨Ånition 5.49 translate as the Ô¨Ånite eigenvalues
of (5.1) with (5.151) according to DeÔ¨Ånition 5.54. The result in the theorem then
follows by the application of Theorem 5.50 to the augmented problem (5.232). In
more details, we prove that
m( ÀúYk(Œª)) = m(Y [0]
k (Œª)),
k ‚àà[0, N]Z,
(5.233)
where Y [0](Œª) is the principal solution of (5.1) at k = 0. Indeed, we have by
Lemma 4.7 and Proposition 3.37 (see (3.107), (3.108))
m( ÀúYk(Œª)) = Œº‚ü®Z[0]
k+1‚ü©, {Sk(Œª)}(02n I2n)T 
= Œº

{Z[0]
k+1}(02n I2n)T , {Sk(Œª)}(02n I2n)T 
= Œº

Y [0]
k+1(Œª), Sk(Œª) (0 I)T 
= m(Y [0]
k (Œª)).
We note that the number ‚Ñìin (5.230) denotes the number of forward focal points
of ÀúY(Œª) or equivalently of Y [0](Œª) in (0, N + 1] for Œª sufÔ¨Åciently negative, and it
satisÔ¨Åes the estimate
‚Ñì=
lim
Œª‚Üí‚àí‚àû[n1(Œª) + q(Œª)] ‚â§Nn + 2n = (N + 2) n,
(5.234)
compared with (5.217). This estimate is better than the one, which we could obtain
from a direct application of Theorem 5.50 to the augmented problem in dimension
2n, which yields that ‚Ñì‚â§(N + 2) 2n. The proof is complete.
‚äì‚äî

322
5
Discrete Symplectic Eigenvalue Problems
Remark 5.56 As in Remark 5.51, we point out that, under the assumptions of
Theorem 5.55, the Ô¨Ånite eigenvalues of (5.1), (5.151) are isolated and bounded from
below and from above.
The following result is a generalization of Theorem 5.31 from the Dirichlet
endpoints to jointly varying endpoints. We utilize the quadratic functional G(y, Œª)
deÔ¨Åned in (5.186), which is considered over the jointly varying endpoints (5.187).
Theorem 5.57 Assume that R1(Œª) and R2(Œª) are piecewise continuously differ-
entiable on R and satisfy conditions (5.152)‚Äì(5.153) and (5.226). Then with the
notation (5.223)‚Äì(5.225), we have
n1(Œª) + q(Œª) = n2(Œª),
Œª ‚ààR,
(5.235)
if and only if there exists Œª0 < 0 such that the quadratic functional G(y, Œª) in (5.186)
over (5.187) obeys the condition G(¬∑, Œª0) > 0.
Proof The result follows from the application of Theorem 5.53 to the augmented
problem (5.232), when we take into account the connection between the quadratic
functional G(y, Œª) in (5.186) over (5.187) and the augmented quadratic functional
ÀúFaug( Àúy, Œª) in (5.197) over (5.198) in Lemma 5.48.
‚äì‚äî
Remark 5.58 The periodic and antiperiodic boundary conditions are included
in (5.155) for the special choice of constant matrices R1(Œª) and R2(Œª). Indeed, for
the periodic endpoints, we have
y0(Œª) = yN+1(Œª),
R1(Œª) =
 0 0
‚àíI I

,
R2(Œª) = ‚àí
I I
0 0

,
L(Œª) = L1(Œª) := J ‚àíJ

ÀúYN+1(Œª) Y [0]
N+1(Œª)

= J I ‚àíZ[0](Œª),
R‚Ä†
2(Œª) = 1
2 RT
2 (Œª),
 = 0,
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.236)
where  is given by (5.185), while for the antiperiodic endpoints, we have
y0(Œª) = ‚àíyN+1(Œª),
R1(Œª) = ‚àí
0 0
I I

,
R2(Œª) =
‚àíI I
0 0

,
L(Œª) = L2(Œª) := J + J

ÀúYN+1(Œª) Y [0]
N+1(Œª)

= J

I + Z[0](Œª)

,
R‚Ä†
2(Œª) = 1
2 RT
2 (Œª),
 = 0.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.237)
5.3
Linear Dependence on Spectral Parameter
In this section we consider an eigenvalue problem with a linear dependence on the
spectral parameter. In particular, we will investigate the problem with the special
linear dependence on Œª, in which the Ô¨Årst equation of (SDSŒª) does not depend on

5.3
Linear Dependence on Spectral Parameter
323
the spectral parameter Œª, i.e.,
xk+1(Œª) = Akxk(Œª) + Bkuk(Œª),
uk+1(Œª) = Ckxk(Œª) + Dkuk(Œª) ‚àíŒªWkxk+1(Œª),

k ‚àà[0, N]Z.
(5.238)
This will allow to use the theory of discrete quadratic functionals (see Sect. 2.3.2),
for which the set of admissible pairs y = (x, u) does not depend on Œª. For this
special case, the matrix Sk(Œª) in (E) has the form
Sk(Œª) =

I
0
‚àíŒªWk I

Sk,
Sk =
Ak Bk
Ck Dk

,
(5.239)
where Sk is symplectic and
Wk = WT
k ,
Wk ‚â•0,
k ‚àà[0, N]Z.
(5.240)
Then, applying Proposition 1.76(i) to the product

I
0
‚àíŒªWk I

Sk, we see that the
symmetric matrix (Sk(Œª)) for this special case has the form
k(Œª) ‚â°k :=
Wk 0
0 0

‚â•0,
k ‚àà[0, N]Z,
Œª ‚ààR.
(5.241)
In this section we apply the results of Sect. 5.1 to problem (E) with this special
linear dependence on Œª; in particular, we concentrate on the speciÔ¨Åc properties of
this problem which do not hold for the general nonlinear case. Further results about
system (5.238) will be presented in Sects. 5.4 and 5.5.
5.3.1
Transformation of Boundary Conditions
In this subsection we consider system (5.238) together with the self-adjoint
boundary conditions (5.151), which are in the special form
R1(Œª)
 x0(Œª)
xN+1(Œª)

+ R2(Œª)
 ‚àíu0(Œª)
uN+1(Œª)

= 0,
R1(Œª) := R1 ‚àíŒªR2 W,
R2(Œª) := R2.
‚é´
‚é¨
‚é≠
(5.242)
Here the constant matrices R1, R2, W obey the conditions (compared with (5.152))
R1, R2 ‚ààR2n√ó2n,
rank(R1 R2) = 2n,
R1RT
2 = R2RT
1 ,
W = WT .

(5.243)

324
5
Discrete Symplectic Eigenvalue Problems
Note that monotonicity assumption (5.153) for this special case is equivalent to
ÀôR1(Œª) RT
2 = ‚àíR2 WRT
2 ‚â§0,
which is satisÔ¨Åed under the assumption
W ‚â•0.
(5.244)
For the separated boundary conditions in the block diagonal form
R1(Œª) = diag{R‚àó
0(Œª), R‚àó
N+1(Œª)},
R2 = diag{‚àíR0, RN+1},
W = diag{W‚àí1, WN+1}
we have from (5.242) the conditions
R‚àó
0(Œª) x0(Œª) + R0u0(Œª) = 0,
R‚àó
N+1(Œª) xN+1(Œª) + RN+1uN+1(Œª) = 0,
R‚àó
0(Œª) = R‚àó
0 + ŒªR0W‚àí1,
R‚àó
N+1(Œª) = R‚àó
N+1 ‚àíŒªRN+1WN+1,
‚é´
‚é™‚é¨
‚é™‚é≠
(5.245)
while conditions (5.243) translate as
R‚àó
0RT
0 = R0(R‚àó
0)T ,
rank(R‚àó
0, R0) = n,
R‚àó
N+1RT
N+1 = RN+1(R‚àó
N+1)T ,
rank (R‚àó
N+1, RN+1) = n,
W‚àí1 = WT
‚àí1,
WN+1 = WT
N+1.
‚é´
‚é™‚é¨
‚é™‚é≠
(5.246)
The monotonicity conditions (5.157), (5.158) are rewritten in the form
ÀôR‚àó
0(Œª) RT
0 = R0W0RT
0 ‚â•0,
ÀôR‚àó
N+1(Œª) RT
N+1 = ‚àíRN+1WN+1RT
N+1 ‚â§0.
Therefore, according to (5.244), it is sufÔ¨Åcient to require that
W‚àí1 ‚â•0,
(5.247)
WN+1 ‚â•0.
(5.248)
In particular, if R1(Œª) is independent on Œª, then monotonicity conditions (5.244),
(5.247), (5.248) are automatically satisÔ¨Åed. Moreover, for the choice of R‚àó
0 = I,
R0 = 0, R‚àó
N+1 = I, and RN+1 = 0, we obtain the Dirichlet boundary conditions
in (E).
The main purpose of this subsection is to transform the mentioned above bound-
ary conditions in such a way that new extended boundary value problem (5.162)
preserves the special linear dependence on Œª given by (5.238).

5.3
Linear Dependence on Spectral Parameter
325
Now we prove the following results for the case of the separated boundary
conditions (5.242).
Lemma 5.59 Consider the low block triangular transformation Àúyk = Lk(Œª) yk
with the matrices
Lk(Œª) := I,
k ‚àà[0, N]Z,
LN+1(Œª) :=

I
0
‚àíŒªWN+1 I

.
(5.249)
Then the eigenvalue problem for system (5.238) with separated boundary condi-
tions (5.245) on [0, N + 1]Z takes the form
Àúyk+1(Œª) =

I
0
‚àíŒª ÀúWk I

Sk Àúyk(Œª),
k ‚àà[0, N]Z,
ÀúWk = Wk,
k ‚àà[0, N ‚àí1]Z,
ÀúWN = WN + WN+1 ‚â•0,
‚é´
‚é¨
‚é≠
(5.250)
with the boundary conditions
R‚àó
0(Œª) Àúx0(Œª) + R0 Àúu0(Œª) = 0,
R‚àó
0(Œª) = R‚àó
0 + ŒªR0W‚àí1
R‚àó
N+1 ÀúxN+1(Œª) + RN+1 ÀúuN+1(Œª) = 0.

(5.251)
That is, for the transformed problem (5.250) with (5.251), the boundary conditions
for k = N + 1 are independent on Œª.
Proof The proof follows from the representation of the boundary conditions in the
right point k = N + 1 as

R‚àó
N+1 ‚àíŒªRN+1WN+1 RN+1

=

R‚àó
N+1 RN+1

LN+1(Œª),
where the matrix LN+1(Œª) is deÔ¨Åned in (5.249).
‚äì‚äî
Remark 5.60 We note that the symplectic transformation with matrix (5.249)
preserves the multiplicities of focal points of any conjoined basis of (SDSŒª)
according to Corollary 4.67.
In the next lemma, we consider the situation when the (separated) boundary
conditions (5.245) are independent on Œª for k = N + 1.
Lemma 5.61 Under the additional assumption
WN+1 = 0,
(5.252)
the eigenvalue problem for system (5.238) with separated boundary condi-
tions (5.245) on [0, N + 1]Z can be extended to an eigenvalue problem of the
special linear form (5.239) on the interval [‚àí1, N +2]Z with the Dirichlet boundary
conditions (5.160).

326
5
Discrete Symplectic Eigenvalue Problems
Proof In Lemma 5.40 for the nonlinear case, we preserve the construction for SN+1,
because under assumption (5.252) the matrix SN+1 is independent on Œª (see the
proof of Lemma 5.40). For the left point k = 0, we introduce the notation
ÀúR :=

R‚àó
0
R0

and construct the constant matrix S‚àí1 such that
S‚àí1 =
 ÀúRT K J T ÀúRT 
,
K := ( ÀúR ÀúRT )‚àí1.
Then we complete the construction of the matrix S‚àí1(Œª) by
S‚àí1(Œª) =

I
0
‚àíŒªW‚àí1 I
  ÀúRT K J T ÀúRT  .
(5.253)
The result then follows from Lemma 5.40.
‚äì‚äî
Based on the results of Lemmas 5.59 and 5.61, one can reformulate Theorem 5.41
for the case of the special linear dependence on Œª.
Theorem 5.62 Under assumptions (5.240), (5.246), (5.247), and (5.248), the
eigenvalue problem for system (5.238) with separated boundary conditions (5.245)
on [0, N + 1]Z is equivalent to the extended problem
Àúyk+1(Œª) =

I
0
‚àíŒª ÀúWk I

Sk Àúyk(Œª), k ‚àà[‚àí1, N + 1]Z,
Àúx‚àí1(Œª) = 0 = ÀúxN+2(Œª),
where the symmetric matrix
ÀúWk :=
‚éß
‚é™‚é®
‚é™‚é©
Wk,
k ‚àà[‚àí1, N ‚àí1]Z,
WN + WN+1,
k = N,
0,
k = N + 1.
(5.254)
is nonnegative deÔ¨Ånite for all k ‚àà[‚àí1, N + 1]Z,
S‚àí1 =
A‚àí1 B‚àí1
C‚àí1 D‚àí1

:=
R‚àó
0
T K0 ‚àíRT
0
RT
0 K0 R‚àó
0
T

,
K0 := (R‚àó
0R‚àó
0
T + R0RT
0 )‚àí1
‚é´
‚é™‚é¨
‚é™‚é≠
(5.255)
and
SN+1 =
AN+1 BN+1
CN+1 DN+1

:=

R‚àó
N+1
RN+1
‚àíKN+1RN+1 KN+1R‚àó
N+1

,
KN+1 := (R‚àó
N+1R‚àóT
N+1 + RN+1RT
N+1)‚àí1.
‚é´
‚é™‚é¨
‚é™‚é≠
(5.256)

5.3
Linear Dependence on Spectral Parameter
327
Proof The proof is based on the subsequent application of Lemmas 5.59 and 5.61.
At the Ô¨Årst step, applying Lemma 5.59, we derive the new boundary problem
with the additional assumption (5.252). Applying Lemma 5.61 to this problem and
incorporating (5.250), we complete the proof of Theorem 5.62.
‚äì‚äî
Next we apply Theorem 5.45 for the nonlinear case to the linear problem (5.238)
with (5.242).
Theorem 5.63 Under
assumptions
(5.243)
and
(5.244),
problem
(5.238)
with (5.242) is equivalent to the linear eigenvalue problem with the separated
boundary conditions
Àúyk+1(Œª) =

I
0
‚àíŒªWk I
 
{Sk} Àúyk(Œª),
k ‚àà[0, N]Z,
ÀúR1(Œª) Àúx0(Œª) + ÀúR2(Œª) Àúu0(Œª) = 0,
ÀúR1(Œª) := ÀúR1 + Œª ÀúR2 ÀúW, ÀúR2(Œª) := ÀúR2
 0 0
‚àíI I

ÀúxN+1(Œª) +
‚àíI ‚àíI
0
0

ÀúuN+1(Œª) = 0,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(5.257)
where
ÀúR1 = R1 P1,
ÀúR2 = ‚àíR2 P1,
ÀúW = P1WP1,
P1 =
0 I
I 0

,
(5.258)
and
ÀôÀúR1(Œª) ÀúRT
2 = ÀúR2 ÀúW ÀúRT
2 ‚â•0.
(5.259)
Proof According to Theorem 5.45, the coefÔ¨Åcients in (5.242) are transformed as
ÀúR(Œª) =
 ÀúR1(Œª) ÀúR2

=

R1 R2
 
I
0
‚àíŒªW I

diag{P1, ‚àíP1}
=

R1 R2

diag{P1, ‚àíP1} diag{P1, ‚àíP1}

I
0
‚àíŒªW I

diag{P1, ‚àíP1}
=
 ÀúR1 ÀúR2
 
I
0
ŒªP1WP1 I

=
 ÀúR1 ÀúR2
  I
0
Œª ÀúW I

=  ÀúR1 + Œª ÀúR2 ÀúW ÀúR2
 ,
where the matrices above are deÔ¨Åned by (5.257) and (5.258). Applying Theo-
rem 5.45 to the case under the consideration, we complete the proof.
‚äì‚äî

328
5
Discrete Symplectic Eigenvalue Problems
Remark 5.64
(i) Observe that according to our construction, the matrix of the symplectic system
in (5.257) is of the same form as the matrix of system (5.239); since by
deÔ¨Ånition (3.101), we have

I
0
‚àíŒªW I
 
=
‚éõ
‚éú‚éú‚éù
I
0
0 0
0
I
0 0
0
0
I 0
0 ‚àíŒªW 0 I
‚éû
‚éü‚éü‚é†.
Consequently, the weight matrix by ‚àíŒª is equal to diag{0, W} ‚â•0.
(ii) Note that in problem (5.257) the boundary condition for k = N + 1 is
independent on Œª. Applying Lemma 5.61, one can extend (5.257) to the
problem with the Dirichlet boundary conditions preserving the special linear
dependence on Œª. By a similar way, one can modify Theorem 5.44 for the
nonlinear case to derive a problem with the separated boundary conditions,
which are independent on Œª for k = 0, and then apply Theorem 5.62 for the
construction of the extended problem with the Dirichlet boundary conditions,
again with the preservation of the special linear dependence on Œª.
5.3.2
Quadratic Functionals
In this subsection we analyze the quadratic functional G(y, Œª) deÔ¨Åned in (5.186)
over the joint endpoints (5.187), respectively, the quadratic functional G(y, Œª)
deÔ¨Åned in (5.188) over the separated endpoints (5.190), when the boundary
conditions depend linearly on Œª as in Sect. 5.3.1.
Given system (SDSŒª) and the 2n √ó 2n matrices R1, R2, W satisfying (5.243)
and (5.244), the functional G(y, Œª) in (5.186) takes the form
G(y, Œª) = F0(y)+
 x0
xN+1
T
‚àíŒª W
  x0
xN+1

‚àíŒª
N

k=0
xT
k+1Wkxk+1,
(5.260)
where F0(y) is the basic functional deÔ¨Åned in (2.56) and  := R‚Ä†
2R1R‚Ä†
2R2 as
in (5.185). (Note that in Sect. 2.3 the functional F0(y) is denoted by F(y).) The
functional G(y, Œª) in (5.260) acts on admissible functions y = (x, u) satisfying the
boundary conditions
 x0
xN+1

‚ààIm RT
2 .
(5.261)

5.3
Linear Dependence on Spectral Parameter
329
Observe that the admissibility condition, i.e., the Ô¨Årst equation of system (5.238),
and the boundary conditions (5.261) do not depend on Œª. The form of the functional
G(y, Œª) in (5.260) yields the following simple comparison result.
Proposition 5.65 Assume that (5.240) and (5.244) hold and consider the functional
G(y, Œª) in (5.260). Then for every Œª, Œª0 ‚ààR, Œª < Œª0, we have the inequality
G(y, Œª) ‚â•G(y, Œª0) for every admissible y satisfying (5.261). Consequently, if
G(¬∑, Œª0) > 0 for some Œª0 ‚ààR, then G(y, Œª) > 0 for all Œª < Œª0 as well.
Similarly, given n √ó n matrices R‚àó
0, R0, R‚àó
N+1, RN+1, and W‚àí1, WN+1
satisfying (5.246), (5.247), and (5.248), the functional G(y, Œª) in (5.188) takes the
form
G(y, Œª) = F0(y) + xT
0 (0 ‚àíŒªW‚àí1) x0
+xT
N+1(N+1 ‚àíŒªWN+1) xN+1 ‚àíŒª
N

k=0
xT
k+1Wkxk+1,
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(5.262)
where 0 := ‚àíR‚Ä†
0R‚àó
0R‚Ä†
0R0 and N+1 := R‚Ä†
N+1R‚àó
N+1R‚Ä†
N+1RN+1 as in (5.189). The
functional G(y, Œª) in (5.262) acts on admissible functions y = (x, u) satisfying the
separated boundary conditions
x0 ‚ààIm RT
0 ,
xN+1 ‚ààIm RT
N+1.
(5.263)
Observe that the boundary conditions (5.263) do not depend on Œª. Motivated by the
statements of the global oscillation theorems (Theorems 5.31, 5.53, and 5.57), our
aim is to Ô¨Ånd conditions, which will guarantee the existence of Œª0 < 0 such that
the functional G(¬∑, Œª0) is positive deÔ¨Ånite. The statement in Proposition 5.65 then
holds for the functional G(y, Œª) in (5.262) under the assumptions (5.240), (5.247),
and (5.248).
For the next results, we recall the deÔ¨Ånition in (2.64) of the symmetric n √ó n
matrix Ek = BkB‚Ä†
kDkB‚Ä†
k, which satisÔ¨Åes BT
k EkBk = BT
k Dk for k ‚àà[0, N]Z.
Proposition 5.66 Assume
W‚àí1 ‚â•0,
Wk > 0,
k ‚àà[0, N ‚àí1]Z,
WN ‚â•0,
WN+1 ‚â•0,
(5.264)
and for some Œª < 0, we have
0 ‚àíCT
0A0 + AT
0 E0A0 ‚àíŒªW‚àí1 > 0
on Im RT
0
(5.265)
N+1 + EN ‚àíŒª(WN + WN+1) > 0
on Im RT
N+1.
(5.266)
Then there exists Œª0 < 0 such that G(¬∑, Œª0) > 0 over (5.263).

330
5
Discrete Symplectic Eigenvalue Problems
Proof For an admissible y, we rewrite G(y, Œª) by using the matrix Ek as
G(y, Œª) = xT
0 (0 ‚àíCT
0A0 + AT
0 E0A0 ‚àíŒªW‚àí1) x0
+
N‚àí1

k=0
!2xT
k (CT
k ‚àíAT
k Ek) xk+1 + xT
k+1(Ek ‚àíCT
k+1Ak+1 ‚àíŒªWk) xk+1
"
+ 2xT
N(CT
N ‚àíAT
NEN) xN+1 + xT
N+1[ N+1 + EN ‚àíŒª(WN + WN+1)] xN+1.
Therefore, the positivity assumption on Wk for k ‚àà[0, N ‚àí1]Z in (5.264) and the
positivity assumptions (5.265) and (5.266) imply that for some Œª0 < 0 the functional
G(y, Œª0) > 0 for all admissible y with (5.263) and x = {xk}N+1
k=0 Ã∏‚â°0.
‚äì‚äî
Consider now a special case of the functional G(y, Œª) in (5.262) in which the
matrices W‚àí1 = 0 = WN+1, i.e.,
G(y, Œª) = F0(y) + xT
0 0x0 + xT
N+1N+1xN+1 ‚àíŒª
N

k=0
xT
k+1Wkxk+1.
(5.267)
Proposition 5.67 Suppose that
Wk > 0,
k ‚àà[0, N]Z,
(5.268)
0 ‚àíAT
0 C0 + AT
0 E0A0 > 0
on Im RT
0 .
(5.269)
Then there exists Œª0 < 0 such that the functional G(y, Œª0) in (5.267) is positive
deÔ¨Ånite over (5.263).
Proof The result follows from Proposition 5.66, since assumptions (5.268)
and (5.269) imply the validity of (5.264)‚Äì(5.266) with W‚àí1 := 0 and WN+1 := 0.
‚äì‚äî
Remark 5.68 One may certainly formulate numerous other sufÔ¨Åcient conditions
for (5.264)‚Äì(5.266) to be satisÔ¨Åed involving nonzero weight matrices W‚àí1 and/or
WN+1. For example, one such condition could be
Wk > 0,
k ‚àà[‚àí1, N ‚àí1]Z,
WN + WN+1 > 0,
WN ‚â•0,
WN+1 ‚â•0,
(5.270)
or the following ones, implying (5.270),
Wk > 0,
k ‚àà[‚àí1, N]Z,
WN+1 ‚â•0,
(5.271)
Wk > 0,
k ‚àà[‚àí1, N + 1]Z.
(5.272)
Condition (5.269) is trivially satisÔ¨Åed for the Dirichlet boundary conditions x0 =
0 = xN+1, i.e., for R0 = 0 = RN+1. In this case, in agreement with the notation

5.3
Linear Dependence on Spectral Parameter
331
in (5.138), the functional G(y, Œª) in (5.267) has the form
F(y, Œª) = F0(y) ‚àíŒª
N

k=0
xT
k+1Wk xk+1.
(5.273)
Thus, we obtain from Proposition 5.67 the following.
Corollary 5.69 Suppose that (5.268) holds. Then there exists Œª0 < 0 such that the
functional F(y, Œª) in (5.273) is positive deÔ¨Ånite over x0 = 0 = xN+1.
Remark 5.70 The question of Ô¨Ånding some simple and easy to verify sufÔ¨Åcient con-
ditions for the positivity of the functional G(¬∑, Œª0) for some Œª0 < 0 in (5.260) over
joint endpoints (5.261) in terms of the coefÔ¨Åcients of system (5.1), e.g., a ‚Äúpositivity
condition‚Äù on the weight matrices Wk and W in the spirit of Proposition 5.67 and
Corollary 5.69, remains an open problem.
5.3.3
Finite Eigenvalues and Finite Eigenfunctions
In this subsection we analyze special properties of the Ô¨Ånite eigenvalues of
problem (SDSŒª) with (5.239) and with the boundary conditions depending linearly
on Œª as in Sect. 5.3.1. In particular, we will discuss the results of the corresponding
global oscillation theorems, including special properties of Ô¨Ånite eigenvalues and
Ô¨Ånite eigenfunctions, which can be derived for this case.
First we consider the general boundary conditions (5.242) determined by the
2n √ó 2n matrices R1, R2, and W satisfying (5.243) and (5.244). According to
DeÔ¨Ånition 5.54, the Ô¨Ånite eigenvalues are determined by the behavior of the function
L(Œª) in (5.221) deÔ¨Åned through the matrices Xk(Œª) and Uk(Œª) in (5.220) and
through the conjoined bases Y [0](Œª) and ÀúY(Œª) of (5.238) such that ÀúY0(Œª) = (I 0)T
and Y [0](Œª) is the principal solution at k = 0. Since the dependence on Œª in
system (SDSŒª) and in the boundary conditions (5.242) is now linear, and since the
initial conditions of X(Œª) and U(Œª) at k = 0 do not depend on Œª, it follows that
L(Œª) is a matrix polynomial. This means that for each Œª0 ‚ààR, the one-sided limits
of the rank of L(Œª) satisfy
rank L(Œª+
0 ) = r = rank L(Œª‚àí
0 ),
r := max
Œª‚ààR rank L(Œª).
(5.274)
This means that the algebraic multiplicity Œ∂(Œª0) in (5.222) is equal to
Œ∂(Œª0) = r ‚àírank L(Œª0)
(5.275)
with r given in (5.274). In order to understand the deÔ¨Ånition of a Ô¨Ånite eigenfunction
for the problem (SDSŒª) with (5.242), we combine the results in Sects. 5.1.2
and 5.3.1.

332
5
Discrete Symplectic Eigenvalue Problems
DeÔ¨Ånition 5.71 Assume (5.239), (5.240), (5.243), and (5.244). A solution y =
(x, u) of (SDSŒª) and (5.242) with Œª
=
Œª0 is called a Ô¨Ånite eigenfunction
corresponding to a Ô¨Ånite eigenvalue Œª0 if it satisÔ¨Åes the nondegeneracy condition
{Wk xk+1}N
k=0 Ã∏‚â°0
or
W
 x0
xN+1

Ã∏= 0.
(5.276)
The dimension œâ(Œª0) of the space of all Ô¨Ånite eigenfunctions y corresponding to
the Ô¨Ånite eigenvalue Œª0 is called a geometric multiplicity of Œª0.
In the following result, we provide a geometric characterization of the Ô¨Ånite
eigenvalues of (SDSŒª) with (5.239). We thus extend Theorem 5.11 to general jointly
varying endpoints.
Theorem 5.72 Let assumptions (5.239), (5.240), (5.243), and (5.244) be satisÔ¨Åed.
A number Œª0 is a Ô¨Ånite eigenvalue of (SDSŒª) with (5.239) with algebraic multiplicity
Œ∂(Œª0) ‚â•1 in (5.275) if and only if there exists a corresponding Ô¨Ånite eigenfunction
y for Œª0. In this case, the geometric multiplicity of Œª0 is equal to its algebraic
multiplicity, i.e., œâ(Œª0) = Œ∂(Œª0).
Proof We proceed by adopting the transformations to the augmented eigenvalue
problem in Theorem 5.44 and then to the extended eigenvalue problem in The-
orem 5.62 (see Remark 5.64(ii)). In this way we obtain an extended augmented
problem over the interval [‚àí1, N + 2]Z with the augmented functions Àúxk =
 x0
xk

and Àúuk =
 ‚àíu0
uk

and the augmented matrices ÀúWk, which have according to (5.254)
the form
ÀúW‚àí1 = 0,
ÀúWk = diag{0, Wk},
k ‚àà[0, N ‚àí1]Z,
ÀúWN = diag{0, WN} + W,
ÀúWN+1 = 0.

(5.277)
The weight matrix Àúk(Œª) ‚â°Àúk ‚â•0 on [‚àí1, N + 1]Z corresponding to (5.241) then
has the form Àúk = diag{ ÀúWk, 0} for k ‚àà[‚àí1, N + 1]Z. The degeneracy condition
in DeÔ¨Ånition 5.8 for this extended augmented problem reads as
ÀúWk Àúxk+1 ‚â°0 on
[‚àí1, N + 1]Z, i.e.,
Wk xk+1 ‚â°0
on [0, N ‚àí1]Z,
WNxN+1 + W
 x0
xN+1

= 0.
(5.278)
Since WN ‚â•0 and W ‚â•0 is assumed, condition (5.278) and hence the degeneracy
condition is equivalent to Wkxk+1 ‚â°0 on [0, N]Z and W

x0
xN+1

= 0. Therefore,
our nondegeneracycondition in (5.276) means that the corresponding solution of the
extended augmented problem is also nondegenerate on [‚àí1, N +2]Z. The statement
in the theorem then follows from the application of Theorem 5.11 to the extended
augmented problem.
‚äì‚äî

5.3
Linear Dependence on Spectral Parameter
333
In the last part of this subsection, we will discuss the properties of the Ô¨Ånite
eigenvalues of (SDSŒª) with (5.242) from the point of view of self-adjoint boundary
value problems. Based on Theorem 5.72, we may deÔ¨Åne a Ô¨Ånite eigenvalue
of (SDSŒª) with (5.239) in the context of the linear dependence on the spectral
parameter in the symplectic system and in the boundary conditions as a number Œª0 ‚àà
C, for which there exists corresponding a solution y = (x, u) of (SDSŒª) with (5.242)
satisfying (5.276). This means, that we now allow complex Ô¨Ånite eigenvalues. Then
we can actually prove that these Ô¨Ånite eigenvalues are real (Proposition 5.74) and
the Ô¨Ånite eigenfunctions corresponding to different Ô¨Ånite eigenvalues are orthogonal
(Proposition 5.73). Here we consider the semi-inner product
‚ü®y, Àúy‚ü©:=
N

k=0
xT
k+1Wk Àúxk+1 +
 x0
xN+1
T
W
 Àúx0
ÀúxN+1

.
(5.279)
Proposition 5.73 Assume (5.239), (5.240), (5.243), and (5.244). Let y and Àúy be
Ô¨Ånite eigenfunctions corresponding to the Ô¨Ånite eigenvalues Œª and ÀúŒª of (SDSŒª)
with (5.242), and let Œª Ã∏= ÀúŒª. Then ‚ü®y, Àúy‚ü©= 0, i.e., the Ô¨Ånite eigenfunctions y and Àúy
are orthogonal with respect to the inner product (5.279).
Proof Let y satisfy (SDSŒª) with (5.239), and let Àúy satisfy (SDSŒª) with (5.239) for
the spectral parameter ÀúŒª. Then
(Œª ‚àíÀúŒª) ‚ü®y, Àúy‚ü©= (Œª ‚àíÀúŒª)
N

k=0
xT
k+1Wk Àúxk+1 + (Œª ‚àíÀúŒª)

x0
xN+1
T
W

Àúx0
ÀúxN+1

=
N

k=0
!
(uT
k+1 ‚àíxT
k CT
k ‚àíuT
k DT
k ) Àúxk+1 ‚àíxT
k+1(Àúuk+1 ‚àíCk Àúxk ‚àíDk Àúuk)
"
+ (Œª ‚àíÀúŒª)

x0
xN+1
T
W

Àúx0
ÀúxN+1

=
N

k=0
!
xT
k (AT
k Dk ‚àíCT
k Bk ‚àíI) Àúuk ‚àíuT
k (BT
k Ck ‚àíDT
kAk + I) Àúxk
"
+ (uT
k Àúxk ‚àíxT
k Àúuk)
		N+1
0
+ (Œª ‚àíÀúŒª)

x0
xN+1
T
W

Àúx0
ÀúxN+1

=

‚àíu0
uN+1
T 
Àúx0
ÀúxN+1

‚àí

x0
xN+1
T 
‚àíÀúu0
ÀúuN+1

+ (Œª ‚àíÀúŒª)

x0
xN+1
T
W

Àúx0
ÀúxN+1

.
(5.280)

334
5
Discrete Symplectic Eigenvalue Problems
The assumptions on R1, R2, W in (5.243) and (5.244) imply that
Ker 
R1 ‚àíŒªR2W, R2
 = Im

‚àíRT
2
(R1 ‚àíŒªR2W)T

(5.281)
and similarly for ÀúŒª. Therefore, since y satisÔ¨Åes the boundary conditions (5.239) and
Àúy satisÔ¨Åes (5.239) with Œª := ÀúŒª, it follows that there exist d, Àúd ‚ààR2n such that
 x0
xN+1

= ‚àíRT
2 d,
 ‚àíu0
uN+1

= (R1 ‚àíŒªR2W)T d,
 Àúx0
ÀúxN+1

= ‚àíRT
2 Àúd,
 ‚àíÀúu0
ÀúuN+1

= (R1 ‚àíÀúŒªR2W)T Àúd.
Substituting this into (5.280), we obtain
(Œª ‚àíÀúŒª) ‚ü®y, Àúy‚ü©= ‚àídT (R1 ‚àíŒªR2W) RT
2 Àúd + dT R2(R1 ‚àíÀúŒªR2W)T Àúd
+ (Œª ‚àíÀúŒª) dT R2WRT
2 Àúd = 0.
And since Œª Ã∏= ÀúŒª, it follows that ‚ü®y, Àúy‚ü©= 0, i.e., the Ô¨Ånite eigenfunctions y and Àúy
are orthogonal with respect to (5.279).
‚äì‚äî
Proposition 5.74 Assume (5.239), (5.240), (5.243), and (5.244). Then the Ô¨Ånite
eigenvalues of (SDSŒª) with (5.242) are real and bounded from below and from
above. Moreover, the total number of Ô¨Ånite eigenvalues of (SDSŒª) with (5.242) can
be estimated by
N‚àí1

k=0
rankWk + rank

diag{0, WN} + W

‚â§(N + 2) n.
(5.282)
Proof Since the coefÔ¨Åcients of system (SDSŒª) and the boundary conditions (5.242)
are real, then with Œª being its Ô¨Ånite eigenvalue with the Ô¨Ånite eigenfunction y, the
complex conjugate number ¬ØŒª is also a Ô¨Ånite eigenvalue with the Ô¨Ånite eigenfunction
¬Øy. In this case ‚ü®¬Øy, ¬Øy‚ü©= ‚ü®y, y‚ü©= ‚ü®y, y‚ü©> 0, by (5.276). Moreover, by Lemma 2.61
applied to system (SDSŒª) and the functional G(y, Œª), we have
G(y, Œª) =
 ‚àíu0
uN+1
T  x0
xN+1

+
 x0
xN+1
T
(  ‚àíŒªW)
 x0
xN+1

= 0,
where we used (5.281) and the fact that y satisÔ¨Åes the boundary conditions (5.242).
Similarly, G( ¬Øy, ¬ØŒª) = 0. Denote F(y) := G(y, 0) and F( ¬Øy) := G( ¬Øy, 0). It follows
that F(y) = F(y) = F( ¬Øy), and thus by (5.260), we obtain
Œª = F(y)
‚ü®y, y‚ü©= F( ¬Øy)
‚ü®¬Øy, ¬Øy‚ü©= ¬ØŒª.

5.3
Linear Dependence on Spectral Parameter
335
This shows that Œª ‚ààR. The boundedness from below of the Ô¨Ånite eigenvalues
follows from Remark 5.56. The estimate in (5.282) follows from the estimate for
the sum N
k=0 rank Àú
Wk, where Àú
Wk are given by (5.277).
‚äì‚äî
Remark 5.75 For the Dirichlet boundary conditions
x0(Œª) = 0 = xN+1(Œª),
(5.283)
i.e., for R1 = I and R2 =  = W = 0, the Ô¨Ånite eigenvalues of (SDSŒª) with (5.283)
are determined by the condition
Œ∏(Œª0) = r ‚àírankX[0]
N+1(Œª0),
1 ‚â§Œ∏(Œª0) ‚â§n,
(5.284)
where according to (5.284), the value r is given by
r = max
Œª‚ààR rankX[0]
N+1(Œª) = rankX[0]
N+1(Œª+
0 ) = rank X[0]
N+1(Œª‚àí
0 )
(5.285)
and the function X[0]
N+1(Œª) comes from the principal solution Y [0](Œª) of (SDSŒª)
at k = 0. In this case X[0]
N+1(Œª) is a matrix polynomial. The nondegeneracy
condition (5.276) for y being a Ô¨Ånite eigenfunction has the form
{Wkxk+1}N‚àí1
k=0 Ã∏‚â°0.
(5.286)
By Propositions 5.73 and 5.74, the Ô¨Ånite eigenvalues of (SDSŒª) with (5.283) are
real, and the Ô¨Ånite eigenfunctions corresponding to different Ô¨Ånite eigenvalues are
orthogonal with respect to the inner product
‚ü®y, Àúy‚ü©=
N‚àí1

k=0
xT
k+1Wk Àúxk+1.
(5.287)
The Ô¨Ånite eigenvalues are bounded from below, by Corollary 5.18. Finally,
by (5.286) the total number of Ô¨Ånite eigenvalues of (SDSŒª) with (5.283) can be
estimated by
N‚àí1

k=0
rankWk ‚â§nN.
(5.288)
Remark 5.76 For the separated boundary conditions (5.245), i.e., when the matrices
R1 = diag{R‚àó
0, R‚àó
N+1} and R2 = diag{‚àíR0, RN+1}, as well as  = diag{0, N+1}
and W = diag{W‚àí1, WN+1}, are block diagonal, the Ô¨Ånite eigenvalues of (SDSŒª)
with (5.245) are determined by the condition; see (5.206),
Œ∏(Œª0) = r ‚àírank (Œª0),
1 ‚â§Œ∏(Œª0) ‚â§n,
(5.289)

336
5
Discrete Symplectic Eigenvalue Problems
where the value r is given by
r = max
Œª‚ààR rank(Œª) = rank (Œª+
0 ) = rank (Œª‚àí
0 ).
(5.290)
The function (Œª) is deÔ¨Åned in (5.205) and comes from the natural conjoined basis
¬ØY(Œª) of (SDSŒª) at k = 0. In this case (Œª) is again a matrix polynomial. The
nondegeneracy condition (5.276) for y being a Ô¨Ånite eigenfunction is
{Wkxk+1}N‚àí1
k=‚àí1 Ã∏‚â°0
or
(WN + WN+1) xN+1 Ã∏= 0.
(5.291)
The Ô¨Ånite eigenvalues of (SDSŒª) with (5.245) are real, and the Ô¨Ånite eigenfunctions
corresponding to different Ô¨Ånite eigenvalues are orthogonal with respect to the inner
product
‚ü®y, Àúy‚ü©=
N‚àí1

k=‚àí1
xT
k+1Wk Àúxk+1 + xT
N+1(WN + WN+1) xN+1.
(5.292)
By Remark 5.51, the Ô¨Ånite eigenvalues of (SDSŒª) with (5.245) are bounded from
below. By (5.291), the total number of Ô¨Ånite eigenvalues of (SDSŒª) with (5.245) can
be estimated by
N‚àí1

k=‚àí1
rank Wk + rank (WN + WN+1) ‚â§(N + 2) n.
(5.293)
Example 5.77 The following example shows that the conclusions in Remark 5.75
do not hold in general without the assumption Wk ‚â•0. Put N = 3,
Ak = diag{1, 0}, Bk = diag{0, 1}, Ck = diag{0, ‚àí1}, Dk = diag{1, 0}
for k ‚àà[0, 3]Z, and
W0 = diag{0, 1},
W1 = 0,
W2 = diag{0, ‚àí1}.
Then the system is symplectic, W0 ‚â•0, W1 ‚â•0, but W2 Ã∏‚â•0. The calculation of
the principal solution Y [0](Œª) by the difference system yields that
X[0]
0 (Œª) = 02,
X[0]
1 (Œª) = diag{0, 1},
X[0]
2 (Œª) = diag{0, Œª},
X[0]
3 (Œª) = diag{0, ‚àí1},
X[0]
4 (Œª) = X[0]
N+1(Œª) ‚â°02.
Hence rN+1 = 0, so that there are no Ô¨Ånite eigenvalues by (5.284) in Remark 5.75.
But every Œª possesses a Ô¨Ånite eigenfunction, namely, the function y = {yk}4
k=0 with
yk = Y [0]
k (Œª)
0
1

, so that x0(Œª) =
0
0

, x1(Œª) =
0
1

, x2(Œª) =
 0
‚àíŒª

, and x4(Œª) =
0
0

.

5.3
Linear Dependence on Spectral Parameter
337
5.3.4
Global Oscillation Theorem
In this subsection we present the global oscillation theorem for problem (5.238)
with (5.283) and comment on its special features resulting from the linear depen-
dence on Œª. The statement of this special global oscillation theorem will be of
particular interest in several applications later in this section as well as in Sect. 5.5.
First we recall the notation (5.49) for n1(Œª) and the notation (5.50) for n2(Œª),
being the number of focal points of Y [0](Œª) in (1, N + 1] and the number of Ô¨Ånite
eigenvalues of (5.238) with (5.283) in (‚àí‚àû, Œª], respectively.
Theorem 5.78 (Global Oscillation Theorem for Linear Dependence on Œª)
Consider system (5.238), i.e., system (5.1) with (5.239) and with Dirichlet boundary
conditions (5.283). Suppose that (5.240) holds, i.e., Wk ‚â•0 for all k ‚àà[0, N]Z.
Then we have for all Œª ‚ààR
n1(Œª+) = n1(Œª) ‚â§L,
(5.294)
n2(Œª+) = n2(Œª) < ‚àû,
(5.295)
n2(Œª+) ‚àín2(Œª‚àí) = n1(Œª+) ‚àín1(Œª‚àí) ‚â•0,
(5.296)
and there exists m ‚àà[0, L]Z, where L := N
k=1 rank Bk ‚â§Nn, such that
n1(Œª) = n2(Œª) + m
for all Œª ‚ààR.
(5.297)
Moreover, for a suitable Œª0 < 0, we have
n2(Œª) ‚â°0
and
n1(Œª) ‚â°m
for all Œª ‚â§Œª0.
(5.298)
Proof The statement follows directly from Theorem 5.17. Here we realize that
assumption (5.38) is automatically satisÔ¨Åed for system (5.238), since the coefÔ¨Åcient
matrix Bk(Œª) ‚â°Bk does not depend on Œª. Also, in view of Proposition 4.4, the
number n1(Œª) is in this case bounded from above by the number L deÔ¨Åned in the
theorem.
‚äì‚äî
When the weight matrices Wk are positive deÔ¨Ånite, we obtain the following more
speciÔ¨Åc oscillation theorem.
Corollary 5.79 (Global Oscillation Theorem for Linear Dependence on Œª)
Consider system (5.238), i.e., system (5.1) with (5.239), with Dirichlet boundary
conditions (5.283). Suppose that (5.268) holds, i.e., Wk > 0 for all k ‚àà[0, N]Z.
Then we have
n1(Œª) = n2(Œª)
for all Œª ‚ààR,
(5.299)
and for a suitable Œª0 < 0, we have n1(Œª) = n2(Œª) ‚â°0 for all Œª ‚â§Œª0.

338
5
Discrete Symplectic Eigenvalue Problems
Proof By Corollary 5.69 we know that the positivity assumption (5.268) implies
the existence of Œª0 < 0 such that the functional F0(y) ‚àíŒª ‚ü®y, y‚ü©W > 0 for all
admissible y = (x, u) with (5.283) x Ã∏‚â°0. This means by Theorem 5.31 that the
equality in (5.299) holds (i.e., the number m = 0 in Theorem 5.78).
‚äì‚äî
We make the following remarks about the above oscillation theorems for linear
dependence on Œª.
Remark 5.80
(i) The second equality in (5.298) measures the ‚Äúindex‚Äù of the quadratic functional
F0(y, Œª) := F0(y) ‚àíŒª ‚ü®y, y‚ü©W. More precisely, the number m = 0 in
Theorem 5.78 if and only if F0(¬∑, Œª) > 0 for Œª < Œª1, where Œª1 is the smallest
Ô¨Ånite eigenvalue of (5.238) with (5.283), compared with Theorem 5.31.
Moreover, in general by the methods of Sect. 5.4, we have that for Œª < Œª1
m = dim{x = {xk}N+1
k=0 , y = (x, u) is admissible such that F0(y; Œª) ‚â§0}.
(ii) The eigenvalue problem (5.238) with (5.283) is self-adjoint in the following
sense. All Ô¨Ånite eigenvalues are real, and the Ô¨Ånite eigenfunctions correspond-
ing to different Ô¨Ånite eigenvalues are orthogonal, as we discuss in Remark 5.75.
(iii) The eigenvalue problem (5.238) with (5.283) is equivalent with the correspond-
ing eigenvalue problem for a 2n(N +1)√ó2n(N +1) matrix pencil A+ŒªB with
the eigenvectors (u0, x1, u1, . . . , xN, uN, uN+1) and with the block diagonal
matrix
B = diag{0, W0, 0, W1, . . . , 0, WN‚àí1, 0, 0}.
We omit here to write down A explicitly, because it is not used here. Then
it follows quite easily from the difference system and the deÔ¨Ånition of the
principal solution Y [0](Œª) of (5.238) that
det (A + ŒªB) = det X[0]
N+1(Œª).
The property in (5.284) and the references on matrix pencils (cf. [148, Ch. XII]
or [61, 318, 319]) imply that rN+1 is the normal rank of the pencil, that
our notion of a Ô¨Ånite eigenvalue (or zeros) coincides with the corresponding
notion for pencils, and, particularly, that the assumption (A2) of [55], i.e.,
det X[0]
N+1 Ã∏‚â°0, means that the pencil is regular. Hence, by omitting this
assumption, we consider the singular case. We also want to mention here that
all the minimal indices of our special matrix pencil (occurring in the Kronecker
canonical form, cf. [148, Ch. XII] or [71, 157, 318]), equal to zero; see also
[148, Section XII.6]. This fact does simplify the Kronecker canonical form of
the pencil considerably, but it is not used directly further on.
(iv) The concept of eigenvalues and eigenvectors for (5.1) of the main reference
[55], i.e., Œª is an eigenvalue if and only if det X[0]
N+1(Œª) = 0, stems from

5.4
Variational Description of Finite Eigenvalues
339
the continuous eigenvalue problems for linear Hamiltonian differential sys-
tems (1.103). If det X[0]
N+1(Œª) Ã∏‚â°0, i.e., if (A2) of [55] holds, then as mentioned
above, the corresponding matrix pencil is regular, and the deÔ¨Ånitions in (5.284)
and in [55] coincide. But if the pencil is singular, then the deÔ¨Ånition of
eigenvalues in [55] is not appropriate anymore. Instead, the concept of Ô¨Ånite
eigenvalues from (5.284) is the right one for the singular case as one can
see, and this concept stems from the theory of matrix pencils. Actually, there
exists also the notion of inÔ¨Ånite eigenvalues (or zeros) in the theory of matrix
pencils (cf. [148] or [319]), but it does not play any role here. In particular,
the geometric meaning of the concept of Ô¨Ånite eigenvalues as formulated in
Remark 5.75 depends on the special structure (e.g., self-adjointness) of the
corresponding matrix pencil, where the assumption Wk ‚â•0 plays an important
role.
(v) We conclude this remark by pointing out some possible applications of
formula (5.299); see also [55, Remark 3(iv)]. Let Œª0 ‚ààR be given. If we want
to know how many Ô¨Ånite eigenvalues of (5.1) are less than or equal to Œª0, we
can calculate recursively the principal solution Y [0](Œª) at k = 0 of (5.238)
and determine the number of Ô¨Ånite eigenvalues (zeros) of (5.238), (5.283),
resp., of X[0]
N+1(Œª), that are less than or equal to Œª0. However, X[0]
N+1(Œª) is
a polynomial, and it might be difÔ¨Åcult to calculate this number. Alternatively,
if the number m as discussed above is known, then by Theorem 5.78 we could
calculate the principal solution at k = 0 of (5.238) for the particular Œª0 in
question and count the number of its focal points in the interval (0, N + 1].
This procedure could possibly lead to a numerical algorithm to treat the
algebraic eigenvalue problem (5.238) with (5.283) also in this singular case,
although it is well known that singular matrix pencils have in general ill-posed
eigenstructure (cf. [318, 319] or [71, pg. 180]). For the numerical treatment of
the algebraic eigenvalue problem for symmetric, banded matrices via Sturm-
Liouville difference equations (note that this is a very special case of (5.238)),
the theory shows that det X[0]
k (Œª) for a ‚ÄúSturmian chain,‚Äù which may be used
similarly as for treating symmetric tridiagonal matrices; see [206] and [212].
5.4
Variational Description of Finite Eigenvalues
In this section we present further results related to the eigenvalue problems for
system (5.1) with linear dependence on the spectral parameter.
In linear algebra, it is well known that the eigenvalues of a real symmetric
matrix can be calculated as the minimum of the associated quadratic form over
an appropriate space of vectors. More precisely, let A be a real symmetric n √ó n
matrix and Œª1 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªn be its eigenvalues, each eigenvalue repeated according
to its multiplicity. Denote by y1, . . . , yn the corresponding system of eigenvectors.

340
5
Discrete Symplectic Eigenvalue Problems
Then the eigenvalues of A satisfy the formula
Œªm = min
‚ü®Ay, y‚ü©
‚ü®y, y‚ü©, y ‚ä•yk, k = 1, . . . , m ‚àí1, y Ã∏= 0
 
.
(5.300)
The main result of this section presents a similar formula for the Ô¨Ånite eigenvalues
of (5.1) with (5.283), resp., with (5.245) or with (5.242). First we need some pre-
liminary computations, which may be interesting regardless their later application.
5.4.1
Extended Picone Identity
In formula (2.67) in Lemma 2.32, we derived the Picone identity, which presents
the quadratic functional F(y) as a sum of ‚Äúsquares.‚Äù In the following statement,
we extend this result to the quadratic functional F0(y, Œª) by incorporating the Ô¨Ånite
eigenfunctions of (5.1) with (5.283).
Theorem 5.81 (Extended Picone‚Äôs Identity) Suppose that Y is a conjoined basis
of the symplectic system (5.1) for a Ô¨Åxed Œª ‚ààR. Let Q be symmetric with
QX = UX‚Ä†X, and deÔ¨Åne M, T , P by (4.1) and (4.2). Let Œª1, . . . , Œªm be the
Ô¨Ånite eigenvalues of (5.1) and (5.283) with the corresponding orthonormal Ô¨Ånite
eigenfunctions y(j) = (x(j), u(j)), 1 ‚â§j ‚â§m. Let Œ≤1, . . . , Œ≤m ‚ààR and deÔ¨Åne
ÀÜy :=
m

j=1
Œ≤jy(j).
Finally, suppose that y = (x, u) is admissible, i.e., xk+1 = Akxk + Bkuk for k ‚àà
[0, N]Z, put Àúy := y + ÀÜy and Àúz := Àúu ‚àíQÀúx, and assume that
y ‚ä•Œ≤jŒªjy(j),
i.e.,
1
y, Œ≤jŒªjy(j)2
= 0,
for all 1 ‚â§j ‚â§m
(5.301)
and that
Àúxk ‚ààIm Xk
for all k ‚àà[1, N]Z.
(5.302)
Then we have that
F0(y, Œª) ‚àíxT
k uk
			
N+1
k=0 =
N

k=0
ÀúzT
k Pk Àúzk +
m

j=1
(Œª ‚àíŒªj) Œ≤2
j
+ ÀúxT
k Qk Àúxk
			
N+1
k=0 ‚àíÀúxT
k Àúuk
			
N+1
k=0 .
(5.303)

5.4
Variational Description of Finite Eigenvalues
341
Proof First we note that since the Ô¨Ånite eigenfunctions y(j) satisfy the boundary
conditions (5.283), it follows that ÀÜx0 = 0 = ÀÜxN+1, Àúx0 = x0, and ÀúxN+1 = xN+1.
From (2.67) in Lemma 2.32, we obtain
F0( Àúy, Œª) =
N

k=0
(
ÀúxT
k+1 ÀúQk Àúxk+1 ‚àíÀúxT
k ÀúQk Àúxk + ÀúzT
k Pk Àúzk
)
= ÀúxT
k Qk Àúxk
			
N+1
k=0 +
N

k=0
ÀúzT
k Pk Àúzk,
because Àúy is admissible and (5.302) holds. Next, by using the recursion in
system (5.1) with Œª = Œªj for 1 ‚â§j ‚â§m and by (2.61) in Lemma 2.30, we conclude
that
F0( ÀÜy) =
N

k=0
ÀÜxT
k+1
!
Ck ÀÜxk + Dk ÀÜuk ‚àíÀÜuk+1
"
=
N

k=0
m

j=1
Œ≤jŒªj ÀÜxT
k+1Wkx(j)
k+1 =
m

j=1
ŒªjŒ≤2
j .
Moreover, by using y ‚ä•y(j) from (5.301), we have
F0(y, ÀÜy) = xT
k ÀÜuk
			
N+1
k=0 +
N

k=0
m

j=1
Œ≤jŒªjxT
k+1Wkx(j)
k+1 = xT
k ÀÜuk
			
N+1
k=0
and similarly
F0( ÀÜy, y) = ÀÜxT
k uk
			
N+1
k=0 = 0.
Altogether, by using x0 = Àúx0 and xN+1 = ÀúxN+1 and the above calculations, we get
F0(y, Œª) ‚àíxT
k uk
			
N+1
k=0 = F(y) ‚àíŒª ‚ü®y, y‚ü©‚àíxT
k uk
			
N+1
k=0
= F(y) + F( ÀÜy) + F(y, ÀÜy) + F( ÀÜy, y) ‚àí
m

j=1
ŒªjŒ≤2
j ‚àíxT
k ÀÜuk
			
N+1
k=0
‚àíŒª
 ‚ü®y, y‚ü©+
/
ÀÜy, ÀÜy
0 
+ Œª
/
ÀÜy, ÀÜy
0
‚àíxT
k uk
			
N+1
k=0

342
5
Discrete Symplectic Eigenvalue Problems
= F( Àúy) ‚àí
m

j=1
ŒªjŒ≤2
j ‚àíxT
k ÀÜuk
			
N+1
k=0 ‚àíŒª ‚ü®Àúy, Àúy‚ü©+ Œª
m

j=1
Œ≤2
j ‚àíxT
k uk
			
N+1
k=0
= F( Àúy, Œª) +
m

j=1
(Œª ‚àíŒªj) Œ≤2
j ‚àíxT
k (ÀÜuk + uk)
			
N+1
k=0
= ÀúxT
k Qk Àúxk
			
N+1
k=0 +
N

k=0
ÀúzT
k Pk Àúzk +
m

j=1
(Œª ‚àíŒªj) Œ≤2
j ‚àíÀúxT
k Àúuk
			
N+1
k=0 .
Therefore, the proof of (5.303) is complete.
‚äì‚äî
We note that the role of assumption (5.302) in Theorem 5.81 is characterized by
Lemma 2.47 in Sect. 2.3.5.
Remark 5.82 Condition (5.301) in Theorem 5.81 is slightly more general than
the corresponding condition used in [56, Theorem 4.2]. Here we incorporate the
coefÔ¨Åcients Œ≤j and the Ô¨Ånite eigenvalues Œªj into the orthogonality condition (5.301),
which shows that in the case of Œ≤j = 0 or Œªj = 0, this condition is not needed.
5.4.2
Rayleigh Principle
In this subsection we extend formula (5.300) to the Ô¨Ånite eigenvalues of (5.1)
with (5.283), resp., with (5.245) or with (5.242). The main results are essentially
based on the validity of the oscillation theorem (Corollary 5.79) saying that
n1(Œª) = n2(Œª),
n1(Œª+) = n1(Œª),
n2(Œª+) = n2(Œª)
for all Œª ‚ààR.
(5.304)
The latter reference states that the conditions in (5.304) are equivalent to the
positivity of the quadratic functional F(¬∑, Œª0) in (5.273) for some Œª0 < 0. For
practical applications, it will be convenient to guarantee this positivity assumption
by conditions imposed on the coefÔ¨Åcients of system (5.1).
If Œª1 ‚â§. . . ‚â§Œªm are the Ô¨Ånite eigenvalues of (5.1) with (5.283), including their
multiplicities, then we put for convenience Œª0 := ‚àí‚àûand Œªm+1 := ‚àû. Note that
m ‚â§nN < ‚àûby (5.288) in Remark 5.75.
Theorem 5.83 (Rayleigh Principle for Dirichlet Boundary Conditions) Assume
that (5.239), (5.240), and (5.273) hold and
there exists Œª0 < 0 such that F(¬∑, Œª0) > 0.
(5.305)
Let Œª1 ‚â§Œª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm denote the Ô¨Ånite eigenvalues of (5.1) with (5.283), with the
corresponding orthonormal Ô¨Ånite eigenfunctions y(j), 1 ‚â§j ‚â§m, with respect to

5.4
Variational Description of Finite Eigenvalues
343
the inner product (5.287). Then for every 0 ‚â§j ‚â§m, we have
Œªj+1 = min
F(y, 0)
‚ü®y, y‚ü©, y = (x, u) is admissible with x0 = 0 = xN+1,
y ‚ä•y(1), . . . , y(j), and {Wkxk+1}N‚àí1
k=0 Ã∏‚â°0
 
.
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(5.306)
Note that we include the case of j = 0, where the orthogonality condition on y
becomes empty, as well as the case of j = m, where Œªm+1 = ‚àû.
Proof of Theorem 5.83 Let 0 ‚â§j ‚â§m be Ô¨Åxed, and choose Œª ‚àà(Œªj, Œªj+1). Then,
by (5.304), we have n2(Œª) = n1(Œª) = j, so that the principal solution Y(Œª) :=
Y [0](Œª) at k = 0 possesses exactly j focal points in the interval (0, N + 1]. The fact
that N + 1 is actually not a focal point of Y(Œª) follows from assumption (5.305),
Proposition 5.65, and Theorem 2.36, which imply that rank Mk(ÀúŒª) = 0 for all ÀúŒª ‚â§
Œª0. Hence,
rankMk(Œª+) = rankMk(Œª) = 0
for all k ‚àà[0, N]Z,
Œª ‚àà(Œªm, Œªm+1).
In particular, we have rank MN(Œª) = 0. First, we apply the extended Picone identity
(Theorem 5.81) to y = 0, which yields
Àúy = ÀÜy =
m

i=1
Œ≤iy(i)
with Àúx0 = 0 = ÀúxN+1, x0 = 0 = xN+1.
Suppose that Œ≤1, . . . , Œ≤j satisfy the j linear homogeneous equations
MT
k Àúxk+1 = 0,
k ‚àà[0, N ‚àí1]Z,
Àúzk ‚ä•
!
Œ± ‚ààRn, Œ± is an eigenvector corresponding
to a negative eigenvalue of Pk
"
,
k ‚àà[0, N]Z,
‚é´
‚é™‚é¨
‚é™‚é≠
(5.307)
where Àúzk = Àúuk ‚àíQk Àúxk. Note that the number of these equations is equal to the
number of of focal points of Y in the open interval (0, N+1). Then, by Lemma 2.48,
assumption (5.302) holds, and we obtain from Theorem 5.81 that
0 = F(y, Œª) =
N

k=0
ÀúzT
k Pk Àúzk +
j

i=1
(Œª ‚àíŒªi) Œ≤2
i ,
(5.308)
where ÀúzT
k Pk Àúzk ‚â•0 for k ‚àà[0, N]Z by (5.307) and Œª ‚àíŒªi ‚â•Œª ‚àíŒªj > 0 for
1 ‚â§i ‚â§j. Hence, (5.308) implies that Œ≤1 = ¬∑ ¬∑ ¬∑ = Œ≤j = 0, so that (5.307)
possesses only the trivial solution. Thus we have shown that
the coefÔ¨Åcient matrix corresponding to system (5.307) is nonsingular.
(5.309)

344
5
Discrete Symplectic Eigenvalue Problems
Now suppose that y = (x, u) is admissible with x0 = 0 = xN+1 and y ‚ä•y(i)
for 1 ‚â§i ‚â§j. According to (5.309), there exists a unique set of constants
Œ≤1, . . . , Œ≤j such that the function Àúy := y + ÀÜy = y + j
i=1 Œ≤iy(i) satisÔ¨Åes the j
linear inhomogeneous equations deÔ¨Åned by (5.307). Consequently, Theorem 5.81
implies that
F(y, Œª) = F(y, Œª) ‚àíxT
k uk
			
N+1
k=0
=
N

k=0
ÀúzT
k Pk Àúzk +
j

i=1
(Œª ‚àíŒªi) Œ≤2
i ‚â•
j

i=1
(Œª ‚àíŒªi) Œ≤2
i ‚â•0.
This shows that
F(y) ‚â•Œª ‚ü®y, y‚ü©
for all Œª ‚àà(Œªj, Œªj+1).
(5.310)
Hence, F(y) ‚â•Œªj+1 ‚ü®y, y‚ü©by the continuity and taking Œª ‚ÜíŒª‚àí
j+1 in (5.310).
Moreover, we have F(y) = Œªj+1 ‚ü®y, y‚ü©for y = y(j+1). For multiple Ô¨Ånite
eigenvalues, use the fact that F(y, Œª) = F(y + ÀÜy, Œª) if y is admissible with
x0 = 0 = xN+1 and if ÀÜy is a Ô¨Ånite eigenvector corresponding to Œª. Hence the
assertion follows.
‚äì‚äî
In later applications in Sect. 5.5, we will use the statement of Theorem 5.83 under
stronger positivity assumption (5.268) instead of (5.305), i.e., under Wk > 0 for all
k ‚àà[0, N]Z.
Corollary 5.84 Assume that (5.239), (5.240), (5.246), (5.268), and (5.273) hold.
Then the Ô¨Ånite eigenvalues Œª1 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm of (5.1) with (5.283) satisfy for every
0 ‚â§j ‚â§m the equality in (5.306), in which we consider admissible y with x0 =
0 = xN+1, y ‚ä•y(1), . . . , y(j), and {xk}N
k=1 Ã∏‚â°0.
Proof The result follows from Theorem 5.83 and Corollary 5.69.
‚äì‚äî
Now we consider the Rayleigh principle for the eigenvalue problem (5.1) with
separated boundary conditions (5.245). Here we use the quadratic functional G(¬∑, Œª)
given in (5.262). We note that by (5.293) the total number m of Ô¨Ånite eigenvalues
of (5.1) with (5.245) satisÔ¨Åes m ‚â§(N + 2) n.
Theorem 5.85 (Rayleigh
Principle
for
Separated
Boundary
Conditions)
Assume that (5.239), (5.240), (5.246), (5.247), (5.248), and (5.262) hold and
there exists Œª0 < 0 such that G(¬∑, Œª0) > 0.
(5.311)
Let Œª1 ‚â§Œª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm denote the Ô¨Ånite eigenvalues of (5.1) with (5.245), with the
corresponding orthonormal Ô¨Ånite eigenfunctions y(j), 1 ‚â§j ‚â§m, with respect to

5.4
Variational Description of Finite Eigenvalues
345
the inner product (5.292). Then for every 0 ‚â§j ‚â§m, we have
Œªj+1 = min
G(y, 0)
‚ü®y, y‚ü©, y = (x, u) is admissible with (5.263),
y ‚ä•y(1), . . . , y(j), and {Wk xk+1}N‚àí1
k=‚àí1 Ã∏‚â°0
or (WN + WN+1) xN+1 Ã∏= 0
 
.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.312)
Proof This statement follows from Theorem 5.83 upon applying it to the equivalent
extended eigenvalue problem on the interval [‚àí1, N + 2]Z with the Dirichlet
boundary conditions x‚àí1(Œª) = 0 = xN+2(Œª). This equivalence is discussed in
details in Theorem 5.41 for the two eigenvalue problems and in Lemma 5.47 for the
associated quadratic functionals.
‚äì‚äî
Assumption (5.311) can be guaranteed by several conditions described in Propo-
sitions 5.66 and 5.67 and in Remark 5.68. Condition (5.311) can also be tested by
the properties of the natural conjoined basis ¬ØY(Œª0) of system (5.238) with Œª := Œª0,
which are presented in Theorem 2.50.
Corollary 5.86 Assume that (5.239), (5.246), (5.270), and (5.262) hold. Then the
Ô¨Ånite eigenvalues Œª1 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm of (5.1) with (5.245) satisfy for every index 0 ‚â§
j ‚â§m the equality in (5.312), in which we consider admissible y with (5.263),
y ‚ä•y(1), . . . , y(j), and {xk}N+1
k=0 Ã∏‚â°0.
Proof The result follows from Theorem 5.85 and Remark 5.68.
‚äì‚äî
When W‚àí1 = 0, WN+1 = 0, and Wk > 0 for all k ‚àà[0, N]Z, we obtain another
generalization of Corollary 5.84 to the separated boundary conditions
R‚àó
0 x0(Œª) + R0 u0(Œª) = 0,
R‚àó
N+1 xN+1(Œª) + RN+1 uN+1(Œª) = 0,
(5.313)
which in this case do not depend on the spectral parameter Œª. In this case the inner
product in (5.292) reduces to the traditional expression
‚ü®y, Àúy‚ü©=
N

k=0
xT
k+1Wk Àúxk+1.
(5.314)
Corollary 5.87 Assume that (5.239), (5.246), (5.268), (5.269), and (5.267) hold.
Then the Ô¨Ånite eigenvalues Œª1 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm of (5.1) with (5.313) satisfy for every
index 0 ‚â§j ‚â§m the equality in (5.312), in which we consider inner product (5.314)
and admissible y with (5.263), y ‚ä•y(1), . . . , y(j), and {xk}N+1
k=0 Ã∏‚â°0.
Proof The result follows from Theorem 5.85 and Proposition 5.67.
‚äì‚äî
As a Ô¨Ånal result in this section, we consider the Rayleigh principle for the
eigenvalue problem consisting of system (5.1) with the joint endpoints (5.242).

346
5
Discrete Symplectic Eigenvalue Problems
Theorem 5.88 (Rayleigh Principle for Joint Boundary Conditions) Assume
that (5.239), (5.240), (5.243), (5.244), and (5.260) hold and
there exists Œª0 < 0 such that G(¬∑, Œª0) > 0.
(5.315)
Let Œª1 ‚â§Œª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm denote the Ô¨Ånite eigenvalues of (5.1) with (5.242), with the
corresponding orthonormal Ô¨Ånite eigenfunctions y(j), 1 ‚â§j ‚â§m, with respect to
the inner product (5.279). Then for every 0 ‚â§j ‚â§m, we have
Œªj+1 = min
G(y, 0)
‚ü®y, y‚ü©, y = (x, u) is admissible with (5.261),
y ‚ä•y(1), . . . , y(j), and {Wk xk+1}N‚àí1
k=0 Ã∏‚â°0
or W
 x0
xN+1

Ã∏= 0
 
.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(5.316)
Proof This statement follows from Theorem 5.85 upon applying it to the equivalent
augmented eigenvalue problem on the interval with the separated. This equivalence
is discussed in details in Theorem 5.44 for the two eigenvalue problems.
‚äì‚äî
Assumption (5.315) can also be tested by the properties of the principal solution
Y [0](Œª0) of system (5.238) with Œª := Œª0, which are presented in Theorem 2.53.
5.5
Applications of Oscillation Theorems
In this section we present results on the numbers the focal points of conjoined bases
of one or two symplectic systems. In the derivation of these results, we utilize the
eigenvalue theory and the oscillation theorems for boundary value problems for
symplectic systems depending linearly on the spectral parameter, i.e., essentially
based on the results in Sects. 5.3‚Äì5.4.
5.5.1
Sturmian Comparison and Separation Theorems
In this subsection we present an alternative approach to the Sturmian comparison
and separation theorems based on the variational techniques from Sect. 5.4.
Comparison theory for symplectic difference systems has been already treated in
Sect. 4.3 (see Corollary 4.57). There, the main tool was the relationship between
the comparative index and the multiplicity of a focal point. Here we present
a proof based on the eigenvalue problem (5.1) and the associated discrete quadratic
functional.

5.5
Applications of Oscillation Theorems
347
We recall from Sects. 2.3.2 and 5.3.4 the quadratic functionals
F(y) =
N

k=0
(
xT
k AT
k Ckxk + 2 xT
k CT
k Bkuk + uT
k BT
k Dkuk
)
,
F(y, Œª) = F(y) ‚àíŒª ‚ü®y, y‚ü©,
where y = (x, u) is admissible, i.e., xk+1 = Akxk + Bkuk for k ‚àà[0, N]Z, and
x0 = 0 = xN+1. We will utilize the symmetric 2n √ó 2n matrices Gk and the n √ó n
matrices Ek deÔ¨Åned in (2.64), which are used to write the functional F(y) in terms
of the x component of y only; see (2.63). With systems (SDS) and (5.1), we consider
another symplectic systems
ÀÜyk+1 = ÀÜSk ÀÜyk,
k ‚àà[0, N]Z,
(5.317)
and
ÀÜyk+1(Œª) = ÀÜSk(Œª) ÀÜyk(Œª),
k ‚àà[0, N]Z,
(5.318)
with the block structure as in (5.239) for the coefÔ¨Åcient matrices Sk(Œª) and ÀÜSk(Œª).
In this case we deÔ¨Åne the corresponding matrices ÀÜG and ÀÜEk and the quadratic
functionals ÀÜF( ÀÜy) and ÀÜF( ÀÜy, Œª) analogously to (2.64) and (5.273). Finally, in this
section we suppose that the weight matrices satisfy
Wk = I = ÀÜWk,
k ‚àà[0, N]Z,
(5.319)
so that the number m = 0 in formula (5.297), i.e.,
n1(Œª) = n2(Œª)
for all Œª ‚ààR
(5.320)
for system (SDS), as well as for system (5.317). In particular, the Rayleigh principle
in Corollary 5.84 holds for both systems (5.1) and (5.318) with the Dirichlet
boundary conditions.
Two following two results represent Sturmian-type comparison theorems for
symplectic systems (SDS) and (5.317).
Theorem 5.89 (Sturmian Comparison Theorem) Suppose that
Gk ‚â•ÀÜGk and Im (Ak ‚àíÀÜAk,
Bk) ‚äÜIm ÀÜBk
(5.321)
for all k ‚àà[0, N]Z. If the principal solution of (5.317) at k = 0 has q focal points
in (0, N + 1], then any conjoined basis of (SDS) has at most q + n focal points in
(0, N + 1].

348
5
Discrete Symplectic Eigenvalue Problems
Proof Let Y be a conjoined basis of (SDS) and suppose that it has p focal points
in (0, N + 1]. Then, as in Proposition 2.38 and the proof of Theorem 4.16, we can
construct for each focal point of Y the corresponding admissible y[j] = (x[j], u[j])
such that x[j]
N+1 = 0 for all 1 ‚â§j ‚â§p. Furthermore, since the principal solution
Y [0] of (5.317) at k = 0 is assumed to have q focal points in (0, N +1], we know by
Corollary 5.79 with Œª = 0 applied to the eigenvalue problem (5.318) with ÀÜW = I
that this eigenvalue problem has q nonpositive Ô¨Ånite eigenvalues Œªi, 1 ‚â§i ‚â§q, with
the corresponding orthonormal Ô¨Ånite eigenvectors ÀÜy(i) = (ÀÜx(i), ÀÜu(i)), 1 ‚â§i ‚â§q.
Moreover, by Corollary 5.84, we have F(y) ‚â•ÀÜF(y) > 0 ¬∑ ‚ü®y, y‚ü©= 0 for ( ÀÜA, ÀÜB)-
admissible y = (x, u) satisfying
y ‚ä•ÀÜy(i),
i.e.,
1
y, ÀÜy(i)2
=
N

k=0
xT
k+1 ÀÜx(i)
k+1 = 0,
1 ‚â§i ‚â§q,
x Ã∏= 0.
Now suppose that p > q + n. Then there exists a nontrivial linear combination
p

j=1
cj
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
/y[j], ÀÜy(1)0
/
y[j], ÀÜy(2)0
...
/
y[j], ÀÜy(q)0
x[j]
0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
= 0.
DeÔ¨Åne
y = (x, u) =
p

j=1
cjy[j].
By construction, xN+1 = 0 and y is admissible. Moreover, p
j=1 cjx[j]
0
= 0 implies
that x0 = 0, as well as
0 =
p

j=1
cj
1
y[j], ÀÜy(i)2
=
1
y, ÀÜy(i)2
for all 1 ‚â§i ‚â§q,
so that y ‚ä•ÀÜy(i) for all 1 ‚â§i ‚â§q. As in the proof of Theorem 4.16 we have that
x Ã∏‚â°0 (since not all cj = 0) and F(z) ‚â§0. From the second condition in (5.321),
it follows that there exists ÀÜu = {ÀÜuk}N
k=0 such that xk+1 = Akxk + Bk ÀÜuk for all k ‚àà
[0, N]Z, and hence ÀÜy := (x, ÀÜu) is admissible for ÀÜF. By using the representation of
quadratic functional ÀÜF via the matrix ÀÜG, as in (2.63), coupled with the Ô¨Årst condition
in (5.321), we Ô¨Ånd that
ÀÜF(4y) =
N

k=0
 xk
xk+1
T
ÀÜGk
 xk
xk+1

‚â§
N

k=0
 xk
xk+1
T
Gk
 xk
xk+1

= F(y) ‚â§0.

5.5
Applications of Oscillation Theorems
349
Hence we have found an ( ÀÜA, ÀÜB)-admissible y = (x, u) with x Ã∏‚â°0, x0 = 0 = xN+1,
y ‚ä•ÀÜy(i) for all 1 ‚â§i ‚â§q, and ÀÜF(y) ‚â§0. This contradicts the Rayleigh principle
(Corollary 5.84), by which ÀÜF(y) > 0 for all admissible y with x0 = 0 = xN+1,
x Ã∏= 0, and y ‚ä•ÀÜy(i) for all 1 ‚â§i ‚â§q. Therefore, we must have p ‚â§q + n, which
proves the result.
‚äì‚äî
Theorem 5.90 (Sturmian Comparison Theorem) Suppose that (5.321) holds. If
the principal solution of (SDS) at k = 0 has q focal points in (0, N + 1], then any
conjoined basis of (5.317) has at least q focal points in (0, N + 1].
Proof Let Y [0] be the principal solution of the (SDS) at k = 0, and let ÀÜY be
a conjoined basis of (5.317). For any Œª ‚ààR, let Y [0](Œª) be the principal solution
of (5.1) at k = 0, and let ÀÜY(Œª) be the conjoined basis of (5.318) such that
ÀÜY0(Œª) ‚â°ÀÜY0, so that these initial conditions are constant in Œª ‚ààR. We denote by
n1(Œª) and p(Œª) the numbers of focal points of Y [0](Œª) and ÀÜY(Œª) in the interval
(0, N + 1]. The assumptions then imply that q = n1(0), and we need to prove that
n1(0) ‚â§p(0). We will show that
n1(Œª) ‚â§p(Œª)
for all Œª ‚ààR.
(5.322)
By the oscillation theorem (Corollary 5.79), there are exactly n2(0) = n1(0) =
q nonpositive Ô¨Ånite eigenvalues of (5.1), (5.283). We denote by Œªi for 1 ‚â§i ‚â§
r all the Ô¨Ånite eigenvalues of (5.1), (5.283) with the corresponding orthonormal
eigenfunctions y(i), 1 ‚â§i ‚â§r (so that q ‚â§r). Fix now Œª ‚ààR. Then we have
Œª ‚àà[Œªm, Œªm+1)
for some m ‚àà{0, . . ., r},
where we put Œª0 := ‚àí‚àûand Œªr+1 := ‚àû. By (5.320), this means that n1(Œª) =
n2(Œª) = m. First suppose that Œª is not a Ô¨Ånite eigenvalue of (5.1), (5.283) so
that Œª ‚àà(Œªm, Œªm+1). Let Àúp be the number of focal points of ÀÜY(Œª) in the open
interval (0, N + 1) so that Àúp ‚â§p(Œª). Put Àúy = (Àúx, Àúu) := m
j=1 Œ≤jy(j), where the
constants Œ≤1, . . . , Œ≤j are chosen in such a way that Àúy satisÔ¨Åes Àúp linear homogeneous
conditions
ÀÜMT
k (Œª) Àúxk+1 = 0,
k ‚àà[0, N ‚àí1]Z,
Àúzk ‚ä•
!
Œ± ‚ààRn, Œ± is an eigenvector corresponding
to a negative eigenvalue of ÀÜPk(Œª)",
k ‚àà[0, N]Z
‚é´
‚é™‚é¨
‚é™‚é≠
(5.323)
where
Àúzk = Àúuk ‚àíÀÜUk(Œª) ÀÜX‚Ä†
k(Œª) Àúxk =
m

j=1
Œ≤j

Àúu(j)
k
‚àíÀÜUk(Œª) ÀÜX‚Ä†
k(Œª) Àúx(j)
k


350
5
Discrete Symplectic Eigenvalue Problems
and where the matrices ÀÜMk(Œª) and ÀÜPk(Œª) are given by (5.40) with ÀÜY(Œª) instead of
Y(Œª). The sequence Àúy is admissible for F, and by the second condition in (5.321),
there exists ÀÜu such that the pair ÀÜy := (Àúx, ÀÜu) is admissible for ÀÜF. Since the value of
the quadratic functional does not depend on the second component of an admissible
sequence y = (x, u), see (2.63), we can write also Àúy = (Àúx, ÀÜu). Then by the extended
Picone identity (Theorem 5.81), we have
ÀÜF( Àúy, Œª) := ÀÜF( Àúy) ‚àíŒª ‚ü®Àúy, Àúy‚ü©=
N

k=0
ÀúzT
k ÀÜPk Àúzk ‚â•0.
We note that the Ô¨Årst condition in (5.323) implies that Àúxk ‚ààIm ÀÜXk for all k ‚àà
[0, N + 1]Z by Lemma 2.48, and hence Theorem 5.81 can be applied. At the same
time, by a direct computation using the orthonormality of y(1), . . . , y(m), we have
FŒª( Àúy) := F( Àúy) ‚àíŒª ‚ü®Àúy, Àúy‚ü©=
m

j=1
(Œªj ‚àíŒª) Œ≤2
j .
Now again by (2.63) and the Ô¨Årst condition in (5.321), we have
m

j=1
(Œªj ‚àíŒª) Œ≤2
j ‚â•
N

k=0
ÀúzT
k ÀÜPk(Œª) Àúzk ‚â•0,
since Œª > Œªj for all 1 ‚â§j ‚â§m. This is however possible only if Œ≤j = 0 for all
1 ‚â§j ‚â§m. This means that the system (5.323) of Àúp linear homogeneous conditions
has only the trivial solution, and hence the number of conditions Àúp is greater than
or equal to the number of parameters Œ≤j (which is equal to q). This proves the
required statement when Œª is not a Ô¨Ånite eigenvalue of (5.1), (5.283). Finally, since
the functions n1(Œª) and p(Œª) are right-continuous, by letting Œª ‚ÜíŒª+
m, we obtain
the statement also in the case when Œª = Œªm is a Ô¨Ånite eigenvalue of (5.1), (5.283).
The proof is complete.
‚äì‚äî
When the two systems (SDS) and (5.317) are the same, then the assumptions
in (5.321) are trivially satisÔ¨Åed, and we obtain from Theorems 5.89 and 5.90 the
following, compare with Sect. 4.2.3 and in particular formula (4.68), where a more
precise estimate for the number of focal points was derived by using the comparative
index.
Corollary 5.91 (Sturmian Separation Theorem) Suppose that the principal solu-
tion of (SDS) at k = 0 has q focal points in (0, N + 1]. Then any conjoined basis
of (SDS) has at at least q and at most q + n focal points in (0, N + 1].

5.5
Applications of Oscillation Theorems
351
5.5.2
ModiÔ¨Åcations of Global Oscillation Theorem
In this subsection we present some modiÔ¨Åcations of the global oscillation theorem
(Theorem 5.78). These extensions are obtained using the number l‚àó(Y, M, N) of
the backward focal points in the interval [M, N) of the conjoined basis Y (see
DeÔ¨Ånition 4.3 and Sect. 4.2.3). The Ô¨Årst application of the concept of backward focal
points (which is the same as ‚Äúfocal points‚Äù of the reversed symplectic system (2.47))
consists in replacing the quantity
n1(Œª) = n1(Y [0](Œª)) := l(Y [0](Œª), 0, N + 1)
by the quantity
n‚àó
1(Y [N+1](Œª)) := l‚àó(Y [N+1](Œª), 0, N + 1),
(5.324)
where l‚àó(Y [N+1](Œª), 0, N + 1) is number of backward focal points of the principal
solution of (5.238) at N + 1 in [0, N + 1); see Theorem 4.34. Hence, as a corollary
of Theorem 4.34, we obtain the next statement.
Corollary 5.92 Under the assumptions of Theorem 5.78, the number n1(Œª)
in (5.294), (5.296), (5.297), (5.298) can be replaced by n‚àó
1(Y [N+1](Œª)) deÔ¨Åned
in (5.324), where l‚àó(Y [N+1](Œª), 0, N + 1) is the number of backward focal points
of the principal solution Y [N+1](Œª) of (5.238) at N + 1 in [0, N + 1).
Another possibility how to apply the number of backward focal points in the
interval [M, N) is the following modiÔ¨Åcation of the global oscillation theorem to
eigenvalues which are strictly less than a given value Œª ‚ààR.
Theorem 5.93 Under the assumptions of Theorem 5.78, there exists an index m‚àó‚àà
N ‚à™{0} such that
n‚àó
1(Y [0](Œª)) = no
2(Œª) + m‚àó,
no
2(Œª) =

Œº<Œª
Œ∏(Œº),
(5.325)
where 
Œº<Œª Œ∏(Œº) is the number of Ô¨Ånite eigenvalues of (5.238), (5.283) which
are less than Œª ‚ààR, Y [0](Œª) is the principal solution of (5.238) at k = 0, and
n‚àó
1(Y [0](Œª)) := l‚àó(Y [0](Œª), 0, N + 1) is the number of backward focal points of
Y [0](Œª) in [0, N + 1).
Proof Let Œª0 < Œªmin = min œÉ, where œÉ is the Ô¨Ånite spectrum of (5.238), (5.283).
Then
no
2(Œª) = n2(Œª) ‚àíŒ∏(Œª) = n2(Œª) + rankX[0]
N+1(Œª)
		Œª
Œª0,

352
5
Discrete Symplectic Eigenvalue Problems
where Œ∏(Œª) is the (algebraic) multiplicity of Œª ‚ààœÉ and Œ∏(Œª) = 0 for Œª Ã∏‚ààœÉ. Hence,
using Corollary 4.6, we obtain
no
2(Œª) = l(Y [0](Œª), 0, N + 1) ‚àíl(Y [0](Œª0), 0, N + 1) + rankX[0]
N+1(Œª)
		Œª
Œª0
= l‚àó(Y [0](Œª), 0, N + 1) ‚àíl‚àó(Y [0](Œª0), 0, N + 1)
= n‚àó
1(Y [0](Œª)) ‚àín‚àó
1(Y [0](Œª0)),
where l‚àó(Y, 0, N + 1) is the number of backward focal points of a given conjoined
basis in [0, N + 1). If we denote m‚àó:= n‚àó
1(Y [0](Œª0)), then the theorem is proved.
‚äì‚äî
Using the equality l‚àó(Y [0](b), 0, N + 1) = l(Y [N+1](b), 0, N + 1) (see Theo-
rem 4.35), we derive the ‚Äúdual version‚Äù of Theorem 5.93.
Corollary 5.94 (Global Oscillation Theorem for Linear Dependence on Œª)
Under the assumptions of Theorem 5.78, there exists an index m‚àó‚ààN ‚à™{0} such
that
n1(Y [N+1](Œª)) = no
2(Œª) + m‚àó,
no
2(Œª) =

Œº<Œª
Œ∏(Œº),
(5.326)
where 
Œº<Œª Œ∏(Œº) is the number of Ô¨Ånite eigenvalues of (5.238), (5.283) which are
less than Œª ‚ààR, Y [N+1](Œª) is the principal solution of (5.238) at k = N + 1, and
n1(Y [N+1](Œª)) is the number of forward focal points of Y [N+1](Œª) in (0, N + 1].
The advantage of the just proved statements for the multiplicities of backward
focal points is that, in view of Lemma 4.8, the previous formulas involve the blocks
of S‚àí1
k (0 I)T , which do not contain the spectral parameter Œª.
5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
In this section we extend the results of Sect. 5.1 for the nonlinear eigenvalue
problems (E), i.e.,
yk+1 = Sk(Œª) yk,
yk =
 xk
uk

,
Œª ‚ààR,
x0 = 0 = xN+1,
by applying the comparative index theory (see Chap. 3). The comparative index
approach gives us the possibility to remove the restrictive assumption (5.38), i.e.,
rankBk(Œª) is constant in Œª on R

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
353
which was used in Sect. 5.1.3 in the local and global oscillation theorems (see
Theorems 5.15, 5.16, 5.17 and Corollary 5.18). Recall that condition (5.38) is
automatically satisÔ¨Åed for nonlinear eigenvalue problems for the scalar and matrix
Sturm-Liouville equations (see Examples 5.35 and 5.36), because the symplectic
coefÔ¨Åcient matrix Sk(Œª) of the associated symplectic eigenvalue problem (E) obeys
the condition det Bk(Œª) Ã∏= 0 for all Œª ‚ààR. It was shown in Example 5.38
that the higher- order Sturm-Liouville difference equations written as a discrete
symplectic system also obey (5.38). However there are important classes of spectral
problems (E), for which condition (5.38) imposes serious restrictions on the
applicability of the local and global oscillation theorems. In Example 5.39, for
spectral problems (E) for the real symplectic difference systems with the general
linear dependence, Sk(Œª) = Sk + ŒªVk on Œª condition (5.38) implies the absence of
real Ô¨Ånite eigenvalues of the linear matrix pencil Bk(Œª) = Bk + Œª ÀúBk. For the most
important special case of (E), for the linear Hamiltonian difference systems (see
Example 5.37) condition (5.38) means that rank [I ‚àíAk(Œª)]‚àí1Bk(Œª) = rank Bk(Œª)
is constant for Œª ‚ààR.
Recall that the proofs of Theorems 5.15, 5.16, 5.17 are based on two main
grounds. The Ô¨Årst one is monotonicity condition (5.3) and its corollaries, which
imply almost all basic properties of the spectral problem (E), including the main
notion of Ô¨Ånite eigenvalues (DeÔ¨Ånition 5.5) and their isolated character (see
Corollary 5.7). The second foundation is the index theorem (see Theorem 1.85
and Corollary 1.86) imposing the restriction in (5.38). The lower boundedness of
the spectrum of (E) (see Corollary 5.18) follows from Theorem 5.17 based on
Corollary 1.86, and then (5.3) together with (5.38) implies that all eigenvalues of (E)
are isolated and bounded from below.
In this section we retain the Ô¨Årst ground assuming that (5.3) holds but change
the second one replacing Corollary 1.86 by the main theorem of the comparative
index theory (see Theorem 3.24). By applying Theorem 3.24, we avoid (5.38) in the
extended version of the local oscillation theorem (see Theorem 5.95) incorporating
the jump discontinuities of the piecewise constant function rank Bk(Œª) for k ‚àà
[0, N]Z. As a corollary we show that the Ô¨Ånite spectrum of the symplectic eigenvalue
problem (E) is bounded from below if and only if so is the set of discontinuity points
of rankBk(Œª) (see Corollary 5.96).
For the proof of the extended version of the global oscillation theorem (see
Theorem 5.98), we assume additionally to (5.3) that rank Bk(Œª) is constant for
all sufÔ¨Åciently negative Œª. Note that this assumption is naturally satisÔ¨Åed for
problems (E) with a polynomial dependence on Œª, in particular for a general linear
dependence on Œª (see Example 5.39), as well as for the Hamiltonian eigenvalue
problems with the nonlinear dependence in Œª considered in Example 5.37.

354
5
Discrete Symplectic Eigenvalue Problems
5.6.1
Statement of Main Results
The consideration in this section is based on Theorem 5.1. In the previous results,
under assumption (5.38), we did not need assertions (i) and (ii) of this theorem,
because we have that (5.9) and (5.10) hold. In this section, assertions (i) and (ii) of
Theorem 5.1 play a leading role.
By Theorem 5.1(i), we conclude that the set Ker Bk(Œª) is piecewise constant in Œª
on R. That is, for every Œª0 ‚ààR, there exists Œ¥ > 0 such that
Ker Bk(Œª) ‚â°Ker Bk(Œª‚àí
0 ) ‚äÜKer Bk(Œª0)
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0),
(5.327)
Ker Bk(Œª) ‚â°Ker Bk(Œª+
0 ) ‚äÜKer Bk(Œª0)
for all Œª ‚àà(Œª0, Œª0 + Œ¥),
(5.328)
and the quantity rank Bk(Œª) is constant on some left and right neighborhoods of Œª0.
By analogy with DeÔ¨Ånition 5.5, we introduce the numbers
œëk(Œª0) := rank Bk(Œª‚àí
0 ) ‚àírankBk(Œª0),
k ‚àà[0, N]Z,
(5.329)
which count the jumps of rank Bk(Œª) in the left neighborhood of Œª0. Moreover,
Theorem 5.1(i) implies that all break points of rank Bk(Œª) are isolated. Now we
present an extended version of Theorems 5.15 and 5.16 without condition (5.38).
Recall that according to deÔ¨Ånition (5.39), we denote by mk(Œª) the multiplicity of
focal points for conjoined bases of (SDSŒª) in the interval (k, k +1] (see (5.39)). The
number n1(Œª) = l(Y(Œª), 0, N + 1) is then the number of forward focal points of
a conjoined basis Y(Œª) = (X(Œª), U(Œª)) in (0, N + 1], including the multiplicities.
Theorem 5.95 (Local Oscillation Theorem for rankB(Œª) Ã∏= const) Let assumpt-
ion (5.3) be satisÔ¨Åed. Let Y(Œª) be a conjoined basis of (SDSŒª) with (5.20). Then
mk(Œª‚àí) and mk(Œª+) exist for all Œª ‚ààR and
mk(Œª+) = mk(Œª) ‚â§n,
mk(Œª+) ‚àímk(Œª‚àí) + rank Bk(Œª‚àí) ‚àírank Bk(Œª)
= rankXk(Œª) ‚àírankXk(Œª‚àí) + rankXk+1(Œª‚àí) ‚àírank Xk+1(Œª).
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(5.330)
Moreover,
n1(Œª+) = n1(Œª) ‚â§n(N + 1),
n1(Œª+) ‚àín1(Œª‚àí) +
N

k=0
œëk(Œª)
= rank XN+1(Œª‚àí) ‚àírankXN+1(Œª) = Œ∏(Œª).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.331)
The proof of Theorem 5.95 is presented in Sect. 5.6.4.

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
355
Recall again that by Corollary 5.7 all break points of rank XN+1(Œª) and of
rankBk(Œª) are isolated, so that by using that n1(Œª) is right-continuous we derive
from (5.331) for any a, b ‚ààR with a < b
n1(b) ‚àín1(a) +

Œº‚àà(a,b]
N

k=0
œëk(Œº) =

Œº‚àà(a,b]
Œ∏(Œº),
(5.332)
where the sums 
Œº‚àà(a,b]
N
k=0 œëk(Œº) and 
Œº‚àà(a,b] Œ∏(Œº) are Ô¨Ånite. If we assume
additionally that the function rank Bk(Œª) is left-continuous for all sufÔ¨Åciently small
Œª, i.e., if there exists Œª00 ‚ààR such that
rankBk(Œª) = rankBk(Œª‚àí)
for all Œª < Œª00,
k ‚àà[0, N]Z,
(5.333)
then by applying Theorem 5.95, we have
n1(Œª+) = n1(Œª),
n1(Œª+) ‚àín1(Œª‚àí) = rankXN+1(Œª‚àí) ‚àírank XN+1(Œª) ‚â•0,

Œª < Œª00.
(5.334)
Repeating the proof of Theorem 5.16 we conclude by (5.334) that n1(Œª) is bounded
and nondecreasing for all Œª < Œª00, then there exists Œª0 such that
n1(Œª) ‚â°m
for all Œª < Œª0.
So we see by (5.334) that
rankXN+1(Œª) = rank XN+1(Œª‚àí)
for all Œª < Œª0,
(5.335)
i.e., the Ô¨Ånite spectrum of (E) is bounded from below. Moreover, using the
boundedness of n1(Œª), we can prove the following corollary to Theorem 5.95.
Corollary 5.96 Assume (5.3). Then, condition (5.333) holds if and only if the Ô¨Ånite
spectrum of (E) is bounded from below.
Proof It was already proved above that (5.333) implies (5.335). Conversely,
assume (5.335). It follows from (5.332) that
						

Œº‚àà(a,b]
N

k=0
œëk(Œº) ‚àí

Œº‚àà(a,b]
Œ∏(Œº)
						
= |n1(b) ‚àín1(a)| ‚â§n(N + 1).
Moreover, under assumption (5.335), we have 
Œº‚àà(a,b] Œ∏(Œº) = 0 for b < Œª0. It
follows that 
Œº‚àà(a,b]
N
k=0 œëk(Œº) is bounded as a ‚Üí‚àí‚àûand œëk(Œº) ‚â•0. Finally,
there exists Œª00 such that (5.333) holds, i.e., œëk(Œª) ‚â°0.
‚äì‚äî

356
5
Discrete Symplectic Eigenvalue Problems
Remark 5.97
(i) Note that conditions (5.3) and (5.333) imply that there exists ÀúŒª such that
rank Bk(Œª) = const,
rankXN+1(Œª) = const
for all Œª < ÀúŒª.
(5.336)
Indeed, by (5.327), (5.328) rank Bk(Œª0) ‚â§rankBk(Œª) for Œª ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥)
and the last inequality coupled with (5.333) implies that 0 ‚â§rank Bk(Œª) ‚â§n is
a nondecreasing function with respect to Œª for Œª < Œª00. Then there exists the
Ô¨Ånite limit of rank Bk(Œª) as Œª ‚Üí‚àí‚àû, i.e., (5.336) holds. By a similar way,
condition (5.335) implies that rankXN+1(Œª) = const for all sufÔ¨Åciently small
Œª.
(ii) For the linear Hamiltonian difference system (5.144) condition (5.333) is
automatically satisÔ¨Åed under (5.3). Indeed, according to Example 5.37, con-
dition (5.3) is equivalent to
ÀôHk(Œª) ‚â•0,
Hk(Œª) =
‚àíCk(Œª) AT
k (Œª)
Ak(Œª) Bk(Œª),

,
(5.337)
and then the symmetric matrix Bk(Œª) is nondecreasing matrix function with
respect to Œª. By Weyl‚Äôs inequality, see [270, Corollary 4.9], all eigenvalues
of Bk(Œª) are nondecreasing with respect to Œª. So we have that ind Bk(Œª) and
ind [‚àíBk(Œª)] are nonincreasing and nondecreasing functions of Œª, so that there
exist Ô¨Ånite limits
lim
Œª‚Üí‚àí‚àûind Bk(Œª) < ‚àû,
lim
Œª‚Üí‚àí‚àûind [‚àíBk(Œª)] < ‚àû.
This means that the number of positive and negative eigenvalues of Bk(Œª) is constant
for all Œª < ÀúŒª. Consequently, we obtain that rank Bk(Œª) = rankBk(Œª) = const for
all Œª < ÀúŒª.
Recall now the notation from Sect. 5.1.3
n1(Œª) ‚â§Nn,
n2(Œª) :=

Œº‚â§Œª
Œ∏(Œº)
for the number of forward focal points of the principal solution Y [0](Œª) in (1, N +1]
and for the number of Ô¨Ånite eigenvalues of (E) less than or equal to Œª, and introduce
a similar notation for the step function
nB(Œª) :=

Œº‚â§Œª
N

k=0
œëk(Œº),
(5.338)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
357
where œëk(Œº) is deÔ¨Åned by (5.329). Note that conditions (5.3) and (5.333) imply that
there exists ÀúŒª ‚ààR such that
n2(Œª) ‚â°0,
nB(Œª) ‚â°0,
n1(Œª) ‚â°m
for all Œª < ÀúŒª,
(5.339)
by formula (5.331) and Corollary 5.96. Under assumptions (5.3) and (5.333), the
functions n2(Œª) and nB(Œª) are also right-continuous, i.e.,
n2(Œª) = n2(Œª+),
nB(Œª) = nB(Œª+),
by Theorem 5.3 and Corollary 5.7. From Corollary 5.96 and Theorem 5.95, we then
derive the following generalization of the global oscillation theorem (Theorem 5.17)
for the case when rank Bk(Œª) is not constant.
Theorem 5.98 (Global Oscillation Theorem for rank Bk(Œª) Ã∏= const) Assume
that (5.3) and (5.333) hold. Then there exists m ‚àà[0, nN]Z such that for any Œª ‚ààR,
we have
n2(Œª) + m = n1(Œª) + nB(Œª),
(5.340)
where m is given by (5.339).
Proof The proof follows from (5.332) for b := Œª, where we evaluate the Ô¨Ånite limits
of the quantities n1(a), 
a<Œº‚â§Œª
N
k=0 œëk(Œº), and 
a<Œº‚â§Œª Œ∏(Œº) as a ‚Üí‚àí‚àû
according to (5.339), (5.335), and (5.333).
‚äì‚äî
Note that under the assumption (5.38), we have in (5.340) that nB(Œª) = 0 for Œª ‚àà
R. In this case Theorems 5.95 and 5.98 present the results of Theorems 5.15, 5.16,
and 5.17. However, the same results follow from Theorem 5.95 under the weakened
assumption rank Bk(Œª) = rank Bk(Œª‚àí) for Œª ‚ààR, i.e., the following corollary holds.
Corollary 5.99 Assume (5.3) and suppose that (5.333) holds for all Œª ‚ààR. Then
under the notation of Theorem 5.98, there exists m ‚àà[0, nN]Z such that
n2(Œª) + m = n1(Œª)
for all Œª ‚ààR,
(5.341)
where m is given by (5.339).
The previous version of the global oscillation theorem (Theorem 5.17) implies
that the number n1(Œª) of focal points of Y [0](Œª) in (0, N + 1] is monotonic in
Œª on R. The present version (Theorem 5.98) says that this function in general is
not monotonic, but there exists a representation of the quantity n1(Œª) ‚àím as the
difference n2(Œª) ‚àínB(Œª) of two nondecreasing functions in accordance with the
Jordan decomposition of a function of bounded variation. In the last part of this
subsection, we provide examples illustrating the results stated above.

358
5
Discrete Symplectic Eigenvalue Problems
Example 5.100 This example is devoted to applications of formula (5.332). Con-
sider problem (E) for the trigonometric difference system with
Sk(Œª) =
 cos Œª sin Œª
‚àísin Œª cos Œª

,
k ‚àà[0, N]Z.
(5.342)
According to (5.3), we have (Sk(Œª)) = I > 0, so that the the monotonicity
condition (5.3) holds for Œª ‚ààR. The principal solution Y [0](Œª) of (E) with (5.342)
has the form Y [0]
k (Œª) =

sin(kŒª), cos(kŒª)
T , and then the Ô¨Ånite eigenvalues of this
problem are Œªp = œÄp/(N + 1), p ‚ààZ. The multiplicities of focal points of Y [0](Œª)
in (k, k + 1] are given by
mk(Œª) =
‚éß
‚é™‚é®
‚é™‚é©
1, Œª = œÄp/(k + 1), Œª Ã∏= œÄl, p, l ‚ààZ,
1, sin(Œª) sin(kŒª) sin((k + 1) Œª) < 0,
0, otherwise.
So we see that mk(Œª) = mk(Œª + œÄl) for l ‚ààZ, and then n1(Œª) is periodic with the
minimal period T = œÄ and nondecreasing in any interval [a, b] ‚äÜ[œÄl, œÄ(l + 1)),
l ‚ààZ. For example, for N = 3, we have
n1(Œª) =
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
0, Œª ‚àà[0, œÄ/4),
1, Œª ‚àà[œÄ/4, œÄ/2),
2, Œª ‚àà[œÄ/2, 3œÄ/4),
3, Œª ‚àà[3œÄ/4, œÄ),
n1(Œª) = n1(Œª + œÄl),
l ‚ààZ,
and by (5.332) the quantity n1(b) ‚àín1(a) presents the number of eigenvalues
of (E), (5.342) in (a, b] for œÄl ‚â§a < b < œÄ(l + 1), l ‚ààZ. However, if
b = œÄ(l + 1), then the function n1(Œª) loses the monotonicity, and in accordance
with (5.332), we restore it by adding the total number of zeros of Bk(Œª) = sin(Œª),
k ‚àà[0, 3]Z, in (a, b]. So we have that n1(œÄ(l + 1)) ‚àín1(a) + 4 = 4 ‚àín1(a)
presents the number of eigenvalues of (E), (5.342) in (a, œÄ(l + 1)] for œÄl ‚â§
a ‚â§œÄ(l + 1), l ‚ààZ. Similarly, for the case a = ‚àíœÄ/2, b = 2œÄ, and
N = 3, the number of focal points of Y [0](Œª) equals to n1(2œÄ) = n1(0) = 0,
n1(‚àíœÄ/2) = n1(œÄ/2) = 2, the number of eigenvalues of (E) in (‚àíœÄ/2, 2œÄ] equals
to 10, the sum 
‚àíœÄ/2<Œº‚â§2œÄ
3
k=0 œëk(Œº) = 4 ¬∑ 3 = 12, and (5.332) says that
n1(2œÄ) ‚àín1(‚àíœÄ/2) + 
‚àíœÄ/2<Œº‚â§2œÄ
3
k=0 œëk(Œº) = ‚àí2 + 12 = 10.

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
359
Consider an example illustrating Theorem 5.98.
Example 5.101 Introduce symplectic difference system (E) with
Sk(Œª) =
Œª ‚àík + 1
Œª ‚àík
‚àíŒª + k
1 ‚àíŒª + k

.
Then we have k(Sk(Œª)) =
 1 1
1 1

‚â•0 and condition (5.336) for the coefÔ¨Åcient
Bk(Œª) = Œª ‚àík for k ‚àà[0, N]Z holds for all Œª < ÀúŒª = 0. For this case, problem (E)
has only one Ô¨Ånite eigenvalue for any N. For N = 3, the principal solution at 0 is
Y [0]
0 (Œª) =
0
1

,
Y [0]
1 (Œª) =

Œª
1 ‚àíŒª

,
Y [0]
2 (Œª) =
2Œª ‚àí1
2 ‚àí2Œª

,
Y [0]
3 (Œª) =
3Œª ‚àí3
4 ‚àí3Œª

,
Y [0]
4 (Œª) =
4Œª ‚àí6
7 ‚àí4Œª

.
Then the problem has the unique eigenvalue Œª1 = 3
2. The multiplicities of focal
points for this solution are
m0(Œª) = 0,
m1(Œª) =

1, Œª ‚àà(‚àí‚àû, 0) ‚à™[ 1
2, 1),
0, otherwise,
m2(Œª) =

1, Œª ‚àà(‚àí‚àû, 1
2) ‚à™[1, 2),
0, otherwise,
m3(Œª) =

1, Œª ‚àà(‚àí‚àû, 1) ‚à™[ 3
2, 3),
0, otherwise.
Then the numbers n1(Œª) of focal points in (0, 4] and the function nB(Œª) are
n1(Œª) =
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
3, Œª ‚àà(‚àí‚àû, 0),
2, Œª ‚àà[0, 1) ‚à™[ 3
2, 2),
1, Œª ‚àà[1, 3
2) ‚à™[2, 3)
0, Œª ‚àà[3, ‚àû).
nB(Œª) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, 0),
1, Œª ‚àà[0, 1),
2, Œª ‚àà[1, 2),
3, Œª ‚àà[2, 3),
4, Œª ‚àà[3, ‚àû).
So we see that the constant m in Theorem 5.98 equals to 3. Finally, we have
n1(Œª) ‚àím + nB(Œª) = n2(Œª) =

0, Œª ‚àà(‚àí‚àû, 3
2),
1, Œª ‚àà[ 3
2, ‚àû).

360
5
Discrete Symplectic Eigenvalue Problems
Example 5.102 Consider 4 √ó 4 symplectic system (SDSŒª) for k ‚àà[0, 2]Z with
S0(Œª) = S2(Œª) =
‚éõ
‚éú‚éú‚éù
1
0 0 0
0
0 0 1
‚àíŒª 0 1 0
0 ‚àí1 0 ‚àíŒª
‚éû
‚éü‚éü‚é†,
S1(Œª) =
‚éõ
‚éú‚éú‚éù
1
0
Œª3
0
0
0
0
1
‚àíŒª 0 1 ‚àíŒª4
0
0 ‚àí1
0
‚àíŒª ‚àíŒª3
‚éû
‚éü‚éü‚é†.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(5.343)
Condition (5.3) takes the form (Sk(Œª)) = diag{0, I} ‚â•0 for k ‚àà{0, 2} and
(S1(Œª)) =
‚éõ
‚éú‚éú‚éù
3Œª4
0
3Œª3 0
0 1 + 3Œª2
0 0
3Œª3
0
3Œª2 0
0
0
0 0
‚éû
‚éü‚éü‚é†‚â•0.
The upper blocks of the principal solution Y [0](Œª) are
X[0]
0 (Œª) = 0,
X[0]
1 (Œª) =
0 0
0 1

,
X[0]
2 (Œª) =
Œª3 0
0 ‚àíŒª

,
X[0]
3 (Œª) =
Œª3
0
0 Œª2 + Œª4 ‚àí1

.
Then the Ô¨Ånite eigenvalues of (E), (5.343) are
Œª1 = ‚àí
5
‚àí1 +
‚àö
5
2
,
Œª2 = 0,
Œª3 =
5
‚àí1 +
‚àö
5
2
,
and the multiplicities of focal points of the principal solution Y [0](Œª) are
m0(Œª) = 0,
m1(Œª) =

1, Œª ‚â•0,
0, Œª < 0,
m2(Œª) =

1, Œª (Œª2 + 1‚àí
‚àö
5
2
) ‚â•0 and Œª Ã∏= 0,
0, otherwise.

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
361
Then the function n1(Œª) = m0(Œª) + m1(Œª) + m2(Œª) takes the form
n1(Œª) =
‚éß
‚é™‚é®
‚é™‚é©
0, Œª < Œª1,
1, Œª1 ‚â§Œª < Œª3,
2, Œª3 ‚â§Œª.
So we see that n1(Œª) does not count the eigenvalue Œª2 = 0. By (5.340), we need
to add the function nB(Œª) = 0 for Œª < 0 and nB(Œª) = 1 for Œª ‚â•0 to derive
n2(Œª) = n1(Œª) + nB(Œª) counting all (real) eigenvalues of the problem.
In the last example, we illustrate Corollary 5.99.
Example 5.103 For the illustration of Corollary 5.99, we change the statement of
the problem in Example 5.102 replacing S1(Œª) in (5.343) by the matrix
S1(Œª) =
‚éõ
‚éú‚éú‚éù
1
0 0 0
0
0 0 1
‚àíŒª 0 1 0
0 ‚àí1 0 ‚àíŒª
‚éû
‚éü‚éü‚é†,
for Œª ‚â§0,
S1(Œª) =
‚éõ
‚éú‚éú‚éù
1
0
Œª3
0
0
0
0
1
‚àíŒª 0 1 ‚àíŒª4
0
0 ‚àí1
0
‚àíŒª ‚àíŒª3
‚éû
‚éü‚éü‚é†,
for Œª > 0,
which is continuously differentiable with respect to Œª ‚ààR. Then, the matrices Sk(Œª)
for k ‚àà[0, 2]Z obey condition (5.333) for all Œª ‚ààR. The modiÔ¨Åed principal solution
Y [0](Œª) has the upper blocks
X[0]
0 (Œª) = 0,
X[0]
1 (Œª) =
0 0
0 1

,
X[0]
2 (Œª) =
0 0
0 ‚àíŒª

for Œª ‚â§0,
X[0]
2 (Œª) =
Œª3 0
0 ‚àíŒª

for Œª > 0,
X[0]
3 (Œª) =
0
0
0 Œª2 ‚àí1

for Œª ‚â§0,
X[0]
3 (Œª) =
Œª3
0
0 Œª2 + Œª4 ‚àí1

for Œª > 0.
By DeÔ¨Ånition 5.5, this modiÔ¨Åed problem has the Ô¨Ånite eigenvalues
ÀúŒª1 = ‚àí1,
ÀúŒª2 =
5
‚àí1 +
‚àö
5
2
,
and Œª = 0 is not a Ô¨Ånite eigenvalue anymore. The multiplicities m0(Œª) and m1(Œª)
of focal points for this principal solution are the same as in Example 5.102, while

362
5
Discrete Symplectic Eigenvalue Problems
m2(Œª) is given by
m2(Œª) =

1, Œª ‚àà[‚àí1, 0) ‚à™[ÀúŒª2, ‚àû),
0, otherwise.
Then it follows that m0(Œª) + m1(Œª) + m2(Œª) = n1(Œª) = n2(Œª) in accordance with
Corollary 5.99 (with m = 0).
5.6.2
Monotonicity and the Comparative Index
Since monotonicity condition (5.3) is formulated for the symplectic coefÔ¨Åcient
matrix Sk(Œª), the main purpose of this subsection is to relate (5.3) with the limit
behavior of the comparative index for symplectic matrices introduced in Sect. 3.3.1.
Recall the notation
‚ü®W‚ü©=
X
U

,
X =
I 0
A B

,
U =
0 ‚àíI
C D

,
W =
A B
C D

(5.344)
for arbitrary symplectic matrix W separated into the n√ón blocks A, B, C, D. Basic
properties of the comparative index Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) are given in Lemma 3.21. Recall
that according to the duality principle (see Theorem 3.11 and Remark 3.41), all
identities in Lemma 3.21 hold also for the dual index Œº‚àó(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©). For example,
instead of (v) in Lemma 3.21, we have
Œº‚àó(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº‚àó(W(0 I)T, ÀÜW(0 I)T ) + Œº‚àó(‚ü®ÀÜW ‚àí1W‚ü©, ‚ü®I‚ü©)
= Œº(W ‚àí1(0 I)T, ÀÜW ‚àí1(0 I)T ) + Œº‚àó(‚ü®W ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©).

(5.345)
For the nonsingular case det B Ã∏= 0 and det ÀÜB Ã∏= 0, it follows that det X Ã∏= 0
and det ÀÜX Ã∏= 0 for X and ÀÜX deÔ¨Åned by (5.344), and then according to Sect. 3.3.3
(see (3.81))
Œº(‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©) = Œº‚àó(‚ü®ÀÜW‚ü©, ‚ü®W‚ü©) = ind ( ÀÜQ ‚àíQ),
Q = UX ‚àí1 =
 B‚àí1A ‚àíB‚àí1
‚àíBT ‚àí1 DB‚àí1

,
‚é´
‚é™‚é¨
‚é™‚é≠
(5.346)
with ÀÜQ deÔ¨Åned analogously to Q.
Connections between monotonicity condition (5.3) and the comparative index
theory are based on the following lemma.
Lemma 5.104 Assume that a symplectic matrix W(Œª) is piecewise continuously
differentiable with respect to Œª ‚ààR and obeys (1.201), i.e., (W(Œª)) ‚â•0 for

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
363
all Œª ‚ààR. Then for any Œª0 ‚ààR, there exists Œ¥ = Œ¥(Œª0) > 0 such that for all
a, b ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) with a ‚â§b
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = Œº(W(b) (0 I)T, W(a) (0 I)T ),
Œº‚àó(‚ü®W(a)‚ü©, ‚ü®W(b)‚ü©) = Œº‚àó(W(a) (0 I)T, W(b) (0 I)T ),

(5.347)
and
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = 0
for all a, b ‚àà[Œª0, Œª0 + Œ¥), a ‚â§b,
Œº‚àó(‚ü®W(a)‚ü©, ‚ü®W(b)‚ü©) = 0
for all a, b ‚àà(Œª0 ‚àíŒ¥, Œª0], a ‚â§b.

(5.348)
Proof For (5.347) we Ô¨Åx Œª0 ‚ààR and introduce the symplectic matrix
R =
I G
0 I

,
G := I ‚àíB(Œª0)B‚Ä†(Œª0).
(5.349)
Note that the 2n√ón submatrix [BT (Œª) DT (Œª)]T of W(Œª) obeys condition (3.1), and
then ÀúW(Œª) = R‚àí1W(Œª) =
 ÀúA(Œª) ÀúB(Œª)
ÀúC(Œª) ÀúD(Œª)

has the nonsingular block
ÀúB(Œª) := B(Œª) ‚àíGD(Œª)
for Œª = Œª0; see formula (1.175) in Lemma 1.68. Since det ÀúB(Œª) is continuous
with respect to Œª and det ÀúB(Œª0) Ã∏= 0, there exists Œ¥ = Œ¥(Œª0) > 0 such that
det ÀúB(Œª) Ã∏= 0 for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥). By Lemma 1.77 applied to the case
under the consideration (with P = I), condition (1.202) holds, then we have for all
a, b ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) with a ‚â§b
Œº(‚ü®R‚àí1W(b)‚ü©, ‚ü®R‚àí1W(a)‚ü©) = Œº‚àó(‚ü®R‚àí1W(a)‚ü©, ‚ü®R‚àí1W(b)‚ü©)
= ind [ ÀúQ(a) ‚àíÀúQ(b)] = 0,

,
(5.350)
where ÀúQ(Œª) is deÔ¨Åned via the blocks of ÀúW(Œª) := R‚àí1W(Œª) according to (5.346).
By Lemma 3.21(v),(iii) condition (5.350) implies
Œº(‚ü®W ‚àí1(a)W(b)‚ü©, ‚ü®I‚ü©) = Œº‚àó(‚ü®W ‚àí1(b)W(a)‚ü©, ‚ü®I‚ü©) = 0
for all a, b ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) with a ‚â§b. Then by Lemma 3.21(v) and (5.345),
we derive (5.347). Next we shall prove (5.348). By Lemma 3.21(v),(iv), it follows
from (5.350) that
Œº(R‚àí1W(b) (0 I)T, R‚àí1W(a) (0 I)T ) = Œº‚àó(R‚àí1W(a) (0 I)T, R‚àí1W(b) (0 I)T ) = 0,

364
5
Discrete Symplectic Eigenvalue Problems
where R is given by (5.349). Then, according to Theorem 3.6 and Theorem 3.5(ix),
Œº(W(b) (0 I)T, W(a) (0 I)T ) = Œº(R(R‚àí1W(b)) (0 I)T, R(R‚àí1W(a)) (0 I)T )
= Œº(R‚àí1W(b) (0 I)T, R‚àí1W(a) (0 I)T ) + Œº(W(b) (0 I)T, R(0 I)T )
‚àíŒº(W(a) (0 I)T, R(0 I)T )
= Œº(R‚àí1W(a) (0 I)T, R‚àí1(0 I)T ) ‚àíŒº(R‚àí1W(b) (0 I)T, R‚àí1(0 I)T ).
So we have derived that for all a, b ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) with a ‚â§b
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = Œº(W(b) (0 I)T, W(a) (0 I)T )
= Œº( ÀúW(a) (0 I)T, R‚àí1(0 I)T ) ‚àíŒº( ÀúW(b) (0 I)T, R‚àí1(0 I)T ),

(5.351)
where the matrix ÀúW(Œª) = R‚àí1W(Œª) has the nonsingular block ÀúB(Œª). Evaluating
the Ô¨Årst comparative index on the right-hand side above according to DeÔ¨Ånition 3.1,
we obtain
Œº( ÀúW(Œª) (0 I)T, R‚àí1(0 I)T ) = Œº2( ÀúW(Œª) (0 I)T, R‚àí1(0 I)T )
= ind [‚àíGB(Œª) ÀúB‚àí1(Œª) G].
Since GB(Œª0) = 0 by (5.349), it follows that ind [‚àíGB(Œª0) ÀúB(Œª0)‚àí1G] = 0.
Putting a := Œª0 and b ‚àà[Œª0, Œª0 + Œ¥) in (5.351), we derive
0 ‚â§Œº(‚ü®W(b)‚ü©, ‚ü®W(Œª0)‚ü©) = Œº(W(b) (0 I)T, W(Œª0) (0 I)T )
= Œº( ÀúW(Œª0) (0 I)T, R‚àí1(0 I)T ) ‚àíŒº( ÀúW(b) (0 I)T, R‚àí1(0 I)T )
= ‚àíŒº( ÀúW(b) (0 I)T, R‚àí1(0 I)T ) ‚â§0.
Thus, we have proved
Œº( ÀúW(Œª) (0 I)T, R‚àí1(0 I)T ) = 0
for all Œª ‚àà[Œª0, Œª0 + Œ¥).
(5.352)
Finally, we complete the proof of the Ô¨Årst equality in (5.348) by using (5.352)
and (5.351). The proof of the second equality in (5.348) is similar. Instead of (5.351),
we have for all a, b ‚àà(Œª0 ‚àíŒ¥, Œª0 + Œ¥) with a ‚â§b
Œº‚àó(‚ü®W(a)‚ü©, ‚ü®W(b)‚ü©) = Œº‚àó(W(a) (0 I)T, W(b) (0 I)T )
= Œº‚àó( ÀúW(b) (0 I)T, R‚àí1(0 I)T ) ‚àíŒº‚àó( ÀúW(a) (0 I)T, R‚àí1(0 I)T ),

(5.353)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
365
where Œº‚àó( ÀúW(Œª) (0 I)T, R‚àí1(0 I)T ) = ind [GB(Œª) ÀúB‚àí1(Œª) G]. Then (5.352) is
replaced by
Œº‚àó( ÀúW(Œª) (0 I)T, R‚àí1(0 I)T ) = 0
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
(5.354)
and we complete the proof of (5.348) combining (5.354) and (5.353).
‚äì‚äî
Using Lemma 3.21(iv), we see that conditions (5.348) are equivalent to
Œº‚àó(‚ü®W(a)‚ü©, ‚ü®W(b)‚ü©) = rankB(b) ‚àírankB(a)
for all a, b ‚àà[Œª0, Œª0 + Œ¥), a ‚â§b,
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = rankB(a) ‚àírankB(b)
for all a, b ‚àà(Œª0 ‚àíŒ¥, Œª0], a ‚â§b,
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.355)
where B(Œª) is the block of W(Œª) given by (5.344).
We proved Lemma 5.104 in the local sense, i.e., all results of this lemma hold in
a neighborhood of Œª0. If we add the assumption
rankB(Œª) is constant for Œª ‚ààR,
(5.356)
then we can reformulate Lemma 5.104 in the global sense.
Lemma 5.105 Under the assumptions of Lemma 5.104 suppose additionally
that (5.356) holds. Then for all a, b ‚ààR with a ‚â§b
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = Œº‚àó(‚ü®W(a)‚ü©, ‚ü®W(b)‚ü©) = 0.
(5.357)
Proof First of all, let us recall that under assumption (1.201), condition (5.356) is
equivalent to
the set Im B(Œª) is constant for Œª ‚ààR
or
B(Œª) B‚Ä†(Œª) is constant in Œª ‚ààR;
(5.358)
see Theorem 1.82 and Corollary 1.83. Then one can prove (5.357) repeating
the main steps of the proof of Lemma 5.104 applied in the global sense under
assumption (5.356). We note that the same result follows also from Lemma 5.104 by
the ‚Äútriangle inequality‚Äù (see Theorem 3.8) applied to the matrices ‚ü®W(a)‚ü©, ‚ü®W(b)‚ü©,
‚ü®W(c)‚ü©for a ‚â§b ‚â§c. Indeed, by (5.348), we have
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = 0,
a, b ‚àà[Œª0, Œª0 + Œ¥), a ‚â§b,

366
5
Discrete Symplectic Eigenvalue Problems
while from the second equality in (5.355) and (5.356), we get
Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = 0,
a, b ‚àà(Œª0 + Œ¥, Œª0], a ‚â§b.
Applying inequality (3.18), we derive that Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = 0 holds for
all a, b ‚àà(Œª0 + Œ¥, Œª0 + Œ¥) with a ‚â§b. By a similar way, we obtain that
Œº(‚ü®W(c)‚ü©, ‚ü®W(b)‚ü©) = 0 and Œº(‚ü®W(b)‚ü©, ‚ü®W(a)‚ü©) = 0 imply Œº(‚ü®W(c)‚ü©, ‚ü®W(a)‚ü©) =
0 for any a ‚â§b ‚â§c.
‚äì‚äî
Equalities (5.348) and (5.355) imply the main theorem of this section.
Theorem 5.106 Assume (5.3) and suppose that Z(Œª) is a symplectic fundamental
matrix of (SDSŒª) satisfying (5.11) for k = 0. Then for any Œª0 ‚ààR, there exist the
Ô¨Ånite limits
Œº

‚ü®Sk(Œª+
0 )‚ü©, ‚ü®Sk(Œª0)‚ü©

= 0,
Œº‚ü®Sk(Œª0)‚ü©, ‚ü®Sk(Œª‚àí
0 )‚ü© = œëk(Œª0),

k ‚àà[0, N]Z,
(5.359)
Œº

‚ü®Zk(Œª+
0 )‚ü©, ‚ü®Zk(Œª0)‚ü©

= 0,
Œº

‚ü®Zk(Œª0)‚ü©, ‚ü®Zk(Œª‚àí
0 )‚ü©

= rankXk(Œª‚àí
0 ) ‚àírankXk(Œª0),

k ‚àà[0, N + 1]Z,
(5.360)
where Y T
k (Œª)
=
(XT
k (Œª), UT
k (Œª))T
=
Zk(Œª) (0 I)T , and œëk(Œª0) are given
by (5.329). In particular, for Z0(Œª) = I, we have
Œº

‚ü®ZN+1(Œª+
0 )‚ü©, ‚ü®ZN+1(Œª0)‚ü©

= 0,
Œº

‚ü®ZN+1(Œª0)‚ü©, ‚ü®ZN+1(Œª‚àí
0 )‚ü©

= Œ∏(Œª0),

(5.361)
where Œ∏(Œª0) is the (algebraic) multiplicity of the Ô¨Ånite eigenvalue Œª0 of (E).
Proof Recall that (5.3) and (5.11) for k = 0 imply (5.11) for k ‚àà[0, N]Z (see
Sect. 5.1.1). Then Sk(Œª) and Zk(Œª) meet all requirements of Lemma 5.104. The
existence of the limits Œº(‚ü®Sk(Œª+
0 )‚ü©, ‚ü®Sk(Œª0)‚ü©) = 0 and Œº(‚ü®Zk(Œª+
0 )‚ü©, ‚ü®Zk(Œª0)‚ü©) = 0
follows directly from (5.348) with a := Œª0, where we put W(Œª) := Sk(Œª) and
W(Œª) := Zk(Œª). The existence of the limits rank Bk(Œª‚àí
0 ) and rank Xk(Œª‚àí
0 ) follows
from Theorems 5.1 and 5.3, but we can also prove this fact independently by using
Lemma 5.104. Indeed, for the case a ‚â§b < Œª0, we have by the second equality
in (5.355) that rank Bk(Œª) and rank Xk(Œª) are nonincreasing with respect to Œª ‚àà
(Œª0 ‚àíŒ¥, Œª0), and then there exist the Ô¨Ånite limits rank Bk(Œª‚àí
0 ) and rank Xk(Œª‚àí
0 ), i.e.,
there exists ÀúŒ¥ ‚àà(0, Œ¥] such that
rankBk(Œª) ‚â°rankBk(Œª‚àí
0 ),
rank Xk(Œª) ‚â°rankXk(Œª‚àí
0 ),

for all Œª ‚àà(Œª0 ‚àíÀúŒ¥, Œª0).
(5.362)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
367
By using the second equality in (5.355), putting W(Œª) := Sk(Œª) with b := Œª0, we
derive the second equality in (5.359). By a similar way, putting W(Œª) := Zk(Œª), we
then complete the proof of (5.360).
‚äì‚äî
Remark 5.107
(i) We remark that the comparative index theory provides another proof of
Theorem 1.81 (or Theorems 5.1(ii) and 5.3(ii)) under assumption (1.201). For
example, applying (5.362) and the second equalities in (5.355) and (5.348), we
see that there exists ÀúŒ¥ > 0 such that
Œº

‚ü®Sk(b)‚ü©, ‚ü®Sk(a)‚ü©

= 0
for all a, b ‚àà(Œª0 ‚àíÀúŒ¥, Œª0), a ‚â§b,
Œº‚àó
‚ü®Sk(a)‚ü©, ‚ü®Sk(b)‚ü©

= 0
for all a, b ‚àà(Œª0 ‚àíÀúŒ¥, Œª0], a ‚â§b.

(5.363)
Then by Lemma 3.21(v) and (5.345), we obtain
Œº1(Sk(b) (0 I)T, Sk(a) (0 I)T ) = 0
for all a, b ‚àà(Œª0 ‚àíÀúŒ¥, Œª0), a ‚â§b,
Œº‚àó
1(Sk(a) (0 I)T, Sk(b) (0 I)T ) = Œº1(Sk(a) (0 I)T, Sk(b) (0 I)T ) = 0
for all a, b ‚àà(Œª0 ‚àíÀúŒ¥, Œª0], a ‚â§b.
By Theorem 3.2(iv), the last conditions are equivalent to (5.6) in Theo-
rem 5.1(ii). The case (5.7) can be derived similarly.
(ii) Analogously, Lemma 5.104 provides an alternative proof of Theorem 1.79
(or Theorems 5.1(i) 5.3(i)). In more details, by Lemma 3.21(v) and (5.345),
conditions (5.363) imply
Œº‚àó
1(S‚àí1
k (b) (0 I)T, S‚àí1
k (a) (0 I)T ) = Œº1(S‚àí1
k (b) (0 I)T, S‚àí1
k (a) (0 I)T ) = 0
for all a, b ‚àà(Œª0 ‚àíÀúŒ¥, Œª0), a ‚â§b,
Œº1(S‚àí1
k (a) (0 I)T, S‚àí1
k (b) (0 I)T ) = 0
for all a, b ‚àà(Œª0 ‚àíÀúŒ¥, Œª0], a ‚â§b.
Then by Theorem 3.2(iv), we derive (5.4) in Theorem 5.1(i) (i.e., condi-
tion (5.327)). By a similar way, conditions (5.13) can be derived. By analogy
with the previous proof, we can also show that (5.328) and (5.14) follow from
the Ô¨Årst equalities in (5.355) and (5.348).
(iii) Note that Lemma 5.104 allows to count the jumps of rank Bk(Œª) and
rankXk(Œª) in the right neighborhood of Œª0. By analogy with the proof of
Theorem 5.106, we can show that there exist the Ô¨Ånite limits
Œº‚àó
‚ü®Sk(Œª0)‚ü©, ‚ü®Sk(Œª+
0 )‚ü©

= rank Bk(Œª+
0 ) ‚àírank Bk(Œª0),
Œº‚àó
‚ü®Sk(Œª‚àí
0 )‚ü©, ‚ü®Sk(Œª0)‚ü©

= 0,

k ‚àà[0, N]Z,
Œº‚àó
‚ü®Zk(Œª0)‚ü©, ‚ü®Zk(Œª+
0 )‚ü©

= rank Xk(Œª+
0 ) ‚àírank Xk(Œª0),
Œº‚àó
‚ü®Zk(Œª‚àí
0 )‚ü©, ‚ü®Zk(Œª0)‚ü©

= 0,

k ‚àà[0, N + 1]Z.

368
5
Discrete Symplectic Eigenvalue Problems
5.6.3
Monotonicity and the Cayley Transform
In this section we investigate oscillatory properties of the following 4n √ó 4n
symplectic system
Yk+1 = W c
k (Œª) Yk,
k ‚àà[0, N]Z,
W c
k (Œª) = 1
2

I + W T ‚àí1
k
(Œª)
J [I ‚àíWk(Œª)]
‚àíJ [I ‚àíW T ‚àí1
k
(Œª)]
I + Wk(Œª)

‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(5.364)
associated with the 2n √ó 2n symplectic difference system
Yk+1 = Wk(Œª) Yk,
k ‚àà[0, N]Z,
(5.365)
with the symplectic matrix Wk(Œª) satisfying the monotonicity condition (1.201).
We will call (5.364) the Cayley system associated with (5.365). Motivation for this
terminology is the following. Assume additionally that
det [I + Wk(Œª)] Ã∏= 0.
(5.366)
Then the Cayley transform of Wk(Œª) is deÔ¨Åned as
C(Wk(Œª)) := [I ‚àíWk(Œª)] [I + Wk(Œª)]‚àí1,
(5.367)
and the matrix J C(Wk(Œª)) is symmetric (see [326, Lemma 1.1]). Then, if we
introduce the notation
W c
k (Œª) =
Ak(Œª) Bk(Œª)
Ck(Œª) Dk(Œª)

,
(5.368)
for the blocks of the coefÔ¨Åcient matrix in (5.364), then the symmetric matrices
A‚àí1
k (Œª) Bk(Œª),
Ck(Œª) A‚àí1
k (Œª),
Bk(Œª) D‚àí1
k (Œª),
D‚àí1
k (Œª) Ck(Œª)
are connected with the Cayley transforms of the matrices W ‚àí1
k
(Œª), W T ‚àí1
k
(Œª),
Wk(Œª), W T
k (Œª) by the formulas
A‚àí1
k (Œª) Bk(Œª) = ‚àíJ C(W ‚àí1
k
(Œª)), Ck(Œª) A‚àí1
k (Œª) = ‚àíJ C(W ‚àí1 T
k
(Œª)),
Bk(Œª) D‚àí1
k (Œª) = J C(Wk(Œª)),
D‚àí1
k (Œª) Ck(Œª) = J C(W T
k (Œª)).

(5.369)
System (5.364) is taken into consideration by a modiÔ¨Åed version of Theo-
rem 4.45, which is the basic tool for the proof of Theorem 5.95. For that proof,
we will need the following equivalent form of formulas (4.111) and (4.109)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
369
in Theorem 4.45 regarding the multiplicities of focal points of conjoined bases
of (4.98) and (SDS).
Proposition 5.108 (Sturmian Comparison Theorem) Equality (4.111) in Theo-
rem 4.45 can be written as
m( ÀÜYk) ‚àím(Yk) + Œº(‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©)
= Œº(‚ü®ÀÜZk‚ü©, ‚ü®Zk‚ü©) + Œº(R‚àí1‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, R‚àí1‚ü®Z‚àí1
k
ÀÜZk‚ü©),

(5.370)
where the symplectic orthogonal 4n √ó 4n matrix R is given by
R =
1
‚àö
2
‚éõ
‚éú‚éú‚éù
0 ‚àíI I
0
0
I
I
0
‚àíI
0 0 ‚àíI
‚àíI
0 0 I
‚éû
‚éü‚éü‚é†
(5.371)
and the comparative index
Œº

R‚àí1‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, R‚àí1‚ü®Z‚àí1
k
ÀÜZk‚ü©

= Œº‚àó
R‚àí1‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, R‚àí1‚ü®ÀÜZ‚àí1
k Zk‚ü©

(5.372)
is equal to the number of forward focal points in (k, k + 1] of the conjoined basis
Yk = R‚àí1‚ü®Z‚àí1
k
ÀÜZk‚ü©of the Cayley system
Yk+1 = W c
k Yk,
k ‚àà[0, N]Z,
with Wk := Z‚àí1
k+1 ÀÜSkZk.
The proof of Proposition 5.108 is given in Sect. 5.6.4. Point out that we will
apply (5.370) to the case Sk := Sk(Œª0) and ÀÜSk := Sk(Œª), where Œª belongs
to a neighborhood of Œª0. Then we have to investigate the oscillatory properties
of (5.364) under the monotonicity condition (1.201).
Lemma 5.109 Let W(Œª) ‚ààR2n√ó2n be a continuously differentiable symplectic
matrix. Then condition (1.201) is equivalent to
(W c(Œª)) = J4n d
dŒª [W c(Œª)] J4n [W c(Œª)]TJ4n ‚â•0,
where J4n ‚ààR4n√ó4n and W c(Œª) is given by (5.364). Moreover, if we assume that
Wk(Œª) obeys (5.366) for k ‚àà[0, N]Z, then each of the following conditions for the
blocks in (5.368)
d
dŒª [A‚àí1
k (Œª) Bk(Œª)] ‚â•0,
(5.373)
d
dŒª [Ck(Œª) A‚àí1
k (Œª)] ‚â§0,
(5.374)

370
5
Discrete Symplectic Eigenvalue Problems
d
dŒª [Bk(Œª) D‚àí1
k (Œª)] ‚â•0,
(5.375)
d
dŒª [D‚àí1
k (Œª) Ck(Œª)] ‚â§0
(5.376)
is equivalent to (1.201) for W(Œª) := Wk(Œª).
Proof For the proof of the Ô¨Årst claim, we use the following representation:
W c = R‚àí1{I, W} R,
{I, W} =
‚éõ
‚éú‚éú‚éù
I 0 0 0
0 A 0 B
0 0 I 0
0 C 0 D
‚éû
‚éü‚éü‚é†,
W =
A B
C D

,
(5.377)
where R is given by (5.371). Moreover, the matrix {I, W} is symplectic if and only
if so is W (see Sect. 3.3.5 for more details). Formula (5.377) justiÔ¨Åes the symplectic
structure of the matrices W c
k (Œª) in (5.364) and the construction of conjoined bases
of (5.364) in the subsequent proofs (see Lemma 5.110). Applying (5.377), we have
(W c(Œª)) = RT ({I, W(Œª)}) R = RT {0, (W(Œª))} R,
where the 4n √ó 4n matrix {0, (W(Œª))} is symmetric and nonnegative if and only
if so is (W(Œª)). The proof of the Ô¨Årst claim is completed. Next, it is easy to verify
that
d
dŒª
1
2 J C(W(Œª))

= [I + W(Œª)]T ‚àí1W T (Œª) (W(Œª)) W(Œª) [I + W(Œª)]‚àí1,
and then condition (1.201) for Wk(Œª) is equivalent to
d
dŒª

J C(Wk(Œª))

‚â•0.
(5.378)
Moreover, using the representations (see Proposition 1.76(ii)), we get
(W ‚àí1(Œª)) = ‚àíW T (Œª) (W(Œª)) W(Œª),
(W T ‚àí1(Œª)) = (J W(Œª) J T ) = J (W(Œª)) J T ,
and (W T (Œª)) = (J W ‚àí1(Œª) J T ) = J (W ‚àí1(Œª)) J T . Thus, we see that
equation (1.201) holds if and only if (see Proposition 1.76 (iv))
(W ‚àí1(Œª)) ‚â§0,
(W ‚àí1 T (Œª)) ‚â•0,
(W T (Œª)) ‚â§0.

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
371
So we also have that (1.201) for Wk(Œª) is equivalent to each of the inequalities
d
dŒª [J C(W ‚àí1
k
(Œª)] ‚â§0,
d
dŒª [J C(W T ‚àí1
k
(Œª)] ‚â•0,
d
dŒª [J C(W T
k (Œª)] ‚â§0.

(5.379)
Using (5.369), (5.378), and (5.379), we then complete the proof of the second claim.
‚äì‚äî
Recall that we will apply the results of this section to the special case of sys-
tem (5.364) with Wk(Œª) := Z‚àí1
k+1(Œª0) Sk(Œª) Zk(Œª0), where Z‚àí1(Œª) is a fundamental
matrix of (SDSŒª). In this case obviously Wk(Œª0) = I. In this connection, we prove
the following lemma.
Lemma 5.110 Assume that a symplectic matrix Wk(Œª) is continuously differen-
tiable and (1.201) holds for W(Œª) := Wk(Œª) for k ‚àà[0, N]Z. Suppose that for
some Œª0 ‚ààR
Wk(Œª0) = I,
k ‚àà[0, N]Z.
(5.380)
Then there exists Œ¥ > 0 such that the principal solution Yk(Œª) at 0 of the Cayley
system (5.364) does not have any forward focal points in the interval (0, N + 1] for
all Œª ‚àà[Œª0, Œª0 + Œ¥), i.e.,
m(Yk(Œª)) = Œº

Yk+1(Œª), W c
k (Œª) (0 I)T 
= 0,
k ‚àà[0, N]Z.
(5.381)
Similarly, there exists Œ¥ > 0 such that for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0]
Œº‚àó
Yk+1(Œª), W c
k (Œª) (0 I)T 
= 0,
k ‚àà[0, N]Z.
(5.382)
Proof Note Ô¨Årst that (5.380) implies that there exists ÀÜŒ¥ > 0 such that (5.366) holds
for all Œª ‚àà(Œª0‚àíÀÜŒ¥, Œª0+ÀÜŒ¥), i.e., the continuous matrices I+Wk(Œª) = 2I+[Wk(Œª)‚àíI]
are nonsingular for k ‚àà[0, N]. Then condition (1.201) implies (5.373) and (5.374)
for the blocks of W c
k (Œª). Moreover, by (5.380), we have A‚àí1
k (Œª0) Bk(Œª0) =
Ck(Œª0) A‚àí1
k (Œª0) = 0, and then we get
A‚àí1
k (Œª) Bk(Œª) ‚â•0,
Ck(Œª) A‚àí1
k (Œª) ‚â§0,
Œª ‚àà[Œª0, Œª0 + ÀÜŒ¥),
(5.383)
A‚àí1
k (Œª) Bk(Œª) ‚â§0,
Ck(Œª) A‚àí1
k (Œª) ‚â•0,
Œª ‚àà(Œª0 ‚àíÀÜŒ¥, Œª0].
(5.384)
Secondly, point out that the principal solution at 0 of system (5.364) has the form
Yk(Œª) =
Xk(Œª)
Uk(Œª)

= Zc
k(Œª) (0 I)T = 1
2
J [I ‚àíZk(Œª)]
I + Zk(Œª)

,
Z0(Œª) = I,
(5.385)

372
5
Discrete Symplectic Eigenvalue Problems
where the symplectic 2n√ó2n matrix Zk(Œª) solves (5.365). Then (5.11) holds for all
k ‚àà[0, N + 1]Z (see Proposition 5.2). Condition (5.380) implies that Zk(Œª0) = I
for k ‚àà[0, N +1]Z, and then the continuous matrices I +Zk(Œª) = 2I +[Zk(Œª)‚àíI]
for k ‚àà[0, N + 1]Z are nonsingular in a sufÔ¨Åciently small neighborhood of Œª0.
Then, applying Lemma 5.109 for the case W(Œª) := Zk(Œª), we see by (5.375) that
d
dŒª [Xk(Œª) U‚àí1
k (Œª)] ‚â•0 and Xk(Œª0) U‚àí1
k (Œª0) = 0. Then we can conclude that there
exists ÀúŒ¥ > 0 such that
Xk(Œª) U‚àí1
k (Œª) ‚â•0
for all Œª ‚àà[Œª0, Œª0 + ÀúŒ¥),
(5.386)
Xk(Œª) U‚àí1
k (Œª) ‚â§0
for all Œª ‚àà(Œª0 ‚àíÀúŒ¥, Œª0].
(5.387)
Finally, we prove (5.381) and (5.382) by using relations which connect the number
of focal points of Yk(Œª) and the transformed conjoined basis J T
4n Yk(Œª), which has
the nonsingular upper block ‚àíUk(Œª), Œª ‚àà(Œª0 ‚àíÀúŒ¥, Œª0 + ÀúŒ¥), given by (5.385). By
Corollary 4.66 (see (4.183)), we have
m(J T
4n Yk(Œª)) ‚àím(Yk(Œª)) ‚àíŒº

J T
4n Yk(Œª), J T
4n (0 I)T 
= ind [‚àíAT
k (Œª) Ck(Œª)] ‚àíind [Ak(Œª) BT
k (Œª)],
Œº(J T
4n Yk(Œª), J T
4n (0 I)T ) = ind [X T
k (Œª) Uk(Œª)].
‚é´
‚é™‚é¨
‚é™‚é≠
(5.388)
By (5.386) and (5.383), we have m(J T
4n Yk(Œª)) = m(Yk(Œª)) for all Œª ‚àà[Œª0, Œª0 +Œ¥),
where Œ¥ := min(ÀÜŒ¥, ÀúŒ¥). Moreover, m(J T
4n Yk(Œª)) = ind Pk(Œª), where
Pk(Œª) = ‚àíUk(Œª) U‚àí1
k+1(Œª) Ck(Œª) = ‚àíAT
k (Œª) Ck(Œª) + CT
k (Œª) Xk+1(Œª) U‚àí1
k+1(Œª) Ck(Œª)
and Pk(Œª0) = 0. Then, by (5.386) and (5.383), we obtain
Pk(Œª) = ‚àíUk(Œª) U‚àí1
k+1(Œª) Ck(Œª) ‚â•0
for all Œª ‚àà[Œª0, Œª0 + Œ¥),
(5.389)
Pk(Œª) = ‚àíUk(Œª) U‚àí1
k+1(Œª) Ck(Œª) ‚â§0
for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0].
(5.390)
So we complete the proof of (5.381) using (5.389), which implies that m(Yk) =
m(J T
4n Yk) = ind Pk(Œª) = 0 for Œª ‚àà[Œª0, Œª0 + Œ¥). For the proof of (5.382), we use
instead of (5.388) the dual identity (see Theorem 3.11)
Œº‚àó
Yk+1(Œª), W c
k (Œª) (0 I)T 
‚àíind [‚àíPk(Œª)] ‚àíŒº‚àó
J T
4n Yk(Œª), J T
4n (0 I)T )
= ind [AT
k (Œª) Ck(Œª)] ‚àíind [‚àíAk(Œª) BT
k (Œª)],
Œº‚àó(J T
4n Yk(Œª), J T
4n (0 I)T ) = ind [‚àíX T
k (Œª) Uk(Œª)],
‚é´
‚é™‚é¨
‚é™‚é≠
which implies that Œº‚àó(Yk+1(Œª), W c
k (Œª) (0 I)T ) = 0 for all Œª ‚àà(Œª0 ‚àíŒ¥, Œª0] due
to (5.390), (5.387), and (5.384). The proof is complete.
‚äì‚äî

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
373
5.6.4
Proofs of the Main Results
In this section we provide the rather technical proof of Proposition 5.108 (see
Sect. 5.6.3) and the proof of the local oscillation theorem (Theorem 5.95).
Proof of Proposition 5.108 For the proof of (5.370), we apply the main properties
of the comparative index presented in Chap. 3. Note Ô¨Årst that with R deÔ¨Åned
by (5.371), we have R (02n I2n)T = (1/
‚àö
2) ‚ü®I2n‚ü©(see notation (5.344)), where
the constant
‚àö
2 can be omitted in computations using Theorem 3.5(i). Applying
the properties of the comparative index, we have by Theorem 3.5(v)
Œº(Yk, ÀÜYk) =  rankw(Yk, ÀÜYk) ‚àíŒº( ÀÜYk, Yk),
and by Lemma 3.21(iv)
Œº

‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©

= Œº‚àó
‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©

+  rankw(Yk, ÀÜYk),
where w(Yk, ÀÜYk) is the Wronskian given by (3.2). Here we also use the calculation
(I 0) ÀÜZ‚àí1
k Zk(0 I)T = wT (Yk, ÀÜYk) (see (4.100)). After substituting the last two
formulas into (4.111) and (4.109) in Theorem 4.45, we derive
m( ÀÜYk) ‚àím(Yk) +Œº

‚ü®ÀÜSk‚ü©, ‚ü®Sk‚ü©

= Œº( ÀÜYk, Yk) + Œº‚àó
‚ü®ÀÜZ‚àí1
k Zk‚ü©, ‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©

.

(5.391)
Now we apply the transformations in Lemma 3.21(v) to get
Œº( ÀÜYk, Yk) = Œº

‚ü®ÀÜZk‚ü©, ‚ü®Zk‚ü©

‚àíŒº

‚ü®Z‚àí1
k
ÀÜZk‚ü©, ‚ü®I‚ü©

,
in Lemma 3.21(iii) to get
Œº‚àó
‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, ‚ü®ÀÜZ‚àí1
k Zk‚ü©

= Œº

‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, ‚ü®Z‚àí1
k
ÀÜZk‚ü©

,
and in Theorem 3.6 to get
Œº

‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, ‚ü®Z‚àí1
k
ÀÜZk‚ü©

= Œº

R(R‚àí1‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©), R(R‚àí1‚ü®Z‚àí1
k
ÀÜZk‚ü©)

= ŒºR‚àí1‚ü®Z‚àí1
k+1 ÀÜZk+1‚ü©, R‚àí1‚ü®Z‚àí1
k
ÀÜZk‚ü© + Œº‚ü®Z‚àí1
k
ÀÜZk‚ü©, ‚ü®I‚ü©.
A subsequent substitution all the formulas derived above into (5.391) leads to the
proof of (5.370). Next, identity (5.372) follows from the relation
Œº

R‚àí1‚ü®W‚ü©, R‚àí1‚ü®ÀÜW‚ü©

= Œº‚àó
R‚àí1‚ü®W ‚àí1‚ü©, R‚àí1‚ü®ÀÜW ‚àí1‚ü©

,
(5.392)

374
5
Discrete Symplectic Eigenvalue Problems
which is similar to identity (iii) in Lemma 3.21. Consider the proof of (5.392).
Applying Theorem 3.6, we have
Œº

R‚àí1‚ü®W‚ü©, R‚àí1‚ü®ÀÜW‚ü©

= Œº

‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©

+ Œº

‚ü®ÀÜW‚ü©, ‚ü®I‚ü©

‚àíŒº

‚ü®W‚ü©, ‚ü®I‚ü©

,
where by Lemma 3.21(iii)
Œº

‚ü®W‚ü©, ‚ü®ÀÜW ‚ü©

= Œº‚àó
‚ü®W ‚àí1‚ü©, ‚ü®ÀÜW ‚àí1‚ü©

,
Œº

‚ü®ÀÜW‚ü©, ‚ü®I‚ü©

= Œº‚àó
‚ü®ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©

,
Œº

‚ü®W‚ü©, ‚ü®I‚ü©

= Œº‚àó
‚ü®ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©

.
Then
Œº

R‚àí1‚ü®W‚ü©, R‚àí1‚ü®ÀÜW‚ü©

= Œº‚àó
‚ü®W ‚àí1‚ü©, ‚ü®ÀÜW ‚àí1‚ü©

+ Œº‚àó
‚ü®ÀÜW ‚àí1‚ü©, ‚ü®I‚ü©

‚àíŒº‚àó
‚ü®W ‚àí1‚ü©, ‚ü®I‚ü©

= Œº‚àóR‚àí1‚ü®W ‚àí1‚ü©, R‚àí1‚ü®ÀÜW ‚àí1‚ü©
by the dual version of Theorem 3.6 (see Corollary 3.12). The proof of (5.392)
and (5.372) is completed. Finally, note that by Lemma 4.7, the comparative index
Œº‚àóR‚àí1‚ü®ÀÜZ‚àí1
k+1Zk+1‚ü©, R‚àí1‚ü®ÀÜZ‚àí1
k Zk‚ü©
is equal to the number of forward focal points in (k, k + 1] of the conjoined basis
Yk = R‚àí1‚ü®Z‚àí1
k
ÀÜZk‚ü©= Zk(0 I)T associated with the fundamental matrix
Zk =
‚àö
2 R‚àí1 {I, Z‚àí1
k
ÀÜZk} R
(see notation (5.377)). It is easy to verify directly that Zk solves the Cayley system
Yk+1 = W c
k Yk,
k ‚àà[0, N]Z,
with Wk := Z‚àí1
k+1 ÀÜSkZk.
The proof of Proposition 5.108 is complete.
‚äì‚äî
Proof of Theorem 5.95 Fix any Œª0 ‚ààR, and apply (5.370) to the case
ÀÜSk := Sk(Œª),
Sk := Sk(Œª0),
ÀÜZk := Zk(Œª),
Zk := Zk(Œª0),
Œª ‚â•Œª0,
where we assume that symplectic fundamental matrix Zk(Œª) does not depend on Œª
for k = 0, i.e., ÀÜZ0 = Z0. Using the notation m(Yk(Œª)) = mk(Œª), where Yk(Œª) =
Zk(Œª) (0 I)T , we have
mk(Œª) ‚àímk(Œª0) + Œº

‚ü®Sk(Œª)‚ü©, ‚ü®Sk(Œª0)‚ü©

= Œº

‚ü®Zk(Œª)‚ü©, ‚ü®Zk(Œª0)‚ü©

+Œº‚àó
R‚àí1‚ü®Z‚àí1
k+1(Œª)Zk+1(Œª0)‚ü©, R‚àí1‚ü®Z‚àí1
k (Œª)Zk(Œª0)‚ü©

,
‚é´
‚é™‚é¨
‚é™‚é≠
(5.393)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
375
where we rewrite the last term according to (5.372). By (5.359) and (5.360) in
Theorem 5.106, we evaluate the right-hand limits
Œº

‚ü®Sk(Œª+
0 )‚ü©, ‚ü®Sk(Œª0)‚ü©

= Œº

‚ü®Zk(Œª+
0 )‚ü©, ‚ü®Zk(Œª0)‚ü©

= 0.
According to Lemma 4.7, the last term in (5.393) is equal to the number of forward
focal points in (k, k + 1] of the conjoined basis
Yk(Œª) = R‚àí1‚ü®Z‚àí1
k (Œª0)Zk(Œª)‚ü©
(5.394)
of the Cayley system (5.364) with the matrix
Wk(Œª) := Z‚àí1
k+1(Œª0) Sk(Œª) Zk(Œª0).
(5.395)
Note that the matrices Zk(Œª0) and Zk+1(Œª0) in (5.395) are constant for the Ô¨Åxed
Œª0, and then (Wk(Œª)) = ZT
k+1(Œª0) (Sk(Œª)) Zk+1(Œª0) ‚â•0 and Wk(Œª0) = I.
Applying (5.381) in Lemma 5.110 and Theorem 3.5(i), we then obtain
Œº‚àóR‚àí1‚ü®Z‚àí1
k+1(Œª+
0 )Zk+1(Œª0)‚ü©, R‚àí1‚ü®Z‚àí1
k (Œª+
0 )Zk(Œª0)‚ü©
= m(Yk(Œª+
0 )) = Œº

Yk(Œª+
0 ), W c
k (Œª+
0 ) (0 I)T 
= 0,
where Yk(Œª) and Wk(Œª) are given by (5.394) and (5.395). Substituting all the limits
derived above into (5.393), we conclude that there exists the Ô¨Ånite limit
mk(Œª+
0 ) = mk(Œª0).
Next, applying (5.370) to the case
ÀÜSk := Sk(Œª0), Sk := Sk(Œª),
ÀÜZk := Zk(Œª0), Zk := Zk(Œª),
ÀÜZ0 = Z0, Œª < Œª0,
we derive
mk(Œª0) ‚àímk(Œª) + Œº

‚ü®Sk(Œª0)‚ü©, ‚ü®Sk(Œª)‚ü©

= Œº

‚ü®Zk(Œª0)‚ü©, ‚ü®Zk(Œª)‚ü©

+Œº

R‚àí1‚ü®Z‚àí1
k+1(Œª)Zk+1(Œª0)‚ü©, R‚àí1‚ü®Z‚àí1
k (Œª)Zk(Œª0)‚ü©

.
‚é´
‚é™‚é¨
‚é™‚é≠
(5.396)
Then we evaluate the left-hand limits
Œº

‚ü®Sk(Œª0)‚ü©, ‚ü®Sk(Œª‚àí
0 )‚ü©

= œëk(Œª0),
Œº

‚ü®Zk(Œª0)‚ü©, ‚ü®Zk(Œª‚àí
0 )‚ü©

=  [rankXk(Œª‚àí
0 ) ‚àírankXk(Œª0)],

376
5
Discrete Symplectic Eigenvalue Problems
according to (5.359) and (5.360) in Theorem 5.106. Note that the last term in (5.396)
is dual to the last term in (5.393), i.e.,
Œº

R‚àí1‚ü®Z‚àí1
k+1(Œª)Zk+1(Œª0)‚ü©, R‚àí1‚ü®Z‚àí1
k (Œª)Zk(Œª0)‚ü©

= Œº‚àó
Yk+1(Œª), W c
k (Œª) (0 I)T 
,
where Yk(Œª) and Wk(Œª) are given by (5.394) and (5.395). Then, by (5.382) the left-
hand limit of this quantity equals to zero, and we derive from (5.396) that
mk(Œª0) ‚àímk(Œª‚àí
0 ) + œëk(Œª0) =  [rankXk(Œª‚àí
0 ) ‚àírankXk(Œª0)].
The proof of (5.330) is completed. Upon summing equality (5.330) for k ‚àà[0, N]Z,
we get (5.331). The proof of Theorem 5.95 is complete.
‚äì‚äî
5.6.5
Weighted Focal Points
In this section we consider the discrete Hamiltonian eigenvalue problems (5.144)
presented in Example 5.37, i.e.,
xk(Œª) = Ak(Œª) xk+1(Œª) + Bk(Œª) uk(Œª),
uk(Œª) = Ck(Œª) xk+1(Œª) ‚àíAT
k (Œª) uk(Œª),

k ‚àà[0, N]Z,
with the Dirichlet boundary conditions
x0(Œª) = 0 = xN+1(Œª),
(5.397)
where the coefÔ¨Åcients Ak, Bk, Ck
: R ‚ÜíRn√ón are piecewise continuously
differentiable in Œª, Bk(Œª) and Ck(Œª) are symmetric, and I ‚àíAk(Œª) is invertible
with ÀúAk(Œª) := [I ‚àíAk(Œª)]‚àí1. The symmetric Hamiltonian Hk(Œª) is deÔ¨Åned by
Hk(Œª) :=
‚àíCk(Œª) AT
k (Œª)
Ak(Œª) Bk(Œª)

and it obeys the monotonicity condition (5.337), i.e.,
ÀôHk(Œª) ‚â•0,
Œª ‚ààR,
k ‚àà[0, N]Z.
Recall that problem (5.144), (5.397) is the most important special case of the
symplectic eigenvalue problem (E), where Sk(Œª) has the form (5.145), i.e.,
Sk(Œª) =

[I ‚àíAk(Œª)]‚àí1
[I ‚àíAk(Œª)]‚àí1Bk(Œª)
Ck(Œª) [I ‚àíAk(Œª)]‚àí1 Ck(Œª) [I ‚àíAk(Œª)]‚àí1Bk(Œª) + I ‚àíAT
k (Œª)

.

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
377
In the previous sections, we have proved generalized versions of the discrete
oscillation theorems for (E) with the nonconstant rank of Bk(Œª). This approach gives
a possibility to compute the number of Ô¨Ånite eigenvalues of (E) between arbitrary
points a, b ‚ààR with a ‚â§b by using the information on the distribution of jumps of
the piecewise constant function rankBk(Œª) for k ‚àà[0, N]Z in (a, b]. It is clear that
obtaining such an information for problems (E) of big dimension n ‚â´1 imposes
considerable computational difÔ¨Åculties.
In this section we offer an approach how to avoid these difÔ¨Åculties for the special
case (5.144), (5.397). For this purpose we introduce a new notion of weighted focal
points for a conjoined basis of (5.144). As it is shown in Sect. 5.6.1, the classical
function n1(Œª) of the number of forward focal points in (0, N + 1] can lose the
monotonic character with respect to Œª if (5.38) is not satisÔ¨Åed. We offer to introduce
a monotonic, but in general indeÔ¨Ånite by sign, function #(Œª) of the number of
weighted focal points in (0, N +1] such that the quantity #(b)‚àí#(a) represents the
number of Ô¨Ånite eigenvalues of (5.144), (5.397) in (a, b] for arbitrary a, b ‚ààR with
a ‚â§b. We prove modiÔ¨Åed versions of Theorems 5.95 and 5.98, which refer to this
new notion of weighted focal points.
Based on the deÔ¨Ånition of forward focal points and its multiplicities (see
DeÔ¨Ånition 4.1), we introduce the number of weighted focal points as follows.
DeÔ¨Ånition 5.111 A conjoined basis Y(Œª) of the linear Hamiltonian difference
system (5.144) has a weighted (forward) focal point in (k, k + 1] if
m(Yk(Œª)) ‚àíind Bk(Œª) Ã∏= 0.
In this case the number of weighted (forward) focal points in (k, k + 1] is deÔ¨Åned as
the quantity
#k(Œª) = #(Yk(Œª)) := m(Yk(Œª)) ‚àíind Bk(Œª),
(5.398)
where m(Yk(Œª)) is given by (4.3).
Note that we have the estimate for m(Yk(Œª)) (see Proposition 4.4(v))
0 ‚â§m(Yk(Œª)) ‚â§rankBk(Œª),
and then by the inequality ind Bk(Œª) ‚â§rank Bk(Œª), we derive that
|#(Yk(Œª))| ‚â§rank Bk(Œª) ‚â§n.
(5.399)
In the following example, we illustrate DeÔ¨Ånition 5.111 for the scalar case n = 1.
This example also shows that the quantity #(Yk(Œª)) can be negative.

378
5
Discrete Symplectic Eigenvalue Problems
Example 5.112 Consider system (5.144) for the case n = 1 with Ak(Œª) ‚â°0. Then
the number of weighted focal points takes values from the set {0, ¬±1} and
#(Yk(Œª)) =
‚éß
‚é™‚é®
‚é™‚é©
1,
if Bk(Œª) > 0, xk(Œª) Ã∏= 0, xk(Œª) xk+1(Œª) ‚â§0,
‚àí1, if Bk(Œª) < 0, xk+1(Œª) Ã∏= 0, xk(Œª) xk+1(Œª) ‚â§0,
0,
otherwise.
Let Y(Œª) = (X(Œª), U(Œª)) be a conjoined basis of (5.144) such that (5.20) holds.
We denote the number of weighted focal points of Y(Œª) in (0, N + 1] by
#(Œª) :=
N

k=0
#k(Œª).
(5.400)
The main result of this section is the following modiÔ¨Åcation of the local oscillation
theorem (see Theorem 5.95) for problem (5.144), (5.397) dealing with the number
of weighted focal points of a conjoined basis Y(Œª) of (5.144).
Theorem 5.113 (Generalized Local Oscillation Theorem)
Suppose that (5.337)
holds and Y(Œª) = (X(Œª), U(Œª)) is a conjoined basis of (5.144) satisfying (5.20).
Then the left- and right-hand limits #k(Œª‚àí) and #k(Œª+) exist for all k ‚àà[0, N]Z and
Œª ‚ààR, and
#k(Œª+) = #k(Œª),
#k(Œª+) ‚àí#k(Œª‚àí) = rankXk(Œª) ‚àírankXk(Œª‚àí)
+ rankXk+1(Œª‚àí) ‚àírankXk+1(Œª).
‚é´
‚é™‚é¨
‚é™‚é≠
(5.401)
Moreover, with the notation in (5.400), we have
#(Œª+) = #(Œª),
|#(Œª)| ‚â§n(N + 1),
#(Œª+) ‚àí#(Œª‚àí) = rank XN+1(Œª‚àí) ‚àírankXN+1(Œª).

(5.402)
Proof Note that monotonicity condition (5.337) implies ÀôBk(Œª) ‚â•0, and then all
eigenvalues Œºi(Œª) for i ‚àà{1, 2, . . . , n} of Bk(Œª) = BT
k (Œª) are real nondecreasing
functions of Œª. The function ind Œºi(Œª) of the scalar argument Œºi(Œª) is piecewise
constant, nonincreasing, and right-continuous, then so is the function ind Bk(Œª)
for k ‚àà[0, N]Z. Similarly, the function ind [‚àíŒºi(Œª)] of the scalar argument
‚àíŒºi(Œª) is piecewise constant, nondecreasing, and left-continuous, so is the function
ind [‚àíBk(Œª)] for k ‚àà[0, N]Z. Hence, for any Œª ‚ààR, there exist the following left-
hand and right-hand limits
ind Bk(Œª+) = ind Bk(Œª),
ind [‚àíBk(Œª‚àí)] = ind [‚àíBk(Œª)],
(5.403)
ind Bk(Œª‚àí) = rankBk(Œª‚àí) ‚àírankBk(Œª) + ind Bk(Œª),
(5.404)
ind [‚àíBk(Œª+)] = rankBk(Œª+) ‚àírankBk(Œª) + ind [‚àíBk(Œª)].
(5.405)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
379
By Theorem 5.95 proved for (E) with the nonconstant rank of Bk(Œª), we have that
(see (5.330))
mk(Œª+) = mk(Œª) ‚â§n,
mk(Œª+) ‚àímk(Œª‚àí) + rankBk(Œª‚àí) ‚àírankBk(Œª)
= rankXk(Œª) ‚àírank Xk(Œª‚àí) + rank Xk+1(Œª‚àí) ‚àírankXk+1(Œª),
where rank Bk(Œª) = rank Bk(Œª) according to (5.145). Then, by (5.403) and (5.330),
the function #k(Œª) is right-continuous, and the left-hand side of the second equality
in (5.330) can be replaced by #k(Œª+) ‚àí#k(Œª‚àí) according to (5.404). The proof
of (5.401) is completed. Note that the inequality in (5.402) follows from (5.399)
and the deÔ¨Ånition of #(Œª). Summing (5.401) for k ‚àà[0, N]Z and using that Yk(Œª)
does not depend on Œª for k = 0, we complete the proof of (5.402).
‚äì‚äî
Note that (5.337) also implies that there exist the Ô¨Ånite limits
lim
Œª‚Üí‚àí‚àûind Bk(Œª) = ck < ‚àû,
k ‚àà[0, N]Z,
i.e., there exists Œª00 such that
ind Bk(Œª) = ck,
N

k=0
ind Bk(Œª) =
N

k=0
ck =: C,
for Œª < Œª00
(5.406)
(we use again that ind Bk(Œª) is monotonic and bounded). Repeating the proof of
Theorem 5.16, we conclude by (5.402) that #(Œª) is bounded and nondecreasing for
all Œª ‚ààR, so that there exists Œª0 such that
#(Œª) ‚â°p,
p = m ‚àíC,
n1(Œª) ‚â°m,
for Œª < Œª0.
(5.407)
Finally, we see by (5.407) and (5.402) that
rank XN+1(Œª) = rank XN+1(Œª‚àí),
for Œª < Œª0,
(5.408)
i.e., the Ô¨Ånite spectrum of (5.144), (5.397) is bounded from below (see also
Remark 5.97(ii)).
Recall the notation
n2(Œª) :=

Œº‚â§Œª
Œ∏(Œº)
for the number of Ô¨Ånite eigenvalues of (5.144), (5.397) less than or equal to Œª. As
a corollary to Theorem 5.113, we derive the following modiÔ¨Åcation of Theorem 5.98
for the special case (5.144), (5.397).

380
5
Discrete Symplectic Eigenvalue Problems
Theorem 5.114 (Generalized Global Oscillation Theorem) Assume that (5.337)
holds. Then the Ô¨Ånite spectrum of (5.144), (5.397) is bounded from below, and there
exists p ‚àà{0, ¬±1, . . ., ¬±n(N + 1)} such that
n2(Œª) + p = #(Œª)
for all Œª ‚ààR,
(5.409)
where p is given by (5.407).
Proof Recall again that all break points of rank XN+1(Œª) are isolated, then using
that #(Œª) is right-continuous we derive for a, b ‚ààR with a < b that
#(b) ‚àí#(a) =

Œº‚àà(a,b]
Œ∏(Œº),
(5.410)
where the sum 
Œº‚àà(a,b] Œ∏(Œº) is Ô¨Ånite. The proof of (5.409) follows from (5.410) for
b := Œª, where we evaluate the Ô¨Ånite limits of the quantities #(a) and 
Œº‚àà(a,Œª] Œ∏(Œº)
as a ‚Üí‚àí‚àûaccording to (5.407) and (5.408).
‚äì‚äî
Corollary 5.115 Assume (5.337) and suppose that the functions ind Bk(Œª) for k ‚àà
[0, N]Z are constant in Œª ‚ààR (depending on k), i.e., (5.406) holds for all Œª ‚ààR.
Then under the notation of Theorem 5.114 we have that there exists m ‚àà[0, nN]Z
such that
n2(Œª) + m = n1(Œª)
for all Œª ‚ààR,
(5.411)
where m is given by (5.407).
The next example shows that n1(Œª) is generally nonmonotonic in the setting of
this section. However, the addition of the ‚Äúcorrection term‚Äù ‚àíind Bk, according
to (5.398), implies that under (5.337) the function #(Œª) is monotonic in Œª.
Example 5.116 Consider problem (5.144), (5.397) for n = 1 and N = 3 with the
Hamiltonian
Hk(Œª) = diag{Œª, Œª ‚àík ‚àí1},
for which condition (5.337) is obviously satisÔ¨Åed. By (5.145), the matrix of the
associated symplectic system is
Sk(Œª) =
 1
Œª ‚àík ‚àí1
‚àíŒª
‚àíŒª2 + (k + 1) Œª + 1

.

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
381
The upper components of the principal solution at k = 0 are
x[0]
0 (Œª) = 0,
x[0]
1 (Œª) = Œª ‚àí1,
x[0]
2 (Œª) = ‚àíŒª3 + 3Œª2 ‚àí3,
x[0]
3 (Œª) = Œª5 ‚àí6Œª4 + 7Œª3 + 10Œª2 ‚àí11Œª ‚àí6,
x[0]
4 (Œª) = ‚àíŒª7 + 10Œª6 ‚àí29Œª5 + 5Œª4 + 69Œª3 ‚àí20Œª2 ‚àí50Œª ‚àí10.
The Ô¨Ånite eigenvalues are the roots of the equation x[0]
4 (Œª) = 0, i.e.,
Œª1 ‚âà‚àí1.0710,
Œª2 ‚âà‚àí0.6565,
Œª3 ‚âà‚àí0.2422,
Œª4 ‚âà1.4278,
Œª5 ‚âà2.7005,
Œª6 ‚âà3.5417,
Œª7 ‚âà4.2998.
The Ô¨Årst graph of Fig. 5.1 illustrates nonmonotonic character of the number n1(Œª)
of forward focal points in (0, 4] evaluated according to (5.49) in the interval Œª ‚àà
[‚àí1.3, 4.5]. The second graph of Fig. 5.1 shows the number of weighted focal points
in (0, 4] computed according to Example 5.112. We can see that the function #(Œª)
is nondecreasing with respect to Œª with the jump discontinuities located in the zeros
Œªi for i ‚àà{1, . . ., 7} of the function x[0]
4 (Œª) (see the last graph of Fig. 5.1).
‚àí1
0
1
2
3
4
0
1
2
3
number of focal points
‚àí1
0
1
2
3
4
‚àí4
‚àí2
0
2
4
number of weighted focal points
‚àí1
0
1
2
3
4
‚àí50
0
50
function x4(ÔÅ¨)
Fig. 5.1 The graphs of Example 5.116

382
5
Discrete Symplectic Eigenvalue Problems
5.6.6
General Endpoints and Nonconstant Rank
In this subsection we present generalizations of the results of Sect. 5.2.3 without the
assumptions (5.210), i.e., without
rank Bk(Œª) is constant for Œª ‚ààR for all k ‚àà[0, N]Z
rankR0(Œª) and rank RN+1(Œª) are constant for Œª ‚ààR

in the global oscillation theorem for separated endpoints (Theorem 5.50). Or, for the
more general case, we omit assumptions (5.226), i.e.,
rank Bk(Œª) is constant for Œª ‚ààR for all k ‚àà[0, N]Z
rankR2(Œª) is constant for Œª ‚ààR

used in Theorem 5.55 for the joint endpoints.
Under the notation of Sect. 5.2.3, we consider the eigenvalue problem (5.1) with
general boundary conditions. First we consider the separated endpoints (5.155).
Recall that we use the notation ¬ØY(Œª) = ( ¬ØX(Œª), ¬ØU(Œª)) for the natural conjoined
basis of system (5.1) with the initial conditions (5.204)
¬ØX0(Œª) = ‚àíRT
0 (Œª),
¬ØU0(Œª) = R‚àóT
0 (Œª),
Œª ‚ààR.
and the auxiliary matrices (5.205)
(Œª) := R‚àó
N+1(Œª) ¬ØXN+1(Œª) + RN+1(Œª) ¬ØUN+1(Œª),
M(Œª) := [I ‚àí(Œª) ‚Ä†(Œª)] RN+1(Œª),
T (Œª) := I ‚àíM‚Ä†(Œª) M(Œª),
P(Œª) := T (Œª) ¬ØXN+1(Œª) ‚Ä†(Œª) RN+1(Œª) T (Œª).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
Then, according to (5.207), (5.208), and (5.209), we introduce the numbers
n1(Œª) := number of forward focal points of ¬ØY(Œª) in (0, N + 1],
(5.412)
p(Œª) := rankM(Œª) + ind P(Œª).
(5.413)
The consideration is based on Theorem 5.41 about the equivalence between
problem (5.1), (5.155) and the extended problem (5.162). According to Theo-
rem 5.41, the matrices S‚àí1(Œª) and SN+1(Œª) given by (5.171) and (5.173) obey the
monotonicity assumption (5.163). Then we consider the numbers
œë‚àí1(Œª0) := rankR0(Œª‚àí
0 ) ‚àírank R0(Œª0),
œëN+1(Œª0) := rankRN+1(Œª‚àí
0 ) ‚àírank RN+1(Œª0),

(5.414)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
383
which count the jumps of the rank of the matrices R0(Œª) and RN+1(Œª) in the
boundary conditions (5.155). Moreover, one can apply the local oscillation theorem
with nonconstant rank (see Theorem 5.95) to the principal solution Y [‚àí1]
k
(Œª) for
k ‚àà[‚àí1, N + 1]Z of problem (5.162) and then incorporate the connection between
Y [‚àí1]
k
(Œª) for k ‚àà[‚àí1, N + 1]Z and ¬ØY(Œª) = ( ¬ØX(Œª), ¬ØU(Œª)) given by (5.216). By
analogy with the proof of Theorem 5.50, we derive the following result.
Theorem 5.117 (Local Oscillation Theorem for Separated Endpoints) Assume
that (5.3), (5.156), (5.157), and (5.158) hold. Let ¬ØY(Œª) be the natural conjoined
basis of (SDSŒª) with (5.204) and mk(Œª) for k ‚àà[0, N]Z are the multiplicities of
forward focal points of ¬ØY(Œª). Then mk(Œª‚àí) and mk(Œª+) exist for all Œª ‚ààR and
satisfy (5.330) for k ‚àà[0, N]Z. Moreover, for k ‚àà{‚àí1, N + 1}, we have
œë‚àí1(Œª) = rankX0(Œª‚àí) ‚àírank X0(Œª)
(5.415)
and
p(Œª+) = p(Œª),
p(Œª+) ‚àíp(Œª‚àí) + œëN+1(Œª) = rankXN+1(Œª) ‚àírankXN+1(Œª‚àí)
+ rank(Œª‚àí) ‚àírank(Œª),
‚é´
‚é™‚é¨
‚é™‚é≠
(5.416)
where p(Œª) is given by (5.209). Instead of (5.331), we have
n1(Œª+) = n1(Œª) ‚â§n(N + 1),
n1(Œª+) ‚àín1(Œª‚àí) + p(Œª+) ‚àíp(Œª‚àí) +
N+1

k=‚àí1
œëk(Œª)
= rank (Œª‚àí) ‚àí(Œª) = Œ∏(Œª),
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.417)
where Œ∏(Œª) is given by (5.206).
Proof For the proof it is sufÔ¨Åcient to repeat the proof of Theorem 5.50 replacing
Theorems 5.15 and 5.16 by Theorem 5.95 formulated for the nonconstant rank of
Bk(Œª). In particular, we incorporate that rank X[‚àí1]
N+2(Œª) = rank (Œª),
m(Y [‚àí1]
‚àí1 (Œª‚àí)) = m(Y [‚àí1]
‚àí1 (Œª)) = m(Y [‚àí1]
‚àí1 (Œª+)) = 0,
m(Y [‚àí1]
k
(Œª)) = m( ¬ØYk(Œª)),
k ‚àà[0, N]Z,
m(Y [‚àí1]
N+1(Œª)) = p(Œª)
which completes the proof.
‚äì‚äî

384
5
Discrete Symplectic Eigenvalue Problems
To formulate the global oscillation theorem, we assume as in the previous
sections that there exists Œª00 < 0 such that
rankBk(Œª) = rankBk(Œª‚àí)
for all Œª < Œª00,
k ‚àà[0, N]Z,
for the blocks of the symplectic matrix Sk(Œª). In addition, we introduce a similar
assumption for the blocks of the separated boundary conditions (5.155)
rankR0(Œª) = rankR0(Œª‚àí)
for all Œª < Œª00,
rankRN+1(Œª) = rankRN+1(Œª‚àí)
for all Œª < Œª00.

(5.418)
Based on Corollary 5.96, we prove a necessary and sufÔ¨Åcient condition for
the boundedness from below the spectrum of problem (5.1), (5.155) with the
nonconstant rank of R0(Œª) and RN+1(Œª).
Corollary 5.118 Assume that (5.3), (5.156), (5.157), and (5.158) hold. Then
conditions (5.333) and (5.418) are satisÔ¨Åed if and only if the Ô¨Ånite spectrum of (5.1),
(5.155) is bounded from below.
Proof The proof is based on Theorem 5.41 about the equivalence between prob-
lem (5.1), (5.155) and the extended problem (5.162). Then it is sufÔ¨Åcient to apply
Corollary 5.96 to the extended problem, where the blocks of S‚àí1(Œª) and SN+1(Œª)
are deÔ¨Åned by the matrices in (5.155) according to (5.171) and (5.173).
‚äì‚äî
Under assumptions (5.333), (5.418), we introduce the notation
n2(Œª) := number of Ô¨Ånite eigenvalues of (5.1), (5.155)
in the interval (‚àí‚àû, Œª],
n ÀúB(Œª) :=

Œº‚â§Œª
N+1

k=‚àí1
œëk(Œº),
(5.419)
where œëk(Œº) for k ‚àà[0, N + 1]Z are deÔ¨Åned by (5.329) and (5.414). Note that
conditions (5.3), (5.333), (5.418), and formula (5.417) imply the existence of ÀúŒª ‚ààR
such that
n2(Œª) ‚â°0,
n ÀúB(Œª) ‚â°0,
n1(Œª) + p(Œª) ‚â°‚Ñì
for all Œª < ÀúŒª.
(5.420)
Moreover, the functions n2(Œª) and n ÀúB(Œª) are right-continuous by Theorems 5.3, 5.1
and Corollary 5.7. From Corollary 5.118 and Theorem 5.117, we derive the
following generalization of the global oscillation theorem (Theorem 5.50).

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
385
Theorem 5.119 (Global Oscillation Theorem for Separated Endpoints)
Assume (5.3), (5.156), (5.157), (5.158), (5.333), and (5.418). Then there exists
a number ‚Ñì‚àà[0, (N + 2) n]Z such that
n1(Œª) + p(Œª) + n ÀúB(Œª) = n2(Œª) + ‚Ñì
for all Œª ‚ààR,
(5.421)
where ‚Ñìis given by (5.420).
Proof The proof is based on Theorem 5.117, and it repeats the proof of Theo-
rem 5.98. The details are therefore omitted.
‚äì‚äî
Remark 5.120 Note that the number n ÀúB(Œª) given by (5.419) can be presented in the
form
n ÀúB(Œª) = nB(Œª) + nL(Œª) + nR(Œª),
(5.422)
where
nL(Œª) :=

Œº‚â§Œª
œë‚àí1(Œº),
(5.423)
nR(Œª) :=

Œº‚â§Œª
œëN+1(Œº),
(5.424)
where nB(Œª) is deÔ¨Åned by (5.338). These three numbers characterize the contri-
bution of Sk(Œª) for k ‚àà[0, N]Z and the left and the right boundary condition,
respectively, to the spectrum of problem (5.1), (5.155). Point out that the matrices
Sk(Œª) for k ‚àà[0, N]Z and R0(Œª) and RN+1(Œª) (and then also the quantities
nB(Œª), nL(Œª), and nR(Œª)) are known, while the numbers n1(Œª) and p(Œª) have to
be computed using the conjoined basis ¬ØY(Œª).
In the following example, we analyze the main results of this subsection for
a discrete Sturm-Liouville eigenvalue problem with linear and quadratic dependence
on Œª in the boundary conditions (5.155). This analysis is motivated by the results in
[150, 166, 167].
Example 5.121 Consider the Sturm-Liouville eigenvalue problem
‚àí(rkxk) + qkxk+1 = Œªwkxk+1,
rk Ã∏= 0,
wk > 0,
k ‚àà[0, N ‚àí1]Z,
R‚àó
0(Œª) x0 + R0(Œª) (r0x0) = 0,
R‚àó
N+1(Œª) xN+1 + RN+1(Œª) (rNxN) = 0.

(5.425)
Recall that according to Example 5.35, problem (5.425) can be rewritten in
form (5.1) (or (SDSŒª)), (5.155) after the replacement uk := rkxk, k ‚àà[0, N]Z,
uN+1 := uN, with the same matrices in the boundary conditions. For the case
n = 1, conditions (5.157)‚Äì(5.158) mean that the function in the left- hand side
is nonnegative, resp., nonpositive, for all Œª ‚ààR, while (5.156) mean that the pair

386
5
Discrete Symplectic Eigenvalue Problems
of functions R‚àó
j (Œª) and Rj(Œª) for j ‚àà{0, N + 1} do not have common zeros.
In particular, if R‚àó
j (Œª) and Rj(Œª) are polynomials, then one can use the resultant
res (R‚àó
j (Œª), Rj(Œª)) (or the eliminant) of two polynomials (see [152]), which is
a polynomial expression of their coefÔ¨Åcients, to formulate a necessary and sufÔ¨Åcient
condition for the validity of (5.156). Note that we exclude the situation when
R‚àó
j (Œª) ‚â°0 (or Rj(Œª) ‚â°0) from the consideration, because in this case the boundary
conditions in (5.425) can be reduced to be independent on Œª (after dividing by
Rj(Œª) Ã∏= 0 for Œª ‚ààR or, respectively, after dividing by R‚àó
j (Œª) Ã∏= 0 for Œª ‚ààR).
For example, for the general quadratic dependence on Œª
R‚àó
j (Œª) = a‚àó
j Œª2+b‚àó
jŒª+c‚àó
j,
Rj(Œª) = ajŒª2+bjŒª+cj,
j ‚àà{0, N+1}
(5.426)
(including the general linear dependence for a‚àó
j = 0 = aj) conditions (5.157)‚Äì
(5.158) take the form
(‚àí1)j/(N+1) (‚àímjŒª2 + 2 lj Œª ‚àíhj) ‚â•0,
mj := b‚àó
jaj ‚àía‚àó
j bj,
lj := a‚àó
j cj ‚àíc‚àó
jaj,
hj := c‚àó
jbj ‚àíb‚àó
jcj,
j ‚àà{0, N + 1},
‚é´
‚é™‚é¨
‚é™‚é≠
(5.427)
while condition (5.156) holds if and only if the resultant res (R‚àó
j (Œª), Rj(Œª)) Ã∏= 0,
Œª ‚ààR (see [152]). In particular, for the linear dependence (a‚àó
j = 0 = aj), we
have res (R‚àó
j (Œª), Rj(Œª)) = ‚àíhj for the case bj Ã∏= 0 and b‚àó
j Ã∏= 0, and similarly
res (R‚àó
j (Œª), Rj(Œª)) = cj (or res (R‚àó
j (Œª), Rj(Œª)) = c‚àó
j) for the case bj = 0 and
b‚àó
j Ã∏= 0 (or b‚àó
j = 0 and bj Ã∏= 0). Therefore, the condition (‚àí1)j/(N+1) hj < 0 for
j ‚àà{0, N + 1} is necessary and sufÔ¨Åcient for (b‚àó
j)2 + b2
j > 0, (5.427), and (5.156)
(compare with the main assumptions in [150, 166]). For the quadratic case with
aj Ã∏= 0 and a‚àó
j Ã∏= 0, the resultant takes the form res (R‚àó
j (Œª), Rj(Œª)) = mjhj ‚àíl2
j .
Therefore, we can see that in this case, the condition (‚àí1)j/(N+1)Mj < 0 for
j ‚àà{0, N + 1}, where Mj :=
 hj lj
lj mj

, is necessary and sufÔ¨Åcient for (5.427),
(5.156). The situation when aj = 0 or a‚àó
j = 0 can be investigated separately by
using the general deÔ¨Ånition of res (R‚àó
j (Œª), Rj(Œª)) (see [152] for more details). In
any case one can use (‚àí1)j/(N+1)Mj < 0 for j ‚àà{0, N + 1} as a sufÔ¨Åcient
condition for (5.427) and (5.156); see [167, Lemmas 4.6 and 4.7]. Regarding the
eigenvalues of problem (5.425), it was proven in [150, 166] that for the linear case
(a‚àó
j = 0 = aj) and under the assumptions rk > 0, (5.156), and (5.157)‚Äì(5.158), the
problem (5.425) has a Ô¨Ånite number of real simple eigenvalues. The same property
is proven in [167] for the case (5.426) with the boundary conditions x0 = 0 and
R‚àó
N+1(Œª) xN+1 + RN+1(Œª) (rNxN) = 0, where MN+1 > 0.
Consider now the eigenvalue problem (5.425) with the quadratic dependence in
Œª in the boundary conditions
‚àí2xk ‚àí2xk+1 = Œªxk+1,
k ‚àà[0, N ‚àí1]Z,
x0 = 0,
(Œª2 + Œª ‚àí1) xN+1 ‚àíŒªxN = 0,

(5.428)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
387
where the parameters lN+1 = 0, mN+1 = hN+1 = 1 given by (5.427) obey the
condition MN+1 > 0. Then by [167] the problem (5.428) has a Ô¨Ånite number of
real simple eigenvalues. By putting uk := xk+1 and yk = (xk, uk)T , we rewrite this
problem in the form of (5.1), (5.155), i.e.,
yk+1 =
 0
1
‚àí1 ‚àíŒª

yk,
k ‚àà[0, N ‚àí1]Z,
x0 = 0,
ŒªxN + (Œª2 ‚àí1) uN = 0.
‚é´
‚é¨
‚é≠
(5.429)
Note that assumptions (5.155), (5.156) hold for (5.429), and then consider the
application of Theorem 5.119 to this problem for the case N = 3. The principal
solution y[0](Œª) of (5.429) at k = 0 and the function (Œª) in (5.205) have the form
y[0]
0 (Œª) =
0
1

,
y[0]
1 (Œª) =
 1
‚àíŒª

,
y[0]
2 (Œª) =

‚àíŒª
‚àí1 + Œª2

,
y[0]
3 (Œª) =
‚àí1 + Œª2
2Œª ‚àíŒª3

,
(Œª) = Œª(Œª2 ‚àí1) (3 ‚àíŒª2).
In this case we have the real simple eigenvalues
Œª1 = ‚àí
‚àö
3,
Œª2 = ‚àí1,
Œª3 = 0,
Œª4 = 1,
Œª5 =
‚àö
3.
We compute the multiplicities of focal points of the principal solution y[0](Œª) by
m0(Œª) = 0,
m1(Œª) =
1, Œª ‚àà[0, ‚àû),
0, Œª ‚àà(‚àí‚àû, 0),
m2(Œª) =
 1, Œª ‚àà[‚àí1, 0) ‚à™[1, ‚àû),
0, otherwise,
and the number p(Œª) given by (5.413) as follows
p(Œª) =
1, Œª ‚àà[‚àí
‚àö
3, ‚àí1) ‚à™[0, 1) ‚à™[
‚àö
3, ‚àû),
0, otherwise.
Then we have
n1(Œª) + p(Œª) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí
‚àö
3),
1, Œª ‚àà[‚àí
‚àö
3, 0),
2, Œª ‚àà[0,
‚àö
3),
3, Œª ‚àà[
‚àö
3, ‚àû),

388
5
Discrete Symplectic Eigenvalue Problems
and we can see that the sum n1(Œª)+p(Œª) does not calculate the eigenvalues Œª2 = ‚àí1
and Œª4 = 1. However, according to Theorem 5.119, we need to incorporate the
inÔ¨Çuence of the nonconstant rank of the coefÔ¨Åcient Œª2 ‚àí1 in the right endpoint
N + 1. For this case we have by (5.424)
nB(Œª) ‚â°0,
nL(Œª) ‚â°0,
n ÀúB(Œª) = nR(Œª) =
‚éß
‚é®
‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí1),
1, Œª ‚àà[‚àí1, 1),
2, Œª ‚àà[1, ‚àû).
Then, by Theorem 5.119 with ‚Ñì:= 0, the sum n1(Œª) + p(Œª) + n ÀúB(Œª) determines all
the eigenvalues of (5.429), i.e.,
n2(Œª) = n1(Œª) + p(Œª) + n ÀúB(Œª) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí
‚àö
3),
1, Œª ‚àà[‚àí
‚àö
3, ‚àí1),
2, Œª ‚àà[‚àí1, 0),
3, Œª ‚àà[0, 1),
4, Œª ‚àà[1,
‚àö
3),
5, Œª ‚àà[
‚àö
3, ‚àû).
Now we consider the generalization of Theorem 5.55 for joint endpoints to the
case when assumptions (5.226) do not hold. Recall the notation (see (5.220))
Xk(Œª) :=

I
0
ÀúXk(Œª) X[0]
k (Œª)

,
Uk(Œª) :=

0
‚àíI
ÀúUk(Œª) U[0]
k (Œª)

,
where Y [0](Œª) is the principal solution of (5.1) at k = 0 and, by (5.221),
L(Œª) := R1(Œª) XN+1(Œª) + R2(Œª) UN+1(Œª),
M(Œª) := [I ‚àíL(Œª) L‚Ä†(Œª)] R2(Œª),
T (Œª) := I ‚àíM‚Ä†(Œª) M(Œª),
P(Œª) := T (Œª) XN+1(Œª) L‚Ä†(Œª) R2(Œª) T (Œª).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
The multiplicity Œ∂(Œª0) of Ô¨Ånite eigenvalue of problem (SDSŒª), (5.151) is presented
by DeÔ¨Ånition 5.54.
The consideration is based on Theorem 5.44, which guarantees that under
assumptions (5.2), (5.3), (5.152), and (5.153), problem (SDSŒª), (5.151) is equivalent
to the augmented problem (5.178) or (5.232) (see the proof of Theorem 5.55). Note
that problem (5.232) obeys all assumptions of the local oscillation theorem for the
separated endpoints (see Theorem 5.117). Moreover, we again use that
rank ÀúBk(Œª) = rank diag{0, Bk(Œª)} = rankBk(Œª),
k ‚àà[0, N]Z,

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
389
where ÀúBk(Œª) is the block of {Sk(Œª)} (see (5.200)). Then the deÔ¨Ånition of the numbers
Àúœëk(Œª0) for k ‚àà[0, N]Z for the augmented problem (5.232) stays the same as before
(see (5.329)), since
Àúœëk(Œª0) = rank diag{0, Bk(Œª‚àí
0 )} ‚àírank diag{0, Bk(Œª0)}
= rankBk(Œª‚àí
0 ) ‚àírank Bk(Œª0) = œëk(Œª0),
k ‚àà[0, N]Z.

(5.430)
As the boundary condition for k = 0 does not depend on Œª, we have according
to (5.414) applied to (5.232) that
Àúœë‚àí1(Œª0) = 0,
ÀúœëN+1(Œª0) = rankR2(Œª‚àí
0 ) ‚àírank R2(Œª0).

(5.431)
Introduce the notation (see (5.223) and (5.225))
n1(Œª) := number of forward focal points of Y [0](Œª) in (0, N + 1],
q(Œª) := rankM(Œª) + ind P(Œª).
Then Theorem 5.117 applied to augmented problem (5.232) reads as follows.
Theorem 5.122 (Local Oscillation Theorem for Joint Endpoints)
Assume (5.2),
(5.3), (5.152), and (5.153). Let Y [0](Œª) be the principal solution at k = 0 of (SDSŒª),
and mk(Œª) for k ‚àà[0, N]Z are the multiplicities of focal points of Y [0](Œª). Then
mk(Œª‚àí) and mk(Œª+) exist for all Œª ‚ààR and satisfy (5.330) for all k ‚àà[0, N]Z.
Moreover, for k = N + 1, we have
q(Œª+) = q(Œª),
q(Œª+) ‚àíq(Œª‚àí) + ÀúœëN+1(Œª) = rankXN+1(Œª) ‚àírankXN+1(Œª‚àí)
+ rankL(Œª‚àí) ‚àírank L(Œª),
‚é´
‚é™‚é¨
‚é™‚é≠
(5.432)
where q(Œª) is given by (5.225). Instead of (5.417), we have
n1(Œª+) = n1(Œª) ‚â§n(N + 1),
n1(Œª+) ‚àín1(Œª‚àí) + q(Œª+) ‚àíq(Œª‚àí) +
N+1

k=0
Àúœëk(Œª)
= rank L(Œª‚àí) ‚àíL(Œª) = Œ∂(Œª),
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(5.433)
where Œ∂(Œª) is given by (5.222).

390
5
Discrete Symplectic Eigenvalue Problems
To formulate the global oscillation theorem, we replace assumptions (5.418) by
the more general assumption for joint endpoints
rank R2(Œª) = rankR2(Œª‚àí)
for all Œª < Œª00.
(5.434)
Using the notion of Ô¨Ånite eigenvalue of problem (SDSŒª), (5.151) and condi-
tions (5.333) and (5.434), we prove an analog of Corollary 5.118 for joint endpoints.
Corollary 5.123 Under assumptions (5.2), (5.3), (5.152), and (5.153), condi-
tions (5.333) and (5.434) hold if and only if the Ô¨Ånite spectrum of problem (SDSŒª),
(5.151) is bounded from below.
Proof We apply Corollary 5.118 to augmented problem (5.178) or (5.232) replac-
ing (5.418) by (5.434).
‚äì‚äî
Introduce the notation
n2(Œª) := number of Ô¨Ånite eigenvalues of (5.1), (5.151) in (‚àí‚àû, Œª],
Àún ÀúB(Œª) :=

Œº‚â§Œª
N+1

k=0
Àúœëk(Œº),
(5.435)
where Àúœëk(Œª) are given by (5.430) and (5.431). Note that under assumptions (5.3),
(5.333), and (5.434) instead of (5.420) for the separated endpoints, we have for some
ÀúŒª ‚ààR
n2(Œª) ‚â°0,
Àún ÀúB(Œª) ‚â°0,
n1(Œª) + q(Œª) ‚â°‚Ñì
for all Œª < ÀúŒª,
(5.436)
where we apply (5.433). Based on Corollary 5.123 and Theorem 5.122, we derive
a generalization of Theorem 5.55 without assumptions (5.226).
Theorem 5.124 (Global Oscillation Theorem for Joint Endpoints)
Assume
that (5.2), (5.3), (5.152), (5.153), (5.333), and (5.434) hold. Then there exists
a number ‚Ñì‚àà[0, (N + 2) n]Z such that
n1(Œª) + q(Œª) + Àún ÀúB(Œª) = n2(Œª) + ‚Ñì
for all Œª ‚ààR,
(5.437)
where ‚Ñìis given by (5.436).
Proof The proof repeats the proof of Theorem 5.55, where instead of Theorem 5.50,
we apply Theorem 5.119.
‚äì‚äî
Remark 5.125 For the case when the endpoints are separated, formula (5.437) turns
into (5.421). Indeed, in this case Àún ÀúB(Œª) = n ÀúB(Œª) and by (5.218)
q(Œª) = Œº
 ÀúVN+1(Œª)‚ü®Z[0]
N+1(Œª)‚ü©, ÀúVN+1(Œª) (02n I2n)T 
,
(5.438)

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
391
where the symplectic matrix ÀúVN+1(Œª) is associated with the boundary condition
in (5.232) at N + 1 by (5.173). For the case of separated endpoints, it is easy to
verify by direct calculations that
ÀúVN+1(Œª) = {V ‚àí1
‚àí1 (Œª), VN+1(Œª)},
(5.439)
where V‚àí1(Œª), VN+1(Œª) are given by (5.171) and (5.173) for separated boundary
conditions (5.155) (remark that we use notation (3.101)). Then it is possible to prove
the relation
q(Œª) = Œº
 ¬ØYN+1(Œª), Y [0]
N+1(Œª)

+ p(Œª),
Œª ‚ààR,
(5.440)
which holds for q(Œª) and p(Œª) given by (5.209) and (5.225) for the case of the
separated boundary conditions. Here ¬ØYN+1(Œª) is the conjoined basis of (5.1) given
by (5.204). Here we present the outline of the rather technical (direct) proof of this
result based on algebraic properties of the comparative index derived in Sect. 3.3.5.
Applying (5.438) and (5.439), we have by (3.105)
q(Œª) = Œº

‚ü®VN+1(Œª)Z[0]
N+1V‚àí1(Œª)‚ü©, {V ‚àí1
‚àí1 (Œª), VN+1(Œª)}(02n I2n)T 
,
where we applied Theorem 3.5(i). Next, by (3.116)
Œº‚ü®VN+1(Œª) Z[0]
N+1(Œª) V‚àí1(Œª)‚ü©, {V ‚àí1
‚àí1 (Œª), VN+1(Œª)}(02n I2n)T 
= Œº‚àó
V ‚àí1
‚àí1 (Œª) [Z[0]
N+1(Œª)]‚àí1(0 I)T, V ‚àí1
‚àí1 (Œª) (0 I)T 
+ ŒºVN+1(Œª) ¬ØYN+1(Œª), VN+1(Œª) (0 I)T 
= Œº
 ¬ØYN+1(Œª), Y [0]
N+1(Œª)

+ p(Œª),
where we use Theorem 3.5(iii), (i) and the deÔ¨Ånition of p(Œª) according to (5.218).
Applying the Sturmian separation result (see formula (4.60))
l( ¬ØY(Œª), 0, N + 1) ‚àíl(Y [0](Œª), 0, N + 1) = Œº
 ¬ØYN+1(Œª), Y [0]
N+1(Œª)

,
it is easy to see that (5.437) indeed turns into (5.421) for the separated endpoints.
Remark 5.126 The periodic and antiperiodic boundary conditions are included
in (5.155) for the special choice of constant matrices R1(Œª) and R2(Œª), as we
discussed in Remark 5.58 in Sect. 5.2.3. In both cases (5.236) and (5.237), the
matrices R2(Œª) are constant in Œª, so that by (5.430) and (5.431) the function Àún ÀúB(Œª)
in (5.436) coincides with the function nB(Œª) in (5.338). Recall now from (5.371)

392
5
Discrete Symplectic Eigenvalue Problems
the symplectic and orthogonal matrix
R :=
1
‚àö
2
‚éõ
‚éú‚éú‚éù
0 ‚àíI I
0
0
I
I
0
‚àíI
0 0 ‚àíI
‚àíI
0 0 I
‚éû
‚éü‚éü‚é†.
which was used in Sect. 5.6.3. Then the matrix ÀúSN+1(Œª) ‚ààSp(4n) associated with
the boundary condition (5.236) at N + 1 of the augmented problem (5.178) can be
taken in the form ÀúSN+1(Œª) ‚â°ÀúSN+1 := RT . For this choice of ÀúSN+1, the number
q(Œª) given by (5.438) for the periodic boundary conditions (5.236) takes the form
(see the Ô¨Årst equality in formula (5.377) and (3.104))
q(Œª) = q1(Œª) := Œº

RT ‚ü®Z[0]
N+1(Œª)‚ü©, RT (0 I)T 
= Œº
 
L1(Œª)
J T L2(Œª)

, RT (0 I)T 
‚â§n.
‚é´
‚é¨
‚é≠
(5.441)
Moreover, consider a generalized version of the periodic and antiperiodic boun-
dary conditions (5.236) and (5.237) in the form
y0(Œª) = ÀÜS(Œª) yN+1(Œª),
(5.442)
where ÀÜS(Œª) is a given symplectic piecewise continuously differentiable matrix for
Œª ‚ààR satisfying ( ÀÜS(Œª)) ‚â•0, where ( ÀÜS(Œª)) is given by (5.3). The problem (5.1),
(5.442) is then equivalent to the following extended problem with the periodic
endpoints
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N + 1]Z,
SN+1(Œª) := ÀÜS(Œª),
y0(Œª) = yN+2(Œª),

(5.443)
where the matrix Sk(Œª) obeys (5.3) for k ‚àà[0, N + 1]Z. Applying the above results
for (5.236) to problem (5.443), we get
L(Œª) = J I ‚àíÀÜS(Œª) Z[0]
N+1(Œª).
Here we used that Z[0]
N+2(Œª) =
ÀÜS(Œª) Z[0]
N+1(Œª), while q(Œª) given by (5.438) for
conditions (5.442) takes the form
q(Œª) = Œº

RT ‚ü®Z[0]
N+2(Œª)‚ü©, RT (0 I)T 
+ Œº

Y [0]
N+2(Œª), ÀÜS(Œª) (0 I)T 
= Œº
 
L(Œª)
I+ ÀÜS(Œª) Z[0]
N+1(Œª)

, RT (0 I)T

+ Œº

ÀÜS(Œª) Y [0]
N+1(Œª), ÀÜS(Œª) (0 I)T 
,

5.6
Oscillation Theorems for Variable Rank of Bk(Œª)
393
where we incorporated the multiplicity Œº

Y [0]
N+2(Œª), ÀÜS(Œª) (0 I)T 
of the focal point
of the principal solution of (5.443) at N + 1 according to (4.14) in Lemma 4.7. In
particular, for the antiperiodic boundary conditions (5.237), we have ÀÜS(Œª) := ‚àíI
in (5.443), and then for this case
q(Œª) = q2(Œª) := Œº

RT ‚ü®‚àíZ[0]
N+1(Œª)‚ü©, RT (0 I)T 
= Œº
 
L2(Œª)
J T L1(Œª)

, RT (0 I)T 
‚â§n,
‚é´
‚é¨
‚é≠
(5.444)
where L1(Œª) and L2(Œª) are given in (5.236) and (5.237) and where we used
Theorem 3.5(i) in the calculations.
Example 5.127 Consider problem (5.1), (5.151) in the form
yk+1(Œª) =
I ‚àíPkŒª2 ŒªI
‚àíŒªPk
I

yk(Œª),
k ‚àà[0, N]Z,
yN+1(Œª) = G y0(Œª),
(5.445)
where G is a constant symplectic matrix. It was proven in [165, Section 3] that under
the assumptions Pk symmetric, Pk ‚â•0, and N
k=0 Pk > 0, problem (5.445) is self-
adjoint, and the width of the central zone of stability of a discrete linear Hamiltonian
system associated with (5.445) can be estimated by using the properties of the
eigenvalues of this problem. Note that problem (5.445) satisÔ¨Åes all the assumptions
of Theorem 5.124, and then this theorem together with Remarks 5.58 and 5.126 can
be applied for the calculation of the eigenvalues of (5.445).
For example, consider the case n = 1, Pk = 1, G = I2, and N = 1. Then
the symplectic fundamental matrix of the symplectic system in (5.445) and L1(Œª)
in (5.236) have the form
Z[0]
0 (Œª) ‚â°I, Z[0]
1 (Œª) =
I ‚àíŒª2 ŒªI
‚àíŒªI
I

, Z[0]
2 (Œª) =
Œª4 ‚àí3Œª2 + 1 2Œª ‚àíŒª3
‚àí2Œª + Œª3
1 ‚àíŒª2

,
L1(Œª) =
 ‚àí2Œª + Œª3
‚àíŒª2
‚àíŒª4 + 3Œª2 ‚àí2Œª + Œª3

,
with det L1(Œª) = Œª2(2 ‚àíŒª) (2 + Œª). Then Œª2 = 0 has the multiplicity Œ∏(Œª2) = 2,
while the eigenvalues Œª1 = ‚àí2 and Œª3 = 2 are simple. The multiplicities mk(Œª) =
mk(Y [0](Œª)), k ‚àà[0, 1]Z of focal points of Y [0](Œª) and the function Àún ÀúB(Œª) = nB(Œª)
given by (5.435) and (5.338) calculating the zeros of Bk(Œª) = Œª for k ‚àà[0, 1]Z are
m0(Œª) = 0, m1(Œª) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí
‚àö
2),
1, Œª ‚àà[‚àí
‚àö
2, 0),
0, Œª ‚àà[0,
‚àö
2),
1, Œª ‚àà[
‚àö
2, ‚àû),
nB(Œª) =
 0, Œª ‚àà(‚àí‚àû, 0),
2, Œª ‚àà[0, ‚àû).

394
5
Discrete Symplectic Eigenvalue Problems
It follows that
m1(Œª) + nB(Œª) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí
‚àö
2),
1, Œª ‚àà[‚àí
‚àö
2, 0),
2, Œª ‚àà[0,
‚àö
2),
3, Œª ‚àà[
‚àö
2, ‚àû),
q(Œª) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí2),
1, Œª ‚àà[‚àí2, ‚àí
‚àö
2),
0, Œª ‚àà[‚àí
‚àö
2, 0),
1, Œª ‚àà[0,
‚àö
2),
0, Œª ‚àà[
‚àö
2, 2),
1, Œª ‚àà[2, ‚àû),
where by Theorem 5.98 the sum m1(Œª) + nB(Œª) calculates the eigenvalues of
problem (5.445) with the Dirichlet boundary conditions (i.e., the zeros of the
polynomial X[0]
2 (Œª) = 2Œª‚àíŒª3). On the other hand, for the calculation of the number
of eigenvalues of (5.445) according to Theorem 5.124, we have to add the number
q(Œª) evaluated according to (5.441) and the deÔ¨Ånition of the comparative index (see
DeÔ¨Ånition 3.1). Finally, we have
n2(Œª) = m1(Œª) + nB(Œª) + q(Œª) =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
0, Œª ‚àà(‚àí‚àû, ‚àí2),
1, Œª ‚àà[‚àí2, 0),
3, Œª ‚àà[0, 2),
4, Œª ‚àà[2, ‚àû),
where n2(Œª) is the number of the eigenvalues (including multiplicities) of (5.445)
less than or equal to the given Œª in the accordance with Theorem 5.124.
5.7
Notes and References
The oscillation theorems for symplectic eigenvalue problems were Ô¨Årst considered
in [55, 102] for systems with linear dependence on Œª and the Dirichlet boundary
conditions. More precisely, in [55], a certain Ô¨Ånite exceptional set of values Œª was
excluded from the statement of the main result, while in [102] all values Œª ‚ààR were
covered. This issue was also closely related to the introduction of the multiplicities
of (forward) focal points in [208], as shown in DeÔ¨Ånition 4.1. Extension of the
oscillation theorems in [102] to separated boundary conditions via a transformation
to the Dirichlet boundary conditions was derived in [55, 103].
Nonlinear dependence on the spectral parameter in symplectic difference sys-
tems, as it is presented in Sect. 5.1, was introduced in [297]. There the oscillation
theorems were proven under the condition that the coefÔ¨Åcient Bk(Œª) ‚â°Bk is
constant in Œª on R, which was also the case in [102]. This assumption was weakened
to the constant Im Bk(Œª) ‚â°R in Œª in [298] for the scalar second-order Sturm-
Liouville difference equations (SLŒª) with (1.30) and to an arbitrary constant image
of Bk(Œª) in Œª in [210] for general symplectic difference systems with Dirichlet
boundary conditions. Discrete oscillation theorems for eigenvalue problems with

5.7
Notes and References
395
separated or general boundary conditions (under Im Bk(Œª) constant in Œª ‚ààR) were
obtained in [305] for systems with linear dependence on Œª and in [301] for systems
with nonlinear dependence on Œª.
Finally, oscillation theorems without condition Im Bk(Œª) constant in Œª for prob-
lem (E) under monotonicity assumption (5.3) were proven in [125, Theorem 2.4].
It particular, it was shown there that assumption (5.3) implies that rankBk(Œª),
Im Bk(Œª), and Ker Bk(Œª) are piecewise constant in Œª (see [125, Remark 3.6]).
Generalizations of these oscillation theorems to symplectic difference systems with
general boundary conditions, which also incorporate possible oscillations in the
rank of the coefÔ¨Åcients in the system and in the boundary conditions, were obtained
recently in [133].
The treatment of discrete symplectic eigenvalue problems with linear dependence
on Œª both in the system and in the boundary conditions as presented in Sect. 5.3
is motivated by the results for linear Hamiltonian differential systems (1.103) in
[205, Section 2.2]. The positivity result in Proposition 5.67 was proven in [103,
Proposition 2]. The Rayleigh principle for symplectic eigenvalue problems with
Dirichlet boundary conditions (Theorem 5.83 and Corollary 5.84) was proven in
[56, Theorem 4.6]. Extensions of this result to separated or joint boundary condi-
tions (constant in Œª) were obtained in [103, Theorem 2] and [305, Theorems 3.2],
respectively. In this respect the results with Rayleigh principle for symplectic
eigenvalue problems with separated and joint boundary conditions depending
(linearly) on Œª (in Theorems 5.85 and 5.88 as well as in Corollaries 5.86 and 5.87)
are also new in the literature. The Sturmian comparison and separation theorems
obtained in Sect. 5.5.1 via the Rayleigh principle are from [56].
It should be noted that linear Hamiltonian system (5.144) with nonlinear
dependence on Œª was Ô¨Årst studied in [44, 264] under a strict normality assumption,
which corresponds to the strict monotonicity of the matrix Hk(Œª), and further in
[210, 297] under (5.337) and the restriction that Im [ ÀúAk(Œª) Bk(Œª)] is constant in
Œª ‚ààR (see Example 5.37). This condition is equivalent to rank Bk(Œª) constant in
Œª ‚ààR by Theorem 5.1(iii). Later, in [95], the last condition was completely omitted.
There are several other topics in the spectral theory of discrete systems, which
were studied within symplectic difference systems (SDS) or linear Hamiltonian
difference systems (2.15). In this context we wish to mention Ô¨Årst the literature
regarding the discrete Weyl-Titchmarsh theory, i.e., the theory of square summable
solutions of symplectic difference systems depending on Œª ‚ààC. The study in
this direction was initiated in [60, 67] for symplectic difference systems (5.238)
with special linear dependence on the spectral parameter Œª, i.e., for the matrix
Sk(Œª) in (5.239) with (5.241). Weyl-Titchmarsh theory for symplectic difference
systems with general linear dependence on Œª was developed in [308‚Äì310, 313]
and with polynomial and analytic dependence on Œª in [89, 90, 311, 312]. The
results in [310, 313] show an interesting phenomenon in the discrete time theory,
where the limit circle invariance (and the Weyl alternative) holds without any
additional assumption in comparison with the corresponding continuous time result.
Extensions of several classical concepts from the theory of square summable
solutions for symplectic difference systems to linear relations were presented in

396
5
Discrete Symplectic Eigenvalue Problems
[68, 335]. Properties of eigenvalues and the spectrum of symplectic difference
systems were studied in [120, 122].
In the literature, there are many studies about the spectral properties of linear
Hamiltonian difference systems (5.144). Those are special symplectic difference
systems as we showed in Example 5.37. Below we review the relevant literature
regarding selected spectral properties of (5.144) with various dependence on Œª
(often linear in Œª). Stability zones were studied in [242‚Äì244]. Spectral properties
of system (5.144) on bounded interval was studied in [264] and on unbounded
interval in [66, 221, 252, 253, 265, 271, 272, 275, 277]. Spectral properties of linear
subspaces associated with system (5.144) were studied in [251, 269]. Further results
from spectral theory of (5.144) were obtained in [33, 44, 144, 235, 261, 337].
We recommend the following additional related references for further reading
about the topics presented in this chapter: [31, 199, 273, 274, 276] for discrete
Sturm-Liouville eigenvalue problems and [18‚Äì20, 29, 72, 73, 158‚Äì161, 197, 198,
217, 218, 228‚Äì231, 233, 240, 260, 278, 320, 325, 329] for applications of symplectic
systems, symplectic algorithms, and related numerical analysis.

Chapter 6
Miscellaneous Topics on Symplectic
Systems
In this chapter we will present some additional topics from the theory of symplectic
difference systems (SDS), which are closely related to their oscillation or spectral
theory. These topics cover the relative and renormalized oscillation theorems for
symplectic eigenvalue problems with nonlinear dependence on spectral parameter
and the theory of symplectic difference systems, which do not impose any controlla-
bility assumption. The latter one includes, in particular, a general theory of recessive
and dominant solutions at ‚àû(as a generalization of Sect. 2.5) and their applications
in the singular Sturmian theory (as an extension and completion of Sect. 4.2.4).
6.1
Relative Oscillation Theory
Relative oscillation theory‚Äîrather than measuring the spectrum of one single
problem‚Äîmeasures the difference between the spectra of two different problems.
This is done by replacing focal points of conjoined bases of one problem by
matrix analogs of weighted zeros of Wronskians of conjoined bases of two different
problems. In this section we develop the relative oscillation theory for symplectic
boundary value problems.
We consider two symplectic eigenvalue problems which may differ both in the
coefÔ¨Åcient matrix of the system and also in the boundary conditions. Together
with problem (5.1), (5.151), we consider the problem in the same form for
system (5.318), i.e.,
ÀÜyk+1(Œª) = ÀÜSk(Œª) ÀÜyk(Œª),
k ‚àà[0, N]Z,
(6.1)
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7_6
397

398
6
Miscellaneous Topics on Symplectic Systems
where matrix ÀÜSk(Œª) is symplectic for every Œª ‚ààR and
ÀÜSk(Œª) =

ÀÜAk(Œª) ÀÜBk(Œª)
ÀÜCk(Œª) ÀÜDk(Œª)

,
(6.2)
With (6.1) we consider boundary conditions of the same form as (5.151), that is,
ÀÜR1(Œª)
 ÀÜx0(Œª)
ÀÜxN+1(Œª)

+ ÀÜR2(Œª)
 ‚àíÀÜu0(Œª)
ÀÜuN+1(Œª)

= 0,
(6.3)
where ÀÜR1(Œª) and ÀÜR2(Œª) are piecewise continuously differentiable matrix-valued
functions such that
ÀÜR1(Œª), ÀÜR2(Œª) ‚ààR2n√ó2n,
rank( ÀÜR1(Œª) ÀÜR2(Œª)) = 2n,
ÀÜR1(Œª) ÀÜRT
2 (Œª) = ÀÜR2(Œª) ÀÜRT
1 (Œª),
Œª ‚ààR.

(6.4)
By analogy with (5.3) and (5.153), we impose the monotonicity assumptions
( ÀÜSk(Œª)) := J ÀôÀÜSk(Œª) J ÀÜST
k (Œª) J ‚â•0,
k ‚àà[0, N]Z,
Œª ‚ààR.
(6.5)
and, using the notation ÀÜR(Œª) := ( ÀÜR1(Œª) ÀÜR2(Œª)) ‚ààR2n√ó4n,
ÀôÀÜR1(Œª) ÀÜRT
2 (Œª) ‚àíÀôÀÜR2(Œª) ÀÜRT
1 (Œª) = ÀôÀÜR(Œª) J4n ÀÜRT (Œª) ‚â§0.
(6.6)
We will investigate the pair of eigenvalue problems (5.1), (5.151) and (6.1), (6.3)
and their particular cases which deal with separated and the Dirichlet boundary
conditions.
The fundamental role in our treatment is played by the relative oscillation
numbers introduced in Chap. 4 (see DeÔ¨Ånition 4.44) for systems (SDS) and (4.98)
and by Theorem 4.56 for the principal solutions of these systems. For this reason we
return in this chapter back to notation (4.10) and (4.11) from Chap. 4. In particular,
we use
l(Y, M, N + 1) :=
N

k=M
m(Yk),
l‚àó(Y, M, N + 1) :=
N

k=M
m‚àó(Yk)
(6.7)
for the numbers of forward and backward focal points of Y in (M, N + 1] and
[M, N + 1), instead of using n1(Y(Œª)) and n‚àó
1(Y(Œª)) as in Chap. 5. Moreover, we
introduce the notation
#{ŒΩ ‚ààœÉ | ŒΩ ‚ààI},
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚ààI}
(6.8)

6.1
Relative Oscillation Theory
399
for the number of Ô¨Ånite eigenvalues of problems (5.1), (5.151) and (6.1), (6.3),
where œÉ and ÀÜœÉ are the Ô¨Ånite spectra of these problems, respectively, and I ‚äÜR.
In particular, we have
n2(Œª) = #{ŒΩ ‚ààœÉ | ŒΩ ‚â§Œª},
where n2(Œª) denotes the number of Ô¨Ånite eigenvalues of (5.1), (5.151) (including
special cases) less than or equal to a given Œª under the notation in Chap. 5.
6.1.1
Sturm-Liouville Difference Equations
In this subsection we brieÔ¨Çy recall the results of G. Teschl and his collaborators
in [22, 314, 315] concerning the relative oscillation and spectral theory for discrete
Sturm-Liouville eigenvalue problems.
Consider a pair of discrete Sturm-Liouville eigenvalue problems
‚àí(rkxk) + pkxk+1 = Œªxk+1,
x0 = 0 = xN+1
(6.9)
and
‚àí(rkÀÜxk) + ÀÜpkxk+1 = ŒªÀÜxk+1,
ÀÜx0 = 0 = ÀÜxN+1
(6.10)
with rk > 0. Introduce the Wronskian for solutions x, ÀÜx of (6.9), (6.10)
wk(x, ÀÜx) = ‚àírk(xk ÀÜxk+1 ‚àíxk+1 ÀÜxk) = ‚àírk[xkÀÜxk ‚àí(xk) ÀÜxk].
(6.11)
In accordance with [314], Wronskian (6.11) has a generalized zero in the interval
[k, k + 1) if either wkwk+1 < 0 or wk = 0 and wk+1 Ã∏= 0. Then, by [314,
Theorem 4.3], in case pk = ÀÜpk for any a < b it holds
#(x[0](a), ÀÜx[N+1](b)) = #{Œª ‚ààœÉ | a < Œª < b},
(6.12)
where #(x, ÀÜx) denotes the number of generalized zeros of wk(x, ÀÜx) in (0, N + 1)
and #{Œª ‚ààœÉ | a < Œª < b} is the number of eigenvalues of (6.9) between a and b.
Here x[0](Œª) and ÀÜx[N+1](Œª) are the principal solutions of (6.9) (or (6.10)) at k = 0
and k = N + 1, respectively, i.e., the nontrivial solutions satisfying x[0]
0
= 0 and
ÀÜx[N+1]
N+1
= 0.
The main result of [22] extends (6.12) to the case pk Ã∏=
ÀÜpk. Assume that
ÀÜx[N+1](Œª) is the principal solution of (6.10) at k = N + 1. According to [22,
Theorem 1.2], the number of weighted generalized zeros of the Wronskian on
(0, N + 1) equals the difference of the number of eigenvalues of (6.10) less than

400
6
Miscellaneous Topics on Symplectic Systems
b and the number of eigenvalues (6.9) less than or equal to a,
#(x[0](a), ÀÜx[N+1](b)) = #(x[N+1](a), ÀÜx[0](b))
= #{ŒΩ ‚ààÀÜœÉ | ŒΩ < b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§a}.
(6.13)
The concept of weighted zero of the Wronskian is deÔ¨Åned as follows.
DeÔ¨Ånition 6.1 Denote
qk(a, b) := pk ‚àíÀÜpk + b ‚àía.
(6.14)
The Wronskian wk(x, ÀÜx) has a weighted zero at k if #k(x, ÀÜx) = ¬±1, where
#k(x, ÀÜx) :=

1,
qk(a, b) > 0, wkwk+1 ‚â§0, wk+1 Ã∏= 0,
‚àí1, qk(a, b) < 0, wk+1wk ‚â§0, wk Ã∏= 0,
(6.15)
and #k(x, ÀÜx) := 0 otherwise. The number of weighted zeros in (0, N + 1) is given
by the formula
#(x, ÀÜx) :=
N

k=0
#k(x, ÀÜx) ‚àí

0, if w0(x, ÀÜx) Ã∏= 0,
1, if w0(x, ÀÜx) = 0.
(6.16)
Note that in case pk = ÀÜpk and b > a the above deÔ¨Ånition reduces to the deÔ¨Ånition
of the generalized zero of the Wronskian in [k, k +1) and the number of generalized
zeros in (0, N + 1).
6.1.2
Dirichlet Boundary Value Problems
In this subsection we consider systems (5.1) and (6.1) together with the Dirichlet
boundary conditions
yk+1(Œª) = Sk(Œª) yk(Œª), k ‚àà[0, N]Z, Œª ‚ààR, x0(Œª) = 0 = xN+1(Œª),
ÀÜyk+1(Œª) = ÀÜSk(Œª) ÀÜyk(Œª), k ‚àà[0, N]Z, Œª ‚ààR, ÀÜx0(Œª) = 0 = ÀÜxN+1(Œª),

(6.17)
We assume the monotonicity conditions (5.3) and (6.5) and suppose that (5.38) hold
for both matrices Sk(Œª) and ÀÜSk(Œª) for k ‚àà[0, N]Z, i.e.,
rankBk(Œª) and rank ÀÜBk(Œª) are constant for Œª ‚ààR and k ‚àà[0, N]Z.
(6.18)
The global oscillation theorems established for problem (E) (see Theorem 5.17)
relates the number of Ô¨Ånite eigenvalues of (E) less than or equal to a given number

6.1
Relative Oscillation Theory
401
Œª := Œª1 to the number of focal points (counting multiplicity) of the principal
solution of the difference system in (E) with Œª = Œª1. Our aim is to add a new
aspect to this classical result by showing that matrix analogs of weighted zeros of
the Wronskian for two suitable matrix solutions of the difference systems in (6.17)
can be used to count the difference between the number of Ô¨Ånite eigenvalues of
problems (6.17).
Note that problems (6.17) under conditions (5.3), (6.5), and (6.18) obey all
assumptions of Theorem 5.17, and then the Ô¨Ånite spectra œÉ and ÀÜœÉ are bounded,
and we can order the Ô¨Ånite eigenvalues of (6.17) into nondecreasing sequences
‚àí‚àû< Œª1 ‚â§Œª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm < +‚àû,
‚àí‚àû< ÀÜŒª1 ‚â§ÀÜŒª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§ÀÜŒªl < +‚àû.

(6.19)
We put Œª1 = ‚àû(ÀÜŒª1 = ‚àû) if œÉ = ‚àÖ(ÀÜœÉ = ‚àÖ). We also deÔ¨Åne
Œª0 = min{Œª1, ÀÜŒª1}.
(6.20)
Recall that according to Theorem 5.17
l(Y [0](a), 0, N + 1) = #{ŒΩ ‚ààœÉ | ŒΩ ‚â§a} + m,
l( ÀÜY [0](b), 0, N + 1) = #{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} + ÀÜm,

(6.21)
where Y [0](Œª) and ÀÜY [0](Œª) are the principal solutions of the symplectic systems
in (6.17) at 0, and where
m := l(Y [0](Œª), 0, N + 1),
ÀÜm = l( ÀÜY [0](Œª), 0, N + 1),
Œª < Œª0.
(6.22)
Then we have from (6.21) and (6.22) that
#{ŒΩ ‚ààÀÜœÉ| ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§a}
= l( ÀÜY [0](b), 0, N + 1) ‚àíl(Y [0](a), 0, N + 1) ‚àí( ÀÜm ‚àím),

(6.23)
where
ÀÜm ‚àím = l( ÀÜY [0](Œª), 0, N + 1) ‚àíl(Y [0](Œª), 0, N + 1),
Œª < Œª0.
(6.24)
Applying Theorem 4.56 connecting the differences of the multiplicities of focal
points on the right-hand sides of (6.23) and (6.24) with the relative oscillation
numbers (see DeÔ¨Ånition 4.44), we prove the following central results.
Theorem 6.2 (Relative Oscillation Theorem)
Assume that (5.3), (6.5), (6.18)
hold for systems (5.1) and (6.1). Let Z[0](Œª) and ÀÜZ[N+1](Œª) be symplectic funda-
mental matrices of these systems associated with the principal solutions Y [0](Œª) =
Z[0](Œª) (0 I)T and ÀÜY [N+1](Œª) = ÀÜZ[N+1](Œª) (0 I)T at k = 0 and k = N + 1,

402
6
Miscellaneous Topics on Symplectic Systems
respectively. DeÔ¨Åne the relative oscillation numbers according to (4.143) (with
ÀÜZ[N+1] := ÀÜZ[N+1](b), Z[M] := Z[M](a), M := 0), i.e.,
#k( ÀÜZ[N+1](b), Z[0](a)) := Œº

‚ü®Gk(a, b)‚ü©, ‚ü®Gk+1(a, b)‚ü©

‚àíŒº

‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©

(6.25)
for k ‚àà[0, N]Z, where
Gk(a, b) := [ ÀÜZ[N+1]
k
(b)]‚àí1Z[0]
k (a).
Then there exists a constant P ‚àà[‚àínN, nN]Z such that for any a, b ‚ààR we have
for the spectra œÉ and ÀÜœÉ of problems (6.17)
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§a} = #( ÀÜZ[N+1](b), Z[0](a), 0, N) ‚àíP,
(6.26)
where
#( ÀÜZ[N+1](b), Z[0](a), 0, N) =
N

k=0
#k( ÀÜZ[N+1](b), Z[0](a))
(6.27)
and, with m, ÀÜm, and Œª0 given by (6.22) and (6.20),
P = ÀÜm ‚àím = #( ÀÜZ[N+1](Œª), Z[0](Œª), 0, N),
Œª < Œª0.
(6.28)
Proof For the proof we use Theorem 4.56 (see (4.107)) and connections (6.23)
and (6.24) derived above.
‚äì‚äî
Remark 6.3 Recall that according to Lemma 4.55 the relative oscillation num-
bers (6.25) can be speciÔ¨Åed at the endpoints k = 0 and k = N as follows:
#0( ÀÜZ[N+1](b), Z[0](a)) = Œº‚àó ÀÜY [N+1]
0
(b), ÀÜS‚àí1
0 (b) S0(a) (0 I)T 
‚àíŒº
 ÀÜS0(b) (0 I)T, S0(a) (0 I)T 
,
(6.29)
#N( ÀÜZ[N+1](b), Z[0](a)) = Œº
 ÀÜSN(b) Y [0]
N (a), ÀÜSN(b) S‚àí1
N (a) (0 I)T 
‚àíŒº‚àó ÀÜS‚àí1
N (b) (0 I)T, S‚àí1
N (a) (0 I)T 
.
(6.30)
In particular, under assumptions (5.3), (6.5) for the case S0(Œª) ‚â°ÀÜS0(Œª) (respec-
tively, for SN(Œª) ‚â°
ÀÜSN(Œª)) we have that Œº ÀÜS0(b) (0 I)T, S0(a) (0 I)T  = 0
(respectively, Œº‚àó ÀÜS‚àí1
N (b) (0 I)T, S‚àí1
N (a) (0 I)T  = 0); see the proof of Theorem 6.4
below.
For the case when Sk(Œª) ‚â°
ÀÜSk(Œª) for k ‚àà[0, N]Z, we have the so-called
renormalized oscillation theorem for (E), which is a corollary to Theorem 6.2.

6.1
Relative Oscillation Theory
403
Theorem 6.4 (Renormalized Oscillation Theorem) Assume that conditions (5.3)
and (6.18) hold for system (5.1). Let Z[0](Œª) and Z[N+1](Œª) be symplectic fun-
damental matrices of (5.1) such that Y [0](Œª) = Z[0](Œª) (0 I)T and Y [N+1](Œª) =
Z[N+1](Œª) (0 I)T are the principal solutions of this system at k = 0 and k = N +1,
respectively. Then for any a, b ‚ààR with a < b the number of Ô¨Ånite eigenvalues of
problem (E) in (a, b] is given by the formula
#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b} =
N

k=0
Œº

‚ü®Gk(a, b)‚ü©, ‚ü®Gk+1(a, b)‚ü©

,
Gk(a, b) := [Z[N+1]
k
(b)]‚àí1Z[0]
k (a).
‚é´
‚é™‚é¨
‚é™‚é≠
(6.31)
Moreover, with Œª1 = min œÉ we have
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} =
N

k=0
Œº

‚ü®Gk(Œª, b)‚ü©, ‚ü®Gk+1(Œª, b)‚ü©

,
Gk(Œª, b) := [Z[N+1]
k
(b)]‚àí1Z[0]
k (Œª),
Œª < Œª1.
‚é´
‚é™‚é¨
‚é™‚é≠
(6.32)
Proof Remark that for Sk(Œª) ‚â°
ÀÜSk(Œª) for k ‚àà[0, N]Z, we have according to
Lemma 5.105 that Œº

‚ü®Sk(b)‚ü©, ‚ü®Sk(a)‚ü©

= 0 for k ‚àà[0, N]Z, where assump-
tion (6.18) plays a key role. Moreover, for the case Sk(Œª) ‚â°ÀÜSk(Œª) for k ‚àà[0, N]Z,
the left-hand side of (6.26) takes the form of the left-hand side of (6.31), while the
constant P = 0 by (6.28). Then the proof of (6.31) follows from (6.25) and (6.26).
Formula (6.32) is derived from (6.31) by taking the limit a ‚Üí‚àí‚àûand using that
the spectrum of (E) under conditions (5.3) and (6.18) is bounded.
‚äì‚äî
Remark 6.5
(i) Note that by (4.148) in Theorem 4.56, we have
#( ÀÜZ[N+1](b), Z[0](a), 0, N) = ‚àí#(Z[N+1](a), ÀÜZ[0](b), 0, N).
Then one can replace the relative oscillation numbers in (6.26) by
‚àí#(Z[N+1](a), ÀÜZ[0](b), 0, N) = ‚àí
N

k=0
#k(Z[N+1](a), ÀÜZ[0](b)),
where, according to DeÔ¨Ånition 4.44, instead of (6.25) we have
#k(Z[N+1](a), ÀÜZ[0](b))
= Œº

‚ü®ÀúGk(a, b)‚ü©, ‚ü®ÀúGk+1(a, b)‚ü©

‚àíŒº

‚ü®Sk(a)‚ü©, ‚ü®ÀÜSk(b)‚ü©

= Œº

‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©

‚àíŒº

‚ü®ÀúGk+1(a, b)‚ü©, ‚ü®ÀúGk(a, b)‚ü©

,
‚é´
‚é™‚é¨
‚é™‚é≠
(6.33)

404
6
Miscellaneous Topics on Symplectic Systems
with
ÀúGk(a, b) := [Z[N+1]
k
(a)]‚àí1 ÀÜZ[0]
k (b).
In particular, this reformulation leads to the representation
#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b} =
N

k=0
Œº‚ü®ÀúGk+1(a, b)‚ü©, ‚ü®ÀúGk(a, b)‚ü©,
ÀúGk(a, b) := [Z[N+1]
k
(a)]‚àí1Z[0]
k (b),
‚é´
‚é™‚é¨
‚é™‚é≠
(6.34)
which is equivalent to (6.31).
(ii) We recall that according to Remark 4.46(i) the value of the comparative
index Œº‚ü®ÀúGk+1(a, b)‚ü©, ‚ü®ÀúGk(a, b)‚ü© in (6.33) and (6.34) presents the multiplic-
ities of forward focal points of the transformed 4n-dimensional (Wronskian)
system (4.112) associated with (5.1) and (6.1). Similarly, the comparative index
Œº‚ü®Gk(a, b)‚ü©, ‚ü®Gk+1(a, b)‚ü© in (6.26) and (6.31) is equal to the multiplicity of
backward focal points of system (4.115) (see Remark 4.46(iii)). Recall also
that by Remark 4.46(ii), (iv) both comparative indices are presented by (4.113)
and (4.116), where the Ô¨Årst addends are associated with transformed 2n-
dimensional (Wronskian) systems (4.114) and (4.117), i.e., with the oscillations
of the Wronskian of Y(Œª) and ÀÜY(Œª). In subsequent sections we will present
some special cases, when formulas (6.25) and (6.33) can be simpliÔ¨Åed by using
the special structure of the symplectic coefÔ¨Åcient matrices Sk(Œª) and ÀÜSk(Œª). In
particular, in these cases they are associated with the oscillation of conjoined
bases of the 2n-dimensional Wronskian systems (4.114) and (4.117).
6.1.3
Lower Block-Triangular Perturbation
In this subsection we investigate the most closely related matrix analog of the
results for Sturm-Liouville problems (6.9), (6.10). Consider the pair of eigenvalue
problems (6.17) with the Dirichlet boundary conditions, whose coefÔ¨Åcient matrices
obey the conditions
Ak(Œª) = ÀÜAk(Œª) ‚â°Ak,
Bk(Œª) = ÀÜBk(Œª) ‚â°Bk,
k ‚àà[0, N]Z.
(6.35)
Then we have that conditions (6.18) are satisÔ¨Åed and under assumptions (5.3)
and (6.5) one can apply Theorems 6.2 and 6.4 to this special case. It follows
from (6.35) that for arbitrary Ô¨Åxed Œª := Œ≤ we have
Sk(Œª) S‚àí1
k (Œ≤) =

I
0
Qk(Œª, Œ≤) I

,
ÀÜSk(Œª) ÀÜS‚àí1
k (Œ≤) =

I
0
ÀÜQk(Œª, Œ≤) I

,

6.1
Relative Oscillation Theory
405
or (compare with (5.239) where Œ≤ = 0)
Sk(Œª) =

I
0
Qk(Œª, Œ≤) I

Sk(Œ≤),
ÀÜSk(Œª) =

I
0
ÀÜQk(Œª, Œ≤) I

ÀÜSk(Œ≤),
(6.36)
where the symmetric matrices Qk(Œª, Œ≤) and ÀÜQk(Œª, Œ≤) (see Sect. 1.6.1) can be
expressed in terms of the blocks of Sk(a) and ÀÜSk(b) as
Qk(Œª, Œ≤) = Ck(Œª) DT
k (Œ≤) ‚àíDk(Œª) CT
k (Œ≤) = Pk(Œª) J PT
k (Œ≤),
Pk(Œª) :=

Ck(Œª) Dk(Œª)

,
ÀÜQk(Œª, Œ≤) = ÀÜCk(Œª) ÀÜDT
k (Œ≤) ‚àíÀÜDk(Œª) ÀÜCT
k (Œ≤) = ÀÜPk(Œª) J ÀÜPT
k (Œ≤),
ÀÜPk(Œª) :=

ÀÜCk(Œª) ÀÜDk(Œª)

.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(6.37)
Moreover, for two arbitrary values of Œª = a and Œª = b, we have
Sk(a) ÀÜS‚àí1
k (b) =

I
0
Qk(a, b) I

,
(6.38)
where the symmetric matrix Qk(a, b) = QT
k (a, b) is given by
Qk(a, b) = Ck(a) ÀÜDT
k (b) ‚àíDk(a) ÀÜCT
k (b) = Pk(a) J ÀÜPT
k (b)
= Qk(a, Œ≤) ‚àíÀÜQk(b, Œ≤) + Pk(Œ≤) J ÀÜPT
k (Œ≤),

(6.39)
with Qk(Œª, Œ≤) and ÀÜQk(Œª, Œ≤) deÔ¨Åned by (6.37). In particular,
Qk(a, b) = Pk(a) J PT
k (b) = Qk(a, Œ≤) ‚àíQk(b, Œ≤),
for the case Sk(Œª) ‚â°ÀÜSk(Œª),
k ‚àà[0, N]Z.

(6.40)
The matrices (Sk(Œª)) and ( ÀÜSk(Œª)) in (5.3) and (6.5) for the case (6.35) take the
form (see (1.193))
(Sk(Œª)) = diag{ ÀôPk(Œª) J T PT
k (Œª), 0},
( ÀÜSk(Œª)) = diag{ ÀôÀÜPk(Œª) J T ÀÜPT
k (Œª), 0}.
Then the monotonicity conditions will be satisÔ¨Åed under the assumption
ÀôPk(Œª) J PT
k (Œª) = ÀôQk(Œª, Œ≤) ‚â§0,
ÀôÀÜPk(Œª) J ÀÜPT
k (Œª) = ÀôÀÜQk(Œª, Œ≤) ‚â§0,

k ‚àà[0, N]Z,
Œª ‚ààR.
(6.41)

406
6
Miscellaneous Topics on Symplectic Systems
For the special linear dependence on Œª (see (5.239) and (5.240)), we then have
Sk(Œª) =

I
0
‚àíŒªWk I
 Ak Bk
Ck Dk

,
ÀÜSk(Œª) =

I
0
‚àíŒª ÀÜWk I
 Ak Bk
ÀÜCk
ÀÜDk

,
(6.42)
so that the matrices Sk(Œª) and ÀÜSk(Œª) obey (6.35), (6.38) for any a, b ‚ààR, and
Qk(a, b) = b ÀÜWk ‚àíaWk + Ck ÀÜDT
k ‚àíDk ÀÜCT
k .
(6.43)
In particular,
Qk(a, b) = (b ‚àía)Wk
for Sk(Œª) ‚â°ÀÜSk(Œª),
k ‚àà[0, N]Z.
(6.44)
For the scalar case of two Sturm-Liouville difference equations (6.9) and (6.10),
which are rewritten in the matrix form (2.36), we then have
Sk(Œª) =

1
1/rk
pk ‚àíŒª 1 + (pk ‚àíŒª)/rk

,
ÀÜSk(Œª) =

1
1/rk
ÀÜpk ‚àíŒª 1 + ( ÀÜpk ‚àíŒª)/rk

.
(6.45)
Then, with the number qk(a, b) from DeÔ¨Ånition 6.1,
Qk(a, b) = b ‚àía + pk ‚àíÀÜpk = qk(a, b).
Recall that, as we mentioned above, the relative oscillation theory for prob-
lems (6.17) under assumption (6.35) is the most closely related analog of the
results for Sturm-Liouville problems (6.9) and (6.10). Assume that Z(a) and ÀÜZ(b)
are symplectic fundamental matrices of systems (5.1) and (6.1) associated with
conjoined bases Y(Œª) and ÀÜY(Œª) of these systems according to (3.14). Then we have
the connections (see (4.100))
w( ÀÜYk(b), Yk(a)) = ‚àí(I 0) ÀÜZ‚àí1
k (b) Yk(a),
w(Yk(a), ÀÜYk(b)) = ‚àí(I 0) Z‚àí1
k (a) ÀÜYk(b),
w( ÀÜYk(b), Yk(a)) = ‚àíwT (Yk(a), ÀÜYk(b)).
‚é´
‚é™‚é¨
‚é™‚é≠
(6.46)
We will show that for the case (6.35) the role of generalized zeros of the Wronskian
is played by focal points of the transformed conjoined bases
ÀÜZ‚àí1
k (b) Yk(a),
Z‚àí1
k (a) ÀÜYk(b)
of the discrete symplectic systems (4.114) and (4.117) rewritten in the form
ÀúYk+1 = ÀÜZ‚àí1
k+1(b) Sk(a) ÀÜS‚àí1
k (b) ÀÜZk+1(b) ÀúYk,
ÀúYk = ÀÜZ‚àí1
k (b) Yk(a),
(6.47)
¬ØYk+1 = Z‚àí1
k+1(a) ÀÜSk(b) S‚àí1
k (a) Zk+1(a) ¬ØYk,
¬ØYk = Z‚àí1
k (a) ÀÜYk(b).
(6.48)

6.1
Relative Oscillation Theory
407
Assume (6.35), then by (6.38) the blocks Bk(a, b) and ÀúBk(a, b) in the right
upper corner of the symplectic matrices in (6.47) and (6.48) have the form
Bk(a, b) = ‚àíÀÜXT
k+1(b) Qk(a, b) ÀÜXk+1(b),
ÀúBk(a, b) = XT
k+1(a) Qk(a, b) Xk+1(a),

(6.49)
while systems (6.47) and (6.48) take the form
‚àíJ  ÀúYk = ÀÜZT
k+1(b) diag{‚àíQk(a, b), 0} ÀÜZk+1(b) ÀúYk,
ÀúYk = ÀÜZ‚àí1
k (b) Yk(a),
(6.50)
‚àíJ  ¬ØYk = ZT
k+1(a) diag{Qk(a, b), 0} Zk+1(a) ¬ØYk,
¬ØYk = Z‚àí1
k (a) ÀÜYk(b).
(6.51)
For systems (5.1) and (6.1) under restriction (6.35), the formulas for the relative
oscillation numbers in (6.26) and (6.31) are simpliÔ¨Åed as follows.
Lemma 6.6 Suppose that the matrices S(Œª) and ÀÜS(Œª) in (5.1) and (6.1) sat-
isfy (6.35) and that Z(Œª) and ÀÜZ(Œª) are symplectic fundamental matrices of (5.1)
and (6.1) associated with conjoined bases Y(Œª) and ÀÜY(Œª) of (5.1) and (6.1) such
that
Z(Œª) (0 I)T = Y(Œª) =
X(Œª)
U(Œª)

,
ÀÜZ(Œª) (0 I)T = ÀÜY(Œª) =
 ÀÜX(Œª)
ÀÜU(Œª)

.
Then the relative oscillation numbers (4.109) are given by the formulas
#k( ÀÜZ(b), Z(a)) = m‚àó(Z‚àí1
k (a) ÀÜYk(b)) ‚àíind ÀúBk(a, b)
= ind Bk(a, b) ‚àím( ÀÜZ‚àí1
k (b) Yk(a)),

(6.52)
where the matrices Bk(a, b) and ÀúBk(a, b) are given by (6.49), and where the quan-
tities m‚àó(Z‚àí1
k (a) ÀÜYk(b)) and m( ÀÜZ‚àí1
k (a) Yk(b)) represent the number of backward
focal points in [k, k + 1) and the number of forward focal points in (k, k + 1] of
the conjoined bases Z‚àí1(a) ÀÜY(b) and ÀÜZ‚àí1(a) Y(b) of systems (6.51) and (6.50),
respectively. In addition, we have the estimate
|#k( ÀÜZ(b), Z(a))| ‚â§min
(
rankBk(a, b), rank ÀúBk(a, b)
)
‚â§n.
(6.53)
Proof The matrices Sk(Œª) and ÀÜSk(Œª) in (5.1) and (6.1) satisfy (6.38), and then
assumption (4.107) of Lemma 4.43 is also satisÔ¨Åed. Using (4.108) and incorpo-
rating (4.16) in Lemma 4.8, we see that
Œº ÀÜZ‚àí1
k (b) Zk(a) (0 I)T, ÀÜZ‚àí1
k+1(b) Zk+1(a) (0 I)T  = m‚àó(Z‚àí1
k (a) ÀÜYk(b))

408
6
Miscellaneous Topics on Symplectic Systems
(compare with Remark 4.46(iii)). So we obtain the proof of the Ô¨Årst identity
in (6.52).
To prove the second identity, we use (4.118). Indeed, replacing the roles Y and ÀÜY
in the Ô¨Årst (already proved) identity (6.52), we obtain by (4.118) that
#k( ÀÜZ(b), Z(a)) =  rankw(Yk(a), ÀÜYk(b)) ‚àí#k(Z(a), ÀÜZ(b))
=  rankw(Yk(a), ÀÜYk(b)) ‚àím‚àó( ÀÜZ‚àí1
k (b) Yk(a))
+ ind [‚àíÀÜXT
k+1(b) Qk(a, b) ÀÜXk+1(b)]
= ind [‚àíÀÜXT
k+1(b) Qk(a, b) ÀÜXk+1(b)] ‚àím( ÀÜZ‚àí1
k (b) Yk(a)),
where, in addition, Proposition 4.4(vi) (see (4.9)) is used.
For the proof of estimate (6.53), we incorporate that the matrices Bk(a, b)
and ÀúBk(a, b) given by (6.49) are the blocks of the symplectic matrices in (6.47)
and (6.48) in the right upper corner. Then by Proposition 4.4(v)
m‚àó(Z‚àí1
k (a) ÀÜYk(b)) ‚â§rank ÀúBk(a, b),
m( ÀÜZ‚àí1
k (b) Yk(a)) ‚â§rankBk(a, b).
Taking in mind that ind ÀúBk(a, b)
‚â§
rank ÀúBk(a, b) and ind Bk(a, b)
‚â§
rankBk(a, b), we derive estimate (6.53). The proof is complete.
‚äì‚äî
As it was mentioned above, it is possible to relate the number (6.52) and the
notion of a weighted generalized zero of the Wronskian for solutions of second-
order Sturm-Liouville difference equations (6.9) and (6.10) presented in Sect. 6.1.1.
Proposition 6.7 The Wronskian of two nontrivial solutions xk(a) and ÀÜxk(b) of (6.9)
and (6.10) has a weighted generalized zero according to DeÔ¨Ånition 6.1 if and only
if the relative oscillation number deÔ¨Åned in Lemma 6.6 for n = 1 with Qk(a, b) :=
qk(a, b) takes the value ¬±1.
Proof Note that by (6.52) #k( ÀÜZ(b), Z(a)) = 1 if and only if m‚àó(Z‚àí1
k (a) ÀÜYk(b)) = 1
and ind ÀúBk(a, b) = 0. According to Remark 4.14(iii), the case m‚àó(Z‚àí1
k (a) ÀÜYk(b)) =
1 is equivalent to the existence of a generalized zero in [k, k + 1) of the solution
Z‚àí1
k (a) ÀÜYk(b) for n = 1. Using connection (6.46) we have that the Wronskian
wk := w(Yk, ÀÜYk) is associated with the upper block of the solution Z‚àí1
k (a) ÀÜYk(b)
(up to the sign, which is not important). Then by Remark 4.14(iii), we have that
m‚àó(Z‚àí1
k (a) Yk(b) = 1 if and only if wk = 0, wk+1 Ã∏= 0, or wkwk+1 ÀúBk(a, b) < 0,
where ÀúBk(a, b) = x2
k+1qk(a, b) according to (6.49). Then, under the assump-
tion qk(a, b) > 0, the last condition is equivalent with wkwk+1 < 0 (note
that we use ind ÀúBk(a, b) = 0, and the case ÀúBk(a, b) = 0 is excluded by
Remark 4.14(iii)). Thus, we have proved that the conditions m‚àó(Z‚àí1
k (a) ÀÜYk(b)) = 1
and ind ÀúBk(a, b) = 0 are equivalent to the Ô¨Årst case in DeÔ¨Ånition 6.1.

6.1
Relative Oscillation Theory
409
In a similar way, we have that #k( ÀÜZ(b), Z(a)) = ‚àí1 if and only if the two
conditions m( ÀÜZ‚àí1
k (b)Yk(a)) = 1 and ind Bk(a, b) = 0 hold. By Remark 4.14(iii),
we have m( ÀÜZ‚àí1
k (b) Yk(a))
=
1 if and only if wk+1
=
0, wk
Ã∏=
0, or
wkwk+1Bk(a, b) < 0, where Bk(a, b) = ‚àíÀÜx2
k+1qk(a, b) according to (6.49).
Then, under the assumption qk(a, b) < 0, the last condition is equivalent with
wkwk+1 < 0. Thus, we have proved that #k( ÀÜZ(b), Z(a)) = ‚àí1 or the two
conditions m( ÀÜZ‚àí1
k (b)Yk(a)) = 1, ind Bk(a, b) = 0 are equivalent to the second
case in DeÔ¨Ånition 6.1.
‚äì‚äî
Based on Lemma 6.6, one can specialize the results of Theorem 6.2 as follows.
Theorem 6.8 Assume that conditions (6.35) and (6.41) hold for systems (5.1) and
(6.1). Let Z[0](Œª) and ÀÜZ[N+1](Œª) be symplectic fundamental matrices of (5.1)
and (6.1) associated with the principal solutions Y [0](Œª) = Z[0](Œª) (0 I)T and
ÀÜY [N+1](Œª) =
ÀÜZ[N+1](Œª) (0 I)T of these systems at k = 0 and k = N + 1,
respectively. Then we have that all the formulas in Theorem 6.2 hold with the relative
oscillation numbers deÔ¨Åned by (6.52), (6.49), (6.39), where ÀÜZ(Œª) := ÀÜZ[N+1](Œª) and
Z(Œª) := Z[0](Œª).
Proof For the proof we use Theorem 6.2 and Lemma 6.6.
‚äì‚äî
In a similar way, we derive the special case of Theorem 6.4.
Theorem 6.9 Assume that conditions (6.35) and (6.41) hold for system (5.1). Let
Z[0](Œª) and Z[N+1](Œª) be symplectic fundamental matrices of (5.1) such that
Y [0](Œª) = Z[0](Œª) (0 I)T and Y [N+1](Œª) = Z[N+1](Œª) (0 I)T are the principal
solutions of this system at k = 0 and k = N + 1, respectively. Then for any
a, b ‚ààR with a < b we have that the number of Ô¨Ånite eigenvalues of problem (E)
in (a, b] is counted by the number of backward focal points of the conjoined basis
[Z[0](a)]‚àí1Y [N+1](b) of system (6.51) in the interval [0, N + 1), i.e.,
#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b} = l‚àó[Z[0](a)]‚àí1Y [N+1](b), 0, N + 1,
(6.54)
where system (6.51) is considered for the case Sk(Œª) ‚â°ÀÜSk(Œª) with Zk(a) := Z[0]
k (a)
and Qk(a, b) ‚â•0 is given by (6.40). Moreover
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} = l‚àó
[Z[0](Œª)]‚àí1Y [N+1](b), 0, N + 1

,
Œª < Œª1,
(6.55)
where Œª1 = min œÉ.
Proof We use Theorem 6.4 for the case (6.35). Remark that for Sk(Œª) ‚â°ÀÜSk(Œª),
k ‚àà[0, N]Z, according to (6.40) and (6.41)
Qk(a, b) ‚â•0,
a, b ‚ààR, a ‚â§b,
(6.56)

410
6
Miscellaneous Topics on Symplectic Systems
Then the relative oscillation number in (6.52) takes the form (here we use that
ÀúBk(a, b) ‚â•0 and Bk(a, b) ‚â§0)
#k( ÀÜZ(b), Z(a)) = m‚àó(Z[0] ‚àí1
k
(a) Y [N+1]
k
(b))
= rankBk(a, b) ‚àím(Z[N+1] ‚àí1
k
(b) Y [0]
k (a)),
Bk(a, b) = ‚àíX[N+1] T
k+1
(b) Qk(a, b) X[N+1]
k+1
(b),
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(6.57)
where Z[0]
k (Œª) and Z[N+1](Œª) are symplectic fundamental matrices of system (5.1)
associated with the principal solutions Y [0]
k (Œª) and Y [N+1]
k
(Œª). Substituting the Ô¨Årst
formula in (6.57) into (6.31), we derive (6.55).
‚äì‚äî
Remark 6.10
(i) Recall that according to Remark 6.5(i) one can modify the representations of
the relative oscillation numbers using (6.33). For the special case under the
consideration, we have instead of (6.33) the formula
#k(Z[N+1](a), ÀÜZ[0](b)) = m‚àó([ ÀÜZ[0]
k (b)]‚àí1 Y [N+1]
k
(a)) ‚àíind [Bk(a, b)]
= ind [ ÀúBk(a, b)] ‚àím([Z[N+1]
k
(a)]‚àí1 ÀÜY [0]
k (b)),

(6.58)
where the matrices Bk(a, b) and ÀúBk(a, b) are given by (6.49) with ÀÜX(b) :=
ÀÜX[0](b) and X(a) := X[N+1](a). In particular, this reformulation leads to the
representation
#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b} = l[Z[N+1](a)]‚àí1Y [0](b), 0, N + 1,
(6.59)
which is equivalent to (6.54) and presents #{ŒΩ
‚ààœÉ | a
< ŒΩ
‚â§b} in
terms of the multiplicities of forward focal points of the conjoined basis
[Z[N+1](a)]‚àí1Y [0](b) of the transformed system (6.51).
(ii) For the special linear dependence on parameter Œª according to (6.42), (6.43),
(6.44), one can use Theorem 5.93 and property (4.147) in Theorem 4.56 to
derive the formulas
#{ŒΩ ‚ààÀÜœÉ | ŒΩ < b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ < a} = #( ÀÜZ[0](b), Z[N+1](a), 0, N) ‚àíP‚àó,
(6.60)
where
P‚àó= ÀÜm‚àó‚àím‚àó= #( ÀÜZ[0](Œª), Z[N+1](Œª), 0, N),
Œª < Œª0.
(6.61)
Similarly, instead of (6.54) we have
#{ŒΩ ‚ààœÉ | a ‚â§ŒΩ < b} = l‚àó
[Z[N+1](a)]‚àí1Y [0](b), 0, N + 1

.
(6.62)
Formulas (6.60), (6.61), and (6.62) can be also derived directly from (6.26),
(6.28), and (6.31) by using Lemma 4.47(iii).

6.1
Relative Oscillation Theory
411
6.1.4
Matrix Sturm-Liouville Eigenvalue Problems
In this subsection we consider the discrete matrix Sturm-Liouville spectral problems
(see Example 5.36)
(Rk(Œª) xk(Œª)) ‚àíQk(Œª) xk+1(Œª) = 0,
k ‚àà[0, N ‚àí1]Z,
x0(Œª) = 0 = xN+1(Œª),
det Rk(Œª) Ã∏= 0,
k ‚àà[0, N]Z,

(6.63)
and
( ÀÜRk(Œª) ÀÜxk(Œª)) ‚àíÀÜQk(Œª) ÀÜxk+1(Œª) = 0,
k ‚àà[0, N ‚àí1]Z,
ÀÜx0(Œª) = 0 = ÀÜxN+1(Œª),
det ÀÜRk(Œª) Ã∏= 0,
k ‚àà[0, N]Z,

(6.64)
where xk(Œª) ‚ààRn for n ‚â•1 and Œª ‚ààR is the spectral parameter and the
real symmetric n √ó n matrix-valued functions Rk(Œª), ÀÜRk(Œª), Qk(Œª), ÀÜQk(Œª) for
k ‚àà[0, N]Z are piecewise continuously differentiable in the variable Œª and obey
the conditions
ÀôRk(Œª) ‚â§0,
ÀôQk(Œª) ‚â§0,
k ‚àà[0, N]Z,
(6.65)
ÀôÀÜRk(Œª) ‚â§0,
ÀôÀÜQk(Œª) ‚â§0,
k ‚àà[0, N]Z.
(6.66)
According to Example 5.36, conditions (6.65) and (6.65) together with the nonsin-
gularity assumptions det Rk(Œª) Ã∏= 0 and det ÀÜRk(Œª) Ã∏= 0 imply (5.3), (6.5), (6.18).
Then one can apply Theorems 6.2 and 6.4 to this special case. As in the previous
subsection, we reÔ¨Åne formulas for the relative oscillation numbers using the
special structure of the symplectic matrices Sk(Œª) and ÀÜSk(Œª) associated with (6.63)
and (6.64) (see Sect. 2.1.2), i.e.,
Sk(Œª) =

I
R‚àí1
k (Œª)
Qk(Œª) I + Qk(Œª) R‚àí1
k (Œª)

= Lk(Œª) Hk(Œª),
Lk(Œª) :=

I
0
Qk(Œª) I

,
Hk(Œª) :=
I R‚àí1
k (Œª)
0
I

,
‚é´
‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é≠
(6.67)
and
ÀÜSk(Œª) =

I
ÀÜR‚àí1
k (Œª)
ÀÜQk(Œª) I + ÀÜQk(Œª) ÀÜR‚àí1
k (Œª)

= ÀÜLk(Œª) ÀÜHk(Œª),
ÀÜLk(Œª) :=

I
0
ÀÜQk(Œª) I

,
ÀÜHk(Œª) :=

I ÀÜR‚àí1
k (Œª)
0
I

.
‚é´
‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é≠
(6.68)
Recall that spectral problems (6.63) and (6.64) are the matrix analogs of the Sturm-
Liouville problems (6.9) and (6.10) with different coefÔ¨Åcients rk(Œª) and ÀÜrk(Œª) and

412
6
Miscellaneous Topics on Symplectic Systems
with the Wronskian wk(x, ÀÜx) = ‚àírkxk+1 ÀÜxk + ÀÜrkxk ÀÜxk+1 (compare with (6.11)). The
relative oscillation theory for (6.9) and (6.10) with rk Ã∏= ÀÜrk and pk Ã∏= ÀÜpk is presented
in [21].
By (6.67) and (6.68), we see that problems (6.63) and (6.64) under the additional
assumption Rk(Œª) ‚â°ÀÜRk(Œª) ‚â°Rk obey conditions (6.35). However, in the general
case of nonconstant Rk(Œª) and/or ÀÜRk(Œª), the theory developed in Sect. 6.1.3 needs
to be generalized to the case when the matrices Rk(Œª) and ÀÜRk(Œª) are different.
Consider two conjoined bases Y(Œª) = X(Œª)
U(Œª)
 and ÀÜY(Œª) =  ÀÜX(Œª)
ÀÜU(Œª)
 of the
symplectic systems in (6.17) associated with (6.63) and (6.64), where we have the
connections (see Sect. 2.1.2)
Uk(Œª) = Rk(Œª) Xk(Œª),
ÀÜUk(Œª) = ÀÜRk(Œª)  ÀÜXk(Œª),
k ‚àà[0, N]Z,
UN+1(Œª) = UN(Œª) + QN(Œª) XN+1(Œª),
ÀÜUN+1(Œª) = ÀÜUN(Œª) + ÀÜQN(Œª) ÀÜXN+1(Œª).
‚é´
‚é™‚é¨
‚é™‚é≠
(6.69)
Note that the coefÔ¨Åcients QN(Œª) and ÀÜQN(Œª) are not needed in equations (6.63)
and (6.64), but for convenience we deÔ¨Åne them at k = N such that (6.65) and (6.66)
hold. In Remark 6.12 we will show that the results of this section do not depend on
the deÔ¨Ånition of QN(Œª) and ÀÜQN(Œª).
Recall that for two Ô¨Åxed values Œª = a and Œª = b (a, b ‚ààR) and k ‚àà[0, N +1]Z,
the Wronskian (3.2) of Yk(a) and ÀÜYk(b) has the form
wk(Y(a), ÀÜY(b)) := wk(a, b) = XT
k (a) ÀÜUk(b) ‚àíUT
k (a) ÀÜXk(b).
(6.70)
Moreover, it satisÔ¨Åes for k ‚àà[0, N]Z the equation (see (4.99))
‚àíwk(a, b) = (XT
k (a)) [Rk(a) ‚àíÀÜRk(b)]  ÀÜXk(b)
+XT
k+1(a) [Qk(a) ‚àíÀÜQk(b)] ÀÜXk+1(b).

(6.71)
For the convenience of the presentation of the subsequent results, we introduce
the notation for the number of backward focal points of the conjoined basis Z‚àí1 ÀÜY
associated with the Wronskian by (6.46) using the notation
m‚àó(wk, wk+1) := m‚àó(Z‚àí1
k
ÀÜYk) = Œº
 ÀÜZ‚àí1
k Yk, ÀÜZ‚àí1
k+1Yk+1

.
Then we have using DeÔ¨Ånition 4.11
m‚àó(wk, wk+1) = rankMk + ind Pk,
Mk := (I ‚àíw‚Ä†
kwk) wT
k+1, Tk := I ‚àíM‚Ä†
kMk, Pk := Tkwk+1w‚Ä†
k CkTk,
Ck := ( ÀÜZ‚àí1
k Yk)TJ ÀÜZ‚àí1
k+1Yk+1 = Y T
k J ÀÜS‚àí1
k SkYk = Y T
k+1J Sk ÀÜS‚àí1
k Yk+1.
‚é´
‚é™‚é¨
‚é™‚é≠
(6.72)

6.1
Relative Oscillation Theory
413
Note that according to Proposition 4.4(v), we have the estimate
m‚àó(wk, wk+1) ‚â§rank Ck ‚â§n.
(6.73)
As we already mentioned above, for the case Rk(Œª) ‚â°ÀÜRk(Œª) ‚â°Rk, one can
apply Lemma 6.6 to evaluate the relative oscillation numbers for problems (6.63)
and (6.64). Here (for convenience) we reformulate this lemma in terms of the
coefÔ¨Åcients Qk(Œª) and ÀÜQk(Œª) in (6.63) and (6.64).
Lemma 6.11 (Case I) Assume that for the two spectral problems (6.63), (6.65)
and (6.64), (6.66), the matrices Rk(Œª) and ÀÜRk(Œª) obey the conditions
ÀôRk(Œª) = ÀôÀÜRk(Œª) = 0,
Rk ‚â°ÀÜRk,
k ‚àà[0, N]Z.
(6.74)
Then the relative oscillation numbers (4.109) have the form
#I
k( ÀÜZ(b), Z(a)) = m‚àó(wk(a, b), wk+1(a, b)) ‚àíind Ck(a, b),
Ck(a, b) = XT
k+1(a) [Qk(a) ‚àíÀÜQk(b)] Xk+1(a),

(6.75)
where m‚àó(wk(a, b), wk+1(a, b)) := m‚àó(Z‚àí1
k (a) ÀÜYk(b)) is the number of backward
focal points of the conjoined basis Z‚àí1
k (a) ÀÜYk(b) according to (6.72) with the matrix
Ck := Ck(a, b).
Proof We use formula (6.52) putting Ck(a, b) := ÀúBk(a, b).
‚äì‚äî
Remark 6.12 Note that in the deÔ¨Ånition of symplectic systems (6.67) and (6.68)
one can put QN(Œª) = ÀÜQN(Œª) = 0 and then #I
N( ÀÜZ(b), Z(a)) = 0. However for the
case when ÀÜZk(b) := ÀÜZ[N+1]
k
(b), we have #I
N( ÀÜZ(b), Z(a)) = 0 for any choice of
QN(Œª) and ÀÜQN(Œª). Indeed, for this case by (6.49), the matrix BN(a, b) = 0, and
then #I
N( ÀÜZ(b), Z(a)) = 0 by estimate (6.53).
Lemma 6.13 (Case II) Assume that for the two spectral problems (6.63), (6.65)
and (6.64), (6.66), the matrices Qk(Œª) and ÀÜQk(Œª) obey the conditions
ÀôQk(Œª) = ÀôÀÜQk(Œª) = 0,
Qk ‚â°ÀÜQk,
k ‚àà[0, N]Z.
(6.76)
Then the relative oscillation numbers (4.109) take the form
#II
k ( ÀÜZ(b), Z(a)) = m‚àó(wk(a, b), wk+1(a, b)) ‚àíind ÀúCk(a, b) + Pk,
ÀúCk(a, b) = UT
k (a) [ ÀÜR‚àí1
k (b) ‚àíR‚àí1
k (a)] Uk(a),
Uk(Œª) := Rk(Œª) Xk(Œª).

(6.77)
Here m‚àó(wk(a, b), wk+1(a, b)) := m‚àó(Z‚àí1
k (a) ÀÜYk(b)) is the number of backward
focal points of Z‚àí1
k (a) ÀÜYk(b) given by (6.72) with Ck := ÀúCk(a, b), and Pk is the

414
6
Miscellaneous Topics on Symplectic Systems
constant (with respect to Œª) deÔ¨Åned by
Pk := ind ÀÜRk(Œª0) ‚àíind Rk(Œª0),
Œª0 ‚ààR.
(6.78)
Proof Note that for case (6.76) matrices (6.67), (6.68) obey the condition
ÀÜS‚àí1
k (b) Sk(a) = ÀÜH ‚àí1
k (b) Hk(a) =

I R‚àí1
k (a) ‚àíÀÜR‚àí1
k (b)
0
I

.
(6.79)
The symplectic upper block-triangular factors Hk(a) and ÀÜHk(b) in (6.79) can be
represented in the form
Hk(a) = ‚àíJ Kk(a) J ,
ÀÜHk(b) = ‚àíJ ÀÜKk(b) J ,
where Kk(a) and
ÀÜKk(b) are the symplectic lower block-triangular matrices.
Assumption (6.76) then implies that Lk(a) ‚â°ÀÜLk(b) = Lk in (6.67) and (6.68).
Consider operator (3.56) introduced in Sect. 3.3.1 (see also (4.102)), i.e.,
L(Y, ÀÜY , S, ÀÜS) := Œº( ÀÜS ÀÜY, ÀÜS (0 I)T ) ‚àíŒº(SY, S (0 I)T ) + Œº(SY, ÀÜS ÀÜY) ‚àíŒº(Y, ÀÜY ).
(6.80)
Applying the multiplicative property of this operator in Lemma 3.22(ii) (with the
data p := 4, W1 = ÀÜW1 := J , W2 := Kk(a), ÀÜW2 := ÀÜKk(b), W3 = ÀÜW3 := ‚àíJ ,
W4 = ÀÜW4 := Lk, Y := Yk, and ÀÜY := ÀÜYk), we obtain
L(Yk, ÀÜYk, Sk(a), ÀÜSk(b))
= L

Yk, ÀÜYk, ‚àíLkJ Kk(a) J , ‚àíLkJ ÀÜKk(b) J

= L(Yk, ÀÜYk, J , J ) + L
J Yk, J ÀÜYk, Kk(a), ÀÜKk(b)

+ L

Kk(a) J Yk, ÀÜKk(b) J ÀÜYk, ‚àíJ , ‚àíJ

+ L

Hk(a) Yk(a), ÀÜHk(b) ÀÜYk(b), Lk, Lk

+
(
Œº

Hk(a) (0 I)T, ‚àíJ (0 I)T 
‚àíŒº
 ÀÜHk(b) (0 I)T, ‚àíJ (0 I)T )
,
where the addends in the braces correspond to the last sum in (3.57). Taking into
account that the right-hand side of operator (6.80) equals zero for Sk = ÀÜSk (see
Lemma 3.22(i)) and evaluating the difference
(
Œº

Hk(a) (0 I)T, ‚àíJ (0 I)T 
‚àíŒº
 ÀÜHk(b) (0 I)T, ‚àíJ (0 I)T )
= Œº ‚àíJ (0 I)T, ÀÜHk(b) (0 I)T  ‚àíŒº ‚àíJ (0 I)T, Hk(a) (0 I)T 

6.1
Relative Oscillation Theory
415
using Theorem 3.5(v), we have
L

Yk(a), ÀÜYk(b), Sk(a), ÀÜSk(b)

= L

J Yk(a), J ÀÜYk(b), Kk(a), ÀÜKk(b)

+ ind ÀÜRk(b) ‚àíind Rk(a).
Recall that the symmetric nonsingular matrices Rk(Œª) and ÀÜRk(Œª) are continuous
functions in Œª and then their eigenvalues have the constant sign for Œª ‚ààR. So we
have ind ÀÜRk(a) = ind ÀÜRk(Œª0) and ind Rk(a) = ind Rk(Œª0) for any Œª0 ‚ààR.
Note that in the operator L

J Yk, J ÀÜYk, Kk(a), ÀÜKk(b)

, the symplectic matrices
Kk(a) and ÀÜKk(b) are unit lower block-triangular (see Sect. 1.6.1), and then they
obey condition (6.38), i.e.,
Kk(a) ÀÜK‚àí1
k (b) = J Hk(a) ÀÜH ‚àí1
k (b) J T =

I
0
ÀÜR‚àí1
k (b) ‚àíR‚àí1
k (a) I

.
Evaluating LJ Yk(a), J ÀÜYk(b), Kk(a), ÀÜKk(b) according to Lemma 6.6, where the
quantity ÀúBk(a, b) is replaced by ÀúCk(a, b) = UT
k (a) [ ÀÜR‚àí1
k (b) ‚àíR‚àí1
k (a)] Uk(a), we
derive (6.77) with Pk given by (6.78) (note that the Wronskian w(J Yk(a), J ÀÜYk(b))
is equal to the Wronskian w(Yk(a), ÀÜYk(b))). The proof is completed.
‚äì‚äî
Consider the evaluation of the relative oscillation numbers for the general case.
Introduce the following Wronskian
wk‚àó(a, b) := XT
k+1(a) ÀÜUk(b) ‚àíUT
k (a) ÀÜXk+1(b),
k‚àó‚àà(k, k + 1),
(6.81)
for Uk(Œª) and ÀÜUk(Œª) deÔ¨Åned as in (6.69). Here we use the intermediate point k‚àó‚àà
(k, k + 1) for a convenient interpretation of the subsequent results. Note that
wk‚àó(a, b) = wk(a, b) ‚àíUT
k (a) [ ÀÜR‚àí1
k (b) ‚àíR‚àí1
k (a)] ÀÜUk(b),
(6.82)
wk+1(a, b) = wk‚àó(a, b) ‚àíXT
k+1(a) [Qk(a) ‚àíÀÜQk(b)] ÀÜXk+1(b),
(6.83)
and then summing (6.82) and (6.83) we derive (6.71). In particular, if case I takes
place (i.e., conditions (6.74) hold), then we have wk‚àó(a, b) = wk(a, b) by (6.82),
and similarly wk+1(a, b) = wk‚àó(a, b) by (6.83) in case II.
Theorem 6.14 (General Case)
For spectral problems (6.63), (6.65) and (6.64),
(6.66) associated with symplectic matrices (6.67) and (6.68), the relative oscillation
numbers (4.109) have the form
#k( ÀÜZ(b), Z(a)) = #II(k, k‚àó) + #I(k‚àó, k + 1),
(6.84)

416
6
Miscellaneous Topics on Symplectic Systems
where the numbers
#II(k, k‚àó) := m‚àó(wk(a, b), wk‚àó(a, b)) ‚àíind ÀúCk(a, b) + Pk,
(6.85)
#I(k‚àó, k + 1) := m‚àó(wk‚àó(a, b), wk+1(a, b)) ‚àíind Ck(a, b)
(6.86)
are evaluated according to (6.77), (6.78), and (6.75), respectively, with the quanti-
ties wk+1(a, b) := wk‚àó(a, b) for case II and wk(a, b) := wk‚àó(a, b) for case I.
Proof For the proof we use factorizations (6.67), (6.68) and Lemma 3.22. Using
Lemma 3.22(ii) (with p = 2, W1 := Hk(a) ÀÜW1 := ÀÜHk(b), W2 := Lk(a), ÀÜW2 :=
ÀÜLk(b), Y := Yk(a), ÀÜY := ÀÜYk(b)), we derive
L

Yk(a), ÀÜYk(b), Sk(a), ÀÜSk(b)

= L

Yk(a), ÀÜYk(b), Lk(a) Hk(a), ÀÜLk(b) ÀÜHk(b)

= LYk(a), ÀÜYk(b), Hk(a), ÀÜHk(b) + LHk(a) Yk(a), ÀÜHk(b) ÀÜYk(b), Lk(a), ÀÜLk(b),
where L

Yk(a), ÀÜYk(b), Hk(a), ÀÜHk(b)

and L

Hk(a) Yk(a), ÀÜHk(b) ÀÜYk(b), Lk(a),
ÀÜLk(b)

can be evaluated according to cases II and I, respectively. For case II
we have that the conjoined bases Yk(a) and ÀÜYk(b) obey the symplectic systems
Yk‚àó(a) = Hk(a) Yk(a) and ÀÜYk‚àó(b) =
ÀÜHk(b) ÀÜYk(b) for k‚àó‚àà(k, k + 1), and then
we have to use the Wronskian Yk‚àó(a)TJ ÀÜYk‚àó(b) = wk‚àó(a, b) given by (6.81)
instead of wk+1(a, b). Similarly, in case I we use that Yk‚àó(a) and ÀÜYk‚àó(b) obey the
symplectic systems Yk+1(a) = Lk(a) Yk‚àó(a) and ÀÜYk+1(b) = ÀÜLk(b) ÀÜYk‚àó(b), and
then we apply (6.75) replacing wk(a, b) by wk‚àó(a, b). Finally, point out that such
modiÔ¨Åcations of (6.77) and (6.75) do not touch the matrices ÀúCk(a, b) and Ck(a, b)
according to their deÔ¨Ånitions in (6.77) and (6.75). The proof is completed.
‚äì‚äî
Now we formulate some properties of the relative oscillation numbers in
Theorem 6.14.
Proposition 6.15 The relative oscillation numbers in (6.84), (6.85), (6.86) satisfy
the following properties.
(i) If case I takes place (i.e., the conditions in (6.74) hold), then in (6.84) we
have #k( ÀÜZ(b), Z(a)) = #I
k( ÀÜZ(b), Z(a)) for #I
k( ÀÜZ(b), Z(a)) given by (6.75).
Similarly, for case II we have #k( ÀÜZ(b), Z(a)) =
#II
k ( ÀÜZ(b), Z(a)) with
#II
k ( ÀÜZ(b), Z(a)) given by (6.77).
(ii) If the conditions
Qk(a) ‚â•ÀÜQk(b),
Rk(a) ‚â•ÀÜRk(b)
(6.87)
hold, then the relative oscillation numbers given by (6.84), (6.85), ad (6.86)
are nonnegative. If additionally to (6.87) we have ÀÜRk(Œª) > 0 or if
Qk(Œª) ‚â°ÀÜQk(Œª),
Rk(Œª) ‚â°ÀÜRk(Œª),
a ‚â§b,

6.1
Relative Oscillation Theory
417
then for a ‚â§b the relative oscillation numbers are presented in the form
#k( ÀÜZ(b), Z(a)) = m‚àó(wk(a, b), wi‚àó(a, b)) + m‚àó(wi‚àó(a, b), wk+1(a, b)) ‚â•0,
(6.88)
where m‚àó(wk, wi‚àó) and m‚àó(wi‚àó, wk+1) are deÔ¨Åned by (6.72) with the quanti-
ties Ck := ÀúCk(a, b) ‚â•0 and Ck := Ck(a, b) ‚â•0 given by (6.77) and (6.75),
respectively.
(iii) For the relative oscillation numbers in (6.84), we have the estimate
		#k( ÀÜZ(b), Z(a))
		 ‚â§rank [Rk(a) ‚àíÀÜRk(b)] + rank[Qk(a) ‚àíÀÜQk(b)] ‚â§2n.
(6.89)
Proof For the proof of (i), we use (6.82) and (6.83). Case I implies (see (6.82)) that
wk(a, b) = wi‚àó(a, b) and the matrices ÀúCk(a, b) and Pk in (6.77) and (6.78) are equal
to the zero matrix. Then #II(i, i‚àó) = 0 and #k( ÀÜZ(b), Z(a)) = #I
k( ÀÜZ(b), Z(a)).
In a similar way, for case II we have Ck(a, b) = 0, and we get from (6.83)
that wk+1(a, b) = wi‚àó(a, b). Finally, it follows that #I(i‚àó, i + 1) = 0 and
#k( ÀÜZ(b), Z(a)) = #II
k ( ÀÜZ(b), Z(a)).
For the proof of (ii), we note that under assumptions (6.87) we have by
Example 3.30 that Œº(‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©) = 0 and then the relative oscillation
numbers are nonnegative because of their deÔ¨Ånition in (6.25). If, additionally, we
have ÀÜRk(Œª) > 0, then by (6.87) we have Rk(Œª) > 0, and moreover (6.87) is
equivalent to ÀÜR‚àí1
k (b) ‚àíR‚àí1
k (a) ‚â•0 (see Remark 3.35) and Pk = 0, ind Ck(a, b) =
ind ÀúCk(a, b) = 0. A similar situation occurs for Qk(Œª) ‚â°ÀÜQk(Œª), Rk(Œª) ‚â°ÀÜRk(Œª),
and a ‚â§b, because of the monotonicity assumptions (6.65). Then the proof of (ii)
is completed.
By (4.119) (see also the proof of Theorem 6.14), the relative oscillation
numbers (6.85) and (6.86) obey the inequalities
|#II(i, i‚àó)| ‚â§rank [Hk(a) ‚àíÀÜHk(b)] = rank[Rk(a) ‚àíÀÜRk(b)],
|#I(i‚àó, i + 1)| ‚â§rank [Lk(a) ‚àíÀÜLk(b)] = rank [Qk(a) ‚àíÀÜQk(b)],
and then for the relative oscillation numbers in (6.84), we have estimate (6.89). The
proof is completed.
‚äì‚äî
Finally, we reformulate Theorems 6.2 and 6.4 for the special case (6.63)
and (6.64), i.e., for the matrix Sturm-Liouville difference equations.
Theorem 6.16 (Relative Oscillation Theorem) Let œÉ and ÀÜœÉ be the Ô¨Ånite spectra,
and let Y [0](Œª) and ÀÜY [N+1](Œª) be the principal solutions of problems (6.63)
and (6.64) with conditions (6.65) and (6.66). Then there exists a constant P ‚àà
[‚àínN, nN]Z such that for all a, b ‚ààR the statements of Theorem 6.2 hold
with the relative oscillation numbers deÔ¨Åned by (6.84), (6.85), and (6.86), where
ÀÜZ(Œª) := ÀÜZ[N+1](Œª) and Z(Œª) := Z[0](Œª).

418
6
Miscellaneous Topics on Symplectic Systems
For the case Rk(Œª) ‚â°ÀÜRk(Œª) and Qk(Œª) ‚â°
ÀÜQk(Œª) for b > a, Theorem 6.16
presents the number of Ô¨Ånite eigenvalues of (6.63) in (a, b].
Theorem 6.17 (Renormalized Oscillation Theorem)
For problem (6.63), (6.65),
all statements of Theorem 6.4 (including the case a := Œª, Œª < Œª1) hold with
Œº‚ü®Gk(a, b)‚ü©, ‚ü®Gk+1(a, b)‚ü© = m‚àó(wk, wk‚àó) + m‚àó(wk‚àó, wk+1) ‚â•0,
(6.90)
where the Wronskians wl := wl(a, b), l = k, k + 1 and wk‚àó:= wk‚àó(a, b)
are deÔ¨Åned by (6.70) and (6.81) with Y(a) := Y [0](a), ÀÜY(b) := Y [N+1](b) and
where m‚àó(wk, wk‚àó) and m‚àó(wk‚àó, wk+1) are given by (6.72) with the quantities
Ck :=
ÀúCk(a, b) ‚â•0 and Ck := Ck(a, b) ‚â•0 given by (6.77) and (6.75),
respectively.
Proof Applying Proposition 6.15(ii) for the case Rk(Œª) ‚â°ÀÜRk(Œª), Qk(Œª) ‚â°ÀÜQk(Œª)
and Theorem 6.4, we complete the proof of Theorem 6.17.
‚äì‚äî
Remark 6.18 In the deÔ¨Ånition of (6.85), we use the number Pk given by (6.78),
which does not depend on a and b. Then it makes sense to introduce the new
constant
ÀúP := P ‚àí
N

i=0
Pk
(6.91)
and use identity (6.26) in the form
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§a}
=
N

k=0
(
#k( ÀÜZ[N+1](b), Z[0](a)) ‚àíPk
)
‚àíÀúP.
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(6.92)
For the numbers #k( ÀÜZ[N+1](b), Z[0](a)) ‚àíPk, one can also improve the esti-
mate (6.89) as follows:
		#k( ÀÜZ(b), Z(a)) ‚àíPk
		 ‚â§rank ÀúCk(a, b) + rankCk(a, b),
where ÀúCk(a, b) and Ck(a, b) are given by (6.77) and (6.75). The proof follows from
inequality (6.53).
6.1.5
Examples
This section is devoted to examples, which illustrate the applications of Theo-
rems 6.16 and 6.17 to the scalar spectral problems (6.63) and (6.64).

6.1
Relative Oscillation Theory
419
Example 6.19 Consider problem (6.63) for the scalar Sturm-Liouville difference
equation
(rk(Œª) xk(Œª)) ‚àíqk(Œª) xk+1(Œª) = 0,
k ‚àà[0, 3]Z,
x0(Œª) = 0 = x4(Œª),
rk(Œª) := (‚àí1)k+1 exp((‚àí1)kŒª),
qk(Œª) = ‚àíŒª.
‚é´
‚é™‚é¨
‚é™‚é≠
(6.93)
Then for the principal solution of (6.93) at 0 deÔ¨Åned by the initial conditions
x[0]
0 (Œª) = 0 and x[0]
1 (Œª) = 1/r0(Œª), we have
x[0]
4 (Œª) = ‚àíŒª3 ‚àí6Œª2 sinh(Œª) ‚àí8Œª sinh2(Œª) + 2Œª + 4 sinh(Œª),
and the Ô¨Ånite eigenvalues of (6.93) are the zeros of x4(Œª), i.e., Œª1 ‚âà‚àí0.6167186,
Œª2 = 0, Œª3 ‚âà0.6167186. According to Theorem 6.17, we have
#k( ÀÜZ(b), Z(a)) = m‚àó(wk, wk‚àó) + m‚àó(wk‚àó, wk+1),
where for the scalar case
m‚àó(wk, wk‚àó) =

1, wk‚àóÃ∏= 0, wkwk‚àó‚â§0,
0, otherwise,
m‚àó(wk‚àó, wk+1) =

1, wk+1 Ã∏= 0, wk+1wk‚àó‚â§0,
0, otherwise.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.94)
Then, according to (6.94) and Theorem 6.17, the number of Ô¨Ånite eigenvalues of
problem (6.93) in the interval (a, b] is equal to the total number of generalized
zeros of the Wronskian in all intervals [k, k‚àó) and [k‚àó, k + 1) for k ‚àà[0, N]Z
and k‚àó‚àà(k, k + 1). For example, if a = ‚àí0.8 and b = 1.8, then we have the
three sign changes of the Wronskian wk(a, b) (see Fig. 6.1), and then according
to Theorem 6.17, the three Ô¨Ånite eigenvalues of problem (6.93), i.e., the numbers
Œª1 ‚âà‚àí0.6167186, Œª2 = 0, Œª3 ‚âà0.6167186, are located in the interval (‚àí0.8, 1.8].
Note that the relative oscillation number 0 ‚â§#k( ÀÜZ[N+1](b), Z[0](a)) ‚â§2 achieves
its maximal value 2 at the point k = 2.
Example 6.20 Consider spectral problem (6.93) and the following spectral problem
(referred to as ‚Äúproblem 1‚Äù and ‚Äúproblem 2‚Äù in Fig. 6.2):
(ÀÜrk(Œª) ÀÜxk(Œª)) ‚àíÀÜqk(Œª) ÀÜxk+1(Œª) = 0,
k ‚àà[0, 3]Z,
ÀÜx0(Œª) = 0 = ÀÜx4(Œª),
ÀÜrk(Œª) = (‚àí1)k,
ÀÜqk(Œª) = ‚àí(Œª + 2).
‚é´
‚é™‚é¨
‚é™‚é≠
(6.95)

420
6
Miscellaneous Topics on Symplectic Systems
Fig. 6.1 The graphs of the sign of the Wronskian and the relative oscillation numbers in
Example 6.19 for the values a = ‚àí0.8 and b = 1.8
‚àí4
‚àí3
‚àí2
‚àí1
0
1
‚àí1
‚àí0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
Graphs of y1,2(Œª)=#(Œº ‚ààœÉ1,2,Œº ‚â§Œª)
problem1
problem2
Fig. 6.2 The graphs of the functions y1,2(Œª) of the number of Ô¨Ånite eigenvalues below or equal to
Œª for Œª ‚ààR for problems 1 and 2 in Example 6.20

6.1
Relative Oscillation Theory
421
The Ô¨Ånite eigenvalues of (6.95) are the zeros of the equation
ÀÜx[0]
4 (Œª) = (Œª + 2)3 ‚àí2Œª ‚àí4 = 0,
ÀÜŒª1 = ‚àí
‚àö
2 ‚àí2 ‚âà‚àí3.4142136,
ÀÜŒª2 = ‚àí2,
ÀÜŒª3 =
‚àö
2 ‚àí2 ‚âà‚àí0.5857864.
The localization of the Ô¨Ånite eigenvalues of (6.93) and (6.95) is shown in Fig. 6.2,
where we present the functions y1,2(Œª) of the number of Ô¨Ånite eigenvalues below or
equal to Œª for Œª ‚ààR.
According to Theorem 6.16, we can calculate the difference between numbers
of Ô¨Ånite eigenvalues of (6.95) and (6.93) using the relative oscillation numbers
#k( ÀÜZ[N+1](b), Z[0](a)) = #II(k, k‚àó) + #I(k‚àó, k + 1). For the scalar case, we have
#II(k, k‚àó) ‚àíPk =
‚éß
‚é™‚é®
‚é™‚é©
1,
ÀÜr‚àí1
k (b) ‚àír‚àí1
k (a) > 0 and wk‚àóÃ∏= 0, wkwk‚àó‚â§0,
‚àí1, ÀÜr‚àí1
k (b) ‚àír‚àí1
k (a) < 0 and wk Ã∏= 0, wkwk‚àó‚â§0,
0,
otherwise,
(6.96)
where the number Pk given by (6.78) is deÔ¨Åned as
Pk := ind ÀÜrk(Œª0) ‚àíind rk(Œª0) = (‚àí1)k+1.
Then we can say that the Wronskian has a weighted zero at the point k if the
quantity #II(k, k‚àó) ‚àíPk = ¬±1. According to Remark 6.18, we can consider the
sum 3
k=0 Pk = 0 as the parameter of problem (6.95).
Similarly, for the scalar case, we derive
#I(k‚àó, k + 1) =
‚éß
‚é™‚é®
‚é™‚é©
1,
qk(a) ‚àíÀÜqk(b) > 0 and wk+1 Ã∏= 0, wk+1wk‚àó‚â§0,
‚àí1, qk(a) ‚àíÀÜqk(b) < 0 and wk‚àóÃ∏= 0, wk+1wk‚àó‚â§0,
0,
otherwise,
(6.97)
and say that the Wronskian has a weighted node at k‚àóif #I(k‚àó, k + 1) = ¬±1.
Denote Ck(a, b) = qk(a) ‚àíÀÜqk(b) and Bk(a, b) = ÀÜr‚àí1
k (b) ‚àír‚àí1
k (a), and observe
that we can calculate the constant ÀúP given by (6.91) evaluating the sum of (6.96)
and (6.97) for a = b = Œª0 < min{Œª1, ÀÜŒª1}. By Fig. 6.3 we conclude that ÀúP = 0,
where we take a = b = Œª0 = ‚àí4. Then, according to Theorem 6.16, we can
evaluate the difference #{ŒΩ ‚ààœÉ2 | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ1 | ŒΩ ‚â§a} between the numbers
of Ô¨Ånite eigenvalues of (6.95) and (6.93) calculating the total number of weighted
zeros of the Wronskian for all k and k‚àó, k ‚àà[0, N]Z, k‚àó‚àà(k, k + 1).

422
6
Miscellaneous Topics on Symplectic Systems
Fig. 6.3 The graphs of the signs of the Wronskian, Ck(a, b) = qk(a)‚àíÀÜqk(b), Bk(a, b) = ÀÜr‚àí1
k (b)‚àí
r‚àí1
k (a), and the relative oscillation numbers in Example 6.20 for the values a = b = ‚àí4
Fig. 6.4 The graphs of the signs of the Wronskian, Ck(a, b) = qk(a)‚àíÀÜqk(b), Bk(a, b) = ÀÜr‚àí1
k (b)‚àí
r‚àí1
k (a), and the relative oscillation numbers in Example 6.20 for the values a = ‚àí10 and b = 10

6.1
Relative Oscillation Theory
423
Next, in Fig. 6.4 we present the graphs of the signs of the Wronskian, Ck(a, b) =
qk(a) ‚àíÀÜqk(b) and Bk(a, b) = ÀÜr‚àí1
k (b) ‚àír‚àí1
k (a) and the relative oscillation numbers
#k( ÀÜZ[N+1](b), Z[0](a)) ‚àíPk for k ‚àà[0, 3]Z. For example, we have
#0( ÀÜZ[N+1](b), Z[0](a)) ‚àíP0 = #II(0, k‚àó) ‚àíP0 + #I(k‚àó, 1) = 2,
k‚àó= 1/2,
because B0(a, b) > 0, w0wk‚àó< 0, C0(a, b) > 0, w1wk‚àó< 0. Similarly, in the next
point k = 1, we have B1(a, b) < 0, w1wk‚àó< 0, C1(a, b) > 0, w2wk‚àó< 0, and
k‚àó= 3/2, and then #1( ÀÜZ[N+1](b), Z[0](a)) ‚àíP1 = ‚àí1 + 1 = 0. Finally, according
to Fig. 6.2, we have
#{ŒΩ ‚ààœÉ2 | ŒΩ ‚â§10} ‚àí#{ŒΩ ‚ààœÉ1 | ŒΩ ‚â§‚àí10} = 3 ‚àí0 = 3,
and the sum of the relative oscillation numbers by Fig. 6.4 equals to 3.
6.1.6
Separated Boundary Conditions
We consider symplectic systems (5.1) and (6.1) with different separated boundary
conditions (5.155), i.e., the problems
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N]Z,
R‚àó
0(Œª) x0(Œª) + R0(Œª) u0(Œª) = 0,
R‚àó
N+1(Œª) xN+1(Œª) + RN+1(Œª) uN+1(Œª) = 0,
ÀÜyk+1(Œª) = ÀÜSk(Œª) ÀÜyk(Œª),
k ‚àà[0, N]Z,
ÀÜR‚àó
0(Œª) ÀÜx0(Œª) + ÀÜR0(Œª) ÀÜu0(Œª) = 0,
ÀÜR‚àó
N+1(Œª) ÀÜxN+1(Œª) + ÀÜRN+1(Œª) ÀÜuN+1(Œª) = 0,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.98)
where we assume that the matrices R‚àó
k(Œª), Rk(Œª), ÀÜR‚àó
k(Œª), ÀÜRk(Œª) for k ‚àà{0, N +
1} obey assumptions (5.156), (5.157), and (5.158). Moreover, we derive all results
under restriction (5.210)
rank Bk(Œª), rank ÀÜBk(Œª) are constant for Œª ‚ààR for all k ‚àà[0, N]Z
rankR0(Œª) and rank RN+1(Œª) are constant for Œª ‚ààR,
rank ÀÜR0(Œª) and rank ÀÜRN+1(Œª) are constant for Œª ‚ààR.
‚é´
‚é™‚é¨
‚é™‚é≠
(6.99)
Under the assumptions of Theorem 5.50 for problems (6.98), the Ô¨Ånite spectra œÉ and
ÀÜœÉ of (6.98) are bounded, and one can order the Ô¨Ånite eigenvalues of (6.98) according
to (6.19) using notation (6.20).

424
6
Miscellaneous Topics on Symplectic Systems
The consideration in this subsection is based on Theorem 5.41. Introduce the
following matrices associated with the separated boundary conditions in (6.98)
(see (5.171) and (5.173))
V‚àí1(Œª) :=
R‚àóT
0 (Œª) K0(Œª) ‚àíRT
0 (Œª)
RT
0 (Œª) K0(Œª) R‚àóT
0 (Œª)

,
K0(Œª) := [R‚àó
0(Œª) R‚àóT
0 (Œª) + R0(Œª) RT
0 (Œª)]‚àí1,
VN+1(Œª) :=

R‚àó
N+1(Œª)
RN+1(Œª)
‚àíKN+1(Œª) RN+1(Œª) KN+1(Œª) R‚àó
N+1(Œª)

,
KN+1(Œª) := [R‚àó
N+1(Œª) R‚àóT
N+1(Œª) + RN+1(Œª) RT
N+1(Œª)]‚àí1.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.100)
and
ÀÜV‚àí1(Œª) :=
 ÀÜR‚àóT
0 (Œª) ÀÜK0(Œª) ‚àíÀÜRT
0 (Œª)
ÀÜRT
0 (Œª) ÀÜK0(Œª)
ÀÜR‚àóT
0 (Œª)

,
ÀÜK0(Œª) := [ ÀÜR‚àó
0(Œª) ÀÜR‚àóT
0 (Œª) + ÀÜR0(Œª) ÀÜRT
0 (Œª)]‚àí1,
ÀÜVN+1(Œª) :=

ÀÜR‚àó
N+1(Œª)
ÀÜRN+1(Œª)
‚àíÀÜKN+1(Œª) ÀÜRN+1(Œª) ÀÜKN+1(Œª) ÀÜR‚àó
N+1(Œª)

,
ÀÜKN+1(Œª) := [ ÀÜR‚àó
N+1(Œª) ÀÜR‚àóT
N+1(Œª) + ÀÜRN+1(Œª) ÀÜRT
N+1(Œª)]‚àí1.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.101)
DeÔ¨Ånition 6.21 Let ÀÜZ[R](Œª) and Z[L](Œª) for Œª ‚ààR be symplectic fundamental
matrices of (6.1) and (5.1), respectively, satisfying
ÀÜZ[R]
N+1(Œª) = ÀÜV ‚àí1
N+1(Œª),
Z[L]
0 (Œª) = V‚àí1(Œª),
(6.102)
where the matrices ÀÜVN+1(Œª) and V‚àí1(Œª) are determined by (6.100) and (6.101).
Consider conjoined bases Y [L]
k
(Œª) = Z[L]
k (Œª) (0 I)T and ÀÜY [R]
k
(Œª) = ÀÜZ[R]
k
(Œª) (0 I)T .
Then the relative oscillation numbers for problems (6.98) with a, b ‚ààR are deÔ¨Åned
by the formulas
#k( ÀÜZ[R](b), Z[L](a)) := Œº

‚ü®Gk(a, b)‚ü©, ‚ü®Gk+1(a, b)‚ü©

‚àíŒº

‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©

,
Gk(a, b) := ÀÜZ[R] ‚àí1
k
(b)Z[L]
k (a),
k ‚àà[0, N]Z,
#‚àí1( ÀÜZ[R](b), Z[L](a)) := Œº‚àó ÀÜV ‚àí1
‚àí1 (b) ÀÜY [R]
0
(b), ÀÜV ‚àí1
‚àí1 (b)V‚àí1(a) (0 I)T 
‚àíŒº
 ÀÜV‚àí1(b) (0 I)T, V‚àí1(a) (0 I)T 
,
#N+1( ÀÜZ[R](b), Z[L](a)) = Œº
 ÀÜVN+1(b)Y [L]
N+1(a), ÀÜVN+1(b)V ‚àí1
N+1(a) (0 I)T 
‚àíŒº‚àó ÀÜV ‚àí1
N+1(b) (0 I)T, V ‚àí1
N+1(a) (0 I)T 
,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.103)

6.1
Relative Oscillation Theory
425
Moreover, we deÔ¨Åne the relative oscillation number on the interval [‚àí1, N +1]Z for
the pair of eigenvalue problems (6.98) by the formula
#( ÀÜZ[R](b), Z[L](a), ‚àí1, N + 1) :=
N+1

k=‚àí1
#k( ÀÜZ[R](b), Z[L](a))
= #( ÀÜZ[R](b), Z[L](a), 0, N) + #‚àí1( ÀÜZ[R](b), Z[L](a))
+ #N+1( ÀÜZ[R](b), Z[L](a)).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.104)
Recall that problems (6.98) are equivalent to extended problems with the
Dirichlet boundary conditions (see Lemma 5.40). Then applying Theorems 6.2
and 6.4 to these extended problems, we derive the corresponding results for the
separated endpoints.
Theorem 6.22 (Relative Oscillation Theorem for Separated Endpoints)
Assume that for problems (6.98) conditions (5.3), (6.5), (6.99), and (5.156)‚Äì
(5.158) hold for the boundary conditions in (6.98). Let Z[L](Œª) and ÀÜZ[R](Œª) be
the symplectic fundamental matrices of these systems deÔ¨Åned by (6.102) associated
with the conjoined bases Y [L](Œª) = Z[L](Œª) (0 I)T and ÀÜY [R](Œª) = ÀÜZ[R](Œª) (0 I)T .
For arbitrary a, b ‚ààR deÔ¨Åne the relative oscillation numbers according to (6.103)
and (6.104). Then there exists a constant P ‚àà[‚àí(N + 2) n, (N + 2) n]Z such that
for any a, b ‚ààR we have for the spectra œÉ and ÀÜœÉ of problems (6.98)
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§a}
= #( ÀÜZ[R](b), Z[L](a), ‚àí1, N + 1) ‚àíP,
(6.105)
where for Œª0 deÔ¨Åned by (6.20) we have
P = ÀÜ‚Ñì‚àí‚Ñì= #( ÀÜZ[R](Œª), Z[L](Œª), ‚àí1, N + 1),
Œª < Œª0
(6.106)
with ‚Ñìgiven by (5.215) and similarly deÔ¨Åned ÀÜ‚Ñì.
Proof For the proof we apply Theorem 6.2 to extended problems with the Dirichlet
boundary conditions. As in the proof of Theorem 5.50, one can show that the
matrices Q0(Œª), QN+1(Œª), ÀÜQ0(Œª), ÀÜQN+1(Œª) used in Theorem 5.41 for the con-
struction of the extended problems can be omitted (here we use the notation ÀÜQk
for k ‚àà{0, N + 1} for the matrices (5.168) associated with the second problem
in (6.98)). Indeed, a direct application of Theorem 6.2 to the extended problems
constructed via Theorem 5.41 leads to the relative oscillation numbers
#k( ÀÜZ[N+2](b), Z[‚àí1](a))
:= Œº

‚ü®ÀúGk(a, b)‚ü©, ‚ü®ÀúGk+1(a, b)‚ü©

‚àíŒº

‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©


(6.107)

426
6
Miscellaneous Topics on Symplectic Systems
for k ‚àà[‚àí1, N + 1]Z, where
ÀúGk(a, b) := diag{ ÀÜQT
N+1(b), ÀÜQ‚àí1
N+1(b)} [ ÀÜZ[R]
k (b)]‚àí1Z[L]
k (a) diag{QT ‚àí1
0
(a), Q0(a)}
for k ‚àà[0, N]Z, and according to Corollary 3.40(i) the symplectic block diagonal
matrices (which are a particular case of low triangular matrices) can be omitted,
i.e., we have the relative oscillation numbers given by (6.103) for k ‚àà[0, N]Z. For
k = ‚àí1 we have according to Remark 6.3 (see (6.29), where we replace the point 0
by ‚àí1)
#‚àí1( ÀÜZ[N+2](b), Z[‚àí1](a)) = Œº‚àó ÀÜS‚àí1
‚àí1(b) ÀÜY [N+2]
0
(b) (0 I)T, ÀÜS‚àí1
‚àí1(b)S‚àí1(a) (0 I)T 
‚àíŒº
 ÀÜS‚àí1(b) (0 I)T, S‚àí1(a) (0 I)T 
.
Using ÀÜY [N+2]
N+1 (b) = ÀÜS‚àí1
N+1(b) (0 I)T (which implies ÀÜY [N+2]
0
(b) = ÀÜY [R]
0
(b) ÀÜQN+1(b))
and the connection between ÀÜSk(Œª), Sk(Œª) and ÀÜVk(Œª), Vk(Œª) for k ‚àà{‚àí1, N + 1}
by Theorem 5.41, we derive the representation for #‚àí1( ÀÜZ[R](b), Z[L](a)) according
to (6.103) omitting all block diagonal matrices with Q0(Œª), QN+1(Œª),
ÀÜQ0(Œª),
ÀÜQN+1(Œª) according to Theorem 3.5(i)‚Äì(ii). The proof for the point N + 1, where
we use (6.30) replacing N by N + 1, is similar.
So we have shown that the relative oscillation numbers for the extended problems
obey DeÔ¨Ånition 6.21, and then applying Theorem 6.2 and incorporating (5.215), we
complete the proof.
‚äì‚äî
For the case when Sk(Œª) ‚â°
ÀÜSk(Œª) for k ‚àà[0, N]Z and Rk(Œª) ‚â°
ÀÜRk(Œª) and
R‚àó
k(Œª) ‚â°ÀÜR‚àó
k(Œª) for k ‚àà{‚àí1, N + 1}, we derive a generalization of Theorem 6.4 for
separated boundary conditions.
Theorem 6.23 (Renormalized Oscillation Theorem for Separated Endpoints)
Under the assumptions of Theorem 6.22, consider only one problem in (6.98). Let
Z[L](Œª) and Z[R](Œª) be symplectic fundamental matrices of system (5.1) deÔ¨Åned
by (6.102) (where we put ÀÜVN+1(Œª) := VN+1(Œª)) associated with the conjoined
bases Y [L](Œª) = Z[L](Œª) (0 I)T and Y [R](Œª) = Z[R](Œª) (0 I)T . Then for any a, b ‚àà
R with a < b, the number of Ô¨Ånite eigenvalues of problem (5.1) with (5.155) in the
interval (a, b] is given by the formula
#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b} =
N

k=0
Œº

‚ü®Gk(a, b)‚ü©, ‚ü®Gk+1(a, b)‚ü©

+Œº‚àó
V ‚àí1
‚àí1 (b) Y [R]
0
(b), V ‚àí1
‚àí1 (b) V‚àí1(a) (0 I)T 
+Œº

VN+1(b) Y [L]
N+1(a), VN+1(b) V ‚àí1
N+1(a) (0 I)T 
,
Gk(a, b) := [Z[R]
k (b)]‚àí1Z[L]
k (a).
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.108)

6.1
Relative Oscillation Theory
427
In particular, for a := Œª, Œª < Œª1 = min œÉ, formula (6.108) presents the number of
Ô¨Ånite eigenvalues of (5.1), (5.155), which are less than or equal to b.
Proof As in the proof of Theorem 6.4, we have for Sk(Œª) ‚â°ÀÜSk(Œª), k ‚àà[0, N]Z,
Rk(Œª) ‚â°ÀÜRk(Œª), and for R‚àó
k(Œª) ‚â°ÀÜR‚àó
k(Œª), k ‚àà{‚àí1, N + 1}, that
Œº‚ü®Sk(b)‚ü©, ‚ü®Sk(a)‚ü© = 0,
k ‚àà[‚àí1, N + 1]Z,
(6.109)
where we use Lemma 5.105 and additionally, for the cases k = ‚àí1 and k = N + 1,
we apply Theorem 5.41 and assumption (6.99). We note that condition (6.109) for
k = ‚àí1 and k = N + 1 implies
Œº

S‚àí1(b) (0 I)T, S‚àí1(a) (0 I)T 
= Œº

V‚àí1(b) (0 I)T, V‚àí1(a) (0 I)T 
= 0,
Œº‚àó
S‚àí1
N+1(b) (0 I)T, S‚àí1
N+1(a) (0 I)T 
= Œº‚àó
V ‚àí1
N+1(b) (0 I)T, V ‚àí1
N+1(a) (0 I)T 
= 0,
where we use Lemma 3.21(v) and Theorem 3.5(i)‚Äì(ii). Then formulas for the
relative oscillation numbers in (6.108) follow from (6.109) and DeÔ¨Ånition 6.21.
‚äì‚äî
Remark 6.24 Assume Rk(Œª) ‚â°ÀÜRk(Œª) ‚â°Rk and R‚àó
k(Œª) ‚â°ÀÜR‚àó
k(Œª) ‚â°R‚àó
k for k ‚àà
{‚àí1, N + 1}, i.e., the boundary conditions of problems (6.98) are the same and do
not depend on Œª. Then the relative oscillation numbers for k = ‚àí1 and k = N +1 in
Theorems 6.22 and 6.23 are equal to zero by DeÔ¨Ånition 6.21 and by the deÔ¨Ånition of
the comparative index. In particular, for the Dirichlet boundary conditions in (6.17),
we have by DeÔ¨Ånition 6.21 that the relative oscillation numbers for k ‚àà{‚àí1, N +1}
are equal to zero, and in this case Theorems 6.22 and 6.23 reduce into Theorems 6.2
and 6.4, respectively.
Another important special case of (6.98) is connected with the situation when
Sk(Œª) ‚â°ÀÜSk(Œª), i.e., when the problems differ in the boundary conditions only. As
a corollary to Theorem 6.22, we have the following result.
Corollary 6.25 Under all assumptions of Theorem 6.22, suppose additionally that
Sk(Œª) ‚â°ÀÜSk(Œª) and a = b. Then the difference of the numbers of Ô¨Ånite eigenvalues
of (6.98) is given by the formula
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
= #‚àí1( ÀÜZ[R](b), Z[L](b)) + #N+1( ÀÜZ[R](b), Z[L](b)) ‚àíP,

(6.110)
with the constant P deÔ¨Åned by
P := #‚àí1( ÀÜZ[R](Œª), Z[L](Œª)) + #N+1( ÀÜZ[R](Œª), Z[L](Œª)) = ÀÜl ‚àíl,
Œª ‚â§Œª0,
Œª0 := min œÉ ‚à™ÀÜœÉ,

(6.111)

428
6
Miscellaneous Topics on Symplectic Systems
where the relative oscillation numbers for k = ‚àí1 and N + 1 are given by (6.103)
and the constants l and ÀÜl are determined in Theorem 6.23.
Remark 6.26 Under the assumptions of Corollary 6.25, suppose that the boundary
conditions in (6.98) do not depend on Œª, i.e., Rk(Œª) ‚â°Rk, ÀÜRk(Œª) ‚â°ÀÜRk, R‚àó
k(Œª) ‚â°
R‚àó
k, ÀÜR‚àó
k(Œª) ‚â°ÀÜR‚àó
k for k ‚àà{‚àí1, N + 1}. Then the second addends in the deÔ¨Ånitions
of #‚àí1( ÀÜZ[R](Œª), Z[L](Œª)) and #N+1( ÀÜZ[R](Œª), Z[L](Œª)) do not depend on Œª as well
and formula (6.110) can be rewritten in the form
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b}‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
= Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(b), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 
+Œº
 ÀÜVN+1Y [L]
N+1(b), ÀÜVN+1V ‚àí1
N+1(0 I)T 
‚àíÀúP,
‚é´
‚é™‚é¨
‚é™‚é≠
(6.112)
where the new constant ÀúP is connected with P given by (6.111) as follows
ÀúP = P + Œº ÀÜV‚àí1(0 I)T, V‚àí1(0 I)T  + Œº‚àó ÀÜV ‚àí1
N+1(0 I)T, V ‚àí1
N+1(0 I)T 
= P1 + P2,
P1 := Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 
,
P2 := Œº ÀÜVN+1Y [L]
N+1(Œª), ÀÜVN+1V ‚àí1
N+1(0 I)T , Œª ‚â§Œª0 := min œÉ ‚à™ÀÜœÉ.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(6.113)
6.1.7
General Boundary Conditions
In this subsection we consider the general case of problems (5.1), (5.151)
and (6.1), (6.3) under the assumptions of Theorem 5.55. In particular, we impose
the conditions
rankBk(Œª) is constant for Œª ‚ààR for all k ‚àà[0, N]Z,
rank R2(Œª) is constant for Œª ‚ààR,
rank ÀÜBk(Œª) is constant for Œª ‚ààR for all k ‚àà[0, N]Z,
rank ÀÜR2(Œª) is constant for Œª ‚ààR.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.114)
As for the case of the separated boundary conditions, the main role in the
consideration plays Theorem 5.44, which gives the possibility to consider prob-
lems (5.1), (5.151) and (6.1), (6.3) as a special case of problems with separated
boundary conditions, and then all results of Sect. 6.1.6 can be applied. Applying
Theorem 5.44, consider the pair of the augmented problems (5.178) associated

6.1
Relative Oscillation Theory
429
with (5.1), (5.151) and (6.1), (6.3)
Àúyk+1(Œª) = {Sk(Œª)} Àúyk(Œª),
k ‚àà[0, N]Z,
 0 0
‚àíI I

Àúx0(Œª) +
‚àíI ‚àíI
0
0

Àúu0(Œª) = 0,
R1(Œª) ÀúxN+1(Œª) + R2(Œª) ÀúuN+1(Œª) = 0
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
¬Øyk+1(Œª) = { ÀÜSk(Œª)} ¬Øyk(Œª),
k ‚àà[0, N]Z,
 0 0
‚àíI I

¬Øx0(Œª) +
‚àíI ‚àíI
0
0

¬Øu0(Œª) = 0,
ÀÜR1(Œª) ¬ØxN+1(Œª) + ÀÜR2(Œª) ¬ØuN+1(Œª) = 0.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.115)
According to DeÔ¨Ånition 6.21, we introduce the 4n √ó 4n matrices associated with
Rk(Œª) and ÀÜRk(Œª) for k ‚àà{1, 2} (see (6.100), (6.101))
VN+1(Œª) :=

R1(Œª)
R2(Œª)
‚àíK(Œª) R2(Œª) K(Œª) R1(Œª)

,
K(Œª) := [R1(Œª) RT
1 (Œª) + R2(Œª) RT
2 (Œª)]‚àí1,
ÀÜVN+1(Œª) :=

ÀÜR1(Œª)
ÀÜR2(Œª)
‚àíÀÜK(Œª) ÀÜR2(Œª) ÀÜK(Œª) ÀÜR1(Œª)

,
ÀÜK(Œª) := [ ÀÜR1(Œª) ÀÜRT
1 (Œª) + ÀÜR2(Œª) ÀÜRT
2 (Œª)]‚àí1.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.116)
The boundary conditions at the left endpoint in problems (6.115) are the same and
do not depend on Œª, and then one can put V‚àí1(Œª) ‚â°ÀÜV‚àí1(Œª) ‚â°S0, where the matrix
S0 is given in (3.102). Applying the additional properties of the comparative index
for symplectic matrices (see Sect. 3.3.5), we derive the following representation of
the relative oscillation numbers for problems (6.115) using the notation introduced
in Sect. 3.3.5.
Lemma 6.27 Let ÀÜZ[N+1](Œª) and Z[0](Œª) be the symplectic fundamental matrices of
systems (6.1) and (5.1) satisfying for all Œª ‚ààR the initial conditions ÀÜZ[N+1]
N+1 (Œª) =
I = Z[0]
0 (Œª) and
Z[L]
k
(Œª) = {Z[0]
k (Œª)} S0,
ÀÜZ[R]
k
(Œª) = { ÀÜZ[N+1]
k
(Œª)} ÀÜV‚àí1
N+1(Œª),

k ‚àà[0, N + 1]Z,
(6.117)
where S0 and ÀÜVN+1(Œª) are deÔ¨Åned by (3.102) and (6.116). Then, concern-
ing the relative oscillation numbers #k( ÀÜZ[R](b), Z[L](a)) deÔ¨Åned by (6.103) for

430
6
Miscellaneous Topics on Symplectic Systems
problems (6.115), we have the identities
#k
 ÀÜZ[R](b), Z[L](a)

= Œº
 ÀÜVN+1(b)‚ü®Gk(a, b)‚ü©, ÀÜVN+1(b)‚ü®Gk+1(a, b)‚ü©

‚àíŒº

‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©

,
k ‚àà[0, N]Z,

(6.118)
where
Gk(a, b) = [ ÀÜZ[N+1]
k
(b)]‚àí1Z[0]
k (a),
and
#‚àí1( ÀÜZ[R](b), Z[L](a)) = 0,
#N+1( ÀÜZ[R](b), Z[L](a)) = Œº
 ÀÜVN+1(b)‚ü®Z[0]
N+1(a)‚ü©, ÀÜVN+1(b)V‚àí1
N+1(a) (0 I)T 
‚àíŒº‚àó ÀÜV‚àí1
N+1(b) (0 I)T, V‚àí1
N+1(a) (0 I)T 
.
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(6.119)
Proof By (6.103) and (6.117), we have for problems (6.115)
#k( ÀÜZ[R](b), Z[L(a))
= Œº
/ ÀÜVN+1(b) WkS0
0
,
/ ÀÜVN+1(b) Wk+1S0
0
‚àíŒº

‚ü®{ ÀÜSk(b)}‚ü©, ‚ü®{Sk(a)}‚ü©

,
where k ‚àà[0, N]Z and
Wk :=
!
[ ÀÜZ[N+1]
k
(b)]‚àí1Z[0]
k (a)
"
.
According to Corollary 3.40(v), by (3.122) with R := ÀÜV‚àí1
N+1, we obtain that the
Ô¨Årst addend on the right-hand side of the previous formula is the same as the
Ô¨Årst summand on the right-hand side of (6.118). Next, using Proposition 3.37,
by (3.109), we obtain
Œº

‚ü®{ ÀÜSk(b)}‚ü©, ‚ü®{Sk(a)}‚ü©

= Œº

‚ü®ÀÜSk(b)‚ü©, ‚ü®Sk(a)‚ü©

.
Then, formula (6.118) is proved. For the proof of (6.119), we note that the relative
oscillation number at k = ‚àí1 equals to zero by Remark 6.24. The representation
of #N+1( ÀÜZ[R](b), Z[L](a)) follows from the deÔ¨Ånition (see (6.103)), where we
incorporate that
Y[L]
N+1(a) = Z[L]
N+1(a) (0 I)T = {Z[0]
N+1(a)} S0(0 I)T = ‚ü®Z[0]
N+1(a)‚ü©,
see (6.117) and (3.104). The proof is completed.
‚äì‚äî

6.1
Relative Oscillation Theory
431
DeÔ¨Åne the relative oscillation numbers for (6.115)
#( ÀÜZ[R](b), Z[L](a), 0, N + 1)
=
N+1

k=0
#k( ÀÜZ[R](b), Z[L](a))
= #( ÀÜZ[R](b), Z[L](a), 0, N) + #N+1( ÀÜZ[R](b), Z[L](a)).
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.120)
Based on Lemma 6.27, we present the relative and renormalized oscillation
theorems for joint endpoints as corollaries to Theorems 6.22 and 6.23.
Theorem 6.28 (Relative Oscillation Theorem for Joint Endpoints)
For prob-
lems (5.1), (5.151) and (6.1), (6.3) assume that (5.3), (5.152), (5.153), (6.4)‚Äì (6.6),
and (6.114) hold. DeÔ¨Åne the relative oscillation numbers according to Lemma 6.27
and (6.120). Then there exists a constant P ‚àà[‚àí(N + 2) n, (N + 2) n]Z such
that for any a, b ‚ààR, we have for the spectra œÉ and ÀÜœÉ of problems (5.1), (5.151)
and (6.1), (6.3) the equality
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§a}
= #( ÀÜZ[R](b), Z[L](a), 0, N + 1) ‚àíP,

(6.121)
where for Œª0 in (6.20) and ‚Ñìgiven by (5.231) (and similarly deÔ¨Åned ÀÜ‚Ñì), we have
P = ÀÜ‚Ñì‚àí‚Ñì= #( ÀÜZ[R](Œª), Z[L](Œª), 0, N + 1),
Œª < Œª0.
(6.122)
Proof The result follows from the relative oscillation theorem (Theorem 6.22)
applied to the two augmented problems (6.115), which have the separated endpoints.
‚äì‚äî
Theorem 6.29 (Renormalized Oscillation Theorem for Joint Endpoints)
Under the assumptions of Theorem 6.28, consider only one problem (5.1) , (5.151).
Assume that the relative oscillation numbers are deÔ¨Åned according to Lemma 6.27,
where ÀÜZ[N+1](Œª) ‚â°Z[N+1](Œª) and ÀÜVN+1(Œª) ‚â°VN+1(Œª). Then for any a, b ‚ààR
with a < b, the number of Ô¨Ånite eigenvalues of problem (5.1) with (5.151) in the
interval (a, b] is given by the formula
#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
=
N

k=0
Œº

VN+1(b) ‚ü®Gk(a, b)‚ü©, VN+1(b) ‚ü®Gk+1(a, b)‚ü©

+ŒºVN+1(b) ‚ü®Z[0]
N+1(a)‚ü©, VN+1(b)V‚àí1
N+1(a) (0 I)T ,
Gk(a, b) := [Z[N+1]
k
(b)]‚àí1Z[0]
k (a).
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.123)

432
6
Miscellaneous Topics on Symplectic Systems
In particular, for a := Œª and Œª < Œª1 = min œÉ, formula (6.123) presents the number
of Ô¨Ånite eigenvalues of (5.1), (5.151), which are less than or equal to b.
Proof We use that problem (5.1), (5.151) is equivalent to the Ô¨Årst problem in (6.115)
with separated endpoints. The result then follows from Theorem 6.23.
‚äì‚äî
Remark 6.30
(i) Using Lemmas 4.47 and 3.39, it is possible to show (see [121, Remark 4.5.10])
that in case of separated boundary conditions, the identity
#( ÀÜZ[R](b), Z[L](a), 0, N + 1) = #( ÀÜZ[R](b), Z[L](a), ‚àí1, N + 1)
holds, where the number on the left-hand side is given by (6.118), (6.119),
(6.120) and on the right-hand side in accordance with DeÔ¨Ånition 6.21. It should
be emphasized that ‚Äúcomponentwise‚Äù identities
#N+1( ÀÜZ[R](b), Z[L](a)) = #N+1( ÀÜZ[R](b), Z[L](a)) + #‚àí1( ÀÜZ[R](b), Z[L](a))
and
#( ÀÜZ[R](b), Z[L](a), 0, N) = #( ÀÜZ[R](b), Z[L](a), 0, N)
do not necessarily hold in general, but they hold in the case when ÀÜSk(Œª) ‚â°
Sk(Œª) for all k ‚àà[0, N]Z.
(ii) For the case R1(Œª) ‚â°ÀÜR1(Œª) ‚â°R1 and R2(Œª) ‚â°ÀÜR2(Œª) ‚â°R2, i.e., when the
boundary conditions are the same and are independent on Œª, we have by (6.119)
that #N+1( ÀÜZ[R](b), Z[L](a)) = 0. In particular, for the Dirichlet boundary
conditions, we put VN+1(Œª) ‚â°ÀÜVN+1(Œª) = I4n, and then Theorem 6.28 reduces
to Theorem 6.2.
By analogy with the case of separated endpoints, consider the case when
problems differ in the boundary conditions only.
Corollary 6.31 Under all assumptions of Theorem 6.28, suppose additionally that
Sk(Œª) ‚â°ÀÜSk(Œª) for all k ‚àà[0, N]Z and a = b. Then the difference of the numbers of
Ô¨Ånite eigenvalues of problems (5.1), (5.151) and (6.1), (6.3) is given by the formula
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} = #N+1( ÀÜZ[R](b), Z[L](b)) ‚àíP,
(6.124)
with the constant P deÔ¨Åned by
P := #N+1( ÀÜZ[R](Œª), Z[L](Œª)) = ÀÜ‚Ñì‚àí‚Ñì,
Œª ‚â§Œª0 := min œÉ ‚à™ÀÜœÉ,
(6.125)
where the relative oscillation number for k = N + 1, a = b is given by (6.119) and
the constants ‚Ñìand ÀÜ‚Ñìare determined in Theorem 6.28.

6.2
Inequalities for Finite Eigenvalues
433
Remark 6.32 As for the case of the separated boundary conditions, under the
assumptions of Corollary 6.31, suppose that the boundary conditions in (5.151)
, (6.3) do not depend on Œª, i.e., Rk(Œª) ‚â°Rk and ÀÜRk(Œª) ‚â°ÀÜRk for k ‚àà{1, 2}. Then
the second addend in the deÔ¨Ånition of #N+1( ÀÜZ[R](Œª), Z[L](Œª)) does not depend on
Œª as well and formula (6.124) takes the form
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
= Œº
 ÀÜVN+1‚ü®Z[0]
N+1(b)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
‚àíÀúP,

(6.126)
where the new constant ÀúP is connected with P given by (6.125) as follows
ÀúP = P + Œº‚àó ÀÜV‚àí1
N+1(0 I)T, V‚àí1
N+1(0 I)T 
= Œº ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T ,
Œª ‚â§Œª0 := min œÉ ‚à™ÀÜœÉ.

(6.127)
6.2
Inequalities for Finite Eigenvalues
In this section we derive inequalities for eigenvalues of problems (6.17), resp.,
for (6.98), resp., for (5.1), (5.151) and (6.1), (6.3), by using inequalities for their
spectral functions. As in Sect. 6.1, we consider these spectral problems under the
assumptions, which guarantee that the Ô¨Ånite spectra are bounded from below. We
order the Ô¨Ånite eigenvalues Œªk ‚ààœÉ of (5.1), (5.151), resp., of ÀÜŒªk ‚ààÀÜœÉ of (6.1), (6.3),
into nondecreasing sequences (see (6.19)) as
‚àí‚àû< Œª1 ‚â§Œª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§Œªm ‚â§. . . ,
‚àí‚àû< ÀÜŒª1 ‚â§ÀÜŒª2 ‚â§¬∑ ¬∑ ¬∑ ‚â§ÀÜŒªl ‚â§. . . .
We also put Œª1 := ‚àû(ÀÜŒª1 := ‚àû) if œÉN = ‚àÖ(ÀÜœÉN = ‚àÖ). According to (6.20) we
deÔ¨Åne Œª0 := min{Œª1, ÀÜŒª1}. For the proofs of the subsequent results, we need the
following.
Proposition 6.33 Assume that for some K ‚ààN ‚à™{0} the inequality
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚â•‚àíK,
(6.128)
holds and that there exists a Ô¨Ånite eigenvalue Œªj+K
‚ààœÉ, j
‚â•1, of prob-
lem (5.1), (5.151). Then there exists the Ô¨Ånite eigenvalue ÀÜŒªj ‚ààÀÜœÉ of (6.1), (6.3),
and it satisÔ¨Åes
ÀÜŒªj ‚â§Œªj+K.
(6.129)

434
6
Miscellaneous Topics on Symplectic Systems
If, instead of (6.128), we have
#{ŒΩ ‚ààÀÜœÉ | ŒΩ < b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚â•‚àíK,
(6.130)
then the inequality in (6.129) is strict, i.e.,
ÀÜŒªj < Œªj+K.
(6.131)
Proof If there exists Œªj+K ‚ààœÉ (with j ‚â•1), then #{ŒΩ ‚ààœÉ | ŒΩ ‚â§Œªj+K} ‚â•j + K
(note that #{ŒΩ ‚ààœÉ | ŒΩ ‚â§Œªj+K} = j + K if Œªj+K is simple) and, according to
assumption (6.128),
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§Œªj+K} ‚â•#{ŒΩ ‚ààœÉ | ŒΩ ‚â§Œªj+K} ‚àíK ‚â•j.
Consequently, there exist ÀÜŒªj ‚ààÀÜœÉ and (6.129) holds. If (6.130) holds, then repeating
the arguments from the proof of the inequality ÀÜŒªj ‚â§Œªj+K, we obtain #{ŒΩ ‚ààÀÜœÉ | ŒΩ <
Œªj+K} ‚â•j. Consequently, the strict inequality (6.131) holds.
‚äì‚äî
In Sect. 6.2.1 we compare the Ô¨Ånite eigenvalues of (5.1), (5.151) and (6.1), (6.3)
under some majorant assumptions for their symplectic coefÔ¨Åcient matrices and
for the matrices in the boundary conditions. There, the consideration is based
on Theorems 6.22 and 6.28, whose assumptions guarantee that œÉ and ÀÜœÉ are
also bounded from above. In Sect. 6.2.2 we consider problems (5.1), (5.151)
and (6.1), (6.3), which differ only in the boundary conditions. For this case we admit
the oscillations of the block Bk(Œª) of Sk(Œª) at ‚àû, which implies that the spectra œÉ
and/or ÀÜœÉ may be unbounded from above. We derive the interlacing properties of
Ô¨Ånite eigenvalues based on the pair of the inequalities
ÀÜŒªj ‚â§Œªj+K,
Œªp ‚â§ÀÜŒªp+ ÀÜK,
p ‚â•1,
j ‚â•1,
K ‚â•0,
ÀÜK ‚â•0,
(6.132)
for the Ô¨Ånite eigenvalues of problems (5.1), (5.151) and (6.1), (6.3) with joint and
separated endpoints.
6.2.1
Comparison of Finite Eigenvalues
In this subsection we prove inequality (6.129) under suitable majorant conditions.
In particular, we investigate the case when (6.129) holds with K = 0 and the
Ô¨Ånite eigenvalues ÀÜŒªj ‚ààÀÜœÉ for (6.1), (6.3) lie below the Ô¨Ånite eigenvalues Œªj ‚ààœÉ
for (5.1), (5.151), i.e.,
ÀÜŒªj ‚â§Œªj.
(6.133)

6.2
Inequalities for Finite Eigenvalues
435
This fact is also proven for problems (6.17) with the Dirichlet boundary conditions,
as well as for (6.98) with the separated endpoints. All these results can be derived
as corollaries to Theorems 6.2, 6.22, and 6.28.
The following theorem formulates sufÔ¨Åcient conditions for inequalities (6.129)
and (6.133), when the boundary conditions are separated.
Theorem 6.34 Under the assumptions of Theorem 6.22, suppose that for the
symplectic coefÔ¨Åcient matrices Sk(Œª) and ÀÜSk(Œª), we have the majorant condition
Œº‚ü®ÀÜSk(Œª)‚ü©, ‚ü®Sk(Œª‚ü© = 0,
Œª ‚ààR,
k ‚àà[0, N]Z,
(6.134)
and the matrix coefÔ¨Åcients in the boundary conditions (6.98) obey the assumption
Œº
‚àíÀÜRT
0 (Œª)
ÀÜR‚àóT
0 (Œª)

,
‚àíRT
0 (Œª)
R‚àóT
0
(Œª)

= Œº‚àó
‚àíÀÜRT
N+1(Œª)
ÀÜR‚àóT
N+1(Œª)

,
‚àíRT
N+1(Œª)
R‚àóT
N+1(Œª)

= 0, Œª ‚ààR.
(6.135)
Then for the constant P given by (6.106), we have that inequality (6.129) holds with
K := P ‚â•0, provided the Ô¨Ånite eigenvalue Œªj+K ‚ààœÉ, j ‚â•1, exists. In particular,
inequality (6.133) holds when
P = 0.
(6.136)
Proof Note that condition (6.135) can be rewritten in the form
Œº ÀÜV‚àí1(Œª)(0 I)T , V‚àí1(Œª)(0 I)T 
= Œº‚àó ÀÜV ‚àí1
N+1(Œª) (0 I)T , V ‚àí1
N+1(Œª) (0 I)T 
= 0,
Œª ‚ààR,

(6.137)
for the matrices Vk(Œª) and ÀÜVk(Œª) for k ‚àà{‚àí1, N+1} deÔ¨Åned by (6.100) and (6.101).
Then, under assumptions (6.134) and (6.137), the relative oscillation numbers given
by (6.103) with a = b := Œª are nonnegative, i.e.,
#k
 ÀÜZ[N+2](Œª), Z[‚àí1](Œª)

‚â•0,
k ‚àà[‚àí1, N + 1]Z,
Œª ‚ààR.
(6.138)
Next, by (6.138) we derive according to (6.105) that
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§Œªj} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§Œªj} ‚â•‚àíP,
(6.139)
where P ‚â•0, because of (6.138) and (6.106). The result then follows from
Proposition 6.33.
‚äì‚äî

436
6
Miscellaneous Topics on Symplectic Systems
Remark 6.35
(i) The majorant condition in (6.134), including the main important special cases
of (SDS), is discussed in Remark 4.51. Note also that condition (5.321)
from Theorem 5.89 is sufÔ¨Åcient for (6.134), because of Lemma 3.25 and
formula (3.74); see Remark 4.51(i).
(ii) Note that condition
ÀÜ‚Ñì= 0
(6.140)
with the constant ÀÜ‚Ñìgiven by (5.215) for the second problem in (6.98) (see
Theorem 6.22) is sufÔ¨Åcient for (6.136). Indeed, according to (6.106), under
assumptions (6.134) and (6.137), we have by (6.138) and (6.140) that
0 ‚â§P = #k
 ÀÜZ[N+2](Œª), Z[‚àí1](Œª)

= ‚àí‚Ñì‚â§0,
k ‚àà[‚àí1, N + 1]Z,
and then P = ‚àí‚Ñì= 0 as well. Finally, condition (6.140) implies (6.136).
(iii) Recall that condition (6.140) is equivalent to the existence of Œª00 < 0 such
that the quadratic functional ÀÜG(y, Œª) in (5.188) associated with the second
problem in (6.98) obeys the condition ÀÜG(¬∑, Œª00) > 0. For problems (6.98)
with the special linear dependence on Œª (see (5.239) and (5.245)), sufÔ¨Åcient
conditions for ÀÜG(¬∑, Œª00) > 0 are given in Propositions 5.66 and 5.67 (see
also Remark 5.68). We recall that equivalent conditions to ÀÜG(¬∑, Œª00) > 0 are
presented in Theorem 2.50.
For the problems (6.17) with the Dirichlet boundary conditions, assump-
tion (6.137) is automatically satisÔ¨Åed. Then we have the following corollary to
Theorem 6.34.
Corollary 6.36 Under the assumptions of Theorem 6.2, suppose that (6.134) holds.
Then inequality (6.129) holds for the Ô¨Ånite eigenvalues of problems (6.17) with K :=
P ‚â•0, where the constant P is given by (6.28). In particular, for the case (6.136),
we have inequality (6.133).
Remark 6.37
(i) It follows from Remark 6.35(ii) that the condition
ÀÜm = 0
(6.141)
with ÀÜm deÔ¨Åned by (5.47) for the second problem in (6.17) (see also Theo-
rem 6.2) is sufÔ¨Åcient for (6.136). Moreover, condition (6.141) is equivalent to
the existence of Œª00 < 0 such that the quadratic functional ÀÜF(y, Œª) in (5.138)
associated with the second problem in (6.17) obeys the condition ÀÜF(¬∑, Œª00) > 0
(see Proposition 5.30).

6.2
Inequalities for Finite Eigenvalues
437
(ii) For the case when problems (6.17) obey assumption (6.35), condition (6.134)
can be replaced by
[X[0]
k+1(Œª)]T [Ck(Œª) ÀÜDT
k (Œª) ‚àíDk(Œª) ÀÜCT
k (Œª)] X[0]
k+1(Œª) ‚â•0,
(6.142)
where Ck(Œª), Dk(Œª) and ÀÜCk(Œª), ÀÜDk(Œª) are the blocks of Sk(Œª) and ÀÜSk(Œª),
respectively (see (5.2) and (6.2)). Here X[0]
k+1(Œª) is the upper block of the
principal solution Y [0](Œª) of the Ô¨Årst problem in (6.17) evaluated at k + 1.
In particular, condition (6.142) holds under the assumption
Ck(Œª) ÀÜDT
k (Œª) ‚àíDk(Œª) ÀÜCT
k (Œª) ‚â•0.
(6.143)
The proof follows from Theorem 6.8 and from formula (6.52), where we use
that (6.142) is equivalent to ÀúBk(a, b) ‚â•0 with a = b := Œª.
(iii) For the pair of eigenvalue problems (6.17) with the special linear dependence
on Œª in (6.42), condition (6.142) takes the form
[X[0]
k+1(Œª)]T [Œª ( ÀÜWk ‚àíWk) + Ck ÀÜDT
k ‚àíDk ÀÜCT
k ] X[0]
k+1(Œª) ‚â•0,
(6.144)
see (6.43). Note that under the additional assumption
ÀÜWk > 0 for k ‚àà
[0, N]Z condition (6.141) is satisÔ¨Åed due to Proposition 5.69, and then
inequality (6.133) holds. In particular, for Sturm-Liouville eigenvalue prob-
lems (6.9), (6.10), condition (6.144) takes the form [x[0]
k+1(Œª)]2(pk ‚àíÀÜpk) ‚â•0
for k ‚àà[0, N ‚àí1]Z, and it certainly implies (6.133), because for this case
ÀÜWk = 1.
(iv) For the discrete matrix Sturm-Liouville spectral problems in Sect. 6.1.4
(see (6.63) and (6.64)), condition (6.134) can be replaced by
[U[0]
k (Œª)]T [ ÀÜR‚àí1
k (Œª) ‚àíR‚àí1
k (Œª)] U[0]
k (Œª) ‚â•0,
[X[0]
k+1(Œª)]T [Qk(Œª) ‚àíÀÜQk(Œª)] X[0]
k+1(Œª) ‚â•0,

(6.145)
where X[0]
k (Œª) and U[0]
k (Œª) are the blocks of the principal solution Y [0](Œª)
of (6.63), i.e., X[0]
0 (Œª) = 0 and U[0]
0 (Œª) = R0(Œª) X[0]
0 (Œª) = I. By
analogy with the proof of Theorem 6.34, we use Remark 6.18 to show that
condition (6.145) implies (6.129) with K := ÀúP given by (6.91). Moreover,
under the assumption ÀúP = 0, we have inequality (6.133) for the Ô¨Ånite
eigenvalues of (6.63) and (6.64). Note that the conditions in (6.145) follow
from the classical majorant assumptions Rk(Œª) ‚â•ÀÜRk(Œª) > 0 and Qk(Œª) ‚â•
ÀÜQk(Œª) (see Proposition 6.15 (ii) and Remark 3.35).
The last result of this subsection is devoted to problems (5.1), (5.151)
and (6.1), (6.3) with joint endpoints.

438
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.38 Under the assumptions of Theorem 6.28, suppose that for the
symplectic coefÔ¨Åcient matrices Sk(Œª) and ÀÜSk(Œª), we have the majorant condi-
tion (6.134), while the matrices in the boundary conditions (5.151) and (6.3) obey
Œº‚àó
‚àíÀÜRT
2 (Œª)
ÀÜRT
1 (Œª)

,
‚àíRT
2 (Œª)
RT
1 (Œª)

= 0,
Œª ‚ààR.
(6.146)
Then inequality (6.129) holds for the Ô¨Ånite eigenvalues of
(5.1), (5.151)
and (6.1), (6.3) with the constant K := P ‚â•0 and P given by (6.122), provided
the Ô¨Ånite eigenvalue Œªj+K exists. In particular, inequality (6.133) holds for the case
of (6.136).
Proof Condition (6.146) can be rewritten as
Œº‚àó ÀÜV‚àí1
N+1(Œª) (0 I)T, V‚àí1
N+1(Œª) (0 I)T 
= 0,
Œª ‚ààR,
(6.147)
where the matrices VN+1(Œª) and ÀÜVN+1(Œª) are deÔ¨Åned by (6.116). It follows that
under assumptions (6.134) and (6.146), the relative oscillation numbers given
by (6.118) and (6.119) with a = b := Œª are nonnegative, and then the proof repeats
the proof of Theorem 6.34. In particular, we derive inequality (6.139), which holds
with P given by (6.122).
‚äì‚äî
Remark 6.39 Note that, by analogy with Remark 6.35(ii), the condition (6.140)
with the constant ÀÜ‚ÑìdeÔ¨Åned by (5.436) is sufÔ¨Åcient for (6.136) with the constant P
given by (6.122). In turn, one can apply the statement of Theorem 5.57 saying that
ÀÜ‚ÑìdeÔ¨Åned by (5.436) equals to zero if and only if there exists Œª00 < 0 such that the
quadratic functional ÀÜG(y, Œª00) in (5.186) over (5.187) associated with (6.1), (6.3)
is positive deÔ¨Ånite. We recall that this positivity condition can be tested by the
properties of the principal solution Y [0](Œª00) in Theorem 2.53.
6.2.2
Interlacing of Eigenvalues for Joint Endpoints
In this subsection we consider problems (5.1), (5.151) and (6.1), (6.3) with the same
coefÔ¨Åcient matrices Sk(Œª) ‚â°ÀÜSk(Œª) and with the boundary conditions which are
independent on Œª, i.e.,
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N]Z,
R1
 x0(Œª)
xN+1(Œª)

+ R2
 ‚àíu0(Œª)
uN+1(Œª)

= 0,
ÀÜyk+1(Œª) = Sk(Œª) ÀÜyk(Œª),
k ‚àà[0, N]Z,
ÀÜR1
 ÀÜx0(Œª)
ÀÜxN+1(Œª)

+ ÀÜR2
 ‚àíÀÜu0(Œª)
ÀÜuN+1(Œª)

= 0.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.148)

6.2
Inequalities for Finite Eigenvalues
439
We assume that the symplectic matrix Sk(Œª) obeys the monotonicity condition (5.3)
and condition (5.333) holds. Then by Corollary 5.123 the spectra œÉ and ÀÜœÉ of (6.148)
are bounded from below.
We investigate the case when the Ô¨Ånite eigenvalues of the Ô¨Årst problem in (6.148)
or in (6.181) interlace the Ô¨Ånite eigenvalues of the second one, i.e., we derive the
inequalities (6.132):
ÀÜŒªj ‚â§Œªj+K,
Œªp ‚â§ÀÜŒªp+ ÀÜK,
p ‚â•1, j ‚â•1,
K ‚â•0, ÀÜK ‚â•0,
provided the Ô¨Ånite eigenvalues Œªj+K and Œªp+ ÀÜK exist. Now we formulate conditions,
when inequalities (6.132) hold for the Ô¨Ånite eigenvalues of (6.148). Introduce the
notation
Rw := rank [(R1 R2) J ( ÀÜR1 ÀÜR2)T ],
(6.149)
for the rank of the Wronskians of boundary conditions in (6.148), and the notation
(see (5.221), (5.220), and (3.52))
RI := max
Œª‚ààI rank L(Œª),
L(Œª) := (R1 R2) /Z[0]
N+1(Œª)0,
ÀÜRI := max
Œª‚ààI rank ÀÜL(Œª),
ÀÜL(Œª) := ( ÀÜR1 ÀÜR2)
/
Z[0]
N+1(Œª)
0
,
‚é´
‚é¨
‚é≠
(6.150)
where Z[0](Œª) is the fundamental matrix of the symplectic system in (6.148) such
that Z[0]
0 (Œª) = I for Œª ‚ààR and the interval I ‚äÜR can be of the form I = [a, b] or
I = (‚àû, b].
Remark 6.40
(i) Recall that by the monotonicity assumption for the matrix Sk(Œª) (see (5.3)),
the functions rankL(Œª) and rank ÀÜL(Œª) are piecewise constant with respect to
Œª ‚àà[a, b] and then the maxima in (6.150) are attained for some Œª ‚àà[a, b].
Moreover, for the case I := (‚àû, b] we use (5.333) which guaranties that
rankL(Œª) and rank ÀÜL(Œª) are constant for all Œª < Œª0 = min{Œª1, ÀÜŒª1}, and then
for this case we evaluate RI and ÀÜRI according to
R(‚àí‚àû,b] = R[Œª,b],
ÀÜR(‚àí‚àû,b] = R[Œª,b],
Œª < Œª0.
(6.151)
(ii) For the case when the spectra are unbounded from above (recall that in this
subsection we assume only condition (5.333)), we introduce the notation
R := sup
Œª‚ààR
rankL(Œª) ‚â§2n,
ÀÜR := sup
Œª‚ààR
rank ÀÜL(Œª) ‚â§2n.
(6.152)

440
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.41 Consider the pair of eigenvalue problems (6.148) under assump-
tions (5.2), (5.3), (5.152), (6.4), and (5.333). Then for a, b ‚ààR, a < b, we have
		# {ŒΩ ‚ààÀÜœÉ | a < ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
		
‚â§min{ra,b, ÀÜra,b, Rw} ‚â§min{RI, ÀÜRI, Rw} ‚â§2n,
I = [a, b],
ra,b := max{rankL(a), rank L(b)},
ÀÜra,b := max{rank ÀÜL(a), rank ÀÜL(b)}.
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.153)
Proof The proof is based on Corollary 6.31 and Remark 6.32. The proof of (6.153)
is derived by analogy with the proof of Corollary 4.25 in Sect. 4.2.2. According
to (6.126) we have
#{ŒΩ ‚ààÀÜœÉ | a < ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
= #{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§a} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} + #{ŒΩ ‚ààœÉ | ŒΩ ‚â§a}
= Œº
 ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 		b
a.
Then it follows that
				Œº
 ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 		b
a
				
‚â§max

Œº
 ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
, Œª ‚àà{a, b}
 
and by Theorem 3.5(vii) the comparative indices on the right-hand side of the above
inequality satisfy the estimate
Œº
 ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
‚â§min{rankL(Œª), Rw}.
(6.154)
Then we have that
		#{ŒΩ ‚ààÀÜœÉ | a < ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
		 ‚â§min{Rw, ra,b} ‚â§min{Rw, RI},
where ra,b is deÔ¨Åned by (6.153). Replacing the roles of the problems (6.148) (and
then interchanging VN+1 and ÀÜVN+1 in (6.154)), we have a similar estimate
		#{ŒΩ ‚ààÀÜœÉ | a < ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
		 ‚â§min{Rw, ÀÜra,b} ‚â§min{Rw, ÀÜRI}
with ÀÜra,b deÔ¨Åned by (6.153) for the second problem in (6.148). Finally, the
combination of the estimates above proves (6.153).
‚äì‚äî

6.2
Inequalities for Finite Eigenvalues
441
Using (5.333), which guaranties that the spectra of (6.148) are bounded from
below (see Corollary 5.123), one can formulate the following corollary to Theo-
rem 6.41.
Corollary 6.42 Under the assumptions of Theorem 6.41, we have for any b ‚ààR
		#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
		 ‚â§ÀúK = min{R, ÀÜR, Rw} ‚â§2n
(6.155)
with the constants R, ÀÜR, and Rw given by (6.152) and (6.149). In particular,
inequalities (6.132) hold with K = ÀÜK := ÀúK, where ÀúK is deÔ¨Åned by (6.155).
Proof The proof of (6.155) follows from (6.153), where one can put a := Œª with
Œª < Œª0 = min{Œª1, ÀÜŒª1}, and then by Proposition 6.33, we have that (6.132) hold
with K = ÀÜK := ÀúK.
‚äì‚äî
Now we specify the results of Corollary 6.42 by imposing more restrictions on
the behavior of L(Œª) and ÀÜL(Œª) with respect to Œª. In particular, the restrictions below
hold for problems (6.148) with the matrix Sk(Œª), which is a polynomial in Œª. For
this case L(Œª) and ÀÜL(Œª) are also polynomials. Note that the restrictions are also
satisÔ¨Åed for the special linear dependence in Œª; see Sect. 5.3.
Theorem 6.43 Under the assumptions of Theorem 6.41, suppose additionally that
for R and ÀÜR given by (6.152) we have
R := sup
Œª‚ààR
rank L(Œª) = rankL(Œª),
ÀÜR := sup
Œª‚ààR
rank ÀÜL(Œª) = rank ÀÜL(Œª),
‚é´
‚é™‚é¨
‚é™‚é≠
Œª < Œª0 = min{Œª1, ÀÜŒª1}.
(6.156)
Then
‚àíÀÜK ‚â§#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚â§K,
K := min{ ÀúP, ÀÜR ‚àíRw + ÀúP} ‚â•0,
ÀÜK := min{Rw ‚àíÀúP, R ‚àíÀúP} ‚â•0,
ÀÜK + K ‚â§min{Rw, R, ÀÜR} ‚â§2n,
‚é´
‚é™‚é¨
‚é™‚é≠
(6.157)
where the constant ÀúP is deÔ¨Åned by (6.127). In particular, inequalities (6.132) for
the Ô¨Ånite eigenvalues of (6.148) hold with K and ÀÜK given by (6.157).
Proof Under assumptions (6.156) we have for b ‚ààR
rank L(œÑ)
		b
Œª ‚â§0,
rank ÀÜL(œÑ)
		b
Œª ‚â§0,
Œª < Œª0.
(6.158)
Next we rewrite (6.126) in the form
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b}
= ÀúP ‚àíŒº

ÀÜVN+1‚ü®Z[0]
N+1(b)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
.
‚é´
‚é¨
‚é≠
(6.159)

442
6
Miscellaneous Topics on Symplectic Systems
Then we obtain
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚â§ÀúP.
(6.160)
The difference in (6.159) can be also estimated using the relation
Œº  ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
= Rw ‚àírank ÀÜL(Œª) + Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©

,

(6.161)
where we apply Theorem 3.5(vi) and use the notation (6.149) and (6.150). Apply-
ing (6.161) to both addends in (6.159), we obtain
ÀúP ‚àíŒº

ÀÜVN+1‚ü®Z[0]
N+1(b)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
= rank ÀÜL(œÑ)|b
Œª + Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1‚ü®Z[0]
N+1(b)‚ü©
		Œª
b
‚â§Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü© = ÀÜR ‚àíRw + ÀúP,
Œª < Œª0,
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.162)
where Œª0 = min{Œª1, ÀÜŒª1} and ÀÜR is given by (6.156). Then we also have
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚â§ÀÜR ‚àíRw + ÀúP.
(6.163)
Combining (6.159) and (6.163), we derive the right estimate in (6.157). To prove the
left estimate, we replace the roles of the problems in the proof given above. Then
we have
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚â§ÀÜK := min{ ÀÜP, R ‚àíRw + ÀÜP},
(6.164)
where by Theorem 3.5(ix)
ÀÜP := Œº

VN+1‚ü®Z[0]
N+1(Œª)‚ü©, VN+1 ÀÜV‚àí1
N+1(0 I)T 
= Rw ‚àíŒº
 ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©, ÀÜVN+1V‚àí1
N+1(0 I)T 
= Rw ‚àíÀúP,
Œª < Œª0;
compare with (6.127). Using the last relation, we see that ÀÜK deÔ¨Åned in (6.164) is
the same as in (6.157). Finally, the estimate for the sum ÀÜK + K can be proved by
direct computations. Indeed, the values of K and ÀÜK depend on the signs of Rw ‚àíÀÜR
and Rw ‚àíR, respectively. So we have
ÀÜK + K =
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
R + ÀÜR ‚àíRw, Rw > max{R, ÀÜR},
R,
R < Rw ‚â§ÀÜR,
ÀÜR,
R ‚â•Rw > ÀÜR,
Rw,
Rw ‚â§min{R, ÀÜR}.

6.2
Inequalities for Finite Eigenvalues
443
From the formula above, we derive the last estimate in (6.157). By Proposition 6.33
we then have that (6.132) hold with K and
ÀÜK given by (6.157). The proof is
completed.
‚äì‚äî
The last result for the case of joint endpoints concerns the strict inequalities
in (6.132).
Theorem 6.44 Under the assumptions of Theorem 6.43, suppose additionally
ÀÜR ‚â§Rw.
(6.165)
Then the Ô¨Årst inequality in (6.132) is strict, i.e., ÀÜŒªj < Œªj+K for j ‚â•1. Similarly, the
condition
R ‚â§Rw
(6.166)
implies that the second inequality in (6.132) is strict, i.e., Œªp < ÀÜŒªp+ ÀÜK for p ‚â•1.
Proof From (6.165) it follows that for K given by (6.157), we have for Œª < Œª0
K = ÀÜR ‚àíRw + ÀúP = Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1
/
Z[0]
N+1(Œª)
0
.
On the other hand, according to (6.159) and (6.162), we have for Œª < Œª0
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b}
= rank ÀÜL(œÑ)
		b
Œª + Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1‚ü®Z[0]
N+1(b)‚ü©
		Œª
b
= ‚àíÀÜŒ∂(b) + rank ÀÜL(œÑ)
		b‚àí
Œª + Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1‚ü®Z[0]
N+1(b)‚ü©
		Œª
b
‚â§‚àíÀÜŒ∂(b) + K,
where ÀÜŒ∂(b) is the multiplicity of ÀÜŒª = b ‚ààÀÜœÉ, or ÀÜŒ∂(b) = 0 if b /‚ààÀÜœÉ, according to
DeÔ¨Ånition 5.54. That is,
ÀÜŒ∂(Œª) = rank ÀÜL(Œª‚àí) ‚àírank ÀÜL(Œª).
(6.167)
From the last estimate, we derive
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ < b} ‚â§K,
or equivalently
#{ŒΩ ‚ààÀÜœÉ | ŒΩ < b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚â•‚àíK.
From the last inequality and Proposition 6.33, we obtain that ÀÜŒªj < Œªj+K for j ‚â•1.
The proof of the second strict inequality is similar.
‚äì‚äî

444
6
Miscellaneous Topics on Symplectic Systems
Remark 6.45
(i) It follows from the results of Corollary 6.42 that between the Ô¨Ånite eigenvalues
Œªj‚àíÀúK, Œªj+ ÀúK ‚ààœÉ (j >
ÀúK ‚â•0), there exists the Ô¨Ånite eigenvalue ÀÜŒªj ‚ààÀÜœÉ.
Similarly, between the Ô¨Ånite eigenvalues ÀÜŒªp‚àíÀúK, ÀÜŒªp+ ÀúK ‚ààÀÜœÉ (p >
ÀúK ‚â•0),
there exists the Ô¨Ånite eigenvalue Œªp
‚ààœÉ. By estimate (6.155) we have
ÀúK ‚â§2n, and then the distance between the indices of the Ô¨Ånite eigenvalues
Œªj+ ÀúK, Œªj‚àíÀúK ‚ààœÉ (or ÀÜŒªp+ ÀúK, ÀÜŒªp‚àíÀúK ‚ààÀÜœÉ) is equal to 2 ÀúK ‚â§4n. At the same time,
by Theorem 6.43, similar arguments applied to Œªj‚àíÀÜK, Œªj+K ‚ààœÉ (j > ÀÜK ‚â•0)
imply that the distance between the indices of Œªj+K, Œªj‚àíÀÜK ‚ààœÉ (j > ÀÜK ‚â•0)
is much smaller than 4n, i.e., K + ÀÜK ‚â§2n (see (6.157)). A similar assertion
holds for ÀÜŒªp‚àíK, ÀÜŒªp+ ÀÜK ‚ààÀÜœÉ (p > K ‚â•0).
(ii) It follows from the formulas for the number ÀÜK in (6.157) that ÀÜK = 0 if and
only if the comparative index
Œº
 ÀÜVN+1
/
Z[0]
N+1(Œª)
0
, ÀÜVN+1V‚àí1
N+1(0 I)T 
= ÀúP,
Œª < Œª0,
attains one of its extremal values Rw or R (see property (vii) of Theorem 3.5
and (6.154)). For the case ÀúP = R, we have ÀÜP = Rw ‚àíR ‚â•0 (see (6.164)), and
then the inequality Œªp < ÀÜŒªp (p ‚â•1) is strict according to the second assertion
in Theorem 6.44. A similar situation occurs for the constant K when changing
the roles of the problems in (6.148). In this case we have to demand ÀúP = 0 or
ÀúP = Rw ‚àíÀÜR ‚â•0. Note that for the last case the inequality ÀÜŒªj < Œªj (j ‚â•1) is
strict (see Theorem 6.44).
(iii) The simplest sufÔ¨Åcient condition for K = 0 in (6.157) is represented by the
majorant condition (6.146) (see Theorem 6.38) coupled with the condition ÀÜ‚Ñì=
0, where the constant ÀÜ‚Ñìis deÔ¨Åned in Theorem 6.28 (see (6.122)). Indeed, by
Remark 6.39 and (6.127), these conditions are sufÔ¨Åcient for ÀúP = 0 and then
also for K = 0.
(iv) One can construct an example of problems (6.148) with a piecewise continu-
ously differentiable matrix Sk(Œª) such that conditions (6.156) do not hold (see
Example 5.103).
Next we present an example showing that estimates (6.157) are exact.
Example 6.46 Consider the eigenvalue problem for n = 2 and N = 4 with the
periodic boundary conditions
4yk+1 = Sk(Œª)4yk,
4y0 = 4yN+1,
(6.168)
with the matrix Sk given by
Sk(Œª) =
‚éõ
‚éú‚éú‚éù
1 0 0 0
0 1 0 0
0 0 1 0
0 ‚àíŒª 0 1
‚éû
‚éü‚éü‚é†
‚éõ
‚éú‚éú‚éù
1 0 0 0
0 0 0 1
0 0 1 0
0 ‚àí1 0 0
‚éû
‚éü‚éü‚é†=
‚éõ
‚éú‚éú‚éù
1 0 0 0
0 0 0 1
0 0 1 0
0 ‚àí1 0 ‚àíŒª
‚éû
‚éü‚éü‚é†.
(6.169)

6.2
Inequalities for Finite Eigenvalues
445
This eigenvalue problem is equivalent to the problem (see Remark 5.58)
4yk+1 = Sk(Œª)4yk,
 0 0
‚àíI I
  4x0
4xN+1

+
‚àíI ‚àíI
0
0
  ‚àí4u0
4uN+1

= 0,
(6.170)
and consequently to the eigenvalue problem (5.180) with the separated endpoints
Àúyk+1 = {Sk(Œª)} Àúyk,
 0 0
‚àíI I

Àúx0 +
‚àíI ‚àíI
0
0

Àúu0 = 0,
 0 0
‚àíI I

ÀúxN+1 +
‚àíI ‚àíI
0
0

ÀúuN+1 = 0.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(6.171)
The matrix Yk = ‚ü®Zk‚ü©with Z0 = I is a conjoined basis of this system satisfying
the required boundary condition at k = 0. Hence, the matrix ÀÜL(Œª) (see (5.221) and
Remark 5.58) for this problem is of the form
ÀÜL(Œª) =
 0 0 ‚àíI ‚àíI
‚àíI I
0
0

‚ü®ZN+1‚ü©= ‚àíJ [ZN+1(Œª) ‚àíI],
(6.172)
and the symplectic fundamental matrix of (6.168) is of the form
Z0(Œª) = I,
Z1(Œª) =
‚éõ
‚éú‚éú‚éù
1 0 0 0
0 0 0 1
0 0 1 0
0 ‚àí1 0 ‚àíŒª
‚éû
‚éü‚éü‚é†,
Z2(Œª) =
‚éõ
‚éú‚éú‚éù
1 0 0
0
0 ‚àí1 0
‚àíŒª
0 0 1
0
0 Œª 0 ‚àí1 + Œª2
‚éû
‚éü‚éü‚é†,
Z3(Œª) =
‚éõ
‚éú‚éú‚éù
1
0
0
0
0
Œª
0 ‚àí1 + Œª2
0
0
1
0
0 1 ‚àíŒª2 0 2Œª ‚àíŒª3
‚éû
‚éü‚éü‚é†,
Z4(Œª) =
‚éõ
‚éú‚éú‚éù
1
0
0
0
0
1 ‚àíŒª2
0
2Œª ‚àíŒª3
0
0
1
0
0 ‚àí2Œª + Œª3 0 1 ‚àí3Œª2 + Œª4
‚éû
‚éü‚éü‚é†,
Z5(Œª) =
‚éõ
‚éú‚éú‚éù
1
0
0
0
0
‚àí2Œª + Œª3
0
1 ‚àí3Œª2 + Œª4
0
0
1
0
0 ‚àí1 + 3Œª2 ‚àíŒª4 0 ‚àí3Œª + 4Œª3 ‚àíŒª5
‚éû
‚éü‚éü‚é†.

446
6
Miscellaneous Topics on Symplectic Systems
Then
rank [Z5(Œª) ‚àíI] = rank T (Œª),
T (Œª) =

‚àí2Œª + Œª3 ‚àí1
1 ‚àí3Œª2 + Œª4
‚àí1 + 3Œª2 ‚àíŒª4 ‚àí3Œª + 4Œª3 ‚àíŒª5 ‚àí1

, det T (Œª) = (Œª + 2)(Œª2 ‚àíŒª ‚àí1)2.
The spectrum ÀÜœÉ is given by the equation det T (Œª) = 0, so that
ÀÜœÉ =

ÀÜŒª1 = ‚àí2, ÀÜŒª2 = ÀÜŒª3 = 1
2 ‚àí
‚àö
5
2 , ÀÜŒª4 = ÀÜŒª5 = 1
2 +
‚àö
5
2
 
.
We compare the spectrum ÀÜœÉ of this problem with the spectrum œÉ of the following
eigenvalue problem
yk+1 = Sk(Œª) yk,
u0 = xN+1, x0 = ‚àíuN+1.
(6.173)
This eigenvalue problem we can rewrite into the form
yk+1 = Sk(Œª) yk,
 0 ‚àíI
‚àíI
0
  x0
xN+1

+
‚àíI
0
0 ‚àíI
  ‚àíu0
uN+1

= 0,
‚é´
‚é™‚é¨
‚é™‚é≠
(6.174)
which is equivalent to the eigenvalue problem with separated boundary conditions
¬Øyk+1 = {Sk(Œª)} ¬Øyk,
 0 0
‚àíI I

¬Øx0 +
‚àíI ‚àíI
0
0

¬Øu0 = 0,
 0 ‚àíI
‚àíI
0

¬ØxN+1 +
‚àíI
0
0 ‚àíI

¬ØuN+1 = 0.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é≠
(6.175)
The matrix L(Œª) (see (5.221)), which we use to determine the Ô¨Ånite eigenvalues, has
the form
L(Œª) = J ‚àíZN+1(Œª).
(6.176)
Consequently, for N = 4 we have
rank[Z5(Œª) ‚àíJ ] = rank
‚éõ
‚éú‚éú‚éù
1
0
‚àí1
0
0 ‚àí2Œª + Œª3 0
‚àí3Œª2 + Œª4
1
0
1
0
0 3Œª2 ‚àíŒª4
0 ‚àí3Œª + 4Œª3 ‚àíŒª5
‚éû
‚éü‚éü‚é†
= 2 + rank
‚àí2Œª + Œª3
‚àí3Œª2 + Œª4
3Œª2 ‚àíŒª4 ‚àí3Œª + 4Œª3 ‚àíŒª5

,

6.2
Inequalities for Finite Eigenvalues
447
with
det
‚àí2Œª + Œª3
‚àí3Œª2 + Œª4
3Œª2 ‚àíŒª4 ‚àí3Œª + 4Œª3 ‚àíŒª5

= ‚àí2Œª2(Œª2 ‚àí3).
Hence, the spectrum is
œÉ =

Œª1 = ‚àí
‚àö
3, Œª2 = 0, Œª3 = 0, Œª4 =
‚àö
3
 
.
We have computed that the Ô¨Ånite eigenvalues of (6.168), (6.173) satisfy
Œªp‚àí2 < ÀÜŒªp, p ‚àà{3, 4, 5},
ÀÜŒªj < Œªj, j ‚àà{1, 2, 3, 4},
(6.177)
where we have additionally that
ÀÜŒª2 = ÀÜŒª3 < ÀÜŒª4 = ÀÜŒª5
(6.178)
and
Œª2 = Œª3.
(6.179)
Let us verify what we obtain as a result of the application of Theorems 6.41, 6.43,
and 6.44. The matrices VN+1 and ÀÜVN+1 of the boundary conditions have the form
ÀÜV‚àí1
N+1 =
‚éõ
‚éú‚éú‚éù
0
‚àí0.5I I
0
0
0.5I I
0
‚àí0.5I
0
0 ‚àíI
‚àí0.5I
0
0 I
‚éû
‚éü‚éü‚é†,
V‚àí1
N+1 =
‚éõ
‚éú‚éú‚éù
0
‚àí0.5I I
0
‚àí0.5I
0
0
I
‚àí0.5I
0
0 ‚àíI
0
‚àí0.5I ‚àíI
0
‚éû
‚éü‚éü‚é†.
(6.180)
and Rw = 4, ÀÜR = 2, R = 4. By Theorem 6.41 (see (6.153)), in any half-open
interval (a, b], the number of Ô¨Ånite eigenvalues of the investigated problems differs
at most by two. Since ÀÜR < Rw, we have K = ÀÜR ‚àíRw + ÀúP, and from R = Rw we
obtain ÀÜK = Rw ‚àíÀúP. Consequently, ÀÜK + K = ÀÜR = 2. We show that K = 0. To this
end, note that
Œº‚àó ÀÜV‚àí1
N+1(0 I)T , V‚àí1
N+1(0 I)T 
= Rw ‚àíŒº‚àó
V‚àí1
N+1(0 I)T , ÀÜV‚àí1
N+1(0 I)T 
= 4 ‚àíŒº‚àó
2

V‚àí1
N+1(0 I)T , ÀÜV‚àí1
N+1(0 I)T 
= 4 ‚àíind
-I 0
I 0
T 0 ‚àíI
‚àíI
0
 I 0
I 0
.
= 4 ‚àí2 = 2.

448
6
Miscellaneous Topics on Symplectic Systems
Hence, the majorant condition (6.146) (see Remark 6.45(iii)) is not satisÔ¨Åed. Let us
compute the constant K. For Œª < Œª0 we have
K = ÀÜR ‚àíRw + ÀúP = Œº‚àó ÀÜVN+1V‚àí1
N+1(0 I)T , ÀÜVN+1
/
Z5(Œª)
0
= Œº‚àó
‚éõ
‚éú‚éú‚éù
‚éõ
‚éú‚éú‚éù
I
I
‚àíI
I
0.5I
0.5I
‚àí0.5I 0.5I
‚éû
‚éü‚éü‚é†,
 J [I ‚àíZ5(Œª)]
0.5 [I + Z5(Œª)]

‚éû
‚éü‚éü‚é†
= Œº‚àó
‚éõ
‚éú‚éú‚éù
‚éõ
‚éú‚éú‚éù
I
0
0
I
0.5I
0
0
0.5I
‚éû
‚éü‚éü‚é†C,
 J (I ‚àíZ5(Œª))
0.5(I + Z5(Œª))

‚éû
‚éü‚éü‚é†,
where the matrix C =
 I
I
‚àíI I

is invertible and it can be neglected in view of the
property (i) of Theorem 3.5. Consequently, for Œª < Œª0 we have
K = ind ![I ‚àíZ5(Œª)]T [I ‚àíZ5(Œª)] ‚àí[I ‚àíZ5(Œª)]T J T [I + Z5(Œª)]"
= ind
!
[I ‚àíZ5(Œª0)]T [I ‚àíZ5(Œª)] + Z5(Œª)TJ T + J Z5(Œª)
"
= ind T1(Œª),
where we have used that Zk(Œª) is a symplectic matrix. The last index leads to the
computation of the index of the matrix
T1(Œª) = AT A + B + BT ,
A :=
 2Œª ‚àíŒª3 + 1
‚àí1 + 3Œª2 ‚àíŒª4
1 ‚àí3Œª2 + Œª4 3Œª ‚àí4Œª3 + Œª5 + 1

,
B :=
‚àí1 + 3Œª2 ‚àíŒª4 ‚àí3Œª + 4Œª3 ‚àíŒª5
2Œª ‚àíŒª3
‚àí1 + 3Œª2 ‚àíŒª4

.
We have that Tr T1(Œª) ‚àºŒª10, det T1(Œª) ‚àº‚àí4Œª9 as Œª ‚Üí¬±‚àû. Hence, the
eigenvalues of T1(Œª) with Œª sufÔ¨Åciently close to ‚àí‚àûare positive. Then K = 0,
ÀÜK = 2, and by Theorem 6.44 we derive the same estimate (6.177). Finally, note
that Theorems 6.41, 6.43, and 6.44 do not provide the information in (6.178)
and (6.179). But if we know (6.178), then (6.177) gives the possibility to order
the Ô¨Ånite eigenvalues of these problems as
ÀÜŒª1 < Œª1 < ÀÜŒª2 = ÀÜŒª3 < Œª2 ‚â§Œª3 < ÀÜŒª4 = ÀÜŒª5 < Œª4.
So we see that this order is correct except of the fact that we cannot conclude
whether Œª2 = Œª3 or Œª2 < Œª3.

6.2
Inequalities for Finite Eigenvalues
449
6.2.3
Interlacing of Eigenvalues for Separated Endpoints
In this subsection we investigate the special case of (6.148) considering the
problems with the separated boundary conditions, whose coefÔ¨Åcient matrices do
not depend on Œª, i.e.,
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N]Z,
R‚àó
0 x0(Œª) + R0 u0(Œª) = 0,
R‚àó
N+1 xN+1(Œª) + RN+1 uN+1(Œª) = 0,
ÀÜyk+1(Œª) = Sk(Œª) ÀÜyk(Œª),
k ‚àà[0, N]Z,
ÀÜR‚àó
0 ÀÜx0(Œª) + ÀÜR0 ÀÜu0(Œª) = 0,
ÀÜR‚àó
N+1 ÀÜxN+1(Œª) + ÀÜRN+1 ÀÜuN+1(Œª) = 0.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.181)
As in Sect. 6.2.2, we assume that the symplectic matrix Sk(Œª) obeys the monotonic-
ity condition (5.3) and condition (5.333) holds. Then by Corollary 5.123, the spectra
œÉ and ÀÜœÉ of (6.148) are bounded from below.
Together with (6.181) we also consider two intermediate problems
Àúyk+1(Œª) = Sk(Œª) Àúyk(Œª),
k ‚àà[0, N]Z,
R‚àó
0 Àúx0(Œª) + R0 Àúu0(Œª) = 0,
ÀÜR‚àó
N+1 ÀúxN+1(Œª) + ÀÜRN+1 ÀúuN+1(Œª) = 0,
¬Øyk+1(Œª) = Sk(Œª) ¬Øyk(Œª),
k ‚àà[0, N]Z,
ÀÜR‚àó
0 ¬Øx0(Œª) + ÀÜR0 ¬Øu0(Œª) = 0,
R‚àó
N+1 ¬ØxN+1(Œª) + RN+1 ¬ØuN+1(Œª) = 0,
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.182)
under the same assumptions for Sk(Œª), so that the Ô¨Ånite spectra ÀúœÉ, ¬ØœÉ of (6.182) are
also bounded from below. We introduce the notation for the ranks of the Wronskians
of the boundary conditions in (6.181) by
rL := rank

(R0 R‚àó
0) J ( ÀÜR0 ÀÜR‚àó
0)T 
,
rR := rank 
(RN+1 R‚àó
N+1) J ( ÀÜRN+1 ÀÜR‚àó
N+1)T ,

(6.183)
and the notation (see (5.205), (5.204), and Sect. 6.1.6)
rI := max
Œª‚ààI rank(Œª),
(Œª) = (R‚àó
N+1 RN+1) Z[L]
N+1(Œª) (0 I)T ,
ÀÜrI := max
Œª‚ààI rank ÀÜ(Œª),
ÀÜ(Œª) = ( ÀÜR‚àó
N+1 ÀÜRN+1) ÀÜZ[L]
N+1(Œª) (0 I)T ,
‚é´
‚é¨
‚é≠
(6.184)

450
6
Miscellaneous Topics on Symplectic Systems
for Z[L]
k (Œª) given by (6.102) and for similarly deÔ¨Åned ÀÜZ[L]
k (Œª) with ÀÜZ[L]
0 (Œª) = ÀÜV‚àí1
with the constant matrix ÀÜV‚àí1(Œª) ‚â°ÀÜV‚àí1 in (6.101). Finally, in estimates for the
Ô¨Ånite eigenvalues of problems with the separated boundary conditions, we also use
maximal rank conditions for (6.182) with the spectra ÀúœÉ and ¬ØœÉ in the form
ÀúrI := max
Œª‚ààI rank Àú(Œª),
Àú(Œª) = ( ÀÜR‚àó
N+1 ÀÜRN+1) Z[L]
N+1(Œª) (0 I)T ,
¬ØrI := max
Œª‚ààI rank ¬Ø(Œª),
¬Ø(Œª) = (R‚àó
N+1 RN+1) ÀÜZ[L]
N+1(Œª) (0 I)T .
‚é´
‚é¨
‚é≠
(6.185)
We also use the notation (see Remark 6.40(ii))
r := sup
Œª‚ààR
rank (Œª) ‚â§n,
ÀÜr := sup
Œª‚ààR
rank ÀÜ(Œª) ‚â§n,
Àúr := sup
Œª‚ààR
rank Àú(Œª) ‚â§n,
¬Ør := sup
Œª‚ààR
rank ¬Ø(Œª) ‚â§n.
‚é´
‚é¨
‚é≠
(6.186)
Let Œª0 be given by the condition
Œª0 < min{Œª1, ÀÜŒª1, ÀúŒª1},
(6.187)
where ÀúŒª1 is the minimal Ô¨Ånite eigenvalue of the Ô¨Årst problem in (6.182) (we put
ÀúŒª1 := ‚àûif ÀúœÉ = ‚àÖ). Now we present a modiÔ¨Åcation of Theorem 6.41 for the
separated endpoints.
Theorem 6.47 Consider
the
pair
of
eigenvalue
problems
(6.181)
under
assumptions (5.2), (5.3), (5.156) for all the matrices in the boundary conditions,
and (5.333). Then for any a, b ‚ààR with a < b, we have
		#{ŒΩ ‚ààÀÜœÉ | a < ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
		
‚â§min{rL, ÀÜra,b, Àúra,b} + min{rR, ra,b, Àúra,b}
‚â§min{ÀúrI, ÀÜrI, rL} + min{ÀúrI, rI, rR} ‚â§2n,
I := [a, b],
ra,b := max{rank(a), rank(b)},
ÀÜra,b := max{rank ÀÜ(a), rank ÀÜ(b)},
Àúra,b := max{rank Àú(a), rank Àú(b)},
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.188)
where Àú(Œª) given by (6.185) is associated with the Ô¨Årst problem in (6.182).
Proof For the proof we use Remark 6.26. By (6.112) and similar arguments as in
the proof of Theorem 6.41, we derive
#{ŒΩ ‚ààÀÜœÉ | a < ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | a < ŒΩ ‚â§b}
= Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		b
a
+Œº
 ÀÜVN+1Y [L]
N+1(Œª), ÀÜVN+1V ‚àí1
N+1(0 I)T 		b
a.
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(6.189)

6.2
Inequalities for Finite Eigenvalues
451
Note that the rank of the Wronskian for the Ô¨Årst addend is
rank w( ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T )
= rankw((0 I)T , [ ÀÜZ[R]
0 (Œª)]‚àí1V‚àí1(0 I)T )
= rankw((0 I)T , ÀÜVN+1Z[L]
N+1(Œª)(0 I)T ) = rank Àú(Œª) = Àúr(Œª).
Then we estimate
				Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		b
a
				
‚â§max{min{rL, Àúr(a)}, min{rL, Àúr(b)}} = min{rL, Àúra,b},
and using the relation
Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		b
a = Œº‚àó
V ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), V ‚àí1
‚àí1 ÀÜV‚àí1(0 I)T 		a
b,
(6.190)
where we apply Theorem 3.5(ix), we derive a similar estimate
				Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		b
a
				 =
				Œº‚àó
V ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), V ‚àí1
‚àí1 ÀÜV‚àí1(0 I)T 		a
b
				
‚â§max{min{rL, ÀÜr(a)}, min{rL, ÀÜr(b)}} = min{rL, ÀÜra,b}.
Combining the estimates derived above, we obtain the estimate for the Ô¨Årst addend
in (6.189) in the form
				Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		b
a
				 ‚â§min{Àúra,b, ÀÜra,b, rL}.
(6.191)
In a similar way, we derive the estimate for the second addend in (6.189), so that
Ô¨Ånally we prove (6.188).
‚äì‚äî
By analogy with the consideration for the case of the joint endpoints, we recall
that (5.333) guaranties that the spectra of (6.181) and (6.182) are bounded from
below (see Corollary 5.118). Then one can formulate the following corollary to
Theorem 6.47.
Corollary 6.48 Under the assumptions of Theorem 6.47, we have for any b ‚ààR
		#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
		 ‚â§ÀúK,
ÀúK := min{ÀÜr, Àúr, rL} + min{r, Àúr, rR} ‚â§2n,

(6.192)

452
6
Miscellaneous Topics on Symplectic Systems
with the constants r, ÀÜr, Àúr, rL, rR given by (6.186) and (6.183). In particular,
inequalities (6.132) hold with K = ÀÜK := ÀúK, where ÀúK is deÔ¨Åned by (6.192).
Now we specify the results of Corollary 6.48 by imposing more restrictions on
the behavior of (Œª), ÀÜ(Œª), Àú(Œª) with respect to Œª. For example, the restrictions
below hold for problems (6.181) with the matrix Sk(Œª) being a polynomial in Œª, in
particular, for problems with the special linear dependence in Œª (see Sect. 5.3).
Theorem 6.49 Under the assumptions of Theorem 6.47, suppose additionally that
for r, ÀÜr, Àúr given by (6.186) we have
r := sup
Œª‚ààR
rank(Œª) = rank (Œª),
ÀÜr := sup
Œª‚ààR
rank ÀÜ(Œª) = rank ÀÜ(Œª),
Àúr := sup
Œª‚ààR
rank Àú(Œª) = rank Àú(Œª),
Œª < Œª0 = min{Œª1, ÀÜŒª1, ÀúŒª1}.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.193)
Then
ÀÜK ‚â§#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚â§K,
K = K1 + K2 := min{P1, ÀÜr ‚àírL + P1} + min{P2, Àúr ‚àírR + P2} ‚â•0,
ÀÜK = ÀÜK1 + ÀÜK2 := min{rL ‚àíP1, Àúr ‚àíP1} + min{rR ‚àíP2, r ‚àíP2} ‚â•0,
ÀÜK + K ‚â§min{rL, ÀÜr, Àúr} + min{rR, r, Àúr} ‚â§2n,
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.194)
where the constants P1 and P2 are given by (6.113). In particular, inequali-
ties (6.132) for the Ô¨Ånite eigenvalues of (6.181) hold with K and ÀÜK given by (6.194).
Proof In the proof we follow the approach developed in the proof of Theorem 6.43.
Under assumptions (6.193) we have for b ‚ààR
rank(œÑ)
		b
Œª ‚â§0,
rank ÀÜ(œÑ)
		b
Œª ‚â§0,
rank Àú(œÑ)
		b
Œª ‚â§0,
Œª < Œª0.
(6.195)
Next we rewrite (6.112) and (6.113) in the form
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b}
= Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		Œª
b
+Œº
 ÀÜVN+1Y [L]
N+1(œÑ), ÀÜVN+1V ‚àí1
N+1(0 I)T 		Œª
b,
Œª < Œª0.
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(6.196)
Then we have for the addends in (6.196) (compare with (6.160))
Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		Œª
b ‚â§P1,
Œº
 ÀÜVN+1Y [L]
N+1(œÑ), ÀÜVN+1V ‚àí1
N+1(0 I)T 		Œª
b ‚â§P2.

(6.197)

6.2
Inequalities for Finite Eigenvalues
453
On the other hand, the comparative indices above can be rewritten in the form
(compare with (6.161))
Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 
= rL ‚àírank ÀÜ(Œª) + Œº
 ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T , ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª)

,
Œº
 ÀÜVN+1Y [L]
N+1(Œª), ÀÜVN+1V ‚àí1
N+1(0 I)T 
= rR ‚àírank Àú(Œª) + Œº‚àó ÀÜVN+1V ‚àí1
N+1(0 I)T , ÀÜVN+1Y [L]
N+1(Œª),
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.198)
where we apply Theorem 3.5(vi). Using (6.198) and (6.195), we have for the
addends in (6.196) for Œª < Œª0 that
Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		Œª
b
= rank ÀÜ(œÑ)
		b
Œª + Œº ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T , ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ)		Œª
b
‚â§Œº ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T , ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(Œª) = ÀÜr ‚àírL + P1.
So we have proved
Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		Œª
b ‚â§ÀÜr ‚àírL + P1,
Œª < Œª0.
(6.199)
In a similar way we prove the estimate for the second addend in (6.196)
Œº
 ÀÜVN+1Y [L]
N+1(œÑ), ÀÜVN+1V ‚àí1
N+1(0 I)T 		Œª
b ‚â§Àúr ‚àírR + P2,
Œª < Œª0.
(6.200)
Combining (6.197), (6.199), and (6.200), we derive the upper estimate in (6.194)
with the constant K. To prove the lower estimate, we rewrite (6.112) in the
equivalent form
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
= Œº‚àóV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ), V ‚àí1
‚àí1 ÀÜV‚àí1(0 I)T 		Œª
b
+Œº

VN+1Y [L]
N+1(œÑ), VN+1 ÀÜV ‚àí1
N+1(0 I)T 		Œª
b,
Œª < Œª0,
‚é´
‚é™‚é™‚é¨
‚é™‚é™‚é≠
(6.201)
which is derived using (6.190) for the Ô¨Årst addend in (6.112) and a similar relation
Œº  ÀÜVN+1Y [L]
N+1(œÑ), ÀÜVN+1V ‚àí1
N+1(0 I)T 		b
a
= Œº

VN+1Y [L]
N+1(œÑ), VN+1 ÀÜV ‚àí1
N+1(0 I)T 		a
b

(6.202)
for the second one (recall that we apply Theorem 3.5(ix)). Repeating the same
arguments as in the proof of the upper estimate and using formula (6.201) instead

454
6
Miscellaneous Topics on Symplectic Systems
of (6.196), we derive (compare with (6.164))
# {ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b}
‚â§ÀÜK = min{ ÀÜP1, Àúr ‚àírL + ÀÜP1} + min{ ÀÜP2, r ‚àírR + ÀÜP2},
Œª < Œª0,

(6.203)
where ÀÜP1 = rL ‚àíP1 and ÀÜP2 = rR ‚àíP2 by Theorem 3.5(ix). Substituting the last
representations into (6.203), we see that the constant ÀÜK in (6.203) is the same as
in the lower estimate in (6.194). The upper bound of the sum K + ÀÜK is derived by
analogy with the proof of the similar estimate in Theorem 6.43 (see (6.157)). By
Proposition 6.33 we have that (6.132) hold with K and ÀÜK given by (6.194). The
proof is completed.
‚äì‚äî
It follows from Theorem 6.49 that the Ô¨Ånite eigenvalues of the intermediate
problem in (6.182) with the spectrum ÀúœÉ separates the Ô¨Ånite eigenvalues of (6.181).
So we have the following corollary.
Corollary 6.50 Under the assumptions of Theorem 6.49, suppose that there exists
the Ô¨Ånite eigenvalue Œªj+K ‚ààœÉ (j ‚â•1), where K ‚â•0 is deÔ¨Åned in (6.194). Then
there exist the Ô¨Ånite eigenvalues ÀúŒªj+K1 ‚ààÀúœÉ and ÀÜŒªj ‚ààÀÜœÉ and the inequality
ÀÜŒªj ‚â§ÀúŒªj+K1 ‚â§Œªj+K,
(6.204)
holds with K1 = min{P1, ÀÜr ‚àírL + P1}, where K1 is the Ô¨Årst addend in the sum
K = K1 + K2 given by (6.194). Similarly, if ÀÜŒªp+ ÀÜK (p ‚â•1) exists, then there exist
ÀúŒªp+ ÀÜK2 ‚ààÀúœÉ and Œªp ‚ààœÉ, and we have the inequality
Œªp ‚â§ÀúŒªp+ ÀÜK2 ‚â§ÀÜŒªp+ ÀÜK,
(6.205)
where ÀÜK2 is the second addend in the sum ÀÜK = ÀÜK1 + ÀÜK2 given by (6.194).
Proof Replacing œÉ by ÀúœÉ in (6.196), we get
#{ŒΩ ‚ààÀúœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b}
= Œº‚àó ÀÜV ‚àí1
‚àí1 ÀÜY [R]
0
(œÑ), ÀÜV ‚àí1
‚àí1 V‚àí1(0 I)T 		Œª
b,
Œª ‚â§Œª0.

(6.206)
i.e., we cancel the second addend in (6.196). For the Ô¨Årst addend in (6.196), we have
derived the estimates (6.197) and (6.199). That is, we have the inequality
#{ŒΩ ‚ààÀúœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚â§K1,
or equivalently the inequality
#{ŒΩ ‚ààÀÜœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀúœÉ | ŒΩ ‚â§b} ‚â•‚àíK1 ‚â•0.

6.2
Inequalities for Finite Eigenvalues
455
Then, by Proposition 6.33 we have ÀÜŒªj ‚â§ÀúŒªj+K1 provided ÀúŒªj+K1 ‚ààÀúœÉ exists. Next
we replace ÀÜœÉ by ÀúœÉ in (6.196) to get
#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀúœÉ | ŒΩ ‚â§b}
= Œº ÀÜVN+1Y [L]
N+1(œÑ), ÀÜVN+1V ‚àí1
N+1(0 I)T 		Œª
b,
Œª ‚â§Œª0.

(6.207)
i.e., we cancel the Ô¨Årst addend in (6.196). Then, arguing as above we derive the
inequality ÀúŒªp ‚â§Œªp+K2, where K2 is the second addend in the sum for K = K1+K2
(see (6.194)). Applying the last inequality to the index p := j + K1, we derive
ÀÜŒªj ‚â§ÀúŒªj+K1 ‚â§Œªj+K or (6.204). For the proof of (6.205), we use (6.201). For the
Ô¨Årst step, we replace œÉ by ÀúœÉ deriving ÀúŒªj ‚â§ÀÜŒªj+ ÀÜK1. For the second step, we replace
ÀÜœÉ by ÀúœÉ and derive Œªp ‚â§ÀúŒªp+ ÀÜK2. By putting j := p + ÀÜK2 we derive (6.205). The
proof is completed.
‚äì‚äî
Next we formulate sufÔ¨Åcient conditions for the strict inequalities in (6.132).
Theorem 6.51 Under the assumptions of Theorem 6.49, suppose that one of the
conditions
ÀÜr ‚â§rL
or
Àúr ‚â§rR
(6.208)
holds. Then we have instead of (6.204) the inequalities
ÀÜŒªj < ÀúŒªj+K1 ‚â§Œªj+K
or
ÀÜŒªj ‚â§ÀúŒªj+K1 < Œªj+K,
(6.209)
and hence the strict inequality ÀÜŒªj < Œªj+K in (6.132) holds. Similarly, if one of the
conditions
Àúr ‚â§rL
or
r ‚â§rR
(6.210)
holds, then
Œªp ‚â§ÀúŒªp+ ÀÜK2 < ÀÜŒªp+ ÀÜK
or
Œªp < ÀúŒªp+ ÀÜK2 ‚â§ÀÜŒªp+ ÀÜK,
(6.211)
and we have the strict inequality Œªp < ÀÜŒªp+ ÀÜK in (6.132).
Proof If ÀÜr ‚â§rL holds, then using (6.206) and the same arguments as in case
of general boundary conditions (see the proof of Theorem 6.44), we show that
ÀÜŒªj < ÀúŒªj+K1. Then by combining this estimate with (6.204), we prove the Ô¨Årst
inequality in (6.209). Similarly, using Àúr ‚â§rR and (6.207), by analogy with the
proof of Theorem 6.44, we derive ÀúŒªp < Œªp+K2. Then, by putting p := j + K1 and
combining this inequality with (6.204), we derive the second inequality in (6.209).
Inequalities (6.211) and Œªp < ÀÜŒªp+ ÀÜK, which are connected to at least one of the
conditions in (6.210), can be proved analogously by using (6.201).
‚äì‚äî

456
6
Miscellaneous Topics on Symplectic Systems
Remark 6.52
(i) Observe that the inequalities of Theorem 6.43 for the joint endpoints are
improved by formulas of Theorem 6.49 for the separated boundary conditions.
Indeed, we have the estimate
min{P1, ÀÜr ‚àírL + P1} + min{P2, Àúr ‚àírR + P2}
‚â§min{P1 + P2, ÀÜr + n ‚àí(rL + rR) + P1 + P2}
= min{ ÀúP, ÀÜR ‚àíRw + ÀúP},
where the constants ÀúP, ÀÜR, Rw, determined by formulas (6.127), (6.152),
(6.149), are evaluated for the case, when the boundary conditions are separated.
For the proof we use Rw = rL + rR (see (5.154)) and
rank ÀÜL(Œª) = n + rank ÀÜ(Œª),
(6.212)
where ÀÜL(Œª) in (5.221) is computed for the case of the separated boundary
conditions and ÀÜ(Œª) is deÔ¨Åned by (5.205). Indeed, for this case we have
by (5.439) and (3.105)
ÀÜVN+1‚ü®Z[0]
N+1(Œª)‚ü©= ‚ü®ÀÜVN+1Z[0]
N+1(Œª) ÀÜV‚àí1‚ü©ÀÜV ‚àí1
‚àí1 ,
and then using the relation rank ÀÜL(Œª) = rank(I 0) ‚ü®ÀÜVN+1Z[0]
N+1(Œª) ÀÜV‚àí1‚ü©, we
derive (6.212). Moreover, by using Lemma 3.39 (see (3.115)), one can show
that the number ÀúP given by (6.127) for the case of the separated boundary
conditions takes the form ÀúP = P1 + P2 with the constants P1 and P2 given
by (6.113). Similarly,
min{rL ‚àíP1, Àúr ‚àíP1} + min{rR ‚àíP2, r ‚àíP2}
‚â§min{rL + rR ‚àíP1 ‚àíP2, n + r ‚àíP1 ‚àíP2}
= min{Rw ‚àíÀúP, R ‚àíÀúP}.
Consequently, inequalities of Theorem 6.43 are improved by formulas of
Theorem 6.49 for separated boundary conditions.
(ii) Observe that the consideration above was associated with the Ô¨Årst intermediate
eigenvalue problem in (6.182) with the spectrum ÀúœÉ. But for the case of ¬Ør < Àúr,
the estimates in Theorem 6.49 can be improved by using the second problem
in (6.182) with the spectrum ¬ØœÉ. For the derivation of the estimates associated
with this problem, it is sufÔ¨Åcient to replace the roles of problems in (6.181),
i.e., replace œÉ by ÀÜœÉ and vice versa.
(iii) As it was already used in the proof of Corollary 6.50, the results in Theo-
rems 6.47, 6.49, and 6.51 and in Corollaries 6.48 and 6.50 can be applied to

6.2
Inequalities for Finite Eigenvalues
457
the case when the problems in (6.181) differ in only one boundary condition.
For example, if we consider the Ô¨Årst problem in (6.181) with the spectrum œÉ
and the Ô¨Årst problem in (6.182) with the spectrum ÀúœÉ (instead of the second
problem in (6.181)), then in all estimates of Theorems 6.47, 6.49, and 6.51 and
Corollaries 6.48 and 6.50, we have rL = 0, P1 = 0, K1 = 0, and then the Ô¨Årst
addend is zero. A similar situation will arise if we consider the second problem
in (6.181) with the spectrum ÀÜœÉ and replace the Ô¨Årst problem with the spectrum
œÉ by the problem with the spectrum ÀúœÉ. In this case rR = 0, P2 = 0, K2 = 0,
and then in all estimates the second addend is zero.
For the sake of convenience (see also Remark 6.52(iii)), we reformulate Theo-
rems 6.49 and 6.51 for a pair of eigenvalue problems (6.181) with the same boundary
condition at k = 0 but different boundary conditions at k = N + 1, i.e.,
yk+1(Œª) = Sk(Œª) yk(Œª),
k ‚àà[0, N]Z,
R‚àó
0 x0(Œª) + R0 u0(Œª) = 0,
R‚àó
N+1 xN+1(Œª) + RN+1 uN+1(Œª) = 0,
Àúyk+1(Œª) = Sk(Œª) Àúyk(Œª),
k ‚àà[0, N]Z,
R‚àó
0 Àúx0(Œª) + R0 Àúu0(Œª) = 0,
ÀÜR‚àó
N+1 ÀúxN+1(Œª) + ÀÜRN+1 ÀúuN+1(Œª) = 0.
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.213)
Theorem 6.53 Let the parameters rR, r, Àúr for eigenvalue problems (6.213) are
determined by (6.183)‚Äì(6.186) and for Œª0 satisfying (6.187) (where we put ÀÜŒª1 = ÀúŒª1)
assumption (6.193) for r and Àúr holds. Then we have the estimates
ÀÜK2 ‚â§#{ŒΩ ‚ààœÉ | ŒΩ ‚â§b} ‚àí#{ŒΩ ‚ààÀúœÉ | ŒΩ ‚â§b} ‚â§K2,
K2 := min{P2, Àúr ‚àírR + P2},
ÀÜK2 := min{rR ‚àíP2, r ‚àíP2},
ÀÜK2 + K2 ‚â§min{rR, r, Àúr} ‚â§n,
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.214)
where P2 is determined by (6.113) for ÀÜœÉ := ÀúœÉ. In particular, if there exists the Ô¨Ånite
eigenvalue Œªj+K2 ‚ààœÉ (j ‚â•1) of the Ô¨Årst problem in (6.213), then there exists the
Ô¨Ånite eigenvalue ÀúŒªj ‚ààÀúœÉ of the second one with ÀúŒªj ‚â§Œªj+K2. If
Àúr ‚â§rR
(6.215)
holds, then we have the strict inequality ÀúŒªj < Œªj+K2. Similarly, the existence of
ÀúŒªp+ ÀÜK2 ‚ààÀúœÉ implies that of Œªp ‚ààœÉ with the inequality Œªp ‚â§ÀúŒªp+ ÀÜK2. Moreover, if
r ‚â§rR
(6.216)
holds, we have the strict inequality Œªp < ÀúŒªp+ ÀÜK2.

458
6
Miscellaneous Topics on Symplectic Systems
Remark 6.54 We note that Theorem 6.53 can be applied to derive the interlacing
properties of the Ô¨Ånite eigenvalues of problem (E) considered on the intervals
[0, N +1]Z and [0, N +2]Z. Since the theory developed in this subsection is devoted
to the case, when the matrices in the boundary conditions do not depend on Œª,
we impose the restriction (6.35) for the blocks Ak(Œª) and Bk(Œª) (see Sect. 6.1.3),
i.e., Ak(Œª) ‚â°Ak and Bk(Œª) ‚â°Bk. In this case problem (E) considered on the
subsequent intervals [0, N + 1]Z and [0, N + 2]Z is equivalent to the special case
of (6.213) on the interval [0, N + 1]Z with the matrices
R0 = RN+1 = 0,
R‚àó
0 = R‚àó
N+1 = I,
ÀÜR‚àó
N+1 := AN+1,
ÀÜRN+1 := BN+1.
For this case we have rR = rank BN+1 and VN+1 = I. By (6.113) the constant
P2 in Theorem 6.53 takes the form P2 = mN+1(Œª) for Œª < Œª0, where mN+1(Œª)
is the multiplicity of a forward focal point of the principal solution Y [0](Œª) of the
symplectic system in (6.213). In particular, for the nonsingular block BN+1, inequal-
ities (6.215) and (6.216) are necessary satisÔ¨Åed, and then, by Theorem 6.53, we have
strict interlacing properties for the Ô¨Ånite eigenvalues of problem (E) considered on
the subsequent intervals [0, N + 1]Z and [0, N + 2]Z (see Example 6.55).
Example 6.55 Consider the Sturm-Liouville problem (6.9) on [0, N + 1]Z and the
same problem on [0, N + 2]Z, i.e., with the Dirichlet boundary conditions x0 = 0 =
xN+2. Then, according to Remark 6.54, we have rR = rank BN+1 = 1, P2 = 0,
Àúr = r = 1, and K2 = 0, ÀÜK2 = 1. Conditions (6.215) and (6.216) are satisÔ¨Åed and
imply the strict inequalities
ŒªN+2
j
< ŒªN+1
j
< ŒªN+2
j+1 .
These inequalities are in full agreement with the classical results (see, e.g., [28,
Chapter 4]) concerning the separation of roots of the polynomials det X[0]
N+1(Œª)
and det X[0]
N+2(Œª). In a similar way, consider the Dirichlet eigenvalue problems on
[0, N + 1]Z and [0, N + 2]Z for the matrix Sturm-Liouville equation
‚àí(Rkxk) + Pkxk+1 = ŒªWkxk+1,
x0 = 0 = xN+1,
(6.217)
with det Rk Ã∏= 0 and Wk > 0. Then, by Remark 6.54 and Corollary 5.69, we have
P2 = 0, rR = rank BN+1 = n, and Àúr = r = n. Conditions (6.215) and (6.216)
(sufÔ¨Åcient for the strict inequalities) are then satisÔ¨Åed, K2 = 0, ÀÜK2 = n, and
ŒªN+2
j
< ŒªN+1
j
< ŒªN+2
j+n .
Next we show an example of spectra of two eigenvalue problems with separated
boundary conditions, for which estimates (6.194) are exact.

6.2
Inequalities for Finite Eigenvalues
459
Example 6.56 Consider the two problems with the matrix Sk(Œª) deÔ¨Åned in (6.169)
and with the separated boundary conditions on [0, N + 1]Z in the form
u0 = 0 = xN+1,
(6.218)
x0 = 0 = uN+1.
(6.219)
Then for problem (6.169), (6.218) with the spectrum œÉ, we have V‚àí1 = J and
VN+1 = I and (Œª) = (I 0) Z5(Œª) (I 0)T . According to Example 6.46 with N = 4
(see the formula for the fundamental matrix Z5(Œª)), we have
rank(Œª) = 1 + rank(‚àí2Œª + Œª3),
and then
œÉ =
!
Œª1 = ‚àí
‚àö
2, Œª2 = 0, Œª3 =
‚àö
2
"
.
Similarly, for problem (6.169), (6.219) with the spectrum ÀÜœÉ, we have ÀÜV‚àí1 = I
and ÀÜVN+1 = J and ÀÜ(Œª) = (0 I) Z5(Œª) (0 I)T . According to Example 6.46 with
N = 4,
rank ÀÜ(Œª) = 1 + rank (‚àí3Œª + 4Œª3 ‚àíŒª5),
and then
ÀÜœÉ = !ÀÜŒª1 = ‚àí
‚àö
3, ÀÜŒª2 = ‚àí1, ÀÜŒª3 = 0, ÀÜŒª4 = 1, ÀÜŒª5 =
‚àö
3".
Let us compare the spectra œÉ and ÀÜœÉ. It is easy to see that
Œªj‚àí2 < ÀÜŒªj (j ‚àà{3, 4, 5}),
ÀÜŒªp < Œªp (p ‚àà{1, 2, 3}).
(6.220)
Now we apply the general theory developed for separated boundary conditions. For
the intermediate eigenvalue problems deÔ¨Åned by (6.182), we have the boundary
conditions
u0 = 0 = uN+1,
(6.221)
x0 = 0 = xN+1.
(6.222)
According to formula for Z5(Œª) in Example 6.46, the spectra of the intermediate
problems (6.169), (6.221) (with the spectrum ÀúœÉ) and (6.169), (6.222) (with the
spectrum ¬ØœÉ) can be found by using the functions Àú(Œª) = (0 I) Z5(Œª) (I 0)T
and Àú(Œª) = (I 0) Z5(Œª) (0 I), respectively, which have the same maximal ranks
Àúr = ¬Ør = 1 (and the same spectra ÀúœÉ = ¬ØœÉ). Finally, we have rL = rR = 2, r = ÀÜr = 2,
Àúr = 1, and by Theorem 6.49 then K = P1 + Àúr ‚àírR + P2 = P1 + P2 ‚àí1, where the

460
6
Miscellaneous Topics on Symplectic Systems
constants P1 and P2 can be computed by using (6.113). Namely, we have
P1 = Œº‚àó
Z‚àí1
5 (Œª) (I 0)T , (I 0)T 
= ind [(1 ‚àí3Œª + Œª4) (‚àí3Œª + 4Œª3 ‚àíŒª5)]
= 0
for Œª ‚Üí‚àí‚àû,
and
P2 = Œº

J Z5(Œª) (I 0)T , (I 0)T 
= 1 + ind [(‚àí1 + 3Œª2 ‚àíŒª4) (‚àí2Œª + Œª3)]
= 1
for
Œª ‚Üí‚àí‚àû.
Then K = 0, and hence, by Theorem 6.51, the inequality ÀÜŒªp < Œªp (p ‚àà{1, 2, 3})
holds. Next, by (6.194) we have ÀÜK = 2, and then Œªj‚àí2 < ÀÜŒªj (j ‚àà{3, 4, 5}). Thus,
we have proved that (6.220) holds by Theorems 6.49 and 6.51. Observe also that the
sum of the comparative indices in (6.113) is
Œº
 ÀÜV‚àí1(0 I)T, V‚àí1(0 I)T 
+ Œº‚àó ÀÜV ‚àí1
N+1(0 I)T, V ‚àí1
N+1(0 I)T 
= 2,
so that the majorant condition (6.137) used in Sect. 6.2.1 is not satisÔ¨Åed.
6.3
Symplectic Systems Without Controllability
In this section we will consider symplectic difference system (SDS) on a discrete
interval of the form [0, ‚àû)Z, which is bounded from below and unbounded from
above and for which we do not impose any controllability assumption. This assump-
tion was used in Sect. 2.5.1 in order to guarantee the existence of the recessive
solution of (SDS) at inÔ¨Ånity. We will see in this section that it is possible to develop
the theory of recessive and dominant solutions at inÔ¨Ånity without the controllability
assumption. The organization of this section is the following. In Sect. 6.3.1 we
discuss the order of abnormality of system (SDS). In Sect. 6.3.2 we introduce
basic notation and derive main properties of conjoined bases of nonoscillatory
system (SDS) at ‚àû. The content of Sects. 6.3.3‚Äì6.3.5 can be considered as technical
results, which are needed for the construction and classiÔ¨Åcation of recessive and
dominant solutions of (SDS) at ‚àû. These three subsections can be skipped for
the Ô¨Årst reading when one aims to see the main results Ô¨Årst. The two central
objects of this section, i.e., the recessive and dominant solutions of (SDS) at ‚àû,
are introduced in Sects. 6.3.6 and 6.3.7, respectively. In Sect. 6.3.8 we introduce the
notion of a genus of conjoined bases of (SDS) and study the existence of recessive
and dominant solutions of (SDS) at ‚àûin different genera of conjoined bases.
This provides a basis for the investigation of limit properties of the recessive and
dominant solutions of (SDS) at ‚àûin Sect. 6.3.9. In Sect. 6.3.10 we present a special

6.3
Symplectic Systems Without Controllability
461
construction of the (unique) minimal recessive solution of (SDS) at ‚àû, which can
be potentially useful for applications in the oscillation and spectral theory of (SDS).
6.3.1
Order of Abnormality
For N ‚àà[0, ‚àû)Z we denote by [N, ‚àû)Z the linear space of n-vector sequences
u = {uk}‚àû
k=N such that uk+1 = Dkuk and Bkuk = 0 on [N, ‚àû)Z. This means
that u ‚àà[N, ‚àû)Z if and only if the pair (x ‚â°0, u) solves (SDS) on [N, ‚àû)Z.
Moreover, we denote by 0[N, ‚àû)Z the subspace of Rn consisting of the initial
values uN of the elements u ‚àà[N, ‚àû)Z. Then the number
d[N, ‚àû)Z := dim [N, ‚àû)Z = dim 0[N, ‚àû)Z,
0 ‚â§d[N, ‚àû)Z ‚â§n,
(6.223)
is called the order of abnormality of (SDS) on the interval [N, ‚àû)Z. It is obvious that
if (x ‚â°0, u) solves (SDS) on [N1, ‚àû)Z, then it solves (SDS) also on [N2, ‚àû)Z for
every N2 ‚àà[N1, ‚àû)Z. This shows that [N1, ‚àû)Z ‚äÜ[N2, ‚àû)Z for all N1 ‚â§N2,
i.e., the function d[k, ‚àû)Z is nondecreasing in k on [0, ‚àû)Z. Hence, the limit
d‚àû:= lim
k‚Üí‚àûd[k, ‚àû)Z = max
!
d[k, ‚àû)Z, k ‚àà[0, ‚àû)Z
"
,
0 ‚â§d‚àû‚â§n,
(6.224)
exists and is called the maximal order of abnormality of (SDS). In particular, the
subspace [N, ‚àû)Z with d[N, ‚àû)Z = d‚àûsatisÔ¨Åes
[N, ‚àû)Z = [K, ‚àû)Z
for every K ‚àà[N, ‚àû)Z.
(6.225)
Note that for an eventually controllable system (SDS), we have d‚àû= 0. The
number d‚àûis one of the important parameters of system (SDS). In a similar
way to (6.223), we deÔ¨Åne the number d[N, L]Z as the order of abnormality of
system (SDS) on the interval [N, L]Z with the associated subspaces [N, L]Z and
0[N, L]Z. Also, for convenience we set [N, N]Z = Rn = 0[N, N]Z for the
case of L = N.
The following result provides a basic connection between the subspaces
0[N, k] for k ‚àà[N, ‚àû)Z and the principal solution Y [N] of (SDS). We recall
that the solution Y [N] is deÔ¨Åned by the initial conditions Y [N]
N
=
 0
I

.
Theorem 6.57 For any N ‚àà[0, ‚àû)Z, we have
0[N, k]Z =
6
j‚àà[N,k]
Ker X[N]
j
for every k ‚àà[N, ‚àû)Z,
(6.226)
d[N, ‚àû)Z = dim
6
k‚àà[N,‚àû)Z
Ker X[N]
k
.
(6.227)

462
6
Miscellaneous Topics on Symplectic Systems
Proof For k = N the equality in (6.226) holds trivially. Let k ‚â•N + 1. If c ‚àà
0[N, k], then y = (x ‚â°0, u) is a solution of (SDS) on [N, k ‚àí1]Z for some
u ‚àà[N, k] with uN = c. By the uniqueness of solutions of system (SDS), it
follows that y = Y [N]c on [N, k]. Hence, X[N]
j
c = 0 for all j ‚àà[N, k]. The
opposite direction is trivial. Equality (6.227) then follows from (6.226) and (6.223).
‚äì‚äî
Remark 6.58 We note that when system (SDS) is eventually controllable (in the
sense of Sect. 2.5.1) and nonoscillatory at ‚àû, then for every N
‚àà[0, ‚àû)Z
the principal solution Y [N] has the matrix X[N]
k
invertible for large k. Therefore,
Theorem 6.57 implies that 0[N, k]Z = {0} for large k and consequently d‚àû= 0.
6.3.2
Nonoscillatory Symplectic System
In this section we will use special symplectic fundamental matrices corresponding,
for a given index j ‚àà[0, ‚àû)Z, to the principal solution Y [j] of (SDS). More
precisely, we denote
[j]
k
=

Y [j]
k
¬ØY [j]
k

,
k ‚àà[0, ‚àû)Z,
w(Y [j], ¬ØY [j]) = I,
(6.228)
where ¬ØY [j] is the conjoined basis of (SDS) such that w(Y [j], ¬ØY [j]) = I, that is,
¬ØY [j]
j
= ‚àíJ (0 I)T = (‚àíI 0)T . This means that the fundamental matrix in (6.228)
satisÔ¨Åes the normalization condition [j]
j
= ‚àíJ . Note that the fundamental matrix
[j]
k
corresponds to the symplectic matrix ÀúZ in Lemma 1.58(vi). We shall represent
conjoined bases of (SDS) in terms of the matrix [j]
k .
Lemma 6.59 Let j ‚àà[0, ‚àû)Z be Ô¨Åxed, and let the symplectic fundamental matrix
[j]
k
of (SDS) be deÔ¨Åned by (6.228). Then for every conjoined basis Y of (SDS),
there exists a unique constant 2n √ó n matrix Dj such that
Yk = [j]
k Dj,
k ‚àà[0, ‚àû)Z,
JDj =
w(Y [j], Y)
w( ¬ØY [j], Y)

.
(6.229)
Proof The form of the matrix Dj in (6.229) follows directly from the expression
Dj
= ‚àíJ ([j]
k )TJ Yk by using the inversion formula S‚àí1 = ‚àíJ STJ for
a symplectic matrix (see Lemma 1.58(ii)) and from the constancy of the Wronskian
of two solutions of (SDS).
‚äì‚äî
Later in Sects. 6.3.11, 6.4.2, and 6.4.3, we will extend these considerations
to symplectic fundamental matrices of (SDS) involving the (minimal) recessive
solutions of (SDS) at ¬±‚àû, i.e., we will use the notation in (6.228) and the result
of Lemma 6.59 with j = ¬±‚àû.

6.3
Symplectic Systems Without Controllability
463
By using Lemma 6.59 and the comparative index, we can derive the following
additional formulas for the multiplicities of focal points.
Remark 6.60 Let Y be a conjoined basis of (SDS), and let Y [j] and Y [j+1] be the
principal solutions of (SDS) at j and j + 1. Then we have
m(j) = Œº

JDj+1, JD[j]
j+1

,
m‚àó(j) = Œº‚àó
JDj , JD[j+1]
j

,
(6.230)
where Dj+1 and D[j]
j+1 are the representation matrices in (6.229) of Y and Y [j] in
terms of the symplectic fundamental matrix [j+1] of (SDS), while Dj and D[j+1]
j
are the representation matrices in (6.229) of Y and Y [j+1] in terms of the symplectic
fundamental matrix [j]. Indeed, since [j+1]
j+1
= ‚àíJ = [j]
j , we have
JDj+1 = ([j+1]
k
)TJ Yk = ‚àíYj+1,
JD[j]
j+1 = ([j+1]
k
)TJ Y [j]
k
= ‚àíY [j]
j+1
(6.231)
(when evaluated at k = j + 1), and similarly
JDj = ([j]
k )TJ Yk = ‚àíYj,
JD[j+1]
j
= ([j]
k )TJ Y [j+1]
k
= ‚àíY [j+1]
j
(6.232)
(when evaluated at k = j). Therefore,
Œº

JDj+1, JD[j]
j+1
 (6.231)
=
Œº(‚àíYj+1, ‚àíY [j]
j+1) = Œº(Yj+1, Y [j]
j+1)
(4.14)
=
m(j),
Œº‚àó
JDj, JD[j+1]
j
 (6.232)
=
Œº‚àó(‚àíYj, ‚àíY [j+1]
j
) = Œº‚àó(Yj, Y [j+1]
j
)
(4.16)
=
m‚àó(j).
In Sect. 6.4.1 we will derive analogs of (6.230) for unbounded intervals.
Fundamental results from the Sturmian theory of discrete symplectic sys-
tems (SDS) are established in Chap. 4. In particular, Theorem 4.24 and its
Corollaries 4.25 and 4.26 state that for a given index N ‚àà[0, ‚àû)Z the numbers of
forward (or left) focal points in the interval (0, N + 1] of any two conjoined bases
of (SDS) differ by at most n. Therefore, based on Corollary 4.25, we formulate the
following result, which will be useful for our future reference.
Proposition 6.61 The following statements are equivalent.
(i) System (SDS) is (non)oscillatory at ‚àû(resp., at ‚àí‚àû).
(ii) Every conjoined basis of (SDS) is (non)oscillatory at ‚àû(resp., at ‚àí‚àû).
(iii) There exists a conjoined basis of (SDS), which is (non)oscillatory at ‚àû(resp.,
at ‚àí‚àû).
Therefore, equivalently to DeÔ¨Ånition 4.37, we say that system (SDS) is nonoscil-
latory at ‚àû(resp., at ‚àí‚àû) if every conjoined basis of (SDS) has Ô¨Ånitely many

464
6
Miscellaneous Topics on Symplectic Systems
forward focal points in (0, ‚àû) (resp., Ô¨Ånitely many backward focal points in
(‚àí‚àû, 0)). In the opposite case, we say that system (SDS) is oscillatory at ‚àû(resp.,
at ‚àí‚àû). We note that by formula (4.13) in Corollary 4.6, it is equivalent to use the
forward or the backward focal points to deÔ¨Åne the (non)oscillation of system (SDS)
at ‚àû(resp., at ‚àí‚àû).
In Example 4.73 we showed that the symplectic system corresponding to the
Fibonacci difference equation xk+2 = xk+1 + xk for k ‚àà[0, ‚àû)Z is oscillatory at
‚àû. Also, the symplectic systems in Examples 4.74 and 4.75 are nonoscillatory at
‚àû.
Example 6.62 Consider system (SDS) with Sk ‚â°J on [0, ‚àû)Z. Then d[0, ‚àû)Z =
d‚àû= 0 and all solutions of (SDS) are periodic with period four. Consider the
conjoined basis Y = {Yk}‚àû
k=0 with Y2j = (0, (‚àí1)jI)T and Y2j+1 = ((‚àí1)jI, 0)T
for j ‚àà[0, ‚àû)Z. Then for each k ‚àà[0, ‚àû)Z either Xk = 0 or Xk+1 = 0. Then for
every N ‚àà[0, ‚àû)Z, the kernel of Xk is not constant on [N, ‚àû)Z, and Y has inÔ¨Ånitely
many focal points in (N, ‚àû). These focal points of multiplicity n arise from the Ô¨Årst
term in (4.3) by violating the kernel condition in (2.37). The focal points are located
in the intervals (k, k + 1] = (2j, 2j + 1] (more precisely, at k + 1 = 2j + 1) for
every j ‚àà[0, ‚àû)Z in the terminology of Sect. 4.1.1. Thus, this system (SDS) is
oscillatory at ‚àû.
Example 6.63 Consider system (SDS) with Sk ‚â°I2n on [0, ‚àû)Z. Then we have
d[0, ‚àû)Z = d‚àû= n, and all solutions of (SDS) are constant on [0, ‚àû)Z. Therefore,
this system is nonoscillatory at ‚àû.
Further examples will be discussed in Sects. 6.3.6 and 6.3.7 in the relation with
the recessive and dominant solutions of (SDS) at ‚àû.
Remark 6.64 If V is a linear subspace in Rn, then we denote by PV the correspond-
ing n √ó n orthogonal projector onto V . It follows that the matrix PV is symmetric,
idempotent, and nonnegative deÔ¨Ånite.
Given a conjoined basis Y of (SDS), we denote by Pk the orthogonal projector
onto Im XT
k and by Rk the orthogonal projector onto Im Xk. That is, according to
Remarks 6.64 and 1.62, we have
Pk := PIm XT
k = X‚Ä†
kXk,
Rk := PIm Xk = XkX‚Ä†
k.
(6.233)
Note that rank Pk = rank XT
k = rankXk = rankRk. When Ker Xk = Ker Xk+1,
i.e., when Im XT
k = Im XT
k+1, we have Pk = Pk+1. Therefore, the projector
P := Pk
(6.234)
is constant on an interval [N, ‚àû)Z where Ker Xk is constant. For convenience but
with slight abuse in terminology, we say that Y has constant kernel on [N, ‚àû)Z
when the kernel of Xk is constant on this interval. Similarly, we say that Y has rank
r on [N, ‚àû)Z when the rank of Xk is equal to r on [N, ‚àû)Z.

6.3
Symplectic Systems Without Controllability
465
Next we derive important properties of conjoined bases of a nonoscillatory
system (SDS) at ‚àû, in particular of conjoined bases with constant kernel on a given
interval [N, ‚àû)Z and with no forward focal points in (N, ‚àû). The latter properties
are equivalent with the two conditions in (2.37), i.e., with
Ker Xk+1 = Ker Xk,
XkX‚Ä†
k+1Bk ‚â•0,
k ‚àà[N, ‚àû)Z.
(6.235)
Later in this section, we will provide a construction of such conjoined bases from
a given conjoined basis with the same properties via the relation ‚Äúbeing contained‚Äù
(see Sect. 6.3.3).
For every conjoined basis Y of (SDS), we deÔ¨Åne its corresponding S-matrix
Sk :=
k‚àí1

j=N
X‚Ä†
j+1 Bj X‚Ä† T
j
.
(6.236)
We start with two monotonicity properties of the matrix Sk and the set Im Sk, which
leads to a deÔ¨Ånition of the T -matrix associated with Y.
Theorem 6.65 Assume that system (SDS) is nonoscillatory at ‚àû. Then for every
conjoined basis Y of (SDS), there exists N
‚àà[0, ‚àû)Z such that the matrix
X‚Ä†
k+1BkX‚Ä† T
k
is symmetric and nonnegative deÔ¨Ånite on [N, ‚àû)Z, the associated
matrix Sk in (6.236) is symmetric, nonnegative deÔ¨Ånite, and nondecreasing on
[N, ‚àû)Z with SN = 0. Moreover, the matrix S‚Ä†
k is eventually nonincreasing, the
limit
T := lim
k‚Üí‚àûS‚Ä†
k
(6.237)
exists, and the matrix T is symmetric and nonnegative deÔ¨Ånite.
Proof The result in Proposition 6.61 implies that for a conjoined basis Y of (SDS),
there exists N ‚àà[0, ‚àû)Z such that the kernel of Xk is constant on [N, ‚àû)Z and
XkX‚Ä†
k+1Bk is symmetric and nonnegative deÔ¨Ånite on [N, ‚àû)Z. This implies that the
matrix
X‚Ä†
k+1BkX‚Ä† T
k
= Pk+1X‚Ä†
k+1BkX‚Ä† T
k
= PkX‚Ä†
k+1BkX‚Ä† T
k
= X‚Ä†
kXkX‚Ä†
k+1BkX‚Ä† T
k
is symmetric and nonnegative deÔ¨Ånite on [N, ‚àû)Z as well. In turn, the matrix Sk
in (6.236) is symmetric, nonnegative deÔ¨Ånite, nondecreasing on [N, ‚àû)Z, and by
convention SN = 0. These properties imply that the matrix S‚Ä†
k is also symmetric
and nonnegative deÔ¨Ånite on [N, ‚àû)Z, and nonincreasing for large k. More precisely,
S‚Ä†
k is nonincreasing on intervals, where Sk has constant image, by Remark 1.60(vi).
Hence, the limit in (6.237) exists and the matrix T is symmetric and nonnegative
deÔ¨Ånite.
‚äì‚äî

466
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.66 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z, and let the matrices P, Rk, and Sk be deÔ¨Åned in (6.234), (6.233),
and (6.236). Then
(i) Im [Uk (I ‚àíP)] = Ker Rk, and hence RkUk = RkUkP, for all k ‚àà[N, ‚àû)Z,
(ii) Bk = Rk+1Bk and Bk = BkRk for all k ‚àà[N, ‚àû)Z,
(iii) PSk = Sk, i.e., Im Sk ‚äÜIm P, for all k ‚àà[N, ‚àû)Z.
If in addition Y has no forward focal points in (N, ‚àû), then
(iv) the set Im Sk is nondecreasing on [N, ‚àû)Z, hence it is eventually constant.
Proof (i) For a vector v ‚ààIm Uk(I ‚àíP), we have v = Uk(I ‚àíP) c for some
c ‚ààRn. This yields that Rkv = X‚Ä†T
k XT
k Uk(I ‚àíP) c = X‚Ä†T
k UT
k Xk(I ‚àíP) c = 0,
since Xk(I ‚àíP) = 0. Therefore, Im Uk(I ‚àíP) ‚äÜKer Rk holds, which yields
the inequality rank Uk(I ‚àíP) ‚â§def Rk. We will show the opposite inequality.
Choose w ‚ààKer Uk(I ‚àíP), i.e., Uk(I ‚àíP) w = 0. Since also Xk(I ‚àíP) w = 0
and rank(XT
k , UT
k ) = n hold, we have (I ‚àíP) w = 0, i.e., w ‚ààIm P. Thus,
Ker Uk(I ‚àíP) ‚äÜIm P and def Uk(I ‚àíP) ‚â§rankP. By using rank Rk = rankP,
we then obtain the needed estimate
def Rk = n ‚àírankRk = n ‚àírank P ‚â§n ‚àídef Uk(I ‚àíP) = rank Uk(I ‚àíP).
Consequently, def Rk = rankUk(I ‚àíP). But since we have already proved that
Im Uk(I ‚àíP) is a subspace of Ker Rk, the statement in part (i) follows. The Ô¨Årst
identity in part (ii) is a reformulation of the fact that Xk+1X‚Ä†
k+1Bk = Bk when
Ker Xk+1 = Ker Xk; see Lemma 2.15 in Sect. 2.2.1. For the second identity in
(ii), we note that Xk+1 = Xk+1Pk+1 = Xk+1Pk and that XkX‚Ä†
k+1Bk and Rk are
symmetric. Therefore, we have
BkRk = Rk+1BkRk = Xk+1PkX‚Ä†
k+1BkRk = Xk+1X‚Ä†
kBT
k X‚Ä†T
k+1XT
k Rk
= Xk+1X‚Ä†
kBT
k X‚Ä†T
k+1XT
k = Xk+1X‚Ä†
kXkX‚Ä†
k+1Bk = Xk+1PkX‚Ä†
k+1Bk
= Xk+1X‚Ä†
k+1Bk = Bk.
For part (iii) we use that the projector Pj is constant on [N, ‚àû)Z, so that we have
PSk =
k‚àí1

j=N
PPj+1X‚Ä†
j+1BjX‚Ä†T
j
=
k‚àí1

j=N
Pj+1X‚Ä†
j+1BjX‚Ä†T
j
= Sk
on [N, ‚àû)Z. This shows that Im Sk = Im PSk ‚äÜIm P on [N, ‚àû)Z. If in addition Y
has no forward focal points in (N, ‚àû), then XkX‚Ä†
k+1Bk ‚â•0 on [N, ‚àû)Z and so Sk is
nonnegative deÔ¨Ånite and nondecreasing on [N, ‚àû)Z; compare with Theorem 6.65.
And since Sk is symmetric, it follows that Im Sk is nondecreasing on [N, ‚àû)Z and
hence eventually constant.
‚äì‚äî

6.3
Symplectic Systems Without Controllability
467
Based on Theorem 6.66(iv), we deÔ¨Åne for a conjoined basis Y of (SDS) with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) the orthogonal
projectors
PSk := PIm Sk = S‚Ä†
kSk = SkS‚Ä†
k,
PS‚àû:= lim
k‚Üí‚àûPSk,
(6.238)
where PS‚àûis the constant projector onto the maximal set Im Sk according to
Theorem 6.66(iv). We then have the inclusions
Im Sk ‚äÜIm PS‚àû‚äÜIm P,
k ‚àà[N, ‚àû)Z,
Im T ‚äÜIm PS‚àû‚äÜIm P,
(6.239)
where we used that Im S‚Ä†
k = Im ST
k = Im Sk by Remark 1.60(i).
In the following result, we show a construction and properties of a special
conjoined basis ¬ØY of (SDS), which completes a given conjoined basis Y with
constant kernel on some interval [N, ‚àû)Z to a normalized pair (see Sect. 2.1.1).
This leads to a special symplectic fundamental matrix k = (Yk, ¬ØYk) of (SDS),
which will be utilized in further development of the theory.
Proposition 6.67 Let Y be a conjoined basis of (SDS) with constant kernel
on [N, ‚àû)Z
with the associated matrices P, Rk, Sk, and PSk
deÔ¨Åned
in (6.234), (6.233), (6.236), and (6.238). Then there exists a conjoined basis ¬ØY
of (SDS) such that
(i) w(Y, ¬ØY ) = I,
(ii) X‚Ä†
N ¬ØXN = 0.
Moreover, such a conjoined basis ¬ØY then satisÔ¨Åes
(iii) X‚Ä†
k ¬ØXkP = Sk for k ‚àà[N, ‚àû)Z,
(iv)
¬ØXkP = XkSk and
¬ØUkP = UkSk + X‚Ä†T
k
+ Uk(I ‚àíP) ¬ØXT
k X‚Ä†T
k
for every
k ‚àà[N, ‚àû)Z (in particular ¬ØXNP = 0), and the solution ¬ØYP of (SDS) is
uniquely determined by Y on [0, ‚àû)Z,
(v) the matrices ¬ØXk for k ‚àà[N, ‚àû)Z are uniquely determined by Y,
(vi) Ker ¬ØXk = Im (P ‚àíPSk) = Im P ‚à©Ker Sk for k ‚àà[N, ‚àû)Z,
(vii)
¬ØPk = I ‚àíP + PSk for k ‚àà[N, ‚àû)Z, where ¬ØPk := ¬ØX‚Ä†
k ¬ØXk,
(viii) S‚Ä†
k = ¬ØX‚Ä†
kXkPSk = ¬ØX‚Ä†
kXk ¬ØPk for k ‚àà[N, ‚àû)Z,
(ix) Im ¬ØXN = Im (I ‚àíRN) and Im ¬ØXT
N = Im (I ‚àíP),
(x) the matrix XN ‚àí¬ØXN is invertible with (XN ‚àí¬ØXN)‚àí1 = X‚Ä†
N ‚àí¬ØX‚Ä†
N,
(xi)
¬ØX‚Ä†
N = ‚àí(I ‚àíP) UT
N .
If in addition the conjoined basis Y has no forward focal points in (N, ‚àû), then
(xii) Xk ¬ØXT
k ‚â•0 for k ‚àà[N, ‚àû)Z.
Proof We will prove (i) and (ii). Let ÀúY be a conjoined basis of (SDS) such that
Y and ÀúY are normalized, i.e., w(Y, ÀúY ) = I (see Sect. 2.1.1). Then according to

468
6
Miscellaneous Topics on Symplectic Systems
Lemma 1.58 applied to the symplectic matrix S := k = (Yk, ¬ØYk), we have
Xk ÀúUT
k ‚àíÀúXkUT
k = I,
Xk ÀúXT
k and Uk ÀúUT
k symmetric,
k ‚àà[0, ‚àû)Z.
(6.240)
Since the projector P is constant on [N, ‚àû)Z, we deÔ¨Åne the constant matrix
D := X‚Ä†
N ÀúXN(P ‚àíI) ‚àíÀúXT
NX‚Ä†T
N .
Then D is symmetric, because X‚Ä†
N ÀúXNP = X‚Ä†
N ÀúXNXT
NX‚Ä†T
N is symmetric by (6.240).
Furthermore, PD = ‚àíX‚Ä†
N ÀúXN. DeÔ¨Åne the solution ¬ØY of (SDS) by ¬ØYk := ÀúYk + YkD
on [0, ‚àû)Z. Then ¬ØY is a conjoined basis of (SDS) satisfying w(Y, ¬ØY ) = I and
X‚Ä†
N ¬ØXN = X‚Ä†
N ÀúXN + PD = 0. This completes the proof of parts (i) and (ii). For part
(iii), let k ‚àà[N, ‚àû)Z be Ô¨Åxed. Then we have
(X‚Ä†
k ¬ØXkP) = X‚Ä†
k+1 ¬ØXk+1P ‚àíX‚Ä†
k ¬ØXkP
= X‚Ä†
k+1( ¬ØXk+1 ‚àíAk ¬ØXk) P + (X‚Ä†
k+1Ak ‚àíX‚Ä†
k) ¬ØXkP
= X‚Ä†
k+1Bk ¬ØUkX‚Ä†
kXk + X‚Ä†
k+1AkXk ¬ØXT
k X‚Ä†T
k
‚àíX‚Ä†
kXk ¬ØXT
k X‚Ä†T
k
= X‚Ä†
k+1Bk( ¬ØUkXT
k ‚àíUk ¬ØXT
k ) X‚Ä†T
k
+ (X‚Ä†
k+1Xk+1 ‚àíP) ¬ØXT
k X‚Ä†T
k
= X‚Ä†
k+1BkX‚Ä†T
k .
Since we already proved that X‚Ä†
N ¬ØXN = 0, we obtain by the summation of the
above equality from j = N to j = k ‚àí1 that X‚Ä†
k ¬ØXkP = Sk, as we claim in (iii).
The formulas for ¬ØXkP and ¬ØUkP on [N, ‚àû)Z in part (iv) follow from the above
construction of ¬ØY. Then for k = N we obtain ¬ØXNP = XNSN = 0, as SN = 0.
Moreover, in view of part (v) proven below, these formulas depend only on the
values of Yk on [N, ‚àû)Z, so that part (iv) is proven. Regarding part (v), we assume
that there exists another conjoined basis ¬Ø¬ØY of (SDS) satisfying (i)‚Äì(iii). Then by
[205, Corollary 3.3.9], there exists a symmetric matrix ¬ØD with ¬Ø¬ØYk = ¬ØYk + Yk ¬ØD
on [0, ‚àû)Z. From X‚Ä†
N ¬Ø¬ØXN = 0 = X‚Ä†
N ¬ØXN, we then obtain P ¬ØD = X‚Ä†
NXN ¬ØD =
X‚Ä†
N( ¬Ø¬ØXN ‚àí¬ØXN) = 0, so that Im ¬ØD ‚äÜKer P = Ker Xk on [N, ‚àû)Z. Therefore,
Xk ¬ØD = 0 and the equality ¬Ø¬ØXk = ¬ØXk on [N, ‚àû)Z follows. Therefore, part (v) holds.
For part (vi) we note that from the identity XT
k ¬ØUk ‚àíUT
k ¬ØXk = I on [N, ‚àû)Z (i.e.,
from w(Y, ¬ØY ) = I), it follows that Ker ¬ØXk ‚äÜIm XT
k = Im P for every k ‚àà[N, ‚àû)Z.
Moreover, by (iii) and (6.239), we get
Ker ¬ØXk ‚äÜIm P ‚à©Ker Sk = Im P ‚à©Ker PSk
(6.239)
=
Im (P ‚àíPSk),
k ‚àà[N, ‚àû)Z.
Conversely, Ô¨Åx an index k ‚àà[N, ‚àû)Z, and assume that v ‚ààIm (P ‚àíPSk) = Im P ‚à©
Ker Sk. The Ô¨Årst identity in (iv) then yields ¬ØXkv = ¬ØXkPv = XkSkv = 0, and hence

6.3
Symplectic Systems Without Controllability
469
v ‚ààKer ¬ØXk. Therefore, the opposite inclusion Im (P ‚àíPSk) ‚äÜKer ¬ØXk also holds,
showing part (vi). In addition, the latter result is equivalent with the fact that the
matrix I ‚àí(P ‚àíPSk) is the orthogonal projector onto the space (Ker ¬ØXk)‚ä•= Im ¬ØXT
k
for every k ‚àà[N, ‚àû)Z. More precisely, we have the formula
¬ØP = ¬ØX‚Ä†
k ¬ØXk = I ‚àíP + PSk,
k ‚àà[N, ‚àû)Z,
(6.241)
which proves part (vii). Next, upon combining the identities PSk = SkS‚Ä†
k and
XkSk = ¬ØXkP from (iv) and PSk P = PSk on [N, ‚àû)Z with (6.241), we obtain
¬ØX‚Ä†
k Xk PSk = ¬ØX‚Ä†
k Xk SkS‚Ä†
k
(iv)
= ¬ØX‚Ä†
k ¬ØXkPS‚Ä†
k
(6.241)
=
(I ‚àíP + PSk) PS‚Ä†
k
= PSk PS‚Ä†
k = S‚Ä†
k
for every k ‚àà[N, ‚àû)Z, i.e., part (viii) holds. For part (ix) we Ô¨Årst observe that
PSN = S‚Ä†
NSN = 0. Then by (vi) we obtain Ker ¬ØXN = Im P, i.e., by taking
the orthogonal complements Im ¬ØXT
N = Im (I ‚àíP). Moreover, from (ii) we have
Im ¬ØXN ‚äÜKer X‚Ä†
N = Im (I ‚àíRN). But since rank ¬ØXN = rank ¬ØXT
N = rank(I ‚àíP) =
rank(I ‚àíRN) (as rank P = rank Rk), it follows that Im ¬ØXN = Im (I ‚àíRN). For
part (x) we note from (ix) and (vii) that
¬ØXN ¬ØX‚Ä†
N = I ‚àíRN,
¬ØPN = ¬ØX‚Ä†
N ¬ØXN = I ‚àíP.
(6.242)
Then XN ¬ØX‚Ä†
N = XNP(I ‚àíP) ¬ØX‚Ä†
N = 0 and ¬ØXNX‚Ä†
N = ¬ØXN(I ‚àíP) PX‚Ä†
N = 0. Thus,
(XN ‚àí¬ØXN) (X‚Ä†
N ‚àí¬ØX‚Ä†
N) = XNX‚Ä†
N ‚àíXN ¬ØX‚Ä†
N ‚àí¬ØXNX‚Ä†
N ‚àí¬ØXN ¬ØX‚Ä†
N
(6.242)
=
RN + (I ‚àíRN) = I.
This shows that the matrices XN ‚àí¬ØXN and X‚Ä†
N ‚àí¬ØX‚Ä†
N are invertible and they are
inverses of each other. Part (xi) is a direct application of the deÔ¨Ånition of the Moore-
Penrose pseudoinverse (see Sect. 1.6.2). If we set A :=
¬ØXN and B := ‚àí(I ‚àí
P) UT
N , then we verify the four properties in (1.157) to conclude that B = A‚Ä†. In
these calculations we use (6.242), property (i) in the form of equations ¬ØXNUT
N =
XN ¬ØUT
N ‚àíI and UT
N ¬ØXN = XT
N ¬ØUN ‚àíI, and the facts that (I ‚àíRN) XN = 0 and
(I ‚àíP) XT
N = 0. Finally, property (xii) follows from (iii) by showing that Xk ¬ØXT
k =
¬ØXkSk ¬ØXT
k ‚â•0 for k ‚àà[N, ‚àû)Z, since Sk ‚â•0 for k ‚àà[N, ‚àû)Z under the stated
additional assumption on Y. The proof of Proposition 6.67 is complete.
‚äì‚äî
Remark 6.68 From the proof of Proposition 6.67(iv), it follows that if ÀúY is any
conjoined basis of (SDS) such that w(Y, ÀúY ) = I, then Sk = X‚Ä†
k ÀúXkP ‚àíX‚Ä†
N ÀúXNP for
all k ‚àà[N, ‚àû)Z.

470
6
Miscellaneous Topics on Symplectic Systems
In the following result, we describe a mutual representation of conjoined bases
of (SDS) with constant kernel on [N, ‚àû)Z.
Theorem 6.69 Let Y (1) and Y (2) be conjoined bases of (SDS) with constant kernels
on [N, ‚àû)Z, and let P (1) and P (2) be the constant projectors deÔ¨Åned by (6.234)
through the functions X(1)
k
and X(2)
k , respectively. Let the conjoined basis Y (2) be
expressed in terms of Y (1) via the matrices M(1), N(1), and let conjoined basis Y (1)
be expressed in terms of Y (2) via the matrices M(2), N(2), that is,
Y (2)
k
=

Y (1)
k
¬ØY (1)
k
 M(1)
N(1)

,
Y (1)
k
=

Y (2)
k
¬ØY (2)
k
 M(2)
N(2)

(6.243)
for all k ‚àà[N, ‚àû)Z, where ¬ØY (1) and ¬ØY (2) are conjoined bases of (SDS) satisfying
the conclusion in Proposition 6.67 with regard to Y (1) and Y (2), respectively. If
Im X(1)
N = Im X(2)
N holds, then
(i) the matrices (M(1))T N(1) and (M(2))T N(2) are symmetric,
(ii) the matrices N(1) and N(2) satisfy N(1) + (N(2))T = 0,
(iii) the matrices M(1) and M(2) are invertible and M(1)M(2) = I = M(2)M(1),
(iv) Im N(1) ‚äÜIm P (1) and Im N(2) ‚äÜIm P (2).
Moreover, the matrices M(1), N(1) do not depend on the choice of ¬ØY (1), and the
matrices M(2), N(2) do not depend on the choice of ¬ØY (2). In fact,
M(1) = ‚àíw( ¬ØY (1), Y (2)),
N(1) = w(Y (1), Y (2)),
M(2) = ‚àíw( ¬ØY (2), Y (1)),
N(2) = w(Y (2), Y (1)).

(6.244)
Proof Since Y (i) and ¬ØY (i) for i ‚àà{1, 2} are normalized conjoined bases of (SDS),
the 2n √ó 2n fundamental matrices in (6.243) are symplectic. By the formula for the
inverse of a symplectic matrix (Lemma 1.58(ii)), we obtain (6.244), i.e.,
M(1)
N(1)

=

( ¬ØU(1)
N )T X(2)
N ‚àí( ¬ØX(1)
N )T U(2)
N
(X(1)
N )T U(2)
N ‚àí(U(1)
N )T X(2)
N

,
(6.245)
M(2)
N(2)

=

( ¬ØU(2)
N )T X(1)
N ‚àí( ¬ØX(2)
N )T U(1)
N
(X(2)
N )T U(1)
N ‚àí(U(2)
N )T X(1)
N

.
(6.246)
Assertion (i) is then a direct consequence of the above expressions and of for-
mula (6.240) for the pairs Y (1),
¬ØY (1) and Y (2), ¬ØY (2). Condition (ii) follows
from (6.244), since w(Y (2), Y (1)) = ‚àí[w(Y (1), Y (2))]T . Regarding item (iii), we
deÔ¨Åne the matrices
L(1) := (X(1)
N )‚Ä†X(2)
N ,
L(2) := (X(2)
N )‚Ä†X(1)
N .
(6.247)

6.3
Symplectic Systems Without Controllability
471
The assumption Im X(1)
N = Im X(2)
N means that the projector R(1)
N onto Im X(1)
N and
the projector R(2)
N onto Im X(2)
N , which are deÔ¨Åned in (6.233), satisfy R(1)
N
= R(2)
N .
Consequently, it follows that
X(1)
N L(1) = R(1)
N X(2)
N = R(2)
N X(2)
N = X(2)
N ,
(6.248)
L(1)L(2) = (X(1)
N )‚Ä†R(2)
N X(1)
N = (X(1)
N )‚Ä†R(1)
N X(1)
N = (X(1)
N )‚Ä†X(1)
N = P (1).
(6.249)
Similarly it can be shown that X(2)
N L(2) = X(1)
N and L(2)L(1) = P (2). In addition,
L(2) = (L(1))‚Ä†,
(6.250)
which follows by an easy veriÔ¨Åcation of the four equalities in (1.157) and by
Im L(i) = Im P (i) for i ‚àà{1, 2}. If we now insert the formula X(1)
N L(1) = X(2)
N
from (6.248) into the expression for M(1) in (6.245) and similarly insert the
formula X(2)
N L(2) = X(1)
N into the expression for M(2) in (6.246), then we get via
w(Y (i), ¬ØY (i)) = I for i ‚àà{1, 2} that
M(1) = ( ¬ØU(1)
N )T X(1)
N L(1) ‚àí( ¬ØX(1)
N )T U(2)
N
= [I + ( ¬ØX(1)
N )T U(1)
N ] L(1) ‚àí( ¬ØX(1)
N )T U(2)
N
= L(1) + ( ¬ØX(1)
N )T [U(1)
N L(1) ‚àíU(2)
N ],
(6.251)
M(2) = ( ¬ØU(2)
N )T X(2)
N L(2) ‚àí( ¬ØX(2)
N )T U(1)
N
= [I + ( ¬ØX(2)
N )T U(2)
N ] L(2) ‚àí( ¬ØX(2)
N )T U(1)
N
= L(2) + ( ¬ØX(2)
N )T [U(2)
N L(2) ‚àíU(1)
N ].
(6.252)
The product M(1)M(2) is then simpliÔ¨Åed to the identity matrix by using the identities
L(1)L(2) = P (1), Proposition 6.67(iv), (6.240), R(1)
N
= R(2)
N . This technical and
rather lengthy calculation is omitted. For part (iv), the matrices N(1) and N(2)
in (6.245) and (6.246) satisfy
N(1) = (X(1)
N )T U(2)
N ‚àí(U(1)
N )T X(1)
N L(1) = (X(1)
N )T [U(2)
N ‚àíU(1)
N L(1)],
(6.253)
N(2) = (X(2)
N )T U(1)
N ‚àí(U(2)
N )T X(2)
N L(2) = (X(2)
N )T [U(1)
N ‚àíU(2)
N L(2)].
(6.254)
Thus, Im N(1) ‚äÜIm (X(1)
N )T = Im P (1) and Im N(2) ‚äÜIm (X(2)
N )T = Im P (2).
In addition, the matrices M(1), N(1) and M(2), N(2) in (6.243) do not depend
on the choice of ¬ØY (1) and ¬ØY (2), because only the conjoined bases Y (1), Y (2) and
the matrices ¬ØX(1)
N , ¬ØX(2)
N , which are unique by Proposition 6.67(v), are used in
expressions (6.251)‚Äì(6.254) for M(1), M(2), N(1), N(2).
‚äì‚äî

472
6
Miscellaneous Topics on Symplectic Systems
Remark 6.70
(i) The equality in Proposition 6.67(iv) implies that for k = N in (6.243), the
conjoined bases Y (1) and Y (2) satisfy
X(2)
N = X(1)
N M(1),
U(2)
N
= U(1)
N M(1) + (X(1)
N )‚Ä†T N(1),
(6.255)
X(1)
N = X(2)
N M(2),
U(1)
N
= U(2)
N M(2) + (X(2)
N )‚Ä†T N(2).
(6.256)
(ii) Equations (6.249) and (6.250) are summarized as
L(1)(L(1))‚Ä† = P (1),
L(2)(L(2))‚Ä† = P (2).
(6.257)
This means that P (1) is the orthogonal projector onto Im L(1) and similarly
P (2) is the orthogonal projector onto Im L(2). Moreover, expressions (6.251)
and (6.252) for matrices M(1) and M(2) provide a connection between M(1)
and L(1) and between M(2) and L(2). In particular,
L(1) = P (1)M(1),
L(2) = P (2)M(2).
(6.258)
These equalities follow from equations (6.251) and (6.257), since ¬ØX(1)
N P (1) =
0 and ¬ØX(2)
N P (2) = 0, by Proposition 6.67(iv). Moreover, condition (iv) in Theo-
rem 6.69 means that N(1) = P (1)N(1) and N(2) = P (2)N(2), which shows that
the representations in (6.243) in fact contain the uniquely determined solutions
¬ØY (1)P (1) and ¬ØY (2)P (2). These facts allows one to rewrite expressions (6.243)
into a form, which is more convenient for the further analysis of the associated
S-matrices. More precisely, from Proposition 6.67(iv), we get
X(2)
k
= X(1)
k
(L(1) + S(1)
k N(1)),
X(1)
k
= X(2)
k
(L(2) + S(2)
k N(2)),

k ‚àà[N, ‚àû)Z.
(6.259)
(iii) A more detailed analysis of the statements in parts (i) and (ii) of this remark
shows that if only Y (1) has constant kernel on [N, ‚àû)Z and (6.255) holds (so
that Im X(2)
N ‚äÜIm X(1)
N ), then the Ô¨Årst equality in (6.259) is satisÔ¨Åed. Similarly,
if Y (2) has constant kernel on [N, ‚àû)Z and (6.256) holds (so that Im X(1)
N
‚äÜ
Im X(2)
N ), then the second equality in (6.259) is satisÔ¨Åed.
Remark 6.71 From the previous remark and Theorem 6.69, it also follows that
the matrices (L(1))T N(1) and (L(2))T N(2) are symmetric. This can be seen from
the calculation (L(1))T N(1) = (M(1))T P (1)N(1) = (M(1))T N(1) and similarly for
(L(2))T N(2) = (M(2))T N(2).
Remark 6.72 As a completion of Theorem 6.69, we show that the matrices M(1) +
S(1)
k N(1) and M(2) + S(2)
k N(2) are invertible for k ‚àà[N, ‚àû)Z. Indeed, from
conditions (i) and (iv) in Theorem 6.69, we obtain that Im (N(1))T ‚äÜIm P (2),

6.3
Symplectic Systems Without Controllability
473
so that Ker X(2)
k
= Ker P (2) ‚äÜKer N(1) on [N, ‚àû)Z. If for some vector v ‚ààRn
we have (M(1) + S(1)
k N(1)) v = 0, then v ‚ààKer X(2)
k
by (6.259) and by L(1) =
P (1)M(1), P (1)S(1)
k
= S(1)
k , and X(1)
k P (1) = X(1)
k . In turn, v ‚ààKer N(1), and so
v ‚ààKer M(1). But since M(1) is invertible by (iii) of Theorem 6.69, it follows that
v = 0. Similarly, one has that M(2) + S(2)
k N(2) is invertible on [N, ‚àû)Z.
The next statement is essentially a continuation of Theorem 6.69 and its proof.
It provides a relation of the S-matrices corresponding to the conjoined bases Y (1)
and Y (2). It will become one of the crucial tools for the development of the theory
of recessive and dominant solutions of (SDS) at ‚àûin Sects. 6.3.6 and 6.3.7.
Theorem 6.73 With
the assumptions and notation of Theorem 6.69 and
Remark 6.70, if the condition Im X(1)
N
= Im X(2)
N holds, then for all k ‚àà[N, ‚àû)Z
we have Im X(1)
k
= Im X(2)
k
and
(L(1) + S(1)
k N(1))‚Ä† = L(2) + S(2)
k N(2),
(6.260)
Im (L(1) + S(1)
k N(1)) = Im P (1),
Im (L(2) + S(2)
k N(2)) = Im P (2),
(6.261)
S(2)
k
= (L(1) + S(1)
k N(1))‚Ä† S(1)
k L‚Ä†T
1 .
(6.262)
Proof Fix k
‚àà
[N, ‚àû)Z. The equality Im X(1)
k
= Im X(2)
k
is a direct con-
sequence of the identities in (6.259). This means that R(1)
k
=
R(2)
k . Using
Theorem 6.66(iii), (6.259), Im L(1) = Im P (1), and Im L(2) = Im P (2), we have
L(1) + S(1)
k N(1) = P (1)(L(1) + S(1)
k N(1))
= (X(1)
k )‚Ä†X(1)
k (L(1) + S(1)
k N(1)) = (X(1)
k )‚Ä†X(2)
k ,
(6.263)
L(2) + S(2)
k N(2) = P (2)(L(2) + S(2)
k N(2))
= (X(2)
k )‚Ä†X(2)
k (L(2) + S(2)
k N(2)) = (X(2)
k )‚Ä†X(1)
k .
(6.264)
Expressions (6.263) and (6.264) then imply formula (6.260) by the veriÔ¨Åcation of
the four equalities in (1.157). In particular, the third and fourth identity in (1.157)
read as
(L(1) + S(1)
k N(1)) (L(2) + S(2)
k N(2)) = (X(1)
k )‚Ä†R(2)
k X(1)
k
= (X(1)
k )‚Ä†R(1)
k X(1)
k
= P (1),
(6.265)
(L(2) + S(2)
k N(2)) (L(1) + S(1)
k N(1)) = (X(2)
k )‚Ä†R(1)
k X(2)
k
= (X(2)
k )‚Ä†R(2)
k X(2)
k
= P (2),
(6.266)

474
6
Miscellaneous Topics on Symplectic Systems
which imply the relations in (6.261). The proof of formula (6.262) is slightly more
complicated. Since by (6.249) we have L(1)L(2) = P (1), from (6.265) we get
(L(1) + S(1)
k N(1)) S(2)
k N(2) = ‚àíS(1)
k N(1)L(2).
Using (6.266), the fact Im S(2)
k
‚äÜIm P (2), and (6.260) we then obtain
S(2)
k N(2) = ‚àí(L(1) + S(1)
k N(1))‚Ä†S(1)
k N(1)L(2).
By Theorem 6.69(ii) and (6.250), we have N(2) = ‚àí(N(1))T and L(2) = (L(1))‚Ä†,
while from Remark 6.71 we know that (N(2))T L(2) is symmetric. This implies
N(1)L(2) = ‚àí(L(1))‚Ä†T N(2), so that
S(2)
k (N(1))T = (L(1) + S(1)
k N(1))‚Ä†S(1)
k (L(1))‚Ä†T (N(1))T .
(6.267)
We will show that the matrix (N(1))T in (6.267) can be canceled. Indeed, if the
equality Im (N(1))T = Im N(2) = Im P (2) holds, then it sufÔ¨Åces to multiply (6.267)
from the right by (N(1))‚Ä†T , because (N(1))T (N(1))‚Ä†T = (N(1))‚Ä†N(1) = P (2),
Im S(2)
k
‚äÜIm P (2), and Im (L(1))‚Ä† = Im L(2) ‚äÜIm P (2). But in general we
only have Im (N(1))T = Im N(2) ‚äÜIm P (2), which shows that more analysis is
required in order to cancel (N(1))T in (6.267). Let us denote G := (L(1))T N(1).
The matrix G is symmetric, Im G ‚äÜIm P (2), and N(1) = (L(1))‚Ä†T G. According
to Lemma 1.89, there exists a sequence {G{ŒΩ}}‚àû
ŒΩ=1 of symmetric matrices with
Im G{ŒΩ} = Im P (2) for all ŒΩ ‚ààN such that G{ŒΩ} ‚ÜíG for ŒΩ ‚Üí‚àû. Furthermore,
with N{ŒΩ} := (L(1))‚Ä†T G{ŒΩ}, we have N{ŒΩ} ‚Üí(L(1))‚Ä†T G = N(1) for ŒΩ ‚Üí‚àû,
and in addition Im N{ŒΩ} = Im P (1) and Im (N{ŒΩ})T = Im P (2) for all ŒΩ ‚ààN. By
verifying the identities in (1.157), it follows that N{ŒΩ}‚Ä† = G{ŒΩ}‚Ä†(L(1))T , and in
particular N{ŒΩ}N{ŒΩ}‚Ä† = P (1) and N{ŒΩ}‚Ä†N{ŒΩ} = P (2) hold. Observe that the matrices
(M(1))T N{ŒΩ} and (L(1))T N{ŒΩ} are symmetric, since
(M(1))T N{ŒΩ} = (M(1))T (L(1))‚Ä†T G{ŒΩ} = (M(1))T (L(2))T G{ŒΩ}
= (M(1))T (M(2))T P (2)G{ŒΩ} = G{ŒΩ},
(L(1))T N{ŒΩ} = (M(1))T P (1)N{ŒΩ} = (M(1))T N{ŒΩ},
where we used Remark 6.70(ii). For each ŒΩ ‚ààN, we now deÔ¨Åne the solution Y {ŒΩ} of
system (SDS) by
Y {ŒΩ}
k
:=

Y (1)
k
¬ØY (1)
k
 M(1)
N{ŒΩ}

,
k ‚àà[N, ‚àû)Z.
(6.268)
Since MT
1 N{ŒΩ} is symmetric and rank ((M(1))T , (N{ŒΩ})T ) = n (as M(1) is invertible
by Theorem 6.69), it follows that Y {ŒΩ} is a conjoined basis of (SDS). Moreover,

6.3
Symplectic Systems Without Controllability
475
the sequence {Y {ŒΩ}}‚àû
ŒΩ=1 converges on [N, ‚àû)Z to the conjoined basis Y (2), which
follows from (6.243) and from the convergence of {(N(1)){ŒΩ}}‚àû
ŒΩ=1 to N(1). Since
Im N{ŒΩ} = Im P (1), the function X{ŒΩ}
k
in (6.268) will have the form as in (6.259).
That is, we have X{ŒΩ}
k
= X(1)
k (L(1) + S(1)
k N{ŒΩ}) on [N, ‚àû)Z for every ŒΩ ‚ààN. Thus,
for each k ‚àà[N, ‚àû)Z, we have the inclusions Im X{ŒΩ}
k
‚äÜIm X(1)
k
= Im X(2)
k
and
Im (X{ŒΩ}
k )T ‚äÜIm [(L(1))T + (N{ŒΩ})T S(1)
k ] ‚äÜIm P (2) = Im (X(2)
k )T for all ŒΩ ‚ààN.
Fix an index K ‚àà[N, ‚àû)Z. Then by Lemma 1.61 (with j := ŒΩ and using that the
interval [N, K]Z is a Ô¨Ånite set), there exists ŒΩ0 ‚ààN such that for all ŒΩ ‚â•ŒΩ0
Im X{ŒΩ}
k
= Im X(2)
k ,
Im (X{ŒΩ}
k )T = Im (X(2)
k )T
for all k ‚àà[N, K]Z,
(6.269)
rankX{ŒΩ}
k
= rankX(2)
k
for all k ‚àà[N, K]Z.
(6.270)
Therefore, by (6.270) and the limit property of the Moore-Penrose pseudoinverse in
Remark 1.60(v), we obtain
(X{ŒΩ}
k )‚Ä† ‚Üí(X(2)
k )‚Ä†
for ŒΩ ‚Üí‚àûand every k ‚àà[N, K]Z.
(6.271)
Fix an index ŒΩ ‚â•ŒΩ0. Then from the second equality in (6.269), it follows that
Ker X{ŒΩ}
k
= Ker X(2)
k
= Ker P (2) on [N, K]Z, so that Y {ŒΩ} is a conjoined basis
of (SDS) with constant kernel on [N, K]Z and Im X{ŒΩ}
N
= Im X(2)
N
= Im X(1)
N .
Hence, Theorem 6.69 (on the interval [N, K]Z) can be applied, and the Ô¨Årst formula
in (6.261) proven above holds for the pair Y (1), Y {ŒΩ}, i.e.,
Im (L(1) + S(1)
k N{ŒΩ}) = Im P (1),
k ‚àà[N, K]Z.
(6.272)
Let S{ŒΩ}
k
be the S-matrix corresponding to the conjoined basis Y {ŒΩ}. Then
S{ŒΩ}
k (N{ŒΩ})T = (L(1) + S(1)
k N{ŒΩ})‚Ä† S(1)
k (L(1))‚Ä†T (N{ŒΩ})T ,
k ‚àà[N, K]Z,
according to (6.267). Since Im (N{ŒΩ})T
= Im P (2), the matrix (N{ŒΩ})T can be
canceled as we showed above, and then we obtain
S{ŒΩ}
k
= (L(1) + S(1)
k N{ŒΩ})‚Ä† S(1)
k (L(1))T ‚Ä†,
k ‚àà[N, K]Z.
(6.273)
Assertion (6.271) yields that S{ŒΩ}
k
‚ÜíS(2)
k
as ŒΩ ‚Üí‚àûfor every k ‚àà[N, K]Z. Since
L(1) + S(1)
k N{ŒΩ} ‚ÜíL(1) + S(1)
k N(1) as ŒΩ ‚Üí‚àûfor each k ‚àà[N, K]Z and (6.272)
holds, it follows from Remark 1.60(v) that
(L(1) + S(1)
k N{ŒΩ})‚Ä† ‚Üí(L(1) + S(1)
k N(1))‚Ä†
as ŒΩ ‚Üí‚àûfor each k ‚àà[N, K]Z.

476
6
Miscellaneous Topics on Symplectic Systems
In turn, equation (6.273) implies that S{ŒΩ}
k
‚ÜíS(2)
k
as ŒΩ ‚Üí‚àûfor each k ‚àà[N, K]Z
and that formula (6.262) holds for all k ‚àà[N, K]Z. But since the index K ‚àà
[N, ‚àû)Z was arbitrary, it follows that (6.262) holds for all k ‚àà[N, ‚àû)Z. The proof
of Theorem 6.73 is complete.
‚äì‚äî
Remark 6.74 Under the assumptions of Theorem 6.73, we take k = N in (6.260)
and obtain by using (6.258) and (6.250) the equality
(P (1)M(1))‚Ä† = (L(1))‚Ä† = L(2) = P (2)M(2) = P (2)(M(1))‚àí1.
(6.274)
The following result provides a connection between a conjoined basis of (SDS)
with constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) with the
principal solution Y [N] of (SDS) and with the order of abnormality. This result, and
in particular inequality (6.279), will serve as another crucial tool for the analysis of
recessive and dominant solutions of (SDS) at ‚àû.
Theorem 6.75 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Let the matrices P, Sk, PS‚àû,
and T be deÔ¨Åned by (6.234), (6.236), (6.233), (6.238), and (6.237). Then for all
k ‚àà[N, ‚àû)Z
X[N]
k
= XkSkXT
N,
rankSk = rank X[N]
k
= n ‚àíd[N, k]Z,
(6.275)
rank PS‚àû= n ‚àíd[N, ‚àû)Z,
(6.276)
0 ‚â§rankT ‚â§n ‚àíd[N, ‚àû)Z,
(6.277)
0[N, ‚àû)Z = Im [X‚Ä†T
N (I ‚àíPS‚àû)] ‚äïIm [UN(I ‚àíP)],
(6.278)
n ‚àíd[N, ‚àû)Z ‚â§rankXk ‚â§n.
(6.279)
Proof As a consequence of estimate (4.62) (with Y [0] := Y [N]) or a consequence
of Theorems 2.39 and 2.36(iv), we know that the principal solution Y [N] has no
forward focal point in [N, ‚àû)Z. This means that the kernel of X[N]
k
is nonincreasing
on [N, ‚àû)Z. Using (6.226) in Theorem 6.57 obtain
0[N, k]Z = Ker X[N]
k
for all k ‚àà[N, ‚àû)Z.
(6.280)
Let Y [N] be expressed in terms of Y via the matrices M[N], N[N], i.e.,
Y [N]
k
=

Yk, ¬ØYk
M[N]
N[N]

,
k ‚àà[N, ‚àû)Z,
(6.281)
where ¬ØY is a conjoined basis of (SDS) from Proposition 6.67. By (6.244) in
Theorem 6.69, we have from (6.281) at k = N
M[N] = ‚àíw( ¬ØY, Y [N]) = ‚àí¬ØXT
N,
N[N] = w(Y, Y [N]) = XT
N.
(6.282)

6.3
Symplectic Systems Without Controllability
477
Since ¬ØXN is uniquely determined by Proposition 6.67(v), the matrices M[N], N[N]
do not depend on the choice of ¬ØY. Furthermore, inserting expressions (6.282)
into the representation of X[N] in (6.281) and using the deÔ¨Ånition of P and
Proposition 6.67(iv) yield for all k ‚àà[N, ‚àû)Z
X[N]
k
= ‚àíXk ¬ØXT
N + ¬ØXkXT
N = ‚àíXkP ¬ØXT
N + ¬ØXkPXT
N
= ‚àíXk(XNSN)T + (XkSk) XT
N = XkSkXT
N.
(6.283)
Since by Theorem 6.66(iii) the equalities PSk = Sk = SkP hold, (6.283) gives
X‚Ä†
kX[N]
k
X‚Ä†T
N
(6.283)
=
X‚Ä†
kXkSkXT
NX‚Ä†T
N = PSkP = Sk,
k ‚àà[N, ‚àû)Z.
(6.284)
The expressions in (6.283) and (6.284) show that rankX[N]
k
=
rankSk,
while (6.280) implies that rankX[N]
k
= n ‚àíd[N, k]Z. Therefore, the equalities
in (6.275) are established. The constancy of Im Sk for large k and the identity
rankSk = rank PSk then yield (6.276). Next, by Remark 1.60(i) we know that
rankS‚Ä†
k = rank Sk = n‚àíd[N, ‚àû)Z for large k, so that the deÔ¨Ånition of T in (6.237)
yields (6.277). In order to prove (6.278), Ô¨Åx k ‚àà[N, ‚àû)Z, and let v ‚àà0[N, k]Z.
By (6.280) and (6.283), we have XkSkXT
Nv = 0, and using Theorem 6.66(iii), we
get
PSk XT
Nv = S‚Ä†
k PSkXT
Nv = S‚Ä†
k X‚Ä†
kXkSkXT
Nv = 0.
Hence, XT
Nv = (I ‚àíPSk) v‚àóholds for some v‚àó‚ààRn. Now we use that the vector
v can be uniquely decomposed as the sum v = v1 + v2, where v1 ‚ààIm XN =
Im X‚Ä†T
N and v2 ‚àà(Im XN)‚ä•= Ker XT
N = Ker RN = Im [UN(I ‚àíP)], by (6.233)
and Theorem 6.66(i). Consequently, XT
Nv1 = (I ‚àíPSk) v‚àówhich in turn implies
that v1 ‚ààIm [X‚Ä†T
N (I ‚àíPSk)]. Thus, v ‚ààIm [X‚Ä†T
N (I ‚àíPSk)] ‚äïIm [UN(I ‚àíP)].
Conversely, every vector w ‚ààIm [X‚Ä†T
N (I ‚àíPSk)] ‚äïIm [UN(I ‚àíP)] has the form
w = X‚Ä†T
N (I ‚àíPSk) w1 + UN(I ‚àíP) w2
for some w1, w2 ‚ààRn.
Then by the aid of (6.283), SkP = Sk, and SkPSk = Sk, we get
X[N]
k
w = XkSkXT
NX‚Ä†T
N (I ‚àíPSk) w1 + XkSkXT
NUN(I ‚àíP) w2
= XkSkP(I ‚àíPSk) w1 + XkSkUT
N XN(I ‚àíP) w2
= XkSk(I ‚àíPSk) w1 + XkSkUT
N XNP(I ‚àíP) w2 = 0.

478
6
Miscellaneous Topics on Symplectic Systems
Thus w ‚ààKer X[N]
k
= 0[N, k]Z by (6.280), and
0[N, k]Z = Im [X‚Ä†T
N (I ‚àíPSk)] ‚äïIm [UN(I ‚àíP)],
k ‚àà[N, ‚àû)Z.
In view of (6.238), we conclude, by taking k ‚Üí‚àû, that (6.278) holds. For (6.279)
we note that n ‚àíd[N, k]Z = rankX[N]
k
‚â§rankXk holds on [N, ‚àû)Z, by (6.275).
Moreover, the equality rank Sk = rankPSk and (6.276) yield that the number
n ‚àíd[N, ‚àû)Z is the maximum of rank X[N]
k
on [N, ‚àû)Z. Therefore, rank Xk lies
necessarily between n ‚àíd[N, ‚àû)Z and n, as we claim in (6.279).
‚äì‚äî
Remark 6.76 Formula (6.275) shows that for a conjoined basis Y of (SDS) with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû), the rank of
its corresponding S-matrix depends only on the rank of X[N] and hence, on the
abnormality of (SDS) on [N, ‚àû)Z, but not on the choice of Y itself. This means
that the changes in Im (X[N]
k
)T and Im Sk occur at the same points, i.e., according
to Theorem 6.66(iv), there exist a Ô¨Ånite partition N0 := N < N1 < N2 < ¬∑ ¬∑ ¬∑ <
Nm < ‚àûof [N, ‚àû)Z, which does not depend on the matrix function S, such that
Im Sk is constant on each subinterval [Nj, Nj+1 ‚àí1]Z, j ‚àà{0, . . ., m ‚àí1} and
Im Sk ‚â°Im SNj ‚´ãIm SNj+1,
k ‚àà[Nj, Nj+1 ‚àí1]Z,
j ‚àà{0, 1, . . . , m ‚àí1}
Im Sk ‚â°Im SNm,
rankSk = n ‚àíd[N, ‚àû)Z,
k ‚àà[Nm, ‚àû)Z.
The estimate in (6.279) is extremely important in the theory of conjoined bases
Y of (SDS). It gives in particular the lower bound for the rank of Xk. We shall
see that all integer values between n ‚àíd[N, ‚àû)Z and n are indeed attained by the
rank of Xk. Moreover, the second condition in (6.275) implies that for all conjoined
bases Y of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points in
(N, ‚àû), the rank of the matrices Sk changes at the same points in [N, ‚àû)Z, i.e., the
points where rankSk changes (increases) do not depend on the particular choice of
the conjoined basis Y.
At the end of this section, we present three extensions of the previous results. The
Ô¨Årst one is a generalization of Theorem 6.73 in a sense that the considered initial
condition can be taken at any index L ‚àà[N, ‚àû)Z. This statement then leads to the
deÔ¨Ånition of a genus of conjoined bases of (SDS) in Sect. 6.3.8.
Theorem 6.77 Let Y (1) and Y (2) be conjoined bases of (SDS) with constant kernel
on [N, ‚àû)Z, and let the equality Im X(1)
L
= Im X(2)
L
be satisÔ¨Åed for some index
L ‚àà[N, ‚àû)Z. Then Im X(1)
k
= Im X(2)
k
holds for all k ‚àà[N, ‚àû)Z.
Proof If k ‚àà[L, ‚àû)Z, then the result follows from Theorem 6.73 (with N := L),
i.e., by (6.259) from the equations
X(3‚àíi)
k
= X(i)
k (M(i)
(L) + S(i)(L)
k
N(i)),
k ‚àà[L, ‚àû)Z,
P (i)M(i)
(L) = (X(i)
L )‚Ä†X(3‚àíi)
L
,
‚é´
‚é¨
‚é≠
i ‚àà{1, 2},
(6.285)

6.3
Symplectic Systems Without Controllability
479
where S(i)(L)
k
:= S(i)
k ‚àíS(i)
L and where M(i)
(L) is the invertible matrix associated with
¬ØY (i) in Proposition 6.67 and Theorem 6.69 (with N := L). We note that the matrix
N(i) does not depend on L ‚àà[N, ‚àû)Z by (6.244) in Theorem 6.69.
For k ‚àà[N, L]Z we use the backward system (2.10). DeÔ¨Åne the Riccati quotients
Q(i)
k
:= U(i)
k (X(i)
k )‚Ä† + (X(i)
k )‚Ä† T (U(i)
k )T (I ‚àíR(i)
k ),
k ‚àà[N, ‚àû)Z,
i ‚àà{1, 2},
(6.286)
where R(i)
k
is the orthogonal projector onto Im X(i)
k
as deÔ¨Åned in (6.233).
By (2.10), (6.286), and Theorem 6.66, we obtain
X(i)
k
= (DT
k ‚àíBT
k Q(i)
k+1) X(i)
k+1,
U(i)
k (X(i)
k )‚Ä† = Q(i)
k R(i)
k ,

k ‚àà[N, ‚àû)Z,
i ‚àà{1, 2}.
(6.287)
The Wronskian N(1) = w(Y (1), Y (2)) is constant, which implies by (6.287) that
(X(1)
k )‚Ä† T N(1) = R(1)
k U(2)
k
‚àíR(1)
k Q(1)
k X(2)
k ,
k ‚àà[N, ‚àû)Z.
(6.288)
We now apply Theorem 6.66(ii) to Y (1) and use (2.10) and (6.288) to get
X(2)
k
= DT
k X(2)
k+1 ‚àíBT
k R(1)
k+1U(2)
k+1
(6.288)
=
(DT
k ‚àíBT
k Q(1)
k+1) X(2)
k+1 ‚àíBT
k (X(1)
k+1)‚Ä† T N(1)
(6.289)
for all k ‚àà[N, ‚àû)Z. We will show that Im X(2)
k
‚äÜIm X(1)
k
on [N, L]Z. DeÔ¨Åne
Zk := X(1)
k (M(1)
(L) ‚àíFkN(1)),
Fk :=
L‚àí1

j=k
(X(1)
j+1)‚Ä†Bj(X(1)
j )‚Ä† T ,
k ‚àà[N, L]Z,
with FL := 0. It follows by the symmetry of X(1)
k (X(1)
k+1)‚Ä†Bk and by the identity
P (1)(X(1)
k+1)‚Ä† = (X(1)
k+1)‚Ä†, as X(1) has constant kernel on [N, ‚àû)Z, that
Zk ‚àí(DT
k ‚àíBT
k Q(1)
k+1) Zk+1
= X(1)
k (M(1)
(L) ‚àíFkN(1)) ‚àí(DT
k ‚àíBT
k Q(1)
k+1) X(1)
k+1(M(1)
(L) ‚àíFk+1N(1))
(6.287)
=
X(1)
k (Fk) N(1) = ‚àíR(1)
k X(1)
k (X(1)
k+1)‚Ä†Bk(X(1)
k )‚Ä† T N(1)
= ‚àíR(1)
k BT
k (X(1)
k+1)‚Ä† T P (1) N(1) = ‚àíBT
k (X(1)
k+1)‚Ä† T N(1)

480
6
Miscellaneous Topics on Symplectic Systems
for k ‚àà[N, L ‚àí1]Z. Therefore, the sequence Zk satisÔ¨Åes the nonhomogeneous
equation (6.289) on [N, L ‚àí1]Z. Moreover, since R(1)
L
= R(2)
L
by the assumption
Im X(1)
L = Im X(2)
L , we have
ZL = X(1)
L P (1)M(1)
(L)
(6.285)
=
R(1)
L X(2)
L = R(2)
L X(2)
L = X(2)
L .
Thus, the uniqueness of backward solutions of equation (6.289) yields
X(2)
k
= Zk = X(1)
k (M(1)
(L) ‚àíFkN(1)),
k ‚àà[N, L]Z.
This implies that Im X(2)
k
‚äÜIm X(1)
k
on [N, L]Z. Upon interchanging the roles of
the conjoined bases Y (1) and Y (2), we derive that Im X(1)
k
‚äÜIm X(2)
k
on [N, L]Z.
Therefore, Im X(1)
k
= Im X(2)
k
holds for k ‚àà[N, L]Z, which completes the proof.
‚äì‚äî
Remark 6.78 The proof of Theorem 6.77 shows that the representation formulas
in (6.285) are in fact satisÔ¨Åed for every index k ‚àà[N, ‚àû)Z.
In the next result, we extend Theorem 6.69 by using a notion of representable
conjoined bases of (SDS).
DeÔ¨Ånition 6.79 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z. We say that a solution ÀúY is representable by Y on the interval [N, ‚àû)Z if
in the relation
ÀúYk = k ÀúD,
k ‚àà[0, ‚àû)Z,
J ÀúD =
w(Y, ÀúY )
w( ¬ØY, ÀúY )

,
(6.290)
where k = (Yk,
¬ØYk) is a symplectic fundamental matrix of (SDS) such that
w(Y, ¬ØY ) = I, the matrix ÀúD does not depend on the conjoined basis ¬ØY.
Theorem 6.80 Assume that Y is a conjoined basis of (SDS) with constant kernel
on [N, ‚àû)Z with P deÔ¨Åned by (6.234), and let ÀúY be a solution of (SDS). Then the
following conditions are equivalent.
(i) The solution ÀúY is representable by Y on [N, ‚àû)Z.
(ii) The (constant) Wronskian w(Y, ÀúY ) of Y and ÀúY satisÔ¨Åes
Im w(Y, ÀúY ) ‚äÜIm P.
(6.291)
(iii) The inclusion Im ÀúXk ‚äÜIm Xk holds for all k ‚àà[N, ‚àû)Z.
(iv) The inclusion Im ÀúXK ‚äÜIm XK holds for some K ‚àà[N, ‚àû)Z.
Proof Let ÀúD be the matrix in (6.290), where ¬ØY is the conjoined basis in Propo-
sition 6.67 associated with Y. First we assume condition (i). Since w(Y, ¬ØY ) = I,
w(Y, Y) = 0, and X‚Ä†
NXN = P hold, it is straightforward to verify that the solution

6.3
Symplectic Systems Without Controllability
481
¬ØY ‚àó:= ¬ØY + Y(I ‚àíP) of (SDS) also satisÔ¨Åes w(Y, ¬ØY ‚àó) = I and X‚Ä†
N ¬ØX‚àó
N = 0. Denote
by ÀúD‚àóthe matrix in (6.290) representing ÀúY in terms of the symplectic fundamental
matrix ‚àó
k := (Yk, ¬ØY ‚àó
k ), i.e.,
ÀúYk = ‚àó
k ÀúD‚àó,
k ‚àà[0, ‚àû)Z,
J ÀúD‚àó=
 w(Y, ÀúY )
w( ¬ØY ‚àó, ÀúY)

.
(6.292)
Observe that w( ¬ØY ‚àó, ¬ØY) = I ‚àíP. Then we have
ÀúD‚àó(6.292)
=
(‚àó
k)‚àí1 ÀúYk
(6.290)
=
‚àíJ (‚àó
k)TJ k ÀúD
= ‚àíJ

w(Y, Y)
w(Y, ¬ØY )
w( ¬ØY ‚àó, Y) w( ¬ØY ‚àó, ¬ØY)

ÀúD =
I P ‚àíI
0
I

ÀúD.
Using the block notation ÀúD =
 F
G

and ÀúD‚àó=
 F ‚àó
G‚àó

, we then obtain the equalities
F ‚àó= F ‚àí(I ‚àíP) G and G‚àó= w(Y, ÀúY ) = G. Since we now assume that ÀúY is
representable by Y, it follows that ÀúD‚àó= ÀúD, and hence F ‚àó= F. This yields that
(I ‚àíP) G = 0, i.e., Im G ‚äÜKer (I ‚àíP) = Im P. Thus, condition (6.291) is
proven. Assume now (ii) and let G := w(Y, ÀúY ). Combining the identities PG = G
and PXT
k = XT
k on [N, ‚àû)Z yields that (I ‚àíP) UT
k ÀúXk = 0 on [N, ‚àû)Z. By using
the property Im [Uk(I ‚àíP)] = Ker Rk on [N, ‚àû)Z from Theorem 6.66(i), we then
get
Im ÀúXk ‚äÜKer [(I ‚àíP) UT
k ] =
!
Im [Uk(I ‚àíP)]
"‚ä•= (Ker Rk)‚ä•= Im Rk = Im Xk
on [N, ‚àû)Z, which shows (iii). Next, part (iii) implies (iv) trivially. Finally, assume
that (iv) is satisÔ¨Åed. Since Im XK = Im RK, it follows that RK ÀúXK = ÀúXK. Hence,
ÀúXK = XKX‚Ä†
K ÀúXK and consequently the matrix F := ‚àíw( ¬ØY, ÀúY) satisÔ¨Åes
F = ‚àí( ¬ØXT
K ÀúUK ‚àí¬ØUT
K ÀúXK) = ¬ØUT
KXKX‚Ä†
K ÀúXK ‚àí¬ØXT
K ÀúUK
= (I + ¬ØXT
KUK) X‚Ä†
K ÀúXK ‚àí¬ØXT
K ÀúUK.
This shows that the matrix F is determined by Y, ÀúY, and ¬ØXK. But since ¬ØXk is
uniquely determined by Y on [N, ‚àû)Z by Proposition 6.67(v), we get that F is
determined by Y and ÀúY only. This implies that the matrix D =
 F
G

does not depend
on the choice of ¬ØY, so that the solution ÀúY is representable by Y on [N, ‚àû)Z. The
proof is complete.
‚äì‚äî

482
6
Miscellaneous Topics on Symplectic Systems
6.3.3
Conjoined Bases with Given Rank
In this subsection we present a construction of conjoined bases Y with a given rank
satisfying (6.279). This construction is based on the notion of an equivalence of
two solutions of (SDS) and the relation being contained for two conjoined bases
of (SDS). More precisely, we say that two solutions Y and ÀúY are equivalent on the
interval [N, ‚àû)Z if
Xk = ÀúXk
for all k ‚àà[N, ‚àû)Z.
(6.293)
This means that
XN = ÀúXN
and
Im (UN ‚àíÀúUN) ‚äÜ0[N, ‚àû)Z.
(6.294)
By using the representation of the space 0[N, ‚àû)Z in (6.278) we obtain the
following more precise statement.
Proposition 6.81 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Let the matrices P and PS‚àûbe
deÔ¨Åned by (6.234) and (6.238). Then two solutions Y (1) and Y (2) of (SDS) are
equivalent on [N, ‚àû)Z if and only if there exist unique n √ó n matrices G and H
such that
X(1)
N = X(2)
N ,
U(1)
N ‚àíU(2)
N
= X‚Ä†T
N G + UNH,
(6.295)
Im G ‚äÜIm (P ‚àíPS‚àû),
Im H ‚äÜIm (I ‚àíP).
(6.296)
Proof The existence of matrices G and H satisfying (6.295) follows from (6.294)
and from the representation of 0[N, ‚àû)Z in (6.278) in Theorem 6.75. The latter
reference also gives the second property in (6.296) and the inclusion Im G ‚äÜ
Im (I ‚àíPS‚àû). However, the matrix G can be chosen so that Im G ‚äÜIm P,
because in (6.295) we may take X‚Ä†T XT X‚Ä†T G = X‚Ä†T P G instead of X‚Ä†T G,
by the properties of the Moore-Penrose pseudoinverse. Equation (6.296) then also
implies the uniqueness of G and H, because Y is a conjoined basis. Conversely, the
conditions in (6.295) and (6.296) imply that (6.294) holds, and thus Y (1) and Y (2)
are equivalent.
‚äì‚äî
The equivalence of solutions on [N, ‚àû)Z leads to an ordering in the set of all
conjoined bases of (SDS). This ordering is phrased in terms of the relation ‚Äúbeing
contained‚Äù deÔ¨Åned below.
DeÔ¨Ånition 6.82 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Let P and PS‚àûbe the associated
orthogonal projectors in (6.234) and (6.238). Consider an orthogonal projector P ‚àó
satisfying
Im PS‚àû‚äÜIm P ‚àó‚äÜIm P.
(6.297)

6.3
Symplectic Systems Without Controllability
483
We say that a conjoined basis Y ‚àóis contained in Y on [N, ‚àû)Z with respect to P ‚àó,
or that Y contains Y ‚àóon [N, ‚àû)Z with respect to P ‚àó, if the solutions Y ‚àóand YP ‚àó
are equivalent on [N, ‚àû)Z, i.e., if X‚àó
k = XkP ‚àófor all k ‚àà[N, ‚àû)Z.
Remark 6.83 The conjoined basis Y ‚àó, which is contained in Y on [N, ‚àû)Z with
respect to the projector P ‚àó, has also a constant kernel on [N, ‚àû)Z and no forward
focal points in (N, ‚àû). The Ô¨Årst property can be seen from X‚àó
k = XkP ‚àóand
Ker Xk = Ker P ‚äÜKer P ‚àó, which imply that Ker X‚àó
k = Ker P ‚àóon [N, ‚àû)Z. This
also shows that P ‚àó= PIm (X‚àó
k)T is the projector associated with Y ‚àóthrough (6.233)
and (6.234). The fact that Y ‚àóhas no forward focal points in (N, ‚àû) is proven as
follows. From the identity P ‚àó= PP ‚àó, we get
(X‚àó
k)‚Ä† = P ‚àó(X‚àó
k)‚Ä† = PP ‚àó(X‚àó
k)‚Ä† = X‚Ä†
kXkP ‚àó(X‚àó
k)‚Ä†
= X‚Ä†
kX‚àó
k(X‚àó
k)‚Ä† = X‚Ä†
kR‚àó
k.
(6.298)
Therefore, by Theorem 6.66(ii), we obtain on [N, ‚àû)Z
X‚àó
k(X‚àó
k+1)‚Ä†Bk = XkP ‚àó(X‚àó
k+1)‚Ä†Bk = Xk(X‚àó
k+1)‚Ä†Bk
(6.298)
=
XkX‚Ä†
k+1R‚àó
k+1Bk = XkX‚Ä†
k+1Bk.
(6.299)
The last term is nonnegative deÔ¨Ånite, since Y has no forward focal points in (N, ‚àû).
We now utilize the matrices G and H in (6.295)‚Äì(6.296) in order to describe
the conjoined bases of (SDS), which are contained in a given conjoined basis
(Theorem 6.84) or which contain a given conjoined basis (Theorem 6.87). We
now introduce the set M(P ‚àó‚àó, P ‚àó, P) of pairs of matrices (G, H) associated with
orthogonal projectors P ‚àó‚àó, P ‚àó, P satisfying the inclusions Im P ‚àó‚àó‚äÜIm P ‚àó‚äÜ
Im P. We deÔ¨Åne
M(P ‚àó‚àó, P ‚àó, P) =
!
(G, H) ‚ààRn√ón √ó Rn√ón, rank (GT, H T, P ‚àó) = n,
P ‚àó‚àóG = 0, PG = G, P ‚àóG = GT P ‚àó, PH = 0
"
,

(6.300)
Note that the set M(P ‚àó‚àó, P ‚àó, P) is always nonempty, because the pair (G, H) with
G := P ‚àíP ‚àóand H := I ‚àíP belongs to M(P ‚àó‚àó, P ‚àó, P). Note also that if P = I,
then H = 0. The following result describes all conjoined bases Y ‚àóof (SDS), which
are contained in a given conjoined basis Y with respect to a Ô¨Åxed projector P ‚àó.
Theorem 6.84 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Let P and PS‚àûbe the associated
orthogonal projectors in (6.234) and (6.238). Consider an orthogonal projector
P ‚àósatisfying (6.297). Then a conjoined basis Y ‚àóof (SDS) is contained in Y on
[N, ‚àû)Z with respect to P ‚àóif and only if for some (G, H) ‚ààM(PS‚àû, P ‚àó, P)
X‚àó
N = XNP ‚àó,
U‚àó
N = UNP ‚àó+ X‚Ä†T
N G + UNH.
(6.301)

484
6
Miscellaneous Topics on Symplectic Systems
Proof Let Y ‚àóbe a conjoined basis of (SDS) which is contained in Y on [N, ‚àû)Z
with respect to P ‚àó. Then Y and YP ‚àóare equivalent on [N, ‚àû)Z by DeÔ¨Ånition 6.82.
From Proposition 6.81 (with Y (1) := YP ‚àóand Y (2) := Y ‚àó), it follows that
Y ‚àósatisÔ¨Åes the initial conditions in (6.301) with the matrices G and H such
that PS‚àûG = 0, PG = G, and PH
= 0. We will show that (G, H) ‚àà
M(PS‚àû, P ‚àó, P). Multiplying (6.301) by (X‚àó
N)T , we get
(X‚àó
N)T U‚àó
N = P ‚àóXT
NUNP ‚àó+ P ‚àóXT
NXT ‚Ä†
N G + P ‚àóXT
NUNH.
(6.302)
The symmetry of XT
NUN and the identities XNP = XN and PH = 0 imply that
P ‚àóXT
NUNH = P ‚àóUT
NXNH = P ‚àóUT
N XNPH = 0.
(6.303)
Upon inserting (6.303) into (6.302) and using XT
NXT ‚Ä†
N
= P and PG = G, we
obtain
P ‚àóG = P ‚àóPG = P ‚àóXT
NXT ‚Ä†
N G = (X‚àó
N)T U‚àó
N ‚àíP ‚àóXT
NUNP ‚àó.
This shows that the matrix P ‚àóG is symmetric, i.e., P ‚àóG = GT P ‚àó. Furthermore, if
v ‚ààRn is a vector such that v ‚ààKer G ‚à©Ker H ‚à©Ker P ‚àó, then (6.301) implies that
v ‚ààKer X‚àó
N ‚à©Ker U‚àó
N = {0}, because Y ‚àóis a conjoined basis. Therefore, Ker G ‚à©
Ker H ‚à©Ker P ‚àó= {0}, which is equivalent with rank (GT, H T, P ‚àó) = n. The
above properties of G and H imply that (G, H) ‚ààM(PS‚àû, P ‚àó, P). Conversely, it
is easy to see that for any pair (G, H) ‚ààM(PS‚àû, P ‚àó, P) the solution Y ‚àóof (SDS)
satisfying the initial conditions in (6.301) is a conjoined basis, which is contained
in Y on [N, ‚àû)Z with respect to P ‚àó.
‚äì‚äî
It follows from Proposition 6.81 that the pair (G, H) ‚ààM(PS‚àû, P ‚àó, P), which
determines the conjoined basis Y ‚àóin Theorem 6.84, is unique. For this reason we
also say that Y ‚àóis contained in Y on [N, ‚àû)Z through the pair (G, H). Moreover,
the matrix G in (6.301) satisÔ¨Åes G = w(Y, Y ‚àó), which can be veriÔ¨Åed by the
calculation of the Wronskian at k = N.
Remark 6.85 For every orthogonal projector P ‚àósatisfying (6.297), there always
exists a conjoined basis Y ‚àówhich is contained in Y with respect to P ‚àóon
[N, ‚àû)Z, for example, it is the conjoined basis Y ‚àóof (SDS) given by the initial
conditions (6.301) with G := P ‚àíP ‚àóand H := I ‚àíP. This follows from
Theorem 6.84 and from the fact that the above choice of (G, H) belongs to
M(PS‚àû, P ‚àó, P).
In the following result, we derive an additional property of the conjoined bases
Y ‚àóof (SDS) which are contained in Y on [N, ‚àû)Z.
Proposition 6.86 Let Y be a conjoined basis of (SDS) with constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû). Let Sk in (6.236) be its
corresponding S-matrix. If Y ‚àóis any conjoined basis of (SDS) which is contained

6.3
Symplectic Systems Without Controllability
485
in Y on [N, ‚àû)Z and if S‚àó
k is its corresponding S-matrix, then S‚àó
k = Sk for all
k ‚àà[N, ‚àû)Z.
Proof Let P ‚àóbe an orthogonal projector satisfying (6.297) such that Y ‚àóis contained
in Y with respect to P ‚àóon [N, ‚àû)Z., i.e., X‚àó
k = XkP ‚àóon [N, ‚àû)Z. Then by
Remark 6.83, the conjoined basis Y ‚àóhas constant kernel on [N, ‚àû)Z and no forward
focal points in (N, ‚àû). In turn, by Theorem 6.66(ii) and identity (6.298), we have
Sk
(6.236)
=
k‚àí1

j=N
X‚Ä†
j+1 Bj X‚Ä†T
j
=
k‚àí1

j=N
X‚Ä†
j+1R‚àó
j+1BjR‚àó
j X‚Ä†T
j
=
k‚àí1

j=N
(X‚àó
j+1)‚Ä† Bj (X‚àó
j )‚Ä†T (6.236)
=
S‚àó
k
(6.304)
for all k ‚àà[N, ‚àû)Z, which completes the proof.
‚äì‚äî
Next we present a supplement to Theorem 6.84 in the sense that we construct
conjoined bases ÀúY of (SDS) with constant kernel on [N, ‚àû)Z, which contain a given
conjoined basis Y ‚àóon [N, ‚àû)Z according to DeÔ¨Ånition 6.82. This construction is
based on a suitable choice of the initial conditions of ÀúY at k = N. We shall see that
this choice is closely related with the set in (6.300)
Theorem 6.87 Let Y ‚àóbe a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Let P ‚àó, R‚àó
k, and PS‚àó‚àûbe the
associated projectors deÔ¨Åned in (6.234), (6.233), and (6.238) through X‚àó. Let P
and R be orthogonal projectors satisfying
Im P ‚àó‚äÜIm P,
Im R‚àó
N ‚äÜIm R,
rankP = rankR,
(6.305)
and let (G, H) ‚ààM(PS‚àó‚àû, P ‚àó, P). If the n√ón matrices X and U solve the system
XX‚Ä† = R,
X‚Ä†X = P,
(6.306)
XP ‚àó= X‚àó
N,
XT U = UT X,
X‚Ä†T G + U(P ‚àó+ H) = U‚àó
N,
(6.307)
we denote by ÀúY the solution of (SDS) given by the initial conditions ÀúXN = X and
ÀúUN = U. Then ÀúY has the following properties.
(i) The solution ÀúY is a conjoined basis of (SDS).
(ii) The conjoined basis ÀúY has constant kernel on [N, ‚àû)Z and no forward focal
points in (N, ‚àû). In addition, the associated projectors ÀúP and ÀúRk deÔ¨Åned
in (6.234) and (6.233) through ÀúX satisfy ÀúP = P and ÀúRN = R.
(iii) The conjoined basis Y ‚àóis contained in ÀúY on [N, ‚àû)Z through the pair (G, H)
or equivalently with respect to the projector P ‚àó.

486
6
Miscellaneous Topics on Symplectic Systems
Proof Let the conjoined basis Y ‚àóand the projectors P ‚àó, R‚àó, PS‚àó‚àûand P, R be as
in the above statement and let (G, H) ‚ààM(PS‚àó‚àû, P ‚àó, P). Let X and U solve
system (6.306)‚Äì(6.307), and let ÀúY be the solution of (SDS) given by the initial
conditions ÀúXN = X and ÀúUN = U. Let ÀúPk := ÀúX‚Ä†
k ÀúXk and ÀúRk := ÀúXk ÀúX‚Ä†
k be the
associated orthogonal projectors in (6.233). Then (6.306) implies that ÀúPN = P
and ÀúRN = R. For part (i) we observe that it is enough to check the two deÔ¨Åning
properties of a conjoined basis at k = N. The symmetry of ÀúXT
N ÀúUN follows from
the second equation in (6.307). Suppose now that ÀúXNv = 0 and ÀúUNv = 0 for
some v ‚ààRn. Then Pv = 0 and P ‚àóv = 0, by the Ô¨Årst inclusion in (6.305). From
[285, Lemmas 5.3(iv) and 5.4], we then obtain that v ‚ààIm P ‚àó. This means that
v ‚ààKer P ‚àó‚à©Im P ‚àó= {0}, i.e., v = 0. Thus, rank( ÀúXT
N,
ÀúUT
N ) = n and ÀúY is
a conjoined basis. For part (ii) we Ô¨Årst observe that G = w( ÀúY , Y ‚àó), because by the
deÔ¨Ånition of M(PS‚àó‚àû, P ‚àó, P) in (6.300), we have PG = G and PH = 0 and
ÀúXT
NU‚àó
N ‚àíÀúUT
NX‚àó
N
(6.307)
=
XT [X‚Ä†T G+U(P ‚àó+H)]‚àíUT XP ‚àó(6.306)
=
PG+UT XPH = G.
We deÔ¨Åne on [N, ‚àû)Z the symmetric matrix Q‚àó
k with the following property
Q‚àó
k := U‚àó
k (X‚àó
k)‚Ä† + [U‚àó
k (X‚àó
k)‚Ä†]T (I ‚àíR‚àó
k),
Q‚àó
kX‚àó
k = U‚àó
k (X‚àó
k)‚Ä†X‚àó
k = U‚àó
k P ‚àó;
(6.308)
see [257, Section 2.1.1]. By (6.308) and Theorem 6.66(i)‚Äì(ii) applied to Y ‚àó, we get
R‚àó
kQ‚àó
k ÀúXk ‚àíR‚àó
k ÀúUk = (X‚àó
k)‚Ä†T GT ,
BkR‚àó
k = Bk = R‚àó
k+1Bk,
R‚àó
kU‚àó
k = R‚àó
kU‚àó
k P ‚àó,

(6.309)
where the equalities in (6.309) are satisÔ¨Åed for k ‚àà[N, ‚àû)Z. It now follows that
X‚àó
k+1 = AkX‚àó
k + BkU‚àó
k = AkX‚àó
k + BkR‚àó
kU‚àó
k P ‚àó= (Ak + BkQ‚àó
k) X‚àó
k
(6.310)
on [N, ‚àû)Z. From (6.309) it follows that the function ÀúX solves on [N, ‚àû)Z the
nonhomogeneous Ô¨Årst-order linear difference equation
ÀúXk+1 = Ak ÀúXk + BkR‚àó
k ÀúUk = (Ak + BkQ‚àó
k) ÀúXk ‚àíBk(X‚àó
k)‚Ä†T GT .
(6.311)
Let k be the solution of the associated homogeneous equation
k+1 = (Ak + BkQ‚àó
k) k,
k ‚àà[N, ‚àû)Z,
N = X.
(6.312)
Note that k is correctly deÔ¨Åned in forward time on [N, ‚àû)Z and that the matrices
Ak + BkQ‚àó
k and hence k are not necessarily invertible. From (6.310) and the
fact NP ‚àó= X‚àó
N (see the Ô¨Årst condition in (6.307)), the uniqueness of solutions

6.3
Symplectic Systems Without Controllability
487
of (6.312) yields the equality X‚àó
k = kP ‚àóon [N, ‚àû)Z. Moreover,from the variation
of constants principle for equations (6.311) and (6.312), we get
ÀúXk = k (P ‚àíS‚àó
k GT ),
k ‚àà[N, ‚àû)Z.
(6.313)
Indeed, for k = N we have N (P ‚àíS‚àó
NGT ) = XP = X = ÀúXN, because S‚àó
N = 0,
and by (6.313), (6.312), P ‚àó(X‚àó
k+1)‚Ä† = (X‚àó
k+1)‚Ä†, and XP ‚àó= X‚àó
N from (6.307), we
get
ÀúXk+1 ‚àí(Ak + BkQ‚àó
k) ÀúXk = ‚àík+1 (S‚àó
k ) GT = ‚àík+1 (X‚àó
k+1)‚Ä†Bk(X‚àó
k)‚Ä†T GT
= ‚àík+1P ‚àó(X‚àó
k+1)‚Ä†Bk(X‚àó
k)‚Ä†T GT
= ‚àíX‚àó
k+1(X‚àó
k+1)‚Ä†Bk(X‚àó
k)‚Ä†T GT
= ‚àíR‚àó
k+1Bk(X‚àó
k)‚Ä†T GT (6.309)
=
‚àíBk(X‚àó
k)‚Ä†T GT .
Equality (6.313) and identities PP ‚àó= P ‚àó, GT P = GT , GT P ‚àó= P ‚àóG, PS‚àó‚àûG =
0, and P ‚àóS‚àó
k = S‚àó
k = S‚àó
k P ‚àó, S‚àó
k = S‚àó
k PS‚àó‚àû, from (6.305), (6.300), and (6.239)
imply that
ÀúXkP = ÀúXk,
ÀúXkP ‚àó= X‚àó
k
on [N, ‚àû)Z.
(6.314)
This shows that Im ÀúXT
k ‚äÜIm P and Im X‚àó
k ‚äÜIm ÀúXk on [N, ‚àû)Z. Next we will
prove that for all k ‚àà[N, ‚àû)Z, we have
Im (P ‚àíS‚àó
k GT ) = Im P = Im (P ‚àíS‚àó
k GT )T = Im (P ‚àíS‚àó
k GT )‚Ä†.
(6.315)
Fix an index k ‚àà[N, ‚àû)Z. Since Im S‚àó
k ‚äÜIm P ‚àó‚äÜIm P by Theorem 6.66(iv)
(with Y := Y ‚àó) and assumption (6.305), the equality S‚àó
k = PS‚àó
k holds. This in
turn implies that P ‚àíS‚àó
k GT = P ‚àíPS‚àó
k GT and hence Im (P ‚àíS‚àó
k GT ) ‚äÜIm P.
Next we consider a vector v ‚ààKer (P ‚àíS‚àó
k GT ), so that by GT = GT P we get
Pv = S‚àó
k GT v = S‚àó
k GT Pv. Then the vector w := Pv satisÔ¨Åes w = S‚àó
k GT w,
i.e., w ‚ààIm S‚àó
k ‚äÜIm PS‚àó‚àû. Thus, w = PS‚àó‚àûw, and consequently with the aid of
GT PS‚àó‚àû= 0, we obtain w = S‚àó
k GT w = S‚àó
k GT PS‚àó‚àûw = 0. This shows that Pv =
w = 0, so that v ‚ààKer P. Therefore, we proved that Ker (P ‚àíS‚àó
k GT ) ‚äÜKer P,
which is equivalent with Im P ‚äÜIm (P ‚àíS‚àó
k GT )T . Altogether, we showed that
Im (P ‚àíS‚àó
k GT ) ‚äÜIm P ‚äÜIm (P ‚àíS‚àó
k GT )T .
(6.316)
Since the dimensions of the subspaces on the left-hand and right-hand sides above
are equal (as rank A = rank AT ), it follows that in (6.316) we actually have
the equalities. This proves the Ô¨Årst two equalities in (6.315). Finally, the last
equality in (6.315) follows from Remark 1.60(i). We now consider the time-reversed

488
6
Miscellaneous Topics on Symplectic Systems
symplectic system (2.47) for ÀúY, i.e.,
ÀúXk = DT
k ÀúXk+1 ‚àíBT
k ÀúUk+1,
ÀúUk = ‚àíCT
k ÀúXk+1 + AT
k ÀúUk+1,
k ‚àà[0, ‚àû)Z.
Its Ô¨Årst equation in combination with Bk = R‚àó
k+1Bk and with (6.308) and (6.309) at
k + 1 implies that ÀúXk satisÔ¨Åes on [N, ‚àû)Z the nonhomogeneous Ô¨Årst-order linear
difference equation
ÀúXk = DT
k ÀúXk+1‚àíBT
k ÀúUk+1 = (DT
k ‚àíBT
k Q‚àó
k+1) ÀúXk+1+BT
k (X‚àó
k+1)‚Ä†T GT .
(6.317)
Fix an index M
‚àà[N, ‚àû)Z, and consider the solution k of the associated
homogeneous equation
k = (DT
k ‚àíBT
k Q‚àó
k+1) k+1,
k ‚àà[N, M ‚àí1]Z,
M = ÀúXM(P ‚àíS‚àó
MGT )‚Ä†.
(6.318)
From (6.318), (6.315), (6.313), and PP ‚àó= P ‚àó, we now obtain the equalities
k P = k,
k P ‚àó= X‚àó
k,
k ‚àà[N, M]Z,
(6.319)
since the sequences kP, k, kP ‚àó, and X‚àó
k satisfy the same difference equation
in (6.318) and
MP = ÀúXM(P ‚àíS‚àó
MGT )‚Ä†P
(6.315)
=
ÀúXM(P ‚àíS‚àó
MGT )‚Ä† = M,
MP ‚àó= ÀúXM(P ‚àíS‚àó
MGT )‚Ä†P ‚àó(6.313)
=
M (P ‚àíS‚àó
MGT ) (P ‚àíS‚àó
MGT )‚Ä†P ‚àó
(6.315)
=
MPP ‚àó= MP ‚àó= X‚àó
M.
We shall prove that
ÀúXk = k (P ‚àíS‚àó
k GT ),
k ‚àà[N, M]Z.
(6.320)
Indeed, the sequence Vk = k (P ‚àíS‚àó
k GT ) satisÔ¨Åes on [N, M ‚àí1]Z the equation
Vk ‚àí(DT
k ‚àíBT
k Q‚àó
k+1) Vk+1
(6.318)
=
k (S‚àó
k ) GT = k (S‚àó
k )T GT
= k P ‚àó(X‚àó
k)‚Ä†BT
k (X‚àó
k+1)‚Ä†T GT
(6.319)
=
R‚àó
kBT
k (X‚àó
k+1)‚Ä†T GT = BT
k (X‚àó
k+1)‚Ä†T GT ,
which is the same equation as (6.317), and
VM =M(P ‚àíS‚àó
M GT )
(6.318)
=
ÀúXM(P ‚àíS‚àó
M GT )‚Ä†(P ‚àíS‚àó
M GT )
(6.315)
=
ÀúXMP
(6.314)
=
ÀúXM.

6.3
Symplectic Systems Without Controllability
489
Therefore, the uniqueness of solutions of (6.317) in backward time yields that
equality (6.320) holds. Our next claim is to prove the equalities
Ker k = Ker P,
‚Ä†
k k = P,
Ker ÀúXk = Ker P,
k ‚àà[N, M]Z.
(6.321)
We start with the Ô¨Årst condition in (6.321). By (6.318), the kernel of k is
nonincreasing on [N, M]Z, which yields through (6.320) that
Ker k ‚äÜKer N = Ker ÀúXN = Ker X = Ker P,
k ‚àà[N, M]Z.
On the other hand, the Ô¨Årst equality in (6.319) implies that Ker P ‚äÜKer k on
[N, M]Z. Thus, Ker k = Ker P, which also yields the second condition in (6.321).
Finally, by Remark 1.62(iv) and S‚àó
k = PS‚àó
k , we have for k ‚àà[N, M]Z
Ker ÀúXk (6.320)
=
Ker k (P ‚àíS‚àó
k GT ) = Ker ‚Ä†
k k (P ‚àíS‚àó
k GT ) = Ker P (P ‚àíS‚àó
k GT )
= Ker (P ‚àíS‚àó
k GT ) = [ Im (P ‚àíS‚àó
k GT )T ]‚ä•(6.315)
=
(Im P )‚ä•= Ker P,
which completes the proof of (6.321). Since the index M ‚àà[N, ‚àû)Z was arbitrary,
it follows from the third condition in (6.321) that Ker ÀúXk = Ker P on [N, ‚àû)Z,
i.e., ÀúY has constant kernel on [N, ‚àû)Z and ÀúPk = ÀúP = P on [N, ‚àû)Z. In addition,
by the same calculations as in (6.298) and (6.299) with Y := ÀúY, we can show that
ÀúX‚Ä†
kR‚àó
k = (X‚àó
k)‚Ä† and ÀúXk ÀúX‚Ä†
k+1Bk = X‚àó
k(X‚àó
k+1)‚Ä†Bk ‚â•0 on [N, ‚àû)Z. This means that
the conjoined basis ÀúY has no forward focal points in (N, ‚àû) and the proof of part
(ii) is complete. For part (iii), we Ô¨Årst observe that Theorem 6.66(ii) and the same
calculation as in (6.304) imply ÀúSk = S‚àó
k on [N, ‚àû)Z. Therefore, P ÀúS‚àû= PS‚àó‚àûand
consequently, Im P ÀúS‚àû= Im PS‚àó‚àû‚äÜIm P ‚àó‚äÜIm P. Hence, Y ‚àóis contained in
ÀúY by DeÔ¨Ånition 6.82. Moreover, since we now have (G, H) ‚ààM(P ÀúS‚àû, P ‚àó, P), it
follows from (6.307) and Theorem 6.84 that Y ‚àóis contained in ÀúY through the pair
(G, H). The proof of Theorem 6.87 is complete.
‚äì‚äî
Remark 6.88 Note that in the discrete case we utilize both forward and backward
(time-reversed) systems (6.312) and (6.318) and that their solutions k and k
are in general singular. In the continuous case, both systems (6.312) and (6.318)
coincide, and the argument therein is more straightforward; see the proof of [285,
Theorem 5.6]. Moreover, the results in Theorem 6.87(ii) and Remark 6.83 show that
the relation being contained preserves not only the constant kernel on [N, ‚àû)Z of
the involved conjoined bases but also the property of having no forward focal points
in (N, ‚àû). This points to a fundamental difference in the discrete theory compared
with the continuous case.
In the next result, we provide a converse to Theorem 6.87. Namely, we prove that
the initial conditions of the conjoined bases ÀúY of (SDS), which contain a given Y ‚àó
on [N, ‚àû)Z, satisfy system (6.306)‚Äì(6.307).

490
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.89 Let ÀúY and Y ‚àóbe conjoined bases of (SDS) such that ÀúY has constant
kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû). If ÀúY contains Y ‚àóon
[N, ‚àû)Z with respect to the projector P ‚àóor equivalently through a pair (G, H) ‚àà
M(PS‚àó‚àû, P ‚àó, ÀúP ), then the matrices ÀúXN and ÀúUN solve system (6.306)‚Äì (6.307) with
P := ÀúP and R := ÀúRN.
Proof By Theorem 6.84 with Y := ÀúY, condition (6.301) holds with a (unique)
pair (G, H) ‚ààM(P ÀúS‚àû, P ‚àó, ÀúP ). Since by Proposition 6.86 the corresponding
S-matrices satisfy ÀúSk = S‚àó
k on [N, ‚àû)Z, it follows that P ÀúS‚àû= PS‚àó‚àû, and
consequently (G, H) ‚ààM(PS‚àó‚àû, P ‚àó, ÀúP ). Set X := ÀúXN and U := ÀúUN. Then the
above choice of P and R yields that (6.305) as well as (6.306)‚Äì(6.307) are satisÔ¨Åed.
‚äì‚äî
The results in Theorems 6.87 and 6.89 show that the construction of conjoined
bases ÀúY of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points
in (N, ‚àû), which contain a given conjoined basis Y ‚àówith the same properties, is
completely characterized by the solutions of the algebraic system (6.306)‚Äì(6.307).
We note that this system is the same as in the continuous case; see [285, Section 5].
There it is known that system (6.306)‚Äì(6.307) is solvable with a suitable choice of
the matrices G and H; see [285, Theorem 5.7 and formula (5.25)] for more details.
At the same time, Theorem 6.84 allows to construct all conjoined bases of (SDS)
with the same properties as above, which are contained in the given Y ‚àó. Combining
these two results with estimate (6.279) yields a construction of conjoined bases Y
of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû),
which have the rank of Xk equal to any value between n ‚àíd[N, ‚àû)Z and n.
This construction is based on the choice of the projectors P and P ‚àóin (6.297)
and (6.305).
Theorem 6.90 Assume that there exists a conjoined basis of (SDS) with constant
kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû). Then for any integer
value r between n ‚àíd[N, ‚àû)Z and n, there exists a conjoined basis Y of (SDS)
with constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) such that
rankXk = r on [N, ‚àû)Z.
Proof Let Y ‚àóbe the conjoined basis of (SDS) from the assumption of the theorem,
and let P ‚àó, R‚àó
k, and PS‚àó‚àûbe its associated projectors from (6.234), (6.233),
and (6.238). Let r be an integer between n ‚àíd[N, ‚àû)Z and n. If r ‚â§rankP ‚àó, then
we choose an orthogonal projector P ‚àó‚àósuch that rank P ‚àó‚àó= r and Im PS‚àó‚àû‚äÜ
Im P ‚àó‚àó‚äÜIm P ‚àóholds; compare with (6.297). It follows by Theorem 6.84 that for
this projector P ‚àó‚àó, there exists a conjoined basis Y ‚àó‚àóof (SDS) with constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû) such that Ker X‚àó‚àó
k = Ker P ‚àó‚àóon
[N, ‚àû)Z, i.e., rankX‚àó‚àó
k
= rankP ‚àó‚àó= r on [N, ‚àû)Z. Similarly, if r ‚â•rank P ‚àó, then
we choose orthogonal projectors P and R such that (6.305) holds and rankP = r.
Then the conjoined basis Y := ÀúY from Theorem 6.87 has the required properties
and rank Xk = rankP = r on [N, ‚àû)Z. The proof is complete.
‚äì‚äî

6.3
Symplectic Systems Without Controllability
491
In the next lemma, we derive a property of the Wronskian of two equivalent
conjoined bases of (SDS) with constant kernel on [N, ‚àû)Z.
Lemma 6.91 Let Y (1) and Y (2) be conjoined bases of (SDS) with constant kernel
on [N, ‚àû)Z, and let P (1), P (2) and PS(1)‚àû, PS(2)‚àûbe the corresponding orthogonal
projectors deÔ¨Åned in (6.234) and (6.238) through X(1)
k
and X(2)
k , respectively. If Y (1)
is equivalent with Y (2) on [N, ‚àû)Z, then
Im w(Y (1), Y (2)) ‚äÜIm (P (1) ‚àíPS(1)‚àû),
Im [w(Y (1), Y (2))]T ‚äÜIm (P (2) ‚àíPS(2)‚àû).

(6.322)
Proof Let Y (1) be equivalent with Y (2) on [N, ‚àû)Z. By Proposition 6.81 (with Y :=
Y (1) and ÀúY := Y (2)), there exist matrices G, H ‚ààRn√ón such that
X(2)
N = X(1)
N ,
U(2)
N ‚àíU(1)
N
= (X(1)
N )‚Ä†T G + U(1)
N H,
(6.323)
and Im G ‚äÜIm (P (1) ‚àíPS(1)‚àû) and Im H ‚äÜIm (I ‚àíP (1)). By (6.323) and the
symmetry of (X(1))T U(1), we obtain for the Wronskian N(1) := w(Y (1), Y (2)) at
k = N
N(1) = (X(1)
N )T (U(2)
N ‚àíU(1)
N ) = (X(1)
N )T (X(1)
N )‚Ä†T G + (X(1)
N )T U(1)
N H.
(6.324)
From the equalities (X(1)
N )T (X(1)
N )‚Ä†T = P (1) and X(1)
N P (1) = X(1)
N , we obtain
(X(1)
N )T (X(1)
N )‚Ä†T G = P (1)G = G and
(X(1)
N )T U(1)
N H = (U(1)
N )T X(1)
N H = (U(1)
N )T X(1)
N P (1)H = 0.
Therefore, (6.324) gives N(1) = G and so Im N(1) = Im G ‚äÜIm (P (1) ‚àí
PS(1)‚àû). The second inclusion in (6.322) follows from the fact that ‚àí[N(1)]T is
the Wronskian of the solutions Y (2) and Y (1).
‚äì‚äî
In the next two results, we provide additional information about the relation
being contained, which will be utilized in the construction of dominant solutions
of (SDS) at ‚àûin Sect. 6.3.7. First we show that the relation being contained for
conjoined bases of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal
points in (N, ‚àû) is invariant under suitable change of the interval [N, ‚àû)Z. Namely,
the point N can always be moved forward and under some additional conditions
also backward. We recall from Sect. 6.3.1 that the order of abnormality d[k, ‚àû)Z
of (SDS) is nondecreasing in k on [0, ‚àû)Z.
Proposition 6.92 Let Y and Y ‚àóbe two conjoined bases of (SDS) with constant
kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû). Then the following
hold.

492
6
Miscellaneous Topics on Symplectic Systems
(i) If Y contains Y ‚àóon the interval [N, ‚àû)Z, then Y contains Y ‚àóalso on the
interval [L, ‚àû)Z for all L ‚àà[N, ‚àû)Z.
(ii) Assume that d[N, ‚àû)Z = d‚àû. If Y contains Y ‚àóon the interval [L, ‚àû)Z for
some index L ‚àà[N, ‚àû)Z, then Y contains Y ‚àóalso on the interval [N, ‚àû)Z,
and hence on [K, ‚àû)Z for every K ‚àà[N, ‚àû)Z.
Proof Fix L ‚àà[N, ‚àû)Z. We denote by Sk, S‚àó
k , resp., S(L)
k
, S‚àó(L)
k
, the S-matrices
corresponding to Y and Y ‚àóon the interval [N, ‚àû)Z, resp., on the interval [L, ‚àû)Z.
Then S(L)
k
= Sk ‚àíSL and S‚àó(L)
k
= S‚àó
k ‚àíS‚àó
L on [L, ‚àû)Z. Let P and P ‚àóbe the
projectors in (6.234) deÔ¨Åned by the functions Xk and X‚àó
k. Moreover, let PS‚àû, PS‚àó‚àû
and PS(L)‚àû, PS‚àó(L)‚àûbe the projectors associated with the matrices Sk, S‚àó
k and S(L)
k
,
S‚àó(L)
k
through (6.238). The inequalities 0 ‚â§S(L)
k
‚â§Sk and 0 ‚â§S‚àó(L)
k
‚â§S‚àó
k for
k ‚â•L or the inclusions in (6.239) then imply
Im PS(L)‚àû‚äÜIm PS‚àû,
Im PS‚àó(L)‚àû‚äÜIm PS‚àó‚àû.
(6.325)
For part (i) we suppose that Y contains Y ‚àóon [N, ‚àû)Z, that is, the inclusions
in (6.297) hold and Y ‚àóis equivalent with YP ‚àóon [N, ‚àû)Z by DeÔ¨Ånition 6.82.
Then Im PS(L)‚àû‚äÜIm P ‚àó‚äÜIm P as well, by the Ô¨Årst inclusion in (6.325), and Y ‚àó
is equivalent with YP ‚àóon [L, ‚àû)Z. Therefore, Y contains Y ‚àóalso on [L, ‚àû)Z, by
DeÔ¨Ånition 6.82. For the proof of part (ii), we assume that d[N, ‚àû)Z = d‚àû. Then
d[N, ‚àû)Z = d[L, ‚àû)Z and by (6.276) and (6.325),
PS(L)‚àû= PS‚àû,
PS‚àó(L)‚àû= PS‚àó‚àû.
(6.326)
Now suppose that Y contains Y ‚àóon [L, ‚àû)Z. Moreover, let Y ‚àó‚àóbe a conjoined
basis of (SDS) with constant kernel on [N, ‚àû)Z such that Y contains Y ‚àó‚àóon
[N, ‚àû)Z with respect to the projector P ‚àó. Such a conjoined basis always exists, by
Remark 6.85. According to part (i) of this theorem, Y contains Y ‚àó‚àóalso on [L, ‚àû)Z
with respect to P ‚àó, and hence, Y ‚àóand Y ‚àó‚àóare equivalent on [L, ‚àû)Z. This means
that X‚àó
k = X‚àó‚àó
k
on [L, ‚àû)Z. We will show that the assumption d[N, ‚àû)Z = d‚àû
allows to extend the latter equality to the whole interval [N, ‚àû)Z. For this we deÔ¨Åne
N‚àó:= w(Y ‚àó, Y ‚àó‚àó). By Lemma 6.91 (with the initial index N := L, Y (1) := Y ‚àó,
Y (2) := Y ‚àó‚àó, P (1) := P ‚àó, PS(1)‚àû:= PS‚àó(L)‚àû, and the Wronskian w(Y ‚àó, Y ‚àó‚àó)), it
follows that Im N‚àó‚äÜIm (P ‚àó‚àíPS‚àó(L)‚àû). Consequently, Im N‚àó‚äÜIm (P ‚àó‚àíPS‚àó‚àû),
by the second equality in (6.326). On the other hand, the equality X‚àó
k = X‚àó‚àó
k
on
[L, ‚àû)Z implies that Im X‚àó
k = Im X‚àó‚àó
k
on [N, ‚àû)Z, by Theorem 6.77. Therefore,
the conjoined bases Y ‚àóand Y ‚àó‚àóare mutually representable on [N, ‚àû)Z in the sense
of Theorem 6.69. In particular, we have
Y ‚àó‚àó
k
= Y ‚àó
k M‚àó+ ¬ØY ‚àó
k N‚àó,
k ‚àà[N, ‚àû)Z,
(6.327)
where ¬ØY ‚àóis a conjoined basis from Proposition 6.67 associated with Y ‚àóand where
M‚àó‚ààRn√ón is a constant invertible matrix. By using (6.327), P ‚àóN‚àó= N‚àó, and

6.3
Symplectic Systems Without Controllability
493
Proposition 6.67(iv) (with Y := Y ‚àóand ¬ØY := ¬ØY ‚àó), we obtain on [N, ‚àû)Z
X‚àó‚àó
k = X‚àó
kM‚àó+ ¬ØX‚àó
kP ‚àóN‚àó= X‚àó
kM‚àó+ X‚àó
kS‚àó
k N‚àó= X‚àó
k(M‚àó+ S‚àó
k N‚àó).
(6.328)
But S‚àó
k N‚àó= S‚àó
k PS‚àó‚àûN‚àó= 0 on [N, ‚àû)Z. Therefore, (6.328) becomes X‚àó‚àó
k
=
X‚àó
kM‚àóon [N, ‚àû)Z. At the same time, we have X‚àó‚àó
k
= X‚àó
k on [L, ‚àû)Z, which gives
the formula X‚àó
kM‚àó= X‚àó
k on [L, ‚àû)Z. Multiplying the latter equation by (X‚àó
k)‚Ä† from
the left and using the identity (X‚àó
k)‚Ä†X‚àó= P ‚àóon [L, ‚àû)Z, we get P ‚àóM‚àó= P ‚àó.
Hence, X‚àó‚àó
k
= X‚àó
kM‚àó= X‚àó
kP ‚àóM‚àó= X‚àó
k on [N, ‚àû)Z. This shows that Y ‚àóand Y ‚àó‚àó
are equivalent on [N, ‚àû)Z, so that Y contains Y ‚àóalso on [N, ‚àû)Z with respect to
P ‚àó. Finally, the fact that Y contains Y ‚àóon [K, ‚àû)Z for every K ‚â•N now follows
from part (i) of this theorem.
‚äì‚äî
Proposition 6.93 Let Y ‚àóbe a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû) with d[N, ‚àû)Z = d‚àû. Then the
following statements hold for every index L ‚àà[N, ‚àû)Z.
(i) If Y ‚àó‚àóis a conjoined basis of (SDS) with constant kernel on [L, ‚àû)Z and no
forward focal points in (L, ‚àû) and it is contained in Y ‚àóon [L, ‚àû)Z, then Y ‚àó‚àó
has constant kernel also on [N, ‚àû)Z and no forward focal points in (N, ‚àû).
(ii) If Y is a conjoined basis of (SDS) with constant kernel on [L, ‚àû)Z and no
forward focal points in (L, ‚àû) and it contains Y ‚àóon [L, ‚àû)Z, then Y has
constant kernel also on [N, ‚àû)Z and no forward focal points in (N, ‚àû).
Proof (i) Fix L ‚àà[N, ‚àû)Z and let Y ‚àóand Y ‚àó‚àóbe as in the theorem. Furthermore,
let PS‚àó‚àûand PS‚àó(L)‚àûbe the orthogonal projectors in (6.238) associated with Y ‚àó
on the intervals [N, ‚àû)Z and [L, ‚àû)Z, respectively, and let P ‚àó‚àóbe the orthogonal
projector in (6.234) associated with Y ‚àó‚àóon [L, ‚àû)Z. Then X‚àó‚àó
k
= X‚àó
kP ‚àó‚àófor every
k ‚àà[L, ‚àû)Z. As in the proof of Proposition 6.92, the projector PS‚àó(L)‚àûis deÔ¨Åned
by the matrix S‚àó(L)
k
= S‚àó
k ‚àíS‚àó
L. Then 0 ‚â§S‚àó(L)
k
‚â§S‚àó
k for k ‚àà[L, ‚àû)Z and
hence Im PS‚àó(L)‚àû‚äÜIm PS‚àó‚àû. The assumption d[N, ‚àû)Z = d‚àûthen implies the
identity [N, ‚àû)Z = [L, ‚àû)Z by (6.225), and the equality PS‚àó(L)‚àû= PS‚àó‚àû
by rank PS‚àó(L)‚àû= n ‚àíd[L, ‚àû)Z = n ‚àíd[N, ‚àû)Z = rankPS‚àó‚àûin (6.276).
From the former equality, it then follows that X‚àó‚àó
k
= X‚àó
kP ‚àó‚àóholds for every
k ‚àà[N, ‚àû)Z, which shows that Y ‚àó‚àóis contained in Y ‚àóalso on [N, ‚àû)Z. Therefore,
Y ‚àó‚àóhas constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû), by
Remark 6.83 (with Y := Y ‚àóand Y ‚àó:= Y ‚àó‚àó). For the proof of part (ii), assume that
Y is a conjoined basis of (SDS) with constant kernel on [L, ‚àû)Z and no forward
focal points in (L, ‚àû) such that Y ‚àóis contained in Y on [L, ‚àû)Z. Using similar
arguments as above, it then follows that X‚àó
k = XkP ‚àófor every k ‚àà[N, ‚àû)Z, where
P ‚àóis the constant orthogonal projector in (6.234) which corresponds to Y ‚àó. Let S‚àó
k
and Q‚àó
k be the matrices in (6.236) and (6.286) associated with Y ‚àóon [N, ‚àû)Z, and
let W := w(Y, Y ‚àó) be the (constant) Wronskian of Y and Y ‚àó. Then
PS‚àó‚àûW = PS‚àó(L)‚àûW = 0,
PW = W,
P ‚àóW = W T P ‚àó,
(6.329)

494
6
Miscellaneous Topics on Symplectic Systems
where P is the constant orthogonal projectors in (6.234) which corresponds to Y on
[L, ‚àû)Z. Similarly as in the proof of Theorem 6.87, we then obtain that
Im (P ‚àíS‚àó
k W T ) = Im P = Im (P ‚àíS‚àó
k W T )T= Im (P ‚àíS‚àó
k W T )‚Ä†,
(6.330)
Xk+1 = (Ak + BkQ‚àó
k) Xk ‚àíBk(X‚àó
k)‚Ä† T W T ,
(6.331)
Xk = (DT
k ‚àíBT
k Q‚àó
k+1) Xk+1 + BT
k (X‚àó
k+1)‚Ä† T W T ,
(6.332)
for all k ‚àà[N, ‚àû)Z. Furthermore, let k and k be, respectively, the solutions of
the associated homogeneous equations
k+1 = (Ak + BkQ‚àó
k) k,
k ‚àà[N, ‚àû)Z,
N = XN,
(6.333)
k = (DT
k ‚àíBT
k Q‚àó
k+1) k+1,
k ‚àà[N, L ‚àí1]Z,
L = XL(P ‚àíS‚àó
LW T )‚Ä†.
(6.334)
The initial condition in (6.334) together with (6.330) and X‚Ä†
LXL = P imply
Ker L = Ker [X‚Ä†
LXL(P ‚àíS‚àó
LW T )‚Ä†] = Ker [P(P ‚àíS‚àó
LW T )‚Ä†] = Ker P.
(6.335)
The equalities XLP ‚àó= X‚àó
L and P ‚àó= PP ‚àóand the initial condition (6.334) give
X‚àó
L =XLPP ‚àó(6.330)
=
XL(P ‚àíS‚àó
LW T )‚Ä†(P ‚àíS‚àó
LW T ) P ‚àó(6.329)
=
L (PP ‚àó‚àíS‚àó
LP ‚àóW)
=L (P ‚àó‚àíS‚àó
LW) = L (P ‚àó‚àíS‚àó
LPS‚àó‚àûW) = L P ‚àó.
On the other hand, the matrix N satisÔ¨Åes NP ‚àó= XNP ‚àó= X‚àó
N by (6.333). By
using similar arguments as in the proof of Theorem 6.87, we get
Xk = k (P ‚àíS‚àó
k W T ),
k ‚àà[N, L]Z,
(6.336)
Xk = k (P ‚àíS‚àó
k W T ),
k ‚àà[N, ‚àû)Z,
(6.337)
Moreover, the kernel of k is nonincreasing on [N, L]Z, while the kernel of k is
nondecreasing on [N, ‚àû)Z by (6.333) and (6.334). In turn, by (6.335) we obtain the
identity kP = k for all k ‚àà[N, L]Z. Furthermore, equations (6.337) and (6.330)
yield the equality XkP = Xk on [N, ‚àû)Z. In particular, for k = N we have NP =
XNP = XN = N, which implies through (6.333) that kP = k for all k ‚àà
[N, ‚àû)Z. From (6.330), (6.336), and (6.337), it then follows that
k = kP = k (P ‚àíS‚àó
k W T ) (P ‚àíS‚àó
k W T )‚Ä† = k (P ‚àíS‚àó
k W T ) (P ‚àíS‚àó
k W T )‚Ä†
= kP = k

6.3
Symplectic Systems Without Controllability
495
for all k ‚àà[N, L]Z. Therefore, the matrix k = k has constant kernel on [N, L]Z
equal to Ker P by (6.335), and consequently Ker Xk = Ker P for all k ‚àà[N, L]Z
by (6.336) and (6.330). Thus, the conjoined basis Y has constant kernel on [N, ‚àû)Z.
Finally, according to (6.299) we have XkX‚Ä†
k+1Bk = X‚àó
k(X‚àó
k+1)‚Ä†Bk ‚â•0 for every
k ‚àà[N, ‚àû)Z. This means that Y has no forward focal points in (N, ‚àû) and the
proof is complete.
‚äì‚äî
6.3.4
Minimal Conjoined Bases
Inequality (6.279) motivates the following notions of a minimal conjoined basis
of (SDS) and a maximal conjoined basis of (SDS).
DeÔ¨Ånition 6.94 A conjoined basis Y of on [N, ‚àû)Z if rank Xk = n ‚àíd[N, ‚àû)Z
for all k ‚àà[N, ‚àû)Z. Similarly, Y is called a maximal conjoined basis on [N, ‚àû)Z
if rank Xk = n for all k ‚àà[N, ‚àû)Z.
Remark 6.95 The terminology in DeÔ¨Ånition 6.94 follows the estimate in (6.279),
as the minimal conjoined bases Y of (SDS) attain the smallest possible rank
of Xk on [N, ‚àû)Z, while the maximal conjoined bases Y of (SDS) attain the
largest possible rank of Xk on [N, ‚àû)Z (i.e., Xk is invertible on [N, ‚àû)Z in this
case). Sometimes we will call conjoined bases Y of (SDS), which satisfy the rank
condition n ‚àíd[N, ‚àû)Z < rankXk < n on [N, ‚àû)Z, as intermediate conjoined
bases on the interval [N, ‚àû)Z.
Minimal conjoined bases of (SDS) constitute an important tool in the investi-
gation of recessive solutions of (SDS). For example, given a conjoined basis Y
of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû)
with the projectors P and PS‚àûin (6.234) and (6.238), then any conjoined basis
Y ‚àóof (SDS) which is contained in Y with respect to the projector P ‚àó:= PS‚àûis
a minimal conjoined basis of (SDS) on [N, ‚àû)Z. In fact, the property P = PS‚àûcan
be shown to be characterizing the minimal conjoined bases Y of (SDS) on [N, ‚àû)Z.
Remark 6.96 If Y is a minimal conjoined basis of (SDS) on [N, ‚àû)Z, then
the abnormality of (SDS) on the interval [N, ‚àû)Z is necessarily maximal, i.e.,
d[N, ‚àû)Z = d‚àû. This follows from estimate (6.279) in Theorem 6.75, which yields
n ‚àíd[N, ‚àû)Z ‚â§rankXk = n ‚àíd‚àû,
k ‚àà[N, ‚àû)Z,
i.e.,
d[N, ‚àû)Z ‚â•d‚àû.
The opposite inequality d[N, ‚àû)Z ‚â§d‚àûholds by the deÔ¨Ånition of d‚àûin (6.224),
so that d[N, ‚àû)Z = d‚àûfollows.
In the next result, we show further basic properties of minimal conjoined bases
of (SDS) on [N, ‚àû)Z.

496
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.97 The following properties of minimal conjoined bases hold.
(i) Let Y be a minimal conjoined basis of (SDS) on [N, ‚àû)Z with the associated
projector P in (6.234). Then
0[N, ‚àû)Z = Im [UN(I ‚àíP)],
Im XN =

0[N, ‚àû)Z
‚ä•.
(6.338)
Consequently, the initial subspace Im XN is the same for all minimal conjoined
bases Y of (SDS) on [N, ‚àû)Z.
(ii) Let Y (1) and Y (2) be two minimal conjoined bases of (SDS) on [N, ‚àû)Z with
the corresponding projectors P (1) and P (2) deÔ¨Åned in (6.234) through X(1)
and X(2). Then Y (1) and Y (2) are equivalent on [N, ‚àû)Z if and only if
P (2) = P (1),
Y (2)
k
= Y (1)
k M,
k ‚àà[N, ‚àû)Z,
(6.339)
where M is a constant nonsingular matrix satisfying P (1)M = P (1).
(iii) Let Y (1) and Y (2) be two minimal conjoined bases of (SDS) on [N, ‚àû)Z with
their associated S-matrices S(1)
k
and S(2)
k
deÔ¨Åned in (6.236). If K ‚àà[N, ‚àû)Z
is an index such that
rankS(1)
k
= n ‚àíd[N, ‚àû)Z = rankS(2)
k
for all k ‚àà[K, ‚àû)Z,
then for k ‚àà[K, ‚àû)Z, we have the equality
(S(3‚àíi)
k
)‚Ä† = (L(i))T (S(i)
k )‚Ä†L(i) + (L(i))T N(i),
i ‚àà{1, 2},
(6.340)
where the matrices L(i) and N(i) are from Theorem 6.69 and its proof, resp.,
from Remarks 6.70 and 6.71.
Proof The Ô¨Årst conclusion in (6.338) follows from equation (6.278) in Theo-
rem 6.75, since for a minimal conjoined basis Y on [N, ‚àû)Z, we have P = PS‚àû.
The second conclusion in (6.338) then follows from Theorem 6.66(i), since
Im XN = Im RN =

Im [UN(I ‚àíP)]
‚ä•=

0[N, ‚àû)Z
‚ä•.
This shows that the set Im XN does not depend on a choice of Y. Part (ii) is
a consequence of Proposition 6.81 with M := I + H. More precisely, by using
Proposition 6.81, the equivalence of the minimal conjoined bases Y (1) and Y (2)
on [N, ‚àû)Z means that X(2)
N
= X(1)
N and Im (U(2)
N
‚àíU(1)
N ) ‚äÜ0[N, ‚àû)Z, while
from (6.338) we get 0[N, ‚àû)Z = Im [U(1)
N (I ‚àíP (1))]. Therefore, the projectors
P (1) and P (2) satisfy P (2) = P (1) and U(2)
N
‚àíU(1)
N
= U(1)
N H with a unique
matrix H satisfying P (1)H
= 0. Consequently, for M := I + H, we have
X(1)
N M = X(2)
N and U(1)
N M = U(2)
N . This completes the formulas in (6.339) by the
uniqueness of solutions of (SDS). In addition, the constant matrix M is nonsingular,

6.3
Symplectic Systems Without Controllability
497
because rankY (2)
k
= n. Finally, P (1)M = P (1) follows by the deÔ¨Ånition of M.
Conversely, if the minimal conjoined bases Y (1) and Y (2) satisfy the equalities
in (6.339) with a nonsingular matrix M such that P (1)M = P (1), then they
are equivalent on [N, ‚àû)Z. This follows from X(2)
N
= X(1)
N P (1)M = X(1)
N
and
U(2)
N
‚àíU(1)
N
= U(1)
N (M ‚àíI), where Im (M ‚àíI) ‚äÜIm (I ‚àíP (1)). For part (iii)
we Ô¨Årst note that equality (6.262) holds on [N, ‚àû)Z, since Im X(1)
N
= Im X(2)
N by
part (i) of this theorem. We multiply (6.262) by (L(1))T from the right and use the
symmetry of L(1)(L(1))‚Ä† = P (1) and the identity S(1)
k P (1) = S(1)
k
on [N, ‚àû)Z from
Theorem 6.66(iii) (with Y := Y (1)) to get
S(2)
k (L(1))T = (L(1) + S(1)
k N(1))‚Ä† S(1)
k
for all k ‚àà[N, ‚àû)Z.
(6.341)
Fix k ‚àà[K, ‚àû)Z, where the index K satisÔ¨Åes K ‚â•Nm by Remark 6.76. Then
by the same remark, we have Im S(1)
k
= Im P (1) and Im S(2)
k
= Im P (2), since
P (1) = PS(1)‚àûand P (2) = PS(2)‚àûas Y (1) and Y (2) are minimal conjoined bases on
[N, ‚àû)Z. Moreover, with the aid of Remark 1.60(i) and (6.250), we get
Im (L(1))T = Im (L(1))‚Ä† = Im L(2) = Im P (2),
(6.342)
and from (6.261) and Theorem 6.69(iv), we obtain
(L(1) + S(1)
k N(1)) (L(1) + S(1)
k N(1))‚Ä† = P (1),
P (1)N(1) = N(1).
(6.343)
By using Remark 1.62 for the pseudoinverse of a product of two matrices and the
equalities S(1)
k (S(1)
k )‚Ä† = PS(1)‚àû= P (1) and (S(2)
k )‚Ä†S(2)
k
= PS(2)‚àû= P (2), and
(L(1))‚Ä†L(1) = P (2) by (6.342), the Moore-Penrose pseudoinverse of the left-hand
side of (6.341) is equal to
[S(2)
k (L(1))T ]‚Ä† = [P (2)(L(1))T ]‚Ä† [S(2)
k P (2)]‚Ä† (6.342)
=
(L(1))‚Ä†T (S(2)
k )‚Ä†,
(6.344)
while the Moore-Penrose pseudoinverse of the right-hand side of (6.341) is
[(L(1) + S(1)
k N(1))‚Ä† S(1)
k ]‚Ä† = (P (1)S(1)
k )‚Ä† [(L(1) + S(1)
k N(1))‚Ä† P (1)]‚Ä†
(6.343)
=
(S(1)
k )‚Ä†(L(1) + S(1)
k N(1)) = (S(1)
k )‚Ä†L(1) + P (1)N(1)
= (S(1)
k )‚Ä†L(1) + N(1).
(6.345)
Using (6.344) and (6.345) in the pseudoinverse of both sides of (6.341) then yields
(L(1))‚Ä†T (S(2)
k )‚Ä† = (S(1)
k )‚Ä†L(1) + N(1).

498
6
Miscellaneous Topics on Symplectic Systems
If we now multiply the latter equation by (L(1))T from the left and use the symmetry
of (L(1))‚Ä†L(1) = P (2), then formula (6.340) with i = 1 follows. The same formula
with i = 2 is then obtained by interchanging the roles of Y (1) and Y (2).
‚äì‚äî
Remark 6.98 The result in Theorem 6.97 implies that that any two minimal
conjoined bases Y ‚àó(1) and Y ‚àó(2) on [N, ‚àû)Z are always mutually representable in
the sense of Theorem 6.69, since by (6.338) they satisfy
Im X‚àó(1)
N
= (0[N, ‚àû)Z)‚ä•= Im X‚àó(2)
N
,
where 0[N, ‚àû)Z is the subspace of the initial conditions uN of the elements
u ‚àà[N, ‚àû)Z. Hence, there exist matrices M‚àó(1), N‚àó(1), M‚àó(2), N‚àó(2) as in
Theorem 6.69 such that
X‚àó(2)
N
= X‚àó(1)
N
M‚àó(1),
U‚àó(2)
N
= U‚àó(1)
N
M‚àó(1) + (X‚àó(1)
N
)‚Ä†T N‚àó(1),
(6.346)
X‚àó(1)
N
= X‚àó(2)
N
M‚àó(2),
U‚àó(1)
N
= U‚àó(2)
N
M‚àó(2) + (X‚àó(2)
N
)‚Ä†T N‚àó(2).
(6.347)
Moreover,by taking the limit as k ‚Üí‚àûin (6.340), we obtain that the corresponding
matrices T ‚àó(1) and T ‚àó(2) in (6.237) associated with the minimal conjoined bases
Y ‚àó(1) and Y ‚àó(2) on [N, ‚àû)Z satisfy the equality
T ‚àó(2) = (M‚àó(1))T T ‚àó(1)M‚àó(1) + (M‚àó(1))T N‚àó(1).
(6.348)
In the next result, we study the situation when the minimal conjoined bases Y ‚àó(1)
and Y ‚àó(2) on [N, ‚àû)Z are constructed from already mutually representable con-
joined bases Y (1) and Y (2) with matrices M(1), N(1), M(2), N(2) from Theorem 6.69.
Proposition 6.99 Let Y (1) and Y (2) be conjoined bases of (SDS) with constant
kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû), and let P (1), P (2) and
PS(1)‚àû, PS(2)‚àûbe the corresponding orthogonal projectors in (6.234) and (6.238).
Moreover, let Y ‚àó(1) be a minimal conjoined basis of (SDS), which is contained
in Y (1) on [N, ‚àû)Z with respect to PS(1)‚àû, and similarly, let Y ‚àó(2) be a minimal
conjoined basis of (SDS) which is contained in Y (2) on [N, ‚àû)Z with respect to
PS(2)‚àû. Suppose that Y (1) and Y (2) are mutually representable on [N, ‚àû)Z through
the matrices M(1), N(1), M(2), N(2) as in Theorem 6.69. If M‚àó(1), N‚àó(1) and M‚àó(2),
N‚àó(2) are the matrices corresponding to Y ‚àó(1) and Y ‚àó(2) in (6.346)‚Äì (6.347), then
P (i)M(i)PS(3‚àíi)‚àû= PS(i)‚àûM‚àó(i),
N‚àó(i)(M‚àó(i))‚àí1 = PS(i)‚àûN(i)(M(i))‚àí1PS(i)‚àû,

i ‚àà{1, 2}.
(6.349)

6.3
Symplectic Systems Without Controllability
499
Proof With the notation from the proposition, we have by Theorem 6.84
X‚àó(1)
N
= X(1)
N PS(1)‚àû,
U‚àó(1)
N
= U(1)
N PS(1)‚àû+ (X(1)
N )‚Ä†T G1 + U(1)
N H1,
(6.350)
X‚àó(2)
N
= X(2)
N PS(2)‚àû,
U‚àó(2)
N
= U(2)
N PS(2)‚àû+ (X(2)
N )‚Ä†T G2 + U(2)
N H2
(6.351)
with (Gi, Hi) ‚ààM(PSi‚àû, PSi‚àû, Pi) for i = 1, 2. We consider the case i = 1,
since the other case i = 2 is obtained by interchanging the roles of the involved
conjoined bases. Inserting the Ô¨Årst equality from (6.350) and from (6.351) into
the Ô¨Årst formula in (6.346) gives X(2)
N PS(2)‚àû= X(1)
N PS(1)‚àûM‚àó(1), from which
we obtain by (6.255) that X(1)
N M(1)PS(2)‚àû= X(1)
N PS(1)‚àûM‚àó(1). Consequently,
multiplying the latter equality by (X(1)
N )‚Ä† from the left and using the identities
(X(1)
N )‚Ä†X(1)
N
= P (1), P (1) PS(1)‚àû= PS(1)‚àû, we get the Ô¨Årst formula in (6.349).
For the proof of the second formula in (6.349), we recall from Theorem 6.69 that
N(1) = w(Y (1), Y (2)) and N‚àó(1) = w(Y ‚àó(1), Y ‚àó(2)). In particular, at the point
k = N, we have
N(1) = (X(1)
N )T U(2)
N ‚àí(U(1)
N )T X(2)
N ,
N‚àó(1) = (X‚àó(1)
N
)T U‚àó(2)
N
‚àí(U‚àó(1)
N
)T X‚àó(2)
N
.

(6.352)
Combining (6.352) with (6.350)‚Äì(6.351) leads to the expression
N‚àó(1) = PS(1)‚àûN(1)PS(2)‚àû
+ PS(1)‚àû(X(1)
N )T (X(2)
N )‚Ä†T G2 + PS(1)‚àû(X(1)
N )T U(2)
N H2
‚àíGT
1 (X(1)
N )‚Ä†X(2)
N PS(2)‚àû‚àíH T
1 (U(1)
N )T X(2)
N PS(2)‚àû.
(6.353)
We now calculate the last four terms on the right-hand side of (6.353) separately. By
the Ô¨Årst equality in (6.256) and the already proven Ô¨Årst formula in (6.349), by the
symmetry of (X(2))T U(2) and the identities X(2)
N H2 = 0, (X(2)
N )T (X(2)
N )‚Ä†T = P (2),
and PS(2)‚àûG2 = 0, we have
PS(1)‚àû(X(1)
N )T (X(2)
N )‚Ä†T G2 = PS(1)‚àû(M(2))T (X(2)
N )T (X(2)
N )‚Ä†T G2
= PS(1)‚àû(M(2))T P (2)G2 = (M‚àó(2))T PS(2)‚àûG2 = 0,
PS(1)‚àû(X(1)
N )T U(2)
N H2 = PS(1)‚àû(M(2))T (X(2)
N )T U(2)
N H2
= PS(1)‚àû(M(2))T (U(2)
N )T X(2)
N H2 = 0.
Similarly, it follows by the Ô¨Årst equality in (6.255) and the Ô¨Årst part of (6.349), by
the symmetry of (X(1))T U(1) and the identities X(1)
N H1 = 0, (X(1)
N )‚Ä†X(1)
N
= P (1),

500
6
Miscellaneous Topics on Symplectic Systems
and PS(1)‚àûG1 = 0 that the last two terms in (6.353) are equal to zero. Therefore, we
have N‚àó(1) = PS(1)‚àûN(1)PS(2)‚àû. Now we use the properties M‚àó(2) = (M‚àó(1))‚àí1,
M(2) = (M(1))‚àí1, N(1)P (2) = N(1) from Theorem 6.69 to get
N‚àó(1)(M‚àó(1))‚àí1 = PS(1)‚àûN(1)PS(2)‚àûM‚àó(2) = PS(1)‚àûN(1)P (2)M(2)PS(1)‚àû
= PS(1)‚àûN(1)(M(1))‚àí1PS(1)‚àû.
This shows the second equality in (6.349).
‚äì‚äî
In the last result of this subsection, we prove a relationship between conjoined
bases ¬ØY (1) and ¬ØY (2) in Proposition 6.67 associated with two minimal conjoined bases
Y (1) and Y (2).
Lemma 6.100 Let Y (1) and Y (2) be minimal conjoined bases of (SDS) on the
interval [N, ‚àû)Z, and let ¬ØY (1) and ¬ØY (2) be their associated conjoined bases from
Proposition 6.67, respectively. Then there exists a constant invertible n √ó n matrix
G such that
¬ØX(2)
k
= ¬ØX(1)
k G,
k ‚àà[N, ‚àû)Z.
(6.354)
Proof Let P (1), R(1)
k
and P (2), R(2)
k
be the orthogonal projectors in (6.234), (6.233)
associated with X(1) and X(2), respectively. First we note that Im X(1)
N
= Im X(2)
N
by Remark 6.98, so that R(1)
N
= R(2)
N . Next we represent Y (1) in terms of Y (2) and
¬ØY (2), and both Y (2) and ¬ØY (2) in terms of Y (1) and ¬ØY (1). Thus, for i ‚àà{1, 2} and any
k ‚àà[N, ‚àû)Z, we have
Y (3‚àíi)
k
= Y (i)
k M(i) + ¬ØY (i)
k N(i),
¬ØY (2)
k
= Y (1)
k
¬ØM(1) + ¬ØY (1)
k
¬ØN(1),
(6.355)
where according to Theorem 6.69, the matrices M(1) and M(2) are invertible with
M(2) = (M(1))‚àí1, N(2) = ‚àí(N(1))T , and
¬ØM(1) = ‚àíw( ¬ØY (1), ¬ØY (2)) = ( ¬ØU(1)
N )T ¬ØX(2)
N ‚àí( ¬ØX(1)
N )T ¬ØU(2)
N ,
(6.356)
¬ØN(1) = w(Y (1), ¬ØY (2)) = (X(1)
N )T ¬ØU(2)
N ‚àí(U(1)
N )T ¬ØX(2)
N
= (M(2))T = (M(1))T ‚àí1.
(6.357)
Therefore, the matrix ¬ØN(1) is invertible. Since by Proposition 6.67(iv) at k = N,
we have P (1)( ¬ØU(1)
N )T = (X(1)
N )‚Ä† and P (1)( ¬ØX(1)
N )T = S(1)
N (X(1)
N )T = 0, as well as
R(2)
N ¬ØX(2)
N = X(2)
N (X(2)
N )‚Ä† ¬ØX(2)
N = 0, it follows from (6.356) that
P (1) ¬ØM(1) = (X(1)
N )‚Ä† ¬ØX(2)
N = (X(1)
N )‚Ä†R(1)
N ¬ØX(2)
N = (X(1)
N )‚Ä†R(2)
N ¬ØX(2)
N = 0.

6.3
Symplectic Systems Without Controllability
501
Therefore, again by (6.355) we get for k ‚àà[N, ‚àû)Z
¬ØX(2)
k
= X(1)
k
¬ØM(1) + ¬ØX(1)
k
¬ØN(1) = X(1)
k P (1) ¬ØM(1) + ¬ØX(1)
k
¬ØN(1) = ¬ØX(1)
k
¬ØN(1).
This shows that (6.354) holds with the matrix G :=
¬ØN(1), which is by equal-
ity (6.357) invertible.
‚äì‚äî
6.3.5
Asymptotics of S-Matrices
In this subsection we derive some additional properties of the S-matrices for
conjoined bases of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal
points in (N, ‚àû). First of all, by a diagonalization argument for symmetric matrices,
we can write the matrices Sk, S‚Ä†
k, T in (6.236) and (6.237) in Theorem 6.65 as
Sk = V
Wk
0
0 0n‚àírk

V T,
S‚Ä†
k = V
W ‚àí1
k
0
0
0n‚àírk

V T,
T = V
T‚ãÜ
0
0 0n‚àír‚àû

V T,
k ‚àà[N, ‚àû)Z.
‚é´
‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é≠
(6.358)
Here V is a constant orthogonal n√ón matrix, Wk are symmetric and positive deÔ¨Ånite
rk √ó rk matrices for k ‚àà[N, ‚àû)Z, and T‚ãÜ:= limk‚Üí‚àûW ‚àí1
k
is symmetric and
nonnegative deÔ¨Ånite r‚àû√ó r‚àûmatrix. Note that by (6.239) the matrix T satisÔ¨Åes
Im T ‚äÜIm PS‚àû. The dimension rk = rankSk = rank ÀÜX[N]
k
of the matrices Wk
in (6.358) is calculated in the second condition in (6.275). This implies that the
rank of Sk changes (i.e., increases in view of Theorem 6.66(iv)) independently of
the conjoined basis Y from which Sk is constructed; compare with Remark 6.76.
Moreover, by using the formulas in (6.358), we can write the orthogonal projectors
PSk for k ‚àà[N, ‚àû)Z and PS‚àûdeÔ¨Åned in (6.238) as
PSk = V
Irk
0
0 0n‚àírk

V T ,
PS‚àû= V
Ir‚àû
0
0 0n‚àír‚àû

V T .
(6.359)
In the following results, we analyze the properties of the S-matrices for such
conjoined bases of (SDS). In particular, we will see that the asymptotic properties
of the S-matrices are affected by the condition
d[N, ‚àû)Z = d[k, ‚àû)Z = d‚àû
for all k ‚àà[N, ‚àû)Z
(6.360)
on the maximal order of abnormality of (SDS) on [N, ‚àû)Z.

502
6
Miscellaneous Topics on Symplectic Systems
Proposition 6.101 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), let Sk be its corresponding S-
matrix in (6.236), and let T be the limit in (6.237). If (6.360) holds, then there exists
an index K ‚àà[N, ‚àû)Z such that
S‚Ä†
k ‚â•T ‚â•0,
rank(S‚Ä†
k ‚àíT ) = n ‚àíd‚àû,
k ‚àà[K, ‚àû)Z.
(6.361)
Proof Without loss of generality, we may assume that Y is a minimal conjoined
basis of (SDS) on [N, ‚àû)Z, since from a given Y we can always construct by
Theorem 6.84 a minimal conjoined basis, which is contained in Y and which by
Proposition 6.86 has the same matrix Sk (and hence T ). The assumptions then
imply that the associated projectors P and PS‚àûsatisfy rankPS‚àû= n ‚àíd‚àû
and PS‚àû= P. This implies that P = S‚Ä†
kSk = SkS‚Ä†
k for k ‚àà[Nm, ‚àû)Z, where
Nm ‚àà[N, ‚àû)Z is the index from Remark 6.76, i.e., Im Sk = Im P is maximal
on [Nm, ‚àû)Z. Consider the auxiliary conjoined basis ÀÜY := Y ‚àí¬ØYT , where ¬ØY
is the conjoined basis from Proposition 6.67. By Proposition 6.61, the conjoined
basis ÀÜY has constant kernel on [K, ‚àû)Z and no forward focal points in (K, ‚àû) for
some index K ‚àà[Nm, ‚àû)Z. By (6.239) the inclusion Im T ‚äÜIm P holds, i.e.,
T = PT . Moreover, Proposition 6.67(iv), X‚Ä†
kXk = P, and PSk = Sk imply that for
k ‚àà[K, ‚àû)Z we have
ÀÜXk = Xk ‚àí¬ØXkT = XkP ‚àí¬ØXkPT = Xk(P ‚àíSkT ),
(6.362)
P ‚àíSkT = P(P ‚àíSkT ) = X‚Ä†
kXk(P ‚àíSkT )
(6.362)
=
X‚Ä†
k ÀÜXk.
(6.363)
Similarly, from S‚Ä†
kSk = P = SkS‚Ä†
k, we obtain for k ‚àà[K, ‚àû)Z
S‚Ä†
k ‚àíT = S‚Ä†
k ‚àíPT = S‚Ä†
k(P ‚àíSkT ),
P ‚àíSkT = Sk(S‚Ä†
k ‚àíT ).
(6.364)
Equations (6.362)‚Äì(6.364) imply that
Ker (P ‚àíSkT ) = Ker ÀÜXk = Ker (S‚Ä†
k ‚àíT ),
k ‚àà[K, ‚àû)Z.
(6.365)
Let ÀÜP be the orthogonal projector deÔ¨Åned in (6.234) through the conjoined basis
ÀÜY on the interval [K, ‚àû)Z. We will show that Im ÀÜP = Im P, i.e., ÀÜP = P by
the uniqueness of orthogonal projectors. One inclusion follows from (6.365), since
Im ÀÜP = Im ÀÜXT
k = Im (S‚Ä†
k ‚àíT ) ‚äÜIm P for k ‚àà[K, ‚àû)Z. On the other hand, by
assumption (6.360) and inequality (6.279) in Theorem 6.75 (with Y := ÀÜY and with
N := K), we have
rank P = n ‚àíd[N, ‚àû)Z
(6.360)
=
n ‚àíd[K, ‚àû)Z
(6.279)
‚â§
rank ÀÜP .

6.3
Symplectic Systems Without Controllability
503
Thus, Im P = Im ÀÜP follows. Since ÀÜP is the orthogonal projector onto Im ÀÜXT
k on
[K, ‚àû)Z and since ÀÜP = P as we just proved, the second equality in (6.365) reads
as Ker (S‚Ä†
k ‚àíT ) = Ker P for all k ‚àà[K, ‚àû)Z. Consequently,
rank (S‚Ä†
k ‚àíT ) = rankP = n ‚àíd[K, ‚àû)Z = n ‚àíd‚àû,
k ‚àà[K, ‚àû)Z,
(6.366)
as we claim in (6.361). Finally, the Ô¨Årst condition in (6.361) follows from the fact
that T is the limit of S‚Ä†
k for k ‚Üí‚àûand from the monotonicity of S‚Ä†
k on [K, ‚àû)Z,
which is guaranteed on this interval by Theorem 6.65.
‚äì‚äî
Remark 6.102 The proof of Proposition 6.101 shows that the statement in (6.361)
can be extended to the whole interval [N, ‚àû)Z (instead only for large k), when the
maximal orthogonal projector PS‚àûis replaced by the projector PSk. Then
S‚Ä†
k ‚àíPSk T PSk ‚â•0,
Ker (S‚Ä†
k ‚àíPSk T PSk) = Ker PSk,
k ‚àà[N, ‚àû)Z.
(6.367)
The result in Proposition 6.101 implies that rank (S‚Ä†
k ‚àíT ) does not depend on
the choice of the matrices Sk and T , i.e., it does not depend on the choice of the
conjoined basis Y with constant kernel on [N, ‚àû)Z and no forward focal points
in (N, ‚àû). In fact, we prove for such a conjoined basis Y of (SDS) the following
equivalence.
Theorem 6.103 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), and let Sk, T , PS‚àûbe its
corresponding matrix in (6.236), (6.237), (6.238). Then the following two conditions
are equivalent:
rank (PS‚àû‚àíSkT ) = n ‚àíd[N, ‚àû)Z,
k ‚àà[N, ‚àû)Z,
(6.368)
rank(S‚Ä†
k ‚àíT ) = n ‚àíd[N, ‚àû)Z,
k ‚àà[M, ‚àû)Z for some M ‚àà[N, ‚àû)Z.
(6.369)
In this case we have the equalities
Im (PS‚àû‚àíSkT ) = Im PS‚àû= Im (PS‚àû‚àíSkT )T ,
k ‚àà[N, ‚àû)Z.
(6.370)
Proof In the proof of Proposition 6.101, we showed that (6.365) and (6.366) hold,
i.e., in the setting of the present theorem, we have
Ker (PS‚àû‚àíSkT ) = Ker PS‚àû= Ker (S‚Ä†
k ‚àíT ),
k ‚àà[K, ‚àû)Z,
(6.371)
where K ‚àà[Nm, ‚àû)Z and Nm is the index from Remark 6.76. That is, the space
Im Sk = Im PS‚àûis maximal on [K, ‚àû)Z. The implication (6.368) ‚áí(6.369)
(with M := K) then follows from (6.371) and from (6.276) in Theorem 6.75. We
will prove the converse implication. Assume (6.369) and set L := max{M, K}.

504
6
Miscellaneous Topics on Symplectic Systems
Then (6.371) yields
Im (PS‚àû‚àíSkT ) = Im PS‚àû,
k ‚àà[L, ‚àû)Z.
(6.372)
Multiplying (6.372) by T from the left and using that T PS‚àû= T , we get
Im (T ‚àíT SkT )] = Im [T (PS‚àû‚àíSkT )] = Im T,
k ‚àà[L, ‚àû)Z.
(6.373)
We will show that this equality is satisÔ¨Åed even for all k ‚àà[N, ‚àû)Z. The matrix
function T SkT is symmetric, nondecreasing, and nonnegative deÔ¨Ånite on [N, ‚àû)Z,
and S‚Ä†
k ‚ÜíT for k ‚Üí‚àûby (6.237). Therefore, the limit theorem for monotone
matrix-valued functions (Theorem 1.88 in Sect. 1.6.5) implies that T SkT ‚ÜíT for
k ‚Üí‚àû, where the convergence is monotone (nondecreasing). This implies that the
symmetric matrix function Gk := T ‚àíT SkT = T (PS‚àû‚àíSkT ) is nonincreasing
and nonnegative deÔ¨Ånite on [N, ‚àû)Z and hence,
Im [T (PS‚àû‚àíSkT )] = Im (T ‚àíT SkT )] ‚äÜIm T,
k ‚àà[N, ‚àû)Z.
(6.374)
The combination of (6.373) and (6.374) and the monotonicity of Gk implies that
Im [T (PS‚àû‚àíSkT )] = Im T,
k ‚àà[N, ‚àû)Z,
(6.375)
or equivalently by taking the orthogonal complements
Ker [T (PS‚àû‚àíSkT )] = Ker T,
k ‚àà[N, ‚àû)Z.
(6.376)
This then implies that
Ker (PS‚àû‚àíSkT ) ‚äÜKer T,
k ‚àà[N, ‚àû)Z,
(6.377)
since if (PS‚àû‚àíSkT ) d = 0 for some vector d ‚ààRn, then T (PS‚àû‚àíSkT ) d = 0
and so d ‚ààKer T by (6.376). Moreover, in this case PS‚àûd = (PS‚àû‚àíSkT ) d = 0
as well, so that we also have the inclusion
Ker (PS‚àû‚àíSkT ) ‚äÜKer PS‚àû,
k ‚àà[N, ‚àû)Z.
(6.378)
On the other hand, we know by T = T P ÀÜS‚àû(even without assumption (6.369)) that
Ker (PS‚àû‚àíSkT ) = Ker (PS‚àû‚àíSkT PS‚àû) ‚äáKer PS‚àû,
k ‚àà[N, ‚àû)Z.
(6.379)
Combining (6.378) and (6.379) yields that
Ker (PS‚àû‚àíSkT ) = Ker PS‚àû,
k ‚àà[N, ‚àû)Z,
(6.380)

6.3
Symplectic Systems Without Controllability
505
which implies through (6.276) the desired equality (6.368). Finally, the equality
Sk = PS‚àûSk implies the inclusion Im (PS‚àû‚àíSkT ) ‚äÜIm PS‚àûon [N, ‚àû)Z, while
under (6.368) or (6.369) the orthogonal complement of (6.380) yields the inclusion
Im PS‚àû‚äÜIm (PS‚àû‚àíSkT )T on [N, ‚àû)Z. Therefore, the rank condition (6.368)
guarantees the equality of the subspaces in (6.370). The proof is complete.
‚äì‚äî
Remark 6.104 We note that the inequality Gk = T ‚àíT SkT ‚â•0 for large k,
derived in the proof of Theorem 6.103 through the limit theorem for monotone
matrix-valued functions (Theorem 1.88), also follows from the properties of the
Moore-Penrose pseudoinverse. Indeed, since we know that 0 ‚â§T ‚â§S‚Ä†
k for large
k and S‚Ä†
k ‚ÜíT monotonically for k ‚Üí‚àû, it follows from Remark 1.60(vi) (with
A := T and B := S‚Ä†
k) that 0 ‚â§T SkT ‚â§T for large k, i.e., Gk ‚â•0 for large k.
In this context the value of the limit limk‚Üí‚àûT SkT = T is an additional property,
which is in fact not needed for the proof of Theorem 6.103.
The next result shows that condition (6.368) turns out to be a characterization of
the interval, where the abnormality of system (SDS) is maximal.
Proposition 6.105 Equality (6.368) holds for some (and hence for any) S-matrix
Sk associated with a conjoined basis Y of (SDS) with constant kernel on [N, ‚àû)Z
and no forward focal points in (N, ‚àû) if and only if condition (6.360) holds.
Proof We have already proven in Proposition 6.101 and Theorem 6.103 that
condition (6.360) implies (6.368) for any S-matrix Sk associated with a conjoined
basis Y of (SDS) on [N, ‚àû)Z. Thus, we suppose that (6.368) holds for some such
a matrix Sk, which corresponds to a conjoined basis Y of (SDS) with constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû). Without loss of generality (by
Theorem 6.84), we may assume that Y is a minimal conjoined basis on [N, ‚àû)Z.
Fix any index M ‚àà[N, ‚àû)Z. We will show that d[M, ‚àû)Z = d[N, ‚àû)Z by using
Theorem 6.75 and Remark 6.76. Consider the matrix function S(M)
k
deÔ¨Åned by
S(M)
k
:= Sk ‚àíSM for all k ‚àà[M, ‚àû)Z. Since the kernel of Y is constant on
[N, ‚àû)Z, and hence on [M, ‚àû)Z, it is straightforward to see from the deÔ¨Ånition
of Sk in (6.236) that S(M)
k
is the S-matrix corresponding to Y on [M, ‚àû)Z. The
following analysis shows that Im S(M)
k
= Im Sk for large k. By (6.239) and the
deÔ¨Ånition of PS‚àûin (6.238), we have Im SM ‚äÜIm PS‚àûand Im Sk = Im PS‚àû
for large k. This implies that SM = PS‚àûSM = SM PS‚àûand PS‚àûSk = Sk with
PS‚àû= S‚Ä†
kSk = SkS‚Ä†
k for large k. Consequently,
S(M)
k
= PS‚àûSk ‚àíSM S‚Ä†
kSk = (PS‚àû‚àíSMS‚Ä†
k ) Sk
for large k.
(6.381)
If we now let k ‚Üí‚àû, then PS‚àû‚àíSMS‚Ä†
k ‚ÜíPS‚àû‚àíSMT . Moreover, this
limiting matrix satisÔ¨Åes Im (PS‚àû‚àíSMT ) ‚äÜIm PS‚àûand also Im (PS‚àû‚àí
SMT )T ‚äÜIm PS‚àû, because Im T ‚äÜIm PS‚àû. By using assumption (6.368) and
Theorem 6.103, we get
Im (PS‚àû‚àíSMT ) = Im PS‚àû= Im (PS‚àû‚àíSMT )T .

506
6
Miscellaneous Topics on Symplectic Systems
In a similar way, we have Im (PS‚àû‚àíSMS‚Ä†
k) ‚äÜIm PS‚àû= Im (PS‚àû‚àíSMT )
and Im (PS‚àû‚àíSMS‚Ä†
k)T ‚äÜIm PS‚àû= Im (PS‚àû‚àíSMT )T for all k ‚àà[N, ‚àû)Z.
Therefore,
Im (PS‚àû‚àíSMS‚Ä†
k) = Im (PS‚àû‚àíSMS‚Ä†
k)T = Im PS‚àû
for large k,
(6.382)
and by Lemma 1.61 (with Aj := PS‚àû‚àíSMS‚Ä†
k and A := PS‚àû‚àíSMT ), we obtain
(PS‚àû‚àíSMS‚Ä†
k)‚Ä† ‚Üí(PS‚àû‚àíSMT )‚Ä†
for k ‚Üí‚àû.
(6.383)
By Remark 1.62 and the equalities in (6.381) and (6.382), we now calculate
(S(M)
k
)‚Ä† = (PS‚àûSk)‚Ä† [(PS‚àû‚àíSMS‚Ä†
k) PS‚àû]‚Ä† = S‚Ä†
k(PS‚àû‚àíSMS‚Ä†
k)‚Ä†
(6.384)
for large k. By using Remark 1.62, the matrix S(M)
k
(S(M)
k
)‚Ä† is the orthogonal
projector onto Im S(M)
k
. Thus, by (6.381) and (6.384), we have for large k that
S(M)
k
(S(M)
k
)‚Ä† = (PS‚àû‚àíSMS‚Ä†
k) SkS‚Ä†
k (PS‚àû‚àíSMS‚Ä†
k)‚Ä†
= (PS‚àû‚àíSMS‚Ä†
k) (PS‚àû‚àíSMS‚Ä†
k)‚Ä†,
(6.385)
where we used the identities SkS‚Ä†
k = PS‚àûand S‚Ä†
kPS‚àû= S‚Ä†
k for large k. But since
by Remark 1.62 the matrix in (6.385) is the orthogonal projector onto the subspace
Im (PS‚àû‚àíSMS‚Ä†
k), we conclude from (6.382) and (6.385) that S(M)
k
(S(M)
k
)‚Ä† = PS‚àû
for large t. This means that the two projectors onto Im S(M)
k
and Im Sk are the same
for large k (and they are equal to PS‚àû), so that Im S(M)
k
= Im Sk for large k. This
implies through Remark 6.76 that
n ‚àíd[M, ‚àû)Z = rankS(M)
k
= rankSk = n ‚àíd[N, ‚àû)Z
for large k.
This shows that d[N, ‚àû)Z = d[M, ‚àû)Z. Since the index M ‚àà[N, ‚àû)Z was
arbitrary, condition (6.368) holds, and the proof is complete.
‚äì‚äî
In our next result, we use the knowledge of the asymptotic properties of the
S-matrices and the T -matrices to provide a complete classiÔ¨Åcation of all minimal
conjoined bases of (SDS) on the given interval [N, ‚àû)Z, where the order of
abnormality d[N, ‚àû)Z is maximal. This turns out to be one of the crucial results
of this subsection, as it will be utilized in the characterization of the matrices T in
Theorem 6.107 below, as well as in the construction of minimal dominant solutions
of (SDS) at ‚àûin Sect. 6.3.7.
Below the letter N denotes also the matrix N from the representation formula in
Theorem 6.69. No confusion should arise regarding the notation for this matrix N
and for the index N used throughout this section for the interval [N, ‚àû)Z.

6.3
Symplectic Systems Without Controllability
507
Theorem 6.106 Let Y be a minimal conjoined basis of (SDS) on [N, ‚àû)Z with the
matrices PS‚àûand T deÔ¨Åned in (6.238) and (6.237), and assume d[N, ‚àû)Z = d‚àû.
Then a solution ÀúY of (SDS) is a minimal conjoined basis on [N, ‚àû)Z if and only if
there exist matrices M, N ‚ààRn√ón such that
ÀúXN = XN M,
ÀúUN = UN M + X‚Ä†T
N N,
(6.386)
M is nonsingular,
MT N = NT M,
Im N ‚äÜIm PS‚àû,
(6.387)
NM‚àí1 + T ‚â•0.
(6.388)
In this case the matrix ÀúT in (6.237), which corresponds to ÀúY, satisÔ¨Åes
rank ÀúT = rank (NM‚àí1 + T ).
(6.389)
Proof Let Y and the index N ‚àà[0, ‚àû)Z be as in the theorem. Then the orthogonal
projector P deÔ¨Åned in (6.234) satisÔ¨Åes P = PS‚àû. If ÀúY is also a minimal conjoined
basis on [N, ‚àû)Z, then Im ÀúXN
= Im XN by Theorem 6.97(i). Therefore, by
Theorem 6.69 (with Y (1) := Y and Y (2) := ÀúY), there exist matrices M, N ‚ààRn√ón
such that (6.386) and (6.387) hold. Moreover, let T and ÀúT be the T -matrices deÔ¨Åned
in (6.237) through the functions Sk and ÀúSk in (6.236), which are associated with
Y and ÀúY, respectively. By using formula (6.348) (with T ‚àó(1) := T , T ‚àó(2) := ÀúT ,
M‚àó(1) := M, and N‚àó(1) := N), we have
ÀúT = MT T M + MT N,
i.e.,
NM‚àí1 + T = MT ‚àí1 ÀúT M‚àí1 ‚â•0,
(6.390)
since ÀúT ‚â•0. This shows condition (6.388). Conversely, let ÀúY be a solution of (SDS)
satisfying (6.386)‚Äì(6.388). Then the conditions in (6.387) together with the identity
XT
N X‚Ä†T
N = P = PS‚àûand the fact that Y is a conjoined basis imply that ÀúY is also
a conjoined basis of (SDS). Let Sk be the S-matrix in (6.236) corresponding to Y on
[N, ‚àû)Z. By Remark 6.70(iii), condition (6.386) then yields
ÀúXk = Xk(PS‚àûM + SkN)
k ‚àà[N, ‚àû)Z.
(6.391)
We will show that ÀúY has constant kernel on [N, ‚àû)Z and that Ker ÀúXk = Ker PS‚àûM
on [N, ‚àû)Z. First we note that by the symmetry of MT N and PS‚àûN = N,
NM‚àí1PS‚àû= MT ‚àí1NT PS‚àû= MT ‚àí1NT = NM‚àí1
holds. Hence, by (6.391), we have for any k ‚àà[N, ‚àû)Z
ÀúXk = Xk(PS‚àûM + SkNM‚àí1M) = Xk(I + SkNM‚àí1) PS‚àûM.
(6.392)
Therefore, Ker PS‚àûM ‚äÜKer ÀúXk on [N, ‚àû)Z. Fix now k ‚àà[N, ‚àû)Z, v ‚ààKer ÀúXk,
and set w := PS‚àûMv. Then Xk(w + SkNM‚àí1w) = 0 by (6.392). Multiplying the

508
6
Miscellaneous Topics on Symplectic Systems
latter equality by X‚Ä†
k from the left and using the identities X‚Ä†
kXk = PS‚àû, PS‚àûSk =
Sk, and w = PS‚àûw, we get w = ‚àíSkNM‚àí1w. This implies by using (6.238)
and (6.239) that w ‚ààIm Sk = Im PSk and consequently,
wT S‚Ä†
kw = ‚àíwT S‚Ä†
k SkNM‚àí1w = ‚àíwT PSkNM‚àí1PSkw.
(6.393)
Equality (6.393) and condition (6.388) then yield wT S‚Ä†
kw ‚â§wT PSkT PSkw, or
equivalently wT (S‚Ä†
k ‚àíPSkT PSk) w ‚â§0. But S‚Ä†
k ‚àíPSkT PSk ‚â•0 according to
Remark 6.102 and thus, w ‚ààKer (S‚Ä†
k ‚àíPSkT PSk) = Ker PSk, by the second
formula in (6.367). Hence we obtain that w ‚ààKer PSk ‚à©Im PSk = {0}. This shows
that w = 0, and then v ‚ààKer PS‚àûM, i.e., Ker ÀúXk ‚äÜKer PS‚àûM. Finally, (6.386)
and the invertibility of M imply that rank ÀúXk = rank ÀúXN = rank XN = n ‚àíd‚àû
on [N, ‚àû)Z. This shows that ÀúY is a minimal conjoined basis of (SDS) on [N, ‚àû)Z.
The proof is complete.
‚äì‚äî
In the last result of this subsection, we present a criterion for the classiÔ¨Åcation
of all T -matrices, which correspond to (minimal) conjoined bases of (SDS) on
an interval [N, ‚àû)Z with the maximal order of abnormality.
Theorem 6.107 Assume that system (SDS) is nonoscillatory. Then D ‚ààRn√ón
is a T -matrix of some minimal conjoined basis Y of (SDS) on [N, ‚àû)Z with
d[N, ‚àû)Z = d‚àûif and only if
D is symmetric,
D ‚â•0,
rankD ‚â§n ‚àíd‚àû.
(6.394)
Proof Let D be a T -matrix associated with a minimal conjoined basis Y a given
interval [N, ‚àû)Z ‚äÜ[0, ‚àû)Z. Let Sk and T be deÔ¨Åned in (6.236) and (6.237), so
that D = T . By Remark 6.96 we have d[N, ‚àû)Z = d‚àû. From Theorem 6.65
and (6.239), we obtain that D is symmetric, nonnegative deÔ¨Ånite and Im D ‚äÜ
Im PS‚àûwith PS‚àûdeÔ¨Åned in (6.238). But since rank PS‚àû= n ‚àíd[N, ‚àû)Z =
n‚àíd‚àûby (6.276), the condition rankD ‚â§n‚àíd‚àûfollows. Conversely, assume that
D ‚ààRn√ón satisÔ¨Åes (6.394). From the third condition in (6.394), we have that there
exists an orthogonal projector Q such that Im D ‚äÜIm Q and rank Q = n ‚àíd‚àû.
Furthermore, the nonoscillation of (SDS) and Theorem 6.90 (with r := n ‚àíd‚àû)
imply that there exists a minimal conjoined basis Y of (SDS) on an interval
[N, ‚àû)Z ‚äÜ[0, ‚àû)Z. Let Sk, PS‚àû, and T be the matrices associated with Y
in (6.236), (6.238), and (6.237). Since d[N, ‚àû)Z = d‚àû, we have rank PS‚àû=
n ‚àíd‚àû= rankQ, and hence there exists an invertible matrix E satisfying
Im EPS‚àû= Im Q. The matrix E can be obtained, e.g., from the diagonalization
of PS‚àûand Q or from Theorem 1.91 in Sect. 1.6.6 (with P‚àó:= 0). In particular,
we then have Im E‚àí1Q = Im PS‚àû, i.e., PS‚àûE‚àí1Q = E‚àí1Q. DeÔ¨Åne now the
matrices M, N ‚ààRn√ón by
M := ET ,
N := E‚àí1D ‚àíT ET .
(6.395)

6.3
Symplectic Systems Without Controllability
509
We show that these matrices satisfy conditions (6.387) and (6.388) in Theo-
rem 6.106. The matrix M is invertible by its deÔ¨Ånition. The symmetry of D and
T implies that MT N = D ‚àíET ET is also symmetric. Moreover, the equalities
QD = D, PS‚àûE‚àí1Q = E‚àí1Q, and PS‚àûT = T yield
PS‚àûN = PS‚àûE‚àí1QD ‚àíT ET = E‚àí1QD ‚àíT ET = E‚àí1D ‚àíT ET = N.
This means that Im N ‚äÜIm PS‚àû. Finally, the inequality D ‚â•0 implies (6.388),
since NM‚àí1 + T = (E‚àí1D ‚àíT ET ) ET ‚àí1 + T = E‚àí1D ET ‚àí1 ‚â•0. Therefore,
we proved that for a given D satisfying (6.394) and for any minimal conjoined basis
Y of (SDS) on [N, ‚àû)Z, the matrices M and N in (6.395) satisfy the conditions
in (6.387) and (6.388). Consider now the solution ÀúY of (SDS) given by the initial
conditions (6.386). By Theorem 6.106 it follows that ÀúY is a minimal conjoined
basis on [N, ‚àû)Z. Moreover, if ÀúT is the matrix in (6.237) associated with ÀúY,
then by (6.390) satisÔ¨Åes ÀúT = MT T M + MT N. By using (6.395) we then obtain
that ÀúT = D. Therefore, the matrix D is a T -matrix associated with the minimal
conjoined basis ÀúY of (SDS) on [N, ‚àû)Z.
‚äì‚äî
Remark 6.108 We note that with the aid of Proposition 6.86 and Theorem 6.90, the
statement in Theorem 6.107 extends directly to any conjoined basis Y of (SDS) with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû).
6.3.6
Recessive Solutions at InÔ¨Ånity
In this subsection we present the concept of a recessive solution of (SDS) at ‚àû. It is
deÔ¨Åned by the property T = 0 in (6.237). It is a generalization of the corresponding
notion in DeÔ¨Ånition 2.63 in Sect. 2.5.
DeÔ¨Ånition 6.109 (Recessive Solution at ‚àû) A conjoined basis ÀÜY of (SDS) is said
to be a recessive solution of (SDS) at ‚àûif there exists N ‚àà[0, ‚àû)Z such that ÀÜY has
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) and satisfying
lim
k‚Üí‚àû
ÀÜS‚Ä†
k = 0,
ÀÜSk :=
k‚àí1

j=N
ÀÜX‚Ä†
j+1 Bj ÀÜXT ‚Ä†
j
,
(6.396)
i.e., the matrix ÀÜT in (6.237) associated with ÀÜY satisÔ¨Åes ÀÜT = 0.
If ÀÜY is a recessive solution of (SDS) at ‚àûsuch that ÀÜY has constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû), then ÀÜXk satisÔ¨Åes the rank
condition in (6.279). Therefore, we introduce the following terminology regarding
the classiÔ¨Åcation of recessive solutions of (SDS) according to their rank.
Remark 6.110 Let ÀÜY be a recessive solution of (SDS) at ‚àû, and let r be its rank on
[N, ‚àû)Z. If r = n ‚àíd‚àû, then ÀÜY is called a minimal recessive solution of (SDS)

510
6
Miscellaneous Topics on Symplectic Systems
at ‚àû, while if r = n, then ÀÜY is called a maximal recessive solution of (SDS)
at ‚àû. This terminology corresponds to the two extreme cases in (6.279) or in
Theorem 6.115 below. We will use the special notation ÀÜY min = Y [‚àû] and ÀÜY max for
the recessive solutions of (SDS) at ‚àû, which are minimal and maximal, respectively,
according to the above deÔ¨Ånition. If n ‚àíd‚àû< r < n, then the recessive solution ÀÜY
will be called intermediate (of the rank r). We note that in the eventually controllable
case, we have d‚àû= 0 (see Remark 6.58), so that the minimal and maximal recessive
solutions of (SDS) at ‚àûcoincide. Therefore, in this case all recessive solutions ÀÜY
of (SDS) at ‚àûhave eventually ÀÜXk invertible, as it is known in Sect. 2.5, or in [16,
Section 3.11] and [81].
The next statement shows that moving the initial point of the interval [N, ‚àû)Z,
with respect to which a recessive solution at ‚àûis considered, to the right does not
change the property of being a recessive solution of (SDS).
Proposition 6.111 Let ÀÜY be a recessive solution of (SDS) at ‚àûon [N, ‚àû)Z. Then
condition (6.360) holds and ÀÜY is a recessive solution of (SDS) at ‚àûon [M, ‚àû)Z
for every M ‚àà[N, ‚àû)Z.
Proof Fix an index M ‚àà[N, ‚àû)Z. Let ÀÜSk deÔ¨Åned in (6.396) be the S-matrix
corresponding to ÀÜY on [N, ‚àû)Z with ÀÜT := limk‚Üí‚àûÀÜS‚Ä†
k = 0. Since by (6.276) we
have rank P ÀÜS‚àû= n‚àíd[N, ‚àû)Z, it follows that condition (6.368) in Theorem 6.103
holds with T := ÀÜT = 0. This yields via Proposition 6.105 that (6.360) is satisÔ¨Åed,
in particular d[N, ‚àû)Z = d[M, ‚àû)Z. Now we consider the S-matrix
ÀÜS(M)
k
:=
k‚àí1

j=M
ÀÜX‚Ä†
j+1Bj ÀÜX‚Ä†T
j
= ÀÜSk ‚àíÀÜSM,
k ‚àà[M, ‚àû)Z,
(6.397)
for ÀÜY on [M, ‚àû)Z. Then as in the proof of Proposition 6.105, we have on [M, ‚àû)Z
( ÀÜS(M)
k
)‚Ä† = (P ÀÜS‚àûÀÜSk)‚Ä† [(P ÀÜS‚àû‚àíÀÜSM ÀÜS‚Ä†
k) P ÀÜS‚àû]‚Ä† = ÀÜS‚Ä†
k (P ÀÜS‚àû‚àíÀÜSM ÀÜS‚Ä†
k )‚Ä†.
(6.398)
Upon taking the limit as k ‚Üí‚àûin (6.398), we obtain that
ÀÜT (M) := lim
k‚Üí‚àû( ÀÜS(M)
k
)‚Ä† = ÀÜT (P ÀÜS‚àû‚àíÀÜSM ÀÜT )‚Ä†.
(6.399)
Note that the limit of (P ÀÜS‚àû‚àíÀÜSM ÀÜS‚Ä†
k)‚Ä† for k ‚Üí‚àûindeed exists and is equal
to (P ÀÜS‚àû‚àíÀÜSM ÀÜT )‚Ä†, because the matrices P ÀÜS‚àû‚àíÀÜSM ÀÜS‚Ä†
k have constant rank for
large k, which is equal to the rank of the limit matrix P ÀÜS‚àû‚àíÀÜSM ÀÜT ; see (6.368)
and Lemma 1.61 or Remark 1.60(v). Since ÀÜT = 0, equality (6.399) yields that
ÀÜT (M) = 0 and ÀÜY is a recessive solution of (SDS) at ‚àûon the interval [M, ‚àû)Z, by
DeÔ¨Ånition 6.109.
‚äì‚äî

6.3
Symplectic Systems Without Controllability
511
The following result shows that the relation ‚Äúbeing contained‚Äù preserves the
property of being a recessive solution of (SDS).
Proposition 6.112 Let ÀÜY be a recessive solution of (SDS) at ‚àûon [N, ‚àû)Z. Then
every conjoined basis of (SDS) with constant kernel on [N, ‚àû)Z and no forward
focal points in (N, ‚àû), which is either contained in ÀÜY on [N, ‚àû)Z or which contains
ÀÜY on [N, ‚àû)Z, is also a recessive solution of (SDS) at ‚àûon the interval [N, ‚àû)Z.
Proof The result follows from Proposition 6.86 and from the proof of Theo-
rem 6.87(iii), since the relation ‚Äúbeing contained‚Äù for conjoined bases of (SDS) with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) preserves the
corresponding S-matrices. SpeciÔ¨Åcally, the conjoined bases Y ‚àówhich are contained
in ÀÜY on [N, ‚àû)Z satisfy S‚àó
k = ÀÜSk on [N, ‚àû)Z by Proposition 6.86, while the
conjoined bases ÀúY of (SDS) which contain ÀÜY on [N, ‚àû)Z satisfy ÀúSk = ÀÜSk on
[N, ‚àû)Z by the proof of Theorem 6.87(iii).
‚äì‚äî
In the next results, we discuss the existence and uniqueness of the minimal
recessive solution at ‚àû(Theorem 6.113) and the relationship of the nonoscillation
of (SDS) at ‚àûwith the existence of the recessive solutions at ‚àû(Theorem 6.115).
The Ô¨Årst statement is a direct generalization of the results in Theorem 2.66 and
Remark 2.69, as we now drop the eventual controllability assumption.
Theorem 6.113 System (SDS) is nonoscillatory at ‚àûif and only if there exists
a minimal recessive solution of (SDS) at ‚àû. In this case the minimal recessive
solution is unique up to a right nonsingular multiple, that is, if ÀÜY is a minimal
recessive solution of (SDS) at ‚àû, then a solution ÀÜY (0) of (SDS) is a minimal
recessive solution at ‚àûif and only if ÀÜY (0)
k
= ÀÜYk ÀÜM on [0, ‚àû)Z for some invertible
matrix ÀÜM.
Proof Assume that system (SDS) is nonoscillatory. Let Y be any Ô¨Åxed conjoined
basis of (SDS). Then there exists a sufÔ¨Åciently large N ‚àà[0, ‚àû)Z such that Y has
constant kernel on [N, ‚àû)Z and no forward focal points in (0, ‚àû) and such that
condition (6.360) holds. Let Sk and T be given in (6.236) and (6.237), and let P
and PS‚àûbe the associated orthogonal projectors in (6.234) and (6.238). Without
loss of generality (by Theorem 6.84 and Remark 6.85 with P ‚àó:= PS‚àû), we may
assume that Y is a minimal conjoined basis on [N, ‚àû)Z, i.e., PS‚àû= P. Consider
the conjoined basis ÀÜY := Y ‚àí¬ØY T , where ¬ØY is given in Proposition 6.67. Then
ÀÜXk = Xk (P ‚àíSkT ),
Ker ÀÜXk = Ker (P ‚àíSkT ) = Ker P,
k ‚àà[N, ‚àû)Z,
(6.400)
where the second condition above follows from (6.370). Thus, ÀÜY has constant kernel
on [N, ‚àû)Z and the corresponding orthogonal projector ÀÜP satisÔ¨Åes ÀÜP = P. We shall
prove that ÀÜY has no forward focal points in (N, ‚àû). From (6.400) and (6.236), it

512
6
Miscellaneous Topics on Symplectic Systems
follows that
ÀÜX‚Ä†
k = (P ‚àíSkT )‚Ä†X‚Ä†
k,
k ‚àà[N, ‚àû)Z,
(6.401)
P ‚àíSkT = P ‚àíSk+1T + (Sk) T
= (P ‚àíSk+1T ) + X‚Ä†
k+1BkX‚Ä†T
k T,
k ‚àà[N, ‚àû)Z.
(6.402)
Note that by (6.370) we have (P ‚àíSk+1T ) (P ‚àíSk+1T )‚Ä† = P. Therefore,
by (6.400)‚Äì(6.402) we obtain
ÀÜXk ÀÜX‚Ä†
k+1Bk = Xk (P ‚àíSkT ) (P ‚àíSk+1T )‚Ä†X‚Ä†
k+1Bk
= Xk [ (P ‚àíSk+1T ) + X‚Ä†
k+1BkX‚Ä†T
k T ] (P ‚àíSk+1T )‚Ä†X‚Ä†
k+1Bk
= XkPX‚Ä†
k+1Bk + XkX‚Ä†
k+1BkX‚Ä†T
k T [k+1]X‚Ä†
k+1Bk
= XkX‚Ä†
k+1Bk + BT
k X‚Ä†T
k+1T [k+1]X‚Ä†
k+1Bk,
(6.403)
where, similarly to (6.399), the matrix T [k+1] = T (P ‚àíSk+1T )‚Ä† and where
X‚Ä†T
k+1P = X‚Ä†T
k+1, as the projector P = PS‚àûis constant on [N, ‚àû)Z. Each term
in the sum in (6.403) is nonnegative deÔ¨Ånite, because Y has no forward focal points
in (0, ‚àû) and T [k+1] ‚â•0. This shows that ÀÜXk ÀÜX‚Ä†
k+1Bk ‚â•0 on [N, ‚àû)Z, i.e., ÀÜY
has no forward focal points in (0, ‚àû) as well. Thus, ÀÜY is a minimal conjoined basis
on [N, ‚àû)Z. Let ÀÜSk be its corresponding S-matrix. From Proposition 6.97(iii) (with
Y (1) := Y, Y (2) := ÀÜY, L(1) := X‚Ä†
N ÀÜXN = X‚Ä†
NXN = P, and N(1) := ‚àíT ), we obtain
the equality ÀÜS‚Ä†
k = S‚Ä†
k ‚àíT for all k large enough. Formula (6.237) now implies
that ÀÜS‚Ä†
k ‚Üí0 for k ‚Üí‚àû, i.e., ÀÜY is a minimal recessive solution of (SDS) at ‚àû.
Conversely, the existence of a minimal recessive solution of (SDS) at ‚àû, which is
a nonoscillatory conjoined basis of (SDS) at ‚àû, implies the nonoscillation of (SDS)
at ‚àûby Proposition 6.61.
Now we prove the uniqueness. Let ÀÜY be a minimal recessive solution of (SDS)
at ‚àûwith respect to the interval [N, ‚àû)Z and let ÀÜY (0) be a minimal recessive
solution of (SDS) at ‚àûwith respect to [N0, ‚àû)Z. Without loss of generality, we
may assume that N0 = N, since shifting the initial point to the right preserves
the property of being a recessive solution of (SDS) at ‚àû, by Proposition 6.111.
Let ÀÜP and ÀÜP (0) be the corresponding orthogonal projectors in (6.233) deÔ¨Åned
through ÀÜX and ÀÜX[0]. By Proposition 6.97(i), we know that Im ÀÜXN = Im ÀÜX[0]
N ,
which in turn implies by Theorem 6.69 (with Y (1) := ÀÜY (0) and Y (2) := ÀÜY) that
ÀÜY (0)
k
= ÀÜYk ÀÜM + ¬ØY (2)
k
ÀÜN on [N, ‚àû)Z, where the matrix ÀÜM is constant and nonsingular
and the matrix ÀÜN satisÔ¨Åes Im ÀÜN ‚äÜIm ÀÜP . If the matrices ÀÜSk, ÀÜT and ÀÜS(0), ÀÜT (0) are now
deÔ¨Åned in (6.236), (6.237) through ÀÜX and ÀÜX(0), respectively, then formula (6.340)
in Proposition 6.97(iii) with i = 2 has the form
( ÀÜS(0)
k )‚Ä† = ÀÜLT ÀÜS‚Ä†
k ÀÜL + ÀÜLT ÀÜN
for large k,
(6.404)

6.3
Symplectic Systems Without Controllability
513
with ÀÜL = ÀÜP ÀÜM by Remark 6.70(ii). Upon taking the limit as k ‚Üí‚àûin (6.404)
and using that ÀÜY and ÀÜY (0) are recessive solutions of (SDS) at ‚àû, i.e., ÀÜT = 0 =
ÀÜT (0), we obtain from (6.404) the equality 0 = ÀÜT (0) = ÀÜLT ÀÜT ÀÜL + ÀÜLT ÀÜN = ÀÜLT ÀÜN.
Multiplying this equation by ÀÜL‚Ä†T from the left and using ÀÜL‚Ä†T ÀÜLT = ÀÜP and ÀÜP ÀÜN =
ÀÜN (see Remark 6.70(ii) again), we obtain ÀÜN = 0. This means that ÀÜY (0)
k
= ÀÜYk ÀÜM
on [N, ‚àû)Z with
ÀÜM invertible. Conversely, if ÀÜY is a minimal recessive solution
of (SDS) at ‚àûwith respect to the interval [N, ‚àû)Z, then the solution ÀÜY (0)
k
:= ÀÜYk ÀÜM
with an invertible ÀÜM obviously has constant kernel on [N, ‚àû)Z. Moreover, ÀÜY (0)
has also no forward focal points in (N, ‚àû), because the matrix ÀÜP =
ÀÜX‚Ä†
k ÀÜXk =
ÀÜX‚Ä†
k+1 ÀÜXk+1 is constant on [N, ‚àû)Z, the matrix
( ÀÜX(0)
k+1)‚Ä† = ( ÀÜXk+1 ÀÜM)‚Ä† = ( ÀÜX‚Ä†
k+1 ÀÜXk+1 ÀÜM)‚Ä†( ÀÜXk+1 ÀÜM ÀÜM‚àí1)‚Ä† = ( ÀÜP ÀÜM)‚Ä† ÀÜX‚Ä†
k+1
(6.405)
by Remark 1.62, and for k ‚àà[N, ‚àû)Z
ÀÜX(0)
k ( ÀÜX(0)
k+1)‚Ä†Bk
(6.405)
=
ÀÜXk ÀÜM( ÀÜP ÀÜM)‚Ä† ÀÜX‚Ä†
k+1Bk = ÀÜXk ÀÜP ÀÜM( ÀÜP ÀÜM)‚Ä† ÀÜP ÀÜX‚Ä†
k+1Bk
= ÀÜXk( ÀÜP ÀÜM) ( ÀÜP ÀÜM)‚Ä†( ÀÜP ÀÜM) ÀÜM‚àí1 ÀÜX‚Ä†
k+1Bk
= ÀÜXk( ÀÜP ÀÜM) ÀÜM‚àí1 ÀÜX‚Ä†
k+1Bk = ÀÜXk ÀÜX‚Ä†
k+1Bk ‚â•0.
Hence, ÀÜY (0) is a minimal conjoined basis of (SDS) on [N, ‚àû)Z. Moreover, we have
the equality Im ÀÜX(0)
N
= Im ÀÜXN and, by Theorem 6.69 (with the same notation as
above), ÀÜN := N(2) = 0. As in (6.404) we then obtain ( ÀÜS(0)
k )‚Ä† = ÀÜLT ÀÜS‚Ä†
k ÀÜL for large k.
Since ÀÜS‚Ä†
k ‚ÜíÀÜT = 0 as k ‚Üí‚àû, it follows that ( ÀÜS(0)
k )‚Ä† ‚ÜíÀÜT (0) = 0 for k ‚Üí‚àûas
well. Therefore, ÀÜY (0) is a minimal recessive solution of (SDS) at ‚àûand the proof is
complete.
‚äì‚äî
In Proposition 6.151 and Theorem 6.153 in Sect. 6.3.10 below, we present further
characterizations of the minimal recessive solution of (SDS) at ‚àû.
Remark 6.114 In the last part of Theorem 6.113, we showed that if ÀÜY is a recessive
solution of (SDS) at ‚àûon [N, ‚àû)Z, then ÀÜY ÀÜM is also a recessive solution of (SDS)
at ‚àûon [N, ‚àû)Z with the same rank for any constant invertible matrix
ÀÜM.
This statement extends [16, Theorem 3.43(i)] to the general concept of recessive
solutions at ‚àûin this paper.
We note that Theorem 6.115 below is an extension of the existence part of
Theorem 6.113. In particular, we shall see that the existence of the minimal recessive
solution of (SDS) from Theorem 6.113 is used in the proof of the implication (i) ‚áí
(ii) in Theorem 6.115. Also, the uniqueness (or some other classiÔ¨Åcation) of the
recessive solutions of (SDS) at ‚àûwith rank r > n‚àíd‚àûis not guaranteed; see, e.g.,
Remark 6.116.

514
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.115 The following statements are equivalent.
(i) System (SDS) is nonoscillatory at ‚àû.
(ii) There exists a recessive solution ÀÜY of (SDS) at ‚àû.
(iii) For any integer value r between n‚àíd‚àûand n, there exists a recessive solution
ÀÜY of (SDS) at ‚àûwith the rank of ÀÜXk equal to r for large k.
Proof (i)‚áí(ii) This follows from Theorem 6.113, as the nonoscillation of (SDS) at
‚àûimplies the existence of the minimal recessive solution of (SDS) at ‚àû.
(ii)‚áí(iii) Let ÀÜY be a recessive solution of (SDS) at ‚àû. By DeÔ¨Ånition 6.109,
there exists an index N ‚àà[0, ‚àû)Z such that ÀÜY is a conjoined basis of (SDS) with
constant kernel on [N, ‚àû)Z, no forward focal points in (N, ‚àû), and its associated
matrix ÀÜSk satisÔ¨Åes (6.396). From Proposition 6.111 we then have d[N, ‚àû)Z = d‚àû.
By Theorem 6.90, for any integer r between n ‚àíd‚àû= n ‚àíd[N, ‚àû)Z and n, there
exists a conjoined basis Y of (SDS) with constant kernel on [N, ‚àû)Z and no forward
focal points in (N, ‚àû) such that rank Xk = r on [N, ‚àû)Z. Moreover, the conjoined
basis Y is in Theorem 6.90 constructed in such a way that it is either contained in
or contains the recessive solution ÀÜY at ‚àûon [N, ‚àû)Z. In turn, Proposition 6.112
yields that Y is also a recessive solution of (SDS) at ‚àûon [N, ‚àû)Z.
(iii)‚áí(i) The choice r := n ‚àíd‚àûyields the existence of the minimal recessive
solution of (SDS) at ‚àû, which through Theorem 6.113 implies the nonoscillation of
system (SDS) at ‚àû. Alternatively, we may use Proposition 6.61 to obtain the same
conclusion.
‚äì‚äî
In Theorem 6.113 we guarantee the uniqueness of the minimal recessive solution
of (SDS) at ‚àû. In the following remark, we show that the minimal recessive solution
is the only one for which this property is satisÔ¨Åed. This remark also shows that
nonunique recessive solutions of (SDS) will always exist as long as d‚àû‚â•1.
Remark 6.116 Let ÀÜY be a recessive solution of (SDS) at ‚àûwith rank r satisfying
n ‚àíd‚àû‚â§r ‚â§n. Then ÀÜY is unique up to a right nonsingular multiple if and only
if r = n ‚àíd‚àû, that is, ÀÜY is a minimal recessive solution of (SDS). We shall prove
by construction the implication ‚Äú‚áí‚Äù, as the opposite direction ‚Äú‚áê‚Äù is contained
in Theorem 6.113. Let ÀÜY be a recessive solution of (SDS) at ‚àûon the interval
[N, ‚àû)Z with the projectors ÀÜP and P ÀÜS‚àûin (6.234) and (6.238). Set ÀÜM := 2I ‚àíÀÜP
and ÀÜN := ÀÜP ‚àíP ÀÜS‚àû, and deÔ¨Åne the solution ÀÜY (0)
k
:= ÀÜYk ÀÜM + ¬ØYk ÀÜN on [0, ‚àû)Z, where
¬ØY is the conjoined basis of (SDS) associated with ÀÜY in Proposition 6.67. Since the
equality ÀÜP P ÀÜS‚àû= P ÀÜS‚àûholds by (6.239), it follows that ÀÜMT ÀÜN = ÀÜP ‚àíP ÀÜS‚àûis
symmetric. The invertibility of ÀÜM then yields that ÀÜY (0) is a conjoined basis of (SDS)
and ÀÜN = w( ÀÜY, ÀÜY (0)). Moreover, ¬ØXk ÀÜP = ÀÜXk ÀÜSk by Proposition 6.67(iv) and ÀÜSk(I ‚àí
P ÀÜS‚àû) = 0 by the Ô¨Årst inclusion in (6.239) for all k ‚àà[N, ‚àû)Z. Then
X[0]
k
= ÀÜXk ÀÜM + ¬ØXk ÀÜN = ÀÜXk ÀÜP (2I ‚àíÀÜP) + ¬ØXk ÀÜP (I ‚àíP ÀÜS‚àû)
= ÀÜXk ÀÜP + ÀÜXk ÀÜSk(I ‚àíP ÀÜS‚àû) = ÀÜXk

6.3
Symplectic Systems Without Controllability
515
on [N, ‚àû)Z, which shows that the solutions ÀÜY and ÀÜY (0) are equivalent on [N, ‚àû)Z.
Therefore, ÀÜY (0) is also a recessive solution of (SDS) at ‚àûon [N, ‚àû)Z with the
same rank r. Now if ÀÜY is unique up to a right nonsingular multiple, then necessarily
ÀÜN = 0. This means that ÀÜP = P ÀÜS‚àû, r = n ‚àíd‚àû, and ÀÜY is a minimal recessive
solution of (SDS) at ‚àû.
Remark 6.117 In the literature one can Ô¨Ånd an alternative deÔ¨Ånition of a recessive
solution of (SDS) in terms of a limit. More precisely, by [16, pg. 115] a conjoined
basis ÀÜY of (SDS) is a recessive solution at ‚àûif for any other linearly independent
conjoined basis Y of (SDS) with Xk invertible for large k we have
lim
k‚Üí‚àûX‚àí1
k
ÀÜXk = 0.
(6.406)
This property is known as the limit characterization (or the limit deÔ¨Ånition) of the
recessive solution at ‚àûand it goes back to the historical papers by Olver and
Sookne [238] and Gautschi [151]. When system (SDS) is eventually controllable,
then both concepts in DeÔ¨Ånition 2.63 and (6.406) coincide; see Theorem 2.67 and
[51, pg. 965] or [104, pg. 211]. However, the above deÔ¨Ånition (6.406) allows also
an eventually noncontrollable system (SDS) and its recessive solutions ÀÜY at ‚àûwith
noninvertible ÀÜXk on [N, ‚àû)Z; see [16, pp. 116‚Äì117]. This poses a question on the
exact relationship between the limit property in (6.406) and the summation property
in (6.396) of a recessive solution of (SDS) at ‚àû. This question is also related with
the so-called dominant solutions of (SDS) at ‚àûconsidered in Sect. 2.5 or [16,
Theorems 3.35 and 3.43]. In the next subsections, we will complete this study and
show that the recessive solutions of (SDS) at ‚àûin DeÔ¨Ånition 6.109 are indeed the
smallest solutions at ‚àûwhen they are compared with suitable dominant solutions
of (SDS) at ‚àû.
As a Ô¨Ånal result in this subsection, we present a block diagonal construction of
certain recessive solutions at ‚àûof symplectic systems arising in higher dimension.
With system (SDS) we consider another symplectic system (with possibly different
dimension n ‚ààN)
yk+1 = Skyk,
k ‚àà[0, ‚àû)Z,
yk =
xk
uk

,
Sk =
Ak Bk
Ck Dk

,
(SDS)
where Sk and J :=
 0 I
‚àíI 0

are 2n √ó 2n matrices such that Sk is real symplectic,
i.e., ST
k J Sk = J for all k ‚àà[0, ‚àû)Z. DeÔ¨Åne the block diagonal matrices
A‚àó
k :=
Ak 0
0 Ak

, B‚àó
k :=
Bk 0
0 Bk

, C‚àó
k :=
Ck 0
0 Ck

, D‚àó
k :=
Dk 0
0 Dk


516
6
Miscellaneous Topics on Symplectic Systems
in the dimension n‚àó:= n + n, and consider the ‚Äúaugmented‚Äù system
y‚àó
k = S‚àó
k y‚àó
k ,
k ‚àà[0, ‚àû)Z,
y‚àó
k =
x‚àó
k
u‚àó
k

,
S‚àó
k =
A‚àó
k B‚àó
k
C‚àó
k D‚àó
k

,
(SDS‚àó)
where the dimension of S‚àó
k and J ‚àó:=
 0 I
‚àíI 0

is 2n‚àó. Since the matrices Sk and Sk
are symplectic, it follows that (S‚àó
k )TJ ‚àóS‚àó
k = J ‚àó, i.e., the augmented system (SDS‚àó)
is a symplectic system. The following result shows that certain recessive solutions
of system (SDS‚àó) at ‚àûcan be constructed from the recessive solutions of (SDS)
and (SDS) at ‚àû.
Theorem 6.118 Assume that the systems (SDS) and (SDS) are nonoscillatory at
‚àû. Let ÀÜY and ÀÜY be recessive solutions of (SDS) and (SDS) at ‚àûwith rank equal
to r and r, respectively. Then the sequence ÀÜY ‚àó
k deÔ¨Åned by
ÀÜX‚àó
k :=
 ÀÜXk 0
0
ÀÜXk

,
ÀÜU‚àó
k :=
 ÀÜUk 0
0
ÀÜUk

,
k ‚àà[0, ‚àû)Z,
(6.407)
is a recessive solution of system (SDS‚àó) at ‚àûwith rank equal to r‚àó:= r + r.
Moreover, the recessive solution ÀÜY ‚àóat ‚àûconstructed in (6.407) is minimal
(maximal) if and only if the recessive solutions ÀÜY and ÀÜY at ‚àûare minimal
(maximal).
Proof By Proposition 6.111, there exists a common index N ‚àà[0, ‚àû)Z such that ÀÜY
and ÀÜY are recessive solutions of (SDS) and (SDS) at ‚àûwith respect to the interval
[N, ‚àû)Z. It is obvious that the rank of ÀÜY ‚àóis equal to r‚àó= r + r and that the orders
of abnormality d[N, ‚àû)Z, d[N, ‚àû)Z, d‚àó[N, ‚àû)Z of systems (SDS), (SDS), (SDS‚àó)
satisfy d‚àó[N, ‚àû)Z = d[N, ‚àû)Z +d[N, ‚àû)Z. This follows from the structure of the
coefÔ¨Åcients in Sk. Moreover, if ÀÜMk, Mk, M‚àó
k and ÀÜTk, T k, T ‚àó
k and ÀÜPk, P k, P ‚àó
k and ÀÜSk,
ÀÜSk, ÀÜS‚àó
k are the matrices in (4.1) and (4.2) and (6.396) associated with the conjoined
bases ÀÜY, ÀÜY, ÀÜY ‚àó, then
M‚àó
k = diag{ ÀÜMk, Mk},
T ‚àó
k = diag{ ÀÜTk, T k},
P ‚àó
k = diag{ ÀÜPk, P k},
ÀÜS‚àó
k = diag{ ÀÜSk, ÀÜSk},
( ÀÜS‚àó
k )‚Ä† = diag{ ÀÜS‚Ä†
k, ÀÜS
‚Ä†
k}.
This means that ÀÜY ‚àóhas constant kernel on [N, ‚àû)Z, no forward focal points in
(N, ‚àû), and ( ÀÜS‚àó
k )‚Ä† ‚Üí0 as k ‚Üí‚àû. Therefore, ÀÜY ‚àóis a recessive solution of the
augmented system (SDS‚àó) at ‚àûaccording to DeÔ¨Ånition 6.109.
‚äì‚äî
We conclude this subsection with three examples, which illustrate the presented
theory of recessive solutions of (SDS) at ‚àû.
Example 6.119 Let n = 1 and consider a scalar system (SDS) with Sk ‚â°
 1 1
0 1

.
This system is nonoscillatory at ‚àû, because it corresponds to the nonoscillatory
second-order Sturm-Liouville difference equation 2yk = 0 on [0, ‚àû)Z, and

6.3
Symplectic Systems Without Controllability
517
d[0, ‚àû)Z = d‚àû= 0. Therefore, by Theorem 6.115 (or Theorem 6.113 or
Theorem 2.66), the conjoined basis ÀÜYk ‚â°
 1
0

of (SDS) is the (unique) recessive
solution of (SDS) at ‚àû. The second linearly independent solution ÀúYk =
 k
1

of (SDS) is not in this case a recessive solution of (SDS) at ‚àûaccording to
DeÔ¨Ånition 6.109.
Example 6.120 Consider system (SDS) with Sk ‚â°I2n. This system is nonoscil-
latory at ‚àû, its solutions are constant on [0, ‚àû)Z, and its order of abnormality is
d[0, ‚àû)Z = d‚àû= n. Every conjoined basis of (SDS) is then a (constant) recessive
solution at ‚àûon the interval [0, ‚àû)Z. The recessive solutions of (SDS) at ‚àûwith
a given rank r between 0 and n in Theorem 6.115 can be constructed by a suitable
choice of the orthogonal projector ÀÜP ‚ààRn√ón with rank ÀÜP = r. More precisely, the
solution ÀÜY with ÀÜX = ÀÜP and ÀÜU = I ‚àíÀÜP is a recessive solution of (SDS) at ‚àûwith
rank equal to rank ÀÜP . If ÀÜP = 0, then ÀÜY = ÀÜY min = Y [0] =
 0
I

is the (unique)
minimal recessive solution of (SDS) at ‚àû. In fact, it is this minimal recessive
solution at ‚àû, which is derived in [16, Example 3.39]. On the other hand, if ÀÜP = I,
then ÀÜY = ÀÜY max =
 I
0

is an example of a maximal recessive solution of (SDS) at
‚àû. Note that ÀÜY (0) =
 I
I

is also a maximal recessive solution of (SDS) at ‚àû, which
is not a constant multiple of the maximal recessive solution ÀÜY max =
 I
0

at ‚àû,
demonstrating the nonuniqueness of the recessive solutions at ‚àûwith rank r ‚â•1 in
Remark 6.116.
Finally, we illustrate the construction of recessive solutions of (SDS) at ‚àûby
using Theorem 6.118.
Example 6.121 Consider symplectic system (SDS) with the coefÔ¨Åcients Ak ‚â°I3 =
diag{1, 1, 1}, Bk ‚â°diag{1, 0, 0}, Ck ‚â°03 = diag{0, 0, 0}, and Dk ‚â°I3 =
diag{1, 1, 1} on [0, ‚àû)Z. This system corresponds to the partitioned system (SDS‚àó),
which arises from the symplectic systems in Example 6.119 and Example 6.120
(with dimension two). System (SDS) is nonoscillatory at ‚àûand d[0, ‚àû)Z =
d‚àû= 2. By Theorem 6.118, ÀÜY min = (diag{1, 0, 0}, diag{0, 1, 1})T with rank
r = n ‚àíd‚àû= 1 is the minimal recessive solution of (SDS) at ‚àû, while ÀÜY max =
(I3, 03)T with rank r = n = 3 is one of the maximal recessive solutions of (SDS)
at ‚àû. Note that for both recessive solutions at ‚àû, we have ÀÜSk = diag{k, 0, 0} on
[0, ‚àû)Z, so that ÀÜS‚Ä†
k = diag{1/k, 0, 0} ‚Üí0 for k ‚Üí‚àû, as required in (6.396).
6.3.7
Dominant Solutions at InÔ¨Ånity
In this subsection we develop the notion of a dominant solution of (SDS) at
‚àûwithout any eventual controllability assumption. As a main result, we prove
(Theorem 6.128) an analog of Proposition 6.115 for dominant solutions at ‚àû.
DeÔ¨Ånition 6.122 (Dominant Solution at ‚àû)
A conjoined basis Y of (SDS) is said
to be a dominant solution of (SDS) at ‚àûif there exists an index N ‚àà[0, ‚àû)Z with

518
6
Miscellaneous Topics on Symplectic Systems
d[N, ‚àû)Z = d‚àûsuch that Y has constant kernel on [N, ‚àû)Z and no forward focal
points in (N, ‚àû) and the corresponding matrix T deÔ¨Åned in (6.237) satisÔ¨Åes
rank T = n ‚àíd‚àû.
(6.408)
From Theorem 6.107 and Remark 6.108, it follows that the dominant solutions
of (SDS) at ‚àûare deÔ¨Åned by the maximal possible rank of the associated matrix
T , while the recessive solutions of (SDS) at ‚àûare deÔ¨Åned by the minimal rank
of T . In this respect the dominant solution of (SDS) at ‚àûcan also be called as
an antirecessive solution of (SDS) at ‚àû. This alternative terminology then complies
with the continuous time notions of principal and antiprincipal solutions at ‚àûof
linear Hamiltonian differential systems (1.103); see [285, DeÔ¨Ånition 7.1] and [286,
DeÔ¨Ånition 5.1]. We also note that with respect to (6.239) and (6.276) the matrix T
associated with a dominant solution Y of (SDS) at ‚àûhas the property
Im T = Im PS‚àû.
(6.409)
In the following we introduce the notation for dominant solutions at ‚àû, which
is analogous to the terminology minimal recessive solution ÀÜY min and maximal
recessive solution ÀÜY max of (SDS) at ‚àûused in Remark 6.110.
Remark 6.123 Let Y be a dominant solution of (SDS) at ‚àûwith r = rankXk on
[N, ‚àû)Z. If r = n ‚àíd‚àû, then Y is called a minimal dominant solution at ‚àû, while
if r = n, then Y is called a maximal dominant solution at ‚àû. This terminology
corresponds to the two extreme cases in formula (6.279). As before, we will use the
notation Y min and Y max for the minimal and maximal dominant solutions of (SDS)
at ‚àû, respectively. Moreover, if n ‚àíd‚àû< r < n, then the dominant solution Y at
‚àûis called intermediate.
When the system (SDS) is eventually controllable, then d‚àû= 0 and hence the
matrix T is positive deÔ¨Ånite. In this case DeÔ¨Ånition 6.122 reduces to DeÔ¨Ånition 2.63.
Our Ô¨Årst result shows that the dominant solutions of (SDS) at ‚àûcan be
characterized by the limit of Sk alone instead of the limit of S‚Ä†
k as k ‚Üí‚àû. In some
situations this condition may be easier to verify in comparison with DeÔ¨Ånition 6.122.
Theorem 6.124 Let Y be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), and assume that d[N, ‚àû)Z = d‚àû.
Let Sk and T be deÔ¨Åned in (6.236) and (6.237) through Y. Then the following
statements are equivalent.
(i) The conjoined basis Y is a dominant solution of (SDS) at ‚àû.
(ii) The limit of Sk exists as k ‚Üí‚àû.
(iii) The matrices Sk and T satisfy the condition
lim
k‚Üí‚àûSk = T ‚Ä†.
(6.410)

6.3
Symplectic Systems Without Controllability
519
Proof From (6.238) and (6.276) and from the assumption d[N, ‚àû)Z = d‚àû, we
know that the equalities rank S‚Ä†
k = rankSk = rank PS‚àû= n ‚àíd‚àûhold for large k.
And since rank T = n‚àíd‚àûis the deÔ¨Åning property for Y being a dominant solution
at ‚àû, it follows that rank S‚Ä†
k = n ‚àíd‚àû= rankT for large k. This is equivalent by
Remark 1.60(v) (with Aj := S‚Ä†
j and A := T ) with the existence of the limit of
(S‚Ä†
k)‚Ä† = Sk as k ‚Üí‚àû, i.e., with condition (6.410).
‚äì‚äî
Next we discuss the dependence of DeÔ¨Ånition 6.122 on the initial index N in the
interval [0, ‚àû)Z. In this respect we obtain a similar statement to Proposition 6.111.
Proposition 6.125 Let Y be a dominant solution of (SDS) at ‚àûwith respect to
the interval [N, ‚àû)Z. Then Y is a dominant solution at ‚àûalso with respect to the
interval [M, ‚àû)Z for every M ‚àà[N, ‚àû)Z.
Proof Fix an index M ‚àà[N, ‚àû)Z, and let Sk and S(M)
k
be the matrices in (6.236)
and (6.397) corresponding to Y on the intervals [N, ‚àû)Z and [M, ‚àû)Z, respectively.
Furthermore, let PS‚àûand T be the associated matrices in (6.238) and (6.237). From
DeÔ¨Ånition 6.122 we have the conditions rank T = n ‚àíd‚àûand d[N, ‚àû)Z = d‚àû.
The latter equation implies that d[M, ‚àû)Z = d‚àû, by (6.224). By Proposition 6.101
and Theorem 6.103, we have that (6.370) holds, while from the proof of Proposi-
tion 6.111, we conclude that (6.398) is satisÔ¨Åed. Summarizing, the conjoined basis
Y satisÔ¨Åes
Im (PS‚àû‚àíSkT ) = Im PS‚àû= Im (PS‚àû‚àíSkT )T ,
k ‚àà[N, ‚àû)Z,
(6.411)
(S(M)
k
)‚Ä† = S‚Ä†
k (PS‚àû‚àíSM S‚Ä†
k)‚Ä†,
k ‚àà[M, ‚àû)Z.
(6.412)
The matrices Gk := PS‚àû‚àíSM S‚Ä†
k satisfy Im Gk ‚äÜIm PS‚àû, which implies that
rankGk ‚â§rankPS‚àûfor all k ‚àà[M, ‚àû)Z. Moreover, by (6.411) the limit matrix
G := limk‚Üí‚àûGk = PS‚àû‚àíSMT satisÔ¨Åes rankG = rankPS‚àû. On the other hand,
the inequality rank Gk ‚â•rankG for large k always holds for a limit of a sequence of
matrices. Therefore, rank Gk = rank G = rankPS‚àûfor large k. Then the properties
of Moore-Penrose pseudoinverse in Remark 1.60(v) imply that by taking the limit
as k ‚Üí‚àûin (6.412) the matrix T (M), deÔ¨Åned in (6.237) and corresponding to the
S-matrix S(M)
k
, satisÔ¨Åes
T (M) = lim
k‚Üí‚àûS‚Ä†
k G‚Ä†
k = T G‚Ä† = T (PS‚àû‚àíSMT )‚Ä†.
(6.413)
We will show that Im T (M) = Im T . Indeed, identity (6.413) yields the inclusion
Im T (M) ‚äÜIm T . On the other hand, by (6.413) and (6.411), we obtain
T (M) (PS‚àû‚àíSMT )
(6.413)
=
T (PS‚àû‚àíSMT )‚Ä†(PS‚àû‚àíSMT )
(6.411)
=
T PS‚àû= T,

520
6
Miscellaneous Topics on Symplectic Systems
since Im T ‚äÜIm PS‚àû. This shows the opposite inclusion Im T ‚äÜIm T (M). Finally,
the equalities rankT (M) = rankT = n ‚àíd‚àûthen imply that Y is a dominant
solution of (SDS) at ‚àûwith respect to the interval [M, ‚àû)Z, by DeÔ¨Ånition 6.122.
‚äì‚äî
Remark 6.126 In the proof of Proposition 6.125 we show that the set Im T (M)
is preserved within the interval [N, ‚àû)Z, i.e., Im T (M) = Im T for every M ‚àà
[N, ‚àû)Z. Moreover, this statement obviously holds for any conjoined basis Y with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) such that
d[N, ‚àû)Z = d‚àû.
In the following statement, we show that the property of Y being a dominant
solution of (SDS) at ‚àûis preserved under the relation being contained from
Sect. 6.3.3.
Proposition 6.127 Let Y be a dominant solution of (SDS) at ‚àûwith respect to
the interval [N, ‚àû)Z. Then every conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), which is either contained in Y on
[N, ‚àû)Z or which contains Y on [N, ‚àû)Z, is also a dominant solution of (SDS) at
‚àûwith respect to the interval [N, ‚àû)Z.
Proof The result follows directly from Proposition 6.86 and DeÔ¨Ånition 6.122.
‚äì‚äî
Next we characterize the nonoscillation of system (SDS) in terms of the existence
of dominant solutions of (SDS) at ‚àû. It is an analog of Theorem 6.115.
Theorem 6.128 The following statements are equivalent.
(i) System (SDS) is nonoscillatory.
(ii) There exists a dominant solution of (SDS) at ‚àû.
(iii) For any integer r satisfying n ‚àíd‚àû‚â§r ‚â§n, there exists a dominant solution
Y of (SDS) at ‚àûwith the rank of Xk equal to r for large k.
Proof If (SDS) is nonoscillatory, then by Theorem 6.107 for any symmetric and
nonnegative deÔ¨Ånite matrix D with rank D = n‚àíd‚àû, there exists N ‚àà[0, ‚àû)Z and
a minimal conjoined basis Y of (SDS) on [N, ‚àû)Z such that d[N, ‚àû)Z = d‚àûand
the corresponding matrix T in (6.237) satisÔ¨Åes T = D, i.e., rankT = n‚àíd‚àû. From
DeÔ¨Ånition 6.122 and Remark 6.123, it then follows that Y is a minimal dominant
solution of (SDS) at ‚àû. Suppose now that (ii) holds, and let Y be a dominant
solution of (SDS) at ‚àû, i.e., there exists N ‚àà[0, ‚àû)Z with d[N, ‚àû)Z = d‚àûsuch
that Y is a conjoined basis of (SDS) with constant kernel on [N, ‚àû)Z and no forward
focal points in (N, ‚àû), and its associated matrix T satisÔ¨Åes rankT = n ‚àíd‚àû. By
Theorem 6.90, for any integer r between n ‚àíd‚àûand n, there exists a conjoined
basis ÀúY of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points in
(N, ‚àû) and with rank ÀúXk = r on [N, ‚àû)Z such that ÀúY is either contained in Y or ÀúY
contains Y on [N, ‚àû)Z. Therefore, ÀúY is also a dominant solution of (SDS) at ‚àû, by
Proposition 6.127, showing part (iii). Finally, if (iii) is satisÔ¨Åed, then Y is a conjoined

6.3
Symplectic Systems Without Controllability
521
basis of (SDS) with Ô¨Ånitely many focal points in (0, ‚àû). Therefore, system (SDS)
is nonoscillatory at ‚àûby Proposition 6.61. The proof is complete.
‚äì‚äî
For an eventually controllable system (SDS), we obtain from Theorem 6.128 the
following counterpart of Theorem 2.66 and Remark 2.69 in Sect. 2.5.1.
Corollary 6.129 Assume that (SDS) is eventually controllable. System (SDS) is
nonoscillatory at ‚àûif and only if there exists a dominant solution Y of (SDS)
at ‚àûwith rank equal to n, i.e., with Xk eventually invertible. In this case the
corresponding matrix T in (6.237) is positive deÔ¨Ånite.
In the last result of this section, we present a construction of all recessive
and dominant solutions of (SDS) at ‚àûfrom the minimal recessive and dominant
solutions at ‚àû, respectively. In this construction we utilize two main ingredients:
(i) the properties in Theorem 6.90 applied to the minimal recessive and dominant
solutions at ‚àûand (ii) the uniqueness of the minimal recessive solution ÀÜY min
of (SDS) at ‚àûin Theorem 6.113.
Remark 6.130 If ÀÜY min is the (unique) minimal recessive solution of (SDS) at ‚àû,
then we deÔ¨Åne the point ÀÜKmin ‚àà[0, ‚àû)Z as the smallest index N ‚àà[0, ‚àû)Z such
that ÀÜY min has constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû).
In particular, we have the identities
d[ ÀÜKmin, ‚àû)Z = d[N, ‚àû)Z = d‚àû
for all N ‚àà[ ÀÜKmin, ‚àû)Z.
(6.414)
These equalities follow from Theorem 6.90, the deÔ¨Ånition of d‚àûin (6.224),
and from the fact that rank ÀÜXmin
k
= n ‚àíd‚àûon [ ÀÜKmin, ‚àû)Z. Moreover, by
Proposition 6.111 the conjoined basis ÀÜY min is a minimal recessive solution of (SDS)
at ‚àûwith respect to the interval [N, ‚àû)Z for every N ‚àà[ ÀÜKmin, ‚àû)Z.
Theorem 6.131 Assume that system (SDS) is nonoscillatory at ‚àûwith the index
ÀÜKmin deÔ¨Åned in Remark 6.130. Then the following statements hold.
(i) A solution Y of (SDS) is a recessive solution at ‚àûif and only if Y is a conjoined
basis of (SDS) with constant kernel on [ ÀÜKmin, ‚àû)Z and no forward focal points
in ( ÀÜKmin, ‚àû), which contains some minimal recessive solution of (SDS) on
[N, ‚àû)Z for some (and hence every) N ‚àà[ ÀÜKmin, ‚àû)Z.
(ii) A solution Y of (SDS) is a dominant solution at ‚àûif and only if Y is a conjoined
basis of (SDS), which contains some minimal dominant solution of (SDS) at
‚àûon [N, ‚àû)Z for some N ‚àà[ ÀÜKmin, ‚àû)Z.
Proof
(i) Let Y be a recessive solution of (SDS) at ‚àû. Then there exists an index
N ‚àà[0, ‚àû)Z such that Y has constant kernel on [N, ‚àû)Z and no forward
focal points in (N, ‚àû), and the corresponding matrix Sk in (6.236) satisÔ¨Åes
S‚Ä†
k ‚Üí0 for k ‚Üí‚àû. From Proposition 6.111, we know that this property of Sk
is preserved under shifting the index N to the right. Therefore, we may assume

522
6
Miscellaneous Topics on Symplectic Systems
that N ‚àà[ ÀÜKmin, ‚àû)Z and hence, we have d[N, ‚àû)Z = d‚àû. Consequently, by
Theorem 6.90 there exists a conjoined basis Y ‚àóof (SDS) with constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû) and with rank X‚àó
k = n‚àíd‚àû
on [N, ‚àû)Z such that Y contains Y ‚àóon [N, ‚àû)Z. In turn, Proposition 6.112
implies that Y ‚àóis a minimal recessive solution of (SDS) at ‚àûwith respect to
the interval [N, ‚àû)Z. From Proposition 6.92(i), we then obtain that Y contains
Y ‚àóalso on [L, ‚àû)Z for all L ‚àà[N, ‚àû)Z. It remains to show that Y contains
Y ‚àóon [L, ‚àû)Z for all L ‚àà[ ÀÜKmin, N ‚àí1]Z. Let us Ô¨Åx such an index L. By
Remark 6.130 we know that d[L, ‚àû)Z = d‚àûand that Y ‚àóhas constant kernel
on [L, ‚àû)Z and no forward focal points in (L, ‚àû). Consequently, Y has also
constant kernel on [L, ‚àû)Z and no forward focal points in (L, ‚àû) according
to Proposition 6.93(ii). On the other hand, Proposition 6.92(ii) implies that Y
contains Y ‚àóalso on [L, ‚àû)Z. This completes the proof of the Ô¨Årst implication.
Conversely, suppose that Y is a conjoined basis of (SDS) with constant kernel
on [ ÀÜKmin, ‚àû)Z and no forward focal points in ( ÀÜKmin, ‚àû). Let ÀÜY min be a minimal
recessive solution of (SDS) at ‚àû, which is contained in Y on [L, ‚àû)Z for some
L ‚àà[ ÀÜKmin, ‚àû)Z. By Remark 6.130, ÀÜY min has constant kernel on [ ÀÜKmin, ‚àû)Z
and no forward focal points in ( ÀÜKmin, ‚àû), and it is a minimal recessive solution
at ‚àûwith respect to [N, ‚àû)Z for every N ‚àà[ ÀÜKmin, ‚àû)Z. Consequently,
Proposition 6.92(i) implies that ÀÜY min is contained in Y on [N, ‚àû)Z for every
N ‚àà[ ÀÜKmin, ‚àû)Z. Finally, from Proposition 6.111 it then follows that Y is
a recessive solution of (SDS) at ‚àû.
(ii) Let Y be a dominant solution of (SDS) at ‚àûwith respect to an interval
[N, ‚àû)Z. By Proposition 6.125, we may assume that N ‚àà[ ÀÜKmin, ‚àû)Z. From
Theorem 6.90 we know that there exists a conjoined basis Y ‚àóof (SDS) with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) such that Y
contains Y ‚àóon [N, ‚àû)Z and rank X‚àó
k = n ‚àíd[N, ‚àû)Z = n ‚àíd‚àûon [N, ‚àû)Z.
In turn, Proposition 6.127 and Remark 6.123 then imply that Y ‚àóis a minimal
dominant solution of (SDS) at ‚àûwith respect to [N, ‚àû)Z. Conversely, let Y be
a conjoined basis of (SDS) with constant kernel on [N, ‚àû)Z ‚äÜ[ ÀÜKmin, ‚àû)Z and
no forward focal points in (N, ‚àû) such that Y contains some minimal dominant
solution of (SDS) on [N, ‚àû)Z. Then d[N, ‚àû)Z = d‚àûby DeÔ¨Ånition 6.122, and
Y is also a dominant solution of (SDS) at ‚àû, by Proposition 6.127.
‚äì‚äî
Remark 6.132 From Theorem 6.131(i), it follows that every recessive solution ÀÜY
of (SDS) at ‚àûis a recessive solution at ‚àûwith respect to the interval [N, ‚àû)Z
for every N ‚àà[ ÀÜKmin, ‚àû)Z. In addition, the orthogonal projector P ÀÜS‚àûin (6.238)
associated with ÀÜY through the matrix ÀÜSk in (6.236) is the same for all initial indices
N ‚àà[ ÀÜKmin, ‚àû)Z, since in this case d[N, ‚àû)Z = d‚àûfor every N ‚àà[ ÀÜKmin, ‚àû)Z,
by Remark 6.130. Similarly, if Y is a dominant solution at ‚àûwith respect to an
interval [N, ‚àû)Z ‚äÜ[ ÀÜKmin, ‚àû)Z, then the corresponding orthogonal projector PS‚àû
in (6.238) is the same for all initial indices L ‚àà[N, ‚àû)Z.

6.3
Symplectic Systems Without Controllability
523
In Theorem 6.118 we showed that recessive solutions of (SDS) at ‚àûcan be
constructed in higher dimensions from the recessive solutions of the corresponding
symplectic systems in lower dimensions by a block diagonal procedure. We note
that exactly the same statement holds also for dominant solutions of (SDS) at ‚àû.
Theorem 6.133 Assume that the systems (SDS) and (SDS) in Theorem 6.118 are
nonoscillatory at ‚àû. Let Y and Y be dominant solutions of (SDS) and (SDS) at ‚àû
with rank equal to r and r, respectively. Then the sequence Y ‚àó
k deÔ¨Åned by
X‚àó
k :=
Xk 0
0 Xk

,
U‚àó
k :=
Uk 0
0 Uk

,
k ‚àà[0, ‚àû)Z,
(6.415)
is a dominant solution of system (SDS‚àó) at ‚àûwith rank equal to r‚àó:= r + r.
Moreover, the dominant solution Y ‚àóat ‚àûconstructed in (6.415) is minimal
(maximal) if and only if the dominant solutions Y and Y at ‚àûare minimal
(maximal).
Proof The statement follows by the same arguments as in the proof of Theo-
rem 6.118 by noting that the maximal order of abnormality of the augmented
system (SDS‚àó) is d‚àó
‚àû= d‚àû+ d‚àû, so that the matrix T ‚àóin (6.237) associated
with Y ‚àóin (6.415) satisÔ¨Åes (using that n‚àó= n + n)
rankT ‚àó= rank diag{T, T } = rankT + rankT
= n ‚àíd‚àû+ n ‚àíd‚àû= n‚àó‚àíd‚àó
‚àû.
The result then follows from DeÔ¨Ånition 6.122 applied system (SDS‚àó).
‚äì‚äî
6.3.8
Genus Conjoined Bases
In this section we introduce the concept of a genus of conjoined bases of (SDS) and
study its properties. As our main results, we prove the existence (Theorem 6.138)
and classiÔ¨Åcation (Theorems 6.139 and 6.141) of recessive and dominant solutions
of (SDS) in every such a genus.
DeÔ¨Ånition 6.134 (Genus of Conjoined Bases) Let Y (1) and Y (2) be two conjoined
bases of (SDS). We say that Y (1) and Y (2) have the same genus (or they belong
to the same genus) if there exists an index N ‚àà[0, ‚àû)Z such that the equality
Im X(1)
k
= Im X(2)
k
holds for all k ‚àà[N, ‚àû)Z.
The relation ‚Äúhaving (or belonging to) the same genus‚Äù is an equivalence relation
on the set of all conjoined bases of (SDS). Therefore, there exists a partition of this
set into disjoint classes of conjoined bases of (SDS), which belong to the same
genus. This allows to interpret each such an equivalence class G as a genus itself. In

524
6
Miscellaneous Topics on Symplectic Systems
particular, when system (SDS) is nonoscillatory, we have the following property of
conjoined bases of (SDS) in one genus G.
Proposition 6.135 Assume that system (SDS) is nonoscillatory at ‚àû. Let Y (1) and
Y (2) be conjoined bases of (SDS). Then the following are equivalent.
(i) The conjoined bases Y (1) and Y (2) belong to the same genus G.
(ii) The equality Im X(1)
k
= Im X(2)
k
holds on some subinterval [N, ‚àû)Z, where
Y (1) and Y (2) have constant kernel.
(iii) The equality Im X(1)
k
= Im X(2)
k
holds on every subinterval [N, ‚àû)Z, where
Y (1) and Y (2) have constant kernel.
Proof The statement follows from DeÔ¨Ånition 6.134 and Theorem 6.77.
‚äì‚äî
Remark 6.136 For a nonoscillatory system (SDS) at ‚àû, there is only one genus of
conjoined bases (denoted by Gmin) containing all conjoined bases Y of (SDS) with
the minimal eventual rank of Xk in (6.279), i.e., with rank Xk = n ‚àíd‚àûfor large k.
This is a direct consequence of the fact that any two conjoined bases Y (1) and Y (2)
of (SDS) with the eventual rank of X(1)
k
and X(2)
k
equal to n‚àíd‚àûnecessarily satisfy
Im X(1)
k
= Im X(2)
k
for large k. Indeed, if Y (1) and Y (2) have constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), then the equality d[N, ‚àû)Z = d‚àû
holds by Remark 6.96. Therefore, Y (1) and Y (2) are minimal conjoined bases on
[N, ‚àû)Z, and by Remark 6.98 they satisfy Im X(1)
N
= (0[N, ‚àû)Z)‚ä•= Im X(2)
N .
In turn, Theorem 6.77 implies that Im X(1)
k
= Im X(2)
k
on [N, ‚àû)Z. In particular,
all minimal recessive and dominant solutions of (SDS) at ‚àûbelong to the minimal
genus Gmin.
Remark 6.137 Similarly to Remark 6.136, there is only one genus of conjoined
bases (denoted by Gmax) containing all conjoined bases Y of (SDS) satisfying
Im Xk = Rn for large k, i.e., with Xk eventually invertible. All maximal recessive
and dominant solutions of (SDS) at ‚àûthen belong to the maximal genus Gmax.
In the following result, we show that there exists both recessive and dominant
solutions of (SDS) at ‚àûin every genus G.
Theorem 6.138 Assume that system (SDS) is nonoscillatory at ‚àû. Let G be a genus
of conjoined bases of (SDS). Then there exists a recessive solution and a dominant
solution of (SDS) at ‚àûin the genus G.
Proof First we focus on the case of the recessive solutions at ‚àû. Let ÀÜY min be the
minimal recessive solution of (SDS) at ‚àûwith ÀÜKmin deÔ¨Åned in Remark 6.130.
Furthermore, let Y be a conjoined basis of (SDS), which belongs to the genus
G. Then there exists an index N ‚àà[ ÀÜKmin, ‚àû)Z such that Y has constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû). By Remark 6.130 we know
that the equality d[N, ‚àû)Z = d‚àûholds and at the same time ÀÜY min is a minimal
recessive solution with respect to [N, ‚àû)Z. Moreover, by Theorem 6.90 there
exists a conjoined basis Y ‚àóof (SDS) with constant kernel on [N, ‚àû)Z and no
forward focal points in (N, ‚àû) such that rankX‚àó
k = n ‚àíd‚àûon [N, ‚àû)Z and such

6.3
Symplectic Systems Without Controllability
525
that Y contains Y ‚àóon [N, ‚àû)Z. Therefore, ÀÜY min and Y ‚àóare minimal conjoined
bases of (SDS) on [N, ‚àû)Z, so that Im ÀÜXmin
N
= Im X‚àó
N by Remark 6.98. Denote
by ÀÜR min
k
, R‚àó
k, Rk the orthogonal projectors in (6.233) deÔ¨Åned by ÀÜXmin
k
, X‚àó
k, Xk,
respectively. Then ÀÜR min
N
= R‚àó
N and Im ÀÜR min
N
= Im R‚àó
N ‚äÜIm RN, by Remark 6.83.
From Theorem 6.87 we know that there exists a conjoined basis ÀÜY of (SDS) with
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) such that ÀÜY
contains ÀÜY min on [N, ‚àû)Z and the equality Im ÀÜXN = Im RN holds. Consequently,
by Proposition 6.86 the conjoined basis ÀÜY is a recessive solution of (SDS) at ‚àû
with respect to [N, ‚àû)Z. And since Im ÀÜXN = Im RN = Im XN, we have that
Im ÀÜXk = Im Xk on [N, ‚àû)Z by Theorem 6.77. This shows that the recessive
solution ÀÜY belongs to the genus G, according to DeÔ¨Ånition 6.134. The proof for
the dominant solution at ‚àûin G can be carried out by exactly the same arguments,
by considering a minimal dominant solution Y min at ‚àûfrom Theorem 6.128 instead
of the minimal recessive solution ÀÜY min at ‚àûin the above proof.
‚äì‚äî
In the next result, we provide a complete classiÔ¨Åcation of all recessive solutions
of (SDS) at ‚àûin a given genus G.
Theorem 6.139 Assume that system (SDS) is nonoscillatory at ‚àûwith
ÀÜKmin
deÔ¨Åned in Remark 6.130. Let ÀÜY be a recessive solution of (SDS) at ‚àû, which
belongs to a genus G, and let ÀÜP and P ÀÜS‚àûbe the constant orthogonal projectors
deÔ¨Åned in (6.234), (6.238), and Remark 6.132 on [ ÀÜKmin, ‚àû)Z through the matrix
ÀÜXk. Then a solution Y of (SDS) is a recessive solution at ‚àûbelonging to the genus
G if and only if for some (and hence for every) index N ‚àà[ ÀÜKmin, ‚àû)Z there exist
matrices ÀÜM, ÀÜN ‚ààRn√ón such that
XN = ÀÜXN ÀÜM,
UN = ÀÜUN ÀÜM + ÀÜX‚Ä†T
N ÀÜN,
(6.416)
ÀÜM is nonsingular,
ÀÜMT ÀÜN = ÀÜNT ÀÜM,
Im ÀÜN ‚äÜIm ÀÜP ,
(6.417)
P ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àû= 0.
(6.418)
Proof Let Y be a recessive solution of (SDS), which belongs to the genus G. From
Theorem 6.131 we know that ÀÜY and Y have constant kernel on [ ÀÜKmin, ‚àû)Z and
no forward focal points in ( ÀÜKmin, ‚àû), and consequently, according to Proposi-
tion 6.135 they satisfy Im ÀÜXk = Im Xk on [ ÀÜKmin, ‚àû)Z. Therefore, by Theorem 6.69
and Remark 6.70 (with Y (1) := ÀÜY and Y (2) := Y) for every N ‚àà[ ÀÜKmin, ‚àû)Z, there
exist ÀÜM, ÀÜN ‚ààRn√ón such that (6.416) and (6.417) hold. We will prove (6.418).
Fix N ‚àà[ ÀÜKmin, ‚àû)Z. Denote by ÀÜY min and Y ‚àóthe minimal recessive solutions
of (SDS) at ‚àûfrom Theorem 6.131, which are contained in ÀÜY and Y on [N, ‚àû)Z,
respectively. By Theorem 6.113 (or Theorem 6.69), we know that Y ‚àó
k = ÀÜY min
k
ÀÜMmin
on [0, ‚àû)Z for some nonsingular matrix
ÀÜMmin. This means that the Wronskian
ÀÜW min := w( ÀÜY min, Y ‚àó) = 0. On the other hand, the conjoined bases ÀÜY min and Y ‚àó
are minimal on [N, ‚àû)Z, and therefore, the formulas in (6.346) hold (with Y ‚àó(1) :=
ÀÜY min, Y ‚àó(2) := Y ‚àó, M‚àó(1) :=
ÀÜMmin, and N‚àó(1) := ÀÜW min = 0). Consequently, by

526
6
Miscellaneous Topics on Symplectic Systems
Proposition 6.99 (with PS(1)‚àû:= P ÀÜS‚àû), we obtain that P ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àû= 0 is
satisÔ¨Åed.
Conversely, Ô¨Åx N ‚àà[ ÀÜKmin, ‚àû)Z, and suppose that a solution Y of (SDS)
satisÔ¨Åes (6.416)‚Äì(6.418). From Remark 6.130 we have d[N, ‚àû)Z = d‚àû. The third
condition in (6.417) yields that ÀÜP ÀÜN = ÀÜN, so that XT
NUN = ÀÜMT ÀÜXT
N ÀÜUN ÀÜM + ÀÜMT ÀÜN
by (6.416). Therefore, XT
NUN is symmetric. If YNd = 0 for some d ‚ààRn, then
ÀÜXN ÀÜMd = 0 and ÀÜUN ÀÜMd = ‚àíÀÜX‚Ä†T
N ÀÜNd again by (6.416). Multiplying the last equality
by ÀÜXT
N, we obtain that 0 = ÀÜUT
N ÀÜXN ÀÜMd = ‚àíÀÜP ÀÜNd = ‚àíÀÜNd. Therefore, ÀÜUN ÀÜMd = 0
as well. But since ÀÜY is a conjoined basis (rank ÀÜYN = n), it follows that ÀÜMd = 0.
The invertibility of ÀÜM then implies that d = 0, i.e., Y is a conjoined basis of (SDS).
Let ÀÜSk be the S-matrix in (6.236) corresponding to ÀÜY on [N, ‚àû)Z, and let ¬ØY be
a conjoined basis of (SDS) from Proposition 6.67 (with Y := ÀÜY). With the aid of the
identities ÀÜP ÀÜN = ÀÜN, ÀÜX‚Ä†
N ¬ØXN = 0, and ¬ØXN ÀÜP = ÀÜXN ÀÜSN = 0 from Proposition 6.67
(with Y := ÀÜY at the index k = N), we can rewrite (6.416) as YN = ÀÜYN ÀÜM + ¬ØYN ÀÜN.
Hence, Yk = ÀÜYk ÀÜM + ¬ØYk ÀÜN for all k ‚àà[N, ‚àû)Z, by the uniqueness of solutions
of (SDS). In particular, by Proposition 6.67 again and ÀÜXk ÀÜP = ÀÜXk on [N, ‚àû)Z, we
get
Xk = ÀÜXk ÀÜM + ÀÜXk ÀÜSk ÀÜN = ÀÜXk( ÀÜP ÀÜM + ÀÜSk ÀÜN),
k ‚àà[N, ‚àû)Z.
(6.419)
We will show that Y has constant kernel on [N, ‚àû)Z. Namely, we will prove that
Ker Xk = Ker ÀÜP ÀÜM on [N, ‚àû)Z. First we note that the symmetry of ÀÜMT ÀÜN implies
the symmetry of ÀÜN ÀÜM‚àí1 and that ÀÜN ÀÜM‚àí1 ÀÜP = ÀÜN ÀÜM‚àí1 holds. Hence, by (6.419) we
obtain
Xk = ÀÜXk ( ÀÜP ÀÜM + ÀÜSk ÀÜN ÀÜM‚àí1 ÀÜM) = ÀÜXk (I + ÀÜSk ÀÜN ÀÜM‚àí1) ÀÜP ÀÜM,
k ‚àà[N, ‚àû)Z.
This implies that Ker ÀÜP ÀÜM ‚äÜKer Xk for all k ‚àà[N, ‚àû)Z. Fix now k ‚àà[N, ‚àû)Z,
v ‚ààKer Xk, and put w := ÀÜP ÀÜMv. Then ÀÜXk (w + ÀÜSk ÀÜN ÀÜM‚àí1w) = 0. Multiplying the
latter equality by ÀÜX‚Ä†
k from the left and using the identities ÀÜP ÀÜSk = ÀÜSk and w = ÀÜP w,
we get w = ‚àíÀÜSk ÀÜN ÀÜM‚àí1w. Therefore, w ‚ààIm ÀÜSk ‚äÜIm P ÀÜS‚àûby (6.239), and thus,
w = ‚àíÀÜSkP ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àûw = 0 by (6.418). This shows that v ‚ààKer ÀÜP ÀÜM, i.e.,
Ker Xk ‚äÜKer ÀÜP ÀÜM. Therefore, Ker Xk = Ker ÀÜP ÀÜM on [N, ‚àû)Z, i.e., the conjoined
basis Y has constant kernel on [N, ‚àû)Z.
Note that the Ô¨Årst equation in (6.416) and the invertibility of
ÀÜM yield that
Im XN = Im ÀÜXN. Then it follows from Theorem 6.77 that Im Xk = Im ÀÜXk for
all k ‚àà[N, ‚àû)Z. In particular, Y belongs to the genus G.
We shall prove that Y has no forward focal points in (N, ‚àû). Since the conjoined
basis Y has constant kernel on [N, ‚àû)Z, we denote by P the associated projector
in (6.234). The fact that Im Xk = Im ÀÜXk on [N, ‚àû)Z implies that Y and ÀÜY are
mutually representable on [N, ‚àû)Z in the spirit of Theorem 6.69 and the subsequent
remarks. This means that by this theorem (with the notation Y (1) := ÀÜY, Y (2) := Y
and S(1)
k
:= ÀÜSk, S(2)
k
:= Sk, P (1) := ÀÜP, P (2) := P, and M(1) := ÀÜM, N(1) := ÀÜN),

6.3
Symplectic Systems Without Controllability
527
we have
Im ( ÀÜP ÀÜM + ÀÜSk ÀÜN) = Im ÀÜP,
Im ÀÜMSk = Im ÀÜSk,
( ÀÜP ÀÜM + ÀÜSk ÀÜN)‚Ä† = P ÀÜM‚àí1 ‚àíSk ÀÜNT ,

k ‚àà[N, ‚àû)Z.
(6.420)
In turn, equalities (6.419), (6.420), and (6.236) yield on [N, ‚àû)Z the formulas
X‚Ä†
k = ( ÀÜP ÀÜM + ÀÜSk ÀÜN)‚Ä† ÀÜX‚Ä†
k,
(6.421)
and
ÀÜP ÀÜM + ÀÜSk ÀÜN = ÀÜP ÀÜM + ÀÜSk+1 ÀÜN ‚àí( ÀÜSk) ÀÜN
= ( ÀÜP ÀÜM + ÀÜSk+1 ÀÜN) ‚àíÀÜX‚Ä†
k+1 Bk ÀÜX‚Ä† T
k
ÀÜN.
(6.422)
Note that by the Ô¨Årst identity in (6.420), we have ( ÀÜP ÀÜM + ÀÜSk ÀÜN) ( ÀÜP ÀÜM + ÀÜSk ÀÜN)‚Ä† = ÀÜP
on [N, ‚àû)Z. Therefore, equations (6.419)‚Äì(6.422) and the symmetry of ÀÜXk ÀÜX‚Ä†
k+1 Bk
on [N, ‚àû)Z imply that
XkX‚Ä†
k+1Bk
(6.419), (6.421)
=
ÀÜXk( ÀÜP ÀÜM + ÀÜSk ÀÜN) ( ÀÜP ÀÜM + ÀÜSk+1 ÀÜN)‚Ä† ÀÜX‚Ä†
k+1Bk
(6.422)
=
ÀÜXk[( ÀÜP ÀÜM + ÀÜSk+1 ÀÜN) ‚àíÀÜX‚Ä†
k+1Bk ÀÜX‚Ä† T
k
ÀÜN] ( ÀÜP ÀÜM + ÀÜSk+1 ÀÜN)‚Ä† ÀÜX‚Ä†
k+1Bk
= ÀÜXk ÀÜP ÀÜX‚Ä†
k+1Bk ‚àí( ÀÜXk ÀÜX‚Ä†
k+1Bk) ÀÜX‚Ä† T
k
ÀÜN( ÀÜP ÀÜM + ÀÜSk+1 ÀÜN)‚Ä† ÀÜX‚Ä†
k+1Bk
= ÀÜXk ÀÜX‚Ä†
k+1Bk ‚àíBT
k ÀÜX‚Ä† T
k+1 ÀÜP ÀÜN( ÀÜP ÀÜM + ÀÜSk+1 ÀÜN)‚Ä† ÀÜX‚Ä†
k+1Bk
(6.420)
=
ÀÜXk ÀÜX‚Ä†
k+1Bk ‚àíLk,
Lk := BT
k ÀÜX‚Ä† T
k+1 ÀÜN(P ÀÜM‚àí1 ‚àíSk+1 ÀÜNT ) ÀÜX‚Ä†
k+1Bk.
(6.423)
Our claim is to show that the matrix Lk in (6.423) is zero. Let ÀÜY min be the minimal
recessive solution of (SDS) from Theorem 6.131(i), which is contained in ÀÜY on
[N, ‚àû)Z, and let ÀÜR min
k
be the corresponding orthogonal projector in (6.234). Then
ÀÜY min is a minimal conjoined basis of (SDS) on [N, ‚àû)Z, so that P ÀÜS‚àû( ÀÜXmin
k
)‚Ä† =
( ÀÜXmin
k
)‚Ä† on [N, ‚àû)Z, by Proposition 6.86. Moreover, the equality ( ÀÜXmin
k
)‚Ä† =
ÀÜX‚Ä†
k ÀÜR min
k
holds for every k ‚àà[N, ‚àû)Z by (6.298) (with Y ‚àó:= ÀÜY min). Then by
ÀÜNP = ÀÜN, the second identity in (6.420), and Theorem 6.66(ii), we obtain
Lk = BT
k ÀÜR min
k
ÀÜX‚Ä† T
k+1 ÀÜN(P ÀÜM‚àí1 ‚àíSk+1 ÀÜNT ) ÀÜX‚Ä†
k+1 ÀÜR min
k
Bk
= BT
k ( ÀÜXmin
k+1)‚Ä† T ÀÜN(P ÀÜM‚àí1 ‚àíÀÜM‚àí1 ÀÜMSk+1 ÀÜNT ) ( ÀÜXmin
k+1)‚Ä†Bk
(6.420)
=
BT
k ( ÀÜXmin
k+1)‚Ä† T P ÀÜS‚àûÀÜN

P ÀÜM‚àí1 ‚àíÀÜM‚àí1P ÀÜS‚àûÀÜMSk+1 ÀÜNT 
P ÀÜS‚àû( ÀÜXmin
k+1)‚Ä†Bk

528
6
Miscellaneous Topics on Symplectic Systems
= BT
k ( ÀÜXmin
k+1)‚Ä† T P ÀÜS‚àû( ÀÜN ÀÜM‚àí1P ÀÜS‚àû‚àíÀÜN ÀÜM‚àí1P ÀÜS‚àûÀÜMSk+1 ÀÜNT P ÀÜS‚àû) ( ÀÜXmin
k+1)‚Ä†Bk
= BT
k ( ÀÜXmin
k+1)‚Ä† T P ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àû(I ‚àíÀÜMSk+1 ÀÜNT P ÀÜS‚àû) ( ÀÜXmin
k+1)‚Ä†Bk
(6.418)
=
0.
Hence, from equality (6.423) we get XkX‚Ä†
k+1Bk = ÀÜXk ÀÜX‚Ä†
k+1Bk on [N, ‚àû)Z. Since
ÀÜY has no forward focal points in (N, ‚àû), i.e., ÀÜXk ÀÜX‚Ä†
k+1Bk ‚â•0 on [N, ‚àû)Z, we
conclude that Y has no forward focal points in (N, ‚àû) as well.
In the Ô¨Ånal step of the proof, we will show that Y is a recessive solution of (SDS)
at ‚àû. By Theorem 6.90, there exists a minimal conjoined basis Y ‚àóof (SDS) on
[N, ‚àû)Z, which is contained in Y on [N, ‚àû)Z. In particular, the equality rankX‚àó
k =
n ‚àíd‚àûholds on [N, ‚àû)Z. Then according to Remark 6.98, there exist matrices
ÀÜMmin, ÀÜNmin ‚ààRn√ón such that (6.346) is satisÔ¨Åed (with Y ‚àó(1) := ÀÜY min, Y ‚àó(2) :=
Y ‚àó, M‚àó(1) :=
ÀÜMmin, and N‚àó(1) :=
ÀÜNmin). In particular, ÀÜMmin is invertible and
ÀÜNmin = w( ÀÜY min, Y ‚àó) by (6.244). Consequently, by Proposition 6.99 (with Y (1) :=
ÀÜY, Y (2) := Y, M(1) :=
ÀÜM, N(1) :=
ÀÜN, and PS(1)‚àû:= P ÀÜS‚àû), we derive that
ÀÜNmin( ÀÜMmin)‚àí1 = P ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àû. In view of (6.418), we get ÀÜNmin( ÀÜMmin)‚àí1 =
0, and hence ÀÜNmin = 0. This implies by (6.346) that Y ‚àó
N = ÀÜY min
N
ÀÜMmin, so that
Y ‚àó
k = ÀÜY min
k
ÀÜMmin on [0, ‚àû)Z by the uniqueness of solutions of (SDS). According to
Theorem 6.113, Y ‚àóis a minimal recessive solution of (SDS) at ‚àûwith respect to
the interval [N, ‚àû)Z. Thus, we proved that Y ‚àó, being a minimal recessive solution
of (SDS) at ‚àû, is contained in Y on [N, ‚àû)Z. Therefore, Y is also a recessive
solution of (SDS) at ‚àûby Proposition 6.112. The proof is complete.
‚äì‚äî
As a special case of Theorem 6.139, we obtain a classiÔ¨Åcation of the recessive
solutions of (SDS) at ‚àûin the maximal genus Gmax.
Corollary 6.140 Assume that system (SDS) is nonoscillatory at ‚àûwith
ÀÜKmin
deÔ¨Åned in Remark 6.130. Let ÀÜY be a maximal recessive solution of (SDS) at ‚àû.
Moreover, let P ÀÜS‚àûbe the orthogonal projector deÔ¨Åned through the invertible matrix
ÀÜXk on [ ÀÜKmin, ‚àû)Z in (6.238) and Remark 6.132. Then a solution Y of (SDS) is
a maximal recessive solution at ‚àûif and only if for some (and hence for every)
index N ‚àà[ ÀÜKmin, ‚àû)Z, there exist matrices ÀÜM, ÀÜN ‚ààRn√ón such that
XN = ÀÜXN ÀÜM,
UN = ÀÜUN ÀÜM + ÀÜXT ‚àí1
k
ÀÜN,
ÀÜM is nonsingular,
ÀÜMT ÀÜN = ÀÜNT ÀÜM,
P ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àû= 0.
Proof The result follows from Theorem 6.139 with ÀÜP = I.
‚äì‚äî
In remaining part of this section, we will derive several classiÔ¨Åcations of the
dominant solutions of (SDS) at ‚àûin a given genus G in terms of recessive solutions
of (SDS) at ‚àûfrom this genus.
Theorem 6.141 Assume that system (SDS) is nonoscillatory at ‚àû. Let G be
a genus of conjoined bases of (SDS). Let ÀÜY be a recessive solution of (SDS) at

6.3
Symplectic Systems Without Controllability
529
‚àûbelonging to G, and let Y be a conjoined basis from G. Denote by P ÀÜS‚àûand
PS‚àûtheir associated orthogonal projectors in (6.238) and Remark 6.132. Then Y
is a dominant solution of (SDS) at ‚àûif and only if
rankP ÀÜS‚àûw( ÀÜY, Y) PS‚àû= n ‚àíd‚àû.
(6.424)
Proof Let ÀÜY be a recessive solution of (SDS) at ‚àûbelonging to G, and let Y be
a conjoined basis from G. We denote ÀÜN := w( ÀÜY, Y). Then there exists an index
N ‚àà[ ÀÜKmin, ‚àû)Z such that ÀÜY and Y have constant kernel on [N, ‚àû)Z and no
forward focal points in (N, ‚àû). By Remark 6.130 we have d[N, ‚àû)Z = d‚àû. Since
ÀÜY and Y belong to the same genus G, we may assume without loss of generality that
Im ÀÜXk = Im Xk on [N, ‚àû)Z. From Theorem 6.69 and Remark 6.70, it then follows
that ÀÜY and Y are mutually representable on [N, ‚àû)Z and the matrix ÀÜN satisÔ¨Åes
ÀÜP ÀÜN =
ÀÜN =
ÀÜNP, where ÀÜP and P are the corresponding orthogonal projectors
in (6.234). Let ÀÜY ‚àóand Y ‚àóbe minimal conjoined bases of (SDS) on [N, ‚àû)Z, which
are contained in ÀÜY and Y on [N, ‚àû)Z, respectively, and let ÀÜN‚àó:= w( ÀÜY ‚àó, Y ‚àó). In
particular, ÀÜY ‚àóis a minimal recessive solution of (SDS) by Proposition 6.112, i.e.,
the associated matrix ÀÜT ‚àóin (6.237) satisÔ¨Åes ÀÜT ‚àó= 0. We apply the representations
of ÀÜY, Y and of ÀÜY ‚àó, Y ‚àóin Theorem 6.69 and Remark 6.98, and in formula (6.349) in
Proposition 6.99 (with Y (1) := ÀÜY, Y (2) := Y, Y ‚àó(1) := ÀÜY ‚àó, Y ‚àó(2) := Y ‚àó, P (1) := ÀÜP ,
P (2) := P, PS(1)‚àû:= P ÀÜS‚àû, PS(2)‚àû:= PS‚àû, and N(1) := ÀÜN). Then there exist
invertible matrices ÀÜM and ÀÜM‚àósuch that
ÀÜP ÀÜMPS‚àû= P ÀÜS‚àûÀÜM‚àó,
P ÀÜM‚àí1P ÀÜS‚àû= PS‚àû( ÀÜM‚àó)‚àí1,
ÀÜN‚àó( ÀÜM‚àó)‚àí1 = P ÀÜS‚àûÀÜN ÀÜM‚àí1P ÀÜS‚àû.

(6.425)
By using (6.425) and the equality ÀÜNP = ÀÜN, we then obtain
ÀÜN‚àó( ÀÜM‚àó)‚àí1 = P ÀÜS‚àûÀÜNP ÀÜM‚àí1P ÀÜS‚àû= P ÀÜS‚àûÀÜNPS‚àû( ÀÜM‚àó)‚àí1.
(6.426)
Let Y be a dominant solution of (SDS) at ‚àû. Then also Y ‚àóis a dominant solution
at ‚àû, by Proposition 6.127. From (6.389) we know that the matrix T ‚àóin (6.237)
associated with Y ‚àósatisÔ¨Åes rank T ‚àó= rank[ ÀÜN‚àó( ÀÜM‚àó)‚àí1 + ÀÜT ‚àó] = rank ÀÜN‚àó( ÀÜM‚àó)‚àí1.
Since rankT ‚àó= n ‚àíd‚àûby DeÔ¨Ånition 6.122, we get from (6.426) that
rankP ÀÜS‚àûÀÜNPS‚àû= rankP ÀÜS‚àûÀÜNPS‚àû( ÀÜM‚àó)‚àí1 = rank ÀÜN‚àó( ÀÜM‚àó)‚àí1 = n ‚àíd‚àû,
i.e., formula (6.424) holds. Conversely, if (6.424) is satisÔ¨Åed, then from (6.426) we
obtain that rank ÀÜN‚àó( ÀÜM‚àó)‚àí1 = n ‚àíd‚àû. Therefore, rank T ‚àó= n ‚àíd‚àûby (6.389),
and hence Y ‚àóis a dominant solution of (SDS) at ‚àûby DeÔ¨Ånition 6.122. Finally,
Proposition 6.127 implies that Y is a dominant solution at ‚àûas well.
‚äì‚äî
When we specialize Theorem 6.141 to the minimal genus Gmin, we obtain
a classiÔ¨Åcation of all minimal dominant solutions of (SDS) at ‚àû.

530
6
Miscellaneous Topics on Symplectic Systems
Corollary 6.142 Assume that system (SDS) is nonoscillatory at ‚àû. Let ÀÜY min be
the minimal recessive solution of (SDS) at ‚àû, and let Y be a minimal conjoined
basis of (SDS). Then Y is a minimal dominant solution of (SDS) at ‚àûif and only
if rank w( ÀÜY min, Y) = n ‚àíd‚àû.
Proof By Theorem 6.141 and its proof with ÀÜP := P ÀÜS‚àûand P := PS‚àû, we have
that P ÀÜS‚àûÀÜN =
ÀÜN and ÀÜNPS‚àû=
ÀÜN, where ÀÜN := w( ÀÜY min, Y). Therefore, the
equality P ÀÜS‚àûÀÜNPS‚àû= ÀÜN holds, and the statement follows from (6.424).
‚äì‚äî
In the following result, we provide important examples of minimal dominant
solutions of (SDS) at ‚àû. We recall that the principal solution Y [N] of (SDS) at the
index N ‚àà[0, ‚àû)Z is deÔ¨Åned as the solution of (SDS) given by the initial conditions
X[N]
N
= 0 and U[N]
N
= I.
Theorem 6.143 Assume that system (SDS) is nonoscillatory at ‚àûwith
ÀÜKmin
deÔ¨Åned in Remark 6.130. Then for every N ‚àà[ ÀÜKmin, ‚àû)Z, the principal solution
Y [N] at the index N is a minimal dominant solution of (SDS) at ‚àû.
Proof Let ÀÜY min be the minimal recessive solution of (SDS) at ‚àûfrom Theo-
rem 6.113, and let N ‚àà[ ÀÜKmin, ‚àû)Z be Ô¨Åxed. Then ÀÜY min has constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), by Remark 6.130. In particular,
the condition d[N, ‚àû)Z = d‚àûholds, by (6.414). In order to simplify the notation,
we put ÀÜY :=
ÀÜY min and Y := Y [N]. Let ÀÜP , ÀÜRk, ÀÜSk, and P ÀÜS‚àûbe the matrices
in (6.234), (6.236), (6.238), and Remark 6.132 associated with ÀÜY. Then ÀÜP = P ÀÜS‚àû
and by Theorem 6.75 the conjoined basis Y satisÔ¨Åes
Xk = ÀÜXk ÀÜSk ÀÜXT
N,
rank ÀÜSk = rank Xk,
k ‚àà[N, ‚àû)Z.
(6.427)
Now Ô¨Åx an index L ‚àà[N, ‚àû)Z such that Y has constant kernel on [L, ‚àû)Z and no
forward focal points in (L, ‚àû). In particular, the rank of Xk is constant on [L, ‚àû)Z.
The second identity in (6.427) then implies that also the rank of ÀÜSk is constant
on [L, ‚àû)Z, which by Theorem 6.66(iv) and property (6.239) yields the equalities
rank ÀÜSk = n ‚àíd[N, ‚àû)Z = n ‚àíd‚àûon [L, ‚àû)Z. Therefore, rank Xk = n ‚àíd‚àûon
[L, ‚àû)Z by (6.427), i.e., Y is a minimal conjoined basis of (SDS) on [L, ‚àû)Z. We
will show that
X‚Ä†
k = ÀÜX‚Ä†T
N ÀÜS‚Ä†
k ÀÜX‚Ä†
k,
k ‚àà[L, ‚àû)Z.
(6.428)
Setting A := ÀÜXk ÀÜSk ÀÜXT
N and B := ÀÜX‚Ä†T
N ÀÜS‚Ä†
k ÀÜX‚Ä†
k for a Ô¨Åxed index k ‚àà[L, ‚àû)Z, we
verify that the matrices A and B satisfy the four deÔ¨Åning equations for the Moore-
Penrose pseudoinverse in (1.157). Namely, the identities ÀÜX‚Ä†
k ÀÜXk = ÀÜP , ÀÜXk ÀÜX‚Ä†
k = ÀÜRk,
and ÀÜS‚Ä†
k ÀÜSk = P ÀÜS‚àûimply that BA = ÀÜRN and AB = ÀÜRk are symmetric. Moreover,
BAB = (BA) B = ÀÜRN ÀÜX‚Ä†T
N ÀÜS‚Ä†
k ÀÜX‚Ä†
k = ÀÜX‚Ä†T
N ÀÜS‚Ä†
k ÀÜX‚Ä†
k = B,
ABA = (AB) A = ÀÜRk ÀÜXk ÀÜSk ÀÜXT
N = ÀÜXk ÀÜSk ÀÜXT
N = A.

6.3
Symplectic Systems Without Controllability
531
Therefore, we get A‚Ä† = B, showing equality (6.428). Let S(L)
k
be the S-matrix
in (6.236), which corresponds to Y on [L, ‚àû)Z, that is,
S(L)
k
:=
k‚àí1

j=L
X‚Ä†
j+1 Bj X‚Ä† T
j
,
k ‚àà[L, ‚àû)Z.
(6.429)
By inserting (6.428) into (6.429) and using the identity  ÀÜSk =
ÀÜX‚Ä†
k+1Bk ÀÜX‚Ä† T
k
together with ÀÜSk ÀÜS‚Ä†
k = ÀÜS‚Ä†
k ÀÜSk = P ÀÜS‚àûon [L, ‚àû)Z, we obtain for every k ‚àà[L, ‚àû)Z
that
S(L)
k
(6.428)
=
k‚àí1

j=L
ÀÜX‚Ä†T
N ÀÜS‚Ä†
j+1 ÀÜX‚Ä†
j+1Bj ÀÜX‚Ä† T
j
ÀÜS‚Ä†
j ÀÜX‚Ä†
N = ÀÜX‚Ä†T
N
 k‚àí1

j=L
ÀÜS‚Ä†
j+1 ( ÀÜSj) ÀÜS‚Ä†
j

ÀÜX‚Ä†
N
= ÀÜX‚Ä†T
N
 k‚àí1

j=L
( ÀÜS‚Ä†
j+1 ÀÜSj+1 ÀÜS‚Ä†
j ‚àíÀÜS‚Ä†
j+1 ÀÜSj ÀÜS‚Ä†
j )

ÀÜX‚Ä†
N
= ÀÜX‚Ä†T
N
 k‚àí1

j=L
(P ÀÜS‚àûÀÜS‚Ä†
j ‚àíÀÜS‚Ä†
j+1P ÀÜS‚àû)

ÀÜX‚Ä†
N
= ‚àíÀÜX‚Ä†T
N
 k‚àí1

j=L
 ÀÜS‚Ä†
j

ÀÜX‚Ä†
N = ÀÜX‚Ä†T
N
 ÀÜS‚Ä†
L ‚àíÀÜS‚Ä†
k
 ÀÜX‚Ä†
N.
(6.430)
Since ÀÜS‚Ä†
k ‚Üí0 as k ‚Üí‚àû, equality (6.430) then implies that the limit of S(L)
k
as k ‚Üí‚àûexists and it is equal to ÀÜX‚Ä†T
N ÀÜS‚Ä†
L ÀÜX‚Ä†
N. Therefore, by Theorem 6.124 we
conclude that Y is a (minimal) dominant solution of (SDS) at ‚àû. We note that
by (6.410) the matrix T (L) in (6.237) associated with Y on [L, ‚àû)Z satisÔ¨Åes the
equality T (L) =  ÀÜX‚Ä†T
N ÀÜS‚Ä†
L ÀÜX‚Ä†
N
‚Ä† = ÀÜXN ÀÜSL ÀÜXT
N by (6.428) and (6.427) at k = N. This
additional information is however not needed in this proof.
‚äì‚äî
Remark 6.144 The result of Theorem 6.143 shows that a minimal dominant
solution of (SDS) at ‚àûis not uniquely determined (up to a constant invertible
multiple), in contrast with the minimal recessive solution of (SDS) at ‚àû. Moreover,
it implies that one cannot expect to have a unifying classiÔ¨Åcation of all minimal
dominant solutions of (SDS) at ‚àûin the spirit of Theorem 6.139. In addition, the
nonuniqueness of minimal dominant solutions of (SDS) at ‚àû(in the minimal genus
Gmin) yields through Theorem 6.131(ii) the same property for all dominant solutions
at ‚àûin every other genus G.
In the case of an eventually controllable system (SDS), we obtain from Corol-
lary 6.142 and Theorem 6.143 an interesting characterization of the dominant
solutions of (SDS) at ‚àû.

532
6
Miscellaneous Topics on Symplectic Systems
Corollary 6.145 Assume that system (SDS) is nonoscillatory at ‚àûand eventually
controllable. Let ÀÜY be the recessive solution of (SDS) at ‚àû. Then a conjoined basis
Y of (SDS) is a dominant solution at ‚àûif and only if the Wronskian w( ÀÜY , Y) is
invertible. In particular, for every index N ‚àà[ ÀÜKmin, ‚àû)Z the principal solution
Y [N] of (SDS) at the index N is a dominant solution at ‚àû. More generally, for
any index N ‚àà[0, ‚àû)Z, the principal solution Y [N] at the index N is a dominant
solution at ‚àûif and only if the matrix ÀÜXN is invertible.
Proof If (SDS) is eventually controllable, then d‚àû= 0, and for every conjoined
basis Y of (SDS), the matrix Xk is eventually invertible, by (6.279). Therefore,
according to Remarks 6.136 and 6.137, there is only one genus G = Gmin = Gmax
of conjoined bases of (SDS). Let ÀÜY be the recessive solution of (SDS) at ‚àûand Y
be a conjoined basis of (SDS). The Ô¨Årst and second statements follow directly from
Corollary 6.142 and Theorem 6.143, respectively. Finally, for Y := Y [N] we have
w( ÀÜY, Y) = ÀÜXT
N, so that by the Ô¨Årst part Y [N] is a dominant solution of (SDS) at ‚àû
if and only if the matrix ÀÜXN is invertible.
‚äì‚äî
6.3.9
Limit Properties of Recessive and Dominant Solutions
In this subsection we derive characterizations of recessive solutions of (SDS)
at ‚àûin terms of a limit involving dominant solutions of (SDS) at ‚àû. This is
a generalization of the limit property (2.134) in Theorem 2.67 to the abnormal case,
in particular to an arbitrary genus G; compare with Remark 6.117.
Theorem 6.146 Assume that system (SDS) is nonoscillatory at ‚àûwith
ÀÜKmin
deÔ¨Åned in Remark 6.130. Let ÀÜY and Y be two conjoined bases of (SDS) from a given
genus G, and let N ‚àà[ ÀÜKmin, ‚àû)Z be such that ÀÜY and Y have constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Denote by ÀÜP , P ÀÜS‚àû, and PS‚àûtheir
associated projectors in (6.234), (6.238), and Remark 6.132. Then ÀÜY is a recessive
solution of (SDS) at ‚àûand rankP ÀÜS‚àûw( ÀÜY, Y) PS‚àû= n ‚àíd‚àûif and only if
lim
k‚Üí‚àûX‚Ä†
k ÀÜXk = V
with
Im V T = Im ( ÀÜP ‚àíP ÀÜS‚àû).
(6.431)
In this case Y is a dominant solution of (SDS) at ‚àû.
Proof Let ÀÜSk and Sk be the S-matrices in (6.236) which are associated with ÀÜY and Y
on [N, ‚àû)Z. Denote ÀÜN := w( ÀÜY, Y). By (6.259) and (6.258) in Remark 6.70 (with
Y (1) := ÀÜY and Y (2) := Y) and by w(Y, ÀÜY ) = ‚àí[w( ÀÜY, Y)]T , we have
Xk = ÀÜXk ( ÀÜP ÀÜM+ ÀÜSk ÀÜN),
ÀÜXk = Xk (P ÀÜM‚àí1‚àíSk ÀÜNT ),
k ‚àà[N, ‚àû)Z,
(6.432)

6.3
Symplectic Systems Without Controllability
533
where the matrix ÀÜM is invertible. By using the identities X‚Ä†
kXk = P and PSk = Sk
on [N, ‚àû)Z, it follows from (6.432) that
X‚Ä†
k ÀÜXk = P ÀÜM‚àí1 ‚àíSk ÀÜNT ,
k ‚àà[N, ‚àû)Z.
(6.433)
Let ÀÜT ‚àóand T ‚àóbe the matrices in (6.237) deÔ¨Åned through the minimal conjoined
bases ÀÜY ‚àóand Y ‚àó, which are contained in ÀÜY and Y on [N, ‚àû)Z, respectively, as in
the proof of Theorem 6.141. It follows by (6.348) that
T ‚àó= ( ÀÜM‚àó)T ÀÜT ‚àóÀÜM‚àó+ ( ÀÜM‚àó)T ÀÜN‚àó,
(6.434)
where ÀÜM‚àóis invertible and ÀÜN‚àó= w( ÀÜY ‚àó, Y ‚àó).
Suppose that ÀÜY is a recessive solution of (SDS) at ‚àûand (6.424) holds. Then
ÀÜT ‚àó= 0, and by (6.434), (6.426), and (6.424), we get
rank T ‚àó(6.434)
=
rank ÀÜN‚àó(6.426)
=
rankP ÀÜS‚àûÀÜNPS‚àû
(6.424)
=
n ‚àíd‚àû.
(6.435)
Therefore, Y is a dominant solution of (SDS) at ‚àûby DeÔ¨Ånition 6.122. This means
that Im T ‚àó= Im PS‚àûsince S‚àó
k = Sk on [N, ‚àû)Z, Im T ‚àó‚äÜIm PS‚àó‚àû= Im PS‚àû
by (6.239), and rank T ‚àó= n ‚àíd‚àûby (6.435). From (6.434) and ÀÜT ‚àó= 0, we know
that T ‚àó= ( ÀÜM‚àó)T ÀÜN‚àó= ( ÀÜN‚àó)T ÀÜM‚àó. Multiplying this equality by (T ‚àó)‚Ä† from the left
and by ( ÀÜM‚àó)‚àí1 from the right and using the identity (T ‚àó)‚Ä† T ‚àó= PS‚àûyield
PS‚àû( ÀÜM‚àó)‚àí1 = (T ‚àó)‚Ä†( ÀÜN‚àó)T .
(6.436)
Furthermore, by (6.433) and Theorem 6.124, we obtain
lim
k‚Üí‚àûX‚Ä†
k ÀÜXk = lim
k‚Üí‚àû(P ÀÜM‚àí1 ‚àíSk ÀÜNT ) = V := P ÀÜM‚àí1 ‚àí(T ‚àó)‚Ä† ÀÜNT .
(6.437)
We will show that Im V T = Im ( ÀÜP ‚àíP ÀÜS‚àû) = Im ÀÜP ‚à©Ker P ÀÜS‚àû. By using (6.437)
and the identities P ÀÜM‚àí1 ÀÜP = P ÀÜM‚àí1, ÀÜNT ÀÜP =
ÀÜNT , we get V ÀÜP = V , which
yields that Im V T
‚äÜIm ÀÜP . Moreover, the equality (T ‚àó)‚Ä†PS‚àû= (T ‚àó)‚Ä† and
formulas (6.425), (6.426), and (6.436) imply that
V P ÀÜS‚àû
(6.437)
=
P ÀÜM‚àí1P ÀÜS‚àû‚àí(T ‚àó)‚Ä†PS‚àûÀÜNT P ÀÜS‚àû
= PS‚àû( ÀÜM‚àó)‚àí1‚àí(T ‚àó)‚Ä†( ÀÜN‚àó)T (6.436)
=
0.
Thus, Im V T ‚äÜKer P ÀÜS‚àû. Hence, we proved that Im V T ‚äÜIm ÀÜP ‚à©Ker P ÀÜS‚àû.
Now we show the opposite inclusion Im ÀÜP ‚à©Ker P ÀÜS‚àû‚äÜIm V T , or equivalently
the inclusion Ker V ‚äÜKer ÀÜP ‚äïIm P ÀÜS‚àû. Let v ‚ààKer V . Then v can be uniquely
decomposed as v = v1 + v2 with v1 ‚ààKer ÀÜP and v2 ‚ààIm ÀÜP. The identity V ÀÜP = V

534
6
Miscellaneous Topics on Symplectic Systems
then implies that V v2 = V ÀÜP v = V v = 0, so that by the deÔ¨Ånition of V in (6.437)
we have [P ÀÜM‚àí1 ‚àí(T ‚àó)‚Ä† ÀÜNT ] v2 = V v2 = 0. Hence, P ÀÜM‚àí1v2 = (T ‚àó)‚Ä† ÀÜNT v2. The
vector w := P ÀÜM‚àí1v2 then satisÔ¨Åes w ‚ààIm (T ‚àó)‚Ä† = Im PS‚àû. By the equalities
ÀÜP ÀÜMP ÀÜM‚àí1 = ÀÜP , ÀÜP v2 = v2, PS‚àûw = w, and the Ô¨Årst formula in (6.425), we get
v2 = ÀÜP ÀÜMP ÀÜM‚àí1v2 = ÀÜP ÀÜMw = ÀÜP ÀÜMPS‚àûw = P ÀÜS‚àûÀÜM‚àów,
i.e.,
v2‚ààIm P ÀÜS‚àû.
This shows that v = v1 + v2 ‚ààKer ÀÜP ‚äïIm P ÀÜS‚àû, which completes the proof of this
direction.
Conversely, assume that (6.431) is satisÔ¨Åed. Denote by V0 := P ÀÜM‚àí1 ‚àíV , where
V is given in (6.431). Then by (6.433) we get Sk ÀÜNT ‚ÜíV0 as k ‚Üí‚àû. The equality
Sk = SkPS‚àûimplies the inclusion Ker PS‚àûÀÜNT ‚äÜKer V0, and similarly Sk =
PS‚àûSk implies that Im V0 ‚äÜIm PS‚àû. In particular, rank V0 ‚â§rank PS‚àûÀÜNT .
Moreover, by using the identities P ÀÜM‚àí1P ÀÜS‚àû= PS‚àû( ÀÜM‚àó)‚àí1 and V P ÀÜS‚àû= 0,
we get V0 P ÀÜS‚àû= PS‚àû( ÀÜM‚àó)‚àí1, which implies that Im PS‚àû‚äÜIm V0. Hence, we
proved the equality Im V0 = Im PS‚àû, so that rank V0 = rankPS‚àû= n ‚àíd‚àû. In
turn, the inequality n ‚àíd‚àû= rank V0 ‚â§rankPS‚àûÀÜNT holds. On the other hand,
we always have rankPS‚àûÀÜNT ‚â§rankPS‚àû= n ‚àíd‚àû. Thus, we conclude that
rankPS‚àûÀÜNT = n ‚àíd‚àû. The deÔ¨Ånition of T ‚àóin (6.237) now yields
PS‚àûÀÜNT = lim
k‚Üí‚àûS‚Ä†
kSk ÀÜNT = lim
k‚Üí‚àû(S‚àó
k )‚Ä†(Sk ÀÜNT ) = T ‚àóV0.
(6.438)
From (6.438) we then obtain the inequality
n ‚àíd‚àû= rankPS‚àûÀÜNT = rank T ‚àóV0 ‚â§rankT ‚àó.
This yields by the third condition in (6.394) that rank T ‚àó= n ‚àíd‚àû. Therefore,
Y is a dominant solution of (SDS) at ‚àû, by DeÔ¨Ånition 6.122. Moreover, by
using (6.426), (6.438), the symmetry of ÀÜN‚àó( ÀÜM‚àó)‚àí1, and the equalities V0 P ÀÜS‚àû=
PS‚àû( ÀÜM‚àó)‚àí1 and T ‚àóPS‚àû= T ‚àó, we get
ÀÜN‚àó( ÀÜM‚àó)‚àí1 (6.426)
=
( ÀÜM‚àó)T ‚àí1PS‚àûÀÜNT P ÀÜS‚àû
(6.438)
=
( ÀÜM‚àó)T ‚àí1T ‚àóV0 P ÀÜS‚àû
= ( ÀÜM‚àó)T ‚àí1T ‚àóPS‚àû( ÀÜM‚àó)‚àí1 = ( ÀÜM‚àó)T ‚àí1T ‚àó( ÀÜM‚àó)‚àí1.
This implies that T ‚àó= ( ÀÜM‚àó)T ÀÜN‚àó. From (6.434) we then obtain the equality
( ÀÜM‚àó)T ÀÜT ‚àóÀÜM‚àó= 0, i.e., ÀÜT ‚àó= 0, as the matrix
ÀÜM‚àóis invertible. Therefore, ÀÜY
is a recessive solution of (SDS) at ‚àû. Finally, Theorem 6.141 yields that (6.424)
holds, which completes the proof.
‚äì‚äî
Motivated by Theorem 2.67, we can now determine when is the limit V in (6.431)
equal to zero. It follows from condition (6.431) that this happens if and only if
ÀÜP = P ÀÜS‚àû, i.e., if and only if Theorem 6.146 is applied to the minimal genus Gmin.

6.3
Symplectic Systems Without Controllability
535
We note that if the system (SDS) is eventually controllable, then Corollary 6.147
below reduces to Theorem 2.67.
Corollary 6.147 Assume that system (SDS) is nonoscillatory at ‚àû. Let ÀÜY and Y be
two conjoined bases of (SDS) from the minimal genus Gmin. Then ÀÜY is a minimal
recessive solution of (SDS) at ‚àûand rankw( ÀÜY , Y) = n ‚àíd‚àûif and only if
lim
k‚Üí‚àûX‚Ä†
k ÀÜXk = 0.
(6.439)
In this case Y is a minimal dominant solution of (SDS) at ‚àû.
Proof Let ÀÜY and Y be as in the corollary, and let K ‚àà[ ÀÜKmin, ‚àû)Z be such that ÀÜY and
Y have constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû). Then ÀÜY
and Y are minimal conjoined bases on [N, ‚àû)Z. Moreover, let ÀÜP , P, P ÀÜS‚àû, and PS‚àû
be the corresponding orthogonal projectors in (6.234), (6.238), and Remark 6.132.
Then ÀÜP = P ÀÜS‚àû, P = PS‚àû, and P ÀÜS‚àûÀÜNPS‚àû= ÀÜN, where ÀÜN := w( ÀÜY , Y). The
statement now follows from Theorem 6.146 (with G := Gmin).
‚äì‚äî
Similarly, the limit in (6.431) involves an invertible Xk when Theorem 6.146 is
applied to the maximal genus Gmax.
Corollary 6.148 Assume that system (SDS) is nonoscillatory at ‚àûwith
ÀÜKmin
deÔ¨Åned in Remark 6.130. Let ÀÜY and Y be two maximal conjoined bases of (SDS),
and let N ‚àà[ ÀÜKmin, ‚àû)Z be such that ÀÜY and Y have invertible ÀÜXk and Xk on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). Let P ÀÜS‚àûand PS‚àûbe their
associated projectors in (6.238) and Remark 6.132. Then ÀÜY is a maximal recessive
solution of (SDS) at ‚àûand rankP ÀÜS‚àûw( ÀÜY, Y) PS‚àû= n ‚àíd‚àûif and only if
lim
k‚Üí‚àûX‚àí1
k
ÀÜXk = V
with
Im V T = Ker P ÀÜS‚àû.
In this case Y is a maximal dominant solution of (SDS) at ‚àû.
Proof The statement follows directly from Theorem 6.146 by using the fact that the
orthogonal projector ÀÜP in (6.234) associated with the maximal conjoined basis ÀÜY
satisÔ¨Åes ÀÜP = I.
‚äì‚äî
In the last result of this subsection, we present an extension of Theorem 6.146.
More precisely, we show that the limit in (6.431) always exists when Y is a dominant
solution of (SDS) at ‚àû. In this case we also obtain an additional information about
the structure of the space Im V T in (6.431).
Theorem 6.149 Assume that system (SDS) is nonoscillatory at ‚àûwith
ÀÜKmin
deÔ¨Åned in Remark 6.130. Let ÀúY and Y be two conjoined bases from a given genus
G, such that Y is a dominant solution of (SDS) at ‚àûand such that ÀúY and Y have
constant kernel on [N, ‚àû)Z and no forward focal points in (N, ‚àû) for some index
N ‚àà[ ÀÜKmin, ‚àû)Z. Let ÀúP , P ÀúS‚àû, ÀúT be the matrices in (6.234), (6.238), (6.237) deÔ¨Åned

536
6
Miscellaneous Topics on Symplectic Systems
through ÀúXk. Then the limit of X‚Ä†
k ÀúXk as k ‚Üí‚àûexists and satisÔ¨Åes
lim
k‚Üí‚àûX‚Ä†
k ÀúXk = V
with
Im V T = Im ÀúT ‚äïIm ( ÀúP ‚àíP ÀúS‚àû).
(6.440)
Proof We proceed similarly as in the proof of Theorem 6.146 (with ÀÜY := ÀúY), since
some of those arguments did not depend on the fact that ÀÜY was a recessive solution
of (SDS) at ‚àû. Let ÀúN := w( ÀúY, Y). Then, as in (6.432) and (6.433),
Xk = ÀúXk ( ÀúP ÀúM + ÀúSk ÀúN),
ÀúXk = Xk (P ÀúM‚àí1‚àíSk ÀúNT ), X‚Ä†
k ÀúXk = P ÀúM‚àí1‚àíSk ÀúNT
on [N, ‚àû)Z, where ÀúM is invertible. Let ÀúT ‚àóand T ‚àóbe the matrices in (6.237) deÔ¨Åned
through the minimal conjoined bases ÀúY ‚àóand Y ‚àó, which are contained in ÀúY and Y
on [N, ‚àû)Z, respectively. Then by (6.348) we have
T ‚àó= ( ÀúM‚àó)T ÀúT ‚àóÀúM‚àó+ ( ÀúM‚àó)T ÀúN‚àó,
(6.441)
as in (6.434). Since Y is a dominant solution of (SDS) at ‚àû, we get by (6.409) the
equality Im T ‚àó= Im T = Im PS‚àûwith T given in (6.237). Moreover, as in (6.437),
lim
k‚Üí‚àûX‚Ä†
k ÀúXk = lim
k‚Üí‚àû(P ÀúM‚àí1 ‚àíSk ÀúNT ) = V := P ÀúM‚àí1 ‚àí(T ‚àó)‚Ä† ÀúNT
(6.442)
with V ÀúP = V and Ker V ‚äÜKer ÀúP ‚äïIm P ÀúS‚àû. This shows that every vector
v ‚ààKer V can be uniquely decomposed as v = v1 + v2, where v1 ‚ààKer ÀúP
and v2 ‚ààIm P ÀúS‚àû. Then for the vector w := P ÀúM‚àí1v2, we have the equality
w = P ÀúM‚àí1P ÀúS‚àûv2 = PS‚àû( ÀúM‚àó)‚àí1v2 by (6.349). Therefore, w ‚ààIm PS‚àû, and
w = (T ‚àó)‚Ä† ÀúNT v2 by (6.442). Moreover, since (P ÀúS‚àûÀúM‚àó)‚Ä† = PS‚àû( ÀúM‚àó)‚àí1 holds
by (6.274), we then obtain
v2 = P ÀúS‚àûv2 = (P ÀúS‚àûÀúM‚àó) (P ÀúS‚àûÀúM‚àó)‚Ä†v2
= P ÀúS‚àûÀúM‚àóPS‚àû( ÀúM‚àó)‚àí1v2 = P ÀúS‚àûÀúM‚àów.
(6.443)
With the identities (T ‚àó)‚Ä†PS‚àû= (T ‚àó)‚Ä† and PS‚àûÀúNT P ÀúS‚àû= ( ÀúN‚àó)T , we then obtain
w = (T ‚àó)‚Ä† ÀúNT v2
(6.443)
=
(T ‚àó)‚Ä†PS‚àûÀúNT P ÀúS‚àûÀúM‚àów = (T ‚àó)‚Ä†( ÀúN‚àó)T ÀúM‚àów.
(6.444)
This expression for the vector w will be utilized in the subsequent proof. Next we
will derive the formula
Ker V =  Ker ÀúT ‚àó‚à©Im P ÀúS‚àû
 ‚äïKer ÀúP.
(6.445)

6.3
Symplectic Systems Without Controllability
537
Let v ‚ààKer V and let v1, v2, and w be its associated vectors deÔ¨Åned above. If
we multiply (6.444) by T ‚àófrom the left and use the identities T ‚àó(T ‚àó)‚Ä† = PS‚àû
and PS‚àû( ÀúN‚àó)T
= ( ÀúN‚àó)T , then we get T ‚àów = ( ÀúN‚àó)T ÀúM‚àów = ( ÀúM‚àó)T ÀúN‚àów.
By using (6.441) in the last equality, it follows that ( ÀúM‚àó)T ÀúT ‚àóÀúM‚àów = 0. The
invertibility of ÀúM‚àóand the equality ÀúT ‚àó= ÀúT ‚àóP ÀúS‚àûthen imply that ÀúT ‚àóP ÀúS‚àûÀúM‚àów =
0. Therefore, the vector v2 = P ÀúS‚àûÀúM‚àów satisÔ¨Åes v2 ‚ààKer ÀúT ‚àó‚à©Im P ÀúS‚àû. Hence,
the inclusion ‚äÜin (6.445) holds. Conversely, assume that v ‚àà Ker ÀúT ‚àó‚à©Im P ÀúS‚àû
‚äï
Ker ÀúP . Then we can write v = v1+v2 with v1 ‚ààKer ÀúT ‚àó‚à©Im P ÀúS‚àûand v2 ‚ààKer ÀúP .
Since V ÀúP = V , it follows from (6.442) that V v = V v1 = [P ÀúM‚àí1 ‚àí(T ‚àó)‚Ä† ÀúNT ] v1.
In turn, applying the identities v1
= P ÀúS‚àûv1, P ÀúM‚àí1P ÀúS‚àû
= PS‚àû( ÀúM‚àó)‚àí1
from (6.349), (T ‚àó)‚Ä†PS‚àû= (T ‚àó)‚Ä†, PS‚àûÀúNT P ÀúS‚àû= ( ÀúN‚àó)T , and (T ‚àó)‚Ä†T ‚àó= PS‚àû
then yields
V v = [P ÀúM‚àí1 ‚àí(T ‚àó)‚Ä† ÀúNT ] P ÀúS‚àûv1 = [PS‚àû( ÀúM‚àó)‚àí1 ‚àí(T ‚àó)‚Ä†( ÀúN‚àó)T ] v1
= (T ‚àó)‚Ä† [T ‚àó( ÀúM‚àó)‚àí1 ‚àí( ÀúN‚àó)T ] v1 = (T ‚àó)‚Ä†( ÀúM‚àó)T ÀúT ‚àóv1,
(6.446)
because T ‚àó( ÀúM‚àó)‚àí1 ‚àí( ÀúN‚àó)T = ( ÀúM‚àó)T ÀúT ‚àóby (6.441), the invertibility of ÀúM‚àó, and
the symmetry of ( ÀúM‚àó)T ÀúN‚àó. Since v1 ‚ààKer ÀúT ‚àó, formula (6.446) yields that V v = 0,
i.e., v ‚ààKer V . Thus, the inclusion ‚äáin (6.445) is satisÔ¨Åed as well. According
to Proposition 6.86, we have ÀúT = ÀúT ‚àó, and hence, the matrix ÀúT ‚àóin (6.445) can
be replaced by ÀúT . Finally, by (6.239) we have the inclusions Im ÀúT ‚äÜIm ÀúP and
Im ÀúT ‚à©Ker P ÀúS‚àû‚äÜIm P ÀúS‚àû‚à©Ker P ÀúS‚àû= {0}, which implies that
Im V T = ( Ker V )‚ä•=

Im ÀúT ‚äïKer P ÀúS‚àû

‚à©Im ÀúP = Im ÀúT ‚äï

Ker P ÀúS‚àû‚à©Im ÀúP

.
This shows the second condition in (6.440) and the proof is complete.
‚äì‚äî
The rank of the limiting matrix V in (6.440) can be connected with the notions
of rank and defect of the genus G, which we introduce in the following remark.
Remark 6.150 Let (SDS) be a nonoscillatory symplectic system at ‚àû. For every
genus G, we introduce its rank and defect as follows. The number rankG is deÔ¨Åned
as the rank of ÀúY, where ÀúY is any conjoined basis from G. This quantity is well
deÔ¨Åned, since any two conjoined bases from G have eventually the same image of
their Ô¨Årst components. Then n ‚àíd‚àû‚â§rankG ‚â§n. Also, we deÔ¨Åne the quantity
def G := n ‚àírank G, for which we have the inequalities 0 ‚â§def G ‚â§d‚àû. From
Theorem 6.149 it then follows that the matrix V in (6.440) satisÔ¨Åes
rank V = rank ÀúT + d‚àû‚àídef G,
(6.447)
since in this case rank V = rank ÀúT +rank ÀúP ‚àírankP ÀúS‚àû, while rank ÀúP = rankG and
rankP ÀúS‚àû= n ‚àíd‚àû. Formula (6.447) shows that the actual value of the rank of V
depends primarily on the rank of ÀúT , because the quantities d‚àûand def G are Ô¨Åxed
within one system (SDS) and its genus G. In particular, the rank of V is minimal

538
6
Miscellaneous Topics on Symplectic Systems
(equal to d‚àû‚àídef G) if and only if the conjoined basis ÀúY is a recessive solution
of (SDS) at ‚àû. This property is well-known in the controllable case, for which
d‚àû= 0 = def G and hence, rankV = rank ÀúT = 0 as in Theorem 2.67.
6.3.10
Reid‚Äôs Construction of Minimal Recessive Solution
In this subsection we present the so-called Reid construction of the (minimal)
recessive solution of (SDS) at ‚àûby means of a pointwise limit of certain
speciÔ¨Åcally chosen solutions of (SDS). First we derive a representation of the
minimal recessive solution of (SDS) at ‚àûin terms of any minimal conjoined basis
Y of (SDS). This result is based on the properties of the associated conjoined basis
¬ØY from Proposition 6.67 and Theorem 6.69.
Proposition 6.151 Assume that system (SDS) is nonoscillatory at ‚àû. Suppose that
N ‚àà[0, ‚àû)Z is an index such that d[N, ‚àû)Z = d‚àûand there exists a conjoined
basis of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points in
(N, ‚àû). Then a solution ÀÜY of (SDS) is a minimal recessive solution at ‚àûwith
respect to the interval [N, ‚àû)Z if and only if
ÀÜYk = Yk ‚àí¬ØYkT,
k ‚àà[N, ‚àû)Z,
(6.448)
for some minimal conjoined basis Y of (SDS) on [N, ‚àû)Z. Here ¬ØY is the conjoined
basis of (SDS) from Proposition 6.67 associated with Y, and the matrix T is deÔ¨Åned
in (6.237).
Proof Let N be as in the proposition. If ÀÜY is a minimal recessive solution at ‚àû
with respect to [N, ‚àû)Z, then it is a minimal conjoined basis on [N, ‚àû)Z, and the
associated matrix ÀÜT in (6.237) satisÔ¨Åes ÀÜT = 0. Formula (6.448) then holds trivially
with Y := ÀÜY. The opposite implication follows from the proof of Theorem 6.113,
where it is shown that Y ‚àí¬ØYT is a minimal recessive solution of (SDS) at ‚àû.
‚äì‚äî
Remark 6.152 In the proof of Theorem 6.113, we showed that the minimal
recessive solution ÀÜY of (SDS) at ‚àûin Proposition 6.151 has constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû). The uniqueness of the minimal
recessive solution at ‚àûin Theorem 6.113 and the deÔ¨Ånition of the index ÀÜKmin in
Remark 6.130 then imply that the index N appearing in Proposition 6.151 satisÔ¨Åes
N ‚àà[ ÀÜKmin, ‚àû)Z.
Next we state and prove the main result of this subsection. We recall that by ÀÜY min
we denote the minimal recessive solution of (SDS) at ‚àû.
Theorem 6.153 Let Y be a minimal conjoined basis of (SDS) on [N, ‚àû)Z with
d[N, ‚àû)Z = d‚àû, and let ¬ØY be the associated conjoined basis of (SDS) from
Proposition 6.67. Then there exists an index L ‚àà[N, ‚àû)Z such that ¬ØXk is invertible

6.3
Symplectic Systems Without Controllability
539
for all k ‚àà[L, ‚àû)Z and the solutions Y (j) of (SDS) given by the initial conditions
X(j)
j
= 0,
U(j)
j
= ‚àí¬ØXT ‚àí1
j
,
j ‚àà[L, ‚àû)Z,
(6.449)
are conjoined bases satisfying
ÀÜY min
k
= lim
j‚Üí‚àûY (j)
k
,
k ‚àà[0, ‚àû)Z.
(6.450)
Proof Let Y and ¬ØY be as in the theorem, and let P, Sk, PSk, and PS‚àûbe the matrices
in (6.234), (6.236), and (6.238), which correspond to Y. Since Y is a minimal
conjoined basis on [N, ‚àû)Z, we have the equality P = PS‚àû. Moreover, with
L := min{k ‚àà[N, ‚àû)Z, rankSk = n ‚àíd[N, ‚àû)Z = n ‚àíd‚àû}
(6.451)
it follows that PSk = PS‚àûfor every k ‚àà[L, ‚àû)Z. The equality Ker ¬ØXk =
Im (P ‚àíPSk) on [N, ‚àû)Z in Proposition 6.67(vi) then implies that Ker ¬ØXk = {0}
for all k ‚àà[L, ‚àû)Z, i.e., the matrix ¬ØXk is invertible on [L, ‚àû)Z. Consequently,
Proposition 6.67(viii) then reads as
S‚Ä†
k = ¬ØX‚àí1
k Xk PS‚àû= ¬ØX‚àí1
k Xk,
k ‚àà[L, ‚àû)Z.
(6.452)
Fix now an index j ‚àà[L, ‚àû)Z, and let Y (j) be the solution of (SDS) given by the
initial conditions (6.449). It is easy to check that Y (j) is a conjoined basis of (SDS).
Moreover, consider the constant matrices M(j) and N(j) such that
Y (j)
k
= YkM(j) + ¬ØYkN(j),
k ‚àà[0, ‚àû)Z.
(6.453)
Since the conjoined bases Y and ¬ØY are normalized by Proposition 6.67(i), the
fundamental matrix (Yk, ¬ØYk) in (6.453) is symplectic with the formula for its inverse
(Yk, ¬ØYk)‚àí1 = ‚àíJ (Yk, ¬ØYk)TJ , by Lemma 1.58(ii). Thus, M(j) = ‚àíw( ¬ØY, Y (j)) and
N(j) = w(Y, Y (j)), i.e.,
M(j) = ¬ØUT
k X(j)
k
‚àí¬ØXT
k U(j)
k ,
N(j) = XT
k U(j)
k
‚àíUT
k X(j)
k ,
k ‚àà[0, ‚àû)Z.
(6.454)
In particular, by evaluating (6.454) at k = j and using (6.449), we obtain that
M(j) = I,
N(j) = ‚àíXT
j ¬ØXT ‚àí1
j
(6.452)
=
‚àí(S‚Ä†
j )T = ‚àíS‚Ä†
j .
(6.455)
It follows from (6.455) that M(j) ‚ÜíI and N(j) ‚Üí‚àíT as j ‚Üí‚àû, where T is
the matrix in (6.237) associated with Y. Finally, the representation in (6.453) and
Proposition 6.151 then imply that for each k ‚àà[0, ‚àû)Z the limit of Y (j)
k
as j ‚Üí‚àû
exists and it is equal to ÀÜY min
k
. Therefore, formula (6.450) holds and the proof is
complete.
‚äì‚äî

540
6
Miscellaneous Topics on Symplectic Systems
Remark 6.154 The initial conditions in (6.449) mean that for each j ‚àà[N, ‚àû)Z,
the solution Y (j) is a conjoined basis, which is a constant nonsingular multiple of
the principal solution Y [j], namely, Y (j)
k
= Y [j]
k Mj for all k ‚àà[0, ‚àû)Z, where
Mj := ‚àí¬ØXT ‚àí1
j
. Then it follows from Remark 6.152 and Theorem 6.143 that for
every index j ‚àà[L, ‚àû)Z, the conjoined basis Y (j)
k
used in the Reid construction of
ÀÜY min in Theorem 6.153 is a (minimal) dominant solution of (SDS) at ‚àû.
In Theorem 6.143 we presented examples of minimal dominant solutions
of (SDS) at ‚àû. Based on formula (6.452), we can now prove that the conjoined
basis ¬ØY considered in Theorem 6.153 is an example of a maximal dominant solution
of (SDS) at ‚àû.
Proposition 6.155 Let Y be a minimal conjoined basis of (SDS) on an interval
[N, ‚àû)Z satisfying d[N, ‚àû)Z = d‚àû. Then the associated conjoined basis ¬ØY from
Proposition 6.67 is a maximal dominant solution of (SDS) at ‚àû.
Proof Let Rk, Sk, T , PS‚àûbe the matrices in (6.233), (6.236), (6.237), (6.238)
corresponding to Y. From the proof of Theorem 6.153, we know that the matrix
¬ØXk is invertible on the interval [L, ‚àû)Z, where L is deÔ¨Åned in (6.451). Let ¬ØS(L)
k
be
the matrix in (6.236) deÔ¨Åned through ¬ØXk on [L, ‚àû)Z, i.e.,
¬ØS(L)
k
:=
k‚àí1

j=L
¬ØX‚àí1
j+1Bj ¬ØXT ‚àí1
j
,
k ‚àà[L, ‚àû)Z.
(6.456)
We show that ¬ØS(L)
k
has a limit as k ‚Üí‚àû. First we note that equality (6.452) yields
S‚Ä†
kX‚Ä†
k = ¬ØX‚àí1
k XkX‚Ä†
k = ¬ØX‚àí1
k Rk on [L, ‚àû)Z. By using (6.456), Theorem 6.66(ii), and
the identities Sk = X‚Ä†
k+1BkX‚Ä†T
k
and SkS‚Ä†
k = S‚Ä†
kSk = PS‚àûon [L, ‚àû)Z, we get
for every k ‚àà[L, ‚àû)Z
¬ØS(L)
k
=
k‚àí1

j=L
¬ØX‚àí1
j+1Rj+1BjRj ¬ØXT ‚àí1
j
=
k‚àí1

j=L
S‚Ä†
j+1X‚Ä†
j+1BjX‚Ä†T
j S‚Ä†
j
=
k‚àí1

j=L
S‚Ä†
j+1(Sj) S‚Ä†
j =
k‚àí1

j=L
(S‚Ä†
j+1Sj+1S‚Ä†
j ‚àíS‚Ä†
j+1SjS‚Ä†
j )
=
k‚àí1

j=L
(PS‚àûS‚Ä†
j ‚àíS‚Ä†
j+1PS‚àû) = ‚àí
k‚àí1

j=L
(S‚Ä†
j ) = S‚Ä†
L ‚àíS‚Ä†
k.
Therefore, the limit of ¬ØS(L)
k
as k ‚Üí‚àûexists and is equal to S‚Ä†
L ‚àíT . By
Theorem 6.124 we conclude that ¬ØY is a (maximal) dominant solution of (SDS) at ‚àû.
‚äì‚äî

6.3
Symplectic Systems Without Controllability
541
Remark 6.156 Assume, as in Proposition 6.155, that [N, ‚àû)Z is an interval such
that there exists a minimal conjoined basis of (SDS) on [N, ‚àû)Z. From Theo-
rem 6.75 it then follows that the index L in (6.451) also satisÔ¨Åes
L = min{k ‚àà[N, ‚àû)Z, Y [N] has constant kernel on [k, ‚àû)Z},
(6.457)
where Y [N] is the principal solution of (SDS) at the index N.
Next we shall comment the existence and uniqueness of the limit in (6.450).
Remark 6.157 The proof of Theorem 6.153 solves also the problem, when the limit
in (6.450) exists and what is its value depending on the chosen initial conditions
in (6.449). More precisely, let Y be a minimal conjoined basis of (SDS) on
[N, ‚àû)Z with d[N, ‚àû)Z = d‚àû, and let ¬ØY be the associated conjoined basis
from Proposition 6.67. Assume that Y (j) is the solution of (SDS) given by the
initial conditions X(j)
j
= 0 and U(j)
j
= Wj with an invertible matrix Wj for all
j ‚àà[ ÀúL, ‚àû)Z for some ÀúL ‚àà[L, ‚àû)Z, where L is deÔ¨Åned in (6.457). Then for
k ‚àà[0, ‚àû)Z, the limit of Y (j)
k
as j ‚Üí‚àûexists if and only if Wj = ‚àí¬ØXT ‚àí1
j
Ej for
j ‚àà[L, ‚àû)Z, where Ej are invertible matrices such that the limit E := limj‚Üí‚àûEj
exists. In this case
lim
j‚Üí‚àûY (j)
k
= ÀÜY min
k
E,
k ‚àà[0, ‚àû)Z,
where ÀÜY min is the minimal recessive solution of (SDS) at ‚àûfrom Remark 6.130.
This statement follows from the proof of Theorem 6.153, in which the matrices M(j)
and N(j) in (6.454) are given by M(j) = Ej and N(j) = ‚àíS‚Ä†
j Ej.
In view of Proposition 6.155, we can deduce that the choice of initial condi-
tions (6.449) with ¬ØY being a maximal dominant solution of (SDS) at ‚àûis natural
and the only possible in order to guarantee the existence of the limit in (6.450).
Remark 6.158 Let N, L, Y, and ¬ØY be as in Remark 6.157. Let ÀúY be a conjoined
basis of (SDS) belonging to the maximal genus Gmax, i.e., the matrix ÀúXk is invertible
for every k ‚àà[ ÀúL, ‚àû)Z for some ÀúL ‚àà[L, ‚àû)Z. Without loss of generality, assume
that ¬ØY and ÀúY have no forward focal points in ( ÀúL, ‚àû). For j ‚àà[ ÀúL, ‚àû)Z, let Y (j) be
the solution of (SDS) given by the initial conditions X(j)
j
= 0 and U(j)
j
= ÀúXT ‚àí1
j
.
By applying Remark 6.157 with Wj := ÀúXT ‚àí1
j
and Ej := ‚àí¬ØXT
j ÀúXT ‚àí1
j
, we will show
that
limj‚Üí‚àûY (j) exists if and only if
ÀúY is a (maximal) dominant solution at ‚àû.

(6.458)
In this case the limit in (6.458) is the minimal recessive solution of (SDS) at
‚àû. Assume Ô¨Årst that ÀúY is a (maximal) dominant solution of (SDS) at ‚àû. From
Theorem 6.153 we know that the conjoined basis ¬ØY belongs to the maximal genus

542
6
Miscellaneous Topics on Symplectic Systems
Gmax. By Theorem 6.149 and Remark 6.150 (with G := Gmax, N := ÀúL, Y := ÀúY, and
ÀúY := ¬ØY), we then obtain
lim
j‚Üí‚àû(‚àíET
j ) = lim
j‚Üí‚àû
ÀúX‚àí1
j
¬ØXj = V,
rank V = rank ¬ØT + d‚àû,
(6.459)
where ¬ØT is the matrix in (6.237), which corresponds to ¬ØY on [ ÀúL, ‚àû)Z. Moreover,
from Proposition 6.155 it follows that ¬ØY is a (maximal) dominant solution of (SDS)
at ‚àû, so that rank ¬ØT = n ‚àíd‚àûby DeÔ¨Ånition 6.122. Hence, the matrix V in (6.459)
is invertible and the sequence Ej ‚ÜíE := ‚àíV T as j ‚Üí‚àûwith E being invertible.
Therefore, the limit in (6.458) exists, and it is equal to the minimal recessive solution
of (SDS) at ‚àû, by Remark 6.157.
Conversely, assume that the limit in (6.458) exists. This means that
E := lim
j‚Üí‚àûEj = ‚àílim
j‚Üí‚àû
¬ØXT
j ÀúXT ‚àí1
j
(6.460)
exists, by Remark 6.157. By using the fact that ¬ØY is a maximal dominant solution at
‚àû, we obtain (through Theorem 6.149 and Remark 6.150) that
F := lim
j‚Üí‚àû
¬ØX‚àí1
j
ÀúXj = ‚àílim
j‚Üí‚àûET ‚àí1
j
,
rankF = rank ÀúT + d‚àû
(6.461)
also exists, where ÀúT is the matrix in (6.237) associated with ÀúY on [ ÀúL, ‚àû)Z.
Identities (6.460) and (6.461) then imply that both the matrices E and F are
invertible with E = ‚àíF T ‚àí1. In turn, the limit in (6.458) is the minimal recessive
solution of (SDS) at ‚àû, again by Remark 6.157. Finally, from the second equality
in (6.461), it follows that rank ÀúT = rank F ‚àíd‚àû= n ‚àíd‚àû. Thus, ÀúY is a (maximal)
dominant solution of (SDS) at ‚àûby DeÔ¨Ånition 6.122.
In the last part of this section, we will discuss the dependence of the construction
of the minimal recessive solution ÀÜY min at ‚àûin Theorem 6.153 with respect to the
used initial data, in particular with respect to the choice of the conjoined bases ¬ØY,
Y, and the index N. First we observe that the representation of Y (j) in (6.453) with
M(j) = I and N(j) = ‚àíS‚Ä†
j from (6.455) does not depend on the choice of ¬ØY, since
in this case N(j) = PN(j) and the solution ¬ØYP is uniquely determined by Y on
[N, ‚àû)Z by Proposition 6.67(iv). Therefore,the construction of ÀÜY min in (6.450) does
not depend on the choice of ¬ØY either. Moreover, in the following remark, we will
show the independence of the construction in Theorem 6.153 also on the minimal
conjoined basis Y.
Remark 6.159 Assume now that in addition to Y in Theorem 6.153, we start
with another minimal conjoined basis Y ‚àóof (SDS) on [N, ‚àû)Z and let ¬ØY ‚àóbe
its associated conjoined basis from Proposition 6.67. By Lemma 6.100 (with
Y (1) := Y and Y (2) := Y ‚àó), we then have ¬ØX‚àó
k = ¬ØXkG for all k ‚àà[N, ‚àû)Z with
a constant invertible matrix G. Following (6.449) we construct for j ‚àà[L, ‚àû)Z the

6.3
Symplectic Systems Without Controllability
543
conjoined bases Y ‚àó(j) of (SDS) satisfying X‚àó(j)
j
= 0 and U‚àó(j)
j
= ‚àí( ¬ØX‚àó
j )T ‚àí1 =
‚àí¬ØXT ‚àí1
j
GT ‚àí1. Hence, we obtain by the uniqueness of solutions of (SDS) that
Y ‚àó(j)
k
= Y (j)
k
M on [0, ‚àû)Z with M := GT ‚àí1. This implies that
lim
j‚Üí‚àûY ‚àó(j)
k
= lim
j‚Üí‚àûY (j)
k
M = ÀÜY min
k
M,
k ‚àà[0, ‚àû)Z.
(6.462)
Thus, using a different minimal conjoined basis Y ‚àóof (SDS) in Theorem 6.153 leads
through (6.462) to a constant right nonsingular multiple of the minimal recessive
solution ÀÜY min. But since ÀÜY min is essentially unique by Theorem 6.113, it follows
that the construction in Theorem 6.153 does not depend on the choice of the minimal
conjoined basis Y.
Remark 6.160 Finally, we note that the result in Theorem 6.153 also does not
depend on the index N, i.e., on the interval [N, ‚àû)Z on which Y is a minimal
conjoined basis of (SDS). This follows immediately from the uniqueness of the
minimal recessive solution of (SDS) at ‚àûin Theorem 6.113. Hence, moving
the index N to the right yields a constant right nonsingular multiple in the
representation (6.450), similarly to formula (6.462) in the previous remark.
6.3.11
Additional Properties of Minimal Recessive Solution
In this subsection we derive some additional properties of the minimal recessive
solution ÀÜY min at ‚àû. These properties will be utilized in Sect. 6.4 in the singular
Sturmian theory for system (SDS). Our Ô¨Årst result represents a variant of Corol-
lary 6.147, but here we consider the conjoined bases ÀÜY min ‚ààGmin and Y ‚ààG to be
from different genera of conjoined bases of (SDS).
Theorem 6.161 Assume that (SDS) is nonoscillatory at ‚àû, and let ÀÜKmin be the
index deÔ¨Åned in Remark 6.130 for ÀÜY min. Then for any N ‚àà[ ÀÜNmin, ‚àû)Z, the
conjoined basis ¬ØY [‚àû] of (SDS), which is associated with ÀÜY min on [N, ‚àû)Z in
Proposition 6.67, is a maximal dominant solution of (SDS) at ‚àû, and it satisÔ¨Åes
lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1 ÀÜXmin
k
= 0.
(6.463)
Proof Fix N ‚àà[ ÀÜKmin, ‚àû)Z, and let ¬ØY [‚àû] be the conjoined basis of (SDS) from
Proposition 6.67, which is associated with ÀÜY min on [N, ‚àû)Z. Then (6.414) holds,
and the result in Proposition 6.155 (with Y := ÀÜY min) implies that ¬ØY [‚àû] is a maximal
dominant solution of (SDS) at ‚àû. It remains to prove (6.463). For simplicity of the
notation, we set ÀÜY := ÀÜY min and Y := ¬ØY [‚àû]. First we consider the maximal recessive
solution ÀÜY max of (SDS) at ‚àû, which contains ÀÜY on [N, ‚àû)Z with respect to the
orthogonal projector P ÀÜS‚àûdeÔ¨Åned in (6.238) through ÀÜY. Such a maximal recessive

544
6
Miscellaneous Topics on Symplectic Systems
solution of (SDS) at ‚àûexists by Theorem 6.115, and it can be chosen so that it
contains ÀÜY on [N, ‚àû)Z by Theorem 6.87 (with P = I = R and P ‚àó= P ÀÜS‚àû). Then
we have
ÀÜXk = ÀÜXmax
k
P ÀÜS‚àû,
k ‚àà[N, ‚àû)Z.
(6.464)
By Theorem 6.141 for the maximal genus G := Gmax (with the given Y and with
ÀÜY := ÀÜY max), we obtain that rank [P ÀÜS‚àûw( ÀÜY max, Y) PS‚àû] = n ‚àíd‚àû. In turn, by
Corollary 6.148 (with ÀÜY := ÀÜY max), we get
lim
k‚Üí‚àûX‚àí1
k
ÀÜXmax
k
= V
with
Im V T = Ker P ÀÜS‚àû.
(6.465)
Therefore, we conclude that
lim
k‚Üí‚àûX‚àí1
k
ÀÜXk
(6.464)
=
lim
k‚Üí‚àûX‚àí1
k
ÀÜXmax
k
P ÀÜS‚àû= V P ÀÜS‚àû
(6.465)
=
0,
since Im P ÀÜS‚àû= Ker V by (6.465). This shows that (6.463) holds.
‚äì‚äî
In the next statement, we apply Theorem 6.161 in order to derive a new property
of the Wronskians of the minimal recessive solution ÀÜY min of (SDS) at ‚àûwith
a conjoined basis Y and its associated conjoined basis ¬ØY. Here we use a symplectic
fundamental matrix [‚àû]
k
of (SDS), which is associated with the minimal recessive
solution ÀÜY min, i.e., following (6.228) we introduce the matrix
[‚àû]
k
:=

ÀÜY min
k
¬ØY [‚àû]
k

,
k ‚àà[N, ‚àû)Z,
w( ÀÜY min, ¬ØY [‚àû]) = I.
(6.466)
Then, as in Lemma 6.59, every conjoined basis Y of (SDS) can be uniquely
represented by a constant 2n √ó n matrix D‚àûsuch that
Yk = [‚àû]
k
D‚àû,
k ‚àà[0, ‚àû)Z,
JD‚àû=
w(Y [‚àû], Y)
w( ¬ØY [‚àû], Y)

.
(6.467)
Theorem 6.162 Assume that (SDS) is nonoscillatory at ‚àû. Let Y be a conjoined
basis of (SDS) with constant kernel on [N, ‚àû)Z and no forward focal points in
(N, ‚àû) for some N ‚àà[0, ‚àû)Z, and let ¬ØY be the conjoined basis of (SDS) from
Proposition 6.67 associated with Y on [N, ‚àû)Z. Then
w( ÀÜY min, Y) [w( ÀÜY min, ¬ØY)]T ‚â•0.
Proof First we observe that by Lemma 2.4 (with the choice ÀúY := ÀÜY min) the matrix
w( ÀÜY min, Y) [w( ÀÜY min, ¬ØY)]T is symmetric. Choose an index K ‚àà[N, ‚àû)Z so that
d[K, ‚àû)Z = d‚àûand the conjoined bases Y, ¬ØY, and ÀÜY min have constant kernel
on [K, ‚àû)Z and no forward focal points in (K, ‚àû). Let ¬ØY [‚àû] be the conjoined

6.3
Symplectic Systems Without Controllability
545
basis of (SDS) from Proposition 6.67 associated with ÀÜY min on the interval [K, ‚àû)Z,
i.e., ( ÀÜXmin
K )‚Ä† ¬ØX[‚àû]
K
= 0. Let D‚àûbe the representing matrix of Y in terms of the
symplectic fundamental matrix [‚àû]
k
, i.e., (6.228) with j = ‚àûand (6.467) hold.
As in the proof of Theorem 6.80, we split D‚àû=
 F
G

with F = ‚àíw( ¬ØY [‚àû], Y) and
G = w( ÀÜY min, Y). Then
Xk = ÀÜXmin
k
F + ¬ØX[‚àû]
k
G,
k ‚àà[0, ‚àû)Z.
(6.468)
From Theorem 6.161 we know that ¬ØY [‚àû] is a maximal dominant solution of (SDS)
at ‚àû, so that the matrix ¬ØX[‚àû]
k
is invertible for all k large enough. By applying
Theorem 6.161, we then obtain
lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1Xk
(6.468)
=
lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1 ÀÜXmin
k
F + G
(6.463)
=
G = w( ÀÜY min, Y).
(6.469)
By repeating the above argument with the conjoined basis ¬ØY instead of Y, we
conclude similarly as in (6.469) that
lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1 ¬ØXk = w( ÀÜY min, ¬ØY).
(6.470)
Therefore, upon combining (6.469) and (6.470), we get
w( ÀÜY min, Y) [w( ÀÜY min, ¬ØY)]T = lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1Xk ¬ØXT
k ( ¬ØX[‚àû]
k
)T ‚àí1 ‚â•0,
where the last inequality follows from Proposition 6.67(xii).
‚äì‚äî
6.3.12
Further Examples
In this subsection we present three examples, in which we illustrate the theory of
dominant solutions at ‚àû‚Äîtheir limit comparison with recessive solutions at ‚àûand
the Reid construction of the (minimal) recessive solution at ‚àûin terms of (maximal)
dominant solutions at ‚àû. For this purpose we will utilize Examples 6.119‚Äì6.121
from Sect. 6.3.6. In agreement with the notation in Remarks 6.110 and 6.123,
recessive solutions at ‚àûwill be denoted by ÀÜY and in the special case of minimal and
maximal recessive solutions at ‚àûby ÀÜY min and ÀÜY max. Similarly, dominant solutions
at ‚àûwill be denoted by Y and in the special case of minimal and maximal dominant
solutions at ‚àûby Y min and Y max.
Example 6.163 Let us continue the considerations initiated in Example 6.119.
Consider a nonoscillatory scalar system (SDS) with n = 1 and Sk ‚â°
 1 1
0 1

on
[0, ‚àû)Z. From Example 6.119 we know that d‚àû= 0 and that the conjoined basis

546
6
Miscellaneous Topics on Symplectic Systems
ÀÜYk ‚â°
 1
0

of (SDS) is the unique recessive solution at ‚àû. In this case we have
ÀÜKmin = 0. On the other hand, according to Corollary 6.145, the conjoined basis
Y = Y [0] =  k
1
 of (SDS) is a dominant solution at ‚àû, being at the same time
the principal solution of (SDS) at the index k = 0. Moreover, the solutions ÀÜY
and Y satisfy X‚àí1
k
ÀÜXk = 1/k ‚Üí0 as k ‚Üí‚àû, as we claim in formula (6.439)
of Corollary 6.147. Finally, the Reid construction of the recessive solution ÀÜY in
Theorem 6.153 is the following. With ¬ØY := Y we have N = 1, and for any index
j ‚àà[1, ‚àû)Z, the solution Y (j) of (SDS) from (6.449) satisfying the initial conditions
X(j)
j
= 0 and U(j)
j
= ‚àí¬ØXT ‚àí1
j
= ‚àí1/j is
X(j)
k
= (j ‚àík)/j,
U(j)
k
= ‚àí1/j,
k ‚àà[0, ‚àû)Z.
Therefore, Y (j)
k
‚Üí
 1
0

= ÀÜYk as j ‚Üí‚àûfor every k ‚àà[0, ‚àû)Z, as we claim in
formula (6.450).
Example 6.164 We continue with Example 6.120. Consider a nonoscillatory sys-
tem (SDS) with n ‚ààN and Sk ‚â°I2n on [0, ‚àû)Z. Then d[0, ‚àû)Z = d‚àû= n
and every conjoined basis of (SDS) is a (constant) recessive and also dominant
solution at ‚àûwith respect to the interval [0, ‚àû)Z. Therefore, we have ÀÜKmin = 0.
Every genus G of conjoined bases is associated with a unique orthogonal projector
P ‚ààRn√ón such that the conjoined basis ÀÜY = Y =

P
I‚àíP

is a recessive and
dominant solution at ‚àûbelonging to G. In addition, we have X‚Ä†
k ÀÜXk = P ‚Ä†P = P for
all k ‚Üí‚àû, so that V = P, ÀÜP = P, and P ÀÜS‚àû= 0 in formula (6.431). The special
choice of P = 0 then yields the solutions ÀÜY min = Y min =  0
I
, while the choice of
P = I yields the solutions ÀÜY max = Y max =  I
0
. Note that Y ‚àó=  I
I
 is another
maximal recessive and dominant solution at ‚àû, which illustrates the nonuniqueness
of these solutions in Remark 6.144.
Example 6.165 We continue with Example 6.121. Consider a nonoscillatory sys-
tem (SDS) with Ak = Dk ‚â°I3, Bk ‚â°diag{1, 0, 0}, and Ck ‚â°03 on [0, ‚àû)Z.
This system arises from the scalar system in Example 6.163 and from the system in
Example 6.164 with dimension two by a block diagonal construction. In this case
d[0, ‚àû)Z = d‚àû= 2 and ÀÜKmin = 0. From Theorems 6.118 and 6.133, we know that
some recessive and dominant solutions of (SDS) at ‚àûcan be constructed from the
recessive and dominant solutions at ‚àûin Examples 6.163 and 6.164 by the same
block diagonal procedure.
(a) First we analyze the minimal genus Gmin with rank r = n ‚àíd‚àû= 1. Then
ÀÜY min
k
=  diag{1, 0, 0}, diag{0, 1, 1} T ,
Y min
k
=

diag{k, 0, 0}, diag{1, 1, 1}
T .

6.3
Symplectic Systems Without Controllability
547
In this case (Xmin
k
)‚Ä† ÀÜXmin
k
= diag{1/k, 0, 0} ‚Üí03 as k ‚Üí‚àû, as we claim in
formula (6.439) of Corollary 6.147.
(b) Further, we examine the maximal genus Gmax, whose rank is r = n = 3. Then
we have
ÀÜY max
k
=

diag{1, 1, 1}, diag{0, 0, 0}
T ,
Y max
k
=

diag{k, 1, 1}, diag{1, 0, 0}
T ,
so that (Xmax
k
)‚Ä† ÀÜXmax
k
= diag{1/k, 1, 1} ‚ÜíV := diag{0, 1, 1} as k ‚Üí‚àû. In
this case we have P ÀÜS‚àû= diag{1, 0, 0} with Im V T = {0} √ó R2 = Ker P ÀÜS‚àû, as
we state in Corollary 6.148.
(c) Next we discuss three different genera with rank equal to r = 2. We note that
only two of them arise from the diagonal construction mentioned above. Let
G1 be the genus with rank r = 2, which contains the recessive and dominant
solutions at ‚àû
ÀÜY (1)
k
=

diag{1, 1, 0}, diag{0, 0, 1}
T ,
Y (1)
k
=  diag{k, 1, 0}, diag{1, 0, 1} T .
In Theorem 6.146 we then have (X(1)
k )‚Ä† ÀÜX(1)
k
= diag{1/k, 1, 0} ‚ÜíV :=
diag{0, 1, 0} as k ‚Üí‚àû, and ÀÜP = diag{1, 1, 0} and P ÀÜS‚àû= diag{1, 0, 0}. Let
G2 be the genus with rank r = 2 given by the recessive and dominant solutions
at ‚àû
ÀÜY (2)
k
=

diag{1, 0, 1}, diag{0, 1, 0} )T ,
Y (2)
k
=

diag{k, 0, 1}, diag{1, 1, 0} )T .
In this case we have (X(2)
k )‚Ä† ÀÜX(2)
k
= diag{1/k, 0, 1} ‚ÜíV := diag{0, 0, 1} as
k ‚Üí‚àû, and ÀÜP = diag{1, 0, 1} and P ÀÜS‚àû= diag{1, 0, 0}. Now we consider the
nondiagonal genus G3 with rank r = 2 deÔ¨Åned by the recessive and dominant
solutions at ‚àû
ÀÜY (3)
k
=
‚éõ
‚éù
‚éõ
‚éù
1 0 0
0 1 0
0 1 0
‚éû
‚é†,
‚éõ
‚éù
0 0
0
0 1
1
0 ‚àí1 ‚àí1
‚éû
‚é†
‚éû
‚é†
T
,
Y (3)
k
=
‚éõ
‚éù
‚éõ
‚éù
k 0 0
0 1 ‚àí1
0 1 ‚àí1
‚éû
‚é†,
‚éõ
‚éù
1 0 0
0 3 ‚àí2
0 1 ‚àí2
‚éû
‚é†
‚éû
‚é†
T
.

548
6
Miscellaneous Topics on Symplectic Systems
In Theorem 6.146 we then have
(X(3)
k )‚Ä† ÀÜX(3)
k
=
‚éõ
‚éù
1/k
0
0
0
1/2
0
0
‚àí1/2
0
‚éû
‚é†‚ÜíV :=
‚éõ
‚éù
0
0
0
0
1/2
0
0 ‚àí1/2
0
‚éû
‚é†
as k ‚Üí‚àû.
The orthogonal projectors
ÀÜP and P ÀÜS‚àûin (6.431) are given by
ÀÜP
=
diag{1, 1, 0}, P ÀÜS‚àû= diag{1, 0, 0}, and ÀÜP ‚àíP ÀÜS‚àû= diag{0, 1, 0}. Hence, in
this case we indeed have Im V T = Im ( ÀÜP ‚àíP ÀÜS‚àû), although V T Ã∏= ÀÜP ‚àíP ÀÜS‚àû.
(d) Finally, we present the Reid construction of the minimal recessive solution ÀÜY min
in Theorem 6.153. With Y := Y min given above in part (a) and with
¬ØYk =

diag{k ‚àí1, ‚àí1, ‚àí1}, diag{1, 0, 0}
T
we have N = 1 and L = 2. For j ‚àà[2, ‚àû)Z the solution in (6.449) is
Y (j)
k
=

diag{(j ‚àík)/(j ‚àí1), 0, 0}, diag{‚àí1/(j ‚àí1), 1, 1} )T ,
k ‚àà[0, ‚àû)Z.
Then we have Y (j)
k
‚Üí(diag{1, 0, 0}, diag{0, 1, 1})T = ÀÜY min
k
as j ‚Üí‚àûfor
every k ‚àà[0, ‚àû)Z, as we claim in formula (6.450) of Theorem 6.153.
6.4
Singular Sturmian Separation Theorems
In this section we establish singular Sturmian separation theorems for conjoined
bases of (SDS) on unbounded intervals. We will consider discrete intervals, which
are unbounded from above, unbounded from below, or unbounded at both endpoints.
By using the theory of recessive and dominant solutions of (SDS) at ‚àû, we
essentially improve the results on singular Sturmian theory in Theorem 4.39 and
Remark 4.40 and at the same time provide singular versions of the separation
theorems presented in Sects. 4.2.2 and 4.2.3.
For convenience and easier reference, we will use the notation
Yk =
Xk
Uk

,
ÀúYk =
 ÀúXk
ÀúUk

, Y [j]
k
=

X[j]
k
U[j]
k

, Y [‚àû]
k
:= ÀÜY min
k
, E :=
0
I

,
(6.471)
for generic conjoined bases Y and ÀúY of (SDS), for the principal solution Y [j]
of (SDS) at the index j (satisfying Y [j]
j
= E), and for the minimal recessive solution
ÀÜY min at ‚àû. For a conjoined basis Y of (SDS), the multiplicity of forward (or left)
focal point in (k, k + 1] and the multiplicity of the backward (or right) focal point

6.4
Singular Sturmian Separation Theorems
549
in [k, k + 1) will be denoted by
mL(k, k + 1] := m(k) = Œº(Yk+1, SkE) = Œº(Yk+1, Y [k]
k+1),
(6.472)
mR[k, k + 1) := m‚àó(k) = Œº‚àó(Yk, S‚àí1
k E) = Œº‚àó(Yk, Y [k+1]
k
),
(6.473)
where m(k) and m‚àó(k) are deÔ¨Åned by (4.3) and (4.6) and where we use the results
of Lemmas 4.7 and 4.8 to connect these multiplicities with the comparative index.
Moreover, using (4.10) and (4.11), we denote by
mL(M, N] := l(Y, M, N) =
N‚àí1

k=M
mL(k, k + 1],
mR[M, N) := l‚àó(Y, M, N) =
N‚àí1

k=M
mR[k, k + 1),
‚é´
‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é≠
(6.474)
the numbers of forward and backward focal points of Y, including their multiplic-
ities, in the intervals (M, N] and [M, N). We will use similar notation 7
mL(M, N]
and 7
mR[M, N) for the numbers of focal points of another conjoined basis ÀúY
of (SDS) in these intervals. We summarize the regular Sturmian separation theorems
from Sects. 4.1 and 4.2 as follows (see Theorems 4.23 and 4.24 and Corollary 4.6).
Proposition 6.166 For any conjoined bases Y and ÀúY of (SDS), we have
mL(M, N] ‚àí7
mL(M, N] = Œº(YN, ÀúYN) ‚àíŒº(YM, ÀúYM),
(6.475)
mR[M, N) ‚àí7
mR[M, N) = Œº‚àó(YM, ÀúYM) ‚àíŒº‚àó(YN, ÀúYN),
(6.476)
mL(M, N] + rankXN = mR[M, N) + rankXM.
(6.477)
Similarly as above, for the principal solution Y [j] of (SDS), we denote by
m[j]
L (M, N] and m[j]
R [M, N) the numbers of its forward and backward focal points
in the indicated intervals. Then we summarize the corresponding regular Sturmian
separation theorems as follows (see Theorems 4.34 and 4.35, formulas (4.62)
and (4.63), and Remark 4.28(iii)).
Proposition 6.167 For the principal solutions Y [M] and Y [N] of (SDS), we have
the identities
m[M]
L (M, N] = m[N]
R [M, N),
m[M]
R [M, N) = m[N]
L (M, N].
(6.478)
For any conjoined basis Y of (SDS), we have the estimates
m[M]
L (M, N] ‚â§mL(M, N] ‚â§m[N]
L (M, N],
(6.479)
m[N]
R [M, N) ‚â§mR[M, N) ‚â§m[M]
R [M, N).
(6.480)

550
6
Miscellaneous Topics on Symplectic Systems
For any conjoined bases Y and ÀúY of (SDS), we have the estimates
		 mL(M, N] ‚àí7
mL(M, N]
		 ‚â§rank X[M]
N
‚â§n,
(6.481)
		 mR[M, N) ‚àí7
mR[M, N)
		 ‚â§rank X[N]
M
‚â§n,
(6.482)
		 mL(M, N] ‚àí7
mR[M, N)
		 ‚â§rank X[N]
M
‚â§n.
(6.483)
In the following subsections, we will extend the results in Propositions 6.166
and 6.167 to unbounded intervals.
6.4.1
Multiplicity of Focal Point at InÔ¨Ånity
In this subsection we assume that system (SDS) is deÔ¨Åned on the interval [0, ‚àû)Z
and that it is nonoscillatory at ‚àû. As a new notion, we deÔ¨Åne for a conjoined
basis Y of (SDS) the multiplicity of its focal point at ‚àû. In this deÔ¨Ånition we
employ the matrix T , which is associated with Y through (6.237). We then prove
a representation formula for the multiplicity at ‚àûin terms of the Wronskian of Y
with the minimal recessive solution Y [‚àû] of (SDS) at ‚àû.
DeÔ¨Ånition 6.168 For a conjoined basis Y of (SDS), we deÔ¨Åne the quantity
mL(‚àû) := n ‚àíd‚àû‚àírankT = def T ‚àíd‚àû,
(6.484)
where T is the matrix in (6.237) associated with Y on an interval [N, ‚àû)Z satisfying
d[N, ‚àû)Z = d‚àû. Moreover, we say that Y has a focal point at ‚àûif mL(‚àû) ‚â•1,
and then mL(‚àû) is called its multiplicity.
Remark 6.169
(i) Estimate (6.277) shows that the quantity mL(‚àû) in (6.484) is correctly deÔ¨Åned
and that 0 ‚â§mL(‚àû) ‚â§n ‚àíd‚àû. Moreover, by Remark 6.126 the number
mL(‚àû) does not depend on the index N satisfying d[N, ‚àû)Z = d‚àû.
(ii) It follows from DeÔ¨Ånition 6.168 that a conjoined basis Y is a recessive solution
of (SDS) at ‚àûif and only if mL(‚àû) = n ‚àíd‚àû(i.e., mL(‚àû) is maximal).
In particular, for the minimal recessive solution Y [‚àû] of (SDS) at ‚àû, we have
m[‚àû]
L
(‚àû) = n ‚àíd‚àû. Similarly, a conjoined basis Y is a dominant solution
of (SDS) at ‚àûif and only if Y has no focal point at ‚àû(i.e., mL(‚àû) = 0 is
minimal).
(iii) The quantity mL(‚àû) is preserved under the relation being contained, since
this relation preserves the corresponding matrices Sk and hence T (see
DeÔ¨Ånition 6.82 and Proposition 6.86).
In the following result, we provide an alternative formula for the multiplicity
mL(‚àû) in DeÔ¨Ånition 6.168 in terms of the Wronskian of Y with the minimal

6.4
Singular Sturmian Separation Theorems
551
recessive solution Y [‚àû] at ‚àû. We recall the quantity rank G for a genus G of
conjoined bases of (SDS) deÔ¨Åned in Remark 6.150.
Theorem 6.170 Assume that system (SDS) is nonoscillatory at ‚àû, and let Y,
belonging to a genus G, be a conjoined basis of (SDS) with constant kernel on
[N, ‚àû)Z and no forward focal points in (N, ‚àû), where the index N ‚àà[0, ‚àû)Z is
such that d[N, ‚àû)Z = d‚àû. Then
Im [w(Y [‚àû], Y)]T = Im T ‚äïIm (P ‚àíPS‚àû),
(6.485)
rankT = rankw(Y [‚àû], Y) ‚àírankG + n ‚àíd‚àû,
(6.486)
mL(‚àû) = rankG ‚àírank w(Y [‚àû], Y),
(6.487)
where P, PS‚àû, T are the matrices in (6.234), (6.238), (6.237) associated with Y.
Proof Let the index N be as in the theorem. By Remark 6.126 the space Im T
is preserved, when N is replaced by any larger index. Therefore, without loss of
generality, we may assume that the index N ‚àà[0, ‚àû)Z is such that d[N, ‚àû)Z = d‚àû
holds and both conjoined bases Y and Y [‚àû] have constant kernel on [N, ‚àû)Z and
no forward focal points in (N, ‚àû), i.e., N ‚â•
ÀÜKmin according to Remark 6.130.
Let ¬ØY [‚àû] be the conjoined basis from Proposition 6.67 associated with Y [‚àû] on
[N, ‚àû)Z. Then by Theorem 6.161, we know that ¬ØY [‚àû] is a maximal dominant
solution of (SDS) at ‚àû. This yields that there exists an index M > N such that
¬ØY [‚àû] has no forward focal points in (M, ‚àû) and ¬ØX[‚àû]
k
is invertible on [M, ‚àû)Z.
Moreover, by (6.469) in the proof of Theorem 6.162, we have
lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1Xk = w(Y [‚àû], Y).
(6.488)
Let Rk for k ‚àà[N, ‚àû)Z be the orthogonal projector onto Im Xk deÔ¨Åned in (6.233).
If ¬ØY [‚àû]‚àó‚ààG is a conjoined basis of (SDS), which is contained in ¬ØY [‚àû] on [M, ‚àû)Z
according to DeÔ¨Ånition 6.82 and which belongs to the same genus G as Y, then
by (6.298) in Remark 6.83, we have the formula
( ¬ØX[‚àû]‚àó
k
)‚Ä† = ( ¬ØX[‚àû]
k
)‚àí1Rk,
k ‚àà[M, ‚àû)Z.
Moreover, ¬ØY [‚àû]‚àóis also a dominant solution of (SDS) at ‚àûby Proposition 6.127.
Therefore, upon applying Theorem 6.149 (with Y := ¬ØY [‚àû]‚àóand ÀúY := Y), we obtain
lim
k‚Üí‚àû( ¬ØX[‚àû]‚àó
k
)‚Ä†Xk = V
with
Im V T = Im T ‚äïIm (P ‚àíPS‚àû).
(6.489)
Consequently, by combining (6.488)‚Äì(6.489), we get
V = lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1RkXk = lim
k‚Üí‚àû( ¬ØX[‚àû]
k
)‚àí1Xk
(6.488)
=
w(Y [‚àû], Y).

552
6
Miscellaneous Topics on Symplectic Systems
This implies through the second part of (6.489) that the equality in (6.485) holds.
By evaluating the ranks of the subspaces in (6.485), we then get
rank w(Y [‚àû], Y) = rankT + rank P ‚àírankPS‚àû= rankT + rank G ‚àí(n ‚àíd‚àû),
which shows (6.486). Finally, formula (6.487) follows from (6.486) by using the
deÔ¨Ånition of the multiplicity mL(‚àû) in (6.484). The proof is complete.
‚äì‚äî
Remark 6.171 If system (SDS) is nonoscillatory at ‚àûand eventually controllable
near ‚àû, then rank Gmin = n, i.e., G = Gmin = Gmax holds for every genus G (see
Remark 6.58). Hence, in this case (6.484) and (6.487) yield that for every conjoined
basis Y of (SDS)
mL(‚àû) = def T = n ‚àírankw(Y [‚àû], Y) = def w(Y [‚àû], Y).
(6.490)
In order to count the numbers of focal points in unbounded intervals, we adopt
as in (6.474) for any M ‚àà[0, ‚àû)Z the notation
mL(M, ‚àû] := mL(M, ‚àû) + mL(‚àû),
mL(M, ‚àû) := l(Y, M, ‚àû) =
‚àû

k=M
mL(k, k + 1],
mR[M, ‚àû) := l‚àó(Y, M, ‚àû) =
‚àû

k=M
mR[k, k + 1),
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.491)
where we used the deÔ¨Ånitions of l(Y, M, ‚àû) and l‚àó(Y, M, ‚àû) in (4.87).
The following result is an analog of the formulas in (6.472), (6.473), and (6.230)
for the unbounded interval [N, ‚àû)Z. We will use the representation of conjoined
bases of (SDS) in terms of the symplectic fundamental matrix [‚àû]
k
in (6.466)
and (6.467).
Theorem 6.172 If Y is a conjoined basis of (SDS) with constant kernel on [N, ‚àû)Z
and no forward focal points in (N, ‚àû), then
mR[N, ‚àû) = 0 = Œº‚àó(YN, Y [‚àû]
N
),
(6.492)
mL(N, ‚àû] = mL(‚àû) = Œº(JD‚àû, JD[N]
‚àû),
(6.493)
where D‚àûand D[N]
‚àûare the constant matrices in (6.467) corresponding to Y and
to the principal solution Y [N].
Proof Since Y [‚àû] is a minimal conjoined basis near ‚àûand Y has constant kernel
on [N, ‚àû)Z and no forward focal points in (N, ‚àû), there exists K ‚àà[N, ‚àû)Z such
that both Y [‚àû] and Y have constant kernel on [K, ‚àû)Z and no forward focal points
in (K, ‚àû), and hence Im X[‚àû]
k
‚äÜIm Xk on [K, ‚àû)Z. This means by Theorem 6.80
(with ÀúY := Y [‚àû]) that Y [‚àû] is representable by Y on [K, ‚àû)Z, i.e., the inclusion

6.4
Singular Sturmian Separation Theorems
553
Im w(Y, Y [‚àû]) ‚äÜIm P or equivalently the equality P w(Y, Y [‚àû]) = w(Y, Y [‚àû])
holds. We Ô¨Årst prove (6.492). Let ¬ØY be the conjoined basis in Proposition 6.67
associated with Y on [N, ‚àû)Z (i.e., X‚Ä†
N ¬ØXN
= 0 holds). Similarly, let ¬ØY [‚àû]
be the conjoined basis in Proposition 6.67 associated with Y [‚àû] on [K, ‚àû)Z.
Following (6.466), we denote by k := (Y, ¬ØY) and [‚àû]
k
:= (Y [‚àû]
k
, ¬ØY [‚àû]
k
) the
corresponding symplectic fundamental matrices of (SDS), so that Yk = kJE and
Y [‚àû]
k
= [‚àû]
k
JE for all k ‚àà[0, ‚àû)Z. Then by Theorem 3.5(iii) (with Z := ‚àíJ ‚àí1
N
and ÀÜZ := ‚àíJ ‚àí1
N [‚àû]
N J ) we obtain
Œº‚àó(YN, Y [‚àû]
N
) = Œº‚àó(Z‚àí1E, Z‚àí1 ÀÜZE) = Œº(ZE, ÀÜZE)
= Œº

‚àíT
NJE, ‚àíT
NJ [‚àû]
N JE

= Œº
 XT
N
¬ØXT
N

,
w(Y, Y [‚àû])
w( ¬ØY , Y [‚àû])
 
,
(6.494)
where in the last equality we also applied the property Œº(‚àíY, ‚àíÀúY) = Œº(Y, ÀúY )
(Theorem 3.5(i) with C1 = C2 := ‚àíI). We now calculate the comparative index
in (6.494) by DeÔ¨Ånition 3.1. Since ¬ØXNP = 0 (see Proposition 6.67(iv)), we have
w = XN w( ¬ØY, Y [‚àû]) ‚àí¬ØXNP w(Y, Y [‚àû]) = XN w( ¬ØY, Y [‚àû]),
M = (I ‚àíRN) w = (I ‚àíRN) XN w( ¬ØY, Y [‚àû]) = 0,
T = I,
P = [w( ¬ØY, Y [‚àû])]T P w(Y, Y [‚àû]) = w(Y [‚àû], ¬ØY) [w(Y [‚àû], Y)]T .
Then by Theorem 6.162, we know that P ‚â•0, and hence the comparative index
in (6.494) is equal to rank M+ind P = 0. Therefore, we proved Œº‚àó(YN, Y [‚àû]
N
) = 0.
But since rank Xk is constant on [N, ‚àû)Z and Y has no forward focal points in
(N, ‚àû), the calculation (using Lemma 4.38)
mR[N, ‚àû)
(4.88)
=
mL(N, ‚àû) + lim
k‚Üí‚àûrank Xk ‚àírank XN = 0
then completes the proof of (6.492). To prove (6.493), we start with the facts that
D‚àû= ([‚àû]
N )‚àí1YN = ([‚àû]
N )‚àí1NJE,
D[N]
‚àû= ([‚àû]
N )‚àí1E,
w(JD‚àû, JD[N]
‚àû) = Y T
N JE = XT
N.
Therefore, we obtain by Theorem 3.5(v) (with Y := JD‚àûand ÀúY := JD[N]
‚àû)
Œº(JD‚àû, JD[N]
‚àû) = rank XN ‚àíŒº(JD[N]
‚àû, JD‚àû).
(6.495)

554
6
Miscellaneous Topics on Symplectic Systems
Now rank XN = rankG and the last term in (6.495) we calculate by Theorem 3.5(iii)
(with Z := J ([‚àû]
N )‚àí1 and ÀÜZ := J ([‚àû]
N )‚àí1NJ ). Then
Œº(JD‚àû, JD[N]
‚àû) = rankG ‚àíŒº

J ([‚àû]
N )‚àí1E, J ([‚àû]
N )‚àí1NJE

(iii)
= rankG ‚àíŒº‚àó
‚àí[‚àû]
N JE, NJE

(i)= rankG ‚àíŒº‚àó(Y [‚àû]
N
, YN)
(v)
= rankG ‚àírank w(Y [‚àû]
N
, YN) + Œº‚àó(YN, Y [‚àû]
N
)
(6.492)
=
rankG ‚àírank w(YN, Y [‚àû]
N
)
(6.487)
=
mL(‚àû).
where above the equality signs we indicate the application of the corresponding
properties (iii) and (i) (with C1 = ‚àíC2 := ‚àíI) and (v) of Theorem 3.5. Observe
that in the last equality we applied Theorem 6.170. Finally, since Y has no forward
focal points in (N, ‚àû), it follows from (6.491) that mL(N, ‚àû] = mL(‚àû), which
completes the proof of (6.493).
‚äì‚äî
6.4.2
Singular Separation Theorems I
In this subsection we derive proper extensions of Propositions 6.166 and 6.167 to
unbounded intervals with singular right endpoint. Our results show that, instead of
considering the principal solution Y [N] at the right endpoint k = N, we have to
use the minimal recessive solution Y [‚àû] at ‚àûin the singular case. For convenience
we will utilize the notation in (6.491) for the numbers of forward and backward
focal points of conjoined bases Y, ÀúY, Y [M], Y [‚àû] in the corresponding unbounded
intervals. Our Ô¨Årst result is a singular version of Proposition 6.166.
Theorem 6.173 (Singular Sturmian Separation Theorem)
Assume that sys-
tem (SDS) is nonoscillatory at ‚àû. Then for any conjoined bases Y and ÀúY of (SDS),
we have the equalities
mL(M, ‚àû] ‚àí7
mL(M, ‚àû] = Œº(JD‚àû, J ÀúD‚àû) ‚àíŒº(YM, ÀúYM)
(6.496)
mR[M, ‚àû) ‚àí7
mR[M, ‚àû) = Œº‚àó(YM, ÀúYM) ‚àíŒº‚àó(JD‚àû, J ÀúD‚àû),
(6.497)
mL(M, ‚àû] + rank w(Y [‚àû], Y) = mR[M, ‚àû) + rank XM,
(6.498)
where D‚àûand ÀúD‚àûare the constant matrices in (6.467) corresponding to Y and ÀúY,
respectively.
Proof Since system (SDS) is nonoscillatory at ‚àû, we have mL(M, ‚àû] < ‚àûand
7
mL(M, ‚àû] < ‚àû. Then we can choose N ‚àà[M, ‚àû)Z such that both conjoined

6.4
Singular Sturmian Separation Theorems
555
bases Y and ÀúY have constant kernel on [N, ‚àû)Z and no forward focal points in
(N, ‚àû). First we will prove that
mL(N, ‚àû] ‚àí7
mL(N, ‚àû] = Œº(JD‚àû, J ÀúD‚àû) ‚àíŒº(YN, ÀúYN)
(6.499)
mR[N, ‚àû) ‚àí7
mR[N, ‚àû) = Œº‚àó(YN, ÀúYN) ‚àíŒº‚àó(JD‚àû, J ÀúD‚àû).
(6.500)
Let [‚àû]
k
be the symplectic fundamental matrix of (SDS) in (6.467) with the
associated matrices D‚àû, ÀúD‚àû, D[N]
‚àû, and D[‚àû]
‚àû
= JE for Y, ÀúY, Y [N], and Y [‚àû],
respectively. Further, consider the symplectic fundamental matrices k and Àúk
of (SDS) such that kE = Yk and ÀúkE = ÀúYk on [0, ‚àû)Z, i.e., k = (‚àó, Yk)
and Àúk = (‚àó, ÀúYk) according to the deÔ¨Ånition of E in (6.471). DeÔ¨Åne the symplectic
matrix R := ‚àíJ ([‚àû]
N )‚àí1. Then (6.467) yields
JD‚àû= ‚àíR NE,
J ÀúD‚àû= ‚àíR ÀúNE,
JD[N]
‚àû= ‚àíRE.
(6.501)
By Theorem 6.172 and by the transformation formula (3.16) in Theorem 3.6 for the
comparative index (with W := ‚àíR, Z := N, ÀÜZ := ÀúN), we get
mL(N, ‚àû] ‚àí7
mL(N, ‚àû]
(6.493)
=
Œº(JD‚àû, JD[N]
‚àû) ‚àíŒº(J ÀúD‚àû, JD[N]
‚àû)
(6.501)
=
Œº(‚àíR NE, ‚àíRE) ‚àíŒº(‚àíR ÀúNE, ‚àíRE)
(3.16)
= Œº(‚àíR NE, ‚àíR ÀúNE) ‚àíŒº(NE, ÀúNE)
(6.501)
=
Œº(JD‚àû, J ÀúD‚àû) ‚àíŒº(YN, ÀúYN),
showing (6.499). Next, we have
Y [‚àû]
N
= R‚àí1E,
YN = NE,
ÀúYN = ÀúNE.
(6.502)
By Theorem 6.172 and by the transformation formula (3.27) for the dual compara-
tive index (with W := R‚àí1, Z := R N, ÀÜZ := R ÀúN), we get
mR[N, ‚àû) ‚àí7
mR[N, ‚àû)
(6.492)
=
Œº‚àó(YN, Y [‚àû]
N
) ‚àíŒº‚àó( ÀúYN, Y [‚àû]
N
)
(6.502)
=
Œº‚àó(R‚àí1R NE, R‚àí1E) ‚àíŒº‚àó(R‚àí1R ÀúNE, R‚àí1E)
(3.27)
=
Œº‚àó(R‚àí1R NE, R‚àí1R ÀúNE) ‚àíŒº‚àó(R NE, R ÀúNE)
(6.501), (6.502)
=
Œº‚àó(YN, ÀúYN) ‚àíŒº‚àó(‚àíJD‚àû, ‚àíJ ÀúD‚àû)
= Œº‚àó(YN, ÀúYN) ‚àíŒº‚àó(JD‚àû, J ÀúD‚àû),

556
6
Miscellaneous Topics on Symplectic Systems
showing (6.500), where in the last step we used that Œº‚àó(‚àíY, ‚àíÀúY) = Œº‚àó(Y, ÀúY ) (see
Theorem 3.5(i) with C1 = C2 = ‚àíI). Next we combine the above formulas (6.499)
and (6.500) with the formulas on the bounded interval in Proposition 6.166 to get
mL(M, ‚àû] ‚àí7
mL(M, ‚àû] = mL(M, N] + mL(N, ‚àû] ‚àí7mL(M, N] ‚àí7
mL(N, ‚àû]
(6.475), (6.499)
=
Œº(JD‚àû, J ÀúD‚àû) ‚àíŒº(YM, ÀúYM),
mR[M, ‚àû) ‚àí7
mR[M, ‚àû) = mR[M, N) + mR[N, ‚àû) ‚àí7
mR[M, N) ‚àí7
mR[N, ‚àû)
(6.476), (6.500)
=
Œº‚àó(YM, ÀúYM) ‚àíŒº‚àó(JD‚àû, J ÀúD‚àû).
Therefore, we proved (6.496) and (6.497). Finally, since the index N is chosen so
that mL(N, ‚àû) = 0 and mR[N, ‚àû) = 0, it follows that mL(M, N] = mL(M, ‚àû)
and mR[M, N) = mR[M, ‚àû) and rank XN = rankG, where G is the genus of Y
near ‚àû. By (6.477) in Proposition 6.166, we then get
mL(M, ‚àû) + rank G = mR[M, ‚àû) + rankXM,
which upon substituting for rankG
= mL(‚àû) + rankw(Y [‚àû], Y) from for-
mula (6.487) in Theorem 6.170 yields the required equation (6.498).
‚äì‚äî
The result in Theorem 4.39, or equivalently the limiting case of (6.475)
and (6.476) as N ‚Üí‚àû, implies the equalities
mL(M, ‚àû) ‚àí7
mL(M, ‚àû) = Œº‚àû(Y, ÀúY ) ‚àíŒº(YM, ÀúYM),
(6.503)
mR[M, ‚àû) ‚àí7
mR[M, ‚àû) = Œº‚àó(YM, ÀúYM) ‚àíŒº‚àó
‚àû(Y, ÀúY ),
(6.504)
where the numbers Œº‚àû(Y, ÀúY ) and Œº‚àó
‚àû(Y, ÀúY) are deÔ¨Åned, respectively, as the limits
Œº‚àû(Y, ÀúY ) := lim
k‚Üí‚àûŒº(Yk, ÀúYk),
Œº‚àó
‚àû(Y, ÀúY ) := lim
k‚Üí‚àûŒº‚àó(Yk, ÀúYk);
(6.505)
see also (4.91) and (4.93). In other words, Œº‚àû(Y, ÀúY ) and Œº‚àó
‚àû(Y, ÀúY ) are deÔ¨Åned
by equations (6.503) and (6.504), since the quantities mL(M, ‚àû), 7mL(M, ‚àû) and
mR[M, ‚àû), 7
mR[M, ‚àû) are Ô¨Ånite for a nonoscillatory system (SDS) at ‚àû. The
results in Theorem 6.173 then allow to calculate these numbers explicitly as values
of the comparative index, which was not possible by the methods of Sect. 4.2.4.
Corollary 6.174 Assume that system (SDS) is nonoscillatory at ‚àû. Then for any
conjoined bases Y and ÀúY of (SDS), the limits in (6.505) satisfy
Œº‚àû(Y, ÀúY ) = Œº(JD‚àû, J ÀúD‚àû) ‚àímL(‚àû) + 7
mL(‚àû),
(6.506)
Œº‚àó
‚àû(Y, ÀúY ) = Œº‚àó(JD‚àû, J ÀúD‚àû),
(6.507)

6.4
Singular Sturmian Separation Theorems
557
where D‚àûand ÀúD‚àûare the constant matrices in (6.467) corresponding to Y and ÀúY,
respectively.
Proof We use identities (6.503) and (6.504) to derive
Œº‚àû(Y, ÀúY) (6.503)
=
mL(M, ‚àû) ‚àí7
mL(M, ‚àû) + Œº(YM, ÀúYM)
= mL(M, ‚àû] ‚àímL(‚àû) ‚àí7
mL(M, ‚àû] + 7
mL(‚àû) + Œº(YM, ÀúYM)
(6.496)
=
Œº(JD‚àû, J ÀúD‚àû) ‚àímL(‚àû) + 7
mL(‚àû),
Œº‚àó
‚àû(Y, ÀúY) (6.504)
=
Œº‚àó(YM, ÀúYM) ‚àímR[M, ‚àû) + 7
mR[M, ‚àû) (6.497)
=
Œº‚àó(JD‚àû, J ÀúD‚àû),
which shows the statement.
‚äì‚äî
We also note that the formulas in (6.506) and (6.507) are new even for
a controllable system (SDS) near ‚àû.
Remark 6.175 Given a conjoined basis Y of (SDS), equation (6.506) allows to
connect the limit Œº‚àû(Y, Y [‚àû]) with the multiplicity mL(‚àû) and with the rank of
the associated matrix T . Namely, by taking ÀúY := Y [‚àû], we get ÀúD‚àû= D[‚àû]
‚àû
= JE
(see the proof of Theorem 6.173), and then the property Œº(Y, ‚àíE) = 0 implies
that Œº(JD‚àû, JD[‚àû]
‚àû) = Œº(JD‚àû, ‚àíE) = 0. Consequently, equation (6.506) and
Remark 6.169 yield the formula
Œº‚àû(Y, Y [‚àû])
(6.506)
=
n ‚àíd‚àû‚àímL(‚àû)
(6.484)
=
rankT.
(6.508)
The results in Theorem 6.173 allow to present exact formulas for the numbers
of focal points of a given conjoined basis Y of (SDS) in terms of the corresponding
numbers of focal points of the the minimal recessive solution Y [‚àû] of (SDS) at ‚àû
and of the principal solution Y [M].
Corollary 6.176 Assume that system (SDS) is nonoscillatory at ‚àû. Then for any
conjoined basis Y of (SDS), we have the equalities
mL(M, ‚àû] = m[M]
L (M, ‚àû] + Œº

JD‚àû, JD[M]
‚àû

,
(6.509)
mL(M, ‚àû] = m[‚àû]
L
(M, ‚àû] ‚àíŒº(YM, Y [‚àû]
M ),
(6.510)
mR[M, ‚àû) = m[M]
R [M, ‚àû) ‚àíŒº‚àóJD‚àû, JD[M]
‚àû
,
(6.511)
mR[M, ‚àû) = m[‚àû]
R [M, ‚àû) + Œº‚àó(YM, Y [‚àû]
M ),
(6.512)
where D‚àûand D[M]
‚àû
are the constant matrices in (6.467) corresponding to Y and
Y [M], respectively.
Proof For (6.509) and (6.511), we apply (6.496) and (6.497) with ÀúY := Y [M]. In
this case ÀúD‚àû= D[M]
‚àû
and Œº(YM, E) = 0 = Œº‚àó(YM, E). For (6.510) and (6.512),

558
6
Miscellaneous Topics on Symplectic Systems
we apply (6.496) and (6.497) with ÀúY := Y [‚àû] and ÀúD‚àû= D[‚àû]
‚àû
= JE. In this case
Œº(JD‚àû, ‚àíE) = 0 = Œº‚àó(JD‚àû, ‚àíE).
‚äì‚äî
In the following result, we relate the numbers of forward and backward focal
points of the minimal recessive solution Y [‚àû] at ‚àû, resp., of the principal solution
Y [M], according to equalities (6.498), (6.509), and (6.512).
Corollary 6.177 Assume that system (SDS) is nonoscillatory at ‚àû. Then
m[‚àû]
L
(M, ‚àû] = m[‚àû]
R [M, ‚àû) + rank X[‚àû]
M ,
(6.513)
m[M]
R [M, ‚àû) = m[M]
L (M, ‚àû] + rankX[‚àû]
M ,
(6.514)
m[‚àû]
L
(M, ‚àû] = m[M]
L (M, ‚àû] + rankX[‚àû]
M ,
(6.515)
m[M]
R [M, ‚àû) = m[‚àû]
R [M, ‚àû) + rank X[‚àû]
M .
(6.516)
Proof For (6.513) we apply (6.498) with Y
:= Y [‚àû], while for (6.514) we
apply (6.498) with Y := Y [M], where we utilize the fact that w(Y [‚àû], Y [M]) =
(X[‚àû]
M )T . Next, for (6.515) we use (6.509) with Y := Y [‚àû] and D‚àû= D[‚àû]
‚àû
= JE.
Since by (6.467) the upper block of JD[M]
‚àû
is equal to w(Y [‚àû], Y [M]) = (X[‚àû]
M )T ,
it follows by Œº(E, Y) = rank X (see Remark 3.4(iii)) that Œº

JD‚àû, JD[M]
‚àû

=
Œº(‚àíE, JD[M]
‚àû)
=
rank X[‚àû]
M
and hence, (6.509) implies (6.515). Finally,
for (6.516) we use (6.512) with Y := Y [M], where Œº‚àó(E, Y [‚àû]
M ) = rankX[‚àû]
M
according to the property Œº‚àó(E, Y) = rank X.
‚äì‚äî
In the next result, we present a complete singular version of Proposition 6.167.
Theorem 6.178 (Singular Sturmian Separation Theorem)
Assume that sys-
tem (SDS) is nonoscillatory at ‚àû. Then for the minimal recessive solution Y [‚àû]
at ‚àûand for the principal solution Y [M], we have the identities
m[M]
L (M, ‚àû] = m[‚àû]
R [M, ‚àû),
m[M]
R [M, ‚àû) = m[‚àû]
L
(M, ‚àû].
(6.517)
For any conjoined basis Y of (SDS), we have the estimates
m[M]
L (M, ‚àû] ‚â§mL(M, ‚àû] ‚â§m[‚àû]
L
(M, ‚àû],
(6.518)
m[‚àû]
R [M, ‚àû) ‚â§mR[M, ‚àû) ‚â§m[M]
R [M, ‚àû).
(6.519)
For any conjoined bases Y and ÀúY of (SDS), we have the estimates
		 mL(M, ‚àû] ‚àí7
mL(M, ‚àû]
		 ‚â§rankX[‚àû]
M
‚â§n,
(6.520)
		 mR[M, ‚àû) ‚àí7
mR[M, ‚àû)
		 ‚â§rankX[‚àû]
M
‚â§n,
(6.521)
		 mL(M, ‚àû] ‚àí7
mR[M, ‚àû)
		 ‚â§rankX[‚àû]
M
‚â§n.
(6.522)

6.4
Singular Sturmian Separation Theorems
559
Proof The equalities in (6.517) follow by subtracting (6.514) and (6.516), respec-
tively, by subtracting (6.514) and (6.515). Next, the comparative index and the
dual comparative index are nonnegative, so that estimate (6.518) is a consequence
of (6.509) and (6.510). Similarly, estimate (6.519) follows from (6.512) and (6.511).
Finally, the lower and upper bounds in (6.518) and (6.519) differ by the same
number rank X[‚àû]
M
(by Corollary 6.177). Therefore, the inequalities in (6.520)‚Äì
(6.522) follow from the estimates in (6.518) and (6.519).
‚äì‚äî
We note that the lower and upper bounds in (6.518)‚Äì(6.522)are optimal in a sense
that they cannot be improved by better bounds, which would be independent on
the arbitrarily chosen conjoined bases Y and ÀúY. In this respect the two quantities
in (6.517) together with the number rank X[‚àû]
M
represent important parameters or
characteristics of the symplectic system (SDS) on the given unbounded interval
[M, ‚àû)Z.
In the remaining part of this subsection, we will study the multiplicities of focal
points of conjoined bases of (SDS) in the open interval (M, ‚àû). The above problem
is closely related with limiting the inequalities in Proposition 6.167 for N ‚Üí‚àû. In
particular, we will see that by taking N ‚Üí‚àûin Proposition 6.167, we do not obtain
the statements in Theorem 6.178. First we consider the upper bound in (6.479). We
have
lim
N‚Üí‚àûm[N]
L (M, N]
(6.478)
=
lim
N‚Üí‚àûm[M]
R [M, N)
(6.491)
=
m[M]
R [M, ‚àû)
(6.517)
=
m[‚àû]
L
(M, ‚àû],
(6.523)
which is the correct upper bound obtained in (6.518). Another expression of this
limit can be obtained as
lim
N‚Üí‚àûm[N]
L (M, N] = lim
N‚Üí‚àû
!m[M]
L (M, N] + rank X[M]
N
"
(6.491)
=
m[M]
L (M, ‚àû) + rank G[M],
(6.524)
where the Ô¨Årst equality follows from (6.475) with ÀúY := Y [M] and where G[M] is the
genus of Y [M] near ‚àû. On the other hand, by considering the lower bound in (6.480),
we get
lim
N‚Üí‚àûm[N]
R [M, N)
(6.478)
=
lim
N‚Üí‚àûm[M]
L (M, N]
(6.491)
=
m[M]
L (M, ‚àû)
= m[M]
L (M, ‚àû] ‚àím[M]
L (‚àû)
(6.517)
=
m[‚àû]
R
[M, ‚àû) ‚àím[M]
L (‚àû),
which is in general smaller than the optimal lower bound in (6.519). Moreover, it is
equal to the optimal lower bound m[‚àû]
R
[M, ‚àû) if and only if m[M]
L (‚àû) = 0, i.e., if
and only if the principal solution Y [M] is a dominant solution of (SDS) at inÔ¨Ånity

560
6
Miscellaneous Topics on Symplectic Systems
(by Remark 6.169(ii)). Altogether, limiting the inequalities in (6.480) for N ‚Üí‚àû,
we obtain the estimate
m[‚àû]
R
[M, ‚àû) ‚àím[M]
L (‚àû) ‚â§mR[M, ‚àû) ‚â§m[M]
R [M, ‚àû),
which contains a nonoptimal lower bound for the number of backward focal points
of Y in [M, ‚àû), while limiting the inequalities in (6.479) for N ‚Üí‚àû, we obtain
a result counting the forward focal points of Y in the open interval (M, ‚àû).
Corollary 6.179 Assume that system (SDS) is nonoscillatory at ‚àû. Then for any
conjoined basis Y of (SDS), we have the estimates
m[M]
L (M, ‚àû) ‚â§mL(M, ‚àû) ‚â§m[‚àû]
L
(M, ‚àû] = m[M]
L (M, ‚àû) + rankG[M],
(6.525)
where G[M] is the genus of the principal solution Y [M] of (SDS) near ‚àû.
Proof The statement follows from (6.479) and from the calculations in (6.523)
and (6.524).
‚äì‚äî
Next we derive an exact relationship between the numbers of forward and
backward focal points of Y [‚àû] and Y [M] in the open interval (M, ‚àû).
Corollary 6.180 Assume that system (SDS) is nonoscillatory at ‚àû. Then
m[M]
L (M, ‚àû) + rank G[M] = m[‚àû]
L
(M, ‚àû) + n ‚àíd‚àû,
(6.526)
m[M]
L (M, ‚àû) = m[‚àû]
L
(M, ‚àû) ‚áîrank G[M] = n ‚àíd‚àû‚áîY [M] ‚ààGmin,
(6.527)
where G[M] and Gmin are the genera of conjoined bases of (SDS) near ‚àû
corresponding to Y [M] and Y [‚àû]. If in addition system (SDS) is controllable near
‚àû, then we have the equality
m[M]
L (M, ‚àû) = m[‚àû]
L
(M, ‚àû).
(6.528)
Proof Equation (6.526) is a reformulation of (6.515), since m[‚àû]
L
(‚àû) = n ‚àíd‚àû
by Remark 6.169(ii) and m[M]
L (‚àû) = rankG[M] ‚àírank w(Y [‚àû], Y [M]), where
w(Y [‚àû], Y [M]) = (X[‚àû]
M )T . The equivalences in (6.527) then follow from equa-
tion (6.526). If in addition the system (SDS) is controllable near ‚àû, then d‚àû= 0
and rank Gmin = n = rankG[M]. In this case we obtain from (6.527) that (6.528) is
indeed satisÔ¨Åed.
‚äì‚äî
As the last result in this subsection, we present limit properties of the comparative
index and the dual comparative index involving a given conjoined basis Y and the
principal solution Y [k] for k ‚Üí‚àû. Namely, we show that these limits are related to
the multiplicity mL(‚àû) and to the maximal order of abnormality d‚àû.

6.4
Singular Sturmian Separation Theorems
561
Theorem 6.181 Assume that system (SDS) is nonoscillatory at ‚àû. Then for
any conjoined basis Y of (SDS), the comparative indices Œº(JD‚àû, JD[k]
‚àû) and
Œº‚àó(JD‚àû, JD[k]
‚àû) have limits for k ‚Üí‚àû, which satisfy
lim
k‚Üí‚àûŒº(JD‚àû, JD[k]
‚àû) = mL(‚àû),
(6.529)
lim
k‚Üí‚àûŒº‚àó(JD‚àû, JD[k]
‚àû) = n ‚àíd‚àû,
(6.530)
where D‚àûand D[k]
‚àûare the constant matrices in (6.467) corresponding to Y and
Y [k], respectively.
Proof For any k ‚àà[0, ‚àû)Z, we have by Corollary 6.176 and Theorem 6.178 on the
interval [k, ‚àû)Z that
Œº(JD‚àû, JD[k]
‚àû)
(6.509)
=
mL(k, ‚àû] ‚àím[k]
L (k, ‚àû]
(6.517)
=
mL(k, ‚àû) + mL(‚àû) ‚àím[‚àû]
R [k, ‚àû).
(6.531)
Since system (SDS) is nonoscillatory at ‚àû, the conjoined bases Y and Y [‚àû] have
for large k no forward and backward focal points in the intervals (k, ‚àû) and [k, ‚àû),
i.e., mL(k, ‚àû) = 0 = m[‚àû]
R [k, ‚àû) for large k. Therefore, equality (6.529) follows
from (6.531). Similarly, we have
Œº‚àó(JD‚àû, JD[k]
‚àû)
(6.511)
=
m[k]
R [k, ‚àû) ‚àímR[k, ‚àû)
(6.517)
=
m[‚àû]
L
(k, ‚àû) + m[‚àû]
L
(‚àû) ‚àímR[k, ‚àû).
(6.532)
And since m[‚àû]
L
(k, ‚àû) = 0 = mR[k, ‚àû) for large k and m[‚àû]
L
(‚àû) = n ‚àíd‚àû, we
obtain equality (6.530) from taking the limit k ‚Üí‚àûin (6.532).
‚äì‚äî
It is interesting to realize that the value of the limit in (6.530) does not depend on
the chosen conjoined basis Y.
6.4.3
Singular Separation Theorems II
In this subsection we present singular separation theorems for system (SDS) on
unbounded intervals involving ‚àí‚àû, i.e., with the left singular endpoint. These
intervals will be either bounded from above or unbounded from above. We will
present results, which are in some sense analogous to those in Sect. 6.4.3.
The maximal order of abnormality of (SDS) near ‚àí‚àûis deÔ¨Åned by
d‚àí‚àû:=
lim
k‚Üí‚àí‚àûd(‚àí‚àû, k]Z,
0 ‚â§d‚àí‚àû‚â§n,

562
6
Miscellaneous Topics on Symplectic Systems
where d(‚àí‚àû, N]Z is the order of abnormality of system (SDS) on the interval
(‚àí‚àû, N]Z. The nonoscillation and eventual controllability of (SDS) near ‚àí‚àûthen
imply that d‚àí‚àû= 0 and that every conjoined basis Y of (SDS) has the matrix Xk
invertible for all negative k large enough.
If (SDS) is nonoscillatory at ‚àí‚àû, then we denote by Y [‚àí‚àû] the (unique) minimal
recessive solution of (SDS) at ‚àí‚àû(by an analog with Theorem 6.115 and the
notation in (6.471)). For completeness we note that a conjoined basis Y of (SDS) is
a recessive solution of (SDS) at ‚àí‚àûif there exists N ‚àà(‚àí‚àû, ‚àí1]Z such that Y has
constant kernel on (‚àí‚àû, N + 1]Z and no backward focal points in (‚àí‚àû, N + 1)
and the corresponding negative semideÔ¨Ånite matrix T‚àí‚àûdeÔ¨Åned by
T‚àí‚àû:=
lim
k‚Üí‚àí‚àû(S‚àí‚àû
k
)‚Ä†,
S‚àí‚àû
k
:= ‚àí
N

j=k+1
X‚Ä†
j BT
j X‚Ä† T
j+1,
k ‚àà(‚àí‚àû, N]Z,
(6.533)
with S‚àí‚àû
N
= 0 satisÔ¨Åes T‚àí‚àû= 0; compare with [300, DeÔ¨Ånition 4.2] in the
controllable case near ‚àí‚àû. Similarly, a conjoined basis Y of (SDS) is a dominant
solution of (SDS) at ‚àí‚àûif there exists N ‚àà(‚àí‚àû, ‚àí1]Z such that
d(‚àí‚àû, N + 1]Z = d‚àí‚àû
(6.534)
holds, the conjoined basis Y has constant kernel on (‚àí‚àû, N +1]Z and no backward
focal points in (‚àí‚àû, N + 1), and the corresponding matrix T‚àí‚àûdeÔ¨Åned in (6.237)
satisÔ¨Åes rankT‚àí‚àû= n ‚àíd‚àí‚àû(i.e., the rank of T‚àí‚àûis maximal).
Remark 6.182 In order to distinguish the notation for possibly different genera of
conjoined bases of (SDS) near ‚àûand ‚àí‚àû, we will denote the genera near ‚àûwith
the upper or lower index + and the genera near ‚àí‚àûwith upper or lower index ‚àí.
That is, G+ will denote a genus near ‚àû(with G+
min and G+
max being the minimal and
maximal genus near ‚àû), while G‚àíwill denote a genus near ‚àí‚àû(with G‚àí
min and
G‚àí
max being the minimal and maximal genus near ‚àí‚àû).
In view of Lemma 6.59 with j = ‚àí‚àû, every conjoined basis Y of (SDS) can be
uniquely represented by a constant 2n √ó n matrix D‚àí‚àûsuch that
Yk = [‚àí‚àû]
k
D‚àí‚àû,
k ‚ààIZ,
JD‚àí‚àû=
w(Y [‚àí‚àû], Y)
w( ¬ØY [‚àí‚àû], Y)

,
(6.535)
where [‚àí‚àû]
k
= (Y [‚àí‚àû]
k
, ¬ØY [‚àí‚àû]
k
) is the symplectic fundamental matrix of (SDS)
deÔ¨Åned by (6.228) with j = ‚àí‚àûand where IZ is the unbounded interval (‚àí‚àû, 0]Z
or (‚àí‚àû, ‚àû)Z = Z.
In the rest of this subsection, we assume that system (SDS) is nonoscillatory at
‚àí‚àû. In analogous way to DeÔ¨Ånition 6.168, we introduce the multiplicity mR(‚àí‚àû)
as follows.

6.4
Singular Sturmian Separation Theorems
563
DeÔ¨Ånition 6.183 For a conjoined basis Y of (SDS), we deÔ¨Åne the quantity
mR(‚àí‚àû) := n ‚àíd‚àí‚àû‚àírank T‚àí‚àû= def T‚àí‚àû‚àíd‚àí‚àû,
(6.536)
where T‚àí‚àûis the matrix in (6.533) associated with Y on (‚àí‚àû, N]Z, which
satisÔ¨Åes (6.534). Moreover, we say that Y has a focal point at ‚àí‚àûif mR(‚àí‚àû) ‚â•1
and then mR(‚àí‚àû) is called its multiplicity.
Following (6.491) and (4.89), we adopt for any conjoined basis Y of (SDS) and
any N ‚àà(‚àí‚àû, 0]Z the notation
mR[‚àí‚àû, N) := mR(‚àí‚àû, N) + mR(‚àí‚àû),
mR(‚àí‚àû, N) :=
N‚àí1

k=‚àí‚àû
mR[k, k + 1),
mL(‚àí‚àû, N] := l(Y, ‚àí‚àû, N) =
N‚àí1

k=‚àí‚àû
mL(k, k + 1].
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.537)
For intervals with two singular endpoints, we denote in a similar way
mL(‚àí‚àû, ‚àû] := mL(‚àí‚àû, ‚àû) + mL(‚àû),
mL(‚àí‚àû, ‚àû) :=
‚àû

k=‚àí‚àû
mL(k, k + 1],
mR[‚àí‚àû, ‚àû) := mR(‚àí‚àû, ‚àû) + mR(‚àí‚àû),
mR(‚àí‚àû, ‚àû) :=
‚àû

k=‚àí‚àû
mR[k, k + 1).
‚é´
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é¨
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é≠
(6.538)
Similar notation will be used for another conjoined basis ÀúY, for the principal solution
Y [N], and for the minimal recessive solution Y [‚àí‚àû] at ‚àí‚àû. Then we have the
following results.
Theorem 6.184 Assume that system (SDS) is nonoscillatory at ‚àí‚àû, and let Y,
belonging to a genus G‚àí, be a conjoined basis of (SDS) with constant kernel on
(‚àí‚àû, N + 1]Z and no backward focal points in (‚àí‚àû, N + 1), where the index
N ‚àà(‚àí‚àû, ‚àí1]Z is such that (6.534) holds. Then
Im [w(Y [‚àí‚àû], Y)]T = Im T‚àí‚àû‚äïIm (P ‚àíPS‚àí‚àû),
(6.539)
rankT‚àí‚àû= rankw(Y [‚àí‚àû], Y) ‚àírank G‚àí+ n ‚àíd‚àí‚àû,
(6.540)
mR(‚àí‚àû) = rankG‚àí‚àírank w(Y [‚àí‚àû], Y).
(6.541)
Proof The results are proven by analogy with Theorem 6.170.
‚äì‚äî

564
6
Miscellaneous Topics on Symplectic Systems
Theorem 6.185 (Singular Sturmian Separation Theorem) If (SDS) is nonoscil-
latory at ‚àí‚àû,, then for any conjoined bases Y and ÀúY of (SDS), we have
mL(‚àí‚àû, N] ‚àí7
mL(‚àí‚àû, N] = Œº(YN, ÀúYN) ‚àíŒº(JD‚àí‚àû, J ÀúD‚àí‚àû),
(6.542)
mR[‚àí‚àû, N) ‚àí7
mR[‚àí‚àû, N) = Œº‚àó(JD‚àí‚àû, J ÀúD‚àí‚àû) ‚àíŒº‚àó(YN, ÀúYN),
(6.543)
mL(‚àí‚àû, N] + rank XN = mR[‚àí‚àû, N) + rankw(Y [‚àí‚àû], Y),
(6.544)
where D‚àí‚àûand ÀúD‚àí‚àûare the constant matrices in (6.535) corresponding to Y and
ÀúY, respectively. If (SDS) is nonoscillatory at ¬±‚àû, then for any conjoined bases Y
and ÀúY of (SDS), we have the equalities
mL(‚àí‚àû, ‚àû] ‚àí7
mL(‚àí‚àû, ‚àû] = Œº(JD‚àû, J ÀúD‚àû) ‚àíŒº(JD‚àí‚àû, J ÀúD‚àí‚àû),
(6.545)
mR[‚àí‚àû, ‚àû)‚àí7
mR[‚àí‚àû, ‚àû) = Œº‚àó(JD‚àí‚àû, J ÀúD‚àí‚àû)‚àíŒº‚àó(JD‚àû, J ÀúD‚àû),
(6.546)
mL(‚àí‚àû, ‚àû]+rankw(Y [‚àû], Y) = mR[‚àí‚àû, ‚àû)+rankw(Y [‚àí‚àû], Y),
(6.547)
where D¬±‚àûand ÀúD¬±‚àûare the constant matrices in (6.467) and (6.535) correspond-
ing to Y and ÀúY, respectively.
Proof Identities (6.542)‚Äì(6.544) are proven by analogy with Theorem 6.173.
Identities (6.545)‚Äì(6.547) follow by adding the corresponding identities in (6.496)‚Äì
(6.498) and (6.542)‚Äì(6.544).
‚äì‚äî
Following (6.506)‚Äì(6.507), Theorem 4.39, and Theorems 4.59 and 4.61 (for one
system (SDS)), we consider the equalities
mL(‚àí‚àû, N] ‚àí7mL(‚àí‚àû, N] = Œº(YN, ÀúYN) ‚àíŒº‚àí‚àû(Y, ÀúY ),
(6.548)
mR(‚àí‚àû, N) ‚àí7
mR(‚àí‚àû, N) = Œº‚àó
‚àí‚àû(Y, ÀúY ) ‚àíŒº‚àó(YN, ÀúYN),
(6.549)
as the limiting case of (6.475)‚Äì(6.476) when the left endpoint approaches ‚àí‚àû,
where the numbers Œº‚àí‚àû(Y, ÀúY ) and Œº‚àó
‚àí‚àû(Y, ÀúY ) are deÔ¨Åned as the limits
Œº‚àí‚àû(Y, ÀúY ) :=
lim
k‚Üí‚àí‚àûŒº(Yk, ÀúYk),
Œº‚àó
‚àí‚àû(Y, ÀúY ) :=
lim
k‚Üí‚àí‚àûŒº‚àó(Yk, ÀúYk).
(6.550)
When considering system (SDS) with two singular endpoints, we also have
mL(‚àí‚àû, ‚àû) ‚àí7
mL(‚àí‚àû, ‚àû) = Œº‚àû(Y, ÀúY ) ‚àíŒº‚àí‚àû(Y, ÀúY ),
mR(‚àí‚àû, ‚àû) ‚àí7mR(‚àí‚àû, ‚àû) = Œº‚àó
‚àí‚àû(Y, ÀúY ) ‚àíŒº‚àó
‚àû(Y, ÀúY ),

6.4
Singular Sturmian Separation Theorems
565
as a sum of (6.503) and (6.548), respectively, as a sum of (6.504) and (6.549). Then
by Theorem 6.185, we can calculate the limits in (6.550) explicitly as values of
the comparative index, which could not be done by the methods in Sects. 4.2.4
and 4.3.3.
Corollary 6.186 Assume that system (SDS) is nonoscillatory at ‚àí‚àû. Then for any
conjoined bases Y and ÀúY of (SDS), the limits in (6.550) satisfy
Œº‚àí‚àû(Y, ÀúY ) = Œº(JD‚àí‚àû, J ÀúD‚àí‚àû),
(6.551)
Œº‚àó
‚àí‚àû(Y, ÀúY ) = Œº‚àó(JD‚àí‚àû, J ÀúD‚àí‚àû) ‚àímR(‚àí‚àû) + 7
mR(‚àí‚àû),
(6.552)
where D‚àí‚àûand ÀúD‚àí‚àûare the constant matrices in (6.535) corresponding to Y and
ÀúY, respectively. Moreover,
Œº‚àó
‚àí‚àû(Y, Y [‚àí‚àû]) = rank T‚àí‚àû.
(6.553)
Proof The statements in (6.551) and (6.552) follow from Theorem 6.185; compare
also with the proof of Corollary 6.174. Equality (6.553) then follows from (6.552)
with ÀúY := Y [‚àí‚àû]; compare with formula (6.508) in Remark 6.175.
‚äì‚äî
Based on Theorem 6.185, we derive exact formulas for the numbers of focal
points of a given conjoined basis Y of (SDS) in terms of Y [‚àí‚àû] and Y [N],
respectively, in terms of Y [‚àí‚àû] and Y [‚àû].
Corollary 6.187 If (SDS) is nonoscillatory at ‚àí‚àû, then for any conjoined basis Y
of (SDS), we have
mL(‚àí‚àû, N] = m[N]
L (‚àí‚àû, N] ‚àíŒº

JD‚àí‚àû, JD[N]
‚àí‚àû

,
(6.554)
mL(‚àí‚àû, N] = m[‚àí‚àû]
L
(‚àí‚àû, N] + Œº(YN, Y [‚àí‚àû]
N
),
(6.555)
mR[‚àí‚àû, N) = m[N]
R [‚àí‚àû, N) + Œº‚àóJD‚àí‚àû, JD[N]
‚àí‚àû
,
(6.556)
mR[‚àí‚àû, N) = m[‚àí‚àû]
R
[‚àí‚àû, N) ‚àíŒº‚àó(YN, Y [‚àí‚àû]
N
),
(6.557)
where D‚àí‚àûand D[N]
‚àí‚àûare the constant matrices in (6.535) corresponding to Y and
Y [N], respectively. If (SDS) is nonoscillatory at ¬±‚àû, then for any conjoined basis
Y of (SDS), we have
mL(‚àí‚àû, ‚àû] = m[‚àí‚àû]
L
(‚àí‚àû, ‚àû] + Œº

JD‚àû, JD[‚àí‚àû]
‚àû

,
(6.558)
mL(‚àí‚àû, ‚àû] = m[‚àû]
L
(‚àí‚àû, ‚àû] ‚àíŒº

JD‚àí‚àû, JD[‚àû]
‚àí‚àû

,
(6.559)
mR[‚àí‚àû, ‚àû) = m[‚àí‚àû]
R
[‚àí‚àû, ‚àû) ‚àíŒº‚àóJD‚àû, JD[‚àí‚àû]
‚àû
,
(6.560)
mR[‚àí‚àû, ‚àû) = m[‚àû]
R
[‚àí‚àû, ‚àû) + Œº‚àó
JD‚àí‚àû, JD[‚àû]
‚àí‚àû

,
(6.561)

566
6
Miscellaneous Topics on Symplectic Systems
where D‚àûand D[‚àí‚àû]
‚àû
are the constant matrices in (6.467) corresponding to Y
and Y [‚àí‚àû], respectively, and D‚àí‚àûand D[‚àû]
‚àí‚àûare the constant matrices in (6.535)
corresponding to Y and Y [‚àû], respectively.
Proof Equalities (6.554) and (6.556) follow from (6.542) and (6.543) with the
choice ÀúY
:= Y [N], while equalities (6.555) and (6.557) follow from (6.542)
and (6.543) with the choice ÀúY := Y [‚àí‚àû]. Equalities (6.558) and (6.560) follow
from (6.545) and (6.546) with the choice ÀúY := Y [‚àí‚àû], while equalities (6.559)
and (6.561) follow from (6.545) and (6.546) with ÀúY := Y [‚àû].
‚äì‚äî
Next we present the relationship between the numbers of forward and backward
focal points of Y [N], Y [‚àí‚àû], and Y [‚àû].
Corollary 6.188 If (SDS) is nonoscillatory at ‚àí‚àû, then
m[‚àí‚àû]
R
[‚àí‚àû, N) = m[‚àí‚àû]
L
(‚àí‚àû, N] + rank X[‚àí‚àû]
N
,
(6.562)
m[N]
L (‚àí‚àû, N] = m[N]
R [‚àí‚àû, N) + rank X[‚àí‚àû]
N
,
(6.563)
m[N]
L (‚àí‚àû, N] = m[‚àí‚àû]
L
(‚àí‚àû, N] + rank X[‚àí‚àû]
N
,
(6.564)
m[‚àí‚àû]
R
[‚àí‚àû, N) = m[N]
R [‚àí‚àû, N) + rank X[‚àí‚àû]
N
.
(6.565)
If (SDS) is nonoscillatory at ¬±‚àû, then
m[‚àí‚àû]
R
[‚àí‚àû, ‚àû) = m[‚àí‚àû]
L
(‚àí‚àû, ‚àû] + rank w(Y [‚àû], Y [‚àí‚àû]),
(6.566)
m[‚àû]
L
(‚àí‚àû, ‚àû] = m[‚àû]
R [‚àí‚àû, ‚àû) + rank w(Y [‚àí‚àû], Y [‚àû]),
(6.567)
m[‚àû]
L
(‚àí‚àû, ‚àû] = m[‚àí‚àû]
L
(‚àí‚àû, ‚àû] + rank w(Y [‚àû], Y [‚àí‚àû]),
(6.568)
m[‚àí‚àû]
R
[‚àí‚àû, ‚àû) = m[‚àû]
R [‚àí‚àû, ‚àû) + rank w(Y [‚àí‚àû], Y [‚àû]).
(6.569)
Proof Equations (6.562) and (6.566) follow from (6.544) and (6.547) with the
choice Y := Y [‚àí‚àû]. Equation (6.563) follows from (6.544) with Y := Y [N],
while (6.567) follows from (6.547) with Y
:= Y [‚àû]. Next, equations (6.564)
and (6.565) follow from (6.555) and (6.557) with the choice Y := Y [N] or (6.554)
and (6.556) with the choice Y := Y [‚àí‚àû], while equations (6.568) and (6.569) follow
from (6.558) and (6.560) with Y := Y [‚àû] or from (6.559) and (6.561) with the
choice Y := Y [‚àí‚àû].
‚äì‚äî
The following two results are analogs of Theorem 6.178 for the singular endpoint
of (SDS) at ‚àí‚àûor for two singular endpoints of (SDS).
Theorem 6.189 (Singular Sturmian Separation Theorem) If (SDS) is nonoscil-
latory at ‚àí‚àû, then
m[‚àí‚àû]
L
(‚àí‚àû, N] = m[N]
R [‚àí‚àû, N),
m[‚àí‚àû]
R
[‚àí‚àû, N) = m[N]
L (‚àí‚àû, N].
(6.570)

6.4
Singular Sturmian Separation Theorems
567
Moreover, for any conjoined basis Y of (SDS), we have the estimates
m[‚àí‚àû]
L
(‚àí‚àû, N] ‚â§mL(‚àí‚àû, N] ‚â§m[N]
L (‚àí‚àû, N],
(6.571)
m[N]
R [‚àí‚àû, N) ‚â§mR[‚àí‚àû, N) ‚â§m[‚àí‚àû]
R
[‚àí‚àû, N),
(6.572)
and for any conjoined bases Y and ÀúY of (SDS), we have the estimates
		 mL(‚àí‚àû, N] ‚àí7
mL(‚àí‚àû, N]
		 ‚â§rank X[‚àí‚àû]
N
‚â§n,
(6.573)
		 mR[‚àí‚àû, N) ‚àí7
mR[‚àí‚àû, N)
		 ‚â§rank X[‚àí‚àû]
N
‚â§n,
(6.574)
		 mL(‚àí‚àû, N] ‚àí7
mR[‚àí‚àû, N)
		 ‚â§rank X[‚àí‚àû]
N
‚â§n.
(6.575)
Proof The equalities in (6.570) follow from (6.562) in combination with (6.565)
and (6.564). The estimates in (6.571) follow from (6.555) and (6.554), while
the estimates in (6.572) follow from (6.556) and (6.557). Finally, the estimates
in (6.573)‚Äì(6.575) follow from (6.571)‚Äì(6.572) by using (6.570).
‚äì‚äî
Theorem 6.190 (Singular Sturmian Separation Theorem) If (SDS) is nonoscil-
latory at ¬±‚àû, then
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû] = m[‚àû]
R
[‚àí‚àû, ‚àû),
m[‚àí‚àû]
R
[‚àí‚àû, ‚àû) = m[‚àû]
L
(‚àí‚àû, ‚àû].
(6.576)
Moreover, for any conjoined basis Y of (SDS), we have the estimates
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû] ‚â§mL(‚àí‚àû, ‚àû] ‚â§m[‚àû]
L
(‚àí‚àû, ‚àû],
(6.577)
m[‚àû]
R [‚àí‚àû, ‚àû) ‚â§mR[‚àí‚àû, ‚àû) ‚â§m[‚àí‚àû]
R
[‚àí‚àû, ‚àû),
(6.578)
and for any conjoined bases Y and ÀúY of (SDS), we have the estimates
		 mL(‚àí‚àû, ‚àû] ‚àí7
mL(‚àí‚àû, ‚àû]
		 ‚â§rank w(Y [‚àû], Y [‚àí‚àû]) ‚â§n,
(6.579)
		 mR[‚àí‚àû, ‚àû) ‚àí7
mR[‚àí‚àû, ‚àû)
		 ‚â§rank w(Y [‚àû], Y [‚àí‚àû]) ‚â§n,
(6.580)
		 mL(‚àí‚àû, ‚àû] ‚àí7
mR[‚àí‚àû, ‚àû)
		 ‚â§rank w(Y [‚àû], Y [‚àí‚àû]) ‚â§n.
(6.581)
Proof The equalities in (6.576) follow from (6.566) in combination with (6.569)
and (6.568). The estimates in (6.577) follow from (6.558) and (6.559), while
the estimates in (6.578) follow from (6.561) and (6.560). Finally, the estimates
in (6.579)‚Äì(6.581) follow from (6.577)‚Äì(6.578) by using (6.576).
‚äì‚äî
We note that the lower and upper bounds in Theorems 6.189 and 6.190 are
optimal in a sense that they cannot be improved by better bounds, which would
be independent on the arbitrarily chosen conjoined bases Y and ÀúY.
In the remaining part of this section, we will present the results regarding the
multiplicities of focal points of conjoined bases of (SDS) in the open intervals

568
6
Miscellaneous Topics on Symplectic Systems
(‚àí‚àû, N) or (‚àí‚àû, ‚àû). Similarly to Corollaries 6.179 and 6.180, we obtain the
following.
Corollary 6.191 If (SDS) is nonoscillatory at ‚àí‚àû, then for any conjoined basis Y
of (SDS), we have the estimates
m[N]
R (‚àí‚àû, N) ‚â§mR(‚àí‚àû, N) ‚â§m[‚àí‚àû]
R
[‚àí‚àû, N)
= m[N]
R (‚àí‚àû, N) + rankG[N]
‚àí,

(6.582)
where G[N]
‚àí
is the genus of the principal solution Y [N] of (SDS) near ‚àí‚àû. Moreover,
we have
m[‚àí‚àû]
R
(‚àí‚àû, N) + n ‚àíd‚àí‚àû= m[N]
R (‚àí‚àû, N) + rankG[N]
‚àí,
(6.583)
m[‚àí‚àû]
R
(‚àí‚àû, N) = m[N]
R (‚àí‚àû, N) ‚áîrankG[N]
‚àí
= n ‚àíd‚àí‚àû
‚áîY [N] ‚ààG‚àí
min,

(6.584)
where G‚àí
min is the genus of conjoined bases of (SDS) near ‚àí‚àûcorresponding to
Y [‚àí‚àû]. If in addition system (SDS) is controllable near ‚àí‚àû, then
m[‚àí‚àû]
R
(‚àí‚àû, N) = m[N]
R (‚àí‚àû, N).
(6.585)
Corollary 6.192 If (SDS) is nonoscillatory at ¬±‚àû, then for any conjoined basis Y
of (SDS), we have the estimates
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) ‚â§mL(‚àí‚àû, ‚àû) ‚â§m[‚àû]
L
(‚àí‚àû, ‚àû]
= m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) + rank G[‚àí‚àû]
+
,

(6.586)
m[‚àû]
R
(‚àí‚àû, ‚àû) ‚â§mR(‚àí‚àû, ‚àû) ‚â§m[‚àí‚àû]
R
[‚àí‚àû, ‚àû)
= m[‚àû]
R
(‚àí‚àû, ‚àû) + rankG[‚àû]
‚àí
,

(6.587)
where G[‚àí‚àû]
+
is the genus of Y [‚àí‚àû] near ‚àûand G[‚àû]
‚àí
is the genus of Y [‚àû] near
‚àí‚àû. Moreover, we have
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) + rank G[‚àí‚àû]
+
= m[‚àû]
L
(‚àí‚àû, ‚àû) + n ‚àíd‚àû,
(6.588)
m[‚àí‚àû]
R
(‚àí‚àû, ‚àû) + n ‚àíd‚àí‚àû= m[‚àû]
R
(‚àí‚àû, ‚àû) + rankG[‚àû]
‚àí
,
(6.589)
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) = m[‚àû]
L
(‚àí‚àû, ‚àû) ‚áîrankG[‚àí‚àû]
+
= n ‚àíd‚àû
‚áîY [‚àí‚àû] ‚ààG+
min,

(6.590)
m[‚àí‚àû]
R
(‚àí‚àû, ‚àû) = m[‚àû]
R (‚àí‚àû, ‚àû) ‚áîrankG[‚àû]
‚àí
= n ‚àíd‚àí‚àû
‚áîY [‚àû] ‚ààG‚àí
min,

(6.591)

6.5
Notes and References
569
and consequently
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) + rankG[‚àí‚àû]
+
= m[‚àû]
R
(‚àí‚àû, ‚àû) + rankG[‚àû]
‚àí
,
(6.592)
m[‚àí‚àû]
R
(‚àí‚àû, ‚àû) ‚àíd‚àí‚àû= m[‚àû]
L
(‚àí‚àû, ‚àû) ‚àíd‚àû,
(6.593)
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) = m[‚àû]
R (‚àí‚àû, ‚àû) ‚áîrank G[‚àí‚àû]
+
= rankG[‚àû]
‚àí
,
(6.594)
m[‚àí‚àû]
R
(‚àí‚àû, ‚àû) = m[‚àû]
L
(‚àí‚àû, ‚àû) ‚áîd‚àí‚àû= d‚àû.
(6.595)
If in addition system (SDS) is controllable near ¬±‚àû, then
m[‚àí‚àû]
L
(‚àí‚àû, ‚àû) = m[‚àí‚àû]
R
(‚àí‚àû, ‚àû) = m[‚àû]
L
(‚àí‚àû, ‚àû) = m[‚àû]
R (‚àí‚àû, ‚àû).
(6.596)
In the Ô¨Ånal result of this subsection, we present the limit properties of the
comparative index at ‚àí‚àûand its relation with the multiplicity mR(‚àí‚àû) for
a conjoined basis Y and with the maximal order of abnormality d‚àí‚àû. It represents
an analog of Theorem 6.181.
Theorem 6.193 Assume that system (SDS) is nonoscillatory at ‚àí‚àû. Then for
any conjoined basis Y of (SDS), the comparative indices Œº(JD‚àí‚àû, JD[k]
‚àí‚àû) and
Œº‚àó(JD‚àí‚àû, JD[k]
‚àí‚àû) have limits for k ‚Üí‚àí‚àû, which satisfy
lim
k‚Üí‚àí‚àûŒº(JD‚àí‚àû, JD[k]
‚àí‚àû) = n ‚àíd‚àí‚àû,
(6.597)
lim
k‚Üí‚àí‚àûŒº‚àó(JD‚àí‚àû, JD[k]
‚àí‚àû) = mR(‚àí‚àû),
(6.598)
where D‚àí‚àûand D[k]
‚àí‚àûare the constant matrices in (6.535) corresponding to Y and
Y [k], respectively.
Proof The proof is analogous to the proof of Theorem 6.181 by using formu-
las (6.554), (6.556), and (6.570). The details are therefore omitted.
‚äì‚äî
6.5
Notes and References
The results in Sect. 6.1.1 are based on [22, 314] and [315, Chapter 4]. In the paper
[21] the authors considered the case when equations (6.9), (6.10) differ also in
rk Ã∏= ÀÜrk. Note that all results in [21, 22, 315] are related to the case of the special
linear dependence on Œª (see Sect. 5.3). The relative oscillation theorems for two
Sturm-Liouville equations with general nonlinear dependence on Œª (see Sect. 1.2.5)
can be derived from [124, Theorems 3.8 and 3.9] (see Sect. 6.1.4). Moreover, in
[124, Subsection 3.2], we discussed connections between the results in [21] and
[124]. For differential Sturm-Liouville eigenvalue problems, the relative oscillation

570
6
Miscellaneous Topics on Symplectic Systems
theory is developed in [153, 213] (see also the references in these papers). The Ô¨Årst
results concerning the relative oscillation theory for discrete symplectic systems are
presented in [117, Section 3] and [118, 120, 121, 123, 124].
The results in Sect. 6.1.2 (see Theorems 6.2 and 6.4) are direct consequence of
the comparison results for focal points of the principal solutions of two symplectic
systems from [117, Corollary 2.4] (see Sect. 4.3.2). The consideration in Sect. 6.1.3
is based on algebraic properties of the comparative index for two symplectic
matrices under assumption (6.35) (see [117, Lemma 2.2] and Sect. 4.3.1, in
particular Lemma 4.43). The Ô¨Årst applications of the comparison results for this
special case to the spectral theory of symplectic systems with the special linear
dependence on Œª (see Sect. 5.3) can be found in [117, Section 3] and [118]. In
particular, the results in Lemma 6.6 are from [118, Lemma 1] (note that the proofs
for the linear and nonlinear cases are the same). Formula (6.60) in Remark 6.10(ii)
concerning the number of eigenvalues in (‚àí‚àû, b) (instead of (‚àí‚àû, b]) was
derived in [118, Theorem 3, formula (3.7)]. In this connection we remark that
the renormalized version of (6.60), formula (6.62) (concerning the number of
eigenvalues of problem (E) in [a, b), compare with Theorem 6.9), is proved in [118,
Theorem 4, formula (3.11)]. Observe that the comments in Remark 6.10(ii) (as well
as [118, Theorem 4, formula (3.11)]) refer to the special linear dependence of on Œª.
A generalization of (6.60) and (6.62) to the case of general nonlinear dependence on
Œª demands introducing the notion of the so-called right Ô¨Ånite eigenvalues, because
condition (5.274) is not in general satisÔ¨Åed.
Majority of the results in Sects. 6.1.4 and 6.1.5 are from the paper [124].
Note that from the results of Sect. 6.1.4, one can easily derive the results for the
scalar case n = 1 concerning a pair of Sturm-Liouville eigenvalue problems with
general nonlinear dependence on Œª. The main results in Sects. 6.1.6 and 6.1.7 are
from [121, Chapter 4], where the consideration is restricted to the special linear
dependence on Œª (see Sect. 5.3). Note, however, that all algebraic properties of the
comparative index used in the results of Sects. 6.1.6 and 6.1.7 remain the same
for the general nonlinear dependence on Œª. Observe also, that the renormalized
oscillation theorems for separated and joint endpoints (see Theorems 6.23 and 6.29),
as well as Corollaries 6.25 and 6.31 and Remarks 6.26 and 6.32, for the case when
the boundary conditions do not depend on Œª can be found in [120, Theorems 1
and 2] (for separated boundary conditions) and in [123, Theorems 5 and 6] (for
general boundary conditions).
The results of Sect. 6.2 belong to the classical research topic strongly developed
for differential Sturm-Liouville eigenvalue problems with some generalizations to
vector case, i.e., for differential matrix Sturm-Liouville eigenvalue problems and for
boundary value problems for linear Hamiltonian differential systems. Comparison
theorems for eigenvalues under some majorant conditions for scalar and vector
differential Sturm-Liouville equations can be found in [280, Chapters 1 and 3]
and in [205, Section 7.5]. For the discrete case, comparison results for eigenvalues
of scalar and vector Sturm-Liouville eigenvalue problems can be found in [262,
Theorem 3.21], [268, Theorem 3.7], and [267, Theorem 5.5]. See also the references
therein.

6.5
Notes and References
571
First comparison theorems for eigenvalues of discrete symplectic eigenvalue
problems with nonlinear dependence on Œª were proven in [301, Theorems 1‚Äì3].
Similar results were proven in [121, Chapter 4], for the case of the special linear
dependence on Œª (see Sect. 5.3). In Sect. 6.2.1 we present a modiÔ¨Åcation of the
results in [301] and [121, Chapter 4] for the general nonlinear dependence on Œª
formulating majorant conditions for the symplectic matrices Sk(Œª) and ÀÜSk(Œª) and
for the matrices of the boundary conditions in terms of the comparative index and
using the relative oscillation theorems from Sect. 6.1 as the main tool for the proofs.
In Sects. 6.2.2 and 6.2.3, we present the comparative index theory as a new
tool for the proof of the interlacing properties of Ô¨Ånite eigenvalues of symplectic
eigenvalue problems with nonlinear dependence on Œª. For the scalar differen-
tial Sturm-Liouville eigenvalue problems, the classical interlacing properties of
eigenvalues are proven in [38] and [69, Chapter 8]; see also [37] and the ref-
erences in the latter paper. For the matrix case, these properties are proven in
[28, Theorem 10.5.1], [254, Theorem 2] (for matrix Sturm-Liouville eigenvalue
problems), in [28, Theorem 10.9.1], [156, Chapter 4] (for linear Hamiltonian
differential systems with general linear dependence on Œª), and in [205, Section 7.5].
For geometrical interpretation of interlacing properties, we refer to [26]. For the
discrete case, results concerning interlacing properties of zeros for orthogonal
polynomials for scalar and matrix case can be found in [28, Chapters 4 and 6]
(see Theorems 4.3.2, 4.3.3, and 6.7.7 therein). Different results concerning the
interlacing properties of eigenvalues for discrete Sturm-Liouville problems can be
found in [149, 322] and the references therein.
For the discrete symplectic systems with special linear dependence on Œª (see
Sect. 5.3), some interlacing properties of Ô¨Ånite eigenvalues are proved in [120] (for
separated boundary conditions) and in [123] (for joint endpoints). These results were
generalized in [121, Chapter 4], but the consideration was restricted to the case of
the special linear dependence on Œª.
Majority of the results in Sect. 6.3 about recessive and dominant solutions
of (SDS) at ‚àû
in the possibly uncontrollable case are derived from [284] and
[290]. More precisely, most of Sects. 6.3.1‚Äì6.3.6 are from [284]. The properties
of the important auxiliary conjoined basis ¬ØY in Proposition 6.67 are collected from
several sources: parts (i)‚Äì(v) from [284, Proposition 4.3 and Remark 4.5]; parts
(vi)‚Äì(viii) from [290, Proposition 2.6]; and parts (ix)‚Äì(xi) are proven as a discrete
version of [281, Theorem 2.2.11]. The proof of Lemma 6.100 is a discrete version
of the proof of [288, Lemma 1]. The proofs of Theorems 6.69, 6.73, 6.75, 6.97(ii)‚Äì
(iii) and of Propositions 6.81 and 6.105 were not discussed in details in [284].
In the presented form, they are discrete analogs of the proofs of [283, Theo-
rems 4.6, 4.10, 5.2, 5.7, 5.15, 5.17, 6.9]. The proof of Theorem 6.84 is a discrete ana-
log of the proof of [285, Theorem 4.13]. Similarly, the proofs of Propositions 6.92
and 6.99 and Theorems 6.106 and 6.107 were not discussed in details in [290].
Their presented versions are discrete analogs of the proofs of [285, Theorem 6.7
and Lemma 6.9] and [286, Theorems 4.4 and 4.9]. Moreover, Lemma 6.91 is the
discrete version of [285, Lemma 6.6]. The concept of representable conjoined bases
in DeÔ¨Ånition 6.79 and Theorem 6.80 is a discrete version of [281, Theorem 2.3.3].

572
6
Miscellaneous Topics on Symplectic Systems
The statement in Theorem 6.153 extends the Reid construction of the recessive
solution of (SDS) at ‚àûknown for the controllable case in [81, Section 4(iii)]. The
corresponding result for controllable linear Hamiltonian differential systems (1.103)
can be found in [70, pg. 44] and [248, Theorem VII.3.4], while for general
abnormal linear Hamiltonian systems, we refer to [288, Theorem 1]. Singular
Sturmian separation theorems on unbounded intervals presented in Sect. 6.4,
including the necessary tools in Sect. 6.3.11, are derived from [292]. The results
in Corollary 6.177 (singular Sturmian separation theorem) are correct singular
versions of [94, Eq. (4.14) and (4.29)]. The results in Corollaries 6.180 and 6.191
represent generalizations of [94, Corollary 4.2, Eqs. (4.14a), (4.16a)] to a possibly
uncontrollable system (SDS) near ‚àûor ‚àí‚àû. A similar statement was obtained in
[91, Theorem 2] and [104, Theorem 1] for an eventually controllable system (SDS)
on the interval (‚àí‚àû, ‚àû); compare with Corollaries 6.191 and 6.192. The equalities
in (6.596) are known in [104, Theorem 1] and in [91, Theorem 2]. The equivalences
in (6.594) and (6.595) then generalize the result in (6.596) to possibly uncontrollable
system (SDS).
Regarding the basic notions in Sect. 6.4.3, it is shown in [300, Section 4] how the
notion of a recessive/dominant solution of (SDS) at ‚àí‚àûcan be transformed into
the corresponding notion at ‚àûand vice versa. Several examples, which illustrate
the concepts and results in Sects. 6.4.2 and 6.4.3, are presented in [292, Section 7].
We note that the development of the presented discrete-time theory was
inÔ¨Çuenced by the corresponding theory of linear Hamiltonian differential
systems (1.103) in [283, 285‚Äì289, 293].
We recommend the following additional related references for further reading
about the topics presented in this chapter: [5, 52, 76] for Sturmian theory of
symplectic systems and their recessive and dominant solutions.

References
1. A.A. Abramov, A modiÔ¨Åcation of one method for solving nonlinear self-adjoint eigenvalue
problems for Hamiltonian systems of ordinary differential equations, Comput. Math. Math.
Phys. 51(1), 35‚Äì39 (2011)
2. R.P. Agarwal, Difference Equations and Inequalities. Theory, methods, and applications, 2nd
edn. Monographs and Textbooks in Pure and Applied Mathematics, vol. 228 (Marcel Dekker,
New York, 2000)
3. R.P. Agarwal, C.D. Ahlbrandt, M. Bohner, A. Peterson, Discrete linear Hamiltonian systems:
A survey. Dynam. Syst. Appl. 8(3‚Äì4), 307‚Äì333 (1999)
4. R.P. Agarwal, M. Bohner, S.R. Grace, D. O‚ÄôRegan, Discrete Oscillation Theory (Hindawi
Publishing, New York, NY, 2005)
5. D. Aharonov, M. Bohner, U. Elias, Discrete Sturm comparison theorems on Ô¨Ånite and inÔ¨Ånite
intervals. J. Differ. Equ. Appl. 18, 1763‚Äì1771 (2012)
6. C.D. Ahlbrandt, Principal and antiprincipal solutions of self-adjoint differential systems and
their reciprocals. Rocky Mt. J. Math. 2, 169‚Äì182 (1972)
7. C.D. Ahlbrandt, Linear independence of the principal solutions at ‚àûand ‚àí‚àûfor formally
self-adjoint differential systems. J. Differ. Equ. 29(1), 15‚Äì27 (1978)
8. C.D. Ahlbrandt, Equivalence of discrete Euler equations and discrete Hamiltonian systems. J.
Math. Anal. Appl. 180, 498‚Äì517 (1993)
9. C.D. Ahlbrandt, Continued fractions representation of maximal and minimal solutions of a
discrete matrix Riccati equation. SIAM J. Math. Anal. 24, 1597‚Äì1621 (1993)
10. C.D. Ahlbrandt, Geometric, analytic, and arithmetic aspects of symplectic continued frac-
tions, in Analysis, Geometry and Groups: A Riemann Legacy Volume, Hadronic Press Collect.
Orig. Artic. (Hadronic Press, Palm Harbor, FL, 1993), pp. 1‚Äì26
11. C.D. Ahlbrandt, Dominant and recessive solutions of symmetric three term recurrences. J.
Differ. Equ. 107, 238‚Äì258 (1994)
12. C.D. Ahlbrandt, M. Bohner, J. Ridenhour, Hamiltonian systems on time scales. J. Math. Anal.
Appl. 250(2), 561‚Äì578 (2000)
13. C.D. Ahlbrandt, C. Chicone, S.L. Clark, W.T. Patula, D. Steiger, Approximate Ô¨Årst integrals
for discrete Hamiltonian systems. Dynam. Contin. Discrete Impuls. Syst. 2, 237‚Äì264 (1996)
14. C.D. Ahlbrandt, M. Heifetz, Discrete Riccati equations of Ô¨Åltering and control, in Proceedings
of the First International Conference on Difference Equations (San Antonio, TX, 1994),
ed. by S. Elaydi, J. Graef, G. Ladas, A. Peterson (Gordon and Breach, Newark, NJ, 1996),
pp. 1‚Äì16
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7
573

574
References
15. C.D. Ahlbrandt, J.W. Hooker, Recessive solutions of symmetric three term recurrence
relations, in Oscillations, Bifurcation and Chaos (Toronto, 1986), Canadian Math. Soc.
Conference Proceedings, Vol. 8, ed. by F. Atkinson, W. Langford, A. Mingarelli (Amer. Math.
Soc., Providence, RI, 1987), pp. 3‚Äì42
16. C.D. Ahlbrandt, A.C. Peterson, Discrete Hamiltonian Systems. Difference Equations, Con-
tinued Fractions, and Riccati Equations. Kluwer Texts in the Mathematical Sciences, Vol. 16
(Kluwer Academic Publishers, Dordrecht, 1996)
17. C.D. Ahlbrandt, A.C. Peterson, A general reduction of order theorem for discrete linear
symplectic systems, in Dynamical Systems and Differential Equations, Vol. I (SpringÔ¨Åeld,
MO, 1996). Discrete Contin. Dynam. Syst. 1998, Added Volume I, 7‚Äì18 (1998)
18. L.D. Akulenko, S.V. Nesterov, A frequency-parametric analysis of natural oscillations of non-
uniform rods. J. Appl. Math. Mech. 67, 525‚Äì537 (2003)
19. L.D. Akulenko, S.V. Nesterov, High-Precision Methods in Eigenvalue Problems and Their
Applications (Chapman and Hall/Crc, Boca Raton, FL, 2005)
20. L.D. Akulenko, S.V. Nesterov, Flexural vibrations of a moving rod. J. Appl. Math. Mech. 72,
550‚Äì560 (2008)
21. K. Ammann, Relative oscillation theory for Jacobi matrices extended. Oper. Matrices 1, 99‚Äì
115 (2014)
22. K. Ammann, G. Teschl, Relative oscillation theory for Jacobi matrices, in Proceedings of the
14th International Conference on Difference Equations and Applications (Istanbul, 2008), ed.
by M. Bohner, Z. Do≈°l√°, G. Ladas, M. √únal, A. Zafer (UÀògur-Bah√ße¬∏sehir University Publishing
Company, Istanbul, 2009), pp. 105‚Äì115
23. W.O. Amrein, A.M. Hinz, D.B. Pearson (eds.), Sturm‚ÄìLiouville Theory. Past and Present.
Including papers from the International Colloquium held at the University of Geneva (Geneva,
2003) (Birkh√§user Verlag, Basel, 2005)
24. D.R. Anderson, Discrete trigonometric matrix functions. PanAmer. Math. J. 7(1), 39‚Äì54
(1997)
25. D.R. Anderson, Normalized prepared bases for discrete symplectic matrix systems. Dynam.
Syst. Appl. 8(3‚Äì4), 335‚Äì344 (1999)
26. V.I. Arnold, Sturm theorems and symplectic geometry. Funct. Anal. Appl. 19(4), 251‚Äì259
(1985)
27. V.I. Arnold, Mathematical Methods of Classical Mechanics, 2nd edn. (Springer, Berlin, 1989)
28. F.V. Atkinson, Discrete and Continuous Boundary Value Problems (Academic Press,
New York, NY, 1964)
29. T. Auckenthalera, V. Blumb, H.J. Bungartza, et al., Parallel solution of partial symmetric
eigenvalue problems from electronic structure calculations. Parallel Comput. 37, 783‚Äì794
(2011)
30. P.B. Bailey, W.N. Everitt, A. Zettl, The SLEIGN2 Sturm‚ÄìLiouville Code. ACM Trans. Math.
Software 21, 143‚Äì192 (2001)
31. B. Bandyrskii, I. Gavrilyuk, I. Lazurchak, V. Makarov, Functional-discrete method (fd-
method) for matrix Sturm‚ÄìLiouville problems. Comput. Methods Appl. Math. 5, 362‚Äì386
(2005)
32. J.H. Barrett, A Pr√ºfer transformation for matrix differential systems. Proc. Am. Math. Soc. 8,
510‚Äì518 (1957)
33. H. Behncke, Spectral theory of Hamiltonian difference systems with almost constant coefÔ¨Å-
cients. J. Differ. Equ. Appl. 19(1), 1‚Äì12 (2013)
34. A. Ben-Israel, T.N.E. Greville, Generalized Inverses: Theory and Applications (Wiley,
New York, 1974)
35. P. Benner, Symplectic balancing of Hamiltonian matrices. SIAM J. Sci. Comput. 22, 1885‚Äì
1904 (2000)
36. D.S. Bernstein, Matrix Mathematics. Theory, Facts, and Formulas with Application to Linear
Systems Theory (Princeton University Press, Princeton, 2005)
37. P.A. Binding, H. Volkmer, Interlacing and oscillation for Sturm‚ÄìLiouville problems with
separated and coupled boundary conditions. J. Comput. Appl. Math. 194(1), 75‚Äì93 (2006)

References
575
38. G.D. Birkhoff, Existence and oscillation theorem for a certain boundary value problem. Trans.
Am. Math. Soc. 10(2), 259‚Äì270 (1909)
39. M. Bohner, Linear Hamiltonian difference systems: disconjugacy and Jacobi-type conditions.
J. Math. Anal. Appl. 199(3), 804‚Äì826 (1996)
40. M. Bohner, Riccati matrix difference equations and linear Hamiltonian difference systems.
Dynam. Contin. Discrete Impuls. Syst. 2(2), 147‚Äì159 (1996)
41. M. Bohner, On disconjugacy for Sturm‚ÄìLiouville difference equations, in Difference Equa-
tions: Theory and Applications (San Francisco, CA, 1995). J. Differ. Equ. Appl. 2(2), 227‚Äì237
(1996)
42. M. Bohner, Symplectic systems and related discrete quadratic functionals. Facta Univ. Ser.
Math. Inform. 12, 143‚Äì156 (1997)
43. M. Bohner, Discrete Sturmian theory. Math. Inequal. Appl. 1(3), 375‚Äì383 (1998)
44. M. Bohner, Discrete linear Hamiltonian eigenvalue problems. Comput. Math. Appl. 36(10‚Äì
12), 179‚Äì192 (1998)
45. M. Bohner, O. Do≈°l√Ω, Disconjugacy and transformations for symplectic systems. Rocky Mt.
J. Math. 27, 707‚Äì743 (1997)
46. M. Bohner, O. Do≈°l√Ω, Trigonometric transformations of symplectic difference systems. J.
Differ. Equ. 163, 113‚Äì129 (2000)
47. M. Bohner, O. Do≈°l√Ω, The discrete Pr√ºfer transformation. Proc. Am. Math. Soc. 129, 2715‚Äì
2726 (2001)
48. M. Bohner, O. Do≈°l√Ω, Trigonometric systems in oscillation theory of difference equations,
in Dynamic Systems and Applications, Proceedings of the Third International Conference
on Dynamic Systems and Applications (Atlanta, GA, 1999), Vol. 3 (Dynamic, Atlanta, GA,
2001), pp. 99‚Äì104
49. M. Bohner, O. Do≈°l√Ω, R. Hilscher, Linear Hamiltonian dynamic systems on time scales:
Sturmian property of the principal solution, in Proceedings of the Third World Congress of
Nonlinear Analysts (Catania, 2000). Nonlinear Anal. 47, 849‚Äì860 (2001)
50. M. Bohner, O. Do≈°l√Ω, R. Hilscher, W. Kratz, Diagonalization approach to discrete quadratic
functionals. Arch. Inequal. Appl. 1(2), 261‚Äì274 (2003)
51. M. Bohner, O. Do≈°l√Ω, W. Kratz, Inequalities and asymptotics for Riccati matrix difference
operators. J. Math. Anal. Appl. 221, 262‚Äì286 (1998)
52. M. Bohner, O. Do≈°l√Ω, W. Kratz, A Sturmian theorem for recessive solutions of linear
Hamiltonian difference systems. Appl. Math. Lett. 12, 101‚Äì106 (1999)
53. M. Bohner, O. Do≈°l√Ω, W. Kratz, Discrete Reid roundabout theorems. Dynam. Syst. Appl.
8(3‚Äì4), 345‚Äì352 (1999)
54. M. Bohner, O. Do≈°l√Ω, W. Kratz, Positive semideÔ¨Åniteness of discrete quadratic functionals.
Proc. Edinb. Math. Soc. (2) 46(3), 627‚Äì636 (2003)
55. M. Bohner, O. Do≈°l√Ω, W. Kratz, An oscillation theorem for discrete eigenvalue problems.
Rocky Mt. J. Math. 33(4), 1233‚Äì1260 (2003)
56. M. Bohner, O. Do≈°l√Ω, W. Kratz, Sturmian and spectral theory for discrete symplectic systems.
Trans. Am. Math. Soc. 361, 3019‚Äì3123 (2009)
57. M. Bohner, W. Kratz, R. ≈†imon Hilscher, Oscillation and spectral theory for linear Hamilto-
nian systems with nonlinear dependence on the spectral parameter. Math. Nachr. 285(11‚Äì12),
1343‚Äì1356 (2012)
58. M. Bohner, A. Peterson, Dynamic Equations on Time Scales. An Introduction with Applica-
tions (Birkh√§user, Boston, 2001)
59. M. Bohner, A. Peterson (eds.), Advances in Dynamic Equations on Time Scales (Birkh√§user,
Boston, 2003)
60. M. Bohner, S. Sun, Weyl‚ÄìTitchmarsh theory for symplectic difference systems. Appl. Math.
Comput. 216(10), 2855‚Äì2864 (2010)
61. D.L. Boley, P. Van Dooren, Placing zeroes and the Kronecker canonical form. Circuits
Systems Signal Process. 13(6), 783‚Äì802 (1994)
62. V.G. Boltyanskii, Optimal Control of Discrete Systems (Wiley, New York, NY, 1978)

576
References
63. A. Bunse-Gerstner, Matrix factorizations for symplectic QR-like methods. Linear Algebra
Appl. 83, 49‚Äì77 (1986)
64. S.L. Campbell, C.D. Meyer, Generalized Inverses of Linear Transformations. Reprint of the
1991 corrected reprint of the 1979 original, Classics in Applied Mathematics, Vol. 56 (Society
for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 2009)
65. P.J. Channell, C. Scovel, Symplectic integration of Hamiltonian systems. Nonlinearity 3(2),
231‚Äì259 (1990)
66. S. Clark, F. Gesztesy, On Weyl‚ÄìTitchmarsh theory for singular Ô¨Ånite difference Hamiltonian
systems. J. Comput. Appl. Math. 171(1‚Äì2), 151‚Äì184 (2004)
67. S. Clark, P. Zem√°nek, On a Weyl‚ÄìTitchmarsh theory for discrete symplectic systems on a half
line. Appl. Math. Comput. 217(7), 2952‚Äì2976 (2010)
68. S. Clark, P. Zem√°nek, On discrete symplectic systems: Associated maximal and minimal
linear relations and nonhomogeneous problems. J. Math. Anal. Appl. 421(1), 779‚Äì805 (2014)
69. E.A. Coddington, N. Levinson, Theory of Ordinary Differential Equations (McGraw‚ÄìHill,
New York, 1955)
70. W.A. Coppel, Disconjugacy. Lecture Notes in Mathematics, Vol. 220 (Springer, Berlin, 1971)
71. J.W. Demmel, Applied Numerical Linear Algebra (Society for Industrial and Applied
Mathematics (SIAM), Philadelphia, 1997)
72. J.W. Demmel, I.S. Dhillon, H. Ren, On the correctness of some bisection-like parallel
algorithms in Ô¨Çoating point arithmetic. Electron. Trans. Numer. Anal. 3, 116‚Äì140 (1995)
73. J. Demmel, A. McKenney, A test matrix generation suite: LAPACK Working Note 9, technical
report, Department of Computer Science, Courant Institute, New York, 1989
74. F.M. Dopico, C.R. Johnson, Complementary bases in symplectic matrices and a proof that
their determinant is one. Linear Algebra Appl. 419, 772‚Äì778 (2006)
75. F.M. Dopico, C.R. Johnson, Parametrization of matrix symplectic group and applications.
SIAM J. Matrix Anal. 419, 1‚Äì24 (2009)
76. Z. Do≈°l√°, D. ≈†krab√°kov√°, Phases of second order linear difference equations and symplectic
systems. Math. Bohem. 128(3), 293‚Äì308 (2003)
77. O. Do≈°l√Ω, On transformations of self-adjoint linear differential systems and their reciprocals.
Ann. Polon. Math. 50, 223‚Äì234 (1990)
78. O. Do≈°l√Ω, Principal solutions and transformations of linear Hamiltonian systems. Arch. Math.
(Brno) 28, 113‚Äì120 (1992)
79. O. Do≈°l√Ω, Oscillation criteria for self-adjoint linear differential equations. Math. Nachr. 166,
141‚Äì153 (1994)
80. O. Do≈°l√Ω, Oscillation criteria for higher order Sturm‚ÄìLiouville difference equations. J. Differ.
Equ. Appl. 4(5), 425‚Äì450 (1998)
81. O. Do≈°l√Ω, Principal and nonprincipal solutions of symplectic dynamic systems on time scales,
in Proceedings of the Sixth Colloquium on the Qualitative Theory of Differential Equations
(Szeged, Hungary, 1999), No. 5, 14 pp. (electronic). Electron. J. Qual. Theory Differ. Equ.,
Szeged, 2000
82. O. Do≈°l√Ω, Oscillation theory of linear difference equations, in CDDE Proceedings (Brno,
2000). Arch. Math. (Brno) 36, 329‚Äì342 (2000)
83. O. Do≈°l√Ω, Trigonometric transformation and oscillatory properties of second order difference
equations, in Communications in Difference Equations (Poznan, 1998) (Gordon and Breach,
Amsterdam, 2000), pp. 125‚Äì133
84. O. Do≈°l√Ω, Discrete quadratic functionals and symplectic difference systems. Funct. Differ.
Equ. 11(1‚Äì2), 49‚Äì58 (2004)
85. O. Do≈°l√Ω, Symplectic difference systems: oscillation theory and hyperbolic Pr√ºfer transfor-
mation. Abstr. Appl. Anal. 2004(4), 285‚Äì294 (2004)
86. O. Do≈°l√Ω, The Bohl transformation and its applications, in 2004‚ÄìDynamical Systems and
Applications, Proceedings of the International Conference (Antalya, 2004) (GBS Publishers
& Distributors, Delhi, 2005), pp. 371‚Äì385
87. O. Do≈°l√Ω, Oscillation theory of symplectic difference systems, in Advances in Discrete
Dynamical Systems, Proceedings of the Eleventh International Conference on Difference

References
577
Equations and Applications (Kyoto, 2006), ed. by S. Elaydi, K. Nishimura, M. Shishikura,
N. Tose. Adv. Stud. Pure Math., Vol. 53 (Mathematical Society of Japan, Tokyo, 2009),
pp. 41‚Äì50
88. O. Do≈°l√Ω, Oscillation and conjugacy criteria for two-dimensional symplectic difference
systems. Comput. Math. Appl. 64(7), 2202‚Äì2208 (2012)
89. O. Do≈°l√Ω, Symplectic difference systems with periodic coefÔ¨Åcients: Krein‚Äôs trafÔ¨Åc rules for
multipliers. Adv. Differ. Equ. 2013(85), 13 pp. (2013)
90. O. Do≈°l√Ω, Symplectic difference systems: natural dependence on a parameter, in Proceedings
of the International Conference on Differential Equations, Difference Equations, and Special
Functions (Patras, 2012). Adv. Dyn. Syst. Appl. 8(2), 193‚Äì201 (2013)
91. O. Do≈°l√Ω, Focal points and recessive solutions of discrete symplectic systems. Appl. Math.
Comput. 243, 963‚Äì968 (2014)
92. O. Do≈°l√Ω, Relative oscillation of linear Hamiltonian differential systems. Math. Nachr.
290(14‚Äì15), 2234‚Äì2246 (2017)
93. O. Do≈°l√Ω, On some aspects of the Bohl transformation for Hamiltonian and symplectic
systems. J. Math. Anal. Appl. 448(1), 281‚Äì292 (2017)
94. O. Do≈°l√Ω, J. Elyseeva, Singular comparison theorems for discrete symplectic systems. J.
Differ. Equ. Appl. 20(8), 1268‚Äì1288 (2014)
95. O. Do≈°l√Ω, J. Elyseeva, Discrete oscillation theorems and weighted focal points for Hamilto-
nian difference systems with nonlinear dependence on a spectral parameter. Appl. Math. Lett.
43, 114‚Äì119 (2015)
96. O. Do≈°l√Ω, J. Elyseeva, An oscillation criterion for discrete trigonometric systems. J. Differ.
Equ. Appl. 21(12), 1256‚Äì1276 (2015)
97. O. Do≈°l√Ω, S. Hilger, R. Hilscher, Symplectic dynamic systems, in Advances in Dynamic
Equations on Time Scales, ed. by M. Bohner, A. Peterson (Birkh√§user, Boston, 2003),
pp. 293‚Äì334
98. O. Do≈°l√Ω, R. Hilscher, Linear Hamiltonian difference systems: transformations, recessive
solutions, generalized reciprocity. Dynam. Syst. Appl. 8(3‚Äì4), 401‚Äì420 (1999)
99. O. Do≈°l√Ω, R. Hilscher, Disconjugacy, transformations and quadratic functionals for symplectic
dynamic systems on time scales. J. Differ. Equ. Appl. 7, 265‚Äì295 (2001)
100. O. Do≈°l√Ω, R. Hilscher, V. Zeidan, Nonnegativity of discrete quadratic functionals correspond-
ing to symplectic difference systems. Linear Algebra Appl. 375, 21‚Äì44 (2003)
101. O. Do≈°l√Ω, W. Kratz, A Sturmian separation theorem for symplectic difference systems. J.
Math. Anal. Appl. 325, 333‚Äì341 (2007)
102. O. Do≈°l√Ω, W. Kratz, Oscillation theorems for symplectic difference systems. J. Differ. Equ.
Appl. 13, 585‚Äì60 (2007)
103. O. Do≈°l√Ω, W. Kratz, Oscilation and spectral theory for symplectic difference systems with
separated boundeary conditions. J. Differ. Equ. Appl. 16, 831‚Äì846 (2010)
104. O. Do≈°l√Ω, W. Kratz, A remark on focal points of recessive solutions of discrete symplectic
systems. J. Math. Anal. Appl. 363, 209‚Äì213 (2010)
105. O. Do≈°l√Ω, W. Kratz, Singular Sturmian theory for linear Hamiltonian differential systems.
Appl. Math. Lett. 26, 1187‚Äì1191 (2013)
106. O. Do≈°l√Ω, ≈†. Pechancov√°, Trigonometric recurrence relations and tridiagonal trigonometric
matrices. Int. J. Differ. Equ. 1(1), 19‚Äì29 (2006)
107. O. Do≈°l√Ω, ≈†. Pechancov√°, Generalized zeros of 2 √ó 2 symplectic difference system and of its
reciprocal system. Adv. Differ. Equ. 2011(Article ID 571935), 23 pp. (2011)
108. O. Do≈°l√Ω, Z. Posp√≠≈°il, Hyperbolic transformation and hyperbolic difference systems. Fasc.
Math. 32, 26‚Äì48 (2001)
109. H.I. Dwyer, A. Zettl, Computing eigenvalues of regular Sturm‚ÄìLiouville problems. Electron.
J. Differ. Equ. 1994(6), 10 pp. (1994)
110. S. Elaydi, An Introduction to Difference Equations, 3rd edn. Undergraduate Texts in
Mathematics (Springer, New York, NY, 2005)
111. Yu.V. Eliseeva, An algorithm for solving the matrix difference Riccati equation. Comput.
Math. Math. Phys. 39(2), 177‚Äì184 (1999)

578
References
112. J.V. Elyseeva, A transformation for symplectic systems and the deÔ¨Ånition of a focal point.
Comput. Math. Appl. 47, 123‚Äì134 (2004)
113. J.V. Elyseeva, Symplectic factorizations and the deÔ¨Ånition of a focal point, in Proceedings of
the Eighth International Conference on Difference Equations and Applications (Brno, 2003),
ed. by S. Elaydi, G. Ladas, B. Aulbach, O. Do≈°l√Ω (Chapman & Hall/CRC, Boca Raton, FL,
2005), pp. 127‚Äì135
114. J.V. Elyseeva, The comparative index for conjoined bases of symplectic difference systems,
in Difference Equations, Special Functions, and Orthogonal Polynomials, Proceedings of the
International Conference (Munich, 2005), ed. by S. Elaydi, J. Cushing, R. Lasser, A. RufÔ¨Ång,
V. Papageorgiou, W. Van Assche (World ScientiÔ¨Åc, London, 2007), pp. 168‚Äì177
115. Yu.V. Eliseeva, Comparative index for solutions of symplectic difference systems. Differential
Equations 45(3), 445‚Äì459 (2009)
116. J.V. Elyseeva, Transformations and the number of focal points for conjoined bases of
symplectic difference systems. J. Differ. Equ. Appl. 15(11‚Äì12), 1055‚Äì1066 (2009)
117. Yu.V. Eliseeva, Comparison theorems for symplectic systems of difference equations. Differ-
ential Equations 46(9), 1339‚Äì1352 (2010)
118. J.V. Elyseeva, On relative oscillation theory for symplectic eigenvalue problems. Appl. Math.
Lett. 23, 1231‚Äì1237 (2010)
119. J.V. Elyseeva, The comparative index and the number of focal points for conjoined bases of
symplectic difference systems, in Discrete Dynamics and Difference Equations, Proceedings
of the Twelfth International Conference on Difference Equations and Applications (Lisbon,
2007), ed. by S. Elaydi, H. Oliveira, J.M. Ferreira, J.F. Alves (World ScientiÔ¨Åc, London,
2010), pp. 231‚Äì238
120. Yu.V. Eliseeva, Spectra of discrete symplectic eigenvalue problems with separated boundary
conditions. Russ. Math. (Iz. VUZ) 55(11), 71‚Äì75 (2011)
121. J.V. Elyseeva, Comparative Index in Mathematical Modelling of Oscillations of Discrete
Symplectic Systems, (in Russian) (Moscow State University of Technology ‚ÄúStankin‚Äù,
Moscow, 2011)
122. Yu.V. Eliseeva, An approach for computing eigenvalues of discrete symplectic boundary-
value problems. Russ. Math. (Iz. VUZ) 56(7), 47‚Äì51 (2012)
123. J.V. Elyseeva, A note on relative oscillation theory for symplectic difference systems with
general boundary conditions. Appl. Math. Lett. 25(11), 1809‚Äì1814 (2012)
124. J.V. Elyseeva, Relative oscillation theory for matrix Sturm-Liouville difference equations
extended. Adv. Differ. Equ. 2013(328), 25 pp. (2013)
125. J.V. Elyseeva, Generalized oscillation theorems for symplectic difference systems with
nonlinear dependence on spectral parameter. Appl. Math. Comput. 251, 92‚Äì107 (2015)
126. J.V. Elyseeva, Generalized reciprocity principle for discrete symplectic systems. Electron. J.
Qual. Theory Differ. Equ. 2015(95), 12 pp. (2015) (electronic)
127. J.V. Elyseeva, Comparison theorems for conjoined bases of linear Hamiltonian differential
systems and the comparative index. J. Math. Anal. Appl. 444(2), 1260‚Äì1273 (2016)
128. J.V. Elyseeva, Comparison theorems for weighted focal points of conjoined bases of
Hamiltonian difference systems, in Differential and Difference Equations with Applications,
Proceedings of the International Conference on Differential & Difference Equations and
Applications (Amadora, 2015), ed. by S. Pinelas, Z. Do≈°l√°, O. Do≈°l√Ω, P.E. Kloeden. Springer
Proceedings in Mathematics & Statistics, Vol. 164 (Springer, Berlin, 2016), pp. 225‚Äì233
129. J.V. Elyseeva, On symplectic transformations of linear Hamiltonian differential systems
without normality. Appl. Math. Lett. 68, 33‚Äì39 (2017)
130. J.V. Elyseeva, The comparative index and transformations of linear Hamiltonian differential
systems. Appl. Math. Comput. 330, 185‚Äì200 (2018)
131. J.V. Elyseeva, Oscillation theorems for linear Hamiltonian systems with nonlinear depen-
dence on the spectral parameter and the comparative index. Appl. Math. Lett. 90, 15‚Äì22
(2019)

References
579
132. J.V. Elyseeva, A.A. Bondarenko, The Schur complement in an algorithm for calculation of
focal points of conjoined bases of symplectic difference systems. Int. J. Pure Appl. Math.
67(4), 455‚Äì474 (2011)
133. J.V. Elyseeva, R. ≈†imon Hilscher, Discrete oscillation theorems for symplectic eigenvalue
problems with general boundary conditions depending nonlinearly on spectral parameter.
Linear Algebra Appl. 558, 108‚Äì145 (2018)
134. L. Erbe, P. Yan, Disconjugacy for linear Hamiltonian difference systems. J. Math. Anal. Appl.
167, 355‚Äì367 (1992)
135. L. Erbe, P. Yan, Qualitative properties of Hamiltonian differece systems. J. Math. Anal. Appl.
171, 334‚Äì345 (1992)
136. L. Erbe, P. Yan, Oscillation criteria for Hamiltonian matrix difference systems. Proc. Am.
Math. Soc. 119, 525‚Äì533 (1993)
137. L. Erbe, P. Yan, On the discrete Riccati equation and its application to discrete Hamiltonian
systems. Rocky Mt. J. Math. 25, 167‚Äì178 (1995)
138. R. Fabbri, R. Johnson, S. Novo, C. N√∫√±ez, Some remarks concerning weakly disconjugate
linear Hamiltonian systems. J. Math. Anal. Appl. 380(2), 853‚Äì864 (2011)
139. H. Fassbender, Symplectic Methods for the Symplectic Eigenproblem (Kluwer, New York.
NY, 2000)
140. K. Feng, The Hamiltonian way for computing Hamiltonian dynamics, in Applied and
Industrial Mathematics (Venice, 1989). Math. Appl., Vol. 56 (Kluwer, Dordrecht, 1991),
pp. 17‚Äì35
141. K. Feng, M. Qin, Symplectic Geometric Algorithms for Hamiltonian Systems. Translated and
revised from the Chinese original. With a foreword by Feng Duan, Zhejiang Science and
Technology Publishing House, Hangzhou, Springer, Heidelberg, 2010
142. K. Feng, D. Wang, A note on conservation laws of symplectic difference schemes for
Hamiltonian systems. J. Comput. Math. 9(3), 229‚Äì237 (1991)
143. K. Feng, H. Wu, M. Qin, Symplectic difference schemes for linear Hamiltonian canonical
systems. J. Comput. Math. 8(4), 371‚Äì380 (1990)
144. A. Fischer, C. Remling, The absolutely continuous spectrum of discrete canonical systems.
Trans. Am. Math. Soc. 361(2), 793‚Äì818 (2009)
145. S. Flach, A.V. Gorbach, Discrete breathers ‚Äì advances in theory and applications. Phys. Rep.
467, 1‚Äì116 (2008)
146. T.E. Fortmann, A matrix inversion identity. IEEE Trans. Automat. Control 15, 599‚Äì599
(1970)
147. F.R. Gantmacher, Lectures in Analytical Mechanics (MIR Publischers, Moscow, 1975)
148. F.R. Gantmacher, Theory of Matrices (AMS Chelsea Publishing, Providence, RI, 1998)
149. C. Gao, R. Ma, Eigenvalues of discrete linear second-order periodic and antiperiodic
eigenvalue problems with sign-changing weight. Linear Algebra Appl. 467, 40‚Äì56 (2015)
150. C. Gao, R. Ma, Eigenvalues of discrete Sturm‚ÄìLiouville problems with eigenparameter
dependent boundary conditions. Linear Algebra Appl. 503, 100‚Äì119 (2016)
151. W. Gautschi, Computational aspects of three term recurrence relations. SIAM Rev. 9, 24‚Äì82
(1967)
152. I.M. Gelfand, M.M. Kapranov, A.V. Zelevinsky, Discriminants, Resultants, and Multidimen-
sional Determinants (Birkh√§user, Boston, 1994)
153. F. Gesztesy, B. Simon, G. Teschl, Zeros of the Wronskian and renormalized oscillation theory.
Am. J. Math. 118(3), 571‚Äì594 (1996)
154. S.K. Godunov, VeriÔ¨Åcation of boundedness for the powers of symplectic matrices with the
help of averaging. Sib. Math. J. 33(6), 939‚Äì949 (1992)
155. S.K. Godunov, M. Sadkane, Numerical determination of a canonical form of a symplectic
matrix. Sib. Math. J. 42(4), 629‚Äì647 (2001)
156. I.C. Gohberg, M.G. Krein, Theory and Applications of Volterra Operators in Hilbert Space.
Translations of Mathematical Monographs, Vol. 24 (American Mathematical Society, 1970)
157. G.H. Golub, C.F. Van Loan, Matrix Computations. John Hopkins Series in Mathematical
Sciences, 2nd edn. (John Hopkins University Press, Baltimore, MD, 1989)

580
References
158. L. Greenberg, An oscillation method for fourth order self-adjoint two-point boundary value
problems with nonlinear eigenvalues. SIAM J. Math. Anal. 22, 1021‚Äì1042 (1991)
159. L. Greenberg, A Pr√ºfer method for calculating eigenvalues of self-adjoint systems of ordinary
differential equations, technical report Tr91-24, University of Maryland, College Park, MD,
1991
160. L. Greenberg, M. Marletta, Algorithm 775: The code SLEUTH for solving fourth-order
Sturm‚ÄìLiouville problems. ACM Trans. Math. Software 23, 453‚Äì493 (1997)
161. L. Greenberg, M. Marletta, Numerical methods for higher order Sturm‚ÄìLiouville problems.
J. Comput. Appl. Math. 125, 367‚Äì383 (2000)
162. D. Greenspan, Discrete Models (Addison-Wesley, London, 1973)
163. E. Hairer, S.P. Norsett, G. Wanner, Ordinary Differential Equations I: Nonstiff Problems
(Springer, New York, NY, 2008)
164. E. Hairer, G. Wanner, Solving Ordinary Differential Equations II: Stiff and Differential-
Algebraic Problems (Springer, New York, NY, 2010)
165. A. Halanay, V. RÀòasvan, Stability and boundary value problems for discrete-time linear
Hamiltonian systems. Dynam. Syst. Appl. 8(3‚Äì4), 439‚Äì459 (1999)
166. B.J. Harmsen, A. Li, Discrete Sturm‚ÄìLiouville problems with parameter in the boundary
conditions. J. Differ. Equ. Appl. 8(11), 969‚Äì981 (2002)
167. B.J. Harmsen, A. Li, Discrete Sturm‚ÄìLiouville problems with nonlinear parameter in the
boundary conditions. J. Differ. Equ. Appl. 13(7), 639‚Äì653 (2007)
168. P. Hartman, Ordinary Differential Equations (Wiley, New York, NY, 1964)
169. P. Hartman, Difference equations: disconjugacy, principal solutions, Green‚Äôs function, com-
plete monotonicity. Trans. Am. Math. Soc. 246, 1‚Äì30 (1978)
170. R.E. Hartwig, A note on the partial ordering of positive semi-deÔ¨Ånite matrices. Linear
Multilinear Algebra 6(3), 223‚Äì226 (1978/79)
171. R. Hilscher, Disconjugacy of symplectic systems and positivity of block tridiagonal matrices.
Rocky Mt. J. Math. 29(4), 1301‚Äì1319 (1999)
172. R. Hilscher, Reid roundabout theorem for symplectic dynamic systems on time scales. Appl.
Math. Optim. 43(2), 129‚Äì146 (2001)
173. R. Hilscher, V. RÀöu≈æiÀáckov√°, Implicit Riccati equations and discrete symplectic systems. Int. J.
Differ. Equ. 1, 135‚Äì154 (2006)
174. R. Hilscher, V. RÀöu≈æiÀáckov√°, Riccati inequality and other results for discrete symplectic systems.
J. Math. Anal. Appl. 322(2), 1083‚Äì1098 (2006)
175. R. Hilscher, V. RÀöu≈æiÀáckov√°, Perturbation of time scale quadratic functionals with variable
endpoints. Adv. Dyn. Syst. Appl. 2(2), 207‚Äì224 (2007)
176. R. Hilscher, P. ÀáReh√°k, Riccati inequality, disconjugacy, and reciprocity principle for linear
Hamiltonian dynamic systems. Dynam. Syst. Appl. 12(1‚Äì2), 171‚Äì189 (2003)
177. R. Hilscher, V. Zeidan, Discrete optimal control: the accessory problem and necessary
optimality conditions. J. Math. Anal. Appl. 243(2), 429‚Äì452 (2000)
178. R. Hilscher, V. Zeidan, Second order sufÔ¨Åciency criteria for a discrete optimal control
problem. J. Differ. Equ. Appl. 8(6), 573‚Äì602 (2002)
179. R. Hilscher, V. Zeidan, Discrete optimal control: second order optimality conditions. J. Differ.
Equ. Appl. 8(10), 875‚Äì896 (2002)
180. R. Hilscher, V. Zeidan, Coupled intervals in the discrete calculus of variations: necessity and
sufÔ¨Åciency. J. Math. Anal. Appl. 276(1), 396‚Äì421 (2002)
181. R. Hilscher, V. Zeidan, Symplectic difference systems: variable stepsize discretization and
discrete quadratic functionals. Linear Algebra Appl. 367, 67‚Äì104 (2003)
182. R. Hilscher, V. Zeidan, Nonnegativity of a discrete quadratic functional in terms of the
(strengthened) Legendre and Jacobi conditions. Comput. Math. Appl. 45(6‚Äì9), 1369‚Äì1383
(2003)
183. R. Hilscher, V. Zeidan, A remark on discrete quadratic functionals with separable endpoints.
Rocky Mt. J. Math. 33(4), 1337‚Äì1351 (2003)
184. R. Hilscher, V. Zeidan, Coupled intervals in the discrete optimal control. J. Differ. Equ. Appl.
10(2), 151‚Äì186 (2004)

References
581
185. R. Hilscher, V. Zeidan, Discrete quadratic functionals with jointly varying endpoints via
separable endpoints, in New Progress in Difference Equations, Proceedings of the Sixth
International Conference on Difference Equations (Augsburg, 2001), ed. by B. Aulbach,
S. Elaydi, G. Ladas (Chapman & Hall/CRC, Boca Raton, FL, 2004), pp. 461‚Äì470
186. R. Hilscher, V. Zeidan, Nonnegativity and positivity of a quadratic functional in the discrete
calculus of variations: A survey. J. Differ. Equ. Appl. 11(9), 857‚Äì875 (2005)
187. R. Hilscher, V. Zeidan, Time scale symplectic systems without normality. J. Differ. Equ.
230(1), 140‚Äì173 (2006)
188. R. Hilscher, V. Zeidan, Coupled intervals for discrete symplectic systems. Linear Algebra
Appl. 419(2‚Äì3), 750‚Äì764 (2006)
189. R. Hilscher, V. Zeidan, Extension of discrete LQR‚Äìproblem to symplectic systems. Int. J.
Differ. Equ. 2(2), 197‚Äì208 (2007)
190. R. Hilscher, V. Zeidan, Applications of time scale symplectic systems without normality. J.
Math. Anal. Appl. 340(1), 451‚Äì465 (2008)
191. R. Hilscher, V. Zeidan, Riccati equations for abnormal time scale quadratic functionals. J.
Differ. Equ. 244(6), 1410‚Äì1447 (2008)
192. R. Hilscher, V. Zeidan, Weak maximum principle and accessory problem for control problems
on time scales. Nonlinear Anal. 70(9), 3209‚Äì3226 (2009)
193. R. Hilscher, V. Zeidan, Multiplicities of focal points for discrete symplectic systems: revisited.
J. Differ. Equ. Appl. 15(10), 1001‚Äì1010 (2009)
194. R. Hilscher, P. Zem√°nek, Trigonometric and hyperbolic systems on time scales. Dynam. Syst.
Appl. 18(3‚Äì4), 483‚Äì506 (2009)
195. R.A. Horn, C.R. Johnson, Topics in Matrix Analysis (Cambridge University Press, Cam-
bridge, 1991)
196. P. Howard, S. Jung, B. Kwon, The Maslov index and spectral counts for linear Hamiltonian
systems on [0, 1]. J. Dynam. Differ. Equ. 30(4), 1703‚Äì1729 (2018)
197. X. Huang, A. Jiang, Z. Zhang, H. Hua, Design and optimization of periodic structure
mechanical Ô¨Ålter in suppression of foundation resonances. J. Sound Vib. 330, 4689‚Äì4712
(2011)
198. Y. Huanga, Z. Denga, L. Yaoa, An improved symplectic precise integration method for
analysis of the rotating rigid-Ô¨Çexible coupled system. J. Sound Vib. 299, 229‚Äì246 (2007)
199. J. Ji, B. Yang, Eigenvalue comparison for boundary value problems for second order
difference equations. J. Math. Anal. Appl. 320(2), 964‚Äì972 (2006)
200. R. Johnson, S. Novo, C. N√∫√±ez, R. Obaya, Uniform weak disconjugacy and principal
solutions for linear Hamiltonian systems, in Recent Advances in Delay Differential and
Difference Equations (Balatonfuered, Hungary, 2013). Springer Proceedings in Mathematics
& Statistics, Vol. 94 (Springer, Berlin, 2014), pp. 131‚Äì159
201. R. Johnson, S. Novo, C. N√∫√±ez, R. Obaya, Nonautonomous linear-quadratic dissipative
control processes without uniform null controllability. J. Dynam. Differ. Equ. 29(2), 355‚Äì383
(2017)
202. R. Johnson, C. N√∫√±ez, R. Obaya, Dynamical methods for linear Hamiltonian systems with
applications to control processes. J. Dynam. Differ. Equ. 25(3), 679‚Äì713 (2013)
203. R. Johnson, R. Obaya, S. Novo, C. N√∫√±ez, R. Fabbri, Nonautonomous Linear Hamiltonian
Systems: Oscillation, Spectral Theory and Control. Developments in Mathematics, Vol. 36
(Springer, Cham, 2016)
204. W.G. Kelley, A. Peterson, Difference Equations: An Introduction with Applications (Aca-
demic Press, San Diego, CA, 1991)
205. W. Kratz, Quadratic Functionals in Variational Analysis and Control Theory. Mathematical
Topics, Vol. 6 (Akademie Verlag, Berlin, 1995)
206. W. Kratz, Banded matrices and difference equations. Linear Algebra Appl. 337(1‚Äì3), 1‚Äì20
(2001)
207. W. Kratz, DeÔ¨Ånitnes of quadratic functionals. Analysis (Munich) 23, 163‚Äì183 (2003)
208. W. Kratz, Discrete oscillation. J. Differ. Equ. Appl. 9, 127‚Äì135 (2003)

582
References
209. W. Kratz, R. ≈†imon Hilscher, Rayleigh principle for linear Hamiltonian systems without
controllability. ESAIM Control Optim. Calc. Var. 18(2), 501‚Äì519 (2012)
210. W. Kratz, R. ≈†imon Hilscher, A generalized index theorem for monotone matrix-valued
functions with applications to discrete oscillation theory. SIAM J. Matrix Anal. Appl. 34(1),
228‚Äì243 (2013)
211. W. Kratz, R. ≈†imon Hilscher, V. Zeidan, Eigenvalue and oscillation theorems for time scale
symplectic systems. Int. J. Dyn. Syst. Differ. Equ. 3(1‚Äì2), 84‚Äì131 (2011)
212. W. Kratz, M. Tentler, Recursion formulae for the characteristic polynomial of symmetric
banded matrices. Linear Algebra Appl. 428, 2482‚Äì2500 (2008)
213. H. Kr√ºger, G. Teschl, Relative oscillation theory, weighted zeros of the Wronskian, and
spectral shift function. Comm. Math. Phys. 287, 613‚Äì640 (2009)
214. G. Ladas, E.A. Grove, M.R.S. Kulenovic, Progress report on rational difference equations. J.
Differ. Equ. Appl. 10, 1313‚Äì1327 (2004)
215. A.J. Laub, Matrix Analysis for Scientists and Engineers (SIAM, Philadelphia, PA, 2005)
216. P.D. Lax, Linear Algebra, Pure and Applied Mathematics (New York), A Wiley-Interscience
Publication (Wiley, New York, 1997)
217. V. Ledoux, M. Van Daele, G. Vanden Berghe, EfÔ¨Åcient computation of high index Sturm‚Äì
Liouville eigenvalues for problems in physics. Comput. Phys. Comm. 180, 241‚Äì250 (2009)
218. J.V. Lill, T.G. Schmalz, J.C. Light, Imbedded matrix Green‚Äôs functions in atomic and
molecular scattering theory. J. Chem. Phys. 78, 4456‚Äì4463 (1983)
219. W.W. Lin, V. Mehrmann, H. Xu, Canonical forms for Hamiltonian and symplectic matrices
and pencils. Linear Algebra Appl. 302‚Äì303, 469‚Äì533 (1999)
220. X.-S. Liu, Y.-Y. Qi, J.-F. He, P.-Z. Ding, Recent progress in symplectic algorithms for use in
quantum systems. Commun. Comput. Phys. 2(1), 1‚Äì53 (2007)
221. Y. Liu, Y. Shi, Regular approximations of spectra of singular discrete linear Hamiltonian
systems with one singular endpoint. Linear Algebra Appl. 451, 94‚Äì130 (2018)
222. V. Loan, A Symplectic method for approximating all the eigenvalues of a Hamiltonian matrix.
Linear Algebra Appl. 61, 233‚Äì251 (1984)
223. D.G. Luenberger, Linear and Nonlinear Programming, 2nd edn. (Addison-Wesley, Reading,
MA, 1984)
224. D.S. Mackey, N. Mackey, F. Tisseur, Structured tools for structured matrices. Electron. J.
Linear Algebra 10, 106‚Äì145 (2003)
225. B. Marinkovi¬¥c, Optimality conditions in discrete optimal control problems with state
constraints. Numer. Funct. Anal. Optim. 28(7‚Äì8), 945‚Äì955 (2007)
226. B. Marinkovi¬¥c, Optimality conditions for discrete optimal control problems with equality and
inequality type of constraints. Positivity 12(3), 535‚Äì545 (2008)
227. B. Marinkovi¬¥c, Second order optimality conditions in a discrete optimal control problem.
Optimization 57(4), 539‚Äì548 (2008)
228. C.R. Maple, M. Marletta, Solving Hamiltonian systems arising from ODE eigenproblems.
Numer. Algorithms 22(3), 263‚Äì284 (1999)
229. M. Marletta, Automatic solution of regular and singular vector Sturm‚ÄìLiouville problems.
Numer. Algorithms 4, 65‚Äì99 (1993)
230. M. Marletta, Numerical solution of eigenvalue problems for Hamiltonian systems. Adv.
Comput. Math. 2(2), 155‚Äì184 (1994)
231. G. Marsaglia, G.P.H. Styan, Equalities and inequalities for ranks of matrices. Linear
Multilinear Algebra 2, 269‚Äì292 (1974)
232. J. Marsden, M. West, Discrete mechanics and variational integrators. Acta Numer. 10, 357‚Äì
514 (2001)
233. J. McMahona, S. Grayb, G. Schatza, A discrete action principle for electrodynamics and the
construction of explicit symplectic integrators for linear, non-dispersive media. J. Comput.
Phys. 228, 3421‚Äì3432 (2009)
234. V. Mehrmann, A symplectic orthogonal method for single input or single output discrete time
optimal quadratic control problems. SIAM J. Matrix Anal. Appl. 9, 221‚Äì247 (1988)

References
583
235. S.J. Monaquel, K.M. Schmidt, On M-functions and operator theory for non-self-adjoint
discrete Hamiltonian systems. J. Comput. Appl. Math. 208(1), 82‚Äì101 (2007)
236. M. Morse, Variational Analysis: Critical Extremals and Sturmian Extensions (Willey,
New York, NY, 1973)
237. P. Nelson, On the effectiveness of the inverse Riccati transformation in the matrix case. J.
Math. Anal. Appl. 67, 201‚Äì210 (1978)
238. F.W.J. Olver, D.J. Sookne, Note on backward recurrence algorithms. Math. Comp. 26, 941‚Äì
947 (1972)
239. C. Paige, C. Van Loan, A Schur decomposition for Hamiltonian matrices. Linear Algebra
Appl. 41, 11‚Äì32 (1981)
240. H.J. Peng, Q. Gao, Z.G. Wu, W.X. Zhong, Symplectic adaptive algorithm for solving
nonlinear two-point boundary value problems in astrodynamics. Celestial Mech. Dynam.
Astronom. 110(4), 319‚Äì342 (2011)
241. C.H. Rasmussen, Oscillation and asymptotic behaviour of systems of ordinary linear differ-
ential equations. Trans. Am. Math. Soc. 256, 1‚Äì49 (1979)
242. V. RÀòasvan, Stability zones for discrete time Hamiltonian systems. Arch. Math. (Brno) 36(5),
563‚Äì573 (2000) (electronic)
243. V. RÀòasvan, Stability zones and parametric resonance for discrete-time Hamiltonian systems.
Dynamic Systems and Applications, Vol. 4 (Dynamic, Atlanta, GA, 2004), pp. 367‚Äì373
244. V. RÀòasvan, On stability zones for discrete-time periodic linear Hamiltonian systems. Adv.
Differ. Equ. 2006(Art. 80757), 1‚Äì13 (2006)
245. W.T. Reid, A Pr√ºfer transformation for differential systems. PaciÔ¨Åc J. Math. 8, 575‚Äì584
(1958)
246. W.T. Reid, Riccati matrix differential equations and non-oscillation criteria for associated
linear differential systems. PaciÔ¨Åc J. Math. 13, 665‚Äì685 (1963)
247. W.T. Reid, Generalized polar coordinate transformations for differential systems. Rocky
Mountain J. Math. 1(2), 383‚Äì406 (1971)
248. W.T. Reid, Ordinary Differential Equations (Wiley, New York, NY, 1971)
249. W.T. Reid, Riccati Differential Equations (Academic Press, New York, NY, 1972)
250. W.T. Reid, Sturmian Theory for Ordinary Differential Equations (Springer, New York, NY,
1980)
251. G. Ren, On the density of the minimal subspaces generated by discrete linear Hamiltonian
systems. Appl. Math. Lett. 27, 1‚Äì5 (2014)
252. G. Ren, Y. Shi, Defect indices and deÔ¨Åniteness conditions for a class of discrete linear
Hamiltonian systems. Appl. Math. Comput. 218(7), 3414‚Äì3429 (2011)
253. G. Ren, Y. Shi, Self-adjoint extensions for discrete linear Hamiltonian systems. Linear
Algebra Appl. 454, 1‚Äì48 (2014)
254. F.S. Rofe-Beketov, A.M. Kholkin, On the connection between spectral and oscillation
properties of the Sturm‚ÄìLiouville matrix problem. Math. USSR-Sb. 31(3), 365‚Äì378 (1977)
255. F.S. Rofe-Beketov, A.M. Kholkin, Spectral Analysis of Differential Operators. World Scien-
tiÔ¨Åc Monograph Series in Mathematics, Vol. 7 (World ScientiÔ¨Åc, Hackensack, NJ, 2005)
256. R.D. Ruth, A canonical integration technique. IEEE Trans. Nuclear Sci. 30, 2669‚Äì2671
(1983)
257. V.
RÀöu≈æiÀáckov√°,
Discrete
Symplectic
Systems
and
DeÔ¨Åniteness
of
Quadratic
Functionals,
PhD
dissertation,
Masaryk
University,
Brno,
2006.
Available
at
https://is.muni.cz/th/p9iz7/?lang=en
258. V. RÀöu≈æiÀáckov√°, Perturbation of discrete quadratic functionals. Tatra Mountains Math. Publ.
38(1), 229‚Äì241 (2007)
259. P. ÀáReh√°k, Oscillatory properties of second order half-linear difference equations. Czechoslo-
vak Math. J. 51(126)(2), 303‚Äì321 (2001)
260. J.M. Sanz-Serna, A. Portillo, Classical numerical integrators for wave-packet dynamics. J.
Chem. Phys. 104(6). 2349‚Äì2355 (1996)
261. H. Schulz-Baldes, Sturm intersection theory for periodic Jacobi matrices and linear Hamilto-
nian systems. Linear Algebra Appl. 436(3), 498‚Äì515 (2012)

584
References
262. G. Shi, H. Wu, Spectral theory of Sturm‚ÄìLiouville difference operators. Linear Algebra Appl.
430, 830‚Äì846 (2009)
263. Y. Shi, Symplectic structure of discrete Hamiltonian systems. J. Math. Anal. Appl. 266(2),
472‚Äì478 (2002)
264. Y. Shi, Spectral theory of discrete linear Hamiltonian systems. J. Math. Anal. Appl. 289(2),
554‚Äì570 (2004)
265. Y. Shi, Weyl‚ÄìTitchmarsh theory for a class of discrete linear Hamiltonian systems. Linear
Algebra Appl. 416, 452‚Äì519 (2006)
266. Y. Shi, Transformations for complex discrete linear Hamiltonian and symplectic systems.
Bull. Aust. Math. Soc. 75(2), 179‚Äì191 (2007)
267. Y. Shi, S. Chen, Spectral theory of second-order vector difference equations. J. Math. Anal.
Appl. 239(2), 195‚Äì212 (1999)
268. Y. Shi, S. Chen, Spectral theory of higher-order discrete vector Sturm‚ÄîLiouville problems.
Linear Algebra Appl. 323, 7‚Äì36 (2001)
269. Y. Shi, C. Shao, G. Ren, Spectral properties of self-adjoint subspaces. Linear Algebra Appl.
438(1), 191‚Äì218 (2013)
270. G.W. Stewart, J. Sun, Matrix Perturbation Theory (Academic Press, Boston, MA, 1990)
271. H. Sun, Q. Kong, Y. Shi, Essential spectrum of singular discrete linear Hamiltonian systems.
Math. Nachr. 289(2‚Äì3), 343‚Äì359 (2016)
272. H. Sun, Y. Shi, Strong limit point criteria for a class of singular discrete linear Hamiltonian
systems. J. Math. Anal. Appl. 336(1), 224‚Äì242 (2007)
273. H. Sun, Y. Shi, Self-adjoint extensions for linear Hamiltonian systems with two singular
endpoints. J. Funct. Anal. 259(8), 2003‚Äì2027 (2010)
274. H. Sun, Y. Shi, Self-adjoint extensions for singular linear Hamiltonian systems. Math. Nachr.
284(5‚Äì6), 797‚Äì814 (2011)
275. H. Sun, Y. Shi, Spectral properties of singular discrete linear Hamiltonian systems. J. Differ.
Equ. Appl. 20(3), 379‚Äì405 (2014)
276. H. Sun, Y. Shi, On essential spectra of singular linear Hamiltonian systems. Linear Algebra
Appl. 469, 204‚Äì229 (2015)
277. S. Sun, Y. Shi, S. Chen, The Glazman‚ÄìKrein‚ÄìNaimark theory for a class of discrete
Hamiltonian systems. J. Math. Anal. Appl. 327(2), 1360‚Äì1380 (2007)
278. N.G. Stephen, Transfer matrix analysis of the elastostatics of one-dimensional repetitive
structures. Proc. R. Soc. Lond. Ser. A Math. Phys. Eng. Sci. 462(2072), 2245‚Äì2270 (2006)
279. J.C.F. Sturm, Memoire sur une classe d‚Äô√©quations differ√©nces partielles. J. Math. Pures Appl.
1, 373‚Äì444 (1836)
280. C.A. Swanson, Comparison and Oscillation Theory of Linear Differential Equations (Aca-
demic Press, New York, NY, 1968)
281. P.
≈†epitka,
Theory
of
Principal
Solutions
at
InÔ¨Ånity
for
Linear
Hamiltonian
Systems,
PhD
dissertation,
Masaryk
University,
Brno,
2014.
Available
at
https://is.muni.cz/th/vqad7/?lang=en
282. P. ≈†epitka, Riccati equations for linear Hamiltonian systems without controllability condition.
Discrete Contin. Dyn. Syst. 39(4), 1685‚Äì1730 (2019)
283. P. ≈†epitka, R. ≈†imon Hilscher, Minimal principal solution at inÔ¨Ånity of nonoscillatory linear
Hamiltonian systems. J. Dynam. Differ. Equ. 26(1), 57‚Äì91 (2014)
284. P. ≈†epitka, R. ≈†imon Hilscher, Recessive solutions for nonoscillatory discrete symplectic
systems. Linear Algebra Appl. 469, 243‚Äì275 (2015)
285. P. ≈†epitka, R. ≈†imon Hilscher, Principal solutions at inÔ¨Ånity of given ranks for nonoscillatory
linear Hamiltonian systems. J. Dynam. Differ. Equ. 27(1), 137‚Äì175 (2015)
286. P. ≈†epitka, R. ≈†imon Hilscher, Principal and antiprincipal solutions at inÔ¨Ånity of linear
Hamiltonian systems. J. Differ. Equ. 259(9), 4651‚Äì4682 (2015)
287. P. ≈†epitka, R. ≈†imon Hilscher, Genera of conjoined bases of linear Hamiltonian systems and
limit characterization of principal solutions at inÔ¨Ånity. J. Differ. Equ. 260(8), 6581‚Äì6603
(2016)

References
585
288. P. ≈†epitka, R. ≈†imon Hilscher, Reid‚Äôs construction of minimal principal solution at inÔ¨Ånity
for linear Hamiltonian systems, in Differential and Difference Equations with Applications,
Proceedings of the International Conference on Differential & Difference Equations and
Applications (Amadora, 2015), S. Pinelas, Z. Do≈°l√°, O. Do≈°l√Ω, P.E. Kloeden, (eds.), Springer
Proceedings in Mathematics & Statistics, Vol. 164 (Springer, Berlin, 2016), pp. 359‚Äì369
289. P. ≈†epitka, R. ≈†imon Hilscher, Comparative index and Sturmian theory for linear Hamiltonian
systems. J. Differ. Equ. 262(2), 914‚Äì944 (2017)
290. P. ≈†epitka, R. ≈†imon Hilscher, Dominant and recessive solutions at inÔ¨Ånity and genera of
conjoined bases for discrete symplectic systems. J. Differ. Equ. Appl. 23(4), 657‚Äì698 (2017)
291. P. ≈†epitka, R. ≈†imon Hilscher, Focal points and principal solutions of linear Hamiltonian
systems revisited. J. Differ. Equ. 264(9), 5541‚Äì5576 (2018)
292. P. ≈†epitka, R. ≈†imon Hilscher, Singular Sturmian separation theorems for nonoscillatory
symplectic difference systems. J. Differ. Equ. Appl. 24(12), 1894‚Äì1934 (2018)
293. P. ≈†epitka, R. ≈†imon Hilscher, Singular Sturmian separation theorems on unbounded intervals
for linear Hamiltonian systems. J. Differ. Equ. 266(11), 7481‚Äì7524 (2019)
294. R. ≈†imon Hilscher, A note on the time scale calculus of variations problems, in Ulmer
Seminare √ºber Funktionalanalysis und Differentialgleichungen, Vol. 14 (University of Ulm,
Ulm, 2009), pp. 223‚Äì230
295. R. ≈†imon Hilscher, Sturmian theory for linear Hamiltonian systems without controllability.
Math. Nachr. 284(7), 831‚Äì843 (2011)
296. R. ≈†imon Hilscher, On general Sturmian theory for abnormal linear Hamiltonian systems, in:
Dynamical Systems, Differential Equations and Applications, Proceedings of the 8th AIMS
Conference on Dynamical Systems, Differential Equations and Applications (Dresden, 2010),
W. Feng, Z. Feng, M. Grasselli, A. Ibragimov, X. Lu, S. Siegmund, J. Voigt (eds.), Discrete
Contin. Dynam. Systems, Suppl. 2011 (American Institute of Mathematical Sciences (AIMS),
SpringÔ¨Åeld, MO, 2011), pp. 684‚Äì691
297. R. ≈†imon Hilscher, Oscillation theorems for discrete symplectic systems with nonlinear
dependence in spectral parameter. Linear Algebra Appl. 437(12), 2922‚Äì2960 (2012)
298. R. ≈†imon Hilscher, Spectral and oscillation theory for general second order Sturm‚ÄìLiouville
difference equations. Adv. Differ. Equ. 2012(82), 19 pp. (2012)
299. R. ≈†imon Hilscher, Eigenvalue theory for time scale symplectic systems depending nonlin-
early on spectral parameter. Appl. Math. Comput. 219(6), 2839‚Äì2860 (2012)
300. R. ≈†imon Hilscher, Asymptotic properties of solutions of Riccati matrix equations and
inequalities for discrete symplectic systems. Electron. J. Qual. Theory Differ. Equ. 2015(54),
16 pp. (2015) (electronic)
301. R. ≈†imon Hilscher, Eigenvalue comparison for discrete symplectic systems, in Difference
Equations, Discrete Dynamical Systems and Applications, Proceedings of the 20th Inter-
national Conference on Difference Equations and Applications (Wuhan, 2014), ed. by
M. Bohner, Y. Ding, O. Do≈°l√Ω (Springer, Berlin, 2015), pp. 95‚Äì107
302. R. ≈†imon Hilscher, V. Zeidan, Picone type identities and deÔ¨Åniteness of quadratic functionals
on time scales. Appl. Math. Comput. 215(7), 2425‚Äì2437 (2009)
303. R. ≈†imon Hilscher, V. Zeidan, Symplectic structure of Jacobi systems on time scales. Int. J.
Differ. Equ. 5(1), 55‚Äì81 (2010)
304. R. ≈†imon Hilscher, V. Zeidan, Symmetric three-term recurrence equations and their symplec-
tic structure. Adv. Differ. Equ. 2010(Article ID 626942), 17 pp. (2010)
305. R. ≈†imon Hilscher, V. Zeidan, Oscillation theorems and Rayleigh principle for linear
Hamiltonian and symplectic systems with general boundary conditions. Appl. Math. Comput.
218(17), 8309‚Äì8328 (2012)
306. R. ≈†imon Hilscher, P. Zem√°nek, DeÔ¨Åniteness of quadratic functionals for Hamiltonian and
symplectic systems: A survey. Int. J. Differ. Equ. 4(1), 49‚Äì67 (2009)
307. R. ≈†imon Hilscher, P. Zem√°nek, New results for time reversed symplectic dynamic systems
and quadratic functionals, in Proceedings of the 9th Colloquium on Qualitative Theory of
Differential Equations, Vol. 9, No. 15, Electron. J. Qual. Theory Differ. Equ. (electronic)
(Szeged, 2012), 11 pp.

586
References
308. R. ≈†imon Hilscher, P. Zem√°nek, Weyl disks and square summable solutions for discrete
symplectic systems with jointly varying endpoints. Adv. Differ. Equ. 2013(232), 18 pp. (2013)
309. R. ≈†imon Hilscher, P. Zem√°nek, Weyl‚ÄìTitchmarsh theory for discrete symplectic systems with
general linear dependence on spectral parameter. J. Differ. Equ. Appl. 20(1), 84‚Äì117 (2014)
310. R. ≈†imon Hilscher, P. Zem√°nek, Limit point and limit circle classiÔ¨Åcation for symplectic
systems on time scales. Appl. Math. Comput. 233, 623‚Äì646 (2014)
311. R. ≈†imon Hilscher, P. Zem√°nek, Generalized Lagrange identity for discrete symplectic
systems and applications in Weyl‚ÄìTitchmarsh theory, in Theory and Applications of Dif-
ference Equations and Discrete Dynamical Systems, Proceedings of the 19th International
Conference on Difference Equations and Applications (Muscat, 2013), ed. by Z. AlSharawi,
J. Cushing, S. Elaydi. Springer Proceedings in Mathematics & Statistics, Vol. 102 (Springer,
Berlin, 2014), pp. 187‚Äì202
312. R. ≈†imon Hilscher, P. Zem√°nek, Time scale symplectic systems with analytic dependence on
spectral parameter. J. Differ. Equ. Appl. 21(3), 209‚Äì239 (2015)
313. R. ≈†imon Hilscher, P. Zem√°nek, Limit circle invariance for two differential systems on time
scales. Math. Nachr. 288(5‚Äì6), 696‚Äì709 (2015)
314. G. Teschl, Oscillation theory and renormalized oscillation theory for Jacobi operators. J.
Differ. Equ. 129, 532‚Äì558 (1996)
315. G. Teschl, Jacobi Operators and Completely Integrable Nonlinear Lattices (AMS Mathemat-
ical Surveys and Monographs, Providence, RI, 1999)
316. Y. Tian, Equalities and inequalities for inertias of Hermitian matrices with applications. Linear
Algebra Appl. 433, 263‚Äì296 (2010)
317. Y. Tian, Rank and inertia of submatrices of the Moore‚ÄìPenrose inverse of a Hermitian matrix.
Electron. J. Linear Algebra 20, 226‚Äì240 (2010)
318. P. Van Dooren, The computation of Kronecker‚Äôs canonical form of a singular pencil. Linear
Algebra Appl. 27, 103‚Äì140 (1979)
319. P. Van Dooren, P. Dewilde, The eigenstructure of an arbitrary polynomial matrix. Computa-
tional aspects. Linear Algebra Appl. 50, 545‚Äì579 (1983)
320. G. Verghese, P. Van Dooren, T. Kailath, Properties of the system matrix of a generalized
state-space system. Int. J. Control 30(2), 235‚Äì243 (1979)
321. M. Wahrheit, Eigenvalue problems and oscillation of linear Hamiltonian systems. Int. J.
Differ. Equ. 2, 221‚Äì244 (2007)
322. Y. Wang, Y. Shi, Eigenvalues of second-order difference equations with periodic and
antiperiodic boundary conditions. J. Math. Anal. Appl. 309(1), 56‚Äì69 (2005)
323. Y. Wang, Y. Shi, G. Ren, Transformations for complex discrete linear Hamiltonian and
symplectic systems. Bull. Aust. Math. Soc. 75(2), 179‚Äì191 (2007)
324. Y. Wu, Symplectic transformation and symplectic difference schemes. Chin. J. Numer. Math.
Appl. 12(1), 23‚Äì31 (1990)
325. L. Xue-Shen, Q. Yue-Ying, H. Jian-Feng, D. Pei-Zhu, Recent progress in symplectic
algorithms for use in quantum systems. Commun. Comput. Phys. 2(1), 1‚Äì53 (2007)
326. V.A. Yakubovich, Arguments on the group of symplectic matrices. Mat. Sb. 55, 255‚Äì280
(1961)
327. V.A. Yakubovich, Oscillatory properties of solutions of canonical equations. Mat. Sb. 56, 3‚Äì
42 (1962)
328. V.A. Yakubovich, V.M. Starzhinskii, Linear Differential Equations with Periodic CoefÔ¨Åcients,
2 volumes (Wiley, New York, 1975)
329. Y. Yal√ßin, L. G√∂ren S√ºmer, S. Kurtulan, Discrete-time modeling of Hamiltonian systems.
Turk. J. Electr. Eng. Comput. Sci. 23, 149‚Äì170 (2015)
330. V. Zeidan, Continuous versus discrete nonlinear optimal control problems, in Proceedings
of the 14th International Conference on Difference Equations and Applications (Istanbul,
2008), ed. by M. Bohner, Z. Do≈°l√°, G. Ladas, M. √únal, A. Zafer (UÀògur-Bah√ße¬∏sehir University
Publishing Company, Istanbul, 2009), pp. 73‚Äì93
331. V. Zeidan, Constrained linear-quadratic control problems on time scales and weak normality.
Dynam. Syst. Appl. 26(3‚Äì4), 627‚Äì662 (2017)

References
587
332. M.I. Zelikin, Control Theory and Optimization. I. Homogeneous Spaces and the Riccati
Equation in the Calculus of Variations. Encyclopaedia of Mathematical Sciences, Vol. 86
(Springer, Berlin, 2000)
333. P. Zem√°nek, Discrete trigonometric and hyperbolic systems: An overview, in Ulmer Seminare
√ºber Funktionalanalysis und Differentialgleichungen, Vol. 14 (University of Ulm, Ulm,
2009), pp. 345‚Äì359
334. P. Zem√°nek, Rofe-Beketov formula for symplectic systems. Adv. Differ. Equ. 2012(104), 9
pp. (2012)
335. P. Zem√°nek, S. Clark, Characterization of self-adjoint extensions for discrete symplectic
systems. J. Math. Anal. Appl. 440(1), 323‚Äì350 (2016)
336. A. Zettl, Sturm‚ÄìLiouville Theory (AMS Mathematical Surveys and Monographs, Providence,
RI, 2005)
337. Z. Zheng, Invariance of deÔ¨Åciency indices under perturbation for discrete Hamiltonian
systems. J. Differ. Equ. Appl. 19(8), 1243‚Äì1250 (2013)

Index
Admissible
pair, 31, 100, 106, 211, 298
sequence, 26
Boundary conditions
Dirichlet, 305
joint
linear, 323
nonlinear, 304, 398
separated
linear, 324
nonlinear, 304
Calculus of variations problem, 25, 78
Comparative index, 199, 216
deÔ¨Ånition, 150
dual, 152
duality principle, 159
estimates, 159
limit at ‚àí‚àû, 569
limit at ‚àû, 556, 561
main theorem, 156, 161
properties, 150, 153
triangle inequality, 157
Comparative index for symplectic matrices
additional properties, 191‚Äì193
basic properties, 173, 178
computation
general case, 180, 182
special case, 181
invertible block A, 185, 186
invertible block B, 183
for linear Hamiltonian system, 187
for Sturm‚ÄìLiouville equation, 183, 184,
189
Conjoined basis, 40, 84
with constant kernel, 464, 467, 470, 476,
480, 484, 485, 491, 493, 501, 521,
544, 551, 563
contained, 483‚Äì485, 491, 493, 511, 520,
521
with given rank, 464, 482, 490, 514, 520
intermediate, 495
maximal, 495
minimal, 495, 496, 507, 508, 540
natural, 117, 316, 382
normalized, 85
representation, 462, 470
Conjugate point, 49
Controllability matrix, 100
Controllable system, 42, 79, 128, 130, 133,
134, 510, 521, 531, 552, 560
Disconjugate equation, 7
Disconjugate system, 94, 104, 105
continuous case, 47, 49, 52
Dominant solution at ‚àí‚àû
deÔ¨Ånition, 562
Dominant solution at ‚àû, 11, 130, 133, 147,
550, 571
block diagonal construction, 523
classiÔ¨Åcation, 528
deÔ¨Ånition, 517
examples, 545
existence, 520
genus, 528
limit characterization, 543
¬© Springer Nature Switzerland AG 2019
O. Do≈°l√Ω et al., Symplectic Difference Systems: Oscillation and Spectral Theory,
Pathways in Mathematics, https://doi.org/10.1007/978-3-030-19373-7
589

590
Index
maximal, 518, 535, 540, 543, 551
minimal, 518, 521, 535
properties, 518‚Äì521, 531, 532
Eigenvalue problem
augmented, 309, 327
comparison of eigenvalues, 571
for Dirichlet endpoints, 16, 262, 338, 399,
400, 411
extended, 305, 326
intermediate, 454, 456
for joint endpoints, 304, 309, 310, 327
linear dependence, 323, 326, 327, 339, 394
for linear Hamiltonian system, 376
for separated endpoints, 304, 305, 307, 325,
326
Euler-Lagrange equation, 27, 36
Feasible pair, 30
Finite eigenfunction
for Dirichlet endpoints, 267, 335
for joint endpoints, 332
linear dependence, 332‚Äì334
for separated endpoints, 336
Finite eigenvalue, 338, 356
for Dirichlet endpoints, 265, 335
existence, 298, 299
interlacing properties, 571
for joint endpoints, 319, 331
linear dependence, 331, 335
properties, 266, 273, 332‚Äì334
for separated endpoints, 316, 335
variational description, 339
Focal point, 6
nonexistence backward, 96, 204, 222, 227,
240, 258, 562, 563
nonexistence forward, 92, 103, 107, 118,
119, 146, 204, 211, 221, 227, 240,
465, 484, 485, 491, 493, 501, 521,
544, 551
weighted forward, 377
Generalized zero, 4, 6, 94, 96, 210
of Wronskian, 399
of Wronskian, weighted, 400, 408
Genus of conjoined bases, 551
defect, 537
deÔ¨Ånition, 523
maximal, 524, 528, 552
minimal, 524, 530, 552, 560
near ‚àí‚àû, 562, 563, 568
for principal solution, 560, 568
properties, 524, 525, 528
rank, 537, 551, 563, 568
Hamiltonian matrix, 38
Hyperbolic system, 88, 142, 143
Identically normal system, 42
Image condition, 103, 110, 116, 117, 119
Index of block symmetric matrix, 166, 168
and comparative index, 167, 171
Index theorem, 81
application to spectral theory, 294
Inequalities for eigenvalues
for Dirichlet endpoints, 436
for joint endpoints, 438
for separated endpoints, 435
Inequalities for spectral functions, 433
for joint endpoints, 438, 440, 441
for separated endpoints, 435, 450, 451
Interlacing of eigenvalues
for Dirichlet endpoints, different intervals,
458
for joint endpoints, 441, 443, 444
for separated endpoints, 452, 454, 455, 457
Jacobi equation, 27, 41, 89, 146
Kernel condition, 92, 103, 106, 211
Legendre condition, 42, 53, 80, 257, 258
Linear Hamiltonian system, 28, 38, 87, 146,
187, 239, 302, 376, 395
continuous, v, 37, 40, 53, 79, 571, 572
Majorant condition, 238‚Äì240
for linear Hamiltonian systems, 239
for spectral problems
joint endpoints, 438
low block triangular perturbation, 437
matrix Sturm‚ÄìLiouville equation, 437
separated endpoints, 435
Matrix pencil, 338
Monotone matrix-valued function, 73
index theorem, 73, 74
limit theorem, 74, 75
Monotonicity in parameter
assumption, 262, 376

Index
591
Cayley transformation, 368
comparative index, 362
for joint endpoints, 304, 324
linear, 323, 324
nonlinear, 304
properties, 263, 264
for separated endpoints, 304, 324
for symplectic matrices, 323, 362
Moore‚ÄìPenrose generalized inverse, 58, 79
Multiplicity of Ô¨Ånite eigenvalue
algebraic, 265, 316, 320, 331
for Dirichlet endpoints, 331
geometric, 267, 332
linear dependence, 331
relation of algebraic and geometric, 267,
332
Multiplicity of focal point
backward, 203, 209, 258, 548
and comparative index, 205, 206, 258
connection forward and backward, 204,
224
continuous case, 42
estimates, 204
forward, 202, 208, 548
at ‚àí‚àû, 563
at ‚àû, 550
properties, 203
symplectic transformation, 248, 250, 251
Nonoscillatory conjoined basis
continuous case, 43
limit properties, 227
Nonoscillatory equation, 9, 12
Nonoscillatory system, 94, 130, 133, 134, 141,
227, 246, 463, 511, 514, 520, 521,
524, 525, 528, 530‚Äì532, 535, 538,
543, 544, 554, 556‚Äì558, 560, 561,
566‚Äì568
at ‚àí‚àû, 247, 563‚Äì569
continuous case, 43, 51, 52
Nonprincipal solution
at ‚àû, continuous case, 52
Optimal control problem, 29, 78
Order of abnormality, 461, 476
maximal, 461, 501, 505, 551, 560, 561
Orthogonal projector, 59, 464, 467, 482
Oscillation theorem
constant rank
global, Dirichlet endpoints, 23, 273,
298, 337, 352
global, joint endpoints, 320, 322
global, separated endpoints, 317, 319
linear dependence, 303, 337, 352
for linear Hamiltonian system, 302
local, 19, 21, 271
for Sturm‚ÄìLiouville equation, 10, 23,
300, 301, 303
global, continuous case, 53
nonconstant rank
generalized global, 380
generalized local, 378
global, Dirichlet endpoints, 357
global, separated endpoints, 385
local, 354, 373, 383, 389
Oscillatory conjoined basis
continuous case, 43
Oscillatory equation, 9
Oscillatory system, 94, 227, 464
continuous case, 43, 51
P -condition, 92, 106, 110, 117, 119, 211
Phase Ô¨Çow, 38
Picone identity, 6, 102
continuous case, 5, 46
extended, 340
Pontryagin maximum principle
weak, 31, 78
Principal solution, 85, 105, 119, 217, 218, 222,
225, 243, 265, 331, 351, 356, 388,
401, 437, 461, 462, 476, 530, 531,
548, 552, 558, 560, 565, 566, 568,
569
at ‚àû, continuous case, 52, 79
Pseudoinverse matrix, 58, 79
Quadratic functional, 26, 31, 99, 137
augmented, 315
continuous case, 4, 46, 47
for Dirichlet endpoints, 105, 107, 110, 331,
436
extended, 313
for joint endpoints, 119, 315, 328, 438
linear dependence, 328‚Äì331
nonnegative deÔ¨Ånite, 27, 32, 49, 110, 115,
117, 119, 147
positive deÔ¨Ånite, 7, 27, 32, 47, 105, 107,
117, 119, 124, 211, 313, 315,
329‚Äì331, 338, 342, 344, 346, 436,
438
for separated endpoints, 117, 313, 329, 330,
436
transformation, 313, 315, 328, 329

592
Index
Rayleigh principle
for Dirichlet endpoints, 342, 395
for joint endpoints, 346
for separated endpoints, 344
Recessive solution at ‚àí‚àû
deÔ¨Ånition, 562
minimal, 565‚Äì568
Recessive solution at ‚àû, 11, 12, 130, 133, 134,
147, 550, 571
block diagonal construction, 515
classiÔ¨Åcation, 525, 528
deÔ¨Ånition, 509
examples, 516, 545
existence, 514
genus, 524, 525
limit characterization, 532, 535
maximal, 510, 535
minimal, 509, 511, 521, 530, 535, 538, 548,
550, 558, 565, 567, 568
properties, 510, 511, 514, 521
Reid‚Äôs construction, 538, 572
Reciprocity principle, 16, 255
examples, 256
generalized, 253, 254, 260
Reid roundabout theorem, 7, 104, 108, 147
continuous case, 47
Relative oscillation numbers
basic properties, 235
deÔ¨Ånition, 233
for Dirichlet endpoints, 402, 415
interpretation, 233
for joint endpoints, 429
for matrix Sturm‚ÄìLiouville problems, 415
for principal solutions, 241
for separated endpoints, 424
Relative oscillation theorem, 569, 571
for Dirichlet endpoints, 401
for joint endpoints, 431
for low block triangular perturbations, 409
for matrix Sturm‚ÄìLiouville problems, 417
for separated endpoints, 425
Relative oscillation theory, 259, 397, 570
continuous, 259
Renormalized oscillation theorem
for Dirichlet endpoints, 403
for joint endpoints, 431
for low block triangular perturbations, 409
for matrix Sturm‚ÄìLiouville problems, 418
for separated endpoints, 426
Riccati inequality, 120, 121, 124, 147, 221,
222, 238, 240, 241
continuous case, 47
Riccati matrix equation, 80, 97, 134
continuous case, 45, 47
explicit, 107
implicit, 99, 105, 147
Riccati operator, 97
Self-reciprocal system, 139
Singular comparison theorems
limit properties, 247
S-matrix, 129, 562
deÔ¨Ånition, 465
dominant solution at inÔ¨Ånity, 518
properties, 484, 501, 503, 505
Solution
degenerate, 266
equivalent, 482
nondegenerate, 266
nonoscillatory, 9
oscillatory, 9
representable, 480
Sturmian comparison theorem, 347, 349, 395
global explicit relations, 237
inequalities for focal points, 244
local explicit relations, 230, 233, 369
for principal solutions, 243
singular, 246, 247
for triangular perturbations, 231
Sturmian separation theorem, 211, 350, 395,
549
continuous case, 43
estimates for focal points, 218‚Äì220, 224,
226
global explicit relations, 217, 218
local explicit relations, 216
for principal solutions, 225, 226, 549, 566
singular, 228, 554, 558, 564, 566, 567, 572
Sturm‚ÄìLiouville equation, 3, 40, 78, 90, 92,
94, 183, 184, 189, 259, 300, 301,
303, 385, 399, 411, 569
Symplectic difference system, v, 28, 83
augmented, 309, 327
Cayley, 369
extended, 305, 326
linear dependence, 303, 322
nonoscillatory, 463
oscillatory, 464
time-reversed, 86, 108, 489
without controllability, 460
Symplectic matrix, 38, 55, 62, 79, 83
depending on parameter, 67, 261, 262
fundamental, 462, 480
Three-term recurrence equation, 89, 146
T -matrix, 130, 550, 551, 557, 562, 563

Index
593
classiÔ¨Åcation, 508
deÔ¨Ånition, 465
dominant solution at inÔ¨Ånity, 521
properties, 503, 507, 537
Transformation
Bohl, 49, 139
Cayley, 368
global explicit relations, 250
hyperbolic, 141, 148
of joint boundary conditions, 309, 310, 327
local explicit relations, 248, 250
low block triangular, 252
Pr√ºfer, 14, 49, 50, 78, 144, 148
of separated boundary conditions, 305, 307,
325, 326
symplectic, 44, 135, 156, 248
J -transformation, 251
trigonometric, 49, 51, 139, 148, 260
Trigonometric system, 86, 139
continuous, 50
Wronskian, 42, 84, 150, 399, 480, 544, 550
forward difference, 230

