Emergence, Complexity and Computation ECC
Yaroslav D. Sergeyev
Renato De Leone   Editors
Numerical 
Infinities and 
Infinitesimals 
in Optimization

Emergence, Complexity and Computation
Volume 43
Series Editors
Ivan Zelinka, Technical University of Ostrava, Ostrava, Czech Republic
Andrew Adamatzky, University of the West of England, Bristol, UK
Guanrong Chen, City University of Hong Kong, Hong Kong, China
Editorial Board
Ajith Abraham, MirLabs, USA
Ana Lucia, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio
Grande do Sul, Brazil
Juan C. Burguillo, University of Vigo, Spain
Sergej ˇCelikovský, Academy of Sciences of the Czech Republic, Czech
Republic
Mohammed Chadli, University of Jules Verne, France
Emilio Corchado, University of Salamanca, Spain
Donald Davendra, Technical University of Ostrava, Czech Republic
Andrew Ilachinski, Center for Naval Analyses, USA
Jouni Lampinen, University of Vaasa, Finland
Martin Middendorf, University of Leipzig, Germany
Edward Ott, University of Maryland, USA
Linqiang Pan, Huazhong University of Science and Technology, Wuhan, China
Gheorghe P˘aun, Romanian Academy, Bucharest, Romania
Hendrik Richter, HTWK Leipzig University of Applied Sciences, Germany
Juan A. Rodriguez-Aguilar
, IIIA-CSIC, Spain
Otto Rössler, Institute of Physical and Theoretical Chemistry, Tübingen,
Germany
Yaroslav D. Sergeyev, University of Calabria, Italy
Vaclav Snasel, Technical University of Ostrava, Czech Republic
Ivo Vondrák, Technical University of Ostrava, Czech Republic
Hector Zenil, Karolinska Institute, Sweden

The Emergence, Complexity and Computation (ECC) series publishes new
developments, advancements and selected topics in the ﬁelds of complexity,
computation and emergence. The series focuses on all aspects of reality-based
computation approaches from an interdisciplinary point of view especially
from applied sciences, biology, physics, or chemistry. It presents new ideas
and interdisciplinary insight on the mutual intersection of subareas of compu-
tation, complexity and emergence and its impact and limits to any computing
based on physical limits (thermodynamic and quantum limits, Bremermann’s
limit, Seth Lloyd limits…) as well as algorithmic limits (Gödel’s proof
and its impact on calculation, algorithmic complexity, the Chaitin’s Omega
number and Kolmogorov complexity, non-traditional calculations like Turing
machine process and its consequences,…) and limitations arising in artiﬁcial
intelligence. The topics are (but not limited to) membrane computing, DNA
computing, immune computing, quantum computing, swarm computing,
analogic computing, chaos computing and computing on the edge of chaos,
computational aspects of dynamics of complex systems (systems with
self-organization, multiagent systems, cellular automata, artiﬁcial life,…),
emergence of complex systems and its computational aspects, and agent
based computation. The main aim of this series is to discuss the above
mentioned topics from an interdisciplinary point of view and present new
ideas coming from mutual intersection of classical as well as modern methods
of computation. Within the scope of the series are monographs, lecture notes,
selected contributions from specialized conferences and workshops, special
contribution from international experts.
Indexed by zbMATH.
More information about this series at https://link.springer.com/bookseries/
10624

Yaroslav D. Sergeyev · Renato De Leone
Editors
Numerical Inﬁnities
and Inﬁnitesimals
in Optimization

Editors
Yaroslav D. Sergeyev
Dipartimento di Ingegneria
Informatica, Modellistica, Elettronica e
Sistemistica
University of Calabria
Rende, Italy
Lobachevsky University
Nizhny Novgorod, Russia
Renato De Leone
Scuola di Scienze e Tecnologie
Università degli Studi di Camerino
Camerino, Italy
ISSN 2194-7287
ISSN 2194-7295 (electronic)
Emergence, Complexity and Computation
ISBN 978-3-030-93641-9
ISBN 978-3-030-93642-6 (eBook)
https://doi.org/10.1007/978-3-030-93642-6
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer
Nature Switzerland AG 2022
Thisworkissubjecttocopyright.AllrightsaresolelyandexclusivelylicensedbythePublisher,
whether the whole or part of the material is concerned, speciﬁcally the rights of translation,
reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any
other physical way, and transmission or information storage and retrieval, electronic adapta-
tion, computer software, or by similar or dissimilar methodology now known or hereafter
developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are
exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in
this book are believed to be true and accurate at the date of publication. Neither the publisher
nor the authors or the editors give a warranty, expressed or implied, with respect to the material
containedhereinorforanyerrorsoromissionsthatmayhavebeenmade.Thepublisherremains
neutral with regard to jurisdictional claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

The editors thank their families for their
love, support, and really inﬁnite patience
during the years of preparation of this
book on ➀inﬁnity.
To Adriana and Ekaterina
To Chiara, Dmitriy, and Robert

Preface
This book is dedicated to two topics that, up to the recent times, were believed
incompatible. In fact, inﬁnities and inﬁnitesimals for centuries were consid-
ered within highly theoretical research areas whereas optimization is a part
of applied mathematics and deals with algorithms and codes implemented
on computers. The possibility to join these two topics under the same cover
is a consequence of the fact that inﬁnities and inﬁnitesimals considered here
are not traditional symbolic entities but numerical ones, namely, they can
be represented on a new supercomputer patented in several countries and
called the Inﬁnity Computer. This computer is able to execute numerical
(i.e., ﬂoating-point) operations with numbers that can have different inﬁnite,
ﬁnite, and inﬁnitesimal parts represented in the positional numeral system
with an inﬁnite base called grossone expressed by the numeral ➀. The numer-
ical character of these inﬁnite and inﬁnitesimal numbers is one of the key
differences with respect to traditional theories of inﬁnity and inﬁnitesimals.
This novel point of view opens completely new horizons not only in pure
mathematics but also in computer science and applied mathematics.
During the last years there was an increasing interest in this new computa-
tionalparadigm.In2013,2016,and2019therewereinternationalconferences
“NUMTA—Numerical Computations: Theory and Algorithms” where the
Inﬁnity Computer and its applications were among the main topics. Several
special issues in leading scientiﬁc journals have been published. The last
NUMTA conference in 2019 had more than 200 participants from 30 coun-
tries. Three special issues and proceedings in volumes 11973 and 11974 of
the Springer book series “Lecture Notes in Computer Science” have been
published.
The interest of the international scientiﬁc community to this paradigm is
also due to the fact that, for the ﬁrst time, inﬁnities and inﬁnitesimals were
vii

viii
Preface
involved not only in scientiﬁc ﬁelds related to pure mathematics such as foun-
dations of mathematics, logic, and philosophy but also in computer science
and applied mathematics.Moreover,there exist several software simulators of
the Inﬁnity Computer that are actively used by researchers in their work with
numerical methods. Nowadays among the ﬁelds of application of the new
computational paradigm we ﬁnd: numerical differentiation and numerical
solution of ordinary differential equations, game theory, probability theory,
cellular automata, Euclidean and hyperbolic geometry, percolation, fractals,
inﬁnite series and the Riemann zeta function, the ﬁrst Hilbert problem, Turing
machines, teaching, etc. A huge bulk of results using the Inﬁnity Computer
paradigm in optimization (linear, non-linear, global, and multi-criteria) is
collected in this volume co-authored by 22 leading experts working in these
ﬁelds. Thus, the reader will have a unique opportunity to ﬁnd in the same
book the state-of-the-art knowledge and practices in optimization using the
Inﬁnity Computing methodology.
The ﬁrst two chapters of the book written by the editors have an intro-
ductory character and describe the Inﬁnity Computer methodology (Chapter
“A New Computational Paradigm Using Grossone-Based Numerical Inﬁni-
ties and Inﬁnitesimals”, written by Yaroslav D. Sergeyev) and some of
the most important results in unconstrained and constrained optimization
(Chapter “Nonlinear Optimization: A Brief Overview”, written by Renato
De Leone). Chapter “The Role of grossone in Nonlinear Programming
and Exact Penalty Methods”, also written by Renato De Leone, is dedicated to
exact penalty methods for solving constrained optimization problems. Using
penalty functions, the original constrained optimization problem can be trans-
formed in an unconstrained one. The chapter shows how ➀can be utilized
in constructing exact continuously differentiable penalty functions for the
case of only equality constraints, the general case of equality and inequality
constraints, and quadratics problems. It is also discussed how these new
penalty functions allow one to recover the exact solution of the unconstrained
problem from the optimal solution of the unconstrained problem. Moreover,
Lagrangian duals associated to the constraints can also be automatically
obtained thanks to the ➀-based penalty functions.
Chapter “Krylov-Subspace Methods for Quadratic Hypersurfaces:
a Grossone–based Perspective” is written by Giovanni Fasano who studies the
role of ➀to deal with two renowned Krylov-subspace methods for symmetric
(possibly indeﬁnite) linear systems. First, the author explores a relationship
between the Conjugate Gradient method and the Lanczos process, along
with their role of yielding tridiagonal matrices which retain large infor-
mation on the original linear system matrix. Then, he shows that coupling

Preface
ix
➀with the Conjugate Gradient method provides clear theoretical improve-
ments. Furthermore, reformulating the iteration of this algorithm using this
➀-based framework allows the author to encompass also a certain number
of Krylov-subspace methods relying on conjugacy among vectors. The last
generalization remarkably justiﬁes the use of a ➀-based reformulation of the
Conjugate Gradient method to solve also indeﬁnite linear systems. Finally,
pairing this method with the algebra of grossone easily provides relevant
geometric properties of quadratic hypersurfaces.
Marco Cococcioni, Alessandro Cudazzo, Massimo Pappalardo, and
Yaroslav D. Sergeyev show in Chapter “Multi-objective Lexicographic
Mixed-Integer Linear Programming: An Inﬁnity Computer Approach” how
a lexicographic multi-objective linear programming problem can be trans-
formed into an equivalent single-objective problem by using the grossone
methodology. Then, the authors provide a simplex-like algorithm, called
GrossSimplex, able to solve the original problem using a single run of the
algorithm. In the second part of the chapter, the authors tackle the mixed-
integer lexicographic multi-objective linear programming problem and solve
it in an exact way, by using a ➀-version of the Branch-and-Bound scheme.
After proving the theoretical correctness of the associated pruning rules and
terminating conditions, they present a few experimental results executed on
an Inﬁnity Computer simulator.
In Chapter “The Use of Inﬁnities and Inﬁnitesimals for Sparse Classi-
ﬁcation Problems”, Renato De Leone, Nadaniela Egidi, and Lorella Fatone
discuss the use of grossone in determining sparse solutions for special classes
of optimization problems. In fact, in various optimization and regression
problems, and in solving overdetermined systems of linear equations it is
often necessary to determine a sparse solution, that is a solution with as many
as possible zero components. The authors show how continuously differen-
tiable concave approximations of the pseudoâe“norm can be constructed
using ➀and discuss properties of some new approximations. Finally, the
authors present some applications in elastic net regularization and Sparse
Support Vector Machine.
Chapter “The Grossone-Based Diagonal Bundle Method” written by
Manlio Gaudioso, Giovanni Giallombardo, and Marat S. Mukhametzhanov
discussesafruitfulimpactoftheInﬁnityComputingparadigmonthepractical
solution of convex nonsmooth optimization problems. The authors consider
a class of methods based on a variable metric approach: the use of the Inﬁnity
Computing techniques allows them to numerically deal with quantities which
can take arbitrarily small or large values, as a consequence of nonsmoothness.
In particular, by choosing a diagonal matrix with positive entries as a metric,
the authors modify the well-known Diagonal Bundle algorithm by means

x
Preface
of matrix updates based on the Inﬁnity Computing paradigm and provide
computational results obtained on a set of benchmark test problems.
Chapter “On the Use of Grossone Methodology for Handling Priorities
in Multi-objective Evolutionary Optimization” written by Leonardo Lai,
Lorenzo Fiaschi, Marco Cococcioni, and Kalyanmoy Deb describes a new
class of problems, called mixed Pareto-lexicographic multi-objective opti-
mizationproblems,asuitablemodelforscenarioswheresomeobjectiveshave
priority over some others. Two relevant subclasses of this problem are consid-
ered:prioritychainsandprioritylevels.ItisshownthattheInﬁnityComputing
methodology allows one to handle priorities efﬁciently. It is remarkable that
this technique can be easily embedded in most of the existing evolutionary
algorithms, without altering their core logic. Three algorithms are described
and tested on benchmark problems, including some real-world problems.
The experiments show that the algorithms using the Inﬁnity Computing
methodology are able to produce more solutions and of higher quality.
Chapter “Exact Numerical Differentiation on the Inﬁnity Computer
and Applications in Global Optimization” written by Maria Chiara Nasso
and Yaroslav D. Sergeyev shows how exact numerical differentiation can
be executed on the Inﬁnity Computer and efﬁciently applied in Lipschitz
globaloptimizationforcomputingderivatives.Optimizationalgorithmsusing
smooth piece-wise quadratic support functions to approximate the global
minimum are also discussed and their convergence conditions are provided.
It is shown that all the methods can be implemented both in the tradi-
tional ﬂoating-point arithmetic and in the novel Inﬁnity Computing frame-
work. Numerical experiments conﬁrm that methods using analytic derivatives
and derivatives computed numerically on the Inﬁnity Computer exhibit the
identical behavior.
Chapter
“Comparing
Linear
and
Spherical
Separation
Using
Grossone-Based Numerical Inﬁnities in Classiﬁcation Problems” authored
by Annabella Astorino and Antonio Fuduli investigates the role played
by the linear and spherical separations in binary supervised learning and
in Multiple Instance Learning (MIL), in connection with the use of the
grossone-based numerical inﬁnities. While in classical binary supervised
learning the objective is to separate two sets of samples, a binary MIL
problem consists in separating two different type of sets (positive and nega-
tive), each of them constituted by a ﬁnite number of samples. The authors
focus on the possibility to construct binary spherical classiﬁers characterized
by an inﬁnitely far center adopting the Inﬁnity Computing methodology.
They show that this approach allows them to obtain a good performance in
terms of average testing correctness and to manage very easily numerical
computations without any tuning of the “big M” parameter.

Preface
xi
In Chapter “Computing Optimal Decision Strategies Using the Inﬁnity
Computer:TheCaseofNon-ArchimedeanZero-SumGames”,MarcoCococ-
cioni, Lorenzo Fiaschi, and Luca Lambertini investigate non-Archimedean
zero-sum games allowing payoffs to be inﬁnite, ﬁnite, and inﬁnitesimal. Since
any zero-sum game is associated to a linear programming problem, the search
for Nash equilibria of non-Archimedean games requires optimization of a
non-Archimedean linear programming problem whose peculiarity is to have
the constraints matrix populated by both inﬁnite and inﬁnitesimal numbers.
The authors implement and test a grossone-based version of the Simplex
algorithm called Gross-Matrix-Simplex method and stress the advantages
of numerical computations with respect to symbolic ones. Some possible
applications related to such games are also discussed in the chapter.
Chapter “Modeling Inﬁnite Games on Finite Graphs using Numerical
Inﬁnities” written by Louis D’Alotto studies inﬁnite games played on ﬁnite
graphs. A new model of inﬁnite games played on ﬁnite graphs using the
grossone paradigm is presented. It is shown that the new grossone-based
model provides certain advantages such as allowing for draws, which are
common in board games, and a more accurate and decisive method for
determining the winner. Numerous examples and illustrations are provided.
Chapter “Adopting the Inﬁnity Computing in Simulink for Scien-
tiﬁc Computing” authored by Alberto Falcone, Alfredo Garro, Marat S.
Mukhametzhanov, and Yaroslav D. Sergeyev describe a software simulator
of the Inﬁnity Computer written in the visual programming environment
Simulink. Since this environment is adopted in many industrial and research
domains for addressing important real-world issues (in particular, handling
problems in control theory and dynamics), the appearance of the Inﬁnity
Computer Simulink-based solution is very important.
Chapter “Addressing Ill-Conditioning in Global Optimization Using
a Software Implementation of the Inﬁnity Computer” addressing some
aspects of ill-conditioning in global optimization is written by Marat S.
Mukhametzhanov and Dmitri E. Kvasov. One of the desirable properties of
global optimization methods is strong homogeneity meaning that a method
produces the same sequences of points at which the objective function is
evaluated both for the original function and a scaled one. It is shown in the
chapter that even if a method possesses this property theoretically, numeri-
cally very small and large scaling constants can lead to ill-conditioning of the
scaled problem. In these cases the usage of numerical inﬁnities and inﬁnitesi-
mals can avoid ill-conditioning produced by scaling. Numerical experiments
illustrating theoretical results are reported.
In conclusion, it is obligatory to mention that all the chapters have been
peer-reviewed by two reviewers each and by the editors. It is our pleasant duty

xii
Preface
to thank the reviewers for their meticulous work. The editors of the present
volume thank the editors of the Springer series “Emergence, Complexity
and Computation” Andrew Adamatzky, Guanrong Chen, and Ivan Zelinka
as well as the Springer Editorial Director Thomas Ditzinger for their friendly
support. Special thanks go to Marco Cococcioni and Lorenzo Fiaschi who
not only co-authored several chapters but also greatly helped the editors with
the Latex compilation of the book.
The editors hope that this book presenting the power of the Inﬁnity
Computing methodology in optimization will become a source of further
interesting developments in this ﬁeld and not only.
Rende, Italy
Camerino, Italy
Yaroslav D. Sergeyev
Renato De Leone

Contents
Theoretical Background
A New Computational Paradigm Using Grossone-Based
Numerical Inﬁnities and Inﬁnitesimals . . . . . . . . . . . . . . . . . . . . . . . .
3
Yaroslav D. Sergeyev
Nonlinear Optimization: A Brief Overview . . . . . . . . . . . . . . . . . . . .
37
Renato De Leone
New Computational Tools in Optimization
The Role of grossone in Nonlinear Programming and Exact
Penalty Methods
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
Renato De Leone
Krylov-Subspace Methods for Quadratic Hypersurfaces:
A Grossone–based Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
Giovanni Fasano
Multi-objective Lexicographic Mixed-Integer Linear
Programming: An Inﬁnity Computer Approach . . . . . . . . . . . . . . .
119
Marco Cococcioni, Alessandro Cudazzo, Massimo Pappalardo,
and Yaroslav D. Sergeyev
The Use of Inﬁnities and Inﬁnitesimals for Sparse
Classiﬁcation Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
Renato De Leone, Nadaniela Egidi, and Lorella Fatone
The Grossone-Based Diagonal Bundle Method . . . . . . . . . . . . . . . .
167
Manlio Gaudioso, Giovanni Giallombardo,
and Marat S. Mukhametzhanov
xiii

xiv
Contents
On the Use of Grossone Methodology for Handling
Priorities in Multi-objective Evolutionary Optimization . . . . . . . .
183
Leonardo Lai, Lorenzo Fiaschi, Marco Cococcioni,
and Kalyanmoy Deb
Applications and Implementations
Exact Numerical Differentiation on the Inﬁnity Computer
and Applications in Global Optimization . . . . . . . . . . . . . . . . . . . . .
221
Maria Chiara Nasso and Yaroslav D. Sergeyev
Comparing Linear and Spherical Separation Using
Grossone-Based Numerical Inﬁnities in Classiﬁcation
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
Annabella Astorino and Antonio Fuduli
Computing Optimal Decision Strategies Using the Inﬁnity
Computer: The Case of Non-Archimedean Zero-Sum Games . . .
271
Marco Cococcioni, Lorenzo Fiaschi, and Luca Lambertini
Modeling Inﬁnite Games on Finite Graphs Using Numerical
Inﬁnities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
297
Louis D’Alotto
Adopting the Inﬁnity Computing in Simulink for Scientiﬁc
Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
313
Alberto Falcone, Alfredo Garro, Marat S. Mukhametzhanov,
and Yaroslav D. Sergeyev
Addressing Ill-Conditioning in Global Optimization Using
a Software Implementation of the Inﬁnity Computer . . . . . . . . . . .
347
Marat S. Mukhametzhanov and Dmitri E. Kvasov

Contributors
Annabella Astorino Institute for High Performance Computing and
Networking (ICAR), National Research Council, Rende, Italy
Marco Cococcioni Department of Information Engineering, University of
Pisa, Pisa, Italy
Alessandro Cudazzo Dipartimento di Informatica, (University of Pisa),
Pisa, Italy
Louis D’Alotto York College, The City University of New York, Jamaica,
Queens, NY, USA;
The Graduate Center, The City University of New York, New York, NY,
USA
Renato De Leone School of Science and Technology, University of
Camerino, Camerino (MC), Italy
Kalyanmoy Deb Department of Electrical and Computer Engineering,
Michigan State University, East Lansing, MI, USA
Nadaniela Egidi School of Science and Technology, University of
Camerino, Camerino, MC, Italy
Alberto Falcone Department of Informatics, Modeling, Electronics and
Systems Engineering (DIMES), University of Calabria, Rende, Italy
Giovanni Fasano Department of Management, University Ca’ Foscari of
Venice, Venice, Italy
Lorella Fatone School of Science and Technology, University of Camerino,
Camerino, MC, Italy
xv

xvi
Contributors
Lorenzo Fiaschi Department of Information Engineering, University of
Pisa, Pisa, Italy
Antonio Fuduli Department of Mathematics and Computer Science,
University of Calabria, Rende, Italy
Alfredo Garro Department of Informatics, Modeling, Electronics and
Systems Engineering (DIMES), University of Calabria, Rende, Italy
Manlio Gaudioso Università della Calabria, Rende, Italy
Giovanni Giallombardo Università della Calabria, Rende, Italy
Dmitri E. Kvasov University of Calabria, Rende, Italy;
Lobachevsky University of Nizhny Novgorod, Nizhny Novgorod, Russia
Leonardo Lai Department of Information Engineering, University of Pisa,
Pisa, Italy
Luca Lambertini Department of Economics, University of Bologna,
Bologna, Italy
Marat S. Mukhametzhanov Università della Calabria, Rende, Italy
Maria Chiara Nasso University of Calabria, Rende, Italy
Massimo Pappalardo Dipartimento di Informatica, (University of Pisa),
Pisa, Italy
Yaroslav D. Sergeyev University of Calabria, Rende, Italy;
Lobachevsky University of Nizhny Novgorod, Nizhny Novgorod, Russia

Theoretical Background

A New Computational Paradigm Using
Grossone-Based Numerical Inﬁnities
and Inﬁnitesimals
Yaroslav D. Sergeyev
Abstract This Chapter surveys a recent computational methodology allow-
ing one to work with inﬁnities and inﬁnitesimals numerically on a supercom-
puter called the Inﬁnity Computer that has been patented in several countries.
This methodology applies the principle The whole is greater than the part to
all numbers (ﬁnite, inﬁnite, and inﬁnitesimal) and to all sets and processes
(ﬁnite and inﬁnite). It is shown that, from the theoretical point of view, the
methodology allows one to consider inﬁnite and inﬁnitesimal quantities more
accurately w.r.t. traditional approaches such as Cantor’s cardinals and non-
standard analysis of Robinson. On the other hand, the methodology has a
pronounced numerical character that gives an opportunity to construct algo-
rithms of a completely new type and run them on the Inﬁnity Computer
(there already exist numerous applications not only in optimization but also
in numerical differentiation, ODEs, game theory, etc.). In this Chapter, some
key aspects of the methodology are described and several examples are given.
Due to the breadth of the subject, the main attention is limited to method-
ological and practical aspects required to grasp applications in optimization
contained in the other Chapters of the book. The material is presented in an
accessible form that does not require any additional knowledge exceeding
the ﬁrst year university course of mathematical analysis.
Y. D. Sergeyev (B)
University of Calabria, Rende (CS), Italy
e-mail: yaro@dimes.unical.it
Lobachevsky State University, Nizhny Novgorod, Russia
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_1
3

4
Y. D. Sergeyev
1
Introduction
The point of view on inﬁnitesimals and inﬁnities accepted nowadays (see,
e.g., [5, 14, 17, 34, 43, 52]) takes its origins from the fundamental ideas of
Leibniz, Newton, and Cantor (see [10, 48, 56]). More recently, in the late
ﬁfties of the 20th century, Robinson (see [63]) has introduced his symbolic
non-standard analysis approach showing that non-archimedean ordered ﬁeld
extensions of the reals contained numbers that could serve as inﬁnitesimals
and their reciprocals as inﬁnities. However, since he used in his approach Can-
tor’s mathematical tools and terminology (cardinal numbers, countable sets,
continuum, one-to-one correspondence, etc.), his methodology has incorpo-
rated advantages and disadvantages of Cantor’s ideas. Among their disadvan-
tages we ﬁnd numerous paradoxes that go against our every day experience.
Is it true that they are inevitable? Is it possible to propose an alternative view-
point that would allow us to avoid some of them and to work with the inﬁnite
in a more precise and, especially, numerical way?
In this Chapter, we describe a recent methodology (see a comprehensive
survey in [75] and a popular presentation in [67]) that, on the one hand, allows
us to avoid numerous classical paradoxes related to inﬁnity and inﬁnitesimals
and, on the other hand, gives the possibility to solve numerically1 problems
involving quantities of this kind (see patents [70]). In effect, this book collects
results where this methodology has been applied in optimization. Before we
start a technical consideration let us mention that numerous papers study-
ing consistency of the new methodology and its connections to the historical
panorama of ideas dealing with inﬁnities and inﬁnitesimals have been pub-
lished (see [29, 50, 51, 53, 55, 71, 76, 81]). In particular, in [76] it is stressed
that it is not related to non-standard analysis. However, the methodology that
will be discussed here is not a contraposition to the traditional views. In con-
trast, it can be viewed as an applied evolution of the intuition of Cantor and
Robinson regarding the existence of different inﬁnities and inﬁnitesimals.
Traditional approaches and the methodology described here do not contra-
dict one another, they can be considered just as different tools having different
accuracies and used for observations of certain mathematical objects dealing
with inﬁnities and inﬁnitesimals.
1 Recall that numerical computations operate with ﬂoating point numbers on a computer
where results of arithmetical operations are approximated in order to store them in the
computer memory. In their turn, symbolic computations are the exact manipulations with
mathematical expressions containing variables that have not any given value and are thus
manipulated as symbols. For instance, non-standard analysis is symbolic (see [63]), it is
not possible to assign any value to non-standard inﬁnities and inﬁnitesimals.

A New Computational Paradigm Using Grossone-Based …
5
The new methodology has been successfully applied in several areas of
pure and applied mathematics and computer science (more than 60 papers
published in international scientiﬁc journals can be found at the dedicated
web page [37]). We provide here just a few examples of areas where this
methodology is useful. First of all, we mention applications in local, global,
and multiple criteria optimization covered in this book (see [4, 11–13, 20–24,
30, 46, 79, 85]). Then, we can indicate game theory and probability (see, e.g.,
[9, 19, 27, 28, 58, 61, 62]), hyperbolic geometry and percolation (see [41,
42, 54]), fractals (see [3, 7, 8, 68, 69, 72, 74]), inﬁnite series (see [65, 66,
75, 84]), Turing machines, cellular automata, ordering, and supertasks (see
[18, 60, 62, 73, 77, 78]), numerical differentiation and numerical solution
of ordinary differential equations (see [1, 25, 26, 39, 80]), etc. In addition,
successful applications of this methodology in teaching mathematics should
be mentioned (see [2, 38, 40]). The dedicated web page [36], developed at
the University of East Anglia, UK, contains, among other things, a compre-
hensive teaching manual and a nice animation related to the Hilbert’s paradox
of the Grand Hotel.
This Chapter is structured as follows. First, in Sect.2 some traditional
numeral systems used to express ﬁnite and inﬁnite quantities are studied
and compared. Then, in Sect.3 the main principles of the new computa-
tional methodology are described whereas Sect.4 discusses a new way of
counting implementing these principles. After that, in Sect.5 it is shown
how different ﬁnite, inﬁnite, and inﬁnitesimal numbers can be represented
in a unique framework allowing one to execute numerical operations on the
Inﬁnity Computer. Section 6 considers some classical paradoxes of inﬁnity in
the traditional and the new frameworks. Section 7 concludes the Chapter that
contains numerous examples and a continuous comparison with traditional
views on inﬁnity is performed.
2
Numeral Systems Used to Express Finite and Inﬁnite
Quantities
A numeral is a group of symbols (which can also be one symbol only) that
represents a number that is a concept. For example, symbols ‘5’, ‘ﬁve’, ‘IIIII’,
and ‘V’, are different numerals, but they all represent the same number. A
numeral system is deﬁned as a set of certain basic numerals, rules used to
write down more complex numerals using the basic ones, and algorithms that
are executed to perform arithmetical operations with these numerals. Thus,
numbers can be considered as objects of an observation that are represented

6
Y. D. Sergeyev
(observed) by instruments of the observation, i.e., by numerals and, more
general, by numeral systems.
In our everyday activities with ﬁnite numbers the same ﬁnite numerals are
used for all purposes where we need to express the quantity we are interested
in. In contrast, when we need to work with inﬁnities and/or inﬁnitesimals,
different numerals are used in different situations. For instance, we use the
symbol ∞in mathematical analysis, symbol ω for working with Cantor’s
ordinals, symbols ℵ0, ℵ1, ... for dealing with Cantor’s inﬁnite cardinals, etc.
Moreover, different arithmetics with different rules should be used to operate
with inﬁnities in different situations. Let us give some examples:
– There exist undetermined operations (∞−∞, ∞
∞, etc.) that are absent
when we work with ﬁnite numbers.
– Arithmetic with ∞does not satisfy Euclid’s Common Notion no. 5 saying
‘The whole is greater than the part’ that holds when we work with ﬁnite
quantities. In fact, it follows that, e.g., ∞−1 = ∞whereas clearly for
any ﬁnite x it follows x −1 < x.
– Addition and multiplication with Cantor’s ordinals are not commutative
(e.g., 1 + ω = ω and ω + 1 > ω), moreover, there does not exist an ordinal
γ such that γ + 1 = ω, etc.
It is well known that traditional computers work numerically only with
ﬁnite numbers and situations where the usage of inﬁnite or inﬁnitesimal
quantities is required are studied mainly theoretically (see [10, 16, 31, 33,
35, 48, 49, 63, 82] and references given therein). The fact that numerical
computations with inﬁnities and inﬁnitesimals have not been implemented
so far on computers can be explained by difﬁculties mentioned above. There
exist also practical troubles that preclude an implementation of numerical
computations with inﬁnities and inﬁnitesimals. For example, it is not clear
how to store an inﬁnite quantity in a ﬁnite computer memory.
In order to understand how one can change his/her view on inﬁnity, let us
consider in a historical perspective some numeral systems used to express
ﬁnite numbers. Through the centuries, numeral systems (see, e.g., [16, 17])
became more and more sophisticated allowing people to express more and
more numbers. Since new numeral systems appear very rarely, in each con-
crete historical period people tend to think that any number can be expressed
by the current numeral system and the importance of numeral systems for
mathematics is very often underestimated (especially by pure mathematicians
who often write phrases of the kind ‘Let us take any x from the interval [0, 1]’
and do not specify how this operation of taking can be executed). However,
if we think about, we can immediately see limitations that various numeral
systems induce. It will become clear that due to practical reasons different

A New Computational Paradigm Using Grossone-Based …
7
numeral systems can express different limited sets of numbers and they can
be more or less suitable for executing arithmetical operations.
In fact, people in different historical periods used different numeral sys-
tems to count and these systems: (a) can be more or less suitable for counting;
(b) can express different sets of numbers. For instance, Roman numeral sys-
tem is not able to express zero and negative numbers and such expressions as
II – VII or X – X are indeterminate forms in this numeral system. As a result,
before the appearance of positional numeral systems and the invention of zero
mathematicians were not able to create theorems involving zero and nega-
tive numbers and to execute computations with them. The positional numeral
system not only has allowed people to execute new operations but has led
to new theoretical results, as well. Thus, numeral systems not only limit us
in practical computations, they induce boundaries on theoretical results, as
well.
It should be stressed that the powerful positional numeral system also has
its limitations. For example, nobody is able to write down a numeral in the
decimal positional system having 10100 digits (see a discussion on feasible
numbers in [57, 64]). In fact, suppose that one is able to write down one
digit in one nanosecond. Then, it will take 1091 s to record all 10100 digits.
Since in one year there are 31.556.926 ≈3.2 · 107 s, 1091 s are approximately
3.2 · 1083 years. This is a sufﬁciently long time since it is supposed that the
age of the universe is approximately 1.382 · 1010 years.
As we have seen above, Roman numeral system is weaker than the posi-
tional one. However, it is not the weakest numeral system. There exist very
poor numeral systems allowing their users to express very few numbers and
one of them is illuminating for our story. This numeral system is used by a
tribe, Pirahã, living in Amazonia nowadays. A study published in Science in
2004 (see [32]) describes that these people use an extremely simple numeral
system for counting: one, two, many. For Pirahã, all quantities larger than
two are just ‘many’ and such operations as 2+2 and 2+1 give the same result,
i.e., ‘many’. Using their weak numeral system Pirahã are not able to see,
for instance, numbers 3, 4, and 5, to execute arithmetical operations with
them, and, in general, to say anything about these numbers because in their
language there are neither words nor concepts for that.
It is worthy of mention that the result ‘many’ is not wrong. It is just
inaccurate. Analogously, when we observe a garden with 547 trees, then
both phrases: ‘There are 547 trees in the garden’ and ‘There are many trees in
the garden’ are correct. However, the accuracy of the former phrase is higher
than the accuracy of the latter one. Thus, the introduction of a numeral system
having numerals for expressing numbers 3 and 4 leads to a higher accuracy

8
Y. D. Sergeyev
of computations and allows one to distinguish results of operations 2+1 and
2+2.
The poverty of the numeral system of Pirahã leads also to the following
results
‘many’ + 1 = ‘many’, ‘many’ + 2 = ‘many’, ‘many’ + ‘many’ = ‘many’
(1)
that are crucial for changing our outlook on inﬁnity. In fact, by changing in
these relations ‘many’ with ∞we get relations used to work with inﬁnity in
the traditional calculus
∞+ 1 = ∞,
∞+ 2 = ∞,
∞+ ∞= ∞.
(2)
Analogously, if we consider Cantor’s cardinals (where, as usual, numeral
ℵ0 is used for cardinality of countable sets and numeral c for cardinality of
the continuum, see, e.g., [83] for their deﬁnitions and related discussions) we
have similar relations
ℵ0 + 1 = ℵ0,
ℵ0 + 2 = ℵ0,
ℵ0 + ℵ0 = ℵ0,
(3)
c + 1 = c,
c + 2 = c,
c + c = c.
(4)
It should be mentioned that the astonishing numeral system of Pirahã is
not an isolated example of this way of counting. In [15], more than 20 lan-
guages having numerals only for small numbers are mentioned. For example,
the same counting system, one, two, many, is used by the Warlpiri people,
aborigines living in the Northern Territory of Australia (see [6]). The Pit-
jantjatjara people living in the Central Australian desert use numerals one,
two, three, big mob (see [47]) where ‘big mob’ works as ‘many’. It makes
sense to remind also another Amazonian tribe—Mundurukú (see [59]) who
fail in exact arithmetic with numbers larger than 5 but are able to compare
and add large approximate numbers that are far beyond their naming range.
Particularly, they use the words ‘some, not many’ and ‘many, really many’
to distinguish two types of large numbers. Their arithmetic with ‘some, not
many’ and ‘many, really many’ reminds the rules Cantor uses to work with
ℵ0 and c, respectively. In fact, it is sufﬁcient to compare
‘some, not many’+ ‘many, really many’ = ‘many, really many’
(5)
with
ℵ0 + c = c
(6)
to see this similarity.

A New Computational Paradigm Using Grossone-Based …
9
Let us compare now the weak numeral systems involved in (1), (5) and
numeral systems used to work with inﬁnity. We have already seen that rela-
tions (1) are results of the weakness of the numeral system employed. More-
over, the usage of a stronger numeral system shows that it is possible to pass
from records 1+2 = ‘many’ and 2+2 = ‘many’ providing for two different
expressions the same result, i.e., ‘many’, to more precise answers 1+2 = 3
and 2+2 = 4 and to see that 3 ̸= 4. In these examples we have the same
objects—small ﬁnite numbers—but results of computations we execute are
different in dependence of the instrument—numeral system—used to repre-
sent numbers. Substitution of the numeral ‘many’ by a variety of numerals
representing numbers 3, 4, etc. allows us both to avoid relations of the type
(1), (5) and to increase the accuracy of computations.
Relations (2)–(4), (6) manifest a complete analogy with (1), (5). Canoni-
cally, symbols ∞, ℵ0, and c are identiﬁed with concrete mathematical objects
and (2)–(4), (6) are considered as intrinsic properties of these inﬁnite objects
(see e.g., [63, 83]). However, the analogy with (1), (5) suggests that relations
(2)–(4), (6) do not reﬂect the nature of inﬁnite objects. They are just a result
of weak numeral systems used to express inﬁnite quantities. As (1), (5) show
the lack of numerals in numeral systems of Pirahã, Warlpiri, Pitjantjatjara,
and Mundurukú for expressing different ﬁnite quantities, relations (2)–(4),
(6) show shortage of numerals in mathematical analysis and in set theory for
expressing different inﬁnite numbers. Another hint leading to the same con-
clusion is the situation with indeterminate forms of the kind III-V in Roman
numerals that have been excluded from the practice of computations after
introducing positional numeral systems.
Thus, the analysis made above allows us to formulate the following key
observation that changes our perception of inﬁnity:
Our difﬁculty in working with inﬁnity is not a consequence of the nature of
inﬁnity but is a result of weak numeral systems having too little numerals to
express the multitude of inﬁnite numbers.
The way of reasoning where the object of the study is separated from
the tool used by the investigator is very common in natural sciences where
researchers use tools to describe the object of their study and the used instru-
ments inﬂuence the results of the observations and determine their accuracy.
The same happens in mathematics studying natural phenomena, numbers,
objects that can be constructed by using numbers, sets, etc. Numeral systems
used to express numbers are among the instruments of observation used by
mathematicians. As we have illustrated above, the usage of powerful numeral
systems gives the possibility to obtain more precise results in mathematics in
thesamewayastheusageofagoodmicroscopegivesthepossibilityofobtain-
ing more precise results in Physics. Traditional numeral systems have been

10
Y. D. Sergeyev
developed to express ﬁnite quantities and they simply have no sufﬁciently
high number of numerals to express different inﬁnities (and inﬁnitesimals).
3
Three Methodological Postulates
In this section, we describe the methodology that will be adopted hereinafter.
Incontrasttothemodernmathematicalfashionthattriestomakeallaxiomatic
systems more and more precise (decreasing so degrees of freedom of the stud-
ied part of mathematics), we would like to be more ﬂexible and just to deﬁne a
set of general rules describing how practical computations should be executed
leaving as much space as possible for further changes and developments dic-
tated by practice of the introduced mathematical language. Notice also that
historically human beings started to count without any help of axiomatic sys-
tems (and nowadays children learn to count by practice, without studying,
e.g., Peano axioms for natural numbers). The spirit of this Chapter is the
same, namely, it shows how to count and gives examples where this way of
counting is useful and more precise with respect to traditional ways of count-
ing dealing with inﬁnity. We start by introducing three Postulates that will ﬁx
our methodological positions with respect to inﬁnite and inﬁnitesimal quan-
tities and mathematics, in general. Then, in the subsequent section, there will
be described practical rules required to execute computations implementing
the ideas expressed in the Postulates.
After this preamble, let us start with the ﬁrst Postulate. Usually, when
mathematicians deal with inﬁnite objects (sets or processes) it is supposed
thathumanbeingsareabletoexecutecertainoperationsinﬁnitelymanytimes.
For example, in a ﬁxed numeral system it is possible to write down a numeral
withany numberofdigits.However,thissuppositionisanabstractionbecause
we live in a ﬁnite world and all human beings and/or computers are doomed
to ﬁnish operations they have started. In the methodology to be introduced,
this abstraction is not used and the following Postulate is adopted.
Methodological Postulate 1. We postulate existence of inﬁnite and
inﬁnitesimal objects but accept that human beings and machines are able
to execute only a ﬁnite number of operations.
Thus,weacceptthatweshallneverbeabletogiveacomplete(inanysense)
description of inﬁnite objects due to our ﬁnite capabilities. In particular, this
means that we accept that we are able to write down only a ﬁnite number of
symbols to express numbers. This Postulate has a practical meaning because
we need to write down numbers and to see results of operations we execute.

A New Computational Paradigm Using Grossone-Based …
11
The second Postulate is adopted following the way of reasoning used in
natural sciences where researchers use tools to describe the object of their
study and the used instruments inﬂuence the results of the observations. When
a physicist uses a weak lens A and sees two black dots in his/her microscope
he/she does not say: “The object of the observation is two black dots”. The
physicist is obliged to say: “The lens used in the microscope allows us to
see two black dots and it is not possible to say anything more about the
nature of the object of the observation until we replace the instrument—the
lens or the microscope itself—with a more precise one”. Suppose that he/she
changes the lens and uses a stronger lens B and is able to observe that the
object of the observation is viewed as ten (smaller) black dots. Thus, we have
two different answers: (i) the object is viewed as two dots if the lens A is
used; (ii) the object is viewed as ten dots by applying the lens B. Which of
the answers is correct? Both. Both answers are correct but with the different
accuracies that depend on the lens used for the observation. The answers are
not in opposition one to another, they both describe the reality (or whatever is
behind the microscope) correctly with the precision of the used lens. In both
cases our physicist discusses what he/she observes and does not pretend to
say what the object is.
The same happens in mathematics studying natural phenomena, numbers,
and objects that can be constructed by using numbers. Numeral systems
used to express numbers are among the instruments of observations used by
mathematicians. The usage of powerful numeral systems gives the possibility
to obtain more precise results in mathematics in the same way as usage of
a good microscope gives the possibility of obtaining more precise results in
physics. However, even for the best existing tool the capabilities of this tool
will be always limited due to Postulate 1 (we are able to write down only a
ﬁnite number of symbols when we wish to describe a mathematical object)
and due to the following Postulate 2 we shall never tell, what is, for example, a
number but we shall just observe it through numerals expressible in a chosen
numeral system.
Methodological Postulate 2. We shall not tell what are the mathematical
objects we deal with; we just shall construct more powerful tools that will
allow us to improve our capacities to observe and to describe properties of
mathematical objects.
This Postulate is important for our study because it emphasizes that the
triad—object of a study, instrument of the study, and a researcher executing
the study—introduced in physics in the 20th century exists in mathematics, as
well. With this Postulate we stress that mathematical results are not absolute,
they depend on mathematical languages used to formulate them, i.e., there
always exists an accuracy of the description of a mathematical result, fact,

12
Y. D. Sergeyev
object, etc. imposed by the mathematical language used to formulate this
result. For instance, the result of Pirahã 2 + 2 = ‘many’ is not wrong, it is
just inaccurate. The introduction of a stronger tool (in this case, a numeral
system that contains a numeral for a representation of the number four) allows
us to have a more precise answer. Postulates 1 and 2 impose us to think
always about the possibility to execute a mathematical operation by applying
a numeral system. They tell us that there always exist situations where we are
not able to express the result of an operation (people working with numerical
codes on computers understand this fact very well).
Numerals that we use to write down numbers, functions, etc. are among our
tools of investigation and, as a result, they strongly inﬂuence our capabilities
to study mathematical objects. This separation (having an evident physical
spirit) of mathematical objects from the tools used for their description is
crucial for our study but it is used rarely in contemporary mathematics. In
fact, the idea of ﬁnding an adequate (absolutely the best) set of axioms for
one or another ﬁeld of mathematics continues to be among the most attractive
goals for many contemporary mathematicians whereas physicists perfectly
understand the impossibility of any attempt to give a ﬁnal description of
physical objects due to limitations of the instruments of study.
Instruments (numeral systems in this case) not only bound our practical
capabilities to compute, they can inﬂuence theoretical results in mathematics,
as well. We illustrate this statement by considering the following simple
phrase ‘Let us consider all x ∈[1, 2]’. For Pirahã, Warlpiri, Pitjantjatjara,
and Mundurukú all numbers are just 1 and 2. For people who do not know
irrational numbers (or do not accept their existence) all numbers are fractions
p
q where p and q can be expressed in a numeral system they know. If both p
and q can assume values 1 and 2 (as it happens for Pirahã), all numbers in this
case are: 1, 1 + 1
2, and 2. For persons knowing positional numeral systems
all numbers are those numbers that can be written in a positional system.
Thus, in different historical periods (or in different cultures) the phrase ‘Let
us consider all x ∈[1, 2]’ has different meanings. As a result, without ﬁxing
the numeral system we use to express numbers we cannot ﬁx the numbers
we deal with and an ambiguity arises.
Let us now introduce the last Postulate. We have already seen in the previ-
ous section that situations of the kind (2)–(4), (6) are results of the weakness
of numeral systems used to express inﬁnite quantities. Thus, we should treat
inﬁnite and inﬁnitesimal numbers in the same manner as we are used to deal
with ﬁnite ones, i.e., by applying the Euclid’s Common Notion no. 5 ‘The
whole is greater than the part’. In our considerations, its straight reformula-
tion ‘The part is less than the whole’ will be used for practical reasons that
will become clear soon. This principle, in our opinion, very well reﬂects orga-

A New Computational Paradigm Using Grossone-Based …
13
nization of the world around us but is not incorporated in many traditional
theories of the inﬁnite where it is true only for ﬁnite numbers. As the analysis
made in the previous section suggests, the reason of this discrepancy is in the
low accuracy of traditional numeral systems used to work with inﬁnity.
Methodological Postulate 3. We adopt the principle ‘The part is less than
the whole’ to all numbers (ﬁnite, inﬁnite, and inﬁnitesimal) and to all sets
and processes (ﬁnite and inﬁnite).
As was already discussed in connection with the numerals of Pirahã,
Warlpiri, Pitjantjatjara, and Mundurukú, the traditional point of view on inﬁn-
ity accepting such results as ∞−1 = ∞should be substituted in such way
that subtraction of 1 from an inﬁnite quantity Q can be registered, i.e., it
should be Q −1 < Q, as it happens with ﬁnite quantities. The Postulate 3
ﬁxes this desire.
It can seem at ﬁrst glance that Postulate 3 contradicts Cantor’s one-to-
one correspondence principle for inﬁnite sets. However, as it will be shown
later, this is not the case. Instead, the situation is similar to the example from
physics described above where we have considered two lenses having differ-
ent accuracies. Analogously, we have two different lenses having different
accuracies used to observe the same inﬁnite objects: Cantor’s approach and
the new one based on Postulates 1–3.
The adopted Postulates impose also the style of exposition of results in
this Chapter: we ﬁrst introduce new mathematical instruments, then show
how to use them in several areas of mathematics giving some examples and
introducing each item as soon as it becomes indispensable for the problem
under consideration. In order to proceed, we need to consider an example
arising in practice where there is the necessity to count extremely large ﬁnite
quantities. This example will help us to develop a new mathematical intu-
ition required to compute with ﬁnite, inﬁnite, and inﬁnitesimal quantities in
accordance with Postulates 1–3.
Imagine that the owner of a granary asks us to count how much grain he
has inside it. Obviously, it is possible to answer that there are many seeds in
the granary. This answer is correct but its accuracy is low. In order to obtain a
more precise answer it would be necessary to count the grain seed by seed but
since the granary is huge, it is not possible to do this due to practical reasons.
To overcome this difﬁculty and to obtain a more precise answer, people take
sacks, ﬁll them with seeds, and count the number of sacks. In this situation,
it is supposed that: (i) all the seeds have the same measure and all the sacks
also; (ii) the number of seeds in each sack is the same and is equal to K1 but
the sack is so big that we are not able to count how many seeds it contains
and to establish the value of K1; (iii) in any case the resulting number K1
would not be expressible by available numerals.

14
Y. D. Sergeyev
Then, if the granary is huge and it becomes difﬁcult to count the sacks, then
trucks or even big train wagons are used. As it was for the sacks, we suppose
that all trucks contain the same number K2 of sacks, and all train wagons
contain the same number K3 of trucks, however, the numbers Ki, i = 1, 2, 3,
are so huge that it becomes impossible to determine them. At the end of the
counting of this type we obtain a result in the following form: the granary
contains 27 wagons, 32 trucks, 56 sacks, and 134 seeds of grain. Note, that
if we add, for example, one seed to the granary, we not only can see that the
granary has more grain but also quantify the increment: from 134 seeds we
pass to 135 seeds. If we take out two wagons, we again are able to say how
much grain has been subtracted: from 27 wagons we pass to 25 wagons.
In the example it is necessary to count a large quantity that is ﬁnite but so
huge that it becomes impossible to count it directly by using the elementary
unit of measure, let us say u0—seeds. Therefore, people are forced to behave
as if the quantity was inﬁnite. To solve the problem of ‘inﬁnite’ quantity, new
units of measure, u1—sacks, u2—trucks, and u3—wagons, are introduced.
The new units have an important feature: all the units ui+1 contain a certain
number Ki of units ui but these numbers, Ki, i = 1, 2, 3, are unknown. Thus,
the quantity that it was impossible to express using only the initial unit of
measure, u0, are perfectly expressible in the new units ui, i = 1, 2, 3, that
we have introduced in addition to u0. Notice that, in spite of the fact that the
numbers Ki, i = 1, 2, 3, are unknown, the accuracy of the obtained answer
is equal to one seed.
This key idea of counting by introduction of new units of measure with
unknown but ﬁxed values Ki, i ≥1, will be used in what follows to deal with
inﬁnite quantities together with the relaxation allowing one to use negative
digits in positional numeral systems.
4
A New Way of Counting and the Inﬁnite Unit
of Measure ①
The way of counting described in the previous section suggests us how to
proceed: it is necessary to extend the idea of the introduction of new units
of measure from sets and numbers that are huge but ﬁnite to inﬁnite sets and
numbers. This can be done by extrapolating from ﬁnite to inﬁnite the idea
that n is the number of elements of the set {1, 2, 3, . . . , n −1, n}.

A New Computational Paradigm Using Grossone-Based …
15
Thus, the inﬁnite unit of measure is introduced as the number of elements
of the set, N, of natural numbers2 and expressed by the numeral ①called
grossone.Usingthegranaryexamplediscussedabovewecanofferthefollow-
ing interpretation: the set N can be considered as a sack and ①is the number
of seeds in the sack. Following our extrapolation, the introduction of ①allows
us to write down the set of natural numbers as N = {1, 2, 3, . . . , ①−1, ①}.
Recall that the usage of a numeral indicating the totality of the elements we
deal with is not new in Mathematics. It is sufﬁcient to mention the theory of
probability (see axioms of Kolmogorov in [45]) where events can be deﬁned
in two ways. First, as unions of elementary events; second, as a sample space,
, of all possible elementary events (or its parts) from which some elemen-
tary events have been excluded (or added in case of parts of ). Naturally,
the latter way to deﬁne events becomes particularly useful when the sample
space consists of inﬁnitely many elementary events.
Grossone is introduced by describing its properties postulated by the Inﬁ-
nite Unit Axiom (IUA) consisting of three parts: Inﬁnity, Identity, and Divis-
ibility. Similarly, in order to pass from natural to integer numbers a new
element—zero—is introduced, a numeral to express it is chosen, and its
properties are described. The IUA is added to axioms for real numbers (that
are considered in sense of Postulate 2). Thus, it is postulated that associa-
tive and commutative properties of multiplication and addition, distributive
property of multiplication over addition, existence of inverse elements with
respect to addition and multiplication hold for grossone as they do for ﬁnite
numbers.
Let us introduce the axiom and then give some comments upon it. Notice
that in the IUA inﬁnite sets will be described in the traditional form, i.e., with-
out indicating the last element. For instance, the set of natural numbers will
be written as N = {1, 2, 3, . . .} instead of N = {1, 2, 3, . . . , ①−1, ①}. We
emphasize that in both cases we deal with the same mathematical object—the
set of natural numbers—that is observed through two different instruments.
In the ﬁrst case traditional numeral systems do not allow us to express inﬁnite
numbers whereas the numeral system with grossone offers this possibility.
Similarly, Pirahã are not able to see ﬁnite natural numbers greater than 2
but these numbers (e.g., 3 and 4) belong to N and are visible if one uses a
more powerful numeral system. A detailed discussion will follow shortly to
show how to use grossone to calculate and express the number of elements
of certain inﬁnite sets.
2 Notice that nowadays not only positive integers but also zero is frequently included in
N. However, since historically zero has been invented signiﬁcantly later with respect to
positive integers used for counting objects, zero is not include in N in this Chapter.

16
Y. D. Sergeyev
The Inﬁnite Unit Axiom. The inﬁnite unit of measure is introduced as
the number of elements of the set, N, of natural numbers. It is expressed by
the numeral ①called grossone and has the following properties:
Inﬁnity. Any ﬁnite natural number n is less than grossone, i.e., n < ①.
Identity. The following relations link ①to identity elements 0 and 1
0 · ①= ①· 0 = 0,
①−①= 0,
①
①= 1,
①0 = 1,
1
①= 1,
0
①= 0.
(7)
Divisibility. For any ﬁnite natural number n sets Nk,n, 1 ≤k ≤n, being
the nth parts of the set, N, of natural numbers have the same number of
elements indicated by the numeral ①
n where
Nk,n = {k, k + n, k + 2n, k + 3n, . . .},
1 ≤k ≤n,
n
k=1
Nk,n = N.
(8)
Let us comment upon this axiom. Its ﬁrst part—Inﬁnity—is quite clear.
In fact, we want to describe an inﬁnite number, thus, it should be larger than
any ﬁnite number. The second part of the axiom—Identity—tells us that ①
interacts with identity elements 0 and 1 as all other numbers do. In reality,
we could even omit this part of the axiom because, due to Postulate 3, all
numbers should be treated in the same way and, therefore, at the moment
we have stated that grossone is a number, we have ﬁxed the usual properties
of numbers, i.e., the properties described in Identity, associative and com-
mutative properties of multiplication and addition, distributive property of
multiplication over addition, etc. The third part of the axiom—Divisibility—
is the most interesting, since it links inﬁnite numbers to inﬁnite sets (in many
traditional theories inﬁnite numbers are introduced algebraically, without any
connection to inﬁnite sets) and is based on Postulate 3. Let us ﬁrst illustrate
it by an example.
Example 1 If we take n = 1, then it follows that N1,1 = N and Divisibility
says that the set, N, of natural numbers has ①elements. If n = 2, we have
two sets N1,2 and N2,2, where
N1,2 = {1,
3,
5,
7, . . . },
N2,2 = {
2,
4,
6,
. . . }
(9)
and they have ①
2 elements each. Notice that the sets N1,2 and N2,2 have the
samenumberofelementsnotbecausetheyareinaone-to-onecorrespondence
but due to the Divisibility axiom. In fact, we are not able to count the number

A New Computational Paradigm Using Grossone-Based …
17
of elements of the sets N, N1,2, and N2,2 one by one because due to Postulate 1
we are able to execute only a ﬁnite number of operations whereas all these
sets are inﬁnite. To deﬁne their number of elements we use Divisibility and
implement Postulate 3 in practice by determine the number of the elements
of the parts using the whole.
Then, if n = 3, we have three sets
N1,3 = {1,
4,
7,
. . . },
N2,3 = {
2,
5,
8,
. . . },
N3,3 = {
3,
6,
9, . . . }
(10)
and they have ①
3 elements each. Note that in formulae (9), (10) we have added
extra spaces writing down the elements ofthe sets N1,2, N2,2, N1,3, N2,3, N3,3
just to emphasize Postulate 3 and to show visually that N1,2 ∪N2,2 = N and
N1,3 ∪N2,3 ∪N3,3 = N.
□
In general, to introduce ①
n we do not try to count elements k, k + n, k +
2n, k + 3n, . . . one by one in (8). In fact, we cannot do this due to Postulate 1.
By using Postulate 3, we construct the sets Nk,n, 1 ≤k ≤n, by separating
the whole, i.e., the set N, in n parts and we afﬁrm that the number of elements
of the nth part of the set, i.e., ①
n , is n times less than the number of elements
of the entire set, i.e., than ①.
As was already mentioned, in terms of our granary example ①can be
interpreted as the number of seeds in the sack. In that example, the num-
ber K1 of seeds in each sack was ﬁxed and ﬁnite but it was impossible to
express it in units u0, i.e., seeds, by counting seed by seed because we had
supposed that sacks were very big and the corresponding number would not
be expressible by available numerals. In spite of the fact that K1, K2, and
K3 were inexpressible and unknown, by using new units of measure (sacks,
trucks, etc.) it was possible to count more easily and to express the required
quantities. Now our sack has the inﬁnite but again ﬁxed number of seeds. It
is ﬁxed because it has a strong link to a concrete set—it is the number of
elements of the set of natural numbers. Since this number is inexpressible by
existing numeral systems with the same accuracy afforded to measure ﬁnite
small sets3, we introduce a new numeral, ①, to express the required quantity.
3 First, this quantity is inexpressible by numerals used to count the number of elements
of ﬁnite sets because the set N is inﬁnite. Second, traditional numerals existing to express
inﬁnite numbers do not have the required high accuracy (recall that we would like to
be able to register the variation of the number of elements of inﬁnite sets even when

18
Y. D. Sergeyev
Then, we apply Postulate 3 and say that if the sack contains ①seeds, then,
even though we are not able to count the number of seeds of the nth part of
the sack seed by seed, its nth part contains n times less seeds than the entire
sack, i.e., ①
n seeds. Notice that the numbers ①
n are integer since they have
been introduced as numbers of elements of sets Nk,n.
The new unit of measure allows us to express a variety of inﬁnite numbers
(including those larger than ①that will be considered later) and calculate
easilythenumberofelementsoftheunion,intersection,difference,orproduct
of sets of type Nk,n. Due to our accepted methodology, we do it in the same
way as these measurements are executed for ﬁnite sets. Let us consider two
simple examples showing how grossone can be used for this purpose.
Example 2 Let us determine the number of elements of the set Ak,n =
Nk,n\{a, b}, a, b ∈Nk,n, n ≥1. Due to the IUA, the set Nk,n has ①
n ele-
ments. The set Ak,n has been constructed by excluding two elements from
Nk,n. Thus, the set Ak,n has ①
n −2 elements. The granary interpretation can
be also given for the number ①
n −2: the number of seeds in the nth part of the
sack minus two seeds. For n = 1 we have ①−2 interpreted as the number
of seeds in the sack minus two seeds.
□
Divisibility and Example 2 show us that in addition to the usual way of
counting, i.e., by adding units, that has been formalized in the traditional
mathematics, there exists also the way to count by taking parts of the whole
and by subtracting units or parts of the whole. The following example shows
a slightly more complex situation (other more sophisticated examples will
be given later after the reader gets accustomed to the concept of ①).
Example 3 Let us consider the following two sets
B1 = {3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 68, 73, 78,
83, 88, 93, 98, 103, 108, 113, 118, . . . },
(11)
B2 = {3, 14, 25, 36, 47, 58, 69, 80, 91, 102, 113, 124, 135, . . . }
(12)
and determine the number of elements in the set
B = (B1 ∩B2) ∪{3, 4, 5, 113}.
one element has been excluded or added). For example, by using Cantor’s Alephs we
say that cardinality of the sets N and N \ {1} is the same—ℵ0. This answer is correct
but its accuracy is low. Using Cantor’s cardinals we are not able to register the fact that
one element was excluded from the set N even though we ourselves have executed this
exclusion. Analogously, we can say that both the sets have many elements. Again, the
answer ‘many’ is correct but its accuracy is also low.

A New Computational Paradigm Using Grossone-Based …
19
It follows immediately from the IUA that B1 = N3,5 and B2 = N3,11. From
(11) and (12) we can see that their intersection is
B1 ∩B2 = N3,5 ∩N3,11 = {3, 58, 113, . . .} = N3,55.
Thus, due to the IUA, the set N3,55 has ①
55 elements. Finally, since 3 and 113
belong to the set N3,55 and 4 and 5 do not belong to it, the set B has ①
55 + 2
elements. The granary interpretation is the following: ①
55 + 2 is the number
of seeds in the 55th part of the sack plus two seeds.
□
The IUA introduces ①as the number of elements of the set of natural
numbers and, therefore, it is the last natural number. We can also talk about
the set of extended natural numbers indicated as N and including N as a
proper subset
N = {1, 2, . . . , ①−1, ①



Natural numbers
, ①+ 1, ①+ 2, . . . , 2①−1, 2①, 2①+ 1, . . .
①2 −1, ①2, ①2 + 1, . . . 3①
①−1, 3①
①, 3①
①+ 1, . . .}.
(13)
The extended natural numbers greater than grossone are also linked to inﬁnite
sets of numbers and can be interpreted in the terms of grain. For example,
①+ 1 is the number of elements of a set B3 = N ∪{a}, where a is integer
and a /∈N. In the terms of grain, ①+ 1 is the number of seeds in a sack plus
one seed.
The extended natural numbers greater than grossone are also linked to sets
of numbers and can be interpreted in the terms of grain.
Example 4 Let us determine the number of elements of the set
Cm = {(a1, a2, . . . , am−1, am) : ai ∈N, 1 ≤i ≤m},
2 ≤m ≤①.
The elements of Cm are m-tuples of natural numbers. It is known from com-
binatorial calculus that if we have m positions and each of them can be ﬁlled
in by one of l symbols, the number of the obtained m-tuples is equal to lm.
In our case, since N has grossone elements, l = ①. Thus, the set Cm has ①m
elements. In the particular case, m = 2, we obtain that the set
C2 = {(a1, a2) : ai ∈N, i ∈{1, 2}},
being the set of couples of natural numbers, has ①2 elements. This fact is
illustrated below

20
Y. D. Sergeyev
(1, 1),
(1, 2),
. . .
(1, ①−1),
(1, ①),
(2, 1),
(2, 2),
. . .
(2, ①−1),
(2, ①),
. . .
. . .
. . .
. . .
. . .
(①−1, 1),
(①−1, 2),
. . .
(①−1, ①−1), (①−1, ①),
(①, 1),
(①, 2),
. . .
(①, ①−1),
(①, ①).
□
Let us consider now how the principle ‘The part is less than the whole’
included in Postulate 3 and the IUA can be reconciled with traditional views
on inﬁnite sets. At ﬁrst sight it seems that there is a contradiction between
the two methodological positions. For instance, traditionally it is said that the
one-to-one correspondence can be established between the set, N, of natural
numbers and the set, O, of odd numbers. Namely, odd numbers can be put
in a one-to-one correspondence with all natural numbers in spite of the fact
that O is a proper subset of N
odd numbers:
1, 3, 5, 7, 9, 11, . . .
↕↕↕↕↕↕
natural numbers:
1, 2, 3, 4 5, 6, . . .
(14)
The traditional conclusion from (14) is that both sets are countable and they
have the same cardinality ℵ0.
Let us see now what we can say from the new methodological position, in
particular, by using Postulate 2. The separation of the objects of study which
are two inﬁnite sets from the instrument used to compare them, i.e., from
the bijection, suggests that another conclusion can be derived from (14): the
accuracy of the used instrument is not sufﬁciently high to see the difference
between the sizes of the two sets.
We have already seen that when one executes the operation of counting,
the accuracy of the result depends on the numeral system used for counting. If
one asked Pirahã to measure sets consisting of four apples and ﬁve apples the
answer would be that both sets of apples have many elements. This answer
is correct but its precision is low due to the weakness of the numeral system
used to measure the sets.
Thus, the introduction of the notion of accuracy for measuring sets is
very important and should be applied to inﬁnite sets also. As was already
discussed, since for cardinal numbers it follows
ℵ0 + 1 = ℵ0,
ℵ0 + 2 = ℵ0,
ℵ0 + ℵ0 = ℵ0,

A New Computational Paradigm Using Grossone-Based …
21
these relations suggest that the accuracy of the cardinal numeral system of
Alephs is not sufﬁciently high to see the difference with respect to the number
of elements of the two sets from (14).
In order to look at the record (14) using the new methodology let us remind
that due to the IUA the sets of even and odd numbers have ①/2 elements
each and, therefore, ①is even. It is also necessary to recall that numbers
that are larger than ①are not natural, they are extended natural numbers. For
instance, ①+ 1 is odd but not natural, it is the extended natural, see (13).
Thus, the last odd natural number is ①−1. Since the number of elements of
the set of odd numbers is equal to ①
2 , we can write down not only the initial
(as it is usually done traditionally) but also the ﬁnal part of (14)
1, 3, 5, 7, 9, 11, . . . ①−5, ①−3, ①−1
↕↕↕↕↕↕
↕
↕
↕
1, 2, 3, 4 5, 6, . . . ①
2 −2, ①
2 −1,
①
2
(15)
concluding so (14) in a complete accordance with the principle ‘The part is
less than the whole’. Both records, (14) and (15), are correct but (15) is more
accurate, since it allows us to observe the ﬁnal part of the correspondence
that is invisible if (14) is used.
In many othercases the ①-based methodology allows us to measure inﬁnite
sets better with respect to Cantor’s cardinals. We conclude this section by
Table 1 that illustrates this fact and collects results proved in [75].
5
Positional Numeral System with the Inﬁnite Base ①
We have already started to write down simple inﬁnite numbers and to execute
arithmetical operations with them without concentrating our attention upon a
general form we wish to use to write down different inﬁnite and inﬁnitesimal
numbers. We also did not describe yet algorithms for executing arithmetical
operations with these numbers. Let us explore these two issues systematically.
Different numeral systems have been developed to describe ﬁnite numbers.
In positional numeral systems, fractional numbers are expressed by the record
(anan−1 . . . a1a0.a−1a−2 . . . a−(q−1)a−q)b
(16)
where numerals ai, −q ≤i ≤n, are called digits, belong to the alphabet
{0, 1, . . . , b −1}, and the dot is used to separate the fractional part from
the integer one. Thus, the numeral (16) expresses the quantity obtained by
summing up

22
Y. D. Sergeyev
Table 1 Cardinalities and the number of elements of some inﬁnite sets, see [75]
Description of sets
Cantor’s cardinalities
Number of elements
The set of natural numbers
N
Countable, ℵ0
①
N \ {3, 5, 10, 23, 114}
Countable, ℵ0
①−5
The set of even numbers E
(the set of odd numbers O)
Countable, ℵ0
①
2
The set of integers Z
Countable, ℵ0
2①+1
Z \ {0}
Countable, ℵ0
2①
Squares of natural numbers
G = {x : x = n2, x ∈
N, n ∈N}
Countable, ℵ0
⌊
√
①⌋
Pairs of natural numbers
P = {(p, q) : p ∈N, q ∈
N}
Countable, ℵ0
①2
The set of numerals
Q1 = { p
q : p ∈Z, q ∈
Z, q ̸= 0}
Countable, ℵ0
4①2 + 2①
The set of numerals
Q2 = {0, −p
q ,
p
q : p ∈
N, q ∈N}
Countable, ℵ0
2①2 + 1
The power set of the set of
natural numbers N
Continuum, c
2①
The power set of the set of
even numbers E
Continuum, c
20.5①
The power set of the set of
integers Z
Continuum, c
22①+1
The power set of the set of
numerals Q1
Continuum, c
24①2+2①
The power set of the set of
numerals Q2
Continuum, c
22①2+1
Numbers x ∈[0, 1)
expressible in the binary
numeral system
Continuum, c
2①
Numbers x ∈[0, 1]
expressible in the binary
numeral system
Continuum, c
2①+ 1
Numbers x ∈(0, 1)
expressible in the decimal
numeral system
Continuum, c
10①−1
Numbers x ∈[0, 2)
expressible in the decimal
numeral system
Continuum, c
2 · 10①

A New Computational Paradigm Using Grossone-Based …
23
anbn + an−1bn−1 + . . . + a1b1 + a0b0 + a−1b−1 + . . . + a−(q−1)b−(q−1) + a−qb−q.
(17)
Record (16) uses numerals consisting of one symbol each, i.e., digits ai ∈
{0, 1, . . . , b −1}, to express how many ﬁnite units of the type bi belong to
the number (17). Quantities of ﬁnite units bi are counted separately for each
exponent i and all symbols in the alphabet {0, 1, . . . , b −1} express ﬁnite
numbers.
To express inﬁnite and inﬁnitesimal numbers we shall use records that are
similar to (16) and (17) but have some peculiarities. In order to construct a
number C in the numeral positional system with the base ①, we subdivide C
into groups corresponding to powers of ①:
C = cpm①pm + . . . + cp1①p1 + cp0①p0 + cp−1①p−1 + . . . + cp−k①p−k.
(18)
Then, the record
C = cpm①pm . . . cp1①p1cp0①p0cp−1①p−1 . . . cp−k①p−k
(19)
represents the number C, where all numerals ci are called grossdigits. They
are not equal to zero and belong to a traditional numeral system. Grossdigits
express ﬁnite positive or negative numbers and show how many correspond-
ing units ①pi should be added or subtracted in order to form the number C.
Grossdigits can be expressed by several symbols using positional systems,
can be written in the form Q
q where Q and q are integers, or in any other
numeral system used to express ﬁnite quantities.
Numbers pi in (19) called grosspowers can be ﬁnite, inﬁnite, and inﬁnites-
imal (the introduction of inﬁnitesimal numbers will be given soon), they are
sorted in the decreasing order
pm > pm−1 > . . . > p1 > p0 > p−1 > . . . p−(k−1) > p−k
with p0 = 0.
In the traditional record (16), there exists a convention that a digit ai
shows how many powers bi are present in the number and the radix b is
not written explicitly. In the record (19), we write ①pi explicitly because
in the ①-based positional system the number i in general is not equal to
the grosspower pi. This gives the possibility to write, for example, such a
number as 3.6①44.5 134①32.1 having grosspowers p2 = 44.5, p1 = 32.1 and
grossdigits c44.5 = 3.6, c32.1 = 134 without indicating grossdigits equal to
zero corresponding to grosspowers smaller than 44.5 and greater than 32.1.
Note also that if a grossdigit cpi = 1 then we often write ①pi instead of 1①pi .

24
Y. D. Sergeyev
The term having p0 = 0 represents the ﬁnite part of C because, due to (7),
we have c0①0 = c0. The terms having ﬁnite positive grosspowers represent
the simplest inﬁnite parts of C. Analogously, terms having negative ﬁnite
grosspowers represent the simplest inﬁnitesimal parts of C. For instance, the
number ①−1 = 1
①is inﬁnitesimal. It is the inverse element with respect to
multiplication for ①:
①−1 · ①= ①· ①−1 = 1.
(20)
Note that all inﬁnitesimals are different from zero. Particularly,
1
①> 0
because it is a result of division of two positive numbers. It also has a clear
granary interpretation. Namely, if we have a sack containing ①seeds, then
one sack divided by the number of seeds in it is equal to one seed. Vice versa,
one seed, i.e., 1
①, multiplied by the number of seeds in the sack, ①, gives one
sack of seeds.
All of the numbers introduced above can be grosspowers, as well. This
gives a possibility to have various combinations of quantities and to construct
terms having a more complex structure.
Example 5 The left-hand expression below shows how to write down num-
bers in the new numeral system and the right-hand shows how the value of
the number is calculated:
4.1①50.3①(−7.2)①2.14.6①01.8①−7.4 = 4.1①50.3①−7.2①2.1 + 4.6①0 + 1.8①−7.4.
The number above has one inﬁnite part with an inﬁnite grosspower, one
inﬁnite part having a ﬁnite grosspower, a ﬁnite part, and an inﬁnitesimal
part.
□
Finally, numbers having a ﬁnite and inﬁnitesimal parts can be
also expressed in the new numeral system, for instance, the number
3.6①0−5.2①−3.711①−16.5①+0.3 has a ﬁnite and two inﬁnitesimal parts, the
second of them has the inﬁnite negative grosspower equal to −16.5①+ 0.3.
In case a ﬁnite number has no inﬁnitesimal parts it is called purely ﬁnite. This
deﬁnition will play an important role in a number of applications described
in the subsequent Chapters.
Let us now describe arithmetical operations with the ①-based positional
numeral system that can be executed on the Inﬁnity Computer. This is a
new supercomputer able to work with numbers (19) numerically. It has been
patented in several countries (see [70, 75]). A working software simulator of
the Inﬁnity Computer has been implemented and the ﬁrst application—the
Inﬁnity Calculator—has been realized. Figure 1 shows operation of multi-
plication executed on the Inﬁnity Calculator that works using the Inﬁnity

A New Computational Paradigm Using Grossone-Based …
25
Fig. 1 Operation of multiplication executed on the Inﬁnity Calculator
Fig. 2 Operation of division executed on the Inﬁnity Calculator
Computer technology. Both operands have one inﬁnite and one inﬁnitesimal
part whereas the result of multiplication has two inﬁnite and two inﬁnitesi-
mal parts. Figure 2 shows division where the ﬁrst operand has two inﬁnite
and two inﬁnitesimal parts and the second operand has one ﬁnite and one
inﬁnitesimal part. The result is the number having two inﬁnite parts.
Let us give now a general description of operations providing other exam-
ples.

26
Y. D. Sergeyev
We start by discussing the operation of addition (subtraction is a direct
consequence of addition and is thus omitted). Let us consider numbers A, B,
and C, where
A =
K

i=1
aki①ki,
B =
M

j=1
bm j①m j,
C =
L

i=1
cli①li,
(21)
and the result C = A + B is constructed by including in it all items aki①ki
from A such that ki ̸= m j, 1 ≤j ≤M, and all items bm j①m j from B such
that m j ̸= ki, 1 ≤i ≤K. If in A and B there are items such that ki = m j,
for some i and j, then this grosspower ki is included in C with the grossdigit
bki + aki, i.e., as (bki + aki)①ki.
Example 6 (Addition) We consider two inﬁnite numbers A and B, where
A = 15①332①7.3(−2)①−4.5,
B = 25①33345.1①6(−3)①−2.
Their sum C is calculated as follows:
C = A + B = 15①33 + 2①7.3 + (−2)①−4.5 + 25①33 + 345.1①6 + (−3)①−2
= 40①33 + 2①7.3 + 345.1①6 + (−3)①−2 + (−2)①−4.5
= 40①332①7.3345.1①6(−3)①−2(−2)①−4.5.
The operation of multiplication of two numbers A and B in the form (21)
returns, as the result, the inﬁnite number C constructed as follows:
C =
M

j=1
C j,
C j = bm j①m j · A =
K

i=1
akibm j①ki+m j,
1 ≤j ≤M.
(22)
Example 7 (Multiplication) We consider two following numbers
A = 1①14(−2.5)①−3,
B = −1①12①−4(−5)①−5
and calculate the product C = A · B. The ﬁrst partial product C1 is equal to
C1 = (−2.5)①−3 · B = (−2.5)①−3(−①1 + 2①−4 −5①−5)
= 2.5①−2 −5①−7 + 12.5①−8.
The second partial product, C2, is computed analogously

A New Computational Paradigm Using Grossone-Based …
27
C2 = ①14 · B = ①14(−①1 + 2①−4 −5①−5)
= −①15 + 2①10 −5①9.
Finally, the product C is equal to
C = C1 + C2 = −①152①10(−5)①92.5①−2(−5)①−712.5①−8.
In the operation of division of a number C by a number B from (21), we
obtain a result A and a reminder R (that may equal zero), i.e., C = A · B + R.
The number A is constructed as follows. The ﬁrst grossdigit akK and the
corresponding maximal exponent kK are established from the equalities
akK = clL/bmM,
kK = lL −mM.
(23)
Then the ﬁrst partial reminder R1 is calculated as
R1 = C −akK ①kK · B.
(24)
If R1 ̸= 0 then the number C is substituted by R1 and the process is repeated
with a complete analogy. The grossdigit akK−i, the corresponding grosspower
kK−i and the partial reminder Ri+1 are computed by formulae (25) and (26)
obtained from (23) and (24) as follows: lL and clL are substituted by the
highest grosspower ni and the corresponding grossdigit rni of the partial
reminder Ri that, in turn, substitutes C:
akK−i = rni/bmM,
kK−i = ni −mM.
(25)
Ri+1 = Ri −akK−i①kK−i · B,
i ≥1.
(26)
The process stops when a partial reminder equal to zero is found (this means
that the ﬁnal reminder R = 0) or when a required accuracy of the result is
reached.
Example 8 (Division) Let us divide the number C = 135①272①09①−2 by
the number B = 9①23①0. For these numbers we have
lL = 2,
mM = 2,
clL = 135,
bmM = 9.
It follows immediately from (23) that akK ①kK = 15①0. The ﬁrst partial
reminder R1 is calculated as
R1 = 135①272①09①−2 −15①0(9①23①0)

28
Y. D. Sergeyev
= 135①272①09①−2 −135①245①0 = 27①09①−2.
By a complete analogy we should construct akK−1①kK−1 by rewriting (23)
for R1. By doing so we obtain equalities
27 = akK−1 · 9,
0 = kK−1 + 2
and, as the result, akK−1①kK−1 = 3①−2. The second partial reminder is
R2 = R1 −3①−2 · 9①23①0 = 27①09①−2 −27①09①−2 = 0.
Thus, we can conclude that the reminder R = R2 = 0 and the ﬁnal result of
division is A = 15①03①−2.
Let us now substitute the grossdigit 9 by 7 in C and divide this new number
˜C = 135①272①07①−2 by the same number B = 9①23①0. This operation
gives us the same result ˜A2 = A = 15①03①−2 (where subscript 2 indicates
that two partial reminders have been obtained) but with the reminder ˜R =
˜R2 = −2①−2. Thus, we obtain ˜C = B · ˜A2 + ˜R2. If we want to continue
the procedure of division, we obtain ˜A3 = 15①03①−2 	
−2
9

①−4 with the
reminder ˜R3 = 2
3①−4. Naturally, it follows ˜C = B · ˜A3 + ˜R3. The process
continues until a partial reminder ˜Ri = 0 is found orwhen a required accuracy
of the result will be reached.
6
Some Paradoxes of Inﬁnity Related to Divergent
Series
The ①-based methodology allows one to avoid numerous classical paradoxes
related to the notion of inﬁnity (for example, Galileo’s paradox, Hilbert’s
paradox of the Grand Hotel, Thomson’s lamp paradox, the rectangle para-
dox of Torricelli, etc., see [66] and the references therein) and provides the
ﬁrst foundations for a mathematical analysis allowing one to work without
indeterminate forms and divergences (see [71]). It is interesting that this anal-
ysis allows one to operate with functions assuming inﬁnite and inﬁnitesimal
values over inﬁnite and inﬁnitesimal domains.
Let us consider just a couple of paradoxes dealing with divergent series
ﬁrst in the traditional fashion and then in the ①-based framework. We shall
show that a very simple chain of equalities including addition of an inﬁnite
number of summands can lead to a paradoxical result.

A New Computational Paradigm Using Grossone-Based …
29
Suppose that we have
x = 1 + 2 + 4 + 8 + . . .
(27)
Then we can multiple both parts of this equality by 2:
2x = 2 + 4 + 8 + . . .
By adding 1 to both parts of the previous formula we obtain
2x + 1 = 1 + 2 + 4 + 8 + . . .
(28)
It can be immediately noticed that the right hand side of (28) is just equal to
x and, therefore, it follows
2x + 1 = x
from which we obtain
x = −1
and, as a ﬁnal paradoxical result, the following equality follows
1 + 2 + 4 + 8 + . . . = −1.
(29)
The paradox here is evident: we have summed up an inﬁnite number of
positive integers and have obtained as the ﬁnal result a negative number.
The second paradox considers the well known divergent series of Guido
Grandi S = 1 −1 + 1 −1 + 1 −1 + . . . (see [44]). By applying the tele-
scoping rule, i.e., by writing a general element of the series as a difference,
we can obtain two different answers using two general elements, 1–1 and
–1+1:
S = (1 −1) + (1 −1) + (1 −1) + . . . = 0,
S = 1 + (−1 + 1) + (−1 + 1) + (−1 + 1) + . . . = 1.
In the literature there exist many other approaches giving different answers
regarding the value of this series (see, e.g., [44]). Some of them use various
notions of average (for instance, Cesàro summation assigns the value 0.5 to
S, see [44, 84]).
Let us consider now these two paradoxes in the new fashion starting from
the deﬁnition of x in (27). Thanks to ①, we have different inﬁnite integers
and, therefore, we can consider sums having different inﬁnite numbers of
summands. Thus, with respect to the new methodology, (27) is not well
deﬁned because the number of summands in the sum (27) is not explicitly

30
Y. D. Sergeyev
indicated. Recall that to say just that there are ∞many summands has the
same meaning of the phrase ‘There are many summands’ (see (1), (2)).
Thus, it is necessary to indicate explicitly an inﬁnite number of addends,
k, (obviously, it can be ﬁnite, as well). After this (27) becomes
x(k) = 1 + 2 + 4 + 8 + . . . + 2k−1
and multiplying both parts by two and adding one to both the right and left
sides of the above equality gives us
2x(k) + 1 = 1 + 2 + 4 + 8 + . . . + 2k−1 + 2k.
Thus, when we go to substitute, we can see that there remains an addend,
2k, that is inﬁnite if k is inﬁnite, and that was invisible in the traditional
framework:
2x(k) + 1 = 1 + 2 + 4 + 8 + . . . + 2k−1



x(k)
+2k.
The substitution gives us the resulting formula
x(k) = 2k −1
that works for both ﬁnite and inﬁnite values of k giving different results for
different values of k (exactly as it happens for the cases with ﬁnite values
of k). For instance, x(①) = 2①−1 and x(3①) = 23①−1. Thus, the paradox
(29) does not take place.
Let us consider now Grandi’s series. To calculate the required sum, we
should indicate explicitly the number of addends, k, in it. Then it follows that
S(k) = 1 −1 + 1 −1 + 1 −1 + 1 −. . .



k addends
=
0, if k = 2n,
1, if k = 2n + 1,
(30)
and it is not important whether k is ﬁnite or inﬁnite. For example, S(①) = 0
since ①is even. Analogously, S(①−1) = 1 because ①−1 is odd.
As it happens in the cases where the number of addends in a sum is
ﬁnite, the result of summation does not depend on the way the summands
are rearranged. In fact, if we know the exact inﬁnite number of addends and
the order the signs are alternated is clearly deﬁned, we know also the exact
number of positive and negative addends in the sum. Let us illustrate this
point by supposing, for instance, that we want to rearrange addends in the
sum S(2①) as follows

A New Computational Paradigm Using Grossone-Based …
31
S(2①) = 1 + 1 −1 + 1 + 1 −1 + 1 + 1 −1 + . . .
Traditional mathematical tools used to study divergent series give an impres-
sion that this rearrangement modiﬁes the result. However, in the ①-based
framework we know that this is just a consequence of the weak lens used to
observe inﬁnite numbers. In fact, thanks to ①we are able to ﬁx an inﬁnite
number of summands. In our example the sum has 2①addends, the number
2①is even and, therefore, it follows from (30) that S(2①) = 0. This means
also that in the sum there are ①positive and ①negative items. As a result,
addition of the groups 1 + 1 −1 considered above can continue only until
the positive units present in the sum will not ﬁnish and then there will be
necessary to continue to add only negative summands. More precisely, we
have
S(2①) = 1 + 1 −1 + 1 + 1 −1 + . . . + 1 + 1 −1



①positive and ①
2 negative addends
−1 −1 −. . . −1 −1



①
2 negative addends
= 0,
(31)
where the result of the ﬁrst part in this rearrangement is calculated as (1 +
1 −1) ·
①
2 =
①
2 and the result of the second part summing up negative units is
equal to −
①
2 giving so the same ﬁnal result S(2①) = 0. It becomes clear from
(31) the origin of the Riemann series theorem. In fact, the second part of (31)
containing only negative units is invisible if one works with the traditional
numeral ∞.
7
Conclusion
In this Chapter, a recently introduced computational methodology allowing
one to work numerically with different inﬁnite and inﬁnitesimal numbers has
been described. The exposition was limited to basic rules and ideas that would
allow the reader to execute his/her own computations. In order to learn more
about this fascinating new opportunity for computing we suggest to refer
to a comprehensive technical survey [75] and the popular book [67]. The
subsequent Chapters of this book describe a number of striking applications
in optimization whereas the list of references includes numerous results in
different ﬁelds of computer science and pure and applied mathematics (many
of them are available at the web page [37]). People interested in teaching this
methodology will beneﬁt from the dedicated web page [36] developed at the
University of East Anglia, UK.

32
Y. D. Sergeyev
References
1. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
2. Antoniotti, L., Caldarola, F., d’Atri, G., Pellegrini, M.: New approaches to basic cal-
culus: an experimentation via numerical computation. In: Sergeyev, Y.D., Kvasov,
D.E., (eds.), Numerical Computations: Theory and Algorithms. NUMTA 2019,
LNCS, vol. 11973, pp. 329–342. Springer (2020)
3. Antoniotti, L., Caldarola, F., Maiolo, M.: Inﬁnite numerical computing applied to
Hilbert’s, Peano’s, and Moore’s curves. Mediterranean J. Math. 17, Article Number
99 (2020)
4. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft. Comput.
24, 17751–17759 (2020)
5. Bagaria, J., Magidor, M.: Group radicals and strongly compact cardinals. Trans. Am.
Math. Soc. 366(4), 1857–1877 (2014)
6. Butterworth, B., Reeve, R., Reynolds, F., Lloyd, D.: Numerical thought with and
without words: evidence from indigenous Australian children. Proc. Natl. Acad. Sci.
U.S.A. 105(35), 13179–13184 (2008)
7. Caldarola, F.: The Sierpinski curve viewed by numerical computations with inﬁnities
and inﬁnitesimals. Appl. Math. Comput. 318, 321–328 (2018)
8. Caldarola, F., Maiolo, M.: On the topological convergence of multi-rule sequences
of sets and fractal patterns. Soft. Comput. 24(23), 17737–17749 (2020)
9. Calude, C.S., Dumitrescu, M.: Inﬁnitesimal probabilities based on grossone. SN
Comput. Sci. 1, Article Number 36 (2020)
10. Cantor, G.: Contributions to the Founding of the Theory of Transﬁnite Numbers.
Dover Publications, New York (1955)
11. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020)
12. Cococcioni,M.,Fiaschi,L.:TheBig-MmethodwiththenumericalinﬁniteM.Optim.
Lett. 15, 2455–2468 (2021)
13. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018)
14. Colyvan, M.: An Introduction to the Philosophy of Mathematics. Cambridge Uni-
versity Press, Cambridge (2012)
15. Comrie, B.: Numeral bases. In: Dryer, M.S., Haspelmath, M., (eds.), The World Atlas
of Language Structures Online. Max Planck Institute for Evolutionary Anthropology,
Leipzig (2013). http://wals.info/chapter/131
16. Conway, J.H., Guy, R.K.: The Book of Numbers. Springer, New York (1996)
17. Corry, L.: A Brief History of Numbers. Oxford University Press, Oxford (2015)
18. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput.
218(16), 8077–8082 (2012)
19. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. Soft. Comput. 55, 143–
158 (2020)

A New Computational Paradigm Using Grossone-Based …
33
20. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
21. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
22. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft. Comput. 24, 17669–17677 (2020)
23. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based com-
putationofnegativecurvaturedirectionsinlarge-scaleoptimization.J.Optim.Theory
Appl. 186, 554–589 (2020)
24. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
25. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: Representation of
Grossone-based arithmetic in Simulink and applications to scientiﬁc computing.
Soft. Comput. 24, 17525–17539 (2020)
26. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A Simulink-based
software solution using the inﬁnity computer methodology for higher order differ-
entiation. Appl. Math. Comput. 409, 125606 (2021)
27. Fiaschi, L., Cococcioni, M.: Numerical asymptotic results in game theory using
Sergeyev’s inﬁnity computing. Int. J. Unconv. Comput. 14(1), 1–25 (2018)
28. Fiaschi, L., Cococcioni, M.: Non-archimedean game theory: a numerical approach.
Appl. Math. Comput. 393, Article Number 125356 (2021). https://doi.org/10.1016/
j.amc.2020.125356
29. Gangle, R., Caterina, G., Tohmé, F.: A constructive sequence algebra for the calculus
of indications. Soft. Comput. 24(23), 17621–17629 (2020)
30. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
31. Gödel, K.: The Consistency of the Continuum-Hypothesis. Princeton University
Press, Princeton (1940)
32. Gordon, P.: Numerical cognition without words: evidence from Amazonia. Science
306(15), 496–499 (2004)
33. Hardy, G.H.: Orders of Inﬁnity. Cambridge University Press, Cambridge (1910)
34. Heller, M., Woodin, W.H. (eds.): Inﬁnity: New Research Frontiers. Cambridge Uni-
versity Press, Cambridge (2011)
35. Hilbert, D.: Mathematical problems: lecture delivered before the international
congress of mathematicians at Paris in 1900. Bull. Am. Math. Soc. 8, 437–479
(1902)
36. https://www.numericalinﬁnities.com
37. https://www.theinﬁnitycomputer.com
38. Iannone, P., Rizza, D., Thoma, A.: Investigating secondary school students’ episte-
mologies through a class activity concerning inﬁnity. In: Bergqvist, E., Österholm,
M., Granberg, C., Sumpter, L., (eds.), Proceedings of the 42nd Conference of the
International Group for the Psychology of Math. Education, vol. 3, pp. 131–138.
PME, Umeå (2018)
39. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation of
higher order Lie derivatives on the inﬁnity computer. J. Comput. Appl. Math. 383,
Article Number 113135 (2021)

34
Y. D. Sergeyev
40. Ingarozza, F., Adamo, M., Martino, M., Piscitelli, A.: A grossone-based numerical
model for computations with inﬁnity: a case study in an Italian high school. In:
Sergeyev, Y.D., Kvasov, D.E., (eds.), Numerical Computations: Theory and Algo-
rithms. NUMTA 2019, LNCS, vol. 11973, pp. 451–462. Springer (2020)
41. Iudin, D.I., Sergeyev, Y.D., Hayakawa, M.: Interpretation of percolation in terms of
inﬁnity computations. Appl. Math. Comput. 218(16), 8099–8111 (2012)
42. Iudin, D.I., Sergeyev, Y.D., Hayakawa, M.: Inﬁnity computations in cellular automa-
ton forest-ﬁre model. Commun. Nonlinear Sci. Numer. Simul. 20(3), 861–870 (2015)
43. Kanamori, A.: The Higher Inﬁnite: Large Cardinals in Set Theory from Their Begin-
nings, 2nd edn. Springer, Berlin (2003)
44. Knopp, K.: Theory and Application of Inﬁnite Series. Dover Publications, New York
(1990)
45. Kolmogorov, A.N.: Foundations of the Theory of Probability, 2nd English edn. Dover
Publications, New York (2018)
46. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed Pareto-lexicographic multi-
objective optimization problems: The case of priority chains. Swarm Evol. Comput.
55, 100687 (2020)
47. Leder, G.C.: Mathematics for all? The case for and against national testing. In:
Cho, S., (ed.), The Proceedings of the 12th International Congress on Mathematical
Education: Intellectual and Attitudinal Chalenges, pp. 189–207. Springer, New York
(2015)
48. Leibniz, G.W., Child, J.M.: The Early Mathematical Manuscripts of Leibniz. Dover
Publications, New York (2005)
49. Levi-Civita, T.: Sui numeri transﬁniti. Rend. Acc. Lincei, Serie 5a 7, 91–113 (1898)
50. Lolli, G.: Inﬁnitesimals and inﬁnites in the history of mathematics: A brief survey.
Appl. Math. Comput. 218(16), 7979–7988 (2012)
51. Lolli, G.: Metamathematical investigations on the theory of grossone. Appl. Math.
Comput. 255, 3–14 (2015)
52. Mancosu, P.: Abstraction and Inﬁnity. Oxford University Press, Oxford (2016)
53. Margenstern, M.: Using grossone to count the number of elements of inﬁnite sets
and the connection with bijections. p-Adic Numb., Ultrametric Anal. Appl. 3(3),
196–204 (2011)
54. Margenstern, M.: An application of grossone to the study of a family of tilings of
the hyperbolic plane. Appl. Math. Comput. 218(16), 8005–8018 (2012)
55. Montagna, F., Simi, G., Sorbi, A.: Taking the Pirahã seriously. Commun. Nonlinear
Sci. Numer. Simul. 21(1–3), 52–69 (2015)
56. Newton, I.: Method of Fluxions (1671)
57. Parikh, R.: Existence and feasibility in arithmetic. J. Symb. Log. 36(3), 494–508
(1971)
58. Pepelyshev, A., Zhigljavsky, A.: Discrete uniform and binomial distributions with
inﬁnite support. Soft. Comput. 24, 17517–17524 (2020)
59. Pica, P., Lemer, C., Izard, V., Dehaene, S.: Exact and approximate arithmetic in an
Amazonian indigene group. Science 306(15), 499–503 (2004)
60. Rizza, D.: Supertasks and numeral systems. In: Sergeyev, Y.D., Kvasov,
D.E., Dell’Accio, F., Mukhametzhanov, M.S., (eds.), Proceedings of the 2nd Inter-
national Conference “Numerical Computations: Theory and Algorithms”, vol. 1776.
AIP Publishing, New York (2016). https://doi.org/10.1063/1.4965369.090005
61. Rizza, D.: A study of mathematical determination through Bertrand’s Paradox. Phi-
los. Math. 26(3), 375–395 (2018)

A New Computational Paradigm Using Grossone-Based …
35
62. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Unconv.
Comput. 14(2), 139–158 (2019)
63. Robinson, A.: Non-standard Analysis. Princeton University Press, Princeton (1996)
64. Sazonov, V.Y.: On feasible numbers. In: D. Leivant (ed.) Logic and Computational
Complexity: LNCS, vol. 960, pp. 30–51. Springer (1995)
65. Sergeyev, Y.D.: Numerical inﬁnities applied for studying Riemann series theorem
and Ramanujan summation. In: AIP Conference Proceedings of ICNAAM 2017,
vol. 1978, p. 020004. AIP Publishing, New York (2018). https://doi.org/10.1063/1.
5043649
66. Sergeyev, Y.D.: Some paradoxes of inﬁnity revisited. Mediterranean J. Math. (to
appear)
67. Sergeyev, Y.D.: Arithmetic of Inﬁnity. Edizioni Orizzonti Meridionali, CS 2003, 2nd
edn. (2013)
68. Sergeyev, Y.D.: Blinking fractals and their quantitative analysis using inﬁnite and
inﬁnitesimal numbers. Chaos, Solitons Fractals 33(1), 50–75 (2007)
69. Sergeyev, Y.D.: Evaluating the exact inﬁnitesimal values of area of Sierpinski’s carpet
and volume of Menger’s sponge. Chaos, Solitons Fractals 42(5), 3042–3046 (2009)
70. Sergeyev, Y.D.: Computer system for storing inﬁnite, inﬁnitesimal, and ﬁnite quanti-
ties and executing arithmetical operations with them. USA patent 7,860,914 (2010)
71. Sergeyev, Y.D.: Counting systems and the First Hilbert problem. Nonlinear Anal.
Ser. A: Theory, Methods Appl. 72(3–4), 1701–1708 (2010)
72. Sergeyev, Y.D.: Using blinking fractals for mathematical modelling of processes of
growth in biological systems. Informatica 22(4), 559–576 (2011)
73. Sergeyev, Y.D.: The Olympic medals ranks, lexicographic ordering, and numerical
inﬁnities. Math. Intell. 37(2), 4–8 (2015)
74. Sergeyev, Y.D.: The exact (up to inﬁnitesimals) inﬁnite perimeter of the Koch
snowﬂake and its ﬁnite area. Commun. Nonlinear Sci. Numer. Simul. 31(1–3), 21–29
(2016)
75. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
76. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
77. Sergeyev, Y.D., Garro, A.: Observability of Turing machines: a reﬁnement of the
theory of computation. Informatica 21(3), 425–454 (2010)
78. Sergeyev, Y.D., Garro, A.: Single-tape and multi-tape Turing machines through the
lens of the Grossone methodology. J. Supercomput. 65(2), 645–663 (2013)
79. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: On strong homogeneity of a
class of global optimization algorithms working with inﬁnite and inﬁnitesimal scales.
Commun. Nonlinear Sci. Numer. Simul. 59, 319–330 (2018)
80. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.:
Numerical methods for solving initial value problems on the inﬁnity computer. Int.
J. Unconv. Comput. 12(1), 3–23 (2016)
81. Tohmé, F., Caterina, G., Gangle, R.: Computing truth values in the topos of inﬁ-
nite Peirce’s α-existential graphs. Appl. Math. Comput. 385, article number 125343
(2020)
82. Wallis, J.: Arithmetica inﬁnitorum (1656)
83. Woodin, W.H.: The continuum hypothesis. Part I. Notices AMS 48(6), 567–576
(2001)

36
Y. D. Sergeyev
84. Zhigljavsky, A.: Computing sums of conditionally convergent and divergent series
using the concept of grossone. Appl. Math. Comput. 218(16), 8064–8076 (2012)
85. Žilinskas, A.: On strong homogeneity of two global optimization algorithms based on
statistical models of multimodal objective functions. Appl. Math. Comput. 218(16),
8131–8136 (2012)

Nonlinear Optimization: A Brief
Overview
Renato De Leone
Abstract In this chapter some of the most important results for uncon-
strained and constrained optimization problems are discussed. This chapter
does not claim to cover all the aspects in nonlinear optimization that will
require more than one complete book. We decided, instead, to concentrate
our attention on few fundamental topics that are also at the basis of the new
results in nonlinear optimization using grossone introduced in the successive
chapters.
1
Introduction
The aim of this chapter is to introduce the reader to the most important results
and algorithms in unconstrained and constrained optimization. However, it
would be impossible to discuss the wide range of results in this area. We
decided to concentrate the attention on few fundamental topics that are also at
the basis of the new results obtained using ①and introduced in the successive
chapters. The interested reader can refer to various classical and recent books
to deepen his/her knowledge. We also omitted almost all proofs of the results,
but complete references are always provided.
After introducing the concepts of convex set and functions, in Sect. 3 opti-
mality conditions for unconstrained optimization are presented as well as the
most important algorithmic techniques: gradient method, conjugate gradient
method, Newton’s and Quasi-Newton’s methods. In the successive Sect. 4 we
concentrate the attention on optimality conditions for constrained optimiza-
R. De Leone (B)
School of Science and Technology, University of Camerino, Camerino (MC), Italy
e-mail: renato.deleone@unicam.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_2
37

38
R. De Leone
tion and the construction of the dual of nonlinear optimization problems.
Finally, some important algorithms for constrained nonlinear optimization
problems are presented.
Three important aspects in optimization are not presented here: global
optimization, multi–objective optimization, and non–smooth optimization.
In this chapter we only discuss ﬁrst and second order optimality conditions
for local optima, and all algorithms will compute a local minimum, or a sta-
tionary point (for the unconstrained case) or a Karush–Kuhn–Tucker point
(for the constrained case). Global optimization is an important area, theo-
retically and practically, for which several different approaches have been
suggested: space covering methods, trajectory methods, random sampling,
random search, etc. A basic reference on various aspects of global optimiza-
tion is [40], while practical applications are discussed in [51]. Finally, a
comprehensive archive of online information can be found at the web page
http://www.globaloptimization.org/.
Many optimization problems are multi–objective in nature, and different
techniques have been proposed to deal with this important aspect of opti-
mization. In general, due to the presence of conﬂicting objectives, there is no
single solution that simultaneously optimizes all the objectives, and, hence,
the aim is to determine non–dominated, Pareto optimal solutions [16, 23].
Two general approaches to multiple-objective optimization are present: com-
bine the individual objective functions into a single function, or move all but
one objective to the constraint set. More recently algorithms based on differ-
ent meta-heuristics have also been proposed in literature [41].
Non–smooth optimization problems arise in many important practical
applications. Here it is assumed that the function is continuous, but not differ-
entiable. The methods for non–smooth optimization can be roughly divided
into two main classes: subgradient methods and bundle methods. Both classes
of methods are based on the assumption that, at each point, the objective func-
tion value and one subgradient can be computed. A classical book on this
topic is [43]. A survey on different numerical methods for non–smooth opti-
mization and the most recent developments presented in [5]. Finally, a recent
compact survey on non–smooth optimization can be found in [28].
We brieﬂy describe our notation now. All vectors are column vectors and
will be indicated with lower case Latin letter (x, y, . . .). Subscripts indicate
components of a vector, while superscripts are used to identify different vec-
tors. Matrices will be indicated with upper case roman letter (A, B, . . .). For a
m × n matrix A, Ai j is the element in the ith row, jth column, A. j is the j–th
column of A, while Ai. is its i–th row. The set of real numbers and the set
of nonnegative real numbers will be denoted by IR and IR+ respectively. The
space of the n–dimensional vectors with real components will be indicated

Nonlinear Optimization: A Brief Overview
39
by IRn and IRn
+ is an abbreviation for the nonnegative orthant in IRn. The
symbol ∥x∥indicates the norm of the vector x. In particular, the Euclidean
norm is denoted by ∥x∥2, and ∥x∥2
2 = xT x. Superscript T indicates transpose.
The scalar product of two vectors x and y in IRn will be denoted by xT y.
The space of the m × n matrices with real components will be indicated by
IRm×n. The rank of a matrix A will be indicated by rankA. A square matrix
A ∈IRn×n is positive semideﬁnite if xT Ax ≥0 for all x ∈IRn and posi-
tive deﬁnite if xT Ax > 0 for all 0 ̸= x ∈IRn. If f : S ⊆IRn →IR∪{±∞},
dom f is the set of points x for which f (x) is deﬁned and f (x) ∈IR. The gra-
dient ∇f (x) of a continuously differentiable function f : IRn →IR at a point
x ∈IRn is a column vector with components [∇f (x)] j = ∂f (x)
∂x j . For a twice
differentiable function f : IRn →IR, the Hessian ∇2 f (x) belongs to IRn×n
and

∇2 f (x)

i j = ∂2 f (x)
∂xi∂x j . If F : IRn →IRm is a continuously differentiable
vector–valued function, then ∇F(x) ∈IRm×n denotes the Jacobian matrix of
F at x ∈IRn. Here and throughout the symbols := and =: denote deﬁnition
of the term on the left and the right sides of each symbol, respectively.
2
Convex Sets and Functions
Deﬁnition 1 ([56]) A set C ⊆IRn is a convex set if
x1, x2 ∈C,
λ ∈[0, 1]
=⇒
(1 −λ)x1 + λx2 ∈C.
Therefore, for a convex set C the segment joining any two distinct points in
C is all contained in C.
Deﬁnition 2 A point x ∈IRn is a convex combination of x1, x2, . . . , xk ∈
IRn if there exist scalars λ1, λ2, . . . , λk such that
x = λ1x1 + λ2x2 + . . . + λkxk with λ1 + λ2 + . . . + λk = 1, λ j ≥0, j = 1, . . . , k.
The concept of convex hull of a set is extremely important in optimization.
Deﬁnition 3 ([46, Deﬁnition 3.1.16]) Given S ⊆IRn the convex hull of S is
deﬁned as
conv S :=
⎧
⎪⎪⎨
⎪⎪⎩
x ∈IRn : x = λ1x1 + λ2x2 + . . . + λkxk
x1, . . . , xk ∈S
λ j ∈[0, 1], j = 1, . . . , k
λ1 + λ2 + . . . + λk = 1
⎫
⎪⎪⎬
⎪⎪⎭

40
R. De Leone
Clearly, if S is a convex set, then S = conv S.
Hyperplanes
H :=

x ∈IRn : pT x = μ

,
and halfspaces
S :=

x ∈IRn : pT x ≤μ

are examples of convex sets (here 0 ̸= p ∈IRn, and μ ∈IR). The set of sym-
metric positive semideﬁnite matrices is a convex subsets of IRn×n the set of
square matrices of dimension n. Another interesting example of convex set
is the norm cone
C :=
 x
t

∈IRn+1 : ∥x∥2 ≤t

⊆IRn+1.
Deﬁnition 4 ([46,Deﬁnition4.1.1])Let f : IRn →IR∪{+∞}, f isaconvex
function if dom f is a convex set and
f

(1 −λ)x + λy

≤(1 −λ) f (x) + λf (y) ∀x, y ∈dom f, λ ∈[0, 1]
(1)
The following propositions provide necessary and sufﬁcient conditions for
convexity for differentiable and twice differentiable functions.
Proposition 1 ([8, 3.1.3], [46, Theorem 6.1.2]) Let f : IRn →IR∪{+∞}
be a differentiable function. The function f is convex if and only if dom f is
convex and
f (y) ≥f (x) + ∇f (x)T (y −x) ∀x, y ∈dom f.
(2)
Proposition 2 ([8, 3.1.4], [46, Theorem 6.3.1]) Let f : IRn →IR∪{+∞},
be twice differentiable. The function f is convex if and only if dom f is convex
and ∇2 f (x) is positive semideﬁnite ∀x ∈dom f .
Finally, let introduce two additional weaker classes of functions whose
importance will be clear when necessary optimality conditions for uncon-
strained optimization problems will be introduced.
Deﬁnition 5 ([46, Deﬁnition 9.3.1]) Let f : IRn →IR∪{+∞} be a differ-
entiable function. The function f is pseudo–convex if
x, y ∈dom f,
∇f (x)T (y −x) ≥0 ⇒f (y) ≥f (x)
A convex function is also pseudo–convex.

Nonlinear Optimization: A Brief Overview
41
Deﬁnition 6 ([8, 3.4.1], [46, Deﬁnition 9.1.1]) Let f : IRn →IR∪{+∞}.
The function f is quasi–convex if
x, y ∈dom f,
f

(1 −λ)x + λy

≤max

f (x), f (y)

for λ ∈[0, 1]
Clearly, a convex function is also quasi–convex. Moreover, a differentiable
pseudo-convex function is also quasi–convex. The opposite is not true.
Forsimplicity,inthesequel,wewillonlyconsiderfunctionswhosedomain
is IRn.
3
Unconstrained Optimization
In this section we will present optimality conditions and algorithms for the
unconstrained optimization problems
min
x∈F f (x)
(3)
where f : IRn →IR is the objective function and the feasible set F ⊆IRn is
an open subset of IRn (note that F may coincide with IRn).
First, let introduce the following deﬁnitions.
Deﬁnition 7 ([6, Deﬁnition 3.4.1]) Let ¯x ∈F . The point ¯x is a global min-
imum of Problem (3) if
f (¯x) ≤f (x), ∀x ∈F .
The point ¯x is a strict global minimum of Problem (3) if
f (¯x) < f (x), ∀x ∈F , x ̸= ¯x.
Deﬁnition 8 ([6, Deﬁnition 3.4.1]) Let ¯x ∈F . The point ¯x is a local mini-
mum of Problem (3) if ∃γ > 0 such that
f (¯x) ≤f (x) ∀x ∈F and ∥x −¯x∥≤γ.
The point ¯x is a strict local minimum if ∃γ > 0 such that
f (¯x) < f (x) ∀x ∈F : 0 < ∥x −¯x∥≤γ.
The point ¯x is a strong or isolated local minimum if ∃γ > 0 such that ¯x is
the only local minimum in {x ∈IRn : ∥x −¯x∥≤γ } ∩F .

42
R. De Leone
If ¯x is a strong local minimum, then it is also a strict local minimum. On
the other hand, a strict local minimum may not be necessarily a strong local
minimum. For example, the function [7, p. 21]
f (x) =

x2 √
2 −sin

4
3π −
√
3 ln(x2)

if x ̸= 0
0
otherwise
has in x = 0 a strict local minimum that is not a strong (isolated) local mini-
mum. In the remaining of the section, without loss of generality, we assume
that F = IRn
3.1
Necessary and Sufﬁcient Optimality Conditions
Consider the nonlinear optimization problem (3) where f : IRn →IR is a
continuously differentiable function. The directional derivatives [3, Chap. 8]
of f at ¯x along the direction d is given by
lim
t→0+
f (¯x + td) −f (¯x)
t
= ∇f (¯x)T d.
A direction d ∈IRn is a descent direction for f (x) at ¯x if
∃δ > 0 : f (¯x + td) < f (¯x) ∀0 < t ≤δ
(4)
If f is continuously differentiable, then d is a descent direction at ¯x if and
only if ∇f (¯x)T d < 0.
A point x∗is a local minimum if at x∗there are no descent directions.
The following theorems provide ﬁrst and second order necessary optimality
conditions for a point x∗.
Theorem 1 Let f : IRn →IR be a continuously differentiable function and
let x∗∈IRn. If x∗is a local minimum then
∇f (x∗) = 0.
(5)
The above result can be easy proved by contradiction; in fact, if ∇f (x∗) ̸= 0,
then d = −∇f (x∗) is a descent direction. This observation is the basis of
the most used technique for function minimization: the gradient method.
Theorem 2 ([35, Proposition 2.5]) Let f : IRn →IR be twice continuously
differentiable and let x∗∈IRn. If x∗is a local minimum then

Nonlinear Optimization: A Brief Overview
43
Algorithm 1: Generic Minimization Algorithm
1 Choose x0 ∈IRn, Set k = 0;
2 if xk ∈ then Stop;
3 Compute a search direction dk ∈IRn;
4 Compute a stepsize αk > 0 along dk;
5 Set xk+1 = xk + αkdk, k = k + 1, return to 2;
∇f (x∗) = 0
(6)
∇2 f (x∗) is positive semideﬁnite.
(7)
The above conditions cannot exactly be reversed to obtain sufﬁciency
optimality conditions. In fact, positive deﬁniteness of the Hessian matrix is
required to obtain a strict local minimum.
Theorem 3 ([35, Proposition 2.6]) Let f : IRn →IR be twice continuously
differentiable and let x∗∈IRn. Suppose that:
∇f (x∗) = 0
(8)
∇2 f (x∗) is positive deﬁnite.
(9)
Then x∗is a strict local minimum.
Conditions for global optima are much more complex to obtain. How-
ever, if f : IRn →IR is a differentiable pseudo–convex function, then a local
minimum is also a global minimum [46, Theorem 9.3.7].
3.2
Algoritms for Unconstrained Optimization
A very general minimization algorithm is presented in Algorithm 1 where
 :=

x ∈IRn : ∇f (x) = 0

(10)
is the set of stationary points. The algorithm, starting from the initial point
x0, constructs either a ﬁnite sequence terminating in a stationary point or an
inﬁnite sequence which, under adequate conditions, converges to a stationary
point, or, has at least an accumulation point that is also a stationary point.
Given the current point xk and a search direction dk, the new point xk+1
is obtained by moving along dk with a stepsize αk.

44
R. De Leone
The following general theorem establishes conditions on the direction dk
and the stepsize αk ensuring that, in the case an inﬁnite sequence is obtained
by Algorithm 1, the sequence has at least one accumulation point and each
accumulation point is a stationary point. Before stating the theorem, it is
necessary to introduce the concept of forcing function.
Deﬁnition 9 ([50, Deﬁnition 14.2.1]) A function σ : IR+ →IR+ is a forcing
function if
∀sequence {tk} ⊆IR+
lim
k σ(tk) = 0
⎫
⎪⎬
⎪⎭
=⇒lim
k tk = 0.
Note that any non–decreasing function σ : IR+ →IR+ such that σ(0) = 0
and σ(t) > 0 when t > 0 is a forcing function. The functions
σ(t) = t,
σ(t) = ctq,
with
c > 0,
q > 0
are examples of forcing functions.
Theorem 4 Let {xk} be obtained by Algorithm 1 and assume that
(i) the level set
L0 :=

x ∈IRn : f (x) ≤f (x0)

is compact,
(ii) dk ̸= 0 when ∇f (xk) ̸= 0,
(iii) f (xk+1) ≤f (xk),
(iv) if ∇f (xk) ̸= 0 for all k then
lim
k
∇f (xk)T dk
dk
= 0,
(v) when dk ̸= 0
|∇f (xk)T dk|
dk
≥σ
∇f (xk)


for some forcing function σ.
Then, either the algorithm terminates after a ﬁnite number of iterations in
a stationary point or an inﬁnite sequence {xk} is generated that satisﬁes the
following properties:
(a) the sequence {xk} remains in L0 and has at least one accumulation point;
(b) each accumulation point of {xk} belongs to L0;

Nonlinear Optimization: A Brief Overview
45
(c) the sequence of real numbers

f (xk)

converges;
(d) lim
k
∇f (xk)
 = 0;
(e) each accumulation point x∗of the sequence {xk} is a stationary point.
With reference to Theorem 4,
• Conditions(iii)and(v)canbeguaranteedbychoosinganopportunedescent
direction dk and a line–search along this direction. In particular, using the
Euclidean norm and choosing σ(t) = ct (with c > 0), Condition (v) can
be written as
∇f (xk)
T dk ≤−c
dk
2
∇f (xk)

2 ,
that is, when xk is not a stationary point, a direction dk must be chosen
such that
∇f (xk)T dk
dk
2
∇f (xk)

2
≤−c.
Geometrically, the above condition requires that the cosine of the angle
between the direction dk and the direction −∇f (xk) (the “antigradient”)
must be greater than a constant independent of k. This implies that dk and
the gradient direction cannot be orthogonal as k goes to inﬁnity.
If σ(t) = ctq (with c > 0), Condition (v) becomes, instead,
∇f (xk)T dk
dk
≤−c
∇f (xk)

q
.
• Condition (iv) can be guaranteed using speciﬁc safeguard rules on the line–
search along the direction dk.
From the above considerations, it is clear the importance of inexact line–
search procedures for determining the stepsize αk.
A simple, but also very effective, line–search procedure is the Armijo
Backtracking method [4, 7, p. 29]. Given xk and a descent search direction
dk, the algorithm starts with a ﬁxed large value of α and decreases it (that is,
the new values of α is obtained by multiplying the current value of α by a
constant δ < 1) until the stopping criterion
f (xk + αdk) ≤f (xk) + γ α∇f (xk)
T dk
(11)
is satisﬁed, where γ ∈(0, 1
2). In other words, the Armijo procedures chooses
as αk the maximum value of α in the set
S =

α : α = δlαinit, l = 0, 1, . . .


46
R. De Leone
for which Condition (11) holds.
The following proposition demonstrates that, if the search direction dk
is opportunely chosen, and the stepsize is obtained according to the Armijo
rule, then conditions (iii) and (iv) in Theorem 4 are automatically satisﬁed.
Proposition 3 Let f : IRn →IR be continuously differentiable. Suppose
that:
(i) L0 is a compact set;
(ii) ∇f

xkT dk < 0. ∀k;
(iii) there exists a forcing function σ : IR+ →IR+ such that
dk ≥σ

|∇f

xkT dk|
dk

.
Then, if αk is chosen according to the Armijo procedure, and xk+1 = xk +
αkdk
(a) f

xk+1
< f

xk
;
(b) lim
k
|∇f

xkT dk|
dk
= 0.
A different line–search stopping criterion was proposed by Goldstein [31]
considering two lines
f (xk) + γ1α∇f (xk)T dk = 0,
f (xk) + γ2α∇f (xk)T dk = 0
where 0 < γ1 < γ2 < 1
2. The chosen stepsize αk > 0 must satisfy, instead of
(11), the following conditions:
f (xk + αkdk) ≤f (xk) + γ1αk∇f (xk)T dk,
(12a)
f (xk + αkdk) ≥f (xk) + γ2αk∇f (xk)T dk.
(12b)
From a geometrical point of view, this corresponds to choose a value for
αk for which f (xk + αkdk) is between the two straight lines with slopes
γ1∇f (xk)T dk and γ2∇f (xk)T dk, and passing through the point (0, f (xk)).
Moreover, let γ1 and γ2 such that 0 < γ1 < γ2 < 1. The step length αk
satisfy the Wolfe conditions [62] if the following conditions are satisﬁed:
f (xk + αkdk) ≤f (xk) + γ1αk∇f (xk)
T dk,
(13a)

Nonlinear Optimization: A Brief Overview
47
∇f (xk + αkdk)
T dk ≥γ2∇f (xk)
T dk.
(13b)
It is possible to show that, when dk is an opportune descent direction, then
using both the Goldstein and the Wolfe line–search methods, similar results
to those in Proposition 3 can be obtained.
Various other line–search procedures have been proposed in literature,
including line–search procedures that do not use information on the gradient
of the function [15, 44] and/or non–monotone line–search procedures [33,
34, 63] for which the monotonicity of the objective function for the generated
sequence is not required.
3.3
The Gradient Method
In the gradient method (also known as the steepest descent method) the search
direction is given by
dk = −∇f (xk).
(14)
For this choice of the search direction, both Condition (iii) and Condi-
tion (v) in Theorem 4 are trivially satisﬁed with σ(t) = t and, therefore, the
method is globally convergent when one of line–search procedures outlined
in the previous subsection is applied. However, the gradient method, even
when applied to the minimization of a strictly convex quadratic function
min
x
1
2xT Mx + qT x
(M ∈IRn×n positive deﬁnite, and q ∈IRn) and exact line–search is utilized,
exhibitslinearrateofconvergence.Thetheorembelowshowsthatthegradient
method has at least linear rate of convergence.
Theorem 5 ([45, Sect. 7.6, p. 218]) Let M ∈IRn×n be a symmetric positive
deﬁnite matrix and let 0 < λ1 ≤λ2 ≤. . . ≤λn be the eigenvalues of M, let
q ∈IRn and let f (x) := 1
2xT Mx + qT x. Let {xk} be obtained by the gradient
method with exact line–search:
xk+1 = xk −

Mxk + q
T 
Mxk + q


Mxk + q
T M

Mxk + q


Mxk + q

.
Then1
1 Here ∥x∥2
M := xT Mx.

48
R. De Leone
xk+1 −x∗
M ≤λn −λ1
λn + λ1
xk −x∗
M
(15a)
and
xk+1 −x∗
2 ≤
λn
λ1
 1
2 λn −λ1
λn + λ1
xk −x∗
2
(15b)
where x∗= −M−1q is the unique minimum point.
Moreover, it is not difﬁcult to construct an examples (see [8, Example
9.3.2, p. 469]) of quadratic problems where the inequalities (15) above are
satisﬁed as equality, demonstrating that, in fact, the gradient method has
linear rate of convergence.
3.4
The Newton’s Method
As stated before the gradient method exhibits a slow rate ofconvergence.Here
we consider a method that, instead, has quadratic rate of convergence at the
expenses of a higher cost per iteration, requiring, in addition to calculate the
gradient at each point, also the calculation of the Hessian function. Moreover,
only local convergence can be established, that is convergence is guaranteed
only if the initial point x0 is chosen sufﬁciently close to the stationary point
x∗.
Let f : IRn →IR be twice continuously differentiable. From Taylor’s
series expansion we have that
f (x + s) = f (x) + ∇f (x)T s + 1
2sT ∇2 f (x)s + β(x, s)
where
lim
s→0
β(x, s)
∥s∥2
= 0.
In Newton’s method, at each iteration a quadratic approximation of the func-
tion f around the current point xk is constructed:
qk(s) := f (xk) + ∇f (xk)
T s + 1
2sT ∇2 f (xk)s,
and the new point xk+1 is obtained as xk+1 = xk + sk where
sk ∈argmin
s
qk(s).

Nonlinear Optimization: A Brief Overview
49
The following theorem provides conditions for local convergence of the
Newton’s method for minimization problems.
Theorem 6 ([25, Theorem 3.1.1] [35, Proposizione 7.2]) Let f : IRn →IR
be a twice continuously differentiable function, and assume that
(a) there exists x∗∈IRn: ∇f (x∗) = 0,
(b) ∇2 f (x∗) is non singular,
(c) ∇2 f (x) is a Lipschitz–continuous function, i.e.,
∃L > 0 : ∀x, y ∈IRn
∇2 f (x) −∇2 f (y)
 ≤L ∥x −y∥.
Then, there exists B(x∗, ρ) := {x ∈IRn : ∥x −x∗∥≤ρ} with ρ > 0 such
that, if x0 ∈B(x∗, ρ),
(i) the Newton’s iterate is well deﬁned,
(ii) the sequence

xk
remains in B(x∗, ρ),
(iii) the sequence

xk
converges to x∗with at least a quadratic rate of
convergence
xk+1 −x∗ ≤α
xk −x∗
2
, for some α > 0.
3.5
The Conjugate Gradient Method
The slow convergence of the gradient method and the heavy requirements of
the fast converging Newton’s method where, at each iteration, it is necessary
to calculate the Hessian matrix, set the stage for new classes of methods that
only require to compute the gradient of the function to minimize, and, at the
same time, exhibit q–superlinear rate of convergence [50]. In this section the
important class of conjugate gradient methods is introduced, while the next
section is devoted to Quasi-Newton’s methods.
Deﬁnition 10 Let M ∈IRn×n be a symmetric positive deﬁne matrix. The n
nonzero vectors d0, d1, . . . , dn−1 in IRn are conjugate directions with respect
to the matrix M if
di T Md j = 0
∀i, j = 0, 1, . . . , n −1, i ̸= j.
(16)
Consider the quadratic function
f (x) = 1
2xT Mx + qT x
(17)

50
R. De Leone
Algorithm 2: Generic Conjugate Direction Method for Quadratic Prob-
lems
1 Choose x0 ∈IRn;
2 Choose d0, d1, . . . , dn−1 nonzero conjugate directions with respect to M;
3 for k=0 to n-1 do
4
Set αk = −(Mxk + q)T dk
dk T Mdk
;
5
Set xk+1 = xk + αkdk
6 end
where M is a symmetric positive matrix, M ∈IRn×n and q ∈IRn; the follow-
ing algorithm utilizes n conjugate directions to determine the unique point
minimizing f (x).
One important result for this algorithm is that for quadratic strictly convex
problems, when conjugate directions are utilized as search directions, then
convergence is achieved in a ﬁnite number of iterations.
Theorem 7 Consider the quadratic function f (x) = 1
2xT Mx + qT x where
M is a symmetric positive matrix, M ∈IRn×n and q ∈IRn. Starting from any
x0 ∈IRn apply Algorithm 2. Then xk+1 is the minimizer of f (x) over the
afﬁne set
Sk :=
⎧
⎨
⎩x ∈IRn : x = x0 +
k

j=0
λ jd j, λ j ∈IR
⎫
⎬
⎭
for k = 0, 1, . . . , n −1. Moreover, xn = −M−1q is the unique minimizers
of f (x) over IRn.
The above Algorithm 2 allows different choices for the set of conjugate
directions. A interesting choice is to link these conjugate directions to the
gradient of the function f (x). Algorithm 3 explores this possibility.
Theorem 8 ([25, Theorem 4.1.1]) Consider the quadratic function f (x) =
1
2xT Mx
+ qT x where M ∈IRn×n is a symmetric positive matrix, and q ∈IRn. The
Conjugate Gradient Algorithm 3 terminates after m < n iterations and for
all i = 0, . . . , m
di T Md j = 0,
j = 0, . . . , i −1,
(18a)

Nonlinear Optimization: A Brief Overview
51
Algorithm 3: Conjugate Gradient Algorithm
1 Choose x0 ∈IRn, Set k = 0;
2 while xk /∈ do
3
if k = 0
then
4
Set dk = −∇f (xk);
5
else
6
Set βk−1 = ∇f (xk)T Mdk−1
dk−1T Mdk−1 ;
7
Set dk = −∇f (xk) + βk−1dk−1;
8
end
9
Set αk = −∇f (xk)T dk
dk T Mdk
;
10
Set xk+1 = xk + αkdk;
11
Set k = k + 1;
12 end
∇f (xi)
T ∇f (x j) = 0,
j = 0, . . . , i −1,
(18b)
∇f (xi)
T di = −∇f (xi)
T ∇f (xi).
(18c)
The theorem above shows that the directions generated by Algorithm 3
are conjugate directions with respect to the matrix M, and, therefore, ﬁnite
termination of algorithm follows from Theorem 7.
It is important to note that
αk = −∇f (xk)T dk
1
dkT Mdk
= ∇f (xk)T ∇f (xk)
dkT Mdk
> 0.
(19)
Moreover, from xk = xk−1 + αk−1dk−1 it follows that
αk−1Mdk−1 = Mxk −Mxk−1 = ∇f (xk) −∇f (xk−1)
and hence
∇f (xk)
T Mdk−1 =
1
αk−1
∇f (xk)
T 
∇f (xk) −∇f (xk−1
=
1
αk−1
∇f (xk)
T ∇f (xk).
Now, from (19), αk−1dk−1T Mdk−1 = ∇f (xk−1)T ∇f (xk−1), and hence

52
R. De Leone
βk−1 = ∇f (xk)T Mdk−1
dk−1T Mdk−1
=
1
αk−1
∇f (xk)T ∇f (xk)
dk−1T Mdk−1
=
∇f (xk)T ∇f (xk)
∇f (xk−1)T ∇f (xk−1)
=: βFR
k−1
(20)
This formula was ﬁrst proposed by Fletcher and Reeves [27]. Alternative
choices, all equivalent in the case of strictly convex quadratic problems, for
βk−1 are
βPRP
k−1 =
∇f (xk)T 
∇f (xk) −∇f (xk−1)

∇f (xk−1)T ∇f (xk−1)
.
(21a)
βHS
k−1 = −
∇f (xk)T 
∇f (xk) −∇f (xk−1)

dk−1T 
∇f (xk) −∇f (xk−1)

(21b)
proposed, respectively, by Polak and Ribiére [52] and Polyak [53] and
Hestenes and Stiefel [39].
For general non–quadratic functions, there is no guarantee that the conju-
gate gradient method will terminate in a ﬁnite number of steps. Moreover, it
is extremely difﬁcult to exactly solve the one–dimensional subproblem and
inexact line–search methods such as Armijo or Goldstein or Wolfe methods
must be utilized. Moreover, each n iterations or when a non–descent direction
is generated, a reset step should be performed using as search direction the
negative gradient direction. Computational results, however, show that the
use of a restarting procedure is not convenient and is better to opportunely
modify the formula for βk−1 and to choose speciﬁc line-search procedure to
globalize the overall scheme.
The ﬁrst global convergence result of the Fletcher-Reeves method with
inexact line search was given by Al-Baali [2]. Under strong Wolfe conditions,
he demonstrated that the method generates sufﬁcient descent directions and,
therefore, global convergence can be established.
For the Polak-Ribiére-Polyak method the convergence for general non-
linear function is uncertain. While global convergence can be proved in the
case of strongly convex functions, there are examples of not strongly convex
functions, for which the method may not converge, even with an exact line
search. Instead, convergence can be proved when
βPRP+
k−1
= min{βPRP
k−1, 0}

Nonlinear Optimization: A Brief Overview
53
is utilized [29]. Additional information on conjugate gradient method for
general nonlinear functions can be found in [35, 38, 54].
3.6
Quasi-Newton’s Methods
As already noted earlier, the Newton’s method is locally convergent at
quadratic rate and requires, at each iteration, to compute the Hessian function.
On the other hand, the gradient method for which global convergence can be
established, only requires to compute the gradient of the function; however,
its convergence can be quite slow (at most linear, in some cases).
The aim of Quasi-Newton’s methods is to deﬁne procedures that
• will not require to compute the Hessian function,
• exhibits q–superlinear rate of convergence.
Two classes of Quasi–Newton methods have been studied in literature:
• direct methods for which
⎧
⎨
⎩
xk+1 = xk −

Bk−1 ∇f (xk),
Bk+1 = Bk + Bk,
Bk+1 ≈∇2 f (xk+1);
• inverse methods where
⎧
⎨
⎩
xk+1 = xk −Hk∇f (xk),
Hk+1 = Hk + Hk,
Hk+1 ≈

∇2 f (xk+1)
−1 .
In order to derive updating formulas for Bk and Hk, consider again the
quadratic function
f (x) = 1
2xT Mx + qT x
where M ∈IRn×n is a symmetric positive matrix, andq ∈IRn. Let now x, y ∈
IRn, then
∇f (y) = ∇f (x) + M(y −x)
or equivalently
M−1 (∇f (y) −∇f (x)) = y −x.
Therefore, since Bk+1 (resp. Hk+1) must be an approximation of M (resp.
M−1), it is reasonable to require that

54
R. De Leone
Algorithm 4: Generic (Direct) Quasi–Newton Method
1 Choose x0 ∈IRn, Choose B0 ∈IRn×n, Set k = 0;
2 while xk /∈ do
3
Set dk = −

Bk−1 ∇f (xk);
4
Compute αk using a line–search procedure;
5
Set xk+1 = xk + αkdk;
6
Compute Bk+1 = Bk + Bk Set k = k + 1;
7 end
∇f (xk+1) −∇f (xk) = Bk+1 
xk+1 −xk
(22a)
or
Hk+1 
∇f (xk+1) −∇f (xk)

= xk+1 −xk.
(22b)
After deﬁning γ k := ∇f (xk+1) −∇f (xk) and δk := xk+1 −xk the above
conditions become
γ k = Bk+1δk
(23a)
and
Hk+1γ k = δk.
(23b)
These conditions are known as “secant conditions”. Furthermore, it is
reasonable to require that Bk+1 (resp. Hk+1) be symmetric and as close as
possible to Bk (resp. Hk) imposing that Bk+1 (resp. Hk+1)) differs from
Bk (resp. Hk by a matrix of rank 1 or 2 and a minimality condition in some
norm, for example in Frobenius norm2[18]. The generic direct Quasi–Newton
method is reported in Algorithm 4.
A similar algorithm can be easily constructed for a Quasi–Newton generic
inverse method.
2 For a matrix A ∈IRm×n, the Frobenius norm ∥A∥F of A is deﬁned as [48]
∥A∥F :=
 
!
!
"
m

i=1
n

j=1
A2
i j =
 
!
!
"
m

i=1
∥Ai.∥2
2 =
 
!
!
"
n

j=1
A. j
2
2
=
#
trace

AT A

=
#
trace

AAT 
.

Nonlinear Optimization: A Brief Overview
55
In the sequel, unless strictly necessary we will drop the superscripts k and
k + 1; the current matrix will be indicated simply by B (resp. H) while the
updated matrix will be indicated by ¯B (resp. ¯H). A similar rule will be used
for γ k and δk.
The simplest updating direct formula for B is a rank-1 updating formula
¯B = B + ρuvT
(24)
where ρ ∈IR and u, v ∈IRn, u, v ̸= 0.
For the symmetric case (i.e., u = v), we have
¯B = B + ρuuT
(25)
and, imposing the secant condition ¯Bδ = γ either ¯B = B (which happens if
already Bδ = γ )or,underthehypothesisthat(γ −Bδ)T δ ̸= 0,thefollowing
formula, known as Symmetric Rank-1 updating formula (SR1), is obtained
¯B = B + (γ −Bδ) (γ −Bδ)T
(γ −Bδ)T δ
.
(26)
This formula was ﬁrst proposed by Davidon [14] and later rediscovered by
Broyden [10].
Using H = B−1 and the Sherman–Morrison–Woodbury [32, 37] formula,
it is possible to derive the inverse Symmetric Rank–1 updating scheme:
¯H = H + (δ −Hγ )(δ −Hγ )T
(δ −Hγ )T γ
.
(27)
Note that in this case the secant condition completely determines the updat-
ingformulaunderthehypothesisthat(γ −Bδ)T δ ̸= 0 (resp.(Hγ −δ)T γ ̸=
0). However, it must be noticed that there is no guarantee that the search direc-
tion that is obtained is a descent direction.
The symmetric rank–1 updating formula (27) has a very interesting
behaviour when applied to a quadratic function.
Theorem 9 ([17, Theorem 7.1]) Let A ∈IRn×n be symmetric and non-
singular. Let {s0, s1, . . . , sm} be m vectors spanning IRn and let yk =
Ask, k = 0, . . . , m. Again, let H0 be a symmetric n × n real matrix and
for k = 0, . . . , m let
Hk+1 = Hk +

sk −Hk yk
sk −Hk ykT

sk −Hk ykT yk

56
R. De Leone
assuming that

sk −Hk ykT yk ̸= 0. Then
Hm+1 = A−1.
The theorem above shows that, given a nonsingular matrix A, the inverse
A−1 can be calculated using the SR1 formula which only involves matrix–
vector multiplications
For general nonlinear functions, under speciﬁc assumptions, including that
$$$$

γ k −BkδkT
δk
$$$$ ≥c
γ k −Bkδk
2
δk
2
and that the sequence {xk} has at least one accumulation point x∗, then [13,
Theorem 2]
lim
k
Bk −∇2 f (x∗)
 = 0.
In the non–symmetric case (mostly utilized for solving system of nonlinear
equations) the updating formula require to choose both vectors u and v and
the secant condition does not deﬁne uniquely both vectors. Therefore, the
new matrix ¯B is required to be as close as possible to the current matrix B.
The following lemma shows that a rank-1 updating formula is obtained when
the closest matrix (in Frobenius norm) to the current matrix B is calculated
among all matrices for which the secant condition is satisﬁed.
Theorem 10 ([17, Theorem 4.1], [18, Lemma 8.1.1]) Let B ∈IRn×n and let
γ, δ ∈IRn. Then, the solution of the minimization problem
min
A
∥A −B∥F
∗subject to γ = Aδ
(28)
is given by
¯B = B + (γ −Bδ) δT
δT δ
.
(29)
Using again the Sherman–Morrison–Woodbury formula, it possible (under
the hypothesis that γ T Hδ ̸= 0) to derive the inverse updating formula:
¯H = H + (δ −Hγ ) δT H
δT Hγ
(30)
The updating formula (30) was ﬁrst proposed by Broyden [9] in the con-
text of solving systems of nonlinear equations. Locally q–superlinear con-

Nonlinear Optimization: A Brief Overview
57
vergence for this method was then proved by Broyden, Dennis and Morè in
[12], see also [19, Theorem 3.3.3] and [19, Theorem 8.2.2].
The generic rank–2 updating formula is given by
¯B = B + auuT + bvvT
where a, b ∈IR and u, v ∈IRn; similar rank–2 updating formulas can be
deﬁned for ¯H.
The use of a rank–2 updating formula allows to imposes important con-
ditions, in addition to the secant property, on the updated matrix such as
symmetry and positive deﬁniteness. Theorem 11 show that the closest matrix
to B for which symmetry and secant condition are satisﬁed can be obtained
via a rank–2 modiﬁcation. Here a weighted Frobenius norm is utilized, where
W is the weight matrix:
∥A −B∥W,F := ∥W(A −B)W∥F .
Theorem 11 ([17, Theorem 7.3]) Let B ∈IRn×n be a symmetric matrix and
let c, δ, γ ∈IRn with cT δ > 0. Let W ∈Rn×n be a symmetric nonsingular
matrix such that Wc = W −1δ. Then, the unique solution of
min
A
∥A −B∥W,F
∗subject to
Aδ = γ
A symmetric
(31)
is given by
¯B = B + (γ −Bδ) cT + c (γ −Bδ)T
cT δ
−(γ −Bδ)T δ

cT δ
2
ccT .
(32)
The above theorem leaves space for opportune choices of the matrix W
and the vector c, which can be utilized to impose positive deﬁniteness of the
updating formula, i.e., conditions that ensure that the matrix ¯B be positive
deﬁnite, provided that the same property holds for B. Positive deﬁniteness of
the matrix ¯B ensures that the search direction utilized in the Quasi–Newton
method (see Algorithm 4) is a descent direction.
In view of the fact that ¯Bδ = γ , if ¯B is positive deﬁnite then 0 < δT ¯Bδ =
δT γ . It is not difﬁcult to show that this condition is also necessary for the
positive deﬁniteness of ¯B [17, Theorem 7.5].

58
R. De Leone
A simple, but extremely interesting, choice for the vector c is c = γ . This
speciﬁc choice leads to the updating formula
¯B = B + (γ −Bδ) γ T + γ (γ −Bδ)T
γ T δ
−(γ −Bδ)T δ

γ T δ
2
γ γ T .
(33)
Again, using the Sherman–Morrison–Woodbury formula, it is possible to
compute the corresponding inverse updating formula (here H = B−1 and
¯H = ¯B−1)
¯H = H + δδT
γ T δ −Hγ γ T H
γ T Hγ .
(34)
These formulas, known as direct and inverse DFP formulas, were ﬁrstly
proposed by Davidon [14] and later rediscovered by Fletcher and Powell that
also clariﬁed and improved them [26].
Moreover, it is also possible to construct updating formulas directly for H
similarly requiring that ¯H be symmetric, that the secant condition be satisﬁed
and ¯H be as close as possible to H in a speciﬁc norm as shown in the theorem
below, in a similar way as done for the direct updating formula.
Theorem 12 Let H ∈IRn×n be a symmetric matrix and let d, δ, γ ∈IRn
with dT γ > 0. Let W ∈Rn×n be a symmetric nonsingular matrix such that
Wd = W −1γ . Then, the unique solution of
min
A
∥W(A −H)W∥F
∗subject to
Aγ = δ
A symmetric
(35)
is given by
¯H = H + (δ −Hγ ) dT + d (δ −Hγ )T
dT γ
−(δ −Hγ )T γ

dT γ
2
ddT .
(36)
Similarly to what done in the direct case, it is possible to impose that the
new matrix ¯H be positive deﬁnite. Moreover, the choice d = δ brings to the
following updating formula
¯H = H + (δ −Hγ ) δT + δ (δ −Hγ )T
δT γ
−(δ −Hγ )T γ

δT γ
2
δδT .
(37)
UsingtheSherman–Morrison–Woodburyformulathecorrespondingdirect
updating formula can be obtained

Nonlinear Optimization: A Brief Overview
59
Algorithm 5: Quasi–Newton method (Broyden class updating scheme)
1 Choose x0 ∈IRn, Choose H0 ∈IRn×n, Set k = 0;
2 while xk /∈ do
3
Set dk = −Hk∇f (xk);
4
Compute αk using a line–search procedure;
5
Set xk+1 = xk + αkdk;
6
Set δ = xk+1 −xk, γ = ∇f (xk+1) −∇f (xk),
v =

γ T Hkγ
 1
2
 δ
γ T δ −
Hkγ
γ T Hkγ

;
7
Choose φk ≥0 ;
8
Compute Hk+1 = Hk + δδT
γ T δ −Hkγ γ T Hk
γ T Hkγ
+ φkvv
T ;
9
Set k = k + 1;
10 end
¯B = B + γ γ T
δT γ −BδδT B
δT Bδ .
(38)
The above formulas are known as (inverse and direct) BFGS updating
formulas from Broyden [11], Fletcher [24], Goldfarb [30] and Shanno [57]
that discovered them.
Starting from the DFP and BFGS updating formulas a whole class (known
as Broyden class) of updating methods can be constructed:
¯Hφ = (1 −φ) ¯HDFP + φ ¯HBFGS
where ¯HDFP and ¯HBFGS are given by (34) and (37) respectively, and φ ∈IR.
Note that ¯Hφ can be easily rewritten as
¯Hφ = ¯HDFP + φvvT
where
v =

γ T Hγ
 1
2
 δ
γ T δ −
Hγ
γ T Hγ

clearly showing the relationship between ¯Hφ and ¯HDFP.
The generic Quasi–Newton algorithm using the Broyden updating scheme
is reported in Algorithm 5 (here we return to use again the index k).
For quadratic strictly convex problems

60
R. De Leone
min f (x) := 1
2xT Mx + qT x
where M ∈IRn×n is a positive deﬁnite matrix and q ∈IRn, ﬁnite termina-
tion is guaranteed when φk ≥0 and αk is obtained via exact line–search
[17, Theorem 8.1], [59, Theorem 5.2.1]. Finite termination follows from the
observation that for all k = 0, . . . , n

xk+1 −xkT
M

xi+1 −xi
= 0,
∀i < k
i.e., the directions δ0 = x1 −x0, δ1 = x2 −x1, . . . , δk=xk+1 −xk are M-
conjugate and xk+1 minimizes f (x) in the afﬁne space the afﬁne set
Sk :=
⎧
⎨
⎩x ∈IRn : x = x0 +
k

j=0
σ jδ j, σ j ∈IR
⎫
⎬
⎭
The following theorem, originally due to Powell, shows global conver-
gence for rank–2 symmetric updating schemes for generic convex optimiza-
tion problems.
Theorem 13 ([17, Theorem 8.2]) Let f : IRn →IR be twice differentiable
and convex. Let x0 ∈IRn and assume the level set L0 be bounded. Let H0
be symmetric and positive deﬁnite and let {xk} be generated by Algorithm 5
with either
• φk = 0 (DFP updating formula) and exact line–search, or
• φk = 1 (BFGS updating formula) and inexact line–search satisfying the
Wolfe condition.
Then, for any ϵ > 0 there exists k such that
∇f (xk)
 < ϵ.
Dixon [22] demonstrated that in case of exact line–search, the sequence {xk}
is independent of φk ≥0. Furthermore, in [24], it is shown that, for stability
reasons, it is better to choose φk ∈[0, 1]. However, from a computational
point of view the choice φk = 1 appears better than φk = 0.
Finally,q–superlinearconvergenceofrank–2updatingmethodsisobtained
in the case φk = 0 or φk = 1 [17, Theorem 8.9] if the stepsize αk is chosen
according to the Wolfe rule (in which case it is possible to show that αk = 1
for k ≥k0) provided that
+∞

k=1
xk −x∗ < +∞.
We refer the interested reader to [35, 59] for additional insight on Quasi–
Newton methods.

Nonlinear Optimization: A Brief Overview
61
4
Constrained Optimization
In this section we concentrate our attention on the constrained optimization
problem
min
x
f (x)
∗subject to ci(x) ≤0
i = 1, . . . , m
ci(x) = 0
i = m + 1, . . . , m + h
(39)
where f : IRn →IR istheobjectivefunctionandci : IRn →IR, i = 1, . . . , m + h
are the constraints deﬁning the feasible region X
X :=

x ∈IRn : ci(x) ≤0, i = 1, . . . , m and ci(x) = 0, i = m + 1, . . . , m + h

.
For simplicity, we will always assume that all the functions are at least twice
continuously differentiable.
Deﬁnition 11 A feasible point ¯x is a local minimum if ∃γ > 0 such that
f (¯x) ≤f (x) ∀x ∈X and ∥x −¯x∥≤γ.
More generally, a point ¯x is a local minimum if ∃I neighborhood of ¯x such
that
f (¯x) ≤f (x) ∀x ∈X ∩I.
A point ¯x is a strict local minimum if ∃I neighborhood of ¯x such that
f (¯x) < f (x) ∀x ∈X ∩I, x ̸= ¯x.
A point ¯x is a strong or isolated local minimum if ∃I neighborhood of ¯x
such that ¯x is the only local minimum in X ∩I.
For the above minimization problem, the Lagrangian function is deﬁned
as follows:
L(x, λ) := f (x) +
m+h

i=1
λici(x)
(40)
where λ ∈IRm+h. First and second order necessary and sufﬁcient optimality
conditions will be expressed in terms of the above Lagrangian function.
Another important concept in constrained optimization is the concept of
active constraints.
Deﬁnition 12 Let ¯x be a feasible point for the constrained optimization prob-
lem (39), i.e., , ¯x ∈X. The set of active constraints at ¯x is

62
R. De Leone
A (¯x) :=

i : 1 ≤i ≤m : ci(¯x) = 0

∪

m + 1, . . . , m + h

.
4.1
Necessary and Sufﬁcient Optimality Conditions
In order to derive optimality conditions for the constrained optimization prob-
lem (39), two sets must be introduced: the tangent cone and the set of lin-
earized feasible directions.
Deﬁnition 13 Let ¯x ∈X. A direction d ∈IRn is tangent to the set X at ¯x if
there exists a sequence

zk
⊆X with limk zk = ¯x and a sequence {θk} of
positive scalars with limk θk = 0 such that
lim
k
zk −¯x
θk
= d.
(41)
The set of all tangent vectors to X at ¯x is called the tangent cone at ¯x and
is denoted by TX (¯x).
Deﬁnition 14 Let ¯x ∈X and let A (¯x) be the set of indices of active con-
straints. The set of linearized feasible directions F (¯x) is the set
F (¯x) :=
d ∈IRn : ∇ci(¯x)T d ≤0,
i = 1, . . . , m, i ∈A (¯x) ,
∇ci(¯x)T d = 0,
i = m + 1, . . . , m + h

.
Clearly, if d ∈F (¯x) also αd ∈F (¯x) for all nonnegative α and hence also
the set F (¯x) is a cone.
These two sets can be viewed as local approximations of the feasible region
X around ¯x.
Note that, while the tangent cone only depends on the geometry of the
feasibleregion,thesetoflinearizedfeasibledirectionsdependsonthespeciﬁc
formulation of the constraints utilized to deﬁne the feasible region. Moreover,
for all ¯x ∈X, TX (¯x) ⊆F (¯x).
A fundamental question is under which conditions the two sets coincide,
that is TX (¯x) = F (¯x) or, to be more precise, under which conditions the
dual cones of the two sets coincide.3 Since the seminal work of Kuhn and
Tucker [42], a number of different (inter–related) Constraint Qualiﬁcation
3 Give a cone K, the dual cone of K is the set
K ∗:=

d ∈IRn : dT x ≥0, ∀x ∈K


Nonlinear Optimization: A Brief Overview
63
conditions have been proposed in literature both forthe case ofonly inequality
constraints and for the more general case of equality of inequality constraints
(see [60] and references therein, including the two schemes showing the
relationships between the different Constraint Qualiﬁcation conditions, and
[46]).
In [60] the various Constraint Qualiﬁcation conditions are partitioned in
4 different levels with weakest (less stringent) conditions being at level 1
and strongest (more stingent) conditions at level 4. In the following, we state
some of the most common Constraint Qualiﬁcation conditions.
Deﬁnition 15 (Guignard’s Constraint Qualiﬁcation, GCQ) [36] Let ¯x ∈X.
The Guignard’s Constraint Qualiﬁcation conditions are satisﬁed at ¯x if
F (¯x) = cl
(conv (TX (¯x))).4
The GCQ is considered the weakest possible Constraint Qualiﬁcation.
Deﬁnition 16 (Abadie’s Constraint Qualiﬁcation, ACQ) [1] Let ¯x ∈X. The
Abadie’s Constraint Qualiﬁcation conditions are satisﬁed at ¯x if TX (¯x) =
F (¯x).
The Abadie’s Constraint Qualiﬁcation requires that TX (¯x) be a convex
cone. Hence this condition is stronger than Guignard’s Constraint Qualiﬁca-
tion.
Deﬁnition 17 (Slater’s Constraint Qualiﬁcation, SCQ) [58] Let ¯x ∈X. The
Slater’s Constraint Qualiﬁcation conditions are satisﬁed at ¯x if
• ci(x) is pseudo–convex at ¯x for all 1 ≤i ≤m and i ∈A (¯x),
• ci(x) is both quasi–convex and quasi–concave5 at ¯x for all m + 1 ≤i ≤
m + h,
• the vectors

∇ci (¯x) ,
m + 1 ≤i ≤m + h

are linearly independent,
• there exists ˆx such that ci

ˆx

< 0, for all 1 ≤i ≤m and i ∈A (¯x) and
ci

ˆx

= 0 for all m + 1 ≤i ≤m + h.
Deﬁnition 18 (Mangasarian–Fromovitz’sConstraintQualiﬁcation,MFCQ)
[47, 3.4–3.6] Let ¯x ∈X. The Mangasarian–Fromovitz’s Constraint Qualiﬁ-
cation conditions are satisﬁed at ¯x if
• the vectors

∇ci (¯x) ,
m + 1 ≤i ≤m + h

are linearly independent,
• there exists d such that ∇ci (¯x)T d < 0, for all 1 ≤i ≤m and i ∈A (¯x)
and ∇ci (¯x)T d = 0 for all m + 1 ≤i ≤m + h.
4 For a set S, cl (S) indicates its closure.
5 A generic function g is quasi–concave if and only if −g is quasi–convex.

64
R. De Leone
Deﬁnition 19 (Linear Independence Constraint Qualiﬁcation, LICQ) [60,
5.4.6] Let ¯x ∈X. Linear Independence Constraint Qualiﬁcation (LICQ) con-
ditions are satisﬁed at ¯x if the vectors

∇ci (¯x) , 1 ≤i ≤m,
i ∈A (¯x)

∪

∇ci (¯x) , m + 1 ≤i ≤m + h

are linearly independent.
Both LICQ and SCQ imply MFCQ. Moreover, MFCQ implies ACQ.
Therefore, if any of these Constraint Qualiﬁcation conditions hold at a fea-
sible point ¯x, then TX (¯x) = F (¯x).
The following lemma provides necessary conditions for a local optimal
solution.
Lemma 1 Let x∗be a local optimal solution of Problem (39). Then
∇f (x∗)T d ≥0
∀d ∈TX

x∗
(42)
Proof Suppose, by contradiction, that at x∗there is a direction d ∈TX (x∗)
such that
∇f (x∗)T d < 0.
Then, there exists a sequence

dk
converging to d and a sequence {θk}
of positive scalars converging to zero with zk = x∗+ θkdk ∈X for all k.
Therefore,
f (zk) = f (x∗+ θkdk) = f (x∗) + ∇f (x∗)T 
zk −x∗
+ o
zk −x∗

= f (x∗) + θk∇f (x∗)T dk + o(θk).
But
lim
k ∇f (x∗)T dk = ∇f (x∗)T d < 0,
and hence
f (zk) −f (x∗) = θk∇f (x∗)T dk + o(θk) < 0
for k sufﬁciently large. Therefore, for each neighborhood of x∗, there exists a
sufﬁciently large index k such that the point zk belongs to such neighborhood
and, hence, x∗is not a local minimum.
In case that Constraint Qualiﬁcation conditions are satisﬁed, the necessary
optimality conditions can be expressed in a more convenient way, in terms of
the Karush–Kuhn–Tucker conditions. This results utilizes Motzkin’s theorem
of the alternative, see [46, Chap. 2].

Nonlinear Optimization: A Brief Overview
65
Theorem 14 ([46, 7.3.7][49, Theorem 12.1]) Let x∗be a local minimum for
the constrained optimization Problem (39) and assume that at x∗some Con-
straint Qualiﬁcation conditions are satisﬁed. Then there exists a Lagrange
multiplier vector λ∗such that the following conditions, known as Karush–
Kuhn–Tucker (or KKT) conditions, hold:
∇x L(x∗, λ∗) = 0,
(43a)
ci(x∗) ≤0 ∀i = 1, . . . , m,
(43b)
ci(x∗) = 0 ∀i = m + 1, . . . , m + h,
(43c)
λ∗
i ≥0 ∀i = 1, . . . , m,
(43d)
λ∗
i ci(x∗) = 0 ∀i = 1, . . . , m,
(43e)
where L(., .) is the Lagrangian function (40).
Note that Condition 43a can be rewritten as
∇f (x∗) +
m+h

i=1
λ∗
i ∇ci(x∗) = 0.
Conditions (43e) are called complementarity conditions and they impose
that for all i = 1, . . . , m either λ∗
i = 0 or ci(x∗) = 0 or both.
In order to derive second order necessary and sufﬁcient conditions, we
need to introduce ﬁrst the concept of critical cone.
Deﬁnition 20 Let x∗be a local minimum for the constrained optimization
Problem (39) and suppose that the pair (x∗, λ∗) satisﬁes the Karush–Kuhn–
Tucker conditions (43) for some λ∗∈IRm+h. The Critical Cone is deﬁned
as:
C (x∗, λ∗) :=

d ∈F (x∗) : ∇ci(x∗)T d = 0,
for all i = 1, . . . , m, i ∈A (¯x) with λ∗
i > 0

.
(44)
Equivalently, d ∈C (x∗, λ∗) if only if
∇ci(x∗)T d = 0 i = 1, . . . , m, i ∈A (¯x) with λ∗
i > 0
(45a)
∇ci(x∗)T d ≤0 i = 1, . . . , m, i ∈A (¯x) with λ∗
i = 0
(45b)
∇ci(x∗)T d = 0 i = m + 1, . . . , m + h
(45c)
Note that the Hessian of the Lagrangian function L (x, λ) is given by

66
R. De Leone
∇2
xx L (x, λ) = ∇2 f (x) +
m+h

i=1
λi∇2ci(x).
This Hessian is of fundamental importance in the second order necessary and
sufﬁcient conditions.
Theorem 15 ([25, Theorem 9.3.1] [49, Theorem 12.5]) Let x∗be a local
minimum for the constrained optimization Problem (39) and assume that
at x∗some Constrained Qualiﬁcation Conditions are satisﬁed. Then, there
exists a Lagrange multiplier vector λ∗such that the Karush–Kuhn–Tucker
conditions (43) are satisﬁed and
dT ∇2
xx L

x∗, λ∗
d ≥0, for all d ∈C

x∗, λ∗
.
(46)
Theorem 16 ([25, Theorem 9.3.2] [49, Theorem 12.6]) Let x∗be a feasible
point for the constrained optimization Problem (39) and assume that there
exists a vector λ∗such that the pait (x∗, λ∗) satiﬁes the Karush–Kuhn–Tucker
conditions (43). Furthermore, suppose that
dT ∇2
xx L

x∗, λ∗
d > 0, for all 0 ̸= d ∈C

x∗, λ∗
.
(47)
Then, x∗is a strict local minimum of the constrained optimization Problem
(39)
As for the unconstrained case, also here there is a signiﬁcative difference
between necessary and sufﬁcient optimality conditions. In fact, for neces-
sary optimality condition the Hessian of the Lagrangian must be positive
semideﬁnite in the Critical Cone. Instead, for sufﬁcient optimality condition,
the Hessian of the Lagrangian must be positive deﬁnite in the same Critical
Cone.
4.2
Duality in Constrained Optimization
The concept of duality is central in constrained optimization as well as in
other ﬁelds of Operations Research (e.g., in Linear programming) and, in
general, in mathematics. Let
f ∗= inf
x∈X f (x).
(48)
The dual function is given by

Nonlinear Optimization: A Brief Overview
67
q(λ) := inf
x L(x, λ)
(49)
where L(x, λ) is the Lagrangian function (40). Note that this dual function
is a concave function (i.e., −q(λ) is a convex function) and its domain D is
a convex set. The dual problem is deﬁned as
max
λ
q(λ)
subject to λi ≥0,
i = 1, . . . , m.
(50)
Moreover, let
q∗= sup
λ
q(λ)
λi ≥0, i = 1, . . . , m.
.
(51)
It is not difﬁcult to show that (Weak Duality), if ¯λ ∈IRm+h with ¯λi ≥0,
i = 1, . . . , m (that is, ¯λ is dual feasible), and ¯x ∈X (that is, ¯x is primal
feasible), then
q(¯λ) = inf
x L(x, ¯λ) ≤L(¯x, ¯λ) = f (¯x) +
m+h

i=1
¯λici(¯x)
= f (¯x) +
m

i=1
¯λici(¯x) ≤f (¯x)
and hence
q∗≤f ∗.
(52)
A more convenient form for the dual problem can be derived for convex
problems. The theorem below shows the relationship between points sat-
isfying Karush–Kuhn–Tucker conditions and optimal solutions of the dual
problem. Moreover, it shows that in convex optimization there is no duality
gap.
Theorem 17 ([49, Theorem 12.12]) Let x∗be an optimal solution of the con-
vex optimization problem (39) where f : IRn →IR and ci : IRn →IR, i =
1, . . . , m areconvexfunctionsandci : IRn →IR, i = m + 1, . . . , m + h are
linear functions. Assume, further, that at x∗some Constraint Qualiﬁcation
conditions are satisﬁed. Then, there exists λ∗such that the pair (x∗, λ∗) satis-
ﬁes the Karush–Kuhn–Tucker conditions (43) and λ∗solves the dual problem
(50), i.e.,

68
R. De Leone
q(λ∗) = max
λ
q(λ)
λi ≥0, i = 1, . . . , m.
(53)
Moreover,
f ∗= f (x∗) = L(x∗, λ∗) = q(λ∗) = q∗
In order to revert, at least partially, this condition, strict convexity is
required.
Theorem 18 ([49, Theorem 12.13]) Let x∗be an optimal solution of the con-
vex optimization problem (39) where f : IRn →IR and ci : IRn →IR, i =
1, . . . , m areconvexfunctionsandci : IRn →IR, i = m + 1, . . . , m + h are
linear functions. Assume, further, that at x∗some Constraint Qualiﬁcation
conditions are satisﬁed. Moreover, suppose that ¯λ is a solution of the dual
problem (50) and that the function L(x, ¯λ) is strict convex in x and
L(¯x, ¯λ) = inf
x L(x, ¯λ).
Then x∗= ¯x and f (x∗) = L(x∗, ¯λ).
The two theorems above are the basis for a different, more convenient,
form for the dual problem, known as Wolfe dual [61]:
max
x,λ
L(x, λ)
subject to
∇x L(x, λ) = 0
λi ≥0, i = 1, . . . , m.
(54)
For this dual optimization problem it is possible to show that, if x∗is
a local minimum at which Constraint Qualiﬁcation conditions are satisﬁed,
thereexistsλ∗∈IRm+h suchthatthepair(x∗, λ∗)satisﬁestheKarush–Kuhn–
Tucker conditions (43) and, furthermore, solves the Wolfe dual problem (54).
4.3
Penalty and Augmented Lagrangian Methods
An important and well studied class of methods for solving nonlinear opti-
mization problems is based on the idea of replacing the original constrained
problem by a single or a sequence of unconstrained problems. For these prob-
lems the new objective function will contain terms penalizing the violation
of the original constraints.
An important issue, both from a theoretical and a practical point of view,
is to determine if the minimizer of the penalty function and the solution of

Nonlinear Optimization: A Brief Overview
69
the original optimization problem coincide. This property is called exactness
of the penalty function [20].
The simplest approach is to use a quadratic term to penalize the violation
of the constraints. For the constrained problem (39), the quadratic penalty
function is given by
ψ(x, μ) := f (x) + μ
 m

i=1
max{0, ci(x)}2 +
m+h

i=m+1
ci(x)2

,
(55)
where μ > 0 is the penalty parameter. If the original functions f (x) and
ci(x), i = 1, . . . , m + h are sufﬁciently smooth, the function ψ(x, μ) is
differentiable (and continuously differentiable, if m = 0, i.e., there are only
equality constraints) and, hence, standard algorithms for unconstrained min-
imization can be applied to calculate its minimizer.
However, when quadratic penalty terms are utilized, it is necessary to drive
the penalty term to +∞. A general scheme require to:
• choose a priori a sequence {μk} →+∞,
• for each value of μk, calculate xμk, a minimizer of ψ(x, μk).
The procedure terminates when the violation of the constraints at xμk is
sufﬁciently small.
For this simple scheme it is possible to show [25, Theorem 12.1.1] [49,
Theorem 17.1] that
1. {ψ(xμk, μk)} is non–decreasing,
2. { f (xμk)} is non–increasing,
3. the constraints violation is non–increasing,
4. every accumulation point x∗of the sequence {xμk} is a solution of Problem
(39).
Another widely used penalty function is the 1–norm penalty function
deﬁned as
φ(x, μ) := f (x) + μ
 m

i=1
max{0, ci(x)} +
m+h

i=m+1
|ci(x)|

.
(56)
This penalty function is exact in the sense that there exists a ﬁnite μ∗> 0
such that for all values of μ ≥μ∗, if x∗is a strict local solution of the
nonlinear problem (39) at which ﬁrst-order necessary optimality conditions
are satisﬁed, then x∗is a local minimizer of φ(x, μ) [49, Theorem 17.3].
However, the 1–norm penalty function is non–smooth and, therefore, speciﬁc
algorithms must be utilized and convergence is in many cases quite slow.

70
R. De Leone
Continuously differentiable exact penalty functions can also be con-
structed [20] by using an Augmented Lagrangian function that includes addi-
tional terms penalizing the violation of the Karush–Kuhn–Tucker conditions.
Under speciﬁc assumptions, stationary point, local and global minimizers of
the Augmented Lagrangian function exactly correspond to Karush–Kuhn–
Tucker points, local and global solutions of the constrained problem [21].
4.4
Sequential Quadratic Programming
A very effective method for solving constrained optimization problems is
based on sequentially solving quadratic subproblems (Sequential Quadratic
Programming, SQP). The idea behind the SQP approach is to construct, at
each iteration, a quadratic approximation of Problem (39) around the current
point xk, and then use the minimizer of this subproblem as the new iterate
xk+1 [49, Chap. 18].
More speciﬁcally, at the current point xk we construct a quadratic approxi-
mation of the problem by a quadratic approximation for the objective function
using the Hessian of the Lagrangian function with respect to the x variables
and linear approximation of the constraints:
min
d
f (xk) + ∇f (xk)T d + 1
2dT ∇2
xx L(xk, λk)d
∗subject to ∇ci(xk)T d + ci(xk) ≤0,
i = 1, . . . , m
∇ci(xk)T d + ci(xk) = 0,
i = m + 1, . . . , m + h.
(57)
Very fast and efﬁcient algorithms exist for solving the above problem that
produce the vector dk, multipliers associated to the linearized constraints
λk+1,andanestimateoftheactiveconstraints.6 Thenthenewpointisobtained
as xk+1 = xk + dk.
Under speciﬁc assumptions, it is possible to show that if x∗is a local solu-
tion of Problem (39), if, at x∗and some λ∗, Karush–Kuhn–Tucker conditions
are satisﬁed, and if (xk, λk is sufﬁciently close to (x∗, λ∗), then there is a local
solution of the subproblem (57) whose active set is the same as the active set
of the nonlinear optimization problem (39) at x∗[55].
6 One of the most important technique for solving convex quadratic programming prob-
lems with equality and inequality constraints is based on Active Set strategy where, at
each iteration, some of the inequality constraints, and all the equality constraints, are
imposed as equalities (the “Working Set”) and a simpler quadratic problem with only
equality constraints is solved. Then the Working Set is update and a new iteration is
performed. For further details refer to [25, 10.3] and [49, 16.5].

Nonlinear Optimization: A Brief Overview
71
The correct identiﬁcation of the active constraints when xk is sufﬁciently
close to x∗is at the basis of the proof of local convergence for the SQP
method.
Acknowledgements The author wants to express his gratitude to prof. Nadaniela Egidi
for reading a ﬁrst version of the manuscript and providing many useful suggestions.
References
1. Abadie, J.: On the Kuhn-Tucker Theorem. Operations Research Center University
of Calif Berkeley, Technical report (1966)
2. Al-Baali, M.: Descent property and global convergence of the Fletcher’ Reeves
method with inexact line search. IMA J. Numer. Anal. 5(1), 121–124 (1985)
3. Apostol, T.M.: Calculus, 2nd edn. Wiley (1967)
4. Armijo, L.: Minimization of functions having Lipschitz continuous ﬁrst partial
derivatives. Pac. J. Math. 16(1), 1–3 (1966)
5. Bagirov, A.M., Gaudioso, M., Karmitsa, N., Mäkelä, M.M., Taheri, S.: Numerical
Nonsmooth Optimization: State of the Art Algorithms. Springer Nature (2020)
6. Bazaraa, M.S., Sherali, H.D., Shetty, C.M.: Nonlinear Programming: Theory and
Algorithms, 3rd edn. Wiley, Newark, NJ (2006)
7. Bertsekas, D.P.: Nonlinear Programming. Athena Scientiﬁc (1999)
8. Boyd, S., Vandenberghe, L.: Convex Optimization. Cambridge University Press,
New York, NY, USA (2004)
9. Broyden, C.G.: A class of methods for solving nonlinear simultaneous equations.
Math. Comput. 19, 577–593 (1965)
10. Broyden, C.G.: Quasi-Newton methods and their application to function minimiza-
tion. Math. Comput. 21, 368–381 (1967)
11. Broyden, C.G.: The convergence of single-rank quasi-Newton methods. Math. Com-
put. 24, 365–382 (1970)
12. Broyden, C.G., Dennis, J.E., Moré, J.J.: On the local and superlinear convergence of
quasi-Newton methods. IMA J. Appl. Math. 12(3), 223–245 (1973)
13. Conn, A.R., Gould, N.I.M., Toint, P.L.: Convergence of Quasi-Newton matrices
generated by the symmetric rank one update. Math. Program. 50(2), 177–195 (1991)
14. Davidon, W.C.: Variable metric method for minimization. AEC Research and Devel-
opment Report ANL-5990, Argonne National Laboratory (1959)
15. De Leone, R., Gaudioso, M., Grippo, L.: Stopping criteria for linesearch methods
without derivatives. Math. Program. 30(3), 285–300 (1984)
16. Deb, K., Deb, K.: Multi-objective optimization. In: Burke, E., Kendall, G. (eds.)
Search Methodologies: Introductory Tutorials in Optimization and Decision Support
Techniques, pp. 403–449. Springer, US, Boston, MA (2014)
17. Dennis, J.E., Moré, J.J.: Quasi-Newton methods, motivations and theory. SIAM Rev.
19, 46–89 (1977)
18. Dennis, J.E., Schnabel, R.B.: Numerical Methods for Unconstrained Optimization
and Nonlinear Equations. Prentice-Hall, Englewook Cliffs, New Jersey (1983)
19. Dennis, J.E., Schnabel, R.B.: Chapter I A view of unconstrained optimization. In:
Optimization. Handbooks in Operations Research and Management Science, vol. 1,
pp. 1–72. Elsevier (1989)

72
R. De Leone
20. Di Pillo, G., Grippo, L.: Exact penalty functions in constrained optimization. SIAM
J. Control Optim. 27(6), 1333–1360 (1989)
21. Di Pillo, G., Liuzzi, G., Lucidi, S., Palagi, L.: An exact augmented Lagrangian
function for nonlinear programming with two-sided constraints. Comput. Optim.
Appl. 25(1), 57–83 (2003)
22. Dixon, L.C.W.: Variable metric algorithms: necessary and sufﬁcient conditions for
identical behavior of nonquadratic functions. J. Optim. Theory Appl. 10, 34–40
(1972)
23. Ehrgott, M.: Multicriteria Optimization, vol. 491. Springer Science & Business
Media (2005)
24. Fletcher, R.: A new approach to variable metric algorithms. Comput. J. 13, 317–322
(1970)
25. Fletcher, R.: Practical Methods of Optimization, 2nd edn. Wiley (1990)
26. Fletcher, R., Powell, M.J.D.: A rapidly convergent descent method for minimization.
Comput. J. 6(2), 163–168 (1963)
27. Fletcher, R., Reeves, C.M.: Function minimization by conjugate gradients. Comput.
J. 7(2), 149–154 (1964)
28. Gaudioso, M., Giallombardo, G., Miglionico, G.: Essentials of numerical nonsmooth
optimization. 4OR 18(1), 1–47 (2020)
29. Gilbert, J.C., Nocedal, J.: Global convergence properties of conjugate gradient meth-
ods for optimization. SIAM J. Optim. 2(1), 21–42 (1992)
30. Goldfarb, D.: A family of variable metric updates derived by variational means.
Math. Comput. 24, 23–26 (1970)
31. Goldstein, A.A.: Constructive Real Analysis. Harper and Row, London (1967)
32. Golub, G.H., Van Loan, C.F.: Matrix Computations. Johns Hopkins University Press,
Baltimore, Maryland (1983)
33. Grippo, L., Lampariello, F., Lucidi, S.: A nonmonotone line search technique for
Newton’s method. SIAM J. Numer. Anal. 23(4), 707–716 (1986)
34. Grippo, L., Sciandrone, M.: Nonmonotone globalization techniques for the Barzilai-
Borwein gradient method. Comput. Optim. Appl. 23(2), 143–169 (2002)
35. Grippo, L., Sciandrone, M.: Methods of unconstrained optimization. (Metodi di
ottimizzazione non vincolata.). Unitext 53. La Matematica per il 3+2. Springer,
Italia (2011)
36. Guignard, M.: Generalized Kuhn-Tucker conditions for mathematical programming
problems in a Banach space. SIAM J. Control 7(2), 232–241 (1969)
37. Hager, W.W.: Updating the inverse of a matrix. SIAM Rev. 31(2), 221–239 (1989)
38. Hager, W.W., Zhang, H.C.: A survey of nonlinear conjugate gradient methods. Pac.
J. Optim. 2(1), 35–58 (2006)
39. Hestenes, M.R., Stiefel, E.: Methods of conjugate gradients for solving linear sys-
tems. J. Res. Natl. Bur. Stand. 49, 409–436 (1952)
40. Horst, R., Pardalos, P.M.: Handbook of Global Optimization, vol. 2. Springer Science
& Business Media (2013)
41. Konak, A., Coit, D.W., Smith, A.E.: Multi-objective optimization using genetic algo-
rithms: a tutorial. Reliab. Eng. Syst. Saf. 91(9), 992–1007 (2006)
42. Kuhn, H.W., Tucker, A.W.: Nonlinear Programming, pp. 481–492. University of
California Press, Berkeley, California (1951)
43. Lemarechal, C., Mifﬂin, R.: Nonsmooth optimization: proceedings of a IIASA work-
shop, March 28–April 8, 1977. Elsevier (2014)

Nonlinear Optimization: A Brief Overview
73
44. Li, D.H., Fukushima, M.: A derivative-free line search and global convergence of
Broyden-like method for nonlinear equations. Optim. Methods Softw. 13(3), 181–
201 (2000)
45. Luenberger, D.G.: Linear and Nonlinear Programming, 2nd edn. Addison–Wesley
(1984)
46. Mangasarian, O.L.: Nonlinear Programming. McGraw-Hill, New York (1969)
47. Mangasarian, O.L., Fromovitz, S.: The Fritz John necessary optimality conditions in
the presence of equality and inequality constraints. J. Math. Anal. Appl. 17, 37–47
(1967)
48. Meyer, C.D.: Matrix Analysis and Applied Linear Algebra. Society for Industrial
and Applied Mathematics, Philadelphia, PA, USA (2000)
49. Nocedal,J.,Wright,S.:NumericalOptimization.SpringerScience&BusinessMedia
(2006)
50. Ortega, J.M., Rheinboldt, W.C.: Iterative Solution of Nonlinear Equations in Several
Variables. Academic Press (1970)
51. Pinter,J.:Continuousglobaloptimization:applications.In:C.Floudas,E.P.M.Parda-
los (eds.) Encyclopedia of Optimization, pp. 482–486. Springer (2008)
52. Polak, E., Ribière, G.: Note sur la convergence de méthodes de directions con-
juguées. ESAIM: Math. Model. Numer. Anal.-Modélisation Mathématique et Anal.
Numérique 3(R1), 35–43 (1969)
53. Polyak, B.T.: The conjugate gradient method in extremal problems. USSR Comput.
Math. Math. Phys. 9(4), 94–112 (1969)
54. Pytlak, R.: Conjugate Gradient Algorithms in Nonconvex Optimization, vol. 89.
Springer Science & Business Media (2008)
55. Robinson, S.M.: Perturbed Kuhn-Tucker points and rates of convergence for a class
of nonlinear-programming algorithms. Math. Program. 7(1), 1–16 (1974)
56. Rockafellar, R.T.: Convex Analysis. Princeton Mathematical Series, Princeton Uni-
versity Press, Princeton, N. J. (1970)
57. Shanno, D.F.: Conditioning of Quasi-Newton methods for function minimization.
Math. Comput. 24, 647–656 (1970)
58. Slater, M.: Lagrange multipliers revisited. Technical report, Cowles Foundation Dis-
cussion Paper No. 80, Cowles Foundation for Research in Economics, Yale Univer-
sity (1950)
59. Sun, W., Yuan, Y.X.: Optimization Theory and Methods: Nonlinear Programming,
vol. 1. Springer Science & Business Media (2006)
60. Wang, Z., Fang, S.C., Xing, W.: On constraint qualiﬁcations: motivation, design and
inter-relations. J. Ind. Manag. Optim. 9, 983–1001 (2013)
61. Wolfe, P.: A duality theorem for non-linear programming. Q. Appl. Math. 19, 239–
244 (1961)
62. Wolfe, P.: Convergence conditions for ascent methods. SIAM Rev. 11(2), 226–235
(1969)
63. Zhang, H.C., Hager, W.W.: A nonmonotone line search technique and its application
to unconstrained optimization. SIAM J. Optim. 14(4), 1043–1056 (2004)

New Computational Tools
in Optimization

The Role of grossone in Nonlinear
Programming and Exact Penalty
Methods
Renato De Leone
Abstract Exact penalty methods form an important class of methods for
solving constrained optimization problems. Using penalty functions, the orig-
inal constrained optimization problem can be transformed in an “equivalent”
unconstrained problem. In this chapter we show how grossone can be uti-
lized in constructing exact differentiable penalty functions for the case of only
equality constraints, the general case of equality and inequality constraints,
and quadratic problems. These new penalty functions allow to recover the
solution of the unconstrained problem from the ﬁnite term (in its grossone
expansion) of the optimal solution of the unconstrained problem. Moreover,
Lagrangian duals associated to the constraints are also automatically obtained
from the inﬁnitesimal terms. Finally a new algorithmic scheme is presented.
1
Introduction
Penalty methods represent an important class of methods for solving con-
strained optimization problems. These functions, in their simplest form, are
composed of two parts: the original objective function and a penalty func-
tion, usually multiplied by a positive scalar called penalty parameter, which
penalize the violation of the constraints. Using penalty functions, the origi-
nal constrained optimization problem can be transformed in an “equivalent”
unconstrained problem. Two major issues must be taken into account when
constructing such penalty functions: exactness and differentiability. Roughly
speaking, exactness requires that the global or local solution of the uncon-
R. De Leone (B)
School of Science and Technology, University of Camerino, Camerino, MC, Italy
e-mail: renato.deleone@unicam.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_3
77

78
R. De Leone
strained problem or a stationary point of it, must correspond to a global or
local minimum of the constrained problem or to a point satisfying Karush–
Kuhn–Tucker conditions. Using the Euclidean norm, it is quite simple to
construct continuously differentiable, or at least differentiable penalty func-
tions, as long as the functions in the original problem are sufﬁciently smooth.
However, in these cases the penalty parameter must be driven to +∞, thus
generating numerical instability. Using the 1–norm, instead, it is possible to
construct penalty functions that are exact, that is they do not require that the
penalty parameter goes to +∞. The difﬁculty in this case arises from the
non–differentiability of the function.
Recently, Sergeyev introduced a new approach to inﬁnite and inﬁnitesi-
mals. The proposed numeral system is based on ①, the number of elements
of IN, the set of natural numbers. We refer the reader to Chap.1 for insights
on the arithmetic of inﬁnity and the properties of ①. Here we want to stress
that ①is not a symbol and is not used to make symbolic calculation. In
fact, the new numeral ①is a natural number, and it has both cardinal and
ordinal properties, exactly as the “standard”, ﬁnite natural numbers. More-
over, the new proposed approach is far apart from non–Standard Analysis, as
clearly shown in [30]. A comprehensive description of the grossone–based
methodology can also be found in [29].
In this chapter we discuss the use of ①in constructing exact differentiable
penalty functions for the case of only equality constraints, the general cases of
equality and inequality constraints, and quadratic problems. Using this novel
penalty function, it is possible to recover the solution of the unconstrained
problem from the ﬁnite term (in its ①expansion) of the optimal solution of the
unconstrained problem. Moreover, Lagrangian duals are also automatically
and at no additional cost obtained just considering the ①−1 grossdigits in
their expansion in term ①.
While this chapter only concentrates the attention on the use of ①to deﬁne
novel exact penalty functions for constrained optimization problems, it must
be noted that the use of ①has been beneﬁcial in many other areas in opti-
mization. Already in [8], the authors demonstrated how the classical simplex
method for linear programming can be modiﬁed, using ①to overcome the
difﬁculties due to degenerate steps. Along this line of research, more recently
in [4], the authors proposed the Inﬁnitely-Big-M method, a re–visitation of
the Big–M method for the Inﬁnity Computer. Various different optimization
problems have been successfully tackled using this new methodology: mul-
tiobjective optimization problems [3, 5, 6, 21], the use of negative curvature
directions in large-scale unconstrained optimization [11, 12], variable met-
ric methods in nonsmooth optimization [16]. Recently, this computational
methodology has also been also utilized in the ﬁeld of Machine Learning

The Role of grossone in Nonlinear Programming …
79
allowing to construct new spherical separations for classiﬁcation problems
[2], and novel sparse Support Vector Machines [10]. Furthermore, the use
of ①has given rise to a variety of applications in several ﬁelds of pure and
applied mathematics, providing new and alternative approaches. Here we
only mention numerical differentiation [26], ODE [1, 20, 31], hyperbolic
geometry [23], inﬁnite series and the Riemann zeta function [25, 27], biol-
ogy [28], and cellular automata [7].
We brieﬂy describe our notation now. All vectors are column vectors and
will be indicated with lower case Latin letter (x, y, . . .). Subscripts indicate
components of a vector, while superscripts are used to identify different vec-
tors. Matrices will be indicated with upper case roman letter (A, B, . . .). The
set of real numbers and the set of nonnegative real numbers will be denoted
by IR and IR+ respectively. The space of the n–dimensional vectors with real
components will be indicated by IRn. Superscript T indicates transpose. The
scalar product of two vectors x and y in IRn will be denoted by xT y. The
norm of a vector x will be indicated by ∥x∥. The space of the m × n matrices
with real components will be indicated by IRm×n. Let f : S ⊆IRn →IR, the
gradient ∇f (x) of f : IRn →IR at a point x ∈IRn is a column vector with
[∇f (x)] j = ∂f (x)
∂x j .
For what is necessary in this chapter, in this new positional numeral system
with base ①a value C is expressed as
C = C(1)①+ C(0) + C(−1)①−1C(−2)①−2 + · · ·
Here and throughout the symbols := and =: denote deﬁnition of the term on
the left and the right sides of each symbol, respectively.
2
Exact Penalty Methods
In this section we will utilize the novel approach to inﬁnite and inﬁnitesimal
numbers proposed by Sergeyev1 to construct exact differentiable penalty
functions for nonlinear optimization problems.
Consider the constrained optimization problem
1 We refer the reader to Chap.1 for an in–depth description of this new applied approach
to inﬁnite and inﬁnitesimal quantities and the arithmetics of inﬁnity.

80
R. De Leone
min
x
f (x)
subject to ci(x) ≤0
i = 1, . . . , m
ci(x) = 0
i = m + 1, . . . , m + h
(1)
where f : IRn →IR istheobjectivefunctionandci : IRn →IR, i = 1, . . . , m + h
are the constraints deﬁning the feasible region X
X :=

x ∈IRn : ci(x) ≤0, i = 1, . . . , m and ci(x) = 0, i = m + 1, . . . , m + h

.
For simplicity, we will assume that all the functions are at least twice con-
tinuously differentiable.
Let ¯x be a feasible point for the above problem. The set of active constraints
at ¯x is deﬁned as
A (¯x) :=

i : 1 ≤i ≤m, ci(¯x) = 0

∪

m + 1, . . . , m + h

.
In nonlinear optimization a key role is played by the Constraint Qualiﬁ-
cation conditions that ensure that the tangent cone and the cone of linearized
feasible directions coincide and allow to express necessary and sufﬁcient
optimality conditions in terms of the well known Karush–Kuhn–Tucker con-
ditions.2 For reader’s easiness we recall here the fundamental Linear Inde-
pendence Constraint Qualiﬁcation that will be heavily utilized in this form
or in a modiﬁed form in this chapter.
Deﬁnition 1 Linear independence constraint qualiﬁcation (LICQ) condition
is said to hold true at ¯x ∈X if the gradients of the active constraints at ¯x are
linearly independent.
Note that weaker Constraint Qualiﬁcation conditions can be imposed [32].
In [34] various Constraint Qualiﬁcation conditions are stated and categorized
into four levels by their relative strengths from weakest (less stringent) to
strongest (more stringent, but easier to check).
The Lagrangian function associated to Problem (1) is given by
L(x, λ) := f (x) +
m+h

i=1
λici(x).
(2)
Necessary and sufﬁcient optimality conditions can be written in terms of
the Lagrangian function. If x∗∈X is a local minimum of Problem (1) at
which LICQ condition holds true, then, there exist a vector λ∗such that the
pair (x∗, λ∗) is a Karush–Kuhn–Tucker point.
2 For further details we refer the reader to Chap.2 and references therein.

The Role of grossone in Nonlinear Programming …
81
Different algorithms have been proposed in literature for ﬁnding a local
minimum of Problem (1). Among the most effective methods, penalty meth-
ods play a crucial role, obtaining the solution of the constrained problem by
solving a single or a sequence of unconstrained optimization problems.
Let δ : IRn →IR+ be a function, when possible continuously differentiable,
such that
δ(x)
= 0 if x ∈X
> 0 otherwise.
Then the constrained optimization problem (1) can be replaced by the
following unconstrained problem
min
x
ψ(x, μ).
(3)
where
ψ(x, μ) := f (x) + μδ(x),
(4)
andμisapositiverealnumber.Differentchoicesforthefunctionδ(x)conduct
to different penalty methods. A convenient, highly utilized, choice is
δ(x) = 1
2
m

i=1
max

ci(x), 0
2 + 1
2
m+h

i=m+1
(ci(x))2
(5)
which is differentiable but not twice differentiable. Therefore, this choice for
δ(x) does not allow to utilize some of the most effective algorithms available
for unconstrained optimization.
One key issue in exterior penalty methods is exactness. Roughly speaking,
the penalty function is exact if, for some ﬁnite value of the parameter μ, a local
(global) minimum of it corresponds to a local (global) minimum point of the
constrainedproblem.Asnotedin[14]thischaracterizationissatisfactoryonly
when both the constrained problem and the penalty function are convex, while
in the non–convex case a more precise deﬁnition of exactness is necessary
[13, 14].
Unfortunately, for the penalty function (5) this exactness property does not
hold, not even in the case of only equality constraints, that is when m = 0. In
[15, p. 279] a simple 1–dimensional counter-example is reported, showing
that the solution of the constraint problem is only obtained when μ →+∞.
Exact penalty functions can be constructed using 1-norm instead of the 2-
norm utilized in (5) to penalize the violation of the constraints. However, in
these cases the resulting function is nondifferentiable, and ad-hoc methods
must be utilized for which convergence is often quite slow. Furthermore,
exact differentiable penalty functions can be constructed [13] by introducing

82
R. De Leone
Algorithm 1: Generic Sequential Minimization Algorithm
1 Choose x0 ∈IRn. Let {μk} be a monotonically increasing sequence of positive real
values, Set k = 0, xμ0 = x0;
2 while δ(xμk) > ϵ do
3
Set k = k + 1;
4
Compute xμk an optimal solution of the unconstrained differentiable problem
min
x
ψ(x, μk).
5 end
in the objective function additional terms related to ﬁrst order optimality
conditions, thus making the objective function more complicate to manage.
Sequential penalty methods require to solve a sequence of minimization
problems with increasing values of the parameter μ as shown in Algorithm
1.
In the algorithm above, the point xμk obtained at iteration k can be used as
starting point for the minimization problem at iteration k + 1. Note that Step
4 cannot be, in general, completed in a ﬁnite number of steps and, hence, the
algorithm must be modiﬁed requiring to calculate, at each iteration, only an
approximation of the optimal solution.
In [8] a novel exact differentiable penalty method is introduced using
the numeral grossone. In the next three sections, the equality constraints,
the general equality and inequality constraints and quadratics case will be
discussed. Finally, a simple new non–monotone algorithmic scheme is also
proposed for the solution of penalty functions based on ①.
3
Equality Constraints Case
Consider the constrained optimization problem with only equality constraints
(that is m = 0):
min
x
f (x)
subject to ci(x) = 0
i = 1, . . . , h.
(6)
Let
δ(x) = 1
2
h

i=1
(ci(x))2

The Role of grossone in Nonlinear Programming …
83
and let ψ(x, μ) be given by (4). In this case, it is possible to show [15,
Theorem 12.1.1] that for the sequence constructed by Algorithm 1
1. {ψ(xμk, μk)} is monotonically non–decreasing,
2. {δ(xμk)} is monotonically non–increasing,
3. { f (xμk)} is monotonically non–decreasing.
Moreover, lim
k ci(xμk) = 0, i = 1, . . . , h and each accumulation point x∗
of the sequence {xμk}k solves Problem (6).
For the equality constrained case, the penalty function proposed in [8] is
deﬁned as follows:
min
x
ψ(x) := f (x) + ①
2
h

i=1
(ci(x))2 .
(7)
Under the hypothesis that any generic point x, the function value f (x),
and the generic constraint ci(x) as well as the gradient ∇f (x) and ∇ci(x)
have a ﬁnite part (i.e., grossdigits corresponding to grosspower 0) and only
inﬁnitesimal terms, it is possible to show that [8, Theorem 3.3] if x∗is a sta-
tionary point for (7) then

x∗(0), λ∗	
is a KKT point for (6), where x∗(0) is the
ﬁnite term in the representation of x∗, and for i = 1, . . . , h, λ∗
i = c(−1)
i
(x∗(0))
where c(−1)
i
(x∗) is the grossdigit corresponding to the grosspower -1 in the
representation of ci(x∗).
The above result strongly relies on the fact that at x∗the LICQ condition
is satisﬁed. The proof is based on the observation that grossdigits “do not
mix”, that is, they are kept well separated in the computations. Therefore,
setting to 0 a grossnumber is equivalent to set to zero all grossdigits in its
representation.
The fundamental aspect of this result is that, by solving the unconstrained
optimization problem (where the objective function is twice continuously
differentiable), an optimal solution of the constrained problem is obtained.
Moreover, the multipliers associated to the equality constraints are automat-
ically recovered at no additional cost, just from the representation of ci(x∗)
in terms of powers of ①.
In [9] two simple examples are discussed, showing the importance of
constraintqualiﬁcationconditions.Here,weproposeanovelexample,similar
in spirit to the ﬁrst example discussed in [9]. The problem is originally studied
in [15, pp. 279–280] to show the effectiveness and weakness of sequential
penalty method.
Consider the problem

84
R. De Leone
Fig. 1 Feasible region
and optimal solution for
Problem (8)
min
x
−x1 −x2
subject to x2
1 + x2
2 −1 = 0.
(8)
The feasible region and the optimal solution for this problem is shown in
Fig.1.
The Lagrangian function is given by
L(x, λ) = −x1 −x2 + λ

x2
1 + x2
2 −1
	
and the optimal solution is x∗=
⎡
⎢⎣
1
√
2
1
√
2
⎤
⎥⎦. Moreover, it is not difﬁcult to show
that the pair

x∗, λ∗=
1
√
2

satisﬁes the KKT conditions.
In Fig.2 the contour plots for the function ψ(x, μ) for different values of
μ are shown.
The penalty function we construct is:
ψ (x, ①) := −x1 −x2 + ①
2

x2
1 + x2
2 −1
	2 .
(9)
The First–Order Optimality Conditions ∇ψ (x, ①) = 0 are:
⎧
⎨
⎩
−1 + 2①x1

x2
1 + x2
2 −1
	
= 0,
−1 + 2①x2

x2
1 + x2
2 −1
	
= 0.
(10)
By symmetry,
x∗
1 = x∗
2 = R = R(0) + ①−1R(−1) + ①−2R(−2) + . . .

The Role of grossone in Nonlinear Programming …
85
-2
-2
-2
-1.75
-1.75
-1.5
-1.5
-1.25
-1.25
-1
-1
-0.75
-0.75
-0.5
-0.5
-0.5
-0.25
-0.25
-0.25
0
0
0
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-1.5
-1.25
-1.25
-1
-1
-1
-0.75
-0.75
-0.75
-0.5
-0.5
-0.5
-0.5
-0.25
-0.25
-0.25
-0.25
0
0
0
0
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-1.25
-1.25
-1
-1
-0.75
-0.75
-0.75
-0.5
-0.5
-0.5
-0.25
-0.25
-0.25
0
0
0
0
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-1.25
-1
-1
-0.75
-0.75
-0.5
-0.5
-0.5
-0.25
-0.25
-0.25
0
0
0
0
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
Fig. 2 Contour plots of ψ(x, μ) for μ = 0.1, 1, 5, 20
and from (10) we have that
−1 + 4①R

R2 −1
2

= 0.
(11)
From (11), by equating the term of order ①to 0, we obtain:
4R(0)

R(0)2
−1
2

= 0
from which either R(0) =
1
√
2 or R(0) = −1
√
2 or R(0) = 0. The ﬁrst choice for
R(0) corresponds to a minimum of the unconstrained problem (and also for
the constrained problem (8)), while the second corresponds to a maximum.
Finally, the third choice of R(0) corresponds to a spurious solution whose
presence is due to the fact that, for this point ˆx =
0
0

, LICQ are not satisﬁed.
In fact ∇h(ˆx) =
0
0

. Fixing now R(0) =
1
√
2, and equating to 0 the ﬁnite
terms in (11), i.e., the term corresponding to ①0, we obtain:

86
R. De Leone
−1 + 4 1
√
2
2 1
√
2
R(−1) = 0,
from which R(−1) = 1
4 and hence
x∗
1 = x∗
2 = R =
1
√
2
+ 1
4①−1 + · · ·
where all remaining terms are inﬁnitesimal of higher order.
Moreover,

x∗
1
	2 +

x∗
2
	2 −1 = 2R2 −1 = 2
1
2 +
2
4
√
2
①−1 + 1
16①−2 + · · ·

−1
=
1
√
2
①−1 + · · ·
where again we neglect inﬁnitesimal of higher order than ①−1.
As expected from the theory, the ①−1 terms in the representation of the
(unique) constraint provides automatically, and at no additional costs, the
value of the Lagrangian multiplier.
Here we want to stress the importance of Constraint Qualiﬁcation condi-
tions that, when not satisﬁed, could bring to spurious results, as shown by
this example.
This situation is even better clariﬁed in the second example from [9]:
min
x
x1 + x2
subject to

x2
1 + x2
2 −2
	2 = 0.
(12)
Here the objective function and the feasible region are the same as in the
ﬁrst example in [9] and the optimal solution is x∗=
−1
−1

with Lagrangian
multiplier λ∗= 1
2. However, in this case
∇c1(x) =
⎡
⎣
2x1

x2
1 + x2
2 −2
	
2x1

x2
1 + x2
2 −2
	
⎤
⎦
which, calculated at the optimal solution, gives:
∇c1
−1
−1

=
0
0

.

The Role of grossone in Nonlinear Programming …
87
Therefore, the LICQ condition is not satisﬁed and the Karush–Kuhn–Tucker
conditions
⎧
⎨
⎩
1 −4λx1

x2
1 + x2
2 −2
	
= 0
1 −4λx2

x2
1 + x2
2 −2
	
= 0

x2
1 + x2
2 −2
	2 = 0
(13)
have no solution. In this case (see [9]) the optimal solution x∗=
c −1
−1

of
Problem (12) cannot be recovered from the exact penalty function
ψ(x, ①) = x1 + x2 + ①
2

x2
1 + x2
2 −2
	4
using ﬁrst order optimality conditions.
4
Equality and Inequality Constraints Case
Consider now the more general nonlinear optimization problem (1) that
includes equality and inequality constraints. In this case, the exact penalty
function proposed in [8] is given by
ψ(x, ①) = f (x) + ①
2
m

i=1
max{0, ci(x)}2 + ①
2
m+h

i=m+1
ci(x)2.
(14)
In order to derive the correspondence between stationary points of (14)
and KKT points for Problem (1) a Modiﬁed LICQ condition is introduced in
[8].
Deﬁnition 2 Let ¯x ∈IRn. The Modiﬁed LICQ (MLICQ) condition is said to
hold true at ¯x if the vectors

∇ci(¯x), i : 1 ≤i ≤m and ci(¯x) ≥0

∪

∇ci(¯x), i = m + 1, . . . , m + h

are linearly independent.
If the above conditions are satisﬁed, and x∗is a stationary point for the
unconstrained problem
min
x
ψ(x, ①)
then, it possible, again, to show [8, Theorem 3.4] that the pair

x∗(0), λ∗	
is a
KKT point for Problem (1), where x∗(0) is the ﬁnite term in the representation

88
R. De Leone
of x∗, and for i = 1, . . . , m + h, λ∗
i = c(−1)
i
(x∗(0)) where c(−1)
i
(x∗) is the
grossdigit corresponding to the grosspower -1 in the representation of ci(x∗).
5
Quadratic Case
In this section we apply the new exact penalty function to the quadratic
problem
min
x
1
2xT Mx + qT x
subject to
Ax = b
x ≥0
(15)
where M ∈IRn×n is positive deﬁnite, A ∈IRm×n with rank(A) = m, q ∈IRn,
and b ∈IRm. We assume that the feasible region is not empty.
For this linearly constrained problem, Constraint Qualiﬁcation conditions
are always satisﬁed and the Karush–Kuhn–Tucker conditions [22] are:
Mx + q −AT u −v = 0,
Ax −b
= 0,
x
≥0,
v
≥0,
xT v
= 0.
(16)
For this quadratic problem, the new exact penalty function using ①is given
by:
ψ(x, ①) := 1
2xT Mx + qT x + ①
2 ∥Ax −b∥2
2 + ①
2 ∥max{0, −x}∥2
2
(17)
and the corresponding unconstrained problem is:
min
x
ψ(x, ①).
(18)
The ﬁrst order optimality conditions can be written as follows
0 = ∇ψ(x, ①) = Mx + q + ①AT (Ax −b) −①max{0, −x}.
(19)
Lemma 1 in [9] shows that the function
δ(x) = 1
2 ∥Ax −b∥2
2 + 1
2 ∥max{0, −x}∥2
2

The Role of grossone in Nonlinear Programming …
89
is convex, and ∇δ(x) = 0 if and only if Ax = b and x ≥0.
Based on this lemma it is possible to show that, if x∗is a stationary point
for the unconstrained problem (18), then

x∗(0), π∗, μ∗	
is a Karush–Kuhn–
Tucker points for Problem (15), where again x∗(0) is the ﬁnite term in the
representation of x∗, and, taking into account the linearity of the original
constraints,
• π∗= Ax∗(−1) + b(−1), where x∗(−1) (resp. b(−1)) is the grossdigit corre-
sponding to the grossterm ①−1 in the representation of x∗(resp. b), and
• μ∗
j = max{0, −x∗(−1)}.
Once again, the proof is based on the fact that during the computation
grossdigits do not mix. Then, the results follow from (19)
• by setting ﬁrst to 0 the terms with grosspower ①, in this way the feasibility
of x∗(0) is provided (second and third Karush–Kuhn–Tucker conditions in
(16)),
• equating to zero the ﬁnite terms (that is the terms with grosspower ①0)
thus obtaining the ﬁrst, fourth and last Karush–Kuhn–Tucker conditions in
(16).
6
A General Scheme for the New Exact Penalty
Function
In the previous sections, we have shown how the solution of the constrained
minimization problem (1) can be obtained by solving an unconstrained min-
imization problem that uses ①. Then, any standard optimization algorithm
can be utilized to obtain a stationary point for these problems from which
the solution of the constrained problems as well the multipliers can be easily
obtained.
In this section a simple novel general algorithmic scheme is proposed to
solve the unconstrained minimization problem arising from penalizing the
constraints using ①, as constructed in the previous sections. The algorithms
belongs to the class of non–monotone descend algorithms [17–19, 33, 35],
and does not require that the new calculated points be necessary better than
the current one. This property is necessary since for a descent algorithm,
when applied to determine the minimum of ψ(x, ①), once a feasible point is
obtained, then all remaining points generated by the algorithm should remain
feasible. This, in general, could be quite complicate to ensure in practice.
For simplicity, consider the generic minimization problem:

90
R. De Leone
min
x
f (x)
where f is continuously differentiable and
f (x) = ①f (1)(x) + f (0)(x) + ①−1 f (−1)(x) + . . .
(20)
∇f (x) = ①∇f (1)(x) + ∇f (0)(x) + ①−1∇f (−1)(x) + . . .
(21)
The proposed algorithm utilizes (as customary in non–monotone algo-
rithms) two sequences {tk}k and {lk}k of positive integers such that
t0 = 0,
tk+1 ≤max {tk + 1, T } ,
l0 = 0,
lk+1 ≤max {lk + 1, L} ,
where T and L are two ﬁxed positive integers.
At the generic iteration k, having xk, it is necessary ﬁrst to verify if the
stopping criterion
∇f (1)(xk) = 0 and ∇f (0)(xk) = 0
is satisﬁed. Otherwise, the next iterate xk+1 is calculated in the following
way:
• if ∇f (1)(xk) ̸= 0, choose xk+1 such that
f (1)(xk+1) ≤f (1)(xk) + σ
∇f (1)(xk)


,
and
f (0)(xk+1) ≤max
0≤j≤lk
f (0)(xk−j) + σ
∇f (0)(xk)


;
• If ∇f (1)(xk) = 0, choose xk+1 such that
f (0)(xk+1) ≤f (0)(xk) + σ
∇f (0)(xk)


,
f (1)(xk+1) ≤max
0≤j≤tk
f (1)(xk−j)
where σ(.) is a forcing function [24].
In other words, when ∇f (1)(xk) ̸= 0 the inﬁnite term cannot grow more
than a quantity that depends on the norm of ∇f (1)(xk). For the ﬁnite term,
instead, the new value f (0)(xk+1) cannot be bigger than the worst value of
f (0)(xk−j) at lk previous steps plus a quantity that depends on the norm of
∇f (0)(xk).

The Role of grossone in Nonlinear Programming …
91
Instead, when ∇f (1)(xk) = 0, the ﬁnite term f (0)(xk+1) cannot grow big-
ger than a quantity that depends on the norm of ∇f (0)(xk), and the inﬁ-
nite term f (1)(xk+1) must be better than the worst of the previous tk values
f (1)(xk−j).
In order to demonstrate convergence of the above scheme, we need to
consider two different cases.
Case 1: there exists ¯k such that ∇f (1)(xk) = 0, for all k ≥¯k. Then
f (1)(xk+1) ≤max
0≤j≤tk
f (1)(xk−j),
k ≥¯k.
Therefore, in this case:
max
0≤i≤T f (1)(x ¯k+T j+i) ≤max
0≤i≤T f (1)(x ¯k+T ( j−1)+i)
and the sequence

max
0≤i≤T f (1)(x ¯k+T j+i)

j
is monotonically decreasing.
Moreover,
f (0)(xk+1) ≤f (0)(xk) + σ
∇f (0)(xk)


,
k ≥¯k.
Assuming that the level sets for f (1)(x0) and f (0)(x0) are compact sets,
the sequence

max
0≤i≤T f (1)(x ¯k+T j+i)

j
has at least one accumulation point
x∗and any accumulation point (according to the second condition) satisﬁes
∇f (0)(x∗) = 0 in addition to ∇f (1)(x∗) = 0.
Case 2: there exists a subsequence jk such that ∇f (1)(x jk) ̸= 0.
In this case we have that
f (1)(x jk+1) ≤f (1)(x jk) + σ
∇f (1)(x jk)


.
Again, taking into account that it is possible that for some index i bigger
than jk, ∇f (1)(xi) = 0
max
0≤i≤M f (1)(x jk+T j+i) ≤max
0≤i≤M f (1)(x jk+T ( j−1)+i) + σ
∇f (1)(x jk)


and hence, assuming again that the level sets for f (1)(x0) and f (0)(x0) are
compact sets, we have that ∇f (1)(x jk) goes to 0.
Moreover,

92
R. De Leone
max
0≤i≤L f (0)(x jk+Lj+i) ≤max
0≤i≤L f (0)(x jk+L( j−1)+i) + σ
∇f (0)(x jk)


and hence also ∇f (0)(x jk) goes to 0.
7
Conclusions
Penalty methods are an important and widely studied class of algorithms in
nonlinear optimization. Using penalty functions the solution of the original
constrained optimization problem could be obtained by solving an uncon-
strained problem. The main issues with this class of methods are exactness
and differentiability. In this chapter we presented some recent development
on penalty functions based on the use of ①. The solution of the proposed
unconstrained problem provides not only the solution of the original prob-
lem but also the Lagrangian dual variables associated to the constraints at no
additional cost, from the expansion of the constraints in terms of ①. Some
simple examples are also reported, showing the effectiveness of the method.
Finally a general non–monotone scheme is presented for the minimization
of functions that include ①grossterms.
References
1. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
2. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft. Comput.
24(23), 17751–17759 (2020)
3. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020)
4. Cococcioni,M.,Fiaschi,L.:TheBig-MmethodwiththenumericalinﬁniteM.Optim.
Lett. 15, 2455–2468 (2021)
5. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Towards lexicographic multi-
objective linear programming using grossone methodology. In: Y.D. Sergeyev, D.E.
Kvasov, F. Dell’Accio, M.S. Mukhametzhanov (eds.) Proceedings of the 2nd Inter-
national Conference. Numerical Computations: Theory and Algorithms, vol. 1776,
p. 090040. AIP Publishing, New York (2016)
6. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018)

The Role of grossone in Nonlinear Programming …
93
7. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput.
218(16), 8077–8082 (2012)
8. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
9. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
10. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft. Comput. 24(23), 17669–17677 (2020)
11. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: How grossone can be helpful
to iteratively compute negative curvature directions. In: Lecture Notes in Computer
Science (including subseries Lecture Notes in Artiﬁcial Intelligence and Lecture
Notes in Bioinformatics) 11353 LNCS, pp. 180–183 (2019)
12. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
13. Di Pillo, G., Grippo, L.: An exact penalty method with global convergence properties
for nonlinear programming problems. Math. Program. 36, 1–18 (1986)
14. Di Pillo, G., Grippo, L.: Exact penalty functions in constrained optimization. SIAM
J. Control Optim. 27(6), 1333–1360 (1989)
15. Fletcher, R.: Practical Methods of Optimization, 2nd edn. Wiley (1990)
16. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
17. Grippo, L., Lampariello, F., Lucidi, S.: A truncated Newton method with nonmono-
tone line search for unconstrained optimization. J. Optim. Theory Appl. 60(3), 401–
419 (1989)
18. Grippo, L., Sciandrone, M.: Nonmonotone globalization techniques for the Barzilai-
Borwein gradient method. Comput. Optim. Appl. 23(2), 143–169 (2002)
19. Grippo, L., Sciandrone, M.: Nonmonotone derivative-free methods for nonlinear
equations. Comput. Optim. Appl. 37(3), 297–328 (2007)
20. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation
of higher order Lie derivatives on the Inﬁnity Computer. J. Comput. Appl. Math.
383(113135) (2021)
21. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed Pareto-lexicographic multi-
objective optimization problems: the case of priority chains. Swarm Evol. Comput.
55 (2020)
22. Mangasarian, O.L.: Nonlinear programming. McGraw-Hill Series in Systems Sci-
ence. McGraw-Hill, New York (1969)
23. Margenstern, M.: An application of grossone to the study of a family of tilings of
the hyperbolic plane. Appl. Math. Comput. 218(16), 8005–8018 (2012)
24. Ortega, J.M., Rheinboldt, W.C.: Iterative solution of nonlinear equations in several
variables. Academic Press (1970)
25. Sergeyev, Y.D.: Numerical point of view on Calculus for functions assuming ﬁnite,
inﬁnite, and inﬁnitesimal values over ﬁnite, inﬁnite, and inﬁnitesimal domains. Non-
linear Anal. Ser. A: Theory, Methods Appl. 71(12), e1688–e1707 (2009)
26. Sergeyev, Y.D.: Higher order numerical differentiation on the inﬁnity computer.
Optim. Lett. 5(4), 575–585 (2011)
27. Sergeyev, Y.D.: On accuracy of mathematical languages used to deal with the Rie-
mann zeta function and the Dirichlet eta function. p-Adic Numbers, Ultrametric
Anal. Appl. 3(2), 129–148 (2011)

94
R. De Leone
28. Sergeyev, Y.D.: Using blinking fractals for mathematical modelling of processes of
growth in biological systems. Informatica 22(4), 559–576 (2011)
29. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
30. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
31. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.:
Numerical methods for solving initial value problems on the inﬁnity computer. Int.
J. Unconv. Comput. 12(1), 3–23 (2016)
32. Solodov, M.V.: Constraint qualiﬁcations. In: Wiley Encyclopedia of Operations
Research and Management Science. Wiley Online Library (2010)
33. Sun, W., Han, J., Sun, J.: Global convergence of nonmonotone descent methods for
unconstrained optimization problems. J. Comput. Appl. Math. 146(1), 89–98 (2002)
34. Wang, Z., Fang, S.C., Xing, W.: On constraint qualiﬁcations: motivation, design and
inter-relations. J. Ind. Manag. Optim. 9, 983–1001 (2013)
35. Zhang, H.C., Hager, W.W.: A nonmonotone line search technique and its application
to unconstrained optimization. SIAM J. Optim. 14(4), 1043–1056 (2004)

Krylov-Subspace Methods for
Quadratic Hypersurfaces: A
Grossone–based Perspective
Giovanni Fasano
Abstract We study the role of the recently introduced inﬁnite number
grossone, to deal with two renowned Krylov-subspace methods for symmet-
ric (possibly indeﬁnite) linear systems. We preliminarily explore the relation-
ship between the Conjugate Gradient (CG) method and the Lanczos process,
along with their speciﬁc role of yielding tridiagonal matrices which retain
large information on the original linear system matrix. Then, we show that on
one hand there is not immediate evidence of an advantage from embedding
grossone within the Lanczos process. On the other hand, coupling the CG
with grossone shows clear theoretical improvements. Furthermore, refor-
mulating the CG iteration through a grossone-based framework allows to
encompass also a certain number of Krylov-subspace methods relying on
conjugacy among vectors. The last generalization remarkably justiﬁes the
use of a grossone-based reformulation of the CG to solve also indeﬁnite
linear systems. Finally, pairing the CG with the algebra of grossone easily
provides relevant geometric properties of quadratic hypersurfaces.
1
Introduction
We consider the iterative solution of indeﬁnite linear systems by Krylov-
subspace methods. After a preliminary analysis, where a couple of renowned
methods are brieﬂy detailed and compared, we directly focus on those algo-
rithms based on the generation of conjugate vectors, and we disregard those
methods which rely on generating Lanczos vectors.
G. Fasano (B)
Department of Management, University Ca’ Foscari of Venice, Venice, Italy
e-mail: fasano@unive.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_4
95

96
G. Fasano
More speciﬁcally, we analyze the behaviour of the Conjugate Gradient
(CG) method in case of degeneracy, since it yields relevant implications when
solving symmetric linear systems within Nonconvex Optimization problems.
In this regard, the current literature on Krylov-subspace methods (see e.g.
[27]) reports plenty of applications in nonlinear programming, where the CG
is used and it can possibly prematurely halt on the solution of indeﬁnite linear
systems (e.g. Newton’s equation for nonconvex problems).
We recall that the CG iteratively computes the sequence {xk}, where xk
approximates at step k the solution of the symmetric linear system Ax = b,
being A ∈Rn×n. The stopping rule of the CG is based on a Ritz-Galerkin
condition, i.e. the norm of the current residual rk = b −Axk is checked, in
order to evaluate the quality of the current approximate solution xk. Unex-
pectedly, the unfortunate choice of the initial iterate x1 may cause a premature
undesired stop of the CG on speciﬁc indeﬁnite linear systems. As well known,
the last drawback may have a direct dramatic impact on optimization frame-
works: a so called gradient-related direction cannot be computed and possibly
inefﬁcient arrangements need to be considered. When a premature stop of
the CG occurs it corresponds to an unexpected numerical failure: namely a
division by a small quantity is involved. This situation is usually addressed
in the literature as a pivot breakdown, and corresponds to the fact that the
steplength along the current search direction selected by the CG tends to
be unbounded. As a consequence, the CG stops beforehand and the current
iterate xk may be far from a solution of the linear system (i.e. the quantity
∥rk∥might be signiﬁcantly nonzero).
This paper speciﬁcally addresses the pivot breakdown of the CG, from
a perspective suggested by the recent introduction of the numeral grossone
[37]. We urge to remark that a comprehensive description of the grossone-
based methodology can be found in [42], and it should be stressed that it is
not formally related to non-standard analysis (see [43]).
Our perspective is deﬁnitely unusual for the CG, since the literature of the
last decades has mainly focused on its performance and stability, rather than
on the way to recover its iteration in the indeﬁnite case. Nevertheless, we are
convinced that a proper investigation of the ultimate reasons of CG degener-
acy might pursue a couple of essential tasks:
• to recover the degeneracy and provide gradient-related directions within
optimization frameworks;
• to generate negative curvature directions, that allow convergence of opti-
mization methods to solutions satisfying second order necessary optimality
conditions.
As regards the organization of the paper, in Sect. 2 we detail similarities
and dissimilarities of two well known Krylov-subspace methods: namely

Krylov-Subspace Methods for Quadratic Hypersurfaces …
97
the CG and the Lanczos process. In Sect. 3 we describe one of the main
conclusions in the current paper, i.e. the use of grossone with the CG can
help overcoming problems of degeneracy in the indeﬁnite case. Section 4
contains details on the second relevant contribution of this paper, namely the
use of grossone for the iterative computation of negative curvature directions
in large scale (unconstrained) optimization frameworks, where the objective
function is twice continuously differentiable. Finally, a section of conclusions
will complete the paper.
As regards the symbols adopted in the paper, we use Rp to represent the set
of the real p-vectors, while for the sake of simplicity ∥x∥is used to indicate
theEuclideannormofthevector x,inplaceof∥x∥2.Giventhen-realvectors x
and y, with xT y we indicate their standard inner product in Rn. The symbol
f ∈Cℓ(A) indicates that the function f is ℓtimes continuously differen-
tiable on the set A. The symbol B ≻0 (respectively B ⪰0) indicates that
the square matrix B is positive deﬁnite (respectively semideﬁnite). Finally,
λM(A) (respectively λm(A)) represents the largest (respectively smallest)
eigenvalue of the square matrix A.
2
The CG Method and the Lanczos Process for Matrix
Tridiagonalization
Let us consider the solution of the symmetric linear system
Ax = b,
A ∈Rn×n,
(1)
where the matrix A is possibly indeﬁnite and nonsingular. As long as A in (1)
is positive deﬁnite, the CG method [26] iteratively provides a tridiagonaliza-
tion of it (see also [22]). A general description of the CG method for solving
(1) is reported in Table 1 [25], where rk+1 = b −Axk+1 and the sequences
{ri} and {pi} are such that after k + 1 iterations:
r T
i r j = 0,
i ̸= j ≤k + 1,
(orthogonality among {ri}),
r T
i p j = 0,
j < i ≤k + 1,
pT
i Ap j = 0,
i ̸= j ≤k + 1,
(conjugacy among {pi}).
Assume that after m steps the CG stops and rm+1 = 0 (i.e. a solution to the
linear system (1) is found), then setting

98
G. Fasano
Table 1 The CG method for solving (1) when A ≻0
Rm =
 r1
∥r1∥· · · rm
∥rm∥

∈Rn×m,
(2)
Pm =
 p1
∥r1∥· · · pm
∥rm∥

∈Rn×m,
(3)
along with
Lm =
⎛
⎜⎜⎜⎝
1
0
−√β1
...
...
...
0
−√βm−1 1
⎞
⎟⎟⎟⎠∈Rm×m,
(4)
and
Dm =
⎛
⎜⎜⎜⎜⎝
1
θ1
0
...
...
0
1
θm
⎞
⎟⎟⎟⎟⎠
∈Rm×m,
(5)
after an easy computation we have from (2)–(5)
PmLT
m = Rm,
(6)
APm = RmLm Dm,
(7)
APmLT
m = RmLm DmLT
m
=⇒
ARm = RmT CG
m
,
(8)
being T CG
m
= Lm DmLT
m ∈Rm×m the symmetric tridiagonal matrix

Krylov-Subspace Methods for Quadratic Hypersurfaces …
99
T CG
m
=
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
1
θ1
−
√β1
θ1
0
−
√β1
θ1

1
θ2 + β1
θ1
 ...
...
...
...
...

1
θm−1 + βm−2
θm−2

−
√βm−1
θm−1
0
−
√βm−1
θm−1

1
θm + βm−1
θm−1

⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
∈Rm×m.
(9)
Remark 1 Relation (8) underlies a three-term recurrence among the resid-
uals {ri}, being
A ri
∥ri∥∈span{ri−1,ri,ri+1},
i ∈{1, . . . , m}.
(10)
2.1
Basics on the Lanczos Process
Similarly to the previous section, let us now consider the Lanczos process
which is reported in Table 2. Unlike the CG method, it was initially conceived
to iteratively solve a symmetric eigenvalue problem in the indeﬁnite case [29],
so that after m steps it allows to reduce (8) into relation
AQm = QmT L
m ,
(11)
where A is the matrix in (1), Qm = (q1 · · · qm) and T L
m is again a tridiagonal
matrix, such that (Sturm sequence of tridiagonal matrices)
λm (A) ≤λm

T L
m

≤λm

T L
m−1

≤· · · ≤λM

T L
m−1

≤λM

T L
m

≤λM (A) .
Moreover, coupling the Lanczos process with a suitable factorization of the
matrix T L
m , the iterative solution of (1) can be pursued.
Indeed, given a symmetric indeﬁnite matrix A, after m ≥1 steps the Lanc-
zos process similarly to (2) generates the directions (the Lanczos vectors)
q1, . . . , qm satisfying the orthogonality properties
qT
i q j = 0,
i ̸= j ≤m.
In particular at step k ≤m of the iterative procedure, the basis {q1, . . . , qk} for
the Krylov subspace Kk(q1, A) .= span{q1, Aq1, . . . , Ak−1q1} is generated.
Then, as for the CG, the Lanczos process provides a basis of Kk(q1, A) which
is used to solve the problem

100
G. Fasano
Table 2 The Lanczos process for the tridiagonalization of (1), when A is possibly indef-
inite
min
x∈Kk(q1,A) ∥Ax −b∥.
Hence, since
dim [K1(q1, A)] < dim [K2(q1, A)] < · · · ,
in at most n iterations of the CG or the Lanczos process a sufﬁcient informa-
tion is available to compute the solution of (1).
Similarly to the CG (see (8)), in case at step m of the Lanczos process we
have qm+1 = 0 (i.e. Km(q1, A) ≡Km+1(q1, A)), then relation (11) holds,
where T L
m ∈Rm×m is the tridiagonal matrix
T L
m =
⎛
⎜⎜⎜⎝
α1 δ1
0
δ1 ...
...
...
... δm−1
0
δm−1 αm
⎞
⎟⎟⎟⎠,
and a conclusion similar to (10) holds, replacing Rm by Qm and T CG
m
by T L
m .
Moreover, at step k ≥1 of the Lanczos process we also have
T L
k
= QT
k AQk,
so that in case the Lanczos process performs n steps, the square matrix Qn
turns to be orthogonal and its columns span Rn.
On the other hand, since A is nonsingular the problem (1) is equivalent to
compute the stationary point of the quadratic functional

Krylov-Subspace Methods for Quadratic Hypersurfaces …
101
q(x) = 1
2xT Ax −bT x,
(12)
and the Lanczos method can be a natural candidate for its solution, too.
Indeed, if the Lanczos process stops at step m (i.e. δm = 0), then replacing
x = Qmz, with z ∈Rm, into (12) and recalling that q1 = b/∥b∥, we obtain:
∇q(z) = QT
m AQmz −QT
mb = T L
m z −∥b∥e1.
Hence, if the solution z∗of the tridiagonal system
T L
m z −∥b∥e1 = 0 ,
z ∈Rm,
(13)
is available, the point x∗= Qmz∗is both a solution of the original system
(1) and a stationary point of (12) over the Krylov subspace Km(b, A) =
span{q1, . . . , qm}.
2.2
How the CG and the Lanczos Process Compare: A Path
to Degeneracy
We urge to give some considerations about the comparison between the CG
and the Lanczos process, in the light of possibly introducing the issue of
degeneracy for both these algorithms:
• the Lanczos process properly does not solve the linear system (1); it rather
reformulates (1) into the tridiagonal one (13). This means that some further
calculations are necessary (i.e. a factorization for the matrix T L
m ) in order
to give the explicit solution of (13) and then backtracking to a solution of
(1). The CG (similarly for the CG-based methods in [14–16, 18] – see the
next sections) does not require the last two-step solution scheme, inasmuch
as at step k it at once decomposes the matrix T CG
k
and computes xk+1 as
xk+1 ∈argmin
x∈Kk(b,A) {∥Ax −b∥} ;
• since the solution z∗of (13) yields the solution x∗= Qmz∗of (1), for the
Lanczos process we apparently need to store the matrix Qm, in order to
calculate x∗. However, in case we are just interested about computing the
solution x∗, the storage of Qm can be avoided (see e.g. [27], the algorithm
SYMMLQ [35] and the algorithm SYMMBK [3]), by means of a suitable
recursion. On the other hand, in case the Lanczos process were also asked to
provide information on negative curvature directions associated with q(x)

102
G. Fasano
in (12), at x∗, then the storage of the full rank matrix Qm seems mandatory
(see also [30]) or an additional computational effort is required (see the
more recent paper [6]). Both the CG and the CG-based schemes reported
in this paper avoid the last additional effort. Hence, our great interest for
speciﬁcally pairing grossone with conjugacy.
We also recall that the tridiagonal matrices T CG
m
and T L
m are obtained in a
similar fashion, by the CG and the Lanczos process, respectively. However,
in general neither in case A ≻0 nor in the indeﬁnite case they coincide,
as extensively motivated in the paper [17]. Furthermore, the CG explicitly
performs the Cholesky-like factorization T CG
m
= Lm DmLT
m of T CG
m
in (8),
in order to solve the linear system (1). The last matrix decomposition always
exists when A ≻0; conversely, if A is indeﬁnite this decomposition exists if
and only if no pivot breakdown occurs, i.e. none of the diagonal entries of
Dm is near zero (which causes a premature stop of the CG).
On the contrary, if the Lanczos process is applied it cannot stop beforehand
also when A is indeﬁnite, because it does rely on any matrix factorization of
T L
m , meaning that no pivot breakdown can occur (see also [35]). Therefore,
the application of the Lanczos process is well-posed in the indeﬁnite case,
too. In the next sections we show that the last conclusion motivates the use of
grossone to handle pivot breakdown for the CG. Conversely, no immediate
application of grossone algebra for the Lanczos process seems advisable,
inasmuch as no breakdown opportunity can take place.
3
Coupling the CG with Grossone: A Marriage
of Interest
Here we motivate the importance of pairing the CG with grossone, in case
the system matrix A in (1) is indeﬁnite. We ﬁrst give a geometric viewpoint
of the CG degeneracy (see the next section), then we detail how to recover
the last degeneracy using grossone: this yields a general framework, that is
used to describe the issue of degeneracy also for several CG-based methods,
as detailed in [12].
3.1
The Geometry Behind CG Degeneracy
When the CG is applied to solve (1), with A indeﬁnite, by Sect. 2.2 a possible
degenerate or nearly degenerate situation may occur, namely pT
k Apk ≈0,

Krylov-Subspace Methods for Quadratic Hypersurfaces …
103
with pk ̸= 0. This implies a couple of results we report here, that will be
suitably reinterpreted in the next sections from an alternative standpoint,
using grossone.
Observe that when A is positive deﬁnite, at any Step k of the CG we
have 0 < λm(A)∥pk∥2 ≤pT
k Apk, so that pT
k Apk is suitably bounded from
below. Conversely, in case A is indeﬁnite (nonsingular), a similar bound does
not hold and possibly we might have pT
k Apk = 0, for a nonzero vector pk.
Furthermore, in order to better analyze the (near) degenerate case, when A
is indeﬁnite nonsingular and at Step k we have |pT
k Apk| ≥εk∥pk∥2, εk > 0,
with ∥pk∥, ∥pk+1∥< +∞, then (see also [15]) the angle αk,k+1 between the
vectors pk and pk+1 satisﬁes
π
2 −arccos

εk
|λM(A)|

≤|αk,k+1| ≤π
2 + arccos

εk
|λm(A)|

.
(14)
The two side inequality (14) suggests that pk and pk+1 may not become
parallel as long as the constant value εk is sufﬁciently bounded away from
zero. Conversely when pk and pk+1 tend to be parallel, it implies from (14)
that εk is approaching zero. As special cases, we report in Figs. 1 and 2 the
geometry of the directions when A ≻0 (Fig. 1) and A is indeﬁnite (Fig. 2),
respectively. In Fig. 1, when the eccentricity of the ellipse increases, then a
(near)degeneracymayoccur,butsince A ≻0 nodegeneracycanbeobserved,
i.e. pk and pk+1 cannot become parallel. On the contrary, in Fig. 2 we have A
indeﬁnite, so that at Step k of the CG we can experience a degeneracy, with
pT
k Apk = 0 andaprematureCGhalt.Equivalently,thepoint xk+1 approaches
a point at inﬁnity and the norm of ∥pk+1∥becomes unbounded; moreover
(see [12]), pk and pk+1 tend to become parallel.
3.2
A New Perspective for CG Degeneracy Using Grossone
This section details how the recently deﬁned extension of real numbers based
on grossone (see e.g. [1, 7, 21, 28, 32, 36–41, 45], along with the related
applications in optimization frameworks [2, 4, 5, 8–12, 23]), can be suitably
used to model the CG degeneracy. In particular, we show that:
• adopting grossone algebra within the CG allows to recover the CG degen-
eracy in the indeﬁnite case;
• coupling the CG with grossone provides results which exactly match the
analysis carried on for the CG-based methods in [14, 31];

104
G. Fasano
Fig. 1 The geometry behind the conjugate directions pk and pk+1: when A ≻0 in (1)
then without loss of generality in (14) we have εk ≥λm(A) > 0
• ourapproachconﬁrmsthegeometrybehindCGdegeneracyintheindeﬁnite
case, as underlined by polarity for quadratic hypersurfaces (see also Fig. 2
and [18]).
On this purpose, let us consider the computation of the steplength θk at Step
k of Table 1. Then, we set
pT
k Apk = s①,
(15)
where
• s = O(①−1) if the Step k is a non-degenerate CG step (i.e. if pT
k Apk ̸= 0),
• s = O(①−2) if the Step k is a degenerate CG step (i.e. if pT
k Apk = 0).
In the last setting, following the standard Landau-Lifsitz notation we indicate
with the symbol O(①−2) a term containing powers of ①at most equal to −2.
Observe that in the last case, standard results for grossone imply that the ﬁnite
part of pT
k Apk equals zero (or equivalently pT
k Apk is inﬁnitesimal). To large
extent, the grossone-based expression on the righthand side of (15) can be
further generalized; nevertheless, the setting (15) both seems simple enough
and adequate to prove that the axioms and the basic algebra of grossone are
well-suited to detail the behaviour of the CG, in the degenerate case.

Krylov-Subspace Methods for Quadratic Hypersurfaces …
105
Fig. 2 The geometry of conjugate directions with A indeﬁnite nonsingular in (1): since
|pT
h Aph| is sufﬁciently bounded away from zero then ph and ph+1 are conjugate and
do not tend to become parallel. Conversely, when pT
k Apk ≈0 then pk and pk+1 tend to
become parallel
In particular, a remarkable aspect of our approach is that using grossone
to cope with CG degeneracy does not require to alter the scheme in Table 1,
which is therefore almost faithfully applied ‘as is’. This represents an
undoubted advantage with respect to the CG-based methods (namely pla-
nar methods) in [14–16, 25, 31], that indeed need to suitably rearrange the
CG iteration in order to dodge degeneracy. The consequence of introducing
grossone in Table 1 is analyzed in the next Sect. 3.3, where in case of CG
degeneracy at Step k, the expressions of the coefﬁcients and vectors at Step
k explicitly depend on ①and its powers.
3.3
Grossone for the Degenerate Step k of the CG
From Table 1, the position (15) and the properties of the CG, when A is
indeﬁnite and the Step k is degenerate we have

106
G. Fasano
rk+1 = rk −θk Apk = rk −∥rk∥2
s①Apk,
(16)
so that after a few arrangements (see [12])
pk+1 = rk+1 + βk pk = −βk−1 pk−1 −∥rk∥2
s①Apk + ∥rk∥2∥Apk∥2
s2①2
pk.
(17)
We highlight that the CG degeneracy implies s①to be inﬁnitesimal, so that
∥pk+1∥tends to be unbounded. The last result matches the geometric perspec-
tive reported in Sect. 3.1. Then, from (17) and the orthogonality/conjugacy
conditions among vectors generated by the CG we can also infer
r T
i r j = 0,
pT
i Ap j = 0,
∀i ̸= j,
along with
pT
k+1Apk+1 = ∥rk∥4
s2①2 (Apk)T A(Apk) −∥rk∥4∥Apk∥4
s3①3
+ O(①),
(18)
(we recall that O(①) in (18) sums up powers of ①equal to +1 and 0), and
r T
k+1 pk+1 = −∥rk∥2 + ∥rk∥4∥Apk∥2
s2①2
.
(19)
From (16), (18)–(19) and recalling that when pT
k Apk is inﬁnitesimal so does
s①, we obtain after some computation
rk+2 = rk −∥rk∥2
∥Apk∥2 A(Apk) −βk−1
s①
∥Apk∥2 Apk−1 + O(①−1).
(20)
A noteworthy consequence of (16)–(17) and (20) is that in practice
• r1, . . . ,rk are independent of ①,
• rk+1 and pk+1 heavily depend on ①,
• rk+2 is independent of negative powers of s①.
Thus, the geometric drawback detailed in Sect. 3.1, i.e. the CG degeneracy
in the indeﬁnite case, can be bypassed by exploiting the simple grossone
algebra and neglecting the (inﬁnitesimal) term with s①in (20). This leaves
the steps in the CG scheme of Table 1 fully unchanged.
Similarly, as regards the computation of the search direction pk+2, by (16),
(17) and (20) we have after some arrangements

Krylov-Subspace Methods for Quadratic Hypersurfaces …
107
pk+2 = rk −∥rk∥2
∥Apk∥2 A(Apk) + ∥rk+2∥2
∥rk∥2 pk −βk−1
s①
∥Apk∥2 Apk−1 + O(①−1).
(21)
Thus, similarly to rk+2, in case of CG degeneracy also pk+2 is independent
of negative powers of ①(i.e. equivalently ∥pk+2∥< +∞, so that grossone
algebra is able to bypass the degeneracy, recovering the CG iteration). After
some computations it is also not difﬁcult to verify that the vectors rk+1, pk+1,
rk+2, pk+2 in (16), (17), (20) and (21) satisfy the standard CG properties
⎧
⎨
⎩
r T
k+2ri = 0,
i = 1, . . . , k + 1,
pT
k+2Api = 0,
i = 1, . . . , k + 1.
(22)
An additional remarkable comment from (21) is that, neglecting the terms
which contain powers of s①larger or equal to 1 (i.e. neglecting inﬁnitesi-
mals in (21)), the vector pk+2 coincides with the one obtained in Algorithm
CG_Plan of [14] (a similar result holds considering the algorithm by Luen-
berger in [31], too). Therefore, the use of grossone to cope with a CG degen-
eracy at Step k does not simply recover the theory and the results in [14,
31], but it also retrieves the same scaling of the generated search directions,
which is a so relevant issue for large scale problems.
Also note that the expression of pk+1 in (17) explicitly includes negative
powers of s①, showing that to large extent it can be assimilated to a vector
with an unbounded norm, in accordance with Fig. 2, where xk+1 is a point at
inﬁnity.
Now, let us compute the iterate xk+2, to verify to which extent using
grossone may recover the CG iteration in case of degeneracy at Step k. By
Table 1 and [12], and using
xk+2 = xk + θk pk + θk+1 pk+1
we obtain the ﬁnal expression
xk+2 = xk + ∥rk∥2
∥Apk∥2 Apk −∥rk∥2
∥Apk∥4 (Apk)T A(Apk)pk + O(①−1), (23)
which perfectly matches the expression of xk+2 computed in [14, 31], as
long as O(①−1) is neglected. Therefore, in case of CG degeneracy at Step k,
using grossone does not simply recover the residuals and search directions as
in (22), but it also recovers the iterate xk+2, since it is independent of grossone.
Table 3 gives a formal description of CG①, i.e. the CG method where ①is

108
G. Fasano
Table 3 The CG①algorithm for solving the symmetric indeﬁnite linear system Ax = b.
In a practical implementation of Step k of CG①, the test pT
k Apk ̸= 0 may be replaced
by the inequality |pT
k Apk| ≥εk∥pk∥2, with εk > 0 small
introduced in case of degeneracy, while Proposition 1 summarizes the results
in the current section.
Proposition 1 Let be given the indeﬁnite linear system Ax = b, with A ∈
Rn×n and n large. Suppose the CG①method in Table 3 is applied for its
solution, using the position (15). In case at Step k ≤n the quantity |pT
k Apk|
is bounded away from zero, then the vectors generated by CG①exactly
preserve the same properties of the corresponding vectors generated by the
CG method in Table 1. Conversely, in case at Step k we have pT
k Apk ≈0,
then the vectors xk+2 in (23) and pk+2 in (21) computed by the CG①differ
by inﬁnitesimals from the corresponding vectors computed by the CG_Plan
in [14] (or by the algorithm in [31]).
4
Large Scale (unconstrained) Optimization Problems:
The Need of Negative Curvatures
The solution of indeﬁnite linear systems like (1) is almost ubiquitous in both
constrained and unconstrained optimization frameworks. E.g. the iterative
solution of the following problem

Krylov-Subspace Methods for Quadratic Hypersurfaces …
109
min
x∈Rn f (x),
(24)
where f is twice continuously differentiable and n is large, requires in a
uniﬁed framework (i) to solve the associated Newton’s equation (ﬁrst order
methods)
∇2 f (x j) s = −∇f (x j),
(25)
and (ii) to identify those minima among the stationary points (second order
methods – see also [6]). The task (ii) is often accomplished by selecting
promising negative curvature directions for the function f at the current
iterate x j. In particular, for the sake of clarity here we restrict our attention to
the Truncated Newton methods, that represent an efﬁcient class of iterative
methods to solve (24). Among them, the second order methods often rely
on the theory in the seminal papers [33, 34], in order to assess algorithms
generating negative curvature directions and converging to solutions where
the Hessian matrix is positive semideﬁnite.
4.1
A Theoretical Path to the Assessment of Negative
Curvature Directions
On the guidelines of the previous section, and with reference to [34], a
sequence {d j} of effective negative curvature directions can be generated
in accordance with the following assumption.
Assumption 1 Let us consider the optimization problem (24), with f ∈
C2(Rn); the nonascent directions in the sequence {d j} are bounded and sat-
isfy (see also [30])
(a) ∇f (x j)T d j ≤0, dT
j ∇2 f (x j)d j ≤0,
(b) if lim j→∞dT
j ∇2 f (x j)d j = 0 then lim j→∞min

0, λm

∇2 f (x j)

=
0.
□
In practice, (a) in Assumption 1 claims that at x j the nonascent vector
d j cannot be a positive curvature direction for f . Conversely, condition (b)
prevents the asymptotic convergence of the iterative algorithm to a region of
concavity for the objective function. Evidently, on convex problems eventu-
ally the solutions of (24) both fulﬁll Newton’s equation and satisfy second
order stationarity conditions, without requiring the computation of negative
curvature directions.
We remark that even in case the current iterate x j is far from a station-
ary point, the use of the negative curvature direction d j may considerably

110
G. Fasano
enhance efﬁciency in Truncated Newton methods. The latter fact was clearly
evidenced in [19, 24, 30], and follows by considering at x j the quadratic
expansion along the vector d
q j(d) = f (x j) + ∇f (x j)T d + 1
2dT ∇2 f (x j)d,
which implies for the directional derivative of q j(d)
∇q j(d)T d = ∇f (x j)T d + dT ∇2 f (x j)d.
Thus, ∇q j(d)T d may strongly decrease both when d is of descent for f at
x j and is a negative curvature direction for f at x j.
On large scale problems, we highlight that computing effective negative
curvature directions for f at x j, fulﬁlling Assumption 1, is a challenging
issue, but it may become an easier task as long as proper factorizations
of ∇2 f (x j) are available. Indeed, suppose at x j the nonsingular matrices
M j ∈Rn×k and C j, Q j, B j ∈Rk×k are available such that
MT
j ∇2 f (x j)M j = C j,
C j = Q j B j QT
j .
(26)
Then,for y ∈Rk andassumingthatw ∈Rk isaneigenvectorof B j associated
with the negative eigenvalue λ < 0, relations (26) yield
(M j y)T ∇2 f (x j)(M j y) = yT 
MT
j ∇2 f (x j)M j

y = yT C j y
= (QT
j y)T B j(QT
j y) = wT B jw = λ∥w∥2 < 0,
so that d j = M j y represents a negative curvature direction for f at x j. Fur-
thermore, if λ is the smallest negative eigenvalue of B j, then M j y also rep-
resents an eigenvector of ∇2 f (x j) associated to it.
The most renowned Krylov-subspace methods for symmetric indeﬁnite
linear systems (i.e. SYMMLQ, SYMMBK, CG, Planar-CG methods [15–
17]) are all able to provide the factorizations (26) (i.e. they fulﬁll item (a)
in Assumption 1) when applied to Newton’s equation at x j. Nevertheless,
fulﬁlling also (b) and the boundedness of the sequence of negative curvature
directions is deﬁnitely a less trivial task (see e.g. the counterexample in Sect.
4 of [34]).
In this regard, we highlight that, under mild assumptions, by the use of
grossone (namely CG①in Table 3) we can easily yield an implicit Hessian
matrix factorization as in (26), fulﬁlling both (a) and (b), as well as the
boundedness of the negative curvature directions {d j} in Assumption 1. To

Krylov-Subspace Methods for Quadratic Hypersurfaces …
111
accomplish this last task we need the next result (the proof follows from
Lemma 4.3 in [34] and Theorem 3.2 in [20]).
Lemma 1 Let problem (24) be given with f ∈C2(Rn), and consider any
iterative method for solving (24), which generates the sequence {x j}. Let the
level set L0 = {x ∈Rn : f (x) ≤f (x0)} be compact, being any limit point
¯x of {x j} a stationary point for (24), with
λ[∇2 f (¯x)]
 > ¯λ > 0. Suppose
n iterations of a Newton-Krylov method are performed to solve Newton’s
equation (25) at iterate x j, so that the decompositions
RT
j ∇2 f (x j)R j = Tj,
Tj = L j B j LT
j
(27)
are available. Moreover, suppose R j ∈Rn×n is orthogonal, Tj ∈Rn×n has
the same eigenvalues of ∇2 f (x j), with at least one negative eigenvalue, and
L j, B j ∈Rn×n are nonsingular. Let ¯z be the unit eigenvector corresponding
to the smallest eigenvalue of B j, and let ¯y ∈Rn be the (bounded) solution
of the linear system LT
j y = ¯z. Then, the vector d j = R j ¯y is bounded and
satisﬁes Assumption 1.
However, three main insidious drawbacks arise from Lemma 1:
• both computing the eigenvector ¯z of B j and solving the linear system
LT
j y = ¯z might not be considered easy tasks;
• the vector ¯y should be provably bounded (equivalently | det(L j)| should
be bounded away from zero, for any j ≥1);
• at iterate x j the Newton-Krylov method adopted to solve (25) possibly
does not perform exactly n iterations.
4.2
CG①for the Computation of Negative Curvature
Directions
Though the third issue raised in the end of the previous section remains of
great theoretical interest, in practice when the sequence {x j} is approaching
a stationary point, then we typically observe that Newton-Krylov methods
tend to perform a large number of iterations to solve (25). On the contrary,
the ﬁrst two issues in the end of the previous section may be deﬁnitely more
challenging, since they can be tackled only by a few Krylov-subspace meth-
ods, due to the structure and the complexity of the generated matrices L j
and B j in Lemma 1. In our approach (see also [11] for more complete jus-
tiﬁcations), we can provably show that the use of CG①can fruitfully fulﬁll
all the hypotheses of Lemma 1. In particular, in the current section we detail

112
G. Fasano
how to couple the Krylov-subspace method in [14] with CG①, in the light
of complying with the hypotheses of Lemma 1. Broadly speaking, observe
that the Krylov-subspace method in [14] is basically a CG-based algorithm
which performs exactly the CG iterations, as long as no degeneracy is experi-
enced. On the contrary, in case at Step k the breakdown condition pT
k Apk ≈0
occurs, a so called planar step is carried on to equivalently replace the Steps
k and k + 1 of the CG. Hence the taxonomy of planar method.
Assume without loss of generality that the Krylov-subspace method in
[14] has performed n steps. Moreover, for the sake of simplicity hereafter in
this section we drop the dependency of matrices on the iterate subscript j.
After some computation the following matrices are generated by the method
in [14] (see also [13])
L =
⎛
⎜⎜⎝
L11
0
0
L21
L22
0
0
L32
L33
⎞
⎟⎟⎠,
B =
⎛
⎜⎜⎝
B11
0
0
0
B22
0
0
0
B33
⎞
⎟⎟⎠,
where
L11 =
⎛
⎜⎝
1
−√β1
...
...
1
⎞
⎟⎠, L21 =
 0 · · · −√βk−1
0 · · ·
0

, L22 =
 1
0
0
1

,
(28)
L32 =
⎛
⎜⎜⎜⎝
−√βkβk+1
0
...
...
0
0
⎞
⎟⎟⎟⎠, L33 =
⎛
⎜⎜⎜⎝
1
−√βk+2
...
...
1
−√βn−1
1
⎞
⎟⎟⎟⎠,
(29)
and
B11 =
⎛
⎜⎜⎜⎝
1
α1
0
...
0
1
αk−1
⎞
⎟⎟⎟⎠,
B22 =

0
√βk
√βk
ek+1

,
B33 =
⎛
⎜⎜⎜⎝
1
αk+2
0
...
0
1
αn
⎞
⎟⎟⎟⎠,
(30)
such that
AR = RT,
T = L BLT ,
(31)
being the matrix R ∈Rn×n orthogonal with

Krylov-Subspace Methods for Quadratic Hypersurfaces …
113
R =
 r1
∥r1∥· · ·
rn
∥rn∥

,
(32)
and rk+1 = Apk, while T ∈Rn×n is tridiagonal. Moreover, the quantities
{αi}, {βi}, ek+1 in (28)–(30) are suitable scalars (being in particular ek+1 =
(Apk)T A(Apk)/
∥Apk∥2). We also recall that βi > 0, for any i ≥1.
Furthermore, to simplify our analysis, the above matrices L and B are
obtainedapplyingthemethodin[14],assumingthatitperformedallCGsteps,
with the exception of only one planar iteration (namely the k-th iteration),
corresponding to have indeed pT
k Apk ≈0. Then, our approach ultimately
consists to introduce the numeral grossone, to exploit a suitable matrix fac-
torization in place of (31), such that Lemma 1 is fulﬁlled. To this purpose, let
us consider again the algorithm CG①in Table 3 (see also [12]), and assume
that at Steps k and k + 1 it generated the coefﬁcients αk and αk+1. Thus, we
have1
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
1
αk
=
s①
∥rk∥2
1
αk+1
= −∥Apk∥2
s①
.
(33)
Moreover, using the equivalence in Table 4 between the quantities computed
by the algorithm in [14] and CG①, we can compute the matrices
ˆL =
⎛
⎜⎜⎜⎜⎝
L11
0
0
L21
VkC−1
k
0
0
ˆL32
L33
⎞
⎟⎟⎟⎟⎠
,
ˆD =
⎛
⎜⎜⎜⎜⎝
B11
0
0
0
ˆB22
0
0
0
B33
⎞
⎟⎟⎟⎟⎠
,
(34)
where L11, L21, are deﬁned in (28), L33 in (29), B11, B33 in (30), and
ˆL32 =
⎛
⎜⎜⎜⎜⎜⎝

−√βkβk+1
0

· VkC−1
k
...
0
⎞
⎟⎟⎟⎟⎟⎠
,
ˆB22 =
⎛
⎜⎜⎜⎝
1
αks①
0
0
s①
αk+1
⎞
⎟⎟⎟⎠,
1 More correctly, we urge to remark that the expressions (33) are obtained neglecting in
the quantity αk+1 the inﬁnitesimal terms, i.e. those terms containing negative powers of
s①, that are indeed negligibly small due to the degenerate Step k in CG①.

114
G. Fasano
Table 4 Correspondence between quantities/vectors computed by the algorithm in [14]
(left) and the algorithm CG①in [12] (right)
Algorithm in [14]
CG①in [12]
ri,
i = 1, . . . , k
ri,
i = 1, . . . , k
rk+1
Apk
ri,
i ≥k + 2
ri,
i ≥k + 2 (neglecting the terms with
s①)
pi,
i = 1, . . . , k
pi,
i = 1, . . . , k
pk+1
Apk
∥Apk∥
pi,
i ≥k + 2
pi,
i ≥k + 2 (neglecting the terms with
s①)
αi,
i = 1, . . . , k
αi,
i = 1, . . . , k
αi,
i ≥k + 2
αi,
i ≥k + 2 (neglecting the terms with
s①)
βi,
i = 1, . . . , k −1
βi,
i = 1, . . . , k −1
βk
∥Apk∥2
∥rk∥2
βi,
i ≥k + 1
βi,
i ≥k + 1 (neglecting the terms with
s①)
with
VkC−1
k
=
⎛
⎜⎜⎜⎝
∥rk∥√βkλk

βk+λ2
k
√−βkλk+1
∥Apk∥

βk+λ2
k+1
∥rk∥λk
√λk

βk+λ2
k
λk+1
√−λk+1
∥Apk∥

βk+λ2
k+1
⎞
⎟⎟⎟⎠
and λk, λk+1 are the eigenvalues of B22 in (30). Thus, in Lemma 1 we have
for matrix Tj the novel expression (see also (31))
Tj = L BLT = ˆL ˆD ˆLT .
We are now ready to compute at iterate x j the negative curvature direction
d j which complies with Assumption 1, exploiting the decomposition Tj =

Krylov-Subspace Methods for Quadratic Hypersurfaces …
115
ˆL ˆD ˆLT from Lemma 1. The next proposition, whose proof can be found in
[11], summarizes the last result.
Proposition 2 Suppose n iterations of CG①algorithm are performed to
solve Newton’s equation (25), at iterate x j, so that the decompositions
RT ∇2 f (x j)R = T,
T = ˆL ˆD ˆLT
exist, where R is deﬁned in (32), and ˆL along with ˆD are deﬁned in (34). Let
ˆz be the unit eigenvector corresponding to the (negative) smallest eigenvalue
of ˆD, and let ˆy be the solution of the linear system ˆLT y = ˆz. Then, the vector
d j = R ˆy is bounded and satisﬁes Assumption 1. In addition, the computation
of d j requires the storage of at most two n-real vectors.
Observe that the computation of the negative curvature direction d j
requires at most the additional storage of a couple of vectors, with respect to
the mere computation of a solution for Newton’s equation at x j. This con-
ﬁrms the competitiveness with respect to the storage required in [20]. Thus,
the approach in this paper does not only prove to be applicable to large-scale
problems, but it also simpliﬁes the theory in [20]. We remark that the theory
in [20] is, to our knowledge, the only proposal in the literature of iterative
computation of negative curvature directions for large-scale problems, such
that
• it does not rely on any re-computation of quantities (as in [24]),
• it does not require any full matrix factorization,
• it does not need any matrix storage.
5
Conclusions
We propose an unconventional approach for a twofold purpose, within large-
scale nonconvex optimization frameworks. On one hand we consider the
efﬁcient solution of symmetric linear systems. On the other hand, our pro-
posal is also able to generate negative curvature directions for the objective
function, allowing convergence towards stationary points satisfying second
order necessary optimality conditions. Our idea exploits the simplicity of
the algebra associated with the numeral grossone [37], which was recently
introduced in the literature.
The theory in this paper also guarantees that the iterative computation
of negative curvatures does not need any matrix storage, while preserving
convergence. In addition, the proposed approach is independent under mul-
tiplication of the function by a positive scaling constant or adding a shifting

116
G. Fasano
constant. This is an important property that is specially exploited in global
optimization frameworks (see e.g. [44, 45]), where strongly homogeneous
algorithms are deﬁnitely appealing.
Acknowledgements The author is thankful to the Editors of the present volume for their
great efforts and constant commitment. The author is also grateful for the support he
received by both the National Research Council–Marine Technology Research Institute
(CNR-INM), and the National Research Group GNCS (Gruppo Nazionale per il Calcolo
Scientiﬁco) within INδAM, Istituto Nazionale di Alta Matematica, Italy.
References
1. Antoniotti, L., Caldarola, F., Maiolo, M.: Inﬁnite numerical computing applied to
Hilbert’s, Peano’s, and Moore’s curves. Mediterr. J. Math. 17(3) (2020)
2. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft Comput.
24, 17751–17759 (2020)
3. Chandra, R.: Conjugate gradient methods for partial differential equations. Ph.D.
thesis, Yale University, New Haven (1978)
4. Cococcioni,M.,Fiaschi,L.:TheBig-MmethodwiththenumericalinﬁniteM.Optim.
Lett. 15(7) (2021)
5. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018)
6. Curtis, F., Robinson, D.: Exploiting negative curvature in deterministic and stochastic
optimization. Math. Program. 176, 69–94 (1919)
7. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. Soft Comput. 55, 143–
158 (2020)
8. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
9. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
10. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft Comput. 24, 17669–17677 (2020)
11. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based com-
putationofnegativecurvaturedirectionsinlarge-scaleoptimization.J.Optim.Theory
Appl. 186(2), 554–589 (2020)
12. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
13. Fasano, G.: Planar-CG methods and matrix tridiagonalization in large scale uncon-
strained optimization. In: Di Pillo, G., Murli, A. (eds.) In: High Performance Algo-
rithms and Software for Nonlinear Optimization. Kluwer Academic Publishers, New
York (2003)
14. Fasano, G.: Conjugate Gradient (CG)-type method for the solution of Newton’s
equation within optimization frameworks. Optim. Methods Softw. 19(3–4), 267–
290 (2004)

Krylov-Subspace Methods for Quadratic Hypersurfaces …
117
15. Fasano, G.: Planar-Conjugate gradient algorithm for large scale unconstrained opti-
mization, part 1: theory. J. Optim. Theory Appl. 125(3), 523–541 (2005)
16. Fasano, G.: Planar-Conjugate gradient algorithm for large scale unconstrained opti-
mization, part 2: application. J. Optim. Theory Appl. 125(3), 543–558 (2005)
17. Fasano, G.: Lanczos conjugate-gradient method and pseudoinverse computation on
indeﬁnite and singular systems. J. Optim. Theory Appl. 132(2), 267–285 (2007)
18. Fasano, G.: A framework of conjugate direction methods for symmetric linear sys-
tems in optimization. J. Optim. Theory Appl. 164(3), 883–914 (2015)
19. Fasano, G., Lucidi, S.: A nonmonotone truncated Newton-Krylov method exploiting
negative curvature directions, for large scale unconstrained optimization. Optim.
Lett. 3(4), 521–535 (2009)
20. Fasano, G., Roma, M.: Iterative computation of negative curvature directions in large
scale optimization. Comput. Optim. Appl. 38(1), 81–104 (2007)
21. Fiaschi, L., Cococcioni, M.: Numerical asymptotic results in game theory using
Sergeyev’s Inﬁnity Computing. Int. J. Unconv. Comput. 14(1) (2018)
22. Fletcher, R.: Conjugate gradient methods for indeﬁnite systems. In: Watson G.A.
(ed.), Proceedings of the Dundee Biennal Conferences on Numerical Analysis.
Springer, Berlin Heidelberg New York (1975)
23. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
24. Gould, N., Lucidi, S., Roma, M., Toint, P.: Exploiting negative curvature directions
in linesearch methods for unconstrained optimization. Optim. Methods Softw. 14,
75–98 (2000)
25. Hestenes, M.: Conjugate Direction Methods in Optimization. Springer, New York,
Heidelberg, Berlin (1980)
26. Hestenes, M., Stiefel, E.: Methods of conjugate gradients for solving linear systems.
J. Res. Nat. Bur. Stand. 49, 409–436 (1952)
27. Higham, N.: Accuracy and Stability of Numerical Algorithms. SIAM, Philadelphia
(1996)
28. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation of
higher order Lie derivatives on the Inﬁnity Computer. J. Comput. Appl. Math. 383
(2021)
29. Lanczos, C.: An iterative method for the solution of the eigenvalue problem of linear
differential and integral operators. J. Res. Nat. Bureau Stand. 45(4), Research Paper
2133 (1950)
30. Lucidi, S., Rochetich, F., Roma, M.: Curvilinear stabilization techniques for Trun-
cated Newton methods in large scale unconstrained optimization. SIAM J. Optim.
8(4), 916–939 (1999)
31. Luenberger, D.G.: Hyperbolic Pairs in the method of conjugate gradients. SIAM J.
Appl. Math. 17, 1263–1267 (1996)
32. Mazzia, F., Sergeyev, Y.D., Iavernaro, F., Amodio, P., Mukhametzhanov, M.S.:
Numerical methods for solving ODEs on the Inﬁnity Computer. In: Sergeyev, Y.D.,
Kvasov, D.E., Dell’Accio, F., Mukhametzhanov, M.S. (eds.) Proceedings of the
2nd International Conferences “Numerical Computations: Theory and Algorithms”,
vol. 1776, p. 090033. AIP Publishing, New York (2016)
33. McCormick, G.: A modiﬁcation of Armijo’s step-size rule for negative curvature.
Math. Program. 13(1), 111–115 (1977)
34. Moré, J., Sorensen, D.: On the use of directions of negative curvature in a modiﬁed
Newton method. Math. Program. 16, 1–20 (1979)

118
G. Fasano
35. Paige, C., Saunders, M.: Solution of sparse indeﬁnite systems of linear equations.
SIAM J. Numer. Anal. 12, 617–629 (1975)
36. Pepelyshev, A., Zhigljavsky, A.: Discrete uniform and binomial distributions with
inﬁnite support. Soft Comput. 24, 17517–17524 (2020)
37. Sergeyev, Y.D.: Arithmetic of Inﬁnity. Edizioni Orizzonti Meridionali, CS, 2nd ed.
(2013)
38. Sergeyev, Y.D.: Lagrange Lecture: methodology of numerical computations with
inﬁnities and inﬁnitesimals. Rendiconti del Seminario Matematico dell’Università e
del Politecnico di Torino 68(2), 95–113 (2010)
39. Sergeyev, Y.D.: Higher order numerical differentiation on the Inﬁnity Computer.
Optim. Lett. 5(4), 575–585 (2011)
40. Sergeyev, Y.D.: Computations with grossone-based inﬁnities. In: Calude, C.S., Din-
neen, M.J. (eds.), Unconventional Computation and Natural Computation: Proceed-
ings of the 14th InternationalConference UCNC2015, LNCS, vol. 9252 , pp. 89–106.
Springer, New York (2015)
41. Sergeyev, Y.D.: Un semplice modo per trattare le grandezze inﬁnite ed inﬁnitesime.
Matematica nella Società e nella Cultura: Rivista della Unione Matematica Italiana
8(1), 111–147 (2015)
42. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
43. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1) (2019)
44. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: On strong homogeneity of a
class of global optimization algorithms working with inﬁnite and inﬁnitesimal scales.
Commun. Nonlinear Sci. Numer. Simul. 59, 319–330 (2018)
45. Žilinskas, A.: On strong homogeneity of two global optimization algorithms based on
statistical models of multimodal objective functions. Appl. Math. Comput. 218(16),
8131–8136 (2012)

Multi-objective Lexicographic
Mixed-Integer Linear Programming:
An Inﬁnity Computer Approach
Marco Cococcioni, Alessandro Cudazzo, Massimo Pappalardo,
and Yaroslav D. Sergeyev
Abstract In this chapter we show how a lexicographic multi-objective lin-
ear programming problem (LMOLP) can be transformed into an equivalent,
single-objective one, by using the Grossone Methodology. Then we provide
a simplex-like algorithm, called GrossSimplex, able to solve the original
LMOLP problem using a single run of the algorithm (its theoretical correct-
ness is also provided). In the second part, we tackle a Mixed-Integer Lexi-
cographic Multi-Objective Linear Programming problem (LMOMILP) and
we solve it in an exact way, by using a Grossone-version of the Branch-and-
Bound scheme (called GrossBB). After proving the theoretical correctness
M. Cococcioni (B)
Dipartimento di Ingegneria dell’Informazione, (University of Pisa), Largo Lucio
Lazzarino, 1, 56122 Pisa, Italy
e-mail: marco.cococcioni@unipi.it
A. Cudazzo · M. Pappalardo
Dipartimento di Informatica, (University of Pisa), Largo B. Pontecorvo, 3, 56127 Pisa,
Italy
e-mail: a.cudazzo1@studenti.unipi.it
M. Pappalardo
e-mail: massimo.pappalardo@unipi.it
Y. D. Sergeyev
Dipartimento di Ingegneria Informatica, Modellistica, Elettronica e Sistemistica,
(University of Calabria), via P. Bucci, Cubo 41-C, 87036 Rende, Italy
e-mail: yaro@dimes.unical.it
Lobachevsky State University, Nizhny Novgorod, Russia
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_5
119

120
M. Cococcioni et al.
of the associated pruning rules and terminating conditions, we show a few
experimental results, run on an Inﬁnity Computer simulator.
1
Introduction
In this contribution we survey recent achievements in the ﬁeld of lexico-
graphic linear programming by providing a coherent mathematical frame-
work for the main results obtained in [2, 6].
Lexicographic multi-objective optimization problem consists of ﬁnding
the solution that optimizes the ﬁrst (most important) objective and, only if
there are multiple equally-optimal solutions, ﬁnd the one that optimizes the
second most important objectives, and so on.
Lexicographic Multi-Objective Linear Programming (LMOLP) consists
of the solution of an optimization problem having multiple linear objective
function, sorted in order of priority (lexicographic property), over a region
deﬁned by linear constraints. If the search region is closed, bounded and
not empty, then at least one solution exists. Sometimes the solution is also
unique, despite the fact the problem is multi-objective. This is due to the
lexicographic property. Indeed, while a Pareto Multi-Objective LP problem in
general admits multiple Pareto optimal solutions (non-dominated solutions),
the lexicographic attribute tends to reduce the number of solutions to a single
optimal one.
In this book chapter we present a technique, based on Grossone [26], to
transform an LMOLP problem into a single objective one (this technique is
known as scalarization). Then we present a generalization of the simplex
algorithm, that we have called GrossSimplex algorithm, which is able to
solve the Grossone-based and scalarized single-objective LP problem. After
showing an illustrative LMOLP problem, solved by the GrossSimplex algo-
rithm, we move to introduce the LMOMILP problem. Then we show how
to solve it by using a Grossone-based extension of the well-known Branch-
and-Bound method: we called this algorithm GrossBB. Finally we present
some test problems having a known solution, and then we demonstrate that
the GrossBB algorithm, coupled with the GrossSimplex, is able to correctly
solve all the considered problems. Before continuing, it is important to remind
that the Grossone Methodology is independent from non-standard analysis,
as discussed in [27].
Concerning related works, it must be acknowledged that the ﬁrst successful
attempt to use Grossone Methodology within LP problems is due to [7]. The
same author together with his co-authors has proposed other applications of

Multi-objective Lexicographic Mixed-Integer Linear …
121
Grossone to optimization problems, in [8–10]. Concerning global optimiza-
tion, Grossone has been used in [28], while regarding convex non-smooth
optimization it has been used in [13]. As regard as evolutionary optimization,
four works have already been presented [15–18]. Grossone Methodology has
also been applied to Game Theory [4, 11, 12], inﬁnite decision processes sci-
ence [21–23], ordinary differential equations [1, 24, 29], among other ﬁelds.
The chapter is organized as follows. In next Section we introduce the
LMOLP problem, while in Sect.3 we show its transformation into a sin-
gle objective problem using the Grossone Methodology. Within the same
Section, we prove that the original formulation and the Grossone-based one
are equivalent. Then in Sect.4 we introduce the GrossSimplex algorithm
(an extension to the simplex algorithm able to work with Grossone-based
numbers) and we show an example of its execution. In Sect.5 we introduce
the LMOMILP problem, and its reformulation using Grossone, again proving
their equivalence. In Sect.6 we provide a Grossone-based extension to a clas-
sical Branch-and-Bound algorithm. Section 7 is devoted to the experimental
results: it shows how the GrossBB algorithm (coupled with the GrossSimplex
one) is able to solve three LMOMILP problems. Finally, Sect.8 provides a
few conclusions.
2
Lexicographic Multi-objective Linear Programming
Given the LMOLP problem:
LexMax
c1T x, c2T x, ..., crT x
s.t.

x∈Rn : Ax = b, x ⩾0

P1
where x and ci, i = 1, ...,r, are column vectors∈Rn, A is a full-rank matrix
∈Rm×n, b is a column vector ∈Rm. LexMax in P1 denotes lexicographic
maximum and means that the ﬁrst objective is much more important than the
second, which is, on its turn, much more important than the third one, and so
on.Sometimesintheliteraturethisisdenotedasc1T x ≫c2T x ≫... ≫crT x.
As in any LP problem, the domain of P1 is a polyhedron:
S ≡

x ∈Rn : Ax = b, x ⩾0

.
(1)
Notice that the formulation of P1 makes no use of Gross-numbers or Gross-
arrays involving ①, namely, it involves ﬁnite numbers only. Hereinafter we
assume that S is bounded and non-empty. In the literature (see, e.g., [14,
20, 30, 31]), there exists two approaches for solving the problem P1: the

122
M. Cococcioni et al.
preemptive scheme and the nonpreemptive scheme. They are described in the
following two subsections.
2.1
The Preemptive Scheme
The preemptive scheme introduced in [30] is an iterative method that attacks
P1 by solving a series of single-objective LP problems. It starts by considering
the ﬁrst objective function alone, i.e., by solving the following problem:
Max
c1T x
s.t.

x∈Rn : Ax = b, x ⩾0

.
P2.1
Since P2.1 is a canonical LP problem, it can be solved algorithmically using
any standard method (e.g., the simplex algorithm, the interior point algorithm,
etc.). Once they have been run, an optimal solution x∗1 with the optimal
value β1 = c1T x∗1 has been obtained. Then the preemptive scheme considers
the second objective of P1 and solves another single-objective LP problem,
where the domain has changed, due to the addition of the equality constraint
c1T x = β1:
Max
c2T x
s.t.

x∈Rn : Ax = b, x ⩾0, c1T x = β1

.
P2.2
The same approach is reiterated, and the algorithm stops either when the
last problem has been solved, i.e., after considering the last objective crT x
or when a unique solution has been found in the current solved LP problem.
Clearly, this approach is time consuming.
2.2
The Nonpreemptive Scheme Based on Appropriate Finite
Weights
It has been shown in [30] that there always exists a ﬁnite scalar M ∈R such
that the solution of the LMOLP problem P1 can be found by solving only
one single-objective LP problem having the following form:
Max
¯cT x
s.t.

x∈Rn : Ax = b, x ⩾0

P3

Multi-objective Lexicographic Mixed-Integer Linear …
123
where
¯c =
r

i=1
ci M−i+1.
(2)
This is a powerful theoretical result. However, from the computational point
of view, ﬁnding the value of M is not a trivial task. Finding an appropriate
value of M and solving the resulting LP problem can be more time consum-
ing than solving the original problem P1 following the preemptive approach.
Indeed, the preemptive scheme requires solving r linear programming prob-
lems only in the worst case and, in addition, it does not require the computa-
tion of M.
In Sect.3, we present a nonpreemptive approach based on inﬁnitesimal
weights (constructed by using Grossone integer powers), that overcomes the
problem of computing M and still requires the solution of only one single-
objective LP problem. Such an LP problem is, however, not a standard one
and thus it will be called Gross-LP problem, to avoid any possible confusion
with its standard formulation involving ﬁnite numbers only.
3
Grossone-Based Reformulation of the LMOLP
Problem
In this Section we will introduce a nonpreemptive Grossone-based scheme
for addressing LMOLP problems. In order to introduce such scheme we need
the following deﬁnitions and notations. Hereinafter, an array made of Gross-
scalars is called Gross-array. In particular, a vector made of Gross-scalars is
called from here on Gross-vector. The deﬁnition of Gross-matrix is similar.
By extension, Gross-vectors and Gross-matrices are called purely ﬁnite iff
all of their entries are purely ﬁnite Gross-numbers (where we have deﬁned
a purely ﬁnite Gross-number as a Gross-number involving a single power
of Grossone, and that power has zero as its exponent: examples are 3.56①0,
0.479, etc.). The used notation is summarized in Table 1.
Let us introduce now the nonpreemptive Grossone-based scheme follow-
ing the lexicographic ①-based approach introduced in [5, 6, 25]. It should be
stressed that it is supposed hereinafter that the original problem P1 has been
stated using purely ﬁnite numbers only. This assumption is not restrictive
from the practical point of view since all the LMOLP problems considered
traditionally are of this kind. However, since we are now in the framework
of ①-based numbers, this assumption should be explicitly stated.

124
M. Cococcioni et al.
Table 1 Notation used in this work
Font style
Example
Quantity
Italics lowercase
n
Purely ﬁnite real scalar
Boldface lowercase
x
Purely ﬁnite real vector
Boldface uppercase
A
Purely ﬁnite real matrix
Italics lowercase with tilde
˜c
Gross-scalar
Boldface lowercase with
tilde
˜y
Gross-vector
To state the problem P4, we reformulate P3 by making use of Gross-scalars
and Gross-vectors and is deﬁned as follows:
Max
˜cT x
s.t.

x∈Rn : Ax = b, x ⩾0

,
P4
where ˜c is a column Gross-vector having n Gross-scalar components:
˜c =
r

i=1
ci①−i+1
(3)
and ˜cT x is the Gross-scalar obtained by multiplying the Gross-vector ˜c by
purely ﬁnite vector x
˜cT x = (c1T x)①0 + (c2T x)①−1 + ... + (crT x)①−r+1,
(4)
where (4) can be equivalently written in the extended form as:
˜cT x = (c1
1x1 + ... + c1
nxn)①0 + (c2
1x1 + ... + c2
nxn)①−1 + ... + (cr
1x1 + ... + cr
nxn)①−r+1.
The fundamental difference between the deﬁnition of ˜c in (3) with respect
to the deﬁnition of ¯c in (2) is that ˜c does not involve any unknown. More pre-
cisely, it does not require the speciﬁcation of a real scalar value, like the value
of M in P3. However, this advantage leads to the fact that standard algorithms
(like the simplex algorithm or the interior point algorithm), traditionally used
for solving P3, can no longer be used in this case since ①-based numbers are
involved in the deﬁnition of the objective function. There will be shown in
the next section that it is still possible to obtain optimality conditions and to
introduce and implement a GrossSimplex algorithm (a generalization of the

Multi-objective Lexicographic Mixed-Integer Linear …
125
traditional simplex algorithm to the case of ①-based numbers) able to solve
problem P4.
In the rest of this section we will prove that problems P1 and P4 are
equivalent and then we will derive the optimality conditions. Before giving
the equivalence theorem, the following three lemmas are required.
The ﬁrst lemma states that all the optimal solutions of P4 are vertices or
belong to the convex hull of vertices, where the set of all the optimal solutions
for a generic problem P is denoted, from hereafter, by the symbol (P).
Lemma 1 Each x∗∈(P4) is a vertex or lies on the convex hull of the optimal
vertices.
The proof of Lemma 1 can be found in the appendix.
The next lemma states that all the optimal solutions of P1 reach the same
(Gross-scalar) objective value for problem P4.
Lemma 2 Foranyx∗∈(P1)itfollows ˜cT x∗= ˜v (˜v beingaconstantGross-
scalar).
Again, the proof of Lemma 2 is given in the appendix.
The third lemma is the last step in preparing the proof of the equivalence
between P1 and P4.
Lemma 3 For all x∗∈(P1) and any vertex ˆx of S such that ˆx /∈(P1),
it follows
˜cT ˆx < ˜cT x∗.
As before, the proof is reported in the appendix.
We are now ready to prove that any solution to P1 is also a solution to P4,
and vice-versa, as shown in next theorem.
Theorem 1 (Equivalence) x∗∈(P1) iff x∗∈(P4).
Proof ⇒If x∗is optimal for P1, then ˜cT x∗= ˜v due to Lemma 2. Therefore,
according to Lemmas 1 and 3, x∗is also optimal for P4.
⇐If x∗is optimal for P4, then due to Lemma 1, it belongs to the convex
hull of some vertices. But from Lemma 3 it follows that all the vertices of
this kind are optimal solutions to problem P1.
4
The GrossSimplex Algorithm
The single-objective Gross-LP problem formulated in P4 using Grossone can
be solved using the GrossSimplex algorithm here described, provided that
the duality theory is extended to the case of Gross-scalars and Gross-vectors.

126
M. Cococcioni et al.
The dual problem of P4 is the following
Min
˜yT b
s.t.

˜y : AT ˜y ⩾˜c

,
P5
where ˜y = [ ˜y1, ..., ˜ym]T is an m-dimensional column Gross-vector, AT ˜y an
n-dimensional column Gross-vector, and ˜yT b a Gross-scalar.
The domain of P5 is the Gross-polyhedron ˜D deﬁned as:
˜D ≡

˜y : AT ˜y ⩾˜c

.
In the following we will assume that ˜D is bounded and non-empty, as we
have assumed for S.
Since optimality conditions are the core of the simplex algorithm, we need
to prove optimality conditions in our context.
Deﬁnition 1 (Deﬁnition of optimality for the Gross-primal problem) A point
x∗is optimal for the problem P4 iff ˜cT x∗⩾˜cT x
∀x∈S.
Deﬁnition 2 (Deﬁnition of optimality for the Gross-dual problem) A point
˜y∗is optimal for the problem P5 iff ˜y∗T b ⩽˜yT b
∀˜y∈˜D.
We need now the following lemma, taken from [6].
Lemma 4 (Weak duality) ∀x∈S and ∀˜y∈˜D, it follows that ˜yT b ⩾˜cT x.
Proof Since x∈S, Ax = b. Pre-multiplying both by ˜yT , we have
˜yT Ax = ˜yT b.
(5)
Now, since ˜y∈˜D, we know that ˜yT A ⩾˜cT . By post-multiplying the latter
by x (being x ⩾0), we have:
˜yT Ax ⩾˜cT x.
By combining it with (5) we obtain ˜yT b ⩾˜cT x.
Theorem 2 (Optimality condition) If x∗∈S, ˜y∗∈˜D and ˜cT x∗= ˜y∗T b, then
it follows that x∗∈(P1) and ˜y∗∈(P5).
Proof It is an immediate consequence of the weak duality Lemma 4.

Multi-objective Lexicographic Mixed-Integer Linear …
127
Algorithm 1: The GrossSimplex algorithm
Step 0. The user has to provide the initial set B of basic indices.
Step 1. Solve the system AT
B ˜y = ˜cB (where AT
B is the sub-matrix obtained by AT by considering the columns indexed by B).
This can be easily calculated as ˜y = A−T
B
˜cB where A−T
B
is an abbreviation for

AT
B
−1, ˜y is a Gross-vector obtained
by linearly combining the Gross-vector ˜cB using the purely ﬁnite scalar elements in A−T
B .
Step 2. Compute ˜s = ˜cN −AT
N ˜y (where N is the complementary set of B) and then select the maximum (gradient rule). When
this maximum is negative (being it ﬁnite or inﬁnitesimal), it means that we are done (the current solution is optimal)
and thus the algorithm STOPS. Otherwise, the position of the maximum in the Gross-vector ˜s is the index k of the
entering variable N(k).
Step 3. Solve the system ABd = AN(k).
Step 4. Find the largest t such that x∗
B −td ⩾0. If there is not such a t, then the problem is unbounded (STOP); otherwise, at
least one component of x∗
B −td equals zero and the corresponding variable is the leaving variable. In case of ties,
use the Lexicographic Pivoting Rule [7] to break them.
Step 5. Update B and N and return to Step 1.
We are now ready to introduce the GrossSimplex algorithm (see Algo-
rithm 1) which exploits the theoretical results presented above. Notice that
the algorithm needs a ﬁrst feasible basis B. It can be found by solving the stan-
dard auxiliary problem analogously to the case where the objective function
is only one (no GrossSimplex required to solve it).
To illustrate the behaviour of the GrossSimplex algorithm we consider the
following problem:
LexMax
4x1 + 2x2, 2x2, x1 + x2
s.t.
2x1
+ x2
≤14
−x1 + 2x2 ≤8
2x1
−x2 ≤10
x1, x2 ≥0.
The polygon S associated to this problem is shown in Fig. 1. It can be seen
that the ﬁrst objective vector c1 = [4, 2]T is orthogonal to segment [α, β]
(α = (6, 2), β = (4, 6)) shown in the same ﬁgure. Thus all the points laying
on this segment are optimal. Since the solution is not unique, there is the
chance to try to improve the second objective vector (c2 = [0, 2]T ) without
deteriorating the ﬁrst one function. The point that maximizes the second
objective is β, associated to solution x∗= [4, 6]T . Since now the solution is
unique, the third objective function can not be taken into account. Thus the
lexicographic optimal solution for the problem is x∗= [4, 6]T .
Before running the GrossSimplex algorithm we had to transform the prob-
lem into the following one, after converting the constraints into equality con-
straints by adding slack variables x3, x4, and x5:

128
M. Cococcioni et al.
Fig. 1 An example in
two dimensions with three
objectives. All the points
in the segment [α, β] are
optimal for the ﬁrst
objective, while point β is
the unique lexicographic
optimum for the given
problem (β = (4, 6))
LexMax
4x1 + 2x2, 2x2, x1 + x2
s.t.
2x1
+ x2
+ x3 = 14
−x1 + 2x2 + x4 = 8
2x1
−x2 + x5 = 10
xi ≥0
i = 1, ..., 5.
T0
The GrossSimplex algorithm has been run on problem T0, by using the
initial basis B = {3, 4, 5} (N is therefore {1, 2}). The initial solution associ-
ated to the initial basis is: x = [0, 0, 14, 8, 10]T , which corresponds to the
point (0, 0) in Fig. 1. Then the algorithm computes ˜s as ˜cN −AT
N ˜y giving
˜s =
	4①0 + 0①−1 + 1①−2
2①0 + 2①−1 + 1①−2

.
Thus, according to the gradient rule for choosing the entering variable,
the one in N having the ﬁrst index is selected, i.e., x1, which is the one
associated to the maximum constraint violation: 4①0 + 0①−1 + 1①−2. The
leaving index, computed according to the lexicographic pivoting rule is the
third, i.e., variable x5. Thus the second base used is B = { 3, 4, 1}. The Gross-
objective function is ˜cT x = 20.00①0 + 0.00①−1 + 5.00①−2 and, of course,
coincides with that of the dual ˜yT b (when ˜y will be also feasible, we will be
at the optimum and the algorithm will end).
The solution associated to this second base is x = [5, 0, 4, 13, 0]T , while
the new value for ˜s is

Multi-objective Lexicographic Mixed-Integer Linear …
129
˜s =
	−2①0 + 0①−1 −0.5①−2
4①0 + 2①−1 + 1.5①−2

.
Again, according to the gradient rule, the next entering index is the second,
i.e., variable x2. The leaving index is the ﬁrst and thus the leaving variable is
x3. Therefore, the next basis (the third) is B = {2, 4, 1}. The Gross-objective
function is equal to 28.00①0 + 4.00①−1 + 8.00①−2.
The solution associated to the third base is x = [6, 2, 0, 10, 0]T , while
the new value for ˜s is
˜s =
	 0①0 + 1①−1 + 0.25①−2
−2①0 −1①−1 −0.75①−2

.
By following the same process, the next entering index is the ﬁrst, i.e.,
variable x5. It is interesting to note that in this case the constraint violation
(a positive entry in ˜s) is not ﬁnite, as in previous case, but inﬁnitesimal:
+1①−1 + 0.25①−2 The leaving index is the second and thus the leaving
variable is x4.
At this point, the Gross-objective function is now equal to 28.00①0 +
12.00①−1 + 10.00①−2, the solution associated to the fourth base is x =
[4, 6, 0, 0, 8]T , and the ˜s is
˜s =
	 0①0 −0.8①−1 −0.2①−2
−2①0 −0.4①−1 −0.6①−2

.
Since all the entries of ˜s are negative (one is inﬁnitesimal and one
is ﬁnite), we are done. In fact, the solution found (once the slack vari-
ables are discarded), is the correct one, i.e., x∗= [4, 6]T . Furthermore,
the Gross-objective function at the end equals to ˜cT x = ˜yT b = 28.00①0 +
12.00①−1 + 10.00①−2. This concludes the step-by-step illustration about
how the GrossSimplex works in a concrete example.
As a ﬁnal note, observe how in [3] a parameter-less way to obtain the initial
basis is shown, based on the Big-M method with an inﬁnitely big value for
M. The idea of that method is to use a numerical, inﬁnitely big value for M,
set equal to ①.
In the next section we present the Lexicographic Multi-Objective Mixed-
Integer Linear Programming problem and then, in the subsequent version,
how to solve it using a Grossone-based extension of the Branch-and-Bound
method.

130
M. Cococcioni et al.
5
Lexicographic Multi-objective Mixed-Integer Linear
Programming
In this section we introduce the LMOMILP problem, which is formalized as:
LexMin c1 T x, c2 T x, ..., cr T x
s.t. Ax ⩽b,
x =
	p
q

p ∈Zk, q ∈Rn−k
P
where ci, i = 1, ...,r, are column vectors∈Rn, x is a column vector∈Rn, A
is a full-rank matrix∈Rm×n, b is a column vector∈Rm. LexMin in P denotes
the lexicographic minimum.
As in any MILP problem, from the problem P, we can deﬁne the polyhe-
dron deﬁned by the linear constraints alone:
S ≡

x∈Rn : Ax ⩽b

.
(6)
Thus we can deﬁne problem R, the relaxation of a lexicographic (mixed) inte-
ger linear problem, obtained from P by removing the integrality constraint
on each variable:
LexMin
c1 T x, c2 T x, ..., cr T x
s.t.
Ax ⩽b.
R
Problem R is called LMOLP (Lexicographic Multi-Objective Linear Prob-
lem), and can be solved using the GrossSimplex algorithm shown in Sect.4.
In addition, every thing we have said above for the MILP problem is still
valid for the LMOMILP.
Notice that the formulation of P makes no use of Gross-numbers or Gross-
arrays involving ①, namely, it involves ﬁnite numbers only. Hereinafter we
assume that S is bounded and non-empty. In the next we will reformulate
the LMOMILP problem P using Grossone, and then we will prove their
equivalence.
We present now an equivalent reformulation of the LMOMILP problem
P, based on Grossone Methodology.
First of all, let us introduce the new problem ˜P, formulated using Gross-
numbers, following the same approach shown in Sect.3:

Multi-objective Lexicographic Mixed-Integer Linear …
131
Min
˜cT x
˜P
s.t. Ax ⩽b,
x =
	p
q

p ∈Zk,
q ∈Rn−k,
where ˜c is a column Gross-vector having n Gross-scalar components built
using purely ﬁnite vectors ci
˜c =
r

i=1
ci①−i+1
(7)
and ˜cT x is the Gross-scalar obtained by multiplying the Gross-vector ˜c by
the purely ﬁnite vector x:
˜cT x = (c1T x)①0 + (c2T x)①−1 + ... + (crT x)①−r+1.
(8)
Observe how Eq.(7) is identical to Eqs.(3), and (8) is the same as Eq.(4).
In Theorem 2 we will prove that problem ˜P is equivalent to problem P
deﬁned on Sect.5.
What makes the new formulation ˜P attractive is the fact that its relaxed
version (from the integrality constraint) is a Gross-LP problem, and therefore
it can be effectively solved using a single run of the GrossSimplex algorithm
introduced in Sect.4. This means that the set of multiple objective func-
tions is mapped into a single (Gross-) scalar function to be optimized. This
opens the possibility to solve the integer-constrained variant of the problem
using an adaptation of the BB algorithm (see Algorithm 2), coupled with the
GrossSimplex. Of course the GrossSimplex will solve the relaxed version of
˜P:
Min
˜cT x
s.t.
Ax ⩽b.
˜R
Theorem 3 (Equivalence of problem ˜Pand problem P) Problem ˜P is equiv-
alent to the problem P. Thus the solutions of the two are the same.
Proof The basic observation is that the integer relaxation R of problem P
is an LMOLP problem, while the integer relaxation of problem ˜P, the ˜R
problem deﬁned above, is a Gross-LP problem. In Sect.3 we have already
proved the equivalence of problems R and ˜R. Now, since problems P and ˜P
have equivalent relaxations, the two will also share the same solutions when
the same integrality constraints will be taken into account on both.

132
M. Cococcioni et al.
In the next subsections we will provide the pruning rules, terminating
conditions and the branching rule, and then we will introduce the GrossBB
algorithm, a generalization of the BB algorithm able to work with Gross-
numbers.
6
A Grossone-Based Extension of the
Branch-and-Bound Algorithm
In this Section we introduce a Grossone-based extension of the Branch-and-
Bound algorithm, called GrossBB, to solve the Grossone-based formulation
of
any
LMOMILP problem. As in any Branch-and-Bound algorithm, we have to
provide the pruning rules (and the proof of their correctness), the termination
conditions and the the branching rules.
6.1
Pruning Rules for the GrossBB
The pruning rules of a standard Branch-and-Bound algorithm (see [19]) can
be adapted to the case of a Grossone reformulated version of any LMOMILP
problem:
Theorem 4 (Pruning rules for the GrossBB) Let xopt be the best solution
found so far for ˜P, and let ˜vS( ˜P) = ˜cT xopt be the current upper bound.
Considering the current node ( ˜Pc) and the associated problem ˜Pc:
1. If the feasible region of problem ˜Pc is empty the sub-tree with root ( ˜Pc)
has no feasible solutions having values lower than ˜cT xopt. So we can
prune this node.
2. If ˜vI( ˜Pc) ⩾˜vS( ˜P), then we can prune at node ( ˜Pc), since the sub-tree
with root ( ˜Pc) cannot have feasible solutions having a value lower than
˜vS( ˜P).
3. If ˜vI( ˜Pc) < ˜vS( ˜P) and the optimal solution ¯x of the relaxed problem
˜Rc is feasible for ˜P, then ¯x is a better candidate solution for ˜P, and
thus we can update xopt (xopt = ¯x) and the value of the upper bound
(˜vS( ˜P) = ˜vI( ˜Pc)). Finally, prune this node according to the second rule.
The correctness of the above pruning rules taken from [2] and, for the con-
venience of the reader, is also provided below.

Multi-objective Lexicographic Mixed-Integer Linear …
133
Proof (Pruning Rule 1) If the feasible region of the current problem ˜Rc is
empty, then also the one of ˜Pc is too, since the domain of ˜Pc has additional
constrains (the integrality constraints). Furthermore, all the domain of the
problems in the leaves of the sub-tree having root in ˜Pc will be empty as
well, since the domains of the leaves have all additional constrains with
respect to ˜Rc. This proves the correctness of the ﬁrst pruning rule.
Now let us prove the second pruning rule.
Proof (Pruning Rule 2) Let us consider the generic leaf Pleaf of the sub-tree
having root ˜Pc. Let us indicate with ˜v( ˜Pc) the optimal value of the current
problem ˜Pc (the one with the integer constraints). Then the values at the
leaves below ˜Pc must be greater than or equal to ˜v( ˜Pc):
˜v( ˜Pleaf ) ⩾˜v( ˜Pc)
∀leaf in SubTree( ˜Pc).
In fact, the domain of ˜Pc includes the ones of all the ˜Pleaf , being each problem
˜Pleaf obtained by enriching ˜Pc with additional constraints. On the other hand,
˜v( ˜Pc) ⩾˜vI( ˜Pc)
since ˜vI( ˜Pc) is obtained as the optimal solution of ˜Rc, a problem having a
domain which includes the one of ˜Pc. Thus the following chain of inequalities
always old:
˜v( ˜Pleaf ) ⩾˜v( ˜Pc) ⩾˜vI( ˜Pc)
∀leaf in SubTree( ˜Pc).
Now, if ˜vI( ˜Pc) ⩾˜vS( ˜P), we can add an element to the chain:
˜v( ˜Pleaf ) ⩾˜v( ˜Pc) ⩾˜vI( ˜Pc) ⩾˜vS( ˜P)
∀leaf in SubTree( ˜Pc)
from which we can conclude that
˜v( ˜Pleaf ) ⩾˜vS( ˜P)
∀leaf in SubTree( ˜Pc).
This means that all the leaves of the current node will contain solutions that
are worse (or equivalent) than the current upper bound. Thus the sub-tree
rooted in ˜Pc can to be pruned (i.e., not explicitly explored). This proves the
correctness of the second pruning rule.
Before proving the pruning rule 3, let us observe how the pruning rule
above prevents from solving multi-modal problems, in the sense that with

134
M. Cococcioni et al.
such pruning rule we are only able to ﬁnd a single optimum, not all the
solutions that might have the same cost function. In other words, the pro-
posed pruning rule does not allow to solve multi-modal problems, because
we are deciding not to explore the sub-tree at a given node that could contain
solutions having the same current optimal objective function value. To solve
multi-modal problems, that rule must be applied only when
˜vI( ˜Pc) > ˜vS( ˜P).
(9)
Proof (Pruning Rule 3)
If ˜vI( ˜Pc) < ˜vS( ˜P) and ¯x is feasible for ˜P, (i.e., if all the components of ¯x
that must be integer are actually ϵ-integer), we have found a better estimate
for the upper bound of ˜P, and thus we can update it:
˜vS( ˜P) = ˜vI( ˜Pc).
As a result, now ˜vI( ˜Pc) = ˜vS( ˜P), and thus:
˜v( ˜Pleaf ) ⩾˜v( ˜Pc) ⩾˜vI( ˜Pc) = ˜vS( ˜P)
∀leaf in SubTree( ˜Pc)
then again we have that the sub-tree having root ˜Pc cannot contain better
solutions than ¯x:
˜v( ˜Pleaf ) ⩾˜vS( ˜P)
∀leaf in SubTree( ˜Pc).
This proves the correctness of the third pruning rule.
6.2
Terminating Conditions, Branching Rules and the
GrossBB Algorithm
Let us now discuss the terminating conditions for the GrossBB algorithm.
The ﬁrst two are exactly the same of the classical BB, while the third requires
some attention.
The terminating conditions are:
1. All the remaining leaves have been visited: if all the leaves have been
visited the GrossBB algorithm stops.
2. Maximum number of iteration reached: when a given maximum num-
ber of iterations (provided by the user at the beginning) has been reached,
the GrossBB stops.

Multi-objective Lexicographic Mixed-Integer Linear …
135
3. ˜ϵ−optimality reached: when the normalized difference between the
global lower bound and the global upper bound at the i-th iteration is
close enough to zero, we can stop:
˜i( ˜P) = ˜vS( ˜P) −˜vI( ˜P)
|˜vS( ˜P)|
⩽
˜ϵ
(10)
Thelastterminatingconditiondeservesadditionalattention.Itﬁrstinvolves
the difference between two Gross-scalars. This intermediate result must be
divided by the absolute value of ˜vS( ˜P). While computing the absolute value
of a Gross-scalar is straightforward, computing the division requires the algo-
rithm described in [26]. The result of the Gross-division is a Gross-scalar that
must be compared with the Gross-scalar ˜ϵ, which has the form:
˜ϵ = ϵ0 + ϵ1①−1 + ϵ2①−2 + ... + ϵr−1①−r+1.
Obviously, it is possible to chose ϵ0 = ϵ1 = ϵ2... = ϵ, to simplify the pre-
sentation.
Let see the example below. Suppose to have three objectives (r=3) and to
have selected ϵ = 10−6. Given the following ˜i( ˜P)
˜i( ˜P) = 1.1 · 10−7 + 5 · 10−3①−1 + 1.7 · 10−8①−2
it is clear that
˜i( ˜P)  ˜ϵ,
becauseitsﬁrst-orderinﬁnitesimalcomponent(5 · 10−3)isnotlessorequalto
ϵ. Thus in this case the GrossBB algorithm cannot terminate: it will continue,
trying to make all the components ⩽ϵ.
Concerning the branching rule for the GrossBB algorithm, it works as
follows. When the sub-tree below ˜Pc cannot be pruned (because it could
contain better solutions), its sub-tree must be explored. Thus we have to
branch the current node into Pl and Pr and to add these two new nodes to
the tail of the queue of the sub-problems to be analyzed and solved by the
GrossSimplex.
We are now ready to provide the pseudo-code for the GrossBB (see Algo-
rithm 2). The GrossBB algorithm, ﬁrstly introduced in [2], is able to solve a
given ˜P LMOMILP problem, by internally using the GrossSimplex and the
GrossBB rules provided above (pruning, terminating, and branching) .
This would allow us to create a division-free variant of the GrossBB algo-
rithm. Anyway, we think that the use of the division is still interesting from
the theoretical point of view, because it allowed us to clarify the concept of

136
M. Cococcioni et al.
Algorithm 2: The GrossSimplex-based GrossBB algorithm
1 Inputs: maxIter and a speciﬁc LMOMILP problem ˜
|P|, to be put within the root
node ( ˜P)
2 Outputs: xopt (the optimal solution, a purely ﬁnite vector), ˜fopt (the optimal value,
a Gross-scalar)
Step 0. Insert ˜
|P| into a queue of the sub problems that must be solved. Put ˜vS( ˜P) = ①, xopt = [ ], and ˜fopt = ①
or use a greedy algorithm to get an initial feasible solution.
Step 1a. If all the remaining leaves have been visited (empty queue), or the maximum number of iterations has been
reached, or the ˜ϵ-optimality condition holds, then goto Step 4. Otherwise extract from the head of the
queue the next problem to solve and call it ˜Pc (current problem). Remark: this policy of insertion of new
problems at the tail of the queue and the extraction from its head leads to a breadth-ﬁrst visit for the binary
tree of the generated problems.
Step 1b. Solve ˜Rc, the relaxed version of the problem ˜Pc at hand, using the GrossSimplex and get ¯x and ˜fc ( = ˜cT ¯x):
[¯x, ˜fc, emptyPolyhedron] ←GrossSimplex( ˜Rc).
Step 2a. If the LP solver has found that the polyhedron is empty, then prune the sub-tree of ( ˜Pc) (according to Pruning
Rule 1) by going to Step 1a (without branching ( ˜Pc)). Otherwise, we have found a new lower value for ˜Pc:
˜vI ( ˜Pc) = ˜fc.
Step 2b. If ˜vI ( ˜Pc) ⩾˜vS( ˜P), then prune the sub-tree under ˜Pc (according to Pruning Rule 2), by going to Step 1a
(without branching ˜Pc).
Step 2c. If ˜vI ( ˜Pc) < ˜vS( ˜P) and all components of ¯x that must be integer are actually ϵ-integer (i.e., ¯x is feasible),
then we have found a better upper bound estimate. Thus we can update the value of ˜vS( ˜P) as:
˜vS( ˜P) = ˜vI ( ˜Pc).
In addition we set xopt = ¯x and ˜fopt = ˜vI ( ˜Pc). Then we also prune the sub-tree under ( ˜Pc) (according to
Pruning Rule 3) by going to Step 1a (without branching ( ˜Pc)).
Step 3. If ˜vI ( ˜Pc) < ˜vS( ˜P) but not all components of ¯x that must be integer are actually ϵ-integer, we have to branch.
Select the component ¯xt of ¯x having the greatest fractional part, among all the components that must be
integer. Create two new nodes (i.e., problems) with a new constraint for this variable, one with a new ⩽
constraint for the rounded down value of ¯xt and another with a new ⩾constraint for the rounded up value of
¯xt . Let us call the two new problems ˜Pl and ˜Pr and put them at the tail of the queue of the problems to be
solved, then goto Step 1a.
Step 4. End of the algorithm.
when a Gross-number is “near zero”. Furthermore, the impact of the compu-
tation of the division of equation (10) on the overall computing time of the
algorithm is negligible, being the overall computing time mainly affected by
the time needed to compute the solutions of the relaxed LMOLP problems.

Multi-objective Lexicographic Mixed-Integer Linear …
137
7
Experimental Results
In this section we introduce three LMOMILP test problems having known
solution, then we verify that the GrossBB combined with the GrossSimplex
is able to solve them. Additional examples can be found in [2].
7.1
Test Problem 1: The “Kite” in 2D
This problem, taken from [2], is a little variant to problem T0 described
above. The main difference is the addition of the integrality constraint. In
addition,thesecondconstraint2x1 + 3x2 ⩽210 hasbeenchangedinto2x1 +
3x2 ⩽210 + 2.5). Finally observe how this formulation does not involve
slack variables:
LexMax
8x1 + 12x2, 14x1 + 10x2, x1 + x2
s.t.
2x1 + 1x2 ⩽120
2x1 + 3x2 ⩽210 + 2.5
4x1 + 3x2 ⩽270
x1 + 2x2 ⩾60
−200 ⩽x1, x2 ⩽+200,
x ∈Zn.
T1
The polygon S associated to problem T1 is shown in Fig. 2 (left sub-ﬁgure).
The integer points (feasible solutions) are shown as black spots, while in light
grey we have provided the domain of the relaxed problem (without the integer
constraints).
It can be seen that the ﬁrst objective vector c1 = [8, 12]T is orthogonal
to segment [α, β] (α = (0, 70.83), β = (28.75, 51.67)) shown in the same
ﬁgure. All the nearest integer points parallel to this segment are optimal for
the ﬁrst objective (see the right sub-ﬁgure in Fig. 2). Since the solution is not
unique, there is the chance to try to improve the second objective vector (c2
= [14, 10]T ).
Let see what happens when we solve this problem using the GrossSimplex-
based GrossBB algorithm.
Since the T1 problem is Lex Max-formulated, we have to feed −˜c to the
GrossSimplex-based GrossBB algorithm.

138
M. Cococcioni et al.
Fig. 2 An example in two dimensions with three objectives. The black points on the
left ﬁgure are all the feasible solutions. All the nearest integer points parallel to the
segment [α, β] (there are many), are optimal for the ﬁrst objective, while point (28, 52)
is the unique lexicographic optimum for the given problem (i.e., considering the second
objective too). The third objective plays no role in this case. On the right, a zoom around
point β is provided, with some optimal solutions for the ﬁrst objective highlighted (the
ones with a bigger black spot)
Initialize ˜vS( ˜P) = ①, xopt = [ ], ˜fopt = ①and insert T1 into a queue of the
sub-problems that must be solved.
Iteration 1 The GrossBB extracts from the queue of problems to be solved
the only one present, and denotes it as the current problem:
˜Pc ≡T1).
Then the algorithm solves its relaxed version: the solution of ˜Rc is ¯x =
[28.7500, 51.6667]T ,with ˜vI( ˜Pc) = −850①0 −919.167①−1 −80.4167①−2.
In this case we have to branch using the component having the highest frac-
tional part (among the variables with integer restrictions, of course). In this
case, it is the ﬁrst component, and thus the new sub-problem on the left ˜Pl
will have the additional constraint x1 ⩽28, while the new on the right ˜Pr
will have the additional constraint x1 ⩾29. This split makes the current solu-
tion [28.7500, 51.6667]T not optimal neither for problems ˜Pl nor for ˜Pr (see
Fig. 3).

Multi-objective Lexicographic Mixed-Integer Linear …
139
Fig. 3 Situation at the
end of iteration 1, for
problem T1
Iteration 2 At this step the queue is composed by [ ˜Pl, ˜Pr], the problems gen-
erated in the previous iteration. The GrossBB extracts now the next problem
from the top of the queue (breadth-ﬁrst visit), namely [ ˜Pl and denotes it as ˜Pc,
the current problem to solve. The optimal solution for the relaxed problem
˜Rc is ¯x = [28.25, 52]T , with ˜vI( ˜Pc) = −850①0 −915.5①−1 −80.25①−2.
We have to branch again, as we did on iteration 1, a thus a new left and right
problems will be generated and added to the queue. The new left problem
will have the additional constraint x1 ⩽28, while the new right problem will
have the additional constraint x1 ⩾29. The length of the queue is now 3.
Iteration 3 Extract the next problem from the top of the queue and denote
it as ˜Pc. The optimal solution of ˜Rc is ¯x = [29.25, 51]T and the associated
˜vI( ˜Pc) = −846①0 −919.5①−1 −80.25①−2. We have to branch, a new left
and right problem will be generated, both will be added to the queue. The left
problem will have the additional constraint x1 ⩽29, while the new on the
right ˜Pr will have the additional constraint x1 ⩾30. The length of the queue
is now 4.
Iteration 4 Extract the next problem from the queue and indicate it as ˜Pc.
Solve ˜Rc, the relaxation of ˜Pc, using the GrossSimplex. Since ˜Rc has an
empty feasible region, prune this node by applying the ﬁrst pruning rule. The
length of the queue is now 3.
Iteration 5 Extract the next problem from the top of the queue and denote it
as ˜Pc. The optimal solution of ˜Rc is ¯x = [28, 52.1667]T and the associated
˜vI( ˜Pc) = −850①0 −913.6667①−1 −80.1667①−2. We have to branch: a
new left and right problems will be generated and added to the queue. The
left problem will have the additional constraint x1 ⩽52, while the right one
will have the additional constraint x1 ⩾53. The length of the queue is now

140
M. Cococcioni et al.
4.
Iteration 6 Extract the next problem from the queue and indicate it as ˜Pc.
ThistimetheGrossSimplexreturnsanintegersolution,i.e.,afeasiblesolution
for the LMOMILP initial problem T1:
¯x = [30, 50]T and
˜vI( ˜Pc) = −840①0 −920①−1 −80①−2.
Since ˜vI( ˜Pc) < ˜vS( ˜P),thenwecanupdate ˜vS( ˜P) = ˜vI( ˜Pc),xopt = ¯x.Finally
we can prune this node, according to the third pruning rule.
Iteration 7 Extract the next problem from the queue and indicate it as ˜Pc.
Again the GrossSimplex returns an integer solution:
¯x = [29, 51]T and
˜vI( ˜Pc) = −844①0 −916①−1 −80①−2.
Since ˜vI( ˜Pc) < ˜vS( ˜P),thenwecanupdate ˜vS( ˜P) = ˜vI( ˜Pc),xopt = ¯x.Finally
we can prune this node, according to the third pruning rule.
Iteration 8 Extract the next problem from the top of the queue and indi-
cate it as ˜Pc. The optimal solution of ˜Rc is ¯x = [26.75, 53]T , with ˜vI( ˜Pc) =
−850①0 −904.5①−1 −79.75①−2. We have to branch: a new left and right
problems will be generated and added to the queue. The left problem will
have the additional constraint x1 ⩽26, while the new on the right ˜Pr will
have the additional constraint x1 ⩾27. The length of the queue is now 4.
Iteration 9 Extract the next problem from the queue and designate it as
the current problem ˜Pc. Solve its relaxation, using the GrossSimplex. In this
case the returned solution is feasible for the initial LMOMILP problem T1,
because it has all integral components:
¯x = [28, 52]T
and
˜vI( ˜Pc) = −848①0 −912①−1 −80①−2.
Since ˜vI( ˜Pc) < ˜vS( ˜P), then update both ˜vS( ˜P) = ˜vI( ˜Pc) and xopt = ¯x.
Finally prune this node by applying the third pruning rule.
Iteration 10 Extract the next problem from the queue and indicate it as ˜Pc.
Solve ˜Rc, the relaxation of ˜Pc, using the GrossSimplex. Since ˜Rc has an
empty feasible region, prune this node by applying the ﬁrst pruning rule.

Multi-objective Lexicographic Mixed-Integer Linear …
141
Iterations 11–79 The GrossBB algorithm is not able to ﬁnd a better solution
than the ¯x = [28, 52]T already found, but continues to branch and explore
the tree, until only two nodes remain in the queue. The processing of the last
two nodes is discussed in the last two iterations 80 and 81, below.
Iteration 80 Extract the next problem from the queue and indicate it as ˜Pc.
Solve ˜Rc using the GrossSimplex. Since ˜Rc has an empty feasible region,
prune this node by applying the ﬁrst pruning rule.
Iteration 81 At this point there is one last unsolved problem from the queue.
Extract this problem and indicate it as ˜Pc. The optimal solution of ˜Rc is:
¯x = [1, 70]T ,
with
˜vI( ˜Pc) = −848①0 −714①−1 −71①−2.
Since ˜vI( ˜Pc) ≥˜vS( ˜P), prune this last node according to the third pruning
rule. Being now the tree empty, the GrossBB algorithm stops according to
the ﬁrst terminating condition and returns the optimal solution found so far:
xopt = [28, 52]T .
The optimal value of the objective function is
˜
cT xopt = 848①0 + 912①−1 +
80①−2.
Table 2 provides a synthesis with the most interesting iterations performed
by the GrossBB.
7.2
Test Problem 2: The Unrotated “House” in 3D
This illustrative example is taken from [2] and is in three dimensions with
three objectives:
LexMax
x1, −x2, −x3
s.t.
−10.2 ⩽x1 ⩽10.2
−10 ⩽x2 ⩽10.2
−10.2 ⩽x3 ⩽10.2
−x1 −x2 ⩽2
−x1 + x2 ⩽2
−20 ⩽xi ⩽20, i = 1, ..., 3,
x ∈Z3,
T2

142
M. Cococcioni et al.
Table 2 Iterations performed by GrossSimplex-based GrossBB algorithm on problem
T1
Iteration Result at node (iteration)
Initialize – ˜vS( ˜P) = ①
– Queue len. 1 (add the root problem to the queue)
1
˜vI ( ˜Pc): −850①0 −919.167①−1 −80.4167①−2. Queue length : 0
– No pruning rules applied, branch ˜Pc in two sub-problems. Queue length: 2
– ˜ = 100①0 + 100①−1 + 100①−2
2
˜vI ( ˜Pc): −850①0 −915.5①−1 −80.25①−2. Queue length: 1
– No pruning rules applied, branch ˜Pc in two sub-problems. Queue length: 3
– ˜ = 100①0 + 100①−1 + 100①−2
3
˜vI ( ˜Pc): −846①0 −919.5①−1 −80.25①−2. Queue length: 2
– No pruning rules applied, branch ˜Pc in two sub-problems. Queue length: 4
– ˜ = 100①0 + 100①−1 + 100①−2
4
Prune node: rule 1, empty feasible region. Queue length: 3
5
˜vI ( ˜Pc): −850①0 −913.667①−1 −80.1667①−2. Queue length: 2
– No pruning rules applied, branch ˜Pc in two sub-problems. Queue length: 4
– ˜ = 100①0 + 100①−1 + 100①−2
6
˜vI ( ˜Pc): −840①0 −920①−1 −80①−2. Queue length: 3
– A feasible solution has been found: xopt = [30, 50]T
– Update ˜vS( ˜P) = ˜vI ( ˜Pc), prune node: rule 3
– ˜ = 0.0119048①0 −0.00688406①−1 + 0.00208333①−2
7
˜vI ( ˜Pc): −844①0 −916①−1 −80①−2. Queue length: 2
– A feasible solution has been found: xopt = [29, 51]T
– Update ˜vS( ˜P) = ˜vI ( ˜Pc), prune node: rule 3
– ˜ = 0.354191①0 −0.127528①−1 + 0.104058①−2
8
˜vI ( ˜Pc): −850①0 −904.5①−1 −79.75①−2. Queue length: 1
– No pruning rules applied, branch ˜Pc in two sub-problems. Queue length: 3
– ˜ = 0.007109①0 −0.00254731①−1 + 0.00208333①−2
9
˜vI ( ˜Pc): −848①0 −912①−1 −80①−2. Queue length: 2
– A feasible solution has been found: xopt = [28, 52]T
– Update ˜vS( ˜P) = ˜vI ( ˜Pc), prune node: rule 3
– ˜ = 0.00235849①0 −0.00822368①−1 −0.003125①−2
10
Prune node: rule 1, empty feasible region. Queue length: 1
...
... ... ... ... ....
80
Prune node: rule 1, empty feasible region. Queue length: 1
81
˜vI ( ˜Pc): −848①0 −714①−1 −71①−2. Queue length: 0
– ˜vI ( ˜Pc) ⩾˜vS( ˜P) prune node: rule 2
Result
Iteration 81. Optimization ended. Optimal solution found:
xopt = [28, 52]T
˜fopt = −848①0 −912①−1 −80①−2
˜ = 0①0 + 0①−1 + 0①−2

Multi-objective Lexicographic Mixed-Integer Linear …
143
Fig. 4 A 3D unrotated “house” problem
with the domain being the cube shown in Fig. 4. It can be immediately seen
that by considering the ﬁrst objective alone (maximize x1), all the nearest
integer points parallel to square having vertices α, β, γ , δ (see Fig. 4) are
optimal for the ﬁrst objective function. Since the optimum is not unique, the
second objective function can be considered in order to improve it without
deterioratingtheﬁrstobjective.Then,alltheintegerpointsneartothesegment
[β, γ ] are all optimal for the second objective too (see Fig. 5, which provides
the plant-view of Fig. 4 with x3 = −10).
Again, the optimum in not unique, and thus we can consider the third
objective, which allows us to select the nearest integer point to γ as the
unique solution that maximizes all the three objectives. In particular, point
[10, −10, −10] is the lexicographic optimum to the given problem.
The problem can be solved with GrossBB algorithm, as shown in Table 3.
The solution xopt = [10, −10, −10]T is actually found after 5 iterations.
The optimal value of the objective function can be computed as ˜cT xopt =
10①0 + 10①−1 + 10①−2.
7.3
Test Problem 3: the Rotated “House” in 5D
Algorithm 3 (ﬁrstly introduced in [2]) shows how to add a small rotation
along the axis perpendicular to the plane containing the ﬁrst two variables x1
and x2, for the “house” problem seen in previous example, after generalizing
it to the n-dimensional case.
The problem considered here (again taken from [2]) consists of the lexi-
cographic optimization of x1, −x2, ..., −x5. The method used to generate a
randomly rotated benchmark is shown on Algorithm 3 (the generated rotation

144
M. Cococcioni et al.
Fig. 5 Section view of Fig. 4 with x3 = −10 (left) and its top-right zoom (right)
Table 3 Iterations performed by GrossBB algorithm on test problem T2
Iteration
Result at node (iteration)
Initialize
– ˜vS( ˜P) = ①
– Queue len. 1 (add the root problem to the queue)
1
˜vI ( ˜Pc): −10.2①0 −10①−1 −10.2①−2. Queue length: 0
– no pruning rules applied, branch ˜Pc in two sub-problems. Queue
length: 2
– ˜ 100①0 + 100①−1 + 100①−2
2
prune node: rule 1, empty feasible region. Queue length: 1
3
˜vI ( ˜Pc): −10①0 −10①−1 −10.2①−2. Queue length: 0
– no pruning rules applied, branch ˜Pc in two sub-problems. Queue
length: 2
– ˜ 100①0 + 100①−1 + 100①−2
4
˜vI ( ˜Pc): −10①0 −10①−1 −10①−2. Queue length: 1
– A feasible solution has been found: xopt = [10, −10, −10]T
– update ˜vS( ˜P) = ˜vI ( ˜Pc), prune node: rule 3
– ˜: 0①0 + 0①−1 + 0.02①−2
5
prune node: rule 1, empty feasible region. Queue length: 0
Result
Iteration 5. Optimization ended. Optimal solution found:
xopt = [10, −10, −10]T
˜fopt = −10①0 −10①−1 −10①−2
˜ = 0①0 + 0①−1 + 0①−2

Multi-objective Lexicographic Mixed-Integer Linear …
145
matrix Q is reported in Appendix A of [2]). After the rotation, a lower bound
and an upper bound were added:
−2ρ ⩽xi ⩽2ρ, i = 1, ..., 5.
Thus the following problem (A′,b′) has been generated:
LexMax
x1, −x2, ..., −x5
s.t.

x′ ∈Z5 : A′x′ ⩽b′
T3
where C′, A′ and vector b′ are reported in Appendix A of [2].
The lexicographic optimum for this problem is:
xopt = [1000, −999, −1000, −1000, −1000]T .
The new problem can be solved with GrossBB algorithm. After 11 steps, the
GrossBB ﬁnds the correct lexicographic optimum (more details in [2], Table
3, Appendix B).
8
Conclusions
To conclude this chapter, let us recall that we have shown the application of
Grossone to solve lexicographic multi-objective linear programming prob-
lems and their mixed-integer counterparts. We have proved that the use of
Grossone allows to give an inﬁnitely lower weights to lower-priority objec-
tives, without the need to specify the value of the ﬁnite weight M to use.
As a future work, we are planning to implement a Grossone-based Branch-
and-Cut algorithm, to speedup the convergence of the GrossBB algorithm
presented here.
Appendix
In this appendix we provide the proofs of Lemmas 1–3, taken from [6], and
reported also here for the sake of self-completeness of this exposition.
Proof (Lemma1)SincetheobjectivefunctionofproblemP4islinearinx,the
associated level sets (˜cT x = ˜v) are hyper-planes. Thus the maximum, for a
bounded and non-empty polyhedron S describing the domain of the problem

146
M. Cococcioni et al.
Algorithm 3: Generation of a randomly rotated “house” problem in Rn
dimensions
Step 1. Let {Ax ⩽b, x ∈Zn} be the initial, unrotated problem, in n-dimensions. The problems is formulated as
follow (ρ is a parameter that controls the size of the house):
LexMax
x1, −x2, ..., −xn
s.t.
−ρ + 0.2 ⩽x1 ⩽ρ + 0.2,
−ρ
⩽x2 ⩽ρ + 0.2
−ρ + 0.2 ⩽xi ⩽ρ + 0.2, i = 3, ..., n
−x1 −x2 ⩽2
−x1 + x2 ⩽2
x ∈Zn.
Step 2. Use as rotation matrix Q with a random little rotation:
rA = 0.0002;
rB = 0.0005;
φ = (rB-rA).*rand(1) + rA;
Q =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
cos (φ)
sin (φ) 0 0 .. 0
−sin (φ) cos (φ) 0 0 ... 0
0
0
1 0 ... 0
0
0
0 1 ... 0
...
...
... ... ... ...
0
0
0 0 ... 1
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
∈Rn×n
Step 3. Rotate the polytope: A′ = AQ (b and C does not change under rotations: b′ = b and C′ = C) and then add
these additional constraints as lower and upper bound for every variables to A′ (they are twice the size of the
house, in order to fully contain it):
−2ρ ⩽xi ⩽2ρ, i = 1, ..., n
Step 4 For the unrotated problem the optimal integer solution is xopt = [ρ, −ρ, −ρ, −ρ, ..., −ρ]T .
When a rotation is applied, if the rotation is between a sufﬁciently small range of angles the optimal solution
is: xopt = [ρ, 1 −ρ, −ρ, −ρ, ..., −ρ]T .
The optimal value is computed as: ˜fopt = ˜cT xopt , where ˜c is derived from C.
must be on a vertex (or belong to the convex hull of the optimal vertices),
for the same reasons for which the maximum of standard single-objective LP
problems is located on a vertex or in the convex hull of the optimal vertices.
In this case, similarly to standard LP, it follows that: (i) not all the vertices of
P4 are optimal, and (ii) not all the basic solutions are vertices.
The next lemma states that all the optimal solutions of P1 reach the same
(Gross-scalar) objective value for problem P4.
Proof (Lemma 2) Let x∗be a generic optimal solution belonging to (P1),
then from (4) we have that the objective value of the problem P4 associated
to it is:
˜cT x∗= (c1T x∗)①0 + (c2T x∗)①−1 + ... + (crT x∗)①−r+1.

Multi-objective Lexicographic Mixed-Integer Linear …
147
We can observe that:
ciT x∗= ki ∈R,
i ∈{1, ...,r},
due to the fact that x∗is optimal for P1 and this problem has been formulated
using purely ﬁnite numbers only. Thus we have
˜cT x∗= k1①0 + k2①−1 + ... + kr①−r+1 = ˜v.
□
The next lemma is the last step in preparing the proof of the equivalence
between P1 and P4.
Proof (Lemma 3) Let ˆx be a vertex of S which is not optimal for P1. Thus,
there exists an index q ∈{1, ...,r} such that
ciT ˆx = ciT x∗,
∀i ∈{1, ..., q −1},
but
cq T ˆx < cq T x∗.
This implies that
˜cT x∗−˜cT ˆx =
r

i=q
①−i+1(ciT x∗−ciT ˆx).
The expression above can be also expanded as follows
˜cT x∗−˜cT ˆx = ①−q+1(cqT x∗−cqT ˆx) + ①−(q+1)+1(c(q+1)T x∗−c(q+1)T ˆx) + ...
+ ①−r+1(crT x∗−crT ˆx).
Since ①−q+1(cqT x∗−cqT ˆx) > 0, it follows that

˜cT x∗−˜cT ˆx

is strictly
positive too, since r is ﬁnite. Indeed, adding a ﬁnite number of inﬁnitesimal
contributions of orders of ①higher than −q + 1 will keep the sum strictly
positive, even when these contributions are negative in sign, due to the prop-
erty of Grossone:
①−q+1(cqT x∗−cqT ˆx)
 >
①−q(c(q+1)T x∗−c(q+1)T ˆx)
 + ...+
①−r+1(crT x∗−crT ˆx)
 .

148
M. Cococcioni et al.
References
1. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
2. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020)
3. Cococcioni,M.,Fiaschi,L.:TheBig-MmethodwiththenumericalinﬁniteM.Optim.
Lett. 15, 2455–2468 (2021)
4. Cococcioni, M., Fiaschi, L., Lambertini, L.: Non-archimedean zero-sum games. J.
Comput. Appl. Math. 393, 113483 (2021)
5. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Towards lexicographic multi-
objective linear programming using grossone methodology. In: Sergeyev, Y.D.,
Kvasov, D.E., Dell’Accio, F., Mukhametzhanov, M.S., (eds.), Proceedings of the
2nd International Conference “Numerical Computations: Theory and Algorithms”,
vol. 1776, p. 090040. AIP Publishing, New York (2016)
6. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018)
7. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
8. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
9. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based com-
putationofnegativecurvaturedirectionsinlarge-scaleoptimization.J.Optim.Theory
Appl. 186(2), 554–589 (2020)
10. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71, 73–93 (2018)
11. Fiaschi, L., Cococcioni, M.: Numerical asymptotic results in game theory using
Sergeyev’s inﬁnity computing. Int. J. Unconvent. Comput. 14(1), 1–25 (2018)
12. Fiaschi, L., Cococcioni, M.: Non-archimedean game theory: a numerical approach.
Appl. Math. Comput. 409, 125356 (2021)
13. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
14. Isermann, H.: Linear lexicographic optimization. OR Spektrum 4, 223–228 (1982)
15. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed pareto-lexicographic many-
objective optimization problems: the case of priority chains. Swarm Evol. Comput.
55, 100687 (2020)
16. Lai,L.,Fiaschi,L.,Cococcioni,M.,Deb,K.:Handlingprioritylevelsinmixedpareto-
lexicographic many-objective optimization problems. In: Ishibuchi, H., Zhang, Q.,
Cheng, R., Li, K., Li, H., Wang, H., Zhou, A. (eds.) Evolutionary Multi-Criterion
Optimization, pp. 362–374. Springer International Publishing, Cham (2021)
17. Lai, L., Fiaschi, L., Cococcioni, M., Deb, K.: Solving mixed pareto-lexicographic
many-objective optimization problems: the case of priority levels. IEEE Trans. Evo-
lut. Comput. (2021). http://dx.doi.org/10.1109/TEVC.2021.3068816

Multi-objective Lexicographic Mixed-Integer Linear …
149
18. Lai, L., Fiaschi, L., Cococcioni, M., Deb, K.: Pure and mixed lexicographic-paretian
many-objective evolutionary optimization: state of the art. Nat. Comput. (2022).
Submitted
19. Pappalardo, M., Passacantando, M.: Ricerca Operativa. Pisa University Press (2012)
20. Pourkarimi, L., Zarepisheh, M.: A dual-based algorithm for solving lexicographic
multiple objective programs. Eur. J. Oper. Res. 176, 1348–1356 (2007)
21. Rizza, D.: Supertasks and numeral systems. In: Proceedings of the 2nd Interna-
tional Conference “Numerical Computations: Theory and Algorithms”, vol. 1776,
p. 090005. AIP Publishing, New York (2016). https://doi.org/10.1063/1.4965369
22. Rizza, D.: A study of mathematical determination through Bertrand’s Paradox. Phi-
los. Math. 26(3), 375–395 (2018)
23. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Uncon-
vent. Comput. 14(2), 139–158 (2019)
24. Sergeyev, Y.D.: Solving ordinary differential equations by working with inﬁnitesi-
mals numerically on the Inﬁnity Computer. Appl. Math. Comput. 219(22), 10668–
10681 (2013)
25. Sergeyev, Y.D.: The olympic medals ranks, lexicographic ordering, and numerical
inﬁnities. Math. Intell. 37(2), 4–8 (2015)
26. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4, 219–320 (2017).
https://doi.org/10.4171/EMSS/4-2-3
27. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
28. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: On strong homogeneity of a
class of global optimization algorithms working with inﬁnite and inﬁnitesimal scales.
Commun. Nonlinear Sci. Numer. Simul. 59, 319–330 (2018)
29. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.:
Numerical methods for solving initial value problems on the inﬁnity computer. Int.
J. Unconvent. Comput. 12(1), 3–23 (2016)
30. Sherali, H., Soyster, A.: Preemptive and nonpreemptive multi-objective program-
ming: relationship and counterexamples. J. Optim. Theory Appl. 39(2), 173–186
(1983)
31. Stanimirovic, I.: Compendious lexicographic method for multi-objective optimiza-
tion. Facta universitatis - Ser.: Math. Inf. 27(1), 55–66 (2012)

The Use of Inﬁnities and Inﬁnitesimals
for Sparse Classiﬁcation Problems
Renato De Leone, Nadaniela Egidi, and Lorella Fatone
Abstract Inthischapterwediscusstheuseofgrossoneandthenewapproach
to inﬁnitesimal and inﬁnite proposed by Sergeyev in determining sparse solu-
tions for special classes of optimization problems. In fact, in various opti-
mization and regression problems, and in solving overdetermined systems
of linear equations it is often necessary to determine a sparse solution, that
is a solution with as many as possible zero components. Expanding on the
results in [16], we show how continuously differentiable concave approxima-
tions of the l0 pseudo–norm can be constructed using grossone, and discuss
the properties of some new approximations. Finally, we will conclude dis-
cussing some applications in elastic net regularization and Sparse Support
Vector Machines.
1
Introduction
In many optimization problems, in regression methods and when solving
over-determined systems of equations, it is often necessary to determine a
R. De Leone (B) · N. Egidi · L. Fatone
School of Science and Technology, University of Camerino, Camerino, MC, Italy
e-mail: renato.deleone@unicam.it
N. Egidi
e-mail: nadaniela.egidi@unicam.it
L. Fatone
e-mail: lorella.fatone@unicam.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_6
151

152
R. De Leone et al.
sparse solution, that is, a solution with the minimum number of nonzero com-
ponents. This kind of problems are known as sparse approximation problems
and arise in different ﬁelds. In Machine Leaning, the Feature Extraction prob-
lem requires, for a given problem, to eliminate as many features as possible,
whilestillmaintainingagoodaccuracyinsolvingtheassignedtask(forexam-
ple, a classiﬁcation task). Sparse solutions are also required in signal/image
processing problem, for example in sparse approximation of signals, image
denoising, etc. [4, 12, 36].
In these cases the l0 pseudo-norm is utilized. This pseudo-norm counts the
number of nonzero elements of a vector. Problems utilizing the l0 pseudo-
norm have been considered by many researchers, but they seem “to pose
many conceptual challenges that have inhibited its widespread study and
application” [4]. Moreover, the resulting problem is NP–hard and, in order to
construct a more tractable problem, various continuously differentiable con-
cave approximations of the l0 pseudo-norm are used, or the l0 pseudo-norm
is replaced by the simpler to handle 1–norm. In [27] two smooth approxima-
tions of the l0 pseudo-norm are proposed in order to determine a vector that
has the minimum l0 pseudo-norm.
Recently, Sergeyev proposed a new approach to inﬁnitesimals and inﬁni-
ties1 based on the numeral ①, the number of elements of IN, the set of natural
numbers. It is crucial to note that ①is not a symbol and is not used to per-
form symbolic calculations. In fact, the ①is a natural number, and it has
both cardinal and ordinal properties, exactly as the “standard”, ﬁnite natu-
ral numbers. Moreover, the new proposed approach is different from non–
Standard Analysis, as demonstrated in [33]. A comprehensive description of
the grossone–based methodology can also be found in [32].
The use of ①and the new approach to inﬁnite and inﬁnitesimals has
been beneﬁcial in several ﬁelds of pure and applied mathematics including
optimization [6–9, 14, 15, 17–19, 23], numerical differentiation [29], ODE
[1, 22, 34], hyperbolic geometry [25], inﬁnite series and the Riemann zeta
function [28, 30], biology [31], and cellular automata [13].
Moreover, this new computational methodology has been also utilized in
the ﬁeld of Machine Learning allowing to construct new spherical separations
for classiﬁcation problems [2], and novel sparse Support Vector Machines
(SSVMs) [16].
In this chapter we discuss the use of ①to obtain new approximations for the
l0 pseudo-norm, and two applications are considered in detail. More speciﬁ-
cally, the chapter is organized as follows. In Sect.2 some of the most utilized
smooth approximations of the l0 pseudo–norm proposed in the literature are
1 See Chap. 1 for an in–depth description of the properties of the new system and its
advantages

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
153
discussed. Then, in the successive Sect.3 it is shown how to utilize ①for con-
structing approximations of the l0 pseudo-norm. Finally, in Sect.4, mostly
based on [16], two relevant applications of the newly proposed approxima-
tion scheme for the l0 pseudo norm are discussed in detail: the elastic net
regulation problem and sparse Support Vector Machines.
We brieﬂy describe our notation now. All vectors are column vectors and
willbeindicatedwithlowercaseLatinletter(i.e. x, y,. . .).Subscriptsindicate
components of a vector, while superscripts are used to identify different
vectors. Matrices will be indicated with upper case Roman letter (i.e. A, B,
. . .). The set of natural and real numbers will be denoted, respectively, by IN
and IR. The space of the n–dimensional vectors with real components will
be indicated by IRn. Superscript T indicates transpose. The scalar product of
two vectors x and y in IRn will be denoted by xT y. Instead, for a generic
Hilbert space, the scalar product of two elements x and y will be indicated by
⟨x, y⟩. The Euclidean norm of a vector x will be denoted by ∥x∥. The space
of the m × n matrices with real components will be indicated by IRm×n. For
a m × n matrix A, Ai j is the element in the ith row, jth column.
In the new positional numeral system with base ①, a gross-scalar (or
gross–number) C has the following representation:
C = C(pm)①pm + · · · + C(p1)①p1 + C(p0)①p0 + C(p−1)①p−1 + · · · + C(p−k)①p−k,
(1)
wherem, k ∈IN,fori = −k, −k + 1, . . . , −1, 0, 1, . . . , m −1, m,thequan-
tities C(pi) are ﬂoating-point numbers and pi are gross-numbers such that
pm > pm−1 > · · · > p1 > p0 = 0 > p−1 > · · · > p−k+1 > p−k.
(2)
If m = k = 0 the gross-number C is called ﬁnite; if m > 0 it is called inﬁnite;
if m = 0, C(p0) = 0 and k > 0 it is called inﬁnitesimal; the exponents pi,
i = −k, −k + 1, . . . , −1, 0, 1, . . . , m −1, m, are called gross-powers.
2
The l0 Pseudo-norm in Optimization Problems
Given a vector x = (x1, x2, . . . , xn)T ∈IRn, the l0 pseudo-norm of x is
deﬁned as the number of its components different from zero, that is:
∥x∥0 = number of nonzero components of x =
n

i=1
1xi,
(3)

154
R. De Leone et al.
where 1a is the characteristic (indicator) function, that is, the function which
is equal to 1 if a ̸= 0 and zero otherwise.
Note that ∥·∥0 is not a norm and hence is called, more properly, pseudo-
norm. In fact, for a non zero vector x ∈IRn, and a not null constant λ ∈IR,
we have:
∥λx∥0 = ∥x∥0 .
Consequently ∥λx∥0 = |λ| ∥x∥0, λ ∈IR, if and only if |λ| = 1.
The l0 pseudo-norm plays an important role in several numerical analysis
and optimization problems, where it is important to get a vector with as few
non-zero components as possible. For example, this pseudo-norm has impor-
tant applications in elastic-net regularization, pattern recognition, machine
learning, signal processing, subset selection problem in regression and port-
folio optimization. For example, in signal and image processing many media
types can be sparsely represented using transform-domain methods, and spar-
sity of the representation is fundamental in many highly used techniques of
compression (see [4] and references therein). In [20, 26] the cardinality-
constrained optimization problem is studied and opportunely reformulated.
In [5] the general optimization problem with cardinality constraints has been
reformulated as a smooth optimization problem.
The l0 pseudo-norm is strongly related to the lp norms. Given a vector
x = (x1, x2, . . . , xn)T ∈IRn, the lp norm of x is deﬁned as
∥x∥p :=
 n

i=1
|xi|p
 1
p
.
It is not too difﬁcult to show that
∥x∥0 = lim
p→0 ∥x∥p
p = lim
p→0
n

i=1
|xi|p .
In Fig.1 the behavior of |σ|p (σ ∈IR) for different values of p is shown (see
also [4]). Note that, as the ﬁgure suggests, for 0 < p < 1, the function ∥x∥p
is a concave function.
It must be noted that the use of ∥x∥0 makes the problems extremely com-
plicated to solve, and various approximations of the l0 pseudo-norm have
been proposed in the scientiﬁc literature, For example, in [27] two smooth
approximations of the l0 pseudo-norm are proposed in order to determine a
particular vector that has the minimum l0 pseudo-norm.
In [24], in the framework of elastic net regularization, the following
approximation of ∥x∥0 is studied:

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
155
Fig. 1 The value of |σ|p
for different values of p
∥x∥0,δ :=
n

i=1
x2
i
x2
i + δ,
(4)
where δ ∈IR, δ > 0, and a small δ is suggested in order to provide a better
approximation of ∥x∥0.
Instead, in the context of Machine Learning and Feature Selection [3], the
following approximation of ∥x∥0:
∥x∥0,α :=
n

i=1

1 −e−α|xi|
,
(5)
where α ∈IR, α > 0, is proposed, and the value α = 5 is recommended.
By using ①, in [16] a new approximation of ∥x∥0 has been suggested. In
the next section we discuss in detail this approximation and we also propose
other approximations that use the new numeral system based on ①. Moreover,
we provide the connections between ∥x∥0 and the new approximations.
Note that the approximation introduced in [16] has been used in connection
to two different applications. The ﬁrst application is an elastic net regulariza-
tion. The second application concerns classiﬁcation problems using sparse
Support Vector Machines. These two applications are extensively reviewed
in Sect.4.

156
R. De Leone et al.
3
Some Approximations of the l0 Pseudo-norm
Using ①
The ﬁrst approximation of the l0 pseudo-norm in terms of ①was proposed
in [16], where, following the idea suggested in [24] of approximating the l0
pseudo-norm
by (4), the following approximation has been suggested:
∥x∥0,①,1 :=
n

i=1
x2
i
x2
i + ①−1 .
(6)
In this case, we have that
∥x∥0,①,1 = ∥x∥0 + C①−1,
(7)
for some gross-number C which includes only ﬁnite and inﬁnitesimal terms.
Therefore, the ﬁnite parts of ∥x∥0 and ∥x∥0,①,1 coincide.
To this scope, let
ψ1(t) =
t2
t2 + ①−1 ,
t ∈IR.
(8)
We have that ψ1(0) = 0 and ψ1(t) = 1 −①−1S, when t ̸= 0, where S is a
gross-number such that
0 < S =
1
t2 + ①−1 < 1
t2 .
Therefore, S has only ﬁnite and inﬁnitesimal terms. Moreover,
n

i=1
x2
i
x2
i + ①−1 =
n

i=1
ψ1(xi) =
n

i=1,xi̸=0
ψ1(xi) = ∥x∥0 + C①−1,
(9)
where
C =
⎧
⎪⎪⎨
⎪⎪⎩
−
n

i=1,xi̸=0
Si,
when ∥x∥0 ̸= 0,
0,
otherwise,
and Si is a gross-number such that

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
157
0 < Si =
1
x2
i + ①−1 < 1
x2
i
,
xi ̸= 0,
i = 1, . . . , n.
Hence C is a gross-number with only ﬁnite and inﬁnitesimal terms and the
ﬁnite part of of ∥x∥0 and ∥x∥0,①,1 are the same.
A different proof of this result is provided in [16]. For i = 1, . . . , n, let
assume that
xi = x(0)
i
+ Ri①−1,
where Ri includes only ﬁnite and inﬁnitesimal terms.
When x(0)
i
= 0:
ψ1(xi) =
R2
i ①−2
R2
i ①−2 + ①−1 = ①−1
R2
i
R2
i ①−1 + 1
= 0 ①0 + R′
i①−1,
where R′
i includes only ﬁnite and inﬁnitesimal terms.
When, instead, x(0)
i
̸= 0:
ψ1(xi) =

x(0)
i
+ Ri①−12

x(0)
i
+ Ri①−12
+ ①−1
= 1 −
①−1

x(0)
i
+ Ri①−12
+ ①−1
= 1 + R′
i①−1,
where, again, R′
i includes only ﬁnite and inﬁnitesimal terms. Therefore,
∥x∥0,①,1 =
n

i=1
ψ1(xi) = ∥x∥0 + S①−1
where S includes only ﬁnite and inﬁnitesimal terms and hence ∥x∥0,①,1 and
∥x∥0 coincide in their ﬁnite part.
Following the idea suggested in [3], we now propose three novel approx-
imation schemes of the l0 pseudo-norm all based on the use of ①. In [3] the
authors proposed to approximate the l0 pseudo-norm using (5) and suggest
to take a ﬁxed value for α, i.e. α = 5, or an increasing sequence of values of
α.
Based on this idea, we propose the following approximation formula for
∥x∥0:
∥x∥0,①,2 :=
n

i=1

1 −①−α|xi|
,
α > 0.
(10)

158
R. De Leone et al.
Also in this case, the ﬁnite parts of ∥x∥0 and ∥x∥0,①,2 coincide. More pre-
cisely, let us show that
∥x∥0,①,2 = ∥x∥0 −①−αmxC,
(11)
where
mx =

min

|xi| : xi ̸= 0

,
when x ̸= 0,
0,
otherwise,
(12)
and C is a gross-number which is null when ∥x∥0 = 0 and, otherwise,
includes only ﬁnite and inﬁnitesimal terms.
Let us deﬁne
ψ2(t) = 1 −①−α|t|,
t ∈IR.
(13)
Since ψ2(0) = 0, we have:
∥x∥0,①,2 =
n

i=1

1 −①−α|xi|
=
=
n

i=1
ψ2(xi) =
n

i=1,xi̸=0
ψ2(xi) =
= ||x||0 −
n

i=1,xi̸=0
①−α|xi| = ||x||0 −①−αmxC.
(14)
It is easy to see that C = 0 when ∥x∥0 = 0. Instead, if ∥x∥0 ̸= 0 then C
has only ﬁnite and inﬁnitesimal terms. This shows that ∥x∥0 and ∥x∥0,①,2
coincide in their ﬁnite part.
Another approximation of the l0 pseudo–norm is given by:
∥x∥0 ≈∥x∥0,①,3 :=
n

i=1

1 −e−①|xi|
.
(15)
In this case, it is possible to show that
∥x∥0,①,3 = ∥x∥0 −e−①mxC,
(16)
where, as in the previous cases, C is a gross-number which includes only
ﬁnite and inﬁnitesimal terms and is null when ∥x∥0 = 0. Hence, also in this
case we have that the ﬁnite parts of ∥x∥0 and ∥x∥0,①,3 coincide.

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
159
To prove the above result, let
ψ3(t) = 1 −e−①|t|,
t ∈IR.
(17)
Since ψ3(0) = 0, we have:
∥x∥0,①,3 =
n

i=1

1 −e−①|xi|
=
=
n

i=1
ψ3(xi) =
n

i=1,xi̸=0
ψ3(xi) =
= ||x||0 −
n

i=1,xi̸=0
e−①|xi| = ||x||0 −e−①mxC,
(18)
where mx is deﬁned in (12) and C is a gross-number with only ﬁnite and
inﬁnitesimal terms. Moreover, C is null when ∥x∥0 = 0.
Finally, another approximation of the l0 pseudo–norm, always in the spirit
of (5), is given by:
∥x∥0,①,4 :=
n

i=1

1 −①−①|xi|
.
(19)
In this last case, let
ψ4(t) = 1 −①−①|t|,
t ∈IR.
(20)
Since even in this circumstance ψ4(0) = 0, we have:
∥x∥0,①,4 =
n

i=1

1 −①−①|xi|
=
=
n

i=1
ψ4(xi) =
n

i=1,xi̸=0
ψ4(xi) =
= ||x||0 −
n

i=1,xi̸=0
①−①|xi| = ||x||0 −①−①mxC,
(21)
where mx is again deﬁned in (12) and C is a gross-number with only ﬁnite
and inﬁnitesimal terms that is null when ||x||0 = 0. As in the previous cases
we have that

160
R. De Leone et al.
∥x∥0,①,4 = ∥x∥0 −①−①mxC,
(22)
and, therefore, the ﬁnite parts of ∥x∥0 and ∥x∥0,①,4 coincide.
We have presented a number of different approximation schemes for the
l0 pseudo-norm. We want to stress that in all the cases the value of ∥x∥0
and its approximation coincide in their ﬁnite part and may only differ for
inﬁnitesimals quantities.
In the next section we will discuss some utilization of these approximating
schemes in two extremely important problems: regularization and classiﬁca-
tion.
4
Applications in Regularization and Classiﬁcation
Problems
In this section we review some interesting uses of the proposed l0 pseudo–
norm approximations in two classes of optimization problems: elastic net
regularization problems and sparse Support Vector Machine classiﬁcation
problems. These two applications are deeply studied in [16].
4.1
Elastic Net Regularization
There are many important applications where we want to determine a solution
x ∈IRn of a given linear system Ax = b, A ∈IRm×n, b ∈IRm, such that x
has the smallest number of nonzero components, that is
min
x
∥x∥0 ,
subject to Ax = b.
To this problem it is possible to associate the following generalized elastic
net regularization:
min
x
1
2 ∥Ax −b∥2
2 + λ0 ∥x∥0 + λ2
2 ∥x∥2
2 ,
(23)
where λ0 > 0 and λ2 > 0 are two regularization parameters (see [24] for
details).
In [24] a suitable algorithm for the solution of Problem (23) with ∥x∥0,δ
(deﬁned in (4)) instead of ∥x∥0 is proposed. The corresponding solution
approximates the solution of (23) and depends on the choice of δ > 0 in (4).

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
161
Following the idea suggested in [24], we look for the solution of the fol-
lowing minimization problem:
min
x
f1(x),
(24)
where
f1(x) := 1
2 ∥Ax −b∥2
2 + λ0 ∥x∥0,①,1 + λ2
2 ∥x∥2
2 .
(25)
Note that Problem (24)–(25) is obtained from Problem (23) by substituting
∥x∥0,①,1 to ∥x∥0.
In [16] we proved that the corresponding solution coincides with the solu-
tion of the original Problem (23) apart from inﬁnitesimal terms. In particular,
in [16], the following iterative scheme for the solution of Problem (24)–(25)
has been proposed: given an initial value x0 ∈IRn, for k = 0, 1, . . ., compute
xk+1 by solving

AT A + λ2I + λ0D(xk)

xk+1 = AT b,
(26)
where I ∈IRn×n is the identity matrix and D ∈IRn×n is the following diag-
onal matrix:
Dii(x) =
2①−1

(xi)2 + ①−12 ,
Di j(x) = 0, i ̸= j.
(27)
The convergence of the sequence {xk} to the solution of Problem (24)–
(25) is ensured by Theorem 1 in [16]. In particular, when L := {x : f1(x) ≤
f1(x0)} is a compact set, the above constructed sequence {xk}k has at least
one accumulation point, xk ∈L for each k = 1, . . . , and each accumulation
point of {xk}k belongs to L and is a stationary point of f1.
In [24] a similar algorithm was proposed, where ∥x∥0 was substituted by
(4). However, in this latter case, the quality of the ﬁnal solution (in terms
of being also a solution of Problem (24)–(25) strongly depends on the value
of δ that is utilized. In our approach, instead, taking into account that ∥x∥0
and our approximation with ①only differ for inﬁnitesimal terms, the ﬁnal
solution solves also Problem (24)–(25).
The results presented here are relative to the ﬁrst of the four approximation
schemes for ∥x∥0 discussed in Sect.3.
Considering the minimization of the following functions

162
R. De Leone et al.
fi(x) := 1
2 ∥Ax −b∥2
2 + λ0 ∥x∥0,①,i + λ2
2 ∥x∥2
2 ,
(28)
with i = 2 or i = 3 or i = 4, and computing the corresponding ﬁrst order
optimality conditions, new iterative schemes similar to (26) can be obtained
and studied.
4.2
Sparse Support Vector Machines
The grossone ①and the different approximations of l0-pseudo norm can be
also used in Sparse Support Vector Machines.
Given empirical data (training set) (xi, yi), i = 1, . . . ,l, with inputs xi ∈
IRn, and outputs yi ∈{−1, 1}, i = 1, . . . ,l, we want to compute a vector
w ∈IRn and a scalar θ (and hence an hyperplane) such that:
wT xi + θ > 0 when yi = 1,
wT xi + θ < 0 when yi = −1.
The classiﬁcation function is
h(x) = sign

wT x + θ

.
Given
φ : IRn →E,
where E is an Hilbert space with scalar product ⟨·, ·⟩, the optimal hyperplane
can be constructed by solving the following (primal) optimization problem
(see [10, 11, 35] and references therein for details):
min
w,θ,ξ
1
2 ⟨w, w⟩+ CeT ξ,
subject to yi

w, φ(xi)

+ θ

≥1 −ξi,
i = 1, . . . ,l,
ξi ≥0,
i = 1, . . . ,l,
(29)
where e ∈IRl is a vector with all elements equal to 1 and C is a positive
scalar.
The dual of (29) is
min
α
1
2αT Qα −eT α,
subject to
yT α = 0,
0 ≤α ≤Ce,
(30)

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
163
where
Qi j = yi y j Ki j,
Ki j = K(xi, x j) :=

φ(xi), φ(x j)

,
i, j = 1, . . . ,l,
and K : IRn × IRn →IR is the kernel function.
We note that, this dual problem and the classiﬁcation function depend only
on Ki j =

φ(xi), φ(x j)

. In fact, from the Karush–Kuhn–Tucker conditions
we have
w =
l
i=1
αi yiφ(xi),
(31)
and the classiﬁcation function reduces to
h(x) = sign

⟨w, φ(x)⟩+ θ

= sign
 l
i=1
αi yi

φ(xi), φ(x)

+ θ

.
In [21], the authors consider an optimization problem based on (29) where
1
2 ⟨w, w⟩is replaced with∥α∥0 (and,then,this termis approximated by 1
2α
α
for opportune values of a diagonal matrix 
) and use the expansion (31) of
w in terms of α.
Furthermore, in [16] the quantity ∥α∥0 is replaced by ∥α∥0,①,1, and the
following ①–Sparse SVM problem is deﬁned:
min
α,θ,ξ
①
2 ∥α∥0,①,1 + CeT ξ,
subject to yi

Ki.T α + θ

≥1 −ξi,
i = 1, . . . ,l,
ξ ≥0,
(32)
where Ki. denotes the column vector that corresponds to the ith row of the
matrix K.
The algorithmic scheme, originally proposed in [21] and revised in [16],
starting from λ0
r = 1, r = 1, . . . ,l, requires, at each iteration, the solution
of the following optimization problem:
min
α,θ,ξ
1
2
l
r=1
λk
rα2
r + CeT ξ,
subject to yi

Ki.T α + θ

≥1 −ξi,
i = 1, . . . ,l,
ξ ≥0,
(33)

164
R. De Leone et al.
and then the update of λk with a suitable formula.
From the Karush–Kuhn–Tucker conditions for Problem (32), it follows
that
1

α2
r + ①−12 αr = ¯K T
r. β,
r = 1, . . . ,l,
(34)
where ¯Kr. is the r–th row of the matrix ¯K with ¯Kr j = y j K jr, for r, j =
1, . . . ,l.
The Conditions (34) above suggest the more natural updating formula:
λk+1
r
=
1

α2
r + ①−12 ,
r = 1, . . . ,l.
(35)
Moreover, by considering the expansion of the gross-number α, it is easy
to verify that formula (35) well mimics the updating formulas for λk proposed
in [21], also providing a more sound justiﬁcation for the updating scheme.
We note that the algorithm proposed in [16], and brieﬂy described here, is
based on the ﬁrst of the approximations of ∥α∥0 discussed in Sect.3. Using the
other different approximations introduced in the same section, new different
updating formulas for λk+1 can be obtained.
5
Conclusions
The use of the l0 pseudo–norm is pervasive in optimization and numerical
analysis, where a sparse solution is often required. Using the new approach to
inﬁnitesimalandinﬁniteproposedbySergeyev,fourdifferentapproximations
of the l0 pseudo–norm are presented in this chapter. In all cases, we proved
that the ﬁnite value of thel0 pseudo–norm and and its approximation coincide,
being different only for inﬁnitesimal terms. The use of such approximations
is beneﬁcial in many applications, where the discontinuity due to the use of
the l0 pseudo–norm is easily eliminated, by using one of the four proposed
approaches presented in this chapter.

The Use of Inﬁnities and Inﬁnitesimals for Sparse Classiﬁcation Problems
165
References
1. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
2. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft. Comput.
24(23), 17751–17759 (2020)
3. Bradley, P.S., Mangasarian, O.L.: Feature selection via concave minimization and
support vector machines. In: Proceedings of the Fifteenth International Conference
on Machine Learning, ICML ’98, pp. 82–90. Morgan Kaufmann Publishers Inc., San
Francisco (1998)
4. Bruckstein, A.M., Donoho, D.L., Elad, M.: From sparse solutions of systems of
equations to sparse modeling of signals and images. SIAM Rev. 51(1), 34–81 (2009)
5. Burdakov, O., Kanzow, C., Schwartz, A.: Mathematical programs with cardinality
constraints: reformulation by complementarity-type conditions and a regularization
method. SIAM J. Optim. 26(1), 397–425 (2016)
6. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020)
7. Cococcioni,M.,Fiaschi,L.:TheBig-MmethodwiththenumericalinﬁniteM.Optim.
Lett. 15, 2455–2468 (2021)
8. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Towards lexicographic multi-
objective linear programming using grossone methodology. In: Sergeyev, Y.D.,
Kvasov, D.E., Dell’Accio, F., Mukhametzhanov, M.S., (eds.) Proceedings of the
2nd International Conference “Numerical Computations: Theory and Algorithms”,
vol. 1776, p. 090040. AIP Publishing, New York (2016)
9. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: Theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018)
10. Cortes,C.,Vapnik,V.:Support-vectornetworks.Mach.Learn.20(3),273–297(1995)
11. Cristianini, N., Shawe-Taylor, J.: An Introduction to Support Vector Machines and
Other Kernel-based Learning Methods. Cambridge University Press (2000)
12. Dabov, K., Foi, A., Katkovnik, V., Egiazarian, K.: Image denoising by sparse 3-d
transform-domain collaborative ﬁltering. IEEE Trans. Image Process. 16(8), 2080–
2095 (2007)
13. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput.
218(16), 8077–8082 (2012)
14. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
15. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
16. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft. Comput. 23(24), 17669–17677 (2020)
17. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: How Grossone Can Be Helpful
to Iteratively Compute Negative Curvature Directions. Lecture Notes in Computer
Science (including subseries Lecture Notes in Artiﬁcial Intelligence and Lecture
Notes in Bioinformatics), vol. 11353, pp. 180–183 (2019)

166
R. De Leone et al.
18. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
19. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
20. Gotoh, J., Takeda, A., Tono, K.: DC formulations and algorithms for sparse opti-
mization problems. Math. Program. 169, 141–176 (2018)
21. Huang, K., Zheng, D., Sun, J., Hotta, Y., Fujimoto, K., Naoi, S.: Sparse learning for
support vector classiﬁcation. Pattern Recogn. Lett. 31(13), 1944–1951 (2010)
22. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation of
higher order lie derivatives on the inﬁnity computer. J. Computat. Appl. Math. 383
(2021)
23. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed Pareto-Lexicographic multi-
objective optimization problems: the case of priority chains. Swarm Evolut. Comput.
55, 100687 (2020)
24. Li, S., Ye, W.: A generalized elastic net regularization with smoothed l0 penalty.
Adv. Pure Math. 7, 66–74 (2017)
25. Margenstern, M.: An application of grossone to the study of a family of tilings of
the hyperbolic plane. Appl. Math. Comput. 218(16), 8005–8018 (2012)
26. Pham Dinh, T., Le Thi, H.A.: Recent advances in DC programming and DCA. In:
Nguyen, N.T., Le Thi, H.S., (eds.) Transactions on Computational Intelligence XIII.
Lecture Notes in Computer Science, vol. 8342. Springer (2014)
27. Rinaldi, F., Schoen, F., Sciandrone, M.: Concave programming for minimizing the
zero-norm over polyhedral sets. Comput. Optim. Appl. 46, 467–486 (2010)
28. Sergeyev, Y.D.: Numerical point of view on calculus for functions assuming ﬁnite,
inﬁnite, and inﬁnitesimal values over ﬁnite, inﬁnite, and inﬁnitesimal domains. Non-
linear Anal. Seri. A: Theory, Methods Appl. 71(12), e1688–e1707 (2009)
29. Sergeyev, Y.D.: Higher order numerical differentiation on the inﬁnity computer.
Optim. Lett. 5(4), 575–585 (2011)
30. Sergeyev, Y.D.: On accuracy of mathematical languages used to deal with the Rie-
mann zeta function and the Dirichlet eta function. p-Adic numbers. Ultrametric Anal.
Appl. 3(2), 129–148 (2011)
31. Sergeyev, Y.D.: Using blinking fractals for mathematical modelling of processes of
growth in biological systems. Informatica 22(4), 559–576 (2011)
32. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
33. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
34. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.:
Numerical methods for solving initial value problems on the inﬁnity computer. Int.
J. Unconv. Comput. 12(1), 3–23 (2016)
35. Smola, A.J., Schölkopf, B.: A tutorial on support vector regression. Stat. Comput.
14(3), 199–222 (2004)
36. Stankovi´c, L., Sejdi´c, E., Stankovi´c, S., Dakovi´c, M., Orovi´c, I.: A tutorial on sparse
signal reconstruction and its applications in signal processing. Circuits Syst. Signal
Process. 38(3), 1206–1263 (2019)

The Grossone-Based Diagonal Bundle
Method
Manlio Gaudioso, Giovanni Giallombardo,
and Marat S. Mukhametzhanov
Abstract We discuss the fruitful impact of the inﬁnity computing paradigm
on the practical solution of convex nonsmooth optimization problems. We
consider a class of unconstrained nonsmooth optimization methods based on
a variable metric approach,where the use ofthe inﬁnity computing techniques
allows one to numerically deal with quantities which can take arbitrarily small
or large values, as a consequence of nonsmoothness. In particular, choosing
a diagonal matrix with positive entries as a metric, we modify the so called
Diagonal Bundle algorithm by means of matrix updates based on the inﬁnity
computing paradigm, and we provide the computational results obtained on
a set of benchmark academic test-problems.
1
Introduction
We address unconstrained optimization problems of the type
min
x∈Rn f (x),
(1)
where f : Rn →R is a real-valued not necessarily differentiable function
of several variables. It is well known that nonsmooth (or nondifferentiable)
optimization is about ﬁnding a local minimizer of f , and that even if nons-
M. Gaudioso · G. Giallombardo (B) · M. S. Mukhametzhanov
Università della Calabria, Rende, Italy
e-mail: giovanni.giallombardo@unical.it
M. Gaudioso
e-mail: manlio.gaudioso@unical.it
M. S. Mukhametzhanov
e-mail: m.mukhametzhanov@dimes.unical.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_7
167

168
M. Gaudioso et al.
moothness occurs at a zero-measure set of the function domain, convergence
is not ensured when algorithms tailored to the smooth case are adopted. In
fact, in-depth research activities have been developed in last decades [6, 20],
and several proposals for dealing with nonsmoothness are offered in the lit-
erature (as for historical contributions, we mention here the books [14, 28,
45] and the seminal papers [8, 27]).
We particularly focus on the convex version of the nonsmooth problem (1),
for which two research mainstreams are active: subgradient methods (see the
classic version in [45] and, among the others, the more recent variants in [5,
17, 36]) and bundle methods. The latter stems from the seminal paper [31],
and beneﬁts from both the cutting plane model [8, 27] and the conjugate sub-
gradient approach [46]. At each iteration of a bundle method [24] the solution
of a quadratic program is required in order to ﬁnd a tentative displacement
from the current approximation of the minimizer. As a consequence of the
nonsmoothness, no matter if line-search techniques are adopted, a sufﬁcient
reduction of the objective function may not be ensured. For such reason,
bundle methods are based on the so called null step, whenever no progress
toward the minimizer is achieved, with some additional information about
the local behavior of the objective function being collected in the bundle.
Literature on bundle methods is very rich. We cite here some contribu-
tions given in [4, 13, 18, 19, 29, 33], and those (see [22, 26, 34]) where
many features of the standard bundle approach are preserver, while trying
to simplify the displacement search, thus avoiding solution of a too burden-
some subproblem at each iteration. The latter ones exploit some ideas coming
from the vast literature on the variable metric approach applied to smooth
optimization, as they adopts variants of standard Quasi–Newton formulae in
order to determine an approximated Hessian matrix (see [15] for a classic
survey on Quasi–Newton methods and [6], with the references therein, for
the applications of the variable metric approach to nonsmooth optimization).
We recall that Quasi–Newton methods for ﬁnding a local minimizer of
a differentiable function f : Rn →R are iterative techniques where, at any
point xk ∈Rn, a matrix Bk is generated as an approximation of the Hessian
matrix such that it satisﬁes the equation
Bksk = uk,
(2)
where
sk ≜xk −xk−1
(3)
and
uk ≜∇f (xk) −∇f (xk−1).
(4)
Sometimes Eq.(2) is replaced by

The Grossone-Based Diagonal Bundle Method
169
Hkuk = sk,
(5)
where Hk is the inverse of Bk.
Methods extending the Quasi–Newton idea to the convex nondifferentiable
case still require at each iteration the Eq.(2) be satisﬁed, but the deﬁnition
of vector uk has to be updated. In fact, denoting by ∂f (x) the subdifferential
and by g ∈∂f (x) any subgradient of f at x, see [24], uk can be restated as
uk ≜gk −gk−1,
(6)
with gk and gk−1 being subgradients of f at the points xk and xk−1, respec-
tively. In the case of nonsmooth functions, the search for a matrix Bk satisfy-
ing (2) is a problem naturally ill-conditioned, given the possible discontinu-
ities in the ﬁrst order derivatives, which may return “large” uk corresponding
to “small” sk.
The latter remark is the main motivation underlying the approach intro-
duced in [21], where Eq.(2) is tackled by applying the grossone concept
[38] to handle inﬁnite and inﬁnitesimal numbers. Such methodology, that
is not related to the well known non-standard analysis framework [41], has
already been successfully applied in optimization [3, 11, 12, 16, 30, 44]
and numerical differentiation [10, 48], and in a number of other theoretical
and computational research areas such as cellular automata [9], Euclidean
and hyperbolic geometry [35], percolation [25], fractals [40], inﬁnite series
and the Riemann zeta function [47], the ﬁrst Hilbert problem [39], Turing
machines [42], and supertasks [37], numerical solution of ordinary differen-
tial equations [2, 43], etc.
In the rest of the chapter, we review in Sect.2 the relevant details of
the grossone-based Quasi-Newton method for nonsmooth optimization pre-
sented in [21], and we report on the computational experience made on some
benchmark academic test-problems in Sect.3.
2
Grossone-Based Matrix Updates in a Diagonal
Bundle Algorithm
We consider the Diagonal Bundle method (D-Bundle) introduced in [26] as
a variable-metric method applied to the nonsmooth problem (1). D-Bundle
is based on the limited-memory bundle approach [22], where ideas coming
from the variable-metric bundle approach [32, 34] are combined with the
extension to nonsmooth problems of the limited-memory approach intro-
duced in [7]. The method adopts the diagonal update formula of the variable-

170
M. Gaudioso et al.
metric matrix presented in [23]. Recalling that D-Bundle can also deal
with nonconvexities, we however narrow our attention to the convex nons-
mooth case. This allows one to adopt an easier structure of D-Bundle, thus
sharpening the role of the inﬁnity computing paradigm.
Assuming that at each point x ∈Rn it is possible to calculate f (x) and
a subgradient g ∈∂f (x), and letting xk be the estimate of the minimum at
iteration k, the search direction dk adopted to locate the next iterate is deﬁned
as
dk = −Hkξk
a,
(7)
where ξk
a is the current aggregate subgradient, and Hk is the inverse of Bk, the
positive deﬁnite variable-metric n × n matrix, resembling the classic approx-
imation of the Hessian matrix adopted in the smooth case.
Once dk is available, a line search along dk is performed, which can return
two possible outcomes: serious-step, whenever a sufﬁcient reduction of the
objective function is achieved, and null-step otherwise. In the serious-step
case, a new approximation xk+1 of a minimizer is obtained, while in the
null-step case an auxiliary point yk+1 is obtained along with a subgradient,
to enrich the function model around xk. Further details regarding formula
(7) are about the deﬁnition of the aggregate subgradient. In the serious-step
case (i.e., the new iterate xk+1 has been located) the aggregate subgradient
ξk+1
a
is any subgradient of f at xk+1. In the null-step case, no move from
the current estimate of the minimizer is made (that is xk+1 = xk), hence the
aggregate subgradient ξk+1
a
is obtained as a convex combination of the three
vectors gk ∈∂f (xk), gk+1 ∈∂f (yk+1), and ξk
a, with multipliers λ∗
1, λ∗
2, and
λ∗
3, respectively, which minimize (see [34, Sect. 4]) the following function
φ(λ1, λ2, λ3) ≜1
2

λ1gk + λ2gk+1 + λ3ξk
a
⊤
Hk 
λ1gk + λ2gk+1 + λ3ξk
a

+
+λ2αk+1 + λ3αk
a,
(8)
where αk+1 is the standard (nonnegative) linearization error
αk+1 ≜f (xk) −f (yk+1) −(gk+1)⊤(xk −yk+1),
and αk
a is the aggregated linearization error. The following recursive equality
αk+1
a
= λ∗
2αk+1 + λ∗
3αk
a,
is adopted to update the aggregated linearization error which is initialized to
zero every time a serious step takes place.
Focusing on the updating technique of matrix Bk, as in [26], matrix Bk
must be kept diagonal and positive deﬁnite. We consider an easier version

The Grossone-Based Diagonal Bundle Method
171
of the technique described in [26]. At iteration k one can only store the
information about the previous iterate, and calculate two correction vectors
sk and uk, according to the deﬁnitions (3) and (6), respectively. Hence, matrix
Bk is obtained by solving the following optimization problem
min
∥Bsk −uk∥
(9)
s.t.
Bii ≥ϵ,
∀i ∈{1, . . . , n},
(10)
Bi j = 0,
∀i ̸= j ∈{1, . . . , n},
(11)
for some ϵ > 0, whose optimal solution can be expressed as
Bk
ii = max

ϵ, uk
i
sk
i

, i = 1, . . . , n.
(12)
Ill-conditioningofproblem(9)–(11)islikelyinducedbynonsmoothnessof
f , as the matrix Bk may contain arbitrarily large elements and, consequently,
Hk may contain arbitrarily small elements, since
Hk
ii = (Bk
ii)−1, i = 1, . . . , n.
(13)
Hence, adopting the inﬁnity computing paradigm in order to control ill-
conditioning [1], the correction vectors sk and uk are ﬁrst replaced with
vectors δk and γ k, respectively, whose components are deﬁned as follows
δk
i =

sk
i ,
if |sk
i | > ϵ,
①−1, otherwise,
(14)
and
γ k
i =

uk
i ,
if |uk
i | > ϵ,
①−1, otherwise.
(15)
Then, the ratio γ k
i
δk
i
is possibly corrected by introducing the following update
rule
bk
i =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
①−1, if 0 < γ k
i
δk
i
≤ϵ
γ k
i
δk
i
,
otherwise.
(16)
Finally, similar to the solution of problem (9)–(11), the elements of the diag-
onal matrix Bk are set according to the rule
Bk
ii = max

①−1, bk
i

, i = 1, . . . , n.
(17)

172
M. Gaudioso et al.
Note that matrix Bk may contain inﬁnite and inﬁnitesimal numbers. How-
ever, in order to calculate dk in a classical arithmetic framework, as in formula
(7), we need to get rid of the dependence on ①and ①−1 in the deﬁnition of
matrix Hk. Thus, we adopt the following scheme which, as far as ﬁnite num-
bers are involved, reﬂects the standard inverse calculation scheme:
Hk
ii =
⎧
⎪⎨
⎪⎩
(Bk
ii)−1
if Bk
ii neither depends on ①nor on ①−1,
(Bk
ii)−1 · ①
if Bk
ii is of the type α①, α ∈R
(Bk
ii)−1 · ①−1
if Bk
ii is of the type α①−1, α ∈R
(18)
Next we report in Algorithm 1 the formal statement of the Grossone
DBundle| method. The input parameters are: the sufﬁcient decrease param-
eter m ∈(0, 1), the matrix updating threshold ϵ > 0, the stepsize reduction
parameter σ ∈(0, 1), the stopping parameter η > 0, and the null step param-
eter θ > 0. We observe that at Step 4, a search direction dk at the current
point xk is selected according to (7). Next, at Step 5, the desirable reduction
wk of the objective function is calculated, and the algorithm stops at Step 6
if wk is very close to zero.

The Grossone-Based Diagonal Bundle Method
173
Fig. 1 Test problems (x0 is the starting point, x∗is the minimizer)
Otherwise, a line-search along dk is executed at Step 9, whose termination
depends on the sufﬁcient decrease condition at Step 10. In case the sufﬁ-
cient decrease condition is fulﬁlled, a serious step takes place along with the
grossone-based update of matrix Hk. If there is no sufﬁcient decrease at Step
10, then the line-search is iterated at Step 21, unless the step size has become
very small. In the latter case a null step occurs, where the aggregate gradient
ξk
a and the linearization error αk
a are updated, but not the matrix Hk. For
further details, especially regarding convergence properties, the deﬁnition of
wk, and the calculation of ξk
a and αk
a in the null-step case, we refer the reader
to [26].

174
M. Gaudioso et al.
Table 1 Results on Chained LQ with size n = 50 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
−66.7329331
3.65E-02
8
5
100
−67.1750430
3.02E-02
11
8
200
−68.1049532
1.69E-02
16
13
300
−68.4659193
1.18E-02
21
18
400
−68.4721827
1.17E-02
22
19
500
−68.4809312
1.16E-02
24
21
Table 2 Results on Chained LQ with size n = 100 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
−135.7207701
3.04E-02
8
6
100
−135.9990819
2.84E-02
10
8
200
−136.1352791
2.75E-02
12
10
300
−136.8200990
2.26E-02
15
13
400
−138.7923614
8.62E-03
20
18
500
−139.3581970
4.60E-03
24
22
3
Computational Experience
We have adopted three different classes of large-scale test problems (see
Fig.1) taken from [6] to evaluate the computational behavior of D-Bundle.
Wehaveselecteddifferentvaluesofthespacedimensionn ∈{50, 100, 200},
and we report the results obtained by stopping the algorithm after N f func-
tion evaluations, with N f ∈{50, 100, 200, 300, 400, 500}. In particular, we
provide the objective function value f ∗, the relative error er = | f ∗−f (x∗)|
1+| f (x∗)| ,
the number of serious steps NS, and the number of Hk updates that involved
the use of grossone N①. We report the results obtained adopting ϵ = 10−2,
see Tables1, 2, 3, 4, 5, 6, 7, 8 and 9, and ϵ = 10−10, see Tables10, 11, 12,
13, 14, 15, 16, 17 and 18. The remaining parameters of the algorithms have
been set as follows: σ = 0.7, m = 0.1, η = 10−10 and θ = 10−4.
The results show that large values of the threshold ϵ for switching to the
use of grossone, imply an increased number of grossone-based steps, with
corresponding lack of accuracy. It can be seen that the ratio of grossone-
based steps over the total number of serious steps is smaller as ϵ decreases.
Hence,theuseofgrossonemayallowreasonabletreatmentofill-conditioning
provided that the threshold ϵ is sufﬁciently small.

The Grossone-Based Diagonal Bundle Method
175
Table 3 Results on Chained LQ with size n = 200 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
−276.9103190
1.60E-02
8
6
100
−277.4285342
1.42E-02
10
8
200
−277.4421523
1.41E-02
12
10
300
−277.5469159
1.37E-02
14
12
400
−277.5469159
1.37E-02
14
12
500
−277.5469159
1.37E-02
14
12
Table 4 Results on Chained CB3 I with size n = 50 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
142.0278332
4.45E-01
7
5
100
118.9363346
2.11E-01
10
8
200
113.6568233
1.58E-01
16
14
300
104.2485194
6.31E-02
20
18
400
102.7413588
4.79E-02
25
23
500
99.2882901
1.30E-02
30
28
The Grossone-D-Bundle approach has been also numerically com-
pared against its standard counterpart, namely, Algorithm 1 where at Step
14 formula (13) for calculating Hk replaces formula (18). The comparison is
made for different values of ϵ in (12) and by stopping the algorithm after a
given number N f of function evaluations. We report in Table19 the results
obtainedforproblemswithsizen = 100,andsettingϵ ∈{10−2, 10−5, 10−10}
and N f ∈{50, 100, 200}. In particular, we provide the relative errors ealg
r
=
| f ∗−f (x∗)|
1+| f (x∗)| , where alg = D and alg = G refer, respectively, to Bk = B①and
Bk = Bϵ. The results show that the Grossone-D-Bundle approach tends
to overperform the standard approach, especially as ϵ decreases.

176
M. Gaudioso et al.
Table 5 Results on Chained CB3 I with size n = 100 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
276.0654964
3.92E-01
8
5
100
223.3313657
1.27E-01
11
8
200
218.4138518
1.03E-01
16
13
300
218.0286772
1.01E-01
20
17
400
200.6511044
1.33E-02
27
24
500
199.0866922
5.46E-03
31
28
Table 6 Results on Chained CB3 I with size n = 200 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
513.8191333
2.90E-01
7
5
100
411.7056803
3.44E-02
11
9
200
403.6445105
1.41E-02
16
14
300
400.5369972
6.36E-03
20
18
400
398.4287379
1.07E-03
24
22
500
398.1830522
4.59E-04
27
25
Table 7 Results on Chained CB3 II with size n = 50 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
125.5297664
2.78E-01
7
4
100
109.5757036
1.17E-01
10
7
200
105.7547185
7.83E-02
13
10
300
101.5635593
3.60E-02
17
14
400
100.9229376
2.95E-02
22
19
500
100.6930428
2.72E-02
24
21
Table 8 Results on Chained CB3 II with size n = 100 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
227.4325378
1.48E-01
7
4
100
203.0976658
2.56E-02
11
8
200
202.4957777
2.26E-02
12
9
300
202.4957777
2.26E-02
12
9
400
202.4957777
2.26E-02
12
9
500
202.4957777
2.26E-02
12
9

The Grossone-Based Diagonal Bundle Method
177
Table 9 Results on Chained CB3 II with size n = 200 and ϵ = 10−2
N f
f ∗
er
NS
N①
50
458.0950749
1.51E-01
8
5
100
428.6046364
7.67E-02
10
7
200
424.6396931
6.68E-02
12
9
300
424.6396931
6.68E-02
12
9
400
423.8254683
6.47E-02
14
11
500
409.6297910
2.91E-02
19
16
Table 10 Results on Chained LQ with size n = 50 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
−69.0981172
2.82E-03
10
4
100
−69.1800716
1.66E-03
13
7
200
−69.1801058
1.66E-03
14
8
300
−69.1801058
1.66E-03
14
8
400
−69.1801058
1.66E-03
14
8
500
−69.1801058
1.66E-03
14
8
Table 11 Results on Chained LQ with size n = 100 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
−139.4816288
3.73E-03
9
4
100
−139.7674121
1.70E-03
12
6
200
−139.7711371
1.67E-03
13
7
300
−139.7711371
1.67E-03
13
7
400
−139.7711371
1.67E-03
13
7
500
−139.7711371
1.67E-03
13
7
Table 12 Results on Chained LQ with size n = 200 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
−280.4361446
3.51E-03
9
4
100
−280.8968967
1.88E-03
11
5
200
−280.8968967
1.88E-03
11
5
300
−280.8968967
1.88E-03
11
5
400
−280.8968967
1.88E-03
11
5
500
−280.8968967
1.88E-03
11
5

178
M. Gaudioso et al.
Table 13 Results on Chained CB3 I with size n = 50 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
100.6694475
2.70E-02
8
1
100
98.2901649
2.93E-03
13
3
200
98.2261786
2.28E-03
17
4
300
98.2022949
2.04E-03
18
5
400
98.2022949
2.04E-03
18
5
500
98.2022949
2.04E-03
18
5
Table 14 Results on Chained CB3 I with size n = 100 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
199.9535378
9.82E-03
9
3
100
199.9446641
9.77E-03
9
3
200
199.2083426
6.07E-03
14
8
300
198.5907641
2.97E-03
19
11
400
198.5907641
2.97E-03
19
11
500
198.5907641
2.97E-03
19
11
Table 15 Results on Chained CB3 I with size n = 200 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
400.6092141
6.54E-03
8
1
100
398.8440820
2.12E-03
10
3
200
398.4688649
1.18E-03
13
5
300
398.4288154
1.07E-03
17
8
400
398.2626085
6.58E-04
20
11
500
398.2282233
5.72E-04
23
14
Table 16 Results on Chained CB3 II with size n = 50 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
111.4655678
1.36E-01
9
5
100
106.0858985
8.17E-02
11
7
200
106.0858985
8.17E-02
11
7
300
106.0858985
8.17E-02
11
7
400
106.0858985
8.17E-02
11
7
500
106.0858985
8.17E-02
11
7

The Grossone-Based Diagonal Bundle Method
179
Table 17 Results on Chained CB3 II with size n = 100 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
210.9095945
6.49E-02
9
5
100
201.9139633
1.97E-02
14
10
200
201.3641400
1.69E-02
18
14
300
201.3641400
1.69E-02
18
14
400
201.3641400
1.69E-02
18
14
500
201.3641400
1.69E-02
18
14
Table 18 Results on Chained CB3 II with size n = 200 and ϵ = 10−10
N f
f ∗
er
NS
N①
50
440.0572743
1.05E-01
9
5
100
404.7495782
1.69E-02
12
8
200
404.7495782
1.69E-02
12
8
300
404.7495782
1.69E-02
12
8
400
404.7495782
1.69E-02
12
8
500
404.7495782
1.69E-02
12
8
Table 19 Comparisons between Chained LQ, Chained CB3 I, and Chained CB3 II, with
size n = 100
N f
ϵ = 10−2
ϵ = 10−5
ϵ = 10−10
eG
r
eD
r
eG
r
eD
r
eG
r
eD
r
Chained LQ
50
3.04E-02 4.75E-01 7.64E-03 7.54E-01 3.73E-03 7.54E-01
100
2.84E-02 2.13E-01 7.64E-03 7.49E-01 1.70E-03 7.54E-01
200
2.75E-02 5.73E-02 7.64E-03 6.88E-01 1.67E-03 7.54E-01
Chained CB3-
I
50
3.92E-01 7.43E-02 7.86E-03 1.05E-02 9.82E-03 1.05E-02
100
1.27E-01 7.43E-02 5.76E-03 1.05E-02 9.77E-03 1.05E-02
200
1.03E-01 1.36E-02 5.51E-04 1.05E-02 6.07E-03 1.05E-02
Chained CB3-
II
50
1.48E-01 1.16E+00 6.47E-02 3.31E+00 6.49E-02 3.31E+00
100
2.56E-02 5.47E-01 5.97E-02 1.42E+00 1.97E-02 2.98E+00
200
2.26E-02 3.49E-01 5.97E-02 2.30E-01 1.69E-02 2.98E+00

180
M. Gaudioso et al.
References
1. Amodio, P., Brugnano, L., Iavernaro, F., Mazzia, F.: A dynamic precision ﬂoating-
point arithmetic based on the inﬁnity computer framework. In: Y.D. Sergeyev, D.E.
Kvasov (eds.) Numerical Computations: Theory and Algorithms. NUMTA 2019,
Lecture Notes in Computer Science, vol. 11974. Springer, Cham (2020)
2. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
3. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft Comput.
24, 17751–17759 (2020)
4. Astorino, A., Gaudioso, M., Gorgone, E.: A method for convex minimization based
on translated ﬁrst-order approximations. Numer. Algor. 76(3), 745–760 (2017)
5. Bagirov, A.M., Karasözen, B., Sezer, M.: Discrete gradient method: derivative-free
method for nonsmooth optimization. J. Optim. Theory Appl. 137(2), 317–334 (2008)
6. Bagirov, A.M., Karmitsa, N., Mäkelä, M.M.: Introduction to Nonsmooth Optimiza-
tion: Theory, Practice and Software. Springer, Berlin (2014)
7. Byrd, R.H., Nocedal, J., Schnabel, R.B.: Representations of quasi-Newton matrices
and their use in limited memory methods. Math. Program. 63(1–3), 129–156 (1994)
8. Cheney, E.W., Goldstein, A.A.: Newton’s method for convex programming and
tchebycheff approximation. Numer. Math. 1(1), 253–268 (1959)
9. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput.
218(16), 8077–8082 (2012)
10. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
11. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft. Comput. 24, 17669–17677 (2020)
12. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based com-
putationofnegativecurvaturedirectionsinlarge-scaleoptimization.J.Optim.Theory
Appl. 186, 554–589 (2020)
13. Demyanov, A.V., Fuduli, A., Miglionico, G.: A bundle modiﬁcation strategy for
convex minimization. Eur. J. Oper. Res. 180(1), 38–47 (2007)
14. Demyanov, V.F., Malozemov, V.N.: Introduction to Minimax. Wiley, New York
(1974)
15. Dennis, J.E., Moré, J.J.: Quasi-Newton methods, motivation and theory. SIAM Rev.
19(1), 46–89 (1977)
16. Fiaschi, L., Cococcioni, M.: The big-M method with the numerical inﬁnite M. Optim.
Lett. 15, 2455–2468 (2021)
17. Frangioni, A., Gorgone, E., Gendron, B.: On the computational efﬁciency of subgra-
dient methods: a case study in combinatorial optimization. Math. Progr. Comput. 9,
573–604 (2017)
18. Fuduli, A., Gaudioso, M.: Tuning strategy for the proximity parameter in convex
minimization. J. Optim. Theory Appl. 130(1), 95–112 (2006)
19. Fuduli, A., Gaudioso, M., Giallombardo, G., Miglionico, G.: A partially inexact
bundle method for convex semi-inﬁnite minmax problems. Commun. Nonlinear Sci.
Numer. Simul. 21(1–3), 172–180 (2015)
20. Gaudioso, M., Giallombardo, G., Miglionico, G.: Essentials of numerical nonsmooth
optimization. 4OR 18(1), 1–47 (2020)

The Grossone-Based Diagonal Bundle Method
181
21. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.: Numerical inﬁnitesimals in
a variable metric method for convex nonsmooth optimization. Appl. Math. Comput.
318, 312–320 (2018)
22. Haarala, N., Miettinen, K., Mäkelä, M.M.: Globally convergent limited memory
bundle method for large-scale nonsmooth optimization. Math. Program. 109(1), 181–
205 (2007)
23. Herskovits, J., Goulart, R.: Sparse quasi-Newton matrices for large scale nonlinear
optimization. In: Proceedings of the 6th Word Congress on Structural and Multidis-
ciplinary Optimization (2005)
24. Hiriart-Urruty, J.B., Lemaréchal, C.: Convex Analysis and Minimization Algorithms
I-II. Springer, Berlin (1993)
25. Iudin, D.I., Sergeyev, Y.D., Hayakawa, M.: Inﬁnity computations in cellular automa-
ton forest-ﬁre model. Commun. Nonlinear Sci. Numer. Simul. 20(3), 861–870 (2015)
26. Karmitsa, N.: Diagonal bundle method for nonsmooth sparse optimization. J. Optim.
Theory Appl. 166(3), 889–905 (2015)
27. Kelley, J.E.: The cutting plane method for solving convex programs. J. SIAM 8(4),
703–712 (1960)
28. Kiwiel, K.C.: Methods of Descent for Nondifferentiable Optimization. Lecture Notes
in Mathematics. Springer, Berlin (1985)
29. Kiwiel, K.C.: Proximity control in bundle methods for convex nondifferentiable
minimization. Math. Program. 46(1–3), 105–122 (1990)
30. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed Pareto-lexicographic multi-
objective optimization problems: The case of priority chains. Swarm Evol. Comput.
55, 100687 (2020)
31. Lemaréchal, C.: An algorithm for minimizing convex functions. In: Rosenfeld, J.
(ed.) Proceedings IFIP ’74 Congress 17, pp. 552–556. North-Holland, Amsterdam
(1974)
32. Lemaréchal, C., Sagastizábal, C.: Variable metric bundle methods: from conceptual
to implementable forms. Math. Prog. Ser. B 76(3), 393–410 (1997)
33. Lukšan, L., Vlˇcek, J.: A bundle-Newton method for nonsmooth unconstrained min-
imization. Math. Prog. Ser. B 83(3), 373–391 (1998)
34. Lukšan, L., Vlˇcek, J.: Globally convergent variable metric method for convex nons-
mooth unconstrained minimization. J. Optim. Theory Appl. 102(3), 593–613 (1999)
35. Margenstern, M.: Fibonacci words, hyperbolic tilings and grossone. Commun. Non-
linear Sci. Numer. Simul. 21(1–3), 3–11 (2015)
36. Nesterov, Y.: Smooth minimization of non-smooth functions. Math. Program.103(1),
127–152 (2005)
37. Rizza, D.: Supertasks and numeral systems. In: Y.D. Sergeyev, D.E. Kvasov,
F. Dell’Accio, M.S. Mukhametzhanov (eds.) Proceedings of the 2nd International
Conference on “Numerical Computations: Theory and Algorithms”, vol. 1776, pp.
090005. AIP Publishing, New York (2016)
38. Sergeyev, Y.D.: Numerical point of view on calculus for functions assuming ﬁnite,
inﬁnite, and inﬁnitesimal values over ﬁnite, inﬁnite, and inﬁnitesimal domains. Non-
linear Anal. Theory Methods Appl. 71(12), 1688–1707 (2009)
39. Sergeyev, Y.D.: Counting systems and the ﬁrst Hilbert problem. Nonlinear Anal.
Theory Methods Appl. 72(3–4), 1701–1708 (2010)
40. Sergeyev, Y.D.: Using blinking fractals for mathematical modelling of processes of
growth in biological systems. Informatica 22(4), 559–576 (2011)

182
M. Gaudioso et al.
41. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
42. Sergeyev, Y.D., Garro, A.: The grossone methodology perspective on Turing
machines. In: Adamatzky, A. (ed.) Automata, Universality, Computation, Emer-
gence, Complexity and Computation, vol. 12, pp. 139–169. Springer, New York
(2015)
43. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.:
Numerical methods for solving initial value problems on the Inﬁnity Computer.
Int. J. Unconv. Comput. 12(1), 3–23 (2016)
44. Sergeyev, Y.D., Nasso, M.C., Mukhametzhanov, M.S., Kvasov, D.E.: Novel local
tuning techniques for speeding up one-dimensional algorithms in expensive global
optimization using Lipschitz derivatives. J. Comput. Appl. Math. 383, 113134 (2021)
45. Shor, N.Z.: Minimization Methods for Non-Differentiable Functions. Springer,
Berlin (1985)
46. Wolfe, P.: Method of conjugate subgradients for minimizing nondifferentiable func-
tions. In: Balinski, M., Wolfe, P. (eds.) Mathematical Programming Studies, vol. 4,
pp. 145–173. North-Holland, Amsterdam (1975)
47. Zhigljavsky, A.: Computing sums of conditionally convergent and divergent series
using the concept of grossone. Appl. Math. Comput. 218(16), 8064–8076 (2012)
48. Žilinskas, A.: On strong homogeneity of two global optimization algorithms based on
statistical models of multimodal objective functions. Appl. Math. Comput. 218(16),
8131–8136 (2012)

On the Use of Grossone Methodology for
Handling Priorities in Multi-objective
Evolutionary Optimization
Leonardo Lai, Lorenzo Fiaschi, Marco Cococcioni, and Kalyanmoy Deb
Abstract This chapter introduces a new class of optimization problems, called
Mixed Pareto-Lexicographic Multi-objective Optimization Problems (MPL-MOPs),
to provide a suitable model for scenarios where some objectives have priority over
some others. Speciﬁcally, this work focuses on two relevant subclasses of MPL-
MOPs, namely optimization problems having the objective functions organized as
priority chains or priority levels. A priority chain (PC) is a sequence of objectives
ordered lexicographically by importance; conversely, a priority level (PL) is a group
ofobjectiveshavingthesameimportanceintermsofoptimization,butalexicographic
ordering exists between the PLs. After describing these problems and discussing why
the standard algorithms are inadequate, an innovative approach to deal with them
is introduced: it leverages the Grossone Methodology, a recent theory that allows
handling priorities by means of inﬁnite and inﬁnitesimal numbers. Most interest-
ingly, this technique can be easily embedded in most of the existing evolutionary
algorithms, without altering their core logic. Three algorithms for MPL-MOPs are
shown: the ﬁrst two, called PC-NSGA-II and PC-MOEA/D, are the generalization of
NSGA-II and MOEA/D, respectively, in the presence of PCs; the third, named PL-
NSGA-II, generalizes instead NSGA-II when PLs are present. Several benchmark
problems, including some from the real world, are used to evaluate the effectiveness
of the proposed approach. The generalized algorithms are compared to other famous
evolutionary ones, either priority-based or not, through a statistical analysis of their
L. Lai · L. Fiaschi (B) · M. Cococcioni
Department of Information Engineering, University of Pisa, Largo Lucio Lazzarino 1, Pisa, Italy
e-mail: lorenzo.ﬁaschi@phd.unipi.it
M. Cococcioni
e-mail: marco.cococcioni@unipi.it
K. Deb
Department of Electrical and Computer Engineering, Michigan State University, 428 S. Shaw
Lane, East Lansing, MI, USA
e-mail: kdeb@egr.msu.edu
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_8
183

184
L. Lai et al.
performances. The experiments show that the generalized algorithms are consistently
able to produce more solutions and of higher quality.
1
Introduction
Evolutionary algorithms [12] are known as one of the most effective strategies to
solve real problems requiring the simultaneous optimization of two or more func-
tions, thanks to their ability to produce a group of diverse trade-off solutions rather
than focusing on a single one. However, researchers have identiﬁed critical issues
that arise when the number of objectives grows, often over three or four [35, 42].
The most troublesome issues when dealing with these so-called many-objective opti-
mization problems include: (i) ineffectiveness of the standard Pareto dominance; (ii)
need for a signiﬁcantly larger population, due to the possibly increased dimension-
ality of the efﬁcient set; (iii) computational inefﬁciency of the diversity estimation
functions; and (iv) ineffectiveness of the canonical recombination operators. Many
proposals attempt to address and mitigate these problems: decomposition [53], Pareto
dominance alternatives [30], custom recombination operators [14], new diversity
management mechanisms [1] or even many-objective speciﬁc frameworks [13, 31,
52].
While the growth in dimension raises computational challenges, the multi- or
many-objective optimization problems originate from practical situations, so it’s
often the case that not all the objectives are of equal importance to decision makers. In
other words, some objectives may be likely organized on the basis of their preference,
e.g. as series of objectives ordered by priority or as multiple groups of objectives
ranked by importance. One important requirement of such real world scenarios is that
no objective shall be completely discarded already at the formulation stage because
of its preference level. As an example, a recent problem from an automobile industry
featuring six objectives clearly states—the weight objective was most important to
minimize, but designers were also interested in solutions having a trade-off in other
ﬁve objectives [21]. In situations like this, instead of treating all the given objectives
as equally important, which is the case of the most common evolutionary multi-
objective optimization (EMO) algorithms, the priority information should be taken
into account during the optimization phase. This allows to guide the optimization
search better, and make it more computationally efﬁcient. Also, by focusing on
the trade-off between similar priority objectives, one can obtain more ﬁne-grained
insights about the important objectives.
The domain of interest are therefore Mixed Pareto-Lexicographic Multi-objective
Optimization Problems (abbreviated as MPL-MOPs), a broad class of problems that
assume a structured precedence relationship among some objectives. Different pri-
ority structures map to different subclasses of MPL-MOPs. In this chapter, the focus
is on two of them: PC-MPL-MOPs, where the objectives are organized in chains
of priority [27], and PL-MPL-MOPs, where the objectives are grouped in levels of
priority [28, 29]. Their models are discussed extensively in Sects.5–7 and 8–11,

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
185
respectively. Sections2 and 4 introduce them brieﬂy: the former is a brief recap of
EMO, while the second delves further into the nature of MPL-MOPs. Conclusions
are drawn in Sect.12.
2
Multi-objective Optimization and Evolutionary
Algorithms
Multi-objective optimization problems (MOPs) are typically stated as:
min
⎡
⎢⎢⎢⎣
f1(x)
f2(x)
...
fm(x)
⎤
⎥⎥⎥⎦s.t. x ∈
where  represents an arbitrary input space. Finding the Pareto optimal solutions
in MOPs is non-trivial, and many different methods exist, from mathematical-
programming ones to EMO algorithms. Being population-based, the latter are able
to deal with a large number of solutions at the same time, whereas other approaches
requirethesameproceduretoberepeatedoverandover(oftenonlychangingthestart-
ing point). Also, evolutionary algorithms proved to be effective to solve hard prob-
lems too, for instance those with many decision variables or local optima. Because
of this, EMO has acquired popularity: noteworthy examples are NSGA-II, SPEA2
and MOEA/D [15, 53, 55].
Recently, the research focus has shifted towards problems with a large number
of objectives, known as many-objective optimization problems (MaOPs) [32]. This
deﬁnition usually applies to any problem with more than three objectives, but it is
common to have ten or more. It has been observed that traditional EMO algorithms
designed for MOPs are often inadequate when facing MaOPs, for a variety of rea-
sons. First, when the number of objectives grows, a larger fraction of the population
becomes nondominated, slowing down the optimization process signiﬁcantly. This is
a very serious issue, which has to do with the ineffectiveness of the Pareto dominance
deﬁnition; alternatives have been proposed, for instance in [19]. Second, the conﬂict
between convergence and diversity assessment exacerbates in a large-dimensional
space, making it harder to ﬁnd a balance between these two pressures. Furthermore,
the recombination operation may be inefﬁcient, calculations and simulations become
computationally expensive, results are harder to understand and visualize.
All these challenges have led to the development of sophisticated methods speciﬁc
for MaOPs, including evolutionary algorithms that are often variations of their MOP
counterpart. A remarkable example is NSGA-III [13], which enhances the funda-
mental ideas of NSGA-II to deal better with many-objective problems. Although the
above issues can be mitigated by the new approaches, they can hardly be eliminated
at all.

186
L. Lai et al.
3
Metrics to Assess the Efﬁcacy of EMO Algorithms
Several performance indicators have been proposed by researchers to evaluate the
quality of a non-dominated solution set [23, 37]. One of the most popular is the
hypervolume indicator [56], which is Pareto compliant, i.e., the better the Pareto front
approximation, the better the performance indicator value. It has been shown that
a Pareto non-compliant indicator may result in misleading performance results [37,
48]. However, the hypervolume indicator becomes often computationally unfeasible
as the objective space dimension scales up.
Two other well known metrics are the generational distance (GD) and the inverted
generational distance (IGD), described in [50] and [7] respectively. Both assess the
quality of a non-dominated objective vector set A = {a1, . . . , an} with respect to a
reference Pareto set Z = {z1, . . . , zm}. The analytical deﬁnition of GD is:
GD(A) = 1
n
 n
	
i=1
d(ai, Z)p

 1
p
where d is the Euclidean distance from ai to its nearest reference point in Z, and
p ∈N. The IGD metrics is the inverted variation, deﬁned as:
IGD(A) = 1
m
 m
	
i=1
d(zi, A)p

 1
p
where d now represents the Euclidean distance from zi to its nearest objective vector
in A. This work uses the stabler indicator (A) = max{GD(A), IGD(A)}, ﬁrst
proposed in [48]. In analogy with [26], p is set to 1, and this choice is bivariate:
(i) it makes the meaning of GD and IGD interpretable (the average of Euclidean
distances); (ii) it has often been used in the literature. As any other metric for EMO
algorithms evaluation [33], (·) is not impeccable, but covers at least convergence
and diversity of obtained solutions. In future works concerning PL-MPL-MOPs, we
plan to include more metrics among those reviewed in [33].
To make a fair and reliable comparison of the algorithms and their performance,
various non-parametric statistical tests have been carried out, speciﬁcally: (i) the
Friedman’s test (ii) the Iman-Davenport’s test (iii) the Holm’s test. Even though the
resulting values are not reported here due to lack of space (they can be found in [27,
28]), it is sufﬁcient to say that the statistical separation and hypotheses have been
thoroughly tested and validated.
4
Mixed Pareto-Lexicographic Optimization
MPL-MOPs refers to a broad class of problems sharing these features:

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
187
• Multiple objectives are involved (multi-objective)
• Some objectives have precedence over some others (lexicographic)
• Some objectives cannot be compared to each other by priority (Pareto)
The mathematical formulation of a MPL-MOP is:
min f1(x), f2(x), . . . , fm(x),
s.t. x ∈
℘( f1, f2, . . . , fm)
where m is the number of objective functions,  is the feasible variables space,
also called decision space or search space, and ℘(·) is a generic priority structure
over the objectives. In the absence of ℘(·), the optimization is implicitly assumed to
be of Paretian type, and solved with the usual EMO algorithms. At the opposite of
Pareto optimization, another well-known corner case of MPL-MOPs is represented
by lexicographic problems [36, 39], where ℘(·) arranges the objectives according
to a total order of importance. Lexicographic problems can be denoted as:
lex min f1(x), f2(x), . . . , fm(x)
s.t. x ∈
(1)
The expression indicates the minimization of the objectives f1, f2, . . . , fm ranked
lexicographically: f1 holds absolutely priority over f2, which in turn has absolute
priority over f3, and so on.
The more general case where ℘(·) is an arbitrary function (i.e., a generic MPL-
MOP) has not received enough research attention, despite the applicability to poten-
tially many real-world scenarios, like [21]. Some studies proposed ad-hoc approaches
to deal with generic priority relations, including linear scalarization [12] or ϵ-
constrained methods [12]. Other scalarization strategies can be found in [22, 38].
Despite being more effective than general purpose ones, these algorithms are not pur-
posely designed to cope with MPL-MOPs, so they have signiﬁcant shortcomings. For
instance, in scalarized problems the weights must be chosen carefully, otherwise the
solutions may be wrong or very inaccurate [12], sometimes, the numerical stability
of the algorithm may get worse too. Moreover, scalarized approaches typically ﬁnd
only one solution at a time, with dramatic consequences on the overall computation
time. Even the simplest priority structure in (1) hides non-trivial complexities. A
common approach, called preemptive method, is to solve the single-objective sub-
problems sequentially: ﬁrst the optimal values for the most important objective are
found, then a constraint is added to force the solutions of the next subproblems to
be in the optimal set of the primary objective. The same procedure is iterated over
the objectives, in order of importance. However it suffers from the growing size of
the set of constraints, which makes it increasingly harder to locate feasible solutions.
Also the constraints may have an arbitrary from, hard to handle.
The word mixed in MPL-MOPs reﬂects the non-homogeneous nature of these
problems, suggesting at the same time an hybrid approach to deal with them. How-

188
L. Lai et al.
Fig. 1 Examples of two different classes of MPL-MOPs: dots represent objectives, arrows prece-
dences, and ovals groups of objectives
ever, the relationship between Pareto optimality and priorities strongly depends on
the structure of the speciﬁc problem, which in turn affects the mathematical descrip-
tion of the problem itself. Algorithms tailored around this model can potentially
converge faster and ﬁnd better solutions. The next sections introduce two of the sig-
niﬁcant families of MPL-MOPs. The ﬁrst one is characterized by chain-like priority
structures [27], where the objectives are indeed partitioned and a lexicographic order-
ing (a chain) exists within each partition. No preference ordering is deﬁned between
the chains; therefore, their simultaneous optimization is Paretian. The above prob-
lems are called Priority-Chain MPL-MOPs, or PC-MPL-MOPs in short. As opposed
to them, Priority-Levels MPL-MOPs (PL-MPL-MOPs in brief) feature a ℘(·) that
arranges the objectives into levels [28, 29]: no priorities exist within each level,
and their functions are optimized concurrently in the Paretian way. On the other
hand, a lexicographic priority scheme is deﬁned across the levels themselves, that
is the Pareto optimization of a level has priority over that of another level. Figure1
illustrates two examples of PC- and PL-MPL-MOPs.
5
The Priority Chains Model
The analytical model of a PC-MPL-MOP [27] is:
min
⎡
⎢⎢⎢⎢⎣
lex min f (1)
1 (x), f (2)
1 (x), . . . , f (p1)
1
(x)
lex min f (1)
2 (x), f (2)
2 (x), . . . , f (p2)
2
(x)
...
lex min f (1)
m (x), f (2)
m (x), . . . , f (pm)
m
(x)
⎤
⎥⎥⎥⎥⎦
s.t. x ∈.
(2)
where lex min f (1)
i
, f (2)
i
, . . . , f (pi)
i
indicates the minimization of the objectives
f (1)
i
, f (2)
i
, . . . , f (pi)
i
according to the lexicographic ordering: f (1)
i
is has priority

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
189
over f (2)
i
, which in turn has priority over f (3)
i
, and so on. Each lex min block can be
seen as a “container” of objectives ranked by importance: for clarity, it is referred to
as macro-objective and denoted as fi. On the other hand, the outer min indicates the
minimization (in the Pareto sense) of the macro-objectives. So (2) can be rewritten
as
min
⎡
⎢⎢⎢⎣
f1(x)
f2(x)
...
fm(x)
⎤
⎥⎥⎥⎦s.t. x ∈
where f1, f2, . . . , fm are the macro-objectives.
Moving from standard objectives to macro-objectives can be fairly intuitive. When
comparing the same macro-objective, say fi, of two different solutions, the one with
the lowest value of the primary objective, i.e., f (1)
i
is preferred. If the two values
happen to be equal, then the preference is determined by the secondary objective,
or the tertiary if they match again, and so on. In other words, secondary objectives
are useful to compare solutions with equal values on the relatively more important
objectives, consistently with the lexicographic ordering. Note the absence of any
mutual precedence between the objectives of different macro-objectives, they are
unrelated. This property implies that swapping e.g. two secondary objectives of a
PC-MPL-MOPs would modify the problem itself. This is not the case for PL-MPL-
MOPs.
Here is a minimal example on how to compare between macro-objectives. Con-
sider three solutions of a minimization problem with two macro-objectives, each
being a chain of two (shown horizontally):
A =
[1 2]
[5 3]

B =
[1 3]
[4 2]

C =
[7 1]
[4 9]

Solution A performs better than B in the ﬁrst macro-objective (because 1 = 1 and
2 < 3), however B is better in the second macro-objective (4 < 5, the secondary
objective does not matter this time), therefore A and B are Pareto nondominated. A
and C are nondominated too, since 1 < 7 and 5 > 4. On the other hand, B is better
than C because it dominates on both the macro-objectives: in fact, 1 < 7, 4 = 4 and
2 < 9.
5.1
Need of a New Approach for PC-MPL-MOPs
Before introducing a novel approach for PC-MPL-MOPs (Sect.6), it is important
to ﬁrst highlights the limits of the standard Paretian ones. An non-priority-aware
optimizer like NSGA-II can be essentially used in two ways for PC-MPL-MOPs:
ignoring the priorities or the secondary objectives. Unfortunately, both alternatives
have critical drawbacks.

190
L. Lai et al.
5.1.1
Ignoring Secondary Objectives
Ignoring all the objectives except the most important ones simpliﬁes the problem at
the cost of discarding important information, hence worsening the overall quality of
the found solutions. As discussed previously, the purpose of secondary objectives is
essentially to help discriminating between two or more solutions when the primaries
are not enough to establish a clear winner. Without secondaries, the algorithm is
bound to either preserve all the nondominated solutions, that is computationally
expensive, or discard one or more of them, randomly or according to some policy,
still with the risk of trashing potentially good ones thus slowing the optimization.
When the number of nondominated solutions is large, a common situation in many-
objectives tasks, these strategy fails with a notable performance degradation.
5.1.2
Ignoring the Priorities, Possibly Filtering a Posteriori
Another possibility is to treat all the objectives as if they had the same importance, no
matter what their real priorities are, and run a conventional optimization algorithm
on all these objectives. Then, after the end of the procedure, one may post-process
the ﬁnal population ﬁltering out the solutions that would be dominated by other indi-
viduals in the same set if the priorities were eventually taken into account. Although
slightly less naïve than the previous option, this one shows critical ﬂaws too. First, a
problem with m chains of p objectives each would become a purely Paretian problem
with m × p objectives, as a many-objective one, with all the negative consequences
that this entails. Also, a secondary objective that is instead given the same importance
of a primary one forces the algorithm to concurrently optimize both, or at least to
try to; if those are somehow conﬂicting, spurious nondominated solutions or even
clusters of them may emerge, in a way that is absolutely detrimental to the origi-
nal optimization task. Moreover, the ﬁltering procedure, despite being useful to pull
out the very best solutions from the ﬁnal set, may actually cause an overly severe
skimming, sometimes preserving very few individuals out of many. Computation-
ally speaking, ending up with two or three solutions after running the algorithm on
a population of thousands is dramatically inefﬁcient. The last two difﬁculties might
also stack together (i.e., ﬁltering an already mediocre set), exasperating the issue
even further.
5.2
Grossone for PC-MPL-MOPs
A very useful application of Grossone Methodology [44] is a ploy to reformulate lex-
icographic problems in a way that allows performing actual numerical computations
by means of macro-objectives, something that is not possible with standard model.
Grossone has been successfully applied in several other optimization problems, such
as in linear and non-linear programming [8, 9, 11], in global optimization [46], in

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
191
large-scale unconstrained optimization [10], in machine learning [2, 3, 20] and in
many other areas. In addition, the Grossone Methodology has been shown to be inde-
pendent from non-standard analysis [45]. The use made of Grossone here is rather
simple: given the lexicographic problem lex min f (1)(x), f (2)(x), . . . , f (p)(x), a G-
scalar is built using each objective f ( j) as a G-digit relative to the G-power ①1−j, an
idea ﬁrstly proposed in [43]. Thus that problem can be rewritten as
min f (1)(x) + ①−1 f (2)(x) + · · · + ①1−p f (p)(x)
or equivalently min f (x). The higher the priority, the higher the G-power: the most
important objective, f (1)(x), is indeed associated the highest exponent (0), whereas
f (p)(x) the lowest (1 −p). The advantage of this approach is clear: whereas before
we had objectives represented by real numbers, now we have macro-objectives rep-
resented by G-scalars. Since all the four basic operations are well-deﬁned for G-
numbers, replacing objectives with macro-objectives in an algorithm is a completely
transparent operation, which does not alter the inner logic of the code. Consequently,
manyexistingnon-lexicographicoptimizationalgorithmscanpotentiallybeextended
to solve certain types of lexicographic problems too. This same technique has been
recently adopted to generalize the simplex algorithm [5, 6]. So, PC-MPL-MOPs can
be easily reformulated with Grossone as
min
⎡
⎢⎢⎢⎢⎣
f (1)
1 (x) + ①−1 f (2)
1 (x) + · · · + ①1−p1 f (p1)
1
(x)
f (1)
2 (x) + ①−1 f (2)
2 (x) + · · · + ①1−p2 f (p2)
2
(x)
...
f (1)
m (x) + ①−1 f (2)
m (x) + · · · + ①1−pm f (pm)
m
(x)
⎤
⎥⎥⎥⎥⎦
.
6
PC-NSGA-II and PC-MOEA/D
This section aims at generalizing the original NSGA-II [15] and MOEA/D [53]
algorithms in order to allow them to solve PC-MPL problems. As said, this result
will be achieved by extending them to handle G-scalars, giving birth to PC-NSGA-II
and PC-MOEA/D, respectively. Of course these new versions must be equipped with
the redeﬁnition of the four elementary operations too, in order to operate with G-
scalars. Different algorithms could be chosen as well, e.g. SPEA2, but NSGA-II and
MOEA/D were eventually picked because they are popular, simple and parameter-
less, in the sense that they do not introduce other parameters than those typically
required by genetic algorithms. Notice that such extended versions inherit the very
same limits and beneﬁt of the underlying algorithms when facing MOPs or MaOPs.
As it will become clear in Sect.7.1, inheriting limits and beneﬁts means that if
an algorithm, for instance, works particularly well with binary genotypes, then its
PC version will manifest that property as well. On the contrary, if an algorithm

192
L. Lai et al.
becomes less effective as the number of objectives increases, its PC counterpart
will suffer MaOPs with many chains. In order to further stress the enhancement in
the supported data types, he algorithms core procedures have been renamed, e.g.,
PC_fast_nondominated_sort and PC_crowding_distance_assignment. Again, these
are aliases for the old names, as the logic behind the functions is still the same.
Consider its pseudocode in Algorithm 1:
• PC_fast_nondominated_sort: the nondominance operator ≺(underlined) replaces
the old ≺.
This is very similar to the traditional deﬁnition of dominance, but the comparisons
are now between macro-objectives (G-scalars) instead of single objectives (reals).
Its formal deﬁnition is:
Deﬁnition 1 (Pareto-Lexicographic dominance (PC-dominance)) Given two solu-
tions A and B, A dominates B (written A ≺B) if:
A ≺B ⇐⇒

fi(xA) ≤fi(xB)
∀i = 1 . . . m
∃j : f j(xA) < f j(xB)
(3)
The underlining notation has general validity: every time it appears, from now on,
it indicates G-scalar quantities or operations between them. This remains consistent
with the use made in Sect.7. Please, notice that the lexicographic contribution is
implicitly performed within the comparisons between two G-scalars.
• PC_crowded_comparison_operator: it works just like the old ≺n operator
described in [15], but the last comparison is now performed between G-scalars
because of the nature of PC_crowding_distance. It is denoted by ≺n.
• PC_crowding_distance: it is a G-scalar, since it is computed by means of opera-
tions (subtractions, divisions, etc.) between G-scalars. G-operations, by design,
preserve the relative importance between the objectives, and such property is
reﬂected in the crowding distance computation too. Being the ﬁnite component of
the macro-objectives, primary objectives play a major role in the density estima-
tion, while the secondaries, mostly contributing to the inﬁnitesimal part, are still
very useful in those situations where it is hard to choose, e.g. when sorting two ele-
ments that have the same ﬁnite crowding distance but different inﬁnitesimal values.
The deﬁnition also makes sense from the perspective of the decision-maker, as it
is reasonable to prefer having a larger variety of options in the domain of the most
relevant aspects, rather than for less important objectives. Notice that the crowding
distance of the extreme points can be initialized to ①, similarly to NSGA-II where
it is set to ∞. If we represent the priorities with non-positive G-powers only (a
non-restrictive assumption) ①is always guaranteed to be greater than any other
crowding distance value.

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
193
Algorithm 1: PC-NSGA-II algorithm
Similarly, MOEA/D can be extended by means of G-scalars to obtain PC-MOEA/D
(see Algorithm 2). For brevity reasons we do not go into the algorithm details, but
please note that the PC extension of MOEA/D is even easier than the NSGA-II one.

194
L. Lai et al.
Algorithm 2: PC-MOEA/D algorithm
Indeed, the function to compute the dominance relation is the only one which needs
to be extended to the G-scalar case. The new function works similarly to its old
version except for the dominance operator, which becomes the ≺described in (3)
instead of the standard ≺.
7
Test Cases for PC-MPL MOPs
Many test problems were proposed to assess the performance of multi-objective opti-
mization algorithms [16, 50, 54]. However, very few articles include problems where
priorities exist among the objectives, and none speciﬁcally for the MPL class. The
following sections contain some new PC-MPL benchmarks to verify the effective-
ness of the PC-generalizations of Sect.6. More problems are also discussed in [27].
Note that this study aims only at validating the conceptual superiority of priority-
structure-aware algorithms design versus their native counterparts or other priority-
based algorithms; instead, it is out of the scope of this chapter to analyze the raw
performance of the PC-algorithms, which ultimately depends on the backbone MOP
algorithm (NSGA-II or MOEA/D here). A detailed analysis concerning the identiﬁ-

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
195
cation and construction of interesting and challenging PC-MPL benchmarks is left
for future studies.
All the experiments use SBX crossover and polynomial mutation for real-encoded
genotypes, and two-point crossover and ﬂip-bit mutation with probability 1
l (bit-
string length l) for binary-encoded ones. The experiments are repeated 50 times for
each benchmark, with 500 epochs per run before halting the algorithm. The initial
population is made of 100 random individuals. In addition to PC-NSGA-II and PC-
MOEA/D, six more algorithms compete on each benchmark: NSGA-II and MOEA/D
ignoring the secondary objectives (Sect.5.1.1), NSGA-II and MOEA/D ignoring the
priorities and a posteriori ﬁltering (Sect.5.1.2), Tan et al. [49], Chang et al. [4].
7.1
Test Problem: PC-1
PC-1 is a PC-MPL 01-knapsack problem, featuring 6 objectives (2 chains of 3 objec-
tives):
max
 f 1(x)
f 2(x)

s.t.
W x ≤C
f j(x) = V jx
V j
= V (1)
j
+ ①−1V (2)
j
+ ①−2V (3)
j
V (1)
1
= [7, 1, 5, 2, 9, 4, 4, 2, 8, 2, 1, 6, 9, 5, 4, 4, 9, 5, 3, 3]T
V (2)
1
= [3, 1, 6, 6, 7, 2, 5, 2, 1, 9, 1, 8, 9, 6, 7, 4, 4, 5, 9, 4]T
V (3)
1
= [2, 1, 3, 5, 8, 9, 5, 7, 1, 6, 4, 7, 9, 5, 1, 5, 5, 4, 4, 2]T
V (1)
2
= [1, 7, 3, 6, 2, 3, 7, 7, 9, 9, 5, 3, 5, 3, 1, 8, 6, 1, 9, 3]T
V (2)
2
= [2, 6, 4, 7, 7, 4, 2, 4, 9, 4, 3, 3, 6, 8, 2, 8, 1, 6, 8, 8]T
V (3)
2
= [8, 9, 5, 9, 8, 9, 4, 9, 7, 5, 4, 5, 3, 4, 4, 7, 3, 8, 2, 4]T
W
= [4, 8, 6, 5, 5, 5, 7, 4, 8, 4, 4, 1, 8, 7, 4, 3, 5, 1, 9, 5]T
C
= 50,
xi ∈{0, 1} i = 1, . . . , 20
(4)
To give an idea of how important the secondaries are in the optimization process,
consider what happens when running PC-NSGA-II and NSGA-II (primary-only) on
this problem. PC-NSGA-II gives the result shown in Fig.2a, which includes 19 dis-
tinct solutions. The True Pareto front (computed through brute-force enumeration),
consists of 22 solutions (see [27]). A comparison between the two highlights that, out
of the 19 found solutions, 16 are true optima, 2 differ from their closest true optimum
for one secondary, 1 for a primary. As for the 6 missing true optima, another solution
with the same primary values was found for 2 of them, while for the other 4 the
primaries error is <= 3.

196
L. Lai et al.
(a) PC-NSGA-II: all the objectives
(b) NSGA-II: primaries only
Fig. 2 Primary objectives of PC-1, after 300 generations with 400 individuals. PC-NSGA-II solu-
tions that would be instead discarded by NSGA-II (i.e. missing on the right plot) are marked with
a cross
With NSGA-II, the secondary objectives are computed only at the end of the
optimization process, and unused during the evolution phase. Not only it ﬁnds fewer
solutions (Fig.2b), but also of lower quality. Out of 11, 8 are true optima, 2 are
sub-optimal with respect to primaries, 1 to secondaries. This shortage of solutions
from NSGA-II is the consequence of its inability to preserve “apparently horizon-
tal/vertical” solutions, which differ in their inﬁnitesimal components only.
The results are analyzed quantitatively with the (·) metric, already introduced in
Sect.3. Table1 reports the mean and standard deviation of the performance measure-
ments collected over 50 runs. It turns out that the PC algorithms do better than their
standard counterparts. Speciﬁcally, PC-MOEA/D turns out to be the best performing
algorithm, immediately followed by MOEA/D without secondaries. This conﬁrms
that PC algorithms inherit beneﬁts and some limitations from their underlying opti-
mizer too. To clarify, based on the empirical evidences, it is reasonable to say that
MOEA/D works consistently better than NSGA-II on this speciﬁc benchmark (PC-
1). Indeed, not only PC-MOEA/D gets a lower score (i.e., mean) than PC-NSGA-II,
but also MOEA/D without secondaries beats NSGA-II without secondaries, and the
same is true even for the third version of MOEA/D versus NSGA-II. Of course, the
property of MOEA/D being better than NSGA-II is not a general one: as we will
see, there exist other problems where the opposite is true, that is NSGA-II beats
MOEA/D. Moreover, the algorithms without secondaries usually perform similarly
to their PC variation, at least on the primary objectives, since both try to optimize
them in a Pareto manner. These considerations justify why PC-MOEA/D is at the
top of the ranking and why MOEA/D without secondaries is second.

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
197
Table 1 Mean and Std of metric (·) on PC-1 after 50 repetitions
Algorithm
Mean
Std
PC-MOEA/D
0.36 + 0.25①−1 + 0.99①−2
0.31 −0.07①−1 + 1.11①−2
MOEA/D pre
0.54 + 0.43①−1 + 3.22①−2
0.19 −0.22①−1 + 1.37①−2
MOEA/D post
1.44 −0.22①−1 + 0.88①−2
0.54 + 0.15①−1 + 0.59①−2
PC-NSGA-II
1.6 + 0.17①−1 + 1.2①−2
0.74 + 0.19①−1 + 0.44①−2
NSGA-II pre
1.95 + 0.57①−1 + 2.37①−2
0.91 + 0.21①−1 + 0.53①−2
NSGA-II post
1.79 + 0.08①−1 −0.77①−2
0.33 −0.02①−1 + 0.88①−2
Tan et al.
12.83 + 2.71①−1 + 4.03①−2
0.73 + 0.04①−1 + 1.2①−2
Chang et al.
18.01 + 4.45①−1 −4.42①−2
2.53 + 2.31①−1 + 3.48①−2
7.2
Test Problem: PC-3
The PC-3 test case is a modiﬁed version of POL, a well-known benchmark based on
the Poloni’s study [41], part of the Van Veldhuizen’s suite [50]:
min
 f (1)
1 (x) + ①−1 f (2)
1 (x)
f (1)
2 (x)

f (1)
1 (x) =

α

1 + (A1 −B1)2 + (A2 −B2)2
/α
f (1)
2 (x) =

α

(x1 + 3)2 + (x2 + 1)2
/α
f (2)
1 (x) = x2
1
A1 = 0.5 sin(1) −2 cos(1) + sin(2) −1.5 cos(2)
A2 = 1.5 sin(1) −cos(1) + 2 sin(2) −0.5 cos(2)
B1 = 0.5 sin(x1) −2 cos(x1) + sin(x2) −1.5 cos(x2)
B2 = 1.5 sin(x1) −cos(x1) + 2 sin(x2) −0.5 cos(x2)
x1, x2 ∈[−π, π], α = 3
The original structure of POL remains unchanged, except for the insertion of the
f loor function (to discretize the problem) and the addition of a third objective, f (2)
1 ,
which is to be considered less important than f (1)
1 .
The parameter α can be tuned to adjust the granularity of the discretization. In
the nondominance ranking procedure, the secondary objective f (2)
1
intervenes only
when two solutions have the same value of f (1)
1 , favoring the one whose coordinate
x1 is closer to 0. Therefore, it is reasonable to expect the new optimal solutions to
be very similar to those of original POL, at most slightly shifted towards the line
x1 = 0; the magnitude of such effect depends on α.
Figure4 shows the results of PC-NSGA-II for PC-3. As expected, the shape of
the Pareto front is similar to the POL one, the most noticeable difference being that it
appears as a set of disconnected points due to the discretization (ﬂoor function). As

198
L. Lai et al.
Table 2 Mean and Std of metric (·) on PC-3 after 50 repetitions
Algorithm
Mean
Std
PC-NSGA-II
0.01
0.02 + 0.01①−1
NSGA-II pre
0.34 + 0.09①−1
0.09 + 0.02①−1
PC-MOEA/D
0.59 −0.02①−1
0.58 −0.02①−1
NSGA-II post
0.65 −0.08①−1
0.16 −0.07①−1
MOEA/D pre
0.89 + 0.05①−1
1.4 −0.01①−1
MOEA/D post
1.23 −0.03①−1
1.48
Tan et al.
1.34 −0.82①−1
0.28 −0.16①−1
Chang et al.
38.06 −7.83①−1
3.0 −0.09①−1
it is often the case, there are some solutions in the Pareto frontier of primary objec-
tives with equal values of f (1)
1
but different values of f (1)
2 , which graphically appear
as vertically-aligned points. While the picture seems to show only a few dozens of
solutions, there are in fact 700 ﬁghting for optimality, but many of them are so close
to each other that they overlap. Using the standard approach of removing priori-
ties, running NSGA-II and eventually ﬁltering by priority-aware nondominance, the
obtained results are those of Fig.3. What at ﬁrst glance seems a richer front is actually
noise. Treating the third objective as important as the other two causes a dramatic
loss of accuracy in the search for optimal solutions, because part of the optimization
focus is shifted towards the minimization of this objective and dragged away from
the minimization of the other (most important) two. Indeed, after ﬁltering the ﬁnal set
of NSGA-II (Fig.3), only 7 out of 700 solutions are left, a very small fraction of the
total population. Also, the solutions found by NSGA-II turn out to be farther away
from the real Pareto front (thus worse) than those found by PC-NSGA-II. Essentially,
it happens because NSGA-II completely ignores the priorities of the objectives, not
taking advantage of that valuable information. On the other hand, PC-NSGA-II is
able to exploit it, succeeding to ﬁnd more accurate solutions.
Table2reportsthemeanandthestandarddeviationofthealgorithmsperformances
on the PC-3 benchmark. We observe once again that the PC algorithms perform better
than their standard counterparts and the other priority-based approaches. Moreover,
PC-NSGA-II turns out to be the overall best performing algorithm this time; NSGA-II
appears to work better than MOEA/D on the current benchmark. Indeed, the second
best performing algorithm is NSGA-II without secondaries. However, PC-MOEA/D
still gets a good score, being third and very close to the second.
8
The Priority Levels Model
PL-MPL-MOPs [28, 29] allow one to consider groups of conﬂicting objectives
ordered by priority. For instance, among the seven objectives of Fig.1b, a prior-

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
199
(a) Pareto front before ﬁltering
(b) Pareto set before ﬁltering
(c) Pareto front after ﬁltering
(d) Pareto set after ﬁltering
Fig. 3 Obtained solutions by NSGA-II for PC-3
ity structure can be deﬁned as illustrated: f A and fB are in the same priority level
and fC, fD and fE are also in the same priority level, but the former is lexicographi-
cally more important than the latter. The objectives fF and fG are in the same priority
level, which has lesser priority than the other ones.
Deﬁnition 2 (PL-MPL-MOP) Any MPL-MOP satisfying the two conditions below
is a PL-MPL-MOP:
• Some groups of objectives have clear precedence over some others and they can
be totally ordered according to it
• Within each group, objectives cannot be compared to each other on the basis of
importance
Finally, the mathematical formulation of a PL-MPL-MOP is:

200
L. Lai et al.
(a) Pareto front
(b) Pareto set
Fig. 4 Solutions obtained by PC-NSGA-II for PC-3
lex min
⎡
⎢⎢⎢⎢⎣
min
⎛
⎜⎜⎜⎝
f (1)
1 (x)
f (1)
2 (x)
...
f (1)
m1 (x)
⎞
⎟⎟⎟⎠, min
⎛
⎜⎜⎜⎝
f (2)
1 (x)
f (2)
2 (x)
...
f (2)
m2 (x)
⎞
⎟⎟⎟⎠, . . . , min
⎛
⎜⎜⎜⎜⎝
f (p)
1
(x)
f (p)
2
(x)
...
f (p)
m p (x)
⎞
⎟⎟⎟⎟⎠
⎤
⎥⎥⎥⎥⎦
,
(5)
where p is the number of levels and f ( j)
i
is the ith objective in the jth level.
In a PL-MPL-MOP, the Pareto-optimal solutions of the objectives in the ﬁrst
level form the decision space for the Pareto optimization of the objectives in the
second level, and then again the latter solutions become the domain for the third one,
and so on for every level. PL-MPL-MOPs are structurally quite similar to purely
lexicographic problems, except that each element of the sequence is now a multi-
objective problem on its own, instead of single-objective function in the original
lexicographic sense [40]. Of course, the formulation above covers the original case
as well, since a purely lexicographic problem is nothing but a particular case with
one objective function in each class. Similarly, the classical formulation of Pareto
MOPs occurs when there is only one priority level.
8.1
A First Example of a Real-World PL-MPL-MO Problem
The automotive crashworthiness problem [34] consists in ﬁnding the best car designs
balancing performance and safety. The original benchmark aims at maximizing the
vehicle acceleration while minimizing mass and toe-board intrusion. Even if the
three objectives are all necessary for a consistent design, one may assume that they

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
201
are not all equally important for a ﬁrm, also their mutual relation may vary across
manufacturers. For instance, a company may be interested in designing high per-
forming cars, in which case it would put more emphasis on the ﬁrst two objectives
(mass and acceleration) than on the safety one. Therefore, during the optimization
the toe-board intrusion should play a role in discriminating among the high speed
cars, rather than on the whole pool of vehicles. A possible approach is to reformu-
late the problem in a PL-fashion, as illustrated in (6). The model splits the original
3-objective optimization task in two PLs: the ﬁrst (high priority) contains the mass
and the acceleration, while the second (lower priority) focuses on safety while still
preserving the goal of maximizing the acceleration.
lex min

min
 mass(x)
−accel(x)

, min

toe(x)
−accel(x)

s.t. x ∈[1, 3]5.
(6)
Conversely, other ﬁrms may prefer to focus on safe cars. Such problem will be
analyzed in particular in the experimental section:
lex min

min
mass(x)
toe(x)

, min

toe(x)
−accel(x)

s.t. x ∈[1, 3]5.
8.2
Need of a New Approach for PL-MPL-MOPs
In this subsection, we aim to point out the limitations of strategies based on standard
optimization techniques when solving PL-MPL-MOPs. In the absence of tools that
are able to concurrently perform Pareto and lexicographic optimization, any viable
approach necessarily requires these two to run separately in distinct stages. How
these steps are interleaved may vary, leading to different options. We identify here
two strategies that are worth of consideration and which recall a lot those in Sect.5.1.
The ﬁrst way is to simply ignore the precedence relations during the multi-
objective search, thus Pareto optimizing all the objectives together, indistinctly. Only
afterwards the priorities are considered, by ﬁltering the solutions that are group-
lexicographically optimal. We refer to this approach as postﬁltering. Clearly, such
an approach is computationally inefﬁcient, as many more solutions need to be found
by the original EMO algorithm in order to have a sizable number of solutions at the
end.
The second approach uses a multi-objective optimizer solving the problem con-
sidering only the ﬁrst level. Only at the end of the process, the objectives from the
other levels are exploited to rank the obtained solutions. This scheme, called here
preﬁltering, is motivated by the fact that primary objectives have the highest impact
during the optimization. The weakness, however, is the little to no inﬂuence of the

202
L. Lai et al.
less important objectives in the result. Unlike the postﬁltering method, it puts indeed
a lot of responsibility on the primary objectives.
Section10 presents a new algorithm that is able to overcome these difﬁculties, that
does not split the optimization into sub-tasks, uses all the objectives concurrently,
yet still privileges those belonging to higher levels. Again, the approach uses the
Grossone Methodology.
8.3
Enhancing PL-MPL Problems by Means of Grossone
The idea to implement PL-aware algorithms is the similar to the one in Sect.5.2 in
the way it uses ①for lexicographic ranking. However, here the ①powers represent
scaling factors for groups of objectives, i.e., multi-objective optimization tasks rather
than single functions. PL-MPL-MOPs can be thus reformulated as:
min
⎡
⎢⎢⎢⎢⎣
⎛
⎜⎜⎜⎝
f (1)
1 (x)
f (1)
2 (x)
...
f (1)
m1 (x)
⎞
⎟⎟⎟⎠+ ①−1
⎛
⎜⎜⎜⎝
f (2)
1 (x)
f (2)
2 (x)
...
f (2)
m2 (x)
⎞
⎟⎟⎟⎠+ · · · + ①1−p
⎛
⎜⎜⎜⎜⎝
f (p)
1
(x)
f (p)
2
(x)
...
f (p)
mp (x)
⎞
⎟⎟⎟⎟⎠
⎤
⎥⎥⎥⎥⎦
.
Without going into the mathematical details, the optimization problem can be thought
has a minimization problem (and not a lexicographic one) of the PLs, whose contri-
bution is weighted in accordance to their priority. The level with the highest priority
is weighted by ①0 (=1, omitted), the second one by ①−1, and so on until no more PLs
remain, thereby giving inﬁnitely more importance to the higher levels. As a practical
example, the Grossone-based rewriting of the problem in (6), called PL-Crash, is
min
 mass(x)
−accel(x)

+ ①−1

toe(x)
−accel(x)

s.t. x ∈[1, 3]5.
With such reformulation of the problem, only one more ingredient is needed to
propose a PL extension of an EMO algorithm for solving PL-MPL-MOPs. Such
element is a novel, Grossone-based deﬁnition of dominance, that will be presented
in the next section. After that, the improvement of some fundamental routines of the
a standard EMO algorithm in order to handle PL-MPL-MOPs in an effective way is
discussed.

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
203
9
Handling Precedence in PL-MPL-MOPs
9.1
A New Deﬁnition of Dominance: PL-Dominance
As the original Pareto-optimality deﬁnition is not enough to cope with PL-MPL-
MOPs, a new one is proposed to take the priority structure into account and guide the
search towards better optima. Unlike PC-dominance, creating a good PL-dominance
is not trivial [28], as it must be well-deﬁned (the transitive property requires special
attention) and be effective in practice. The idea behind the PL-dominance proposed
here is to extend the concept of non-dominated fronts. According to the Pareto dom-
inance, a front is deﬁned as a set of solutions which do not dominate each other,
but are dominated by those of previous fronts and, in turn, dominate those in the
subsequent fronts. The new deﬁnition introduces the concept of “subfronts”, which
generalize “fronts” and consist in nested fronts determined by the priorities. The
procedure to partition the population into subfronts, described below, may resemble
in some aspects the preference-based ranking scheme by Fonseca and Fleming [17].
First, considering only the objectives with the highest priority, a set of non-
dominated fronts is determined as usual, according to Pareto dominance. Then, these
fronts are taken individually (one by one), and each is further split on the basis of the
objectives of the second highest priority level, determining new groups of (sub)fronts.
The same procedure is iterated recursively on the newly deﬁned subfronts, until there
are no more priority levels left. The whole population is eventually partitioned in
a hierarchy of subfronts, where the term “subfronts” indicates the groups obtained
after every splitting. Grossone Methodology comes in handy, letting one uniquely
identify any subfront within the hierarchy by means of a G-scalar index. For instance,
Fi where i = 2①0 + 7①−1 + 3①−2 denotes all the solutions in the front 2 for the
primary objectives, front 7 for the secondary objectives (within the individuals in the
front 2 for the primaries) and front 3 for the tertiaries (among those with primary
front 2 and secondary front 7). The formal deﬁnition is:
Deﬁnition 3 (PL-Dominance) Given a PL-MPL-MOP and two solutions A and B
belonging to the subfronts Fi and Fj, respectively, A “PL-dominates” B if and only
if i is strictly smaller than j: A ≺∗B ⇐⇒i < j.
It is worth noting the a posteriori nature of the deﬁnition: it is not always possible
to tell whether two elements are dominated or not before assigning a ﬁtness rank
to the whole population. In other words, the non-dominance relation is not just a
function of two arguments (solutions), but has a global dependency on all the other
individuals.
The transitivity of the proposed PL-Dominance can be proven:
Proposition 1 PL-dominance in Deﬁnition3 is transitive.
Proof Let S be a set of distinct solutions already partitioned in subfronts. Following
the notation above, indicate the partitioning in subfronts as follows: ∀X ∈S, X ∈

204
L. Lai et al.
Fx. In order to demonstrate that ≺∗is transitive, the following must hold: ∀X, Y, Z ∈
S, X ≺∗Y ∧Y ≺∗Z ⇒X ≺∗Z. One can show that it is always true by repeatedly
applying Deﬁnition3. Indeed, X ≺∗Y ∧Y ≺∗Z =⇒x < y ∧y < z =⇒x < y <
z.
9.2
PL-Dominance in PL-Crash Problem
For a better comprehension of how PL-Dominance works, this subsection illustrates
its step-by-step application in the case of PL-Crash problem (6). In accordance with
Deﬁnition3, the optimal Pareto front shall consists of all the solution falling in the
subfront indexed by the G-scalar 1 + 1①−1. This means that among those solutions
which are Pareto efﬁcient considering the objective in the ﬁrst PL (mass and accelera-
tion), the ones that are truly optimal are also Pareto efﬁcient considering acceleration
and toe-board intrusion only.
This request affects the optimal three-dimensional front of the original problem
(given in [13]) as described in the next lines. First, all the solutions are projected on
the mass-acceleration plane and only the Pareto efﬁcient survives. Figure5 reports
this process: the green dots indicate the individuals which are preserved and therefore
form the parent front, the one indexed by the G-scalar 1. Then, the survived solutions
are projected on the toe-acceleration plane (second priority level, Fig.6), and only
those which are non-dominated also there can be considered truly optimal. Such
individuals, highlighted in red in Fig.7, are the only ones which belong to the subfront
1 + 1①−1, since they are the non-dominated solutions (including secondaries) of the
non-dominated ones in the ﬁrst PL.
If one wants to retrieve the sub-optimal solutions belonging to the 1 + 2①−1
subfront (assuming it is not empty), s/he should discard the solutions just found and
repeat the procedure above. On the other hand, if one wants the solutions in the
2 + ①−1 subfront, s/he should eliminate all the solutions in the front 1 (regardless
the inﬁnitesimals), and again repeat the procedure just illustrated.
Figure8 shows the solutions of the PL-MPL-MOP problem (red points) in the
entire three-dimensional objective space (marked with blue points). No known dom-
ination check on the entire objective space is able to promote the red points only.
This further highlights the novelty in the PL-dominance deﬁnition as well as its
effectiveness in PL-MPL-MOPs. Note that the postponed ﬁltering only works when
the whole front of the non-prioritized problem is known, which may not be the case
for high-dimensional problems Sect.8.2. To overcome these issues, next section
introduces a generalization of NSGA-II, enhanced with Grossone Methodology and
PL-Dominance in order to transparently and directly cope with any PL-MPL-MOP.

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
205
Fig. 5 Original optimal
solutions on the
mass-acceleration plan. First
PL in green
Fig. 6 Original optima on
the toe-acceleration plan.
First PL optima in green,
second in magenta
10
Algorithm for PL: PL-NSGA-II
The new deﬁnition of PL-dominance paves the way for a generalization of ranking-
based EMO algorithms to solve PL-MPL problems. Here, it is presented for NSGA-II
only, yet nothing prevents the very same approach to be exploited in other frameworks
as well. NSGA-II core operations are already illustrated Sect.6 and are reported here
too to simplify the reading and help the reader understanding: (i) assignment of a
non-dominance rank to each solution; (ii) sorting the population by rank; (iii) best-
to-worst accommodation of the fronts in the next population, until a too large to
ﬁt one is found; (iv) ﬁlling the next population with the solutions of the last front
according to their crowding distance.

206
L. Lai et al.
Fig. 7 Original optimal
solutions on the
toe-acceleration plan: in red
the optimal solutions for
both PLs
Fig. 8 Effect of the priority
on the 3D Pareto front. Only
the red solutions are truly
optimal

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
207
Fig. 9 An example of ranking procedure based on Deﬁnition3
The ﬁrst two steps, together, are efﬁciently carried out by the NSGA-II subproce-
dure called fast_nondominated_sort, while the fourth mainly leverages on the routine
crowding_distance_assignment. Since they are not designed to do anything special
when some objectives have priority over others, we improved them to increase their
effectiveness when solving PL-MPL-MOPs, obtaining their PL extension. The pieces
are eventually put together, creating PL-NSGA-II, our variant of NSGA-II speciﬁcally
adapted for PL-MPL-MOPs.
10.1
PL Fast Non-dominated Sort and PL Crowding Distance
In PL-NSGA-II, the solutions are split into subfronts on the basis of the PL-
Dominance, which by deﬁnition makes two solutions less likely to be non-dominated
each other than NSGA-II does. As a consequence, PL_fast_nondominated_sort is
expected to return a reasonably larger number of smaller-sized fronts, that is a posi-
tive thing considering that the main weakness of many-objective algorithms is indeed
having large sets of non-dominated solutions, as mentioned earlier. This difﬁculty
is alleviated by taking into account the priority levels of the objectives. A visual
example of the rank assignment procedure is outlined in Fig.9. Refer to Algorithms
3 and 4 for the corresponding pseudocode.

208
L. Lai et al.
Algorithm 3: Priority Levels fast non-dominated sort
Algorithm 4: Fast non-dominated sort in each level

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
209
The proposed PL_crowding_distance_assignment is described in Algorithm 5,
and it basically consists in a G-weighted sum of the standard crowding distances
computed within every priority level. In practice, it follows these steps: ﬁrst, the stan-
dard crowding distance is computed for the primary (read most important) objectives
and weighted by ①0; then, the same happens considering the second level objectives
only, with weight ①−1; this is repeated for every level, decreasing the G-weight
after each step; ﬁnally, all the partial results are added together to form a G-scalar,
representing the PL crowding distance.
Since PL_crowding_distance_assignment is computed within each subfront, and
subfronts tend to be generally smaller with respect to NSGA-II fronts because of the
new ranking system, we can observe that in PL-NSGA-II the non-dominated sorting
algorithm carries more weight than the crowding distance one. A shift in the delicate
balance between convergence and diversity preservation may look questionable, but
it can be justiﬁed by the following consideration. Diversity preservation mechanisms
exist to keep a certain degree of spread among the best solutions. With the addition
of extra information to the problem, namely the priorities, we have more means to
tell which solutions are better than which, therefore it is easier to circumscribe a
smaller set of best solutions. Such an increase in the ability to estimate the quality
of solutions partially alleviates the need to maintain a large diversity between them
because, from the perspective of a decision maker, it may be preferable to have a
narrow set of truly optimal solutions rather than a larger group of diversiﬁed but
potentially sub-optimal ones. That being said, the PL crowding distance still plays
a crucial role after all, and does a decent job at spreading the solutions across the
efﬁcient set, especially nearer to the convergence.
Algorithm 5: Priority Levels crowding distance assignment

210
L. Lai et al.
10.2
PL-NSGA-II
By incorporating both PL_fast_nondominated_sort and PL_crowding_distance
_assignment into NSGA-II, one obtains an enhanced version that is also capable of
handling PL-MPL-MOPs in a proper way; the name of this algorithm is PL-NSGA-II.
Now, look how the two new functions affect the make_new_pop procedure, that is
drafting the parent population for the next generation. Similarly to what happens in
NSGA-II, the subfronts are sequentially included in the next population in order of
rank; when there remains no enough room to insert the next subfront in its entirety,
the latter is sorted by PL crowding distance and the ﬁttest individuals eventually
survive. PL-NSGA-II could in theory support custom recombination and mutation
operators too, which is another very promising research direction. The pseudocode
of PL-NSGA-II is speciﬁed in Algorithm 6.
Algorithm 6: PL-NSGA-II algorithm
Of course, there may be other ways to implement these functionalities, and the
same ideas can also be ported to other EMO algorithms as well. This algorithm
was chosen for its simplicity and similarity to the Grossone-based generalization of
NSGA-II.

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
211
11
Test Cases for PL-MPL-MOPs
As for PC-MPL-MOPs, there is a lack of existing PL-MPL-MOPs test problems
too. The following paragraphs deal with both synthetic problems and a real-world
one, which is an adaptation of the 10-objective GAA problem [51]. The latter allows
to introduce of levels of priority quite naturally (given the insights of a domain
expert, and it has thus been renamed PL-GAA. Finally, the PL-Crash problem already
introduced in Sect.8.1 is revisited.
The performance of PL-NSGA-II is compared against seven classic EMO algo-
rithms: (i) postﬁltered NSGA-II (NSGA-II-post), (ii) preﬁltered NSGA-II (NSGA-
II-pre), (iii) postﬁltered NSGA-III (NSGA-III-post), (iv) postﬁltered MOEA/D
(MOEA/D-post), (v) preﬁltered MOEA/D (MOEA/D-pre), (vi) the favoring graph-
based approach proposed in [47] (Schmiedle et al.), and (vii) the dynamic prioritized
goal-based approach proposed in [49] (Tan et al.), already considered in Sect.7
for priority chains. NSGA-III preﬁltered is not considered as an interesting option
because the number of objectives at the ﬁrst level is too low to justify the use of a
many-objective optimizer. Note that the performances of direction-based algorithms
such as NSGA-III and MOEA/D would be better if the priority information was
somehow used to guide the search: this idea is left for a future study. As in Sect.7,
SBX crossover and polynomial mutation operators are adopted, each algorithm run
50 times per benchmark.
11.1
Test Problem: PL-1
PL-1 has ﬁve objectives, two of which are less important than the others.
min
⎡
⎣
⎛
⎝
f (1)
1 (x)
f (1)
2 (x)
f (1)
3 (x)
⎞
⎠+ ①−1
 f (2)
1 (x)
f (2)
2 (x)
⎤
⎦,
f (1)
1 (x) = cos
 π
10 x1

cos
 π
10 x2

,
f (1)
2 (x) = cos
 π
10 x1

sin
 π
10 x2

,
f (1)
3 (x) = sin
 π
10 x1

+ g(x),
f (2)
1 (x) = ((x1 −2)2 + (x2 −2)2 −1)2,
f (2)
2 (x) = ((x1 −2)2 + (x2 −2)2 −3)2,
g(x) =

x3 −
45
9 + (x1 −2)2 + (x2 −2)2
2
,
x1, x2, x3 ∈[0, 5].

212
L. Lai et al.
Fig. 10 PL-1 theoretical Pareto set (blue) and efﬁcient set (red)
The easiest way to grasp this problem is to decompose it into smaller parts.
Considering only the ﬁrst three objectives, namely those whose priority is maximum,
it can be recognized that the Pareto surface (on which g(x) = 0) is an octant of a
unit sphere. In the variable space, it is generated by the following set of points:
S :=

(x1, x2, x3) ∈R3  x1 ∈[0, 5], x2 ∈[0, 5], x3 = 45/

9 + (x1 −2)2 + (x2 −2)2
,
which corresponds to a bell-shaped curve on the x3-axis. Figure10a reports it in
gray. Among all Pareto-optimal solutions for the primary objectives, i.e., the points
in S, secondary objectives f (2)
1
and f (2)
2
make non-dominated only the points within
the blue annular region. Moving to the objective space, the entire positive octant
represents the efﬁcient set in the primary objective space, while only the red region
is it also for the whole problem, i.e., considering also the secondaries (see Fig.10b).
The solution found by PL-NSGA-II for PL-1 is the one in Fig.11: the quality of
the solutions found by PL-NSGA-II is evident. Indeed, the set of optimal points both
in the decision (Fig.11a) and in the objective space (Fig.11b) seems to closely ﬁt
the theoretical expectations of Fig.10.
To obtain it, PL-NSGA-II run for 500 generations with a population of 100 indi-
viduals, and the same holds for all the other algorithms. Table3 reports the mean and
the standard deviation of their performance. PL-NSGA-II appears to be the best algo-
rithm, outperforming the second one both in terms of mean and standard deviation.
In other words, not only PL-NSGA-II achieves better results, but it is also stabler.
11.2
PL-GAA: A Real-World Problem
The GAA benchmark [51] is a difﬁcult many-objective problem from a real-world
scenario. It challenges the decision maker to tune 27 constrained variables in order
to design a family of three slightly different aircrafts for general aviation. The crucial

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
213
Fig. 11 Obtained solutions by PL-NSGA-II for PL-1
Table 3 PL-1: Mean and Std. Dev. for metric (·)
Algorithm
Mean
Std
PL-NSGA-II
0.002 + 0.43①−1
0.002 −0.09①−1
MOEA/D-post
0.01 + 2.18①−1
0.01 + 0.33①−1
MOEA/D-pre
0.01 + 2.94①−1
0.01 + 0.90①−1
NSGA-II-pre
0.01 + 3.53①−1
0.01 + 0.53①−1
NSGA-II-post
0.15 + 2.42e4①−1
0.03 −6.94e3①−1
NSGA-III-post
0.49 + 1.47e3①−1
0.23 + 8.11e3①−1
Tan et al.
6.63 + 6.62e4①−1
7.16 −3.42e4①−1
Schmiedle et al.
8.92 + 4.10e4①−1
6.8 −7.12e3①−1
point is that not only the optimization procedure must maximize the aircraft perfor-
mances over conﬂicting parameters, but also the resulting airplanes must be similar
enough not to force industrial facilities diversiﬁcation. The objective space has 10
dimensions, 9 of which describe the aircraft performances, while the last one mea-
sures their diversity (henceforth called PFPF). The 9 performance metrics are: the
takeoff noise (NOISE), empty weight (WEMP), direct operating costs (DOC), ride
roughness (ROUGH), fuel weight (WFUEL), ﬂight range (RANGE), purchase price
(PURCH), maximum lift/drag ratio (LDMAX), maximum cruise speed (VCMAX).
Also, PFPF and the ﬁrst 6 performance metrics are constrained objectives.
With the help of a domain expert, the problem has been reformulate dividing the
10 objectives in 4 PLs, obtaining the new problem PL-GAA:
min
⎡
⎣⌊PFPF⌋
+ ①−1
⎛
⎝
DOC
–LDMAX
–RANGE
⎞
⎠+ ①−2
⎛
⎝
NOISE
PURCH
WEMP
⎞
⎠+ ①−3
⎛
⎝
ROUGH
WFUEL
–VCMAX
⎞
⎠
⎤
⎦.

214
L. Lai et al.
The PL with the highest importance consists of only one objective: PFPF. Since the
aircraftsimilarityisthedecision-maker’smainconcern,thischoicecomesasanatural
option. As stated in [51], the decision-maker can tolerate a diversity level not greater
than 0.05. Thus, the PFPF output space is discretized in intervals of length 0.05, by
means of the ﬂoor operator: ⌊·⌋. In this way, all the aircraft conﬁgurations within the
tolerance constraint (PFPF ∈[0, 0.05]) are considered maximally optimized for the
ﬁrst PL. This will produce a number of feasible designs which will be considered
equally good for PFPF objective. Subsequent levels will then determine a single
or more preferred solutions. With regard to the second PL, the choice fell on the
DOC objective because its importance is already pointed out in [51], while the other
two (LDMAX and RANGE) are two critical factors in aircraft performance and
usability, respectively. A detailed discussion about the remaining two PLs is omitted
for brevity; nevertheless, it should be noted that the third PL still contains some
highly impacting aircraft features, like NOISE (which can limit the possibility to
land close to an urban center) or PURCH (of course, the price plays a relevant role
in the decision process). Conversely, the least important level contains not so crucial
properties (e.g., the maximum speed VCMAX), or aspects for which relatively cheap
and simple customer solutions already exist (e.g., the roughness ROUGH).
In the experiments, due to the complexity of the problem, each algorithm run with
200 individuals for 2,000 generations. Moreover, due to the presence of constraints
also on the objectives, the pre-ﬁltered approaches have been excluded from the per-
formance comparison, since they necessarily perform poorly. Table4 reports the
algorithms average performance (the performance of NSGA-II-pre and MOEA/D-
pre have not been reported, being their use on this problem clearly meaningless). As
before, PL-NSGA-II ﬁnds noticeably better solutions than the other algorithms, even
for this challenging problem. It is worth noting that the ﬁnite component of the (·)
metric has a special meaning: it is zero only when PFPF falls within [0, 0.05], which
indicates that all the algorithms with a non-inﬁnitesimal mean were not always able
to fully satisfy the PFPF constraint. Also, the higher the mean value is, the higher
the average decision maker dissatisfaction is; the higher the variance is, the higher
the randomness of the performance quality is.
The numerical evidences tell us that only two algorithms are able to respect such
a constraint, namely PL-NSGA-II (always) and Schmiedle et al. (most of the cases).
This fact is quite interesting indeed, while PL-NSGA-II is designed to properly
master the Pareto dominance also in the presence of priority levels (PL-dominance),
Schmiedle et al. does not use the Pareto dominance at all. Instead, it leverages on the
favoring binary relation (see [47]), suggesting to address to this aspect the reasons of
its high performances and capability to satisfy the PFPF’s constraint. All in all, the
only algorithm with an inﬁnitesimal mean, i.e., able to always guarantee the PFPF
constraint satisfaction is PL-NSGA-II, proving its strength.

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
215
Table 4 PL-GAA: Mean and Std. Dev. for metric (·) (NSGA-II-pre and MOEA/D-pre not
reported, being their use meaningless on this problem)
Algorithm
Mean
Std. Dev.
PL-NSGA-II
4.29e3①−1 + 1.91e4①−2+
21.82①−3
1.65e4①−1 + 3.23e4①−2
+4.04e4①−3
Schmiedle et al.
0.06 + 1.00e4①−1 +
7.74e4①−2 + 19.7①−3
0.24 −1.30e3①−1 +
5.63e8①−2 + 3.08e12①−3
NSGA-II-post
1.24 + 1.12e5①−1 +
6.66e5①−2 + 482.83①−3
1.36 −1.12e4①−1 +
2.55e9①−2 + 2.08e13①−3
NSGA-III-post
3.9 + 3.24e4①−1 +
4.13e5①−2 + 214.36①−3
4.99 + 1.13e4①−1 +
8.48e7①−2 −1.91e11①−3
Tan et al.
102.55 + 8.90e4①−1 +
5.48e5①−2 + 421.65①−3
1.22e2 + 1.23e4①−1 +
1.92e7①−2 −1.99e9①−3
MOEA/D-post
113.08 + 8.23e4①−1 +
8.66e5①−2 + 1.47e3①−3
26.11 −5.64e3①−1 +
9.56e7①−2 + 2.01e10①−3
Table 5 PL-Crash: Mean and Std. Dev. for metric (·)
Algorithm
Mean
Std
PL-NSGA-II
0.002 + 2.99e −5①−1
0.02 + 2.00e −4①−1
NSGA-II-post
1.00 + 0.52①−1
0.22 −0.001①−1
NSGA-II-pre
1.12 + 0.57①−1
0.23 −0.01①−1
MOEA/D-post
14.29 + 1.80①−1
11.76 −0.37①−1
MOEA/D-pre
19.50 + 1.43①−1
12.12 −0.30①−1
Tan et al.
29.96 + 1.73①−1
16.97 + 0.48①−1
NSGA-III-post
94.51 + 4.51①−1
44.14 + 1.55①−1
Schmiedle et al.
143.14 + 10.76①−1
32.06 + 2.23①−1
11.3
Test Problem: PL-Crash
This section provides brief experimental results on the PL-Crash problem already
discussedintheprevioussectionsofthiswork.Table5containsthemeanandstandard
deviation values of the (·) metric. Again, PL-NSGA-II signiﬁcantly outperforms
the competitors.
12
Conclusions
In this chapter the novel and very general class of Mixed Pareto-Lexicographic Multi-
Objective Problems has been introduced and discussed. The peculiarity of these
problems is to have the objective functions organized according to a priority structure,
and different structures lead to different models. In particular, two models have been

216
L. Lai et al.
deeply investigated: PC-MPL-MOPs, where the objective are organized in chains of
priority; and PL-MPL-MOPs, where the functions are grouped in levels which are
ordered by priority. In order to solve the intrinsic limits of standard approaches when
dealing with these two classes of MPL-MOPs, the Grossone Methodology has been
leveraged to achieve two results: (i) a reformulation of the models which is easier to
be processed by a computer; (ii) the generalization of standard EMO algorithms in
order to make them able to cope with these more general problems. The effectiveness
of the generalizations has been tested on several benchmark and compared with
several well-known algorithms (Grossone-based algorithms have been evaluated on
an Inﬁnity Computer simulator implemented by the authors). The results testify that
the additional information about priority relations among objectives can be exploited
to signiﬁcantly improve the algorithms search, guiding them towards higher quality
solutions than those provided by conventional multi-objective algorithms.
References
1. Adra, S.F., Fleming, P.J.: Diversity management in evolutionary many-objective optimization.
IEEE Trans. Evolut. Comput. 15, 183–195 (2011)
2. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft. Comput. 24(23),
17751–17759 (2020)
3. Cavoretto, R., De Rossi, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: On the search of the
shape parameter in radial basis functions using univariate global optimization methods. J.
Global Optim. 79(2), 305–327 (2021)
4. Chang, P.-C., Hsieh, J.-C., Lin, S.-G.: The development of gradual-priority weighting approach
for the multi-objective ﬂowshop scheduling problem. Int. J. Prod. Econ. 79, 171–183 (2002)
5. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Towards lexicographic multi-objective linear
programmingusinggrossonemethodology.In:Proceedingsofthe2ndInternationalConference
“Numerical Computations: Theory and Algorithms”. AIP Conference Proceedings, vol. 1776,
p. 90040 (2016)
6. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective linear pro-
gramming using grossone methodology: theory and algorithm. Appl. Math. Comput. 318,
298–311 (2018)
7. Coello Coello, C.A., Sierra, M.R.: A study of the parallelization of a coevolutionary multi-
objective evolutionary algorithm. In: Mexican International Conference on Artiﬁcial Intelli-
gence, pp. 688–697 (2004)
8. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming and operations
research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
9. De Leone, R.: Nonlinear programming and grossone: quadratic programming and the role of
constraint qualiﬁcations. Appl. Math. Comput. 218(16), 290–297 (2018)
10. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based computation of
negative curvature directions in large-scale optimization. J. Optim. Theory Appl. 186, 554–589
(2020)
11. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the conjugate
gradient breakdown in nonlinear programming. Comput. Optim. Appl. 71(1), 73–93 (2018)
12. Deb, K.: Multi-objective Optimization Using Evolutionary Algorithms, vol. 16. Wiley, New
York (2001)
13. Deb, K., Jain, H.: An evolutionary many-objective optimization algorithm using reference-
point-based nondominated sorting approach, part I: Solving problems with box constraints.
IEEE Trans. Evolut. Comput. 18, 577–601 (2014)

On the Use of Grossone Methodology for Handling Priorities in Multi-objective …
217
14. Deb, K., Joshi, D., Anand, A.: Real-coded evolutionary algorithms with parent-centric recom-
bination. In: Proceedings of the 2002 Congress on Evolutionary Computation, vol. 1, pp. 61–66
(2002)
15. Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algo-
rithm: NSGA-II. IEEE Trans. Evolut. Comput. 6, 182–197 (2002)
16. Deb, K., Thiele, L., Laumanns, M., Zitzler, E.: Scalable test problems for evolutionary multi-
objective optimization. Evolut. Multiobjective Optim. 105–145 (2005)
17. Fonseca, C.M., Fleming, P.J.: Multiobjective optimization and multiple constraint handling
with evolutionary algorithms – Part I: A uniﬁed formulation. IEEE Trans. Syst Man Cybern.-
Part A: Syst. Humans 28, 26–37 (1998)
18. García, S., Molina, D., Lozano, M., Herrera, F.: A study on the use of non-parametric tests
for analyzing the evolutionary algorithms’ behaviour: a case study on the CEC’ 2005 special
session on real parameter optimization. J. Heuristics 15, 617 (2009)
19. Garza-Fabre, M., Pulido, G. T., Coello Coello, C.A.: Ranking methods for many-objective
optimization. In: Mexican International Conference on Artiﬁcial Intelligence, pp. 633–645
(2009)
20. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.: Numerical inﬁnitesimals in a variable
metric method for convex nonsmooth optimization. Appl. Math. Comput. 318, 312–320 (2018)
21. Gaur, A., Khaled Talukder, A., Deb, K., Tiwari, S., Xu, S., Jones, D.: Unconventional optimiza-
tion for achieving well-informed design solutions for the automobile industry. Eng. Optim. 52,
1542–1560 (2020)
22. Gergel, V, Grishagin, V., Israﬁlov, R.: Adaptive dimensionality reduction in multiobjective opti-
mization with multiextremal criteria. In: Machine Learning, Optimization, and Data Science,
pp. 129–140 (2019)
23. Hansen, M.P., Jaszkiewicz, A.: Evaluating the quality of approximations to the non-dominated
set. IMM, Department of Mathematical Modelling, TU Denmark (1994)
24. Holm, S.: A simple sequentially rejective multiple test procedure. Scand. J. Stat. 65–70 (1979)
25. Iman, R.L., Davenport, J.M.: Approximations of the critical region of the fbietkan statistic.
Commun. Stat.-Theory Methods 9, 571–595 (1980)
26. Ishibuchi, H., Masuda, H., Tanigaki, Y., Nojima, Y.: Modiﬁed distance calculation in genera-
tional distance and inverted generational distance. In: International Conference on Evolutionary
Multi-Criterion Optimization, pp. 110–125 (2015)
27. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed Pareto-Lexicographic multi-objective opti-
mization problems: the case of priority chains. Swarm Evolut. Comput. 55, 100687 (2020)
28. Lai, L., Fiaschi, L., Cococcioni, M., Deb, K.: Solving mixed pareto-lexicographic multi-
objective optimization problems: the case of priority levels. IEEE Trans. Evolut. Comput.
(2021)
29. Lai, L., Fiaschi, L., Cococcioni, M., Deb, K.: Handling priority levels in mixed pareto-
lexicographic many-objective optimization problems. In: Proceedings of the 2021 Interna-
tional Conference on Evolutionary Multi-Criterion Optimization, Shenzhen, China, pp. 362–
374 (2021)
30. Laumanns, M., Thiele, L., Deb, K., Zitzler, E.: Combining convergence and diversity in evo-
lutionary multiobjective optimization. Evolut. Comput. 10, 263–282 (2002)
31. Li, K., Deb, K., Kwong, S.: An evolutionary many-objective optimization algorithm based on
dominance and decomposition. IEEE Trans. Evol. Comp. 19, 694–716 (2015)
32. Li, H., Deb, K., Zhang, Q., Suganthan, P.N., Chen, L.: Comparison between MOEA/D and
NSGA-III on a set of novel many and multi-objective benchmark problems with challenging
difﬁculties. Swarm Evol. Comput. 46, 104–117 (2019)
33. Li, M., Yao, X.: Quality evaluation of solution sets in multiobjective optimisation: a survey.
ACM Comput. Surv. (CSUR) 52, 1–38 (2019)
34. Liao, X., Li, Q., Yang, X., Zhang, W., Li, W.: Multiobjective optimization for crash safety
design of vehicles using stepwise regression model. Struct. Multidiscip. Optim. 35, 561–569
(2008)

218
L. Lai et al.
35. Khare, V., Yao, X., Deb, K.: Performance scaling of multi-objective evolutionary algorithms. In:
International Conference on Evolutionary Multi-Criterion Optimization, pp. 376–390 (2003)
36. Khosravani, S., Jalali, M., Khajepour, A., Kasaiezadeh, A., Chen, S.K., Litkouhi, B.: Applica-
tion of Lexicographic optimization method to integrated vehicle control systems. IEEE Trans.
Ind. Electron. 65, 9677–9686 (2018)
37. Knowles, J., Corne, D.: On metrics for comparing nondominated sets. In: IEEE Proceedings
of the 2002 Congress on Evolutionary Computation, vol. 1, pp. 711–716 (2002)
38. Marler, R.T., Arora, J.S.: Survey of multi-objective optimization methods for engineering.
Struct. Multidiscip. Optim. 26, 369–395 (2004)
39. Marques-Silva, J., Argelich, J., Graça, A., Lynce, I.: Boolean lexicographic optimization: algo-
rithms & applications. Ann. Math. Art. Int. 62, 317–343 (2011)
40. Miettinen, K.: Nonlinear Multiobjective Optimization. Springer Science, New York (1999)
41. Poloni, C.: Hybrid GA for multi objective aerodynamic shape optimisation. Genetic Algorithms
in Engineering and Computer Science, 397–415 (1995)
42. Purshouse, R.C., Fleming, P.J.: Evolutionary many-objective optimisation: an exploratory anal-
ysis. In: The 2003 IEEE Congress on Evolutionary Computation, vol. 3, pp. 2066–2073 (2003)
43. Sergeyev, Y.D.: The Olympic medals ranks, lexicographic ordering, and numerical inﬁnities.
Math. Intell. 37(2), 4–8 (2015)
44. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications, and reper-
cussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320 (2017)
45. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-standard
analysis and comments upon logical fallacies in some texts asserting the opposite. Found. Sci.
24(1), 153–170 (2019)
46. Sergeyev, Y.D., Nasso, M.C., Mukhametzhanov, M.S., Kvasov, D.E.: Novel local tuning tech-
niques for speeding up one-dimensional algorithms in expensive global optimization using
Lipschitz derivatives. J. Comput. Appl. Math. 383, 113134 (2021)
47. Schmiedle, F., Drechsler, N., Große, D., Drechsler, R.: Priorities in multi-objective optimiza-
tion for genetic programming. In: Proceedings of the 3rd Annual Conference on Genetic and
Evolutionary Computation, pp. 129–136 (2001)
48. Schutze, O., Esquivel, X., Lara, A., Coello Coello, C.A.: Using the averaged Hausdorff distance
as a performance measure in evolutionary multiobjective optimization. IEEE Trans. Evol.
Comput. 16, 504–522 (2012)
49. Tan, K.C., Khor, E.F., Lee, T.H., Sathikannan, R.: An evolutionary algorithm with advanced
goal and priority speciﬁcation for multi-objective optimization. J. Artif. Intell. Res. 18, 183–215
(2003)
50. Van Veldhuizen, D.A.: Multiobjective evolutionary algorithms: classiﬁcations, analyses, and
new innovations. Air Force Institute of Technology Wright Patterson AFB, OH, USA (1999)
51. Wang, L., Ng, A.H.C., Deb, K.: Multi-objective Evolutionary Optimisation for Product Design
and Manufacturing. Springer Nature, Berlin (2011)
52. Yuan, Y., Xu, H., Wang, B., Yao, X.: A new dominance relation-based evolutionary algorithm
for many-objective optimization. IEEE Trans. Evolut. Comput. 20, 16–37 (2016)
53. Zhang, Q., Li, H.: MOEA/D: a multiobjective evolutionary algorithm based on decomposition.
IEEE Trans. Evolut. Comput. 11, 712–731 (2007)
54. Zhang, Q., Zhou, A., Zhao, S., Suganthan, P.N., Liu, W., Tiwari, S.: Multiobjective optimiza-
tion test instances for the CEC 2009 special session and competition. University of Essex,
Colchester, and Nanyang technological University, Singapore, TR, vol. 264 (2008)
55. Zitzler, E., Laumanns, M., Thiele, L.: SPEA2: improving the strength Pareto evolutionary
algorithm. TIK-report 103 (2001)
56. Zitzler,E.,Thiele,L.:Multiobjectiveoptimizationusingevolutionaryalgorithms:acomparative
case study. In: International Conference on Parallel Problem Solving from Nature, pp. 292–301
(1998)

Applications and Implementations

Exact Numerical Differentiation
on the Inﬁnity Computer
and Applications in Global
Optimization
Maria Chiara Nasso and Yaroslav D. Sergeyev
Abstract There exist many applications where it is necessary to approximate
numerically derivatives of a function f (x) which is given by a computer
procedure. A novel way to efﬁciently compute exact derivatives (the word
“exact” means here with respect to the accuracy of the implementation of
f (x)) is presented in this Chapter. It uses a new kind of a supercomputer—the
Inﬁnity Computer—able to work numerically with different ﬁnite, inﬁnite,
and inﬁnitesimal numbers. Numerical examples illustrating these concepts
and numerical tools are given. In particular, the ﬁeld of Lipschitz global
optimization having a special interest in exact numerical differentiation is
considered in cases where there exists a code for computing f (x) but a code
for its derivative f ′(x) is not available. In addition, it is supposed that the ﬁrst
derivative f ′(x) satisﬁes the Lipschitz condition. Algorithms using smooth
piece-wise quadratic support functions and their convergence conditions are
discussed. All the methods are implemented both in the traditional ﬂoating-
point arithmetic and in the Inﬁnity Computing framework.
M. C. Nasso (B) · Y. D. Sergeyev
University of Calabria, Rende, CS, Italy
e-mail: mc.nasso@dimes.unical.it
Y. D. Sergeyev
e-mail: yaro@dimes.unical.it
Y. D. Sergeyev
Lobachevsky State University, Nizhny Novgorod, Russia
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_9
221

222
M. C. Nasso and Y. D. Sergeyev
1
Introduction
The capabilities of the Inﬁnity Computer framework cover a wide range of
actions. In fact, this methodology, working with ﬁnite, inﬁnite and inﬁnites-
imal numbers, was successfully applied in several areas of mathematics and
computer science. In [8, 12, 16, 37], the Inﬁnity Computer framework was
applied in game theory and probability, in hyperbolic geometry and percola-
tion
(see
[26,
32]),
fractals
(see [3, 7]), inﬁnite series (see [45, 51]), Turing machines, cellular automata
and supertasks (see [11, 38, 47]), local, global, and multiple criteria opti-
mization (see [14, 17, 52]), numerical differentiation and numerical solution
of ordinary differential equations (see [1, 15, 24]), etc. The methodology is
taught nowadays in several countries (see, e.g., [2, 23, 25]), in particular, the
University of East Anglia, UK developed a web page ([22]) in which a teach-
ing manual can be found. In the following pages we will focus our attention
on exact numerical differentiation on the Inﬁnity Computer and describe how
it can be used in Global Optimization.
In many applications (e.g. numerical simulation, differentiation, and inte-
gration) it is required to calculate derivatives of a function g(x) which is given
by a computer procedure calculating its approximation f (x). Usually, proce-
dures for evaluating the exact values of derivatives of f (x) are not available
and numerical approximations or automatic differentiation techniques are
often
used
for
this
purpose
(see,
e.g.
[4, 9, 33] and references given therein for a detailed discussion).
The simplest formulae used on traditional computer to approximate the
ﬁrst derivative f ′(x) which require evaluation of f (x) at two points and use
forward, backward, and central differences are the following:
f ′(x) ≈f (x + h) −f (x)
h
, f ′(x) ≈f (x) −f (x −h)
h
,
(1)
f ′(x) ≈f (x + h) −f (x −h)
2h
.
(2)
However, due to the ﬁniteness of digits in the mantissa of ﬂoating-point num-
bers, round-off errors in these procedures dominate calculation when h →0.
Both f (x + h) and f (x −h) tend to f (x), so that their difference tends to the
difference of two almost equal quantities and thus contains fewer and fewer
signiﬁcant digits that provokes an explosion of the computational error. As
an example, let us consider a computer procedure f (x) implementing the
function g(x) = x+3
x+1 and study errors provided by formulae (1), (2) during
approximation of the value f ′(y) at the point y = 1 in dependence of the

Exact Numerical Differentiation and Global Optimization
223
0
1
2
3
4
5
6
7
8
9
10
Stepsize h
10-8
-10
-9
-8
-7
-6
-5
-4
-3
-2
-1
0
log10 Error
Forward difference
Backward difference
(a)
0
2
4
6
8
10
12
14
16
18
20
Stepsize h
10-6
-12
-10
-8
-6
-4
-2
0
log10 Error
Central difference
(b)
Fig. 1 When h becomes sufﬁciently small the error of approximation increases drasti-
cally
step h. It can be seen from Fig. 1 that when h becomes sufﬁciently small the
error of approximation increases drastically. Thus, it is meaningless to carry
out these computations beyond a certain treshold value of h. Calculations of
higher derivatives suffer from the same problems.
Let us consider some other techniques. The complex step method (see [31])
allows one to improve approximations of f ′(x) avoiding subtractive cancel-

224
M. C. Nasso and Y. D. Sergeyev
lation errors present in (1), (2) by using the following formula to approximate
f ′(x)
f ′(x) ≈Im[ f (x + ih)]
h
,
(3)
where Im(u) is the imaginary part of u. Though this estimate does not
involve the dangerous difference operation, it is still an approximation of
f ′(x) because it depends on the choice of the step h.
Another approach consists of the usage of symbolic (algebraic) computa-
tions (see, e.g., [9]) where f (x) is differentiated as an expression in symbolic
form in contrast to manipulating numerical quantities used to express f (x).
Unfortunately this approach can be too slow when it is applied to long codes
coming from real world applications.
There is an extensive literature (see, e.g., [4, 5, 10] and references given
therein) dedicated to automatic (algorithmic) differentiation (AD) that is a
set of techniques based on the mechanical application of the chain rule to
obtain derivatives of a function given as a computer program. By applying
the chain rule of derivation to elementary operations this approach allows one
to compute derivatives of arbitrary order automatically with the precision of
the code representing f (x).
Implementations of AD can be broadly classiﬁed into two categories that
have their advantages and disadvantages (see [5, 10] for a detailed discus-
sion): (i) AD tools based on source-to-source transformation changing the
semantics by explicitly rewriting the code; (ii) AD tools based on operator
overloading using the fact that modern programming languages offer the pos-
sibility to redeﬁne the semantics of elementary operators. In particular, the
dual numbers extending the real numbers by adjoining one new element d
with the property d2 = 0 (i.e., d is nilpotent) can be used for this purpose
(see, e.g., [4]). Every dual number has the form v = a + db, where a and
b are real numbers and v can be represented as the ordered pair (a, b). On
the one hand, dual numbers have a clear similarity with complex numbers
z = a + ib where i2 = −1. On the other hand, speaking informally it can be
said that the imaginary unit d of dual numbers is a close relative to inﬁnitesi-
mals (we mean here a general non formalized idea about inﬁnitesimals) since
the square (or any higher power) of d is exactly zero and the square of an
inﬁnitesimal is ‘almost zero’.
All the methods described above use traditional computers as computa-
tional devices and propose a number of techniques to calculate derivatives
on them. In this Chapter, a new way to calculate derivatives numerically is
described. It is made by using a new kind of a supercomputer—the Inﬁn-
ity Computer—introduced in [43, 45] and able to work numerically with
different ﬁnite, inﬁnite, and inﬁnitesimal quantities. This computer is based

Exact Numerical Differentiation and Global Optimization
225
on a new applied point of view on inﬁnite and inﬁnitesimal numbers (see
[42]) that, as shown in [46], is not related to non-standard analysis. The new
approach does not use Cantor’s ideas and works with inﬁnite and inﬁnites-
imal numbers being in accordance with the principle ‘The part is less than
the whole’. Since this framework allows one to efﬁciently compute exact
derivatives, it is applied in one-dimensional algorithms in expensive global
optimization using derivatives in the case where the optimized function is
given as a black box.
2
Numerical Differentiation on the Inﬁnity Computer
In order to start, let us recall the basics of the positional numeral system with
the base grossone used at the Inﬁnity Computer (grossone is expressed by
the numeral ①, see [45] and Chap. 1 of this book for detailed descriptions
of ①). To express an inﬁnite, ﬁnite, or inﬁnitesimal number C at the Inﬁnity
Computer we subdivide C into groups corresponding to different powers
of ①:
C = cpm①pm + · · · + cp1①p1 + cp0①p0 + cp−1①p−1 + · · · + cp−k①p−k.
(4)
Then, the record
C = cpm①pm . . . cp1①p1cp0①p0cp−1①p−1 . . . cp−k①p−k
(5)
represents the number C, where ﬁnite numbers ci called grossdigits can be
both positive and negative (in case during computations a grossdigit cpi = 0
is obtained, the corresponding term cpi①pi is excluded from C). Grossdigits
show how many corresponding units should be added or subtracted in order
to form the number C. Grossdigits can be expressed by several symbols.
Numbers pi in (5) called grosspowers can be ﬁnite, inﬁnite, and inﬁnitesimal,
they are sorted in the decreasing order with p0 = 0.
Purely ﬁnite numbers in this numeral system are represented by numerals
having only one grosspower p0 = 0. In fact, if we have a number C such that
m = k = 0 in representation (5), then, since ①0 = 1 (see [45]), we have C =
c0①0 = c0. Thus, the number C in this case does not contain grossone and is
equal to the grossdigit c0 being a conventional ﬁnite number expressed in a
traditional ﬁnite numeral system. Terms having negative ﬁnite grosspowers
represent the simplest inﬁnitesimal parts of C. For instance, the number
2①−1 = 2
①is inﬁnitesimal. If a number contains a term c0①0 and some

226
M. C. Nasso and Y. D. Sergeyev
inﬁnitesimal terms, then it is ﬁnite but not purely ﬁnite. Terms having ﬁnite
positive grosspowers represent the simplest inﬁnite parts of C.
Let us now suppose that we have a set of basic functions (sin(x), cos(x), ax
etc.) represented at the Inﬁnity Computer by their truncated Taylor series or
other kinds of approximations (see [34]) using the argument x and ﬁnite
constants that are connected by four arithmetical operations. We consider a
function g(x) and a computer procedure calculating its approximation f (x)
that is constructed using the said implementations of basic functions, the
argument x, and ﬁnite constants connected by four arithmetical operations.
We suppose that f (x) approximates g(x) sufﬁciently well with respect to
some criteria and we shall not discuss the goodness of this approximation
in this Chapter. Our attention will be attracted to numerical calculations of
derivatives f ′(x), . . . f (k)(x) and the information that can be obtained from
the computer procedure f (x) for this purpose. The following theorem holds
(see [44]).
Theorem 1 Suppose that:
(i) for a function f (x) calculated by a procedure implemented at the Inﬁnity
Computer there exists an unknown Taylor expansion over an interval [a, b],
with a and b purely ﬁnite numbers, containing a purely ﬁnite point y;
(ii) f (x), f ′(x), f (2)(x), . . . f (k)(x) assume purely ﬁnite values or are equal
to zero for purely ﬁnite points x ∈[a, b];
(iii) f (x) has been evaluated at a point y + ①−1 ∈[a, b]. Then the Inﬁn-
ity Computer returns the result of this evaluation in the positional numeral
system with the inﬁnite radix ①in the following form
f (y + ①−1) = c0①0c−1①−1c−2①−2 . . . c−(k−1)①−(k−1)c−k①−k,
(6)
where
f (y) = c0, f ′(y) = c−1, f (2)(y) = 2! · c−2, . . . f (k)(y) = k! · c−k.
(7)
Proof Let us consider the Taylor expansion for f (x) with h > 0
f (x + h) = f (x) + f ′(x)h + f (2)(x)h2
2 + · · ·
by assuming x = y and h = ①−1. Obviously, the Taylor expansion of f (x)
is unknown for the Inﬁnity Computer. Due to the rules of its operation,
while calculating f (y + ①−1), different exponents of ①are simply col-
lected in independent groups with ﬁnite grossdigits. Since functions f (x),
f ′(x), f (2)(x), . . . f (k)(x) assume purely ﬁnite values or are equal to zero

Exact Numerical Differentiation and Global Optimization
227
over the interval [a, b] with a, b which are also purely ﬁnite, the highest
grosspower in the number (6) is necessary less or equal to zero. Thus, the
number that the Inﬁnity Computer returns can have only a ﬁnite and inﬁnites-
imal parts. The fact that four arithmetical operations (see [45]) executed by
the Inﬁnity Computer with the operands having ﬁnite integer grosspowers in
the form (5) produce only results with ﬁnite integer grosspowers concludes
the proof.
□
Let us comment upon the theorem. It describes a situation where we need to
evaluate f (x) and its derivatives at a point x = y but analytic expressions of
f (x), f ′(x), f (2)(x), . . . f (k)(x) are unknown and computer procedures for
calculating f ′(x), f (2)(x), . . . f (k)(x)areunavailable.Moreover,theinternal
structure of the procedure f (x) can also be unknown for us.
Instead of the usage of traditional formulae (1), (2), we evaluate f (x)
at the point y + ①−1. The Inﬁnity Computer will return the number in
the form (6) from where we can easily obtain exact values of f (y) and
f ′(y), f (2)(x), . . . f (k)(y) as shown in (7) without any knowledge of the
formula and/or computer procedure for evaluating derivatives. Due to the
fact that the Inﬁnity Computer is able to work with inﬁnite and inﬁnitesimal
numbers numerically, the values f ′(y), . . . f (k)(y) are calculated exactly at
the point x = y without introduction of dangerous operations (1), (2) related
to the necessity to use ﬁnite values of h when one works with traditional
computers.
If we come back to the function g(x) = x+3
x+1 and calculate the value
f (1 + ①−1) of its implementation f (x) obtained using the Inﬁnity Com-
puter framework, we have that f (1 + ①−1) = 2①0 −1
2①−1 from where one
can obtain that f (1) = 2, f ′(1) = −1
2 which coincide with the exact val-
ues of the functions g(x), g′(x) in the point x = 1. Let us now illustrate the
theorem by other examples.
Example 1 Suppose that we have a computer procedure implementing
the following function f (x) = 2x2 and we want to evaluate the values
f (y), f ′(y), f (2)(y), and f (3)(y) at a point x = y. If we evaluate now f (x)
at a point y + ①−1 we obtain
f (y + ①−1) = 2(y + ①−1)2 = 2y2 + 4y①−1 + 2①−2 =
(8)
2y2①04y①−12①−2.
(9)
By applying (7) we immediately calculate the required values
f (y) = 2y2, f ′(y) = 4y, f (2)(y) = 4.

228
M. C. Nasso and Y. D. Sergeyev
That, obviously, coincide with the respective derivatives
f ′(x) = 4x, f (2)(x) = 4,
at the point x = y. The Inﬁnity Computer executes (8), (9) numerically using
a given value of y. For instance, for y = 36 it executes the following opera-
tions
f (36 + ①−1) = 2 · 36①01①−1 · 36①01①−1 =
2592①0144①−12①−2.
(10)
From (10) by applying (7) we obtain that
f (36) = 2592, f ′(36) = 144, f (2)(36) = 2! · 2 = 4,
that are correct values of f (x) and the derivatives at the point y = 36.
□
Example 2 Supposethatwehavetwofunctions g1(x) = sin(3x)and g2(x) =
ex and they are represented in the Inﬁnity Computer as
f1(x) = 3x −9x3
2 , f2(x) = 1 + x + x2
2
(11)
being respectively the ﬁrst two and three items in the corresponding Taylor
expansions. If we want to evaluate f1(x) and f ′
1(x) at a point y, we apply the
ﬁrst formula from (11) at the Inﬁnity Computer as follows
f1(y + ①−1) = 3(y + ①−1) −9(y + ①−1)3
2
= 3y + 3①−1 −9(y3 + 3y2①−1 + 3y①−2 + ①−3)
2
=
3y −9
2 y3 +

3 −27
2 y2

①−1 −27
2 y①−2 −9
2 ①−3.
Thus, the Inﬁnity Computer returns
f1(y) = 3y −9
2 y3, f ′
1(y) = 3 −27
2 y2.
For istance, for y = 2 we obtain
f1(2 + ①−1) = 3(2 + ①−1) −9(2 + ①−1)3
2
=
−30 −51①−1 −27①−2 −9
2①−3.
Therefore

Exact Numerical Differentiation and Global Optimization
229
f1(2) = −30, f ′
1(y) = −51.
If we want to calculate f2(x), f ′
2(x) and f (2)
2 (x) at a point y, we obtain
f2(y + ①−1) = 1 + y + ①−1 + (y + ①−1)2
2
=
(1 + y + y2
2 )①0(1 + y)①−1 1
2①−2.
Therefore
f2(y) = 1 + y + y2
2 , f ′
2(y) = 1 + y, f (2)
2 (y) = 1.
Thus for y = −4, the Inﬁnity Computer returns
f2(−4 + ①−1) = 1 −4 + ①−1 + (−4 + ①−1)2
2
=
5①0 −3①−1 1
2①−2.
Then we have
f2(−4) = 5, f ′
2(−4) = −3, f (2)
2 (−4) = 1.
Notice that the Inﬁnity Computer just uses formulae in (11) and works with
the accuracy of approximation of g1(x) and g2(x) bounded by the accuracy
of f1(x) and f2(x).
□
Example 3 Suppose that we have a computer procedure implementing
the following function f (x) = x+5
x2
and we want to calculate the values
f (y), f ′(y), f (2)(y), and f (3)(y) at the point y = 2. As in the previous
examples, we evaluate f (x) at a point y + ①−1. We consider the Inﬁnity
Computer that returns grossdigits corresponding (as it was in the previous
examples automatically) to the exponents of grossone from 0 to −3. Then
we have
f (2 + ①−1) = 2 + ①−1 + 5
(2 + ①−1)2 =
7①0①−1
4①04①−1①−2 =
1.7500①0 −1.500①−11.0625①−2 −0.6875①−3.

230
M. C. Nasso and Y. D. Sergeyev
By applying (7) we obtain that
f (2) = 1.7500, f ′(2) = −1.500,
f (2)(2) = 2! · 1.0625 = 2.1250, f (3)(2) = 3! · −0.6875 = −4.125,
that are values which one obtains by using explicit formulae
f (x) = x + 5
x2
, f ′(x) = −x + 10
x3
, f (2)(x) = 2(x + 15)
x4
, f (3)(x) = −6(x + 20)
x5
for f (x) and its derivatives at the point x = 2.
□
3
Application in Lipschitz Global Optimization
Globaloptimizationisanimportantresearchﬁeldwithnumerousapplications
in engineering, electronics, machine learning, optimal decision making, etc.
In many of these applications, even in the univariate case, evaluations of
the objective functions and derivatives are often time-consuming and the
number of function evaluations executed by algorithms is extremely high
due to the presence of multiple local extrema. As a result, the problems of an
accelerationoftheglobalsearchandcomputingefﬁcientlyexactderivativesin
the case where the optimized function is given as a black box arise inevitably.
The necessity to ﬁnd the best (in other words, global) solution in the situa-
tionwhereahighnumberoflocalextremaispresentexplainsthecontinuously
increasing interest of researchers to global optimization algorithms looking
for global minimum (or maximum). One of the important methodologies
developed to attack this problem is Lipschitz global optimization (see, e.g.,
[29, 35]).Itusesanaturalassumptionontheglobaloptimizationproblemsup-
posing that the objective function under consideration has bounded slopes,
in other words, it satisﬁes the Lipschitz property and at the same moment
it can be multiextremal and each evaluation can be a very time-consuming
operation. An important subclass in Lipschitz global optimization consists
of functions with the ﬁrst derivative satisfying the Lipschitz condition (see
[13, 28], etc.).
Problems belonging to Lipschitz global optimization are extremely difﬁ-
cult even in the one-dimensional case and are under an intensive study at least
for two reasons. First, there exists a huge number of applications where prob-
lemsofthiskindarise.Thesecondreasonisthatone-dimensionalschemesare
broadly used for constructing multi-dimensional global optimization meth-
ods.

Exact Numerical Differentiation and Global Optimization
231
In this Chapter, our attention is devoted to the global optimization problem
f ∗= f (x∗) = min f (x),
x ∈D,
(12)
where f (x), with x ∈D = [a, b], is the objective black-box function and
its ﬁrst derivative f ′(x) satisﬁes the Lipschitz condition with an unknown
Lipschitz constant 0 < M < ∞, i.e.
| f ′(x) −f ′(y)| ≤M|x −y|,
x, y ∈D.
(13)
An additional practical difﬁculty consists in the fact that it is supposed that
there exists a code for computing f (x) only and a code for the derivative
f ′(x) is not available. The problem (12), (13) is under a close scrutiny since
the nineties of the last century. Breiman and Cutler (see [6]) have proposed a
method to solve the problem (12) where the constant M from (13) is a priori
known whereas Gergel in [18] has proposed a global optimization method
that estimates M in the course of the search. Both methods use in their work
auxiliary non-smooth support functions that are less or equal to f (x), x ∈D.
Since the objective function f (x) is differentiable over the search region D,
in [30, 40] there have been introduced methods constructing smooth support
functions that are closer to the objective function f (x) with respect to non-
smooth ones providing so a notable acceleration in comparison with the
methods [6, 18].
Moreover, it is well known in Lipschitz global optimization that the usage
of the global (i.e., the same for the whole search region D) Lipschitz constant
or its global estimate can slow down the search. In order to overcome this
difﬁculty, a number of local tuning techniques automatically controlling the
exploitation-exploration trade-off have been proposed in [19, 27, 40, 49].
These techniques adaptively estimate local Lipschitz constants over different
subregions of D constructing auxiliary functions that are closer to f (x) with
respect to those using the global Lipschitz constant (or its estimates). As
a result, methods using local tuning techniques are signiﬁcantly faster than
algorithms working with the global Lipschitz constant.
Let us present now a theoretical background required for construction of
smooth support functions for global optimization algorithms for solving the
problem (12), (13). Global optimization methods introduced in [40] construct
a smooth support function ψi(x) at each subinterval [xi−1, xi], 2 ≤i ≤k,
of the search region D where the points xi, 1 ≤i ≤k, are the so-called trial
points, i.e., points where f (x) and f ′(x) have been evaluated. The function
ψi(x) is constructed using the fact that the maximal possible curvature of
f (x) is determined by the Lipschitz constant M from (13). The functions

232
M. C. Nasso and Y. D. Sergeyev
x1
x2
y
x3
2
|
y
2
y
3
|
y
3
z1
z2
z3
f(x)
φ1(x)
φ2(x)
φ3(x)
π2(x)
π3(x)
Fig. 2 Constructing smooth support functions ψi(x) for f (x)
ψi(x) ≤f (x),
x ∈[xi−1, xi], 2 ≤i ≤k,
(14)
can be built using the following three functions
πi(x) = 0.5Mx2 + bix + ci,
(15)
φi−1(x) = zi−1 + z′
i−1(x −xi−1) −0.5M(x −xi−1)2,
(16)
φi(x) = zi −z′
i(xi −x) −0.5M(xi −x)2,
(17)
where zi = f (xi), z′
i = f ′(xi), and bi, ci are two parameters to be deter-
mined.
Notice that φi−1(x) and φi(x) are support functions for f (x) and are
obtained from the Taylor formulae based at the points xi−1 and xi, respec-
tively. The meaning of the parabola πi(x) will be explained in a minute. It
has been shown in [6, 18] that
max{φi−1(x), φi(x)},
x ∈[xi−1, xi], 2 ≤i ≤k,
is a non-smooth minorant for f (x) over [xi−1, xi]. Then, the key observation
made in [40] in order to construct a smooth minorant consists in the fact
that due to the boundedness of the curvature of f (x), it cannot be below the
parabola πi(x) over the interval [y′
i, yi] that can be found by asking that the
piece-wise quadratic function

Exact Numerical Differentiation and Global Optimization
233
ψi(x) =
⎧
⎪⎨
⎪⎩
φi−1(x),
x ∈[xi−1, y′
i],
πi(x),
x ∈[y′
i, yi],
φi(x),
x ∈[yi, xi],
(18)
is a smooth support function for f (x) over [xi−1, xi] (see Fig. 2). The values
yi, y′
i and bi, ci from (15) can be determined by “gluing” the functions
φi−1(x), πi(x), φi(x) and their ﬁrst derivatives. In other words, the following
system of equations should be solved:
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
φi−1(y′
i) = πi(y′
i)
φi(yi) = πi(yi)
φ′
i−1(y′
i) = π′
i(y′
i)
φ′
i(yi) = π′
i(yi)
(19)
As was shown in [40], its solution is:
yi = xi −xi−1
4
+ z′
i −z′
i−1
4M
+ zi−1 −zi + z′
i xi −z′
i−1xi−1 + 0.5M(x2
i −x2
i−1)
M(xi −xi−1) + z′
i −z′
i−1
,
(20)
y′
i = −xi −xi−1
4
−z′
i −z′
i−1
4M
+ zi−1 −zi + z′
i xi −z′
i−1xi−1 + 0.5M(x2
i −x2
i−1)
M(xi −xi−1) + z′
i −z′
i−1
,
(21)
bi = z′
i −2Myi + Mxi,
(22)
ci = zi −z′
ixi −0.5Mx2
i + My2
i .
(23)
Then we construct ψi(x), searching for the point
pi = min{ψi(x) : x ∈[xi−1, xi]}
and the respective value R(i) = ψi(pi) called characteristic of the interval
[xi−1, xi]. The term characteristic is due to the class of characteristic methods
introduced in [20] for solving Lipschitz global optimization problems. The
same terminology is used in Divide the Best methods (see [41]) to determine
a goodness of each subregion of the search domain. In fact, the methods under
consideration belong to the class of Divide the Best algorithms.
Since in practice it is difﬁcult to know a priori the global constant M and
its usage over the whole region D can slow down the search, Local Tuning
techniques can be applied in order to automatically balance global and local

234
M. C. Nasso and Y. D. Sergeyev
information during the global search and allow one to obtain a signiﬁcant
acceleration of the algorithms.
4
Local Tuning Techniques
The ﬁrst local tuning technique automatically balancing global and local
information during the global search has been initially introduced in [39]
for Lipschitz functions that can be non-differentiable. It has been shown that
strategies of this kind allow one to obtain a signiﬁcant acceleration of the
search. As a result, an intensive research activity focused on developing new
local tuning strategies and ﬁnding new classes of problems where they can
be applied has begun (see, for example, [21, 27, 48]).
We start this section by presenting two traditional strategies for choosing
an estimate for the global value M from (13). After that a known local tuning
from [40] and two recent local tuning techniques from [49] will be introduced.
In order to describe these procedures let us denote as {xi}k the ordered trial
points (the operation of evaluation of f (x) and f ′(x) at a point x is called
trial), where k ≥2 is the number of iterations of the algorithm (for k = 2:
x1 = a and x2 = b). Let r > 1 be the reliability parameter of the methods.
For each interval [xi−1, xi], 2 ≤i ≤k, its local Lipschitz constant for
f ′(x) is estimated by values mi in one of the following ﬁve ways:
1. A priori given Lipschitz constant. Set
mi = M,
2 ≤i ≤k.
(24)
In this case, an algorithm uses the same exact a priori known value M from
(13) of the Lipschitz constant of f ′(x) for each subinterval [xi−1, xi], 2 ≤
i ≤k.
2. Global estimate. Compute estimates
mi = r · max{ξ, Hk},
2 ≤i ≤k,
(25)
where ξ > 0 is a technical parameter (a small number greater than 0) reﬂect-
ing the supposition that f ′(x) is not constant over the interval [xi−1, xi].
Then,
Hk = max{vi : 2 ≤i ≤k},
(26)
with
vi = |2(zi−1 −zi) + (z′
i−1 + z′
i)(xi −xi−1)| + di
(xi −xi−1)2
(27)

Exact Numerical Differentiation and Global Optimization
235
and
di =

|2(zi−1 −zi) + (z′
i−1 + z′
i)(xi −xi−1)|2 + (z′
i −z′
i−1)2(xi −xi−1)2.
(28)
Notice that this adaptive estimate of the global Lipschitz constant is
obtained by imposing that the upper bound
φ+
i−1(x) = zi−1 + z′
i−1(x −xi−1) + 1
2mi(x −xi−1)2,
based on the point xi−1 is equal or greater than the lower bound
φ−
i (x) = zi + z′
i(x −xi) −1
2mi(x −xi)2,
based on the point xi, over the interval [xi−1, xi], i.e.,
φ+
i−1(x) ≥φ−
i (x),
x ∈[xi−1, xi],
(29)
and the upper bound
φ+
i (x) = zi + z′
i(x −xi) + 1
2mi(x −xi)2,
based on the point xi is equal or greater than the lower bound
φ−
i−1(x) = zi−1 + z′
i−1(x −xi−1) −1
2mi(x −xi−1)2,
based on the point xi−1, over the interval [xi−1, xi] i.e.,
φ+
i (x) ≥φ−
i−1(x),
x ∈[xi−1, xi],
(30)
As shown in [50], in order to satisfy (29), (30) it is sufﬁcient that the following
inequality holds for mi:
mi ≥τ(x),
x ∈[xi−1, xi],
where
τ(x) = 2|zi −zi−1 + z′
i(x −xi) −z′
i−1(x −xi−1)|
(x −xi)2 + (x −xi−1)2
.
It can be proved that the values vi from (27) are such that
vi = max{τ(x) : x ∈[xi−1, xi]}.

236
M. C. Nasso and Y. D. Sergeyev
As was already mentioned, strategies 1 and 2 described above can slow
down the global search. In order to overcome this problem, the following
local tuning technique has been introduced in [40].
3. Maximum Local Tuning. Compute estimates
mi = r · max{λi, γi, ξ},
(31)
where ξ is a small positive number,
λi = max{vi−1, vi, vi+1},
3 ≤i ≤k −1,
(32)
with vi as in (27); when k = 2 only v2 should be considered and when i = 2
and i = k we consider only v2, v3 and vk−1, vk, respectively.
The value γi is calculated as follows:
γi = Hk (xi −xi−1)
Xmax
,
(33)
Xmax = max{(xi −xi−1),
2 ≤i ≤k}.
(34)
Notice that these adaptive local estimates of local Lipschitz constants are
obtained during the search balancing through (31) local and global informa-
tion obtained in the course of the previous iterations. Indeed, when the interval
[xi−1, xi] is small then the local information managed by λi has a decisive
rule; in contrast, when the interval [xi−1, xi] is wide the global information
represented by γi is used.
It should be stressed that in the case of the a priori given Lipschitz constant,
condition (13) ensures that ψi(x) from (2) is a minorant for f (x). Since
strategies 2 and 3 estimate Lipschitz constants, the resulting functions ψi(x)
can violate the inequality ψi(x) ≤f (x). This fact can lead to the loss of
the global solution during the search. Conditions ensuring convergence to
global solutions of optimization methods using global and local estimates of
Lipschitz constants for f ′(x) will be established in the following pages.
In order to introduce the Maximum-Additive Local Tuning for derivatives
let us notice that the Maximum Local Tuning technique described above
balances local and global information about f ′(x) computing the maximum
among values λi, γi, and ξ (see (31)). It has been recently shown in [48] that
for functions g(x) satisfying the Lipschitz condition
|g(x) −g(y)| ≤L|x −y|,
x, y ∈D,
(35)
with a constant L, 0 < L < ∞, it makes sense to use a maximum-additive
convolution of values representing local and global information collected

Exact Numerical Differentiation and Global Optimization
237
during the search (that, clearly, are collected in a different way w.r.t. (32)
and (33) since functions satisfying (35) can be non-differentiable whereas
λi and γi estimate Lipschitz constants for derivatives). Let us illustrate a
maximum-additive convolution of (32) and (33) for our problem (12)–(13).
4. Maximum-Additive Local Tuning for derivatives. Compute estimates
mi = r · max{vi, 1
2(λi + γi), ξ},
2 ≤i ≤k,
(36)
where values vi, λi, and γi are from (27), (32), and (33), respectively.
This estimate provides an additive mixture of λi and γi with the equal
usage of local and global information. The presence of vi in (36) is explained
by the fact that for small intervals the estimate γi can be very small (see
(33)) leading so to the prohibited situation vi > 0.5(λi + γi). If vi was not in
(36), this could lead to the possibility that points y′
i and yi can be generated
outside the interval [xi−1, xi] and this could produce errors in the work of
algorithm. The presence of vi in (36) avoids this case. Notice also that (36) can
be generalized to the case of a weighted usage of local and global estimates
depending on a parameter 0 < ρ < 1 as follows
mi = r · max{vi, ρλi + (1 −ρ)γi, ξ}.
The idea for the last local tuning technique we are going to introduce also
comes from algorithms developed to deal with problems satisfying Lipschitz
condition (35). Among the ﬁrst methods proposed to solve this problem we
ﬁnd algorithms of Piyavskij (see [36]) and Strongin (see [27]). The former is
based on geometric ideas and constructs for the objective function a piece-
wise linear minorant having slopes ±L deﬁned by (35) whereas the latter
uses a stochastic model for its work and adaptively estimates L by the value
μ = max{μi : 2 ≤i ≤k}, μi = |zi −zi−1|(xi −xi−1)−1.
It has been proven in [50] that the method of Strongin has a geometric
interpretation. It can be viewed as a procedure constructing over each interval
[xi−1, xi], 2 ≤i ≤k, an auxiliary piece-wise linear function (that becomes
a minorant under certain conditions) with the local slopes ±si, where
si = 0.5(rμ + μ2
i
rμ), 2 ≤i ≤k.
(37)
It can be seen from (37) that in si we have a mixture of a local information
represented by μi and the global one represented by μ. Methods using the
local tuning technique (37) have been tested in [27] showing a promising

238
M. C. Nasso and Y. D. Sergeyev
performance on a broad class of test problems satisfying (35). Let us now
introduce the following Mixed Local Tuning technique for derivatives evolv-
ing the idea of the convolution (37) from algorithms working with functions
satisfying (35) to methods that can be used to solve our problem (12)–(13).
5. Mixed Local Tuning for derivatives. Compute values
mi = max{rvi, 0.5(rη + v2
i (rη)−1)},
η = max{Hk, ξ},
2 ≤i ≤k,
(38)
where Hk is from (26). In this local tuning the local information is represented
by vi and the global one is represented by η.
Let us now make a remark regarding the correct construction of the func-
tions ψi(x) from (18). As was already mentioned above, if over an interval
[xi−1, xi] the value mi is underestimated, the points y′
i and yi can be gener-
ated outside the interval [xi−1, xi] and this can produce errors in the work
of the algorithms. It has been proven in [40, 50] that strategies (24), (25),
and (31) ensure that the points y′
i and yi are inside the interval [xi−1, xi]. An
analogous result can be proven (see [49]) for the strategies (36) and (38).
Theorem 2 If β is a ﬁnite number and the following condition
vi < mi ≤β < ∞,
(39)
takes place for the strategies (36) and (38), then for functions ψi(x) con-
structed by these algorithms
y′
i ∈(xi−1, xi), yi ∈(xi−1, xi).
Moreover, it follows
y′
i −xi−1 ≥
(mi
vi −1)2
4mi
vi (mi
vi + 1)(xi −xi−1),
(40)
xi −yi ≥
(mi
vi −1)2
4mi
vi (mi
vi + 1)(xi −xi−1).
(41)
Proof The proof is analogous to the proof of Theorem 4.11 from [50] with
the remark that strategies (36) and (38) ensure that the inequality (39) is
satisﬁed automatically since the parameter r is a ﬁnite number r > 1.

Exact Numerical Differentiation and Global Optimization
239
5
General scheme and convergence conditions
We are now ready to describe decision rules of ﬁve global optimization algo-
rithms using the strategies illustrated above to estimate Lipschitz constants.
The methods have a similar structure that is reported in the following General
Scheme incorporating the ﬁve algorithms using Derivatives (GSD).
STEP 0. The ﬁrst two trials are executed at the points x1 = a and x2 = b.
For k ≥2 we choose the point xk+1 using the following steps:
STEP 1. Renumber the points x1, . . . , xk and the corresponding function
values z1, . . . , zk of the previous iterations by subscripts so that
a = x1 < · · · < xk = b,
zi = f (xi),
1 ≤i ≤k.
STEP 2. Calculate the current estimate mi of the Lipschitz constants of
f ′(x) over the intervals [xi−1, xi], 2 ≤i ≤k, in one of the ways previously
described in (24), (25), (31), (36), and (38).
STEP 3. Calculate for each interval [xi−1, xi], 2 ≤i ≤k its characteristic
Ri.
STEP 4. Select the interval (xt−1, xt) corresponding to the minimal char-
acteristic, i.e., such that
Rt = min{Ri : 2 ≤i ≤k}.
STEP 5. If the stopping rule is not satisﬁed, i.e.,
|xt −xt−1| > ε,
where ε is the accuracy of the search, then execute the next trial at the point
xk+1 = pt = min{ψt(x) : x ∈[xt−1, xt]}
(42)
Using the procedures proposed to estimate M in the previous section and
the general scheme described above we obtained the following 5 algorithms:
• DKC: The method using the ﬁrst Derivatives and the a priori Known Lip-
schitz Constant M, see (24).
• DGE: The method using the ﬁrst Derivatives and the Global Estimate of
the Lipschitz Constant M, see (25).
• DML: The method using the ﬁrst Derivatives and the Maximum Local
Tuning, see (31).
• DMAL:Themethodusingtheﬁrst Derivativesandthe Maximum-Additive
Local Tuning, see (36).

240
M. C. Nasso and Y. D. Sergeyev
• DMXL: The method using the ﬁrst Derivatives and the Mixed Local Tun-
ing, see (38).
The following global convergence properties have been studied in [40, 49,
50]. Let us consider an inﬁnite trial sequence {xk} generated by an algorithm
belongingtothegeneralscheme GSD withtheaccuracyε = 0.Thefollowing
results for each algorithm belonging to GSD hold:
Theorem 3 Let the point x, (x ̸= a, x ̸= b) be a limit point of the sequence
{xk} generated by an algorithm belonging to the general scheme GSD during
the course of minimizing a function f (x), x ∈[a, b]. If the values mi satisfy
conditions (39) then the point x will be a local minimizer of the function
f (x).
Theorem 4 Let x, (x ̸= a, x ̸= b) be a limit point of the sequence {xk} gen-
erated by an algorithm belonging to the general scheme GSD during the
course of minimizing a function f (x), x ∈[a, b]. Then, if condition (39) is
fulﬁlled for the intervals containing x, there exist two subsequences of {xk}
converging to x, one from the left, the other from the right.
Theorem 5 Let x be a limit point of the sequence {xk} generated by an algo-
rithm belonging to the general scheme GSD and condition (39) be fulﬁlled.
We then have for trial points xk
f (xk) ≥f (x),
k ≥1.
(43)
Corollary 1 If, given the conditions of the theorem, alongside x there exists
another limit point x′ of the sequence {xk} then f (x) = f (x′).
Let us denote by M j the local Lipschitz constant of f ′(x) over an interval
[x j−1, x j], by X the set of limit points of {xk} and by X∗the set of global
minimizers of f (x). The following theorem then takes place.
Theorem 6 Let x∗be a global minimizer of f (x) and [x j−1, x j], j = j(k),
be an interval containing this point during the course of k-th iteration of
GSD. If there exists an iteration number s such that, for all k ≥s for the
values m j, j = j(k), the inequality
M j ≤m j ≤β
(44)
takes place for [x j−1, x j] where β is a ﬁnite number and (39) holds for all
the other intervals, then the point x∗is a limit point of the sequence {xk}.
Corollary 2 Given the conditions of the theorem, all limit points of {xk} are
global minimizers of f (x).

Exact Numerical Differentiation and Global Optimization
241
Corollary 3 If, given the condition of the theorem, (44) holds for all points
x∗∈X∗, then X = X∗.
6
Numerical experiments
In this section, we present results of numerical experiments executed in order
to apply the Local Tuning techniques described above and to compute exact
(recall that the word exact means: up to the machine precision) derivatives for
black-box functions during the work of the algorithms without the necessity
to have a code for evaluating f ′(x). In order to do so we can use the Inﬁnity
Computer and the opportunity offered by Theorem 1.
The ﬁve methods using previously discussed smooth support functions and
Local Tuning techniques were implemented both in the traditional ﬂoating-
point arithmetic and in the Inﬁnity Computing framework. Two classes of
randomly generated test functions have been used to test the methods. Class 1
contains 100 Shekel test functions f (x) (see [50]) where
f (x) = −
10
	
i=1

k2
i (10x −ai)2 + ci
−1 ,
0 ≤x ≤1,
(45)
with randomly generated parameters 1 ≤ki ≤3, 0.1 ≤ci ≤0.3, 0 ≤ai ≤
10, 1 ≤i ≤10.
Class 2 contains functions g(x) = −f (x), where f (x) is from (45). Func-
tions g(x) were randomly generated and chosen in such way that the global
solution x∗from (12) is an internal point of the search region [a, b], i.e.,
x∗̸= a ∧x∗̸= b. In the traditional ﬂoating-point arithmetic, analytical for-
mulae for the ﬁrst derivative have been used providing so exact values of
f ′(x). In the Inﬁnity Computing implementation the derivatives have been
calculated numerically also giving exact values of f ′(x). Both implemen-
tations have given identical results in the numerical experiments described
below conﬁrming so that the Inﬁnity Computing opens very interesting hori-
zons in numerical global optimization in situations where the objective func-
tion is given as a black box and a code for computing derivatives is absent.
Three series of experiments have been executed. For each method the
technical parameter ξ from (25) was set to 10−8. As concerns the ﬁrst two
series, the reliability parameter r1 was obtained starting from the initial value
1.1 and it was increased with step equal to 0.1 until at least the 90% of all
test problems were solved, i.e., the tested algorithm has generated a point xk
after k trials such that |xk −x∗| ≤ε with ε = 10−4 for the ﬁrst series and

242
M. C. Nasso and Y. D. Sergeyev
Fig. 3 Graphs of a function from Class 1 (a) and from Class 2 (b) and trial points
generated by the ﬁve methods during their work
ε = 10−6 for the second series of experiments. For the remaining unsolved
problems the parameter r2 was used. It was obtained starting from r1 and it
was increased with step equal to 0.1 until the remaining problems were all
solved. Figures 3a and 3b show two examples of application of the methods
respectively on a function from Class 1 and on a function from Class 2
together with trial points generated by the ﬁve methods during their work
with these functions.
As the objective functions f (x) are considered to be hard to evaluate,
the number of trials was chosen as the comparison criterion. We reported

Exact Numerical Differentiation and Global Optimization
243
Table 1 Results of numerical experiments with ε = 10−4 on Class 1
Method
r1
AVG 1
Success
(%)
r2
AVG 2
Weighted
AVG
DKC
–
41.32
100
–
–
41.32
DGE
1.1
36.64
92
1.5
56.50
38.23
DML
1.1
34.42
90
1.8
60.80
37.06
DMAL
1.2
29.92
90
2.4
52.90
32.22
DMXL
1.1
26.78
90
2.8
59.20
30.02
in Tables 1, 2, 3 and 4, for each method on both classes, the parameters r1,
the averages of trials (AVG 1) and the percentages of test problems solved
using r1 in the columns 2–4, respectively; the parameters r2, the averages of
trials (AVG 2) to solve the remaining problems and the weighted averages
(Weighted AVG) in the last columns 5–7, where
Weighted AVG = AVG 1 · n1 + AVG 2 · (100 −n1)
100
,
and n1 is the number of problems solved using r1. Best results are shown in
all tables in bold.
As can be seen from Tables 1, 2, 3 and 4, the algorithms DML, DMAL, and
DMXL using the local tuning strategies show the most promising behavior.
Due to this reason, the third series of experiments was carried out with these
three methods only. This series of experiments has been done starting from the
following observation regarding unsolved problems of the ﬁrst two series of
experiments with the parameter r1. It has been realized that the main reason
for the failure was that algorithms did not have enough information about
the local Lipschitz constants during the ﬁrst iterations and used therefore
signiﬁcantly smaller values of the estimates mi w.r.t. the real values causing
a premature stop of the methods after a very small number of iterations being
so an indicator of this abnormal situation.
To overcome this problem, the parameter r = r(k) dependent on the num-
ber of trials k has been chosen. The main idea was to choose a value n ≥2
of trials such that for k ≤n, the parameter r1(k) is relatively high in order
to obtain a sufﬁcient information on the behavior of the objective function,
while for k > n the parameter was stated to the previously tested value, i.e.,

244
M. C. Nasso and Y. D. Sergeyev
Table 2 Results of numerical experiments with ε = 10−4 on Class 2
Method
r1
AVG 1
Success
(%)
r2
AVG 2
Weighted
AVG
DKC
–
237.36
100
–
–
237.36
DGE
1.1
98.72
97
1.3
94.67
98.60
DML
1.1
38.61
96
1.3
31.00
38.31
DMAL
1.1
31.11
95
1.3
38.40
31.47
DMXL
1.3
73.55
95
1.5
74.40
73.59
Table 3 Results of numerical experiments with ε = 10−6 on Class 1
Method
r1
AVG 1
Success
(%)
r2
AVG 2
Weighted
AVG
DKC
–
45.79
100
–
–
45.79
DGE
1.1
40.25
92
1.5
61.13
41.92
DML
1.1
37.39
90
1.8
65.90
40.24
DMAL
1.2
33.37
90
2.4
59.20
35.95
DMXL
1.1
29.82
90
2.8
66.40
33.48
Table 4 Results of numerical experiments with ε = 10−6 on Class 2
Method
r1
AVG 1
Success
(%)
r2
AVG 2
Weighted
AVG
DKC
–
377.24
100
–
–
377.24
DGE
1.1
156.18
97
1.3
158.33
156.24
DML
1.1
41.49
96
1.3
35.00
41.23
DMAL
1.1
34.09
95
1.3
42.60
34.52
DMXL
1.3
115.06
95
1.5
115.40
115.08
r1(k) = 1.1. For the remaining unsolved problems the parameter r2 equal
to the previously used value of r(k), k ≤n, has been taken. Two values,
n = 5 and n = 10, have been applied and the best result was included in
Table 5. The choice of the parameter r1(k) has been done using the values r2
from Table 1, i.e., r1(k) = r2, k ≤n, for all the cases but DMXL on Class 2

Exact Numerical Differentiation and Global Optimization
245
Table 5 Results for the third series of experiments
Method
Class 1
Class 2
DML
DMAL
DMXL
DML
DMAL
DMXL
r1(k) for k ≤n
1.8
2.4
2.8
1.3
1.3
1.7
n
10
10
10
5
5
5
r1(k) for k > n
1.1
1.1
1.1
1.1
1.1
1.1
AVG 1
34.91
28.56
27.12
36.55
29.06
60.06
Success
92%
90%
91%
100%
100%
97%
r2
1.8
2.4
2.8
–
–
1.7
AVG 2
60.00
52.00
58.56
–
–
98.00
Weighted AVG
36.92
30.90
29.95
36.55
29.06
61.20
where r1(k) = r2 + 0.2 has been taken. Accuracy ε = 10−4 was used in all
the experiments. As can be seen from Table 1 and Table 5, using a high
value of the parameter r at the initial iterations improves performance of the
algorithms.
References
1. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
2. Antoniotti, L., Caldarola, F., d’Atri, G., Pellegrini, M.: New approaches to basic
calculus: an experimentation via numerical computation. Lect. Notes Comput. Sci.
11973 LNCS, 329–342 (2020). https://doi.org/10.1007/978-3-030-39081-5_29
3. Antoniotti, L., Caldarola, F., Maiolo, M.: Inﬁnite numerical computing applied to
Hilbert’s, Peano’s, and Moore’s curves. Mediterr. J. Math. 17(3) (2020)
4. Berz,M.:Automaticdifferentiationasnonarchimedeananalysis.In:ComputerArith-
metic and Enclosure Methods, pp. 439–450. Elsevier, Amsterdam (1992)
5. Bischof, C., Bücker, M.: Computing derivatives of computer programs. In: Modern
Methods and Algorithms of Quantum Chemistry Proceedings, NIC Series, vol. 3, 2
edn., pp. 315–327. John von Neumann Institute for Computing, Jülich (2000)
6. Breiman, L., Cutler, A.: A deterministic algorithm for global optimization. Math.
Program. 58(1–3), 179–199 (1993)
7. Caldarola, F.: The Sierpinski curve viewed by numerical computations with inﬁnities
and inﬁnitesimals. Appl. Math. Comput. 318, 321–328 (2018)
8. Calude, C.S., Dumitrescu, M.: Inﬁnitesimal probabilities based on grossone. SN
Comput. Sci. 1(36) (2020)
9. Cohen, J.S.: Computer Algebra and Symbolic Computation: Mathematical Methods.
A K Peters Ltd, Wellesley, MA (1966)

246
M. C. Nasso and Y. D. Sergeyev
10. Corliss, G., Faure, C., Griewank, A., Hascoet, L., Naumann, U. (eds.): Automatic
Differentiation of Algorithms:From Simulation to Optimization. Springer, New York
(2002)
11. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput.
218(16), 8077–8082 (2012)
12. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. Soft Comput. 55, 143–
158 (2020)
13. Daponte, P., Grimaldi, D., Molinaro, A., Sergeyev, Y.D.: An algorithm for ﬁnding
the zero-crossing of time signals with lipschitzean derivatives. Measurement 16(1),
37–49 (1995)
14. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
15. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: Representation of
Grossone-based arithmetic in Simulink and applications to scientiﬁc computing. Soft
Comput. 24, 17525–17539 (2020)
16. Fiaschi, L., Cococcioni, M.: Non-archimedean game theory: a numerical approach.
Appl. Math. Comput. (125356) (2020). https://doi.org/10.1016/j.amc.2020.125356
17. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
18. Gergel, V.P.: A global search algorithm using derivatives. In: Yu I. Neymark (Ed.),
Systems Dynamics and Optimization, pp. 161–178 (1992)
19. Gergel, V.P., Grishagin, V.A., Israﬁlov, R.A.: Local tuning in nested scheme of global
optimization. Procedia Comput. Sci. 51, 865–874 (2015)
20. Grishagin, V.A.: On convergence conditions for a class of global search algorithms.
In: Numerical Methods of Nonlinear Programming, pp. 82–84. KSU, Kharkov
(1979). (In Russian)
21. Grishagin, V.A., Israﬁlov, R.A.: Global search acceleration in the nested optimization
scheme. In: T. Simos, C. Tsitouras (eds.) Proceedings of International Conference
on Numerical Analysis and Applied Mathematics (ICNAAM 2015), vol. 1738, p.
400010. AIP Publishing, NY (2016). https://doi.org/10.1063/1.4952198
22. https://www.numericalinﬁnities.com
23. Iannone, P., Rizza, D., Thoma, A.: Investigating secondary school students’ episte-
mologies through a class activity concerning inﬁnity. In: Bergqvist, E., Österholm,
M., Granberg, C., Sumpter, L. (eds.) Proceedings of the 42nd Conference of the
International Group for the Psychology of Math. Education, vol. 3, pp. 131–138.
PME, Umeå (2018)
24. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation
of higher order Lie derivatives on the Inﬁnity Computer. J. Comput. Appl. Math.
383(113135) (2021)
25. Ingarozza, F., Adamo, M.T., Martino, M., Piscitelli, A.: A grossone-based numerical
model for computations with inﬁnity: a case study in an italian high school. Lect.
Notes Comput. Sci. LNCS 11973, 451–462 (2020). https://doi.org/10.1007/978-3-
030-39081-5_39
26. Iudin, D.I., Sergeyev, Y.D., Hayakawa, M.: Interpretation of percolation in terms of
inﬁnity computations. Appl. Math. Comput. 218(16), 8099–8111 (2012)
27. Kvasov, D.E., Mukhametzhanov, M.S., Nasso, M.C., Sergeyev, Y.D.: On acceleration
of derivative-free univariate Lipschitz global optimization methods. In: Sergeyev,

Exact Numerical Differentiation and Global Optimization
247
Y.D., Kvasov, D. (eds), Numerical Computations: Theory and Algorithms. NUMTA
2019. Lecture Notes in Computer Science, vol. 11974, pp. 413–421. Springer, Cham
(2020)
28. Kvasov, D.E., Sergeyev, Y.D.: A univariate global search working with a set of
Lipschitz constants for the ﬁrst derivative. Optim. Lett. 3(2), 303–318 (2009)
29. Kvasov, D.E., Sergeyev, Y.D.: Lipschitz global optimization methods in control prob-
lems. Autom. Remote Control 74(9), 1435–1448 (2013)
30. Lera, D., Sergeyev, Y.D.: Acceleration of univariate global optimization algorithms
working with Lipschitz functions and Lipschitz ﬁrst derivatives. SIAM J. Optim.
23(1), 508–529 (2013)
31. Lyness, J.N., Moler, C.B.: Numerical differentiation of analytic functions. SIAM J.
Numer. Anal. 4, 202–210 (1967)
32. Margenstern, M.: An application of grossone to the study of a family of tilings of
the hyperbolic plane. Appl. Math. Comput. 218(16), 8005–8018 (2012)
33. Moin, P.: Fundamentals of Engineering Numerical Analysis. Cambridge University
Press, Cambridge (2001)
34. Muller, J.M.: Elementary Functions: Algorithms and Implementation. Birkhäuser,
Boston (2006)
35. Pintér, J.D.: Global Optimization in Action (Continuous and Lipschitz Optimization:
Algorithms, Implementations and Applications). Kluwer Academic Publishers, Dor-
drecht (1996)
36. Piyavskij, S.A.: An algorithm for ﬁnding the absolute extremum of a function. USSR
Comput. Math. Math. Phys. 12(4), 57–67 (1972)
37. Rizza, D.: A study of mathematical determination through Bertrand’s Paradox.
Philosophia Mathematica 26(3), 375–395 (2018)
38. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Unconv.
Comput. 14(2), 139–158 (2019)
39. Sergeyev, Y.D.: A one-dimensional deterministic global minimization algorithm.
Comput. Math. Math. Phys. 35(5), 705–717 (1995)
40. Sergeyev, Y.D.: Global one-dimensional optimization using smooth auxiliary func-
tions. Math. Program. 81(1), 127–146 (1998)
41. Sergeyev, Y.D.: On convergence of “divide the best” global optimization algorithms.
Optimization 44(3), 303–325 (1998)
42. Sergeyev, Y.D.: Arithmetic of Inﬁnity. Edizioni Orizzonti Meridionali, CS , 2nd ed.
(2013)
43. Sergeyev, Y.D.: Computer system for storing inﬁnite, inﬁnitesimal, and ﬁnite quanti-
ties and executing arithmetical operations with them. USA patent 7,860,914 (2010)
44. Sergeyev, Y.D.: Higher order numerical differentiation on the Inﬁnity Computer.
Optim. Lett. 5(4), 575–585 (2011)
45. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
46. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
47. Sergeyev, Y.D., Garro, A.: Observability of Turing machines: a reﬁnement of the
theory of computation. Informatica 21(3), 425–454 (2010)
48. Sergeyev, Y.D., Mukhametzhanov, M.S., Kvasov, D.E., Lera, D.: Derivative-free
local tuning and local improvement techniques embedded in the univariate global
optimization. J. Optim. Theory Appl. 171(1), 186–208 (2016)

248
M. C. Nasso and Y. D. Sergeyev
49. Sergeyev, Y.D., Nasso, M.C., Mukhametzhanov, M.S., Kvasov, D.E.: Novel local
tuning techniques for speeding up one dimensional algorithms in expensive global
optimization using lipschitz derivatives. J. Comput. Appl. Math. 383(113134) (2021)
50. Strongin, R.G., Sergeyev, Y.D.: Global Optimization with Non-convex Constraints:
Sequential and Parallel Algorithms. Kluwer Academic Publishers, Dordrecht (2000)
51. Zhigljavsky, A.: Computing sums of conditionally convergent and divergent series
using the concept of grossone. Appl. Math. Comput. 218(16), 8064–8076 (2012)
52. Žilinskas, A.: On strong homogeneity of two global optimization algorithms based on
statistical models of multimodal objective functions. Appl. Math. Comput. 218(16),
8131–8136 (2012)

Comparing Linear and Spherical
Separation Using Grossone-Based
Numerical Inﬁnities in Classiﬁcation
Problems
Annabella Astorino and Antonio Fuduli
Abstract We investigate the role played by the linear and spherical separa-
tions in binary supervised learning and in Multiple Instance Learning (MIL),
in connection with the use of the grossone-based numerical inﬁnities. While
in the binary supervised learning the objective is to separate two sets of sam-
ples, a binary MIL problem consists in separating two different type of sets
(positive and negative), each of them constituted by a ﬁnite number of sam-
ples. We remind that using the spherical separation in classiﬁcation problems
provides an advantage especially in terms of computational time, since, when
the center of the separating sphere is (judiciously) ﬁxed in advance, the corre-
sponding optimization problem reduces to a structured linear program, easily
solvable by an ad hoc algorithm. In particular, by embedding the grossone
idea, here we analyze the case where the center of the sphere is selected far
from both the two sets, obtaining in this way a kind of linear separation. This
approach is easily extensible to the margin concept (of the type adopted in the
Support Vector Machine technique) and to MIL problems. Some numerical
results are reported on classical binary datasets drawn from the literature.
A. Astorino (B)
Institute for High Performance Computing and Networking (ICAR), National Research
Council, Rende, Italy
e-mail: annabella.astorino@icar.cnr.it
A. Fuduli
Department of Mathematics and Computer Science, University of Calabria, Rende, Italy
e-mail: antonio.fuduli@unical.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_10
249

250
A. Astorino and A. Fuduli
1
Introduction
Classiﬁcation problems in mathematical programming concern separation of
sample sets by means of an appropriate surface. This ﬁeld, entered by many
researchers in optimization community in the last years, is a part of the more
general machine learning area, aimed at providing automated systems able
to learn from human experiences.
The objective of pattern classiﬁcation is to categorize samples into differ-
ent classes on the basis of their similarities. More formally, given a set of
labelled and unlabelled samples, characterized by some features, for each of
them we want to express a particular feature, the class label, as a function of
the remaining ones. This is done by constructing a prediction function, by
means of which we would like to predict the class of each sample. In machine
learning literature many approaches [14] have been indeed devised for auto-
matically distinguishing among different samples on the basis of their pat-
terns: approaches of supervised, unsupervised and semi-supervised learning,
and more recently approaches of Multiple Instance Learning. In particular,
in the supervised case most of the learning models apply the inductive infer-
ence concept, where the prediction function, derived only from the labelled
input data, is used to predict the label of any future object. A well established
supervised technique is the Support Vector Machine (SVM) [33, 58], which
has revealed a powerful classiﬁcation tool in many application areas.
A widely adopted alternative to supervised classiﬁcation is the unsuper-
vised one, where all the objects are unlabelled: as a consequence, in such
case, the prediction function is constructed by clustering the data on the
basis of their similarities [22, 28]. In the middle we ﬁnd the semisupervised
techniques [29], that apply the transductive inference concept: the prediction
function is derived from the information concerning all the available data
(both labelled and unlabelled samples). This function is not aimed at predict-
ing the class label of newly incoming samples, but only at making a decision
about the currently available unlabelled objects. Some useful references are
[5, 30], the latter being a semisupervised version of the SVM technique.
A more recent classiﬁcation framework is constituted by the Multiple
Instance Learning (MIL) [42], whose main difference with respect to the
traditional supervised learning scenario resides in the nature of the learning
samples. In fact, each sample is not represented by a ﬁxed-length vector of
features but by a bag of feature vectors that are referred to as instances. The
classiﬁcation labels are only provided for the entire training bags whereas the
labels of the instances inside them are unknown. The task is to learn a model
that predicts the labels of the new incoming bags, possibly together with the

Comparing Linear and Spherical Separation Using Grossone-Based …
251
labels of the instances inside them. A seminal SVM-type MIL paper is [1],
while some recent articles are [11–13, 15, 17, 21, 24, 40, 49].
In this work, strictly connected with [7], starting from the spherical
binary supervised classiﬁcation approach reported in [16], we introduce
some spherical separation models for both supervised learning and Multiple
Instance Learning. Such models are obtained by embedding the grossone-
based numerical methodology [53], which allows to select the center of the
sphere far from both the two sets (of samples or of bags), providing a kind
of linear separation.
Spherical separation falls into the class of the nonlinear separation surfaces
[10, 14], differently, for example, from the well known supervised learning
SVM technique [33, 58], where a classiﬁer is constructed by generating a
hyperplane far away from the points of the two sets. Also the SVM approach
allows to obtain general nonlinear classiﬁers by adopting kernel transforma-
tions. In this case the basic idea is to map the data into a higher dimensional
space (the feature space) and to separate the two transformed sets by means
of a hyperplane, that corresponds to a nonlinear surface in the original input
space. The main advantage of spherical separation is that, once the center of
the sphere is heuristically ﬁxed in advance, the optimal radius can be found
quite effectively by means of simple sorting algorithms such as those ones
reported in [9, 16]. No analogous simpliﬁcation strategy is apparently avail-
able if one adopts the SVM approach. Moreover, another advantage is to work
directly in the input space. In fact to keep, whenever possible, the data in the
original space seems appealing in order to stay close to the real life modeled
processes. Of course kernel methods are characterized by high ﬂexibility,
even if sometimes they provide results which are hard to be interpreted in the
original input space, differently from the nonlinear classiﬁers acting directly
in such space (see for example [19, 20]).
The chapter is organized in the following way. In the next section we focus
on supervised classiﬁcation, distinguishing between linear and spherical sep-
aration, the latter suitable for grossone application (see [7]). In Sect.3 we dis-
cuss the possibility to extend the grossone spherical separation to Multiple
Instance Learning, while in Sect.4 we comment the numerical results pub-
lished in [7], which conﬁrm the practical applicability of the grossone-based
numerical inﬁnities in classiﬁcation problems. Finally some conclusions are
drawn in Sect.5.

252
A. Astorino and A. Fuduli
2
Linear and Spherical Separability for Supervised
Classiﬁcation
Let
A = {a1, . . . , am},
with ai ∈IRn, i = 1, . . . , m
and
B = {b1, . . . , bk},
with bl ∈IRn, l = 1, . . . , k,
be the two ﬁnite sets of samples (points in IRn). The classical binary classi-
ﬁcation problem consists in discriminating between A and B by means of a
separating surface, obtained by minimizing any classiﬁcation error. Such sur-
face can be a hyperplane (linear separation) or a nonlinear surface, such as a
sphere (spherical separation). A seminal paper on linear separation appeared
in 1965 by Mangasarian [47], while the ﬁrst approach for pattern classiﬁca-
tion based on a minimum volume sphere dates back to 1999 by Tax and Duin
[56].
2.1
Linear Separation
The two sets A and B are linearly separable if and only if there exists a
hyperplane
H(w, γ ) = {x ∈IRn | wT x = γ }, with w ∈IRn and γ ∈IR,
such that
wT ai ≤γ −1
i = 1, . . . , m
and
wT bl ≥γ + 1
l = 1, . . . , k.
A geometrical characterization of linear separability is that A and B are
linearly separable if and only if their convex hulls do not intersect, i.e.
conv(A) ∩conv(B) = ∅,
as depicted in Fig.1, where the two cases of linearly separable and inseparable
sets are considered.
The problem of ﬁnding a separating hyperplane can be formulated as a
linear program [23], but several other approaches have been proposed, such
as the SVM technique [33, 58], where the idea is to generate a separation
hyperplane far away from the objects of both the two sets. This is done by

Comparing Linear and Spherical Separation Using Grossone-Based …
253
Fig. 1 Linear separation: a A and B are separable since conv(A) ∩conv(B) = ∅; b A
and B are not separable since conv(A) ∩conv(B) ̸= ∅
maximizing the margin (i.e. the distance between two parallel hyperplanes
supporting the sets), representing a measure of the generalization capability,
i.e. the ability of the classiﬁer to correctly classify any new sample (see
Fig.2). In particular, from the mathematical point of view, the SVM provides
a separating hyperplane H(w, γ ) by minimizing the following error function:
min
w,γ
1
2∥w∥2 + C
m

i=1
max{0, aT
i w −γ + 1} + C
k

l=1
max{0, −bT
l w + γ + 1},
(1)
where the minimization of ﬁrst term corresponds to the maximization of
the margin, and the last two terms represent the misclassiﬁcation errors in
correspondence to the two point sets A and B, respectively. The parameter
C is a positive constant giving the tradeoff between these two objectives. We
conclude this subsection, reminding that the above nonsmooth minimization
problem can be easily rewritten as a smooth quadratic programming problem.
2.2
Spherical Separation
In the spherical separation the idea is to ﬁnd a sphere
S(x0, R) = {x ∈IRn | ∥x −x0∥2 = R2},

254
A. Astorino and A. Fuduli
Fig. 2 Among all the separating hyperplanes, the SVM approach selects that one with
the largest margin
with center x0 ∈IRn and radius R, enclosing all points of A and no points
of B.
2.2.1
Spherical Separation Without Margin
The set A is spherically separable from the set B if and only if there exists a
sphere S(x0, R) such that
∥ai −x0∥2 ≤R2
i = 1, . . . , m
and
∥bl −x0∥2 ≥R2
l = 1, . . . , k.
We observe that, in this case, the role played by the two sets is not symmet-
ric; in fact a necessary (but not sufﬁcient) condition for the existence of a
separation sphere is the following (see Fig.3):
conv(A) ∩B = ∅.
Based on the above spherical separability deﬁnition, the classiﬁcation error
associated to any sphere S(x0, R) is
m

i=1
max{0, ∥ai −x0∥2 −R2} +
k

l=1
max{0, R2 −∥bl −x0∥2}.

Comparing Linear and Spherical Separation Using Grossone-Based …
255
Fig. 3 Spherical separation of A from B: a A is separable from B and then conv(A) ∩
B = ∅; b A is not separable from B even if conv(A) ∩B = ∅; c A is not separable from
B since conv(A) ∩B ̸= ∅
To take into account the generalization capability, in [16] the authors have
proposed to construct a minimal volume separation sphere by solving the
following problem:
min
x0,z z + C
m

i=1
max{0, ∥ai −x0∥2 −z} + C
k

l=1
max{0, z −∥bl −x0∥2},
(2)
with z
△= R2 ≥0 and C > 0 being the parameter tuning the tradeoff between
the minimization of the volume and the minimization of the classiﬁcation
error.
Some works devoted to spherical separation are [2, 3, 8, 9, 16, 18, 44].
In particular, the approach presented in [16] assumes that the center x0 of the
sphere is ﬁxed (for example, equal to the barycenter of A): in such case it
is easy to see that problem (2) reduces to a univariate, convex, nonsmooth
optimization problem and it is rewritable as a structured linear program,
whose dual can be solved in time O(p log p), where p is the cardinality of
the biggest set between A and B. In fact the optimal value of the variable z
(the square of the radius) is computable by simply comparing the distances,
preliminarly sorted, between the center x0 and each point in the two sets. For
further technical details on such approach we refer the reader directly to [16].
2.2.2
Spherical Separation with Margin
Now we consider a margin spherical separation, where we extend the SVM
concept of margin to the spherical case with the aim at providing a better
quality classiﬁer. In particular the set A is strictly spherically separable from

256
A. Astorino and A. Fuduli
Fig. 4 Strict spherical
separation of A from B
the set B if there exists a sphere S(x0, R) such that
∥ai −x0∥2 ≤(R −M)2,
i = 1, . . . , m
and
∥bl −x0∥2 ≥(R + M)2,
l = 1, . . . , k,
for some margin M, 0 < M ≤R (see Fig.4).
Based on the above deﬁnition, the classiﬁcation error becomes
m

i=1
max{0, ∥ai −x0∥2 −(R −M)2} +
k

l=1
max{0, (R + M)2 −∥bl −x0∥2},
which, by setting z
△= R2 + M2 and q
△= 2RM, can be rewritten as:
m

i=1
max{0, q −z + ∥ai −x0∥2} +
k

l=1
max{0, q + z −∥bl −x0∥2}.
In [9] the authors have proposed to solve the following optimization prob-
lem:
min
x0,0≤q≤z C
⎛
⎝
m

i=1
max{0, q −z + ∥ai −x0∥2} +
k

l=1
max{0, q + z −∥bl −x0∥2}
⎞
⎠−q,

Comparing Linear and Spherical Separation Using Grossone-Based …
257
Fig. 5 A hyperplane can be interpreted as a sphere with an inﬁnitely far center
where the objective of margin maximization is represented by the term −q,
while the tradeoff between classiﬁcation error and margin is accounted by
the positive weighting parameter C.
In case the center x0 of the sphere is given, the above problem reduces
to the minimization of a nonsmooth and convex function [4, 37] in the two
variables z and q. Such problem can be easily put in the form of a structured
linear program, which is solvable by an extended version of the algorithm
presented in [16] (see [9] for the details).
2.3
Comparing Linear and Spherical Separation in the
Grossone Framework
From the mathematical point of view, both the linear and the spherical sepa-
rations are characterized by the same number of variables to be determined:
in fact a separation hyperplane is identiﬁed by the bias and the normal, while
a sphere is obtained by computing the center and the radius. In this perspec-
tive, a hyperplane can be viewed as a particular sphere where the center is
inﬁnitely far (see Fig.5).
Then a possible choice of the center x0 is to take a point far from both the
sets A and B, i.e.
x0 = xA
0 + M

xA
0 −xB
0

,
(3)

258
A. Astorino and A. Fuduli
Fig. 6 Spherical separation with a far center
where
xA
0
△= 1
m
m

i=1
ai
and
xB
0
△= 1
k
k

l=1
bl
are the barycenters of A and B, respectively, while M is a sufﬁciently large
positive parameter, commonly named “big M” (see for example [32]).
Formula (3) corresponds to computing x0 from xA
0 along the direction
xA
0 −xB
0 with stepsize equal to M (see Fig.6).
Noticethat,ingeneral,the“big M”constantisnoteasytobemanagedfrom
the numerical point of view, since indeed it is not evident how to quantify the
minimum threshold value such that M could be considered sufﬁciently big:
as a consequence, in the practical cases, the necessity to test many trial values
arises. A possible way to overcome this numerical difﬁculty is to obtain an
inﬁnitely far center by exploiting the grossone theory [53], setting M equal
to ①, where the symbol ①denotes the new numeral grossone.

Comparing Linear and Spherical Separation Using Grossone-Based …
259
Differently from [16], where various values of M in formula (3) have been
tested in order to obtain a good classiﬁcation performance, a remarkable
advantage in using the grossone resides in avoiding the necessity to repeat
several tests with larger and larger values of M.
We conclude the subsection by highlighting that the new grossone-based
computational methodology, which is not related to the nonstandard analysis
[54], is applied in various ﬁelds, such as in optimization [31, 34–36, 41, 55],
in numerical differentiation [52], in ordinary differential equations [43] and
so on. To the best of our knowledge, it seems that the only machine learning
paper involving the grossone idea is [7]. Finally some more theoretical works
are in logics and philosophy [45, 46, 50], in probability [27] and in fractals
analysis [25, 26].
3
Linear and Spherical Separability for Multiple
Instance Learning
Multiple Instance Learning (MIL) [42] is a machine learning paradigm, con-
sisting in classifying sets of samples: the samples are called instances and
the sets are called bags. The main peculiarity of a MIL problem stays in the
learning phase, where only the labels of the bags are known while the labels
of the instances are unknown.
The ﬁrst MIL paper [38] has appeared in 1997: in such work a drug design
problem has been tackled, with the aim at discriminating between active and
non-active molecules. A drug molecule is active (i.e. it has the desired drug
effect) if one or more of its conformations binds to a particular target site
(typically a larger protein molecule): the peculiarity of the problem is that
it is not known a priori which conformation makes a molecule active, being
available only the label of the overall molecule. In the MIL perspective, each
molecule is a bag and the corresponding conformations are the instances.
We focus on binary MIL problems, aimed at discriminating between pos-
itive and negative bags, in the presence of only two classes of instances. We
adopt the so-called standard MIL assumption (very common in the litera-
ture), stating that a bag is positive if and only if it contains at least a positive
instance and it is negative otherwise.
Since the considerations reported in Sect.2.3 for supervised classiﬁcation
can be extended to MIL, in the sequel we ﬁrst remind the SVM type model
for MIL introduced in [1] and, successively, we propose our modiﬁcation of
such model based on the spherical separation.

260
A. Astorino and A. Fuduli
3.1
The SVM Type Model for MIL
The SVM type model proposed for MIL in [1] provides, in the instance space,
a separating hyperplane H(w, γ ) by solving the following optimization prob-
lem:
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
min
w,γ,y
1
2∥w∥2 + C
m

i=1

j∈J +
i
max{0, y j(xT
j w −γ ) + 1}
+ C
k

l=1

j∈J −
l
max{0, −xT
j w + γ + 1}

j∈J +
i
y j + 1
2
≥1 i = 1, . . . , m
y j ∈{−1, +1}
j ∈J +
i ,
i = 1, . . . , m,
(4)
where m is the number of positive bags indexed by the sets J +
i , i = 1, . . . , m,
k is the number of negative bags indexed by the sets J −
l ,l = 1, . . . , k, x j is the
jth instance belonging to a bag and y j is the class label of the instance x j. The
m constraints involved in the above nonlinear mixed integer program impose
that at least one instance of each positive bag is labelled positively by y j =
+1, i.e. the satisfaction of the standard MIL assumption. A separating MIL
hyperplane is depicted in Fig.7, where the two dashed polygons represent
the positive bags and the three continuous polygons are the negative bags.
Notice that in case each bag is a singleton and y j = 1 for any j, problem
(4) reduces to the classical SVM problem (1).
3.2
A Grossone MIL Spherical Model
In this subsection, in order to embed the grossone framework into the MIL
paradigm, we propose to modify problem (4) by substituting the hyperplane
for a sphere. We obtain the following nonlinear mixed integer optimization
problem:

Comparing Linear and Spherical Separation Using Grossone-Based …
261
Fig. 7 MIL separating hyperplane: two positive bags (dashed polygons) and three neg-
ative bags (continuous polygons). The circles and the squares inside the bags represent
the instances
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
min
x0,R,y R2 + C
m

i=1

j∈J +
i
max{0, y j(∥x j −x0∥2 −R2)}
+ C
k

l=1

j∈J −
l
max{0, R2 −∥x j −x0∥2}

j∈J +
i
y j + 1
2
≥1 i = 1, . . . , m
y j ∈{−1, +1}
j ∈J +
i ,
i = 1, . . . , m.
(5)
According to the concept of spherical separation reported in Sect.2.2.1,
the above model takes into account the standard MIL assumption, which, in
case of a separating sphere, imposes that a bag is positive if at least one of its
instances is inside the sphere and it is negative otherwise (see Fig.8, where
the represented bags are the same as in Fig.7).
A possible approach to solve heuristically problem (5) could be to use
a BDC (Block Coordinate Descent) [57] type algorithm, consisting in the
alternation between the computation of the vector y when the couple (x0, R)
is ﬁxed and, vice-versa, the computation of the couple (x0, R) when y is
ﬁxed. In particular, when y is ﬁxed, x0 could be set by adopting the following
formula (analogous to formula (3), with M substituted by ①):

262
A. Astorino and A. Fuduli
Fig. 8 MIL separating sphere: two positive bags (dashed polygons) and three negative
bags (continuous polygons). The circles and the squares inside the bags represent the
instances
x0 = x+
0 + ①(x+
0 −x−
0 ),
(6)
where x+
0 and x−
0 are the barycenters of the currently positive and negative
instances, respectively. Once y is ﬁxed and x0 is computed by formula (6),
the corresponding optimal radius of the sphere is obtainable by using the ad
hoc algorithm presented in [16].
4
Some Numerical Results
In [7] some numerical experiments have been performed to test the grossone
idea in the supervised spherical separation without margin. In fact the center
of the sphere has been chosen as follows:
x0 = xA
0 + ①

xA
0 −xB
0

,
i.e. by setting M = ①in formula (3).
The code, named in [7] FC①, has been implemented in Matlab and it
has been tested on thirteen data sets drawn from the literature and listed in
Table1.

Comparing Linear and Spherical Separation Using Grossone-Based …
263
Table 1 Data sets
Data set
Dimension
Points
Cancer
9
699
Diagnostic
30
569
Heart
13
297
Pima
9
769
Ionosphere
34
351
Sonar
60
208
Mushrooms
22
8124
Prognosis
32
110
Tic Tac Toe
9
958
Votes
16
435
Galaxy
14
4192
g50c
50
550
g10n
10
550
The ﬁrst ten test problems have been taken from the UCI Machine Learn-
ing Repository [48], a collection of databases, domain theories, and data
generators that are used by the machine learning community. Galaxy is the
data set used in galaxy discrimination with neural networks [51], while an
accurate description of g50c and g10n is reported in [30].
In order to manage the grossone arithmetic operations, the authors have
used the Matlab Environment of the new Simulink-based solution of the
Inﬁnity Computer [39], where an arithmetic C++ library is integrated within
a Matlab environment. In particular, given the two gross-numbers x and y,
from such library the following C++ subroutines have been used:
• TestGrossMatrix(x,y,’-’), returning the difference between x
and y;
• TestGrossMatrix(x,y,’+’), returning the sum of x and y;
• TestGrossMatrix(x,y,’*’), returning the product of x and y;
• GROSS_cmp(x,y), returning 1 if x > y, −1 if x < y and 0 if x = y.
Using the Matlab notation, any vector g of n gross-number elements (that in
the sequel, for the sake of simplicity, we call gross-vector) has been expressed
as a couple (G,fg), with
G = [g1; g2; . . . ; gn]
and
fg = [fg1 fg2 . . . fgn],

264
A. Astorino and A. Fuduli
where gj, j = 1, . . . , n, is an array of appropriate dimension representing
a gross-number. For each row of gj, the ﬁrst element contains a gross-digit,
while the second one contains the corresponding gross-power. The scalar
fgj, j = 1, . . . , n, is necessary to provide the position in G of the last com-
ponent of gj.
To manage the gross-vectors, in [7] the following new Matlab subroutines
have been implemented:
• realToGrossone(r), returning a grossone representation (G,fg) of
a real vector r;
• extract(G,fg,i), returning the ith gross-number in the gross-vector
(G, fg);
• normGrossone(G,fg), computing the squared Euclidean norm of the
gross-vector (G,fg);
• scalProdG(G1,fg1,G2,fg2),computingthescalarproductbetween
the two gross-vectors (G1,fg1) and (G2,fg2);
• BubbleSortGrossone(G,fg,sign), sorting the gross-vector (G,
fg) in the ascending order if sign = 1 and in the descending order if
sign = −1.
For each data set, in order to compute the best value of the parameter C,
a bilevel cross-validation strategy [6] has been adopted, by varying C in the
grid {10−1, 100, 101, 102}: such choice of the grid has been suggested by the
necessity to obtain a nonzero optimal value of z, which in turn provides the
optimal value of the radius R, as shown in [16].
In Table2 we report the results, provided by Algorithm FC①and published
in [7], expressed in terms of average testing correctness. Such results have
been compared by the authors with those ones relative to the two following
ﬁxed-center classical variants, obtained by setting
x0 = xA
0
(Algorithm FCA)
and
x0 = xA
0 + xB
0
(Algorithm FCAB),
respectively, and with the results obtained by a variant of the standard linear
SVM (Algorithm SVM0), where, in order to have a fair comparison, the
margin term has been dropped by setting, in the fitcsvm Matlab subroutine,
the penalty parameter BoxConstraint equal to 106. We recall in fact the
spherical approach implemented in [7] does not involve any margin concept.
In Table2, for each data set, the best result is underlined.
In comparison with FCA and FCAB, the choice of the inﬁnitely far center
appears to be the best one: in fact Algorithm FC①outperforms the other two

Comparing Linear and Spherical Separation Using Grossone-Based …
265
Table 2 Numerical results
Data set
FCA
FCAB
FC①
SVM0
Cancer
97.00
95.71
97.57
71.86
Diagnostic
83.86
53.33
89.65
92.11
Heart
74.33
55.00
87.33
68.67
Pima
69.35
66.23
61.43
61.82
Ionosphere
51.14
40.75
78.86
69.43
Sonar
59.05
52.86
65.71
75.24
Mushrooms
76.44
64.50
78.19
49.59
Prognosis
56.00
45.00
68.00
53.00
Tic Tac Toe
71.79
70.42
57.79
50.11
Votes
82.79
53.35
86.74
76.51
Galaxy
80.24
51.36
89.19
54.32
g50c
67.62
50.26
90.58
86.56
g10n
53.58
45.02
77.66
90.24
approaches on all the data sets except Pima and Tic Tac Toe, where the best
performance is got by ﬁxing x0 as the barycenter of A. We note also that
choosing x0 as the barycenter of all the points is not a good strategy, since
the corresponding results are very poor on all the test problems, but Cancer
and Tic Tac Toe, where the testing correctnesses appear comparable.
Also with respect to SVM0, Algorithm FC①is characterized by a good
performance, except on Diagnostic, Sonar and g10n, while on Pima both the
approaches behave almost the same. These results were expected because,
even if taking the radius inﬁnitely far makes the spherical separability tend
to the linear separability, the two approaches differ substantially. We recall in
fact that, if two sets are linearly separable, they are also spherical separable
(even taking a very large radius), but the vice-versa is not true.
5
Conclusions
In this work we have examined the main differences between linear and
spherical separation in the light of the grossone theory. In particular, we have
recalled the main observations reported in [7] for supervised classiﬁcation,
extendingthemtothecasesofthesupervisedsphericalseparationwithmargin
and of the Multiple Instance Learning.

266
A. Astorino and A. Fuduli
We have focused on the possibility to construct binary spherical classiﬁers
characterized by an inﬁnitely far center. As shown by the preliminary numer-
ical results reported in [7], adopting the grossone theory allows to obtain a
good performance in terms of average testing correctness, managing very
easily the numerical computations, which do not require any tuning of the
“big M” parameter.
Future research could consist in extending such approach to the kernel
trick, which is well suitable in the ﬁxed-center spherical separation, as shown
in [16], and to practically implement the grossone idea for solving MIL
problems.
References
1. Andrews, S., Tsochantaridis, I., Hofmann, T.: Support vector machines for multiple-
instance learning. In: Becker, S., Thrun, S., Obermayer, K. (eds.) Advances in Neural
Information Processing Systems, pp. 561–568. MIT Press, Cambridge (2003)
2. Astorino, A., Bomze, I., Brito, P. Gaudioso, M.: Two spherical separation procedures
via non-smooth convex optimization. In: De Simone, V., Di Seraﬁno, D., Toraldo,
G. (eds.) Recent Advances in Nonlinear Optimization and Equilibrium Problems: A
Tribute to Marco D’Apuzzo, Quaderni di Matematica, Dipartimento di Matematica
della Seconda Universitá di Napoli, vol. 27, pp. 1–16. Aracne (2012)
3. Astorino, A., Bomze, I., Fuduli, A., Gaudioso, M.: Robust spherical separation.
Optimization 66(6), 925–938 (2017)
4. Astorino, A., Frangioni, A., Fuduli, A., Gorgone, E.: A nonmonotone proximal bun-
dle method with (potentially) continuous step decisions. SIAM J. Optim. 23(3),
1784–1809 (2013)
5. Astorino, A., Fuduli, A.: Nonsmooth optimization techniques for semisupervised
classiﬁcation. IEEE Trans. Pattern Anal. Mach. Intell. 29(12), 2135–2142 (2007)
6. Astorino, A., Fuduli, A.: The proximal trajectory algorithm in SVM cross validation.
IEEE Trans. Neural Netw. Learn. Syst. 27(5), 966–977 (2016)
7. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft Comput.
24(23), 17751–17759 (2020)
8. Astorino, A., Fuduli, A., Gaudioso, M.: DC models for spherical separation. J. Global
Optim. 48(4), 657–669 (2010)
9. Astorino, A., Fuduli, A., Gaudioso, M.: Margin maximization in spherical separation.
Comput. Optim. Appl. 53(2), 301–322 (2012)
10. Astorino, A., Fuduli, A., Gaudioso, M.: Nonlinear programming for classiﬁcation
problems in machine learning. In: AIP Conference Proceedings, vol. 1776 (2016)
11. Astorino, A., Fuduli, A., Gaudioso, M.: A Lagrangian relaxation approach for binary
multiple instance classiﬁcation. IEEE Trans. Neural Netw. Learn. Syst. 30(9), 2662–
2671 (2019)
12. Astorino, A., Fuduli, A., Gaudioso, M., Vocaturo, E.: Multiple instance learning
algorithm for medical image classiﬁcation. In: CEUR Workshop Proceedings, vol.
2400 (2019)

Comparing Linear and Spherical Separation Using Grossone-Based …
267
13. Astorino, A., Fuduli, A., Giallombardo, G., Miglionico, G.: SVM-based multiple
instance classiﬁcation via DC optimization. Algorithms 12(12) (2019)
14. Astorino, A., Fuduli, A., Gorgone, E.: Non-smoothness in classiﬁcation problems.
Optim. Methods Softw. 23(5), 675–688 (2008)
15. Astorino, A., Fuduli, A., Veltri, P., Vocaturo, E.: Melanoma detection by means of
multiple instance learning. Interdiscip. Sci.: Comput. Life Sci. 12(1), 24–31 (2020)
16. Astorino,A.,Gaudioso,M.:Aﬁxed-centersphericalseparationalgorithmwithkernel
transformations for classiﬁcation problems. Comput. Manag. Sci. 6(3), 357–372
(2009)
17. Astorino, A., Gaudioso, M., Fuduli, A., Vocaturo, E.: A multiple instance learning
algorithm for color images classiﬁcation. In: ACM International Conference Pro-
ceeding Series, pp. 262–266 (2018). www.scopus.com. Cited By :15
18. Astorino, A., Gaudioso, M., Khalaf, W.: Edge detection by spherical separation.
Comput. Manag. Sci. 11(4), 517–530 (2014)
19. Astorino, A., Gaudioso, M., Seeger, A.: Conic separation of ﬁnite sets. I. The homo-
geneous case. J. Convex Anal. 21 (2014)
20. Astorino, A., Gaudioso, M., Seeger, A.: Conic separation of ﬁnite sets II. The non-
homogeneous case. J. Convex Anal. 21(3), 819–831 (2014)
21. Avolio, M., Fuduli, A.: A semiproximal support vector machine approach for binary
multiple instance learning. IEEE Trans. Neural Netw. Learn. Syst. 32(8), 3566–3577
(2021)
22. Bagirov, A., Karmitsa, N., Taheri, S.: Partitional Clustering via Nonsmooth Opti-
mization. Springer, Berlin (2020)
23. Bennett, K.P., Mangasarian, O.L.: Robust linear programming discrimination of two
linearly inseparable sets. Optim. Methods Softw. 1, 23–34 (1992)
24. Bergeron, C., Moore, G., Zaretzki, J., Breneman, C., Bennett, K.: Fast bundle algo-
rithm for multiple instance learning. IEEE Trans. Pattern Anal. Mach. Intell. 34(6),
1068–1079 (2012)
25. Caldarola, F.: The exact measures of the Sierpinski d-dimensional tetrahedron in
connection with a diophantine nonlinear system. Commun. Nonlinear Sci. Numer.
Simul. 63, 228–238 (2018)
26. Caldarola, F.: The Sierpinski curve viewed by numerical computations with inﬁnities
and inﬁnitesimals. Appl. Math. Comput. 318, 321–328 (2018)
27. Calude, C.S., Dumitrescu, M.: Inﬁnitesimal probabilities based on grossone. SN
Comput. Sci. 1, article number: 36 (2020)
28. Celebi, M.E. (ed.): Partitional Clustering Algorithms. Springer International Pub-
lishing, Berlin (2015)
29. Chapelle, O., Schölkopf, B., Zien, A. (eds.): Semi-supervised learning. MIT Press,
Cambridge (2006)
30. Chapelle, O., Zien, A.: Semi-supervised classiﬁcation by low density separation.
In: Proceedings of the Tenth International Workshop on Artiﬁcial Intelligence and
Statistics, pp. 57–64 (2005)
31. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020)
32. Cococcioni,M.,Fiaschi,L.:TheBig-MmethodwiththenumericalinﬁniteM.Optim.
Lett, 15, 2455–2468 (2021)

268
A. Astorino and A. Fuduli
33. Cristianini, N., Shawe-Taylor, J.: An Introduction to Support Vector Machines and
Other Kernel-based Learning Methods. Cambridge University Press, Cambridge
(2000)
34. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
35. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
36. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
37. Demyanov, A., Fuduli, A., Miglionico, G.: A bundle modiﬁcation strategy for convex
minimization. Eur. J. Oper. Res. 180, 38–47 (2007)
38. Dietterich, T.G., Lathrop, R.H., Lozano-Pérez, T.: Solving the multiple instance
problem with axis-parallel rectangles. Artif. Intell. 89(1–2), 31–71 (1997)
39. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A simulink-based
inﬁnity computer simulator and some applications. In: Sergeyev, Y.D., Kvasov, D.E.
(eds.) Numerical Computations: Theory and Algorithms, pp. 362–369. Springer
International Publishing, Cham (2020)
40. Gaudioso, M., Giallombardo, G., Miglionico, G., Vocaturo, E.: Classiﬁcation in the
multiple instance learning framework via spherical separation. Soft Comput. 24,
5071–5077 (2020). https://doi.org/10.1007/s00500-019-04255-1
41. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals
in a variable metric method for convex nonsmooth optimization. Appl. Math. Com-
put. 318, 312–320 (2018)
42. Herrera, F., Ventura, S., Bello, R., Cornelis, C., Zafra, A., Sánchez-Tarragó, D.,
Vluymans, S.: Multiple Instance Learning: Foundations and Algorithms. Springer
International Publishing, Berlin (2016)
43. Iavernaro, F., Mazzia, F.: Solving ordinary differential equations by generalized
Adams methods: properties and implementation techniques. Appl. Numer. Math.
28(2–4), 107–126 (1998)
44. Le Thi, H.A., Minh, L.H., Pham Dinh, T., Ngai, V.H.: Binary classiﬁcation via
spherical separator by DC programming and DCA. J. Global Optim. 56, 1393–1407
(2013)
45. Lolli, G.: Inﬁnitesimals and inﬁnites in the history of mathematics: a brief survey.
App. Math. Comput. 218(16), 7979–7988 (2012)
46. Lolli, G.: Metamathematical investigations on the theory of grossone. Appl. Math.
Comput. 255, 3–14 (2015)
47. Mangasarian, O.L.: Linear and nonlinear separation of patterns by linear program-
ming. Oper. Res. 13(3), 444–452 (1965)
48. Murphy, P.M., Aha, D.W.: UCI repository of machine learning databases (1992).
www.ics.uci.edu/~mlearn/MLRepository.html
49. Plastria, F., Carrizosa, E., Gordillo, J.: Multi-instance classiﬁcation through spherical
separation and VNS. Comput. & Oper. Res. 52, 326–333 (2014)
50. Rizza, D.: A study of mathematical determination through Bertrand’s Paradox. Phi-
los. Math. 26(3), 375–395 (2018)
51. Odewahn,S.,Stockwell,E.,Pennington,R.,Humphreys,R.,Zumach,W.:Automated
star/galaxy discrimination with neural networks. Astron. J. 103(1), 318–331 (1992)
52. Sergeyev, Y.D.: Higher order numerical differentiation on the inﬁnity computer.
Optim. Lett. 5(4), 575–585 (2011)

Comparing Linear and Spherical Separation Using Grossone-Based …
269
53. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
54. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
55. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: On strong homogeneity of a
class of global optimization algorithms working with inﬁnite and inﬁnitesimal scales.
Comm. Nonlinear Sci. Num. Sim. 59, 319–330 (2018)
56. Tax, D.M.J., Duin, R.P.W.: Data domain description using support vectors. In:
ESANN’1999 proceedings Bruges, pp. 251–256. Belgium (1999)
57. Tseng, P.: Convergence of a block coordinate descent method for nondifferentiable
minimization. J. Optim. Theory App. 109(3), 475–494 (2001)
58. Vapnik, V.: The Nature of the Statistical Learning Theory. Springer, New York (1995)

Computing Optimal Decision
Strategies Using the Inﬁnity
Computer: The Case of
Non-Archimedean Zero-Sum Games
Marco Cococcioni, Lorenzo Fiaschi, and Luca Lambertini
Abstract As is well known, zero-sum games are appropriate instruments for
the analysis of several issues across areas including economics, international
relations and engineering, among others. In particular, the Nash equilibria
of any two-player ﬁnite zero-sum game in mixed-strategies can be found
solving a proper linear programming problem. This chapter investigates and
solvesnon-Archimedeanzero-sumgames,i.e.,gamessatisfyingthezero-sum
property allowing the payoffs to be inﬁnite, ﬁnite and inﬁnitesimal. Since any
zero-sum game is coupled with a linear programming problem, the search
for Nash equilibria of non-Archimedean games requires the optimization of a
non-Archimedean linear programming problem whose peculiarity is to have
the constraints matrix populated by both inﬁnite and inﬁnitesimal numbers.
This fact leads to the implementation of a novel non-Archimedean version of
the Simplex algorithm called Gross-Matrix-Simplex. Four numerical exper-
iments served as test cases to verify the effectiveness and correctness of the
new algorithm. Moreover, these studies helped in stressing the difference
between numerical and symbolic calculations: indeed, the solution output by
the Gross-Matrix Simplex is just an approximation of the true Nash equi-
librium, but it still satisﬁes some properties which resemble the idea of a
non-Archimedean ε-Nash equilibrium. On the contrary, symbolic tools seem
M. Cococcioni (B) · L. Fiaschi
Department of Information Engineering, University of Pisa,
Largo Lucio Lazzarino 1, Pisa, Italy
e-mail: marco.cococcioni@unipi.it
L. Fiaschi
e-mail: lorenzo.ﬁaschi@phd.unipi.it
L. Lambertini
Department of Economics, University of Bologna, Strada Maggiore 45, Bologna, Italy
e-mail: luca.lambertini@unibo.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_11
271

272
M. Cococcioni et al.
to be able to compute the “exact” solution, a fact which happens only on
very simple benchmarks and at the price of its intelligibility. In the general
case, nevertheless, they stuck as soon as the problem becomes a little more
challenging, ending up to be of little help in practice, such as in real time
computations. Some possible applications related to such non-Archimedean
zero-sum games are also discussed.
1
Introduction
Non-Archimedean zero-sum games are a contact point between three dis-
tinct branches of Mathematics, namely Non-Archimedean Analysis (NAA),
Linear Programming (LP) and Game Theory (GT). The former deals with
algebraicstructureslackingoftheArchimedes’property[4, 39],whichmeans
they contain elements that are not ﬁnitely comparable, i.e., their elements are
inﬁnitely large or inﬁnitely small with respect to each other. Two examples
are Sergeyev’s Grossone Methodology (GM) [42] (along with his patented
Inﬁnity Computer [21, 22, 40]) and Robinson’s hyperreal numbers [38]: both
allow one to use numbers which can be inﬁnite, inﬁnitesimal, rather than just
ﬁnite as one may be used to work with.
LP is the well know and deeply studied branch of optimization theory
ﬁrstly introduced by Kantoroviˇc [28] and Dantzig [13]. It consists in the
optimization of linear functions, subject to linear constraints (both equalities
and inequalities) [47]. Moreover, LP has a very well know and strict relation
with GT, i.e., the discipline which models the behaviour of rational agents
within competitive environments, commonly called games [31]. Indicating
with ZG the set of two-person ﬁnite zero-sum games in mixed-strategies
[33], then any game in ZG can be always transformed in an LP problem
[1] whose optima are the Nash equilibria of the original game. In particular,
such optimization task has the game’s payoffs matrix as the constraint matrix
of the problem. The word “ﬁnite” means that the games model competitive
environments where each player is endowed with a ﬁnite number of possible
strategies, the label “zero-sum” refers to the fact that gains in the game are
always exactly balanced by other players’ losses, while “mixed-strategies”
meansthattheplayersadopteachstrategytheyhaveaccordingtoaprobability
distribution.
So far, the GM has been used both in LP and in GT, but separately. The
applicationoftheGMtoLP[7, 8, 16]gavebirthtotheveryﬁrstgeneralization
of the Simplex algorithm to non-Archimedean quantities [6], namely the
Gross-Simplex (G-Simplex in short). It has been the starting point for the

Computing Optimal Decision Strategies Using the Inﬁnity …
273
developing of the Gross-Matrix Simplex used in this chapter [10]. Another
fruitful result from the interaction between GM and LP is an enhancement of
the Big-M method [3, 13, 46], namely the Inﬁnitely-Big-M method (I-Big-
M) [9].
On the other hand, GT mainly leveraged GM to model both non-
Archimedean payoffs (inﬁnite, ﬁnite or inﬁnitesimal) and non-Archimedean
probabilities(ﬁniteorinﬁnitesimal)inthePrisoner’sDilemma[23–25].Other
applications of GM to GT involve games on graphs [11, 12] and inﬁnite
decision-making processes [37]. More broadly, GM has also been success-
fully applied to more general optimization problems ([18, 19, 26, 44]), to
machine learning [2, 5] and to many other ﬁelds.
All in all, this chapter introduces a new algorithm, namely Gross-Matrix-
Simplex (in brief GM-S), able to ﬁnd Nash equilibria of games in NZG, i.e.,
the non-Archimedean extension of ZG. In particular, it is able to cope with
non-Archimedean LP problems also having the constraint matrix and the
unknowns vector ﬁlled with non-Archimedean numbers. The efﬁcacy of the
algorithm is tested on several experiments. Since GM-S outputs an arbitrarily
precise approximation of a true Nash equilibrium of a game, a relevant part
of this chapter is dedicated to study such approximation, to characterize it
and to show its anti-exploitation properties, which resemble those of standard
ε-Nash equilibria. Before continuing, it is important to remark that GM is
independent from non-standard analysis, as shown in [43].
2
Zero-Sum Games
Any game G is typically represented by the triple {N, S, u}, where N =
{1, . . . , n} indicates the set of players which take part to the game. Each
of them has at his/her disposal a set of strategies to adopt, namely Si. The
set S is deﬁned as the Cartesian product of all the players sets of strategies,
i.e., S = n
i=1 Si. Finally, u : S →Rn is the game utility function, where the
entry ui : S →R is the i-th player utility function, which assumes his/her
income provided the strategies implemented by all the participants.
The game-theoretic model which will be generalized to the case of non-
Archimedean quantities is the one of ﬁnite two-person zero-sum game in
mixed-strategies. Formally, a zero-sum game [48] is any game satisfying the
following property:
n

i=1
ui(s) = 0 ∀s ∈S,

274
M. Cococcioni et al.
which means that the total utility experienced by the players altogether is
always zero (whence the zero-sum label). On the other hand, a game is ﬁnite
if the competitive scenario involves agents each having a ﬁnite number of
strategies, i.e.,
|Si| ∈N ∀i ∈N.
Whenever the number of players is ﬁnite too, these games take the name of
matrix games, since they are fully represented by the n-dimensional matrix
A = [u(sk)]k, where k = (k1, . . . , kn), sk = (sk1, . . . , skn), ki ∈{1, . . . ,
|Si|} and ski ∈Si, i = 1, . . . , n. An interesting corner case consists of those
games involving just two players, i.e., n = 2. Their matrix A simpliﬁes a lot,
ending to have the following structure:
A =
⎡
⎢⎣
u(s1
1, s2
1) · · · u(s1
1, s2
|S2|)
...
...
...
u(s1
|S1|, s2
1) · · · u(s1
|S1|, s2
|S2|)
⎤
⎥⎦,
where si
j means the j-th strategy of player i, i.e., s j ∈Si, i = 1, 2. The label
mixed-strategies refers to a game G′ = {N, , h} for which there exists a
game G = {N, S, u} and for which the following equalities are satisﬁed:
Si =
⎧
⎨
⎩δi : Si →[0, 1] :

s∈Si
δi(s) = 1
⎫
⎬
⎭,
 =
n

i=1
Si
δ : S →[0, 1],
δ(s) =
n

i=1
δi(si),
δi ∈Si,
si ∈Si
hi(δ) =

s∈S
ui(s)δ(s),
h = (h1, . . . , hn).
As a result, G′ describes the very same environment of G, but this time each
player can adopt a behavior δi which is a probability distribution over the
strategies, rather than choosing a single one (whence the mixed nature of
their strategies).
The choice of two-player ﬁnite zero-sum games in mixed-strategies is
threefold:
• Finiteness and mixed-strategies guarantee the existence of at least one Nash
equilibrium, as a corollary of the Nikaido-Isoda theorem [32];

Computing Optimal Decision Strategies Using the Inﬁnity …
275
• The presence of two players and the zero-sum property jointly imply that
every Nash equilibrium is at the intersection of minimax (or maximin)
strategies;
• Together, these four properties and their consequences allow one to refor-
mulate the search for Nash equilibria as an LP problem [1].
Let one give a better look to the last dot. The Nash equilibria of games in
ZG are all and only the mixed-strategies x and y which satisfy
min
x∈S1
max
y∈S2
xT Ay = max
y∈S2
min
x∈S1
xT Ay ,
(1)
where A is the game matrix. The primal LP reformulation of (1) is the one
in (2), while the dual is (3).
max λ
s.t. λ1T ≤xT A
xT 1 = 1
x ≥0
(2)
min μ
s.t. Ay ≤μ1
1T y = 1
y ≥0
(3)
where 1 is the vector, of proper dimension, ﬁlled by ones, and λ, μ ∈R.
Both the cases allow a rewriting into the canonical form reported below:
min cT x
s.t. Ax = b
xT 1 = 1
x ≥0
Nash and ε-Nash Equilibria in Numerical Algorithms In most of the
cases, numerical routines implemented to ﬁnd Nash equilibria, e.g. Simplex
algorithm for games in ZG, output just an approximation of them. This is
due to the rounding errors induced by the ﬁniteness of the machine on the
computations, which may be themselves ill-conditioned. Such errors propa-
gate during the algorithm execution and persist in its output, playing a crucial
role from a game theoretical perspective since the result may not form a Nash
equilibrium anymore. This implies that unilateral deviation from that strategy

276
M. Cococcioni et al.
proﬁle may lead to beneﬁts for the deviator. In ﬁnite games however, such a
beneﬁt is bounded, testifying that the approximated strategies form a ε-Nash
equilibrium [35], a relaxed version of the Nash equilibrium.
Originally introduced in [36], ε-Nash equilibria are one of the key ingre-
dients of Proposition 1, which links the deviator beneﬁt bound to the quality
of the optimal strategy approximation.
Deﬁnition 1 (Nash equilibrium) Let G be a two-person zero-sum game and
H(x, y) be the game value function. Then, (x∗, y∗) is said to be a Nash
equilibrium if and only if H(x∗, y) ≤H(x∗, y∗) ≤H(x, y∗) ∀x ∈S1,
y ∈S2.
Deﬁnition 2 (ε-Nash equilibrium) Let G be a two-person zero-sum game
and H(x, y) be the game value function. Then, (x∗, y∗) is said to be an
ε-Nash equilibrium, indicated by (xε, yε), if and only if H(x∗, y) −ε ≤
H(x∗, y∗) ≤H(x, y∗) + ε ∀x ∈S1, y ∈S2, ε ≥0.
Lemma 1 Let G be a ﬁnite two-person zero-sum game and H(x, y) =
xT Ay be the game value function. If (x∗, y∗) is a Nash equilibrium, then
min
i (Ay∗)i = H(x∗, y∗) = max
j (x∗T A) j.
Proof The proof comes straightforwardly from Deﬁnition 1; indeed, if there
exists j such that H(x∗, y∗) < (x∗T A) j, then (x∗, y∗) is no more a Nash
equilibrium. To prove it, let y be the deterministic strategy where y j = 1
if j = j and zero otherwise. Then, it happens that H(x∗, y∗) = x∗T Ay∗<
x∗T Ay = H(x∗, y) ≤max j(x∗T A) j, which is in contrast with the assump-
tion that H(x∗, y∗) is a Nash equilibrium.
Lemma 2 Let x ∈Rn and A ∈Rn×m. Then, max
j (xT A) j ≤||x|| ||Ax||,
where ||Ax|| = sup
u∈Sn ||uT A||.
Proof The following two inequalities are true and prove the lemma:
max
j (xT A) j ≤||xT A|| ≤||x|| ||Ax||. The ﬁrst one holds by construction,
while the second follows from the Cauchy-Schwarz inequality.
Hereinafter, always assume x ∈S1 and y ∈S2. This shall increase the
conciseness and improve the readability of the text.
Deﬁnition 3 (δ-approximating strategy) Let x be an approximation of the
strategy x∗. Then, x is said to δ-approximate x∗, indicated by xδ, if and only
if ||x∗−xδ|| ≤δ
2, δ ∈R+.

Computing Optimal Decision Strategies Using the Inﬁnity …
277
Proposition 1 Let G be a ﬁnite two-person zero-sum game and H(x, y) =
xT Ay be the game value function. Let also (xδ, yδ) be the δ-approximation of
the game Nash equilibrium (x∗, y∗), i.e., ||x∗−xδ|| ≤δ
2 and ||y∗−yδ|| ≤
δ
2. Then, (xδ, yδ) is an ε-Nash equilibrium with ε = δ||A||.
Proof Let x = x∗−xδ and y = y∗−yδ. By construction and applying
Lemma 2 to the last inequality, one has
xT
δ Ayδ ≤max
y
xT
δ Ay = max
j (xT
δ A) j = max
j ((xδ + x −x)T A) j =
= max
j ((x∗−x)T A) j = max
j (x∗T A −T
x A) j ≤max
j (x∗T A) j −min
j (T
x A) j ≤
≤max
j (x∗T A) j + δ
2||A||,
(4)
where ||A|| = max(||A||x, ||A||y). By means of analogous manipulations, it
holds true that
min
i (Ay∗)i −δ
2||A|| ≤min
i (Ayδ)i ≤xT
δ Ayδ.
Leveraging Lemma 1, one can rewrite it as
H(x∗, y∗) −1
2ε ≤min
x
H(x, yδ) ≤H(xδ, yδ) ≤max
y
H(xδ, y) ≤H(x∗, y∗) + 1
2ε,
(5)
having imposed ε = δ||A||. The proof completes using the ﬁrst and last
inequalities of (5), which give
H(x∗, y∗) −1
2ε ≤min
x
H(x, yδ) =⇒H(x∗, y∗) ≤min
x
H(x, yδ) + 1
2ε
max
y
H(xδ, y) ≤H(x∗, y∗) + 1
2ε =⇒max
y
H(xδ, y) −1
2ε ≤H(x∗, y∗)
and plugging them back into (5), respectively at the end and at the beginning
of the inequalities chain, obtaining:
max
y
H(xδ, y) −ε ≤H(xδ, yδ) ≤min
x
H(x, yδ) + ε.
The interpretation of Proposition 1 is the following: in real-world standard
applications, one can arbitrarily approximate the game value H(x∗, y∗),
i.e., up to a certain user-deﬁned tolerance ε by opportunely setting δ in the
optimizingalgorithm(ofcourse,bothε andδ mustbegreaterthanthemachine
precision). Indeed, δ measures the closeness of (xδ, yδ) to the truly optimal
Nash-equilibrium and at the same time it bounds the value of ε. Therefore,

278
M. Cococcioni et al.
when δ approaches zero also ε does, forcing the deviator’s beneﬁt towards
values sufﬁciently small to be considered negligible for practical purposes.
3
Non-Archimedean Zero-Sum Games and the
Gross-Matrix-Simplex Algorithm
A non-Archimedean zero-sum game is a zero-sum game where the payoffs
can assume also inﬁnite and inﬁnitesimal values. A very intuitive method
to represent them within a machine is leveraging Grossone Methodology
[42], where each payoff ˜z, which can be made by different inﬁnite, ﬁnite and
inﬁnitesimal components, is represented as follows:
˜z =

i∈P
zi①i,
(6)
where P ⊂Z is a ﬁnite set of G-powers, zi ∈R ∀i ∈P. As an example, con-
sider the payoff 4①+ 3 −2①−1. One can interpret it as a reward constituted
by three goods ordered by priority, approach which was originally proposed
in [41]. In fact, it represents four units of the most important ware, three of the
second one and a debt of two units of the third one. This is possible because
the value of each good (a ﬁnite number) contributes to the payoff weighted
by a scalar which is inﬁnitely incommensurable with all the others. In the
current case, the ﬁrst and most important commodity has an inﬁnite impact
on the value of the payoff (indeed, it is multiplied by the inﬁnite scalar ①),
the second commodity has a ﬁnite effect (it is multiplied by 1 = ①0), while
the third commodity an inﬁnitesimal one.
Section2 showed that one can ﬁnd at least one Nash equilibrium for each
game in ZG solving the LP problem coupled with it. In case games in NZG
are considered, the LP problems turns into a non-Archimedean one (in brief,
NALP). In literature, there already exists a Simplex-like algorithm able to
deal with certain NALP problems, namely the Gross-Simplex algorithm [6].
It consists of an improved version of the Dantzig’s algorithm enhanced by
means of GM in order to cope with non-Archimedean cost functions. Never-
theless, its implementation is useless in the current context since the NALP
problem associated to games in NZG have the constraints matrix A which
is non-Archimedean.
This fact motivates the implementation of a further generalization of the
Simplex algorithm, namely the Gross-Matrix-Simplex, which is able to solve
such class of NALP and, as a consequence, to output strategy proﬁles which

Computing Optimal Decision Strategies Using the Inﬁnity …
279
Algorithm 1: The Gross-Matrix-Simplex algorithm
Step 0. The user has to provide the initial set B of basic indices.
Step 1. Compute ˜xB as: ˜xB = ˜A−1
B b (where ˜AB is the sub-matrix obtained by ˜A by
considering the columns indexed by B, while ˜A−1
B is the inverse of ˜AB, i.e., the
non-Archimedean matrix which satisﬁes the equality ˜A−1
B ˜AB = ˜AB ˜A−1
B = I).
Step 2. Compute ˜y as: ˜y = cT
B ˜A−1
B (where ˜y is a G-vector obtained by linearly combining
the
purely ﬁnite vector cT
B by the G-scalar elements in the rows of ˜A−1
B ).
Step 3. Compute ˜s as: ˜s=cT
N −˜y ˜AN (where N is the complementary set of B) and then
select the maximum (gradient rule). When this maximum is negative (being it
inﬁnite, ﬁnite or inﬁnitesimal), then the current solution is optimal and the
algorithm stops. Otherwise, the position of the maximum in the G-vector ˜s is the
index k of the entering variable N(k).
Step 4. Compute ˜d as: ˜d = ˜A−1
B ˜AN(k), where ˜AN(k) is the G-vector corresponding to the
N(k)-th column of ˜A.
Step 5. Find the largest G-scalar ˜t > 0 such that ˜xB −˜t ˜d ⩾0. If there is not such a ˜t, then
the problem is unbounded (STOP); otherwise, at least one component of ˜xB −˜t ˜d,
say h,
equals to zero and the corresponding variable is the leaving variable.
Step 6. Update sets B and N by swapping B(h) and N(k), then return to Step 1.
are themselves non-Archimedean. The problem to solve is the following:
min cT ˜x
s.t.
˜A ˜x = b
˜x ≥0
(7)
where ˜A is the G-matrix containing the payoffs, c and b are the (purely ﬁnite)
objective and constant-terms vectors.
Algorithm1 reports the pseudocode of the Gross-Matrix-Simplex. A pos-
teriori, one could have achieved a better coherency if the Gross-Simplex
algorithm would have been named Gross-Cost-Simplex, since it is only able
to handle non-Archimedean cost functions ˜c. The most interesting instruction
Algorithm1 is the computation of the inverse of a non-Archimedean matrix,
which is achieved by means of the Gaussian-Jordan elimination algorithm
tailored to cope with non-Archimedean quantities. A very appealing way to
improve the algorithm is to substitute the explicit computation of the inverse
with an incremental LU factorization. This should lead to better numerical
stability, as it happens in the original Simplex algorithm. A dedicated work
about it seems perfectly reasonable and absolutely promising

280
M. Cococcioni et al.
The next subsection investigates a property similar to Proposition 1 for
games in NZG, i.e., the reliability of numerical solvers for Nash equilibria
in case of non-Archimedean payoffs. Then, the discussion will move to show
the effectiveness of GM-S to solve NALP problems, i.e., to numerically ﬁnd
Nash equilibria of games in NZG. To do this, several test cases are presented,
solved and discussed.
E-Nash Optimality in Non-Archimedean Contexts
Similarly to standard routines, algorithms working with non-Archimedean
numbers suffer from rounding errors the G-digits: for instance, the machine
represents the G-number
1
3①as 0.3333①(where the number of 3s is
architecture-dependent). However, they are afﬂicted by one further source of
inaccuracy: the ﬁnite space for G-scalars components, e.g., a computer cannot
exactlyrepresenttheG-scalar
1
①+1 = 1
①−
1
①2 +
1
①3 + . . . = 
i∈N
(−1)i−1①−i
because it would need an inﬁnite memory. Therefore, it is interesting to inves-
tigate whether the approximated non-Archimedean Nash equilibria found by
numerical routines are somehow related to a non-Archimedean version of
ε-Nash equilibria, as it happens in the standard case (see Sect.2). This time,
the number of G-scalar components the machine is able to store, say k, shall
play a role as well as the rounding G-digits tolerance δ. Proposition 2 for-
mally extends the result in Proposition 1 to the non-Archimedean scenario.
As before, the deﬁnitions of (δ, k)-approximating strategy and (ε, k)-Nash
equilibrium are needed, i.e., the non-Archimedean extension of Deﬁnition 3
and Deﬁnition 2, respectively.
Roughly speaking, the former states that a non-Archimedean strategy ˜x
(δ, k)-approximates ˜x∗if the G-digits of the ﬁrst k components of ||˜x∗−˜x||
(which is a G-scalar) are bounded by a value proportional to δ. Notice that
(δ, k)-approximating strategies are exactly the type of solutions GM-S is
designed to seek for and to output. The notion (ε, k)-Nash equilibrium works
in a very similar way, and Proposition 2 shall prove that they are the type of
Nash equilibrium output by the GM-S algorithm. For the sake of simplicity,
hereinafter assume that || ˜A|| is a ﬁnite number. This fact does not affect
generality since the following scaling is always possible whenever ˜A does
not satisfy it: ˜A ←˜A(|| ˜A||)−1.
Deﬁnition 4 ((δ, k)-approximating strategy) Let ˜x be an approximation of
the non-Archimedean strategy ˜x∗. Then, ˜x is said to be a (δ, k)-approximation
of ˜x∗, indicated by ˜xk
δ , if and only if ||˜x∗−˜x|| = || ˜x|| = 
i∈Z−
0
i①i is such
that |i| < δ
2 ∈R+ ∀i = 0, . . . , 1 −k, k ∈N.
Deﬁnition 5 ((ε, k)-Nash equilibrium) Let G be a ﬁnite non-Archimedean
two-personzero-sumgameand H(˜x, ˜y)bethegamenon-Archimedeanvalue

Computing Optimal Decision Strategies Using the Inﬁnity …
281
function. Also suppose that H(˜x, ˜y) assumes at most ﬁnite values (if not
shrink it so). Then, the feasible strategy proﬁle (˜x∗, ˜y∗) is said to be an (ε, k)-
Nash equilibrium, indicated by (˜x∗, ˜y∗)k
ε, if and only if max
˜y
H(˜x∗, ˜y) −
˜ε ≤H(˜x∗, ˜y∗) ≤min
˜x
H(˜x, ˜y∗) + ˜ε, where ˜ε = 
i∈Z−
0
εi①i ≥0, ε ∈R+
0 and
|εi| ≤ε ∀i = 0, . . . , 1 −k, k ∈N.
Finally, Proposition 2 shows that the strategy proﬁle output by GM-S is
an (ε, k)-Nash equilibrium. This come from the fact that GM-S is designed
to output (δ, k)-approximating strategies, while Proposition 2 links (δ, k)-
approximations of Nash equilibria strategies to the property of being (ε, k)-
Nash equilibria.
Proposition 2 Let G be a ﬁnite non-Archimedean two-person zero-sum game
and ˜A is the non-Archimedean payoff matrix. If all the entries of ˜A have the
form of (6), then any (δ, k)-approximation (˜xk
δ , ˜yk
δ ) of a Nash equilibrium
(˜x∗, ˜y∗) is an (ε, k)-Nash equilibrium.
Proof The result of Eq.(4) holds true until the last inequality even in a non-
Archimedean context, i.e.,
˜xT
δ ˜A ˜yδ ≤max
j (˜x∗T ˜A) j −min
j ( ˜T
x ˜A) j.
To continue with the inequality chain, let one introduce two new G-scalars ˜νk
x
and ˜ν−k
x such that ˜νk
x is the ﬁrst k components of ||˜x∗−˜xk
δ || = || ˜x|| = 
i∈Z−
0
i①i, i.e., ˜νk
x =
1−k

i=0
i①i, while ˜ν−k
x is the remaining components of || ˜x||,
i.e., ˜ν−k
x = || ˜x|| −˜νk
x. Then, Leveraging Lemma 2 (which holds even in a
non-Archimedean context) it holds true that −min
j ( ˜T
x ˜A) j ≤|| ˜x|| ||A|| =
||˜νk
x|| ||A|| + ||˜ν−k
x || ||A|| ≤˜δ
2|| ˜A|| + ||˜ν−k
x || ||A|| = 1
2 ˜εk
x + 1
2 ˜ε−k
x = 1
2 ˜εx,
where ˜δ =
1−k

j=0
δ①j, ˜εk
x = δ|| ˜A||, ˜ε−k
x = 2||˜ν−k
x || ||A||.Finally,deﬁne ˜εy accord-
ingly and set ˜ε = max(˜εx, ˜εy), i.e., ˜ε = ˜εk + ˜ε−k, where ˜εk = ˜εk
x = ˜εk
y and
˜ε−k = max(˜ε−k
x , ˜ε−k
y ). Reasoning similarly to Proposition 1, one obtains:
max
˜y
H(˜xk
δ , ˜y) −˜ε ≤H(˜xk
δ , ˜yk
δ ) ≤min
˜x
H(˜x, ˜yk
δ ) + ˜ε.

282
M. Cococcioni et al.
By deﬁnition, one can rewrite ˜εk as follows:
˜εk =
1−k

h=0
εh①h = ˜δ|| ˜A|| =
1−k

i=0
δ①i
 ⎛
⎝
j∈P
a j①j
⎞
⎠= δ
1−k

i=0

j∈P
a j①i+ j,
εh = δ

(i, j)∈Hh
a j①i+ j ∀h = 0, . . . , 1 −k,
where Hh = {(i, j) ∈{0, . . . , 1 −k} × P | i + j = h}. Of course, Hh =
∅=⇒εh = 0 by construction. In addition, it holds true that
|εh| = δ


(i, j)∈Hh
a j①i+ j ≤δ

(i, j)∈Hh
|a j|①i+ j ≤δ max
h
|Hh| max
j∈P |a j| ≤δk max
j∈P |a j| = ε,
which means that the absolute value of all the G-digits of ˜εk are bounded
by a positive constant depending on δ, similarly to Deﬁnition 5. The proof
completes noticing that, by construction, ˜εk and ˜ε−k are completely separated
from components perspective, i.e., the smallest G-power in ˜εk is greater than
the biggest one in ˜ε−k (which comes from the particular choice of ˜νk
x and ˜ν−k
x ).
This implies that the ﬁrst k components of ˜ε form exactly ˜εk, and therefore
(˜xk
δ , ˜yk
δ ) satisﬁes Deﬁnition 5, i.e., it is an (ε, k)-Nash equilibrium.
In fact, Proposition 2 states a ﬁner the approximation of the optimal strat-
egy proﬁle corresponds with a higher negligiblity of the ﬁrst k components
of the deviation beneﬁt. Notice that nothing can be said about the term ˜ε−k
except that its magnitude is not greater than ①−k, which is reasonable since
the machine representation truncates G-scalars up to the (k-1)-th compo-
nent, i.e., the computations are not aware of the components with magnitude
smaller or equal to ①−k.
4
Numerical Illustrations
This section aims at assess the effectiveness of GM-S algorithm to ﬁnd Nash
equilibria of games in NZG. Furthermore, Sect.4.1 spends some lines to
verify that GM-S outputs are both (δ, k)-approximations and (ε, k)-Nash
equilibria. The majority of the experiments refer to non-Archimedean varia-
tions of the very well known zero-sum game called rock-paper-scissors. The
choice of this model comes from the fact it is simple enough to make its
non-Archimedean modiﬁcations easy to understand and predictable in terms
of Nash equilibria. Table1 reports its canonical form, while its mathematical

Computing Optimal Decision Strategies Using the Inﬁnity …
283
Table 1 Rock-Paper-Scissors canonical form
℘1/℘2
R
P
S
R
0
1
−1
P
−1
0
1
S
1
−1
0
Algorithm 2: Procedure to double-check the results provided by the
GM-S algorithm
step 0. Let (x∗, y∗) be a Nash equilibrium for a given n-dimensional game obtained
somehow
(in our case by GM-S).
Step 1. Indicate with Ax and Ay the index set of active strategies in x∗and y∗,
respectively. This means that i ∈Az ⇔zi > 0, i ∈{1, . . . , n}, z = x, y
Step 2. Deﬁne the active matrix B as the payoff matrix reduced to the row indexes in Ax
and the column indexes in Ay, i.e., B = AAy
Ax .
Step 3. Deﬁne C and D such that Ci = Bi −Bi+1 ∀i = 1, . . . , |Ay| −1 and C|Ay| = 1,
while for D holds true that Di = Bi −Bi+1 ∀i = 1, . . . , |Ax| −1 and D|Ax| = 1.
Step 4. Verify that Cx∗= e and Dy∗= e hold true, where we have indicated with e the last
(under the natural ordering) vector of the canonical base with proper dimension,
i.e., e = (0, . . . , 0, 1)T .
formulation is reported in (8), where A indicates the payoffs matrix whose
content coincides with Table1.
min
x∈1 max
y∈2 xT Ay
(8)
1 = 2 =

(ρ1, ρ2, ρ3) ∈R3 
3

i=1
ρi = 1, ρi ≥0∀i

In this game there exists only one Nash equilibrium,which is shown in Eq.(9):
x∗= y∗=
1
3, 1
3, 1
3

(9)
It is right to say that all the experiments outcomes have been double-checked
verifying that they are basic Nash equilibria [45]. The procedure to do it is
reported in Algorithm2.

284
M. Cococcioni et al.
4.1
Experiment 1: Inﬁnitesimally Perturbed
Rock-paper-scissors
The ﬁrst experiment involves the very same problem of Table1 with one
single payoff inﬁnitesimally perturbed, namely the ˜A2,1 (see Eq.(10)). The
main idea is to check the GM-S algorithm sensibility to inﬁnitesimal changes
in the matrix game. To improve the readability, the inﬁnitesimal components
shall be colored in blue. Since the original problem admits a unique Nash
equilibrium, it is reasonable to expect that the new game’s one is inﬁnitely
close to the former. Table2 reports GM-S iterations executed during the opti-
mization, while Eq.(11) shows the new Nash equilibrium, which conﬁrms
the intuition of inﬁnity closeness. However, GM-S algorithm is able to tell
exactly how much the two are similar (up to the machine precision, of course).
˜A =
⎡
⎣
0
1 −1
−1−①−1
0
1
1
−1
0
⎤
⎦
(10)
˜xk
δ =
⎡
⎣
1
31
3 −1
9①−1 + 1
27①−2
1
3 +1
9①−1 −1
27①−2
⎤
⎦,
˜yk
δ =
⎡
⎣
1
3 −1
9①−1 + 1
27①−2
1
31
3 +1
9①−1 −1
27①−2
⎤
⎦
(11)
The reason why in Table2 the cost function starts from an inﬁnite value
and the length of vector ˜x is larger than expected is due to the use of I-Big-M
method [9] as wrapper for the GM-S solver. It provides an easy way to retrieve
a feasible starting basis adding a set of artiﬁcial variables to the problem and
inﬁnitely penalizing them by the term ①in the cost function (as pioneered
in [16, 17]). The fact that at the end of the optimization the cost function has
a ﬁnite value means that all the artiﬁcial variables have exited the basis and
the solution is a feasible one.
Finally,letoneverifythatthe(δ, 3)-approximatingstrategyproﬁle(˜xk
δ , ˜yk
δ )
is really an (ε, 3)-Nash equilibrium. Theoretically, the strategy pair (˜xk
δ , ˜yk
δ )
approximates the Nash equilibrium (˜x∗, ˜y∗) deﬁned as
˜x∗=

1
3,
①
3①+1,
3①+2
3(3①+1)
T
,
˜y∗=
 ①
3①+1, 1
3,
3①+2
3(3①+1)
T
.
Expanding the second entry of ˜x∗one gets
①
3①+1 = 
i∈Z−
0
1
3(−3)−i ①i = 1
3 −
1
9①−1 +

Computing Optimal Decision Strategies Using the Inﬁnity …
285
Table 2 GM-S iterations for Game 1 of Eq.(10): inﬁnitesimally perturbed rock-paper-scissors game
It.
Base
˜x
cT ˜x
1
{4, 5, 6}

0, 0, 0, 1
3 , 1
3 , 1
3 , 0, 0, 0
 
−①
2
{2, 5, 6}

0, 1
4 −1
8 ①−1 + 1
16 ①−2, 0, 0, 1
4 + 1
8 ①−1 −1
16 ①−2, 1
2 , 0, 0, 0

−3
4 ①−3
8 + 3
16 ①−1 −1
16 ①−2
3
{2, 3, 6}

0, 1
3 −1
9 ①−1 + 1
27 ①−2, 1
6 + 1
9 ①−1 −1
27 ①−2, 0, 0, 1
2 , 0, 0, 0

−1
2 ①−1
2
4
{2, 3, 1}

1
3 , 1
3 −1
9 ①−1 + 1
27 ①−2, 1
3 + 1
9 ①−1 −1
27 ①−2, 0, 0, 0, 0, 0, 0

−1

286
M. Cococcioni et al.
1
27①−2 −1
81①−3 + . . ., which becomes exactly the second entry of ˜xk
δ when
it is truncated up to the second inﬁnitesimal component (k = 3). Repeating
the same operation with all the other entries, the fact that ˜xk
δ and ˜yk
δ are
(δ, 3)-approximations of ˜x∗and ˜y∗is veriﬁed. Then, Proposition 2 states
that if (˜xk
δ , ˜yk
δ ) is a (ε, 3)-Nash equilibrium, then it must hold true that
|H(˜xk
δ , ˜yk
δ ) −min
˜x (˜x, ˜yk
δ )| ≤˜ε = ˜εk + ˜ε−k = ˜ε−k < M①−k, with M ∈R+
sufﬁciently big (the last equality comes from the fact that δ = 0). The
game value associated to (11) is H(˜xk
δ , ˜yk
δ ) =
−5

i=−1
1
3(−3)−i ①i, while the
row player optimal strategy as answer to ˜yk
δ isx = [0, 1, 0]T , which leads
to H(x, ˜yk
δ ) = −1
9①−1 + 1
27①−2 −1
27①−3. Therefore, the deviation beneﬁt
is |H(˜xk
δ , ˜yk
δ ) −H(x, ˜yk
δ )| = 2
81①−3 +
1
243①−4 −
1
729①−5 = ε−k < M①−3
for M > 2
81. This means that (˜xk
δ , ˜yk
δ ) is a (ε, 3)-Nash equilibrium since
˜εk is negligible and ˜ε−k has magnitude not greater than ①−3 (provided
that the same veriﬁcation is done for column player as deviator, study
which is omitted for brevity). In addition, notice how close the approx-
imation of H(˜xk
δ , ˜yk
δ ) to H(˜x∗, ˜y∗) is. Since H(˜x∗, ˜y∗) = −
1
3(3①+1) =

i∈Z−
1
3(−3)−i ①i = −1
9①−1 + 1
27①−2 −1
81①−3 + . . ., we have |H(˜x∗, ˜y∗) −
H(˜xk
δ , ˜yk
δ )| = | 
i∈Z
i<−5
1
3(−3)−i ①i|: the game value is well approximated up to
the ﬁfth order of inﬁnitesimal.
4.2
Experiment 2: A Purely Finite 4-by-3 Game
In games where more than one Nash equilibrium exists, even an inﬁnitesimal
perturbation can signiﬁcantly affect the optimal strategy choice. For instance,
consider the game in Eq.(12) which is built adding one strategy for the row
player to the rock-paper-scissors of Table8. The crucial aspect is that the
new game has inﬁnitely many Nash equilibria, without any further criterion
by means of which to choose among them. Therefore, the choice of which
mixed-strategy to play depends only on the actual implementation of the
decision making algorithm, e.g., the Simplex algorithm.

Computing Optimal Decision Strategies Using the Inﬁnity …
287
Table 3 GM-S iterations for the purely ﬁnite Game 2 of Eq.(12)
It.
Base
˜x
cT ˜x
1
{5, 6, 7}

0, 0, 0, 0, 1
3, 1
3, 1
3, 0, 0, 0
 
−①
2
{5, 6, 1}
 1
4, 0, 0, 0, 1
4, 1
2, 0, 0, 0, 0
 
−3
4①−1
4
3
{2, 6, 1}
 1
3, 1
6, 0, 0, 0, 1
2, 0, 0, 0, 0
 
−1
2①−1
2
4
{2, 3, 1}
 1
3, 1
3, 1
3, 0, 0, 0, 0, 0, 0, 0
 
−1
A =
⎡
⎢⎢⎣
0
1 −1
−1
0
1
1 −1
0
1
2 −1
1
2
⎤
⎥⎥⎦
(12)
Table3 reports the iterations of GM-S algorithm running on the degenerate
problem (12). The routine suggests that the row-player adopts the strategy
xk
δ = [1
3, 1
3, 1
3, 0]T , which is essentially the same as in the original game (9),
i.e., x∗= [1
3, 1
3, 1
3]T . To improve the readability, the optimal strategies have
been reported as fractions. Next subsection shall show that an inﬁnitesimal
perturbation of these payoffs causes a ﬁnite change on the equilibrium rather
than an inﬁnitesimal one.
4.3
Experiment 3: Inﬁnitesimally Perturbed 4-by-3 Game
Assume now that a secondary information to better discriminate among the
inﬁnite Nash equilibria in (12) is available. It consists of a second payoff
matrix As whose importance is subordinated to the one of Eq.(12):
As =
⎡
⎢⎢⎣
0
2 −2
−2
0
2
2 −2
0
−1 −2
1
⎤
⎥⎥⎦
As discussed at the beginning of Sect.3 and shown in Eq.(6), the two sources
of information can be eventually merged without losing the priority informa-
tion by means of GM. In particular, a new non-Archimedean zero-sum game
is built summing the payoffs entry-wise and scaling down the ones having

288
M. Cococcioni et al.
lesser priority by the ①−1, i.e., the new payoff matrix ˜A is obtained as
˜A = A + As①−1,
which in fact means
˜A =
⎡
⎢⎢⎢⎣
0
1 +2①−1 −1 −2①−1
−1 −2①−1
0
1 +2①−1
1 +2①−1 −1 −2①−1
0
1
2 −①−1 −1 −2①−1
1
2 +①−1
⎤
⎥⎥⎥⎦.
(13)
The overall game is now a non-Archimedean one, falling in the set NZG,
since ˜A is non-Archimedean.
In the face of the inﬁnitesimal perturbation on the payoffs matrix induced
by the secondary information, the result is all but negligible. As opposed to
the problem in Table1, there exist inﬁnitely many Nash equilibria in (12).
This means that the presence of a secondary payoffs in As informs the opti-
mization algorithm of an additional discriminating rule to better single out
the most preferable Nash equilibria. More importantly, the equilibrium found
in Table3 may not be optimal also with respect to the secondary informa-
tion, while all those the strategy proﬁles which are may notably differ from
it. This is the case of problem in (13), as testiﬁed by Tables4 and 5 which
report the GM-S algorithm iterations computed to solve it for the row and
the column-player, respectively.
The new equilibrium is:
˜x∗
δ =
⎡
⎢⎢⎣
2
5 + 4
75①−1 −16
25①−2
1
5 −28
75①−1 + 56
125①−2
0
2
5 + 8
25①−1 −28
125①−2
⎤
⎥⎥⎦,
˜y∗
δ =
⎡
⎣
1
3 + 4
15①−1 −8
25①−2
1
3 −4
15①−1 + 8
25①−2
1
3
⎤
⎦. (14)
Observe how its ﬁnite part has changed from xk
δ = [1
3, 1
3, 1
3, 0]T of the pre-
vious equilibrium to xk
δ = [2
5, 1
5, 0, 2
5]T of the current one.

Computing Optimal Decision Strategies Using the Inﬁnity …
289
Table 4 GM-S iterations for Game 3 of Eq.(13): row-player
It.
Base
˜x
cT ˜x
1 {5, 6, 7}

0, 0, 0, 0, 1
3 , 1
3 , 1
3 , 0, 0, 0

−①
2 {5, 4, 7}

0, 0, 0, 1
4 −1
4 ①−1 + 1
4 ①−2, 3
8 −1
8 ①−1 + 1
8 ①−2, 0, 3
8 + 3
8 ①−1 −3
8 ①−2, 0, 0, 0

−3
4 ①−1
2 + 1
2 ①−1 −1
4 ①−2
3 {5, 4, 1}
 3
10 + 3
50 ①−1 +
3
250 ①−2, 0, 0, 2
5 + 2
25 ①−1 +
2
125 ①−2,
3
10 −7
50 ①−1 −
7
250 ①−2, 0, 0, 0, 0, 0

−3
10 ①−14
25 −14
125 ①−1 −
3
250 ①−2
4 {2, 4, 1}
 2
5 + 4
75 ①−1 −16
25 ①−2, 1
5 −28
75 ①−1 + 56
125 ①−2, 0, 2
5 + 8
25 ①−1 −48
125 ①−2, 0, 0, 0, 0, 0, 0

−1
Table 5 GM-S iterations for Game 3 of Eq.(13): column-player
It.
Base
˜y
cT ˜y
1
{4, 5, 6, 7}

0, 0, 0, 1
4 , 1
4 , 1
4 , 1
4 , 0, 0, 0, 0

−①
2
{4, 3, 6, 7}

0, 0, 2
9 −17
5 ①−1 + 27
50 ①−2, 4
9 + 1
5 ①−1 −31
100 ①−2, 0, 2
9 + 1
10 ①−1 −3
20 ①−2, 1
9 + 1
25 ①−1 −2
25 ①−2, 0, 0, 0, 0

−7
9 ①+ 253
450 + 394
100 ①−1 −27
50 ①−2
3
{4, 3, 6, 1}
 1
10 + 1
25 ①−1 −
8
125 ①−2, 0,
3
10 −7
25 ①−1 + 56
125 ①−2, 1
2 + 2
5 ①−1 −6
25 ①−2, 0,
1
10 −4
25 ①−1 −18
125 ①−2, 0, 0, 0, 0, 0

−3
5 ①−16
25 + 78
125 ①−1 −48
125 ①−2
4
{4, 3, 2, 1}
 1
3 −4
3 ①−1 + 16
3 ①−2, 1
3 −8
3 ①−1 + 40
3 ①−2, 1
3 −8
3 ①−2, 4①−1 −16①−2, 0, 0, 0, 0, 0, 0, 0

−5 +20①−1 −16①−2
5
{7, 3, 2, 1}
 1
3 −2
9 ①−1 + 4
27 ①−2, 1
3 −2
9 ①−1 + 4
27 ①−2, 1
3 −2
9 ①−1 + 4
27 ①−2, 0, 0, 0,
2
3 ①−1 −4
9 ①−2, 0, 0, 0, 0

−5
3 + 10
9 ①−1 −4
9 ①−2
6 {10, 3, 2, 1}
 1
3 −8
15 ①−2, 1
3 −8
15 ①−1 + 8
15 ①−2, 1
3 −8
39 ①−1, 0, 0, 0, 0, 0, 0,
4
5 ①−1, 0

−1 + 4
5 ①−1

290
M. Cococcioni et al.
Fig. 1 First entry of x∗after symbolic computations in Mathematica (g here stands for
①). Please observe how the provided solution is very difﬁcult to read
4.4
Experiment 4: High Dimensional Games
This experiment aims at challenging GM-S algorithm on high-dimensional
games, comparing the efﬁcacy with symbolic approaches one. The ﬁrst test
case is not a true high-dimensional game since it involves only 8 strategies
per player. However, it is still a signiﬁcant experiment since it already allows
one to stress the limits of symbolic tools, such as Mathematica, which start
to struggle even in this relatively low dimensional scenario. When game
complexity grows, the gap between numerical and symbolic algorithms efﬁ-
cacy becomes more and more evident. The main reason is that, considering
games in NZG, symbolic tools search for Nash equilibria repeatedly apply-
ing Algorithm2 with randomly chosen active strategies, as stated in [45],
which is an unpractical and combinatorial NP-hard task. Moreover, when
found, the Nash equilibrium readability would probably be quite low, as
stressed by Fig.1 which reports the ﬁrst entry of the row player optimal strat-
egy computed in Mathematica (the letter g stands for ①). On the other hand,
the numerical GM-S algorithm is able to show the approximated equilibrium
components in a very interpretable way, e.g., Eq.(15) where the entire solu-
tion of the 8 × 8 problem is shown. The payoff matrix and GM-S iterations
can be found in the appendix of [10].

Computing Optimal Decision Strategies Using the Inﬁnity …
291
˜x∗
δ =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0.18 −0.36①−1 + 1.05①−2
0.15 +0.01①−1 −1.96①−2
0.26 −0.66①−1 + 1.34①−2
0
0.22 +0.3①−1 + 2.09①−2
0.08 +0.36①−1 −0.95①−2
0.11 +0.34①−1 −1.57①−2
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
˜y∗
δ =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0.01 +0.54①−1 + 3.12①−2
0.14 −0.15①−1 −1.03①−2
0
0.21 +0.37①−1 + 2.71①−2
0.27 +0.34①−1 −0.81①−2
0
0.1 −0.81①−1 −2.19①−2
0.27 −0.29①−1 −1.8①−2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(15)
Considering a game with a 10 × 10 payoff matrix instead, the symbolic
tool struggles a lot in computing the game solution and its execution time
grows drastically, passing from 1.28s of the 8 × 8 game to 6.98. To stress
even more this fact, a true high-dimensional non-Archimedean zero-sum
game has been considered. This time, each player can choose among 60
different strategies, and the game has 5 levels of priority information, i.e.,
60 × 60 payoff matrix is ﬁlled by random G-scalars having 4 inﬁnitesimal
components. While Mathematica does not output the result in a reasonable
amount of time for practical purposes, GM-S took only 122.487s to compute
the Nash Equilibrium, a quite remarkable result. For the sake of brevity, the
matrix and the associated Nash equilibrium for both the 10 × 10 and 60 × 60
games are omitted.
5
A Brief Overview of Applications
As in [10], to which we refer the reader interested in a more detailed illus-
tration, also here we offer a compact perspective of the models and ﬁelds
which plausibly feature the non-Archimedean zero-sum property. Whenever
the latter is identiﬁed, the game under examination can be treated using GM
and of course the GM-S algorithm.
The ﬁrst example has a dual nature, depending on whether players are
ﬁrms or political parties, and is traditionally known as the Hotelling/Downs
game of spatial competition [20, 27].
In both cases, players are supposed to choose their respective locations
along a ﬁnite linear segment along which consumers or voters are distributed.
In absence of a price mechanism, this can describe the choice of electoral
platforms, with parties trying to acquire political consensus. In such a case
the game has a zero-sum nature because any additional vote gained by a party
is lost by the other (leaving aside any degree of abstention), and the model
naturally lends itself to a non-Archimedean interpretation.

292
M. Cococcioni et al.
Ifinsteadthegamefeaturesapricestageappearingafterthelocationchoice
and prices are strategically set by ﬁrms, the game is no longer a zero-sum
one. Yet, it becomes so if prices are regulated, in which case ﬁrms’ proﬁts
depend solely on locations and the resulting relative size of market shares. It
is also worth stressing that in such a case the Hotelling version of the model
is observationally equivalent to Downs’s.
This example is particularly relevant as it concerns a game which simulta-
neously belongs to the backbone of large literatures in industrial economics
and politics. But several other non-Archimedean zero-sum games can be
ﬁgured out.
For instance, another setting which has a twofold interpretation is that in
which an entrepreneur owning a ﬁrm in dire straits is forced to sell it but
maintains a symbolic amount of share and the family name on the gate of
the production plant. From a realistic point of view, this payoff may look
almost immaterial, but this does not correspond to the original owner’s per-
ception. The same applies to a seemingly different scenario in which we
may just replace property with sovereignty. This holds for very small States
surrounded by larger ones and embedded in fully integrated regions like the
EU (think of Montecarlo, Liechtenstein, Andorra and San Marino). Political
independence, accompanied by economic integration, may still matter a lot,
although these Countries are net importers and, say, their basketball or foot-
ball clubs may happen to play in the leagues of larger European Countries.
One additional example relies on [34] and is also connected to Patrolling
games. Here, the matter is about construction operation purposes. The non-
Archimedean property arises if the quality criteria adopted to decide which
project to pursue are deﬁned in binary terms, in such a way that the presence
of any relevant component (say, ﬁre escapes) is valued 1 while its absence is
valued 0.
6
Conclusions
The chapter introduced for the ﬁrst time the non-Archimedean zero-sum
games and a numerical algorithm able to compute approximations of their
Nash equilibria, namely the GM-S algorithm. A lot of attention has been
dedicated to characterized the type of strategy proﬁle the algorithm is able
to output, showing a strong correlation with the standard ε-Nash equilib-
rium. Both the algorithm implementation and the theoretical study leveraged
Grossone Methodology to better reason about non-Archimedean quantities
as well as execute numerical non-Archimedean operations. The chapter also

Computing Optimal Decision Strategies Using the Inﬁnity …
293
illustrated several test cases, some of which high-dimensional, to verify the
effectiveness of GM-S algorithm and to highlight the limits of symbolic tools.
All the computations run over an Inﬁnity Computer simulator implemented
in software. Finally, Some possible real-world applications of this new mod-
eling tool have been presented and discussed. It is right to say that such
results would not be obtained without the previous achievements in non-
Archimedean linear programming [6, 7, 9] and non-Archimedean Prisoner’s
Dilemmas [23–25].
References
1. Adler, I.: The equivalence of linear programs and zero-sum games. Int. J. Game
Theory 42, 165–177 (2013). Springer
2. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft. Com-
put. 24(23), 17751–17759 (2020)
3. Bazaraa, M. S., Jarvis, J. J., Sherali, H. D.: Linear Programming and Network Flows.
Wiley (1990)
4. Bosch, S., Güntzer, U., Remmert, R.: Non-Archimedean Analysis: A Systematic
Approach to Rigid Analytic Geometry. Springer, Berlin, Heidelberg (2012)
5. Cavoretto, R., De Rossi, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: On the search
of the shape parameter in radial basis functions using univariate global optimization
methods. J. Global Optim. 79(2), 305–327 (2021)
6. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: Theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018)
7. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Grossone Methodol-
ogy for Lexicographic Mixed-Integer Linear Programming Problems. In: Sergeyev,
Y.D.,KvasovD.E.(eds)NumericalComputations:TheoryandAlgorithms.NUMTA
2019. Springer Lecture Notes in Computer Science, vol. 11974, pp. 337–345 (2020)
8. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020)
9. Cococcioni, M., Fiaschi, L.: The Big-M method with the numerical inﬁnite M.
Optim. Lett. 15, 2455–2468 (2021). https://doi.org/10.1007/s11590-020-01644-6
10. Cococcioni, M., Fiaschi, L., Lambertini, L.: Non-Archimedean zero-sum games. J.
Comput. Appl. Math. 393, 113483 (2021)
11. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. In: Sergeyev, Y.D.,
Kvasov D.E. (eds) Numerical Computations: Theory and Algorithms. NUMTA
2019. Springer Lecture Notes in Computer Science, vol. 11974, pp. 346–353 (2020)
12. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. Soft. Comput. 24,
17509–17515 (2020)
13. Dantzig, G.B.: Programming in a Linear Structure. United Air Force, Washington,
D.C. (1948)
14. Dantzig, G.B., Thapa, M.N.: Linear Programming 1: Introduction. Springer, New
York (1997)

294
M. Cococcioni et al.
15. Dantzig, G.B., Thapa, M.N.: Linear Programming 2: Theory and Extensions.
Springer, New York (2003)
16. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming
and operations research. Appl. Math. Comput. 218, 8029–8038 (2021)
17. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft. Comput. 24(23), 17669–917677 (2020)
18. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based com-
putation of negative curvature directions in large-scale optimization. J. Optim. The-
ory Appl. 186(2), 554–589 (2020)
19. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
20. Downs, A.: An Economic Theory of Democracy. Harper and Row (1957)
21. Falcone, A., Garro, A., Mukhametzhanov, M.S.S., Sergeyev, Y.D.: Representation
of grossone-based arithmetic in simulink for scientiﬁc computing. Soft. Comput.
24, 17525–17539 (2020)
22. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A Simulink-based
software solution using the Inﬁnity Computer methodology for higher order differ-
entiation. Appl. Math. Comput. 409, 125606 (2021)
23. Fiaschi, L., Cococcioni, M.: Numerical asymptotic results in game theory using
Sergeyev’s arithmetic of inﬁnity. Int. J. Unconvent. Comput. 14, 1–25 (2018)
24. Fiaschi, L., Cococcioni, M.: Generalizing pure and impure iterated prisoner’s
dilemmas to the case of inﬁnite and inﬁnitesimal quantities. In: Sergeyev, Y.D.,
Kvasov D.E. (eds) Numerical Computations: Theory and Algorithms. NUMTA
2019. Springer Lecture Notes in Computer Science, vol. 11974, pp. 370–377 (2020)
25. Fiaschi, L., Cococcioni, M.: Non-Archimedean Game Theory: A Numerical
Approach. Appl. Math. Comput. 125356 (2020)
26. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.: Numerical inﬁnitesimals in
a variable metric method for convex nonsmooth optimization. Appl. Math. Comput.
318, 312–320 (2018)
27. Hotelling, H.: Stability in Competition. Econ. J. 39, 41–57 (1929)
28. Kantoroviˇc, L.V.: Mathematical methods of organizing and planning production.
Publication House of the Leningrad State University (1939)
29. Levi-Civita, T.: Sugli inﬁniti ed inﬁnitesimi attuali, quali elementi analitici. Tip.
Ferrari (1893)
30. Levi-Civita, T.: Sui numeri transﬁniti. Tipograﬁa della R, Accademia dei Lincei
(1898)
31. Myerson, R.B.: Game Theory. Harvard University Press (2013)
32. Nikaidô, H., Isoda, K.: Note on non-cooperative convex games. Pac. J. Math. 5,
807–815 (1955)
33. Owen, G.: Game Theory. Academic (1995)
34. Peldschus, F.: Experience of the game theory application in construction manage-
ment. Technol. Econ. Dev. Econ. 14, 531–545 (2008)
35. Petrosyan, L.A., Zenkevich, N.A.: Game Theory. World Scientiﬁc Publishing Co.
Pte. Ltd., 9824 (2016)
36. Radner, R.: Collusive behavior in noncooperative epsilon-equilibria of oligopolies
with long but ﬁnite lives. J. Econ. Theory 22, 136–154 (1980)
37. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Unconv.
Comput. 14, 139–158 (2019)

Computing Optimal Decision Strategies Using the Inﬁnity …
295
38. Robinson, A.: Non-standard Analysis. Princeton University Press (2016)
39. Schneider, P.: Nonarchimedean Functional Analysis. Springer Science & Business
Media (2013)
40. Sergeyev, Y.D.: Computer system for storing inﬁnite, inﬁnitesimal, and ﬁnite quan-
tities and executing arithmetical operations with them. USA patent 7,860,914 (2010)
41. Sergeyev, Y.D.: The Olympic Medals Ranks, lexicographic ordering and numerical
inﬁnities. Math. Intell. 37, 4–8 (2015)
42. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4, 219–320 (2017)
43. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from
non-standard analysis and comments upon logical fallacies in some texts asserting
the opposite. Found. Sci. 24, 153–170 (2019)
44. Sergeyev, Y.D., Nasso, M.C., Mukhametzhanov, M.S., Kvasov, D.: Novel local tun-
ing techniques for speeding up one-dimensional algorithms in expensive global opti-
mization using Lipschitz derivatives. J. Comput. Appl. Math. 383, 113134 (2021)
45. Shapley, L.S., Snow, R.N.: Basic Solutions of Discrete Games. Ann. Math. Stud.
(1950)
46. Soleimani-Damaneh, M.: Modiﬁed Big-M method to recognize the infeasibility of
linear programming models. Knowl.-Based Syst. 21, 377–382 (2008)
47. Vanderbei, R.J. et al.: Linear Programming. Springer (2015)
48. Washburn, A.R.: Two-Person Zero-Sum Games. Springer (2014)

Modeling Inﬁnite Games on Finite
Graphs Using Numerical Inﬁnities
Louis D’Alotto
Abstract In his seminal work, Robert McNaughton (see [14] and [10])
developed a model of inﬁnite games played on ﬁnite graphs. Here is presented
a new model of inﬁnite games played on ﬁnite graphs using the Grossone
paradigm. The new Grossone model provides certain advantages such as
allowing for draws, which are common in board games, and a more accurate
and decisive method for determining the winner.
1
Introduction
The theory of grossone has been developed as an extension of the Cantor
theory to better understand the inﬁnite. Here grossone is applied to investigate
games of inﬁnite duration. The games investigated occur on ﬁnite graphs and
arethosewithperfectinformation.Thatis,andtypically,aperfectinformation
game is played on a board where a player moves pieces subject to a given
set of rules and each player knows everything important to the game that has
previously occurred.
This chapter is dedicated in loving memory to my wife Zana, who has and will always
be my motivation and my inspiration.
L. D’Alotto (B)
York College, The City University of New York, Jamaica, Queens, NY 11451, USA
e-mail: ldalotto@york.cuny.edu
The Graduate Center, The City University of New York, 356 Fifth Avenue,
New York, NY 10016, USA
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_12
297

298
L. D’Alotto
Fig. 1 The consumer-producer problem
Finite board games such as tic-tac-toe, chess, checkers, and go are common
and most of us have a good understanding of them. These are games of
strategy, once the speciﬁc positions are known. Of course we must exclude
all games of chance and card games where players do not reveal their hands,
since these are not games with perfect information. A board game will have
a conﬁguration (a state or a state of play) and it must be made precise to
include all information about any situation in the game. The conﬁguration
describes the current state or standing of the game. Of signiﬁcant importance,
the conﬁguration will dictate which player is to move next. Hence, in board
games, the play moves go from one player to the other. A board game such as
tic-tac-toe has only a very small number of conﬁgurations. Here we can easily
compute (via computer search techniques) all the conﬁgurations and hence
this game is not very interesting. However, and on the other hand, games of
checkers, chess and go have an extremely large number of conﬁgurations and
command a lot of attention from computer scientists and mathematicians.
Finite board games that are played to inﬁnity may sound like science
or mathematical ﬁction. Indeed, following the traditional Turing machine
model, a computation is complete when it halts and produces some type of
result. However when a game is played to inﬁnity, it is implied that the game
continues for an indeﬁnite period and the play continues without bound. A
typical application that can be considered an inﬁnite game is the operating
system of a computer (a multiprogramming machine). The operating system
has to manage multiple processes (or users on a server) without termination.
When one process (or user) is satisﬁed, there are others waiting for system
resources to be processed. Hence process-oriented theory is an application of
inﬁnite games to computer science (see [14]). Running of a business may also
be modeled as an inﬁnite game. For example, the consumer-producer process
(see Fig.1) where the producer makes items, stores them in a warehouse,
and the consumer purchases (consumes) them. In Fig.1, for simplicity it
is assumed the warehouse can store three items. Here the objective is to
maintain the business and keep both the consumer and producer satisﬁed. If
the warehouse is full and the producer still produces items, then the consumer

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
299
fails the business game since they fail to satisfy the producer. If the warehouse
is empty and the consumer still wants to buy, then the producer fails to satisfy
the consumer. Here the objective is to keep items in the warehouse for the
consumer to purchase but not overﬁll the warehouse. The game continues
on as an inﬁnite process. With respect to the theory of Büchi automata, the
failing states, f (c) and f (p), can be entered ﬁnitely many times as long
as the states 0 to 3 (call these the favorable states) are entered inﬁnitely
many times. However, with the current vague notion of inﬁnity, suppose the
favorable states are entered inﬁnitely many times but the failing states are also
entered inﬁnitely many times. The consumer and the producer are satisﬁed
inﬁnitely many times but also are unsatisﬁed inﬁnitely many times. Hence
the game is failed by one (or both) of the players but the game also entered
the favorable states inﬁnitely many times. This dichotomy exists due to our
vague notion of inﬁnity.
Another important inﬁnite game (or inﬁnite process) is the famed Dining
Philosopher’s Problem and deals with synchronization. In the classic situ-
ation, there are ﬁve philosophers sitting at a round table. In front of each
philosopher is a plate of spaghetti and a single fork on both the left and
right sides of each philosopher. Each philosopher, not being very dexterous,
requires two forks to eat their spaghetti. Hence only non-adjacent philoso-
phers can eat and at most two at a time. Each of these philosophers can
either eat or think. If a philosopher is not eating then they are thinking. If
someone is thinking then that philosopher is not eating. So thinking and
eating are mutually exclusive. If each philosopher grabs a single fork, then
they are deadlocked and no one can eat. The game continues indeﬁnitely,
when a philosopher eats, the others (who are not eating) think. Of course, the
objective is for the philosophers to avoid starvation.
2
The Inﬁnite Unit Axiom and Grossone
Applying the following new paradigm facilitates us to better understand the
notion of inﬁnite games on graphs and update networks. The problem of
better understanding the notion of computing with inﬁnity was approached
beginning in 2003 by Yaroslav D. Sergeyev (see [19–23]). In these works,
a new unit of measure on the set of natural numbers N is deﬁned. Thus, the
following axiom evolves the idea of the inﬁnite unit.
Axiom Inﬁnite Unit axiom. The number of elements in the set N of natural
numbers is equal to the inﬁnite unit denoted as ①and called grossone.
□
There are a few postulates that follow the Inﬁnite Unit axiom:

300
L. D’Alotto
1. Inﬁnity: For any ﬁnite natural number n, n < ①.
2. Identity: The following relationships hold and are extended from the usual
identity relationships of the natural numbers:
a) 0 · ①= ①· 0 = 0, b) ①−①= 0,
c) ①
①= 1,
d) ①0 = 1,
e) 1①= 1.
3. Divisibility: For any ﬁnite natural number n, the numbers
①, ①
2 , ①
3 , ①
4 , ..., ①
n , ...
are deﬁned as the number of elements in the nth part of N.1
The divisibility property will be of signiﬁcant importance in determining
a winner of an inﬁnite game. Indeed, determining a winner will result by
determining the number of elements in a sequence. It is important to mention,
with the introduction of the Inﬁnite Unit axiom and grossone, ①, we list the
natural numbers as
N = {1, 2, 3, 4, ..., ①−2, ①−1, ①}.
As a consequence of this new paradigm, we have the following important
theorem.
Theorem 1 The number of elements of any inﬁnite sequence is less or equal
to ①.
Proof See [20] or [25].
Recently there has been a large amount of research activity on the logi-
cal theory and applications of grossone. To name a few, see [2–8, 11, 13,
1 In [19], Sergeyev formally presents the divisibility axiom as saying for any ﬁnite natural
number n sets Nk,n, 1 ≤k ≤n, being the nth parts of the set N, have the same number
of elements indicated by the numeral ①
n where
Nk,n = {k, k + n, k + 2n, k + 3n, ...}, 1 ≤k ≤n,
n
k=1
Nk,n = N
and illustrates this with examples of the odd and even natural numbers.

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
301
15–18, 22, 26, 28]. As a result of the ①numeral system, we have the math-
ematical tools to express the number of elements in inﬁnite sets. It must be
stressed, however, that the grossone-based methodology is not related to non-
standard analysis, see [27]. This next section will describe a new application
of grossone to inﬁnite games.
3
Inﬁnite Games
Formally, an inﬁnite graph game is deﬁned on a ﬁnite bipartite directed graph
whose set, Q, of vertices are partitioned into two sets: R, the set of vertices
from which Red moves, and B, the set of vertices from which Blue moves.
The game has a place marker which is moved from vertex to vertex along the
directed edges. The place marker signiﬁes the progress of the play. When the
marker is on a vertex of R, it is Red’s move to move to a vertex in B. When
the marker is on a vertex of B, it is Blue’s turn to move to a vertex of set
R. The play continues in this fashion, Red moves to a Blue vertex and Blue
moves to a Red vertex.
Deﬁnition 1 An inﬁnite game, G, is a 6-tuple
G = (Q, B, R, E, W(B), W(R))
where,
1. Q is the ﬁnite set of positions (vertices).
2. B and R are subsets of Q, such that B ∪R = Q and B ∩R = ∅.
3. E is a set of directed edges between B and R such that:
a. for each b ∈B there exists r ∈R such that (b,r) ∈E.
b. for each r ∈R there exists b ∈B such that (r, b) ∈E.
4. W(B) is called the winning set for Blue.
5. W(R) is called the winning set for Red.
6. W(B) ∩W(R) = ∅.
At this time it should be noted that the winning sets for each player are not
limited to vertices of the player’s color.
Deﬁnition 2 A play that begins from position q is a complete2 inﬁnite
sequence p = q1q2q3q4...q①−1q①suchthatq = q1 and(qi, qi+1) ∈E, ∀i ∈
2 Here we use the notion of complete taken from [19], that is the sequence contains ①
elements.

302
L. D’Alotto
N, E is the edge relation. Hence a play is a sequence of states of the game.
That is,
p : N →Q.
To determine how a player can win, let p be a play and consider the set of
all vertices that occur inﬁnitely often. We now have the following deﬁnition.
Deﬁnition 3 In(p) is the set of vertices, in play p, that occur inﬁnitely often,
called the inﬁnity set of p.
We now have the following cases to determine a win:
1. W(B) ⊂In(p) and W(R) ̸⊂In(p), then Blue wins.
2. W(B) ̸⊂In(p) and W(R) ⊂In(p), then Red wins.
3. W(B) ̸⊂In(p) and W(R) ̸⊂In(p), then Draw.
4. W(B) ⊂In(p) and W(R) ⊂In(p), then the frequencies of occurrence
of the elements in each set must be considered.
Cases 1 and 2 above are the result that whatever winning set a player chooses,
all vertices must occur inﬁnitely often for a player to have a chance of winning
(this concept is consistent with the ideology presented in [24]). All vertices
must occur inﬁnitely often also prevents a player from choosing too many
vertices for their winning set.3 Next we look at a simple example to analyze
the situation when a player chooses the empty set.
Example 1 Suppose Blue chooses ∅as their winning set (this is consis-
tent with the premise that no choice is also a choice). That is, W(B) = ∅.
The reason for Blue’s choice is clear. ∅⊂In(p), hence Blue is hoping that
W(R) ̸⊂In(p) and Blue wins the game (the same can be true for Red, if
Red chooses the empty set). Of course the situation can arise if both players
choose ∅. In that case, the game will result in a draw. However, to show this
we ﬁrst need to deﬁne more machinery.
It is necessary to deﬁne a frequency function to count the number of
occurrences of a given vertex in a play sequence. This gives rise to the next
two deﬁnitions.
Deﬁnition 4 Given Q = {q1, q2, ..., qn} is the ﬁnite set of states and let D
be a subset of Q. Let p be an inﬁnite sequence of states, from a play, deﬁne
a new sequence by the function
ψD,p : N →{0, 1}
3 It is noted here that, as is usual, the ⊂symbol can also imply equality.

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
303
where,
ψD,p(i) =
1 i f p(i) ∈D
0
otherwise
∀i ∈N.
Deﬁnition 5 Deﬁne the frequency function, f reqp, as
f reqp(D) =
①

i=1
ψD,p(i).
These deﬁnitions are valid in general, however here they are applied to the
winning sets for Blue and Red, respectively W(B) and W(R).
With the previous deﬁnitions, if both winning sets are subsets of the inﬁnity
set (the elements of both player’s winning sets occur inﬁnitely often) a winner
canbedetermined.Ifthefrequencyoftheelementsin W(B)isgreaterthanthe
frequencyoftheelementsin W(R),thenBlueisthewinner.Ifthefrequencyof
the elements in W(R) is greater than the frequency of the elements in W(B),
then Red is the winner. If the frequencies are equal, then a draw results. This
is a key advancement as a result of the grossone theory. As an immediate
consequence from the above deﬁnitions, the following propositions are true.
Proposition 1 For any sequence p, f reqp(∅) = 0.
Proof p(i) /∈∅∀i ∈N. Hence ψD(i) = 0 ∀i ∈N. Therefore f reqp(∅) =
0.
Proposition 2 If both players choose the empty set as their winning set, then
the game is a draw.
Proof
By Proposition 1, f reqp(W(B)) = f reqp(W(R)) = f reqp(∅) =
0.
4
Strategies
As with all games, a strategy is important for winning the game or to prevent
your opponent from winning (in the latter case, at least strive for a draw).
Hence a strategy allows a player to give a deﬁnition of the winner (or draw)
from a given position in the game. Generally, a strategy for a player is a rule
that speciﬁes the next move of the player, given the history of the past moves.
To give a more formal notion of a strategy, let

304
L. D’Alotto
p = q1, q2, q3, ...., q①−1, q①
be a play in the game G. Then the histories of this play are
q1, q1q2, q1q2q3, q1q2q3q4, ....
It is immediately apparent that there are inﬁnitely many histories in game G.
Therefore we will look at two sets of histories, the set H(B) that contains all
histories whose last positions are positions where Blue makes a move, and
the set H(R) that contains all the histories whose last positions are positions
where Red makes a move. Hence, a strategy for Blue is a function f where
f : H(B) →G
such that ∀v = q1...qn ∈H(B), (qn, f (v)) ∈E.
Hence, if f is a strategy for a player and q is a state position in the game,
then all plays that begin from q, in which the player follows the strategy f
can be considered. These plays are called consistent with f .
Deﬁnition 6 Call the strategy f of a player a winning strategy from a
position q if all plays consistent with f that begin from q are won by the
player. In this case it can be said that the player wins the game from q.
5
Examples and Results
Example 2 Referring to the game in Fig.2, assume that W(B) = {b1} and
W(R) = {r1}. Then Blue is always the winner, no matter where the game
begins. If W(B) = {b1} and if W(R) = {r1,r2}, then Blue’s winning strat-
egy would be to move to either r1 or r2 ﬁnitely many times and the other
inﬁnitely times. Therefore W(R) ̸⊂In(p).
For instance, if the following sequence is played
p = r1, b1,r2, b1,r1, b1,r2, b1,r1, b1,r1, b1,r1, b1,r1, ...
then
In(p) = {b1,r1}
and W(R) ̸⊂In(p), however W(B) ⊂In(p), which implies Blue wins the
game. If W(B) = {r1} and W(R) = {r2} (as mentioned previously, a player
does not have to choose their color as their winning set) then Blue wins the
game. The winning strategy for Blue consists of moving to r2 ﬁnitely many
times. Actually Blue can move to r2 inﬁnitely many times, however it must

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
305
Fig. 2 A simple game
be less than ①/4 times. The following theorem and corollaries provide a
better understanding of the frequency function.
Theorem 2 For any set A and play p, the frequency function, f reqp(A) ≤
①.
Proof This follows directly from the properties of ①and Theorem 1.
Corollary 1 For any game, the frequency of occurrence of any single vertex
is ≤①/2.
Proof Follows from Theorem 2 and the deﬁnition of a game, since there are
two players.
Corollary 2 For any game where Q is the set of vertices, f reqp(Q) = ①.
Proof Using the premise of a complete sequence, the corollary directly fol-
lows from Theorems 1 and 2.
This next example will illustrate this new application of the grossone
paradigm to inﬁnite games.
Example 3 Referring again to the game in Fig.2, suppose the play goes as
follows:
p = r2, b1,r1, b1,r2, b1,r1, b1,
r2 skip

r1
, b1,r1, b1,r2, b1,r1, b1,r2, b1,r1, b1, ...
Here the In(p) = {b1,r1,r2}. Hence, the frequency of occurrence for each
vertex in the In(p) is:
f req({b1}) = ①/2,
f req({r1}) = ①/4 + 1,
f req({r2}) = ①/4 −1.
Using the winning sets W(B) = {r1} and W(R) = {r2}, Blue wins the game.
Example 4 In Fig.3, if Blue chooses b4, that is W(B) = {b4}, a strategy
for Red would be to choose ∅. Then from r3, Red can always move to b3 an
inﬁnite number of times or move to b4 a ﬁnite number of times. In this case,
the best Blue can hope for is a draw.

306
L. D’Alotto
Fig. 3 A more complex game
Example 5 Referring again to Fig.3, if each node is visited once in the 6
node outside cycle, that is via edges (r1, b3), (b3,r3), (r3, b4), (b4,r2),
(r2, b1), (b1,r1), then the frequency of each vertex occurrence is ①/6. The
sequence that will ensure this is:
p = r1, b3,r3, b4,r2, b1,r1, b3,r3, b4,r2, b1,r1, b3...
If player Blue chooses their winning sets W(B) = {b1, b3}, then Red can
choose W(R) = {r2,r3} and Red has a winning strategy. When Blue lands
on vertex b1, Blue must move to r1 to get to b3 (part of Blue’s winning set).
The play continues and can follow the outside cycle. However, at some point,
Red moves from r2 back to b4 a ﬁnite number of times. For instance, a play
can follow:
p = r1, b3,r3, b4,r2, b4,r2, b4,r2, b4,r2, b1,r1, b3,r3, b4,r2, b1,r1, ...
hence
f reqp({b1, b3}) = ①
3 −2,
f reqp({r2,r3}) = ①
3 + 1,
and Red wins the game.
So far the counting arguments presented seem quite straightforward. How-
ever, some counting arguments can be a bit more complicated but neverthe-
less still computable, see [25]. The following example in Fig.4 shows that
the number of moves does not straightforwardly and necessarily compute
to a natural number. However applying the integer ﬂoor function, a natural
number is obtained.

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
307
Fig. 4 A simple game where the number of occurrences is counted with a log function
Here it is supposed that a player chooses the set {b1} as their winning
set. Hence the number of occurrences of b1 will be counted. Consider the
following sequence:
b1

1
,r2, b1

3
,r1, b2,r2, b1

7
,r1, b2, ...,r1, b2,r2, b1

15
,r1, b2, ...,r2, b1

31
, ...
The sequence repeats r1, b2 then r2 to b1. Continuing this pattern, the b1
vertex occurs at the next power of 2 away from the previous b1 vertex. This
is the case where k = −1.
There are four vertices and hence three other cases:
k = 0
r2, b1

2
,r2, b1

4
,r1, b2,r2, b1

8
,r1, b2, ...,r1, b2,r2, b1

16
,r1, b2, ..., b1

32
, ...
k = 1
b2,r2, b1

3
,r2, b1

5
,r1, b2,r2, b1

9
,r1, b2, ...,r1, b2,r2, b1

17
,r1, ..., b1

33
, ...
k = 2
r1, b2,r2, b1

4
,r2, b1

6
,r1, b2,r2, b1

10
,r1, b2, ...,r1, b2,r2, b1

18
, ..., b1

34
, ...
The number of occurrences of b1 in each sequence is:
⌊log2(n −k)⌋∀n ∈N.
Analogously, the set
{k + 2i : −1 ≤k ≤2, i ∈N, k + 2i ≤①}

308
L. D’Alotto
Fig. 5 An update game
for the maximum possible i, has the following number of elements
⌊log2(①−k)⌋.
6
An Application: Update Games and Networks
Communication network problems can be modeled using the concept of inﬁ-
nite games presented herein this paper. For example, in a distributed database
system a problem of redundancy of data can be resolved by sharing informa-
tion between all nodes of the system. This can be accomplished by a packet of
current data continuously running through all nodes of the distributed system.
Hence this is a solution (theoretically) without termination.
In an update game, one player is called the control player (color). The
control player is the player who is responsible for updating all the vertices
(nodes) in the game. The following deﬁnition can now be stated.
Deﬁnition 7 An update game is a game G = (Q, B, R, E, W(B), W(R))
for which Blue (or Red) is the control player, Q = W(B) (or Q = W(R))
and W(R) = ∅(respectively, W(B) = ∅).
Deﬁnition 8 An update game is an update network if the control player has
a winning strategy to win the update game from any position of the game.
Figure5, with Blue as the control player, is an update network. As is seen,
Blue can update every vertex from b1 as follows:
p = b1,r1, b1,r2, b1,r3, b1,r1, b1,r2, b1,r3, b1,r1...

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
309
Here the set of vertices Q = {b1,r1,r2,r3} = W(B) = In(p). It is obvious
that f reqp({b1}) = ①/2 and hence, by Corollary 2, f reqp({r1,r2,r3}) =
①/2. From b1, Blue must move to one of the Red vertices. The Red vertices
must be visited an inﬁnite number of times in order for Blue to win and
make this an update network, however their frequencies do not have to be
equal. Hence note that Fig.5 is not an update network with Red as the control
player. Of course this update network does not have to be limited to three
Red vertices. Hence the following proposition is obvious and stated without
proof.
Proposition 3 An update game with color players Blue (B) and Red (R),
where the control color B has only one position, is an update network if
∀r ∈R, there exists a bi-directional edge from the control color to each r.
7
Conclusion
This paper has presented a new model of inﬁnite games played on ﬁnite
graphs by applying the theory of grossone and the Inﬁnite Unit axiom. In his
original work, McNaughton (see [14]) presented and developed a model of
inﬁnite games played on ﬁnite graphs using traditional methods of dealing
with inﬁnity. This paper has extended that work to count the number of times
vertices in a board game are visited, although vertices can be visited an inﬁnite
number of times. Indeed, two players choose their winning sets and the player
whose winning set is visited more frequently wins the game. With this new
paradigm, as is common in the usual ﬁnite duration board games (chess,
checkers, go), a draw can result. This was not the case in McNaughton’s
original work. Hence a more ﬁner decision process is used in determining
the winner or if the game results in a draw.
References
1. Cantor, G.: Contributions to the Founding of the Theory of Transﬁnite Numbers.
Dover Publications, New York (1955)
2. Caldarola, F.: The exact measures of the Sierpi´nski d-dimensional tetrahedron in
connection with a Diophantine nonlinear system. Commun. Nonlinear Sci. Numer.
Simul. 63, 228–238 (2018)
3. Cococcioni, M., Fiaschi, L., Lambertini, L. Non-Archimedean zero-sum games. J.
Comput. Appl. Math. 393, article 113483 (2021)
4. Cococcioni, M., Fiaschi, L. Non-Archimedean game theory: a numerical approach.
Appl. Math. Comput. 409, article 125356 (2021)

310
L. D’Alotto
5. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
Conjugate Gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
6. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
7. D’Alotto, L.: A classiﬁcation of one-dimensional cellular automata using inﬁnite
computations. Appl. Math. Comput. 255, 15–24 (2015)
8. Fiaschi, L., Cococcioni, M.: Numerical asymptotic results in game theory using
Sergeyev’s inﬁnity computing. Int. J. Unconv. Comput. 14(1), 1–25 (2018)
9. Gordon, P.: Numerical cognition without words: evidence from Amazonia. Science
306, 496–499 (2004)
10. Khoussainov, B., Nerode, A., Automata Theory and its Applications. Birkhauser,
(2001)
11. Iudin, D.I., Sergeyev, Y.D., Hayakawa, M.: Inﬁnity computations in cellular automa-
ton forest-ﬁre model. Commun. Nonlinear Sci. Numer. Simul. 20(3), 861–870 (2015)
12. Lolli, G.: Inﬁnitesimals and inﬁnites in the history of mathematics: a brief survey.
Appl. Math. Comput. 218(16), 7979–7988 (2012)
13. Lolli, G.: Metamathematical investigations on the theory of Grossone. Appl. Math.
Comput. 255, 3–14 (2015)
14. McNaughton, R.: Inﬁnite games played on ﬁnite graphs. Ann. Pure Appl. Logic 65,
149–184 (1993)
15. Margenstern, M.: Using Grossone to count the number of elements of inﬁnite sets
and the connection with bijections, p-Adic Numbers. Ultrametr. Anal. Appl. 3(3),
196–204 (2011)
16. Montagna, F., Simi, G., Sorbi, A.: Taking the Pirahã seriously. Commun. Nonlinear
Sci. Numer. Simul. 21(1–3), 52–69 (2015)
17. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Unconv.
Comput. 14(2), 139–158 (2019)
18. Rizza, D.: How to make an inﬁnite decision. Bull. Symbol. Logic 24(2), 227 (2018)
19. Sergeyev, Y.D.: Arithmetic of Inﬁnity. Edizioni Orizzonti Meridionali, Italy (2003)
20. Sergeyev, Y.D.: A new applied approach for executing computations with inﬁnite
and inﬁnitesimal quantities. Informatica 19(4), 567–596 (2008)
21. Sergeyev, Y.D., Counting systems and the ﬁrst Hilbert problem. Nonlinear Anal. Ser.
A: Theory, Methods Appl. 72(3–4), 1701–1708 (2010)
22. Sergeyev, Y.D.: Numerical computations and mathematical modeling with inﬁnite
and inﬁnitesimal numbers. J. Appl. Math. Comput. 29, 177–195 (2009)
23. Sergeyev, Y.D. Computations with grossone-based inﬁnities. In: Calude, C.S., Din-
neen, M.J. (eds.), Proceedings of the 14th International Conference “Unconventional
Computation and Natural Computation”, Lecture Notes in Computer Science, vol.
9252, pp. 89–106. Springer (2015)
24. Sergeyev, Y.D.: The Olympic medals ranks, lexicographic ordering and numerical
inﬁnities. Math. Intell. 37(2), 4–8 (2015)
25. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320
(2017)
26. Sergeyev, Y.D., Garro, A.: Observability of turing machines: a reﬁnement of the
theory of computation. Informatica 21(3), 425–454 (2010)
27. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24, 153–170 (2019)

Modeling Inﬁnite Games on Finite Graphs Using Numerical Inﬁnities
311
28. Tohmé, F., Caterina, G., Gangle, R.: Computing truth values in the topos of inﬁnite
Peirce’s α-existential graphs. Appl. Math. Comput. 385, article 125343 (2020)
29. Zhigljavsky, A.: Computing sums of conditionally convergent and divergent series
using the concept of grossone. Appl. Math. Comput. 218, 8064–8076 (2012)

Adopting the Inﬁnity Computing in
Simulink for Scientiﬁc Computing
Alberto Falcone, Alfredo Garro, Marat S. Mukhametzhanov,
and Yaroslav D. Sergeyev
Abstract Numerical computing represents a critical aspect of conventional
computer architecture. Traditional computers adopt the IEEE 754-1985
binary ﬂoating-point standard to represent and work with real numbers.
Due to the architectural limitations of traditional computers, it is impos-
sible to handle inﬁnite and inﬁnitesimal quantities numerically. This chapter
is devoted to the Inﬁnity Computer, a supercomputer that permits to execute
numerical computation with ﬁnite, inﬁnite, and inﬁnitesimal numbers. The
accessible software simulator of the Inﬁnity Computer is adopted in many
industrial and research domains for addressing important real-world issues,
where precision plays a crucial aspect. However, the Inﬁnity Computer sim-
ulator is not suitable for handling problems in control theory and dynamics,
where visual programming environments like Simulink are commonly used.
In this context, the chapter presents the Simulink-based Solution for the Inﬁn-
A. Falcone · A. Garro (B) · M. S. Mukhametzhanov · Y. D. Sergeyev
Department of Informatics, Modeling, Electronics and Systems Engineering (DIMES),
University of Calabria, via P. Bucci 41/C, 87036 Rende, Italy
e-mail: alfredo.garro@unical.it
A. Falcone
e-mail: alberto.falcone@dimes.unical.it
M. S. Mukhametzhanov
e-mail: m.mukhametzhanov@dimes.unical.it
Y. D. Sergeyev
e-mail: yaro@dimes.unical.it
Y. D. Sergeyev
Institute of Information Technology, Mathematics and Mechanics (IITMM),
Lobachevsky
State University of Nizhny Novgorod, 603950 Nizhny Novgorod, Russia
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_13
313

314
A. Falcone et al.
ity Computer, a novel solution that allows one to exploit the Inﬁnity Computer
arithmetic within the Simulink environment.
1
Introduction
To represent and deal with numbers, traditional computers adopt the IEEE
754-1985 binary ﬂoating-point standard (see [1]). Despite computers can deal
with ﬁnite numbers, numerical computations involving inﬁnite and inﬁnitesi-
mal quantities are impossible due to the presence of indeterminate forms and
the inability of putting an inﬁnite representation of a number into the ﬁnite
computer memory (see [50]).
The Inﬁnity Computer is a new type of supercomputer that can operate with
ﬁnite, inﬁnite, and inﬁnitesimal numbers numerically. The already available
software simulator of the Inﬁnity Computer was implemented in the C++
language and is used to tackle complex real-world problems in a variety
of industrial and research domains, including mathematics and physics (see
[50] and references given therein). However, due to implementation issues
related to extending and integrating the C++ source code of arithmetic and
elementary operations in well-established environments like Simulink, the
software simulator is not sophisticated enough to handle problems in control
theory and dynamical systems.
To address these challenges, the chapter presents an innovative solution
that integrates the Inﬁnity Computer arithmetic within the Simulink environ-
ment, a well-known graphical programming environment for exploring and
analyzing dynamic systems produced by MathWorks (see [21]). Simulink
adopts a graphical block diagramming notation that is tightly integrated with
Matlab. Simulink is widely used in the modeling and simulation domain,
including distributed simulation, Co-Simulation of Cyber-Physical Systems
(CPS) and Model-Based design (see [5, 14, 29, 38, 39]).
The chapter is organized as follows. Section2 brieﬂy presents the Inﬁnity
Computer and Matlab Simulink environment. The Simulink-based solution
for operating with the Inﬁnity Computing concepts within the Simulink envi-
ronment is presented in Sect.3. A set of numerical experiments is described
in Sect.4 to show the practicability and validity of the proposed solution.
Finally, conclusions and future works are outlined in Sect.5.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
315
2
Background
The chapter employs notions and concepts from the Inﬁnity Computing and
its representation of numbers, as well as related algebraic operations, and the
MATLAB Simulink environment, as described in the following subsections.
2.1
The Inﬁnity Computing and Representation of Numbers
In the Inﬁnity Computing (see [50]), numbers are represented using the posi-
tional numeral system with the inﬁnite radix ①introduced as the number of
elements of the set of natural numbers:
C = d0①p0 + d1①p1 + · · · + dn①pn,
(1)
where quantities di, i = 0, ..., n, are ﬁnite (positive or negative) ﬂoating-
point numbers called grossdigits, and
pi,
i = 0, ..., n, are called
grosspowers and can be ﬁnite, inﬁnite and inﬁnitesimal (positive or nega-
tive), n is the number of grosspowers used in computations (can be ﬁxed or
variable for all computations).1 Due to Simulink constraints (e.g., difﬁculties
in working with variable-sized matrices in algebraic loops) and for simplic-
ity, this chapter only considers ﬁnite ﬂoating-point grosspowers. It should be
highlighted that this methodology is not related to non-standard analysis (see
[51] for details).
In the Inﬁnity Computer, a ﬁnite ﬂoating-point number A can be easily
expressedusingjustonegrosspower p0 = 0 : A = A①0.Furthermore,differ-
ent inﬁnite and inﬁnitesimal numbers can be expressed: e.g., the numbers ①,
①2,
−1.5①2.5,
−1.2①3.2
−1.2①0 + 2.3①−1.2 are inﬁnite, because they contain at least one ﬁnite pos-
itive grosspower; whereas, the numbers ①−1 = 1
①, 2.5①−1.5, 1.3①−2.2 −
1.7①−3.1 areinﬁnitesimal,becausetheycontainonlyﬁnitenegativegrosspow-
ers. Let us refer to the numbers given in the form (1) as grossnumbers here-
inafter.
The Inﬁnity Computer has previously been utilized effectively to solve
real-world engineering issues and practical mathematics, such as handling
ill-conditioning (see [34, 53]), optimization (see [10, 11, 15–17, 34, 53,
58]), Turing machines and inﬁnite series (see [52, 57]), game theory and
1 It should be noted that in the literature dedicated to the Inﬁnity Computer, a different
notation with p0 = 0 is generally used, but here we adopted this matrix notation, since
it better represents the details of our implementation.

316
A. Falcone et al.
probability (see [9, 12, 30, 41, 43]), fractals and cellular automata (see [7,
8, 13, 47, 49]), numerical differentiation and ordinary differential equations
(see [2, 26, 35, 46, 48, 55]), binary spherical classiﬁers (see [3]), Spencer
Brown’s Calculus of Indications (see [31]), etc.
2.2
The MATLAB/Simulink Environment
Simulink is a simulation environment for MATLAB developed by Math-
Works (see [37]). It enables engineers to model, simulate and analyze
dynamic systems using the block diagram language before deploying on
hardware. Furthermore, Simulink provides graphical tools for displaying the
progress of a simulation, which considerably improves understanding of the
system’s behavior.
Simulink has the potential to signiﬁcantly increase productivity (see [21,
37]). In the past, the traditional approach for developing a system was to begin
with its components and describe their logic using blocks. The so-obtained
blocks were then translated into the corresponding source code using a target
programming language (for example, C/C++). Because the system had to be
described twice, once in block notation and then in a programming language,
this method required duplication of effort.
This approach exposes the translation process, from blocks to source code,
to accuracy risks making the debugging stage difﬁcult due to errors that could
happen in the design (block diagram level), in the programming (program-
ming level), and/or in the translation process. This approach is no longer
required with Simulink because blocks are the “program”.
Simulink is widely used in research and industry to investigate and assess
design alternatives for complex systems so as to determine the optimal con-
ﬁguration that meets the requirements. The multi-domain nature of Simulink
may be used by research teams to collaboratively simulate the behavior of the
system’s components, each of which developed by a team, also to evaluate
how components inﬂuence the behaviour of the entire system [18, 22–24].
Simulink allows one to: (i) minimize the cost of prototypes by testing the
system under risky and/or time-consuming conditions; (ii) verify and validate
the system design with hardware-in-the-loop testing and rapid prototyping;
and, (iii) maintain requirement traceability from design down to source code.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
317
3
The Simulink-Based Solution for the Inﬁnity
Computer (SSIC)
This section presents the Simulink-based Solution for the Inﬁnity Computer
(SSIC), a Simulink-based solution for operating with the Inﬁnity Computing
[25, 26]. It allows one to rapidly develop simulation models by exploiting
the Inﬁnity Computing arithmetic within the Simulink environment [37].
Furthermore, as demonstrated in several publications (see [45, 50] and ref-
erences given therein), the Inﬁnity Computer executes computations numer-
ically using the IEEE 754 ﬂoating-point numbers, rather than symbolically.
In particular, it has been demonstrated in the papers [36, 40] that the Inﬁn-
ity Computer is signiﬁcantly faster than symbolic computations, allowing
one to achieve exact2 solutions for various real-life problems as symbolic
computations do. It should be emphasized that this methodology has nothing
to do with non-standard analysis (see [51]).
The following subsections are devoted to describe in detail the proposed
solution. Speciﬁcally, Sect.3.1 describes how grossnumbers are represented
in SSIC; whereas, Sect.3.2 presents the architecture of SSIC along with the
provided four functional modules, i.e., Arithmetic Blocks Module (ABM),
Elementary Blocks Module (EBM), Utility Blocks Module (UBM), and Dif-
ferentiation Blocks Module (DBM). For each module, the offered blocks are
described together with examples showing their applicability.
3.1
Representation of Grossnumbers in SSIC
A grossnumber x is represented in SSIC through a standard Simulink Con-
stantblock asavariablesizedvector(1-Darray)ormatrix(2-Darray)depend-
ing on the dimensionality of the “Constant value” parameter (see [37]). The
output has the same dimensions and elements as the “Constant value” param-
eter. If “Constant value” is a vector and the “Interpret vector parameters as
1-D” setting is enabled, Simulink considers the output as a 1-D array; oth-
erwise, the output is handled as a 2-D array. Regardless of the output size,
the ﬁrst column indicates the grossdigits, while the second one speciﬁes the
grosspowers of a number expressed in the form (1): the number (1) is repre-
sented by the following 2-D array:
2 Since the computations on the Inﬁnity Computer are numerical and all the numbers
and operations belong to the IEEE 754 ﬂoating-point standard [1], then the word “exact”
means “up to machine precision”.

318
A. Falcone et al.
C =
⎡
⎢⎢⎣
d0 p0
d1 p1
· · ·
dn pn
⎤
⎥⎥⎦.
(2)
For instance, the number 6 is represented in SSIC through the 1-D array
6 0	
, whereas the number 6①0 + 1①−1 is represented by the 2-D array

6 0
1 −1

.
3.2
Architecture
SSIC brings the power of the Inﬁnity Computer into the Simulink Graphical
Programming Environment (GPE). The solution has been deﬁned to facilitate
the modeling and simulation of dynamic systems by allowing engineers to
focus on the speciﬁc aspects of their system’s components rather than the
low-level functionalities provided by the Inﬁnity Computer Arithmetic C++
library (ICA-lib).
The proposed solution is general-purpose and domain-independent and
was created according to the Modular Programming Paradigm (see [4]),
which emphasizes separating the functionalities of a software into inde-
pendent modules, each of which has a group of closely related blocks and
resources to perform a given function (e.g., sqrt, cos, and sin) (see [5]). The
modular architecture of SSIC enables one to exploit the large set of Inﬁnity
Computer blocks in conjunction with the Simulink standard ones. Because
modules have independent concerns, the proposed solution is easy to main-
tain and upgrade; this means that, it is possible to obtain a module and make
the necessary changes without causing issues to the other modules.
Specialists can easily model, simulate, and evaluate hybrid systems using
SSIC to face important real-world problems, where precision and accuracy
in the calculations are critical aspects (e.g., Modern Complex Engineered
Systems (CES), Automation, and Aerospace (see [6, 20, 28, 32, 33])).
SSIC has been developed by using the standard Simulink Blocks and S-
Functions, which allows engineers to jointly exploit the beneﬁts of the Inﬁn-
ity Computer with the already available Simulink functionalities. Figure1
presents an overview of the proposed solution and its integration with the
Matlab/Simulink environments. SSIC is placed between the Simulink Graph-
ical Programming Environment and Matlab Environment layers.
TheSimulinkGraphicalProgrammingEnvironment representstheSimulink
environment used for modeling, simulating, and analyzing dynamic systems

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
319
Fig. 1 The Simulink-based Solution for the Inﬁnity Computer (SSIC) [27]
through the graphical block diagramming tool according to the Model-Based
Design (MBD) paradigm (see [19]). MBD is an effective method for dealing
with issues concerning the design and execution of complex systems, signal
processing equipment, and communication components. MBD offers a com-
mon framework that can be used to create models with advanced functional-
ities by combining continuous-time and discrete-time blocks. The obtained
models can be simulated in Simulink under different operational conditions
leading to rapid prototyping, testing, and veriﬁcation of the system’s require-
ments and performances.
The Simulink Environment layer includes all the standard Simulink blocks
as well as those offered by SSIC. Speciﬁcally, SSIC provides a collection of
functional blocks to manage computations on inﬁnite, ﬁnite, and inﬁnitesimal
quantities represented in the form (2). Each functional block accepts as input
inﬁnite, ﬁnite, and inﬁnitesimal numbers that are forwarded to the appropriate

320
A. Falcone et al.
S-Function to perform the computation by interacting with ICA-lib. The SSIC
functional block modules are depicted in Fig.2.
The Matlab Environment represents the infrastructure where the Inﬁnity
Computer arithmetic C++ library (ICA-lib) has been integrated to perform
inﬁnite, ﬁnite, and inﬁnitesimal computations. The ICA-lib was integrated
into Simulink through a Matlab executable ﬁle (MEX) that serves as an inter-
face between the involved parts. When the MEX ﬁle is compiled, Simulink
dynamically loads it and allows to invoke the Inﬁnity Computer arithmetic
functions as if they were natively built-in.
Finally, the ICA-lib provides a collection of services, each of which offers
C++ classes and interfaces that implement speciﬁc functionalities to handle
inﬁnite, ﬁnite, and inﬁnitesimal quantities, as well as associated computa-
tions.
Fig. 2 The Simulink-based Inﬁnity Computer solution (SSIC) and its functional block
modules

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
321
3.3
Arithmetic Blocks Module
The Arithmetic Blocks Module (ABM) is described in this section. It includes
different blocks speciﬁcally deﬁned to perform arithmetic operations on inﬁ-
nite, ﬁnite, and inﬁnitesimal numbers, such as Sum, Subtraction, Multiplica-
tion and Division. All the ABM blocks accept as input two arguments x, y,
which are speciﬁed as follow:
x =
⎡
⎢⎢⎣
x0 p0
x1 p1
· · ·
xN pN
⎤
⎥⎥⎦, y =
⎡
⎢⎢⎣
y0 q0
y1 q1
· · ·
yN qN
⎤
⎥⎥⎦,
(3)
where N is the maximum precision used to perform arithmetic operations.
This number determines the number of rows in the matrix representation (2)
of each grossnumber (1). It is a conﬁguration parameter deﬁned within each
block, and its value is set to 20 by default.
The precision of the Inﬁnity Computer is speciﬁed through the parameter
n,
n
≤N, which can be conﬁgured in the “n_conﬁguration.m” ﬁle.
The x, y arguments represent the grossnumbers
x = x0①p0 + x1①p1 + · · · + xN①pN ,
y = y0①q0 + y1①q1 + · · · + yN①qN .
(4)
The result of the applied operation is a matrix z ∈RN×2:
z = z0①γ0 + z1①γ1 + · · · + zN①γN ,
(5)
where z has dimension and number of elements according to the Inﬁnity
Computer algebra (see [45]), where the ﬁrst n rows are signiﬁcant, whereas
the remaining N −n ones are null.
For each ABM block, the speciﬁc function and an example showing its
application are presented, hereinafter.
Sum. This block adds the values of its inputs. The Simulink model depicted
in Fig.3a adds the grossnumbers A = 4①0 + 2①−1 and B = 1①1 + 3①0 +
4①−1. After running the simulation, the result C = 1①1 + 7①0 + 6①−1 is
displayed using the standard Display block.
The grossnumbers A, B, and C are deﬁned as:

322
A. Falcone et al.
(a)
(b)
(c)
(d)
Fig. 3 Simulink models that perform addition (a), subtraction (b), multiplication (c),
and division (d) of the grossnumbers A = 4①0 + 2①−1 and B = 1①1 + 3①0 + 4①−1
A =
K

i=1
aki①ki, B =
M

j=1
bm j①m j, C =
L

i=1
cli①li.
(6)
According to the Inﬁnity Computer arithmetic (see [50]), the result C is
determined by including both the items of A, aki①ki : ki ̸= m j with 1 ≤j ≤
M and the ones of B, bm j①m j : m j ̸= ki with 1 ≤i ≤K, and the terms with
the same grosspower (ali + bli)①li.
Subtraction. This block subtracts the grossnumbers provided in input. This
operation is a direct result of the Sum block explained above. Figure3b depicts
a Simulink model that executes the subtraction of A = 4①0 + 2①−1 and B =
1①1 + 3①0 + 4①−1. By using the Display block, the result C = −1①1 +
1①0 −2①−1 is displayed.
Multiplication. This block multiplies the values of its inputs. Figure3c
depicts a Simulink model that performs the multiplication operation between
the grossnumbers A = 4①0 + 2①−1 and B = 1①1 + 3①0 + 4①−1. The Dis-
play block displays the outcome of the multiplication C = 4①1 + 14①0 +
22①−1 + 8①−2, which is deﬁned as follow:
C =
M

j=1
C j,
1 ≤j ≤M,
(7)
where C j = bm j①m j · A = K
i=1 akibm j①ki+m j.
Division. This block divides the values of its inputs. The Simulink model
depicted in Fig.3d carry out the division operation between the gross-
numbers A = 4①0 + 2①−1 and B = 1①1 + 3①0 + 4①−1. The grossnumber

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
323
C = 4①−1 −10①−2 + 14①−3 −2①−4... that is the result of the operation
is shown by a Display block.
The division operation C = A/B yields to a result C and a reminer R,
with the ﬁrst grossdigits ckK = alL/bmM and the maximum exponent kK =
lL −mM.
The ﬁrst partial reminder R∗is calculated as: R∗= A −ckK ①kK · B. The
calculation ends when either R∗= 0 or the default accuracy is reached; oth-
erwise, the number A is replaced with R∗and the computation process starts
again (see [50]).
3.4
Elementary Blocks Module
The Elementary Blocks Module (EBM) provides common elementary func-
tions, such as sine, cosine, exponential, and logarithm.
The truncated Taylor series has been used to implement each elementary
function f (x):
f (x) = f (x0) +
N

i=1
di f (x0)
dxi
(x −x0)i
i!
,
(8)
where x0 denotes a ﬁnite ﬂoating-point number. For each elementary func-
tion f (x), where f (x) ∈{sin(x), cos(x), exp(x), log(x), x p (p is ﬁnite),
√x}, its Taylor expansion (8) is known as well as the analytical formulae for
the respective derivatives di f (x0)
dxi
that is simple to implement. For each f (x),
except x p and log(x), the value x0 is selected as the ﬁnite part of the input x
even if this ﬁnite part is equal to 0. Since the functions x p and log(x) are not
differentiable at the point x0 = 0, the value x0 was chosen as the ﬁnite part
of x, if it is different from 0, and 0.1 otherwise (the number 0.1 was chosen
to be neither too small nor too large and to keep the computations also in the
case, when x0 = 0). Since the number x and the numbers (x −x0) are gross-
numbers, then the computations in this Taylor expansion are performed using
the arithmetic operations implemented in the Inﬁnity Computer library. The
value N is the same as in (1), since the resulting value f (x) at a grossnumber
x is also a grossnumber of the form (1).
All the EBM blocks accept one argument x as input (except the block Pow,
which implements the function x p and takes the second input p speciﬁed as
a standard ﬂoating-point number), which is deﬁned as follows:

324
A. Falcone et al.
x =
⎡
⎢⎢⎣
x0 p0
x1 p1
· · ·
xN pN
⎤
⎥⎥⎦,
(9)
where N is the conﬁguration parameter that has the same meaning as pre-
viously. The real precision of the Inﬁnity Computer is also deﬁned by the
parameter n (i.e., the rows in (9) starting from the (n + 1)-th contain only
zeros).
In this solution, the expansions (8) are only relevant if the input x is not
inﬁnite; otherwise, the Taylor series diverges. If these elementary functions
should be evaluated also in the inﬁnite points x, then other implementations
should be exploited (e.g., Newton’s method).
Sin. The trigonometric sine of an argument x given as a grossnumber
is computed by this block. The standard C + + library math.h is used to
calculate the values ± sin(x0) and ± cos(x0), which are the corresponding
derivatives used in the Taylor formula (8). Figure4a depicts a Simulink model
that calculates sin(4①0 + 2①−1). The result −0.7568①0 −1.307①−1 +
1.514①−2... is shown through a Display block.
Cos. The trigonometric cosine of an argument x given as a grossnumber
is computed by this block. The values ± sin(x0) and ± cos(x0) that represent
the derivatives used in the Taylor formula (8) are calculated using the library
math.h. The computation cos(4①0 + 2①−1) is performed by the Simulink
model depicted in Fig.4b, where the result of the computation −0.6536①0 +
1.514①−1 + 1.307①−2... is shown by a Display block.
Exp. This block calculates the base-e exponential function of a grossnum-
ber x, which is e raised to the power x : ex. The value exp(x0), which rep-
resents the respective derivative used in the Taylor formula (8), is calculated
using the library math.h. A Simulink model that performs the computation
e(4①0+2①−1) is shown in Fig.4c, where the result 54.6①0 + 109.2①−1 +
109.2①−2... is shown by a Display block.
Log. The natural logarithm of a grossnumber x is calculated by this block.
The values log(x0) and x p
0 , where p is ﬁnite, used for the computation of the
respective derivatives in the Taylor formula (8) are calculated using the library
math.h. Figure4d shows a Simulink model that executes the computation
log(4①0 + 2①−1). A Display block displays the result 1.386①0 + 0.5①−1 −
0.125①−2 + 0.0416①−3... of the computation.
Pow. This block uses the function x p that returns the base x raised to the
power p. The values xq
0 , where q are ﬁnite, are computed using the library
math.h for the computation of the respective derivatives in the Taylor formula
(8). The value p is speciﬁed as a standard ﬂoating-point number. Figure4e

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
325
(a)
(b)
(c)
(d)
(e)
(f)
Fig. 4 Simulink models that perform the trigonometric function sin x (a), the trigono-
metric function cos x (b), the base-e exponential function ex (c), the natural logarithm
log x (d), the base x to the exponent power p, x p, where p = −3.5 (e), and the square
root √x (f) of the grossnumber x = 4①0 + 2①−1
Fig. 5 Implementation of the Pythagorean trigonometric identity sin2 x + cos2 x = 1
using the presented blocks. The identity is satisﬁed even on matrix-type input of the form
(2)
depicts a Simulink model that performs the computation (4①0 + 2①−1)−3.5.
A Display block shows the result 0.0078①0 −0.0136①−1 + 0.0153①−2 −
0.0141①−3 of the computation.
Sqrt. This block has been added for convenience in calculations. It
exploits the block Pow to return the square root of a grossnumber x :
√x = x1/2. Figure4f shows a Simulink model that performs the compu-
tation

(4①0 + 2①−1). A Display block shows the result 2①0 + 0.5①−1 −
0.0625①−2... of the computation.

326
A. Falcone et al.
An example of using of the above mentioned blocks is presented in Fig.5.
Here, an illustrative example with the Pythagorean trigonometric identity
sin2 x + cos2 x = 1 is provided. One can see that the implementation of the
sine and cosine functions is correct and maintains the main identity prop-
erty even on matrix-type input of the form (2). The result of the operations
sin2 x + cos2 x is also given in the form (2) and consists of the ﬁnite part
only: [1 0] (additional zero rows are added just to maintain the ﬁxed size of
the inputs/outputs and can be removed, if the output is variable-size).
3.5
Utility Blocks Module
The Utility Blocks Module (UBM) offers common utility function blocks
necessary for enabling the realization of models according to the Inﬁnity
Computer solution and making them compatible with the Simulink envi-
ronment. The provided blocks are: Continuous2Discrete, ﬁllGrossnumber,
toGross, and getFinitePart.
Continuous2Discrete. This block allows one to set the Sample Time to
Discrete for all variable size blocks and Signals. It enables the sampling of
time as a discrete numerical value. The generated value is used to update the
blocks’ internal states throughout the simulation execution.
ﬁllGrossnumber. This block adds zero rows to the matrix representation
of its input in order to ﬁx the size of all variables (by default, the size of all
variables expressed as grossnumbers is 20 by 2, i.e. the number N from (2)
is set to 20). More in detail, given a matrix M ∈Rn×m with m = 2 and i < n
signiﬁcant rows, the function adds an k-by-m rows of zeros, where k = n −i
to ﬁll M.
This block is required, for example, to handle Simulink models containing
algebraic loops where variable size variables are not allowed.
toGross. This block converts a ﬁnite ﬂoating-point number x into its matrix
representation
x 0	
from (2). The resulting matrix is compatible with SSIC
and therefore can be used as input for the other provided blocks.
getFinitePart. This block returns the ﬁnite part of a grossnumber x as
a standard ﬂoating-point number. For instance, given x =
⎡
⎣
3
1
6
0
4.1 −5
⎤
⎦, this
block returns the value 6, while for y =

 3
2
3.1 −1

the result is 0.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
327
(a)
(b)
(c)
(d)
(e)
Fig. 6 Simulink models that perform the inﬁnitesimal pertubation of x (a), the extraction
of the derivatives from the value of the function f (x0 + ①−1) (b), the extraction of a
speciﬁc N−th derivative from the value f (x0 + ①−1) (c), the computation of the Lie
derivatives for ODE (d), and the Taylor series at the point t around the point t0 using the
value y0 = f (t0) and the ﬁrst N derivatives speciﬁed in the vector derivs (e) [27]
3.6
Differentiation Blocks Module
The Differentiation Blocks Module (DBM) offers a collection of blocks and
subsystems for handling higher order differentiation of a function imple-
mented through Simulink standard blocks. Speciﬁcally, DBM provides ﬁve
blocks that are: (i) Inﬁnitesimal Pertubation, (ii) Extract All Derivatives, (iii)
Extract One Derivative, (iv) Lie Derivatives Subsystem, and (v) Taylor Series.
Inﬁnitesimal Pertubation. This block adds the inﬁnitesimal pertubation
①−1 to its input x : y = x + ①−1 whether x is speciﬁed; otherwise the block
produces as output y = ①−1. The structure of this block is depicted in Fig.6a,
where the input and output are both supplied as grossnumbers in matrix form.
The input x0 is not mandatory; this means that, if it is not provided the output
returns the grossnumber ①−1 in matrix form.

328
A. Falcone et al.
Extract All Derivatives. This block extracts derivatives from the value of
the function f (x0 + ①−1) (see, Fig.6b). It takes as input two arguments:
f _cur and N. The ﬁrst one is a grossnumber deﬁned according to Eq.2;
whereas N represents the number of derivatives to calculate. The output is
the vector of the ﬁrst N derivatives
[ f (x0), f ′(x0), f ′′(x0), f (3)(x0), ..., f N(x0)],
where each element of the vector is an IEEE 754 binary64 ﬂoating-point
number (see [1]).
The computation of the ﬁrst N derivatives of f (x), at the point x0, is
performed by this block as follows. First, the value of the function f (x) at
the point x = x0 + ①−1 is calculated:
f (x0 + ①−1) = f (x0) + f ′(x0) · ①−1 + · · · + f (N)(x0)
N!
· ①−N + O(①−N−1),
(10)
where the coefﬁcient of ①−i provides the exact i−th derivative of f (x)
divided by i! (O(∼) represents the standard Big O notation).
f (i)(x0) = Get FinitePart( f (x0 + ①−1) · ①i · i!),
(11)
All the operations are performed using the ABM module and the utility
block Get FinitePart. Since all derivatives of order i, i = 1, 2, ..., N, are
extracted, the computational procedure has been designed in order to avoid
the computation of the factorials i! at each stage as presented in Algorithm
13.1 (see [27, 46] for details).
Figure7 shows a Simulink model that computes the ﬁrst N derivatives
of a univariate function f (x) at a ﬁnite point x0 using the blocks Inﬁnites-
imal Perturbation and Extract All Derivatives presented above. The model
receives the input x0 as an IEEE 754 binary64 ﬂoating-point number, which
is converted by the toGross block to the corresponding grossnumber. After
that, the inﬁnitesimal quantity ①−1 is added to the value of x0 using the
block “Inﬁnitesimal Perturbation”, yielding the value y = x0 + ①−1. The
result y of this addition operation is given as input to the objective function
f (x), which is designed using the SSIC blocks. Then, the result f (y) with

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
329
Fig. 7 The Simulink model for computation of the ﬁrst N derivatives of a univariate
function f (x) at the ﬁnite point x0. The input x0 is given as a ﬁnite IEEE 754 binary64
ﬂoating-point number, the output of the objective_ f unction block is represented in the
matrix form as in [25, 26], the output Derivatives is given as a ﬁnite ﬂoating-point
vector [ f (x0), f ′(x0), f ′′(x0), f (3)(x0), ..., f N(x0)] [27]
the number of the desired derivatives N is moved to the block “Extract All
Derivatives”, where the values of the N derivatives are calculated according
to (11).
Extract One Derivative. This block is similar to the Extract All Derivatives
one, except that the Extract One Derivative block extracts just one derivative
of order N, which is speciﬁed through the input argument N, from the result
of the function f (x0 + ①−1). The structure of this block is shown in Fig.6c.
The block’s inputs are the same as for the Extract All Derivatives, while the
output is a ﬁnite IEEE 754 binary64 ﬂoating-point number.
Lie Derivatives Subsystem. This subsystem calculates Lie derivatives in
the ﬁeld of numerical solution to ODEs, where the ﬁrst derivative of the
unknown function y(t) is given by the function f (t, y(t)). More in detail,
this block allows one to calculate the ﬁrst N total derivatives of the function
f (t, y(t)), which are the ﬁrst N + 1 derivatives of y(t) at the point t0. The
structure of the block is depicted in Fig.6d along with its inputs, which are
supplied as standard ﬁnite IEEE 754 binary64 ﬂoating-point numbers. The
output of this block is a vector containing the ﬁrst N Lie derivatives of f (t, y)
at (t0, y0)
[D0 f (t0, y0), D1 f (t0, y0), ..., DN f (t0, y0)],
where each element of the vector is an IEEE 754 binary64 ﬂoating-point
number [1].
Because the computing method for the Lie derivatives is more complex
to implement w.r.t. the other differentiation techniques, this subsystem was
built differently w.r.t. the previous blocks. Speciﬁcally, the user who wishes
to apply this subsystem should specify not only the required inputs, but also
the function f (t, y) in the appropriate computational block. The detailed
description of this block is given in Fig.8, where the Simulink models for

330
A. Falcone et al.
Fig. 8 The Simulink models based on SSIC for computation of the ﬁrst N Lie derivatives
of a function f (t0, y0). Before the main computational system (shown at the top of the
ﬁgure), the initial values should be generated and written to the global variable y_current
(see the subsystem on the left and bottom). The subsystem Euler Step performs the Euler
steps (12) and is described at the bottom and right of the ﬁgure [27]
computation of the ﬁrst N Lie derivatives of the function f (t, y) (given by
the block f (t, y))3 at the initial value (t0, y0) are presented.
First, the initial conditions t0 and y0 being the ﬁrst two inputs of this
computational system are transformed to the grossnumbers and stored in the
Data Store Memory “y_current” (see the bottom and left of Fig.8). The
value f (t0 + k · ①−1, yk) is then computed in the block f (t, y) within the
loop f or k = 1 : N block. Following that, the values yk are computed at the
subsystem Euler Step (described at the bottom and right of the ﬁgure):
yk = yk−1 + ①−1 f (yk−1), k = 1, ..., N.
(12)
At the same time, f (t0 + k · ①−1, yk) are transferred to the Compute Dif-
ferences block, where these values are stored and the associated forward
differences and Lie derivatives Dk f (y0) are calculated (see [27, 35, 36]):
3 The function f is considered as non-autonomous to avoid unnecessary computations
of the higher order derivatives w.r.t. t.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
331
Dk f (y0) = y(k+1)(t0) = ①k · Fk
①−1( f (t0, y0), ..., f (tk, yk)) + O(①−1), k = 1, ..., N,
(13)
Fk
①−1( f (t0, y0), ..., f (tk, yk)) =
k

i=0
(−1)i
k
i

f (tk−i, yk−i).
(14)
When the f or loop ﬁnishes its work, the Compute Differences block returns
the
values
of
the
Lie
derivatives.
Matlab
functions
join_values
(explore_values) are needed only to join separate variables t and y to
one vector [t, y] (and to explore the vector [t, y] to two separate values t
and y, respectively). The submodule Compute Differences contains Matlab
functions, which calculate the respective backward difference and return the
values of the derivatives. When the f or loop ends, the Compute Differ-
ences block returns the values of the Lie derivatives. The Matlab functions
join_values(explore_values) are required to join the single variables t and
y into a single vector [t, y] (and to explore the vector [t, y] to two independent
values t and y, respectively). The submodule Compute Differences provides
Matlab functions to compute the respective backward difference and return
the values of the derivatives.
Taylor Series. This block computes the Taylor series of a function f (t) at
the point t around the point t0 using the function’s value y0 = f (t0) and the
ﬁrst N derivatives of the function f (t) (calculated, e.g., using the previously
deﬁned differentiation blocks). The structure of this block is depicted in
Fig.6e. This block has ﬁve inputs and one output that are:
• N. Number of the used derivatives;
• t. The point at which the Taylor series should be calculated;
• t0. The initial point around which the Taylor series is calculated;
• y0. The value of the function to be approximated at the point t0;
• derivs. The vector of the ﬁrst N derivatives;
• y. The output of the block as a ﬁnite IEEE 754 binary64 ﬂoating-point
number.
4
Assessment and Evaluation
Three series of numerical experiments have been carried out to study and
evaluate the proposed solution. All the experiments have been performed on
a computer with the Windows 10 operating system, an i7-8550U processor,
8 GB of RAM, and the Matlab version 2016b. All the arithmetical operations
have been calculated according to the IEEE 754-1985 binary ﬂoating-point
standard using double precision.

332
A. Falcone et al.
Fig. 9 The Simulink submodules of the functions f1(x) from (16) deﬁned by using SSIC
[27]
4.1
Differentiation of a Univariate Function
In the ﬁrst series of the experiments introduced in [27], the ﬁrst derivative
has been calculated through SSIC using (11) and numerically using the cen-
tral difference with ﬁnite steps h implemented manually (let us recall that
in Simulink, only the backward difference w.r.t. the time variable t is imple-
mented internally):
f ′(x) ≈Fh
c (x) = f (x + h) −f (x −h)
2h
,
(15)
The ﬁrst three test functions fi(x), i = 1, 2, 3 delineated in [54] and the
function f4(x) =
f3(x)
1+ f2(x) have been considered:
f1(x) = 1
6x6 −52
25x5 + 39
80x4 + 71
10x3 −79
20x2 −x + 0.1,
f2(x) = sin(x) + sin(10x
3 ),
f3(x) = −5
i=1 i sin[(i + 1)x + i],
f4(x) =
f3(x)
1+ f2(x).
(16)
The Simulink implementations of these functions implemented by using
SSIC are shown in Figs.9 and 10 (for the functions f1(x) and f2(x), respec-
tively) and Fig.11 (for the function f3(x)). Concerning the function f4(x), its
Simulink implementation is omitted, since it follows from the implementa-
tions of the functions f2(x) and f3(x) and includes only two basic operations
between them.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
333
Fig. 10 The Simulink submodules of the function f2(x) from (16) deﬁned by using
SSIC [27]
Fig. 11 The Simulink subsystem of the function f3(x) from (16) deﬁned through SSIC
[27]
For each test function, the following values of the steps h have been
used: 10−1, 10−2,...,10−15. Then, the ﬁrst derivative of each test function
has been computed by both the Inﬁnity Computer and numerically using
(15) at each point xi = i · 10−3, i = 0, ..., 103. Following that, the Normal-
ized Root Mean Square Errors (NRMSE) have been determined for each test
problem as reported below:
N RMSE =

1
Ntrials
Ntrials
i=1
(yapprox
i
−yexact
i
)2
max
i=1,...,Ntrials
yexact
i
−
min
i=1,...,Ntrials
yexact
i
,
(17)
where yapprox
i
is the approximation of the ﬁrst derivative at the point xi
obtained by SSIC (let us call them y′
IC(xi), hereinafter) and by the central

334
A. Falcone et al.
Table 1 NRMSE’s obtained by SSIC (11) and by the Central Difference (15) for each
test function fi(x), i = 1, 2, 3, 4
Differentiation using SSIC
f ′
1(x)
f ′
2(x)
f ′
3(x)
f ′
4(x)
2.1e-16
5.8e-17
1.6e-16
1.6e-16
Differentiation using (15) with the stepsize h
h
f ′
1(x)
f ′
2(x)
f ′
3(x)
f ′
4(x)
10−5
7.7e-11
6.4e-11
2.4e-10
3.4e-10
10−6
2.5e-11
1.3e-11
3.6e-11
3.1e-11
10−7
3.1e-10
1.3e-10
3.5e-10
3.1e-10
differences from (15) (let us call them y′
NU M(xi), hereinafter). The obtained
NRMSE values4 are reported in Table1.
As reported in Table1, SSIC allows one to calculate the ﬁrst derivative
of the presented functions on the interval [0, 1] exactly (i.e., up to machine
precision), while the central difference did not allow to obtain errors smaller
than 2.5 · 10−11, 1.3 · 10−11, 3.6 · 10−11, and 3.1 · 10−11 for the functions
f1(x), f2(x), f3(x), and f4(x), respectively. Furthermore, one can see also
that errors started to grow for the values h < 10−6 due to numerical (mainly
cancellation) issues. However, for these test functions, the errors produced
by the central differences are always smaller than 10−1, which might be
acceptable for some applications. Figure12 shows the graphs of the NRMSE
values obtained by the central differences w.r.t. the stepsize h for a better
visualization of the obtained results.
4.2
Higher Order Differentiation of a Univariate Function
In the second series ofexperiments introduced in [27], the higherorder deriva-
tives calculated with SSIC (11) are compared with those obtained numerically
using the consecutive application of the internal Simulink block Derivative.
The ﬁrst ﬁve Pintér’s functions f pinter
i
(x) from [42] commonly used to evalu-
ate global optimization algorithms have been used as test functions. Figure13
shows the Simulink subsystem to evaluate the Pintér’s functions.
4 Only the results with the smallest errors obtained with h = 10 −5, 10 −6, 10 −7 for
the central difference are shown in Table1, while the remaining values are displayed in
Fig.12.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
335
10-15
10-12
10-9
10-6
10-3
10-1
Stepsize h
10-12
10-10
10-8
10-6
10-4
10-2
Normalized Root Mean Square Error
function f1(x)
function f2(x)
function f3(x)
function f4(x)
Fig. 12 Graphs of the NRMSE’s obtained by the Central Difference (15) for each test
function fi(x), i = 1, 2, 3, 4, w.r.t. the stepsize h [27]
Fig. 13 The Simulink subsystem based on SSIC of the Pintér’s functions f pinter
i
(x)
from [27, 42]
Table 2 Average NRMSE’s over the ﬁrst 5 Pintér’s test functions obtained by computa-
tion of the ﬁrst 5 derivatives on SSIC and by the consecutive application of the Simulink
blocks Derivative
t = 10−1
t = 10−2
t = 10−3
t = 10−4
t = 10−5
SSIC
Num
SSIC
Num
SSIC
Num
SSIC
Num
SSIC
Num
f ′
4.0e-17
2.5e-01
5.0e-17
2.6e-02
5.0e-17
2.6e-03
4.9e-17
2.6e-04
4.9e-17
2.6e-05
f ′′
6.6e-17
4.1e-01
6.5e-17
4.9e-02
6.3e-17
4.9e-03
6.3e-17
4.9e-04
6.4e-17
4.9e-05
f ′′′
4.9e-17
4.7e-01
5.1e-17
7.3e-02
4.9e-17
7.2e-03
4.9e-17
7.2e-04
4.9e-17
1.9e-03
f (4)
7.5e-17
4.9e-01
6.8e-17
8.8e-02
7.2e-17
8.9e-03
7.1e-17
4.3e-03
7.1e-17
2.8e+01
f (5)
6.8e-17
6.3e-01
6.8e-17
1.1e-01
6.3e-17
1.1e-02
6.3e-17
1.2e+01
6.3e-17
7.4e+05

336
A. Falcone et al.
For each test function, the ﬁrst ﬁve derivatives have been calculated by
using SSIC and the consecutive application of the Simulink Derivative
blocks at the points xi = t0 + i · t, i = 0, 1, ..., Ntrials, where t0 = 0,
Ntrials =
1
t , and t is the Simulink’s sample time value (ﬁxed sample
times have been used). The sample time t have been set to the following
values: 10−1, 10−2,...,10−5, whereas the values of xi have been calculated
through the Simulink internal block clock.
For each s−th test function and for each j−th derivative f ( j)
s
(xi), i=1, ...,
Ntrials, s, j = 1, ..., 5, the values N RMSEs, j have been calculated accord-
ing to (17). Then, for each j−th derivative, the average NRMSE’s have been
calculatedovertheﬁvetestfunctions: N RMSEavg, j = 1
5
5
s=1 N RMSEs, j.
Table2 and Fig.14 show the obtained results.
As reported in Table2, SSIC allows one to compute the higher order deriva-
tives of the Pintér’s functions up to machine precision, and the result is inde-
pendent of the sample time (for each derivative, the results obtained with
SSIC are different for various sample times t, since the grids xi on which
the derivatives’ values are calculated are different and depend on the sample
time t: xi = t0 + i × t, but the error order is the same in all the cases).
In their turn, the errors produced by the Simulink Derivative block are
sensitive to the choice of the sample time t. Since the Derivative block
employs the ﬁrst order backward difference, it is known that the differen-
tiation error is of order 1, implying that the error should decrease approxi-
mately with the same rate that the sample time t does. However, the error
decreases at the same rate for the 3−rd, 4−th, and 5−th derivatives until
the value t = 10−4 for the 3−rd derivative and t = 10−3 for the 4−th
and 5−th derivatives. If t decreases after these values, the error does not
decrease with the same rate or even starts to increase due to numerical (mostly
cancellation) issues.
For example, with t less than or equal to 10−4, the computation of
the ﬁfth derivative becomes not signiﬁcant due to large errors, while the
computation of the fourth derivative becomes not signiﬁcant with t less
than or equal to 10−5. Furthermore, for the ﬁrst ﬁve derivatives, numerical
differentiation using the block Derivative did not allow to obtain errors
less than 2.6 × 10−5, 4.9 × 10−5, 7.2 × 10−4, 4.3 × 10−3, and 1.1 × 10−2,
respectively.
Another crucial issue is the loss of information caused by the Derivative
blocks at the ﬁrst k points when computing the k−th derivative. This is
explained by the backward difference formula, which cannot be used at the
ﬁrst points, while SSIC is able to calculate derivatives at any ﬁnite point with-
out loss of information. The graphs of these average NRMSE’s are depicted
in Fig.14.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
337
10-5
10-4
10-3
10-2
10-1
Sample time
10-6
10-4
10-2
100
102
104
106
Average NRMSE
1st derivative
2nd derivative
3rd derivative
4th derivative
5th derivative
Fig. 14 Graphs of the average NRMSE’s over the ﬁrst 5 Pintér’s test functions obtained
by computation of the ﬁrst 5 derivatives by the consecutive application of the Simulink
blocks Derivative w.r.t. the sample time t [27]
It is also evident that the error coming from the Derivative blocks can be
reduced using different Simulink tools as, e.g., variable-step methods instead
of ﬁxed sample times. However, these tools do not overcome the numerical
issues discussed above; rather, they allow improving the accuracy but do not
ensure to obtain results up to machine precision.
4.3
Computation of the Lie Derivatives for ODEs
In the third series of the experiments introduced in [27], the ﬁrst ﬁve test
problems from [55] have been considered. Each test problem is made up of
an ODE of the form:

y′(t) = f (y(t)),
y(t0) = y0,
(18)
where y ∈Rn, f : Rn →Rn, t ∈R.
The solution y(t) of the corresponding ODE is a univariate function con-
tinuously differentiable inﬁnitely many times at the ﬁnite points t. Problems
3 and 5 are autonomous, while the remaining ones are not (in this cases, let
us refer to the function f (y) from the right side of the Eq.(18) as the func-
tion f (t, y), since y(t) is always univariate in these problems). The Simulink
models are presented in Fig.15.
Since the initial conditions delineated in [55] for each test problem are
too simple (speciﬁcally, all the conditions are y(0) = 1), then in this series

338
A. Falcone et al.
(a)
(b)
(c)
(d)
(e)
Fig. 15 The Simulink submodules of the ODE’s right-side functions fi(t, y), i =
1, ..., 5, from [55] deﬁned through SSIC. Test functions f3(t, y) and f5(t, y) (shown
in c and e, respectively) are autonomous (i.e.,they do not depend on t), while the func-
tions f1(t, y), f2(t, y), and f4(t, y) (shown in a, b, and d, respectively) are not [27]
of the experiments, the initial conditions were generated at the point t0 = 1,
maintaining the same solution of each ODE as in [55].
Traditionally, there are numerous numerical methods accessible in Matlab
for computing higher order Lie derivatives of the right-side functions f (y)
from (18) (e.g., using Matlab’s Symbolic computations or other available
automated differentiation algorithms). For example, in the recent work [36],
Matlab’s symbolic toolbox and ADiGator (see [56]) have been investigated.
It has been shown that these methods are inefﬁcient, since they require the use
of higher order tensors and, as a consequence, a large amount of processing
resources, particularly, in the case of high dimensions and complex functions.
Thus, because there is no method in Simulink for computing exact Lie deriva-
tives without using complicated formulas involving higher order tensors (see
[36] for details), then with the aim of showing the potential and the advan-
tages of SSIC in differentiation of the solution to the initial value problems,
we do not compare the presented computational method with another tech-
niques. Instead, let us compare the Taylor f or the Inf inity Computer
(TIC) method proposed in [55], which is the simplest method that uses the
exact values of the derivatives, with the standard numerical methods avail-
able in Simulink that use ﬁxed stepsizes: Runge-Kutta of order 4 (ODE4) and

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
339
Table 3 Relative errors obtained by the internal Simulink numerical methods Runge-
Kutta (ODE4) and Dormand-Prince (ODE5 and ODE8) and by the TIC using 4, 5, 8, and
15 derivatives, respectively, at the points ti = 1.05, 1.1, 1.15, and 1.2 for the ﬁrst 5 test
problems from [55]
N
t
EO DE4
ET IC4
EO DE5
ET IC5
EO DE8
ET IC8
ET IC15
1
1.05
4.4e-16
2.5e-09
3.0e-16
2.1e-11
3.0e-16
1.5e-16
1.5e-16
1.10
5.8e-16
7.9e-08
5.8e-16
1.3e-09
5.8e-16
2.9e-15
2.9e-16
1.15
7.1e-16
5.8e-07
8.5e-16
1.5e-08
8.5e-16
9.8e-14
2.8e-16
1.20
1.2e-15
2.4e-06
5.5e-16
7.9e-08
5.5e-16
1.3e-12
1.4e-16
2
1.05
7.3e-16
3.9e-09
2.4e-16
3.2e-11
2.4e-16
1.2e-16
1.2e-16
1.10
2.0e-15
1.2e-07
4.5e-16
2.0e-09
4.5e-16
3.5e-15
3.4e-16
1.15
2.1e-15
8.5e-07
2.1e-16
2.1e-08
2.1e-16
1.4e-13
0.0e+00
1.20
3.0e-15
3.4e-06
4.0e-16
1.1e-07
4.0e-16
1.8e-12
4.0e-16
3
1.05
1.6e-16
2.5e-09
1.6e-16
2.1e-11
1.6e-16
1.6e-16
1.6e-16
1.10
1.0e-15
7.7e-08
5.9e-16
1.3e-09
5.9e-16
2.5e-15
0.0e+00
1.15
8.4e-16
5.6e-07
0.0e+00 1.4e-08
0.0e+00 9.3e-14
0.0e+00
1.20
1.6e-15
2.3e-06
4.0e-16
7.5e-08
4.0e-16
1.2e-12
2.7e-16
4
1.05
3.7e-15
2.5e-09
1.6e-16
2.1e-11
1.6e-16
1.6e-16
1.6e-16
1.10
7.5e-15
7.7e-08
5.9e-16
1.3e-09
5.9e-16
2.5e-15
0.0e+00
1.15
1.2e-14
5.6e-07
0.0e+00 1.4e-08
0.0e+00 9.3e-14
0.0e+00
1.20
1.6e-14
2.3e-06
4.0e-16
7.5e-08
4.0e-16
1.2e-12
2.7e-16
5
1.05
1.3e-14
7.6e-08
0.0e+00 1.3e-09
0.0e+00 2.2e-15
2.2e-16
1.10
2.6e-14
2.3e-06
3.9e-16
7.5e-08
3.9e-16
1.1e-12
3.9e-16
1.15
3.9e-14
1.6e-05
1.8e-16
7.8e-07
1.8e-16
4.0e-11
1.8e-16
1.20
5.2e-14
6.1e-05
1.6e-16
4.0e-06
1.6e-16
4.8e-10
3.2e-16
Dormand-Prince of orders 5 and 8 (ODE5 and ODE8, respectively). All these
methods have been selected only for illustrative reasons: see, for example,
[2, 35, 55] for more complex algorithms employing exact higher order Lie
derivatives and a further detailed comparison between them.
First, the derivatives y(i)(t0), i = 1, ..., N, have been computed for each
test problem using (13). After that, the Taylor expansion has been recon-
structed:
yT IC,N(t) = y0 +
N

i=1
y(i)(t0)
i!
(t −t0)i.
(19)
Then, the sequence of points ti = t0 + h · i, i = 0, ..., Ntrials, has been
generated, where Ntrials = (t f −t0)/h, t f = 1.2, and h is the ﬁnite stepsize
that was set equal to 10−3. At each point ti, the values yT IC,N(ti) have been

340
A. Falcone et al.
calculated using N = 4, 5, 8, 15 (let us call the respective methods as TIC4,
TIC5, TIC8, and TIC15, hereinafter). On the grid ti, the methods ODE4,
ODE5, and ODE8 have been also applied with the same initial condition
(t0, y0). The values produced by these methods at each point ti are denoted
as yO DE,N(ti),where N = 4, 5, 8forthemethodsODE4,ODE5,andODE8,
respectively. Finally, relative errors Emethod(ti) = |ymethod(ti)−yexact(ti)|
|yexact(ti)
| have
been calculated at the points ti = 1.05, 1.1, 1.15, 1.2 for each method ∈
{T IC4, T IC5, T IC8, T IC15, O DE4, O DE5, O DE8}. The results are
presented in Table3, where it is possible to observe that the error produced
by the TIC4, TIC5, and TIC8 methods increases as the values of ti. increase.
However, for small time intervals, i.e., at the point t = 1.05, the error pro-
duced by TIC8 is the best among all methods, except for the last problem,
where it was higher than the errors of ODE8 and TIC15. In general, the
numerical methods ODE4, ODE5, and ODE8 yield less errors than the TIC
methods of the same order (the errors of ODE4 are better than the errors of
TIC4, the errors of ODE5 are better than the ones of TIC5, etc.). It is evi-
dent that more sophisticated than TIC methods should be exploited, when the
search interval is large and/or just a few number of derivatives can be calcu-
lated. In this case, TIC methods are inappropriate, because other numerical
methods of the same order are more “stable” (see Table3).
It should be emphasized that the application of TIC methods is appropriate
when higher order derivatives of the solution y(t) can be calculated efﬁciently
at the starting point t0. In this case, one can use a high-order TIC method
(e.g., order 15), for which the complexity is always constant: only a ﬁxed
numberofderivativesshouldbecalculatedattheinitialpoint.Theso-obtained
derivatives can be used to compute the Taylor series at any desired point t
without re-evaluating them. Traditionally, it is difﬁcult to built a numerical
method of a high order (e.g., of order 15); therefore lower order methods
are typically used with a smaller stepsize, requiring more computational
resources for their implementation. As reported in Table3, the method TIC15
gives the best error for all test problems, with the exception of the last one
at t = 1.2, where the error is slightly greater than the machine precision.
In this case, the TIC method generates a polynomial approximation that is
continuously differentiable up to 15-th order. It may also be computed at
any desired time t without having to re-evaluate the derivatives or system
functions.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
341
5
Conclusion
This chapter proposed the Simulink-based software solution to the Inﬁnity
Computer (SSIC), which allows one to use the Inﬁnity Computer arithmetic
within the Simulink environment for studying and analyzing dynamic sys-
tems. SSIC exploits the Inﬁnity Computer software simulator, which was
developed in C + + according to the patents (see [44]) and integrated in
the Simulink environment through MEX-ﬁles for low-level functionalities.
The proposed solution is user-friendly, general purpose, and domain inde-
pendent, i.e., it can be used in any domain where high precision computations
are required.
SSIC provides four functional modules, i.e., Arithmetic Blocks Module
(ABM), Elementary Blocks Module (EBM), Utility Blocks Module (UBM),
and Differentiation Blocks Module (DBM). The blocks provided by each
module can be used in the same way as their internal Simulink equivalents;
thus, no additional tools or sophisticated techniques are required.
The solution has been evaluated through three series of numerical exper-
iments involving high order differentiation. It has been shown that the com-
plexity of implementing functions using the proposed solution and traditional
Simulink blocks is the same, whereas SSIC allows one to use the potentiality
of the Inﬁnity Computer in Simulink without having to refer to the Inﬁnity
Computer’s low-level procedures.
Future research efforts will be directed to: (i) improve and extend the
proposed solution to support a wider set of concepts and operations offered by
the Inﬁnity Computer; (ii) conduct experiments with the solution in different
research domains.
References
1. IEEE Standard for Binary Floating-Point Arithmetic: ANSI/IEEE Std. 754–1985,
1–20 (1985). https://doi.org/10.1109/IEEESTD.1985.82928
2. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A
generalized Taylor method of order three for the solution of initial value problems
in standard and inﬁnity ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39
(2017)
3. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft Comput.
24(23), 17751–17759 (2020)
4. Baldwin, C.Y., Clark, K.B.: Modularity in the Design of Complex Engineering Sys-
tems, pp. 175–205. Springer, Berlin, Heidelberg (2006). https://doi.org/10.1007/3-
540-32834-3_9
5. Bocciarelli, P., D’Ambrogio, A., Falcone, A., Garro, A., Giglio, A.: A model-driven
approach to enable the simulation of complex systems on distributed architectures.

342
A. Falcone et al.
SIMULATION: Trans. Soc. Model. Simul. Int. 95(12) (2018). https://doi.org/10.
1177/0037549719829828
6. Bouskela, D., Falcone, A., Garro, A., Jardin, A., Otter, M., Thuy, N., Tundis, A.:
Formal requirements modeling for cyber-physical systems engineering: an integrated
solution based on form-l and modelica. Requirements Engineering (2021). https://
doi.org/10.1007/s00766-021-00359-z
7. Caldarola, F.: The exact measures of the Sierpinski d-dimensional tetrahedron in
connection with a diophantine nonlinear system. Commun. Nonlinear Sci. Numer.
Simul. 63, 228–238 (2018)
8. Caldarola, F., Maiolo, M.: On the topological convergence of multi-rule sequences
of sets and fractal patterns. Soft Comput. 24(23), 17737–17749 (2020)
9. Calude, C.S., Dumitrescu, M.: Inﬁnitesimal probabilities based on grossone. SN
Comput. Sci. (2020). https://doi.org/10.1007/s42979-019-0042-8
10. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexico-
graphic multi-objective mixed-integer linear programming problem using branch-
and-bound and grossone methodology. Commun. Nonlinear Sci. Numer. Simul. 84,
105177 (2020). https://doi.org/10.1016/j.cnsns.2020.105177
11. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective lin-
ear programming using grossone methodology: theory and algorithm. Appl. Math.
Comput. 318, 298–311 (2018). https://doi.org/10.1016/j.amc.2017.05.058
12. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput.
218(16), 8077–8082 (2012)
13. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. Soft Comput. 24(23),
17509–17515 (2020)
14. D’Ambrogio, A., Falcone, A., Garro, A., Giglio, A.: Enabling reactive streams in
HLA-based simulations through a model-driven solution. In: 23rd IEEE/ACM Inter-
national Symposium on Distributed Simulation and Real Time Applications, DS-RT
2019, Cosenza, Italy, October 7-9, 2019, pp. 1–8. Institute of Electrical and Elec-
tronics Engineers Inc. (2019). https://doi.org/10.1109/DS-RT47707.2019.8958697
15. De Leone, R.: Nonlinear programming and grossone: quadratic programming and
the role of constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
16. De Leone, R., Egidi, N., Fatone, L.: The use of grossone in elastic net regularization
and sparse support vector machines. Soft Comput. 24(23), 17669–17677 (2020)
17. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the
conjugate gradient breakdown in nonlinear programming. Comput. Optim. Appl.
71(1), 73–93 (2018)
18. Falcone, A., Garro, A.: Using the HLA standard in the context of an international
simulation project: The experience of the “smashteam”. In: 15th International Con-
ference on Modeling and Applied Simulation, MAS 2016, Held at the International
Multidisciplinary Modeling and Simulation Multiconference, I3M 2016, Larnaca,
Cyprus, September 26-28, 2016, pp. 121–129. Dime University of Genoa (2016)
19. Falcone, A., Garro, A.: A java library for easing the distributed simulation of space
systems. In: 16th International Conference on Modeling and Applied Simulation,
MAS 2017, Held at the International Multidisciplinary Modeling and Simulation
Multiconference, I3M 2017, Barcelona, Spain, September 18-20, 2017, pp. 6–13.
CAL-TEK S.r.l. (2017)
20. Falcone, A., Garro, A.: Reactive HLA-based distributed simulation systems with
RxHLA. In: 22nd IEEE/ACM International Symposium on Distributed Simulation
and Real Time Applications, DS-RT 2018, Madrid, Spain, October 15-17, 2018, pp.

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
343
1–8. Institute of Electrical and Electronics Engineers Inc. (2018). https://doi.org/10.
1109/DISTRA.2018.8600936
21. Falcone, A., Garro, A.: Distributed co-simulation of complex engineered systems
by combining the high level architecture and functional mock-up interface. Simul.
Model. Pract. Theory 97(August), 101967 (2019). https://doi.org/10.1016/j.simpat.
2019.101967
22. Falcone, A., Garro, A., Anagnostou, A., Taylor, S.J.E.: An introduction to develop-
ing federations with the high level architecture (HLA). In: 2017 Winter Simulation
Conference, WSC 2017, Las Vegas, NV, USA, December 3-6, 2017, pp. 617–631.
Institute of Electrical and Electronics Engineers Inc. (2017). https://doi.org/10.1109/
WSC.2017.8247820
23. Falcone, A., Garro, A., D’Ambrogio, A., Giglio, A.: Engineering systems by com-
bining BPMN and HLA-based distributed simulation. In: 2017 IEEE International
Conference on Systems Engineering Symposium, ISSE 2017, Vienna, Austria, Octo-
ber 11-13, 2017, pp. 1–6. Institute of Electrical and Electronics Engineers Inc. (2017).
https://doi.org/10.1109/SysEng.2017.8088302
24. Falcone, A., Garro, A., D’Ambrogio, A., Giglio, A.: Using BPMN and HLA for
engineering sos: lessons learned and future directions. In: 2018 IEEE International
Conference on Systems Engineering Symposium, ISSE 2018, Rome, Italy, October
1-3, 2018, pp. 1–8. Institute of Electrical and Electronics Engineers Inc. (2018).
https://doi.org/10.1109/SysEng.2018.8544399
25. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: Representation of
grossone-based arithmetic in simulink for scientiﬁc computing. Soft Comput. 24(23),
17525–17539 (2020). https://doi.org/10.1007/s00500-020-05221-y
26. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A simulink-based
inﬁnity computer simulator and some applications. In: 3rd International Conference
and Summer School ’Numerical Computations: Theory and Algorithms’, NUMTA
2019, Le Castella, Crotone, Italy, June 15-21, 2019, pp. 362–369. Springer Nature
Switzerland AG (2020). https://doi.org/10.1007/978-3-030-40616-5_31
27. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A simulink-based
software solution using the inﬁnity computer methodology for higher order differ-
entiation. Appl. Math. Comput. 125606 (2021). https://doi.org/10.1016/j.amc.2020.
125606
28. Falcone, A., Garro, A., Taylor, S.J.E., Anagnostou, A.: Simplifying the develop-
ment of HLA-based distributed simulations with the HLA development kit software
framework (DKF). In: 21st IEEE/ACM International Symposium on Distributed
Simulation and Real Time Applications, DS-RT 2017, Rome, Italy, October 18-20,
2017, pp. 216–217 (2017). https://doi.org/10.1109/DISTRA.2017.8167691
29. Falcone, A., Garro, A., Tundis, A.: Modeling and simulation for the performance
evaluation of the on-board communication system of a metro train. In: 13th Inter-
national Conference on Modeling and Applied Simulation, MAS 2014, Held at
the International Multidisciplinary Modeling and Simulation Multiconference, I3M
2014, Bordeaux, France, September 10-12, 2014, pp. 20–29. Dime University of
Genoa (2014)
30. Fiaschi, L., Cococcioni, M.: Numerical asymptotic results in game theory using
Sergeyev’s Inﬁnity Computing. Int. J. Unconvent. Comput. 14(1), 1–25 (2018)
31. Gangle, R., Caterina, G., Tohmé, F.: A constructive sequence algebra for the calculus
of indications. Soft Comput. 24(23), 17621–17629 (2020)

344
A. Falcone et al.
32. Garro, A., Falcone, A., Chaudhry, N.R., Salah, O., Anagnostou, A., Taylor, S.J.E.:
A prototype HLA development kit: Results from the 2015 simulation exploration
experience. In: 3rd ACM Conference on SIGSIM-Principles of Advanced Discrete
Simulation, ACM SIGSIM PADS 2015, London, United Kingdom, June 10-12, 2015,
pp. 45–46. Association for Computing Machinery Inc. (2015). https://doi.org/10.
1145/2769458.2769489
33. Garro, A., Falcone, A., D’Ambrogio, A., Giglio, A.: A model-driven method to
enable the distributed simulation of BPMN models. In: 27th IEEE International
Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises,
WETICE 2018, Paris, France, June 27-29, 2018, pp. 121–126. Institute of Electri-
cal and Electronics Engineers Inc. (2018). https://doi.org/10.1109/WETICE.2018.
00030
34. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.: Numerical inﬁnitesimals in
a variable metric method for convex nonsmooth optimization. Appl. Math. Comput.
318, 312–320 (2018)
35. Iavernaro, F., Mazzia, F., Mukhametzhanov, M., Sergeyev, Y.D.: Conjugate-
symplecticity properties of Euler-Maclaurin methods and their implementation on
the inﬁnity computer. Appl. Numer. Math. 155, 58–72 (2020). https://doi.org/10.
1016/j.apnum.2019.06.011
36. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation of
higher order lie derivatives on the inﬁnity computer. J. Comput. Appl. Math. 383,
113135 (2021)
37. MathWorks: Simulink home page (2019). https://www.mathworks.com/products/
simulink.html. Accessed 03 Dec 2019
38. Möller, B., Garro, A., Falcone, A., Crues, E.Z., Dexter, D.E.: Promoting a-priori
interoperability of HLA-based simulations in the space domain: The SISO space ref-
erence FOM initiative. In: 20th IEEE/ACM International Symposium on Distributed
Simulation and Real Time Applications, DS-RT 2016, London, UK, September 21-
23, 2016, pp. 100–107. Institute of Electrical and Electronics Engineers Inc. (2016).
https://doi.org/10.1109/DS-RT.2016.15
39. Möller, B., Garro, A., Falcone, A., Crues, E.Z., Dexter, D.E.: On the execution
controlofHLAfederationsusingtheSISOspacereferenceFOM.In:21stIEEE/ACM
International Symposium on Distributed Simulation and Real Time Applications,
DS-RT 2017, Rome, Italy, October 18-20, 2017, pp. 75–82. Institute of Electrical and
Electronics Engineers Inc. (2017). https://doi.org/10.1109/DISTRA.2017.8167669
40. Mukhametzhanov, M.S., Sergeyev, Y.D.: The inﬁnity computer vs. symbolic com-
putations: First steps in comparison. In: AIP Conference Proceedings, vol. 2293, p.
420045. AIP Publishing LLC (2020)
41. Pepelyshev, A., Zhigljavsky, A.: Discrete uniform and binomial distributions with
inﬁnite support. Soft Comput. 24(23), 17517–17524 (2020)
42. Pintér,J.D.:Globaloptimization:software,testproblems,andapplications.In:Parda-
los, P.M., Romeijn, H.E. (eds.) Handbook of Global Optimization, vol. 2, pp. 515–
569. Kluwer Academic Publishers, Dordrecht (2002)
43. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Uncon-
vent. Comput. 14(2), 139–158 (2019)
44. Sergeyev, Y.D.: Computer system for storing inﬁnite, inﬁnitesimal, and ﬁnite quanti-
ties and executing arithmetical operations with them. USA patent 7,860,914 (2010),
EU patent 1728149 (2009), RF patent 2395111 (2010)
45. Sergeyev, Y.D.: Arithmetic of Inﬁnity. Edizioni Orizzonti Meridionali, CS (2003,
2nd ed. 2013)

Adopting the Inﬁnity Computing in Simulink for Scientiﬁc Computing
345
46. Sergeyev, Y.D.: Higher order numerical differentiation on the inﬁnity computer.
Optim. Lett. 5(4), 575–585 (2011)
47. Sergeyev, Y.D.: Using blinking fractals for mathematical modelling of processes of
growth in biological systems. Informatica 22(4), 559–576 (2011)
48. Sergeyev, Y.D.: Solving ordinary differential equations by working with inﬁnitesi-
mals numerically on the inﬁnity computer. Appl. Math. Comput. 219(22), 10668–
10681 (2013)
49. Sergeyev, Y.D.: The exact (up to inﬁnitesimals) inﬁnite perimeter of the Koch
snowﬂake and its ﬁnite area. Commun. Nonlinear Sci. Numer. Simul. 31(1–3), 21–29
(2016)
50. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications,
and repercussions on two Hilbert problems. EMS Surv. Math. Sci. 4, 219–320 (2017)
51. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-
standard analysis and comments upon logical fallacies in some texts asserting the
opposite. Found. Sci. 24(1), 153–170 (2019)
52. Sergeyev, Y.D., Garro, A.: Single-tape and multi-tape Turing machines through the
lens of the Grossone methodology. J. Supercomput. 65(2), 645–663 (2013)
53. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: On strong homogeneity of a
class of global optimization algorithms working with inﬁnite and inﬁnitesimal scales.
Commun. Nonlinear Sci. Numer. Simul. 59, 319–330 (2018)
54. Sergeyev, Y.D., Mukhametzhanov, M.S., Kvasov, D.E., Lera, D.: Derivative-free
local tuning and local improvement techniques embedded in the univariate global
optimization. J. Optim. Theory Appl. 171(1), 186–208 (2016)
55. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.:
Numerical methods for solving initial value problems on the Inﬁnity Computer.
Int. J. Unconvent. Comput. 12(1), 3–23 (2016)
56. Weinstein, M., Rao, A.: Algorithm 984: Adigator, a toolbox for the algorithmic
differentiation of mathematical functions in matlab using source transformation via
operator overloading. ACM Trans. Math. Softw. 44(2) (2017)
57. Zhigljavsky, A.: Computing sums of conditionally convergent and divergent series
using the concept of grossone. Appl. Math. Comput. 218(16), 8064–8076 (2012)
58. Žilinskas, A.: On strong homogeneity of two global optimization algorithms based on
statistical models of multimodal objective functions. Appl. Math. Comput. 218(16),
8131–8136 (2012)

Addressing Ill-Conditioning in Global
Optimization Using a Software
Implementation of the Inﬁnity Computer
Marat S. Mukhametzhanov and Dmitri E. Kvasov
Abstract The present chapter studies the impact of scaling on global optimization
algorithms. In particular, the notion of strong homogeneity is under study. A method
is strongly homogeneous if it produces the same sequences of evaluation points
independently both of multiplication of the objective function by a scaling constant
and of adding a shifting constant. It is shown that even if a method possesses this
property theoretically, numerically very small and large scaling constants can lead to
ill-conditioning of the scaled problem. A new class of global optimization problems
where the objective function can have not only ﬁnite but also inﬁnite or inﬁnitesimal
Lipschitz constants is described. The strong homogeneity of several Lipschitz global
optimization algorithms is then addressed within the Inﬁnity Computing framework.
It is ﬁnally shown that the usage of numerical inﬁnities and inﬁnitesimals can in
certain cases avoid ill-conditioning produced by scaling.
1
Introduction
Global optimization problems are considered in this chapter. One of the desirable
properties of numerical global optimization methods (see [5, 19, 62, 67, 74]) is their
strong homogeneity: this means that a method produces the same sequences of trial
points (i.e., points where the objective function f (x) is evaluated) independently of
both shifting f (x) vertically and its multiplication by a scaling constant. Therefore,
the optimization of a scaled function
g(x) = g(x; α, β) = α f (x) + β,
α > 0,
(1)
M. S. Mukhametzhanov · D. E. Kvasov (B)
University of Calabria, Rende (CS), Italy
e-mail: m.mukhametzhanov@dimes.unical.it
D. E. Kvasov
Lobachevsky University of Nizhny Novgorod, Nizhny Novgorod, Russia
e-mail: kvadim@dimes.unical.it
© The Author(s), under exclusive license to Springer Nature Switzerland
AG 2022
Y. D. Sergeyev and R. De Leone (eds.), Numerical Inﬁnities and Inﬁnitesimals
in Optimization, Emergence, Complexity and Computation 43,
https://doi.org/10.1007/978-3-030-93642-6_14
347

348
M. S. Mukhametzhanov and D. E. Kvasov
instead of the original objective function f (x) can be useful. The concept of strong
homogeneity was introduced in [74] where it was shown that both the P-algorithm
(see [73]) and the one-step Bayesian algorithm (see [42]) are strongly homogeneous.
The case α = 1, β ̸= 0 was considered in [19, 67] where a number of homogeneous
methods enjoying this property were studied. Therefore, there exist global optimiza-
tion methods that are homogeneous or strongly homogeneous and algorithms (see,
for example, the DIRECT algorithm from [35] and a huge number of its modiﬁcations
as surveyed in [34, 35]) that do not possess this useful property.
The above-mentioned methods were developed for solving practically important
Lipschitz global optimization problems (see, e.g., [3, 27, 39, 43, 45, 55, 59, 67–69,
71, 72]) and belong to the class of “Divide-the-Best” algorithms as from [48] (see
also [31, 59]). The so-called geometric and information algorithms from this class
are considered in this chapter (see [59, 66–68]). The ﬁrst type of algorithms is based
on a geometrical interpretation of the Lipschitz condition and originates from [46]
where a piecewise linear minorant for the objective function was constructed using
the Lipschitz condition. The second approach is based on the information-statistical
algorithm proposed in [67] and uses a stochastic model to calculate probabilities of
locating global minimizers within subregions of the search domain (for other rich
ideas in stochastic global optimization see [71, 72, 74]). In both the cases, different
strategies to estimate global and local Lipschitz constants can be used (see, e.g., [46,
59, 63, 65–68]).
In this chapter, following the paper [62] (see also [37]) it will be shown that several
univariate methods using the local tuning on the objective function behaviour (as
surveyed, e.g., in [59, 63, 65]) enjoy the strong homogeneity property. Moreover,
it will be shown that this property is valid for the considered methods not only for
ﬁnite values of the constants α and β from (1) but for inﬁnite and inﬁnitesimal ones,
as well. A class of global optimization problems with the objective function having
inﬁnite or inﬁnitesimal Lipschitz constants is also described as in [62]. Numerical
computations with functions that can assume inﬁnite and inﬁnitesimal values are
executed using the Inﬁnity Computing paradigm: its comprehensive description can
be found in [49, 53] (it should be stressed that it is not-related to non-standard
analysis, see [54]). This computational methodology has already been successfully
applied in optimization and numerical differentiation [4, 9–11, 14–18, 20–22, 25,
32, 38, 51, 65] and in a number of other theoretical and applied research areas
such as, e.g., cellular automata [12, 13], hyperbolic geometry [41], percolation [33],
fractals [2, 6, 7, 52], inﬁnite series [50, 70], probability theory [8, 44], logic [24, 40,
47], Turing machines [56, 57], numerical solution of ordinary differential equations
[1, 64], etc. In particular, in the paper [25], grossone-based numerical inﬁnities and
inﬁnitesimals weresuccessfullyusedtohandleill-conditioninginamultidimensional
optimization problem.
The importance to have the possibility to work with inﬁnite and inﬁnitesimal
scaling/shifting constants α and β has an additional value due to the following fact
(see [62]). It can happen that when a (theoretically) strongly homogeneous method
is applied to the function g(x) from (1), numerically very small and/or large ﬁnite
constants α and β can lead to the ill-conditioning of the corresponding global opti-

Addressing Ill-Conditioning in Global Optimization …
349
mization problem due to overﬂow and/or underﬂow during the construction of g(x)
from f (x). Thus, global minimizers can change their locations and the values of
global minima can change, as well. As a result, applying even strong homogeneous
methods to solve these problems will lead to ﬁnding the changed values of minima
related to g(x) and not the desired global solution to the original function f (x) we
are interested in. As shown in [62], numerical inﬁnities and inﬁnitesimals and the
Inﬁnity Computing framework can help in this situation.
The rest of this chapter is structured as follows. Section2 states the problem for-
mally and discusses ill-conditioning induced by scaling. It is stressed that the intro-
duction of numerical inﬁnities and inﬁnitesimals allows us to consider a new class
of functions having inﬁnite or inﬁnitesimal Lipschitz constants. Section3 presents
geometric and information Lipschitz global optimization algorithms studied in this
chapter and shows how an adaptive estimation of global and local Lipschitz constants
can be performed. So far, the fact whether these methods are strongly homogeneous
or not was an open problem even for ﬁnite constants α and β until [62]. Section4
shows that these methods enjoy the strong homogeneity property for ﬁnite, inﬁnite,
and inﬁnitesimal scaling and shifting constants. Section5 describes how in certain
cases the usage of numerical inﬁnities and inﬁnitesimals can avoid ill-conditioning
produced by scaling and illustrates these results numerically. Finally, a brief conclu-
sion is given in Sect.6.
2
Problem Statement and Ill-Conditioning Induced by
Scaling
2.1
Lipschitz Global Optimization and Ill-Conditioning
Produced by Scaling
Let us consider a univariate global optimization problem where it is required to ﬁnd
the global minimum f ∗and global minimizers x∗such that
f ∗= f (x∗) = min f (x),
x ∈D = [a, b] ⊂R.
(2)
It is assumed that the objective function f (x) is multiextremal, non-differentiable,
and Lipschitz continuous over the interval D, i.e.,
| f (x1) −f (x2)| ≤L|x1 −x2|,
x1, x2 ∈D,
(3)
where L is the Lipschitz constant, 0 < L < ∞(see, e.g., [23, 28, 30, 36, 43, 58,
59, 61, 66, 68, 72]). In many situations, it can be required to optimize a scaled
function g(x) from (1) instead of the original objective function f (x) (see, e.g., [19,
67, 74]), thus giving rise to the study of strong homogeneity for global optimization
algorithms (as introduced in Sect.1).

350
M. S. Mukhametzhanov and D. E. Kvasov
As an illustration, let us consider the Pintér’s class of univariate test problems
from [45]. Each function fs(x), 1 ≤s ≤100, of this class is deﬁned over the interval
[−5, 5] and has the following form:
fs(x) = 0.025(x −x∗
s )2 + sin2[(x −x∗
s ) + (x −x∗
s )2] + sin2(x −x∗
s ),
(4)
where the global minimum f ∗is equal to 0 for all the functions and the global
minimizer x∗
s , 1 ≤s ≤100, is chosen randomly (and differently for each test func-
tion of the class) from the interval [−5, 5] (we used the random number generator
implemented in the GKLS-generator of multidimensional test classes from [26, 60]).
For example, let us consider the ﬁrst test function f1(x) of the class (4) with
x∗
1 = −3.9711481954 and take α = 10−8 and β = 108, thus obtaining the scaled
function
ˆg1(x) = 10−8 f1(x) + 108.
(5)
As can be seen in Fig.1a and b, the functions f1(x) and ˆg1(x) have completely differ-
ent minimizers due to the used scaling constants in ˆg1. As a result, if we wish to invert
the function ˆg1(x) trying to establish the original function f1(x), i.e., to compute the
function ˆf1(x) = ( ˆg1(x) −108)/10−8, then it will not coincide with f1(x). Figure1c
shows ˆf1(x) constructed from ˆg1(x) using piecewise linear approximations with step
h = 0.001. Due to underﬂows taking place in commonly used numeral systems, the
function ˆg1(x) degenerates in constant functions over several sub-intervals and many
local minimizers disappear (see, e.g., local minimizers from the interval [−3, −2]
in Fig.1a, b). On the other hand, due to overﬂows, several local minimizers become
global ones for the scaled function ˆg1(x). In particular, one can ﬁnd from Fig.1b,
c the following global solutions to the problems with the objective functions ˆg1(x)
and ˆf1(x): (x∗, ˆg∗
1) = (−5, 108) and (x∗, ˆf ∗
1 ) = (−5, 0), respectively, while it can
be seen from Fig.1a that the point x = −5 is not even a local minimizer.
This simple example shows that it does not make sense to talk about the strong
homogeneity property in case of very huge or very small ﬁnite values of constants α
and β in (1), since it is not possible to construct correctly the corresponding scaled
functions on the traditional computers. Within the Inﬁnity Computing paradigm
not only ﬁnite, but also numerical inﬁnite and inﬁnitesimal values of α and β can
be adopted and ill-conditioning of global optimization problems can be avoided in
certain cases.
2.2
Functions with Inﬁnite and Inﬁnitesimal Lipschitz
Constants
The introduction of the Inﬁnity Computer paradigm allows us to consider univariate
global optimization problems with the objective function g(x) from (1) that can
assume not only ﬁnite values, but also inﬁnite and inﬁnitesimal ones. Let us suppose

Addressing Ill-Conditioning in Global Optimization …
351
Fig. 1 Graphs of a the test function (4), b the scaled function ˆg1(x) from (5), c the inverted scaled
function ˆf1(x) = ( ˆg1(x) −108)/10−8. The form of the functions ˆg1(x) and ˆf1(x) is qualitatively
different with respect to that of the original function f1(x) due to overﬂows and underﬂows
that the original function f (x) assumes ﬁnite values only and satisﬁes condition (3)
with a ﬁnite constant L. Since in (1) the scaling/shifting parameters α and β can be
not only ﬁnite but also inﬁnite and inﬁnitesimal, the Inﬁnity Computing framework is
required to work with g(x). Thus, the following optimization problem is considered
min g(x) = min (α f (x) + β),
x ∈D = [a, b] ⊂R,
α > 0,
(6)
where the function f (x) can be multiextremal, non-differentiable, and Lipschitz
continuous with a ﬁnite value of the Lipschitz constant L from (3). In their turn, the
values α and β can be ﬁnite, inﬁnite, and inﬁnitesimal numbers representable in the
grossone-based numeral system.
The ﬁniteness of the original Lipschitz constant L from (3) is the essence of the
Lipschitz condition allowing people to construct optimization methods for traditional
computers.Thescaledobjectivefunction g(x)from(6)canassumenotonlyﬁnite,but
alsoinﬁniteandinﬁnitesimalvaluesand,therefore,inthesecasesitisnotLipschitzian
in the traditional sense. However, the Inﬁnity Computer paradigm extends the space
of functions that can be treated theoretically and numerically to functions assuming
inﬁnite and inﬁnitesimal values. This fact allows us to extend the concept of Lipschitz

352
M. S. Mukhametzhanov and D. E. Kvasov
functions to the cases where the Lipschitz constant can assume inﬁnite/inﬁnitesimal
values.
The rest of the chapter will follow the results from [62]. Hereafter, we will indicate
by“”all thevalues relatedtothefunction g(x) whiletheterms without “”will indicate
the values related to the function f (x). The following lemma shows an important
property of the Lipschitz constant for the objective function g(x).
Lemma 1 The Lipschitz constant L of the function g(x) = α f (x) + β, where f (x)
assumes only ﬁnite values and has the ﬁnite Lipschitz constant L over the interval
[a, b] and α, α > 0, and β can be ﬁnite, inﬁnite, and inﬁnitesimal, is equal to αL.
Proof The following relation can be obtained from the deﬁnition of g(x) and the
fact that α > 0
|g(x1) −g(x2)| = α| f (x1) −f (x2)|,
x1, x2 ∈[a, b].
Since L is the Lipschitz constant for f (x), then
α| f (x1) −f (x2)| ≤αL|x1 −x2| = L|x1 −x2|,
x1, x2 ∈[a, b],
and this inequality proves the lemma.
Thus, the new Lipschitz condition for the function g(x) from (1), (6) can be written
as
|g(x1) −g(x2)| ≤αL|x1 −x2| = L|x1 −x2|,
x1, x2 ∈D,
(7)
where the constant L from (3) is ﬁnite and the quantities α and L can assume inﬁnite
and inﬁnitesimal values. Notice that inﬁnities and inﬁnitesimals are expressed in ①
numerals, and Lemma 1 describes the ﬁrst property of this class.
Some geometric and information global optimization methods (see [45, 46, 59,
63, 66–68]) used for solving the traditional Lipschitz global optimization problem
(2) are adopted hereinafter for solving the problem (6). A general scheme describing
these methods is presented in the next section.
3
A General Scheme Describing Geometric and
Information Algorithms
Methods studied in this chapter have a similar structure and belong to the class
of “Divide-the-Best” global optimization algorithms from [48]. They can have the
following differences in their computational schemes:
(i) Methods are either Geometric or Information (see [59, 67, 68] for detailed
descriptions of these classes of methods);

Addressing Ill-Conditioning in Global Optimization …
353
(ii) Methods can use different approaches to estimate the Lipschitz constant: an
a priori estimate, a global adaptive estimate, and local tuning techniques, for
example, Maximum Local Tuning (MLT) and Maximum-Additive Local Tuning
(MALT) (see [59, 63, 68] for detailed descriptions of these approaches).
The ﬁrst difference, (i), consists of the choice of characteristics Ri [31] for subin-
tervals [xi−1, xi], 2 ≤i ≤k, where the points xi, 1 ≤i ≤k, are called trial points
and are points where the objective function g(x) has been evaluated during previous
iterations:
Ri =
 zi+zi−1
2
−li
xi−xi−1
2
,
for geometric methods,
2(zi + zi−1) −li(xi −xi−1) −(zi−zi−1)2
li(xi−xi−1), for information methods,
(8)
where zi = g(xi) and li is an estimate of the Lipschitz constant for subinterval
[xi−1, xi], 2 ≤i ≤k.
The second issue, (ii), is related to four different strategies used in this chapter to
estimate the Lipschitz constant L. The ﬁrst one is an a priori given estimate L > L.
The second way is to use an adaptive global estimate of the Lipschitz constant L
during the search (the word global means that the same estimate is used for the whole
region D). The global adaptive estimate Lk can be calculated as follows
Lk =
r · H k, if H k > 0,
1,
otherwise,
(9)
where r > 0 is a reliability parameter and
H k = max{Hi : 2 ≤i ≤k},
(10)
Hi = |zi −zi−1|
xi −xi−1
, 2 ≤i ≤k.
(11)
Finally, the Maximum (MLT) and Maximum-Additive (MALT) local tuning
techniques consist of estimating local Lipschitz constants li for each subinterval
[xi−1, xi], 2 ≤i ≤k, as follows
l MLT
i
=
r · max{λi, γi}, if H k > 0,
1,
otherwise,
(12)
l M ALT
i
=

r · max{Hi, λi+γi
2
}, if H k > 0,
1,
otherwise,
(13)
where Hi is from (11), and λi and γi are calculated as follows
λi = max{Hi−1, Hi, Hi+1}, 2 ≤i ≤k,
(14)

354
M. S. Mukhametzhanov and D. E. Kvasov
γi = H k (xi −xi−1)
Xmax
,
(15)
with H k from (10) and
Xmax = max{xi −xi−1 : 2 ≤i ≤k}.
(16)
Wheni = 2andi = k only H2, H3,and Hk−1, Hk,shouldbeconsidered,respectively,
in (14).
After these preliminary descriptions we are ready to describe the General Scheme
(GS) of algorithms studied in this chapter.
Step 0.
Initialization. Execute ﬁrst two trials at the points a and b, i.e., x1 := a,
z1 := g(a) and x2 := b, z2 := g(b). Set the iteration counter k := 2. Suppose that
k ≥2 iterations of the algorithm have already been executed. The iteration k + 1
consists of the following steps.
Step 1.
Reordering. Reorder the points x1, . . . , xk (and the corresponding function
values z1, . . . , zk) of previous trials by subscripts so that
a = x1 < . . . < xk = b,
zi = g(xi), 1 ≤i ≤k.
Step 2.
Estimates of the Lipschitz constant. Calculate the current estimates li of
the Lipschitz constant for each subinterval [xi−1, xi], 2 ≤i ≤k, in one of the
following ways.
Step 2.1.
A priori given estimate. Take an a priori given estimate L of the
Lipschitz constant for the whole interval [a, b], i.e., set li := L.
Step 2.2.
Global estimate. Set li := Lk, where Lk is from (9).
Step 2.3.
“Maximum” local tuning. Set li := l MLT
i
, where l MLT
i
is from (12).
Step 2.4.
“Maximum-Additive” local tuning. Set li := l M ALT
i
, where l M ALT
i
is
from (13).
Step 3.
Calculation of characteristics. Compute for each subinterval [xi−1, xi],
2 ≤i ≤k, its characteristic Ri by using one of the following rules.
Step 3.1.
Geometric methods.
Ri = zi + zi−1
2
−li
xi −xi−1
2
.
(17)
Step 3.2.
Information methods.
Ri = 2(zi + zi−1) −li(xi −xi−1) −(zi −zi−1)2
li(xi −xi−1).
(18)
Step 4.
Subinterval selection. Determine an interval [xt−1, xt], t = t(k), for per-
forming the next trial as follows

Addressing Ill-Conditioning in Global Optimization …
355
t = min arg min
2≤i≤k Ri.
(19)
Step 5.
Stopping rule. If
xt −xt−1 ≤ε,
(20)
where ε > 0 is a given accuracy of the global search, then Stop and take as an
estimate of the global minimum g∗the value g∗
k = min1≤i≤k{zi} obtained at a
point x∗
k = arg min1≤i≤k{zi}.
Otherwise,
go to Step 6.
Step 6.
New trial. Execute the next trial zk+1 := g(xk+1) at the point
xk+1 = xt + xt−1
2
−zt −zt−1
2lt
.
(21)
Increase the iteration counter k := k + 1, and go to Step 1.
4
Strong Homogeneity of Algorithms Belonging to General
Scheme with Finite, Inﬁnite, and Inﬁnitesimal Scaling
and Shifting Constants
In this section, we address the strong homogeneity of the previously described algo-
rithms both in the traditional and in the Inﬁnity Computing frameworks. We show
(as given in [62]) that methods belonging to the GS enjoy the strong homogeneity
property for ﬁnite, inﬁnite, and inﬁnitesimal scaling and shifting constants. Recall
that all the values related to the scaled function g(x) are indicated by “” and the
values related to the function f (x) are written without “”.
The following lemma establishes how the adaptive estimates of the Lipschitz
constantLk,l MLT
i
, andl M ALT
i
that can assume ﬁnite, inﬁnite, and inﬁnitesimal values
are related to the respective original estimates Lk, l MLT
i
, and l M ALT
i
that can be ﬁnite
only.
Lemma 2 Let us consider the function g(x) = α f (x) + β, where f (x) assumes
only ﬁnite values and has a ﬁnite Lipschitz constant L over interval [a, b] and α, α >
0, and β can be ﬁnite, inﬁnite and inﬁnitesimal numbers. Then, the adaptive estimates
Lk,l MLT
i
andl M ALT
i
from (9), (12) and (13) are equal to αLk, αl MLT
i
and αl M ALT
i
,
respectively, if H k > 0, and to 1, otherwise.
Proof It follows from (11) that

Hi = |zi −zi−1|
xi −xi−1
= α|zi −zi−1|
xi −xi−1
= αHi.
(22)

356
M. S. Mukhametzhanov and D. E. Kvasov
If H k ̸= 0, then H k = max
2≤i≤k
|zi−zi−1|
xi−xi−1 and H k ≥Hi, 2 ≤i ≤k. Thus, using (22) we
obtain αH k ≥αHi = 
Hi, and, therefore, 
H k = αH k and from (9) it follows Lk =
αLk. On the other hand, if H k = 0, then both estimates for the functions g(x) and
f (x) are equal to 1 (see (9)).
The same reasoning can be used to show the respective results for the local tuning
techniques MLT and MALT (see (12) and (13))
λi = max{ 
Hi−1, 
Hi, 
Hi+1} = α max{Hi−1, Hi, Hi+1},
γi = 
H k xi −xi−1
Xmax
= αH k xi −xi−1
Xmax
= αγi,
l MLT
i
=

r · max{λi,γi}, if 
H k > 0,
1,
otherwise.
l M ALT
i
=

r · max{ 
Hi,
λi+γi
2
}, if 
H k > 0,
1,
otherwise.
Therefore, we can conclude that
l{MLT,M ALT}
i
=

αl{MLT,M ALT }
i
, if H k > 0,
1,
otherwise.
Lemma 3 Suppose that characteristics Ri, 2 ≤i ≤k, for the scaled objective func-
tion g(x) are equal to an afﬁne transformation of the characteristics Ri calculated
for the original objective function f (x)
Ri = αk Ri + βk,
2 ≤i ≤k,
(23)
where the constants αk, αk > 0, and βk can be ﬁnite, inﬁnite, or inﬁnitesimal and
possibly different for different iterations k. Then, the same interval [xt−1, xt], t =
t(k), from (19) is selected at each iteration for the next subdivision during optimizing
f (x) and g(x), i.e.,
t(k) = t(k).
Proof Since, due to (19), t = arg min2≤i≤k Ri, then Rt ≤Ri and
αk Rt + βk ≤αk Ri + βk,
2 ≤i ≤k.
Due to (23), this can be re-written as
Rt = min
2≤i≤k
Ri = αk Rt + βk.

Addressing Ill-Conditioning in Global Optimization …
357
Notice that if there are several values j such that R j = Rt, then (see (19)) we have t <
j, j ̸= t, i.e., even in this situation it follows
t(k) = t(k). This observation concludes
the proof.
The following Theorem shows that methods belonging to the GS enjoy the strong
homogeneity property.
Theorem 1 Algorithms belonging to the GS and applied for solving the problem (6)
are strongly homogeneous for ﬁnite, inﬁnite, and inﬁnitesimal scales α > 0 and β.
Proof Two algorithms optimizing functions f (x) and g(x) will generate the same
sequences of trials if the following conditions hold:
(i) The same interval [xt−1, xt], t = t(k), from (19) is selected at each iteration for
the next subdivision during optimizing functions f (x) and g(x), i.e., it follows

t(k) = t(k).
(ii) The next trial at the selected interval [xt−1, xt] is performed at the same point
during optimizing functions f (x) and g(x), i.e., in (21) it follows xk+1 = xk+1.
In order to prove assertions (i) and (ii), let us consider computational steps of
the GS. For both functions, f (x) and g(x), Steps 0 and 1 of the GS work with the
same interval [a, b], do not depend on the objective function, and, as a result, do
not inﬂuence (i) and (ii). Step 2 is a preparative one, it is responsible for estimating
the Lipschitz constants for all the intervals [xi−1, xi], 2 ≤i ≤k and was studied in
Lemmas 1 and 2. Step 3 calculates characteristics of the intervals and, therefore, is
directly related to the assertion (i). In order to prove it, we consider computations of
characteristics Ri for all possible cases of calculating estimates li during Step 2 and
show that there always possible to indicate constants αk and βk from Lemma 3.
Lemmas 1 and 2 show that for the a priori given ﬁnite Lipschitz constant L for
the function f (x) (see Step 2.1) it follows L = αL. For the adaptive estimates of
the Lipschitz constants for intervals [xi−1, xi], 2 ≤i ≤k, (see (9), (12), (13) and
Steps 2.2–2.4 of the GS) we have li = αli, if H k > 0, and li = li = 1, otherwise
(remind that the latter corresponds to the situation zi = z1, 1 ≤i ≤k). Since Step 3
includes substeps deﬁning information and geometric methods, then the following
four combinations of methods with Lipschitz constant estimates computed at one of
the substeps of Step 2 can take place:
(a) The valueli = αli and the geometric method is used. From (17) we obtain
Ri = zi−1 +zi
2
−li
xi −xi−1
2
= α(zi−1 + zi
2
−li
xi −xi−1
2
) + β = αRi + β.
Thus, in this case we have αk = α and βk = β.
(b) The valueli = αli and the information method is used. From (18) we get

358
M. S. Mukhametzhanov and D. E. Kvasov
Ri = 2(zi +zi−1) −li(xi −xi−1) −(zi −zi−1)2
li(xi −xi−1) =
2α(zi + zi−1) + 4β −αli(xi −xi−1) −α2(zi −zi−1)2
αli(xi −xi−1) = αRi + 4β.
Therefore, in this case it follows αk = α and βk = 4β.
(c) The valueli = li = 1 and the geometric method is considered. Since in this case
zi = z1, 1 ≤i ≤k, then for the geometric method (see (17)) we have
Ri = zi−1 +zi
2
−li
xi −xi−1
2
=z1 −xi −xi−1
2
=
αz1 + β −xi −xi−1
2
= Ri + αz1 −z1 + β.
Thus, in this case we have αk = 1 and βk = z1(α −1) + β.
(d) The valueli = li = 1 and the information method is used. Then, the character-
istics (see (18)) are calculated as follows
Ri = 2(zi +zi−1) −li(xi −xi−1) −(zi −zi−1)2
li(xi −xi−1) =
4z1 −(xi −xi−1) = 4αz1 + 4β −(xi −xi−1) = Ri + 4αz1 −4z1 + 4β.
Therefore, in this case it follows αk = 1 and βk = 4(z1(α −1) + β).
Let us show now that assertion (ii) also holds. Since for both the geometric and
the information approaches the the same formula (21) for computing xk+1 is used,
we should consider only two cases related to the estimates of the Lipschitz constant:
(a) Iflt = αlt, then it follows
xk+1 = xt + xt−1
2
−zt −zt−1
2lt
= xt + xt−1
2
−α(zt −zt−1)
2αlt
= xk+1.
(b) Iflt = lt = 1, then zi = z1, 1 ≤i ≤k, and we have
xk+1 = xt + xt−1
2
−zt −zt−1
2lt
= xt + xt−1
2
= xk+1.
This result concludes the proof.

Addressing Ill-Conditioning in Global Optimization …
359
5
Numerical Illustrations
In order to illustrate the behavior of methods belonging to the GS in the Inﬁnity
Computer framework, the following four algorithms being examples of concrete
implementations of the GS have been tested:
• Geom-AL: Geometric method with an a priori given overestimate of the Lipschitz
constant. It is constructed by using Steps 2.1 and 3.1 in the GS.
• Geom-GL: Geometric method with the global estimate of the Lipschitz constant.
It is formed by using Steps 2.2 and 3.1 in the GS.
• Inf-GL: Information method with the global estimate of the Lipschitz constant. It
is formed by using Steps 2.2 and 3.2 in the GS.
• Inf-LTMA: Information method with the “Maximum-Additive” local tuning. It
is built by applying Steps 2.4 and 3.2 in the GS.
The algorithm Geom-AL has one parameter, namely, an a priori given overes-
timate of the Lipschitz constant. In algorithms Inf-LTMA, Inf-GL, and Geom-GL,
the Lipschitz constant is estimated during the search and the reliability parameter r
is used. As in [62], the values of the Lipschitz constants of the functions f (x) for
the algorithm Geom-AL were taken from [36] (and multiplied by α for g(x)). The
value of the parameter r for the Information algorithms Inf-LTMA and Inf-GL was
set equal to 2.0, while for the geometric algorithm Geom-GL it was set equal to 1.1.
The value ϵ = 10−4(b −a) was used in the stopping criterion (20).
Recall that (see Sect.2) huge or very small scaling/shifting constants can pro-
voke ill-conditioning of the scaled function g(x) in the traditional computational
framework. In the Inﬁnity Computing framework, the positional grossone-based
numeral system allows us to avoid this ill-conditioning and to work safely with
inﬁnite and inﬁnitesimal scaling/shifting constants if the respective grossdigits and
grosspowers are not too large or too small. In order to illustrate this fact, two pairs
of the values α and β were used in our experiments: (α1, β1) = (①1, ①−1) and
(α2, β2) = (①−2, ①5). The corresponding grossdigits and grosspowers involved in
their grossone-based representation are, respectively: 1 and 1 for α1; 1 and −1 for
β1; 1 and −2 for α2; and 1 and 5 for β2. These values do not provoke instability
in numerical operations. Hereinafter, scaled functions constructed using constants
(α1, β1) are indicated as g(x) and functions using (α2, β2) are designated as h(x).
The algorithms Geom-AL, Geom-GL, Inf-GL, and Geom-LTMA were tested
on the Pintér’s class of 100 univariate test problems and on the respective scaled
functions g(x) and h(x) constructed from them. On all 100 test problems with inﬁnite
and inﬁnitesimal constants (α1, β1) and (α2, β2), the results for the original functions
f (x) and for the scaled functions g(x) and h(x) coincided. To illustrate this fact, let
us consider the ﬁrst problem from the set of 100 tests (see Figs.2a and 1a).
In Fig.2b, the results for the scaled function
g1(x) = ①1 f1(x) + ①−1,
are presented, and in Fig.2c, the results for the scaled function

360
M. S. Mukhametzhanov and D. E. Kvasov
Fig. 2 Results for a the original test function f1(x) from [45], b the scaled test function g1(x) =
①1 f1(x) + ①−1, c the scaled test function h1(x) = ①−2 f1(x) + ①5. Trial points are indicated by
the signs “+” under the graphs of the functions and the number of trials for each method is indicated
on the right. The results coincide for each method on all three test functions
h1(x) = ①−2 f1(x) + ①5,
are shown. It can be seen that the results coincide for all four methods on all three
test functions f1(x), g1(x), and h1(x).
Analogous results hold for the remaining test problems fi(x), gi(x), and hi(x),
i = 2, . . . , 100. In Fig.3, the operational characteristics for each algorithm on each
test class are presented. An operational characteristic, constructed on a class of 100
randomly generated test functions, is a graph showing the number of solved problems
in dependence on the number of executed evaluations of the objective function (see
[29]). Each test problem was considered to be solved if an algorithm generated a point
in the ϵ-neighborhood of the global minimizer x∗. It can be seen from Fig.3 that the
operational characteristics of the algorithms perfectly coincide for the presented three
test classes.
It can be seen from these experiments that even if the scaling constants α and
β have a different order (e.g., when α is inﬁnitesimal and β is inﬁnite) the scaled
problems continue to be well-conditioned (cf. discussion on ill-conditioning in the
traditional framework with ﬁnite scaling/shifting constants, see Fig.1). This fact
suggests that even if ﬁnite constants of signiﬁcantly different orders are required,

Addressing Ill-Conditioning in Global Optimization …
361
Fig. 3 Operational characteristics for a the original test class fi(x) from [45], b the scaled test class
gi(x) = ①1 fi(x) + ①−1, c the scaled test class hi(x) = ①−2 fi(x) + ①5. The results coincide for
each method on all three test classes
①can also be used to avoid ill-conditioning by substituting very small constants
by ①−1 and very huge constants by ①. If, for instance, α is too small (as, e.g.,
in (5), α = 10−8) and β is too large (as, e.g., in (5), β = 108 ≫10−8), the values
α1 = ①−1 and β1 = ①can be used in computations instead of α = 10−8 and β = 108
avoiding so the situations of underﬂow and overﬂow. When the optimization process
is terminated, the global minimum f ∗of the original function f (x) can be easily
extracted from the grossone-based solution g∗= α1 f ∗+ β1 = ①−1 f ∗+ ①of the
scaled problem using ①−1 and ①while the original ﬁnite constants α and β can be
then used to get the required value g∗= α f ∗+ β (in our case, g∗= 10−8 f ∗+ 108).
6
Concluding Remarks
The scaling issues in Lipschitz global optimization have been considered in this
chapter by using the Inﬁnity Computing framework. A class of global optimization
problems has been particularly examined in which the objective function can have
ﬁnite, inﬁnite or inﬁnitesimal Lipschitz constants. The strong homogeneity of geo-
metric and information algorithms for solving univariate Lipschitz global optimiza-

362
M. S. Mukhametzhanov and D. E. Kvasov
tion problems belonging to this class has been studied and illustrated numerically
for ﬁnite, inﬁnite, and inﬁnitesimal scaling constants.
It has also been shown that when global optimization problems become ill-condi-
tioned due to very huge and/or small scaling/shifting constants in the traditional
computational frameworks working with ﬁnite numbers, the application of the Inﬁn-
ity Computing can help. It is useful in these situations to substitute ﬁnite constants
provoking numerical problems by inﬁnite and inﬁnitesimal grossone-based numbers
thus allowing one to avoid ill-conditioning of the scaled problems.
References
1. Amodio, P., Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: A generalized
Taylor method of order three for the solution of initial value problems in standard and inﬁnity
ﬂoating-point arithmetic. Math. Comput. Simul. 141, 24–39 (2017)
2. Antoniotti, L., Caldarola, F., Maiolo, M.: Inﬁnite numerical computing applied to Hilbert’s,
Peano’s, and Moore’s curves. Mediter. J. Math. 17(3) (2020)
3. Archetti, F., Candelieri, A.: Bayesian Optimization and Data Science. Springer Briefs in Opti-
mization. Springer, New York (2019)
4. Astorino, A., Fuduli, A.: Spherical separation with inﬁnitely far center. Soft Comput. 24,
17751–17759 (2020)
5. Audet, C., Caporossi, G., Jacquet, S.: Constraint scaling in the mesh adaptive direct search
algorithm. Paciﬁc J. Optim. 16(4), 595–610 (2020)
6. Caldarola, F.: The Sierpinski curve viewed by numerical computations with inﬁnities and
inﬁnitesimals. Appl. Math. Comput. 318, 321–328 (2018)
7. Caldarola, F., Maiolo, M.: On the topological convergence of multi-rule sequences of sets and
fractal patterns. Soft Comput. 24, 17737–17749 (2020)
8. Calude, C.S., Dumitrescu, M.: Inﬁnitesimal probabilities based on grossone. SN Comput. Sci.
1 (2020)
9. Cococcioni, M., Cudazzo, A., Pappalardo, M., Sergeyev, Y.D.: Solving the lexicographic multi-
objective mixed-integer linear programming problem using branch-and-bound and grossone
methodology. Commun. Nonlinear Sci. Numer. Simul. 84 (2020). Article 105177
10. Cococcioni, M., Fiaschi, L.: The Big-M method with the numerical inﬁnite M. Optim. Lett.
15(7), 2455–2468 (2021)
11. Cococcioni, M., Pappalardo, M., Sergeyev, Y.D.: Lexicographic multi-objective linear pro-
gramming using grossone methodology: theory and algorithm. Appl. Math. Comput. 318,
298–311 (2018)
12. D’Alotto, L.: Cellular automata using inﬁnite computations. Appl. Math. Comput. 218(16),
8077–8082 (2012)
13. D’Alotto, L.: A classiﬁcation of one-dimensional cellular automata using inﬁnite computations.
Appl. Math. Comput. 255, 15–24 (2015)
14. D’Alotto, L.: Inﬁnite games on ﬁnite graphs using grossone. Soft Comput. 55, 143–158 (2020)
15. De Cosmis, S., De Leone, R.: The use of grossone in mathematical programming and operations
research. Appl. Math. Comput. 218(16), 8029–8038 (2012)
16. De Leone, R.: Nonlinear programming and grossone: quadratic programming and the role of
constraint qualiﬁcations. Appl. Math. Comput. 318, 290–297 (2018)
17. De Leone, R., Fasano, G., Roma, M., Sergeyev, Y.D.: Iterative grossone-based computation
of negative curvature directions in large-scale optimization. J. Optim. Theory Appl. 186(2),
554–589 (2020)
18. De Leone, R., Fasano, G., Sergeyev, Y.D.: Planar methods and grossone for the conjugate
gradient breakdown in nonlinear programming. Comput. Optim. Appl. 71(1), 73–93 (2018)

Addressing Ill-Conditioning in Global Optimization …
363
19. Elsakov, S.M., Shiryaev, V.I.: Homogeneous algorithms for multiextremal optimization. Com-
put. Math. Math. Phys. 50(10), 1642–1654 (2010)
20. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A Simulink-based Inﬁnity
Computer simulator and some applications. In: LNCS, vol. 11974, pp. 362–369. Springer
(2017)
21. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: Representation of Grossone-
based arithmetic in Simulink and applications to scientiﬁc computing. Soft Comput. 24, 17525–
17539 (2020)
22. Falcone, A., Garro, A., Mukhametzhanov, M.S., Sergeyev, Y.D.: A Simulink-based software
solution using the inﬁnity computer methodology for higher order differentiation. Appl. Math.
Comput. 409 (2021). Article 125606
23. Floudas, C.A., Pardalos, P.M. (eds.): Encyclopedia of Optimization (6 Volumes), 2nd edn.
Springer (2009)
24. Gangle, R., Caterina, G., Tohmé, F.: A constructive sequence algebra for the calculus of indi-
cations. Soft Comput. 24(23), 17621–17629 (2020)
25. Gaudioso, M., Giallombardo, G., Mukhametzhanov, M.S.: Numerical inﬁnitesimals in a vari-
able metric method for convex nonsmooth optimization. Appl. Math. Comput. 318, 312–320
(2018)
26. Gaviano, M., Kvasov, D.E., Lera, D., Sergeyev, Y.D.: Algorithm 829: software for generation
of classes of test functions with known local and global minima for global optimization. ACM
Trans. Math. Softw. 29(4), 469–480 (2003)
27. Gergel, V., Barkalov, K., Sysoev, A.: Globalizer: A novel supercomputer software system for
solving time-consuming global optimization problems. Numer. Algebra Control Optim. 8(1),
47–62 (2018)
28. Gergel, V.P., Grishagin, V.A., Gergel, A.V.: Adaptive nested optimization scheme for multidi-
mensional global search. J. Glob. Optim. 66, 35–51 (2016)
29. Grishagin, V.A.: Operating characteristics of some global search algorithms. Probl. Stoch.
Search 7, 198–206 (1978). In Russian
30. Grishagin, V.A., Israﬁlov, R.A., Sergeyev, Y.D.: Convergence conditions and numerical com-
parison of global optimization methods based on dimensionality reduction schemes. Appl.
Math. Comput. 318, 270–280 (2018)
31. Grishagin, V.A., Sergeyev, Y.D., Strongin, R.G.: Parallel characteristic algorithms for solving
problems of global optimization. J. Global Optim. 10(2), 185–206 (1997)
32. Iavernaro, F., Mazzia, F., Mukhametzhanov, M.S., Sergeyev, Y.D.: Computation of higher order
Lie derivatives on the Inﬁnity Computer. J. Comput. Appl. Math. 383 (2021)
33. Iudin, D.I., Sergeyev, Y.D., Hayakawa, M.: Inﬁnity computations in cellular automaton forest-
ﬁre model. Commun. Nonlinear Sci. Numer. Simul. 20(3), 861–870 (2015)
34. Jones, D.R., Martins, J.R.R.A.: The DIRECT algorithm: 25 years later. J. Glob. Optim. 79,
521–566 (2021)
35. Jones, D.R., Perttunen, C.D., Stuckman, B.E.: Lipschitzian optimization without the Lipschitz
constant. J. Optim. Theory Appl. 79, 157–181 (1993)
36. Kvasov, D.E., Mukhametzhanov, M.S.: Metaheuristic vs. deterministic global optimization
algorithms: the univariate case. Appl. Math. Comput. 318, 245–259 (2018)
37. Kvasov, D.E., Mukhametzhanov, M.S., Sergeyev, Y.D.: Ill-conditioning provoked by scal-
ing in univariate global optimization and its handling on the Inﬁnity Computer. In: M.T.M.
Emmerich et al. (ed.) Proceedings LEGO – 14th International Global Optimization Workshop,
vol. 2070 (1). AIP Conference Proceedings (2019). Article 020011
38. Lai, L., Fiaschi, L., Cococcioni, M.: Solving mixed Pareto-Lexicographic manyobjective opti-
mization problems: the case of priority chains. Swarm Evol. Comput. 55 (2020). Article 100687
39. Lera, D., Posypkin, M., Sergeyev, Y.D.: Space-ﬁlling curves for numerical approximation and
visualization of solutions to systems of nonlinear inequalities with applications in robotics.
Appl. Math. Comput. 390 (2021). Article 125660
40. Lolli, G.: Metamathematical investigations on the theory of grossone. Appl. Math. Comput.
255, 3–14 (2015)

364
M. S. Mukhametzhanov and D. E. Kvasov
41. Margenstern, M.: Fibonacci words, hyperbolic tilings and grossone. Commun. Nonlinear Sci.
Numer. Simul. 21(1–3), 3–11 (2015)
42. Mockus, J.: Bayesian Approach to Global Optimization. Kluwer Academic Publishers,
Dodrecht (1988)
43. Paulaviˇcius, R., Žilinskas, J.: Simplicial Global Optimization. SpringerBriefs in Optimization.
Springer, New York (2014)
44. Pepelyshev, A., Zhigljavsky, A.: Discrete uniform and binomial distributions with inﬁnite
support. Soft Comput. 24, 17517–17524 (2020)
45. Pintér, J.D.: Global optimization: software, test problems, and applications. In: Pardalos, P.M.,
Romeijn, H.E. (eds.) Handbook of Global Optimization, vol. 2, pp. 515–569. Kluwer Academic
Publishers, Dordrecht (2002)
46. Piyavskij, S.A.: An algorithm for ﬁnding the absolute extremum of a function. USSR Comput.
Math. Math. Phys. 12(4), 57–67 (1972)
47. Rizza, D.: Numerical methods for inﬁnite decision-making processes. Int. J. Unconv. Comput.
14(2), 139–158 (2019)
48. Sergeyev, Y.D.: On convergence of “divide the best” global optimization algorithms. Optimiza-
tion 44(3), 303–325 (1998)
49. Sergeyev, Y.D.: A new applied approach for executing computations with inﬁnite and inﬁnites-
imal quantities. Informatica 19(4), 567–596 (2008)
50. Sergeyev, Y.D.: Numerical point of view on Calculus for functions assuming ﬁnite, inﬁnite,
and inﬁnitesimal values over ﬁnite, inﬁnite, and inﬁnitesimal domains. Nonlinear Anal. Ser.
A: Theory Methods Appl. 71(12), e1688–e1707 (2009)
51. Sergeyev, Y.D.: Higher order numerical differentiation on the Inﬁnity Computer. Optim. Lett.
5(4), 575–585 (2011)
52. Sergeyev, Y.D.: Using blinking fractals for mathematical modelling of processes of growth in
biological systems. Informatica 22(4), 559–576 (2011)
53. Sergeyev, Y.D.: Numerical inﬁnities and inﬁnitesimals: methodology, applications, and reper-
cussions on two Hilbert problems. EMS Surv. Math. Sci. 4(2), 219–320 (2017)
54. Sergeyev, Y.D.: Independence of the grossone-based inﬁnity methodology from non-standard
analysis and comments upon logical fallacies in some texts asserting the opposite. Found. Sci.
24(1), 153–170 (2019)
55. Sergeyev, Y.D., Candelieri, A., Kvasov, D.E., Perego, R.: Safe global optimization of expensive
noisy black-box functions in the δ-Lipschitz framework. Soft Comput. 24(23), 17715–17735
(2020)
56. Sergeyev, Y.D., Garro, A.: Observability of turing machines: a reﬁnement of the theory of
computation. Informatica 21(3), 425–454 (2010)
57. Sergeyev, Y.D., Garro, A.: Single-tape and multi-tape Turing machines through the lens of the
Grossone methodology. J. Supercomput. 65(2), 645–663 (2013)
58. Sergeyev, Y.D., Grishagin, V.A.: A parallel method for ﬁnding the global minimum of univariate
functions. J. Optim. Theory Appl. 80(3), 513–536 (1994)
59. Sergeyev, Y.D., Kvasov, D.E.: Deterministic Global Optimization: An Introduction to the Diag-
onal Approach. Springer, New York (2017)
60. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: Emmental-type GKLS-based multiex-
tremal smooth test problems with non-linear constraints. In: LNCS, vol. 10556, pp. 383–388.
Springer (2017)
61. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: Operational zones for comparing meta-
heuristic and deterministic one-dimensional global optimization algorithms. Math. Comput.
Simul. 141, 96–109 (2017)
62. Sergeyev, Y.D., Kvasov, D.E., Mukhametzhanov, M.S.: On strong homogeneity of a class
of global optimization algorithms working with inﬁnite and inﬁnitesimal scales. Commun.
Nonlinear Sci. Numer. Simul. 59, 319–330 (2018)
63. Sergeyev, Y.D., Mukhametzhanov, M.S., Kvasov, D.E., Lera, D.: Derivative-free local tuning
and local improvement techniques embedded in the univariate global optimization. J. Optim.
Theory Appl. 171, 186–208 (2016)

Addressing Ill-Conditioning in Global Optimization …
365
64. Sergeyev, Y.D., Mukhametzhanov, M.S., Mazzia, F., Iavernaro, F., Amodio, P.: Numerical
methods for solving initial value problems on the inﬁnity computer. Int. J. Unconv. Comput.
12(1), 3–23 (2016)
65. Sergeyev, Y.D., Nasso, M.C., Mukhametzhanov, M.S., Kvasov, D.E.: Novel local tuning tech-
niques for speeding up one-dimensional algorithms in expensive global optimization using
Lipschitz derivatives. J. Comput. Appl. Math. 383 (2021). Article 113134
66. Sergeyev,Y.D.,Strongin,R.G.,Lera,D.:IntroductiontoGlobalOptimizationExploitingSpace-
Filling Curves. Springer, New York (2013)
67. Strongin, R.G.: Numerical Methods in Multiextremal Problems: Information-Statistical Algo-
rithms. Nauka, Moscow (1978). (In Russian)
68. Strongin, R.G., Sergeyev, Y.D.: Global Optimization with Non-Convex Constraints: Sequential
and Parallel Algorithms. Kluwer Academic Publishers, Dordrecht (2000)
69. Žilinskas, A., Žilinskas, J.: A hybrid global optimization algorithm for non-linear least squares
regression. Journal of Global Optimization 56(2), 265–277 (2013)
70. Zhigljavsky, A.: Computing sums of conditionally convergent and divergent series using the
concept of grossone. Appl. Math. Comput. 218(16), 8064–8076 (2012)
71. Zhigljavsky, A., Žilinskas, A.: Bayesian and High-Dimensional Global Optimization. Springer
Briefs in Optimization. Springer, New York (2021)
72. Zhigljavsky, A., Žilinskas, A.: Stochastic Global Optimization. Springer, New York (2008)
73. Žilinskas, A.: Axiomatic characterization of a global optimization algorithm and investigation
of its search strategies. Oper. Res. Lett. 4, 35–39 (1985)
74. Žilinskas, A.: On strong homogeneity of two global optimization algorithms based on statistical
models of multimodal objective functions. Appl. Math. Comput. 218(16), 8131–8136 (2012)

