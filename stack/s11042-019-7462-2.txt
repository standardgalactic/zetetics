Multimedia Tools and Applications (2019) 78:21731–21758
https://doi.org/10.1007/s11042-019-7462-2
CMAIR: content and mask-aware image retargeting
Hon-Hang Chang1
· Timothy K. Shih1 · Carl K. Chang2 · Wallapak Tavanapong3
 Hon-Hang Chang
sicachang@gmail.com
Timothy K. Shih
timothykshih@gmail.com
Carl K. Chang
chang@iastate.edu
Wallapak Tavanapong
tavanapo@iastate.edu
1
No. 300, Zhongda Rd., Zhongli District, Taoyuan City, 32001, Taiwan (R.O.C.)
2
Iowa State University, 226 Atanasoff Hall, Ames, IA 50011-1090, USA
3
Iowa State University, 232 Atanasoff Hall, Ames, IA 50011-1040, USA
Published online: 2 April 2019
© Springer Science+Business Media, LLC, part of Springer Nature 2019
Abstract
In recent years, more and more image retargeting techniques have been proposed to facil-
itate our daily life, in particular those based on the use of seam carving, warping or the
combination of them. However, these techniques can only retarget the source picture into the
same shape of a square, and these approaches cannot be reshape into a circular, a polygon
or other shapes. This paper focuses on creating a graphics editing system, named CMAIR
(Content and Mask-Aware Image Retargeting), for image retargeting, which can retarget
the source images into different shapes of image to highlight the salient objects of primary
region of interest. CMAIR effectively supports removal of unimportant pixels, and frames as
many surrounding objects inside the provided mask as possible. Also, we propose a unique
irregular interpolation method to produce four possible target images, and an evaluation
mechanism to decide the best candidate image as the final output with the consideration of
image saliency. The results show that not only the source image can be placed into different
targeted shapes of mask, but also the salient objects are retained and highlighted as much as
possible.
Keywords Image retargeting · Seam carving · Irregular interpolation · Image saliency ·
Region of interest
Received: 21 February 2018 / Revised: 19 January 2019 / Accepted: 7 March 2019 /

21732
Multimedia Tools and Applications (2019) 78:21731–21758
1 Introduction
More and more novel devices were invented in recent years, such as smart phones, tablets,
smart TV, etc., featuring variations of screen sizes and aspect ratios. One of the most impor-
tant issues in image processing is to choose the type of retargeting operator that best suits
our requirements: adjust the size directly with a given aspect ratio (uniform scaling); cut-
ting the continuous and interested region out (cropping); putting black streaks above and
below the frame while making the targeted aspect ratio (letterboxing); warping specific
regions to highlight the salient objects (warping); carving paths of unimportant pixels to
retain important regions only (seam carving); retargeting image based on Quality Assess-
ment; and learning based image retargeting. For the purpose of browsing pictures more
effectively on a variety of shapes of the screen, a content-and-shape-aware image retargeting
technique [31] was proposed fairly recently. The author presents a novel image retargeting
algorithm called content and shape-aware image retargeting (CASAIR) that can be used to
retarget images to a large family of nonrectangular shapes, based on the idea of seam seg-
ment carving. And, the low-cost seam segments from the image, which are determined by a
cost function incorporating inputs from image content and target shape.
Nevertheless, there are some main issues with these retargeting operators: croping, scal-
ing warping, and seam carving. First, cropping [9, 23, 24, 36, 39, 40] will only retain one
significant region with a given aspect ratio, so it is not possible to get an interested region
which contains all the important objects, especially if the objects are evenly dispersed in
the image. Second, scaling-based approaches [19, 32, 42, 46] merge pixels from the source
according to the targeted scale, and the idea of this method is to merge pixels in each
row and each column to the same targeted width and height, respectively. Therefore, these
approaches can only retarget saliency objects linearly in only horizontal and vertical direc-
tions, and other objects located in the same column and the same row of saliency object will
be assigned with the same scaling ratio, even these objects with unimportant saliency. Third,
warping [14, 21, 22, 34, 41, 43] approaches divide source image into different sizes of quads
on the grid. Doing so, the flexible quads will be distorted by considering the saliency and
gradient to fit the targeted size. Compared with scaling operator using only rectangle quads,
warping can highlight more subjects effectively. However, all quads are defined and fully
connected on the grid to maintain the consistency of image information, the adjacent quads
will be deformed to distort the objects. Since the scaling and warping based method are used
to merge adjacent pixels in one of the three cases including background-background, object-
background, and object-object, such methods tend to distort the homogeneous regions.
Besides, salient objects can easily result in smaller or bigger homogeneity when the sur-
rounding grid is changed. For example, when the object under examination has a smaller
quad size, its surrounding objects will also become smaller after retargeting. Seam carving
[1, 3, 6, 7, 13, 16–18, 30, 37] based techniques can be used to highlight more important
objects by continuously removing the seams which are depicted by lowest-cost of energy,
but the approach is in inherently discrete, it is easy to cause obvious distortion for structured
image objects after carving removal of seams.
Compared with scaling and warping based methods, seam carving emphasizes the per-
ception of the resulted image while removing the pixels. The basic idea is to repeatedly
remove the optimal seams to fit the targeted size, where all seams in each iteration are made
up of H or W pixels. Take the vertical seam for example, the seam is composed of H pixels
with an eight-connected path from the energy map. The energy map is computed by gradi-
ent detection to ensure that only unimportant pixels are removed from an optimal seam in

Multimedia Tools and Applications (2019) 78:21731–21758
21733
order to highlight important pixels. However, these above techniques are only designed for
the image from rectangle shape to another.
Lastly, mixed retargeting operators [8, 10, 35, 44, 45], quality assessment based [2, 4,
5, 11, 12, 20, 25–28, 33, 38, 47] and learning based retargeting [29] method are proposed
to generate target image with less visually distorted. These methods combine more advan-
tages of retargeting operators to generate better results than using single operator. However,
these retargeting methods did not maintain the size of multiple objects as the first priority,
and these methods are only designed for generating another rectangle targeted result with
different aspect ratios.
When it comes to content-aware image retargeting [1–14, 16–30, 32–47], the rectan-
gular shaped images still may not allow direct conversion to irregular shapes. That is, all
salient objects from the source image should be included inside the targeted mask even if
it is irregularly shaped. However, there is currently no effective way to solve this problem,
because, all these retargeting techniques are designed for the conversion between rectangu-
lar images with different aspect ratios. For example, when a source image with size H by
W is retargeted to a targeted image H ′ by W ′, the number of pixels in each row and column
of the image representation will be W ′ and H ′ only. For content-and-shape-aware image
retargeting, Qi et al. [31] remove the pixels from source image which correspond to the
seam-segments to fit the irregular shape. The targeted results show that all objects are possi-
ble to be included in the irregular mask. However, the objects located around the boundary
of mask cannot be preserved well because most of the seam segments are defined around the
contour of targeted mask. Hence, the image contents which farther from the center would
have been largely removed by seam segment to cause severe deformation.
In this paper, we propose a novel algorithm for image retargeting by using seam-carving
concepts. Our algorithm proposed a content-and-mask-aware approach, which is quite dif-
ferent from the content-aware and content-and-shape-aware approach which are established
by Avidan et al. [1] and Qi et al. [31]. Besides, our energy map can be more effective in
dealing with the irregular shape of targeted mask than that of Qi et al.’s method. The method
of Qi et al. produces the segmented seams to remove all surrounding pixels inside the tar-
geted irregular mask. Instead, we propose the concept of pair-seams carving to retarget ”all
pixels.” Compared with segmented seams [31], our pair seams in each iteration will be gen-
erated not only around the contour of mask to avoid serious distortion of image content
at the edge of the mask. The proposed pair seams are used to retarget image, that is, the
internal seams path with unimportant image saliency will be removed, and the outer seam
is defined as a demarcation to push more image content inside the mask. Furthermore, an
irregular interpolation mechanism is proposed in this paper to further preserve more image
content in the targeted mask.
As a result, the objects of major concerns in the resultant image are effectively high-
lighted with bigger sizes based on seam carving operator. And, there are no distortion on
the edges of the targeted mask, carving by using our pair-seams compared by using segment
seams. Besides, the proposed irregular interpolation make more pixels be present inside the
irregular mask, the presented technique allows us to address the problem that some objects
cannot be kept in the targeted mask.
The rest of this paper is organized as follows. In Section 2, we introduce some related
works on image retargeting. Next, we propose our CMAIR (content-and-mask-aware image
retargeting) algorithm in Section 3. We then evaluate the proposed algorithm by resizing
several kinds of test images in Section 4 with comprehensive comparisons. Finally, we draw
conclusions in Section 5.

21734
Multimedia Tools and Applications (2019) 78:21731–21758
2 Related works
Cropping, scaling, warping and seam carving are four operators for image retargeting, which
is an effective way to convert image to a different aspect ratio. Moreover, the four operators
can retarget image content to highlight important objects by removing some unimportant
regions or pixels. The user may select different operators, each with a different character-
istic, suitable for different needs to produce the resultant image. For example, if we want
to enlarge all objects from the source image, we will not use scaling and warping based
methods to retarget image. Neither will we apply cropping-based method to retarget images
which contain dispersed multiple subjects.
As for the cropping-based approach [9, 23, 24, 36, 39, 40], this operator is a good way
to preserve and highlight all the salient-content in the region of interest (ROI). But, their
methods cannot keep any information which are not in the ROI.
In contrast, scaling-based and warping-based techniques [14, 19, 21, 22, 32, 34, 41–43,
46] may distort objects, so Qu et al. [32] use a graph model to preserve spatial structure
during the retargeting phase. This approach ensures that it can retain all the salient-content
by adjusting the size of squads of grid to enlarge an important region, yet it may not increase
the size of all important objects. Such approaches typically sacrifice some important objects
to make them smaller. Seam carving is a good choice to highlight descret multiple important
objects[1, 3, 6, 7, 13, 16–18, 30, 37], but it is easy to cause structural damage of objects,
especially the linear structure.
In recent years, Guo et al. and Lin et al. present more effective approaches to image retar-
geting based on image warping [14, 21]. In order to retain the structure of saliency-content
during the retargeting phase, Guo et al. proposed saliency-based mesh parameterization.
This approach preserves the image structures during the retargeting phase since it captures
underlying image structures. Moreover, Lin et al. propose a patch-based retargeting scheme
with an extended significance. Their technique has two contributions. First, it preserves the
shapes of visually salient objects. Second, it avoids linear and structure damages.
Still, scaling-based and warping-based methods cannot guarantee that all objects are
maintained at their original size during the retargeting phase because of the restriction of
homogeneous distortion. For example, if some important objects use bigger squads, other
regions need to be presented in smaller squads; thus, the rest of the objects will become
smaller easily (see in Fig. 1). In this case, the 9 patterns are preserved integrally in size as
original than using warping (WP) and cropping (CP). In sum, scaling-based and warping-
based approaches are not a wise choice to retarget image, if your goal is to maintain the
original size of all important objects.
Fig. 1 Three image retargeting operators: cropping (CP), warping (WP), and seam carving (SC)

Multimedia Tools and Applications (2019) 78:21731–21758
21735
Avidan et al. [1] present a seam-carving-based image retargeting approach. The basic
idea of seam-carving is to define multiple seams in unimportant regions. Then, the carving
phase removes these seams to fit the aspect ratio. So, the resultant image retains only salient
objects. Therefore, all the salient objects will occupy a relatively large proportion in the
whole image after removal of seams since the new target image is composed of salient-pixels
only. In other words, the size of salient objects after retargeting based on seam-carving
approach [1, 3, 6, 7, 13, 16–18, 30, 37] will become bigger than scaling-based and warping-
based methods. In order to combine the advantages of retargeting operators, M. Rubinstein
et al. [35] presents a retargeting technique to considerate all relegated operators to acheive
better target image. Then, the most appropriate retargeting operator will be selected to retar-
get in each retargeting stage. Besides, Wu. et al. have chosen seam carving and warping as
the main retargeting operetors [44, 45] to highlight the objects more effectively. However,
it did not maintain both the integrity of the objects with assigned deforming squads (see
example in Fig. 1 (WP)).
Note that the retargeting techniques mentioned above have their strong points and short-
comings. Nonetheless, these techniques have the same drawback. That is, their algorithms
cannot be applied to convert the image to irregular shapes. A novel approach called Content-
and-Shape-Aware Image Retargeting (CASAIR) is proposed by Qi et al. [31], where the
image is deformed to a non-rectangular shape. The algorithm is based on the idea of
seam-segment-carving that successively removes low-cost seam segments from image and
retargets the image to irregular shapes. However, most of the segmented seams are defined
in the periphery of the targeted mask by Qi et al.’s approach. But, the objects in periphery
locations are seriously deformed, resulting in some salient objects with missing parts.
In order to address the missing parts in Qi’s retargeting approach and put more content
into the irregular mask, our retargeting algorithm CMAIR, as another seam-carving-based
retargeting approach, proposes the concept of pair-seams that effectively improve the energy
map of Qi et al. The retargeting mechanism moves more image content into an irregular
mask, as much as possible. Finally, we use the proposed irregular interpolation mechanism
to optimize the targeted image, and furthermore, this step puts more salient objects into the
irregular mask.
3 Content and mask-aware image retargeting
In seam carving-based approach, energy is produced by the gradient and the saliency. In
this section, a content-and-mask-aware energy generating scheme is proposed in order to
deal with irregular frame shapes, while the strategy uses gradient and saliency. The rest of
this section explains the details of the proposed CMAIR, with the following sub-systems:
Energy Generating System, Image Retargeting System, and Irregular-Interpolation
System. A flow chart of the aforementioned three steps is shown in Fig. 2. In Qi et al.’s
method [31], seam segment is defined and carving starts in peripheral of the image in order
to push all image content into the target mask. So, the resultant image contain both important
and unimportant image content, that is, it did not highlight the important image content.
Also, the image content is incomplete around the mask, as all seam segments are defined
and carved on the outside of the input mask. Instead, our main seam defined in the whole
range of ROI to find and remove unimportant image content which are in low energy to
highlight important objects, and another pair-seam is used to let all peripheral pixels be
pushed inside the target frame.

21736
Multimedia Tools and Applications (2019) 78:21731–21758
Fig. 2 Work flow of the proposed CMAIR (Content and Mask-Aware Image Retargeting) system
The energy generation system takes in two inputs: a source image I and a mask map EM.
The saliency map ES, based on human spatiotemporal perception have been used to detect
Region of Interest (ROI) in input image. As most important objects are inside the ROI, the
ROI is used here to define our mask map EM with size RW by RH. And, the boundary
values of ROI are [l, r] and [u, d] in horizontal and vertical direction, respectively. Then,
the mask map EM is created by the given irregular shape IS (see Fig. 2), and the EM is
given as a rectangular image of size W by H, with 0 for mask area and 1 for not-mask area.
Both ROI and mask map EM are illustrated in Fig. 3a. And, the resultant ROI detection is
shown in (b-d), the detected ROI cover important objects stickers, man, bicycle, and etc.
Fig. 3 Example of ROIs

Multimedia Tools and Applications (2019) 78:21731–21758
21737
The gradient map EG, saliency map ES, and mask map EM are used to generate the
energy map E. The multiple main seams and the pair-seams are defined in the retarget-
ing system. Then, a retargeting approach named CMAIR is proposed here to generate two
targeted results, T I and T IROI (Fig. 2).
In order to further deform the two targeted images T I and T IROI to fit in the targeted
mask, an irregular interpolation approach is presented for computing two targeted results.
Also, an evaluation mechanism is presented in this paper, in order to compare and demon-
strate the best targeted result from the 4 candidates of targeted images, T I, T IROI, T I ′ and
T I ′
ROI (Fig. 2).
3.1 Energy generating system
Energy map is composed based on gradient map and saliency map. A new approach is used
to generate our content-and-mask-aware energy map E. Most seams can be defined in the
mask area (MA) (see in Fig. 4c) by our content-and-mask-aware energy map. And, more
saliency-objects can be preserved in the mask area. In this section, we illustrate how to
compute the content-and-mask-aware energy map E.
3.1.1 Mask map (EM)
In order to know the location of Region of Interest (ROI) in the source image I, we assume
the area with the highest number of saliency-objects as the most suitable candidate. We
represent the ROI with size RW by RH, at location (Rx, Ry), and boundary (l, r, u, d) (see
Fig. 3a).
The ROI is defined by saliency map ES with a given threshold RT . And, the saliency map
ES with real numbers in [0.0, 1.0] is implemented by Itti’s method [15] since it can achieve a
lower complexity and can preserve both saliency-objects and partial backgrounds. Based on
our experience in processing different kinds of images, and since more saliency-objects are
more noticeable, it is good to bias the saliency toward important content, taking RT = 0.15.
As shown in Fig. 3b–d, the ROI contains saliency-objects (sticker, men, and bicycles) and
part of important backgrounds (dining table, girl, PCs, chairs, desks, mountains, grassland,
etc.). Then, the given irregular shape IS is resized to the size RH by RW in order to define
Fig. 4 Retarget image to fit the ROI using SC, RSC, and MASC

21738
Multimedia Tools and Applications (2019) 78:21731–21758
the mask map EM. Initially, the mask map EM is created with all ‘1’, and updated by
the (1).
EM(i, j) =
 0, (i, j) ∈ROI ∧IS(i −l, j −u) = 1,
1, otherwise,
(1)
where EM(i, j) is a binary value, and i = 1, · · · , W, and j = 1, · · · , H. So, the mask area
(MA) in mask map EM will be assigned with a lower value (with EM(i, j) = 0) than the
rest area (with EM(i, j) = 1).
ROI-based seam carving, RSC, (see Fig. 4b) provides better results in preserving more
saliency-objects, as compared to ordinary seam carving SC (see Fig. 4a). And, all seams are
forced to remain in ROI. That is, removal of seams only occurs from outside to inside of the
mask area. Thus, the concept of mask-aware seam carving, MASC, is afresh proposed in
this paper. All seams are defined with a probability in the mask area (see Fig. 4c). Almost all
saliency-objects are moved to the mask area. Comparing three targeted images (see Fig. 4d–
f), the results using MASC preserves more saliency-objects in the mask area then those
using SC and RSC. In general, RSC has a better target image than SC.
3.1.2 Energy (E)
In Qi et al.’s method [31], seam carving is used to retarget a source image to size RW by
RH in order to fit the ROI. However, the retargeting approach fails in effectively mov-
ing the saliency-objects to the mask area (MA). In Qi’s retargeting method, all seams are
defined in the whole ROI (see Fig. 4b as an example). Our pair-seam carving is contrary to
Qi’s segment-seam carving, as all seams are defined in the mask area as much as possible,
therefore, the targeted saliency-objects (see Fig. 4c) are preserved better in mask area (MA).
Next, the details of MASC is explained in order to introduce the seams in vertical and
horizontal directions respectively. The pixels in location (x, y) of input image I are repre-
sented as I(x, y). A vertical “main seam” Sv is composed from a set of connected pixels Sy
in image I(x, y) in the range [l, r], where the row y only has one seam pixel, and l and r
represent the horizontal boundary in the ROI within image I. Similarly, the horizontal seam
only has one pixel in each column x, and u and d represent the vertical boundary.
Seams S is a vertical or a horizontal path of pixels. In this paper, v and h denote the
directions of vertical and horizontal, and the vertical and horizontal main seams are repre-
sented as Sv and Sh, respectively. Also, both the energy map E in vertical and horizontal
direction are presented as Ev and Eh, respectively.
Both the main seams Sv and Sh are 8-connected path of pixels in an W × H image from
top to bottom, and the coordinate sets in vertical and horizontal seam pixels are formally
defined by (2) and (3).
sP = {sP
j }H
j=1 = {P(j), j}H
j=1,
s.t.∀j, |P(j) −P(j −1)| ≤1

l ≤P(j) ≤r,
(2)
sQ = {sQ
i }W
i=1 = {i, Q(i)}W
i=1,
s.t.∀i, |Q(i) −Q(i −1)| ≤1

u ≤Q(i) ≤d,
(3)
where H and W represent the height and the width of a given input image I, and P is a
mapping as P : [1, . . . , H] →[1, . . . , W]. sP and sQ are coordinate sets in the seams
Sv and Sh, respectively. Take the vertical seam Sv as example, I(sP
j ) denotes the vertical
seam pixel in row j, and P(j) is the x-coordinate in row y. Note that the vertical seam is

Multimedia Tools and Applications (2019) 78:21731–21758
21739
composed by 8 connected path of pixels (|P(j) −P(j −1)| ≤1) and the main seam is
defined in the ROI range (l ≤P(j) ≤r). Also, the vertical seam Sv and horizontal seam
Sh can be represented by (4) and (5).
Sv = {I(sP
j )}H
j=1 = {I(P(j), j)}H
j=1,
(4)
Sh = {I(sQ
i )}W
i=1 = {I(i, Q(i))}W
i=1,
(5)
The vertical and horizontal seams Sv and Sh shows the lowest energy Ev and Eh. Their
optimal versions, Sv
∗and Sh
∗, are deformed by (6) and (7).
Sv
∗= arg min
Sv Ev(Sv) = arg min
Sv
H

j=1
Ev(I(sP
j )),
(6)
Sh
∗= arg min
Sh Eh(Sh) = arg min
Sh
W

i=1
Eh(I(sQ
i )),
(7)
Both the optimal vertical and horizontal seams Sv
∗and Sh
∗are found by dynamic program-
ming. The process of dynamic programming starts from cumulative energy map for vertical
and horizontal seams, Ev and Eh, as in (8) and (9).
Ev(x, y) =
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
EI(x, y),
y = 1, l ≤x ≤r
EI(x, y)+
	1
i=−1 Ev(x + i, y −1), y > 1, l ≤x ≤r
∞,
otherwise,
(8)
Eh(x, y) =
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
EI(x, y),
x = 1, u ≤y ≤d
EI(x, y)+
	1
j=−1 Eh(x −1, y + j), x > 1, u ≤y ≤d
∞,
otherwise,
(9)
where the vertical energy map Ev is computed by importance map EI from top to bottom
(see (8)). For example, Ev(H, W) and EI(1, 1) represent the energy value of Ev on the
bottom-right corner and the important value of the importance map EI on the left-top corner.
The horizontal energy map Eh can be implemented in the same way as the vertical one (see
(9)).
The importance map EI is composed of gradient map EG, saliency map ES, and mask
map EM.
EI = wg × EG + ws × ES + wm × EM,
(10)
Here, we adopt Itti’s saliency detecting approach [15] in defining the saliency map ES with
real numbers in range [0.0, 1.0]. In our experience, the weights wg, ws, and wm are set to
0.7, 0.2 and 0.1, respectively in considering both the image content (content-aware) and the
mask area (mask-aware), in order to preserve more integral saliency-objects. To generate

21740
Multimedia Tools and Applications (2019) 78:21731–21758
the gradient map EG, difference values in the horizontal, vertical, and other directions are
used to define the gradient of image content (see (11)).
∂y(x, y) =
w/2
i=−w/2
w/2
j=−w/2M27(i, j) I(x + i, y + j),
∂x(x, y) =
w/2
i=−w/2
w/2
j=−w/2M45(i, j) I(x + i, y + j),
∂xy(x, y) =
w/2
i=−w/2
w/2
j=−w/2M18(i, j) I(x + i, y + j),
∂yx(x, y) =
w/2
i=−w/2
w/2
j=−w/2M63(i, j) I(x + i, y + j),
(11)
where (i, j) denote the corresponding location (x, y) in the difference matrices ∂y, ∂x, ∂xy
and ∂yx, which are used to detect the gradient in different directions (see Fig. 5). And, in 11,
w represents the width of the gradient mask, (x, y) and (i, j) represent the coordinate of a
pixel and difference value at in image and gradient mask, respectively. As shown in Fig. 5,
we omit the horizontal edges (see Fig. 5c) as the vertical lines in the image will cause heavy
distortion after the removal of the vertical seams (see Fig. 5b). Different directions of edge
are considered here. And, the improved vertical edge detecting phase can be defined by (12).
Also, horizontal edge detection can be defined by omitting the vertical edges, as defined
in (13).
Ev
G = α × ∂y + β × ∂xy + γ × ∂yx,
(12)
Eh
G = α × ∂x + β × ∂xy + γ × ∂yx,
(13)
In (12), α, β, and γ are three different weights in range [0.0, 0.1]. And, the sum of these
three weights is equal to 1.0. Here, α, β, and γ are set to 0.5, 0.25, and 0.25 to better preserve
the vertical gradient than the others. Similarly, the same assigned values of weights α, β,
and γ are settled to define the horizontal edge.
3.2 Image retargeting system
Obviously, the targeted image using the three methods: SC, RSC, and MASC, has distortion
on their borders (see Fig. 4). That is, the effect of moving the saliency-objects inside the
ROI is limited. Only H −RH pixels can be removed in each column, and only W −RW
pixels can be removed in each row to fit the size of the height RH and the width RW of the
ROI (see Fig. 3).
Fig. 5 Edge masks for edge detection with different orientation a Mask with oriented number. b–c Vertical
and horizontal edge mask. d–e two bevel mask M18 and M63

Multimedia Tools and Applications (2019) 78:21731–21758
21741
As shown in Fig. 6a–b, some pixels are missing if too many seams (i.e., the number of
seams n > l) are defined and removed. To solve this problem, additional pair-seams SL, SR,
SU, and SD are defined here. In Fig. 6e, SL and SR are vertical pair-seams in the x-range
[1, l] and [r, W], and SU and SD are horizontal pair-seams in the y-range [1, u] and [d, H].
3.2.1 Deﬁnition of pair-seams
After a vertical “main seam” Sv is defined, the vertical pair-seams SL (or SR) will be
duplicated and the pixels are moved, located between the two seams SL (or SR) and Sv,
in order to fill the missing pixels of the seam Sv (see Fig. 6d). Also, the gap of horizon-
tal “main seam” Sh can be filled with horizontal pair-seams SU (or SD). So, the approach
of pair-seams carving can move saliency-objects to the mask area by repeatedly removing
and duplicating the main-seam and pair-seams, but also guarantee that the target image with
H × W real pixels (see Fig. 6c–d). That is, it will not cause the problem of missing some
pixels (see Fig. 6b). Here, the coordinate sets of four pair-seams are defined by (14)–(17).
sL = {sL
j }H
j=1 = {L(j), j}H
j=1,
s.t.∀j, |L(j) −L(j −1)| ≤1

L(j) < l,
(14)
sR = {sR
j }H
j=1 = {R(j), j}H
j=1,
s.t.∀j, |R(j) −R(j −1)| ≤1

R(j) > r,
(15)
sU = {sU
i }W
i=1 = {i, U(i)}W
i=1,
s.t.∀i, |U(i) −U(i −1)| ≤1

U(i) < u,
(16)
sD = {sD
i }W
i=1 = {i, D(i)}W
i=1,
s.t.∀i, |D(i) −D(i −1)| ≤1

D(i) > d,
(17)
where L(j) and R(j) represent the x-coordinate of the j −th row in pair-seams SL and SR,
respectively; L(i) and R(i) represent the y-coordinate of i−th column in pair-seams SL and
SR, respectively. Similar to the main seam Sv, the four pair-seams made up by 8 neighbor
connected as the following restrictions: |L(j) −L(j −1)| ≤1, |R(j) −R(j −1)| ≤1,
|U(i −1) −U(i)| ≤1, and |D(i −1) −D(i))| ≤1. Also, the four pair-seams can be
represented by (18).
SL = {I(sL
j )}H
j=1 = {I(L(j), j)}H
j=1,
SR = {I(sR
j )}H
j=1 = {I(R(j), j)}H
j=1,
SU = {I(sU
i )}W
i=1 = {I(U(i), i)}W
i=1,
SD = {I(sD
i )}W
i=1 = {I(D(i), i)}W
i=1,
(18)
where sL
j and sR
j are the coordinates the pixels of pair-seams in row j, and sU
i and sD
i
are
the coordinates of pair-seams pixels in row i. For example, if the 7 −th row of pair-seam

21742
Multimedia Tools and Applications (2019) 78:21731–21758
pixels in pair-seams SL is located in (24, 7), the 7 −th pair-seam pixel in SL is represented
as SL
7 = I(sL
7 ) = I(L(7), 7). Then, the optimal pair-seams will be chosen by (19).
SL
∗= arg min
SL ELR(SL) = arg min
SL
H

j=1
ELR(I(sL
j )),
SR
∗= arg min
SR ELR(SR) = arg min
SR
H

j=1
ELR(I(sR
j )),
SU
∗= arg min
SU EUD(SU) = arg min
SU
W

i=1
EUD(I(sU
i )),
SD
∗= arg min
SD EUD(SD) = arg min
SD
W

i=1
EUD(I(sD
i )),
(19)
Here, the vertical and horizontal pair-seams are defined by the energy map ELR and EUD,
respectively, defined by (20)–(21).
ELR(x, y) =
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
EI ′(x, y),
y = 1,
(x < l) 
(x > r),
∞,
y = 1,
(x > l  x < r),
EI ′(x, y)+
1	
i=−1
ELR(x + i, y −1), y ̸= 1,
(x < l 
 x > r),
∞,
y ̸= 1,
(x > l  x < r),
(20)
EUD(x, y) =
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
EI ′(x, y),
x = 1,
(y < u 
 y > d),
∞,
x = 1,
(y > u  y < d),
EI ′(x, y)+
1	
j=−1
EUD(x −1, y + j), x ̸= 1,
(y < u  y > d),
∞,
x ̸= 1,
(y > u  y < d),
(21)
The energy map for SL, SR, SU and SD are defined in the range [1, l], [r, W], [1, u], and
[d, H], respectively. Similar to the energy generating phase for main seam Sv (8)–(9), the

Multimedia Tools and Applications (2019) 78:21731–21758
21743
Fig. 6 The process of seam carving and pair-seam carving. a Main seams. b Removal of main seams. c Main
seam and pair-seams. d Pair-seams carving. e Defined main seams and pair-seams
energy map is created by the cumulative importance map. But, the pair-seams are defined
outside the ROI and the pair seams are not in the mask area MA. That is, we do not need
to consider the mask-aware issue so the new importance map EI ′ is composed by gradient
map and saliency map only in (22).
EI ′ = wg × EG + ws × ES,
(22)
In our experience, we set wg and ws to 0.8 and 0.2, respectively, to increase the perception
of image content than detected saliency content.
3.2.2 Pair-seams carving
Our image retargeting process is shown in Fig. 6c and d. The pixels between pair-seam SL
and main seam Sv are moved inward from SL to Sv. In order to move more pixels to the
mask area, we have to choose the best pair-seams, SL or SR, to retarget the image. Taking
the vertical main seam Sv as an example, if the seam Sv is on the right half of ROI, the
pair-seams SL will be selected as the vertical pair-seam Sv′ to be duplicated, since we can
move more pixels, located outside the ROI and mask area MA, from SL to Sv. That is,
this approach will keep more pixels in ROI and MA. Hence, the difference of coordinate
between main seam and the center of ROI mv and mh can be defined by (23).
mv =
H
j=1 sP
j −((l + r)/2, j),
mh =
W
i=1 sQ
i −(i, (u + d)/2), .
(23)
Here, sP
j −((l + r)/2, j) represent the difference of coordinate between main seam Sv and
the center of ROI in row j. The value of mv > 0 means that the main seam is located on the

21744
Multimedia Tools and Applications (2019) 78:21731–21758
right half of ROI, and vice versa. And, both pair-seams Sv′ and Sh′ are defined by (24) and
(25).
Sv′ =
⎧
⎨
⎩
SL, mv > 0,
SR, otherwise,
(24)
Sh′ =
⎧
⎨
⎩
SU, mh > 0,
SD, otherwise,
(25)
Therefore, the main seam, Sv or Sh, and another pair of seam, Sv′ or Sh′, will be selected to
retarget the image. The retargeting process is shown in Fig. 6c and d. In Fig. 6c, the pixels
in red are main-seam pixels, and the pixel in blue are pair-seam pixels. The image pixel in
each row can be retargeted by removing and duplicating main-seam pixels and pair-seam
pixels (see Fig. 6d). Then, the pixels in each row j and column i, in the horizontal and the
vertical retargeting process, are shown in (26) and (27), respectively.
Ij =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
{I(i, j)L(j)
i=1 ∥I(i, j)P(j)−1
i=L(j) ∥I(i, j)W
i=P(j)+1}H
j=1,
Sv′ = SL
{I(i, j)P(j)−1
i=1
∥I(i, j)R(j)
i=P(j)+1∥I(i, j)W
i=R(j)}H
j=1,
Sv′ = SR
(26)
Ii =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
{I(i, j)U(i)
j=1∥I(i, j)Q(i)−1
j=U(i)∥I(i, j)H
j=Q(i)+1}W
i=1,
Sh′ = SU
{I(i, j)Q(i)−1
j=1
∥I(i, j)D(i)
j=Q(i)+1∥I(i, j)H
j=D(i)}W
i=1,
Sh′ = SD
(27)
where (x, y) denote the pixel location in input image I, and I(x, y) represent each pixel
in range x = 1, · · · , W and y = 1, · · · , H. And, the notation “∥” is an operand, denoting
the series connection of pixels in each row or column. That is, the target image in each row
and column can be represented as W and H connected pixels by repeatedly removing and
duplicating the pixels in main seams and pair-seams.
3.2.3 The 4ion
Our approach can repeatedly retarget image without any missing pixel (see Fig. 6d). It
is possible to cause serious distortion in image content if too many pixels are duplicated,
removed, or moved. Therefore, a termination condition is defined here to avoid such serious
distortion.
First, the source image will be retargeted in the horizontal direction with removal of
NV main-seams Sv and duplication of NV pair-seams Sv′ till the MSEv
NV value is lower
than the threshold T H. Here, the vertical and horizontal main-seams are the red seams,
possibility defined in the range of ROI boundary [l, r] (4) and [u, d] (5), respectively.
Then the defined main seams in ROI will be removed; other pair-seams in blue and green
color are defined in the not-ROI region with the range [1, l], [r, W], [1, u], and [d, H]
(see (19)), respectively (also see Figs. 3a and 6e). And, NV and NH represent the total
number of seams been removed in horizontal and vertical directions to get the target image

Multimedia Tools and Applications (2019) 78:21731–21758
21745
T I v = T INV and T I h = T INH in horizontal and vertical directions, respectively. Here,
we set T H to 0.75 to prevent the image from being destroyed by more than 25 percent.
MSEv
nv(x, y) =
	W
x=1
	H
y=1 ∥I(x, y) −T I v
nv(x, y)∥
(W × H)
,
MSEh
nh(x, y) =
	W
x=1
	W
y=1 ∥T I h
NV (x, y) −T I h
nh(x, y)∥
(W × H)
,
(28)
where nv and nh are the iteration number of vertical and horizontal pair-seams carving,
nv = 1, · · · , NV and nh = 1, · · · , NH. And, I(x, y), T I v(x, y), and T I h(x, y) repre-
sent a pixel in source image I, target image after removal of NV seams, and target image
after removal of NV + NH seams, respectively. Then, the value of mean square error in
correspond location (x, y) in vertical and horizontal retargeting process can be represented
as MSEv(x, y) and MSEh(x, y), (see (28)). Also, another target image T IROI, cropped
by ROI from targeted image T I = T I h
NH is presented here as the candidate of the final
targeted image.
3.3 Irregular interpolation
The image retargeting phase is performed in (NV +NH) iterations to obtain the two retar-
geted images T I and T IROI, as the candidate of the final output image. The main seam,
pair seam, and target image in the interaction nv are represented as Sv
nv, Sv
nv
′, and T I v
nv,
respectively. And, T I v
NV and T I h
NH are two output target image after interaction NV and
NV +NH of pair-seams carving. That is, NV vertical main seams Sv
nv and pair-seams Sv
nv
′
(nv = 1, · · · , NV ) are used to retarget source image I in the horizontal direction. Then,
NH horizontal main seams Sh
nh and pair seams Sh
nh
′ (nh = 1, · · · , NH) are used to retarget
target image T I v
NV , to obtain our final target image T I = T I h
NH . A mechanism for irreg-
ular interpolation is presented here to further deform the image content to fit the shape of
the mask. Actually, not all the masks are suitable for irregular interpolation. For example,
the shape of mask ’butterfly’ (see the dashed line in Fig. 7c) is too irregular, which is not
suggested to reshape image using interpolation. In general, there are two difficulties to pro-
hibit some irregular masks from using interpolation directly, with acceptable image quality:
1. the difference of the mask areas is too big between two neighboring columns or rows
(see the dashed line in the Fig. 7c); and, 2. the mask area is too small in one of the rows or
columns (see the dashed line in the bottom of the Fig. 7f). The mask area in horizontal Mh
and vertical Mv directions are defined in (29).
Mh
y =
RW
i=1IS(i, y)
Mv
x =
RH
j=1IS(x, j)
(29)
Among this, Mh
y and Mv
x represent the measured value in row y and column x, and
	RW
i=1IS(i, y) and 	RH
j=1IS(x, j) are used to accumulate the mask area in horizontal and
vertical directions.
Hence, the approach for convex hull is presented here to address the first difficulty. As
shown in Fig. 8a, the convex hull is used to fill the gap. Then, the interpolated results by
using the optimal mask IS′ will not cause heavy distortion due to the rapid changes between
two neighboring columns or rows (see Fig. 8b). In order to avoid some of the columns or
rows with a small mask area, the mask areas in each column or row are limited to be more

21746
Multimedia Tools and Applications (2019) 78:21731–21758
Fig. 7 The selected masks
than a threshold value, th, of the height RH or width RW (see Fig. 8c). The value th is set
to (RH + RW)/10. Then, convex hull is applied again to smooth the contour of the mask
to obtain the optimal mask IS′ (see Fig. 8d). Finally, the target image T I and T IROI can
be reshaped by the optimal mask (see Fig. 9a–j) using bidirectional interpolation in (30), to
get the optimal target image T I ′ and T I ′
ROI.
T I ′(xi, yj) = T I(xi/W, yj/H),
T I ′
ROI(xi, yj) = T IROI(xi/W, yj/H),
(30)
where xi represents the xi-th pixels in horizontal. T I is a targeted image produced by our
image retargeting system. T IROI is cropped from the ROI of T I. Similarly, two interpolated
images T I ′ and T I ′
ROI can be generated. T I ′ is the interpolated image from T I and T I ′
ROI
is the interpolated image cropped by ROI from T I ′. Here, one of the four candidates of
targeted results T I, T I ′, T IROI, and T I ′
ROI will be selected as the best output by our
evaluation mechanism CMEM.
3.4 The content-and-mask-aware evaluation mechanism (CMEM)
The four targeted images T I, T I ′, T IROI, and T I ′
ROI have different image content. First,
we resize the targeted images to the same size, RH by RW. Then, we analyze the four tar-
geted images by the consideration of (1). number of saliency-objects, and (2). deformation
of saliency-objects.
In the targeted image T IROI, the pixels outside the ROI are removed, the saliency-
objects will be highlighted in an area larger than T I; but, T I can preserve more image
Fig. 8 Remark targeted mask. a Define gaps. b Fill the gaps in (a). c Define gaps in (b). d Fill the gaps in
(c). The red and black dot lines represent the process of convex-hull creating and gap-filling respectively

Multimedia Tools and Applications (2019) 78:21731–21758
21747
Fig. 9 Optimal masks based on Fig. 7
content (background and salient-objects) than T IROI. Comparing T I and T I ′, more
saliency-objects are deformed in T I ′ than those deformed in T I. The comparison of these
three items is as follows. (1). T I ′ > T I > T I ′
ROI > T IROI, and, (2). T I ′
ROI > T I ′ >
T IROI > T I.
In order to choose the best target image to fit our needs, the CMEM (31) is presented
here as an evaluation mechanism to decide the output target. And, the method is based on
two factors, namely, number of saliency NS and deformation of saliency DS. The NS and
the DS are defined by the saliency map and the gradient of saliency map. The targeted
image with more saliency-objects will get a higher NS. That is, the saliency-objects can be
preserved well. And, the DS will be presented in higher values, if the saliency-objects are
deformed.
CMEM = wNS × NS + wDS × DS,
(31)
where, wNS and wDS are the weights of NS and DS, and wNS plus wDS is equal to 1. In
general, the interpolated target image T I ′ and T I ′
ROI are with higher value of wDS × DS
than T I and T IROI. That is, if we focus on selecting a target image with lowest image
distortion as final output image, we will assign higher weight as penalty for the DS. And,
if we expect to choose a target image as final output image, containing more image content
from source image, and we will assign lower value to wDS. Here, 0.5 and 0.5 are assigned
to wNS and wDS to consider both number and distortion of image content. Then, the NS
and DS can be defined by (32) and (33).
NS = 	
(x,y)∈MA ES(x, y)/AM,
(32)
DS = 1 −(	
(x,y)∈MA EG′(x, y))/AM,
(33)
As described in the section 3-A, the irregular shape IS is composed by binary value ‘1’
(mask area) and ‘0’. So, the number of binary value in irregular shape IS, named area of
mask AM, can be defined as: AM = 	
IS(i,j)=1 IS(i, j). Also, The gradient of saliency

21748
Multimedia Tools and Applications (2019) 78:21731–21758
map EG′ is adopted here to evaluate the degree of distortion DS in saliency-objects,
applying gradient detection on saliency map ES from target image (see (34) and (35)).
∂y(x, y) =
w/2
i=−w/2
w/2
j=−w/2M27(i, j) ES(x + i, y + j),
∂x(x, y) =
w/2
i=−w/2
w/2
j=−w/2M45(i, j) ES(x + i, y + j),
∂xy(x, y) =
w/2
i=−w/2
w/2
j=−w/2M18(i, j) ES(x + i, y + j),
∂yx(x, y) =
w/2
i=−w/2
w/2
j=−w/2M63(i, j) ES(x + i, y + j),
(34)
E′
G = α × ∂y + β × ∂x + γ × ∂xy + λ × ∂yx,
(35)
Among these, EG′(x, y) is a gradient value calculated by (34). Here, we assigned α, β, γ ,
and λ as the same weight 0.25 to get the saliency edge. In most cases, the targeted image
IT ′ and IT ′
ROI are with higher DS than those of IT and ITROI, as the process of irregular
interpolation deform the image content. wNS and wDS are weights in range [0.0, 1.0], and
are set according to user preferences. The weight wNS and wDS are set to 0.6 and 0.3,
respectively, in our cases. Then, the saliency-objects in the targeted image with large sizes
will be selected as an output image with a higher priority. Conclusively, the whole process
of our CMAIR is shown in Fig. 10.
Fig. 10 Work flow of the proposed CMAIR (Content and Mask-Aware Image Retargeting) method

Multimedia Tools and Applications (2019) 78:21731–21758
21749
Fig. 11 Comparison of object’s structural integrity between CP, RCP, RSC, Qi et al.’s method CASAIR [31]
and the proposed method CMAIR
4 Experimental results
In this section, the methods, namely cropping (CP), ROI-cropping (RCP), ROI-seam-
carving RSC, and Qi et al.’s method CASAIR [31] are compared to highlight the strengths of
our method on irregular image retargeting. An example of comparison of object’s structural
integrity between CP, RCP, RSC, Qi et al.’s method CASAIR [31] and the proposed method
CMAIR is shown in Fig. 11. Obviously, an irregular frame is difficult to accommodate all
objects (see in Fig. 11). The resultant images using CP, RCP and RSC sacrificed the integrity
of some important objects (objects A, B, C and D). Qi et al.’s SSC approach performs bet-
ter at keeping the contents of the object than CP, RCP and RSC, but the edge problem
will be happen by using segmented seam carving (see in (e)). Compared to CASAIR, our
CMAIR does not only remove the portion of the pixel at the edge of the frame (see in (f)).
So, our CMAIR approach can suppress the problem that the object of the resultant image
is partially destroyed. Besides, our CMAIR approach can also highlight objects. Besides,
our approach also has the ability to magnify the subject by removing more unimportant
information (see in Fig. 12). The blue rectangle marked in Fig. 12 shown the advantage of
removing unimportant information using RSC and CMAIR.
As pointed out in section III, the proposed CMAIR algorithm was tested on different
types of source images and masks. And, experimental results demonstrated a significant
difference between the targeted results of our CMAIR method and others, emphasizing that
our CMAIR can keep more salient-objects. In addition, our targeted salient-objects can be
prevented from being severely deformed.
Fig. 12 Comparison of size of object between CP, RCP, RSC, Qi et al.’s method CASAIR [31] and the
proposed method CMAIR

21750
Multimedia Tools and Applications (2019) 78:21731–21758
To ensure the fairness of comparison, ten targeted masks (see Fig. 9) are optimized using
the proposed irregular interpolation for retargeting. In order to verify the usefulness of our
retargeting method, multiple source images and target masks were used to produce multiple
target results.
4.1 Analysis and comparison
We compare our approach with Qi, et al.’s method, CASAIR [31]. In Qi’s method, the mul-
tiple segmented seams, defined in the source image, are used to retarget rectangle image to
irregular shape. The CASAIR method, in simple terms, removes the pixels corresponding to
the segmented seams; then, the retargeting mechanism rearrange the retain pixels to obtain
the target irregular image.
However, the CASAIR method is more likely to produce incomplete salient-objects, and
less likely to retain the size of salient-objects as that of the originals. The segmented seams
unevenly defined in the outer ring of the mask might result in severely deformed objects,
especially in some parts of objects which are located around the boundary of the mask (see
13a). Figure 13 metaphorically depicts the difference between the source (e) and Qi’s target
image (d). The petals at around the boundary of mask, for example, will be deformed (see
in (d)) by the removal of defined segmented seams (see in (c)). See in the red round line
in (d), one of the petals was removed, but our CMAIR approach can keep all the complete
petals (see the blue round line in (i)).
The proposed CMAIR contrasts starkly with the CASAIR method in the definitions of
seam. In CMAIR, the main seams Sv and Sh are defined as the range of [l, r] and [u, d]
(see 6e); thus, the main seams will be defined only at around the ring boundary of mask,
to avoid the occurrence of local deformation of the salient-objects. Obviously, our method
outperforms on salient-objects preservation than Qi et al.’s method.
More results from CP (cropping), RCP (ROI-cropping), RSC (ROI seam carving),
CASAIR (Qi et al.’s method [31]), and the proposed CMAIR are analyzed and compared
in Fig. 14. In the comparison of the integrity of the experimental results, the first column
of Fig. 14 can be clearly found that the rightmost person with severe distortion. And in
the comparison of the size of the subject, CMAIR can highlight the size of the subject
Fig. 13 Comparison between Qi et al.’s method CASAIR [31] and the proposed method CMAIR

Multimedia Tools and Applications (2019) 78:21731–21758
21751
Fig. 14 Comparison among cropping (second column), ROI cropping (third column), ROI seam carving
(fourth column), CASAIR [31] (fifth column) and the proposed method CMAIR (sixth column)
more than CASAIR (e.g. the results of petals, butterflies, couple, mountain, elephants, clock
and the sun). Also, the selected salient-objects in blue color are presented in the first col-
umn, all objects are manually marked by us to evaluate the amount of change after using
our CMAIR. A factor named SOR, pretest-posttest design was used to test the ratio of
the number of salient-pixels SP from the total pixels NP of source or the targeted image
(SOR = SP/NP). The higher SOR from the targeted image compared to the source image
means that the targeted result preserved salient-objects well by making the salient-object
occupy a larger proportion in the whole image. CP and RCP are two different cropping
methods. CP crops the source image with mask-area directly. And, RCP crops the mask area
(MA) of source image to obtain the ROI image. The ROI seam carving is implemented by
the approach illustrated of Fig. 4b. And, all seams are defined in the range of [l r]. Compare
to traditional seam carving SC (see Fig. 4a), RSC can keep more salient-objects in ROI; and,
our CMAIR method is implemented using the strategy of Fig. 4c. As the results observed
in Fig. 4, the SOR in the proposed CMAIR is higher than others. That is, our CMAIR pre-
served more salient-objects than other retargeting methods, especially compared to another
content-and-mask-aware retargeting method, namely CASAIR [31].

21752
Multimedia Tools and Applications (2019) 78:21731–21758
Fig. 15 Comparison among ROI cropping (first row), ROI seam carving (second row) and the proposed
method (third row). Blue circles show the imperfect results
Clearly, the results in Fig. 14 revealed that the salient-objects appears to be an important
consideration in irregular retargeting. Three key points are presented here in our com-
parison: 1. size of salient-objects, 2. number of salient-objects, and 3. deformation of
salient-objects. The RCP and RSC performed better in preserving salient-objects size than
CASAIR. But, the CASAIR can keep more salient-objects than CP, RCP, and RSC. Besides,
we compared the results between CASIR and the proposed CMAIR method. The salient-
objects near the boundary of the mask are heavily deformed. The petals, for example,
are incomplete in the targeted image using CASAIR. Also, the rightmost person becomes
thinner, and the clock and the sun are heavily deformed. Overall, our CMAIR retargeting
method performs with better results in keeping salient-objects.
Another comparison is shown in Fig. 15 to prove that our CMAIR can be applied to
retarget different types of masks. The targeted images generated using ROI cropping and
ROI seam carving are shown in the first and the second row, respectively. For comparing
Fig. 16 Comparison among ROI cropping (first row), ROI seam carving (second row) and proposed method
(third row). Blue box show our advantage

Multimedia Tools and Applications (2019) 78:21731–21758
21753
Fig. 17 Comparison among ROI cropping (first row), ROI seam carving (second row) and the proposed
method (third row). Blue box show our advantage
these three methods, we use blue circles to highlight the shortage in the targeted image
using RCP and RSC. Most of the salient-objects are not preserved well in the RCP than
using CMAIR. For example, the woman’s head and foot are missed in the targeted image.
In this case, our targeted image can preserve more salient-objects such as head, shoulder,
hand, foot, tree, etc.
In order to clarify the relative contribution of our method, more results retargeted by
different kinds of input images and masks are shown in Figs. 16 and 17. The square frames
are marked on our targeted image to emphasize our strengths. Figure 16 shows two example
results, which contain large proportion of the salient-objects (racing car and lotus). Both
RCP and RSC methods cannot preserve salient-objects well, especially in the second and
the third mask, when the area of salient-objects is too big. As mentioned in section III, the
final targeted results will be selected as output by (see (31)). The targeted image T I ′
ROI is
selected as the output, since T I ′
ROI is with the lowest value of CMEM. The other three
targeted images T I, T I ′, and T IROS have the higher CMEM due to the less salience NS,
as the salient-objects are missing. It means that the three targeted image cannot retain the
whole main object inside the mask. In another example, the T I ′
ROI is selected as the output
image (shown on the right side of Fig. 17). That is, our CMAIR output has the strength of
preserving more detail of salient-objects.
In addition, some images with complex content are shown in Fig. 17. One image with
huge areas of the salient-objects (motorcycle) and another image with a large number of
salient-objects (people) are illustrated. The salient-objects are preserved well using CMAIR,
as compared to using RCP and RSC.
5 Conclusion
We proposed a novel algorithm for content-and-mask-aware image retargeting. The proto-
type system can be used to convert rectangular image to irregular shapes, with reasonable
preservation of saliency property in highlighted objects. The prototype system further allows

21754
Multimedia Tools and Applications (2019) 78:21731–21758
different user-defined conditions, to generate the best targeted results. Other image retarget-
ing methods mostly focus on rectangular shape, except one similar algorithm proposed by
Qi, et al. However, for the integrity of salient objects, our CMAIR approach performs much
better.
The main contribution of this paper can be discussed from three different perspectives.
We proposed a new definition to compute energy based on retargeting image and frame
masks. New concepts called pair-seams carving and irregular interpolation can consider
both removal and duplication of contents at the same time. Finally, thresholds of termination
conditions ensure the best fit of contents in irregular masks based on user preferences.
Experimental results show that our CMAR system can deal with the images with a larger
number and the sizes of salient objects better than existing techniques (see Fig. 13, the
flowers, the art painting, and the photos with strong edges of objects). Important background
thus can be preserved better.
Our irregular interpolation can further deform images to retargeted shapes using bilinear
interpolation. But, as mentioned in section 4.3, we can only deform the image to a similar
targeted shape. That is, it cannot guarantee that the image will be completely deformed to
fit the targeted shape exactly. Thus, our proposed CMAIR system cannot deal with irregular
masks with very small and discontinuous areas. In the future, we will improve our irregular
interpolation system to cope with this problem (perhaps, with a heuristic and interactive
approach). In addition, we will extend the method to deal with temporal coherence, which
is essentially important for irregular video retargeting.
Acknowledgements
The authors would like to express thanks to National Central University, Taiwan and
the Iowa State University, America for providing a comfortable experimental environment and adequate
research facilities.
References
1. Avidan S, Shamir A (2007) Seam carving for content-aware image resizing. In: ACM Transactions on
Graphics (TOG), vol 26. ACM, pp 10
2. Barnes C, Shechtman E, Finkelstein A, Goldman DB (2009) Patchmatch: a randomized correspondence
algorithm for structural image editing. ACM Trans Graph 28(3):24–1
3. Bo Y, Sun K, Liu L (2013) Matching-area-based seam carving for video retargeting. IEEE Trans Circuits
Syst Video Technol 23(2):302–310
4. Bo Y, Yuan B, Bo Y (2014) Effective video retargeting with jittery assessment. IEEE Trans Multimedia
16(1):272–277
5. Castillo S, Judd T, Gutierrez D (2011) Using eye-tracking to assess different image retargeting meth-
ods. In: Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and
Visualization, ACM, pp 7–14
6. Cho S, Choi H, Matsushita Y, Lee S (2009) Image retargeting using importance diffusion. In: 2009 16th
IEEE International Conference on Image processing (ICIP), IEEE, pp 977–980
7. Deng C, Lin W, Cai J (2012) Content-based image compression for arbitrary-resolution display devices.
IEEE Trans Multimedia 14(4):1127–1139
8. Dong W, Zhou Ning, Paul J-C, Zhang X (2009) Optimized image resizing using seam carving and
scaling. In: ACM Transactions on Graphics (TOG), vol 28, ACM, pp 125
9. Fan X, Xie X, Zhou H-Q, Ma W-Y (2003) Looking into video frames on small displays. In: Proceedings
of the Eleventh ACM International Conference on Multimedia, ACM, pp 247–250
10. Fang Y, Chen Z, Lin W, Lin C-W (2012) Saliency detection in the compressed domain for adaptive
image retargeting. IEEE Trans Image Process 21(9):3888–3901
11. Fang Y, Lin W, Lee B-S, Lau C-T, Chen Z, Lin C-W (2012) Bottom-up saliency detection model based
on human visual sensitivity and amplitude spectrum. IEEE Trans Multimedia 14(1):187–198

Multimedia Tools and Applications (2019) 78:21731–21758
21755
12. Fang Y, Zeng K, Wang Z, Lin W, Fang Z, Lin C-W (2014) Objective quality assessment for image
retargeting based on structural similarity. cIEEE J Emerging Sel Top Circuits Syst 4(1):95–105
13. Grundmann Matthias, Kwatra Vivek, Han Mei, Essa Irfan (2010) Discontinuous seam-carving for video
retargeting. In: 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, pp
569–576
14. Guo Y, Liu F, Shi J, Zhou Z-H, Gleicher M (2009) Image retargeting using mesh parametrization. IEEE
Trans Multimedia 11(5):856–867
15. Itti L, Koch C, Niebur E (1998) A model of saliency-based visual attention for rapid scene analysis.
IEEE Trans Pattern Anal Mach Intell 20(11):1254–1259
16. Kiess J, Kopf S, Guthier B, Effelsberg W (2010) Seam carving with improved edge preserva-
tion. In: ISAndamp;t/SPIE electronic imaging, International Society for Optics and Photonics, pp
75420g–75420g
17. Kopf S, Guthier B, Lemelson H, Effelsberg W (2009) Adaptation of web pages and images for mobile
applications. In: ISAndamp;t/SPIE Electronic Imaging, International Society for Optics and Photonics,
pp 72560c–72560c
18. Lee J-H, Kim K, Park J, Park JY, Jung S-W (2016) Image recomposition using seam carving
and insertion considering the rule of thirds. IEIE Transaction on Smart Processing and Computing
5(1):1–4
19. Li B, Duan L-Y, Wang J, Ji R, Lin C-W, Gao W (2014) Spatiotemporal grid flow for video retargeting.
IEEE Trans Image Process 23(4):1615–1628
20. Liang Y, Liu Y-J, Gutierrez D (2017) Objective quality prediction of image retargeting algorithms. IEEE
Trans Vis Comput Graph 23(2):1099–1110
21. Lin S-S, Yeh I-C, Lin C-H, Lee T-Y (2013) Patch-based image warping for content-aware retargeting.
IEEE Trans Multimedia 15(2):359–368
22. Liu F, Gleicher M (2005) Automatic image retargeting with fisheye-view warping. In: Proceedings
of the 18th Annual ACM Symposium on User Interface Software and Technology, ACM, pp 153–
162
23. Liu F, Gleicher M (2006) Video retargeting: automating pan and scan. In: Proceedings of the 14th ACM
International Conference on Multimedia, ACM, pp 241–250
24. Liu Hao, Xie Xing, Ma Wei-Ying, Zhang Hong-Jiang (2003) Automatic browsing of large pictures on
mobile devices. In: Proceedings of the Eleventh ACM International Conference on Multimedia, ACM,
pp 148–155
25. Liu Y-J, Xi L, Xuan Y-M, Chen W-F, Fu X-L (2011) Image retargeting quality assessment. In: Computer
Graphics Forum, vol 30. Wiley online library, pp 583–592
26. Ma L, Lin W, Deng C, Ngan KN (2012) Image retargeting quality assessment: a study of subjective
scores and objective metrics. IEEE J Sel Top Sign Proces 6(6):626–639
27. Ma L, Lin W, Deng C, Ngan KN (2012) Study of subjective and objective quality assessment of retar-
geted images. In: 2012 IEEE International Symposium on Circuits and Systems (ISCAS), IEEE, pp
2677–2680
28. Ma L, Xu L, Zhang Y, Yan Y, Ngan KN (2016) No-reference retargeted image quality assessment based
on pairwise rank learning. IEEE Trans Multimedia 18(11):2228–2237
29. Ni B, Xu M, Cheng B, Wang M, Yan S, Qi T. (2013) Learning to photograph a compositional perspective.
IEEE Trans Multimedia 15(5):1138–1151
30. Pritch Y, Kav-Venaki E, Peleg S (2009) Shift-map image editing. In: 2009 IEEE 12th International
Conference on Computer Vision, IEEE, pp 151–158
31. Qi S, Chi Y-TJ, Peter AM, Ho J (2016) Casair: Content and shape-aware image retargeting and its
applications. IEEE Trans Image Process 25(5):2222–2232
32. Qu Z, Wang J, Xu M, Lu H (2013) Context-aware video retargeting via graph model. IEEE Trans
Multimedia 15(7):1677–1687
33. Rubinstein M, Gutierrez D, Sorkine O, Shamir A (2010) A comparative study of image retargeting. In:
ACM Transactions on Graphics (TOG), vol 29. ACM, pp 160
34. Rubinstein M, Shamir A, Avidan S (2008) Improved seam carving for video retargeting. In: ACM
Transactions on Graphics (TOG), vol 27. ACM, pp 16
35. Rubinstein M, Shamir A, Avidan S (2009) Multi-operator media retargeting. In: ACM Transactions on
Graphics (TOG), vol 28, ACM, pp 23
36. Santella A, Agrawala M, DeCarlo D, Salesin D, Cohen M (2006) Gaze-based interaction for semi-
automatic photo cropping. In: Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems, ACM, pp 771–780
37. Shamir A, Sorkine O (2009) Visual media retargeting. In: ACM SIGGRAPH ASIA 2009 Courses, ACM,
pp 11

21756
Multimedia Tools and Applications (2019) 78:21731–21758
38. Simakov Denis, Caspi Yaron, Shechtman Eli, Irani Michal (2008) Summarizing visual data using bidirec-
tional similarity. In: 2008. CVPR 2008. IEEE Conference on Computer Vision and Pattern Recognition,
IEEE, pp 1–8
39. Suh B, Ling H, Bederson BB, Jacobs DW (2003) Automatic thumbnail cropping and its effectiveness. In:
Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology, ACM,
pp 95–104
40. Tao C, Jia J, Sun H (2007) Active window oriented dynamic video retargeting. In: Proceedings of the
Workshop on Dynamical Vision, ICCV
41. Wang Y-S, Fu H, Sorkine O, Lee T-Y, Seidel H-P (2009) Motion-aware temporal coherence for video
resizing. ACM Trans Graph (TOG) 28(5):127
42. Wang Y-S, Tai C-L, Sorkine O, Lee T-Y (2008) Optimized scale-and-stretch for image resizing. In:
ACM Transactions on Graphics (TOG), vol 27. ACM, pp 118
43. Wolf L, Guttmann M, Cohen-Or D (2007) Non-homogeneous content-driven video-retargeting. In: 2007.
ICCV 2007. IEEE 11th International Conference on Computer Vision, IEEE, pp 1–6
44. Wu L, Cao L, Min X, Wang J (2014) A hybrid image retargeting approach via combining seam carving
and grid warping. J Multimed 9(4):483–492
45. Wu L, Gong Y, Yuan X, Zhang X, Cao L (2014) Semantic aware sport image resizing jointly using seam
carving and warping. Multimed Tools Appl 70(2):721–739
46. Yen T-C, Tsai C-M, Lin C-W (2011) Maintaining temporal coherence in video retargeting using mosaic-
guided scaling. IEEE Trans Image Process 20(8):2339–2351
47. Zhang L, Wang M, Nie L, Hong L, Rui Y, Qi T (2015) Retargeting semantically-rich photos. IEEE Trans
Multimedia 17(9):1538–1549
Publisher’s note
Springer Nature remains neutral with regard to jurisdictional claims in published maps
and institutional affiliations.
Hon-Hang Chang acquired his PhD degree in Department of Computer Science and Information Engineer-
ing of National Central University (NCU) of Taiwan in 2017. His research fields are image processing,
information hiding and water marking.

Multimedia Tools and Applications (2019) 78:21731–21758
21757
Timothy K. Shih is Professor at Department of Computer Science and Information Engineering, National
Central University, Taiwan. Prof. Shih is a Fellow of the Institution of Engineering and Technology (IET). In
addition, he is a senior member of ACM and a senior member of IEEE.
Carl K. Chang is Professor and Director of Software Engineering Lab of the Department of Computer Science
at Iowa State University. He received a PhD in computer science from Northwestern University in 1982, and
worked for GTE Automatic Electric and Bell Laboratories before joining the University of Illinois at Chicago
in 1984. He joined the Iowa State University in 2002 as department chair of computer science. He stepped
down as chair after having served in that capacity for 11 years.

21758
Multimedia Tools and Applications (2019) 78:21731–21758
Wallapak Tavanapong received the B.S. degree in Computer Science from Thammasat University, Thailand
in 1992 and the M.S. and Ph.D. degrees in Computer Science from the University of Central Florida in 1995
and 1999, respectively. She joined Iowa State University in s1999 and is currently a Professor of Computer
Science. She is a co-founder and a Chief Technology Officer of EndoMetric, a software company that offers
computer-aided technology for colonoscopy.

