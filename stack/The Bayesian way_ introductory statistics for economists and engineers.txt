THE 
BAYESIAN 
WAY
Introductory Statistics for 
Economists and Engineers
Svein Olav Nyberg


The Bayesian Way


The Bayesian Way
Introductory Statistics for Economists and Engineers
Svein Olav Nyberg
University of Agder
Grimstad, Norway

This edition first published 2019
© 2019 John Wiley & Sons, Inc
Edition History
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or
transmitted, in any form or by any means, electronic, mechanical, photocopying, recording or
otherwise, except as permitted by law. Advice on how to obtain permission to reuse material from
this title is available at http://www.wiley.com/go/permissions.
The right of Svein Olav Nyberg to be identified as the author of the material in this work has been
asserted in accordance with law.
Registered Office(s)
John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, USA
Editorial Office
111 River Street, Hoboken, NJ 07030, USA
For details of our global editorial offices, customer services, and more information about Wiley
products visit us at www.wiley.com.
Wiley also publishes its books in a variety of electronic formats and by print-on-demand. Some
content that appears in standard print versions of this book may not be available in other formats.
Limit of Liability/Disclaimer of Warranty
In view of ongoing research, equipment modifications, changes in governmental regulations, and
the constant flow of information relating to the use of experimental reagents, equipment, and
devices, the reader is urged to review and evaluate the information provided in the package insert or
instructions for each chemical, piece of equipment, reagent, or device for, among other things, any
changes in the instructions or indication of usage and for added warnings and precautions. While
the publisher and authors have used their best efforts in preparing this work, they make no
representations or warranties with respect to the accuracy or completeness of the contents of this
work and specifically disclaim all warranties, including without limitation any implied warranties of
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales
representatives, written sales materials or promotional statements for this work. The fact that an
organization, website, or product is referred to in this work as a citation and/or potential source of
further information does not mean that the publisher and authors endorse the information or
services the organization, website, or product may provide or recommendations it may make. This
work is sold with the understanding that the publisher is not engaged in rendering professional
services. The advice and strategies contained herein may not be suitable for your situation. You
should consult with a specialist where appropriate. Further, readers should be aware that websites
listed in this work may have changed or disappeared between when this work was written and when
it is read. Neither the publisher nor authors shall be liable for any loss of profit or any other
commercial damages, including but not limited to special, incidental, consequential, or other
damages.
Library of Congress Cataloging-in-Publication Data
Names: Nyberg, Svein Olav, author.
Title: The Bayesian way : introductory statistics for economists and engineers / Svein Olav Nyberg.
Description: 1st edition. | Hoboken, NJ : John Wiley & Sons, 2018. | Includes index. |
Identifiers: LCCN 2017060721 (print) | LCCN 2018007080 (ebook) | ISBN 9781119246886 (pdf) |
ISBN 9781119246893 (epub) | ISBN 9781119246879 (cloth)
Subjects: LCSH: Bayesian statistical decision theory. | Economics–Statistical methods. |
Engineering–Statistical methods.
Classification: LCC QA279.5 (ebook) | LCC QA279.5 .N93 2018 (print) | DDC 519.5/42–dc23
LC record available at https://lccn.loc.gov/2017060721
Cover image: © Javi Tejedor Calleja /
Cover design by Wiley
Set in 10/12pt WarnockPro by Aptara Inc., New Delhi, India
10 9 8 7 6 5 4 3 2 1

This book is dedicated to my two beautiful daughters Kira Amalie and
Amaris Beate.
Thank you for being patient with Pappa.


vii
Contents
Dedication
v
Preface
ix

Introduction
1
Part I
Foundations
7

Data
9

Multivariate Data
31

Set Theory and Combinatorics
51

Probability
71

Bayes’Theorem
107

Stochastic Variables on ℝ
137

Stochastic Variables II
171

Discrete Distributions
197

Continuous Distributions
225
Part II
Inference
267

Introduction
269

viii
Contents

Bayes’Theorem for Distributions
279

Bayes’Theorem with Hyperparameters
299

Bayesian Hypothesis Testing
329

Estimates
351

Frequentist Inference
371

Linear Regression
389
A
Appendix
405
B
Solutions to Exercises
423
C
Tables
489
Index
497

ix
Preface
What could possess a man to write a statistics textbook? They are, after all,
bountiful. Well, they are, but when I started lecturing the subject, I found cer-
tain elements missing in all of the books I had available. And as I sat there
contemplating what was lacking, I started writing down what I thought should
have been there, and – well, I really never decided to write this book; it decided
to make me its author.
There are two schools of statistics: bayesianism and frequentism. The key
difference is how they interpret the concept of probability. Even though there
is a lot of common ground, this difference ultimately gives rise to different
methods and interpretations of results. We will explore both schools in this
book, but with an emphasis on the Bayesian way.
So why should we choose the Bayesian way, when it is the one less travelled
by? In the spring of 2016, The American Statistical Association published a
joint proclamation against misuse of p values,1 a popular frequentist measure
of the validity of a scientific result. The reason for the problem is simple: users
simply don’t understand the concept! In addition, it is open to abuse (so called
“p hacking”) if you have understood it. The result of all this is scientific reports
that don’t hold water.
The ASA members were not in agreement as to the solution of the problem,
but many suggested teaching applied users of statistics in the Bayesian school
rather than in the predominant frequentist school. The two schools have each
their advantage: The frequentist school has formulas that are quick to calcu-
late manually, with the use of tables. The Bayesian theory is more unified, and
thereby easier to comprehend. With our current access to tools for calculation,
ease of manual calculation is no longer important, so the time is ripe for the
Bayesian way.
1See Nature March 7th, 2016: http://www.nature.com/news/statisticians-issue-warning-over-
misuse-of-p-values-1.19503

x
Preface
We must, however, remember that frequentism still is the dominant school.
With that in mind, this is not a “purist” Bayesian text, but is rather “Bayesian in
a frequentist way”, making it easier for students to translate results to and from
the frequentist framework and jargon.
Which background do you need to read this book? What do you need to
know? Not much beyond high school math, and you will understand a lot with
even less of a background. When you get to the chapters with the probability
distributions, it helps to understand what a function is: that the function is not
identical to a single formula, but that it is better to think of it as its graph: given
an x as input on the horizontal axis, you get an f(x) as output on the vertical axis.
To be able to do more, a little college math helps. That is, differentiation and
integration, and basic linear algebra: multiplying matrices and vectors, and the
inverse of a matrix. For understanding, the fundamental theorem of calculus is
the key: if F(t) = ∫f (t)dt, then f (t) = F′(t).
A textbook has three dimensions: theory, understanding, and application.
Since this book is aimed at applied rather than theoretical studies, proofs
have been strongly toned down, and have been included only where a proof
would build understanding for a practical user. But mostly, we aim to build
understanding through illustrations, explanations, stories and examples. The
basics of statistics are the same across disciplines, so the same material spans
economics and engineering, as well as science, and even plain fantasy! But we
have also emphasized plain drilling, since many practical users need simple
assignments without too much text.
The ∗mark on some sections means that this section is more theoretical or
advanced, and may require a bit more of your mathematical background or
interest.
You can’t write a book without making mistakes. So we appreciate feedback,
and will publish errata and other useful information on the book’s web site,
http://bayesians.net
A book like this is not written in isolation, and many have given useful com-
ments and suggestions. I would particularly like to thank Billy Case, Steffen
Monrad and Torbjørn Bratten for helpful comments and insights throughout
the writing of this book, and Kira Nyberg, Abbot S̄ozen and Nicholas Caplin
for their illustrations. I would also like to thank Bjørn Olav Hogstad, Nils
Johannesen, Aksa Imran, Øystein Rott, Tore Nordseth, Asle Olufsen, Trygve
Pedersen, Arvid Siqveland, Jannicke Bærheim, Jostein Trondal, my wife Elin
and my father Arne Olav for reading and commenting. I would also like
to thank Erik Yggeseth, Sondre Glimsdal, Hans Grelland, Alireza Borhani,
Mathias P¨atzold, Odd Aalen, and Tom Lassen for examples, inspiration and
other direct help. Thanks are also due to my students for having put up with
being taught from preliminary versions of the book, all the while giving patient
feedback for further development, and thanks to Yvonne Goldsworthy for
insisting that I turn my notes into a book. This book was first published in

Preface
xi
Norwegian, and then later translated into English with a few modifications.
I would like to thank those who have helped me with the English-language
version: Branislav Vidakovic, Jim Farino, Beatrice Kondo, Michael LaTorra,
Gunvor Myklebust, Mark Tabladillo, Nathan Bar-Fields, Hugh Middleton,
John Conway, Tom Chantler, and Hans Jakob Rivertz. I would also like to thank
Michael Brace for his careful copyediting, and Brani Vidakovic for making sure
the English version came into existence in the first place.
This book would not have been what it is without you.
Svein Olav Nyberg
Grimstad, August 2017




Introduction
CONTENTS
1.1
Parallel Worlds, 2
1.2
Counting Positives, 4
1.3
Calculators and Web Support, 6
1.4
Exercises, 6
Modern statistics has two roots: the probability theory Pascal and Fermat
invented in Holland in the late 1600s to solve gaming related problems, and
Prussian state book keeping in the eighteenth century. The name comes from
the latter; and statistics does indeed originally mean “pertaining to matters of
the state” – state bureaucracy and gambling – an odd match indeed. Yet, they
share a need for meticulous reckoning. Prussian bureaucrats kept track of every
oar in the Prussian navy. Not 4218 oars, but 4217. Accuracy was a virtue! But
the same applies in gambling: calculate your odds wrong, and your fantastic
winning gambling strategy is the hole where you flushed last month’s salary.
Statistics has matured and won new territories since its inception.
r Florence Nightingale originated the techniques of descriptive statistics we all
know so well: techniques to visualize data that would otherwise be dry and
lifeless. With a few simple charts, she showed how unsanitary conditions in
the lazarets caused higher mortality rates in wounded soldiers.
r In physics, we use statistics to describe large systems when it is infeasible to
keep track of all the elements. This is statistical mechanics.
r Physicists have also discovered that small particles act like microscopic
roulette wheels: their actions are unpredictable, and we can only state prob-
abilities for what they might do. This is quantum mechanics.
r On the internet, you often get ads tailored to your preferences. This tailoring
is made based on usage statistics about what you look for and which links
you click.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


1 Introduction
r At the other end of the internet, your email client most probably filters
unwanted promotion emails. These filters are often Bayesian spam filters,
based on statistics of what you mark as junk.
r Medical research uses advanced statistics to tell whether and how well drugs
work, how epidemics spread, and the connections between environment,
genetics, other factors, and health.
r Meteorology is statistical. It rarely makes sure predictions, but does instead
seek to find the probabilities that the temperature, wind speed, and rain fall
will be within a certain interval.
r Advanced computer games often employ (Bayesian) statistical learning
strategies so that, while the player learns the game, the game also learns the
player’s strategies in order to counter them better.
r Financial mathematics employs advanced probability theory to calculate the
best pricing for buying and selling.
.
Parallel Worlds
According to the statistician P. A. Fisher, statistics has a threefold purpose:
(1) collecting and ordering data;
(2) systematizing, and summarizing in a few key numbers what the data are
saying;
(3) using the collected data to estimate data we have yet to collect.
This sets up two parallel worlds, interacting and reflecting one another. The
first world, the world of data, is the world we live in. The second world is the
idealized world of our probability calculations, where the properties of proba-
bilities mirror those of data, like idealized versions. These two worlds interact
in that we set up the probabilities in World 2 based on the data from World 1,
and then project probabilities of possible data back from World 2 to World 1.
These worlds mirror one another both in structure and in concepts. In
World 1, we have tables of proportions, and in World 2 we have tables of prob-
abilities. Indeed, the probabilities themselves behave exactly like proportions.
In World 1, we draw graphs of how the height of military recruits is distributed
in a given year, whereas in World 2 we draw graphs of what we consider to be
the probability distribution of the recruits’ heights.
The simplest and also oldest model of probability comes from Pascal and
Fermat’s model for games. The model calculates the probability P of an event A
by finding a symmetrical set of possible states; the probability of event A is then
the quotient of the positive states (those associated with A) to the total number
of possible states:
P(A) = positive
total .

1.1 Parallel Worlds

D4
D12
D10
D6
D120
D60
D48
D30
D24
D20
D7
D2
D8
D4
D12
D10
D6
D120
D60
D48
D30
D24
D20
D7
D2
D8
Figure .Dice Dk are named by the number of their surfaces.
This formula shows us probability as a kind of proportion. Proportions are
numbers between zero and one, or percentages between 0 and 100%. A per-
centage is
1
100, or if the probability is p = 0.237, you find the percentage-wise
number by multiplying by 100%, that is: p = 23.7%. In Chapter 5 we will look at
the different definitions of probability in more detail. What they all have in com-
mon is that probability is a number between zero and one, and that it behaves
like a proportion.
Consider a symmetrical n-sided die Dn to get an instructive example of how
to calculate probabilities the way Pascal and Fermat did: these dice may be
found in most games shops, and come in varieties from the four-sided D4, via
the common cube D6, and further on to D8, D10, D12, and D20. See Figure 1.1.
If you paint five of the sides of a D20 red, the probability of getting red when
you toss that die is P = positive
total
= 5
20 = 0.25 = 25%.
Trials in the real world rarely give us the precise proportion of our proba-
bilities. The data are what they are. But the visual descriptions are the same.
We will see more on this in Chapters 2 and 5. Let us look at the tosses with
a four-sided die: outcomes of real-world trials to the left, and probabilities of
outcomes in the ideal world to the right.
Data (Chapter 2)
Probabilities (Chapter 5)
33 tosses gave “1”, 39 tosses gave “2”,
42 tosses gave “3”, 36 tosses gave “4”.
p(1) = 0.25, p(2) = 0.25,
p(3) = 0.25, p(4) = 0.25.
Frequency table (+ proportions).
Probability table.
Outcome Positives
Proportion
1
33
33∕150 = 0.22
2
39
39∕150 = 0.26
3
42
42∕150 = 0.28
4
36
36∕150 = 0.24
SUM
150
1
Outcome Probability
1
0.25
2
0.25
3
0.25
4
0.25
SUM
1


1 Introduction
1
2
3
4
0.1
0.2
0.3
0.4
1
2
3
4
0.1
0.2
0.3
0.4
Distribution of data
Probability distribution
.
Counting Positives
It is important to count “positives” in the right way. First of all, the possibili-
ties have to be equal, or symmetrical. Consider the case where I write the inte-
gers “1” through “5” on some equally large cards, and put them in a hat: is the
drawing of each number equally probable? What if I told you that there were
906 cards, and that I wrote “1” on 900 of them, and that “2”, “3”, and “5” were
represented with two cards each – while I completely omitted “4”? Are the alter-
natives still equal? Of course not. The probability of drawing each card is the
same, but the probability of each number is not. We say alternatives are sym-
metrical when you can swap two elements without altering the dynamics of the
system. That is: no element is preferentially treated by the system compared to
any other alternative.
Try now a simple coin, and flip it twice. What is the probability of no heads?
It is tempting to enumerate the possibilities: no heads, one heads, two heads,
and conclude that since there are three possibilities, P(0 heads) = positive
total
= 1
3.
But are the alternatives symmetrical? No, for if we inspect a bit more closely,
we see that no heads means you flipped the sequence TT, whereas one heads
could mean either HT or TH – that is: two different sequences. Two heads
again means HH, which is realized only through a the single sequence of two
heads. So, breaking this down to the single flips that we take as symmetrical, we
see that the symmetrical options for two flips are: TT, TH, HT, and HH. This
gives us
P(0) = P(TT) =
|{TT}|
|{TT, TH, HT, HH}| = 1
4.
We illustrate this through two sets of tables (two coin flips in Table 1.1, and two
tosses of D4 in Table 1.2).
Precise estimates and tests for such probabilities are the concerns of the later,
more advanced chapters on statistical inference (basic inference in Section 13.2,
estimates in Section 15.7, and testing in Section 14.2.2). The exploration of how
to count the positives and the possibles is called combinatorics, and is explored
in Section 4.

1.2 Counting Positives

Table .Tables for two coin flips
Outcomes
Number of Heads
Probability table
H
T
H
HH
TH
T
HT
TT
H
T
H
2H
1H
T
1H
0H
Heads Ways Probability
0
1
1∕4
1
2
2∕4
2
1
1∕4
Table .Tables for two tosses of a four-sided die D4
Outcome
Probability table
Die 1
1
2
3
4
1
1, 1
2, 1
3, 1
4, 1
2
1, 2
2, 2
3, 2
4, 2
3
1, 3
2, 3
3, 3
4, 3
4
1, 4
2, 4
3, 4
4, 4
5
1, 5
2, 5
3, 5
4, 5
6
1, 6
2, 6
3, 6
4, 6
Die 2
SUM
Ways
Prob.
2
1
1∕24
3
2
2∕24
4
3
3∕24
5
4
4∕24
6
4
4∕24
7
4
4∕24
8
3
3∕24
9
2
2∕24
10
1
1∕24
TOT
24
1
Total
Die 1
1
2
3
4
1
2
3
4
5
2
3
4
5
6
3
4
5
6
7
4
5
6
7
8
5
6
7
8
9
6
7
8
9
10
Die 2


1 Introduction
.
Calculators and Web Support
In our times, most of us have access to decent or even advanced statistical
tools. The most common, and surprisingly advanced, tools are spreadsheets like
Microsoft® Excel. We have chosen to focus on three common calculators from
Casio®, Hewlett Packard, and Texas InstrumentsTM, and on Mathematica®,
which is freely and very easily accessible through the free front end Wolfram
Alpha: http://www.wolframalpha.com.
We will also strive to link to other tools and resources at the book’s web page,
and if you would like to contribute a program or a manual, please contact us at
http://bayesians.net.
.
Exercises
1
Review: Read the chapter.
– What is the purpose of statistics?
– What is a D8?
– Given a D4 and a D6: in how many ways can you get a total of five?
2
Find the symmetrical alternatives when you flip a coin three times. What is
the probability of two heads and one tails?
3
Find the symmetrical alternatives when you toss two D6. What is the prob-
ability that their sum is three? What is the probability their sum is seven?
4
If we could make pancakes forever, and it turns out that the proportion of
burned pancakes stabilizes at 0.137, would that matter for the probability
that pancakes are burnt?

Part I
Foundations




Data
CONTENTS
2.1
Tables and Diagrams, 10
2.2
Measure of Location: Mode, 14
2.3
Proportion Based Measures: Median and Percentile, 15
2.4
Measures of Spread: Variance and Standard Deviation, 20
2.5
Grouped Data, 22
2.6
Exercises, 28
By data we mean a collection of a given type of values. The values are most
commonly numbers, but can be anything we have received in response to our
queries or measurements. Non-numerical values are called categorical data,
which simply means information about membership of a category. One exam-
ple of this is if our query is about preferences for a political election; the data
would then be the names of a political party like Democrat, Republican, Liber-
tarian, or Green in the USA, but also the categories Don’t know, Others, and
Blank. With categorical data, numbers come into play only when we are count-
ing the number of hits in the different categories. This is as opposed to numer-
ical data, which is the most common form of data, where the data are them-
selves numbers. Examples of such data are the times for a 60 yards dash, where
the data are the times, and not the runners themselves or their names. Or the
waist circumference of diabetic teenagers, where again the data are simply the
number of inches in each measurement.
The population is the total of all possible values – including the ones that are
not measured. We have two models of this: the rather concrete urn model, and
the more abstract process model. We start with the urn model.
The urn model of a population is a finite set, an “urn” that contains little
notes with values written on them. In an election, the population is the politi-
cal preferences of the voters, and not the voters themselves. In an urn model of
the population of the 2016 US election, the population would be the 139 mil-
lion individual votes, and have values “Green”, “Libertarian”, “Republican”, or
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


2 Data
Population
Sample
Figure .Population and sample.
“Democrat”. So if, for instance, there were 4 042 291 votes for the libertarian
party, the population contains 4 042 291 values “Libertarian”. If you are looking
at diabetic teenagers’ waist circumferences, the population is the total set of
waist measurements that could have been collected. So the population might
contain a million “36.0 inches”, and none of “20.0 inches”. What matters to us
are the values, and how many there are of each.
The process model of a population differs from the urn model in the same way
that dice differ from a deck of cards. We abstract away the number of instances
of each value, and look instead at the proportions for each value. For the US
election mentioned above, four million then becomes 3.2%. For the value “17”
on a D32 die, the proportion 3.125% is all we have, as there is no fixed number
of dice tosses. When we later in this book will be talking about sampling from
a probability distribution, we are referring to the process model.
The sample consists of the data we have actually collected. In an urn model,
we justify sampling by appealing to cost: the sample will usually be a lot
smaller than the population, as illustrated in Figure 2.1. So if we can draw suffi-
ciently reliable conclusions by sampling a thousand values rather than doing an
exhaustive measurement of several millions, then we should be sampling. In a
presidential election, polls are often conducted by asking a few thousand voters
for their preference. The pollsters then draw a fairly reliable conclusion about
the political preferences of the entire population.
We will need to index our data. The most common way of indexing is enu-
meration, x1, x2, … , xn, but other indexes like time and location might at times
be more expedient. If you are looking at stock prices, like the ones in Figure 2.2
from the Oslo Stock Exchange (OSE), then it is better to write the price of an
Orkla stock, at 12:00 on the 16th of September 2008, as x2008.09.16.12:00, than to
enumerate it as x3127 if it was your 3127th observation. But if no special factors
come into play, enumeration x1, x2, … , xn is the default choice.
.
Tables and Diagrams
We often compress our observations into groups of equal value, noting only
the number of observations for the value. We express this in a frequency table,
counting how many there are of each kind, and a bar chart.

2.1 Tables and Diagrams

100.00
90.00
80.00
70.00
60.00
Price
Jan 08
Mar 08
May 08
Jul 08
Sep 08
Figure .Orkla stock price. Source: OSE 2008.
Example 2.1.1
Nathan counts the different books on Suzie’s science book-
shelf. He makes the frequency table and bar chart in Figure 2.3 from his
measurements.
We have two basic types of data: numerical data and categorical data. When
the data values are numbers, the horizontal axis becomes a value axis, whereas
the vertical axis marks (relative) frequency.
Example 2.1.2
We asked 150 households how many TVs they owned. Our
data are collected in Figure 2.4.
We are frequently more interested in the relative frequencies (proportions)
pk = ak∕∑ak than in the absolute frequencies ak themselves. When polling
agencies report probable voter distribution for the next election, most of us
are more interested in hearing that Jill Stein got 1% of the polled votes than
in knowing that exactly 18 of the 1800 respondents said they would vote for
Stein.
Value vk (subject)
Frequency ak
A: Astronomy
3
P: Physics
5
EE: Electrical Engineering
16
M: Mathematics
6
S: Statistics
9
E: Economics
1
Sum, n
40
A
P
EE M
S
E
5
10
15
20
(b) Bar chart.
(a) Table.
Figure .The books on Suzie’s bookshelf.


2 Data
Value vk (TVs)
Frequency ak
1
33
2
39
3
42
4
36
Sum
150
1
2
3
4
15
30
45
60
Figure .Number of TVs in a household.
Example 2.1.3
(Continuation of Example 2.1.2) We find the proportions of
how many households own how many TVs by normalizing the frequency table.
That is, by dividing the category frequency by the total frequency, as shown in
Figure 2.5.
Example 2.1.4 We have data from adherents.com about the adherents of the
largest religions. We display the data in Figures 2.6 and 2.7.
In this chart, the relative size of each religion is very visible, since the size
of the pie slices is proportional to the number of adherents of each religion.
But if we are interested making the smaller religious groups visible, we must
abandon proportional representation. We choose a method that maintains the
ordering by size, but not proportionally, by taking the logarithm of the number
of adherents. The largest religions remain largest, but a factor of 10 is now only
1 unit, and a factor of 100 is 2 units higher.
So a logarithmic vertical axis brings forth the smaller religions in this
chart.
..
Cumulative Data
In many applications, it is more useful to know how many of the values fall
within a certain interval, or over or below a given value, than it is to know how
Value vk (TVs)
Relative frequency pk
1
33∕150 = 0.22 = 22%
2
39∕150 = 0.26 = 26%
3
42∕150 = 0.28 = 28%
4
36∕150 = 0.24 = 24%
Sum
1
1
2
3
4
0.1
0.2
0.3
0.4
Figure .Relative frequency of number of TVs in a household.

■Christianity
2 100 000 000
■Islam
1 500 000 000
■None
1 100 000 000
■Hindu
900 000 000
■Traditional Chinese
394 000 000
■Buddhism
376 000 000
■Tribal religion
300 000 000
■Traditional African
100 000 000
■Sikh
23 000 000
■Juche
19 000 000
■Spirits
15 000 000
■Judaism
14 000 000
■Baha’i
7 000 000
■Jainism
4 200 000
■Shinto
4 000 000
■Cao Dai
4 000 000
■Zoroaster
2 600 000
■Tenrikyo
2 000 000
■Traditional European
1 000 000
(b) The pie chart.
(a) Colour codes.
Figure .Pie charts are good for visualizing proportions.
Christianity
Islam
None
Hindu
Trad. Chinese
  Buddhism
Tribal religion
African Trad.
Sikh
Juche
   Spirits
  Judaism
Baha'i
  Jainism
Shinto
Cao Dai
Zoroaster
Tenrikyo
Trad. European
106
107
108
109
Figure .Bar chart with logarithmic vertical axis.


2 Data
Table .Cumulative frequency table for number of TVs in household
Value
Frequency
Cumulative frequency
1
33
33
2
39
39 + 33 = 72
3
42
42 + 72 = 114
4
36
36 + 114 = 150
Value
Cumulative frequency
1
33
2
72
3
114
4
150
many have a certain exact value. It is, for instance, of more interest to know how
large a proportion of drivers have a blood alcohol content above 0.5
, than it
is to know how many of them have precisely 0.73
. The most common way of
stating these numbers is the cumulative frequency: the number who are at or
below a given threshold value.
Example 2.1.5
(Continuation of Example 2.1.2) We asked 150 households
how many TVs they had. We want to know how many households had three
TVs or fewer, and the same for the other possible values. In Table 2.1, we expand
the frequency table with an extra column for the cumulative frequency, and
then form the table with the cumulative frequency alone.
The cumulative frequency chart is related to its table in the same way that the
bar chart is related to the regular frequency table. In Figure 2.14, we illustrate
how we construct the cumulative frequency diagram 2.8c from the frequency
chart 2.8a:
.
Measure of Location: Mode
It is frequently expedient to say what is a “typical value” for a given set of data.
This is often known as a measure of location. The main measures of location
are the mean ̄x and the median ̃x. The median is literally in the middle, with half
15
30
45
60
1
2
3
4
15
30
45
60
75
90
105
120
135
150
1
2
3
4
15
30
45
60
75
90
105
120
135
150
1
2
3
4
(c) Cumulative frequency.
(a) Frequency.
(b) Constructing.
Figure .Construction of the cumulative frequency diagram.

2.3 Proportion Based Measures: Median and Percentile

of the observations on either side, whereas the mean is weighted by distance,
like the center of gravity of a group of equally heavy objects.
But there is one more measure of what is “typical”, and it’s particularly useful
for categorical data. You can’t perform arithmetic on categorical data, or even
sort by size, so there is no mean or median. But the mode can be defined regard-
less of the nature of the data. It is simply the most frequently occurring value. In
the religions example, the mode is “Christianity”, since it has the highest num-
ber of adherents. In the TV survey, the mode is three, since the most common
number of TVs in a household is three.
.
Proportion Based Measures: Median and Percentile
For proportion based measures, we order our observations by giving them new
indexes by rising order of magnitude: x(1), x(2), … , x(n).
Example 2.3.1 Let x1 = 9, x2 = −1, x3 = 7, x4 = 5, x5 = 2. Switching to order-
ing indexes, we get x(1) = −1, x(2) = 2, x(3) = 5, x(4) = 7, x(5) = 9.
The median is the “observation in the middle”: there are as many observations
above it as below it. We calculate the median ̃x of the observations x(1), … , x(n)
like this: If n is odd, there is one observation in the middle, which is the median.
If n is even, there are two observations in the middle; the median is then the
middle value between these two.
Definition 2.3.2
The median ̃x of the observations x(1), x(2), … , x(n) is
given by
̃x =
{
x([n+1]∕2)
if n is odd
1
2(x(n∕2) + x(n∕2+1))
if n is even.
Example 2.3.3 Your observations are 2, 200, 10, 78, 5. What is the median?
Answer: We order the five observations by value (see Figure 2.9): x(1) = 2,
x(2) = 5, x(3) = 10, x(4) = 78, x(5) = 200. Then
̃x = x([5+1]∕2) = x(3) = 10.
2
5
10
78
200
x=10
~
Figure .Odd numbers: the median is the middle observation.


2 Data
-1
3
5
6
7
6
x=5.5
~
Figure .Even numbers: the median is the average of the two middle observations.
Example 2.3.4 Your observations are 3, 6, −1, 7, 6, 5. What is the median?
Answer: We order the six observations by value (see Figure 2.10): x(1) = −1,
x(2) = 3, x(3) = 5, x(4) = 6, x(5) = 6, x(6) = 7. Then
̃x = 1
2
(x(6∕2) + x(6∕2+1)
) = 1
2(x(3) + x(4)) = 1
2(5 + 6) = 5.5.
The formula remains the same if we have grouped data having the same value.
We just need to remember to count each value as many times as it was observed,
and find the middle of the sorted observations.
Example 2.3.5
What is the median number of TVs in the households from
Examples 2.1.2, 2.1.3, and 2.1.5?
To answer this calls for a revisit of the cumulative table, as shown in
Table 2.2).
There are 150 measurements in total, an even number. The median is then
the average of x(75) and x(76). We see from the ordered table that x(75) = 3 and
x(76) = 3, so ̃x = (3 + 3)∕2 = 3.
..
Measure of Proportion: Percentile
The median ̃x divides the data so that at least 50% of them are smaller than or
equal to ̃x, and at least 50% are larger than or equal to ̃x. The generalization of
this is the pth percentile, a value that divides the data so that at least p% of them
are smaller than or equal to it, and at least (100 −p)% of them are larger than
Table .Using the cumulative table to find the median
Value
Cumulative frequency
1
33
2
72
3
114
4
150
Observations, ordered
x(1) to x(33) have 1 TV.
x(34) to x(72) have 2 TVs.
x(73) to x(114) have 3 TVs.
x(115) to x(150) have 4 TVs.

2.3 Proportion Based Measures: Median and Percentile

or equal to it. There are, however, several different versions of the percentile,
so we must choose one standard among the many possible.
We will follow the National Institute of Standards and Technology, NIST.
The reasoning leading up to this standard goes like this: The median is
the most important percentile, the 50th percentile. For an even number of
observations ̃x is an average. But let us refine that perspective by allowing
non-integer
ordering
indexes:
If
we
have
n = 4
observations,
̃x =
x((50∕100)×(n+1)) = x((50∕100)×(4+1)) = x(2.5). This puts x(2.5) right in the mid-
dle of x(2) and x(3), giving us x(2.5) = 0.5x(2) + 0.5x(3) by linear interpolation.
We then define the pth percentile as x((p∕100)×(n+1)), and calculate it by linear
interpolation where necessary. We will mostly get x(𝜅) for a non-integer
𝜅. For instance x(3.7). We calculate x(3.7) by linear interpolation, like this:
x(3.7) = (1 −0.7)x3 + 0.7x4. The general formula and method are as follows.
Definition 2.3.6 The pth percentile for an ordered list {x(1), … , x(n)} is
Pp = x(𝜅) = x(h) + d × (x(h+1) −x(h)),
where 𝜅=
p
100 × (n + 1), a number with integer part h and decimal part d,
meaning 𝜅= h.d. If 𝜅< 1 or 𝜅> n, use respectively 𝜅= 1 or 𝜅= n instead.
Mathematica: Quantile[list,
p
100, {{0, 1}, {0, 1}}]
Excel: PERCENTILE.EXC(marked cells,
p
100)
Method 2.3.7 How to calculate the pth percentile Pp, in detailed steps in
the table below (with illustration in Figure 2.11):
Method
Example
0. Find the data and the desired
percentile.
Data: x1 = 5.5, x2 = 7.42, x3 = −14.7,
x4 = 22.8, x5 = 1.12, x6 = 5.02, x7 = 1.
Find the 70th percentile for these data.
1. Identify p and n.
p = 70 and n = 7.
2. Order the data by rising value.
x(1) = −14.7, x(2) = 1, x(3) = 1.12,
x(4) = 5.02, x(5) = 5.5, x(6) = 7.42,
x(7) = 22.8.
3. 𝜅=
p
100 × (n + 1), with integer
part h and decimal part d.
𝜅=
70
100 × (7 + 1) = 5.6, so h = 5 and d = 0.6.
4. Pp = x(𝜅)
= x(h) + d × (x(h+1) −x(h)).
P70 = x(5.6)
= x(5) + 0.6 × (x(6) −x(5))
= 5.5 + 0.6 × (7.42 −5.5) = 6.652.


2 Data
20
60
80
100
-10
10
20
x(1)=-14.7
x(2)=1
x(4)=5.02
x(5)=5.5
x(6)=7.42
x(7)=22.8
Value
Percentile
P70=6.652
70
40
x(3)=1.12
Figure .Percentile.
Definition 2.3.8
The median ̃x = P50 is one of three important per-
centiles known as the quartiles: Q1 = P25, Q2 = P50, Q3 = P75. The interquar-
tile range Q3 −Q1 is often used as a measure of how spread out the data are.
..
Measure of Location: Mean
The mean is a popular measure, and is the value we obtain if we obtain is we
divide the total evenly between the objects we have measured. If, for instance,
Peter, Paul, Ewan, and Tom earn respectively 1, 2, 4, and 5 ounces of gold per
month, they would each have earned 3 ounces of gold per month if it had been
divided evenly, since 1+2+4+5
4
= 3. So 3 is the mean of the numbers 1, 2, 4, and 5.
Definition 2.3.9 Given values x1, … , xn, the sum is
Σx =
n
∑
k=1
xk.
We use this for the following formal definition of the mean.
Definition 2.3.10 The mean ̄x of the observations x1, x2, … , xn is defined
as
̄x = Σx
n .

2.3 Proportion Based Measures: Median and Percentile

Example 2.3.11 “Ye olde milky bar” wants to know the mean number of milk
shakes sold per day, for a given week. The number of milk shakes sold on the
different weekdays are x1 = 163, x2 = 178, x3 = 167, x4 = 191, x5 = 175. The
mean number of units sold per day is then the total divided by the number of
days:
̄x = x1 + x2 + x3 + x4 + x5
5
= 163 + 178 + 167 + 191 + 175
5
= 174.8.
If we have many measurements of equal value, it may make sense to group
the data by value. We definere vk to be the measured values, and ak to be the
number of observations with value vk. Then
̄x = Σx
n
where Σx =
∑
k
akvk
and
n =
∑
k
ak.
(2.1)
Example 2.3.12 We want to find the mean number of TVs in Example 2.1.2.
We use formula 2.1 on the data from the table, and get
̄x = 33 × 1 + 39 × 2 + 42 × 3 + 36 × 4
33 + 39 + 42 + 36
= 2.54.
We get a related formula if we use the relative frequency pk rather than the
frequency ak:
̄x =
∑
k
pk × vk,
where pk =
ak
∑ak
.
(2.2)
The relative frequency formula is particularly useful when there is no canonical
base unit to break the measurements down into, as in the following example:
Example 2.3.13 In the hydro power plant Vanna they measure the water flow
through the turbines at millions of cubic meter per hour. We have the following
data from 14:00 to 15:00 on a given day: For the first 17 minutes the flow was
0.83 million m3∕h. From 14:17 to 14:45, it was 1.13 million m3∕h, after which
it fell to 0.98 million m3∕h for the last quarter hour. What was the mean water
flow at Vanna during that hour?
So how large a proportion of the hour did each period take? The first
period lasted 17 minutes, so p1 = 17
60, and v1 = 0.83. The second period lasted


2 Data
28 minutes, so p2 = 28
60 and v2 = 1.13. Finally, the third period lasted for 15 min-
utes, so p3 = 15
60 and v3 = 0.98. The mean flow is then
̄x = p1v1 + p2v2 + p3v3 = 17
60 × 0.83 + 28
60 × 1.13 + 15
60 × 0.98 = 1.0075.
.
Measures of Spread: Variance and Standard Deviation
Variance and standard deviation are measures of how spread out the data are
around the mean. The standard deviation is the square root of the variance,
so we always calculate the variance first. There are two types of variance, the
sample variance and the population variance. We write 𝜎2
x for the population
variance, and s2
x for the sample variance, meaning 𝜎x and sx are the respective
standard deviations. We recall that a population is all the possible values in our
scope, whereas the sample is our actual measurements.
Definition 2.4.1 For values x1, … , xn, the sum of the squared deviations is
SSx =
n
∑
k=1
(xk −̄x)2.
Given a finite population, the population variance is simply the average
squared deviation for the population.
Definition 2.4.2 The population variance of a population whose values are
x1, x2, … , xn, is
𝜎2
x = SSx
n .
The quantity 𝜎x =
√
𝜎2
x is the population standard deviation.
However, we rarely measure entire populations, so the population variance
is mostly a creature of theory. What we tend to do instead, is to measure a
smaller sample from the population, and approximate the variance by calcula-
tions from that sample. The best approximation to the population variance of
the total, is the sample variance. The sample variance is similar to the popula-
tion variance, but to compensate for how the sample mean deviates from the
population mean, we divide by n −1 instead of n.

2.4 Measures of Spread: Variance and Standard Deviation

Look in Section 16.1 for a more detailed exposition of why we divide by n −1
rather than by n.
Definition 2.4.3
The sample variance calculated from the values
x1, x2, … , xn, is
s2
x = SSx
n −1.
The sample standard deviation is sx =
√
s2
x.
The most useful formula for SSx is the following one, using the sum of
squares.
Definition 2.4.4 The square sum of the values x1, x2, … , xn, is
Σx2 =
n
∑
k=1
x2
k.
As we add more data, we just need to add the new values xi to Σx, and x2
i to
our new friend Σx2 for book-keeping. This way, we don’t need to recalculate all
the (xk −̄x)2 against a ̄x that will of course change value as new data arrive.
Rule 2.4.5
SSx = Σx2 −n ⋅̄x2 = Σx2 −
Σ2
x
n .
Example 2.4.6
“Ye olde milky bar” wants to find the variance and standard
deviation of the number of milk shakes sold per day. They use one week’s mea-
surements. They want to
(1) find the variance and standard deviation of the number of servings within
the week itself, i.e. the week itself is the population;
(2) estimate the variance and standard deviation of the number of servings over
a larger time period, i.e. the week itself is a sample from the greater time
period.
We recall our data, x1 = 163, x2 = 178, x3 = 167, x4 = 191, x5 = 175, and
remember from example 2.3.11 that ̄x = 174.8. We then get
(1) SSx = (1632 + 1782 + 1672 + 1912 + 1752) −5 ⋅174.82 = 472.8;


2 Data
(2) population variance and standard deviation for the week itself:
r 𝜎2
x = SSx
5 = 472.8
5
= 94.56
r 𝜎x =
√
94.56 = 9.7;
(3) Sample variance and standard deviation for the week as an approximation
to a larger time frame:
r s2
x = SSx
5−1 = 472.8
5−1 = 118.2
r sx =
√
118.2 = 10.9.
We have the following simplified formula when the data are given with rela-
tive frequencies.
Rule 2.4.7
𝜎2
x =
(
∑
k
pk × v2
k
)
−̄x2.
We revisit the continuous measurements of the water flow at the Vanna
hydro power plant in the following example.
Example 2.4.8 We will now find the variance and standard deviation of the
water flow at Vanna. From Example 2.3.13, we have p1 = 17
60 and v1 = 0.83, and
then p2 = 28
60 and v2 = 1.13, and finally p3 = 15
60 and v3 = 0.98. Mean flow was
̄x = 1.0075. So
r 𝜎2
x =
(
17
60 × 0.832 + 28
60 × 1.132 + 15
60 × 0.982)
−1.00752 = 0.016 1187;
r 𝜎x =
√
0.016 1187 = 0.126 96.
.
Grouped Data
We often group data into larger groups of values, either for expediency, or
because the data already is present in such groups. One example is clothes sizes,
where we are typically presented with values of the kind “49–51 cm” rather than
a precise, single value.
But the accuracy of measurements also naturally groups the data into such
groups. If we measure the height of recruits for a military batallion, our accu-
racy will be in the order of 1 cm, so a measurement of “175 cm” really means all
heights from 174.5 to 175.5 cm, and so on. Or it could be deliberately divided
into even coarser groups, since a single cm matters little. We then display our
data in a histogram. Notice that histograms differ from bar charts in that they

2.5 Grouped Data

Height in cm
Number of recruits
150−170
88
170−180
1032
180−190
811
190−205
69
Sum
2000
150-170
170-180
180-190
190-205
25
50
100
75
(b) Histogram.
(a) Grouped frequency table.
Figure .Indre Istindfjord, 1959.
mark entire intervals packed back to front, rather than individual values. Do
also note that with the histogram, we use area instead of height.
Example 2.5.1
As an example, here are the heights of recruits from Indre
Istindfjord in 1959, grouped into groups of uneven width for the purpose of
illustration in Figure 2.12.
How do we treat grouped data? We have the following two options.
(1) Representation
We treat the data in the interval between x and y as discretely represented by
the interval midpoint x+y
2 , and calculate as if the midpoint was the actual
value. With this option, we use the formulas we have already established
for point data. When we ignore measure inaccuracy, and for instance just
record the height of all men between 173.5 and 174.5 cm as “174 cm”, this
is what we actually do, and it works fine as long as the intervals are not too
wide. See Figure 2.13.
160
170
180
190
250
500
1000
750
1250
1500
2000
1750
200
Figure .Cumulative bar chart when data are
treated by interval midpoint.


2 Data
160 170 180
190
250
500
1000
750
1250
1500
2000
1750
200
150
250
500
1000
750
1250
1500
2000
1750
160 170
180
190
200
150
250
500
1000
750
1250
1500
2000
1750
cm
recruits
F
160
170
180
190
200
150
(c) Cumulative graph F(x) by 
itself.
(a) Cumulative chart by itself.
(b) Evenly distributed.
Figure .Cumulative bar chart when data are treated as evenly distributed over interval.
(2) Continuous
We consider the data in the interval between x and y to be evenly distributed
over the interval. At the beginning of the interval, we will therefore include
none of the data, but will then progress along a straight line until the end
of the interval, where all the data in the interval are included.
We will explore the continuous alternative. The cumulative graph in Fig-
ure 2.14 provides the information we need, and is also easy to set up directly
from the values at the ends of the interval.
Example 2.5.2 We want to know the number of recruits at 183 cm or shorter,
so we draw the cumulative graph for the data in Figure 2.15, and read (red line)
that there is slightly in excess of 1400 recruits at 183 cm or less.
We can study proportions in the same way.
Example 2.5.3 We want to find the proportion of recruits between 172 and
178 cm. We may do this in two ways, both illustrated in Figure 2.16. We either
Height in cm
(Cumulative) frequency
Up to 150
0
Up to 170
88
Up to 180
1120
Up to 190
1931
Up to 205
2000
250
500
1000
750
1250
1500
2000
1750
160
170
180
190
200
150
F
Figure .Finding percentiles when data are treated as evenly distributed over their
respective intervals.

2.5 Grouped Data

0.025
0.05
0.10
0.075
160 170
180
190
200
f
t (height)
150
0.125
0.25
0.5
0.375
0.625
0.75
1.0
0.875
160
170
180
190
200
150
F
(a) Proportions, f (x).
(b) Cumulative proportions, F (x).
Figure .Finding proportions when data are treated as evenly distributed over interval.
find the area under the graph of histogram 2.16a between 172 and 178, divided
by the total area below the graph. Or: we simply read the difference between
the values of the cumulative graph 2.16b at 172 and at 178.
The cumulative approach is of course also just an approximation, giving us
half and quarter recruits. But it enables us to deal with large data sets, and is
therefore often preferable to exact calculations even where these are possible.
They are also an early model of another type of proportion: probabilities. For
even though observed recruits never will be evenly smeared over an interval,
the probabilites for the different heights will be distributed with a density given
by a function not too dissimilar from these continuous distributions of data.
..
Measures of Location and Spread for Grouped Data
Question: What were the mean, and the sample variance and standard devia-
tion of the height of the recruits from Indre Istindfjord in 1959?
We will answer this question both by representation and by the continuous
model.
Example 2.5.4 Answered through representation: the first group, from 150 to
170, has a1 = 88 data points, and is represented by the midtpoint v1 = 160. For
the second group, v2 = 175 and a2 = 1032. The third group has v3 = 185 and
a3 = 811. Finally, for the fourth group, v4 = 197.5 and a4 = 69. The total num-
ber of recruits is n = a1 + a2 + a3 + a4 = 2000. This gives an average height of
r Σx = 88 × 160 + 1032 × 175 + 811 × 185 + 69 × 197.5 = 358 343
r ̄x = Σx
n = 358 343
1999
= 179.171.


2 Data
We calculate (sample) variance and standard deviation as follows:
r Σ2
x = 88 × 1602 + 1032 × 1752 + 811 × 1852 + 69 × 197.52 = 64 305 706
r SSx = Σ2
x −Σ2
x∕n = 64 305 706 −358 3432
2000
= 101 032
r s2
x = SSx
n−1 = 101 032
1999
= 50.54
r sx =
√
50.5413 = 7.11.
For the continuous model, we need to modify the formulas used to calculate
for variances. The modifications are needed in order to take into account that
the data already are spread out by virtue of being evenly distributed over the
interval. It turns out that the needed correction is a factor of 1
12 times the width
of the interval, like this:
Let interval k be Ik = (lk , uk). The interval midpoint is vk = (lk + uk)∕2
and the interval width is bk = uk −lk. With this notation, the modified
formulas may be stated as the following rule.
Rule 2.5.5 For numerical data grouped into intervals where interval k has
midpoint vk and width bk, we get that
Σx =
∑
k
ak × vk
(2.3)
Σx2 =
∑
k
ak ×
(
v2
k + 1
12 × b2
k
)
.
(2.4)
Example 2.5.6 We return our attention to the example of the recruits: Σx and
̄x are the same for both models, so Σx = 358 343 and ̄x = 179.171
Σx2 = 88 ×
(
1602 + 1
12 × 202)
+ 1032 ×
(
1752 + 1
12 × 102)
+ 811 ×
(
1852 + 1
12 × 102)
+ 69 ×
(
197.52 + 1
12 × 152)
= 64 325 291
SSx = Σx2 −
Σ2
x
n = 64 325 291 −358 3432
2000
= 120 438
s2
x = SSx
n−1 = 120 438
1999
= 60.25
sx =
√
60.25 = 7.76.

2.5 Grouped Data

Table .Cumulative frequency table and cumulative relative frequency table
k
Height in
group k
Cumulative
frequency, ̃F(uk)
Relative cumulative
frequency, F(uk)
0
Up to 150
0
0
1
150 to 170
88
0.044
2
170 to 180
1120
0.56
3
180 to 190
1931
0.9655
4
190 to 205
2000
1
..
Median and Percentile for Grouped Data
Definition 2.5.7 For grouped data we define the percentile Pp as the t value
at which F(t) =
p
100. The median is P50.
Method 2.5.8
(1) Set up a table of cumulative relative frequencies. In the relative frequency
column, for interval k, you will have F(uk) (which is equal to F(lk+1)).
(2) Locate the group k for which F(lk) ≤
p
100 ≤F(uk).
(3) Pp = lk +
p
100 −F(lk)
F(uk) −F(lk) × (uk −lk).
Example 2.5.9 Find the 37.4th percentile for the Indre Istindfjord recruits in
1959.
(1) We do this through the cumulative table (Table 2.3), and the diagram shown
in Figure 2.17.
0.125
0.25
0.5
0.375
0.625
0.75
1.0
0.875
F
p/100=0.374
160
170
180
190
200
150
Pp =176.395
Figure .Finding the percentile through a
cumulative graph.


2 Data
(2)
p
100 = 0.374, which is between F(l2) = 0.044 and F(u2) = 0.56, so k = 2.
(3) Since l2 = 170 and u2 = 180, then
P37.4 = l2 +
p
100 −F(l2)
F(u2) −F(l2) × (u2 −l2)
= 170 + 0.374 −0.044
0.56 −0.044 × (180 −170) = 176.395.
.
Exercises
1
Review: Read the chapter.
(a) Explain in your own words what Σx, Σx2, SSx, ̄x, and ̃x are. Why do we
have different formulas for these quantities?
(b) What is the difference between population and sample, and how are
they connected?
2
Measures of location: Find all the three measures of location (mode,
median, mean), and decide which is the most suitable one for the situation.
(a) The members of Femund Fishers’ Union are located as follows:
i. 24 are from Drevsjø in Engerdal, which has postal code 2443
ii. 6 are from ˚Alesund, which has postal code 6020
iii. 19 are from Røros, which has postal code 7374
iv. 1 are from Bodø, which has postal code 8092
(b) A class of 50 enginering students had the following income distribution
3 months after graduating:
i. 5 were unemployed, so their income was 0.
ii. 41 had yearly salaries (in NOK) of respectively 340 000, 341 000,
342 000 ... in increments of 1000 up to 380 000.
iii. The last four earned respectively 613 000, 727 000, 958 000 and
70 000 000.
(c) For a class of 100 economists, the wage distribution was as follows
3 months after graduation:
i. 51 earned nothing.
ii. Of the 49 remaining, 24 earned 312 000, while 25 earned 478 000.
3
The position number 𝜔(letter) tells us where in the alphabet the given
letter is located. For instance: 𝜔(“b”) = 2. Find the mean, median and pop-
ulation standard deviation for the vowel position numbers in the English
alphabet.
4
For the data sets below:
r Calculate the median and the interquartile range.
r Find the mean and the sample standard deviation.
(a) {−1, −3, 4}
(b) {−0.2, 9.6, −0.1, 11.1, 1.3, −0.2, 11.1, −0.8, 0.4}

2.6 Exercises

(c) {60, 66, 70, 103, 138, 34}
(d) {0.971 49, 0.659 64, 0.345 81, 0.515 90, 0.928 81}
5
We have written the data sets below as pairs of lists: v = {v1, … , vn} and
a = {a1, … , an}, meaning a1 observations of value v1 etc.
r Set up a frequency table and bar chart.
r Set up a cumulative frequency table and a cumulative bar chart.
r Calculate the median and the interquartile range.
r Calculate the mean and the sample standard deviation.
r Mark these measures on the horizontal axes of your charts.
(a) v = {5.6, 5.8, 5.1, 6.4, 5.2, 6.3, 5.0, 5.8, 6.0} and a =
{3, 2, 1, 2, 9, 8, 7, 4, 8}
(b) v = {2, 3, 5, 7, 11} and a = {3, 4, 2, 6, 4}
(c) v = {0.620 362, 0.230 49, 0.375 471, 0.035 230 2, 0.562 372,
0.485 507} and a = {109, 130, 73, 61, 9, 74}
6
You are in charge of a joint purchase of retro sports jackets for local FC Bay-
ern Munich supporter club. The sizes correspond to chest measurements,
and are (in cm): S=87-94, M=94-102, L=102-110, XL=110-121, XXL=121-
133, 3XL=133-145. A few of the members are interested in making orders,
and the total is 23S, 161M, 93L, 211XL, 131XXL and 42 3XL. Use the for-
mulas for grouped data for calculations on the chest measurements in your
local FCB supporter club.
(a) Create a table and a cumulative table, and draw the histogram and the
cumulative graph.
(b) For each interval, find the interval limits lk and uk, and calculate the
widths bk and the average value vk.
(c) Find the median and the two quartiles.
(d) Find mean and the sample variance.
7
We have written the data sets below as pairs of lists, a = {a1, … , an}
and I = {(l1, u1), … , (ln, un)}, meaning a1 observations in interval I1
etc.
r Make the cumulative table and graph.
r Calculate median and interquartile range.
r Find the mean and the sample standard deviation.
r Mark these measures on the horizontal axes of your charts.
(a) I = {(12, 24)} and a = {100}
(b) I = {(0, 30), (30, 60), (60, 90)} and a = {48, 96, 48}
(c) I = {(0, 0.07), (0.07, 0.14), (0.14, 0.28), (0.28, 0.56), (0.56, 1.00)}
and
a = {24, 38, 48, 66, 74}
8
A randomized survey among the supporters of the Scottish football team
Heart of Midlothian FC yielded the following numbers in the different age


2 Data
groups: 0-12 years: 1, 13-18: 9, 19-34: 41, 35-50: 58, 51-64: 33, 65-80: 2. Use
the formulas for grouped data in the following calculations:
(a) Create a table and a cumulative table, and draw the histogram and the
cumulative graph.
(b) For each interval: Find the limits lk and uk, and the width bk and the
average value vk. (Remember you are dealing with stated age here.)
(c) Find the median and the two quartiles.
(d) Find the mean and the sample standard deviation.
9
The Big Gummy Worm Project: This is a practical exercise, where you
need
r a big bag of gummy worms or equivalent
r a measuring tool (e.g., a ruler or measuring tape)
For each gummy worm,
r stretch the gummy worm over the measuring tool until it snaps
r write down the colour, and the length at which it snapped
When you are done measuring and eating gummy worms, gather the data
into tables: one joint table, and one per colour or colour group (depending
on how many tables your teacher has told you to make). Remember that
these are grouped data. For each group:
r Create the frequency table
r Create the cumulative frequency table
r Draw a diagram for each table. (bar chart or histogram; which one do you
think is suitable?)
r Draw a cumulative diagram for each table. (cumulative bar chart or
cumulative graph; which one do you think is suitable?)
r Calculate the median and the mean for each group, and mark on the hor-
izontal axis of the diagrams.
r Calculate the population standard deviation for whole bag, and the sam-
ple standard deviation for each colour group. Explain the difference and
the connection.



Multivariate Data
CONTENTS
3.1
Introduction, 31
3.2
Covariance and Correlation, 32
3.3
Linear Regression, 37
3.4
Multilinear Regression, 43
3.5
Exercises, 48
.
Introduction
We are frequently interested in finding statistical relations between different
variables. We often have one or more controlled variables, and are looking to
see what will happen to the uncontrolled variables. An example of this is if
we study the impact of fertilizer on plant growth. The fertilizer is a controlled
variable, whereas the biomass is an uncontrolled measurement variable, giving
us a pair (fertilizer, biomass). We can also study the relation between a set of
all uncontrolled variables. For instance, by looking at the triplet (age, height,
weight) in random humans.
Example 3.1.1 For a little experiment, I asked my Facebook friends for their
height h (cm) and weight w (kg), and got the data summarized in Table 3.1 and
Figure 3.1.
There is no theoretical limit to how many variables we can include in our
joint measurements, and with current technology the practical limit is also as
good as gone for most applications. We can handle data sets with millions of
joint variables. But to build a fundamental intuition and understanding, two-
and three-joint variables suffice.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


3 Multivariate Data
Table .Height and weight data
h (cm) 188 189 170 163 172 182 168 182 190 181 170 183.5 187 181 162
w (kg)
102 160 100
67
58
94
56
57
83
83
57
79
93
94
79
Example 3.1.2 I asked for some personal data for a given week:
r total number of visits to or by friends (both ways);
r total number of dreams remembered;
r total number of nightmares.
The data are summarized in Table 3.2.
Displaying multivariate data can take some ingenuity, but is reasonably easy
for two and three dimensions. If we have a computer, we can rotate the plot
to see where the data points are located. On paper, we help out with effects
like reference planes and indications of distance from that plane. We see this in
Figures 3.2a and 3.2b.
.
Covariance and Correlation
In addition to measures for the individual variables, such as the mean, median,
and variance, we have measures of the relations between the variables. The two
most important ones are covariance and correlation. Covariance is a bit like
variance; we will see that the variance of x is the covariance of x with itself
(𝜎xx = 𝜎2
x). We define the following.
Definition 3.2.1 For sets of pairs {(xk, yk)}n
k=1,
SSxy =
n
∑
k=1
(xk −̄x)(yk −̄y).
weight (kg)
height (cm)
160
170
180
190
60
80
100
120
140
160
Figure .Plot of height versus weight data.

3.2 Covariance and Correlation

Table .Personal data for a week
Person
Visits
Dreams
Nightmares
A
4
2
2
B
12
2
0
C
5
1
1
D
11
0
0
E
1
3
2
F
0
5
3
G
6
0
0
H
8
3
1
I
0
7
7
J
0
7
7
K
0
1
0
L
7
0
0
M
6
36
24
N
1
2
0
Definition 3.2.2
For n pairs of data, {(xk, yk)}n
k=1 we have
covariance
correlation
𝜎xy = 1
nSSxy
(population)
𝜌xy =
𝜎xy
𝜎x𝜎y
sxy =
1
n −1SSxy
(sample)
rxy =
sxy
sxsy
.
As with variance, the sample covariance is calculated from a subset of the
population as an approximation and estimate of the population covariance
from the entire population, so the population covariance is mostly a theoretical
ideal, and what we calculate is the sample covariance. Interestingly, though, the
sample and the population correlation are always identical.
Dreams
Visits
Nightmares
0
0
5
10
Visits
0
5
10
0 2
4 6 8
Dreams
02 4 6 8
2
4
6
Nightmares
0
2
4
6
(a) Without effects
(b) With effects
Figure .Seeing data in 3D with and without helpful effects.


3 Multivariate Data
 quadrant 1
quadrant 3
quadrant 2
quadrant 4
160
170
180
190
60
80
100
x
y
Figure .Dividing data into the four quadrants around the mean point (̄x, ̄y).
To visualize what covariance and correlation are about (Figure 3.3), we divide
the pairs into four quadrants, where the dividing lines are ̄x and ̄y, respectively.
In quadrants 1 and 3, the product (xk −̄x)(yk −̄y) is positive. For pairs in
quadrants 2 and 4, it is negative. SSxy is the sum of these products, so the
covariances are positive if the products of the pairs in quadrants 1 and 3 out-
weigh the products in quadrants 2 and 4, and negative if it is the other way
around.
Positive covariance is primarily characterized by a data cloud that stretches
from quadrant 3 to quadrant 1, while being narrower in the direction of quad-
rant 2 to quadrant 4. With negative covariance we have the opposite, and
if the covariance is zero, it is generally equally wide along both diagonals
(Figure 3.4).
So what is the difference between covariance and correlation? It is this: cor-
relation tells you how strongly the variation of the two variables are linked,
whereas the covariation tells you a mix of the strength of the link and the size
of the variations. The correlation varies from a minimum of −1 to a maximum
(a) σxy > 0.
(b) σxy = 0.
(c) σxy < 0.
Figure .Typical appearances for the three covariance values 𝜎xy < 0, 𝜎xy = 0, and 𝜎xy > 0.

3.2 Covariance and Correlation

4
6
8
10
4
6
8
10
(a) ρxy = 0.578 σxy = 0.137.
4
6
8
10
4
6
8
10
(b) ρxy = 0.578 σxy = 1.23.
Figure .Contrasting correlation and covariation.
at 1. The closer the correlation is to 1, the closer the cloud of data points will
be to an increasing straight line, as we see in Figure 3.6. On the opposite end,
near −1 the cloud is very nearly on a decreasing straight line. However, around
0, the x and y values are spread independently, and do not gather around any
clear line.
The covariance includes the spread of the data cloud. The formulas make
this precise: covariance 𝜎xy equals correlation 𝜌xy times the measures of spread,
𝜎x𝜎y. Thus the two always have the same sign. We notice the difference if
we multiply the values by a constant n: the correlation remains unchanged,
whereas the covariance is multipied by a factor of n2.
In Figure 3.5b, we have expanded by a factor of n = 3, making the covariance
n2 = 9 times as big. The elliptical demarcations are just aids to mark the data
clouds.
Which one of these two you will be employing, depends as always on context,
and sometimes these quantities will simply be intermediate steps in a bigger
calculation. As a rule of thumb, if we are interested in how tight the relation
between the x and y values is, you are looking for the correlation, whereas if it’s
the magnitude that counts, you are interested in covariance.
2
4
6
8
2
4
6
8
10
12
Figure .Lower plot: 𝜌xy = 1,
𝜎xy = 0.13; upper plot: 𝜌xy = 0.71,
𝜎xy = 1.78.


3 Multivariate Data
In the same way as we used Σx2, the sum of squares, to calculate the variance,
we employ the product sum, Σxy, to calculate the covariance, as follows.
Definition 3.2.3 For n data pairs {(xk, yk)}n
k=1, the product sum is
Σxy =
n
∑
k=1
xkyk.
The rule for calculating SSxy is then simplified to the following rule.
Rule 3.2.4 For n data pairs {(xk, yk)}n
k=1,
SSxy = Σxy −n × ̄x × ̄y = Σxy −
Σx × Σy
n
.
Example 3.2.5
In Table 3.3, we look at the height–weight data from
Example 3.1.1.
Table .Height and weight data, together with some calculated values
h
w
h × w
188
102
19 176
189
160
30 240
170
100
17 000
163
67
10 921
172
58
9 976
182
94
17 108
168
56
9 408
182
57
10 374
190
83
15 770
181
83
15 023
170
57
9 690
183.5
79
14 496.5
187
93
17 391
181
94
17 014
162
79
12 798
2 668.5
1 262
226 386
Σh = 2 668.5
Σw = 1 262
Σhw = 226 386
SShw = Σhw −Σh × Σw
n
= 226 386 −2 668.5 × 1 262
15
= 1 877.09
so
𝜎hw = SShw
n
= 1 877.09
15
= 125.047
shw = SShw
n −1 = 1 877.09
14
= 133.979.

3.3 Linear Regression

The standard deviations are 𝜎h = 9.205 43, 𝜎w = 25.684 9, sh = 9.528 53 and
sw = 26.586 4. Then
𝜌hw = 𝜎hw
𝜎h𝜎w
=
125.047
9.205 43 × 25.684 9 = 0.528 9
rhw = shw
shsw
=
133.979
9.528 53 × 26.586 4 = 0.528 9.
We notice that 𝜌hw = rhw, as they should be, since they are always equal.
.
Linear Regression
We study statistics with a twofold aim: to gain an overview of what is already the
case, and to make predictions about the future in order to inform our choices.
An old technique for both of these is linear regression. Linear regression is
the idea that there is an underlying linear relation between two quantities: an
explanatory variable x, and a response variable y, and that we can recover this
linear relationship from the data, even if they are not on a straight line. The
relation is in other words like this:
y = a + bx + 𝜀,
where 𝜀is noise or inaccuracy in how the straight line a + bx predicts the
y value.
Linear regression proceeds in three steps, as illustrated in Figure 3.7.
How good our guesses are, is the subject of Chapter 17.1. But for now, we can
see from the illustrative example in Figure 3.7 that the guess will be a good but
not perfect alignment with the original, underlying relation.
So why do we bother to use linear regression to find y values from x values,
rather than just measuring the y values directly? Some common reasons are as
follows.
2
4
6
8
5
10
15
(a) There is an underlying
but unknown linear relation
y = a + bx.
2
4
6
8
5
10
15
(b) We make pairwise
measurements (x, y),
where a noise ε has been
added to y.
2
4
6
8
5
10
15
(c) Our best guess at
y = a + bx, given the data, is
the regression line
ˆy = α + βx
Figure .The three steps of linear regression.


3 Multivariate Data
r Measurement of x may be cheap, nearby, now, or low-risk, whereas mea-
surement of y may be expensive, far away, in the future (or distant past), or
downright dangerous.
r Where the x measurement is easily available, the y measurement is possible
only through destroying the object under study. An example of that is the
measurement of body fat. Exact measurement of body fat y means literally
picking the person apart, and is possible on dead people only, whereas mea-
surement of the thickness of a skinfold, or electrical conductance in the body,
is fast and readily done.
Example 3.3.1
“Well kept 20 room oil rig for sale. Panoramic view of the
ocean, and own helicopter landing site.” This was the actual text when the Nor-
wegian oil company StatOil sold the oil rig Veslefrikk on the Norwegian equiv-
alent of Craigslist, Finn.no, for 1 krone (roughly 12 US cents).
You are the project manager for a new Seeland, heading a team that has
already restored a few other, similar oil rigs. Before restoring, you check the
rigs for what you call “major faults”, and you have noticed that the restoration
price seems to have something reasonably close to a linear relation to the num-
ber of major faults. You have restored five platforms for a new district of Seeland
so far:
x: Major faults
20
4
5
19
10
y: Restoration (millions of NOK)
121.56
104.23
108.08
119.01
110.16
Throughout the next pages, we will be answering the following questions
regarding the oil platform restorations.
(a) What is the linear regression line between restoration price y and number
of major faults x? (Answered in Example 3.3.4.)
(b) What are the residuals 𝜀i, the differences between predicted and actual
price of restoration? (Answered in Example 3.3.10.)
(c) What is the standard error for the regression line? (Answered in Example
3.3.10.)
(d) You find a total of 14 major faults in Veslefrikk. What does the regression
line predict the restoration cost to be? (Answered in Example 3.3.4.)
We start out by looking at what it means to find a regression line for a set of data
pairs. We know the regression line is a straight line; but which one should we
choose? We will look at four candidates, four linear functions ̃y(x), and for each
of them mark the residuals 𝜀i = yi −̃y(xi), which are the differences between
the values predicted by the regression lines and the actual measurements. The
residuals are illustrated in Figure 3.8.
Our first definition of and formula for linear regression originated with
Adrien-Marie Legendre, in his book on the orbits of comets. In his book, he

3.3 Linear Regression

5
10
15
20
105
110
115
120
(a) ˜y = 120 −0.5x
5
10
15
20
105
110
115
120
(b) ˜y = 100 + 0.3x
5
10
15
20
105
110
115
120
(c) ˜y = 112 + 0x
5
10
15
20
105
110
115
120
(d) ˆy = 101.5 + 0.96x
Figure .The regression line is the straight line closest to the data.
defined the straight line best adapted to the data as the one with the smallest
total squared distance to the actual measurements. With him, we define the
simple linear regression line in the following way.
Definition 3.3.2 Given a set of data pairs {(xk, yk)}k∈I, the linear regression
line is the straight line ̂y(x) = 𝛼+ 𝛽x minimizing
∑
k∈I
𝜀2
k =
∑
k∈I
(yk −̂y(xk))2,
where 𝜀k = yk −̂y(xk) is the difference between the measured y value, and
the one predicted by the line. We call x the explanatory variable, and y the
response variable.
There are several ways to calculate the coefficients 𝛼and 𝛽for the regression
line ̂y = 𝛼+ 𝛽x. Our chosen method is matrix regression, which is tidy, simple,
and easy to generalize. Notice that matrix regression is not a separate type of
regression; it is simply an efficient method.


3 Multivariate Data
Method 3.3.3
We start out with a set of data pairs {(xi, yi)}n
i=1. We then
define the design matrix X and the response vector y as follows:
X =
⎡
⎢
⎢⎣
1
x1
⋮
⋮
1
xn
⎤
⎥
⎥⎦
y =
⎡
⎢
⎢⎣
y1
⋮
yn
⎤
⎥
⎥⎦
.
Then
𝜷=
[
𝛼
𝛽
]
= (XTX)−1 XTy,
where 𝛼and 𝛽are the coefficients of the regression line ̂y(x) = 𝛼+ 𝛽x.
Example 3.3.4
We want to calculate the regression line for the oil rigs in
Example 3.3.1, and then use that to estimate the cost of restoring Veslefrikk,
which had 14 major faults. We get
XTX =
[
1
1
1
1
1
20
4
5
19
10
]
×
⎡
⎢
⎢
⎢
⎢⎣
1
20
1
4
1
5
1
19
1
10
⎤
⎥
⎥
⎥
⎥⎦
=
[
5
58
58
902
]
(XTX)−1 =
[
5
58
58
902
]−1
=
[
451∕573
−29∕573
−29∕573
5∕1146
]
XTy =
[
1
1
1
1
1
20
4
5
19
10
]
×
⎡
⎢
⎢
⎢
⎢⎣
121.56
104.23
108.08
119.01
110.16
⎤
⎥
⎥
⎥
⎥⎦
=
[
563.04
6 751.31
]
giving us
𝜷=
[
451∕573
−29∕573
−29∕573
5∕1146
]
×
[
563.04
6 751.31
]
≈
[
101.471 3
0.960 061
]
.
The linear regression line is then
̂y(x) = 𝛼+ 𝛽x = 101.471 3 + 0.960 061x.
The expected cost of restoring Veslefrikk is then
̂y(14) = 101.471 + 0.960 061 × 14 ≈114.9 million NOK.
We state the connection with variance, covariance, and correlation without
further ado as follows.
Rule 3.3.5 For {(xk, yk)}k∈I we have 𝛽=
𝜎xy
𝜎2
x
= 𝜌xy
𝜎y
𝜎x
.

3.3 Linear Regression

α0
}
βx
x
-6
-4
-2
2
4
6
10
0
5
10
15
(a) Normal form: ˆy(x) = α0 + βx.
Reference point: (0, y(0)).
α*
}β(x-x)
x
x
- 6
- 4
- 2
2
6
10
0
10
15
(b) Centered form: ˆy(x) = α* + β(x −x).
Reference point: ( ¯x, ¯y).
Figure .Two notations for the same line, with different reference points.
..
Centered Data
Statisticians have many tricks to modify data to make them more amendable
to analysis. We will here employ the most useful one for the context of linear
regression: centering of the x values. Centering simply means that we replace
the x value by its deviation from the center, the mean ̄x, giving us x∗= x −̄x.
The resulting regression line will be the same, but we will write it in centered
form. See Figure 3.9 for illustration.
When x = 0, a0 is the y value; in other words a0 is the y intercept. But 𝛼∗, on
the other hand, is where the regression line intercepts the vertical line x = ̄x,
and the value is 𝛼∗= ̄y. We will use matrix regression, and show how we get
the same line whether we use normal form or centered form.
Example 3.3.6 We continue Example 3.2.5, and find the linear regression line
linking weight to height.
XTX =
[
15
2 668.5
2 668.5
475 997
]
(XTX)−1 =
[
24.9651
−0.139 958
−0.139 958
0.000 786 72
]
XTw =
[
1 262
226 386
]
𝜷=
[
𝛼0
𝛽
]
= (XTX)−1 × XTv =
[
−178.385
1.475 65
]
,
which gives us the linear regression line ̂w(h) = 𝛼0 + 𝛽h = −178.385 + 1.475 65h.


3 Multivariate Data
We then calculate the regression line in centered form as follows.
Example 3.3.7 In centered form, we subtract ̄h = 177.9 from the height data.
Our calculations then give us
XT
∗X∗=
[
15
0
0
1 271.1
]
(XT
∗X∗)−1 =
[
0.066 666 7
0
0
0.000 786 72
]
XT
∗w =
[
1 262
1 875.7
]
𝜷∗=
[
𝛼∗
𝛽
]
= (XT
∗X∗)−1 × XT
∗w =
[
84.133 3
1.475 65
]
,
which yields 𝛼∗= 84.133 3 and 𝛽= 1.475 65, and the linear regression line
̂w(h) = 𝛼∗+ 𝛽× h∗= 𝛼∗+ 𝛽(h −̄h) = 84.133 3 + 1.475 65(h −177.9).
If we multiply the parenthesis, we get the same equation as in normal form:
̂w(h) = 84.133 3 + 1.475 65(h −177.9) = −178.385 + 1.475 65h.
Notice that we will always have
XTX =
[
n
Σx
Σx
Σx2
]
and
XTy =
[ Σy
Σxy
]
,
where we may recall from Rule 2.4.5 that Σx2 −Σ2
x∕n. If we are using centered
form, this simplifies to
XT
∗X∗=
⎡
⎢
⎢
⎢⎣
n
0
0
n
∑
k=1
(xk −̄x)2
⎤
⎥
⎥
⎥⎦
=
[
n
0
0
SSx
]
.
(3.1)
..
Residuals and Standard Errors
We will look at the difference between the predicted values ̂y(xi) and the mea-
surements yi.
Definition 3.3.8 Given data pairs {(xi, yi)}n
i=1, we have
r 𝜀i = yi −̂y(xi) (error/residual for measurement i);
r SSe = ∑n
i=1 𝜀2
i (total squared error);
r s2
e =
1
n−2SSe (standard error for linear regression, squared).

3.4 Multilinear Regression

The best ways to calculate SSe (and thereby also se), are the following.
Rule 3.3.9 Given data pairs {(xi, yi)}n
i=1,
SSe = yTy −𝜷TXTX𝜷
= yTy −𝜷TXTy.
The errors remain the same, independently of whether we perform our calcu-
lations in normal or centered form, since the measurements and the regression
line are identical, regardless of form.
Example 3.3.10 We revisit the oil rig example (Example 3.3.1).
Total squared error: we will calculate SSe in two ways. First, we will calcu-
late it by finding each individual error, squaring them, and then adding up the
total:
i
xi (error)
yi (cost)
̂y(xi)
𝜺i
𝜺
i
1
20
121.56
120.673
0.887 487
0.787 633
2
4
104.23
105.312
−1.081 54
1.169 72
3
5
108.08
106.272
1.808 4
3.270 32
4
19
119.01
119.712
−0.702 452
0.493 439
5
10
110.16
111.072
−0.911 902
0.831 566
5
∑
i=1
𝜀2
i = 6.552 7
We then calculate SSe by employing the matrix formulas. We see that yTy =
∑y2
k = 63 620.6, so
SSe = 63 620.6 −
[
101.471 3
0.960 061
]T
×
[
5
58
58
902
]
×
[
101.471 3
0.960 061
]
= 6.552 7.
In other words, the two calculations yield the same, and SSe =
∑
i 𝜀2
i .
Standard error: s2
e =
1
5−2 × 6.552 7 = 2.184 23, so se = 1.477 91.
We will pursue this example further later in the book, in Example 17.1.2.
.
Multilinear Regression
We generalize the 2-variable linear regression for quantities (x, y) by letting x
be a vector of k different quantities, where measurement i is the pair (xi, y), and
xi = ⟨xi,1, xi,2, … , xi,k
⟩. See Figure 3.10 for an illustration with k = 2.


3 Multivariate Data
0
5
0
5
8
6
4
2
0
10
Figure .The difference between observed value yi (point) and predicted value ̂y(xi)
(surface), with the distance marked as lines between point and surface.
Definition 3.4.1 Given a data set {(xi, yi)}n
i=1, where xi = ⟨xi,1, … , xi,k⟩, the
linear regression surface is given by
̂y(x) = 𝛼0 + 𝛽1x1 + 𝛽2x2 + ⋯+ 𝛽kxk
(normal form)
̂y(x) = 𝛼∗+ 𝛽1x∗
1 + 𝛽2x∗
2 + ⋯+ 𝛽kx∗
k
(centered form)
= 𝛼∗+ 𝛽1(x1 −x1) + 𝛽2(x2 −x2) + ⋯+ 𝛽k(xk −xk),
where the coefficients 𝛼and 𝛽minimize the total square distance between
observed value yi and predicted value ̂y(xi).
The method of matrix regression is easily generalized to this new setting, and
the only difference is that we get a larger X matrix, since we have to make room
for all the dimensions of x.
Method 3.4.2 Given the data set {(xi, yi)}n
i=1 = {(xi,1, xi,2, … , xi,k, yi)}n
i=1, we
define the design matrix X and the response vector y as follows:
X =
⎡
⎢
⎢⎣
1
x1,1
…
x1,k
⋮
⋮
⋮
1
xn,1
…
xn,k
⎤
⎥
⎥⎦
y =
⎡
⎢
⎢⎣
y1
⋮
yn
⎤
⎥
⎥⎦
.

3.4 Multilinear Regression

Then
𝜷=
⎡
⎢
⎢
⎢⎣
𝛼
𝛽1
⋮
𝛽k
⎤
⎥
⎥
⎥⎦
= (XTX)−1 XTy,
where 𝛼and 𝛽1, … , 𝛽k are the coefficients of the regression surface
̂y = 𝛼+ 𝛽1x1 + 𝛽2x2 + ⋯+ 𝛽kxk.
In normal form, 𝛼= 𝛼0, whereas in centered form, 𝛼= 𝛼∗= ̄y and the x
are x∗.
The centered form is defined relative to the mean of each component of x, so
x∗
i = xi −xi.
Notice that the key matrices are
XTX =
⎡
⎢
⎢
⎢
⎢⎣
n
Σx1
Σx2
⋯
Σx1
Σx2
1
Σx1x2
⋯
Σx2
Σx1x2
Σx2
2
⋯
⋮
⋮
⋮
⋱
⎤
⎥
⎥
⎥
⎥⎦
and
XTy =
⎡
⎢
⎢
⎢⎣
Σy
Σx1y
Σx2y
⋮
⎤
⎥
⎥
⎥⎦
so when we are using centered form,
XT
∗X∗=
⎡
⎢
⎢
⎢⎣
n
0
0
⋯
0
SSx1
SSx1x2
⋯
0
SSx1x2
SSx2
⋯
⋮
⋮
⋮
⋱
⎤
⎥
⎥
⎥⎦
.
Example 3.4.3
We are going to find the regression surface for the data in
Table 3.4:
Table .
Raw data {(xi,1, xi,2, yi)}
Centered data {(x∗
i,1, x∗
i,2, yi)}
x1
x2
y
4
2
2
12
2
0
5
1
1
7
5
3
Average:
7
2.5
1.5
x∗
1
x∗
2
y
−3
−0.5
2
5
−0.5
0
−2
−1.5
1
0
2.5
3
0
0
1.5


3 Multivariate Data
Normal form: We leave the calculation as an exercise for the reader, and just
state the result before moving on to show the detailed calculations for the cen-
tered form:
̂y = 283
169 −41
169x1 + 103
169x2.
Centered form: The design matrix is
X∗=
⎡
⎢
⎢
⎢⎣
1
−3
−0.5
1
5
−0.5
1
−2
−1.5
1
0
2.5
⎤
⎥
⎥
⎥⎦
,
which gives us
XT
∗X∗=
⎡
⎢
⎢⎣
4
0
0
0
38
2
0
2
9
⎤
⎥
⎥⎦
and
(XT
∗X∗
)−1 =
⎡
⎢
⎢
⎢
⎢⎣
1
4
0
0
0
9
338
−1
169
0
−1
169
19
169
⎤
⎥
⎥
⎥
⎥⎦
.
Furthermore,
y =
⎡
⎢
⎢
⎢⎣
2
0
1
3
⎤
⎥
⎥
⎥⎦
so
XT
∗y =
⎡
⎢
⎢⎣
6
−8
5
⎤
⎥
⎥⎦
then
𝜷∗= (XT
∗X∗
)−1 × (XT
∗y) =
⎡
⎢
⎢
⎢⎣
3
2
−41
169
103
169
⎤
⎥
⎥
⎥⎦
.
The linear regression surface is then
̂y = 3
2 −41
169(x1 −x1) + 103
169(x2 −x2) = 3
2 −41
169(x1 −7) + 103
169(x2 −2.5).

3.4 Multilinear Regression

This is the same surface we got when we did our calculations in normal form:
3
2 −41
169
(x1 −7) + 103
169
(
x2 −5
2
)
= 283
169 −41
169x1 + 103
169x2.
..
Residuals and Standard Errors for Multilinear Regression
Definition 3.4.4 Given data a set {(xi,1, xi,2, … , xi,k, yi)}n
i=1,
r 𝜀i = yi −⟨1, xi,1, xi,2, … , xi,k⟩× 𝜷(error for measurement i)
r SSe = ∑n
i=1 𝜀2
i (total squared error)
r s2
e =
1
n−(k+1)SSe (standard error for linear regression, squared).
Just like in the bi-variate case,
Rule 3.4.5 Given the data set {(xi,1, xi,2, … , xi,k, yi)}n
i=1
SSe = yTy −𝜷TXTX𝜷.
Example 3.4.6 We continue Example 3.4.3, and calculate the following:
(1) The total squared error SSe
(2) The standard error se
Answer:
(1) Total squared error: We do the calculation in centered form. First,
note that ⃗yTy = |y|2 = 14. Next, our calculations give us (X∗𝜷∗)T =
⟨25
13, −3
169, 181
169, 511
169⟩. The transpose of this is 𝜷T
∗XT
∗= (X∗𝜷∗)T, so
𝜷T
∗XT
∗X∗𝜷∗= (X∗𝜷∗)T(X∗𝜷∗) = |X∗𝜷∗|2 = 2 364
169
SSe = yT⃗y −𝜷T
∗XT
∗X∗𝜷∗
= 14 −2 364
169 =
2
169 = 0.011 834 3.
(2) Standard error: s2
e =
1
4−(2+1) ×
2
169 =
2
169, so se =
√
2
13 ≈0.108 786.


3 Multivariate Data
.
Exercises
1
Review: Read the chapter.
(a) What is the difference between covariance and correlation?
(b) What is “centered form”?
(c) What is SSe a measure of?
2
You are given the data set D = {(x, y)}i∈I = {(−1, 3), (0, 5), (3, 9), (5, 7)}.
(a) Set up the data in a table.
(b) Plot the data in a diagram.
(c) Calculate the covariance between x and y (both the population and the
sample versions).
(d) Calculate the correlation between x and y.
3
You are given the data set D = {(x, y)}i∈I = {(−1, 3), (0, 5), (3, 9), (5, 7)}.
Find the linear regression line.
(a) Write the data in centered form, D∗= {(x∗, y)}i∈I.
(b) Find the regression coefficient 𝛽by employing Rule 3.3.5.
(c) Find the regression line in centered form by employing Method 3.3.3.
(d) Find the regression line in normal form by employing Method 3.3.3.
(e) Multivariate calculus:
i. Let ya,b(x) = a + bx, and calculate f (a, b) = ∑4
i=1(ya,b(xi) −yi)2.
ii. Find the extremal point (𝛼0, 𝛽) of f (a, b). This is the point where
𝜕
𝜕a f (a, b) = 𝜕
𝜕b f (a, b) = 0, and is a minimum.
iii. Write down the linear regression line y = a + bx.
(f) Check to see if you have the same regression line/coefficients in all the
four methods.
(g) Find the best estimate for the y-value when x = 10.
(h) Draw the regression line in a diagram together with the data points.
4
For the data sets below, calculate the following.
r The covariances 𝜎xy and sxy.
r The correlation between x and y.
r The linear regression line. Use matrix regression.
r The square of the standard error, s2
e.
r Illustrate at least one of them with a regression line and data points.
(a) D = {(85, 221.5), (103, 146.1), (98, 262.6), (94, 139.8), (90, 189), (80,
126), (75, 146.5), (102, 221.4), (107, 252.9), (102, 121.4)}.
(b) D = {(5.65, 2.64), (15.62, 9.03), (−2.96, −1.19), (1.29, 2.02), (3.84,
−1.82)}.
(c) D = {(28, 24), (66, 69), (44, 48), (39, 44), (9, 9), (1, 15), (73, 64),
(41, 44)}.

3.5 Exercises

5
For the data sets below, calculate the following.
r The linear regression surface. Use matrix regression.
r The square of the standard error, s2
e.
(a) D = {(42, 79, 1056), (62, 51, 564), (57, 47, 507), (37, 49, 655), (17, 26,
337), (39, 78, 1155), (43, 43, 593), (20, 13, 174), (97, 52, 485), (82, 94,
1158)}.
(b) D = {(101.6, 64.8, 91.5), (14.9, 37.6, 66.6), (37.9, 48.9, 84.8), (−23.7,
28.4, 91.4), (8.7, 33.5, 43.6), (43.1, 16.5, 93.3), (44.3, 32.6, 65.)}.
(c) D = {(−8.5, 22.8, 73.1), (−10.8, 14.8, 69.3), (−5.8, 24.6, 74.9), (−12.9,
20.8, 71.5), (−10.5, 18.9, 75.3)}.




Set Theory and Combinatorics
CONTENTS
4.1
The Set Operation Symbols, 51
4.2
Combinatorics and Product Sets, 56
4.3
Repeated Sampling, 59
4.4
Exercises, 66
We may think of a set as a container for its elements. A box with a deck of cards
inside is a physical realization of a set, and the elements are the individual cards
in the stack. If we want to illustrate set operations with the set of cards, we can
spread out the cards, and draw lines around groups of cards. The groups we
can create in this way are the subsets of the original set.
.
The Set Operation Symbols
r Element ∈: See Figure 4.1. This symbol indicates that something is an
element of a set. x ∈A means that x is an element of the set A. Notice that
an element either is or is not a member of a set; there is no number to “how
much” it is a member, so listing an element twice still just means it is a mem-
ber, not that there are two of it in the set.
A
x∈A
Figure .The element relation x ∈A.
r { , | }: These four symbols are the ones we use to specify sets. We may write
a set in the following two ways.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


4 Set Theory and Combinatorics
1) As a list: A = {1, 3, 5, shoe, Lars, ace of spades, Superbowl}. The elements
can literally be anything. If we can make a list of it, it is a set! We see
that the required building blocks are the parentheses “{” and “}”, and the
commas. Together with the elements themselves, that is what we need to
make a set from a list. The order is irrelevant, so two lists with the same
elements in different order will still mean the same set.
2) As a description of the elements: B = {x|x wears green and plays football}.
This introduces a new symbol, the vertical line “|”; it means “where (the
following condition applies):”. We would like to use these descriptions of
conditions to define subsets. For instance, if C is a deck of cards: D = {x ∈
C|x has a value less than nine}, the set D will be the set of all cards in the
deck that have a value less than nine.
r Subset ⊂, ⊃: See Figure 4.2. If a set B contains all elements that are also
contained in another set A, and maybe some more as well, we say that A is a
subset of B. We will write this as A ⊂B. We can also turn the symbol around
and write B ⊃A to mean the same. This is also stated as B being a superset of
A. If you find it hard to remember which is which, recall the inequality signs
from mathematics: the opening is always toward the larger one.
A
B
A ⊂ B 
Figure .Subset A ⊂B.
r Union and intersection. These are two very useful symbols for building sets.
– Union ∪: See Figure 4.3. Union is inclusive, and A ∪B is the set that con-
tains all elements that are contained in at least one of the sets. In logical
terminology A ∪B are the elements that are in A or B. Notice that we use
the term “or” in the sense of mathematical logic, where it means “at least
one of them is the case”, as in “I’ll make dinner if your father or mother
comes for a visit”, and not “or” as in “I’ll marry Brenda or April when I
graduate”.
An
example:
If
A = {1, 3, 5, 9}
and
B = {2, 5, 8},
then
A ∪B =
{1, 2, 3, 5, 8, 9}. Notice that we list elements occurring in both sets
only once.
A
B
A U B
Figure .Union A ∪B.

4.1 The Set Operation Symbols

– Intersection ∩: See Figure 4.4. In mathematics, we describe the intersec-
tion between the sets A and B like this: A ∩B, whereas the more common
use in statistics is AB, that is: no symbol between A and B. Intersection is
exclusive, so AB contains only those elements that are in both A and B. An
example: If A = {1, 3, 5, 9} and B = {2, 5, 8}, then AB = {5}, since the only
element present in both sets is 5.
AB
Figure .Intersection A ∩B or AB.
– If we are taking the union or intersection of many sets, we use a notation of
indexes, where we enumerate the sets, for instance A1, A2, A3, … , so that
we can (for instance) write the union of the first thousand sets as follows:
∪1000
k=1 Ak. That is, the set of all elements that are members of at least one of
those 1000 sets. Or if we wanted the intersection between sets 42 through
513, we would write ∩513
k=42Ak. That would give us only those elements that
were present in all of those sets.
Sometimes enumeration itself can be a bit cumbersome, especially if
we have a non-counting labelling system for our sets. In those instances,
we make the index set I, so that i ∈I indexes the set Ai, and the union of
all the sets is ∪i∈IAi. The sets could for instance be the list of books read
this year by current students at US universities. The set I would be the
set of indexes of students, for instance indexing each by their university’s
name, followed by their last name and a number, so that an index could
be “HarveyMudd.Johnson.23”. That student’s book list would then be the
set AHarveyMudd.Johnson.23, and the union ∪i∈IAi would be all books read by
at least one current student at a US university. Writing ∪i∈IAi instead of
∪b
i=aAi can also be justified simply by simplicity, even when both forms are
available. The form ∪b
i=aAi is really only necessary when it is important to
specify the numbers a and b.
r Set difference ∖: See Figure 4.5. The symbol “∖” means set difference. A∖B
indicates the members of A that are left when we have removed the elements
that are also members of B. If A = {1, 3, 5, 9} and B = {2, 5, 8}, then A∖B =
{1, 3, 9}, whereas B∖A = {2, 8}.
A concrete example is if A are the drivers through the Lincoln tunnel
on a given Friday evening, and B are the sober drivers on the same Friday
evening. If the police tested drivers for intoxication by the Lincon tunnel
that Friday evening, then A∖B would be the drivers they fined or gave other
legal reaction.


4 Set Theory and Combinatorics
In some mathematics and statistics texts, you will also come across the
symbol −for set difference. That is, A −B instead of A∖B.
A \ B
Figure .Set difference A∖B.
r The Universe Ω: See Figure 4.6. In statistics, we need to specify our uni-
verse of discourse. Which objects, events, possibilities, sequences, etc. we
are studying. These, and none other. We name this set Ω, which is the most
common name. You will also find S used for this purpose. In all the set illus-
trations, Ω is the surrounding rectangle.
It is helpful to think of Ω as the total space of possible events for our prob-
abilistic studies. In practical calculations, however, Ω rarely has a function
as anything but a theoretical entity in the background to ensure the theory
stays consistent, and we often employ an Ω that is far larger than the space
of possible events.
Ω
Figure .The universe Ω.
r The empty set ∅: See Figure 4.7. The set containing no elements at all is very
important in statistics. We write it ∅= { }. It might seem like a pointless set,
but it expresses the important feature of two sets having an empty intersec-
tion. That is, no elements in common. We write AB = ∅to express that A
and B are disjoint.
A
B
AB=Ø
(a) AB = Ø.
(b) The empty set Ø.
Figure .The empty set has no elements; in diagrams, it is a non-existent region.

4.1 The Set Operation Symbols

r Complement Ac: See Figure 4.8. This is really a special case of set difference,
since technically, Ac = Ω∖A. So Ac are all the elements of Ω that are not in A.
If Ω is a deck of cards, and A are the face cards, then Ac are the number cards.
Ac
A
Figure .The complement Ac.
r Cardinality |A| (number of elements): We let | ⋅| be the cardinality of a set.
If for instance A = {Thor, Eric, Gunther, John, Hassan}, then |A| = 5.
Sets You Should Know
r ℕ= {1, 2, 3, 4, …}, “the natural numbers” are the positive integers.
r ℕ0 = {0, 1, 2, 3, …} are the positive integers, plus 0.
r ℤ= {… , −3, −2, −1, 0, 1, 2, 3, …} are all the integers, both positive and
negative.
r ℚ= { a
b|a, b ∈ℤ, b ≠0} – all the fractions.
r ℝare all the real numbers.
Overview
We employ, and should employ, Euler diagrams to illustrate properties of sets.
We typically draw a rectangle to signify the universal set Ω, and use other
shapes inside of that for sets A and B. This is very helpful for visualizing union,
intersection, and number of sets. We sum up and gather all the illustrations in
Figure 4.9.
See For Yourself
It is common to list relations between set operations. It is usually a waste of
time to memorize these. A far better use of your time is to draw them, and see
with your own eyes. Try illustrating the list below, and you will remember the
relations without even trying!
r |A ∪B| = |A| + |B| −|AB|
r |AB| = |A| + |B| −|A ∪B|
r |A∖B| = |A| −|AB|
r |Ac| = |Ω| −|A|
r A ∪B = B ∪A
r AB = BA
r A ∪∅= A (How do you draw the empty set ∅? Do you draw it at all?)
r A∅= ∅
r (Ac)c = A


4 Set Theory and Combinatorics
A
x∈A
(a) Element: x. Set: A.
B
(b) The set B.
A U B
(c) Union A ∪B.
AB
(d) Intersection A ∩B.
A \ B
(e) Set difference A B.
Ac
A
(f) Complement Ac.
A
B
A ⊂ B
(g) Subset A ⊂B.
(h) Empty set ∅= nothing.
Ω
(i) Universe Ω = all.
Figure .Sets and set operations.
.
Combinatorics and Product Sets
We are often looking for the probability of a compound event. It then matters
that we know how to count. Not as in counting 1-2-3…, but as in being able
to find the cardinality of a set. For the simpler operations union, intersection,
and set difference, the Euler diagrams are our best friends and helpers for
this task.
But we have other ways of making sets from sets: Product sets! We are really
doing this all the time in everyday life, for instance when we are ordering
pizza. What kind of meat are we going to have? Chicken, beef, ham, pepper-
oni, or none? (5 options) Should we have onion? (2 options) Olives? (2 options)
Which of the cheeses they offer should we choose? (maybe 4 different ones, so:
4 options). Each of these choices are independent of the others, which gives us
5 × 2 × 2 × 4 possible pizzas – 80 different pizzas! And we have yet to enter the
dispute over pineapple and more exotic pizza toppings.
The elements of product sets are sequences. If A = {a1, a2, a3, a4} and B =
{b1, b2, b3}, then the product set of the two is A × B = {(a, b) | a ∈A, b ∈B}.
Table 4.1 lists all the elements in the product A × B, multiplication table
style.

4.2 Combinatorics and Product Sets

Table .Elements of the product set A × B
a1
a2
a3
a4
b1
(a1, b1)
(a2, b1)
(a3, b1)
(a4, b1)
b2
(a1, b2)
(a2, b2)
(a3, b2)
(a4, b2)
b3
(a1, b3)
(a2, b3)
(a3, b3)
(a4, b3)
Table .Brian’s table
Brian
walk
cycle
work
(Brian, walk, work)
(Brian, cycle, work)
school
(Brian, walk, school)
(Brian, cycle, school)
pub
(Brian, walk, pub)
(Brian, cycle, pub)
Another example is if A = {Brian, Howard}, while B = {walks, cycles} and
C = {work, school, pub}. How many possible sentences are there, then, saying
that “A used means B for getting to C”? We’ll list the options to see:
1.
Brian walks to work.
7. Howard walks to work.
2.
Brian walks to school.
8. Howard walks to school.
3. Brian walks to the pub.
9.
Howard walks to the pub.
4.
Brian cycles to work.
10. Howard cycles to work.
5.
Brian cycles to school.
11. Howard cycles to school.
6. Brian cycles to the pub.
12. Howard cycles to the pub.
This case can also be captured in a table. Or tables, since we have a third vari-
able, and must create a separate table for each option of one of the variables.
We create a table for Brian (4.2) and a table for Howard (4.3).
Another way to visualize product sets, is by a tree diagram. This is more gen-
eral than just simple products, since the branches can be pruned according to
certain rules (as we will see later in Section 4.3, repeated sampling). We illus-
trate the example in Figure 4.10.
If you prefer a vertical flow, that is of course doable (Figure 4.11).
Let S be all the sentences we can form in the example above. Clearly, S =
A × B × C, and unsurprisingly, |S| = |A| × |B| × |C|.
Table .Howard’s table
Howard
walk
cycle
work
(Howard, walk, work)
(Howard, cycle, work)
school
(Howard, walk, school)
(Howard, cycle, school)
pub
(Howard, walk, pub)
(Howard, cycle, pub)


4 Set Theory and Combinatorics
Brian
Howard
work
school
pub
cycle
walk
work
school
pub
work
school
pub
cycle
walk
work
school
pub
Figure .A horizontal tree diagram.
If we choose to expand the sentence by specifying a day of the week, we see
that we must write each of the sentences in S seven times, once for each of
the days of the week in W = {Monday, Tuesday, Wednesday, Thursday, Friday,
Saturday, Sunday}. The set T of sentences “A used means B to get to C on day
W” is seven times as large as the set of sentences “A used means B to get to C”.
To calculate, since T = A × B × C × W, then |T| = |A| × |B| × |C| × |W|.
Stated as a general rule, this is as follows.
Rule 4.2.1 The product rule: If you have a sequence of n sets A1, A2, … , An,
and pick one element ak each from each set Ak, the total possible num-
ber of ways of doing this, equal to the total number of possible sequences
(a1, a2, … , an), is
|A1| × |A2| × ⋯× |An|
Brian
Howard
cycle
walk
work school pub
work school pub
cycle
walk
work school pub
work school pub
Figure .A vertical tree diagram.

4.3 Repeated Sampling

.
Repeated Sampling
Some of the most important product sets are the (repeated) products of a set
with itself, or almost itself. For instance: The set of outcomes for a coin toss is
U = {H, T}. The set of possible sequences of three tosses is S = U3 = U × U ×
U, and its size is |S| = |U|3 = 23 = 8.
Assignment: A single sports game has three possible outcomes: H (home win),
A (away win), and D (draw). If you are going to post a betting slip for a simulta-
neous bet at 12 simultaneous games, how many such betting slips are possible?
We have four basic types of sampling, determined according to two criteria:
Is the sampling done with replacement? Are the results ordered or unordered?
Method 4.3.1 Repeated sampling
1) You first need to determine what type of sampling you are looking at. Ask
and answer the following two questions.
(a) With/without replacement: Are the same elements available for the
next sampling? This is what with replacement means. For dice and
coins, this is the default. For sampling from an urn, this is the case
only if you replace the elements before the next sampling.
r Yes: “with replacement”
r No: “without replacement”
(b) Ordered/unordered: Does the order of the results matter?
r Yes: “ordered” – a sequence, like Heads-Tails-Tails-Heads-Heads
r No: “unordered” – a combination, like three Heads, two Tails
2) Find the parameters n for k:
(a) How many elements are available on the first sampling? This is n.
(b) How many tries? This is k.
We see typical examples from each of the four categories in Table 4.4.
The most important categories are “ordered, with replacement” and
“unordered, without replacement”.
The formulas: When we perform k samples, with n initial possibilities, the
number of possibilities are, depending on replacement and ordering, as shown
in Table 4.5.
Table .Examples from the four categories
with replacement
without replacement
ordered (sequence)
Daily 4 (Exact/Straight)
Solitaire
unordered (combination)
Daily 4 (Any/Box)
Powerball (white balls)


4 Set Theory and Combinatorics
Table .The counting formulas for the four categories
with replacement
without replacement
ordered (sequence)
nk
n!
(n −k)!
unordered (combination)
(
k + n −1
k
)
(
n
k
)
This might be your first encounter with the binomial coefficient (n
k
). The
binomial coefficient is the following expression: (n
k
) =
n!
(n−k)!×k!. We read (n
k
)
as “n choose k” or “n over k”. Most calculators have the binomial coefficient
nCr built-in, often next to the permutation command nPr and factorial (!).
r x! for n! = 1 × 2 × 3 × ⋯× (n −1) × n
r nPr for
n!
(n−r)!
r nCr for (n
r
) =
n!
r!(n−r)!.
Now, why are the sampling formulas as they are? We will illustrate through
the following representative examples.
Example-proof 4.3.2 Ordered sampling with replacement: Let us examine
the Daily 4 (Exact/Straight).
1) What kind of sampling this is:
(a) With/without replacement: We have four columns, and pick a number
from each. The pick is with replacement, since number remains eligible
for the other rows even after you’ve chosen it for one of the rows.
(b) Ordered/unordered: It is also ordered, since when you play Straight/
Exact, you need the exact sequence to win.
2) The parameters n and k are:
(a) For each column, you have 10 options, one for each digit 0–9. So n = 10.
(b) You must pick a number four times, once for each column, so k = 4.
According to our overview, we are to use the formula nk. Let us see how
this formula arises: with just 1 single column, you have 10 options; one per
digit. With 2 columns, your choices correspond to the two-digit numbers
00, 01, … , 98, 99, for a total of 100. So you had to multiply the original 10
by a factor of 10 (number of options for the second digit). Adding another
column means that each of these 100 numbers may be expanded by another
digit 0–9 (10 options), so you’d have to multiply by 10 yet again, for a total
of 1000, which makes sense, since there are exactly a thousand numbers

4.3 Repeated Sampling

from 000, 001, … , up to 998, 999. We see how the system goes, and multiply
by 10 for each new column. For the four columns in Daily 4, that means
104 = 10 000, which is indeed nk since the number of possibilities for each col-
umn was n = 10, and the number of “draws” is the number of columns. That is,
k = 4.
Example-proof 4.3.3 Ordered sampling without replacement: Solitaire is
a class of card games known to most people, and involves laying out a specified
amount of cards on the table, in a specified order. The best known is perhaps
Klondike, where the starting configuration has seven cards lying face-up, at the
top of their respective piles. It matters not only which cards are there, but also
which card is on top of which pile. So how many arrangements of seven face-up
cards are possible?
1) What kind of sampling this is:
(a) With/without replacement: Once a card is in one of the seven posi-
tions, it cannot be in any of the others. So this is without replacement.
(b) Ordered/unordered: The placement of the cards – their order –
matters, so it is ordered.
2) The parameters n and k are:
(a) You have an initial choice of 52 cards, so n = 52.
(b) There are 7 face-up cards, so k = 7.
According to our overview, we are to use the formula
n!
(n−k)!. Let us see how
this formula arises: we see the following.
r The first card is drawn from 52 available cards.
r Once the first card is selected, you have only 52 −1 = 51 available options
for the second card.
r Similarly, for the third card, you have 51 −1 = 50 options.
r … and so on: 49 options for the fourth card, 48 for the fifth, 47 for the sixth,
and 46 for the seventh.
The number of possible configurations is thus
52 × 51 × 50 × 49 × 48 × 47 × 46
= 52 × 51 × 50 × 49 × 48 × 47 × 46 × ⋯× 3 × 2 × 1
45 × 44 × ⋯× 3 × 2 × 1
= 52!
45! =
52!
(52 −7)!.
We notice that regardless of the size of the deck or pile or urn we pick from,
the number of available elements will decrease by one for each draw, which
means the general formula will always be the one we employed in this example.


4 Set Theory and Combinatorics
In other words, the formula for k ordered draws without replacement from n
possibilities, is
n!
(n −k)!.
In our example, n = 52 and k = 7, so the total possible number of 7 picked
from 52 is
52!
(52−7)! = 674 274 182 400.
Example-proof 4.3.4 Unordered sampling without replacement: This time
we will look at regular five-card hand poker.
1) What kind of sampling this is:
(a) With/without replacement: Once a card is dealt to your hand, it cannot
be dealt again, so this is without replacement.
(b) Ordered/unordered: In poker, which cards are in your hand matters,
but not the order in which you received them, so this is unordered.
2) The parameters n and k are:
(a) You have an initial choice of 52 cards, so n = 52.
(b) You are dealt 5 cards, so k = 5.
According to our overview, we are to use the formula (n
k
). Let us see how
this formula arises: since the sampling is unordered, different sequences of
five cards are the same sequence, and this the same hand in poker. So, how
many sequences make up the same hand? This is the same as asking how many
ways we can order the five cards on our hand. We do it card by card: We
have five different positions, and so the first card has all of those five posi-
tions to choose from. The second hand has four, since one is taken by the
first card. The third card has three, the fourth card two, and then the fifth and
last card has to take the one available spot. The total number of orderings is
thus 5 × 4 × 3 × 2 × 1 = 5! = 120, meaning every poker hand can be realized
through 5! = 120 different sequences of how they were dealt. To find the total
number of possible poker hands, divide the possible number of deal sequences
by the number of sequences per hand:
(
52!
(52−5)!
)
5!
=
52!
(52 −5)!5! =
(
52
5
)
.
This reasoning applies to the general case of picking k elements from a total of
n – unordered and without replacement. So the general formula is
(
n
k
)
=
n!
(n −k)! × k!.
(that is: “n choose k”, which is named after precisely this kind of sampling).

4.3 Repeated Sampling

In our example, n = 52 and k = 5, so the total number of possibilities is (52
5
) =
2 598 960.
Notice that when we draw k elements from a total of n, we are splitting a set of
n elements into two sets of respectively k and n −k elements each. So whether
you choose to pick the set of k afterwards, or to pick the set of n −k, or if you are
content with the splitting without picking one afterwards, the formula holds to
describe the number of ways to split the set.
Example-proof 4.3.5
Unordered sampling with replacement: How many
combinations of results are possible as a result of tossing 13 D8 dice, one after
the other? An example of such a combination is “five 1s, two 3s, one 4, one 5,
two 7s, and two 8s”.
1) What kind of sampling this is:
(a) With/without replacement: A die cannot “expend” a number by dis-
playing it. It is still available as a possibility for each of the other
dice. So repeated die tosses, or tosses with multiple dice, is done with
replacement.
(b) Ordered/unordered: In this scenario, we only count the 1s, the 2s, etc.,
and we do not care exactly which dice has which result, as long as the
numbers are right. In other words, the order does not matter, so this is
unordered.
2) The parameters n and k are as follows.
(a) Each die has 8 possible outcomes, so n = 8.
(b) There are 13 dice to be tossed, so k = 13.
According to our overview, we are to use the formula (k+n−1
k
). Let us see how
this formula arises: let us pick 13 white dice for our experiment. We will add 7
black dice, for a total of 20 dice. After we have tossed the white dice, we sort
the dice into a 20-space row as follows: first, we put all the white dice showing
1. Then a black die. After that, the white 2s. Then a new black die. And so on
until, after the last black die, we put the white 8s. If there should happen to be
no white 2s, for instance, then the first and second black die will be neighbours.
In Figure 4.12, we see possibility, with two 1s, two 2s, no 3s, three 4s, two 5s and
one 6, no 7s, and three 8s.
We notice that when we know where in the lineup of 20 the 7 black dice are
positioned, we also know the values of the white dice between them. So the
results of tossing 13 dice D8 correspond uniquely to the ways of placing 7 black
1
1
2
2
4
4
4
5
5
6
8
8
8
Figure .Thirteen white dice, separated by seven black ones.


4 Set Theory and Combinatorics
dice in 20 spaces. That is, (20
7
). Or, equivalently, the number of ways to position
13 white dice in those 20 spaces: (20
13
).
Going through this again, with the parameters k and n not bound to numbers,
we have tossed k dice Dn, which requires n −1 black dice, and k + n −1 spaces
for all the dice. The general formula for k dice Dn is then (k+n−1
k
).
In our example, n = 8 and k = 13, so the total number of possibilities is
(13+8−1
13
) = 77 520.
..
Multiple Sets
Here, we will make use of the multinomial formula from Appendix A.2, a gen-
eralization of the following binomial formula.
Definition 4.3.6
(
n
k1, k2, … , km
)
=
n!
k1!k2! ⋯km!.
Rule 4.3.7 The number of ways to divide a set of n elements into m subsets
of k1, k2, … , km elements each is
(
n
k1, k2, … , km
)
.
Example-proof 4.3.8 You are going to distribute n = 14 one-hour tasks over
a k = 3 day period, and all that matters is how many hours you will be working
each day. You have k1 = 4 hours available on Friday, k2 = 7 on Saturday, and
k3 = 3 on Sunday. In how many ways can the 14 tasks be distributed among the
three days, when a task has to be finished on the day it was started?
You mark the tasks A, B, … , N, and make an array of 14 boxes, one for each
hour, and each box gets one task. Task A has 14 boxes to choose from, whereas
task B has 13, etc., meaning that you have 14 × 13 × ⋯= 14! ways to distribute
the tasks among the boxes. You then mark the first 4 boxes “Friday”, the next
7 “Saturday”, and the last 4 “Sunday”. Moving tasks within one day is obviously
the same distribution of tasks among days. Say Friday has tasks H, N, B, and
F. If this is rearranged to B, N, F, H, then Friday still has the same tasks. There
are 4! ways to rearrange that Friday. Similarly, Saturday can have its 7 tasks
rearranged in 7! ways, and Sunday sees 3! ways to arrange its tasks. In total,
(4!)(7!)(3!) arrangements are possible without altering which task ends up on
which day.

4.3 Repeated Sampling

The number of ways to split the tasks between the days is then the total
number of ways to arrange the tasks into 14 hours, divided by the number of
arrangements that have the same tasks on the same day:
14!
(4!)(7!)(3!) =
(
14
4, 7, 3
)
=
(
n
k1, k2, k3
)
.
In the converse situation, you are not dividing a set into subsets, but rather
combining a specified number of elements from different sets into one single
set. How many ways are there of doing that?
Rule 4.3.9 You are sampling from k sets, {Aj}k
j=1. From Aj, you pick nj ele-
ments in a specified way (ordered/unordered; with/without replacement).
The number of ways to sample nj elements from set j in the specified way
is Mj. The total number of ways you can perform this sampling is then
M =
k
∏
j=1
Mj = M1 × M2 × ⋯× Mk.
Example 4.3.10
You have 3 urns; the first has 14 red balls, the second has
12 blue, and the last one has 20 green. You are going to pick 3 red, 7 blue, and
5 green balls. How many ways can you do this?
Answer: From all three urns, you will be sampling without replacement, and
the number of ways of doing this is respectively M1 = (14
3
), M1 = (12
7
), M1 =
(20
5
). The number of ways to pick 3 red, 7 blue, and 5 green balls is then
M = M1 × M2 × M3 =
(
14
3
)
×
(
12
7
)
×
(
20
5
)
= 4 469 617 152.
Example 4.3.11
Your name is Bilbo, and you are on an expedition with the
13 dwarves Thorin, Fili, Kili, Balin, Dwalin, Bifur, Bofur, Bombur, Oin, Gloin,
Dori, Nori, and Ori. A sign in the forest you are passing through warns “Do not
leave the path”, so naturally you just have to check out the woods. You can pick
4 dwarves for company. You will each carry one weapon: sword, bow, or staff.
How many configurations of you are possible for this little excursion?
Answer: The first set, A1, is the dwarves. They are 13, and you are picking 4;
the order in which you pick them does not matter, hence it is unordered. The
number of ways to pick companions is thus M1 = (13
4
) = 715.
The other set is the weapons: {sword, bow, staff}. Since you may all choose
freely and independently, this is with replacement. But it matters who gets


4 Set Theory and Combinatorics
which weapon, so the choice of weapons is ordered. You are 5, so the number
of ways to choose weapons for all 5 is M2 = 35 = 243.
The total number of configurations is thus M = M1 × M2 = 715 × 243 =
173 745.
Summary
1) Sequences may be illustrated by drawing tree diagrams, and by counting.
2) The binomial coefficient is (n
k
) =
n!
k!×(n−k)!, and is read as “n pick k”.
3) Sampling may be ordered or unordered, and with or without replacement.
This makes for four different types of sampling/draws, each with its own
formula.
4) Sequence means: The order matters. Corresponds to ordered sampling.
5) Combination means: The order is irrelevant. Corresponds to unordered
sampling.
Test Yourself!
The formula for dividing a set of n elements into sets of respectively k and
n −k elements is generalized to the multinomial formula for the number of
ways to divide a set of n into m sets of k1, k2, … , km−1 and km elements (where
k1 + ⋯+ km = n. The number of ways to do this, is
n!
k1! × k2!⋯km!. Show how you
get this formula, either by a special case, or by demonstrating the general for-
mula directly. Hint: make one division first, and then subdivide one of these
afterwards.
.
Exercises
Set Theory
1
Review: Read the chapter.
(a) What is a set?
(b) What is a sequence?
(c) What is a combination?
(d) Why does (n
k
) = ( n
n−k
)?
(e) What are the connections between binomial and multinomial?
2
A = {a, b, c, d, e, h, i, j}, B = vowels, C = letters with an even numbered
place in the alphabet. Find A ⧵(B ∩C).
3
Kari and Mona are looking at who in their class they have beaten at arm
wrestling. Kari has beaten 15, wheras Mona has beaten 13. Of these, 7 have
been beaten by both Kari and Mona.

4.4 Exercises

(a) How many have been beaten by at least one of them?
(b) Call the set of classmates beaten by Kari, K, and the set beaten by Mona
M. How do you write the set of those who were beaten by both Kari
and Mona?
(c) How do you write the set of those who were beaten by at least one of
Kari or Mona?
(d) Recall that the cardinality (size) of the set A is |A|. Write a formula to
link the cardinalities of the sets in the previous two exercises and those
of M and K themselves.
4
Palle and Jens are looking at which capitals they have visited. Palle has vis-
ited 17 capitals, whereas Jens has visited 23. The number of capitals visited
by at least one of them is 33.
(a) How many capitals have been graced by a visit from both?
(b) Call Palle’s capitals P, and Jens’ capitals J. How do you write “capitals
visited by at least one of the two”?
(c) How do you write the set of capitals visited by both?
(d) Recall that the cardinality (size) of the set A is |A|. Write a formula to
link the cardinalities of the sets in the previous two exercises and those
of P and J themselves.
5
In the Scottish village Glenwhisky there are many pubs. Half of the pubs
serve Dalwhinnie, and a third serve Laphroig. Only 5% of the pubs serve
both Dalwhinnie and Laphroig.
(a) Angus MacAbstainer drinks only these two brands of whisky, and is
otherwise a teetotaler. What is the proportion of pubs that serve at
least one whisky that Angues drinks?
(b) Call the set of pubs serving Dalwhinnie, D, and the ones serving
Laphroig L. For a set of pubs, A, let p(A) be the proportion of pubs that
are A. Write your calculation of Angus’s pubs as a statement about the
relation between p(D), p(L), P(D ∪L), and p(DL).
6
In your church’s stock of hymnals, 3
5 of the hymnals are of the old edition.
Half the hymnals have a flyer about your upcoming Christmas concert.
Nine out of ten of your church’s hymnals are either old or have a flyer about
your Christmas concert.
(a) What is the proportion of hymnals that also have a flyer?
(b) Call the set of old edition hymnals E, and the set of hymnals with a flyer
in them F. Writing p(A) as the proportion of a set A, write the relation
above as a general statement about the proportions p(S), p(L), p(SL),
and p(S ∪L).


4 Set Theory and Combinatorics
7
A = {red, orange, green, indigo, violet}, and B = {yellow, green, blue}. Ω
consists of all seven colors of the rainbow, and is our universe.
(a) What is Ac?
(b) What is A ∪B?
(c) What is A ∩B?
(d) What is A ⧵B?
(e) What is B ⧵A?
(f) Is it true that “green ∈A”?
(g) Is it true that “yellow ∈A”?
(h) Is it true that “green ∉B”?
(i) Is it true that “yellow ∉B”?
(j) Is it true that “red ∉(A ∩B)c”?
Combinatorics
8
Calculate (
28
2,3,5,7,11
)
9
Calculate (231
4
)
10
The jedi master N’s light saber display at a small venue at your university
is fully booked, and the arrangement committee decides to expand with
an extra show, and to divide the hopeful viewers into two batches. There is
only room for 58 at the first show (which is also everyone’s primary choice),
but a total of 80 hopeful attendees. How many different ways can you divide
the 80 so that 58 get to see the first show, whereas the remaining 22 get to
attend the second?
11
You are sports dictator in the UK for a day, and have decided that precisely
7 of the next 12 Premier League (European) football matches should be
home wins. In how many ways can you pick those 7 games?
12
Your university has a mid-semester break (which everyone knows means
a self study week). You are taking 7 subjects this semester, but knowing
yourself, you decide to pursue 3 of them over the week. How many different
combinations of 3 subjects can you choose, from the 7 you are following?
13
You have a CD collection of 60 CDs, but as you are going to your cabin you
find that your bag can hold at most 13. You decide to bring the maximum
number; how many different combinations of CDs can you bring?
14
You are playing 5-dice Yatzee. How many different full houses are possible?
15
You are playing strip poker. Wearing briefs only, you realize your hand is
terrible. You decide to trade in 3 of your cards. Any, since you consider

4.4 Exercises

them all equally bad. How many different sets of 3 cards is it possible to
discard from your hand of 5?
16
You are deer hunting with 6 buddies. As a deer shows up at the edge of the
clearing, you all pull your rifles and shoot. The deer dies instantly. As you
later quarter the deer, you find only 3 bullets. How many different combi-
nations of hunters could have contributed to the kill?
17
In Norway, a phone number consists of 8 digits, where the first cannot be
0. A phone number was recently sold for 1 million NOK. It consisted of a
number, followed by 6 equal digits different from the first, before the first
digit was repeated.
(a) How many such phone numbers are possible?
(b) Can you think of other rare types of phone number?
(c) How many are there of these?
18
Cinema: Ewan and Aiden notice that they have both bought tickets to the
same movie, and both of them in row 13, which has 25 seats.
(a) How many different ways can Ewan and Aiden be placed in row 13?
(b) How many of these ways put them next to one another?
(c) (Chapter 5) If the choice of tickets is random, what is the probability
that they end up next to one another?
19
There are 3 cookies left on the table. You realize that if you are quick, you
may get away with grabbing two before someone else grabs the third.
(a) How many pairs of cookies is it possible to pick from the 3 (the order
is irrelevant)?
(b) What if the other guy got to grab one cookie, whereupon you grabbed
two: how many different ways would there be for him to grab his one
cookie?
(c) Why are these two answers the same?
20
You see 8 attractive women on the beach. You know you’ll get around to
inviting 3 of them for a barbecue party before your friend Bram has invited
the remaining 5 to his barbecue party.
(a) How many different combinations of your 3 invitations are possible,
given the 8 women?
(b) How many different combinations of Bram’s 5 invitations are possible,
given the 8 women?
(c) Why are these two answers the same?
21
You have decided to divide a deck of cards into two piles; one of 22 cards,
and one of 30.


4 Set Theory and Combinatorics
(a) You pick the 30 cards for pile 1, and the remaining 22 are put into pile
2. How many divisions into 2 such piles are possible?
(b) You decide to instead pick 22 cards for pile 1, and let the remaining 30
be put into pile 2. How many divisions into two such piles is possible?
(c) Why are these two answers the same?
22
There are 70 white roses on a rosebush. You are either painting them red,
or leaving them white.
(a) You are painting 47 roses red (and leaving the rest white). In how many
ways can you do that?
(b) You are leaving 23 white (and painting the rest red). In how many ways
can you do that?
(c) Why are these two answers the same?
23
The number of ways to sample s elements from a set of n possible,
unordered, and without replacement, has a certain formula.
(a) What is this formula?
(b) What is the formula for sampling n −s elements from a set of n
possible?
(c) Why are the answers to these two questions the same?
24
You and your friends Gregory, Bear, and Arne are doing a project together.
You have subdivided the project into 34 tasks, and you have decided that
you’ll do 8 tasks, Gregory will do 5, Bear will do 9, and Arne will do 12.
How many ways are there to divide the tasks among you in this fashion?
25
Repeated sampling: In how many ways can you sample 5 elements from
a collection of 12, when the sampling is …
(a) ordered, with replacement;
(b) unordered, with replacement;
(c) ordered, without replacement;
(d) unordered, without replacement.
(e) Give a practical example of each of the four kinds of sampling.



Probability
CONTENTS
5.1
The Concept of Probability, 71
5.2
Basic Probability, 78
5.3
Conditional Probability, 83
5.4
Independence, 88
5.5
Repeated Sampling and Probability, 94
5.6
Exercises, 100
.
The Concept of Probability
The concept of probability arose in an exchange between Fermat and Pascal, as
they were analyzing how justly to split the pot of a game that had been inter-
rupted before its conclusion. Their solution was to distribute the pot propor-
tional to the probability of winning. For instance: say we have a game of dice
with $12 in the pot, and all that remains is a single toss of a D20 die. You win
if it lands on 4, 7, or 13. Otherwise, someone else wins. How much should you
get if the game is interrupted and the D20 never is tossed? The answer is that
since your position in the game is 3 out of the 20 sides, you should have 3
20 of
the $12 pot. That is, 1 dollar and 80 cents. The number 3
20 is the probability for
you to win the entire $12 pot.
..
Kolmogorov’s Axioms of Probability
The axioms of probability most commonly referred to were set up by the
Russian mathematician Andrej N. Kolmogorov (1903–1987) in his 1933 book
Foundations of the Theory of Probability. These axioms are best understood by
thinking of probabilities as proportions.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


5 Probability
Definition 5.1.1 (Kolmogorov) P is a probability if
(1) 0 ≤P(A) ≤1
(2) P(Ω) = 1
(3) P (⋃n
i=1 Ai
) = ∑n
i=1 P(Ai) if AiAj = ∅when Ai ≠Aj,
where A, A∗are subsets of Ω.
The last point is often written for pairs of sets. Generalization via induction
is then left to the reader. For pairs, axiom (3) is that P(A ∪B) = P(A) + P(B)
whenever AB = ∅.
..
Probability and Euler Diagrams
When we view probability through the eyes of Kolmogorov, as a kind of propor-
tion, Euler diagrams are natural tools for understanding and calculating simple
probabilities. The whole, or “universe” for our probability calculations, is Ω.
We often think of Ω as the set containing all possible outcomes, and call it the
sample space. It can be more fine-grained than that as well, to make room for
mathematical techniques like approximations, but for our mental pictures, we
should think of it as being precisely the set of all the possible outcomes.
Subsets of the sample space Ω are then best viewed as collections of out-
comes. If your Ω is the set of possible outcomes when tossing a D6 5 times, A
can for instance be all outcomes whose sum is between 10 and 15. You may
think of the area marking A as a claim on a part of the pot proportional to
P(A).
We have everything to small sample spaces like Ω = D6 = {1, 2, 3, 4, 5, 6} and
Ω = {heads, tails}, up via Ω = {all infinite card sequences card1, card2, … } or
Ω = {all possible sets of stock price graphs on NASDAQ over the course of one
year}, to the Ωs describing large infinite sets in mathematical probability theory,
like the possible paths of Brownian motions.
Kolmogorov’s axioms lend themselves easily to Euler diagram illustrations:
that P(Ω) = 1 is immediate, since the whole’s part of the whole – is 1. That
0 ≤P(A) ≤1 is readily seen by just drawing the subset A ⊂Ω. The area for A
can never be larger than Ω itself (that is: 1), but not smaller than the empty set
(that is: 0). The third axiom deserves an explicit illustration (Figure 5.1), and a
warning: it matters whether sets overlap or not!
Our illustration contains only a finite number of sets, but the rule applies to
any countable collection of sets, A1, A2, …

5.1 The Concept of Probability

A1
A4
A
A3
A2
A
(a) Overlapping sets.
A1
A4
A
A3
A2
(b) Non-overlapping sets.
Figure .When the sets don’t overlap, the total is larger.
..
Notation
Which notation should we use for probability? We saw that Kolmogorov’s nota-
tion for probability was through the function P, where the probability of A is
P(A). Some Bayesians, like E. T. Jaynes, point out that this notation omits the
context of the probability, and that there always is a context. Their notation
can be seen as an amendment of Kolmogorov’s, where the context is included
after “|”, a vertical line: the probability of A in context K is P(A|K). Notice that
the line “|” is vertical, and not slanted like “∕” or the set difference symbol “∖”.
The vertical line “|” is to be read as “given (that)”, so the fleshed-out meaning
of P(A|K) is “the probability of A given (context) K”. As an example, P(7|D8) is
“the probability that the die will show a 7, given that the die is a fair D8”.
What, then, is the probability of striking a 2 when you toss a die? If you
write P(2), a fair deal has been taken for granted. Most readers would prob-
ably respond right away that P(2) = 1
6. This means taking for granted that the
die is a fair D6, and not for instance a D20. If it has not been otherwise specified
D6, we should then write P(2|D6).
But P(A) is a compact and neat notation. Since the context often is given or
is fair to assume, this will be our main probability notation. However, when we
need to specify the context, we will write P(A|K), or preferably PK(A) when this
makes sense.
This kind of notation will be very useful in Chapter 6, where new obser-
vations will narrow our context from the initial Ω0 of all possibilities, to ever
narrowing contexts Ω1, then Ω2, … that are limited to the contexts where these
observations are the case. An example of this is if you are analyzing the UEFA
cup. Let’s say you look at event A = “Bayern Munich wins the UEFA cup final”.
The context Ω0 might simply be that the team is in the tournament. Maybe the
next context we look at, Ω1, is that we know they have made it all the way to the
finals. A further sharpening of context, Ω2, could be if in addition goalkeeper
Manuel Neuer is injured. For notational simplicity, we put the index on P


5 Probability
rather than on Ω. In other words, we write P0(A) = P(A|Ω0), P1(A) = P(A|Ω1),
P2(A) = P(A|Ω2), etc.
..
Deﬁnitions of Probability
We have so far not defined what probability is. This is not without reason, for
there is no consensus on this issue among statisticians and probabilists.
We have two basic intuitions about probability: symmetry, and relative fre-
quency. Considerations of symmetry are the reason we assign a probability of
1
30 to getting a 7 on a D30, before we have tossed such a die even once. We may
also start counting the successes Sn at getting a 7 in n tosses, to get the relative
frequency an = Sn
n . If the D30 is fair, an will converge to
1
30 as n grows larger.
We will see later, in Rule 9.2.5, that as a general rule, the relative frequency
an converges to the probability p as n →∞. This rule holds independently of
your definition of probability. But more importantly, as we will see in a little
while: one school uses this property as the very definition of probability.
Common to all definitions is that they obey Kolmogorov’s axioms.
The first definition corresponds to the following immediate, naive intuition
most of us have of probability.
Definition 5.1.2
Probability (subjective): This probability is personal,
and you find your probability of A by establishing what you think is a fair
bet for A: if you think it is a fair bet that the price for betting on A is m, while
the price for betting against is n, in a gamble where the winner takes the pot
of n + m, then your personal probability of A is
P(A) =
m
m + n.
In other words, P(A) is A’s fraction of what was put into the pot in a fair bet.
The fair bet is the equilibrium point where you consider both bets equally
advantageous. If, at this equilibirum point, the cost of betting on A is lowered,
or the price of betting against A is raised, you would not bet against A, but only
on. Conversely, at the equilibrium point, if the cost of betting on A is raised
or the price of betting against A is lowered, you would not find it in your own
interest to do anything but bet against A.
Some objections to this type of probability are as follows.
r Two people will rarely assign the same probability to an event A, so P(A) does
not have a unique, objective, value.
r Subjective (non-objective) probabilities are not applicable in arenas that
require objectivity.

5.1 The Concept of Probability

r Complex situations do not easily lend themselves to such subjective evalua-
tions, and evaluations may easily turn out to be inconsistent.
r Personal psychology may bias evaluations, especially if you are risk averse or
risk seeking.
Definition 5.1.3
Probability (frequentist): If an experiment can be
repeated in an identical manner, but still have different outcomes, the out-
come is said to be random. For this type of experiment, we define the
frequentist probability of a class of outcomes, A, as
P(A) = lim
n→∞
Sn
n ,
where Sn is the frequency of outcomes of type A after n repetitions. P(A) is in
other words the limit of the relative frequency as the number of trials tends to
infinity.
Some objections to the frequentist type of probability are as follows.
r “Randomness”: what is considered an “identical” experiment is a subjective
opinion.
r Choice of the underlying model is a subjective choice.
r An infinite number of experiments – identical or not – has never been per-
formed (and given what we know of physics: never can be), so there exist no
probabilities by this definition.
r The relative frequencies may never approach a limit: an = Sn
n may fluctuate
between 0 and 1 without ever settling, as n grows to ∞.
r The definition rules out assignment of probabilities to one-time events. That
is, it rules out speaking about
– “the probability that the dinosaurs were wiped out by a comet”;
– “the probability that the USA will get another President Bush”;
– “the probability that she will say yes when you propose”.
The first two points require an explanation. Many believe that the frequentist
school is objective, and a way to “let the data alone speak” without any subjec-
tive component whatsoever. But let us examine a typical experiment: tossing
a coin. It is a physical experiment where the tacit assumption is that if we do
an infinity of identical flips, some coins will land heads, and some will land
tails, and that the relative frequency of tails will converge to a limit p as n →∞.
And indeed, in our everyday experience, we have seen that such coin flips land
roughly half tails and half heads, so it shouldn’t be unreasonable to say that p is
somewhere around 1
2. But are the coin tosses identical experiments?


5 Probability
If we look at the underlying physics, calculating the path of the coin is
complicated. But with identical starting points, the laws of mechanics tell us
that the coin should follow the same path each and every time, and land at the
same spot, with the same side facing up. Nothing random at all! What makes
the outcome seem random is that the coin flip is sensitive to initial conditions:
if the coin is slightly higher forwards, up, rotated … or if you flick it just a
smidgeon harder, these minute differences may be sufficient to cause it to land
on the opposite side. But with sufficient precision in all these variables, the
result will be the same every time.
So the “randomness” of these seemingly identical experiments is simply the
result of these experiments not being identical, but that we do not know what
these minute differences are, or that we have not calculated their effects. This
applies to coin tosses, but also to medical experiments or Gallup polls, where
the “randomness” is simply a way of saying that we don’t know. The randomness
states a property of our state of knowledge, i.e. a subjective factor, rather than
an objective facet of the experiment itself.
This does not mean that the frequentist approach is useless, but it does mean
that, when its proponents claim that objectivity requires us to use frequentist
methods, they are simply wrong. The frequentist approach is not objective; it
has just disguised its subjective components.
There is one school, however, that refers probability wholly to the objective
realm.
Definition 5.1.4
Probability (propensity): Probability is a tendency
towards the different outcomes of a system, where the tendencies are inherent
in the system itself. P(A) is the degree to which this tendency points to outcome
A. It is often called a propensity.
The main objection to this definition is that it is no definition at all! It turns
out to be hard to formalize the propensity probabilities. Yet, despite the difficul-
ties, this is an avenue worth pursuing – not as the only concept of probability,
but as a form of probability applicable to physical systems that behave the way
our current theories of physics, say quantum mechanics, work.
This book follows the classical school. This school is known in modern
times as the objective Bayesian school. This as opposed to the first definition,
the subjective Bayesian school.
Definition 5.1.5
Probability (classical): Probability is a state of knowl-
edge, or degree of knowledge. The basic probabilities are defined from
symmetry in our knowledge about the system: if A and B are symmetrical
(interchangeable) in the model, then P(A) = P(B).

5.1 The Concept of Probability

For example, if a die is symmetrical (like the typical Dn), its sides are
interchangeable in our model, so P(1) = P(2) = ⋯= P(6). Since P(Ω) = 1, we
have P(1) + P(2) + ⋯+ P(6) = 6 × P(1) = 1, meaning P(1) = 1
6. From this, we
calculate all the other probabilities pertaining to the Dn.
Some objections to the classical (objective Bayesian) definition of probability
are as follows.
r There is no agreed-upon or objective procedure that can determine symme-
try in all possible cases and models.
r If there is too little structure or information to determine any symmetry,
there is no useful basis for probabilities for decision making.
r Practical calculations of problems of a certain complexity tend to require
more computing power than corresponding frequentist techniques.
Though our favorite is clear, we will refrain from appointing our favorite as
the winner. We notice that, with the exception of the propensity definition, all
the schools depend on a subjective component – a component of knowledge
or evaluation.
The philosophy of probability is an interesting area of study in its own right,
but we shall move on to statistical methods. These methods are mostly common
to all schools, but when we get to statistical inference, we will focus on the
Bayesian kind. Perhaps the main advantage of Bayesian methodology is that it’s
conceptually whole, and thus easily understood. We will also include the basic
frequentist methods in their own chapter, since they have in many ways set the
stage for modern statistics, as we believe it is beneficial for students of both
schools to know the basics of both methodologies – not just philosophically,
but also for a practitioner’s practical working understanding of the methods.
We will also see that Bayesians and frequentists often end up with equal
or similar answers, even though the theoretical backdrop and the interpreta-
tions are different. This facilitates cooperation across schools. We should still
be aware of the differences, so as not to mix up evaluations. A classical example
illustrates the difference that lies at the core. We will introduce three charac-
ters who will be with us throughout the book: Bard the Bayesian, Frederick the
frequentist, and their friend Sam.
Example 5.1.6
Frederick notices that there is a coin under a piece of cloth
next to him on the table. He can’t see which side is up. Sam asks his two friends
what the probability is that it is heads up?
r Bard says that there is a 50% probability that it’s heads up. “The symmetry,”
he says, “means our state of knowledge is symmetrical with respect to the
two alternatives, heads and tails.”
r Frederick, on the other hand, is not interested in Bard’s state of knowledge,
but asks what would happen if he performed an infinite number of trials.


5 Probability
There is no tossing involved, as that would change the state of the coin, but
just observation. “What,” he says out loud, “is the relative frequency of heads
when I observe the state of this coin repeatedly?” He shows Sam, by lift-
ing the cloth to reveal the coin, putting the cloth back over it, and lifting it
again. “Same result every time!” he exclaims, “and think about it, Sam. Didn’t
we already know that before we lifted the cloth? It would either be heads
all the time, in which case the probability of heads would be 100%,
or tails all the time, in which case the probability of its being heads
was 0%.” Sam nods, and Frederick concludes: “In such cases, where the out-
come is fixed but unknown, the probability is always either 0 or 100%, but we
don’t know which one!”
Most readers will probably be a bit surprised at Frederick’s claim that the
probability of heads is an unknown “0 or 100%, but we don’t know which”, rather
than the 50% that Bard talked about. The reason is that Fredrick’s concept of
probability is different from that of our common intuition, worked up through
hard nights of betting and calculating probabilities of poker hands even after
the cards had already been dealt.
Some textbooks use this or similar examples to admonish the student to
adhere to the “correct” concept of probability. That is, Frederick’s frequentism.
If you with Bard answered 50%, you will be told that you are in the wrong. Well,
you aren’t. In this book, we are going by the opposite premise: we openly state
our preference for the Bayesian way, but will not admonish you as being wrong
simply for disagreeing with us.
.
Basic Probability
Rule 5.2.1
The following rules are frequently used in probability
calculations:
(a) P(A ∪B) = P(A) + P(B) −P(AB)
(d) P(Ac) = 1 −P(A)
(b) P(AB) = P(A) + P(B) −P(A ∪B)
(e) P(Ω) = 1
(c) P(A∖B) = P(A) −P(AB)
(f) P(∅) = 0.
Proof: You prove these rules by employing Kolmogorov’s axioms: divide the
universe Ω into four disjoint parts: AB, A∖B, B∖A, and (A ∪B)c = AcBc, and
write out the composition of the sets in Rule 5.2.1 in terms of these four parts.
For instance: A consists of AB and A∖B. The equalities follow by applying
Kologorov’s third axiom. For example: P(A) = P(AB) + P(A∖B).
Verifying these rules is perhaps especially simple by using the Euler diagram
in Figure 5.2.

5.2 Basic Probability

A
B
(a) The sets A and B.
A\B
B\A
AB
A  B
c  c
(b) ... with all four subdivisions marked.
Figure .Use Euler diagrams to verify Rule 5.2.1 graphically.
Example 5.2.2 It is November, and the meteorologists say there is a 14% prob-
ability of rain for tomorrow. What is the probability it will not rain tomorrow?
Answer: Here, A = “It will rain tomorrow”, and P(A) = 0.14. We are calculat-
ing P(Ac). Rule 5.2.1.d gives us the answer: P(Ac) = 1 −P(A) = 1 −0.14 = 0.86,
i.e. an 86% probability that it won’t rain tomorrow.
Example 5.2.3
Signal diagram: See Figure 5.3. When a switch is closed, it
conducts electricity. The probability that switch A is closed is 0.7, the probabil-
ity that both are closed is 0.3, and the probability that none of them is closed is
0.2. Find the probability that
(a) … B is closed;
(b) … the circuit conducts electricity.
Answer: We name the events by their switches, so A means switch A is closed,
and B means switch B is closed. The space of possibilities can be decomposed
into AB, A∖B, B∖A, and AcBc. The basic probability rules in Rule 5.2.1 then give
us the probabilities we are looking for: P(B) = P(AB) + P(B∖A) = 0.1 + 0.3 =
0.4, and P(circuit conducts electricity) = P(A ∪B) = 0.4 + 0.3 + 0.1 = 0.8.
A\B
B\A
AB
A B
c c
0.3
0.2
0.4
0.1
(a) The Euler diagram of the circuit.
A
B
(b) The circuit diagram.
Figure .Using an Euler diagram to calculate probabilities for the circuit.


5 Probability
Example 5.2.4 In the following examples, we will find probabilities according
to the classical definition (Definition 5.1.5): identify mutually exclusive events
E1, … , Ek that together make up all possibilities. These correspond to a parti-
tion of Ω into disjoint sets A1, … , Ak. The probability of each of these events or
sets is then the same, and is therefore 1
k .
(a) What is the probability of getting ball 2 if you draw from a bag of 3 equal
balls, numbered 0, 1, 2?
(b) What is the probability of getting 2 heads if you toss an ordinary coin twice?
(c) What is the probability of getting a prime number on a D12?
(d) What is the probability of getting the sum 5 when you throw two D6?
(e) You mark 1 radian of a tire with white paint, drive for a long drive, and stop.
What is the probability that the point on the wheel that points straight down
is painted white?
(f) You have lost your goldfish in a 1000 m3 pool of muddy water, and pump
out 513 m3 that you filter through a net. What is the probability that you
will find your goldfish in the net?
Answers:
(a) The draw of the balls are symmetric possibilities, so the probability to draw
ball 2 is 1∕3.
(b) In this instance, the possible numbers of heads are not symmetric possi-
bilities, since you can get 1 heads in 2 ways (heads–tails and tails–heads),
whereas 0 and 2 heads are realizable through only 1 sequence each. Here,
the sequences are the symmetric possibilities (see Sections 5.4 and 5.5).
Since 2 heads are realized by 1 out of 4 possible sequences, P(2) = 0.25.
(c) The primes less than 12 are 2, 3, 5, 7, 11. On a D12, all possibilities are equal,
so P(prime) = 5∕12.
(d) As in the case of the coin, here the sequences a–b are symmetrical, where a
and b range from 1 to 6. This means there are 6 × 6 = 36 possibilities. Five
is the sum of these sequences: 1–4, 2–3, 3–2 and 4–1. So P(5) = 4
36 = 1
9.
Then, P(non 5) = 1 −P(5) = 8∕9.
(e) This is the continuous version of the symmetry method. There are no pre-
ferred angles, so the probability of a given interval of angles equals their
part of the whole. A wheel – of any circumference – spans from 0 to 2𝜋
radians, for a total span of 2𝜋. The probability of hitting white paint, which
covers 1 radian, is then P(white) = 1∕2𝜋≈0.159.
(f) Continuous and three-dimensional, but the method of symmetry still
works. No cubic meter of water is preferred, so the probability of finding
the goldfish equals the proportion of water that was pumped out. In other
words, P(goldfish) = 513 m3
1000 m3 = 0.513.

5.2 Basic Probability

Example 5.2.5 In the following examples, we will find probabilities according
to the subjective definition (Definition 5.1.2) of probability: by deciding how we
would bet.
(a) You have built a bridge of straws, and a friend wants to bet that a five-year
old child can blow it down. You consider it a fair bet if you pay $10 and he
pays $5, and the winner takes all. What is your probability that a five-year
old child will succeed in blowing down the bridge?
(b) The odds at an online gambling site tell you that a $100 bet that the Green
Bay Packers will win the Superbowl will pay $350 if you win. You trust these
odds to be good. What is your probability that the Green Bay Packers will
win the Superbowl?
(c) You consider investing $1000 in a project that will yield $x if successful,
but where you will lose your $1000 if it fails. You consider the probability
of success to be 80%. What is the smallest payoff x that will justify your
investment?
Answers:
(a) P(succeeds in blowing down) = bet for “succeeds”
total pot
=
5
10+5 = 1
3.
(b) Here you know the total pot of m + n = $350, and your required bet of n =
$100. That means P(Green Bay Packers wins the Superbowl) = $100
$350 = 2
7.
(c) For a fair bet, you would demand 1000
x
= 0.8, in other words a payoff of at
least x = $1250 given success.
We now have two of the four philosophies of probability left: the propensity
school, and the frequentist school. The propensity theory is as stated not a well
formed theory, which makes calculations difficult. But there are situations in
physics (i.e. quantum mechanics) where it can be well argued that mathemat-
ical descriptions of physical symmetries partition the set of possibilities into
sets of equal probability; if a system has precisely five interchangeable states,
then the probability of each state is 1
5. More complex continuous style calcula-
tions can be performed on the basis of the wave function Ψ. So to the extent
that propensities may be calculated, they correspond to similar calculations in
classical probability. The difference is that in classical probability, the symme-
tries are among states of knowledge, whereas in the propensity theory, these
symmetries are assumed to be physical, or objective.
In the frequentist school, we know a probability only after an infinite
sequence of trials. Even a coin that has yielded 1000 tails in a row may turn out
to give only 50% tails in the long run, so no finite number of trials – no mat-
ter how large – may fill the requirement of the frequentist definition of prob-
ability. What is done in the frequentist school is to make an estimate on the


5 Probability
probability, and then to say you have a certain degree of confidence that the
probability is within a certain range from the estimated value. What exactly
“confidence” is, is hard to say, but it is commonly considered an error to equate
it with a probability.
Definition 5.2.6 An estimate m on a magnitude 𝜇is called unbiased if an
infinite sequence of estimates m1, m2, m3, … , performed in precisely the same
manner, would give
lim
n→∞
m1 + m2 + m3 + ⋯+ mn
n
= 𝜇.
Example 5.2.7 In the following examples, we will make simple estimates on
probabilities according to the frequentist definition (Definition 5.1.3) of prob-
ability. A frequentist estimate on a probability should be unbiased. It turns out
that the unbiased estimate of P(A) is ̃P(A) = Sn∕n, where Sn is the number of
occurrences of A after n trials.
(a) You have tossed a D6 die 300 times, and got 45 ones, 51 twos, 46 threes,
52 fours, 58 fives, and 48 sixes. What are the frequentist estimates of
P(1), … , P(6)?
(b) You have tossed a D6 die twice, and got one 3 and one 5. Estimate
P(1), … , P(6).
Answers:
(a) The estimates are (to three decimal places) ̃P(1) = 45
300 = 0.150, ̃P(2) =
51
300 = 0.170, ̃P(3) = 46
300 = 0.153, ̃P(4) = 52
300 = 0.173, ̃P(5) = 58
300 = 0.193,
̃P(6) = 48
300 = 0.160.
(b) The estimates are (to three decimal places) ̃P(1) = 0
2 = 0.000, ̃P(2) = 0
2 =
0.000, ̃P(3) = 1
2 = 0.500, ̃P(4) = 0
2 = 0.000, ̃P(5) = 1
2 = 0.500, ̃P(6) = 0
2 =
0.000.
..
Simple Calculations
We often state simple probabilities in tables, as illustrated by the following
example.
Example 5.2.8
Your mobile phone does not react when you press the start
button. Your friend Frederick has created a table (Table 5.1) of the probabilities
of the causes.

5.3 Conditional Probability

Table .Causes and probabilities for your dead phone
Cause
Probability
Empty battery
0.65
Pushing the wrong button
0.25
Dead phone
0.07
No battery
0.03
(a) What is the probability that the fault is battery related?
(b) What is the probability that the fault is not battery related?
Answers:
(a) P(fault is battery related) = 0.65 + 0.03 = 0.68.
(b) P(fault is not battery related) = 1 −P(fault is battery related)
= 1 −0.68 = 0.32.
.
Conditional Probability
You are on a plane with a friend, heading for your vacation destination, and you
recently heard that only 1 in 200 000 flights end in a crash. You estimate the
probability of your flight ending in a crash as were it randomly picked among
200 000, so you get a very small number indeed. P(crash) =
1
200 000 = 0.000 005.
But then your friend asks if you would change your mind if a fire broke out in
one of the engines. You have read that one in ten planes with an engine on fire,
crashes. You immediately update your probability estimate to P(crash) = 1
10 =
0.1. Your estimate is conditioned on fire in an engine.
We illustrate this in Figure 5.4. To the left, we have the universe Ω of all pos-
sible flights, where A are the flights that end in a crash, B are the ones where
A: the plane crashes
Ω: flights
B : engines not on fire
B: engines on fire
c
(a) All plane rides.
B  is the new Ω
c
A: the plane crashes
(b) Engines...not on ﬁre.
A: the plane 
     crashes
B is the new Ω
(c) ... on ﬁre.
Figure .The conditional probability of a plane crash, given that the engines are on fire.


5 Probability
A
The World
A
c
World, given A
P(B|A)
AB
A B
World, given A
P(B|A )
c
c
B
c
Figure .P(B|A) is the proportion of AB in A.
an engine catches on fire, and Bc are the ones where the engines don’t catch
on fire. We have inflated B for the sake of illustration. In the right diagram, we
see how A’s proportion of flights increases dramatically when the engine’s on
fire, whereas in the middle one we see how A’s proportion of the flights remains
minuscule when the engines are not on fire.
In general, we do as follows: you want to know the probability of an occur-
rence A given another occurrence B. We call this the probability of A conditional
on B, or “A given B”, and write it P(A|B). The conditional probability P(⋅|B) is a
probability, with all the properties of the full probability P(⋅) = P(⋅|Ω); the only
difference is that for P(⋅|B), the universe is B, not the old Ω.
Just like P(⋅) = P(⋅|Ω) is a proportion (of Ω), so P(⋅|A) is a proportion of a
more limited universe: the universe where A is the case. P(⋅|A) is a probability
where A is the context, just like Ω is the context in P(⋅) = P(⋅|Ω).
P(B|A) is the proportion of A that is also B. This is, as we see in Figure 5.5,
a fraction between P(AB) and P(B). Similarly, P(B|Ac) is the proportion of Ac
that is also B, which, as we see, is a totally different number.
This leads us to formal definition of P(A|B), Definition 5.3.1.
Definition 5.3.1 P(A|B) = P(AB)
P(B) .
We illustrate this in Figure 5.6. The straightforward probability is repre-
sented as a solid object, with the understanding that its size is its probability.
The conditional probability is represented as a solid object within a larger

5.3 Conditional Probability

P(A)
P(B|A)
P(AB)
P(B)
P(AB)
P(A|B)
Figure .P(B|A) = P(AB)
P(A) and P(A|B) = P(AB)
P(B) .
object, with the understanding that the ratio of the size of the smaller object
to the larger object is the conditional probability.
Strictly speaking, all probabilities are conditional probabilities. This is per-
haps particularly important for us Bayesians, where an ever underlying condi-
tion to the Ω is our state of knowledge: if I toss a coin and hide from you that it
landed heads, then for you, P(tails) = 1
2, whereas for me P(tails) = 0. So strictly
speaking, if we flesh out any P(A), we should really be writing P(A|total state
of your knowledge about everything). But this would for one thing lead to very
cumbersome notation, so we will leave the greater context as a background and
out of our notation, and reserve the conditional notation for conditioning on
occurrences within the already set-up model.
It will at times be both notationally and conceptually useful to write PB(⋅)
instead of P(⋅|B), and in Chapter 6 on Bayes, that is exactly what we will do!
Example 5.3.2 P(AB) = 0.5 and P(B) = 0.8. What is P(A|B)?
Answer: P(A|B) = P(AB)
P(B) = 0.5
0.8 = 0.625 .
Example 5.3.3 P(A|B) = 0.7 and P(B) = 0.8. What is P(AB)?
Answer: Multiply by P(B) on both sides of Definition 5.3.1, to get P(AB) =
P(A|B) × P(B). In our problem, that gives us P(AB) = 0.7 × 0.8 = 0.56 .
We sum this up in the generally useful formula for the joint probability P(AB),
expressed in Rule 5.3.4, and in Figure 5.7.
Rule 5.3.4 P(A) × P(B|A) = P(AB).
P(A)
P(B|A)
P(AB)
P(B)
P(A|B)
Figure .P(A) × P(B|A) = P(AB) = P(A|B) × P(B).


5 Probability
Example 5.3.5
You have a bag with one each of the gamer dice D4, D6, D8,
D10, D12, D20. You will draw one, and then toss it. What is the probability that
you pick a D8 and then toss a 2?
Answer: Let B = “drawing a D8”, and A = “getting 2 when you toss the die you
drew”. There are six dice, so the probability of drawing the D8 is P(B) = 1∕6. The
probability of getting a 2, given that you picked the D8, is of course P(A|B) =
1∕8. The probability of drawing a D8 and then throwing a 2 is then
P(AB) = 1∕8 × 1∕6 = 1
48.
Example 5.3.6
The probability of a serious personnel accident at the Lille-
foss Steelworks on a given day is 0.001. The probability that production will be
stopped for the rest of the day after a serious personnel accident is 0.73. What,
then, is the probability of a personnel accident followed by a stop in production
for the rest of the day?
Let A = production stop, and B = serious personnel accident. We have been
given that P(B) = 0.001, and that P(A|B) = 0.73, and have been asked
to calculate P(AB). The answer is P(AB) = P(A|B) × P(B) = 0.73 × 0.001 =
0.000 73.
Example 5.3.7 Mørkvik Marine Solutions construct mini platforms with two
load-carrying beams they call the A beam and the B beam. An analysis of 468
mini platforms reveals that 23 of them have a crack in the A beam, 18 have a
crack in the B beam, and 15 have cracks in both. Your company owns a Mørkvik
mini platform, and you have just discovered a crack in the B beam. Use the
relative frequencies of cracks as your probabilities, and answer the following
question: What is the probability that the A beam has a crack as well?
Answer: We let the sets A and B designate cracks in the A and B beams, respec-
tively. Our probabilities are P(A) = 23
468, P(B) = 18
468, and P(AB) = 15
468. Our task
is to find the probability of a crack in the A beam given that there is a crack in
the B beam. The probability is
P(A|B) = P(AB)
P(B) =
15
468
18
468
= 5
6 ≈0.83.
Notice that P(A) does not enter into the calculation of P(A|B).
Example 5.3.8
We continue Example 5.2.8. Your phone is connected to a
charger cable, so it should have worked if the error had been battery related.
Make a table of the conditional probabilities for the non-battery-related errors,
conditioned on the error not being battery related.

5.3 Conditional Probability

Table .Causes and conditional probabilities for your dead phone
Cause
Conditional probability
Pressing the wrong button
0.25∕0.32 = 0.781 25
Dead telephone
0.07∕0.32 = 0.218 75
Answer: We already know that P(the error is not battery related) = 0.32. We
get the conditional probabilities by dividing by this number. All are collected in
Table 5.2.
..
Multiple Conditioning
You might wonder what happens if the conditional probability P(A|B) itself is
conditioned on yet another event C. The probability of “A, given B, given C”,
is it P((A|B)|C)? No, fortunately not, as that would have led us down the path
to some pretty ugly notation, much along the lines of the old saying If only we
had bacon, we could make eggs&bacon if only we had eggs! That’s just a very
cumbersome way to say that we could make eggs&bacon if only we had eggs
and bacon. In probability notation, it is the same: “A, given B, given C” is simply
“A, given B and C”. That means our conditional probability is not P((A|B)|C),
but rather P(A|BC).
Notation taken care of, we now expand Rule 5.3.4 to multiple events, in what
is known as the product rule of probability. Given sets A1, … , An, we have
P(AnAn−1 ⋯A2A1) = P(An−1 ⋯A2A1) × P(An|An−1 ⋯A2A1).
We expand, one set at a time, with the first set first:
P(An−1 ⋯A2A1) = P(An−1|An−2 ⋯A2A1) × P(An−2 ⋯A2A1).
Repeating the process, we get the formula
Rule 5.3.9
P
( n
⋂
j=1
Aj
)
= P(A1) ×
n
∏
k=2
P
(
Ak
||||||
k−1
⋂
j=1
Aj
)
.
Example 5.3.10
In a simple market without any other mechanisms at play,
the four insurance giants ShiRe, gRendel, ReRe and VirGo have mutually reas-
sured one another. The probability that VirGo goes bankrupt within a given
year is 0.05. If VirGo goes bankrupt, then the probability that ReRe too is going
bankrupt in the same year, is 0.31. If both VirGo and ReRe go bankrupt within
the same year, then the probability that gRendel will be bankrupt as well that


5 Probability
year, is 0.47. If all the three other companies go bankrupt within a given year, the
probability that ShiRe too will be bankrupt that year, is 0.38. (Notice that our
probabilities are about simultaneity, so the precise order of the bankruptcies do
not matter.) What is the probability that all four companies will be bankrupt in
a given year?
Answer: Let A1 be that VirGo goes bankrupt that year. Let further A2, A3 and
A4 be the respective bankrupcties of ReRe, gRendel and ShiRe in the same year.
We have been given the probabilities
P(A1) = 0.05
P(A2|A1) = 0.31
P(A3|A1A2) = 0.47
P(A4|A1A2A3) = 0.38.
The probability that they all will be bankrupt within a given year is then
P(A1A2A3A4) = 0.05 × 0.31 × 0.47 × 0.38 = 0.002 768 3 ≈0.002 8.
Summary and Rules
r P(A|B) is the probability of A, given that B is the case.
r P(A|B) is a probability. Think of B as the context, and if it helps write P(A|B)
as PB(A) to accustom yourself to conditional probability being a regular
probability.
r P(A|B) is best illustrated in Euler diagrams as the part of B that is at the same
time A.
r Definition: P(A|B) = P(AB)
P(B) .
r Important relation: P(AB) = P(A|B) × P(B).
Test Yourself!
r Show that P(A|B) is a probability.
r Draw Euler diagrams to show: P(AB) = P(A|B) × P(B).
r Draw one or two diagrams with the sets A and B. Draw A large, and B small,
and make them intersect. Use the Euler-diagram(s) to visualize how P(A|B)
and P(B|A) differ.
.
Independence
Dependence between two events A and B means that the occurrence of the one
influences the probability of the occurrence of the other. Independence is then
the opposite: that the occurrence of one of them does not influence the proba-
bility of the occurrence of the other.

5.4 Independence

Example 5.4.1 You are on an airplane, and then an engine catches fire. Before
the fire, you estimated the probability of a plane crash to be
1
200 000. After the fire,
you estimate the probability of a crash to be 1
10. Since the probability changed
as a result of the information about the fire, we say that “engine fire” and “plane
crash” are dependent events.
Example 5.4.2
You are on an airplane, and then announce that it’s chicken
for dinner. Before the announcement, you estimated the probability of a plane
crash to be
1
200 000. After the announcement, you estimate the probability of a
crash to be
1
200 000. Since the probability remained unchanged as a result of the
announcement, we say that “chicken dinner” and “plane crash” are independent
events.
You can come up with a multitude of examples for yourself by simply consid-
ering if the occurrence of the one event influences the occurrence of the other.
In probability theory, our simplest examples are repeated tosses of a die or coin,
where the outcome of one try does not influence the probabilities of the results
in subsequent trials. That is: the results of the tosses are independent. We state
this mathematically, as the definition of independence:
Definition 5.4.3 A is independent of B iff P(A|B) = P(A).
That is, A is independent of B if the proportion that is A remains unchanged
when we change context from the entire universe Ω to the sub-universe B. The
next rule states a common way to test (and sometimes also define) indepen-
dence. It follows from our basic definition above, but has the advantage of a
neater form in itself and for its generalizations. As a bonus, it also shows that
when A is independent of B, then B is independent of A. So independence is a
symmetrical property, and we will say that “A and B are independent (of each
other)”.
Rule 5.4.4 A and B are independent iff P(AB) = P(A) × P(B).
Proof: P(AB) = P(A|B) × P(B) = P(A) × P(B).
A good way to visualize independence, is to think of each set as independently
ruling the extension along its own axis. We see this for two sets in Figure 5.8,
and for three sets in Figure 5.9.


5 Probability
]
]
P(A)
P(B)
P(AB)=P(A) P(B)
A
B
Figure .Independence for two events.
Example 5.4.5 We have a coin with P(H) = 0.65. What is P(HT)?
Answer: The coin tosses are independent events: A is “toss one resulted in an
H”, while B is “toss two resulted in a T”. Because of independence,
P(HT) = P(H) × P(T) = 0.65 × 0.35 = 0.227 5.
Independence is readily generalized to multiple events. For one event being
independent of two others, we say that A is independent of both B1 and B2
when the probability of A remains unchanged regardless of whether B1 or B2
are the case. In other words:
P(A| B1B2) = P(A| B1Bc
2) = P(A| Bc
1B2) = P(A| Bc
1Bc
2) = P(A).
For multiple sets, this generalizes to the following definition.
Definition 5.4.6 A is independent of B1, … , Bn iff P(A|B1B2 ⋯Bn) = P(A),
and the inequality holds when you replace one or more Bk by Bc
k.
Independence between multiple sets can be expressed in a myriad ways, but
outside of the definition, the most important one is this, a formula that is itself
frequently also employed as a definition:
C
A
B
P(ABC)=P(A) P(B) P(C)
P(A)
P(B)
P(C)
Figure .Independence for three events.

5.4 Independence

Rule 5.4.7 A1, … , An are independent of each other iff
P(A1A2 ⋯An) = P(A1) × ⋯× P(An)
and the inequality holds if you exchange one or more Ak for Ac
k.
Example 5.4.8
A1, A2, A3 are independent, and P(A1) = 0.4, P(A2) = 0.6,
P(A3) = 0.3. What is P(A1A2A3)?
Answer: P(A1A2A3) = P(A1) × P(A2) × P(A3) = 0.4 × 0.6 × 0.3 = 0.072.
Example 5.4.9 You toss three dice; a D4, a D10, and a D20. What is the prob-
ability that D4 and D20 display prime numbers, but that at the same time, D10
doesn’t?
Answer: Let A1, A2, A3 be the events that D4, D10, D20, respectively, displayed
primes. We are then calculating the probability of A1Ac
2A3. Since each of these
three events are about independently tossed dice, the events themselves are
independent.
r P(A1) = primes
total = n({2,3})
n(D4) = 2
4 = 0.5
r P(A2) = primes
total = n({2,3,5,7})
n(D10)
= 4
10 = 0.4
– P(Ac
2) = 1 −P(A2) = 1 −0.4 = 0.6
r P(A3) = primes
total = n({2,3,5,7,11,13,17,19})
n(D20)
= 8
20 = 0.4
r P(A1Ac
2A3) = 0.5 × 0.6 × 0.4 = 0.12
Example 5.4.10 A biased coin has probability p = P(H) = 0.55 of heads, and
1 −p = P(T) = 0.45 of tails. What is P(HHTTTHTHTHT)?
Answer:
P(HHTTTHTHTHT)
= P(H)P(H)P(T)P(T)P(T)P(H)P(T)P(H)P(T)P(H)P(T)
= P(H)5 × P(T)6 = p5 × (1 −p)6 = 0.555 × 0.456 = 0.000 417 916.
We see that the probability is independent of the order of the heads and
tails, and depended only on the number of each. For a coin with P(H) = p, the
general formula for the probability of a sequence of k heads and n −k tails is
pk(1 −p)n−k.
NOTE: The word “independence” has several uses, and we need to be aware
of one particular use that often causes confusion in statistics: In politics and
geography we speak of independence as a kind of separation, which would cor-
responds to disjoint sets. See Figure 5.10 for the Euler diagram.


5 Probability
A1
A4
A5
A3
A2
Figure .Political independence
corresponds to disjoint sets.
This is rather the opposite of statistical independence, as depicted in Fig-
ures 5.8 and 5.9, where the sets intersect precisely as much with the other sets
as with their complements.
We should rather think of independence in a more moral or psychological,
decision-making sense. Imagine you are buying a jacket, and you see a nice
mocha coloured one that you’d like to wear. But you have heard that M, a per-
son you are a bit at odds with, has such a jacket. What is then the (morally and
psychologically) independent decision? (a) Not buying the jacket, because M
has such a jacket? Or (b) to buy that jacket regardless of what M might own
or think about it? And you probably answered correctly: (b) is the independent
decision, corresponding to statistical independence.
Assignment: Think about different pairs of sets, events and decisions from life
around you, and determine which one are independent, which ones are mutu-
ally exclusive, and which ones are neither. It may be useful to do this as a group
exercise where one comes up with a pair and the rest assess the pair. Try picking
examples to trick each other into the wrong assessment!
..
Conditional Independence
If A1 and A2 are independent, then P(A1A2) = P(A1) × P(A2).
Question: What about conditional probabilities? Is P(A1A2|B) = P(A1|B) ×
P(A2|B) when A1 and A2 are independent?
Answer: That actually depends on the conditioning event B! Recall that the
conditional probability P(⋅|B) = PB(⋅) works just like any (other) regular proba-
bility, only that the context is B, not Ω. Let us try to device a B such that a pair A1
and A2 that are independent in context Ω are not so in context B. If you recall
our discussion above, that disjointness is the opposite of statistical indepen-
dence, just let B = (A1A2) ∪(Ac
1Ac
2). Draw an Euler diagram and see that in this
case, P(A1A2|B) = P(A1|B) = P(A2|B), so that P(A1A2|B) ≠P(A1|B) × P(A2|B)
(unless they are all equal to 1).

5.4 Independence

For a practical example, let us device a B that works much in the same way
as our B above: Let A1 be that Nathan turns up at the party tonight, and A2
that Beatrice turns up. If Nathan and Beatrice don’t know each other, then we
may consider A1 and A2 to be independent events, where the event that one of
them turns up doesn’t alter the probability of the other one turning up. But let
us introduce event that maybe happened earlier that day: B = “Nathan fell in
love with Beatrice, and wants to be at the parties she’s at”. Will A1 and A2 then
be independent? No, for if B is the case, then Beatrice’s presence at the party
increases the probability that Nathan wil turn up. So A1 and A2 are condi-
tionally dependent. A new event, C = “Nathan has gotten over Beatrice”, may
make the events independent again, and this time conditionally independent
given C.
When determining if A1 and A2 are independent given B, consider what kind
of world B creates, and assess how A1 and A2 influence each other’s proba-
bilities in that world. We defines ordinary independence between A1 and A2
by that the probability of A1 was uninfluenced by whether A2 was the case or
not. Conditional independence is then that the conditional probability of A1 is
uninfluenced by whether A2 is the case or not. We write this as a definition:
Definition 5.4.11 A1 and A2 are conditionally independent given B, if
P(A1|A2B) = P(A1|B).
Just as for regular independence, this means
Rule 5.4.12 A1 and A2 are conditionally independent given B, if
P(A1A2|B) = P(A1|B) × P(A2|B).
Example 5.4.13 You have an urn with two red (R) and two white (W) balls.
You are going to draw two balls; let A1 = “the first ball is R”, and let A2 =
“the second ball is R”. After drawing the first ball, you toss a coin to decide
whether to return the ball to the urn. Let B = “you return the ball”. Are A1 and
A2 independent, given B? Are A1 and A2 independent?
If B is returned after the first draw, you have four balls at both draws: two W
and two R.
r P(A1|B) = reds
total = 2
4.
r P(A2|B) = reds
total = 2
4.
r A1A2 is the set of two draws where the outcome is RR. We may draw a tree
diagram and see that 4 out of 16 branches yield RR, meaning P(A1A2|B) =
red−red
total
= 4
16.


5 Probability
We see that P(A1A2|B) = 4
16 = 2
4 × 2
4 = P(A1|B) × P(A2|B), so A1 is indepen-
dent of A2, given B.
But notice that the independence is conditional on B, return of the ball. If the
ball is not returned, corresponding to Bc, the independence vanishes. If the ball
is not returned, there are only three balls left for the next draw, so the proba-
bility of getting R on the second draw if you had R on the first, is reduced to
1
3. So while P(A1|Bc) = 1
2 and P(A2|Bc) = 1
2, we still have P(A1A2|Bc) = 1
6, so
P(A1|Bc) × P(A2|Bc) ≠P(A1A2|Bc), meaning that A1 and A2 are not indepen-
dent, given Bc.
Conditional independence for multiple sets is captured in the formula
When A1, … , An are conditionally independent of each other, given B, then
P(A1 ⋯An|B) = P(A1|B) ⋯P(An|B).
.
Repeated Sampling and Probability
In Chapter 4, we studied how many ways there were to sample from a given set,
and got different formulas (Method 4.3.1) depending on whether the sampling
was ordered or unordered, and whether the sampled unit was replaced. We will
now study probabilities for repeated samplings. More precisely, we will divide
the set to be sampled from into kinds, and look at the probabilities of getting
certain sequences or combinations of kinds as we sample.
Definition 5.5.1 Sequence and combination:
r A sequence of n samplings from a set is list of the results of the sampling,
in the order they occurred. It is ordered.
r A combination of n samplings from a set is an overview of how many were
sampled of each kind. It is unordered.
Example 5.5.2
Coin toss. A 7 toss sequence yields HTTHHTH. The corre-
sponding combination is 4H and 3T.
Example 5.5.3
You have an urn with 4 red balls (“R”), 17 green (“G”), and
8 blue (“B”). Sampling 9 balls yields the sequence RGGGBGGBG; the corre-
sponding combination is 1R, 6G and 2B.

5.5 Repeated Sampling and Probability

We know that when we remove an element from an urn, a deck of cards, or
some other finite repository, we thereby alter the proportions of the different
kinds of item. If you have a bag of assorted candies with 2 Almond Joy and
1 Twizzler left, and you pick an Almond Joy, the proportion of Almond Joy
changes from 2
3 to 1
2. But if we replace the Almond Joy, the proportions are
unchanged. So when the probability of drawing a given type equals the propor-
tion of that type, then the probability will remain unchanged if you replace after
the draw.
When we sample with replacement, the probabilities remain unchanged
when the probability of a type equals its proportion. This is then a model
for any kind of repeated trial with identical probabilities, like tossing dice or
coins, or waiting for a red car to drive by. We will later come to know these as
Bernoulli processes (Definition 9.2.4). For now, we will use the term sampling
with replacement.
So our first division line is whether the trial is a “sampling with replacement”,
or a “sampling without replacement”. Given m different possible outcomes of
the trial, then
r in sampling without replacement, we need to specify the total number of
elements, N, the number of types, m, and the total number of elements of
each type, S1, S2, … , Sm;
r in sampling with replacement, we need only specify the number of types, m,
and the proportions for each type, p1, p2, … , pm. If you know Sk and N, then
pk = Sk∕N.
Since we will be working mainly with cases of only two types, we make two
tables: one for the special case of sampling from sets of only two types, and
one general table for sampling from sets of m types. For the latter, we will be
employing the multinomial in Section A.2.
Note 5.5.4
These probabilities resurface in Chapter 9 as probability distri-
butions, respectively in Section 9.4 (unordered without replacement) and in
Section 9.3 (unordered with replacement).
Rule 5.5.5 For n samples with or without replacement, recorded as ordered
sequences or as unordered combinations, the formulas are as follows.
r We set the parameters to two types, N elements (if applicable), S = S1 ele-
ments of the first type (if applicable), and p = p1. Further, k is the number
of positives (the first kind), whereas n −k is the number of negatives. The
probability of such a result is then given by the following table.


5 Probability
With replacement
Without replacement
Sequence
(ordered)
pk(1 −p)n−k
(N−n
S−k
)
(N
S
)
Combination
(unordered)
(
n
k
)
pk(1 −p)n−k
(S
k
)(N−S
n−k
)
(N
n
)
=
(N−n
S−k
)(n
k
)
(N
S
)
r We set the parameters to m types, N elements (if applicable), Sj elements of
the type j (if applicable), and the proportion of type j is pj. Further kj is the
number results of the jth kind. The probability of such a result is given by
the following table.
With replacement
Without replacement
Sequence
(ordered)
pk1
1 ⋯pkm
m
(
N−n
S1−k1…Sm−km
)
(
N
S1…Sm
)
Combination
(unordered)
(
n
k1 … km
)
pk1
1 ⋯pkm
m
(
n
k1 … km
)(
N−n
S1−k1…Sm−km
)
(
N
S1…Sm
)
Note 5.5.6 Approximation: If n, the number of samples, is a lot smaller than
the total number of elements, N, the calculated values for sampling with and
without replacement will be very similar. In situations where small errors do not
matter, it is expedient to use the faster formulas of sampling with replacement,
even when the sampling is without. See Chapter 9 for more details.
Example-proof 5.5.7
A coin has P(H) = 0.6 and P(T) = 0.4. What is
P(HTTHHHHT)?
Answer: This is a sequence, “with replacement”, so the right formula is pk(1 −
p)n−k. Here, p = P(H) = 0.6, n = 8, and k = 5. But instead of just plugging into
the formula, we will look at how it arises in this specific instance.
The coin tosses are independent events: A1 is “toss 1 landed H”, A2 is “toss 2
landed T”, and so on up to A8 being “toss 8 landed T”. Therefore,
P(HTTHHHHT) = P(H)P(T)P(T)P(H)P(H)P(H)P(H)P(T)
= (P(H))5 × (P(T))3 = pk(1 −p)n−k,

5.5 Repeated Sampling and Probability

which is the formula; we use that p = 0.6, n = 8, and k = 5, and get
P(HTTHHHHT) = 0.65 × 0.43 ≈0.005 0.
Example-proof 5.5.8 A coin has P(H) = 0.6 and P(T) = 0.4. What is the prob-
ability of precisely 5 heads in 8 tosses?
Answer: This is a combination, “with replacement”, so the right formula is
(n
k
)pk(1 −p)n−k. Here, p = P(H) = 0.6, n = 8, and k = 5. But instead of just
plugging into the formula, we will look at how it arises in this specific instance.
In the previous example, we calculated the probability that a given sequence
of 5 heads in 8 tosses was (P(H))5 × (P(T))3. The probability is the same for all
such sequences, so we need to multiply by the number of such sequences. So
how many are they? In the example above, we got heads in tosses 1, 4, 5, 6, and
7. This corresponds to marking the numbers 1, 4, 5, 6, 7 in the sequence from 1
to 8. We recall that an unordered sampling of k from a total of n may be done in
(n
k
) ways, so the number of different sequences with 5 heads in 8 tosses is (8
5
).
P(5 heads in 8 tosses) = (8
5
)0.6k0.4n−k
= (n
k
)pk(1 −p)n−k,
which is the formula; we use that p = 0.6, n = 8, and k = 5, and get
P(5 heads in 8 tosses) =
(8
5
)
× 0.65 × 0.43 ≈0.28.
Example-proof 5.5.9 A certain deck of cards has 19 marked cards (M), and
33 unmarked cards (U). You are dealt a hand of 5 cards. What is the probability
that precisely 2 of the cards are marked – that is, 2M and 3U?
Answer: This is a combination, “without replacement”, so the right formula is
(S
k
)(N−S
n−k
)
(N
n
)
.
Here, N = 52, S = 19, n = 5, and k = 2. But instead of just plugging into the
formula, we will look at how it arises in this specific instance.
This is a simple application of the formula P = positive
total . From a deck of 52
cards, how many hands of 5 are possible? Combinatorics tells us that the total
number of ways to choose n elements from a total of N is (N
n
). So the possible
number of hands is (52
5
).
The positives are the hands that have 2 of the 19 marked cards, and 3 of the
33 unmarked. So we must see how many ways we can pick the 2 from the 19,


5 Probability
and 3 from the 33. This is respectively (19
2
) and (33
3
) ways. By Rule 4.3.9, the
number of positive hands is then (19
2
)(33
3
). This means
P(2M and 3U) = positive
total
=
(19
2
)(33
3
)
(52
5
)
=
(S
k
)(N−S
n−k
)
(N
n
)
,
which in this case is
P(2 M and 3 U)=
932 976
2 598 960 ≈0.358 981.
Example-proof 5.5.10 A certain deck of cards has 19 marked cards (M), and
33 unmarked cards (U). You are dealt a hand of 5 cards. What is the probability
that you are dealt your hand in the sequence MUUMU?
Answer: This is a sequence, “without replacement”, so the right formula is
(N−n
S−k
)
(N
S
) .
Here, N = 52, S = 19, n = 5, and k = 2. But instead of just plugging into the
formula, we will look at how it arises in this specific instance.
Consider all possible sequences of M and U if we put all the 52 cards in a row.
Each sequence is a unique distribution of S = 19 marked cards among the N =
52 positions in the sequence. The number of possible sequences is (N
S
) = (52
19
).
How many such sequences start in MUUMU? Well, these are the sequences
starting in MUUMU, and ending in a tail of 19 −2 U and 33 −3 M. So how
many such tails are possible? The tail has S −k = 19 −2 M, out of a total of
N −n = 52 −5 cards. The number of sequences starting in MUUMU is then
(N−n
S−k
) = (52−5
19−2
). Then
P(MUUMU) = positive
total
= number of sequences starting in MUUMU
total possible sequences
=
(52−5
19−2
)
(52
19
)
=
(N−n
S−k
)
(N
S
) ,
which in this case is
P(MUUMU) =
2 741 188 875 414
76 360 380 541 900 ≈0.035 898 1.

5.5 Repeated Sampling and Probability

Example 5.5.11
We will now consider an example with m > 2 alternatives.
In all the sub examples, we’ll be looking at a bag of chocolates with 4 different
types: dark, milk, white, and mint. The bag contains S1 = 10 dark chocolates,
S2 = 18 milk chocolates, S3 = 6 white chocolates, and S4 = 11 mint chocolates.
A total of N = 45 chocolates.
(1) Frederick is curious what’s inside the bag, so he picks one, inspects it, and
returns it to the bag. He does this 7 times, and gets mint, milk, milk, dark,
mint, white, and milk. What is the probability of this exact sequence?
Answer: This is an ordered sampling, with replacement. We calculate the p
values: p1 = S1
N = 10
45, p2 = S2
N = 18
45, p3 = S3
N = 6
45, p4 = S4
N = 11
45. The num-
ber of positives for each is k1 = 1, k2 = 3, k3 = 1, k4 = 2. The probability of
the sequence is then
P = pk1
1 × pk2
2 × pk3
3 × pk4
4 =
(10
45
)1
×
(18
45
)3
×
( 6
45
)1
×
(11
45
)2
=
3 872
34 171 875 ≈0.000 11.
(2) The gambler Sam saw what Frederick got, but for his own sake, he is more
interested in the probability that such a sampling would yield 1 dark, 3 milk,
1 white, and 2 mint. What is the probability of this result?
Answer: This is unordered sampling with replacement. The formula for
this probability is like the sequence in the previous example, but with an
added multinomial factor for the number of sequences corresponding to
these numbers.
P =
(
7
1, 3, 1, 2
)
× pk1
1 × pk2
2 × pk3
3 × pk4
4 = 420 ×
3 872
34 171 875
= 108 416
2 278 125 ≈0.048.
(3) Sam now wants to make a bet with the Bayesian Bard about what Bard will
get if he samples 7 chocolates. Sam forgets that Bard is a glutton when it
comes to chocolate, and will eat each piece he picks. That is: his sampling
will be without replacement. What is the probability that Bard ate mint,
milk, milk, dark, mint, white, and milk?
Answer: This is ordered sampling without replacement. The formula
requires not just the numbers from the result, but also the number of ele-
ments in the bag. The required values are S1 = 10, S2 = 18, S3 = 6, S4 = 11,
N = 45, k1 = 1, k2 = 3, k3 = 1, k4 = 2, n = 7.
P =
(
45−7
10−1, 18−3, 6−1, 11−2
)
(
45
10, 18, 6, 11
)
=
(
38
9, 15, 5, 9
)
(
45
10, 18, 6, 11
) =
68
481 299 ≈0.000 141 28.


5 Probability
(4) Bard cares more for which pieces he got to eat than the order in which he
ate them. What is the probability that Bard ate 1 dark, 3 milk, 1 white, and
2 mint?
Answer: This is unordered sampling without replacement. The formula for
this probability is like the sequence in the previous example, but with an
added multinomial factor for the number of sequences corresponding to
these numbers.
P =
(
7
1, 3, 1, 2
)
×
(
45−7
10−1, 18−3, 6−1, 11−2
)
(
45
10, 18, 6, 11
)
= 420 ×
68
481 299
= 1 360
22 919 ≈0.059 339.
Summary and Rules
r A and B are independent when P(AB) = P(A) × P(B), or equivalently when
P(A|B) = P(A), which is also equivalent to P(B|A) = P(B).
r Informally, we say A and B are independent of the occurrence if one of them
does not influence the probability of the occurrence of the other.
r If A and B are mutually exclusive, then they are not independent.
Test Yourself!
r Show, by employing Euler diagrams, that if A and B are mutually exclusive,
then this is not true unless the product is zero: P(AB) = P(A) × P(B).
r Show, either by employing Euler diagrams or by formal proof, that if two of
the following are equal, then all three must be: P(A), P(A|B), P(A|Bc).
Example 5.5.12 P(B|A) = 0.5, P(B) = 0.8, and P(A) = 0.6; what is P(A|B)?
Answer: P(A|B) = P(A)×P(B|A)
P(B)
= 0.6×0.5
0.8
= 0.375.
.
Exercises
1
Review: Read the chapter.
(a) What is an Euler diagram? What can it teach us about the basic laws
of probability?
(b) What is frequentist probability?
(c) What is Bayesian probability?
(d) What does conditional probability mean, and how does it differ from
regular probability?
(e) What does statistical independence mean?

5.6 Exercises

Exploration
2
Coin flipping: best done in groups, as a competition. Try to control the out-
come of a coin flip, flipped from a reasonable (not too far, not too close)
distance from a level surface. After a period of practice, set up a compe-
tition sequence of 10 coin flips, where you compete on who gets closest
to 100% (or 0%) heads. To win, you should try to make the initial condi-
tions of your coin flips as consistent as possible. Notice and control height
and distance to the surface, as well as where on your hand you place the
coin, how it is oriented, and how hard you flip it with your thumb. In your
preparatory training, see what makes for the best consistency: a soft or a
hard surface; hard or limp slipping; etc.
3
Resistors: pick some resistors with the same nominal resistance. Measure
the actual resistance, and compare it to the nominal: is it over or under?
Measure in batches of 10. Do you think you can influence the number that
are over? Give reasons for why or why not. Then try it out!
Deﬁnitions
4
The cooler: your local corner supermarket tends to be a bit negligent about
checking their stock, and you know from experience that one in five milk
cartons is past its sell-by date. Earlier today, you bought a carton of milk,
and forgot to check the date.
(a) What is the frequentist probability that your milk is past its sell-by
date?
(b) What is the objective Bayesian probability that your milk is past its
sell-by date?
5
The cooler II: your flat mate is going to the local corner supermarket to
buy milk, and she never checks the sell-by date.
(a) What is the frequentist probability that the milk she buys is past its
sell-by date?
(b) What is the objective Bayesian probability that the milk she buys is past
its sell-by date?
Basic Probability
6
A given coin has probability p = 0.37 of heads. What is the probability of
tails?
Conditional Probability
7
P(A) = 0.5, P(B) = 0.25, P(AB) = 0.125.
(a) What is P(A ∪B)?
(b) What is P(A|B)?
(c) What is P(B|A)?


5 Probability
8
P(A) = 0.5, P(B|A) = 0.2, P(A|B) = 0.4. Find P(B).
9
A biased D6 die has probabilities P(1) = 0.1, P(2) = 0.1, P(4) = 0.2, P(5) =
0.2, P(6) = 0.15. What is P(3)?
10
P(A) = 1
3, P(B) = 1
4, and P(B|A) = 1
5.
(a) What is P(AB)?
(b) What is P(A ∪B)?
(c) What is P(A|B)?
11
P(A) = 0.3, P(B) = 0.2, and P(B|A) = 0.25.
(a) What is P(AB)?
(b) What is P(A ∪B)?
(c) What is P(A|B)?
12
P(AB) = 1
4 and P(B) = 3
4. What is P(A|B)?
13
P(AB) = 0.12 and P(A) = 0.6. What is P(B|A)?
14
Illustrate the following formulas with Euler diagrams, and give five con-
crete examples of each:
P(A ∪B) = P(A) + P(B) −P(AB)
and
P(AB) = P(A) + P(B) −P(A ∪B).
Repeated Sampling
15
A coin has probability p = 0.37 of heads. What is the probability of the
sequence HHTHTHHHTTTHHHHTTHTHTHHT?
16
A coin has probability p = 0.37 of heads. What is the probability of 14
heads in 37 flips?
17
A coin has probability p = 0.53 of heads. What is the probability of 21
heads in 47 flips?
18
A coin has probability p = 0.61 of heads. What is the probability of 30
heads in 60 flips?
19
Assorted Candies I: you are tidying up after a party, and find a bag of
assorted candies. The only pieces left in the bag are 7 Almond Joy and 13
Twizzlers.

5.6 Exercises

(a) You pick a candy at random. What is the probability that you get an
Almond Joy?
(b) You like neither Twizzlers nor Almond Joy, so you return your piece to
the bag to try again. You try a total of five times, and return the piece
to the bag every time. What are the probabilities that you got Almond
Joy 0, 1, 2, 3, 4, and 5 times, respectively.
(c) Later in the morning, you are so hungry you’ll eat even Almond Joy
and Twizzlers, so you pick 5 and eat. What are the probabilities that
you ate respectively 0, 1, 2, 3, 4, or 5 Almond Joy?
20
You have a box of 40 fuses that look exactly alike except for the colour.
There are 4 violet (V), 22 blue (B), 7 red (R), 5 orange (O), and 2 yellow (Y)
fuses. Find the probabilities of the following samples.
(a) YBBROBROV (sampling with replacement).
(b) YBBROBROV (sampling without replacement).
(c) 1V, 3B, 2R, 2O, 1Y (sampling with replacement).
(d) 1V, 3B, 2R, 2O, 1Y (sampling without replacement).
21
A bag of Christmas candies contains 20 candies in red foil, 12 in green foil,
and 8 in blue foil. If you eat 10 candies at random, what is the probability
that you eat 5 red, 3 green, and 2 blue?
22
A bag of 50 identical looking chocolate balls contains 30 chocolates filled
with liqueur (L), and 20 filled with marzipan (M). If you eat 10 random
chocolates, what is the probability that you eat them in the following
sequence: LMLMLMLMLM?
23
You have flipped a coin 50 times. The probabilities of heads and tails are
equal: 1
2
(a) Find P(HTHTTTHHHTHHTTTTTHTTHHH
HTTTHHHHTTTTHHHTTTTHHHTHTTT).
(b) If we rearrange the Hs and the Ts into a different sequence of 27 tails
in 50 attempts, what is the probability of this new sequence?
(c) How many different sequences amount to a combination with 27 heads
in 50 attempts?
(d) How many different sequences of heads and tail are possible in 50 coin
flips?
(e) What is the probability of 27 tails in 50 coin flips?
24
You’ve been flipping coins again. This time only 8 times. The probabilities
of heads and tails are equal: 1
2.


5 Probability
(a) What is the probability of TTHTTTHT?
(b) If we rearrange the Hs and the Ts into a different sequence of 5 tails in
8 attempts, what is the probability of this new sequence?
(c) How many different sequences with 5 tails in 8 attempts are there?
(d) How many different sequences of heads and tail are possible in
8 attempts?
(e) What is the probability of 5 tails in 8 coin flips?
25
You’ve been flipping a coin again, 8 times. But this time the coin is biased,
with a probability of heads of 1
3.
(a) What is the probability of TTHTTTHT?
(b) If we rearrange the Hs and the Ts into a different sequence of 6 tails in
8 attempts, what is the probability of this new sequence?
(c) Is the probability of HHHHHHHH the same as the probability of
TTHTTTHT?
(d) What determines the probability of a given sequence? Why?
(e) How many different sequences with 6 tails in 8 attempts are there?
(f) What is the probability for 6 tails in 8 coin flips?
26
Gold Digger Airlines run a daily shuttle between San Remo and Dry
Creek. They have two aircraft: a two-engine DC-3 that used to belong to
a Columbian drug cartel, and an old four-engine DC-6B bought from the
US Army. All the six engines, that is, all the engines on both planes, have
the same probability p of failing. For both planes: find the probability that
half the engines will fail
(a) when p = 0.001;
(b) for p in general;
(c) let’s assume you hold your life dear, and that a plane will crash if half
or more of the engines fail. For which values of p should you prefer the
two-engine DC-3 (given that you fly at all)?
Combinatorics
27
Birthdays: we are investigating to figure out how many persons may be in
the same room, before the probability that at least 2 of them have the same
birthday exceeds 1
2. Are you able to make a good guess at the answer in
advance?
(a) Musa and Ibrahim wonder what the probability that the two are not
born on the same date happens to be. Calculate this!
(b) Their common friend Issa found the answer, but he wonders what
the probability that none of the three have the same birthday happens
to be.
(c) What is the probability that at least two of them share a birthday.

5.6 Exercises

(d) Math teacher Mohammed thinks the three have an interesting inves-
tigation, and wonders what the probability is if they include him as a
fourth person. What is the probability that Musa, Ibrahim, Issa, and
Mohammed all have different birthdays?
(e) What is the probability that at least two of the four share a birthday?
(f) Their fellow student Aisa tells them to finish their warm-ups, and go
for the main question: How many persons can be present in a room
before the probability that at least two of them have the same birthday
exceeds 1
2? She hints that the answer is less than 30. What is answer to
Aisa’s question?
28
For each of the official hands in regular five-card hand poker, calculate the
number of ways to realise such a hand. (Warning: calculations of the sim-
plest hands are somewhat demanding! Hint: Start out with the rare hands,
and work your way down.)




Bayes’Theorem
CONTENTS
6.1
Bayes’Formula, 107
6.2
The Probability of an Observation, 109
6.3
Bayes’Theorem, 111
6.4
Next Observation and Update, 114
6.5
Updating, When the Probability of Bn+1
Depends on B1, … , Bn, 118
6.6
Applied Examples, 122
6.7
Bayesian Updating in the Long Run, 125
Summary, 129
6.8
Exercises, 129
.
Bayes’Formula
We have seen that P(A|B), which is A’s proportion of B, very rarely equals
P(B|A), that is, B’s proportion of A. But are the two still related? They are, and
this relation is important enough to have its own name: Bayes’ formula.
Rule 6.1.1 Bayes’ formula P(A|B) = P(A) ⋅P(B|A)
P(B)
Proof: Use P(AB) = P(A) ⋅P(B|A) (5.3.4) for P(AB) in P(A|B) = P(AB)
P(B) (5.3.1), as
illustrated in Figure 6.1.
Example 6.1.2
Mammography:1 Knowing that roughly one in ten women
will get breast cancer at some point in life, you want to check yourself regularly
1 The numbers vary, so we have employed a simpilified version of numbers from https://www
.cancer.gov and Professor Odd Aalen.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


6 Bayes’ Theorem
P(A)
P(B|A)
P(B)
P(B)
P(AB)
P(A|B)
Figure .
P(A)⋅P(B|A)
P(B)
= P(AB)
P(B) = P(A|B).
so that you catch the disease early. Like most women, you take the test several
times, so the probability that you have cancer as you go to your next check-up
is 5‰. You also know that 10% of all mammograms are positive, and also that
about 80% of those who actually have cancer get a positive mammogram. So
now you have been tested, and your mammogram is positive. Does this mean
that the probability that you have breast cancer is 80%?
Answer: We translate our question into mathematical notation, and let A =
{has cancer} and B = {has positive mammogram}. What we know thus far, is
that P(B|A) = 80%. But what you are looking for is P(A|B), the conditional prob-
ability that you have cancer if your mammogram is positive. To find this latter
quantity, Bayes’ formula tells us that we need P(A) and P(B) as well. We read
above that P(B) = 10%, and that P(A) = 5‰. Then
P(A|B) = P(A) ⋅P(B|A)
P(B)
= 0.005 ⋅0.8
0.1
= 0.04 = 4%.
You may get even more accurate results if you narrow down to the numbers
for your demographic, but the take-home message of this example is clear: a
positive mammogram does not by itself mean you have cancer. It just means
you need a follow-up test. For we see that the two conditional probabilities
P(A|B) and P(B|A) are very different. This is illustrated in Figure 6.2.
B
A
AB
(a) A and B intersect in AB.
B
AB
(b) P(A B) = P (AB)
P (B) .
A
AB
(c) P(B A) = P (AB)
P (A) .
Figure .A’s share of B may be large, while at the same time B’s share of A is small.

6.2 The Probability of an Observation

Bayes’ formula is important, since we need to know both the difference and
the relation between P(A|B) and P(B|A). Many confusions and much abuse of
probabilities hinge on confusing P(A|B) and P(B|A). By demonstrating the dif-
ference, we can clear up confusion and unmask abuses.
.
The Probability of an Observation
The machinery we will soon get to know as Bayes’ theorem begins with Bayes’
formula, and with another important rule, the rule of total probability. This is
expressed in Rule 6.2.1 and in Figure 6.3.
Rule 6.2.1 Total probability: If Aj are disjoint sets, and ∪jAj = Ω, then we
have for any B that
P(B) =
∑
j
P(AjB) =
∑
j
P(Aj) ⋅P(B|Aj).
Conditional probability
Joint probability of
Probability of
of event B, given
event B and
alternative Ak
alternative Ak
alternative Ak
k
P(Ak)
P(B Ak)
P(AkB)
1
  A1
 A1B
 A1B
2
  A2
  A2B
  A2B
3
  A3
  A3B
  A3B
P(B), the total probability of event B:
B
Figure .Total probability illustrated with Euler diagrams.


6 Bayes’ Theorem
D
D
D
D
D
D
4
6
8
10
12
20
7
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
5
6
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
5
6
7
8
9
10
11
12
5
6
7
8
9
10
5
6
7
8
Figure .The possibilities and their
probabilities.
Proof:
The first equality follows from Kolmogorov’s 2nd axiom: let B be
a disjoint union of sets AkB; that is, let B = A1B ∪⋯∪AnB. Then P(B) =
P(A1B) + ⋯+ P(AnB). The second equality is Rule 5.3.4.
Example 6.2.2 A purely numerical example.
Joint probability = Product
k
P(Ak)
P(B|Ak)
P(Ak)⋅P(B|Ak) = P(AkB)
1
0.6
0.3
0.6⋅0.3 = 0.18
2
0.3
0.9
0.3⋅0.9 = 0.27
3
0.1
0.5
0.1⋅0.5 = 0.05
Total probability = Sum:
P(B) = 0.18 + 0.27 + 0.05 = 0.5
Example 6.2.3 Gamesmaster has six dice in a box: D4, D6, D8, D10, D12, and
D20, all of them having four red sides and the remainder white. He picks a die
at random, and tosses it, all out of view of the gamers and us. He will tell us if
it landed red or white. What is the probability that it landed white?
Answer: We will go through the set-up and the calculations in detail. The
answer consists of three equally important phases: the preparatory phase,
where we identify the alternatives Ak and the (potential) observation B.
The second phase is to quantify the probabilities of Ak and B, and the final
phase is the calculation itself, where we fill in the table and calculate the
probability P(B). The possibilities and their probabilities are illustrated in
Figure 6.4.
Identification: Here, we identify the alternatives Ak, and the (potential) obser-
vation B.

6.3 Bayes’ Theorem

r The alternatives Ak are the mutually exclusive events that our universe is
divided into. Here, Ak is “we drew Dk”, for k = 4, 6, 8, 10, 12, 20.
r B is the (potential) observation of which we are calculating the probability.
Here, B = “Gamesmaster’s die landed on white”.
Quantification: We first quantify the probabilities of each alternative Ak, and
then the conditional probabilities of B given Ak for each Ak.
r Since there is no preferred die, the principle of symmetry says they are
equally probable. Since there are 6 dice, P(Ak) =
prositive
total
= 1
6 for all k.
r P(B|Ak) is the probability of white given the die is Dk. The principle of sym-
metry says this probability is given by the number of sides on the die, so
P(B|Ak) = 1 −4
k .
Calculation: We enter the probabilities in the table. We get that P(B) = 29
60:
k
P(Ak)
P(B|Ak)
P(Ak) × P(B|Ak) = P(AkB)
4
(1∕6)
0∕4
(1∕6) × 0 = 0
6
(1∕6)
(2∕6)
(1∕6) × (2∕6) = 1∕18
8
(1∕6)
(4∕8)
(1∕6) × (4∕8) = 1∕12
10
(1∕6)
(6∕10)
(1∕6) × (6∕10) = 1∕10
12
(1∕6)
(8∕12)
(1∕6) × (8∕12) = 1∕9
20
(1∕6)
(16∕20)
(1∕6) × (16∕20) = 2∕15
P(B) = Sum = 29∕60
.
Bayes’Theorem
Bayes’ theorem is by many considered the crown jewel of statistics. So what
does it do? Bayes’ theorem works like a machine taking old probabilities and
new data as its inputs, and whose outputs are new, updated probabilities. Bayes’
theorem is stated in Rule 6.3.1, and shown graphically in Figure 6.5.
Rule 6.3.1 Bayes’ theorem: If we divide Ω into n disjoint (mutually exclu-
sive) sets A1, A2, … An, then
P(Ak|B) =
P(Ak) × P(B|Ak)
∑
j P(Aj) × P(B|Aj).
Proof: Use the expression in Rule 6.2.1 for P(B) in the denominator in Bayes’
formula (Rule 6.1.1).


6 Bayes’ Theorem
Prior
Likelihood
Joint
Posterior
k
P(Ak)
P(B Ak)
P(AkB)
P(Ak B)
1
  A1
 A1B
 A1B
 A1B
2
  A2
  A2B
  A2B
  A2B
3
  A3
  A3B
  A3B
  A3B
Total, P(B):
B
Figure .Bayes’theorem illustrated with Euler diagrams.
Bayes’ theorem is easily calculated in a table, both on paper and in a spread-
sheet. We start out with the following numerical example.
Example 6.3.2 We have three alternatives A1, A2, A3, and an observation B.
The probabilities are P(A1|Ω) = 0.7, P(B|A1) = 0.3, P(A2|Ω) = 0.1, P(B|A2) =
0.6, P(A3|Ω) = 0.2, and P(B|A3) = 0.8. Find P(A2|B).
Answer: Using the plain formula, we get
P(A2|B) =
0.1 × 0.6
0.7 × 0.3 + 0.1 × 0.6 + 0.2 × 0.8 ≈0.140.
We then perform the calculations in a table. The table we employ for calcu-
lating Bayes’ theorem is the same that we used to calculate total probability,
expanded with an additional column for P(Ak|B), which we get by dividing the
joint probabilities by the total probability:
k
P0(Ak)
P0(B|Ak)
P0(AkB)
P0(Ak|B) = P1(Ak)
1
0.7
0.3
0.7 × 0.3 = 0.21
0.21∕0.43 = 0.488
2
0.1
0.6
0.1 × 0.6 = 0.06
0.06∕0.43 = 0.140
3
0.2
0.8
0.2 × 0.8 = 0.16
0.16∕0.43 = 0.372
Sum = 0.43

6.3 Bayes’ Theorem

Notice that we enumerated the probabilities in the example above. Proba-
bility 0 is the base probability P0(A) = P(A) = P(A|Ω), conditioned on only the
fundamental context Ω. Probability 1 is in addition conditioned on B being the
case. We may include B in the context rather than making it explicit in the nota-
tion, so we write P1(A) = P(A|BΩ). In the next section, we will update one more
time, with observation B2. This gives us the probability P2(A) = P(A|B1B2).
Note on notation and columns
The table for Bayes’ theorem is an expanded version of the table for total prob-
ability, but notice that we are naming of the columns slightly differently.
r The initial probability, P0(Ak), is the prior probability.
r P0(B|Ak) is a likelihood.
r The product P0(Ak) × P0(B|Ak) is the joint probability P0(BAk).
r The sum of the joint probabilities P0(BAk) is the total probability P0(B).
r The final column, P1(Ak) = P0(Ak|B), is the posterior probability.
It may feel strange to think that knowledge can update a probability. But recall
that, classically understood, probability is degree of knowledge. Probability is
a truth with fractional value. But to aid this understanding, we need a logical
example.
Example 6.3.3 Hassan and Rizwan are among the five qualified applicants for
an engineering position with GrenDrill Ltd in the North Sea. They meet at their
mailboxes, and they both have a letter from GrenDrill. What is the probability
that Hassan got the job? Since there are five applicants, the symmetry criterion
tells us that it is 1
5.
Rizwan opens his envelope first; he got the job! What is now the probability
that Hassan got the job? Logic tells us that since the job is now taken, Hassan
can’t get the job. So we see that the knowledge that Rizwan got the job forced
us to update the probability that Hassan got the job, from 1
5 to 0.
Now another example, but with a few more fractions.
Example 6.3.4 Hassan and Rizwan are among the five qualified applicants for
two engineering position with GrenDrill Ltd in the North Sea. They meet at
their mailboxes, and they both have a letter from GrenDrill. What is the prob-
ability that Hassan got the job? Since there are five applicants and two jobs, the
symmetry criterion tells us that it is 2
5 = 40%.
Rizwan opens his envelope first; he got one of the two positions GrenDrill!
What is now the probability that Hassan got a job with GrenDrill? The knowl-
edge that Rizwan got one of the jobs makes us realize that there are four appli-
cants left, and one job. Logic then dictates that the probability that Hassan


6 Bayes’ Theorem
D
D
D
D
D
D
4
6
8
10
12
20
1
Figure .The world, when
B = white.
got this other job is 1
4 = 25% – down from the 40% that it was before Rizwan
opened his envelope.
Example 6.3.5
This is a continuation of Example 6.2.3, where we looked at
Gamesmaster’s dice.
Gamesmaster has six dice in a box: D4, D6, D8, D10, D12, and D20, all of them
having four red sides and the remainder white. He picks a die at random, and
tosses it, all out of view of the gamers and us. He announces that it landed white.
(That is, the event is B1 = W, “white”.) For all the k, find the updated (posterior)
probabilities P1(Ak) = P0(Ak|B1) that he had picked the Dk die. In Figure 6.6,
we follow up Figure 6.4, by conditioning on knowing that B = white.
Answer: We expand the table from Example 6.2.3 by one column, and find:
Prior
Likelihood
Joint
Posterior
k
P0(Ak)
P0(B1|Ak)
P0(B1Ak)
P1(Ak) = P0(B1Ak)∕P0(B1)
4
1∕6
0
0
0
6
1∕6
1∕3
1∕18
10∕87
8
1∕6
1∕2
1∕12
5∕29
10
1∕6
3∕5
1∕10
6∕29
12
1∕6
2∕3
1∕9
20∕87
20
1∕6
4∕5
2∕15
8∕29
P0(B1) = 29∕60
.
Next Observation and Update
What happens, and what should we do, if we run more rounds of observations
and updated probabilities? This is often the case, so it is expedient to employ a
tidy form of notation.
Our rounds of updates will then progress as follows.
r The basic probability is P0, where the probability of A is P0(A).
r After observing B1, we update the probabilities:
– the new probability of A is P1(A) = P0(A|B1).
r After the next observation, B2, we update the probabilities again:
– the probability of A is now P2(A) = P1(A|B2) = P0(A|B1B2).
r This continues after new observations B3, B4, …

6.4 Next Observation and Update

Even though there is nothing wrong with the conditional probability notation
P(A|B1B2 … Bn), it is far neater and efficient to write Pn(A).
We illustrate this with Euler diagrams in Figure 6.7, and name our observa-
tions B, C, and D for visual clarity. Notice how A2’s proportion of the totality
changes as the totality itself changes upon new information.
Rule 6.4.1 Next observation: Given a (posterior) probability Pm, the prob-
ability that the next observation is C is
Pm(C) =
∑
j
Pm(AjC) =
∑
j
Pm(C|Aj) × Pm(Aj).
We recognize this as Rule 6.2.1 (total probability) applied to Pm. We find
Pm(C) as before, in the Sum cell in the table when we fill in Pm(Ak) in the first
column, and Pm(C|Ak) in the second.
Example 6.4.2 We continue Example 6.3.5 by looking at the probability that
Gamesmaster gets RRR, three reds, in the next three tosses.
Gamesmaster has previously tossed a die he picked at random, and he got W.
The exploration is continuing with the same, unknown, die. Let B be the event
“his first toss landed W”. Let further C be the event that his next three tosses
land RRR. We are going to find the probability of C. In Figure 6.8, we follow up
Figure 6.6 by showing the new event C = RRR.
Answer: We have already done the identification stage, so now we must quan-
tify the probabilities. We already know the likelihoods P(red|Ak) = 4
k , so
P(RRR|Ak) =
(4
k
)3
.
But what are the (prior) probabilities of the Ak? A common beginner’s mistake
is to employ P0(Ak) as the prior also at this stage. But an error? Why is it an
error? It is an error because we are then discarding the information and the
conclusion from the previous round. Let us see what goes wrong:
Wrong
Prior
Likelihood
Joint probability
k
P0(Ak)
P0(C|Ak)
4
1∕6
1
1∕6
6
1∕6
8∕27
4∕81
8
1∕6
1∕8
1∕48
10
1∕6
8∕125
4∕375
12
1∕6
1∕27
1∕162
20
1∕6
1∕125
1∕750
P0(C) ≈0.255 056
Wrong probability


6 Bayes’ Theorem
Ω
Ω corresponds to the infor-
mation and context at the
start of the investigation.
Ω
Ω
 A2
The basic context is Ω.
P0(A2) =P(A2 Ω)
B
New information corre-
sponds to a set B ⊂Ω. The
total information is now B.
B
B
 A2
The new context is B.
P1(A2) =P(A2 B)
B
C
The new information corre-
sponds to a set C. The total
information is now BC.
BC
BC
 A2
The new context is BC.
P2(A2) =P(A2 BC)
BC
D
The new information corre-
sponds to a set D. The total
information is now BCD.
BCD
BCD
 A2
The new context is BCD.
P3(A2) =P(A2 BCD)
Figure .Progression of updates illustrated with Euler diagrams.

6.4 Next Observation and Update

D
D
D
D
D
D
4
6
8
10
12
20
Figure .Observation
C = RRR, given B = white.
We see that we have a contribution from the D4, a die we already know is out
of the picture. The contribution in the joint probability column says that the
probability of “The die is the D4, and we will get RRR” is 1
6. But when D4 is out
of the picture, the probability of this event is not 1
6, but 0. So to get it right, we
need to bring with us the information from the previous round, which excludes
this die and alters the probabilities of the rest. We carry that information with
us by using the old posterior probabilities P1(Ak) = P0(Ak|B) as our new prior
probabilities for the new round.
Prior
Likelihood
Joint probability
k
P1(Ak)
P1(C|Ak)
P1(AkC)
4
0
0
0
6
10∕87
8∕27
0.034 057
8
5∕29
1∕8
0.021 551 7
10
6∕29
8∕125
0.013 241 4
12
20∕87
1∕27
0.008 514 26
20
8∕29
1∕125
0.002 206 9
0.079 571 3
So the right probability of getting RRR is P1(C) = P(C|B) = 0.079 571 3, and
not P0(C) = 0.255 056.
We now look at the posterior probability if Gamesmaster’s die actually land-
ing RRR.
Example 6.4.3 (Continuation of Example 6.4.2) Gamesmaster announces that
he has tossed the die three more times. He got RRR. What are the new and
updated probabilities of which die he picked? We expand the table from Exam-
ple 6.4.2 by a posterior column, and find:
Prior
Likelihood
Joint
Posterior
k
P1(Ak)
P1(C|Ak)
P1(AkC)
P2(Ak)
4
0
1
0
0
6
10∕87
8∕27
0.034 057
0.428 007
8
5∕29
1∕8
0.021 551 7
0.270 848
10
6∕29
8∕125
0.013 241 4
0.166 409
12
20∕87
1∕27
0.008 514 26
0.107 002
20
8∕29
1∕125
0.002 206 9
0.027 734 8
0.079 571 3


6 Bayes’ Theorem
4 6 8 10 12
20
0.20
0.10
(a) f1(k)
(prior probability)
4 6 8 10 12
20
0.25
0.50
0.75
1.00
(b) g1(k)
(likelihood).
4 6 8 1012
20
0.01
0.02
0.03
(c) f1(k) × g1(k)
(joint probability).
(d) f2(k)
(posterior probability).
4 6 8 10 12
20
0.40
0.30
0.20
0.10
Figure .Bayes’theorem with discrete functions.
We may also write the probabilities Pn(Ak) and Pn(Bn+1|Ak) as functions fn(k)
and gn(k) for more efficient notation when the number of alternatives is large,
and the values are reasonably easy to express by formulas. We will introduce
probabilities as functions in the next chapter, and will generalize Bayes’ theo-
rem to probability functions in Chapter 12. So we let this be a taster and an
illustration for now. fn and gn are discrete functions of the variable k, and we
plot the graph of functions in the example above in Figure 6.9.
We see clearly how f2(k) is a scaled version of f1(k) × g1(k).
Now, what would have happened if we had updated directly from P0 to P2
by gathering the observations in Examples 6.4.3 and 6.4.2 into one observation,
WRRR? The calculation is left as an exercise to the reader (Exercise 11), where
we find that the resulting posterior is identical to the posterior from the two-
step updating – as it should be. We capture this observation as the following
rule.
Rule 6.4.4
Assume we have an initial probability P0, and update it in n
steps, first applying Bayes’ theorem to observation B1 for the first update to
P1, and then to B2 to P2, … and so on all the way to Pn. If we update P0 in
one go, by applying Bayes’ theorem once, to the totality of the observations,
B = B1B2 … Bn, we get the same posterior probability Pn.
.
Updating, When the Probability of Bn+
Depends on B, … , Bn
In the example of Gamesmaster and the dice, the outcome of the first toss
of the die did not affect the probabilities of the subsequent tosses. This is an
example of a type of exploration where the probability of Bn+1 is indepen-
dent of the previous observations B1, … , Bn. This frequently corresponds to
sampling with replacement. The most common type of experiment where the

6.5 Updating, When the Probability of Bn+1 Depends on B1, … , Bn

probability of Bn+1 does depend on the previous observations B1, … , Bn corre-
sponds to sampling without replacement. We will look at an example.
Example 6.5.1 We have 3 urns containing 50 balls each. The first contains 40
red (R) and 10 yellow (Y) balls, the second contains 25 red and 25 yellow balls,
and the third and last contains 10 red and 40 yellow balls. We mix the urns,
and pick one at random, not knowing which of the three it is. By the symmetry
criterion, it is then equally probable that we picked any of them. We have 3
possibilities:
r A1: The urn we picked has 40 red and 10 yellow balls. f0(1) = P0(A1) = 1
3
r A2: The urn we picked has 25 red and 25 yellow balls. f0(2) = P0(A2) = 1
3
r A3: The urn we picked has 10 red and 40 yellow balls. f0(3) = P0(A3) = 1
3.
We then sample 5 balls from the urn, without replacing them. Our first obser-
vation, B1, is RYRRY. Common for all 3 urns is that N = 50 (total number of
balls in the urn). For each urn, we have Sk red balls, n = 5 sampled balls, and
s = 3 sampled reds. Then g(k) = P(B1|Ak) = (N−n
Sk−s
)∕(N
Sk
), giving us
r A1: S1 = 40, so g0(1) = P0(B1|A1) = (50−5
40−3)
(50
10) =
2 223
105 938
r A2: S2 = 25, so g0(2) = P0(B1|A2) = (50−5
25−3)
(50
25) =
75
2 303
r A3: S3 = 10, so g0(3) = P0(B1|A3) = (50−5
10−3)
(50
10) =
234
52 969.
Then,
k
Prior
Likelihood
Joint
Posterior
1
1∕3
2 223∕105 938
741∕105 938
741∕2 047 ≈0.361 993
2
1∕3
75∕2 303
25∕2 303
50∕89 ≈0.561 798
3
1∕3
234∕52 969
78∕52 969
156∕2 047 ≈0.076 209 1
∑= 89∕4 606
Figure 6.10 visualizes the table as functions. Again, we see that f1(k) is a scaled
version of f0(k) × g0(k). It always is.
Example 6.5.2
We sample more balls to get a closer estimate of which
urn we picked. Without replacement this time as well. This time, we get
B2 = RRYYYRYR. What are the new probabilities that we picked urns 1, 2,
and 3?


6 Bayes’ Theorem
0.1
0.2
0.3
1
2
3
(a) f0(k).
0.01
0.02
0.03
1
2
3
(b) g0(k).
1
2
3
0.01
(c) f0(k) ×g0(k).
0.1
0.3
0.5
1
2
3
(d) f1(k).
Figure .Visualized as functions.
Answer: The new prior probabilities equal the old posterior probabilities:
r f1(1) = P1(A1|B1) =
741
2 047
r f1(2) = P1(A2|B1) = 50
89
r f1(3) = P1(A3|B1) =
156
2 047.
The likelihoods:
r P(B2|A1): Here, N = 50, S = 40, …
Wait a minute! The urn no longer has 50 balls, since we removed 5 in the
first round. There are now N = 50 −5 = 45 left. The number of reds has
changed as well; diminished by 3. So the likelihoods are not simply P(C|A1),
that is, the probability of RRYYYRYR given A1 = “sampling from urn 1”, but
rather P(C|A1B1), that is, the probability of sampling RRYYYRYR given A1B1 =
“sampling from urn 1, where we removed 5 balls, whereof 3 were red”. So for
the correct likelihoods, N = 45, n = 8, and s = 4, and
r A1: S1 = 37, so g1(1) = P1(B2|A1) = P0(B2|A1B1) = (45−8
37−4)
(45
37) =
4 403
14 370 213
r A2: S2 = 22, so g1(2) = P1(B2|A2) = P0(B2|A2B1) = (45−8
22−4)
(45
22) =
1 771
412 542
r A3: S3 = 7, so g1(3) = P1(B2|A3) = P0(B2|A3B1) = (45−8
7−4 )
(45
7 ) =
259
1 512 654.
The fractions are getting large, so we switch to decimals. Then,
Prior
Likelihood
Joint
Posterior
1
0.361 993
0.000 306 398
0.000 110 914
0.043 740 9
2
0.561 798
0.004 292 9
0.002 411 74
0.951 113
3
0.076 209 1
0.000 171 222
0.000 013 048 7
0.005 145 99
∑= 0.002 535 7
Figure 6.11 visualizes the table as functions.

6.5 Updating, When the Probability of Bn+1 Depends on B1, … , Bn

0.1
0.3
0.5
1
2
3
(a) f1(k).
0.002
0.004
1
2
3
(b) g1(k).
0.001
0.002
1
2
3
(c) f1(k) × g1(k).
0.4
0.8
1
2
3
(d) f2(k).
Figure .Visualized as functions.
In Example 6.5.2 we updated the posterior probabilities from Example 6.5.1
by means of new data. Would we have gotten the same results if we instead had
updated with all the data at once? The answer is again yes, but let us first look
at the example, and then explain why.
Example 6.5.3 We are going to do a one-stop update of the same updating that
we did in two steps through Examples 6.5.1 and 6.5.2: The total observation is
B = B1B2 = RYRRYRRYYYRYR. This is a sampling without replacement, with
N = 50, n = 13, and s = 7, and
r A1: S1 = 40, so g(1) = P(B|A1) = (50−13
40−7 )
(50
40)
=
1 887
293 493 662 ≈6.429 × 10−6
r A2: S2 = 25, so g(2) = P(B|A2) = (50−13
25−7 )
(50
25)
=
6 325
45 242 106 ≈1.398 × 10−4
r A3: S3 = 10, so g(3) = P(B|A3) = (50−13
10−7 )
(50
10)
=
111
146 746 831 ≈7.564 × 10−7.
The table is then
k
Prior
Likelihood
Joint
Posterior
1
1∕3
6.429 × 10−6
2.143 × 10−6
0.043 740 9
2
1∕3
1.398 × 10−4
4.660 × 10−5
0.951 113
3
1∕3
7.564 × 10−7
2.521 × 10−7
0.005 145 99
4.900 × 10−5
We see that it’s the same posterior probability that we got after the second
step of the two-step updating.
So we have shown by example that it does not matter if you update all at
once, or in steps. The theoretical side is simple: just notice that f2 ∝f1g1 (where
∝means is proportional to), since f2 = f1g1∕S. In the same way, f1 ∝f0g0. This
means f2 ∝f0g0g1, corresponding to a direct update from f0 to f2, with g = g0g1
as the likelihood. In other words: the likelihood of the one-stop update equals
the product of the likelihoods of the many-step update. We show this, that g is


6 Bayes’ Theorem
the right likelihood for observation B = B1B2, by a little bit of formal manipu-
lation:
g(k) = g0(k)g1(k) = P(B1|Ak)P(B2|AkB1) = P(B1Ak)
P(Ak)
× P(B1AkB2)
P(AkB1)
= P(B1AkB2)
P(Ak)
= P(B1B2|Ak) = P(B|Ak).
.
Applied Examples
Both frequentists and Bayesians make use of Bayes’ theorem, and both do
so when they can construct a prior probability within the framework of
their theories of probability. There is a difference, however. For a Bayesian,
the prior reflects their state of knowledge, and may therefore in principle
always be found. The frequentist, on the other hand, must use some form of
empirical estimate of what an infinite sequence of experiments would have
yielded, and this may not always be obtained, or be obtained with sufficient
confidence.
How important is the prior? Some might say that it does not matter at all, and
that “observations are to speak for themselves”; they will employ the likelihood
to do the posterior’s job. So to answer this anti-prior sentiment, we will show an
example where the use of a prior makes all the difference, and justly so. (Notice
that this is an example that would cause no disagreement between Bayesians
and frequentists; it is not a matter of schools.)
Example 6.6.1 The cab accident: One night, a man was run down by a cab,
and the cab flew the crime. The town court, not knowing which precise driver
commited the crime, is now going to decide which taxi company is responsible.
The town has three taxi companies: Blue Taxi, Zebra, and EcoCab. The court
has summoned the only witness in the case, 89 year old Olga Johnson. Olga
swears under oath that the taxi was green. Zebra and Blue Taxi’s lawyers thank
Olga, and argue that the case is now closed, since the only taxi company in town
with green cabs is EcoCab. Blue Taxi’s cabs are blue, and Zebra’s have black and
white stripes.
But EcoCab’s lawyer asks the court to hear him out before passing judgement.
He has examined Olga and her ability to recognize colors and patterns in low
light conditions, and it turns out that
r 100% of the time, she sees green as green,
r 0% of the time, she sees zebra stripes as green,
r 20% of the time, she sees blue as green.

6.6 Applied Examples

Upon seeing this, the judge sends Zebra’s lawyer home. Blue Taxi’s lawyer
asks why he was not dispensed as well. For surely the company he represents
“is five times less likely to be the culprit than is EcoCab.”
So why should not EcoCab be judged to be the most likely offender?
It turns out that Blue Taxi is the big cab company in town, with 25 cabs,
whereas EcoCab has only 2. So if we were to pick a non-striped taxi at ran-
dom, the probabilities are P(blue) = 25∕27, whereas P(green) = 2∕27. These
numbers are the prior probabilities when we are going to calculate the prob-
abilities of which cab was responsible for the hit-and-run. We write this in a
table:
Prior
Likelihood
Joint
Posterior
Blue
25∕27
20%
5∕27
5∕7 ≈71%
Green
2∕27
100%
2∕27
2∕7 ≈29%
7∕27
The probability that the responsible taxi was an EcoCab is thus no more
than 29%.
What we saw in this example was that the underlying shares of the cab park,
in other words the prior probabilities, played a major role in determining the
final probability of guilt. The likelihood by itself seemed to point in one direc-
tion, but all facts were not on the table until the prior was accounted for, and
then the summing up of the knowledge from both prior and likelihood in the
posterior turned around the verdict that we had expected from the likelihood
alone.
The underlying proportion plays an important role in medical diagnosis as
well, and in that domain it is known as the base rate. The language used when
employing Bayes’ theorem in the diagnosis of disease is slightly different even
though it means the same. A table for diagnosing a disease in a population will
typically look like Table 6.1.
The numbers a, b, c, and d may be the numbers in each category after a major
survey, or they may be exact or estimated percentages of the population, where
a% + b% + c% + d% = 100%. Specificity is the share of the healthy who get
Table .Sensitivity–specificity table for medical diagnosis
Diseased
Healthy
Positive test
a
b
a + b
Negative test
c
d
c + d
Base rate
a+c
T
b+d
T
T = a + b + c + d
Sensitivity
a
a+c
d
b+d
Specificity


6 Bayes’ Theorem
a negative test result, whereas sensitivity is the share of the diseased who
get a positive test result.
So we have two concerns to balance: sensitivity is about the percentage of
the diseased whose disease is revealed by the test, and we naturally want as
many of those cases found as we can. But false diagnosis may also be a prob-
lem, and we want the share of healthy people who get a negative test result to
be as high as possible as well. This is specificity. While the ideal test is 100%
specific and 100% sensitive, a higher number in one tends to mean a lower
number in the other, so we have to do with less, and try to find the optimal
balance.
Example 6.6.2 (Continuation of Example 6.1.2) We lay out the numbers con-
cerning the test results in more detail. We will calculate the probability that
you have breast cancer if your mammogram came back positive, both by look-
ing at the sensitivity–specificity table, and by using Bayes’ theorem the way
we are used to using it. Let A = {has breast cancer} and B = {has positive
mammogram}. We are told that
r P(A) = 5‰ (so P(Ac) = 99.5%)
r P(B|A) = 80% and P(Bc|Ac) = 95%.
Sensitivity–specificity table: We fill in the information as percentages:
Diseased
Healthy
Positive test
a
b
a + b
Negative test
c
d
c + d
Base rate
a + c = 0.5%
99.5% = b + d
Sensitivity
a
a+c = 80%
95% =
d
b+d
Specificity
We resolve the values: a =
a
a+c ⋅(a + c) = 0.8 ⋅0.005 = 0.004, b = (a +
c) −a = 0.005 −0.004 = 0.001,
d =
d
b+d ⋅(b + d) = 0.95 ⋅0.995 = 0.945 25,
b = (b + d) −d = 0.995 −0.945 25 = 0.049 75, and enter them into the table:
Diseased
Healthy
Positive test
0.4%
4.975%
5.375%
Negative test
0.1%
94.525%
94.625%
Baserate
0.5%
99.5%
Sensitivity
80%
95%
Specificity

6.7 Bayesian Updating in the Long Run

Bayes’ theorem: We start from the information of a positive mammogram (B),
and know that P(B|A) = 0.8. We then find that P(B|Ac) = 1 −P(Bc|Ac) = 1 −
0.95 = 0.05. Further, P(A) = 0.005 and P(Ac) = 0.995, so the table for Bayes’
theorem becomes
Prior
Likelihood
Joint
Posterior
Diseased
0.005
0.8
0.004
≈7.4%
Healthy
0.995
0.05
0.049 75
≈92.6%
0.053 75
.
Bayesian Updating in the Long Run
We make two main uses of Bayes’ theorem:
r circling inwards in ever better guesses at the underlying alternatives;
r making predictions of future observations through increasingly improved
probabilities.
Sometimes, only the first point is of interest. In Example 6.6.2, we are only
interested in knowing if we have breast cancer or not. If we have a battery of
tests, we would like our probabilities to be as close to 0 or 100% as possible. We
are really not interested in the mammograms themselves, and finding the prob-
abilities of results of future mammograms tells us nothing more about whether
we have that cancer or not. The same is the case in Example 6.6.1, the cab acci-
dent: we want to establish responsibility for this accident, not predict how well
Olga will report the next accident she sees.
But at other times, the underlying alternatives are of mere transient interest,
as tools to make guesses about the future. This is the mindset of a gambler of
any stripe, be it at the casino or in more serious businesses like insurance or
military modelling. In the case of gambling, we are interested in the probability
of future results, for that is how we decide how to bet.
Let us have a closer look at what a multiply repeated updating by Bayes’ the-
orem would look like: both for the circling in on the alternatives, and for the
predictions of one or of multiple future observations. We continue the exam-
ple of Gamesmaster and his dice, as previously studied in Examples 6.2.3, 6.3.5,
6.4.2, and 6.4.3.
Example 6.7.1 Let us just change perspective for a moment. Instead of being
one of the players, we are now Gamesmaster. We picked a new die this time, and
since we have Gamesmaster’s privileged viewpoint, we know it is a D10. With
its 4 red and 6 white sides, P(R) = 0.4 and P(W) = 0.6, and the probability of a
given sequence S of k reds and l whites is P(S) = 0.4k0.6l.


6 Bayes’ Theorem
We toss the die … first 3 times, then 67 more for a total of 70, and then finally
we add enough tosses for a total of 500. The result of the first 3 tosses was RRW.
The result of the 70 first (including the first 3), is 31 red and 39 white. The score
for all the 500 tosses was a total of 193 red and 307 white.
So let us give this information to the players, who only get to know the results
but not the actual die, and watch their estimates. They will look at three things:
r the probability of the alternatives: which die we had picked (Pn(Dk));
r the probability of red (Pn(
)) and of white (Pn(
)) in the next toss;
r the probability of k red in the next five tosses (Pn(k red in five tosses)).
But let us start at the very beginning, in Figure 6.12, before we have made any
tosses at all, and the players only have the prior probabilities to go by.
(a) P0(Dk).
(b) P0.
0
1
2
3
4
5
(c) P0(k red in ﬁve tosses).
Figure .The prior probabilities.
Then we start, in Figure 6.13, and look at their estimates after a small number
of trials (the first three).
(a) P3(Dk).
(b) P3.
0
1
2
3
4
5
(c) P3(k red in ﬁve tosses).
Figure .The posterior probabilities after three trials.
Then we move on to a medium number of trials (70) in Figure 6.14.
Finally, we look at their estimates after many trials (all the 500) in Figure 6.15.
As a postscript, let us look at our own estimates in Figure 6.16, from our
privileged position as Gamesmaster; let us call our probabilities PG. Then
PG(D10) = 1, since we know we picked a D10.
We see that the players had converged pretty well on our privileged point of
view after 500 tosses, and have a very high probability that the right die is the

6.7 Bayesian Updating in the Long Run

(a) P70(Dk).
(b) P70.
0
1
2
3
4
5
(c) P70(k red in ﬁve tosses).
Figure .The posterior probabilities after 70 trials.
(a) P500(Dk).
(b) P500.
0
1
2
3
4
5
(c) P500(k red in ﬁve tosses).
Figure .The posterior probabilities after 500 trials.
(a) PG(Dk).
(b) PG.
0
1
2
3
4
5
(c) PG(k red in ﬁve tosses).
Figure .The probabilities from Gamesmaster’s perspective.
D10. Their probabilities for the different results are a very good match for ours
in both 1 and 5 tosses. A deeper result of the theory of probability tells us that
this was no odd statistical fluke, but rather what we should expect will happen
in the long run. With probability 1, the players’ Pn(D10) will tend to 1 as the
number of observations, n grows large, and the probabilities of the results of
the next tosses will converge to the probabilities of the privileged viewpoint of
we who know that it was the D10 that was picked.
Note 6.7.2 Keen students might be reading this book a second time, or they
have looked ahead at the graphs for the binomial probability distribution


6 Bayes’ Theorem
(“repeated sampling with replacement”) in Section 9.3. If so, they will probably
find the graph of Pn(k red in 5 tosses) for n = 0 or 3 a bit odd compared to
those of the binomial distribution. The graphs for the binomial distribution
have a pleasant dromedary shape, whereas the graphs we refer to here have
a rare rise at the far right end that can’t be explained through a binomial
distribution.
Maybe, these students may ask themselves, the graph should have followed
the distribution of repeated tosses of a single die whose probability of white is
p = P(red). That is, a “D4∕p” die. The short answer to that is no. The some-
what longer answer is to ask these students to calculate for themselves, in
Exercises 12–14, and see how the predictive probability is a weighted average of
the probabilities for the different dice, and that this is different from the results
of some “average die”.
We saw, in Examples 6.6.1 and 6.6.2, that the posterior probability depends
on the prior probability. Or the base rate, in medical diagnosis. We speak of this
as sensitivity to the prior. But at the other end of this sensitivity: what happens
when our data set is massive?
Example 6.7.3
We revisit Gamesmaster and the dice, but this time with a
non-uniform prior. Let P(D4) = P(D6) = 0.4, and P(Dk) = 0.05 for the rest.
For a realistic reason for such a skew prior, imagine a scenario where there
are far more D4 and D6 than any other type of die. We see the results in
Figure 6.17.
We see that the posterior is close to indistinguishable from the posterior in
Example 6.7.1. The tendency of the data to assert themselves over the prior
when they come in large numbers is something we speak of as the dominance
of the data. It means that in the long run, after many trials, the weight of the
information from the prior becomes insignificant compared to the weight of
the information from the gathered data.
(a) Prior P0(Dk).
(b) Posterior P500(Dk) after 500 tosses.
Figure .The long-term posterior (500 tosses) with different prior probabilities.

6.8 Exercises

Summary
(1) When we get new data B, this will change the probabilities of other events
and occurrences Ak, and we are able to calculate the new probabilities with
Bayes’ theorem.
(2) The probability before the event of the data B is called the prior, and we
write P0(Ak), or P(Ak|Ω), or simply P(Ak) if Ω is understood. The probablity
after the event of the data B is called the posterior and we write P(Ak|B) or
P1(Ak).
(3) Posterior probabilities are probabilities conditioned on the data B (and on
the initial context, Ω).
(4) The “reverse” probabilities, P(B|Ak) are called likelihoods, and are used in
the context of Bayes’ theorem to calculate posterior probabilities from prior
probabilities.
(5) Bayes’ formula and Bayes’ theorem are not exclusive to Bayesians, but are
also used by for instance frequentists, since these formulas may be used
whenever we have conditional probabilities.
(6) The difference between Bayesians and frequentists stems from their dif-
ferent concepts of probability. Expressed in terms of conditional probabili-
ties, the Bayesian look at both P(event|model) and P(model|event) as con-
ditional probabilities, whereas a frequentist will as a rule only accept the
former.
.
Exercises
1
Read the chapter.
(a) Why was EcoCab not found guilty in Example 6.6.1, even though the
eye witness stated that the offending taxi was green (EcoCab’s color)?
(b) Is it possible to use Bayes’ theorem when sampling without replace-
ment?
(c) As a follow-up to the previous question: “Yes, but … ?” – yes, but what
do we need to be careful to do?
(d) What is sensitivity?
(e) What is specificity?
(f) What happens to the probabilities of the alternatives under Bayes’ the-
orem in the long run, after many trials?
2
… the a-ha version: Your best friend is holding a black and a white marble,
and asks you to open your hands and close your eyes.
(a) He deposits one marble in each of your hands, and asks you to close
your hands before you open your eyes. What is the probability that the
marble in your right hand is black?
(b) He asks you to open your left hand, and there you see a black marble.
What is now the probability that the marble in your right hand is black?


6 Bayes’ Theorem
3
Just calculation: Do all of the exercises in a Bayes’ theorem table. Do in
addition try out at least one by using the formula directly, to see for yourself
that the two methods give the same result.
i.
Calculate P(B).
ii.
Calculate all posterior probabilities P(Ak|B).
(a) Prior: P(A1) = 1
2, P(A2) = 1
2
Likelihood: P(B|A1) = 0.7, P(B|A2) = 0.3
(b) Prior: P(A1) = 1
2, P(A2) = 1
2
Likelihood: P(B|A1) = 0.07, P(B|A2) = 0.03
(c) Prior: P(A1) = 1
3, P(A2) = 1
3, P(A3) = 1
3
Likelihood: P(B|A1) = 0.12, P(B|A2) = 0.87, P(B|A3) = 0.01
(d) Prior: P(A1) = 1
3, P(A2) = 1
3, P(A3) = 1
3
Likelihood:
P(B|A1) = 0.0012,
P(B|A2) = 0.0087,
P(B|A3) =
0.0001
(e) Prior: P(A1) = 0.3, P(A2) = 0.7
Likelihood: P(B|A1) = 0.001, P(B|A2) = 0.011
(f) Prior: P(A1) = 0.1, P(A2) = 0.9
Likelihood: P(B|A1) = 2
3, P(B|A2) = 3
11
(g) Prior: P(A1) = 1
11, P(A2) = 8
11, P(A3) = 2
11
Likelihood: P(B|A1) = 0.012, P(B|A2) = 0.001, P(B|A3) = 0.7
(h) Prior: P(A1) = 0.237 1, P(A2) = 0.455 4, P(A3) = 0.307 5
Likelihood: P(B|A1) = 0.8, P(B|A2) = 0.07, P(B|A3) = 0.2
(i) Prior: P(A1) = 0.07, P(A2) = 0.07, P(A3) = 0.07, P(A4) = 0.79
Likelihood:
P(B|A1) = 0.8,
P(B|A2) = 0.07,
P(B|A3) = 0.007,
P(B|A4) = 0.000 7
(j) Prior: P(A1) = 1
55, P(A2) = 2
55, P(A3) = 3
55, P(A4) = 4
55, P(A5) =
5
55, P(A6) = 6
55, P(A7) = 7
55, P(A8) = 8
55, P(A9) = 9
55, P(A10) = 10
55
Likelihood:
P(B|A1) = 0.1,
P(B|A2) = 0.2,
P(B|A3) = 0.3,
P(B|A4) = 0.4,
P(B|A5) = 0.5,
P(B|A6) = 0.6,
P(B|A7) = 0.7,
P(B|A8) = 0.8, P(B|A9) = 0.9, P(B|A10) = 1.0
(k) Prior: P(A1) = 1
55, P(A2) = 2
55, P(A3) = 3
55, P(A4) = 4
55, P(A5) =
5
55, P(A6) = 6
55, P(A7) = 7
55, P(A8) = 8
55, P(A9) = 9
55, P(A10) = 10
55
Likelihood:
P(B|A1) = 0.1,
P(B|A2) = 0.09,
P(B|A3) = 0.08,
P(B|A4) = 0.07, P(B|A5) = 0.06, P(B|A6) = 0.05, P(B|A7) = 0.04,
P(B|A8) = 0.03, P(B|A9) = 0.02, P(B|A10) = 0.01
(l) Prior: P(A1) = 1
55, P(A2) = 2
55, P(A3) = 3
55, P(A4) = 4
55, P(A5) =
5
55, P(A6) = 6
55, P(A7) = 7
55, P(A8) = 8
55, P(A9) = 9
55, P(A10) = 10
55
Likelihood:
P(B|A1) = 0.1,
P(B|A2) = 0.081,
P(B|A3) = 0.064,
P(B|A4) = 0.049, P(B|A5) = 0.036, P(B|A6) = 0.025, P(B|A7) =
0.016, P(B|A8) = 0.009, P(B|A9) = 0.004, P(B|A10) = 0.001

6.8 Exercises

(m) Create your own problems to solve and to share with your friends
for comparison, like the following.
i. Choose the number of alternatives n.
ii. Choose P(Ak) for all the n alternatives. Make sure that P(Ak) ≥
0 and ∑
k P(Ak) = 1.
iii. Choose likelihoods P(B|Ak) ∈[0, 1] (their sum does not need
to be 1).
4
You have 3 urns. In the first urn, there are 91 red and 34 blue balls. The
second contains 14 red and 25 blue balls, and the third has 40 red and
25 blue. You pick an urn that random.
(a) What are A1, A2, and A3?
(b) What are the prior probabilities P(A1), P(A2), and P(A3)?
(c) What are the probabilities P(R|Ak) of drawing a red ball from each urn,
and what are the probabilities of blue P(B|Ak)?
(d) You now sample balls from urn 30, with replacement. Your sequence
of results (we will call it S) had 20 red and 10 blue balls. Calculate the
likelihoods P(S|Ak).
(e) Calculate the posterior probabilities P(Ak|S).
(f) Your pocket contains two coins, and you pick one of them. Let A1 be
that you picked coin 1, and A2 that you picked coin 2.
i. What are P(A1) and P(A2) if none of the coins are preferred?
ii. Coin 1 is fair. What is P(H|A1) and P(T|A1)?
iii. Coin 2 is biased, with P(H|A2) = 0.407. What is P(T|A2)?
iv. (Bayes’ theorem) You flip the coin twice, and get tails both times.
Calculate P(TT|A1) and P(TT|A2).
v. Calculate the posterior probabilities P(A1|TT) and P(A2|TT) in a
table.
vi. You flip the coin 3 more times, and get HTH. Set up a new table,
using the posterior from the previous exercise as your new prior. Find
the new likelihoods, and calculate the new posterior probabilities.
5
Text exercises For each exercise:
(a) identify the alternatives Ak;
(b) identify the pivotal event B;
(c) calculate the prior probabilities P(Ak) and the likelihoods P(B|Ak);
(d) calculate the posterior probabilities P(Ak|B).
i. You have 6 dice, D1, D2, D3, D4, D5, and D6. A friend of yours picks
one of them at random. He tosses it, and gets 3. For each k, find the
probability that the die he picked was the Dk.
ii. Some students have a biased D20. For this die:
r the probability of an even number is 9
15;
r the probability that the outcome is in the top six is 4
5;


6 Bayes’ Theorem
r the conditional probability of an even number, given that the out-
come is in the top six, is 2
3.
If you know the die has landed on an even number, what is the prob-
ability that it is in the top six?
iii. The proud nation of Molvania has 2 weightlifting teams. On one
team (“the steroid team”), 70% use steroids, whereas on the other
team (“the clean team”), 10% use steroids.
r What is the probability that a randomly picked lifter uses
steroids? (The teams are equally large, so each lifter has the same
chance of being picked.)
r To decide which team to send to the Olympics, Molvania’s min-
ister of sports tosses a die, and the probability that he sends the
steroid team is 2
3. Now, we read in the newspaper that a Molva-
nian lifter was randomly picked for a steroid test during the
Olympics, and his test came back negative. Use this information
to update the probability that the steroid team was sent to the
Olympics.
iv. Genius Consulting are testing out 3 different statistics software bun-
dles: Freequen, Gnormal and Halfling. When they test the software
with a problem with 100 variables, Freequen crashes 10% of the
time, Gnormal crashes 20% of the time, and Halfling crashes 30%
of the time.
Sophie is one of Genius Consulting’s ten software testers. Six
testers are assigned to Freequen, three to Gnormal, and the last one
to Halfling. Sophie’s program crashes when she tests it with a 100-
variable problem. What is probability that Sophie was assigned to
Halfling?
6
A certain Mr. Claus has mixed up his Scandinavian gift bags this
Christmas, and he does not know which one goes to Denmark, which one
goes to Sweden, and which one goes to Norway. The Danish bag has 70%
soft gifts, the Norwegian one has 40%, whereas the Swedish bag has 20%.
Mr. Claus has now put one of the bags in his sleigh, and it’s your job as an
engineering elf to find the probabilities of which country it is from. You
sample 8 gifts, and by squeezing carefully, you determine that 4 of them
are soft.
(a) Identify the alternatives Ak.
(b) What are the values P(Ak)?
(c) Identify the pivotal event B.
(d) Calculate P(B|Ak). Note: the bags contain millions of gifts each, so
the difference between sampling with and without replacement is
negligible.
(e) Calculate the posterior probabilities P(Ak|B).
(f) Say in your own words what you just found out.

6.8 Exercises

(g) You sample 42 more gifts, to get a sharper guess before Mr. Claus takes
off. Seventeen of the gifts are soft. What are your new probabilities for
which bag is on the sleigh?
7
Sinterklaas Inc. make two kinds of advent calendar. Type A contains 8
pieces of marzipan and 16 pieces of chocolate. Type G contains 16 pieces
of marzipan and 8 pieces of chocolate. They make 3 times as many A cal-
endars as G calendars. You have bought one of their advent calendars, but
do not know which.
(a) What are the probabilities that you bought the respective calendars?
That is, what are P(A) and P(G)?
(b) On December 2nd you have opened 2 hatches, and you got 2 marzi-
pan. Use this to update the probabilities that you bought the respective
calendars.
(c) What is the probability that you will get marzipan in your calendar on
December 3rd?
8
It is rumoured that, every year, the Alaskan Easter Bunny brings all chil-
dren in his state an easter egg filled with 30 chocolates. The eggs are usu-
ally filled with 22 milk chocolates and 8 white chocolates, but this year the
Mr. Easter has hired some new bunny ladies in the chocolate kitchen, and
so this year there are three different types of egg:
r 10 000 eggs are like the classical ones described above;
r 4 000 eggs have milk chocolate only;
r 6 000 eggs have 15 of each kind.
Charlie Chocoholic wakes up when Mr. Easter arrives, so he tries to make
Charlie fall asleep by telling him about the bunny ladies and their new types
of egg. But then Charlie just has to check what kind of egg he just got.
Mr. Easter tells him he is allowed 5 chocolates, but no more; the rest must
wait until daybreak.
(a) What are your prior probabilities for the three egg types?
(b) Charlie picks 5 chocolates and eats: milk, milk, white, white, and milk.
What are the likelihoods for the 3 egg types?
(c) What are your updated, posterior probabilities for the three egg
types?
9
A confidential poll by the polling company Giddyup showed that in a cer-
tain area
r 1 in 4 lawyers belong to a secret society;
r 2 out of 3 lawyers who are members of secret societies had lied to protect
a client, whereas:
r half of all lawyers in general had lied to protect a client.
Which proportion of the lawyers who had lied to protect a client are also
members of some secret society?


6 Bayes’ Theorem
10
Assorted candies II: You have 4 bags of mixed candies on the table. They
are leftovers from a party, so naturally there are only Almond Joys (A) and
Twizzlers (T) left. The contents are as follows:
r bag 1: 5 Almond Joys and 3 Twizzlers
r bag 2: 7 Almond Joys and 8 Twizzlers
r bag 3: 2 Almond Joys and 9 Twizzlers
r bag 4: 11 Almond Joys and 13 Twizzlers.
a. A bit tired from tidying up, you zone out and pick a bag at random.
You start picking out candies, looking at them, then returning them
to their bag. You repeat this 7 times, and observe ATTATAA.
i. What are the (prior) probabilities that you had picked the differ-
ent bags?
ii. What is the probability of your observation, given the different
bags.
iii. Now find the posterior probabilities for the bags.
b. You pick three more pieces and return them, this time getting
LKL. Update the probabilities for the bags on the basis of this new
information.
c. A bit later you put the bag back, and you are joined by your brother.
Like you, he picks a bag at random, and then he picks out a few pieces.
But unlike to you, he eats them. He eats TTA. Find, for each of the
bags, the updated probability that it was picked by your brother.
11
Calculate the posterior probabilities for the dice in Examples 6.4.3 and 6.4.2
when you collect all the observations into one big observation for your one
update, i.e. WRRR. Compare your one-step updated probability – let’s call
it P′
1 – to P2 from Example 6.4.3. What do you see?
12
You have two D6 dice. Die 1 is all white, whereas die 2 is all black. Games-
master picks one of them. Let Ak be that he picked die k.
(a) What are the prior probabilities P0(A1) and P0(A2)?
(b) What is the probability that his first toss lands white, p = P(white)?
(c) What is the probability that his tosses of the die are white first, then
black?
(d) Let die 3 be “the average die” between the all-white die 1 and the all-
black die 2, that is, a die with 3 white sides and 3 black. What is p =
P(W) for this die, and what is P(WB)?
(e) Is repeated tosses with die 3 equivalent to randomly picking either die
1 or die 2, and then tossing the picked die repeatedly?
13
Details for Example 6.7.1. You got RRW.
(a) Calculate the posterior probabilities P1 for each of the dice.
(b) Find p = P1(R), the probability that the next observation is R.

6.8 Exercises

(c) If you have sampling with replacement, where the alternatives are
red (R) and white (W), and p = P1(red) from the above, what is then
P(RRRRR)?
(d) Find p = P1(RRRRR), the probability that the next five observations are
RRRRR.
(e) Why are the probabilities in the two die questions different?
14
[Use a decent tool for calculating] You are selling a car brand that has 2 fac-
tories. The factories’ output is equal. Lately, 2.5% of the cars from Factory
A have had problems with their brakes, whereas only 0.5% of the cars from
Factory B have had such problems. The manufacturer never reveals which
factory has produced which cars, and you now have a big new shipment of
cars from one of these factories, but you don’t know which. You test 150 of
these cars, and find brake problems in only one of them.
(a) What is the prior probability that the shipment is from Factory B?
(b) What is the posterior probability that the shipment is from Factory B?
(c) What is the probability p that there is a problem with the brakes of the
next car?
(d) What is the probability that there is a problem with the brakes of 50 or
more of the next 3000 cars?
(e) What error could you have committed in the previous calculation?




Stochastic Variables on ℝ
CONTENTS
7.1
Real Stochastic Variables, 137
7.2
Discrete Probability Distributions on ℝ, 141
7.3
Continuous Probability Distributions on ℝ, 147
7.4
Percentile and Inverse Cumulative Distribution, 155
7.5
Expected Value, 160
7.6
Variance, Standard Deviation, and Precision, 164
7.7
Exercises, 167
In Chapter 2, we mentioned that the values of a stock on a historical chart are
data about that stock, whereas the projected (and unknown) future values are
stochastic variables.
Norges Bank’s key policy rate is the Norwegian central bank’s equivalent of
the US Federal funds rate. In Figure 7.1, we see their data and their projections
from 2008, a very interesting year. In the figure, they use color coding to indicate
how likely it is that the interest rate ends up within such and such bounds at a
given date. The policy rate for January 2009, for instance, was in October 2008
a stochastic variable with a 15% probability of being below 4.75, and a 70%
probability of being between 4.75 and 7.00.
.
Real Stochastic Variables
How do we indicate a magnitude we don’t know the value of? The simple answer
is: as probabilities of being so and so large. And this is also the complex answer.
But precisely how do we implement this, mathematically? To implement these
probabilities, we start out with a set Ω. The set Ω may be something as simple
as the set of possible values, but we get a much more generally useful theory if
we allow Ω to be uncoupled from the specific values, just the way in a car we
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


7 Stochastic Variables on ℝ
2006
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
3096
5096
7096
9096
2007
2008
2009
2010
2011
Figure .Key policy rate; the future in blue. Source: Norges Bank 2008.
uncouple the engine and the wheels, leaving us with the option of reconnecting
them through a transmission system with gears and all kinds of controls.
So we start out with a for now unspecified set Ω, and will explore possible
specifications below. The minimum requirement is that this set must contain
subsets A ⊂Ω and a probability function P allowing us to find probabilities
P(A). We will further require Ω to be at least large enough that we can map it
onto the possible values of the magnitude we want to study. And it is this map
that is our first concern. We call it a stochastic variable.
Definition 7.1.1
A real stochastic variable is a function X : Ω →ℝ. The
probability P on Ω then becomes a probability on the possible values of X in
the following way: for an interval I = (a, b), let C ⊂Ω be the set of elements
for which X has values in I. Then
P({𝜔| X(𝜔) ∈I}) = P(C).
For the rest of the book, we will use the shorthand P(X ∈I) for this probability.
This may look a bit “mathematically complicated” at first glance, so let us
make Ω and X concrete through a few examples.
Example 7.1.2
Let Ω be all the fish in the salmon fishing river Loppa; that
is: each 𝜔is a particular fish. X(𝜔) is the weight of fish 𝜔, and P(X ∈(2, 3)) is
the probability that a randomly sampled fish in Loppa weights between 2 and
3 kg.

7.1 Real Stochastic Variables

This simple image is really all you need. Many fish – many individual 𝜔–
may have the same weight value, but every possibly sampleable weight has at
least one fish whose weight is of that particular value. But as you may already
have guessed, we will often do well to let Ω be a much larger set than even
the possible weighable candidates – even all the way up to an infinitely large
set, even though our entire population may be a rather small and finite set.
This applies in particular to unknown magnitudes, where we really do not have
much knowledge to go on. Indeed, even the fish in the example above would be
best studied with an infinite Ω, as in the following example.
Example 7.1.3 Let Ω be all the fish in the river Loppa, at a specified time t this
month. That is, each 𝜔is a given fish at a given time. X(𝜔) is then the weight of
that fish at that given time, and P(X ∈(2, 3)) is the probability that a salmon in
Loppa, randomly sampled at a random time, weighs between 2 and 3 kg.
And this is just how it begins ...
When we proceed to processes of not just one sample but many, in the course
of doing inference, the set Ω needs to take into consideration these factors as
well, and the description becomes a bit more complex.
Example 7.1.4 In Example 6.7.1, we update probabilities. Here, each 𝜔is not
just which die was possibly picked, but also each possible infinite sequence of
test results from the die tosses we did or could have performed in order to
determine the probabilities for each die. So, for instance, a single 𝜔could be
𝜔= “D8, WRRW …”.
This also highlights another useful reason for employing a large Ω rather
than just the possibilities we want to know the probability of: on a sin-
gle Ω we may have many different stochastic variables. We do have the
X, which is simply X = “which k is our Dk”. But we also have others, like
Y = “the number of R in the next five tosses”, or Z = “the number of tries
before our first successive 10 Rs in a row”.
This Ω also illustrates conditional probability, as follows.
r PD4(R) = P(R|D4) is the probability of R (red) given that we had picked a D4.
For this conditional probability we restrict our attention to the 𝜔∈Ω begin-
ning in D4, and look at the relative probability of having R first in the sequence
of tosses.
r PRWR(D12) is the probability that we had picked D12 given that the first three
tosses yielded RWR. For this conditional probability we restrict our atten-
tion to the 𝜔∈Ω whose tossing sequence start RWR, and look at the relative
probability of starting D4.
r Some of the most important probabilities stem from updating probabilities
by Bayes’ theorem; that is, P0, P1, P2, etc.


7 Stochastic Variables on ℝ
We are still talking about the same stochastic variable X, but this time as
conditioned, since we are now looking at its action on a subset of Ω.
But once it is introduced and explained, most of us can leave Ω behind, and
concentrate on the properties of the stochastic variables, like X. If you need to
think about Ω and are not a theoretical statistician or mathematician, just think
“salmon in Loppa”, and you will have all that you need. Notation-wise, we will
forget the little 𝜔as well, and simply write X instead of X(𝜔).
The key property of X is the probability of its values, which is where our
investigation started out. We usually indicate these probabilities by the cumu-
lative probability distribution. All stochastic variables X have one, and we write
FX(x) = P(X ≤x).
Definition 7.1.5 F is a cumulative probability distribution for X iff
r when x < y, then F(x) ≤F(y);
r F(−∞) = 0 and F(∞) = 1;
r F(x) = P(X ≤x).
We will look at three types of stochastic variables on ℝ: discrete, contin-
uous, and mixed, the latter in Chapter 8.2. Figure 7.2 shows us the three
types.
Purely discrete and purely continuous stochastic variables are each charac-
terized by their type of probability distribution f (x). We will investigate these in
the coming sections. Not all stochastic variables have a probability distribution
even though they all have a cumulative probability distribution F(x). We will
look at mixed stochastic variables, which are among those that do not have a
probability distribution function, in Chapter 8.2. But first, we discuss the two
types of stochastic variable that are recognized by their specific type of proba-
bility distribution.
f(x)
F(x)
1
1
1
Discrete
Continuous
Mixed
Figure .The three different types of stochastic variables we will be looking at.

7.2 Discrete Probability Distributions on ℝ

.
Discrete Probability Distributions on ℝ
Just as we made tables and diagrams of proportions for data, we can make tables
and diagrams of probabilities for stochastic variables. The table and diagram
are ways of specifying a discrete function f by connecting the argument (out-
come) x to the function’s value (probability) f (x). A stochastic variable whose
probabilities we may specify by a discrete function is called a discrete stochastic
variable. We define this formally as follows.
Definition 7.2.1 A function f on a finite or countable set U (“sample space”)
is a discrete probability distribution for X if
(1) f (x) ≥0 for all x ∈U;
(2)
∑
x∈U
f (x) = 1;
(3) f (x) = P(X = x) for all x ∈U.
We write X ∼f , which we read as “X has probability distribution f ”. We will
also find it useful to speak of the point probability px = f (x).
Example 7.2.2
You have found five old radio tubes at the storage at your
new job, and have been told that there is a 50% probability that a given tube
functions. Let the stochastic variable X be the number of functioning tubes
among the ones you have found. We consider each tube to be an indepen-
dent trial, so we calculate the probabilities for X by means of the formula for
unordered sampling with replacement. The parameters are p = 0.5 and n = 5,
so f (k) = P(X = k) =
(
5
k
)
0.55. We then have that X ∼f , and we specify the
values of f in a probability table, and then plot the graph of the discrete func-
tion f . We do this in Figure 7.3.
Outcome k
f (k)
0
0.03125
1
0.15625
2
0.3125
3
0.3125
4
0.15625
5
0.03125
SUM
1
0
1
2
.05
.10
.15
.20
.25
.30
3
5
4
Figure .This is a binomial distribution. More about binomial distributions in Section 9.3.


7 Stochastic Variables on ℝ
Table .The skippings with their probabilities
x ∈U
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
f (x) = px
0.11
0.03
0.18
0.21
0.16
0.01
0.08
0.19
0.03
Rule 7.2.3 If X has a discrete probability distribution f , we find the proba-
bility that X ∈A by summing the point probabilities of the elements in A:
P(X ∈A) =
∑
x∈A
px =
∑
x∈A
f (x).
Example 7.2.4
You have an old milling machine that is stepwise adjustable
in tenths of a millimeter. It has become a bit loose, so it sometimes skips to a
different step, closer to you or away from you. Let the stochastic variable X be
how many millimeters it has skipped away from you. Your colleague in charge
of the milling machine tells you that, by long and careful observation, they have
arrived at the probabilities of the different values of X shown in Table 7.1 and
Figure 7.4.
1) Show that f is a discrete probability distribution.
2) A = {−0.2, 0, 0.2, 0.3}. What is P(X ∈A)? (See Figure 7.5.)
3) What is P(X < 0)? (See Figure 7.6.)
-0.2
-0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Figure .The graph of the
skipping probabilities.
−0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
A
Figure .The set A.
−0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
X<0
Figure .The set of x where x < 0.

7.2 Discrete Probability Distributions on ℝ

−0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Figure .P(X ∈A) = ∑
x∈A px =
0.11 + 0.18 + 0.16 + 0.01 = 0.46.
Answer:
(1) We check the criteria from Definition 7.2.1:
(a) is f (x) ≥0 for all x ∈U? Yes;
(b) does ∑
x∈U f (x) = ∑
x∈U px = 1.
Both criteria hold, so f is a discrete probability distribution.
(2) We see the answer in Figure 7.7.
(3) We see the answer in Figure 7.8.
−0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Figure .P(X < 0) =
p−0.2 + p−0.1 = 0.11 + 0.03 = 0.14.
The sample space U does not need to be a finite set. It may also be infinite,
as long as you can enumerate the possible values: first value, second value,
third…and by that cover all the values. Not all sets are countable; it is, for
instance, impossible to enumerate the elements of [0, 1].
Example 7.2.5 You return to the tubes, but this time you find yourself in tube
heaven! The five tubes in Example 7.2.2 came from a storage that held thou-
sands of tubes! You decide to test tubes until you have found a functioning one.
The probability that a given tube functions is still 1
2 for each individual tube. Let
X be the number of tubes you test before finding finally one that works. Include
only the non-functioning tubes. Then
X ∼f (n) =
1
2n+1 .
(1) What is the sample space U?
(2) Show that f is a discrete probability distribution.
(3) A = {1, 4, 5}. What is P(X ∈A)?
(4) What is P(X > 2)?


7 Stochastic Variables on ℝ
0
1
2
3
4
5
6
7
8
X≥3
Figure .P(X > 2) = P(X ≥3)
= ∑∞
n=3
(
1
2
)n+1
= 1
8.
0
1
2
3
4
5
6
7
8
X>2
X≤2
Figure .P(X > 2) = 1 −P(X ≤2)
= 1 −
(∑2
n=1
(
1
2
)n+1)
= 1
8.
Answer: We notice that f (n) =
(
1
2
)n+1
, so we may employ the formula for
geometric series in Appendix A.2.
(1) We may find the functioning tube after having gone through 0, 1, 2, ... non-
functioning tubes, so U = {0, 1, 2, …} = ℕ0.
(2) We check the two criteria:
(a) is f (n) ≥0 for all n ∈U? Yes, since f (n) =
1
2n+1 > 0 for all n ∈ℕ0;
(b) ∑∞
n=0 f (n) = ∑∞
n=0
(
1
2
)n+1
= ∑∞
n=0
1
2 ⋅
(
1
2
)n
= 1
2 ⋅
1
1−1
2
= 1.
Both criteria hold, so f is a discrete probability distribution.
(3) P(X ∈A) = p1 + p4 + p5 = 1
22 + 1
25 + 1
26 = 19
64.
(4) We may solve this in two ways. We show by both direct calculation
(Figure 7.9) and by complementary probability (Figure 7.10).
Notice that since the values are discrete, X > 2 is the same as X ≥3, whereas
the complimentary event X ≤2 may be written X < 3. The neighboring sets
X ≤2 and X > 2 do, despite being immediate neighbors, have a gap of one unit
between them.
This is a geometric distribution. More about these in Section 9.5.
..
Cumulative Discrete Distribution
We will now revisit the cumulative probability distribution, but now from the
perspective of already having a discrete probability distribution function. We
will in other words look at the relation between cumulative probability and dis-
crete probability distributions.

7.2 Discrete Probability Distributions on ℝ

0
1
2
3
5
4
.10
.20
.30
0
1
2
3
5
4
.25
.50
1
.75
F(3)
Figure .We read from the cumulative graph that F(3) = 0.8125.
Rule 7.2.6 If X ∼f , that is if X is a discrete stochastic variable with proba-
bility distribution f (k) = P(X = k), then the cumulative distribution is given
by
F(k) = P(X ≤k) =
∑
j≤k
f (j).
Example 7.2.7 (Continuation of Example 7.2.2) X is the number of function-
ing tubes when you have 5 tubes that each have a 50% probability of working.
What is the probability that 3 or fewer are functioning? We solve the problem
graphically in Figure 7.11, and numerically in Table 7.2.
Table .The probability that fewer or fewer tubes work, is F(3) = 0.8125
cumulative
Outcome
probability
probability
k
f(k)
F(k) =
∑
j≤k
f(j)
0
4
3
2
1
0
0.03125
= 0.03125
1
0.15625
+0.03125
= 0.18750
2
0.31250
+0.18750
= 0.50000
3
0.31250
+0.50000
= 0.81250
4
0.15625
+0.81250
= 0.96875
5
0.03125
+0.96875
= 1.00000


7 Stochastic Variables on ℝ
Example 7.2.8 We continue Example 7.2.4 of the loose milling machine.
(1) Find the cumulative distribution F.
(2) What is the probability that is skips less than 0.2 mm away from you?
(3) Use F to find the probability that it skips more than 0 but no more than
0.4 mm away from you.
Answer:
(1) We may calculate individual values by the summing formula, like for
instance
F(0.1) =
∑
x≤0.1
f (x) = f (−0.2) + f (−0.1) + f (0) + f (0.1) = 0.53.
or we can do one better by extending the probability table by an extra row
for F, like in Example 7.2.7, by remembering that for discrete distributions,
F(x) equals the previous F value plus f (x). We do this in Table 7.3.
(2) This is P(X < 0.2) = P(X ≤0.1) = F(0.1) = 0.53
(3) This is P(0 < X ≤0.4) = F(0.4) −F(0) = 0.78 −0.32 = 0.46
Since F(x) = P(X ≤x), we may find the probability that X is in the interval
⟨a, b] like this:
P(X ∈⟨a, b]) = F(b) −F(a)
Example 7.2.9 We continue Example 7.2.5, where we found that X ∼f (n) =
1
2n+1 for n ∈ℕ0
(1) Find the cumulative probability distribution F.
(2) Use F to find the probability that you must go through 3 non-working tubes
before you find one that works.
Answer:
(1) The cumulative probability distribution is
F(n) =
∑
k≤n
f (k) =
n
∑
k=0
1
2k+1 =
n
∑
k=0
1
2 ⋅
(1
2
)k
= 1
2 ⋅1 −(1∕2)n+1
1 −1∕2
= 1 −(1∕2)n+1
(2) This is P(X > 3) = 1 −P(X ≤3) = 1 −F(3) = 1 −(1 −(1∕2)3+1) = 1∕16
Table .Cumulative probability distribution for the skipping of the milling machine
x
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
f (x)
0.11
0.03
0.18
0.21
0.16
0.01
0.08
0.19
0.03
F(x)
0.11
0.14
0.32
0.53
0.69
0.7
0.78
0.97
1

7.3 Continuous Probability Distributions on ℝ

Table .The original probabilities of the balls
x
1
3
4
7
9
Two-digit ball
probabilities
0.13
0.04
0.21
0.14
0.12
0.36
Table .The conditional probabilities of the single-digit balls
x
1
3
4
7
9
Probabilities
0.203 125
0.062 5
0.328 125
0.218 75
0.187 5
Example 7.2.10
We have an urn with enumerated balls. But someone has
removed the two-digit balls, and only those. The probabilities for each type
of ball before the two-digit balls were removed are given in Table 7.4. Find
the new probabilities for the remaining balls.
Answer: This is a conditional probability, conditioned on the alternative
“single-digit ball”, which has a total of P(single-digit ball) = 0.64, so we divide
the stated probabilities by the probability of the total, 0.64, and get the condi-
tional probabilities, in Table 7.5.
.
Continuous Probability Distributions on ℝ
For a continuous stochastic variable, single values have probability zero. Posi-
tive probabilities are reserved for sets of positive extension. Variables that are
able to take any value in an interval are typically continuous, whereas variables
that are limited to a finite set of values are discrete. Our possible measurement
values of the height of a human being are discrete. Most of the time, we measure
in centimeters: 181, 182, 183 cm, etc., but sometimes we refine it to millimeters.
But typically, we will have a limit to our accuracy. The height itself, on the other
hand, is a continuous variable capable of taking any value within the cm or mm
intervals. The probability that we measure a person to be 182 cm is positive,
whereas the probability that he is 182.000 … cm is zero.
We will look at an example before formally defining continuous stochastic
variables.
Example 7.3.1
Let X be the point on your right front tire pointing straight
down right now. What is the probability that X is in any of the following areas.
(1) A: from 10 to 130◦counterclockwise from the valve?
(2) B: from 220 to 240◦counterclockwise from the valve?
(3) C: precisely at 300◦counterclockwise from the valve?
Answer: We calculate the probability on the assumption that it is spread uni-
formly over the circumference of the tire, meaning that the probability of it


7 Stochastic Variables on ℝ
P(X ∈A)
=
130° −10°
360°
= 1
3
P(X ∈B)
=
240° −220°
360°
= 1
18
P(X ∈C)
=
300° −300°
360°
= 0
50
100 150 200 250 300 350
0.2
0.4
0.6
0.8
1.0
A
B
C
Figure .Probabilities of hitting certain segments of a tire.
being in a given segment equals that segment’s proportion of the circumfer-
ence. See Figure 7.12 for the illustrated calculations.
The continuous stochastic variable X above assigns positive probability to
intervals, whereas its point probabilities all are zero.
Definition 7.3.2 The function f on the interval (A, B) is a continuous prob-
ability distribution for X if
(1) f (x) ≥0;
(2) ∫B
A f (x) dx = 1;
(3) P(a < X < b) = ∫b
a f (x) dx.
If this holds, X is furthermore a continuous stochastic variable. We write
X ∼f , and read that “X has probability distribution f .”
Probability in the continuous case is not like in the discrete case given by the
sum of probabilities for individual outcomes, with a discrete graph of point
probabilities. In the continuous case, probability is rather given as the area
under the graph of a function F defined on an entire interval, in other words the
integral of f . The continuous probability distribution f is often called a proba-
bility density.
Note that P(X ∈⟨a, b⟩) = P(X ∈[a, b]), since the probability of X taking an
endpoint value is zero. Indeed, any finite collection of points has probability
zero for a continuous stochastic variable. Working with continuous distribu-
tions, we may then without any loss write our intervals (a, b), leaving it inde-
terminate whether the endpoints are included or not. For discrete and mixed
distributions, though, (end)points may have positive probability, and thus we
need to include them.
Example 7.3.3 X ∼f , where
f (x) =
{
2x
0 ≤x ≤1
0
otherwise.

7.3 Continuous Probability Distributions on ℝ

0.0
0.1
0.2
0.3
0.4
0.5
0.6
A
0.7
0.8
0.9
1.0
Figure .A is the union of
two intervals.
(1) Show that X is a continuous stochastic variable.
(2) A = (0.1, 0.2) ∪(0.7, 0.9). What is P(X ∈A)? (see Figure 7.13).
Answer:
(1) We check the criteria:
(a) f (x) ≥0 for all x;
(b) ∫∞
−∞f (x) dx = ∫1
0 2x dx = 1.
which means that f is a continuous probability distribution.
(2) We calculate by dividing into intervals, integrating over each of them, and
then summing. The total is the sum of the areas under the graph in the
intervals, as illustrated in Figure 7.14.
P(X ∈A) = P(X ∈(0.1, 0.2) ∪(0.7, 0.9))
= P(X ∈(0.1, 0.2)) + P(X ∈(0.7, 0.9))
= ∫
0.2
0.1
2x dx + ∫
0.9
0.7
2x dx = 0.35.
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
2.0
Figure .The probabilities of hitting A, which means hitting any of the two intervals.


7 Stochastic Variables on ℝ
1
2
3
4
0.1
0.2
0.3
(a) Less than 1 min late.
1
2
3
4
0.1
0.2
0.3
(b) More than 4 min late.
Figure .Lecturer N’s delay in Example 7.3.4.
Example 7.3.4
Lecturer N always comes late for lectures after lunch, but
he is never more than five minutes late. The delay is a continuous stochas-
tic variable X with probability density f (t) = 12
625t(5 −t)2 in the interval [0, 5].
(Figure 7.15.)
(a) What is the probability that N is less than 1 minute late? (Figure 7.15a.)
(b) What is the probability that N is 4 or more minutes late? (Figure 7.15b.)
Answer:
(a) P(X ≤1) = ∫1
0 f (t) dt = ∫1
0
12
625t(5 −t)2 dt ≈0.18.
(b) We may solve this in two ways. We show by both direct calculation
(Figure 7.16) and by complementary probability (Figure 7.17).
Notice that since these values are continuous, then P(X > 4) is the same
as P(X ≥4), whereas the complimentary probability P(X ≤4) may be written
P(X < 4). The neighbors X < 4 and X > 4 are flush with one another; the gap
between them is 0 units wide.
0
1
2
3
X≥4
4
5
Figure .P(X > 4) =
P(X ≥4) = ∫5
4 f(t) dt =
∫5
4
12
625t(5 −t)2 dt ≈0.02.
0
1
2
3
X>4
4
5
X≤4
Figure .P(X > 4) =
1 −P(X ≤4) =
1 −∫4
0
12
625t(5 −t)2 dt ≈0.02.

7.3 Continuous Probability Distributions on ℝ

−10
−5
5
10
0.05
0.10
0.15
0.20
0.25
0.30
Figure .P(|X| < 3).
Continuous distributions may be limited to an interval, or they may span over
all real numbers from minus to plus infinity, like the following distributions.
Example 7.3.5 X ∼f (x) = 1∕𝜋
1+x2 . What is the probability that |X| < 3? (See Fig-
ure 7.18.)
Answer: P(|X| < 3) = ∫3
−3
1∕𝜋
1+x2 dx =
[
1
𝜋⋅tan−1(x)
]3
−3 ≈0.795.
Example 7.3.6 The height of waves right outside Bolgevik harbor, measured in
meters, is Z ∼f (z) = 2ze−z2. What is the probability that a given wave exceeds
2 m in height? (See Figure 7.19.)
1
2
3
4
5
6
0.2
0.4
0.6
0.8
Figure .P(Z > 2).


7 Stochastic Variables on ℝ
Answer:
P(Z ≤2) = ∫
2
0
2ze−z2 dz (we substitute u = z2, so du
dz = 2z)
= ∫
z=2
z=0
du
dz e−u dz = ∫
z=2
z=0
e−u du
= [−e−u]z=2
z=0 =
[
−e−z2]2
0
= −e−22 −(−e−02) = 1 −e−4
P(Z > 2) = 1 −P(Z ≤2) = e−4 ≈0.018 3.
−6
−4
−2
0
2
4
6
0.2
Figure .P(−7 ≤X ≤0).
Example 7.3.7
(Numerical example using a piecewise defined distribution
function)
X ∼f (x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪⎩
x+5
12
x ∈[−5, −3)
1
6
x ∈[−3, 1)
−x+3
12
x ∈[1, 3)
0
otherwise.
Find P(−7 ≤X ≤0). (See Figure 7.20.)
Answer:
P(−7≤X ≤0) = ∫0
−7 f (x) dx = ∫−5
−7 f (x) dx + ∫−3
−5 f (x) dx + ∫0
−3 f (x) dx
= ∫−5
−7 0 dx + ∫−3
−5
x+5
12 dx + ∫0
−3
1
6 dx = 0 + 1
6 + 1
2 = 2
3.
..
Cumulative Continuous Distribution
For a continuous stochastic variable, the link between the probability distri-
bution and the cumulative distribution is one of the fundamental theorems of
calculus – see the following definition.

7.3 Continuous Probability Distributions on ℝ

1
2
3
4
0.1
0.2
0.3
(a) P(X ≤3) = ∫
3
0 f(t)dt.
1
2
3
4
0.2
0.4
0.6
0.8
1
(b) P(X ≤3) = F(3).
Figure .The two ways of finding P(X ≤3) are essentially the same.
Definition 7.3.8 If X ∼f , that is, if X is a continuous stochastic variable on
(A, B) with probability distribution f , the cumulative probability distribution
is given by
F(x) = P(X ≤x) = ∫
x
A
f (t) dt.
Conversely,
f (x) = F′(x).
Example 7.3.9 We continue Example 7.3.4, where the probability density of
lecturer N’s delay is given by f (t) = 12
625t(5 −t)2. Sonia is 3 minutes late for the
lecture, and as she enters the lecture hall she wonders what the probability is
that N has arrived.
Answer: Graphically, see Figure 7.21. The calculations go like this:
F(t) = ∫
t
0
f (x) dx = ∫
t
0
12
625x(5 −x)2 dx =
1
625(150t2 −40t3 + 3t4)
P(X ≤3) = F(3) = ∫
3
0
f (t) dt =
1
625(150 × 32 −40 × 33 + 3 × 34) ≈0.82.
Example 7.3.10 (Continuation of Example 7.3.5) X ∼f (x) = 1∕𝜋
1+x2 .
(1) What is F(x)?
(2) Use F to find P(|X| < 3).
We see this illustrated in Figure 7.22.


7 Stochastic Variables on ℝ
-10
−5
5
10
0.05
0.10
0.15
0.20
0.25
0.30
(a) P
X < 3) = ∫
3
−3 f
10
5
5
10
0.2
0.4
0.6
0.8
F(-3)
F(3)
(b) P
X < 3) = F(3) −F(−3).
(t) dt.
Figure .The two ways of finding P(|X| < 3) are essentially the same.
Answer:
(1) F(x) = ∫
x
−∞
1∕𝜋
1 + t2 dt =
[ 1
𝜋⋅tan−1(t)
]x
−∞
= 1
𝜋
(
tan−1(x) −
(
−𝜋
2
))
= 1
2 + 1
𝜋tan−1(x).
(2) P(|X| < 3) = P(−3 < X < 3) = F(3) −F(−3) = 2
𝜋tan−1(3).
Example 7.3.11
(Continuation of Example 7.3.6) The height of waves right
outside Bolgevik harbor. Find the cumulative distribution F(z), and use this
to find the probability that a given wave is between 0.3 and 0.5 meters
tall.
Answer: We use the integration from Example 7.3.6, and get
FZ(z) = P(Z ≤z) = ∫
z
0
2ze−z2 dz = 1 −e−z2
P(Z ∈(0.3, 0.5)) = FZ(0.5) −FZ(0.3) = e−0.09 −e−0.25 ≈0.135.
Example 7.3.12 (Continuation of Example 7.3.7) Find the cumulative proba-
bility distribution for
X ∼f (x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪⎩
x+5
12
x ∈[−5, −3)
1
6
x ∈[−3, 1)
−x+3
12
x ∈[1, 3)
0
otherwise.

7.4 Percentile and Inverse Cumulative Distribution

F(x) =
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪⎩
0
x ≤−5
(z + 5)2
24
x ∈[−5, −3)
x + 4
6
x ∈[−3, 1)
−x2 + 6x + 15
24
x ∈[1, 3)
1
x ≥3
−10
−5
5
10
0.25
0.5
0.75
1
Figure .The conclusion.
Answer: This has to be done piecewise, interval by interval, remembering
that the “area under graph” accumulates as we move from left to right in
the series of intervals. In general for x ∈⟨a, b], we have F(x) = ∫x
−∞f (z) dz =
∫a
−∞f (z) dz + ∫x
a f (z) dz = F(a) + ∫x
a f (z) dz. We see the conclusion with
Figure 7.23. The details are as follows:
⟨−∞, −5] : F(x) = ∫
x
−∞
0 dx = 0
⟨−5, −3] : F(x) = F(−5) + ∫
x
−5
z + 5
12
dz = 0 + (x + 5)2
24
= (x + 5)2
24
⟨−3, 1] : F(x) = F(−3) + ∫
x
−3
1
6 dz = 1
6 + x + 3
6
= x + 4
6
⟨1, 3] : F(x) = F(1) + ∫
x
1
−z + 3
12
dz = 5
6 + −x2 + 6x −5
24
= −x2 + 6x + 15
24
⟨3, ∞⟩: F(x) = F(3) + ∫
x
3
0 dz = 1 + 0 = 1.
.
Percentile and Inverse Cumulative Distribution
Just as interesting as the probability that X ≤x is the complementary question:
“At which value x is the probability that X ≤x first equal to or larger than p =
P% =
P
100?”
Definition 7.4.1 Let X ∼f , and let F be the cumulative distribution. Then
the Pth percentile PP of X is the smallest value of x such that
F(x) ≥
P
100.
For continuous distributions, this is the solution x of the equation
F(x) =
P
100.
The median is mX = P50.


7 Stochastic Variables on ℝ
Example 7.4.2 (Discrete case) X is the number of heads after five tosses with
a fair die.
(1) What is the 86th percentile of X?
(2) What is the median of X?
Answer: This continues Example 7.2.2, and we make use of the table there.
(1) We search the F(k) column until we find a number exceeding 86
100. We see
that F(3) = 0.812 5 < 0.86 ≤0.968 75 = F(4), so F(4) is the first number
equal to or in excess of 86
100. This means P86 = 4.
We may also solve this graphically: we find P86 at 86
100 on the y-axis, going
horizontally until we hit the graph, and then vertically until we hit the x-axis
and may read the percentile value.
(2) mX = P50, so we find the smallest number in excess of (or equal to) 0.5 in
the right column; that number is 0.5 itself. Then we read the entry in the
“outcome” column of the same row, which says 2, so mX = 2.
For continuous probability distributions, the percentile goes by a different
name: the cumulative inverse, iCDF for short.
Rule 7.4.3 Let X ∼f , and let F be the cumulative distribution. If F(x) < F(y)
when x < y, then the cumulative inverse, F−1(p), exists, and
F−1(p) = PP,
where P = 100p.
Example 7.4.4 (Continuous case) We continue Example 7.3.4 about N’s delay,
X ∼f (t) = 12
625t(5 −t)2.
(1) Dan T. is a pragmatist, and wants optimal use of his time. He wonders how
late he himself may be if he wants a 50% probability that N is there before
him.
(2) Ahmad would like to present the class with an overview, with illustrations
of P10, P40, P65, and P90.
Answer: This is a continuation of Example 7.3.9, where we found that F(t) =
1
625(150t2 −40t3 + 3t4). We use this to answer the following questions.
(1) Dan T. wants to find P50, which is also the median, mX. It is also F−1(0.5).
He must then solve
F(t) = 50
100 = 0.5, which is the equation
1
625(150t2 −40t3 + 3t4) = 0.5.

7.4 Percentile and Inverse Cumulative Distribution

1
2
3
4
5
0.1
0.2
0.3
(a) f(t).
1
2
3
4
5
0.2
0.4
0.6
0.8
1
(b) F(t).
0.2
0.4
0.6
0.8
1
1
2
3
4
5
(c) F −1(p).
Figure .Three graphical solutions, which are essentially identical.
1
2
3
4
5
0.1
0.2
0.3
1
2
3
4
5
0.1
0.2
0.3
1
2
3
4
5
0.1
0.2
0.3
1
2
3
4
5
0.1
0.2
0.3
1
2
3
4
5
0.2
0.4
0.6
0.8
1
1
2
3
4
5
0.2
0.4
0.6
0.8
1
1
2
3
4
5
0.2
0.4
0.6
0.8
1
1
2
3
4
5
0.2
0.4
0.6
0.8
1
P10 = 0.713
P40 = 1.646
P65 = 2.378
P90 = 3.398
Figure .Ahmed’s project, using the (cumulative) distribution, f(t) and F(t).
0.2 0.4 0.6 0.8 1
1
2
3
4
5
0.2 0.4 0.6 0.8 1
1
2
3
4
5
0.2 0.4 0.6 0.8 1
1
2
3
4
5
0.2 0.4 0.6 0.8 1
1
2
3
4
5
F −1(10) =0.713
F −1(40) =1.646
F −1(65) =2.378
F −1(90) =3.398
Figure .Ahmed’s project, using the inverse cumulative distribution F−1(p).
This is a fourth degree polynomial equation, so Dan T. solves it in Wolfram
Alpha, and gets
F−1(0.5) = P50 = 1.929 = 1 minute and 56 seconds.
The different graphical solutions are shown in Figure 7.24.
(2) Ahmed’s project is answered in the same way as Dan’s. His solutions are
shown in Figure 7.25.
Ahmed’s questions may also be solved by using the inverse cumulative
distribution, as shown in Figure 7.26.


7 Stochastic Variables on ℝ
..
Some Easy Functions to Calculate
For the examples below, we urge the reader to integrate f (t) and verify that it
is indeed F(t), and to differentiate F(t) and verify that it is indeed f (t). Further-
more, verify that F−1(p) is indeed the inverse of F(x), either by solving F(x) = p,
or by calculating and finding that F (F−1(p)) = p and F−1 (F(x)) = x.
Example 7.4.5 A uniform probability distribution on [3, 8]:
r f (t) = 0.2
r F(t) = 0.2t −0.6
r F
−1(p) = 5p + 3.
In Figure 7.27, we see that P(X ≤5) = F(5) = 0.4.
3
4
5
6
7
8
0.1
0.2
0.3
0.4
(a) P(X ≤5) = ∫
5
3 f(t)dt
3
4
5
6
7
8
0.2
0.4
0.6
0.8
1.0
(b) P(X ≤5) = F(5)
0.0
0.2
0.4
0.6
0.8
1.0
3
4
5
6
7
8
(c) P40 = F −1(0.4)
Figure .P(X ≤5) = F(5) = ∫5
3 f(t) dt = 0.4 – equivalently P40 = F
−1(0.4) = 5.
Example 7.4.6 Linearly rising probability on [0, 10]:
r f (t) =
t
50
r F(t) =
t2
100
r F
−1(p) = 10√p.
In Figure 7.28, we see that P(X ≤6) = F(6) = 0.36.
2
4
6
8
10
0.05
0.10
0.15
0.20
(a) P(X ≤6) = ∫
6
0 f(t)dt.
2
4
6
8
10
0.2
0.4
0.6
0.8
1.0
(b) P(X ≤6) = F(6).
0.2
0.4
0.6
0.8
1.0
2
4
6
8
10
(c) P36 = F −1(0.36).
Figure .P(X ≤6) = F(6) = ∫6
0 f(t) dt = 0.36 – equivalently P36 = F
−1(0.36) = 6.

7.4 Percentile and Inverse Cumulative Distribution

0.5
1.0
1.5
2.0
2.5
3.0
0.1
0.2
0.3
0.4
0.5
(a) P(X ≤2.3) = ∫
2.3
0
f(t)dt.
0.5 1.0 1.5 2.0 2.5 3.0
0.2
0.4
0.6
0.8
1.0
(b) P(X ≤2.3) = F(2.3).
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
2.0
2.5
3.0
(c) P83 = F
−1(0.83).
Figure .P(X ≤2.3) = F(2.3) = 0.83 – equivalently P83 = F
−1(0.83) = 2.3.
Example 7.4.7 A half sine wave on [0, 𝜋]:
r f (t) = 1
2 sin(t)
r F(t) = 1
2 sin2 (
t
2
)
r F
−1(p) = 2 sin−1 (√p).
In Figure 7.29, we see that P(X ≤2.3) = F(2.3) = 0.83.
Example 7.4.8 A compound sine wave on [0,
√
𝜋]:
r f (t) = t sin(t2)
r F(t) = sin2 (
t2
2
)
r F
−1(p) =
√
2 sin−1 (√p).
In Figure 7.30, we see that P(X ≤1.1) = F(1.1) = 0.32.
Example 7.4.9 Negative exponential function on [0, ∞]:
r f (t) = e−t
r F(t) = 1 −e−t
r F
−1(p) = −ln(1 −p).
In Figure 7.31, we see that P(X ≤1.5) = F(1.5) = 0.78.
0.5
1.0
1.5
0.2
0.4
0.6
0.8
1.0
1.2
(a) P(X ≤1.1) = ∫
1.1
0
f(t)dt.
0.5
1.0
1.5
0.2
0.4
0.6
0.8
1.0
(b) P(X ≤1.1) = F(1.1).
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
(c) P32 = F
−1(0.32).
Figure .P(X ≤1.1) = F(1.1) = 0.32 – equivalently P32 = F
−1(0.32) = 1.1.


7 Stochastic Variables on ℝ
0.5
1.0
1.5
2.0
2.5
3.0
0.2
0.4
0.6
0.8
1.0
(a) P(X ≤1.5) = ∫
1.5
0
f(t)dt.
0.5
1.0
1.5
2.0
2.5
3.0
0.2
0.4
0.6
0.8
1.0
(b) P(X ≤1.5) = F(1.5).
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
2.0
2.5
3.0
(c) P78 = F
−1(0.78).
Figure .P(X ≤1.5) = F(1.5) = 0.78 – equivalently P78 = F
−1(0.78) = 1.5.
0.5
1.0
1.5
0.5
1.0
1.5
(a) P(X ≤1.2) = ∫
1.2
0
f(t)dt.
0.5
1.0
1.5
0.2
0.4
0.6
0.8
1.0
(b) P(X ≤1.2) = F(1.2).
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
(c) P92 = F
−1(0.92).
Figure .P(X ≤1.2) = F(1.2) = 0.92 – equivalently P92 = F
−1(0.92) = 1.2.
Example 7.4.10 A compound function on [0, ∞]:
r f (t) = 5t4e−t5
r F(t) = 1 −e−t5
r F−1(p) =
5√
−ln(1 −p).
In Figure 7.32, we see that P(X ≤1.2) = F(1.2) = 0.92.
.
Expected Value
We found that the average of a data set may be written ̄x =
∑
all x x ⋅px, where
px is the proportion of the data having value x. The proportion formula for
the average ̄x may be generalized to probabilities, since probability is a kind
of proportion. Just let px be the point probability of the value x. You then get
the expected value of the discrete stochastic variable X, which is written E[X]
or 𝜇X.
Definition 7.5.1 For a discrete stochastic variable X with point probabilities
P(X = x) = px,
𝜇X = E[X] =
∑
all x
x × px.

7.5 Expected Value

Example 7.5.2 Sam is more interested in what the future may bring than in
past history. He has been invited to play a game with a single toss of a D4. He has
to bet £3, and will be paid the amount shown by the die. Sam thinks this is an
excellent game, since he gets a prize no matter what! But he’s lost in gambling
before, so he asks his good friend Bard if he really should join the game, and if
he should perhaps negotiate his bet. The die D4 has, as we remember, uniform
probabilities. That is,
P(X = k) = 0.25 for all x ∈U = {1, 2, 3, 4}.
Bard tells Sam that he can expect to lose in the long run, since his bet is larger
than the expected payoff of the game. Bard asks Sam to calculate the expected
value of the game for himself. Sam looks at the D4, and calculates:
𝜇X = E[X] =
4
∑
k=1
k ⋅pk = 1 ⋅0.25 + 2 ⋅0.25 + 3 ⋅0.25 + 4 ⋅0.25 = 2.5.
The expected payoff of £2.5 is less than Sam’s bet. Sam decides not to join the
game, and decides to look for another one instead.
This formula transfers easily to continuous variables. We just need to replace
the point probabilities px by the probability density f (x), and replace the sum-
mation sign by an integral, and we get the formula
𝜇X = ∫
∞
−∞
x ⋅f (x) dx.
(7.1)
The integration limits may be narrowed to fit the range of the stochastic
variable X.
Example 7.5.3
We revisit the example of N’s delay, X ∼f (t) = 12
625t(5 −t)2,
and wonder: What is N’s expected delay? Figure 7.33 has the answer.
Example 7.5.4 This continues Example 7.3.7, where
X ∼f (x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪⎩
x+5
12
x ∈[−5, −3)
1
6
x ∈[−3, 1)
−x+3
12
x ∈[1, 3)
0
otherwise.


7 Stochastic Variables on ℝ
We will now find E[X]:
E[X] = ∫
∞
−∞
x ⋅f (x) dx
= ∫
−3
−5
x ⋅x + 5
12
dx + ∫
1
−3
x ⋅1
6 dx + ∫
3
1
x ⋅−x + 3
12
dx = −1.
𝜇X = E[X]
= ∫
5
0
t × f (t)dt
= ∫
5
0
t × 12
625t(5 −t)2dt
= 2.
1
2
3
4
0.1
0.2
0.3
median
(P50)
mean
Figure .The answer to example 7.5.3.
Example 7.5.5 It’s Saturday evening, and Sam is sitting on his couch expect-
ing to become a millionaire. He and Bard decided, as an experiment, to fill out a
12-game betting slip using a D3 to decide whether to bet H (home), D (draw), or
A (away) for each game. The betting slip is currently in Bard’s office. After Liv-
erpool FC’s totally unexpected 5–1 win over Manchester United, the payouts
are as follows:
r 12 correct: £500 000
r 11 correct: £8 947
r 10 correct: £52.
What is Sams and Bards expected payout from their betting slip?
Answer:
r The probability of 12 correct is
(
1
3
)12
≈1.88 ⋅10−6.
r The probability of 11 correct is
(
12
1
)
⋅2
3 ⋅
(
1
3
)11
≈0.000 045.
r The probability of 10 correct is
(
12
2
)
⋅
(
2
3
)2 (
1
3
)10
≈0.000 50.
The expected payout is then
1.88 ⋅10−6 ⋅500 000 + 0.000 045 ⋅8 947 + 0.000 50 ⋅52 = 1.37.

7.5 Expected Value

The price of the betting slip was just £1, so this bet has an expected positive net
result of £0.37. It’s the kind of bet you would like to be in. But when Sam asks
Bard if they should repeat the experiment next week, Bard declines, since the
expected payout on a normal week is 50 pence.
Example 7.5.6 Bard, Svein, and Thor are at the airport with their friend Sam,
who is going to attend a poker tournament in Las Vegas. The four friends are
making time pass by playing a long-lasting mediaeval card game with open
cards called Rondebleu, and they have roughly half an hour left of the game
when boarding for Sam’s flight is announced. There is £1120 in the pot, and
they would like to split it fairly before they part.
Bard instructs that the fair share would be the price they would be willing to
pay to resume the game with the same cards and the same pot.
“How much would that be?” Svein asks.
Bard replies that they should not choose to participate if the new bet
exceeded the expected payout. So the limiting price to participate would be
each player’s probability to win, times the total pot.
“Ah OK, just the pot times my probability to win!” exclaims Svein. “That’s an
easy one, for since I’m in the lead, I have a 100% probability to win!”
Bard then offers Svein to play him afterwards, each keeping their current
cards. Svein will have to pay £1120, and Bard 0. Svein doesn’t think much of
that proposal, he says, since all he gets out of it is to have his money back at the
end of the game. So then Bard offers a different deal: Svein pays £1000 to join
the game, and gets paid £1120 if and when he wins.
Svein realizes that even this is a poor bet, since there is still a significant prob-
ability that one of the others will win, and then he’d lose £1000 on a risky wager.
Meekly, Svein asks Bard to calculate the actual probabilities to win, and dis-
tribute the pot accordingly.
The Rondebleu probabilities are easy to calculate: they are 60% for Svein to
win, 30% for Sam, and 10% for Thor. Bard lost early on, so he’s not in.
(1) Expected payout for Svein is 1120 ⋅0.6 = 672, so Svein gets £672.
(2) Expected payout for Sam is 1120 ⋅0.3 = 336, so Sam gets £336 to bring to
Vegas.
(3) Expected payout for Thor is 1120 ⋅0.1 = 112, so he gets £112.
The players agree that this is fair, and reason as follows: if Bard put each of
their cards in sealed envelopes with the payouts as price tags, any of them would
think the naming price fair for any of the envelopes, even if it wasn’t their own.
They wave farewell to Sam, and agree to visit Frederick to continue the game.
Thor pays £672 to take over Svein’s old hand, since he’s tired of being the under-
dog, whereas Bard buys Thor’s old hand for £112. Svein buys Sam’s hand for
£336. Frederick just shakes his head at his crazy gambler friends, and goes to
put on some hot water to make them all a nice cup of tea.


7 Stochastic Variables on ℝ
Example 7.5.7
It is “student surprise” day at your university, and Tonya,
Samuel, and Guillaume have been told that the surprise lecturer is either Svein
Nyberg, Bill Gates, or Larry Ellison, and that the probabilities that it is just that
person are, respectively 0.8, 0.15, and 0.05. Samuel has decided to ask the lec-
turer to contribute to the students’ education fund, with a promise to do one
push-up for every hundred dollars donated.
Samuel has heard that Nyberg is a tightwad, but will give $100 just to see
Samuel do a push-up, whereas Ellison is known to give 1000, and Gates is said
to give ten thousand if asked. Tonya says she’ll give a dollar to charity for every
push-up Samuel does, if Guillaume matches her. Guillaume starts worrying that
the surprise lecturer might be Bill Gates, and asks Tonya if he can prepay the
expected amount instead, “you know, just as in a bet”. Tonya says that’s fair. How
much must Guillaume pay?
Answer: Remember that the probabilities are 0.8, 0.15, and 0.05. Tonya’s
expected payment is then
E[X] = 0.8 ⋅1 + 0.15 ⋅10 + 0.05 ⋅100 = 7.3
so Guillaume has to pay 7 dollars and 30 cents. Guillaume doesn’t have any cent
coins on him, but since he is a generous man, he donates $8 to the fund.
.
Variance, Standard Deviation, and Precision
The most common measures of spread for both stochastic variables and pop-
ulations/data, are variance and standard deviation. We will now study these
measures for stochastic variables. For data, see Chapter 2.
Definition 7.6.1 The variance of a stochastic variable X is the mean square
distance from the expected value 𝜇X:
Var(X) = E[(X −𝜇X)2].
Rule 7.6.2 A simpler calculation than the definition, is the identity
Var(X) = E[(X −𝜇X)2] = E[X2] −𝜇2
X.
r For discrete X, it then follows that Var(X) =
(
∑
all x
x2 ⋅px
)
−𝜇2
X.
r For continuous variables, Var(X) =
(
∫
∞
−∞
x2 ⋅p(x) dx
)
−𝜇2
X.

7.6 Variance, Standard Deviation, and Precision

If X is measured in units of unit u, then so is the mean, but the variance goes
in units of u2. To get a measure of spread that is commensurate with the X and
with the expectation, we must use the standard deviation – see the following
definition.
Definition 7.6.3 The standard deviation of a stochastic variable X is
𝜎X =
√
Var(X).
Example 7.6.4 We continue Example 7.5.2 concerning Sam’s D4. Recall that
P(X = k) = 0.25 for all x ∈U = {1, 2, 3, 4}, and that the expected value was
𝜇X = 2.5. What is the standard deviation of X?
Answer: We find E[X2], Var(X), and 𝜎X in turn:
E[X2] =
∑
all k
k2 × pk =
4
∑
k=1
k2 × 0.25 = 7.5
Var(X) = E[X2] −𝜇2
X = 7.5 −2.52 = 1.25
𝜎X =
√
Var(X) =
√
1.25 ≈1.118.
Example 7.6.5 We revisit the situation in Example 7.3.4 about N’s delay X ∼
f (t) = 12
625t(5 −t)2. We calculated (Example 7.5.3) that his expected delay was
2 minutes. But what is the spread of these delays? We want to answer it in terms
of the standard deviation.
Answer: We find E[X2], Var(X), and 𝜎X in turn:
E[X2] = ∫
5
0
t2 ⋅f (t) dt = ∫
5
0
t2 ⋅12
625t(5 −t)2 dt = 5
Var(X) = E[X2] −𝜇2
X = 5 −22 = 1
𝜎X =
√
Var(X) =
√
1 = 1.
Illustration: We often consider values inside one standard deviation of the mean
as “normal”, so we have marked N’s normal delays in Figure 7.34. That is, the
delays within 1 standard deviation 𝜎X on either side of 𝜇X.


7 Stochastic Variables on ℝ
1
2
3
4
0.1
0.2
0.3
μ+σ
μ−σ
μ
Figure .The mean 𝜇plus/minus one standard deviation 𝜎.
Example 7.6.6 We continue Examples 7.3.7 and 7.5.4, where
X ∼f (x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪⎩
x+5
12
x ∈[−5, −3)
1
6
x ∈[−3, 1)
−x+3
12
x ∈[1, 3)
0
otherwise.
We will calculate Var(X) and 𝜎X, and recall that 𝜇X = E[X] = −1:
E[X2] = ∫
∞
−∞
x2 ⋅f (x) dx
= ∫
−3
−5
x2 ⋅x + 5
12
dx + ∫
1
−3
x2 ⋅1
6 dx + ∫
3
1
x2 ⋅−x + 3
12
dx = 13
3
Var(X) = E[X2] −𝜇2
X = 13
3 −(−1)2 = 10
3
𝜎X =
√
Var(X) =
√
10
3 .
You have probably pondered a bit, and wondered why we have chosen such
a seemingly cumbersome measure of spread as 𝜎X, where we have to subtract,
square, sum, and then take the square root again. Surely, it would be a lot eas-
ier to just sum |x −𝜇X| ⋅px and be done with it! Well, seemingly it would. In
Section 8.3 we will see that mean and variance are very well behaved when
we add stochastic variables: Z = X + Y. The formulas are nice, tidy, and neat.
Corresponding formulas if we decided to use ∑|x −𝜇X| ⋅px as our measure

7.7 Exercises

of spread, on the other hand, are not user friendly at all. And since statistics
relies heavily on adding stochastic variables, we need our measure of spread to
behave well under addition.
..
Precision
We will make much use of the inverse of the variance of a stochastic variable,
known as the precision.
Definition 7.6.7 The precision of a stochastic variable X is
𝜏X = 1
𝜎2
X
.
Example 7.6.8 X has standard deviation 𝜎X = 5. What is its precision 𝜏X?
Answer: 𝜏X =
1
𝜎2
X
= 1
52 = 0.04.
.
Exercises
1
Read the chapter.
(a) What are the smallest and largest values possible for a discrete distri-
bution function f (x)?
(b) What are the smallest and largest values possible for a continuous dis-
tribution function f (x)?
(c) What are the smallest and largest values possible for a cumulative dis-
tribution function F(x)?
(d) What is f (x), and what is F(x)? What is the difference between the two?
(e) What does discrete probability have in common with data analysis?
Which common measures do we have?
(f) How do you calculate P(a < X ≤b) from F(x)?
(g) What is the relation between P(X > a) and P(X ≤a)?
Discrete Stochastic Variables
2
In the exercises below, you are given concrete stochastic variables X.
r Make a table of the probabilities larger than 0.
r Draw a probability diagram from the table.
r Find E[X].
r Find Var(X).
r Find 𝜎X.
r Find 𝜏X.


7 Stochastic Variables on ℝ
(a) X is the outcome of flipping a fair coin with “0” on one side and “1”
on the other.
(b) X is the sum of the outcomes of two fair coins with “0” on one side
and “1” on the other.
(c) X is the sum of the outcomes of three fair coins with “0” on the one
side, and “1” on the other.
(d) X is the outcome of tossing a fair D4.
(e) X is the sum of two fair D4.
(f) X is the outcome of tossing a fair D6.
(g) X is the sum of two fair D6.
3
For the following sets M and functions f , do the following.
r Make a table and diagram for f .
r Determine if f is a discrete probability distribution. If it is, let X ∼f and
do the following.
i. Find 𝜇X.
ii. Find Var(X).
iii. Find 𝜎X.
iv. Find 𝜏X.
v. Find P(X ∈M).
(a) M = [−3, 2] and f (x) =
{ x
4
if x = 1, 2, 3, 4
0
otherwise.
(b) M = {1, 4} and f (x) =
{ x
10
if x = 1, 2, 3, 4
0
otherwise.
(c) M = {2, 4, 6} and f (x) =
{ x
k
if x = 1, 2, 3, 4, 5, 6
0
otherwise.
Answer the assignment for the value of k that makes f (x) a discrete
probability distribution.
4
We create a family of distributions, determined by a parameter r. For each
r, let
hr(n) =
{
k
(n−1)!
if n = 1, 2, … , r
0
otherwise
with a value of k so that hr is a probability distribution.
(a) Calculate the value of k for r = 4.
(b) Let Y ∼h4. Write down the probability table for Y.
(c) Calculate 𝜇Y .
(d) Calculate E[Y 5].

7.7 Exercises

Continuous Stochastic Variables
5
Which of the following functions are continuous probability distributions?
r f (x) =
⎧
⎪
⎨
⎪⎩
1∕40
x ∈[−10, 0]
3∕40
x ∈[0, 10]
0
x ∉[−10, 10]
r f (x) =
⎧
⎪
⎨
⎪⎩
1∕2
x ∈[2, 6]
−1
x ∈[6, 7]
0
x ∉[4, 7]
r f (x) =
{
−1
2 sin(x)
x ∈[𝜋, 2𝜋]
0
x ∉[𝜋, 2𝜋]
r f (x) =
⎧
⎪
⎨
⎪⎩
1∕6
x = 4
1∕3
x = 5
1∕2
x = 6
0
x ∉{5, 6, 7}.
6
For the functions f (x) above that are continuous probability distributions:
let X ∼f (x), and find 𝜇X, 𝜎2
X, and P(X ≥5).
7
For the following sets M and functions f , do the following in (a)–(d).
r Graph f , and mark [a, b] along the horizontal axis.
r Determine whether f (x) is a continuous probability distribution. If it is,
let X ∼f and do the following.
i. Find 𝜇X.
ii. Find Var(X).
iii. Find 𝜎X.
iv. Find 𝜏X.
v. Find P(X ∈M).
(a) M = [0.5, 1.5] and function f (x) =
{2x
x ∈[0, 1]
0
otherwise.
(b) M = [0, 5] and function f (x) =
{cos(x)
x ∈[−𝜋
2 , 𝜋
2 ]
0
otherwise.
(c) M = {0, 5} and function f (x) =
{sin(x)
x ∈[−𝜋
2 , 𝜋
2 ]
0
otherwise.
(d) M = [0, 0.5] and function f (x) =
{3x2
x ∈[0, 1]
0
otherwise.


7 Stochastic Variables on ℝ
(e) The Christmas tree distribution looks like its name. Its distribution
function is
f (x) =
⎧
⎪
⎨
⎪⎩
x + 1
for x ∈[−1, 0]
1 −x
for x ∈[0, 1]
0
for all other values of x.
i. What is 𝜇X?
ii. What is 𝜎X?
iii. What is P(X ∈(0.5, 1.5))?
(f) The Mohawk proto distribution is given by the continuous function
̄f (x) =
⎧
⎪
⎨
⎪⎩
1 −10x2 −24x3 −15x4
if −1 ≤x < 0
1 −10x2 + 24x3 −15x4
if 0 ≤x ≤1
0
if |x| > 1.
i. Why is ̄f not a probability distribution?
ii. Find the constant k that makes f (x) = k ⋅̄f (x) a probability distribu-
tion.
iii. The stochastic variable X has probability distribution f . Find
A. 𝜇X.
B. P (X ∈[−2, −0.5] ∪[0.5, 2]).



Stochastic Variables II
CONTENTS
8.1
Mixed Distributions∗, 171
8.2
Two- and Multi-variable Probability Distributions∗, 177
8.3
The Sum of Independent Stochastic Variables, 190
8.4
The Law of Large Numbers∗, 191
8.5
Exercises, 193
In Chapter 5, we looked at stochastic variables X of just one variable x ∈ℝ.
Mixed distributions have, in addition to the input variable x, a choice between
different distributions. In the flow diagram in Figure 8.1, the choice is between
distribution 1 and distribution 2. The extra dimension is {1, 2} – the choice
between 1 and 2.
Given n distributions, the extra dimension is {1, 2, … , n}. In a limiting case,
illustrated in Figure 8.2, the choice dimension gets infinitely large, maybe even
as large as ℝ, which moves us on to two-variable stochastic variables, with prob-
ability distributions on ℝ× ℝ, that is: ℝ2.
.
Mixed Distributions∗
Mixed distributions between a continuous and a discrete distribution, as illus-
trated in Figure 8.3, can be very useful. Purely discrete and purely continuous
stochastic variables each have their type of f probability distribution function.
Such probability distribution functions are very useful. However, discrete–
continuous mixed distributions have cumulative distributions F only.
An elevator provides examples of both mixed waiting time and mixed state.
Example 8.1.1 Waiting time: When you arrive at work, you run up the stairs
60% of the time, and ride the elevator in the remaining 40%.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


8 Stochastic Variables II
p1=0.6
p2=0.4
40%
60%
Figure .A mixed probability distribution.
The time it takes you to run up the stairs, Xt, has a continuous distribution
f (t) =
1
32 000(−3600 + 240t −3t2) for 20 ≤t ≤60. The time it takes to take the
elevator, on the other hand, Xh, has a discrete distribution, with point proba-
bilities p25 = 0.5, p33 = 0.25, p41 = 0.125, p49 = 0.062 5, and p57 = 0.062 5.
The time to get to your floor is therefore a discrete–continuous mixed
stochastic variable X which is a mix between Xt and Xh with probabilities
wt = 0.6 and wh = 0.4.
Example 8.1.2 State of the elevator: You want to know where the elevator
might be. Some of the time, it stands still on one floor. The rest of the time,
it is moving between floors. Its position, given that it stands still, is a discrete
stochastic variable. Its position, given that it is moving, is a continuous variable.
The unconditioned total picture of where the elevator is at any given time is
therefore a discrete–continuous mixed stochastic variable.
Example 8.1.3
The weather: The amount of rain on a rainy day follows a
continuous distribution. When it doesn’t rain, the amount of rain is a discrete
(a) f (x, y).
0.01
0.02
0.00
0.00
0.01
0.02
0.00
0.01
0.02
0
0
0
0
5
5
5
5
10
10
10
10
0
0
5
5
10
10
(b) Conditional probabilities.
(c) Marginal probabilities.
Figure .We will be studying two-variable distributions in Section 8.2.

8.1 Mixed Distributions∗

20
30
40
50
60
0.5
1
(a) Discrete.
20
30
40
50
60
0.5
1
(b) Continuous.
(c) Mixing...
20
30
40
50
60
0.5
203040 50 601.0
0.5
0.0
1
(d) Mixed!
Figure .Discrete–continuous mixed cumulative distribution.
stochastic variable whose value always is 0. So the amount of rain on any given
day follows a discrete–continuous mixed distribution.
Example 8.1.4
Water flow: Some watercourses have both dry and wet
periods. The water flow of these is a discrete–continuous mixed stochastic
variable.
So now that we know mixed stochastic variables exist and are relevant, how
do we calculate them? The answer is to divide the universe of the problem
into mutually exclusive conditions 𝜃1, … , 𝜃n. For each condition 𝜃k, we find
the stochastic variable Xk, its cumulative distribution function Fk, and a weight
wk = P(𝜃k) which is the probability that the condition is realized.
If X is the height of a randomly chosen Norwegian, the conditions may be
M(ale) and F(emale), making X a mixture of XM and XF, with weights wM
and wF.
If X is a discrete–continuous mix, the primary conditioning is discrete (with
stochastic variable Xd) and continuous (with stochastic variable Xc).
Rule 8.1.5
If X is a weighted mix of stochastic variables X1, … , Xn, with
weights w1, … , wn, then
FX(x) =
n
∑
k=1
wk ⋅Fk(x)
fX(x) =
n
∑
k=1
wk ⋅fk(x) (iff all the Xk are of the same type)
E[Xm] =
n
∑
k=1
wk ⋅E[Xm
k ]
Var(X) =
n
∑
k=1
wk ⋅Var(Xk) +
n
∑
k=1
wk(𝜇k −𝜇)2.
For 2 variables X1, X2, we may use the simplified formula
Var(X) = w1 ⋅Var(X1) + w2 ⋅Var(X2) + w1w2(𝜇1 −𝜇2)2.


8 Stochastic Variables II
Example 8.1.6 For the elevator example (Example 8.1.1), find
1) P(X ≤40);
2) E[X];
3) Var(X).
Answer: We answer the corresponding questions for the two components, Xd
and Xc, and combine according to Rule 8.1.5:
1)
Fc(x) = ∫
x
20
f (t) dt =
1
32 000(−x3 + 120x2 −3 600x + 32 000)
Fc(40) = 1
2
Fd(40) =
∑
x≤40
fd(x) = p25 + p33 = 0.75
P(X ≤40) = F(40) = 0.6 ⋅Fc(40) + 0.4 ⋅Fd(40) = 0.6.
2) E[Xc] = ∫
60
20
x ⋅
1
32 000(−3 600 + 240x −3x2) dx = 40
E[Xd] =
∑
all x
x ⋅fd(x) = 32.5
E[X] = F(40) = 0.6 ⋅E[Xc] + 0.4 ⋅E[Xd] = 37.
3)
E[X2
c ] = ∫
60
20
x2 ⋅
1
32 000(−3600 + 240x −3x2) dx = 1680
Var(Xc) = E[X2
c ] −E[Xc]2 = 80
E[X2
d] =
∑
all x
x2 ⋅fd(x) = 1148
Var(Xd) = E[X2
d] −E[Xd]2 = 91.75
Var(X) = 0.6 ⋅80 + 0.4 ⋅91.75 + 0.6 ⋅0.4(40 −32.5)2 = 98.2.
We do, however, seldom find the stochastic variable readily decomposed for
us, so have to do that job ourselves. We decompose into discrete and continuous
as follows.
r The decomposition is X = wd ⋅Xd + wc ⋅Xc.
r Find the points xk with positive point probability pk. Let p = ∑
k pk. Then,
Xd ∼fd, where fd(xk) = pk
p , with weight wd = p.
r The continuous part Xc has a continuous (proto) probability distribution f (x)
on an interval I. Then, Xc ∼fc, where fc(x) =
1
∫I f (x) f (x), with weight wc =
1 −wd.

8.1 Mixed Distributions∗

Example 8.1.7
You are sponsoring a charitable sack run, and have pledged
1 Norwegian crown per meter, but have promised to pay a minimum of 200
crowns, but a maximum of 1000 crowns. The length of the sack run, in meters,
has a probability distribution f (x) = 7.5 ⋅10−13x(2000 −x)2 in the interval
I = [0, 2000]. Decompose your pledged amount X into a discrete part Xd and a
continuous part Xc, and find the weights wd and wc. Then, find your expected
sponsorship amount.
Answer: For 200 meters or less, you pay 200 crowns, and the probability of that
is p200 = ∫200
0
f (x) dx = 0.052 3. For 1000 meters or more, you pay 1000 crowns,
and the probability of that is p1000 = ∫2 000
1 000 f (x) dx = 0.312 5. These are the two
points of our discrete component Xd, and the total probability of that con-
dition is wd = p200 + p1000 = 0.052 3 + 0.312 5 = 0.364 8. Then, wc = 1 −wd =
0.635 2, and
Xd ∼fd(x) =
⎧
⎪
⎨
⎪⎩
0.052 3
0.364 8 = 0.143 366
for x = 200
0.312 5
0.364 8 = 0.856 634
for x = 1 000
E[Xd] = 0.143 366 ⋅200 + 0.856 634 ⋅1 000 = 885.307
Xc ∼fc(x) = f (x)
wc
= 1.1807 ⋅10−12x(2 000 −x)2 for 200 < x < 1 000
E[Xc] = ∫
1 000
200
x ⋅f (x) dx = 618.942
E[X] = 0.364 8 ⋅885.307 + 0.635 2 ⋅618.942 = 716.112.
Mixed distributions may also be mixes where all components are continu-
ous or all components are discrete. In such cases, we are able to work with a
probability distribution f , and not just the cumulative distribution F.
Example 8.1.8 The Loppen river is known for good fishing of Salmon, char,
and trout. The weights of the fish of each species are Normally distributed (see
Section 10.1) with each their mean weights 𝜇and standard deviations 𝜎. The
catches are distributed between the species as follows:
r 63.7% salmon, with 𝜇= 4.2 and 𝜎= 1.2;
r 22.4% char, with 𝜇= 1.7 and 𝜎= 0.5;
r 13.9% trout, with 𝜇= 0.95 and 𝜎= 0.1.
Let X be the weight of a random catch in Loppen, and let the components
Xs, Xc, Xt be the weights given that the catch is respectively a salmon, a char, and
a trout. You can easily calculate and find that 𝜇X = 3.188 25 and that Var(X) =
2.819 22. We are going to find the probability density f of X. This is illustrated


8 Stochastic Variables II
2
4
6
2
4
(a) Three distributions.
(b) Mixing distributions.
2
2
4
6
4
6
0.2
0.4
0.6
0.6
0.4
0.2
(c) The mixed distribution.
Figure .A mix of three continuous distributions of fish weights.
in Figure 8.4. For the calculation, we have to look a bit ahead to Section 10.1 to
find the formula for the Normal distribution, and we get
f (x) = ws fs(x) + wc fc(x) + wt ft(x)
=
0.637
1.2
√
2𝜋
e−(x−4.2)2
2⋅1.22 +
0.224
0.5
√
2𝜋
e−(x−1.7)2
2⋅0.52 +
0.139
0.1
√
2𝜋
e−(x−0.95)2
2⋅0.12 .
We conclude our investigation of mixed distributions by looking at mixes
with not just 2 or 3, or even countably many components, but mixes with a con-
tinuum of components. Then, the point weights wk are replaced by probability
densities w(k), and the sums are replaced by integrals, since this is a transition
from discrete to continuous stochastic variables.
Rule 8.1.9 Let X be a mix of stochastic variables Xy of the same type, where
the weights are given by a continuous probability distribution w(y). Then,
FX(x) = ∫
∞
y=−∞
w(y) ⋅Fy(x) dy
fX(x) = ∫
∞
y=−∞
w(y) ⋅fy(x) dy
E[Xm] = ∫
∞
y=−∞
w(y) ⋅E[Xm
k ] dy
Var(X) = ∫
∞
y=−∞
w(y) ⋅(Var(Xy) + (𝜇y −𝜇)2) dy.
Example 8.1.10 Θt, the position of a fault in a flywheel, given that the fault
arose at time t, has distribution ft(𝜃) =
1
1𝜋(1 + cos(𝜃−t)). The time that the
fault arises, t, has distribution g(t) = e−t for t ≥0. Then Θ, the position of the
fault, is a mixed distribution with continuously distributed weights wt = g(t)
and individual components Θt. Find the distribution of Θ.

8.2 Two- and Multi-variable Probability Distributions∗

Answer:
fΘ(𝜃) = ∫
∞
t=0
e−t ⋅1
1𝜋(1 + cos(𝜃−t)) dt
= sin(𝜃) + cos(𝜃) + 2
4𝜋
=
2 +
√
2 cos
(
𝜃−𝜋
4
)
4𝜋
.
When we are looking at mixed probability distributions, we are essentially
looking at two variables: the index of the weights, w, and the variable y. It is
then natural to proceed to the full-blooded theory of two- and multi-variable
probability distributions.
.
Two- and Multi-variable Probability Distributions∗
Definition 8.2.1 Z is a two-dimensional stochastic variable when its sample
space is U = ℝ2. We may then write Z decomposed into its two dimensions
as Z = ⟨X, Y⟩. The cumulative probability distribution is FZ, with
FZ(x, y) = P({X ≤x} ∩{Y ≤y}).
We call fZ(x, y) = fXY(x, y) the simultaneous distribution of X and Y. The rela-
tion between the distribution f and the cumulative distribution F has already
been explored in Section 8.2.1 for discrete X and Y, and Section 8.2.2 for con-
tinuous X and Y.
The variable X has a marginal probability distribution, which is simply its
probability distribution when we factor out Y and look at X alone. The marginal
cumulative probability distribution of X is FX(x) = P(X ≤x) = FZ(x, ∞). We
find the marginal probability distribution fX from FX, by taking the differences
(discrete) or by differentiation (continuous). The same goes for Y.
For a given value x of X, we have the conditional stochastic variable Y|X=x, or
Y|x for short. It has the conditional distribution f|x(y) = fZ(x, y)∕fX(x).
..
Discrete X and Y
Rule 8.2.2 If (X, Y) is a pair of discrete stochastic variables with joint point
probabilities pab = fXY(a, b),
pab = P(X = a, Y = b)
P((x, y) ∈C) =
∑
(x,y)∈C
pxy,


8 Stochastic Variables II
then the marginal probability distributions are
fX(a) =
∑
y
fXY(a, y)
fY(b) =
∑
x
fXY(x, b),
whereas the conditional probability distributions are
f|Y=y(x) = fXY(x, y)
fY(y)
f|X=x(y) = fXY(x, y)
fX(x) .
Example 8.2.3 Sam flips four coins. Bard wins the ones that land heads. He
then flips the remaining coins, and Frederick wins the heads of this new round.
Let X and Y be the respective number of coins Bard and Frederick win.
(1) Make a table of the values of fXY, and include the marginal probabilities fX
and fY.
(2) Find the conditional probabilities f|Y=2(x); write them up in a table.
(3) Find the probability that Bard and Frederick won one coin each.
(4) Find the probability that Bard and Frederick won equally many coins.
(5) Find the probability that Bard and Frederick won three coins in total.
Answer:
(1) We first need to find the values fXY(a, b), and will here show how
to calculate one such value, fXY(2, 1): the probability of two heads in
four tosses is (4
2
) × 0.53 = 0.375. After Bard has won two coins, there
are 4 −2 = 2 coins left. The probability of one heads in two tosses is
(2
1
) × 0.52 = 0.5. This means fXY(2, 1) = P(X = 2, Y = 1) = 0.375 × 0.5 =
0.187 5.
Corresponding calculations for other values of a and b first give the
probability that X = a, that a of the five tosses land heads: (4
a
) × 0.54. We
then find the probability that Y = b, that b of the next 4 −a tosses land
heads: (4−a
b
) × 0.54−a. The formula to fill the distribution table for fXY
is thus
fXY(a, b) =
(
4
a
)
× 0.54 ×
(
4 −a
b
)
× 0.54−a.

8.2 Two- and Multi-variable Probability Distributions∗

fXY
Y = 0
Y = 1
Y = 2
Y = 3
Y = 4
fX
X = 0
0.003 906 25
0.015 625
0.023 437 5
0.015 625
0.003 906 25
0.0625
X = 1
0.031 25
0.093 75
0.093 75
0.031 25
0
0.25
X = 2
0.093 75
0.187 5
0.093 75
0
0
0.375
X = 3
0.125
0.125
0
0
0
0.25
X = 4
0.0625
0
0
0
0
0.0625
fY
0.316 406
0.421 875
0.210 938
0.046 875
0.003 906 25
(2) Let us take a closer look at fXY for Y = 2, and divide by fY(2) to get
f|Y=2(x):
x fXY(x, 2)
0 0.023 4375
1 0.093 75
2 0.093 75
3 0
4 0
fY(2) 0.210 938
x f|Y=2(x)
0 0.023 4375∕0.210 938 = 1∕9
1 0.093 75∕0.210 938 = 4∕9
2 0.093 75∕0.210 938 = 4∕9
3 0∕0.210 938 = 0
4 0∕0.210 938 = 0
∑1
(3) The probability that Bard and Frederick each got one coin is P(X = 1, Y =
1) = fXY(1, 1). We read this probability in the first table, where is says that
fXY(1, 1) = 0.093 75.
(4) The probability that they got the same number of coins, is
P(X = Y) = fXY(0, 0) + fXY(1, 1) + fXY(2, 2) + fXY(3, 3) + fXY(4, 4)
= 0.003 906 25 + 0.093 75 + 0.093 75 + 0 + 0 = 0.191 406.
(5) The probability that they got three coins in total is
P(X + Y = 3) = fXY(0, 3) + fXY(1, 2) + fXY(2, 1) + fXY(0, 3)
= 0.125 + 0.1875 + 0.093 75 + 0.015 625 = 0.421 875.
Rule 8.2.4 Some handy rules for calculations
r Given the point probabilities fXY(x, y), we find the cumulative probability
FXY(x, y) as follows:
FXY(i, j) =
∑
a ≤i
b ≤j
fXY(a, b).
In a table, this means that FXY(i, j) is the sum of all the values in the rect-
angle spanned by (i, j) and the upper left corner of the fXY table, as shown
in Figure 8.5.


8 Stochastic Variables II
fW (2,2)
FW (2,2)
Figure .Finding the cumulative distribution.
=
+
–
–
Figure .Finding the probability distribution.
r Conversely, we may find the point probabilities from the cumulative prob-
abilities by calculating differences, as shown in Figure 8.6.
r Finally, the following rule helps us calculate the probabilities of general
rectangles when we know the cumulative distribution FXY:
P(a < X < A, b < Y < B) = FXY(A, B) −(FX(a, B)
+ FY(A, b) −FXY(a, b)).
If there is no upper limit A or B, use ∞as the upper limit, and that
FZ(x, ∞) = FX(x) and FZ(∞, y) = FY(y).
Example 8.2.5 (Continuation of Example 8.2.3)
(1) Make a table of the cumulative values FXY, FX, and FY.
(2) Find the probability that Bard and Frederick won at most one coin each.
(3) Find the probability that Bard won at least one coin and that Frederick won
at least two.
(1) The cumulative table is then
FXY
Y = 0
Y = 1
Y = 2
Y = 3
Y = 4
FX
X = 0
0.003 906 25
0.019 5313
0.042 9688
0.058 5938
0.0625
0.0625
X = 1
0.035 1563
0.144 531
0.261 719
0.308 594
0.3125
0.3125
X = 2
0.128 906
0.425 781
0.636 719
0.683 594
0.6875
0.6875
X = 3
0.253 906
0.675 781
0.886 719
0.933 594
0.9375
0.9375
X = 4
0.316 406
0.738 281
0.949 219
0.996 094
1.
1.
FY
0.316 406
0.738 281
0.949 219
0.996 094
1.

8.2 Two- and Multi-variable Probability Distributions∗

(2) The probability that Bard and Frederick won at most one coin each is P(X ≤
1, Y ≤1) = FXY(1, 1), which we find in the cumulative table: FXY(1, 1) =
0.144 531.
(3) Find the probability that Bard won at least one coin and that Frederick won
at least two. We illustrate this by coloring the fXY table:
fXY
Y = 0
Y = 1
Y = 2
Y = 3
Y = 4
X = 0 0.003 906 25 0.015 625 0.023 437 5 0.015 625 0.003 906 25
X = 1 0.031 25
0.093 75
0.093 75
0.031 25
0.
X = 2 0.093 75
0.187 5
0.093 75
0.
0.
X = 3 0.125
0.125
0.
0.
0.
X = 4 0.062 5
0.
0.
0.
0.
In this particular case, summing the colored rectangles is an easy job,
since only three of them are non-zero. But we will employ the general tech-
nique in Rule 8.2.4, and then we get
P(X ≥1, Y ≥2) = P(X > 0, Y > 1)
= 1 −(FX(0) + FY(1) −FXY(0, 1)) = 0.218 75.
..
Continuous X and Y
Wind speed is a typical example of a continuous stochastic variable that has
both an X and a Y component. If we regard wind as a three-dimensional phe-
nomenon, it also has a Z component. Wind speed has this in common with any
other geometry related stochastic variable: it may be decomposed into com-
ponents by coordinates. Conversely, any pair (X, Y) of continuous stochastic
variables has a joint cumulative probability distribution FXY, and a joint prob-
ability density fXY.
Rule 8.2.6 If (X, Y) is a pair of continuous variables, with probability den-
sities f and cumulative densities F, then
FXY(A, B) = P(X ≤A and Y ≤B)
=
∫
A
−∞∫
B
−∞
fXY(x, y)
FX(x) = FXY(x, ∞) and FY(y) = FXY(∞, y).
Notice that it does not matter if we include the end points or not, since for
continuous stochastic variables all point probabilities are zero. The marginal
probability distributions are
fX(x) = ∫
∞
−∞
fXY(x, y) dy = d
dxFX(x)
fY(y) = ∫
∞
−∞
fXY(x, y) dx = d
dyFY(y)


8 Stochastic Variables II
whereas the conditional probability distributions are
f|Y=y(x) = fXY(x, y)
fY(y)
f|X=x(y) = fXY(x, y)
fX(x)
when the denominator differs from 0.
See Figure 8.7 for different illustrations of bivariate probability distributions.
Before we proceed, we will write up the rules for two continuous stochastic
variables, analogous to Rule 8.2.4:
Rule 8.2.7 If (X, Y) is a pair of continuous stochastic variables, then
P(X ≤a, Y ≤b) = FXY(a, b) = ∫
b
−∞∫
a
−∞
fXY(x, y) dx dy
P(X > a, Y > b) = 1 −FX(a) −FY(b) + FXY(a, b)
P(W ∈⟨a, b] × ⟨c, d]) = FXY(b, d) −FXY(a, d) −FXY(b, c) −FXY(a, c).
For general areas, the rule is stated in Rule 8.2.8. Notice that this rule requires
multivariate integration.
–2
0
2
4
6
8
10
–2
0
2
10
10
10
10
0.00
0.00
0.01
0.02
0.00
0.01
0.02
0.01
0.02
5
5
5
5
0
0
0
0
10
10
10
10
10
10
1.0
1.0
0.5
0.5
0.0
0.0
5
5
5
5
5
5
0
0
0
0
0
0
4
6
8
10
Level plots.
Conditional: f|x and f|y.
Cumulative, FXY (x, y).
FXY, FX, and FY .
Distribution, fXY (x, y).
With fX, and fY .
Figure .Illustrations of bivariate probability distributions.

8.2 Two- and Multi-variable Probability Distributions∗

Rule 8.2.8* If D ⊂ℝ2, then
P((X, Y) ∈D) = ∬D
fXY(x, y) dA.
Example 8.2.9 Loading the HTML code of Sondromatic Ltd’s web pages takes
between 0 and 1 milliseconds. The logo is loaded from a different server, and
this loading also takes between 0 and 1 milliseconds. The loading times are a
stochastic variable pair, X and Y, with joint probability distribution fXY(x, y) =
6(y −x)2 in the unit square [0, 1] × [0, 1].
1) Find the cumulative probability distribution FXY.
2) Find the probability that the HTML code loads in less than 0.5 milliseconds
and that the logo loads in less than 0.7 milliseconds.
3) Find the probability that the sum of the HTML code and logo loading times
is less than 1 millisecond.
4) Find the marginal cumulative probability distributions FX and FY.
5) Find the marginal probability distributions fX and fY.
Answers:
(1) FXY(x, y) = ∫
y
−∞∫
x
−∞
fXY(z, w) dz dw
= ∫
y
0 ∫
x
0
6(w −z)2 dz dw (since X, Y ≥0)
= 2x3y −3x2y2 + 2xy3.
(2) We are finding the probability that 0 ≤X ≤0.5 and 0 ≤Y ≤0.7. See Fig-
ure 8.8. The simplest method is using FXY.
P(X ≤0.5, Y ≤0.7) = FXY(0.5, 0.7) = 0.150 5.
(3) Here, we want to find the probability that X + Y ≤1. See Figure 8.9. Since
this area is not rectangular, we can’t use the cumulative distribution FXY.
We recall that 0 ≤X, Y ≤1, and integrate fXY over indicated area.
P(X + Y ≤1) = ∫
1
0 ∫
1−x
0
fXY dy dx
= ∫
1
0 ∫
1−x
0
6(y −x)2 dy dx = 1
2.


8 Stochastic Variables II
1.0
1.0
0.5
0.5
(a) The area [0,0.5] × [0,0.7].
(b) The graph of fXY over the area.
1.0
0.5
0.0
0
1
2
1.0
0.5
0.0
Figure .fXY over a rectangular area.
(b) The graph of fXY over the area.
1.0
1.0
0.5
0.5
(a) 0 ≤X, Y and X + Y ≤1.
6
4
2
0
0.0
0.5
1.0
0.0
0.5
1.0
Figure .fXY over a triangular area.
(4) FX(x) = FXY(x, ∞) = FXY(x, 1) (since Y ≤1)
= 2x3 ⋅1 −3x2 ⋅12 + 2x ⋅13 = 2x3 −3x2 + 2x
FY(y) = FXY(∞, y) = FXY(1, y) (since X ≤1)
= 2 ⋅13y −3 ⋅12y2 + 2 ⋅1y3 = 2y −3y2 + 2y3.
(5) fX(x) = 𝜕
𝜕xFX(x) = 𝜕(2x3 −3x2 + 2x)
𝜕x
= 6x2 −6x + 2
fY(y) = 𝜕
𝜕yFY(y) = 𝜕2y −3y2 + 2y3
𝜕y
= 2 −6y + 6y2.

8.2 Two- and Multi-variable Probability Distributions∗

Example 8.2.10 In Windy Bay, the wind always comes from some southeast-
ern direction. Let Z = (X, Y), where X is the eastern component, and Y is the
southern. The joint probability density is fZ(x, y) = 4xye−(x2+y2) for x, y ∈[0, ∞).
(1) Find the cumulative probability density FZ(x, y).
(2) Find the cumulative marginal probability densities FX(x) and FY(y).
(3) Find the marginal probability densities fX(x) and fY(y).
(4) Find the probability that the absolute wind speed is less than r.
Answers:
(1) FZ(x, y) = ∫
x
−∞∫
y
−∞
fZ(z, w) dw dz
= ∫
x
0 ∫
y
0
fZ(z, w) dw dz (since fZ(x, y) = 0 when x, y < 0)
= ∫
x
0 ∫
y
0
4ze−z2we−w2 dw dz = 4 ∫
x
0
ze−z2
∫
y
0
we−w2 dw dz
= 4 ∫
x
0
ze−z2 dz × ∫
y
0
we−w2 dw (see the calculation in 7.3.6)
= 4 × 1 −e−x2
2
× 1 −e−y2
2
=
(
1 −e−x2) (
1 −e−y2)
.
(2) FX(x) = FZ(x, ∞) = 1 −e−x2.
FY(y) = FZ(∞, y) = 1 −e−y2.
(3) We may find these magnitudes in either of two ways, and will show both.
r Method 1, finding fX and fY by differentiating FX and FY:
fX(x) = 𝜕
𝜕xFX(x) = 𝜕
𝜕x
(
1 −e−x2)
= 2xe−x2.
fY(y) = 𝜕
𝜕yFY(y) = 𝜕
𝜕y
(
1 −e−y2)
= 2ye−y2.
r Method 2, finding fX and fY by integrating fXY:
fX(x) = ∫
∞
−∞
fZ(x, y) dy = ∫
∞
0
4xye−(x2+y2) dy.
= 4xe−x2
∫
∞
0
ye−y2 dy = 4xe−x2 × 1
2 = 2xe−x2
fX(x) = ∫
∞
−∞
fZ(x, y) dx = 2ye−y2.


8 Stochastic Variables II
(4) Here, we employ Rule (8.2.8) and integration from multivariate calculus:
P(|Z| ≤r) = P(X2 + Y 2 ≤r2) = ∬x2+y2≤r
fZ(x, y) dA
= ∫
r
0 ∫
√
r2−x2
0
4xye−(x2+y2) dy dx
= ∫
r
0
2xe−x2 ⎛
⎜
⎜⎝∫
√
r2−x2
0
2ye−y2 dy
⎞
⎟
⎟⎠
dx
= ∫
r
0
2xe−x2 (
1 −ex2−r2)
dx = ∫
r
0
2x
(
e−x2 −e−r2)
dx
= 1 −(1 + r2)e−r2.
..
Covariance and Correlation
Covariance and correlation are as important to studying pairs of stochastic vari-
ables as they are to the treatment of pairwise data. They tell us how tight and
close the two magnitudes X and Y are.
Definition 8.2.11 The covariance (“co-variance”)
𝜎XY = E[(X −𝜇X)(Y −𝜇Y)].
As is so often the case, the following formula for practical calculation differs
from the formula used for the definition, and is simpler.
Rule 8.2.12 𝜎XY = E[XY] −E[X] ⋅E[Y], where
E[XY] =
⎧
⎪
⎨
⎪⎩
∫
ℝ2
xyfXY(x, y) dA
(continuous)
∑
x,y
xyfXY(x, y)
(discrete).
We will first look at the following discrete example.
Example 8.2.13 (Continuation of Examples 8.2.3 and 8.2.5)
𝜇X =
∑
x
xfX(x)
= 0 × 0.062 5 + 1 × 0.25 + 2 × 0.375 + 3 × 0.25 + 4 × 0.062 5 = 2

8.2 Two- and Multi-variable Probability Distributions∗

𝜇Y =
∑
y
yfY(y) = 0 × 0.316 406 + 1 × 0.421 875 + 2 × 0.210 938
+ 3 × 0.046 875 + 4 × 0.003 906 25 = 1
E[XY] =
∑
x,y
xyfXY(x, y) =
∑
x
(
x ×
∑
y
yfXY(x, y)
)
= 0 ×
(
∑
y
yfXY(0, y)
)
+ 1 × (0 × 0.031 25 + 1 × 0.093 75 + 2 × 0.093 75 + 3 × 0.031 25 + 4 × 0)
+ 2 × (0 × 0.093 75 + 1 × 0.187 5 + 2 × 0.093 75 + 3 × 0 + 4 × 0)
+ 3 × (0 × 0.125 + 1 × 0.125 + 2 × 0 + 3 × 0 + 4 × 0)
+ 4 × (0 × 0.062 5 + 1 × 0 + 2 × 0 + 3 × 0 + 4 × 0)
= 1.5
𝜎XY = E[XY] −𝜇X𝜇Y = 1.5 −2 × 1 = −0.5.
Example 8.2.14
(Continuation of Example 8.2.9) What is the covariance
between the load time of the HTML code and of the logo of Sondromatics’
front page?
Answer: We calculate 𝜇X, 𝜇Y, and E[XY], and insert the numbers into formula
(8.2.12) for 𝜎XY:
𝜇X = E[X] = ∫
∞
−∞
xfX(x) dx = ∫
1
0
x(6x2 −6x + 2) dx = 1
2
𝜇Y = E[Y] = ∫
∞
−∞
yfY(y) dx = ∫
1
0
y(2 −6y + 6y2) dy = 1
2
E[XY] = ∬ℝ
xyfXY(x, y) dA = ∫
1
0 ∫
1
0
6xy( y −x)2 dx dy = 1
6
𝜎XY = E[XY] −𝜇X𝜇Y = 1
6 −1
2 ⋅1
2 = −1
12.
Example 8.2.15
(Continuation of Example 8.2.10) What is the covariance
between the southern and the eastern wind components?
Answer: We will make use of the fact that ∫∞
0
z2e−z2 dz =
√
𝜋
4 . This is a tough
integral, so do the calculation by means of a calculator or other such tool. We
used Mathematica®, to obtain an exact answer.
𝜇X = ∫
∞
0
xfX(x) dx = ∫
∞
0
x ⋅2xe−x2 dx =
√
𝜋
2
𝜇Y = ∫
∞
0
yfY(y) dy = ∫
∞
0
y ⋅2ye−y2 dy =
√
𝜋
2


8 Stochastic Variables II
E[XY] = ∫
∞
0
∫
∞
0
xyfXY(x, y) dx dy = ∫
∞
0
∫
∞
0
xy ⋅4xye−(x2+y2) dx dy
= 4 ∫
∞
0
x2e−x2 dx ⋅∫
∞
0
y2e−y2 dy
= 4 ⋅
√
𝜋
4 ⋅
√
𝜋
4 = 𝜋
4
𝜎XY = E[XY] −𝜇X𝜇Y = 𝜋
4 −
√
𝜋
2 ⋅
√
𝜋
2 = 0.
The covariance tells us how the two variables are related, but its primary
function is instrumental rather than being an end measure in itself. If we were to
scale the variables X and Y by a factor of r, we do that by scaling 𝜎XY by a factor
of r2. For an and-in-itself measure of relation, we would like it to be invariant
when we scale the variables, or convert from (say) millimeters to inches. The
correlation 𝜌XY is such a measure.
Definition 8.2.16 The correlation 𝜌XY is given by
𝜌XY = 𝜎XY
𝜎X𝜎Y
and is a number between −1 and 1 expressing the strength of the linear rela-
tion between X and Y.
In addition to our previous calculations, we need the standard deviations 𝜎X
and 𝜎Y.
Example 8.2.17
(Continuation of Example 8.2.14) What is the correlation
between the loading times for the HTML code and for the logo at Sondromat-
ics’ front page?
Answer: We calculate the variance and standard deviations of X and Y, and
insert into formula (8.2.16) for 𝜌XY:
E[X2] = ∫
∞
−∞
x2fX(x) dx = ∫
1
0
x2(6x2 −6x + 2) dx = 11
30
Var(X) = E[X2] −𝜇2
X = 11
30 −
(
1
2
)2
= 7
60
𝜎X =
√
Var(X) =
√
7
60
E[Y 2] = ∫
∞
−∞
y2fY(y) dy = ∫
1
0
y2(2 −6y + 6y2) dx = 11
30
Var(Y) = E[Y 2] −𝜇2
Y = 11
30 −
(
1
2
)2
= 7
60

8.2 Two- and Multi-variable Probability Distributions∗

𝜎Y =
√
Var(Y) =
√
7
60
𝜌XY = 𝜎XY
𝜎X𝜎Y
=
−1
12
√
7
60 ⋅
√
7
60
= −5
7.
We conclude this section with the following definition.
Definition 8.2.18 Z is an n-dimensional stochastic variable when its sam-
ple space is U = ℝn. We write Z = ⟨Z1, … , Zn⟩, where Z ∼F and Zi ∼Fi for
each of i = 1, … , n.
..
Independence
The concepts conditional probability and independent sets translate seamlessly
into the context of stochastic variables. Note that even though the definition
of independence is derived from the concept of independence for sets, (5.4.3)
and (5.4.4), we prefer the following characterization, which we will let be our
working definition of independence for stochastic variables.
Definition 8.2.19 If X and Y are independent stochastic variables, and Z =
(X, Y), then Fz(x, y) = Fx(x) ⋅Fy(y) for all x and y.
Rule 8.2.20
If X and Y have probability distributions respectively fx and
fy, we may also characterize independence between X and Y by the fact that
fz(x, y) = fx(x) ⋅fy(y), or by the fact that f|x(y) = fY(y).
This “product check” for independence applies to independence between
multiple stochastic variables as well.
Example 8.2.21 (X, Y) is given by the following table. Determine whether X
and Y are independent.
HHHHH
y
x
1
2
1
0.5
0
2
0
0.5
Answer: We see that fX(x) = 0.5 for x = 1, 2, and that fY(y) = 0.5 for x = 1, 2.
The product then becomes 0.25 in all four rectangles, and thus different from
fXY(x, y). Since, then, fX ⋅fY ≠fXY, we conclude that X and Y are not indepen-
dent. Or more briefly: that they are dependent.


8 Stochastic Variables II
Example 8.2.22 (X, Y, Z), and fXYZ(x, y, z) = e−(x+y+z) for x, y, z ∈[0, ∞). Are
X, Y, and Z independent?
Answer: We have that
fX(x) = ∫
∞
0
∫
∞
0
e−(x+y+z) dy dz = e−x
and, correspondingly, fY(y) = e−y and fZ(z) = e−z, which means that fXYZ = fX ⋅
fY ⋅fZ, which implies that X, Y, and Z are independent.
An implication worth noting is the following rule.
Rule 8.2.23 If X and Y are independent, then 𝜎XY = 0. Conversely, if 𝜎XY ≠0,
then X and Y are dependent.
Note that the implication is one-way, and that you cannot conclude from
𝜎XY = 0 that X and Y must be independent. See assignment 11.
.
The Sum of Independent Stochastic Variables
Sometimes, we are interested in more than a single stochastic variable Xi. In
hypothesis testing (Chapter 14), we need to look at the difference between two
stochastic variables X and Y to calculate the probability that X > Y.
In the game of Monopoly, we use two dice. What interests us is not the value
of each individual die, but the sum. In Yatzee “chance”, we similarly care about
the sum of 5 or 6 dice, but not about outcomes of the individual dice. How are
these sums distributed? That is: what are the probabilities of the different sums?
As opposed to the individual dice, whose values are uniformly distributed, the
sums of n dice are concentrated around the expected value of the sum.
Rule 8.3.1 If X and X1, … , Xn are stochastic variables with expected values
respectively 𝜇X and 𝜇1, … , 𝜇n, and X = a1 ⋅X1 + ⋯+ an ⋅Xn, then
𝜇X = a1𝜇1 + ⋯+ an𝜇n.
If the variables X1, … , Xn are independent, and the variances are 𝜎2
X and
𝜎2
1, … , 𝜎2
n, then
𝜎2
X = a2
1𝜎2
1 + ⋯+ a2
n𝜎2
n.
How to remember this formula? Think Pythagoras!

8.4 The Law of Large Numbers∗

Example 8.3.2
A toss of a D4 die has expected value 𝜇= 5∕2 and stan-
dard deviation 𝜎=
√
5∕4. A toss of a D6 die has expected value 𝜇= 7∕2 and
𝜎=
√
35∕12. What is the expected value and the standard deviation of the sum,
if we toss one D4 and one D6?
Answer: The two tosses are independent stochastic variables X1 and X2, with
𝜇1 = 5∕2 and 𝜇2 = 7∕2, and 𝜎1 =
√
5∕4 and 𝜎2 =
√
35∕12. The outcome of
the two tosses is the stochastic variable X = X1 + X2. We employ the formu-
las above, and get
𝜇= 𝜇1 + 𝜇2 = 5
2 + 7
2 = 6
𝜎2 = 𝜎2
1 + 𝜎2
2 = 5
4 + 35
12 = 25
6
𝜎=
√
𝜎2 =
5
√
6 = 5
√
6
6 .
Rule 8.3.3 Let X1, … , Xn be independent stochastic variables with expected
values 𝜇1, … , 𝜇n and common standard deviation 𝜎. The mean value of the
variables is X = (X1 + ⋯+ Xn)∕n. Then
𝜇X = 𝜇1 + ⋯+ 𝜇n
n
and
𝜎X =
𝜎
√
n
.
.
The Law of Large Numbers∗
In this section, we will present a few probability theoretical theorems that pro-
vide a theoretical background for later and more advanced topics in statistics,
like those in the inference in this book. This theoretical aspect is singled out in
this one section, so that students who plan to take statistics further and deeper
can pause here to go into proofs, whereas the students who aim more for appli-
cation without care for deeper mathematical proof may just keep the results
here “for reference”.
Rule 8.4.1 Markov’s inequality: If X ≥0, then
P(X ≥a) ≤E[X]
a
.
Proof: Define Y to be 0 when 0 ≤X < a, and a when X ≥a. Since X ≥Y then
E[X] ≥E[Y]. This means that
E[X] ≥E[Y] = P(Y = 0) ⋅0 + P(Y = a) ⋅a = P(Y = a) ⋅a = P(X ≥a) ⋅a.
Divide both ends by a, and you get Markov’s inequality.


8 Stochastic Variables II
Rule 8.4.2
Chebyshev’s inequality: For a stochastic variable X with
expected value E[X] = 𝜇and variance E[|X −𝜇|2] = 𝜎2,
P[|X −𝜇| ≥k𝜎] ≤1
k2 .
Proof: Define the positive stochastic variable Y = |X −𝜇|2. It has expected
value E[Y] = E[|X −𝜇|2] = 𝜎2. Markov’s inequality tells us that
P[Y ≥𝜀2] ≤E[Y]
𝜀2
= 𝜎2
𝜀2 .
Since x2 > y2 when x > y > 0, it then follows that
P[|X −𝜇| ≥𝜀] = P[|X −𝜇|2 ≥𝜀2] ≤𝜎2
𝜀2 .
Let 𝜀= k𝜎. Then
P[|X −𝜇| ≥k𝜎] ≤
𝜎2
(k𝜎)2 = 1
k2 .
This result – or more precisely the middle result P[|X −𝜇| ≥𝜀] ≤𝜎2∕𝜀2
from the proof – is handy in proving The Law of Large Numbers.
Rule 8.4.3 Let X1, X2, … , Xn, … be independent stochastic variables with
the same probability distribution with expected value 𝜇< ∞and variance
𝜎2 < ∞, and let Xn = 1
n
∑n
k=1 Xk. Then
lim
n→∞P(|Xn −𝜇| ≥𝜀) = 0 for all 𝜀> 0.
Proof: According to Rule 8.3.1, we get that 𝜇Xn = 𝜇and that 𝜎2
Xn
= 1
n𝜎2. Then
P(|Xn −𝜇| ≥𝜀) ≤1
n ⋅𝜎2
𝜀2 ,
which goes to 0 when n →∞.
The Law of Large Numbers exists in many forms, many of them stronger than
the version we just proved. For those who plan to take statistics further, the
following formulations are useful. We list them without proof.

8.5 Exercises

Rule 8.4.4
Let X1, X2, … , Xn, … be independent stochastic variables with
the same probability distribution with expected value 𝜇X < ∞. Let Xn =
1
n
∑n
k=1 Xk. Then
limn→∞P(|Xn −𝜇X| ≥𝜀) = 0 for all 𝜀> 0 (Weak Law of Large Numbers)
P(limn→∞Xn = 𝜇X) = 1
(Strong Law of Large Numbers).
.
Exercises
Mixed Distributions
1
In the subproblems below, X is a mixed distribution with k components
Xk, with respective weights wk. For each subproblem, find 𝜇X, Var(X), and
P(X ≥0).
(a) 2 components. w1 = 0.2, w2 = 0.8. 𝜇1 = −3, 𝜇2 = 5, Var(X1) = 9,
Var(X2) = 16, P(X1 ≥0) = 0.2, P(X2 ≥0) = 0.9.
(b) 2 components. w1 = 0.9, w2 = 0.1. 𝜇1 = 7, 𝜇2 = 11, Var(X1) = 50,
Var(X2) = 50, P(X1 ≥0) = 0.11, P(X2 ≥0) = 0.11.
(c) 2 components. w1 = 0.5, w2 = 0.5. 𝜇1 = 5, 𝜇2 = −5, Var(X1) = 25,
Var(X2) = 25, P(X1 ≥0) = 1, P(X2 ≥0) = 0.
(d) 3 components. w1 = 0.1, w2 = 0.6, w3 = 0.3. 𝜇1 = 2, 𝜇2 = 4, 𝜇3 =
8, Var(X1) = 4, Var(X2) = 8, Var(X3) = 16, P(X1 ≥0) = 0.841 345,
P(X2 ≥0) = 0.921 35, P(X3 ≥0) = 0.977 25.
(e) 3 components. w1 = 0.9, w2 = 0.09, w3 = 0.01. 𝜇1 = 1, 𝜇2 = 2, 𝜇3 =
100, Var(X1) = 1, Var(X2) = 1, Var(X3) = 1, P(X1 ≥0) = 0.841 345,
P(X2 ≥0) = 0.977 25, P(X3 ≥0) = 1.
2
In the subproblems below, there is one discontinuity. Graph Fc, Fd, and FX,
and find 𝜇X and Var(X).
(a) Continuous: wc = 0.7, Xc ∼f (x) = 0.1 for 0 ≤x ≤10.
Discrete: wd = 0.3, and p4 = 1.
(b) Continuous: wc = 0.15, Xc ∼f (x) = 2x for 0 ≤x ≤1.
Discrete: wd = 0.85, and p0 = 1.
(c) Continuous: wc = 0.6, Xc ∼f (x) = 0.5 sin(x) for 0 ≤x ≤𝜋.
Discrete: wd = 0.4, and p𝜋= 1.
3
We have a mixed distribution with two discontinuities. The continous
part is given by wc = 0.2, and Xc ∼f (x) = 0.1 for 0 ≤x ≤10. The discrete
part is given by wd = 0.8, and the two discontinuities are p3 = 0.375 and
p9 = 0.625.
Graph Fc, Fd, and F, and find 𝜇X and Var(X).


8 Stochastic Variables II
4
The artist Sandra has insured her concert tour. Insurance agents Beowulf
have calculated with a 12% probability that the tour will be in the red, and
that, in such a case, the loss will be distributed g(x) = 5 × 10−7e−5×10−7x
(in Section 10.3 we will get to know this as the exponential distribution
with 𝜆= 5 × 10−7). The insurance covers the entire loss. Let X be the pay-
ment from Beowulf to Sandra. Beowulf charges their policies at a price
of 1.7 times the expected payment, plus 0.1 times the standard deviation.
How much are they charging Sandra for her policy?
5
Find the charge for Sandra’s policy, should the payment be capped at
5 000 000.
Two- and Multi-variable Probability Distributions
6
For Z = (X, Y) given by following table, find the marginal probabilities,
P(X + Y = 4), and the correlation 𝜌xy:
X = 1
X = 2
X = 3
Y = 1
0.05
0.05
0.3
Y = 2
0.05
0.25
0.05
Y = 3
0.2
0.05
0
7
Soren K. has studied previous exams in German philosophy, and has dis-
covered that the lecturer seems to love the two obscure philosophers Max
Stirner and Karl Werder. Soren sets up a table he believes expresses the
joint probabilities for the respective number of questions on Stirner (X)
and on Werder (Y):
X = 1
X = 2
X = 3
Y = 2
0
0.1
0.2
Y = 3
0.05
0.15
0.1
Y = 4
0.15
0.2
0.05
(a) Write up the table for the cumulative probability FXY.
(b) Find the probability that Soren gets a total of 5 questions about these
two philosophers.
(c) Find the conditional probabilities P(X = 1|X + Y = 5), P(X = 2|X +
Y = 5), and P(X = 3|X + Y = 5), and write them into a table.
(d) What do you find, when you calculate P(X = a|X + Y = 5)? (Textual
answer; not calculation.)
8
You have a bag of one each of the dice D4, D6, D8, D10, D12, D20. You sample
a die, and toss it. Let X be the number of faces on the die, and let Y be the
value of the toss. Are X and Y independent?

8.5 Exercises

9
Z = (X, Y) ∼fZ(x, y) = 4
5
(2 −x −y3) for x, y ∈[0, 1]. Find the marginal
probabilities fx and fy, the covariance 𝜎xy, and determine whether X and
Y are independent.
10
Z = (X, Y) ∼fZ(x, y), which is 1
𝜋inside the circle x2 + y2 = 1, and 0 other-
wise (where 𝜋= 3.141 59 …).
(a) Find the marginal probability distributions fx and fy.
(b) Are X and Y independent?
(c) Find the conditional probability distributions f|Y=y(x) and f|X=x(y).
11
Let X be a stochastic variable taking the values −2, −1, 0, 1, 2 with proba-
bility 1
5 each, and let Y = X2. Are X and Y independent? What is 𝜌XY?
The Sum of Independent Stochastic Variables
12
Find 𝜇Z and 𝜎Z, when ...
(a) Z = X −Y, 𝜇X = 4, 𝜎X = 3, 𝜇Y = −3, 𝜎Y = 2;
(b) Z = X1 + X2 + X3, and 𝜇X1 = 1, 𝜇X2 = 2, 𝜇X3 = 3, whereas 𝜎X1 = 3,
𝜎X2 = 4, 𝜎X3 = 12;
(c) Z = ∑6
k=1 Xk and 𝜇Xk = k and 𝜎Xk =
√
k;
(d) Z = 1
2X and 𝜇X = 14 and 𝜎X = 4;
(e) Z = kX and 𝜇X = 𝜇and 𝜎X = 𝜎;
(f) Z = ∑6
k=1
1
k Xk and 𝜇Xk = k and 𝜎Xk =
√
k.
13
Let X, Y be independent stochastic variables with standard deviation
respectively 𝜎X and 𝜎Y, and let Z = aX + (1 −a)Y. Let 𝜎Z be Z’s standard
deviation. For which value(s) of a is 𝜎Z the smallest?




Discrete Distributions
CONTENTS
9.1
How to Read the Overview, 197
9.2
Bernoulli Distribution, bernp, 199
9.3
Binomial Distribution, bin(n,p), 202
9.4
Hypergeometric Distribution, hyp(n,S,N), 207
9.5
Geometric and Negative Binomial Distributions, nb(k,p), 210
9.6
Poisson Distribution, pois𝜆, 213
9.7
Discrete Distributions: Overview, 216
9.8
Exercises, 217
In this chapter, we will look at some key discrete probability distributions. With
the exception of the uniform distribution, they are built from binary events,
which are events with only two possible outcomes: ⊤(positive outcome) and ⊥
(negative outcome). These distributions then state the probability of the num-
ber of positive or negative outcomes under different counting scenarios.
.
How to Read the Overview
Each distribution begins with a box with the most commonly used properties
of the distribution. If the distribution has its own symbol 𝜓, we will use that
to designate it, and the uppercase version of the symbol, Ψ, for the cumulative
distribution function. If not, we will use the name and NAME in these roles. By
means of the distribution’s parameters p1, p2, … , pk, we may then describe
r the probability distribution (pdf) 𝜓(p1,…,pk)(x) or name(p1,…,pk)(x)
r the cumulative probability distribution (CDF) Ψ(p1,…,pk)(x) or NAME(p1,…,pk)
(x)
r the inverse cumulative distribution (iCDF) Ψ−1
(p1,…,pk)(x) or NAME−1
(p1,…,pk)(x)
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


9 Discrete Distributions
r the expected value 𝜇X = E[X], together with a formula for calulating it from
the parameters p1, … , pk
r the variance 𝜎2
X, together with a formula for calulating it from the parameters
p1, … , pk.
We also show how to calculate the properties of the distribution in
Mathematica®. Where possible we will also show how to calculate the cumu-
lative probability distribution in some higher-end popular graphic calculators
from CASIO®, TI®, and HP®.
In Mathematica, the distributions are invoked by the name of the distribu-
tion, followed by a parenthetical list of its parameters:
Mathematica: NameOfDistribution[p1, … , pk].
The key commands for calculating the distribution in Mathematica are:
r PDF[NameOfDistribution[p1, … , pk], x] gives the probability distribution
f (x).
r CDF[NameOfDistribution[p1, … , pk], x] gives the cumulative probability
distribution F(x), which equals P(X ≤x).
r InverseCDF[NameOfDistribution[p1, … , pk], x] gives F−1(x).
r Probability[condition on x, x ≈NameOfDistribution[p1, … , pk]] gives P(X ∈
{x| condition on x}); the condition on x may for instance be x < a or a ≤x < b.
To get the ≈sign, type (esc)dist(esc).
r Mean[NameOfDistribution[p1, … , pk]] gives 𝜇X, also known as E[X].
r Variance[NameOfDistribution[p1, … , pk]] gives 𝜎2
X.
r StandardDeviation[NameOfDistribution[p1, … , pk]] gives 𝜎X.
r RandomVariate[NameOfDistribution[p1, … , pk]] gives a random number,
sampled according to the probabilities indicated by the distribution.
For a general exposition of discrete probability distributions, see Section 7.2.
Sometimes, direct calculations on distributions can be very demanding, or
even too demanding, given the tools at hand. For that reason, we often employ
approximations to simplify calculations. Even advanced tools like Mathematica
or R have their limitations: binomial expressions like ∑n
k=0
(n
k
) ⋅f (k) are not too
difficult to handle as long as n is reasonable, but Mathematica may take several
hours to complete if n = 1 000 000. So do make use of the approximations where
this is expedient. You’ll get there faster, and with sufficient precision.
Whilst there are many excellent packages available,1 we will focus on Math-
ematica as our advanced tool of choice, as it has a simple and freely available
interface online at
http://www.wolframalpha.com
1For the advanced user, we recommend getting acquainted with the freely available tool R.

9.2 Bernoulli Distribution, bernp

This book has web support, which includes calculator guides, at
http://bayesians.net
.
Bernoulli Distribution, bernp
Bernoulli distribution: A Bernoulli trial X with parameter p is a single trial
whose outcome is either success ⊤or failure ⊥, where P(⊤) = p. Then,
X ∼bernp, a probability distribution with a single parameter: p.
pdf: bernp(x) =
⎧
⎪
⎨
⎪⎩
1 −p
x = 0
p
x = 1
0
else
CDF: BERNp(x) =
⎧
⎪
⎨
⎪⎩
0
x < 0
1 −p
0 ≤x < 1
1
p ≥1
Expected value: 𝜇X = p
Variance: 𝜎2
X = p(1 −p)
Binomial: bernp = bin(1,p)
Mathematica: BernoulliDistribution[p]
bern0.3(x)
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0
BERN0.3(x)
1
0.2
0.4
0.6
0.8
1.
0
..
Fair Odds
When you play for money, the essence of the game is a bet. So what is the
fair price for joining a bet where the probability of winning £K is p? And what
are odds?
Definition 9.2.1 Odds is the proportion of the probability of winning to the
probability of losing:
Odds for = of = P(⊤)∕P(⊥) = p∕(1 −p)
Odds against = oa = P(⊥)∕P(⊤) = (1 −p)∕p.


9 Discrete Distributions
Calculate backwards, and the odds will give you back the probability of win-
ning. Let of = a : b. Then
p = 1∕(oa + 1) = 1 −1∕(of + 1) = b∕(a + b).
Odds is a traditional way of stating betting chances by a number, and predated
Pascal and Fermat’s invention of probability by roughly a hundred years.
It is customary to write the odds ratio a∕b as a : b or as a −b. If possible, one
chooses low integers for a and b, or chooses one of the numbers to be 1. So we
would not write odds as 3.25 : 2.5, but would rather multiply both sides by 4,
and write the odds as 13 : 10. Alternatively, we would divide both sides by b,
and write 1.3 : 1.
A bookmaker’s odds tells you how many times your bet gets paid out if you
win. If the odds are a : b (against; it is usually “odds against” if nothing else is
specified), and you have bet £K, your winnings will be £ K
b (a + b). So if the odds
are even, that is, equal probability of winning and losing, 1 : 1, the pay-out for
a £100 bet is 100
1 (1 + 1) = £200.
Note 1 Continental European bookmakers do not use odds ratios in the way of
the anglophone world, but prefer to state the winnings as a multiple of the bet.
Their odds is this multiple. This number equals oa + 1, and thus equals 1∕p.
Note 2
The bookmaker is himself no gambler, but a businessman striving
to maintain a steady living. His odds are therefore not stipulated on what he
believes to be the probabilities of the different outcomes. Instead, the book-
maker will base his odds on how many people make the bets, so that what he
gets in exceeds what he pays out, no matter what the outcome. This means that
if you do know the true probability that the horse Silky White will win the next
horse race better than anyone else does, your expected payout is positive. But
before you wager your student loan on a horse, remember the thousands of
broke gamblers who were assured they knew the outcomes of past horse races.
Never gamble what you can’t afford to lose!
The bookmaker ideally sets his odds in the same way Black and Scholes’ 1973
formula dictates the right price for financial derivatives.
Rule 9.2.2 The fair price for a gamble with payoff G, and probability p to
win, is p ⋅G.

9.2 Bernoulli Distribution, bernp

Example 9.2.3 The fair odds on Silky White is 3 : 2 against.
1) Find oa as a decimal number.
2) Find of as a decimal number.
3) Find the continental European odds.
4) Find the probability p that Silky White wins.
5) What is a fair price for the bet where you get £100 if Silky White wins?
6) If you bet £100 with these odds, and Silky White wins, how large is your
payout?
7) A British bookmaker offers odds of 7 : 4 against. Does it pay to place a bet
on Silky White with him?
Answers:
1) oa = 3∕2 = 1.5.
2) of = 1∕oa = 0.667.
3) Continental European odds = oa + 1 = 1.5 + 1 = 2.5.
4) p = b∕(a + b) = 2∕(3 + 2) = 0.4.
5) p ⋅G = 0.4 ⋅100 = £40.
6) 100∕0.4 = £250.
7) With this bookmaker, you are paid 7+4
4
= 2.75 times your bet if you win,
which is in excess of the 2.5 multiplier of a fair bet, meaning this bet pays
better for you to play than a fair bet.
..
Bernoulli Process
The Bernoulli distribution for a single trial is rarely seen in practical application.
We are more interested in repeated trials, in what we call a Bernoulli process.
We define the following.
Definition 9.2.4 A Bernoulli process with parameter p is a sequence of tri-
als where
1) each trial has exactly 2 possible outcomes: ⊤and ⊥;
2) P(⊤) = p for each trial;
3) the outcomes of the trials are independent.
A single Bernoulli trial is simply a trial of whether a certain event occurs or
not. The typical examples are from the gaming world in the tossing of a coin
or betting on a roulette colour. But daily life furnishes us with equally good
examples: checking whether a light bulb is dead is a Bernoulli trial, asking a
girl out for a date is a Bernoulli trial, applying for a scholarship is a Bernoulli
trial. We have a Bernoulli process of n trials when we perform n identical but


9 Discrete Distributions
independent trials. Examples are five coin flips, or applying for three scholar-
ships. The context for the trials must be the same, yielding P(⊤) = p for all trials,
independently of the outcomes of the other trials.
Bernoulli trials are in themselves very easy to comprehend, but still the the-
ory built on their backs will have far-reaching consequences. The Law of Large
Numbers (8.4.3 and 8.4.4) for Bernoulli trials are central to our understanding
of probability, and lie at the base of the frequentist definition of probability.
Rule 9.2.5 Let X1, X2, … , Xn, … be independent Bernoulli trials with prob-
ability p of success, and let Zn = 1
n
∑n
k=1 Xk. The stochastic variable Zn is then
the proportion of successes after n Bernoulli trials.
limn→∞P(|Zn −p| ≥𝜀) = 0 when 𝜀> 0 (Bernoulli’s theorem)
P(limn→∞Zn = p) = 1
(Borel’s Law of Large Numbers).
.
Binomial Distribution, bin(n,p)
Binomial distribution: Given a Bernoulli process with parameter p
(probability of success), let the stochastic variable X be the number of ⊤in
n trials. Then, X ∼bin(n,p); this means X follows a binomial probability
distribution bin(n,p) with parameters n and p.
pdf: bin(n,p)(x) = (n
x
)px(1 −p)n−x
CDF: BIN(n,p)(x)
CASIO: BinomialPD(x, n, p)
BinomialCD(x, n, p)
HP: binomial(n, x, p)
binomial_cdf(n, p, x)
TI: binompdf(n, p, x)
binomcdf(n, p, x)
Mathematica: BinomialDistribution[n, p]
Expected value: 𝜇X = np
Variance: 𝜎2
X = np(1 −p)
Poisson approximation: poisnp (9.6) is good when n0.31p < 0.47
Normal approximation: 𝜙(𝜇X, 𝜎X) (10.1.5) is good when np(1 −p) > 5
bin( n,p) (x)
25
30
35
40
0.02
0.04
0.06
0.08
0.1
0.12
BIN( n,p) (x)
25
30
35
40
0.2
0.4
0.6
0.8
1.

9.3 Binomial Distribution, bin(n,p)

n = 13,p = 0.27:
2
4
6
8
10
12
0.05
0.1
0.15
0.2
μ = 3.51, σ = 1.6
n = 13,p = 0.5:
2
4
6
8
10
12
0.05
0.1
0.15
0.2
μ = 6.5, σ = 1.8
n = 13,p = 0.85:
2
4
6
8
10
12
0.1
0.2
μ = 11.05, σ = 1.29
..
Application: Repeated Sampling With Replacement
The binomial distribution describes the probabilities of repeated sampling
with replacement from Section 5.5, and we see that the distribution for-
mula bin(n,p)(x) is the formula for the probabilities for repeated sampling with
replacement of two kinds in Rule 5.5.5. Typical situations where this is useful
are as follows.
r Industrial: The rate of critical failure in the cars you produce is 0.8%. What
is the probability that more than 1% of 20 thousand new cars have critical
failures?
r Sports: Bayern Munich wins 83% of their Bundesliga games. What is the
probability that they win 9 out of the next 10?
r Medicine: If a disease is misdiagnosed as something else 10% of the time,
how probable is it that a doctor will misdiagnose exactly 2 out of his next
9 cases of this disease?
r Economics: Your company has submitted proposals for 14 different projects
this month, and they tend to win 40% of them. What is the probability that
your company will win 5 projects this month?
..
Calculating Binomial Distributions
Example 9.3.1
X ∼bin(7,0.34), binomially distributed with parameters n = 7
and p = 0.34. Find
1) 𝜇X
2) 𝜎X
3) P(X ∈{3, 4, 5})
4) P(X ≤2).
Answers:
1) 𝜇X = np = 7 ⋅0.34 = 2.38
2) 𝜎X =
√
np(1 −p) =
√
7 ⋅0.34 ⋅(1 −0.34) = 1.253
3) P(X ∈{3, 4, 5}) = BIN(7,0.34)(5) −BIN(7,0.34)(2) = 0.437 054
4) P(X ≤2) = BIN(7,0.34)(2) = f (2) + f (1) + f (0) = 0.555 284.


9 Discrete Distributions
p
q
Figure .Steps for a random walk.
Calculating binomial distributions is generally a straightforward application
for the formulas. There is no shortcut for exact calculations of cumulative
probability, but you may often end up doing less work if you remember that
P(X < a) + P(X = a) + P(X > a) = 1.
Example 9.3.2 X is binomially distributed with p = 0.9 and n = 20. What is
P(X ≤19)? Here, we can either sum the point probabilities from p0 up to and
including p19, or we can simply note that
P(X ≤19) = 1 −P(X > 19) = 1 −P(X = 20) = 1 −0.920 = 0.878 423.
A common error is to forget to include P(X = 0) in the sum.
..
Application: Random Walk
Simple random walk is a process on the integers, with probability p of the next
step being the current position +1, and probability q = 1 −p for −1, as illus-
trated in Figure 9.1. This is a close relative of the Bernoulli process, with alter-
natives −1 and +1 rather than 0 and 1. A popular illustration is that of a drunken
Irishman’s pub crawl, where a skew coin determines which pub he visits next:
the one up the street, or the one down the street.
The probability distribution of where the Irishman is after n steps with
p = 0.55 is illustrated in Figure 9.2 for n = 1, … , 8.
−4 −2
0
2
4
6
0.1
0.2
0.3
0.4
0.5
n = 1
−4 −2
0
2
4
6
0.1
0.2
0.3
0.4
0.5
n = 2
−4 −2
0
2
4
6
0.1
0.2
0.3
0.4
n = 3
−4 −2
0
2
4
6
0.1
0.2
0.3
n = 4
−4 −2
0
2
4
6
0.1
0.2
0.3
n = 5
−4 −2
0
2
4
6
0.1
0.2
0.3
n = 6
−4 −2
0
2
4
6
0.1
0.2
n = 7
−4 −2
0
2
4
6
0.1
0.2
n = 8
Figure .Probability distributions after n steps of the random walk.

9.3 Binomial Distribution, bin(n,p)

5
10
15
20
25
30
−2
−1
1
2
30 steps
50
100 150 200 250 300
−10
−5
5
10
15
20
25
30
300 steps
500 1000 1500 2000 2500 3000
50
100
150
200
250
3000 steps
Figure .The path of the random walk after a given number of steps.
The probability distribution for simple random walk is almost the same as
for the binomial distribution. The distribution formula for a random walk Xn
with parameter p (= the probability of +1), is then
P(Xn = x) = bin(n,p)
(x + n
2
)
.
The expected value is 𝜇n = E[Xn] = (2p −1)n, and the variance is 𝜎2
n =
4np(1 −p).
Sample random walks are usually illustrated by using the horizontal axis for
time and the vertical axis for position/value. Such an illustration may then look
like Figure 9.3 (p = 0.55).
Random walk and its continuous counterpart Brownian motion are used to
model everything from the motion of pollen in liquids to the movements of
stock markets.
Example 9.3.3 The stock of Goldum Ltd is in a market where it trades once
per day, and the share price follows a random walk with probability p = 0.51 of a
$1 increase, and a probability q = 0.49 of a $1 decrease. The price of one share
starts at $105. What is the probability that the price is less than $105 dollars
after 20 days have passed? What is the expected share price, and what is the
variance?
Answer: The share price in dollars equals Yn = Xn + 105 for a random walk X
starting at 0 with parameter p = 0.51, so we deduct 105 on both sides, and ask
the equivalent question of the probability that P(X20 < 0). The calculation:
P(X20 < 0) =
∑
x<0
P(X20 = x) =
∑
x<0
bin(20, 0.51)
(x + 20
2
)
=
∑
x<20
bin(20, 0.51)
(x
2
)
=
∑
x<10
bin(20, 0.51) (x)
=
9
∑
x=0
bin(20, 0.51) (x) = 0.377 056 ≈38%.


9 Discrete Distributions
The expected share price after 20 days is
E[Y20] = E[105 + X20] = 105 + 𝜇20 = 105 + (2 ⋅0.51 −1) ⋅20 = 105.4.
The variance of Y20 equals that of X20, and is 𝜎2
20 = 4 ⋅20 ⋅0.51 ⋅0.49 =
19.992.
..
The Normal Approximation
The binomial distribution is the discrete counterpart of the continuous distri-
bution called the Normal distribution, which we shall look at in Section 10.1.
If we scale the binomial distribution along the horizontal axis (that is, “in the
x-direction”), so that the gaps between the bars are no longer 1 unit, but n−1∕2,
it will approximate the Normal distribution. We illustrate the progression with
p = 0.6 in Figure 9.4.
Example 9.3.4 X follows the binomial distribution f with parameters n = 90
and p = 0.4. Find P(X ∈{30, … , 39}) by using the Normal approximation.
Solution: 𝜇X = 90 ⋅0.4 = 36 and 𝜎X =
√
90 ⋅0.4(1 −0.4) = 4.65, so the Nor-
mal approximation is 𝜙(36,4.65). Rule 10.1.13 then says that
P(29 < X ≤39) = Φ(36, 4.65)
(
39 + 1
2
)
−Φ(36, 4.65)
(
29 + 1
2
)
= 0.693.
By comparison, direct calculations give P(29 < X ≤39) = 0.695.
Poisson Approximation
The binomial distribution may also be approximated by the Poisson distribu-
tion, that we will be visiting in Section 9.6. In Figure 9.5, we see how binomial
distributions with parameters n and p converge to the Poisson distribution with
parameter np = 𝜆when n grows while p = 𝜆
n:
n = 50
n = 500
n = 5000
φ( 3,1)
20 25 30 35 40 45
0.02
0.04
0.06
0.08
0.1
280 300 320 340
0.01
0.02
0.03
2900 3000 3100
0.002
0.004
0.006
0.008
0.01
2
4
6
8
0.1
0.2
0.3
0.4
20 25 30 35 40 45
0.2
0.4
0.6
0.8
1.
280 300 320 340
0.2
0.4
0.6
0.8
1.
2900
3000
3100
0.2
0.4
0.6
0.8
1.
2
4
6
8
0.2
0.4
0.6
0.8
1.
Figure .Approximating the Normal distribution.

9.4 Hypergeometric Distribution, hyp(n,S,N)

n = 50
n = 100
n = 5000
p = 0.3
p = 0.15
p = 0.003
λ = 15
5
10 15 20 25 30 35
0.02
0.04
0.06
0.08
0.1
0.12
5
10 15 20 25 30 35
0.02
0.04
0.06
0.08
0.1
5
10 15 20 25 30 35
0.02
0.04
0.06
0.08
0.1
5
10 15 20 25 30 35
0.02
0.04
0.06
0.08
0.1
Figure .Approximating the Poisson distribution.
Example 9.3.5 X ∼bin(223, 0.07). Find P(X = 14).
Solution: We employ the Poisson approximation with 𝜆= np = 223 × 0.07 =
15.61, and get
P(X = 14) ≈pois15.61(14) = 15.6114
14!
× e−15.61 = 0.097 25.
By comparison, direct calculations give bin(223, 0.07)(14) = 0.099 8.
.
Hypergeometric Distribution, hyp(n,S,N)
Hypergeometric distribution: Given n samples without replacement from
a population of N elements, whereof S have the property ⊤whereas the rest
have the property ⊥, let the stochastic variable X be the number of ⊤
sampled. Then, X ∼hyp(n,S,N); that is, X follows a hypergeometric
probability distribution hyp(n,S,N) with parameters n, S, and N. Let p = S
N .
pdf: hyp(n,S,N)(x) = (S
x)(N−S
n−x)
(N
n)
CDF: HYP(n,S,N)(x)
CASIO: HypergeoPD(x, n, S, N)
HypergeoCD(x, n, S, N)
Mathematica: HypergeometricDistribution[n, S, N]
Expected value: 𝜇X = np
Variance: 𝜎2
X = np(1 −p) × N−n
N−1
Binomial approximation: bin(n,p) (9.3) is good when n < N
10
Poisson approximation: poisnp (9.6) is good when
{
100 < n < N
10
n0.31p < 0.47
Normal approximation: 𝜙(𝜇X, 𝜎X) (10.1.5) is good when
{
n < N
10
np(1 −p) > 5


9 Discrete Distributions
hyp( n,S,N) (x)
HY P( n,S,N) (x)
5
10
15
20
0.05
0.1
0.15
0.2
5
10
15
20
0.2
0.4
0.6
0.8
1.
..
Application: Sampling Without Replacement
The hypergeometric distribution describes the probabilities of unordered sam-
pling without replacement in Section 5.5, and we see that the distribution for-
mula hyp(n,S,N)(x) is the formula for the probabilities for repeated sampling
without replacement of two kinds in rule 5.5.5.
1) Industry: Adobe Illustrator is installed on 8 of your company’s 53 laptops.
Your team bring 7 random laptops for a mission. Once boarded on your
flight, you realise you need at least 2 laptops with AI installed. What is the
probability of this happening?
2) Sports: Bayern Munich’s first team has 32 players, whereof 16 are Germans.
Out of the 32, 4 are goalkeepers; 3 of these 4 are German. If a team of 11 is
randomly assembled, what is the probability of picking precisely 8 German
players?
3) Medicine: You work in the cancer ward, and today 5 of its 23 patients will
receive bad news on the doctor’s round. You are assigned 8 random patients.
What is the probability that you will be giving exactly 3 of them bad news?
..
Calculations on Hypergeometric Distributions
Example 9.4.1 X ∼hyp(6,21,34), following a hypergeometric distribution with
parameters n = 6, S = 21, and N = 34. Find
1) 𝜇X
2) 𝜎X
3) P(X ∈{2, 4})
4) P(X > 2).
Answers:
1) 𝜇X = np = n × S
N = 6 × 21
34 = 3.705 88.

9.4 Hypergeometric Distribution, hyp(n,S,N)

2) 𝜎X =
√
np(1 −p) × N −n
N −1 =
√
n × S
N
(
1 −S
N
)
× N −n
N −1
=
√
6 × 21
34
(
1 −21
34
)
× 34 −6
34 −1 = 1.096 48.
3) P(X ∈{2, 4}) = P(X = 2) + P(X = 4) = f (2) + f (4)
= (21
2 )(34−21
6−2 )
(34
6 )
+ (21
4 )(34−21
6−4 )
(34
6 )
= 0.111 644 + 0.347 11 = 0.458 754.
4) P(X > 2) = 1 −P(X ≤2) = 1 −( f (2) + f (1) + f (0)) = 0.866 985.
Calculation of hypergeometric distributions is straightforward, just as for
binomial distributions, but it is still the most time consuming of the common
probability distributions. We will therefore be moved to employ approxima-
tions to other distributions quite frequently, and, in particular, approximation
to the binomial distribution.
Binomial Approximation
For fixed n, we see that hyp(n,S,N)(x) becomes increasingly more similar to
bin(n,S∕N)(x) the larger N becomes. In Figure 9.6, p = S
N = 0.6 and n = 5, and N
is increasing.
Example 9.4.2 X ∼hyp(8, 98, 213). Find P(X ∈{5, 6, 7}).
Solution: We employ the binomial approximation, with parameter p = 98
213 =
0.460 1:
P(X ∈{5, 6, 7}) ≈BIN(8, 0.460 1)(7) −BIN(8, 0.460 1)(4) = 0.278 0.
By comparison, direct calculation on the hypergeometric distribution gives
0.274 6.
(N,S) = (10,6)
(20,12)
(500,300)
binomial,p = 0.6
1
2
3
4
5
0.1
0.2
0.3
0.4
1
2
3
4
5
0.1
0.2
0.3
0.4
1
2
3
4
5
0.1
0.2
0.3
1
2
3
4
5
0.1
0.2
0.3
Figure .Approximating the binomial distribution.


9 Discrete Distributions
Poisson Approximation
The hypergeometric distribution inherits the Poisson approximation from the
binomial distribution.
Example 9.4.3 X ∼hyp(200,150,5000). Find P(X ∈{3, 4, 5}).
Solution: We employ the Poisson approximation, with parameter 𝜆= nS
N =
200×150
5000
= 6:
P(X ∈{3, 4, 5}) = POIS6(5) −POIS6(2) = 0.383 7.
By comparison, direct calculation on the hypergeometric distribution gives
0.384 2.
Normal Approximation
The hypergeometric distribution inherits the Normal approximation from the
binomial distribution.
Example 9.4.4 X ∼hyp(50,320,800). Find P(20 < X ≤30).
Solution: 𝜇X = 50 × 320
800 = 20, and 𝜎X =
√
50 × 0.4 × 0.6 × 800−50
800−1 = 3.356 2,
so our Normal approximation is 𝜙(20, 3.356 2), and so
P(20 < X ≤30) ≈Φ(20, 3.356 2)
(
30 + 1
2
)
−Φ(20, 3.356 2)
(
20 + 1
2
)
= 0.441.
By comparison, direct calculation on the hypergeometric distribution gives
0.436 5.
.
Geometric and Negative Binomial Distributions, nb(k,p)
Negative binomial distribution: Let L be the number of failures (⊥) from a
Bernoulli process with parameter p = P(⊤) that is terminated upon getting a
total of k successes (⊤). Then L ∼nb(k,p); that is, L follows a negative
binomial probability distribution nb(k,p) with parameters k and p.
pdf:
CDF:
nb(k,p)(x) =
(
x + k −1
k −1
)
pk(1 −p)x
= p × bin(x+k−1,p)(k −1)
NB(k,p)(x) = I(k, x+1)(p)
= 1 −BIN(x+k,p)(k −1)
(formulas A.2.17 and A.4.3)

9.5 Geometric and Negative Binomial Distributions, nb(k,p)

CASIO:
p ⋅BinomialPD(k −1, x + k −1, p)
1-BinomialCD(k −1, x + k, p)
HP: p ⋅binomial(x + k −1, k −1, p)
1-binomial_cdf(x + k, p, k −1)
TI: p ⋅binompdf(x + k −1, p, k −1)
1-binomcdf(x + k, p, k −1)
Mathematica: NegativeBinomialDistribution[k, p]
Expected value: 𝜇X = k(1 −p)∕p
Variance: 𝜎2
X = k(1 −p)∕p2
Other distributions: The negative binomial distribution is the discrete
counterpart to the Erlang and Gamma distributions (Section 10.3).
There exists a variant of the negative binomial distribution that instead of
counting failures counts the total number of trials, but both terminate at k
successes. In Mathematica, this variant is called PascalDistribution[k, p].
nb( k,p) (x)
NB( k,p) (x)
5
10
15
20
25
0.02
0.04
0.06
0.08
5
10
15
20
25
0.2
0.4
0.6
0.8
1.
..
Application: Waiting for Success
Whereas the binomial distribution indicates the probability of x successes in n
independent Bernoulli trials with parameter p, the negative binomial distribu-
tion indicates the probability of x failures when the Bernoulli trials are termi-
nated at k successes: it looks at the number of actual frogs you end up kissing
before you have kissed k princes.
r Industrial: Your signal has 80% probability of successful transmission, and
if the transmission fails, you just resend. How many failed transmissions will
you make before the event of a successful transmission?
r Sports: You are playing miniature golf on a court where the ball returns to
its starting point if you miss the hole. How many misses will you go through
before finally putting the ball into the hole?
r Medicine: A certain chemotherapy has a 70% chance of success, indepen-
dently of previous treatments. How many failed attempts will the patient go
through before he is cured?


9 Discrete Distributions
5
10
15
0.05
0.10
0.15
0.20
pdf: geomp(x) = p(1 −p) x
5
10
15
0.4
0.6
0.8
1.
CDF: GEOMp(x) = 1 −(1 −p) x+1
Figure .A geometric distribution.
r Economics: Your company tends to win 40% of their submitted proposals.
How many proposals must they submit to have at least a 50% probability of
winning 8 of them?
..
Geometric Distribution
A special case of the negative binomial distribution is the geometric distri-
bution, geomp, which indicates the probability of x failures before a success.
geomp(x) = nb(1,p)(x). Since a Bernoulli process consists of independent trials,
and thus can be said to be memoryless, the number of failures before k successes
equals the sum of k waiting times under a geometric distribution. Formally: if
Y ∼nb(n,p), then Y = X1 + ⋯+ Xn, where Xk ∼geomp. In Figure 9.7, we see
the pdf and the CDF of a typical geometric distribution.
..
Calculating Geometric Distributions
Example 9.5.1 L ∼geom0.25(x), that is, a geometric distribution with param-
eter p = 0.25. Find: (1) 𝜇L, (2) 𝜎2
L, (3) P(L ∈{3, 4}), and (4) P(L > 1).
Solution:
(1)
𝜇L = 1−p
p
= 1−0.25
0.25
= 3.
(2)
𝜎2
L = 1−p
p2 = 1−0.25
0.252 = 12.
(3) P(L ∈{3, 4}) = P(L = 3) + P(L = 4) = f (3) + f (4)
= 0.25 × 0.753 + 0.25 × 0.754 = 0.184 57.
(4)
P(L > 1) = 1 −P(L ≤1) = 1 −F(1)
= 1 −[1 −(1 −0.25)1+1] = 0.752 = 0.562 5.

9.6 Poisson Distribution, pois𝜆

..
Calculating Negative Binomial Distributions
Example 9.5.2
L ∼nb(7, 0.25), that is, a negative binomial distribution with
parameters k = 7 and p = 0.25. Find
(1) 𝜇L.
(2) 𝜎2
L.
(3) P(L ∈{4, 5}).
(4) P(L > 0).
Answer:
(1) 𝜇L = k(1−p)
p
= 7(1−0.25)
0.25
= 21.
(2) 𝜎2
L = k(1−p)
p2
= 7(1−0.25)
0.252
= 84.
(3) P (L ∈{4, 5}) = f (4) + f (5)
= (10
6
)0.257 × 0.754 + (11
6
)0.257 × 0.755
= 0.004 055 5 + 0.006 691 58 = 0.010 747 1.
(4) We employ the principle of complementary probability:
P(L > 0) = 1 −P(L = 0) = 1 −
(
6
6
)
0.257 × 0.750 = 0.999 939.
.
Poisson Distribution, pois𝝀
Poisson distribution: The Poisson distribution counts occurrences in trials
where the occurrences appear independently and according to a given rate
𝜆. Let X be the number of occurrences. Then X ∼pois𝜆; that is, X follows a
Poisson distribution with parameter 𝜆.
pdf: pois𝜆(x) = 𝜆x
x! × e−𝜆
CDF: POIS𝜆(x)
CASIO: PoissonPD(x, 𝜆)
PoissonCD(x, 𝜆)
HP: poisson(𝜆, x)
poisson_cdf(𝜆, x)
TI: poissonpdf(𝜆, x)
poissoncdf(𝜆, x)
Mathematica: PoissonDistribution[𝜆]
Expected value: 𝜇X = 𝜆
Variance: 𝜎2
X = 𝜆
Normal approximation: 𝜙(𝜇X, 𝜎X) (see Section 10.1.5) is good when 𝜆> 10.


9 Discrete Distributions
poisλ(x)
POISλ(x)
5
10
15
20
25
30
35
0.02
0.04
0.06
0.08
0.1
5
10
15
20
25
30
35
0.2
0.4
0.6
0.8
1.
..
Application: Poisson Processes, and Many Trials with
Rare Occurrences
The Poisson distribution is intimately connected to the Poisson process (Sec-
tion A.4.2). We may well view the Poisson process as a continuous counter-
part to the Bernoulli process, or as a limiting case of a Bernoulli process where,
instead of probing at every integer point in time, we probe at every half, quarter,
eighth, … , or 1
nth unit, but with the probability p of success at each trial going
down such that pn remains constant.
That constant is the rate 𝜆= np, and the Poisson process proper is when we
let n →∞. However, for small p and large n, the Poisson process is an excellent
approximation to the Bernoulli process.
In its own right, the Poisson process describes waiting for an occurrence of
⊤when the probability of a ⊤occurring in an interval [a, b] is proportional
to the size of the interval, and independent of occurrences outside the inter-
val. The Poisson distribution measures the number of occurrences in a fixed
interval. Examples are the number of calls to a call center in a given 15 minute
time span, the number of smiles from a stranger in the streets in a given hour,
the number of shooting stars in the sky in a given year. Other examples are as
follows.
r Industrial: Blow-outs per day for oil wells in the golden age for oil in Texas.
r Sports: Goals during a football (soccer) match.
r Medicine: Bone fractures in the ER during a given weekend.
r Economics: Unsolicited job applications to your company within a given
month.
A Poisson process may also model occurrences in domains other than time.
Distance, area, volume, and terabytes of data are examples of such domains.
The number of hitch-hikers along a three mile stretch of a uniform road is most
likely Poisson distributed. The number of sharks in a cubic mile of water in the
Mexican Gulf is also Poisson distributed, as is the number of true transvestites
at a showing of Rocky Horror. Other examples are as follows.

9.6 Poisson Distribution, pois𝜆

1) Typos on a given page of a newspaper.
2) Algae in a pint of water from a lake.
3) Number of supernovas in the Andromeda galaxy.
4) Number of bit errors in 10 petabytes of data.
The Erlang distribution measures the complementary property of the Pois-
son process: Whereas the Poisson distribution measures the number of occur-
rences x in an interval of width t, the Erlang distribution measures the time t
it takes until x occurrences. See Section 10.3.
..
Calculating the Poisson Distribution
Example 9.6.1
X ∼pois(8), that is, it is Poisson distributed with parameter
𝜆= 8. Find
1) 𝜇X
2) 𝜎X
3) P(X ∈{7, 8, 9})
4) P(X > 0).
Answer:
1) 𝜇X = 𝜆= 8
2) 𝜎X =
√
𝜆=
√
8 = 2.828 43
3) P(X ∈{7, 8, 9}) = f (7) + f (8) + f (9) = 87
7! × e−8 + 88
8! × e−8 + 89
9! × e−8
= 0.139 587 + 0.139 587 + 0.124 077 = 0.403 25
4) P(X > 0) = 1 −P(X = 0) = 1 −f (0) = 0.999 665.
An example of how the Poisson distribution is a limiting case of the bino-
mial distribution with large n and small p is this: look at the atoms in a lump
of radioactive material. A good and vivid image of it is that each atom has a
1012-sided die, a D1 000 000 000 000, and tosses it in wait for the single event (per-
haps a 1) signalling that the atom should split spontaneously. The die may be a
bit smaller or a bit bigger, depening on which kind of atom we are looking at.
But given n = 1 000 000 000 000 atoms, how many will spontaneously undergo
fission during one round of die tossing?
We could, in principle, calculate this by means of the binomial distribu-
tion, but in practice, n! = 1 000 000 000 000! is a bit much to handle, even for
advanced computing equipment. Luckily, if we go even further, by increasing
n to infinity, and at the same time diminishing p such that np stays constant
(𝜆= np), our calculations suddenly turn very tractable: we get the Poisson dis-
tribution with parameter 𝜆= np. And the larger the value of n, for the same
value of 𝜆, the better an approximation the Poisson distribution is.


9 Discrete Distributions
Example 9.6.2 A test of Crazy Mint’s hard candies has shown that there are on
average 3.7 cracked candies per 100 bags. Find the probability that next time
you buy 100 Crazy Mint hard candies, you will find exactly 1 cracked candy.
Then find the probability that you will find 3. Finally, find the probability that
you will find 5, 6, or 7 cracked candies.
Answer: Cracked candies are rare,2 so we consider their occurrences to be
Poisson distributed with some parameter 𝜆.
Since 𝜇= 𝜆for Poisson distributions, then 𝜆= 𝜇, and we already know that
𝜇= 3.7. The number of cracked candies, X, is then Poisson distributed with
parameter 𝜆= 3.7, and so
f (x) = pois3.7(x) = 3.7x
x! ⋅e−3.7.
Then
P(X = 1) = f (1) = 3.71
1! ⋅e−3.7 ≈0.091
P(X = 3) = f (3) = 3.73
3! ⋅e−3.7 ≈0.208
P(X ∈{5, 6, 7}) = POIS3.7(7) −POIS3.7(4) = 0.278.
Normal Approximation
Example 9.6.3 X ∼pois100. Find P(X ∈{88, 89, … , 102, 103}).
Answer: 𝜇X = 𝜆= 100 and 𝜎X =
√
𝜆=
√
100 = 10 give Normal approxima-
tion 𝜙(100,10). Rule 10.1.13 then says that
P(87 < X ≤103) ≈Φ(100, 10)
(
103 + 1
2
)
−Φ(100, 10)
(
87 + 1
2
)
= 0.531.
By comparison, direct calculation on the Poisson distribution gives 0.539.
.
Discrete Distributions: Overview
Which distributions do we use when? And when may we use an approximation?
The section for each distribution gives a numerical guideline for when to use
a simpler distribution as an approximation. Outside of this, some handy rules
for deciding which distribution to use are as follows.
r You have a finite population where each element has an equal chance of being
chosen: Uniform distribution.
2Technically, we have satisfied the rule of thumb for when the Poisson approximation to the
binomial distribution may be applied, since n0.31p < 0.47.

9.8 Exercises

r The number of trials is fixed, and you measure the probabilities of the num-
ber of successes.
– For sampling from a small population where the element you sample dis-
appears or is otherwise excluded from further sampling after having been
chosen once: Hypergeometric distribution.
– For Bernoulli processes, or by sampling from medium-sized populations
where the outcomes so far have negligible effect on the next sampling
probability: Binomial distribution.
– For Poisson processes or sampling from large populations where the prob-
ability of success is low: Poisson distribution.
r The number of successes is fixed, and you measure the probabilities of the
number of trials before the required number of successes is achieved.
– You are waiting for 1 success: Geometric distribution.
– You are waiting for more than 1 success: Negative binomial distribution.
.
Exercises
..
Discrete Uniform Probability Distribution
The discrete uniform distribution has been omitted as a section so that the
student may have at hand a tractable probability distribution to build up and
study its properties. The first assignment is the key.
1
X follows a discrete uniform distribution over the n numbers {a, a + 1,
… , b −1, b} if P(X = c) = 1∕n whenever c is in the list, and 0 otherwise.
Use the rules from chap. 7 to answer the problems below.
(a) Find 𝜇X.
(b) Find 𝜎2
X.
(c) Sketch the probability distribution function (pdf) f (x), and the cumu-
lative probability distribution function (CDF) F(x) for the uniform
distribution.
2
The stochastic variable X follows a uniform probability distribution over
the integers {0, … , 99}. What, then, is P(X ∈{2, 3, 5, 7, 11, 13, 17, 19})?
3
You have a fair D100 die with the numbers 0 … 99 printed on each face.
What is the probability that a toss yields a prime number below 20?
4
For the two questions above: what are the values of 𝜇X and of 𝜎X? (You
must have solved problem 1 to answer this.)
5
You have a fair D60 die with the numbers 0 … 59 printed on each face. Find
the expected value and standard deviation of the outcomes from a single


9 Discrete Distributions
toss, and find the probability that 4 is one of its digits. (You must have
solved problem 1 to answer this.)
..
Bernoulli Distribution, bernp
6
What is the Bernoulli distribution, and what is its use?
7
For which value of the parameter p does a Bernoulli distributed stochastic
variable X have the largest expected value 𝜇X?
8
For which value of the parameter p does a Bernoulli distributed stochastic
variable X have the largest variance 𝜎2
X?
9
What is the maximal value of the precision 𝜏X for a Bernoulli distributed
stochastic variable X? Which values of p give the largest values of the
precision?
10
Odds: the probability that Bayern Munich wins the Bundesliga next year
is 81.25%.
(a) Find of as a decimal number.
(b) Find of as an integer fraction a : b.
(c) Find oa.
(d) Find the continental European odds.
(e) What is the fair price for a bet that gives you a return of 100 euro if
Bayern Munich wins the Bundesliga next year?
(f) If you bet 100 euro with the odds given above, and Bayern Munich wins
the Bundesliga, how much do you win?
(g) A British bookmaker offers you odds of 1 : 10 against. Would it pay to
place the bet that Bayern Munich wins the Bundesliga with him?
..
Binomial Distribution, bin(n,p)
11
The stochastic variable X is the number of ⊤from five trials in a
Bernoulli process with parameter p = 0.55. Find the distribution function
f of X, and calculate its expected value and standard deviation. What is
P(X ∈{0, 1, 2})?
12
You have a motorized lawn mower whose probability of starting the first
time you pull the cord is p = 0.55. If you try this on five separate occasions:
what is the probability that, on two or fewer of those occasions, it would
start on the first pull of the cord?

9.8 Exercises

13
The stochastic variable Y is the number of ⊤from 14 trials in a Bernoulli
process with parameter p = 0.4. Find the distribution function g of
Y, and calculate its expected value and standard deviation. What is
P(Y ∈{3, 4, 5})?
14
In a delayed food shipment, p = 40% have passed their expiry date. If you
pick 14 random food items, what is the probability that 3, 4, or 5 have
passed their expiry date?
15
The stochastic variable Z is the number of ⊤from 20 trials in a Bernoulli
process with parameter p = 0.8. Find the distribution function h of
Z, and calculate its expected value and standard deviation. What is
P(Z ∈{0, 1, 2, 3, 4, 5})?
16
The craftsmen where you live on average keep 80% of their deadlines. You
hire 20 craftsmen for an expansion of your home. What is the probability
that no more than 5 go past their deadlines?
17
Assume that precisely 30% of the population will be voting Liberal Demo-
crat at the next election. You are conducting a poll. What is the probability
that between 27 and 33% of a random sample will tell you that they are
going to vote Liberal Democrat, if …
(a) you poll 10 people;
(b) you poll 100 people;
(c) you poll 1 000 people;
(d) you poll 10 000 people?
18
DiscCo’s latest 8TB hard drive has an error rate given by the fact that the
probability of error in a given bit within a given hour is p = 50 × 10−15.
(We use the fact that 8TB = 8 × 8 × 10244 = 70 368 744 177 664 bits.)
(a) What is the expected number of errors in 1 hour?
(b) What is the variance in the number of errors in 1 hour?
(c) What is the probability of at most 5 errors within 1 hour?
19
A repair protein by the name of helicase moves along a strand of DNA
in a random walk driven by water molecules. If we assume an upwards
movement with probability p = 0.51, and then down with probability
q = 0.49, …
(a) what are the possible positions relative to the starting point after
10 steps;
(b) what is the probability of having moved at least 4 units up in
10 steps;


9 Discrete Distributions
(c) what is the expected number of units moved upwards after 10 000
steps;
(d) what is the variance in the number of units moved upwards after 10 000
steps;
(e) what is the probability of having moved at least 100 units upwards after
10 000 steps?
..
Hypergeometric Distribution, hyp(n,S,N)
20
A stochastic variable X follows a hypergeometric distribution with param-
eters N = 20, S = 13, and n = 5. Find the distribution function f of
X, and calculate its expected value and standard deviation. What is
P(X ∈{0, 1, 2})?
21
In a bag of assorted candies, there are 13 Almond Joys and 7 Twizzlers left.
You sample 5 candies at random. What is the probability that you get 2 or
fewer Almond Joys?
22
A stochastic variable X follows a hypergeometric distribution with param-
eters N = 30, S = 7, and n = 9. Find the distribution function f of X, and
calculate its expected value and standard deviation. What is P(X ∈{0, 1})?
23
A bag contains 23 copper rings and 7 gold rings. You reach into the bag
and grab 9 rings. What is the probability that at most 1 of them is a gold
ring?
24
You have a hand in 5-card poker with 2 kings, 1 ace, and 2 numbered cards.
You consider trading in the two numbered cards and the ace for three new
cards. What is the probability that at least one of your three new cards is
an ace?3
..
Poisson Distribution, pois𝝀
25
X is Poisson distributed and 𝜆= 2.8. Calculate 𝜇X, 𝜎X, P(X = 1), and
P(X ≠1).
26
X is Poisson distributed and 𝜇X = 3.5. Calculate 𝜎X, P(X = 5), and
P(X > 0).
27
X is Poisson distributed and 𝜎X = 5. Calculate 𝜇X, P(X = 7), and P(X ≤2).
3Since all the other cards are unknown to you, the remainder is all 47 cards, including those of the
other players. The distribution of the number of aces is thus hypergeometric with parameters
N = 47, S = 3, and n = 3, and your job is to find f (1) + f (2) + f (3) – or, equivalently, 1 −f (0).

9.8 Exercises

28
X is Poisson distributed and P(X = 0) = 0.1. Calculate 𝜆, 𝜇X, 𝜎X, and
P(X = 1).
29
The stochastic variable X is Poisson distributed with parameter 𝜆= 2.37.
Find the distribution function f for X, and calculate the expected value and
standard deviation. What is P(X ∈{0, 1})?
30
You have tested a lump of Cryptonite with a Geiger counter, and found
that it gives an average of 2.37 clicks on the counter per minute. Find the
probability of 1 click or less in the next minute.
31
The stochastic variable X is Poisson distributed with parameter 𝜆= 1. Find
the distribution function f of X, and calculate the expected value and stan-
dard deviation. What is P(X ∈{0})?
32
The gambling joint Backstab Saloon by Crater Lake in Oregon evict an
average of one cheat per hour. You are on your way to Seattle to talk to “Bill”
about a lucrative job, but have an hour to spare at Backstab. You position
yourself outside the joint in hopes of seeing how they evict a cheat. What
is the probabilty that you won’t get to see any eviction?
33
X, the number of foxes the Easter Bunny sees in the forest on a given day,
is Poisson distributed. During the seven days of Week 5, Mr Bunny saw
respectively 1, 5, 4, 7, 3, 2, and 8 foxes. By an odd coincidence, 𝜇X and the
average number of foxes in Week 5 are exactly the same. Calculate 𝜇X, and
use that to answer the following questions.
(a) What is 𝜆?
(b) What is 𝜎X?
(c) What is the probability that the Easter Bunny will see precisely five
foxes today?
..
Overview and General
34
The difference between the binomial and uniform distributions.
(a) You toss a fair D12 whose faces have values 1, … , 12. What is the prob-
ability of an outcome of 3 or less?
(b) You toss a fair coin 12 times. What is the probability of 3 or fewer
heads? Why does this answer differ from the problem above?
35
The PirateBay problem: Find the distribution for yourself! Is it uniform,
binomial, hypergeometric, or Poisson? For some of the problems, you
should use an approximation rather than try to calculate exactly. You
may indicate the exact distribution, but use the approximation for the
calculation.


9 Discrete Distributions
One the one side, we have five activists against music and video piracy:
Martha, Orrin, Tamara, and Otto. Their job is to gather the IP numbers of
pirates. On the opposite side, we have four independent pirates: the stu-
dents Ringo Smith, John Washington, Paul Dibley, and George Atwick.
(a) One evening, 28 people downloaded an album by the Norwegian
band Ragnar¨ok from PirateBay. Among them were our four students.
Martha’s quota that evening was 1 single IP-address from that torrent.
What is the probability that her catch was one of the four students?
Which distribution do you use for your calculation?
(b) Tamara followed a torrent at PirateBay, where 37 people downloaded
John Denver’s last album. Among them were three of our students.
Tamara’s quota was 5 IP addresses. What is the probability that at least
2 of these 5 were from our students? Which distribution do you use for
your calculation?
(c) Orrin watched a torrent at a Norwegian tracker, where 10 000 eager
young boys downloaded Mira Craig’s latest album. All our 4 students
were among them. Orrin’s target was 300 IP addresses. What is the
probability that his catch will include precisely 2 of our students?
Which distribution do you use for your calculation?
(d) Otto followed at Swedish porn torrent with 16 384 participants (in
the torrent, not the film!). He sampled all IP addresses ending in 133.
Assume that these three digits are evenly distributed from 000 to 255.
What is the expected number of IP addresses Otto will gather? What
is the probability that his catch will be exactly 15 pirates? Which dis-
tribution do you use for your calculation?
36
The Autopol problem: There is a new toll ring around the town Autopol.
There are some initial hiccups, so the company running the toll booths
only get to check on one in every four cars passing through the toll gates.
But the cars that have not paid when checked get a major fine. The cruisers
Hans Rust-Holch and Fritz K¨onigsegg want to test the new system, and
discuss the probabilities of getting caught dodging the toll payments.
(a) What is the probability that they will be caught dodging if they do it
once (1 time)?
(b) What is the probability that they will be caught dodging twice if they
dodge 5 times?
(c) What is the smallest number of times they must dodge the toll payment
for the expected number of times to get caught to be at least 2? What
is the standard deviation?
(d) What is the largest number of times they can dodge the payment before
the probability of getting caught at least once exceeds 50%?
(e) After 12 dodgings, Hans and Fritz have been caught 4 times. Seven of
the 12 times they dodged the payment, Hans sat in the rear, reading

9.8 Exercises

“Wunderbaum Heute”. What is the probability that he read that mag-
azine exactly 3 of the times they were caught?
(f) On average, every 1024th car passing the toll ring around Autopool has
“Wunderbaum Heute” lying in the rear seats. The magazine “Wunder-
baum Heute” has no impact on the probability of getting caught, so
WH readers are caught just the same as everyone else. In the week
Hans and Fritz tested out the dodging, 16 384 drivers were caught.
What is the probability that exactly 15 of these had “Wunderbaum
Heute” in the backseats?




Continuous Distributions
CONTENTS
10.1 Normal Distribution, 𝜙(𝜇,𝜎), 226
10.2 Binormal Distribution, 𝜙(𝜇,Σ)
∗, 234
10.3 Gamma Distribution, 𝛾(k,𝜆) – With Family, 240
10.4 “Student’s”t Distribution, t(𝜇,𝜎,𝜈), 245
10.5 Beta Distribution, 𝛽(a,b), 249
10.6 Weibull Distribution, weib(𝜆,k)
∗, 257
10.7 Exercises, 259
In this chapter, we will look at some key discrete probability distributions. Each
distribution begins with a box with the most commonly used properties of the
distribution. If the distribution has its own symbol 𝜓, we will use that to desig-
nate it, and the uppercase version of the symbol, Ψ, for the cumulative distribu-
tion function. If not, we will use the name and NAME in these roles. By means
of the distribution’s parameters p1, p2, … , pk, we may then describe the …
r probability distribution (pdf) 𝜓(p1,…,pk)(x) or name(p1,…,pk)(x);
r cumulative probability distribution (CDF) Ψ(p1,…,pk)(x) or NAME(p1,…,pk)(x);
r inverse cumulative distribution (iCDF) Ψ−1
(p1,…,pk)(x) or NAME−1
(p1,…,pk)(x);
r expected value 𝜇X = E[X], together with a formula for calulating it from the
parameters p1, … , pk;
r variance 𝜎2
X, together with a formula for calulating it from the parameters
p1, … , pk.
You will also be shown how to perform calculations on these distributions
and their properties – primarily in Mathematica, but where possible also on
CASIO, TI, and HP calculators. For details, see the beginning of Chapter 9.
For a general exposition of continuous probability distributions, see Sec-
tion 7.3.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


10 Continuous Distributions
.
Normal Distribution, 𝝓(𝝁,𝝈)
Normal distribution: X ∼𝜙(𝜇,𝜎) is a continuous stochastic variable taking
values in ℝ; it is Normally distributed with parameters 𝜇∈ℝ, and 𝜎> 0.
pdf: 𝜙(𝜇,𝜎)(x) = k × e−(x−𝜇)2∕2𝜎2,
where k = 1∕
√
2𝜋𝜎
CDF: Φ(𝜇,𝜎)(x)
iCDF: Φ−1
(𝜇,𝜎)(p)
CASIO: NormCD(−1099, x, 𝜎, 𝜇)
InvNormCD(−1, p, 𝜎, 𝜇)
HP: normald_cdf(𝜇, 𝜎, x)
normald_icdf(𝜇, 𝜎, p)
TI: normalcdf(−1099, x, 𝜇, 𝜎)
invNorm(p, 𝜇, 𝜎)
Wolfram: NormalDistribution[𝜇, 𝜎]
You may also use 𝜙(x) = 𝜙(0,1)(x), the standard Normal distribution, and
use tables for the values of Φ(x). Then Φ(𝜇,𝜎)(x) = Φ
(x −𝜇
𝜎
)
.
Expected value: 𝜇X = 𝜇
Variance: 𝜎2
X = 𝜎2
φ( μ,1) (x)
−4
−2
0
2
4
0.2
0.4
0.6
0.8
1.
μ=−2
μ=0
μ=2
Φ( μ,1) (x)
−4
−2
0
2
4
0.2
0.4
0.6
0.8
1.
φ( 0,σ) (x)
−4
−2
0
2
4
0.2
0.4
0.6
0.8
1.
σ=0.5
σ=1
σ=2
Φ( 0,σ) (x)
−4
−2
0
2
4
0.2
0.4
0.6
0.8
1.
..
Applications: Nearly Everything!
Show a person in the street the curve of the Normal distribution, and the imme-
diate response will be statistics! No other function graph is as characteristic of
statistics as precisely the Normal distribution. The Normal distribution appears

10.1 Normal Distribution, 𝜙(𝜇,𝜎)

so often in statistical analysis that its name stems from precisely that: it is the
Normal distribution. The Normal distribution is completely characterized once
you know its means 𝜇and standard deviation 𝜎, and therefore the probability
distribution normally uses precisely these two values as its parameters: 𝜙(𝜇,𝜎).
Variants are using the variance, writing 𝜙(𝜇,𝜎2), while a small minority prefer the
precision 𝜏= 1∕𝜎2, writing 𝜙(𝜇,𝜏). As far as the curve is concerned, 𝜇indicates
its middle, where its maximum is located, whereas 𝜎indicates how it is spread,
and is (as stated) its standard deviation. It is more common to write 𝜙as N, but
since the use of Φ for the cumulative distribution is universal, we will stick with
consistency and use 𝜙for the distribution function.
The name “Normal distribution” is easily seen to be true when we see its many
areas of application. Typical domains covered by the Normal distribution are
the following.
r The weight of animals and humans often follow a Normal distribution
around the average.
r Performance: how fast 16 year olds at a school will complete a 100 yard dash
will often follow a Normal distribution.
r Scores on proper IQ tests are Normally distributed around a middle of 100.
r Product quality: the length of the firewood you buy will be Normally dis-
tributed around the average length, and the standard deviation will be smaller
the more experienced the woodcutter.
r Scientific measurements: different measurements of one and the same mag-
nitude may give different results for different measuring tools or even differ-
ent measurings with the same tool. The results will follow a Normal distri-
bution, and the standard deviation indicates measurement uncertainty.
Another important use of the Normal distribution is as an approximation
to other distributions, through the so-called Normal approximation. This does
in particular hold for sums of identically distributed, independent stochastic
variables, since such sums tend to a Normal distribution when the number of
variables increases. This has its own subsection at the end of this section on the
Normal distribution.
..
Calculating the Normal Distribution
The values of Φ may be found in several ways.
Example 10.1.1 X ∼𝜙(3.1, 5.7). What is P(X ≤12)?
Answer: P(X ≤12) = Φ(3.1, 5.7)(12). We calculate the answer in several ways.
1) We use the fact that Φ(𝜇, 𝜎)(x) = Φ((x −𝜇)∕𝜎), and find the values for Φ in
Table C.6.
Φ(3.1, 5.7)(12) = Φ
(12 −3.1
5.7
)
= Φ(1.561 4) ≈Φ(1.56) = 0.940.


10 Continuous Distributions
2) Mathematica: CDF[NormalDistribution[3.1, 5.7], 12] gives 0.940 786.
3) CASIO: NormCD(−1099, 12, 5.7, 3.1) gives 0.940 785.
4) TI: normalcdf(−1099, 12, 3.1, 5.7) gives 0.940 785.
5) HP: normald_cdf(3.1, 5.7, 12) gives 0.940 785.
Example 10.1.2 Abe has waded into the middle of his favourite salmon river
Flomma. The weight of the next salmon he catches in Flomma is Normally dis-
tributed with mean 𝜇= 3.2 kg and standard deviation 1.3 kg. What is the prob-
ability that the next salmon Abe catches weighs between 2 and 5 kg?
Answer: 𝜇= 3.2 and 𝜎= 1.3, and we need to find P(X ∈(2, 5)), so
P(X ∈(2, 5)) = Φ(3.2, 1.3)(5) −Φ(3.2, 1.3)(2) = 0.738 931.
The probability that the next salmon Abe catches is between 2 and 5 kg, is
74%. We find the probability by means of calculation tools, thus:
r Mathematica: Probability[2<x<5, x≈NormalDistribution[3.2,1.3]];
r CASIO: NormCD(2, 5, 1.3, 3.2);
r TI: normalcdf(2, 5, 3.2, 1.3);
r HP: normald_cdf(3.2, 1.3, 5) – normald_cdf(3.2, 1.3, 2).
..
z𝜶, the Inverse of 𝚽
The most common calculation for a Normally distributed variable X ∼𝜙(𝜇,𝜎)
is to find P(X ≤a). The second most common is the inverse question: given a
probability p, for which value of x is P(X ≤x) = p? As we saw in Section 7.4, the
answer is in the iCDF, so x = Φ−1
(𝜇,𝜎)(p). For both theoretical and practical pre-
calculator reasons, this inverse is often calculated via the inverse of the cumula-
tive standard Normal distribution, Φ−1 = Φ−1
(0,1), giving us x = Φ−1
(𝜇,𝜎)(p) = 𝜇+
𝜎× Φ−1(p). This method is so common that we give Φ−1(𝛼) its own name: z𝛼.
Φ(x) and z𝛼= Φ−1(𝛼) are illustrated in Figure 10.1.
−4
−2
0
2
4
0.2
0.4
0.6
0.8
1
a
Φ(a)
Φ(t)
(a) The cumulative standard Normal
distribution Φ.
α
z  α
0.2
0.4
0.6
0.8
1
−3
−2
−1
1
2
3
(b) The inverse of Φ, the function
zα = Φ−1(α).
Figure .The cumulative standard normal distribution Φ and its inverse.

10.1 Normal Distribution, 𝜙(𝜇,𝜎)

“Left” version, z𝛼= 𝜙−1(𝛼)
“Right” version, z𝛼= 𝜙−1(1 −𝛼)
𝛼= 0.05
−3
−2
−1
0
1
2
3
Left z0.05 = −1.645.
−3
−2
−1
0
1
2
3
Rightz0.05 = 1.645.
𝛼= 0.95
−3
−2
−1
0
1
2
3
Left z0.95 = 1.645.
−3
−2
−1
0
1
2
3
Rightz0.95 = −1.645.
Figure .Left and right versions of z𝛼for 𝛼= 0.05 and 𝛼= 0.95.
Definition 10.1.3 z𝛼= Φ−1(𝛼)
It is more common to use z𝛼to designate the right tail (that is, that z𝛼is the
solution to P(X ≥z) = 𝛼) rather than the left tail of the straight inverse (that
is, that z𝛼is the solution to P(X ≤z) = 𝛼). But they are easy to use around one
another, since the “right” z𝛼equals the “left” z1−𝛼, and conversely. We will, as
we said, stick with the “left” z𝛼. See Figure 10.2 for illustration of the difference
and complementarity.
The symmetry between left and right is succinctly expressed in the following
rule.
Rule 10.1.4 zp = −z1−p.
Example 10.1.5 z0.8 = −z0.2 = −(−0.841 621) = 0.841 621.
Rule 10.1.6 Let X ∼𝜙(𝜇,𝜎). Then the solution x to P(X ≤x) = 𝛼is given by
the fact that x = Φ−1
(𝜇,𝜎)(𝛼) = 𝜇+ 𝜎⋅z𝛼.


10 Continuous Distributions
We may calculate the values of the iCDF of the Normal distribution, Φ−1
(𝜇,𝜎),
as follows.
1) Standard Normal: Find z𝛼, and use that Φ−1
(𝜇,𝜎)(𝛼) = 𝜇+ 𝜎⋅z𝛼.
2) Mathematica: Φ−1
(𝜇,𝜎)(p) is InverseCDF[NormalDistribution[𝜇, 𝜎],p].
3) CASIO: InvNormCD(p, 𝜎, 𝜇).
4) TI: invNorm(p, 𝜇, 𝜎).
5) HP: normald_icdf(𝜇, 𝜎, p).
Example 10.1.7 Abe is fishing in Flomma (Example 10.1.2) and wonders how
heavy the 90% heaviest salmon there are.
Answer: We understand that Abe wants to find an x such that P(X > x) = 0.9,
that is, P(X ≤x) = 0.1. Since X ∼𝜙(3.2, 1.3)(x), then x = Φ−1
(3.2, 1.3)(0.1). We cal-
culate the value as follows.
r The table gives us that z0.1 = −1.281 6, so
x = 𝜇+ z0.1𝜎= 3.2 −1.281 6 ⋅1.3 = 1.533 92.
r Mathematica: InverseCDF[NormalDistribution[3.2, 1.3],0.1] gives 1.533 98.
r CASIO: InvNormCD(0.1, 1.3, 3.2) gives 1.533 98.
r TI: invNorm(0.1, 3.2, 1.3) gives 1.533 98.
r HP: normald_icdf(𝜇, 𝜎, p).
So 90% of the salmon in his river are heavier than 1.53 kg.
Example 10.1.8
(Continued from Example 10.1.7) Abe also wants to know
how heavy the 90% lightest salmon are.
Answer: Calculation tools do this in the same way as above, but with new num-
bers, but most tables stop at p = 0.1 or 0.2. To get past this, we make use of
Rule 10.1.4:
x = 𝜇+ z0.9𝜎= 𝜇−z0.1𝜎= 3.2 −(−1.2816) × 1.3 = 4.866 08.
So 90% of the salmon weigh less than 4.87 kg.
Example 10.1.9 In the mass production of vehicles for land based transport
(cars, trains, buses, etc.), the main producer will set certain performance stan-
dards for the production of parts: for the measured specs, the mean ± four
standard deviations should be within some set toleration limits. The underly-
ing assumption is that these properties are Normally distributed. A car consists
of 15 000 parts.
(a) What is the probability that a car has components outside of the tolerance
limits?

10.1 Normal Distribution, 𝜙(𝜇,𝜎)

(b) If we assume that all deviations outside of ± six sigma will lead to com-
plaints, how many complaints may be expected on a production of one mil-
lion cars?
Answer: This will at the outset seem to be a problem solely about the Normal
distribution, but it illustrates how the distributions work together. We calculate
the following.
(a) The probability that a given component lies with the ±4𝜎limit is
p = Φ(4) −Φ(−4) = 0.999 936 66.
The probability that all 15 000 components of a car are within the limits
is then p15 000 = 0.386 7. The probability of one or more components being
outside the limits is then
1 −p15 000 = 1 −0.386 7 = 0.613 3.
(b) The probability that a given component lies within the ±6𝜎limit, is
r = Φ(6) −Φ(−6) = 0.999 999 998 026 824 7.
The probability that all 15 000 components of a car are within the limits is
then r15 000 = 0.999 970 402 8. The number of complaints will be binomially
distributed as bin1 000 000,1−r. The expected number of complaints is then
n ⋅(1 −r) = 100 000 0 × 0.000 029 60 = 29.6.
..
The Sum of Independent Normal Distributions
The sum of independent Normally distributed variables will itself follow a Nor-
mal distribution. The most common sums are the sum or difference of two vari-
ables. We write the special case of two components first, and the general case
after that.
Rule 10.1.10 For Z = X + Y, we have
𝜇Z = 𝜇X + 𝜇Y
𝜎2
Z = 𝜎2
X + 𝜎2
Y,
whereas for W = X −Y, we have
𝜇W = 𝜇X −𝜇Y
𝜎2
W = 𝜎2
X + 𝜎2
Y.
The general form is weighted sums of stochastic variables. The rule then
modifies to the following.
Rule 10.1.11
Let Xk ∼𝜙(𝜇k,𝜎k) and bk ∈ℝ, and let Y = r + ∑n
k=1 bnXn.
Then Y ∼𝜙(𝜇,𝜎), where
𝜇= r +
n
∑
k=1
bn𝜇n
and
𝜎2 =
n
∑
k=1
b2
n𝜎2
n.


10 Continuous Distributions
Important special cases are as follows:
r if X ∼𝜙(𝜇,𝜎), and k ∈ℝ, and Y = kX, then Y ∼𝜙(k𝜇,|k|𝜎);
r if X ∼𝜙(𝜇,𝜎), and r ∈ℝ, and Z = X + r, then Z ∼𝜙(𝜇+r,𝜎);
and one special case merits its own separate rule, as follows.
Rule 10.1.12
Given n stochastic variables Xk ∼𝜙(𝜇,𝜎), with mean ̄X =
(X1 + ⋯+ Xn)∕n, we have ̄X ∼𝜙(𝜇, 𝜎∕
√
n).
..
Normal Approximation
A central reason why the Normal distribution is the most normal probability
distribution is that the sum of many small, random variations add up to some-
thing looking a lot like the Normal distribution. Not only that, but many of the
other probability distributions become increasingly similar to the Normal dis-
tribution when their parameters grow large. In these cases, it is often expedient
to replace the exact calculation by a Normal approximation.
Rule 10.1.13
The Normal approximation to the (distribution of the)
stochastic variable X is
X ≈𝜙(𝜇X,𝜎X)(x),
where we use ≈to indicate “has approximate distribution”. For continuous X,
P(X ≤n) = Φ(𝜇X,𝜎X)(n).
For discrete X, the formula for a point probability is (as illustrated in Fig-
ure 10.3)
P(X = n) ≈Φ(𝜇X,𝜎X)
(
n + 1
2
)
−Φ(𝜇X,𝜎X)
(
n −1
2
)
.
2
4
6
8
10
12
14
0.02
0.04
0.06
0.08
0.10
0.12
Figure .Point probability ⇒interval
probability.

10.1 Normal Distribution, 𝜙(𝜇,𝜎)

That is, the discrete value n corresponds to the interval n ± 1
2, and so for the
calculation of cumulative discrete distributions, we add the so-called continuity
correction:
P(X ≤n) = Φ(𝜇X,𝜎X)
(
n + 1
2
)
.
Example 10.1.14
X is a discrete stochastic variable with 𝜇X = 14.7
and 𝜎X = 3.4. Employ the Normal approximation to calculate P = P(X ∈
{14, 15, 16, 17, 18, 19}).
Solution: P = Φ(14.7, 3.4)(19.5) −Φ(14.7, 3.4)(13.5) = 0.558 924.
Example 10.1.15 Y er is a continuous stochastic variable with 𝜇Y = 42 and
𝜎Y = 15. Employ the Normal approximation to calculate P(Y ∈(20, 40)).
Solution: P(Y ∈(20, 40)) = Φ(42, 15)(40) −Φ(42, 15)(20) = 0.375 732.
Precisely when you should use the Normal approximation instead of exact
calculation depends on the balance between error tolerance in your calcu-
lations and your need for simplification and speed of calculation. In these
two chapters about the different probability distributions, we provide rules of
thumb for each distribution for when a Normal approximation is acceptable.
But keep in mind that these are rules of thumb, and not universally valid crite-
ria regardless of your actual needs.
We round off this section with a known theorem that is closely related to the
Normal approximation, and that is often invoked to explain the ubiquitousness
of the Normal distribution mathematically.
Rule 10.1.16
Central limit theorem: Let Xk be a sequence of indepen-
dent stochastic variables sharing the same E[Xk] = 𝜇and Var(Xk) = 𝜎2, let
̄Xn be the average of the first n variables, and Zn = ( ̄X −𝜇)∕(𝜎∕
√
n). Then
lim
n→∞Zn = Z ∼𝜙(0,1)(x).
..
In Brief
We illustrate the anatomy of the Normal distribution in Figure 10.4 by looking
at a representative Normal distribution.
We notice that
r the peak lies over x = 𝜇;
r 𝜙(x) is symmetrical around 𝜇;
r 𝜙(𝜇,𝜎)(𝜇) =
1
√
2𝜋𝜎2 ;


10 Continuous Distributions
5
0
5
10
0.05
0.10
0.15
0.20
μ
+σ
−σ
Top, ϕ(μ)=
1
2πσ
Inflection point
Inflection point
+2σ
+3σ
+4σ
−2σ
−3σ
−4σ
Figure .𝜙(3,2). Marked: the mean, plus
integer multiples of the standard
deviation.
r inflection points at x = 𝜇± 𝜎;
r a rough graph of the curve will seem to hit the x-axis on each side at between
𝜇± 3𝜎and 𝜇± 4𝜎.
.
Binormal Distribution, 𝝓(𝝁,𝚺)
∗
Binormal distribution: If Z =
[
X
Y
]
follows a binormal distribution, it takes
values in ℝ2, and its probability distribution is
fz(z) = N(𝝁, Σ)(z) = k × e−1
2 (z−𝝁)TΣ−1(z−𝝁z),
where k =
1
√
(2𝜋)2|Σ|
r Expected value: 𝝁= 𝝁z =
[𝜇x
𝜇y
]
∈ℝ2
r Covariance matrix: Σ = Σz =
[
𝜎2
x
𝜎xy
𝜎xy
𝜎2
y
]
∈ℝ2 × ℝ2
Mathematica: MultinormalDistribution
[
{𝜇x, 𝜇y},
(
𝜎2
x
𝜎xy
𝜎xy
𝜎2
y
)]
3D plot of fz(x,y)
The level curves offz(x,y)
−1
0
1
2
3
4
5
0
2
4
6
8
10

10.2 Binormal Distribution, 𝜙(𝜇,Σ)
∗

Rule 10.2.1 Conditional and marginal: The conditional variable X|y fol-
lows the probability distribution fx|y(x) = 𝜙(𝜇X|y, 𝜎2
X|y), where
𝜇X|y = 𝜇x +
𝜎xy
𝜎2
y
(y −𝜇y)
𝜎2
X|y = 𝜎2
y(1 −𝜌xy)2
where 𝜌xy = 𝜎xy∕
√
𝜎2
x𝜎2
y.
The marginal probability distribution for X is
fx(x) = 𝜙(𝜇x,𝜎x)(x).
Correspondingly for Y, when we switch the roles of x and y.
These properties are illustrated in Figure 10.5.
..
Special Case: X and Y Independent
The simplest kind of binormal distribution is when X and Y are indepen-
dent. We then know that fx|y = fx, fy|x = fy, and that fz(x, y) = fx(x) × fy(y)
(Rule 8.2.19). Since 𝜎xy = 0, then Σ is a diagonal matrix:
Σ =
[
𝜎2
x
0
0
𝜎2
y
]
and
𝜙(𝝁, Σ) = 𝜙(𝜇x, 𝜎x) × 𝜙(𝜇y, 𝜎y).
The level curves of Z are now ellipses with the x- and y-axes as its principal
axes. See Figure 10.6 for examples.
(a) The cross sections are proportional to
the conditional distributions.
(b) The marginal distributions, scaled, in
blue and green on the side planes.
Figure .Conditional and marginal distributions for a binormal distribution.


10 Continuous Distributions
(a) 3D plot.
10
15
20
25
10
15
20
25
σ =
x 1, σ =
x 3
σ =
x 3, σ =
x 3
σ =
x 3, σ =
x 1
σ =
x 1, σ =
x 1
(b) Level curve plot.
Figure .The function stretches along each axis proportional to the 𝜎for that axis.
..
The General Case as a Rotation of the Special Case
The general covariance matrix is
̂Σ =
[
̂𝜎2
x
̂𝜎xy
̂𝜎xy
̂𝜎2
y
]
=
[
̂𝜎2
x
𝜌̂𝜎x ̂𝜎y
𝜌̂𝜎x ̂𝜎y
̂𝜎2
y
]
,
where 𝜌is the correlation coefficient between the x- and the y-components. For
all covariance matrixes ̂Σ, we may find another coordinate system by a rotation
with angle 𝜃, so that the covariance matrix is a diagonal matrix Σ in the rotated
coordinate system. In brief, we say that we rotate the distribution, covariance
matrix, and vector of expected values. From linear algebra, we have that the
rotation matrix for rotating a vector x ∈ℝ2 by an angle 𝜃counterclockwise is
R𝜃=
[
cos 𝜃
−sin 𝜃
sin 𝜃
cos 𝜃
]
.
We see an example of a rotated (and shifted) binormal distribution in
Figure 10.7.
When we rotate an independent binormal distribution with expectation vec-
tor 𝝁and covariance matrix Σ by an angle 𝜃counterclockwise, we get the
dependent binormal distribution 𝜙( ̂𝜇, ̂Σ), where
̂𝜇= R𝜃𝝁=
[ 𝜎x cos 𝜃−𝜎y sin 𝜃
𝜎y cos 𝜃+ 𝜎x sin 𝜃
]
̂Σ = R𝜃ΣR−𝜃=
[
𝜎2
x cos2 𝜃+ 𝜎2
y sin2 𝜃
(𝜎2
x −𝜎2
y
) cos 𝜃sin 𝜃
(𝜎2
x −𝜎2
y
) cos 𝜃sin 𝜃
𝜎2
x cos2 𝜃+ 𝜎2
y sin2 𝜃
]
.

10.2 Binormal Distribution, 𝜙(𝜇,Σ)
∗

(a) 3D plot.
4
6
8
10
12
14
16
10
15
20
25
(b) Level curve plot.
Figure .An independent distribution (orange), and a 40◦rotation of this (blue).
But what about the converse case, where we start with a non-independent
covariance matrix ̂Σ? How do we find the independent covariance matrix Σ
that it is the rotation of? The solution is to start by finding the angle 𝜃, and then
use the rotation formula above in reverse:
𝜃= 1
2 tan−1
(
2̂𝜎xy
̂𝜎2
x −̂𝜎2
y
)
𝝁= R−𝜃̂𝜇
Σ = R−𝜃̂ΣR𝜃.
Example 10.2.2 The wind speed at East Cape (in m/s) is a stochastic variable
Z = ( ̂X, ̂Y) ∼𝜙( ̂𝜇, ̂Σ), where
̂𝜇=
[
−1
3
]
,
̂Σ =
[
12.1
4.7
4.7
9.7
]
,
and X is the eastward wind speed, whereas Y is the northward wind speed. If
you want to rotate the coordinate system so that Z = (X, Y) is independent,
1) what is the angle of rotation, 𝜃;
2) what is the rotated coordinate of a vector x;
3) what is 𝝁;
4) what is the diagonal covariance matrix Σ?
Answer:
1) 𝜃= 1
2 tan−1 (
2×4.7
12.1−9.7
)
= 0.660 409 rad = 37.838 6◦.


10 Continuous Distributions
2) The coordinate comes through a rotation with an angle −𝜃, so the new coor-
dinates are
R−𝜃x = R−0.660 4
[
x
y
]
=
[
0.789 7x + 0.613 4y
0.789 7y −0.613 4x
]
.
3) 𝝁is a rotation of ̂𝜇=
[
−1
3
]
. The formula for the general x gives
𝝁= R−0.660 4 ̂𝜇=
[
0.789 7 × (−1) + 0.613 4 × 3
0.789 7 × 3 −0.613 4 × (−1)
]
=
[
1.050 5
2.982 5
]
.
4) Σ = R−0.660 4ΣR0.660 4. Use a calculation tool. In Mathematica:
RotationMatrix[−0.660 4].
[
12.1 4.7
4.7
9.7
]
. RotationMatrix[0.660 4]//MatrixForm.
We get
Σ =
[
15.750 8
0.000 085 884 6
0.000 085 884 6
6.049 23
]
.
We should have had 0 outside of the diagonal, but got 0.000 085 884 6. This is
due to numerical inaccuracy. Since statistics is the art of being approximate
in an accurate way, and you know that the values outside of the diagonal
really are 0, double check your setup, and if it still looks good, round off
these values to 0:
Σ =
[
15.75
0
0
6.049
]
.
..
Multinormal Distribution
The generalization of a binormal distribution is a multinormal distribution.
When X = (X1, … , Xn) is a multinormal distribution over ℝn, then
f (x) = N(𝝁, Σ)(x) = k × e−1
2 (x−𝝁)TΣ−1(x−𝝁)
where k =
1
√
(2𝜋)n|Σ|
.
Expected value and position parameter: 𝝁=
⎡
⎢
⎢⎣
𝜇1
…
𝜇n
⎤
⎥
⎥⎦
.
Covariance matrix and variance parameters: Σ =
⎡
⎢
⎢⎣
𝜎2
1
⋯
𝜎1n
⋮
⋱
⋮
𝜎n1
⋯
𝜎2
n
⎤
⎥
⎥⎦
.

10.2 Binormal Distribution, 𝜙(𝜇,Σ)
∗

Mathematica: MultinormalDistribution
⎡
⎢
⎢⎣
{𝜇1, … , 𝜇n},
⎡
⎢
⎢⎣
𝜎2
1
⋯
𝜎1n
⋮
⋱
⋮
𝜎n1
⋯
𝜎2
n
⎤
⎥
⎥⎦
⎤
⎥
⎥⎦
.
As with the binormal distributions (two-dimensional multinormal), the
three- and higher-dimensional multinormal distributions may be rotated into a
coordinate system where the components are independent, and Σ is a diagonal
matrix. Graphic rendering is hard in higher dimensions, though. In Figure 10.8,
we see the level curves of a multinormal distribution in three dimensions.
Figure .The level curves of a multinormal distribution in three dimensions.


10 Continuous Distributions
.
Gamma Distribution, 𝜸(k,𝝀) – With Family
Gamma distribution T ∼𝛾(k,𝜆) is a continuous stochastic variable taking
values in [0, ∞); we say that it follows the gamma distribution with
parameters k, 𝜆> 0.
pdf: 𝛾(k,𝜆)(t) =
𝜆k
Γ(k)tk−1e−𝜆t where Γ(k) is the Γ function (A.2.10)
The 𝛾distribution derives its name from the Γ function. Below, we use 𝜒2
(see Section 10.3.1) to calculate CDF and iCDF, due to its uniquitousness in
calculators.
CDF: Γ(k,𝜆)(t) (when 2k ∈ℕ)
iCDF: Γ−1
(k,𝜆)(p) (when 2k ∈ℕ)
CASIO: ChiCD(0, 2𝜆t, 2k)
InvChiCD(1 −p, 2k)∕(2𝜆)
HP: chisquare_cdf(2k, 2𝜆t)
chisquare_icdf(2k, p)∕(2𝜆)
TI: 𝜒2cdf(0, 2𝜆t, 2k)
CX: Inv𝜒2(p, 2k)∕2𝜆
83+: Solver: 𝜒2cdf(0, 2𝜆x, 2k) −
p = 0 ≫x = 1
Wolfram: GammaDistribution[k, 1
𝜆]
Expected value: 𝜇T = k
𝜆
Variance: 𝜎2
T = k
𝜆2
Normal approximation: 𝜙(𝜇T, 𝜎T) is a good approximation when k > 30
γ( k,1.5)) (t)
0
1
2
3
4
5
6
7
8
0.2
0.4
0.6
0.8
1.
k=8
k=5
k=3
k=2
k=1
Γ( k,1.5) (t)
0
1
2
3
4
5
6
7
8
0.2
0.4
0.6
0.8
1.
γ( 2,λ) (t)
0
1
2
3
4
5
0.2
0.4
0.6
0.8
1.
λ=0.5
λ=1
λ=1.5
λ=2
λ=2.5
Γ( 2,λ) (t)
0
1
2
3
4
5
0.2
0.4
0.6
0.8
1.

10.3 Gamma Distribution, 𝛾(k,𝜆) – With Family

..
The Family
The gamma distribution is the most general form in a family of related distri-
butions. The other distributions are special cases of the 𝛾distribution, each in
their own way, sometimes with a twist in how the parameters are set up. The
closest cousin is the Erlang distribution, which differs only in the requirement
that k be an integer. We have:
𝛾(k,𝜆)(x) = 𝛾(k,𝜆)(x)
k, 𝜆> 0
GammaDistribution[k, 1
𝜆]
erl(k,𝜆)(x) = 𝛾(k,𝜆)(x)
k ∈ℕ, 𝜆> 0
ErlangDistribution[k, 𝜆]
exp𝜆(x) = 𝛾(1,𝜆)(x)
𝜆> 0
ExponentialDistribution[𝜆]
𝜒2
𝜈(x) = 𝛾( 𝜈
2 , 1
2
)(x)
𝜈∈ℕ
ChiSquareDistribution[𝜈]
S−1𝜒2
𝜈(x) = 𝛾( 𝜈
2 , S
2
)(x)
𝜈∈ℕ
“S−1 times chi squared”.
The 𝜒2 parameter 𝜈is traditionally called the “degrees of freedom”, and is
sometimes written df .
In statistics, calculating inverse cumulative probabilities is as important as
calculating the probabilities themselves. This goes for the 𝛾family as well. In
Mathematica, you find the inverse by simply invoking InverseCDF for the dis-
tribution, but when you are limited to the repertoir of a desktop calculator, you
need to rewrite the expression to get what you want. Let 𝕏2 be the cumulative
𝜒2 distribution, and 𝕏−2 its inverse. Then,
r basic identity: Γ−1
(k,𝜆)(p) =
𝕏−2
2k (p)
2𝜆
;
r CASIO: InvChiCD(1 −p, 2k)∕(2𝜆);
r TI CX: Inv𝜒2(p, 2k)∕2𝜆
r TI 83+: Solver: 𝜒2cdf(0, 2𝜆x, 2k) −p = 0 ≫x = 1
r HP: chisquare_icdf(2k, p)/(2𝜆).
Let us take a closer look at the family members.
..
Application of the Exponential and Erlang Distributions:
Waiting Times
Historically, the Erlang distribution was invented by the Dane A. K. Erlang to
analyse problems in telecommunications, since the incoming calls for a large
company may be modelled as a Poisson process (Section A.4.2). In a Poisson
process, the Poisson distribution (9.6) describes the number of occurrences
within a fixed time t. The Erlang distribution does the opposite, and describes
the waiting time t for a fixed number of occurrences k.
The Poisson process is what we call “memoryless”, so the probability of a new
occurrence within the next second, minute or hour is independent of the num-
ber of occurrences thus far, and how long the process has been going on. An


10 Continuous Distributions
important special case of the Erlang distribution is the waiting time for a sin-
gle occurrence: exp𝜆(t) = erl(1,𝜆)(t). The waiting time for one occurrence has its
own name and symbol: the exponential distribution, exp𝜆.
Calculating the Erlang distribution
Calculating the Erlang and exponential distributions is straightforward, espe-
cially for low values of k. Since k is an integer, the pdf and the CDF have the
simpler form
pdf:
erl(k,𝜆)(x) =
𝜆k
(k −1)!xk−1e−𝜆x
CDF:
ERL(k,𝜆)(x) = 1 −
k−1
∑
n=0
((𝜆x)n
n! e−𝜆x
)
.
In Appendix A.4, the identity A.4.6 may make for quicker calculations on
some calculators.
Example 10.3.1 A Poisson process has rate 𝜆= 4.4. Let T be the waiting time
for k = 13 occurrences. What are 𝜇T, 𝜎T, and P(T > 2) for this waiting time?
Answer: 𝜇T = 13
4.4 = 2.954 55, and 𝜎T =
√
13
4.4 = 0.819 443.
P(T > 2) = 1 −P(T ≤2) =
13−1
∑
n=0
((4.4 ⋅2)n
n!
e−4.4⋅2
)
= 0.889 838.
Using identity A.4.6, we may also calculate the probability thus:
P(T > 2) = 1 −ERL(13,4.4)(2) = POIS4.4 ⋅2(13 −1) = 0.889 838.
Example 10.3.2 Your wife works at a call center, and her day is over when she
has filled a certain quota of calls. The arrival of these calls is described by a
Poisson process. You know neither the rate 𝜆nor how many calls k your wife
must complete before she is done, but she said she believed it would take 𝜇T = 1
3
hours, but that the uncertainty was 𝜎T = 1
6 hours. As you sit there pondering
why your wife, who is so proficient at statistics, works at a call center, you decide
to estimate the parameters 𝜆and k. What are 𝜆and k?
Answer: 𝜇T = k
𝜆and 𝜎T =
√
k
𝜆, which means we must solve the following sys-
tem of equations:
k∕𝜆= 1∕3
√
k∕𝜆= 1∕6.

10.3 Gamma Distribution, 𝛾(k,𝜆) – With Family

φ( 5,σ)
0
2
4
6
8
10
0.2
0.4
0.6
0.8
0
2
4
6
8
10
0.2
0.4
0.6
0.8
0
2
4
6
8
10
0.2
0.4
0.6
0.8
0
2
4
6
8
10
0.2
0.4
0.6
0.8
σ
1
2
3
4
5
1
2
3
4
5
1
2
3
4
5
1
2
3
4
5
τ
1
2
3
4
5
1
2
3
4
5
1
2
3
4
5
1
2
3
4
5
Figure .Spread, 𝜎and 𝜏itself for different values of 𝜏.
We divide the first equation by the second, and get
k∕𝜆
√
k∕𝜆
=
√
k = 1∕3
1∕6 = 2.
So
√
k = 2, which gives k = 4. Inserting that into the first equation, we get
4∕𝜆= 1∕3
𝜆= 12.
..
Application of the 𝜸and 𝝌Distributions: Precision
Probability distributions 𝛾and 𝜒2 describe the precision 𝜏. Recall from Sub-
section 7.6.1 that the relationship between precision and variance is that
𝜏= 1∕𝜎2. Note that 𝜎2 has its own probability distributions (inverse 𝛾and
inverse 𝜒2), but that we will stick with the probability distributions for 𝜏,
since they are the most tractable. Everything we need to know about 𝜎can be
obtained from querying about 𝜏.
In the illustrations in Figure 10.9 and summed up in Figure 10.10a, we see a
normal distribution centered around 𝜇= 5, with different values for the spread
(standard deviation) parameter 𝜎(and the precision 𝜏). When we do not know
0
2
4
6
8
10
0.2
0.4
0.6
0.8
(a) φ( 5,σ) for different values of σ.
0.5
1.
1.5
2.
2.5
3.
0.5
1.
1.5
(b) τ = 1 σ2 has distribution γ( 12, 12.5) .
Figure .The possible shapes of the normal distribution for different 𝜎, when 𝜏= 1∕𝜎2
follows a 𝛾distribution.


10 Continuous Distributions
the precise measure of spread and precision, we indicate it by a probability dis-
tribution describing how likely it is that they have such-and-such values. This
distribution is usually a gamma distribution, like the one in 10.10b.
Theory tells us that if X1, … , Xn ∼𝜙(0,1) are independent, and Z = ∑n
k=1 X2
k,
then Z ∼𝜒2
n. Since variance is calculated from the squares, this means that 𝜒2
and thereby the 𝛾family are intimately tied to the study of the Normal distribu-
tion and its friends. The gamma distribution therefore figures among our core
probability distributions.
We will see more about this in Chapter 13, but for now we’ll make do with a
quick example of calculations.
Example 10.3.3
You have studied Oh Mega!, a manufacturer of electronic
component, and in particular their production of resistors. Like all such compo-
nents, their resistors are not infinitely precise, but their resistance values follow
a normal distribution 𝜙(𝜇,𝜎)(x). The goal of your study is to estimate 𝜎. You have
heard that the most expedient way of doing this is to study 𝜏= 1∕𝜎2 rather than
𝜎itself. You are going to
1) determine the probability that 𝜏< 2;
2) find a value of 𝜏0 making it 90% probable that the precision 𝜏is at least as
large as 𝜏0;
3) translate the resultats for 𝜏into resultats for 𝜎.
After some measurements of Oh Mega!’s line of 100 Ω resistors, you have the
following probability distribution for the precision:
𝜏∼𝛾(31.5,16)(t).
The cumulative probability distribution is then Γ(31.5,16)(t) = 𝕏2
63(32t).
You may then answer your questions.
Answer:
1) P(𝜏< 2) = 0.558 82, which we calculate as follows:
(a) Mathematica: CDF[GammaDistribution[31.5, 1
16
], 2];
(b) CASIO: ChiCD(0, 64, 63);
(c) TI: 𝜒2cdf(0, 64, 63);
(d) HP: chisquare_cdf(63, 64).
2) The 𝜏value 𝜏0 for which P(𝜏> 𝜏0) = 0.9, is the 𝜏value where P(𝜏< 𝜏0) =
0.1. That is, 𝜏0 = Γ−1
(31.5,16)(0.1) = 𝕏−2
63 (0.1)∕32 = 1.534 7, which we calculate
as follows:
(a) Mathematica: InverseCDF[GammaDistribution[31.5, 1
16
], 0.1];
(b) CASIO: InvChiCD(0.9, 63)∕32;
(c) TI: Solver. 𝜒2cdf(0, 32x, 63) −0.1 = 0 or Inv𝜒2(0.1, 63)∕32;
(d) HP: chisquare_icdf(63, 0.1)∕32.

10.4 “Student’s” t Distribution, t(𝜇,𝜎,𝜈)

3) That 𝜏< 2 means that 𝜎>
√
0.5, since 𝜏= 1∕𝜎2 and thereby 𝜎= 1∕
√
𝜏.
Then
P(𝜎>
√
0.5) = 0.558 82.
Further, we had that P(𝜏> 1.534 7) = 90%, which is equivalent to
P(𝜎< 0.807 212) = 90%.
.
“Student’s”t Distribution, t(𝝁,𝝈,𝝂)
t distribution: X ∼t(𝜇, 𝜎,𝜈)(x) is a continuous stochastic variable taking
values in ℝ; we say that it follows a t distribution with parameters 𝜇∈ℝ,
𝜎> 0, and 𝜈∈ℕ. The parameter 𝜈is traditionally called “degrees of
freedom”, and is sometimes written df .
pdf: t(𝜇,𝜎,𝜈)(x) = k ⋅
(
1 + (x −𝜇)2
𝜈𝜎2
)−(𝜈+1)∕2
,
where k =
Γ
( 𝜈+1
2
)
Γ
( 𝜈
2
) ⋅
1
𝜎
√
𝜋𝜈
(for the Γ function, see A.2.10).
CDF: T(𝜇,𝜎,𝜈)(x)
iCDF: T−1
(𝜇,𝜎,𝜈)(p)
CASIO: tCD(−1099, (x −𝜇)∕𝜎, 𝜈)
𝜇−𝜎∗InvTCD(p, 𝜈)
HP: student_cdf(𝜈, (x −𝜇)∕𝜎)
𝜇+ 𝜎∗student_icdf(𝜈, p)
TI: tcdf(−1099, (x −𝜇)∕𝜎, 𝜈)
𝜇+ 𝜎∗invT(p, 𝜈)
Wolfram: StudentTDistribution[𝜇, 𝜎, 𝜈]
If your calculation tools do not support t with three parameters, go via the
standard version t𝜈= t(0,1,𝜈), using the relation T(𝜇,𝜎,𝜈)(x) = T𝜈
(x −𝜇
𝜎
)
.
Expected value: 𝜇X =
{
𝜇
𝜈> 1
−
𝜈≤1
Variance: 𝜎2
X =
{𝜎2
𝜈
𝜈−2
𝜈> 2
∞
𝜈≤2
Normal approximation: 𝜙(𝜇, 𝜎) is a good approximation when 𝜈> 30
t( 0,1,ν) (x)
−2
0
2
4
6
0.1
0.2
0.3
0.4
ν=1
ν=2
ν=5
ν=∞ (ϕ−distr.)
T( 0,1,ν) (x)
−2
0
2
4
6
0.2
0.4
0.6
0.8
1.


10 Continuous Distributions
f(x) with μ = 0
−2
0
2
4
6
0.1
0.2
0.3
0.4
t  with σ=1 and ν=1
ϕ with σ=1.25 
F(x) with μ = 0
−2
0
2
4
6
0.2
0.4
0.6
0.8
1.
..
Applications: Almost Everything
The t distribution arises in both Bayesian and frequentist inference when
we have measured n values xk from a Normal distributed population with
unknown standard deviation 𝜎, and are estimating the location measure 𝜇, or
the next measurement, xn+1. The applications of the t distribution are thus the
same as for the Normal distribution.
..
Calculating t Distributions
In ye olden days, everything was calculated by hand, or looked up in tables.
For the Normal distribution, you’d look up Φ(x) = p in suitable tables of Φ. But
T𝜈(x) = p would require one table per degree of freedom 𝜈, making that task a
whole lot more arduous. But when working with the t distribution, it is often a
workaround to calculate from p to x instead of calculating from x to p. These
days, however, both calculations are done with ease in a fraction of a second.
Example 10.4.1 Our estimate of the length (in m) of the next plank from the
sawmill, is X ∼t(4.95,0.1,15). What is the probability that the next plank is shorter
than 5 m?
Answer: This is P(X ≤5) = T(4.95, 0.1, 15)(5) = 0.687 835.
r Mathematica: CDF[StudentTDistribution[4.95, 0.1, 15],5];
r CASIO: tCD
(
−1099, 5−4.95
0.1 , 15
)
;
r HP: student_cdf
(
15, 5−4.95
0.1
)
;
r TI: tcdf
(
−1099, 5−4.95
0.1 , 15
)
.
Example 10.4.2
You are out fishing, and are following an estimate of the
weight in kilograms of the next fish: Y ∼t(2.4,0.7,9). What is the probability that
the next fish weighs in excess of 2 kg?
Answer: This is P(Y ≥2) = 1 −T(2.4, 1.2, 9)(2) = 0.709 152.

10.4 “Student’s” t Distribution, t(𝜇,𝜎,𝜈)

Example 10.4.3 You are observing traffic noise, and your estimate of the noise
from the next truck (in decibels), is Z ∼t(93,12,21). What is the probability that
this noise is in the interval from 90 to 100 dB?
Answer: This is P(90 < Z ≤100) = T(93,12,21)(100) −T(93,12,21)(90) = 0.314 551.
In the section on the Normal distribution, we looked at the sum and differ-
ence between Normal distributed variables. We need similar operations for the
t distribution. We have the following rule for pairs of t distributed variables.
Rule 10.4.4 If X ∼t(𝜇X, 𝜎X, 𝜈X) and Y ∼t(𝜇Y , 𝜎Y , 𝜈Y ) are independent, and Z =
X ± Y, then Z itself does not follow precisely a t distribution, but a very good
approximation to the distribution of the difference is Satterthwaite’s approx-
imation:
Z ∼fZ(z) ≈t(𝜇Z, 𝜎Z,𝜈Z)(z),
where
r 𝜇Z = 𝜇X ± 𝜇Y
r 𝜎Z =
√
𝜎2
X + 𝜎2
Y
r 𝜈Z =
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
(
𝜎2
X
𝜈X+1 +
𝜎2
Y
𝜈Y +1
)2
⎛
⎜
⎜
⎜⎝
(
𝜎2
X
𝜈X+1
)2
𝜈X
+
(
𝜎2
Y
𝜈Y +1
)2
𝜈Y
⎞
⎟
⎟
⎟⎠
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
.
where ⌊x⌋is the integer part of x. If Y ∼𝜙, then 𝜈Z = 𝜈X.
There are variants of the formula for degrees of freedom that give similar
values, and we sometimes speak of the Welch–Satterthwaite formula and test.
Example 10.4.5 If X ∼t(−8,3,11) and Y ∼t(2,4,9), then Z = X −Y ∼t(𝜇Z,𝜎Z,𝜈Z),
where 𝜇Z = (−8) −2 = −10, 𝜎Z =
√
32 + 42 = 5, and
𝜈Z =
⎢
⎢
⎢
⎢
⎢
⎢⎣
(
32
11+1 +
42
9+1
)2
( ( 32
11+1
)2
11
+
( 42
9+1
)2
9
)
⎥
⎥
⎥
⎥
⎥
⎥⎦
= ⌊16.456 5⌋= 16.


10 Continuous Distributions
..
t𝝂,𝜶, the inverse of T(,,𝝂)(x)
In statistics, calculating inverse cumulative probabilities is as important as cal-
culating probabilities. This goes for t distributions as well. We are therefore
interested in the inverse cumulative t distribution T(𝜇,𝜎,𝜈). See the beginning of
this section (Section 10.4) for how to calculate it and its inverse.
There is a useful standard variant of the CDF, the cumulative t distribution,
T𝜈= T(0,1,𝜈). But its inverse, the iCDF, has an even more useful standard vari-
ant, t𝜈,p = T−1
𝜈(p) = T−1
(0,1,𝜈)(p). It uses the same symbol as the pdf, distribution
t function itself, but in this book we distinguish them by the fact that the pdf is
written with the three parameters as an index with parentheses, thus: t(𝜇,𝜎,𝜈)(x),
whereas the standard iCDF is written with the parameter and the argument
values 𝜈and p both in the index (that is: two indexes as opposed to three),
thus: t𝜈,p.
As with z𝛼, the standard inverse for the 𝜙distribution, t𝜈, p indicates the value
of x for which the area under the left tail of t(0,1,𝜈)(⋅), from −∞to x, has area p.
The relation between t𝜈,p and the general T−1 is
T−1
(𝜇,𝜎,𝜈)(p) = 𝜇+ 𝜎⋅t𝜈,p.
Example 10.4.6 Find t2, 0.1.
r In the table of t𝜈,p values, p is given by the choice of column, and 𝜈by the
choice of row: to find t2, 0.1, locate the column for p = 0.1, and the row for
𝜈= 2. They intersect in the number −1.885 6, which means that t2, 0.1 =
−1.885 6.
r Mathematica: InverseCDF[StudentTDistribution[0, 1, 2], 0.1] gives
−1.885 62.
r CASIO: −InvTCD(0.1, 2) gives −1.885 62 (notice the minus sign!).
r HP: student_icdf(2, 0.1) gives −1.885 62.
r TI: invT(0.1, 2) gives −1.885 62.
Example 10.4.7
Your estimate of X, the weight of the next capercaillie you
shoot in the Long Forest, is X ∼t(3.5, 0.7, 11). Find a fixed weight x such that there
is a probability of exactly 5% that the next capercaillie you shoot weighs less
than that.
Answer: We show our standard ways of calculating:
r T−1
(𝜇,𝜎,𝜈)(0.05) = 𝜇+ 𝜎⋅t𝜈, 0.05 = 3.5 −0.7 ⋅t11, 0.05 = 2.242 88
r Mathematica: InverseCDF[StudentTDistribution[3.5, 0.7, 11], 0.05];
r CASIO: 3.5 −0.7⋅InvTCD(0.05, 11);
r HP: 3.5 + 0.7⋅student_icdf(11, 0.05);
r TI: 3.5 + 0.7⋅invT(0.05, 11).

10.5 Beta Distribution, 𝛽(a,b)

Rule 10.4.8 t𝜈,1−p = −t𝜈,p
Example 10.4.9 X ∼t(6,2.1,3). Find x such that P(X ≤x) = 0.9.
Answer: 𝜇+ 𝜎⋅t𝜈,p = 6 + 2.1 ⋅t3, 0.9
= 6 −2.1 ⋅t3, 0.1 = 6 −2.1 ⋅(−1.637 74) = 9.439 26.
.
Beta Distribution, 𝜷(a,b)
𝛽distribution: X ∼t(𝜇, 𝜎,𝜈)(x) is a continuous stochastic variable taking
values in [0, 1]; we say that it follows a 𝛽distribution with parameter a, b > 0.
pdf: 𝛽(a,b)(x) =
1
B(a, b) ⋅xa−1(1 −x)b−1,
where B(a, b) is the Euler B function (A.2.14). The notation for the CDF is
thus I(a,b)(x). To calculate CDF and iCDF below, we use the F distribution
(A.3.1).
CDF: I(a,b)(x)
iCDF: I−1
(a,b)(p)
CASIO: FCD
(
0,
bx
a(1−x), 2a, 2b
)
1∕
(
1 +
b
a⋅InvFCD(1−p,2a,2b)
)
HP: fisher_cdf
(
2a, 2b,
bx
a(1−x)
)
1∕
(
1 +
b
a⋅fisher icdf(2a,2b,p)
)
TI: Fcdf
(
0,
bx
a(1−x), 2a, 2b
)
CX: 1∕
(
1 +
1
a⋅InvF(p,2a,2b)
)
83+: Solver: Fcdf
(
0,
bx
a(1−x), 2a, 2b
)
−
p = 0 ≫x = 0.5
Wolfram: BetaDistribution[a,b]
Expected value: 𝜇X =
a
a+b
Variance: 𝜎2
X =
ab
(a+b)2(a+b+1)
Normal approximation: 𝜙(𝜇X, 𝜎X) is a good approximation when a, b > 10.
β( 3,b) (x)
0
0.2
0.4
0.6
0.8
1.
1
2
3
4
5
b=0.5
b=1
b=3
b=7
b=12
I( 3,b) (x)
0.2
0.4
0.6
0.8
1.
0.2
0.4
0.6
0.8
1.


10 Continuous Distributions
β( a,3) (x)
0
0.2
0.4
0.6
0.8
1.
1
2
3
4
5
a=0.5
a=1
a=3
a=7
a=12
I( 1,3) (x)
0.2
0.4
0.6
0.8
1.
0.2
0.4
0.6
0.8
1.
β( a,a) (x)
Equal parameters
0
0.2
0.4
0.6
0.8
1.
1
2
3
4
5
a=b=0.5
a=b=1
a=b=3
a=b=8
a=b=20
I( a,a) (x)
0.2
0.4
0.6
0.8
1.
0.2
0.4
0.6
0.8
1.
..
Application: Proportions
The beta distributions are primarily used in the study of proportions, including
the type of proportion we call probabilities. It is the preferred distribution for
estimating the parameter p for Bernoulli processes. Since the study of propor-
tions is central, this makes the beta distribution a similarly central probability
distribution, especially in Bayesian analysis. When we employ the 𝛽distribu-
tions to study a proportion 𝜋, this means that we do not know its value for
sure, and that instead, the 𝛽probability distribution expresses our knowledge
of it. 𝜋is then itself a stochastic variable, 𝜋∼𝛽(a,b). The proportion 𝜋can be
for instance any of the following.
r The probability that an unknown biased coin lands heads up.
r The proportion of patients having a certain disease cured by a given
medicine.
r The probability that Osman Sow of the MK Dons scores his next goal with
the left foot.
r The percentage of voters who will vote Libertarian in the next US presidential
election.
r What proportion of the day will be cloudy.
r Pepsi Cola’s market share in Russia next year.
r The probability that Manuel Neuer of FC Bayern Munich saves the next shot
at his goal.

10.5 Beta Distribution, 𝛽(a,b)

When we say about a proportion X that it is a stochastic variable X ∼𝛽(a,b),
we say something about how probable it is that the proportion is within a
certain interval. We will look more closely at this in Section 13.2 about sta-
tistical inference, where we have rules for Bayesian updating of probabilities
for proportions through 𝛽distributed prior probabilities.
But let us return to the present: how do we calculate 𝛽distributions?
..
Calculating 𝜷Distributions
The first quantities that we want to calculate for X ∼𝛽(a,b), are the probabilities
P(X ∈(A, B)), the expected value 𝜇X, and the variance 𝜎2. We calculate the lat-
ter two from the parameters by means of the formulas on the overview sheet
at the beginning of Section 10.5, whereas the probability in principle involves
calculating an integral:
P(X ∈(A, B)) = ka,b ⋅∫
B
A
xa−1(1 −x)b−1 dx,
where ka,b = Γ(a + b)
Γ(a)Γ(b).
The resulting integral will be a polynomial, and probably one of a high degree
resulting from calculating (1 −x) to some power. This is the kind of calculation
we leave to our calculation tools.
Example 10.5.1 Bard is looking at 𝜋, the proportion of patients who have their
fractured tailbone healed within a week of taking WunderzilTM.
1) After a controlled study, Bard concludes that 𝜋∼𝛽(17,5).
(a) What does Bard’s result say is the expected proportion of healed
patients, E[𝜋]?
(b) How sharp is this estimate?
(c) What is the probability that 𝜋is larger than 75%?
2) Bard conducts a second study, and updates his estimate to 𝜋∼𝛽(40,11).
(a) What is now the expected proportion of healed patients, E[𝜋]?
(b) How precise is the new estimate?
(c) What is the new probability that 𝜋is larger than 75%?
Answer:
1) After the first study:
(a) 𝜇𝜋=
17
17+5 = 0.772 727;
(b) we recall from Section 7.6.1 that the precision is 𝜏= 1∕𝜎2, so for a 𝛽(a,b)
distributed stochastic variable 𝜋we have
𝜏𝜋= (a + b)2(a + b + 1)
ab
= (17 + 5)2(17 + 5 + 1)
17 ⋅5
= 130.965;


10 Continuous Distributions
(c) the probability that 𝜋is larger than 75% is then
P(𝜋≥0.75) = 1 −I(17,5)(0.75) = ∫
1
0.75
𝛽(17,5)(p)dp = 0.632 58.
2) After the second study:
(a) 𝜇𝜋=
40
40+11 = 0.784 314;
(b) this time,
𝜏𝜋= (40 + 11)2(40 + 11 + 1)
40 ⋅11
= 307.391;
(c) the probability that 𝜋is larger than 75% is now updated to
P(𝜋≥0.75) = 1 −I(40,11)(0.75) = ∫
1
0.75
𝛽(40,11)(p) dp = 0.737 798.
The second estimate, which Bard got after collecting more data, was (not
surprisingly) sharper than the first estimate.
Example 10.5.2
Your estimate of X, the proportion of students who prefer
Pepsi Max to other light sodas, is X ∼𝛽(102,53)(x). Find the probability that the
proportion who prefer Pepsi Max is less than 70%.
Answer: We are finding P(X < 0.7).
r Mathematica: CDF[BetaDistribution[102, 53],0.7]=0.865 549.
Most desktop calculators do not have the 𝛽distribution built in, so we must
rewrite to make it fit what’s available. It turns out that calculations of the 𝛽
distribution may be rewritten into calculations concerning the F distribution
(Section A.3.1). The recipe is given in the overview at the beginning of Sec-
tion 10.5.
r CASIO: FCD(0,
53⋅0.7
102(1−0.7), 2 ⋅102, 2 ⋅53) = 0.865 549.
r HP: fisher_cdf(2 ⋅102, 2 ⋅53,
53⋅0.7
102(1−0.7)) = 0.865 549.
r TI: Fcdf(0,
53⋅0.7
102(1−0.7), 2 ⋅102, 2 ⋅53) = 0.865 549.
Example 10.5.3
Your estimate of the proportion of left-foot goals by Arjen
Robben (FC Bayern Munich) is Y ∼𝛽(15,24)(x). Find the probability that the true
proportion lies between 20 and 40%.
Answer: We are calculating P(0.2 < X < 0.4).
r Mathematica: Probability[0.2 < x < 0.4, x ≈BetaDistribution[15,24] gives us
0.582 778.
r HP: fisher_cdf(30, 48,
24⋅0.4
15(1−0.4)) −fisher_cdf(30, 48,
24⋅0.2
15(1−0.2)).

10.5 Beta Distribution, 𝛽(a,b)

On the CASIO and TI calculators, the cumulative probability distributions
have two x value entries, lower and upper, so what we get out is really the prob-
ability that the stochastic variable takes a value between lower and upper. We
make use of that feature:
r CASIO: FCD(
24⋅0.2
15(1−0.2),
24⋅0.4
15(1−0.4), 2 ⋅15, 2 ⋅24);
r TI: Fcdf(
24⋅0.2
15(1−0.2),
24⋅0.4
15(1−0.4), 2 ⋅15, 2 ⋅24).
How do we calculate the probability that 5 of Arjen Robben’s next 15 goals
are scored with his left foot? It is tempting to make a best estimate p of the pro-
portion of his left-foot scorings, and to calculate the answer using the binomial
distribution. This solution even sounds correct – and, because it is so convinc-
ing, we need to look at it in detail to see why it is wrong. The short of it, in
summary, is that the uncertainty of the estimate p cannot be neglected, since it
has an effect. We have actually seen this once before, in Note 6.7.2 and the asso-
ciated problems. We will see this effect even more spectacularly in the applied
example (Example 13.2.2) in Chapter 13.
For the correct solution, we look at the general question: when the 𝛽distri-
bution describes a game’s probability 𝜋, what is the probability of a sequence
of positive (⊤) and negative (⊥) outcomes? Or for a concrete example (Exam-
ple 10.5.6): if we have a coin with probability 𝜋of H, and 𝜋∼𝛽(18,22), what is
then the probability of HHTHTHTH?
Rule 10.5.4
If X1, … , Xn are trials in a Bernoulli process with parame-
ter 𝜋, and 𝜋∼𝛽(a,b), then the probability of a given sequence of k⊤and l⊥
(k + l = n) is given by
P =
ka,b
ka+k,b+l
=
(
Γ(a+b)
Γ(a)Γ(b)
)
(
Γ(a+b+k+l)
Γ(a+k)Γ(b+l)
) =
(
a+b
a
)
⋅
ab
a+b
(
a+b+k+l
a+k
)
⋅(a+k)(b+l)
a+b+k+l
.
where the last equality is for integers only. For half-integer values, use the fact
that
Γ(n + 1
2) = (2n)!
n!4n
√
𝜋.
The probability of a combination with k⊤and l⊥equals the probability of
such a sequence times the number of such sequences,
(
k+l
k
)
.1
1The probability of the combination has its own name, the beta binomial distribution (see
Appendix A.3.3).


10 Continuous Distributions
Proof: For each value of p, the probability of a sequence with k⊤and l⊥equals
pk(1 −p)l. Similar to what we did in 6.4.1, we take the weighted mean of the
sequence probabilities, with weight per p equal to f (p) = 𝛽(a,b)(p) for p. Then
P(k⊤, l⊥) = ∫
1
0
pk(1 −p)l𝛽(a,b)(p) dp = ∫
1
0
ka,bpa+k−1(1 −p)b+l−1 dp
=
ka,b
ka+k,b+l ∫
1
0
ka+k,b+l pa+k−1(1 −p)b+l−1 dp
=
ka,b
ka+k,b+l ∫
1
0
𝛽(a+k,b+l)(p) dp =
ka,b
ka+k,b+l
.
Example 10.5.5 𝜋∼𝛽(12.5,23.5). Find the probability that the next three obser-
vations are ⊤⊥⊤.
Answer: We employ Rule 10.5.4, but since a and b are half integers, we cannot
use the simplified formula for integers. We put k = 2 and l = 1 into the formula,
and get
P(⊤⊥⊤) =
(
Γ(12.5+23.5)
Γ(12.5)Γ(23.5)
)
(
Γ(12.5+23.5+2+1)
Γ(12.5+2)Γ(23.5+1)
) =
(
Γ(36)
Γ(12.5)Γ(23.5)
)
(
Γ(39)
Γ(14.5)Γ(24.5)
)
=
(
35!
24!
12!412
√
𝜋⋅
46!
23!423
√
𝜋
)
(
38!
28!
14!414
√
𝜋⋅
48!
24!424
√
𝜋
) ≈0.078 347 3.
Example 10.5.6
We have a coin whose probability 𝜋of H is distributed
𝜋∼𝛽(18,22).
r What is the probability of HHTHTHTH? (sequence).
r What is the probability of 5H and 3T? (combination).
Answer: Here, a = 18, b = 22, k = 5, and l = 3, so we may use the simplified
formula for integers:
P(HHTHTHTH) =
(
18+22
18
)
⋅18⋅22
18+22
(
18+22+5+3
18+5
)
⋅(18+5)(22+3)
18+22+5+3
=
1 254
414 305 ≈0.003 026 76;
P(5H, 3T) =
(5 + 3
5
)
P(HHTHTHTH) = 702 24
414 305 ≈0.169 498.

10.5 Beta Distribution, 𝛽(a,b)

0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
1
2
3
(a) a = 1, b = 5.
0
0.1
0.2
0.3
0.4
1
2
3
4
5
6
(b) a = 5, b = 25.
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35
2
4
6
8
(c) a = 10, b = 50.
0.05
0.1
0.15
0.2
0.25
0.3
2
4
6
8
10
12
(d) a = 20, b = 100.
0.12 0.14 0.16 0.18
0.2
0.22
5
10
15
20
25
(e) a = 100, b = 500.
0.14
0.15
0.16
0.17
0.18
0.19
10
20
30
40
50
(f) a = 500, b = 2500.
Figure .Normal approximation and comparison to increasing parameter values for 𝛽.
..
Normal Approximation
To calculate 𝛽(a, b) for very large values of a and b, we must resort to approxi-
mations even when we use a calculating tool. For this, we use Rule 10.1.13, Nor-
mal approximation, from Section 10.1.5. Since 𝛽(a,b) has expected value
a
a+b and
standard deviation
√
ab
(a+b)2(a+b+1), the correct Normal approximation for 𝛽(a,b)
is 𝜙(
a
a+b ,
√
ab
(a+b)2(a+b+1)
). In Figure 10.11, we have let 𝛽be blue, and have colored
N purple. Note the scaling along the two axes; how the curves get narrower and
taller as the parameter values for a and b increase.
Example 10.5.7 X ∼𝛽(2 183, 7 927). What are
1) 𝜇X;
2) 𝜎X;
3) P(X ∈(0.21, 0.22))?
Answer: a = 2 183 and b = 7 927, so
1) 𝜇=
2 183
2 183+7 927 = 0.215 925;
2) 𝜎=
√
2 183×7 927
(2 183+7 927)2(2 183+7 927+1) = 0.004 091 98;
3)P(X ∈(0.21, 0.22)) = Φ(0.215 925, 0.004 091 98)(0.22)
−Φ(0.215 925, 0.004 091 98)(0.21) = 0.766 528.
There is a 76% probability that X ∈(0.21, 0.22).


10 Continuous Distributions
..
Inverse Cumulative 𝜷Distribution
In statistics, calculating inverse cumulative probabilities is as important as cal-
culating the probabilities themselves. This applies to the 𝛽distributions as well.
We will therefore look at the inverse of the cumulative 𝛽distribution, I(a,b),
and show an example of calculating it on our favourite tools, commonly via
the inverse F distribution,
I−1
(a,b)(p) =
1
1 +
b
a⋅F−1
(2a,2b)(p)
.
Our tools find I−1
(a,b)(p) thus:
r Mathematica: InverseCDF[BetaDistribution[a,b],p];
r CASIO: 1∕(1 +
b
a⋅InvFCD(1−p, 2a, 2b));
r HP: 1∕(1 +
b
a⋅fisher icdf(2a, 2b, p))
r TI CX: 1∕(1 +
b
a⋅InvF(p, 2a, 2b))
r TI 83+: Solver: Fcdf(0,
bx
a(1−x), 2a, 2b) −p = 0 ≫x = 0.5
If direct calculation of I−1
(a,b)(p) is inaccessible, and even calculation via rewrit-
ing into the F distribution is unavailable, the best remaining route is the Normal
approximation, Φ−1
(𝜇X,𝜎X)(p).
Example 10.5.8
Bard has estimated the proportion 𝜓of Sith among the
Jedi. According to his findings, it is 𝜓∼𝛽(10,40)(p). He wants to find a number
p0 ∈(0, 1) so that there is an exact probability of 90% that the proportion of
Sith is less than or equal to p0.
Answer: Bard needs to find a p0 such that P(𝜓≤p0) = I(10,40)(p0) = 0.9. In
other words, he needs to calculate p0 = I−1
(10,40)(0.9). He does that in one of the
following ways:
r Mathematica: InverseCDF[BetaDistribution[10,40],0.9] gives p0 = 0.274 411;
r CASIO: 1∕(1 +
40
10⋅InvFCD(1−0.9, 2 × 10, 2 × 40))
r HP: 1∕(1 +
40
10⋅fisher icdf(2 × 10, 2 ×, 0.9));
r TI: Solver: Fcdf(0,
40x
10(1−x), 20, 80) −0.9 = 0 or 1∕(1 +
40
10⋅InvF(0.9,20,80));
r Normal approximation: 𝜇𝜓= 0.2, 𝜎𝜓= 0.056 011 2:
I−1
(10,40)(0.9) ≈Φ−1
(0.2, 0.0560112)(0.9) = 0.271 781.
Hence, it is less than 90% probable that a smaller proportion of the Jedi than
27% are Sith.

10.6 Weibull Distribution, weib(𝜆,k)
∗

.
Weibull Distribution, weib(𝝀,k)
∗
Weibull distribution T ∼weib(k,𝜆)(x) is a continuous stochastic variable
taking values in [0, ∞). We say that it follows the Weibull distribution with
parameters 𝜆, k > 0.
pdf: weib(k,𝜆)(t) = k
𝜆×
( t
𝜆
)k−1
e−(t∕𝜆)k
CDF:
iCDF:
WEIB(k,𝜆)(t) = 1 −e−(t∕𝜆)k
WEIB−1
(k,𝜆)(p) = 𝜆(−ln(1 −p))1∕k
Wolfram: WeibullDistribution[k, 𝜆]
Other distributions:
Exponential: weib(1,1∕𝜆)(t) = exp𝜆(t)
Rayleigh: WEIB(
2,
√
2 𝜎
)(t) = RAYL𝜎(t) = 1 −e−t2∕2𝜎2
Expected value:
Variance:
𝜇T = 𝜆
k ⋅Γ
(1
k
)
𝜎2
T = 𝜆2
(
Γ
(
1 + 2
k
)
−
(
Γ
(
1 + 1
k
))2)
weib( 1.5 , λ) (x)
0
2
4
6
8
10
12
0.2
0.4
0.6
0.8
1.
λ=0.8
λ=2
λ=3
λ=5
λ=8
WEIB ( 1.5 , λ) (x)
0
2
4
6
8
10
12
0.2
0.4
0.6
0.8
1.
weib( k , 2) (x)
0
2
4
0.2
0.4
0.6
0.8
1.
k=0.5
k=1
k=1.3
k=2
k=4
3
1
( k , 2) (x)
0
2
4
0.2
0.4
0.6
0.8
1.
WEIB
..
Application: Waiting and Decay Times
The Weibull distribution is, like the Erlang and exponential distributions, used
in the study of waiting times. The exponential distribution is a special case of


10 Continuous Distributions
Weibull with the first parameter k = 1. The waiting times typically described
by the Weibull distribution are the lifetimes of things, components, or living
beings. Since what the Weibull is waiting for is a death, it is said to be a study of
decay times. As opposed to the variants of the Erlang distribution, the Weibull is
not memoryless, but rather knows how much time has passed since the incep-
tion. And as opposed to the Erlang distribution, the decay rate is not constant,
but is rather proportional to some power of the time that has passed since the
inception, tk−1. The length of a human life is Weibull distributed, and k −1 > 0,
since the rate of death is higher when you are 89 than when you are 5.
The death and decay rate, that is, the probability density describing how
probable it is that a component that has survived up until time t will die at
precisely time t, either rises or falls with time or stays constant.
r If the death rate sinks with time, this indicates a high “infant mortality”; for
industrial components, this is a sign that many of the components had initial
production errors, and therefore failed early. Or with living beings, it indi-
cates complications around birth and early years typical of societies with hard
conditions for children. This corresponds to k < 1.
r If the death rate sinks with time, this indicates that the deaths are due to wear.
In human terms, this is more akin to modern societies, and corresponds to
k > 1.
r If the death rate is constant, this indicates mortality due to random events.
In human terms, this would be like a society where most deaths were by acci-
dent, war, or other randomly selected killings that kill irrespective of age –
much like, presumably, bronze age cultures. This corresponds to k = 1, which
is the exponential distribution.
The Weibull distribution’s first parameter 𝜆decides the scale of the distribu-
tion, or in more colloquial terms: how long-lived the population is. The param-
eter k determines the shape of the distribution: if it is heavy on early, late, or
medium term deaths. The upper illustration on the overview page for this sec-
tion (10.6) shows how the shape changes weib(k,𝜆) from a rapidly descending
curve that is “thick” around 0 for k < 1, via the exponential curve when k = 1,
and how it progresses towards having a distinct hump as k grows beyond 1.
The lower illustration in the overview shows how 𝜆stretches or compresses
the curve of weib(k,𝜆)(x) without altering its fundamental shape.
The Weibull distribution with k = 2 is the Rayleigh distribution, and so,
like the Rayleigh distribution, the Weibull distribution is used in the study of
weather and related phenomena.
..
Calculating the Weibull Distribution
Calculating the Weibull distribution is straightforward from the formulas, for
pdf, CDF, and iCDF alike. This is one of the few distributions where the Normal

10.7 Exercises

approximation is a bad idea, since calculating the Weibull distribution itself is
simpler – and of course more exact!
Example 10.6.1
T follows a Weibull distribution with parameters 𝜆= 5.6
and k = 41. Use the Normal approximation to find P(T ≤5.6), and then check
against the exact value.
Answer:
1) The Weibull distribution with parameters 𝜆= 5.6 and k = 41 has expected
value 𝜇= 5.52 and standard deviation 𝜎= 0.17, so its Normal approxima-
tion is 𝜙(5.52,0.17).
2) Rule 10.1.13 then says that
P(T ≤5.6) = Φ(5.52, 0.17)(5.6) = 0.68.
(By comparison, the exact value is 0.63.)
Example 10.6.2
Dynamic Acoustics’ top model headphones have a lifetime
that follows a Weibull distribution with parameters 𝜆= 15.4 and k = 1.7. They
have a 5 year warranty.
1) What is the principal cause of failure in these headphones? Defect, random-
ness, or wear?
2) What is the probability that the headphones will start failing before the war-
ranty expires?
3) What is the probability that the headphones last for at least 20 years?
Answer:
1) Since k = 1.7 > 1, the principal cause of failure is wear.
2) Their lifetime is a stochastic variable T with distribution weib(1.7,15.4). Then
P(T ≤5) = WEIB(1.7,15.4)(5) = 1 −e
−
(
5
15.4
)1.7
≈0.14 = 14%.
3) We invoke the rule of complementary probabilities, and then
P(T > 20) = 1 −WEIB(1.7,15.4)(20) = e
−
( 20
15.4
)1.7
≈0.21 = 21%.
.
Exercises
..
Normal Distribution, 𝝓(𝝁,𝝈)
1
Get to know your calculation tools and tables, to familiarize yourself with
computing 𝜙(𝜇,𝜎)(x), Φ(𝜇,𝜎)(x), and z𝛼. Write down your findings in a note-
tobok for probability distributions.


10 Continuous Distributions
2
Cumulative Normal distribution Φ(𝜇,𝜎) and probability
(a) X ∼𝜙(0,1); what is P(X ≤1.43)?
(b) X ∼𝜙(0,1); what is P(X > 1.43)?
(c) X ∼𝜙(0,1); what is P(X ≤−2.38)?
(d) X ∼𝜙(0,1); what is P(X > −2.38)?
(e) X ∼𝜙(3, 1.9); what is P(X ≤4.35)?
(f) X ∼𝜙(3, 1.9); what is P(X > 4.35)?
(g) X ∼𝜙(−7, 4); what is P(X ≤0.2)?
(h) X ∼𝜙(0,1); what is P(X ∈(−2.38, 1.43))?
(i) X ∼𝜙(10,5); what is P(X ∈(8, 13))?
3
Inverse cumulative Normal distribution z
(a) Find z0.05.
(b) Find z0.95.
(c) Let X ∼𝜙(2,1). Find a such that P(X ≤a) = 0.05.
(d) Let X ∼𝜙(2,1). Find a such that P(X ≤a) = 0.95.
4
The Normal approximation
(a) A discrete stochastic variable X has expected value 𝜇X = 3 and
𝜎X = 1.2. Use the Normal approximation to find P(X ≤4).
(b) A continuous stochastic variable X has expected value 𝜇X = 3 and
𝜎X = 1.2. Use the Normal approximation to find P(X ≤4).
(c) A discrete stochastic variable X has expected value 𝜇X = 5.1 and
𝜎X = 2.2. Use the Normal approximation to find P(X ∈{6, 7}).
(d) A continuous stochastic variable X has expected value 𝜇X = 5.1 and
𝜎X = 2.2. Use the Normal approximation to find P(X ∈(5, 7)).
(e) A discrete stochastic variable X has expected value 𝜇X = 12.1 and
𝜎X = 4.7. Use the Normal approximation to find
P = P(X ∈{12, 13, 14, 15, 16, 17, 18, 19}).
5
Sums of Normally distributed stochastic variables
(a) X1 ∼𝜙(0,1), X2 ∼𝜙(−1,3), X3 ∼𝜙(2,4), X4 ∼𝜙(2,2). These four stochas-
tic variables are independent, and X = X1 + X2 + X3 + X4. What is the
distribution of X?
(b) Xk ∼𝜙(2,4), and X = ∑10
k=1 Xk. What is the distribution of X?
(c) Xk ∼𝜙(7,4), k = 1, 2, 3, 4. Let X be the average of the Xk. What is the
distribution of X?
..
Binormal Distribution, 𝝓(𝝁, 𝚺)
X and Y independent
6
What is the probability that X < 7 and Y < 0, when Z = (X, Y) is binor-
mally distributed with
𝝁=
[
5
−3
]
and
𝜎=
[
100
0
0
81
]
?

10.7 Exercises

X and Y dependent
7
Let X be the stock price of SnowPeak Ltd, and let Y be the stock price of
FjordWater Ltd. The prices of the two stocks are correlated, so Z = (X, Y)
is binormally distributed with parameters
𝝁=
[
20
12
]
and
𝜎=
[
49
−28
−28
64
]
.
(a) Find the probability distribution for the price of each stock separately –
that is: the marginal probability distributions fx(x) and fy(y).
(b) Find the probability distribution of the stock price of each of the stocks
as a function of the price of the other – that is: the conditional proba-
bility distributions fx|y(x) and fy|x(y).
(c) Find the distribution of Z as a rotation of an independent distribution.
..
Gamma Distribution, 𝜸(k,𝝀), With Family
8
T ∼exp5. What are 𝜇T, 𝜎T, and P(T ≤4)?
9
T ∼exp2.3. What are 𝜇T, 𝜎T, and P(T ≤3.2)?
10
T ∼exp3.1. What are 𝜇T, 𝜎T, and P(T > 1.2)?
11
T ∼exp4.4. What are 𝜇T, 𝜎T, and P(T ∈⟨0.15, 0.28])?
12
T ∼exp𝜆, and E[T] = 2.9. What are 𝜆, 𝜇T, and 𝜎T?
13
T ∼exp𝜆, and Var(T) = 2.25. What are 𝜆, 𝜇T, and 𝜎T?
14
T ∼erl(2,5). What are 𝜇T, 𝜎T, and P(T ≤1)?
15
T ∼erl(3, 2.3). What are 𝜇T, 𝜎T, and P(T ≤1.7)?
16
T ∼erl(5,3.1). What are 𝜇T, 𝜎T, and P(T > 2.3)?
17
T ∼erl(2,4.4). What are 𝜇T, 𝜎T, and P(T ∈⟨0.2, 2])?
18
T ∼erl(2,𝜆), and E[T] = 2.9. What are 𝜆, 𝜇T, and 𝜎T?
19
T ∼erl(3,𝜆), and Var(T) = 2.25. What are 𝜆, 𝜇T, and 𝜎T?
20
You and Morty Matrix are campaigning on the high street for the com-
ing election, handing out leaflets for the “Mathematics Party, because
2 + 2 = 4”. You meet 1 sympathizer every 23 minutes. This waiting time
is exponentially distributed.


10 Continuous Distributions
(a) What is the probability that the next sympathizer arrives within half
an hour?
(b) What is the probability that 2 sympathizers arrive within half an hour?
21
You are on probation with Statisticus Ltd for 4 weeks, as sales engineer. The
waiting time between sales is exponentially distributed, but with param-
eter 𝜆being a characteristic of the salesman. The requirement for being
permanently hired is 2 sales within the probation period.
(a) What is the probability of getting the first sale within 2 weeks, as a
function of 𝜆, when time is measured in weeks?
(b) What must your 𝜆be if you are going to have at least a 60% probability
of permanent employment?
22
You are measuring a radioactive material, and the number of minutes
until the next click on the Geiger counter is exponentially distributed with
parameter 𝜆= 0.25.
(a) What is the expected waiting time for 10 clicks?
(b) What is the probability of at least 3 clicks within 2 minutes?
(c) What is the probability of precisely 3 clicks within 2 minutes?
23
At the bookstore where you are working, the number of minutes until the
next sale of the book Home Engineering is exponentially distributed with
parameter 𝜆= 1
15.
(a) What is expected time until the next sale of Home Engineering?
(b) What is the probability that the next sale happens in between 5 and
20 minutes?
24
This Christmas, you have a seasonal job in a bookstore. T, the number of
minutes until the next customer asks about the book Home Engineering is
exponentially distributed with parameter 𝜆= 1
15.
(a) Write down the probability distribution of the waiting time until 3 cus-
tomers have asked about the book Home Engineering.
(b) What is the probability that you must wait more than 30 minutes before
3 customers have asked about the book Home Engineering? Calculate
in both of the following ways.
r Calculate directly on the distribution itself.
r Calculate by using the Normal approximation.
(c) What is the probability that precisely m customers have asked about
the book during a 30 minute time period?
(d) What is the expected number of customers who have asked about the
book during the period?
25
You have studied Oh Mega’s production of capacitors. Just as with the
resistors in Example 10.3.3, their values follow a Normal distribution

10.7 Exercises

𝜙(𝜇,𝜎)(x), and just as in the case of the resistors, you study 𝜏, and get that
𝜏∼𝛾(16, 4)(t).
(a) Write down the cumulative probability distribution of 𝜏by means of a
𝜒2 distribution.
(b) Find the probability that 𝜏< 6.
(c) Find a value 𝜏0 such that P(𝜏< 𝜏0) = 90%.
(d) Translate the results for 𝜏into results for 𝜎.
26
You have studied the salmon in the river Loppa, and are more interested in
the weight variations than in the mean weight. The salmon weight follows
a Normal distribution 𝜙(𝜇,𝜎)(x), so you study the variance by means of 𝜏.
Your investigations have concluded that 𝜏∼𝛾(19.5, 44)(t).
(a) Write down the cumulative probability distribution of 𝜏by means of a
𝜒2 distribution.
(b) Find the probability that 𝜏> 0.64.
(c) Find a value 𝜏0 such that P(𝜏> 𝜏0) = 95%.
(d) Translate the results for 𝜏into results for 𝜎.
27
You have studied the brightness of a certain type of star, and are interested
in the variation. The brightness follows a Normal distribution 𝜙(𝜇,𝜎)(x), so
you study the variance by means of 𝜏. Your investigations have concluded
that 𝜏∼𝛾(101.5, 15)(t).
(a) Write down the cumulative probability distribution of 𝜏by means of a
𝜒2 distribution.
(b) Find the probability that 𝜎> 2.
(c) Find a value 𝜎0 such that P(𝜎< 𝜎0) = 98%.
..
Student’s t Distribution, t(𝝁,𝝈,𝝂)
28
Find t4, 0.1.
29
X ∼t(0,1,8). Find an x such that P(X ≤x) = 0.005.
30
X ∼t(0,1,6). Find an x such that P(X ≤x) = 0.9.
31
X ∼t(7,3,11). Find an x such that P(X ≤x) = 0.95.
32
X ∼t(−3.14, 7.2, 23). Find an x such that P(X ≤x) = 0.999.
33
X ∼t(4.4, 3.1,7) and Y ∼t(−0.1, 2.2,18). Find the probability distribution of
Z = X −Y.
..
Beta Distribution, 𝜷(a,b)
34
X ∼𝛽(1,1). Find 𝜇X, 𝜎X, P(X ≤0.4), and graph the probability distribution.


10 Continuous Distributions
35
X ∼𝛽(2,2). Find 𝜇X, 𝜎X, P(X > 0.6), and graph the probability distribution.
36
X ∼𝛽(2,3). Find 𝜇X, 𝜎X, P(X ∈⟨0.3, 0.6]), and graph the probability
distribution.
37
X ∼𝛽(3,2). Find 𝜇X, 𝜎X, P(X ∈⟨0.4, 0.65]), and graph the probability
distribution.
38
X ∼𝛽(53,22). Find P(X ≤0.7), and p such that P(X ≤p) = 80%.
39
X ∼𝛽(108,72). Find P(X ≤0.5), and p such that P(X ≤p) = 95%.
40
X ∼𝛽(17,42). Find P(X ≤0.2) and p such that P(X ≤p) = 10%.
41
X ∼𝛽(43,19). Find P(X ≥0.8), and p such that P(X ≥p) = 90%.
42
X ∼𝛽(128,81). Find P(X ≥0.6), and p such that P(X ≥p) = 99%.
43
X ∼𝛽(491,396). Find 𝜇X and 𝜎X, and find P(X ∈[0.45, 0.50⟩). (You may cal-
culate this both exactly and with the Normal approximation.)
44
In the following problems, the probability distributions for the parameter
p of a Bernoulli process are given. Find the probability of event H.
(a) p ∼𝛽(12,17)(p). H = ⊤.
(b) p ∼𝛽(12,17)(p). H = ⊥.
(c) p ∼𝛽(12,17)(p). H = ⊥⊤.
(d) p ∼𝛽(12,17)(p). H = ⊤⊥.
(e) p ∼𝛽(12,17)(p). H = ⊤⊤⊤⊥⊥⊤⊥⊥.
(f) p ∼𝛽(12,17)(p). H = ⊥⊥⊥⊥⊤⊤⊤⊤.
(g) p ∼𝛽(12,17)(p). H = 4⊥and 4⊤(combination).
(h) p ∼𝛽(52,12)(p). H = a given sequence with 3⊤and 1⊥.
(i) p ∼𝛽(52,12)(p). H = the combination 3⊤and 1⊥.
(j) p ∼𝛽(52,12)(p). H = the combination 4⊤and 0⊥.
(k) p ∼𝛽(52,12)(p). H = the combination 2⊤and 2⊥.
(l) p ∼𝛽(52,12)(p). H = the combination 1⊤and 3⊥
(m) p ∼𝛽(52,12)(p). H = the combination 0⊤and 4⊥.
(n) p ∼𝛽(52,12)(p). H = at least 3⊤in 4 trials.
(o) p ∼𝛽(52,12)(p). H = less than 3⊤in 4 trials.
45
Let X be the proportion of 40 W light bulbs that break when dropped onto
a carpet from a height of 1 m. You have tried it out, and your probability
distribution for X is now X ∼𝛽(23,48).

10.7 Exercises

(a) What is the expected proportion of light bulbs 𝜇X that break when
dropped onto a carpet from a height of 1 m?
(b) What is the probability that the next light bulb you drop onto a carpet
from a height of 1 m, will break?
(c) What is the probability that X is within 5% of this value?
46
As above, but you have made more trials, and now X ∼𝛽(50,103).
47
It is election time, and you are fact checking candidate April Weather-
stone’s factual claims. Let Y be the proportion of errors in Weatherstone’s
factual claims. Your estimate of Y, after studying two months of election
campaigns, is 𝛽(17,64). What is the probability that 2 or fewer of Weather-
stone’s next 10 factual claims are erroneous?
..
Weibull Distribution, weib(k,𝝀)
48
T ∼weib(5,4). What are 𝜇T, 𝜎2
T, and P(T ≤4)?
49
T ∼weib(0.2, 2). What are 𝜇T, 𝜎T, and P(T ≥1)?
50
T ∼weib(2,5). What are 𝜇T, 𝜎T, and P(T ∈(1, 3))?
51
T ∼weib(0.5,3). What are 𝜇T, 𝜎T, and P(T ∈(2, 4))?
52
When Jack goes into the Canadian wilderness, he looks most forward to
seeing reindeer. Let T be the time (in hours) that it takes before he sees a
reindeer. T ∼weib(2,2).
(a) What is expected waiting time 𝜇T for Jack to see a reindeer?
(b) What is the probability that Jack sees a reindeer before time 𝜇T?
53
It is given that T, the time (in seconds) it takes Santa’s engineer elves
to make a remote controlled car, is Weibull distributed with parameters
𝜆= 2.5 and k = 1.
(a) What is the expected time for the engineering elves to make a car?
(b) What is the standard deviation for the time for the engineering elves
to make a car?
(c) What is the probability that they take between 0.5 and 1.5 seconds?
54
The longevity of Solan’s motorized vehicles (in years), is T ∼f (x) =
weib(1,0.5)(x).
(a) What are 𝜇T and 𝜎2
T?
(b) What is the probability that a given motorized vehicle lasts for more
than one year?


10 Continuous Distributions
(c) Write down f (x) as simplified as possible. You will then see that the
lifetime distribution of the vehicles is a special case of the Weibull dis-
tribution, which is also known under another name. Which probability
distribution is this? And what are the parameter(s)?
..
Continuous Uniform Distribution
The continuous uniform distribution has been omitted as a section so that the
student should have at hand a tractable probability distribution to build up and
study its properties. The first assignment is the key.
55
X follows a continuous uniform probability distribution over the interval
I = (a, b) if P(X = x) = 1∕(b −a) whenever x ∈I, and 0 otherwise. Use the
rules from sections 7.3, 7.5 and 7.6 to solve the problems below:
(a) Find 𝜇X.
(b) Find 𝜎2
X.
(c) Graph the probability distribution f (x) and the cumulative probability
distribution F(x) of the continuous uniform probability distribution.
56
X is (continuously) uniformly distributed over an interval [a, b], and
M ⊂[a, b] is a disjoint union of intervals whose widths sum up to w. What
is P(X ∈M)?

Part II
Inference




Introduction
CONTENTS
11.1
Mindful of the Observations, 269
11.2
Technically …, 277
11.3 Reflections, 278
.
Mindful of the Observations
In the old days, Bayesian statistics was often called inverse statistics. That is
a rather accurate way of putting it, if by “ordinary” (non-inverse) statistics we
mean working from a model to predictions of observations, as shown in Fig-
ure 11.1. The model is then summed up in probability distributions for the
observations, as for instance a Normal distribution 𝜙, or distributions bernp
for Bernoulli processes, and erl(k,𝜆) and pois𝜆for Poisson processes.
The “forward” direction in this paradigm is conclusion from model to obser-
vation, whereas inverse statistics concludes from observation to model, and
then after that to the next observation. We have borrowed abbot S¯ozen from the
Norwegian zen temple Bugaku in order to illustrate how we perform Bayesian
statistical inference.
We had our first glimpse of statistical inference in Chapter 6. Our core exam-
ple was the Gamesmaster’s dice, Example 6.3.5, which we expanded in Exam-
ple 6.7. Gamesmaster picked a random die from a bag containing one each of
the dice D4, D6, D8, D10, D12, D20 that are all painted red on four of the faces
and white on the remainder. He then tossed the die behind a screen, and the
players were told only if the die had landed red or white, but not which die he
had. From this, they were to guess which die Gamesmaster had picked, and to
give probabilities for the reds and whites of the next observations.
We then looked at probability distributions, and got a taste of the extended
concept of “population”: when we have a finite population, an observation is
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


11 Introduction
Model
Observation
μ
σ
λ
π
X1
X2
X3
Figure .The zen monk S¯ozen sees both the model and the observations.
equivalent to a random sampling from that population. But often, our observa-
tions arise from an ongoing process; there is no fixed set from which to sample.
It is often still noticeable, however, that the observations follow a statistical dis-
tribution f (x), as if they were sampled from an infinitely large population whose
measurement distributions are described by f (x). So, in the extended concept
of “population”, we will say that the essential feature of the model and the pop-
ulation is not the precise elements, but the distribution f (x) of the values. We
say that we sample from a probability distribution f (x).
..
Models and Walls
We let abbot S¯ozen illustrate, while Bard and Frederick and their friends make
comments.
“So what is the difference between Frederick’s frequentism and Bard’s
Bayesianism here?” Sam asks.
“So far,” Frederick replies, “nothing. Or almost nothing. The two of us have
different interpretations of the meaning of the basic concept of probability, and
in the Gamesmaster’s dice example, we frequentists insist that, when the die has
been picked, it has been picked. From there on, there is nothing random about
it: it was either picked, or it wasn’t picked. As you will see if you remember
Example 5.1.6, we will say that after the die is picked, the value of the probability
P(D8) is either 0 or 100%, regardless of our state of knowledge about it. But to
the Bayesians, probability is something entirely different, so the dice example
works nicely within their paradigm.

11.1 Mindful of the Observations

μ
σ
λ
π
X1
X2
X3
Figure .Zen monk S¯ozen does not see the model, only the observations.
“But the dice example is still a useful one, for it illustrates both our similarities
and our differences,” Frederick continues, “and what we both do. Each die Dk
corresponds to a model, a probability distribution for assigning probabilities to
our red–white observations. But we do not know which model is the correct
one. Is it D8? Is it D20? We do not know, for we do not see the probability dis-
tribution directly. As illustrated in Figure 11.2, we only see the observations. We
see red and we see white, but we do not see the die. We do not see how many
faces are white, and how many are red.”
“Statistical investigations are all essentially like that,” Bard says, and takes
over. “The underlying reality is not directly accessible to us, but is as if hidden
behind a screen, just like the dice. We do not see the probability distribution
from which the observations are sampled, but we see the observations. Like-
wise, we do not see the probability p that a coin will give heads, but we see the
outcomes of individual coin flips. Neither do we see the waiting time parameter
𝜆for a Poisson process, but we may measure individual actual waiting times.”
“There are times when we in principle could have discerned the underlying
model,” Frederick interjects. “We consider the weights of salmon in the river
Loppa to be Normally distributed 𝜙(𝜇,𝜎), and if we had managed the feat of
emptying the river of every single fish, we would have the precise values of 𝜇and
𝜎. But note that this would be the weights of the salmon there and then, and not
of one minute later, and it would work only if we captured and weighed all the
salmon at once. So though theoretically thinkable, such exhaustive knowledge
will in practice be impossible, and the population parameters will be as if hidden
behind a screen.”
“But what do you do if you can’t know?” Sam asks, “do you just give up?”


11 Introduction
μ
σ
λ
π
X1
X2
X3
σ∼Γ(k,λ)
μ∼t (μ,σ,ν)
Figure .Zen monk S¯ozen estimates the model parameters based on the observations.
“No,” Frederick replies, “we estimate the parameters of the distribution, like
S¯ozen in his figure (Figure 11.3). But this is where Bard and I part ways. For
Bard considers the parameters to be stochastic variables, and sets up proba-
bility distributions for them according to his observations. For my own part, I
consider only the observations to be stochastic variables, whereas the param-
eters are fixed but unknown magnitudes whose probability of having such and
such values, or of being within such and such intervals, is 0 or 100%. So S¯ozen’s
illustration (Figure 11.3) illustrates Bard’s viewpoint only, not mine.”
..
Randomness
“To get good estimates of the parameters,” Bard says, “we have to make our
observations in the right way. We need representative observations. If we wish
to know what the British think about the question of Scottish independence, we
will not be doing an overly good job of it if all we do is poll the first 20 Scotsmen
exiting a football match between England and Scotland. But what does work
well, is random sampling from the population, since randomness has no prefer-
ence. Both Frederick’s techniques and mine are based on such non-preferential
sampling.”
“But we still need to stay alert,” Frederick takes over, “for what is random is
not always easy to discern. Picking random persons outside the football match
is random enough, but it is the wrong ‘random’. We need to make sure our ran-
domness is unbiased, not preferring one part of the population to another.”
“In all fairness, we should mention that randomness is a hard enough problem
that it belongs to philosophy as well as to statistics,” Bard interjects, “for what
does it really mean for anything to be random? As we saw in the discussion

11.1 Mindful of the Observations

on randomness in Section 5.14, a die may be ‘random’ in an everyday sense.
But upon closer examination, when we looked at the physics of the situation, it
was anything but random. Maybe randomness is simply another way of saying
I don’t know – an expression of our ignorance or partial ignorance, about the
details of the system. Or maybe the proponents of the theory of propensity are
right: that randomness is a fundamental property of some systems.”
“And we tend not to know these underlying mechanisms,” Frederick replies,
“but what we know, is how we choose our observations. We should therefore
examine what sources of bias there may be in this particular system, and then
we should strive to eradicate these sources of bias from our samples, to the
best of our ability. For instance: if we are looking at salmon weights in Loppa,
we should examine whether certain parts of the river have smaller or bigger fish
than the rest, or if different sizes of fish are more easily caught at different times
of the day. We then remove the possibilities of such bias by not fishing at only
one spot, or at only one time of day.”
“And then we use the weight of the fish caught without such bias to estimate
the weight of all the salmon of Loppa?” Sam asks.
“Precisely!” Bard and Frederick intone in unison.
..
Next Observation
“After that,” Bard continues, “we estimate the next observation – the weight of
the next salmon. This is what S¯ozen does in Figure 11.4. Or maybe we don’t.
That depends what the goals of our investigations are.
μ
σ
λ
π
X1
X2
X3
   ∼f (..,..,..)
X4
σ∼Γ(k,λ)
μ∼t (μ,σ,ν)
Figure .Zen monk S¯ozen uses his estimate of the model to estimate the next
observation.


11 Introduction
“Sometimes, the question is whether a person has cancer or not, and we
use diagnostic observations to determine that. In such instances, we are solely
interested in the question of whether or not they have cancer, not in predicting
the result of diagnostic observation.
“The example of Gamesmaster’s dice is at the opposite end: here, our real
interest is only in whether the next toss will yield a red or a white, whereas
estimating the number of faces is interesting only as a means to that end: when
I have a probability distribution for that parameter – the number of faces – I
may also find a probability distribution for the next observation.”
“I notice that you share the same goal, but evaluate the methods differently,”
Sam comments, “but could I ask you both to clarify one thing for me. I don’t
quite understand what Frederick means by estimate if it’s not a probability dis-
tribution, and I don’t understand how Bard is able to transmogrify observations
into probability distributions. Would you care to explain?”
“That’s why we’re here,” Bard replies. “The key to answering both questions
lies in understanding our views on probability. My philosophy allows me a
prior probability expressing my degree of knowledge and ignorance prior to
the investigations. If I know nothing, I choose to work with a prior expressing
my ignorance. But regardless of how much or how little I know, I have a prior
probability. Having a prior probability allows me to apply Bayes’ theorem to the
observations to find a posterior probability, just as we did in the Gamesmaster’s
dice example. That is the key to my side. Without a prior probability, it is not
possible to obtain a posterior probability to estimate the model.”
“That’s me!” Frederick says and waves his hands. “I’m the prior-less guy, so
that you can see the difference between us. For us frequentists, degree of knowl-
edge or conviction, ignorance, or whatever, is irrelevant. For us, probability is
not about degrees of knowledge, hence the kind of prior probability Bard talks
about makes no sense within our framework. Frequentist estimates are prop-
erties of the data alone.”
..
The Data Alone
“But aren’t the estimates properties of the model as well?” Sam queries
Frederick.
“Actually, no,” Frederick replies. “I know it might sound strange, and though
I consider my view to be far more correct than Bard’s, I have in time realized
that quite a few, even professors in other disciplines, never get a good grasp of
what my methods are actually all about. We have had our meetings of concern
in the statistics association, …”
“… and the solution is to teach a method that people understand: Bayes! ”
Bard interjects.
“… and the solution is not agreed upon,” Frederick retorts, “but my father
taught me something that might be of use to understand our two worlds. He

11.1 Mindful of the Observations

was in control of one of the major casinos on the island I come from, and he
told me that the trick to running a successful casino is not to win every game,
but to win in the long run. This applies even though you as the controller of the
casino often hold the same kind of privileged position that the Gamesmaster
has in the dice example.”
Frederick stops to see if Sam is paying attention, and continues: “The gambler
may win or lose, because gambling is a hobby to him. Or at least ought to be. But
if you are running the casino, this is your livelihood, so by the end of the day,
in summary, you must be a net winner. You may lose individual games along
the way, and this is even in your interest, for that is what attracts gamblers to
your casino. But your net total, when the day is done, should be one where your
winnings outrank your losses. Are you with me? ”
Sam nods, “but what does this have to do with statistical estimates?”
“Everything!” Frederick replies, “ at least in the frequentist world. For we use
the data, and the data alone, to estimate the model. These estimates are, as I
told you, properties of the data, and which data we get from our investigation
is random. So whether our estimates capture or do not capture the parame-
ter is …” says Frederick, and adds a dramatic pause, “random! You see: like the
casino, we do not mind missing the target in individual cases. But our tech-
niques are designed to capture the parameters as best as possible in the long run.
Bard’s techniques are more like those of a gambler, trying to win the individual
gambles.”
Sam’s eyes show a glimmer of understanding, so Frederick adds: “But I will
readily admit that our techniques do not bear the same semblance of unity that
Bard’s do.”
“That’s right,” Bard points out, “for whereas I find all that I need through the
(posterior) probability distribution of the model, Frederick does not have any
core engine driving all of his methods from a single framework. My colleagues
have often called frequentist techniques ad hoc inventions …”
“And some of mine call your priors superstition,” Frederick interjects.
“But despite the differences between our two schools, the two of us have
agreed to present statistics together,” Bard continues, “for the benefit of you
students. We think that regardless of which of our two school you are attracted
to, you will understand it better when it is contrasted to the other one. For
the difference lies in different philosophies, and they again are best under-
stood in each others’ contrast. This is also the root source of our differ-
ences. That, and of course disagreements as to the practicality of our two
approaches in handling the uncertainty that is after all the subject matter
of statistics. And we know and respect each others’ techniques for what
they are.”
“Amen!” Frederick agrees. “But as you surely understand, then, I would like
to explain my techniques on a case basis, if that is all right with you, Sam. I’ve
even got my own chapter in Bard’s book, Chapter 16!”


11 Introduction
Sam nods, but at the same time, Frederick and Bard remember that they are
competitors in an area that is even closer to the hearts of both of them. For they
are both in love with their common friend Mina.
Bard and Frederick are of course unable to separate statistics from their infat-
uations, and start discussing how large a proportion of her hugs Mina will be
granting each of them. The statistical model in question is then her tendency of
handing out hugs, parameter p for the probability, whereas the observations are
the hugs themselves – or rather: to whom the hugs are given. The future obser-
vation is then who gets the next hug. Bard, who is the Bayesian, has a prior
belief that the two of them have an equally large chance of getting the next hug,
whereas the frequentist Frederick says he will wait and see until he has some
observations to go by.
Then Mina gives the first hug to Frederick.
Frederick observes that he has received 100% of the hugs, and that thus the
best estimate is that Mina will hug him only; he therefore predicts that Mina’s
next hug will be his as well. In Section 16.1, we will learn about the conceptual
underpinnings of Frederick’s estimate: unbiased point estimates. We will also
be looking at a more nuanced and less infatuated form of Frederick’s reasoning
around proportions in Section 16.3.1.
Bard on his side concludes that Mina probably will be giving more hugs to
Frederick than to himself, but not all of them. Bard weighs his initial model
against the data gathered, and his estimate is that Mina will give 1
3 of her future
hugs to him, and 2
3 to Frederick. This is a Bayesian point estimate. We will learn
more about Bayesian estimates of proportions in Section 13.2.
After a week has passed, Bard has received 17 hugs, and Frederick 28. In
Frederick’s model, Bard’s future share is
17
17+28 ≈37.8% of the hugs, whereas
Frederick himself gets the rest. I Bard’s model, he will be receiving
17+1
17+1+28+1 ≈
38.3% of the hugs. So we see that even though the two friends develop their
models in different ways, they converge to some kind of agreement as they
gather more data. The end of the story? The end of this story is that Mina dates
Sam. She is her own woman, and not the subject of possessive calculations. Or
as Bard and Frederick head-shakingly agree, “in statistics and romance, nothing
is certain!”

11.2 Technically …

.
Technically …
In statistical inference, there are a few technical phrases that are well worth
noting, and we have compiled the following list of key terms.
Parameter: We implicitly assume that the underlying population may indeed
be well described by means of a probability distribution, and that this distribu-
tion again belongs to a certain class and may be specified by means of a few
parameters p1, p2, … , pk. If, for instance, the population is the salmon weights
in Loppa, and we say that the salmon weight follows the probability distribu-
tion 𝜙(3,0.7), then 𝜇= 3 and 𝜎= 0.7 are the parameters in our investigation. In
our Loppa examples, we knew the values of 𝜇and 𝜎, but in statistical inference,
the values of these parameters are usually hidden, and known only through
estimates.
Observation: Before our observations, our future observations are stochastic
variables X1, X2, … following the probability distribution(s) of the population.
When we have observed Xk, have a concrete value xk, we call this concrete value
xk a realized value for Xk. The Loppa salmon weights are Xk ∼𝜙(3,0.7) prior
to weighing. After weighing, their weight are realized values. For instance, the
unknown X5 has materialized as the concrete x5 = 4.1.
Statistic: We rarely need the individual observations when we perform
inference; what we need are mathematical summaries of the data; such a
summary number is called a statistic. Fundamentally, any number that is a
function of the observations is a statistic, but the interesting and relevant ones
tend to be the ones we used for summing up our data in Chapter 2: mean
( ̄X = 1
n(X1 + ⋯+ Xn)), variance, standard deviation, median, and percentile.
Here too, we differentiate between the statistic Ψ as a stochastic variable prior
to observation, and its realized value 𝜓afterwards.
A collection of statistics is sufficient if they contain enough information for
our inferences. For instance, for the Loppa salmon, the mean and the variance
are together sufficient statistics for inference on the parameters 𝜇and 𝜎. The
realized value of ̄X is in this instance ̄x.
Estimator: A statistic ̂Θ is an estimator if it is an estimate (a guess) at the value
of the parameter 𝜃. For instance, for the Loppa salmon, ̄X is an estimator for 𝜇.
Since using “the data alone” for estimation is primarily a frequentist notion,
estimators are a topic in Section 16.1.
Posterior: Bayesians typically code and extract all information about a
parameter through its posterior probability distribution. This is uniquely
Bayesian. A Bayesian may for instance say, after 15 observations, that 𝜇, the
mean salmon weight in Loppa, follows a Student’s t distribution, 𝜇∼t(2.9, 0.1, 14),
whereas he after 200 observations may come up with the more precise estimate
𝜇∼t(2.93, 0.04, 199). This is the topic of Chapters 12 and 13.
Prior: Another key Bayesian concept. Whereas the posterior codes the
total information available after the new observations, the prior codes the


11 Introduction
information prior to these observations. The observations themselves are
coded into the likelihood.
.
Reﬂections
1
Bayesian/frequentist
(a) Who makes their estimates of the model parameters from the data
alone?
(b) Who speaks of P(observation | model )?
(c) Who speaks of P(model | observation )?
(d) Who presupposes randomness for their methods?
(e) Who does all their inference through a probability distribution?
(f) Who speaks of unbiased estimates?
2
What are the two main purposes of statistical inference mentioned by Bard
and Frederick? What is the difference between these two purposes, and how
are the purposes related?
3
Why is randomness important?
4
May you observe a population, a model, or the model’s parameters directly?
5
Your company has acquired the Chuck Wood’s lumber mill. Along with
the mill itself, they also got the mill’s inventory. Your job is to estimate the
humidity of the lumber by measuring 100 units. Discuss in groups which
factors may bias the selection and sampling of units.
6
Discuss strengths and weaknesses in Bard’s and Frederick’s estimates of the
proportion of hugs Mina will give to each of them. May one of the ways of
analysing fit better in one context, and the other better in another context?
If so: which kind of analysis fits which kind of context best?



Bayes’Theorem for Distributions
CONTENTS
12.1
Discrete Prior, 280
12.2 Continuous Prior, 285
12.3 Next Observation, 288
12.4 Repeat Updates, 291
12.5 Choice of Prior, 291
12.6 Exercises, 295
Geophysicist Hannah is impressed by Bayes’ theorem, but asks Bard “Isn’t it
somewhat limited? I overheard you telling Sam that you used it to determine
probability distributions, but I think I must have been mistaken. For Bayes’ the-
orem, that’s what you do in those little tables with priors and likelihoods and
posteriors, when you’re given a finite list of alternatives. But probability dis-
tributions are often about an infinite number of alternatives … and sometimes
even whole intervals, so that the alternatives are not denumerable.”
In response, Bard asks Hannah for examples of probability distributions from
her own field of expertise, geophysics. Hannah considers the question for a little
while, before she answers: “Right now, I am studying the amount of uranium in
a certain area, and from previous studies of this kind, I have found that the
amount in grams, in a 10 kg sample, follows the distribution xe−x.”
“OK, that will work as an example, actually as a useful prior probability distri-
bution,” Bard answers, and asks: “Are you able to use Geiger counters on these
samples, and get clicks such that the frequency of clicks tells you something
about how much uranium is in the sample?”
Hannah nods.
“OK,” Bard continues, “you probably have some known probability distribu-
tion describing when the next click will come in, given x grams of uranium in
your sample. What is it?”
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


12 Bayes’ Theorem for Distributions
“I really can’t recall,” Hannah replies, “but can’t we for now just say it’s …
maybe xe−tx for two clicks?”
“That will work,” Bard replies. “Then all we need is a measurement.”
“Let us say the second click occurs at t = 7.0 minutes,” Hannah replies; “but
how would you use Bayes’ theorem to find a new probability distribution for
the amount of uranium in the sample then?”
“Good question,” Bard replies, “and we will get to the answer. That is, you
will get to the answer, and use Bayes’ theorem to find a new probability distri-
bution for your uranium sample. But before you do so, we will look at some
simpler examples. Your uranium example has a continuous prior and a contin-
uous likelihood. It is simpler for understanding to start with something that is
essentially Bayes’ theorem as you already know it, with a discrete prior and a
discrete likelihood.”
.
Discrete Prior
We start out simply, with an example having four enumerated alternatives,
A1, … , A4. We will continue as hinted, at the end of Chapter 6, and write the
row values as function values, so that we are simply multiplying functions.
Example 12.1.1 For each alternative Ak,
r let the prior probability be fpre(k) = P(Ak) = 1
30k2;
r let the likelihood be g(k) = gB(k) = P(B|Ak) = 1
k .
What is then the posterior probability fpost(k) = Ppost(Ak) = P(Ak|B)?
Prior
Likelihood
Joint
Posterior
k
fpre(k)
g(k)
P × L = fpre(k) ⋅g(k)
fpost(k)
I = {1, 2, 3, 4}
k2∕30
1∕k
k∕30
k∕10
S = 1∕3
Do you see how S is then the sum? This is because that one row of k’s is really
4 rows packed into one, so that S =∑4
k=1 k∕30 = 1∕30 + 2∕30 + 3∕30 + 4∕30 =
1∕3.
We may also graph our functions, as in Figure 12.1.

12.1 Discrete Prior

1
2
3
4
0.1
0.2
0.3
0.4
0.5
1
2
3
4
0.2
0.4
0.6
0.8
1
1
2
3
4
0.02
0.04
0.06
0.08
0.1
0.12
Joint, f ·g.
1
2
3
4
0.1
0.2
0.3
0.4
Prior fpre(k).
Likelihood g(k).
Posterior fpost(k).
Figure .Bayes’theorem shown with function graphs.
You probably see how this saves you a fair bit of work, compared to writing
each row on its own,1 but it also opens up the possibility of infinitely many
“rows”, or alternative values for k.
Example 12.1.2 Let the prior probability distribution be f0(k) = 1
2k2−k for all
integers k, and let the likelihood be k4−k. May we then find a posterior proba-
bility distribution for all k ∈ℕ? The answer is yes:
Values of k
Prior
Likelihood
Joint
Posterior
k ∈ℕ
1
2k2−k
k4−k
1
2k28−k
343
72 k28−k
S = 36
343
where we calculated S = ∑∞
k=1
1
2k28−k = 36
343 on a calculator.
The general rule for updating a probability distribution is as follows.
Rule 12.1.3 Bayes’ theorem, discrete prior: Let X ∼fpre(x). We update this
probability distribution by means of an observation Y = y, thus: for each x,
let g(x) = hx(y) be the probability (density) function for Y, conditional on that
X = x. Then the updated probability distribution for X, fpost(x) is found via
this table:
1Try it out: write out this table with four rows, to see for yourself.


12 Bayes’ Theorem for Distributions
Values
Prior
Likelihood
Joint
Posterior
x ∈I
fpre(x)
g(x)
fpre(x) ⋅g(x)
fpost(x) =
fpre(x)⋅g(x)
S
S =
∑
z∈I
fpre(z) ⋅g(z)
Working with the above functional version of Bayes’ theorem, you calculate
the sum by means of some calculation tool, so once that is set up, you should
not worry if the formulas look complex; it’s now a job for the computer.
Example 12.1.4
Once a year, the betting agency Mad Oaks sets up a new
round of what they call an “octo lotto”: it consists of eight balls that are either
red or white. At the beginning of the year, each ball has had its color determined
by the toss of a fair die, so that the number of red balls is distributed bin(8, 0.5).
Gamblers are not told the colors of these eight balls. Further games are then
based on sampling from these balls, with replacement, and displaying only one
ball at a time.
It’s January, and the first three results are in: red–red–red. Estimate the num-
ber of red balls in this year’s lot of eight.
Your prior estimate on the number of reds is fpre(x) = bin(8, 0.5)(x) = (8
x
)0.58
for x = 0, … , 8. Further, if there are x reds among the 8, the probability of get-
ting a red ball is p = x
8, so the likelihood function is g(x) = (3
3
)p3(1 −p)3−3 =
p3 = ( x
8)3 = 0.59x3.
x values
Prior
Likelihood
Joint
Posterior
0, … , 8
(
8
x
)
0.58
0.59x3
0.517(
8
x
)
x3
1
22 528
(
8
x
)
x3
S = 0.171 875
where S = ∑8
x=0 0.517 ⋅(8
x
)x3 = 0.171 875.
We display this graphically in Figure 12.2, where the colored graphs in 12.2b
and in 12.2c correspond to the likelihoods and joint probabilities of the actual

12.1 Discrete Prior

(a) Prior.
(b) Likelihood.
(c) Joint and Sum.
(d) Posterior.
Figure .Bayes’theorem for Mad Oaks’“octo lotto”.
observation, whereas the grayed-out graphs in the same correspond to the like-
lihoods and joint probabilities of other potential observations.
..
… When Likelihood is a Density
“We employ the same rule when the likelihood is a probability density as when
it is a discrete point probability,” Bard tells Hannah. “We could do the maths
and justify it via a limit argument with increasingly small partitions, but given
our thrust, I hope we can write this on the we know it can be done but don’t care
about the details account.”
“Absolutely!” Hannah agrees, “I am application oriented, and it suffices for
me to get the general gist of it to know that it is indeed so. If a mathemati-
cal proof helps understanding, then fine, but just going through the motions
because some abstract person expects it is of no use to me.”
Example 12.1.5 We have prior distribution function X ∼fpre(x) = 1
55(10 −x)
for x = 0, 1, … , 9, and the likelihood is the probability density g(x) = x2. We
find the updated probability distribution fpost(x) like this:
k
Prior
Likelihood
Joint
Posterior
{0, … , 9}
1
55(10 −x)
x2
1
55(10 −x)x2
1
825(10 −x)x2
S = 15
where S = ∑9
x=0
1
55(10 −x)x2 = 15.
Bayes’ theorem with the likelihood being a probability density applies just as
much if the x-dimension is categorical data, for instance if x is one of {Salmon,
Seachar, Trout}, as in the following continuation of Example 8.1.8.
Example 12.1.6 In the Loppen watercourses, sports fishers catch three differ-
ent species of fish. You yourself have caught a fish there, but know so little about
fish, you say, that you “couldn’t distinguish a cod from a shark”. You therefore


12 Bayes’ Theorem for Distributions
descide to resort to a stronger suit of yours: statistics. Catches in Loppen are
distributed as follows.
r Salmon: 63.7%, with weight distribution ∼gL(y) = 𝜙(4.2,1.2)(y).
r Seachar: 22.4%, with weight distribution ∼gS(y) = 𝜙(1.7,0.5)(y).
r Trout: 13.9%, with weight distribution ∼gO(y) = 𝜙(0.95,0.1)(y).
Your fish weighs 2.5 kg, so the probability densities for the different fish are
as follows.
r Salmon: gL(2.5) = 0.121 9.
r Seachar: gS(2.5) = 0.221 8.
r Trout: gO(2.5) = 0.000 0.
r Joint: g(3) = 0.637gL(2.5) + 0.224gS(2.5) + 0.139gO(2.5) = 0.127 3.
The table then becomes:
k values
Prior
Likelihood
Joint
Posterior
Salmon
0.637
0.121 9
0.077 64
0.610
Seachar
0.224
0.221 8
0.049 70
0.390
Trout
0.139
0.000 0
0.000
0.000
S = 0.127 3
There is thus a 61% probability that your fish is a salmon, and a 39% proba-
bility that it is a seachar. The probability that it is a trout is negligible.
We display this graphically in Figure 12.3, where the colored graphs in 12.3b,
12.3c, and 12.3d correspond to the likelihoods, joint probabilities, and sums of
the actual observation, whereas the grayed-out graphs in the same correspond
to the likelihoods, joint probabilities, and sums of other potential observations.
(a) Prior.
(b) Likelihood.
(c) Joint.
(d) Joint and sum.
(e) Posterior.
(f) All.
Figure .Bayes’theorem for the fish in the Loppen watercourses.

12.2 Continuous Prior

.
Continuous Prior
“You handled the two cases of the discrete prior skillfully,” Bard complements
Hannah.
“Thank you,” Hannah replies, “with good help. But the way you say discrete
prior makes me think there is a case of continuous prior as well.”
“I’m not very good at keeping secrets,” Bard admits, “or playing poker. I am
simply too easy to read.”
“I assume the transition from discrete to continuous prior works by these
limit arguments you mentioned,” Hannah continues, or almost asks, “just as
with the likelihood. Is that right?”
“Indeed it is,” Bard replies, “and the rule for continuous prior is almost like
the one for discrete prior, but with one key difference. Can you guess what it is?”
“That the S is not a discrete sum, but an integral,” Hannah responds almost
before Bard has asked his question. “I am a geo-physicist, after all!”
“And right you are,” Bard confirms.
Rule 12.2.1
Bayes’ theorem, continuous prior: let X ∼fpre(x). We update
this probability distribution by means of an observation Y = y, thus: for every
x, let g(x) = hx(y) be the probability (density) of Y, given that X = x. Then
the updated probability distribution fpost(x) for X is given by the following
table:
Values
Prior
Likelihood
Joint
Posterior
x ∈I
fpre(x)
g(x)
fpre(x) ⋅g(x)
fpost(x) =
fpre(x)⋅g(x)
S
∫I
fpre(z) ⋅g(z) dz.
Example 12.2.2
The switch on an old diesel generator starts the generator
only sometimes. At Motorkopf Ltd, you have a policy to the effect that units
whose failure rate exceeds 20%, must be replaced. You decide to perform a sta-
tistical test of this switch, and include former experiences with this switch in
the form of a prior probability distribution for 𝜋, the switch’s failure rate. It is
fpre(x) =
1
e−1ex (on [0, 1]). Then you perform five trials, and the switch works
four out of the five times. The success rate is x, which is hence the probability
of success in a single trial. The probability of four successes out of five trials


12 Bayes’ Theorem for Distributions
then equals g(x) = (5
4
)x4(1 −x). This is the likelihood. We may now find the
posterior probability distribution:
x-values
Prior
Likelihood
Joint
Posterior
[0, 1]
1
e −1ex
5x4(1 −x)
5
e −1exx4(1 −x)
1
53e −144exx4(1 −x)
S = 265e −720
e −1
where
S = ∫
1
0
f (x)g(x) = ∫
1
0
1
e −1exx4(1 −x) dx = 265e −720
e −1
.
The posterior distribution is thus fpost(x) ≈14.5exx4(1 −x).
We display this graphically in Figure 12.4, where the colored graphs in 12.4b
and 12.4c correspond to the likelihoods and joint probabilities of the actual
observation, whereas the grayed-out graphs in the same correspond to the like-
lihoods and joint probabilities of other potential observations.
The purpose of using Bayes’ theorem is rarely just to find the posterior prob-
ability distribution. We want to make use of this new probability distribution
for some purpose, for instance calculating the probability that the value of the
stochastic variable is within a certain interval.
In this case, you will be looking at whether 𝜋, the rate at which the switch
works, is in excess of 80%. Your investigations have yielded a statistical answer,
and you find the probability that the rate exceeds 80% like this:
P(𝜋> 0.8) = ∫
1
0.8
fpost(x) dx = ∫
1
0.8
14.5exx4(1 −x) dx = 0.40.
We continue this example in Section 12.3.
(a) Prior.
(b) Likelihood.
(c) Joint and sum.
(d) Posterior.
Figure .Bayes’theorem for the switch on the diesel generator.

12.2 Continuous Prior

..
… When Likelihood is a Density
“Now we have only one category left,” Bard continues, “the continuous prior
when the likelihood is a probability density. Your problem is of this kind. What
is your prior, Hannah?”
“It must be the probability of the amount of uranium in the sample … No,
wait! … the probability distribution, before my measurements with the Geiger
counter. And then the posterior probability distribution for the amount of ura-
nium – which is what I am looking for – after my Geiger measurements. The
prior is fpre(x) = xe−x.”
“Good,” Bard replies, “and the likelihood?”
“… is that which has a different probability for the different x-values …
probability distribution for the different x-values,” Hannah replies, “and this is
of course the number of clicks on the Geiger counter. The likelihood is then
g(x) = xe−tx.”
“And you believed this would be difficult?” Bard laughs. “You might as well
calculate the posterior while you are at it!”
Hannah fills in Table 12.1:
Table .Hannah’s table for the uranium sample
Values
Prior
Likelihood
Joint
Posterior
x ∈[0, ∞)
xe−x
xe−1x
x2e−2x
4x2e−2x
S = 1
4
“I integrated the function in the ‘Joint’ column from 0 to ∞, since that was
the range of possible values,” Hannah comments. “The next click can’t be sooner
than 0 – like 10 minutes ago! And then the integral became S = ∫∞
0
x2e−2x = 1
4.”
“Correct!” Bard exclaims, “now everything is in place!”
We display this graphically in Figure 12.5, where the colored parts of the
graphs in 12.5b and 12.5c correspond to the likelihoods and joint probabilities
(a) Prior.
(b) Likelihood.
(c) Joint and sum.
(d) Posterior.
Figure .Bayes’theorem for Hannah’s uranium, illustrated.


12 Bayes’ Theorem for Distributions
of the actual observation, whereas the grayed-out parts of the graphs in the
same correspond to the likelihoods and joint probabilities of other potential
observations.
.
Next Observation
In the first Bayes chapter, we had a rule to determine the probability of the next
observation (Rule 6.4.1). This rule applies to the function version of Bayes’ the-
orem as well, but with the modification that we find a probability distribution,
discrete or continuous.
We have seen, through the kinds and examples we have examined, that in
Bayes’ theorem, x has taken the place of Ak, and fpre(x) has replaced P(Ak). But
what was g(x) again? Well, let us look at the Gamesmaster examples in the first
Bayes chapter. There, Ak was that “die Dk had been picked”, whereas B was a
totally different event whose probabilities varied depending on which die had
been picked.
In the language of probability distributions and stochastic variables, this
means that g(x) measures the probability of an observation y you have made
(for instance that a die toss gave y = 7), given that X = x. But when we are find-
ing the probability that the next toss of the die ends up thus and thus, then y
is not fixed, so we should really write gy(x). If the observation is Y ∼h(y), then
gy(x) = h|X=x(y), the conditional probability (density) of Y, conditioned on the
fact that X = x. Still, for our purposes it has until now been better to keep the
notation x centered, and rather leave the observational variable y implicit.
But in this round, it is precisely the probability (density) that Y = y we are
after, and then y must be made explicit! We again sum over gy(x) for the different
values of x, with the weights for each x given by f (x). We sum it up as follows.
Rule 12.3.1 Given the (posterior) probability distribution X ∼f (x), we find
the probability (density) that the next observation is Y = y by looking at the
Sum box, S in our tables, when f (x) is filled into the place of the prior, and
g(x) = gy(x) is the likelihood for an observation y. This is Rule 6.2.1, function
version.
f|X=x(y) =
⎧
⎪
⎨
⎪⎩
∑
x f (x) ⋅gy(x)
(X is discrete)
∫∞
−∞f (x) ⋅gy(x) dx
(X is continuous).
Example 12.3.2 (Continuation of Example 12.2.2) You will never get a precise
value for 𝜋, the success rate for the switch. But you may still calculate the prob-
ability that it works next time you try it. It is really simple: set up the Bayes’

12.3 Next Observation

theorem table, minus the last column, and then the answer according to
Rule 12.3.1 may be found in the Sum box at the bottom of your table. If this
is what you want to find, you do not need the posterior column.
We write the posterior from Example 12.2.2 into the prior place of the table,
and the probability that the switch works once, given that 𝜋= x, is g(x) = x:
x-values
Prior
Likelihood
Joint
[0, 1]
1
53e−144exx4(1 −x)
x
1
53e−144exx5(1 −x)
S ≈0.74
where S = ∫1
0
exx5(1−x)
53e−144 dx = 840−309e
53e−144 ≈0.74. Since this is less than 80%, the
switch must be replaced.
“Interesting,” Hannah says, and asks, “may I say something about the prob-
ability of when the next click happens on my Geiger counter as well? Not just
the probability or probability density of a click at some specified time like for
instance t = 1, but for general t, as a function?”
“Try,” Bard replies, “but look at the diagrams we made in conjunction with our
updates first. There, we have marked the conditional probabilities of our actual
observation, the likelihood, in color, whereas the conditional probabilities of the
other, potential, observations are depicted in light gray. The sum is then a single
number, as also marked.”
“OK,” Hannah replies, “so if I look at all the potential observations rather
than just the actual one, I get different values for each possible observation,
or more accurately a probability distribution? Like this?” And she redoes the
colors, making the diagrams in Figure 12.6.
“Just like that!” Bard replies, “and now the calculations themselves are a mere
formality. Calculate as you have illustrated.”
1
2
3
4
5
0.1
0.2
0.3
(a) f(x) = xe
.
−x
(b) Joint and S(t).
0
1
2
3
0.1
0.2
0.3
0.4
0.5
0.6
(c) S(t) =
.
2
( t+1) 3
Figure .Hannah’s first illustration for the calculation of S(t) for the uranium sample.


12 Bayes’ Theorem for Distributions
Table .Hannah’s table for the uranium sample
x values
Prior P(x)
Likelihood L(t, x)
P(x) × L(t, x)
x ∈[0, ∞)
xe−x
xe−tx
x2e−(t+1)x
S(t) =
2
(t+1)3
“Then I will leave t as t instead of fixing its value to be one in the likelihood,”
I think, “but instead just use g(x) = xe−tx as-is. See Table 12.2.”
“Not bad,” Bard comments, “but this is the probability distribution for the
possible values of the first observation. What is the probability distribution of
the next observation?”
“Of course!” Hannah replies, “I have to use the last probability distribution
expressing my current knowledge, that is the posterior, and not my initial prob-
ability distribution, the prior. May I have a second try?”
Bard nods, and Hannah illustrates (Figure 12.7), and calculates (Table 12.3).
“And you got it just right!” Bard comments. “Maybe you should consider
becoming a statistician?”
0
1
2
3
4
5
0.1
0.2
0.3
0.4
0.5
0.6
(a) f(x) =
.
4x2e−2x
(b) Joint and S(t).
0
1
2
3
0.2
0.4
0.6
0.8
1
(c) S(t) =
.
24
( t+2) 4
Figure .Hannah’s second illustration for the uranium sample.
Table .Hannah’s second table for the uranium sample
x values
Prior P(x)
Likelihood L(t, x)
P(x) × L(t, x)
x ∈[0, ∞)
4x2e−2x
xe−tx
4x3e−(t+2)x
S(t) =
24
(t+2)4

12.5 Choice of Prior

.
Repeat Updates
As in the tabular version of Bayes’ theorem, we make further updates by setting
the new prior equal to the old posterior distribution. And as in the tabular ver-
sion of Bayes’ theorem, all we need to do is to extend the table for calculating
the next observation with a column for the posterior distribution. We continue
Example 12.3.2
Example 12.4.1 The switch on the old diesel generator:
x
Prior
Likelihood
Joint
Posterior
[0, 1]
exx4(1−x)
53e−144
x
1
53e−144exx5(1 −x)
ex(1−x)x5
840−309e
S = 840−309e
53e−144
.
Choice of Prior
How should you select your prior? The prior may be any probability distribu-
tion, and ideally, it reflects your entire knowledge and conviction about the
parameter you are estimating. For practical purposes, we limit ourselves to
probability distributions that lend themselves to reasonable calculations, and
we may actually do this, being well assured that the precise shape of the prior
plays a diminishing role as our data set grows.
Sensitivity to prior is your first concern in choosing a prior. The posterior is
a balance between the prior and the likelihood: when the data are few, the prior
dominates. When the data set grows, the likelihood dominates, and we speak
of the “dominance of the data”. This means that your choice of prior matters the
most when your data are few. In such instances, a well chosen prior is worth its
weight in gold, whereas a poorly chosen prior will give you a posterior accord-
ing to the GIGO (“Garbage In, Garbage Out”) principle. For big data sets, the
prior must be very informative if it is to make much of a difference, and such
priors usually arise only as the posterior probability distribution from previous
investigations.
Let us now look at how we ought to choose our prior.
A neutral prior is the best choice if you are ignorant about the parameter, or
if your knowledge is very limited. It is also the right choice if you are evaluating
a case where you are required to be neutral and not include your own previous


12 Bayes’ Theorem for Distributions
knowledge or opinion, and therefore must “let the data speak for themselves”.
A neutral prior is also a wise choice when your data set is small, and you need
to be careful not to “contaminate” the result by previous impressions. This is
the starting point of what we call Objective Bayes.
When you know something about the parameter you are estimating, it pays
to use an informative prior coding that knowledge. The reason is that if you
instead use a neutral prior, your analysis will not reflect the entirety of your
knowledge, but only the data you last gathered.
Remember that the posterior distribution only reflects reality to the extent of
the knowledge you code into it. Imagine that you are the captain of a sunken
submarine, and that your instruments give certain depth readings, whereas
your intuition as a captain tells you something like “we were cruising at a depth
of 250 meters before the accident happened, and then we sank for half a minute
before we came to rest, which brings us to roughly 300 meters’ depth, plus or
minus 20 meters”. Would you discard your intuition as a captain and solely
trust the instruments? Remember that your analysis might determine where
the search and rescue will be conducted. What will give you and your crew the
greatest chance of being rescued? Trusting your intuition as a captain, or relying
solely on what the instruments told you?
A good rule of thumb for choosing a prior is to use “Occam’s razor” and
not make the prior more complicated than it need be. If you wish to limit your
search to a given interval [A, B], use the simplest possible function that is pos-
itive inside the interval, but close to zero outside. In the next chapter, we will
look at some particularly well suited priors that turn Bayesian updating into
very simple calculations, all the while making ample room for coding your pre-
vious knowledge into the prior probability distributions.
In some cases, the best way to express your prior is graphically, as follows.
(1) Make a function graph ̃f expressing your convictions about the probabil-
ities. The more determinate your convictions are, the more precise your
function graph needs to be if it is to reflect your convictions.
(2) Let I = ∫∞
−∞̃f (x) dx, and let f (x) = I−1 ⋅̃f (x).
(3) Calculate what the probability distribution f says about P(X ∈⟨a, b]) for
important intervals. If you think the values sound wrong, return to step
one, and adjust your prior graph.
Example 12.5.1
Svein is giving a prior estimate of the mean weight in his
class. He thinks most of his fellow classmates are around eighty-something
kilograms, so he is convinced the mean is eighty-something, “probably near
the middle of the eighties”, but is otherwise not at all sure. In Figure 12.8, he
draws a rough graph he thinks might work: a “sour” parabola intersecting the
horizontal axis at 80 and 90 kg.

12.5 Choice of Prior

75
80
85
90
95
5
10
15
20
25
(a) Svein’s parabolic distribution
˜f(x) = (x −80)(90 −x)
for 80 < x < 90.
70
75
80
85
90
95
0.1
0.2
(b) Normed parabolic distribution
f(x) =
3
500(x −80)(90 −x)
for 80 < x < 90.
Figure .Making a prior distribution function.
..
Improper Priors
When you are ignorant and know absolutely nothing about the matter at hand,
a fully neutral prior giving equal weight to all possible values is a tempting ideal.
But is this even possible? For who hasn’t in their time desired a probability dis-
tribution that would be uniform over the integers, or over all the real numbers?
The immediate answer is that there is no such distribution, since a uniform dis-
tribution by definition is f (x) = k for all the values x for which it is defined. The
total probability is then the sum or integral of f over all the possible values, and
thus ends up as infinity. But such a prior still remains an ideal when we need to
allow all values and show preference to none.
The good news is that under the right circumstances we may employ such
a function as a prior. But what are the right circumstances? Let us first look at
the following motivating example.
Example 12.5.2 You are a subordinate engineer on a team who has jumped to
the Pegasus galaxy, and you have found an abandoned dart, a wraith space ves-
sel, and you want to know how long the vessel has been abandoned for. Rodney
McKay, the team genius, declares that we as rational beings must acknowledge
that we are unable to make any pronouncement on the issue until we have made
empirical investigations. Ronen Dex finds a fully charged battery next to the
dart, and McKay informs us that the probability that the battry should be fully
charged after having lain there for t months is h(t) = e−2t. Your job is to find a
probability distribution for how long the dart has been abandoned.
You recall some statistics you learned back on Earth. You see that X, the
time the dart has been abandoned, is a stochastic variable with sample space
U = ℝ+ = [0, ∞). You take McKay seriously, and decide that the prior f (t) must
assign equal probability to all values of t, so that f (t) = k for all t ∈[0, ∞). But
you run into a problem: the total probability must be 1, which requires that
∫∞
0
f (t) dt = ∫∞
0
k dt = 1. But for any positive k, the integral becomes infinite!


12 Bayes’ Theorem for Distributions
You are therefore left with two options. Your first option is to recall that the
wraith dart can’t have been abandoned for just any length of time; there is some
upper limit. A million or a billion years? No, the wraith civilisation is not that
old. So the dart can’t have been abandoned for longer than that. You don’t know
precisely how old the wraith civilisation is, but as the resourceful person you
are, you simply write “n years”, with n to be filled in later. Your prior is
fn(t) =
⎧
⎪
⎨
⎪⎩
0
t < 0
1∕n
t ∈[0, n)
0
t ≥n.
To save some calculations, you cheat and rescale the prior to fn = 1 on [0, n),
instead of the unscaled 1∕n. It makes no difference to the posterior, since when
the prior or likelihood are scaled by a factor of c, that factor disappears in the
posterior, since you divide by the total, S, which has been scaled by that factor
c as well.
You use McKay’s likelihood, h(t) = e−2t. Your table is then
t
Prior
Likelihood
Joint
Posterior
t ∈[0, n)
1
e−2t
e−2t
2e−2t
1 −e−2n
1 −e−2n
2
X’s posterior distribution is thus ̂fn = 2e−2t∕1 −e−2n. The expression is
somewhat cumbersome, and you notice that it is very near 2e−2t, and that
indeed limn→∞̂fn = limn→∞2e−2t∕(1 −e−2n) = 2e−2t. You decide to see what
happens if you allow yourself to choose n = ∞for your prior, and then use
fpre(t) =
{
0
t < 0
1
t ≥0.
The table then becomes:
t
Prior
Likelihood
Joint
Posterior
t ≥0
1
e−2t
e−2t
2e−2t
1
2

12.6 Exercises

You have discovered a shortcut! By letting the prior be a function that strictly
speaking is no probability distribution, you made your calculations and results
quicker and neater than what an exact calculation would have given you, but
yet with a result that is very close. Delighted, you decide to tell McKay of your
discovery. McKay glances at your calculations, and exclaims “Oh yes, improper
priors. Very useful! I have used them myself since I first attended a statistics
course at the university at age nine.”
Definition 12.5.3 A function or operator f (x) is an improper prior in a cal-
culation of a posterior probability distribution if it is non-negative, and the
use of it as a prior yields that S = ∫I fpre × g < ∞(continuous) S = ∑
I fpre ×
g < ∞(discrete), making the posterior probability distribution found into a
probability distribution.
Bayes’ theorem may then be used in precisely the same way as when we
employ a proper prior.
.
Exercises
1
Santa’s workshop makes 10 different types of sack for Santa and his elves,
types A1, A2, … , A10. The number of Ax type sacks made are 17 × x. In
other words, there exist 17 A1 sacks, 34 A2 sacks, etc. The proportion of
soft gifts depends on the type of sack they is in. Type A1 contains 1% soft
gifts, A2 contains 4%, and in general, sacks of type Ax contain x2% soft gifts.
Each sack contains one million gifts. Your elf gets one such sack, picked at
random.
– What is the probability that your elf got a sack of type Ax?
– The elf pulls out two random gifts for you. Both are soft. Use this infor-
mation to update the probabilities of which type of sack your elf picked.
– What is the probability that your elf has a bag of type A8?
2
You have 100 Ak, numbered from 1 to 100, and fpre(k) = k2∕338 350. You
make observation B1, and see that g(k) = P(B1|Ak) = 1∕k. What are the
posterior probabilities Ppost(Ak)?
3
You participate in a chocolate lottery, where every participant gets a bag.
Your Christmas elf has filled the bags like this: he puts a dark chocolate
into the bag. Then he tosses a coin. If the coin lands heads, he adds a milk
chocolate, and tosses the coin again, and repeats the process. The process
stops at the first tails. Let A1 be that there are zero milk chocolates in the
bag, A2 that there is one, etc. Now, your elf is coming to you. You know how


12 Bayes’ Theorem for Distributions
he filled the bag, but the bag is enchanted (of course), so the size does not
reveal what’s inside.
(a) Show that the prior probabilities are: P(A1) = 1∕2, whereas P(A2) =
1∕4, P(A3) = 1∕8, … , P(Ak) = 1∕2k, which means that the prior proba-
bility distribution function is f (k) = 1∕2k for all positive integers k.
(b) The elf allows you to shout “Abra cadabra, chocolate come to me!” to
your bag, and then a random chocolate from the bag will appear. When
you try it, you get a dark chocolate. This is your observation B. Show
that the probability of getting a dark chocolate from bag k is P(B|Ak) =
positive∕total = 1∕k. This is your likelihood.
(c) Find the updated ( posterior) probability of the alternatives Ak. (Hint:
∑∞
j=1 2−j × j−1 = ln(2).)
4
You have found a magic lamp on the beach. The genie in the lamp is a math-
ematician, and she has decided to fill a bag with rocks in the following way:
she tossed a fair coin repeatedly until she got tails. She then counted the
total number of tosses, X, and filled the bag with 2X rocks. The first rock is
an ordinary, gray pebble, but the rest are nuggets of gold.
(a) Let f (n) = P(X = n). Find an expression for the function f (n).
(b) Let g(n) be the probability that a random sampling from the bag yields a
gold nugget, given that the genie tossed the coin n times. Find an expres-
sion for g(n).
(c) You now sample a rock from the bag, at random. It’s a gold nugget. Find
the updated probability distribution that the genie had flipped the coin
n times.
(d) The genie puts a gray pebble in the bag as replacement for the gold
nugget, and asks you to have a go one more time. What is the proba-
bility that the next rock is a gold nugget as well?
5
Bernoulli trials
– The alternatives are indexed by an x running from 1 through 15.
– The prior probability in choosing among the 15 alternatives is uniform.
– For alternative x, we have P(⊤) = x∕15 whereas P(⊥) = 1 −P(⊤).
– You perform two trials, “with replacement”; the outcome is ⊤⊥.
(a) Write down the function f (x) describing the prior probabilities of get-
ting alternative x.
(b) Find the likelihood function g(x).
(c) Fill in the table to find the posterior probability that you got alterna-
tive x.
(d) What is the probability that the next trial yields ⊤?
6
Sacks with handles; the contents are white (W) and black (B) balls.
– You have seven sacks with an index x running from 1 through 7.
– Sack x has x handles, and in a random pick, each handle has equal prob-
ability of being picked.

12.6 Exercises

– All the sacks are filled with white (W) and black (B) balls, a total of 50 in
each sack. In sack x, there are x2 white balls.
– You pick a random ball from your sack, and get black. You put the ball
back in the sack.
(a) Write down the function f (x) expressing the prior probabilities you
picked sack x when you pulled a random handle.2
(b) Find the likelihood function g(x).
(c) Fill in the table to find the posterior probability that you picked sack x
when you pulled a random handle.
(d) What is the probability that the observation of your next trial, “2 sam-
plings with replacement” yields W–W?
7
Nuts come in two different chiralities (threadings); left-handed (L) and
right-handed (R). Oleson’s hardware store sells packs containing both kinds
in one pack.
– Oleson sells 5 types of nut pack. The types are enumerated by an x run-
ning from 1 through 5.
– All packs contain 100 nuts. A pack of type x has 10x left-handed (L) nuts;
the remainder are right-handed (R).
– Oleson has just not sold any of the packs, so he knows he has 30 −5x
packs of type x in his store.
– The packs are unfortunately unmarked, so now the entire inventory of
them is now on sale. You pick a pack at random, and then pick a nut to
study it. It is a left-handed nut (L). You put it back before picking a new
random nut; it, too, is left-handed (L).
(a) Write down the function f (x) expressing the prior probabilities3 you
picked a pack of type x.
(b) Find the likelihood function g(x).
(c) Fill in the table to find the posterior probability that you picked a pack
of type x.
(d) You put the nut back. What is the probability that the next random nut
you pick is left-handed (L)?
8
You are updating a prior probability
fpre(x) =
⎧
⎪
⎨
⎪⎩
0.5 + 0.25x
x ∈⟨−2, 0]
0.5 −0.25x
x ∈⟨0, 2]
0
otherwise
2Hint: what is the total number of handles? How many handles does alternative x have? What,
then, is f (x)?
3Hint: what is the total number of nut packs? ∑5
x=1(30 −5x) = 150 −5 ∑5
x=1 x = ⋯.


12 Bayes’ Theorem for Distributions
and have a likelihood
g(x) =
⎧
⎪
⎨
⎪⎩
14
x ≤−1
2
x ∈⟨−1, 0]
3
x > 0.
Find the posterior probability distribution fpost(x).
9
Make a die or any other physical object that may serve as your “random
generator”. Divide the possible outcomes into two roughly equal sets. If, for
instance, you have made a 6-sided die, you may divide it into A: “low num-
bers” (1, 2, 3) and B: “high numbers” (4, 5, 6). Your task is to estimate the 𝜋,
the probability of getting A.
(a) Make a guess at the value of 𝜋. Guess is the key here, but feel free to make
a few preliminary trials. Let p be this value, and let n be the number of
tosses you would have to perform to be as certain as you are. Let your
prior distribution be 𝜋∼𝛽(a,b)(x), where a = n × p and b = n × (1 −p).
If you need easy calculations, round off a and b to the nearest integer.
(b) Use the cumulative beta distribution (Section 10.5) to find the proba-
bility that P(𝜋> 0.5).
(c) Use the inverse cumulative beta distribution (Subsection 10.5.4) to find
an interval [A1, B1] such that P(𝜋< A1) = 10% and P(𝜋> B1) = 10%.
(d) Toss the die a self-chosen number of times, and get k A and l B. What is
the probability of this outcome if 𝜋= x? This is your likelihood function
g(x).
(e) Find the posterior probability distribution for 𝜋.
(f) Find the probability that P(𝜋> 0.5).
(g) Find an interval [A2, B2] such that P(𝜋< A2) = 10% and P(𝜋> B2) =
10%.
(h) Repeat the last three assignments, and repeat again. Make a guess at
how many trials you must make for the interval [An, Bn] to be no wider
than 0.1.
(i) And repeat.



Bayes’Theorem with Hyperparameters
CONTENTS
13.1 Bayes’Theorem for Gaussian Processes, 299
13.2 Bayes’Theorem for Bernoulli Processes, 314
13.3 Bayes’Theorem for Poisson Processes, 320
13.4 Exercises, 323
This chapter and the previous one are about the same thing: employing Bayes’
theorem to perform what a student once called “a magical transformation of
observations into probability distributions”. But as opposed to the previous
chapter, where we were left to do heavy sums and integrals, here we will be
working with techniques where the heavy mathematical lifting has been done
in advance, so that all we have to do is to compute a few simple sums and put
them into the right formulas. It is the technique of hyperparameters.
To explain this magic that transforms observations into probability distribu-
tions, and just what a hyperparameter really is, we will let ourselves be led out
into the woods by a boy we’ll call Rocky. To be more precise, we will be looking
for Rocky, and in that process we will be discovering our first Bayesian updating
rule for Gaussian processes.
.
Bayes’Theorem for Gaussian Processes
The Normal distribution is frequently also called the Gaussian distribution
after its discoverer, Carl Friedrich Gauss. A Gaussian process is a sequence of
independent observations X1, X2, … sampled from a common Normal distri-
bution 𝜙(𝜇,𝜎).
But as opposed to what we did in Section 10.1, we are not going to use the
parameters 𝜇and 𝜎to discern the properties of the observations X1, X2, … (Fig-
ure 11.1). We are going in the opposite direction, and will use the observations
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


13 Bayes’ Theorem with Hyperparameters
Rock
Rocky
Figure .The position of the rock follows a Normal distribution 𝜙(𝜇,𝜎).
X1, X2, … to discern the properties of the unknown parameters 𝜇and 𝜎, as illus-
trated in Figure 11.3. We are going to find probability distributions for the val-
ues of the parameters 𝜇and 𝜎, and it is the parameters of these new probability
distributions that are what we call hyperparameters.
Now we will look for Rocky. Rocky likes to toss red rocks on the path when
he walks in the woods. Precisely where the rock lands, we do not know, but
it is always Normally distributed with center 𝜇at Rocky’s own position, and
standard deviation 𝜎. So when his position is at 𝜇, the position x of his rocks
are x ∼𝜙(𝜇,𝜎), as illustrated in Figure 13.1.
Then Rocky hides in the woods, right off the path from where he stood when
he threw the rock. When we arrive, we can’t see Rocky, but we can see his red
pebble. If we had no reason to suspect any part of the path was a more likely
launching base for Rocky’s toss than any other part, then “the rock is more than
five meters to the left of where Rocky stood” and “Rocky stood more than five
meters to the right of where the rock has now landed” have the same probability.
This goes for any other distance as well, not just five meters. Indeed,
𝜙(𝜇,𝜎)(x) = 𝜙(x,𝜎)(𝜇).
We have illustrated this symmetry in Figure 13.2.
We have now performed the magic trick: transformed the observation x into
a probability distribution for 𝜇. The parameters of 𝜇’s probability distribution
are x and 𝜎, which are then the hyperparameters.
Now, this was under the neutral assumption that Rocky could have been any-
where on the path, with equal probability. But what if we had more information?
What if something influenced where Rocky stood when he tossed his rocks?

13.1 Bayes’ Theorem for Gaussian Processes

Rock
Rocky
Figure .P(rock is more than five meters to the left of Rocky) = P(Rocky is more than five
meters to the right of rock).
Pebbles, Rocky’s little sister, likes to play with her big brother when the family
is out for a hike in the woods. And Rocky, being a good big brother, includes
her in his play. This time, they have agreed that Pebbles gets to throw the rock
first, and that Rocky then tosses the rock from where it landed. We arrive later,
and Pebbles tells us where she stood when she tossed the rock. We know the
standard deviation for her throws as well, 𝜎Pebbles, and as with Rocky, where they
land is centered on where they were thrown from. As illustrated in Figure 13.3,
Rocky
Pebbles
Figure .Pebbles sets the hyperparameters for the prior probability.


13 Bayes’ Theorem with Hyperparameters
this gives us a probability distribution for Rocky’s launch base, 𝜇, even before
we have found the pebble:
𝜇∼𝜙(𝜇Pebbles , 𝜎Pebbles).
Since we now have a probability distribution for Rocky’s position 𝜇given in
advance of finding the rock, we will call 𝜇Pebbles and 𝜎Pebbles the prior hyperpa-
rameters for 𝜇.
The numbers from the observations of where Rocky’s rock landed makes up
the likelihood, and when we combine prior and likelihood, we get the poste-
rior probability distribution for Rocky’s position 𝜇. We may use the techniques
from the previous chapter to calculate this posterior probability distribution by
multiplying prior with likelihood and dividing by the total.
However, we have thus far kept the calculations out in the open as sums and
integrals, but do we really need to? The calculations we need to perform are
quite advanced, especially from the stand-point of bachelor’s degree studies in
engineering, economics, or medicine, for example, but they end in almost iden-
tical results every time. Identical except for the alterations of a few key num-
bers. So these operations are really also quite unnecessary to perform more
than once. And that one time is for the theoretician when he sets up the frame-
work for the formulas.
We have by now understood how data become probability distributions, and
we have understood what hyperparameters are. So let us leave the advanced
calculations to the theorist, just as we leave car maintenance to the mechanic,
and instead focus on how to operate the gas pedal, the brakes, and the steering
wheel.
This chapter consists of Bayesian driving lessons.
First, we will look at three driving lessons for Gaussian processes, with
slightly different rules according to whether 𝜎and 𝜇are known in advance or
need to be managed. A bit like the difference in handling a car with manual or
with automatic gear shift. After that, we will learn how to drive Poisson pro-
cesses and Bernoulli processes. Common to all the driving lessons is a notation
for keeping tidy track of the hyperparameters:
P ⊧p1 (we say something about the first parameter)
p2 (we say something about the second parameter)
⋮
where the socket-plug-like “P ⊧” means that “In the model with probability dis-
tribution P, the hyperparameters, or intermediate values we use to calculate the
hyperparameters, are thus: ”.
To update the probabilities and hyperparameters, we make use of the statis-
tics we mentioned in Section 11.2, and recall that a collection of statistics is

13.1 Bayes’ Theorem for Gaussian Processes

sufficient for our updates if we need no further information about our observa-
tions in order to perform the update.
We then conclude with new hyperparameters and new probability distribu-
tions for the parameters, pi ∼f (x), where f (x) is pi’s (new) probability distribu-
tion. After that, we may also indicate the probability distribution of the next
observation, named for instance X+, or – if we are looking at the next m obser-
vations – X+m.
..
Unknown 𝝁But Known 𝝈
You are estimating the parameter 𝜇for a Normal distribution 𝜙(𝜇,𝜎) where the
standard deviation 𝜎has known value s0.
Choice of prior for 𝜇: Let your best estimate on the parameter 𝜇be m0. Then
indicate how certain you are of your estimate m0 as follows: let 𝜅0 be how many
measurements would be needed for you to be as certain as you are. If you have
somehow found your prior for 𝜇expressed as a Normal distribution 𝜙(mpre,spre),
let m0 = mpre and 𝜅0 = s2
0∕s2
pre.
Don’t panic if you don’t know which values to use. Not knowing is simply
nothing other than saying that you are as certain as if you had zero observations.
You code this in numbers as 𝜅0 = 0 and m0 = 0. These are the hyperparameter
values of Jeffreys’ reference prior,1 which is an objective, neutral prior for the
hyperparameters.
In both cases, let Σ0 = m0𝜅0. Your prior hyperparameters are then given by
P0 ⊧𝜅0 (the strength of you prior, in observation equivalents)
Σ0 (prior’s counterpart to the “sum of observations”).
Updating: After n observations x1, … , xn, the sufficient statistics are n and Σx =
∑n
k=1 xk. You posterior hyperparameters are then
P1 ⊧𝜅1 = 𝜅0 + n
Σ1 = Σ0 + Σx.
This process may be repeated as many times as you want, on to P2, P3, … as
far as you may wish to go, where the prior hyperparameters for the new update
equal the posterior hyperparameters from the previous update. When we
wish to obtain the posterior probability distributions for 𝜇and the (posterior)
predictive probability distribution for the next observation X+, let m1 = Σ1∕𝜅1.
1Jeffreys’ prior for 𝜇here is an improper prior (see Section 12.5.1) giving equal probability to all
x ∈ℝ. It is often written f (x) = 𝜙(0,∞)(x) ≡1, a Normal distribution with precision 𝜏= 0.


13 Bayes’ Theorem with Hyperparameters
μ
X+
κ1 = 5
κ1 = 20
κ1 = 1000
μ known
Figure .The probability distributions for different numbers of observations.
Then
𝜇∼𝜙(
m1, s0
√
1∕𝜅1
)(x)
X+ ∼𝜙(
m1, s0
√
1+1∕𝜅1
)(x),
which also gives us m1 = E[𝜇] = Σ1
𝜅1 . See Figure 13.4 for an illustration of how
these probability distributions change as you get more observations.
We consider 𝜎to be a known quantity when we know 𝜎with sufficient pre-
cision for our purposes. If you do not know 𝜎with the desired precision, you
should go to Section 13.1.3, where we treat both 𝜇and 𝜎as unknown quantities.
Typical cases will be processes where the uncertainty resides in the act or
apparatus of measurement itself, rather than in what is measured, such as in
Example 13.1.1. In such cases, we may get to know the uncertainty 𝜎with great
precision, all the while the value 𝜇that we want to estimate arises new and
unknown for every new object we want to measure. Other cases are when the
uncertainty describes a standard deviation in a production with similar equip-
ment, where over time we get to know the uncertainty 𝜎of the production
equipment better and better, all the while the concrete values of the produced
units are new and unknown for every case, as in Example 13.1.2.
Example 13.1.1 Eggeseth’s laser speed gauges measure the speed of an object
by sending out one or more pulses of laser light. The gauge then measures the
Doppler shift in the reflection of each pulse, and calculates the speed from that
shift. The uncertainty for a single pulse measurement is stated as 5 km/h. The
traffic police are trying out Eggeseth’s smallest model, which makes its mea-
surements with three independent pulses. The built-in calculator finds the aver-
age assesment from the three pulse measurements, which it then shows on the
display.

13.1 Bayes’ Theorem for Gaussian Processes

On a straight stretch on the M8 between Paisley and Glasgow, they spot their
first speeder driving at 137 km/h. Considering the measurement uncertainty:
what is the probability that the actual speed was in excess of 135 km/h?
Answer: Here, 𝜇is the actual speed, whereas 𝜎is the uncertainty in speed mea-
surement from each pulse, which means 𝜎= 5.
The traffic police are bound to judge by the measurements alone, so they set
𝜅0 = 0 and therefore also m0 = 0. Then, Σ0 = 𝜅0m0 = 0. Then the prior hyper-
parameters are
P0 ⊧𝜅0 = 0
Σ0 = 0.
For the updating, they need the sum of the pulse measurements. Since the
average of the 3 measurements is 137, Definition 2.3.10 tells us that Σx =
3 × 137 = 411. The updated hyperparameters are then
P1 ⊧𝜅1 = 0 + 3 = 3
Σ1 = 0 + 411 = 411.
That gives the following probability distribution for the speed:
𝜇∼𝜙(411∕3, 5
√
1∕3)(x) = 𝜙(137 , 2.886 75)(x).
The probability that the actual seed was in excess of 135 km/h is then
P(𝜇> 135) = 1 −Φ(137 , 2.886 75)(135) = 0.755 789 ≈76%.
“Does it matter how many sensors he has,” Sam queries. “The lot of them are,
after all, equally inaccurate.”
“It actually does,” Bard replies, “for they even each other out in the sum, such
that the precision of the average is greater than each individual precision. If the
traffic police had used a 20 pulse gauge when they got 137 km/h, they would
have had P(X > 135) ≈96%, and if they had bought Eggeseth’s latest model
with 500 pulses, the probability that the speed was less than 135 km/h would
have been roughly 2 × 10−19. See Figure 13.5.”
Example 13.1.2
You produce audiophile miniature amplifiers. You have
designed several series with different output effects, and therefore know well
from experience that the standard deviation of your production is 𝜎= 0.7 W.
1) At the beginning of the production, you measure the first five amplifiers you
produced. The sum of their output effects is Σx = 11.729 W. Use a neutral
prior, and find the probability distribution for the value of 𝜇, the mean out-
put power (in watts) of the production. Find the probability distribution of


13 Bayes’ Theorem with Hyperparameters
135
140
145
0.04
0.08
0.12
3 pulses: 76%.
135
140
145
0.10
0.20
0.30
20 pulses: 96%.
135
140
145
0.5
1.0
1.5
500 pulses: 100%.
Figure .The probabilities of X > 135 km∕h for laser gauges with different numbers of
pulses.
the effect the next amplifier produced, and finish off by calculating the prob-
abilities P(𝜇< 2) and P(X+ < 2).
2) Later on in your production, you measure seven new units, and the
output power measurements are x1 = 2.360, x2 = 2.359, x3 = 2.335, x4 =
2.345, x5 = 2.354, x6 = 2.355, and x7 = 2.357 W. Use this to update the
probability distribution of 𝜇, and find the new probability distribution for the
output effect of the next amplifier. Then, calculate the probabilities P(𝜇< 2)
and P(X+ < 2).
Answer: The unknown mean output power is 𝜇, and the known standard devi-
ation is 𝜎= 0.7.
(1) You are using a neutral prior, so then
P0 ⊧𝜅0 = 0
Σ0 = 0.
The updated values are then
P1 ⊧𝜅1 = 𝜅0 + n = 0 + 5 = 5
Σ1 = Σ0 + Σx = 0 + 11.729 = 11.729.
This gives the following probability distributions for 𝜇and X+:
𝜇∼𝜙(11.729∕5, 0.7
√
1∕5)(x) = 𝜙(2.345 8 , 0.313 05)(x)
X+ ∼𝜙(11.729∕5, 0.7
√
1+1∕5)(x) = 𝜙(2.345 8 , 0.766 812)(x).
This in turn gives us that
P(𝜇< 2) = Φ(2.345 8 , 0.313 05)(2) = 0.134 663 ≈13.5%
P(X+ < 2) = Φ(2.345 8 , 0.766 812)(2) = 0.326 01 ≈32.6%.

13.1 Bayes’ Theorem for Gaussian Processes

(2) You employ Rule 2.3.9, and find from your measurements that2 Σ′
x = 16.465
and n′ = 7. Since P1 describes what you knew before the measurements, its
hyperparameters are your priors:
P1 ⊧𝜅1 = 5
Σ1 = 11.729.
The updated values are then
P2 ⊧𝜅2 = 𝜅1 + n′ = 5 + 7 = 12
Σ2 = Σ1 + Σ′
x = 11.729 + 16.465 = 28.194.
The new probability distributions for 𝜇and X+ are then
𝜇∼𝜙(28.194∕12, 0.7
√
1∕12)(x) = 𝜙(2.349 5 , 0.202 073)(x)
X+ ∼𝜙(28.194∕12, 0.7
√
1+1∕12)(x) = 𝜙(2.349 5, 0.728 583)(x),
which means that
P(𝜇< 2) = Φ(2.349 5, 0.202 073)(2) = 0.041 853 ≈4.2%
P(X+ < 2) = Φ(2.349 5, 0.728 583)(2) = 0.315 721 ≈31.6%.
..
Known 𝝁But Unknown 𝝈
You are estimating the parameter 𝜎for a Normal distribution 𝜙(𝜇,𝜎), when the
mean 𝜇has known value m0.
Prior for 𝜎: Let your best estimate of the parameter 𝜎be s0. Then indicate how
certain you are of your estimate s0 as follows: let n0 be how many measurements
would be needed for you to be as certain as you are. Don’t panic if you don’t know
which values to use. Not knowing is simply nothing other than saying that you
are as certain as if you had zero observations. This gives you the reference priors,
in other words objective, neutral priors for the hyperparameters. To code this
in numbers, you let 𝜈0 = n0 −1 and SS0 = s2
0 × max(0, 𝜈0).
Then, your prior hyperparameters are given by
P0 ⊧𝜈0
SS0.
Updating: After n observations x1, … , xn, the sufficient statistics are n, Σx, and
SSx. You get another set of sufficient statistics if you use SBx instead of SSx. We
2Use the prime “ ′ ” on Σ′
x to mark a new round of measurements and distinguish its sum Σ′
x from
that of the first round, Σx.


13 Bayes’ Theorem with Hyperparameters
τ
σ
X+
ν1 = 5
ν1 = 8
ν1 = 20
σ kjent
Figure .The probability distributions for different numbers of observations.
recall that Σx = ∑n
k=1 xk, ̄x = Σx∕n, and SSx = ∑n
k=1(xk −̄x)2, whereas the new
statistic is SBx = ∑n
k=1(xk −m0)2 = SSx + n × (̄x −m0)2.
Your posterior hyperparameters are then
P1 ⊧𝜈1 = 𝜈0 + n
SS1 = SS0 + SBx.
This process may be repeated as many times as you want, on to P2, P3, … far
as you may wish to go, where the prior hyperparameters for the new update
equal the posterior hyperparameters from the previous update. We might then
wish to obtain
(1) the (marginal posterior) probability distribution for the precision 𝜏= 𝜎−2;
(2) the (posterior) predictive probability distribution for the next observation
X+.
Let s1 =
√
SS1∕𝜈1. Then the probability distributions of 𝜏and X+ are
given as
𝜏∼𝛾(𝜈1∕2,SS1∕2)
X+ ∼t(m0,s1,𝜈1),
which also gives us 𝜏1 = E[𝜏] = 𝜈1∕SS1. Notice that s1 =
√
SS1∕𝜈1 = 1∕√𝜏1.
See Table 13.6 for an illustration of how these probability distributions change
as you get more observations.
It is a bit unusual to know 𝜇but not 𝜎, but it may still occur, such as for
instance when
r we may find Σx (the sum of the observations) and n in a very simple manner.
If we have caught n = 2000 fish in a net, finding Σx is easy since it is the total

13.1 Bayes’ Theorem for Gaussian Processes

weight of the catch. With such a large number of individual values, Σx∕n is
a sufficiently precise estimate of 𝜇that we may consider 𝜇= Σx∕n to be a
known value. To find the estimate of 𝜎, however, we need to weigh the fish
one by one;
r we have pairwise, independent measurements of differences. If X1, X2 ∼
𝜙(𝜇X,𝜎X)(x), Rule 10.1.10 says that X1 −X2 = W ∼𝜙(0 ,
√
2 𝜎X)(w), which
means that 𝜇W = 0 is known, and we may use the rule above to find a prob-
ability distribution for 𝜎W =
√
2 𝜎X, and that by dividing by
√
2 we may find
a probability distribution for 𝜎X.
Example 13.1.3
In your small fishing boat, you have been working off the
coast of Helgeland in Norway, and are now coming in to the small fishing village
Sandessjøen to sell your cod. A marine biologist wants to know the standard
deviation of cod in the area. You don’t know, but your total catch weighs in at
6541 kg, and as the filleting factory counts the fish, they find that you had 1055
cod. This gives you confidence to state that the mean weight of Helgeland cod
is known, and is m0 = 6541∕1055 = 6.2 kg.
To find the standard deviation requires weighing cod individually, but this
is time consuming, and the cod have already been filleted anyway. But you tell
the marine biologist that you had taken home eight randomly picked cod for
your spouse. You weigh them together, and the weights are, respectively, 5.45,
4.1, 6.6, 4.9, 7.1, 6.9, 5.95, and 6.95 kg. What is the probability that the standard
deviation 𝜎for Helgeland cod exceeds 2 kg?
Answer: The marine biologist asks you to use a neutral prior, that is n0 = 0, so
your prior hyperparameters are given by
P0 ⊧𝜈0 = −1
SS0 = 0.
We recall that the known value of 𝜇is m0 = 6.2 kg. For the eight cod you
brought home, you find Σx = 47.95 and thus ̄x = 5.993 75. Using Rule 2.4.1, you
find SSx = 8.407 19. Your posterior hyperparameters are then
P1 ⊧𝜈1 = 𝜈0 + n = −1 + 8 = 7
SS1 = SS0 + SSx + n(̄x −m0)2
= 0 + 8.407 19 + 8(5.993 75 −6.2)2 = 8.747 5.
The probability distribution of 𝜏= 𝜎−2 is then
𝜏∼𝛾(72, 8.747 5∕2)(t) = 𝛾(3.5, 4.373 75)(t)
This means the probability that 𝜎> 2 (see Figure 13.7) is
P(𝜎> 2) = P(𝜎−2 < 0.25) = Γ(3.5, 4.373 75)(0.25) = 0.051 222 8 ≈5%.


13 Bayes’ Theorem with Hyperparameters
0.5
1.0
1.5
2.0
1
Figure .P(𝜎> 2) when 𝜏∼𝛾(3.5, 4.373 75)(t).
..
Unknown 𝝁and 𝝈
Choice of prior hyperparameters: You are estimating the parameters 𝜇and
𝜎for a Normal distribution 𝜙(𝜇,𝜎). You find the values 𝜅0, m0, and Σ0 in the
same way as in Section 13.1.1, and the values 𝜈0 and SS0 in the same way as in
Section 13.1.2. For our calculations, we will also make use of C0 = SS0 +
𝜅0 × m2
0.
Then, your prior hyperparameters are given by
P0 ⊧𝜅0
Σ0
𝜈0
SS0 or C0.
Updating: After n observations x1, … , xn, your sufficient statistics are n and
Σx = ∑n
k=1 xk, plus a choice of either Σx2 = ∑n
k=1 x2
k, or SSx = Σx2 −Σ2
x∕n.
Your posterior hyperparameters are then given by
P1 ⊧𝜅1 = 𝜅0 + n
Σ1 = Σ0 + Σx
}
m1 = Σ1∕𝜅1
𝜈1
= 𝜈0 + n
C1 = C0 + Σx2
SS1 = C1 −Σ2
1∕𝜅1
= SS0 + SSx + (n𝜅0∕𝜅1) × (Sx∕n −m0)2
⎫
⎪
⎪
⎬
⎪
⎪⎭
s2
1 = SS1∕𝜈1.
This process may be repeated as many times as you want, on to P2, P3, … as
far as you may wish to go, where the prior hyperparameters for the new update
equal the posterior hyperparameters from the previous update. We may wish
to obtain probability distributions, and we have available
(1) the (marginal posterior) probability distribution for the precision 𝜏= 𝜎−2;
(2) the (marginal posterior) probability distribution for the mean 𝜇;
(3) the (posterior) predictive probability distribution for next observation X+.

13.1 Bayes’ Theorem for Gaussian Processes

The probability distributions are
𝜏∼𝛾(𝜈1∕2,SS1∕2)
𝜇∼t(m1, s1 ×
√
1∕𝜅1, 𝜈1)
X+ ∼t(m1, s1 ×
√
1+1∕𝜅1, 𝜈1).
Example 13.1.4 Tara, Penelope, and Beatrice want to estimate the distribu-
tion of income among their fellow students. Their first guess is that the mean
is £16 000, but they are no more certain of this than if they had asked three stu-
dents. They know nothing about the standard deviation. They proceed to ask
50 students about their annual incomes, and get a mean of ̄x = 15 734.80 and
the sample standard deviation is sx = 8 655.30. What are the probability distri-
butions for the mean 𝜇and the precision 𝜏= 𝜎−2 for the distribution of income
among their fellow students? Also, what is the probability distribution for the
income of the next student, were they to ask?
Answer: We begin with the prior:
P0 ⊧𝜅0 = 3
Σ0 = 3 × 16 000 = 48 000
𝜈0 = −1
SS0 = 0
C0 = 0 + 3 × 16 0002 = 768 000 000.
The students have already calculated ̄x and sx, so we employ Defini-
tions 2.3.10 and 2.4.3, and Rule 2.4.5 in reverse, to find Σx = 786 740, SSx =
3 670 796 686.41, and Σx2 = 16 049 993 238.41. Then the updated hyperparam-
eters are
P1 ⊧𝜅1 = 𝜅0 + n = 3 + 50 = 53
Σ1 = Σ0 + Σx = 48 000 + 786 740 = 834 740
m1 = Σ1
𝜅1
= 834 740
53
𝜈1 = 𝜈0 + n = −1 + 50 = 49
C1 = C0 + Σx2 = 768 000 000 + 16 049 993 238.41
= 16 817 993 238.41
SS1 = C1 −
Σ2
1
𝜅1
= 16 817 993 238.41 −834 7402
53
≈3 670 995 736.52
s2
1 = SS1
𝜈1
= 3 670 995 736.52
49
.


13 Bayes’ Theorem with Hyperparameters
μ
X
μ
Figure .S¯ozen performs his measurements in two rounds, and with him, we will perform
our updates in two rounds as well.
We get that
𝜏∼𝛾(49∕2, 3 670 995 736.52∕2)(t) = 𝛾(24.5, 1 835 497 868.26)(t)
𝜇∼t(834 740∕53,
√
3 670 995 736.52∕49 ×
√
1∕53, 49)(x) = t(15 749.80, 1 188.93, 49)(x)
X+ ∼t(834 740∕53,
√
3 670 995 736.52∕49 ×
√
1+1∕53, 49) = t(15 749.80, 8 736.81, 49)(x).
Example 13.1.5
In Figure 13.8, we see abbot S¯ozen being concerned with
mindfulness in traffic. He wants to gauge the speed of the cars driving past in
the 50 km/h zone outside Bugaku temple. He decides to use an Eggeseth laser
speed gauge with 500 pulses, so that the measurement uncertainty becomes a
negligible factor. He wants to see how the speeds are distributed. As part of his
investigations, he wants to know the probability that the mean speed is 10% or
more above the speed limit, and also the probability that any random car would
speed at more than 20% above the speed limit.
(1) During his first round, he measures 10 cars passing by with speeds (in
kilometers per hour) of 59.1, 60.1, 60.1, 57.1, 59.9, 58.1, 47.6, 56.1, 56.0,
and 57.8, which gives us the following statistics to work with: n = 10, Σx =
571.9, and Σx2 = 32 830.7.
(2) In his next round, he measures 40 cars. We mark the new statistics with a
prime to distinguish them from those of the first round. They are n′ = 40,
Σ′
x = 2254.2, and Σ′
x2 = 127 436.06.
We are now going to calculate the probability distributions for 𝜇, 𝜎, and X+,
and then the probabilities P(𝜇> 60) and P(X+ > 60). For our first update, we
use a neutral prior.
Solution: Neutral prior means
P0 ⊧𝜅0 = 0
Σ0 = 0
𝜈0 = −1
C0 = 0.

13.1 Bayes’ Theorem for Gaussian Processes

When we make our update with S¯ozen’s first set of measurements, we get
P1 ⊧𝜅1 = 0 + 10 = 10
Σ1 = 0 + 571.9 = 571.9
m1 = 571.9
10
= 57.19
𝜈1 = −1 + 10 = 9
C1 = 0 + 32 830.7 = 32 830.7
SS1 = 32 830.7 −10 × 57.192 = 123.7.
The first-round posterior probability distributions are then
𝜏∼𝛾(9∕2, 123.7∕2)(t) = 𝛾(4.5, 61.85)(t)
𝜇∼t(571.9∕10,
√
123.7∕9 × (1∕
√
10), 9)(x) = t(57.19, 1.172, 9)(x)
X+ ∼t(571.9∕10,
√
123.7∕9 ×
√
1+1∕10, 9) = t(57.19, 3.888, 9)(x)
giving us probabilities
P(𝜇> 60) = 1 −T(57.19, 1.172, 9)(60) ≈2.0%
P(X+ > 60) = 1 −T(57.19, 3.888, 9)(60) ≈24.4%.
We then perform our second update with S¯ozen’s second set of measure-
ments, using the posterior hyperparameters of the first round as our priors:
P2 ⊧𝜅2 = 10 + 40 = 50
Σ2 = 571.9 + 2 254.2 = 2 826.1
m2 = 56.522
𝜈2 = 9 + 40 = 49
C2 = 32 830.7 + 127 436.06 = 160 266.76
SS2 = 160 266.76 −50 × 56.5222 = 529.9.
The second-round posterior probability distributions are then
𝜏∼𝛾(49∕2, 529.9∕2)(t) = 𝛾(24.5, 264.95)(t)
𝜇∼t(2 826.1∕50,
√
529.9∕49 × 1∕
√
50, 49)(x) = t(56.522, 0.465, 49)(x)
X+ ∼t(2 826.1∕50,
√
529.9∕49 ×
√
1+1∕50, 49) = t(56.522, 3.321, 49)(x)
giving us probabilities
P(𝜇> 60) = 1 −T(56.522, 0.465, 49)(60) ≈0.0%
P(X+ > 60) = 1 −T(56.522, 3.321, 49)(60) ≈15.0%.
We see that 𝜇, the cars’ mean speed, becomes very precise, whereas our esti-
mate of the speed of the next car remains spread out. This corresponds to our


13 Bayes’ Theorem with Hyperparameters
intuition of the matter, for it would indeed be strange if the passing cars started
driving at speeds increasingly close to the mean speed just because S¯ozen had
started gauging their speeds. So while the precision of our 𝜇estimate keeps
growing, the probability distribution of our estimates of how fast the next car
passes by Bugaku, X+, instead converges to the underlying but unknown prob-
ability distribution of the actual seeds, 𝜙(𝜇,𝜎). So the limiting standard deviation
for our estimate of 𝜇is zero, whereas for X+ the limit is the underlying 𝜎.
..
Summary
We esimate the parameters 𝜇and 𝜎for a Normal distribution 𝜙(𝜇,𝜎) by means of
n observations x1, … , xn sampled from this Normal distribution. The sufficient
statistics are n, Σx, and SSx, where Σx = ∑n
k=1 xk, and SSx = ∑n
k=1(xk −̄x)2. For
known 𝜇= m0, we may replace the statistic SSx by SBx = ∑n
k=1(xk −m0)2 =
SSx + n × (̄x −m0)2. For unknown 𝜇, we may use the statistic Σx2 = ∑n
k=1 x2
k
instead of SSx.
r Let m0 be your best estimate of 𝜇, and let 𝜅0 be how many measurements
would be needed for you to be as certain as you are. Let Σ0 = 𝜅0m0.
r Let s0 be your best estimate of 𝜎, and let n0 be how many measurements
would be needed for you to be as certain as you are. Let 𝜈0 = n0 −1, and SS0 =
max(0, 𝜈0) × s2
0. If you are using the statistic Σx2, let C0 = SS0 + 𝜅0 × m2
0.
r If you are ignorant of either 𝜇or 𝜎, indicate your certainty by letting the
observation equivalents (respectively 𝜅0 and 𝜈0) be zero. This corresponds
to an objective and neutral prior in the absence of observation.
r If you are certain of the values of 𝜇or 𝜎, choose the corresponding rectangle
in Table 13.1.
Notice that there really are three degrees of knowledge for each parameter:
fully known, fully unknown, and partially unknown. However, since the updat-
ing rules are the same for fully unknown and partially unknown, the two are
merged into the category unknown.
.
Bayes’Theorem for Bernoulli Processes
We recall from Section 9.2.2 that a Bernoulli process is a sequence of indepen-
dent Bernoulli distributed stochastic variables with common parameter p.
If the parameter p of a Bernoulli process is unknown, we may estimate it by
means of Bayes’ theorem. For individual observations, p is the parameter of a
Bernoulli distribution bernp, and for n observations, p is the second param-
eter of a binomial distribution bin(n,p). The hyperparameter version of Bayes’
theorem gives an estimate of the parameter p, and of the next observations,
according to the following rules.

13.2 Bayes’ Theorem for Bernoulli Processes

Table .Summary of the Gaussian updating rules
𝜎= s0 (known)
𝜎unknown
𝜇= m0 (known)
No updating.
Posterior hyperparameters:
𝜈1 = 𝜈0 + n
SS1 = SS0 + SBx
}
s2
1 = SS1
𝜈1
Posterior values:
𝜏= 1∕s2
0
𝜇= m0
X+ ∼𝜙(m0, s0)(x)
Posterior values:
𝜏∼𝛾(𝜈1∕2, B1∕2)(t)
𝜇= m0
X+ ∼t(m0, s1, 𝜈1)(x)
𝜇unknown
Posterior hyperparameters:
𝜅1 = 𝜅0 + n
Σ1 = Σ0 + Σx
}
m1 = Σ1
𝜅1
Posterior hyperparameters:
𝜅1 = 𝜅0 + n
Σ1 = Σ0 + Σx
}
m1 = Σ1
𝜅1
𝜈1 = 𝜈0 + n
C1 = C0 + Σx2
SS1 = C1 −𝜅1m2
1
⎫
⎪
⎪
⎬
⎪
⎪⎭
s2
1 = SS1
𝜈1
Alternatively:
SS1 = SS0 + SSx + n × 𝜅0
𝜅1
(x −m0)2
Posterior values:
𝜏= 1∕s2
0
𝜇∼𝜙(m1, s0
√
1∕𝜅1)(x)
X+ ∼𝜙(m1, s0
√
1+1∕𝜅1)(x)
Posterior values:
𝜏∼𝛾(𝜈1∕2, B1∕2)(t)
𝜇∼t(m1, s1 ×
√
1∕𝜅1, 𝜈1)(x)
X+ ∼t(m1, s1 ×
√
1+1∕𝜅1, 𝜈1)(x)
Choice of prior: You are estimating the parameter p for a Bernoulli distribution
bernp. You then find two parameters: a0 is the weight of success, ⊤, whereas b0 is
the weight of failure, ⊥. You choose either a neutral prior expressing ignorance,
or an informative prior expressing your knowledge.
r The neutral prior has parameters a0 = b0 = u ∈[0, 1]. There are three com-
mon choices of value for u.
– u = 0: “Total ignorance” (Novick & Hall, Haldane, Jaynes). Use this if you
do not even know whether both ⊤and ⊥are possible outcomes.
– u = 0.5: “Ordinary ignorance” (Jeffreys). Use this if you know that both ⊤
and ⊥are possible outcomes, but otherwise know nothing about p.
– u = 1: “Informed ignorance” (Laplace, Bayes). Use this if you initially,
before observations, consider all values of p to be equally probable.


13 Bayes’ Theorem with Hyperparameters
If, in a concrete case, you find yourself unable to choose between two of the
alternative values for u above: choose the lowest one!
r An Informative prior may be chosen either from posterior hyperparameters
from a previous update, or by coding your informal knowledge as numbers,
thus: make a guess p0 of p, and let 𝜅0 be how many observations you would
need to be as certain as you are. Then, a0 = 𝜅0p0 and b0 = 𝜅0(1 −p0). Notice
that you should end up with a0, b0 ≥1, since otherwise you would have a
value p0 too extreme to be justified by as few as 𝜅0 observations.
Your prior hyperparameters are then given by
P0 ⊧a0
b0.
Updating: After n observations x1, … , xn, you have found k = number of ⊤,
and l = number of ⊥. Then, k and l are sufficient statistics. Your posterior
hyperparameters are then
P1 ⊧a1 = a0 + k
b1 = b0 + l.
This process may be repeated as many times as you want, on to P2, P3, … as
far as you may wish to go, where the prior hyperparameters for the new update
equal the posterior hyperparameters from the previous update. We may then
read off the following posterior and predictive probability distributions.
1) The (posterior) probability distribution of the parameter p.
2) K+m – the number of successes (⊤) during the next m observations.
3) L+s – the number of failures (⊥) before s new successes (⊤).
The probability distributions are then (the probability distributions 𝛽b and
𝛽nb are described in Appendix A.3):
p ∼𝛽(a1, b1)
K+m ∼𝛽b(a1, b1, m)
L+s ∼𝛽nb(a1, b1, s),
which also gives us p1 = E[p] =
a1
a1+b1 .
A special case is if a1 or b1 is zero. In that case p follows a discrete probability
distribution with either P(⊤) = 0 or (⊤) = 1, with the opposite probability for
⊥. For all other cases, see Table 13.9 for an illustration of how these probability
distributions change as you make more observations.

13.2 Bayes’ Theorem for Bernoulli Processes

p
K+4
L+5
n = 3.
n = 12.
n = 45.
p known.
Figure .The probability distributions for different numbers of observations.
Example 13.2.1
“SeedSmart Ltd” has planted 18 new rose bushes for Sam.
They did so last year as well, and then 6 of the bushes yielded red roses, whereas
12 yielded white. “How many will there be of each kind?” Sam wonders.
“Let’s calculate,” Bard replies. “First, we must set the prior distribution param-
eters for the proportion of red roses. What do you know about roses, Sam? And
what did you know before you started growing them in your own garden?
“I know they come in both a red and a white variety – well, at least the
ones from SeedSmart,” Sam replies, “and they seem to have white and red
only – and already last year I knew that SeedSmart’s system of keeping track of
which seeds are which variety is no better than random, so any bush from them
could be either red or white.
“To me,” Bard comments, “it sounds like your knowledge is best expressed
through a neutral prior with a0 = b0 = u = 1. Agreed, Sam?”
Sam nods, and Bard starts calculating:
Prior P0 ⊧a0 = 1
b0 = 1.
Updating: P1 ⊧: a1 = a0 + 6 = 1 + 6 = 7
b1 = b0 + 12 = 1 + 12 = 13.
So the proportion of rose bushes that are red is p ∼𝛽(7,13). The best estimate
of p is then E[p] =
7
7+13 = 0.35.
“And now you probably wonder how many red rose bushes you will be grow-
ing for your Rosie?” Bard asks.
Sam nods; “she would have preferred three red and two white. What is
the probability of that? Do we use a binomial distribution with p = 0.35 and
n = 5?”


13 Bayes’ Theorem with Hyperparameters
Bard reminds Sam that he has solved problems with an uncertain p before
(Chapter 6: problems (12)–(14)), and says: “Just use the formula for predictive
distributions when p is uncertain. Let us do the calculations together. And … I
left my pocket calculator with all the pre-programmed functions at home today,
so we’ll have to make do with the ugly formula.”
Bard writes:
P(K+5 = 3) = 𝛽b(7,13,5)(3) =
(5
3
)
×
(
7+13
7
)
× 7 × 13
7+13
(
7+13+5
7+3
)
× (7+3)(13+5−3)
7+13+5
“0.179 842,” Sam bursts out before Bard has had time to calculate anything at
all. “I’ve got Wolfram Alpha on my phone, so I only needed to type
PDF[BetaBinomialDistribution[7, 13, 5, 3]
and the answer popped out together with a fair bit of explanation and other
links!”
We shall look at a more demanding example to illustrate how much of a dif-
ference it may make if we commit the error of calculating with a binomial distri-
bution with fixed rate parameter value p1 = E[p] instead of taking into account
the uncertainty in the rate parameter p.
Example 13.2.2 Troll Motors have tested their assembly line to test produc-
tion quality. They want fewer than 1% of their cars to have a critical number of
production errors, and, during the testing of 500 cars, 4 had the critical amount
of such errors. That is, 4∕500 = 0.08, which is not too bad. But what is the prob-
ability that fewer than 1% of the cars produced will end up with the critical
number of errors if Troll produces 20 000 cars?
We must first choose our prior, and we here invoke the rule that if in doubt,
choose the lowest u value. Then,
Prior P0 ⊧a0 = 0
b0 = 0.
Updated, P1 ⊧a1 = a0 + 4 = 4
b1 = b0 + 496 = 496.
Let X be the number of cars with a critical number of errors. We know that
1% of a production of 20 000 cars is 200. What, then, is P(X ≤200)?

13.2 Bayes’ Theorem for Bernoulli Processes

Wrong solution: A cumulative binomial distribution with parameter p =
4∕500 = 0.08 gives
P(X ≤200) = BIN(20 000 , 0.08)(200) = 0.999 049 ≈99.9%.
That is, a mere 0.1% probability that the number of cars with critically many
errors exceeds 1% of the production. Pretty good, isn’t it? There should be no
doubt that the assembly line is ready for full production! It is a pity, then, that
this was the wrong way to calculate this probability, since we forgot to include
the effect of the uncertainty in the value of p!
Correct solution: We include the uncertainty in p by calculating using a beta
binomial distribution:
P(X ≤200) = P(K+200 00 ≤200) = BB(4, 496, 20 000)(200) = 0.734 991 ≈73.5%.
There is in other words a 26.5% probability that more than 1% of the
20 000 cars will have critically many errors, and there is a significant difference
between 26.5 and 0.1%.
N.B. Notice that CDF[BetaBinomialDistribution[4, 496, 20000], 200]
exceeds the capacity of the free version of Wolfram Alpha, so you need to
rewrite to
Sum PDF[BetaBinomialDistribution[4, 496, 20000], x] x from 0 to 200.
The general lesson to take home from this example is that, when the num-
ber of future occurrences to be predicted is far larger than the number in the
preliminary test, and the p value lies somewhere in the extremes (near zero or
one), then the error of approximating the correct solution, which uses the 𝛽b
distribution, by a simple bin distribution may become spectacularly large. In
the case above, the error would have been very costly, and one may wonder if
such a decision maker would get to keep his job.
For a given 𝜀> 0 we may check if
|||||
k2
a + l2
b −(k + l)2
a + b
|||||
< 2𝜀.
A reasonable rule-of-thumb limit for when to approximate the 𝛽b and 𝛽nb
distributions by the bin and nb distributions is 𝜀= 0.05. When that rule is sat-
isfied,
r bin(k+l, a∕(a+b))(k) is a good approximation to 𝛽b(a,b,k+l)(k)
r nb(k, a∕(a+b))(l) is a good approximation to 𝛽nb(a,b,k)(l).


13 Bayes’ Theorem with Hyperparameters
.
Bayes’Theorem for Poisson Processes
We recall from Sections 9.6.1 and 10.3.2 that a Poisson process is a waiting and
counting process with rate 𝜆, where the waiting time for the next occurrence is
exponentially distributed exp𝜆, whereas the number of occurrences during the
next (time) unit is Poisson distributed pois𝜆.
If the parameter 𝜆of a Poisson process is unknown, we may estimate it by
means of Bayes’ theorem. We then count the number of occurrences n in the
space of t (time) units, and estimate 𝜆according to the following rules.
Prior for 𝜆: Let 𝜆0 be your best guess at the value of the rate parameter 𝜆. Then
indicate how certain you are of your estimate 𝜆0 by stating how many occur-
rences 𝜅0 you would need to be as certain as you are, or for how many (time)
units 𝜏0 you would have needed to observe to be as certain as you are. These
values are related through the formula 𝜆0 = 𝜅0
𝜏0 . If you are completely uncer-
tain, or for other reasons want a neutral reference prior,3 you simply refrain
from making a guess at 𝜆0, and set 𝜅0 = 𝜏0 = 0.
Then your prior hyperparameters are given by
P0 ⊧𝜅0
𝜏0.
Updating: You have registered n occurrences during t units. For an estimate of
the rate 𝜆for a Poisson process, n and t are sufficient statistics. Your posterior
hyperparameters are then
P1 ⊧𝜅1 = 𝜅0 + n
𝜏1 = 𝜏0 + t.
This process may be repeated as many times as you want, on to P2, P3 … as
far as you may wish to go, where the prior hyperparameters for the new update
equal the posterior hyperparameters from the previous update. When we wish
to read the posterior probability distribution for 𝜆and the predictive probabil-
ities for the next observations, we find that
𝜆∼𝛾(𝜅1 , 𝜏1)(l).
As for the predictions, we have two different predictions we may make:
r N+𝜃, the number of occurrences in the next 𝜃units;
N+𝜃∼nb(𝜅1 ,
𝜏1
𝜏1+𝜃)(𝜂),
3Another common reference prior corresponds to 𝜅0 = 1
2 and 𝜏0 = 0, but we will stick with the
simplest one.

13.3 Bayes’ Theorem for Poisson Processes

λ
T+50
N+
κ1 = 1.
κ1 = 6.
κ1 = 100.
λ known.
Figure .The probability distributions for different values of the hyperparameters.
where nb is the negative binomial distribution (9.5), using the generalized
binomial (Section A.2.12) when the numbers are non-integer.
r T+k, the waiting time for the next k occurrences:
T+k ∼g𝛾(k , 𝜅1 , 𝜏1)(t),
where g𝛾is the gamma–gamma distribution (Section A.3.2).
See Table 13.10 for an illustration of how these probability distributions
change as you make more observations.
Example 13.3.1 We look a hundred years back in time, to Norway, to study
the number of offspring for women who had passed child bearing age (we use
50 as a cut-off). The number of offspring in societies with high childhood mor-
tality are generally considered to be Poisson distributed. We are estimating 𝜆
for this Poisson distribution. For our prior, we use the numbers from a similar
study from Sweden at the same time, where they counted a total of 26 offspring,
distributed between 5 women. We use for our prior
P0 ⊧𝜅0 = 26
𝜏0 = 5.
In our Norwegian study, we look at 10 women, and note that they had a total
of 49 offspring. Our updated probabilities are then
P1 ⊧𝜅1 = 26 + 49 = 75
𝜏1 = 5 + 10 = 15.
We then get a posterior distribution for the parameter 𝜆:
𝜆∼𝛾(75,15)(l).


13 Bayes’ Theorem with Hyperparameters
2
4
6
8
0.2
0.4
0.6
(a) Posterior distribution, λ ~ γ( 75,15) (l).
2
4
6
8
0.05
0.10
0.15
η
(b) Next number of offspring, f(η).
Figure .Distributions used for studying the number of offspring.
In this case, we have no waiting time T, since our units are not time, but the
individual women. We would, however, like to estimate the number of offspring
the next woman has. That estimate is
N+ ∼f (𝜂) = nb(75 , 15
16 )(𝜂).
From these distributions we may read all that we need to know, such as for
instance that the expected number of offspring is 75(1 −15
16)∕15
16 = 5. See Fig-
ure 13.11 for illustration.
Example 13.3.2
You work for the venture capital investment company
Reodora, and you are responsible for their portfolio of technologically innova-
tive companies. In a model inspired by Warren Buffett, these companies will pay
Reodora $10 million every time their free funds are in excess of $20 million –
unless they can make good use of them for internal investment. Your experi-
ence with these payments is that they follow a Poisson process. Your job right
now is to estimate that process’s 𝜆, and then to estimate the waiting time for
the next two payments.
The portfolio is almost four years old, but since the money flow for the first
year tends to go out rather than in, you limit your investigations to the past
three years. You find that Reodora have received 39 payments during the period.
Since this is roughly one payment per month, you decide to use months as your
time units. You use a neutral prior:
P0 ⊧𝜅0 = 0
𝜏0 = 0.
Your updated probabilities are then
P1 ⊧𝜅1 = 0 + 39 = 39
𝜏1 = 0 + 36 = 36 (since 3 years = 36 months).

13.4 Exercises

0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
(a) Posterior distribution for λ.
1
2
3
4
5
6
7
0.1
0.2
0.3
t
(b) Waiting time for two payments, T+2.
Figure .Distributions used for studying Reodora’s portfolio payments.
We then get the following posterior distribution for the parameter 𝜆:
𝜆∼𝛾(39,36)(l).
The waiting time for the next two payments is then distributed
T+2 ∼g𝛾(2,39,36)(t) =
65t
54
(
t
36 + 1
)41 .
See Figure 13.12 for illustration.
.
Exercises
Bayes’Theorem for Gaussian Processes
1
You are given a prior or prior hyperparameters for a Gaussian process, and
observational data, and values z and s. Find (if relevant) the posterior (pre-
dictive) probability distribution of 𝜇, 𝜏, and X+. Further, calculate (if rele-
vant) the probabilities P(𝜇< z), P(𝜎< s), and P(X+ < z). To build under-
standing, it pays off to draw at least a few of the function graphs.
Unknown 𝜇, known 𝜎.
(a) Prior: 𝜅0 = 0, Σ0 = 0. s0 = 2.5. Statistics: n = 5, Σx = 23.43. z = 6.
(b) Prior: 𝜅0 = 0, Σ0 = 0. s0 = 6. We have 7 observations with ̄x = 45.414 3.
z = 40.
(c) Prior: 𝜅0 = 0, Σ0 = 0. s0 = 15.9. Data: {319.3, 369.4, 327.3}. z = 350.
(d) Prior: 𝜅0 = 0, Σ0 = 0. s0 = 200. Statistics: n = 12, Σx = 35 723.7.
z = 3 125.
(e) Prior: 𝜙(5,1). s0 = 2. We have 8 observations with ̄x = 5.45. z = 6.
(f) Prior: 𝜙(510,15). s0 = 30. Statistics: n = 7, Σx = 3568.2. z = 500.
(g) Prior: 𝜙(0.19,0.03). s0 = 0.03. Data: {0.174, 0.144, 0.255, 0.237}. z = 0.15.
Known 𝜇, unknown 𝜎.
(h) Prior: 𝜈0 = −1, SS0 = 0. m0 = 23. Statistics: n = 5, Σx = 119.03, SSx =
3.433 77. z = 25 and s = 1.25.


13 Bayes’ Theorem with Hyperparameters
(i) Prior: 𝜈0 = −1, SS0 = 0. m0 = 50. We have 8 observations with average
̄x = 49.871 6 and sample standard deviation sx = 3.424 29. z = 45 and
s = 10.
(j) Prior: 𝜈0 = 2, SS0 = 0.16. m0 = 1.2. Data: {1.18, 1.14, 1.22, 1.25, 1.15,
1.18, 1.22, 1.15, 1.24, 1.26}. z = 1 and s = 0.1.
Unknown 𝜇, unknown 𝜎.
(k) Prior: 𝜅0 = 0, Σ0 = 0, 𝜈0 = −1, SS0 = 0. Statistics: n = 8, Σx = 318 32,
Σx2 = 126 742 346. z = 4 000 and s = 100.
(l) Prior: 𝜅0 = 0, Σ0 = 0, 𝜈0 = −1, SS0 = 0. We have 7 observations with
average ̄x = 11.528 6 and sample standard deviation sx = 24.234 2. z = 0
and s = 15.
(m) Prior: 𝜅0 = 1, Σ0 = 0.007, 𝜈0 = 1, SS0 = 1.042. Data: {0.232, −1.587,
−0.986}. z = 0 and s = 0.5.
(n) Prior: 𝜅0 = 0, Σ0 = 0, 𝜈0 = −1, SS0 = 0. Statistics: n = 13, Σx = 295.839,
SSx = 174.964. z = 20 and s = 5.
(o) Prior: 𝜅0 = 2, Σ0 = 40, 𝜈0 = 2, SS0 = 3. We have 8 observations with
average ̄x = 19.671 9 and sample standard deviation sx = 1.044 14. z =
17.9 and s = 1.179.
(p) Prior: 𝜅0 = 0, Σ0 = 0, 𝜈0 = −1, SS0 = 0. Statistics: n = 8, Σx = 737.1,
SSx = 6 604.9. z = 50 and s = 25.
(q) Prior: 𝜅0 = 6, Σ0 = 0.000 019 8, 𝜈0 = 5, SS0 = 1.5 ⋅10−7. We have 30
observations with average ̄x = 3.306 35 ⋅10−6 and sample standard
deviation sx = 2.997 56 ⋅10−8. z = −0.000 04 and s = 0.000 04.
2
(Theoretical) Prove the formula for the probability distribution of X+ in Sec-
tion 13.1.1. (Hint: Use that 𝜇and (X+ −𝜇) ∼𝜙(0,𝜎) are independent.)
3
Capacitors: You have measured the capacitance of FR Electronics’s small-
est capacitors. From a sample of 25 measurements, you got an average of
c = 49.19 μF, and a sample standard deviation of sc = 2.15 μF. Assume the
capacitance of this kind of capacitor follows a Normal distribution 𝜙(𝜇,𝜎)
with unknown values for 𝜇and 𝜎. Use a neutral prior, and find the prob-
ability distributions of 𝜇and 𝜏, and find the probability that a randomly
selected capacitor of this kind has a capacitance of more than 50 μF.
4
(Challenge) The tensile strength of cables of the same type and thickness
typically follows some Normal distribution 𝜙(𝜇,𝜎), where 𝜇and 𝜎depend
only on type and thickness. A colleague of yours has pulled apart wires of
a certain type and thickness to find their tensile strength. The only thing
you know is that your colleague made use of a neutral prior, and that the
posterior probability distribution for 𝜇(in kilonewtons) was 𝜇∼t(943,11,6).
What is the probability that the next cable deforms at a smaller load than
900 kN?

13.4 Exercises

Bayes’Theorem for Bernoulli Processes
5
Posterior: You are given the prior hyperparameters of a binomial process,
observation data, and a value p. Find the posterior distribution for 𝜋and
its Normal approximation. Further, calculate the probability P(𝜋≤p) both
by exact calculation on 𝛽, and by using the Normal approximation.
(a) Prior hyperparameters: a0 = 2, b0 = 2. Observations: 17 positive, 29
negative. p = 0.4.
(b) Prior: 𝛽(1,7). Observed: k = 4 positive and l = 89 negative. p = 0.07.
(c) Prior hyperparameters: a0 = 0, b0 = 0. Observed: k = 42 positive and
l = 13 negative. p = 0.7.
(d) Prior: 𝛽(0.5, 0.5). Observed: k = 434 positive and l = 177 negative.
p = 0.7.
6
Predictive: [requires a good calculation tool] You are given the posterior for
the Bernoulli parameter 𝜋, and numbers m, s, k, and l. Find the predictive
distributions for K+m and L+s, and calculate the probabilities P(K+m ≤k)
and P(L+s < l).
(a) Posterior: a1 = 19, b1 = 31. m = 5, s = 5, k = 3, l = 7.
(b) Posterior: a1 = 5, b1 = 96. m = 20, s = 4, k = 3, l = 12.
(c) Posterior: a1 = 42, b1 = 13. m = 7, s = 14, k = 4, l = 5.
(d) Posterior: a1 = 434.5, b1 = 177.5. m = 32, s = 20, k = 23, l = 8.
7
The Bayern Munich player Arjen Robben scores most of his goals with the
left foot. The statistics of the goals he has scored by foot are as follows:
Season
left
right
2013/14
9
1
2014/15
12
2
2015/16
3
0
Let 𝜋be the proportion of Robben’s foot scorings that he does with his
left. Find the probability distribution of 𝜋when…
(a) you use Jeffreys’ prior for proportions, and update the probability dis-
tribution for 𝜋with the observations from 2013/14;
(b) you go a new round, and update with the observations from 2014/15;
(c) you further update with the observations from 2015/16;
(d) What is the probability that 𝜋is in excess of 75%?
(e) Find the probability distribution of the number of left-foot goals in
Robben’s next 3 foot scorings.
(f) Find the probability that 2 out of the next 3 foot scorings are done with
his left.
8
Bard has given you a biased coin, and you wonder what the probability 𝜋
of heads is. He replies that he doesn’t quite know, but that his friend Sam,


13 Bayes’ Theorem with Hyperparameters
who gave it to him, once estimated the probability of heads to be 3
7, and
that Sam was as certain of that as if he had flipped the coin 21 times.
(a) What are your prior hyperparameters a0 and b0?
(b) You get 23 heads and 18 tails. What are the posterior hyperparameters?
(c) You decide to flip the coin a few more times, to get an even sharper
estimate on 𝜋. What are your prior hyperparameters this time?4
(d) You now get 458 heads and 366 tails. What are your posterior hyper-
parameters now?
9
You are looking at the proportion 𝜋of consumers who prefer MegaCola to
its competitors. You use Jeffreys’ prior hyperparameters, a0 = b0 = 0.5.
(a) You arrange blind tastings of MegaCola and and its competitors, and
then ask the participants to indicate which one they preferred. After
having tested 50, the feedback is that 41 of them prefer MegaCola.
What are your posterior hyperparameters, and what is the probability
distribution of 𝜋?
(b) What is the probability that the proportion who prefer MegaCola
exceeds 75%?
10
You are estimating the proportion of Macintoshes among the laptops of a
rather large company. Your prior hyperparameters are a0 = 7 and b0 = 3.
You ask 10 laptop-using colleagues; 8 of them are on a Macintosh. What
are now your posterior hyperparameters for the proportion of MacBooks?
11
You are looking into the quality of the diamonds of the diamond mines in
a new area. You have a special interest in “Fancy diamonds”5 of quality IF
and VVS, and you are estimating 𝜋, the proportion of diamonds from the
new mines that fit one of these descriptions. After having evaluated 172
diamonds, you have found 19 that are either IF or VVS, while the rest are
of lower quality grades.
(a) You are unsure which of the 3 neutral priors to choose. Find the poste-
rior distributions you find for 𝜋, for each of them.
(b) Calculate, for each of the 3 priors, the probability that 𝜋> 0.1.
12
In the two-player board game Go, black and white take turns putting a
stone on the board, with black having the first move. Sondre Glimsdal, the
Og Go club chairman, wonders what percentage of the games is won by
each color. He believes it is fairly even, so his prior for the proportion of
games won by white is 𝛽(7,7).
4Yes, the answer is obvious; mathematics and statistics problems don’t have to be hard!
5Naturally colored diamonds.

13.4 Exercises

(a) Sondre looks at 20 randomly chosen games, and sees that 13 were won
by white, and 7 were won by black. What is Sondre’s posterior proba-
bility distribution for the proportion of games won by white?
(b) Sondre looks at another 20 random games, and finds that 11 of these
were won by white, and 9 were won by black. What is Sondre’s new
posterior probability distribution for the proportion of games won by
white?
(c) What is Sondre’s probability that white wins at least half of the games?
Bayes’Theorem for Poisson Processes
13
Posterior: You are given prior hyperparameters for a Poisson process, and
observational data. Find the posterior distribution for the rate parameter 𝜆.
(a) Prior: 𝜅0 = 0, 𝜏0 = 0. Observed: n = 7 occurrences during t = 5 units.
(b) Prior: 𝜅0 = 5, 𝜏0 = 10. Observed: n = 3 occurrences during t = 7 units.
(c) Prior: 𝜆∼𝛾(12,3). Observed: n = 17 occurrences during t = 5 units.
k = 2.
(d) Prior: 𝜅0 = 3, 𝜏0 = 73. Observed: n = 6 occurrences during t = 119
units.
14
Predictive: [requires a good calculating tool] You are given posterior distri-
butions or hyperparameters for the rate 𝜆of a Poisson process, and values
k, l, m. Calculate the predictive distribution for N+ and T+k, and calculate
P(T+k ≤l) and P(N+1 ≤m).
(a) Posterior hyperparameters: 𝜅1 = 7, 𝜏1 = 5. k = 2, l = 3, m = 4.
(b) Posterior: 𝜆∼𝛾(8,17). k = 1, l = 2, m = 1.
(c) Posterior hyperparameters: 𝜅1 = 29, 𝜏1 = 8. k = 3, l = 1, m = 5.
(d) Posterior: 𝜆∼𝛾(9,192). k = 2, l = 30, m = 0.
15
(t = units = number of hunters) The daily catch for grouse hunters in an
area is considered to be Poisson distributed with rate 𝜆. One day, you talked
to 23 hunters from a certain part of the Lowlands, and their total catch was
111 grouse. Use a neutral prior, and find the posterior probability distribu-
tion for 𝜆.
16
(t = time = number of weeks) The number of plumbing gaskets that need
changing every week in an apartment complex is assumed to follow a Pois-
son process with rate 𝜆. You are estimating this need for an apartment
complex with 70 flats, and have looked into the documentation for the last
semester (26 weeks), and find 53 gasket changes registered. Use a neutral
prior, and calculate the posterior probability distribution for 𝜆.
17
(t = distance = number of kilometers) The number of cracks in the tarmac
per kilometer of road is assumed to follow a Poisson process with rate 𝜆.


13 Bayes’ Theorem with Hyperparameters
Your job is to find this rate for a lesser highway, and you have found 13
cracks in 10 km. Use neutral prior, and calculate the posterior probability
distribution of 𝜆.
18
(t = area = number of square meters) How many four-leaf clovers are there
per square meter in a field of leaf clovers? Assume that the occurrence
follows a Poisson process with rate 𝜆. You look at three independent leaf
clover fields. The first field is t1 = 1.9 m2 in area, and has n1 = 0 four-leaf
clovers. The second field had an area of t2 = 0.7 m2, and has n2 = 3 four-
leaf clovers, whereas the third spot of area t3 = 1.2 m2 had n3 = 1 four-leaf
clovers. Use a neutral prior, and find the posterior probability distribution
of 𝜆.
19
(t = volume = number of cubic meters) The number of bacterial colonies
per cubic centimeter in a certain polluted lake is assumed to be Poisson
distributed with parameter 𝜆. You sample 1 deciliter, and find 157 bacte-
rial colonies. Use a neutral prior, and calculate the posterior probability
distribution of 𝜆.



Bayesian Hypothesis Testing
CONTENTS
14.1 The Utility Function u, 329
14.2 Comparing to a Fixed Value, 334
14.3 Pairwise Comparison, 340
14.4 Exercises, 345
“Sam?” Bard asks, “do you want to take part in a free bet? Free for you, that is,
not me. I’ll be tossing this D8 die into a box – there we go! – where none of us
can see it, and then you will bet on one of the alternatives: was it a 5, or was it
a non-5?”
“Well then, I bet on the non-5,” Sam replies, “since it has the greater proba-
bility of the two. Logical!”
“I forgot to tell you something,” Bard continues. “If you bet on 5 and were
right, I’ll give you £200. If you bet on non-5 and were right, I will pay you £1. A
wrong guess gives you nothing, of course.”
“Hold on,” Sam says hurriedly, “that is a quite different bet. I am changing my
bet to 5. Logical!”
“Good,” Bard replies, “Let’s have a look, and . . . ah, it was a 4.”
“I don’t regret my choice,” Sam responds, “and I would bet likewise if we did
it again.” He looks suggestively at Bard before he continues: “For it was logical
to bet as I did. 1
8 times 200 is 25, whereas 7
8 times 1 is less than a pound. So in
the long run my betting strategy will pay off.”
“Good again,” Bard announces, “you have just made a decision by means of a
utility function!”
.
The Utility Function u
“A decision is a choice between different alternatives 𝜃1, 𝜃2, …,” Bard explains.
“An alternative 𝜃has a utility function u𝜃(x) describing the consequences of
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


14 Bayesian Hypothesis Testing
100
(a) Alternative 1: Betting that x < 100.
100
(b) Alternative 2: Betting that x > 100.
Figure .Two alternatives, illustrated together with a probability distribution.
choosing 𝜃for the different values of a variable x. But x is an unknown quan-
tity, like the outcome when I tossed the D8, so the rational choice therefore
depends on the probability distribution over the x values. Look at the proba-
bility distribution in Figure 14.1, Sam: Would you bet that x is larger or smaller
than 100?”
“I see that x < 100 is a lot more probable,” Sam replies, “but you’re not fooling
me this time! Before I give my final answer, I would like to know the payoff for
each of the two alternatives!”
“I like your way of thinking,” Bard smiles, “for you have realized that you need
to take both probability and utility into account. The yardstick of how much an
alternative is worth is expected utility.”
Definition 14.1.1 For a continuous stochastic variable X ∼f (x) taking val-
ues in (A, B), and a utility function u𝜃(x), the expected utility is
U𝜃= E[u𝜃(X)] = ∫
B
A
u𝜃(x) ⋅f (x) dx.
“And for a discrete X, we naturally use the sum instead of the integral,” Bard
comments, “in any case we will stick with two kinds of utility: stepwise func-
tions and linear functions. These kinds of function lend themselves easily to
calculation and theoretical reasoning.”
Stepwise functions
A stepwise function divides ℝinto n intervals, and is constant within each
interval. (See Figure 14.2.)
u𝜃(x) =
⎧
⎪
⎨
⎪⎩
v1
x ∈I1
v2
x ∈I2
⋮⋮
vn
x ∈In.

14.1 The Utility Function u

I1
I2
I3
I4
Figure .A stepwise function.
The expected utility of a stepwise function u, given a stochastic variable
X, is
U𝜃=
n
∑
k=1
vk × P(X ∈Ik) = v1 × P(X ∈I1)
+ v2 × P(X ∈I2) + ⋯+ vn × P(X ∈In).
Linear functions
A linear function
u𝜃(x) = a + bx
is a utility function for X when |𝜇X| < ∞. (See Figure 14.3.) The expected utility
of a linear function u, given a stochastic variable X, is
U𝜃= a + b𝜇X.
Example 14.1.2 Let X ∼𝜙(2,5), and let u1 and u2 be two utility functions,
u1(x) =
⎧
⎪
⎪
⎨
⎪
⎪⎩
3
x < −1
2
−1 < x < 2
5
2 < x < 6
−1
x > 6
and u2(x) = −1 + 3x,
and find U1 and U2.


14 Bayesian Hypothesis Testing
Figure .A linear function.
Answer: The expected utility values of X under respectively u1 and u2 are then
U1 = 3P(X < −1) + 2P(−1 < X < 2) + 5P(2 < X < 6) −1P(X > 6)
= 3 × 0.274253 + 2 × 0.225747 + 5 × 0.288145 −1 × 0.211855 = 2.503 12.
U2 = −1 + 3𝜇X = −1 + 3 × 2 = 5.
Example 14.1.3 Let Y ∼𝛾(4,1), and let u1 and u2 be two utility functions,
u1(y) =
{
2
y < 5
8
y > 5
and u2(y) = 27 −5y,
and find U1and U2.
Answer: The expected utilities of Y, under respectively u1 and u2, are then
U1 = 2P(Y < 5) + 8P(Y > 5) = 2 ⋅0.734974 + 8 ⋅0.265026 = 3.59016
U2 = 27 −5𝜇Y = 27 −5 ⋅4
1 = 7
Example 14.1.4 Let Z ∼𝛽(7,13), and let u1 and u2 be two utility functions,
u1(z) =
⎧
⎪
⎨
⎪⎩
−1
z < 0.2
4
0.2 < z < 0.5
10
z > 0.5
and u2(z) = 2.3 + 0.8z,
and find U1 and U2.
Answer: The expected utility values for Z under respectively u1 and u2 are then
U1 = −1P(Z < 0.2) + 4P(0.2 < Z < 0.5) + 10P(Z > 0.5)
= −1 ⋅0.067 600 1 + 4 ⋅0.848 866 + 10 ⋅0.083 534 2 = 4.163 21.
U2 = 2.3 + 0.8𝜇Z = 2.3 + 0.8 ⋅
7
7 + 13 = 2.58.

14.1 The Utility Function u

0
1 000
1 000 000 1 000 000 000
U(x) = material utility
x = money
(a) Concave economic utility.
50
100
150
200
U(x) = health utility
x = blood pressure
(b) Non-concave health utility.
Figure .Two other utility models.
For practical purposes, it often makes sense to tie the concept of utility
directly to something measurable. In economics, a simple model is the simple
equality utility = pay-off. A more common, but unfortunately more compli-
cated, model is letting the utility be a concave function of the pay-off, as illus-
trated in Figure 14.4.
Different choices and contexts result in different utility profiles. The utility of
a lower exchange rate between the UK £ and the US $ is different for a woman
from the USA planning a trip to London and a British man planning a vacation
in Boston. We will now look at two examples with stepwise and linear utility
functions where utility = pay-off, and we will then compare the values of the
two choices.
Example 14.1.5 Frederick is buying shares in ACME Dynamics Ltd. His inves-
tigations tell him that X, the now value in one year from now, follows a Normal
distribution X ∼𝜙(47.2,4.7). What is the utility function u(x) of buying k shares if
the current price is £40.0, and what is the expected pay-off U of that purchase?
Answer: The pay-off is the sales value minus the cost. The sales value is £x per
share, whereas the cost is £40.0. For k shares, the utility function is then
u1(x) = k(x −40.0).
This is a linear function, so since 𝜇X = 47.2, the expected utility is
U1 = k(𝜇X −40.0) = k(47.2 −40.0) = 7.2k.
Example 14.1.6 Frederick considers options1 as an alternative to buying the
shares themselves. The options in this instance are our bets, and cost £10 a
1An option is an agreement about a future transaction, based on the future value of a share,
commodity, or other item. The simplest options are agreements that give the holder of the option
the right but not the duty to buy (or to sell) a given number of shares of a certain company at a
previously agreed price at a certain set time T, regardless of the actual price at time T.


14 Bayesian Hypothesis Testing
piece. In one year from now, they yield £0 if the share price X is less than or
equal to £47.5, but £25 if X > 47.5. What is the utility function u2(x) of buying
k such options, and what is the expected pay-off of buying these k options when
X ∼𝜙(47.2, 4.7)?
Answer: Pay-off equals yield minus expense. The separating value is a share
price of x = £47.5, so
u2(x) =
{
k(0 −10) = −10k
x ≤47.5
k(25 −10) = 15k
x > 47.5.
We see that
P(X ≤47.5) = Φ(47.2,4.7)(47.5) = 0.525 447
P(X > 47.5) = 1 −Φ(47.2,4.7)(47.5) = 0.474 553.
This gives the expected utility
U2 = −0.525 447 × 10k + 0.474 553 × 5k = 1.863 82k.
Example 14.1.7 Frederick ponders whether he should buy shares or options,
given that X ∼𝜙(47.2, 4.7). He has £200 to spend, so he can either buy 200
40 = 5
shares for them, or 200
10 = 20 options. The expected pay-off for buying shares
is then U1 = 7.2 × 5 = £36, whereas the pay-off of buying options is U2 =
1.863 82 × 20 = £37.276 4. This means U2 > U1, so in this case, the ratio-
nal choice is for Frederick to spend his £200 buying options rather than
shares.
.
Comparing to a Fixed Value
A common comparison is between two stepwise utility functions u0 and u1
that are split once, at the same x value. Often, u0 then corresponds to a choice
not to act, and we call this the null alternative. The study of the difference
between the two utility functions boils down to studying their difference, u(x) =
u1(x) −u0(x). That is, the difference in utility between acting on alternative 1
on the one hand, and on the other hand of “letting everything stay the same”
and accordingly not acting to change anything (alternative 0). This is called a
one sided hypothesis test.
The act of choice in a one sided hypothesis test boils down to a very simple
question: will you act on the value of a certain stochastic variable Θ being larger
or smaller than a given reference value 𝜃0? The two beliefs in themselves have
neither cost nor value, so the utility depends what actions accompany the two
choices.

14.2 Comparing to a Fixed Value

Example 14.2.1 As an illustration, let us look at Mr. K¨onigsegg, who is accused
of speeding at 140 km/h on a small road in Norway. The consequences of a
guilty and a not guilty verdict are very different, and they depend on whether
we act on the belief that his speed X was in excess of this reference speed x0 =
140 km/h, or not.
A golden rule of thumb for a fair court system is that “it is better that
10 guilty men go free than 1 innocent man be wrongly convicted”. This may be
justified from considerations of utility for society. In this instance, alternative 0
is a not guilty verdict for K¨onigsegg, whereas alternative 1 is to convict him of
speeding at past 140 km/h. The utility difference between the two alternatives
is u(x) = u1(x) −u0(x). A precise assessment of this utility is difficult, but we
will nevertheless have to choose some numbers to illustrate the method. Let x
be the speed.
r If K¨onigsegg is guilty, that is, x > 140 km/h, declaring him guilty rather than
innocent is worth 1 unit of utility.
r If K¨onigsegg is not guilty, that is, x ≤140 km/h, declaring him innocent
rather than guilty is worth 10 units of utility.
This means that
u(x) =
{ −10
x ≤140
1
x > 140.
Since U1 = E[u1(X)] and U0 = E[u0(X)], then U = E[u(X)] = U1 −U0. We
will then choose alternative 1 over alternative 0 only if U1 > U0, which is equiv-
alent to U > 0. Let X be K¨onigsegg’s speed, and p = P(X ≤140). Then
U = −10p + 1(1 −p) = 1 −11p.
This means that U > 0 when p < 1
11 ≈0.09. We should in other words not
find K¨onigsegg guilty of speeding at more than 140 km/h unless the proba-
bility that his speed was less than 140 km/h, is less than 9%. At this limit, we
ensure that the limit goes at 10 guilty going free for every innocent man found
guilty.
This kind of evaluation is known under another name, hypothesis testing,
where we boil down the procedure to its bare bones, as follows: you have a
null value 𝜃0, and are going to determine whether A: Θ < 𝜃0, or B: Θ > 𝜃0.
r If A is the case, it is wA utility units better to choose alternative A than to
choose alternative B.
r If B is the case, it is wB utility units better to choose alternative B than to
choose alternative A.


14 Bayesian Hypothesis Testing
The null alternative is the alternative with the largest w value. In hypoth-
esis testing, we call this alternative the null hypothesis, and name it H0. The
other alternative, called the alternative hypothesis, is written H1. We then find
U thus: let w0 be the largest of the two values, and w1 the smallest, and let
p = P(H0). Then
U = w1 ⋅P(H1) −w0 ⋅P(H0) = w1(1 −p) −w0p = w1 −(w0 + w1)p.
We choose H1 over H0 only if there is positive expected utility in doing so, in
other words if U > 0. That is the case only when p <
w1
w0+w1 .
Note 14.2.2 The significance of a hypothesis test is 𝛼=
w1
w0+w1 , where w0 and
w1 are as defined in the section above.
We formally define a hypothesis test in the following way.
Definition 14.2.3 A one sided hypothesis test of a stochastic variable Θ with
significance 𝛼is a test of whether Θ < 𝜃0 or Θ > 𝜃0. One alternative is speci-
fied as the null hypothesis H0, whereas the other is specified as the alternative
hypothesis H1. We then say that we test hypothesis H1, and the conclusion is
that we
r choose H1 if P(H0) < 𝛼. (“We reject the null hypothesis H0.”)
r choose H0 if P(H0) ≥𝛼. (“We do not reject the null hypothesis H0.”)
A hypothesis test is left sided if H1 is specified as Θ < 𝜃0, and right sided if
H1 is specified as Θ > 𝜃0.
The significance 𝛼is either stated directly, or we calculate it ourselves as
𝛼=
w1
w0 + w1
,
where w0 is the utility of choosing H0 over H1 if H0 actually is the case, and
w1 is the utility of choosing H1 over H0 if H1 actually is the case.
It is worth noting the following.
r Θ is usually a parameter, and its probability distribution is usually a posterior
probability distribution after some measurements, like the ones we find in
Chapters 12 and 13.
r The significance value 𝛼often follows a customary rule of thumb within the
area of application, rather than being explicitly calculated from precise utility
considerations of the problem at hand. Typical customary values for 𝛼are 0.1,
0.05, and 0.01.

14.2 Comparing to a Fixed Value

r H1 is often an alternative to the ruling consensus, and if assumed true would
require a change in current practice. Conversely, H0 often equals the consen-
sus. Hence the name the conservative hypothesis.
r H1 is often the alternative we desire to be true, but that requires costly action.
Example 14.2.4 (Purely numerical example) 𝜃∼t(12,3,5). Test the alternative
hypothesis 𝜃> 7 with significance value 𝛼= 0.075.
Answer: H1 is that 𝜃> 7, so then the null hypothesis is H0: 𝜃≤𝜃0 = 7. The
calculation then gives us that P(H0) = P(𝜃≤7) = T(12,3,5)(7) = 0.078 > 𝛼. So
we choose H0. Or in other words: we don’t reject H0 in favor of H1.
Example 14.2.5
Hypothesis test and action: The Norwegian pharmaceu-
tical Lyvjaberg AS are testing out their blood pressure reducing medicine
Odrøre. How much blood pressure is lowered after one month’s use of the
medicine will follow a Normal distribution 𝜙(𝜇,𝜎), and they want to estimate
𝜇. More specifically, they wish to see if they beat the best of their competition,
whose medicine results in a reduction of blood pressure of 31 mmHg after one
month’s use.
The alternative hypothesis H1 is that 𝜇> h0 = 31, in other words that Odrøre
on average is better than its competitors’ products. H0 is then that 𝜇≤31,
which is to say that Odrøre is not better on average, but worse than (or at best:
equally good as) the others.
From previous market experience, Lyvjaberg thinks that the cost w0 of start-
ing production if Odrøre turns out not to be better than the competition after
all, when it is tried out on a grand scale, is roughly 20 times larger than the loss
w1 of not starting production if Odrøre happened to actually be the best prod-
uct. The test significance is then 𝛼=
1
20+1 ≈0.05. The choice of rounding off
to 0.05 is motivated both by this being a round number close enough to
w1
w0+w1 ,
and that 0.05 is acknowledged as a decent and easily recognizable significance
value.
Lyvjaberg has reviewed the change of blood pressure of 25 volunteers after a
month of trying out their medicine. For objectivity’s sake, they have chosen a
neutral prior, and their posterior probability distribution for 𝜇is then t(39, 3.9,24).
The hypothesis test then consists of the following calculation:
P(H0) = P(𝜇≤31) = T(39, 3.9, 24)(31) ≈0.026 < 0.05 = 𝛼.
Given this result, Lyvjaberg rejects the null hypothesis H0. Or in our words:
they choose alternative H1, and act on that. That is, they are now sufficiently
convinced that Odrøre is better than the competing products, and they start
production.


14 Bayesian Hypothesis Testing
..
Hypothesis Testing for Gaussian Processes
For a Gaussian process, we perform inference on the parameters 𝜇and 𝜎, and
on the next observation X+. In practice, this means calculating on 𝛾, 𝜙, and
t distributions.
Example 14.2.6
You have been asked officially to certify the plums of a
fruit farmer from Hardanger. More specifically, you will assess whether his
Mallard plums may be sold under the protected label Hardanger plums. The
size requirement is that the diameter be at least 40 mm. You assume that the
weight follows a Normal distribution 𝜙(𝜇,𝜎). The key variable to assess here is
neither of the parameters 𝜇and 𝜎, but rather the size of the next plum, X+.
However, since you are at it, you decide to test the parameters 𝜇and 𝜎as well.
You perform the hypothesis test with significance 𝛼= 0.05, and ask yourself
three questions. The first two for comments and tips to the farmer, and the last
one for the certification itself.
1) Is the mean diameter 𝜇more than 45 mm? (H𝜇
0 : 𝜇≤45.)
2) Is the standard deviation 𝜎less than 5 mm? (H𝜎
0 : 𝜎≥5.)
3) Does a randomly sampled plum have a diameter in excess of 40 mm? (H+
0 :
X+ ≤40.)
Since this is an official certification, you should use a neutral prior, mean-
ing 𝜅0 = Σ0 = n0 = SS0 = 0. You measure the diameters of 30 randomly picked
plums, and derive the statistics n = 30, Σx = 1445.22, and SSx = 401.179.
From the statistics, you get the distributions 𝜏∼𝛾(14.5, 200.59)(t) and 𝜇∼
t(48.174, 0.679 062, 29)(x), whereas X+ ∼t(48.174, 3.780 86, 29)(x). Then
1) P(H𝜇
0 ) = T(48.174, 0.679 062, 29)(45) = 0.000 031 < 𝛼;
2) P(H𝜎
0 ) = P(𝜎≥5) = P(𝜏≤0.04) = Γ(14.5, 200.59)(0.04) = 0.025 0 < 𝛼;
3) P(H+
0 ) = T(48.174, 3.78086, 29)(40) = 0.0195 < 𝛼.
You therefore reject all three null hypotheses, and choose H1. You tell the
farmer that his plums will overall be within the required values, but that he
may expect one in fifty plums to be a bit too far on the small side.
..
Hypothesis Testing for Bernoulli Processes
With Bernoulli processes, we test the parameter p. Using the methods of Sec-
tion 13.2, the posterior probabilities we obtain for p become 𝛽distributions. So
in this section, we do calculations on 𝛽distributions.
Example 14.2.7 Arboreal scientist Bryn believes that maple leaves have a ten-
dency to land underside up rather than sunnyside up, but decides that this is

14.2 Comparing to a Fixed Value

worthy of an empirical investigation. Let 𝜋be the proportion of maple leaves
landing with the underside up. Bryn’s null hypothesis H0 is that 𝜋≤0.5, while
the alternative hypothesis is that H1: 𝜋> 0.5. Bryn starts with a flat prior, 𝛽(1,1),
Bayes’ prior for informed ignorance for Bernoulli processes. Bryn decides to test
with significance 𝛼= 0.06. He looks at 50 leaves on the ground, and find that
31 lie underside up, whereas the remaining 19 lie sunnyside up. Bryn’s posterior
distribution is then 𝜋∼𝛽(32,20). That means
P(H0) = I(32,20)(0.5) = ∫
0.5
0
𝛽(32,20)(x) dx = 0.046 < 0.06.
Since P(H0) < 𝛼, Bryn rejects the null hypothesis in favor of the alternative
hypothesis, and may from now on confidently state that maple leaves land more
frequently underside up than sunnyside up.
..
Hypothesis Testing for Poisson Processes
For a Poisson process, we test the parameter 𝜆. Using the methods of Sec-
tion 13.3, the posterior probabilities we obtain for 𝜆become 𝛾distributions.
So in this section, we do calculations on 𝛾distributions.
Example 14.2.8
The consultancy Aleatica are analysing a call center for
Ratatosk Marketing Ltd. They work from the standard assumption that the
incoming calls are a Poisson process, and set out to find the rate parameter
𝜆. Specifically, they want to test if 𝜆, the rate of incoming calls per minute, is
more than 0.2. In the language of statistics, their alternative hypothesis H1 is
that 𝜆> 0.2. If they reject H0 and accept H1, they will recommend restructur-
ing. Restructuring is costly, so they choose a significance value of 𝛼= 0.1 for
the test. Their custom is to use a neutral prior (𝜅0 = 𝜏0 = 0), and the observa-
tional time span is two hours. They note 28 incoming calls during that time,
which means their statistics are n = 28 and t = 120 (minutes). Then
P1 ⊧𝜅1 = 𝜅0 + n = 0 + 28 = 28
𝜏1 = 𝜏0 + t = 0 + 120 = 120,
so 𝜆∼𝛾(28, 120). This means
P(H0) = P(𝜆≤0.2) = Γ(28, 120)(0.2) = 0.232 258 > 0.1 = 𝛼.
As a result of this, Aleatica does not reject H0, and therefore do not recom-
mend that Ratatosk restructure their business.


14 Bayesian Hypothesis Testing
.
Pairwise Comparison
In the previous section, we looked at comparison of a stochastic variable against
a fixed magnitude. But we are more often interested in comparing two stochas-
tic variables against each other – usually comparing two parameters 𝜃1 and 𝜃2.
In the previous section, we grouped this study by process. Here, we will group
by probability distribution.
..
Normal and t Distributed Variables
We have at hand two unknown Normal distributions 𝜙(𝜇x,𝜎x) and 𝜙(𝜇y,𝜎y), and
are going to decide which is the largest: 𝜇x, or 𝜇y. How we calculate this depends
on the degree and type of dependence between the two magnitudes. The two
simplest cases to handle are as follows.
r The values come pairwise, {(xi, yi)}. We may then often assume that the differ-
ences zi = xi −yi follow a Normal distribution, 𝜙(𝜇z,𝜎z), where 𝜇z = 𝜇x −𝜇y.
The case then reduces to hypothesis testing the single variable 𝜇z, using {zi}
as data, so we return to Section 14.2.1, and notice that testing 𝜇x < 𝜇y reduces
to testing if 𝜇z < 0. Similarly for testing 𝜇x > 𝜇y.
An example of such a study would be if y were husband height and x were
wife height, and you wanted to assess the question of whether husbands can be
said to be taller than their wives.
r The posterior probability distributions for 𝜇x and 𝜇y are independent. This
typically comes about when the sampled values and the priors are indepen-
dent, and is thus a reasonable assumption when the inferences for 𝜇x and
𝜇y have been performed independently. Whereas for the pairwise collected
data we reduced the two variables to one a priori, we will for the indepen-
dent variables perform that reduction a posteriori. In other words, we will
take the posterior probability distributions of 𝜇x and 𝜇y and use the formulas
of Rules 10.1.10 and 10.4.4 to find a new stochastic variable 𝜃= 𝜇x −𝜇y. To
test whether 𝜇x < 𝜇y, we then simply test whether 𝜃> 0. Similarly for testing
𝜇x > 𝜇y.
Example 14.3.1 A Finnish forester wants to test where the pines grow best,
and has made a test planting of 17 trees at “Plot A”, and 23 trees at “Plot B”.
One year later, he measures how much taller the trees have grown, and brings
his data to a statistician in Helsinki. The forester says he has the most faith in
plot B, but that it will be costly to move his main production there, and away
from A. The statistician considers the costs, and says he will test the alternative
hypothesis 𝜇B > 𝜇A with significance 𝛼= 0.1. The statistician calculates, and

14.3 Pairwise Comparison

using neutral priors, he gets that 𝜇A ∼t(48.1, 4.3, 16), whereas 𝜇B ∼t(51.7, 4.1, 22).
He then uses Rule 10.4.4 to derive the probability distribution of 𝜃= 𝜇A −𝜇B:
1) 48.1 −51.7 = −3.6;
2)
√
4.12 + 4.32 = 5.941 38;
3)
⎢
⎢
⎢
⎢
⎢
⎢⎣
(
4.32
16+1 + 4.12
22+1
)2
( ( 4.32
16+1
)2
16
+
( 4.12
22+1
)2
22
)
⎥
⎥
⎥
⎥
⎥
⎥⎦
= 33,
so 𝜃∼t(−3.6, 5.941 38, 33). The alternative hypothesis H1 is then that 𝜃< 0,
whereas the conservative hypothesis is H0: 𝜃≥0. We calculate
P(H0) = P(𝜃≥0) = 1 −T(−3.6, 5.941 38, 33)(0) = 0.274 357 > 0.1 = 𝛼.
The statistician therefore tells the forester that he should continue using A as
his main plot, rather than plot B.
..
𝜸Distributed Variables
This section concerns parameters 𝜏for Gaussian processes, and parameters 𝜆
for Poisson processes. Their posterior probability distributions are 𝛾distribu-
tions. If A and B are 𝛾distributed, then A −B does not have any nice distribu-
tion, so we can’t solve the problem by comparing two 𝛾distributed by subtrac-
tion, the way we did in Section 14.3.1.
But another fundamental arithmetic operation saves the day: division. Rule
A.3.1 lets us study Q = A∕B, and through that finding the probability that A <
c × B. Indeed, if A ∼𝛾(kA,lA)(t) and B ∼𝛾(kB,lB)(t), then
P(A < c × B) = P
(A
B < c
)
= F(2kA,2kB)
(
c × kBlA
kAlB
)
.
On our favorite calculating tools, this is
r Mathematica: CDF
[
FRatioDistribution[2kA, 2kB], c × kBlA
kAlB
]
r CASIO: FCD
(
0, c × kBlA
kAlB , 2kA, 2kB
)
r TI: Fcdf
(
0, c × kBlA
kAlB , 2kA, 2kB
)
r HP: fisher_cdf
(
2kA, 2kB, c × kBlA
kAlB
)
.
Example 14.3.2 The consultancy Aleatica are helping a call center; they are
going to determine if Group B has an incoming call rate so much higher than


14 Bayesian Hypothesis Testing
that of Group A that the call center should reorganize. The alternative hypoth-
esis (implying reorganization) is then H1: 𝜆B > 𝜆A, and cost considerations give
them a significance value of 𝛼= 0.2.
r Group A gets 48 incoming calls during a two-hour span, and, following
the calculations in Example 14.2.8, we get the posterior distribution 𝜆A ∼
𝛾(48,120).
r Group B gets 78 incoming calls during a three-hour span, which results in
the posterior distribution 𝜆B ∼𝛾(78,180).
We then calculate
P(H0) = P(𝜆A ≥𝜆B) = P(𝜆B ≤𝜆A)
= F(2⋅78,2⋅48)
(48 ⋅180
78 ⋅120 ⋅1
)
= F(156,96)
(12
13
)
= 0.325 872 > 0.2 = 𝛼.
Aleatica does therefore not reject H0, and therefore does not recommend
restructuring.
You perform the calculation in our example tools as follows:
r Mathematica: CDF
[
FRatioDistribution[156, 96], 12
13
]
r CASIO: FCD
(
0, 12
13, 156, 96
)
r TI: Fcdf
(
0, 12
13, 156, 96
)
r HP: fisher_cdf
(
156, 96, 12
13
)
.
This test may not only tell us the probability of A being larger than B, but will
also find the probability that A is larger than a certain multiple of B, as in the
following example.
Example 14.3.3 As in Example 14.3.2, Aleatica is helping a call center evaluate
whether they should reorganize. However, at this call center, Group B is 1.5
times larger than Group A. Aleatica here recommends reorganizing only if B’s
incoming call rate 𝜆B is at least twice as large as A’s rate 𝜆A. Their alternative
hypothesis H1 is therefore 𝜆B > 2𝜆A. Calculating costs leads them to conclude
a significance of 𝛼= 0.05. the posterior distributions of the rate parameters are
r 𝜆A ∼𝛾(97, 90)
r 𝜆B ∼𝛾(241, 90).

14.3 Pairwise Comparison

Then
P(H0) = P(𝜆B ≤2𝜆A)
= F(2⋅kB, 2⋅kA)
(
2 ⋅kA ⋅lB
kB ⋅lA
)
= F(2⋅241, 2⋅97)
(
2 ⋅97 ⋅90
241 ⋅90
)
= 0.032 414 5 < 0.05 = 𝛼.
This means that Aleatica recommends that the call center should act on H1
being true, and therefore reorganize.
..
𝜷Distributed Variables
This section concerns parameters p and 𝜋for Bernoulli processes. Their pos-
terior probability distributions are 𝛽distributions. For the Gaussian variables
in Section 14.3.1, we could compare two variables by subtraction, calculating
probabilities for the difference. For the 𝛾distributed variables in Section 14.3.2,
we could compare two variables by division, calculating probabilities for the
ratio. For 𝛽distributed variables, we have no such solution, but we neverthe-
less do have a means – a formula – for comparing the probability of one 𝛽dis-
tributed variable being greater than the other. The formula for comparing 𝛽
distributions is stated in Rule A.3.3.
Example 14.3.4
Zen abbot S¯ozen and protestant priest Skippervold both
enjoy quirky European football statistics. S¯ozen says fotball is a matter of heart,
and roots for the Edinburgh team Heart of Midlothian. Skippervold, on the
other hand, thinks a team named after the mother of Jesus is a better choice,
and roots for the team Motherwell from the city of the same name. They know
they will never agree which team is best, so they compete by means of idiosyn-
cratic statistical comparisons. The usual routine is that one of them makes a
statement about some statistic he thinks favors his own team, and then they
investigate the alternative hypothesis that it indeed does favor the proponents
team, with significance 𝛼= 0.2.
Today, it’s S¯ozen’s turn. He claims that Hearts’s U20 youth team have a higher
percentage of left-foot shots at the goal than does Motherwell’s U20 team.
S¯ozen in addition claims that left-foot scorings indicate something positive
about the culture and tolerance in a football team.
For their empirical investigation, the two friends have chosen to watch the
game between two youth teams in the FA Youth Cup finals in 2016. In this
game, there were a total of 41 shots at the goals, of which 19 were by Hearts,
and 22 by Motherwell. Hearts’s players shot 12 times at Motherwell’s goal with


14 Bayesian Hypothesis Testing
Figure .S¯ozen observes, calculates posterior distributions, and concludes.
their right foot, and 7 times with their left, whereas Motherwell’s players shot
14 shots at Hearts’s goal with their right, and 8 with their left.
We were going to look at the long-term proportion of left-foot goal shots for
the two teams. Let this proportion be pH for the Hearts youth, and let it be pM
for Motherwell. In the inference, use Novick and Hall’s neutral prior for both.
That gives us the posterior probability distributions for these two parameters
pH = 𝛽(7,12)
pM = 𝛽(8,14).
The alternative hypothesis H1 is that pH > pM, which means H0: pH ≤pM.
Then, what remains is to find P(H0). We will do an exact calculation for both,
and do them with a Normal approximation using the formulas of Section A.3.4.
Exact first:
P(H0) = P(pH ≤pM) = p(pM > pH)
=
8−1
∑
k=0
Γ(7 + k)Γ(12 + 14)Γ(k + 14 + 1)Γ(7 + 12)
(14 + k)Γ(7)Γ(12)Γ(14)Γ(k + 1)Γ(7 + 12 + k + 14)
= 0.488 756 > 0.2 = 𝛼.
We see with S¯ozen in Figure 14.5 that we can’t reject H0. This means S¯ozen
has no support for his claim that the Hearts youth use their left foot more than
the kids from Motherwell when shooting a goal.
We may also calculate via the Normal approximation: 𝛿= pH −pM. Then,
P(H0) = P(pH < pM) = P(𝛿< 0)
= Φ(
7
7+12 −
8
8+14 ,
√
7⋅12
(7+12)2(7+12+1) +
8⋅14
(8+14)2(8+14+1)
)(0)
= 0.487 043 > 0.2 = 𝛼.
In this case, the Normal approximation was sufficiently close to the exact
calculation that the two yielded the same result. We don’t reject H0.

14.4 Exercises

.
Exercises
Utility Functions
1
In the problems below, you are given the probability distribution of
a stochastic variable X and a utility function u(x). Find the expected
utility U.
(a) X ∼𝛽(17,9) and u(x) = 3x + 2;
(b) X ∼𝛾(7,21) and u(x) =
{
9
x < 0.3
−4
x > 0.3;
(c) X ∼𝜙(5.3,1.9) and u(x) =
⎧
⎪
⎨
⎪⎩
−1
x < 3
1.5
3 < x < 6
4
x > 6;
(d) X ∼t(10,5,2) and u(x) =
{
−1
x < 15
7
x > 15;
(e) X ∼𝜙(41.3,9.1) and u(x) = −2x + 90;
(f) X ∼t(−2.73,1.21,8) and u(x) = −5x + 8.
2
You are going to decide whether A: Θ < 𝜃0 or B: Θ > 𝜃0. The gain in utility
of choosing A instead of B is
u(x) =
{
wA
x < 𝜃0
−wB
x > 𝜃0.
In the first three subproblems below, you are given 𝜃0, wA, and wB. For-
mulate the decision problem as a hypothesis test by indicating significance
level 𝛼and stating the alternative hypothesis H1.
(a) 𝜃0 = 7, wA = 9, wB = 1;
(b) 𝜃0 = −3, wA = 25, wB = 175;
(c) 𝜃0 = 100, wA = 1, wB = 100.
(d) A pharmaceutical company has developed a medicine that changes
certain blood values. They have two choices: to produce, or not to pro-
duce. If the mean change in that blood value is more than 17, they earn
1 unit more by producing than by not producing. If the change is below
17, they save 19 units by not producing. Convert this into statements
about A, B, and 𝜃0, and proceed as in the other subproblems.
Hypothesis Test for Gaussian Processes
3
You are given the posterior distribution 𝜃∼f (x), the significance 𝛼,
and alternative hypothesis H1. Test, and decide between the competing
hypotheses.
(a) 𝜃∼𝜙(7,2), 𝛼= 0.05, and H1: 𝜃> 3.
(b) 𝜃∼𝜙(9,2), 𝛼= 0.05, and H1: 𝜃> 7.


14 Bayesian Hypothesis Testing
(c) 𝜃∼𝜙(8,3), 𝛼= 0.006, and H1: 𝜃< 16.
(d) 𝜃∼t(7,2,3), 𝛼= 0.05, and H1: 𝜃> 3.
(e) 𝜃∼t(9,2,5), 𝛼= 0.05, and H1: 𝜃> 4.
(f) 𝜃∼t(24,3,1), 𝛼= 0.075, and H1: 𝜃< 16.
4
You have a job controlling how well pubs fill pint servings. More precisely,
you sample to evaluate if the mean servings 𝜇are at least 1.0 pint. For your
job, you use a neutral prior. At one particular pub one evening, you have
sampled 10 pints, and measured: {0.98, 0.98, 0.96, 1.02, 0.98, 1.0, 1.02, 0.96,
0.96, 0.98}. Using these data, determine whether H1: 𝜇< 1.0, with signifi-
cance 𝛼= 0.1.
5
Capacitors: Measuring 25 of FR Electronics’s smallest capacitors, you
got ̄c = 49.19 μF and sample standard deviation sc = 2.15 μF. Assume the
capacitances follow a Normal distribution 𝜙(𝜇,𝜎), and determine, with sig-
nificance 𝛼= 0.02 and neutral prior, the alternative hypothesis that the
mean 𝜇is less than 50 μF.
Hypothesis Test for Bernoulli Processes
6
You are given a (posterior) distribution for 𝜋∼𝛽(a,b), a significance 𝛼, and
H1. Test the following competing hypotheses, to decide between them,
both by direct calculation and by Normal approximation.
(a) Posterior: 𝜋∼𝛽(35,24), 𝛼= 0.1, and H1: 𝜋> 0.5.
(b) Posterior: 𝜋∼𝛽(78,21), 𝛼= 0.05, and H1: 𝜋< 0.85.
(c) Prior: 𝜋∼𝛽(1,1). Observations: 22 positive outcomes and 51 negative.
𝛼= 0.02, and H1: 𝜋> 0.2.
7
You are estimating 𝜋, the proportion who prefer MegaCola to its competi-
tors, and your posterior hyperparameters for 𝜋are a1 = 41.5 and b1 = 9.5.
If the proportion who prefer MegaCola is more than 75%, MegaCola will
launch a costly campaign. A consideration of the utilities on both sides
results in your having to decide whether 𝜋> 0.75 with significance 𝛼= 0.1.
What will be your recommendation to MegaCola?
8
Your are estimating 𝜋, the proportion of “Fancy diamonds” of quality IF
and VVS, in a diamond mining project where they are considering buy-
ing new and expensive mining equipment if this proportion exceeds 0.1.
Owing to the high costs, they will be determining whether H1: 𝜋> 0.1
with significance 𝛼= 0.1. For your report, you use Jeffreys’ prior (u = 0.5).
After examining 172 rocks, you have found 19 that are either IF or VVS,
whereas the rest are of lower grade. What will be your recommendation
for the mining project?

14.4 Exercises

Hypothesis Test for Poisson Processes
9
You are given a probability distribution for 𝜏∼𝛾(k,𝜆), a significance 𝛼, and
H1. Determine the hypothesis test, both by direct calculation and by using
the Normal approximation.
(a) Posterior: 𝜏∼𝛾(6, 3), 𝛼= 0.04, and H1: 𝜏< 4.
(b) Posterior: 𝜏∼𝛾(10, 29.7), 𝛼= 0.05, and H1: 𝜏> 0.2.
(c) Posterior: 𝜏∼𝛾(17.5, 53.4), 𝛼= 0.1, and H1: 𝜏> 0.5.
(d) Posterior: 𝜏∼𝛾(20∕3,
√
32), 𝛼= 0.001, and H1: 𝜏< 3.2.
10
(t = time) The number of plumbing gaskets that need changing every week
in an apartment complex is assumed to follow a Poisson process with rate
𝜆. You are estimating this need for an apartment complex with 70 flats, and
have looked into the documentation for the last semester (26 weeks), and
find registered 53 gasket changes. For your hypothesis test, use a neutral
prior, and let hypothesis H1 for the rate be that 𝜆> 1.5. Decide between
H0 and H1 with significance 𝛼= 0.06.
11
(t = volume in cubic centimeters) The number of bacterial colonies per
cubic centimeter in a certain polluted lake is assumed to be Poisson dis-
tributed with parameter 𝜆. You sample 1 deciliter, and find 157 bacterial
colonies. Use neutral prior, and test the alternative hypothesis H1: 𝜆< 1.75
with significance 𝛼= 0.04.
Pairwise Comparison for Gaussian Processes
12
The brothers Odd and Kjell Aukrust lie home in bed with whooping cough,
and as Kjell rattles off a particularly long-lasting cough, Odd exclaims: That
one lasted for rather a long time, but not as long as mine do! Kjell disagrees,
so they decide to measure coughing times (in seconds):
r Odd: 22, 20, 21, 20, 21, 21, 19, 21
r Kjell: 15, 12, 32, 12, 11, 13, 14.
The budding statistician Odd assumes the lengths of the coughing
bouts follow Normal distributions, respectively 𝜙(𝜇K,𝜎K) (Kjell) and 𝜙(𝜇O,𝜎O)
(Odd). He would like to establish with significance 𝛼= 0.2 that his own
bouts of coughing last longer than Kjell’s, in other words he wants to test
H1: 𝜇O > 𝜇K. But Odd is ill today, so he leaves it up to us to do the work.
We use neutral priors.
13
Nicholas believes that the tomcat Baggins purrs for longer than the female
cat Perry, but Caroline, who is a student keenly interested in statistics, asks
him to back up his claim by hypothesis testing it with significance 𝛼= 0.1.


14 Bayesian Hypothesis Testing
Nicholas then times how long each cat purrs after one single stroke, and
gets the following purring durations (in seconds):
r Baggins: 59, 71, 102, 64, 56, 83
r Perry: 48, 43, 51, 48, 54.
Assume that the purring durations follow Normal distributions, with
respective mean values 𝜇B for Baggins and 𝜇P for Perry. Use neutral pri-
ors and assume 𝜎unknown. Which side has the burden of proof here? To
answer this, establish which hypothesis is H0 and which is H1, and decide
between the two competing hypotheses.
Pairwise Comparison for Poisson Processes
14
Your are comparing two 𝛾distributed variables Θ ∼𝛾(k,l) and Ψ ∼𝛾(m,n) to
decide between hypotheses H1 (as specified below) and H0, with signifi-
cance 𝛼.
(a) Θ ∼𝛾(7, 70), and Ψ ∼𝛾(4, 80). Significance 𝛼= 0.05, and H1: Θ > Ψ.
(b) Θ ∼𝛾(9, 20), and Ψ ∼𝛾(11, 20). Significance 𝛼= 0.1, and H1: Θ < Ψ.
(c) Let the parameters in the Problem 14.b be 10 times as large. This
corresponds to 10 times as many observations of each kind as in the
previous problem. Do you think there should be a difference? Think
about it for a while, and then calculate to see whether it matters
or not!
15
(t = units = hunters) You have been told that 23 grouse hunters from a
certain part of the Lowlands had a total catch of 111 grouse in a single day,
and concluded that the catch rate there was 𝜆Lowlands ∼𝛾(111, 23). You have
now spoken to 8 hunters from the Highlands, and their catch on the same
day was 65 grouse. Use a neutral prior and find the posterior probability
distribution for 𝜆Highlands. Then decide, with significance 𝛼= 0.1, whether
H1: 𝜆Highlands > 𝜆Lowlands.
Pairwise Comparison for Bernoulli Processes
16
You are comparing two 𝛽distributed variables 𝜓∼𝛽(k,l) and 𝜋∼𝛽(m,n) to
determine the hypothesis H1 (which is either 𝜓> 𝜋, or 𝜓< 𝜋) with signif-
icance 𝛼. Do this both by exact calculation using Rule A.3.3, and by Normal
approximation. (The exact calculation requires good calculation tools.)
(a) 𝜓∼𝛽(2,5) and 𝜋∼𝛽(4,3), 𝛼= 0.1, H1: 𝜓< 𝜋.
(b) 𝜓∼𝛽(23,17) and 𝜋∼𝛽(17,23), 𝛼= 0.1, H1: 𝜓> 𝜋.
(c) 𝜓∼𝛽(20,20) and 𝜋∼𝛽(17,23), 𝛼= 0.05, H1: 𝜓> 𝜋.
(d) Let the parameters of the Problem 16.c be 10 times as large. This cor-
responds to ten times as many positive observations and ten times as

14.4 Exercises

many negative observations. Do you think there should be a difference?
Think about it for a while, and then calculate to see whether it matters
or not!
17
Your company has for a long time used Imperial Deliveries for freight.
Lately, however, a promising new competitor has surfaced: Centurium
Falcon Freight. You decide to test the rate of delivery errors to compare the
two. Let 𝜋ID be the proportion of erroneous deliveries at Imperial Deliver-
ies, and let 𝜋CFF be the rate for Centurium Falcon Freight.
Your internal routines are built around delivery by Imperial Deliveries,
making a change of freight company cost a bit. However, at the same time
there is a fair bit to save if the new alternative is an improvement. A cost
analysis using utility functions indicates that you should test the hypothesis
H1: 𝜋CFF < 𝜋ID with significance 𝛼= 0.15.
You run 200 trial deliveries with both companies. Imperial Deliveries
make four delivery errors, whereas Centurium Falcon Freight make one
error. Investigate, with prior 𝛽(1,1), and decide between the competing
hypotheses.




Estimates
CONTENTS
15.1 Introduction, 351
15.2 Point Estimates, 351
15.3 Interval Estimates, 352
15.4 Estimates for the 𝜙Distribution, 355
15.5 Estimates for the t Distribution, 357
15.6 Estimates for 𝛾Distributions, 359
15.7 Estimates for 𝛽Distributions, 362
15.8 Exercises, 365
.
Introduction
We are going to estimate an unknown parameter 𝜃from a model from some
observations. A point estimate of a parameter 𝜃is a single value that is thought
to be the best representative of our knowledge about 𝜃.
The interval estimate for a parameter is the tolerant relative of the point esti-
mate, in that it gives a certain slack and indicates an entire interval of possible
values. The interval estimates are stated in terms of their sizes: if the size is
in terms of probability, we speak of a P% credible interval, and if the size is in
terms of the interval width, we speak of an HPD interval of width l. (HPD means
Highest Posterior Density.)
We have interval estimates for the next observation X+ as well, and these are
the (posterior) predictive intervals.
.
Point Estimates
A point estimate for a parameter 𝜃is a summary of our knowledge about the
parameter in a single number ̂𝜃, which is our best guess at the value of 𝜃. In the
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


15 Estimates
0
1
Ε[θ]
θMAP
θ
∼
(a) β distribution.
0 1
10
Ε[θ]
θMAP θ
∼
(b) γ distribution.
Figure .Unequal point estimates.
Bayesian school, we find the point estimates from the probability distribution
for the parameter, f (x). The three most important point estimates are
r MAP, the Maximum A Posteriori estimate 𝜃MAP, is simply the max value of
the probability distribution (also known as its mode);
r The median ̃𝜃;
r The expected value 𝜇𝜃= E[𝜃].
These three are “best guesses”, each in its own way: 𝜃MAP is the maximum
value of the probability distribution, ̃𝜃minimizes l(t) = E[|𝜃−t|], whereas
𝜇𝜃= E[𝜃] minimizes k(t) = E[(𝜃−t)2].
For symmetrical distributions, like the Normal and t distributions, all three
point estimates coincide, whereas for the 𝛽and 𝛾distributions, we usually have
either E[𝜃] ≥̃𝜃≥𝜃MAP, or 𝜃MAP ≥̃𝜃≥E[𝜃], as illustrated in Figure 15.1.
Rule 15.2.1 The three point estimates for 𝜙, t, 𝛽, and 𝛾distributions are:
Distribution
MAP
Median
Expected value
𝜙(𝜇,𝜎)
𝜇
𝜇
𝜇
t(𝜇,𝜎,𝜈)
𝜇
𝜇
𝜇
𝛽(a,b)
a−1
a+b−2
I−1
(a,b)(0.5)
a
a+b
𝛾(k,𝜆)
k−1
𝜆
Γ−1
(k,𝜆)(0.5)
k
𝜆
.
Interval Estimates
Definition 15.3.1 A P% interval estimate for a stochastic variable Θ is an
interval (a, b) where P(a < Θ < b) = P%.
r A P% interval estimate for a parameter 𝜃is called a credible interval. We
will denote this by an upper index 𝜃, that is, I𝜃.
r A P% interval estimate for the next observation, X+, is called a predictive
interval. We will denote this by an upper index +, that is, I+.

15.3 Interval Estimates

The point of interval estimates is to indicate a range of values for a variable
Θ so that the reader may feel confident that there is a P% probability that Θ
is within this range. Which range, and thereby which interval limits serve that
purpose best, depends on the application. One-sided limits and intervals are
best when only one of the directions is critical to hedge against. For instance:
you are more interested in knowing that there is a 99% probability that your
Christmas present from grandma in Australia will arrive before the December
22nd than in knowing that there is a 99% probability that it will arrive after the
December 15th. Or the other way round: you are told you may get a reward,
and might be more interested in knowing that there is a 90% probability that
your reward will be in excess of a thousand dollars than that there is a 90%
probability that your reward will be less than two thousand dollars.
But the one-sided intervals are not the most frequently used ones. The most
used are the “symmetric” or “two-sided with equal tails”. A symmetric inter-
val I2𝛼= (a, b) for Θ is characterized by the fact that P(Θ < a) = P(Θ > b) = 𝛼,
which means that the probability of each “tail” is 𝛼. These interval estimates
limit the range of possible values in both directions, which makes sense for most
applications: it is not sufficient to know that a hammer, an electronic compo-
nent, or a shoe are larger than some given magnitude. Neither is it sufficient that
they are smaller than such a magnitude. Like Goldilocks, we want our numbers
limited in both directions, and find a range where they are just right.
Let F be a cumulative probability density. Then the three most common inter-
val estimates, with their lower indexes, are as follows.
1) Left-sided (1 −𝛼)100% interval: I𝛼,l = (F−1(0), F−1(1 −𝛼)).
2) Symmetric
(1 −2𝛼)100%
interval
with
equal
tails:
I2𝛼= (F−1(𝛼),
F−1(1 −𝛼)).
3) Right-sided (1 −𝛼)100% interval: I𝛼,r = (F−1(𝛼), F−1(1)).
Notice how the limits of I2𝛼coincide with the limits of I𝛼,l and I𝛼,r. If we find
I2𝛼, we have the one-sided intervals for free. We illustrate L0.1, I0.2, and R0.1 for
our four most used probability distributions in Figure 15.2.
The one-sided intervals are specified either by only an upper limit, or by only
a lower limit. The two-sided intervals are specified by both limits, implicitly
giving us the two one-sided intervals. So after the first example, we will stick
with two-sided intervals only.
..
HPD Intervals
We have a fourth kind of interval estimate that we call HPD (Highest Posterior
Density) intervals. This is also a two-sided interval. For a given probability P%
the HPD interval H is the narrowest possible interval where P(Θ ∈H) = P%.


15 Estimates
Normal
distribution
t distribution
γ distribution
β distribution
L0.1
I0.2
R0.1
Figure .One- and two-sided intervals given by probability P% compared.
This also means that among intervals of width l, H is the interval with the high-
est probability of containing Θ. Note, as illustrated in Figure 15.3, that the prob-
ability density is the same at both endpoints of an HPD interval.
For symmetric distributions like 𝜙and t, the HPD intervals are identical to
the symmetric intervals. For other distributions, like the 𝛾and 𝛽distributions,
they differ, and there, the HPD intervals are most easily found from the width
l, rather than from the probability P%. We therefore find it expedient to write
the HPD intervals for Θ of width l as HΘ
l .
If H𝜏is an HPD interval for 𝜏, then the interval of the corresponding values
for 𝜎is not an HPD interval for 𝜎. This is as opposed to the (1 −2𝛼)100% sym-
metric interval for 𝜏, where the interval of the corresponding values of 𝜎is a
(1 −2𝛼)100% symmetric interval as well.
Normal
distribution
t distribution
γ distribution
β distribution
Hl
Figure .HPD intervals.

15.4 Estimates for the 𝜙Distribution

..
Estimating Sample Size
When you are testing the quality of cars in commercial production, the cost of a
single measurement may very well be an entire car, as in a crash test. At the same
time, achieving accurate results from the tests carry very high utility for both
the manufacturer and the customer. The same applies to medical research. In
medical trials, the test subjects face a potential hazard to their health – and
in the worst case, maybe life. At the same time, accurate test results save lives.
In both of these cases, we need to balance the cost of testing against the utility
of the results.
We may explore the full blooded version of the balance between the utility
of the result and the cost of the testing if we have a utility function weighing
the utility of the width of the interval against the cost of further observation.
This approach belongs to advanced studies, but such advanced statistics studies
should be undertaken if you want to plan very expensive test regimes.
In this book, we will keep to the basics, and employ formulas that start with
either a desired interval width l, or a fixed probability 1 −2𝛼that Θ is in the
interval. Where possible, we will find the number of observations n required for
the interval to have probability (1 −2𝛼)100% or width l (or narrower). Where
this is not obtainable, our formulas will give a statistically best guess of the
n required for the interval to have (roughly) width l, or probability 1 −2𝛼of
containing Θ.
.
Estimates for the 𝝓Distribution
Problem: We have a Gaussian process with observables Xk ∼𝜙(𝜇,𝜎). The
parameter 𝜇itself is unknown, whereas 𝜎= s0 is known. Using the methods
of Section 13.1.1, we find the posterior distribution of 𝜇and the predictive dis-
tribution of X+. Both follow Normal distributions. We then find estimates for
𝜇and X+.
Example 15.4.1 (Continuation of Example 13.1.1) The traffic police had mea-
sured speeds on a straight stretch on the M8 between Paisley and Glasgow,
where they spotted their first possible speeder. Their probability distribution
of his speed 𝜇was
𝜇∼𝜙(137, 2.886 75)(x).
We will find both right- and left-sided 95% credible intervals for the actual
speed 𝜇, as well as a 90% symmetric credible interval for 𝜇. We will also find
the three kinds of point estimate for 𝜇.


15 Estimates
Solution: To find the credible intervals, we first need to find 𝛼. For the one-
sided intervals, that means solving the equation (1 −𝛼)100% = 95%, and for
the symmetric ones, solving (1 −2𝛼)100% = 90%. In both cases, 𝛼= 0.05. The
intervals are then
I𝜇
0.05,l =
(
Φ−1
(137, 2.886 75)(0), Φ−1
(137, 2.886 75)(0.95)
)
= (−∞, 141.748)
I𝜇
0.10 =
(
Φ−1
(137, 2.886 75)(0.05), Φ−1
(137, 2.886 75)(0.95)
)
= (132.252, 141.748)
I𝜇
0.05,r =
(
Φ−1
(137, 2.886 75)(0.05), Φ−1
(137, 2.886 75)(1)
)
= (132.252, ∞).
The point estimates are straightforward:
𝜇MAP = ̃𝜇= E[𝜇] = 137.
..
Estimating Sample Size
Rule 10.1.6 provides a useful quick formula for interval estimates: if Θ ∼𝜙(m,s),
then the (1 −2𝛼)100% symmetric interval estimate is
IΘ
2𝛼= m ± z𝛼× s.
For the posterior and predictive distributions, we may use the hyperparameters
in Section 13.1.1 directly. The formulas then become
[t]I𝜇
2𝛼= m1 ± z𝛼s0
√
1
𝜅1
I+
2𝛼= m1 ± z𝛼s0
√
1 + 1
𝜅1
.
We recall that 𝜅1 = 𝜅0 + n, which means that as n, the number of observa-
tions, increases, the width of the credible interval I𝜇
2𝛼shrinks to 0, while the
width of the predictive interval I+
2𝛼converges to a stable width of 2z𝛼s0. We use
these facts to establish the required sample sizes for a given interval width.
Rule 15.4.2
(Required sample size with fixed 𝛼) If 𝜎= s0 is known, the
(1 −2𝛼)100% credible interval for 𝜇will be narrower than l if the number
of observations is at least
n =
4z2
𝛼
l2 × s2
0 −𝜅0.
Notice that this also means that, when we have n or more observations, P(𝜇∈
H𝜇
l ) ≥1 −2𝛼. We will look at an example of an interval estimate for 𝜇and X+.

15.5 Estimates for the t Distribution

Example 15.4.3 (Continuation of Example 13.1.2) You have tested the output
effect of your audiophile miniature amplifiers in two rounds, and you consider
𝜎to be known, with value s0 = 0.7 mW.
r Find 95% interval estimates for 𝜇and X+ from both rounds.
r How wide will the predictive interval for X+ be when n approaches infinity?
r For which number of observations n will the width of I𝜇
0.1 be less than
0.1 mW?
r For which number of observations n will P(𝜇∈H𝜇
0.1) be larger than 0.95?
Answer: After the first round, we had 𝜇∼𝜙(2.345 8, 0.313 05) and X+ ∼
𝜙(2.345 8, 0.766 812). We see that 95% = (1 −2 ⋅0.025) × 100%, and therefore use
that z0.025 = −1.959 96, which gives the intervals
I𝜇
0.05 = 2.345 8 ± 1.959 96 × 0.313 05 = (1.732 23, 2.959 37)
I+
0.05 = 2.345 8 ± 1.959 96 × 0.766 812 = (0.842 879, 3.848 72),
where the respective widths of the intervals are 1.227 13 and 3.005 84.
After
the
second
round,
we
had
𝜇∼𝜙(2.349 5, 0.202 073)
and
X+ ∼
𝜙(2.349 5, 0.728 583). Then
I𝜇
0.05 = 2.349 5 ± 1.959 96 × 0.202 073 = (1.953 45, 2.745 55)
I+
0.05 = 2.349 5 ± 1.959 96 × 0.728 583 = (0.921 503, 3.777 5),
where the respective widths of the intervals are 0.792 11 and 2.855 99.
The width of the predictive interval converges to 2 × 1.959 96 × 0.7 = 2.743 94
as n →∞, whereas the width of the credible interval for 𝜇converges to 0, as it
does for any such credible interval. Since 𝜅0 = 0, the width of I𝜇
0.05 will be less
than 0.1 when
n = 4 × 1.959 962
0.12
× 0.72 −0 = 752.923.
Since we may only make whole observations, we round up, so n = 753 is the
smallest number of observations for which the width of I𝜇
0.05 is less than 0.1,
and also P(𝜇∈H𝜇
0.1) > 0.95.
.
Estimates for the t Distribution
Problem: We have a Gaussian process with observations Xk ∼𝜙(𝜇,𝜎). The
parameters 𝜇and 𝜎are both unknown. Using the method in Section 13.1.3, we
find the posterior distribution of 𝜇and the predictive distribution of X+. Both
are t distributions. In addition, we find the posterior distribution of 𝜏= 𝜎−2,
which is a 𝛾distribution. Here, we will find estimates for 𝜇and X+.


15 Estimates
From Section C.2, we may deduce a useful formula for symmetric interval
estimates when Θ ∼t(m,s,𝜈). Then
IΘ
2𝛼= m ± t𝜈,𝛼× s.
If we return to the hyperparameters in Section 13.1.3, the formulas become
I𝜇
2𝛼= m1 ± t𝜈1,𝛼s1
√
1
𝜅1
I+
2𝛼= m1 ± t𝜈1,𝛼s1
√
1 + 1
𝜅1
,
where m1 = Σ1∕𝜅1 and s2
1 = SS1∕𝜈1. We have no corresponding expression for
the credible interval of 𝜎.
Example 15.5.1 (Continuation of Example 13.1.5) Abbot S¯ozen has measured
the speed of the cars driving past in the 50 zone outside his temple. He did this
in two rounds, and we will help him by calculating the 80% interval estimates
for the parameter 𝜇and for the next observation X+.
First round: The posterior probability distributions were 𝜏∼𝛾(4.5, 61.854 5)
and 𝜇∼t(57.19, 1.172 41, 9), whereas the predictive distribution was X+ ∼
t(57.19, 3.888 44, 9). Since 80% = (1 −2 × 0.1) × 100%, and t9, 0.1 = 1.383 03, we
have
I𝜇
0.2 = 57.19 ± 1.383 03 × 1.172 41 = (55.568 5, 58.811 5)
I+
0.2 = 57.19 ± 1.383 03 × 3.888 44 = (51.812 2, 62.567 8).
Second round: The posterior probability distributions were 𝜏∼𝛾(24.5, 264.953)
and 𝜇∼t(56.522, 0.465 068, 49), whereas the predictive distribution was X+ ∼
t(56.522, 3.321 25, 49). Since t49, 0.1 = 1.299 07, we have
I𝜇
0.2 = 56.522 ± 1.299 07 × 0.465 068 = (55.917 8, 57.126 2)
I+
0.2 = 56.522 ± 1.299 07 × 3.321 25 = (52.207 5, 60.836 5).
We see that just as in the case of the known 𝜎, the width of I𝜇, the credible
interval for the cars’ mean speed, gets narrower as the number of observations
increases, whereas the predictive interval I+ for the speed of the next car stays
roughly as wide (and will indeed converge on some fixed positive value).
..
Estimating Sample Size
For t distributions, there is no formula corresponding to Rule 15.4.2 giving a
credible interval that has a guaranteed maximum width for a sample size of n

15.6 Estimates for 𝛾Distributions

observations. Since 𝜎is unknown, the best we are able to achieve is an estimate
that itself is subject to probabilities.
This kind of estimate requires that we have some information about 𝜎.
The simplest relation requires prior hyperparameters 𝜅0, SS0, and 𝜈0 > 0 (see
13.1.2). We then have the following rule.
Rule 15.5.2
The expected probability that 𝜇∈H𝜇
l is equal to or greater
than 1 −2𝛼when
n ≥
4t2
2𝜈0, 𝛼
l2
× SS0
𝜈0
−𝜅0.
This is also the probability that I𝜇
2𝛼is narrower than l.
Example 15.5.3 (Continuation of 15.5.1 and 13.1.5) How many new measure-
ments must S¯ozen make of the cars driving past his temple if he wants a credible
interval of width l = 0.5 and at the same time an expected probability of 95%
for it to contain 𝜇, the cars’ actual mean speed?
Answer: Here, the prior hyperparameters equal the posterior hyperparameters
from the previous round. We have 𝜅2 = 50, SS2 = 529.906, and 𝜈2 = 49 > 0.
Using the fact that t98, 0.025 = −1.984 47, we get that n must be at least
n ≥
4t2
2𝜈2, 𝛼
l2
⋅SS2
𝜈2
−𝜅2 =
4t2
98, 0.025
0.52
⋅529.906
49
−50 = 631.413,
which means S¯ozen must observe the speed of at least 632 more cars to get the
desired values for the interval.
.
Estimates for 𝜸Distributions
Problem 1: We’ve got a Gaussian process with observations Xk ∼𝜙(𝜇,𝜎). The
parameters 𝜇and 𝜎are unknown. Using the method of Section 13.1.3, we find
the posterior distribution of 𝜏= 1∕𝜎2, which is a 𝛾distribution. We are going
to find estimates for 𝜏and 𝜎.
Problem 2: We’ve got a Poisson process with unknown parameter 𝜆. Using the
method of Section 13.3, we find the posterior distribution of 𝜆, which is a 𝛾
distribution. We are going to find estimates for 𝜆.
The credible interval with equal tails follows the general rule, with F−1(p) =
Γ−1
(k,𝜆)(p). From 10.3, we have the rule that Γ−1
(k,𝜆)(p) =
1
2𝜆× 𝕏−2
2k (p), which facil-
itates the use of a calculator for handling the 𝛾distribution. These two rules


15 Estimates
combined imply that
I𝜆
2𝛼=
(
Γ−1
(k,𝜆)(𝛼), Γ−1
(k,𝜆)(1 −𝛼)
)
=
( 1
2𝜆𝕏−2
2k (𝛼), 1
2𝜆𝕏−2
2k (1 −𝛼)
)
.
The width of IΘ
2𝛼is then
1
2𝜆
(
𝕏−2
2k (1 −𝛼) −𝕏−2
2k (𝛼)
)
, and hence a multiple of
E[Θ] = k
𝜆. We will make use of this fact when we get to the estimation of sample
sizes.
For a distribution Θ ∼𝛾(k,𝜆)(x) and a given length l, the HPD interval HΘ
l =
(a, a + l) is given by
a =
l
e𝜆l∕(k−1) −1.
Example 15.6.1
(For problem 1: continuation 2 of Example 13.1.5) Abbot
S¯ozen has measured the speed of the cars driving past in the 50 zone outside his
temple. He did this in two rounds, and we will now help him by calculating the
estimates for the second round: both the interval estimates I𝜏
0.1, I𝜎
0.1, and H𝜏
0.07
and the point estimates 𝜏MAP, ̃𝜏, and E[𝜏].
The posterior probability distribution from the second round is 𝜏∼
𝛾(24.5, 264.953).
Point estimates:
𝜏MAP = 24.5 −1
264.953 = 0.088 695
̃𝜏= Γ−1
(24.5, 264.953)(0.5) = 0.091 214 2
E[𝜏] =
24.5
264.953 = 0.092 469 2.
Interval estimates: the interval limits for I𝜏
0.1 then become Γ−1
(24.5, 264.953)
(0.05) = 0.064 030 8 and Γ−1
(24.5, 264.953)(0.95) = 0.125 189. Since 𝜏= 1∕𝜎2, and
thereby 𝜎= 1∕
√
𝜏, the interval limits for I𝜎
0.1 are then 1∕
√
0.064 030 8 = 3.951 9
and 1∕
√
0.125 189 = 2.826 29, which means that
I𝜏
0.1 = (0.064 030 8, 0.125 189)
I𝜎
0.1 = (2.826 29, 3.951 9),

15.6 Estimates for 𝛾Distributions

whose widths are, respectively, 0.061 158 7 and 1.125 61. If we were to insist
on a width of l = 0.07, and find the HPD interval H𝜏
0.07, we would get the left
endpoint
a =
0.07
e264.953 × 0.07∕(24.5−1) −1 = 0.058 2517.
The right endpoint is then 0.058 251 7 + 0.07 = 0.128 251 7, which means
H𝜏
0.07 = (0.058 252, 1 282 517).
Example 15.6.2 (For problem 2) Archbishop Itabashi thinks our friend abbot
S¯ozen needs some extra mindfulness training. At the same time, he worries
that his cat Dai-ichi is becoming radioactive, so S¯ozen is told to follow Dai-ichi
with a Geiger counter for an hour. How radioactive Dai-ichi is, remains to be
established, but the cat is obviously very active, so S¯ozen has to pay attention
to getting his Geiger clicks. After 60 minutes, S¯ozen has registered 28 Geiger
clicks from the cat.
The number of Geiger clicks over a time period follows a Poisson distribution
with parameter 𝜆. The archbishop thinks that we, the readers, also need some
mindfulness training, so he puts us to work to find interval estimates for 𝜆,
starting with neutral hyperparameters. He specifies that he first wants I𝜆
0.08. He
then wants us to find l, the width of I𝜆
0.08, and then to find the most probable
interval of width l; that is, H𝜆
l .
Answer: 𝜅0 = 𝜏0 = 0, so
P1 ⊧𝜅1 = 0 + 28 = 28
𝜏1 = 0 + 60 = 60.
Then
𝜆∼𝛾(28,60)(l).
The credible interval with equal tails is then
I𝜆
2 × 0.04 =
(
Γ−1
(28,60)(0.04), Γ−1
(28, 60)(0.96)
)
= (0.324 318, 0.631 909),
whose width is l = 0.307 591. The HPD interval H𝜆
0.307 591 = (a, a + l) is then
given by
a =
0.307 591
e60 × 0.307 591∕(28−1) −1 = 0.313 59.
Then H𝜆
0.37 = (0.313 59, 0.621 181), and P(𝜆∈H𝜆
0.307 591) = 0.922 391.


15 Estimates
..
Estimating Sample Size
For the Poisson process parameter 𝜆, the most accessible formula for sample
size is a formula that looks at the relative size; that is, it looks at the ratio of
the interval width l to E[𝜆]. For these estimates, it is expedient to use the fact
that the Normal approximation to 𝛾(𝜅1,𝜏1) is 𝜙(𝜇,𝜎), with 𝜇= 𝜅1
𝜏1 and 𝜎2 = 𝜅1
𝜏2
1
.
Then
IΘ
2𝛼≈𝜅1
𝜏1
± z𝛼⋅
√𝜅1
𝜏1
giving an interval width of l = 2z𝛼⋅
√𝜅1
𝜏1 .
Rule 15.6.3
Define the relative interval width of IΘ
2𝛼to be r =
l
E[𝜆]. Since
E[𝜆] = 𝜅1
𝜏1 , we have r = 2z𝛼
√𝜅1 . This means that in order for r < R for some fixed
magnitude R, we need
𝜅1 ≥
4z2
𝛼
R2 ,
which means that the number of new observations must be at least
n ≥
4z2
𝛼
R2 −𝜅0.
Example 15.6.4
(Continuation of Example 15.6.2) How many more clicks
must S¯ozen get on his Geiger counter if the relative interval width should be
r < 0.1 for I𝜆
0.08?
Answer: S¯ozen has already gathered 𝜅0 = 28 clicks. Since z0.04 = −1.750 69,
n ≥4 ⋅1.750 692
0.12
−28 = 1197.97.
This means that S¯ozen needs at least 1198 more clicks.
.
Estimates for 𝜷Distributions
Problem: We have a Bernoulli process with unknown parameter p, where we
have made n observations with outcomes ⊤or ⊥.

15.7 Estimates for 𝛽Distributions

In Section 13.2, we found the posterior probability distribution p ∼𝛽(a,b). The
symmetric (1 −2𝛼)100% credible interval for p is then
Ip
2𝛼=
(
I−1
(a,b)(𝛼), I−1
(a,b)(1 −𝛼)
)
.
For larger parameter values, typically a, b > 10, we may use the Normal approx-
imation 𝜙(𝜇,𝜎) where 𝜇=
a
a+b and 𝜎2 =
ab
(a+b)2(a+b+1). This gives the approxi-
mate (1 −2𝛼)100% credible interval
Ip
2𝛼≈
(
Φ−1
(𝜇,𝜎)(𝛼), Φ−1
(𝜇,𝜎)(1 −𝛼)
)
.
The HPD interval Hp
l = (k, k + l) for p ∼𝛽(a,b) is given by solving for k in the
following equation (where k is a real solution in the unit interval (0, 1)):
(k + l)a−1(1 −k −l)b−1 −ka−1(1 −k)b−1 = 0.
Except for very low values of a and b, this equation must be solved numerically,
requiring a decent tool. A good starting point for a numerical search is k0 =
E[p] =
a
a+b. In Mathematica and Wolfram Alpha, the command is
FindRoot [(k + l)a−1(1 −k −l)b−1 −ka−1(1 −k)b−1, {k, k0}] .
Example 15.7.1 Hot rod: Sam has looked at 36 old Volvo Amazon cars, and
has recorded that 22 of them have been treated with hot rod, bodywork repairs
using liquid lead, while 14 had not received such treatment. The only thing Sam
knew about hot rodding in advance was that there was such a thing, so he chose
for his prior hyperparameters a0 = 1 and b0 = 1. We are going to estimate 𝜋,
the total proportion of hot rodded Volvo Amazon cars.
We will first find the three point estimates. Then, we will calculate I𝜋
0.05, using
both exact calculation and Normal approximation. Finally, we will find the HPD
interval H𝜋
0.3.
Answer: The posterior distribution for the proportion of hot rodded old Volvo
Amazon cars is 𝜋∼𝛽(1+22,1+14) = 𝛽(23,15).
The point estimates are then
𝜋MAP =
23 −1
23 + 15 −2 = 0.611 111
̃𝜋= I−1
(23,15)(0.5) = 0.607 129
E[𝜋] =
23
23 + 15 = 0.605 263.


15 Estimates
Exact calculation of the 𝛽distribution (see Section 10.5) gives
Ip
2⋅0.025 =
(
I−1
(23,15)(0.025), I−1
(23,15)(0.975)
)
= (0.447 568, 0.752 458),
an interval whose width is l = 0.304 89.
For the Normal approximation, 𝜇= 0.605 263 and 𝜎= 0.078 269 7, which
gives
Ip
2⋅0.025 ≈
(
Φ−1
(𝜇,𝜎)(0.025), Φ−1
(𝜇,𝜎)(0.975)
)
= (0.451 857, 0.758 669),
an interval whose width is l = 0.306 812.
For the HPD interval, we solve
(k + 0.3)23−1(1 −k −0.3)15−1 = k23−1(1 −k)15−1
and get the left limit of the interval k = 0.453 97. The right end of the interval
is then k + l = 0.453 97 + 0.3 = 0.753 97, so
H𝜋
0.3 = (0.453 97, 0.753 97).
For this interval, P(𝜋∈H𝜋
0.3) = 0.946 308.
..
Estimating Sample Size
For the 𝛽distributions, we choose a “worst case” sample size formula guaran-
teeing that a credible interval of width l has a probability of at least 1 −2𝛼of
containing 𝜋.
Rule 15.7.2
If the parameter 𝜋has prior probability distribution 𝛽(a,b),
a, b > 1, then n or more new observations, where
n =
z2
𝛼
l2 −a −b,
will ensure that P(𝜋∈H𝜋
l ) ≥1 −2𝛼, and that the width of I𝜋
2𝛼will be l or
less.
Example 15.7.3 (Continuation of Example 15.7.1) How many new observa-
tions must Sam make to ensure that the width of a 95% credible interval for 𝜋
is at most 0.1?
Answer: Sam’s old posterior will be his new prior, so for the formula, a = 23 and
b = 15. From Example 15.7.1, we have 𝛼= 0.025 and l = 0.1, so the number of

15.8 Exercises

new observations Sam needs to make is at least
n =
z2
0.025
0.12 −23 −15 = 346.146,
that is, 347 new observations.
.
Exercises
Gaussian Processes With Known 𝝈
1
From distribution to interval.
(a) 𝜇∼𝜙(14, 3). Find I𝜇
0.025,l and I𝜇
0.025,r and I𝜇
0.05.
(b) 𝜇∼𝜙(−4.3, 7.2). Find I𝜇
0.005,l and I𝜇
0.005,r and I𝜇
0.01.
(c) 𝜇∼𝜙(48,
√
19). Find I𝜇
0.1.
(d) X+ ∼𝜙(0.018, 0.000 134). Find I+
0.005.
(e) 𝜇∼𝜙(4.3,−7.2). Find I𝜇
0.03.
2
From data + prior to interval. Find I𝜇
2𝛼and I+
2𝛼.
(a) Data: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, neutral prior, known 𝜎= 2.3; 2𝛼=
0.05.
(b) Prior: 𝜅0 = 7, Σ0 = 1 253, s0 = 15. 2𝛼= 0.1. We have 23 observations
with ̄x = 185.814.
(c) Prior: 𝜅0 = 7, Σ0 = 35.7, s0 = 0.1. 2𝛼= 0.02. Statistics: n = 5, Σx =
25.615.
3
Sample size:
(a) Given known 𝜎= 5, and prior hyperparameter 𝜅0 = 0, how many
observations n do you have to make to ensure I𝜇
0.01 is narrower than
0.5?
(b) With known 𝜎= 0.42, and prior hyperparameter 𝜅0 = 8 how many
observations n do you have to make to ensure I𝜇
0.07 is narrower than
0.123?
4
You have tried weighing your dog, knowing well that it is unable to stand
still on the scales. You have done this four times, and based on the wobbling
of the weight dial, you assume the weighings correspond to 𝜎= 0.4 kg; the
mean weight was ̄y = 17.5 kg. Using a neutral prior, indicate a 90% credible
interval for your dog’s weight.
5
Your son is doing athletics, and his performance varies from day to day.
He wants to compete, and has asked you to help him by assessing his high
jumps. His coach is also a gymnastics and mathematics teacher, and tells


15 Estimates
you that jump heights of each athlete follows a Normal distribution 𝜙(𝜇,𝜎),
and that in his club, 𝜎= 3 cm. You measure your son’s high jumps 10 times,
and the total is 15.7 meters. Using a neutral prior, find 90% interval esti-
mates for the mean jump height, 𝜇, and for your son’s next jump, X+.
Gaussian Processes With Unknown 𝝈
6
From distribution to interval.
(a) 𝜇∼t(68.1,11.9,17). Find I𝜇
0.001.
(b) 𝜇∼t(68.1,11.9,4). Find I𝜇
0.001 and I𝜇
0.1.
(c) X+ ∼t(5,1.2,7). Find I+
0.02.
7
From data + prior to interval. Find I𝜇
2𝛼and I+
2𝛼. In addition, find I𝜏
2𝛼and I𝜎
2𝛼.
(a) Data: {0.896, 0.279, 0.865, 0.955, 0.936, −0.046}; use a neutral prior.
2𝛼= 0.05.
(b) Prior: 𝜅0 = 6, m0 = 150, 𝜈0 = 5, s0 = 10. 2𝛼= 0.1. Statistics: n = 18,
Σx = 2 644.9, SSx = 3 978.54.
(c) Prior: 𝜅0 = 4, Σ0 = 80, 𝜈0 = 3, SS0 = 27. 2𝛼= 0.05. You have 38 obser-
vations with average ̄x = 19.823 7 and sample standard deviation sx =
3.551 43.
8
Sample size:
(a) Using prior hyperparameters 𝜅0 = 7, 𝜈0 = 6, and SS0 = 17, how many
observations n do you need to make in order for P(𝜇∈H𝜇
1.3) ≥0.9?
(b) Using prior hyperparameters 𝜅0 = 5, 𝜈0 = 4, and SS0 = 50, how many
observations n do you need to make in order for P(𝜇∈H𝜇
2 ) ≥0.86?
9
A standard European football goal is 732 cm wide and 244 cm high, so if
the goalkeeper is standing in the middle of the goal, he needs to be able to
throw himself far enough to the sides that his hands are 366 cm away from
the middle, if he wants to cover the entire goal. We have data from the small
Norwegian football club Jerv’s junior goalkeeper in 1986, Christian Finne.
The average reach for 8 throws is x = 378 cm, and their sample standard
deviation is sx = 14 cm. Find a 96% credible interval for Finne’s reach when
using a neutral prior.
10
You are out diving with five friends, and stop to admire a school of gold-
fish. At that point, you are all at the same depth. Your ACME depth gauges
respectively 33.1, 28.3, 29.0, 29.7, 33.2, and 30.9 meters. Find a 90% credi-
ble interval for your actual depth. Use a neutral prior.
11
You are following the band P¨unk Fl¨oyd, and just attended a concert with
a rather permeating smell of sweet smoke. The police had conducted ran-
dom checks of 10 audience members, and had in total impounded 54.4

15.8 Exercises

grams of hashish. The individual weights were as follows: 5.8, 6.0, 1.8, 3.4,
6.8, 4.7, 7.8, 6.1, 6.0, and 6.0 grams. Use a neutral prior, and find a 90%
credible interval for the mean possession in the audience. In addition, find
a 90% predictive interval estimate for the amount of hashish possessed by
a random member of the audience (X+), and credible intervals for 𝜏and 𝜎.
12
In the Norwegian box office hit film Il Tempo Gigante, it was said that on
Reodor Felgen’s first run of his racing car Il Tempo Gigante, the seismo-
graph in Bergen registered it as an earthquake in Fl˚aklypa of magnitude
7.8 on the Richter scale. For extra observations, the seismograph in Reyk-
javik registered it as 7.6, and the one in Helsinki had it at 7.9. Use a neutral
prior, and find a 95% credible interval for the magnitude of the earthquake
in Fl˚aklypa when Felgen drove off in his Il Tempo Gigante.
Poisson Process
13
From distribution to interval.
(a) 𝜆∼𝛾(4,17). Find I𝜆
0.05.
(b) 𝜆∼𝛾(7,128). Find I𝜆
0.001.
(c) 𝜆∼𝛾(2,8). Find I𝜆
0.1.
14
From data + prior to interval. Find I𝜇
2𝛼and I+
2𝛼.
(a) Prior: 𝜅0 = 3, 𝜏0 = 5. Observed: n = 13 occurrences during t = 20
units. 2𝛼= 0.02.
(b) Prior: 𝜅0 = 4, 𝜏0 = 8. Observed: n = 48 occurrences during t = 100
units. 2𝛼= 0.1.
(c) Prior: 𝜅0 = 0, 𝜏0 = 0. Observed: n = 7 occurrences during t = 128
units. 2𝛼= 0.001.
15
Sample size: Your prior hyperparameter is 𝜅0 = 5. How many observations
do you need to make for the relative interval width r for a 80% credible
interval to be less than 0.2?
16
(t = units) The daily catch for grouse hunters in an area is considered to
be Poisson distributed with rate 𝜆. One day, you talked to 23 hunters from
a certain part of the Lowlands, and their total catch was 111 grouse. Use a
neutral prior, and find an 85% credible interval for 𝜆.
17
(t = time) The number of plumbing gaskets that need changing every week
in an apartment complex is assumed to follow a Poisson process with rate
𝜆. You are estimating this need for an apartment complex with 70 flats, and
have looked into the documentation for the last semester (26 weeks), and
find registered 53 gasket changes. Use a neutral prior, and calculate an 80%
credible interval for 𝜆.


15 Estimates
18
(t = length) The number of cracks in the tarmac per kilometer of road is
assumed to follow a Poisson process with rate 𝜆. Your job is to find this rate
for a lesser highway, and you have found 13 cracks in 10 km. Use a neutral
prior, and calculate a 92% credible interval for 𝜆.
19
(t = area = number of square meters) How many four-leaf clovers are there
per square meter in a field of leaf clovers? Assume that the occurrence
follows a Poisson process with rate 𝜆. You look at three independent leaf
clover fields. The first field is t1 = 1.9 m2 in area, and has n1 = 0 four-
leaf clovers. The second field has an area of t2 = 0.7 m2, and has n2 = 3
four-leaf clovers, whereas the third spot of area t3 = 1.2 m2 has n3 = 1
four-leaf clovers. Use a neutral prior, and find a 90% credible interval
for 𝜆.
20
(t = volume = number of cubic centimeters) The number of bacterial
colonies per cubic centimeter in a certain polluted lake is assumed to be
Poisson distributed with parameter 𝜆. You sample 1 deciliter, and find 157
bacterial colonies. Use a neutral prior, and calculate a 95% credible interval
for 𝜆.
Bernoulli Process
21
From distribution to interval.
(a) 𝜋∼𝛽(43,96). Find I𝜋
0.1, both by exact calculation of 𝛽, and by using Nor-
mal approximation.
(b) 𝜋∼𝛽(7,128). Find I𝜋
0.001, both by exact calculation of 𝛽, and by using Nor-
mal approximation.
(c) 𝜋∼𝛽(2,2). Find I𝜋
0.05.
(d) 𝜋∼𝛽(1,1). Find I𝜋
0.12 (hint: sketch the graph).
22
From data + prior to interval. Find I𝜋
2𝛼.
(a) 2𝛼= 0.07. Prior: a0 = 3, b0 = 5.
Observed: k = 13 positives and l = 20 negatives.
(b) 2𝛼= 0.1. Prior: a0 = 0, b0 = 0 (Novick and Hall).
Observed: k = 4 positives and l = 9 negatives.
(c) 2𝛼= 0.05. Prior: a0 = 0.5, b0 = 0.5 (Jeffreys).
Observed: k = 44 positives and l = 19 negatives.
(d) 2𝛼= 0.02. Prior: a0 = 1, b0 = 1 (Laplace).
Observed: k = 79 positives and l = 198 negatives.
23
Sample size: 𝜋has prior hyperparameters a0 = 12 and b0 = 31. How many
new observations do you need to make to ensure that I𝜋
0.2 is narrower than
0.05?

15.8 Exercises

24
You are studying Bard’s biased coin. Your prior hyperparameters for 𝜋, the
probability of heads, is a0 = 9 and b0 = 12. Find the 90% symmetric cred-
ible interval for 𝜋after each update.
(a) You flip 23 heads and 18 tails.
(b) You flip again, and get 458 heads and 366 tails.
(c) You finally flip 5 571 heads and 4 429 tails.
(d) How many times do you need to flip the coin in total for the width of
I𝜋
0.1 to be less than 0.01?
25
Sondre Glimsdal wants to estimate 𝜋, the proportion of Go1 games won by
white. His prior is 𝜋∼𝛽(7,7). Sondre updates his estimate by observing new
games. Find the 80% symmetric credible interval for 𝜋after each update.
(a) 1st observation: white wins 13 and black wins 7.
(b) 2nd observation: white wins 11 and black wins 9.
(c) How many new games does he need to observe to ensure that the width
of I𝜋
0.2 is less than 0.05?
(d) 3rd observation: white wins 348 and black wins 255.
1Also known in Korean as baduk and in Chinese as Wei Qi.




Frequentist Inference⋆
CONTENTS
16.1 Unbiasedness and Point Estimates, 371
16.2 Interval Estimates, 375
16.3 Hypothesis Testing, 379
16.4 Exercises, 386
“This is my chapter,” Frederick exclaims proudly. “Here, I will teach you my
way of thinking and calculating, so that you Bayesian students may speak and
cooperate freely with my frequentist students.”
“The first expression I want to teach you,” he continues, “is that of being
unbiased. My most popular techniques for point and interval estimates are built
around this concept.”
.
Unbiasedness and Point Estimates
“So what does it mean to be unbiased?” Frederick asks. “It is to make the sam-
ple represent the population. For us frequentists, the concrete sample is a ran-
dom trial. One out of many possible samples from the population. We want the
aggregate of samples to yield the right values – in the long run.”
More precisely, we recall from Section 11.2 that the population has parameter
𝜃. From the samples, which are our observations, we may calculate an estimator
̂Θ = h(X1, … , Xn), a stochastic variable which is a function of the X values.
Definition 16.1.1
Let ̂Θ be an estimator for the parameter 𝜃. Then, ̂Θ is
unbiased if E[̂Θ] = 𝜃.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


16 Frequentist Inference⋆
When we have the concrete observations x1, … , xn, we get a concrete value
̂𝜃that we call a point estimate of 𝜃. An estimator that is not unbiased is, not
surprisingly, called biased.
“Note that not all our estimators are unbiased,” Frederick continues, “that is,
not all the estimators we frequentists make use of. The Bayesian have a great
many biased estimators. But back to us: the reason for this is that the property
of being unbiased often gets lost when you put the numbers through a function:
E[f (Θ)] ≠f (E[Θ]).”
Sam looks at Frederick with a puzzled look, so Frederick explains: “Let me
take an example of a function: f (x) =
√
x. The sample variance Var(X) is an
unbiased estimator of the population variance. However, its square root, the
sample standard deviation 𝜎X =
√
Var(X), is not an unbiased estimator of
the population standard deviation. We could make an unbiased estimator of
the standard deviation. But then the square of it would not be an unbiased esti-
mator of the population variance.”
Rule 16.1.2 The three most important unbiased point estimates are
r ̂𝜇, estimate of 𝜇, the mean of a population, is ̂𝜇= ̄x
r ̂
𝜎2, estimate of 𝜎2, the variance of a population, is ̂
𝜎2 = s2
x
r ̂p, estimate of p, the proportion of ⊤in a population, is ̂p = k
n, where k is
the number of ⊤in n observations.
“So you actually started this course,” Frederick smiles at Sam, “by calculating
unbiased point estimates!”
..
x is an Unbiased Estimator of 𝝁
For a single observation X, we see that E[X] = 𝜇, the mean of the population.
So for a single observation, the observation itself is an unbiased estimator of 𝜇.
For larger samples,
E[ ̄X] = E
[X1 + ⋯+ Xn
n
]
= 𝜇+ ⋯+ 𝜇
n
= 𝜇
(according to Rule 8.3.3), so the average ̄X is an unbiased estimator of 𝜇as well.
..
s
x is an Unbiased Estimator of 𝝈
The population variance is 𝜎2. We are going to show that the sample variance
s2
x =
1
n−1SSx is an unbiased estimator of 𝜎2. To do this in a simple and tidy man-
ner, we need to make some observations.

16.1 Unbiasedness and Point Estimates

Notice that Xk −X = (Xk −𝜇) −
(
X −𝜇
)
, which means that
SSx =
n
∑
k=1
((Xk −𝜇) −
(
X −𝜇
))2
=
n
∑
k=1
(Xk −𝜇)2 +
n
∑
k=1
(
X −𝜇
)2
+ 2
n
∑
k=1
(
X −𝜇
) (Xk −𝜇)
=
n
∑
k=1
(Xk −𝜇)2 −n
(
X −𝜇
)2
.
Show the details of the last equality for yourself. The key to this exercise is
to calculate that ∑n
k=1(X −𝜇)(Xk −𝜇) = n(X −𝜇)2. Given this equality, we get
E[SSx] = (n −1)𝜎2.
This means that E[s2
x] = E
[SSx
n−1
]
= 𝜎2, and hence the sample variance is
unbiased.
“This was the theoretical way. Many of my students, however, prefer to build
their understanding through seeing a live example rather than a theoretical
deduction,” Frederick points out, “so I will now show you the unbiasedness of
the sample variance through a simple example. Simple, but with a bit of calcu-
lation; you never get away from that.”
Example 16.1.3
We have a population consisting of 3 values: = {x1 =
0, x2 = 0, x3 = 6}. We will first calculate the (population) mean and variance.
After that, we are going to calculate the sample means and variances for all
the possible samples of 2 elements from this population. Note that there are
a total of 9 possible samples, since we may choose the same element repeat-
edly. The possible 2-element samples (with replacement), are u1 = (x1, x1), u2 =
(x1, x2), u3 = (x1, x3), u4 = (x2, x1), u5 = (x2, x2), u6 = (x2, x3), u7 = (x3, x1),
u8 = (x3, x2), u9 = (x3, x3).
Population measures: 𝜇= 0+0+6
3
= 2 and 𝜎2
x = 02+02+62
3
−22 = 8.
Sample measures: We calculate the following for each of the 9 samples.
r The averages for these samples are ̄x1 = 0+0
2
= 0, and (calculated in the same
way), ̄x2 = 0, ̄x3 = 0+6
2
= 3, ̄x4 = 0, ̄x5 = 0, ̄x6 = 3, ̄x7 = 3, ̄x8 = 3, ̄x9 = 6.
r The population variances for these samples are 𝜎2
1 = 02+02
2
−02 = 0, and (cal-
culated in the same way), 𝜎2
2 = 0, 𝜎2
3 = 02+62
2
−32 = 9, 𝜎2
4 = 0, 𝜎2
5 = 0, 𝜎2
6 = 9,
𝜎2
7 = 9, 𝜎2
8 = 9, 𝜎2
9 = 0.
r The sample variances for these samples are s2
1 = 0, s2
2 = 0, s2
3 = 18, s2
4 = 0,
s2
5 = 0, s2
6 = 18, s2
7 = 18, s2
8 = 18, s2
9 = 0.


16 Frequentist Inference⋆
The average of the sample averages is 0+0+3+0+0+3+3+3+6
9
= 2, which equals
the population mean, 𝜇. So we see here that the sample average ̂𝜇= ̄xi is an
unbiased estimator of 𝜇.
The
average
of
the
population
variances
of
these
samples
is
0+0+9+0+0+9+9+9+0
9
= 4, which is smaller than the population variance of
, since 𝜎2
x = 8. So we see here that taking the population variance of the
sample data is not an unbiased estimator of the population variance of the
original population .
The average of the sample variances is 0+0+18+0+0+18+18+18+0
9
= 8, which
equals the population variance 𝜎2
x for the population . So we see here that
the sample variance of the samples is an unbiased estimator of the population
variance of the original population.
..
MLE⋆
“Even though unbiasedness gives the most important point estimates,”
Frederick says, “we have others. The second most important estimate is the
maximal likelihood estimate, or MLE for short.”
“The MLE is quite similar to our MAP,” Bard interjects, “the maximum a
posteriori estimate. The difference between the MLE and the MAP is that the
MAP includes a prior.”
Frederick continues: “The Bayesians find their MAP from a posterior distri-
bution, whereas we frequentists find the MLE from what you have come to
know as the likelihood function. In both cases, the estimate is simply the argu-
ment value that gives the maximum value, which again puts these estimates in
the same category as the mode.”
“MAP and MLE are often good estimates,” Bard says, “and they are a bit more
robust under functions like the square root. But for very skewed distributions,
or for multimodal distributions, that is, distributions with multiple maxima,
these estimates may turn out very different from the other point estimates, as
we see in Figure 16.1.”
(a) Multimodal distribution
(b) Skewed distribution
Figure .Mode in red, mean in green.

16.2 Interval Estimates

.
Interval Estimates
“Now it’s time for my interval estimates.” Frederick smiles, “We frequentists
call our interval estimates confidence intervals. They often coincide with the
Bayesians’ credible intervals. But despite this, the intervals don’t mean the
same.”
r A given (1 −𝛼) × 100% credible interval I𝜃
𝛼for a parameter 𝜃is an interval of
Bayesian probability P(𝜃∈I𝜃
𝛼) = 1 −𝛼.
r It is, on the other hand, meaningless to speak of any “frequentist probability”
that a given confidence interval ̂I𝜃
𝛼contains the parameter 𝜃. Probabilities of
this kind follow Example 5.1.6, and are either 0 or 100%, but we do not know
which.
r However, what we can speak of is the frequentist probability that the method
will result in an interval that contains 𝜃: using the method, each new data
set will result in a new interval ̂I𝜃
𝛼. Even if we are not allowed to say anything
about each individual interval, we may still speak of the proportion of inter-
vals that contain 𝜃, and firmly say that this proportion will approximate 1 −𝛼
as the number of such data sets and confidence intervals approaches infin-
ity. We have illustrated this process of creating 80% confidence intervals in
Figure 16.2.
“We are going to stick with two-sided interval estimates in this lecture,”
Frederick explains, “and to one parameter only, for simplicity’s sake.”
..
Interval Estimates for Gaussian Processes
“For us, the variance 𝜎2 is either fully known, or fully unknown,” Frederick
begins, “with no middle ground of a partly known 𝜎. This goes for all popu-
lation parameters.”
“We are going to look at some of the most common interval estimates,”
Frederick continues, “and the first thing you Bayesians will notice, is that we
do not ascribe any probability distribution to the parameters. When we have n
observations, we find the sufficient statistics n, Σx, and SSx, and calculate 𝜈=
n −1, ̄x = Σx∕n, and s2
x = SSx∕(n −1). For Gaussian processes, our (1 −𝛼)100%
confidence intervals are given in Table 16.1.”
“Even though this does not depend on the school, frequentist or Bayesian,
that is,” Frederick says, “it is more common in my camp to find estimates for
𝜎2, whereas the Bayesians tend to prefer estimating 𝜏. It really doesn’t matter,
since 𝜏= 1∕𝜎2 so that you can find the one from the other, but it’s useful to
know.


16 Frequentist Inference⋆
−1.0
−0.5
θ
0.5
1.0
Figure .80% confidence interval for 𝜇,
constructed from data sampled from a Normal
distribution 𝜙(0,1). The intervals capture the true
value (𝜇= 0) roughly 80% of the time.
“But in my chapter, you will get the rules that work best for you,” he continues.
“In my school, we like to express the confidence interval ̂
I𝜎2
𝛼thus:
SSx
𝜒2
𝜈, 1−𝛼∕2
< 𝜎2 <
SSx
𝜒2
𝜈, 𝛼∕2
.
Table .Gaussian confidence intervals
𝝈= 𝝈(known)
𝝈unknown
𝜇
̂I𝜇
𝛼= ̄x ± z𝛼∕2 ⋅𝜎0 ⋅
√
1
n
̂I𝜇
𝛼= ̄x ± t𝜈, 𝛼∕2 ⋅sx ⋅
√
1
n
𝜏
–
̂I𝜏
𝛼=
(
Γ−1
(
𝜈∕2,SSx∕2
) (𝛼∕2) , Γ−1
(
𝜈∕2,SSx∕2
) (1 −𝛼∕2)
)
X+
̂I+
𝛼= ̄x ± z𝛼∕2 ⋅𝜎0 ⋅
√
1 + 1
n
̂I+
𝛼= ̄x ± t𝜈, 𝛼∕2 ⋅sx ⋅
√
1 + 1
n

16.2 Interval Estimates

Note 16.2.1 Here, 𝜒2 is a shorthand overload of the 𝜒2 symbol: 𝜒2
𝜈,𝛼denotes the
inverse cumulative 𝜒2 distribution with argument 𝛼, with 𝜈degrees of freedom.
The commands for 𝜒2
𝜈,𝛼are
r Mathematica: InverseCDF[ChiSquareDistribution[𝜈], 𝛼]
r Casio: InvChiCD(𝛼, 𝜈)
r TI CX: Inv𝜒2(𝛼, 𝜈)
r TI 83+: Solver: 𝜒2cdf(0, x, 𝜈) −𝛼= 0 ≫x = 1
r HP: chisquare_icdf(𝜈, 𝛼).
Example 16.2.2
In the time after Example 15.4.1, engineering student Rolf
has hacked Eggeseth’s smallest laser speed gauge so that it now uses 20 pulses
for its measurements, with each individual measurement following a Normal
distribution with 𝜎= 5. Rolf has also made the gauge calculate P% interval esti-
mates automatically, and he has put a switch on the side of the gauge, to switch
between Bayesian (with neutral prior) and frequentist calculation. Eggeseth
sets the switch to frequentist right before his favorite speeder Klaus K¨onigsegg
whizzes past. Rolf reads the display: “137 km/h”, and also gives the 98% (sym-
metric) confidence interval for Klaus K¨onigsegg’s actual speed. What is this
interval?
Answer: We use the formula for a 98% confidence interval for 𝜇with known
𝜎. Using 𝛼= 1 −0.98 = 0.02, we get the interval
137 ± z0.01 ×
5
√
20
≈(134.4, 139.6).
Additional question: Does Rolf’s new switch really add anything?1
Example 16.2.3
Mulligan & Daughters Ltd is a stable company with a
200 year history. Adjusted for inflation, the earnings have been stable and at
the same level for the last 50 years, and the average income for the last 30 years
in current value, is ̄x = £37.1 million, while the sample standard deviation is
sx = £2.73 million. Find (with all numbers in current value)
1) the 90% confidence interval for the mean income;
2) the 90% prediktivt intervall for next year’s income;
3) the 90% confidence interval for the variance in the income.
1Answer: No. For Gaussian processes, the frequentist confidence intervals are identical to the
corresponding Bayesian credible intervals (with neutral prior) when 𝜎is fully known or fully
unknown.


16 Frequentist Inference⋆
Answer: n = 30, so 𝜈= 29, which means that SSx = 29 × 2.732 = 216.134.
1) ̂
I𝜇
0.1 = 37.1 ± t29, 0.05 × 2.73 ×
√
1∕30 ≈(36.3, 37.9);
2) ̂
I+
0.1 = 37.1 ± t29, 0.05 × 2.73 ×
√
1 + 1∕30 ≈(32.4, 41.8);
3) we calculate the confidence interval for 𝜎2 in both ways:
r ̂
I𝜏
0.1 =
(
Γ−1
(14.5, 108.067)(0.05), Γ−1
(14.5, 108.067)(0.95)
)
= (0.081 932 3, 0.196 901),
which gives
̂
I𝜎2
0.1 =
(
1
0.196 901,
1
0.081 932 3
)
= (5.078 7, 12.205 2)
r ̂
I𝜎2
0.9 =
(
216.134
𝜒2
29, 0.95
, 216.134
𝜒2
29, 0.05
)
=
(216.134
42.557 , 216.134
17.708 4
)
= (5.078 7, 12.205, 2).
Additional question: How does the frequentist predictive interval differ from
the Bayesian predictive interval with neutral priors?2
..
Conﬁdence Intervals for Bernoulli Processes
“We have different techniques for calculating confidence intervals for the
parameter 𝜋for a Bernoulli process,” Frederick explains, “some slow but exact,
and others fast but a bit imprecise. Statistics is after all the art of being imprecise
in a precise way.
“The most common method is the fast one,” he continues, “and it is the pre-
ferred one when we have more than 30 observations. After n observations,
you have k positives, and let ̂𝜋= k
n. A (1 −𝛼)100% confidence interval for the
true proportion (the parameter 𝜋for a Bernoulli process) is according to this
method given by
̂𝜋± z𝛼∕2
√
̂𝜋(1 −̂𝜋)
n
.
2Answer: Numerically, not at all. For Gaussian processes, the frequentist predictive intervals are
identical to the corresponding Bayesian intervals (with neutral priors) when 𝜎is fully known or
wholly unknown.

16.3 Hypothesis Testing

Example 16.2.4 The Motherwell striker Louis Moult scored 15 goals in the
2015/16 season of the Scottish Premier League, whereof 10 with his right foot.
Find a 90% confidence interval for 𝜋, the proportion of goals Moult scores with
his right foot in the long run.
Answer: ̂𝜋= 10
15 = 2
3 and 𝛼
2 = (1 −0.9)∕2 = 0.05, so
̂
I𝜋
0.1 = 2
3 ± z0.05
√
2
3(1 −2
3)
15
= (0.466, 0.867).
.
Hypothesis Testing
Frederick can’t quite hide his pride when he reveals to Sam that the technique
of hypothesis testing originated with the frequentist school, “but it is unfortu-
nately also the most misinterpreted one.”
Frederick continues: “So let us first see what classical, frequentist, hypothesis
testing is about, to make sure you understand hypothesis testing right.”
Sam nods: “Sounds great to me; I like understanding.
“I have understood what Bayesian hypothesis testing is,” he continues. “I find
the posterior probability distribution for 𝜃, and then I check the probability that
𝜃is smaller than some reference value 𝜃0. If that probability is less than a critical
value 𝛼, I conclude that 𝜃> 𝜃0.”
Frederick approves: “You understand that well. Our school does not speak
of any probability distributions for parameters like 𝜃, but instead regards the
conditional probability distributions of the data given that 𝜃= 𝜃0. For us, the
conservative hypothesis H0 is that 𝜃= 𝜃0, rather than that 𝜃is in some given
interval in the way of the Bayesians. The alternative hypothesis H1 comes in
three types: (i) 𝜃> 𝜃0, (ii) 𝜃< 𝜃0, (iii) 𝜃≠𝜃0.”
“OK,” Sam says, “I see that one. Any other differences?”
“Yes,” Frederick replies, “this is all about making decisions. In our school, we
weigh this decision between the possibilities of two types of error. We look at
the probability of committing the worse of these two kinds. Just as with confi-
dence intervals, it is all about probability in the aggregate, that is, how large a
share of our trials will end in this type of error in the long run, as opposed to
the Bayesian probability of making an error in a single trial. The two types of
error are type I and type II errors, as shown in Table 16.2.
“As long as you don’t actually know,” Frederick explains, “there is the possibil-
ity of error. If you reject H0, you may make an error. If you don’t reject H0, you
may also make an error. But one of these errors is in general considered more
serious: rejecting H0 when it is true. This is why the strictness of the hypothesis
test is based on how likely it is that we are making this type of error, measured
against a significance level 𝛼.”


16 Frequentist Inference⋆
Table .Error types
His true
His false
Not reject H0
Correct decision
Type II error
Reject H0
Type I error
Correct decision
“So only when the probability of H0 is less than 𝛼, you may reject H0,” Sam
intones.
“No, the probability of a parameter value is a Bayesian idea,” Frederick
explains. “We of the frequentist school don’t judge by any probability of the
parameter value, but rather by the probability of the data given the parameter.
Let me explain ... ”
“Oh, the other way around,” Sam nods. “Please do!”
“Our method starts from the default model, the null hypothesis H0.”
Frederick begins, “We want to devise our test so that, if H0 is true, the prob-
ability that our data will make us reject is less than some significance value 𝛼.
This is tantamount to finding a rejection region of data values that are in some
way too extreme for the model to be seen as a good explanation. The rejection
region will be the most extreme results, and the probability that the data end
up in that region will be less than 𝛼.”
“So in other words,” Sam interjects, “H0 is rejected when the data are too
extreme?”
“Yes,” Frederick confirms, “and we may determine this in one of two ways:
either we establish the region in advance, by finding a first too extreme value.
Then we reject H0 if our data are equally or more extreme. The other way is
by waiting for the actual data, and finding the probability p of getting data as
extreme as our actual data, or worse, given H0.”
“Hmm. I see that one,” Sam says, “for then what you call data as extreme
as ours, or worse will either be a subset of the rejection region, and then the
probability p will be at most 𝛼, or it will not, and then p will be bigger. But in
that case, our data are not in the rejection region.”
“I am impressed by your learning, Sam,” Fredrick smiles.
“Thank you,” Sam smiles in return, “then I understand about the type I errors.
But given again that H0 is true,” Sam queries, “what is the acceptable probability
of a type II error? Is that 𝛼as well, or is it 1 −𝛼?”
“That value is totally dependent on the exact value of 𝜃,” Frederick replies,
“which we don’t know. But it does in any case not matter for our decision pro-
cess. We focus on the type I error only, since that is the serious error.”
“Then I think I understand,” Sam responds thoughtfully, “but then it’s time
to learn the ropes – performing the techniques – isn’t it? Knowing is doing, as
they say.”

16.3 Hypothesis Testing

0
2
4
6
8
10
12 14
0
2
4
6
8
10
12
14
0
2
4
6
8
10
12
14
0.17
0.46
0.94
Parameter line
Observation lines:
Figure .Parameter and observation line for a Bernoulli process.
“I like the way you are thinking,” Frederick applauds, “so let us look at the
techniques. To understand the technique, it helps to draw two parallel lines:
one for the possible values of the parameter 𝜃, and one for the values of the
observations. I will illustrate this in the hypothesis test of the parameters p and
𝜇. Then, I will do a hypothesis test of 𝜎as well, and you will be equipped with
a good frequentist starter kit.”
..
Hypothesis Testing of Proportions
When we look at the parameter 𝜋for a Bernoulli process, the parameter line is
the range of possible values 𝜋, the probability of success, may take. In the case
of 𝜋, that means the interval [0, 1]. The other line, the observation line, consists
of the integers from 0 through n, where n is the number of trials. We illustrate
this in Figure 16.3.
“The exact calculation for this hypothesis test of p is as follows,” Frederick
says. “We will look at the quicker method via approximation afterwards. But
the exact method first, for the sake of understanding.”
Sam agrees.
Method 16.3.1 In a (right) one-sided frequentist hypothesis test of a pro-
portion 𝜋, the alternative hypothesis H1 is that 𝜋> 𝜋0, whereas the conser-
vative hypothesis H0 is that 𝜋= 𝜋0. The observations are from n Bernoulli
trials, and the number of successes are a stochastic variable X following a
binomial distribution with parameters n and the unknown 𝜋. From an obser-
vation of k successes, we find the p-value
p = P(X ≥k|𝜋= 𝜋0) =
n
∑
m=k
( n
m
)
𝜋m
0 (1 −𝜋0)n−m.


16 Frequentist Inference⋆
We perform the hypothesis test with significance level 𝛼; this means that the
result of the hypothesis test is given as follows.
r If p < 𝛼, we reject the null hypothesis H0.
r If p ≥𝛼, we don’t reject the null hypothesis H0.
In a (left-tailed) test, we turn the inequality in the calculation of p as
follows:
p = P(X ≤k|𝜋= 𝜋0) =
k
∑
m=0
( n
m
)
𝜋m
0 (1 −𝜋0)n−m.
In a two-sided test, we reject H0 with significance 𝛼iff (iff = “if and
only if”) we reject H0 in one of the two corresponding one-sided tests with
significance 𝛼
2.
Example 16.3.2 Sam arranges a Christmas dance party for a large company,
and thinks it would be good if there were roughly as many men as women.
He decides to investigate, and does this with significance 𝛼= 0.1, as nothing
stricter is required for a Christmas party. Let 𝜋be the proportion of men.
His alternative hypothesis is then that 𝜋≠1
2. The conservative hypothesis is
that 𝜋= 𝜋0 = 1
2. So far, n = 14 people have signed up for Sam’s party, whereof
k = 8 men. We look at both tails:
P(8 or more men) =
14
∑
m=8
(14
m
)
0.5m(1 −0.5)14−m = 0.3953 > 𝛼∕2
P(8 or fewer men) =
8
∑
m=0
(14
m
)
0.5m(1 −0.5)14−m = 0.7880 > 𝛼∕2
... and none of the numbers give any reason to reject H0, which means we don’t
reject the null hypothesis H0, which says that there is an equal chance that the
next guest joining will be a man as that it will be a woman.
“The quicker, approximate, calculation uses the Normal approximation
(10.1.13),” Frederick explains, “and since most textbooks drop the continuity
correction ± 1
2, so will we. But note that if we had calculated Example 16.3.2,
the correct Normal approximation would have needed to include the continu-
ity correction ± 1
2, giving us the respective numbers 0.394 6 and 0.788 7, which
are very close to the exact answer. Note that without the continuity correction,
we get 0.2965 and 0.703 5, which is quite a lot more off.
“But recall again that statistics is the art of being imprecise in a precise man-
ner,” Frederick smiles, “and as a rule of thumb, the quickest method is good
enough when we have in excess of 30 observations. This goes even without the

16.3 Hypothesis Testing

continuity correction, which after all takes some time to apply, and thus the
quick and good enough method is to use the uncorrected Normal approxima-
tion when you have more than 30 observations.”
Method 16.3.3 After n observations with k successes, let ̂𝜋= k∕n, and let
w =
̂𝜋−𝜋0
√
𝜋0(1−𝜋0)
n
.
Then z decides the hypothesis test thus:
Alternative
Reject H0 in favor of H1 if
hypothesis H1
Direct test (alt. 1)
Indirect test (alt. 2)
𝜋< 𝜋0
Φ(w) < 𝛼
w < z𝛼
𝜋> 𝜋0
Φ(−w) < 𝛼
−w < z𝛼
𝜋≠𝜋0
Φ(−|w|) < 𝛼
2
−|w| < z𝛼∕2
Notice that most textbooks use z𝛼= −Φ−1(𝛼), which gives positive values for
𝛼< 0.5, while we in this book use the inverse directly with z𝛼= Φ−1(𝛼), which
gives negative values for 𝛼< 0.5.
Example 16.3.4 The Aberdeen striker Adam Rooney scored 38 goals in the
last two seasons, whereof 29 with his right foot. Decide with significance
𝛼= 0.1 whether Rooney scores the majority of his goals with the right foot.
Answer: We are going to look at 𝜋, the proportion of goals he scores with his
right foot. The null hypothesis is that 𝜋= 𝜋0 = 0.5, whereas H1 is that 𝜋> 𝜋0.
Here, ̂𝜋= 29
38, so
w =
29
38 −0.5
√
0.5(1−0.5)
38
≈3.244 43.
We calculate this as follows both directly and indirectly, to show both
methods.
r Directly: Φ(−w) = Φ(−3.244 43) = 0.000 59 < 0.1, so we reject the null
hypothesis in favor of the alternative hypothesis that he scores the majority
of his goals with his right foot.
r Indirectly: −w = −3.244 43 < −1.281 55 = z0.1, so we reject the null hypoth-
esis in favor of the alternative hypothesis that he scores the majority of his
goals with his right foot.


16 Frequentist Inference⋆
0
20
200
40
60
80
100
1
120
0
20
40
60
80
100
120
Parameter line
Observation line
Figure .Parameter and observation line for a Gaussian process.
..
Hypothesis Testing for the Mean Value of Gaussian Processes
“When we looked at hypothesis testing of proportions,” Frederick says, “we saw
that the parameter line was the interval [0, 1], whereas the observation line was
the integers 0, … , n. The two could not be confused. But when we are working
with the Gaussian case, which means the Normal or t distribution, both of these
lines are the entire set of real numbers, ℝ, and the conditional distribution,
given that 𝜇= 𝜇0, is a Normal distribution centered at 𝜇0. We have illustrated
this in Figure 16.4.
“In a (right) one-sided hypothesis test for the mean 𝜇in a Normal distributed
population with variance 𝜎2,” Frederick explains, “an alternative hypothesis H1
is that 𝜇> 𝜇0, whereas the conservative hypothesis H0 is that 𝜇= 𝜇0. After n
observations, we calculate the p-value, the probability p that the average of the
measurements is at least as large as ̄x, and reject the null hypothesis if p < 𝛼.
“The common way to calculate this,” Frederick informs us, “is by defining
w =
⎧
⎪
⎪
⎨
⎪
⎪⎩
̄x −𝜇0
𝜎∕
√
n
if 𝜎is known
̄x −𝜇0
sx∕
√
n
if 𝜎is unknown
and then deciding the hypothesis in the same way as for the parameter 𝜋for
Bernoulli processes.
“Recall again that many textbooks use z𝛼= −Φ−1(𝛼) and t𝜈, 𝛼= −T−1
𝜈(𝛼),”
Frederick points out, “which gives positive values for 𝛼< 0.5, but that we in
this book use z𝛼= Φ−1(𝛼) and t𝜈, 𝛼= T−1
𝜈(𝛼), which gives negative values for
𝛼< 0.5.”
Method 16.3.5 For known 𝜎, we use w to decide the hypothesis as follows:
Alternative
Reject H0 in favor of H1 if
hypothesis H1
Direct test (alt. 1)
Indirect test (alt. 2)
𝜇< 𝜇0
Φ(w) < 𝛼
w < z𝛼
𝜇> 𝜇0
Φ(−w) < 𝛼
−w < z𝛼
𝜇≠𝜇0
Φ(−|w|) < 𝛼
2
−|w| < z𝛼∕2

16.3 Hypothesis Testing

Method 16.3.6 For unknown 𝜎, we use w to decide the hypothesis as fol-
lows, with 𝜈= n −1:
Alternative
Reject H0 in favor of H1 if
hypothesis H1
Direct test (alt. 1)
Indirect test (alt. 2)
𝜇< 𝜇0
T𝜈(w) < 𝛼
w < t𝜈, 𝛼
𝜇> 𝜇0
T𝜈(−w) < 𝛼
−w < t𝜈, 𝛼
𝜇≠𝜇0
T𝜈(−|w|) < 𝛼
2
−|w| < t𝜈, 𝛼∕2
Example 16.3.7
Cruising enthusiast Jamal claims that the dB pressure in
Newark’s cruising cars is higher than in East Orange’s. The cruisers of East
Orange have measured dB tested all their cruiser cars, and the mean dB pres-
sure was ̄x = 112.3 dB. Jamal won’t get any support for a comprehensive test
unless he can prove with reasonable certainty that he will get a better result.
He therefore decides to go for a hypothesis test of his claim. He chooses signif-
icance level 𝛼= 0.1.
He measures the dB pressure in 16 cars, and gets ̄x = 113.4 dB and sx =
6.4 dB. This means
w = 113.4 −112.3
6.4∕
√
16
= 0.687 5.
The reference value is the East Orange result of 𝜇0 = 112.3 dB, and the alter-
native hypothesis is that 𝜇, the mean dB pressure in Newark, is greater than 𝜇0,
in other words we have H1: 𝜇> 𝜇0. Direct calculation gives T15(−0.687 5) =
0.251 13 > 𝛼. Indirect calculation gives t𝜈,𝛼= t15, 0.1 = −1.340 61 < −0.687 5,
so −w < t𝜈, 𝛼doesn’t hold. Jamal sees from both the direct and the indirect cal-
culation that he can’t reject the null hypothesis with significance 𝛼= 0.1. This
means he can’t expect support for a comprehensive test of the dB pressure in
Newark’s cruiser cars.
..
Hypothesis Testing for the Variance of Gaussian Processes
“Consider a Normal distributed population where both 𝜇and 𝜎are unknown,”
Frederick begins. “When the variance 𝜎2 is unknown, we are often inter-
ested in knowing whether it is above or below some critical ‘null’ value 𝜎2
0. To
test the variance against the null value after n observations, we calculate SSx
(or s2
x = SSx
n−1).
“You determine the hypothesis either directly or indirectly,” Frederick says,
“and the most common method for us frequentists is the indirect one, with 𝜒2,
as shown in Note 16.2.1, whereas you Bayesians are more used to using Γ and
the direct method. So let us here, too, use Γ for the direct method, and 𝜒2 for
the indirect method.”


16 Frequentist Inference⋆
Method 16.3.8 Hypothesis test for variance: Use the statistics n and SSx,
and let 𝜈= n −1. With reference value 𝜎2
0 for the null hypothesis H0 : 𝜎2 =
𝜎2
0, and 𝜏0 = 1∕𝜎2
0, the hypothesis tests are determined as follows:
Alternative
Reject H0 in favor of H1 if
hypothesis H1
Direct test (alt. 1)
Indirect test (alt. 2)
𝜎2 < 𝜎2
0
Γ(
𝜈∕2,SSx∕2
)(𝜏0) < 𝛼
SSx
𝜎2
0
< 𝜒2
𝜈,𝛼
𝜎2 > 𝜎2
0
1 −Γ(
𝜈∕2,SSx∕2
)(𝜏0) < 𝛼
SSx
𝜎2
0
> 𝜒2
𝜈,1−𝛼
𝜎2 ≠𝜎2
0
Γ(
𝜈∕2,SSx∕2
)(𝜏0) < 𝛼
2
or
1 −Γ(
𝜈∕2,SSx∕2
)(𝜏0) < 𝛼
2
SSx
𝜎2
0
< 𝜒2
𝜈, 𝛼∕2
or
SSx
𝜎2
0
> 𝜒2
𝜈, 1−𝛼∕2
Example 16.3.9
A new EU directive is being proposed, concerning the
amount of soup in canned soups. The directive is currently being tried out in
Ireland, and Wyvern Broth has an inspector visiting to inspect their canned
Mulligatawny soups. The directive puts an upper limit on the variance of the
contents by insisting that the standard deviation be at most five grams. Does
Wyvern Broth’s Mulligatawny soup production satisfy the requirements? The
alternative hypothesis is that it does. H1 is then that 𝜎< 𝜎0 = 5, which we may
reformulate as 𝜎2 < 25 or 𝜏> 𝜏0 = 0.04.
The inspector weighs n = 10 cans, and gets {xi} = {398.0, 395.0, 399.0, 400.5,
398.5, 398.0, 401.5, 401.0, 402.0, 401.0}. This gives the other statistic, SSx =
41.725.
Direct
calculation
gives
Γ(9∕2,41.725∕2)
(
1
25
)
= Γ(4.5,20.862 5)(0.04) =
0.004 311 87, which is less than 𝛼= 0.05, so we reject the null hypothesis.
If we instead choose the indirect test, 𝜒2
9, 0.05 = 3.32511, whereas SSx
𝜎2
0
=
41.725
25
= 1.669. Since SSx
𝜎2
0
= 1.669 < 3.325 11 = 𝜒2
𝜈,𝛼, the indirect method also
tells us to reject the null hypothesis.
The inspector therefore gives Wyvern Broth a pass for the variance of the
cans.
.
Exercises
Interval Estimates
1
Find the P% = (1 −𝛼)100% interval estimates ̂I𝜇
𝛼and ̂I+
𝛼; 𝜎is known.
(a) 𝜎0 = 2. Data: {5.9, 5.8, 4.8, 4.7, 1.6, 2.8, 2.6, 5.8, 5.1, 4.1}. P% = 90%.

16.4 Exercises

(b) 𝜎0 = 12.1. 𝛼= 0.05. We have 47 observations with ̄x = 66.008 5.
(c) 𝜎0 = 3.73. P% = 99.9%. Statistics: n = 100 00, Sx = 274 046.
2
Find the P% = (1 −𝛼)100% interval estimates ̂I𝜇
𝛼, ̂I𝜎
𝛼(use that 𝜎= 1∕
√
𝜏)
and ̂I+
𝛼; 𝜎is unknown.
(a) 𝛼= 0.1. We have 29 observations with average ̄x = 8.206 9 and sample
standard deviation sx = 1.688 18.
(b) P% = 98%. We have 398 observations with average ̄x = 29.688 6 and
sample standard deviation sx = 4.724 27.
(c) You have examined mechanical wear on a certain flooring, and want
to find a 98% confidence interval for the mean wear. You examined 8
floors, and measured wear depths of respectively 49.3, 65.8, 55.5, 54.4,
58.7, 61.7, 63.2, 57.8 μm.
3
Find the (1 −𝛼)100% confidence interval ̂Ip
𝛼.
(a) k = 17 positive and l = 25 negative. 𝛼= 0.05.
(b) You have heard that Coca and Pepsi have an equal share in the Cola
market at your university, and decide to investigate if this is true. Your
investigations find 46 Pepsi drinkers and 54 Coca drinkers. Give a 90%
confidence interval for 𝜋, the proportion of Coca drinkers in your entire
university.
Hypothesis Testing
4
Determine the hypothesis test outcome about the parameter 𝜋for a
Bernoulli process; significance 𝛼.
(a) H1: 𝜋> 0.5. 𝛼= 0.05. Observations: k = 8 positive and l = 6 negative.
(b) H1: 𝜋< 0.25. 𝛼= 0.1. Observations: k = 2 positive and l = 18 negative.
(c) H1: 𝜋< 0.1. 𝛼= 0.05. Observations: k = 4 positive and l = 96 negative.
(d) H1: 𝜋≠0.5. 𝛼= 0.1. Observations: k = 40 positive and l = 60 negative.
(e) You have heard that Coca and Pepsi have an equal share in the Cola
market at your university, and decide to investigate if this is true. Your
investigations find 46 Pepsi drinkers and 54 Coca drinkers. Does this
suffice if you want to say their markets shares are unequal, with signifi-
cance 𝛼= 0.1?
5
Determine the hypothesis test outcome about the mean 𝜇for a Gaussian
process; significance 𝛼.
(a) H1: 𝜇≠25. 𝛼= 0.05. Statistics: n = 27, Sx = 715.333. 𝜎0 = 3.73
(known).
(b) H1: 𝜇> 80. 𝛼= 0.01. We have 200 observations with ̄x = 80.674 1.
𝜎0 = 5.1 (known).
(c) H1: 𝜇≠25. 𝛼= 0.02. Data: {28.1, 42.1, 22.7, 38.8, 28.8, 37.0, 20.4, 37.3}.
𝜎unknown.


16 Frequentist Inference⋆
(d) H1: 𝜇< 100. 𝛼= 0.005. Statistics: n = 500, Sx = 49 650, SSx = 53 803.8.
𝜎unknown.
6
It is claimed that the mean compression strength for a certain kind of steel
beam exceeds 60 000 psi, and you have decided to determine the test out-
come of this alternative hypothesis with 𝛼= 0.1. Your observations are
{60 060, 59 580, 60 498, 60 071, 60 593, 60 384, 60 013, 60 491, 60 321, 60 626,
59 897, 61 002, 60 149, 61 058, 60 901}.
7
Determine the hypothesis test outcome concerning the variance 𝜎2 of a
Gaussian process; significance 𝛼.
(a) H1: 𝜎2 < 100. 𝛼= 0.05. Data: {92.0, 86.3, 93.5, 111.4, 69.8, 106.0, 97.3,
78.7, 102.1, 106.6, 72.6, 107.4, 80.8, 87.8, 97.7}.
(b) H1: 𝜎2 > 25. 𝛼= 0.02. We have 100 observations with sample standard
deviation sx = 6.412 36.
8
We look at the steel beams in (Exercise 6) again. This time, we are testing
the variance, and the alternative hypothesis is H1: 𝜎≠666. Determine the
hypothesis test outcome with 𝛼= 0.1.



Linear Regression
CONTENTS
17.1
Linear Regression With Hyperparameters, 390
17.2 Frequentist Estimates for Linear Regression, 395
17.3 A Logarithmic Example, 395
17.4 Exercises, 400
In Section 3.3, we introduced the linear regression line, which was the straight
line with the smallest total square distance to the observations. We are now
going to study the regression line by means of statistical inference.
The basic assumption is simply that there is a relation between the two mag-
nitudes x and y that ideally fits a straight line
y(x) = a + bx.
This is thought to describe a real (but not directly observable) relation between
the variables. The difference between the value given by the line, and the actual
observation, may have many reasons: maybe there are other influencing factors,
or maybe there is an uncertainty in the measurement process – or maybe it’s
just some noise or uncertainty inherent in the value itself. But regardless of the
underlying reason for the deviations, we may treat them as noises following a
common Normal distribution, 𝜀∼𝜙(0,𝜎). This means that we see the observed
value as the value given by the linear relation, plus the noise. We have illustrated
this in Figure 17.1, and in the equation
y(x) = a + bx + 𝜀.
Linear regression is in other words described by 3 parameters: height a, slope
b, and precision 𝜏= 1∕𝜎2. Given these three parameters, the measured value
Y, given x, follows a Normal distribution:
Y(x) ∼𝜙(a+bx,𝜎).
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


17 Linear Regression
2
4
6
8
5
10
15
20
Figure .Linear relation, plus
noise.
.
Linear Regression With Hyperparameters
When we perform inference for the regression line, we go the opposite way,
as illustrated in Figure 17.2: instead of looking at how y sample values statisti-
cally arise from the parameters a, b of the line, and from the noise parameter
𝜏, we start with the observation pairs {(xi, yi)} – and any prior knowledge we
might have – and from that we estimate the precision parameter 𝜏and the line
parameters a and b. This gives us our best guess at the regression line
̂y(x) = 𝛼0 + 𝛽x = 𝛼∗+ 𝛽(x −̄x)
itself, but also a probability distribution for the possible values of y(x) given our
observations, centered at ̂y(x).
The data for linear regression are n observations (x1, y1), … , (xn, yn). The
sufficient statistics are n, Σx, SSx, Σy, SSe, and Σxy. You find these statistics by
calculating simple linear regression (Section 3.3).
The inference requires prior probability distributions in addition to the
observations. This means prior hyperparameters for a, b, and 𝜏. We should take
into account, however, that most of us are notoriously poor at estimating the
line parameters a and b, and even less reliable when it comes to stating how
certain these estimates are. And then the informative prior quickly turns into
a disinformative prior instead. For this reason, we will stick with neutral priors
for these parameters.
2
4
6
8
5
10
15
Figure .Observations, and
regression line as a best guess given
the uncertainty.

17.1 Linear Regression With Hyperparameters

The uncertainty parameter 𝜎, on the other hand, is curiously enough more
accessible to us. This is because it often concerns uncertainties in the measure-
ment process itself, but also because we do have a firmer grasp of the variation
of the y-values that go with some fixed x-value. We have therefore chosen to
retain the option of informative priors for 𝜎.
..
How-to
Prior for 𝜏or 𝜎: Let s0 be your best estimate on the uncertainty 𝜎, and let n0 be
how certain you are, expressed in observation equivalents. We will work with
𝜈0 = n0 −2 and SS0 = s2
0 × max(0, 𝜈0). If you don’t know, simply let 𝜈0 = −2 and
SS0 = 0. This makes your prior hyperparameters for 𝜎(𝜏) expressed by
P1 ⊧
𝜈0
SS0.
The other hyperparameters are implicitly given by the model, since we do not
allow informative priors for a or b.
Updating: The prior, together with the statistics from the matrix regression,
gives the posterior hyperparameters:
P1 ⊧
̄x = Σx∕n
𝛽=
[
𝛼0
𝛽
]
= (XTX)−1XTy
𝜈1 = 𝜈0 + n
SS1 = SS0 + SSe
or 𝛼∗instead of 𝛼0 if you are working with centered x data. Since 𝛼0 + 𝛽x =
𝛼∗+ 𝛽(x −̄x), and therefore 𝛼∗= 𝛼0 + 𝛽̄x, we may easily switch our notation
between the two.
We update in a single round only. If we add new data, the mean ̄x moves,
making the formulas for updating overly complicated. So you should instead
recalculate the relevant statistics for all the data, both old and new. Since this
is the final step, we may now read the probability distributions for the preci-
sion 𝜏= 𝜎−2, the slope b, the values of the regression line y(x), and the next
observation Y+(x). We get
𝜏∼𝛾( 𝜈1
2 , SS1
2
)
s2
1 = SS1
𝜈1
b ∼t(
𝛽,s1 ×
√1
SSx ,𝜈1
)
y(x) ∼t(
𝛼0+𝛽x,s1 ×
√1
n + 1
SSx (x−̄x)2,𝜈1
)
Y+(x) ∼t(
𝛼0+𝛽x+,s1 ×
√
1+ 1
n + 1
SSx (x−̄x)2,𝜈1
).
Notice that the neutral prior for 𝜎(𝜈0 = −2 and SS0 = 0), gives s2
1 = SSe
n−2 = s2
e.


17 Linear Regression
2
4
6
8
5
10
15
20
(a) The credible interval I0.2 and
probability distributions for y(x).
2
4
6
8
5
10
20
15
(b) The predictive interval I+
0.2 and
probability distributions for Y+ (x).
Figure .Plots of y(x) and Y+(x) with uncertainty and interval bands.
The 100 × (1 −2𝜃)% symmetric credible and predictive intervals, as illus-
trated in Figure 17.3, are given by
I2𝜃(x) = 𝛼0 + 𝛽x ± t𝜈1,𝜃× s1 ×
√
1
n +
1
SSx
(x −̄x)2
I+
2𝜃(x) = 𝛼0 + 𝛽x ± t𝜈1,𝜃× s1 ×
√
1 + 1
n +
1
SSx
(x −̄x)2.
If 𝜎is known well enough that we may count it as certain for all practical
purposes, let “known well enough” be approximated by “certainty”, and set
s1 = s0. With this approximation, 𝜈0 = ∞, and the t distributions in the for-
mulas above become Normal distributions with the same parameters, since
lim𝜈→∞t(𝜇,𝜎,𝜈) = 𝜙(𝜇,𝜎).
The difference between the curves for the credible intervals I𝜃for y(x), and
the predictive intervals I+
𝜃for Y+(x), is that the latter are always wider. Whereas
the precision of y(x) may be arbitrarily large, Y+(x) will never be more precise
than what the uncertainty/noise 𝜀∼𝜙(0,s0) allows. We see a credible and a pre-
dictive band of the same percentage in Figure 17.4.
Example 17.1.1 (Continuation of Example 3.3.7) We revisit the height/weight
data, and believe we know something about the variability of weights, so we set
s0 = 4. We tell ourselves that we are as sure of this as if we had made 5 to 10
observations. It is better to choose the lower number so as not to overshoot, so
we set n0 = 5. We want to find
(a) the posterior distribution of 𝜏;
(b) the posterior distribution of b;
(c) the posterior distribution of y(x);
(d) the 95% credible interval for y(x); and
(e) the 90% credible interval for Y+(x) when x = 181.

17.1 Linear Regression With Hyperparameters

1
2
3
4
5
10
15
−1
5
Figure .Comparison of I0.3(x) (blue, inner) and I+
0.3(x) (green, outer).
The prior hyperparameters are then
P0 ⊧
𝜈0 = n0 −2 = 5 −2 = 3
SS0 = s2
0 × max(0, 𝜈0) = 42 × 3 = 48.
Simple linear regression: We have n = 15 and Σh = 2 668.5, which means
̄x = 177.9. We write the x data in centered form, x∗
i = xi −̄x. We have calcu-
lated the simple linear regression before, in Example 3.3.7, and gotten
HT
∗H∗=
[
15
0
0
1 271.1
]
HT
∗v =
[
1 262
1 875.7
]
𝛽∗=
[
84.133 3
1.475 65
]
.
Updating requires calculating
SSe = vTv −𝛽T
∗HT
∗H∗𝛽∗= 7 127.85.
Then, P1 ⊧
̄x = 177.9
𝛽∗=
[
𝛼∗
𝛽
]
=
[
84.133 3
1.475 65
]
𝜈1 = 𝜈0 + n = 3 + 15 = 18
SS1 = SS0 + SSe = 48 + 7 127.85 = 7 175.85.
We may then answer the questions:
1) 𝜏∼𝛾( 18
2 , 7 175.9
2
)
2) b ∼t(
1.475 7,19.966 ×
√
1
1 271.1 ,18
)
3) y(x) ∼t(
84.133 3+1.475 65(x−177.9),19.966 4 ×
√1
15 +
1
1 271.1 (x−177.9)2,18
)


17 Linear Regression
4) Y+(x) ∼t(
84.133 3+1.475 65(x−177.9),19.966 4 ×
√
1+ 1
15 +
1
1271.1 (x−177.9)2,18
)
5) I0.05 = 84.133 3 + 1.475 65(x −177.9) ± 41.947 8 ×
√
1
15 +
1
1 271.1(x −177.9)2
6) I+
0.1 = 84.133 3 + 1.475 65(x −177.9) ± 34.622 9 ×
√
16
15 +
1
1271.1(x −177.9)2,
and so I+
0.1(181) = 88.707 9 ± 35.884 9 = (52.823, 124.593) .
Example 17.1.2 (Continuation of Examples 3.3.1 and 3.3.10) We were going
to restore old platforms. This time around, we are interested in finding
(a) a 90% credible interval for y(x); and
(b) a 90% predictive interval for the cost of the next platform, given x type 1
errors.
Prior: We consider 𝜎to be totally unknown, and so we set n0 = SS0 = 0. Then,
P0 ⊧
𝜈0 = n0 −2 = −2
SS0 = 0.
Data: The raw data are the pairs {(xi, yi)} = {(20, 121.56), (4, 104.23), (5, 108.08),
(19, 119.01), (10, 110.16)}, giving us ̄x = 11.6. We subtract ̄x from the x values,
and get centered data {(x∗
i , yi)} = {(8.4, 121.56), (−7.6, 104.23), (−6.6, 108.08),
(7.4, 119.01), (−1.6, 110.16)}. We leave the details of the calculations to the
reader, and note that, in centered form, we get
XT
∗X∗=
[
5
0
0
229.2
]
XT
∗y =
[
563.04
220.046
]
𝛽∗=
[
112.416
0.939 328
]
.
The total squared error, where the error is the distance between the observed
and the predicted value, is independent of whether we describe the line in cen-
tered form or not. From Example 3.3.10, we have SSe = 6.552 7. In the lower
right corner of XT
∗X∗, we find SSx = 229.2.
Updating : P1 ⊧
̄x = 11.6
𝛽∗=
[
𝛼∗
𝛽
]
=
[
112.416
0.939 328
]
𝜈1 = 𝜈0 + n = −2 + 5 = 3
SS1 = SS0 + SSe = 0 + 6.552 7 = 6.552 7.
Using that s1 × t3, 0.05 = 3.478 07, we get the intervals
(a) I0.1(x) = 112.608 + 0.960 061(x −58∕5) ± 3.478 07 ×
√
0.2 + (x −11.6)2
229.2
;
(b) I+
0.1(x) = 112.608 + 0.960 061(x −11.6) ± 3.478 07 ×
√
1.2 + (x −11.6)2
229.2
.

17.3 A Logarithmic Example

.
Frequentist Estimates for Linear Regression
The frequentist intervals for the regression line are identical to the corre-
sponding Bayesian intervals when 𝜎is completely unknown, which means that
Example 17.1.2 is an example of frequentist linear regression as well. Exchange
𝜈1 →n −2, and s1 →se =
√
SSe∕(n −2) and you get the frequentist formulas:
̂I𝜃(x) = 𝛼0 + 𝛽x ± tn−2, 𝜃∕2 × se ×
√
1
n +
1
SSx
(x −̄x)2
̂J𝜃(x) = 𝛼0 + 𝛽x ± tn−2, 𝜃∕2 × se ×
√
1 + 1
n +
1
SSx
(x −̄x)2.
The theoretical difference lies, as always, in the interpretation of what the
intervals mean.
.
A Logarithmic Example
Related data are not always linearly related, but may be related via some func-
tion, for instance a root, a logarithm, or a polynomial. We are not going into
the full study of all these regressions, but will look at an example that may whet
your appetite for further study. We are going to look at an industrial example
where we take the logarithms of both variables, and then find the linear rela-
tion between these. Working back from that, we then get a relation between
the original variables. The calculations for this example will be identical for a
frequentist and for a Bayesian using a neutral prior for an unknown 𝜎.
Example 17.3.1 We studied a welded joint in a certain type of machinery to
see how many cycles N this component lasts before breaking, given a tension
S on the component. The relation between the variables S and N is known to
be logarithmically linear, and our task is to find this relation, with uncertainty.
For Table 17.1, we add columns for log S and log N (here, log = log10).
r The first extra consideration is incomplete data. In Table 17.1, “↓” indicates
that the component had not failed after the completed set of five million
cycles. This means that we do not know how many cycles it would have taken
for it to fail, except that this number is in excess of the number of cycles it
had gone through. How do we handle such information? There are several
ways of handling incomplete data, and which one you choose depends on
the purpose of your calculations.
– Ideally, you use a weighting over the possible values, in other words a prob-
ability distribution. This does have the disadvantage of leading us far astray
from the neat formulas of an introductory statistics course and text.


17 Linear Regression
Table .Tension and lifecycles for the welded joint
S
N
X = log S
Y = log N
1
265
42 000
2.423 25
4.623 25
2
265
70 000
2.423 25
4.845 1
3
265
79 000
2.423 25
4.897 63
4
202
107 000
2.305 35
5.029 38
5
202
188 000
2.305 35
5.274 16
6
202
204 000
2.305 35
5.309 63
7
139
537 000
2.143 01
5.729 97
8
139
597 000
2.143 01
5.775 97
9
108
800 000
2.033 42
5.903 09
10
108
1 077 000
2.033 42
6.032 22
11
108
5 000 000↓
2.033 42
6.698 97↓
12
108
5 200 000↓
2.033 42
6.716 00↓
13
108
5 400 000↓
2.033 42
6.732 39↓
14
74
5 000 000↓
1.869 23
6.698 97↓
15
74
5 200 000↓
1.869 23
6.716 00↓
– You may choose to use the time the component survived as its lifetime.
Since the actual lifetime would have been at least as large as this number,
you will at least not overshoot the regression line.
– The incomplete data may indicate a “region of immortality”, where the
actual lifetime differs drastically from the relation binding the other data.
Such virtual immortality would, if actually explored, pull the regression
line far out from the line indicated by the data in the “main” region. If we
suspect this is the case, we should remember that most linear regressions
are nothing but good approximations valid only inside precisely just a lim-
ited region.
This indicates that it may be a good idea to omit the incomplete data,
and this is also what practitioners do. But we need to do this with care, so
as to avoid a bias in the opposite direction. Look at Figure 17.5. In our case,
if we omit the immortals (marked as red dots), we get for S = 108 that the
average lifetime is roughly 900 000 cycles. But we then get that, if the three
components that did not fail had failed just a little sooner, for instance at
4.9 million cycles, S = 108 would have implied an average lifetime of over
3 million cycles. This gives us the seeming paradox that earlier failure for
some components would imply a longer average lifetime! This means that
if we omit observations, we must also omit the other observations with
S = 108 or lower (blue dots, circled in red).
r The second extra consideration is the logarithmic relation. It may be logarith-
mic in only one variable, in which case we are looking for the linear regression
between X and log Y, or between log X and Y, or it may be double, as in this
case, where we must find the linear regression between log X and log Y.

17.3 A Logarithmic Example

100
150
200
250
5×104
1×105
5×105
1×106
5×106
Figure .The logarithmic data.
After these initial considerations, we proceed with the calculations, using the
logarithmic data. We choose to narrow the domain of the linear regression,
and keep only the first 8 results. We then calculate the centered x values (using
̄x = 2.308 75), and get the design matrix X∗and the response vector y for the
data:
X∗=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
1
0.114 268
1
0.114 268
1
0.114 268
1
−0.003 626 3
1
−0.003 626 3
1
−0.003 626 3
1
−0.165 963
1
−0.165 963
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
y =
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
4.623 25
4.845 1
4.897 63
5.029 38
5.274 16
5.309 63
5.729 97
5.775 97
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
.
This means that
XT
∗X∗=
[
8
0
0
0.094 298 5
]
(XT
∗X∗
)−1 =
[
0.125
0
0
10.604 6
]
XT
∗y =
[
41.485 1
−0.324 604
]
.


17 Linear Regression
100
150
200
250
5×104
1×105
5×105
1×106
5×106
Regression line
Figure .The logarithmic data with regression line.
We then get1
𝛽∗= (XT
∗X∗
)−1 XT
∗y =
[
5.185 64
−3.442 3
]
SSe = yTy −𝛽T
∗XT
∗X∗𝛽∗= 0.090 236 9.
The regression line between x and y, illustrated in Figure 17.6, is then
y = 5.185 64 −3.442 3(x −2.308 98).
We insert x = log S and y = log N, and get the following relation between S
and N:
log N = 5.185 64 −3.442 3(log S −2.308 98)
N = 10log N = 105.185 64−3.442 3(log S−2.308 98) = 1013.133 8−3.442 3 log S
= 1013.133 8 S−3.442 3 = 1.360 95 × 1013 S−3.442 3.
We now wish to find 95% interval estimates for the linear regression, as illus-
trated in Figure 17.7. We then use that s2
e = SSe∕(n −2) = 0.090 236 9∕6 =
0.015 039 5, which means se = 0.122 636, and that t6,0.025 = 2.446 91, and get
I𝜃(x) = 𝛼∗+ 𝛽(x −x) + 2.446 9 × 0.122 636
√
1
8 + (x −̄x)2
SSx
= 13.133 8 −3.442 3x ± 0.300 078
√
0.125 + (x −2.308 98)2
0.094 298 5
I𝜃(S) = 1.360 95 × 1013 S−3.442 3 × 10±0.300 078
√
0.125+(log S−2.308 98)2∕0.094 298 5.
1These calculations are sensitive to round-off errors, so your decimals might deviate somewhat
from our results, which were calculated using Mathematica®.

Epilogue

100
150
200
250
5×104
1×105
5×105
1×106
5×106
Regression line
95% confidence interval
credible interval
{
Figure .The logarithmic data with regression line and 95% interval curves.
The 95% predictive interval, as illustrated in Figure 17.8, is then
I+
𝜃(x) = 13.133 8 −3.442 3x ± 0.300 078
√
1.125 + (x −2.308 98)2
0.094 298 5
I+
𝜃(S) = 1.360 95 × 1013 S−3.442 3 × 10±0.300 078
√
1.125+(log S−2.308 98)2∕0.094 298 5.
Epilogue
We have travelled to the mountains of statistics and back. As befits the theme,
our travelling companions sit contemplating the big ship at the Smyril Line’s
ferry terminal. It is soon ready for departure to Iceland.
“My hard working friends,” Bard says as he gets up to board the ferry, “now
it’s time for us to say goodbye. My work is done. We have reached the shores of
the ocean of statistics, and here at the harbour … our journey together ends.
100
150
200
250
5×104
1×105
5×105
1×106
5×106
Regression line
95%
95% predictive interval
confidence interval
credible interval
{
Figure .The logarithmic data with regression line and 95% predictive curves.


17 Linear Regression
It feels sad to part from you, but it is not a sadness that springs from hurt and
harm, for you have grown on your journey and are ready to unfold your own
wings and soar.”
Bard gathers his suitcases and nods to his statistics colleague, “It’s time,
Froderick.”
“What does he mean by that?” Sam asks Frederick.
“We went on this journey together, Sam, to save the world from frequentism,”
Frederick replies, “and the world has indeed been saved … but not I.”
“You can’t mean what you’re saying. You can’t leave!” Sam says with eyes
growing misty.
Frederick gives Sam his notebook from their journey, before he too boards
the boat: “The last few pages are for you, Sam.”
.
Exercises
1
Volume training 1: In the problems below, you are given observational data
{(xi, yi)}, and information about 𝜎. Find the …
– posterior distribution of 𝜏.
– posterior distribution of y(x).
– posterior predictive distribution of Y+(x).
– P% = (1 −𝛼1)100% credible interval I𝛼1 for the regressions line y(x).
– Q% = (1 −𝛼2)100% predictive interval I+
𝛼2 for the next observation Y+(x).
(a) Data:
{(33.74, 260.1),
(28.71, 226.7),
(39.9, 300.3),
(43.29, 321),
(14.2, 112.3)} Uncertainty: 𝜎0 = 4 and n0 = 5. 𝛼1 = 0.05, 𝛼2 = 0.1.
(b) Data: {(1, 2), (2, 4), (3, 3)}. 𝜎unknown. P% = Q% = 90%.
(c) Data: {(2, 10), (3, 8), (4, 8), (6, 7)}. 𝜎0 = 0.5 and n0 = 4. 𝛼1 = 𝛼2 =
0.05.
(d) Data: {(0, 0), (1, 2), (2, 7), (3, 5)}. 𝜎unknown. P% = 90%, Q% = 95%.
(e) Data: {(−2, 7), (1, 5), (8, 6)}. 𝜎unknown. 𝛼1 = 𝛼2 = 0.02.
(f) Data: {(28, 24), (66, 69), (44, 48), (39, 44), (9, 9), (1, 15), (73, 64),
(41, 44)}. 𝜎0 = 7, n0 = 10. P% = Q% = 80%.
(g) Data: {(−2.9, 0.8), (43.7, 36.9), (16.4, 11.7), (47.3, 41.9), (25.5, 16.9),
(22.1, 23.1), (38.4, 42.4), (35.3, 38.8)}. 𝜎0 = 5.5, n0 = 6. 𝛼1 = 𝛼2 =
0.02.
(h) Data: {(135.1, 8.9), (208.7, 16.), (241.4, 16.5), (217.1, 6.6), (215.3, 7.7),
(154.8, 2.4), (263.8, 18.6)}. 𝜎unknown. P% = 95%, Q% = 90%.
2
Volume training 2: In the problems below, you are given observational data
{(xi, yi)}, and information about 𝜎. Find the …
– posterior distribution of 𝜏.
– posterior distribution of y(x).
– posterior predictive distribution of Y+(x).

17.4 Exercises

(a) Data: {(77, 3), (94, 19), (87, 8), (86, 21), (70, 1), (75, 8), (81, 1), (80, 16),
(91, 11), (98, 22), (82, 4), (86, 21), (101, 15), (75, 2), (83, 18), (87, 7),
(78, 15), (93, 12), (77, 8), (80, 12)}. 𝜎unknown.
(b) Data: {(23, −80), (2, 2), (22, −79), (20, −67), (10, −37), (−8, 41)}.
𝜎0 = 3 and n0 = 100 000.
(c) Data: {(46, 50), (100, 105), (64, 68), (3, 8), (82, 88), (48, 57)}. 𝜎0 = 2
and n0 = 1000.
3
Volume training 3: In the problems below, you are given observational data
{(xi, yi)}, and information about 𝜎. Find the …
– P% = (1 −𝛼1)100% credible interval I𝛼1 for the regressions line y(x).
– Q% = (1 −𝛼2)100% predictive interval I+
𝛼2 for the next observation Y+(x).
(a) Data: {(3, 22), (7, 16), (11, 8), (4, 21), (12, 13), (17, 3), (7, 11), (6, 14),
(13, 10), (2, 20), (15, 9), (13, 11), (14, 14), (15, 4), (8, 8), (12, 5), (16, 3),
(6, 9), (15, 0), (2, 19)}. 𝜎0 = 4 and n0 = 7. 𝛼1 = 0.08, 𝛼2 = 0.01.
(b) Data: {(10, 16), (26, 24), (22, 20), (23, 15), (26, 28)}. 𝜎0 = 0.5 and n0 =
30. P% = Q% = 93%.
(c) Data: {(10, 16), (26, 24), (22, 20), (23, 15), (26, 28)}. 𝜎unknown. 𝛼1 =
𝛼2 = 0.07.
4
The Norway Cup is a European football youth cup and training camp that
has arranged at Ekebergsletta in Oslo every year since 1972 (except for
in 1976, when the organizers, Bækkelagets Sportsklub, arranged the Oslo
Handball Cup instead). We are going to look at the trend in the number
of participating teams. To make this problem easy to calculate by hand, we
have chosen just a few of the years, 10 years apart:
Year
Teams
1975
710
1985
1204
1995
1228
2005
1535
2015
1639
Find the linear regression line for the number of teams as a function of the
year. Then find the interval estimate and the predictive interval when you
presuppose a neutral prior – both intervals at 90%.
5
In American football, there was a scandal where the New England Patriots
had inflated their balls rather poorly ahead of a decisive game against the
Indianapolis Colts. Our local football coach informs us that balls behave
differently when they are flaccid than when they are hard, and he wants to
demonstrate this to us with a ball that has been unused for a few months.


17 Linear Regression
He drops it from a height of 227 cm, and measures its bounce after having
inflated it with, respectively, 0, 1, 2, 3, and 4 pumps.
Pumps, x
Rebound height, y (cm)
0
95
1
111
2
115
3
122
4
129
The coach tells us the uncertainty in his measurements was 𝜎0 = 4 cm. He
was confident that this was an accurate assessment, so we assume n0 = ∞,
and use the Normal approximation t(m,s,∞) = 𝜙(m,s)(x).
(a) Find the linear regression line y = 𝛼+ 𝛽(x −x).
In the rest of this exercise, we will estimate the regression line
y(x) = a∗+ b(x −x).
(b) Find the posterior distribution of b.
(c) Find the posterior distribution of a∗.
(d) Find the probability distribution of the next observation of the rebound
height, given a total of 20 pumpings.
(e) Find a 90% credible interval for Y+, given x+ = 20 pumpings.
(f) Why is the linear regression a good model for the rebound height as a
function of the number of times the ball has been pumped? Why is the
linear regression a bad model?
6
The spectral slope is an important characteristic of voices and musical
instruments. The spectral slope is the slope b of the regression line between
ln x and y, where x is the frequency (measured in hertz), and y is the ampli-
tude (measured in decibels). You have made such measurements from a
recording of a singer who sings the vowel E. The measurements are
Measurement





x (Hz)
360
540
720
900
1080
y (dB)
−3
−13
−22
−25
−28
𝜎is unknown. Let z = ln x. We are going to look at the regression between
z and y.
(a) Find the regression line y = 𝛼∗+ 𝛽(z −z).
(b) Find the posterior probability distribution of the spectral slope b.
(c) A mathematics savvy vocal afficionado claims that this particular singer
has a greater spectral slope than −25 when he sings E. Determine this
hypothesis with significance 𝛼= 0.1.

17.4 Exercises

7
Investigate whether there is a (linear) relation between the weekly salaries
of the best UK football strikers and the number of goals they score, with
significance 𝛼= 0.2. We will be using data from 2015.
Player (Team)
Goals, x
Salary, y
Sergio Aguero (Manchester City)
25
£204 000
Harry Kane (Tottenham)
20
£35 000
Raheem Sterling (Liverpool)
7
£30 000
Peter Crouch (Stoke)
7
£43 000
8
You are investigating the solubility of xylose in water inside a pumping sys-
tem. The water is pressurized, so you get temperatures well in excess of
200◦C. The variables are temperature (x) and (maximum) grams of xylose
per liter (y). Your measurements are
x (◦C)
24
42
62
83
103
124
143
164
185
y (g/L)
497
811
1061 1592 2190 2543 3131 3601
4236
Present your conclusion in the form of a linear regression line, with uncer-
tainty. Indicate a 90% credible interval for solubility at 100◦C. Also indi-
cate a 90% predictive interval for a measurement of the solubility at 100◦C.
Explain the difference between the two.



A
Appendix
CONTENTS
A.1
Project, 405
A.2
Notation, Formulas, Functions, 408
A.3
Other Probability Distributions, 409
A.4 Processes, 414
A.
Project
Statistics is a central tool in professional studies, so it makes sense to tie what
could be an abstract subject concretely to the profession it is meant to serve.
One of the best ways to do this is simply to make concrete use of the statistical
tools in a project related to the profession itself. If possible, the project should
run through the entire statistics course, from data gathering and summary in
the first chapters to inference at the end of the course. We have the following
three main types of project.
Empirical
This is the basic form of project, and for most students also the best. The project
starts with data collection and basic calculations. You may also present your
data in tables and diagrams, all according to Chapters 2 and 3.
The grand analysis of the data comes later, in Part II of the book: Inference.
You or the lecturer may sneak a peek to see which probability distributions you
will need, and keep this in mind when you get to the part about probability
distributions. The probability distributions will then take on a more concrete
character for you, in that they come alive to you as they relate to your project.
However, the project does not start with gathering data. The project starts
when you, maybe with the help of an instructor, identify a professional question
that statistics may answer for you. The first thing you should write is therefore
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


A Appendix
a brief pre project report. It would be of help to get feedback and possibly course
corrections from an instructor.
The pre project report should first of all state what your project wants to
achieve, and why. Do you, for instance, want to know if oak is harder than birch?
Or maybe you want to know if flats consume less electricity per square meter
than houses do? Or maybe you suspect that there is some approximately linear
relation between the hardness and the durability of flooring? Though this is
very simple, and you may think this could be left until the end of the project, this
is actually the key part of the report, and needs to be done thoroughly before
the remainder of the project is undertaken.
The pre project report should also state how you are going to obtain your
data, and roughly how many measurements you are planning to do. An instruc-
tor may adjust this number. As a rule of thumb, never go below 30 measure-
ments. Exceptions are if the measurements are costly or time consuming. For
less demanding kinds of observations, you may well aim for a few hundred; this
does in particular go for questions of proportion.
Finally, state which inferential techniques you will be using. This is possible
to figure out on your own, but an instructor will be of valuable help here. You
may find that what you actually do along the way ends up differing from your
pre project, but it is always better to have a plan to guide your aim. Finally, write
down which probability distributions you believe you will be making the most
use of.
How long should your pre project report be? No more than one or two pages!
The pre project may then serve as a template for the final report.
Could or should you do the project in small groups? Absolutely! But for the
collective: only if each group member pulls their own weight. And for the indi-
vidual: only if you are active in all phases of the project, so that it serves as an
aid to learning statistics throughout the entire course and not just a small part.
Which kind of data will you be looking at? In principle, anything you wish,
but the main types are the following.
r Magnitudes. For instance weight, distance, resistance, money, lifetime,
blood pressure, and number of new customers. These kinds of data come
under Gaussian processes, and the key probability distributions are 𝜙, t, 𝛾,
bin, and F.
r Proportions. Here, the key measurements are simply success (⊤) and failure
(⊥), and the summary looks at the total number of each kind, but nothing
more. These kinds of data come under Bernoulli processes, and the key prob-
ability distributions are 𝛽, 𝜙, F, bin, nb, 𝛽b, and 𝛽nb.
r “Rare occurrences”. These may be waiting times, like waiting for clicks on a
Geiger counter, or the occurrence of some rare toad in a swamp, or the num-
ber of offspring in a given species. These kinds of data come under Poisson
processes, and the key probability distributions are 𝛾, pois, g𝛾, nb, 𝜙and F.

A.1 Project

r Pairwise data. Here, you gather data in pairs, for instance (height, weight)
or (cost, effect). These kinds of data come under linear regression, and the
key probability distributions are t, 𝛾, and 𝜙.
The project is rounded off by writing a project report, which should consist
of two parts. The first part is a presentation of what and why: what you found
out, with conclusions and illustrations, and an explanation of why you wanted
to find out what you did. Think of this part of your project as written for a
customer, or possibly for the management of your company. This part is what
you aim for when you write the what-and-why part of the pre project.
The other part of the project report is the how. Think of this part as some-
thing not intended for the customer, the management or any other end user,
but rather for technical experts who may be hired to evaluate the quality and
soundness of your results. This part should contain the raw data, and the cal-
culations, presented to a sufficient degree of detail that another student at your
own level would be able to follow what is stated. It may be helpful for groups to
meet up in pairs to read each other’s reports with this in mind.
Programming
Programming may mean many things, so this should be clarified by an instruc-
tor in advance. It may be anything from programming statistical functionality
on calculators or other tools that other course participants may also enjoy (we
are keenly interested in sharing such programs at http://bayesians.net, so please
contact us if you have anything to share), to programming statistical simula-
tions. These simulations may also be related to empirical investigations, and so
two groups may cooperate – each with their own project – one simulating and
the other empirical.
A programming project should also have a pre project report about the how
and why, and should of course end with a project report.
Theoretical
Theoretical projects at this level do not mean developing new theories, but
rather gathering information and evaluating the extent to which a company
or institution may need statistical analyses, and to compile an overview of how
statistics is already used. You will find that, more often than not, they are in
need of such analyses and calculations without being quite aware that this is
what they need, or what such an analysis may do for the company.
Here, too, a pre project report should indicate which areas of the company
or institution you believe would be most fruitful to study, and how you have
planned to evaluate the company’s needs for statistical analyses.
This kind of project requires a high degree of self-drivenness and motivation,
or a strong pre-existing conviction that the company has statistical needs that


A Appendix
are not being met, so we would recommend choosing the theoretical project
only if you have this degree of motivation.
A.
Notation, Formulas, Functions
A.2.1 An index is a unique identification tag for an element. Common indexes
are number, date, place, and kind. Indexes may be multiple, like a2,3 or a23,
or aGrimstad, 2009.08.27:18:27:31.05.
A.2.2 The index set is the set I of elements we wish to include.
A.2.3 Union
n
⋃
j=m
Aj =
⋃
j∈I={m,…,n}
Aj = Am ∪Am+1 ∪⋯∪An.
A.2.4 Intersection
n
⋂
j=m
Aj =
⋃
j∈I={m,…,n}
Aj = Am ∩Am+1 ∩⋯∩An.
A.2.5 Sum
n
∑
j=m
aj =
∑
j∈I={m,…,n}
aj = am + am+1 + ⋯+ an−1 + an.
A.2.6 Product
n
∏
j=m
ak =
∏
j∈I={m,…,n}
aj = am ⋅am+1 ⋅⋯⋅an−1 ⋅an.
If I = ∅, then
∏
k∈∅
ak = 1.
A.2.7 Faculty is defined for all n ∈ℕ0, and is: n! =
n
∏
k=1
k.
A.2.8 Multinomial:
(
n
k1,k2,…,km
)
=
n!
k1!⋅k2!⋅⋯⋅km!.
A.2.9
Binomial:
(
n
k
)
=
n!
k!⋅(n−k)!.
Note
that
(
n
k
)
=
(
n
k,n−k
)
,
and
that
(
n
k1, k2, … , km
)
=
(
n
k1
)
⋅
(n −k1
k2
)
⋅⋯⋅
(n −k1 −k2 −⋯−km−2
km−1
)
.
In calculator notation:
n!
(n −k)! = n nPr k
(n
k
)
= n nCr k
(
n
k1, k2, … , km
)
= (n nCr k1) × ⋯× ((n −k1 −⋯−km−2) nCr km−1).
A.2.10 Gamma function Γ(z):
Γ(n)
=
(n −1)!
when n ∈ℕ
Γ(z)
= ∫∞
0
tz−1e−tdt
when −z ∉ℕ0
Γ(z)
≈
(
z
e
)z √
2𝜋
z
for large z
Γ(n + 1
2) =
(2n)!
n!4n
√
𝜋
when n ∈ℕ

A.3 Other Probability Distributions

A.2.11 The little gamma function 𝛾(z, x):
𝛾(z, x) = ∫x
0 tz−1e−t dt
when −z ∉ℕ0
𝛾(z, ∞) =
Γ(z).
A.2.12 Generalized binomial:nCr =
(
n
r
)
=
Γ(n + 1)
Γ(r + 1)Γ(n −r + 1).
A.2.13 Pochhammer function:(p)q = Γ(p + q)
Γ(p)
.
A.2.14 Euler B function B(a, b):
B(a, b) = ∫1
0 ta−1(1 −t)b−1 dt = Γ(a)Γ(b)
Γ(a+b) .
A.2.15 The incomplete Euler Beta function B(a,b)(x):
B(a,b)(x) = ∫x
0 ta−1(1 −t)b−1 dt
for x ∈[0, 1].
A.2.16 𝛽function 𝛽(a,b):
𝛽(a,b)(t) =
1
B(a,b) ⋅ta−1(1 −t)b−1
for t ∈[0, 1].
A.2.17 Regularized Beta function I(a,b)(x):
I(a,b)(x) =
B(a,b)(x)
B(a,b)
= ∫x
0 𝛽(a,b)(x).
A.2.18 Geometric sum
B∑
k=A
rk:
B∑
k=A
rk = rA −rB+1
1 −r
∞
∑
k=A
rk =
rA
1 −r (when |r| < 1).
A.
Other Probability Distributions
In addition to the probability distributions we looked at in detail in Chapters 9
and 10, we have a few other probability distributions that come in handy for
our calculations. They are mainly variants of probability distributions where
some parameter itself follows a probability distribution rather than having a
fixed value.
We have no need of studying them in detail, but only need to know how to
use them and know their relations to other distributions. It is recommended
to program these functions into your calculator, or to see if there are any ready
programs in http://bayesians.net for your calculator.


A Appendix
A..
Snedecor–Fisher Distribution (“F distribution”)
The very first distribution we will look at is a distribution that is very useful for
calculating other distributions, since it is ubiquitous on advanced pocket cal-
culators, and many other probability distributions may be transformed into it.
F distribution: T ∼f(𝛼,𝛽)(t) is a continuous stochastic variable taking values
in [0, ∞). The probability distribution is
f(𝛼,𝛽)(t) =
√
(𝛼t)𝛼× 𝛽𝛽
(𝛼t+𝛽)𝛼+𝛽
t × B(𝛼∕2 , 𝛽∕2)
,
where B is the Euler Beta function (A.2.14). To express the cumulative
probability distribution, we use the incomplete Euler B function (A.2.15),
F(𝛼,𝛽)(t) =
B(𝛼∕2 , 𝛽∕2)(z)
B(𝛼∕2 , 𝛽∕2)
,
where z =
𝛼t
𝛼t+𝛽.
Expected value: 𝜇T =
𝛽
𝛽−2
Variance: 𝜎2
T =
2𝛽2(𝛼+𝛽−2)
𝛼(𝛽−4)(𝛽−2)2
Mathematica: FRatioDistribution[𝛼, 𝛽]
CASIO: F(𝛼,𝛽)(t) is FCD(0, t, 𝛼, 𝛽)
TI: F(𝛼,𝛽)(t) is Fcdf(0, t, 𝛼, 𝛽)
HP: F(𝛼,𝛽)(t) is fisher_cdf(𝛼, 𝛽, t)
Calculators that have the F distribution typically also have f and F−1. A dif-
ferent distribution h(t) may often be calculated through the F distribution, if
the cumulative distribution satisfies H(t) = F(𝛼,𝛽)(m(t)). Then the probability
distribution itself is the derivative, h(t) = m′(t) ⋅f(𝛼,𝛽)(m(t)), whereas H−1(p) =
m−1(F−1
(𝛼,𝛽)(p)). In the case where m(t) = kt, this reduces to h(t) = k ⋅f(𝛼,𝛽)(kt)
and H−1(p) = 1
k ⋅F−1
(𝛼,𝛽)(p).
A..
Two Compound Gamma Distributions
The first way to compound two gamma distributions is to divide one stochastic
variable by the other. This gives us the following rule.
Rule A.3.1 Pairwise gamma distributed variables: Let T1 ∼𝛾(k,𝜆)(t) and
T2 ∼𝛾(𝜅,𝜏)(t) be independent, and let m = 𝜅𝜆
k𝜏. Define the derived stochastic
variables Q = T1
T2 and Q∗= mQ. Then
Q∗∼f(2k,2𝜅)(t)
Q ∼m ⋅f(2k,2𝜅)(mt)
P(Q∗< t) = F(2k,2𝜅)(t)
P(Q < t) = F(2k,2𝜅)(mt).

A.3 Other Probability Distributions

The other way to compound two gamma distributions is when T ∼𝛾(k,𝜆) and
𝜆itself is not constant, but rather 𝜆∼𝛾(𝜅,𝜏). Then, T ∼g𝛾(k,𝜅,𝜏)(t). This distri-
bution is called the gamma–gamma distribution. It goes under other names,
not least the “Beta Prime distribution”, in which case it is written 𝛽II.
Gamma–gamma distribution: T ∼g𝛾(k,𝜅,𝜏)(t) is a continuous stochastic
variable taking values in [0, ∞). The probability distribution is
g𝛾(k,𝜅,𝜏)(t) =
1
B(k,𝜅)
⋅𝜏𝜅⋅tk−1
(𝜏+ t)𝜅+k ,
where B is the Euler Beta function (A.2.14). To express the cumulative
probability distribution, we use the incomplete Euler B function (A.2.15),
GΓ(k,𝜅,𝜏)(t) =
B(k,𝜅)
(
t
t+𝜏
)
B(k,𝜅)
.
Expected value: 𝜇T =
k𝜏
𝜅−1
Variance: 𝜎2
T = k𝜏2(𝜅+k−1)
(𝜅−2)(𝜅−1)2
Mathematica: BetaPrimeDistribution[k, 𝜅, 𝜏]
CASIO: GΓ(k,𝜅,𝜏)(t) is FCD(0, 𝜅t
k𝜏, 2k, 2𝜅)
TI: GΓ(k,𝜅,𝜏)(t) is Fcdf(0, 𝜅t
k𝜏, 2k, 2𝜅)
HP: GΓ(k,𝜅,𝜏)(t) is fisher_cdf(2k, 2𝜅, 𝜅t
k𝜏)
A..
(Negative) Binomial Distribution When p is Uncertain: 𝜷b and 𝜷nb
When the binomial parameter p itself is uncertain, following a probability dis-
tribution p ∼𝛽(a,b), we must refine our formulas for calculating binomial and
negative binomial probability. The new formulas exchange the parameter p
with the pair a, b, and we get the formulas below.
Beta-binomial distribution: when X ∼bin(n,p), and p ∼𝛽(a,b)(x), we may
express the probability distribution of X directly, as X ∼𝛽b(a,b,n)(x), where
𝛽b(a,b,n)(x) =
(n
x
)(a)x(b)n−x
(a + b)n
(See A.2.13 for (p)q.)
The cumulative probability distribution is
ßB(a,b,n)(x) =
x
∑
z=0
𝛽b(a,b,n)(z).
Expected value: 𝜇X =
na
a+b
Variance: 𝜎2
X =
nab(a+b+n)
(a+b)2(a+b+1)
Mathematica: BetaBinomialDistribution[a,b,n]


A Appendix
Beta-negative-binomial distribution: when X ∼nb(k,p) and p ∼𝛽(a,b)(x), we
may express the probability distribution of X directly, as X ∼𝛽nb(a,b,k)(x),
where
𝛽nb(a,b,k)(x) =
(x −1
k −1
) (a)k(b)x
(a + b)x+k
(See A.2.13 for (p)q.)
The cumulative probability distribution is
ßNB(a,b,k)(x) =
x
∑
z=0
𝛽nb(a,b,k)(z).
Expected value: 𝜇X =
bk
a−1
Variance: 𝜎2
X = kb(a+b−1)(a+k−1)
(a−2)(a−1)2
Mathematica: BetaNegativeBinomialDistribution[a,b,k]
The following rule may come in handy if you need to calculate manually, or
you are programming a calculator.
Rule A.3.2 The formulas for the 𝛽b and 𝛽nb distributions, broken down to
Γ functions, faculty, and binomial, look like this:
𝛽b(a,b,n)(x) =
(n
x
)
⋅
(
Γ(a+b)
Γ(a)Γ(b)
)
(
Γ(a+b+n)
Γ(a+x)Γ(b+n−x)
)
=
(n
x
)
⋅
(
a+b
a
)
⋅
ab
a+b
(
a+b+n
a+x
)
⋅(a+x)(b+n−x)
a+b+n
𝛽nb(a,b,k)(x) =
(
x + k −1
k −1
)
⋅
(
Γ(a+k)
Γ(a)
Γ(b+x)
Γ(b)
)
(
Γ(a+b+k+x)
Γ(a+b)
)
=
(
x + k −1
k −1
)
⋅
(
a+b
a
)
⋅a+b+k+x
a+b
(
a+b+k+x
a+k
)
⋅(a+k)(b+x)
ab
.
On some calculators, the latter formulations for each of the probability distri-
butions will work for integers only, since the binomial and faculty functions are
defined for integers only. However, see A.2.12 for how to handle non-integers
as arguments for those functions.
The Γ version works for all calculators that have the Γ function.
In practice, these functions occur after Bayesian updating for proportions,
and then the prior determines whether the posterior will be an integer or not. If

A.3 Other Probability Distributions

the prior hyperparameters are integers, then so are the posterior hyperparam-
eters, meaning that a and b in the distributions above are integers. The same
goes for half-integers (integer plus 1
2).
For half-integers, we may use from formula A.2.10 that Γ(n + 1
2) = (2n)!
n!4n
√
𝜋.
A..
Comparison of 𝜷Distributed Variables
Comparison of 𝛽distributed stochastic variables requires a bit of computing
power, but if you use the formula below, you will get an exact answer rather
than an approximation.
Rule A.3.3 If 𝜓∼𝛽(a,b) and 𝜋∼𝛽(𝜃,𝜌) are independent stochastic variables,
then
P(𝜓≤𝜋) =
𝜃−1
∑
k=0
B(a + k , b + 𝜌)
(𝜌+ k) ⋅B(k + 1 , 𝜌) ⋅B(a, b),
where the B function is as described in A.2.14 in Appendix A.2: B(a, b) =
Γ(a)Γ(b)
Γ(a+b) , so
P(𝜓≤𝜋) =
𝜃−1
∑
k=0
Γ(a + k)Γ(b + 𝜌)Γ(k + 𝜌+ 1)Γ(a + b)
(𝜌+ k)Γ(a)Γ(b)Γ(𝜌)Γ(k + 1)Γ(a + b + k + 𝜌).
We may rewrite this into a formula using faculty or binomials:
P(𝜓≤𝜋) =
𝜃−1
∑
k=0
(
a+b
a
)
⋅
(
k+𝜌
k
)
⋅ab𝜌(a + b + k + 𝜌)
(
a+b+k+𝜌
a+k
)
⋅(a + b)(k + 𝜌)(a + k)(b + 𝜌).
If you don’t have access to advanced calculating tools, you should settle for
a Normal approximation to the 𝛽distributions. The Normal approximation
works best when all the four parameters a, b, 𝜃, 𝜌are larger than 10, but if you
are cut off from exact calculation, the Normal approximation is the only game
in town, so you might as well use it. Just keep in mind that it is rather inaccu-
rate for small parameter values. With the Normal approximation, we get that
the difference 𝛿= 𝜓−𝜋between (the Normal approximations to) two 𝛽dis-
tributions follows a Normal distribution, thus:
𝛿∼𝜙(
a
a+b −𝜃
𝜃+𝜌,
√
ab
(a+b)2(a+b+1) +
𝜃𝜌
(𝜃+𝜌)2(𝜃+𝜌+1)
)
.
Then
P(𝜓≤𝜋) = Φ(
a
a+b −𝜃
𝜃+𝜌,
√
ab
(a+b)2(a+b+1) +
𝜃𝜌
(𝜃+𝜌)2(𝜃+𝜌+1)
)(0).


A Appendix
A.
Processes
In this book, we are looking at three stochastic processes:
r Bernoulli processes;
r Poisson processes; and
r Gaussian processes.
These are observational processes, describing the magnitudes we observe
under certain conditions. We will briefly look at their properties, and which
probability distributions belong to the processes. What these three processes
have in common is that the observations are independent.
A..
Bernoulli Processes
A Bernoulli process consists of a sequence of independent Bernoulli trials,
each of which has the same two outcomes ⊤and ⊥, and the same probability
p = P(⊤). When we speak of a sequence, we tend to think of it as a temporal
sequence where one trial happens after the other, as illustrated in Figures A.1
and A.2.
However, though the Bernoulli process is best studied when the trials come
in a sequence, much of the theory will come into play if the trials are ordered in
other ways, for instance on a surface, in a volume, or in any other way. As long
as you know there are n trials, it may be studied via the Bernoulli process (see
Figure A.3).
?
?
?
?
?
1
?
1 done
?
?
?
?
3
2
1
3 done
2
6
5
4
3
1
7
7 done
Just the results
Figure A.Bernoulli process: choices being made, in sequence.
Figure A.Bernoulli process: … and on it goes …
Figure A.Bernoulli on a surface.

A.4 Processes

We will now look at the key probability distributions involved with the
Bernoulli process. The first is the Bernoulli distribution itself (9.2), which
describes each of the trials, and which we looked at above.
A...
Known p
The key to the Bernoulli process is counting, and with a known Bernoulli
parameter p, we have the following two counting distributions.
1) bin(n,p)(k): the binomial distribution (Section 9.3) counts k, the number of
successes ⊤, given n Bernoulli trials with parameter p (Figure A.10). So
bin(n,p)(k) is the probability that n Bernoulli trials with parameter p will yield
k ⊤.
2) nb(k,p)(m): the negative binomial distribution (Section 9.5) counts m, the
number of failures ⊥, given that the Bernoulli process with parameter p
runs until k successes ⊤have been achieved (Figure A.5). So nb(k,p)(m) is the
probability that Bernoulli trials with parameter p yield m ⚪before they yield
its kth ⚫.
Addition rules
Rule A.4.1
If X1 ∼bin(m,p)(x) and X2 ∼bin(n,p)(x) are independent, and
X = X1 + X2, then
X ∼bin(m+n,p)(x).
In particular, if X ∼bin(n,p)(x), then X may be considered the sum of n
Bernoulli variables Xk ∼bin(1,p)(x) = bernp(x), as X = X1 + X2 + ⋯+ Xn.
Figure A.Twenty trials yielded five successes (⚫).
Figure A.Waiting for five successes (⚫): we first got twelve failures (⚪).
m=13
n=27
X =2
X =4
m+n=40
X=6
Figure A.X = X1 + X2.


A Appendix
1.
3.
2.
6.
5.
4.
Y =2
Y =7
Y =5
Y =11
Y =6
Y =0
Figure A.Number of ⚪before the next ⚫is Yk.
Rule A.4.2 If Y1 ∼nb(k,p)(y) and Y2 ∼nb(m,p)(y) are independent, and Y =
Y1 + Y2, then
Y ∼nb(k+m,p)(y).
In particular, if Y ∼bin(k,p)(y), then Y may be considered the sum of k geo-
metrically distributed variables Yi ∼nb(1,p)(x) = geomp(x), as Y = Y1 + Y2 +
⋯+ Yk. We see this illustrated in Figure A.7.
A...
Relations
Rule A.4.3 For a Bernoulli process with parameter p,
BIN(n,p)(k) = 1 −NB(k+1,p)(n −k −1),
or equivalently,
NB(k,p)(n) = 1 −BIN(n+k,p)(k −1).
Proof: The proof of this is simple if you read what the distributions say. Both
expressions concern a Poisson Bernoulli with rate p, and what happens up until
the nth trial. BIN(n,p)(k) is the probability that there will be k or fewer ⊤within
trial n.
For the other expression, NB(k+1,p)(n −k −1) is the probability that there will
be at most n −k −1 failures before the (k + 1)th success. Or in other words
that the (k + 1)th success will come no later than at trial number … n. Why n?
Because the number of trials equals the number of ⊤plus the number of ⊥,
and the number of ⊤will be precisely k + 1 since this is the (k + 1)th ⊤, and the
number of ⊥was just stated to be at most n −k −1. And (n −k −1) + (k + 1) = n.
The events “k or fewer ⊤within trial n” and “⊤number k + 1 comes at or
before trial n” are complementary, and hence
BIN(n,p)(k) + NB(k+1,p)(n −k −1) = 1,
which proves the rule.
This rule also implies that pois𝜆t(k) = ERL(k,𝜆)(t) −ERL(k+1,𝜆)(t).

A.4 Processes

A...
Unknown p
If p is not known, the most useful distribution for studying p itself is the beta
distribution (Section 10.5). When p ∼𝛽(a,b)(t), we get two counting distribu-
tions that are the counterparts of the two counting distributions for a known p,
but with p ∼𝛽(a,b)(t). The distributions are as follows.
1) 𝛽b(a,b,n)(k): the beta binomial distribution is the counterpart of the bino-
mial distribution, where the parameters a and b replace the parameter p
and express how p is distributed.
2) 𝛽nb(a,b,k)(m): the beta binomial distribution is the counterpart of the nega-
tive binomial distribution, where the parameters a and b replace the param-
eter p and express how p is distributed.
See Appendix A.3.3 for details about these two distributions.
A..
Poisson Process
The Poisson process is best understood as a refinement of the Bernoulli process.
The primary mode is when the events are ordered along a time line, but for our
spatially ordered brain, seeing the process as spread out over a surface gives a
good intuition of what is at play. We illustrate this in Figure A.8, where the grid
of a Bernoulli process is refined until, at the end, with infinite refinement, we
have a Poisson process.
For the purposes of process, however, we will stay with the temporal
sequence, and thus the line. The same limiting process takes place there, and so
we have an infinitely fine division of the timeline, where positive events occur
according to a certain rate 𝜆. In the steps of the limiting process, 𝜆= np where
n and p are binomial parameters. We illustrate the limit in Figure A.9.
We will now look at the key probability distributions involved with the
Poisson process. Note that the aspects of the Poisson process particularly
Figure A.Poisson on a surface, as a limit of Bernoulli processes.
0
Figure A.Poisson process along a line.


A Appendix
relevant to these distributions are described, together with the distributions
themselves, in Sections 9.6.1 and 10.3.2.
A...
Known Rate 𝝀
The Poisson process also has discrete occurrences, but, as opposed to the
Bernoulli process, the times, spaces, volumes, and intervals containing and sep-
arating the occurrences are not integers, but positive real numbers. For a known
rate parameter 𝜆, we then have the following two distributions.
1) pois𝜆t(x): the Poisson distribution (Section 9.6) counts the number of occur-
rences for a Poisson process with rate parameter 𝜆after t time units. More
precisely, pois𝜆t(x) is the probability of precisely x units when t time units
have passed. See Figure A.10 for an illustration of counting occurences in a
Poisson process over 26 time units. Note that this differs from the simpler
standard notation for the Poisson distribution, where the time is implicitly
set to “1 unit”, and the number of occurrences are distributed pois𝜆(x). The
Poisson process may also describe searches over volumes V, surfaces A, and
so on, where the rate of occurrence per unit remains a constant 𝜆. For the
Poisson distribution, the parameter is then 𝜆V, or 𝜆A, and so on. See also
the addition rule A.4.4 below. It is the continuous counterpart of what the
binomial distribution is for the Bernoulli process.
2) erl(k,𝜆)(t): the Erlang distribution (Section 10.3) measures t, the time k of
occurrences take for a Poisson process with rate parameter 𝜆(Figure A.11).
So erl(k,𝜆)(t) is the probability density that the kth occurrence happens at
time t. It is the continuous counterpart of what the negative binomial distri-
bution is for the Bernoulli process.
Addition rules
Rule A.4.4 If Z1 ∼pois𝜆1(x) and Z2 ∼pois𝜆2(x) are independent, and Z =
Z1 + Z2, then
Z ∼pois𝜆1+𝜆2(x).
0
Figure A.The number of occurrences during 26 time units is distributed Z ∼pois26𝜆. Here,
there were Z = 5 occurrences.
0
Figure A.The waiting time for four
occurrences is distributed W = erl(4,𝜆). Here, it
took W = 13.7 time units.

A.4 Processes

Z=5
Z =2
Z =4
k=8
κ=16
k+κ=24
Figure A.Z = Z1 + Z2.
0
W =2.9
1.
3.
2.
5.
4.
W =3.7
W =1.1
W =6
W =7.7
Figure A.The Erlang waiting time for five occurrences is the sum of five exponential
waiting times for the individual occurrences.
This rule says that, for a Poisson process with parameter 𝜆, the number of
occurrences in two distinct intervals (or areas, volumes, and so on) equals the
number of occurrences in the first, plus the number of occurrences in the other.
We see this illustrated in Figure A.12.
Rule A.4.5
If W1 ∼erl(k,𝜆)(t) and W2 ∼erl(𝜅,𝜆)(t) are independent, and
W = W1 + W2, then
W ∼erl(k+𝜅,𝜆)(t).
In particular, if W ∼erl(k,𝜆)(t), then W may be considered the sum of k expo-
nentially distributed variables Wi ∼erl(1,𝜆)(t) = exp𝜆(t), as W = W1 + W2 +
⋯+ Wk. We see this illustrated in Figure A.13.
A...
Relations
An important relationship is that when the waiting time for one occurrence
in the Poisson process is Tj ∼exp𝜆(t), the waiting time for k occurrences is
T = T1 + ⋯+ Tk, and then T ∼erl(k,𝜆)(t). We see that the Poisson process is
the continuous counterpart of the Bernoulli process:
Process:
Bernoulli(p) ↔Poisson(𝜆)
Waiting time for one occurrence:
geomp(x) ↔exp𝜆(x)
Waiting time for n occurrences:
nb(n,p)(x) ↔erl(n,𝜆)(x)
Number of occurrences:
bin(n,p)(x) ↔pois𝜆t(x).
Rule A.4.3 for the Bernoulli process has the following counterpart for the
Poisson process, which is actually neater and more elegant in the continuous
Poisson case.


A Appendix
Rule A.4.6 For a Poisson process with parameter 𝜆,
POIS𝜆t(k) = 1 −ERL(k+1,𝜆)(t),
or equivalently,
ERL(k,𝜆)(t) = 1 −POIS𝜆t(k −1).
Proof: The proof of this is simple if you read what the distributions say. Both
expressions concern a Poisson process with rate 𝜆, and what happens before
time t. POIS𝜆t(k) is the probability that there will be k or fewer occurrences
before time t. For the other expression, ERL(k+1,𝜆)(t) is the probability that the
time it took for k + 1 occurrences was at most t, or in other words that, by
time t, there were k + 1 or more occurrences. So the first expression says k or
fewer, and the second says k + 1 or more, which means they are complementary,
and so
POIS𝜆t(k) + ERL(k+1,𝜆)(t) = 1,
which proves the rule.
This rule also implies that pois𝜆t(k) = ERL(k,𝜆)(t) −ERL(k+1,𝜆)(t).
A...
Unknown Rate 𝝀
If 𝜆is not known, the most useful distribution for studying 𝜆itself is the
gamma distribution (Section 10.3). When 𝜆∼𝛾(𝜅,𝜏)(t), we get two distributions
which are the counterparts of the two distributions for a known 𝜆, but with
𝜆∼𝛾(𝜅,𝜏)(t). The distributions are as follows.
1) nb(k,p)(x), the negative binomial distribution, where the parameters k = 𝜅
and p =
𝜏
𝜏+𝜃, is the counterpart of the Poisson distribution pois𝜆𝜃(x) as the
distribution counting how many occurrences x you may find in 𝜃units.
2) g𝛾(k,𝜅,𝜏)(t), the gamma–gamma distribution, is the counterpart of the Erlang
distribution erl(k,𝜆)(t) measuring how long a time it takes for k occurrences
of the Poisson process.
See Section 13.3 for details.
A..
Gaussian Process
The Gaussian distribution, or as we prefer to call it, the Normal distribution,
may also be seen as a limiting case of the binomial distribution, as we saw in
Section 9.3.4. The Gaussian processes are, however, best studied in their own
right.
There are, also, many processes that are called Gaussian. We shall concen-
trate on only one type: a sequence of independent stochastic variables that

A.4 Processes

Figure A.The model: five weights independently sampled from a Gaussian distribution
𝜙(𝜇,𝜎).
follow identical Gaussian distributions, {Xk}∞
k=1, Xk ∼𝜙(𝜇,𝜎). So we have one
measurement per positive integer, where each measurement is sampled from
the same Normal distribution 𝜙(𝜇,𝜎). This is illustrated in Figure A.14.
A...
Known Parameter 𝝈
The two relevant distributions in this case are the Normal distribution itself
(Section 10.1), and by extension, the multiNormal distribution with a mean
with entries all 𝜇, and diagonal covariance matrix with diagonal entries all equal
to 𝜎2.
A...
Unknown Parameter 𝝈
In statistical inference, we do not know the distribution they were sampled
from, and so at least one of the parameters is partially or wholly unknown.
We only have the data themselves, and maybe some prior information, to work
with. This is illustrated in Figure A.15.
Weight
Figure A.The reality: five cats whose weights follow a Gaussian distribution 𝜙(𝜇,𝜎) with
unknown parameters 𝜇and 𝜎.


A Appendix
The two relevant distribution in this case are as follows.
1) 𝛾(k,𝜆)(t) is the most useful probability distribution for describing the preci-
sion parameter 𝜏= 1∕𝜎2.
2) The t distribution: if X follows a Normal distribution with precision param-
eter 𝜏, and 𝜏itself is 𝛾distributed, then X actually follows a t distribution.
A...
The Parameter 𝝁?
Whether the parameter 𝜇is known or unknown does not influence which dis-
tributions are relevant.


B
Solutions to Exercises
CONTENTS
B.1
Introduction, 423
B.2
Data, 424
B.3
Multidimensional Data, 425
B.4
Set Theory and Combinatorics, 427
B.5
Probability, 430
B.6
Bayes’Theorem, 434
B.7
Stochastic Variables on R, 445
B.8
Stochastic Variables II, 450
B.9
Discrete Distributions, 453
B.10 Continuous Distributions, 458
B.11 Inference: Introduction, 465
B.12 Bayes’Theorem for Distributions, 466
B.13 Bayes’Theorem with Hyperparameters, 470
B.14 Bayesian Hypothesis Testing, 475
B.15 Estimates, 479
B.16 Frequentist Inference, 482
B.17 Linear Regression, 485
B.
Introduction
1
Review: Read the chapter itself until you have found your answers.
2
The symmetrical alternatives are sequences of H and T. The best way to
sort them is alphabetically: HHH, HHT, HTH, HTT, THH, THT, TTH,
TTT. We count a total of eight sequences, of which three (HHT, HTH, and
THH) have two heads and one tails, so
P(2H and 1T) = 3
8.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


B Solutions to Exercises
3
We make a table like the one we did for D4 and D6 above, and get 36 squares.
We write in the outcomes of the two D6 dice. The squares with sum three
are (1, 2) and (2, 1), so
P(3) = 2
36 = 1
18.
The squares with sum seven are far more numerous. They are (1, 6), (2, 5),
(3, 4), (4, 3), (5, 2), and (6, 1), so
P(7) = 6
36 = 1
6.
So if you are betting on the outcome of a toss of two 6-sided dice, it pays to
bet on seven rather than on three.
4
Yes. By the frequentist definition, this means that the probability of burning
a given pancake is 0.137. We will later see how the Bayesian probability also
converges to 0.137 as the number of pancakes increases.
B.
Data
1
Review: Read the chapter itself until you have found your answers.
2
Measures of location:
(a) i. Mode = 2443 (Drevsjø; central location near Femunden, and has the
most members)
ii. Median = 6020 ( ˚Alesund; is in the list, but with few members, and
far away from Femunden)
iii. Mean = 4859 (Postal code Nedenes, a small place down south far
away from Femunden, not in list)
iv. Mode is best.
(b) i. Mode = 0 NOK
ii. Median = 359 500 NOK
iii. Mean = 1.74 NOK
iv. Median is the most representative.
(c) i. Mode = 0 NOK
ii. Median = 0 NOK
iii. Mean = 194 000 NOK
iv. Mean is the most representative.
3
The position number … The vowels are a, e, i, o, u, and their positions are
1, 5, 9, 15, 21. Σx = 51, so the mean = 10.2, the median = 9, and since Σx2 =
773, then SSx = 252.8, which means the population standard deviation is
𝜎x = 15.9.

B.3 Multidimensional Data

4
To find the answers in Mathematica/Wolfram Alpha, write Median[list],…,
Mean[list], StandardDeviation[list]. The interquartile range is a bit heftier,
since there are about 20 different versions of it, and you have to specify
which:
Quantile[theList, 3/4, {{1, −1}, {0, 1}}] −Quantile[theList, 1/4, {{1,
−1}, {0, 1}}].
For the exercises, we get:
(a) ̃x = −1, Q3 −Q1 = 7, ̄x = 0, sx =
√
13
(b) ̃y = 0.4, Q3 −Q1 = 10.55, ̄y = 3.577 78, sy = 5.314 55
(c) ̃z = 68, Q3 −Q1 = 58.25, ̄z = 78.5, sz = 36.582 8
(d) ̃w = 0.659 64, Q3 −Q1 = 0.519 295, ̄w = 0.684 33, sw = 0.267 304.
5
The numbers are:
(a) ̃y = 5.8, Q3 −Q1 = 0.8, ̄y = 5.675, sy = 0.498 428
(b) ̃z = 7, Q3 −Q1 = 4, ̄z = 6, sz = 3.265 99
(c) ̃w = 0.375 471, Q3 −Q1 = 0.331 882, ̄w = 0.368 707, sw = 0.196 231.
6
You are in charge of …
(a) …
(b) bS = 7, bM = 8, bL = 8, bXL = 11, bXXL = 12, b3XL = 12, and
vS = 90.5, vM = 98, vL = 106, vXL = 115.5, vXXL = 127, v3XL = 139
(c) ̃x = 112.789, Q1 = 101.068, and Q3 = 121.71
(d) ̄x = 112.803, and s2
x = 171.877.
7
We give the values only – no diagrams or tables:
(a) ̃x = 18, Q3 −Q1 = 6, ̄x = 18, sx = 3.481 55
(b) ̃x = 45, Q3 −Q1 = 30, ̄x = 45, sx = 22.972 8
(c) ̃x = 0.343 636, Q3 −Q1 = 0.486 920, ̄x = 0.401 4, sx = 0.288 17.
8
A randomized survey …
(a) …
(b) Intervals: (0, 13), (13, 19), (19, 35), (35, 51), (51, 65), (65, 81) (If you are
12.95 years old, your stated age is 12.) Finding bk and vk is straightfor-
ward.
(c) ̃x = 40.793 1 and Q1 = 29.146 3 and Q3 = 50.724 1
(d) ̄x = 40.357 6 and sx = 14.324 8.
The solution here will depend on your specific jelly worms.
B.
Multidimensional Data
1
Review: Read the chapter itself until you have found your answers.


B Solutions to Exercises
2
You are given the data set …
(a)
k
xk
yk
1
−1
3
2
0
5
3
3
9
4
5
7
(b) Diagram: Plot the four points in an xy coordinate system.
(c) Covariance: 𝜎xy = 17
4 = 4.25 and sxy = 17
3 ≈5.666 67.
(d) Correlation: 𝜌xy = rxy =
17
√
455 ≈0.796 972.
3
You are given the data set …
(a) D∗= {(x∗, y)}i∈I = {(−2.75, 3), (−1.75, 5), (1.25, 9), (3.25, 7)}
(b) 𝛽= 0.747 253
(c) y = 6 + 0.747 253(x −1.75)
(d) y = 4.692 31 + 0.747 253x
(e) Multivariate calculus:
i. f (a, b) = (ya,b(xi) −yi)2 = ∑4
i=1(a + bxi −yi)2 = (a −b −3)2 +
(a + 3b −9)2 + (a + 5b −7)2 + (a −5)2 = 4a2 + 14ab −48a +
35b2 −118b + 164;
ii. fa = 𝜕
𝜕a f = 8a + 14b −48 and fb = 𝜕
𝜕b f = 14a + 70b −118, so fa =
fb = 0 gives the solution a = 61
13 ≈4.692 31 and b = 68
91 ≈0.747 253;
iii. y = 4.692 31 + 0.747 253x.
(f) Yes, they are identical, and shall be identical. Always.
(g) y(10) = 4.692 31 + 0.747 253 × 10 = 12.164 8.
(h)
−2
0
2
4
2
4
6
8
10
4
For the data sets below, calculate the following.
r The covariances 𝜎xy and sxy.
r The correlation between x and y.
r The linear regression line. Use matrix regression.
r The square of the standard error, s2
e.
r Illustrate at least one of them with a regression line and data points.

B.4 Set Theory and Combinatorics

(a) 𝜎xy = 182.928,
sxy = 203.253,
𝜌xy = 0.351 942,
y = 182.72 +
1.748 17(x −93.6) = 19.091 7 + 1.748 17x and s2
e = 2 827.5
(b) 𝜎xy = 21.007 2,
sxy = 26.259,
𝜌xy = 0.880 048,
y = 2.136 +
0.549 377(x −4.688) = −0.439 478 + 0.549 377x, and s2
e = 5.600 83
(c) 𝜎xy = 462.359,
sxy = 528.411,
𝜌xy = 0.966 852,
y = 39.625 +
0.847 613(x −37.625) = 7.733 58 + 0.847 613x, and s2
e = 36.443 7.
5
For the data sets below, calculate the following.
r The linear regression surface. Use matrix regression.
r The square of the standard error, s2
e.
(a) y = 38.271 6 −3.896 61x1 + 15.477 4x2, and s2
e = 1 819.11
(b) y = 75.815 5 + 0.167 863x1 −0.124 208x2, and s2
e = 481.789
(c) y = 67.736 2 + 0.201 929x1 + 0.345 562x2, and s2
e = 6.576 54.
B.
Set Theory and Combinatorics
Set Theory
1
Review: Read the chapter itself until you have found your answers.
2
A ⧵(B ∩C) = {a, b, c, d, e, h, i, j} (equal to A itself).
3
…
(a) 21.
(b) KM.
(c) K ∪M.
(d) |K ∪M| = |K| + |M| −|KM|.
4
…
(a) 7.
(b) P ∪J.
(c) PJ.
(d) |P ∪J| = |P| + |J| −|PJ|.
5
…
(a) 47
60.
(b) p(D ∪L) = p(D) + p(L) −p(DL).
6
…
(a) 1
5.
(b) p(SL) = p(S) + p(L) −p(S ∪L).


B Solutions to Exercises
7
…
(a) Ac = {yellow, blue}.
(b) A ∪B{red, orange, yellow, green, blue, indigo, violet}, and thus equal
to Ω.
(c) A ∩B = {green}.
(d) A ⧵B = {red, orange, indigo, violet}.
(e) B ⧵A = {yellow, blue}.
(f) Yes.
(g) No.
(h) No.
(i) No.
(j) No.
Combinatorics
8
(
28
2,3,5,7,11
)
= 1 052 427 228 652 800.
9
(
231
4
)
= 115 584 315.
10
(
80
58
)
=
(
80
22
)
= 27 088 786 024 742 634 400.
11
…
(
12
7
)
= 792.
12
(
7
3
)
= 35.
13
(
60
13
)
= 5 166 863 427 600.
14
6 ⋅5 = 30.
15
(
5
3
)
= 10.
16
(
7
3
)
= 35.
17
…
(a) 90.
(b) …
(c) …

B.4 Set Theory and Combinatorics

18
Cinema: …
(a) 25 ⋅24 = 600.
(b) 24 + 24 = 48.
(c)
48
600 = 0.08.
19
…
(a) 3.
(b) 3.
(c) When the other guy picks his cookies, he has by that picked the other
two for you. Conversely, once you have grabbed your two, you have
chosen the remaining cookie for him.
20
…
(a)
(
8
3
)
= 56.
(b)
(
8
5
)
= 56.
(c) When you pick 3 women to invite to your party, you have by that cho-
sen the remaining 5 for Bram. Conversely, when he has chosen his 5,
he has thereby chosen the remaining 3 for you.
21
…
(a)
(
52
30
)
= 270 533 919 634 160.
(b)
(
52
22
)
= 270 533 919 634 160.
(c) If you see two piles of cards of 20 and 32 cards, respectively, there is
no way to tell which pile was actively chosen, and which one got the
remainder.
22
…
(a)
(
70
47
)
= 1 791 608 261 879 217 600.
(b)
(
70
23
)
= 1 791 608 261 879 217 600.
(c) If you see a rosebush of 47 red and 23 white roses, respectively, there is
no way to tell which color was actively chosen, and which one got the
remainder.
23
…
(a)
(
n
s
)
.
(b)
(
n
n−s
)
.
(c) Because
(
n
s
)
=
n!
s!(n−s)! =
n!
(n−s)!s! =
(
n
n−s
)
.
24
(
34
8,5,9,12
)
= 351 045 037 084 341 600.


B Solutions to Exercises
25
Repeated sampling: …
(a) 125 = 248 832.
(b)
(
12+5−1
5
)
= 4 368.
(c)
12!
(12−5)! = 95 040.
(d)
(
12
5
)
= 792.
(e) …
B.
Probability
1
Review: Read the chapter itself until you have found your answers.
Exploration
2
Coin flipping: …
3
Resistors: …
Deﬁnitions
4
The cooler: your local corner supermarket
(a) 0 or 100%, but you do not know which until you have checked the
carton.
(b) 1
5 = 20%.
5
The cooler II: …
(a) Estimate: 1
5 = 20%, since a frequentist regards future occurrences to
be ruled by randomness, and thus subject to probability.
(b) 1
5 = 20%; i.e. the same answer as in the previous problem, since objec-
tive Bayesian probability is degree of knowledge.
Basic Probability
6
1 −p = 0.63.
Conditional Probability
7
(a) P(A ∪B) = 0.625
(b) P(A|B) = 0.5
(c) P(B|A) = 0.25
8
P(B) = 0.25

B.5 Probability

9
P(3) = 0.25
10
(a) P(AB) = 1
15
(b) P(A ∪B) = 31
60
(c) P(A|B) = 4
15
11
(a) P(AB) = 0.075
(b) P(A ∪B) = 0.425
(c) P(A|B) = 0.375
12
P(A|B) = 1
3
13
P(B|A) = 0.2
14
…
Repeated Sampling
15
P(HHTHTHHHTTTHHHHTTHTHTHHT) = 8.876 × 10−9
16
P(14 heads in 37 flips) = 0.133 5
17
P(21 heads in 47 flips) = 0.060 7
18
P(30 heads in 60 flips) = 0.023 2
19
Assorted Candies I: you are tidying up after a party, …
(a) 0.35.
(b) The respective probabilities are P(0 Almond Joy) = 0.116 029, P(1
Almond Joy) = 0.312 386, P(2 Almond Joy) = 0.336 416, P(3 Almond
Joy) = 0.181 147, P(4 Almond Joy) = 0.048 770 3, P(5 Almond Joy) =
0.005 252 19.
(c) The respective probabilities are P(0 Almond Joy) = 0.083 010 8, P(1
Almond Joy) = 0.322 82, P(2 Almond Joy) = 0.387 384, P(3 Almond
Joy) = 0.176 084, P(4 Almond Joy) = 0.029 347 3, P(5 Almond Joy) =
0.001 354 49.
20
You have a box of 40 fuses …
(a) P(YBBROBROV) = 3.980 65 × 10−7 (with replacement).
(b) P(YBBROBROV) = 6.257 75 × 10−7 (without replacement).
(c) P(1V, 3B, 2R, 2O, 1Y) = 0.006 018 75 (with replacement).
(d) P(1V, 3B, 2R, 2O, 1Y) = 0.009 461 71 (without replacement).


B Solutions to Exercises
21
P = 0.112 668
22
P = 0.000 853 512
23
You have flipped a coin 50 times.
(a)
(
1
2
)50
≈8.881 78 × 10−16
(b)
(
1
2
)50
≈8.881 78 × 10−16
(c)
(
50
27
)
= 108 043 253 365 600
(d) 1 125 899 906 842 624
(e) We can calculate this in two ways, since P(H) = P(T) = 0.5:
r
108 043 253 365 600
1 125 899 906 842 624 ≈0.095 961 7
r (
50
27
)
×
(
1
2
)50
≈108 043 253 365 600 × 8.881 78 × 10−16 =
0.095 961 7
24
You’ve been flipping coins again.
(a)
(
1
2
)8
= 0.003 906 25
(b)
(
1
2
)8
= 0.003 906 25
(c)
(
8
5
)
= 56
(d) 28 = 256
(e) We can calculate this in two ways, since P(H) = P(T) = 0.5:
r 56
256 = 0.218 75
r (
8
5
)
×
(
1
2
)8
= 56 × 0.003 906 25 = 0.218 75.
25
(a) P(TTHTHTHT) = P(H)2 × P(T)6 =
(
1
3
)2
×
(
2
3
)6
= 0.009 754 61
(b) P(H)2 × P(T)6 =
(
1
3
)2
×
(
2
3
)6
= 0.009 754 61
(c) No
(d) The probability of the sequence equals the product of the probabilities
of the elements of the sequence. A coin flip is “with replacement”, so
the probability of the elements depends only on whether it is heads or
tails, not on its place in the sequence. The probability of the sequence is
then the probability of heads to a power equal to the number of heads,
times the probability of tails to a power equal to the number of tails.
(e)
(
8
6
)

B.5 Probability

(f)
(
8
6
)
× P(T)6 × P(H)2 = 28 ×
(
1
3
)2
×
(
2
3
)6
= 0.273 129.
26
Gold Digger Airlines
(a) DC-3: Half of 2 engines is 1. The probability that half the engines fail
is therefore P =
(
2
1
)
0.0011 × (1 −0.001)2−1 = 0.001 998.
DC-6B: Half of 4 engines is 2. The probability that half the engines fail
is therefore P =
(
4
2
)
0.0012 × (1 −0.001)4−2 = 5.988 01 × 10−6.
(b) DC-3: P =
(
2
1
)
p1 × (1 −p)2−1 = 2(p −p2).
DC-6B: P =
(
4
2
)
p2 × (1 −p)4−2 = 6(p −p2)2.
(c) The probability of engine failure in at least half the engines is
DC-3: P(1 or 2 fails) =
(
2
1
)
p1 × (1 −p)2−1 +
(
2
2
)
p2 × (1 −p)2−2 =
2p −p2.
DC-6B: P(2, 3, or 4 fail) =
(
4
2
)
p2 × (1 −p)4−2 +
(
4
3
)
p3 × (1 −p)4−3 +
(
4
4
)
p4 × (1 −p)4−4 = 6(p −p2)2 = 6(1 −p)2p2 + 4(1 −p)p3 + p4 =
6p2 −8p3 + 3p4.
We solve the inequality 2p −p2 ≤6p2 −8p3 + 3p4 and see that it
holds for p ∈( 2
3 , 1). If you really have to fly, you should choose the
two-engine DC-3 if p > 2
3.
Combinatorics
27
Birthdays:
(a) Musa can be born on 365 days, but Ibrahim must be born on one of
the 364 others. So there are 365 × 364 ways they can be born on differ-
ent days. Since the total possible ways they can be born without this
restriction is 365 × 365, and so the probability they are not born on the
same day is 365
365 × 364
365 ≈0.997 26
(b) 365
365 × 364
365 × 363
365 ≈0.991 796
(c) 1 −0.991 796 = 0.008 204 17
(d) 0.983 644
(e) 1 −0.983 644 = 0.016 355 9
(f) P(22 students all have different birthdays) =
365!
(365−22)!
36522
≈0.524 305,
whereas P(23 students all have different birthdays) =
365!
(365−23)!
36523
≈
0.492 703. In other words: when more than 23 are present, the proba-
bility that at least two of them share a birthday exceeds 1
2.
28
http://en.wikipedia.org/wiki/List_of_poker_hands


B Solutions to Exercises
B.
Bayes’Theorem
1
Read the chapter.
2
… the a-ha version:
(a) 50%
(b) 0% – the probability changed even though you did not observe the mar-
ble itself. All you did to update the probability was to get more informa-
tion.
3
Just calculation:
(a)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
2
0.7
0.35
0.7
2
1
2
0.3
0.15
0.3
0.05
(b)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
2
0.07
0.035
0.7
2
1
2
0.03
0.015
0.3
0.05
(c)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
3
0.12
0.04
0.12
2
1
3
0.87
0.29
0.87
3
1
3
0.01
1
300
0.01
1
3
(d)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
3
0.001 2
0.000 4
0.12
2
1
3
0.008 7
0.002 9
0.87
3
1
3
0.000 1
1
30 000
0.01
1
300

B.6 Bayes’ Theorem

(e)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.3
0.001
0.000 3
0.037 5
2
0.7
0.011
0.007 7
0.962 5
0.008
(f)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.1
2
3
2
30
22
103
2
0.9
3
11
27
110
81
103
103
330
(g)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
11
0.012
12
11 000
12
1420
2
8
11
0.001
8
11 000
8
1420
3
2
11
0.7
1400
11 000
1400
1420
1 420
11 000
(h)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.237 1
0.8
0.189 68
0.670 11
2
0.455 4
0.07
0.031 878
0.112 62
3
0.307 5
0.2
0.061 5
0.217 27
0.283 058
(i)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.07
0.8
0.056
0.904 057
2
0.07
0.07
0.004 9
0.079 105
3
0.07
0.007
0.000 49
0.007 910 5
4
0.79
0.000 7
0.000 553
0.008 927 56
0.061 943


B Solutions to Exercises
(j)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
55
0.1
1
550
1
385
2
2
55
0.2
4
550
4
385
3
3
55
0.3
9
550
9
385
4
4
55
0.4
16
550
16
385
5
5
55
0.5
25
550
25
385
6
6
55
0.6
36
550
36
385
7
7
55
0.7
49
550
49
385
8
8
55
0.8
64
550
64
385
9
9
55
0.9
81
550
81
385
10
10
55
1.0
100
550
100
385
385
550
(k)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
55
0.1
10
5500
10
220
2
2
55
0.09
18
5500
18
220
3
3
55
0.08
24
5500
24
220
4
4
55
0.07
28
5500
28
220
5
5
55
0.06
30
5500
30
220
6
6
55
0.05
30
5500
30
220
7
7
55
0.04
28
5500
28
220
8
8
55
0.03
24
5500
24
220
9
9
55
0.02
18
5500
18
220
10
10
55
0.01
10
5500
10
220
220
5500

B.6 Bayes’ Theorem

(l)
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
55
0.1
100
55 000
100
1210
2
2
55
0.081
162
55 000
162
1210
3
3
55
0.064
192
55 000
192
1210
4
4
55
0.049
196
55 000
196
1210
5
5
55
0.036
180
55 000
180
1210
6
6
55
0.025
150
55 000
150
1210
7
7
55
0.016
112
55 000
112
1210
8
8
55
0.009
72
55 000
72
1210
9
9
55
0.004
36
55 000
36
1210
10
10
55
0.001
10
55 000
10
1210
1210
55 000
(m) …
4
(a) The alternatives Ak correspond to the urns, so Ak corresponds to the
event that you picked urn k.
(b) The prior probability of each urn must be equal, since there are no
grounds to prefer one urn to another, so P(Ak) = 1
3.
(c) The probability of drawing a red ball from the urns is, respectively,
P(R|A1) =
91
91+34 = 91
125, P(R|A2) =
14
14+25 = 14
39, and P(R|A3) =
40
40+25 =
40
65. The probability of blue is 1 minus the probability of red.
(d) P(S|A1) =
(
91
125
)20
⋅
(
1 −91
125
)10
≈3.875 40 ⋅10−9, P(S|A2) =
(
14
39
)20
⋅
(
1 −14
39
)10
≈1.479 19 ⋅10−11,
P(S|A3) =
(
40
65
)20
⋅
(
1 −40
65
)10
≈
4.297 34 ⋅10−9.
(e) Table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
3
3.875 40 ⋅10−9
1.291 8 ⋅10−9
0.473 329
2
1
3
1.479 19 ⋅10−11
4.930 63 ⋅10−12
0.001 806 64
3
1
3
4.297 34 ⋅10−9
1.432 45 ⋅10−9
0.524 864
2.729 18 ⋅10−9


B Solutions to Exercises
(f) i. P(A1) = P(A2) = 1
2
ii. P(H|A1) = P(T|A1) = 1
2
iii. P(T|A2) = 1 −P(H|A2) = 0.593
iv. (see table below)
v. Let B be the result TT. The table is then
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.5
0.25
0.125
0.415 525
2
0.5
0.351 649
0.175 825
0.584 477
0.300 825
vi. Let C be that you got HTH. The table is then
k
P(Ak|B)
P(C|AkB)
P × L
P(Ak|CB)
1
0.415 525
0.125
0.051 940 6
0.474 977
2
0.584 477
0.098 229 9
0.057 413 1
0.525 021
0.109 354
5
Text exercises
(a) You have 6 dice, D1, D2, D3, D4, D5, and D6. …
i. The alternatives are which die was picked: Ak = “he picked die Dk”.
ii. The pivotal event B is that the die landed on 3.
iii. The prior probability P(Ak) is the probability that your friend picked
the Dk die. Since no die is preferred, each die is equally probable,
so P(Ak) = 1
6. The probability of getting 3 on die Dk is P(B|Ak), so
P(B|A1) = 0, P(B|A2) = 0, P(B|A3) = 1
3, P(B|A4) = 1
4, P(B|A5) = 1
5,
P(B|A6) = 1
6.
iv. We get the posterior probabilities P(Ak|B) from the table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
6
0
0
0
2
1
6
0
0
0
3
1
6
1
3
1
18
20
57
4
1
6
1
4
1
24
5
19
5
1
6
1
5
1
30
4
19
6
1
6
1
6
1
36
10
57
19
120

B.6 Bayes’ Theorem

(b) i. Your task is to find the probability that the outcome was one of the
top six values on the die, given that the outcome was an even number.
We will use the Bayes apparatus, with the first alternative A1 being
that the outcome is in the top six, and the second alternative, A2,
being that it wasn’t.
ii. The pivotal event B is that you know the outcome was an even
number.
iii. You already know that P(A1) = 4
5, P(B) = 9
15, and P(B|A1) = 2
3. With
all this information, Bayes’ formula will do the job.
iv. Bayes’ formula says that P(A1|B) = P(A1)⋅P(B|A1)
P(B)
=
4
5 ⋅2
3
9
15
= 8
9.
(c) r 0.5 ⋅0.7 + 0.5 ⋅0.1 = 0.4.
r We use Bayes’ theorem as follows.
i & iii. The alternatives are which team was sent to the Olympics.
A1 = The Clean Team was sent to the Olympics, whereas
A2 = The Steroid Team was sent to the Olympics. The prior
probabilities are then P(A1) = 1
3 and P(A2) = 2
3.
ii & iii. The pivotal event B is that a lifter from the team tested neg-
atively for steroids. The likelihood is the probability of the
negative test, given the team, and equals the proportion of non-
steroid users on the team, so P(B|A1) = 1 −10% = 1 −0.1 =
0.9 and P(B|A2) = 1 −70% = 1 −0.7 = 0.3.
iv. Since we are after only one posterior probability, P(A1|B), it
is quicker to use the formula in Bayes’ theorem than to use a
table. We get:
P(A1|B) =
P(A1) ⋅P(B|A1)
P(A1) ⋅P(B|A1) + P(A2) ⋅P(B|A2)
=
1
3 ⋅0.9
1
3 ⋅0.9 + 2
3 ⋅0.3
= 0.6.
(d) i. The question to be answered is “What is the probability that Sofia
was assigned to Halfling?” So Halfling is one alternative, A1. The oth-
ers are then the alternatives to Halfling: A2 = Freequen, and A3 =
Gnormal.
ii. The pivotal event B is the crash when tested with a 100-variable
problem.
iii. One out of ten testers were assigned to Halfling, so the prior proba-
bility Sophie was assigned there is P(A1) = 1
10. Six out of ten were
assigned to Freequen, meaning P(A2) = 6
10, and 3 out of 10 got
Gnormal, so P(A3) = 3
10.


B Solutions to Exercises
The likelihood is the probability of a crash, given the software.
Since Halfling crashes 30% of the time, P(B|A1) = 0.3, and similarly
for the others, P(B|A2) = 0.1 and P(B|A3) = 0.2.
iv. We calculate the posterior probabilities P(Ak|B) in a table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.1
0.3
0.03
0.2
2
0.6
0.1
0.06
0.4
3
0.3
0.2
0.06
0.4
0.15
6
(a) A1 = “Claus picked the Danish bag”, A2 = “Claus picked the Norwegian
bag”, A3 = “Claus picked the Swedish bag”.
(b) Since no bag is preferred, P(A1) = P(A2) = P(A3). Together with
P(A1) + P(A2) + P(A3) = 1, this means that P(Ak) = 1
3 for k = 1, 2, 3.
(c) The pivotal event B is the squeezing of 8 gifts, where it turned out that
4 were soft.
(d) We do our calculations for sampling with replacement, so
r P(B|A1) = 0.74 ⋅0.34 = 0.001 944 81
r P(B|A2) = 0.44 ⋅0.64 = 0.003 317 76
r P(B|A3) = 0.24 ⋅0.84 = 0.000 655 36.
(e) We do this in a table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
3
0.001 944 81
0.000 648 27
0.32863
2
1
3
0.003 317 76
0.001 105 92
0.560 628
3
1
3
0.000 655 36
0.000 218 453
0.110 741
0.001 972 64
(f) We found, using our total knowledge up to know, new and updated
probabilities of which bag Mr. Claus had taken on board his sleigh. The
new probabilities are P(Danish bag) ≈33%, P(Norwegian bag) ≈56%,
P(Swedish bag) ≈11%.
(g) C = sampling 42 new gifts, 17 are soft.
r P(C|A1B) = 0.717 ⋅0.325 = 1.971 05 ⋅10−16
r P(C|A2B) = 0.417 ⋅0.625 = 4.884 29 ⋅10−13
r P(C|A3B) = 0.217 ⋅0.825 = 4.951 76 ⋅10−15.

B.6 Bayes’ Theorem

The table is then
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.328 63
1.971 05 ⋅10−16
6.477 47 ⋅10−17
0.000 236 025
2
0.560 628
4.884 29 ⋅10−13
2.738 27 ⋅10−13
0.997 766
3
0.110 741
4.951 76 ⋅10−15
5.483 65 ⋅10−16
0.001 998 12
2.744 4 ⋅10−13
meaning the new probabilities are P(Danish bag) ≈0.2
, P(Norwegian
bag) ≈99.8%, P(Swedish bag) ≈2
.
7
(a) P(A) =
3
3+1 = 0.75 and P(G) =
1
3+1 = 0.25.
(b) We answer by using the Bayes table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
A
0.75
7
69
21
276
21
51
G
0.25
10
23
30
276
30
51
51
276
(c) Let C = you get marzipan in your calendar on December 3rd. When we
are now calculating the probability of getting marzipan, we must not
forget that we have already eaten 2, so the remainder is either 6 or 14,
depending on which calendar we have, so P(C|AB) = 6
22 and P(C|AB) =
14
22. We calculate the total probability without using a table this time, and
P(C|B) = P(C|AB) ⋅P(A|B) + P(C|GB) ⋅P(G|B)
=
6
22 ⋅21
51 + 14
22 ⋅30
51 = 91
187.
8
Let A1 = classical, A2 = milk chocolate only, and A3 = has 15 of each.
(a) The principle of symmetry says that your prior probabilities should
equal their proportions, so
P(A1) =
10 000
10 000 + 4 000 + 6 000 = 0.5;
P(A2) =
4 000
10 000 + 4 000 + 6 000 = 0.2;


B Solutions to Exercises
P(A3) =
6 000
10 000 + 4 000 + 6 000 = 0.3.
(b) We calculate the likelihoods of our sequence by the formula of ordered
sampling without replacement.
r P(B|A1) =
( 30−5
22−3
)
( 30
22
) =
308
10179
r P(B|A2) = 0 (Why can we tell this without using the formula?)
r P(B|A3) =
( 30−5
15−3
)
( 30
15
) =
35
1044.
(c) We find the posterior probabilities by means of the Bayes table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.5
308
10 179
154
10 179
176
293
2
0.2
0
0
0
3
0.3
35
1044
7
696
117
293
2 051
81 432
9
Here, we use Bayes’ formula, and let S = member of secret society, and L =
lied to protect client.
P(S|L) = P(S) ⋅P(L|S)
P(L)
=
1
4 ⋅2
3
1
2
= 1
3.
10
(a) We name the bags A1, … , A4, in the order from the question.
i. P(Ak) = 1
4.
ii. Ordered sampling (B) with replacement gives us:
r P(B|A1) =
(
5
8
)3
⋅
(
3
8
)4
=
10 125
2 097 152
r P(B|A2) =
(
7
15
)3
⋅
(
8
15
)4
=
1 404 928
170 859 375
r P(B|A3) =
(
2
11
)3
⋅
(
9
11
)4
=
52 488
19 487 171
r P(B|A4) =
(
11
24
)3
⋅
(
13
24
)4
=
38 014 691
4 586 471 424.

B.6 Bayes’ Theorem

iii. The Bayes table gives us:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
1
4
10 125
2 097 152
0.001 206 994 057
0.200 893
2
1
4
1 404 928
170 859 375
0.002 055 678 829
0.342 148
3
1
4
52 488
19 487 171
0.000 673 366 083
0.112 075
4
1
4
38 014 691
4 586 471 424
0.002 072 109 880
0.344 883
P(B) = 0.006 008 15
(b) Observation C gives new likelihoods ….
r P(C|A1B) =
(
5
8
)2
⋅
(
3
8
)1
= 0.146 484
r P(C|A2B) =
(
7
15
)2
⋅
(
8
15
)1
= 0.116 148
r P(C|A3B) =
(
2
11
)2
⋅
(
9
11
)1
= 0.027 0473
r P(C|A4B) =
(
11
24
)2
⋅
(
13
24
)1
= 0.113 788
… and a new table:
k
P(Ak)
P(B|Ak)
P × L
P(Ak|B)
1
0.200 893
0.146 484
0.029 427 6
0.264 061
2
0.342 148
0.116 148
0.039 739 8
0.356 595
3
0.112 075
0.027 047 3
0.003 031 33
0.027 200 9
4
0.344 883
0.113 788
0.039 243 5
0.352 142
P(B) = 0.111 442
(c) Remember that you returned your bag, and that your brother has
picked a new one. Your old posterior applied to your bag, not his, so
your brother starts afresh with prior P(Ak) = 0.25. His sampling, D, is
without replacement …
r P(D|A1) =
( 8−3
5−1
)
( 8
5
) = 0.089 285 7
r P(D|A2) =
( 15−3
7−1
)
( 15
7
) = 0.143 59
r P(D|A3) =
( 11−3
2−1
)
( 11
2
) = 0.145 455


B Solutions to Exercises
r P(D|A4) =
( 24−3
11−1
)
( 24
11
) = 0.141 304
… and his table is:
k
P(Ak)
P(D|Ak)
P × L = P(DAk)
P(Ak|D)
1
0.25
0.089 285 7
0.022 321 4
0.171 824
2
0.25
0.143 59
0.035 897 5
0.276 329
3
0.25
0.145 455
0.036 363 8
0.279 918
4
0.25
0.141 304
0.035 326
0.271 929
P(D) = 0.129 909
11
We see that the one-step update gives the same probabilities as the two-
step update in the example.
12
(a) P0(A1) = P0(A2) 1
2.
(b) p = 1
2.
(c) P = 0, because either the die is all black, and cannot land white on the
first toss, or it is all white, and cannot land black on the second toss.
(d) p = P(W) = 0.5 and P(WB) = p ⋅(1 −p) = 0.25.
(e) As we saw in the exercises above: no. The probability is equal for a
single toss, but different for more than one toss.
13
(a) P1(D4) = 0,
P1(D6) = 0.311 745,
P1(D8) = 0.263 035,
P1(D10) =
0.202 011, P1(D12) = 0.155 872, P1(D20) = 0.067 336 9.
(b) p = 0.485 577.
(c) P(RRRRR) = p5 = 0.026 995 3.
(d) p = 0.052 004 3.
(e) As we saw in assignment 12, the probabilities are equal for one trial,
but different for repeated trials.
14
(a) 0.5.
(b) P(B) = 0.804 718. (So then, P(A) = 0.195 282.)
(c) p = P(A) ⋅0.025 + P(B) ⋅0.005 = 0.008 905 64.
(d) This is where you need the tool. The probability that exactly k of the
3000 cars has brake problems is
P(k) =
(3000
k
) (P(A) ⋅0.025k(1 −0.025)3000−k
+ P(B) ⋅0.005k(1 −0.005)3000−k) .

B.7 Stochastic Variables on R

To find the probability that 50 or more have problems, you must either
sum over all the k from 50 and up to 3000, like this, ∑3000
k=50 P(k), or
you must make use of the complementary probability and calculate
1 −∑49
k=0 P(k). This is not to be done by hand, whichever way you
choose. The answer is P(50 or more of the cars have brake problems) =
0.195 126.
(e) You could have calculated as if the origin of each car was indepen-
dently sampled. Then, each car would have an independent probability
p = 0.008 905 64 of brake error, and the probability of k cars with brake
errors would be
P(k) =
(3000
k
)
pk(1 −p)3000−k.
This would give P(50 or more of the cars have brake problems) =
0.000 033 643 6, which is wrong. It is wrong because the origin of each
car is not independent, but rather the opposite, since they all come from
the same factory.
B.
Stochastic Variables on R
1
Read the chapter.
Discrete Stochastic Variables
2
(a) r Table:
x
P(X = x)
0
0.5
1
0.5
r E[X] = 0.5, Var(X) = 0.25, 𝜎X = 0.5, 𝜏X = 4
(b) r Table:
x
P(X = x)
0
0.25
1
0.5
2
0.25
r E[X] = 1, Var(X) = 0.5, 𝜎X =
√
0.5 ≈0.707, 𝜏X = 2


B Solutions to Exercises
(c) r Table:
x
P(X = x)
0
0.125
1
0.375
2
0.375
3
0.125
r E[X] = 1.5, Var(X) = 0.75, 𝜎X =
√
0.75 ≈0.866, 𝜏X = 4
3
(d) r Table:
x
P(X = x)
1
0.25
2
0.25
3
0.25
4
0.25
r E[X] = 2.5, Var(X) = 1.25, 𝜎X =
√
1.25 ≈1.118, 𝜏X = 0.8
(e) r Table:
x
P(X = x)
2
0.062 5
3
0.125
4
0.187 5
5
0.25
6
0.187 5
7
0.125
8
0.062 5
r E[X] = 5, Var(X) = 2.5, 𝜎X =
√
2.5 ≈1.58, 𝜏X = 0.4
(f) r Table:
x
P(X = x)
1
1
6
2
1
6
3
1
6
4
1
6
5
1
6
6
1
6

B.7 Stochastic Variables on R

r E[X] = 3.5, Var(X) = 35
12 ≈2.92, 𝜎X =
√
35
12 ≈1.71, 𝜏X = 12
35
(g) r Table:
x
P(X = x)
2
1
36
3
2
36
4
3
36
5
4
36
6
5
36
7
6
36
8
5
36
9
4
36
10
3
36
11
2
36
12
1
36
r E[X] = 7, Var(X) = 35
6 ≈5.83, 𝜎X =
√
35
6 ≈2.42, 𝜏X = 6
35
3
(a) r Table:
x
f (x)
1
0.25
2
0.5
3
0.75
4
1
r The sum of the values of f (x) is 2.5 ≠1, so f is not a discrete proba-
bility distribution.
(b) r Table:
x
f (x)
1
0.1
2
0.2
3
0.3
4
0.4


B Solutions to Exercises
r The sum of the values of f (x) is 1, and f (x) ≥0 for all x, so it is a
discrete probability distribution.
r 𝜇X = 3, Var(X) = 1, 𝜎X = 1, 𝜏X = 1, P(X ∈{1, 4}) = 0.5
(c) r Table:
x
f (x)
1
1
k
2
2
k
3
3
k
4
4
k
5
5
k
6
6
k
r The sum of the values of f (x) is 21
k , and f (x) ≥0 for all x, which means
it is a discrete probability distribution iff k = 21. We set k = 21, and
then
r 𝜇X = 13
3 , Var(X) = 20
9 , 𝜎X = 2
√
5
3 , 𝜏X = 9
20, P(X ∈{2, 4, 6}) = 4
7
4
(a) ∑4
n=1
k
(n−1)! = 8
3k, which is 1 when k = 3
8.
(b)
x
P(X = x)
1
0.375
2
0.375
3
0.187 5
4
0.062 5
(c) 𝜇Y = 1 ⋅0.375 + 2 ⋅0.375 + 3 ⋅0.187 5 + 4 ⋅0.062 5 = 1.937 5.
(d) E[Y 5] = 15 ⋅0.375 + 25 ⋅0.375 + 35 ⋅0.187 5 + 45 ⋅0.062 5 = 121.938.
Continuous Stochastic Variables
5
r Yes. This is a continuous probability distribution.
r No, this is not a continuous probability distribution.
r Yes, this is a continuous probability distribution.
r No, this is not a continuous probability distribution.
6
r
𝜇X = ∫
0
−10
x ⋅1
40 dx + ∫
10
0
x ⋅3
40 dx = 5
2

B.7 Stochastic Variables on R

𝜎2
X = ∫
0
−10
x2 ⋅1
40 dx + ∫
10
0
x2 ⋅3
40 dx −
(5
2
)2
= 100
3
P(X ≥5) = ∫
10
5
3
40 dx = 0.375.
r This is not a continuous probability distribution.
r
𝜇X = ∫
2𝜋
𝜋
−x
2 sin(x) dx = 3𝜋
2
𝜎2
X = ∫
2𝜋
𝜋
−x2
2 sin(x) dx −
(3𝜋
2
)2
= 𝜋2
4 −2
P(X ≥5) = ∫
2𝜋
5
−1
2 sin(x) dx = sin2 (5
2
)
≈0.358 169.
r This is not a continuous probability distribution.
7
(a) r Graph … draw an ordinary function graph.
r ∫∞
−∞f (x) dx = ∫1
0 2x dx = 1, and f (x) ≥0 for all x, so f is a continuous
probability distribution.
r 𝜇X = 2
3, Var(X) = 1
18, 𝜎X =
1
3
√
2, 𝜏X = 18, P(X ∈[0.5, 1.5]) = 0.75.
(b) r Graph … draw an ordinary function graph.
r ∫∞
−∞f (x) dx = ∫
𝜋
2
−𝜋
2
cos(x) dx = 2, so f is not a continuous probability
distribution.
(c) r Graph … draw an ordinary function graph.
r sin(x) is not positive in the interval [−𝜋
2 , 0], so f is not a continuous
probability distribution.
(d) r Graph … draw an ordinary function graph.
r ∫∞
−∞f (x) dx = ∫1
0 3x2 dx = 1, and f (x) ≥0 for all x, so f is a continuous
probability distribution.
r 𝜇X = 3
4, Var(X) = 3
80, 𝜎X =
√
3
4
√
5, 𝜏X = 22.5, P(X ∈[0, 0.5]) = 0.125.
(e)
i. 𝜇X = 0
ii. 𝜎X =
1
√
6
iii. P(X ∈(0.5, 1.5)) = 0.125.
(f)
i. ̄f is not a probability distribution, because ∫∞
−∞̄f (x) dx = 4
3 ≠1
ii. k = 3
4
iii. The stochastic variable X:
A. 𝜇X = 0
B. P (X ∈[−2, −0.5] ∪[0.5, 2]) = 0.453 125.


B Solutions to Exercises
B.
Stochastic Variables II
Mixed Distributions
1
(a) 𝜇X = 3.4, Var(X) = 24.84, P(X ≥0) = 0.76.
(b) 𝜇X = 7.4, Var(X) = 51.44, P(X ≥0) = 0.11.
(c) 𝜇X = 0, Var(X) = 50, P(X ≥0) = 0.5.
(d) 𝜇X = 5, Var(X) = 14.2, P(X ≥0) = 0.930 12.
(e) 𝜇X = 2.08, Var(X) = 97.933 6, P(X ≥0) = 0.855 163.
2
(a) We find 𝜇c = 5 and 𝜇d = 4, so 𝜇X = 4.7. Further, Var(Xc) = E[X2
c ] −
𝜇2
c = ∫10
0
x × 1
10 dx −52 = 25
3 , so Var(X) = 0.7Var(Xc) + 0.3Var(Xd) +
0.7 × 0.3(5 −4)2 = 6.043 33.
(b) We find 𝜇c = ∫1
0 x × 2x dx = 2∕3 and 𝜇d = 0, so 𝜇X = 0.1. Further,
Var(Xc) = ∫1
0 x2 × 2x dx −( 2
3)2 = 1
18, so Var(X) = 0.065.
(c) We find 𝜇c = 𝜋
2 and 𝜇d = 𝜋, so 𝜇X = 7𝜋
10 . Further, Var(Xc) = 𝜋2−8
4 , so
Var(X) = 21𝜋2−120
100
.
3
We find 𝜇c = 5 and 𝜇d = 6.75, so 𝜇X = 6.4. Further, Var(Xc) = 25
3 and
Var(Xd) = 8.437 5, so Var(X) = 14.552 5.
4
We first decompose X: the probability of no loss is p0 = 0.88. That gives us
wd = p0 = 0.88, and wc = 1 −wd = 0.12.
Further,
fd(x) =
{
1 for x = 0
0 otherwise.
The distribution of the payment, given that the tour runs at a loss, equals
the conditional distribution of the loss,
fc(x) = g(x) = 5 × 10−7e−5 × 10−7x (for x > 0).
This gives us 𝜇d = 0, Var(Xd) = 0, 𝜇c = 2 × 106, and Var(Xc) = 4 × 1012.
Then
𝜇X = 0.88 × 0 + 0.12 × 2 × 106 = 240 000.00
Var(X) = 0.88 × 0 + 0.12 × 4 × 1012 + 0.88 × 0.12(2 × 106 −0)2
= 9.024 × 1011

B.8 Stochastic Variables II

𝜎X =
√
Var(X) = 949 947.00.
The charge for Sandra’s policy is then
charge = 1.7 × 𝜇X + 0.1 × 𝜎X = 1.7 × 240 000.00 + 0.1 × 949 947.00
= 502 995.00.
5
We decompose X: The probability of no loss is p0 = 0.88. Loss in excess
of 5 million gives a payment of 5 million, so p5mill = P(loss) × P(loss >
5 000 000 |loss) = 0.12 × ∫∞
5 000 000 f (x) dx = 0.009 850 2. Outside of these
two, X has no positive point probabilities. So wd = p = p0 + p5mill =
0.889 850 2, and wc = 1 −wd = 0.110 15.
This means
fd(x) =
⎧
⎪
⎨
⎪⎩
0.88
0.889 850 2 = 0.988 93
for x = 0
0.009 850 2
0.889 850 2 = 0.011 069 5 for x = 5 million.
The continuous distribution applies to a loss x ∈I = [0, 5 000 000]. We use
the distribution of the loss, f (x) = 5 × 10−7e−5 × 10−7x, so ∫5 000 000
0
f (x) dx =
0.917 915. For x ∈I, we have
fc(x) = 5 × 10−7e−5 × 10−7x
0.917 915
= 5.447 13e−5 × 10−7x.
We get 𝜇d = 55 347.50, Var(Xd) = 2.736 74 × 1011, 𝜇c = 1 552 872, and
Var(Xc) = 1.564 44 × 1012. Then
𝜇X = 0.889 850 2 × 55 347.50 + 0.110 15 × 1 552 872
= 220 300.00
Var(X) = 0.889 850 2 × 2.736 74 × 1011 + 0.110 15 × 1.564 44 × 1012
+ 0.889 850 2 × 0.110 15 × (1 552 872 −55 347.50)2
= 6.356 62 × 1011
𝜎X =
√
Var(X) = 797 284.00.
For this policy, Sandra will be charged
charge = 1.7 × 𝜇X + 0.1 × 𝜎X = 1.7 × 220 300.00 + 0.1 × 797 284.00
= 454 238.00.


B Solutions to Exercises
Two- and Multi-variable Probability Distributions
6
Table, with the marginal probabilities in red:
X = 1
X = 2
X = 3
Y = 1
0.05
0.05
0.3
0.4
Y = 2
0.05
0.25
0.05
0.35
Y = 3
0.2
0.05
0
0.25
0.3
0.35
0.35
1
P(X + Y = 4) = 0.75 and 𝜌XY = −0.694 203.
7
The philosophers Max Stirner and Karl Werder:
(a)
X = 1
X = 2
X = 3
Y = 2
0
0.1
0.3
Y = 3
0.05
0.3
0.6
Y = 4
0.2
0.65
1
(b) P(X + Y = 5) = P(X = 1 & Y = 4) + P(X = 2 & Y = 3) + P(X =
3 & Y = 2) = 0.15 + 0.15 + 0.2 = 0.5.
(c) r P(X = 1|X + Y = 5) = P(X=1&X+Y=5)
P(X+Y=5)
= P(X=1&Y=4)
P(X+Y=5)
= 0.15
0.5 = 0.3
r P(X = 2|X + Y = 5) = P(X=2&X+Y=5)
P(X+Y=5)
= P(X=2&Y=3)
P(X+Y=5)
= 0.15
0.5 = 0.3
r P(X = 3|X + Y = 5) = P(X=3&X+Y=5)
P(X+Y=5)
= P(X=3&Y=2)
P(X+Y=5)
= 0.2
0.5 = 0.4.
(d) The probability of getting a questions about Stirner, given that you get
five questions in total about the two philosophers.
8
No, since P(Y = y) is 0 iff y > X, and 1
X otherwise, so P(Y = y) is dependent
on the value of X.
9
fx(x) = 1
5(7 −4x) for x ∈[0, 1], whereas fy(y) = 2
5(3 −2y3). Further, the
covariance is 𝜎xy = −1
250, and since 𝜎xy ≠0, then X and Y are not inde-
pendent.
10
(a) fx(x) = 2
𝜋
√
1 −x2 when x ∈(−1, 1), and 0 otherwise. Same function for
fy.
(b) No, since fx × fy ≠fZ(x, y).

B.9 Discrete Distributions

(c) f|Y=y(x) =
1
2
√
1−y2 if |x| <
√
1 −y2, and 0 otherwise. Correspondingly
for f|X=x(y).
11
They are not independent. 𝜌xy = 0.
The Sum of Independent Stochastic Variables
12
(a) 𝜇Z = 7, 𝜎Z =
√
13
(b) 𝜇Z = 6, 𝜎Z = 13
(c) 𝜇Z = 21, 𝜎Z =
√
21
(d) 𝜇Z = 7, 𝜎Z = 2
(e) 𝜇Z = k𝜇, 𝜎Z = k𝜎
(f) 𝜇Z = 6, 𝜎Z =
7
2
√
5
13
The standard deviation of aX is a𝜎X, and the standard deviation of
(1 −a)Y is (1 −a)𝜎Y. The standard deviation of Z is then 𝜎2
Z = a2𝜎2
X +
(1 −a)2𝜎2
Y. This is a function of a, so let us name it f (a). Then, f ′(a) =
2a𝜎2
X −2(1 −a)𝜎2
Y and f ′′(a) = 2𝜎2
X + 2𝜎2
Y > 0, so we find a critical point
(a minimum) when f ′(a) = 0. That is, when 2a𝜎2
X −2(1 −a)𝜎2
Y = 0. The
minimum value of 𝜎Z is thus realized when a =
𝜎2
Y
𝜎2
X+𝜎2
Y
.
B.
Discrete Distributions
B..
Discrete Uniform Probability Distribution
The discrete uniform distribution has been omitted as a section so that the
student may have at hand a tractable probability distribution to build up and
study its properties. The first assignment is the key.
1
The general properties of a discrete uniform distribution with parameters
a and b, and n = b −a + 1, are then:
(a) 𝜇X = a+b
2
(b) 𝜎2
X = n2−1
12
(c)
f(x)
F(x)
5
10
15
20
25
−0.02
0.02
0.04
0.06
0.08
0.10
5
10
15
20
25
1
0


B Solutions to Exercises
2
P(X ∈{2, 3, 5, 7, 11, 13, 17, 19}) = 0.08.
3
This is identical to the previous question, and hence the answer is identical
too.
4
𝜇X = 49.5 and 𝜎X =
√
9999
12 ≈28.866 1.
5
𝜇X = 29.5 and 𝜎X ≈17.3. There are 15 elements in A = {0, … , 59} with one
of its digits equal to 4, so P(A) = 0.25.
B..
Bernoulli Distribution, bernp
6
A Bernoulli distribution applies to the outcome of a single Bernoulli trial,
and measures the probability of success in that single trial. The distribution
is not used on its own for single trials, though, but is a component of com-
posite distributions for repeated, independent Bernoulli trials – typically,
the binomial or negative binomial distributions.
7
Since 𝜇X = p, the maximal value is obtained at the highest value of p, which
is p = 1.
8
Since 𝜎2
X = p(1 −p), a function whose maximum is reached at p = 1
2, the
variance is maximized for p = 0.5.
9
The precision 𝜏X is the inverse of the variance, 𝜏X =
1
p(1−p), which grows
arbitrarily large (to infinity) as p approaches 0 and 1.
10
(a) of = 0.812 5∕(1 −0.812 5) = 4.333.
(b) of = 13 : 3.
(c) oa = 1∕of = 3 : 13 = 0.230 8.
(d) Continental European odds = oa + 1 = 1.230 8.
(e) p ⋅G = 0.812 5 ⋅100 = 81 euro and 25 cents.
(f) 100∕0.812 5 = 123 euro and 8 cents.
(g) With this bookmaker, your winnings will be 1+10
10
= 1.1 times your bet,
which is less than the fair rate of 1.230 8, so this bet is worse for you
than a fair bet, and you should not take it.
B..
Binomial Distribution, bin(n,p)
11
X ∼f (x) =
(
5
x
)
0.55x ⋅0.455−x, and 𝜇X = 2.75 and 𝜎X = 1.112 43. Further,
P(X ∈{0, 1, 2}) = 0.406 873.

B.9 Discrete Distributions

12
This is identical to the last part of the previous problem, and hence the
answer is also the same.
13
X ∼f (x) =
(
14
x
)
0.4x ⋅0.614−x, and 𝜇X = 5.6 and 𝜎X = 1.833 03. Further,
P(X ∈{3, 4, 5}) = 0.446 063.
14
This is identical to the last part of the previous problem, and hence the
answer is also the same.
15
Z ∼f (z) =
(
20
z
)
0.8z ⋅0.220−z, and 𝜇Z = 16 and 𝜎Z = 1.788 85. Further,
P(Z ∈{0, 1, 2, 3, 4, 5}) = 1.8 ⋅10−7.
16
This is identical to the last part of the previous problem, and hence the
answer is also the same.
17
If you don’t have a good calculator, use the Normal approximation for large
numbers.
(a) bin(10, 0.3)(3) =
(
10
3
)
0.330.77 = 0.266 828 ≈27%
(b)
33
∑
k=27
bin(100, 0.3)(k) = 0.554 859 ≈55%
(c)
330
∑
k=270
bin(1 000, 0.3)(k) = 0.964 751 ≈96%
(d)
3 300
∑
k=2700
bin(10 000, 0.3)(k) = 0.999 999 999 942 169 532 741 ≈100%
18
Let the number of errors be X ∼bin(70 368 744 177 664 , 50 × 10−15).
(a) E[X] = np = 3.518 44.
(b) Var(X) = np(1 −p) = 3.518 44.
(c) Here, it pays to use an approximation – even if you have a decent cal-
culating tool.
r Exact answer:
P(X ≤5) = BIN(70 368 744 177 664 , 50 × 10−15)(5) = 0.855 167 136 678 …
Even with a good tool like Mathematica, you must help the tool a
bit. Do not allow it to use its built-in binomial distribution, but ask it
instead to calculate using the formula for a binomial distribution, but
with the replacement (1 −p)a ≈ea(−p−1
2 p2−1
3 p3−⋯−1
n pn−⋯), stopping
at some n. Note that you get high accuracy even when you stop at
n = 1.


B Solutions to Exercises
r Poisson approximation: P(X ≤5) = POIS3.518 437(5) = 0.855 167.
r Normal
approximation:
P(X ≤5) = Φ(3.518 437 , 3.518 437)(5 + 1
2) =
0.713 349.
19
…
(a) −10, −8, −6, −4, −2, 0, 2, 4, 6, 8, 10 units.
(b) We sum the probabilities bin(10, 0.51)
(
x+10
2
)
for x = 4, 6, 8, 10, as in the
following formula:
5
∑
k=2
bin(10, 0.51)(k + 5) =
10
∑
k=7
bin(10, 0.51)(k) ≈19%.
(c) E[X] = (2p −1)n = (2 ⋅0.51 −1) ⋅10 000 = 200.
(d) E[X] = 4np(1 −p) = 4 ⋅10 000 ⋅0.51 ⋅0.49 = 999 6.
(e) Calculate exactly (as in the problem with 10 steps), or employ the Nor-
mal approximation. Exact answer:
5 000
∑
k=50
bin(10 000, 0.51)(k + 5 000) =
10 000
∑
k=5 050
bin(10 000, 0.51)(k) ≈84%.
B..
Hypergeometric Distribution, hyp(n,S,N)
20
f (x) =
( 13
x
)( 7
5−x
)
( 20
5
)
and 𝜇X = n ⋅S
N = 5 ⋅13
20 = 3.25, 𝜎X = 0.947 643 and
P(X ∈{0, 1, 2}) = 0.206 785.
21
This is identical to the last part of the previous problem, and hence the
answer is also the same.
22
f (x) =
( 7
x
)( 23
9−x
)
( 30
9
)
and 𝜇X = n ⋅S
N = 9 ⋅7
30 = 2.1, 𝜎X = 1.079 75 and P(X ∈
{0, 1}) = 0.297 011.
23
This is identical to the last part of the previous problem, and hence the
answer is also the same.
24
Let X be the number of aces among your new cards. X follows a hypergeo-
metric distribution with N = 47 (the remaining cards), S = 3 (the remain-
ing aces), and n = 3 (the number of new cards), and thus
f (x) =
(
3
x
)(
44
3−x
)
(
47
3
)
,

B.9 Discrete Distributions

so
P(at least 1 ace) = 1 −P(no ace) = 1 −hyp(3,3,47)(0)
= 1 −0.817 = 0.183 225.
B..
Poisson Distribution, pois𝝀
25
𝜇X = 𝜆= 2.8,
𝜎X =
√
𝜆=
√
2.8 = 1.673 32,
P(X = 1) = 2.81
1! ⋅e−2.8 =
0.170 268, and P(X ≠1) = 1 −P(X = 1) = 0.829 732.
26
Since 𝜇X = 3.5, we have 𝜆= 3.5. Then 𝜎X =
√
3.5 = 1.870 83, P(X =
5) = 3.55
5! e−3.5 = 0.132 169, and P(X > 0) = 1 −P(X = 0) = 1 −3.50
0! e−3.5 =
0.969 803.
27
𝜇X = 𝜎2
X = 25, which gives 𝜆= 25. Then P(X = 7) = 257
7! e−25 = 0.000 016 8
and P(X ≤2) = P(X = 0) + P(X = 1) + P(X = 2) = 4.7 ⋅10−9.
28
P(X = 0) = e−𝜆= 0.1, so 𝜆= −ln(0.1) ≈2.303. Then 𝜇X = 2.303 and 𝜎X =
√
2.303 = 1.517. Further, P(X = 1) = 2.3031
1!
e−2.303 = 0.230 3.
29
f (x) = 2.37x
x! e−2.37 and 𝜇X = 𝜆= 2.37, whereas 𝜎X =
√
2.37 = 1.539. Then
P(X ∈{0, 1}) = P(X = 0) + P(X = 1) = 2.370
0! e−2.37 + 2.371
1! e−2.37 = 0.315.
30
The same as the end of the above problem. The probability of 1 click or less
is 0.315.
31
f (x) = e−1
x! and 𝜇X = 𝜆= 1, whereas 𝜎X =
√
𝜆= 1. Further, P(X ∈{0}) =
P(X = 0) = e−1
0! = e−1 ≈0.367 879.
32
The same as the end of the above problem. The probability of one eviction
or fewer is 0.367 879 ≈37%.
33
(a) 𝜆= 𝜇X = 30
7 ≈4.285 7.
(b) 𝜎X =
√
𝜆= 2.070 2.
(c) P(X = 5) = 0.165 8.
B..
Overview and General
34
The difference between the binomial and uniform distributions.
(a) P = 3
12 = 0.25.


B Solutions to Exercises
(b) P =
((
12
0
)
+
(
12
1
)
+
(
12
2
)
+
(
12
3
))
⋅
(
1
2
)12
= 299
4096.
35
The PirateBay problem: No numerical answers, but the best choice of
distribution is indicated. Discuss the solutions in groups; which approxi-
mations apply when the numbers are sufficiently large, and so on?
(a) Uniform distribution.
(b) Hypergeometric distribution.
(c) Binomial distribution, as an approximation to hypergeometric distri-
bution.
(d) Poisson distribution works best for these calculations.
36
The Autopol problem: No numerical answers, but the best choice of dis-
tribution is indicated. Discuss the solutions in groups; which approxima-
tions apply when the numbers are sufficiently large, and so on?
(a) Uniform distribution.
(b) Binomial distribution.
(c) Binomial distribution.
(d) Binomial distribution.
(e) Hypergeometric distribution.
(f) Poisson distribution.
B.
Continuous Distributions
B..
Normal Distribution, 𝝓(𝝁,𝝈)
1
Remember that this includes both your calculators and online tools such as
Wolfram Alpha and software like R that you might have on your computer
2
Cumulative Normal distribution Φ(𝜇,𝜎) and probability
(a) P(X ≤1.43) = Φ(0,1)(1.43) = 0.923 641.
(b) P(X > 1.43) = 1 −Φ(0,1)(1.43) = 0.076 359.
(c) P(X ≤−2.38) = Φ(0,1)(−2.38) = 0.008 656 32.
(d) P(X > −2.38) = 1 −Φ(0,1)(−2.38) = 0.991 344.
(e) P(X ≤4.35) = Φ(3, 1.9)(4.35) = 0.761 311.
(f) P(X > 4.35) = 1 −Φ(3, 1.9)(4.35) = 0.238 689.
(g) P(X ≤0.2) = Φ(−7, 4)(0.2) = 0.964 07.
(h) P(X ∈(−2.38, 1.43)) = Φ(0,1)(1.43) −Φ(0,1)(−2.38) = 0.914 985.
(i) P(X ∈(8, 13)) = Φ(10,5)(13) −Φ(10,5)(8) = 0.381 169.
3
Inverse cumulative Normal distribution z
(a) z0.05 = −1.644 85.
(b) z0.95 = 1.644 85.
(c) a = 0.355 146.
(d) a = 3.644 85.

B.10 Continuous Distributions

4
The Normal approximation
(a) P(X ≤4) ≈Φ(3, 1.2)
(
4 + 1
2
)
= 0.894 35.
(b) P(X ≤4) ≈Φ(3, 1.2)(4) = 0.797 672.
(c) P(X ∈{6, 7}) ≈Φ(5.1, 2.2)
(
7 + 1
2
)
−Φ(5.1, 2.2)
(
6 −1
2
)
= 0.290 206.
(d) P(X ∈(5, 7)) ≈Φ(5.1, 2.2)(7) −Φ(5.1, 2.2)(5) = 0.324 234.
(e) P ≈Φ(12.1, 4.7)
(
19 + 1
2
)
−Φ(12.1, 4.7)
(
12 −1
2
)
= 0.493 101.
5
Sums of Normally distributed stochastic variables
(a) X ∼𝜙(3,
√
30)(x).
(b) X ∼𝜙(20 ,
√
160)(x).
(c) X ∼𝜙(7,2)(x).
B..
Binormal Distribution, 𝝓(𝝁, 𝚺)
X and Y independent
6
P(X < 7, Y < 0) = P(X < 7) ⋅P(Y < 0) = Φ(5,10)(7) ⋅Φ(−3,9)(0)
= 0.579 26 ⋅0.630 559 = 0.365 257.
X and Y dependent
7
(a) fx(x) = 𝜙(20,7)(x) and fy(y) = 𝜙(12,8)(y).
(b) fx|y(x) = 𝜙(14.75+0.4375y, 16)(x)
fy|x(y) = 𝜙( 4
7 (x+1), 12.25
)(y).
(c)
𝜃= 1
2 tan−1 (
2⋅28
49−64
)
= −0.654∕, 541
R𝜃=
[
0.793 327 0.608 795
−0.608 795 0.793 327
]
̂𝜇= R−𝜃𝜇=
[
8.561
21.695 8
]
̂Σ = R−𝜃ΣR𝜃=
[
27.5129
0
0
85.4871
]
.
B..
Gamma Distribution, 𝜸(k,𝝀), With Family
8
𝜇T = 0.2, 𝜎T = 0.2, and P(T ≤4) = 1.000 0.
9
𝜇T = 0.434 783, 𝜎T = 0.434 783, and P(T ≤3.2) = 0.999 364.
10
𝜇T = 0.322 581,
𝜎T = 0.322 581,
and
P(T > 1.2) = 1 −P(T ≤1.2) =
0.024 234.


B Solutions to Exercises
11
𝜇T = 0.227 273, 𝜎T = 0.227 273, and P(T ∈⟨0.15, 0.28]) = 0.225 143.
12
𝜇T = E[T] = 2.9. Then 𝜆=
1
2.9 ≈0.344 8 and 𝜎T = 1
𝜆=
1
1∕𝜆= 2.9.
13
𝜎T =
√
Var(T) =
√
2.25 = 1.5. Then 𝜆=
1
𝜎T =
1
1.5 = 2
3 and 𝜇T = 1
𝜆=
1
1∕𝜎T = 1.5.
14
𝜇T = 0.4, 𝜎T = 0.282 843, and P(T ≤1) = 0.959 57.
15
𝜇T = 1.304 35, 𝜎T = 0.753 066, and P(T ≤1.7) = 0.748 411.
16
𝜇T = 1.612 9, 𝜎T = 0.721 312, and P(T > 2.3) = 0.161 46.
17
𝜇T = 0.454 5, 𝜎T = 0.321 412, and P(T ∈⟨0.2, 2]) = 0.778 315.
18
k = 2 and 𝜇T = 2.9, so 𝜆=
k
𝜇T =
2
2.9 = 0.689 7, and then 𝜎T =
√
k
𝜆= 𝜇T
√
k =
2.9
√
2 = 2.050 6.
19
k = 3 and 𝜎2
T = 2.25, so 𝜎T = 1.5. Then 𝜆=
√
k
𝜎T =
√
3
1.5 = 1.154 7, so 𝜇T =
k
𝜆= 𝜎T ×
√
k = 2.598.
20
𝜆=
1
𝜇T = 1
23, so
(a) P(one sympathizer within 30 minutes) = EXP 1
23 (30) = 1 −e−30
23 ≈
0.728 7;
(b) the waiting time T for two is then Erlang distributed, with k = 2 and
𝜆= 1
23,
P(T ≤30) = 1 −
( 1
0! × e−30𝜆+ 30𝜆
1! × e−30𝜆)
= 1 −53
23e−30
23
= 0.374 716.
21
(a) P(the first sale within 2 weeks) = EXP𝜆(2) = 1 −e−2𝜆.
(b) The waiting time for 2 sales is then Erlang distributed erl(2,𝜆). Let T be
the waiting time in weeks for 2 sales.
P(T ≤4) = 1 −
1
∑
n=0
((4𝜆)n
n! e−4𝜆
)
= 1 −e−4𝜆(1 + 4𝜆).

B.10 Continuous Distributions

This gives the equation
1 −e−4𝜆(1 + 4𝜆) = 0.6,
which in turn gives 𝜆= 0.505 6. Then you need 𝜆> 0.505 6 in order to
have more than a 60% probability of permanent employment.
22
Let T be the waiting time for 10 clicks.
(a) Then T ∼erl(10,0.25), so E[T] = 𝜇T =
10
0.25 = 40 minutes.
(b) The probability of at least 3 clicks equals the probability that the third
click has occurred, in other words
f (3) = ERL(3,0.25)(2) ≈0.014 39.
(c) We find the number of clicks by means of Rule A.4.6, that is, by the
Poisson distribution. Here, the parameter is 0.25 × 2 = 0.5, so
P(T = 3) = 0.53
3! e−0.5 ≈0.012 64.
23
Call the waiting time T. Then
(a) 𝜇T = 1
𝜆= 15;
(b) P(T ∈(5, 20)) = EXP1∕15(20) −EXP1∕15(5)
=
(
1 −e−20
15
)
−
(
1 −e−5
15
)
= 0.452 9.
24
(a) 𝜆= 1
15 and n = 3, so f (t) = 𝜆ntn−1
(n −1)!e−𝜆t =
t2
6750e−t
15 .
(b) Probability of waiting longer than 30 minutes:
r direct: the corresponding cumulative distribution becomes
ERL(3,1∕15)(t) = 1 −
2
∑
k=0
t2
15k × k!e−t
15
so
P(T > 30) = 1 −ERL(3,1∕15)(30) =
2
∑
k=0
30k × e−2
15k × k! = 5
e2 ≈0.68.
r by the Normal approximation: 𝜇= n
𝜆= 45 and 𝜎2 = n
𝜆2 = 675, giv-
ing 𝜎= 15
√
3. This means that
P(T > 30) ≈1 −Φ(45, 15
√
3)(30) = 0.72.


B Solutions to Exercises
(c) The number of customers have asked about the book within a limited
time period is Poisson distributed, with parameter 30𝜆= 30 × 1
15 = 2,
so
P(m) = 2m
m!e−2.
(d) The expected value for a Poisson distribution equals the parameter 𝜆,
so the expected number of customers who have asked about the book
during a period of 30 minutes is 2.
25
(a) Γ(16,4)(t) = 𝕏2
32(8t).
(b) P(𝜏< 6) = Γ(16,4)(6) = 0.965 6.
(c) 𝜏0 = Γ−1
(16,4)(0.9) = 5.323 09, so P(𝜏< 5.323 09) = 90%.
(d) P(𝜎> 0.408 248) = 0.965 6 and P(𝜎> 0.309 205) = 90%.
26
(a) Γ(19.5, 44)(t) = 𝕏2
39(88t).
(b) P(𝜏> 0.64) = 1 −Γ(19.5, 44)(0.64) = 0.035 797 1.
(c) 𝜏0 = Γ−1
(19.5, 44)(1 −0.95) = 0.291 993, so P(𝜏> 0.291 993) = 95%.
(d) P(𝜎< 1.25) = 0.035 797 1 and P(𝜎< 1.850 6) = 95%.
27
(a) Γ(101.5, 15)(t) = 𝕏2
203(30t).
(b) P(𝜎> 2) = P(𝜏< 0.25) = 4.7 × 10−105 ≈0.
(c) This corresponds to finding a value 𝜏0 such that P(𝜏> 𝜏0) = 98%, or
equivalently, P(𝜏< 𝜏0) = 2%. The solution is 𝜏0 = Γ−1
(101.5, 15)(0.02) =
5.459 77, so 𝜎0 = 0.427 969. Thus, P(𝜎< 0.427 969) = 98%.
B..
Student’s t Distribution, t(𝝁,𝝈,𝝂)
28
t4,0.1 = −1.533 2.
29
x = −3.355 4.
30
x = 1.439 8.
31
x = 12.39.
32
x = 21.95.
33
Z ∼t(4.5, 3.8,10).
B..
Beta Distribution, 𝜷(a,b)
34
𝜇X = 0.5, 𝜎X =
1
2
√
3, P(X ≤0.4) = 0.4.

B.10 Continuous Distributions

35
𝜇X = 0.5, 𝜎X =
1
2
√
5, P(X > 0.6) = 0.352.
36
𝜇X = 0.4, 𝜎X = 0.2, P(X ∈⟨0.3, 0.6]) = 0.472 5.
37
𝜇X = 0.6, 𝜎X = 0.2, P(X ∈⟨0.4, 0.65]) = 0.383 781.
38
P(X ≤0.7) = I(53,22)(0.7) = 0.436 117 and p = I−1
(53,22)(0.8) = 0.751 395.
39
P(X ≤0.7) = I(108,72)(0.7) = 0.003 480 6 and p = I−1
(108,72)(0.8) = 0.659 279.
40
P(X ≤0.2) = I(17,42)(0.2) = 0.058 5361 and p = I−1
(17,42)(0.1) = 0.214 525.
41
P(X ≥0.8) = 1 −I(43,19)(0.8) = 0.026 194 2
and
p = I−1
(43,19)(1 −0.9) =
0.617 472.
42
P(X ≥0.6) = 1 −I(128,81)(0.6) = 0.647 272,
and
p = I−1
(128,81)(1 −0.99) =
0.532 88.
43
𝜇X = 0.553 551,
𝜎X = 0.016 682 4,
Normal
approximation:
P(X ∈
[0.45, 0.5⟩) = 0.000 664. (Exact: P(X ∈[0.45, 0.5⟩) = 0.000 7007 15.)
44
(a) P = 12
29.
(b) P = 17
29.
(c) P = 34
145 ≈0.234 483.
(d) P = 34
145 ≈0.234 483.
(e) P = 0.003 122 16.
(f) P = 0.003 122 16.
(g) P = 0.218 551.
(h) P = 0.097 082 8.
(i) P = 0.388 331.
(j) P = 0.444 963.
(k) P = 0.140 231.
(l) P = 0.024 694 7.
(m) P = 0.001 780 87.
(n) P = 0.833 294.
(o) P = 0.166 706.
45
(a) 𝜇X = 0.323 944.
(b) The probability is the same as 𝜇X, that is, 0.323 944.
(c) P(X ∈⟨𝜇X −0.05, 𝜇X + 0.05]) = 0.632 215.


B Solutions to Exercises
46
(a) 𝜇X = 0.326 797.
(b) The probability is the same as 𝜇X, that is, 0.326 797.
(c) P(X ∈⟨𝜇X −0.05, 𝜇X + 0.05]) = 0.813 675.
47
You are finding the probability of 0, 1, or 2 factual errors. Notice that there
are
(
10
k
)
possible sequences of k factual errors in 10 tries, so
P(0) =
(10
0
)
⋅
(
17+64
17
)
⋅17⋅64
17+64
(
17+64+0+10
17+0
)
⋅(17+0)(64+10)
17+64+0+10
= 0.108 611
P(1) =
(10
1
)
⋅
(
17+64
17
)
⋅17⋅64
17+64
(
17+64+1+9
17+1
)
⋅(17+1)(64+9)
17+64+1+9
= 0.252 93
P(2) =
(10
2
)
⋅
(
17+64
17
)
⋅17⋅64
17+64
(
17+64+2+8
17+2
)
⋅(17+2)(64+8)
17+64+2+8
= 0.284 546.
So the probability of 2 or fewer errors in her next 10 factual claims is
0.646 087.
B..
Weibull Distribution, weib(k,𝝀)
48
𝜇T = 3.672 7 and 𝜎2
T = 0.707 68, whereas P(T ≤4) = 0.632 1.
49
𝜇T = 240 and 𝜎T = 3 802.32, whereas P(T ≥1) = 0.418 721.
50
𝜇T = 4.431 1 and 𝜎T = 2.316 3, whereas P(T ∈(1, 3)) = 0.263 1.
51
𝜇T = 6 and 𝜎T = 13.416, whereas P(T ∈(2, 4)) = 0.126 8.
52
(a) 𝜇T = 1.772 45.
(b) P(T < 𝜇T) = 0.544 062.
53
(a) 𝜇T = 2.5.
(b) 𝜎T = 2.5.
(c) P(T ∈(0.5, 1.5)) = 0.269 919.
54
𝜆= 0.5 and k = 1.
(a) We use the formulas for the Weibull distribution, and get
𝜇T = 𝜆
k Γ
(1
k
)
= 0.5
1 Γ
(1
1
)
= 0.5.

B.11 Inference: Introduction

𝜎2
T = 0.52
(
Γ
(
1 + 2
1
)
−
(
Γ
(
1 + 1
1
))2)
= 0.25.
(b)
P(T > 1) = 1 −P(T ≤1) = 1 −F(1)
= 1 −
(
1 −e
−
( x
𝜆
)k)
= e
−
( x
𝜆
)k
= e
−
( 1
0.5
)1
= e−2 ≈0.135 335.
(c)
f (x) = 1
0.5 ⋅
(x
𝜆
)1−1
e
−
( x
0.5
)1
= 1
0.5e−x
0.5
= 1
𝜆e−x
𝜆= exp𝜆.
Exponential distribution, with parameter 𝜆= 0.5.
B..
Continuous Uniform Distribution
The continuous uniform distribution has been omitted as a section so that the
student should have at hand a tractable probability distribution to build up and
study its properties. The first assignment is the key.
55
(a) 𝜇X = a+b
2 .
(b) 𝜎2
X = 1
12 ⋅(b −a)2.
(c)
f(x)
F(x)
5
10
15
0.02
0.04
0.06
0.08
0.1
0.12
5
10
15
0.2
0.4
0.6
0.8
1.
1.2
56
P(X ∈M) =
w
b−a.
B.
Inference: Introduction
1
Bayesian/frequentist
(a) The frequentists.
(b) Both frequentists and Bayesians.
(c) The Bayesians.
(d) Both frequentists and Bayesians.
(e) The Bayesians.
(f) The frequentists.


B Solutions to Exercises
2-6
These assignments are for reflection, to be discussed in groups. There is
no fixed right answer.
B.
Bayes’Theorem for Distributions
1
– The total number of sacks is ∑10
x=1 17x = 935. The probability that he
picked a sack of type x is P(Ax) = 17x∕935 = x∕55.
– We will use Bayes’ theorem. The prior is the answer from the previous
sub-problem, P(Ax) = x∕55, whereas the likelihood is the probability of
B being “picking soft + soft”. The exact answer is hypergeometric, and
gives
P(B|Ax) =
(1 000 000 −2
10 000x2 −2
)/(1 000 000
10 000x2
)
.
However, since the number sampled is miniscule compared to the total,
we will employ the binomial approximation, yielding
P(B|Ax) = (10 000x2∕1 000 000)2 = x4∕10 000.
The Bayes table then becomes
x
fpre(x)
g(x)
fpre × g
fpost(x)
1, … , 10
x
55
x4
10 000
x5
550 000
x5
220 825
220 825
550 000
– Set x = 8 in the posterior expression, fpost(x) = x5∕220 825, and you get
f (8) = 85∕220 825 ≈0.148 4 .
2
k
fpre(k)
g(k)
fpre × g
fpost(k)
1, … , 100
k2
338 350
1
k
k
338 350
k
5050
1
67
3
(a) This is a geometric probability distribution with parameter p = 1
2, so
f (k) = 1
2k for all positive integers k.
(b) Ak means that there are k chocolates in the bag. There is always pre-
cisely one dark chocolate, whereas the rest are milk chocolates, so
when B = “you got a dark chocolate”, then P(B|Ak) = 1
k .

B.12 Bayes’ Theorem for Distributions

(c)
k
fpre(k)
g(k)
fpre ⋅g
fpost(k)
k ∈ℕ
1
2k
1
k
1
k⋅2k
1∕ln 2
k⋅2k
ln 2
4
(a) This is a geometric probability distribution with p = 0.5, so f (n) =
0.5n.
(b) After n trials, there are 2n rocks in the bag, whereof 2n −1 are gold
nuggets. The probability of sampling a gold nugget is then g(n) = 1 −
1
2n .
(c)
k
fpre(k)
g(k)
fpre ⋅g
fpost(k)
k ∈ℕ
1
2k
1 −1
2k
1
2k −
1
22k
1.5
2k −1.5
22k
2
3
(d) There is now one more rock and one gold nugget less than at the start.
The probability of sampling a gold nugget, given An (that the genie got
n heads), is then g2(n) = P(C|AnB) = 1 −2∕2n = 1 −1∕2n−1. We find
the probability of a gold nugget in the next try thus:
fpre2 = fpost1
g2(k)
fpre2 ⋅g2
k ∈ℕ
1.5
2k −1.5
22k
1 −2
2k
1.5
2k −4.5
22k +
3
23k
3
7
5
(a) f (x) = 1
15.
(b) g(x) = x
15 ⋅
(
1 −x
15
)
.
(c)
k
fpre(x)
g(x)
fpre ⋅g
fpost(x)
1, … , 15
1
15
x
15
(
1 −x
15
)
x
152
(
1 −x
15
)
3x
112
(
1 −x
15
)
112
675
(d)
k
fpre(x)
g(x)
fpre ⋅g
1, … , 15
3x
112 ⋅
(
1 −x
15
)
x
15
x2
560 ⋅
(
1 −x
15
)
1
2


B Solutions to Exercises
6
(a) The total number of handles is 1 + 2 + ⋯+ 7 = 28. Then, f (x) = x∕28.
(b) g(x) = (50 −x2)∕50.
(c)
k
fpre(x)
g(x)
fpre ⋅g
fpost(x)
1, … , 7
x
28
50−x2
50
x(50−x2)
1400
x(50−x2)
616
11
25
(d) Given that you picked sack x, it is g2(x) =
x4
2500, which gives
k
fpre(x)
g(x)
fpre ⋅g
1, … , 7
x(50−x2)
616
x4
2500
x5(50−x2)
1 540 000
203
1250
7
(a) The total number of nut packs is ∑5
x=1(30 −5x) = 150 −5 ∑5
x=1 x =
75, so f (x) = (30 −5x)∕75.
(b) g(x) = (10x∕100)2 = x2∕100.
(c)
k
fpre(x)
g(x)
fpre × g
fpost(x)
1, … , 5
30−5x
75
x2
100
x2(30−5x)
7500
x2(30−5x)
525
7
100
(d) Given that the picked pack was of type x, you have g2(x) = 10x
100, which
means
k
fpre(x)
g(x)
fpre × g
1, … , 5
x2(30−5x)
525
x
10
x3(30−5x)
5250
53
150
8
We see that the total set of dividing points for the piecewise defined func-
tions is {−2, −1, 0, 2}, so we divide the table according to indicated intervals
so as to see the functional expressions inside each interval:

B.12 Bayes’ Theorem for Distributions

x values
fpre(x)
g(x)
fpre × g
fpost(x)
⟨−∞, −2]
0
14
0
0
⟨−2, −1]
0.5 + 0.25x
14
7 + 3.5x
1.75 + 0.875x
⟨−1, 0]
0.5 + 0.25x
2
1 + 0.5x
0.25 + 0.125x
⟨0, 2]
0.5 −0.25x
3
1.5 + 0.75x
0.375 + 0.1875x
⟨2, ∞⟩
0
3
0
0
4
Detailed calculation of S:
S = ∫
−2
−∞
0 dx + ∫
−1
−2
7 + 3.5x dx + ∫
0
−1
1 + 0.5x dx
+ ∫
2
0
1.5 −0.75x dx + ∫
∞
2
0 dx
= 0 + 1.75 + 0.75 + 1.5 + 0 = 4.
(In this example, the rows for the values x ≤2 and x > 2 are included for
the sake of completeness. In general, rows where fpre × g = 0 for all x values
in the row’s interval may be omitted.)
Prior
Likelihood
Prior×Likelihood
Posterior
−3
−2
−1
1
2
3
0.1
0.2
0.3
0.4
0.5
−3
−2
−1
1
2
3
4
8
12
−3
−2
−1
1
2
3
1
2
3
−3
−2
−1
1
2
3
0.2
0.4
0.6
0.8
9
(a) The beta distribution is a conjugate prior for Bernoulli processes,
which makes calculations easier. Save the results of your manual calcu-
lations here, and return to this problem after having read Section 13.2,
and compare your calculations here to how you would solve this same
assignment by employing the methods there.
(b) Congratulations! You have just performed a hypothesis test. Save your
results, and revisit this assignment to compare to the calculation you
make by following the method in Section 14.2.2.
(c) Congratulations! You have just found an interval with an 80% proba-
bility of containing the true value of 𝜋. That is: P(𝜋∈[A1, B1]) = 0.8.
This is your first interval estimate. Save your results, and revisit this
assignment to compare to the calculation you would do following the
methods of Section 15.7.


B Solutions to Exercises
(d) The likelihood is g(x) = xk(1 −x)l.
(e) Write your prior as fpre(x) = K1xa−1 ⋅(1 −x)b−1. Then the posterior is
fpost(x) =
fpre(x)g(x)
∫1
0 fpre(x)g(x) dx
= (K1xa−1(1 −x)b−1) ⋅xk(1 −x)l
∫1
0 fpre(x)g(x) dx
= K2xa+k−1(1 −x)b+l−1
= 𝛽(a+k,b+l)(x).
You might wonder how we got K2, but think: could it be any
other value than the constant for 𝛽(a+k,b+l)(x), when we know that
∫1
0 𝛽(a+k,b+l)(x) dx = 1?
(f) You have now sharpened your hypothesis test by including more data.
(g) You have now sharpened your interval estimate by including more
data. Notice that the new interval is narrower than the first.
(h) Compare your guess to Section 15.7.
(i) If you made it this far, you have done a good piece of work and deserve
a decent coffee break. The rest of the book will not just be easy for you,
but plain sailing!
B.
Bayes’Theorem with Hyperparameters
Bayes’Theorem for Gaussian Processes
1
Unknown 𝜇, known 𝜎.
(a) 𝜇∼𝜙(4.686, 1.11803), and X+ ∼𝜙(4.686, 2.738 61).
Probabilities: P(𝜇<6) = 88.01% and P(X+ <6) = 68.43%.
(b) 𝜇∼𝜙(45.414 3, 2.267 79), and X+ ∼𝜙(45.414 3, 6.414 27).
Probabilities: P(𝜇<40) = 0.85% and P(X+ <40) = 19.93%
(c) 𝜇∼𝜙(338.667, 9.179 87), and X+ ∼𝜙(338.667, 18.359 7).
Probabilities: P(𝜇<350) = 89.15% and P(X+ <350) = 73.15%.
(d) 𝜇∼𝜙(2976.97, 57.735), and X+ ∼𝜙(2976.97, 208.167).
Probabilities: P(𝜇<3125) = 99.48% and P(X+ <3125) = 76.15%.
(e) 𝜅0 = 4 and Σ0 = 20, so 𝜇∼𝜙(5.3, 0.557 735) and X+ ∼𝜙(5.3, 2.081 67).
Probabilities: P(𝜇<6) = 88.732 7% and P(X+ <6) = 63.166 6%.
(f) 𝜅0 = 4 and Σ0 = 2040, so 𝜇∼𝜙(509.8,9.0) and X+ ∼𝜙(509.8,31.3).
Probabilities: P(𝜇<500) = 13.81% and P(X+ <500) = 37.71%.
(g) 𝜅0 = 1 and Σ0 = 0.19, so 𝜇∼𝜙(0.200,0.013) and X+ ∼𝜙(0.200,0.033).
Probabilities: P(𝜇<0.15) = 0.01% and P(X+ <0.15) = 6.49%.

B.13 Bayes’ Theorem with Hyperparameters

Known 𝜇, unknown 𝜎.
(h) 𝜏∼𝛾(2, 3.341 3)(t), while X+ ∼t(23, 1.292 54, 4)(x).
Probabilities:
P(𝜎< 1.25) = P(𝜏> 0.64) = 1 −P(𝜏<0.64) = 36.98%
and P(X+ <25) = 90.17%.
(i) 𝜏∼𝛾(3.5, 41.106 2)(t), while X+ ∼t(50, 3.427 04, 7)(x).
Probabilities: P(𝜎<10) = 99.72% and P(X+ <45) = 9.4%.
(j) 𝜏∼𝛾(6., 0.088 95)(t), while X+ ∼t(1.2, 0.125 505, 12)(x).
Probabilities: P(𝜎<0.1) = 12.22% and P(X+ <1) = 6.85%.
Unknown 𝜇, unknown 𝜎.
(k) 𝜏∼𝛾(3.5, 41 409)(t) and 𝜇∼t(3 979, 38.456 4, 7)(x), while
X+ ∼t(3979, 115.369, 7)(x). Probabilities: P(𝜎<100) = 30.84%, whereas
P(𝜇<4 000) = 69.90% and P(X+ <4 000) = 56.96%.
(l) 𝜏∼𝛾(3., 1 761.89)(t) and 𝜇∼t(11.528 6, 9.159 66, 6)(x), while
X+ ∼t(11.528 6, 25.907 4, 6)(x). Probabilities: P(𝜎<15) = 1.57%, whereas
P(𝜇<0) = 12.75% and P(X+ <0) = 33.60%.
(m) 𝜏∼𝛾(2., 1.612 37)(t) and 𝜇∼t(−0.583 5, 0.448 94, 4)(x), whereas
X+ ∼t(−0.583 5, 1.003 86, 4)(x). Probabilities: P(𝜎<0.5) = 1.18%, while
P(𝜇<0) = 86.82% and P(X+ <0) = 70.39%.
(n) 𝜏∼𝛾(6, 87.482)(t) and 𝜇∼t(22.756 8, 1.059 04, 12)(x), whereas
X+ ∼t(22.756 8, 3.962 56, 12)(x). Probabilities: P(𝜎<5) = 85.77%, while
P(𝜇<20) = 1.15% and P(X+ <20) = 24.99%.
(o) 𝜏∼𝛾(5, 5.401 91)(t)
and
𝜇∼t(19.737 5, 0.328 692, 10)(x),
whereas
X+ ∼t(19.737 5, 1.090 15, 10)(x).
Probabilities:
P(𝜎<1.179) = 65.11%,
while P(𝜇<17.9) = 0.01% and P(X+ <17.9) = 6.14%.
(p) 𝜏∼𝛾(3.5, 3302.45)(t)
and
𝜇∼t(92.137 5, 10.860 2, 7)(x),
whereas
X+ ∼t(92.137 5, 32.580 7, 7)(x). Probabilities: P(𝜎<25) = 15.86%, while
P(𝜇<50) = 0.30% and P(X+ <50) = 11.85%.
(q) 𝜏∼𝛾(17.5, 7.5⋅10−8)(t) and 𝜇∼t(3.305 3⋅10−6, 0.000 010 910 9, 35)(x), whereas
X+ ∼t(3.305 3⋅10−6, 0.000 066 368 4, 35)(x).
Probabilities:
P(𝜎<0.000 04) = 12.22%,
while
P(𝜇<−0.000 04) =
0.02% and P(X+ <−0.000 04) = 25.92%.
2
X+ = 𝜇+ (X+ −𝜇), and since these two stochastic variables are indepen-
dent, we employ Rule 10.1.10, and get that 𝜇X+ = E[𝜇] = Σ1
𝜅1 while 𝜎2
X+ =
𝜎2
𝜇+ 𝜎2
(X+−𝜇) = 𝜎2 +
(
𝜎
√1
𝜅1
)2
= 𝜎2 (
1 + 1
𝜅1
)2
.
3
The neutral prior hyperparameters are 𝜅0 = Σ0 = SS0 = n0 = 0, so 𝜈0 =
n0 −1 = −1. Updating these by means of the data then gives 𝜅1 = 25,
𝜈1 = 24, Σ1 = 1 229.75, SS1 = 110.94, so then
𝜏∼𝛾(12, 55.47)
𝜇∼t(49.19, 0.43, 24)


B Solutions to Exercises
X+ ∼t(49.19, 2.192 6, 24)
P(X+ > 50) = 1 −T(49.19, 2.192 6, 24)(50) = 0.357 5.
4
Non-informative = neutral prior means 𝜅0 = Σ0 = SS0 = n0 = 0, so 𝜈0 =
n0 −1 = −1. We see from the posterior of 𝜇that 𝜈1 = 6, which means that
the number of measurements is n = 𝜈1 −𝜈0 = 6 −(−1) = 7. That again
means that 𝜅1 = 0 + 7 = 7. We now look at 𝜇’s second parameter, and first
notice that
√
SS1
𝜈1 = 11 ⋅√𝜅1 = 11 ⋅
√
7. Further, the next parameter for
X+ equals
√
SS1
𝜈1 ⋅
√
1 + 1
𝜅1 = 11 ⋅
√
7 ⋅
√
1 + 1
7 = 11 ⋅
√
7 + 1 ≈31.112 7.
This gives us a predictive probability distribution
X+ ∼𝜇∼t(943, 31.1127, 6),
which allows us to calculate the specific probability,
P(X+ < 900) = T(943, 31.112 7, 6)(900) ≈0.1081 = 10.8%.
Bayes’Theorem for Bernoulli Processes
5
Posterior:
(a) Posterior: 𝜋∼𝛽(19,31). P(𝜋< 0.4) = 0.622 259. Normal approximation:
𝜋∼𝜙(0.38, 0.067 967 7). P(𝜋< 0.4) = 0.615 719.
(b) Posterior: 𝜋∼𝛽(5,96). P(𝜋< 0.07) = 0.836 836. Normal approxima-
tion: 𝜋∼𝜙(0.049 505, 0.021 478 3). P(𝜋< 0.07) = 0.830 015.
(c) Posterior hyperparameters: a1 = 42, b1 = 13. P(𝜋< 0.7) = 0.134 791.
Parameters
for
Normal
approximation:
𝜇= 0.763 636,
𝜎=
0.056 772 7. P(𝜋< 0.7) = 0.131 166.
(d) Posterior hyperparameters: a1 = 434.5, b1 = 177.5. P(𝜋< 0.7) =
0.290 458. Parameters for Normal approximation: 𝜇= 0.709 967,
𝜎= 0.018 327 9. P(𝜋< 0.7) = 0.293 278.
6
Predictive:
(a) K+5 ∼𝛽b(19,31,5) and L+5 ∼𝛽nb(19,31,5).
Probabilities: P(K+5 ≤3) = ßB(19,31,5)(3) = 0.917 656 and
P(L+5 ≤7) = ßNB(19,31,5)(7) = 0.499 604.
(b) K+20 ∼𝛽b(5,96,20) and L+4 ∼𝛽nb(5,96,4).
Probabilities: P(K+20 ≤3) = ßB(5,96,20)(3) = 0.974 169 and
P(L+4 ≤12) = ßNB(5,96,4)(12) = 0.012 409 5.
(c) K+7 ∼𝛽b(42,13,7) and L+14 ∼𝛽nb(42,13,14).
Probabilities: P(K+7 ≤4) = ßB(42,13,7)(4) = 0.225 352 and
P(L+14 ≤5) = ßNB(42,13,14)(5) = 0.699 216.
(d) K+32 ∼𝛽b(434.5,177.5,32) and L+20 ∼𝛽nb(434.5,177.5,20).

B.13 Bayes’ Theorem with Hyperparameters

Probabilities: P(K+32 ≤23) = ßB(434.5,177.5,32)(23) = 0.605 77
and P(L+20 ≤8) = ßNB(434.5,177.5,20)(8) = 0.573 26.
7
(a) Prior: 𝛽(0.5, 0.5). Posterior: 𝜋∼𝛽(9.5, 1.5).
(b) 𝜋∼𝛽(21.5, 3.5).
(c) 𝜋∼𝛽(24.5, 3.5).
(d) P(𝜋> 0.75) = 0.961 184. (For this assignment, use a good tool that has
the Beta distribution available in some form. In Mathematica/Wolfram
Alpha, you write 1-CDF[BetaDistribution[24.5, 3.5],0.75].)
(e) K+3 ∼𝛽b(24.5, 3.5,3)(x).
(f) P(K+3 = 2) = 𝛽b(24.5, 3.5,3)(2) = 0.269 289.
8
(a) a0 = np = 21 ⋅3
7 = 9 and b0 = n(1 −p) = 21 ⋅4
7 = 12.
(b) a1 = 32 and b1 = 30.
(c) New prior = old posterior: a1 = 32 and b1 = 30.
(d) New posterior: a2 = 490 and b2 = 396.
9
(a) Posterior: a1 = 41.5 and b1 = 9.5, so 𝜋∼𝛽(41.5, 9.5).
(b) We make use of the cumulative 𝛽distribution, and get
P(𝜋> 75%) = 1 −I(41.5, 9.5)(0.75) = 0.876.
If you calculate this by means of the Normal approximation,
𝛽(41.5, 9.5) ≈𝜙(0.814, 0.0540), which gives P(𝜋> 0.75) = 1 −P(𝜋≤0.75) =
1 −Φ(0.814, 0.0540)(0.75) = 0.882.
10
You are estimating the proportion of Macintoshes among the laptops of a
rather large company. Posterior: a1 = 15 and b1 = 5.
11
(a) Flat prior (Bayes, u = 1) gives 𝛽(20,154). Jeffreys’ prior (u = 0.5) gives
𝛽(19.5, 153.5). Novick and Hall (u = 0) give 𝛽(19,153).
(b) We first calculate the exact answer. Then flat prior gives P(𝜋> 0.1) =
71.9%. Jeffreys’ gives P(𝜋> 0.1) = 68.6%. Novick and Hall give P(𝜋>
0.1) = 65.0%. If we resort to the Normal approximation, our calcu-
lations give that for the flat prior, P(𝜋> 0.1) = 73.2%. Jeffreys’ gives
P(𝜋> 0.1) = 70.2%. Novick and Hall give P(𝜋> 0.1) = 67.0%. We are
therefore best off to report that the probability that these diamond
mines yield more than 1
10 high grade fancy diamonds is 2
3.
12
Let 𝜋be the proportion of games won by white.
(a) Prior hyperparameters: a0 = 7, b0 = 7.
Posterior hyperparameters: a1 = 20, b1 = 14. Then 𝜋∼𝛽(20,14).


B Solutions to Exercises
(b) 𝜋∼𝛽(31,23).
(c) P(𝜋≥0.5) = 0.864 16.
Using the Normal approximation will give P(𝜋≥0.5) = 0.867.
Bayes’Theorem for Poisson Processes
13
(a) Posterior: 𝜆∼𝛾(7,5).
(b) Posterior hyperparameters: 𝜅1 = 8, 𝜏1 = 17.
(c) Posterior: 𝜆∼𝛾(29,8).
(d) Posterior hyperparameters: 𝜅1 = 9, 𝜏1 = 192.
14
(a) Predictive: N+1 ∼nb(7, 5
6 )(𝜂) and T+2 ∼g𝛾(2,7,5).
Probabilities: P(T+2 ≤3) = GΓ(2,7,5)(3) = 0.864 958 and
P(N+1 ≤4) = NB(7,0.833 333)(4) = 0.975 494.
(b) Predictive: N+1 ∼nb(8, 17
18 )(𝜂) and T+ = T+1 ∼g𝛾(1,8,17).
Probabilities: P(T+ ≤2) = GΓ(1,8,17)(2) = 0.589 264 and
P(N+1 ≤1) = NB(8,0.944 444)(1) = 0.914 349.
(c) Predictive: N+1 ∼nb(29, 8
9 )(𝜂) and T+3 ∼g𝛾(3,29,8).
Probabilities: P(T+3 ≤1) = GΓ(3,29,8)(1) = 0.684 853 and
P(N+1 ≤5) = NB(29,0.888 889)(5) = 0.829 829.
(d) Predictive: N+1 ∼nb(9, 192
193 )(𝜂) and T+2 ∼g𝛾(2,9,192).
Probabilities: P(T+2 ≤30) = GΓ(2,9,192)(30) = 0.400 007 and
P(N+1 ≤0) = P(N+1 = 0) = nb(9,0.994 819)(0) = 0.954 323.
15
Prior: 𝜅0 = 0, 𝜏0 = 0. Data: n = 111, t = 23. Posterior: 𝜅1 = 111, 𝜏1 = 23.
Then 𝜆∼𝛾(111,23).
16
Prior: 𝜅0 = 0, 𝜏0 = 0. Data: n = 53, t = 26. Posterior: 𝜅1 = 53, 𝜏1 = 26.
Then 𝜆∼𝛾(53,26).
17
Prior: 𝜅0 = 0, 𝜏0 = 0. Data: n = 13, t = 10. Posterior: 𝜅1 = 13, 𝜏1 = 10.
Then 𝜆∼𝛾(13,10).
18
This corresponds to three updates in one go, with 𝜏0 = 0, t1 = 1.9, t2 = 0.7,
and t3 = 1.2, so 𝜏3 = 3.8, while 𝜅0 = 0, n1 = 0, n2 = 3, and n3 = 1, so 𝜅3 =
4. Then 𝜆∼𝛾(4,3.8).
19
Prior: 𝜅0 = 0, 𝜏0 = 0. Data: n = 157, t = 100 (1 deciliter = 100 cm3). Pos-
terior: 𝜅1 = 157, 𝜏1 = 100. Then 𝜆∼𝛾(157,100).

B.14 Bayesian Hypothesis Testing

B.
Bayesian Hypothesis Testing
Utility Functions
1
In the problems below, you are given the probability distribution of a
stochastic variable X and a utility function u(x). Find the expected utility
U.
(a) U = 3E[X] + 2 = 3 ⋅
17
17+9 + 2 = 3.961 54.
(b) U = 9 ⋅P(X < 0.3) −4 ⋅P(X > 0.3) = 9 ⋅Γ(7,21)(0.3) −4 ⋅
(1 −Γ(7,21)(0.3)) = 1.742 97.
(c) U = −1 ⋅P(X < 3) + 1.5 ⋅P(3 < X < 6) + 4 ⋅P(X > 6) = −1 ⋅
Φ(5.3,1.9)(3) + 1.5 ⋅(Φ(5.3,1.9)(6) −Φ(5.3,1.9)(3)) + 4 ⋅(1 −Φ(5.3,1.9)(6)) =
2.108 1.
(d) U = −1 ⋅P(X < 15) + 7 ⋅P(X > 15) = −1 ⋅T(10,5,2)(15) + 7 ⋅
(1 −T(10,5,2)(15)) = 0.690 599.
(e) U = −2E[X] + 90 = −2 ⋅41.3 + 90 = 7.4.
(f) U = −5E[X] + 8 = −5 ⋅(−2.73) + 8 = 21.65.
2
You are going to decide whether A: Θ < 𝜃0 or B: Θ > 𝜃0. The gain in utility
of choosing A instead of B is
u(x) =
{
wA
x < 𝜃0
−wB
x > 𝜃0.
In the first three subproblems below, you are given 𝜃0, wA, and wB. For-
mulate the decision problem as a hypothesis test by indicating significance
level 𝛼and stating the alternative hypothesis H1.
(a) Since wB < wA, then H1 is the same as B, which is that Θ > 7, and the
significance level is 𝛼=
wB
wB+wA =
1
1+9 = 0.1.
(b) wA < wB, so then H1 = A: Θ < −3, and 𝛼=
25
25+175 = 0.125.
(c) wA < wB, so then H1: Θ < 100, and 𝛼=
1
1+100 ≈0.01.
(d) 𝜃0 = 17, A = “not produce” (Θ < 17), B = “produce” (Θ > 17). wA = 19,
wB = 1. Since wB < wA, then H1 is the same as B, which is that Θ > 17,
and the significance level is 𝛼=
wB
wB+wA =
1
1+19 = 0.05.
Hypothesis Test for Gaussian Processes
3
You are given the posterior distribution 𝜃∼f (x), the significance 𝛼,
and alternative hypothesis H1. Test, and decide between the competing
hypotheses.
(a) H0: 𝜃≤3, and so P(H0) = Φ(7,2)(3) = 0.022 < 𝛼, so we reject H0.


B Solutions to Exercises
(b) H0: 𝜃≤7, and so P(H0) = Φ(9,2)(7) = 0.158 ≥𝛼, so we don’t reject H0.
(c) H0: 𝜃≥16, and so P(H0) = 1 −Φ(8,3)(16) = 0.004 < 𝛼, so we reject H0.
(d) H0: 𝜃≤3, and so P(H0) = T(7,2,3)(3) = 0.069 663 > 𝛼so we don’t reject
H0 in favor of H1.
(e) Here, H0: X ≤4, and so P(H0) = T(9,2,5)(4) = 0.027 < 𝛼, so we reject H0
in favor of H1.
(f) Here, H0: X ≥16, and so P(H0) = 1 −T(24,3,1)(16) = 0.885 8 > 𝛼so we
don’t reject H0 in favor of H1.
4
𝜇∼t(0.984,0.007 18,9), so then P(𝜇≥1.0) = 0.026 4 < 𝛼, which means you
reject H0, and conclude that the mean serving contains less than 1.0 pint.
5
In the corresponding problem, problem (3) in Chapter 13, we found
that the posterior distribution was 𝜇∼t(49.19, 0.43, 24), so that P(H0) = 1 −
T(49.19, 0.43, 24)(50) = 0.035 9 > 𝛼, which means that we don’t reject H0.
Hypothesis Test for Bernoulli Processes
6
You are given a (posterior) distribution for 𝜋∼𝛽(a,b), a significance 𝛼, and
H1. Test the following competing hypotheses, to decide between them,
both by direct calculation and by Normal approximation.
(a) H0:
𝜋≤0.5,
which
gives
us
P(H0) = I(35,24)(0.5) = 0.074 < 𝛼,
which means that we reject H0. Normal approximation gives
𝜋∼𝜙(0.593,0.063 4), and so P(H0) = Φ(0.593,0.063 4)(0.5) = 0.071 < 𝛼, so
therefore we reject H0.
(b) H0: 𝜋≥0.85, and so P(H0) = 0.055 > 𝛼, which means that we don’t
reject H0. Normal approximation gives 𝜋∼𝜙(0.788,0.040 9), and so
P(H0) = 0.064 > 𝛼, so therefore we don’t reject H0.
(c) Then the posterior is 𝜋∼𝛽(23,52). Further, H0: 𝜋≤0.2, and so P(H0) =
0.015 9 < 𝛼, which means that we reject H0. Normal approximation
gives 𝜋∼𝜙(0.307,0.052 9), and so P(H0) = 0.021 9 > 𝛼, so therefore we
don’t reject H0. We therefore take note of this: that in cases where we
are very close to the limit set by the significance, the Normal approx-
imation may yield the opposite conclusion of what exact calculation
does.
7
P(H0) = P(𝜋≤0.75) = I(41.5 9.5)(0.75) = 0.124 > 𝛼, so you don’t reject H0.
MegaCola does not launch their campaign. (Using Normal approximation,
you get P(𝜋≤0.75) = 0.118.)
8
H0 is then 𝜃< 0.1. The posterior distribution is 𝜋∼𝛽(19.5, 153.5), and so
P(H0) = 0.314 > 0.1, and you don’t reject H0. The mining company will not
buy the new equipment.

B.14 Bayesian Hypothesis Testing

Hypothesis Test for Poisson Processes
9
You are given a probability distribution for 𝜏∼𝛾(k,𝜆), a significance 𝛼, and
H1. Determine the hypothesis test, both by direct calculation and by using
the Normal approximation.
(a) H0: 𝜏≥4, and so P(H0) = 1 −Γ(6,3)(4) = 0.020 341 < 𝛼, which means
that we reject H0. Normal approximation gives 𝜋∼𝜙(2,0.816 497), and so
P(H0) = Φ(2,0.816 497)(4) = 0.007 < 𝛼, so therefore we reject H0.
(b) H0:
𝜏≤0.2,
and
so
P(H0) = Γ(10, 29.7)(0.2) = 0.079 9 > 𝛼,
which
means that we don’t reject H0. Normal approximation gives 𝜋∼
𝜙(0.336 7,0.106 474), and so P(H0) = Φ(0.336 7, 0.106 474)(0.2) = 0.099 6 > 𝛼,
so therefore we don’t reject H0.
(c) H0: 𝜏≤0.5, and so P(H0) = Γ(17.5, 53.4)(0.5) = 0.976 023 > 𝛼, which
means that we don’t reject H0. Normal approximation gives 𝜋∼
𝜙(0.327 7,0.078 34), and so P(H0) = Φ(0.327,7, 0.078 34)(0.5) = 0.986 1 > 𝛼, so
therefore we don’t reject H0.
(d) H0:
𝜏≥3.2,
and
so
P(H0) = Γ(20∕3,
√
32)(3.2) = 0.000 818 < 𝛼,
which means that we reject H0. Normal approximation gives
𝜋∼𝜙(1.197 4, 0.463 7),
and
so
P(H0) = 1 −Φ(1.1974, 0.4637)(3.2) =
0.000 007 86 < 𝛼, so therefore we reject H0.
10
Prior: 𝜅0 = 0, 𝜏0 = 0. Data: n = 53, t = 26. Posterior: 𝜅1 = 53, 𝜏1 = 26.
Then 𝜆∼𝛾(53, 26). Then P(H0) = P(𝜆≤1.5) = Γ(53, 26)(1.5) = 0.019 < 𝛼,
which means that we reject H0.
11
Prior: 𝜅0 = 0, 𝜏0 = 0. Data: n = 157, t = 100 (1 deciliter = 100 cm3). Poste-
rior: 𝜅1 = 157, 𝜏1 = 100. Then 𝜆∼𝛾(157,100). Then P(H0) = P(𝜆≥1.75) =
1 −Γ(157,100)(1.75) = 0.079 > 𝛼, which means that we don’t reject H0.
Pairwise Comparison for Gaussian Processes
12
The posterior probability distributions are 𝜇K ∼t(15.571 4, 2.784 8, 6) and 𝜇O ∼
t(20.625, 0.323 899, 7), so with Θ = 𝜇O −𝜇K, we get Θ ∼t(5.053 57, 2.803 57, 6).
The hypothesis that Odd coughs longest in the mean is then H1:
Θ > 0, whereas H0: Θ ≤0. Then P(H0) = T(5.053 57, 2.803 57, 6)(0) = 0.061 <
0.2, which means that we reject the null hypothesis H0 in favor of the alter-
native hypothesis H1. Odd may therefore conclude that his coughing bouts
are indeed the longest lasting in the mean.
13
The
posterior
distributions
become
𝜇B ∼t(72.5, 7.093, 5)
and
𝜇P ∼
t(48.8, 1.827, 4), so 𝜇B −𝜇P = Θ ∼t(23.7, 7.325, 5). The claim that Baggins
purrs the longest is then H1: Θ > 0. You decide the hypothesis test by
calculating: P(H0) = P(Θ ≤0) = T(23.7, 7.325, 5)(0) = 0.0115 < 𝛼, so you
reject H0. Baggins purrs the longest.


B Solutions to Exercises
Pairwise Comparison for Poisson Processes
14
(a) P(H0) = F(2k, 2m)
(
ml
kn
)
= F(2⋅7, 2⋅4)
(
4⋅70
7⋅80
)
= 0.123 > 𝛼,
which means we don’t reject H0 and don’t say that Θ > Ψ.
(b) P(H0) = 1 −F(2k,2m)
(
ml
kn
)
= 1 −F(2⋅9,2⋅11)
(
11⋅20
9⋅20
)
= 0.324 > 𝛼,
which means that we don’t reject H0 and don’t say that Θ < Ψ.
(c) The assignment says that Θ ∼𝛾(90, 200), and Ψ ∼𝛾(110, 200).
Significance 𝛼= 0.1, and H1: Θ < Ψ. Then
P(H0) = 1 −F(2k, 2m)
(
ml
kn
)
= 1 −F(2⋅90, 2⋅110)
(110 ⋅200
90 ⋅200
)
= 0.078 < 𝛼,
which means that we reject H0 and say that Θ < Ψ.
15
𝜆Highlands ∼𝛾(65, 8). You already know that 𝜆Lowlands ∼𝛾(111, 23), so
P(H0) = P(𝜆Highlands ≤𝜆Lowlands) = P
(𝜆Highlands
𝜆Lowlands
≤1
)
= F(2k,2m)
(
ml
kn
)
= F(2⋅65,2⋅111)
(111 ⋅8
65 ⋅23
)
= 0.06% < 𝛼.
You therefore reject H0, and conclude that the catch rate is higher in the
Highlands than in the Lowlands.
Pairwise Comparison for Bernoulli Processes
16
(a) P(H0) = P(𝜓≥𝜋) = P(𝜋≤𝜓). Exact (Rule A.3.3):
P(H0) =
2−1
∑
k=0
B(4+k, 3+5)
(5+k)⋅B(k+1, 5)⋅B(4,3) = 0.121 212 > 𝛼,
which means that we don’t reject H0.
Normal approximation:
P(H0) = Φ(
4
4+3 −2
2+5
√
4⋅3
(4+3)2(4+3+1) +
2⋅5
(2+5)2(2+5+1)
)(0) = 0.113 9 > 𝛼,
which again means that we don’t reject H0.
(b) P(H0) = P(𝜓≤𝜋). Exact (Rule A.3.3):
P(H0) =
17−1
∑
k=0
B(23+k, 17+23)
(23+k)⋅B(k+1, 23)⋅B(23,17) = 0.086 941 < 𝛼.
Exact reject H0.
Normal approximation: P(H0) = 0.084 743 9 < 𝛼, which means that we
reject H0.
(c) P(H0) = P(𝜓≤𝜋). Exact (Rule A.3.3):
17−1
∑
k=0
B(20+k, 20+23)
(23+k)⋅B(k+1, 23)⋅B(20,20) = 0.247 963 > 𝛼,
which means that we don’t reject H0.

B.15 Estimates

Normal approximation: P(H0) = 0.247 301 > 𝛼, which again means
that we don’t reject H0.
(d) In other words: 𝜓∼𝛽(200,200) and 𝜋∼𝛽(170,230), 𝛼= 0.05, H1: 𝜓> 𝜋.
Then P(H0) = P(𝜓≤𝜋). Exact calculation (Rule A.3.3):
P(H0) =
170−1
∑
k=0
B(200+k, 200+230)
(230+k)⋅B(k+1, 230)⋅B(200,200) = 0.016 552 4 < 𝛼,
which means that we reject H0.
Normal approximation: P(H0) = 0.016 338 9 < 𝛼, which again means
that we reject H0.
17
(Recall that “success” in this context is an erroneous delivery, not a delivery
well made.) Imperial Deliveries: 196 correct, 4 errors, making the posterior
probability distribution 𝜋ID ∼𝛽(5,197). Centurium Falcon Freight: 199 cor-
rect, 1 error, making the posterior probability distribution 𝜋CFF ∼𝛽(2,200).
For our problem, we have that H0: 𝜋ID ≤𝜋CFF, which means
P(𝜋ID ≤𝜋CFF) =
2−1
∑
k=0
B(5+k, 197+200)
(200+k)⋅B(k+1, 200)⋅B(5,197) = 0.107 617 < 𝛼.
Calculating by means of Normal approximation gives P(H0) = 0.125 374 <
𝛼. In both cases, you reject the null hypothesis that Imperial Deliveries are
at least as good as Centurium Falcon Freight when it comes to error rate,
and you therefore choose Centurium Falcon Freight as your freight com-
pany from now on.
B.
Estimates
Gaussian Processes With Known 𝝈
1
From distribution to interval.
(a) I𝜇
0.025,l = (−∞, 19.879 9) and I𝜇
0.025,r = (8.12011, ∞), and
I𝜇
0.05 = (8.1201 1, 19.879 9).
(b) I𝜇
0.005,r = (−22.846, ∞) and I𝜇
0.005,l = (−∞, 14.246), and
I𝜇
0.01 = (−22.846, 14.246).
(c) I𝜇
0.1 = (40.830 2, 55.169 8).
(d) I+
0.005 = (0.017 623 9, 0.018 376 1).
(e) Does not exist, since 𝜎≤0.
2
From data + prior to interval. Find I𝜇
2𝛼and I+
2𝛼.
(a) I𝜇
0.05 = (3.64, 6.36) and I+
0.05 = (0.29, 9.71).


B Solutions to Exercises
(b) I𝜇
0.1 = (179.7, 188.7) and I+
0.1 = (159.1, 209.3).
(c) I𝜇
0.02 = (5.04, 5.18) and I+
0.02 = (4.87, 5.35).
3
Sample size:
(a) n = 2 655.
(b) n = 146.
4
I𝛼= (17.2, 17.8).
5
(Did you remember to convert 3 cm to 0.03 m?)
I𝜇
0.1 = (1.554 4, 1.585 6) and I+
0.1 = (1.518 25, 1.621 75).
Gaussian Processes With Unknown 𝝈
6
From distribution to interval.
(a) I𝜇
0.001 = (20.915, 115.285).
(b) I𝜇
0.001 = (−34.3626, 170.563) and I𝜇
0.1 = (42.731, 93.469).
(c) I+
0.02 = (1.40246, 8.59754).
7
From data + prior to interval. Find I𝜇
2𝛼and I+
2𝛼. In addition, find I𝜏
2𝛼and I𝜎
2𝛼.
(a) I𝜏
0.05 = (0.919 908, 14.201 8), so I𝜎
0.05 = (0.265 355, 1.042 62).
I𝜇
0.05 = (0.201 377, 1.093 62), whereas I+
0.05 = (−0.532 83, 1.827 83).
(b) I𝜏
0.1 = (0.002 895 68, 0.007 780 3), so I𝜎
0.1 = (11.337 1, 18.583 4).
I𝜇
0.1 = (142.799, 152.609), whereas I+
0.1 = (123.181, 172.228).
(c) I𝜏
0.05 = (0.051 064 2, 0.122 647), so I𝜎
0.05 = (2.855 44, 4.425 29).
I𝜇
0.05 = (18.759, 20.921 9), whereas I+
0.05 = (12.749, 26.932).
8
Sample size:
(a) n ≥
4t2
12 , 0.05
1.32
⋅17
6 −7 = 14.3, so the smallest number is n = 15.
(b) n ≥
4t2
8 , 0.07
22
⋅50
4 −5 = 28.5, so the smallest number is n = 29.
9
I𝜇
0.04 = (365.5, 390.5).
10
I𝜇
0.1 = (29.0, 32.4).
11
I𝜇
0.1 = (4.44, 6.44), whereas I+
0.1 = (2.12, 8.76). Further, I𝜏
0.1 = (0.124, 0.629),
so I𝜎
0.1 = (1.26, 2.84).
12
I𝜇
0.05 = (7.4, 8.1).

B.15 Estimates

Poisson Process
13
From distribution to interval.
(a) I𝜆
0.05 = (0.064, 0.516).
(b) I𝜆
0.001 = (0.010 53, 0.148 9).
(c) I𝜆
0.1 = (0.044 420 2, 0.592 983).
14
From data + prior to interval. Find I𝜇
2𝛼and I+
2𝛼.
(a) I𝜆
0.02 = (0.327 244, 1.069 72).
(b) I𝜆
0.1 = (0.377 166, 0.596 314).
(c) I𝜆
0.001 = (0.010 53, 0.1489).
15
n ≥
4z2
0.1
0.22 −5 = 159.237, so the smallest number is n = 160.
16
I𝜆
0.15 = (4.18, 5.50).
17
I𝜆
0.2 = (1.69, 2.40).
18
I𝜆
0.08 = (0.74, 1.99).
19
I𝜆
0.1 = (0.36, 2.04).
20
I𝜆
0.05 = (1.33, 1.82).
Bernoulli Process
21
From distribution to interval.
(a) Exact: I𝜋
0.1 = (0.246 666, 0.375 169).
Normal approximation: I𝜋
0.1 = (0.245 096, 0.373 609).
(b) Exact: I𝜋
0.001 = (0.010 241 5, 0.135 421).
Normal approximation: I𝜋
0.001 = (−0.010 711, 0.114 415).
(c) I𝜋
0.05 = (0.094 299 3, 0.905 701).
(d) I𝜋
0.12 = (0.06, 0.94).
22
From data + prior to interval. Find I𝜋
𝛼.
(a) Exact: I𝜋
0.07 = (0.258 303, 0.530 382).
Normal approximation: I𝜋
0.07 = (0.253 862, 0.526 626).
(b) Exact: I𝜋
0.1 = (0.122 851, 0.527 327).
Normal approximation: I𝜋
0.1 = (0.104 797, 0.510 587).
(c) Exact: I𝜋
0.05 = (0.578 125, 0.800 939).
Normal approximation: I𝜋
0.05 = (0.583 418, 0.807 207).


B Solutions to Exercises
(d) Exact: I𝜋
0.02 = (0.226 254, 0.351 71).
Normal approximation: I𝜋
0.02 = (0.223 866, 0.349 611).
23
n =
z2
0.1
0.052 −12 −31 = 613.95, so at least 614 new observations.
24
(a) I𝜋
0.1 = (0.412 2, 0.619 5).
(b) I𝜋
0.1 = (0.525 5, 0.580 4).
(c) I𝜋
0.1 = (0.548 9, 0.564 6).
(d) Since we are looking at the total number of flips, we do not subtract our
previous flips, a and b, so n =
z2
0.05
0.012 = 27 055.4, that is, at least 27 056.
25
(a) I𝜋
0.2 = (0.479 5, 0.694 7).
(b) I𝜋
0.2 = (0.487 5, 0.659 4).
(c) a2 = 31 and b2 = 23, and so n =
z2
0.1
0.052 −31 −23 = 602.95,
in other words, he needs 603 more observations.
(d) I𝜋
0.2 = (0.552 1, 0.601 5).
B.
Frequentist Inference
Interval Estimates
1
Find the P% = (1 −𝛼)100% interval estimates ̂I𝜇
𝛼and ̂I+
𝛼; 𝜎is known.
(a) ̂
I𝜇
0.1 = 4.32 ± z0.05 × 2 ×
√
1
10 = (3.279 7, 5.360 3) and
̂
I+
0.1 = 4.32 ±
z0.05 × 2 ×
√
1 + 1
10 = (0.869 726, 7.770 27).
(b) ̂
I𝜇
0.05 = 66.008 5 ± z0.025 × 12.1 ×
√
1
47 = (62.549 2, 69.467 8)
and
̂
I+
0.05 = 66.008 5 ± z0.025 × 12.1 ×
√
1 + 1
47 = (42.042, 89.975).
(c) ̂
I𝜇
0.001 = 27.404 6 ± z0.000 5 × 3.73 ×
√
1
10 000 = (27.281 9, 27.527 4) and
I+
0.001 = 27.404 6 ± z0.000 5 × 3.73 ×
√
1 +
1
100 00 = (15.130 4, 39.678 9).
2
Find the P% = (1 −𝛼)100% interval estimates ̂I𝜇
𝛼, ̂I𝜎
𝛼(use that 𝜎= 1∕
√
𝜏)
and ̂I+
𝛼; 𝜎is unknown.
(a) ̂
I𝜏
0.1 = (0.212 132, 0.518 018),
so
I𝜎
0.1 = (1.389 4, 2.171 18).
I𝜇
0.1 = 8.206 9 ± t28,0.05 × 1.688 18 ×
√
1
29 = (7.673 61, 8.740 18), while
̂
I+
0.1 = 8.206 9 ± t28,0.05 × 1.688 18 ×
√
1 + 1
29 = (5.285 99, 11.127 8).

B.16 Frequentist Inference

(b) ̂
I𝜏
0.02 = (0.037 7407, 0.052 533 8),
so
I𝜎
0.02 = (4.362 95, 5.147 48).
I𝜇
0.02 = 29.688 6 ± t397,0.01 × 4.724 27 ×
√
1
398 = (29.135 5, 30.241 7),
while
̂
I+
0.02 = 29.688 6 ± t397, 0.01 × 4.724 27 ×
√
1 +
1
398 =
(18.639 9, 40.737 3).
(c) We calculate and find the statistics n = 8, Sx = 466.4, SSx = 196.28,
and get: ̂
I𝜏
0.02 = (0.006 312 63, 0.094 127 3), so I𝜎
0.02 = (3.26, 12.59).
I𝜇
0.02 = 58.3 ± t7,0.01 × 5.295 28 ×
√
1
8 = (52.687 3, 63.912 7),
while
̂
I+
0.02 = 58.3 ± t7, 0.01 × 5.295 28 ×
√
1 + 1
8 = (41.462, 75.138).
3
Find the (1 −𝛼)100% confidence interval ̂Ip
𝛼.
(a) ̂
I𝜋
0.05 = 0.404 762 ± z0.025 ×
√
0.404 762(1−0.404 762)
42
=
(0.256 316, 0.553 208).
(b) The numbers are k = 46 positives and l = 54 negatives. 𝛼= 0.1. Then
̂
I𝜋
0.1 = 0.46 ± z0.05 ×
√
0.46(1−0.46)
100
= (0.378 021, 0.541 979).
Hypothesis Testing
4
Determine the hypothesis test outcome about the parameter 𝜋for a
Bernoulli process; significance 𝛼.
(a) Since
k + l < 30,
we
do
an
exact
calculation.
p = P(X ≥8) =
∑14
m=8
(
14
m
)
× 0.5m(1 −0.5)14−m = 0.395 264 > 𝛼, so we don’t reject
the null hypothesis.
(b) p = P(X ≤2) = ∑2
m=0
(
20
m
)
× 0.25m(1 −0.25)20−m = 0.091 3 < 𝛼,
so
we reject the null hypothesis.
(c) k + l > 30, so we may use a normal approximation: w =
0.04−0.1
0.019 595 9 =
−3.061 86.
Φ(w) = Φ(−3.06 186) = 0.0011 < 𝛼,
so
we
reject
the
null
hypothesis.
By
comparison,
exact
calculation
gives
p = P(X ≤4) = ∑4
m=0
(
100
m
)
× 0.1m(1 −0.1)100−m = 0.023 711 1 < 𝛼,
which also implies that we reject H0.
(d) k + l > 30, so we may use a normal approximation: w =
0.4−0.5
0.048 989 8 =
−2.041 24. Φ(−|w|) = Φ(−2.041 24) = 0.021 < 0.05
2 , so we reject the
null hypothesis, and may say 𝜋≠0.5.
We may check this by direct calculation as well, by checking if
the probability one way is less than 𝛼
2. We see that p = P(X ≤40) =
∑40
m=0
(
100
m
)
× 0.5m(1 −0.5)100−m = 0.028 < 𝛼
2, so we reject the null
hypothesis when we go via direct calculation as well.


B Solutions to Exercises
(e) The numbers of this problem are: H1 : 𝜋≠0.5, 𝛼= 0.1. You have
n = 100 trials with k = 46 successes. This means that w =
0.46−0.5
0.049 839 7 =
−0.802 572,
so
Φ(−|w|) = Φ(−0.802 572) = 0.211 111 > 𝛼,
which
means we don’t reject the null hypothesis.
5
Determine the hypothesis test outcome about the mean 𝜇for a Gaussian
process; significance 𝛼.
(a) w = 26.493 8−25.
3.73
√
27
= 2.080 99, so Φ(−|w|) = Φ(−2.080 99) = 0.019 < 𝛼
2,
so we reject the null hypothesis.
(b) w = 80.674 1−80.
5.1
√
200
= 1.869 22, so Φ(−w) = Φ(−1.869 22) = 0.030 796 4 >
𝛼, so we don’t reject the null hypothesis.
(c) w = 31.9−25
7.997 86
√
8
= 2.440 17, so Φ(−|w|) = Φ(−2.440 17) = 0.022 4 > 𝛼
2, so
we don’t reject the null hypothesis.
(d) w = 99.3−100.
10.383 8
√
500
= −1.507 39, so T(w) = T(−1.507 39) = 0.066 2 > 𝛼, so
we don’t reject the null hypothesis.
6
w = 60 376.3−60 000
423.645
√
15
= 3.439 85. The null hypothesis is that the mean is
60 000, so we calculate T𝜈(−w) = T14(−3.439 85) = 0.001 99 < 𝛼, and see
that we must reject the null hypothesis.
7
Determine the hypothesis test outcome concerning the variance 𝜎2 of a
Gaussian process; significance 𝛼.
(a) n = 15, SSx = 768.773, so
SSx
𝜎2
0
= 768.773
102
= 7.687 73. Since 𝜒2
14,0.05 =
6.570 63, it follows that SSx
𝜎2
0
> 𝜒2
𝜈,𝛼, and hence we don’t reject the null
hypothesis.
(b) This gives us SSx = 4070.72, so
SSx
𝜎2
0
= 4070.72
52
= 162.829. Since
𝜒2
99,0.98 = 129.996, it follows that SSx
𝜎2
0
> 𝜒2
𝜈,𝛼, and hence we reject the
null hypothesis.
8
From the data, we get that n = 15, SSx = 2.512 65 × 106. Then
SSx
𝜎2
0
=
2.512 65 × 106
6662
= 5.66 478. The comparison values are 𝜒2
𝜈,𝛼∕2 = 𝜒2
14,0.05 =
6.570 63 and 𝜒2
𝜈,1−𝛼∕2 = 𝜒2
14,0.95 = 23.684 8. We see that SSx
𝜎2
0
< 𝜒2
𝜈,𝛼∕2, and
hence we reject the null hypothesis that 𝜎= 666.

B.17 Linear Regression

B.
Linear Regression
1
Volume training 1:
(a) – 𝜏∼𝛾( 8
2 , 132.296
2
)
– y(x) ∼t(
244.08+7.19091(x−31.968), 4.066 57 ×
√1
5 +
1
520.561 (x−31.968)2, 8
)
– Y+(x) ∼t(
244.08+7.19091(x−31.968), 4.06657 ×
√
6
5 +
1
520.561 (x−31.968)2, 8
)
– I0.05 = 244.08 + 7.190 9(x −31.968) ± 9.3775
×
√
1
5 +
1
520.56(x −31.968)2
– I+
0.1 = 244.08 + 7.190 9(x −31.968) ± 7.562
×
√
6
5 +
1
520.56(x −31.968)2.
(b) – 𝜏∼𝛾(0.5, 0.75)
– y(x) ∼t(
3+0.5(x−2), 1.224 74 ×
√1
3 + 1
2 (x−2)2, 1
)
– Y+(x) ∼t(
3+0.5(x−2), 1.224 74 ×
√4
3 + 1
2 (x−2)2, 1
)
– I0.1 = 3 + 0.5(x −2) ± 7.732 7 ×
√
1
3 + 1
2(x −2)2
– I+
0.1 = 3 + 0.5(x −2) ± 7.732 7 ×
√
4
3 + 1
2(x −2)2.
(c) – 𝜏∼𝛾(3, 0.735 714)
– y(x) ∼t(
8.25−0.657 143(x−3.75), 0.495 215 ×
√1
4 +
1
8.75 (x−3.75)2, 6
)
– Y+(x) ∼t(
8.25−0.657 143(x−3.75), 0.495 215 ×
√
5
4 +
1
8.75 (x−3.75)2, 6
)
– I0.05 = 8.25 −0.657 143(x −15∕4) ± 1.211 75
×
√
1
4 +
1
8.75(x −3.75)2
– I+
0.05 = 8.25 −0.657 143(x −3.75) ± 1.211 75
×
√
5
4 +
1
8.75(x −3.75)2.
(d) – 𝜏∼𝛾(1, 4.5)
– y(x) ∼t(
3.5+2.(x−1.5), 2.121 32 ×
√1
4 + 1
5 (x−1.5)2, 2
)
– Y+(x) ∼t(
3.5+2.(x−1.5), 2.121 32 ×
√
5
4 + 1
5 (x−1.5)2, 2
)
– I0.1 = 3.5 + 2(x −1.5) ± 6.194 23 ×
√
1
4 + 1
5(x −1.5)2
– I+
0.05 = 3.5 + 2(x −1.5) ± 9.127 3 ×
√
5
4 + 1
5(x −1.5)2.
(e) – 𝜏∼𝛾(0.5, 0.914 557)
– y(x) ∼t(
6−0.056 962(x−2.33 33), 1.352 45 ×
√1
3 +
1
52.667 (x−2.333 3)2, 1
)
– Y+(x) ∼t(
6−0.056 962(x−2.333 3), 1.352 45 ×
√4
3 +
1
52.667 (x−2.333 3)2, 1
)


B Solutions to Exercises
– I0.02 = 6 −0.056 962(x −2.333 3) ± 43.036
×
√
1
3 +
1
52.667(x −2.333 3)2
– I+
0.02 = 6 −0.056 962(x −2.333 3) ± 43.036
×
√
4
3 +
1
52.667(x −2.333 3)2.
(f) – 𝜏∼𝛾(8, 305.331)
– y(x) ∼t(
39.625+0.847 613(x−37.625), 6.177 9 ×
√1
8 +
1
4363.88 (x−37.625)2, 16
)
– Y+(x) ∼t(
39.625+0.847 613(x−37.625), 6.177 9 ×
√9
8 +
1
4363.88 (x−37.625)2, 16
)
– I0.2 = 39.625 + 0.847 61(x −301∕8) ± 8.258 4
×
√
1
8 +
1
4363.9(x −37.625)2
– I+
0.2 = 39.625 + 0.847 61(x −37.625) ± 8.258 4
×
√
9
8 +
1
4363.9(x −37.625)2.
(g) – 𝜏∼𝛾(6, 147.677)
– y(x) ∼t(
26.562 5+0.903 14(x−28.225), 4.961 14 ×
√1
8 +
1
1910.46 (x−28.225)2, 12
)
– Y+(x) ∼t(
26.562 5+0.903 14(x−28.225), 4.961 14 ×
√9
8 +
1
1910.46 (x−28.225)2, 12
)
– I0.02 = 26.563 + 0.903 14(x −28.225) ± 13.301
×
√
1
8 +
1
1910.46(x −28.225)2
– I+
0.02 = 26.563 + 0.903 14(x −28.225) ± 13.301
×
√
9
8 +
1
1910.46(x −28.225)2
(h) – 𝜏∼𝛾(2.5, 57.074 9)
– y(x) ∼t(
10.957 1+0.092 891 5(x−205.171), 4.778 07 ×
√1
7 +
1
124 54.4 (x−205.171)2, 5
)
– Y+(x) ∼t(
10.957 1+0.092 891 5(x−205.171), 4.778 07 ×
√8
7 +
1
12 454.4 (x−205.171)2, 5
)
– I0.05 = 10.957 + 0.092 892(x −205.171) ± 12.282
×
√
1
7 +
1
12 454(x −205.17)2
– I+
0.1 = 10.957 + 0.092 892(x −205.171) ± 9.628 1
×
√
8
7 +
1
12 454(x −205.17)2.
2
Volume training 2:
(a) – 𝜏∼𝛾(9, 302.561)
– y(x) ∼t(
11.2+0.503 382(x−84.05), 5.798 1 ×
√1
20 +
1
1278.95 (x−84.05)2, 18
)
– Y+(x) ∼t(
11.2+0.503 382(x−84.05), 5.798 1 ×
√21
20 +
1
1 278.95 (x−84.05)2, 18
)
.

B.17 Linear Regression

(b) – 𝜏∼𝛾(50 002, 450 019)
– y(x) ∼t(
−36.666 7+−3.913 65(x−11.5), 3 ×
√1
6 +
1
787.5 (x−11.5)2, 100 004
)
≈𝜙(
−36.666 7−3.913 65(x−11.5), 3 ×
√1
6 +
1
787.5 (x−11.5)2
)
– Y+(x) ∼t(
−36.666 7−3.913 65(x−11.5), 3 ×
√7
6 +
1
787.5 (x−11.5)2, 100 004
)
≈𝜙(
−36.666 7−3.913 65(x−11.5), 3 ×
√7
6 +
1
787.5 (x−11.5)2
)
.
(c) – 𝜏∼𝛾(502, 2004.75)
– y(x) ∼t(
62.666 7+0.998 67(x−57.1667), 1.998 38 ×
√1
6 +
1
5 640.83 (x−57.1667)2, 1004
)
≈𝜙(
62.666 7+0.998 67(x−57.1667), 2 ×
√1
6 +
1
5 640.83 (x−57.1667)2
)
– Y+(x) ∼t(
62.666 7+0.998 67(x−57.166 7), 1.998 38 ×
√7
6 +
1
5 640.83 (x−57.166 7)2, 1004
)
≈𝜙(
62.666 7+0.998 67(x−57.166 7), 2 ×
√7
6 +
1
5 640.83 (x−57.166 7)2
)
.
3
Volume training 3:
(a) – I0.08 = 11 −1.047 25(x −9.9) ± 6.717 26 ×
√
1
20 +
1
469.8(x −9.9)2
– I+
0.01 = 11 −1.047 25(x −9.9) ± 10.260 7 ×
√
21
20 +
1
469.8(x −9.9)2
(b) – I0.07 = 20.6 + 0.529 68(x −21.4)±2.861 36×
√
1
5 +
1
175.2(x −21.4)2
– I+
0.07 = 20.6 + 0.529 68(x −21.4)±2.861 36×
√
6
5 +
1
175.2(x −21.4)2.
(c) – I0.07 = 20.6 + 0.529 68(x −21.4) ± 13.349 ×
√
1
5 +
1
175.2(x −21.4)2
– I+
0.07 = 20.6 + 0.529 68(x −21.4) ± 13.349 ×
√
6
5 +
1
175.2(x −21.4)2.
4
– Regression line: y = 1 263.2 + 21.89(x −1 995)
– I0.1 = 1 263.2 + 21.89(x −1995) ± 293.629 ×
√
1
5 +
1
1 000(x −1 995)2
– I+
0.1 = 1 263.2 + 21.89(x −1 995) ± 293.629 ×
√
6
5 +
1
1 000(x −1 995)2.
5
(a) y = 114.4 + 7.9(x −2)
(b) b ∼𝜙(7.9, 1.264 91)(x).
(c) a∗= y(̄x) ∼𝜙(114.4, 1.788 85)(x).
(d) Y+ ∼𝜙(256.6, 23.186).
(e) I = (218.5, 294.7).
(f) This question is open to many correct answers, and the key is that you
have reflected upon the question and have reasons for your answer.
Concerning why it is a bad model, you may for instance demonstrate
that this model becomes absurd if the number of pumpings, x, is set


B Solutions to Exercises
very high, as the ball will then be predicted to rebound higher than the
height it was dropped from. As for its being a good model, you may
show how it actually fits very well within a narrower range of x values.
6
(a) y = −18.2 −23.282 9(z −6.508 81).
(b) b ∼t(−23.282 9, 1.737 84, 3).
(c) H1
is
that
b > −25.
Then,
P(H0) = T(−23.282 9, 1.737 84, 3)(−25) =
0.197 983, which is greater than the significance 𝛼, so we don’t reject
H0, and will therefore not claim that this singer’s spectral slope is
higher than −25.
7
The
linear
regression
line
is
y = 78 000 + 6 761.62(x −14.75) =
−21 733.9 + 6 761.62x, which has a positive slope, 6 761.62. The pos-
terior probability distribution of the slope is b ∼t(6 761.62, 4 380.15, 2). The
alternative hypothesis H1 is that b > 0. We test the hypothesis:
P(H0) = P(b ≤0) = T(6 761.62, 4 380.15, 2) = 0.131 323 < 𝛼.
With significance 𝛼= 0.2, you may conclude that the salary increases with
the number of goals scored.
8
The
regression
line
is
y(x) = 2184.67 + 23.443 7(x −103.333) =
+23.443 7x −237.838. We indicate the uncertainty through the posterior
distribution: y(x) ∼t(
2 184.67+23.443 7(x−103.333), 123.2 ×
√1
9 +
1
24 528 (x−103.333)2, 7
).
For a temperature of 100◦C, we have y(100) ∼t(2 106.5, 41.2, 7), so I0.1 =
(2 028.5, 2 184.5). The predictive distribution is Y+(100) ∼t(2 106.5, 129.9, 7),
so I+
0.1(100) = 2 106.5 ± 246.1 = (1 860.4, 2 352.6). The explanation of the
difference is that, for the measurement, we must add the uncertainty of the
measurement itself to the uncertainty in our knowledge of the solubility.


C
Tables
CONTENTS
C.1
zp (Left Tail), 490
C.2
Percentiles for t Distribution with 𝜈Degrees of Freedom, 491
C.3
Percentiles for 𝜒2 Distribution with 𝜈Degrees of Freedom, 492
C.4
The Γ Function, 493
C.5
Φ(x) = ∫x
0 𝜙(0,1)(t) dt, x ≤0, 494
C.6
Φ(x) = ∫x
0 𝜙(0,1)(t) dt, x ≥0, 495
The following tables were generated by Mathematica. Use Mathematica or
some similar tool directly if you need more accurate values. The commands
used are
r zp is InverseCDF[NormalDistribution[0,1], p]
r t𝜈,p is InverseCDF[StudentTDistribution[0,1,𝜈], p]
r 𝜒2
𝜈(x) is InverseCDF[ChiSquareDistribution[𝜈, x]]
r Γ(x) is Gamma[x]
r Φ(x) is CDF[NormalDistribution[0,1], x].
These commands also work in Wolfram Alpha (http://alpha.wolfram.com). See
also the sections for the different probability distributions to find the com-
mands for TI, Casio, and HP calculators. If you are interested in more powerful
statistics tools, it might be worth your time to learn the free and freely available
statistics tool R. See http://bayesians.net for more information. Even though
modern tools have made tables obsolete, such tools are sometimes unavailable.
For this reason, extended or other tables will be added at http://bayesians.net
upon request.
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


C Tables
C.
zp (Left Tail)
−2
−1
1
2
0.01
0.025
0.05
0.1
0.2
0.5
0.8
0.9
0.95
0.975
0.99
-2.326
-0.842
0.000
2.326
-1.960
1.960
-1.645
1.645
-1.282
1.282
0.842
−0.842
0.2
p
zp
0.00000
−∞
0.0001
−3.719
0.00025 −3.481
0.0005
−3.290
0.001
−3.090
0.0025
−2.807
0.005
−2.576
0.01
−2.326
0.015
−2.170
0.02
−2.054
0.025
−1.960
0.03
−1.881
0.035
−1.812
0.04
−1.751
0.045
−1.695
0.05
−1.645
0.06
−1.555
p
zp
0.07 −1.476
0.08 −1.405
0.09 −1.341
0.10 −1.282
0.15 −1.036
0.20 −0.842
0.30 −0.524
0.40 −0.253
0.50
0
0.60
0.253
0.70
0.524
0.80
0.842
0.85
1.036
0.90
1.282
0.91
1.341
0.92
1.405
0.93
1.476
p
zp
0.94
1.555
0.95
1.645
0.955
1.695
0.96
1.751
0.965
1.812
0.97
1.881
0.975
1.960
0.98
2.054
0.985
2.170
0.99
2.326
0.995
2.576
0.9975
2.807
0.999
3.090
0.9995
3.290
0.99975 3.481
0.9999
3.719
1.00000
∞

C.2 Percentiles for t Distribution with 𝜈Degrees of Freedom

Values for the right tail have the opposite sign, since z is antisymmetric around
p = 0.5:
z1−p = −zp.
C.
Percentiles for t Distribution with 𝝂Degrees
of Freedom
The table shows t𝜈,p for the left tail. Values for the right tail have the opposite
sign, since t is anti-symmetric around p = 0.5:
t𝜈,1−p = −t𝜈,p.
HHHHH
𝜈
p
0.01
0.025
0.05
0.1
0.9
0.95
0.975
0.99
1
−31.82
−12.71
−6.314
−3.078
3.078
6.314
12.71
31.82
2
−6.965
−4.303
−2.920
−1.886
1.886
2.920
4.303
6.965
3
−4.541
−3.182
−2.353
−1.638
1.638
2.353
3.182
4.541
4
−3.747
−2.776
−2.132
−1.533
1.533
2.132
2.776
3.747
5
−3.365
−2.571
−2.015
−1.476
1.476
2.015
2.571
3.365
6
−3.143
−2.447
−1.943
−1.440
1.440
1.943
2.447
3.143
7
−2.998
−2.365
−1.895
−1.415
1.415
1.895
2.365
2.998
8
−2.896
−2.306
−1.860
−1.397
1.397
1.860
2.306
2.896
9
−2.821
−2.262
−1.833
−1.383
1.383
1.833
2.262
2.821
10
−2.764
−2.228
−1.812
−1.372
1.372
1.812
2.228
2.764
11
−2.718
−2.201
−1.796
−1.363
1.363
1.796
2.201
2.718
12
−2.681
−2.179
−1.782
−1.356
1.356
1.782
2.179
2.681
13
−2.650
−2.160
−1.771
−1.350
1.350
1.771
2.160
2.650
14
−2.624
−2.145
−1.761
−1.345
1.345
1.761
2.145
2.624
15
−2.602
−2.131
−1.753
−1.341
1.341
1.753
2.131
2.602
16
−2.583
−2.120
−1.746
−1.337
1.337
1.746
2.120
2.583
17
−2.567
−2.110
−1.740
−1.333
1.333
1.740
2.110
2.567
18
−2.552
−2.101
−1.734
−1.330
1.330
1.734
2.101
2.552
19
−2.539
−2.093
−1.729
−1.328
1.328
1.729
2.093
2.539
20
−2.528
−2.086
−1.725
−1.325
1.325
1.725
2.086
2.528
21
−2.518
−2.080
−1.721
−1.323
1.323
1.721
2.080
2.518
22
−2.508
−2.074
−1.717
−1.321
1.321
1.717
2.074
2.508
23
−2.500
−2.069
−1.714
−1.319
1.319
1.714
2.069
2.500
24
−2.492
−2.064
−1.711
−1.318
1.318
1.711
2.064
2.492
25
−2.485
−2.060
−1.708
−1.316
1.316
1.708
2.060
2.485
26
−2.479
−2.056
−1.706
−1.315
1.315
1.706
2.056
2.479
27
−2.473
−2.052
−1.703
−1.314
1.314
1.703
2.052
2.473
28
−2.467
−2.048
−1.701
−1.313
1.313
1.701
2.048
2.467
29
−2.462
−2.045
−1.699
−1.311
1.311
1.699
2.045
2.462
30
−2.457
−2.042
−1.697
−1.310
1.310
1.697
2.042
2.457
In Mathematica®, t𝜈,p is InverseCDF[StudentTDistribution[ 0, 1, 𝜈], p ].


C Tables
C.
Percentiles for 𝝌Distribution with 𝝂Degrees
of Freedom
The table shows 𝜒2
p for the left tail. You find the right tail for p as 𝜒2
1−p. Note
that there are no symmetries to make use of in the case of 𝜒2.
χ    (right tail)
0.9
2
χ    (left tail)
0.1
2
χ    (right tail)
0.1
2
χ    (left tail)
0.9
2
HHHHH
𝜈
p
0.01
0.025
0.05
0.1
0.9
0.95
0.975
0.99
1
0.000
0.001
0.004
0.016
2.706
3.841
5.024
6.635
2
0.020
0.051
0.103
0.211
4.605
5.991
7.378
9.210
3
0.115
0.216
0.352
0.584
6.251
7.815
9.348
11.345
4
0.297
0.484
0.711
1.064
7.779
9.488
11.143
13.277
5
0.554
0.831
1.145
1.610
9.236
11.07
12.833
15.086
6
0.872
1.237
1.635
2.204
10.645
12.592
14.449
16.812
7
1.239
1.690
2.167
2.833
12.017
14.067
16.013
18.475
8
1.646
2.180
2.733
3.490
13.362
15.507
17.535
20.090
9
2.088
2.700
3.325
4.168
14.684
16.919
19.023
21.666
10
2.558
3.247
3.940
4.865
15.987
18.307
20.483
23.209
11
3.053
3.816
4.575
5.578
17.275
19.675
21.920
24.725
12
3.571
4.404
5.226
6.304
18.549
21.026
23.337
26.217
13
4.107
5.009
5.892
7.042
19.812
22.362
24.736
27.688
14
4.660
5.629
6.571
7.790
21.064
23.685
26.119
29.141
15
5.229
6.262
7.261
8.547
22.307
24.996
27.488
30.578
16
5.812
6.908
7.962
9.312
23.542
26.296
28.845
32.000
17
6.408
7.564
8.672
10.085
24.769
27.587
30.191
33.409
18
7.015
8.231
9.390
10.865
25.989
28.869
31.526
34.805
19
7.633
8.907
10.117
11.651
27.204
30.144
32.852
36.191
20
8.260
9.591
10.851
12.443
28.412
31.410
34.170
37.566
21
8.897
10.283
11.591
13.240
29.615
32.671
35.479
38.932
22
9.542
10.982
12.338
14.041
30.813
33.924
36.781
40.289
23
10.196
11.689
13.091
14.848
32.007
35.172
38.076
41.638
24
10.856
12.401
13.848
15.659
33.196
36.415
39.364
42.980
25
11.524
13.120
14.611
16.473
34.382
37.652
40.646
44.314
26
12.198
13.844
15.379
17.292
35.563
38.885
41.923
45.642
27
12.879
14.573
16.151
18.114
36.741
40.113
43.195
46.963
28
13.565
15.308
16.928
18.939
37.916
41.337
44.461
48.278
29
14.256
16.047
17.708
19.768
39.087
42.557
45.722
49.588
30
14.953
16.791
18.493
20.599
40.256
43.773
46.979
50.892

C.
The 𝚪Function
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
1 9.513 51
4.590 84
2.991 57
2.218 16
1.772 45
1.489 19
1.298 06
1.164 23
1.068 63
1
1 0.951 351 0.918 169 0.897 471 0.887 264 0.886 227 0.893 515 0.908 639 0.931 384 0.961 766
2
1 1.046 49
1.101 8
1.166 71
1.242 17
1.329 34
1.429 62
1.544 69
1.676 49
1.827 36
3
2 2.197 62
2.423 97
2.683 44
2.981 21
3.323 35
3.717 02
4.170 65
4.694 17
5.299 33
4
6 6.812 62
7.756 69
8.855 34
10.136 1
11.6317
13.381 3
15.431 4
17.837 9
20.667 4
5
24 27.931 8
32.578 1
38.078
44.598 8
52.342 8
61.553 9
72.527 6
85.621 7
101.27
6
120 142.452
169.406
201.813
240.834
287.885
344.702
413.408
496.606
597.494
7
720 868.957
1 050.32
1 271.42
1 541.34
1 871.25
2 275.03
2 769.83
3 376.92
4 122.71
8
5 040 6 169.59
7 562.29
9 281.39
11 405.9
14 034.4
17 290.2
21 327.7
26 340.
32 569.4
9 40 320 49 973.7
62 010.8
77 035.6
95 809.5
119 292
148 696
185 551
231 792
289 868
0
1
2
3
4
5
6
7
8
9
10 3.63 × 105
3.63 × 106
3.99 × 107
4.79 × 108
6.23 × 109
8.72 × 1010
1.31 × 1012
2.09 × 1013
3.56 × 1014
6.40 × 1015
20 1.22 × 1017
2.43 × 1018
5.11 × 1019
1.12 × 1021
2.59 × 1022
6.2 × 1023
1.55 × 1025
4.03 × 1026
1.09 × 1028
3.05 × 1029
30 8.84 × 1030
2.65 × 1032
8.22 × 1033
2.63 × 1035
8.68 × 1036
2.95 × 1038
1.03 × 1040
3.72 × 1041
1.38 × 1043
5.23 × 1044
40 2.04 × 1046
8.16 × 1047
3.35 × 1049
1.41 × 1051
6.04 × 1052
2.66 × 1054
1.2 × 1056
5.5 × 1057
2.59 × 1059
1.24 × 1061
50 6.08 × 1062
3.04 × 1064
1.55 × 1066
8.07 × 1067
4.27 × 1069
2.31 × 1071
1.27 × 1073
7.11 × 1074
4.05 × 1076
2.35 × 1078
60 1.39 × 1080
8.32 × 1081
5.08 × 1083
3.15 × 1085
1.98 × 1087
1.27 × 1089
8.25 × 1090
5.44 × 1092
3.65 × 1094
2.48 × 1096
70 1.71 × 1098
1.2 × 10100
8.5 × 10101
6.1 × 10103
4.5 × 10105
3.3 × 10107
2.5 × 10109
1.9 × 10111
1.5 × 10113
1.1 × 10115
80 8.9 × 10116
7.2 × 10118
5.8 × 10120
4.8 × 10122
3.9 × 10124
3.3 × 10126
2.8 × 10128
2.4 × 10130
2.1 × 10132
1.9 × 10134
90 1.7 × 10136
1.5 × 10138
1.4 × 10140
1.2 × 10142
1.2 × 10144
1.1 × 10146
1. × 10148
9.9 × 10149
9.6 × 10151
9.4 × 10153
100 9.3 × 10155
9.3 × 10157
9.4 × 10159
9.6 × 10161
9.9 × 10163
1. × 10166
1.1 × 10168
1.1 × 10170
1.2 × 10172
1.3 × 10174
110 1.4 × 10176
1.6 × 10178
1.8 × 10180
2. × 10182
2.2 × 10184
2.5 × 10186
2.9 × 10188
3.4 × 10190
4. × 10192
4.7 × 10194
120 5.6 × 10196
6.7 × 10198
8.1 × 10200
9.9 × 10202
1.2 × 10205
1.5 × 10207
1.9 × 10209
2.4 × 10211
3. × 10213
3.9 × 10215
130 5. × 10217
6.5 × 10219
8.5 × 10221
1.1 × 10224
1.5 × 10226
2. × 10228
2.7 × 10230
3.7 × 10232
5. × 10234
6.9 × 10236
140 9.6 × 10238
1.3 × 10241
1.9 × 10243
2.7 × 10245
3.9 × 10247
5.6 × 10249
8. × 10251
1.2 × 10254
1.7 × 10256
2.6 × 10258
For n ≥10, Stirling’s approximation to Γ yields a value less than 1% off from the true value: Γ(x) ≈
√
2𝜋
x
(x
e
)x
.
For positive integers n, you may use that Γ is a generalization of faculty to get an exact answer: Γ(n) = (n −1)!


C Tables
C.
𝚽(x) = ∫x
𝝓(,)(t) dt, x ≤
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
−0.0 0.500 0.496 0.492 0.488 0.484 0.480 0.476 0.472 0.468 0.464
−0.1 0.460 0.456 0.452 0.448 0.444 0.440 0.436 0.433 0.429 0.425
−0.2 0.421 0.417 0.413 0.409 0.405 0.401 0.397 0.394 0.390 0.386
−0.3 0.382 0.378 0.374 0.371 0.367 0.363 0.359 0.356 0.352 0.348
−0.4 0.345 0.341 0.337 0.334 0.330 0.326 0.323 0.319 0.316 0.312
−0.5 0.309 0.305 0.302 0.298 0.295 0.291 0.288 0.284 0.281 0.278
−0.6 0.274 0.271 0.268 0.264 0.261 0.258 0.255 0.251 0.248 0.245
−0.7 0.242 0.239 0.236 0.233 0.230 0.227 0.224 0.221 0.218 0.215
−0.8 0.212 0.209 0.206 0.203 0.200 0.198 0.195 0.192 0.189 0.187
−0.9 0.184 0.181 0.179 0.176 0.174 0.171 0.169 0.166 0.164 0.161
−1.0 0.159 0.156 0.154 0.152 0.149 0.147 0.145 0.142 0.140 0.138
−1.1 0.136 0.133 0.131 0.129 0.127 0.125 0.123 0.121 0.119 0.117
−1.2 0.115 0.113 0.111 0.109 0.107 0.106 0.104 0.102 0.100 0.099
−1.3 0.097 0.095 0.093 0.092 0.090 0.089 0.087 0.085 0.084 0.082
−1.4 0.081 0.079 0.078 0.076 0.075 0.074 0.072 0.071 0.069 0.068
−1.5 0.067 0.066 0.064 0.063 0.062 0.061 0.059 0.058 0.057 0.056
−1.6 0.055 0.054 0.053 0.052 0.051 0.049 0.048 0.047 0.046 0.046
−1.7 0.045 0.044 0.043 0.042 0.041 0.040 0.039 0.038 0.038 0.037
−1.8 0.036 0.035 0.034 0.034 0.033 0.032 0.031 0.031 0.030 0.029
−1.9 0.029 0.028 0.027 0.027 0.026 0.026 0.025 0.024 0.024 0.023
−2.0 0.023 0.022 0.022 0.021 0.021 0.020 0.020 0.019 0.019 0.018
−2.1 0.018 0.017 0.017 0.017 0.016 0.016 0.015 0.015 0.015 0.014
−2.2 0.014 0.014 0.013 0.013 0.013 0.012 0.012 0.012 0.011 0.011
−2.3 0.011 0.010 0.010 0.010 0.010 0.009 0.009 0.009 0.009 0.008
−2.4 0.008 0.008 0.008 0.008 0.007 0.007 0.007 0.007 0.007 0.006
−2.5 0.006 0.006 0.006 0.006 0.006 0.005 0.005 0.005 0.005 0.005
−2.6 0.005 0.005 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004
−2.7 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003
−2.8 0.003 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002
−2.9 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.001 0.001 0.001
−3.0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
−3.1 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
−3.2 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001
If x ≤−3.3, then Φ(x) = 0.000.

C.6 Φ(x) = ∫x
0 𝜙(0,1)(t) dt, x ≥0

C.
𝚽(x) = ∫x
𝝓(,)(t) dt, x ≥
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.0 0.500 0.504 0.508 0.512 0.516 0.520 0.524 0.528 0.532 0.536
0.1 0.540 0.544 0.548 0.552 0.556 0.560 0.564 0.567 0.571 0.575
0.2 0.579 0.583 0.587 0.591 0.595 0.599 0.603 0.606 0.610 0.614
0.3 0.618 0.622 0.626 0.629 0.633 0.637 0.641 0.644 0.648 0.652
0.4 0.655 0.659 0.663 0.666 0.670 0.674 0.677 0.681 0.684 0.688
0.5 0.691 0.695 0.698 0.702 0.705 0.709 0.712 0.716 0.719 0.722
0.6 0.726 0.729 0.732 0.736 0.739 0.742 0.745 0.749 0.752 0.755
0.7 0.758 0.761 0.764 0.767 0.770 0.773 0.776 0.779 0.782 0.785
0.8 0.788 0.791 0.794 0.797 0.800 0.802 0.805 0.808 0.811 0.813
0.9 0.816 0.819 0.821 0.824 0.826 0.829 0.831 0.834 0.836 0.839
1.0 0.841 0.844 0.846 0.848 0.851 0.853 0.855 0.858 0.860 0.862
1.1 0.864 0.867 0.869 0.871 0.873 0.875 0.877 0.879 0.881 0.883
1.2 0.885 0.887 0.889 0.891 0.893 0.894 0.896 0.898 0.900 0.901
1.3 0.903 0.905 0.907 0.908 0.910 0.911 0.913 0.915 0.916 0.918
1.4 0.919 0.921 0.922 0.924 0.925 0.926 0.928 0.929 0.931 0.932
1.5 0.933 0.934 0.936 0.937 0.938 0.939 0.941 0.942 0.943 0.944
1.6 0.945 0.946 0.947 0.948 0.949 0.951 0.952 0.953 0.954 0.954
1.7 0.955 0.956 0.957 0.958 0.959 0.960 0.961 0.962 0.962 0.963
1.8 0.964 0.965 0.966 0.966 0.967 0.968 0.969 0.969 0.970 0.971
1.9 0.971 0.972 0.973 0.973 0.974 0.974 0.975 0.976 0.976 0.977
2.0 0.977 0.978 0.978 0.979 0.979 0.980 0.980 0.981 0.981 0.982
2.1 0.982 0.983 0.983 0.983 0.984 0.984 0.985 0.985 0.985 0.986
2.2 0.986 0.986 0.987 0.987 0.987 0.988 0.988 0.988 0.989 0.989
2.3 0.989 0.990 0.990 0.990 0.990 0.991 0.991 0.991 0.991 0.992
2.4 0.992 0.992 0.992 0.992 0.993 0.993 0.993 0.993 0.993 0.994
2.5 0.994 0.994 0.994 0.994 0.994 0.995 0.995 0.995 0.995 0.995
2.6 0.995 0.995 0.996 0.996 0.996 0.996 0.996 0.996 0.996 0.996
2.7 0.997 0.997 0.997 0.997 0.997 0.997 0.997 0.997 0.997 0.997
2.8 0.997 0.998 0.998 0.998 0.998 0.998 0.998 0.998 0.998 0.998
2.9 0.998 0.998 0.998 0.998 0.998 0.998 0.998 0.999 0.999 0.999
3.0 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999
3.1 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999
3.2 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999
If x ≥3.3, then Φ(x) = 1.000.



Index
Dk, a k sided die
3
H0
336, 379
H1
336, 379
P ⊧
302
Γ, 𝛾
Γ(x) function
408, 494
𝛾distribution
225, 240
𝛾(x) function
409
g𝛾distribution
321, 411
Ω and stochastic variables
137
Ω, universal set
54
𝛼, linear regression
37
𝛼, parameter of 𝜒2
377, 494
𝛼, parameter of t
248, 493
𝛼, parameter of z
228, 492
𝛼, significance
336, 379
𝛽, linear regression
44
𝜒2
𝜈,𝛼, inverse cumulative 𝜒2
377,
494
∅, the empty set
54
𝜆, parameter
213, 241, 320, 339, 341,
359
𝜇, parameter
225, 226, 245
𝜈, parameter of 𝜒2
241, 377, 494
𝜈, parameter of t
225, 245, 248, 493
𝜌, correlation coefficient
33, 188
𝜎, parameter
225, 226, 245
𝜎XY, covariance
186
∼, has probability distribution
141,
148
p, 𝜋, Bernoulli parameters
202
p-value
381, 384, 386
t𝜈,𝛼, inverse cumulative t
248, 493
z𝛼, inverse cumulative 𝜙
228, 492
a
alternative hypothesis H1
336, 379
average, data, see mean
b
bar chart
10
Bayes’ formula
107
Bayes’ theorem
basic form
111
for functions
279
for Gaussian mean 𝜇
303, 310
for Gaussian precision 𝜏
307, 310
for Gaussian variance 𝜎2
307, 310
for Poisson rate 𝜆
320
for proportion p
314
Bernoulli process
201
𝛽distribution
250, 362
Bernoulli distribution
201
binomial distribution
202
comparison of parameter
343
confidence interval
378
credible interval
362
hypothesis test
338
hypothesis test (freq.)
381
inference for p
314
negative binomial distribution
210
parameter p or 𝜋
202
binomial coefficient
60
c
categorical data
11
centered form, linear regression
41
central limit theorem
233
Chebyshev’s inequality
192
The Bayesian Way: Introductory Statistics for Economists and Engineers, First Edition.
Svein Olav Nyberg.
© 2019 John Wiley & Sons, Inc. Published 2019 by John Wiley & Sons, Inc.


Index
combination
59, 94
combinatorics
56
conditional probability
83, 177, 182
confidence interval
375
and credible interval
375
Bernoulli process
378
Gaussian process
375
linear regression
395
variance
376
conservative hypothesis
336, 379
continuity correction
233
correlation
33, 188
covariance
33, 186
credible interval
352
Bernoulli process
363
Gaussian process
355, 358,
359
HPD interval
353, 360, 363
linear regression
392
Poisson process
359
sample size
355
d
degrees of freedom
246
Satterthwaite’s formula
247
diagram
141
dice, Dk
3
e
error types
379
estimate
interval
352
point
351
estimator
277
Euler diagram
55, 72
expected value
point estimate
352
expected value 𝜇X, E[X]
160
explanatory variable
37
f
frequentist
75
g
Gaussian process
299
comparison of parameters
340
comparison of precision 𝜏
341
confidence interval
375
credible interval
355, 357, 359
hypothesis test of 𝜇
338
hypothesis test of 𝜇(freq.)
384
hypothesis test of 𝜎
338
hypothesis test of 𝜎(freq.)
385
hypothesis test of X+
338
inference for mean 𝜇
303
inference for precision 𝜏
307, 310
inference for the mean 𝜇
310
inference for variance 𝜎2
307, 310
predictive interval
355, 357, 359
grouped data
22
h
histogram
23
HPD interval
353, 360, 363
hypothesis test
error types
379
null value
335
utility function
334
i
iff = “if and only if”
382
independence
88, 189
inference
269, 277
interquartile range
18
interval estimate
confidence interval
375
credible interval
352
HPD interval
353, 360, 363
linear regression
392, 395
one-sided
353
predictive interval
352
symmetric
353
two-sided
353
inverse cumulative distribution
155,
228, 248, 256
inverse cumulative probability
241
k
Kolmogorov’s axioms
72
l
Law of Large Numbers
193
likelihood
113, 280
linear regression
37, 389
confidence interval
395
credible interval
392

Index

interval estimate
392, 395
predictive interval
392, 395
probability distribution
391
Lord of the Rings
399
m
marginal probability
177, 181
Markov’s inequality
191
Mathematica
6, 198
matrix regression
39
mean
26
mean 𝜇
160, 225, 226
comparison
340
confidence interval for
375
credible interval for
355
hypothesis test
338
hypothesis test (freq.)
384
inference for
303, 310
median
15, 27, 155, 352
mode
15, 352
n
next observation
115, 288, 303
normal form
41
null hypothesis
336, 379
null value
335
o
observation
277
odds
199
ordered
59, 94
p
parameter
277
percentile
16, 27, 155
pie chart
13
point estimate
372
point probability
141
Poisson process
214, 241
comparison of rate 𝜆
341
credible interval
359
Erlang distribution
241
hypothesis test
339
inference for 𝜆
320
Poisson distribution
214
rare occurrences
214
waiting time
241
population
9, 269
posterior
113, 277, 280, 303, 308, 310,
316, 320
precision 𝜏
164
comparison
341
inference for
307, 310
predictive interval
352
linear regression
392, 395
predictive probability distribution
303,
308, 310, 316, 320, 391
prior
113, 277, 280, 302, 303, 307, 316
informative
316
neutral/reference
303, 307, 316, 320
probability
classical (objective Bayes)
76
conditional
83
Euler diagram
72
frequentist
75
Kolmogorov’s axioms
72
propensity
76
repeated sampling
94
subjective (subjective Bayes)
74
total
109
probability density
148
probability distribution
137
2-variable
177
𝛽distribution
225, 249
𝛽b distribution
411
𝛽nb distribution
411
𝛾distribution and family
225, 240
𝜒2 distribution
241
erl, Erlang distribution
241
exp, exponential distribution
241
𝜙(𝜇,Σ), binormal distribution
234
𝜙(𝜇,𝜎), Normal distribution
225, 226
z𝛼(inverse cumulative)
228
Normal approximation
232
standard Normal distribution
𝜙= 𝜙(0,1)
226
bern, Bernoulli distribution
199
bin, binomial distribution
202
f , Snedecor–Fisher distribution
410
g𝛾distribution
411
hyp, hypergeometric distribution
207
nb, negative binomial
distribution
210
rayl, Rayleigh distribution
258
t distribution
225, 245
pois, Poisson distribution
213


Index
probability distribution (Continued)
weib, Weibull distribution
225, 257
conditional
177, 182
continuous
147, 225
cumulative
144, 152
discrete
141, 197
Gaussian, see Normal distribution
inverse cumulative
155
linear regression
391
marginal
177, 181
median
155
mixed
171
multivariate
177
percentile
155
predictive
303, 308, 310, 316, 320,
391
simultaneous
177
product sum
36
propensity
76
q
quartile
18
r
radioactivity
215, 361
random walk
204
randomness
272
raw data
45
regression, see linear regression
regression line
37
relative frequency
11
repeat sampling
combination
59
ordered
59
replacement
59, 95
sequence
59
unordered
59
repeated sampling
ordered and unordered
94
sequence and combination
94
replacement
59, 95
residual
38, 42
s
sample
10
sample size
355, 356, 358, 362, 364
sample space
72, 141, 189
sampling, combinatorics
replacement
203
Satterthwaite’s formula
247
sequence
59, 94
set operations
complementary set Ac
54
intersection AB
53
product sets
56
set difference A∖B
53
the empty set ∅
54
tree diagram
57
union A ∪B
52
significance 𝛼
336, 379
simultaneous distribution
177
square sum
21
standard deviation
20, 21, 164
standard error
42
statistic
277
sufficient
277, 303
stochastic variable
137
conditional
177, 182
marginal
177, 181
Student’s t distribution
225, 245
t
table
10, 31, 141, 178
total probability
109
u
unbiased
371
unordered
59, 94
updating
111, 113, 114, 281, 283, 285,
291, 303, 307, 310, 316, 320
utility function
329, 355
hypothesis test
334
v
variance
20, 21, 26, 164
comparison
341
confidence interval
376
hypothesis test
338
hypothesis test (freq.)
385
inference for
307, 310
w
web support
6, 199
Wolfram Alpha
6, 198

WILEY END USER LICENSE
AGREEMENT
Go to www.wiley.com/go/eula to access Wiley’s ebook
EULA.

