343
Philos Phenomenol Res. 2022;104:343–363. 
wileyonlinelibrary.com/journal/phpr
DOI: 10.1111/phpr.12768  
O R I G I N A L  A R T I C L E
Perception and Probability
Alex Byrne
Department of Linguistics and Philosophy, MIT
Correspondence: Alex Byrne, Department of Linguistics and Philosophy, MIT.
Email: abyrne@mit.edu
1 | 
INTRODUCTION
One very popular framework in contemporary epistemology is Bayesian. The central epistemic 
state is subjective confidence, or credence. Traditional epistemic states like belief and knowledge 
tend to be sidelined, or even dispensed with entirely. (In an attempt to sugar the pill, credences 
are often called degrees of belief.) Instead of believing or knowing that Jones will get the job, the 
target phenomenon is having a certain credence that Jones will get the job. Given this framework, 
the overarching question is: what credences are the “rational” ones to have?
Credences are often introduced as familiar mental states, merely in need of a special label for 
the purposes of epistemology. But whether they are implicitly recognized by the folk or posits of 
a sophisticated scientific psychology, they do not appear to fit well with perception, as is often 
noted:
A central tenet of the Bayesian program is the representation of beliefs by distri-
butions, which assign probability to each of a set of hypotheses. The prominent 
theoretical status accorded to such ambiguity seems rather puzzlingly at odds with 
the all- or- nothing nature of our everyday perceptual lives. For instance, subjects ob-
serving ambiguous or rivalrous visual displays famously report experiencing either 
percept alternately and exclusively; for even the most fervent Bayesian, it seems 
impossible simultaneously to interpret the Necker cube as potentially facing either 
direction. (Daw and Courville 2007: 1528)
This paper investigates the tension between probabilistic cognition and non- probabilistic perception. 
The tension is real, and the solution— to adapt a phrase from Quine and Goodman— is to renounce cre-
dences altogether.
© 2021 Philosophy and Phenomenological Research, Inc

BYRNE
344
 
2 | 
BELIEF AND CREDENCE
Start with belief— also known as full belief or outright belief.1 For the purposes of this paper, we 
can adopt the simple view that believing p is a relational state of people and other animals: to 
believe p is to stand in the believing relation to the proposition p (cf. Stalnaker 1988: 150, 1999).
When one believes p one treats p as settled, and so is inclined to rely on p as a premise or assump-
tion. One’s inclination might be more or less strong (as a glass might be more or less fragile), which 
seems to correspond to the strength of belief: one believes p more strongly, the greater one’s inclina-
tion to rely on p in reasoning (Williamson 2000: 99).
Beliefs may be more or less strong or firm, but it would be a mistake to conclude from this that beliefs 
come in degrees, as Moon points out (2017: 767- 68). (Mattresses may be more or less firm, but they do not 
come in degrees.)2 More importantly, to believe p more or less strongly is to believe it. If I know that a coin 
biased .6 in favor of heads is about to be tossed, I do not believe that it will land heads; a fortiori I do not 
believe that it will land heads “less strongly” than I believe that it will land either heads or tails.3
In the case of the coin, I neither believe that it will land heads or that it will not land heads. I do 
believe that the probability of the coin landing heads is .6, but (on the face of it) this is nothing spe-
cial— it is just a belief like any other. I may hold it more or less strongly, and for good or bad reasons. 
If in fact the coin is fair then my belief is false. Admittedly, it is not entirely clear what the relevant 
notion of probability is, but it is usually easy enough to apply in practice.
According to many philosophers, I may also have a certain credence in the proposition that the coin will 
land heads, intuitively thought of as the “amount of confidence” or “level of confidence” that I place in that 
proposition.4 The amount of confidence (Cr) is usually scaled from 0 to 1 and— at least in the ideally ratio-
nal agent— is taken to obey the Kolmogorov axioms of probability. Thus Cr(p) = 1 when p is a logical 
truth, and Cr(p v q) = Cr(p) + Cr(q) when p and q are incompatible. So in addition to my belief that the 
probability of the coin landing heads is .6, I may have credence (or “subjective probability”) .6 in the prop-
osition that the coin will land heads. If Oberon has credence .6 in p and Titania has .5 credence in p, they 
bear different attitudes— different determinates of the same determinable— to the same proposition.5,6
 1For the reasons given in Hawthorne et al. 2016, ‘belief’ may have another weaker interpretation in certain context. The 
stronger “fully believe” interpretation is in force here (see Williamson forthcoming).
 2Thus the terminology of ‘degrees of belief’ (an early occurrence of which is in Ramsey 1926) is not especially apt for belief; 
for credence, it is not apt at all.
 3‘Strongly/firmly believe’ is unexceptionable, unlike ‘weakly believe’. Thomas Jefferson wrote to Samuel Kercheval Monticello 
that we should not “weakly believe that one generation is not as capable as another of taking care of itself, and of ordering its 
own affairs”; Holton (2014: n. 13, 34- 5) notes that Jefferson’s ‘weakly believe’ is vanishingly rare. ‘Partly believe’ is more 
familiar. (It appears in the King James Bible: “For first of all, when ye come together in the church, I hear that there be divisions 
among you; and I partly believe it”, 1 Corinthians 11:18.) But ‘partly’ does not seem to indicate the strength of belief: the most 
straightforward interpretation of ‘I partly believe the reports’ is ‘I believe (only) some parts of the reports’.
 4E.g. Joyce 2010: 431.
 5Thus on the view that replaces probabilistically graded doxastic attitudes with beliefs in propositions about probability, there are 
no credences (here following Hájek and Lin 2017: 210 and Staffel 2013: 3537, not Dogramaci 2018: 10 or Leitgeb 2017: 20).
 6This understanding of credence (and, indeed, the very first paragraph of this section) departs from the ambitious have- your- 
cake- and- eat- it account of credence and knowledge in Moss 2018. Moss argues that the contents of belief are not 
propositions, but rather “probabilistic contents”, namely “sets of probability spaces” (4), which assign probabilities to 
possibilities. An ordinary full belief in p has a “nominally probabilistic content”, which only assigns probability to 
possibilities in which p is true; for her credences are beliefs with “thoroughly probabilistic contents” (14), where the 
probability spaces are of the more usual kind. Thus, according to Moss, if Oberon has .6 credence in p, the content of his 
belief is a set of probability spaces all of which assign .6 to p. (Hence if Oberon fully believes p then his credence in p is 1, 
although Moss rejects the converse.) She also expresses much sympathy with the view that perception has probabilistic 
content (89- 99). Moss’s account is highly relevant to the topic of this paper, but is unexamined here for reasons of space.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
345
 
It is generally agreed that our credences fall short of the ideal, perhaps by some considerable mar-
gin. Although some of our credences are precise (e.g. those pertaining to coin flips), some of our 
credences may be “imprecise”, as well as not defined on numerous propositions.7 And they are some-
times probabilistically inconsistent when defined— to take a famous example, a person’s credence that 
Linda is a bank teller might be lower than his credence that she is a feminist bank teller (Tversky and 
Kahneman 1983). But the enterprise of studying the constraints governing the credences of an ideally 
rational agent would hardly be central to epistemology— and perhaps not even intelligible— unless 
imperfect agents like ourselves had credences too (cf. Holton 2014: 15).8
Although belief and credence appear to be quite different, appearances can be misleading: 
knowledge- how and knowledge- that appear different, but arguably the former is a species of the latter 
(Stanley and Williamson 2001). Could belief be a species of credence? Equating believing p with 
having credence 1 in p sets the bar for belief too high, since credence 1 is supposed to correspond to 
maximal certainty, admitting of no further gradations.9 But equating believing p with having credence 
> x (the “Lockean view”) is also problematic, because— it is generally agreed— rational belief ag-
glomerates: if one rationally believes p and believes q one may rationally believe p&q. But rational 
credence > x does not: if one has rational credence > x in p and rational credence > x in q, the rational 
credence to have in p&q might be < x. (See, e.g., Holton 2008: 34; Sturgeon 2008.) A reduction in the 
other direction, of credence to belief, seems hopeless from the start: as was pointed out, to have cre-
dence .6 in p is not to believe anything. Here we will make the widely (although not universally) ac-
cepted assumption that appearances are not misleading: beliefs do not tag along for free once credences 
are in place.10
Granted that neither credence nor belief can be reduced to the other, there is an immediate prob-
lem, which Weisberg (2020: 2) calls the dualist dilemma. Credences are supposed to be information- 
encoding action- guiding states: Titania opened the fridge because she had high credence that it 
contained beer. But belief and knowledge are supposed to be information- encoding action- guiding 
states too: Titania opened the fridge because she believed (or knew) it contained beer. Since neither 
explanation requires the other, we appear to have pointless redundancy. Perhaps worse, we might have 
conflicting norms. Suppose that opening the fridge would maximize Titania’s expected utility, but she 
doesn’t know that it contains beer. According to the recommendations of decision theory, she should 
open the fridge; according to the maxim ‘Act only on what you know’ (Hawthorne and Stanley 2008), 
she shouldn’t.11
Despite this tension, many theorists (Weisberg included) are dualists: we have both credences and 
beliefs. Weisberg himself tries to resolve the dilemma by arguing (in part) that although we “simulta-
neously have full and partial beliefs [i.e. credences] about one and the same propositions disposition-
ally…only one of these dispositional states will be active at any given moment” (2020: 21- 2).
 7See, e.g., White 2010, Schoenfield 2012.
 8See also Hájek and Lin 2017.
 9It also appears to set the bar too low, since having credence 1 that a ticket in an infinite lottery will lose is not to be wrong if 
it wins (see Williamson forthcoming; cf. Moss 2018: 56). For defenses of belief = credence 1 see Clarke 2013 and Greco 
2015; Wedgwood 2012 argues for a more complicated kind of reduction.
 10See also Sturgeon 2008, Sturgeon 2015, Dietrich and List 2021.
 11Weisberg’s version of the “dilemma”, unlike the one in the text, makes the terminology appropriate: either beliefs and 
credences “dictate the same inferences, actions, and assertions…or they do not” (2020: 2). He also notes the parsimony 
problem: “How are full and partial beliefs stored and maintained without duplicating cognitive burdens like storage and 
maintenance?” (3). (For related discussion see Staffel 2013, Buchak 2014, Hájek and Lin 2017, Jackson 2019.)
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
346
 
Historically, credence monism was more favored by Bayesians. We have credences, and either 
don’t have beliefs or else the folk notion of belief is too confused to bear much theoretical weight. As 
Jeffrey puts in in an often- quoted remark: “our ordinary notion of belief is only vestigially present in 
the notion of degree of belief. I am inclined to think Ramsey sucked the marrow out of the ordinary 
notion and used it to nourish a more adequate view.’ (1970: 171– 172).12 Since there is little motivation 
to sweep away belief while sparing knowledge (and obviously impossible if knowledge entails belief), 
credence monism is extremely revisionary. Learning has to go too, since that involves the acquisition 
of knowledge, although in practice Bayesians like Jeffrey treat it as unproblematic.
That leaves belief monism, the thesis of this paper: “there are no such things as credences” (Holton 
2014: 20). Belief monism is not widely defended, although it has some prominent adherents.13
Two final assumptions. First, credences are not reducible to dispositions to bet, or any other uncon-
troversial items.14 Second, we know and believe various things. The contest is between dualism and 
belief monism.15
3 | 
PERCEPTION AS A PROPOSITIONAL ATTITUDE
So far we have discussed two familiar propositional attitudes: belief and credence. They are at least 
somewhat similar, which is why reductive programs are worth pursuing. We now need to introduce a 
third belief- like propositional attitude.
Philosophers of perception frequently invoke tomatoes and J. L. Austin’s piece of soap that looks 
just like a lemon, so imagine seeing a tomato and soap bar on a tabletop, in good light. (The soap 
is a white bar of Ivory, not a lemon lookalike.) You are not just visually presented with this (the red 
tomato) and that (the white soap), but with the fact that this is red and ovoid and that that is white and 
cuboid, and that this is to the left of that. In a situation of this kind, in which you have no reason to 
think anything amiss, you will believe (and, moreover, know) that a red ovoid is next to a white cuboid. 
And if you are familiar with basic household items, you will believe (and know) this red tomato is next 
to that white bar of soap. Here is McDowell making essentially the same point:
In a particular experience in which one is not misled, what one takes in is that things are 
thus and so. That things are thus and so is the content of the experience, and it can also 
be the content of a judgement: it becomes the content of a judgement if the subject de-
cides to take the experience at face value. (McDowell 1994: 26)16
Vision is in the business of delivering information (“that things are thus and so”) about the perceiver’s 
environment, information that specialized subsystems glean from the environment’s interaction with light. 
Treated with appropriate caution, Thomas Reid’s metaphor is useful here: information (or misinformation) 
 12See also Jeffrey 1992: 1- 2, Maher 1993: 130. A nice summary of Jeffrey’s view is in Leitgeb 2017: 19.
 13For varying degrees of sympathy, see Harman 1986, Easwaran 2016, Horgan 2017, Dogramaci 2018, Mandelbaum 2018 
and Williamson forthcoming.
 14The classic reduction to betting prices is in de Finetti 2017: 64. For some convincing arguments in favor of non- reducibility, 
see Eriksson and Hájek 2007.
 15Disparaging belief and knowledge as outdated relics of folk psychology would be more convincing if scientists didn’t 
traffic heavily in them (for helpful discussion see Nagel 2013).
 16McDowell later amended his view, but not in ways relevant to this paper (McDowell 2008).
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
347
 
delivered by perception is the testimony of the senses. Vision is testifying that this is red and ovoid and that 
that is white and cuboid— and of course it is testifying to much else besides. Put in contemporary jargon, 
the testimony of the senses is the “content of perception”.
It is a short step from this to the introduction of a third propositional attitude, exing. (‘Exing’ is 
meant to suggest ‘experiencing’, although it should not be taken to be equivalent to any ordinary 
English expression.) When one “takes in that things are thus and so”, one exes that things are thus and 
so. If one’s senses testify to p (in the intended interpretation of Reid’s metaphor), one exes p. If one 
exes p and the operative sense is vision, then we can think of vision scientists as trying to explain how 
the visual system derives p from retinal stimulation, “how to get from optical images of scenes back 
to knowledge of the objects that gave rise to them” (Palmer 1999: 23).17
All this granted, there must be a point at which exing falls silent and judging and believing take 
over. If I see the bar and soap and immediately form the belief that Titania has been shopping, I am 
not simply taking “the experience at face value”. I did not ex that Titania has been shopping because 
I didn’t even see Titania, and anyway having been shopping has no characteristic visual signature. My 
belief, rather, is the result of some kind of inference from propositions I did ex. If Titania has not been 
shopping and I claim that my senses were deceiving me, then, in Reid’s words, this “lays the blame 
where it ought not to be laid” (quoted in Van Cleve 2015: 139). There was nothing wrong with the 
testimony of perception, the fault is in what I did with it.
A trickier case is my belief that this red tomato is next to that white bar of soap. Is vision testifying 
to the presence of a tomato, and soap, as such? There is near- universal agreement that “low- level” 
features like color, texture, shape, motion and so on are part of the deliverances of vision, but whether 
the list extends to botanical or artifact kinds is disputed (see, e.g., Siegel and Byrne 2016). For present 
purposes this dispute won’t matter; for convenience we will assume the “rich view”, on which one can 
ex that this tomato is next to that bar of soap.
4 | 
EXING AND PERCEPTUAL EPISTEMOLOGY
An epistemically rational person is not simply a coherent one, or so we may fairly assume. To believe a 
consistent fairy tale is not to believe as one should. Similarly with having credences that confirm to the 
probability calculus: “subjective Bayesianism” is not the correct theory of rationality.18 Further constraints 
come from the world itself, and in particular from perception. Setting credences aside for the moment, 
perception “justifies” belief, or “provides reasons” for belief, or (more plainly put) induces knowledge. 
Exactly how this works is controversial. On one view, if one exes p, one has “prima facie justification” for 
believing p, whether p is true or not.19 On another view, exing is a determinable of a factive propositional 
attitude, which we can call sensing, which does all the epistemological heavy lifting. In the good case, when 
everything is working well, one senses (and exes) p; if one takes one’s experience at face value, then one 
ends up knowing p. In the illusory bad case, one merely exes p and the corresponding belief is excusable 
 17Information from the various senses is pooled (this is particularly clear for smell and taste), hence a single attitude of exing 
is arguably all that is needed; a single attitude is useful but not crucial for the purposes of this paper. Exing appears in 
Morrison 2016 as “perceptually entertaining” (37). There are plenty of exing sympathizers; some recent ones include Siegel 
2010, 2017, Speaks 2015, Schellenberg 2018, Brogaard 2018. Other views of perception are even less hospitable to the 
credence picture. See, e.g., Campbell 2002, Travis 2004, Martin 2004, Brewer 2006, Johnston 2006. Some views hostile to 
exing could be adapted to accommodate credences, e.g. Gupta 2006.
 18See, e.g. Fitelson et al. 2006: 606.
 19See, e.g., Pryor 2000, Huemer 2001, and Siegel and Silins 2015.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
348
 
but unjustified. This is closer to McDowell’s account.20 In a variant, there is no step between sensing (or 
exing) p and believing p— experience is automatically “taken at face value”. On this view, exing (and so 
sensing) entails believing, and sensing (but not exing) entails knowing (Byrne 2016).21
When you see the tomato and soap, it is natural to think that vision testifies that the tomato is red 
and the soap is white, with no qualification needed. Vision is not testifying that the hypothesis that the 
soap is white is likely correct; neither is there anything palpably probabilistic in the attitude, the exing 
relation of ostensible perceptual awareness that you bear to the content. There is nothing hesitant or 
tentative in the presentation of the scene before your eyes: the tomato and soap are just there.
Here is McDowell saying much the same thing. Consider a good case of seeing a medium- sized 
green object in daylight. One is in a position in which:
the greenness of things is visibly there for one, present to one’s rationally self- conscious 
awareness…One’s perceptual state leaves no possibility that it is not green (McDowell 
2011: 38, last emphasis added).
Now it is true that Bayesian models are very popular in perceptual psychology, and for good reason. 
Recovery of the layout of the environment from the retinal stimulus is a notoriously ill- posed problem: 
many hypotheses are compatible with the data. A promising approach is to employ Bayesian methods. In 
a Bayesian perceptual model, the end result of the strictly Bayesian part is a posterior probability distribu-
tion over various possibilities— for instance, different orientations of lines, or different shapes. Leaving it 
there would plainly be inadequate: as an overview of such models explains, “Perception normally yields 
a determinate percept. For instance, one sees an object as having a determinate shape, not a spectrum of 
more or less probable shapes” (Rescorla 2015: 697). To accommodate the phenomenology, the Bayesian 
theorist adds a decision rule to determine one possibility as the “best” hypothesis. One such decision rule 
selects the environmental possibility that has the maximum posterior probability (the MAP, or Maximum 
A Posteriori Rule) (Mamassian et al. 2002; see also Bennett et al. 2014, Rescorla 2015). The proposition 
corresponding to the selected possibility is then the one that the subject exes.
As illustrated by the quotation at the beginning, bistable figures like the Necker cube (below) viv-
idly show the need for a decision rule.
 20See Byrne 2014.
 21For related views, see Gluer 2009, Quilty- Dunn 2015, and Lewis 1980b: 239.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
349
 
The stimulus suggests two plausible real world hypotheses (ironically, neither is correct when viewing 
the usual 2D illustration). On both hypotheses a wire cube is before the perceiver, but the hypotheses dis-
agree about its orientation. Any reasonable Bayesian prior will not favor one over the other. As Denison 
says, “If there is any situation in which we might expect perception to give us a probabilistic experience, 
it is when viewing a bistable figure…But this is not what happens” (2017: 67). Instead, we oscillate from 
seeing the Necker figure as a wire cube with one orientation, to seeing it with another.
Exing, then, is no more probabilistic than believing— even less so, if one can’t ex propositions 
about probabilities. It is thus quite ill- suited to interface with credences. If one exes p, what should 
one’s credence in p be, all else equal? If p is always a fact about some inner realm of self- disclosing 
sensations or appearances, credence 1 is arguably appropriate (and then updating could proceed in the 
usual manner, by ordinary conditionalization). But Cartesianism about perception has had its day, and 
on the contemporary and much better motivated view, p is a proposition about various aspects of one’s 
physical environment. Even in the good case, maximal certainty about the presence of tomatoes and 
soap is too dogmatic: if updating can only proceed by conditionalization (including Jeffrey condition-
alization), it would never be rational to change one’s mind.22 But any lower credence than 1 is entirely 
arbitrary. The rational response to an ordinary case of testimony (perhaps just knowledgeable testi-
mony) is belief in the content of the testimony. On the standard picture of exing, the edges of our “web 
of belief”, where it “impinges on experience” (Quine 1951: 39), are not “degrees of belief” or 
credences— they are full beliefs.
As Munton insightfully puts it:
It is natural to understand the contents of belief states and perceptual states as structurally 
analogous to each other. This is motivated in part by the way in which the two seem capa-
ble of interacting with each other. But if belief comes in degrees, while perceptual states 
stand in a binary relation to their contents, how do they interface with each other? What 
facts about an experience fix the credence a subject is entitled to have in its contents? …
what determines the probability that visual evidence receives? How does that evidence 
take a graded form, if the experiential state itself is binary? There is a mismatch between 
the form of the visual state and that of the belief- state that responds to it. (Munton 2016: 
310)
If the propositional attitude distinctive of perceiving is exing, credences are not found at the edges of 
the web of belief. They must lie in the interior.
Granted that the web starts out with some “a priori” prior credences in the interior, how can cre-
dences rationally change? If perceptual experience doesn’t directly induce a rational change in cre-
dence, then the only other candidate is belief, or knowledge. For instance, knowledge that the coin has 
a probability of .5 of landing heads might rationally induce a credence of .5 that the coin will land 
heads (cf. the “Principal Principle” of Lewis 1980a: 26623). The relevant kind of probability could be 
“objective chance” as found in quantum mechanics, some other kind of physical probability, or 
 22Conditionalizing on p amounts to replacing one’s probability function POLD(α) with PNEW(α) = POLD(α|p); thus PNEW(p) = 
1, and so one becomes 100% certain in p. Jeffrey conditionalizing on p, in the simplest case where one becomes x% confident 
in p and 1- x% confident in ~p, amounts to replacing POLD(α) with PNEW(α) = POLD(α|p).x% + POLD(α|~p).1- x%. In both cases 
if POLD (q) = 1 then PNEW (q) = 1. (See Jeffrey 1965: ch. 11.)
 23As Lewis formulates the Principal Principle, it is not stated in terms of knowledge (or belief) at all, but rather credence. 
Roughly: given that you have credence 1 that the objective chance of p is x, your credence in p should also be x.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
350
 
probability relative to evidence (evidential probability). Knowledge of the symmetry of the coin, the 
tossing process, or the frequency of previous tosses, may have a similar effect without passing through 
explicit knowledge of probabilities. Thus, a dynamic system of credences may be restored by suppos-
ing that exing produces knowledge right at the perception- cognition interface, which in turn is lever-
aged to produce more knowledge, which at some point induces rational credences.24
Dogramaci has recently defended a proposal along these lines:
you have a rational credence, n, in a proposition p— if and only if, and because— you 
reasoned that the chance25 of p is n, and your reasoning followed the correct rules for 
reasoning about chances. (2018: 11)
Dogramaci’s proposal is far from the usual Bayesian vision: knowledge and belief are in the driving 
seat, with credences coming along for the ride. This is more of a vindication of traditional epistemology 
than anything else.
Worse, on this kind of proposal credences seem otiose. Either credences change in response to ex-
plicit knowledge of probabilities or else from knowledge that itself can easily yield knowledge of prob-
abilities. So why bother with credences at all? Why not reason directly about probabilities? Indeed, 
Dogramaci himself is “inclined to accept” the view that “credences just are ordinary full beliefs with 
probabilistic contents” (10). (In the more standard terminology adopted in this paper, this is the view 
that there are no credences.)
The upshot is that credences are dubious entities if perception is not probabilistic. Munton, how-
ever, raises this problem for the Bayesian only to propose a solution. Along with Morrison (2016), she 
argues that perception is probabilistic after all. Can Munton and Morrison pull the Bayesian’s chest-
nuts out of the fire? The next section examines that question.26
5 | 
IS PERCEPTION PROBABILISTIC?
Morrison and Munton’s views are similar; it will be convenient to start with Morrison. He defends 
perceptual confidence, “the view that our perceptual experiences assign degrees of confidence” 
(2016: 15), where “degrees of confidence”, at least in the “ideal” case, can be formally represented as 
obeying the probability calculus (21).27 After noting that philosophers of perception “became con-
vinced that experiences are belief- like in many ways”, he says that “[a]ccording to perceptual confi-
dence, experiences are belief- like in yet another way: they can assign more or less confidence” (16).
Now here Morrison is following many other philosophers and casually talking of beliefs when in 
all strictness he means credences. (At one point he mentions a “ten percent” “confidence at the level 
of belief” (15), clearly having credence .1 in mind.) If perceptual confidence is correct, then 
experiences are more credence- like than belief- like. As Munton puts the view, “visual states include 
 24Cf. Williamson 2010: 4- 7.
 25“When I talk of chance here, I mean a specific sense of this ambiguous term, one that has been called evidential or 
epistemic probability” (Dogramaci 2018: 10).
 26For more discussion of Morrison and Munton see Block 2018 (Morrison), Beck 2020 and Siegel 2020 (Morrison and 
Munton).
 27Morrison’s considered view is actually more qualified— see below.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
351
 
something like the perceptual analogue of credence” (2016: 316).28 And that is exactly what we want. 
If exing is graded like credence, then perceptual input has a probabilistic structure. The web of belief 
is really a web of credence, at least at the edges. Beliefs must lie further from the periphery.
The previous section suggested that perception simply presents the world— the red tomato next to 
the white soap, for instance. However, philosophers are notoriously fond of restricted diets of exam-
ples, and the philosophy of perception is no exception. Staring glassily at some nearby medium- sized 
objects is a rather unusual kind of perceptual situation. More often we are actively scanning a scene 
to try to identify something— one’s keys, a familiar face in a crowd. And of course mundane actions 
are governed by perception— a glimpse of a patch of ice, or uneven pavement, prompts a step to the 
side. Often these sorts of cases are freighted with uncertainty— probably that is Titania (although it 
could be Oberon), probably the pavement is uneven (although there could be a misleading shadow), 
and so on.
Uncontroversially, sometimes uncertainty is on the side of cognition, rather than perception. 
Gazing at the tomato and the soap, and wondering how they got there, I suspect that Titania came 
home early: ‘Perhaps she came home early’, I might say. But there is no temptation to think that per-
ception is testifying that Titania came home early, hesitantly or not; neither is perception testifying 
that there’s a decent chance that Titania came home early. Rather, perception tells me something about 
the tomato and the soap, and it is this strictly perceptual evidence that supports my suspicion that 
Titania came home early. All “perceptual” uncertainty might be like that— a view that Morrison labels 
post- perceptual confidence.29
According to perceptual confidence, uncertainty is also sometimes on the side of perception; spe-
cifically, a kind of uncertainty that is analogous to credences. That is, probability is not in the content 
of perception, but rather in the attitude. Just as a hardcore Bayesian like Jeffrey replaces ‘believing p’ 
with ‘having credence x in p’, the proponent of perceptual confidence replaces ‘exing p’ with ‘exing 
p to degree x’— exingx p, for short. Morrison and Munton provide a number of motivating examples. 
Here are two representative ones.
Vision in fog: Elmer looks through a window and sees a tree being slowly enveloped by fog; “as the 
fog becomes thicker,…the degree of justification Elmer’s experience provides for a tree belief [e.g., 
that there is a tree outside] begins to wane” (Munton 2016: 304).
Peripheral vision: fixating on a cross, with five closely spaced vertical black bars displaced some 
distance to the right, “It looks as though there could be three bars, four bars, five bars, six bars, seven 
bars, or eight bars, but most likely five or six bars” (Morrison 2016: 18).
The second example shows that uncertainty even attends the tomato and soap example. Visual 
acuity drops off quite dramatically outside foveal vision, a fact not immediately apparent because our 
eyes are typically jittering from one point to another. But if you try to read the inscription Ivory on the 
soap while fixating on the tomato, it will be obvious.
Now one could take these examples to support what we can call perceptual probability: the con-
tent of perception is, at least sometimes, probabilistic. Munton does not pursue this possibility (2016: 
316); Morrison, on the other hand, expresses some sympathy with it. (In fact, Morrison understands 
perceptual confidence as a broad thesis that has perceptual probability as a special case. But for our 
purposes it is better to take perceptual confidence as the narrow thesis that exing should be replaced 
by exingx.)
 28The full quotation from Munton is: “…perceptual analogue of credence for belief” (emphasis added), which elides the 
crucial difference between credence and belief.
 29In the psychological literature ‘visual confidence’ is used for “an observer’s ability to judge the accuracy of her perceptual 
decisions” (Mamassian 2016: 459)— metacognitive “post- perceptual” confidence, not a view like Morrison and Munton’s.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
352
 
perceptual probability does not force a credence- based epistemology. If perception is testifying 
that an object is “likely to be a tree” (Munton 2016: 316), then since that could rationally induce a 
probabilistic belief with the same content, why is there any need for credences? On the other hand, 
perceptual probability is not uncongenial to credence- based epistemology. There may be advantages 
to using credences rather than beliefs, and perceptual probability allows that they too could be ratio-
nally induced at the web’s edges.
perceptual probability cannot be ignored, then. We can use Munton’s fog example as the main 
proving ground for both perceptual probability and perceptual confidence.
Elaborating on the example, Munton writes:
If [Elmer] goes to the window soon, he will be able to see the tree outside clearly. That 
experience entitles him to have a high credence in the proposition that there’s a tree 
outside. If he waits a little longer, his foggier experience will entitle him to have only a 
moderate credence in that same content. Why? Both experiences have tree content. But 
that content is presented with different degrees of confidence. When it is presented with 
a high degree of confidence, that entitles Elmer to have a correspondingly high credence 
in the corresponding proposition. When it is presented with a moderate confidence, that 
entitles him to have the same middling degree of belief in its contents. (2016: 322)
Let pTREE be the proposition that this (the tree outside Elmer’s window) is a tree. Munton describes 
Elmer’s situation in accord with perceptual confidence: picking some numbers for illustration, if Elmer 
looks out of the window early, he will ex.9 pTREE; and if he looks out of the window late, he will ex.6 pTREE. 
(We can ignore qualifications about time and tense.) On the alternative view, perceptual probability, the 
propositions that Elmer exes will be about probability, specifically the probability of pTREE. If Elmer looks 
out of the window early, then his experience will testify that the probability of pTREE is .9.
Take perceptual probability first. What kind of probability could experience be testifying to? One 
possibility Morrison mentions is subjective confidence. On that view:
your experience is like a weatherman who tells you how much subjective probability he 
assigns to the possibility that it will rain tomorrow. (2017: 75)
One proposition that Elmer exes when he looks out of the window early, then, can be more explicitly 
expressed as: this experience is confident to degree .9 in pTREE (cf. Morrison 2016: 38).
This is not a very appealing view, if only for the reason that it loses the idea of a perceptual presen-
tation as of a tree entirely. This object is not presented as a tree, or even as likely to be a tree. Rather, 
it is presented as something this experience is 90% confident is a tree. Like Morrison’s weatherman, 
perceptual experience is simply telling Elmer about itself, specifically about its own degrees of confi-
dence. Not only is the content of Elmer’s perceptual state compatible with this object not being a tree, 
it is also compatible with this object being not at all likely to be a tree.30
 30Morrison mentions the similarity of his proposal to Searle’s, on which the content of Elmer’s perceptual state is: there is a 
tree there which is causing this visual experience (cf. Searle 1983: 48- 9). But Searle’s view at least has the advantage that it 
does not eliminate the perceptual presentation as of a tree. This problem applies to two other suggestions of Morrison’s, that 
your experience is “telling you how much confidence you should have”, or is ordering you to have a certain confidence level 
(“Assign fifty percent confidence!”) (2016: 38).
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
353
 
The other possibility is that the relevant probability is “objective”— a physical probability of some 
kind, or (more plausibly) an evidential one. And this is more attractive: perceptual experience is not 
entirely self- absorbed, and the object is presented as (likely to be) a tree.
If Elmer looks out the window early, and watches the tree as the fog slowly gathers, his visual sys-
tem first testifies that prob(pTREE)=.9, and continues to revise this number downwards. Now imagine 
a different case: Elmer is watching a tree shrinking in size (on a clear day). Elmer’s visual system 
first testifies that the height of the tree=h, and continues to revise this number downwards. If the tree 
is shrinking sufficiently quickly, Elmer’s visual system will be able to detect the change, and Elmer 
will have the visual impression that the tree is changing— specifically, that it is becoming smaller. 
Similarly, if the probability that that is a tree is changing sufficiently quickly, Elmer’s visual system 
will be able to detect the change, and Elmer will have the visual impression that the tree is changing: 
specifically, that it is becoming less likely to be a tree. But that is not how a tree being rapidly swathed 
in fog looks: the only apparent change in the scene is the increasing fog.
Putting confidence or probability in the content is not particularly promising, then. That leaves 
perceptual confidence, on which the perceptual propositional attitude is the credence- like attitude of 
exingx.
Return again to Elmer, looking at the befogged tree. He may ex various propositions, including 
pTREE, but his experience is not fragmented, waiting for cognition to combine it into one detailed story 
about scene before his eyes. He plausibly exes a proposition that specifies the scene in much more 
detail than any tractable linguistic representation of it, and that entails any other proposition that he 
exes. Let that proposition, the total content of Elmer’s experience at that time, be pMAX; pMAX entails 
pTREE. If perceptual confidence is right, Elmer exes pMAX to a certain degree, say .7. Presumably that 
proposition could be exed to a different degree, say .9. There should be a pair of cases, then, where 
one subject exes pMAX to degree .7 and the other exes pMAX to degree .9. And the difficulty is that 
there seem to be no such cases. Given the total content, there is no wiggle room for the hypothesized 
perceptual confidence in this proposition to vary.
Let us examine this objection in more detail. As Morrison notes, if the motivating examples support 
perceptual confidence, they also “support confidentialism, the view that if two experiences have the 
same phenomenology, they assign confidence in the same way” (2016: 21), and along similar lines 
Munton says that “[d]ifferences in confidence are phenomenally detectable” (2016: 317). A widely held 
(albeit disputed) thesis is intentionalism, the view that (necessarily) if two experiences have the same 
content, the experiences have the same phenomenal character (Harman 1990 is an early classic defense31). 
perceptual confidence, confidentialism, and intentionalism are jointly inconsistent. By perceptual con-
fidence, the perceiving propositional attitude is exingx. By intentionalism, exingx p and exingy p have the 
same phenomenal character, even if x≠y, which implies that confidentialism is false.
It is not enough to reject intentionalism. Imagine seeing a red spot in good light: your visual sys-
tem can detect both the color of the spot and the intensity of the illuminant, among other things. For 
simplicity, pretend that the total content of your experience is the proposition that that the spot is red 
and brightly illuminated. Your experience has a distinctive “phenomenal character” (PCR), quite dif-
ferent from the phenomenal character associated with seeing a green spot (PCG). Perhaps some kind 
of “inverted spectrum” scenario shows that someone could ex that the spot is red and brightly illumi-
nated, just as you do, but with the accompanying phenomenal character being PCG (Block 2003). If 
that is right then intentionalism is false. But in order to defend perceptual confidence, we need to 
argue that the exed proposition— that the spot is red and brightly illuminated— can be (in Munton’s 
 31See also Tye 2000, Chalmers 2004, and Speaks 2015.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
354
 
phrase) “presented with different degrees of confidence”. And it is quite unclear how to do that. Cases 
of seeing the spot under dim light are irrelevant, since that is to change the content.32
The upshot is that the total content of experience does not appear to be something that can be exed 
to differing degrees. In fact, there seems little reason to suppose that the total content is exed to any 
degree at all. The propositions that Morrison and Munton isolate as “assigned degrees of confidence” 
are never the total contents of the relevant experiences.
Couldn’t the traditional attitude of exing and the new- fangled attitude of exingx be combined? 
When p is the total content, one exes p. But for various weaker propositions q (that this is a tree, for 
instance), one may exx q. The problem with this suggestion is that the senses come out as incoherent: 
they testify to p without qualification, but also hesitantly testify to some propositions entailed by p. 
Taking one’s experience “at face value” would then require full belief in p and, say, .5 credence in 
q— not a rational combination by anyone’s lights.
Finally, a second objection. Elmer, suppose, has different “amounts of confidence” in propositions, 
represented by a function CfELMER from propositions to the interval [0, 1]. Assuming Elmer is a mere 
mortal, CfELMER not a probability function: perhaps CfELMER(p) = .7, but CfELMER(~p) is undefined, 
or is set at .4. So why is CfELMER a credence function? In other words, why are Elmer’s states of confi-
dence credences, as opposed to graded but non- probabilistic mental states? Because Elmer’s states of 
confidence aim at probabilities, in the sense that there something defective about them if CfELMER isn’t 
a probability function. Elmer’s amount of confidence in p and his amount of confidence in ~p should 
sum to 1: his confidence function Cf should be like the credence function Cr of an ideally rational 
agent. Without this normative story, there is no reason to think that ‘x’ in ‘is confident in p to degree 
x’ stands for a probability at all.
Likewise for ‘exing p to degree x’: a normative story is required if “degrees of perceptual confi-
dence” are going to be probabilities, and so are suitable to interface with credences. That is, we need 
to establish that, “like degree of doxastic confidence, degrees of [perceptual confidence] are more or 
less ideal to the extent they preserve the axioms of probability theory” (Morrison 2016: 34). But is 
that plausible?
Block has remarked on the apparent “lack of logical structure” in perception, vision in particular 
(Block 2019: 507).33 Put in terms of exing, Block’s point is that if p is a proposition that can be exed, 
then ~p isn’t; similarly, if exing can predicate feature F, then it can’t predicate ~F.34 That seems right: 
returning to the tomato and soap, vision presents the tomato as red, but does not present the soap as 
not- red— rather, it simply presents the soap as white. (Red is a feature that can produce perceptual 
“pop- out”; not- red is not.) A similar point goes for Morrison and Munton’s examples. To the extent 
that it is plausible to think of vision as presenting incompatible alternatives, these do not include p and 
~p, or an object’s either having F or ~F. As Morrison describes his example of peripheral vision, 
“there could be three bars, four bars, five bars…”.35 Block attributes the lack of negation to the repre-
sentational format of perception (which Block thinks is iconic), but we need not investigate this fur-
ther. It is sufficient to note that the absence of negation is not credibly a deficit, something corrected 
by an “ideal” visual system to which primate visual systems aspire. Yet without the claim that an ideal 
 32The original case is Jeffrey’s “observation by candlelight” (1965: 165- 6), mentioned by both Morrison and Munton.
 33See also Pautz 2020.
 34Disjunction is another example; Block himself doesn’t think perception has propositional content (2019: 507).
 35Morrison suggests that “In simple cases, our experiences assign confidence to a possibility and its negation, like that [a 
person in the distance is] Isaac and that it’s not Isaac” (2016: 20); but by the usual tests not being Isaac is not a feature that 
figures in perceptual content.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
355
 
visual system would constrain the perceiver to ex1- x ~p if she exesx p, “visual confidences” are not 
probabilities. And if they are not probabilities, we are back to Munton’s “mismatch between the form 
of the visual state” and the probabilistic credences that allegedly respond to it.
6 | 
AGAINST CREDENCES
The (provisional) conclusion is that perception is not probabilistic: both perceptual probability and 
perceptual confidence are false. If there are credences, their point of entry is cognitive, not percep-
tual. But a cognitive point of entry threatens to render credences redundant. The easiest way out is 
to deny that we have credences, but this option is frequently not considered. This last section takes it 
seriously.
One— perhaps the main— reason why belief- monism is usually off the table is that credence is 
taken to be “an intuitive notion in folk psychology, familiar from everyday speech and thought” 
(Eriksson and Hájek 2007: 20936). Elaborating, Eriksson and Hájek write:
After all, we have various ways in English (and, we hazard to guess, every natural lan-
guage) for conveying our degrees of belief. Think of the spectrum of phrases that we have 
at our disposal: “I’m certain that p”, “I’m almost certain that p”, “I’m extremely confi-
dent that p”, “I’m moderately confident that p”, “I’m fairly confident that p”, … all the 
way down to their duals at the other end: “I’m certain that not- p”, and so on. (Eriksson 
and Hájek 2007: 209)
However, this list of phrases is not exactly the promised “spectrum” from ‘I’m certain that p’ to ‘I’m 
certain that not- p’. First, the phrases are very limited in number. Second, and more significantly, confi-
dence vanishes around Eriksson and Hájek’s ellipsis, which is why ‘I’m certain that’ reappears at the other 
end. A poll asked Americans how confident they were that the Mueller investigation into President 
Trump’s ties to Russia were fair and impartial. They were given three possible responses: “extremely/
very”, “moderately”, and “not very/not at all”.37 Someone who thought that it was pretty much a tossup— 
that the investigation was about as likely to be partial as to be impartial— should choose the last option, 
not the second one. To be “moderately confident” (or, indeed, “fairly confident”) that the investigation 
was impartial is, if not actually to believe that it is impartial, then to be teetering on the edge.38 One should 
be not at all confident that a fair coin will land heads; likewise, one should be not at all confident that it 
will land tails (cf. Wright and Ayton 1994: 4). As Williamson puts it, “‘No confidence’ is quite different 
from ‘no chance’” (Williamson forthcoming). Only by appeal to the charity of the hearer can one force ‘no 
confidence’ to be ‘no chance’. The question ‘How confident are you on a scale of 0% to 100% that this 
coin will land heads?’ is best interpreted as asking for an estimate of probability: thus, if the coin is fair, 
‘50% confident’ is the right answer.
What about the extremes? Doesn’t “everyday speech and thought” at least give us a handle on cre-
dence 1 and credence zero? We do say, after all, that we are extremely/completely/very confident in 
various propositions. Kellyanne Conway, counsellor to President Trump, once told reporters that “I’m 
very confident he’s not breaking any laws”. Even if she had sincerely said she was “100% confident”, 
 36See also Christensen 2004, Sturgeon 2015, Pettigrew 2016, and Leitgeb 2017, among others.
 37The poll was by the Associated Press- NORC Center for Public Affairs Research, March 2019.
 38It’s also worth noting that ‘I am moderately confident that…’ is quite a rare construction.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
356
 
it is safe to say that she would not have bet her life for a dollar on the proposition that Trump is no law 
breaker. If betting behavior is good test of credence, then Conway did not have credence 1 in that prop-
osition. By the betting test, no ordinary person has credence 1 in anything; if it occurs at all, credence 
1 appears to be a sign of insanity rather than the ideal of rationality.
Do comparative judgments point towards credences? According to Staffel, “degrees of belief are 
the kinds of attitudes we mean when we [say]…that S is more confident in p than in q” (Staffel 2013: 
3536- 7). To take a morbid example from John Venn, “Do I not feel more certain that some one will 
die this week in the whole town, than in the particular street in which I live?” (Venn 1888: 149). The 
at- least- as- confident- in- x- than- y relation at best only generates a partial order over propositions, since 
for many pairs of propositions p, q (including some I have entertained), I will not be at least as confi-
dent in p than I am in q, and neither be at least as confident in q than I am in p. (For example, take p 
to be the proposition that there is life elsewhere in our galaxy, and q to be the proposition that my 
young son will be an accountant.) And although one can make sense of numerically qualified compar-
isons, like ‘I am twice as confident in p that I am in q’, the natural interpretive strategy is to understand 
these unusual locutions as covert probability talk: ‘I think p is twice as likely to be true than q’. (More 
typical numerically qualified uses of ‘confidence’ are used to speak about self- assurance, not cre-
dence: ‘I am twice as confident as I used to be’.) Ordinary comparative judgments of confidence by 
themselves do not give us anything like the rich structure of a probability space.39
Credences are not worn on the sleeve of our talk about confidence. They may yet be implicated 
in some unobvious way, as a number of sophisticated semantic proposals have it (e.g. Yalcin 2012). 
But to use the virtues of these proposals to argue for credences is to put the semantic cart before the 
psychological horse. An independent case for credences needs to be given first.
Perhaps credences are evident by the light of introspection? (Introspection is understood here as a 
method of knowing about one’s own mental states that has no application to the mental states of oth-
ers.40) Indeed, it is invariably assumed that one has at least some knowledge of one’s credences, pre-
sumably by a first- person method.41
One can easily learn to speak the lingo of credences, and to report one’s ostensible degrees of 
confidence in various propositions. That might seem to be evidence for credences— why else would 
the reporting come so easily? However, there are plausible alternative explanations that render the 
postulation of credences idle. One is given a simple coin- tossing problem. What is one’s credence that 
the coin will land heads twice? The only apparent way to answer is to calculate the probability that the 
coin will land heads twice. Once one has worked that out (rightly or wrongly), the probability simply 
gets transferred to one’s supposed credence: ‘I have credence .25 that the coin will land heads’. And a 
mere recipe for converting known statements about Xs to corresponding statements about Ys does not 
suggest that the latter are true, otherwise astrology would be on a much surer footing.
Another kind of case where probability judgments seem to be in the driving seat are non- numerical 
comparisons like Venn’s example: “Do I not feel more certain that some one will die this week in the 
whole town, than in the particular street in which I live?” There is no need to suppose that an affirma-
tive answer is given by comparing one’s credences in the two propositions: one can simply note that 
deaths in Venn’s street are deaths in his town, but not conversely. So (given a background assumption 
 39Given certain assumptions, a comparative probability relation can be represented by a (non- unique) probability function; 
see Stefánsson 2017. Stefánsson uses this formal result to argue that only comparative credences are psychologically real (see 
Stefánsson 2018 for some qualifications). This position is also vulnerable to the main arguments in this paper.
 40On introspection of credences, see Dogramaci 2016; on introspection of the strength of belief, see Byrne 2018: 119- 20.
 41Or, if not knowledge, then a Bayesian surrogate.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
357
 
about mortality) deaths in his town must be more probable than deaths in his street, which one can 
express in terms of “feeling more certain”. Alternatively, as in the fable of Linda the feminist bank 
teller, one might answer by using Kahneman and Tversky’s representative heuristic. A representative 
bank teller is not, like Linda, a philosophy major passionate about social justice; hence Linda is more 
likely to be a feminist bank teller than a bank teller— which again one can express in terms of feeling 
more certain. If one is familiar with the ideology of credences, one can further report that one has 
greater credence that Linda is a feminist bank teller, but we have not yet seen any reason to think that 
this report is correct.
One can answer Venn’s question without being able to discern one’s credence in either proposition. 
If we have direct introspective access to credences, an explanation is needed of how one can com-
pare them without having the foggiest idea of their actual values. That is not to say that one can’t be 
provided, but the most parsimonious hypothesis is that answering Venn’s question does not involve 
comparing credences at all.
So far we have gone some way to undermining the positive case for credences; let us now consider 
the positive case against.
6.1 | The difficulty of probabilistic reasoning
In 2012 97 members of the UK Parliament were asked for the probability of getting heads twice in 
two coin tosses. 60 gave the wrong answer (Spiegelhalter 2019: 209). Admittedly they were not told 
that the coin could land either heads or tails with equal probability, or that the probability of a second 
head given a first head is the same as the probability of a second head given a first tail, but this would 
only have confused them further.
It is not just MPs. People in general are not very good at reasoning with explicitly probabilistic 
premises (say, the probability of positive test result given cancer = .8); we do much better if presented 
with natural frequencies (of 10 people with a positive test result, 8 will have cancer). Given data in the 
form of conditional probabilities, we find it difficult to work out, say, the probability that a person has 
cancer given a positive test result. Given similar data in the form of natural frequencies, the problem 
is much more tractable.42 Holton uses this fact to argue against credences:
[I]f the probabilities were really in the attitudes [as opposed to being in the content], then 
to do the calculation the subjects would need to have credences of the correct degree 
before they could apply Bayes’ rule. But the relevant degrees of credence are exactly 
what they are given when the problems are presented as conditional probabilities. In 
contrast, in the natural frequency presentation, the conditional probabilities are merely 
implicit in the data. The subjects would first have to calculate the relevant conditional 
probabilities and then go on to apply Bayes’ rule. So you would expect the natural fre-
quency presentation, requiring a further step, to be more difficult than the conditional 
probability presentation. (Holton 2014: 24)43
 42Simplifying Holton’s example (2014: 22): 10 in 1000 people have cancer; of those 10, 8 will have a positive test result. Of 
the remaining 990, 99 will have a positive test result. Assuming these frequencies reflect the probabilities, the probability of 
cancer conditional on a positive test = 8/107 = 7%.
 43Holton has another argument, which starts from the premise that the two presentations are “logically equivalent” 
“descriptions of the same situation” (25). But the two presentations are not logically equivalent, since natural frequencies are 
compatible with numerous different assignments of probability.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
358
 
Holton is assuming that if we have credences, they are used to reason with probabilities. That is, if 
one has a probabilistic problem to solve (‘What is the probability that someone with a positive test result 
has cancer?’) one first forms the appropriate credences, given the description of the problem. Next, one’s 
Bayesian psychological machinery starts whirring and grinding, and one forms a new credence— more 
exactly, a conditional credence, one’s credence in a person having cancer, conditional on having a positive 
test result. One then, in effect, converts this conditional credence into a belief about conditional probabil-
ity, and the content of that belief is the answer: ‘The probability that someone with a positive test result 
has cancer = 10%’. Explicitly stating the conditional probabilities, rather than leaving them implicit in the 
natural frequencies, would then presumably make the problem easier.
However, Holton’s argument does not quite work as stated. As Holton himself emphasizes, putting 
the problem in terms of natural frequencies makes it easy to solve through a simple calculation. Given 
that a simple calculation is available, why take the trouble of converting frequencies to probabilities, 
then to credences, and back again to probabilities? And if subjects stick with the simple calculation, 
then the natural frequency presentation does not involve a “further step”— the method is entirely dif-
ferent. So there is no reason to expect it to be more difficult.
Still, that does not explain why we do so badly with the conditional probability presentation. We 
clearly do not form the appropriate credences and let the Bayesian machinery do its work: the vast ma-
jority of us become confused and give the wrong answer. And there is no evidence that the unconfused 
minority are manipulating credences, rather than explicitly reasoning with beliefs about probabilities.
This is puzzling. If we have credences, then there must be at least a rough match between them 
and our statements of probability and confidence. For if these come drastically apart, and credences 
explain behavior, then one would predict peculiar dissociations— I claim to feel very confident that 
Zippy will win the 2.30, but put all my money on The Sluggard. Given that we have both beliefs and 
credences, one would expect the credences to provide some added value, otherwise they would be an 
evolutionary extravagance.
Perhaps the fact that the problem is stated linguistically somehow biases us to reason with beliefs 
about probabilities rather than credences. So let us leave language behind altogether, and examine 
how chimpanzees, our closest relatives, cope with elementary probability problems. Chimpanzees are 
similar to us in so many ways: they have the same basic perceptual apparatus; they know about the 
mental lives of their fellows and have complex social relations; they can count, anticipate the future, 
and reason using disjunctive syllogism. It would be extraordinary if credences arose in the human 
lineage, leaving chimpanzees to muddle through with old- fashioned belief and knowledge. Credences 
are of no more help with distinctively human problems than they are with problems faced by all great 
apes. If we have credences, chimpanzees surely do as well.
Here is one relevant experiment (Hanus and Call 2014).44 A chimpanzee watches treats being put 
into closed cans, resulting in (say) two of six cans on the right, and one of two cans on the left, con-
taining a treat. The chimpanzee does not know which individual cans have treats, and has the option 
of picking one can from the right or one can from the left. Choosing left will maximize the expected 
gain: 50% chance of a treat as opposed to 33%. Chimpanzees do better than chance, and seem to be 
sensitive to the ratio of the two probabilities— the higher it is, the more likely they are to make the 
right choice. Interestingly, they show no appreciation of the significance of probability 1, treating the 
certainty of a treat on one side like any other probability, to be compared to the probability of a treat 
on the other. If chimpanzees have credences, one would expect the advantages of the Bayesian 
 44See also Tecwyn et al. 2017. On probabilistic reasoning in infants, see Denison and Xu 2014.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
359
 
machinery to be on display here. Instead, the chimpanzees’ performance suggests that they are merely 
capable of rudimentary probability judgments.
Chimpanzees, like many other animals, have a variety of ways of coping with uncertainty. For ex-
ample, they can monitor how well they have performed on a rewarded task where the reward is dis-
pensed some distance away. The chimpanzees can either wait for a cue that tells them they will be 
rewarded, or else move to the reward site before the cue (making it easier to get the reward). They are 
more likely to move early when they successfully complete the task (Beran et al. 2015). But this so-
phisticated ability does not require credences.45
6.2 | Credences and memory
On the Bayesian picture, credences are supposed to be retained, just like beliefs, and updated when neces-
sary. Without retention, there would be no learning (more precisely, no Bayesian surrogate of learning). And 
if credences are retained, they can surely be recalled, brought to mind when the occasion requires. What 
would recalling a credence be like? If one has credence x in p one can note that psychological fact and com-
mit it to memory, later recollecting that one has credence x in p. However, this is ordinary belief- memory, 
not credence- memory in the pertinent sense. If one can bring to mind one’s stored credence x in p, the 
content of this episode of recollection should be p, the content of the credence. How could the probabilistic 
index x manifest itself? The obvious suggestion is: through a feeling of confidence. That is, one will recall 
p, but one’s recollection will more or less confident, depending on the value of x.
Sometimes confidence is an entirely intellectual affair, as with Venn’s example of being more 
certain of a death next week in one’s town than a death in one’s street. Venn uses ‘feel more certain’ 
which, although perfectly appropriate, blurs the distinction between his example and ones where there 
really is some kind of “feeling” or sensation. (“Feeling confident in p” is therefore improbably a 
natural psychological kind.) The classic illustrations of phenomenological confidence are “tip of the 
tongue” states, poetically described by William James:
Suppose we try to recall a forgotten name. The state of our consciousness is peculiar. 
There is a gap therein; but no mere gap. It is a gap that is intensely active. A sort of 
wraith of the name is in it, beckoning us in a given direction, making us at moments 
tingle with the sense of our closeness and then letting it sink back without the longed- for 
term. (James 1893: 251)
Consider an example discussed by Weisberg (2020). If asked for the capital of Iceland, one might an-
swer ‘Reykjavik’, but in some palpable way “feel uncertain” that the answer is correct. (And similarly for 
comparatives: one might palpably “feel more certain” that Reykjavik is the capital than that Bergen is.) 
And this seems to be exactly the desired phenomenon: if there is such a thing as recalling a credence, this 
is an example. Weisberg sees a problem here, noting that there is much evidence suggesting that these 
sorts of “feelings of confidence” (or “feelings of knowing”) are due to cues like ease of processing (“flu-
ency”) and whether related information can be brought to mind.46 As he puts it, “confidence in memory- 
based beliefs appears to be constructed at the time of recall, rather than stored” (18). Weisberg directly 
 45On “uncertainty monitoring” in animals, see Smith et al. 2003, Smith and Washburn 2005.
 46See, e.g., Oppenheimer 2008.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
360
 
draws the conclusion that credence is “constructed at the time of recall” (19), but this seems to be because 
he identifies credence and confidence (in the ordinary sense47).
However, confidence— whether of the intellectual or phenomenological variety— is not credence. 
The fact that feelings of confidence derive from the process of recollection does not immediately show 
that credences are not stored in memory. But we can reach that conclusion by slightly expanding and 
amending Weisberg’s line of thought. If we can recall credences, their strength is manifest (at least 
sometimes) in feelings of confidence. Feelings of confidence are based on cues like fluency. Yet it 
is very implausible that fluency and related cues are an indication of the strength of remembered 
credence. A storage system for credences needs to keep track of two items, propositions and their 
probabilistic indices. There is no reason to think that retrieving <p, .5> is going to be harder than 
retrieving <p, .9>. And what on earth would be the point of making middling or low credences a 
struggle to retrieve?
If we can store credences, we should be able to recollect them. Since the best candidate for doing 
that is not sensitive to the strength of credence, but is rather driven by unrelated factors, credences are 
not remembered.
* * *
Orthodoxy about credences and orthodoxy about perception conflict. Attempts to resolve the con-
flict by amending orthodoxy about perception instructively fail. This paper has recommended hetero-
doxy about credences instead. As Weisberg emphasizes, the empirical issues are subtle and 
complicated, and any conclusion should be stated circumspectly. There are no credences. Probably.48
ORCID
Alex Byrne 
 https://orcid.org/0000-0003-3652-1492 
REFERENCES
Beck, J. (2020). On perceptual confidence and “completely trusting your experience”. Analytic Philosophy, 61, 174– 188.
Bennett, D., Trommerhauser, J., & van Dam, L. C. J. (2014). Bayesian modeling of perceiving: A guide to basic prin-
ciples. In D. Bennett & C. Hill (Eds.), Sensory integration and the unity of consciousness. Cambridge, MA: MIT 
Press.
Beran, M. J., Perdue, B. M., Futch, S. E., Smith, J. D., Evans, T. A., & Parrish, A. E. (2015). Go when you know: 
Chimpanzees’ confidence movements reflect their responses in a computerized memory task. Cognition, 142, 
236– 246.
Block, N. (2003). Mental paint. In M. Hahn & B. Ramberg (Eds.), Reflections and replies: Essays on the philosophy of 
Tyler Burge. Cambridge, MA: MIT Press.
Block, N. (2018). If perception is probabilistic, why doesn't it seem probabilistic? Philosophical Transactions of the 
Royal Society B, 373, 20170341.
Block, N. (2019). Attention as a conduit: reply to Nicholas Silins and Susanna Siegel. In A. Pautz & D. Stoljar (Eds.), 
Blockheads! (pp. 505– 510). Cambridge, MA: MIT Press.
Brewer, B. (2006). Perception and content. European Journal of Philosophy, 14, 165– 181.
Brogaard, B. (2018). Seeing and saying. Oxford: Oxford University Press.
Buchak, L. (2014). Belief, credence, and norms. Philosophical Studies, 169, 1– 27.
 47E.g., “how do dualists explain the tight connection between full belief and high credence? Typically, we believe P only 
when we are highly confident in P” (Weisberg 2020: 3, emphasis added).
 48Many thanks to Jake Beck, Tyler Brooke- Wilson, Andy Egan, E.J. Green, Steven Gross, Anil Gupta, Alan Hájek, Richard 
Holton, Harvey Lederman, John Morrison, Jessie Munton, Ram Neta, Susanna Schellenberg, Miriam Schoenfield, Susanna 
Siegel, Kieran Setiya, Jonna Vance, Roger White, and audiences at MIT, Cambridge, and the 2019 Rutgers Epistemology 
Conference.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
361
 
Byrne, A. (2014). McDowell and Wright on anti- scepticism etc. In D. Dodd & E. Zardini (Eds.), Scepticism and percep-
tual justification (pp. 275– 297). Oxford: Oxford University Press.
Byrne, A. (2016). The epistemic significance of experience. Philosophical Studies, 173, 947– 967.
Byrne, A. (2018). Transparency and self- knowledge. Oxford: Oxford University Press.
Campbell, J. (2002). Reference and consciousness. Oxford: Oxford University Press.
Chalmers, D. J. (2004). The representational character of experience. In B. Leiter (Ed.), The future for philosophy (pp. 
153– 181). Oxford: Oxford University Press.
Christensen, D. (2004). Putting logic in its place: Formal constraints on rational belief. Oxford: Oxford University 
Press.
Clarke, R. (2013). Belief is credence one (in context). Philosophers’ Imprint, 13, 1– 18.
Daw, N., & Courville, A. (2007). The pigeon as particle filter. Advances in Neural Information Processing Systems, 20, 
1528– 1535.
de Finetti, B. (2017). Theory of probability. Chichester, UK: John Wiley.
Denison, R. N. (2017). Precision, not confidence, describes the uncertainty of perceptual experience: Comment on John 
Morrison’s “perceptual confidence”. Analytic Philosophy, 58, 58– 70.
Denison, S., & Xu, F. (2014). The origins of probabilistic inference in human infants. Cognition, 130, 335– 347.
Dietrich, F., & List, C. (2021). The relation between degrees of belief and binary beliefs: A general impossibility the-
orem. In I. Douven (Ed.), Lotteries, knowledge, and rational belief: Essays on the lottery paradox (pp. 223– 254). 
Cambridge: Cambridge University Press.
Dogramaci, S. (2016). Knowing our degrees of belief. Episteme, 13, 269– 287.
Dogramaci, S. (2018). Rational credence through reasoning. Philosophers' Imprint, 18, 1– 25.
Easwaran, K. (2016). Dr. Truthlove or: How I learned to stop worrying and love Bayesian probabilities. Noûs, 50, 
816– 853.
Eriksson, L., & Hájek, A. (2007). What are degrees of belief? Studia Logica, 86, 185– 215.
Fitelson, B., Hajek, A., & Hall, N. (2006). Probability. In J. Pfeifer & S. Sarkar (Eds.), The philosophy of science: An 
encyclopedia (pp. 599– 610). Routledge.
Glüer, K. (2009). In defence of a doxastic account of experience. Mind and Language, 24, 297– 327.
Greco, D. (2015). How I learned to stop worrying and love probability 1. Philosophical Perspectives, 29, 179– 201.
Gupta, A. (2006). Empiricism and experience. Oxford: Oxford University Press.
Hájek, A., & Lin, H. (2017). A tale of two epistemologies? Res Philosophica, 94, 207– 232.
Hanus, D., & Call, J. (2014). When maths trumps logic: Probabilistic judgements in chimpanzees. Biology letters, 10, 
20140892.
Harman, G. (1986). Change in view. Cambridge, MA: MIT Press.
Harman, G. (1990). The intrinsic quality of experience. Philosophical Perspectives, 4, 31– 52.
Hawthorne, J., Rothschild, D., & Spectre, L. (2016). Belief is weak. Philosophical Studies, 173, 1393– 1404.
Hawthorne, J., & Stanley, J. (2008). Knowledge and action. Journal of Philosophy, 105, 571– 590.
Holton, R. (2008). Partial belief, partial intention. Mind, 117, 27– 58.
Holton, R. (2014). Intention as a model for belief. In M. Vargas & G. Yaffe (Eds.), Rational and social agency: Essays 
on the philosophy of Michael Bratman (pp. 12– 37). Oxford: Oxford University Press.
Horgan, T. (2017). Troubles for Bayesian formal epistemology. Res Philosophica, 94, 233– 255.
Huemer, M. (2001). Skepticism and the veil of perception. Lanham, MD: Rowman & Littlefield.
Jackson, E. (2019). Belief and credence: Why the attitude- type matters. Philosophical Studies, 176, 2477– 2496.
James, W. (1893). The principles of psychology, Vol. 1. New York: Henry Holt.
Jeffrey, R. (1965). The logic of decision. Chicago: University of Chicago Press.
Jeffrey, R. (1970). Dracula Meets Wolfman: Acceptance vs. partial belief. In M. Swain (Ed.), Induction, acceptance, 
and rational belief (pp. 157– 185). Dordrecht: Reidel.
Jeffrey, R. (1992). Probability and the art of judgment. Cambridge: Cambridge University Press.
Johnston, M. (2006). Better than mere knowledge? The function of sensory awareness. In T. S. Gendler & J. Hawthorne 
(Eds.), Perceptual experience (pp. 260– 290). Oxford: Oxford University Press.
Joyce, J. M. (2010). The development of subjective Bayesianism. In D. M. Gabbay, J. Woods, & A. Kanamori (Eds.), 
Handbook of the history of logic, Volume 10 (pp. 415– 475). Amsterdam: Elsevier.
Leitgeb, H. (2017). The stability of belief: How rational belief coheres with probability. Oxford: Oxford University 
Press.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
362
 
Lewis, D. (1980a). A subjectivist’s guide to objective chance. In R. C. Jeffrey (Ed.), Studies in inductive logic and prob-
ability, volume II (Vol. 2; pp. 263– 293). Berkeley: University of California Press.
Lewis, D. (1980b). Veridical hallucination and prosthetic vision. Australasian Journal of Philosophy, 58, 239– 249.
Maher, P. (1993). Betting on theories. Cambridge: Cambridge University Press.
Mamassian, P. (2016). Visual confidence. Annual Review of Vision Science, 2, 459– 481.
Mamassian, P., Landy, M., & Maloney, L. T. (2002). Bayesian modelling of visual perception. In R. P. N. Rao, B. A. 
Olshausen, & M. S. Lewicki (Eds.), Probabilistic models of the brain: Perception and neural function (pp. 13– 36). 
Cambridge, MA: MIT Press.
Mandelbaum, E. (2018). Troubles with Bayesianism: An introduction to the psychological immune system. Mind and 
Language, 1– 17.
Martin, M. G. F. (2004). The limits of self- awareness. Philosophical Studies, 120, 37– 89.
McDowell, J. (1994). Mind and world. Cambridge, MA: Harvard University Press.
McDowell, J. (2008). Avoiding the myth of the given. In J. Lindgaard (Ed.), John McDowell: Experience, norm, and 
nature (pp. 1– 14). Oxford: Blackwell.
McDowell, J. (2011). Perception as a capacity for knowledge. Milwaukee WI: Marquette University Press.
Moon, A. (2017). Beliefs do not come in degrees. Canadian Journal of Philosophy, 47, 760– 778.
Morrison, J. (2016). Perceptual confidence. Analytic Philosophy, 57, 15– 48.
Moss, S. (2018). Probabilistic knowledge. Oxford: Oxford University Press.
Munton, J. (2016). Visual confidences and direct perceptual justification. Philosophical Topics, 44, 301– 326.
Nagel, J. (2013). Knowledge as a mental state. Oxford Studies in Epistemology, 4, 275– 310.
Oppenheimer, D. M. (2008). The secret life of fluency. Trends in Cognitive Sciences, 12, 237– 241.
Palmer, S. E. (1999). Vision science: Photons to phenomenology. Cambridge, MA: MIT Press.
Pautz, A. (2020). Representationalism about consciousness. In U. Kriegel (Ed.), Oxford handbook of the philosophy of 
consciousness (pp. 405– 437). Oxford: Oxford University Press.
Pettigrew, R. (2016). Accuracy and the laws of credence. Oxford: Oxford University Press.
Pryor, J. (2000). The skeptic and the dogmatist. Noûs, 43, 517– 549.
Quilty- Dunn, J. (2015). Believing in perceiving: Known illusions and the dual- component theory. Pacific Philosophical 
Quarterly, 96, 550– 575.
Quine, W. V. O. (1951). Two dogmas of empiricism. Philosophical Review, 60, 20– 43.
Ramsey, F. P. (1926). Truth and probability. In R. B. Braithwaite (Ed.), Foundations of mathematics and other logical 
essays (pp. 156– 198). London: Kegan, Paul, Trench, Trubner, & Co.
Rescorla, M. (2015). Bayesian perceptual psychology. In M. Matthen (Ed.), The Oxford handbook of philosophy of 
perception (pp. 694– 716). Oxford: Oxford University Press.
Schellenberg, S. (2018). The unity of perception: Content, consciousness, evidence. Oxford: Oxford University Press.
Schoenfield, M. (2012). Chilling out on epistemic rationality. Philosophical Studies, 158, 197– 219.
Searle, J. R. (1983). Intentionality. Cambridge: Cambridge University Press.
Siegel, S. (2010). The contents of visual experience. Oxford: Oxford University Press.
Siegel, S. (2017). The rationality of perception. Oxford: Oxford University Press.
Siegel, S. (2020). How can experiences explain uncertainty? Mind and Language, 35, 1– 25.
Siegel, S., & Byrne, A. (2016). Rich or thin? In B. Nanay (Ed.), Current controversies in philosophy of perception (pp. 
59– 80). New York: Routledge.
Siegel, S., & Silins, N. (2015). The epistemology of perception. In M. Matthen (Ed.), The Oxford handbook of the phi-
losophy of perception (pp. 781– 811). Oxford: Oxford University Press.
Smith, J. D., Shields, W. E., & Washburn, D. A. (2003). The comparative psychology of uncertainty monitoring and 
metacognition. Behavioral and Brain Sciences, 26, 317– 339.
Smith, J. D., & Washburn, D. A. (2005). Uncertainty monitoring and metacognition by animals. Current Directions in 
Psychological Science, 14, 19– 24.
Speaks, J. (2015). The phenomenal and the representational. Oxford: Oxford University Press.
Spiegelhalter, D. (2019). The art of statistics. London: Pelican.
Staffel, J. (2013). Can there be reasoning with degrees of belief? Synthese, 190, 3535– 3551.
Stalnaker, R. (1988). Belief attribution and context. In R. H. Grimm & D. D. Merrill (Eds.), Contents of thought (pp. 
140– 156). Tucson, AZ: University of Arizona Press. Page reference to the reprint in Stalnaker 1999.
Stalnaker, R. (1999). Context and content: Essays on intentionality in speech and thought. Oxford University Press.
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

BYRNE
363
 
Stanley, J., & Williamson, T. (2001). Knowing how. Journal of Philosophy, 98, 411– 444.
Stefánsson, H. O. (2017). What is “real” in probabilism? Australasian Journal of Philosophy, 95, 573– 587.
Stefánsson, H. O. (2018). On the ratio challenge for comparativism. Australasian Journal of Philosophy, 96, 380– 390.
Sturgeon, S. (2008). Reason and the grain of belief. Noûs, 42, 139– 165.
Sturgeon, S. (2015). The tale of Bella and Creda. Philosophers’ Imprint, 15, 1– 9.
Tecwyn, E. C., Denison, S., Messer, E. J., & Buchsbaum, D. (2017). Intuitive probabilistic inference in capuchin mon-
keys. Animal Cognition, 20, 243– 256.
Travis, C. (2004). The silence of the senses. Mind, 113, 57– 94.
Tversky, A., & Kahneman, D. (1983). Extensional versus intuitive reasoning: the conjunction fallacy in probability 
judgment. Psychological Review, 90, 293– 315.
Tye, M. (2000). Consciousness, color, and content. Cambridge, MA: MIT Press.
Van Cleve, J. (2015). Problems from reid. Oxford: Oxford University Press.
Venn, J. (1888). The logic of chance. London: Macmillan and Co.
Wedgwood, R. (2012). Outright belief. Dialectica, 66, 309– 329.
Weisberg, J. (2020). Belief in psyontology. Philosophers’ Imprint, 20, 1– 27.
White, R. (2010). Evidential symmetry and mushy credence. In T. Szabó Gendler & J. Hawthorne (Eds.), Oxford studies 
in epistemology (Vol. 3, pp. 161– 186). Oxford: Oxford University Press.
Williamson, J. (2010). In defence of objective Bayesianism. Oxford: Oxford University Press.
Williamson, T. (2000). Knowledge and its limits. Oxford: Oxford University Press.
Williamson, T. (forthcoming). Knowledge, credence, and the strength of belief. In A. Flowerree & B. Reed (Eds.), 
Towards an expansive epistemology: Norms, action, and the social sphere. London: Routledge.
Wright, G., & Ayton, P. (Eds.). (1994). Subjective probability. Chichester, UK: Wiley.
Yalcin, S. (2012). Bayesian expressivism. Proceedings of the Aristotelian Society, 112, 123– 157.
How to cite this article: Byrne A. Perception and Probability. Philosophy and 
Phenomenological Research, 2022;104:343–363. https://doi.org/10.1111/phpr.12768
 19331592, 2022, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/phpr.12768 by Massachusetts Institute of Technolo, Wiley Online Library on [17/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

