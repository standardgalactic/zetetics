Efﬁciently Determining the Appropriate Mix of Personal
Interaction and Reputation Information in Partner Choice
Shulamit Reches1
Philip Hendrix2
Sarit Kraus1
Barbara J. Grosz2
1 Department of Computer Science, Bar-Ilan University, Ramat-Gan, 52900 Israel
reches@013.net, sarit@cs.biu.ac.il
2 SEAS, Harvard University, Cambridge, MA 02138 USA
{phendrix, grosz}@eecs.harvard.edu
ABSTRACT
Many multi-agent settings require that agents identify appropriate
partners or teammates with whom to work on tasks. When select-
ing potential partners, agents may beneﬁt from obtaining informa-
tion about alternative possibilities through gossip (i.e., by consult-
ing others) or using a reputation system (a centralized repository
of information about past behavior). This paper deﬁnes a statistical
model, the “Information-Acquisition Source Utility model" (IASU)
by which agents operating in an uncertain world can determine the
amount of information to collect about potential partners before
choosing one and which information sources they should consult
(gossip, reputation system, or additional personal interaction with
the agent). The IASU model explicitly represents the cost of in-
formation, which may vary by information source. To maximize
the expected gain from a choice, it estimates the utility of choosing
a partner by iteratively estimating the beneﬁt of additional infor-
mation. The paper reports empirical studies that compare the ef-
fectiveness of the IASU model with a baseline in which only prior
experience with a potential partner is used as the basis of the deci-
sion and with a model that determines in advance both the amount
of information and its allocation among the different sources. Two
different application domains are used in these empirical studies,
the Surrogate Venture Game model, which concerns choosing an
optimal partner for a business venture, and a restaurant domain.
The results of the experiments show that the use of the model sig-
niﬁcantly increases the agents’ overall utility.
Categories and Subject Descriptors
I.2.11 [Distributed Artiﬁcial Intelligence]: Multiagent systems
1.
INTRODUCTION
In many multi-agent system (MAS) settings, agents may need to
choose a partner for a long term collaboration [21]. For example, an
agent may look for a possible partner with whom to cooperate in an
online negotiation. Usually, agents have many possible partners to
choose from, and thus they can beneﬁt from obtaining information
from other agents’ experience with potential partners. Relying on
personal information may be risky, because an agent may not have
enough information to make a good decision.
Cite as: Efﬁciently Determining the Appropriate Mix of Personal Inter-
action and Reputation Information in Partner Choice, Shulamit Reches,
Philip Hendrix, Sarit Kraus, and Barbara J. Grosz, Proc. of 7th Int. Conf.
on Autonomous Agents and Multiagent Systems (AAMAS 2008),
Padgham, Parkes, Müller and Parsons (eds.), May, 12-16., 2008, Estoril,
Portugal, pp. XXX-XXX.
Copyright c⃝2008, International Foundation for Autonomous Agents and
Multiagent Systems (www.ifaamas.org). All rights reserved.
This paper focuses on the problem of deciding how much infor-
mation to collect about potential partners before choosing one of
them, given a variety of information sources, with different costs
associated with accessing each source. For expository purposes we
use the term candidate to refer to a potential partner and the term
Chooser to refer to the agent that needs to choose a partner.
To obtain an accurate picture of a candidate in an environment
in which information is incomplete, the Chooser would have to in-
teract many times before its personal experience was sufﬁcient to
accurately judge the candidate as a long term collaborator. In some
MAS environments, agents may not be able to take part in enough
such interactions before making a long term commitment. Gossip
[6] and reputation systems [8] provide mechanisms which agents
may use to gain knowledge about the behavior of other agents. This
paper considers environments that have three information sources:
(1) personal interaction, i.e. experience gained through direct in-
teraction with a candidate; (2) gossip, information obtained from
another agent about the behavior of a candidate; (3) reputation sys-
tem, a centralized repository of information. Obtaining informa-
tion about candidates from these information sources may improve
a Chooser’s decision of which candidate is most likely to make the
best partner.
In most situations, there is a cost associated with obtaining in-
formation. For example, the cost of accessing information in a rep-
utation system may be the time needed to search on-line, the time
needed to check reliability, or the money that must be paid for in-
formation from a speciﬁc supplier. As a result, a resource-bounded
Chooser must be able to decide how to allocate its resources among
the different information sources to obtain a better picture of the
candidates.
In this paper, we investigate analytic and empirical methods for
deciding how much information to acquire from each source (per-
sonal, gossip or reputation system) given their associated costs, so
that the agent will make the best decision in choosing a long term
partner.
We deﬁne a statistical model, the Information-Acquisition Source
Utility (IASU) to determine the maximum expected utility when
choosing a partner for a long term collaboration. The IASU model
combines prior information about available candidates with beliefs
about the distribution of the candidates in the environment. Given
this information, it estimates the amount of information a Chooser
should obtain about each candidate and which information sources
to use to maximize the Chooser’s reward. We derive a utility func-
tion that estimates the expected reward from every possible alloca-
tion of the Chooser’s resources and then ﬁnds its maxima. Locating
the maxima of this utility function provides an estimation of the al-
location that maximizes the Chooser’s utility.
Extensive research has been devoted to the problem of determin-

ing how to allocate resources to select the best candidate among
several available options [2, 3, 16, 18]. However, prior research
has not taken into account the use of such resources as gossip in-
formation or information obtained through a centralized reputation
system. In contrast, research in the reputation arena [11, 22, 10]
has not addressed the question of appropriate allocation of the in-
formation obtained.
We have applied the IASU model to two test domains: (1) the
Venture Game in which an agent has to choose an optimal candidate
with which to play in order to obtain a maximum utility score; (2) a
Restaurant Domain in which an agent must identify the best restau-
rant among several candidates to choose as a subcontractor for a
long term catering contract. The Venture Game domain is a sim-
ulation domain similar to the Surrogate Venture game introduced
by Hendrix [9] to capture the essence of the dependence among
partners undertaking business ventures. In this game an agent has
the ability to enter business ventures with other agents by invest-
ing its recourses in a venture. The agent working with the invested
recourses will successfully complete the venture and return a high
reward, or fail and produce no reward.
The restaurant test domain was created using information ob-
tained through customer surveys and online restaurant reviews. In
this domain, an employer seeks a restaurant from which it can
purchase a quantity of meals for its employees at a reduced cost.
The employer is committed to selecting a high quality restaurant to
avoid having to pay for additional meals if employees choose to se-
lect a different restaurant. The IASU model is intended to help an
employer pick the best restaurant to minimize the employer’s costs
when buying meals.
In the next section we describe the construction of the IASU
model, describe a two-candidate case and then the k-candidate case.
Section 3 contains an evaluation of the IASU model. In Section 4,
we present related work in the ﬁeld. Conclusions are given in Sec-
tion 5.
2.
THE IASU MODEL
The Information-Acquisition Source Utility (IASU) model, is a
statistical model that represents the tradeoff between exploration
and exploitation when choosing a candidate for long term collabo-
ration. It speciﬁes the allocation of the information among various
information sources.
We formally model the set of candidates as c1, ..., ck ∈C. Each
candidate ci is assigned a competence value pi (0 ≤pi < 1), which
is the probability the candidate will succeed in performing a task.
The competence values of the candidates are initially unknown to
the Chooser and are sampled from a Beta random variable [1]. Al-
though the pi’s are unknown in advance, the Chooser has some
prior beliefs about the candidates’ mean and variance based on its
knowledge of the world. These prior assumptions may be inac-
curate. The agent can estimate the values of αi and βi, such as
pi ∼B(αi, βi).
In an ideal world, the Chooser aims to select a partner with the
highest competence value, but since obtaining information is costly,
it may not be able to do so. Therefore, the Chooser’s goal is to de-
termine the amount of information to be requested from the differ-
ent information sources such that its choice of a partner will maxi-
mize its overall expected utility. The expected utility will take into
consideration the beneﬁt and the associated costs of obtaining the
additional information.
Initially, the agent has very little prior information about any can-
didate. As a result, it needs to obtain additional units of informa-
tion about the potential candidates. A unit of information about a
candidate is the result of one interaction with that candidate. Each
Parameter
Description
C = c1, ..., ck
Set C is a set of k candidates.
pi
The competence value of candidate ci.
TB,ci
The total number of prior information units
(i.e., baseline information) about candidate ci.
SB,ci
The number of successful interactions with
candidate ci among TB,ci.
TP,ci
The total number of additional information units
about ci obtained through personal interaction.
SP,ci
The number of successful interactions with
candidate ci among TP,ci.
γ
The expected number of information units
available about a candidate from gossip.
Tg,ci
The number of gossip requests about ci.
Tg,ci
The number of additional information units about
ci obtained from gossip (Tg,ci · γ on average).
SG,ci
The number of successful interactions reported
about ci among Tg,ci.
ρ
The expected number of information
units available about a candidate from the
reputation system.
Tr,ci
Tr,ci =

1
if reputation system is used
0
otherwise
Tr,ci
The number of additional information units
about ci obtained from the reputation system
SR,ci
The number of successful interactions reported
about ci among Tr,ci (Tr,ci · ρ on average).
Tν,ci
TP,ci + Tg,ci + Tr,ci, the total
number of new information units about ci.
Sν,ci
The number of successful interactions with
candidate ci among Tν,ci.
µ
Average candidate competence.
costP
The direct cost for each unit of information
obtained by personal interaction.
costG
The direct cost of each request for gossip.
costR
The direct cost of obtaining information about
a candidate from the reputation system.
r
The reward obtained from a
successful performance.
Pr(pi = xi)
The posterior function for pi, using the prior
distribution, pi ∼B(αi, βi) and the sample
with TB,ci units and a value of SB,ci.
Table 1: The notation used for the theorems and proofs.
outcome provides one unit of information on the competence of the
candidate. For simplicity, we assume that the outcome of an inter-
action is either a success or a failure.
Table 1 presents the notation we use in describing the IASU
model. The parameters TB,ci and SB,ci refer respectively to the
total amount of prior information units about candidate ci and
the number of successful interactions with candidate ci among
TB,ci. The remaining parameters represent additional information
the Chooser can obtain through personal interaction, gossip or the
reputation system. We describe the model in two stages, the simple
case of only two candidates, and the general case of an arbitrary
number of candidates.
2.1
The two candidate case
In the two candidate case, the Chooser chooses between two can-
didates, c1 and c2. With no loss of generality, we assume that
the Chooser believes c1 is the best choice given the prior infor-

mation (TB,c1 and TB,c2). The information obtaining procedure
is worthwhile only if consequently the agent changes its decision
from alternative c1 to alternative c2. Otherwise, the agent need-
lessly spent its resources. To estimate the optimal amount of in-
formation to acquire, the Chooser must calculate the probability
that this information would cause it to change its decision and se-
lect c2. Additional information may change the Chooser’s decision
if the information is positive about c2 or negative about c1. We
use P_change(c1, c2) to denote the probability that the Chooser
changes its decision from the current best candidate c1, to the sec-
ond candidate c2, due to the acquisition of additional information1.
The amount of information collected for each candidate may not
be identical, and thus the Chooser must decide how it should de-
termine what information to gather and which candidate to select
given that information. For example, suppose the agent has one in-
formation unit about alternative c1 that is “success" and six units
of information about alternative c2, ﬁve of which are “success"
and one is “failure" (TB,c1=1,SB,c1=1 and TB,c2=6,SB,c2=5). Al-
though alternative c2 has had more failures, the agent has more
information about this alternative.
Given this information, how
should the Chooser determine which candidate would make the
best partner?
The heuristic used in this paper to determine the best candidate
given possibly unequal amounts of information is to calculate the
average number of successful interactions among t interactions for
each candidate, and then choose the candidate with the highest
value. If the Chooser has n < t units of information for a spe-
ciﬁc candidate, it will add to its prior information t −n units of
information with an average success rate of µ. We demonstrate late
that the value of t does not matter.
We use E_gain(c1, c2) to denote the expected gain from obtain-
ing Tν,ci (i = 1, 2) units of information about candidates c1 and
c2. We use E_utility(c1, c2) to denote the total expected utility
of the agent from obtaining Tν,ci (i = 1, 2) units of information
about candidates c1 and c2, while taking the costs into considera-
tion. E_utility(c1, c2) is the difference between the expected gain
from obtaining the information , denoted E_gain(c1, c2), and the
cost of obtaining this information.
To determine the optimal allocation of information, we need to
calculate the utility function of the agent from allocation of the in-
formation on candidates c1 and c2, denoted by E_utility(c1, c2).
Since the cost of obtaining information is a denoted value, we have
to estimate the value of E_gain(c1, c2).
In order to calculate E_gain(c1, c2), we ﬁrst need to ﬁnd the value
of P_change(c1, c2), which is the probability that the information
would cause the agent to change its decision from c1 to c2.
Proposition 1 gives the value of P_change(c1, c2), which
Proposition
2
uses
to
provide
the
value
of
the
function
E_gain(c1, c2).
To compute P_change(c1, c2), we need to calculate the number
of successful performances for each candidate in t trials, where t is
equal to the maximum total number of information units of a can-
didate which is the sum of the number of prior information units
TB,ci, and the total number of additional information units Tν,ci
(i.e. max(TB,c1+Tν,c1,TB,c2+Tν,c2)). For the candidate that has
fewer information units ci we add t-(TB,cl+Tν,cl) so that the two
candidates have an equal number of information units. For these
additional units of information, we use µ as the success rate. The
number of successful information units about candidate ci, among
the total additional information units Tν,ci is Sν,ci (for i = 1, 2).
Therefore, the new average for c1 after obtaining Tν,c1 units of in-
1P_change(ci, cj) is used as an abbreviation with reduced param-
eters.
formation, about candidate c1 is:
( SB,c1+Sν,c1+(t-Tν,c1-TB,c1)·µ)/t,
and similarly the new average for c2. The Chooser will change
from candidate c1 to candidate c2, after Tν,c1, Tν,c2 additional
units of information if the following inequality holds:
SB,c2 + Sν,c2 + (t −Tν,c2 −TB,c2) · µ > SB,c1 + Sν,c1 + (t −
Tν,c1 −TB,c1)µ
This inequality is equivalent to:
Sν,c1-Sν,c2 < SB,c2−SB,c1+µ·(TB,c1+Tν,c1−(TB,c2+Tν,c2).
We denote ∆c1,c2 to be
SB,c2−SB,c1+µ · (TB,c1+Tν,c1−(TB,c2+Tν,c2)). ∆c1,c2 repre-
sents the difference between the number of estimated successful
information units of candidate c1 and c2. P_change(c1, c2) is the
probability that Sν,c1-Sν,c2< ∆c1,c2.
The number of successful information units from each knowl-
edge source [personal interactions, gossip and reputation system,
which are respectively SP,ci, SG,ci and SR,ci for i = (1, 2)],
are binomial random variables with probability of pi for success,
(SP,ci∼B(pi, TP,ci) and on average: SG,ci∼B(pi, TG,ci)
and SR,ci∼B(pi, TR,ci)). Since SP,ci, SG,ci and SR,ci are inde-
pendent, the total number of successful information units, Sν,ci is
also a binomial random variable: Sν,ci∼B(pi, Tν,ci), for i = 1, 2.
Proposition 1. The value of P_change(c1, c2) is
Σ
⌈∆c1,c2 ⌉−1
i=−Tν,c2
Σ
Tν,c1
k=i
`Tν,c1
k
´`Tν,c2
k−i
´
pk
1(1 −p1)Tν,c1 −k·
pk−i
2
(1 −p2)Tν,c2 −k+i
where
∆c1,c2=SB,c2−SB,c1+µ · ((TB,c1+Tν,c1)−(TB,c2+Tν,c2))
PROOF. For
any
given
integer
y,
the
probability
of
Sν,c1−Sν,c2=y, is:
P(Sν,c1−Sν,c2=y)=
PTν,c1
i=y P(Sν,c1=i, Sν,c2=i −y)=
PTν,c1
i=y P(Sν,c1=i)· P(Sν,c2=i −y)=
PTν,c1
i=y
`Tν,c1
i
´
pi
1(1 −p1)Tν,c1 −i`Tν,c2
i−y
´
pi−y
2
(1 −p2)Tν,c2 −i+y
We then obtain:
P_change(c1, c2)=P(Sν,c1 −Sν,c2 < ∆c1,c2)
=Σ
⌈∆c1,c2 ⌉−1
y=−Tν,c2
P(Sν,c1 −Sν,c2 = y)
=Σ
⌈∆c1,c2 ⌉−1
y=−Tν,c2
Σ
Tν,c1
i=y (
Tν,c1
i
)pi
1(1 −p1)Tν,c1 −i ·
(
Tν,c2
i−y )pi−y
2
(1 −p2)Tν,c2 −i+y
(We use the notation ⌈∆c1,c2⌉, since ∆c1,c2 may not always have
an integer value)
The function P_change(c1, c2) is expressed in terms of p1 and
p2 which are not known to the Chooser. As a result, the equations
for calculating the reward and the gain from choosing a particu-
lar candidate integrate over all possible values of p1 and p2. In
Proposition 2, we present the gain function E_gain(c1, c2) con-
sidering all the possible values of p1 and p2. The input to function
E_gain(c1, c2) is a speciﬁc allocation of the Tν,ci, (i = 1, 2) units
of information, and the prior units of information (TB,ci, and SB,ci
for i = 1, 2), and the output value is the reward obtained from that
information.
Proposition 2. E_gain(c1, c2) is the expected gain from ob-
taining Tν,c1 units of information about c1 and Tν,c2 units of infor-
mation about c2, denoted
Z 1
0
Z 1
0
P_change(c1, c2)(x2−x1) ·r·N·Pr(p1=x1)Pr(p2 =x2)dx1dx2
where r is the reward obtained from a successful performance and

N is the number of interactions the agent intends to perform with
that candidate.
PROOF. Candidate c1 is currently the prior-best candidate. If the
Chooser does not obtain any additional information, it will choose
c1. The expected reward is
p1 · r · N
The Chooser will change its decision from c1 to c2 with a prob-
ability of P_change(c1, c2). In this case the reward will be
P_change(c1, c2) · p2 · r · N
The agent will continue with c1 with a probability of
1 −P_change(c1, c2). So, the expected reward will be
(1 −P_change(c1, c2)) · p1 · r · N
The expected gain from obtaining Tν,c1 and Tν,c2 additional
units of information is the difference between the reward obtained
with the additional information and the reward obtained without the
additional information, which is:
P_change(c1, c2) · p2 · r · N + (1 −P_change(c1, c2) · p1 · r ·
N −p1 · r · N = P_change · (c1, c2)(p2 −p1) · r · N
To calculate the expected gain we integrate over all possible val-
ues of the parameters p1 and p2, and multiply the equation by their
posterior functions, denoted Pr(pi = xi) which is the probability
for partner ci to have a competence value pi, given the prior belief
of pi being a Beta random variable such as: pi ∼Beta(αi, βi),
and the prior sample which is the TB,ci baseline units of informa-
tion about each possible partner ci and the value of SB,ci.
We calculate the parameters αi, and βi using the estimated val-
ues of the mean and the variance of pi that can be obtained from
our knowledge about the world 2. Given the results of the prior
sample with TB,ci units and that pi ∼Beta(αi, βi), the posterior
function for pi is: Pr(pi = xi) =
Γ(αi+βi+TB,ci )
Γ(αi+si)Γ(βi+TB,ci −si)psi+αi−1
i
(1 −pi)TB,ci −si+βi−1
Finally, we consider the cost of obtaining information. The ex-
pected utility from obtaining TP,ci, TG,ci, TR,ci units of informa-
tion about candidate ci for i = 1, 2, is
E_utility(c1, c2) =
E_gain(c1, c2) −
X
z∈{P,g,r}
costx · (Tx,c1 + Tx,c2)
2.2
The K-candidate case
We denote the probability bestb as the probability that after ob-
taining Tν,ci additional units of information about each ci, candi-
date cb will be superior to all other candidates and therefore will
be chosen by the Chooser. Since the information units are indepen-
dent,
bestb =
Y
∀i∈C,i̸=b
P_change(ci, cb)
(1)
Without loss of generality, assume candidate c1 is currently the
best candidate among these k candidates. The Chooser’s gain after
obtaining any additional units of information consists of the fol-
lowing elements:
2This is due to the fact that in a Beta distribution µi =
αi
αi+βi , σi =
αiβi
(αi+βi)2(αi+βi+1)
• Candidate c1 is currently the prior-best candidate.
If the
Chooser does not obtain any additional information, it will
choose c1. The expected reward will be
p1 · r · N
• The Chooser will change its decision from candidate c1 to
candidate ci with a probability of besti. In this case the ex-
pected reward will be
k
X
i=2
besti · pi · r · N
• The Chooser will continue with candidate c1 with probability
best1 = 1 −Pk
i=2 besti. The expected reward will be
(1 −
k
X
i=2
besti) · p1 · r · N
The expected gain from obtaining additional units of information
is the difference between the reward of the process after obtaining
the additional information, and the reward without obtaining the
additional information which is:
k
X
i=2
besti · (pi −p1) · r · N
To calculate the expected gain we integrate over all possible values
of the parameters pi and pj, as was done in the two candidate
case. Considering all possible values of pi we attain the following
proposition. The proof is immediate from the above explanation.
Proposition 3.
The expected reward from obtaining Tν,ci
additional units of information about each candidate ci is
E_gain(1, .., k) =
Z 1
0
. . .
Z 1
0
k
X
i=2
besti·(xi−x1)·r·N ·
k
Y
i=1
Pr(pi = xi)dx1 . . . dxk
We consider the various costs involved in obtaining
Pk
i=1 Tν,ci units of information and present the agent’s utility.
the expected utility of the Chooser after collecting Tν,ci units of
information for every candidate ci given the direct costs costP ,
costG and costR is,
E_utility(c1, ..., ck) =E_gain(c1, ..., ck)−
X
z∈{P,G,R}
k
X
j=1
(costz · Tz,cj)
The function E_utility(c1, .., ck) estimates the expected util-
ity of the agent from obtaining Tν,c1, ..., Tν,ck units of information
from the different information sources. The function determines
an allocation of information for the different candidates and infor-
mation sources, and ﬁnds the expected reward from that alloca-
tion. As a result, its maxima is actually the information alloca-
tion: T m
ν,c1, ..., T m
ν,ck that maximizes the Chooser’s expected util-
ity, Since the Chooser’s resources are limited an integer M > 0
exists such that M is the maximum number of information units
the Chooser can obtain (Pk
i=1 Tν,ci ≤M). According to this up-
per bound, we are able to ﬁnd the maximum of the utility function
using the Nelder-Mead (Simplex) method [13]. This maxima esti-
mates the expected optimal allocation of the information units that
will maximize the Chooser’s gain. Then, the ﬁnal decision about

the best candidate is made using the information collected accord-
ing to this optimal allocation.
3.
EVALUATION AND
EMPIRICAL RESULTS
We compared the results of IASU with baseline results that took
the best prior candidate without using additional information. We
also compared IASU with the results of the ﬁxed number of exper-
iments model (the FNE model) [19] which decides in advance how
many additional units of information a Chooser should obtain and
divides the units among the candidates in proportion to their qual-
ity, as determined by the baseline results. Since the FNE model
does not differentiate between the additional sources of informa-
tion, we allocated the units of information in such a way that more
information is gathered about the candidate with the highest esti-
mated competence and the least amount of information is gathered
about the candidate with the lowest estimated competence accord-
ing to prior information.
To emphasize the importance of IASU, we describe two domains
in which obtaining information is necessary, the Surrogate Venture
Game and a Restaurant domain. In both domains the Chooser needs
to select a candidate for a long term commitment. In the Surrogate
Venture domain, using personal interactions reduces the number of
the future N interactions, whereas in the restaurant domain per-
sonal interactions do not reduce N.
3.1
Surrogate Venture Domain
In the Surrogate Venture domain [9] there are two types of
agents: investment agents and candidates. The investment agent
plays many games of the Surrogate Venture and every game con-
sists of a sequence of rounds. In each game it chooses a candidate
with whom to make an investment in a single venture. Each can-
didate is assigned a competence at the beginning of the game. A
venture can end in either a success or a failure. The investor agent
offers an investment for the venture and if the venture is success-
ful, the agent receives a reward, otherwise, the venture fails and the
agent loses its investment. After any rewards have been received a
new round begins.
3.1.1
Scoring
The success or failure of a venture is based on the competence
of the candidate. The probability of success of the venture is the
same as the candidate’s competence. Formally, P(success) = pi
where pi is the competence of candidate i. The outcome of a
venture is a Boolean value determined by
outcome =

success
if x ≤P(success)
failure
otherwise
where x is sampled from a uniformly distributed random value in
the range [0, 1). The scoring function may be likened to an em-
ployer utilizing the work of an employee. When the employer as-
signs an employee to a task the employer must pay the employee
(the investment), and the employee may or may not succeed at their
assigned task. The employer receives a reward for an employee
completing a task. If the employee fails, then the venture invest-
ment is lost, and there is no reward.
3.1.2
The Utility Function
We hypothesized that the IASU model would lead to higher re-
wards than the baseline and FNE models because of its ability to
acquire precise amounts of additional information.
In this game any interaction with a candidate ci produces a suc-
cessful venture with a probability of pi. Assuming that from prior
According to
Set A
Set B
Set C
Set D
baseline
74.21
184.08
184.08
184.08
FNE model
84.09
209.18
205.41
206.23
IASU
89.41
219.01
215.77
218.82
Table 2: Results for the 2-candidate case in the surrogate ven-
ture domain depicting the average reward (in points) for each
of the four parameter settings. The higher the better.
personal information candidate c1 is the best choice, then obtain-
ing Tν,ci additional units of information for each candidate ci in
this domain is as follows:
1. Since c1 is currently the best candidate, if the Chooser does
not obtain any additional information it will perform all N interac-
tions using c1. Thus, the mean number of points in this case will
be N · (r · p1 −costP ).
2.
The average reward, from the total number of additional
information units about ci obtained through personal interaction
Pk
l=1 TP,cl, is: Pk
i=1 TP,ci · r · pi.
3. The Chooser will change from candidate c1 to candidate ci
with a probability of besti. In this case, the total reward will be:
Pk
i=2 besti · (N −Pk
l=1 TP,cl) · (r · pi −costP ).
4. The agent will continue with candidate c1 with a probability
of best1 = (1 −Pk
i=2 besti). In this case the total reward will be:
(1 −Pk
i=2 besti) · (N −Pk
l=1 TP,cl) · (r · p1 −costP )
5.
Finally, we need to subtract the cost of asking for gos-
sip (Pk
i=1 Tg,ci times) and the reputation system (Pk
i=1 Tcj,r
times) and the cost of the total number of personal interactions
Pk
i=1 TP,ci, which is:
Pk
i=1 Tg,ci · costG + Pk
i=1 Tcj,r · costR + Pk
i=1 TP,cicostP .
6. The expected utility gain from all the new information units
Pk
i=1 Tν,ci, is the difference between the expected reward using
the additional information and the expected reward obtained using
only the prior information. As a result, the utility function is:
E_utility(c1, .., ck) =
k
X
i=2
besti·(N−
k
X
l=1
TP,cl)·r·(pi−p1)+
k
X
i=1
TP,ci ·r·(pi −p1)−(
k
X
i=1
Tg,ci ·costG +
k
X
i=1
Tcj,r ·costR)
3.1.3
Empirical Results
Simulations were run for the two- and three-candidate cases of
Surrogate Venture. We set the number of prior information units,
TB,ci, to 6; the length of collaboration, N, to 100; the average
competence of the candidates to 0.5; the average number of units
of gossip and reputation information received upon requesting the
information to 10 and 25 respectively; and the cost of personal in-
teraction costP was set to 1. The values that were varied were
the reward for a successful venture, the cost of gossip information
costG, and the cost of reputation information costR. The IASU,
baseline, and FNE models were tested for each value setting.
For the two-candidate case, we randomly clustered eight can-
didates into four pairs.
The competence values for the four
pairs were (0.155,0.539), (0.5781,0.7236), (0.357,0.597), and
(0.3961,0.7302). Each competence value was randomly sampled
from a Beta distribution having parameters Beta(2,2). The remain-
ing parameters were varied across four experiments. We use the
tuple (r, costG, costR) to represent the values of the parameters.
Our aim in choosing the values for these tuples was to investigate
how the changing costs and rewards in the game affect the rewards

Figure 1: Rewards for varying costs of gossip.
of the Chooser. For these tuples we used values
• Set A: (3.0, 0.5, 1.25)
• Set B: (5.0, 0.5, 1.25)
• Set C: (5.0, 3.0, 5.0)
• Set D: (5.0, 0.5, 5.0)
Each of the candidate clusters was run with each of these sets of
parameters.
Table 2 summarizes the average reward the agent obtained by us-
ing the baseline alternative, the FNE model, and by applying IASU.
The agent’s gain was higher (t-test, PV<0.05) when using IASU,
compared with the FNE and the baseline models.
For the three-candidate case, we used four clusters of candidates
and the average competence of the candidates was 0.5. Each one
of the clusters contained three candidates. The competence val-
ues for the four triples were (0.155,0.539,0.578), (0.155, 0.539,
0.724), (0.539, 0.578, 0.724), and (0.357, 0.539, 0.724). As in the
2-candidate case, each of the candidate clusters was run with each
of these varying parameters.
• Set A: (5, 3, 5)
• Set B: (3, 0.5, 1.25)
• Set C: (5, 0.5, 1.25)
Table 3 summarizes the average reward for each experiment. In
most of these cases, the agent’s gain was signiﬁcantly higher (t-
test, PV <0.05 ) when using IASU, compared with the FNE and
the prior best models.
In a second round of experiments we varied the cost of gossip
while ﬁxing all other parameters. The goal of this set of experi-
ments was to determine how the cost of gossip affects the average
reward of the Chooser. The number of prior information units was
set to 5, and the Chooser received one unit of information for each
gossip request. This was done so that one gossip request and one
personal interaction would yield the same amount of information.
As in the previous experiment, we set the length of collaboration,
N, to 100; the average competence of the candidates to 0.5; and the
cost of personal interaction costP was set to 1. Six candidates were
clustered into three pairs, with the competence values for the three
pairs set as (0.538, 0.408), (0.823, 0.225), and (0.646, 0.285). The
models were run with various initial successes of prior information
units, dependent on the worker agents’ competence values, and for
each input value the model was run 1000 times.
Figure 1 illustrates the effect of the cost of gossip on the average
reward of the IASU model. The baseline model is not affected by
the cost of gossip, because it does not take gossip information into
According to
set A
set B
set C
baseline
173.82
65.25
175.42
FNE model
198.6
87.78
214.98
IASU
210.86
96.77
228.668
Table 3: The three-candidate case in the surrogate venture
domain-the average reward for each parameter setting, accord-
ing to the different approaches. The higher the better.
account. The FNE model acquires a ﬁxed amount of personal and
gossip information, meaning that as the cost of gossip increases,
the average reward for the FNE model will decrease. As expected,
the average reward obtained by the IASU model was signiﬁcantly
higher than the FNE or baseline model (t-test, PV<0.05). The
Chooser requested a lot of gossip information when the cost of gos-
sip was low, in turn helping to increase the Chooser’s average re-
ward. The average reward decreased as the cost of gossip increased
because the Chooser sought less gossip information and the cost
of the gossip information that it did seek reduced the reward. The
average reward of the IASU model remains greater than that of the
FNE model even when the cost of gossip is high. This difference is
in part due to IASU’s ability to dynamically determine how much
information (personal or gossip) to obtain, whereas the FNE model
seeks ﬁxed amount of information.
3.2
Restaurant Domain
To model the restaurant domain we denote a set of k possible
restaurants: r1...rk; each restaurant ri has an unknown parameter
pi which is its satisfaction rate; the agent employer has to pay the
subcontractor for N meals in advance. According to the agent’s
prior knowledge, r1 is currently the best choice. This models a
minimum problem, where the agent has to choose the best restau-
rant at a minimal cost. We evaluate the utility function as follows:
• Candidate r1 is currently the best candidate, so the agent
does not obtain additional knowledge, r1 will be chosen.
Since the agent pays for N meals in advance, if an employee
is not satisﬁed with the subcontractor, the agent has to pay
him twice; se denote sub for the unused meal and exp for
the meal the employee used. In this case the expected cost
will be:
N · sub + (1 −p1) · N · exp
because 1 −p1 is the unsatisfactory rate which estimates the
percentage of employees that will choose another restaurant.
• The employer will change the decision from restaurant r1 to
restaurant ri, with a probability besti. If the agent decides to
get information, the cost will be:
k
X
i=2
besti · (N · sub + (1 −pi) · N · exp)+
(1 −
k
X
i=2
besti) · (N · sub + (1 −p1) · N · exp) =
k
X
i=2
besti·N ·exp·(p1−pi)+N ·sub+(1−p1)·N ·exp
• The utility of obtaining additional units of information is the
difference between the utility received from choosing c1 and

N=200
N=500
N=1000
baseline
1793.88
4484.71
8969.42
FNE model
1653.35
4106.06
8193.93
IASU
1606.55
4014.79
8020.63
Table 4: The average costs (in dollars) for each value of N ac-
cording to the different approaches. (Two-candidate case in the
restaurant domain.) The lower the better.
choosing a candidate with a higher competence than c1, i.e.,
k
X
i=2
besti · N · exp · (p1 −pi)
• The utility function is deﬁned as
E_utility(r1, ..., rk) =
Z 1
0
...
Z 1
0
k
X
i=2
besti · N · exp · (p1 −pi)dp1...dpk
+
k
X
i=1
TP,cicostP +
k
X
i=1
Tg,cicostG +
k
X
i=1
Tr,cjcostR
3.2.1
Empirical Results
For the restaurant domain we, used a database derived from a sur-
vey conducted on employees at several high-tech companies. The
employees were asked to judge restaurants they had visited recently
and to rate their satisfaction level after each visit. Each impression
of an employee from one visit at a speciﬁc restaurant contributed
a unit of information about that restaurant. This data yields both
a gossip database and a personal interaction database. In addition,
any person who visited a speciﬁc restaurant is a reputable source
of gossip. We refer to the information obtained from one of the
employees as the personal experience of the Chooser. The repu-
tation system for the restaurants, was taken from on-line websites
www.2eat.co.il, and www.rest.co.il. We set the cost of personal in-
teraction, costP at $1, the cost of obtaining information through
gossip, costG at $2, and the cost of obtaining information through
the reputation system, costR at $3. We set µ = 0.5; sub, the cost
of a meal according to the agreement with the subcontractor at $6;
and exp, the cost of a meal in another restaurant at $10.
We investigated four pairs of restaurants and ran experiments for
each of them, varying the value of N, the number of meals the agent
intends to pay for in advance, between 200, 500, and 1000. We in-
vestigated three groups, each containing three different restaurants.
For this three-candidate case we set N to 200. We compared the
results that were obtained with the results of the baseline model and
the FNE model.
The IASU succeeded in reducing the agent’s expenses.
The
agent’s costs in the two candidate case were statistically signiﬁ-
cantly lower when using the IASU in contrast to the baseline model
(t-test, PV<0.005 for all the values of N) and to the FNE model(t-
test, PV=0.01 for N=200, PV=0.05 for N=500 and PV=0.06 for
N=1000). Table 4 summarizes the average costs of the agent ac-
cording to IASU, the baseline model and the FNE model for the
different values of N according to the two-candidate case. In the
three-candidate case the IASU improved the costs incurred by the
agent in all three experiments.
Table 5 describes the costs in-
curred by the agent according to the baseline, the FNE model and
the IASU. The results are statistically signiﬁcant in comparison to
the two other models.(t-test, PV=0.004 compared to the baseline
model, PV=0.02 compared to the FNE model.)
exp. 1
exp. 2
exp. 3
baseline
1699.88
1991.29
1664.44
FNE model
1438.24
1706.84
1714.34
IASU
1331.86
1680.73
1507.82
Table 5: The average costs (in dollars) for each group in the
three-candidate case of the restaurant domain. The lower the
better.
4.
RELATED WORK
Extensive research has been conducted on the problem of choos-
ing an alternative among k available candidates. This research has
determined how to allocate personal interaction information among
different alternatives in order to maximize the expected gain from
the choice.
Research on the Max K-armed bandit problem [3, 18] which is
concerned with ﬁnding the trials’ allocation that maximizes the ex-
pected maximum payoff obtained from one alternative.
Azoulay-Schwartz and Kraus [2] constructed a formal statistical
model to ﬁnd the optimal additional units of information to reveal
the best alternative. Talman et al. [19] generalized the model of
Azoulay-Schwartz & Kraus [2] to suit domains that involve choos-
ing between heuristics or strategies. The two-candidate model was
adapted to these domains and experimental results were presented.
For the general k-candidate case, k > 2, the paper presented the
ﬁxed number of experiments model (FNE model), which decides in
advance how many additional units of information the agent should
obtain, denoted by N and divides it between the candidates in pro-
portion to their quality according to the agent’s baseline knowledge
(initial units of information). Experimental results show that the
gain from utilizing this approach was very small. In contrast to the
FNE model, the EURICA model [16] presents a statistical model
for ﬁnding the best heuristic among several candidates using infor-
mation from personal interactions.
Cicirello & Smith [3] repeatedly ran trials on different candidate
agents, each time trying to improve the current maximum reward.
The same approach can be found in heuristics-related works, such
as Selman et al. [17] who conducted a large number of experiments
in order to identify the best heuristic.
Grass & Zilberstein [7] developed a decision theoretic approach
that uses an explicit representation of the user’s decision model to
plan and execute information gathering actions. Their system is
based on information sources that return perfect information about
the query.
Teacy et al. and Huynh et al. [20, 11] provide quantitative re-
sults with respect to reputation systems that vary the amount of
interaction between agents in the system. The IASU differs from
these models in that the IASU does not have a population of agents
choosing to interact and create reputation information.
Instead,
only one agent has makes decisions, i.e. the interaction is one-
sided.
Huynh, Maes, Pujol, Teacy [11, 22, 14, 20] use agents that col-
lect reputation information from many individual agents, rather
than a central reputation authority. These papers do not address the
cost of continuously asking many agents for reputation information
about multiple agents. The current research extends Hendrix’s [10]
use of cost and tackles this problem by charging a deﬁned cost for
the reputation information.
A variety of ways of combining personal information and repu-
tation information have been introduced by Ramchurn et al. [15]
and Teacy et al. [20], including a model named TRAVOS that uses
beta distributions to help model other agents. Neal and Hinton [12]

use the EM algorithm to estimate values of unobserved variables.
In particular, estimating values when sample data is sparse is a nec-
essary component of estimating another agent’s competency after
only a few interactions.
Fullam and Barber [5] learned how to appropriately mix previ-
ously acquired information from personal interaction and gossip
sources. Our research learns how to seek appropriate amounts of
such information, not how to combine them.
Dearden et al. [4] determined the value of information when
choosing actions (physical actions in the environment) based on the
need to explore vs. exploit. We add to this action space information
seeking options (gossip and reputation information). Dearden et al.
learned an optimal policy over many iterations while we focused
on partner selection in only one iteration. These differences in ob-
jectives lead to signiﬁcant differences in models and formalization.
5.
CONCLUSIONS
This paper presents the Information-Acquisition Source Utility
model (IASU), which is a statistical model which aims to improve
the automated decision-making process of choosing the best can-
didate for a partner by incorporating gossip and reputation infor-
mation. The IASU model computes the amount of additional in-
formation the agent should obtain about each candidate and from
which sources (personal interaction, gossip and reputation system).
It takes into account the cost associated in acquiring such informa-
tion. IASU is a generalization of a model developed by Azoulay-
Schwartz and Kraus [2] and implemented by Reches,Talman and
Krause [16], which considered the problem of choosing between k
candidates when an automated agent has a small amount of prior
knowledge about each candidate. We evaluated the IASU in the
Venture Game domain and the Restaurants domain, both of which
require the Chooser to determine how many units of information to
obtain about each candidate and through which information source.
These experiments determine that the IASU model is signiﬁcantly
better than FNE.
6.
ACKNOWLEDGMENTS
The research reported in this paper was supported in part by Na-
tional Science Foundation grants IIS-0705406 and CNS-0453923
to Harvard University and ISO-705587 to UMIACS, University of
Marylan with which Sarit Kraus is afﬁliated. Any opinions, ﬁnd-
ings, and conclusions or recommendations expressed in this mate-
rial are those of the authors and do not necessarily reﬂect the views
of the National Science Foundation. We thank Meir Kalech for
helpful comments on framing the experiments and earlier drafts of
the paper.
7.
REFERENCES
[1] M. Abramowitz and I. A. Stegun. Handbook of
Mathematical Functions with Formulas, Graphs, and
Mathematical Tables. Dover, New York, 1964.
[2] R. Azoulay-Schwartz and S. Kraus. Acquiring an optimal
amount of information for choosing from alternatives. In CIA
VI, pages 123–137, 2002.
[3] V. Cicirello and S. Smith. The max k-armed bandit: A new
model for exploration applied to search heuristic selection. In
AAAI-05, July 2005. Best Paper Award.
[4] R. Dearden, N. Friedman, and S. J. Russell. Bayesian
q-learning. In AAAI-98, pages 761–768, 1998.
[5] K. Fullam and S. Barber. Dynamically learning sources of
trust information: Experience vs. reputation. Autonomous
Agents and Multi-Agent Systems, pages 1055–1062, 2007.
[6] K. K. Fullam and K. S. Barber. Learning trust strategies in
reputation exchange networks. In AAMAS ’06, pages
1241–1248, New York, NY, USA, 2006. ACM Press.
[7] J. Grass and S. Zilberstein. A value-driven system for
autonomous information gathering. Journal of Intelligent
Information Systems, 14:5–27, 2000.
[8] R. Gupta and A. K. Somani. Reputation management
framework and its use as currency in large-scale peer-to-peer
networks. In P2P ’04: Proceedings of the Fourth
International Conference on Peer-to-Peer Computing
(P2P’04), pages 124–132, Washington, DC, USA, 2004.
IEEE Computer Society.
[9] P. Hendrix and B. J. Grosz. Reputation in the joint venture
game. In AAMAS ’07, New York, NY, USA, 2007. ACM
Press.
[10] P. Hendrix and B. J. Grosz. Reputation in the venture games.
In AAAI-07, 2007.
[11] T. D. Huynh, N. Jennings, and N. Shadbolt. Fire: An
integrated trust and reputation model for open multi-agent
systems. Proceeding of 16th European Conference on
Artiﬁcial Intelligence, pages 18–22, 2004.
[12] R. Neal and G. Hinton. A view of the em algorithm that
justiﬁes incremental, sparse, and other variants. In M. I.
Jordan, editor, Learning in Graphical Models. Kluwer, 1998.
[13] J. Nelder and R. Mead. A simplex method for function
minimization. The Computer Journal, 7:308–313, 1964.
[14] M. Pujol, R. Sanguesa, and J. Delgado. Extracting reputation
in multi agent systems by means of social network topology.
Proceedings of the First International Joint Conference on
Autonomous Agents and Multiagent Ssytems: Part 1, pages
467–474, 2002.
[15] S. D. Ramchurn, C. Sierra, L. Godo, and N. Jennings. A
computational trust model for multi-agent interactions based
on conﬁdence and reputation. Proceedings of 6th
International Workshop of Deception, Fraud and Trust in
Agent Societies, pages 69–75, 2003.
[16] S. Reches, S. Talman, and S. Kraus. A statistical
decision-making model for choosing between multiple
alternatives. In AAMAS ’07, New York, NY, USA, 2007.
ACM Press.
[17] B. Selman, H. A. Kautz, and B. Cohen. Local search
strategies for satisﬁability testing. In the 2nd DIMACS
Challenge on Cliques, Coloring and Satis., 1993.
[18] M. J. Streeter and S. Smith. An asymptotically optimal
algorithm for the max k-armed bandit problem. In AAAI-06,
July 2006.
[19] S. Talman, R. Toester, and S. Kraus. Choosing between
heuristics and strategies: an enhanced model for
decision-making. In Proceedings of the International Joint
Conference of Artiﬁcial Intelligence, pages 324–330, 2005.
[20] W. Teacy, J. Patel, N. Jennings, and M. Luck. Coping with
inaccurate reputation sources: Experimental analysis of a
probabilistic trust model. AAMAS ’05, pages 997–1004,
2005.
[21] M. M. Vanzin and K. S. Barber. Decentralized partner ﬁnding
in multi-agent systems. In Coordination of Large-Scale
Multiagent Systems, pages 75–98. Springer, March 2006.
[22] G. Zacharia and P. Maes. Trust through reputation
mechansims. Applied Artiﬁcial Intelligence, 14:881–907,
2000.

