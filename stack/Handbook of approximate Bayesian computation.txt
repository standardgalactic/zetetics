
Handbook of 
Approximate Bayesian 
Computation 

Chapman & Hall/CRC 
Handbooks of Modern Statistical Methods 
Series Editor
Garrett Fitzmaurice, Department of Biostatistic, Harvard School of Public Health,  
 Boston, MA, U.S.A.
The objective of the series is to provide high-quality volumes covering the state-of-the-art in the theory 
and applications of statistical methodology. The books in the series are thoroughly edited and present 
comprehensive, coherent, and unified summaries of specific methodological topics from statistics. 
The chapters are written by the leading researchers in the field, and present a good balance of theory 
and application through a synthesis of the key methodological developments and examples and case 
studies using real data.
Longitudinal Data Analysis
Edited by Garrett Fitzmaurice, Marie Davidian, Geert Verbeke, and Geert Molenberghs
Handbook of Spatial Statistics
Edited by Alan E. Gelfand, Peter J. Diggle, Montserrat Fuentes, and Peter Guttorp
Handbook of Markov Chain Monte Carlo 
Edited by Steve Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng 
Handbook of Survival Analysis 
Edited by John P. Klein, Hans C. van Houwelingen, Joseph G. Ibrahim, and Thomas H. Scheike
Handbook of Mixed Membership Models and Their Applications 
Edited by Edoardo M. Airoldi, David M. Blei, Elena A. Erosheva, and Stephen E. Fienberg 
Handbook of Missing Data Methodology
Edited by Geert Molenberghs, Garrett Fitzmaurice, Michael G. Kenward, Anastasios Tsiatis, and Geert 
Verbeke 
Handbook of Design and Analysis of Experiments
Edited by Angela Dean, Max Morris, John Stufken, and Derek Bingham 
Handbook of Cluster Analysis
Edited by Christian Hennig, Marina Meila, Fionn Murtagh, and Roberto Rocci
Handbook of Discrete-Valued Time Series
Edited by Richard A. Davis, Scott H. Holan, Robert Lund, and Nalini Ravishanker
Handbook of Big Data 
Edited by Peter Bühlmann, Petros Drineas, Michael Kane, and Mark van der Laan
Handbook of Spatial Epidemiology 
Edited by Andrew B. Lawson, Sudipto Banerjee, Robert P. Haining, and María Dolores Ugarte
Handbook of Neuroimaging Data Analysis
Edited by Hernando Ombao, Martin Lindquist, Wesley Thompson, and John Aston 
Handbook of Statistical Methods and Analyses in Sports
Edited by Jim Albert, Mark E. Glickman, Tim B. Swartz, Ruud H. Koning
Handbook of Methods for Designing, Monitoring, and Analyzing Dose-Finding Trials
Edited by John O’Quigley, Alexia Iasonos, Björn Bornkamp
Handbook of Quantile Regression 
Edited by Roger Koenker, Victor Chernozhukov, Xuming He, and Limin Peng 
Handbook of Environmental and Ecological Statistics 
Edited by Alan E. Gelfand, Montserrat Fuentes, Jennifer A. Hoeting, Richard Lyttleton Smith
For more information about this series, please visit: https://www.crcpress.com/go/handbooks

Handbook of 
Approximate Bayesian 
Computation
Edited by
S. A. Sisson
Y. Fan
M. A. Beaumont

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2019 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed on acid-free paper
International Standard Book Number-13: 978-1-4398-8150-7 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts 
have been made to publish reliable data and information, but the author and publisher cannot assume 
responsibility for the validity of all materials or the consequences of their use. The authors and publishers 
have attempted to trace the copyright holders of all material reproduced in this publication and apologize 
to copyright holders if permission to publish in this form has not been obtained. If any copyright material 
has not been acknowledged please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, 
transmitted, or utilized in any form by any electronic, mechanical, or other means, now known or 
hereafter invented, including photocopying, microfilming, and recording, or in any information storage 
or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.
com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood 
Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and 
registration for a variety of users. For organizations that have been granted a photocopy license by the 
CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are 
used only for identification and explanation without intent to infringe.
Library of Congress Cataloging‑in‑Publication Data
Names: Sisson, S. A. (Scott A), editor. | Fan, Y. (Yanan), editor. | 
Beaumont, M. A. (Mark A.), editor.
Title: Handbook of approximate Bayesian computation / edited by S.A. Sisson, 
Y. Fan, M.A. Beaumont.
Description: Boca Raton, Florida : CRC Press, [2019] | Includes 
bibliographical references and index.
Identifiers: LCCN 2018010970 | ISBN 9781439881507 (hardback : alk. paper) | 
ISBN 9781315117195 (e-book) | ISBN 9781439881514 (web pdf) | ISBN 
9781351643467 (epub) | ISBN 9781351633963 (mobi/kindle)
Subjects: LCSH: Bayesian statistical decision theory. | Mathematical analysis.
Classification: LCC QA279.5 .H36 2019 | DDC 519.5/42--dc 3
LC record available at https://lccn.loc.gov/2018010970
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

Contents
Preface
ix
Editors
xi
Contributors
xiii
I
Methods
1
1
Overview of ABC
3
S. A. Sisson, Y. Fan, and M. A. Beaumont
2
On the History of ABC
55
Simon Tavar´e
3
Regression Approaches for ABC
71
Michael G.B. Blum
4
ABC Samplers
87
S. A. Sisson and Y. Fan
5
Summary Statistics
125
Dennis Prangle
6
Likelihood-Free Model Choice
153
Jean-Michel Marin, Pierre Pudlo, Arnaud Estoup,
and Christian Robert
7
ABC and Indirect Inference
179
Christopher C. Drovandi
8
High-Dimensional ABC
211
David J. Nott, Victor M.-H. Ong, Y. Fan, and S. A. Sisson
9
Theoretical and Methodological Aspects of Markov
Chain Monte Carlo Computations with Noisy
Likelihoods
243
Christophe Andrieu, Anthony Lee, and Matti Vihola
v

vi
Contents
10 Asymptotics of ABC
269
Paul Fearnhead
11 Informed Choices: How to Calibrate ABC
with Hypothesis Testing
289
Oliver Ratmann, Anton Camacho, Sen Hu, and Caroline Colijn
12 Approximating the Likelihood in ABC
321
Christopher C. Drovandi, Clara Grazian, Kerrie Mengersen,
and Christian Robert
13 A Guide to General-Purpose ABC Software
369
Athanasios Kousathanas, Pablo Duchen, and Daniel Wegmann
14 Divide and Conquer in ABC: Expectation-Propagation
Algorithms for Likelihood-Free Inference
415
Simon Barthelm´e, Nicolas Chopin, and Vincent Cottet
II
Applications
435
15 Sequential Monte Carlo-ABC Methods for Estimation
of Stochastic Simulation Models of the Limit Order
Book
437
Gareth W. Peters, Efstathios Panayi, and Francois Septier
16 Inferences on the Acquisition of Multi-Drug
Resistance in Mycobacterium Tuberculosis Using
Molecular Epidemiological Data
481
Guilherme S. Rodrigues, Andrew R. Francis, S. A. Sisson,
and Mark M. Tanaka
17 ABC in Systems Biology
513
Juliane Liepe and Michael P.H. Stumpf
18 Application of ABC to Infer the Genetic History
of Pygmy Hunter-Gatherer Populations from Western
Central Africa
541
Arnaud Estoup, Paul Verdu, Jean-Michel Marin,
Christian Robert, Alex Dehne-Garcia, Jean-Marie Cornuet,
and Pierre Pudlo
19 ABC for Climate: Dealing with Expensive Simulators
569
Philip B. Holden, Neil R. Edwards, James Hensman,
and Richard D. Wilkinson

Contents
vii
20 ABC in Ecological Modelling
597
Matteo Fasiolo and Simon N. Wood
21 ABC in Nuclear Imaging
623
Y. Fan, Steven R. Meikle, Georgios I. Angelis,
and Arkadiusz Sitek
Index
649


Preface
Approximate Bayesian computation (ABC) is now recognised as the ﬁrst
member of the class of ‘likelihood-free’ methods, which have been instrumental
in driving research in Monte Carlo methods over the past decade. ABC origi-
nated from the need to address challenging inferential problems in population
genetics, where the complexity of a model meant that the associated likeli-
hood function was computationally intractable and could not be evaluated
numerically in any practical amount of time. At its heart, ABC is a very sim-
ple method: numerical evaluation of the likelihood function is replaced with
an assessment of how likely it is the model could have produced the observed
data, based on simulating pseudo-data from the model and comparing it to
the observed data.
The idea is remarkably simple, but this simplicity also means that ABC
methods are highly accessible as analysis tools in a manner similar to the way
in which the accessibility of the Metropolis–Hastings algorithm was respon-
sible for the propagation of Bayesian inferential methods in the 1990s. The
last ten years have seen a surge in interest from the statistical community,
as researchers have realised how powerful ABC can be as a computational
technique. Major advances have been made in terms of computation and the-
ory. In addition, ABC methods have been extensively applied to wide ranging
and diverse applications in many disciplines. With such rapid developments,
it seemed to us that now was a good time to put together an overview of ABC
research and its applications. This will be the ﬁrst book that synthesises the
most important aspects of ABC research within a single volume.
This handbook is intended to be a comprehensive reference for both devel-
opers and users of ABC methodology. While ABC methods are still relatively
new, in this Handbook, we have attempted to include a substantial amount
of the fundamental ideas so that the material covered will be relevant for
some time. Graduate students and researchers new to ABC wishing to become
acquainted with the ﬁeld will be able to ﬁnd instruction on the basic theory
and algorithms. Many chapters are written in tutorial style with detailed
illustrations and examples. Part I ﬁrst provides an overview of the basic
ABC method and then some history on it’s developmental origins. This is fol-
lowed by detailed expositions on various aspects of ABC techniques, including
algorithm development, construction and choice of summary statistics, model
choice, asymptotic theory, and variants and extensions of ABC algorithms
that deal with particular modelling situations. A purpose-written chapter on
software available for implementing ABC methods is also provided.
ix

x
Preface
For those who are interested in seeing how ABC is implemented in prac-
tice, Part II contains a number of applied chapters written by discipline ex-
perts, detailing the use of ABC in particular discipline applications. These
are intended to be exemplar ABC implementations in a range of ﬁelds, with
topics including ﬁnancial market dynamics, multi-drug resistance, systems bi-
ology, population genetics, climate simulators, dynamic ecological models, and
medical imaging.
When planning this book, we soon realised that no single source can give
a truly comprehensive overview of ABC research and application—there is
just too much of it and its development is moving too fast. Instead, the edi-
torial goal was to obtain high quality contributions that may stand the test
of time. We have enlisted a group of contributors who are at the very fore-
front of ABC research and application. To ensure a uniformly high quality, all
handbook contributions (including those written by members of the editorial
panel) were submitted to a rigorous peer review process and many underwent
several revisions. We thank the anonymous referees for their thoughtful and
focused reviews. We also thank the editorial team from Chapman & Hall/CRC
Press for their advice and patience throughout the production process.
We are proud to be able to bring together this handbook on an exciting and
novel statistical technique that has greatly expanded the modelling horizons
of applied research across the board. We hope that ABC will have as much
impact in the next ten years as it has had in the previous decade.
S. A. Sisson
Y. Fan
M. A. Beaumont

Editors
S. A. Sisson is a professor of statistics at the University of New South Wales,
Sydney. He is a past president of the Statistical Society of Australia and a
deputy director of the Australian Research Centre of Excellence in Mathemat-
ical and Statistical Frontiers. He has received a 2017 ARC Future Fellowship
and the 2011 Moran Medal from the Australian Academy of Science. Scott
is interested in computational statistics and methods, particularly in com-
putationally challenging modelling scenarios, extreme value theory, and the
application of Bayesian statistics to problems in a wide range of disciplines.
Y. Fan is a senior lecturer in statistics at the University of New South Wales,
Sydney. She obtained her PhD in statistics, on Markov chain Monte Carlo
methods, from the University of Bristol. Currently, her research interests in-
clude development of computational statistical methods, Bayesian modelling,
image analysis, and climate modelling.
M. A. Beaumont is a professor of statistics at the University of Bristol. His
research interests focus mainly on problems in population genetics and the
statistical methodology associated with them.
xi


Contributors
Christophe Andrieu
School of Mathematics
University of Bristol
Bristol, United Kingdom
Georgios I. Angelis
Faculty of Health Sciences
The University of Sydney
Sydney, Australia
Simon Barthelm´e
CNRS
Gipsa-lab
Grenoble INP
Grenoble, France
M. A. Beaumont
School of Mathematics
University of Bristol
Bristol, United Kingdom
Michael G.B. Blum
Laboratoire TIMC-IMAG, UMR 5525
Universit´e Grenoble Alpes, CNRS
Grenoble, France
Anton Camacho
Centre for the Mathematical
Modelling of Infectious Diseases
London School of Hygiene and
Tropical Medicine
London, United Kingdom
Nicolas Chopin
ENSAE-CREST
Paris, France
Caroline Colijn
Department of Mathematics
Imperial College London
London, United Kingdom
Jean-Marie Cornuet
CBGP, INRA, CIRAD, IRD,
Montpellier SupAgro
University of Montpellier
Montpellier, France
Vincent Cottet
ENSAE-CREST
Paris, France
Alex Dehne-Garcia
CBGP, INRA, CIRAD, IRD,
Montpellier SupAgro
University of Montpellier
Montpellier, France
Christopher C. Drovandi
School of Mathematical Sciences
Queensland University of Technology
Brisbane, Australia
Pablo Duchen
Department of Biology
University of Fribourg
Fribourg, Switzerland
Neil R. Edwards
School of Environment, Earth
and Ecosystem Sciences
Open University
Milton Keynes, United Kingdom
xiii

xiv
Contributors
Arnaud Estoup
CBGP, INRA, CIRAD, IRD,
Montpellier SupAgro
University of Montpellier
Montpellier, France
Y. Fan
School of Mathematics and Statistics
University of New South Wales
Sydney, Australia
Matteo Fasiolo
School of Mathematics
University of Bristol
Bristol, United Kingdom
Paul Fearnhead
Department of Mathematics
and Statistics
Lancaster University
Lancaster, United Kingdom
Andrew R. Francis
Centre for Research in Mathematics
Western Sydney University
Sydney, Australia
Clara Grazian
Nuﬃeld Department of Medicine
University of Oxford
Oxford, United Kingdom
James Hensman
PROWLER.io
Cambridge, United Kingdom
Philip B. Holden
School of Environment, Earth
and Ecosystem Sciences
Open University
Milton Keynes, United Kingdom
Sen Hu
School of Mathematics and Statistics
University College Dublin
Dublin, Ireland
Athanasios Kousathanas
Department of Biology
University of Fribourg
Fribourg, Switzerland
Anthony Lee
School of Mathematics
University of Bristol
Bristol, United Kingdom
Juliane Liepe
Quantitative and Systems Biology
Max-Planck-Institute for Biophysical
Chemistry
G¨ottingen, Germany
Jean-Michel Marin
IMAG
University of Montpellier, CNRS
Montpellier, France
Steven R. Meikle
Faculty of Health Sciences and Brain
and Mind Centre
The University of Sydney
Sydney, Australia
Kerrie Mengersen
School of Mathematical Sciences
Queensland University of Technology
Brisbane, Australia
David J. Nott
Department of Statistics and Applied
Probability
National University of Singapore
Singapore
Victor M.-H. Ong
Department of Statistics and Applied
Probability
National University of Singapore
Singapore

Contributors
xv
Efstathios Panayi
Department of Actuarial
Mathematics and Statistics
Heriot-Watt University
Edinburgh, United Kingdom
Gareth W. Peters
Department of Actuarial
Mathematics and Statistics
Heriot-Watt University
Edinburgh, United Kingdom
Dennis Prangle
School of Mathematics Statistics
and Physics
Newcastle University
Newcastle upon Tyne
United Kingdom
Pierre Pudlo
Institut de Math´ematiques de
Marseille
Aix-Marseille Universit´e
Marseille, France
Oliver Ratmann
Department of Mathematics
Imperial College London
London, United Kingdom
Christian Robert
CEREMADE
Universit´e Paris Dauphine
Paris, France
Guilherme S. Rodrigues
CAPES Foundation
Ministry of Education of Brazil
Bras´ılia, Brazil
Francois Septier
Institute Mines-Telecom Lille
CRIStAL UMR CNRS 9189
Lille, France
S. A. Sisson
School of Mathematics and Statistics
University of New South Wales
Sydney, Australia
Arkadiusz Sitek
Radiology Department
Massachusetts General Hospital
and Harvard Medical School
Boston, Massachusetts
Michael P.H. Stumpf
Melbourne Integrative Genomics
School of BioSciences and School of
Mathematics and Statistics
University of Melbourne
Parkville, Australia
Mark M. Tanaka
School of Biotechnology and
Biological Sciences
University of New South Wales
Sydney, Australia
Simon Tavar´e
Department of Applied Mathematics
and Theoretical Physics
University of Cambridge
Cambridge, United Kingdom
Paul Verdu
UMR 7206, Ecoanthropology
and Ethnobiology
CNRS-MNHN-Universit´e Paris
Diderot-Sorbonne Paris Cit´e
Paris, France
Matti Vihola
Department of Mathematics and
Statistics
University of Jyv¨askyl¨a
Jyv¨askyl¨a, Finland

xvi
Contributors
Daniel Wegmann
Department of Biology
University of Fribourg
Fribourg, Switzerland
Richard D. Wilkinson
School of Mathematics and Statistics
University of Sheﬃeld
Sheﬃeld, United Kingdom
Simon N. Wood
School of Mathematics
University of Bristol
Bristol, United Kingdom

Part I
Methods


1
Overview of ABC
S. A. Sisson, Y. Fan, and M. A. Beaumont
CONTENTS
1.1
Introduction ......................................................
3
1.2
Likelihood-Free Intuition .........................................
6
1.3
A Practical Illustration: Stereological Extremes .................
7
1.3.1
Background and model ..................................
8
1.3.2
Analysis .................................................
8
1.4
A g-and-k Distribution Analysis .................................
11
1.5
Likelihood-Free Methods or ABC? ..............................
14
1.6
The Approximate Posterior Distribution ........................
15
1.6.1
Simple examples .........................................
19
1.7
The Use of Summary Statistics ..................................
23
1.7.1
Summary statistic basics ................................
23
1.7.2
Some practical issues with summary statistics ..........
28
1.8
An ABC Analysis in Population Genetics .......................
34
1.9
Levels of Approximation in ABC ................................
41
1.10
Interpretations of ABC ..........................................
43
1.11
Further Reading ..................................................
44
1.12
Conclusion ........................................................
45
Acknowledgements .......................................................
45
References
...............................................................
46
1.1
Introduction
In
Bayesian
inference,
complete
knowledge
about
a
vector
of
model
parameters, θ ∈Θ, obtained by ﬁtting a model M, is contained in the poste-
rior distribution. Here, prior beliefs about the model parameters, as expressed
3

4
Handbook of Approximate Bayesian Computation
through the prior distribution, π(θ), are updated by observing data yobs ∈Y
through the likelihood function p(yobs|θ) of the model. Using Bayes’ theorem,
the resulting posterior distribution:
π(θ|yobs) =
p(yobs|θ)π(θ)

Θ p(yobs|θ)π(θ)dθ,
contains all necessary information required for analysis of the model, includ-
ing model checking and validation, predictive inference, and decision making.
Typically, the complexity of the model and/or prior means that the posterior
distribution, π(θ|yobs), is not available in closed form, and so numerical meth-
ods are needed to proceed with the inference. A common approach makes use
of Monte Carlo integration to enumerate the necessary integrals. This relies on
the ability to draw samples θ(1), θ(2), . . . , θ(N) ∼π(θ|yobs) from the posterior
distribution so that a ﬁnite sample approximation to the posterior is given by
the empirical measure:
π(θ|yobs) ≈1
N
N

i=1
δθ(i)(θ),
where δZ(z) denotes the Dirac measure, deﬁned as δZ(z) = 1 if z ∈Z and
δZ(z) = 0 otherwise. As the size of the sample from the posterior gets large,
then the ﬁnite sample approximation better approximates the true posterior so
that limN→∞1
N
N
i=1 δθ(i)(θ) →π(θ|yobs), by the law of large numbers. As a
result, the expectation of a function a(θ) under π(θ|yobs) can be estimated as:
Eπ[a(θ)] =

Θ
a(θ)π(θ|yobs)dθ
≈

Θ
a(θ) 1
N
N

i=1
δθ(i)(θ)dθ = 1
N
N

i=1
a(θ(i)).
There are a number of popular algorithms available for generating samples
from posterior distributions, such as importance sampling, Markov chain
Monte Carlo (MCMC) and sequential Monte Carlo (SMC) (Chen et al. 2000;
Doucet et al. 2001; Del Moral et al. 2006; Brooks et al. 2011).
Inherent in such Monte Carlo algorithms is the need to numerically
evaluate the posterior distribution, π(θ|yobs), up to a normalisation con-
stant, commonly many thousands or millions of times. For example, in the
Metropolis–Hastings algorithm, an MCMC algorithm, this arises through
computing the probability that the Markov chain accepts the proposed
move from a current point θ to a proposed point θ′ ∼q(θ, θ′), where q is
some proposal density, given by α(θ, θ′) = min

1, π(θ′|yobs)q(θ′,θ)
π(θ|yobs)q(θ,θ′)

. Similarly
in SMC algorithms, the incremental particle weight is given by wt(θt) =
πt(θt|yobs)Lt−1(θt,θt−1)
πt−1(θt−1|yobs)Mt(θt−1,θt), where Mt and Lt−1 are transition kernels, and πt

Overview of ABC
5
denotes a function strongly related to the posterior distribution, such as
πt(θt|yobs) = [π(θt|yobs)]t/T π(θt)1−t/T . Evaluating acceptance probabilities or
particle weights clearly requires evaluation of the likelihood function.
However, for an increasing range of scientiﬁc problems – see Section 1.11
for a selection – numerical evaluation of the likelihood function, π(yobs|θ), is
either computationally prohibitive, or simply not possible. Examples of the
former can occur where the size of the observed dataset, yobs, is suﬃciently
large that, in the absence of low dimensional suﬃcient statistics, evaluating
the likelihood function even once is impracticable. This can easily occur in
the era of Big Data, for example, through large genomic datsets. Partial like-
lihood intractability can arise, for instance, in models for Markov random
ﬁelds. Here, the likelihood function can be written as p(yobs|θ) =
1
Zθ ˜p(yobs|θ),
where ˜p(yobs|θ) is a function that can be evaluated, and where the normalisa-
tion constant, Zθ = 
Y ˜p(y|θ), depends on the parameter vector θ. Except for
trivial datasets, the number of possible data conﬁgurations in the set Y means
that brute-force enumeration of Zθ is typically infeasible (Møller et al. 2006;
Grelaud et al. 2009). While there are algorithmic techniques available that
arrange for the intractable normalising constants to cancel out within, for
example, Metropolis–Hastings acceptance probabilities (Møller et al. 2006),
or that numerically approximate Zθ through, for example, path sampling or
thermodynamic integration, these are not viable when ˜p(y|θ) itself is also com-
putationally intractable. Instances when the complete likelihood function is
unavailable can also occur when the model density function is only implicitly
deﬁned, for example, through quantile or characteristic functions (Drovandi
and Pettitt 2011; Peters et al. 2012). Similarly, the likelihood function may
only be implicitly deﬁned as a data generation process.
In these scenarios, if the preferred model is computationally intractable,
the need to repeatedly evaluate the posterior distribution to draw samples
from the posterior makes the implementation of standard Bayesian simula-
tion techniques impractical. Faced with this challenge, one option is simply to
ﬁt a diﬀerent model that is more amenable to statistical computations. The
disadvantage of this approach is that the model could then be less realistic, and
not permit inference on the particular questions of interest for the given anal-
ysis. A more attractive alternative, may be to consider an approximation to
the preferred model, so that modelling realism is maintained at the expense of
some approximation error. While various posterior approximation methods are
available, ‘likelihood-free’ Bayesian methods, of which approximate Bayesian
computation (ABC) is a particular case, have emerged as an eﬀective and
intuitively accessible way of performing an approximate Bayesian analysis.
In this chapter, we aim to give an intuitive exploration of the basics of ABC
methods, illustrated wherever possible by simple examples. The scope of this
exploration is deliberately limited, for example, we focus only on the use of
simple rejection sampling-based ABC samplers, in order that this chapter will
provide an accessible introduction to a subject which is given more detailed
and advanced treatments in the rest of this handbook.

6
Handbook of Approximate Bayesian Computation
1.2
Likelihood-Free Intuition
The basic mechanism of likelihood-free methods can be fairly easily under-
stood at an intuitive level. For the moment, we assume that data generated
under the model, y ∼p(y|θ), are discrete. Consider the standard rejection
sampling algorithm for sampling from a density f(θ):
Standard Rejection Sampling Algorithm
Inputs:
• A target density f(θ).
• A sampling density g(θ), with g(θ) > 0 if f(θ) > 0.
• An integer N > 0.
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from sampling density g.
2. Accept θ(i) with probability
f(θ(i))
Kg(θ(i)) where K ≥maxθ
f(θ)
g(θ).
Else go to 1.
Output:
A set of parameter vectors θ(1), . . . , θ(N) which are samples from f(θ).
If we specify f(θ) = π(θ|yobs), and suppose that the prior is used as the
sampling distribution, then the acceptance probability is proportional to the
likelihood, as then f(θ)/Kg(θ) ∝p(yobs|θ). While direct evaluation of this
acceptance probability is not available if the likelihood is computationally in-
tractable, it is possible to stochastically determine whether or not to accept
or reject a draw from the sampling density, without numerical evaluation of
the acceptance probability. The following discussion assumes that the data y
are discrete (this will be relaxed later).
This can be achieved by noting that the acceptance probability is pro-
portional to the probability of generating the observed data, yobs, under the
model p(y|θ) for a ﬁxed parameter vector, θ. That is, suitably normalised, the
likelihood function p(y|θ) can be considered as a probability mass function
for the data. Put another way, for ﬁxed θ, if we generate a dataset from the
model y ∼p(y|θ), then the probability of generating our observed dataset
exactly, so that y = yobs, is precisely p(yobs|θ). From this observation, we can
use the Bernoulli event of generating y = yobs (or not) to determine whether
to accept (or reject) a draw from the sampling distribution, in lieu of directly
evaluating the probability p(yobs|θ).

Overview of ABC
7
This insight permits a rewriting of the simple rejection sampling algorithm,
as given below. A critical aspect of this modiﬁed algorithm is that it does not
require numerical evaluation of the acceptance probability (i.e. the likelihood
function). Note that if sampling is from g(θ) rather than the prior π(θ), then
the acceptance probability is proportional to p(yobs|θ)π(θ)/g(θ). In this case,
deciding whether to accept a draw from g(θ) can be split into two stages:
ﬁrstly, as before, if we generate y ∼p(y|θ), such that y ̸= yobs, then we reject
the draw from g(θ). If, however, y = yobs, then we accept the draw from g(θ)
with probability π(θ)/[Kg(θ)], where K ≥maxθ f(θ)/g(θ). (These two steps
may be interchanged so that the step with the least computational overheads
is performed ﬁrst.) Importance sampling versions of this and later algorithms
are examined in chapter 4.
Likelihood-Free Rejection Sampling Algorithm
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ), consisting of a
prior distribution π(θ) and a procedure for generating data under the
model p(yobs|θ).
• A proposal density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• An integer N > 0.
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from sampling density g.
2. Generate y ∼p(y|θ(i)) from the likelihood.
3. If y = yobs, then accept θ(i) with probability
π(θ(i))
Kg(θ(i)),
where K ≥maxθ
π(θ)
g(θ) . Else go to 1.
Output:
A set of parameter vectors θ(1), . . . , θ(N) which are samples from π(θ|yobs).
1.3
A Practical Illustration: Stereological Extremes
In order to illustrate the performance of the likelihood-free rejection sampling
algorithm, we perform a re-analysis of a stereological dataset with a compu-
tationally intractable model ﬁrst developed by Bortot et al. (2007).

8
Handbook of Approximate Bayesian Computation
1.3.1
Background and model
Interest is in the distribution of the size of inclusions, microscopically small
particles introduced during the production of steel. The steel strength is
thought to be directly related to the size of the largest inclusion. Commonly,
the sampling of inclusions involves measuring the maximum cross-sectional di-
ameter of each observed inclusion, yobs = (yobs,1, . . . , yobs,n)⊤, obtained from a
two-dimensional planar slice through the steel block. Each cross-sectional in-
clusion size is greater than some measurement threshold, yobs,i > u. The infer-
ential problem is to analyse the unobserved distribution of the largest inclusion
in the block, based on the information in the cross-sectional slice, yobs. The
focus on the size of the largest inclusion means that this is an extreme value
variation on the standard stereological problem (Baddeley and Jensen 2004).
Each observed cross-sectional inclusion diameter, yobs,i, is associated with
an unobserved true inclusion diameter Vi. Anderson and Coles (2002) pro-
posed a mathematical model assuming that the inclusions were spherical with
diameters V , and that their centres followed a homogeneous Poisson process
with rate λ > 0 in the volume of steel. The distribution of the largest inclusion
diameters, V |V > v0 was assumed to follow a generalised Pareto distribution,
with distribution function:
Pr(V ≤v|V > v0) = 1 −

1 + ξ(v −v0)
σ
	−1/ξ
+
,
(1.1)
for v > v0, where [a]+ = max{0, a}, following standard extreme value the-
ory arguments (Coles 2001). However, the probability of observing the cross-
sectional diameter yobs,i (where yobs,i ≤Vi) is dependent on the value of Vi,
as larger inclusion diameters give a greater chance that the inclusion will be
observed in the two-dimensional planar cross-section. This means that the
number of observed inclusions, n, is also a random variable. Accordingly, the
parameters of the full spherical inclusion model are θ = (λ, σ, ξ)⊤.
Anderson and Coles (2002) were able to construct a tractable likelihood
function for this model by adapting the solution to Wicksell’s corpuscle prob-
lem (Wicksell 1925). However, while their model assumptions of a Poisson
process are not unreasonable, the assumption that the inclusions are spherical
is not plausible in practice.
Bortot et al. (2007) generalised this model to a family of ellipsoidal
inclusions. While this model is more realistic than the spherical inclu-
sion model, there are analytic and computational diﬃculties in extending
likelihood-based inference to more general families of inclusion (Baddeley and
Jensen 2004; Bortot et al. 2007). As a result, ABC methods are a good can-
didate procedure to approximate the posterior distribution in this case.
1.3.2
Analysis
For simplicity, suppose that we are interested in the spherical inclusions model,
so that the true posterior distribution can be estimated directly. Suppose also

Overview of ABC
9
that the parameters of the generalised Pareto distribution are known to be
σ = 1.5 and ξ = 0.1, so that interest is in the Poisson rate parameter, λ, only.
In this setting, a suﬃcient statistic for the rate parameter is nobs, the ob-
served number of inclusions, so that π(θ|yobs) = π(λ|nobs) is the distribution
of interest. Accordingly, we can replace yobs = nobs in the likelihood-free rejec-
tion sampling algorithm. For the dataset considered by Bortot et al. (2007),
nobs = 112.
Figure 1.1a shows scaled density estimates of π(λ|nobs) (solid lines)
obtained using the likelihood-free rejection sampling algorithm, for vary-
ing numbers of observed inclusions, nobs = 92, 102, 112, 122, and 132. As
the observed number of inclusions increases, accordingly, so does the loca-
tion and scale of the posterior of the rate parameter. The dashed lines in
Figure 1.1a denote the same density estimates of π(λ|nobs), but obtained
using a conditional version of the standard MCMC sampler developed by
Anderson and Coles (2002), which makes use of numerical evaluations of the
likelihood. These estimates are known to correspond to the true posterior.
The likelihood-free rejection algorithm estimates clearly coincide with the true
posterior distribution.
The density estimates obtained under the likelihood-free algorithm are
each based on approximately 25,000 accepted samples, obtained from 5 million
draws from the U(0, 100) prior. That is, the acceptance rate of the algo-
rithm is approximately 0.5%. This algorithm is clearly very ineﬃcient, with
the computational overheads being partially inﬂuenced by the mismatch
between prior and posterior distributions, but they are primarily dominated
by the probability of generating data from the model that exactly matches
15
20
25
30
35
40
45
92
102
112
122
132
(a)
15
20
25
30
λ
λ
35
40
45
0.00
0.05
0.10
0.15
0.20
(b)
Density
nobs
n = nobs
|n–nobs| ≤ 10
|n–nobs| ≤ 20
FIGURE 1.1
Posterior density estimates of π(λ|nobs) for the stereological extremes example,
based on spherical inclusions. (a) Density estimates using the likelihood-free
rejection sampler (solid lines) and standard MCMC algorithm (dashed lines),
with nobs = 92, 102, 112, 122, and 132. (b) Density estimates for nobs = 112,
with the relaxed criterion that ∥y −yobs∥≤h for h = 0, 10, and 20.

10
Handbook of Approximate Bayesian Computation
the observed data, nobs. This is the price for avoiding likelihood evaluation.
On balance, the computational ineﬃciency is practically acceptable for this
speciﬁc case. However, this raises the question of how viable this approach
will be for more complex analyses, when the probability of generating data
such that y = yobs becomes even lower. Further, the acceptance probability
will be exactly zero if the data generated under the model, y ∼p(y|θ), are
continuous, which is likely to be the case in general.
In order to alleviate such computational overheads, one possible variation
on the likelihood-free rejection algorithm would be to adjust the potentially
very low (or zero) probability requirement that y = yobs exactly. Instead, the
acceptance criterion could require that the generated data are simply ‘close’
to the observed data. For example, this might require that ∥y −yobs∥≤h for
some h ≥0 and distance measure ∥·∥, such as Euclidean distance. This would
also permit a relaxation of our previous assumption that data generated under
the model, y ∼p(y|θ), are discrete. In this way, step 3 of the Sampling stage
of the likelihood-free rejection algorithm would become:
Likelihood-Free Rejection Sampling Algorithm
3. If ∥y −yobs∥≤h, then accept θ(i) with probability
π(θ(i))
Kg(θ(i)),
where K ≥maxθ
π(θ)
g(θ) .
Else go to 1.
Of course, the output samples would no longer be draws from π(θ|yobs)
unless h = 0, but will instead be draws from an approximation of π(θ|yobs).
The logic behind this modiﬁcation is that increasing h will considerably
improve the acceptance rate of the algorithm. The hope is that, if h remains
small, then the resulting estimate of the posterior will still be close to the true
posterior. An illustration of this is shown in Figure 1.1b, which shows den-
sity estimates obtained using the adjusted requirement that ∥n −nobs∥≤h
for h = 0 (i.e. n = nobs), 10 and 20. Computationally there is a marked
improvement in algorithmic eﬃciency: the low 0.5% acceptance rate for h = 0
increases to 10.5% and 20.5% for h = 10 and 20 respectively.
However, there are now some clear deviations in the density estimate re-
sulting from the likelihood-free algorithm, compared to the actual posterior,
π(λ|nobs) (solid lines). In fact, it is more accurate to refer to these density es-
timates as an approximation of the posterior. On one hand, the location and
shape of the density are broadly correct, and for some applications, this level
of approximation may be adequate. On the other hand, however, the scale of
the approximation is clearly overestimated for larger values of h. Intuitively
this makes sense: the adjusted criterion ∥y −yobs∥≤h accepts θ ∼g(θ)
draws if the generated data y are merely ‘close’ to yobs. As such, for many
values of θ, where it was previously very unlikely to generate data such that

Overview of ABC
11
y = yobs, it may now be possible to satisfy the more relaxed criterion. This
will accordingly result in a greater range of θ values that will be accepted
and thereby increase the variability of the posterior approximation. The more
relaxed the criterion (i.e. the larger the value of h), the greater the resulting
variability.
It is possible to be more precise about the exact form of the posterior
obtained through this adjusted procedure – this will be discussed in detail
in the next section. However, for this particular analysis, based on samples
λ(1), . . . , λ(N) and datasets n(1), . . . , n(N) obtained from the likelihood-free
rejection algorithm, it can be seen that as the posterior approximation is
constructed from those values of λ = λ(i) such that ∥n(i) −nobs∥≤h, then
the posterior approximation can ﬁrstly be expressed as:
ˆπ(λ|nobs) = 1
N
N

i=1
δλ(i)(λ)
=
1
N

λ(i):∥n(i)−nobs∥≤h
δλ(i)(λ)
=
h∗

h′=−h∗
⎛
⎝1
N

λ(i):(n(i)−nobs)=h′
δλ(i)(λ)
⎞
⎠,
where h∗is the largest integer such that ∥h∗∥≤h. It then follows that:
lim
N→∞ˆπ(λ|nobs) =
h∗

h′=−h∗
Pr(n = nobs + h′)π(λ|nobs + h′).
(1.2)
That is, the ‘likelihood-free’ approximation of the posterior, π(θ|yobs), is pre-
cisely an average of the individual posterior distributions π(λ|nobs + h′) for
h′ = −h∗, . . . , h∗, weighted according to Pr(n = nobs + h′), the probability of
observing the dataset, nobs + h′, based on samples drawn from the (prior pre-
dictive) distribution p(n|λ)π(λ). This can be loosely observed from Figure 1.1,
in which the approximations for h = 10 and h = 20 in panel (b) respectively
correspond to rough visual averages of the centre three and all ﬁve displayed
posteriors in panel (a). For h = 0 we obtain limN→∞ˆπ(λ|nobs) = π(λ|nobs) as
for standard Monte Carlo algorithms.
Similar interpretations and conclusions arise when the data y are contin-
uous, as we examine for a diﬀerent model in the following subsection. This
also allows us to introduce a fundamental concept in ABC methods, the use
of summary statistics.
1.4
A g-and-k Distribution Analysis
The univariate g-and-k distribution is a ﬂexible unimodal distribution that
is able to describe data with signiﬁcant amounts of skewness and kurtosis.
Originally developed by Tukey (1977) (see also Martinez and Iglewicz 1984;

12
Handbook of Approximate Bayesian Computation
Hoaglin 1985; and Rayner and MacGillivray 2002), the g-and-k and related
distributions have been analysed in the ABC setting by Peters and Sisson
(2006), Allingham et al. (2009), Drovandi and Pettitt (2011), and Fearnhead
and Prangle (2012) among others. Its density function has no closed form, but
is alternatively deﬁned through its quantile function as:
Q(q|A, B, g, k) = A + B

1 + c1 −exp{−gz(q)}
1 + exp{−gz(q)}
	
(1 + z(q)2)kz(q)
(1.3)
for B > 0, k > −1/2, where z(q) = Φ−1(q) is the q-th quantile of the
standard normal distribution function. The parameter c measures overall
asymmetry, and is conventionally ﬁxed at c = 0.8 (resulting in k > −1/2)
(Rayner and MacGillivray 2002). This distribution is very ﬂexible, with many
common distributions obtained or well approximated by particular parame-
ter settings, such as the normal distribution when g = k = 0. Given θ =
(A, B, g, k)⊤, simulations z(q) ∼N(0, 1) drawn from a standard normal distri-
bution can be transformed into samples from the g-and-k distribution through
equation (1.3).
Figure 1.2 shows a scatterplot of samples from the likelihood-free ap-
proximation of the posterior π(θ|yobs) (grey dots), based on a simulated
dataset yobs of length n = 1, 000 generated from the g-and-k distribution
A
B
g
0.5
1.0
1.5
0.0 0.2 0.4 0.6 0.8 1.0
3.0 3.5 4.0
0.5 1.0 1.5
0 2 4 6 8
3.0
3.5
4.0
0.0 0.4 0.8
0
2
4
6
8
10
k
FIGURE 1.2
Pairwise scatterplots of samples from the likelihood-free approximation to the
posterior using the full dataset (grey dots) and four summary statistics (black
dots). True parameter values (A, B, g, k) = (3, 1, 2, 0.5) are indicated by the
cross ×.

Overview of ABC
13
with parameter vector θ0 = (3, 1, 2, 0.5)⊤. This analysis was based on deﬁning
∥y−yobs∥= (y−yobs)⊤ˆΣ−1(y−yobs) ≤h as Mahalanobis distance, with h given
by the 0.005 quantile of the diﬀerences ∥y −yobs∥for i = 1, . . . , N = 100, 000
Monte Carlo samples from the joint prior π(θ) = π(A)π(B)π(g)π(k) =
N(1, 5) × N(0.25, 2) × U(0, 10) × U(0, 1). The matrix ˆΣ was determined as
the sample covariance matrix of y using 2,000 samples generated under the
model y|θ0 with θ = θ0 ﬁxed at its true value.
As is apparent from Figure 1.2, the likelihood-free approximation to
π(θ|yobs) (grey dots) is particularly poor, the true parameter vector θ0 is
not even close to the estimated posterior samples. This outcome is a direct
result of the dimension of the comparison y−yobs. The chance of generating an
n = 1, 000-dimensional vector y that is close to yobs, even if θ = θ0, is vanish-
ingly small. The odds of matching y with yobs can be increased by redeﬁning
both in terms of their order statistics, although the chances still remain ex-
tremely low (see Example 3 in Section 1.7.1 for an illustration). This means
that h must be relatively large, which results in accepting samples θ(i) that
generate data y(i) that are not actually close to yobs, and thereby producing
a poor approximation to π(θ|yobs).
The obvious way to avoid this problem is to reduce the dimension of the
data comparison y −yobs. Suppose that lower dimensional statistics s = S(y)
and sobs = S(yobs) are available, such that S(y) is suﬃcient for, or highly
informative for θ under the model, but where dim(S(y)) ≪dim(y). Then the
comparison ∥y −yobs∥might be replaced by ∥s −sobs∥without too much loss
of information, but with the advantage that the dimension of S(y) is now
much lower. That is, step 3 in the likelihood-free rejection sampling algorithm
could be further replaced by:
Likelihood-Free Rejection Sampling Algorithm
3. Compute s = S(y).
If ∥s −sobs∥≤h, then accept θ(i) with probability,
π(θ(i))
Kg(θ(i))
where K ≥maxθ
π(θ)
g(θ) . Else go to 1.
Using this idea, Drovandi and Pettitt (2011) suggested the statistics
SA = E4,
SB = E6 −E2,
Sg = (E6 + E2 −2E4)/SB,
and Sk = (E7 −E5 + E3 −E1)/SB
as informative for A, B, g, and k, respectively, so that S(y) = (SA, SB, Sg, Sk)⊤,
where E1 ≤E2 ≤. . . ≤E8 are the octiles of y. Repeating the above g-and-k
analysis but using the four-dimensional comparison ∥s −sobs∥rather than
∥y −yobs∥(and recomputing ˆΣ and h under the same conditions), the result-
ing posterior samples are shown in Figure 1.2 (black dots).

14
Handbook of Approximate Bayesian Computation
The diﬀerence in the quality of the approximation to π(θ|yobs) when using
S(y) rather than y, is immediately apparent. The true parameter value θ0
is now located ﬁrmly in the centre of each pairwise posterior sample, sev-
eral parameters (particularly A and g) are more precisely estimated, and evi-
dence of dependence between parameters (as is to be expected) is now clearly
seen.
While it is unreasonable to expect that there has been no loss of informa-
tion in moving from y to S(y), clearly the overall gain in the quality of the
approximation to the likelihood-free posterior has been worth it in this case.
This suggests that the use of summary statistics S(y) is a useful tool more
generally in approximate Bayesian computational techniques.
1.5
Likelihood-Free Methods or ABC?
The terms likelihood-free methods and approximate Bayesian computation are
both commonly used to describe Bayesian computational methods developed
for when the likelihood function is computationally intractable or otherwise
unavailable. Of course, ‘likelihood-free’ is arguably a misnomer, in no sense
is the likelihood function not involved in the analysis. It is the function used
to generate the data y ∼p(y|θ), and it accordingly must exist, whether or
not it can be numerically evaluated or written down. Rather, in this context,
‘likelihood-free’ refers to any likelihood-based analysis that proceeds without
direct numerical evaluation of the likelihood function. There are several tech-
niques that could be classiﬁed according to this description.
‘Approximate Bayesian computation,’ commonly abbreviated to ‘ABC’,
was ﬁrst coined by Beaumont et al. (2002) in the context of Bayesian statis-
tical techniques in population genetics (although see Tavar´e 2019, Chapter 2,
this volume) and refers to the speciﬁc type of likelihood-free methods con-
sidered in this book. In particular, given the ‘approximate’ in ABC, it refers
to those likelihood-free methods that produce an approximation to the poste-
rior distribution resulting from the imperfect matching of data ∥y −yobs∥or
summary statistics ∥s −sobs∥.
Thus, the likelihood-free rejection algorithm described above with h = 0,
which only accepts samples, θ, which have exactly reproduced the observed
data yobs, is not an ABC algorithm, as the method produces exact samples
from the posterior distribution – there is no approximation. (The Monte Carlo
approximation of the posterior is not considered an approximation in this
sense.) It is, however, a likelihood-free method. Whereas, the likelihood-free
rejection algorithm which may accept samples if ∥y −yobs∥≤h, for h > 0, is
an ABC algorithm, as the samples will be drawn from an approximation to the
posterior distribution. Similarly, when the sampler may alternatively accept
samples if ∥s−sobs∥≤h, for any h ≥0 (including h = 0), the resulting samples

Overview of ABC
15
are also drawn from an approximate posterior distribution. As such, this is
also an ABC algorithm. The only exception to this is the case where h = 0 and
the summary statistics are suﬃcient: here there is no posterior approximation,
the algorithm is then likelihood-free, but not an ABC method.
With a few exceptions (such as indirect inference, see Chapter 7), all of the
methods considered in this book are both ABC and (by deﬁnition) likelihood-
free methods. The aim of any ABC analysis is to ﬁnd a practical way of
performing the Bayesian analysis, while keeping the approximation and the
computation to a minimum.
1.6
The Approximate Posterior Distribution
In contrast to the intuitive development of likelihood-free methods in the
previous Sections, we now describe the exact form of the ABC approximation
to the posterior distribution that is produced from the likelihood-free rejection
algorithm. The procedure of (i) generating θ from the sampling distribution,
g(θ), (ii) generating data, y, from the likelihood, p(y|θ), conditional on θ, and
(iii) rejecting θ if ∥y −yobs∥≤h, is equivalent to drawing a sample (θ, y) from
the joint distribution proportional to:
I(∥y −yobs∥≤h)p(y|θ)g(θ),
where I is the indicator function, with I(Z) = 1 if Z is true, and I(Z) = 0
otherwise. If this sample (θ, y) is then further accepted with probability pro-
portional to π(θ)/g(θ), this implies that the likelihood-free rejection algorithm
is sampling from the joint distribution proportional to:
I(∥y −yobs∥≤h)p(y|θ)g(θ)π(θ)
g(θ) = I(∥y −yobs∥≤h)p(y|θ)π(θ).
(1.4)
Note that if h = 0, then the θ marginal of (1.4) equals the true posterior
distribution, as:
lim
h→0

I(∥y −yobs∥≤h)p(y|θ)π(θ)dy =

δyobs(y)p(y|θ)π(θ)dy
= p(yobs|θ)π(θ).
That is, for h = 0, the likelihood-free rejection algorithm draws samples,
(θ, y), for which the marginal distribution of the parameter vector is the true
posterior, π(θ|yobs). (The marginal distribution of the auxiliary dataset y is a
point mass at {y = yobs} in this case.)
It is useful in the following to generalise the above formulation slightly.
In (1.4), the indicator term I(∥y −yobs∥≤h) only takes the values 0 or 1.

16
Handbook of Approximate Bayesian Computation
This is useful in the sense that it allows clear ‘If ∥y −yobs∥≤h, then . . . ’
statements to be made in any algorithm, which can simplify implementation.
However, it is intuitively wasteful of information, as it does not discriminate
between those samples, θ, for which the associated dataset y exactly equals the
observed dataset yobs, and those samples, θ, for which the associated dataset is
the furthest away from yobs, (i.e. ∥y −yobs∥= h). As the former case produces
samples that are exact draws from the true posterior distribution, whereas the
latter case does not, this produces a motivation for a more continuous scaling
from 1 (when y = yobs) to 0 (when ∥y −yobs∥is large).
This can be achieved by replacing the indicator function, I(∥y−yobs∥≤h),
with a standard smoothing kernel function, Kh(u), with u = ∥y−yobs∥, where:
Kh(u) = 1
hK
u
h

.
Kernels are symmetric functions such that K(u) ≥0 for all u,

K(u)du = 1,

uK(u)du = 0, and

u2K(u)du < ∞. Here, h > 0 corresponds to the scale
parameter, or ‘bandwidth’ of the kernel function. Several common forms for
kernel functions are given in Table 1.1, and these are illustrated in Figure 1.3.
Following convention, we deﬁne limh→0 Kh(u) as a point mass at the origin
(u = 0).
An alternative speciﬁcation of a smoothing kernel for multivariate
datasets is obtained by writing u = y −yobs, where u = (u1, . . . , un)⊤,
y = (y1, . . . , yn)⊤, and yobs = (yobs,1, . . . , yobs,n)⊤, so that ui = yi −yobs,i.
Then we can write Kh(u) = n
i=1 Khi(ui), where the scale parameter of each
individual kernel function, Khi(ui), may vary. A further, more general speci-
ﬁcation may determine Kh(u) as a fully multivariate, smooth and symmetric
function, satisfying the above moment constraints. One such example is a
multivariate N(0, Σ) distribution, for some ﬁxed covariance matrix Σ.
Substituting the kernel function, Kh(u), into the likelihood-free rejection
algorithm results in the ABC rejection sampling algorithm:
TABLE 1.1
The Functional Forms of Several Common
Kernel Functions
Kernel
K(u)
Uniform
1
2I(|u| ≤1)
Triangular
(1 −|u|)I(|u| ≤1)
Epanechnikov
3
4(1 −u2)I(|u| ≤1)
Biweight
15
16(1 −u2)3I(|u| ≤1)
Gaussian
1
√
2πe−1
2 u2

Overview of ABC
17
−1
0
1
0
1
Common kernel functions
u
Kh(u)
Uniform
Triangular
Epanechnikov
Biweight
Gaussian
FIGURE 1.3
Standard kernel functions, K(u), listed in Table 1.1 plotted on a common
scale (with maximum at 1).
ABC Rejection Sampling Algorithm
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ), consisting of a
prior distribution π(θ) and a procedure for generating data under the
model p(yobs|θ).
• A proposal density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• An integer N > 0.
• A kernel function Kh(u) and scale parameter h > 0.
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from sampling density g.
2. Generate y ∼p(y|θ(i)) from the likelihood.
3. Accept θ(i) with probability Kh(∥y−yobs∥)π(θ(i))
Kg(θ(i))
,
where K ≥Kh(0) maxθ
π(θ)
g(θ) . Else go to 1.
Output:
A set of parameter vectors θ(1), . . . , θ(N) ∼πABC(θ|yobs).

18
Handbook of Approximate Bayesian Computation
In order to determine the form of the target distribution, πABC(θ|yobs), of
this algorithm, we can follow the same argument as before. By (i) generating
θ from the importance distribution, g(θ), (ii) generating data, y, from the
likelihood, p(y|θ), conditional on θ, and then (iii) accepting the sample (θ, y)
with probability proportional to Kh(∥y −yobs∥)π(θ(i))/g(θ(i)), this results in
samples from the joint distribution:
πABC(θ, y|yobs) ∝Kh(∥y −yobs∥)p(y|θ)π(θ).
(1.5)
When Kh(u) is the uniform kernel (see Table 1.1), then (1.5) reduces to (1.4).
Accordingly, we deﬁne the ABC approximation to the true posterior distribu-
tion as:
πABC(θ|yobs) =

πABC(θ, y|yobs)dy,
(1.6)
where πABC(θ, y|yobs) is given by (1.5).
As before, as h →0, so that only those samples, θ, that generate data for
which y = yobs are retained, then (1.5) becomes:
lim
h→0 πABC(θ, y|yobs)
∝
lim
h→0 Kh(∥y −yobs∥)p(y|θ)π(θ)
=
δyobs(y)p(y|θ)π(θ),
and so limh→0 πABC(θ|yobs) ∝

δyobs(y)p(y|θ)π(θ)dy = p(yobs|θ)π(θ). That is,
samples from the true posterior distribution are obtained as h →0. However,
h = 0 is not a viable choice in practice, as for continuous yobs, it corresponds
to an algorithm with an acceptance rate of zero.
To see what marginal distribution the ABC rejection algorithm is sam-
pling from for h > 0, we can integrate πABC(θ, y|yobs) over the auxiliary data
margin, y.
A natural question to ask is, how accurate is this approximation?
Re-writing the right hand side of (1.5) without the prior distribution, π(θ),
we can similarly deﬁne the ABC approximation to the true likelihood, p(y|θ),
for a ﬁxed value of θ, as:
pABC(yobs|θ) =

Kh(∥y −yobs∥)p(y|θ)dy.
(1.7)
In this manner, ABC can be interpreted as a regular Bayesian analysis, but
with an approximated likelihood function.
Working in the univariate case for simplicity of illustration, so that y, yobs ∈
Y = R and ∥u∥= |u|, we can obtain:
pABC(yobs|θ) =

Kh(|y −yobs|)p(y|θ)dy
=

K(u)p(yobs −uh|θ)du
=

K(u)

p(yobs|θ) −uhp′(yobs|θ) + u2h2
2
p′′(yobs|θ) −. . .
	
du
= p(yobs|θ) + 1
2h2p′′(yobs|θ)

u2K(u)du −. . . ,
(1.8)

Overview of ABC
19
using the substitution u = (yobs −y)/h, a Taylor expansion of p(yobs −uh|θ)
around the point yobs, and the kernel function properties of Kh(u) =
K(u/h)/h,

K(u)du = 1,

uK(u)du = 0 and K(u) = K(−u). The above
is a standard smoothing kernel density estimation expansion, and assumes
that the likelihood, p(y|θ), is inﬁnitely diﬀerentiable. As with kernel density
estimation, the choice of scale parameter is more important than the choice
of kernel function in terms of the quality of the approximation.
Then, the pointwise bias in the likelihood approximation for ﬁxed θ can
be expressed as:
bh(y|θ) := pABC(y|θ) −p(y|θ),
(1.9)
as a function of y, which to second order can be written as
ˆbh(y|θ) = 1
2h2σ2
Kp′′(y|θ),
where σ2
K =

u2K(u)du is the variance of the kernel function. Accordingly,
the magnitude of the bias is reduced if h is small, corresponding to better ap-
proximations. Clearly, the second derivative of the likelihood function, p′′(y|θ),
is typically also unavailable if the likelihood function itself is computationally
intractable. When y, yobs ∈Y is multivariate, a similar derivation to the above
is available. In either case, the ABC approximation to the true posterior is
deﬁned through (1.6).
In a similar manner, we can determine the pointwise bias in the resulting
ABC posterior approximation. From (1.9) we can write:
bh(yobs|θ)π(θ)
=
pABC(yobs|θ)π(θ) −p(yobs|θ)π(θ)
=
πABC(θ|yobs)cABC −π(θ|yobs)c,
(1.10)
where cABC =

pABC(yobs|θ)π(θ)dθ > 0 and c =

p(yobs|θ)π(θ)dθ > 0.
Rearranging (1.10), we obtain:
ah(θ|yobs)
:=
πABC(θ|yobs) −π(θ|yobs)
=
bh(yobs|θ)π(θ) + π(θ|yobs)c
cABC
−π(θ|yobs)
(1.11)
=
bh(yobs|θ)π(θ)
cABC
+ π(θ|yobs)

c
cABC
−1

,
as a function of θ. As h →0, then bh(yobs|θ) →0 from (1.9), and so
pABC(yobs|θ) →p(yobs|θ) pointwise, for ﬁxed θ. Further, c/cABC →1 as h
gets small, so that ah(θ|yobs) →0.
1.6.1
Simple examples
In many simple cases, the ABC approximation to the posterior distribution
can be derived exactly.

20
Handbook of Approximate Bayesian Computation
Example 1:
Suppose that the observed data, yobs, is a single draw from a continuous
density function p(y|θ), and that θ is a scalar. If we consider the particular
case where Kh(∥u∥) is the uniform kernel on [−h, h] (see Table 1.1), and
∥u∥= |u|, then we have:
πABC(θ|yobs)
∝
π(θ)
 ∞
−∞
Kh(|y −yobs|)p(y|θ)dy
=
π(θ)
2h
 yobs+h
yobs−h
p(y|θ)dy
=
π(θ)[P(yobs + h|θ) −P(yobs −h|θ)]
2h
,
(1.12)
where P(y|θ) =
 y
−∞p(z|θ)dz is the cumulative distribution function of y|θ.
Noting that as limh→0[P(yobs + h|θ) −P(yobs −h|θ)]/2h = p(yobs|θ) via
L’Hopital’s rule, then πABC(θ|yobs) →π(θ|yobs) as h →0, as required. Also,
[P(yobs + h|θ) −P(yobs −h|θ)]/2h ≈1/2h for large h, and so πABC(θ|yobs) →
π(θ) as h →∞.
Suppose now that p(y|θ) = θe−θy, for θ, y ≥0, is the density function of
an Exp(θ) random variable, and that the prior π(θ) ∝θα−1e−βθ is given by a
Gamma(α, β) distribution with shape and rate parameters α > 0 and β > 0.
Then from (1.12), and for 0 < h < yobs + β, we can directly obtain:
pABC(yobs|θ)
=
1
2he−θyobs(eθh −e−θh)
ˆbh(yobs|θ)
=
1
6h2θ3e−θyobs
πABC(θ|yobs)
=
θα−1e−θ(yobs+β) 
eθh −e−θh
Γ(α)
(yobs+β−h)α −
Γ(α)
(yobs+β+h)α
,
where Γ(α) =
 ∞
0
zα−1e−zdz is the gamma function.
Figure 1.4a illustrates the true likelihood function, p(y|θ), (black dashed
line) and the ABC approximation to the true likelihood function, pABC(y|θ),
(solid grey line) as a function of y for h = 0.91 and θ = 2. Also shown (grey
dashed line) is the second order approximation to the ABC likelihood func-
tion, p(y|θ) +ˆbh(y|θ). In this case, the second order approximation provides a
reasonable representation of the ABC likelihood, pABC(y|θ). For other choices
of h and θ, the quality of this representation will vary.
The ABC approximation, πABC(θ|yobs), to the true posterior π(yobs|θ),
given yobs = 2 and α = β = 1.2 is shown in Figure 1.4b for various values
of h = 0.01, . . . , 2.7 (grey lines). The true posterior is illustrated by the black
dashed line. For small h (h = 0.01), πABC(θ|yobs) is indistinguishable from the
true posterior. As h increases, so does the scale of the approximate posterior,
which begins to exhibit a large loss of precision compared to the true posterior.
Both mean and mode of πABC(θ|yobs) increase with h.

Overview of ABC
21
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
0.0
0.5
1.0
1.5
2.0
2.5
3.0
y
θ
θ
Likelihood
True
2nd order
ABC approximation
0
1
2
3
4
5
0.0
0.2
0.4
0.6
0.8
1.0
(b)
(a)
Density
True
h = 0.01
h = 0.91
h = 1.8
h = 2.7
0
1
2
3
4
5
−0.8
−0.6
−0.4
−0.2
0.0
0.2
(c)
Approximate bias
h = 0.01
h = 0.91
h = 1.8
h = 2.7
FIGURE 1.4
Approximations involved in the ABC analysis of the Exponential-Gamma ex-
ample. (a) Various likelihood functions with h = 0.91 and θ = 2. The true
likelihood function, p(y|θ), and the ABC approximation to the likelihood,
pABC(y|θ), are denoted by black-dashed and solid grey lines respectively.
The second order approximation to pABC(y|θ), given by p(y|θ) + ˆbh(y|θ), is
illustrated by the grey-dashed line. (b) The ABC posterior approximation,
πABC(θ|yobs) with yobs = 2 for various values of h = 0.01, 0.91, 1.80, 2.70.
(c) Approximation bias in the ABC posterior as a function of h for yobs = 2.
Dashed lines indicate the exact bias a(θ|yobs) for each h, whereas solid lines
denote the second order bias ˆa(θ|yobs).
Finally, Figure 1.4c shows the resulting bias, ah(θ|yobs), in the ABC pos-
terior approximation as a function of θ and h. Dashed and solid lines, respec-
tively, show the exact bias ah(θ|yobs) and the second order bias ˆah(θ|yobs)
(deﬁned as ah(θ|yobs) in (1.11), but with ˆbh(y|θ) substituted for bh(y|θ)).
Clearly, the bias in the main body of the distribution, particularly in the
region around the mode, is well described by the second order approximation,

22
Handbook of Approximate Bayesian Computation
ˆah(θ|yobs), whereas the bias in the distributional tails is more heavily inﬂu-
enced by terms of higher order than two.
Example 2:
Suppose that the observed data, yobs = (yobs,1, . . . , yobs,n)⊤, are n independent
draws from a univariate N(θ, σ2
0) distribution, where the standard deviation,
σ0 > 0, is known. For this model, we know that p(yobs|θ) ∝p(¯yobs|θ), where
¯yobs =
1
n

i yobs,i, as the sample mean is a suﬃcient statistic for θ. If we
specify Kh(u) as a Gaussian N(0, h2) kernel (see Table 1.1), then the ABC
approximation to the likelihood, p(¯yobs|θ) is given by
pABC(¯yobs|θ) =
 ∞
−∞
Kh(|¯y −¯yobs|)p(¯y|θ)d¯y
=
 ∞
−∞
1
√
2πh exp

−(¯y −¯yobs)2
2h2

√n
√
2πσ0
exp

−n(¯y −θ)2
2σ2
0

d¯y
∝exp

−(θ −¯yobs)2
2(σ2
0/n + h2)

for h ≥0. That is, ¯yobs ∼N(θ, σ2
0/n+h2) under the ABC approximation to the
likelihood. In comparison to the true likelihood, for which ¯yobs ∼N(θ, σ2
0/n),
the variance is inﬂated by h2, the variance of the Gaussian kernel. Accordingly,
if the prior for θ is given by a N(m0, s2
0) distribution, where m0 and s0 > 0
are known, then:
πABC(θ|yobs) = φ
m0s−2
0
+ ¯yobs(σ2
0/n + h2)−1
s−2
0
+ (σ2
0/n + h2)−1
,
1
s−2
0
+ (σ2
0/n + h2)−1

,
where φ(a, b2) denotes the density of a N(a, b2) distributed random variable.
Clearly πABC(θ|yobs) →π(θ|yobs) as h →0. However, the approximation
will be quite reasonable if σ2/n is the dominating component of the variance
so that h is small in comparison (Drovandi 2012). A similar result to the above
is available in the case of a multivariate parameter vector, θ.
Figure
1.5a
illustrates
the
resulting
ABC
posterior
approximation
πABC(θ|yobs) with ¯yobs = 0 when σ2/n = 1 for the improper prior given
by m0 = 0, s2
0 →∞, so that the true posterior distribution is N(0, 1) (dashed
line). The approximation is clearly quite reasonable for h = 0.5 and h = 0.1,
as then h2 < σ2
0/n. Figure 1.5b shows the same posterior approximations, but
based on a uniform kernel over [−h, h] for Kh(u), rather than the Gaussian
N(0, h2) kernel. This ABC posterior is derived from (1.12). The resulting forms
for πABC(θ|yobs) are no longer within the Gaussian family for h > 0, exhibit
a ﬂatter behaviour around the mean, and are more concentrated around the
mean due to the compact support of the uniform kernel. The approximations
with either kernel perform well for small h.
This example additionally provides some insight into the asymptotic be-
haviour of the ABC posterior approximation. Following standard likelihood

Overview of ABC
23
−4
−2
0
2
4
0.0
0.1
0.2
0.3
0.4
(a)
Density
True  
h = 10
h = 4.5
h = 3
h = 2
h = 1.3
h = 0.5
h = 0.1
−4
−2
θ
θ
2
0
4
0.0
0.1
0.2
0.3
0.4
(b)
Density
FIGURE 1.5
ABC posterior approximations, π(θ|yobs), for a N(0, 1) target distribution
(dashed lines) for various values of kernel scale parameter h. The posterior
approximations are based on (a) N(0, h2) and (b) uniform over [−h, h] kernel
functions, Kh(u).
asymptotic results, when the amount of data, n, becomes large, the true like-
lihood function, p(y|θ), will approximately behave as a Gaussian distribu-
tion. As most prior distributions will have little impact in this setting (they
will be approximately constant over the region of high posterior density), it
follows that the ABC posterior approximation, πABC(θ|yobs), will follow a
Gaussian distribution with a variance that is inﬂated by an h2 term. Conse-
quently, the ABC posterior approximation, πABC(θ|yobs), may then in prin-
ciple be improved simply by rescaling the posterior variance to remove this
term (Drovandi 2012).
1.7
The Use of Summary Statistics
1.7.1
Summary statistic basics
Despite the development in the previous Section, the ABC posterior approxi-
mation πABC(θ|yobs) ∝

Kh(∥y−yobs∥)p(y|θ)p(θ)dy is rarely used in practice.
This is because, except in very speciﬁc scenarios (such as when yobs is very
low dimensional, or when the likelihood function p(y|θ) factorises into very
low dimensional components), it is highly unlikely that y ≈yobs can be gen-
erated from p(y|θ) for any choice of θ for realistic datasets. This results in the
need to use a large value of the kernel scale parameter h in order to achieve
viable rejection sampling algorithm acceptance rates (or a similar loss of per-
formance in other algorithms), and in doing so produce poorer ABC posterior
approximations.

24
Handbook of Approximate Bayesian Computation
In the stereological extremes analysis in Section 1.3 we replaced the full
dataset yobs with a suﬃcient statistic nobs for the model parameter λ when
estimating π(θ|yobs) = π(λ|nobs). As suﬃcient statistics can be much lower
dimensional than the full dataset, it is clear that greater approximation accu-
racy can be achieved for the same computational overheads when using low
dimensional statistics (which is hinted at in the g-and-k distribution analysis
in Section 1.4). The following example, based on Drovandi (2012), highlights
the computational beneﬁts in using lower dimensional, and less variable suﬃ-
cient statistics.
Example 3:
Suppose that y = (y1, y2)⊤, where yi ∼Binomial(n, θ) with θ ∼U(0, 1). Con-
sider three possible vectors of suﬃcient statistics: s1 = (y1, y2)⊤is the full
dataset, s2 = (y(1), y(2))⊤are the order statistics y(1) ≤y(2), and s3 = y1 + y2
is the sum of the two individual values. All three vectors of statistics are
suﬃcient for this simple model.
It is easy to compute the marginal distribution of each summary statistic
pi(si) =
 1
0 p(si|θ)π(θ)dθ as follows:
p1(s1) =
 1
0
2

i=1

n
yi

θyi(1 −θ)n−yidθ
=

n
y1
 
n
y2

B(y1 + y2 + 1, 2n −y1 −y2 + 1),
p2(s2) =

2 −I(y(1) = y(2))
  1
0
2

i=1

n
yi

θyi(1 −θ)n−yidθ
=

2 −I(y(1) = y(2))
  n
y1
  n
y2

B(y1 + y2 + 1, 2n −y1 −y2 + 1),
p3(s3) =
 1
0
 2n
s3

θs3(1 −θ)2n−s3dθ
=

2n
s3

B(s3 + 1, 2n −s3 + 1)
= 1/(2n + 1),
where B(a, b) =
 1
0 za−1(1 −z)b−1dz is the beta function. Here, pi(si) is the
probability of generating the vector si under an ABC rejection sampling al-
gorithm with sampling distribution given by the prior, g(θ) = π(θ). That is,
pi(si) is the acceptance probability of the algorithm if we only accept those
suﬃcient statistics that exactly match the observed suﬃcient statistics.
Suppose that we observe yobs = (yobs,1, yobs,2)⊤= (1, 2)⊤from n = 5
experiments. From the above, we have algorithm acceptance rates of:
p1(s1
obs) =
5
132 ≈0.038, p2(s2
obs) = 5
66 ≈0.076, and p3(s3
obs) = 1
11 ≈0.091,

Overview of ABC
25
where si
obs denotes the statistic si derived from yobs. The probability p1(s1) is
the probability of generating ﬁrst y1 = 1, and then y2 = 2. As a result, p1(s1)
will decrease rapidly as the length of the observed dataset yobs increases.
The probability p2(s2) corresponds to the probability of generating either
y = (1, 2)⊤or y = (2, 1)⊤, which are equivalent under the binomial model.
Hence, s2 has twice the probability of s1 of occurring. Finally, the probability
p3(s3) is the probability of generating y = (1, 2)⊤, (2, 1)⊤, (0, 3)⊤, or (3, 0)⊤.
Each of these cases is indistinguishable under the assumed model, and so the
event s3 occurs with the largest probability of all.
Quite clearly, while still producing samples from the true target distribu-
tion, π(θ|yobs), the impact on the eﬃciency of the sampler of the choice of
suﬃcient statistics is considerable, even for an analysis with only two obser-
vations, y1 and y2. The most eﬃcient choice is the minimal suﬃcient statistic.
The diﬀerences in the acceptance rates of the samplers would become even
greater for larger numbers of observations, n.
While the optimally informative choice of statistic for an ABC analysis is
a minimal suﬃcient statistic, this may still be non-viable in practice. For ex-
ample, if the minimal suﬃcient statistic is the full dataset yobs, sampling from
πABC(θ|yobs) will be highly ineﬃcient even for moderately sized datasets. Sim-
ilarly, in a scenario where the likelihood function may not be known beyond
a data generation procedure, identiﬁcation of any low-dimensional suﬃcient
statistic (beyond, trivially, the full dataset yobs) may be impossible. Further,
low dimensional suﬃcient statistics may not even exist, depending on the
model.
In general, a typical ABC analysis will involve speciﬁcation of a vector
of summary statistics s = S(y), where dim(s) ≪dim(y). The rejection sam-
pling algorithm with then contrast s with sobs = S(yobs), rather than y with
yobs. As a result, this procedure will produce samples from the distribution
πABC(θ|sobs) as follows:
ABC Rejection Sampling Algorithm
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ), consisting of a
prior distribution π(θ) and a procedure for generating data under the
model p(yobs|θ).
• A proposal density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• An integer N > 0.
• A kernel function Kh(u) and scale parameter h > 0.
• A low dimensional vector of summary statistics s = S(y).

26
Handbook of Approximate Bayesian Computation
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from sampling density g.
2. Generate y ∼p(y|θ(i)) from the likelihood.
3. Compute summary statistic s = S(y).
4. Accept θ(i) with probability Kh(∥s−sobs∥)π(θ(i))
Kg(θ(i))
where K ≥Kh(0) maxθ
π(θ)
g(θ) . Else go to 1.
Output:
A set of parameter vectors θ(1), . . . , θ(N) ∼πABC(θ|sobs).
Similar to the discussion in Section 1.6, it can be seen that the ABC
posterior approximation now has the form:
πABC(θ|sobs) ∝

Kh(∥s −sobs∥)p(s|θ)π(θ)ds,
(1.13)
where p(s|θ) denotes the likelihood function of the summary statistic s = S(y)
implied by p(y|θ). (That is, p(s|θ) =

Y δs(S(y))p(y|θ)dy.) If we let h →0,
so that only those samples, θ, that generate data for which s = sobs are
retained, then:
lim
h→0 πABC(θ|sobs)
∝

lim
h→0 Kh(∥s −sobs∥)p(s|θ)π(θ)ds
=

δsobs(s)p(s|θ)π(θ)ds
=
p(θ|sobs)π(θ).
Hence, samples from the distribution π(θ|sobs) are obtained as h →0. If the
vector of summary statistics, s = S(y), is suﬃcient for the model parame-
ters, then π(θ|sobs) ≡π(θ|yobs), and so samples are produced from the true
posterior distribution. However, if S(y) is not suﬃcient – and this is typi-
cally the case in practice – then the ABC posterior approximation is given by
(1.13), where in the best scenario (i.e. as h →0) the approximation is given
by π(θ|sobs).
The following example illustrates the eﬀect of using a non-suﬃcient sum-
mary statistic.
Example 4:
Consider again the univariate Gaussian model in Example 2. Suppose that
we modify this example (Drovandi 2012), so that the model still assumes
that the observed data yobs = (yobs,1, . . . , yobs,n)⊤are random draws from

Overview of ABC
27
a univariate N(θ, σ2
0) distribution, but where we now specify an insuﬃcient
summary statistic, s = ¯y1:n′ =
1
n′
n′
i=1 yi with n′ < n.
Writing sobs = S(yobs), the resulting ABC approximation to the likelihood
function becomes:
pABC(sobs|θ) =

Kh(s −sobs)p(s|θ)ds
∝
 ∞
−∞
1
√
2πh exp

−(s −sobs)2
2h2

√
n′
√
2πσ0
exp

−n′(s −θ)2
2σ2
0

ds
∝exp

−
(θ −sobs)2
2(σ2
0/ωn + h2)

,
where ω = n′/n is the proportion of the n observations used in the vector
of summary statistics. That is, sobs ∼N(θ, σ2/ωn + h2). When ω = 1, then
sobs = ¯yobs is suﬃcient for θ and so sobs ∼N(θ, σ2/n + h2) recovers the same
result as Example 2.
When n′ < n, so that s is no longer suﬃcient for θ, the mean of the Gaus-
sian likelihood function is centred on the mean ¯yobs,1:n′ rather than ¯yobs,1:n,
but more critically, the variance of the Gaussian likelihood is σ2/ωn + h2. It
is evident that there are now two sources of error, both of which inﬂate the
variance of the likelihood. The ﬁrst, h2, arises through the matching of the
simulated and observed data through the Gaussian kernel. The second source
of error comes from the 0 < ω < 1 term, which can be interpreted as the de-
gree of ineﬃciency of replacing y by s = S(y). That is, the use of non-suﬃcient
statistics reduces the precision of the likelihood (and by turn, the posterior
distribution) in this case.
From Example 2, it follows that when n is large and the posterior is asymp-
totically Gaussian, the ABC posterior approximation, πABC(θ|sobs), can be
improved by rescaling to remove h2 from the posterior variance. However, cor-
recting for the lack of suﬃciency in the summary statistic, s, would require
knowledge of the relative ineﬃciency of s over y, which may be diﬃcult to
obtain in practice.
The choice of summary statistics for an ABC analysis is a critical deci-
sion that directly aﬀects the quality of the posterior approximation. Many
approaches for determining these statistics are available, and these are re-
viewed in Blum et al. (2013) and Prangle (2019), Chapters 3 and 5, this
volume. These methods seek to trade oﬀtwo aspects of the ABC posterior
approximation that directly result from the choice of summary statistics. The
ﬁrst is that π(θ|yobs) is approximated by π(θ|sobs). As this represents an ir-
revocable potential information loss, the information content in sobs should
be high. The second aspect of the ABC posterior approximation is that the
simulated and observed summary statistics are compared within a smoothing
kernel Kh(∥s −sobs∥) as part of the form of πABC(θ|sobs) (1.13). As stochas-
tically matching s and sobs becomes increasingly diﬃcult as the dimension of
the summary statistics increases, the dimension of s should be low.

28
Handbook of Approximate Bayesian Computation
As such, the dimension of the summary statistic should be large enough so
that it contains as much information about the observed data as possible, but
also low enough so that the curse-of-dimensionality of matching s and sobs
is avoided. For illustration, in Example 3, the optimum choice of summary
statistic is a minimal suﬃcient statistic. However, for other models it may be
the case that the dimension of the minimal suﬃcient statistic is equal to that
of the original dataset. As this will cause curse-of-dimensionality problems in
matching s with sobs, it is likely that a more accurate ABC posterior approx-
imation can be achieved by using a lower-dimensional non-suﬃcient statistic,
rather than remaining within the class of suﬃcient statistics. This was indeed
the case in the g-and-k distribution analysis in Section 1.4.
1.7.2
Some practical issues with summary statistics
Even with the above principles in mind, summary statistic choice remains one
of the most challenging aspects of implementing ABC in practice. For instance,
it is not always viable to continue to add summary statistics to s until the
resulting ABC posterior approximation does not change for the worse, as is
illustrated by the following example.
Example 5:
Suppose that y = (y1, . . . , yn)⊤with yi ∼Poisson(λ). Combined with conju-
gate prior beliefs λ ∼Gamma(α, β), this gives λ|y ∼Gamma(α + n¯y, β + n).
For this model, we know that the sample mean ¯y is a suﬃcient statistic. How-
ever, we also know that the mean and variance of a Poisson(λ) model are
both equal to λ, and so we might also expect the sample variance v2 to also
be informative for λ, although it is not suﬃcient. Suppose that we observe
yobs = (0, 0, 0, 0, 5)⊤, which gives (¯yobs, v2
obs) = (1, 5). Here, as the sample
mean and variance are quite diﬀerent from each other, we might expect that
the Poisson model is not appropriate for these data.
Figure 1.6 illustrates various ABC posterior approximations to the true
target distribution (solid lines) based on a prior with α = β = 1 (dashed
lines), with Kh(u) speciﬁed as a uniform kernel over [−h, h] and ∥u∥
representing Euclidean distance. The top row illustrates the resulting poste-
rior approximations, π(λ|sobs), when the summary statistics s are given as the
sample mean ¯y (a), the sample standard deviation v (b), or both (c) when the
kernel scale parameter is h = 0. Using s = ¯y recovers the true posterior exactly,
which is no surprise as ¯y is a suﬃcient statistic. Using s = v produces an in-
formed ABC approximation, but one which is based on a variance that is con-
sistent with a larger mean under the Poisson model. When s = (¯y, v)⊤, then
we again obtain the true posterior distribution as π(λ|¯yobs, vobs) ≡π(λ|¯yobs)
through suﬃciency, and the additional information that v brings about the
sample y has no eﬀect on the ABC estimated posterior.
The bottom row in Figure 1.6 shows the same information as the top
row, except that the kernel scale parameter is now non-zero (h = 0.3).

Overview of ABC
29
s = y
λ
Density
0.0
0.4
0.8
Density
0.0
0.4
0.8
Density
0.0
0.4
0.8
Density
0.0
0.4
0.8
Density
0.0
0.4
0.8
Density
0.0
0.4
0.8
s = v
λ
10
Prior
Posterior
s = (y,v)⊤
s = y
s = v
s = (y,v)⊤
λ
λ
λ
λ
0.0
1.0
2.0
3.0
0
2
4
6
8
0.0
1.0
2.0
3.0
0.0
(a)
(b)
(c)
1.0
2.0
3.0
2
4
6
8
0.5
1.5
2.5
3.5
FIGURE 1.6
Various ABC posterior approximations (histograms) for a Gamma(α + ¯y,
β + n) target distribution (solid line) with a Gamma(α, β) prior (dashed lines).
Columns illustrate posterior estimates based on (a) sample mean s = ¯y,
(b) standard deviation s = v, and (c) s = (¯y, v)⊤as summary statistics.
Top row shows results with h = 0 and the bottom row with h = 0.3.
The posterior approximations based on s = ¯y and s = v are minor devia-
tions away from those in the top row when h = 0. This occurs as the values of
λ that are able to reproduce the observed summary statistics within a non-zero
tolerance h = 0.3 are slightly diﬀerent to those that can reproduce the sum-
mary statistics exactly. However, the third panel with s = (¯y, v)⊤is clearly
biased to the right, with the resulting ABC posterior approximation visually
appearing to be a loose average of those distributions with s = ¯y and s = v.
This behaviour is diﬀerent from when h = 0. In that case, when adding
more information in the vector of summary statistics in going from s = ¯y to
s = (¯y, v)⊤, the posterior approximation does not change as the summary
statistic s = ¯y is suﬃcient, and it is being matched exactly. However, when
h > 0, because the ABC algorithm allows a non perfect matching of the
suﬃcient statistic ¯y, it additionally allows the extra information in the sample
standard deviation v to also contribute to the approximation. In this case,
because the observed summary statistics ¯yobs and vobs are inconsistent with
respect to the model, this then results in a strongly biased ﬁt when moving
from s = ¯y to s = (¯y, v)⊤.
As such, while it may be tempting to include progressively more sum-
mary statistics into sobs until the ABC posterior approximation does not
change appreciably, the assumption that this will provide the most accurate
posterior approximation is clearly incorrect. Even if sobs contains suﬃcient
statistics for the model, the inclusion of further statistics can still bias the

30
Handbook of Approximate Bayesian Computation
posterior approximation, particularly in the case where the observed data are
inconsistent with the model.
The identiﬁcation of suitable summary statistics is clearly a critical part
of any analysis. Accordingly, many techniques have been developed for this
purpose. See e.g. Chapters 3 and 5, this volume for a detailed review and
comparison of these methods. While the choice of summary statistics is itself
of primary importance, it is less appreciated that the distance measure ∥· ∥
can also have a substantial impact on ABC algorithm eﬃciency, and therefore
the quality of the posterior approximation.
Consider the distance measure ∥s −sobs∥= (s −sobs)⊤Σ−1(s −sobs).
Here, we can specify the covariance matrix Σ as the identity matrix to pro-
duce Euclidean distance, or as a diagonal matrix of non-zero weights to give
weighted Euclidean distance (e.g. Hamilton et al. 2005; Luciani et al. 2009),
or as a full covariance matrix to produce Mahalanobis distance (e.g. Peters
et al. 2012; Erhardt and Sisson 2016). To see why standard and weighted Eu-
clidean distance can be a poor choice, consider the setting in Figure 1.7, where
candidate parameter values, θ, generating continuous bivariate statistics, s|θ,
s = (s1, s2)⊤, are accepted as draws from πABC(θ|sobs) if s lies within a ball
of radius h, centered on sobs. That is, Kh is the uniform kernel on [−h, h], and
∥· ∥denotes Euclidean distance.
−4
−4
−2
0
2
4
−2
0
2
4
s2
s1
h
Type I
Type I
Type II
Type II
Sobs
FIGURE 1.7
The concept of type I and II errors for accept/reject decisions in ABC samplers
under a uniform kernel, Kh(u), over [−h, h] and Euclidean distance, ∥· ∥.
The circle represents the acceptance region for a simulated summary statistic
s = (s1, s2)⊤, centred on sobs. The ellipse represents the possible dependence
between s1 and s2.

Overview of ABC
31
If we reasonably suppose that the elements of s may be dependent and on
diﬀerent scales, their true distribution under the model may be better repre-
sented by an ellipse (grey lines). As such, an eﬃcient ABC algorithm should
accept candidate draws from πABC(θ|sobs) if s|θ lies within this ellipse. Con-
sequently, implementing a circular acceptance region (implying independence
and identical scales) induces both type I (i.e. candidate samples are rejected
when they should be accepted) and type II (i.e. candidate samples are ac-
cepted when they should be rejected) errors.
Work linking the ABC posterior with non-parametric density estimation
methods (Blum 2010; see Section 1.10) provides support for this argument.
Here, for a multivariate kernel KH(u) = det(H)−1K(H−1u), where K is a
symmetric multivariate density function with zero mean and ﬁnite variance,
a general rule of thumb is to specify the bandwidth matrix as H ∝Σ−1/2,
where Σ is the covariance matrix of the data (e.g. Scott 1992; Wand and Jones
1995). In the ABC context, this is equivalent to deﬁning ∥· ∥as Mahalanobis
distance, where Σ is the covariance matrix of s (or s|θ).
Note that the above argument assumes that the summaries s1 and s2 are
both informative for the model parameter θ. For example, in the case where
s1 + s2 is uninformative, but s1 −s2 is informative, then it is credible that
the circular acceptance region could result in a more accurate ABC posterior
approximation than that resulting from the elliptical region. In general, the
best acceptance region is tied up with the choice of the summary statistics in
a more complicated way than that presented here (see e.g. Prangle 2017 for a
discussion).
The following example illustrates the eﬀect that diﬀerent covariance ma-
trices Σ can have on the ABC posterior approximation.
Example 6:
Suppose that the model is speciﬁed as y1, . . . , y50 ∼N(θ, 1), with a uniform
prior θ ∼U(−5, 5). Various suﬃcient statistics are available for this model. We
consider two alternatives: s1 = (¯y1:40, ¯y41:50)⊤and s2 = (¯y1:25−¯y26:50, ¯y26:50)⊤,
where ¯ya:b = (b −a + 1)−1 b
i=a yi. In each case, given the observed suﬃcient
statistics sobs = (0, 0)⊤, the exact posterior distribution π(θ|yobs) is N(0, 1/50)
truncated to (−5, 5). However, the covariance matrices of s1 and s2 for ﬁxed
θ are quite diﬀerent (though they do not depend on the exact value of θ),
namely
Cov(s1|θ) =
1/40
0
0
1/10

,
Cov(s2|θ) =
 2/25
−1/25
−1/25
1/25

,
(1.14)
with a negative correlation between the elements of s2 of −1/
√
2 ≈−0.71. We
implement ABC using the distance measure as ∥s −sobs∥= (s −sobs)Σ−1(s −
sobs)′ and consider the impact of the choice of Σ.
We use a version of the ABC rejection sampling algorithm (see box)
that maintains a sample θ(1), . . . , θ(N) of size N from the ABC posterior

32
Handbook of Approximate Bayesian Computation
approximation, which progressively lowers the kernel scale parameter h un-
til a stopping rule is satisﬁed. On algorithm termination, the samples are
identical to those samples that would have been obtained under the stan-
dard ABC rejection sampling algorithm if it was implemented with the lowest
value of h achieved under the stopping rule. This allows us to implement a
rejection sampling algorithm that will terminate when a pre-speciﬁed degree
of accuracy has been achieved. The (random) number of iterations obtained
before algorithm termination will accordingly be an indicator of the eﬃciency
of the model speciﬁcation – in this case, the eﬀect of diﬀerent covariance
matrices Σ.
ABC Rejection Sampling Algorithm (with Stopping Rule)
Initialise:
For each particle i = 1, . . . , N:
• Generate θ(i) ∼π(θ) from the prior, y(i) ∼p(y|θ(i)) from the
likelihood.
• Compute summary statistics s(i) = S(y(i)) and distance ρ(i) =
∥s(i) −sobs∥.
• Generate u(i) ∼U(0, 1) that determines whether to accept the
particle. (i.e. accept if u(i) ≤Kh(ρ(i))/Kh(0).)
• Determine the smallest h that results in the acceptance of all N par-
ticles. For example,
h =

max
i {−[ρ(i)]2/(2 log(u(i)))}
or
h = max
i {ρ(i)}
if (respectively)
Kh(ρ) ∝exp{−ρ2/(2h2)}
or
Kh(ρ) ∝1 on [−h, h].
• Calculate the acceptance probabilities W (i) = Kh(ρ(i))/Kh(0), i =
1, . . . , N.
Simulation:
While the stopping rule is not satisﬁed, repeat:
1. Identify the index of the particle that will ﬁrst be rejected if h is
reduced: r = argi min{W (i) −u(i)}.
2. Set the new value of h to be the lowest value which would result in
the acceptance of all particles, except particle r.
3. Recompute acceptance probabilities W (i) given the new value of h.

Overview of ABC
33
4. Replace particle r by repeating:
(a) Generate θ(r) ∼π(θ), y(r) ∼p(y|θ(i)), u(r) ∼U(0, 1).
(b) Compute s(r) = S(y(r)), ρ(r) = ∥s(r) −sobs∥,
W (r) = Kh(ρ(r))/Kh(0)
Until u(r) ≤W (r).
Output:
A set of parameter vectors θ(1), . . . , θ(N) ∼πABC(θ|sobs), with h deter-
mined as the largest achieved value that satisﬁes the stopping rule.
Table 1.2 displays the average number of data generation steps [i.e.
generating y ∼p(y|θ)] in each algorithm implementation, per ﬁnal accepted
particle, as a function of smoothing kernel type and the form of Σ, based on
100 replicate simulations of N = 500 samples. The stopping rule continued
algorithm execution until an estimate of the absolute diﬀerence between em-
pirical (FN(θ)) and true (F(θ)) model cumulative distribution functions was
below a given level. Speciﬁcally, when N
i=1 |FN(θ(i)) −F(θ(i))| < 0.01825. In
Table 1.2, the true form of Σ is given by Cov(s1|θ) and Cov(s2|θ) (1.14), and
the diagonal form refers to the matrix constructed from the diagonal elements
of Cov(s2|θ).
The summary statistics for s = s1 are independent, but are on diﬀer-
ent scales. Accordingly, when this diﬀerence of scale is accounted for (Σ =
true), algorithm eﬃciency, and therefore ABC posterior approximation accu-
racy, is greatly improved compared to when the diﬀerence in scale is ignored
TABLE 1.2
Mean Number of Summary Statistic Generations per Final Accepted Particle
(with Standard Errors in Parentheses), as a Function of the Form of Covariance
Matrix, Σ, and Smoothing Kernel Kh, and for Two Diﬀerent Sets of Suﬃcient
Statistics s1 = (¯y1:40, ¯y41:50)⊤and s2 = (¯y1:25 −¯y26:50, ¯x26:50)⊤. Results are
Based on 100 Replicates of Posterior Samples of Size N = 500
Form of Σ
Summary
Statistic
Kernel
Identity
Diagonal
True
s = s1
Uniform
134.7
(5.8)
84.5
(2.4)
Epanechnikov
171.6
(4.7)
111.1
(3.8)
Triangle
232.3
(7.1)
153.0
(5.1)
Gaussian
242.4
(6.5)
153.6
(4.9)
s = s2
Uniform
182.5
(5.6)
161.0
(4.1)
84.4
(2.4)
Epanechnikov
245.5
(6.6)
209.2
(7.2)
111.1
(3.8)
Triangle
336.3
(8.9)
277.2
(6.9)
144.2
(3.8)
Gaussian
368.2
(12.6)
289.7
(9.7)
157.7
(4.3)

34
Handbook of Approximate Bayesian Computation
(Σ = identity). The summary statistics s2 are both negatively correlated and
on diﬀerent scales. As for s1, when summary statistic scale is taken into con-
sideration (Σ = diagonal), an improvement in algorithm eﬃciency and ABC
posterior approximation accuracy is achieved compared to when it is ignored.
However, in this case, further improvements are made when the correlation
between the summary statistics is also accounted for (Σ = true). These results
are consistent regardless of the form of the smoothing kernel Kh. Note that
the uniform kernel produces the most eﬃcient algorithm and most accurate
ABC posterior approximation, and that this steadily worsens as the form of
the kernel deviates away from the uniform density, with the worst performance
obtained under the Gaussian kernel.
This approach has been implemented in practice by, for example, Lu-
ciani et al. (2009) and Erhardt and Sisson (2016), who identify some value of
θ = θ∗in a high posterior density region via a pilot analysis and then estimate
Cov(s|θ∗) based on repeated draws from p(s|θ∗).
1.8
An ABC Analysis in Population Genetics
To illustrate some of the points concerning summary statistics, we consider
here a population genetic example, very similar to that considered in the paper
by Pritchard et al. (1999), a key paper in the development of ABC methods.
In population genetics, we are often confronted with sequence data (as illus-
trated in Table 1.3), and we wish to infer demographic parameters that may
be associated with such data. The standard modelling framework that is used
is Kingman’s coalescent (Hein, Schierup, and Wiuf 2004), which describes the
genealogical relationship of DNA sequences in a sample. The general likelihood
problem that we wish to solve then can be represented as:
p(yobs|φ) =

H
p(yobs|H)p(H|φ)dH,
where yobs represents the observed set of sequences in a sample, φ is an un-
observed vector of parameters, and H represents the unobserved genealogy
history, including mutations. A common mutation model, used here, is the
inﬁnite-sites model, in which every mutation that occurs in a genealogy is
unique. Typically H is high dimensional, represented as a variable-length vec-
tor of times of events in the genealogical history, and the types of events.
Although the likelihood can be computed exactly for simple demographic
models and small datasets (Hein et al. 2004) it is generally more ﬂexible to
resort to Monte Carlo methods (Marjoram and Tavar´e 2006).
One approach is through importance sampling. Here, an instrumental dis-
tribution qφ,y(H) is available that describes the distribution of all genealogical
histories H that are consistent with the data y, as a function of the model
parameters φ. The distribution qφ,y(H) is easy to simulate from and has a

Overview of ABC
35
TABLE 1.3
Inﬁnite Sides Data Simulated with ms in a Format
Suitable for the Genetree Program. The Left Hand
Column Gives the Number of Times the Sequence
on the Right is Observed in the Sample (of Size 30 in
this Case). The Ancestral Type is denoted by 0, and
the Mutant (Derived) Type is Denoted by 1.
The Length of the Sequence is Equal to the Number
of Segregating Sites S and is Equal to the Number of
Mutations that Occurred int he Genealogy. All
Sequences that Share a Mutation at a Given Position
are Descendent (and Possibly Further Mutated)
Copies of the Sequence in which that Mutation First
Occurred. The Sequences are Ordered
Lexicographically
1 : 000000000000000000000001000100000000000000
1 : 000000000000000000001010001000000000101001
1 : 000000000000000100000010001000010000101001
5 : 000000100000100000000000000000000000000000
1 : 000000100000100000000000000000001000000000
2 : 000000100000100000000000000001000000000000
1 : 000000100000100000000000000010000000000000
2 : 000000100000100001000000000000000000000000
2 : 000000100000100010000000000000000000000000
1 : 000000100001100001000000000000000000000000
1 : 000000100100100000100000000000000001000000
1 : 000000100100100000110000000000000000000000
1 : 000000101000100000000100100000000000000110
2 : 000001100010010000000000000000000000000000
2 : 000010010000000000000001010000000000010000
2 : 000100000000000000000000001000100000001000
1 : 001000000000001000000000001000000110101000
1 : 010000100000100000000000000000000000000000
2 : 100000000000000000000010001000000000101001
known functional form that can be directly evaluated. It also has the prop-
erty that p(y|H′) = 1 for H′ ∼qφ,y(H). Hence, p(yobs|φ) can be estimated by:
ˆp(yobs|φ) = 1
N
N

i=0
p(H(i)|φ)
qφ,yobs(H(i))
where H(i) ∼qφ,yobs(H) for i = 1, . . . , N.
In this analysis, we compare an ABC approach to the above impor-
tance sampling method that targets the true likelihood. The aim is to in-
vestigate the performance of diﬀerent summary statistics on ABC inferences,
using the importance sampling-based inferences as a (noisy) ground truth.

36
Handbook of Approximate Bayesian Computation
The demographic model that generates the data is one of smooth exponential
expansion. In this model, the current population size N0 contracts backwards
in time as N0(t) = N0 exp(−βt), where time t is expressed in units of 2N0 and
β = 2N0b is the growth rate in this scaled time. An additional parameter in
the model is the scaled mutation rate θ0 = 4N0μ.
In the ABC analysis, simulations are carried out using the ms program
of Hudson (2002). A technical complication that needs to be accounted for
when using ms is that time in this program is scaled in units of 4N0 rather than
2N0 that appears standardly in most treatments (e.g. Hein et al. 2004), and,
more importantly, in the Genetree importance sampling program (Griﬃths
and Tavare 1994) that is used for the ground truth. The data in Table 1.3
were generated using the ms command:
ms 20 1 -t 50 -G 30,
which simulates one instance of 20 sequences with θ = 50 and α = 30, where
α = β/2 (because of the diﬀerent scaling of time, noted above). Assuming
independent uniform priors U(0, 200) for each parameter φ = (θ0, α)⊤, it
is straightforward to generate particles by sampling parameter values from
the prior and then compute an importance weight for each particle using an
algorithm suggested by Stephens and Donnelly (2000). The implementation
here (described in Maciuca 2003) is a modiﬁcation of the Genetree program to
include the Stephens and Donnelly algorithm, following De Iorio and Griﬃths
(2004). Although the particles could be used directly for weighted density
estimation, it is computationally easier to ﬁrst re-sample them in proportion to
their weights w(i), because the distribution of weights is typically very skewed
(they have high variability). For the data in Table 1.3, N = 108 generated
particles yielded an eﬀective sample size (estimated by (
i w(i))2/ 
i w(i)2)
of around 300. The following analyses are based on re-sampling 1000 particles.
For the ABC analysis, parameter values φ = (θ0, α)⊤are simulated from
the prior, data sets are simulated using ms, and summary statistics computed.
The four summary statistics examined comprise the number of segregating
sites, S0, which corresponds to the number of mutations in the genealogy un-
der the inﬁnite sites mutation model, the average pairwise Hamming distance
between all pairs of sequences in the sample, π0, Tajima’s D, and Fay and
Wu’s H0. These latter two statistics express the diﬀerence in estimates of
the scaled mutation parameter θ0, assuming a standard coalescent model (i.e.
with no population growth), based on two diﬀerent unbiased estimators, one
of which is π0. The average pairwise distance, π0, is directly an estimate of θ0
because in the standard constant size model the expected time to coalescence
for a pair of sequences is 2N0, and therefore the expected number of mutations
occurring down both branches since the common ancestor is (2N0 + 2N0)μ.
Other estimators have been developed, based on the number of segregating
sites (Watterson’s estimator, used in Tajima’s D), or the number of segre-
gating sites weighted by the number of times the mutant type occurs in the
sample (Fu’s estimator, used in Fay and Wu’s H0). Only under the standard

Overview of ABC
37
constant size model will these estimators all have the same expectation, and
therefore deviations between them can be used to identify departures from
this model. Negative values of D and positive values of H0 are expected to be
found in growing populations. The output of the ms program can be piped
to a program sample_stats, included with ms, which computes these four
summary statistics. The observed summary statistics are:
sobs = (π0, S0, D, H0)⊤= (5.90, 42, −1.64, 3.67)⊤.
ABC methods were implemented by ﬁrst simulating N = 1, 000, 000 param-
eter values from the U(0, 200) prior distributions, storing these in the ﬁle
params.txt (in the order indicated by the key-word tbs), and then running
the ms program with the command:
ms 20 1 -t tbs -G tbs < params.txt.
The summary statistics corresponding to these simulated data were then ob-
tained and then ∥s−sobs∥computed as Euclidean distance. The ABC posterior
approximation was obtained by using a uniform kernel Kh over [−h, h] and de-
termining the kernel scale parameter h as the value retaining the 1000 samples
for which s(i) is closest to sobs.
The summary statistics are measured on diﬀerent scales. A common prac-
tice is to centre and scale them using the standard deviation for each summary
statistic sampled from the prior predictive distribution. [However, some au-
thors argue that the motivations for this are ﬂawed, as an arbitrary change in
the prior can change the scaling of a summary statistic within the analysis.
Instead, following a similar discussion to that in Example 6, the scaling should
be based on Cov(s|θ∗) for some value of θ = θ∗in the high posterior density
region, rather than Cov(s). See e.g. Erhardt and Sisson 2016.] For the present
analysis, the prior predictive sample standard deviations for π0, S0, D, and H0
are 14.3, 69.0, 0.50, and 7.3, respectively. In Figure 1.8, the estimated posterior
distributions using both scaled and unscaled summary statistics are shown.
Figure 1.8 compares the resulting ABC posterior approximation using (a)
all four summary statistics, (b) D and H0 only, (c) π0 and S0 only, or (d) π0 or
S0 alone. The ﬁrst point to note is that the data, although quite informative
about θ0 or α jointly, do not allow us to make a very detailed inference about
either parameter individually that is, they are only partially identiﬁable in
the model – at least for these data. This is the case both for the full-likelihood
and ABC inferences, although the density for the full-likelihood method, as
estimated by importance sampling, tends to be more localised towards the
true parameter value (indicated by a +).
When all four summary statistics are used (panel a) the 95% high pos-
terior density envelope for ABC is quite similar to that for importance sam-
pling (black line), but is shifted towards higher values of α and θ0. Scaled
or unscaled summary statistics give similar results. The ABC posterior ap-
proximation for π0 and S0 together (panel b) is very similar to that for the

38
Handbook of Approximate Bayesian Computation
0
50
100
150
200
0
50
100
150
200
Mutation rate θ0
Mutation rate θ0
Mutation rate θ0
Mutation rate θ0
(a)
(b)
(c)
(d)
+
+
+
+
0
50
100
150
200
0
50
100
150
200
Growth rate α
Growth rate α
Growth rate α
Growth rate α
0
50
100
150
200
0
50
100
150
200
0
50
100
150
200
0
50
100
150
200
95%
50%
50%
5%
5%
5%
50%
95%
95%
5%
5%
5%
50%
95%
95%
50%
50%
95%
95%
95%
5%
5%
5%
50%
95%
95%
50%
50%
95%
95%
95%
5%
5%
50%
95%
50%
95%
FIGURE 1.8
Various ABC posterior approximations using diﬀerent summary statistics and
scalings, compared to the ‘ground truth’ importance sampling-based posterior
(black lines). The true parameter value is indicated by a +. Estimates show
the 95%, 50%, and 5% highest posterior density contours. ABC posteriors are
based on (a) all four summary statistics; (b) π0 and S0 only; (c) D and H0
only; and (d) π0 (light grey dotted) and S0 (dark grey dotted). For panels
(a)–(c) the ABC posterior is based on scaled summary statistics (dark grey
dotted line), and unscaled summary statistics (light grey dotted line).
full set of summary statistics. In this case, the distances for scaled and un-
scaled summaries are the same because S is discrete and matched exactly.
This outcome perhaps indicates that one should be cautious of adding sum-
maries such as Tajima’s D because it is simply a non-linear function of π0
and S0. Whereas H0 includes additional information from the site frequency
spectrum, and would be expected to be informative (positive H0 indicates
a deﬁcit of high-frequency derived mutations compared with that expected
under the standard model). Using D and H0 together (panel c) yields a less

Overview of ABC
39
TABLE 1.4
Data from Locus 9pMB8 Surveyed in 11 Biaka
Pygmies (Hammer et al. 2010), Using the Same
Layout as for Table 1.3
1 : 000000000000000000000000000000000010100001
1 : 000000000000000000000000001000000000000010
1 : 000000000000000000000001010100111001000100
4 : 000000000000000011010000000100000000000000
1 : 000000000000000111010010000100000100000000
4 : 000000000000000111010010000101000100000000
1 : 000000000000010000000000000000000000000000
1 : 000000000000100111010000000100000000000000
1 : 000000000001000000000000010100000000001100
1 : 000000000010000000000000010100000000000100
1 : 000000000100001000000100100000000010000000
1 : 000000010000000000000000000000000010100001
1 : 000100001000000000000000000100000000000100
1 : 001000000001000000101000010100000000010100
1 : 010001100000000000000000001000000000000000
1 : 100010000000000011010000000110000000000000
concentrated posterior approximation. Both statistics are based on the dif-
ference of two estimators of mutation rate, and therefore it is unsurprising
that θ0 is not well localised. The posteriors based on π0 and S0 individually
(panel d), superﬁcially look surprisingly similar to the full-likelihood poste-
rior. However there is much stronger support for larger values of θ0 and α
than in the importance-sampling based posterior.
We conduct a similar analysis with sequence data published in Hammer
et al. (2010) from locus 9pMB8 surveyed in 11 Biaka pygmies (resulting in
22 sequences). The data are shown in Table 1.4. Like the simulated data
above, there are 42 sites that are segregating within the Biaka sample and
which are compatible with the inﬁnite sites model. The ABC simulations
were performed as previously, using all four summary statistics. The observed
summary statistics for these data are:
sobs = (π0, S0, D, H0)⊤= (7.52, 42, −1.35, 4.0)⊤.
The posterior computed using importance sampling was also computed as
before, but required 12 × 108 particles to achieve a similar eﬀective sample
size to that for the previous dataset.
It is immediately apparent from Figure 1.9 that the ABC posterior ap-
proximation and ground-truth posterior are very similar, unlike the previous
analysis. This diﬀering behaviour is not due to Monte Carlo error. The result
illustrates a point that outside the exponential family there is no single, low-
dimensional set of summary statistics s that will be highly informative for θ,
for all observed datasets. Summary statistics that work well for one dataset

40
Handbook of Approximate Bayesian Computation
0
50
100
150
200
0
50
100
150
200
Mutation rate θ0
Growth rate α
95%
95%
95%
50%
50%
50%
5%
5%
5%
95% 95%
95%
FIGURE 1.9
Comparison of ABC posterior approximations (dotted lines) and full-
likelihood (black lines) posterior for the Biaka pygmy data in Table 1.4. ABC
posterior approximations are based on all four summary statistics, which are
scaled (dark grey dotted line) and unscaled (light grey dotted line).
may perform less well on another. In the case of the two datasets considered
here, it may be argued that in the latter, despite the smaller sample size, there
is a stronger signal of growth in these data, which is more readily captured by
the summary statistics. For the simulated data, the signal is less strong, and
information in other summary statistics, such as the site frequency spectrum
or higher moments of the distribution of pairwise Hamming distances, may
be required for the ABC posterior to better match the true posterior.
From a computational perspective, the 106 ABC simulations took about
3 minutes on a desktop computer, whereas 108 importance sampling sim-
ulations took around 4 hours, i.e. the computational eﬀort per iteration is
broadly similar for both approaches. The algorithms used in each are ‘sim-
ilar yet diﬀerent’, in that they both generate genealogical trees, but in one
case the tree is constrained by the data, and in the other it is independent
of the data. Naively one might think that an importance sampling algorithm
should be more eﬃcient because it always generates a tree that is compatible
with the data. However, it is typically very diﬃcult to devise an algorithm
that samples trees in proportion to their conditional distribution under the
model, and therefore genealogical importance sampling tends to be ineﬃcient,
as illustrated here, where 108 simulations only give an eﬀective sample size of

Overview of ABC
41
around 300. Of course, it is possible to use sequential methods, or a pseudo-
marginal method to improve eﬃciency (Beaumont 2003; Cornuet et al. 2012;
Andrieu et al. 2019a), but similar approaches are available for ABC as well.
1.9
Levels of Approximation in ABC
The primary challenge in implementing an ABC analysis is to reduce the
impact of the approximation, while restricting the required computation to
acceptable levels. In eﬀect, this is the usual ‘more computation for more
accuracy’ tradeoﬀ. It is therefore worthwhile to brieﬂy summarise the quality
and nature of the approximations involved in any ABC analysis. While some
of these approximations are common with standard Bayesian analyses, in par-
ticular points 1 and 5 below, within the ABC framework these have additional,
more subtle implications. In order, from model conception to implementation
of the analysis, the ABC approximations are:
1. All models are approximations to the real data-generation process.
While this is true for any statistical analysis, this approximation can pro-
duce an ABC-speciﬁc issue if the assumed model is not suﬃciently ﬂexible
to be able to reproduce the observed summary statistics. In this scenario,
the kernel scale parameter h will necessarily be large (as all simulated data
are far from the observed data), and as a consequence, the quality of the
ABC approximation may be low. Further, if, for this inﬂexible model, the
observed summary statistics contain conﬂicting information for a model
parameter, this may cause additional bias in the posterior approximation
for this parameter, as is illustrated in Example 5. In summary, this means
that the more unlikely a model is to have generated the observed data, the
worse the ABC approximation will be. In general, this is problematic, as
it implies that routine inspection of the ﬁtted ABC posterior may not in
itself be enough to determine model adequacy, as the ABC posterior may
be a poor estimate of the true posterior, and poor data generation models
may appear more likely (with h > 0) than they actually are (with h = 0).
By extension, this also implies that posterior model probabilities of inad-
equate models (constructed from the normalising constant of the poorly
estimated ABC posterior distribution) may also be aﬀected, although this
has yet to be fully explored in the literature. See Chapter 10, in this hand-
book for an exploration of related ABC asymptotics results to date, and
Chapter 6 for particular methods for performing ABC model choice.
2. Use of summary statistics rather than full datasets.
The full posterior distribution π(θ|yobs) ∝p(yobs|θ)π(θ) is replaced by
the partial posterior π(θ|sobs) ∝p(sobs|θ)π(θ), where sobs = S(yobs) is

42
Handbook of Approximate Bayesian Computation
a vector of summary statistics. If S is suﬃcient for θ, then there is no
approximation at this stage. More commonly, for non-suﬃcient S, there is
a loss of information.
3. Weighting of summary statistics within a region of the observed summary
statistics.
The partial posterior π(θ|sobs) is replaced by the ABC approximation to
the partial posterior:
πABC(θ|sobs) ∝π(θ)

Kh(∥s −sobs∥)p(s|θ)ds,
where Kh is a standard smoothing kernel with scale parameter h ≥0. If
h = 0 or in the limit as h →0 then there is no further approximation at this
stage. In most cases, however, h > 0 and so ABC makes use of a kernel den-
sity estimate as an approximation to the true likelihood function. This as-
pect of approximation can be a particular problem in ABC when the num-
ber of model parameters θ is large, as then the vector of summary statistics,
s, must be equivalently large for parameter identiﬁability, and, hence, the
comparison ∥s −sobs∥will suﬀer from the curse of dimensionality.
4. Approximations due to other ABC techniques.
There are a number of other ABC techniques not discussed in this chap-
ter that are optionally implemented in ABC analyses in order to improve
some aspect of the approximations in points 1 and 2 or to achieve a greater
computational performance. Many of these are discussed in later chapters,
but some common methods involve post-processing techniques such as re-
gression and marginal adjustments (e.g. Beaumont et al. 2002; Blum and
Fran¸cois 2010; Blum et al. 2013; Blum 2019; Nott et al. 2019), or develop
alternative approximations to the intractable likelihood function, while
remaining in the ABC framework, such as expectation-propagation ABC,
synthetic likelihoods, and copula or regression-density estimation models
(e.g. Wood 2010; Fan et al. 2013; Barthelm´e and Chopin 2014; Barthelm´e
et al. 2019; Li et al. 2017; Price et al. 2017).
5. Monte Carlo error.
In common with most Bayesian analyses, performing integrations using
Monte Carlo methods introduces Monte Carlo error. Typically, this error
may be reduced by using larger numbers of samples from the posterior or
by reducing the variability of importance weights. The same is true for
an ABC analysis, although with the additional point that more posterior
samples eﬀectively allow for a lower kernel scale parameter h and conse-
quently an improved ABC posterior approximation. As a result, for a ﬁxed
number of Monte Carlo samples, the choice of kernel scale parameter rep-
resents a typical bias-variance tradeoﬀ: if h is large, more posterior draws

Overview of ABC
43
are available, reducing variance, but at the cost of a poorer ABC approx-
imation; if h is small, the ABC posterior approximation is improved, but
Monte Carlo variance is increased.
1.10
Interpretations of ABC
There are a number of closely related ways in which ABC methods may be
understood or interpreted. The most common of these is conditional density
estimation of the posterior (e.g. Blum 2010; Bonassi et al. 2011) in the sense
usually understood in a conventional Bayesian analysis. Before observing the
data, the distribution π(θ, y) = p(y|θ)π(θ) describes prior beliefs about the
model parameters and credible datasets under the model. When a dataset
yobs is observed, interest is then in the conditional distribution of θ given
that y = yobs. In the ABC setting, π(θ, y) is represented by the joint sample
(θ(i), y(i)) ∼π(θ, y), i = 1, . . . , N. Weighting the vectors θ(i) based on the
value of ∥y(i) −yobs∥(larger weights for smaller ∥y(i) −yobs∥), then produces
an empirical conditional density estimate of π(θ|yobs).
Similarly, we have already discussed that the ABC approximation to the
true likelihood, pABC(yobs|θ), is a kernel density estimate of p(y|θ), follow-
ing (1.7) and (1.8). This allows ABC to be considered as a regular Bayesian
analysis with an approximated likelihood function.
Fearnhead and Prangle (2012) noted that the ABC approximation to the
posterior can be considered as a continuous mixture of posterior distributions:
πABC(θ|yobs)
∝

Kh(∥y −yobs∥)p(y|θ)π(θ)dy
=

w(y)π(θ|y)dy,
where π(θ|y) = p(y|θ)π(θ)/π(y), with weight function w(y) ∝Kh(∥y −
yobs∥)π(y). This is the continuous equivalent of equation (1.2) obtained during
the analysis of stereological extremes in Section 1.3.2.
While ABC is most often thought of as an approximate method, Wilkinson
(2013) pointed out that ABC methods can be considered as exact if e = y−yobs
(or e = ∥y −yobs∥) is considered as the error (either from observation error or
model misspeciﬁcation) obtained in ﬁtting the model p(y|θ) to the observed
data yobs. From this perspective, the smoothing kernel Kh is simply the den-
sity function of this error, so that e ∼Kh, and h is a scale parameter to be
estimated.
Finally, while ABC methods are universally used for the analysis of models
with computationally intractable likelihood functions, it is often overlooked
that they also provide a useful inferential mechanism for tractable models.

44
Handbook of Approximate Bayesian Computation
As an illustration, consider a scenario where a standard Bayesian analysis is
available for a complex, but incorrect model, given the observed dataset. Under
this model, predictions of some particular quantity of interest, T(y), could be
precise, but completely implausible due to the limitations in the model. Con-
sider now an ABC analysis based on this model, based on matching summary
statistics that include T(y). ABC methods would identify those parameter val-
ues θ that are most likely to have produced these statistics under the model.
This means that predictions of T(y) under the ABC approximation now have
some chance of being accurate (although they may be less precise), as the
model may be able to predict the summary statistics, including T(y), even if
it can’t accurately predict the full dataset. This allows ABC to be interpreted
as a mechanism for ﬁtting models based on summary statistics that may in fact
be more useful than the exact inference with the full dataset. An explicit exam-
ple of this in the robust model selection context was given by Li et al. (2017).
Related arguments allow ABC to be thought of as a natural method to ﬁt
models when the full dataset (yobs) is only partially observed (sobs) and has
missing data (see e.g. Chapter 16, this volume). ABC methods have also been
used to determine weakly informative prior distributions in a regular tractable
Bayesian analysis, exploiting the mechanism of predictive data matching to
identify a priori non-viable regions of the parameter space (Nott et al. 2016).
1.11
Further Reading
ABC methods have been extensively and rapidly developed since their ﬁrst
modern appearance in Tavar´e et al. (1997) and Pritchard et al. (1999). Nat-
urally a number of review articles have been written for various discipline
audiences to review the techniques available at the time. While with time
such reviews can rapidly become dated, they often provide useful perspec-
tives on ABC methods as viewed at the time. See, for example, the reviews
by Beaumont (2010), Bertorelle et al. (2010), Blum et al. (2013), Csill´ery
et al. (2010), Sisson and Fan (2011), Marin et al. (2012), Turner and Zandt
(2012), Robert (2016), Erhardt and Sisson (2016), Lintusaari et al. (2016), and
Drovandi (2017). Each of the chapters in this handbook also makes for excel-
lent reading and review material on focused aspects of ABC (Andrieu et al.
2019b; Barthelm´e et al. 2019; Blum 2019; Drovandi 2019; Drovandi et al. 2019;
Fan and Sisson 2019; Fearnhead 2019; Kousathanas et al. 2019; Marin et al.
2019; Nott et al. 2019; Prangle 2019; Ratmann et al. 2019; Tavar´e 2019).
Because ABC methods are now recognised as a standard Bayesian tool,
their scientiﬁc reach has eﬀectively become as extensive as standard Bayesian
methods. While it is accordingly futile to exhaustively describe all areas in
which ABC has applied, the below selection is provided to provide a ﬂavour of
the impact ABC methods have had. Beyond the applications in this handbook,

Overview of ABC
45
ABC methods have been successfully applied to applications in α-stable
models (Peters et al. 2012), archaeology (Wilkinson and Tavar´e 2009), cell
biology (Johnston et al. 2014; Vo et al. 2015a,b), coalescent models (Tavar´e
et al. 1997; Fan and Kubatko 2011), ecology (Jabot and Chave 2009; Wood
2010), evolutionary history of mosquitos (Bennett et al. 2016), ﬁltering (Jasra
et al. 2012), extreme value theory (Erhardt and Smith 2012; Erhardt and
Sisson 2016), ﬁnancial modelling (Peters et al. 2012), host-parasite systems
(Baudet et al. 2015), HIV contact tracing (Blum and Tran 2010), human evo-
lution (Fagundes et al. 2007), hydrological models (Nott et al. 2014), infectious
disease dynamics (Luciani et al. 2009; Aandahl et al. 2012), inﬁnite mixture
models for biological signalling pathways (Koutroumpas et al. 2016), image
analysis (Nott et al. 2014), long range dependence in stationary processes
(Andrade and Rifo 2015), operational risk (Peters and Sisson 2006), quantile
distributions (Allingham et al. 2009; Drovandi and Pettitt 2011), pathogen
transmission (Tanaka et al. 2006), phylogeography (Beaumont et al. 2010),
protein networks (Ratmann et al. 2007, 2009), population genetics (Beaumont
et al. 2002), psychology (Turner and Zandt 2012), single cell gene expression
(Lenive et al. 2016), spatial point processes (Shirota and Gelfand 2016), species
migration (Hamilton et al. 2005), state space models (Vakilzadeh et al. 2017),
stochastic claims reserving (Peters et al. 2012), susceptible-infected-removed
(SIR) models (Toni et al. 2009), trait evolution (Slater et al. 2012), and wire-
less communications engineering (Peters et al. 2010). Within this handbook
novel analyses can be found in Peters et al. (2019), Rodrigues et al. (2019),
Liepe and Stumpf (2019), Estoup et al. (2019), Holden et al. (2019), Fasiolo
and Wood (2019) and Fan et al. (2019).
1.12
Conclusion
ABC methods are based on an inherently simple mechanism, simulating data
under the model of interest and comparing the output to the observed dataset.
While more sophisticated ABC algorithms and techniques have subsequently
been developed (and many of these are discussed in more detail in this hand-
book), this core mechanic remains a constant. It is this methodological sim-
plicity that has made ABC methods highly accessible to researchers in across
many disciplines. We anticipate that this will continue in the future.
Acknowledgements
SAS is supported by the Australian Research Council under the Discovery
Project scheme (DP160102544) and the Australian Centre of Excellence in
Mathematical and Statistical Frontiers (CE140100049).

46
Handbook of Approximate Bayesian Computation
References
Aandahl, R. Z., J. Reyes, S. A. Sisson, and M. M. Tanaka (2012). A model-
based Bayesian estimation of the rate of evolution of VNTR loci in
Mycobacterium Tuberculosis. PLoS Computational Biology 8, e1002573.
Allingham, D. R., A. R. King, and K. L. Mengersen (2009). Bayesian estima-
tion of quantile distributions. Statistics and Computing 19, 189–201.
Anderson, C. W. and S. G. Coles (2002). The largest inclusions in a piece of
steel. Extremes 5, 237–252.
Andrade, P. and L. Rifo (2015). Long-range dependence and approximate
Bayesian computation. Communications in Statistics: Simulation and
Computation, in press.
Andrieu, C., A. Lee, and M. Vihola (2019a). Theoretical and methodological
aspects of MCMC computations with noisy likelihoods. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Markov chain Monte
Carlo. Chapman & Hall/CRC Press, Boca Raton, FL.
Andrieu, C., A. Lee, and M. Vihola (2019b). Theoretical and methodological
aspects of MCMC computations with noisy likelihoods. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Baddeley, A. and E. B. V. Jensen (2004). Stereology for Statisticians.
Chapman & Hall/CRC Press, Boca Raton, FL.
Barthelm´e, S. and N. Chopin (2014). Expectation propagation for likelihood-
free inference. Journal of the American Statistical Association
109,
315–333.
Barthelm´e, S., N. Chopin, and V. Cottet (2019). Divide and conquer in ABC:
Expectation-Propagation algorithms for likelihood-free inference. In S. A.
Sisson, Y. Fan, and S. A. Sisson (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Baudet, C., B. Donati, C. Sinaimeri, P. Crescenzi, C. Gautier, C. Matias,
and M.-F. Sagot (2015). Cophylogeny reconstruction via an approximate
Bayesian computation. Systematic Biology 64, 416–431.
Beaumont, M. A. (2003). Estimation of population growth or decline in ge-
netically monitored populations. Genetics 164(3), 1139–1160.
Beaumont, M. A. (2010). Approximate Bayesian computation in evolution and
ecology. Annual Review of Ecology, Evolution and Systematics 41, 379–406.

Overview of ABC
47
Beaumont, M. A., R. Nielsen, C. P. Robert, J. Hey, O. Gaggiotti, L. Knowles,
A. Estoup, et al. (2010). In defence of model-based inference in phylogeog-
raphy. Molecular Ecology 19, 436–466.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162, 2025–2035.
Bennett, K. L., F. Shija, Y.-M. Linton, G. Misinzo, M. Kaddumukasa,
R. Djouaka, O. Anyaele, et al. (2016). Historical environmental change
in Africa drives divergence and admixture of aedes aegypti mosquitoes:
A precursor to successful worldwide colonization? Molecular Ecology 25,
4337–4354.
Bertorelle, G., A. Benazzo, and S. Mona (2010). Abc as a ﬂexible framework
to estimate demography over space and time: Some cons, many pros.
Molecular Ecology 19, 2609–2625.
Blum, M. G. B. (2010). Approximate Bayesian computation: A non-
parametric perspective. Journal of the American Statistical Associa-
tion 105, 1178–1187.
Blum, M. G. B. (2019). Regression approaches for ABC. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Blum, M. G. B. and O. Fran¸cois (2010). Non-linear regression models for
approximate Bayesian computation. Statistics and Computing 20, 63–75.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson (2013).
A comparative review of dimension reduction methods in approximate
Bayesian computation. Statistical Science 28, 189–208.
Blum, M. G. B. and V. C. Tran (2010). HIV with contact-tracing: A case
study in approximate Bayesian computation. Biostatistics 11, 644–660.
Bonassi, F. V., L. You, and M. West (2011). Bayesian learning from marginal
data in bionetwork models. Statistical Applications in Genetics and
Molecular Biology 10(1).
Bortot, P., S. G. Coles, and S. A. Sisson (2007). Inference for stereological
extremes. Journal of the American Statistical Association 102, 84–92.
Brooks, S. P., A. Gelman, G. Jones, and X.-L. Meng (Eds.) (2011). Handbook
of Markov Chain Monte Carlo. Chapman & Hall/CRC Press, Boca
Raton, FL.
Chen, M.-H., Q.-M. Shao, and J. G. Ibrahim (2000). Monte Carlo Methods
in Bayesian Computation. Springer-Verlag.
Coles, S. G. (2001). An Introduction to Statistical Modelling of Extreme
Values. Springer-Verlag.

48
Handbook of Approximate Bayesian Computation
Cornuet, J., J.-M. Marin, A. Mira, and C. P. Robert (2012). Adaptive multiple
importance sampling. Scandinavian Journal of Statistics 39(4), 798–812.
Csill´ery, K., M. G. B. Blum, O. E. Gaggiotti, and O. Fran¸cois (2010).
Approximate Bayesian computation in practice. Trends in Ecology and
Evolution 25, 410–418.
De Iorio, M. and R. C. Griﬃths (2004). Importance sampling on coalescent
histories. i. Advances in Applied Probability 36, 417–433.
Del Moral, P., A. Doucet, and A. Jasra (2006). Sequential Monte Carlo
samplers. Journal of the Royal Statistical Society, Series B 68, 411–436.
Doucet, A., N. de Freitas, and N. Gordon (2001). Sequential Monte Carlo
Methods in Practice. Springer-Verlag.
Drovandi, C. C. (2012). Bayesian Algorithms with Applications. Ph. D. thesis,
Queensland University of Technology.
Drovandi, C. C. (2017). Approximate Bayesian computation. Wiley StatsRef:
Statistics Reference Online, 1–9.
Drovandi, C. C. (2019). ABC and indirect inference. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Drovandi, C. C., C. Grazian, K. Mengersen, and C. P. Robert (2019).
Approximating the likelihood in approximate Bayesian computation. In
S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Drovandi, C. C. and A. N. Pettitt (2011). Likelihood-free Bayesian estimation
of multivariate quantile distributions. Computational Statistics and Data
Analysis 55, 2541–2556.
Erhardt, R. and S. A. Sisson (2016). Modelling extremes using approximate
Bayesian computation. In Extreme Value Modelling and Risk Analysis.
Chapman & Hall/CRC Press.
Erhardt, R. and R. L. Smith (2012). Approximate Bayesian computing
for spatial extremes. Computational Statistics & Data Analysis
56,
1468–1481.
Estoup, A., P. Verdu, J.-M. Marin, C. P. Robert, A. Dehne-Garcia, J.-M.
Corunet, and P. Pudlo (2019). Application of approximate Bayesian
computation to infer the genetic history of Pygmy hunter-gatherers
populations from West Central Africa. In S. A. Sisson, Y. Fan, and M. A.
Beaumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.

Overview of ABC
49
Fagundes, N. J. R., N. Ray, M. A. Beaumont, S. Neuenschwander, F. M.
Salzano, S. L. Bonatto, and L. Excoﬃer (2007). Statistical evaluation
of alternative models of human evolution. Proceedings of the National
Academy of Science of the United States of America 104, 17614–17619.
Fan, H. H. and L. S. Kubatko (2011). Estimating species trees using approx-
imate Bayesian computation. Molecular Phylogenetics and Evolution 59,
354–363.
Fan, Y., S. R. Meikle, G. Angelis, and A. Sitek (2019). ABC in nuclear
imaging. In S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of
Approximate Bayesian Computation. Chapman & Hall/CRC Press, Boca
Raton, FL.
Fan, Y., D. J. Nott, and S. A. Sisson (2013). Approximate Bayesian
computation via regression density estimation. Stat 2(1), 34–48.
Fan, Y. and S. A. Sisson (2019). ABC samplers. In S. A. Sisson, Y. Fan, and
M. A. Beaumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Fasiolo, M. and S. N. Wood (2019). ABC in ecological modelling. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Fearnhead, P. (2019). Asymptotics of ABC. In S. A. Sisson, Y. Fan, and
M. A. Beaumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for ap-
proximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society, Series B 74, 419–474.
Grelaud, A., C. P. Robert, J.-M. Marin, F. Rodolphe, and J.-F. Taly (2009).
ABC likelihood-free methods for model choice in Gibbs random ﬁelds.
Bayesian Analysis 4, 317–336.
Griﬃths, R. C. and S. Tavare (1994). Sampling theory for neutral alleles in
a varying environment. Philosophical Transactions of the Royal Society B:
Biological Sciences 344(1310), 403–410.
Hamilton, G., M. Currat, N. Ray, G. Heckel, M. A. Beaumont, and
L. Excoﬃer (2005). Bayesian estimation of recent migration rates after a
spatial expansion. Genetics 170, 409–417.
Hammer, M. F., A. E. Woerner, F. L. Mendez, J. C. Watkins, M. P. Cox,
and J. D. Wall (2010). The ratio of human X chromosome to autosome
diversity is positively correlated with genetic distance from genes. Nature
Genetics 42(10), 830–831.

50
Handbook of Approximate Bayesian Computation
Hein, J., M. Schierup, and C. Wiuf (2004). Gene Genealogies, Variation
and Evolution: A Primer in Coalescent Theory. Oxford University Press,
Oxford.
Hoaglin, D. C. (1985). Summarizing shape numerically: The g-and-h distri-
butions. In D. C. Hoaglin, F. Mosteller, and J. W. Tukey (Eds.), Exploring
Data Tables, Trends and Shapes. Wiley, New York.
Holden, P. B., N. R. Edwards, J. Hensman, and R. D. Wilkinson (2019). ABC
for climate: dealing with expensive simulators. In S. A. Sisson, Y. Fan, and
M. A. Beaumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Hudson, R. R. (2002). Generating samples under a wright–ﬁsher neutral
model of genetic variation. Bioinformatics 18(2), 337–338.
Jabot, F. and J. Chave (2009). Inferring the parameters of the netural theory
of biodiversity using phylogenetic information and implications for tropical
forests. Ecology Letters 12, 239–248.
Jasra, A., S. Singh, J. Martin, and E. McCoy (2012). Filtering via ABC.
Statistics and Computing 22, 1223–1237.
Johnston, S., M. J. Simpson, D. L. S. McEwain, B. J. Binder, and J. V.
Ross (2014). Interpreting scratch assays using pair density dynamics and
approximate Bayesian computation. Open Biology 4(9), 140097.
Koutroumpas, K., P. Ballarini, I. Votsi, and P.-H. Cournede (2016). Bayesian
parameter estimation for the Wnt pathway: An inﬁnite mixture models
approach. Bioinformatics 32, 781–789.
Kousathanas, A., P. Duchen, and D. Wegmann (2019). A guide to general
purpose ABC software. In S. A. Sisson, Y. Fan, and M. A. Beaumont
(Eds.), Handbook of Approximate Bayesian Computation. Chapman &
Hall/CRC Press, Boca Raton, FL.
Lenive, O., P. D. W. Kirk, and M. P. H. Stumpf (2016). Inferring extrinsic
noise from single-cell gene expression data using approximate Bayesian
computation. BMC Systems Biology 10, 81.
Li, J., D. J. Nott, Y. Fan, and S. A. Sisson (2017). Extending approximate
Bayesian computation methods to high dimensions via Gaussian copula.
Computational Statistics and Data Analysis 106, 77–89.
Liepe, J. and M. P. H. Stumpf (2019). ABC in systems biology. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Chapman & Hall/CRC Press, Boca Raton, FL.

Overview of ABC
51
Lintusaari, J., M. U. Gutmann, R. Dutta, S. Kaski, and J. Corander
(2016). Fundamentals and recent developments in approximate Bayesian
computation. Systematic Biology, in press.
Luciani, F., S. A. Sisson, H. Jiang, A. R. Francis, and M. M. Tanaka (2009).
The epidemiological ﬁtness cost of drug resistance in Mycobacterium
tuberculosis. Proceedings of the National Academy of the Sciences of the
United States of America 106, 14711–14715.
Maciuca, S. (2003). Project report.
Marin, J. M., P. Pudlo, C. P. Robert, and R. J. Ryder (2012). Approx-
imate Bayesian computational methods. Statistics and Computing 22,
1167–1180.
Marin, J.-M., P. Pudlo, A. Estoup, and C. P. Robert (2019). Likelhood-free
model choice. In S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.),
Handbook of Approximate Bayesian Computation. Chapman & Hall/CRC
Press, Boca Raton, FL.
Marjoram, P. and S. Tavar´e (2006). Modern computational approaches for
analysing molecular genetic variation data. Nature Reviews Genetics 7(10),
759–770.
Martinez, J. and B. Iglewicz (1984). Some properties of the Tukey g and
h family of distributions. Communications in Statistics: Theory and
Methods 13, 353–369.
Møller, J., A. N. Pettitt, R. Reeves, and K. Berthelsen (2006). An eﬃcient
Markov chain Monte Carlo method for distributions with intractable
normalising constants. Biometrika 93, 451–458.
Nott, D. J., C. C. Drovandi, K. Mengersen, and M. Evans (2016). Approx-
imation of Bayesian predictive p-values with regression ABC. Bayesian
Analysis, in press.
Nott, D. J., Y. Fan, L. Marshall, and S. A. Sisson (2014). Approxi-
mate Bayesian computation and Bayes linear analysis: Towards high-
dimensional ABC. Journal of Computational and Graphical Statistics 23,
65–86.
Nott, D. J., V. M.-H. Ong, Y. Fan, and S. A. Sisson (2019). High-dimensional
ABC. In S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of
Approximate Bayesian Computation. Chapman & Hall/CRC Press, Boca
Raton, FL.
Peters, G. W., Y. Fan, and S. A. Sisson (2012). On sequential Monte Carlo,
partial rejection control and approximate Bayesian computation. Statistics
and Computing 22, 1209–1222.

52
Handbook of Approximate Bayesian Computation
Peters, G. W., I. Nevat, S. A. Sisson, Y. Fan, and J. Yuan (2010). Bayesian
symbol detection in wireless relay networks via likelihood-free inference.
IEEE Transactions on Signal Processing 56, 5206–5218.
Peters, G. W., E. Panayi, and F. Septier (2019). SMC-ABC methods for
estimation of stochastic simulation models of the limit order book. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Peters, G. W. and S. A. Sisson (2006). Bayesian inference, Monte Carlo
sampling and operational risk. Journal of Operational Risk 1, 27–50.
Peters, G. W., S. A. Sisson, and Y. Fan (2012). Likelihood-free Bayesian infer-
ence for α-stable models. Computational Statistics and Data Analysis 56,
3743–3756.
Prangle,
D.
(2017).
Adapting
the
ABC
distance
function.
Bayesian
Analysis 12, 289–309.
Prangle, D. (2019). Summary statistics in approximate Bayesian computa-
tion. In S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of
Approximate Bayesian Computation. Chapman & Hall/CRC Press, Boca
Raton, FL.
Price, L. F., C. C. Drovandi, A. Lee, and D. J. Nott (2017). Bayesian synthetic
likelihood. Journal of Computational and Graphical Statistics, in press.
Pritchard, J. K., M. T. Seielstad, A. Perez-Lezaun, and M. W. Feldman
(1999). Population growth of human Y chromosomes: A study of Y
chromosome microsatellites. Molecular Biology and Evolution 16(12),
1791–1798.
Ratmann, O., C. Andrieu, T. Hinkley, C. Wiuf, and S. Richardson (2009).
Model criticism based on likelihood-free inference, with an application
to protein network evolution. Proceedings of the National Academy of
Sciences of the United States of America 106, 10576–10581.
Ratmann, O., A. Camacho, S. Hu, and C. Colijn (2019). Informed choices:
How to calibrate ABC with hypothesis testing. In S. A. Sisson, Y. Fan, and
M. A. Beaumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Ratmann, O., O. Jorgensen, T. Hinkley, M. Stumpf, S. Richardson, and
C. Wiuf (2007). Using likelihood-free inference to compare evolutionary
dynamics of the protien networks of h. pylori and p. falciparum. PLoS
Computational Biology 3, e230.
Rayner, G. and H. MacGillivray (2002). Weighted quantile-based estimation
for a class of transformation distributions. Computational Statistics &
Data Analysis 39(4), 401–433.

Overview of ABC
53
Robert, C. P. (2016). Approximate Bayesian computation: A survey on recent
results. In R. Cools and D. Nuyens (Eds.), Monte Carlo and Quasi-Monte
Carlo Methods, pp. 185–205. Springer.
Rodrigues, G. S., A. R. Francis, S. A. Sisson, and M. M. Tanaka (2019).
Inferences on the acquisition of multidrug resistance in mycobacterium
tuberculosis using molecular epidemiological data. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Scott, D. W. (1992). Multivariate Density Estimation: Theory, Practice and
Visualisation. John Wiley & Sons.
Shirota, S. and A. E. Gelfand (2016). Approximate Bayesian compu-
tation
and
model
validation
for
repulsive
spatial
point
processes.
https://arxiv.org/abs/1604.07027.
Sisson, S. A. and Y. Fan (2011). Likelihood-free Markov chain Monte Carlo.
In Handbook of Markov chain Monte Carlo, pp. 219–341. Chapman &
Hall/CRC Press, Boca Raton, FL.
Slater, G. J., L. J. Harmon, D. Wegmann, P. Joyce, L. J. Revell, and M. E.
Alfaro (2012). Fitting models of continuous trait evolution to incompletely
sampled comparative data using approximate Bayesian computation.
Evolution 66, 752–762.
Stephens, M. and P. Donnelly (2000). Inference in molecular population
genetics. Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 62(4), 605–635.
Tanaka, M. M., A. R. Francis, F. Luciani, and S. A. Sisson (2006). Using
Approximate Bayesian Computation to estimate tuberculosis transmission
parameters from genotype data. Genetics 173, 1511–1520.
Tavar´e, S. (2019). On the history of ABC. In S. A. Sisson, Y. Fan, and
M. A. Beaumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Tavar´e, S., D. J. Balding, R. C. Griﬃths, and P. Donnelly (1997). Inferring
coalescence times from DNA sequence data. Genetics 145, 505–518.
Toni, T., D. Welch, N. Strelkowa, A. Ipsen, and M. P. H. Stumpf (2009).
Approximate Bayesian computation scheme for parameter inference and
model selection in dynamical systems. Journal of the Royal Society
Interface 6, 187–202.
Tukey, J. W. (1977). Modern techniques in data analysis. In NSF-Sponsored
Regional Research Conference. Southeastern Massachusetts University,
North Dartmouth, MA.
Turner, B. M. and T. V. Zandt (2012). A tutorial on approximate Bayesian
computation. Journal of Mathematical Psychology 56, 69–85.

54
Handbook of Approximate Bayesian Computation
Vakilzadeh, M. K., Y. Huang, J. L. Beck, and T. Abrahamsson (2017). Ap-
proximate Bayesian computation by subset simulation using hierarchical
state space models. Mechanical Systems and Signal Processing 84, 2–20.
Vo, B. N., C. C. Drovandi, A. N. Pettitt, and G. J. Pettet (2015a).
Melanoma
cell
colony
expansion
parameters
revealed
by
approxi-
mate
Bayesian
computation.
PLoS
Computational
Biology
11(12),
e1004635.
Vo, B. N., C. C. Drovandi, A. N. Pettitt, and M. J. Simpson (2015b).
Quantifying uncertainty in parameter estimates for stochastic models
of collective cell spreading using approximate Bayesian computation.
Mathematical Biosciences 263, 133–142.
Wand, M. P. and M. C. Jones (1995). Kernel Smoothing. Chapman &
Hall/CRC Press, Boca Raton, FL.
Wicksell, S. D. (1925). The corpsucle problem: A mathematical study of a
biometric problem. Biometrika 17, 84–99.
Wilkinson, R. D. and S. Tavar´e (2009). Estimating primate divergence times
by using conditioned birth-and-death processes. Theoretical Population
Biology 75, 278–285.
Wilkinson, R. L. (2013). Approximate Bayesian computation (ABC) gives
exact results under the assumption of model error. Statistical Applications
in Genetics and Molecular Biology 12, 129–141.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological
dynamic systems. Nature 466, 1102–1104.

2
On the History of ABC
Simon Tavar´e
CONTENTS
2.1
Introduction ......................................................
55
2.2
Coalescent Trees and Mutation ..................................
55
2.3
Statistical Inference ..............................................
59
2.4
Computationally Intensive Methods .............................
60
2.5
A Bayesian Approach ............................................
62
2.6
ABC Takes Oﬀ...................................................
64
2.7
Conclusion ........................................................
65
2.8
Acknowledgements ...............................................
66
References
...............................................................
66
2.1
Introduction
What follows is a personal view of the evolution of ABC – approximate
Bayesian computation – up to 2003 and it is certainly not intended to be an
exhaustive review. ABC arose as an inferential method in population genetics
to address estimation of parameters of interest such as mutation rates and de-
mographic parameters in cases where the underlying probability models had
intractable likelihoods. To set the scene I will give a very brief introduction to
genealogical trees and the eﬀects of mutation, focusing on the simplest case in
which a panmictic population is assumed to be very large and of constant size
N and within which there is no recombination. The treatment follows that
in Tavar´e (2004).
2.2
Coalescent Trees and Mutation
The ancestral relationships among n individuals sampled at random from
the population can be described by Kingman’s coalescent (Kingman, 1982)
55

56
Handbook of Approximate Bayesian Computation
Looking back into the past, the sample has n distinct ancestors for time Tn,
at which point two individuals are chosen at random to coalesce, the sample
then having n −1 distinct ancestors. We continue merging random pairs of
ancestors in such a way that for time Tj the sample has j distinct ancestors, for
j = n −1, . . . , 2. The times Tj are independent exponential random variables
with mean:
E[Tj] =
2
j(j −1).
In this setting, time is measured in units of N generations. The height of the
tree is TMRCA = Tn + · · · + T2, the time to the most recent common ancestor
(MRCA) of the sample.
This description produces random coalescent trees, as illustrated in
Figure 2.1.
It is worth noting that E[TMRCA] = 2(1 −1/n), while the average time for
which the sample has just two ancestors is E[T2] = 1. Thus, the height of the
tree is inﬂuenced most by T2, as Figure 2.1 clearly shows.
Conditional on the coalescent tree of the sample, mutations in the genomic
region of interest are modelled in two steps. In the ﬁrst, potential mutations
are poured down the branches of the coalescent tree from the MRCA accord-
ing to independent Poisson processes of rate θ0/2, where θ0 = 2Nu is the
compound mutation parameter, u being the chance of a mutation occurring
in the genomic region in a given generation. Once the locations of mutations
are determined, their eﬀects are modeled by a mutation process that changes
the current type.
I will describe three mutation models, the ﬁrst being the so-called inﬁnitely
many alleles model, used originally to study the behaviour of allozyme frequen-
cies. Mutations arising on the branches of the coalescent tree are marked by a
sequence Uj, j = 0, 1, . . . of distinct labels, a mutation on a branch replacing
the current label with the next available U. An example is given in Figure 2.2,
which shows the sample of size n = 5 represented by labels U2, U2, U5, U3, and
U3, respectively.
The particular values of the types observed in a sample are not of interest;
rather, it is the number of types Cj(n) represented j times in the sample, for
j = 1, 2, . . . , n, that records the information in these data. In the example
above, there are K5 = 3 types, with C1(5) = 1, C2(5) = 2. Note that C1(n) +
2C2(n) + · · · + nCn(n) = n.
In the second example, known as the inﬁnitely many sites model, we think
of the genomic region of interest as the unit interval (0,1), and assume that
each mutation in the coalescent tree arises at a novel position in the genomic
region. These positions may be realised as values in a sequence Uj, j = 0, 1, . . .
of distinct labels (generated, e.g., as independent random variables uniformly
distributed in (0, 1)). Figure 2.2 can be used to illustrate this model too. Each
individual in the sample is represented as a sequence of mutations back to

On the History of ABC
57
FIGURE 2.1
Six realisations of coalescent trees for a sample of size n = 5, drawn on the
same scale. (Reprinted by permission from Springer Nature, Lectures on Prob-
ability Theory and Statistics, Volume 1837, Part I, 2004, Tavar´e, S., Copyright
2004.)
the root. Reading from left to right in the ﬁgure, we see that the ﬁrst two
individuals in the sample have mutations at locations {U1, U2}, the third at
{U1, U2, U4, U5}, and the fourth and ﬁfth at {U0, U3}.
We can write these in rather more conventional ‘DNA style’ by representing
the ancestral type as 0, mutants as 1, and recording the mutation status of

58
Handbook of Approximate Bayesian Computation
U1
U2
U0
U3
U4
U5
U2
U2
U5
U3
U3
FIGURE 2.2
A coalescent tree for n = 5 with mutations U0, U1, . . . , U5 marked on the
branches. The labels at the bottom of the tree give the type of each individual,
assuming the inﬁnitely many alleles model. Two types (U2, U3) are represented
twice and one type (U5) once. (Reprinted by permission from Springer Nature,
Lectures on Probability Theory and Statistics, Volume 1837, Part I, Tavar´e,
S., Copyright 2004.)
each individual in an n × s matrix, where s is the number of mutations, or
segregating sites, that have occurred in the coalescent tree. For our example,
the sequences are:
⎛
⎜
⎜
⎜
⎜
⎝
U0
U1
U2
U3
U4
U5
1
0
1
1
0
0
0
2
0
1
1
0
0
0
3
0
1
1
0
1
1
4
1
0
0
1
0
0
5
1
0
0
1
0
0
⎞
⎟
⎟
⎟
⎟
⎠
.
(2.1)

On the History of ABC
59
In practice, of course, the ancestral labeling is often not known, and neither is
the time-ordered labeling of the mutations; the sequences would be recorded by
ordering the columns according to positions along the genome. Any sequence
dataset consistent with the inﬁnitely many sites model, such as that in (2.1),
can be represented by a rooted tree if the ancestral labeling is known and
as an unrooted tree if it is not. See Chapter 5 of Tavar´e (2004) for further
details.
In the previous examples mutations have a simple structure, in that they do
not allow for back mutations, for example. More detailed models of sequence
evolution have also been developed. For example, rather than representing the
DNA region as a unit interval, it might be described as a series of m completely
linked sites, each site containing one of the letters A, C, G, or T. There are now
M = 4m possible values (or haplotypes) for each sequence. Mutations are laid
down on the coalescent tree as before, the results of each mutation being given
by an M × M mutation probability matrix P. The (i, j)th element of P gives
the probability that sequence i mutates to sequence j when a mutation occurs.
These models are referred to collectively as ﬁnite sites models. For historical
amusement, when these models were used in the early days of sequence data
the sample sizes were n ≈60 and the length of the sequences m ≈360 (Ward
et al., 1991). How things have changed!
2.3
Statistical Inference
Statistical inference for the parameter θ0 for the inﬁnitely many alleles model
was the subject of Ewens’ celebrated paper (Ewens, 1972). Ewens established
that Kn := C1(n) + · · · + Cn(n), the number of types observed in the sample,
is suﬃcient for θ0, and that the (moment and) maximum likelihood estimator
θE of θ0 is the solution of the equation:
Kn =
n−1
	
j=0
θ
θ + j .
In large samples, θE is asymptotically Normally distributed with mean θ0 and
variance θ0/ log n. This last result goes some way to explaining why accurate
estimation of θ0 is hard; even modern-day sample sizes do not make much
progress.
For the inﬁnitely many sites mutation model, θ0 has traditionally been
estimated by making use of the summary statistic Sn, the number of seg-
regating sites observed in the sample. Watterson’s classic paper (Watterson,
1975) derived the basic results. We note ﬁrst that:

60
Handbook of Approximate Bayesian Computation
Conditional on the total length Ln = 2T2+· · ·+nTn of the branches of
the coalescent tree, Sn has a Poisson distribution with mean Lnθ0/2.
Hence, unconditionally:
E[Sn] = θ0
2 E[Ln] = θ0
2 2

1 + 1
2 + · · · +
1
n −1

= θ0
n−1
	
j=1
1
j .
(2.2)
This gives Watterson’s unbiased estimator:
θW = Sn
n−1
	
j=1
1
j .
In large samples, θW is approximately normally distributed with mean θ0
and variance θ0/ log n. The rate of decay of the variance of θW and θE, the
reciprocal of the logarithm of the sample size n (rather than of the sample
size itself, as might have been anticipated), reﬂects the dependence among the
observations arising from the tree structure of the coalescent.
2.4
Computationally Intensive Methods
Computationally intensive methods have been used to ﬁt stochastic models to
data for many years. Among the early examples are Ottestad (1956), Edwards
(1967), Trudgill and Ross (1969), Hoel and Mitchell (1971). Edwards noted
that:
Particular emphasis will be placed on the need to formulate sound
methods of ‘estimation by simulation’ on complex models.
Ross (1972) explored approximate likelihood methods to ﬁt models to data,
and a systematic treatment was provided in the paper by Diggle and Gratton
(1984).
By the early 1990s, the emergence of DNA sequence data led to a num-
ber of computational inference methods in population genetics. Among these
is Lundstrom et al. (1992), who analysed mitochondrial data by using a ﬁnite
sites model to describe the behaviour of purine-pyrimidine sites across the
region. Their ﬁrst approach compared the expected number of sites of diﬀer-
ent types with the observed numbers, and estimated parameters by matching
expected to observed numbers as closely as possible. Their second approach
was a composite likelihood method that treated the sites as independent.
Kuhner et al. (1995) developed an ingenious Metropolis–Hastings Monte Carlo

On the History of ABC
61
method to estimate the parameter θ in another ﬁnite sites model, exploiting
the coalescent structure to generate a likelihood curve from which inference
could be made.
Griﬃths and Tavar´e (1994c,b) introduced another approach to full-
likelihood-based inference by exploiting a classical result about Markov chains.
For a discrete-time Markov chain {Xk, k ≥0} with state space S and transi-
tion matrix P = (pxy, x, y ∈S), let A be a set of states for which the hitting
time:
η = inf{k ≥0 : Xk ∈A},
is ﬁnite with probability one starting from any x ∈T := S \ A. Let f be a
function on S, and deﬁne:
ux(f) = E
 η

k=0
f(Xk) | X0 = x

,
for all X0 = x ∈S (so that ux(f) = f(x), x ∈A). Then for all x ∈T :
ux(f) = f(x)
	
y∈S
pxyuy(f).
(2.3)
A simulation approach to solve equations such as the one in (2.3) follows: sim-
ulate a trajectory of the chain X starting at x until it hits A at time η, com-
pute the value of product η
k=0 f(Xk), and repeat this many times to obtain
an estimate of ux(f). In the applications in Griﬃths and Tavar´e (1994c,b),
coalescent-based recursions for likelihoods were reduced to this form. The
method is essentially a version of von Neumann and Ulam’s suggestion for
matrix inversion, as described in Forsythe and Leibler (1950), and improved
by sequential Monte Carlo by Halton (1962, 1970). Further examples may be
found in Chapter 6 of Tavar´e (2004). Felsenstein et al. (1999) showed how to
exploit importance sampling to design more eﬃcient ways to (in our language)
choose the process X, and this resulted in a number of more eﬀective inference
methods; see, for example, Stephens and Donnelly (2000) and Griﬃths et al.
(2008). A Markov chain Monte Carlo (MCMC) approach to inference for the
inﬁnitely many sites model appears in Racz (2009).
Summary statistics continued to be used for inference, as illustrated
by Weiss and von Haeseler (1998), who described what is essentially the fre-
quentist version of ABC in the context of inference about population history,
based on the number of segregating sites and the mean pairwise distance
among the sequences. They produced a likelihood surface over a grid of pa-
rameter values, approximating the likelihood by repeated simulation of the
model and recording the proportion of simulated values of the statistics that
were suﬃciently close to the observed values.
The distributions of unobservable features of coalescent models, such as
TMRCA, conditional on observed values of the data, have also been studied by

62
Handbook of Approximate Bayesian Computation
Monte Carlo methods. Griﬃths and Tavar´e (1994a) considered inference for
TMRCA under the inﬁnitely many sites model, using data of the form (2.1)
and exploiting a version of the approach outlined in (2.3). Fu and Li (1997)
studied a similar problem, but using the maximal value of the number of
nucleotide diﬀerences between any pair of sequences in the dataset as the
observed statistic. Their method uses a simple form of density estimation to
approximate TMRCA.
2.5
A Bayesian Approach
Bayesian methods provide a natural setting for inference not just about model
parameters, but also about unobservables in the underlying model. Tavar´e
et al. (1997) illustrated this for the inﬁnitely many sites model by developing a
rejection algorithm for simulating observations from TMRCA and θ, conditional
on the number of segregating sites Sn = s seen in the data. The method is
based on the observation made above (2.2) that, conditional on the times
T2, . . . , Tn and θ, the number of segregating sites in the sample of size n
has a Poisson distribution with mean E[Sn|Tn, . . . , T2, θ] = θ Ln/2; we write
S ∼Po(θLn/2).
Suppose then that θ has prior distribution π(), and let p(s|λ) denote the
probability that a Poisson random variable with mean λ has value s:
p(s|λ) = e−λλs
s!
, s = 0, 1, . . . .
The rejection algorithm is:
A1 Generate θ ∼π(·).
A2 Generate Tn, . . . , T2 from the coalescent model. Calculate Ln = n
j=2 jTj
and TMRCA = n
j=2 Tj.
A3 Accept (θ, TMRCA) with probability proportional to:
α = p(s|θLn/2).
Accepted values of this algorithm have the required distribution, that of
(θ, TMRCA) given Sn = s.
The previous method may be viewed as an application of the rejection
algorithm, which proceeds as follows. For discrete data D, probability model
M with parameters θ having prior π(), we can simulate observations from:
f(θ|D) ∝P(D|θ) π(θ),
(2.4)

On the History of ABC
63
via
B1 Generate θ ∼π(·).
B2 Accept θ with probability proportional to the likelihood P(D|θ).
This method can be extended dramatically in its usefulness using the follow-
ing, stochastically equivalent, version:
C1 Generate θ ∼π(·).
C2 Simulate an observation D′ from model M with parameter θ.
C3 Accept θ if D′ = D.
For the example in algorithm A above, C3 takes the form
C3 Simulate an observation S ∼Po(θLn/2), and accept (TMRCA, θ) if S = s.
While algorithms B and C are probabilistically identical, C is much more gen-
eral in that one does not need to compute probabilities explicitly to make it
work; only simulation is needed. Version C is due to Rubin (1984). Surpris-
ingly, the result does not seem to be described in text books that focus on
simulation.
The drawback in C is clear. It will typically be the case that for a given
value of θ, the chance of the outcome D′ = D, namely P(D|θ), is either vanish-
ingly small or very time consuming to compute, resulting in an algorithm that
does not work eﬀectively. This is where ABC ﬁnally comes into play, in the
form of the following scheme. We start with a metric ρ to compare datasets
and a tolerance h ≥0, and then:
D1 Generate θ ∼π(·).
D2 Simulate an observation D′ from model M with parameter θ.
D3 Compute ρ := ρ(D′, D), and accept θ as an approximate draw from f(θ|D)
if ρ ≤h.
The parameter h measures the tension between computability and accuracy.
If ρ is a metric, then ρ = 0 =⇒D′ = D, so that such an accepted θ is indeed
an observation from the true posterior.
Pritchard et al. (1999) were the ﬁrst to describe a version of this scheme,
in which the datasets in D3 were compared through a choice of summary
statistics. Thus, ρ compares how well a set of simulated summary statistics
matches the observed summary statistics. If the statistics are suﬃcient for θ,
then when h = 0, the accepted values of θ are still from the true posterior
based on the full data. This begs the question of how one might identify

64
Handbook of Approximate Bayesian Computation
‘approximately suﬃcient’ statistics, a topic covered in Chapter 5, this volume.
The method is also applicable to continuous data.
2.6
ABC Takes Oﬀ
Beaumont et al. (2002) showed that it might be better to soften the hard cutoﬀ
suggested in algorithm D, by making use of the all the simulated values. They
proposed to weight values of θ by the size of the corresponding distance ρ;
smaller values of ρ suggest an observation whose distribution is closer to the
required posterior. They made a number of suggestions for how the weights
might be chosen, and then used to produce a sample with better sampling
properties than the original hard cut-oﬀmethod.
The development of ABC was predicated on the availability of computa-
tional power and the lack of tractable likelihoods. The latter is also an issue
for MCMC methods, and this motived Marjoram et al. (2003) to suggest an
MCMC method that does not need likelihoods in its implementation.
In the present setting the idea behind classical MCMC (Hastings, 1970)
is to construct an ergodic Markov chain that has f(θ|D) as its stationary
distribution. In skeleton form, it works as follows:
E1 The chain is now at θ.
E2 Propose a move to θ′ according to a proposal distribution q(θ, θ′).
E3 Calculate the Hastings ratio:
α = min

1, P(D|θ′)π(θ′)q(θ′, θ)
P(D|θ)π(θ)q(θ, θ′)

.
(2.5)
E4 Move to θ′ with probability α, else remain at θ.
It is the ratio of likelihoods in E3 that might cause problems. Marjoram et al.
(2003) proposed the following:
F1 The chain is now at θ.
F2 Propose a move to θ′ according to q(θ, θ′).
F3 Generate D′ using parameter θ′.
F4 If D′ = D, go to F5, else remain at θ.
F5 Calculate:
α = min

1, π(θ′)q(θ′, θ)
π(θ)q(θ, θ′)

.
F6 Move to θ′ with probability α, else remain at θ.

On the History of ABC
65
This likelihood-free method does indeed have the correct stationary distribu-
tion. In practice the rejection step is often replaced by a version of D3:
F4 If ρ(D′, D) ≤h, go to next step, else return θ,
and this too might involve a comparison of summary statistics. Marjoram
et al. (2003) were able to assess the eﬀect of summary statistics in a popula-
tion genetics problem, and Plagnol and Tavar´e (2004) used the method in a
problem concerning divergence times of primate species.
Marjoram et al. (2003) also suggested that the likelihood terms in (2.5) be
approximated by estimates of the form:
ˆP(D|θ) = 1
B
B
	
j=1
I(D′
j = D),
for B independent simulations of the model with parameter θ; algorithm F is
the special case B = 1. Beaumont (2003) made a similar suggestion, and this
motivated the development of the ‘pseudo-marginal method’ (Andrieu and
Roberts, 2009), discussed in Chapter 12 , this volume.
2.7
Conclusion
The term ‘Approximate Bayesian computation’ has arisen more than once.
For example, Sweeting (1996) used it to describe computation based on the
asymptotic behaviour of signed roots of log-density ratios. He argued that:
. . . analytic approximation still has an important role to play in
Bayesian statistics.
In the setting of the present handbook, and in some sense at the other end
of the analytical spectrum, it was Beaumont et al. (2002) who coined the
term ‘approximate Bayesian computation’, in the article that made ABC the
popular technique it has become.
Where did the acronym ABC arise? By the time we submitted Marjoram
et al. (2003) for publication at the end of 2002, the University of Southern
California (USC) group had held many meetings on what we then called ABC.
In the submitted version, the term ABC appeared twice:
. . . we have the following approximate Bayesian computation (ABC)
scheme for data D summarised by S
and:
. . . and it is often useful to replace the full data by a number of judi-
ciously chosen summary statistics. The resulting approximate Bayesian
computation, which we dub ABC, allows us to explore scenarios which
are intractable if the full data are used.

66
Handbook of Approximate Bayesian Computation
In the published version, ABC does not appear, because of house style at the
time in the Proceedings of the National Academy of Sciences. This from the
proofs:
D – AU: Per PNAS style, nonstandard abbreviations are allowed only
when used at least 5 times in the main text.
A missed opportunity for the National Academy of Sciences! In 2003, I gave an
invited lecture at the Royal Statistical Society entitled (with a certain amount
of bravado) ‘Who needs likelihoods’, in which ABC appeared several times,
as the write-up in the RSS News in October 2003 showed. It concluded:
The lively discussion that followed reinforced our feeling that we were
not hearing the last of ABC.
This observation turned out to be true, and ABC has become a standard
approach in the statistician’s toolbox. New areas of application arise fre-
quently, as the rapidly expanding literature shows. One area that would
repay deeper analysis is that of cancer evolution, a ﬁeld that is produc-
ing enormous amounts of DNA sequence and phenotype data and for which
there is a dearth of inference methods. For an early application see Tsao
et al. (2000). Inference for agent-based models in stem cell biology appears in
Sottoriva and Tavar´e (2010), which motivated the approach in Sottoriva et al.
(2013) for colorectal cancer.
2.8
Acknowledgements
I thank Dr. Andy Lynch and two anonymous reviewers for helpful comments
on an earlier version of this article, and Paul Gentry, Conference and Events
Manager at the Royal Statistical Society, for tracking down the Royal Statis-
tical Society News report on ABC.
References
Andrieu, C. and G. Roberts (2009). The pseudo-marginal approach for eﬃcient
Monte Carlo computations. Ann Stat 37, 697–725.
Beaumont, M. A. (2003). Estimation of population growth or decline in
genetically monitored populations. Genetics 164, 1139–1160.
Beaumont, M. A. (2008). Joint determination of topology, divergence times
and immigration in population trees. In S. Matsumara, P. Forster,

On the History of ABC
67
and C. Renfrew (Eds.), Simulations, Genetics and Human Prehistory,
pp. 135–154. McDonald Institute for Archaeological Research, Cambridge,
UK.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162, 2025–2035.
Diggle, P. J. and R. J. Gratton (1984). Monte Carlo methods of inference for
implicit statistical models. J R Statist Soc B 46, 193–227.
Edwards, A. W. F. (1967). A biometric case history: Studies on the distribu-
tion of sexes in families, 1889–1966. Abstract 1286. Biometrics 23, 176.
Ewens, W. (1972). The sampling theory of selectively neutral alleles. Theor
Popul Biol 3, 87–112.
Felsenstein, J., M. Kuhner, J. Yamato, and P. Beerli (1999). Likelihoods on
coalescents: A Monte Carlo sampling approach to inferring parameters from
population samples of molecular data. In F. Seillier-Moiseiwitsch (Ed.),
Statistics in Molecular Biology and Genetics, Volume 33 of IMS Lecture
Notes–Monograph Series, pp. 163–185. Institute of Mathematical Statistics
and and American Mathematical Society, Hayward, CA.
Forsythe, G. and R. Leibler (1950). Matrix inversion by the Monte Carlo
method. Math Comput 26, 127–129.
Fu, Y.-X. and W.-H. Li (1997). Estimating the age of the common ancestor
of a sample of DNA sequences. Mol Biol Evol 14, 195–199.
Griﬃths, R. and S. Tavar´e (1994a). Ancestral inference in population genetics.
Stat Sci 9, 307–319.
Griﬃths, R. and S. Tavar´e (1994b). Sampling theory for neutral alleles in a
varying environment. Phil Trans R Soc Lond B 344, 403–410.
Griﬃths, R. and S. Tavar´e (1994c). Simulating probability distributions in the
coalescent. Theor Popul Biol 46, 131–159.
Griﬃths, R. C., P. A. Jenkins, and Y. S. Song (2008). Importance sampling
and the two-locus model with subdivided population structure. Adv Appl
Probab 40, 473–500.
Halton, J. (1962). Sequential Monte Carlo. Proc Camb Philos Soc 58, 57–58.
Halton, J. (1970). A retrospective and prospective study of the Monte Carlo
method. SIAM Rev. 12, 1–63.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains
and their applications. Biometrika 57, 97–109.

68
Handbook of Approximate Bayesian Computation
Hoel, D. G. and T. J. Mitchell (1971). The simulation, ﬁtting, and testing of
a stochastic cellular proliferation model. Biometrics 27, 191–199.
Kingman, J. (1982). On the genealogy of large populations. J Appl
Probab 19A, 27–43.
Kuhner, M., J. Yamato, and J. Felsenstein (1995). Estimating eﬀective popu-
lation size and mutation rate from sequence data using Metropolis-Hastings
sampling. Genetics 140, 1421–1430.
Lundstrom, R., S. Tavar´e, and R. Ward (1992). Estimating mutation rates
from molecular data using the coalescent. Proc Natl Acad Sci USA 89,
5961–5965.
Marjoram, P., J. Molitor, V. Plagnol, and S. Tavar´e (2003). Markov
chain Monte Carlo without likelihoods. Proc Natl Acad Sci USA 100,
15324–15328.
Ottestad, P. (1956). On the size of the stock of Antarctic ﬁn whales relative
to the size of the catches. The Norwegian Whaling Gazette 45, 298–308.
Plagnol, V. and S. Tavar´e (2004). Approximate Bayesian computation and
MCMC. In H. Niederreiter (Ed.), Monte Carlo and Quasi-Monte Carlo
Methods 2002, pp. 99–114. Springer-Verlag Berlin, Germany.
Pritchard, J. K., M. T. Seielstad, A. Perez-Lezaun, and M. W. Feldman (1999).
Population growth of human Y chromosomes: A study of Y chromosome
microsatellites. Mol Biol Evol 16, 1791–1798.
Racz, M. Z. (2009). MCMC and the inﬁnite sites model. Technical report,
Department of Statistics Summer Project, University of Oxford, Oxford,
UK.
Ross, G. J. S. (1972). Stochastic model ﬁtting by evolutionary operation.
In J. R. N. Jeﬀers (Ed.), Mathematical Models in Ecology, pp. 297–308.
Blackwell Scientiﬁc Publications, Oxford, UK.
Rubin, D. B. (1984). Bayesianly justiﬁable and relevant frequency calculations
for the applied statistician. Ann Stat 12, 1151–1172.
Sottoriva, A., I. Spiteri, D. Shibata, C. Curtis, and S. Tavar´e (2013). Single-
molecule genomic data delineate patient-speciﬁc tumor proﬁles and cancer
stem cell organization. Cancer Res 73(1), 41–49.
Sottoriva, A. and S. Tavar´e (2010). Integrating approximate Bayesian compu-
tation with complex agent-based models for cancer research. In G. Saporta
and Y. Lechevallier (Eds.), COMPSTAT 2010 – Proceedings in Computa-
tional Statistics, pp. 57–66. Physica Verlag Heidelberg.

On the History of ABC
69
Stephens, M. and P. Donnelly (2000). Inference in molecular population
genetics. J R Stat Soc B 62, 605–655.
Sweeting, T. J. (1996). Approximate Bayesian computation based on signed
roots of log-density ratios (with discussion). Bayesian Stat 5, 427–444.
Tavar´e, S. (2004). Ancestral inference in population genetics. In J. Picard
(Ed.), Lectures On Probability Theory And Statistics: Ecole d’Et´e de Proba-
bilit´es de Saint-Flour XXXI – 2001, Volume 1837 of Lecture Notes in Math-
ematics, pp. 1–188. Springer-Verlag, New York.
Tavar´e, S., D. J. Balding, R. C. Griﬃths, and P. Donnelly (1997). Inferring
coalescence times for molecular sequence data. Genetics 145, 505–518.
Trudgill, D. L. and G. J. S. Ross (1969). The eﬀect of population density on
the sex ratio of Heterodera rostochiensis: A two dimensional model. Nema-
tologica 15, 601–607.
Tsao, J., Y. Yatabe, R. Salovaara, H. J. Jarvinen, J. P. Mecklin, L. A. Aalto-
nen, S. Tavar´e, and D. Shibata (2000). Genetic reconstruction of individual
colorectal tumor histories. Proc Natl Acad Sci USA 97, 1236–1241.
Ward, R., B. Frazier, K. Dew, and S. P¨a¨abo (1991). Extensive mitochon-
drial diversity within a single amerindian tribe. Proc Natl Acad Sci USA
8720–8724.
Watterson, G. A. (1975). On the number of segregating sites in genetical
models without recombination. Theor Popul Biol 7, 256–276.
Weiss, G. and A. von Haeseler (1998). Inference of population history using a
likelihood approach. Genetics 149, 1539–1546.


3
Regression Approaches for ABC
Michael G.B. Blum
CONTENTS
3.1
Introduction ......................................................
71
3.2
Principle of Regression Adjustment .............................
72
3.2.1
Partial posterior distribution ............................
72
3.2.2
Rejection algorithm followed by adjustment ............
73
3.2.3
Regression adjustment ..................................
73
3.2.4
Fitting regression models ................................
74
3.2.5
Parameter transformations ..............................
76
3.2.6
Shrinkage ................................................
77
3.3
Theoretical Results about Regression Adjustment ..............
77
3.4
Application of Regression Adjustment to Estimate Admixture
Proportions Using Polymorphism Data .........................
79
3.5
Regression Methods Besides Regression Adjustment ............
81
3.6
Conclusion ........................................................
82
References
...............................................................
83
3.1
Introduction
In this chapter, we present regression approaches for approximate Bayesian
computation (ABC). As for most methodological developments related to
ABC, regression approaches originate with coalescent modeling in popula-
tion genetics [3]. After performing rejection sampling by accepting parameters
that generate summary statistics close enough to those observed, parameters
are adjusted to account for the discrepancy between simulated and observed
summary statistics. Because adjustment is based on a regression model, such
approaches are coined as regression adjustment in the following.
Regression adjustment is a peculiar approach in the landscape of Bayesian
approaches where sampling techniques are usually proposed to account for
mismatches between simulations and observations [4, 5]. We suggest vari-
ous reasons explaining why regression adjustment is now a common step in
71

72
Handbook of Approximate Bayesian Computation
practical applications of ABC. First, it is convenient and generic because the
simulation mechanism is used to generate simulated summary statistics as a
ﬁrst step, and it is not used afterwards. For instance, the software ms is used
to generate DNA sequences or genotypes when performing ABC inference in
population genetics [6]. Statistical routines, which account for mismatches,
are completely separated from the simulation mechanism and are used in a
second step. Regression adjustment can therefore be readily applied in a wide
range of contexts without implementation eﬀorts. By contrast, when consider-
ing sampling techniques, statistical operations and simulations are embedded
within a single algorithm [5, 7], which may require new algorithmic develop-
ment for each speciﬁc statistical problem. Second, regression approaches have
been shown to produce reduced statistical errors compared to rejection algo-
rithms in a quite diverse range of statistical problems [3,8,9]. Last, regression
approaches are implemented in diﬀerent ABC software including DIYABC [10]
and the R abc package [11].
In this chapter, I introduce regression adjustment using a comprehensive
framework that includes linear adjustment [3], as well as more ﬂexible ad-
justments, such as non-linear models [8]. The ﬁrst section presents the main
concepts underlying regression adjustment. The second section presents a the-
orem that compares theoretical properties of posterior distributions obtained
with and without regression adjustment. The third section presents a prac-
tical application of regression adjustment in ABC. It shows that regression
adjustment shrinks posterior distributions when compared to a standard re-
jection approach. The fourth section presents recent regression approaches for
ABC that are not based on regression adjustment.
3.2
Principle of Regression Adjustment
3.2.1
Partial posterior distribution
Bayesian inference is based on the posterior distribution deﬁned as:
π(θ|yobs) ∝p(yobs|θ)π(θ),
(3.1)
where θ ∈Rp is the vector of parameters, and yobs are the data. Up to a
renormalising constant, the posterior distribution depends on the prior π(θ)
and on the likelihood function p(yobs|θ). In the context of ABC, inference is no
longer based on the posterior distribution π(θ|yobs), but on the partial poste-
rior distribution π(θ|sobs), where sobs is a q-dimensional vector of descriptive
statistics. The partial posterior distribution is deﬁned as follows:
π(θ|sobs) ∝p(sobs|θ)π(θ).
(3.2)
Obviously, the partial posterior is equal to the posterior if the descriptive
statistics sobs are suﬃcient for the parameter θ.

Regression Approaches for ABC
73
3.2.2
Rejection algorithm followed by adjustment
To simulate a sample from the partial posterior p(θ|sobs), the rejection algo-
rithm followed by adjustment works as follows:
1. Simulate n values θ(i), i = 1, . . . , n, according to the prior distribution π.
2. Simulate descriptive statistics s(i) using the generative model p(s(i)|θ(i)).
3. Associate with each pair (θ(i), s(i)) a weight w(i) ∝Kh(∥s(i)−sobs∥), where
∥· −· ∥is a distance function, h > 0 is the bandwidth parameter, and K
is an univariate statistical kernel with Kh(∥· ∥) = K(∥· ∥/h).
4. Fit a regression model where the response is θ and the predictive variables
are the summary statistics s [equations (3.3) or (3.5)]. Use a regression
model to adjust the θ(i) in order to produce a weighted sample of ad-
justed values. Homoscedastic adjustment [equation (3.4)] or heteroscedas-
tic adjustment [equation (3.6)] can be used to produce a weighted sample
(θ(i)
c , w(i)), i = 1, . . . , n, which approximates the posterior distribution.
To run the rejection algorithm followed by adjustment, there are several
choices to make. The ﬁrst choice concerns the kernel K. Usual choices for
K encompass uniform kernels that give a weight of 1 to all accepted simu-
lations and zero otherwise [12] or the Epanechnikov kernel for a smoother
version of the rejection algorithm [3]. However, as for traditional density
estimation, the choice of statistical kernel has a weak impact on estimated
distribution [13]. The second choice concerns the threshold parameter h. For
kernels with a ﬁnite support, the threshold h corresponds to (half) the win-
dow size within which simulations are accepted. For the theorem presented in
Section 3.4, I assume that h is chosen without taking into account the simula-
tions s(1), . . . , s(n). This technical assumption does not hold in practice, where
we generally choose to accept a given percentage p, typically 1% or 0.1%, of
the simulations. This practice amounts at setting h to the ﬁrst p-quantile
of the distances ∥s(i) −sobs∥. A theorem where the threshold depends on
simulations has been provided [14]. Choice of threshold h corresponds to bias-
variance tradeoﬀ. When choosing small values of h, the number of accepted
simulations is small and estimators might have a large variance. By contrast,
when choosing large values of h, the number of accepted simulations is large
and estimators might be biased [1].
3.2.3
Regression adjustment
The principle of regression adjustment is to adjust simulated parameters θ(i)
with non-zero weights w(i) > 0 in order to account for the diﬀerence between

74
Handbook of Approximate Bayesian Computation
the simulated statistics s(i) and the observed one sobs. To adjust parameter
values, a regression model is ﬁtted in the neighbourhood of sobs:
θ(i) = m(s(i)) + ε,
i = 1, · · · , n,
(3.3)
where m(s) is the conditional expectation of θ given s, and ε is the residual.
The regression model of equation (3.3) assumes homoscedasticity, for exam-
ple, it assumes that the variance of the residuals does not depend on s. To
produce samples from the partial posterior distribution, the θ(i)’s are adjusted
as follows:
θ(i)
c
= ˆm(sobs) + ˆε(i)
(3.4)
= ˆm(sobs) + (θ(i) −ˆm(s(i))),
where ˆm represents an estimator of the conditional expectation of θ given s,
and ˆε(i) is the ith empirical residual. In its original formulation, regression
adjustment assumes that m is a linear function [3], and it was later extended
to non-linear adjustments [8]. Other regression adjustment techniques have
also been proposed when parameters and summary statistics are real-valued
functions [15].
The homoscedastic assumption of equation (3.3) may not be always valid.
When the number of simulations is not very large because of computational
constraints, local approximations, such as the homoscedastic assumption, are
no longer valid because the neighborhood corresponding to simulations for
which w(i) ̸= 0 is too large. Regression adjustment can account for het-
eroscedasticity that occurs when the variance of the residuals depend on the
summary statistics. When accounting for heteroscedasticity, the regression
equation can be written as follows [8]:
θ(i) = m(s(i)) + σ(s(i))ζ,
i = 1, · · · , n,
(3.5)
where σ(s) is the square root of the conditional variance of θ given s, and ζ
is the residual. Heteroscedastic adjustment involves an additional scaling step
in addition to homoscedastic adjustment (3.4) (Figure 3.1):
θ(i)
c′ = ˆm(sobs) + ˆσ(sobs)ˆζ(i)
= ˆm(sobs) + ˆσ(sobs)
ˆσ(s(i)) (θ(i) −ˆm(s(i))),
(3.6)
where ˆm and ˆσ are estimators of the conditional mean and of the conditional
standard deviation.
3.2.4
Fitting regression models
Equations (3.4) and (3.6) of regression adjustment depend on the estimator
of the conditional mean ˆm and possibly of the conditional variance ˆσ. Model

Regression Approaches for ABC
75
Summary statistic
No adjustment 
Summary statistic
Model parameter
sobs
h
h
θ(i)
θ(i)
Summary statistic
θc
(i)
θ(i)
θc′
Linear adjustment 
sobs
sobs
h
h
Posterior distribution
Posterior distribution
Non-linear and 
heteroscedastic adjustment
Posterior distribution
Model parameter
h
h
(i)
FIGURE 3.1
Posterior variances of the histograms obtained after adjustment are reduced
compared to the posterior variance obtained without adjustment.
ﬁtting is performed using weighted least squares. The conditional mean is
learned by minimising the following weighted least square criterion:
E(m) =
n

i=1
(θ(i) −m(s(i)))2w(i).
(3.7)
For linear adjustment, we assume that m(s) = α + βs [3]. The parameters α
and β are inferred by minimising the weighted least square criterion given in
equation (3.7).
For heteroscedastic adjustment [equation (3.4)], the conditional variance
should also be inferred. The conditional variance is learned after minimisation
of a least square criterion. It is obtained by ﬁtting a regression model where the
answer is the logarithm of the squared residuals. The weighted least squares
criterion is given as follows:
E(log σ2) =
n

i=1

log((ˆε(i))2) −log σ2(s)
2
w(i).
Neural networks have been proposed to estimate m and σ2 [8]. This choice
was motivated by the possibility oﬀered by neural networks to reduce the
dimension of descriptive statistics via an internal projection on a space of
lower dimension [16].

76
Handbook of Approximate Bayesian Computation
In general, the assumptions of homoscedasticity and linearity [equation
(3.3)] are violated when the percentage of accepted simulation is large. By
contrast, heteroscedastic and non-linear regression models [equation (3.5)] are
more ﬂexible. Because of this additional ﬂexibility, the estimated posterior
distributions obtained after heteroscedastic and non-linear adjustment is less
sensitive to the percentage of accepted simulations [8]. In a coalescent model,
where the objective was to estimate the mutation rate, heteroscedastic adjust-
ment with neural networks was found to be less sensitive to the percentage of
accepted simulations than linear and homoscedastic adjustment [8]. In a model
of phylodynamics, it was found again that statistical error obtained with neu-
ral networks decreases at ﬁrst – because the regression method requires a
large enough training dataset – and then reaches a plateau [9]. However for a
larger phylodynamics dataset, statistical error obtained with neural networks
increases for higher tolerance values. Poor regularisation or the limited size of
neural networks were advanced as putative explanations [9].
In principle, estimation of the conditional mean m and of the condi-
tional variance σ2 can be performed with diﬀerent regression approaches.
For instance, the R abc package implements diﬀerent regression models for
regression adjustment including linear regression, ridge regression, and neural
networks [11]. Lasso regression is another regression approach that can be
considered. Regression adjustment based on lasso (least absolute shrinkage
and selection operator) was shown to provide smaller errors than neural net-
work in a phylodynamic model [9]. An advantage of lasso, ridge regression and
neural networks compared to standard multiple regression is that they account
for the large dimension of the summary statistics using diﬀerent regularisation
techniques. Instead of considering regularised regression, there is an alterna-
tive where the initial summary statistics are replaced by a reduced set of
summary statistics or a combination of the initial summary statistics [17,18].
The key and practical advantage of regression approaches with regularisation
is that they implicitly account for the large number of summary statistics and
the additional step of variable selection can be avoided.
3.2.5
Parameter transformations
When the parameters are bounded or positive, parameters can be transformed
before regression adjustment. Transformations guarantee that the adjusted
parameter values lie in the range of the prior distribution [3]. An addi-
tional advantage of the log and logit transformations is that they stabilise
the variance of the regression model and make regression model (3.3) more
homoscedastic [1].
Positive parameters are regressed on a logarithm scale φ = log(θ),
φ = m(s) + ε.
Parameters are then adjusted on the logarithm scale:
φ(i)
c
= ˆm(sobs) + (φ(i) −ˆm(s(i))).

Regression Approaches for ABC
77
The ﬁnal adjusted values are obtained by exponentiation of the adjusted pa-
rameter values:
θ(i)
c
= exp(φ(i)
c ).
Instead of using a logarithm transformation, bounded parameters are
adjusted using a logit transformation. Heteroscedastic adjustment can also
be performed after log or logit transformations.
3.2.6
Shrinkage
An important property of regression adjustment concerns posterior shrinkage.
When considering linear regression, the empirical variance of the residuals is
smaller than the total variance. In addition, residuals are centred for linear
regression. These two properties imply that for linear adjustment, the empir-
ical variance of θ(i)
c
is smaller than the empirical variance of the non-adjusted
values θ(i) obtained with the rejection algorithm. Following homoscedastic
and linear adjustment, the posterior variance is consequently reduced. For
non-linear adjustment, shrinkage property has also been reported, and the
additional step generated by heteroscedastic adjustment does not necessarily
involve additional shrinkage when comparing θ(i)
c
to θ(i)
c′ [1]. However, shrink-
age obtained with regression adjustments can be excessive, especially for small
tolerance rates, and it can aﬀect posterior calibration. In a model of admixture,
95% credibility intervals obtained with regression adjustments were found to
contain only 84% of the true values in less favourable situations [19].
3.3
Theoretical Results about Regression Adjustment
The following theoretical section is technical and can be skipped by readers
not interested by mathematical results about ABC estimators based on re-
gression adjustment. In this section, we give the main theorem that describes
the statistical properties of posterior distributions obtained with or without
regression adjustment. To this end, the estimators of the posterior distribution
are deﬁned as follows:
ˆπj(θ|sobs) =
n

i=1
˜Kh′(θ(i)
j
−θ)w(i), j = 0, 1, 2,
(3.8)
where θ(i)
0
= θ(i) (no adjustment), θ(i)
j
= θ(i)
c
for j = 1, 2 (homoscedastic ad-
justment), ˜K is an univariate kernel, and ˜Kh′(·) = ˜K(·)/h′. Linear adjustment
corresponds to j = 1 and quadratic adjustment corresponds to j = 2. In non-
parametric statistics, estimators of the conditional density with adjustment
have already been proposed [20,21].
To present the main theorem, we introduce the following notations: if Xn
is a sequence of random variables and an is a deterministic sequence, the

78
Handbook of Approximate Bayesian Computation
notation Xn = oP (an) means that Xn/an converges to zero in probability,
and Xn = OP (an) means that the ratio Xn/an is bounded in probability
when n goes to inﬁnity. The technical assumptions of the theorem are given
in the appendix of [1].
Theorem 3.1. We assume that conditions (A1)–(A5) given in the appendix
of [1] hold. The bias and variance of the estimators ˆπj(θ|sobs), j = 0, 1, 2 are
given by:
E[ˆπj(θ|sobs)−π(θ|sobs)] = C1h′2+C2,jh2+OP ((h2+h′2)2)+OP ( 1
nhq ), (3.9)
Var[ˆπj(θ|sobs)] =
C3
nhqh′ (1 + oP (1)),
(3.10)
where q is the dimension of the vector of summary statistics, and the constants
C1, C2,j, and C3 are given in [1].
Proof: See [1].
There are other theorems that provide asymptotic biases and variances of
ABC estimators but they do not study the properties of estimators arising
after regression adjustment. Considering posterior expectation (e.g. posterior
moments) instead of the posterior density, Barber et al. [22] provides asymp-
totic bias and variance of an estimator obtained with rejection algorithm. Biau
et al. [14] studied asymptotic properties when the window size h depends on
the data instead of being ﬁxed in advance.
Remark 1. Curse of dimensionality The mean square error of the es-
timators is the sum of the squared bias and of the variance. With elementary
algebra, we can show that for the three estimators ˆπj(θ|sobs), j = 0, 1, 2, the
mean square error is of the order of n−1/(q+5) for an optimal choice of h. The
speed with which the error approaches 0 therefore decreases drastically when
the dimension of the descriptive statistics increases. This theorem highlights
(in an admittedly complicated manner) the importance of reducing the dimen-
sion of the statistics. However, the ﬁndings from these asymptotic theorems,
which are classic in non-parametric statistics, are often much more pessimistic
than the results observed in practice. It is especially true because asymptotic
theorems in the vein of theorem 3.1 do not take into account correlations
between summary statistics [23].
Remark 2. Comparing biases of estimators with and without
adjustment
It is not possible to compare biases (i.e. the constant C2,j,
j = 0, 1, 2) for any statistical model. However, if we assume that the residual
distribution of ε in equation (3.3) does not depend on s, then the constant C2,2
is 0. When assuming homoscedasticity, the estimator that achieves asymptot-
ically the smallest mean square error is the estimator with quadratic adjust-
ment ˆp2(θ|sobs). Assuming additionally that the conditional expectation m is
linear in s, then both ˆp1(θ|sobs) and ˆp2(θ|sobs) have a mean square error lower
than the error obtained without adjustment.

Regression Approaches for ABC
79
3.4
Application of Regression Adjustment to Estimate
Admixture Proportions Using Polymorphism Data
To illustrate regression adjustment, I consider an example of parameter
inference in population genetics. Description of coalescent modeling in pop-
ulation genetics is out of the scope of this chapter, and we refer interested
readers to dedicated reviews [24, 25]. This example illustrates that ABC can
be used to infer evolutionary events, such as admixture between sister species.
I assume that two populations (A and B) diverged in the past and admixed
with admixture proportions p and 1 −p to form a new hybrid species C that
subsequently splits to form two sister species C1 and C2 (Figure 3.2). Simu-
lations are performed using the software DIYABC (Do It Yourself Approxi-
mate Bayesian Computation) [10]. The model of Figure 3.2 corresponds to a
model of divergence and admixture between species of a complex of species
from the butterﬂy gender Coenonympha. We assume that 2 populations of
the Darwin’s Heath (Coenonympha darwiniana) originated through hybridis-
ation between the Pearly Heath (Coenonympha arcania) and the Alpine Heath
(Coenonympha gardetta) [26]. A total of 16 summary statistics based on Sin-
gle Nucleotide Polymorphisms (SNPs) are used for parameter inference [26].
A total of 106 simulations are performed and the percentage of accepted sim-
ulations is of 0.5%.
I consider four diﬀerent forms of regression adjustment: linear and
homoscedastic adjustment, non-linear (neural networks) and homoscedas-
tic adjustment, linear and heteroscedastic adjustment, and non-linear and
Time
A
B
C
C1
C2
p
1 – p
FIGURE 3.2
Graphical description of the model of admixture between sister species. Two
populations (A and B) diverge in the past and admixed with admixture pro-
portions p and 1−p to form a new hybrid species C that subsequently diverges
to form two sister species (C1 and C2).

80
Handbook of Approximate Bayesian Computation
Rejection
Homo. linear
adj.
Homo.
non-linear
adj.
0.04
0.06
0.08
0.10
0.12
0.14
CV Error (mean +/− 2SD)
Hetero. linear
adj.
Hetero.
non-linear
adj.
FIGURE 3.3
Errors obtained when estimating the admixture proportion p with diﬀerent
ABC estimators. The errors are obtained with cross-validation and error
bars (two standard deviations) are estimated with bootstrap. adj. stands for
adjustment.
heteroscedastic adjustment. All adjustments were performed with the R
package abc [11, 27]. I evaluate parameter inference using a cross-validation
criterion [11]. The cross-validation error decreases when considering linear
adjustment (Figure 3.3). However, considering heteroscedastic instead of ho-
moscedastic adjustment does not provide an additional decrease of the cross-
validation error (Figure 3.3).
Then, using real data from a butterﬂy species complex, we compare
the posterior distribution of the admixture proportion p obtained without
adjustment, with linear and homoscedastic adjustment, and with non-linear
and homoscedastic adjustment (Figure 3.4). For this example, considering
regression adjustment considerably changes the shape of the posterior distri-
bution. The posterior mean without adjustment is of p = 0.51 [95% C.I. =
(0.12, 0.88)]. By contrast, when considering linear and homoscedastic adjust-
ment, the posterior mean is of 0.93 [95% C.I. = (0.86, 0.98)]. When considering
non-linear and homoscedastic adjustment, the posterior mean is 0.84
[95% C.I. = (0.69, 0.93)]. Regression adjustment conﬁrms a larger contribu-
tion of C. arcania to the genetic composition of the ancestral C. darwiniana
population [26]. This example shows that regression adjustment not only
shrinks credibility intervals, but can also shift posterior estimates. Compared
to rejection, the posterior shift observed with regression adjustments provides
a result that is more consistent with published results [26].

Regression Approaches for ABC
81
0.0
0.2
0.4
0.6
0.8
1.0
0
5
10
15
Admixture proportion p
Density
Rejection
Homoscedastic 
and linear adjustment
Homoscedastic 
and non-linear
adjustment
FIGURE 3.4
Posterior distribution of the admixture coeﬃcient p obtained using real data
from a butterﬂy species complex to compute observed summary statistics.
This example shows that regression adjustment not only shrinks credibility
intervals, but can also shift posterior estimates. The admixture coeﬃcient p
measures the relative contribution of Coenonympha arcania to the ancestral
C. darwiniana population.
3.5
Regression Methods Besides Regression Adjustment
There are other regression methods besides regression adjustment that have
been proposed to estimate E[θ|sobs] and π(θ|sobs) using the simulations as
a training set. A ﬁrst set of methods consider kernel methods to perform
regression [28]. The principle is to deﬁne a kernel function K to compare
observed statistics to simulated summary statistics. Because of the so-called
kernel trick, regression with kernel methods amounts at regressing θ with Φ(s),
where < Φ(s), Φ(s′) >= K(s, s′) for two vector of summary statistics s and s′.
Then, an estimate of the posterior mean is obtained as follows:
E[θ|sobs] =
n

i=1
wiθ(i),
(3.11)
where wi depends on the inverse the Gram matrix containing the values
K(s(i), s(j)) for i, j = 1 . . . , n. A formula to estimate posterior density can
also be obtained in the same lines as formula (3.11). Simulations suggest
that kernel ABC gives better performance than regression adjustment when

82
Handbook of Approximate Bayesian Computation
high-dimensional summary statistics are used. For a given statistical error,
it was reported that fewer simulations should be performed when using ker-
nel ABC instead of regression adjustment [28]. Other kernel approaches have
been proposed for ABC where simulated and observed samples or summary
statistics are directly compared through a distance measure between empirical
probability distributions [29,30].
Another regression method in ABC that does not use regression
adjustment considers quantile regression forest [19]. Generally used to estimate
conditional mean, random forests also provide information about the full con-
ditional distribution of the response variable [31]. By inverting the estimated
conditional cumulative distribution function of the response variable, quantiles
can be inferred [31]. The principle of quantile regression forest is to use ran-
dom forests in order to give a weight wi to each simulation (θ(i), s(i)). These
weights are then used to estimate the conditional cumulative posterior dis-
tribution function F(θ|sobs) and to provide posterior quantiles by inversion.
An advantage of quantile regression forest is that tolerance rate should not
be speciﬁed and standard parameters of random forest can be considered
instead. A simulation study of coalescent models shows that regression ad-
justment can shrink posterior excessively by contrast to quantile regression
forest [19].
3.6
Conclusion
This chapter introduces regression adjustment for approximate Bayesian com-
putation [3,8]. We explain why regression adjustment shrinks posterior distri-
bution, which is a desirable feature because credibility intervals obtained with
rejection methods can be too wide [1]. When inferring admixture with single
nucleotide polymorphisms data in a complex of butterﬂy species, the poste-
rior distribution obtained with regression adjustment was not only shrunk
when compared to standard rejection, but also shifted to larger values, which
conﬁrm results obtained for this species complex with other statistical ap-
proaches [26]. We have introduced diﬀerent variants of regression adjustment,
and it might be diﬃcult for ABC users to choose which adjustment is appro-
priate in their context. We argue that there is no best strategy in general.
In the admixture example, we found, based on a cross-validation error crite-
rion, that homoscedastic linear adjustment provides considerable improvement
compared to rejection. More advanced adjustments provide almost negligible
improvements if no improvement at all. However, in a model of phylodynam-
ics, non-linear adjustment was reported to achieve considerable improvement
compared to linear adjustment [9]. In practical applications of ABC, we sug-
gest to compute errors, such as cross-validation estimation errors to choose a
particular method for regression adjustment.

Regression Approaches for ABC
83
With the rapid development of complex machine learning approaches, we
envision that regression approaches for approximate Bayesian computation
can be further improved to provide more reliable inference for complex models
in biology and ecology.
References
[1] M
G
B
Blum.
Approximate
Bayesian
computation:
A
nonpara-
metric perspective. Journal of the American Statistical Association,
105(491):1178–1187, 2010.
[2] K Csill´ery, M G B Blum, O E Gaggiotti, and O Fran¸cois. Approximate
Bayesian computation (ABC) in practice. Trends in Ecology & Evolution,
25(7):410–418, 2010.
[3] M A Beaumont, W Zhang, and D J Balding. Approximate Bayesian
computation
in
population
genetics.
Genetics,
162(4):2025–2035,
2002.
[4] P Marjoram, J Molitor, V Plagnol, and S Tavar´e. Markov chain Monte
Carlo without likelihoods. Proceedings of the National Academy of
Sciences, 100(26):15324–15328, 2003.
[5] S A Sisson, Y Fan, and M M Tanaka. Sequential Monte Carlo without
likelihoods. Proceedings of the National Academy of Sciences, 104(6):
1760–1765, 2007.
[6] R R Hudson. Generating samples under a wright–ﬁsher neutral model
of genetic variation. Bioinformatics, 18(2):337–338, 2002.
[7] M A Beaumont, J-M Cornuet, J-M Marin, and C P Robert. Adaptive
approximate Bayesian computation. Biometrika, 96(4):983–990, 2009.
[8] M G B Blum and O Fran¸cois. Non-linear regression models for
Approximate Bayesian computation. Statistics and Computing, 20:63–73,
2010.
[9] E Saulnier, O Gascuel, and S Alizon. Inferring epidemiological parameters
from phylogenies using regression-ABC: A comparative study. PLoS
Computational Biology, 13(3):e1005416, 2017.
[10] J-M Cornuet, P Pudlo, J Veyssier, A Dehne-Garcia, M Gautier,
R Leblois, J-M Marin, and A Estoup. DIYABC v2. 0: A software to
make approximate Bayesian computation inferences about population
history using single nucleotide polymorphism, DNA sequence and
microsatellite data. Bioinformatics, 30(8):1187–1189, 2014.

84
Handbook of Approximate Bayesian Computation
[11] K Csill´ery, O Fran¸cois, and M G B Blum. ABC: An R package for
approximate Bayesian computation (ABC). Methods in Ecology and
Evolution, 3(3):475–479, 2012.
[12] J K Pritchard, M T Seielstad, A Perez-Lezaun, and M W Feldman.
Population growth of human Y chromosomes: A study of Y chromosome
microsatellites
chromosome
microsatellites.
Molecular
Biology
and
Evolution, 16(12):1791–1798, 1999.
[13] B W Silverman. Density Estimation for Statistics and Data Analysis,
Volume 26. CRC Press, London, UK, 1986.
[14] G Biau, F C´erou, A Guyader, et al. New insights into approxi-
mate Bayesian computation. In Annales de l’Institut Henri Poincar´e,
Probabilit´es et Statistiques, volume 51, pp. 376–403. Institut Henri
Poincar´e, Paris, 2015.
[15] G S Rodrigues, D J Nott, and S A Sisson. Functional regression
approximate
Bayesian
computation
for
Gaussian
process
density
estimation. Computational Statistics & Data Analysis, 103:229–241, 2016.
[16] B D Ripley. Neural networks and related methods for classiﬁcation. Jour-
nal of the Royal Statistical Society. Series B (Methodological), volume 56,
pp. 409–456, 1994.
[17] P Fearnhead and D Prangle. Constructing summary statistics for
approximate
Bayesian
computation:
Semi-automatic
approximate
Bayesian computation. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 74(3):419–474, 2012.
[18] M G B Blum, D Nunes, D Prangle, S A Sisson, et al. A comparative
review
of
dimension
reduction
methods
in
approximate
Bayesian
computation. Statistical Science, 28(2):189–208, 2013.
[19] L Raynal, J-M Marin, P Pudlo, M Ribatet, C P Robert, and A Estoup.
ABC random forests for Bayesian parameter inference. arXiv preprint
arXiv:1605.05537, 2016.
[20] R J Hyndman, D M Bashtannyk, and G K Grunwald. Estimating and
visualizing conditional densities. Journal of Computing and Graphical
Statistics, 5:315–336, 1996.
[21] B E Hansen. Nonparametric conditional density estimation. Working
paper available at http://www.ssc.wisc.edu/ bhansen/papers/ncde.pdf,
2004.

Regression Approaches for ABC
85
[22] S Barber, J Voss, and M Webster. The rate of convergence for
approximate
Bayesian
computation.
Electronic
Journal
of
Statis-
tics Electronic Journal of Statistics Electronic Journal of Statistics,
9:80–105, 2015.
[23] D W Scott. Multivariate Density Estimation: Theory, Practice, and
Visualization. John Wiley & Sons, New York, 2009.
[24] R R Hudson. Gene genealogies and the coalescent process. Oxford
Surveys in Evolutionary Biology, 7(1):44, 1990.
[25] N A Rosenberg and M Nordborg. Genealogical trees, coalescent theory
and the analysis of genetic polymorphisms. Nature Reviews Genetics,
3(5):380–390, 2002.
[26] T Capblancq, L Despr´es, D Rioux, and J Mav´arez. Hybridization
promotes speciation in coenonympha butterﬂies. Molecular Ecology,
24(24):6209–6222, 2015.
[27] R Core Team. R: A Language and Environment for Statistical Computing.
R Foundation for Statistical Computing, Vienna, Austria, 2016.
[28] S Nakagome, K Fukumizu, and S Mano. Kernel approximate Bayesian
computation in population genetic inferences. Statistical Applications in
Genetics and Molecular Biology, 12(6):667–678, 2013.
[29] J Mitrovic, D Sejdinovic, and Y Teh. DR-ABC: Approximate Bayesian
computation with kernel-based distribution regression. In Proceedings of
ICML 2016, volume 48, pp. 1482–1491. JMLR W&CP, New York, 2016.
[30] M Park, W Jitkrittum, and D Sejdinovic. K2-ABC: Approximate
Bayesian computation with inﬁnite dimensional summary statistics via
kernel embeddings. Proceedings of AISTATS, pp. 398–407, 2016.
[31] N Meinshausen. Quantile regression forests. Journal of Machine Learning
Research, 7(Jun):983–999, 2006.


4
ABC Samplers
S. A. Sisson and Y. Fan
CONTENTS
4.1
Introduction ......................................................
88
4.2
Rejection and Importance Sampling .............................
89
4.2.1
Rejection sampling ......................................
89
4.2.2
Importance sampling ....................................
91
4.2.3
Importance/rejection sampler variants ..................
95
4.2.3.1
Rejection control importance sampling ......
95
4.2.3.2
ABC importance sampling ...................
96
4.2.3.3
ABC rejection sampling with
stopping rule ..................................
99
4.2.3.4
Rejection-based ABC algorithms for
expensive simulators ..........................
99
4.2.3.5
Marginal ABC samplers ......................
100
4.3
Markov Chain Monte Carlo Methods ............................
102
4.3.1
ABC-Markov chain Monte Carlo samplers ..............
102
4.3.2
Augmented space ABC-Markov chain Monte Carlo
samplers ................................................
105
4.3.3
Other ABC-Markov chain Monte Carlo samplers .......
107
4.4
Sequential Monte Carlo Sampling ...............................
109
4.4.1
Sequential importance sampling ........................
110
4.4.2
Sequential Monte Carlo samplers .......................
113
4.5
Discussion ........................................................
116
Acknowledgements .......................................................
117
References
...............................................................
117
87

88
Handbook of Approximate Bayesian Computation
4.1
Introduction
Approximate Bayesian computation (ABC) is a phrase that describes a collec-
tion of methods and algorithms designed to perform a Bayesian analysis using
an approximation to the true posterior distribution, when the likelihood func-
tion implied by the data generating process is computationally intractable. For
observed data yobs ∈Y, the likelihood function p(y|θ) depends on a vector of
model parameters θ ∈Θ, from which prior beliefs π(θ) may be updated into
posterior beliefs π(θ|yobs) ∝p(yobs|θ)π(θ) via Bayes’ theorem. In the standard
ABC framework (see e.g. Sisson et al. 2018, Chapter 1, this volume), the ABC
approximation to π(θ|yobs) is given by:
πABC(θ|sobs) ∝

Kh(∥s −sobs∥)p(s|θ)π(θ)ds,
(4.1)
where Kh(u) = K(u/h)/h is a standard kernel density function with scale
parameter h > 0, ∥· ∥is an appropriate distance metric (e.g. Euclidean or
Mahalanobis distance), p(s|θ) is the (intractable) likelihood function of the
low-dimensional vector of summary statistics s = S(y) implied by p(y|θ), and
sobs = S(yobs). Deﬁning Kh(∥s −sobs∥) →δsobs(s) as h →0, where δZ(z)
denotes the Dirac measure, deﬁned as δZ(z) = 1 if z ∈Z and δZ(z) = 0
otherwise, then as a result:
lim
h→0 πABC(θ|sobs) ∝

δsobs(s)p(s|θ)π(θ)ds = p(sobs|θ)π(θ) ∝π(θ|sobs).
Accordingly, πABC(θ|sobs) provides an approximation to the partial posterior
π(θ|sobs), which becomes more accurate as h gets small. If the summary statis-
tics s are suﬃcient for θ, then π(θ|sobs) will equal π(θ|yobs), and so, for small
h, the ABC posterior approximation πABC(θ|sobs) will be a good approxima-
tion of the true posterior. If either s is not suﬃcient, or h is not small, then
the ABC posterior approximation πABC(θ|sobs) will be of the form (4.1).
In terms of drawing samples from the approximate posterior πABC(θ|sobs),
the choice of summary statistics s = S(y) is typically considered known, and
interest is then in sampling from πABC(θ|sobs), for a speciﬁc and low value of
h, as eﬃciently as possible. The more eﬃcient the simulation procedure, the
further h can be lowered within the sampling framework, resulting in samples
from a more accurate approximation of π(θ|sobs).
In this chapter, we survey the various forms of ABC algorithms that have
been developed to sample from πABC(θ|sobs). These have broadly followed
the familiar Monte Carlo classes of algorithms, including rejection and impor-
tance sampling, Markov chain Monte Carlo (MCMC), and sequential Monte
Carlo (SMC)-based algorithms. While each of these classes have their ABC-
speciﬁc implementations and characteristics, in general, they target the joint
distribution of parameter vector θ and summary statistic s given by:
πABC(θ, s|sobs) ∝Kh(∥s −sobs∥)p(s|θ)π(θ).
(4.2)

ABC Samplers
89
By noting that (4.1) is obtained from (4.2) by integrating over s (i.e.
πABC(θ|sobs) =

πABC(θ, s|sobs)ds), samples from πABC(θ|sobs) can be ob-
tained by ﬁrst drawing samples from (4.2) and then discarding the marginal
s values.
An alternative, but related Monte Carlo approach is based on sampling
from (4.1) directly, by obtaining an unbiased and non-negative estimate of
the ABC posterior distribution function, such as:
ˆπABC(θ|sobs) ∝π(θ)
T
T

t=1
Kh(∥s(t) −sobs∥),
where s(1), . . . , s(T) ∼p(s|θ) are samples from the intractable model given θ,
and then using this estimate in place of πABC(θ|sobs) within a standard Monte
Carlo algorithm (e.g. Del Moral et al. 2012). This approach falls within the
family of pseudo-marginal Monte Carlo methods (Beaumont 2003; Andrieu
and Roberts 2009), a more general class of likelihood-free samplers that has
gained popularity outside of the ABC setting. For a detailed and in-depth
discussion of the connections between ABC-MCMC algorithms and pseudo-
marginal MCMC methods see Andrieu et al. (2019) (Chapter 9, this volume).
4.2
Rejection and Importance Sampling
4.2.1
Rejection sampling
The earliest ABC samplers (e.g. Tavar´e et al. 1997; Pritchard et al. 1999) were
basic rejection sampling algorithms. Under the standard rejection sampling
framework (e.g. Ripley 1987; Liu 2001), interest is in obtaining samples from
some target distribution f(θ) = Z−1 ˜f(θ), which is known up to a normalising
constant Z =
 ∞
−∞˜f(θ)dθ. The standard rejection sampling algorithm obtains
draws θ′ ∼g(θ) from a sampling density g(θ) from which it is trivial to sample,
such that:
˜f(θ) ≤Mg(θ),
for all θ and some positive constant M > 0. The draws θ′ are then accepted
as independent samples from the target density f(θ) with probability
˜
f(θ′)
Mg(θ′).
To see that the above procedure is correct, for simplicity, consider the case in
which θ is univariate, with the extension to multivariate θ being straightfor-
ward. Deﬁne A as the event that a sample θ′ from g(θ) is accepted. Then, the
overall acceptance rate of the algorithm is:
Pr(A) =

˜f(θ)
Mg(θ)g(θ)dθ = 1
M

˜f(θ)dθ = Z
M ,

90
Handbook of Approximate Bayesian Computation
and hence the distribution of accepted draws is:
Pr(θ′ ≤θ|A) = Pr(θ′ ≤θ, A)
Pr(A)
=
 θ
−∞
˜
f(θ′)
Mg(θ′)g(θ′)dθ′
P(A)
= F(θ),
as required, where F(θ) =
 θ
−∞f(z)dz is the distribution function associ-
ated with f(θ). The eﬃciency of the algorithm is associated with the value
of M, with smaller values of M (subject to ˜f(θ) ≤Mg(θ), ∀θ) correspond-
ing to more eﬃcient samplers. That is, for ﬁxed g(θ), the optimum choice is
M = maxθ
˜
f(θ)
g(θ). Good choice of the sampling distribution g(θ), for example
to approximate f(θ), can result in smaller values of M.
The ABC version of the rejection sampler was discussed in Sisson et al.
(2018) (Chapter 1, this volume), which we reproduce here as Algorithm 4.1.
Algorithm 4.1: ABC Rejection Sampling
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ) consisting of a prior
distribution π(θ) and a procedure for generating data under the model
p(yobs|θ).
• A proposal density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• An integer N > 0.
• A kernel function Kh(u) and scale parameter h > 0.
• A low-dimensional vector of summary statistics s = S(y).
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from sampling density g.
2. Generate y(i) ∼p(y|θ(i)) from the model.
3. Compute summary statistic s(i) = S(y(i)).
4. Accept
θ(i)
with
probability
Kh(∥s(i)−sobs∥)π(θ(i))
Mg(θ(i))
where
M
≥
Kh(0) maxθ
π(θ)
g(θ) .
Else go to 1.
Output:
A set of parameter vectors θ(1), . . . , θ(N) ∼πABC(θ|sobs).
Originally developed by Pritchard et al. (1999) following earlier ideas by
Tavar´e et al. (1997), the ABC rejection sampling algorithm is typically de-
scribed heuristically as follows: for the candidate parameter vector θ′ ∼g(θ),
a dataset y′ is generated from the (intractable) generative model and summary

ABC Samplers
91
statistics s′ = S(y′) computed. If the simulated and observed datasets are sim-
ilar (in some manner), so that s′ ≈sobs, then θ′ could credibly have generated
the observed data under the given model, and so θ′ is retained and forms part
of the sample from the ABC posterior distribution π(θ|sobs). Conversely, if s′
and sobs are dissimilar, then θ′ is unlikely to have generated the observed data
for this model, and so θ′ is discarded. The parameter vectors accepted under
this approach oﬀer support for sobs under the model and so may be considered
to be drawn approximately from the posterior distribution π(θ|sobs). In this
manner, the evaluation of the likelihood p(yobs|θ′), essential to most Bayesian
posterior simulation methods, is replaced by an evaluation of the proximity
of summaries of a simulated dataset s′ to the observed summaries sobs.
More precisely, this algorithm targets πABC(θ, s|sobs) given by (4.2), the
joint distribution of parameter vector and summary statistic given sobs.
Accordingly, the sampling distribution is also deﬁned on this space as
g(θ, s) = p(s|θ)g(θ), and the acceptance probability of the vector (θ, s) is
then given by:
πABC(θ, s|sobs)
Mg(θ, s)
∝Kh(∥s −sobs∥)p(s|θ)π(θ)
Mp(s|θ)g(θ)
= Kh(∥s −sobs∥)π(θ)
Mg(θ)
.
The normalising constant M is similarly given by:
M ≥max
s,θ
Kh(∥s −sobs∥)p(s|θ)π(θ)
p(s|θ)g(θ)
= Kh(0) max
θ
π(θ)
g(θ) ,
with maxs Kh(∥s −sobs∥) = Kh(0) resulting from the zero-mean, symmetry
and (typically) unimodal characteristics of standard kernel density functions.
Accordingly, the construction of the target and sampling distributions on the
joint space (θ, s) results in the form of the acceptance probability and nor-
malisation constant M being free of intractable likelihood terms. An example
implementation of this algorithm is given in Sisson et al. (2018) (Chapter 1,
this volume).
4.2.2
Importance sampling
One down side of rejection sampling is the need to determine a near opti-
mal value for the normalising constant M in order to produce an eﬃcient
algorithm. Importance sampling is a procedure that, rather than calculat-
ing acceptance probabilities, avoids this by alternatively assigning the draw
θ′ ∼g(θ) an (importance) weight w(θ′) = f(θ′)/g(θ′). The weighted vector θ′
is then a draw from f(θ), and desired expectations under the target distribu-
tion f are computed as weighted expectations under the importance sampling
density g.
To see this, suppose that we are interested in estimating the expectation:
Ef[h(θ)] =

h(θ)f(θ)dθ.

92
Handbook of Approximate Bayesian Computation
By deﬁning w(θ) = f(θ)/g(θ) we have:
Eg[w(θ)h(θ)] =

w(θ)h(θ)g(θ)dθ =

h(θ)f(θ)dθ = Ef[h(θ)].
In this manner we can then estimate the expectation as:
Ef[h(θ)] ≈1
N
N

i=1
w(i)h(θ(i)),
where w(i) = w(θ(i)), and where θ(i) ∼g(θ) are draws from g. In the more
typical case where the target distribution is unnormalised, so that f(θ) =
Z−1 ˜f(θ), we can work with ˜f(θ) only by deﬁning ˜w(θ) = ˜f(θ)/g(θ) and then
noting that:
Eg[ ˜w(θ)] =

˜w(θ)g(θ)dθ =

˜f(θ)dθ = Z ≈1
N
N

i=1
˜w(i),
(4.3)
for θ(i) ∼g(θ), where ˜w(i) = ˜w(θ(i)). As a result, the expectation Ef[h(θ)]
may be approximated as:
Ef[h(θ)]
=

h(θ)f(θ) = 1
Z

h(θ) ˜f(θ)
=
1
Z

˜w(θ)h(θ)g(θ)dθ = Eg[ ˜w(θ)h(θ)]
Eg[ ˜w(θ)]
≈
1
N
N
i=1 ˜w(i)h(θ(i))
1
N
N
i=1 ˜w(i)
=
N

i=1
W (i)h(θ(i)),
(4.4)
for θ(i) ∼g(θ), where W (i) = ˜w(i)/ N
j=1 ˜w(j) denotes normalised weights.
This approximation is not unbiased due to the biased estimator of 1/Z,
although the bias becomes small as N becomes large.
From an ABC perspective, importance sampling works much the same as
rejection sampling. The target distribution is πABC(θ, s|sobs), and the impor-
tance distribution on joint parameter value and summary statistics space is
g(θ, s) = p(s|θ)g(θ). As a result, the (unnormalised) importance weights are
computed as:
πABC(θ, s|sobs)
g(θ, s)
∝Kh(∥s −sobs∥)p(s|θ)π(θ)
p(s|θ)g(θ)
= Kh(∥s −sobs∥)π(θ)
g(θ)
:= ˜w(θ),
which is again free of intractable likelihood terms. The full ABC importance
sampling algorithm is given in Algorithm 4.2.
As with rejection sampling, the choice of the (marginal) importance distri-
bution g(θ) is crucial to the eﬃciency of the algorithm. In standard importance
sampling, if g(θ) ∝˜f(θ), then ˜w(θ) ∝1. In this case, there is no variation in

ABC Samplers
93
Algorithm 4.2: ABC Importance Sampling
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ), consisting of a prior
distribution π(θ) and a procedure for generating data under the model
p(yobs|θ).
• An importance sampling density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• An integer N > 0.
• A kernel function Kh(u) and scale parameter h > 0.
• A low-dimensional vector of summary statistics s = S(y).
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from importance sampling density g.
2. Generate y(i) ∼p(y|θ(i)) from the model.
3. Compute summary statistic s(i) = S(y(i)).
4. Compute weight ˜w(i) = Kh(∥s(i) −sobs∥)π(θ(i))/g(θ(i)).
Output:
A set of weighted parameter vectors (θ(1), ˜w(1)), . . . , (θ(N), ˜w(N)) ∼
πABC(θ|sobs).
the importance weights, and each sample θ(i) contributes equally when com-
puting posterior expectations via (4.4). However, if g(θ) is diﬀerent to ˜f(θ),
then the variability in ˜w(θ) from θ means that some samples θ(i) will con-
tribute more than others in this computation. In extreme cases, Monte Carlo
estimates of expectations can be highly variable when they are dominated by
a small number of θ(i) with relatively large weights. This is known as sample
degeneracy. Accordingly, for importance sampling algorithms, the focus is on
reducing the variability of ˜w(θ) over θ.
A common measure of the degree of sample degeneracy is the eﬀective
sample size (ESS) (Liu et al. 1998; Liu 2001), estimated as:
ESS =
 N

i=1
[W (i)]2
−1
,
1 ≤ESS ≤N,
(4.5)
which is computed using the normalised weights W (i) = ˜w(i)/ N
j=1 ˜w(j). The
ESS is an estimate of the eﬀective number of equally weighted θ(i) in a given
weighted sample, which can be loosely interpreted as the information content.
When g(θ) ∝˜f(θ) so that we have samples directly from f(θ), then W (i) =1/N

94
Handbook of Approximate Bayesian Computation
and ESS = N. However, when there is severe particle degeneracy in the
extreme case where W (1) = 1 and W (i) = 0 for i = 2, . . . , N, then ESS = 1.
Speciﬁcally in the ABC framework where ˜w(θ(i)) = Kh(∥s(i)−sobs∥)π(θ(i))/
g(θ(i)), if g is diﬀuse compared to the (marginal) target distribution
πABC(θ|sobs), samples θ(i) ∼g(θ) from regions of low posterior density will
tend to generate summary statistics s(i) that are very far from the observed
statistics sobs, and this will produce low weights w(i) compared to samples
θ(i) in regions of high posterior density. This is the same as for the standard
importance sampling case. However, in ABC importance sampling, an addi-
tional factor is that the importance weight ˜w(θ) is a function of the kernel
function Kh(∥s −sobs∥), which contains the stochastic term s. This has some
implications, which are also relevant for sequential Monte Carlo-based ABC
samplers, discussed in Section 4.4.
When Kh has non-compact support, such as when Kh(u) = φ(u; 0, h2),
where φ(x; μ, σ2) denotes the Gaussian density function with mean μ and
variance σ2, the importance weight ˜w(i) is guaranteed to be non-zero for each i.
However, the resulting importance weight can be highly variable, depending
on whether s(i) is close to or far from sobs. This typically produces samples
(θ(i), ˜w(i)) with low eﬀective sample sizes.
If Kh has a compact support (and this is typical in most ABC implementa-
tions), then ˜w(i) = 0 is likely for small h, even when θ(i) is in a high posterior
density region. This means that Algorithm 4.2 will return many (θ(i), ˜w(i)) for
which the weight is exactly zero, resulting in low eﬀective sample sizes, and
maybe even complete algorithm failure if ˜w(i) = 0 for all i = 1, . . . , N. As a
result, a common variation of Algorithm 4.2 is to repeat steps 1–4 for each
i, until a non-zero weight has been generated. This eﬀectively introduces a
rejection sampling step within the importance sampling algorithm. This idea
(c.f. Fernhead and Prangle 2012) can be used to improve the ESS for ABC
importance sampling algorithms, regardless of the choice of the kernel, by
modifying step 4 in Algorithm 4.2 to be
Algorithm 4.3: ABC Importance/Rejection Sampling
Same as Algorithm 4.2, but replacing step 4 of Sampling with:
4. With probability Kh(∥s(i) −sobs∥)/Kh(0) set ˜w(i) = π(θ(i))/g(θ(i)), else
go to 1.
When
Kh
has
compact
support,
this
ensures
that
steps
1–4
of
Algorithm 4.2 are repeated until Kh(∥s(i) −sobs∥) is non-zero. When Kh
has non-compact support, this oﬀers some control over the variability of the
weights, as only samples for which s(i) is reasonably close to sobs are likely to
be accepted.
Under Algorithm 4.3, in the particular case of when Kh is the uniform ker-
nel on [−h, h], if in addition g(θ) ∝π(θ), so that the importance distribution is

ABC Samplers
95
proportional to the prior, then ˜w(i) ∝1 for any i. This results in W (i) = 1/N
and ESS = N, and the ABC importance sampling algorithm eﬀectively re-
duces to the ABC rejection sampling algorithm, but without the need to
compute the normalising constant M. This setup is very common in prac-
tice, as it removes the need to compute importance weights, and to worry
about algorithm performance with respect to eﬀective sample size, which is
always maximised. However, in this case, algorithm performance is dominated
by the number of times steps 1–4 are repeated before a sample θ(i) is ac-
cepted. In general, the eﬃciency of Algorithm 4.3 is a combination of the
resulting eﬀective sample size and the number of repetitions of the sampling
steps 1–4.
4.2.3
Importance/rejection sampler variants
There are many variants on ABC importance and rejection samplers. A few of
these are detailed in the following, chosen either because of their popularity,
or because of their links with particular ABC samplers discussed in later
sections.
4.2.3.1
Rejection control importance sampling
Liu et al. (1998) developed a general importance-rejection algorithm technique
known as rejection control, with the aim of reducing the number of θ(i) samples
that are produced with very small weights in an importance sampler. This
method was exploited within an ABC sequential Monte Carlo framework by
Sisson et al. (2007) and Peters et al. (2012) (see Section 4.4), however, it may
also be implemented directly within an ABC importance sampler as outlined
in the following.
Suppose that a weighted sample (θ(i), ˜w(i)) is drawn from f(θ) using an
importance sampling algorithm. In order to control the size of the importance
weight, ˜w(i) is compared to some pre-speciﬁed threshold value c > 0. If ˜w(i) > c
then the weight is considered suﬃciently large, and the sample θ(i) is accepted.
However, if ˜w(i) < c, then θ(i) is probabilistically rejected, with a higher
rejection rate for lower ˜w(i). In this manner, the variability of the accepted
importance weights can be reduced. In particular, each sample θ(i) is accepted
with probability:
r(i) = min

1, ˜w(i)
c
	
,
which results in the automatic acceptance of samples for which ˜w(i) > c and
an acceptance probability of ˜w(i)/c otherwise. This means that larger c results
in less variable weights, although at the price of more rejections. The accepted
samples are then draws from the modiﬁed importance sampling distribution:
g∗(θ) = M −1 min

1, ˜w(θ)
c
	
g(θ),

96
Handbook of Approximate Bayesian Computation
where ˜w(θ) = ˜f(θ)/g(θ) and with normalising constant M =

min{1, ˜w(θ)/c}
g(θ)dθ. As a result, setting:
˜w∗(θ) =
˜f(θ)
g∗(θ)
˜w∗(i) =
˜f(θ(i))
g∗(θ(i)) = M ˜w(i)
r(i) ,
(4.6)
means that the samples (θ(i), ˜w∗(i)) will be weighted samples from f(θ), but
with the property that:
V arg∗

 ˜f(θ)
g∗(θ)

≤V arg

 ˜f(θ)
g(θ)

.
(4.7)
That is, the rejection control algorithm can reduce the variance of the
importance weights (Liu 2001). While it may be diﬃcult to evaluate
M = Eg

min

1, ˜
w(θ)
c

analytically, it may be estimated from the samples
(θ(i), ˜w(i)) via:
ˆ
M ≈1
N
N

i=1
min

1, ˜w(i)
c
	
.
If an estimate of M is not required, its computation can be avoided for
importance sampling purposes by calculating the normalised weights W ∗(i) =
˜w∗(i)/ N
j=1 ˜w∗(j), as the M term then cancels in numerator and denominator.
As with ABC rejection sampling (Algorithm 4.2), the ABC implementation
of rejection control importance sampling targets πABC(θ, s|sobs), resulting in a
weight calculation of ˜w(i) = Kh(∥s(i)−sobs∥)π(θ(i))/g(θ(i)). The full algorithm
is given in Algorithm 4.4.
Note that while Algorithm 4.4 requires pre-speciﬁcation of the rejection
threshold c, a suitable value may be practically diﬃcult to determine in ad-
vance. As such, Algorithm 4.4 may be alternatively executed by ﬁrst im-
plementing steps 1–3 only for i = 1, . . . , N, and then specifying c as some
quantile of the resulting empirical distribution of ˜w(1), . . . , ˜w(N). Following
this, Algorithm 4.4 may then continue implementation from step 4 onwards
for each i = 1, . . . , N (e.g. Peters et al. 2012).
As with ABC importance/rejection sampling (Algorithm 4.3), when Kh
has compact support, rejection control will replace those samples for which
the simulated and observed summary statistics are too far apart, resulting in
˜w(i) = 0. More generally, however, rejection control provides much greater
control over the variability of the weights regardless of Kh, producing more
uniform weights for larger c. The price for this control is the greater number
of rejections induced as c increases (Peters et al. 2012).
4.2.3.2
ABC importance sampling
While most published descriptions of importance and rejection sampling ABC
algorithms follow the format given in Algorithms 4.1 through 4.4, in practice it

ABC Samplers
97
Algorithm 4.4: ABC Rejection Control Importance Sampling
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ) consisting of a prior
distribution π(θ) and a procedure for generating data under the model
p(yobs|θ).
• An importance sampling density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• An integer N > 0.
• A kernel function Kh(u) and scale parameter h > 0.
• A low-dimensional vector of summary statistics s = S(y).
• A rejection control threshold c > 0.
Sampling:
For i = 1, . . . , N:
1. Generate θ(i) ∼g(θ) from importance sampling density g.
2. Generate y(i) ∼p(y|θ(i)) from the model and compute summary statistic
s(i) = S(y(i)).
3. Compute weight ˜w(i) = Kh(∥s(i) −sobs∥)π(θ(i))/g(θ(i)).
4. Reject θ(i) with probability 1−r(i) = 1−min{1, ˜
w(i)
c }, and go to Step 1.
5. Otherwise, accept θ(i) and set modiﬁed weight ˜w∗(i) = ˜w(i)/r(i).
Output:
A set of weighted parameter vectors (θ(1), ˜w∗(1)), . . . , (θ(N), ˜w∗(N)) ∼
πABC(θ|sobs).
is not uncommon to deviate from these and implement a slight variation. The
reason for this is that Algorithms 4.1 through 4.4 require pre-speciﬁcation of
the kernel scale parameter h > 0, without which, importance weights cannot
be calculated and accept/reject decisions cannot be made. In reality, as the
scale of the distances ∥s(i) −sobs∥is unlikely to be known in advance, it is
diﬃcult to pre-determine a suitable value for h.
Algorithm 4.5 presents a variation on the ABC importance sampler of
Algorithm 4.3 that avoids pre-speciﬁcation of h. Here, a large number N ′
of (θ(i), s(i)) pairs are generated from the importance sampling distribution
p(s|θ)g(θ). These are the only samples that will be used in the algorithm, so
the computational overheads are ﬁxed at N ′ draws from the model, unlike
Algorithm 4.3, in which the number of draws is random and unknown in
advance. The N samples for which s(i) is closest to sobs (as measured by ∥· ∥)
are then identiﬁed, and h determined to be the smallest possible value so
that only these N samples have non-zero weights (assuming a kernel Kh with
compact support). Once h is ﬁxed, the importance weights can be calculated

98
Handbook of Approximate Bayesian Computation
Algorithm 4.5: ABC k-nn Importance Sampling
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ) consisting of a prior
distribution π(θ), and a procedure for generating data under the model
p(yobs|θ).
• An importance sampling density g(θ), with g(θ) > 0 if π(θ|yobs) > 0.
• Integers N ′ ≫N > 0.
• A kernel function Kh(u) with compact support.
• A low-dimensional vector of summary statistics s = S(y).
Sampling:
For i = 1, . . . , N ′:
1. Generate θ(i) ∼g(θ) from importance sampling density g.
2. Generate y(i) ∼p(y|θ(i)) from the model.
3. Compute summary statistic s(i) = S(y(i)).
• Identify the N-nearest neighbours of sobs as measured by ∥s(i) −sobs∥.
• Index these nearest neighbours by [1], . . . , [N].
• Set h to be the largest possible value, such that Kh(maxi{∥s([i]) −
sobs∥}) = 0.
• Compute weights ˜w([i]) = Kh(∥s([i]) −sobs∥)π(θ([i]))/g(θ([i])) for i =
1, . . . , N.
Output:
A set of weighted parameter vectors (θ([1]), ˜w([1])), . . . , (θ([N]), ˜w([N])) ∼
πABC(θ|sobs).
as before, and the N samples (θ(i), ˜w(i)) with non-zero ˜w(i) are returned as
weighted samples from πABC(θ|sobs).
This approach is explicitly used in for example, Beaumont et al. (2002)
and Blum et al. (2013), and implicitly in many other ABC implementations.
The diﬀerences between Algorithms 4.3 and 4.5 may seem small- if the value
of h determined in Algorithm 4.5 was used in Algorithm 4.3, then (assuming
the same pseudo-random numbers used in the appropriate places) the result-
ing draws from πABC(θ|sobs) would be identical. However, Algorithm 4.5 is
based on a k-nearest neighbour algorithm for density estimation of the ABC
likelihood function, and so possesses very diﬀerent theoretical properties com-
pared to Algorithm 4.3. This k-nearest neighbour approach is discussed and
analysed in detail in the rejection sampling context by Biau et al. (2015).

ABC Samplers
99
4.2.3.3
ABC rejection sampling with stopping rule
A version of ABC rejection sampling (Algorithm 4.1) which similarly does not
require pre-speciﬁcation of the kernel scale parameter h > 0 is presented in
Example 6 (Section 1.7.2) of Sisson et al. (2018, Chapter 1, this volume). We
do not reproduce this algorithm here for brevity. The algorithm identiﬁes the
smallest value of h needed to accept exactly N samples before some stopping
rule is achieved. This stopping rule could be based on an overall computa-
tional budget [such as using exactly N ′ total draws from p(s|θ)] or on some
perceived level of accuracy of the resulting ABC posterior approximation.
If the stopping rule is based on an overall computational budget of exactly
N ′ draws from p(s|θ) (and again the same pseudo-random numbers), this al-
gorithm will produce exactly the same ﬁnal samples from πABC(θ|sobs) as
Algorithm 4.1, were the ABC rejection sampler to adopt the identiﬁed choice
of h. Of course, the advantage here is that the value of h is automatically
determined.
4.2.3.4
Rejection-based ABC algorithms for expensive simulators
It is not uncommon for the data generation step y(i) ∼p(y|θ(i)) in ABC
algorithms to be expensive and thereby dominate the computational overheads
of the algorithms. While there are a few principled ways to mitigate this (see
discussion of Prangle et al. 2017 and Everitt and Rowi´nska 2017 in Section
4.4.2), within rejection-based ABC algorithms, it is sometimes possible to
reject a proposed sampler θ(i) before generating the data y(i) ∼p(y|θ(i)). To
see this, note that e.g. step 4 of Algorithm 4.3
4. With probability Kh(∥s(i) −sobs∥)/Kh(0) set ˜w(i) = π(θ(i))/g(θ(i)), else
go to 1.
can be alternatively implemented as:
4. With probability π(θ(i))/g(θ(i)) set ˜w(i) = Kh(∥s(i) −sobs∥)/Kh(0), else
go to 1.
This means that steps 2 and 3 of Algorithm 4.3 (generate y(i) ∼p(y|θ(i))
and compute s(i) = S(y(i))) need not be performed until the event in step 4
with probability π(θ(i))/g(θ(i)) has occurred. This allows for a possible early
rejection of θ(i) before any data generation needs to take place. (Note that if
g(θ) = π(θ) there is no beneﬁt to be gained.) This modiﬁcation trades some
computational savings for weights ˜w(i) constructed from diﬀerent terms, and
thereby having diﬀerent variance properties. This idea, which is a standard
technique in standard sequential Monte Carlo samplers (e.g. Del Moral et al.
2006), can be implemented in any rejection-based ABC algorithm, including
ABC-MCMC and ABC-SMC samplers (Sections 4.3 and 4.4).

100
Handbook of Approximate Bayesian Computation
4.2.3.5
Marginal ABC samplers
Until now we have presented ABC algorithms as producing samples (θ(i), s(i))
exactly from the joint distribution πABC(θ, s|sobs) ∝Kh(∥s−sobs∥)p(s|θ)π(θ).
As a result, samples θ(i) from the ABC approximation to the posterior
π(θ|yobs) given by:
πABC(θ|sobs) ∝

Kh(∥s −sobs∥)p(s|θ)π(θ)ds,
may be obtained by marginalising over the realised s(i). An alternative
approach to construct an ABC algorithm could be to directly target the
(marginal) posterior πABC(θ|sobs) rather than the joint posterior πABC(θ,
s|sobs). This approach becomes apparent when noting that πABC(θ|sobs) can
be estimated pointwise (up to proportionality), for ﬁxed θ, as:

Kh(∥s −sobs∥)p(s|θ)π(θ)ds ≈π(θ)
T
T

t=1
Kh(∥s(t) −sobs∥) := ˆπABC(θ|sobs),
where s(1), . . . , s(T) ∼p(s|θ) are T independent draws of summary statistics
from the partial likelihood p(s|θ) for a given θ. This Monte Carlo estimate of
πABC(θ|sobs) is unbiased up to proportionality (in that Es|θ[ˆπABC(θ|sobs)] ∝
πABC(θ|sobs)), and so ˆπABC(θ|sobs) may be used in place of πABC(θ|sobs)
in a standard rejection or importance sampler which targets πABC(θ|sobs).
Using this substitution will produce a random, estimated acceptance prob-
ability or importance weight. However, because it is also unbiased (up to
proportionality), the resulting target distribution will remain the same as
if the exact weight had been used i.e. πABC(θ|sobs), although the sampler
weights/acceptances will become more variable. This is the so-called marginal
ABC sampler (e.g. Marjoram et al. 2003; Reeves and Pettitt 2005; Sisson
et al. 2007; Ratmann et al. 2009; Toni et al. 2009; Peters et al. 2012, among
others).
As with standard Monte Carlo estimates, the number of Monte Carlo draws
T aﬀects the variability of the ABC posterior estimator. Bornn et al. (2017)
explore the question of how many draws, T, produces the most eﬃcient over-
all sampler in the context of ABC rejection and Markov chain Monte Carlo
algorithms. If T is large, the estimate of πABC(θ|sobs) is accurate, and so
the acceptance probability is accurate, but at the cost of many Monte Carlo
draws, however, if T is small, the acceptance probability is highly variable,
but is much cheaper to evaluate. When using a uniform kernel Kh, Bornn
et al. (2017) conclude that in fact T = 1 is the most eﬃcient, as (loosely) the
combination of T draws used to accept one θ(i) could be better used to accept
up to T diﬀerent θ(i)’s, each using one Monte Carlo draw per ABC posterior
estimate.

ABC Samplers
101
The idea of the marginal ABC sampler is closely related to the construction
of the more recently developed pseudo-marginal sampler (Beaumont 2003;
Andrieu and Roberts 2009), a more general class of likelihood-free sampler
that has gained popularity outside of the ABC setting. Here, rather than
treating ˆπABC(θ|sobs) as an unbiased estimate of πABC(θ|sobs) in an algorithm
that targets πABC(θ|sobs), an alternative joint posterior distribution can be
constructed:
πABC(θ, s(1), . . . , s(T)|sobs) ∝

1
T
T

t=1
Kh(∥s(t) −sobs∥)
 
 T

t=1
p(s(t)|θ)

π(θ),
(4.8)
which is deﬁned over the joint posterior of θ and all T summary statistic
replicates (e.g. Sisson and Fan 2011; Del Moral et al. 2012), where T = 1
gives the usual ABC joint posterior πABC(θ, s|sobs). A useful property of this
form of joint posterior is that the θ-marginal distribution is the same for any
value of T, and in particular:

. . .

πABC(θ, s(1), . . . , s(T)|sobs)ds(1) . . . ds(T) = πABC(θ|sobs).
This means that any sampler targeting πABC(θ, s(1), . . . , s(T)|sobs) can pro-
duce samples from πABC(θ|sobs). Consider now an importance sampler tar-
geting πABC(θ, s(1), . . . , s(T)|sobs) with the importance sampling density:
g(θ, s(1), . . . , s(T)) = g(θ)
T

t=1
p(s(t)|θ).
The resulting importance weight is:
πABC(θ,s(1),...,s(T )|sobs)
g(θ,s(1),...,s(T ))
∝[ 1
T
T
t=1 Kh(∥s(t)−sobs∥)][
T
t=1 p(s(t)|θ)]π(θ)
g(θ) T
t=1 p(s(t)|θ)
= ˆπABC(θ|sobs)
g(θ)
.
This means that any marginal ABC sampler targeting πABC(θ|sobs) through
the unbiased estimate of the ABC posterior given by ˆπABC(θ|sobs) is directly
equivalent to an exact algorithm targeting πABC(θ, s(1), . . . , s(T)|sobs). That
is, all marginal ABC samplers are justiﬁed by their equivalent joint space ABC
algorithm.
This idea also extends to using unbiased approximations of posterior dis-
tributions within MCMC samplers (see next section), where the technique
has expanded beyond ABC algorithms to more general target distributions.
Here, it is more generally known as pseudo-marginal Monte Carlo methods.
See Andrieu et al. (2019) (Chapter 9, this volume) for a more detailed discus-
sion of the connections between ABC marginal samplers and pseudo-marginal
MCMC methods.

102
Handbook of Approximate Bayesian Computation
4.3
Markov Chain Monte Carlo Methods
Markov chain Monte Carlo (MCMC) methods are a highly accessible class
of algorithms for obtaining samples from complex distributions (e.g. Brooks
et al. 2011). By constructing a Markov chain with the target distribution of
interest as its limiting distribution, following chain convergence, a realised
random sample path from this chain will behave like a (serially correlated)
sample from the target distribution,. Their strong performance and simplicity
of implementation has made MCMC algorithms the dominant Monte Carlo
method for the past two decades (Brooks et al. 2011). As such, it is only
natural that MCMC-based ABC algorithms have been developed.
4.3.1
ABC-Markov chain Monte Carlo samplers
The Metropolis–Hastings algorithm is the most popular class of MCMC
algorithm. Given the current chain state θ(i), the next value in the sequence
is obtain by sampling a candidate value θ′ from a proposal distribution
θ′ ∼g(θ(i), θ) = g(θ|θ(i)), which is then accepted with probability a(θ, θ′) =
min{1, f(θ′)g(θ′,θ(i))
f(θ)g(θ(i),θ′) } so that θ(i+1) = θ′, or otherwise rejected so that θ(i+1) =
θ(i). Under this mechanism, the target distribution is f(θ), and there is great
ﬂexibility in the choice of the proposal distribution g. An implementation
of this sampler in the ABC setting is given in Algorithm 4.6. ABC MCMC
algorithms were originally developed by Marjoram et al. (2003). See for
example, Bortot et al. (2007), Wegmann et al. (2009), Ratmann et al. (2009),
Sisson and Fan (2011) and Andrieu et al. (2019) (Chapter 9, this volume) for
more discussion on ABC-MCMC samplers.
As with ABC importance and rejection samplers, the target distribution of
ABC MCMC algorithms is the joint ABC posterior πABC(θ, s|sobs). On this
space, the proposal distribution becomes:
g[(θ, s), (θ′, s′)] = g(θ, θ′)p(s′|θ′),
and, as a result the acceptance probability of the proposed move from
(θ(i), s(i)) to (θ′, s′) ∼g[(θ(i), s(i)), (θ′, s′)] becomes a[(θ(i), s(i)), (θ′, s′)] =
min{1, α[(θ(i), s(i)), (θ′, s′)]}, where
α[(θ(i), s(i)), (θ′, s′)] =
πABC(θ′, s′|sobs)g[(θ′, s′), (θ(i), s(i))]
πABC(θ(i), s(i)|sobs)g[(θ(i), s(i)), (θ′, s′)]
=
Kh(∥s′ −sobs∥)p(s′|θ′)π(θ′)
Kh(∥s(i) −sobs∥)p(s(i)|θ(i))π(θ(i))
g(θ′, θ(i))p(s(i)|θ(i))
g(θ(i), θ′)p(s′|θ′)
=
Kh(∥s′ −sobs∥)π(θ′)
Kh(∥s(i) −sobs∥)π(θ(i))
g(θ′, θ(i))
g(θ(i), θ′),
which is free of intractable likelihood terms, p(s|θ), and so may be directly
evaluated.

ABC Samplers
103
Algorithm 4.6: ABC Markov Chain Monte Carlo Algorithm
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ) consisting of a prior
distribution π(θ), and a procedure for generating data under the model
p(yobs|θ).
• A Markov proposal density g(θ, θ′) = g(θ′|θ).
• An integer N > 0.
• A kernel function Kh(u) and scale parameter h > 0.
• A low-dimensional vector of summary statistics s = S(y).
Initialise:
Repeat:
1. Choose an initial parameter vector θ(0) from the support of π(θ).
2. Generate y(0) ∼p(y|θ(0)) from the model and compute summary statis-
tics s(0) = S(y(0)),
until Kh(∥s(0) −sobs∥) > 0.
Sampling:
For i = 1, . . . , N:
1. Generate candidate vector θ′ ∼g(θ(i−1), θ) from the proposal density g.
2. Generate y′ ∼p(y|θ′) from the model and compute summary statistics
s′ = S(y′).
3. With probability:0
min

1,
Kh(∥s′ −sobs∥)π(θ′)g(θ′, θ(i−1))
Kh(∥s(i−1) −sobs∥)π(θ(i−1))g(θ(i−1), θ′)
	
set (θ(i), s(i)) = (θ′, s′). Otherwise set (θ(i), s(i)) = (θ(i−1), s(i−1)).
Output:
A set of correlated parameter vectors θ(1), . . . , θ(N) from a Markov chain
with stationary distribution πABC(θ|sobs).
Algorithm 4.6 satisﬁes the detailed balance (time reversibility) condition
with respect to πABC(θ, s|sobs), which ensures that πABC(θ, s|sobs) is the sta-
tionary distribution of the Markov chain. Detailed balance states that:
πABC(θ, s|sobs)P[(θ, s), (θ′, s′)] = πABC(θ′, s′|sobs)P[(θ′, s′), (θ, s)],

104
Handbook of Approximate Bayesian Computation
where the Metropolis–Hastings transition kernel P is given by:
P[(θ, s), (θ′, s′)] = g[(θ, s), (θ′, s′)]a[(θ, s), (θ′, s′)].
Assuming that (without loss of generality) a[(θ′, s′), (θ, s)] = min{1, α[(θ′, s′),
(θ, s)]} = 1 (and so a[(θ, s), (θ′, s′)] = α[(θ, s), (θ′, s′)]), the detailed balance
condition is satisﬁed since:
πABC(θ, s|sobs)P[(θ, s), (θ′, s′)]
=
πABC(θ, s|sobs)g[(θ, s), (θ′, s′)]α[(θ, s), (θ′, s′)]
=
Kh(∥s −sobs||)p(s|θ)π(θ)
z
g(θ, θ′)p(s′|θ′)Kh(∥s′ −sobs∥)π(θ′)g(θ′, θ)
Kh(∥s −sobs∥)π(θ)g(θ, θ′)
=
Kh(∥s′ −sobs∥)p(s′|θ′)π(θ′)
z
g(θ′, θ)p(s|θ)
=
πABC(θ′, s′|sobs)P[(θ′, s′), (θ, s)],
where z =
 
Kh(∥s −sobs∥)p(s|θ)π(θ)dsdθ is the normalisation constant of
πABC(θ, s|sobs) (e.g. Sisson and Fan 2011).
Marjoram et al. (2003) found that the ABC-MCMC algorithm oﬀered an
improved acceptance rate over rejection sampling-based ABC algorithms with
the same scale parameter h, although at the price of serial correlation in the
Markov chain sample path θ(1), . . . , θ(N). Thus, for kernels Kh with compact
support, the same mechanism that causes many rejections or zero weights in
ABC rejection and importance samplers, now results in many rejected pro-
posals in the ABC-MCMC algorithm. The diﬀerence here is that the chain
simply remains at the current state θ(i) for long periods of time, giving addi-
tional posterior weight to θ(i). Techniques for improving the performance of
standard MCMC algorithms may also be applied to ABC-MCMC samplers.
However there is one feature of ABC-MCMC that is diﬀerent to that of the
standard algorithm, that is particularly acute when using kernel functions Kh
with compact support.
Consider a proposed move from θ(i) to θ′. In standard MCMC, the ac-
ceptance probability is based on the relative density of the posterior eval-
uated at θ′ compared to that evaluated at θ(i). In ABC-MCMC, the den-
sity of the posterior at θ′ is determined through the ability of the model
to generate a summary statistic s′ ∼p(s|θ′) that is close to sobs, as mea-
sured through Kh(∥s′ −sobs∥). That is, to move to θ′, a summary statistic
s′ must be generated that is close enough to sobs. This is the standard ABC
mechanism. However, the result of this for the ABC-MCMC algorithm is that
it means that the acceptance rate of the sampler is directly related to the
value of the (intractable) likelihood function evaluated at θ′. As a result, the
sampler may mix rapidly in regions of high posterior density, but will have
much worse mixing in regions of relatively low posterior density (Sisson et al.
2007). For this reason, ABC-MCMC samplers can often get stuck in regions

ABC Samplers
105
of low posterior density for long periods time, eﬀectively producing conver-
gence issues for the algorithm.
This eﬀect is more pronounced when the kernel Kh has compact support,
such as the uniform kernel on [−h, h] which is endemic in ABC implementa-
tions, although it is still present for kernels deﬁned on the real line, such as the
Gaussian density kernel. In a study of ‘sojourn time’ within ABC-MCMC sam-
plers (that is, the number of consecutive iterations in the sampler in which
a univariate parameter θ remained above some high threshold), Sisson and
Fan (2011) found empirically that samplers with uniform kernels had a sub-
stantially higher expected sojourn time than samplers with Gaussian kernels,
indicating that the latter had superior chain mixing in distributional tails.
Despite this, ABC-MCMC samplers are routinely implemented with uniform
kernels Kh.
Chain mixing can be improved by alternatively targeting the joint posterior
distribution πABC(θ, s(1), . . . , s(T)|sobs) given by (4.8). Under this (pseudo)
marginal sampler framework (Section 4.2.3.5) as T →∞, the mixing prop-
erties of the ABC-MCMC approach that of the equivalent standard MCMC
sampler directly targeting πABC(θ|sobs) (if it would be possible to numeri-
cally evaluate the density function). Sisson and Fan (2011) empirically demon-
strated this improvement, as measured in sojourn times, as T increases. Of
course, this improvement of chain mixing comes at the price of overall sampler
performance, as the computational overheads of generating s(1), . . . , s(T) for
large T would be extremely high. The results of Bornn et al. (2017), that
T = 1 is the optimum eﬃciency choice for uniform kernels Kh, also hold for
ABC MCMC samplers.
4.3.2
Augmented space ABC-Markov chain Monte Carlo
samplers
The standard ABC MCMC sampler (Algorithm 4.6) requires pre-speciﬁcation
of the kernel scale parameter h. As with ABC rejection and importance sam-
plers, there are a number of ways in which lack of knowledge of a suitable
value for the kernel scale parameter can be incorporated into the basic algo-
rithm. Most of these methods also attempt to improve chain mixing over the
standard algorithm, which uses a ﬁxed, low value of h. At the very simplest
level, this could involve adaptively adjusting h as a function of ∥s −sobs∥at
the current and proposed states of the chain, and either allow h to slowly
reduce to some target value to improve convergence at the start of the
sampler (e.g. Ratmann et al. 2007, Sisson and Fan 2011, p. 325) or adap-
tively choose h to achieve some pre-determined overall sampler acceptance
probability.
Augmenting the dimension of the target distribution is a common strategy
to improve the performance of Monte Carlo algorithms. In order to help the
ABC-MCMC sampler escape from regions of low posterior density, Bortot
et al. (2007) proposed augmenting the joint ABC posterior πABC(θ, s|sobs)

106
Handbook of Approximate Bayesian Computation
to additionally include the kernel bandwidth h, treating this as an unknown
additional parameter. The resulting joint posterior distribution is given by:
πABC(θ, s, h|sobs) ∝Kh(∥s −sobs∥)p(s|θ)π(θ)π(h),
and the resulting ABC approximation to the partial posterior π(θ|sobs) is then
given by:
˙πABC(θ|sobs) =
 
πABC(θ, s, h|sobs)dsdh,
(4.9)
where h > 0. Here, h is treated as a tempering parameter in the manner of
simulated tempering (Geyer and Thompson 1995), with larger and smaller
values, respectively, corresponding to ‘hot’ and ‘cold’ tempered posterior dis-
tributions. Larger values of h increase the scale of the kernel density function
Kh, under which the sampler is more likely to accept proposed moves and
thereby alleviating the sampler’s mixing problems, although at the price of
a less accurate posterior approximation. Lower values of h produce a more
accurate posterior approximation, but will induce slower chain mixing. The
density π(h) is a pseudo-prior, which serves to inﬂuence the mixing of the
sampler through the tempered distributions.
Note that the augmented space ABC posterior approximation ˙πABC(θ|sobs)
given by (4.9) will in general be diﬀerent to that of πABC(θ|sobs), as the latter
contains a ﬁxed value of h, whereas the former integrates over the uncer-
tainty inherent in this parameter. Rather than use (4.9) as the ﬁnal ABC
approximation to π(θ|sobs), Bortot et al. (2007) chose to remove those sam-
ples (θ(i), s(i), h(i)) for which h(i) was considered too large to come from a
good approximation to π(θ|sobs). In particular, they examined the distribu-
tion of θ(i)|h(i) ≤h∗, aiming to choose the largest value of h∗, such that the
distribution of θ(i)|h(i) ≤h∗did not change if h∗was reduced further. The
resulting ABC posterior approximation is therefore given by:
¨πABC(θ|sobs) =
 h∗
0

πABC(θ, s, h|sobs)dsdh.
This approach eﬀectively permits an a posteriori evaluation of an appropriate
value h∗, such that the approximation ¨πABC(θ|sobs) is as close as possible
(subject to Monte Carlo variability) to the true posterior π(θ|sobs).
A similar idea was explored by Baragatti et al. (2013) in an ABC version of
the parallel tempering algorithm of Geyer and Thompson (1995). Here, M > 1
parallel ABC-MCMC chains are implemented with diﬀerent kernel density
scale parameters hM < hM−1 < . . . < h1, with state transitions allowed
between chains so that the states of the more rapidy mixing chains (with
higher h values) can propagate down to the more slowly mixing chains (with
lower h). The ﬁnal ABC posterior approximation is the output from the chain
with h = hM. A related augmented space ABC sampler based on the equi-
energy MCMC sampler of Kou et al. (2006) could similarly be implemented.

ABC Samplers
107
Ratmann et al. (2009) take the auxiliary space ABC sampler of Bortot
et al. (2007) beyond the solely mechanical question of improving Markov
chain mixing and towards estimation of the distribution of s −sobs under
the model. This is more in line with the ABC approximation ˙πABC(θ|sobs)
given by (4.9), and the interpretation of the ABC approximation to π(θ|sobs)
as an exact model in the presence of model error due to Wilkinson (2013).
It additionally allows an assessment of model adequacy. Instead of comparing
s to sobs through Kh(∥s −sobs∥) with a single h, Ratmann et al. (2009) al-
ternatively make the comparison independently and univariately for each of
the q summary statistics in s = (s1, . . . , sq)⊤via Khr(τr −|sr −sobs,r|) for
r = 1, . . . , q. Here, τr is the parameter denoting the true, but unknown, dis-
crepancy between the r-th summary statistics of s and sobs, i.e. |sr −sobs,r|,
and so if τr = 0, then the model can adequately explain the observed data
as described through the r-th summary statistic. The full model has a joint
target distribution of:
πABC(θ, s(1), . . . , s(T), τ|sobs)
∝
min
r

1
Thr
T

t=1
Khr (τr −|sr(t) −sobs,r|)
 
 T

t=1
p(s(t)|θ)

π(θ)π(τ),
based on T samples s(1), . . . , s(T) ∼p(s|θ), where sr(t) is the r-th element
of s(t), and π(τ) = q
r=1 π(τr). The minimum over the univariate density
estimates aims to focus the model on the most conservative estimate of model
adequacy, while also reducing computation over τ to its univariate margins.
Here, interest is in the posterior distribution of τ in order to determine model
adequacy (i.e. if the posterior marginal distribution of πABC(τr|sobs) is centred
on 0), whereas the margin speciﬁc kernel scale parameters hr are determined
via standard kernel density estimation arguments over the observed sample
|sr(t) −sobs,r| for t = 1, . . . , T.
4.3.3
Other ABC-Markov chain Monte Carlo samplers
The ﬁeld of MCMC research with tractable target distributions is fairly ma-
ture, and it is not diﬃcult to imagine that many known techniques can be
directly applied to ABC-MCMC algorithms to improve their performance.
Diﬀerent forms of algorithms include Hamiltonian Monte Carlo ABC sam-
plers (Meeds et al. 2015), which use a moderate number of simulations under
the intractable model to produce an ABC estimate of the otherwise intractable
gradient of the potential energy function, multi-try Metropolis ABC (Aandahl
2012; Kobayashi and Kozumi 2015), which uses multiple proposals to choose
from at each stage of the sampler to ensure improved mixing and acceptance
rates, in addition to the various augmented space samplers discussed in the
previous section (Bortot et al. 2007; Ratmann et al. 2009; Baragatti et al.
2013). Of course, transdimensional ABC-MCMC samplers can also be imple-
mented for multi-model posterior inference.

108
Handbook of Approximate Bayesian Computation
General improvements in eﬃciency can be obtained by using quasi
Monte Carlo ABC methods to form eﬃcient proposal distributions (Cabras
et al. 2015). In a similar manner, Neal (2012) developed a coupled ABC
MCMC sampler which uses the same random numbers to generate the sum-
mary statistics for diﬀerent parameter values, and showed this algorithm to
be more eﬃcient than the standard ABC MCMC sampler.
Within the standard ABC MCMC sampler, Kousathanas et al. (2016)
proposed using a subset ˜s ⊆s of the vector of summary statistics within
the acceptance probability when updating a subset of the model parameters
conditional on the rest. Here the idea was to reduce the dimension of the
comparison ∥˜s −˜sobs∥within the kernel Kh to increase the eﬃciency and
mixing of the algorithm. Rodrigues (2017) developed a related algorithm based
on the Gibbs sampler.
Lee and Latuszy´nski (2014) present an analysis of the variance bounding
and geometric ergodicity properties of three reversible kernels used for ABC
MCMC, previously suggested by Lee et al. (2012), which are based on the
uniform kernel Kh. Given that current state of the chain is θ(i) and a proposed
new state is drawn from θ′ ∼g(θ(i), θ), the following algorithms were examined
(where I(·) denotes the indicator function):
• Method 1: Draw s′(1), . . . , s′(T) ∼p(s|θ′).
Accept the move θ(i+1) = θ′ (and s(t) = s′(t) ∀t) with probability
min
⎧
⎨
⎩1,
T
t=1 I(∥s′(t) −sobs∥≤h)

π(θ′)g(θ′, θ(i))
T
t=1 I(∥s(t) −sobs∥≤h)

π(θ(i))g(θ(i), θ′)
⎫
⎬
⎭
else reject and set θ(i+1) = θ(i).
• Method 2: Draw s(1), . . . , s(T−1) ∼p(s|θ(i)) and s′(1), . . . , s′(T) ∼p(s|θ′).
Accept the move θ(i+1) = θ′ with probability
min
⎧
⎨
⎩1,
T
t=1 I(∥s′(t) −sobs∥≤h)

π(θ′)g(θ′, θ(i))

1 + T −1
t=1 I(∥s(t) −sobs∥≤h)

π(θ(i))g(θ(i), θ′)
⎫
⎬
⎭
else reject and set θ(i+1) = θ(i).
• Method 3: Reject the move and set θ(i+1) = θ(i) with probability
1 −min

1, π(θ′)g(θ′, θ(i))
π(θ(i))g(θ(i), θ)
	
.
For T
= 1, 2, . . . draw s(T) ∼p(s|θ(i)) and s′(T) ∼p(s|θ′) until
T
t=1 I(∥s(t) −sobs∥≤h) + I(∥s′(t) −sobs∥≤h) ≥1.
If I(∥s′(T) −sobs∥≤h) = 1 then set θ(i+1) = θ′ else set θ(i+1) = θ(i).

ABC Samplers
109
Method 1 is the acceptance probability constructed from the standard
Monte Carlo estimate of the ABC posterior ˆπABC(θ|sobs) using a ﬁxed num-
ber, T, of summary statistic draws, as described in Section 4.2.3.5. Method
2 is the same as Method 1, except that T −1 of the summary statistics of
the current chain state s|θ(i) are regenerated anew in the denominator of the
acceptance probability. The idea here is to help the Markov chain escape re-
gions of low posterior probability more easily than under Method 1, at the
cost of higher computation. Method 3 produces a random number of summary
statistic generations, with computation increasing until either s|θ(i) or s′|θ′ is
suﬃciently close to sobs.
Under some technical conditions, Lee and Latuszy´nski (2014) conclude
that Methods 1 and 2 cannot be variance bounding, and that Method 3
(as with the standard Metropolis–Hastings algorithm if it were analytically
tractable) can be both variance bounding and geometrically ergodic. Over-
all these results, in addition to other methods for constructing estimates of
intractable likelihoods (e.g. Buchholz and Chopin 2017), are very interesting
from the perspective of future simulation-based algorithm design.
4.4
Sequential Monte Carlo Sampling
It can be diﬃcult to design an importance sampling density g(θ) that is able
to eﬃciently place a large number of samples in regions of high posterior den-
sity. Sequential Monte Carlo (SMC) and sequential importance sampling (SIS)
algorithms are designed to overcome this diﬃculty by constructing a sequence
of slowly changing intermediary distributions fm(θ), m = 0, . . . , M, where
f0(θ) = g(θ) is the initial importance sampling distribution, and fM(θ) = f(θ)
is the target distribution of interest. A population of particles (i.e. sam-
ples θ(i), i = 1, . . . , N) is then propagated between these distributions, in
sequence, so that f1(θ), . . . , fM−1(θ) act as an eﬃcient importance sampling
bridge between g(θ) and f(θ). There are a number of techniques available
for speciﬁcation of the intermediary distributions (e.g. Geyer and Thompson
1995, Del Moral et al. 2006). There is a rich literature on the construction of
eﬃcient SMC and SIS algorithms. See e.g. Liu et al. (1998), Gilks and Berzuini
(2001), Neal (2001), Doucet et al. (2001) and Chopin (2002) among others.
These algorithms invariably involve some combination of three main ideas.
Given a weighted sample (θ(1)
m−1, w(1)
m−1), . . . , (θ(N)
m−1, w(N)
m−1) from interme-
diary distribution fm−1(θ), the reweighting step propagates the particles to
the next intermediary distribution fm(θ). This could involve a simple impor-
tance reweighting, or something more involved if hybrid importance/rejection
schemes are employed (e.g. Liu et al. 1998).
Depending on the eﬃciency of the transitions between fm−1(θ) and fm(θ),
the variability of the importance weights w(i)
m could be very high, with some

110
Handbook of Approximate Bayesian Computation
particles having very small weights, and others having very large weights –
commonly known as particle degeneracy. This can be measured through the
eﬀective sample size (4.5) (Liu et al. 1998, Liu 2001). The resampling step
is designed to replenish the particle population by resampling the particles
from their empirical distribution (θ(1)
m , w(1)
m ), . . . , (θ(N)
m , w(N)
m ). In this manner,
particles with low weights in regions of low density will likely be discarded
in favour of particles with higher weights in regions of higher density. Fol-
lowing resampling, the eﬀective sample size will be reset to N as each weight
will then be set to w(i)
m = 1/N. Resampling should not occur too frequently.
A common criterion is to resample when the eﬀective sample size falls below
a pre-speciﬁed threshold, typically E = N/2. See e.g. Douc et al. (2005) for a
review and comparison of various resampling methods.
Finally, the move step aims to both move the particles to regions of
high probability, and increase the particle diversity in the population. The
latter is important since, particularly after resampling, particles with high
weights can be replicated in the sample. Any transition kernel Fm(θ, θ′) can
be used for the move step, although an MCMC kernel is a common choice
(e.g. Gilks and Berzuini 2001) as it results in the importance weight being
unchanged, although there is also the chance that the proposed move is re-
jected. Other kernels, such as Fm(θ, θ′) = φ(θ′; θ, σ2
m) to add a random normal
scatter to the particles, will require the importance weights to be modiﬁed.
See e.g. Del Moral et al. (2006) for discussion on diﬀerent forms of the move
kernel.
4.4.1
Sequential importance sampling
In the ABC framework a natural choice for the sequence of intermediary
distributions is
fm(θ) = πABC,hm(θ, s|sobs) ∝Khm(∥s −sobs∥)p(s|θ)π(θ),
for m = 0, . . . , M, indexed by the kernel scale parameter, where the sequence
h0 ≥h1 ≥. . . ≥hM is a monotonic decreasing sequence. Accordingly, each
successive distribution with decreasing hm, will be less diﬀuse and a closer
approximation to π(θ|sobs) (Sisson et al. 2007). A sequential importance sam-
pling version of the ABC rejection control importance sampler (Algorithm
4.4) is given in Algorithm 4.7.
This algorithm is a particular version of the sampler proposed by Peters
et al. (2012) (see also Sisson et al. 2007) who incorporated the partial rejection
control mechanism of Liu et al. (1998) and Liu (2001) into the SMC sampler
framework. When applied in the ABC setting, rejection control provides one
means of controlling the otherwise highly variable particle weights. As with the
ABC rejection control importance sampler (Algorithm 4.4), samples from an
importance sampling distribution gm(θ), constructed from the samples from
the previous population targeting fm−1(θ), are combined with the rejection
control mechanism in order to target fm(θ).

ABC Samplers
111
Algorithm 4.7: ABC Sequential Rejection Control Importance
Sampling Algorithm
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ), consisting of a prior
distribution π(θ) and a procedure for generating data under the model
p(yobs|θ).
• A kernel function Kh(u) and a sequence of scale parameters h0 ≥h1
≥. . . ≥hM.
• An initial sampling distribution g(θ), and a method of constructing sub-
sequent sampling distributions gm(θ), m = 1, . . . , M.
• An integer N > 0.
• A sequence of rejection control thresholds values cm, m = 1, . . . , M.
• A low dimensional vector of summary statistics s = S(y).
Initialise:
For i = 1, . . . , N:
• Generate θ(i)
0
∼g(θ) from initial sampling distribution g.
• Generate y(i)
0
∼p(y|θ(i)
0 ) and compute summary statistics s(i)
0
= S(y(i)
0 ).
• Compute weights w(i)
0
= Kh0(∥s(i)
0 −sobs∥)π(θ(i)
0 )/g(θ(i)
0 ).
Sampling:
For m = 1, . . . , M:
1. Construct sampling distribution gm(θ).
2. For i = 1, . . . , N:
(a) Generate θ(i)
m ∼gm(θ), y(i)
m ∼p(y|θ(i)
m ) and compute s(i)
m = S(y(i)
m ).
(b) Compute weight w(i)
m = Khm(∥s(i)
m −sobs∥)π(θ(i)
m )/gm(θ(i)
m ).
(c) Reject θ(i)
m with probability 1 −r(i)
m = 1 −min{1, w(i)
m
cm }, and go to
step 2a.
(d) Otherwise, accept θ(i)
m and set modiﬁed weight w∗(i)
m
= w(i)
m /r(i)
m .
Output:
A set of weighted parameter vectors (θ(1)
M , w∗(1)
M ), . . . , (θ(N)
M , w∗(N)
M
) drawn
from πABC(θ|sobs) ∝

KhM (∥s −sobs∥)p(s|θ)π(θ)ds.
The initial sampling distribution g(θ) can be any importance sampling
density, as with standard importance sampling algorithms. There are a num-
ber of adaptive ways to construct the subsequent importance distributions

112
Handbook of Approximate Bayesian Computation
gm(θ) for m = 1, . . . , M, based on the population of samples from the previ-
ous intermediary distribution (θ(1)
m−1, w∗(1)
m−1), . . . , (θ(N)
m−1, w∗(N)
m−1). The simplest
of these is to specify gm(θ) as some standard parametric family, such as the
multivariate normal distribution, with parameters estimated from the previ-
ous particle population (e.g. Chopin 2002). Another option is to construct a
kernel density estimate of the distribution of the previous particle popula-
tion gm(θ) = N
i=1 W ∗(i)
m−1Fm(θ(i)
m−1, θ) where W ∗(i)
m−1 = w∗(i)
m−1/ N
j=1 w∗(j)
m−1,
and Fm(θ, θ′) is some forward mutation kernel describing the probability
of moving from θ to θ′, such as Fm(θ, θ′) = φ(θ′; θ, Σm), the multivari-
ate normal density function centred at θ and with covariance matrix Σm
(Del Moral et al. 2006; Beaumont et al. 2009; Peters et al. 2012). These and
other possibilities may also be constructed by ﬁrst reweighting the draws from
the previous population fm−1(θ) so that they target fm(θ).
If the kernel Kh has compact support then step 2c of Algorithm 4.7 will
automatically reject any θ(i)
m for which Khm(∥s(i)
m −sobs∥) = 0. (This also
happens for Algorithm 4.4.) This practical outcome occurs for most ABC
SIS and SMC algorithms used in practice, as use of the uniform kernel is
predominant (e.g. Sisson et al. 2007, Toni et al. 2009, Beaumont et al. 2009,
Del Moral et al. 2012), although the rejection of θ(i) is sometimes hard coded
as in Algorithm 4.3, rather than being part of a more sophisticated importance
weight variance control mechanism, such as rejection control.
In the limit as rejection thresholds cm →0 for m = 1, . . . , M (and deﬁning
0/0 := 1), the rejection control mechanism will allow all particles to proceed
to the next stage of the algorithm. Therefore cm →0 represents a standard
sequential importance sampler that will likely result in the collapse of the
particle population (i.e. all weights w∗(i)
m
= 0) in the ABC setting, for low hm.
However, non-zero rejection control thresholds cm permit a ﬁner scale con-
trol over the importance weights w(i)
m beyond distinguishing between zero and
non-zero weights, with larger cm resulting in more similar weights with less
variability, though at the price of higher computation through more rejections.
In this manner, rejection control provides one way in which ABC SMC algo-
rithms may be implemented with kernels Kh that are non-uniform, or have
non-compact support, without which the eﬀective sample size of the sampler
would deteriorate almost immediately for low hm (Peters et al. 2012).
As with the ABC rejection control importance sampler (Algorithm 4.4),
suitable rejection thresholds may be dynamically determined during algorithm
run-time by, for each m, ﬁrst implementing steps 2a and 2b for i = 1, . . . , N,
specifying cm as some function (such as a quantile) of the empirical distribu-
tion of the realised w(1)
m , . . . , w(N)
m , and then continuing Algorithm 4.7 from
step 2c onwards for each i = 1, . . . , N (Peters et al. 2012).
The sequence of scale parameters h0 ≥h1 ≥. . . ≥hM in Algorithm
4.7 has been presented as requiring pre-speciﬁcation in order to implement
the sampler. However, as with any annealing-type algorithm, identifying an
eﬃcient sequence is a challenging problem. Fortunately, as with the automatic

ABC Samplers
113
determination of the rejection control thresholds cm, choice of the scale
parameters can also be automated, and one such method to achieve this is
discussed in the next section. To initialise the algorithm eﬃciently, setting
h0 = ∞would result in all particles θ(1)
0 , . . . , θ(N)
0
having relatively similar
weights w(i)
0
= π(θ(i)
0 )/g(θ(i)
0 ), as a function of the prior and initial sampling
distributions.
4.4.2
Sequential Monte Carlo samplers
An alternative representation of population based algorithms is the sequential
Monte Carlo sampler (Del Moral et al. 2006). Here, the particles are deﬁned
on the space of the path that each particle will take through the sequence of
distributions f0(θ), . . . , fM(θ). Hence, if θ(i)
m ∈Θ, then the path of particle i
through the ﬁrst m distributions is given by θ(i)
1:m = (θ(i)
1 , . . . , θ(i)
m ) ∈Θm for
m = 1, . . . , M. SMC samplers explicitly implement each of the reweighting,
resampling and move steps, and at their most general level have sophisticated
implementations (e.g. Del Moral et al. 2006). A number of SMC samplers
have been developed in the ABC framework (see Sisson et al. 2007, Toni et al.
2009, Beaumont et al. 2009, Drovandi and Pettitt 2011a, Del Moral et al.
2012). Algorithm 4.8 presents a generalisation (to general kernels Kh) of the
adaptive ABC SMC sampler of Del Moral et al. (2012).
This algorithm provides an alternative method to rejection control to avoid
the collapse of the particle population, for an arbitrary choice of kernel Kh,
by making particular sampler design choices. Firstly, the probability of gen-
erating particles θ(i)
m with identically zero weights w(i)
m = 0 is reduced by in-
creasing the number of summary statistics drawn to T, thereby targeting the
joint distribution πABC(θ, s(1), . . . , s(T)|sobs) as described in Section 4.2.3.5,
although at the price of greater computation. Within the scope of an ABC
SMC sampler that makes use of MCMC kernels within the move step (as with
Algorithm 4.8), the alternative algorithms analysed by Lee and Latuszy´nski
(2014) (see Section 4.3.3) could also be implemented (e.g. Bernton et al. 2017).
In combination with the increased number of summary statistic replicates,
Algorithm 4.8 directly controls the degree of particle degeneracy in mov-
ing from distribution fm−1(θ) to fm(θ). In particular, the next kernel scale
parameter hm < hm−1 is chosen as the value which results in the eﬀective
sample size following the reweighting step, being reduced by a user speci-
ﬁed proportion, α. In this manner, the sample degeneracy will reduce in a
controlled manner at each iteration, and the sequence of hm will adaptively
reduce at exactly the rate needed to achieve this. When the eﬀective sample
size is reduced below some value E, resampling occurs and resets the eﬀec-
tive sample size back to N, and the process repeats. As a result, resampling
repeatedly occurs automatically after a ﬁxed number of reweighting steps, as
determined by α.

114
Handbook of Approximate Bayesian Computation
Algorithm 4.8: ABC Sequential Monte Carlo Algorithm
Inputs:
• A target posterior density π(θ|yobs) ∝p(yobs|θ)π(θ) consisting of a prior
distribution π(θ) and a procedure for generating data under the model
p(yobs|θ).
• A kernel function Kh(u), and an integer N > 0.
• An initial sampling density g(θ) and sequence of proposal densities
gm(θ, θ′), m = 1, . . . , M.
• A value α ∈[0, 1] to control the eﬀective sample size.
• A low dimensional vector of summary statistics s = S(y).
Initialise:
For i = 1, . . . , N:
• Generate θ(i)
0
∼g(θ) from initial sampling distribution g.
• Generate y(i)
0 (t) ∼p(y|θ(i)
0 ) and compute summary statistics s(i)
0 (t) =
S(y(i)
0 ) for t = 1, . . . , T.
• Compute weights w(i)
0
= π(θ0
i )/g(θ(i)
0 ), and set m = 1.
Sampling:
1. Reweight:
Determine
hm
such
that
ESS(w(1)
m , . . . , w(N)
m )
=
αESS(w(1)
m−1, . . . , w(N)
m−1) where
w(i)
m = w(i)
m−1
T
t=1 Khm(∥s(i)
m−1(t) −sobs∥)π(θ(i)
m )
T
t=1 Khm−1(∥s(i)
m−1(t) −sobs∥)π(θ(i)
m−1)
,
and then compute new particle weights and set θ(i)
m = θ(i)
m−1 and s(i)
m (t) =
s(i)
m−1(t) for i = 1, . . . , N, and t = 1, . . . , T.
2. Resample: If ESS(w(1)
m , . . . , w(N)
m ) < E then resample N particles
from the empirical distribution function {θ(i)
m , s(i)
m (1), . . . , s(i)
m (T), W (i)
m }
where W (i)
m = w(i)
m / N
j=1 w(j)
m and set w(i)
m = 1/N.
3. Move: For i = 1, . . . , N: If w(i)
m > 0:
• Generate θ′ ∼gm(θ(i)
m , θ), y′(t) ∼p(y|θ(i)
m ) and compute s′(t) =
S(y′(t)) for t = 1, . . . , T.

ABC Samplers
115
• Accept θ′ with probability
min

1,
T
t=1 Khm(∥s′(t) −sobs∥)π(θ′)g(θ′, θ(i)
m )
T
t=1 Khm(∥s(i)
m (t) −sobs∥)π(θ(i)
m )g(θ(i)
m , θ′)

and set θ(i)
m = θ′, s(i)
m (t) = s′(t) for t = 1, . . . , T.
4. Increment m = m + 1. If stopping rule is not satisﬁed, go to 1.
Output:
A set of weighted parameter vectors (θ(1)
M , w(1)
M ), . . . , (θ(N)
M , w(N)
M ) drawn
from πABC(θ|sobs) ∝

KhM (∥s −sobs∥)p(s|θ)π(θ)ds.
This algorithm requires a stopping rule to terminate. If left to continue, hm
would eventually reduce very slowly, which is an indication that the sampler
can no longer eﬃciently move the particles around the parameter space. Del
Moral et al. (2012) argue that this identiﬁes natural values of hM that should
then be adopted. In particular, they terminate their algorithm when the
MCMC move rate drops below 1.5%, which then determines the ﬁnal value
of hM. Alternative strategies to adaptively choose the kernel scale parameter
sequence have been proposed by Drovandi and Pettitt (2011a), Drovandi and
Pettitt (2011b), Silk et al. (2013) and Daly et al. (2017).
SMC algorithms provide many easy opportunities for sampler adapta-
tion, unlike MCMC samplers which are constrained by the need to main-
tain the target distribution of the chain. For example, within ABC SMC
algorithms, Prangle (2017) adaptively learns the relative weightings of the
summary statistics within the distance function ∥s−sobs∥to improve eﬃciency,
Bonassi
and
West
(2015)
construct
adaptive
move
proposal
kernels
gm(θ(i)
m , θ) = N
i=1 ν(i)
m−1Fm(θ(i)
m−1, θ) based on weighting components of gm,
via ν(i)
m−1, based on the proximity of s(i)
m−1 to sobs, and Filippi et al. (2013)
develop a diﬀerent method of adaptively constructing the sequence of inter-
mediary distributions, fm(θ), based on Kullback–Leibler divergences between
successive distributions.
Other ideas can be incorporated within ABC SMC algorithms in par-
ticular settings, or can use the ideas from ABC SMC algorithms to tackle
problems related to posterior simulation. For example, Prangle et al. (2017)
use ideas from rare event modelling to improve sampler eﬃciency within
ABC SMC algorithms. When simulation from the model p(s|θ) is expensive,
Everitt and Rowi´nska (2017) ﬁrst use a cheap approximate simulator within
an ABC SMC algorithm to rule out unlikely areas of the parameter space,

116
Handbook of Approximate Bayesian Computation
so that expensive computation with the full simulator is avoided until abso-
lutely necessary. Jasra et al. (2012) implement an ABC approximation within
an SMC algorithm to perform ﬁltering for a hidden Markov model. Dean
et al. (2014) and Yildirim et al. (2015) use ABC SMC methods for optimi-
sation purposes (with a diﬀerent sequence of intermediary distributions), so
as to derive maximum (intractable) likelihood estimators for hidden Markov
models.
4.5
Discussion
ABC samplers have proved to be highly accessible and simple to implement,
and it is this that has driven the popularity and spread of ABC methods more
generally. Multi-model versions of each of these algorithms are available (e.g.
Toni et al. 2009, Chkrebtii et al. 2015) or can be easily constructed, with
ABC posterior model probabilities and Bayes factors being determined by the
relative values of
1
N
N
i=1 Kh(∥s(i) −sobs∥) under each model. Although here
the user needs to clearly understand the ideas of summary statistic informa-
tiveness for model choice (e.g. Marin et al. 2014) and the problems involved
in computing Bayes factors as h →0 (Martin et al. 2017).
Improvements to general ABC samplers include increasing algorithmic eﬃ-
ciency by using quasi Monte Carlo methods (Buchholz and Chopin 2017), and
the use of multi-level rejection sampling (Warne et al. 2017) (see Jasra et al.
2017 for the SMC version) for variance reduction. The lazy ABC method of
Prangle (2016) states that it may be possible to terminate expensive simula-
tions s ∼p(s|θ) early, if it is also possible to calculate the probability that the
full simulation when run to completion would have been rejected. Diagnostics
to determine whether the kernel scale parameter hm is suﬃciently low that
πABC(θ|sobs) is indistinguishable from π(θ|sobs) were developed by Prangle
et al. (2014). There are many related results on the rate of convergence of
ABC algorithms as measured through the mean squared error of point esti-
mates (Blum 2010; Fernhead and Prangle 2012; Calvet and Czellar 2015; Biau
et al. 2015; Barber et al. 2015). ABC samplers have also allowed previously
unclear links to other algorithms to become better understood – for example,
Nott et al. (2012) have reinterpreted the Kalman ﬁlter as an ABC algorithm,
and Drovandi (2019) (Chapter 7, this volume) has comprehensively described
the links between ABC and indirect inference.
A number of algorithms related to ABC methods have emerged, including
Bayesian empirical likelihoods (Mengersen et al. 2013) and bootstrap likeli-
hoods (Zhu et al. 2016), the synthetic likelihood (Wood 2010, Drovandi et al.
2019, Chapter 12, this volume), the expectation-propagation ABC algorithm
(Barthelm´e and Chopin 2014; Barthelm´e et al. 2019, Chapter 14, this vol-
ume), Albert et al. (2015)’s particle-based simulated annealing algorithm, and

ABC Samplers
117
Forneron and Ng (2016)’s optimisation-based likelihood free importance sam-
pling algorithm. Perhaps the biggest oﬀshoot of ABC samplers is the more
general pseudo-marginal Monte Carlo method (Beaumont 2003; Andrieu and
Roberts 2009), which implements exact Monte Carlo simulation with an unbi-
ased estimate of the target distribution, of which ABC is a particular case. See
Andrieu et al. (2019) (Chapter 9, this volume) for an ABC-centred exploration
of these methods.
Acknowledgements
SAS is supported by the Australian Research Council under the Discovery
Project scheme (DP160102544), and the Australian Centre of Excellence in
Mathematical and Statistical Frontiers (CE140100049).
References
Aandahl, R. Z. (2012). Likelihood-free Bayesian methods for inference using
stochastic evolutionary models of Mycobacterium tuberculosis. Ph. D.
thesis, University of New South Wales, Sydney.
Albert, C., H. R. Keunsch, and A. Scheidegger (2015). A simulated annealing
approach to approximate Bayesian computation. Statistics and Comput-
ing 25, 1217–1232.
Andrieu, C., A. Lee, and M. Vihola (2019). Theoretical and methodological
aspects of MCMC computations with noisy likelihoods. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Boca Raton, FL, Chapman & Hall/CRC Press.
Andrieu, C. and G. O. Roberts (2009). The pseudo-marginal approach for
eﬃcient Monte Carlo computations. Annals of Statistics 37, 697–725.
Baragatti, M., A. Grimaud, and D. Pommeret (2013). Likelihood-free parallel
tempering. Statistics and Computing 23, 535–549.
Barber, S., J. Voss, and M. Webster (2015). The rate of convergence of approx-
imate Bayesian computation. Electronic Journal of Statistics 9, 80–105.
Barthelm´e, S. and N. Chopin (2014). Expectation-propagation for likelihood-
free inference. Journal of the American Statistical Association
109,
315–333.

118
Handbook of Approximate Bayesian Computation
Barthelm´e, S., N. Chopin, and V. Cottet (2019). Divide and conquer in ABC:
Expectation-propagation algorithms for likelihood-free inference. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Boca Raton, FL, Chapman & Hall/CRC Press.
Beaumont, M. A. (2003). Estimation of population growth or decline in ge-
netically monitored populations. Genetics 164, 1139–1160.
Beaumont, M. A., J.-M. Cornuet, J.-M. Marin, and C. P. Robert (2009).
Adaptive approximate Bayesian computation. Biometrika 96, 983–990.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162, 2025–2035.
Bernton, E., P. E. Jacob, M. Gerber, and C. P. Robert (2017). Inference in
generative models using the Wasserstein distance. arXiv:1701.05146.
Biau, G., F. C´erou, and A. Guyader (2015). New insights into approximate
Bayesian computation. Annales de l’Institut Henri Poincare (B) Probability
and Statistics 51, 376–403.
Blum, M. G. B. (2010). Approximate Bayesian computation: A non-
parametric perspective. Journal of the American Statistical Associa-
tion 105, 1178–1187.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson (2013). A com-
parative review of dimension reduction methods in approximate Bayesian
computation. Statistical Science 28, 189–208.
Bonassi, F. V. and M. West (2015). Sequential Monte Carlo with adap-
tive weights for approximate Bayesian computation. Bayesian Analysis 10,
171–187.
Bornn, L., N. Pillai, A. Smith, and D. Woodward (2017). The use of a single
pseudo-sample in approximate Bayesian computation. Statistics and Com-
puting 27, 583–590.
Bortot, P., S. G. Coles, and S. A. Sisson (2007). Inference for stereological
extremes. Journal of the American Statistical Association 102, 84–92.
Brooks, S. P., A. Gelman, G. L. Jones, and X.-L. Meng (Eds.) (2011). Hand-
book of Markov Chain Monte Carlo. CRC Press.
Buchholz, A. and N. Chopin (2017). Improving approximate Bayesian com-
putation via quasi Monte Carlo. https://arxiv.org/abs/1710.01057.
Cabras, S., M. E. C. Nueda, and E. Ruli (2015). Approximate Bayesian com-
putation by modelling summary statistics in a quasi-likelihood framework.
Bayesian Analysis 10, 411–439.

ABC Samplers
119
Calvet, L. E. and V. Czellar (2015). Accurate methods for approximate
Bayesian computation ﬁltering. Journal of Financial Econometrics 13,
798–838.
Chkrebtii, O. A., E. K. Cameron, S. A. Campbell, and E. M. Bayne (2015).
Transdimensional approximate Bayesian computation for inference in inva-
sive species models with latent variables of unknown dimension. Computa-
tional Statistics & Data Analysis 86, 97–110.
Chopin, N. (2002). A sequential particle ﬁlter method for static models.
Biometrika 89, 539–551.
Daly, A. C., D. J. Gavaghan, C. Holmes, and J. Cooper (2017). Hodgkin-
Huxley revisited: Reparametrization and identiﬁability analysis of the
classic action potential model with approximate Bayesian methods. Royal
Society Open Science 2, 150499.
Dean, T. A., S. S. Singh, A. Jasra, and G. W. Peters (2014). Parameter estima-
tion for hidden Markov models with intractable likelihoods. Scandinavian
Journal of Statistics 41, 970–987.
Del Moral, P., A. Doucet, and A. Jasra (2006). Sequential Monte Carlo
samplers. Journal of the Royal Statistical Society, Series B 68, 411–436.
Del Moral, P., A. Doucet, and A. Jasra (2012). An adaptive sequential Monte
Carlo method for approximate Bayesian computation. Statistics and Com-
puting 22, 1009–1020.
Douc, R., O. Cappe, and E. Moulines (2005). Comparison of resampling
schemes for particle ﬁltering. Proceedings of the 4th International Sym-
posium on Image and Signal Processing and Analysis, 64–69.
Doucet, A., N. de Freitas, and N. Gordon (Eds.) (2001). Sequential Monte
Carlo Methods in Practice. Springer.
Drovandi, C. and A. Pettitt (2011a). Estimation of parameters for macropar-
asite population evolution using approximate Bayesian computation. Bio-
metrics 67, 225–233.
Drovandi, C. and A. Pettitt (2011b). Likelihood-free Bayesian estimation of
multivariate quantile distributions. Computational Statistics & Data Anal-
ysis 55, 2541–2556.
Drovandi, C. C. (2019). ABC and indirect inference. In S. A. Sisson, Y. Fan,
and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian Compu-
tation. Boca Raton, FL, Chapman & Hall/CRC Press.
Drovandi, C. C., C. Grazian, K. Mengersen, and C. P. Robert (2019). Ap-
proximating the likelihood in approximate Bayesian computation. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Boca Raton, FL, Chapman & Hall/CRC Press.

120
Handbook of Approximate Bayesian Computation
Everitt, R. G. and P. A. Rowi´nska (2017). Delayed acceptance ABC-SMC.
https://arxiv.org/abs/1708.02230.
Fernhead, P. and D. Prangle (2012). Constructing summary statistics for ap-
proximate Bayesian computation: Semi-automatic approximate Bayesian
computation (with discussion). Journal of the Royal Statistical Society,
Series B 74, 419–474.
Filippi, S., C. P. Barnes, J. Cornebise, and M. P. H. Stumpf (2013). On op-
timality of kernels for approximate Bayesian computation using sequential
Monte Carlo. Statistical Applications in Genetics and Molecular Biology 12,
1–12.
Forneron, J.-J. and S. Ng (2016). A likelihood-free reverse sampler of the
posterior distribution. Advances in Econometrics 36, 389–415.
Geyer, C. J. and E. A. Thompson (1995). Annealing Markov chain Monte
Carlo with applications to ancestral inference. Journal of the American
Statistical Association 90, 909–920.
Gilks, W. R. and C. Berzuini (2001). Following a moving target: Monte Carlo
inference for dynamic Bayesian models. Journal of the Royal Statistical
Society, Series B 63, 127–146.
Jasra,
A.,
S.
Jo,
D.
J.
Nott,
C.
Shoemaker,
and
R.
Tempone
(2017). Multilevel Monte Carlo in approximate Bayesian computation.
https://arxiv.org/abs/1702.03628.
Jasra, A., S. S. Singh, J. Martin, and E. McCoy (2012). Filtering via ABC.
Statistics and Computing 22, 1223–1237.
Kobayashi, G. and H. Kozumi (2015). Generalized multiple-point Metropolis
algorithms for approximate Bayesian computation. Journal of Statistical
Computation and Simulation 85, 675–692.
Kou, S. C., Q. Zhou, and W. H. Wong (2006). Equi-energy sampler with
applications in statistical inference and statistical mechanics. Annals of
Statistics 34, 1581–1619.
Kousathanas, A., C. Leuenberger, J. Helfer, M. Quinodoz, M. Foll, and
D. Wegmann (2016). Likelihood-free inference in high-dimensional models.
Genetics 203, 893–904.
Lee, A., C. Andrieu, and A. Doucet (2012). Discussion of a paper by
P. Fearnhead and D. Prangle. Journal of the Royal Statistical Society,
Series B 74, 419–474.
Lee, A. and Latuszy´nski (2014). Monte Carlo methods for approximate
Bayesian computation. Biometrika 101, 655–671.

ABC Samplers
121
Liu, J. S. (2001). Monte Carlo Strategies in Scientiﬁc Computing. Springer-
Verlag, New York.
Liu, J. S., R. Chen, and W. H. Wong (1998). Rejection control and sequential
importance sampling. Journal of the American Statistical Association 93,
1022–1031.
Marin, J.-M., N. Pillai, C. P. Robert, and J. Rousseau (2014). Relevant statis-
tics for Bayesian model choice. Journal of the Royal Statistical Society,
Series B 76, 833–859.
Marjoram, P., J. Molitor, V. Plagnol, and S. Tavar´e (2003). Markov chain
Monte Carlo without likelihoods. Proceedings of the National Academy of
Sciences of the United States of America 100, 15324–15328.
Martin, G. M., D. T. Frazier, E. M. R. Renault, and C. P. Robert (2017).
The validation of approximate Bayesian computation: Theory and practice.
Technical report, Dept. of Econometrics and Business Statistics, Monash
University.
Meeds, E., R. Leenders, and M. Welling (2015). Hamiltonian ABC. Uncer-
tainty in Artiﬁcial Intelligence 31, 582–591.
Mengersen, K., P. Pudlo, and C. P. Robert (2013). Bayesian computation via
empirical likelihood. Proceedings of the National Academy of Sciences of
the United States of America 110, 1321–1326.
Neal, P. (2012). Eﬃcient likelihood-free Bayesian computation for household
epidemics. Statistics and Computing 22, 1239–1256.
Neal, R. (2001). Annealed importance sampling. Statistics and Computing 11,
125–139.
Nott, D. J., L. Marshall, and M. N. Tran (2012). The ensemble Kalman ﬁlter
is an ABC algorithm. Statistics and Computing 22, 1273–1276.
Peters, G. W., Y. Fan, and S. A. Sisson (2012). On sequential Monte Carlo,
partial rejection control and approximate Bayesian computation. Statistics
and Computing 22, 1209–1222.
Prangle, D. (2016). Lazy ABC. Statistics and Computing 26, 171–185.
Prangle, D. (2017). Adapting the ABC distance function. Bayesian Analy-
sis 12, 289–309.
Prangle, D., M. G. B. Blum, G. Popovic, and S. A. Sisson (2014). Diagnostic
tools for approximate Bayesian computation using the coverage property.
Australia and New Zealand Journal of Statistics 56, 309–329.

122
Handbook of Approximate Bayesian Computation
Prangle, D., R. G. Everitt, and T. Kypraios (2017). A rare event approach to
high-dimensional approximate Bayesian computation. Statistics and Com-
puting, in press.
Pritchard, J. K., M. T. Seielstad, A. Perez-Lezaun, and M. W. Feldman (1999).
Population growth of human Y chromosomes: A study of Y chromosome
microsatellites. Molecular Biology and Evolution 16, 1791–1798.
Ratmann, O., C. Andrieu, T. Hinkley, C. Wiuf, and S. Richardson (2009).
Model criticism based on likelihood-free inference, with an application to
protein network evolution. Proceedings of the National Academy of Sciences
of the United States of America 106, 10576–10581.
Ratmann, O., O. Jorgensen, T. Hinkley, M. Stumpf, S. Richardson, and
C. Wiuf (2007). Using likelihood-free inference to compare evolutionary
dynamics of the protein networks of h. pylori and p. falciparum. PLoS
Computational Biology 3, e230.
Reeves, R. W. and A. N. Pettitt (2005). A theoretical framework for approxi-
mate Bayesian computation. In A. R. Francis, K. M. Matawie, A. Oshlack,
and G. K. Smyth (Eds.), Proceedings of the 20th International Workshop
for Statistical Modelling, Sydney Australia, July 10–15, 2005, pp. 393–396.
Ripley, B. D. (1987). Stochastic Simulation. John Wiley & Sons.
Rodrigues, G. S. (2017). New methods for inﬁnite and high-dimensional ap-
proximate Bayesian computation. Ph. D. thesis, University of New South
Wales, Sydney.
Silk, D., S. Filippi, and M. P. H. Stumpf (2013). Optimising threshold sched-
ules for approximate Bayesian computation sequential Monte Carlo sam-
plers: Applications to molecular systems. Statistical Applications in Genet-
ics and Molecular Biology 12.
Sisson, S. A. and Y. Fan (2011). Likelihood-free MCMC. In S. Brooks,
A. Gelman, G. L. Jones, and X.-L. Meng (Eds.), Handbook of Markov Chain
Monte Carlo, pp. 313–335. Chapman & Hall/CRC Press.
Sisson, S. A., Y. Fan, and M. A. Beaumont (2019). Overview of approxi-
mate Bayesian computation. In S. A. Sisson, Y. Fan, and M. A. Beaumont
(Eds.), Handbook of Approximate Bayesian Computation. Chapman &
Hall/CRC Press.
Sisson, S. A., Y. Fan, and M. M. Tanaka (2007). Sequential Monte Carlo
without likelihoods. Proceedings of the National Academy of Sciences of
the United States of America 104, 1760–1765. Errata (2009), 106:16889.

ABC Samplers
123
Tavar´e, S., D. J. Balding, R. C. Griﬃths, and P. Donnelly (1997). Inferring
coalescence times from DNA sequence data. Genetics 145, 505–518.
Toni, T., D. Welch, N. Strelkowa, A. Ipsen, and M. P. H. Stumpf (2009). Ap-
proximate Bayesian computation scheme for parameter inference and model
selection in dynamical systems. Journal of the Royal Society Interface 6,
187–202.
Warne, D. J., R. E. Baker, and M. J. Simpson (2017). Multilevel rejec-
tion sampling for approximate Bayesian computation. https://arxiv.org/
abs/1702.03126.
Wegmann, D., C. Leuenberger, and L. Excoﬃer (2009). Eﬃcient approximate
Bayesian computation coupled with Markov chain Monte Carlo without
likelihood. Genetics 182, 1207–1218.
Wilkinson, R. L. (2013). Approximate Bayesian computation (ABC) gives
exact results under the assumption of model error. Statistical Applications
in Genetics and Molecular Biology 12, 129–141.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466, 1102–1104.
Yildirim, S., S. S. Singh, T. A. Dean, and A. Jasra (2015). Parameter estima-
tion in hidden Markov models with intractable likelihoods using sequen-
tial Monte Carlo. Journal of Computational and Graphical Statistics 24,
846–865.
Zhu, W., J. M. Marin, and F. Leisen (2016). A bootstrap likelihood approach
to Bayesian computation. Australia and New Zealand Journal of Statis-
tics 58, 227–224.


5
Summary Statistics
Dennis Prangle
CONTENTS
5.1
Theory ............................................................
127
5.1.1
The curse of dimensionality .............................
127
5.1.2
Suﬃciency ...............................................
128
5.2
Strategies for Summary Statistic Selection ......................
129
5.3
Subset Selection Methods ........................................
129
5.3.1
Methods .................................................
130
Approximate suﬃciency .................................
130
Entropy/loss minimisation ..............................
131
Mutual information .....................................
131
Regularisation approaches
..............................
132
Related methods ........................................
132
5.3.2
Discussion ...............................................
133
Comparison of subset selection methods ................
133
Advantages and disadvantages of subset selection ......
133
5.4
Projection Methods ..............................................
134
5.4.1
Dimension reduction techniques
........................
134
Partial least squares .....................................
134
Linear regression ........................................
135
Boosting .................................................
135
5.4.2
Generating training data ................................
136
5.4.3
Discussion ...............................................
137
Comparison of projection methods
.....................
137
Advantages and disadvantages of projection methods ..
137
5.5
Auxiliary Likelihood Methods ...................................
137
5.5.1
Methods .................................................
138
Maximum likelihood estimators .........................
138
Likelihood distance ......................................
139
Scores ....................................................
139
5.5.2
Discussion ...............................................
139
Comparison of auxiliary likelihood methods ............
139
Which auxiliary likelihood? .............................
140
Advantages and disadvantages of auxiliary likelihood
methods .................................................
140
125

126
Handbook of Approximate Bayesian Computation
5.6
Model Choice .....................................................
141
5.6.1
Theory ...................................................
141
Curse of dimensionality .................................
141
Suﬃciency and consistency ..............................
142
5.6.2
Methods .................................................
143
Using an encompassing model ..........................
143
Mutual information .....................................
143
Projection/classiﬁcation methods .......................
143
Local error rates .........................................
144
5.6.3
Discussion ...............................................
145
Comparison of methods .................................
145
Prospects ................................................
145
5.7
Discussion ........................................................
145
Empirical performance ..................................
145
Which method to use ...................................
146
Prospects ................................................
147
References
...............................................................
148
To deal with high dimensional data, ABC algorithms typically reduce them
to lower dimensional summary statistics and accept when simulated sum-
maries S(y) are close to the observed summaries S(yobs). This has been an
essential part of ABC methodology since the ﬁrst publications in the popula-
tion genetics literature. Overviewing this work Beaumont et al. (2002) wrote:
‘A crucial limitation of the...method is that only a small number of summary
statistics can usually be handled. Otherwise, either acceptance rates become
prohibitively low or the tolerance...must be increased, which can distort the
approximation’, and related the problem to the general issue of the curse of
dimensionality: many statistical tasks are substantially more diﬃcult in high
dimensional settings. In ABC, the dimension in question is the number of
summary statistics used.
To illustrate the issue, consider an ABC rejection sampling algorithm. As
more summary statistics are used, there are more opportunities for random
discrepancies between S(y) and S(yobs). To achieve a reasonable number of
acceptances, it is necessary to use a large threshold and accept many poor
matches. Therefore, as noted in the earlier quote, using too many summary
statistics distorts the approximation of the posterior. On the other hand, if
too few summary statistics are used, some ﬁne details of the data can be lost.
This allows parameter values to be accepted which are unlikely to reproduce
these details. Again, a poor posterior approximation is often obtained.
As a result of the considerations earlier, a good choice of ABC summary
statistics must strike a balance between low dimension and informativeness.
Many methods have been proposed aiming to select such summary statistics,
and the main aim of this chapter is to review these. There is some overlap

Summary Statistics
127
between this material and the previous review paper of Blum et al. (2013).
This chapter adds coverage of recent developments, particularly on auxiliary
likelihood methods and ABC model choice. However, less detail is provided
on each method here, due to the larger number now available. The chapter
focuses on summary statistic selection methods which can be used with stan-
dard ABC algorithms. Summary statistic methods for more specialised recent
algorithms (see Chapters 8, 11, and 21 of this book for example are discussed
only brieﬂy. Secondary aims of the chapter are to collate relevant theoreti-
cal results and discuss issues which are common to many summary statistic
selection methods.
An overview of the chapter is as follows. Section 5.1 is a review of
theoretical results motivating the use of summary statistics in ABC. Section
5.2 describes three strategies for summary statistic selection and introduces
some general terminology. Sections 5.3–5.5 describe particular methods from
each strategy in turn. Up to this point, the chapter concentrates on ABC
for parameter inference. Section 5.6 instead considers summary statistics
for ABC model choice, covering both theory and methods. Section 5.7 con-
cludes by summarising empirical comparisons between methods, discussing
which method to use in practice, and looking at prospects for future
developments.
5.1
Theory
This section describes why methods for selecting summary statistics are nec-
essary in more theoretical detail. Section 5.1.1 discusses the curse of dimen-
sionality, showing that low dimensional informative summaries are needed.
The concept of suﬃcient statistics, reviewed in Section 5.1.2, would appear
to provide an ideal choice of summaries. However, it is shown that low di-
mensional suﬃcient statistics are typically unavailable. Hence, methods for
selecting low dimensional insuﬃcient summaries are required.
Note that from here to Section 5.5, the subject is ABC for parameter
inference, understood to mean inference of continuous parameters. Theoretical
results on ABC for model choice will be discussed in Section 5.6. These are
also relevant for inference of discrete parameters.
5.1.1
The curse of dimensionality
A formal approach to the curse of dimensionality is to consider how the error
in an ABC approximation is related to the number of simulated datasets pro-
duced, n. It can be shown that, at least asymptotically, the rate at which the
error decays becomes worse, as the dimension of the data increases. For ex-
ample, Barber et al. (2015) consider mean squared error of a Monte Carlo

128
Handbook of Approximate Bayesian Computation
estimate produced by ABC rejection sampling. Under optimal ABC tuning
and some regularity conditions, this is shown to be Op(n−4/(q+4)), where q
denotes dim S(y). This is an asymptotic result in a regime where n is large
and the ABC bandwidth h is close to zero. Several authors (Blum, 2010a;
Fearnhead and Prangle, 2012; Biau et al., 2015) consider diﬀerent deﬁnitions
of error and diﬀerent ABC algorithms and prove qualitatively similar results.
That is, similar asymptotic expressions for error are found with slightly diﬀer-
ent terms in the exponent of n. While these asymptotic results may not exactly
capture behaviour for larger h, they strongly suggest that high dimensional
summaries typically give poor results.
Note that it is sometimes possible to avoid the curse of dimensionality for
models whose likelihood factorises, such as state space models for time series
data. This can be done by performing ABC in stages for each factor. This
allows summary statistics to be chosen for each stage, rather than requiring
high dimensional summaries of the entire model. Jasra (2015) reviews this
approach for time series data. See also the related method in Chapter 21 of
this book.
5.1.2
Suﬃciency
Two common deﬁnitions of suﬃciency of a statistic s = S(y) under a model
parameterised by θ are as follows. See Cox and Hinkley (1979) for full de-
tails of this and all other aspects of suﬃciency covered in this section. The
classical deﬁnition is that the conditional density π(y|s, θ) is invariant to θ.
Alternatively, the statistic is said to be Bayes suﬃcient for θ if θ|s and θ|y
have the same distribution for any prior distribution and almost all y. The
two deﬁnitions are equivalent for ﬁnite dimensional θ. Bayes suﬃciency is a
natural deﬁnition of suﬃciency to use for ABC, as it shows that in an ideal
ABC algorithm with suﬃcient S and h →0, the ABC target distribution
equals the correct posterior. It can also be used to consider suﬃciency for
a subset of the parameters, which is useful later when ABC model choice is
considered.
For independent identically distributed data, the Pitman–Koopman–
Darmois theorem states that under appropriate assumptions, only models
in the exponential family possess a suﬃcient statistic with dimension equal
to the dimension of θ. For other models, the dimension of any suﬃcient
statistic increases with the sample size. Exponential family models generally
have tractable likelihoods so that ABC is not required. This result strongly
suggests that for other models, low dimensional suﬃcient statistics do not
exist.
Despite this result there are several ways in which notions of suﬃciency can
be useful in ABC. First, stronger suﬃciency results are possible for ABC model
choice, which are outlined in Section 5.6. Second, notions of approximate and
asymptotic suﬃciency are used to motivate some methods described later
(i.e., those of Joyce and Marjoram, 2008 and Martin et al., 2014).

Summary Statistics
129
5.2
Strategies for Summary Statistic Selection
This chapter splits summary statistic selection methods into three strate-
gies: subset selection, projection, and auxiliary likelihood. This section gives
an overview of each and introduces some useful general terminology. The cat-
egories are based on those used in Blum et al. (2013) with slight changes:
auxiliary likelihood is added and ‘regularisation’ is placed under subset se-
lection. In practice, the categories overlap, with some methods applying a
combination of the strategies.
Subset selection and projection methods require a preliminary step of
choosing a set of data features z(y). For subset selection these can be thought
of as candidate summary statistics. For convenience, z(y) is often written sim-
ply as z below and is a vector of scalar transformations of y, (z1, z2, . . . , zk).
The feature selection step of choosing z is discussed further below. Both meth-
ods also require training data (θi, yi)1≤i≤ntrain to be created by simulation.
Subset selection methods select a subset of z, typically that which opti-
mises some criterion on the training data. Projection methods instead use the
training data to choose a projection of z, for example, a linear transformation
Az + b, which performs dimension reduction.
Auxiliary likelihood methods take a diﬀerent approach which does not need
data features or training data. Instead, they make use of an approximating
model whose likelihood (the ‘auxiliary’ likelihood) is more tractable than the
model of interest. This may be chosen from subject area knowledge or make
use of a general approach, such as composite likelihood. Summary statistics
are derived from this approximating model, for example, its maximum likeli-
hood estimators.
All these methods rely on some subjective input from the user. In sub-
set selection methods, candidate summaries z(y) must be supplied. A typical
choice will be a reasonably small set of summaries which are believed to be in-
formative based on subject area knowledge. (Large sets become too expensive
for most methods to work with.) Projection methods also require a subjective
choice of z(y). A typical choice will be many interesting features of the data,
and various non-linear transformations. These may not be believed to be in-
formative individually, but permit a wide class of potential projections. There
is less requirement for dim z to be small than for subset selection. Auxiliary
likelihood methods instead require the subjective choice of an approximate
likelihood (discussed in Section 5.5.2.)
5.3
Subset Selection Methods
Subset
selection
methods
start
with
candidate
summary
statistics
z = (z1, z2, . . . , zk) and attempt to select an informative subset. The following
methods fall into two groups. The ﬁrst three run ABC for many possible sub-

130
Handbook of Approximate Bayesian Computation
sets and choose the best based on information theoretic or other summaries of
the output. This requires ABC to be run many times, which is only computa-
tionally feasible for rejection or importance sampling ABC algorithms, since
these allow simulated datasets to be re-used. The ﬁnal method, regularisation,
takes a diﬀerent approach. All these methods are described in Section 5.3.1.
Section 5.3.2 compares the methods and discusses the strengths and weak-
nesses of this strategy.
5.3.1
Methods
Approximate suﬃciency (Joyce and Marjoram, 2008)
Joyce and Marjoram (2008) propose a stepwise selection approach. They add/
remove candidate summary statistics to/from a subset one at a time and assess
whether this signiﬁcantly aﬀects the resulting ABC posterior. The motivation
is that given suﬃcient statistics S(·) of minimal dimension, adding further
summaries will not change π(θ|S(yobs)), but removing any summary will. This
would be a test for suﬃciency, but requires perfect knowledge of π(θ|S(yobs)).
Joyce and Marjoram propose a version of this test based on having only a
density estimate and argue it is a test of approximate suﬃciency. A further
approximation is due to using πABC(θ|S(yobs)) in place of π(θ|S(yobs)).
The approach involves testing whether the change from using summaries
S(y) to S′(y) has a signiﬁcant eﬀect on the ABC posterior. As various subsets
are compared, this test will be repeated under many choices of S(y) and S′(y).
A change is deemed signiﬁcant if:

ˆπABC(θ|S′(yobs))
ˆπABC(θ|S(yobs)) −1
 > T(θ),
(5.1)
where ˆπABC(θ) is an estimated posterior density based on ABC rejection sam-
pling output, detailed shortly. The threshold T(·) is deﬁned to test the null
hypothesis that ABC targets the same distribution under both sets of sum-
mary statistics and control for multiple comparison issues arising from testing
(5.1) for several θ values. See the appendix of Joyce and Marjoram for precise
details of how this is deﬁned.
Only the case of scalar θ is considered by Joyce and Marjoram. Here they
propose letting ˆπABC(θ) be a histogram estimator. That is, the support of θ
is split into bins B1, B2, . . . , Bb, and the proportion of the accepted sample in
bin Bi gives ˆπABC(θ) for θ ∈Bi. In practice, (5.1) is evaluated at a ﬁnite set
of parameters θ1 ∈B1, θ2 ∈B2, . . . , θb ∈Bb.
Joyce and Marjoram note it is not obvious how to implement their method
for higher dimensional parameters. This is because the sample size required
to use the histogram estimator of ˆπABC(θ) becomes infeasibly large, and the
paper’s choice of T(·) is speciﬁc to this estimator.

Summary Statistics
131
Entropy/loss minimisation (Nunes and Balding, 2010)
Nunes and Balding (2010) propose two approaches. The ﬁrst aims to ﬁnd the
subset of z which minimises the entropy of the resulting ABC posterior. The
motivation is that entropy measures how concentrated, and thus informative,
the posterior is, with lowest entropy being most informative. In practice, an
estimate of the entropy is used which is based on a ﬁnite sample from the
ABC posterior: an extension of the estimate of Singh et al. (2003).
One criticism of the entropy criterion (Blum et al., 2013) is that in some
circumstances an ABC posterior having smaller entropy does not correspond
to more accurate inference. For example it is possible that given a particularly
precise prior the correct posterior may be more diﬀuse. (See the next page for
a further comment on this.)
The second approach aims to ﬁnd the subset of z which optimises the
performance of ABC on datasets similar to yobs, by minimising the average of
the following loss function (root mean squared error):

t−1
t

i=1
||θi −θ′||2
1/2
.
Here, θ′ is the parameter value which generated data y′, and (θi)1≤i≤t is
the ABC output sample when y′ is used as the observations. Performing this
method requires generating (θ′, y′) pairs such that y′ is close to yobs. Nunes and
Balding recommend doing so using a separate ABC analysis whose summary
statistics are chosen by entropy minimisation. To summarise, this is a two-
stage approach. First, select summaries by entropy minimisation and perform
ABC to generate (θ′, y′) pairs. Second, select summaries by minimising root
mean squared error.
Mutual information (Barnes et al., 2012; Filippi et al., 2012)
Barnes et al. (2012) and Filippi et al. (2012) discuss how suﬃciency can be re-
stated in terms of the concept of mutual information. In particular, suﬃcient
statistics maximise the mutual information between S(y) and θ. From this,
they derive a necessary condition for suﬃciency of S(y): the Kullback–Leibler
(KL) divergence of π(θ|S(yobs)) from π(θ|yobs) is zero for example:

π(θ|yobs) log
π(θ|yobs)
π(θ|S(yobs))dθ = 0.
This motivates a stepwise selection method to choose a subset of z. A statistic
zi is added to the existing subset S(y) to create a new subset S′(y) if the
estimated KL divergence of πABC(θ|S(yobs)) from πABC(θ|S′(yobs)) is above
a threshold. One proposed algorithm chooses zi to maximise this divergence
(a ‘greedy’ approach). Another attempts to save time by selecting any accept-
able zi. Steps are also provided to remove statistics that have become unnec-
essary. Two approaches are given for estimating KL divergence between two
ABC output samples. The stepwise selection algorithm terminates when the

132
Handbook of Approximate Bayesian Computation
improvement in KL divergence is below a threshold. To determine a suitable
threshold, it is suggested to perform ABC several times with ﬁxed summaries
and evaluate the KL divergences between samples. From this, a threshold can
be found indicating an insigniﬁcant change.
The mutual information method is closely related to the previous methods
in this section. Like the method of Joyce and Marjoram (2008), it seeks a sub-
set S(y), such that adding further statistics does not signiﬁcantly change the
ABC posterior. However, the KL criterion has the advantage that it can be
applied when dim θ > 1. It does share the disadvantage that πABC(θ|S(yobs))
is used in place of π(θ|S(yobs)), which is a poor estimate unless h ≈0. Max-
imising mutual information as in Barnes et al., can be shown to be equivalent
to minimising the expected entropy of π(θ|S(y)) (taking expectation over y).
This provides some information theoretic support for the entropy minimisa-
tion approach of Nunes and Balding (2010), but also gives more insight into its
limitations: the entropy of π(θ|S(yobs)), which they consider may not be rep-
resentative of expected entropy. Barnes et al. also argue their method is more
robust than Nunes and Balding’s to the danger of selecting more statistics
than is necessary for suﬃciency.
Barnes et al. extend their method to model choice. This is discussed in
Section 5.6.
Regularisation approaches (Blum, 2010b; Sedki and Pudlo, 2012;
Blum et al., 2013)
This method was proposed by Sedki and Pudlo (2012) and Blum et al. (2013).
The idea is to ﬁt a linear regression with response θ and covariates z based
on training data and perform variable selection to ﬁnd an informative subset
of z. Variable selection can be performed by minimising AIC or BIC (see Blum
et al., 2013, for details of these in this setting including how to calculate.)
This typically requires a stepwise selection approach, although the cost of this
could be avoided by using the lasso (Hastie et al., 2009) rather than ordi-
nary regression. The papers propose also using the ﬁtted regression for ABC
regression post-processing, as well as summary statistic selection. A related
earlier approach (Blum, 2010b) proposed using a local linear regression model
and performing variable selection by an empirical Bayes approach: maximis-
ing the likelihood of the training data after integrating out the distribution of
the regression parameters.
Related methods
Heggland and Frigessi (2004) provide asymptotic theory on summary statis-
tic selection in another likelihood-free method, indirect inference. Roughly
speaking, the most useful summary statistics are those with low variance and
expectation that changes rapidly with the parameters. This theory is used to
select summary statistics from a set of candidates by numerically estimating
their variance and the derivative of their expectation based on a large number

Summary Statistics
133
of simulations from promising parameter values. It would be useful to develop
ABC versions of this theory and methodology. Ratmann et al. (2007) go some
way towards providing the latter for a particular application.
5.3.2
Discussion
Comparison of subset selection methods
Joyce and Marjoram (2008) is based on rough ideas of suﬃciency and can be
implemented only in the limited setting of a scalar parameter. The entropy
minimisation method of Nunes and Balding (2010) and the approach of
Barnes et al. (2012) are successively more sophisticated information theoretic
approaches. The latter has the best theoretical support of methods based on
such arguments. However, all these methods are motivated by properties of
π(θ|S(yobs)), but then use πABC(θ|S(yobs)) in its place. For suﬃciently large h
these may be quite diﬀerent, and it is unclear what eﬀect this will have on the
results. The loss minimisation method of Nunes and Balding (2010) avoids this
problem. It chooses S so that ABC results on simulated data optimise a spec-
iﬁed loss function given a particular choice of h. The question of robustness to
the choice of which simulated datasets are used to assess this is still somewhat
open, but otherwise this method seems to provide a gold standard approach.
The drawback of all the previous methods is that they can be extremely ex-
pensive (see below). Regularisation methods are cheaper, but have received
little study, so their properties are not well understood.
Advantages and disadvantages of subset selection
An advantage of subset selection methods is interpretability. If the summaries
in z have intuitive interpretations, then so will the resulting subset. This
is especially useful for model criticism by the method of Ratmann et al.
(2009). Here, one investigates whether the simulated S(y) values accepted
by ABC are consistent with sobs. If some particular component of sobs cannot
be matched well by the simulations, this suggests model mis-speciﬁcation. Un-
derstanding the interpretation of this summary can hopefully suggest model
improvements.
A disadvantage is the implicit assumption that a low dimensional infor-
mative subset of z exists. Subset selection can be thought of as a projection
method which is restricted to projections to subsets. However, it may be the
case that the best choice is outside this restriction, for example, the mean of
the candidate summaries.
Further disadvantages are cost and scalability problems. For small k
(denoting dim z), it may be possible to evaluate the performance of all subsets
of z and ﬁnd the global optimum. For large k, this is prohibitively expensive
and more sophisticated search procedures such as stepwise selection must be
used. However, such methods may only converge to a local optimum, and the
computational cost still grows rapidly with k.

134
Handbook of Approximate Bayesian Computation
Computational cost is particularly large for the methods which require
ABC to be re-run for each subset of z considered. The computing require-
ment is typically made more manageable by using the same simulations for
each ABC analysis. However, this restricts the algorithm used in this stage
to ABC rejection or importance sampling. Therefore, the resulting summary
statistics have not been tested at the lower values of h, which could be achieved
using ABC-MCMC or ABC-SMC and may not be good choices under these
algorithms.
Finally, as discussed in Section 5.2, subset selection methods require a
feature selection stage to choose the set of potential summaries z. In all the
papers cited earlier, this step is based on subjective choice and is crucial to
good performance. Comparable subjective choices are also required by the
strategies described later. However a particular constraint here is that dim z
cannot be too large or the cost of subset selection becomes infeasible.
5.4
Projection Methods
Projection methods start with a vector of data features z(y) = (z1, z2, . . . , zk)
and attempts to ﬁnd an informative lower dimensional projection, often a lin-
ear transformation. To choose a projection, training data (θi, yi)1≤i≤ntrain are
created by simulation from the prior and model and some dimension reduc-
tion technique is applied. Section 5.4.1 presents various dimension reduction
methods which have been proposed for use in ABC. Section 5.4.2 describes
variations in how the training data are generated. It is generally possible to
match up the two parts of the methodology as desired. Section 5.4.3 compares
the methods and discusses the strengths and weaknesses of this strategy.
5.4.1
Dimension reduction techniques
Partial least squares (Wegmann et al., 2009)
Partial least squares (PLS) aim to produce linear combinations of covariates
which have high covariance with responses and are uncorrelated with each
other. In the ABC setting, the covariates are z1, . . . , zk and the responses are
θ1, . . . , θp. The ith PLS component ui = αT
i z maximises:
p

j=1
Cov(ui, θj)2,
subject to Cov(ui, uj) = 0 for j < i and a normalisation constraint on
αi, such as αT
i αi = 1. In practice, empirical covariances based on training
data are used. Several algorithms to compute PLS components are available.

Summary Statistics
135
These can produce diﬀerent results, as they use slightly diﬀerent normalisation
constraints. For an overview of PLS, see Boulesteix and Strimmer (2007).
PLS produces min(k, ntrain −1) components. Wegmann et al. (2009) use
the ﬁrst c components as ABC summary statistics, with c chosen by a cross-
validation procedure. This aims to minimise the root mean squared error in
a linear regression of θ on u1, . . . , uc. This approach is similar to the regular-
isation subset selection methods of Section 5.3.
Linear regression (Fearnhead and Prangle, 2012)
Fearnhead and Prangle (2012) ﬁt a linear model to the training data: θ ∼
N(Az + b, Σ). The resulting vector of parameter estimators ˆθ(y) = Az + b is
used as ABC summary statistics. This is a low dimensional choice: dim ˆθ(y) =
dim θ = p.
Motivation for this approach comes from the following result. Con-
sider π(θ|S(yobs)), which is the ABC target distribution for h = 0. Then
S(y) = E(θ|y) can be shown to be the optimal choice in terms of minimising
quadratic loss of the parameter means in this target distribution. Fitting a
linear model produces an estimator of these ideal statistics.
A linear regression estimate of E(θ|y) is crude, but can be improved by
selecting good z(y) features. Fearnhead and Prangle propose comparing z(y)
choices by looking at the goodness of ﬁt of the linear model, in particular the
BIC values. Another way to improve the estimator is to train it on a local
region of the parameter space. This is discussed in Section 5.4.2. Fearnhead
and Prangle use the name ‘semi-automatic ABC’ to refer to summary statistic
selection by linear regression with these improvements. Good performance is
shown for a range of examples and is particularly notable when z(y) is high
dimensional (Fearnhead and Prangle, 2012; Blum et al., 2013).
As Robert (2012) points out, the theoretical support for this method is only
heuristic, as it focuses on the unrealistic case of h = 0. Another limitation is
that these summaries focus on producing good point estimates of θ, and not on
accurate uncertainty quantiﬁcation. Fearnhead and Prangle propose a modi-
ﬁed ABC algorithm (‘noisy ABC’), which tackles this problem to some extent.
The earlier discussion also motivates using more advanced regression-like
methods. Fearnhead and Prangle investigate the lasso (Hastie et al., 2009),
canonical correlation analysis (Mardia et al., 1979), and sliced inverse regres-
sion (Li, 1991) (see Prangle, 2011 for details). The former two do not produce
signiﬁcant improvements over linear regression in the applications considered.
The latter produces large improvements in one particular example, but re-
quires signiﬁcant manual tuning. Many further suggestions can be found in
the discussions published alongside Fearnhead and Prangle (2012).
Boosting (Aeschbacher et al., 2012)
Boosting is a non-linear regression method. Like linear regression, it requires
training data and outputs predictors ˆθ(y) of E(θ|y), which can be used as ABC

136
Handbook of Approximate Bayesian Computation
summary statistics. Boosting is now sketched for scalar θ. For multi-variate θ,
the whole procedure can be repeated for each component. The approach be-
gins by ﬁtting a ‘weak’ estimator to the training data. For this, Aeschbacher
et al. (2012) use linear regression with response θ and a single covariate:
whichever feature in z(y) maximises reduction in error (e.g. mean squared
error). The training data are then weighted according to the error under this
estimator. A second weak estimator is ﬁtted to this weighted training data
and a weighted average of the ﬁrst two estimators is formed. The training data
are weighted according to its error under this, and a third weak estimator is
formed, and so on. Eventually the process is terminated, and the ﬁnal weighted
average of weak estimators is output as a ‘strong’ estimator. The idea is that
each weak estimator attempts to concentrate on data which have been esti-
mated poorly in previous steps. See B¨uhlmann and Hothorn (2007) for a full
description.
5.4.2
Generating training data
A straightforward approach to draw training data pairs (θ, y) is to sample θ
from the prior and y from the model conditional on θ. This approach is used
by Wegmann et al. (2009), for example. In rejection or importance sampling
ABC algorithms, this training data can be re-used to implement the ABC
analysis. Hence, there is no computational overhead in producing training
data. For other ABC algorithms, this is not the case.
Fearnhead and Prangle (2012) and Aeschbacher et al. (2012) use diﬀer-
ent approaches to generate training data which aim to make the projection
methods more eﬀective. The idea is that the global relationship between θ
and y is likely to be highly complicated and hard to learn. Learning about
the relationship close to yobs may be easier. This motivates sampling training
pairs from a more concentrated distribution.
Aeschbacher et al. (2012) implement this by performing a pilot ABC anal-
ysis using S(y) = z (i.e. all the data features). The accepted simulations are
used as training data for their boosting procedure. The resulting summary
statistics are then used in an ABC analysis.
Fearnhead and Prangle (2012) argue that such an approach might be dan-
gerous. This is because S(y) is only trained to perform well on a concentrated
region of (θ, y) values and could perform poorly outside this region. In par-
ticular it is possible that S(y) ≈S(yobs) in regions excluded by the pilot
analysis, producing artefact posterior modes. Fearnhead and Prangle instead
recommend performing a pilot ABC analysis using ad-hoc summary statistics.
This is used to ﬁnd a training region of parameter space, R, containing most
of the posterior mass. Training θ values are drawn from the prior truncated to
R, and y values from the model. Summary statistics are ﬁtted and used in a
main ABC analysis, which also truncates the prior to R. This ensures that θ
regions excluded by the pilot remain excluded in the main analysis. Note that

Summary Statistics
137
this truncation approach was introduced by Blum and Fran¸cois (2010) in a
regression post-processing context.
5.4.3
Discussion
Comparison of projection methods
Partial least squares is a well established dimensional reduction method. How-
ever, it does not have any theoretical support for use in ABC and some-
times performs poorly in practice (Blum et al., 2013). Fearnhead and Prangle
(2012) provide heuristic theoretical support to the approach of constructing
parameter estimators for use as ABC summary statistics, and show empiri-
cally implementing this by the simple method of linear regression can perform
well in practice. It is likely that more sophisticated regression approaches will
perform even better. Boosting is one example of this. A particularly desirable
goal would be a regression method which can incorporate the feature selection
step and estimate E(θ|y) directly from the raw data y. This is discussed further
in Section 5.7.
Advantages and disadvantages of projection methods
Projection methods avoid some of the disadvantages of subset selection meth-
ods. In particular, the high computational costs associated with repeating
calculations for many possible subsets are avoided. Also, a wider space of
potential summaries is searched, not just subsets of z. However, this means
that the results may be less interpretable and thus harder to use for model
criticism. (For further discussion of all these points see Section 5.3.2.)
Another advantage of projection methods is that they can be implemented
on almost any problem. This is in contrast to auxiliary likelihood methods,
which require the speciﬁcation of a reasonable approximate likelihood.
Projection methods require a subjective choice of features z(y), as do sub-
set selection methods. However, projection methods have more freedom to
choose a large set of features and still have a feasible computational cost,
and some methods provide heuristic tools to select between feature sets (i.e.
Fearnhead and Prangle, 2012 use BIC.).
5.5
Auxiliary Likelihood Methods
An intuitively appealing approach to choosing summary statistics for ABC
inference of a complicated model is to use statistics which are known to
be informative for a simpler related model. This has been done since the
earliest precursors to ABC in population genetics (e.g. Fu and Li, 1997;
Pritchard et al., 1999). Recently, there has been much interest in formalising

138
Handbook of Approximate Bayesian Computation
this approach. The idea is to specify an approximate and tractable likeli-
hood for the data, referred to as an auxiliary likelihood, and derive summary
statistics from this. Several methods to do this have been proposed, which
are summarised in Section 5.5.1 and discussed in Section 5.5.2. There have
also been related proposals for new likelihood-free methods based on auxiliary
likelihoods which are covered elsewhere in this volume (see Chapters 8 and 12).
First some notation and terminology is introduced. The auxiliary likeli-
hood is represented as pA(y|φ). This can be thought of as deﬁning an auxiliary
model for y. This diﬀers from the model whose posterior is sought, which is
referred to here as the generative model. The auxiliary model parameters, φ,
need not correspond to those of the generative model, θ. A general question is
which auxiliary likelihood to use. This is discussed in Section 5.5.2, including
a description of some possible choices. To assist in reading Section 5.5.1, it
may be worth keeping in mind the simplest choice: let the auxiliary model be
a tractable simpliﬁed version of the generative model.
5.5.1
Methods
Maximum likelihood estimators
Here, S(y) = ˆφ(y) = argmaxφpA(y|φ). That is, the summary statistic vector
is the maximum likelihood estimator (MLE) of φ given data y under the auxil-
iary model. To use this method, this MLE must be unique for any y. Typically,
S(y) must be calculated numerically, which is sometimes computationally
costly.
This approach was proposed by Drovandi et al. (2011), although Wilson
et al. (2009) use a similar approach in a particular application. It was mo-
tivated by a similar choice of summaries in another likelihood-free method,
indirect inference (Gourieroux et al., 1993). The terminology ABC-IP for
this approach was introduced by Gleim and Pigorsch (2013): ‘I’ represents
indirect and ‘P’ using parameter estimators as summaries.
Some theoretical support for ABC-IP is available. Gleim and Pigorsch
(2013) note that classical statistical theory shows that ˆφ(y) is typically asymp-
totically suﬃcient for the auxiliary model (see Chapter 9 of Cox and Hinkley,
1979 for full details). This assumes an asymptotic setting, where n →∞as
the data becomes more informative. As a simple example, y could consist of n
independent identically distributed observations. Asymptotic suﬃciency im-
plies ˆφ(y) asymptotically summarises all the information about the auxiliary
model parameters.
Ideally, ˆφ(y) would also be asymptotically suﬃcient for the generative
model. Gleim and Pigorsch show this is the case if the generative model
is nested within the auxiliary model. However, having a tractable auxiliary
model of this form is rare. Martin et al. (2014) note that even without
asymptotic suﬃciency for the generative model, Bayesian consistency can
be attained. That is, the distribution π(θ|ˆφ(y)) asymptotically shrinks to a
point mass on the true parameter value. They give necessary conditions for

Summary Statistics
139
consistency: essentially that in this limit, ˆφ(y) perfectly discriminates between
data generated by diﬀerent values of θ.
Likelihood distance
Gleim and Pigorsch (2013) suggest a variation on ABC-IP which uses the
distance function:
||ˆφ(y), ˆφ(yobs)|| = log pA(yobs|ˆφ(yobs)) −log pA(yobs|ˆφ(y)).
(5.2)
This is the log likelihood ratio for the auxiliary model between the MLEs
under the observed and simulated datasets. They refer to this as ABC-IL:
‘L’ represents using a likelihood distance.
It is desirable that ||ˆφ(y), ˆφ(yobs)|| = 0 if and only if ˆφ(y) = ˆφ(yobs). This
requires pA to be well behaved. For example, it suﬃces that y →ˆφ(y) is a
one-to-one mapping. However, weaker conditions can sometimes be used: see
Drovandi et al. (2015) Section 7.3, for example.
Scores
Gleim and Pigorsch (2013) suggest taking:
S(y) =

∂
∂φi log pA(y|φ)
φ= ˆφ(yobs)

1≤i≤p .
(5.3)
This is the score of the auxiliary likelihood evaluated under parameters
ˆφ(yobs). As earlier, ˆφ(yobs) is the MLE of yobs under the auxiliary likelihood.
Gleim and Pigorsch refer to this approach as ABC-IS: ‘S’ refers to using
score summaries.
The motivation is that the score has similar asymptotic properties to those
described earlier for the MLE (Gleim and Pigorsch, 2013; Martin et al., 2014),
but is cheaper to calculate. This is because numerical optimisation is required
once only, to ﬁnd ˆφ(yobs), rather than every time S(y) is computed. Drovandi
et al. (2015) also note that ABC-IS is more widely applicable than ABC-IP,
as it does not require existence of a unique MLE for pA(y|φ) under all y, only
under yobs.
Some recent variations of ABC-IS include: application to state-space mod-
els by using a variation on Kalman ﬁltering to provide the auxiliary likelihood
and use of a marginal score (Martin et al., 2014); alternatives to the score func-
tion (5.3) based on proper scoring rules (Ruli et al., 2014); and using a rescaled
score when the auxiliary model is a composite likelihood (Ruli et al., 2016).
5.5.2
Discussion
Comparison of auxiliary likelihood methods
ABC-IS has the advantage that it is not based on calculating the MLE repeat-
edly. This can be computationally costly, may be prone to numerical errors,

140
Handbook of Approximate Bayesian Computation
and, indeed, a unique MLE may not even exist. Furthermore, the asymp-
totic properties discussed earlier suggest the score-based summaries used by
ABC-IS encapsulate similar information about the auxiliary likelihood as the
MLE. This recommends use of ABC-IS. However, empirical comparisons by
Drovandi et al. (2015) suggest the best auxiliary likelihood method in practice
is problem speciﬁc (see Section 5.7 for more details).
Which auxiliary likelihood?
Various choices of auxiliary likelihood have been used in the literature. Ex-
amples include the likelihood of a tractable alternative model for the data or
of a ﬂexible general model, such as a Gaussian mixture. Another is to use
a tractable approximation to the likelihood of the generative model, such as
composite likelihood (Varin et al., 2011). There is a need to decide which
choice to use.
An auxiliary likelihood should ideally have several properties. To produce
low dimensional summary statistics, it should have a reasonably small number
of parameters. Also, it is desirable that it permits fast and accurate computa-
tion of the MLE or score. These two requirements are easy to assess. A third
requirement is that the auxiliary likelihood should produce summary statis-
tics which are informative about the generative model. This seems harder to
quantify.
Drovandi et al. (2015) recommend performing various goodness-of-ﬁt tests
to see how well the auxiliary likelihood matches the data. Similarly, Gleim
and Pigorsch (2013) use the BIC to choose between several possible auxiliary
likelihoods. Such tests are computationally cheap and give insight into the
ability of the model to summarise important features of the data. However, it
is not clear that performing better in a goodness-of-ﬁt test necessarily results
in a better ABC approximation. Ideally, what is needed is a test of how well an
auxiliary likelihood discriminates between datasets drawn from the generative
model under diﬀerent parameter values. How to test this is an open problem.
Advantages and disadvantages of auxiliary likelihood methods
Auxiliary likelihood methods avoid the necessity of choosing informative data
features required by subset selection and projection methods. This is replaced
by the somewhat analogous need to choose an informative auxiliary likeli-
hood. However, such a choice may often be substantially easier, particularly if
well-developed tractable approximations to the generative model are already
available. In other situations, both tasks may be equally challenging.
Another advantage of auxiliary likelihood methods is that they avoid the
computational cost of generating training data, as required by preceding meth-
ods. Instead, they make use of subject area knowledge to propose auxiliary
likelihoods. In the absence of such knowledge, one could try to construct an
auxiliary likelihood from training data. This is one viewpoint of how projection
methods based on regression operate.

Summary Statistics
141
5.6
Model Choice
ABC can be applied to inference when there are several available models
M1, M2, . . . , Mr. See Chapter 7 in this volume or Didelot et al. (2011) for de-
tails of algorithms. This section is on the problem of choosing which summary
statistics to use here. The aim of most work to date is to choose summaries
suitable for inferring the posterior model weights. The more challenging prob-
lem of also inferring model parameters is mentioned only brieﬂy.
A natural approach used by some early practical work is to use summary
statistics which are informative for parameter inference in each model. Un-
fortunately, except in a few special cases, this can give extremely poor model
choice results, as highlighted by Robert et al. (2011). The issue is that sum-
mary statistics, which are good for parameter inference within models, are
not necessarily informative for choosing between models. This section sum-
marises more recent theoretical and practical work which shows that infor-
mative summary statistics can be found for ABC model choice. Therefore,
ABC model choice can now be trusted to a similar degree to ABC parameter
inference.
The remainder of this section is organised as follows. Section 5.6.1
re-examines suﬃciency and other theoretical issues for ABC model choice,
as there are some surprisingly diﬀerent results to those described earlier in
the chapter for the parameter inference case. Section 5.6.2 reviews practi-
cal methods of summary statistic selection, and Section 5.6.3 gives a brief
discussion.
Note that model choice can be viewed as inference of a discrete parame-
ter m ∈{1, 2, . . . , r} indexing the available models. Therefore, the following
material would also apply to ABC inference of a discrete parameter. How-
ever, as elsewhere in this chapter, the phrase ‘parameter inference’ is gen-
erally used in the section as shorthand to refer to inference of continuous
parameters.
5.6.1
Theory
Curse of dimensionality
As described earlier ABC suﬀers a curse of dimensionality when dealing with
high dimensional data. Theoretical work on this, summarised in Section 5.1.1,
has focused on the parameter inference case. However, the technical arguments
involved focus on properties of the summary statistics, rather than of the pa-
rameters. Therefore, it seems likely that the arguments can be adapted to give
unchanged results for model choice simply by considering the case of discrete
parameters.
This means it remains important to use low dimensional summary statis-
tics for ABC model choice.

142
Handbook of Approximate Bayesian Computation
Suﬃciency and consistency
As for parameter inference case, the ideal summaries for ABC model choice
would be low dimensional suﬃcient statistics. Unlike the case of parameter
inference, such statistics do exist for ABC model choice, and results are also
available on links to consistency and suﬃciency for parameter inference. These
theoretical results are now summarised and will motivate some of the methods
for summary statistic choice described in the next section.
First, some terminology is deﬁned, based on the deﬁnitions of suﬃciency
in Section 5.1.2. Let θi represent the parameters associated with model Mi.
Statistics S(y) that are suﬃcient for θi under model Mi will be referred to
below as suﬃcient for parameter inference in that model. Now consider the
problem of jointly inferring θ1, θ2, . . . , θr, m, where m is a model index. This
is equivalent to inference on an encompassing model in which the data are
generated from Mi conditional on θi when m = i. Statistics will be referred
to as suﬃcient for model choice if they are Bayes suﬃcient for m in this
encompassing model.
Didelot et al. (2011) show that suﬃcient statistics for model choice between
models M1 and M2 can be found by taking parameter inference suﬃcient
statistics of a model in which both are nested. This result is of limited use, as
such parameter inference suﬃcient statistics rarely exist in low dimensional
form (see discussion in Section 5.1.2). However, it has useful consequences in
the special case where M1 and M2 are both exponential family distributions
for example:
π(y|θi, Mi) ∝exp
	
si(x)T θi + ti(x)

,
for i = 1, 2. In this case, si(x) is a vector of parameter inference suﬃcient
statistics for model Mi and exp[ti(x)] is known as the base measure. Didelot
et al. (2011) show that suﬃcient statistics for model choice are the concate-
nation of s1(x), s2(x), t1(x), and t2(x).
Prangle et al. (2014) prove that the following vector of statistics is suﬃcient
for model choice:
T(y) = (T1(y), T2(y), . . . , Tr−1(y)),
where
Ti(y) = π(y|Mi)/
r

j=1
π(y|Mj).
Here, Ti(y) is the evidence under Mi divided by the sum of model evidences.
Furthermore, any other vector of statistics is suﬃcient for model choice if and
only if it can be transformed to T(y).
Thus low dimensional suﬃcient statistics exist if the number of models r is
reasonably small. This results may seem at ﬁrst to contradict the arguments
of Section 5.1, that these are only available for exponential family models.

Summary Statistics
143
A contradiction is avoided because model choice is equivalent to inferring the
discrete parameter m, and a model with a discrete parameter can be expressed
as an exponential family.
A related result is proved by Marin et al. (2014). They give necessary
conditions on summary statistics S(y) for Pr(m|S(y)) to be consistent in an
asymptotic regime corresponding to highly informative data. That is, these
conditions allow for perfect discrimination between models in this limiting
case. In addition to several technical conditions, the essential requirement is
that the limiting expected value of the summary statistic vector should diﬀer
under each model.
5.6.2
Methods
Using an encompassing model (Didelot et al., 2011)
As described earlier, Didelot et al. (2011) prove that suﬃcient statistics for
model choice between exponential family models can be found by concate-
nating the parameter suﬃcient statistics and base measures of each model.
Situations where this can be used are rare, but one is the Gibbs random ﬁeld
application considered by Grelaud et al. (2009). In this case, the base measures
are constants and so can be ignored.
Mutual information (Barnes et al., 2012)
This method was described earlier for the case of parameter inference. To
recap brieﬂy, it is a subset selection method motivated by the concept of
mutual information, which sequentially adds or removes candidate summary
statistics to or from a set. Each time, a Kullback–Leibler divergence between
the ABC posterior distributions under the previous and new sets is estimated.
The process terminates when the largest achievable divergence falls below a
threshold.
Barnes et al. (2012) adapt this method to ﬁnd summary statistics for joint
model and parameter inference as follows. First, they estimate suﬃcient statis-
tics for parameter inference under each model, and concatenate these. Next,
they add further statistics until model suﬃciency is also achieved. Alterna-
tively, the method could easily be adapted to search for statistics which are
suﬃcient for model choice only.
Projection/classiﬁcation methods (Estoup et al., 2012; Prangle
et al., 2014)
The idea here is to use training data to construct a classiﬁer which attempts
to discriminate between the models given data y. Informative statistics are
taken from the ﬁtted classiﬁer and used as summary statistics in ABC. This
can be thought of as a projection approach mapping high dimensional data y
to low dimensional summaries.

144
Handbook of Approximate Bayesian Computation
Two published approaches of this form are now described in more de-
tail. Training data (θi, mi, yi)1≤i≤ntrain are created, where yi is drawn from
π(y|θi, mi) (generating θi, mi pairs is discussed below). A vector of data fea-
tures z(y) must be speciﬁed. A classiﬁcation method is then used to ﬁnd linear
combinations αT z(y) which are informative about m, the model index. Estoup
et al. (2012) use linear discriminant analysis, and Prangle et al. (2014) use
logistic regression (for the case of two models). For a review of both, see Hastie
et al. (2009), who note they typically give very similar results. As motivation,
Prangle et al. observe that, in the two model case, logistic regression produces
a crude estimate of logit[Pr(M1|y)], which would be suﬃcient for model choice
as discussed earlier (extending this argument to more than two models is also
discussed).
The simplest approach to drawing θi, mi pairs is simply to draw mi
from its prior (or with equal weights if this is too unbalanced) and θi
from the appropriate parameter prior. Prangle et al. (2014) observe that
it can sometimes be hard for their classiﬁer to ﬁt the resulting training
data. They propose instead producing training data which focus on the most
likely θ regions under each model (as in the similar approach for parameter
inference in Section 5.4.2). The resulting summary statistics are only trained
to discriminate well in these regions, so a modiﬁed ABC algorithm is required
to use them. This involves estimation of some posterior quantities and so may
not be possible in some applications.
Alternatively, Estoup et al. (2012) ﬁrst perform ABC with a large num-
ber of summary statistics. The accepted output is used as training data to
ﬁt model choice summary statistics. These are then used in regression post-
processing. This avoids the need for a modiﬁed ABC algorithm, but the
ﬁrst stage of the analysis may still suﬀer from errors due to the curse of
dimensionality.
Local error rates (Stoehr et al., 2014)
Stoehr et al. (2014) compare three sets of summary statistics for ABC
model choice in the particular setting of Gibbs random ﬁelds. The idea
is to pick the choice which minimises the local error rate, deﬁned shortly.
This method could easily be used more generally, for example, as the ba-
sis of a subset selection method similar to the loss minimisation method of
Nunes and Balding (2010).
The local error rate is Pr( ˆ
M(yobs) ̸= M|yobs), where ˆ
M(y) is the model
with greatest weight under the target distribution of the ABC algorithm given
data y. (This can be interpretted as using a 0-1 loss function). In practice,
this quantity is unavailable, but it can be estimated. Suppose a large number
of (yi, Mi)1≤i≤nval validation pairs have been generated. Stoehr et al. sug-
gest running ABC using each yi in turn as the observations and evaluating
an indicator variable δi, which equals 1 when ABC assigns most weight to
model Mi. Non-parametric regression is then used to estimate Pr(δ = 1|yobs).

Summary Statistics
145
This is challenging if dim y is large, so dimension reduction is employed.
Stoehr et al. use linear discriminant analysis for this (as in the Estoup et al.,
2012 approach described earlier.) To reduce costs, a cross-validation scheme
is used so that the same simulations can be used for ABC analyses and
validation.
5.6.3
Discussion
Comparison of methods
The approach of Didelot et al. (2011) – choosing suﬃcient statistics for an
encompassing model – is only useful in specialised circumstances, such as
choice between exponential family models. The other methods listed earlier
are more generally applicable. Their advantages and disadvantages are simi-
lar to those discussed earlier for corresponding parameter inference methods.
In particular, the two subset selection methods have the disadvantage that
they have high computational costs if there are many candidate summary
statistics.
Prospects
Comparatively few summary statistic selection methods have been proposed
for the model choice setting. Thus, there is potential to adapt other existing
approaches from the parameter inference case for use here. In particular, it
would be interesting to see whether regularisation or auxiliary likelihood ap-
proaches can be developed.
Another promising future direction is to construct model choice summary
statistics using more sophisticated classiﬁcation methods than those described
earlier, for example, random forests or deep neural networks. As an alternative
to using these methods to produce summary statistics, some of them can
directly output likelihood-free inference results (Pudlo et al., 2015).
Finally, choosing summary statistics for joint ABC inference of model and
parameters is a desirable goal. One approach is to separately ﬁnd summaries
for model choice and for parameter inference in each model and concatenate
these. However, it may be possible to produce lower dimensional informative
summaries by utilising summaries which are informative for several of these
goals. Finding methods to do this is an open problem.
5.7
Discussion
Empirical performance
Most papers proposing methods of summary statistic choice report some em-
pirical results on performance. These show some merits to all the proposed
methods. However, it is diﬃcult to compare these results to each other as

146
Handbook of Approximate Bayesian Computation
there are many diﬀerences between the applications, algorithms, and tuning
choices used. Two studies are reported here which compare several methods
on multiple parameter inference applications. Little comparable work exists
for model choice methods.
Blum et al. (2013) compare several subset selection and projection methods
on three applications using ABC rejection sampling. They conclude: ‘What
is very apparent from this study is that there is no single “best” method of
dimension reduction for ABC.’ The best performing methods for each appli-
cation are: the two stage method of Nunes and Balding (2010) on the smallest
example (k = 6). the AIC and BIC regularisation methods on a larger ex-
ample (k = 11), and the linear regression method of Fearnhead and Prangle
(2012) on the largest example (k = 113). (Recall k = dim z i.e. the number of
data features.)
Drovandi et al. (2015) compare auxiliary likelihood methods on several
applications using ABC MCMC. They conclude: ‘Across applications con-
sidered in this paper, ABC IS was the most computationally eﬃcient and
led to good posterior approximations’. However, they note that its posterior
approximation was not always better than ABC-IP and ABC-IL, so that again,
the best approach seems problem speciﬁc.
Which method to use
Although many methods for choosing summary statistics have been proposed,
there are no strong theoretical or empirical results about which to use in
practice for a particular problem. Also, the area is developing rapidly, and
many new approaches can be expected to appear soon. Therefore, only very
general advice is given here.
Each of the strategies discussed has its particular strengths. When a small
set of potential summaries can be listed, subset selection performs a thorough
search of possible subsets. When a good tractable approximate likelihood is
available, auxiliary likelihood methods can make use of it to produce informa-
tive parameter inference summaries, although they are not yet available for
model choice. Projection methods are highly ﬂexible and can be applied to
almost any problem.
It seems advisable to consider subset selection or auxiliary likelihood meth-
ods in situations that suit their strengths and projection methods otherwise.
The question of which methods are most appealing within each strategy is dis-
cussed within their respective sections. For parameter inference, the empirical
comparisons described earlier can also provide some guidance.
Ideally, if resources are available, the performance of diﬀerent methods
should be assessed on the problem of interest. This requires repeating some
or all of the analysis for many simulated datasets. To reduce the compu-
tation required, Bertorelle et al. (2010) and Blum et al. (2013) advocate

Summary Statistics
147
performing a large set of simulations and re-using them to perform the required
ABC analyses. This restricts the algorithm to ABC rejection or importance
sampling.
Finally, note that there is considerable scope to modify the summary
statistics generated by the methods in this chapter. For example, the user
may decide to choose a combination of statistics produced by several diﬀerent
methods or add further summary statistics based on subject area insights.
Prospects
This chapter has shown how, amongst other approaches, classiﬁcation and
regression methods can be used to provide ABC summary statistics from
training data. There are many sophisticated tools for these in the statistics
and machine learning literature, which may produce more powerful ABC sum-
mary statistic selection methods in future. It would be particularly desirable
to ﬁnd methods which do not require a preliminary subjective feature selec-
tion stage. One promising approach to this is regression using deep neural
networks (Goodfellow et al, 2016), although it is unclear whether the amount
of training data required to ﬁt these well would be prohibitively expensive
to simulate. Another possibility is to come up with dictionaries of generally
informative features for particular application areas. Fulcher et al. (2013) and
Stocks et al. (2014) implement ideas along these lines for time series analysis
and population genetics, respectively.
A topic of recent interest in ABC is the case where a dataset y is made up
of many observations which are either independent and identically distributed
or have some weak dependence structure. Several approaches to judging the
distance between such datasets have been recently proposed. These fall some-
what outside the framework of this chapter, as they bypass producing conven-
tional summary statistics and instead simply deﬁne a distance. An interesting
question is the extent to which these alleviate the curse of dimensionality. The
methods base distances on: classical statistical tests (Ratmann et al., 2013);
the output of classiﬁers (Gutmann et al., 2018); and kernel embeddings (Park
et al., 2016).
This chapter has concentrated on using summary statistics to reduce the
ABC curse of dimensionality and approximate the true posterior π(θ|yobs).
However, other aspects of summary statistics are also worth investigating.
First, it is possible that dimension-preserving transformations of S(y) may
also improve ABC performance. This is exploited by Yıldırım et al. (2015) in
the context of a speciﬁc ABC algorithm for example. Second, several authors
(Wood, 2010; Girolami and Cornebise, 2012; Fasiolo et al., 2016) discuss cases
where the true posterior is extremely hard to explore, for example, because
it is very rough with many local modes. They argue that using appropriate
summary statistics can produce a better behaved π(θ|sobs) distribution, which
is still informative about model properties of interest.

148
Handbook of Approximate Bayesian Computation
References
Aeschbacher, S., M. A. Beaumont, and A. Futschik (2012). A novel approach
for choosing summary statistics in approximate Bayesian computation.
Genetics 192(3), 1027–1047.
Barber, S., J. Voss, and M. Webster (2015). The rate of convergence for ap-
proximate Bayesian computation. Electronic Journal of Statistics 9, 80–105.
Barnes, C. P., S. Filippi, M. P. H. Stumpf, and T. Thorne (2012). Considerate
approaches to constructing summary statistics for ABC model selection.
Statistics and Computing 22, 1181–1197.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162, 2025–2035.
Goodfellow, I., Y. Bengio, and A. Courville (2016). Deep Learning. Cambridge,
MA: MIT press
Bertorelle, G., A. Benazzo, and S. Mona (2010). ABC as a ﬂexible frame-
work to estimate demography over space and time: Some cons, many pros.
Molecular Ecology 19(13), 2609–2625.
Biau, G., F. C´erou, and A. Guyader (2015). New insights into approximate
Bayesian computation. Annales de l’Institut Henri Poincar´e (B) Proba-
bilit´es et Statistiques 51(1), 376–403.
Blum, M. G. B. (2010a). Approximate Bayesian computation: A nonparamet-
ric perspective. Journal of the American Statistical Association 105(491),
1178–1187.
Blum, M. G. B. (2010b). Choosing the summary statistics and the accep-
tance rate in approximate Bayesian computation. In Proceedings of COMP-
STAT’2010, pp. 47–56. New York: Springer.
Blum, M. G. B. and O. Fran¸cois (2010). Non-linear regression models
for approximate Bayesian computation. Statistics and Computing 20(1),
63–73.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson (2013). A com-
parative review of dimension reduction methods in approximate Bayesian
computation. Statistical Science 28, 189–208.
Boulesteix, A.-L. and K. Strimmer (2007). Partial least squares: A versatile
tool for the analysis of high-dimensional genomic data. Brieﬁngs in Bioin-
formatics 8(1), 32–44.
B¨uhlmann, P. and T. Hothorn (2007). Boosting algorithms: Regularization,
prediction and model ﬁtting. Statistical Science, 477–505.

Summary Statistics
149
Cox, D. R. and D. V. Hinkley (1979). Theoretical Statistics. CRC Press: Boca
Raton, FL.
Didelot, X., R. G. Everitt, A. M. Johansen, and D. J. Lawson (2011).
Likelihood-free estimation of model evidence. Bayesian Analysis 6(1),
49–76.
Drovandi, C. C., A. N. Pettitt, and M. J. Faddy (2011). Approximate Bayesian
computation using indirect inference. Journal of the Royal Statistical Soci-
ety: Series C 60(3), 317–337.
Drovandi, C. C., A. N. Pettitt, and A. Lee (2015). Bayesian indirect inference
using a parametric auxiliary model. Statistical Science 30(1), 72–95.
Estoup, A., E. Lombaert, J.-M. Marin, T. Guillemaud, P. Pudlo, C. P. Robert,
and J.-M. Cornuet (2012). Estimation of demo-genetic model probabilities
with approximate Bayesian computation using linear discriminant analysis
on summary statistics. Molecular Ecology Resources 12(5), 846–855.
Fasiolo, M., N. Pya, and S. N. Wood (2016). A comparison of inferential meth-
ods for highly nonlinear state space models in ecology and epidemiology.
Statistical Science 31(1), 96–118.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic ABC. Journal of the
Royal Statistical Society: Series B 74, 419–474.
Filippi, S., C. P. Barnes, and M. P. H. Stumpf (2012). Contribution to the
discussion of Fearnhead and Prangle (2012). Journal of the Royal Statistical
Society: Series B 74, 459–460.
Fu, Y.-X. and W.-H. Li (1997). Estimating the age of the common ancestor
of a sample of DNA sequences. Molecular Biology and Evolution 14(2),
195–199.
Fulcher, B. D., M. A. Little, and N. S. Jones (2013). Highly comparative time-
series analysis: The empirical structure of time series and their methods.
Journal of the Royal Society Interface 10(83), 0048.
Girolami, M. and J. Cornebise (2012). Contribution to the discussion of Fearn-
head and Prangle (2012). Journal of the Royal Statistical Society: Series
B 74, 460–461.
Gleim, A. and C. Pigorsch (2013). Approximate Bayesian computation with
indirect summary statistics. Technical report, University of Bonn, Bonn,
Germany.
Gourieroux, C., A. Monfort, and E. Renault (1993). Indirect inference. Journal
of Applied Econometrics 8(S1), S85–S118.

150
Handbook of Approximate Bayesian Computation
Grelaud, A., C. P. Robert, J.-M. Marin, F. Rodolphe, and J. F. Taly (2009).
ABC likelihood-free methods for model choice in Gibbs random ﬁelds.
Bayesian Analysis 4(2), 317–336.
Gutmann, M. U., R. Dutta, S. Kaski, and J. Corander. (2018). Likelihood-free
inference via classiﬁcation. Statistics and Computing, 28(2), 411–425.
Hastie, T., R. Tibshirani, and J. Friedman (2009). The Elements of Statistical
Learning. Springer.
Heggland, K. and A. Frigessi (2004). Estimating functions in indirect infer-
ence. Journal of the Royal Statistical Society: Series B 66(2), 447–462.
Jasra, A. (2015). Approximate Bayesian computation for a class of time series
models. International Statistical Review 83, 405–435.
Joyce, P. and P. Marjoram (2008). Approximately suﬃcient statistics and
Bayesian computation. Statistical Applications in Genetics and Molecular
Biology 7. Article 26.
Li, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of
the American Statistical Association 86(414), 316–327.
Mardia, K. V., J. T. Kent, and J. M. Bibby (1979). Multivariate Analysis.
Academic Press: London, UK.
Marin, J.-M., N. S. Pillai, C. P. Robert, and J. Rousseau (2014). Relevant
statistics for Bayesian model choice. Journal of the Royal Statistical Society:
Series B 76(5), 833–859.
Martin, G. M., B. P. M. McCabe, W. Maneesoonthorn, and C. P. Robert
(2014). Approximate Bayesian computation in state space models. arXiv
preprint arXiv:1409.8363.
Nunes, M. A. and D. J. Balding (2010). On optimal selection of summary
statistics for approximate Bayesian computation. Statistical Applications in
Genetics and Molecular Biology 9(1). Article 34.
Park, M., W. Jitkrittum, and D. Sejdinovic (2016). K2-ABC: Approximate
Bayesian computation with kernel embeddings. In Artiﬁcial Intelligence and
Statistics, 398–407.
Prangle, D. (2011). Summary statistics and sequential methods for approxi-
mate Bayesian computation. Ph.D. thesis, Lancaster University, Lancaster,
UK.
Prangle, D., P. Fearnhead, M. P. Cox, P. J. Biggs, and N. P. French (2014).
Semi-automatic selection of summary statistics for ABC model choice. Sta-
tistical Applications in Genetics and Molecular Biology 13, 67–82.

Summary Statistics
151
Pritchard, J. K., M. T. Seielstad, A. Perez-Lezaun, and M. W. Feldman (1999).
Population growth of human Y chromosomes: A study of Y chromosome
microsatellites. Molecular Biology and Evolution 16(12), 1791–1798.
Pudlo, P., J. M. Marin, A. Estoup, J. M. Cornuet, M. Gautier, and C. P.
Robert (2015). Reliable ABC model choice via random forests. Bioinfor-
matics 32(6), 859–866.
Ratmann, O., C. Andrieu, C. Wiuf, and S. Richardson (2009). Model criti-
cism based on likelihood-free inference, with an application to protein net-
work evolution. Proceedings of the National Academy of Sciences 106(26),
10576–10581.
Ratmann, O., A. Camacho, A. Meijer, and G. Donker (2013). Statistical mod-
elling of summary values leads to accurate approximate Bayesian computa-
tions. arXiv preprint arXiv:1305.4283.
Ratmann, O., O. Jorgensen, T. Hinkley, M. Stumpf, S. Richardson, and
C. Wiuf (2007). Using likelihood-free inference to compare evolutionary
dynamics of the protein networks of H. pylori and P. falciparum. PLoS
Computational Biology 3, 2266–2278.
Robert, C. P. (2012). Contribution to the discussion of Fearnhead and Prangle
(2012). Journal of the Royal Statistical Society: Series B 74, 447–448.
Robert, C. P., J. M. Cornuet, J.-M. Marin, and N. Pillai (2011). Lack of
conﬁdence in approximate Bayesian computation model choice. Proceedings
of the National Academy of Sciences 108(37), 15112–15117.
Ruli, E., N. Sartori, and L. Ventura (2014). Approximate Bayesian computa-
tion with proper scoring rules. In Proceedings of the 47th Scientiﬁc Meeting
of the Italian Scientiﬁc Society, Cagliari, Italy.
Ruli, E., N. Sartori, and L. Ventura (2016). Approximate Bayesian compu-
tation with composite score functions. Statistics and Computing (online
preview) 26(3), 679–692.
Sedki, M. A. and P. Pudlo (2012). Contribution to the discussion of Fearnhead
and Prangle (2012). Journal of the Royal Statistical Society: Series B 74,
466–467.
Singh, H., N. Misra, V. Hnizdo, A. Fedorowicz, and E. Demchuk (2003). Near-
est neighbor estimates of entropy. American Journal of Mathematical and
Management Sciences 23, 301–321.
Stocks, M., M. Siol, M. Lascoux, and S. D. Mita (2014). Amount of informa-
tion needed for model choice in approximate Bayesian computation. PLoS
One 9(6), e99581.

152
Handbook of Approximate Bayesian Computation
Stoehr, J., P. Pudlo, and L. Cucala (2014). Adaptive ABC model choice and
geometric summary statistics for hidden Gibbs random ﬁelds. Statistics and
Computing 25(1), 129–141.
Varin, C., N. M. Reid, and D. Firth (2011). An overview of composite likeli-
hood methods. Statistica Sinica 21(1), 5–42.
Wegmann, D., C. Leuenberger, and L. Excoﬃer (2009). Eﬃcient approximate
Bayesian computation coupled with Markov chain Monte Carlo without
likelihood. Genetics 182(4), 1207–1218.
Wilson, D. J., E. Gabriel, A. J. H. Leatherbarrow, J. Cheesbrough, S. Gee,
E. Bolton, A. Fox, C. A. Hart, P. J. Diggle, and P. Fearnhead (2009).
Rapid evolution and the importance of recombination to the gastroenteric
pathogen Campylobacter jejuni. Molecular Biology and Evolution 26(2),
385–397.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466(7310), 1102–1104.
Yıldırım, S., S. Singh, T. Dean, and A. Jasra (2015). Parameter estimation in
hidden Markov models with intractable likelihoods using sequential Monte
Carlo. Journal of Computational and Graphical Statistics (online preview)
24(3), 846–865.

6
Likelihood-Free Model Choice
Jean-Michel Marin, Pierre Pudlo, Arnaud Estoup,
and Christian Robert
CONTENTS
6.1
Introduction ......................................................
153
6.2
Simulate Only Simulate ..........................................
155
6.3
The Curse of Insuﬃciency .......................................
157
6.3.1
Some counter-examples ..................................
159
6.3.2
Still some theoretical guarantees ........................
160
6.4
Selecting the Maximum a Posteriori Model via Machine
Learning .........................................................
162
6.4.1
Reconsidering the posterior probability estimation .....
163
6.4.2
Random forests construction ............................
164
6.4.3
Approximating the posterior probability of the
maximum a posteriori ..................................
165
6.5
A First Toy Example
............................................
166
6.6
Human Population Genetics Example ...........................
170
6.7
Conclusion ........................................................
173
References
...............................................................
174
6.1
Introduction
As it is now hopefully clear from earlier chapters in this book, there exists
several ways to set ABC methods ﬁrmly within the Bayesian framework. The
method has now gone a very long way from the ‘trick’ of the mid-1990s [1,2],
where the tolerance acceptance condition:
d(y, yobs) ≤ϵ,
153

154
Handbook of Approximate Bayesian Computation
was a crude practical answer to the impossibility to wait for the event
d(y, yobs) = 0 associated with exact simulations from the posterior distri-
bution [3]. Not only do we now enjoy theoretical convergence guarantees [4–6]
as the computing power grows to inﬁnity, but we also beneﬁt from new results
that set actual ABC implementations, with their ﬁnite computing power and
strictly positive tolerances, within the range of other types of inference [7–9].
ABC now stands as an inference method that is justiﬁable on its own ground.
This approach may be the only solution available in complex settings, such as
those originally tackled in population genetics [1,2], unless one engages into
more perilous approximations. The conclusion of this evolution towards main-
stream Bayesian inference is quite comforting about the role ABC can play in
future computational developments, but this trend is far from delivering the
method a blank conﬁdence check, in that some implementations of it will alas
fail to achieve consistent inference.
Model choice is actually a fundamental illustration of how much ABC can
err away from providing a proper inference when suﬃcient care is not prop-
erly taken. This issue is even more relevant when one considers that ABC is
used a lot – at least in population genetics – for the comparison and, hence,
the validation of scenarios that are constructed based on scientiﬁc hypothe-
ses. The more obvious diﬃculty in ABC model choice is indeed conceptual
rather than computational, in that the choice of an inadequate vector of sum-
mary statistics may produce an inconsistent inference [10] about the model
behind the data. Such an inconsistency cannot be overcome with more pow-
erful computing tools. Existing solutions avoiding the selection process within
a pool of summary statistics are limited to speciﬁc problems and diﬃcult to
calibrate.
Past criticisms of ABC from the outside have been most virulent about
this aspect, even though not always pertinent (see, e.g. [11,12] for an extreme
example). It is therefore paramount that the inference produced by an ABC
model choice procedure be validated on the most general possible basis for
the method to become universally accepted. As we discuss in this chapter,
reﬂecting our evolving perspective on the matter, there are two issues with
the validation of ABC model choice: (1) is it not easy to select a good set of
summary statistics and (2) even selecting a collection of summary statistics
that lead to a convergent Bayes factor may produce a poor approximation at
the practical level.
As a warning, we note here that this chapter does not provide a com-
prehensive survey of the literature on ABC model choice, neither about the
foundations (see [13,14]) and more recent proposals (see [15–17]), nor on the
wide range of applications of the ABC model choice methodology to speciﬁc
problems as in, for example, [18,19].
After introducing standard ABC model choice techniques, we discuss the
curse of insuﬃciency. Then, we present the ABC random forest strategy for
model choice and consider ﬁrst a toy example and, at the end, a human pop-
ulation genetics example.

Likelihood-Free Model Choice
155
6.2
Simulate Only Simulate
The implementation of ABC model choice should not deviate from the original
principle at the core of ABC, in that it proceeds by treating the unknown
model index M as an extra parameter with an associated prior, in accordance
with standard Bayesian analysis. An algorithmic representation associated
with the choice of a summary statistic S(·) is thus as follows:
Algorithm 6.1: Standard ABC Model Choice
for i = 1 to N do
Generate M from the prior π(M)
Generate θ from the prior πM(θ)
Generate y from the model fM(y|θ)
Set M(i) = M, θ(i) = θ and s(i) = S(y)
end for
return
the values M(i)
associated with the k smallest distances
d

s(i), S(yobs)

.
In this presentation of the algorithm, the calibration of the tolerance ε
for ABC model choice is expressed as a k-nearest neighbours (k-nn) step, fol-
lowing the validation of ABC in this format by [6], and the observation that
the tolerance level is chosen this way in practice. Indeed, this standard strat-
egy ensures a given number of accepted simulations is produced. While the
k-nn method can be used towards classiﬁcation and, hence, model choice,
we will take advantage of diﬀerent machine learning tools in Section 6.4.
In general, the accuracy of a k-nn method heavily depends on the value of
k, which must be calibrated, as illustrated in [20]. Indeed, while the primary
justiﬁcation of ABC methods is based on the ideal case when ϵ ≈0, hence,
k should be taken ‘as small as possible’, more advanced theoretical analyses
of its non-parametric convergence properties led to conclude that ϵ had to be
chosen away from zero for a given sample size [4–6]. Rather than resorting to
non-parametric approaches to the choice of k, which are based on asymptotic
arguments, [20] rely on an empirical calibration of k using the whole simulated
sample known as the reference table to derive the error rate as a function of k.
Algorithm 6.1 thus returns a sample of model indices that serves as an
approximate sample from the posterior distribution π(M|yobs) and provides
an estimated version via the observed frequencies. In fact, the posterior prob-
abilities can be written as the following conditional expectations:
P

M = m
S(Y) = s

= E

1{M=m}
S(Y) = s

.
Computing these conditional expectations based on independent and identi-
cally distributed (iid) draws from the distribution of (M, S(Y)) can be in-
terpreted as a regression problem in which the response is the indicator of

156
Handbook of Approximate Bayesian Computation
whether or not the simulation comes from model m and the covariates are
the summary statistics. The iid draws constitute the reference table, which
also is the training database for machine learning methods. The process used
in the earlier ABC Algorithm 6.1 is a k-nn method, if one approximates the
posterior by the frequency of m among the k nearest simulations to s. The
proposals of [13] and [21] for ABC model choice are exactly in that vein.
Other methods can be implemented to better estimate P

M = m
S(Y) = s

from the reference table, the training database of the regression method. For
instance, Nadaraya-Watson estimators are weighted averages of the responses,
where weights are non-negative decreasing functions (or kernels) of the dis-
tance d(s(i), s). The regression method commonly used (instead of k-nn) is a
local regression method, with a multi-nomial link, as proposed by [22] or
by [19]: local regression procedures ﬁt a linear model on simulated pairs
(M(i), s(i)) in a neighbourhood of s. The multi-nomial link ensures that the
vector of probabilities has entries between 0 and 1 and sums to 1. However,
local regression can prove computationally expensive, if not intractable, when
the dimension of the covariate increases. Therefore, [23] proposed a dimen-
sion reduction technique based on linear discriminant analysis (an exploratory
data analysis technique that projects the observation cloud along axes that
maximise the discrepancies between groups, see [24]), which produces to a
summary statistic of dimension M −1.
Algorithm 6.2: Local Logistic Regression ABC Model Choice
Generate N samples

M(i), s(i)
as in Algorithm 6.1
Compute weights ωi = Kh(s(i) −S(yobs)), where K is a kernel density and
h is its bandwidth estimated from the sample

s(i)
Estimate the probabilities P

M = m
s

by a logistic link based on the
covariate s from the weighted data

M(i), s(i), ωi

Unfortunately, all regression procedures given so far suﬀer from a curse of
dimensionality: they are sensitive to the number of covariates, for example, the
dimension of the vector of summary statistics. Moreover, as detailed in the fol-
lowing sections, any improvements in the regression method do not change the
fact that all these methods aim at approximating P

M = m
S(Y) = s

as a
function of s and use this function at s = sobs, while caution and cross-checking
might be necessary to validate P

M = m
S(Y) = sobs
as an approximation
of P

M = m
Y = yobs
.
A related approach worth mentioning here is the expectation propagation
ABC (EP-ABC) algorithm of [17], which also produces an approximation of
the evidence associated with each model under comparison. Without getting
into details, the expectation-propagation approach of [25,26] approximates the
posterior distribution by a member of an exponential family, using an itera-
tive and fast moment-matching process that takes only a component of the

Likelihood-Free Model Choice
157
likelihood product at a time. When the likelihood function is unavailable, [17]
propose to instead rely on empirical moments based on simulations of those
fractions of the data. The algorithm includes, as a side product, an estimate
of the evidence associated with the model and the data, hence, can be ex-
ploited for model selection and posterior probability approximation. On the
positive side, the EP-ABC is much faster than a standard ABC scheme, does
not always resort to summary statistics, or at least to global statistics, and is
appropriate for ‘big data’ settings where the whole data cannot be explored at
once. On the negative side, this approach has the same degree of validation as
variational Bayes methods [27], which means converging to a proxy posterior
that is at best optimally close to the genuine posterior within a certain class,
requires a meaningful decomposition of the likelihood into blocks which can
be simulated, calls for the determination of several tolerance levels, is criti-
cally dependent on calibration choices, has no self-control safety mechanism,
and requires identiﬁability of the models’ underlying parameters. Hence, while
EP-ABC can be considered for conducting model selection, there is no theo-
retical guarantee that it provides a converging approximation of the evidence,
while the implementation on realistic models in population genetics seems out
of reach.
6.3
The Curse of Insuﬃciency
The paper [10] issued a warning that ABC approximations to posterior proba-
bilities cannot always be trusted in the double sense that (1) they stand away
from the genuine posterior probabilities (imprecision), and (2) they may even
fail to converge to a Dirac distribution on the true model as the size of the
observed dataset grows to inﬁnity (inconsistency). Approximating posterior
probabilities via an ABC algorithm means using the frequencies of accep-
tances of simulations from each of those models. We assumed in Algorithm
6.1 the use of a common summary statistic (vector) to deﬁne the distance
to the observations, as otherwise the comparison between models would not
make sense. This point may sound anti-climactic since the same feature occurs
for point estimation, where the ABC estimator is an estimate of E[θ|S(yobs)].
Indeed, all ABC approximations rely on the posterior distributions knowing
those summary statistics, rather than knowing the whole dataset. When con-
ducting point estimation with insuﬃcient statistics, the information content is
necessarily degraded. The posterior distribution is then diﬀerent from the true
posterior, but, at least, gathering more observations brings more information
about the parameter (and convergence when the number of observations goes
to inﬁnity), unless one uses only ancillary statistics. However, while this infor-
mation impoverishment only has consequences in terms of the precision of the
inference for most inferential purposes, it induces a dramatic arbitrariness in

158
Handbook of Approximate Bayesian Computation
the construction of the Bayes factor. To illustrate this arbitrariness, consider
the case of starting from a statistic S(x) suﬃcient for both models. Then,
by the factorisation theorem, the true likelihoods factorise as:
f1(x|θ) = g1(x)π1(S(x)|θ) and f2(x|θ) = g2(x)π2(S(x)|θ),
resulting in a true Bayes factor equal to:
B12(x) = g1(x)
g2(x) BS
12(x),
(6.1)
where the last term, indexed by the summary statistic S, is the limiting (or
Monte Carlo error-free) version of the ABC Bayes factor. In the more usual
case where the user cannot resort to a suﬃcient statistic, the ABC Bayes fac-
tor may diverge one way or another as the number of observations increases.
A notable exception is the case of Gibbs random ﬁelds where [13] have shown
how to derive inter-model suﬃcient statistics, beyond the raw sample. This
is related to the less pessimistic paper of [28], also concerned with the lim-
iting behaviour for the ratio (6.1). Indeed, these authors reach the opposite
conclusion from ours, namely, that the problem can be solved by a suﬃciency
argument. Their point is that, when comparing models within exponential
families (which is the natural realm for suﬃcient statistics), it is always pos-
sible to build an encompassing model with a suﬃcient statistic that remains
suﬃcient across models.
However, apart from examples where a tractable suﬃcient summary statis-
tic is identiﬁed, one cannot easily compute a suﬃcient summary statistic for
model choice, and this results in a loss of information, when compared with
the exact inferential approach, hence, a wider discrepancy between the exact
Bayes factor and the quantity produced by an ABC approximation. When
realising this conceptual diﬃculty, [10] felt it was their duty to warn the com-
munity about the dangers of this approximation, especially when considering
the rapidly increasing number of applications using ABC for conducting model
choice or hypothesis testing. Another argument in favour of this warning is
that it is often diﬃcult in practice to design a summary statistic that is infor-
mative about the model.
Let us signal here that a summary selection approach purposely geared
towards model selection can be found in [15]. Let us stress in, and for,
this section that the said method similarly suﬀers from the earlier curse
of dimensionality. Indeed, the approach therein is based on an estimate of
Fisher’s information contained in the summary statistics about the pair (M, θ)
and the correlated search for a subset of those summary statistics that is
(nearly) suﬃcient. As explained in the paper, this approach implies that the
resulting summary statistics are also suﬃcient for parameter estimation within
each model, which obviously induces a dimension inﬂation in the dimension
of the resulting statistic, in opposition to approaches focussing solely on the
selection of summary statistics for model choice, like [16] and [29].

Likelihood-Free Model Choice
159
We must also stress that, from a model choice perspective, the vector
made of the (exact!) posterior probabilities of the diﬀerent models obviously
constitutes a Bayesian suﬃcient statistics of dimension M −1, but this vec-
tor is intractable precisely in cases where the user has to resort to ABC
approximations. Nevertheless, this remark is exploited in [16] in a two-stage
ABC algorithm. The second stage of the algorithm is ABC model choice
with summary statistics equal to approximation of the posterior probabilities.
Those approximations are computed as ABC solutions at the ﬁrst stage of
the algorithm. Despite the conceptual attractiveness of this approach, which
relies on a genuine suﬃciency result, the approximation of the posterior prob-
abilities given by the ﬁrst stage of the algorithm directly rely on the choice
of a particular set of summary statistics, which brings us back to the original
issue of trusting an ABC approximation of a posterior probability.
There therefore is a strict loss of information in using ABC model choice,
due to the call both to insuﬃcient statistics and to non-zero tolerances (or a
imperfect recovery of the posterior probabilities with a regression procedure).
6.3.1
Some counter-examples
Besides a toy example opposing Poisson and geometric distributions to point
out the potential irrelevance of the Bayes factor based on poor statistics,
[10] goes over a realistic population genetic illustration, where two evolution
scenarios involving three populations are compared, two of those populations
having diverged 100 generations ago and the third one resulting from a recent
admixture between the ﬁrst two populations (scenario 1) or simply diverging
from population 1 (scenario 2) at the same date of ﬁve generations in the
past. In scenario 1, the admixture rate is 0.7 from population 1. Simulated
datasets (100) of the same size as in experiment 1 (15 diploid individuals per
population, 5 independent micro-satellite loci) were generated assuming an
eﬀective population size of 1000 and a mutation rate of 0.0005. In this ex-
periment, there are six parameters (provided with the corresponding priors):
the admixture rate (U[0.1, 0.9]), three eﬀective population sizes (U[200, 2000]),
the time of admixture/second divergence (U[1, 10]), and the date of the ﬁrst
divergence (U[50, 500]). While costly in computing time, the posterior proba-
bility of a scenario can be estimated by importance sampling, based on 1000
parameter values and 1000 trees per parameter value, thanks to the modules
of [30]. The ABC approximation is produced by Do It Yourself Approximate
Bayesian Computation (DIYABC) [31], based on a reference sample of two
million parameters and 24 summary statistics. The result of this experiment
is shown on Figure 6.1, with a clear divergence in the numerical values despite
stability in both approximations. Taking the importance sampling approxima-
tion as the reference value, the error rates in using the ABC approximation to
choose between scenarios 1 and 2 are 14.5% and 12.5% (under scenarios 1 and
2), respectively. Although a simpler experiment with a single parameter and
the same 24 summary statistics shows a reasonable agreement between both

160
Handbook of Approximate Bayesian Computation
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Importance sampling estimates of P(M = 1|y)
ABC estimates of P(M = 1|y)
FIGURE 6.1
Comparison of importance sampling (ﬁrst axis) and ABC (second axis) esti-
mates of the posterior probability of scenario 1 in the ﬁrst population genetic
experiment, using 24 summary statistics. (From Robert, C.P. et al., Proc. Natl
Acad. Sci., 108, 15112–15117, 2011.)
approximations, this result comes as an additional support to our warning
about a blind use of ABC for model selection. The corresponding simulation
experiment was quite intense, as, with 50 markers and 100 individuals, the
product likelihood suﬀers from an enormous variability that 100,000 particles
and 100 trees per locus have trouble addressing despite a huge computing
cost.
An example is provided in the introduction of the paper [32], sequel to [10].
The setting is one of a comparison between a normal y ∼N(θ1, 1) model and
a double exponential y ∼L(θ2, 1/
√
2) model.1 The summary statistics used in
the corresponding ABC algorithm are the sample mean, the sample median,
and the sample variance. Figure 6.2 exhibits the absence of discrimination
between both models, since the posterior probability of the normal model
converges to a central value around 0.5–0.6 when the sample size grows, irrel-
evant of the true model behind the simulated datasets.
6.3.2
Still some theoretical guarantees
Our answer to the (well-received) aforementioned warning is provided in
[32], which deals with the evaluation of summary statistics for Bayesian
model choice. The main result states that, under some Bayesian asymptotic
1The double exponential distribution is also called the Laplace distribution, hence, the
notation L(θ2, 1/
√
2), with mean θ2 and variance one.

Likelihood-Free Model Choice
161
Gauss
(a)
(b)
(c)
Laplace
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
n = 10
Gauss
Laplace
n = 100
Gauss
Laplace
n = 1000
FIGURE 6.2
Comparison of the range of the ABC posterior probability that data are from
a normal model with unknown mean θ when the data are made of n = 10, 100,
and 1000 observations (a–c respectively) either from a Gaussian (lighter) or
Laplace distribution (darker) and when the ABC summary statistic is made of
the empirical mean, median, and variance. The ABC algorithm generates 104
simulations (5,000 for each model) from the prior θ ∼N(0, 4) and selects the
tolerance ϵ as the 1% distance quantile over those simulations. (From Marin,
J.-M. et al., J. R. Stat. Soc. B, 76, 833–859, 2014.)
assumptions, ABC model selection only depends on the behaviour of the mean
of the summary statistic under both models. The paper establishes a theoreti-
cal framework that leads to demonstrate consistency of the ABC Bayes factor
under the constraint that the ranges of the expected value of the summary
statistic under both models do not intersect. A negative result is also given
in [32], which mainly states that, whatever the observed dataset, the ABC
Bayes factor selects the model having the smallest eﬀective dimension when
the assumptions do not hold.
The simulations associated with the paper were straightforward in that (1)
the setup compares normal and Laplace distributions with diﬀerent summary
statistics (including the median absolute deviation), (2) the theoretical results
told what to look for, and (3) they did very clearly exhibit the consistency
and inconsistency of the Bayes factor/posterior probability predicted by the
theory. Both boxplots shown here on Figures 6.2 and 6.3 show this agreement:
when using (empirical) mean, median, and variance to compare normal and
Laplace models, the posterior probabilities do not select the true model, but
instead aggregate near a ﬁxed value. When using instead the median absolute
deviation as summary statistic, the posterior probabilities concentrate near
one or zero depending on whether or not the normal model is the true model.
It may be objected to such necessary and suﬃcient conditions that Bayes
factors simply are inappropriate for conducting model choice, thus making
the whole derivation irrelevant. This foundational perspective is an arguable
viewpoint [33]. However, it can be countered within the Bayesian paradygm by
the fact that Bayes factors and posterior probabilities are consistent quantities

162
Handbook of Approximate Bayesian Computation
Gauss
(a)
(b)
(c)
Laplace
0.0
0.2
0.4
0.6
0.8
1.0
n = 10
Gauss
Laplace
0.0
0.2
0.4
0.6
0.8
1.0
n = 100
Gauss
Laplace
0.0
0.2
0.4
0.6
0.8
1.0
n = 1000
FIGURE 6.3
Same representation as Figure 6.2 when using the median absolute deviation
of the sample as its sole summary statistic. (From Marin, J.-M. et al., J. R.
Stat. Soc. B, 76, 833–859, 2014.)
that are used in conjunction with ABC in dozens of genetic papers. Further
arguments are provided in the various replies to both of Templeton’s radical
criticisms [11,12]. That more empirical and model-based assessments also are
available is quite correct, as demonstrated in the multi-criterion approach
of [34]. This is simply another approach, not followed by most geneticists so far.
A concluding remark about [32] is that, while the main bulk of the paper
is theoretical, it does bring an answer that the mean ranges of the summary
statistic under each model must not intersect if they are to be used for ABC
model choice. In addition, while the theoretical assumptions therein are not
of the utmost relevance for statistical practice, the paper includes recommen-
dations on how to conduct a χ2 test on the diﬀerence of the means of a given
summary statistics under both models towards assessing whether or not this
summary is acceptable.
6.4
Selecting the Maximum a Posteriori Model via
Machine Learning
The earlier sections provide enough arguments to feel less than conﬁdent in
the outcome of a standard ABC model choice Algorithm 6.1, at least in the
numerical approximation of the probabilities P(M = m|S(Y) = sobs) and in
their connection with the genuine posterior probabilities P(M = m|Y = yobs).
There are indeed three levels of approximation errors in such quantities, one
due to the Monte Carlo variability, one due to the non-zero ABC tolerance
or, more generally, to the error committed by the regression procedure when
estimating the conditional expected value, and one due to the curse of in-
suﬃciency. While the derivation of a satisfying approximation of the genuine
P(M = m|Y = yobs) seems beyond our reach, we present in the following

Likelihood-Free Model Choice
163
a novel approach to both construct the most likely model and approximate
P(M = m|S(Y) = sobs) for the most likely model, based on the machine
learning tool of random forests.
6.4.1
Reconsidering the posterior probability estimation
Somewhat paradoxically, since the ABC approximation to posterior proba-
bilities of a collection of models is delicate, [20] support inverting the order
of selection of the a posteriori most probable model and of approximation of
its posterior probability, using the alternative tool of random forests for both
goals. The reason for this shift in order is that the rate of convergence of local
regression procedure, such as k-nn or the local regression with multi-nomial
link, heavily depends on the dimension of the covariates (here the dimension
of the summary statistic). Thus, since the primary goal of ABC model choice
is to select the most appropriate model, both [20] and [35] argue that one does
not need to correctly approximate the probability:
P(M = m|S(Y) ≈sobs),
when looking for the most probable model in the sense of:
P(M = m|Y = yobs),
probability. Stoehr et al. [35] stresses that selecting the most adequate model
for the data at hand as the maximum a posteriori (MAP) model index is a
classiﬁcation issue, which proves to be a signiﬁcantly easier inference problem
than estimating a regression function [24,36]. This is the reason why [35] adapt
the earlier Algorithm 6.1 by resorting to a k-nn classiﬁcation procedure, which
sums up as returning the most frequent (or majority rule) model index among
the k simulations nearest to the observed dataset, nearest in the subspace
of the summary statistics. Indeed, generic classiﬁcation aims at forecasting a
variable M taking a ﬁnite number of values, {1, . . . , M}, based on a vector
of covariates S = (S1, . . . , Sd). The Bayesian approach to classiﬁcation stands
in using a training database (mi, si) made of independent replicates of the
pair (M, S(Y)) that are simulated from the prior predictive distribution. The
connection with ABC model choice is that the latter predicts a model index,
M, from the summary statistic S(Y). Simulations in the ABC reference table
can thus be envisioned as creating a learning database from the prior predictive
that trains the classiﬁer.
Pudlo et al. [20] widen the paradigm shift undertaken in [35], as they use a
machine learning approach to the selection of the most adequate model for the
data at hand and exploit this tool to derive an approximation of the posterior
probability of the selected model. The classiﬁcation procedure chosen by [20] is
the technique of random forests (RFs) [37], which constitute a trustworthy and
seasoned machine learning tool, well adapted to complex settings like those
found in ABC settings. The approach further requires no primary selection

164
Handbook of Approximate Bayesian Computation
of a small subset of summary statistics, which allows for an automatic input
of summaries from various sources, including softwares like DIYABC [29].
At a ﬁrst stage, an RF is constructed from the reference table to predict
the model index and applied to the data at hand to return a MAP estimate.
At a second stage, an additional RF is constructed for explaining the selection
error of the MAP estimate, based on the same reference table. When applied
to the observed data, this secondary random forest produces an estimate of
the posterior probability of the model selected by the primary RF, as detailed
in the following [20].
6.4.2
Random forests construction
An RF aggregates a large number of classiﬁcation trees by adding for each
tree a randomisation step to the classiﬁcation and regression trees (CARTs)
algorithm [38]. Let us recall that this algorithm produces a binary classiﬁ-
cation tree that partitions the covariate space towards a prediction of the
model index. In this tree, each binary node is partitioning the observations
via a rule of the form Sj < tj, where Sj is one of the summary statistics
and tj is chosen towards the minimisation of an heterogeneity index. For in-
stance, [20] use the Gini criterion [29]. A CART is built based on a learning
table, and it is then applied to the observed summary statistic sobs, pre-
dicting the model index by following a path that applies these binary rules
starting from the tree root and returning the label of the tip at the end of
the path.
The randomisation part in RF produces a large number of distinct CARTs
by (1) using for each tree a bootstrapped version of the learning table on a
bootstrap sub-sample of size Nboot and (2) selecting the summary statistics at
each node from a random subset of the available summaries. The calibration
of a RF thus involves three quantities:
– B, the number of trees in the forest.
– ntry, the number of covariates randomly sampled at each node by the
randomised CART.
– Nboot, the size of the bootstraped sub-sample.
The so-called out-of-bag error associated with an RF is the average number
of times a point from the learning table is wrongly allocated, when averaged
over trees that exclude this point from the bootstrap sample.
The way [20] build a random forest classiﬁer given a collection of statistical
models is to start from an ABC reference table including a set of simulation
records made of model indices, parameter values, and summary statistics for
the associated simulated data. This table then serves as a training database
for a random forest that forecasts a model index based on the summary
statistics.

Likelihood-Free Model Choice
165
Algorithm 6.3: Random Forest ABC Model Choice
Generate N samples

M(i), s(i)
as in Algorithm 6.1 (the reference table)
Construct Ntree randomised CART which predicts the model indices using
the summary statistics
for b = 1 to Ntree do
draw a bootstrap sub-sample of size Nboot from the reference table
grow a randomised CART Tb
end for
Determine the predicted indices for sobs and the trees {Tb; b = 1, . . . , Ntree}
Assign sobs to an indice (a model) according to a majority vote among the
predicted indices.
6.4.3
Approximating
the
posterior
probability
of
the
maximum a posteriori
The posterior probability of a model is the natural Bayesian uncertainty quan-
tiﬁcation [39], since it is the complement of the posterior loss associated with
a 0–1 loss 1M̸= ˆ
M(sobs), where ˆM(sobs) is the model selection procedure, for
example, the RF outcome described in the previous section. However, for
reasons described earlier, we are unwilling to trust the standard ABC approx-
imation to the posterior probability as reported in Algorithm 6.1. An initial
proposal in [35] is to instead rely on the conditional error rate induced by the
k-nn classiﬁer knowing S(Y) = sobs, namely:
P

M ̸= 
M(sobs)
sobs
,
where 
M denotes the k-nn classiﬁer trained on ABC simulations. The afore-
mentioned conditional expected value of 1{M̸=
M(sobs)} is approximated in [35],
with a Nadaraya-Watson estimator on a new set of simulations, where the au-
thors compare the model index m(i), which calibrates the simulation of the
pseudo-data y(i), and the model index 
M(s(i)), predicted by the k-nn approach
trained on a ﬁrst database of simulations. However, this ﬁrst proposal has the
major drawback of relying on non-parametric regression, which deteriorates
when the dimension of the summary statistic increases. This local error also
allows for the selection of summary statistics adapted to sobs, but the proce-
dure of [35] remains constrained by the dimension of the summary statistic,
which typically have to be less than ten.
Furthermore, relying on a large dimensional summary statistic – to bypass,
at least partially, the curse of insuﬃciency – was the main reason for adopting
a classiﬁer such as RFs in [20]. Hence, the authors proposed to estimate the
posterior expectation of 1M̸= ˆ
M(sobs) as a function of the summary statistics,
via another RF construction. Indeed:

166
Handbook of Approximate Bayesian Computation
E[1M̸= ˆ
M(sobs)|sobs] =
k

i=1
P[M = i|sobs] × 1 ˆ
M(sobs)̸=i
= P[M ̸= ˆM(sobs)|sobs]
= 1 −P[M = ˆM(sobs)|sobs] .
The estimation of E[1M̸= ˆ
M(s)|s] proceeds as follows:
– Compute the values of 1M̸= ˆ
M(s) for the trained random forest and all
terms in the reference table.
– Train a second RF regressing 1M̸= ˆ
M(s) on the same set of summary statis-
tics and the same reference table, producing a function ϱ(s) that returns
a machine learning estimate of P[M ̸= ˆM(s)|s].
– Apply this function to the actual observations to produce 1 −ϱ(sobs) as
an estimate of P[M = ˆM(sobs)|sobs].
6.5
A First Toy Example
We consider in this section a simple uni-dimensional setting with three models
where the marginal likelihoods can be computed in closed form.
Under model 1, our dataset is a n-sample from an exponential distribution
with parameter θ (with expectation 1/θ), and the corresponding prior distribu-
tion on θ is an exponential distribution with parameter 1. In this model, given
the sample y = (y1, . . . , yn) with yi > 0, the marginal likelihood is given by:
m1(y) = Γ(n + 1)

1 +
n

i=1
yi
−n−1
.
Under model 2, our dataset is a n-sample from a log-normal distribution with
location parameter θ and dispersion parameter equal to 1 [which implies an
expectation equal to exp(θ + 0.5)]. The prior distribution on θ is a standard
Gaussian distribution. For this model, given the sample y = (y1, . . . , yn) with
yi > 0, the marginal likelihood is given by:
m2(y) = exp
⎡
⎣−
 n

i=1
log(yi)
2
/(2n(n + 1)) −
 n

i=1
log2(yi)
2
/2
+
 n

i=1
log(yi)
2
/(2n) −
n

i=1
log(yi)
⎤
⎦× (2π)−n/2 × (n + 1)−1/2.

Likelihood-Free Model Choice
167
Under model 3, our dataset is a n-sample from a gamma distribution with
parameter (2, θ) (with expectation 2/θ), and the prior distribution on θ is an
exponential distribution with parameter 1. For this model, given the sample
y = (y1, . . . , yn)with yi > 0, the marginal likelihood is given by:
m3(y) = exp
 n

i=1
log(yi)

Γ(2n + 1)
Γ(2)n

1 +
n

i=1
yi
−2n−1
.
We consider three summary statistics:
 n

i=1
yi,
n

i=1
log(yi),
n

i=1
log2(yi)

.
These summary statistics are suﬃcient not only within each model, but also
for the model choice problem [28], and the purpose of this example is not to
evaluate the impact of a loss of suﬃciency.
When running ABC, we set n = 20 for the sample size and generated a
reference table containing 29,000 simulations (9,676 simulations from model 1,
9,650 from model 2, and 9,674 from model 3). We further generated an inde-
pendent test dataset of size 1,000. Then, to calibrate the optimal number of
neighbours in the standard ABC procedure [13,21], we exploited 1,000 inde-
pendent simulations.
For each element of the test dataset, as obvious from the above mi(y)’s, we
can evaluate the exact model posterior probabilities. Figure 6.4 represents the
posterior probability of model 3 for every simulation, ranked by model index.
In addition, Figure 6.5 gives a plot of the ﬁrst two LDA projections of the
test dataset. Both ﬁgures explain why the model choice problem is not easy in
this setting. Indeed, based on the exact posterior probabilities, selecting the
model associated with the highest posterior probability achieves the smallest
prior error rate. Based on the test dataset, we estimate this lower bound as
being around 0.245, for example, close to 25%.
Based on a calibration set of 1,000 simulations, and the earlier reference
table of size 29,000, the optimal number of neighbours that should be used
by the standard ABC model choice procedure, for example, the one that min-
imises the prior error rate, is equal to 20. In this case, the resulting prior error
rate for the test dataset is equal to 0.277.
By comparison, the RF ABC model choice technique of [20] based on
500 trees achieves an error rate of 0.276 on the test dataset. For this example,
adding the two LDA components to the summary statistics does not make a
diﬀerence. This alternative procedure achieves similarly good results in terms
of prior error rate, since 0.276 is relatively closed to the absolute lower bound of
0.245. However, as explained in previous sections and illustrated on Figure 6.6,
the RF estimates of the posterior probabilities are not to be trusted. In short,
a classiﬁcation tool is not necessarily appropriate for regression goals.

168
Handbook of Approximate Bayesian Computation
*
*
*
*
***
*
**
***
*
**
*
*
*
*
*
*
*
*
*
*
*
***
*
*
***
**
*
*****
*
**
*
**
*
*
*
*
*
**
*
*
*
**
******
*
****
***
*
*
*
*
*
*
**
*
**
*
**
*
*
*
**
*
*
**
*
*
****
*
*
*
*
***
*
**
*
***
*
**
*
**
*
**
**
*
*
*
*
***
*
*
**
*
**
*
*
*****
*
**
*
*
**
*
*
*
******
*
*
**
*
***
*
*
*
***
*****
*
**
*
*
*
****
*
*
***
*
*******
**
*
*
**
*
***
*
*
**
*
*
*
*
*
***
*
*
*
***********
*
**
*
*
*
*
*
*
*
*******
*
*
*****
*
******
*
*******
*
***
*
*
*
****
*
*****
*
*
*
***
*
*
*
*
**********
*
*
*****
*
**
*
***
*
****
*
*
*
*
*
*
*
*
**
*
*****
*
*
*
*
*
*
*
*
***
*
**
*
*
*
***
*
*
*
*
*
*
**
*
*
*
*
**
*
*****
*
**
*
*
***
*
*
*
*
**
*
*
*
*
*
***
**
*
*
**
*
**
*
*
*
*
*
*
*
*
**
*
*
*
*
*
**
*
*
*
**
*
*
**
*
**
*
**
*
*****
*
*
**
*
*
*
*
*
**
*
*
*
**
*
*
*
*
*
*
*
*
****
*
**
*
*
*
*
*
**
*
*
**
*
*
*
*
*
*
*
*
*
*
**********
*
*
*
**
*
**
*
*
*
*
*
*
***
*
*
****
*
**
*
*
****
*
*****
*
*
**
*
*
*
*
***
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
****
*
*
*
*
**
*******
*
*
*
*
*
*
*
*
*
*
*
****
*
*
*
*
*
**
*
*
*
*
*
*
*
*
**
**
*
****
*
*
*
****
*
*
******
*
*
**
*
*
*
*
*
***
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
*
**
*
***
*
*
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
**
**
*
**
**
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
***
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
*
*
*
**
*
*
**
**
*
*
*
*
*
**
*
*
*
**
*
**
*
**
*
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
**
***
*
*
*
*
*
*
*
*
*
*
*
*
*
*
**
*
*
*
*
*
**
*
*
*
*
*
*
**
**
*
*
*
*
*
*
****
*
*
*
*
*
*
***
*
*
*
*
*
*
*
*
***
*
*
*
*
**
*
*
**
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
0
200
400
600
800
1000
0.0
0.2
0.4
0.6
0.8
1.0
Index in the test sample
Posterior probability of model 3
FIGURE 6.4
True posterior probability of model 3 for each term from the test sample.
Colour corresponds to the true model index: black for model 1, dark grey for
model 2, and light grey for model 3. The terms in the test sample have been
ordered by model index to improve the representation.
−4
−3
−2
−1
0
1
0
2
4
6
8
10
LD1
LD2
FIGURE 6.5
LDA projection along the ﬁrst two axes of the test dataset, with the same
colour code as in Figure 6.4.

Likelihood-Free Model Choice
169
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability of model 1
RF estimates of posterior probability of model 1
FIGURE 6.6
True posterior probabilities of model 1 against their Random Forest estimates
for the test sample, with the same colour code as in Figure 6.4.
A noteworthy feature of the RF technique is its ability to be robust against
non-discriminant variates. This obviously is of considerable appeal in ABC
model choice since the selection of summary statistics is an unsolved challenge.
To illustrate this point, we added to the original set of three summary statistics
variables that are pure noise, being produced by independent simulations from
standard Gaussian distributions. Table 6.1 shows that the additional error
TABLE 6.1
Evolution of the Prior Error Rate for the RF
ABC Model Choice Procedure as a Function
of the Number of White Noise Variates
Extra Variables
Prior Error Rate
0
0.276
2
0.283
4
0.288
6
0.272
8
0.280
10
0.286
20
0.318
50
0.355
100
0.391
200
0.419
1,000
0.456

170
Handbook of Approximate Bayesian Computation
TABLE 6.2
Evolution of the Prior Error Rate for a Standard ABC
Model Choice as a Function of the Number of White
Noise Variates
Extra Variables
Optimal k
Prior Error Rate
0
20
0.277
2
20
0.368
4
140
0.468
6
200
0.491
8
260
0.492
10
260
0.526
20
260
0.542
50
260
0.548
100
500
0.559
200
500
0.572
1,000
1,000
0.594
due to those irrelevant variates grows much more slowly than for the standard
ABC model choice technique, as shown in Table 6.2. In the latter case, a few
extraneous variates suﬃce to propel the error rate above 50%.
6.6
Human Population Genetics Example
We consider here the massive single nucleotide polymorphism (SNP)
dataset already studied in [20], associated with a Most Recent Com-
mon Ancestor (MRCA) population genetic model corresponding to King-
man’s coalescent that has been at the core of ABC implementations
from their beginning [1]. The dataset corresponds to individuals orig-
inating from four human populations, with 30 individuals per popula-
tion. The freely accessible public 1000 Genome databases +http://www.
1000genomes.org/data has been used to produce this dataset. As detailed
in [20], one of the appeals of using SNP data from the 1000 Genomes Project
[40] is that such data does not suﬀer from any ascertainment bias.
The four human populations in this study included the Yoruba population
(Nigeria) as representative of Africa, the Han Chinese population (China) as
representative of East Asia (encoded CHB), the British population (England
and Scotland) as representative of Europe (encoded GBR), and the popu-
lation of Americans of African ancestry in SW USA (encoded ASW). After
applying some selection criteria described in [20], the dataset includes 51,250

Likelihood-Free Model Choice
171
Scenario 1
Scenario 1
GBR
GBR
CHB
CHB
Single out-of-Africa event/No admixture for ASW
Single out-of-Africa event/No admixture for ASW
YRI
YRI
ASW
ASW
Nbn34
Nbn34
(Warning ! Time is not to scale.)
(Warning ! Time is not to scale.)
Nbn4
Nbn4
Nbn3
Nbn3
Na
Na
N1
N1
N2
N2
N3
N3
N4
N4
t4
t4
t3
t3
t2
t2
t3-d34
t3-d34
t2-d4
t2-d4
t2-d3
t2-d3
t1
t1
0
N34
N34
Scenario 2
GBR
CHB
Single out-of-Africa event/ASW =  admixture
(YRI + GBR)
ASW
YRI
Nbn34
(Warning ! Time is not to scale.)
Nbn4
Nbn3
Na
N1
N2
N3
N4
ra
1-ra
t4
t3
t2
t3-d34
t2-d4
t2-d3
t1
0
N34
FIGURE 6.7
Two scenarios of evolution of four human populations genotyped at 50,000
SNPs. The genotyped populations are YRI = Yoruba (Nigeria, Africa),
CHB = Han (China, East Asia), GBR = British (England and Scotland,
Europe), and ASW = Americans of African ancestry (SW USA).
SNP loci scattered over the 22 autosomes with a median distance between two
consecutive SNPs equal to 7 kb. Among those, 50,000 were randomly chosen
for evaluating the proposed RF ABC model choice method.
In the novel study described here, we only consider two scenarios of evo-
lution. These two models diﬀer by the possibility or impossibility of a re-
cent genetic admixture of Americans of African ancestry in SW USA between
their African forebears and individuals of European origins, as described in
Figure 6.7. Model 2 thus includes a single out-of-Africa colonisation event
giving an ancestral out-of-Africa population with a secondarily split into one
European and one East Asian population lineage and a recent genetic admix-
ture of Americans of African origin with their African ancestors and European
individuals. RF ABC model choice is used to discriminate among both models
and returns error rates. The vector of summary statistics is the entire collec-
tion provided by the DIYABC software for SNP markers [29], made of 112
summary statistics described in the manual of DIYABC.
Model 1 involves 16 parameters, while model 2 has an extra parameter,
the admixture rate ra. All times and durations in the model are expressed
in number of generations. The stable eﬀective populations sizes are expressed
in number of diploid individuals. The prior distributions on the parameters
appearing in one of the two models and used to generate SNP datasets are as
follows:
1. Split or admixture time t1, U[1, 30]
2. Split times (t2, t3, t4), uniform on their support

(t2, t3, t4) ∈[100, 10, 000]⊗3|t2 < t3 < t4


172
Handbook of Approximate Bayesian Computation
3. Admixture rate (proportion of genes with a non-African origin in model 2)
ra ∼∼U[0.05, 0.95]
4. Eﬀective population sizes N1, N2, N3, N3, and N34, U [1,000, 100,000]
5. Bottleneck durations d3, d4, and d34, U[5, 500]
6. Bottleneck eﬀective population sizes Nbn3, Nbn4, and Nbn34, U[5, 500]
7. Ancestral eﬀective population size Na, U[100, 10,000]
For the analyses, we use a reference table containing 19,995 simulations:
10,032 from model 1 and 9,963 from model 2. Figure 6.8 shows the distri-
butions of the ﬁrst LDA projection for both models, as a byproduct of the
simulated reference table. Unsurprisingly, this LDA component has a mas-
sive impact on the RF ABC model choice procedure. When including the
LDA statistic, most trees (473 out of 500) allocate the observed dataset to
model 2. The second random forest to evaluate the local selection error leads a
high conﬁdence level: the estimated posterior probability of model 2 is greater
than 0.999. Figure 6.9 shows contributions for the most relevant statistics
in the forest, stressing once again the primary role of the ﬁrst LDA axis.
Note that using solely this ﬁrst LDA axis increases considerably the prior
error rate.
Density
−5
0
5
10
0.0
0.2
0.4
0.6
0.8
FIGURE 6.8
Distribution of the ﬁrst LDA axis derived from the reference table, in light grey
for model 1 and in dark grey for model 2. The observed dataset is indicated
by a black vertical line.

Likelihood-Free Model Choice
173
AP0_2_1&4
AV1_1_2&3
FM1_1&4
AV1_2_1&4
AM1_1_3&4
AMO_1_2&4
NV1_1&2
NMO_1&2
FMO_1&4
FP0_1&4
FP0_1&2
AMO_3_1&2
AP0_3_1&2
FMO_1&2
AV1_1_2&4
AM1_1_2&4
FV1_1&2
AP0_4_1&2
FM1_1&2
AMO_4_1&2
0
(a)
(b)
500
1000
1500
AP0_2_1&4
NMO_1&2
FM1_1&4
AV1_1_2&3
AM1_1_3&4
AMO_1_2&4
NV1_1&2
FP0_1&4
FP0_1&2
FMO_1&4
AP0_3_1&2
AMO_3_1&2
AV1_1_2&4
AM1_1_2&4
FMO_1&2
FV1_1&2
FM1_1&2
AP0_4_1&2
AMO_4_1&2
LD1
0
500
1000
1500
2000
FIGURE 6.9
Contributions of the most frequent statistics in the RF. The contribution of
a summary statistic is evaluated as the average decrease in node impurity at
all nodes where it is selected, over the trees of the RF when using the 112
summary statistics (a), and when further adding the ﬁrst LDA axis (b).
6.7
Conclusion
This chapter has presented a solution for conducting ABC model choice and
testing that diﬀers from the usual practice in applied ﬁelds like population
genetics, where the use of Algorithm 6.1 remains the norm. This choice is not

174
Handbook of Approximate Bayesian Computation
due to any desire to promote our own work, but proceeds from a genuine belief
that the ﬁgures returned by this algorithm cannot be trusted as approximating
the actual posterior probabilities of the model. This belief is based on our
experience along the years we worked on this problem, as illustrated by the
evolution in our papers on the topic.
To move to a machine-learning tool like random forests somehow represents
a paradigm shift for the ABC community. For one thing, to gather intuition
about the intrinsic nature of this tool and to relate it to ABC schemes is cer-
tainly anything but straightforward. For instance, a natural perception of this
classiﬁcation methodology is to take it as a natural selection tool that could
lead to a reduced subset of signiﬁcant statistics, with the side appeal of provid-
ing a natural distance between two vectors of summary statistics through the
tree discrepancies. However, as we observed through experiments, subsequent
ABC model choice steps based on the selected summaries are detrimental to
the quality of the classiﬁcation once a model is selected by the random forest.
The statistical appeal of a random forest is on the opposite, that it is quite
robust to the inclusion of poorly informative or irrelevant summary statistics
and on the opposite able to catch minute amounts of additional information
produced by such additions.
While the current state-of-the-art remains silent about acceptable approx-
imations of the true posterior probability of a model, in the sense of being
conditional to the raw data, we are nonetheless making progress towards the
production of an approximation conditional on an arbitrary set of summary
statistics, which should oﬀer strong similarities with the above. That this step
can be achieved at no signiﬁcant extra cost is encouraging for the future.
Another important inferential issue pertaining to ABC model choice is to
test a large collection of models. The diﬃculties to learn how to discriminate
between models certainly increase when the number of likelihoods in com-
petition gets larger. Even the most up-to-date machine learning algorithms
will loose their eﬃciency if one keeps constant the number of iid draws from
each model, without mentioning that the time complexity will increase lin-
early with the size of the collection to produce the reference table that trains
the classiﬁer. Thus, this problem remains largely open.
References
[1] S. Tavar´e, D. Balding, R. Griﬃth, and P. Donnelly. Inferring coalescence
times from DNA sequence data. Genetics, 145(26):505–518, 1997.
[2] J. Pritchard, M. Seielstad, A. Perez-Lezaun, and M. Feldman. Population
growth of human Y chromosomes: A study of Y chromosome microsatel-
lites. Molecular Biology and Evolution, 16(12):1791–1798, 1999.

Likelihood-Free Model Choice
175
[3] D. Rubin. Bayesianly justiﬁable and relevant frequency calculations for
the applied statistician. The Annals of Statistics, 12(4):1151–1172, 1984.
[4] M. Blum. Approximate Bayesian computation: A non-parametric per-
spective. Journal of the American Statistical Association, 105(491):
1178–1187, 2010.
[5] P. Fearnhead and D. Prangle. Constructing summary statistics for ap-
proximate Bayesian computation: Semi-automatic approximate Bayesian
computation.
Journal
of
the
Royal
Statistical
Society:
Series
B,
74(3):419–474, 2012.
[6] G. Biau, F. C´erou, and A. Guyader. New insights into approximate
Bayesian computation. Annales de l’Institut Henri Poincar´e, Probabilit´es
et Statistiques, 51(1):376–403, 2015.
[7] S.N. Wood. Statistical inference for noisy nonlinear ecological dynamic
systems. Nature, 466:1102–1104, 2010.
[8] R. Wilkinson. Approximate Bayesian computation (ABC) gives exact
results under the assumption of model error. Statistical Applications in
Genetics and Molecular Biology, 12(2):129–141, 2013.
[9] R. Wilkinson. Accelerating ABC methods using Gaussian processes. In
Proceedings of the 17th International Conference on Artiﬁcial Intelligence
and Statistics (AISTATS), volume 33 of AI & Statistics 2014, pp. 1015–
1023. JMLR: Workshop and Conference Proceedings, 2014.
[10] C.P. Robert, J.-M. Cornuet, J.-M. Marin, and N. Pillai. Lack of conﬁdence
in ABC model choice. Proceedings of the National Academy of Sciences,
108(37):15112–15117, 2011.
[11] A. Templeton. Statistical hypothesis testing in intraspeciﬁc phylogeogra-
phy: Nested clade phylogeographical analysis vs. approximate Bayesian
computation. Molecular Ecology, 18(2):319–331, 2008.
[12] A. Templeton. Coherent and incoherent inference in phylogeography
and human evolution. Proceedings of the National Academy of Sciences,
107(14):6376–6381, 2010.
[13] A. Grelaud, J.-M. Marin, C.P. Robert, F. Rodolphe, and F. Tally.
Likelihood-free methods for model choice in Gibbs random ﬁelds.
Bayesian Analysis, 3(2):427–442, 2009.
[14] T. Toni and M. Stumpf. Simulation-based model selection for dynam-
ical systems in systems and population biology. Bioinformatics, 26(1):
104–110, 2010.

176
Handbook of Approximate Bayesian Computation
[15] C. Barnes, S. Filippi, M. Stumpf, and T. Thorne. Considerate approaches
to constructing summary statistics for ABC model selection. Statistics
and Computing, 22(6):1181–1197, 2012.
[16] D. Prangle, P. Fearnhead, M. Cox, P. Biggs, and N. French. Semi-
automatic selection of summary statistics for ABC model choice. Statis-
tical Applications in Genetics and Molecular Biology, 13(1):67–82, 2014.
[17] S. Barthelm´e and N. Chopin. Expectation propagation for likelihood-
free
inference.
Journal
of
the
American
Statistical
Association,
109(505):315–333, 2014.
[18] M. Beaumont. Joint determination of topology, divergence time and im-
migration in population trees. In S. Matsumura, P. Forster, and C. Ren-
frew (Eds.), Simulations, Genetics and Human Prehistory, pp. 134–154.
Cambridge, UK: (McDonald Institute Monographs), McDonald Institute
for Archaeological Research, 2008.
[19] J.-M. Cornuet, V. Ravign´e, and A. Estoup. Inference on population his-
tory and model checking using DNA sequence and microsatellite data
with the software DIYABC (v1.0). BMC Bioinformatics, 11:401, 2010.
[20] P. Pudlo, J.-M. Marin, A. Estoup, J.-M. Cornuet, M. Gautier, and C.P.
Robert. Reliable ABC model choice via random forests. Bioinformatics,
32(6):859–866, 2016.
[21] T. Toni, D. Welch, N. Strelkowa, A. Ipsen, and M. Stumpf. Approxi-
mate Bayesian computation scheme for parameter inference and model
selection in dynamical systems. Journal of the Royal Society Interface,
6(31):187–202, 2009.
[22] N. Fagundes, N. Ray, M. Beaumont, S. Neuenschwander, F. Salzano,
S. Bonatto, and L. Excoﬃer. Statistical evaluation of alternative models
of human evolution. Proceedings of the National Academy of Sciences,
104(45):17614–17619, 2007.
[23] A. Estoup, E. Lombaert, J.-M. Marin, C.P. Robert, T. Guillemaud,
P. Pudlo, and J.-M. Cornuet. Estimation of demo-genetic model prob-
abilities with approximate Bayesian computation using linear discrim-
inant analysis on summary statistics. Molecular Ecology Resources,
12(5):846–855, 2012.
[24] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statisti-
cal Learning. Data Mining, Inference, and Prediction. Springer Series in
Statistics. New York: Springer-Verlag, 2 ed., 2009.

Likelihood-Free Model Choice
177
[25] T. Minka and J. Laﬀerty. Expectation-propagation for the generative
aspect model. In Proceedings of the Eighteenth Conference on Uncer-
tainty in Artiﬁcial Intelligence, UAI’02, pp. 352–359. San Francisco, CA:
Morgan Kaufmann Publishers Inc., 2002.
[26] M. Seeger. Expectation propagation for exponential families. Technical
report. Berkeley, CA: University of California, 2005.
[27] T. Jaakkola and M. Jordan. Bayesian parameter estimation via varia-
tional methods. Statistics and Computing, 10(1):25–37, 2000.
[28] X. Didelot, R. Everitt, A. Johansen, and D. Lawson. Likelihood-free
estimation of model evidence. Bayesian Analysis, 6(1):48–76, 2011.
[29] J.-M. Cornuet, P. Pudlo, J. Veyssier, A. Dehne-Garcia, M. Gautier,
R. Leblois, J.-M. Marin, and A. Estoup. DIYABC v2.0: A software
to make approximate Bayesian computation inferences about popula-
tion history using single nucleotide polymorphism, DNA sequence and
microsatellite data. Bioinformatics, 30(8):1187–1189, 2014.
[30] M. Stephens and P. Donnelly. Inference in molecular population genetics.
Journal of the Royal Statistical Society: Series B, 62(4):605–635, 2000.
[31] J.-M. Cornuet, F. Santos, M. Beaumont, C.P. Robert, J.-M. Marin,
D. Balding, T. Guillemaud, and A. Estoup. Inferring population history
with DIYABC: A user-friendly approach to approximate Bayesian com-
putation. Bioinformatics, 24(23):2713–2719, 2008.
[32] J.-M. Marin, N. Pillai, C.P. Robert, and J. Rousseau. Relevant statistics
for Bayesian model choice. Journal of the Royal Statistical Society: Series
B, 76(5):833–859, 2014.
[33] M. Evans. Measuring Statistical Evidence Using Relative Belief. Boca
Raton, FL: CRC Press, 2015.
[34] O. Ratmann, C. Andrieu, C. Wiujf, and S. Richardson. Model criti-
cism based on likelihood-free inference, with an application to protein
network evolution. Proceedings of the National Academy of Sciences,
106(26):10576–10581, 2009.
[35] J. Stoehr, P. Pudlo, and L. Cucala. Adaptive ABC model choice and
geometric summary statistics for hidden Gibbs random ﬁelds. Statistics
and Computing, 25(1):129–141, 2015.
[36] L. Devroye, L. Gy¨orﬁ, and G. Lugosi. A Probabilistic Theory of Pat-
tern Recognition, volume 31 of Applications of Mathematics (New York).
New York: Springer-Verlag, 1996.

178
Handbook of Approximate Bayesian Computation
[37] L. Breiman. Random forests. Machine Learning, 45(1):5–32, 2001.
[38] L. Breiman, J. Friedman, C. Stone, and R. Olshen. Classiﬁcation and
Regression Trees. Boca Raton, FL: CRC Press, 1984.
[39] C.P. Robert. The Bayesian Choice. New York: Springer-Verlag, 2nd ed.,
2001.
[40] 1000 Genomes Project Consortium, G.R. Abecasis, A. Auton, et al. An
integrated map of genetic variation from 1,092 human genomes. Nature,
491:56–65, 2012.

7
ABC and Indirect Inference
Christopher C. Drovandi
CONTENTS
7.1
Introduction ......................................................
179
7.2
Indirect Inference ................................................
181
7.3
ABC II Methods .................................................
185
7.4
Bayesian Indirect Likelihood with a Parametric Auxiliary
Model ............................................................
189
7.5
Further Reading ..................................................
192
7.6
Examples .........................................................
196
7.6.1
Infectious disease example ..............................
196
7.6.2
Spatial extremes example ...............................
199
7.7
Discussion ........................................................
204
Acknowledgements .......................................................
205
References
...............................................................
205
7.1
Introduction
Indirect inference (II) is a classical method for estimating the parameter of a
complex model when the likelihood is unavailable or too expensive to evaluate.
The idea was popularised several years prior to the main developments in ap-
proximate Bayesian computation (ABC) by Gourieroux et al. (1993); Smith
(1993), where interest was in calibrating complex time series models used
in ﬁnancial applications. The II method became a very popular approach in
the econometrics literature [e.g. Smith (1993); Monfardini (1998); Dridi et al.
(2007)] in a similar way to the ubiquitous application of ABC to models in
179

180
Handbook of Approximate Bayesian Computation
population genetics. However, the articles by Jiang and Turnbull (2004) and
Heggland and Frigessi (2004) have allowed the II approach to be known and
appreciated by the wider statistical community.
In its full generality, the II approach can be viewed as a classical
method to estimate the parameter of a statistical model on the basis of
a so-called indirect or auxiliary summary of the observed data (Jiang and
Turnbull, 2004). A special case of II is the simulated method of moments
(McFadden, 1989), where the auxiliary statistic is a set of sample moments.
In this spirit, the traditional ABC method may be viewed as a Bayesian version
of II, where prior information about the parameter may be incorporated and
updated using the information about the parameter contained in the summary
statistic. However, much of the II literature has concentrated on developing
the summary statistic from an alternative parametric auxiliary model that is
analytically and/or computationally more tractable. The major focus of this
chapter is on approximate Bayesian methods that harness such an auxiliary
model. These are referred to as parametric Bayesian indirect inference (pBII)
methods by Drovandi et al. (2016).
One such approach, referred to as ABC II, uses either the parameter
estimate or the score of the auxiliary model as a summary statistic for ABC.
When the auxiliary parameter is used, the ABC discrepancy function (distance
between observed and simulated data) may be based on a direct comparison
of the auxiliary parameter estimates [ABC IP where P denotes parameter
(Drovandi et al., 2011)] or indirectly via the auxiliary log-likelihood [ABC IL
where L denotes likelihood (Gleim and Pigorsch, 2013)]. Alternatively, a dis-
crepancy function can be formulated by comparing auxiliary scores [ABC IS
where S denotes score (Gleim and Pigorsch, 2013)]. Another approach, which
diﬀers substantially from the ABC II methods in terms of its theoretical un-
derpinnings, uses the likelihood of the auxiliary model as a replacement to
the intractable likelihood of the speciﬁed (or generative) model provided that
a mapping has been estimated between the generative and auxiliary param-
eters (Reeves and Pettitt, 2005; Gallant and McCulloch, 2009). This method
has been referred to as parametric Bayesian indirect likelihood (pBIL) by
Drovandi et al. (2016). These methods will be discussed in greater detail in this
chapter.
This chapter begins with a tutorial and a summary of the main
developments of II in Section 7.2. This is followed by a review of ABC II
methods in Section 7.3. Section 7.4 describes the parametric Bayesian in-
direct likelihood approach to approximate Bayesian inference using ideas
from II. Other connections between ABC and II are provided in Section 7.5
for further reading. The methods are illustrated on an infectious dis-
ease model and a spatial extremes application in Section 7.6. The chap-
ter is summarised in Section 7.7, which also discusses some possible
future directions for utilising or building upon the current Bayesian II
literature.

ABC and Indirect Inference
181
7.2
Indirect Inference
The purpose of this section is to give an overview of the II developments in
the classical framework. It is not our intention to provide a comprehensive
review of the II literature, but rather to provide a tutorial on the method and
to summarise the main contributions.
Assume that there is available a parametric auxiliary model with a cor-
responding likelihood pA(yobs|φ), where φ is the parameter of this model.
The auxiliary model could be chosen to be a simpliﬁed version of the model
of interest (the so-called generative model here) or simply a data-analytic
model designed to capture the essential features of the data. The majority
of the literature on ﬁnancial time series applications has considered the for-
mer; for example, Monfardini (1998) considers autoregressive moving average
auxiliary models to estimate the parameters of a stochastic volatility model.
In contrast, in an ABC application, Drovandi et al. (2011) use a regression
model that has no connection to the assumed mechanistic model, in order to
summarise the data.
The main objective of II is to determine the relationship between the
generative parameter, θ, and the auxiliary parameter, φ. This relationship,
denoted here as φ(θ), is often referred to as ‘the mapping’ or binding function
in the II literature. If the binding function is known and injective (one-to-one),
then the II estimate based on observed data yobs is θobs = θ(φobs), where θ(·)
is the inverse mapping and φobs is the estimate obtained when ﬁtting the
auxiliary model to the data. The II approach essentially answers the question,
what is the value of θ that could have produced the auxiliary estimate φobs?
In this sense, the II approach acts as a correction method for assuming the
wrong model.
Unfortunately the binding function, φ(θ), is generally unknown, but it can
be estimated via simulation. First, using a similar notation and explanation
in Heggland and Frigessi (2004), deﬁne an estimating function, Q(yobs; φ), for
the auxiliary model. This could be, for example, the log-likelihood function
of the auxiliary model. Before the II process begins, the auxiliary model is
ﬁtted to the observed data:
φobs = arg max
φ
Q(yobs; φ).
For a particular value of θ, the process involves simulating n independent
and identically distributed (iid) datasets from the generative model, y1:n =
(y1, . . . , yn). Each replicate dataset yi, i = 1, . . . , n, has the same dimension
as the observed data yobs. Then, the auxiliary model is ﬁtted to this simulated
data to recover an estimate of the binding function, φn(θ):
φn(θ) = arg max
φ
Q(y1:n; φ),

182
Handbook of Approximate Bayesian Computation
where Q(y1:n; φ) = n
i=1 Q(yi; φ). The binding function is deﬁned as φ(θ) =
limn→∞φn(θ). There is an alternative representation of φn(θ). Deﬁne the
estimated auxiliary parameter based on the ith simulated dataset as:
φ(θ, yi) = arg max
φ
Q(yi; φ).
Then we obtain φn(θ) via:
φn(θ) = 1
n
n

i=1
φ(θ, yi).
When this formulation for φn(θ) is used, the deﬁnition of the binding function
can also be represented as E[φ(θ, y)] with respect to f(y|θ). The II procedure
then involves solving an optimisation problem to ﬁnd the θ that generates a
φn(θ) closest to φobs:
θobs,n = arg min
θ {(φn(θ) −φobs)⊤W(φn(θ) −φobs)},
(7.1)
(Gourieroux et al., 1993), where the superscript ⊤denotes transpose and θobs,n
is the II estimator, which will depend on n. Gourieroux et al. (1993) show that
the asymptotic properties of this estimator is the same regardless of what form
is used for φn(θ). Note that equation (7.1) assumes that the auxiliary parame-
ter estimates φn(θ) and φobs are unique. The II estimator should have a lower
variance by increasing n, but this will add to the computational cost. Note
that the above estimator will depend on the weighting matrix W, which needs
to be positive deﬁnite. This matrix allows for an eﬃcient comparison when the
diﬀerent components of the auxiliary estimator have diﬀerent variances and
where there is correlation amongst the components. One simple choice for the
matrix W is the identity matrix. Another choice is the observed information
matrix J(φobs), which can be used to approximate the inverse of the asymp-
totic variance of φobs. Discussion on more optimal choices of the weighting
matrix (in the sense of minimising the asymptotic variance of the indirect
inference estimator) is provided in Gourieroux et al. (1993) and Monfardini
(1998), for example.
An alternative approach proposed in Smith (1993) is to set the II estimator
as the one that maximises the auxiliary estimating function using the observed
data yobs and the estimated mapping:
θobs,n = arg max
θ
Q(yobs; φn(θ)).
(7.2)
This is referred to as the simulated quasi-maximum likelihood (SQML) esti-
mator by Smith (1993), who uses the log-likelihood of the auxiliary model as
the estimating function. Gourieroux et al. (1993) show that the estimator in
(7.1) is asymptotically more eﬃcient than the one in (7.2), provided that an
optimal W is chosen.

ABC and Indirect Inference
183
An estimator that is quite diﬀerent to the previous two, suggested by
Gallant and Tauchen (1996), involves using the derivative of the estimating
function of the auxiliary model. This is deﬁned for some arbitrary dataset y as:
SA(y, φ) =
∂Q(y; φ)
∂φ1
, · · · , ∂Q(y; φ)
∂φpφ
⊤
,
where pφ = dim(φ) and φi is the ith component of the parameter vector φ.
The estimator of Gallant and Tauchen (1996) is given by:
θobs,n = arg min
θ
⎧
⎨
⎩
	
1
n
n

i=1
SA(yi, φobs)

⊤
Σ
	
1
n
n

i=1
SA(yi, φobs)

⎫
⎬
⎭.
(7.3)
The quantity SA(yobs, φobs) does not appear in (7.3), as it can be assumed
to be 0 by deﬁnition. This approach, referred to by Gallant and Tauchen
(1996) as the eﬃcient method of moments (EMM) when the estimating func-
tion Q is the auxiliary log-likelihood, can be very computationally convenient
if there is an analytic expression for SA, as the method only requires ﬁtting
the auxiliary model to data once to determine φobs before the II optimisation
procedure in equation (7.3). Alternatively, it would be possible to estimate
the necessary derivatives, which still could be faster than continually ﬁtting
the auxiliary model to simulated data. The EMM approach is also dependent
upon a weighting matrix, Σ. One possible choice for Σ is J(φobs)−1, since
J(φobs) can be used to estimate the variance of the score.
Gourieroux et al. (1993) show that the estimators in (7.1) and (7.3)
are asymptotically equivalent for certain choices of the weighting matrices.
However, their ﬁnite sample performance may diﬀer and thus the optimal
choice of estimator may be problem dependent. For example, Monfardini
(1998) compares estimation of a stochastic volatility model using II techniques
based on auxiliary autoregressive (AR) and autoregressive moving average
(ARMA) models. Estimation of the AR model is computationally trivial, so
Monfardini (1998) use the estimator in (7.1), whereas the ARMA model is
harder to estimate, but has an analytic expression for the score, thus (7.3) is
used. A simulation study showed smaller bias for the AR auxiliary model.
As is evident from earlier, a common estimating function is the auxiliary
log-likelihood:
Q(y1:n; φ) =
n

i=1
log pA(yi|φ).
However, the user is free to choose the estimating function. Heggland and
Frigessi (2004) demonstrate how the estimating function can involve simple
summary statistics of the data, for example, the sample moments. This sim-
ulated method of moments (McFadden, 1989) involves ﬁnding a parameter
value that generates simulated sample moments closest to the pre-speciﬁed
observed sample moments. Thus, the simulated method of moments is a special
case of II. Heggland and Frigessi (2004) suggest that the auxiliary statistic

184
Handbook of Approximate Bayesian Computation
should be chosen such that it is sensitive to changes in θ, but is robust to dif-
ferent independent simulated datasets generated based on a ﬁxed θ. Heggland
and Frigessi (2004) also show that when the auxiliary statistic is suﬃcient for
θ and has the same dimension as θ, the II estimator has the same asymptotic
eﬃciency as the maximum likelihood estimator (MLE) except for a multiplica-
tive factor of 1+1/n, which reduces to 1 as n →∞. Jiang and Turnbull (2004)
mention that II estimators could be improved further via a one step Newton–
Raphson correction (e.g. Le Cam 1956), but would require some computations
involving the complex generative model.
The Bayesian indirect inference procedures summarised in the following
are essentially inspired by their classical counterparts earlier. Since a number
of methods are surveyed here, all with diﬀerent acronyms, Table 7.1 deﬁnes
the acronyms again for convenience together with a description of the methods
and key relevant literature.
TABLE 7.1
A List of Acronyms Together with Their Expansions for the Bayesian
Likelihood-Free Methods Surveyed in this Chapter. A Description of Each
Method is Shown Together with Some Key References
Acronym
Expansion
Description
Key References
ABC II
ABC indirect
inference
ABC that uses an aux-
iliary model to form a
summary statistic
Gleim and Pigorsch
(2013);
Drovandi
et al. (2015)
ABC IP
ABC indirect
parameter
ABC that uses the pa-
rameter estimate of
an auxiliary model as
a summary statistic
Drovandi
et
al.
(2011);
Drovandi
et al. (2015)
ABC IL
ABC indirect
likelihood
ABC that uses the like-
lihood of an auxiliary
model to form a dis-
crepancy function
Gleim and Pigorsch
(2013);
Drovandi
et al. (2015)
ABC IS
ABC indirect
score
ABC
that
uses
the
score of an auxiliary
model to form a sum-
mary statistic
Gleim and Pigorsch
(2013);
Martin
et
al.
(2014);
Drovandi
et
al.
(2015)
BIL
Bayesian
in-
direct
likelihood
A
general
approach
that
replaces
an
intractable likelihood
with
a
tractable
likelihood
within
a
Bayesian algorithm
Drovandi
et
al.
(2015)
(Continued)

ABC and Indirect Inference
185
TABLE 7.1 (Continued)
A List of Acronyms Together with Their Expansions for the Bayesian
Likelihood-Free Methods Surveyed in this Chapter. A Description of Each
Method is Shown Together with Some Key References
Acronym
Expansion
Description
Key References
pdBIL
Parametric
BIL on the
full
data
level
BIL method that uses
the
likelihood
of
a
parametric
auxiliary
model on the full data
level to replace the in-
tractable likelihood
Reeves and Pettitt
(2005);
Gallant
and
McCulloch
(2009);
Drovandi
et al. (2015)
psBIL
Parametric
BIL on the
summary
statistic
level
BIL method that uses
the
likelihood
of
a
parametric
auxiliary
model on the sum-
mary
statistic
level
to
replace
the
in-
tractable likelihood of
the summary statistic
Drovandi
et
al.
(2015)
ABC-cp
ABC compos-
ite
parameter
ABC that uses the pa-
rameter of a compos-
ite likelihood to form
a summary statistic
This chapter, but see
Ruli et al. (2016)
for
a
composite
score approach
ABC-ec
ABC
extremal
coeﬃcients
ABC
approach
of
Erhardt
and
Smith
(2012)
for
spatial
extremes models
Erhardt and Smith
(2012)
7.3
ABC II Methods
The ﬁrst of the ABC II methods to appear in the literature uses the param-
eter of the auxiliary model as a summary statistic. For each dataset that is
simulated from the model, y ∼p(·|θ), the auxiliary model is ﬁtted to this data
to produce the simulated summary statistic, s = φy. Drovandi et al. (2011)
propose to compare this simulated summary statistic to the observed sum-
mary statistic, sobs = φobs, which is obtained by ﬁtting the auxiliary model to
the observed data prior to the ABC analysis, using the following discrepancy
function:
||s −sobs|| =

(φy −φobs)⊤J(φobs)(φy −φobs),
(7.4)

186
Handbook of Approximate Bayesian Computation
where the observed information matrix of the auxiliary model evaluated at the
observed summary statistic, J(φobs), is utilised to provide a natural weighting
of the summary statistics that also takes into account any correlations between
the components of the auxiliary parameter estimate. This method is referred
to by Drovandi et al. (2015) as ABC IP. Instead, if we base the discrepancy
on the auxiliary likelihood (Gleim and Pigorsch, 2013), we obtain the ABC
IL method:
||s −sobs|| = log pA(yobs|φobs) −log pA(yobs|φy).
Under some standard regularity conditions, it is interesting to note that the
ABC IP discrepancy function appears in the second order term of the Taylor
series expansion of the ABC IL discrepancy function. This might suggest that
the ABC IL discrepancy function is more eﬃcient than the discrepancy func-
tion of ABC IP generally, but this requires further investigation. A common
aspect of the ABC IP and ABC IL approaches is that they both use the
auxiliary parameter estimate as a summary statistic. As such, these meth-
ods involve ﬁtting the auxiliary model to every dataset simulated from the
generative model during an ABC algorithm. In one sense, it is desirable to
extract as much information out of the auxiliary model as possible. From this
point of view, an attractive estimation procedure is maximum likelihood:
φobs = arg max
φ∈Φ pA(yobs|φ),
which tends to be more eﬃcient than other simpler estimation approaches,
such as the method of moments. However, in most real applications there is
not an analytic expression for the auxiliary MLE, and one must then resort
to numerical optimisation algorithms [e.g. Drovandi et al. (2011) apply the
Nelder-Mead derivative free optimiser]. Having to determine a numerical MLE
at every iteration of the ABC algorithm not only slows down the method, but
also potentially introduces further issues if the numerical optimiser is prone to
getting stuck at local modes of the auxiliary likelihood surface. A pragmatic
approach may be to initialise the numerical optimiser at the observed auxiliary
parameter estimate, φobs.
In summary, the earlier review reveals that the optimal choice of auxiliary
estimator may be a trade-oﬀbetween the computational cost of obtaining
and the statistical eﬃciency of the chosen auxiliary estimator. One approach
to expand on this literature might be to start with a computationally sim-
ple, but consistent estimator (e.g. the method of moments) and apply one
iteration of a Newton–Raphson method to produce an asymptotically eﬃ-
cient estimator (Le Cam, 1956) in a timely manner. It is important to note
that the ABC IP and ABC IL methods are essentially ABC versions of the
classical II approaches in Gourieroux et al. (1993) (who compare observed
and simulated auxiliary parameters) and Smith (1993) (who maximises the
auxiliary log-likelihood), respectively.

ABC and Indirect Inference
187
A rather diﬀerent approach to ABC IP and ABC IL considered by Gleim
and Pigorsch (2013) uses the score of the auxiliary model as the summary
statistic, resulting in the ABC IS procedure. A major advantage of the ABC
IS approach is that we always evaluate the score at the observed auxiliary es-
timate, φobs. Any simulated data, y, obtained during the ABC algorithm can
be substituted directly into the auxiliary score to determine the simulated
summary statistic, without needing to ﬁt the auxiliary model to the simu-
lated data. In cases where there is an analytic expression for the score, the
summary statistic can be very fast to compute (similar to more traditional
summary statistics used in ABC), and this leads to substantial computational
savings over ABC IP and ABC IL. However, in many applications, the deriva-
tives of the auxiliary likelihood are not available analytically. In such situa-
tions, it is necessary to estimate the derivatives numerically [see, e.g. Martin
et al. (2014) and Section 7.6.1] using a ﬁnite diﬀerence strategy, for example.
This may contribute another small layer of approximation and add to the
computational cost, although the number of likelihood evaluations required
to estimate the score is likely to be less than that required to determine the
auxiliary MLE.
When the MLE is chosen as the auxiliary estimator, then the observed
score (or summary statistic here, sobs) can be assumed to be numerically 0.
Therefore, a natural discrepancy function in the context of ABC IS is given by:
||s −sobs|| =

SA(y, φobs)⊤J(φobs)−1SA(y, φobs),
(7.5)
where s = SA(y, φobs). We can again utilise the observed auxiliary information
matrix to obtain a natural weighting of the summary statistics. The ABC IS
approach is eﬀectively an ABC version of the EMM method in Gallant and
Tauchen (1996).
The assumptions required for each ABC II approach to behave in a sat-
isfactory manner are provided in Drovandi et al. (2015). In summary, the
ABC IP approach requires a unique auxiliary parameter estimator so that
each simulated dataset results in a unique value of the ABC discrepancy.
ABC IL requires a unique maximum likelihood value and ABC IS requires a
unique score (and some other mild conditions) for each simulated dataset gen-
erated during the ABC algorithm. Drovandi et al. (2015) consider an example
where the auxiliary model is a mixture model, which does not possess a unique
estimator due to the well-known label switching issue with mixtures. The ABC
IL and ABC IS approaches were more suited to handling the label switching
problem.
Martin et al. (2014) contain an important result that shows that the aux-
iliary score carries the same information as the auxiliary parameter estimate,
thus the ABC II approaches will have the same target distribution in the
limit as h →0. Martin et al. (2014) demonstrate that the discrepancy func-
tion involving the auxiliary score can be written as a discrepancy function
involving the auxiliary parameter estimate, thus ABC will produce the same

188
Handbook of Approximate Bayesian Computation
draws regardless of the choice of summary statistic in the limit as h →0.
Whilst Drovandi et al. (2015) demonstrate empirically that there are diﬀer-
ences amongst the ABC II results for h > 0, the result of Martin et al. (2014)
does provide more motivation for a score approach, which will often be more
computationally eﬃcient.
In choosing an auxiliary model in the context of ABC II, it would seem
desirable if the auxiliary model gave a good ﬁt to the observed data so that
one is reasonably conﬁdent that the quantities derived from the auxiliary
model capture most of the information in the observed data. In particular,
the auxiliary MLE is asymptotically suﬃcient for the auxiliary model. Thus,
assuming some regularity conditions on the auxiliary model, if the generative
model is a special case of the auxiliary model then the statistic derived from
the auxiliary model will be asymptotically suﬃcient also for the generative
model (Gleim and Pigorsch, 2013). An advantage of the ABC II approach is
that the utility of the summary statistic may be assessed prior to the ABC
analysis by performing some standard statistical techniques, such as goodness-
of-ﬁt and/or residual analyses. For example, Drovandi et al. (2015) consider
a chi-square goodness-of-ﬁt test to indicate insuﬃcient evidence against the
auxiliary model providing a good description of the data in an application
involving a stochastic model of macroparasite population evolution. This is
in contrast to more traditional choices of summary statistics (Blum et al.,
2013), where it is often necessary to perform an expensive simulation study to
select an appropriate summary. The well-known curse of dimensionality issue
associated with the choice of summary statistic in ABC (Blum, 2010) can be
addressed to an extent in the ABC II approach by choosing a parsimonious
auxiliary model which might be achieved by comparing competing auxiliary
models through some model selection criterion (e.g. Drovandi et al. (2011) use
the Akaike Information Criterion).
Alternatively, it might be more convenient to select the auxiliary model
as a simpliﬁed version of the generative model so that the auxiliary param-
eter has the same interpretation as the generative parameter (parameter of
the generative model). For example, Section 7.6.1 considers performing infer-
ence for a Markov process using the corresponding linear noise approximation
as the auxiliary model. This approach has the advantage that the summary
statistic will have the same dimension as the parameter of interest [which can
be desirable, see e.g. Fearnhead and Prangle (2012), and indeed necessary
for some methods (Nott et al., 2014; Li et al., 2015)] and that there will be
a strong connection between the generative and auxiliary parameters. The
obvious drawback is, assuming the generative model is correct, the simpliﬁed
version of the model in general will not provide a good ﬁt to the observed data,
and ultimately, any asymptotic suﬃciency for the auxiliary model is lost for
the generative model.
From a classical point of view, it is well known that basing inferences on
the wrong model may result in biased parameter estimates. From a Bayesian
perspective, the mode and concentration of the posterior distribution may not

ABC and Indirect Inference
189
be estimated correctly when employing an approximate model for inference
purposes. As mentioned in Section 7.2, II can be viewed as a method that pro-
vides some correction for assuming the wrong/simpliﬁed version of the model
(Jiang and Turnbull, 2004). It does this by ﬁnding the parameter value of the
generative model that leads to simulated data where the parameter estimate
based on the simpliﬁed model applied to the simulated data is closest to that
of the observed data. It may also be that applying ABC II in a similar way
may lead to posterior modes that are closer to the true posterior mode in gen-
eral, compared to when inferences are solely based on the misspeciﬁed model.
Furthermore, ABC has a tendency to provide a less concentrated posterior
distribution relative to the true posterior, which depends on how much infor-
mation has been lost in the data reduction. Thus, using auxiliary parameter
estimates of a simpliﬁed model as summary statistics in ABC will not lead
to over concentrated posteriors, as may be the case if the simpliﬁed model
was used directly in the Bayesian analysis. Using a summary statistic derived
from such an auxiliary model in ABC is yet to be thoroughly explored in the
literature [although see Martin et al. (2014) for an example].
Under certain regularity conditions on the auxiliary model that lead to
II producing a consistent estimator [e.g. Gourieroux et al. (1993)], ABC II
will produce Bayesian consistency in the limit as h →0 (Martin et al., 2014).
Under the regularity conditions, in equation (7.4), φobs →φ(θ0) (where θ0 is
the true value of the parameter), and φy →φ(θ), where y ∼p(y|θ) as the
sample size goes to inﬁnity. Thus, in the limit as h →0, ABC will only keep
θ = θ0.
Martin et al. (2014) also take advantage of the strong one-to-one corre-
spondence between the auxiliary and generative parameters in the situation
where the auxiliary model is a simpliﬁed version of the generative model. Here,
Martin et al. (2014) suggest the use of the marginal score for a single auxiliary
parameter, which is the score with all other components of the parameter in-
tegrated out of the auxiliary likelihood, as a summary statistic to estimate the
univariate posterior distribution of the corresponding single generative model
parameter.
7.4
Bayesian Indirect Likelihood with a Parametric
Auxiliary Model
An alternative to ABC II that has been considered in the literature by Reeves
and Pettitt (2005) and Gallant and McCulloch (2009) is to use the likelihood
of an auxiliary parametric model as a replacement to that of the intractable
generative likelihood, provided a relationship, φ(θ), has been estimated be-
tween the generative and auxiliary parameters. See also Ryan et al. (2016) for
an application of this method to Bayesian experimental design in the presence
of an intractable likelihood. This approach is investigated in more theoretical

190
Handbook of Approximate Bayesian Computation
detail in Drovandi et al. (2015) and is referred to as pdBIL (where d stands
for data). It is also possible to apply a parametric auxiliary model to the
summary statistic likelihood, where some data reduction has been applied.
One then obtains psBIL (where s denotes summary statistic), which is dis-
cussed brieﬂy later in this section. The pdBIL method could be considered
as a Bayesian version of the simulated quasi-maximum likelihood approach in
Smith (1993). If the so-called mapping or binding function, φ(θ), is known,
then the approximate posterior of the pdBIL approach is given by:
πA(θ|yobs) ∝pA(yobs|φ(θ))π(θ),
where πA(θ|yobs) denotes the pdBIL approximation to the true posterior and
pA(yobs|φ(θ)) is the likelihood of the auxiliary model evaluated at the param-
eter φ(θ).
Unfortunately, in practice, the relationship between φ and θ will be un-
known. More generally, it is possible to estimate φ(θ) via simulation of n
independent and identically distributed datasets, y1:n = (y1, . . . , yn), from
the generative model based on a proposed parameter, θ. Then the auxiliary
model is ﬁtted to this large dataset to obtain φn(θ), which could be based on
maximum likelihood:
φn(θ) = arg max
φ
n

i=1
pA(yi|φ).
The target distribution of the resulting method is given by:
πA,n(θ|yobs) ∝pA,n(yobs|θ)π(θ),
where
pA,n(yobs|θ) =

y1:n
pA(yobs|φn(θ))
 n

i=1
p(yi|θ)

dy1:n,
which can be estimated unbiasedly using a single draw of n independent and
identically distributed datasets, y1:n ∼p(·|θ). The introduction of the second
subscript n in pA,n(yobs|θ) highlights that an additional layer of approximation
is introduced by selecting a ﬁnite value of n to estimate the mapping [see
Drovandi et al. (2015) for more details]. The empirical evidence in Drovandi
et al. (2015) seems to suggest, in the context of pdBIL, that the approximate
posterior becomes less concentrated as the value of n decreases. Therefore,
if the auxiliary model chosen is reasonable (discussed later in this section),
then better posterior approximations can be anticipated by taking n as large
as possible. Initially it would seem apparent that the computational cost of
the pdBIL approach would grow as n is increased. However, Drovandi et al.
(2015) report an increase in acceptance probability of a Markov chain Monte
Carlo (MCMC) algorithm targeting πA,n(θ|yobs) as n is increased. Thus, up to

ABC and Indirect Inference
191
a point, n can be raised without increasing the overall computing time since
fewer iterations of MCMC will be required to obtain an equivalent eﬀective
sample size compared with using smaller values of n. Values of n above a
certain limit where the acceptance probability does not increase may reduce
the overall eﬃciency of the approach.
Like ABC IP and ABC IL, pdBIL requires an optimisation step for every
simulated dataset, so it can be an expensive algorithm. For a Potts model
application with a single parameter, Moores et al. (2015) propose to run
pre-simulations across the prior space for a chosen value of n and ﬁt a non-
parametric model in order to smooth out the eﬀect of n and recover an es-
timate of the mapping, denoted ˆφ(θ). A major computational advantage of
this approach is that the estimated mapping can be re-used to analyse mul-
tiple observed datasets of the same size. However, devising a useful strategy
to extend this idea to higher dimensional problems than that considered by
Moores et al. (2015) is an open area of research.
For the pdBIL method to lead to a quality approximation, the approach
relies on a quite strong assumption that the auxiliary likelihood acts as a
useful replacement likelihood across the parameter space with non-negligible
posterior support and that the auxiliary likelihood reduces further in regions
of very low posterior support (Drovandi et al., 2015). In contrast, the ABC II
methods require that the summary statistic coming from the auxiliary model
is informative and an eﬃcient algorithm is available to ensure a close matching
between the observed and simulated summary statistics in order to produce a
close approximation to the true posterior distribution. Drovandi et al. (2015)
demonstrate that under suitable conditions, the pdBIL method will target
the true posterior in the limit as n →∞if the generative model is nested
within the auxiliary model. In this ideal scenario, ABC II methods will not be
exact as h →0 since the quantities drawn from the auxiliary model will not
produce a suﬃcient statistic in general, as the dimension of the statistic will be
smaller than the size of the data [however, under suitable regularity conditions,
the statistic will be asymptotically suﬃcient (Gleim and Pigorsch, 2013)].
Of course, it would seem infeasible to ﬁnd a tractable auxiliary model that
incorporates an intractable model as a special case. However, this observation
does suggest, in the context of pdBIL method, that a ﬂexible auxiliary model
may be useful.
We note that pdBIL is not illustrated empirically in this chapter, but a
number of examples are provided in Reeves and Pettitt (2005); Gallant and
McCulloch (2009); Drovandi et al. (2015).
We note that a parametric auxiliary model can also be applied at a sum-
mary statistic level; that is, when some data reduction technique has been per-
formed. As mentioned earlier, the method is referred to as psBIL in Drovandi
et al. (2015). A popular psBIL method in the literature is to assume a multi-
variate normal auxiliary model. Here, the likelihood of the multivariate normal
distribution, with a mean and covariance matrix dependent on θ, is used as
a replacement to the intractable summary statistic likelihood. This technique

192
Handbook of Approximate Bayesian Computation
has been referred to as synthetic likelihood (Wood, 2010; Price et al., 2018),
and is covered in much greater detail in chapter 12 of Drovandi et al. (2018)
(this volume).
7.5
Further Reading
Ruli et al. (2016) propose to use the score of a composite likelihood approx-
imation of the full likelihood as a summary statistic for ABC (referred to as
ABC-cs). Methods involving the composite likelihood can be applied when the
full data likelihood is intractable, but the likelihood of certain subsets of the
data can be evaluated cheaply. Section 7.6.2 considers an example in spatial
extremes where composite likelihood methods are applicable. The method of
Ruli et al. (2016) has a strong connection with the ABC IS method, but it
does not quite fall under the ABC II framework as the composite likelihood
is not associated with any parametric auxiliary model, but rather is used as a
proxy to the full data likelihood formed by simplifying the dependency struc-
ture of the model. Of course, an alternative to Ruli et al. (2016) could use the
composite likelihood estimate as a summary statistic and obtain approaches
similar to ABC IP and ABC IL (Section 7.6.2 considers a composite likelihood
variant on ABC IP). However, as with ABC IS, the approach of Ruli et al.
(2016) can be relatively fast if the composite score is easier to obtain than the
composite parameter estimator.
Pauli et al. (2011) and Ribatet et al. (2012) consider a Bayesian analysis
where they use the composite likelihood directly as a replacement to the true
likelihood. A naive application of this can lead to posterior approximations
that are incorrectly concentrated, as each data point may appear in more than
one composite likelihood component depending on how the data subsets are
constructed. However, Pauli et al. (2011) and Ribatet et al. (2012) suggest
so-called calibration approaches in an attempt to correct this. The method of
Ruli et al. (2016) essentially by-passes this issue by using the composite likeli-
hood to form a summary statistic for ABC. Therefore, Ruli et al. (2016) rely
on this summary statistic being approximately suﬃcient in order to achieve a
good approximation to the true posterior distribution. The approach of Ruli
et al. (2016) generally falls under the Bayesian indirect inference framework, as
it involves simulation from the true model in an attempt to correct an estima-
tor based solely on the composite likelihood. The dimension of the summary
statistic will coincide with that of the generative model parameter and there
will likely be a strong correspondence between the two.
Forneron and Ng (2016) develop an approach called the reverse sampler
(RS) that produces approximate Bayesian inferences that have a strong con-
nection with II. The approach involves solving many II problems with a dif-
ferent random seed each time, and upon re-weighting the resulting solutions,

ABC and Indirect Inference
193
Algorithm 7.1: The reverse sampler of Forneron and Ng (2016)
1: for i = 1 to T where T is the number of samples do
2:
Solve the II optimisation problem θ(i)
=
arg maxθ{(s(θ, ξ(i)) −
sobs)⊤W(s(θ, ξ(i)) −sobs)} where ξ(i) ∼p(ξ). Set ρ(i) = (s(θ(i), ξ) −
sobs)⊤W(s(θ(i), ξ) −sobs)
3:
Set the weight for sample θ(i) as w(i) ∝π(θ(i))vol(sθ(θ(i), ξ(i)))−1
4: end for
an independent sample is generated from an approximate posterior. The sum-
mary statistic may come from an auxiliary model or could be any summarisa-
tion of the full data. The approach is provided in Algorithm 7.1. It is important
to note that each II optimisation uses n = 1, as in ABC. For this approach, we
denote the simulated summary statistic as s(θ, ξ), where ξ are a set of random
numbers generated through the simulation, ξ ∼p(ξ). For each II optimisation
procedure, ξ is held ﬁxed. This is equivalent to using the same random seed
during each II optimisation.
Denote the sample obtained from solving the ith optimisation problem as
θ(i). After θ(i) is generated, it must be weighted. One aspect of the weighting
is the prior density, π(θ(i)). It also involves a Jacobian term and a volume term
if the number of summary statistics exceeds the dimension of the parameter.
Denote sθ(θ, ξ) as the Jacobian:
sθ(θ, ξ) = ∂s(θ, ξ)
∂θ
,
which is a q × p matrix, where q is the dimension of the summary statistic
and p is the dimension of the parameter. That is, the (j, k) element of this
matrix is given by ∂sj(θ,ξ)
∂θk
, where sj(θ, ξ) is the function for the jth summary
statistic. Then the weight for sample θ(i) is given by:
w(i) ∝π(θ(i))vol(sθ(θ(i), ξ(i)))−1,
where
vol(sθ(θ(i), ξ(i))) =

det

sθ(θ(i), ξ(i))⊤sθ(θ(i), ξ(i))

.
Upon normalisation of the weights, a weighted sample is obtained from an
approximate posterior. Forneron and Ng (2016) also include a kernel function
to the weights, Kh(||sobs −sθ(θ(i), ξ(i))||) to give higher weight to II optimi-
sation samples that get closer to the observed summary statistic. Note that
if sθ(θ(i), ξ(i)) is unavailable analytically, it can be estimated via numerical
diﬀerentiation, for example, ﬁnite diﬀerencing.
Here we provide an example to obtain some insight into the approximation
behaviour of the RS. Consider a dataset y1, . . . , yN ∼N(μ, 1) of length N.

194
Handbook of Approximate Bayesian Computation
A suﬃcient statistic is s = ¯y ∼N(μ, 1/√n). We may think of the simu-
lated data as a transformation of the parameter and some noise variables,
yi = μ + ξi, where ξi ∼N(0, 1) and ξ = (ξ1, . . . , ξN). To obtain the summary
statistic, we have s(μ, ξ) = ¯y = μ + ¯ξ, where ¯ξ is the sample mean of the noise
variables. The Jacobian of this transformation is 1. For ﬁxed, ¯ξ(i) we obtain
μ(i) = ¯yobs −¯ξ(i), in which case sobs −s(μ(i), ξ(i)) = 0. Eﬀectively the RS al-
gorithm samples from μ ∼N(¯yobs, 1/√n), which is the posterior distribution
of μ if the prior is uniform and improper over the real line. If the prior was
selected diﬀerently then the μ(i) samples need to be weighted proportional
to the prior density w(i) ∝π(μ(i)). Assume for the rest of this example that
π(μ) ∝1 for −∞< μ < ∞.
Now consider the two-dimensional summary (¯y, m), where m is the sam-
ple median. This remains a suﬃcient statistic, so that ABC targets the true
posterior in the limit as h →0. Here we have ¯y = μ + ¯ξ and m = μ + mξ
where ¯ξ is the sample mean of the noise variables and mξ is the median of the
noise variables. We set the discrepancy function as the following:
||sobs −s(μ, ξ)|| =

¯yobs −(μ + ¯ξ)
2 + {mobs −(μ + mξ)}2 .
Minimising this with respect to μ for some ξ(i), we obtain μ(i) = (¯yobs −
¯ξ(i) + mobs −m(i)
ξ )/2. Thus in this case RS does not draw directly from the
posterior (despite the fact that the statistic is suﬃcient). This is conﬁrmed in
Figure 7.1(a) where there is departure from the true posterior (although it is
better than an RS sampler that just uses the median as a summary). Here,
we investigate the impact on the approximate posterior as we discard some of
the μ RS samples with the highest discrepancy. Figure 7.1(b) demonstrates
improved accuracy by discarding only 50% of the draws. This is equivalent
to using a uniform kernel with an appropriate value of h in the RS weighting
function of Forneron and Ng (2016).
Also shown in Figure 7.1(a) is the posterior when using ﬁve summary
statistics (mean, median, min, max, and midrange). The partial derivatives
of the summaries (for ﬁxed noise variables) with respect to the parameter are
all equal to 1 so that the Jacobian term for all samples is the same so that
the weights are the same for each sample. Again using the squared Euclidean
distance, it is easy to show what the expression is for μ drawn during the RS
sampler. Here, there is quite a large departure from the true posterior, demon-
strating that the RS method does suﬀer from a curse of dimensionality in the
summary statistic, as with ABC. Figure 7.1(c) shows that the approximation
can be improved by discarding samples with the highest discrepancy values.
However, a large proportion (around 95% say) need to be discarded to get
close to the true posterior. The results demonstrate that care must be taken
when choosing summary statistics for RS, as in ABC.
Figures 7.1(d) and (e) demonstrate that using a local regression adjustment
of Beaumont et al. (2002) (as is commonly done in ABC) almost fully corrects
the RS approximations. It appears the regression adjustment can be quite
useful for RS, as it is for ABC.

ABC and Indirect Inference
195
−0.4
−0.2
0
0.2
0.4
0.6
0.8
0
(a)
0.5
1
1.5
2
2.5
3
3.5
4
True
Mean/median
5 summaries
Median
−0.4
−0.2
0
0.2
0.4
0.6
0
(b)
0.5
1
1.5
2
2.5
3
3.5
4
True
Mean/median
Mean/median keep 75%
Mean/median keep 50%
−0.4
−0.2
0
0.2
0.4
0.6
0
(c)
0.5
1
1.5
2
2.5
3
3.5
4
True
Mean/median
Mean/median keep 20%
Mean/median keep 5%
−0.4
−0.2
0
0.2
0.4
0.6
0
(d)
0.5
1
1.5
2
2.5
3
3.5
4
4.5
True
Mean/median
Mean/median reg adj
−0.4
−0.2
0
0.2
0.4
0.6
0
(e)
0.5
1
1.5
2
2.5
3
3.5
4
4.5
True
5 summaries
5 summaries reg adj
FIGURE 7.1
RS example for the normal location model with diﬀerent choices of the sum-
mary statistics and using rejection and regression adjustment. (a)–(e): see text
for description.

196
Handbook of Approximate Bayesian Computation
7.6
Examples
In this section, we consider two case studies involving real data to demon-
strate how ideas from indirect inference can enhance ABC inferences. Note
throughout all ABC analyses, we use the uniform kernel weighting function,
Kh(||s −sobs||) = I(||s −sobs|| ≤h).
7.6.1
Infectious disease example
Consider a stochastic susceptible-infected (SI) model where the number of
susceptibles and infecteds at time t are denoted by S(t) and I(t), respectively.
In an inﬁnitesimal time Δt, a transmission can occur with approximate prob-
ability βS(t)I(t)Δt, which increments the number of infectives and reduces
the number of susceptibles by one. A removal can occur in that time with
approximate probability γI(t)Δt. Removed individuals play no further part
in the process. This model has been applied to a smallpox epidemic dataset in
O’Neill and Roberts (1999); Fearnhead and Meligkotsidou (2004). The dataset
consists of the removal times in days [see (Becker, 1989, p. 111)]. The village
consists of 120 people, one of whom becomes infected and introduces it into
the community. We set the ﬁrst removal at time t = 0, where, for simplicity,
we assume that there is exactly one infected, i.e. I(0) = 1 and S(0) = 118.
We adopt the same interpretation of the dataset that Golightly et al. (2015)
use where the observations refer to daily recordings of S(t) + I(t), which
changes only on days where a removal takes place. Thus, we do not assume
that the epidemic has necessarily ceased with the last removal recorded in the
dataset.
Samples from the true posterior distribution can be obtained using the
particle MCMC approach speciﬁed in Drovandi et al. (2016) that makes use
of the alive particle ﬁlter [see Del Moral et al. (2015) for additional infor-
mation on the alive particle ﬁlter]. However, in general, it is very diﬃcult to
devise exact and computationally feasible strategies for these Markov process
models, especially when the model contains several populations. Therefore,
here, we consider approximate Bayesian inference approaches that use a di-
rect approximation to the true stochastic process. A popular and tractable
approximation to continuous time Markov chains is the linear noise approxi-
mation (LNA). Fearnhead et al. (2014) base their posterior inferences directly
on the LNA and thus require that the LNA be a very good approximation to
the Markov process, which may not always be the case.
A diﬀerent approach is to use the auxiliary LNA model to form summary
statistics for ABC. In this situation, there are as many summary statistics as
generative model parameters and the auxiliary and generative model parame-
ters have the same interpretation. We denote the LNA model parameters as βA
and γA, where superscript A denotes the auxiliary model. The auxiliary model

ABC and Indirect Inference
197
likelihood is denoted as pA(y|φ) where φ = (βA, γA) is the auxiliary parameter.
The auxiliary parameter estimate based on the observed data is given by:
φobs = arg max
φ
pA(yobs|φ).
To reduce the computational burden, we consider an ABC IS approach. That
is, we consider the score of the LNA model and always use φobs in the score
function for the summary statistic:
s = SA(y, φobs) =
∂log pA(y|φ)
∂βA
|φ=φobs, ∂log pA(y|φ)
∂γA
|φ=φobs
⊤
,
where y is a simulated dataset. We assume that φobs has been obtained accu-
rately enough so that we can assume sobs = SA(yobs, φobs) = (0, 0)⊤. We set
the discrepancy function || · || as the L2 norm of s. However, there is no an-
alytic expression for the score. Therefore, we estimate the score numerically,
which requires several evaluations of the LNA likelihood. Thus calculating
the summary statistic based on the score is mildly computationally intensive,
and given that ABC tends to suﬀer from poor acceptance rates, we propose
a method here to accelerate the algorithm without altering the ABC target
distribution.
To improve the computational eﬃciency of the ABC approach, we pro-
pose an implementation of the lazy ABC method of Prangle (2016). Our
approach uses a second summary statistic, which we call the lazy summary
statistic (denoted by sobs,lazy and slazy for the observed and simulated data,
respectively), for which computation is trivial once data have been simulated
from the generative model, but which is less informative than the originally
proposed summary statistic. The discrepancy function for the lazy summary
statistic is given by:
ρlazy = ||slazy −sobs,lazy||.
First, a decision on whether or not to compute the actual summary statistic
is made on the basis of the distance between the observed and simulated lazy
summary statistics. If ρlazy falls below a threshold, hlazy, then the proposal
may have produced simulated data reasonably close to the observed data, and
it is then worthwhile to compute the more informative summary statistic.
However, if the lazy distance is too high, then the proposed parameter may
be rejected and thus calculation of the expensive summary is not required.
In order to obtain an algorithm that preserves the original ABC target, it is
necessary to include a continuation probability, α, which may require some
tuning. Therefore, a proposal that performs poorly in terms of the lazy sum-
mary statistic will still make it through to the second stage with probability α.
We implement this approach within an MCMC ABC method [Prangle (2016)
consider ABC importance sampling], which must include α in the acceptance

198
Handbook of Approximate Bayesian Computation
probability to ensure a theoretically correct method. When ρlazy > hlazy, we
eﬀectively estimate the ABC likelihood with a random variable that can be
two possible values:
0
with probability 1 −α
I(||s−sobs||≤h)
α
with probability α
.
The expected value of this random variable is I(||s −sobs|| ≤h), the desired
ABC likelihood. Thus, our implementation of the lazy ABC approach is an
instance of the pseudo-marginal method of Andrieu and Roberts (2009). The
drawback of this approach is that it inﬂates the variance of the ABC likelihood.
If ρlazy > hlazy and ρ ≤h, then the ABC likelihood gets inﬂated, meaning
that the MCMC algorithm may become stuck there for a large number of
iterations.
We also incorporate the early rejection strategy of Picchini and Forman
(2016). The approach of Picchini and Forman (2016) involves a simple re-
ordering of steps in MCMC ABC where it is possible to reject a proposed
parameter prior to simulating data. This approach does not alter the target
distribution when a uniform weighting function is applied, as we do here.
For this application, the lazy summary statistic is a scalar, so we choose
the absolute value to compute the distance between the observed and sim-
ulated lazy summary statistic in line 7 of Algorithm 7.2. For the actual
summary statistic, we use the discrepancy function in equation (7.5) at line 18
of Algorithm 7.2, with J set as the identity matrix for simplicity.
The results of using the LNA approximation and the ABC methods are
shown in Figure 7.2 (note that the ABC results are based on the lazy ABC
implementation). The results are compared with particle MCMC, which has
the true posterior as its limiting distribution. The LNA results tend to be
overprecise (especially for β), whereas the ABC results tend to be slightly
conservative. Note that we also ran ABC using the ﬁnal observation as the
(simple) summary statistic with h = 0, which also provides good results. The
posterior for β based on the simple summary is similar to that when the LNA
summary statistic is used, but is slightly less precise for γ.
In terms of lazy ABC we use the value of S(t) + I(t) at the end of the
recording time as the lazy summary statistic. In order to tune hlazy, we run
ABC with the summary statistic formed from the LNA approximation only
for a small number of iterations and recorded at each iteration the value of
the simulated lazy summary statistic and whether or not the proposal was
accepted or rejected. From Figure 7.2(c), it is evident that most of the accep-
tances based on the actual summary statistic occur when the lazy summary
statistic is between 70 and 110 (the observed value is 90). Many simulations do
not produce a lazy summary statistic within this range, so that early rejection
based on this lazy summary statistic seems like a good choice. Therefore, we
set the lazy discrepancy to be the absolute value between the last observed
and simulated data point and set hlazy = 20. Note that if a proposal does

ABC and Indirect Inference
199
Algorithm 7.2: MCMC ABC Algorithm Using a Lazy Summary
Statistic
1: Set C = 1
2: Set θ(0)
3: for i = 1 to T do
4:
Draw θ∗∼q(·|θ(i−1))
5:
Compute r = min

1,
π(θ∗)
Cπ(θ(i−1))

6:
if U(0, 1) < r then
7:
Simulate y ∼p(·|θ∗)
8:
Compute lazy ABC discrepancy ρlazy = ||slazy −sobs,lazy||
9:
if ρlazy > hlazy then
10:
if U(0, 1) < α then
11:
Continue and set Cprop = 1/α
12:
else
13:
Reject early: set θ(i) = θ(i−1) and go to the next iteration of the
MCMC algorithm
14:
end if
15:
else
16:
Set Cprop = 1
17:
end if
18:
Compute ABC discrepancy ρ = ||s −sobs||
19:
if ρ ≤h then
20:
θ(i) = θ∗and C = Cprop
21:
else
22:
θ(i) = θ(i−1)
23:
end if
24:
else
25:
θ(i) = θ(i−1)
26:
end if
27: end for
not satisfy hlazy, then we continue nonetheless with probability α = 0.1. This
seems like a reasonably conservative choice.
The lazy ABC approach resulted in a very similar acceptance rate to usual
ABC, 2.3% and 2.5%, respectively, however, the lazy ABC approach was about
3.5 times faster (roughly 16 hours down to 4.5 hours).
7.6.2
Spatial extremes example
If it exists, the limiting distribution of the maximum of a suitably normalised
sequence of independent and identically distributed (multivariate) random
variables is in the family of multivariate extreme value distributions (MEVDs).
Max-stable processes are the inﬁnite-dimensional generalisation of MEVDs.

200
Handbook of Approximate Bayesian Computation
−7.5
−7
−6.5
0
1
2
3
4
PMCMC
LNA
Simple
ABC
(a)
−4
−3
−2
0
0.5
1
1.5
2
PMCMC
LNA
Simple
ABC
(b)
0
20
40
60
80
100
120
0
1
Slazy
Accept/reject
(c)
FIGURE 7.2
Results for the epidemic example. Shown are the posterior distributions of
(a) log β and (b) log γ based on the particle MCMC approach (solid), LNA ap-
proximation (dash), ABC with the ﬁnal observation as the summary statistic
(dot), and ABC with the LNA parameter as a summary statistic (dot-dash).
Subﬁgure (c) shows the results of the pilot run where the x-axis is the value of
the lazy summary statistic, whereas the y-axis shows the ABC accept/reject
outcome based on the corresponding summary statistic formed by the LNA.
Consider a set of extremal observations yt
obs = (yt
obs(x1), . . . , yt
obs(xD)) ∈
RD collected at spatial locations x1, . . . , xD ∈X ⊂Rp at time t. Here, we
deﬁne an extremal observation as the maximum of a sequence of independent
and identically distributed random variables. Assume that T independent and
identically distributed extremal observations are taken at each location, in-
dexed by t = 1, . . . , T. We denote the full dataset as y1:T
obs , whereas all the data
at the ith location is y1:T
obs (xi). It is possible to model such data using spatial

ABC and Indirect Inference
201
models called max-stable processes [see, e.g. Schlather (2002) and Davison
et al. (2012)]. The max-stable process arises from considering the limiting
distribution of the maximum of a sequence of independent and identically
distributed random variables. Here, we follow Erhardt and Smith (2014) and
focus on a max-stable process where each marginal (i.e. for a particular spatial
location) has a unit-Fr´echet distribution with cumulative distribution function
G(z) = exp(−1/z). Additional ﬂexibility on each marginal can be introduced
via a transformation with location (μ), scale (σ), and shape (ξ) parameters.
Assuming that Z has a unit-Fr´echet distribution, the random variable:
Y = σ
ξ (Zξ −1) + μ,
has a generalised extreme value distribution. The ﬁrst step, then, is to esti-
mate the (μ, σ, ξ) parameters for each of the marginals separately based on
the T observations y1:T
obs (xi) at each location, i = 1, . . . , D, to transform the
data so that they, approximately, follow a unit-Fr´echet distribution. The data
following this transformation we denote as z1:T
obs (xi).
For simplicity, we consider a realisation of this max-stable process at a
particular time point, and thus drop the index t for the moment. Assume
that the corresponding random variable for this realisation is denoted Z =
(Z(x1), . . . , Z(xD)). Unfortunately the joint probability density function of Y
is diﬃcult to evaluate for D > 2. However, an analytic expression is available
for the bivariate cumulative distribution function of any two points, say xi
and xj (with realisations zi and zj), which depends on the distance between
the two points, h = ||xi −xj||:
G(zi, zj) = exp
	
−1
2
 1
zi
+ 1
zj
 
1 +

1 −2(ρ(h) + 1)
zizj
(zi + zj)2
1/2
,
(7.6)
where ρ(h) is the correlation of the underlying process. For simplicity, we
consider only the Whittle-Mat´ern covariance structure:
ρ(h) = c1
21−ν
Γ(ν)
 h
c2
ν
Kν
 h
c2

,
where Γ(·) is the gamma function and Kν(·) is the modiﬁed Bessel function of
the second kind. Note that there are several other options [see Davison et al.
(2012)]. In the above equation, 0 ≤c1 ≤1 is the sill, c2 > 0 is the range, and
ν > 0 is the smooth parameter. The sill parameter is commonly set to c1 = 1,
which we adopt here. Therefore, interest is in the parameter θ = (c2, ν). Here,
the prior on θ is set as uniform over (0, 20) × (0, 20).
A composite likelihood can be constructed (Padoan et al., 2010; Ribatet
et al., 2012) since there is an analytic expression for the bivariate likelihood
(i.e. the joint density of the response at two spatial locations), which can

202
Handbook of Approximate Bayesian Computation
be obtained from the cumulative distribution function in (7.6). The compos-
ite likelihood for one realisation of the max-stable process can be derived
by considering the product of all possible (unordered) bivariate likelihoods
(often referred to as the pairwise likelihood). Then another product can be
taken over the T independent realisations of the process. Ribatet et al. (2012)
utilise an adjusted composite likelihood directly within a Bayesian algorithm
to obtain an approximate posterior distribution for the parameter of the cor-
relation function. We investigate a diﬀerent approach and use the composite
likelihood parameter estimate as a summary statistic for ABC. The composite
likelihood can be maximised using the function ﬁtmaxstab in the SpatialEx-
tremes package in R (Ribatet et al., 2013). For simplicity, we refer to this
approach as ABC-cp [where cp denotes ‘composite parameter’ to be consis-
tent with Ruli et al. (2016), who refer to their method as ABC-cs (‘composite
score’)].
Our approach is compared with an ABC procedure in Erhardt and Smith
(2012), who use a diﬀerent summary statistic. The method ﬁrst involves com-
puting the so-called tripletwise extremal coeﬃcients. One extremal coeﬃcient
calculation involves three spatial points. Erhardt and Smith (2014) use esti-
mated tripletwise extremal coeﬃcients, which for three spatial locations i, j, k
can be obtained using:
1
T
t=1 1/ max(zt
obs(xi), zt
obs(xj), zt
obs(xk))
.
The
full
set
of
estimated
tripletwise
coeﬃcients
is
high-dimensional,
precisely
D
3

. The dimension of this summary is reduced by placing the ex-
tremal coeﬃcients into K groups, which are selected by grouping similar tri-
angles (formed by the three spatial locations) together. This grouping depends
only on the spatial locations and not the observed data. Erhardt and Smith
(2012) then use the mean of the extremal coeﬃcients within each group to
form a K dimensional summary statistic. For the ABC discrepancy function,
Erhardt and Smith (2012) consider the L1 norm between the observed and
simulated K group means. For brevity, we refer to this ABC approach as
ABC-ec, where ec stands for ‘extremal coeﬃcients’. The reader is referred to
Erhardt and Smith (2012) for more details. This method is implemented with
the assistance of the ABCExtremes R package (Erhardt, 2013).
There are several issues associated with ABC-ec. First, it can be com-
putationally intensive to determine the K groups. Second, there is no clear
way to choose the value of K. There is a trade-oﬀbetween dimensional-
ity and information loss, which may require investigation for each dataset
analysed. Third, only the mean within each group is considered, whereas
the variability of the extremal coeﬃcients within each group may be infor-
mative too. Finally, there is no obvious ABC discrepancy to apply. In con-
trast, the ABC-cp oﬀers a low-dimensional summary statistic (same size as
the parameter) and a natural way to compare summary statistics through

ABC and Indirect Inference
203
the Mahalanobis distance (using an estimated covariance matrix of what is
returned by ﬁtmaxstab). However, the tripletwise extremal coeﬃcients con-
sider triples of locations (and so should carry more information compared
with the pairwise approach of the composite likelihood), and also we ﬁnd
that computing the summary statistic of ABC-cp using ﬁtmaxstab is slower
than a C implementation of the tripletwise extremal coeﬃcients calcula-
tion (called into R using the Rcpp package (Eddelbuettel et al., 2011)). On
the other hand, ABC-cp avoids the expensive clustering of triangles into
groups.
For both approaches, an MCMC ABC algorithm was used with pro-
posal distributions carefully chosen to ensure a desired acceptance probability
based on the results of some pilot runs. ABC-ec was run for 2,000,000 it-
erations, and the ABC tolerance chosen resulted in an acceptance rate of
roughly 0.8%. Due to the extra computation associated with maximising the
composite likelihood at each iteration, ABC-cp was run for 100,000 itera-
tions, with an ABC tolerance that results in an acceptance probability of
roughly 8%.
Here, we re-analyse the data considered in Erhardt and Smith (2014),
which consists of the maximum annual summer temperature at 39 locations
in midwestern United States of America between 1895 and 2009. The data
at each spatial location are ﬁrstly transformed to approximately unit-Fr´echet
margins by ﬁtting a generalised extreme value distribution by maximum like-
lihood, and also taking into account a slight trend in the maximum summer
temperatures over time [see Erhardt and Smith (2014) for more details]. The
max-stable process is then ﬁtted to this transformed data using the ABC
approaches described earlier.
Contour plots of the bivariate posterior distributions for both the ABC-ec
and ABC-cp approaches are shown in Figure 7.3. Despite the much higher ac-
ceptance rate for ABC-cp, the resulting posterior for ABC-cp is substantially
more concentrated compared with the results from ABC-ec. Furthermore, it
can be seen that the posterior spatial correlation function is determined much
more precisely with ABC-cp.
Despite the encouraging results, a thorough simulation study is required
to conﬁrm the ABC-cp approach as a generally useful method for spatial
extremes applications. Erhardt and Smith (2012) note that very diﬀerent
parameter conﬁgurations can lead to a similar correlation structure, as demon-
strated by the ‘banana’ shape target in Figure 7.3. Therefore it may be ineﬃ-
cient to compare composite parameter summary statistics directly via the
Mahalanobis distance. Comparison through the composite likelihood itself
may perform better. Alternatively, if an expression for the composite score can
be derived, then the ABC-cs method of Ruli et al. (2016) may be a computa-
tionally convenient approach for these sorts of models. The ABC-cp method
implemented here relies on already available functions in existing R pack-
ages. Thus we leave the composite likelihood and score methods for further
research.

204
Handbook of Approximate Bayesian Computation
c2
ν
 0.05 
 0.1 
 0.15 
 0.2 
 0.25 
 0.3 
(a)
 0.5 
 1 
 1.5 
 2 
 2.5 
 3 
(b)
0
5
10
15
20
c2
0
5
10
15
20
0.2
0.4
0.6
0.8
1.0
ν
0.2
0.4
0.6
0.8
1.0
0
100
200
300
400
500
0.0
0.2
0.4
0.6
0.8
1.0
h
ρ(h)
(d)
0
100
200
300
400
500
0.0
0.2
0.4
0.6
0.8
1.0
h
ρ(h)
(c)
FIGURE 7.3
Posterior results for the spatial extremes example. Shown are the bivariate
posterior distributions of (c2, ν) based on the (a) ABC-ec and (b) ABC-cp
approaches. The posterior median and 95% credible interval of the spatial
correlation function are shown for the (c) ABC-ec and (d) ABC-cp methods.
7.7
Discussion
In this chapter, we provided a description of the indirect inference method
and also detailed links between various likelihood-free Bayesian methods
and indirect inference. As highlighted by the examples in this chapter
and other applications in articles such as Gallant and McCulloch (2009);
Drovandi et al. (2011); Gleim and Pigorsch (2013); Drovandi et al. (2015),

ABC and Indirect Inference
205
it is clear that the tools presented in this chapter can provide useful posterior
approximations in complex modelling scenarios.
During this chapter, we have also considered an extension of the reverse
sampler of Forneron and Ng (2016) using regression adjustment, an MCMC
implementation of the lazy ABC approach of Prangle (2016) and developed
an ABC approach for spatial extremes models using the parameter estimate
of a composite likelihood as the summary statistic.
A possible avenue for future research involves likelihood-free Bayesian
model choice. It is well-known that Bayes factors based on summary statistic
likelihoods do not correspond to those based on the full data likelihoods
(Robert et al., 2011). It is typically not clear how to choose a summary statis-
tic that is useful for model discrimination [although see, e.g. Didelot et al.
(2011); Estoup et al. (2012); Prangle et al. (2014); Martin et al. (2014); Lee
et al. (2015) for progress in this area]; a summary statistic that is suﬃcient
for the parameter of each model is still generally not suﬃcient for the model
indicator [see Marin et al. (2013)]. An interesting direction for further re-
search is to explore whether ﬂexible auxiliary models can assist in developing
likelihood-free methods that are useful for model selection in terms of Bayes
factors and posterior model probabilities.
Acknowledgements
The author is grateful to Kerrie Mengersen for the helpful comments and
suggestions on an earlier draft. The author was supported by an Australian
Research Council’s Discovery Early Career Researcher Award funding scheme
(DE160100741). The author is an Associate Investigator of the Australian
Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).
References
Andrieu, C. and G. O. Roberts (2009). The pseudo-marginal approach
for eﬃcient Monte Carlo computations. The Annals of Statistics 37(2),
697–725.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162(4), 2025–2035.
Becker, N. G. (1989). Analysis of Infectious Disease Data, Volume 33.
New York: Chapman & Hall/CRC Press.

206
Handbook of Approximate Bayesian Computation
Blum, M. G. B. (2010). Approximate Bayesian computation: A non-
parametric perspective. Journal of the American Statistical Associa-
tion 105(491), 1178–1187.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson (2013). A com-
parative review of dimension reduction methods in approximate Bayesian
computation. Statistical Science 28(2), 189–208.
Davison, A. C., S. A. Padoan, and M. Ribatet (2012). Statistical modeling of
spatial extremes. Statistical Science 27(2), 161–186.
Del Moral, P., A. Jasra, A. Lee, C. Yau, and X. Zhang (2015). The alive
particle ﬁlter and its use in particle Markov chain Monte Carlo. Stochastic
Analysis and Applications 33(6), 943–974.
Didelot, X., R. G. Everitt, A. M. Johansen, and D. J. Lawson (2011).
Likelihood-free estimation of model evidence. Bayesian Analysis 6(1),
49–76.
Dridi, R., A. Guay, and E. Renault (2007). Indirect inference and calibration
of dynamic stochastic general equilibrium models. Journal of Economet-
rics 136(2), 397–430.
Drovandi, C. C., A. N. Pettitt, and M. J. Faddy (2011). Approximate Bayesian
computation using indirect inference. Journal of the Royal Statistical Soci-
ety: Series C (Applied Statistics) 60(3), 503–524.
Drovandi, C. C., A. N. Pettitt, and A. Lee (2015). Bayesian indirect inference
using a parametric auxiliary model. Statistical Science 30(1), 72–95.
Drovandi, C. C., A. N. Pettitt, and R. A. McCutchan (2016). Exact and
approximate Bayesian inference for low integer-valued time series models
with intractable likelihoods. Bayesian Analysis 11(2), 325–352.
Eddelbuettel, D., R. Fran¸cois, J. Allaire, J. Chambers, D. Bates, and K. Ushey
(2011). Rcpp: Seamless R and C++ integration. Journal of Statistical Soft-
ware 40(8), 1–18.
Erhardt, R. (2013). ABCExtremes: ABC Extremes. R package version 1.0.
Erhardt, R. J. and R. L. Smith (2012). Approximate Bayesian comput-
ing for spatial extremes. Computational Statistics & Data Analysis 56(6),
1468–1481.
Erhardt, R. J. and R. L. Smith (2014). Weather derivative risk measures for
extreme events. North American Actuarial Journal 18, 379–393.
Estoup, A., E. Lombaert, J.-M. Marin, T. Guillemaud, P. Pudlo, C. P. Robert,
and J. Cournuet (2012). Estimation of demo-genetic model probabilities
with approximate Bayesian computation using linear discriminant analysis
on summary statistics. Molecular Ecology Resources 12(5), 846–855.

ABC and Indirect Inference
207
Fearnhead, P., V. Giagos, and C. Sherlock (2014). Inference for reaction net-
works using the linear noise approximation. Biometrics 70(2), 457–466.
Fearnhead, P. and L. Meligkotsidou (2004). Exact ﬁltering for partially
observed continuous time models. Journal of the Royal Statistical Society:
Series B (Statistical Methodology) 66(3), 771–789.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic ABC (with discus-
sion). Journal of the Royal Statistical Society: Series B (Statistical Method-
ology) 74(3), 419–474.
Forneron, J.-J. and S. Ng (2016). A likelihood-free reverse sampler of the
posterior distribution. In Essays in Honor of Aman Ullah, pp. 389–415.
Emerald Group Publishing.
Gallant, A. R. and R. E. McCulloch (2009). On the determination of general
scientiﬁc models with application to asset pricing. Journal of the American
Statistical Association 104(485), 117–131.
Gallant, A. R. and G. Tauchen (1996). Which moments to match? Economet-
ric Theory 12(4), 657–681.
Gleim, A. and C. Pigorsch (2013). Approximate Bayesian computation with
indirect summary statistics. Technical report, University of Bonn.
Golightly, A., D. A. Henderson, and C. Sherlock (2015). Delayed acceptance
particle MCMC for exact inference in stochastic kinetic models. Statistics
and Computing 25(5), 1039–1055.
Gourieroux, C., A. Monfort, and E. Renault (1993). Indirect inference. Journal
of Applied Econometrics 8(S1), S85–S118.
Heggland, K. and A. Frigessi (2004). Estimating functions in indirect infer-
ence. Journal of the Royal Statistical Society: Series B (Statistical Method-
ology) 66(2), 447–462.
Jiang, W. and B. Turnbull (2004). The indirect method: Inference based
on intermediate statistics – A synthesis and examples. Statistical Sci-
ence 19(2), 239–263.
Le Cam, L. (1956). On the asymptotic theory of estimation and testing
hypotheses. In Proceedings of the Third Berkeley Symposium on Mathe-
matical Statistics and Probability, Volume 1: Contributions to the Theory
of Statistics, pp. 129–156. Berkeley, CA: The Regents of the University of
California.
Lee, X. J., C. C. Drovandi, and A. N. Pettitt (2015). Model choice problems
using approximate Bayesian computation with applications to pathogen
transmission data sets. Biometrics 71(1), 198–207.

208
Handbook of Approximate Bayesian Computation
Li, J., D. J. Nott, Y. Fan, and S. A. Sisson (2017). Extending approximate
Bayesian computation methods to high dimensions via Gaussian copula.
Computational Statistics and Data Analysis, 106, 77–89.
Marin, J.-M., N. S. Pillai, C. P. Robert, and J. Rousseau (2013). Relevant
statistics for Bayesian model choice. Journal of the Royal Statistical Society:
Series B (Statistical Methodology) 76(5), 833–859.
Martin, G. M., B. P. M. McCabe, W. Maneesoonthorn, and C. P.
Robert (2014). Approximate Bayesian computation in state space models.
arXiv:1409.8363.
McFadden, D. (1989). A method of simulated moments for estimation of dis-
crete response models without numerical integration. Econometrica: Jour-
nal of the Econometric Society 57(5), 995–1026.
Monfardini, C. (1998). Estimating stochastic volatility models through indi-
rect inference. The Econometrics Journal 1(1), C113–C128.
Moores, M. T., C. C. Drovandi, K. L. Mengersen, and C. P. Robert (2015).
Pre-processing for approximate Bayesian computation in image analysis.
Statistics and Computing 25(1), 23–33.
Nott, D. J., Y. Fan, L. Marshall, and S. A. Sisson (2014). Approximate
Bayesian computation and Bayes linear analysis: Toward high-dimensional
ABC. Journal of Computational and Graphical Statistics 23(1), 65–86.
O’Neill, P. D. and G. O. Roberts (1999). Bayesian inference for partially
observed stochastic epidemics. Journal of the Royal Statistical Society:
Series A (Statistics in Society) 162(1), 121–129.
Padoan, S. A., M. Ribatet, and S. A. Sisson (2010). Likelihood-based infer-
ence for max-stable processes. Journal of the American Statistical Associa-
tion 105(489), 263–277.
Pauli, F., W. Racugno, and L. Ventura (2011). Bayesian composite marginal
likelihoods. Statistica Sinica 21, 149–164.
Picchini, U. and J. L. Forman (2016). Accelerating inference for diﬀusions
observed with measurement error and large sample sizes using approxi-
mate Bayesian computation. Journal of Statistical Computation and Simu-
lation 86(1), 195–213.
Prangle, D. (2016). Lazy ABC. Statistics and Computing, 26, 171–185.
Prangle, D., P. Fearnhead, M. P. Cox, P. J. Biggs, and N. P. French (2014).
Semi-automatic selection of summary statistics for ABC model choice.
Statistical Applications in Genetics and Molecular Biology 13(1), 67–82.

ABC and Indirect Inference
209
Price, L. F., C. C. Drovandi, A. Lee, and D. J. Nott (2018). Bayesian synthetic
likelihood. Journal of Computational and Graphical Statistics 27(1), 1–11.
Reeves, R. W. and A. N. Pettitt (2005). A theoretical framework for approxi-
mate Bayesian computation. In A. R. Francis, K. M. Matawie, A. Oshlack,
and G. K. Smyth (Eds.), Proceedings of the 20th International Workshop
on Statistical Modelling, Sydney, Australia, pp. 393–396.
Ribatet, M., D. Cooley, and A. C. Davison (2012). Bayesian inference from
composite likelihoods, with an application to spatial extremes. Statistica
Sinica 22, 813–845.
Ribatet, M., R. Singleton, and R Core team (2013). SpatialExtremes:
Modelling Spatial Extremes. R package version 2.0-0.
Robert, C. P., J.-M. Cornuet, J.-M. Marin, and N. S. Pillai (2011). Lack of con-
ﬁdence in approximate Bayesian computation model choice. Proceedings of
the National Academy of Sciences of the United States of America 108(37),
15112–15117.
Ruli, E., N. Sartori, and L. Ventura (2016). Approximate Bayesian compu-
tation using composite score functions. Statistics and Computing 26(3),
679–692.
Ryan, C., C. C. Drovandi, and A. N. Pettitt (2016). Optimal Bayesian ex-
perimental design for models with intractable likelihoods using indirect
inference applied to biological process models. Bayesian Analysis, 11(3),
857–883.
Schlather, M. (2002). Models for stationary max-stable random ﬁelds.
Extremes 5(1), 33–44.
Smith, Jr., A. A. (1993). Estimating nonlinear time-series models using
simulated vector autoregressions. Journal of Applied Econometrics 8(S1),
S63–S84.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466(7310), 1102–1104.


8
High-Dimensional ABC
David J. Nott, Victor M.-H. Ong, Y. Fan, and S. A. Sisson
CONTENTS
8.1
Introduction ......................................................
211
8.2
Direct ABC Approximation of the Posterior ....................
213
8.2.1
The marginal adjustment strategy ......................
214
8.2.2
A toy example ...........................................
215
8.2.3
Gaussian copula ABC ...................................
219
8.2.4
A multivariate g-and-k model for a foreign currency
exchange dataset ........................................
222
8.2.5
A non-linear multiple quantile regression analysis ......
226
8.3
ABC Approximation of the Sampling Distribution of Summary
Statistics .........................................................
229
8.3.1
A ﬂexible regression density estimator ..................
230
8.3.2
Analysis of stereological extremes .......................
232
8.4
Other Approaches to High-Dimensional ABC ...................
235
8.5
Discussion ........................................................
237
Acknowledgements .......................................................
237
References
...............................................................
238
8.1
Introduction
Other chapters in this volume have discussed the curse of dimensionality that
is inherent to most standard approximate Bayesian computation (ABC) meth-
ods. For a p-dimensional parameter of interest θ = (θ1, . . . , θp)⊤, ABC imple-
mentations make use of a summary statistic s = S(y) for data y ∈Y of
dimension q, where typically q ≥p. When either θ or s is high dimensional,
standard ABC methods have diﬃculty in producing simulated summary data
that are acceptably close to the observed summary sobs = S(yobs), for observed
data yobs. This means that standard ABC methods have limited applicability
in high-dimensional problems.
211

212
Handbook of Approximate Bayesian Computation
More precisely, write π(θ) for the prior, p(y|θ) for the data model, p(yobs|θ)
for the likelihood function, and π(θ|yobs) ∝p(yobs|θ)π(θ) for the intractable
posterior distribution. Standard ABC methods based on S(y) typically ap-
proximate the posterior as π(θ|yobs) ≈πABC,h(θ|sobs), where:
πABC,h(θ|sobs) ∝

Kh(∥s −sobs∥)p(s|θ)π(θ) ds,
(8.1)
and where Kh(∥u∥) is a kernel weighting function with bandwidth h ≥0.
A Monte Carlo approximation of (8.1) involves a kernel density estimation
of the intractable likelihood based on ∥s −sobs∥, the distance between sim-
ulated and observed summary statistics. As a result, the quality of the ap-
proximation decreases rapidly as the dimension of the summary statistic q
increases, as the distance between s and sobs necessarily increases with their
dimension, even setting aside the approximations involved in the choice of an
informative S(y).
Several authors (e.g. Blum, 2010; Barber et al., 2015) have given results
which illuminate the way that the dimension of the summary statistic q im-
pacts the performance of standard ABC methods. For example, Blum (2010)
obtains the result that the minimal mean squared error of certain kernel ABC
density estimators is of the order of N −4/(q+5), where N is the number of
Monte Carlo samples in the kernel approximation. Barber et al. (2015) con-
sider a simple rejection ABC algorithm where the kernel Kh is uniform and
obtain a similar result concerned with optimal estimation of posterior expec-
tations. Biau et al. (2015) extend the analysis of Blum (2010) using a nearest
neighbour perspective, which accounts for the common ABC practice of choos-
ing h adaptively based on a large pool of samples (e.g. Blum et al., 2013).
Regression adjustments (e.g. Blum, 2010; Beaumont et al., 2002; Blum and
Fran¸cois, 2010; Blum et al., 2013) are extremely valuable in practice for ex-
tending the applicability of ABC approximations to higher dimensions, since
the regression model has some ability to compensate for the mismatch between
the simulated summary statistics s and the observed value sobs. However, ex-
cept when the true relationship between θ and s is known precisely (allowing
for a perfect adjustment), these approaches may only extend ABC applicabil-
ity to moderately higher dimensions. For example, Nott et al. (2014) demon-
strated a rough doubling of the number of acceptably estimated parameters
for a ﬁxed computational cost when using regression adjustment compared
to just rejection sampling, for a simple toy model. Non-parametric regression
approaches are also subject to the curse of dimensionality, and the results
of Blum (2010) also apply to certain density estimators which include non-
parametric regression adjustments. Nevertheless, it has been observed that
these theoretical results may be overly pessimistic in practice for some prob-
lems. See Li and Fearnhead (2016) for some recent progress on theoretical
aspects of regression adjustment for uncertainty quantiﬁcation.

High-Dimensional ABC
213
This chapter considers the question of whether it may be possible to
conduct reliable ABC-based inference for high-dimensional models or when
the number of summary statistics q ≥p is large. As a general principle,
any methods that improve the eﬃciency of existing ABC techniques, such
as more eﬃcient Monte Carlo sampling algorithms, will as a result help
extend ABC methods to higher dimensions, simply because they permit a
greater inferential accuracy (measured by an eﬀectively lower kernel band-
width h) for the same computational overheads. However, there is a limit
to the extent to which these improvements can produce substantial high-
dimensional gains, as ultimately the bottleneck is determined by the ∥s−sobs∥
term within the kernel Kh embedded as part of the approximate posterior
πABC,h(θ|sobs).
Instead, we examine ways in which the reliance on the q-dimensional com-
parison ∥s −sobs∥can be reduced. One technique for achieving this is by
estimating low-dimensional marginal posterior distributions for subsets of θ
and then reconstructing an estimate of the joint posterior distribution from
these. This approach takes advantage of the fact that the marginal posterior
distribution πABC,h(θ(1)|sobs) =

πABC,h(θ|sobs)dθ(2) for some partition of
the parameter vector θ = (θ(1)⊤, θ(2)⊤)⊤can be much more accurately ap-
proximated using ABC directly as πABC,h(θ(1)|s(1)
obs), since the corresponding
necessary set of summary statistics s(1) ⊂s would be a lower-dimensional vec-
tor compared with the summary statistics s required to estimate the full joint
distribution πABC,h(θ|sobs). The same idea can also be implemented when ap-
proximating the likelihood function, where it is the sampling distribution of
the summary statistics p(s|θ) that is approximated based on low-dimensional
estimates for subsets of s.
The previous techniques are applicable for general ABC inference prob-
lems without any particular exploitable model structure and are the primary
focus of this chapter. For models with a known exploitable structure, it may
be possible to achieve better results (e.g. Bazin et al., 2010; Barthelm´e and
Chopin, 2014; White et al., 2015; Ong et al., 2018; Tran et al., 2017), and we
also discuss these brieﬂy.
8.2
Direct ABC Approximation of the Posterior
In this section, we consider direct approximation of the posterior distribu-
tion π(θ|sobs) given the observed summary statistics sobs. We ﬁrst describe
the marginal adjustment approach of Nott et al. (2014), in which the stan-
dard ABC approximation of the joint posterior distribution is improved by
replacing its univariate margins with more precisely estimated marginal ap-
proximations. These more precise marginal distributions are obtained by

214
Handbook of Approximate Bayesian Computation
implementing standard ABC methods to construct each univariate marginal
posterior separately, for which only low-dimensional summary statistics are re-
quired. These univariate marginal posteriors then replace the margins in the
original approximate joint posterior sample, via an appropriate replacement
of order statistics.
While the marginal adjustment can work well, we show an instructive toy
example where this strategy fails to adequately estimate the posterior depen-
dence structure. We subsequently discuss the Gaussian copula ABC approach
of (Li et al., 2017), which extends the marginal adjustment to improve esti-
mation of all pairwise dependences of the joint posterior, in combination with
the marginal estimates, by use of a meta-Gaussian distribution (Fang et al.,
2002). These ideas are illustrated by several examples.
8.2.1
The marginal adjustment strategy
The marginal adjustment method of Nott et al. (2014) is motivated by the
following observation. Suppose we wish to estimate accurately the univariate
marginal posterior distribution π(θj|sobs) of the parameter θj. If we can ﬁnd
a summary statistic, say s(j) ⊂s, that is nearly marginally suﬃcient for θj
in the data model p(y|θj), then π(θj|sobs) ≈π(θj|s(j)
obs), and this summary
statistic can be used to obtain marginal ABC posterior inferences about θj.
Because θj is univariate, the summary statistic s(j) can be low dimensional.
Accordingly, the marginal ABC model takes the form:
πABC,h(θj|s(j)
obs)
∝

Kh(∥s(j) −s(j)
obs∥)p(s(j)|θj)π(θj)ds(j)
=
 
Kh(∥s(j) −s(j)
obs∥)p(s|θ)π(θ−j|θj)π(θj)dθ−jds
where θ−j denotes the elements of θ excluding θj, and π(θ−j|θj) denotes the
conditional prior of θ−j given θj.
The idea of Nott et al. (2014) is to exploit the observation that marginal
posterior inferences are much easier in the ABC framework, as they only in-
volve a lower-dimensional subset of summary statistics, s(j) ⊂s. A sample
from the joint ABC posterior πABC,h(θ|sobs) is ﬁrst obtained, and then this
joint sample is adjusted so that its marginal distributions match those esti-
mated from the lower-dimensional ABC analyses, πABC,h(θj|s(j)
obs).
Write s = (s1, . . . , sq)⊤for the summary statistics used to approximate
the joint posterior πABC,h(θj|sobs) and s(j) = (s(j)
1 , . . . , s(j)
qj )⊤for the sum-
mary statistics used to approximate the marginal posterior distribution of θj,
πABC,h(θj|s(j)
obs). The marginal adjustment algorithm is then implemented as
follows:
1. Using standard ABC methods (including regression adjustments), ob-
tain an approximate sample from the joint posterior distribution
π(θ|sobs), θJ1, . . . , θJr say, based on the full summary statistic s.

High-Dimensional ABC
215
2. Using standard ABC methods, for each j = 1, . . . , p, obtain an
approximate
sample
from
the
univariate
marginal
distribution
π(θj|s(j)
obs), θM1
j
, . . . , θMr′
j
say, based on the lower-dimensional summary
statistic s(j).
3. Write θM
j (k) for the k-th order statistic of the (marginally estimated)
sample θM1
j
, . . . , θMr′
j
and θJ
j (k) for the k-th order statistic of the
(jointly estimated marginal) sample θJ1
j , . . . , θJr
j . Also write R(j, k) for
the rank of θJk
j
within the sample θJ1
j , . . . , θJr
j . Deﬁne
θAk = (θM
1 (R(1, k)), . . . , θM
p (R(p, k)))⊤.
Then θAk, k = 1, . . . , r, is a marginally adjusted approximate sample
from π(θ|sobs).
It is worth stating in words what is achieved by the previous step 3. The sam-
ples θAk, k = 1, . . . , r are the same as θJk, except that componentwise, the
order statistics θJ
j (k) have been replaced by the corresponding order statistics
θM
j (k). If we were to convert the samples θAk and θJk to ranks component-
wise, they would be exactly the same, and so the dependence structure in the
original samples θJk is preserved in θAk in this sense. However, the estimated
marginal distribution in θAk for θj is simply the estimated marginal distribu-
tion obtained from the samples θM1
j
, . . . , θMr′
j
, so that the adjusted samples
θAk give the more precisely estimated marginal distributions from the low-
dimensional analyses of step 2, while preserving the dependence structure
from the joint samples of step 1.
While it is true that the dependence structure obtained at step 1 may not
be well estimated due to standard ABC curse-of-dimensionality arguments, it
is also the case that the marginal adjustment improves the estimation of the
marginal posterior distributions. These ideas are illustrated in the following
example.
8.2.2
A toy example
Following Li et al. (2017), we let the data y = (y1, . . . , yp)⊤, p ≥2 follow a
N(θ, Ip) distribution, where θ = (θ1, . . . , θp)⊤is the parameter of interest and
Ip denotes the p × p identity matrix. The prior π(θ) is speciﬁed as the twisted
normal form (Haario et al., 1999):
π(θ) ∝exp
⎛
⎝−θ2
1
200 −(θ2 −bθ2
1 + 100b)2
2
−
p

j=3
θ2
j
⎞
⎠
where we set b = 0.1, and if p = 2 the 	p
j=3 θ2
j term is omitted. A con-
tour plot of π(θ) for p = 2 is shown in Figure 8.1. This is an interesting
example because the likelihood only provides location information about θ.

216
Handbook of Approximate Bayesian Computation
−15 −10
−5
0
5
10
15
20
−15 −10 −5
0
5
10
15
20
 0.05 
 0.05 
 0.1 
 0.1 
 0.15 
 0.2 
 0.25 
 0.3 
 0.35 
 0.4 
 0.45 
−15
−15
−10
−5
0
5
−10
−5
0
5
θ1
θ1
θ2
θ2
 0.01 
 0.02 
 0.03 
 0.1 
 0.05 
 0.05 
 0.1 
 0.1 
 0.15 
 0.15 
 0.2 
 0.2 
 0.25 
 0.25 
 0.3 
 0.3 
 0.35 
 0.35 
 0.4 
 0.4 
 0.45 
 0.5 
 0.6 
 0.65 
 0.85 
 0.005 
θ1
θ2
−5
0
5
10
15
−5
0
5
10
15
 0.01 
 0.02 
 0.08 
 0.05 
 0.05 
 0.05 
 0.1 
 0.1 
 0.1 
 0.15 
 0.15 
 0.2 
 0.2 
 0.25 
 0.25 
 0.3 
 0.005 
 0.01 
FIGURE 8.1
Contour plots of twisted normal prior distribution π(θ) (grey dashed lines),
likelihood (solid grey), and posterior (solid black) for p = 2. Middle and
right panels illustrate the case when yobs = (−10, 0)⊤and yobs = (10, 0)⊤,
respectively.
The dependence structure in the posterior comes mostly from the prior, and
the association between θ1 and θ2 changes direction in the left and right tails
of the prior (Figure 8.1). So the posterior dependence changes direction de-
pending on whether the likelihood locates the posterior in the left or right
tail of the prior. This feature makes it diﬃcult for standard regression adjust-
ment methods, which merely translate and scale particles [e.g. generated from
(s, θ) ∼p(s|θ)π(θ)], to work in high dimensions.
Figures 8.2 and 8.3 show what happens in an analysis of this example with
p = 5 and p = 50, respectively. Four ABC approximation methods are consid-
ered with observed data yobs = (10, 0, ..., 0)⊤. The contour plots of the bivari-
ate posterior estimates π(θ1, θ2|sobs) are represented by solid lines, while the
contour plot of the true bivariate margin is represented by grey dashed lines.
For both ﬁgures, panel (a) shows the estimates obtained via standard rejection

High-Dimensional ABC
217
(a)
8
9
10
11
12
−2
−1
0
1
2
(b)
θ1
8
9
10
11
12
θ1
θ2
−2
−1
0
1
2
θ2
(c)
8
9
10
11
12
−2
−1
0
1
2
(d)
θ1
8
9
10
11
12
θ1
θ2
−2
−1
0
1
2
θ2
FIGURE 8.2
Contour plots of the (θ1, θ2) margin of various ABC posterior approxima-
tions for the p = 5 dimensional model π(θ|sobs) are represented by the black
lines. True contours for the bivariate margins are represented by the grey
dashed lines. The diﬀerent ABC approximations approaches are (a) rejection
sampling, (b) rejection sampling with marginal adjustment, (c) rejection sam-
pling with regression adjustment, and (d) rejection sampling with regression
and marginal adjustment.
ABC, while panels (b), (c), and (d) show estimates obtained after marginal,
linear regression and both linear regression and marginal adjustment respec-
tively. Note the regression adjustment step is performed after the rejection
sampling stage and before the marginal adjustment.
For the case when p = 5 (Figure 8.2), rejection sampling alone captures the
correlation between θ1 and θ2, but the univariate margins are too dispersed.
Performing a marginal adjustment following rejection sampling is not good
enough, as it only corrects the margin to the right scale and is not able to
recover dependence structure. On the other hand, rejection sampling with
linear regression adjustment is able to give a good approximation to the true
posterior. Performing a subsequent marginal adjustment (Figure 8.2d) shows
no further visual improvement.

218
Handbook of Approximate Bayesian Computation
−10
−5
0
5
10
15
−10
−5
0
5
10
(a)
θ1
θ1
θ2
θ2
8
9
10
11
12
−2
−1
0
1
2
(b)
θ1
θ2
8
9
10
11
12
−2
−1
0
1
2
(d)
θ1
θ2
8
9
10
11
12
−2
−1
0
1
2
(c)
FIGURE 8.3
Contour plots of the (θ1, θ2) margin of various ABC posterior approxima-
tions for the p = 50 dimensional model π(θ|sobs) are represented by the black
lines. True contours for the bivariate margins are represented by the grey
dashed lines. The diﬀerent ABC approximations approaches are (a) rejection
sampling, (b) rejection sampling with marginal adjustment, (c) rejection sam-
pling with regression adjustment, and (d) rejection sampling with regression
and marginal adjustment.
The example for p = 50 (Figure 8.3) shows both the strengths and limita-
tions of the marginal and regression adjustment strategies. It is very clear
that standard rejection ABC estimates do not seem to be using much of
the information given by the likelihood, as the posterior estimate follows the
shape of the prior distribution π(θ). Performing either regression or marginal
adjustment centres the estimates on the right location, but the shape of the
contour plots for the adjustments are incorrect. Moreover, applying marginal
adjustment after regression adjustment corrects the univariate margins well,
but does not recover the dependence structure. In this example, all four
approaches are not able to recover the dependence structure of the true
bivariate posterior. It is worth noting in this example that for the normal
case with b = 0, the marginal adjustment approach works very well even in
high dimensions.

High-Dimensional ABC
219
This example shows some of the limitations of the marginal adjustment
strategy. One possible approach to improve the estimation of the dependence
structure (not discussed by Nott et al., 2014) is to use the marginal adjustment
on a reparameterised parameter vector θ∗, where the margins of θ∗account
for the dependence structure in θ, while θ∗
i and θ∗
j , i ̸= j remain approxi-
mately independent. This approach would require some prior knowledge of
the dependence structure.
Since the key idea of the marginal adjustment approach is to build up
a more accurate approximation of the joint posterior from estimates of uni-
variate marginal posterior distributions, it is natural to ask if it is possible
to consider estimation of marginal posterior distributions of dimension larger
than one and to use these to help estimate the joint dependence structure of
π(θ|sobs) more accurately.
8.2.3
Gaussian copula ABC
One way to implement this idea is the Gaussian copula ABC method of Li et al.
(2017). Suppose that C(u) = P(U1 ≤u1, . . . , Up ≤up) is the distribution func-
tion of a random vector U = (U1, . . . , Up), where the marginal distribution of
each Uj ∼U(0, 1) is uniform. Then C(u) is called a copula. Multivariate dis-
tributions can always be written in terms of a copula, and their marginal dis-
tribution functions, which is an implication of Sklar’s theorem (Sklar, 1959).
This allows for a decoupling of the modelling of marginal distributions and the
dependence structure of a multivariate distribution. One useful type of copula
derives from a multivariate Gaussian distribution. Suppose that η ∼N(0, C)
is a p-dimensional multivariate Gaussian random vector, where C is a correla-
tion matrix. The distribution of U = (Φ(η1), . . . , Φ(ηp))⊤, where Φ(·) denotes
the standard normal distribution function is then a copula. This kind of cop-
ula, called a Gaussian copula, characterises the dependence structure of a
multivariate Gaussian distribution, and it is parametrised by the correlation
matrix C.
Suppose now that we further transform U as γ = (F −1
1
(U1), . . . , F −1
p
(Up))⊤,
where F1(·), . . . , Fp(·) are distribution functions with corresponding density
functions f1(·), . . . , fp(·). The components of γ then have the marginal den-
sities f1(·), . . . , fp(·), respectively, and the dependence structure is being
described by the Gaussian copula with correlation matrix C. Clearly, if the
densities fj(·), j = 1, . . . , p are themselves univariate Gaussian, then γ is mul-
tivariate Gaussian. A distribution constructed from a Gaussian, copula and
given marginal distributions is called meta-Gaussian (Fang et al., 2002), and
its density function is:
h(γ) = |C|−1/2 exp

1
2z⊤(I −C−1)z

p

j=1
fj(γj),
where z = (z1, . . . , zp)⊤, and zj = Φ−1(Fj(γj)).

220
Handbook of Approximate Bayesian Computation
Li et al. (2017) considered using a meta-Gaussian distribution to approxi-
mate the posterior distribution π(θ|sobs) in ABC. It is easily seen that a meta-
Gaussian distribution is determined by its bivariate marginal distributions, so
that if we are prepared to accept a meta-Gaussian approximation to the joint
posterior distribution in a Bayesian setting, then it can be constructed based
on bivariate posterior marginal estimates. Asymptotically, the posterior will
tend to be Gaussian, but a meta-Gaussian approximation may work well even
when we are far from this situation since it allows for ﬂexible estimation of the
marginal distributions. As with the marginal adjustment, since the bivariate
marginal posterior distributions can be estimated using low-dimensional sum-
mary statistics, this can help to circumvent the ABC curse of dimensionality
in estimation of the joint posterior dependence structure.
As before, write s(j) for the statistics that are informative for ABC esti-
mation of the univariate posterior marginal π(θj|sobs), and now write s(i,j)
for the summary statistics informative for ABC estimation of the bivariate
posterior margin π(θi, θj|sobs), i ̸= j. Construction of the Gaussian copula
ABC approximation to the posterior π(θ|sobs) proceeds as follows:
1. Using standard ABC methods (including regression adjustments), for
each j = 1, . . . , p, obtain an approximate sample from the univariate
marginal distribution π(θj|s(j)
obs), θU1
j , . . . , θUr
j
say, based on the lower-
dimensional summary statistic s(j). Use kernel density estimation to
construct an approximation ˆgj(θj) to π(θj|s(j)
obs).
2. Using standard ABC methods, for i = 1, . . . , p −1 and j = i + 1, . . . , p,
obtain an approximate sample from the bivariate marginal distribu-
tion π(θi, θj|s(i,j)
obs ), (θBj1
i
, θBi1
j
), . . . , (θBjr
i
, θBir
j
) say, based on the low-
dimensional summary statistics s(i,j).
3. Write R(i, j, k) as the rank of θBjk
i
within the sample θBj1
i
, . . . , θBjr
i
.
With this notation R(j, i, k), j > i, is the rank of θBik
j
within the sample
θBi1
j
, . . . , θBir
j
. Estimate Cij by ˆCij, the sample correlation between the
vectors:

Φ−1

R(i, j, 1)
r + 1

, Φ−1

R(i, j, 2)
r + 1

, . . . , Φ−1

R(i, j, r)
r + 1
⊤
and

Φ−1

R(j, i, 1)
r + 1

, Φ−1

R(j, i, 2)
r + 1

, . . . , Φ−1

R(j, i, r)
r + 1
⊤
.
4. Construct the Gaussian copula ABC approximation of π(θ|sobs) as
the meta-Gaussian distribution with marginal distributions ˆgj(θj),
j
=
1, . . . , p (step 1), and Gaussian copula correlation matrix
ˆC = [ ˆCij]i,j=1,...,p, where ˆCij, j > i, is as in step 2, ˆCji = ˆCij and ˆCii = 1.

High-Dimensional ABC
221
While the estimated correlation matrix ˆC can fail to be positive deﬁnite using
this procedure (although this did not occur in our analyses), methods to ad-
just this can be easily implemented (e.g. Løland et al., 2013). Note that by
using the approximate posterior sample from π(θi, θj|s(i,j)
obs ) from step 2 and the
ﬁtted (bivariate) copula model for the pair, it is possible to investigate whether
the Gaussian copula dependence structure at least represents the true bivariate
posterior dependence structure well (though not the full multivariate depen-
dence structure). This can be supplemented by application speciﬁc goodness
of ﬁt checking of posterior predictive densities based on the joint copula ap-
proximation.
In the twisted normal toy example of Section 8.2.2, the copula strategy
can succeed where the marginal adjustment strategy alone fails. Similar to
Figure 8.3, Figure 8.4 illustrates both the bivariate estimates of π(θ1, θ2|sobs)
based on the Gaussian copula ABC approximation (black solid lines) and the
true margins (grey dashed lines) for the p = 50 dimensional model. From the
contour plots, the ABC copula approximation is able to produce estimates
largely similar to the true bivariate margins, in stark contrast to the marginal
adjustment alone in Figure 8.3. Thus, in this example where standard ABC
sampling with regression and/or marginal adjustment fails, the copula strat-
egy succeeds.
In order to investigate the performance of each ABC posterior estimation
method more precisely, we follow Li et al. (2017) and vary the dimension of
8.5
9.0
9.5
10.0
10.5
11.0
11.5
−2
−1
0
1
2
Copula
θ1
θ2
FIGURE 8.4
Contour plots of the (θ1, θ2) margin of the Gaussian copula ABC posterior
approximation of the p = 50 dimensional model π(θ|sobs) (black lines). The
true contours of π(θ1, θ2|sobs) are represented by grey dashed lines.

222
Handbook of Approximate Bayesian Computation
the model, p, from 2 to 250. Table 8.1 shows the mean estimated Kullback–
Leibler (KL) divergence between the true bivariate margin π(θ1, θ2|sobs) and
the bivariate margin of the full ABC posterior approximation based on 100
replicate approximations, for all ﬁve approaches.
Observe that when the dimension p increases, the performance of the stan-
dard rejection ABC approach deteriorates. Adopting any of the adjustment
strategies improves the overall performance, but the estimated KL divergences
still increase with dimension p up to ﬁxed limits. This suggests that if accurate
estimation of the posterior dependence structure is important, then regression
and marginal adjustment strategies alone may be limited to low dimensional
models. From Table 8.1 it is clear that Gaussian copula ABC outperforms
all other methods in terms of KL divergence, and its performance does not
deteriorate with increasing dimension, p. This is not surprising, as the Gaus-
sian copula ABC approximation is constructed from bivariate estimates of
π(θ1, θ2|sobs) and is therefore able to capture the dependence structure of all
bivariate pairs of the full posterior distribution π(θ|sobs).
In the following sections, we implement Gaussian copula ABC for two
real data analyses: an analysis of multivariate currency exchange data, and
simultaneous estimation of multiple quantile regressions.
8.2.4
A multivariate g-and-k model for a foreign currency
exchange dataset
The g-and-k distribution (Rayner and MacGillivray, 2002) is a ﬂexible model
for univariate data. It is typically speciﬁed through its quantile function:
Q(p|A, B, g, k) = A + B

1 + c1 −exp{−gz(p)}
1 + exp{−gz(p)}

(1 + z(p)2)kz(p),
(8.2)
where A, B > 0, g, and k > −0.5 are parameters, respectively, controlling
location, scale, skewness, and kurtosis of the distribution. The parameter c
is conventionally ﬁxed at 0.8 (resulting in k > −0.5), and z(p) denotes the
p-quantile of the standard normal distribution. Many distributions can be
recovered or well approximated for appropriate values of A, B, g, and k (such
as the normal when g = k = 0). Despite its attractive properties as a model,
inference using the g-and-k distribution is challenging since the density, given
by the derivative of the inverse of the quantile function, has no closed form.
However, since simulation from the model is trivial by transforming uniform
variates on [0, 1] through the quantile function, an ABC implementation is one
possible inferential approach. This idea was ﬁrst explored by Peters and Sisson
(2006) and Allingham et al. (2009). Here, we consider a multivariate extension
of the model developed by Drovandi and Pettitt (2011). This model has a
univariate g-and-k distribution for each margin, and the dependence structure
is speciﬁed through a Gaussian copula. Note that this use of a Gaussian copula

High-Dimensional ABC
223
TABLE 8.1
Estimated Kullback–Leibler Divergence of the (θ1, θ2) Margin of Various ABC Posterior Approximation
to π(θ1, θ2|s(1,2)
obs ). Numbers in Parentheses Represent Standard Errors of Mean Divergences over 100 Replications
Rejection
Regression then
p
Only
Marginal
Regression
Marginal
Copula ABC
2
0.058 (<0.001)
0.040 (<0.001)
0.043 (<0.001)
0.035 (<0.001)
0.039 (<0.001)
5
0.807 (<0.001)
0.053 (0.001)
0.613 (0.002)
0.037 (<0.001)
0.040 (<0.001)
10
1.418 (0.002)
0.100 (0.001)
1.078 (0.002)
0.061 (0.001)
0.040 (<0.001)
15
1.912 (0.002)
0.292 (0.002)
1.229 (0.003)
0.202 (0.001)
0.039 (<0.001)
20
2.288 (0.002)
0.450 (0.001)
1.280 (0.003)
0.292 (0.001)
0.039 (<0.001)
50
3.036 (0.003)
0.520 (0.002)
1.474 (0.009)
0.335 (0.001)
0.040 (<0.001)
100
3.362 (0.002)
0.524 (0.002)
1.619 (0.013)
0.341 (0.001)
0.039 (<0.001)
250
3.663 (0.003)
0.515 (0.002)
1.737 (0.015)
0.344 (0.001)
0.039 (<0.001)

224
Handbook of Approximate Bayesian Computation
to describe the dependence structure in the data model is distinct from the use
of a Gaussian copula to approximate the dependence structure of the posterior
distribution.
Suppose that the data are n independent multivariate realisations y =
(y1, . . . , yn), where yi = (yi
1, . . . , yi
q)⊤. We assume that marginally, each yi
j
i = 1, . . . , n follows a g-and-k distribution with parameters (Aj, Bj, gj, kj),
j = 1, . . . , q. Gaussian copula ABC approximates the joint distribution of yi by
a meta-Gaussian distribution, with Gaussian copula correlation matrix C. For
a q-dimensional data model, there are 4q marginal parameters and q(q −1)/2
distinct parameters in the correlation matrix, giving p = q(q+7)/2 parameters
in total. We consider an analysis of log daily returns for q = 16 currencies
(resulting in p = 184 parameters) versus the Australian dollar for 1,757 trading
days covering the period 1st January 2007 to 31st December 2013 (Reserve
Bank of Australia, 2014).
As a prior on C, we adopt the distribution obtained by sampling V ∼
Wishart(Iq, q) and then rescaling V to be a valid correlation matrix with
1’s on the diagonal. The priors on A, B, g, and k for each marginal are
independent and uniform over the parameter support, although we adopted
uniform distributions with ranges of [−0.1, 0.1], [0, 0.05], [−1, 1], and [−0.2, 0.5]
for Aj, Bj, gj, and kj to produce samples (s, θ) proportional to p(s|θ)π(θ),
but restricted to a region of high posterior density following an initial pilot
analysis (see e.g. Fearnhead and Prangle, 2012).
Following the strategy of Li et al. (2017), the following summary statis-
tics were considered informative for each marginal parameter: writing Lkj,
k = 1, 2, 3 for the quantiles and Okj, k = 1, . . . , 7 for the octiles of y1
j , . . . , yn
j ,
the marginally informative summary statistics were chosen as L2j for Aj,
(L3j −L1j, (E7j −E5j + E3j −E1j)/(L3j −L1j))⊤for Bj, (L3j + L1j −2L2j)/
(L3j −L1j) for gj, and (E7j −E5j +E3j −E1j)/(L3j −L1j) for kj. These sum-
mary statistic choices were guided by similar summary statistics in Drovandi
and Pettitt (2011), and preliminary analyses to determine which sets of the
distinct summaries were marginally informative for individual parameters. For
pairs of parameters, the summary statistics for individual parameters were
simply combined. For the correlation parameters in the Gaussian copula, we
follow Drovandi and Pettitt (2011) and use the robust normal scores correla-
tion coeﬃcient for the marginal summary statistic.
Contour plots of various estimates of the bivariate (B1, k1) poste-
rior marginal distribution using ABC rejection sampling are illustrated in
Figure 8.5. The top panels show estimates using the full (p-dimensional) vec-
tor of summary statistics with (a) regression adjustment and (b) marginal
adjustment, respectively. The performance of each approach individually is
poor as the distributions do not exhibit the more accurately estimated de-
pendence structures observed in the remaining panels. These estimates are
based on ABC rejection sampling with both marginal and regression adjust-
ments, using (c) the full vector of summary statistics and (d) the marginally

High-Dimensional ABC
225
0.0065 0.0070 0.0075 0.0080
0.00
0.05
0.10
0.15
0.20
(a)
0.0065 0.0070 0.0075 0.0080
0.00
0.05
0.10
0.15
0.20
(b)
0.0065 0.0070 0.0075 0.0080
0.00
0.05
0.10
0.15
0.20
(c)
B1
B1
B1
k1
k1
k1
B1
B1
k1
k1
0.0065 0.0070 0.0075 0.0080
0.00
0.05
0.10
0.15
0.20
(d)
0.0065 0.0070 0.0075 0.0080
0.00
0.05
0.10
0.15
0.20
(e)
FIGURE 8.5
Contour plots of the (B1, k1) margin of rejection sampling-based ABC
posterior approximations to the multivariate g-and-k model. Top panels show
estimates using (a) regression adjustment, (b) marginal adjustment, and
(c) both regression then marginal adjustment, using the full vector of summary
statistics. Panel (d) shows the same as (c), but using the lower dimensional
vector of summary statistics informative for (B1, k1). Panel (e) shows the
estimate for the Gaussian copula ABC approximation.
informative summary statistics for (B1, k1). The similarity between pan-
els (c) and (d) indicates that the marginally informative summary statis-
tics are indeed highly informative for the parameter pair (B1, k1). Finally,
panel (e) illustrates the Gaussian copula ABC approximation. The similarity
between panels (d) and (e) indicates that the copula model provides an
excellent approximation of the bivariate posterior marginal distribution.

226
Handbook of Approximate Bayesian Computation
8.2.5
A non-linear multiple quantile regression analysis
Quantile regression can provide a robust alternative to standard mean regres-
sion. Model estimates obtained at multiple quantile levels can also provide a
more complete picture of the conditional distribution between predictor and
response. For a regression with a single covariate x, and response y, the linear
model corresponding to the τ-th quantile, Qy(τ|x), is given by:
Qy(τ|x) = ατ + βτx,
where the coeﬃcients ατ and βτ depend on the quantile level, τ ∈(0, 1). Stan-
dard methods ﬁt quantile regressions independently for each quantile level,
which can lead to problems of quantiles crossing and a lack of borrowing of
information across the quantile levels (Rodrigues and Fan, 2017).
Bayesian approaches to quantile regression require the speciﬁcation of a
likelihood. However, exact and tractable likelihood functions are often not
available for these models. Quantile regression requires the inversion of many
conditional quantile distributions, which are often not analytically available,
although numerical grid search can be used (e.g. Reich et al., 2010; Tokdar
and Kadane, 2012). However, in the presence of larger datasets, numerical
grid searches can become computationally prohibitive, see for example Reich
et al. (2010) who suggest using approximations as an alternative.
We consider a dataset for analysing immunodeﬁciency in infants. In the
search for reference ranges to help diagnose infant immunodeﬁciency, Isaacs
et al. (1983) measured the serum concentration of immunoglobulin-G (IgG) in
298 pre-school children. We are interested in estimating the IgG conditional
quantiles at the levels τ = 0.1, 0.2, 0.3, 0.7, 0.75, 0.8, 0.95. A quadratic model
in age (x) is used to ﬁt the data due to the expected smooth change of IgG
with age, so that:
Qy(τ|x) = ατ + βτx + ητx2.
(8.3)
Figure 8.6 illustrates this dataset. The black lines show the separately ﬁtted
regression lines for the diﬀerent quantile levels, based on a frequentist estima-
tor using the quantreg package in R (Koenker, 2005). Since these curves are
ﬁtted separately, no correlation is assumed between the quantile curves, and
for close quantile levels τ, the ﬁtted quantile estimates can easily cross each
other. In practice, strong correlations can exist between curves close to each
other, and the true quantile levels will not cross.
We follow the linearly interpolated likelihood function approach of Feng
et al. (2015) as a data model p(s|θ), while extending their quantile function
Qy(r|x) to contain more than one predictor as in (8.3). For each observed
covariate xobs,i, i = 1, . . . , n, a synthetic data point yi can be obtained via:
yi = Qy(τj|xobs,i) + Qy(τj+1|xobs,i) −Qy(τj|xobs,i)
τj+1 −τj
(ui −τj),

High-Dimensional ABC
227
1
2
3
4
5
6
0
5
10
15
20
Immunoglobulin-G concentration data
Age
Serum IgG Concentration
FIGURE 8.6
The immunoglobulin-G dataset. The ﬁtted lines correspond to the classical
quantile estimator at the quantile levels τ = 0.1, 0.2, 0.3, 0.7, 0.75, 0.8, 0.95.
where ui ∼U(0, 1), where j is determined so that τj < ui < τj+1, and where
Qτ(y|x) is the model (8.3), which depends on parameters ατ, βτ, and ητ.
If ui < τ1, yi is generated from a normal distribution centred on ¯yobs, with
standard deviation three times the sample standard deviation of yobs, and
truncated below Qy(τ1|x). Similarly, if ui > τm, we simulate from the same dis-
tribution except that it is truncated above Qy(τm|x). The parameters ατ, βτ,
and ητ are sampled from multivariate Gaussian prior distributions π(θ), with
mean vector and covariance matrix based on the estimates obtained using
quantreg. This prior is constrained to satisfy the quantile monotonicity con-
dition so that the ﬁtted quantile regression lines do not cross.
The full vector of summary statistics is constructed as:
s = S(y) = (ˆατ1, . . . , ˆατm, ˆβτ1, . . . , ˆβτm, ˆητ1, . . . , ˆητm,
puτ1, . . . , puτm, plτ1, . . . , plτm, q1(y), . . . , q100(y))⊤,
where ˆατ, ˆβτ, and ˆητ are the independent frequentist estimators for ατ, βτ,
and ητ at quantile level τ, puτ is the proportion of data points above the
τth quantile curve, plτ is the proportion of data points below the τth quan-
tile curve, and q1(y), . . . , q100(y) are the 100 equally spaced quantiles of the
data y. The summary statistics for ατi are ˆατi, puτi, plτi, and the closest 20
quantiles q1(y), . . . , q100(y) to the level τi. Similarly, for βτj, the marginally in-
formative summary statistics will be ˆβτj, puτj, plτj, and the closest 20 quantiles

228
Handbook of Approximate Bayesian Computation
q1(y), . . . , q100(y) to the level τj; and so on. Then for the summaries of the
bivariate margin, (ατi, βτj), we concatenate the two sets of summaries.
The following analysis is based on N = 1,000,000 samples (s(ℓ), θ(ℓ)) ∼
p(s|θ)π(θ), ℓ= 1, . . . , N. We specify the smoothing kernel Kh(·) as uniform
over the range (−h, h) and determine h as the 0.001 quantile of the Euclidean
distances between observed and simulated summary statistics. Our model si-
multaneously ﬁts the seven quantile levels shown in Figure 8.6, resulting in
a p = 21 dimensional model with q = 135 total summary statistics. Note
that with the application of post-hoc adjustments, monotonicity of the con-
ditional quantiles may not be preserved. If this occurs, the oﬀending samples
may simply be discarded, although a preferable solution is the development
of adjustments that ﬂexibly respect constraints.
Figure 8.6 (left panel) shows the mean predicted conditional quantile esti-
mates for the levels τ = 0.1, 0.3, 0.75, 0.95 based on ﬁtting the seven quantile
level model. Although the true quantile curves are not known here, we might
expect the independently ﬁtted frequentist estimates to provide a reasonable
guide to the truth in this analysis. When the sample size is reasonably large
(here n = 298), the frequentist approach can produce estimators with good
properties (such as a reduced chance for neighbouring quantiles to overlap as
n gets large). As a result, in the current example, the frequentist estimates
should be expected to produce similar results to the Bayesian approaches,
particularly in the non-extreme regions where there is more data. However,
the Bayesian analyses naturally enforce non-crossing of quantiles, and so
are preferable for this reason, in spite of the approximate posterior. Results
from three diﬀerent ABC variants are shown in Figure 8.7 (left panel). For
most quantile levels there are small diﬀerences between the marginal uni-
variate quantile estimates, although quantile non-crossing is enforced in each
of the Bayesian estimates. For the lower τ = 0.1 quantile, where data are
more scarce, increasing the quality of the ABC posterior approximation from
standard rejection ABC (dashed line) to regression adjusted ABC (dot-dash
line) to regression and marginally adjusted ABC (dotted line), produces a
marginal quantile that is increasingly close to the frequentist estimate and
which roughly partitions 10% of the data below it. This suggests that there
is some ABC approximation error (although this is less obvious in the up-
per τ = 0.95 quantile), but that this is less apparent the better the ABC
approximation becomes.
In the case of these marginal quantile estimates, Gaussian copula ABC pro-
duces quantile estimates (not shown) that are highly similar to the regression
and marginally adjusted estimates (dotted line). However, the real diﬀerences
here are in the quality of the dependence structure of the ABC posterior.
Figure 8.7 (right panel) shows the correlation in the estimated posterior
bivariate margins of (αi, αj), (βi, βj), and (ηi, ηj) for i ̸= j when using Gaus-
sian copula ABC (x-axis) and standard ABC with regression and marginal
adjustment using the full vector of summary statistics (y-axis). Here, it is evi-
dent that Gaussian copula ABC is able to capture correlations in the bivariate

High-Dimensional ABC
229
1
2
3
4
5
6
0
5
10
15
20
Immunoglobulin-G Concentration data
Age
Serum IgG concentration
qr
abc
abc reg
abc marg
0.0
0.1
0.2
0.3
0.4
0.5
0.00
0.05
0.10
0.15
Posterior correlations
Bivariate correlation
Marginal adjustment correlation
FIGURE 8.7
Left panel: Posterior mean predictive conditional quantile estimates using the
full vector of summary statistics based on standard ABC (dashed line), re-
gression adjusted ABC (dot dash line), and both regression and marginally
adjusted ABC, for the quantiles τ = 0.1, 0.2, 0.3, 0.7, 0.75, 0.8, 0.95. For clarity,
only τ = 0.1, 0.3, 0.75, 0.95 level quantiles are shown. Right panel: Estimated
correlation of posterior margins π(αi, αj|sobs) (dot), π(βi, βj|sobs) (triangle),
and π(ηi, ηj|sobs) (plus) i ̸= j, for regression and marginally adjusted ABC
with the full vector of summary statistics (y-axis), against that for Gaussian
copula ABC (x-axis).
margins that are missed by regular ABC, even when using the univariate
marginal adjustment. The quality of the posterior approximation will be vital
when considering analyses that critically depend on full, multiple, quantile
inference. This lends support to the Gaussian copula approach as a viable
ABC model approximation able to capture much of the bivariate dependence
structure of π(θ|sobs).
8.3
ABC Approximation of the Sampling Distribution
of Summary Statistics
An alternative to direct ABC approximation of the posterior distribution
π(θ|sobs) is to instead approximate the sampling distribution of summary
statistics p(s|θ) (Leuenberger and Wegmann, 2010; Fan et al., 2013), thereby
approaching the intractable likelihood problem from the more usual ABC
conditional density estimation perspective. The resulting estimated density is
then an analytically tractable approximation of the likelihood function for a

230
Handbook of Approximate Bayesian Computation
Bayesian analysis using conventional Bayesian computational tools. Such ap-
proaches may be preferable in problems where inference is required for multiple
datasets arising from the same model.
One way to achieve this is to ﬁrst estimate the joint distribution of (s, θ)
ﬂexibly and to then condition on observing s = sobs in the joint model.
This approach was considered by Bonassi et al. (2011) using multivariate nor-
mal mixture models for the density estimator on (s, θ). Synthetic likelihood
(Wood, 2010) is another method that directly approximates the likelihood via
an assumed density, such as p(s|θ) ≈Nq(μ(θ), Σ(θ)), where the mean μ(θ)
and covariance matrix Σ(θ) are unknown functions of the parameter θ. Vari-
ous techniques are then needed to estimate θ. For further details on synthetic
likelihoods, See, for example, Wood (2010), Chapters 12 and 20, this volume.
8.3.1
A ﬂexible regression density estimator
We describe the ﬂexible conditional density estimation approach of Fan et al.
(2013). As with other ABC density estimators, it is constructed from a sample
of N summary statistic and parameter pairs (s1, θ1), . . . , (sN, θN) drawn from
a distribution p(s|θ)h(θ). Note that while the summary statistics are generated
given θ from the sampling distribution for the intractable model of interest,
the parameters are not necessarily generated from the prior. Instead, h(θ) is
a distribution chosen to reﬂect the region over which the likelihood should
be well approximated. Some rough knowledge of the high likelihood region
of the parameter space, perhaps based on an initial pilot analysis, is useful
for setting h(θ). The method of Fan et al. (2013) is based on relating the
summary statistics s to θ by regression approximations, and so it is useful if the
actual relationships between s and θ are as simple as possible. One convenient
procedure to achieve this is the semi-automatic summary statistic approach
of Fearnhead and Prangle (2012), which constructs one summary statistic per
parameter, where each summary statistic is an estimate of the posterior mean
value of the parameter, based on a pilot run. That is, sk is the univariate
summary statistic informative for θk, k = 1, . . . , p, with sj = (sj
1, . . . , sj
p).
The ﬁrst step is to build marginal regression models for each component of
s conditional on θ. The training data (s1
k, θ1), . . . , (sN
k , θN) are used to build
the marginal model for sk, resulting in an estimated marginal density ˆfk(sk|θ)
for sk. Fan et al. (2013) use a fast variational method for ﬁtting mixture of
heteroscedastic regression models (Nott et al., 2012; Tran et al., 2012) for the
conditional density estimation.
Then a conditional density estimate for the joint distribution of s given θ
is constructed, using a method closely related to that considered in Giordani
et al. (2013) for the unconditional case. The data (sj, θj) are transformed
to (U j, θj), where U j
k = Φ−1( ˆFk(sj
k|θj)), where ˆFk(sk|θ) is the distribution
function corresponding to the density ˆfk(sk|θ). If the marginal densities for
each sk are well estimated, the transformation to U j makes each component

High-Dimensional ABC
231
of U j approximately standard normal regardless of the value of θ. A mixture
of normals model is then ﬁtted to the data (U j, θj), j = 1, . . . , N. Write the
ﬁtted normal mixture as:
K

k=1
wkN(μk, Ψk),
where N(μ, Ψ) denotes the multivariate normal distribution with mean μ and
covariance matrix Ψ, (μk, Ψk), k = 1, . . . , K are means and covariances of
K normal mixture components, and wk, k = 1, . . . , K are mixing weights,
wk ≥0, 	K
j=1 wj = 1. The mixture model for the joint distribution of (U, θ)
then implies a normal mixture model for the conditional density of U|θ:
K

k=1
wc
kN(μc
k, Ψc
k),
where:
wc
k =
wkφ(θ; μk, Ψk)
	K
j=1 wjφ(θ; μj, Ψj)
,
are mixing weights with φ(θ; μ, Ψ) denoting the multivariate normal density
function in θ with mean μ and covariance matrix Ψ, and μc
k and Ψc
k are the
conditional mean and covariance of U given θ in the k-th multivariate normal
component N(μk, Ψk) in the joint mixture model. Write ˆg(U|θ) for the result-
ing estimated conditional density of U given θ. Inverting the transformation
of s to U then produces an estimate of the conditional density of s given θ:
ˆL(s|θ) = ˆg(U|θ)
K

j=1
ˆfj(sj|θ)
φ(Uj; 0, 1).
(8.4)
An approximation of the observed data likelihood is then given by ˆL(sobs|θ).
The purpose of the transformation from s to U is to simplify the mixture
modelling of the joint distribution (U, θ) compared to what would be required
to estimate the joint distribution of (s, θ). Note that in ˆL(s|θ), the marginal
density of sk is not exactly ˆf(sk|θ) due to the fact that the estimated marginal
distributions in ˆg(U|θ) are not exactly standard normal. Giordani et al. (2013)
suggest replacing the φ(U j; 0, 1) in (8.4) by its exact marginal distribution in
ˆg(U|θ), but Fan et al. (2013) found that good approximations to L(sobs|θ)
were obtained without this step.
The previous conditional density estimation method seeks to estimate each
univariate marginal conditional distribution sk|θ arbitrarily well, while ap-
proximating the overall joint dependence structure by a mixture of normals
model. This approach can work well in relatively high dimensions, in the or-
der of tens to hundreds, provided that the dependence structure is relatively
straightforward to capture. This also underlines the importance of techniques

232
Handbook of Approximate Bayesian Computation
that can produce summary statistics with simple relationships to θ, such as
the method developed by Fearnhead and Prangle (2012).
8.3.2
Analysis of stereological extremes
To illustrate the regression density estimation approach, we re-analyse a
dataset originally analysed using ABC methods by Bortot et al. (2007), and
which was previously considered in Chapter 1, this volume. The data comprise
information about the intensity and size distribution of inclusions in a three-
dimensional block of clean steel, with the recorded observations being the
inclusion sizes (above a threshold of ν0 = 5 μm), and their number, observed
in a two-dimensional cross-section.
Bortot et al. (2007) considered models assuming spherical or ellipsoidal in-
clusion shapes. For the elliptical model, the inclusion size is the length of the
major axis of the two-dimensional planar ellipse. In both models, the locations
of the inclusions above 5 μm in size follow a Poisson process with intensity
λ. Conditional on having an inclusion larger than ν0, the distribution of the
inclusion size is generalised Pareto, with scale parameter σ > 0 and shape pa-
rameter ξ. So in both models there are three parameters, θ = (λ, σ, ξ)⊤. For
the analysis, the priors are log λ ∼N(0, 1002), σ ∼gamma(0.01, 0.0001), and
ξ ∼N(0, 1002). For the spherical inclusion model, it is possible to directly eval-
uate the likelihood, but for the ellipsoidal inclusion model, this is not possible
and so ABC methods are an attractive option. Here, we focus on the ellip-
soidal inclusion model. An analysis of standard rejection ABC with regression
adjustment for the spherical model can be found in Erhardt and Sisson (2016).
The high-dimensionality aspect of this analysis comes from the number
of summary statistics, rather than the number of parameters. The summary
statistics used comprise the logarithm of the number of inclusions observed in
the two-dimensional cross-section (s1 = 111), and sj+1 = log(q(j+1) −q(j)),
j = 1, . . . , 111, where the q(j), j = 1, . . . , 112 are 112 equally spaced quantiles
of the observed inclusion sizes. This gives q = 112 summary statistics in total
and corresponds to conditional density estimation in 112+3=115 dimensions.
The conditional density estimation method requires the choice of h(θ). This
is achieved via a pilot analysis by ﬁrstly sampling values (si, θi), i = 1, . . . , n,
where the θi are sampled from a uniform distribution over a range wide enough
to include the support of the posterior and the si are sampled from p(s|θi).
The sample mean ˆμ and covariance matrix ˆΣ are then calculated for those θ
values for which ∥si −sobs∥≤20. The distribution h(θ) is then speciﬁed as
the truncated normal distribution:
h(θ) ∝N(ˆμ, ˆΣ)I((θ −ˆμ)⊤ˆΣ−1(θ −ˆμ) < 9).
The conditional density estimation method for estimating p(s|θ) is then im-
plemented using N = 5,000 draws (si, θi) ∼p(s|θ)h(θ), i = 1, . . . , N.

High-Dimensional ABC
233
S1
−18 −14 −10 −6
20 60 100 140
−1.5
−0.5
0.5
250 350 450
−18 −14 −10 −6
S2
S3
0.5 1.5 2.5
20 60 100 140
λ
σ
0
2
4
6
8
250
350 450
−1.5
−0.5
0.5
0.5 1.5 2.5
0
2
4
6
8
ξ
FIGURE 8.8
Pairwise scatterplots between the Fearnhead and Prangle (2012) semi-
automatic summary statistics s1, s2, and s3 and the parameters λ, σ, and
ξ for the ellipsoidal inclusions model.
For comparison with the 115-dimensional regression density estimation
approach, an additional analysis is performed in only six dimensions, using
the three-dimensional summary statistics obtained using the semi-automatic
method of Fearnhead and Prangle (2012). Figure 8.8 shows pairwise scatter-
plots of the components of s and θ for the samples generated from h(θ)p(s|θ)
[plotting the Fearnhead and Prangle (2012) statistics analysis for clarity]. The
resulting scatterplots, after ﬁtting the ﬂexible models fk(s|θ) to the univari-
ate marginal distributions and transforming to the statistics U, are illustrated
in Figure 8.9. Clearly the dependence structure has been greatly simpliﬁed,
which facilitates the accurate mixture modelling of (U, θ).

234
Handbook of Approximate Bayesian Computation
U1
−3 −1 1 2 3
20 60 100 140
−1.5
−0.5
0.5
−3 −1
1 2 3 4
−3 −1 1 2 3
U2
U3
−4 −2
0 1 2 3
20 60 100 140
λ
σ
0
2
4
6
8
−3 −1 1 2 3 4
−1.5
−0.5
0.5
−4 −2 0 1 2 3
0
2
4
6
8
ξ
FIGURE 8.9
Pairwise scatterplots between the transformed Fearnhead and Prangle (2012)
summary statistics U1, U2, and U3 and the parameters λ, σ, and ξ for the
ellipsoidal inclusions model.
The histograms in Figure 8.10 show the regression density estimated
marginal posterior distributions obtained by using the original 112 sum-
mary statistics (top panels) and the lower dimensional Fearnhead and Pran-
gle (2012) statistics (bottom panels). The solid line illustrates the density
estimates obtained by the ‘gold standard’ ABC-Markov chain Monte Carlo
(MCMC) analysis of Bortot et al. (2007) using large computational over-
heads. It is apparent that even when modelling the original high-dimensional
set of summary statistics, reasonable answers are obtained using the regres-
sion density approach, although using the same method, but with the Fearn-
head and Prangle (2012) summary statistics naturally results in an improved
performance.

High-Dimensional ABC
235
λ
Density
40
60
80 100 120
0.00
0.01
0.02
0.03
0.04
0.05
σ
Density
0.5
1.5
2.5
3.5
0.0
0.2
0.4
0.6
0.8
1.0
1.2
ξ
Density
−0.6
−0.2 0.0 0.2
0
1
2
3
4
λ
Density
40
60
80 100 120
0.00
0.01
0.02
0.03
0.04
0.05
σ
Density
0.5
1.5
2.5
3.5
0.0
0.2
0.4
0.6
0.8
1.0
1.2
ξ
Density
−0.6
−0.2 0.0 0.2
0
1
2
3
4
FIGURE 8.10
Histograms illustrating the estimated marginal posterior distributions ob-
tained by regression density estimation for the ellipsoidal inclusions model
using 112 summary statistics (top rows) and the three Fearnhead and Prangle
(2012) summary statistics (bottom rows). The solid line shows the ‘gold stan-
dard’ marginal densities obtained using the method of Bortot et al. (2007),
with a kernel scale parameter of h = 0.33.
8.4
Other Approaches to High-Dimensional
ABC
Beyond the density estimation techniques described earlier, there are a few
alternative approaches for extending ABC analyses to higher dimensions. ABC
methods have been previously developed for functional parameters, speciﬁcally

236
Handbook of Approximate Bayesian Computation
in the case of non-parametric hierarchical density estimation (Rodrigues et al.,
2016). However, while these ‘inﬁnite-dimensional’ parameters require the
development of specialised ABC methods (such as a functional regression
adjustment), the dimensionality of these techniques is strictly not high-
dimensional in the sense considered in this chapter.
Various possibilities are available when the model of interest has a known
and exploitable structure. The simplest of these is where the model factorises
into a hierarchical structure p(s|θ, φ) = f(θ|φ) 
i pi(s(i)|θ(i)) (e.g. Bazin
et al., 2010), where s(i) and θ(i) denote mutually exclusive partitions of s
and θ. In this case, the ABC approximation to the joint posterior π(θ|sobs)
may be naturally constructed using the lower dimensional comparisons
∥s(i) −s(i)
obs∥only.
When the data model can be written in a conditional factorisation form
p(s|θ) = p(s1|θ) q
i=1 p(si|s1:(i−1), θ), where s1:k = (s1, . . . , sk)⊤, and where
conditional simulation from p(si|s1:(i−1), θ) is possible, Barthelm´e and Chopin
(2014) (see also White et al., 2015) proposed an expectation-propogation ABC
scheme. If si is low dimensional, then p(θ|si,obs, s1:(i−1),obs) (that is, the pos-
terior obtained by matching ∥si −si,obs∥based on simulating conditionally
on s1:(i−1),obs) can be well estimated via regular ABC, which Barthelm´e and
Chopin (2014) then approximate by a Gaussian density. This leads to a Gaus-
sian approximation of p(θ|sobs), which may be accurate if the number of
summary statistics is large. This may be realistic if the summary statistics
S(y) = y are the observed data. See Chapter 14, this volume, for further
details of this approach.
Kousathanas et al. (2016) consider constructing an MCMC sampler with
univariate updates to sample from each univariate conditional distribution
π(θi|θ−i, sobs). Here, they note that if a low-dimensional summary statistic
can be identiﬁed that is suﬃcient for the conditional distribution of θi|θ−i,
then an ABC-MCMC sampler can be implemented that compares summary
statistics of a much lower dimension than the full vector s at each update
step. They demonstrate this approach on a high-dimensional linear model
with univariate summary statistics for each parameter update.
Finally, synthetic likelihood methods were discussed in Section 8.3 as
a method to approximate the likelihood function using an assumed para-
metric form, for example, p(s|θ) ≈Nq(μ(θ), Σ(θ)) (Wood, 2010). As this
technique relies on estimating μ(θ) and Σ(θ) for each θ based on a po-
tentially large number of Monte Carlo samples from p(s|θ), this approach
can have high computational overheads. Variational Bayes has only recently
been considered as a possible approach for ﬁtting intractable models with
synthetic likelihoods, but with greatly reduced computational costs. This
then allows higher-dimensional analyses to be implemented. See, for exam-
ple, Tran et al. (2017) and Ong et al. (2018) for further details on this
technique.

High-Dimensional ABC
237
8.5
Discussion
Given that a direct ABC approximation of the joint posterior distribution
π(θ|sobs) involves a kernel density approximation of the likelihood, where
the dimensionality involved is the dimension of the summary statistic s, it
might initially seem that development of useful, general purpose methods for
high-dimensional ABC may not be possible. However, if we are prepared to
step away from the limiting comparison of ∥s −sobs∥within the likelihood
approximation of standard ABC methods, and build an approximations to
π(θ|s) or p(s|θ) from approximations of lower-dimensional distributions, then
it may be possible to develop useful ABC posterior approximations even in
high-dimensional settings. The key idea in these approaches is that instead of
matching a single vector of summary statistics in high dimensions, ∥s −sobs∥,
we instead match many diﬀerent low dimensional summary statistic vectors
in constructing our joint posterior approximation. While the methods de-
scribed here will not always work for posterior distributions with a highly
complex dependence structure, or in very high dimensions, further develop-
ment of related methods using the same ‘divide and conquer’ strategy may be
a promising direction for future research in high-dimensional ABC. This may
be particularly true for those methods that are easily parallelisable in their
implementation.
Another area that perhaps has good potential for future research involves
those techniques related to pseudo-marginal MCMC methods (see Chapter 9,
this volume, Andrieu et al., 2019), which is currently seeing a surge of research
interest beyond ABC. These methods have opened up ways to perform exact
estimation and sampling for models with intractable likelihood functions, the
ideas of which can be extended to implement various forms of approximation
of posterior distributions. These include synthetic likelihoods (see Chapter 12,
this volume) and variational Bayes methods, which can both be fast to im-
plement, and for which the latter tends to underestimate uncertainty. The
extension of likelihood-free inference methods to problems of higher dimen-
sion is a very active research area and promises to be so for the forseeable
future.
Acknowledgements
SAS is supported by the Australian Research Council under the Discovery
Project scheme (DP160102544) and the Australian Centre of Excellence in
Mathematical and Statistical Frontiers (CE140100049).

238
Handbook of Approximate Bayesian Computation
References
Allingham, D. R., A. R. King, and K. L. Mengersen (2009). Bayesian estima-
tion of quantile distributions. Statistics and Computing 19, 189–201.
Andrieu, C., A. Lee, and M. Vihola (2019). Theoretical and methodological
aspects of MCMC computations with noisy likelihoods. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Barber, S., J. Voss, and M. Webster (2015). The rate of convergence for
approximate Bayesian computation. Electronic Journal of Statistics 9,
80–105.
Barthelm´e, S. and N. Chopin (2014). Expectation propagation for likelihood-
free inference. Journal of the American Statistical Association 109, 315–333.
Barthelm´e, S., N. Chopin, and V. Cottet (2019). Divide and conquer in ABC:
Expectation-propagation algorithms for likelihood-free inference. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Bazin, E., K. Dawson, and M. A. Beaumont (2010). Likelihood-free infer-
ence of population structure and local adaptation in a Bayesian hierarchical
model. Genetics 185, 587–602.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162, 2025–2035.
Biau, G., F. C´erou, and A. Guyader (2015). New insights into approximate
Bayesian computation. Annales de l’Institut Henri Poincar´e, Probabilit´es et
Statistiques 51(1), 376–403.
Blum, M. G. B. (2010). Approximate Bayesian computation: A non-
parametric perspective. Journal of the American Statistical Associa-
tion 105, 1178–1187.
Blum, M. G. B. and O. Fran¸cois (2010). Non-linear regression models for
approximate Bayesian computation. Statistics and Computing 20, 63–75.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson (2013). A com-
parative review of dimension reduction methods in approximate Bayesian
computation. Statistical Science 28, 189–208.
Bonassi, F. V., L. You, and M. West (2011). Bayesian learning from marginal
data in bionetwork models. Statistical Applications in Genetics and Molec-
ular Biology 10(1).

High-Dimensional ABC
239
Bortot, P., S. G. Coles, and S. A. Sisson (2007). Inference for stereological
extremes. Journal of the American Statistical Association 102, 84–92.
Drovandi, C. C., C. Grazian, K. Mengersen, and C. P. Robert (2019). Approxi-
mating the likelihood in approximate Bayesian computation. In S. A. Sisson,
Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Drovandi, C. C. and A. N. Pettitt (2011). Likelihood-free Bayesian estimation
of multivariate quantile distributions. Computational Statistics and Data
Analysis 55, 2541–2556.
Erhardt, R. and S. A. Sisson (2016). Modelling extremes using approximate
Bayesian computation. In D. Dey and J. Yan (Eds.), Extreme Value Mod-
elling and Risk Analysis, pp. 281–306. Boca Raton, FL: Chapman and
Hall/CRC Press.
Fan, Y., D. J. Nott, and S. A. Sisson (2013). Approximate Bayesian compu-
tation via regression density estimation. Stat 2(1), 34–48.
Fang, H.-B., K.-T. Fang, and S. Kotz (2002). The meta-elliptical distributions
with given marginals. Journal of Multivariate Analysis 82(1), 1–16.
Fasiolo, M. and S. N. Wood (2019). ABC in ecological modelling. In S. A.
Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of Approximate
Bayesian Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society, Series B 74, 419–474.
Feng, Y., Y. Chen, and X. He (2015). Bayesian quantile regression with ap-
proximate likelihood. Bernoulli 21(2), 832–580.
Giordani, P., X. Mun, M.-N. Tran, and R. Kohn (2013). Flexible multivariate
density estimation with marginal adaptation. Journal of Computational and
Graphical Statistics 22(4), 814–829.
Haario, H., E. Saksman, and J. Tamminen (1999). Adaptive proposal distri-
bution for random walk Metropolis algorithm. Computational Statistics 14,
375–395.
Isaacs, D., D. G. Altman, C. E. Tidmarsh, H. B. Valman, and A. D. B. Webster
(1983). Serum immunoglobulin concentration in preschool children mea-
sured by laser nephelometry: Reference ranges for IgG, IgA, IgM. Journal
of Clinical Pathology 36, 1193–1196.
Koenker, R. (2005). Quantile Regression, Volume 38 of Econometric Society
Monographs. Cambridge: Cambridge University Press.

240
Handbook of Approximate Bayesian Computation
Kousathanas, A., C. Leuenberger, J. Helfer, M. Quinodoz, M. Foll, and
D. Wegmann (2016). Likelihood-free inference in high-dimensional models.
Genetics 203, 893–904.
Leuenberger, C. and D. Wegmann (2010). Bayesian computation and model
selection without likelihoods. Genetics 184, 243–52.
Li, J., D. J. Nott, Y. Fan, and S. A. Sisson (2017). Extending approximate
Bayesian computation methods to high dimensions via Gaussian copula.
Computational Statistics and Data Analysis 106, 77–89.
Li, W. and P. Fearnhead (2016). Improved convergence of regression adjusted
approximate Bayesian computation. arXiv: 1609.07135.
Løland, A., R. B. Huseby, N. L. Hjort, and A. Frigessi (2013). Statistical
corrections of invalid correlation matrices. Scandinavian Journal of Statis-
tics 40(4), 807–824.
Nott, D. J., Y. Fan, L. Marshall, and S. A. Sisson (2014). Approximate
Bayesian computation and Bayes linear analysis: Towards high-dimensional
ABC. Journal of Computational and Graphical Statistics 23(1), 65–86.
Nott, D. J., S. L. Tan, M. Villani, and R. Kohn (2012). Regression density
estimation with variational methods and stochastic approximation. Journal
of Computational and Graphical Statistics 21, 797–820.
Ong, V. M.-H., D. J. Nott, M.-N. Tran, S. A. Sisson, and C. C. Drovandi
(2018). Variational Bayes with synthetic likelihood. Statistics and Comput-
ing, 28(4), 971–988.
Peters, G. W. and S. A. Sisson (2006). Bayesian inference, Monte Carlo sam-
pling and operational risk. Journal of Operational Risk 1, 27–50.
Rayner, G. and H. MacGillivray (2002). Weighted quantile-based estimation
for a class of transformation distributions. Computational Statistics & Data
Analysis 39(4), 401–433.
Reich, B. J., H. D. Bondell, and H. J. Wang (2010). Flexible Bayesian quantile
regression for independent and clustered data. Biostatistics 11(2), 337–352.
Reserve Bank of Australia (2014). Historical data. http://www.rba.gov.au/
statistics/historical-data.html.
Rodrigues, G. S., D. J. Nott, and S. A. Sisson (2016). Functional regression
approximate Bayesian computation for Gaussian precess density estimation.
Computational Statistics and Data Analysis 103, 229–241.
Rodrigues, T. and Y. Fan (2017). Regression adjustment for non cross-
ing Bayesian quantile regression. Journal of Computational and Graphical
Statistics 26, 275–284.

High-Dimensional ABC
241
Sisson, S.A., Y. Fan, and M. A. Beaumont (2019). Overview of approximate
Bayesian computation. In S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.),
Handbook of Approximate Bayesian Computation. Chapman & Hall/CRC
Press, Boca Raton, FL.
Sklar, A. (1959). Fonctions de repartition a n dimensions et leur marges.
Publications de l’Institut de Statistique de l’Universit´e de Paris 8, 229–231.
Tokdar, S. T. and J. B. Kadane (2012). Simultaneous linear quantile regres-
sion: A semiparametric Bayesian approach. Bayesian Analysis 7(1), 51–72.
Tran, M.-N., D. J. Nott, and R. Kohn (2012). Simultaneous variable selection
and component selection for regression density estimation with mixtures of
heteroscedastic experts. Electronic Journal of Statistics 6, 1170–1199.
Tran, M.-N., D. J. Nott, and R. Kohn (2017). Variational Bayes with
intractable likelihood. Journal of Computational and Graphical Statistics,
26(4), 873–882.
White, S. R., T. Kypraios, and S. P. Preston (2015). Piecewise approximate
Bayesian computation: Fast inference for discretely observed Markov mod-
els using a factorised posterior distribution. Statistics and Computing 25,
289–301.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466, 1102–1104.


9
Theoretical and Methodological Aspects
of Markov Chain Monte Carlo
Computations with Noisy Likelihoods
Christophe Andrieu, Anthony Lee, and Matti Vihola
CONTENTS
9.1
The Noisy Likelihood Perspective ...............................
244
9.2
Pseudo-Marginal Algorithms .....................................
246
9.3
Performance Measures ...........................................
249
9.3.1
Approximation of the noiseless algorithm ...............
250
9.3.2
Rates of convergence ....................................
251
9.3.3
Comparison of algorithms ...............................
254
9.4
Strategies to Improve Performance ..............................
255
9.4.1
Averaging estimators ....................................
255
9.4.2
Rejuvenation ............................................
257
9.4.3
Playing with the Us .....................................
259
9.4.3.1
Stratiﬁcation ..................................
260
9.4.3.2
Introducing dependence between
estimators .....................................
260
9.4.4
Locally adaptive ABC-Markov chain Monte Carlo .....
262
9.4.5
Inexact algorithms .......................................
263
9.5
Remarks ..........................................................
265
References
...............................................................
265
Approximate Bayesian computation (ABC) [1,2] is a popular method
for Bayesian inference involving an intractable, or expensive to evaluate,
likelihood function, but where simulation from the model is easy. The method
consists of deﬁning an alternative likelihood function, which is also in general
intractable, but naturally lends itself to pseudo-marginal computations [3],
hence, making the approach of practical interest. The aim of this chap-
ter is to show the connections of ABC Markov chain Monte Carlo with
243

244
Handbook of Approximate Bayesian Computation
pseudo-marginal algorithms, review their existing theoretical results, and dis-
cuss how these can inform practice and hopefully lead to fruitful methodolog-
ical developments.
9.1
The Noisy Likelihood Perspective
Consider some data yobs ∈Y assumed to arise from a family of probability
distributions with densities

ℓ(· | θ), θ ∈Θ

, with respect to some appropriate
reference measure λ(·), indexed by some unknown parameter θ ∈Θ ⊂Rd for
some d ∈N. In a Bayesian context, θ is ascribed a prior distribution with
density η(·) (with respect to some appropriate measure) and the posterior
distribution has density:
π(θ | yobs) ∝η(θ)ℓ(yobs | θ).
The intractability of the likelihood function may prevent the implementation
of traditional sampling algorithms. To circumvent this problem, it is natural
to seek to approximate the desired likelihood function ℓ(yobs | θ), and ABC
methods do so by taking advantage of the fact that sampling from the family of
distributions

ℓ(· | θ)λ(·), θ ∈Θ

may be simple. Standard practice consists
ﬁrst of deﬁning a function of the data s : Y →Rq for some q ∈N+, and
thereby the ‘summary statistics’ used to compare datasets. Then a distance
∥· ∥on Rq and a ‘kernel’ K : R+ →[0, 1] are chosen and combined to form
ψ(y1, y2) := K

∥s(y1) −s(y2)∥

for y1, y2 ∈Y, whose rˆole is to measure the
strength of the dissimilarity between datasets. One is naturally not constrained
to this speciﬁc form of ψ, and the only requirement is that ψ : Y2 →[0, 1] and
is statistically sensible. Note that there is no loss of generality in choosing the
upper bound 1 for ψ since multiplicative constants do not aﬀect Bayes’ rule.
A standard choice for ψ is:
ψ(y1, y2) := I

∥s(y1) −s(y2)∥≤ϵ

,
(9.1)
for some ϵ > 0, although most of this chapter will deal with the general case,
rather than this speciﬁc choice. Now, given ψ : Y2 →[0, 1], one can the deﬁne
the ‘ABC likelihood’ function
ℓψ
ABC(yobs | θ) :=

ψ(y, yobs)ℓ(y | θ)λ(dy).
(9.2)
One can think of ABC likelihoods arising from the standard choice of ψ as
being kernel density estimators of the probability density of the observed
summary statistics under the assumed model for the data. The associated
posterior distribution has density:
π(θ) := πABC(θ | yobs) ∝η(θ)ℓψ
ABC(yobs | θ),

Theoretical and Methodological Aspects of MCMC Computations
245
and we will use the simpliﬁed notation π(θ) in the remainder of the chap-
ter. It seems at ﬁrst sight that we have not made any progress since the new
likelihood function is now an integral with respect to a distribution whose
density is assumed to be intractable. This prevents direct implementation
of the workhorse of Markov chain Monte Carlo (MCMC) methodology, the
Metropolis–Hastings (MH) algorithm, described in Algorithm 9.1 for a family
of proposal distributions {q

θ, ·

, θ ∈Θ}. For notational simplicity, we adopt
the convention that for a random variable X ∼ϖ(·), where ϖ(·) is a proba-
bility distribution, x ∼ϖ(·) means that x is a realisation of X, and do not
use capital fonts for Greek letters representing random variables.
Algorithm 9.1: Exact ABC-MCMC Update
1
Given θ
2
Sample ϑ ∼q(θ, ·)
3
Return ϑ with probability
min

1, η(ϑ)ℓψ
ABC(yobs | ϑ)q(ϑ, θ)
η(θ)ℓψ
ABC(yobs | θ)q(θ, ϑ)

4
Otherwise return θ.
This is where the possibility to sample from ℓ(· | θ)λ(·) comes into play, in
combination with the standard ‘auxiliary variable trick’. Deﬁne the probability
distribution on Θ × Y with the following density
π(θ, y) ∝η(θ)ℓ(y | θ)ψ(y, yobs).
(9.3)
Evidently, this distribution has π(dθ) as a marginal, and we aim to sample
from this joint distribution. The rejection ABC algorithm proceeds, in its
simplest form, by sampling θ ∼η and y ∼ℓ(· | θ)λ(·), and accepting (θ, y) with
probability ψ(y, yobs), therefore not requiring the evaluation of the likelihood
function. This idea can also be used in the context of the MH algorithm by
choosing a family of probability distributions {q

θ, ·

, θ ∈Θ} to update the
parameter component and {ℓ

· | θ

, θ ∈Θ} to update the auxiliary dataset
component. The resulting update is described in Algorithm 9.2 (we add an
index to the auxiliary datasets to indicate the distribution they are sampled
from) and ﬁrst appeared in [4].
We note that in some latent variable models, the ABC posterior π is not
approximate. In particular, if yobs ∼ψ(y, ·) and y ∼ℓ(· | θ)λ(·) for some
θ ∈Θ with s the identity function, then ℓψ
ABC(yobs | θ) is the exact, albeit
intractable, likelihood function. This has been stressed in [5] and is taken
advantage of in, for example, [6] and [7].

246
Handbook of Approximate Bayesian Computation
Algorithm 9.2: ABC-MCMC
1
Given (θ, yθ)
2
Sample ϑ ∼q(θ, ·) and yϑ ∼ℓ(· | ϑ)λ(·)
3
Return (ϑ, yϑ) with probability
min
	
1, η(ϑ) × ψ(yϑ, yobs)q(ϑ, θ)
η(θ) × ψ(yθ, yobs)q(θ, ϑ)

(9.4)
4
otherwise return (θ, yθ).
9.2
Pseudo-Marginal Algorithms
We now develop another perspective on Algorithm 9.2, which turns out to be
fruitful in many respects and on which the remainder of the chapter is based.
As we shall see, this alternative point of view suggests many useful extensions,
is both conceptually and notationally much simpler, and in fact covers scenar-
ios of interest beyond ABC. Note, however, that despite the attractive generic
nature of this perspective, one should in practice not forget about the initial
problem at hand since it may possess additional speciﬁc structure one may
exploit. The main starting point here is to notice that with Y ∼ℓ(· | θ)λ(·),
then ψ(Y, yobs) is an unbiased estimator of (9.2), and that one can write the
joint posterior density (9.3) as follows, in terms of the marginal π(θ):
π(θ, y) ∝η(θ)ℓψ
ABC(yobs | θ)
ψ(y, yobs)
ℓψ
ABC(yobs | θ)
ℓ(y | θ) ∝π(θ)
ψ(y, yobs)
ℓψ
ABC(yobs | θ)
ℓ(y | θ),
where we have assumed θ such that ℓψ
ABC(yobs | θ) ̸= 0. From this, we conclude
that π(θ)ψ(Y, yobs)/ℓψ
ABC(yobs | θ) is an unbiased (and non-negative) estimator
of π(θ) when Y ∼ℓ(· | θ)λ(·). Clearly the acceptance probability (9.4) can be
equally written as:
min

1,

π(ϑ)
ψ(yϑ, yobs)
ℓψ
ABC(yobs | ϑ)
q(ϑ, θ)
  
π(θ)
ψ(yθ, yobs)
ℓψ
ABC(yobs | θ)
q(θ, ϑ)

,
that is, Algorithm 9.2 can be thought of as an approximate implementation of
the exact update Algorithm 9.1, where the expression for π(·) is replaced with
an unbiased, ‘noisy’ estimator. However, Algorithm 9.2 targets the joint distri-
bution with density π(θ, y) and is therefore exact in the sense that an ergodic
Markov chain built on this type of update can produce samples of distribution
arbitrarily close to π(dθ). This remark leads in fact to a far more widely appli-
cable idea [8,3] and the resulting methods are referred to as pseudo-marginal
algorithms (see [9,10] for earlier, related, but diﬀerent ideas). Indeed, assume
that for any θ ∈Θ, we can generate ‘unbiased measurements’ of π(θ) of the

Theoretical and Methodological Aspects of MCMC Computations
247
form π(θ) × W, where W ∼Qθ, Qθ

W ≥0

= 1, and such that EQθ[W] = C
for some C > 0 independent of θ, and consider the probability distribution on
Θ × W with density:
˜π(θ, w) = π(θ) × w × Qθ(w).
(9.5)
For simplicity, we will hereafter assume that C = 1. Note that we do not
assume here that π(θ) is tractable, but rather that π(θ) × w is: W is purely
conceptual and implicit in real scenarios. In the ABC scenario described above,
W is the positive real valued random variable, such that for any θ ∈Θ and
A ∈B

R

, the Borel σ-algebra on R:
Qθ(Wθ ∈A) =

I{ψ(y, yobs)/ℓψ
ABC(yobs | θ) ∈A}ℓ(y | θ)λ(dy).
(9.6)
Now an MH update, with transition probability denoted ˜P, targetting this
distribution, and with proposal distribution q(θ, ϑ) × Qϑ(u) has acceptance
probability:
˜α(θ, w; ϑ, u) = min
	
1, π(ϑ) × u × Qϑ(u)
π(θ) × w × Qθ(w)
q(ϑ, θ)Qθ(w)
q(θ, ϑ)Qϑ(u)

= min
	
1, π(ϑ) × u q(ϑ, θ)
π(θ) × w q(θ, ϑ)

.
The Markov transition kernel, which we denote by ˜P, is described algorithmi-
cally in Algorithm 9.3
Algorithm 9.3: Generic Pseudo-Marginal Algorithm
1
Given (θ, w)
2
Sample ϑ ∼q(θ, ·) and u ∼Qϑ
3
Return (ϑ, u) with probability
min
	
1, π(ϑ) × u q(ϑ, θ)
π(θ) × w q(θ, ϑ)

4
Otherwise return (θ, w)
Clearly a Markov chain Monte Carlo based on this update is exact in the
sense outlined earlier and can be thought of as being an approximation of
an exact MH update, which we denote by P, with acceptance probability
min

1, r(θ, ϑ)

, where
r(θ, ϑ) := π(ϑ) q(ϑ, θ)
π(θ) q(θ, ϑ) ,
which would use the exact values of the density π(θ).
What
is
the
interest
of
these
developments?
First,
˜π(θ, w)
and
Algorithm 9.3 are notationally and conceptually simple, equivalent represen-
tations of π(θ, y) and Algorithm 9.2, respectively, in that they lead to equiva-
lent algorithms, provided we are only interested in the properties of the chain

248
Handbook of Approximate Bayesian Computation
{θi, i ≥0}. Indeed, let {(ˇθi, Yi), i ≥0} and {(θi, Wi), i ≥0} be the Markov
chains, such that with μ (resp. νθ for any θ ∈Θ) a probability distribution on
Θ (resp. on Y) and for any θ ∈Θ and A ∈B

R

:
˜νθ( ˜Wθ ∈A) :=

I{ψ(y, yobs)/ℓABC(yobs | θ) ∈A}νθ(dy),
(ˇθ0, Y0) ∼μ × ν·, (θ0, W0) ∼μ × ˜ν· and Markov transition probabilities as
described in Algorithm 9.2 and Algorithm 9.3, respectively. With ˇP(·) and
P(·) the respective probabilities it can be checked easily that for any m ∈N,
i1, i2, . . . , im ∈N and A1, A2, . . . , Am ∈B(Θ)m we have:
ˇP
ˇθi1 ∈A1, . . . , ˇθim ∈Am

= P (θi1 ∈A1, . . . , θim ∈Am) ,
which indeed implies that the processes {ˇθi, i ≥0} and {θi, i ≥0} are proba-
bilistically indistinguishable. In particular, at a conceptual level this tells us
on the one hand that the properties of the algorithm (i.e. {ˇθi, i ≥0}) are fully
characterised by the properties of the random variables induced by (9.6), but
also that the algorithm can be thought of as random perturbation of the exact
algorithm with exact acceptance probability min

1, r(θ, ϑ)

, suggesting links
between the exact algorithm and its perturbations.
A second feature of this representation is that it emphasises the fact that
the central property exploited in ABC is the possibility to produce unbiased
and non-negative estimators of (9.2) cheaply, and such estimators are not
restricted to the standard choice ψ(Y, yobs) with Y ∼ℓ(· | θ)λ(·). For example,
one could average N multiple copies of the estimator as proposed in [11] and
utilised in, for example, [12]. That is, for any θ ∈Θ and Y 1, Y 2, . . . , Y N iid
∼
ℓ(· | θ)λ(d·) consider the unbiased estimator Tθ(N) of ℓABC(yobs | θ):
Tθ(N) := 1
N
N

i=1
ψ

Y i, yobs).
(9.7)
This leads to the unit expectation, non-negative random variable Wθ(N) =
Tθ(N)/ℓψ
ABC(yobs | θ), and in the light of the earlier, there is no need to check
the validity of a noisy MH algorithm that uses this estimator. One can check
that the algorithm now targets:
π(θ)QN
θ (w1, w2, . . . , wN) 1
N
N

i=1
wi,
but that it is also possible to aggregate, that is, deﬁne w(N) := N −1 N
i=1 wi,
such that the associated random variable has distribution QN
θ

Wθ(N) ∈A

=

I

w(N) ∈A

QN
θ (d(w1, w2, . . . , wN)). We will return to such aggregation
strategies in Section 9.4.1 and discuss alternatives to a product form of the
joint distribution of density QN
θ (w1, w2, . . . , wN), since it is in fact suﬃcient
that its N marginals all be Qθ(·) for the above to hold.

Theoretical and Methodological Aspects of MCMC Computations
249
9.3
Performance Measures
Before presenting various possible strategies to improve on standard ABC-
MCMC algorithms in the next section, we recall here standard performance
measures for MCMC algorithms and a summary of some known theoretical
results relating (essentially) the properties of

Wθ, θ ∈Θ

to the perfor-
mance of pseudo-marginal algorithms. As we shall see, the variability and
extreme behaviour of the estimators Wθ play a fundamental part in the (bad)
behaviour of ABC-MCMC algorithms. The intuition goes as follows, upon re-
calling the expression for the acceptance probability of the noisy algorithm
(Algorithm 9.3) in terms of the acceptance ratio of the exact algorithm:
min

1, r(θ, ϑ) u
w

,
and that Wθ is a non-negative random variable of expectation one. Reali-
sations of Wθ can take values larger than one and make leaving the state
(θ, w) more diﬃcult than for the exact algorithm (since u has to match w),
resulting in the familiar ‘sticky behaviour’ of the ABC-MCMC algorithm
(see, e.g. [13]).
For μ, a probability distribution deﬁned on some measurable space

E, E

and Π : E×E →[0, 1] a Markov transition kernel with invariant distribution μ,
that is, μΠ = μ, we are interested in this section in two performance measures,
that address asymptotic variance and bias:
1. Letting Φ0 ∼μ and Φn ∼Π(Φn−1, ·) for n ≥1 one may be inter-
ested, for a function f : E →R in the behaviour of ergodic averages
ST (Φ) := T −1 T −1
k=0 f(Φk), their asymptotic variance is a natural perfor-
mance measure, and we will focus on the quantity:
var (f, Π) := lim
T →∞Tvarμ

ST (Φ)

,
2. Letting for x ∈E, Lx(Φn) be the law of the n-th state Φn of the Markov
chain

Φi, i ≥0

where Φ0 = x, we may be interested in the rate of
convergence to equilibrium of the Markov chain. That is, for an appropriate
norm ∥· ∥∗characterise the distance between Lx(Φn) and μ for all n ≥0
and, for example, establish the existence of M > 0, V : E →R+ and
ρ ∈[0, 1) or α > 0 or {r(n), n ≥0}, such that either of the following
inequalities hold for n ≥1:
∥Lx(Φn) −μ∥∗≤
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
Mρn
(uniformly ergodic)
MV (x)ρn
(geometrically ergodic)
MV (x)n−α
(polynomially ergodic)
V (x)r−1(n),
r(n) →∞
(ergodic).

250
Handbook of Approximate Bayesian Computation
The role of V is to take into account the inﬂuence of the initialisation on
convergence and we leave the norms unspeciﬁed, although it may be useful
to know that they correspond to the supremum of
E

f(Φn)

−μ

f
 for
f in certain classes of functions. Such results will therefore provide us with
a sense of the speed at which bias vanishes as n increases.
In the sequel, P is the noiseless algorithm, ˜P is the noisy algorithm using the
family

Qθ, θ ∈Θ

, and ˜PN is the noisy algorithm which averages N samples
marginally identically distributed according to

Qθ, θ ∈Θ

and joint distri-
butions denoted

QN
θ , θ ∈Θ

. We will also consider more general families
of noisy algorithms
 ˜Pλ, λ ∈R+

indexed by λ > 0, that is, using weight
distributions

Q(λ)
θ , θ ∈Θ, λ ∈Λ ⊂R+

, with the convention that ˜Pλ=0 = P
(i.e. the latter is not deﬁned on the same space as ˜Pλ, λ ̸= 0).
We start with simple results which conﬁrm that ˜P is a suboptimal approx-
imation of P, but that concentration of Wθ on 1 allows ˜P to approach some
performance measures of P arbitrarily closely.
9.3.1
Approximation of the noiseless algorithm
The pseudo-marginal algorithm, Algorithm 9.3, never has a smaller asymptotic
variance than its corresponding marginal algorithm [14, Theorem 7], therefore
justifying attempts to approximate P in order to improve performance of ˜P.
A natural class of functions to consider are those with ﬁnite second moment
under π, that is, functions {f : π(f 2) < ∞}, where π(f 2) :=

f(θ)2π(dθ), or
equivalently, the functions f, such that the random variable f(X) has ﬁnite
variance when X ∼π, that is, varπ(f) < ∞.
Theorem 9.1 (Noiseless is best). Assume f : Θ →R satisﬁes π(f 2) < ∞.
The asymptotic variances of f with respect to the pseudo-marginal algorithm
˜P and the marginal algorithm P always satisfy:
var(f, P) ≤var(f, ˜P).
Under general technical conditions, the asymptotic variance of the pseudo-
marginal algorithm converges to the asymptotic variance of the marginal
algorithm [14, Theorem 21]. Denote by
˜θ(λ)
k , k ≥0

the Markov chain with
initial distribution ˜πλ and kernel ˜Pλ.
Theorem 9.2. Assume that

|f(θ)|2+δπ(θ)dθ < ∞for some δ > 0, that
var(f, P) < ∞and there exists a constant λ0 ∈Λ such that:
lim
n→∞
sup
0≤λ≤λ0

∞

k=n
E[ ¯f(˜θ(λ)
0 ) ¯f(˜θ(λ)
k )]
 = 0
where
¯f = f −π(f),
and that:
lim
λ→0

|1 −w|Q(λ)
θ (dw) = 0
for all θ ∈Θ.

Theoretical and Methodological Aspects of MCMC Computations
251
Then:
lim
λ→0 var(f, ˜Pλ) = var(f, P).
The ﬁrst condition simply says that the tails of the integrated autoco-
variances vanish uniformly for suﬃciently good approximations of P, which
should be the case, for example, if the approximation does not perturb the
ergodicity properties of P signiﬁcantly. This is further investigated in [14] and
related to the results of Section 9.3.2. The second condition is very natural
and formalises the idea of concentration of ˜πλ

d(θ, w)

on π(dθ)δ1(dw). The
following result formalises the fact that approximations involving unbounded
noises are undesirable [3, Theorem 8].
Theorem 9.3. If the weight distributions are such that:
π

{θ ∈Θ :
 ∞
MQθ(dw) > 0 for all M < ∞}

> 0,
then the pseudo-marginal algorithm cannot be geometrically ergodic.
Corollary 9.1. Even when P is geometrically ergodic, as soon as:
	
θ ∈Θ :
 ∞
M
Qθ(dw) > 0 for all M < ∞

,
has a positive π-probability, then for any N ∈N+:
	
θ ∈Θ :
 ∞
M
QN
θ (dw) > 0 for all M < ∞

,
has a positive π-mass, and
˜PN cannot be geometrically ergodic for any
N ∈N+.
Broadly speaking, the result simply says that boundedness of the weights is
required to ensure geometric ergodicity, and the corollary, that while averaging
may ensure convergence of the integrated autocovariance, it will not always be
the case that one can approach the rate of convergence of P: in fact the result
says that one cannot even be geometric. In other words, despite the fact that
‘bad events’ (e.g. the N weights we have drawn are all large simultaneously)
have a vanishing probability of occurrence as N increases, their impact on the
long term properties of the algorithm may still be felt. Such bad behaviour will
however vanish, for example, for a ﬁxed simulation length T as N increases,
provided naturally that the algorithm is not initialised at points corresponding
to such bad events.
9.3.2
Rates of convergence
The ﬁrst result of this section holds under a condition (9.8) stronger than
uniform ergodicity for P, but often used in practice to establish this prop-
erty whenever the space Θ is compact, and the assumption that the noise is

252
Handbook of Approximate Bayesian Computation
uniformly bounded [the condition in [3, Theorem 8] is slightly more general].
In words the result says that uniform ergodicity of the noiseless algorithm is
inherited by the noisy algorithm in this scenario.
Theorem 9.4. Suppose there exists ϵ > 0, a probability measure ν on the
measurable space

Θ, T

, such that for any A ∈T :

A
q(θ, dϑ) min{1, r(θ, ϑ)} ≥ϵν(A)
for all θ ∈Θ,
(9.8)
and M < ∞, such that for all θ ∈Θ, Qθ

Wθ ≤M

= 1, then ˜P is also
uniformly ergodic.
It should be noted that even in this favourable scenario, ˜PN may not
achieve the rate of convergence of P for any N ≥1 [3, Remark 1]. The interest
of the next result is that it establishes in a simple, yet representative, scenario
a direct link between the existence of general moments of Wθ and the rate of
convergence to equilibrium one may expect from the algorithm.
Theorem 9.5. Suppose there exists ϵ > 0, a probability measure ν on the
measurable space

Θ, T

, such that for any A ∈T :

A
q(θ, dϑ) min{1, r(θ, ϑ)} ≥ϵν(A)
for all θ ∈Θ,
and a non-decreasing convex function φ : [0, ∞) →[1, ∞) satisfying:
lim inf
t→∞
φ(t)
t
= ∞
and
MW := sup
θ∈Θ

φ(w)Qθ(dw) < ∞.
(9.9)
Then ˜P is sub-geometrically ergodic with a rate of convergence characterised
by φ.
Corollary 9.2. Consider, for example, the case φ(w) = wβ + 1 for some
β > 1. Then, there exists C > 0, such that for any function f : Θ →R and
n ∈N+:
E

f(θn)

−π

f
 ≤C |f|∞n−(β−1),
where |f| ∞:= supθ∈Θ |f(θ)|. For readers familiar with the total variation
distance, this implies that for any θ ∈Θ:
∥Lθ(θn) −π(·)∥T V ≤Cn−(β−1).
Other rates of convergence may be obtained for other functions φ [15].
These last results will typically hold only in situations where Θ is bounded:
extensions to more general scenarios have been considered in [14], but require
one to be more speciﬁc about the type of MH updates considered and involve

Theoretical and Methodological Aspects of MCMC Computations
253
TABLE 9.1
Convergence Inheritance. The Constants are such that ϵ, δ > 0 and
c ∈R, While c(·) : Θ →R+ on the Last Line Should Satisfy Some
Growth Conditions [14, Theorem 38]. IMH and RWM Stand for
Independent MH and Random Walk Metropolis, Respectively
Marginal P
Wθ
Pseudo-marginal ˜
P
Uniform
Wθ ≤c a.s.
Uniform
Geometric
Wθ ≤c a.s.
Geometric if ˜P positive
(conjecture in
general [14, Section 3])
Any
Wθ unbounded
Not geometric
Uniform
EQθ

W 1+ϵ
θ

≤c
Polynomial
Uniform
Uniform integrability (9.9)
Sub-geometric
IMH
–
IMH
Geometric RWM
EQθ

W 1+ϵ
θ
+ W −δ
θ

≤c(θ)
Polynomial
[14, Theorem 38]
substantial additional technicalities. A rough summary of known results is
presented in Table 9.1, we refer the reader to [14] for precise statements.
One clear distinction in Table 9.1 is the inheritance of geometric ergodicity
of P by (at least) positive ˜P when Wθ is almost surely uniformly bounded,
and its failure to do so when Wθ is unbounded, for all θ in some set of pos-
itive π-probability. In the case where Wθ is almost surely bounded but not
uniformly so, characterisation is not straightforward. Indeed, there are cases
where ˜P does inherit geometric ergodicity and cases where it does not, see [14,
Remark 14] and [16, Remark 2]. In [16] and its supplement, it is shown that
failure to inherit geometric ergodicity in statistical applications is not uncom-
mon when using ‘local’ proposals such as a random walk, see Theorem 9.9.
One attractive property of uniformly and geometrically ergodic ˜P is that
var(f, ˜P) < ∞for all f with varπ(f) < ∞. Conversely, when ˜P is not geomet-
rically ergodic, and the chain is not almost periodic in a particular technical
sense, then there do exist f with varπ(f) < ∞, such that var(f, ˜P) is not
ﬁnite (see [17] for more details). It is, however, not straightforward to identify
which functions have ﬁnite asymptotic variance in the sub-geometric regime.
It has recently been shown that uniformly bounded second moments of Wθ
and geometric ergodicity of P are suﬃcient to ensure that all functions f of
θ only with varπ(f) < ∞have ﬁnite asymptotic variance [18].
Theorem 9.6. Let P be geometrically ergodic and supθ EQθ

W 2
θ

< ∞. Then
for any f : Θ →R with varπ(f) < ∞, var(f, ˜P) < ∞.
We note that this result holds even in the case where Wθ is unbounded, in
which case ˜P is not geometrically ergodic: the functions f with varπ(f) < ∞
that have inﬁnite asymptotic variance in this case are not functions of θ alone
and must depend on w.

254
Handbook of Approximate Bayesian Computation
9.3.3
Comparison of algorithms
The results of the previous section are mostly concerned with comparisons
of the noisy algorithm with its noiseless version. We consider now com-
paring diﬀerent variations of the noisy algorithm. Intuitively one would, at
comparable cost, prefer to use an algorithm which uses the estimators with
the lowest variability. It turns out that the relevant notion of variability is the
convex order [19].
Deﬁnition 9.1. The random variables W1 ∼F1 and W2 ∼F2 are convex
ordered, denoted W1 ≤cx W2 or F1 ≤cx F2 hereafter, if for any convex function
φ : R →R,
E[φ(W1)] ≤E[φ(W2)],
whenever the expectations are well deﬁned.
We note that the convex order W (1) ≤cx W (2) of square-integrable random
variables automatically implies var(W (1)) ≤var(W (2)), but that the reverse
is not true in general. As shown in [20, Example 13], while the convex order
allows one to order performance of competing algorithms, the variance is not
an appropriate measure of dispersion.
Let
¯P1
and
¯P2
be
the
corresponding
competing
pseudo-marginal
implementations of the MH algorithm targeting π(·) marginally sharing the
same family of proposal distributions {q(θ, ·), θ ∈Θ}, but using two families
of weight distributions {Q(1)
θ , θ ∈Θ} and {Q(2)
θ , θ ∈Θ}. Hereafter the prop-
erty Q(1)
θ
≤cx Q(2)
θ
for all θ ∈Θ is denoted {Q(1)
θ , θ ∈Θ} ≤cx {Q(2)
θ , θ ∈Θ}.
We introduce the notion of the right spectral gap, GapR(Π), of a μ-reversible
Markov chain evolving on E, noting that the MH update is reversible with
respect to its invariant distribution. This can be intuitively understood as
follows in the situation where E is ﬁnite, in which case the transition matrix
Π can be diagonalised (in a certain sense) and its eigenvalues shown to be
contained in [−1, 1]. In this scenario, GapR(Π) = 1 −λ2, where λ2 is the sec-
ond largest eigenvalue of Π. These ideas can be generalised to more general
spaces. The practical interest of the right spectral gap is that it is required to
be positive for geometric ergodicity to hold and provides information about
the geometric rate of convergence when, for example, all the eigenvalues (in the
ﬁnite scenario) are non-negative.
Theorem 9.7. Let π(·) be a probability distribution on some measurable
space (Θ, T ), and let ¯P1 and ¯P2 be two pseudo-marginal approximations of P
aiming to sample from π(·), sharing a common family of marginal proposal
probability distributions {q(θ, ·), θ ∈Θ}, but with distinct weight distributions
satisfying {Q(1)
θ , θ ∈Θ} ≤cx {Q(2)
θ , θ ∈Θ}. Then,
1. for any θ, ϑ ∈Θ, the conditional acceptance rates satisfy αθϑ( ¯P1) ≥
αθϑ( ¯P2),

Theoretical and Methodological Aspects of MCMC Computations
255
2. for any f : Θ →R with varπ(f) < ∞, the asymptotic variances satisfy
var(f, ¯P1) ≤var(f, ¯P2),
3. the spectral gaps satisfy GapR( ¯P1) ≥min{GapR( ¯P2), 1 −˜ρ∗
2}, where ˜ρ∗
2 :=
˜π2-ess sup(θ,w)˜ρ2(θ, w), the essential supremum of the rejection probability
corresponding to ¯P2,
4. if π(θ) is not concentrated on points, that is π({θ}) = 0 for all θ ∈Θ, then
GapR( ¯P1) ≥GapR( ¯P2).
Various applications of this result are presented in [20], including the char-
acterisation of extremal bounds of performance measures for {Qθ, θ ∈Θ}
belonging to classes of probability distributions (i.e. with given variance). As
we shall see in the next section, this result is also useful to establish that
averaging estimators always improves the performance of algorithms, that in-
troducing dependence between such copies may be useful, or that stratiﬁcation
may be provably helpful in some situations.
9.4
Strategies to Improve Performance
9.4.1
Averaging estimators
Both intuition and theoretical results indicate that reducing variability of the
estimates of π(·) in terms of the convex order ensures improved performance.
We brieﬂy discuss here some natural strategies. The ﬁrst one consists of av-
eraging estimators of the density, that is considered for any θ ∈Θ estimators
of π(θ) of the form:
1
N
N

i=1
π(θ)W i = π(θ) 1
N
N

i=1
W i,
for (w1, w2, . . . , wN) ∼QN
θ

·

for a probability distribution QN
θ

·

on RN
+
such that for i = 1, . . . , N [3]:

wiQN
θ (w1, w2, . . . , wN)d(w1, w2, . . . , wN) = 1,
and chosen in such a way that it reduces the variability of the estimator.
A possibly useful application of this idea in an ABC framework could consist
of using a stationary Markov chain with a Qθ-invariant transition kernel to
sample W 1, W 2, . . ., such as a Gibbs sampler, which may not require evalua-
tion of the probability density of the observations.
Increasing N is, broadly speaking, always a good idea, at least provided
one can perform computations in parallel at no extra cost.

256
Handbook of Approximate Bayesian Computation
Proposition 9.1 (see e.g. [19, Corollary 1.5.24]). For exchangeable random
variables

W 1, W 2, . . .

, for any N ≥1:
1
N + 1
N+1

i=1
W i ≤cx
1
N
N

i=1
W i.
Letting
˜PN denote the noisy transition kernel using N exchangeable
random variables

W 1, W 2, . . .

, this leads to the following result [20] by a
straightforward application of Theorem 9.7.
Theorem 9.8. Let

W 1, W 2, . . .

be exchangeable and f satisfy π(f 2) < ∞.
Then for N ≥2, N →var(f, ˜PN) is non-increasing.
It can also be shown, with an additional technical condition, that N →
GapR
 ˜PN

is non-decreasing, suggesting improved convergence to equilibrium
for positive algorithms.
A simple question arising from Theorem 9.8, is whether var(f, ˜PN) ap-
proaches var(f, P) as N →∞for all f, such that π(f 2) < ∞under weaker
conditions than in Theorem 9.2. In the ABC setting, however, it can be shown
under fairly weak assumptions when Θ is not compact that this is not the
case [16, Theorem 2].
Theorem 9.9. Assume that ψ satisﬁes (9.1), π(θ) > 0 for all θ ∈Θ,
ℓABC(yobs | θ) →0 as |θ| →∞, and:
lim
r→∞sup
θ∈Θ
q(θ, B∁
r(θ)) = 0,
where B∁
r(θ) is the complement of the | · | ball of radius r around θ. Then ˜PN
cannot be geometrically ergodic for any N, and there exist functions f with
π(f 2) < ∞, such that var(f, ˜PN) is not ﬁnite.
The assumptions do not preclude the possibility that P is geometrically
ergodic and hence var(f, P) being ﬁnite for all f with π(f 2) < ∞, and so this
result represents a failure to inherit geometric ergodicity in such cases. This
result can be generalised to other choices of ψ under additional assumptions,
see the supplement to [16].
The inability of ˜PN more generally to escape the fate of ˜P1 is perhaps
not surprising: from Table 9.1, we can see that apart from the case where P
is a geometric RWM, the conditions on Wθ are unaﬀected by simple averag-
ing. Further results in this direction are provided by quantitative bounds on
asymptotic variances established by [21, Proposition 4] when ψ satisﬁes (9.1)
and by [22] for general pseudo-marginal algorithms; more detailed results than
below can be found in the latter.
Theorem 9.10. Assume that ˜PN is positive. Then for f : Θ →R with
varπ(f) < ∞,
var(f, ˜P1) ≤(2N −1)var(f, ˜PN).

Theoretical and Methodological Aspects of MCMC Computations
257
This shows that the computational cost of simulating the Markov chain
with transition kernel ˜PN is proportional to N, then there is little to no gain
in using N ≥1. This is, however, not always the case: there may be some
signiﬁcant overhead associated with generating the ﬁrst sample, or parallel
implementation may make using some N > 1 beneﬁcial [22]. It also implies
that var(f, ˜PN) < ∞implies var(f, ˜P1) < ∞so the class of π-ﬁnite variance
functions with ﬁnite var(f, ˜PN) does not depend on N. The selection of pa-
rameters governing the concentration of Wθ around 1 in order to maximise
computational eﬃciency has been considered more generally in [23] and [24],
although the assumptions in these analyses are less speciﬁc to the ABC setting.
We now consider dependent random variables W 1, . . . , W N. It is natu-
ral to ask whether for a ﬁxed N ≥1, introducing dependence can be either
beneﬁcial or detrimental. We naturally expect that introducing some form
of negative dependence between estimates could be helpful. For probability
distributions F1, F2, . . . , FN deﬁned on some measurable space

E, E

, the as-
sociated Fr´echet class F

F1, F2, . . . , FN

is the set of probability distributions
on EN with F1, F2, . . . , FN as marginals. There are various ways one can com-
pare the dependence structure of elements of F

F1, F2, . . . , FN

and one of
them is the supermodular order, denoted:

W 1, W 2, . . . , W N
≤sm

˜W 1, ˜W 2, . . . , ˜W N
.
(9.10)
hereafter, (see [19] for a deﬁnition). In the case N = 2, this can be shown to
be equivalent to:
E

f

W 1
g

W 2
≤E

f
 ˜W 1
g
 ˜W 2
,
for any non-decreasing functions f, g : E →R for which the expectations exist.
Interestingly, (9.10) implies the following convex order:
N

i=1
W i ≤cx
N

i=1
˜W i,
see, for example, the results in [25, Section 9.A]. An immediate application of
Theorem 9.7 allows us then to order corresponding noisy algorithms in terms
of the dependence structure of

W 1, W 2, . . . , W N
and
 ˜W 1, ˜W 2, . . . , ˜W N
.
We note, however, that it may be diﬃcult in practical situations to check that
the supermodular order holds between two sampling schemes.
9.4.2
Rejuvenation
We have seen that introducing multiple copies and averaging improves perfor-
mance of the algorithm, at the expense of additional computation, which may
oﬀset the beneﬁts if parallel architectures cannot be used. In this section, we
show that the introduction of N ≥2 copies also allows for the development
of other algorithms, which may address the sticky behaviour of some ABC

258
Handbook of Approximate Bayesian Computation
algorithms. We observe that averaging also induces a discrete mixture struc-
ture of the distribution targetted:
π(θ)QN
θ (w1, w2, . . . , wN) 1
N
N

i=1
wi =
N

i=1
1
N π(θ)QN
θ (w1, w2, . . . , wN)wi
=
N

k=1
˜π(k, θ, w1, w2, . . . , wN)
with
˜π(k, θ, w1, w2, . . . , wN) := 1
N π(θ)QN
θ (w1, w2, . . . , wN)wk.
This is one of the other (hidden) ideas of [26], which can also be implicitly
found in [27,28], where such a distribution is identiﬁed as target distribution
of the algorithm. This means that the mechanism described in Algorithm 9.3
is not the sole possibility in order to deﬁne MCMC updates targetting π(θ)
marginally. In particular, notice the form of the following two conditional
distributions:
˜π(k | θ, w1, w2, . . . , wN) =
wk
N
i=1 wi ,
(9.11)
and with w−k :=

w1, w2, . . . , wk, wk+1, . . . , wN
:
˜π(w−k | k, θ, wk) = QN
θ (w−k | wk),
(9.12)
which can be used as Gibbs type MCMC updates leaving ˜π invariant. In
addition, we have the standard decomposition:
˜π(k, θ, w1, w2, . . . , wN) = ˜π(k | θ, w1, w2, . . . , wN) × ˜π(θ, w1, w2, . . . , wN)
= ˜π(k | θ, w1, w2, . . . , wN)
× π(θ)QN
θ (w1, w2, . . . , wN) 1
N
N

i=1
wi,
which tells us that at equilibrium, k can always be recovered by sampling from
(9.11). Then (9.12) suggests that one can rejuvenate N −1 of the aggregated
pseudo-marginal estimators w1, w2, . . . , wN, provided sampling from Qθ(w−k |
wk) is simple: this is always the case when independence is assumed. From
above, the following MCMC update leaves ˜π(θ, w1, w2, . . . , wN) invariant:
R(θ, w; d(ϑ, u)) :=
N

k=1
˜π(k | θ, w)QN
θ (u−k | wk)δθ,wk(dϑ × duk),
and is described algorithmically in Algorithm 9.4 [where P

w1, w2, . . . , wN
]
is the probability distribution of a discrete valued random variable, such that
P

K = k

∝wk).

Theoretical and Methodological Aspects of MCMC Computations
259
Algorithm 9.4: iSIR Algorithm
1
Given θ, w1, w2, . . . , wN
2
Sample k ∼P

w1, w2, . . . , wN
3
Sample u−k ∼QN
θ (· | wk) and set uk = wk
4
Return θ, u1, . . . , uN
Such algorithms are of general interest, and are analysed in [29]. This update
can, however, also be intertwined with the standard ABC update. In the
context of ABC, this gives Algorithm 9.5.
Algorithm 9.5: iSIR with ABC
1
Given θ, y1, . . . , yN
2
Sample k ∼P

ψ(y1, yobs), ψ(y2, yobs), . . . , ψ(yN, yobs)

3
Sample ˜yi ∼ℓ

· | θ

λ(d·), i ∈{1, . . . , N} \ {k} and set ˜yk = yk
4
Return θ, ˜y1, . . . , ˜yN
and intertwining Algorithm 9.5 with Algorithm 9.3 one obtains Algorithm 9.6.
In fact, a recent result [30, Theorem 17] ensures that the resulting algo-
rithm has a better asymptotic variance, the key observation being that one can
compare two diﬀerent inhomogeneous Markov chains with alternating transi-
tion kernels ˜P and R. For the standard pseudo-marginal algorithm, R is the
identity, whereas for ABC with rejuvenation, R is the iSIR.
9.4.3
Playing with the Us
In practice, simulation of the random variables Y on a computer often involves
using d (pseudo-)random numbers uniformly distributed on the unit interval
[0, 1], which are then mapped to form one Y i. That is, there is a mapping from
the unit cube [0, 1]d to Y, and with an inconsequential abuse of notation, if
U i ∼U(

0, 1
d) then Y (U i) ∼ℓ(y | θ)λ(dy) and
Tθ(N) := 1
N
N

i=1
ψ

Y

U i
, yobs

,
is
an
unbiased
estimator
of (9.2),
equivalent
in
fact
to (9.7).
This
representation is discussed in [31] as a general reparametrisation strategy to
circumvent intractability, and we show here how this can be also exploited
in order to improve the performance of ABC-MCMC. An extremely simple
illustration of this is the situation where d = 1 and an inverse cdf method is
used, that is Y (U) = F −1(U), where F is the cumulative distribution function
(cdf) of Y . This is the case, for example, for the g-and-k model, whose inverse
cdf is given by [6].

260
Handbook of Approximate Bayesian Computation
Algorithm 9.6: ABC-MCMC with Rejuvenation
1
Given θ, y1, . . . , yN
2
Sample k ∼P

ψ(y1, yobs), ψ(y2, yobs), . . . , ψ(yN, yobs)

3
Sample ˜yi ∼ℓ

· | θ

λ(d·), i ∈{1, . . . , N} \ {k} and set ˜yk = yk
4
Sample ϑ ∼q(θ, ·)
5
Sample ˇyi ∼ℓ

· | ϑ

λ(d·), i ∈{1, . . . , N}
6
Return (ϑ, ˇy1, . . . , ˇyN) with probability
min
⎧
⎪
⎪
⎨
⎪
⎪
⎩
1,
η(ϑ) × 1
N
N

i=1
ψ(ˇyi, yobs)q(ϑ, θ)
η(θ) × 1
N
N

i=1
ψ(˜yi, yobs)q(θ, ϑ)
⎫
⎪
⎪
⎬
⎪
⎪
⎭
,
otherwise return (θ, ˜y1, . . . , ˜yN).
9.4.3.1
Stratiﬁcation
Stratiﬁcation is a classical variance reduction strategy with applications to
Monte Carlo methods. It proceeds as follows in the present context. Let A :=

A1, . . . , AN

be a partition of the unit cube [0, 1]d, such that P(U 1 ∈Ai) =
1/N and such that it is possible to sample uniformly from each Ai. Perhaps
the simplest example of this is when A corresponds to the dyadic sub-cubes of
[0, 1]d. Let V i ∼U(Ai) for i = 1, . . . , N be independent. We may now replace
the estimator in (9.7) with:
T strat
θ
(N) := 1
N
N

i=1
ψ

Y

V i
, yobs

.
It is straightforward to check that this is a non-negative unbiased estimator of
ℓψ
ABC(yobs | θ), which means that W strat
θ
(N) := T strat
θ
(N)/ℓψ
ABC(yobs | θ) has
unit expectation as required. It has been shown in [20, Section 6.2] that when
ψ satisﬁes (9.1), Theorem 9.7 applies directly in this scenario and that ˜P strat,
the approximation of P corresponding to using {W strat
θ
(N), θ ∈Θ} instead of
{Wθ(N), θ ∈Θ} always dominates ˜P. These results extend to more general
choices of ψ(·, ·), but require a much better understanding of this function.
9.4.3.2
Introducing dependence between estimators
Ideally for the acceptance probability of ˜P,
min
	
1, r(θ, ϑ)wϑ
wθ

,
to be reasonably large, we would like wϑ large when wθ is large. That is, we
would like large and nefarious realisations of wθ to be compensated by larger
values of wϑ. A natural idea is therefore to attempt to introduce ‘positive de-
pendence’ between the estimators. [32] discuss the introduction of dependence

Theoretical and Methodological Aspects of MCMC Computations
261
in the discussion of [26], and a more sophisticated methodology that seeks to
correlate wθ and wϑ has recently been proposed in [33].
Viewing the introduction of positive dependence very generally, for θ, ϑ ∈
Θ let Qθϑ(dw × du) have marginals Qθ(dw) and Qϑ(dw). It is shown in [20]
that if in addition:
Qθϑ(A × B) = Qϑθ(B × A),
θ, ϑ ∈Θ,
A, B ∈B(R+),
then the algorithm with the earlier acceptance ratio and proposal Qθϑ(A ×
B)/Qθ(A) remains exact, that is, reversible with respect to (9.5). A natu-
ral question is how one may implement the abstract condition earlier. Let
U(S) denote the uniform distribution over the set S. In the context of ABC
applications where the observations are functions of U ∼U(

0, 1
d), that is
Y = Y (U), it is possible to introduce dependence on the uniforms involved.
Assume for now that d = 1 and let C(·, ·) be a copula, that is a probability
distribution on

[0, 1]2, B

[0, 1]2
with the uniform distribution on [0, 1] as
marginals [34]. Some copulas induce positive or negative dependence between
the pair of uniforms involved. It is possible to deﬁne a partial order among cop-
ulas (and in fact more generally for distributions with ﬁxed marginals), which
ranks copulas in terms of the ‘strength’ of the dependence. The concordance
order (W (2)
θ
, W (2)
ϑ ) ≤c (W (1)
θ
, W (1)
ϑ ) holds if and only if for any non-decreasing
functions for which the expectations exist:
E

f

W (2)
θ

g

W (2)
ϑ

≤E

f

W (1)
θ

g

W (1)
ϑ

.
Now let for any θ ∈Θ, Wθ = wθ

U1

= ψ ◦yθ

U1

and

U1, U2

∼C(·, ·).
If C(·, ·) is symmetric, then for any θ, ϑ ∈Θ, with A−1
θ
:=

u ∈[0, 1] :
wθ(u) ∈A

Qθϑ

Wθ ∈Aθ, Wϑ ∈Aϑ

= P

U1 ∈A−1
θ , U2 ∈A−1
ϑ

= C

A−1
θ , A−1
ϑ

= C

A−1
ϑ , A−1
θ

= Qϑθ

Wϑ ∈Aϑ, Wθ ∈Aθ

,
that is the required condition is satisﬁed for the algorithm to remain exact.
Now, for example, if for any θ ∈Θ wθ : [0, 1] →R+ is monotone, one should
choose a copula which induces positive dependence. Indeed, as stated in [20],
(W (2)
θ
, W (2)
ϑ ) ≤c (W (1)
θ
, W (1)
ϑ ) implies that the expected acceptance ratio is
larger for the choice (W (1)
θ
, W (1)
ϑ ) than the (W (2)
θ
, W (2)
ϑ ). However, increasing
the expected acceptance probability does not guarantee improved performance
of the algorithm: for example, in the limiting case, the Fr´echet–Hoeﬀding
bounds will lead to reducible Markov chains in many scenarios. More speciﬁ-
cally, consider the copula deﬁned as a mixture of the independent copula and
the ‘copy’ copula with weights (λ, 1 −λ):
Cλ(A, B) = λU(A ∩B) + (1 −λ)U(A)U(B).

262
Handbook of Approximate Bayesian Computation
This copula is symmetric for all λ ∈[0, 1] and is such that sampling from its
conditionals is simple: copy with probability λ or draw afresh from a uniform.
Note that λ = 0 corresponds to the standard pseudo marginal. It is not diﬃcult
to show that if 0 ≤λ ≤λ′ ≤1, then (W (λ)
θ
, W (λ)
ϑ
) ≤c (W (λ′)
θ
, W (λ′)
ϑ
), meaning
that the conditional acceptance ratio is a non-decreasing function of λ in terms
of the concordance order. However, the choice λ = 1, which corresponds to
the upper Fr´echet–Hoeﬀding bound will obviously lead to a reducible Markov
chain. This is therefore a scenario where λ needs to be optimised and where
adaptive MCMC may be used [35]. Such schemes can naturally be extended
to the multivariate scenario, but require the tuning of more parameters and
an understanding of the variations of wθ(·) along each of its coordinates.
9.4.4
Locally adaptive ABC-Markov chain Monte Carlo
Given the inability of ˜PN to inherit geometric ergodicity from P in fairly
simple ABC settings, one may wonder if an alternative Markov kernel that uses
a locally adaptive number of pseudo-samples can. A variety of such kernels are
presented in [36], but we restrict our interest here to the ‘1-hit’ ABC-MCMC
method proposed in [37] for the speciﬁc setting where ψ satisﬁes (9.1):
Algorithm 9.7: 1-hit ABC-MCMC
1
Given θ
2
Sample ϑ ∼q(θ, ·)
3
With probability
1 −min
	
1, η(ϑ)q(ϑ, θ)
η(θ)q(θ, ϑ)

,
stop and output θ.
4
Sample Yθ ∼ℓ(· | θ)λ(d·) and Yϑ ∼ℓ(· | ϑ)λ(d·) independently until
I {∥s(Yθ) −s(yobs)∥≤ϵ} + I {∥s(Yϑ) −s(yobs)∥≤ϵ} ≥1,
and output ϑ if I {∥s(Yϑ) −s(yobs)∥≤ϵ} = 1. Otherwise, output θ
This algorithm deﬁnes a Markov chain evolving on Θ that is not a Metropolis–
Hastings Markov chain. Indeed, the algorithm deﬁnes a transition kernel ˇP in
which the proposal is q as in Algorithm 9.1, but the acceptance probability is:
min
	
1, η(ϑ)q(ϑ, θ)
η(θ)q(θ, ϑ)

×
ℓψ
ABC(yobs | ϑ)
ℓψ
ABC(yobs | θ) + ℓψ
ABC(yobs | ϑ) −ℓψ
ABC(yobs | θ)ℓψ
ABC(yobs | ϑ)
.

Theoretical and Methodological Aspects of MCMC Computations
263
From this, it can be veriﬁed directly that the Markov chain is reversible with
respect to π.
An interesting feature of this algorithm is that a random number of pseudo-
observations from the distributions associated with both θ and ϑ are sampled
in what can intuitively be viewed as a race between the two parameter values.
In fact, the number of paired samples required for the race to terminate, N, is a
geometric random variable depending on both ℓψ
ABC(yobs | θ) and ℓψ
ABC(yobs | ϑ)
in such a way that N is typically larger when these quantities are both small
and smaller when either of these are large. This can be interpreted broadly
as a local adaptation of the computational eﬀort expended in simulating the
Markov chain, in contrast to the ﬁxed N strategy outlined in Section 9.4.1.
In [16, Proposition 3], it is shown that the expected computational cost of
simulating each iteration of the resulting Markov chain is bounded whenever η
deﬁnes a proper prior. In [16, Theorem 4], it is shown that ˇP can inherit (under
additional assumptions) geometric ergodicity from P even when Theorem 9.9
holds, that is, ˜PN is not geometrically ergodic for any N. Consequently, ˇP
can provide superior estimates of expectations, in comparison to ˜PN, for some
functions f, such that π(f 2) < ∞.
9.4.5
Inexact algorithms
A natural question in the context of ABC-MCMC methods is how pseudo-
marginal methods compare to inexact variants. Of course, there are a large
number of inexact methods, and we consider here only the simple case aris-
ing from a small modiﬁcation of the pseudo-marginal algorithm known as
Monte Carlo within Metropolis (MCWM) [38]. In this algorithm, a Markov
chain is deﬁned by the transition kernel ˆPλ, whose algorithmic description is
given in Algorithm 9.8. Here, as in the pseudo-marginal approach, one has for
any λ > 0:
EQ(λ)
θ
[Wθ] = 1,
θ ∈Θ,
and one deﬁnes a Markov chain evolving on Θ as follows:
Algorithm 9.8: MCWM ABC
1
Given θ
2
Sample ϑ ∼q(θ, ·)
3
Sample Wθ ∼Q(λ)
θ
4
Sample Wϑ ∼Q(λ)
ϑ
5
Return the realisation ϑ with probability
min
	
1, π(ϑ) × Wϑq(ϑ, θ)
π(θ) × Wθq(θ, ϑ)

,
otherwise return θ.

264
Handbook of Approximate Bayesian Computation
This Markov chain has been studied in [3], in the case where P is uniformly
ergodic, see also [39]. Extensions to the case where P is geometrically ergodic
are considered in [40]. One such result is [40, Theorem 4.1]:
Theorem 9.11. Assume P is geometrically ergodic, that
lim
λ→0 sup
θ∈Θ
Q(λ)
θ (|Wθ −1| > δ) = 0,
∀δ > 0,
and
lim
λ→0 sup
θ∈Θ
EQ(λ)
θ

W −1
θ

= 1.
Then ˆPλ is geometrically ergodic for all suﬃciently small λ. In addition, under
a very mild technical assumption on P:
lim
λ→0 ∥π −ˆπλ∥TV = 0,
where ˆπλ is the unique invariant distribution associated with ˆPλ for suﬃciently
small λ.
Results of this kind invite comparison with corresponding results for ˜P,
the pseudo-marginal Markov transition kernel. While Theorem 9.11 is reas-
suring, the earlier assumptions correspond to ‘uniform in θ’ assumptions on
Q(λ)
θ , similar to assumptions for analysing ˜P, that may not hold in practical
applications. Nevertheless, there are diﬀerences, and ˇP can be geometrically
ergodic when ˜P is not when the same distributions {Qθ, θ ∈Θ} are em-
ployed for both. On the other hand, examples in which ˜P is geometrically
ergodic, but ˆP is transient can also be constructed, so a degree of caution is
warranted.
This result can be interpreted in the speciﬁc case where N is a number
of i.i.d. pseudo-samples. When Wθ(N) is a simple average of N i.i.d. ran-
dom variables Wθ, one can see that the assumptions of Theorem 9.11 are
weaker than corresponding assumptions for ˜PN. In fact, the conditions are
satisﬁed when the weights Wθ are uniformly integrable (rather than being uni-
formly bounded) and there exist constants M > 0, β > 0 and γ ∈(0, 1) such
that:
sup
θ∈Θ
Qθ(Wθ ≤w) ≤Mwβ,
w ∈(0, γ).
The latter condition imposes, for example, the requirement that Qθ(Wθ = 0)=0
for all θ ∈Θ, and indeed the MCWM algorithm is not deﬁned without this as-
sumption. When the weights Wθ additionally have a uniformly bounded 1+k
moment, then one can obtain bounds on the rate of convergence of ˆπN to π
in total variation [40, Proposition 4.1].

Theoretical and Methodological Aspects of MCMC Computations
265
9.5
Remarks
In this chapter, we have presented a relevant subset of theory and directions
in methodological research pertaining to ABC-MCMC algorithms. Given the
recent prevalence of applications involving ABC, this survey has not been
exhaustive and has focused on speciﬁc aspects in which the theory is partic-
ularly clear. For example, we have not treated the question of which kernels
are most appropriate in various applications, and indeed methodological in-
novations such as the incorporation of a tolerance parameter ϵ [such as that
found in (9.1), but which may parameterise alternative kernels as well] as a
state variable of the ABC Markov chain (see, e.g. [41,42]).
Theoretical and methodological advances continue to be made in this
area. For example, the spectral gap of the Markov kernel ˜PN discussed in
Section 9.4.1 does not increase as a function of N in general, and it is of in-
terest to consider whether alternative Markov kernels can overcome this issue.
In [43], it is shown that in many cases the spectral gap of the ABC-MCMC ker-
nel with rejuvenation in Section 9.4.2 does improve as N grows, and alternative
methodology similar to that in Section 9.4.4 is both introduced and analysed.
Finally, we note that when the model admits speciﬁc structure, alternatives
to the simple ABC method presented here may be more computationally eﬃ-
cient. Indeed, in the case where the observations are temporally ordered, then
it is natural and typically much more eﬃcient to consider sequential Monte
Carlo methods for generating Wθ (see, e.g. [44]).
References
[1] M. A. Beaumont, W. Zhang, and D. J. Balding. Approximate Bayesian
computation in population genetics. Genetics, 162(4):2025–2035, 2002.
[2] S. Tavare, D. J. Balding, R. Griﬃths, and P. Donnelly. Inferring coales-
cence times from DNA sequence data. Genetics, 145(2):505–518, 1997.
[3] C. Andrieu and G. O. Roberts. The pseudo-marginal approach for eﬃ-
cient Monte Carlo computations. Ann. Statist., 37(2):697–725, 2009.
[4] P. Marjoram, J. Molitor, V. Plagnol, and S. Tavar´e. Markov chain
Monte Carlo without likelihoods. Proc. Natl. Acad. Sci. USA, 100(26):
15324–15328, 2003.
[5] R. D. Wilkinson. Approximate Bayesian computation gives exact results
under the assumption of model error. Stat. Appl. Genet. Mol. Biol.,
12(2):129–141, 2013.

266
Handbook of Approximate Bayesian Computation
[6] P. Fearnhead and D. Prangle. Constructing summary statistics for ap-
proximate Bayesian computation: Semi-automatic approximate Bayesian
computation. J. R. Stat. Soc. Ser. B Stat. Methodol., 74(3):419–474, 2012.
[7] T. A. Dean, S. S. Singh, A. Jasra, and G. W. Peters. Parameter estimation
for hidden Markov models with intractable likelihoods. Scand. J. Statist.,
41(4):970–987, 2014.
[8] M. A. Beaumont. Estimation of population growth or decline in geneti-
cally monitored populations. Genetics, 164:1139–1160, 2003.
[9] A. Kennedy and J. Kuti. Noise without noise: A new Monte Carlo
method. Physical Review Letters, 54(23):2473, 1985.
[10] L. Lin and J. Sloan. A stochastic Monte Carlo algorithm. Phys. Rev. D,
61(hep-lat/9905033):074505, 1999.
[11] C. Becquet and M. Przeworski. A new approach to estimate parame-
ters of speciation models with application to apes. Genome research,
17(10):1505–1519, 2007.
[12] P. Del Moral, A. Doucet, and A. Jasra. An adaptive sequential Monte
Carlo method for approximate Bayesian computation. Stat. Comput.,
22(5):1009–1020, 2012.
[13] S. A. Sisson, Y. Fan, and M. M. Tanaka. Sequential Monte Carlo without
likelihoods. Proc. Natl. Acad. Sci. USA, 104(6):1760–1765, 2007.
[14] C. Andrieu and M. Vihola. Convergence properties of pseudo-marginal
Markov chain Monte Carlo algorithms. Ann. Appl. Probab., 25(2):
1030–1077, 2015.
[15] R. Douc, G. Fort, E. Moulines, and P. Soulier. Practical drift condi-
tions for subgeometric rates of convergence. Ann. Appl. Probab., 14(3):
1353–1377, 2004.
[16] A. Lee and K. Latuszy´nski. Variance bounding and geometric ergodicity
of Markov chain Monte Carlo kernels for approximate Bayesian compu-
tation. Biometrika, 101(3):655–671, 2014.
[17] G. O. Roberts and J. S. Rosenthal. Variance bounding Markov chains.
Ann. Appl. Probab., 18(3):1201–1214, 2008.
[18] G. Deligiannidis and A. Lee. Which ergodic averages have ﬁnite asymp-
totic variance? arXiv preprint arXiv:1606.08373, 2016.
[19] A. M¨uller and D. Stoyan. Comparison Methods for Stochastic Models and
Risks. Hoboken, NJ: Wiley, 2002.
[20] C. Andrieu and M. Vihola. Establishing some order amongst exact ap-
proximations of MCMCs. Ann. Appl. Probab., 26(5):2661–2696, 2016.

Theoretical and Methodological Aspects of MCMC Computations
267
[21] L. Bornn, N. S. Pillai, A. Smith, and D. Woodard. The use of a sin-
gle pseudo-sample in approximate Bayesian computation. Stat. Comput.,
27:583–590, 2017.
[22] C. Sherlock, A. Thiery, and A. Lee. Pseudo-marginal Metropolis–Hastings
using averages of unbiased estimators. Biometrika, 104(3):727–734,
2017.
[23] C. Sherlock, A. H. Thiery, G. O. Roberts, and J. S. Rosenthal. On the
eﬃciency of pseudo-marginal random walk Metropolis algorithms. Ann.
Statist., 43(1):238–275, 2015.
[24] A. Doucet, M. K. Pitt, G. Deligiannidis, and R. Kohn. Eﬃcient implemen-
tation of Markov chain Monte Carlo when using an unbiased likelihood
estimator. Biometrika, 102(2):295–313, 2015.
[25] M. Shaked and J. G. Shanthikumar. Stochastic Orders. New York:
Springer, 2007.
[26] C. Andrieu, A. Doucet, and R. Holenstein. Particle Markov chain Monte
Carlo methods. J. R. Stat. Soc. Ser. B Stat. Methodol., 72(3):269–342,
2010.
[27] H. Tjelmeland. Using all Metropolis–Hastings proposals to estimate mean
values. Technical Report 4, Norwegian University of Science and Tech-
nology, Trondhem, Norway, 2004.
[28] H. M. Austad. Parallel multiple proposal MCMC algorithms. Master’s
thesis, Norwegian University of Science and Technology, 2007.
[29] C. Andrieu, A. Lee, and M. Vihola. Uniform ergodicity of the iterated
conditional SMC and geometric ergodicity of particle Gibbs samplers.
Bernoulli, 24(2):842–872, 2018.
[30] F. Maire, R. Douc, and J. Olsson. Comparison of asymptotic variances of
inhomogeneous Markov chains with application to Markov chain Monte
Carlo methods. Ann. Statist., 42(4):1483–1510, 2014.
[31] C. Andrieu, A. Doucet, and A. Lee. Discussion of ‘Constructing summary
statistics for approximate Bayesian computation: semi-automatic approx-
imate Bayesian computation’ by Fearnhead and Prangle. J. R. Stat. Soc.
Ser. B Stat. Methodol., 74(3):451–452, 2012.
[32] A. Lee and C. Holmes. Discussion of ‘particle Markov chain Monte Carlo’
by Andrieu, Doucet & Holenstein. J. R. Stat. Soc. Ser. B Stat. Methodol.,
72(3):327–329, 2010.
[33] G. Deligiannidis, A. Doucet, and M. K. Pitt. The correlated pseudo-
marginal method. arXiv preprint arXiv:1511.04992, 2015.

268
Handbook of Approximate Bayesian Computation
[34] R. B. Nelsen. An Introduction to Copulas, volume 139. New York:
Springer, 1999.
[35] C. Andrieu and J. Thoms. A tutorial on adaptive MCMC. Stat. Comput.,
18(4):343–373, 2008.
[36] A. Lee. On the choice of MCMC kernels for approximate Bayesian com-
putation with SMC samplers. In Proceedings of the Winter Simulation
Conference, 2012.
[37] A. Lee, C. Andrieu, and A. Doucet. Discussion of ‘Constructing sum-
mary statistics for approximate Bayesian computation: Semi-automatic
approximate Bayesian computation’ by Fearnhead and Prangle. J. R.
Stat. Soc. Ser. B Stat. Methodol., 74(3):449–450, 2012.
[38] P. D. O’Neill, D. J. Balding, N. G. Becker, M. Eerola, and D. Mollison.
Analyses of infectious disease data from household outbreaks by Markov
chain Monte Carlo methods. J. R. Stat. Soc. Ser. C Applied Statistics,
49(4):517–542, 2000.
[39] P. Alquier, N. Friel, R. Everitt, and A. Boland. Noisy Monte Carlo:
Convergence of Markov chains with approximate transition kernels. Stat.
Comput., 16(1):29–47, 2016.
[40] F. J. Medina-Aguayo, A. Lee, and G. O. Roberts. Stability of noisy
Metropolis–Hastings. Stat. Comput., 26(6):1187–1211, 2016.
[41] P. Bortot, S. G. Coles, and S. A. Sisson. Inference for stereological ex-
tremes. J. Am. Stat. Assoc., 102(477):84–92, 2007.
[42] O. Ratmann, C. Andrieu, C. Wiuf, and S. Richardson. Model criticism
based on likelihood-free inference, with an application to protein network
evolution. Proc. Natl. Acad. Sci. USA, 106(26):10576–10581, 2009.
[43] A. Lee, C. Andrieu, and A. Doucet. An active particle perspective of
MCMC and its application to locally adaptive MCMC algorithms. In
preparation.
[44] J. S. Martin, A. Jasra, S. S. Singh, N. Whiteley, P. Del Moral, and
E. McCoy. Approximate Bayesian computation for smoothing. Stoch.
Anal. Appl., 32(3):397–420, 2014.

10
Asymptotics of ABC
Paul Fearnhead
CONTENTS
10.1
Introduction ......................................................
269
10.2
Posterior Concentration ..........................................
272
10.2.1
Posterior concentration of ABC .........................
272
10.2.2
Rate of concentration ...................................
274
10.2.3
Eﬀect of binding function ...............................
275
10.2.4
Model error ..............................................
276
10.3
ABC Posterior and Posterior Mean ..............................
277
10.3.1
ABC posterior ...........................................
277
10.3.2
ABC posterior mean ....................................
279
10.4
Monte Carlo Error ...............................................
281
10.5
The Beneﬁts of Regression Adjustment
.........................
283
10.6
Discussion ........................................................
285
Acknowledgements .......................................................
286
References
...............................................................
286
10.1
Introduction
This chapter aims to give an overview of recent work on the asymptotics
of approximate Bayesian computation (ABC). By asymptotics here we mean
how does the ABC posterior, or point estimates obtained by ABC, behave in
the limit as we have more data? The chapter summarises results from three
papers, Li and Fearnhead (2018a), Frazier et al. (2016) and Li and Fearnhead
(2018b). The presentation in this chapter is deliberately informal, with the
hope of conveying both the intuition behind the theoretical results from these
papers and the practical consequences of this theory. As such, we will not
present all the technical conditions for the results we give: The Interested
269

270
Handbook of Approximate Bayesian Computation
reader should consult the relevant papers for these, and the results we state
should be interpreted as holding under appropriate regularity conditions.
We will focus on ABC for a p-dimensional parameter, θ, from a prior
p(θ) (we use the common convention of denoting vectors in bold, and we
will assume these are column vectors). We assume we have data of size n
that is summarised through a d-dimensional summary statistic. The asymp-
totic results we review consider the limit n →∞, but assume that the sum-
mary statistic is of ﬁxed dimension. Furthermore, all results assume that
the dimension of the summary statistic is at least as large as the dimen-
sion of the parameters, d ≥p – this is implicit in the identiﬁability condi-
tions that we will introduce later. Examples of such a setting are where the
summaries are sample means of functions of individual data points, quan-
tiles of the data, or, for time-series data, are empirical auto-correlations of
the data. It also includes summaries based on ﬁxed-dimensional auxillary
models (Drovandi et al., 2015) or on composite likelihood score functions
(Ruli et al., 2016).
To distinguish the summary statistic for the observed data from the sum-
mary statistic of data simulated within ABC, we will denote the former by
sobs and the latter by s. Our model for the data will deﬁne a probability model
for the summary. We assume that this in turn speciﬁes a probability density
function, or likelihood, for the summary, fn(s; θ), which depends on the pa-
rameter. In some situations, we will want to refer to the random variable for
the summary statistic, and this will be Sn,θ. As is standard with ABC, we
assume that we can simulate from the model, but cannot calculate fn(s; θ).
The most basic ABC algorithm is a rejection sampler (Pritchard et al.,
1999), which iterates the following three steps:
(RS1) Simulate a parameter from the prior: θi ∼p(θ).
(RS2) Simulate a summary statistic from the model given θi: si ∼fn(s|θi).
(RS3) Accept θi if ∥sobs −si∥< ϵ.
Here, ∥sobs −si∥is a suitably chosen distance between the observed and
simulated summary statistics, and ϵ is a suitably chosen bandwidth. In the
following, we will assume that ||x|| is either Euclidean distance, ||x||2 = xT x,
or a Mahalanobis distance, ||x||2 = xT Γx for some chosen positive-deﬁnite
d × d matrix Γ.
If we deﬁne a (uniform) kernel function, K(x), to be 1 if ∥x∥< 1
and 0 otherwise, then this rejection sampler is drawing from the following
distribution:
πABC(θ) ∝p(θ)

fn(s|θ)K
sobs −s
ϵ

ds.

Asymptotics of ABC
271
We call this the ABC posterior. If we are interested in estimating a function
of the parameter h(θ), we can use the ABC posterior mean:
hABC =

h(θ)πABC(θ)dθ.
In practice, we cannot calculate this posterior mean analytically, but would
have to estimate it based on the sample mean of h(θi) for parameter values θi
simulated using the previous rejection sampler.
In this chapter, we review results on the behaviour of the ABC posterior,
the ABC posterior mean, and Monte Carlo estimates of this mean as n →∞.
In particular, we consider whether the ABC posterior concentrates around
the true parameter value in Section 10.2. We then consider the limiting
form of the ABC posterior and the frequentist asymptotic distribution of
the ABC posterior mean in Section 10.3. For the latter two results, we com-
pare these asymptotic distributions with those of the true posterior given the
summary – which is the best we can hope for once we have chosen our sum-
mary statistics.
The results in these two sections ignore any Monte Carlo error. The impact
of Monte Carlo error on the asymptotic variance of our ABC posterior mean
estimate is the focus of Section 10.4. This impact depends on the choice of
algorithm we use to sample from the ABC posterior (whereas the choice of
algorithm has no eﬀect on the actual ABC posterior or posterior mean that
are analysed in the earlier sections). The earlier rejection sampling algorithm
is ineﬃcient in the limit as n →∞, and thus we consider more eﬃcient
importance sampling and Markov chain Monte Carlo (MCMC) generalisations
in this section.
We then review results that show how post-processing the output of ABC
can lead to substantially stronger asymptotic results. The chapter ﬁnishes with
a discussion that aims to draw out the key practical insights from the theory.
Before we review these results, it is worth mentioning that we can gener-
alise the deﬁnition of the ABC posterior, and the associate posterior mean,
given earlier. Namely, we can use a more general form of kernel than the uni-
form kernel. Most of the results we review apply if we replace the uniform
kernel by a diﬀerent kernel, K(x), that is monotonically decreasing in ∥x∥.
Furthermore, the speciﬁc form of the kernel has little aﬀect on the asymptotic
results – what matters most is how we choose the bandwidth and, in some
cases, the choice of distance. The fact that most of the theoretical results do
not depend on the choice of kernel means that, for concreteness, we will pri-
marily assume a uniform kernel in our following presentation. The exceptions
being in Section 10.3 where it is easier to get an intuition for the results if we
use a Gaussian kernel. By focussing on these two choices, we do not mean to
suggest that they are necessarily better than other choices, it is just that they
simplify the exposition. We will return to the choice of kernel in the Discussion.

272
Handbook of Approximate Bayesian Computation
10.2
Posterior Concentration
The results we present in this section are from Frazier et al. (2016) (though
see also Martin et al., 2016) and consider the question of whether the ABC
posterior will place increasing probability mass around the true parameter
value as n →∞. It is the most basic convergence result we would wish for,
requires weaker conditions than results we give in Section 10.3, and is thus
easier to apply to other ABC settings (see, e.g. Marin et al., 2014; Bernton
et al., 2017).
We will denote the true parameter value by θ0. If we deﬁne:
PrABC(∥θ −θ0∥< δ) =

θ:∥θ−θ0∥<δ
πABC(θ)dθ,
the ABC posterior probability that θ is within some distance δ of the true
parameter value, then for posterior concentration, we want that for any δ > 0:
PrABC(∥θ −θ0∥< δ) →1,
as n →∞. That is, for any strictly positive choice of distance, δ, regard-
less of how small it is, as n →∞, we need the ABC, posterior to place
all its probability on the event that θ is within δ of the true parameter
value.
To obtain posterior concentration for ABC, we will need to let the band-
width depend on n, and henceforth we denote the bandwidth by ϵn.
10.2.1
Posterior concentration of ABC
The posterior concentration result of Frazier et al. (2016) is based upon as-
suming a law of large numbers for the summary statistics. Speciﬁcally, we
need the existence of a binding function, b(θ), such that for any θ:
Sn,θ →b(θ),
in probability as n →∞. If this holds, and the binding function satisﬁes
an identiﬁability condition: that b(θ) = b(θ0) implies θ = θ0, then we have
posterior concentration providing the bandwidth tends to zero, ϵn →0.
To gain some insight into this result and the assumptions behind it, we
present an example. To be able to visuallise what is happening, we will
assume that the parameter and summary statistic are both one-dimensional.
Figure 10.1 shows an example binding function, a value of θ0 and sobs, and
output from the ABC rejection sampler.
As n increases, we can see the plotted points, that show proposed param-
eter and summary statistic values, converge towards the line that shows the

Asymptotics of ABC
273
s
2
3
4
5
6
7
s
2
3
4
5
6
7
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
2
3
4
5
6
7
s
2
3
4
5
6
7
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
FIGURE 10.1
Example binding function, b(θ) (top-left plot). Pairs of parameter and sum-
mary statistic values proposed by a rejection sampler (top-middle). Output
of rejection sampler (top-right): θ0 and b(θ0) (dotted vertical and horizontal
lines, respectively); sobs (bold circle and dashed horizontal line) and accep-
tance region for proposed summaries (bold dashed horizonal lines); and pairs
of parameter and summary statistic values accepted (bold) and rejected (grey)
by the rejection sampler. Bottom-row plots are the same as top-right plot, but
for increasing n and decreasing ϵn. Here, and for all plots, our results are for
a simple scenario where data are independent and identically distributed (iid)
Gaussian with a mean that is a function of the parameter, and the summary
statistic is the sample mean. (In this case the binding function is, by deﬁnition,
equal to the mean function.)
binding function. This stems from our assumption of a law of large numbers
for the summaries, so that for each θ value, the summaries should tend to b(θ)
as n increases.
We also have that the observed summary statistic, sobs, converges towards
b(θ0). Furthermore, we are decreasing the bandwidth as we increase n, which
corresponds to narrower acceptance regions for the summaries, which means
that the accepted summary statistics converge towards b(θ0). Asymptotically,
only parameter values close to θ0, which have values b(θ) which are close
to b(θ0), will simulate summaries close to b(θ0). Hence, the only accepted
parameter values will be close to, and asymptotically will concentrate on, θ0.
This can be seen in practice from the plots in the bottom row of Figure 10.1.
The identiﬁability condition on the binding function is used to ensure that
concentration of accepted summaries around b(θ0) results in ABC posterior

274
Handbook of Approximate Bayesian Computation
concentration around θ0. What happens when this identiﬁability condition
does not hold is discussed in Section 10.2.3.
10.2.2
Rate of concentration
We can obtain stronger results by looking at the rate at which concentration
occurs. Informally, we can think of this as the supremum of rates, λn →0,
such that:
PrABC(∥θ −θ0∥< λn) →1,
as n →∞. For parametric Bayesian inference with independent and identically
distributed data, this rate would be 1/√n.
Assuming the binding function is continuous at θ0, then the rate of
concentration will be determined by the rate at which accepted summaries
concentrate on b(θ0). As described earlier, this depends on the variability
(or ‘noise’) of the simulated summaries around the binding function and on
the bandwidth, ϵn. The rate of concentration will be the slower of the rates at
which the noise in the summary statistics and the rate at which ϵn tend to 0.
We can see this from the example in Figure 10.2, where we show output
from the ABC rejection sampler for diﬀerent values of n, but with ϵn tending
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
2
3
4
5
6
7
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
FIGURE 10.2
Example of ABC concentration for diﬀering rates of the noise in the sum-
mary statistics and rates of ϵn. Plots are as in Figure 10.1. Top-row: noise in
summary statistics halving, or equivalently sample size increasing by a factor
of 4, and ϵn decreasing by 1/
√
2 as we move from left to right. Bottom-row:
noise in summary statistics decreasing by 1/
√
2, or equivalently sample size
doubling, and ϵn halving as we move from left to right.

Asymptotics of ABC
275
to 0 at either a faster or slower rate than that of the noise in the summaries.
For each regime, the rate of concentration of both the accepted summaries and
of the accepted parameter values is determined by the slower of the two rates.
10.2.3
Eﬀect of binding function
The shape of the binding function for values of θ for which b(θ) is close to
b(θ0) aﬀects the ABC posterior, as it aﬀects the range of θ values that will
have a reasonable chance of producing summary statistic values that would
be accepted by the ABC rejection sampler.
If the identiﬁability condition holds and the binding function is diﬀeren-
tiable at θ0, then the value of this gradient will directly impact the ABC
posterior variance. This is shown in the top row of Figure 10.3. If this gra-
dient is large (top-left plot) then even quite large diﬀerences in summary
statistics would correspond to small diﬀerences in the parameter, and, hence
a small ABC posterior variance. By comparison, if the gradient is small
(top-right plot), then large diﬀerences in parameters may mean only small
diﬀerences in summary statistics. In this case, we expect a much larger ABC
posterior variance for the same width of the region in which the summary
statistics are accepted.
2
3
4
5
6
s
0.5
1.0
1.5
2.0
2.5
3.0
3.5
−1.0−0.5 0.0 0.5 1.0 1.5
θ
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
2
3
4
5
6
7
s
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
2
3
4
5
6
7
s
0.5
1.0
1.5
2.0
2.5
3.0
3.5
θ
s
FIGURE 10.3
Example of the eﬀect of the shape of binding function on the ABC poste-
rior (plots are as in Figure 10.1). Top row: gradient of binding function at
b(θ0) aﬀects the ABC posterior variance, with larger gradient (left-hand plot)
resulting in lower ABC posterior variance than smaller gradient (right-hand
plot). Bottom row: eﬀect of non-identiﬁability on the ABC posterior.

276
Handbook of Approximate Bayesian Computation
The bottom row of Figure 10.3 shows what can happen if the identiﬁability
condition does not hold. The bottom-left plot gives an example where there are
two distinct parameter values for which the binding function is equal to b(θ0).
In this case, we have a bi-modal ABC posterior that concentrates on these
two values. The bottom-right plot shows an example where there is a range of
parameter values whose binding function value is equal to b(θ0), and in this
case, the ABC posterior will concentrate on this range of parameter values.
It can be diﬃcult in practice to know whether the identiﬁability condi-
tion holds. In large data settings, observing a multi-modal posterior as in
the bottom-left plot of Figure 10.3 would suggest that it does not hold. In
such cases, it may be possible to obtain identiﬁability by adding extra sum-
maries. The wish to ensure identiﬁability is one reason for choosing a higher-
dimensional summary than parameter. However, this does not come without
potential cost, as we show in Section 10.3.
10.2.4
Model error
One of the implicit assumptions behind the result on posterior concentration
is that our model is correct. This manifests itself within the assumption that
as we get more data, the observed summary statistic will converge to the value
b(θ0). If the model we assume in ABC is incorrect, then this may not be the
case (see Frazier et al., 2017, for a fuller discussion of the impact of model
error). There are then two possibilities, the ﬁrst is that the observed summary
statistic will converge to a value b(˜θ) for some parameter value ˜θ ̸= θ0. In
this case, by the earlier arguments, we can still expect posterior concentration
but to ˜θ and not θ0.
The other possibility is that the observed summary statistic converges to
a value that is not equal to b(θ) for any θ. This is most likely to occur when
the dimension of the summary statistic is greater than the dimension of the
parameter. To give some insight into this scenario, we give an example in
Figure 10.4, where we have independent identically distributed data from a
Gaussian distribution with mean θ and variance θ2+2, but our model assumes
the mean and variance are θ and θ2 + 1, respectively. This corresponds to a
wrong assumption about the variance. We then apply ABC with summary
statistics that are the sample mean and variance.
As shown in the ﬁgure, we still can get posterior concentration in this
setting. If we denote the limiting value of the binding function for the true
model as b0, then the posterior concentrates on parameter value, or values,
whose binding function value is closest, according to the distance we use for
deciding whether to accept simulated summaries, to b0.
In this second scenario, it may be possible to detect the model error
by monitoring the closeness of the accepted summaries to the observed
summaries. If the model is correct, then the distance between accepted and
observed summaries tends to 0 with increasing n. Whereas in this model error
scenario, these distances will tend towards some non-zero constant.

Asymptotics of ABC
277
−2
−1
0
1
2
1
2
3
4
5
s1
s2
−2
−1
0
1
2
1
2
3
4
5
s1
s2
−2
−1
0
1
2
1
2
3
4
5
s1
s2
−2
−1
0
1
2
1
2
3
4
5
s1
s2
FIGURE 10.4
Example of the eﬀect of model error in ABC for the Gaussian model with
incorrect variance described in the text. The plots, from left to right and
top to bottom, correspond to increasing sample size. Each plot shows the
two-dimensional binding function as we vary θ (line); the observed summary
statistic (grey circle) and accepted (black dots) and rejected (grey dots) sum-
mary statistic values. (For this model the parameter value used to simulate
the summary statistics will be close to the ﬁrst summary statistic, s1.)
10.3
ABC Posterior and Posterior Mean
We now consider stronger asymptotic results for ABC. To obtain these results,
we need extra assumptions in addition to those required for posterior concen-
tration (see Frazier et al., 2016; Li and Fearnhead, 2018a, for full details). The
most important of these is that the summary statistics obey a central limit
theorem:
√n {Sn,θ −b(θ)} →N {0, A(θ)} ,
for some d × d positive deﬁnite matrix A(θ). In the aforementioned central
limit theorem, we have assumed a 1/√n rate of convergence, but it is trivial
to generalise this (Li and Fearnhead, 2018a).
10.3.1
ABC posterior
Under this central limit assumption, we ﬁrst consider convergence of the ABC
posterior. Formal results can be found in Frazier et al. (2016) (but see also
Li and Fearnhead, 2018b). Here, we give an informal presentation of these
results.

278
Handbook of Approximate Bayesian Computation
To gain intuition about the limiting form of the ABC posterior, we can
use the fact from the previous section that there is posterior concentration
around θ0. Thus, asymptotically, we need only consider the behaviour of the
model for θ close to θ0. Also, asymptotically, the noise in the summaries is
Gaussian. So if we make a linear approximation to b(θ) for θ close to θ0, our
model will be well approximated by:
Sn,θ = b(θ0) + D0(θ −θ0) +
1
√nZ,
where D0 is the d × p matrix of ﬁrst derivatives of b(θ) with respect to θ,
with these derivatives evaluated at θ0; and Z is a d-dimensional Gaussian
random variable with covariance matrix A(θ0). Furthermore, for θ close to
θ0, the prior will be well approximated by a uniform prior. For the following,
we assume that D0 is of rank p.
Wilkinson (2013) shows that the eﬀect of the approximation in ABC,
whereby we accept simulated summaries which are similar, but not identical,
to the observed summary, is equivalent to performing exact Bayesian inference
under a diﬀerent model. This diﬀerent model has additional additive noise,
where the distribution of the noise is given by the kernel, K(·), we use in ABC.
So if V is a d-dimensional random variable with density K(·), independent
of Z, then our ABC posterior will behave like the true posterior for the model:
Sn,θ = b(θ0) + D0(θ −θ0) +
1
√nZ + ϵnV .
(10.1)
From Section 10.2.2, we know that the rate of concentration is the slower of the
rate of the noise in the summaries, 1/√n under our central limit theorem, and
the bandwidth ϵn. This means that we get diﬀerent limiting results depending
on whether ϵn = O(1/√n) or not. This can be seen from (10.1), as whether
ϵn = O(1/√n) or not will aﬀect whether the ϵnV noise term dominates or not.
If √nϵn →∞, so ϵn is the slower rate, then to get convergence of the ABC
posterior we need to consider the re-scaled variable t = (θ −θ0)/ϵn. If we
further deﬁne ˜Sn,θ = {Sn,θ −b(θ0)}/ϵn, then we can re-write (10.1) as:
˜Sn,θ = D0t + V +
1
ϵn
√nZ →D0t + V .
Thus, the limiting form of the ABC posterior is equivalent to the true posterior
for this model, given observation ˜sobs = {sobs−b(θ0)}/ϵn, with a uniform prior
for t. The shape of this posterior will be determined by the ABC kernel. If we
use the standard uniform kernel, then the ABC posterior will asymptotically
be uniform. By converting from t to θ, we see that the asymptotic variance
for θ is O(1/ϵ2
n) in this case.
The other case is that √nϵn →c for some positive, ﬁnite constant c. In
this case, we consider the re-scaled variable t = √n(θ −θ0) and re-scaled

Asymptotics of ABC
279
observation ˜Sn,θ = √n{Sn,θ −b(θ0)}. The ABC posterior will asymptotically
be equivalent to the true posterior for t under a uniform prior, for a model:
˜Sn,θ = D0t + Z + ϵn
√nV →D0t + Z + cV ,
and given an observation ˜sobs = √n{sobs −b(θ0)}.
We make three observations from this. First, if ϵn = o(1/√n), so c = 0,
then using standard results for the posterior distribution of a linear model,
the ABC posterior for t will converge to a Gaussian with mean:
{DT
0 A(θ0)−1D0}−1DT
0 A(θ0)−1˜sobs,
(10.2)
and variance I−1, where I = DT
0 A(θ0)−1D0. This is the same limiting form
as the true posterior given the summaries. The matrix I can be viewed as
an information matrix, and note that this is larger if the derivatives of the
binding function, D0, are larger; in line with the intuition we presented in
Section 10.2.3.
Second, if c ̸= 0, the ABC posterior will have a larger variance than the
posterior given summaries. This inﬂation of the ABC posterior variance will
increase as c increases. In general, it is hard to say the form of the posterior,
as it will depend on the distribution of noise in our limiting model, Z + cV ,
which is a convolution of the limiting Gaussian noise of the summaries and a
random variable drawn from the ABC kernel.
Finally, we can get some insight into the behaviour of the ABC posterior
when c ̸= 0 if we assume a Gaussian kernel, as again the limiting ABC pos-
terior will be the true posterior for a linear model with Gaussian noise. If the
Gaussian kernel has variance Σ, which corresponds to measuring distances
between summary statistics using the scaled distance ∥x∥= xT Σ−1x, then
the ABC posterior for t will converge to a Gaussian with mean:

DT
0 (A(θ0) + c2Σ)−1D0
−1 DT
0 {A(θ0) + c2Σ}−1˜sobs,
(10.3)
and variance, ˜I−1, where:
˜I = DT
0 {A(θ0) + c2Σ}−1D0.
10.3.2
ABC posterior mean
We now consider the asymptotic distribution of the ABC posterior mean.
By this we mean the frequentist distribution, whereby we view the posterior
mean as a function of the data and look at the distribution of this under
repeated sampling of the data. Formal results appear in Li and Fearnhead
(2018a), but we will give informal results, building on the results we gave
for the ABC posterior. We will focus on the case where ϵn = O(1/√n),
but note that results hold for the situation where ϵn decays more slowly;
in fact, Li and Fearnhead (2018a) show that if ϵn = o(n−3/10), then the ABC

280
Handbook of Approximate Bayesian Computation
posterior mean will have the same asymptotic distribution as for the case we
consider, where ϵn = O(1/√n).
The results we stated for the ABC posterior in Section 10.3.1 for the case
ϵn = O(1/√n) included expressions for the posterior mean; see (10.2) and
(10.3). The latter expression was under the assumption of a Gaussian kernel
in ABC, but most of the exposition we give below holds for a general kernel
(see Li and Fearnhead, 2018a, for more details).
The ﬁrst of these, (10.2), is the true posterior mean given the summaries.
Asymptotically our re-scaled observation ˜sobs has a Gaussian distribution with
mean 0 and variance A(θ0) due to the central limit theorem assumption, and
the posterior mean for t is a linear transformation of ˜sobs. This immediately
gives that the asymptotic distribution of the ABC posterior mean of t is
Gaussian with mean 0 and variance I−1. Equivalently, for large n, the ABC
posterior mean for θ will be approximately normally distributed with mean
θ0 and variance I−1/n.
The case where √nϵn →c for some c > 0 is more interesting. If we have
d = p, so we have the same number of summaries as we have parameters, then
D0 is a square matrix. Assuming this matrix is invertible, we see that the ABC
posterior mean simpliﬁes to D−1
0 ˜sobs. Alternatively, if d > p, but Σ = γA(θ0)
for some scalar γ > 0, so that the variance of our ABC kernel is proportional
to the asymptotic variance of the noise in our summary statistics, then the
ABC posterior mean again simpliﬁes; this time to:

DT
0 A(θ0)−1D0
−1 DT
0 A(θ0)−1˜sobs.
In both cases, the expressions for the ABC posterior mean are the same as
for the c = 0 case and are identical to the true posterior mean given the
summaries. Thus, the ABC posterior mean has the same limiting Gaussian
distribution as the true posterior mean in these cases.
More generally for the c > 0 case, the ABC posterior mean will be diﬀerent
from the true posterior mean given the summaries. In particular, the asymp-
totic variance of the ABC posterior mean can be greater than the asymptotic
variance of the true posterior mean given the summaries. Li and Fearnhead
(2018a) show that it is always possible to project a d > p-dimensional sum-
mary to a p-dimensional summary, such that the asymptotic variance of the
true posterior mean is not changed. This suggests using such a p-dimensional
summary statistic for ABC (see Fearnhead and Prangle, 2012, for a diﬀerent
argument for choosing d = p). An alternative conclusion from these results is
that one should scale the distance used to be proportional to an estimate of
the variance of the noise in the summaries.
It is interesting to compare the asymptotic variance of the ABC posterior
mean to the limiting value of the ABC posterior variance. Ideally, these would
be the same, as that implies that the ABC posterior is correctly quantifying
uncertainty. We do get equality when ϵn = o(1/√n); but in other cases we can

Asymptotics of ABC
281
see that the ABC posterior variance is larger than the asymptotic variance of
the ABC posterior mean, and thus ABC over-estimates uncertainty. We will
return to this in Section 10.5.
10.4
Monte Carlo Error
The previous section included results on the asymptotic variance of the ABC
posterior mean – which gives a measure of accuracy of using the ABC posterior
mean as a point estimate for the parameter. In practice, we cannot calculate
the ABC posterior mean analytically, and we need to use output from a Monte
Carlo algorithm, such as the rejection sampler described in the Introduction.
A natural question is what eﬀect does the resulting Monte Carlo error have?
And can we implement ABC in such a way that, for a ﬁxed Monte Carlo sample
size, the Monte Carlo estimate of the ABC posterior mean is an accurate point
estimate? Or do we necessarily require the Monte Carlo sample size to increase
as n increases?
Li and Fearnhead (2018a) explore these questions. To do so, they consider
an importance sampling version of the rejection sampling algorithm we previ-
ously introduced. This algorithm requires the speciﬁcation of a proposal dis-
tribution for the parameter, q(θ), and involves iterating the following N times:
(IS1) Simulate a parameter from the proposal distribution: θi ∼q(θ).
(IS2) Simulate a summary statistic from the model given θi: si ∼fn(s|θi).
(IS3) If ∥sobs −si∥< ϵn, accept θi, and assign it a weight proportional to
π(θi)/q(θi).
The output is a set of, Nacc say, weighted parameter values which can be used
to estimate, for example, posterior means. With a slight abuse of notation,
if the accepted parameter values are denoted θk and their weights wk for
k = 1, . . . , Nacc, then we would estimate the posterior mean of θ by:
ˆθN =
1
	Nacc
k=1 wk
Nacc

k=1
wkθk.
The use of this Monte Carlo estimator will inﬂate the error in our point
estimate of the parameter by Var(ˆθN), where we calculate variance with re-
spect to randomness of the Monte Carlo algorithm.
If the asymptotic variance of the ABC posterior mean is O(1/n), we would
want the Monte Carlo variance to be O(1/(nN)). This would mean that the
overall impact of the Monte Carlo error is to inﬂate the mean square error
of our estimator of the parameter by a factor 1 + O(1/N) (similar to other
likelihood-free methods; e.g. Gourieroux et al., 1993; Heggland and Frigessi,
2004).

282
Handbook of Approximate Bayesian Computation
Now the best we can hope for with a rejection or importance sampler
would be equally weighted, independent samples from the ABC posterior.
The Monte Carlo variance of such an algorithm would be proportional to the
ABC posterior variance. Thus, if we want the Monte Carlo variance to be
O(1/n), then we need ϵn = O(1/√n), as for slower rates the ABC posterior
variance will decay more slowly than O(1/n).
Thus, we will focus on ϵn = O(1/√n). The key limiting factor in terms of
the Monte Carlo error of our rejection or importance sampler is the acceptance
probability. To have a Monte Carlo variance that is O(1/n), we will need an
implementation whereby the acceptance probability is bounded away from 0
as n increases. To see whether and how this is possible, we can examine the
acceptance criteria in step, (RS3) or (IS3):
∥sobs −si∥= ∥{sobs −b(θ0)} + {b(θ0) −b(θi)} + {b(θi) −si}∥.
We need this distance to have a non-negligible probability of being less than
ϵn. Now, the ﬁrst and third bracketed terms on the right-hand side will be
Op(1/√n) under our assumption for the central limit theorem for the sum-
maries. Thus, this distance is at best Op(1/√n), and if ϵn = o(1/√n), the
probability of the distance being less than ϵn should tend to 0 as n increases.
This suggests we need √nϵn →c for some c > 0. For this choice, if we
have a proposal which has a reasonable probability of simulating θ values
within O(1/√n) of θ0, then we could expect the distance to have a non-zero
probability of being less than ϵn as n increases. This rules out the rejection
sampler or any importance sampler with a pre-chosen proposal distribution.
But an adaptive importance sampler that learns a good proposal distribution
(e.g. Sisson et al., 2007; Beaumont et al., 2009; Peters et al., 2012) can have
this property.
Note that such an importance sampler would need a proposal distribution
for which the importance sampling weights are also well behaved. Li and
Fearnhead (2018a) give a family of proposal distributions that have both an
acceptance probability that is non-zero as n →∞and have well-behaved
importance sampling weights.
Whilst Li and Fearnhead (2018a) did not consider MCMC based imple-
mentations of ABC (Marjoram et al., 2003; Bortot et al., 2007), the intuition
behind the results for the importance sampler suggest that we can implement
such algorithms in a way that the Monte Carlo variance will be O(1/(nN)).
For example, if we use a random walk proposal distribution with a variance
that is O(1/n), then after convergence the proposed θ values will be a dis-
tance Op(1/√n) away from θ0 as required. Thus, the acceptance probability
should be bounded away from 0 as n increases. Furthermore, such a scaling is
appropriate for a random walk proposal to eﬃciently explore a target whose
variance is O(1/n) (Roberts et al., 2001). Note that care would be needed
whilst the MCMC algorithm is converging to stationarity, as the proposed
parameter values at this stage will be far away from θ0.

Asymptotics of ABC
283
10.5
The Beneﬁts of Regression Adjustment
We ﬁnish this chapter by brieﬂy reviewing asymptotic results for a popular
version of ABC which post-processes the output of ABC using regression ad-
justment. This idea was ﬁrst proposed by Beaumont et al. (2002) (see Nott
et al., 2014, for links to Bayes linear methods). We will start with a brief de-
scription, then show how using regression adjustment can enable the adjusted
ABC posterior to have the same asymptotic properties as the true posterior
given the summaries, even if ϵn decays slightly slower than 1/√n.
Figure 10.5 provides an example of the ABC adjustment. The idea is to run
an ABC algorithm that accepts pairs of parameters and summaries. Denote
these by (θk, sk) for k = 1 . . . , Nacc. These are shown in the top-left plot of
Figure 10.5. We then ﬁt p linear models that, in turn, aim to predict each
component of the parameter vector from the summaries. The output of this
ﬁtting procedure is a p-dimensional vector ˆα, the intercepts in the p linear
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
2
3
4
5
6
7
8
9
θ
s
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
2
3
4
5
6
7
8
9
θ
s
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
2
3
4
5
6
7
8
9
θ
s
1.0
1.5
2.0
2.5
3.0
3.5
0.0 0.2 0.4 0.6 0.8 1.0 1.2
θ
ABC Posterior
FIGURE 10.5
Example of the regression correction procedure of Beaumont et al. (2002) for
a single parameter, single summary statistic. Output of an ABC algorithm
(top-left) showing accepted pairs of parameter and summary values (dots),
the binding function for this model (solid line), and θ0 and sobs (circle and
also vertical and horizontal lines, respectively). Top-right: the ﬁt from a linear
model predicting the parameter value from the summary (solid line). Bottom-
left: the adjusted output (dots; with original output in grey); we plot both
old and adjusted parameter values against original summary statistic values.
Bottom-right: the ABC posterior based on the original accepted parameter
values (solid line) and the adjusted values (dashed line).

284
Handbook of Approximate Bayesian Computation
models, and a p × d matrix ˆB, whose ijth entry is the coeﬃcient of the j
summary statistic in the linear model for estimating the ith component of θ.
An example of such ﬁt is shown in the top-left hand plot of Figure 10.5.
This ﬁt is indicative of biases in our accepted θ, which correspond to diﬀerent
values of the summaries. In our example, the ﬁt suggests that θ values accepted
for smaller, or larger, values of the summary statistic will, on average, be
less then, or greater than, the true parameter value. We can then use the
ﬁt to correct for this bias. In particular, we can adjust each of the accepted
parameter values to ˜θk for k = 1, . . . , Nacc where:
˜θk = θk −ˆB(sk −sobs).
The adjusted parameter values are shown in the bottom-left plot of Figure
10.5, and a comparison of the ABC posteriors before and after adjustment
are shown in the bottom-right plot. From the latter, we see the adjusted ABC
posterior has a smaller variance and has more posterior mass close to the true
parameter value.
The vector ˆα and the matrix ˆB can be viewed as estimates of the vector
α and the matrix B that minimises the expectation of:
p

i=1
⎛
⎝θi −αi −
d

j=1
BijSj
⎞
⎠
2
,
where expectation is with respect to parameter, summary statistic pairs drawn
from our ABC algorithm. Li and Fearnhead (2018b) show that if we adjust
our ABC output using this optimal B, then, for any ϵn = o(n−3/10), the
adjusted ABC posterior has the same asymptotic limit as the true posterior
given the summaries. Obviously, the asymptotic distribution of the mean of
this adjusted posterior will also have the same asymptotic distribution as the
mean of the true posterior given the summaries.
The intuition behind this result is that, asymptotically, if we choose
ϵn = o(n−3/10), then our accepted samples will concentrate around the true
parameter value. As we focus on an increasingly small ball around the true
parameter value, the binding function will be well approximated by the linear
regression model we are ﬁtting. Thus, the regression correction step is able to
correct for the biases we obtain from accepting summaries that are slightly
diﬀerent from the observed summary statistics. From this intuition, we see
that a key requirement of our model, implicit within the assumptions needed
for the theoretical result, is that the binding function is diﬀerentiable at the
true parameter value: as such, a diﬀerentiability condition is needed for the
linear regression model to be accurate.
In practice we use an estimate ˆB, and this will inﬂate the asymptotic vari-
ance of the adjusted posterior mean by a factor that is 1+O(1/Nacc), a similar
eﬀect to that of using Monte Carlo draws to estimate the mean. Importantly,
we get these strong asymptotic results even when ϵn decays more slowly than

Asymptotics of ABC
285
1/√n. For such a choice, for example, ϵn = O(n−1/3), and with a good impor-
tance sampling or MCMC implementation, the asymptotic acceptance rate of
the algorithm will tend to 1 as n increases.
10.6
Discussion
The theoretical results we have reviewed are positive for ABC. If initially we
ignore using regression adjustment, then the results suggest that ABC with
ϵn = O(1/√n) and with an eﬃcient adaptive importance sampling or MCMC
algorithm will have performance that is close to that of using the true posterior
given the summaries. Ignoring Monte Carlo error, the accuracy of using the
ABC posterior mean will be the same as that of using the true posterior mean
if either we have the same number of summaries as parameters, or we choose an
appropriate Mahalanobis distance for measuring the discrepancy in summary
statistics. However, for this scenario, the ABC posterior will over-estimate the
uncertainty in our point estimate. The impact of Monte Carlo error will only
be to inﬂate the asymptotic variance of our estimator by a factor 1+O(1/N),
where N is the Monte Carlo sample size.
We suggest that this scaling of the bandwidth, ϵn = O(1/√n), is optimal
if we do not use regression adjustment. Choosing either a faster or slower rate
will result in Monte Carlo error that will dominate. One way of achieving
this scaling is by using an adaptive importance sampling algorithm and ﬁxing
the proportion of samples to accept. Thus, the theory supports the common
practice of choosing the bandwidth indirectly in this manner.
Also, based on these results, we suggest choosing the number of summary
statistics to be close to, or equal to, the number of parameters and choosing
a distance for measuring the discrepancy in summary statistics that is based
on the variance of the summary statistics. In situations where there are many
potentially informative summary statistics, a dimension reduction approach,
that tries to construct low-dimensional summaries that retain the information
about the parameters, should be used (e.g. Wegmann et al., 2009; Fearnhead
and Prangle, 2012; Blum et al., 2013; Prangle et al., 2014).
The results for ABC with regression adjustment are stronger still. These
show that the ABC posterior and its mean can have the same asymptotics as
the true ABC posterior and mean given the summaries. Furthermore, this is
possible with ϵn decreasing more slowly than 1/√n, in which case the accep-
tance rate of a good ABC algorithm will increase as n increases. These strong
results suggest that regression adjustment should be routinely applied. One
word of caution is that the regression adjustment involves ﬁtting a number of
linear models to predict the parameters from the summaries. If a large number
of summaries are used, then the errors in ﬁtting these models can be large
(Fearnhead and Prangle, 2012) and lead to under-estimation of uncertainty in

286
Handbook of Approximate Bayesian Computation
the adjusted posterior (Marin et al., 2016). This again suggests using a small
number of summary statistics, close or equal to the number of parameters.
Whilst the choice of bandwidth is crucial to the performance of ABC, and
the choice of distance can also have an important impact on the asymptotic
accuracy, the actual choice of kernel asymptotically has little impact. It aﬀects
the form of the ABC posterior, but does not aﬀect the asymptotic variance of
the ABC posterior mean (at least under relatively mild conditions).
These asymptotic results ignore any ‘higher-order’ eﬀects of the kernel that
become negligible as n gets large; so there may be some small advantages of
one kernel over another for ﬁnite n, but these are hard to quantify. Intuitively,
the uniform kernel seems the most sensible choice–as for a ﬁxed acceptance
proportion, it accepts the summaries closest to the observed. Furthermore, in
situations where there is model error, it is natural to conjecture that a kernel
with bounded support, such as the uniform kernel, will be optimal. For such
a case, we want to only accept summaries that are d0 + O(1/√n), for some
constant distance d0 > 0, away from the observed summary (see Figure 10.4).
This is only possible for a kernel with bounded support.
Acknowledgements
This work was supported by Engineering and Physical Sciences Research
Council (EPSRC) through the i-like programme grant. It also beneﬁtted from
discussions during the BanﬀInternational Research Station (BIRS) workshop
on Validating and Expanding ABC Methods in February 2017.
References
Beaumont, M. A., Cornuet, J.-M., Marin, J.-M. and Robert, C. P. (2009).
Adaptive approximate Bayesian computation. Biometrika 96(4), 983–990.
Beaumont, M. A., Zhang, W. and Balding, D. J. (2002). Approximate
Bayesian computation in population genetics. Genetics 162, 2025–2035.
Bernton, E., Jacob, P. E., Gerber, M. and Robert, C. P. (2017). Inference in
generative models using the Wasserstein distance. arXiv:1701.05146.
Blum, M. G., Nunes, M. A., Prangle, D., Sisson, S. A. et al. (2013). A com-
parative review of dimension reduction methods in approximate Bayesian
computation. Statistical Science 28(2), 189–208.

Asymptotics of ABC
287
Bortot, P., Coles, S. G. and Sisson, S. A. (2007). Inference for stereological
extremes. Journal of the American Statistical Association 102(477), 84–92.
Drovandi, C. C., Pettitt, A. N., Lee, A. et al. (2015). Bayesian indirect infer-
ence using a parametric auxiliary model. Statistical Science 30(1), 72–95.
Fearnhead, P. and Prangle, D. (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 74(3), 419–474.
Frazier, D. T., Martin, G. M., Robert, C. P. and Rousseau, J. (2016). Asymp-
totic properties of approximate Bayesian computation. arXiv.1607.06903.
Frazier, D. T., Robert, C. P. and Rousseau, J. (2017) Model misspeciﬁcation
in ABC: Consequences and diagnostics. arXiv.1708.01974.
Gourieroux, C., Monfort, A. and Renault, E. (1993). Indirect inference.
Journal of Applied Econometrics 8(S1), S85–S118.
Heggland, K. and Frigessi, A. (2004). Estimating functions in indirect infer-
ence. Journal of the Royal Statistical Society: Series B 66, 447–462.
Li, W. and Fearnhead, P. (2018a). On the asymptotic eﬃciency of ap-
proximate Bayesian computation estimators. Biometrika 105(2), 285–299.
https://doi.org/10.1093/biomet/asx078.
Li, W. and Fearnhead, P. (2018b). Convergence of regression-adjusted
approximate
Bayesian
computation.
Biometrika,
105(2),
301–318.
https://doi.org/10.1093/biomet/asx081.
Marin, J.-M., Pillai, N. S., Robert, C. P. and Rousseau, J. (2014). Relevant
statistics for Bayesian model choice. Journal of the Royal Statistical Society:
Series B (Statistical Methodology) 76(5), 833–859.
Marin, J.-M., Raynal, L., Pudlo, P., Ribatet, M. and Robert, C. P. (2016).
ABC random forests for Bayesian parameter inference. arXiv.1605.05537.
Marjoram, P., Molitor, J., Plagnol, V. and Tavare, S. (2003). Markov chain
Monte Carlo without likelihoods. Proceedings of the National Academy of
Sciences 100, 15324–15328.
Martin, G. M., McCabe, B. P., Maneesoonthorn, W. and Robert, C. P. (2016).
Approximate Bayesian computation in state space models. arXiv:1409.8363.
Nott, D. J., Fan, Y., Marshall, L. and Sisson, S. (2014). Approximate Bayesian
computation and Bayes’ linear analysis: Toward high-dimensional ABC.
Journal of Computational and Graphical Statistics 23(1), 65–86.

288
Handbook of Approximate Bayesian Computation
Peters, G. W., Fan, Y. and Sisson, S. A. (2012). On sequential Monte Carlo,
partial rejection control and approximate Bayesian computation. Statistics
and Computing 22(6), 1209–1222.
Prangle, D., Fearnhead, P., Cox, M. P., Biggs, P. J. and French, N. P. (2014).
Semi-automatic selection of summary statistics for ABC model choice.
Statistical Applications in Genetics and Molecular Biology 13(1), 67–82.
Pritchard, J. K., Seielstad, M. T., Perez-Lezaun, A. and Feldman, M. W.
(1999). Population growth of human Y chromosomes: A study of Y chro-
mosome microsatellites. Molecular Biology and Evolution 16, 1791–1798.
Roberts, G. O., Rosenthal, J. S. et al. (2001). Optimal scaling for various
Metropolis-Hastings algorithms. Statistical Science 16(4), 351–367.
Ruli, E., Sartori, N. and Ventura, L. (2016). Approximate Bayesian com-
putation with composite score functions. Statistics and Computing 26(3),
679–692.
Sisson, S. A., Fan, Y. and Tanaka, M. M. (2007). Sequential Monte Carlo with-
out likelihoods. Proceedings of the National Academy of Sciences 104(6),
1760–1765.
Wegmann, D., Leuenberger, C. and Excoﬃer, L. (2009). Eﬃcient approximate
Bayesian computation coupled with Markov chain Monte Carlo without
likelihood. Genetics 182(4), 1207–1218.
Wilkinson, R. D. (2013). Approximate Bayesian computation (ABC) gives
exact results under the assumption of model error. Statistical Applications
in Genetics and Molecular Biology 12(2), 129–141.

11
Informed Choices: How to Calibrate ABC
with Hypothesis Testing
Oliver Ratmann, Anton Camacho, Sen Hu, and Caroline Colijn
CONTENTS
11.1
Introduction ......................................................
289
11.2
Equivalence Hypothesis Tests ....................................
292
11.3
Equivalence Hypothesis Tests within ABC ......................
294
11.4
A User Guide to the abc.star R Package .......................
300
11.4.1
Testing if locations are similar ..........................
300
11.4.2
Testing if dispersions are similar ........................
303
11.4.3
Testing if rates are similar ..............................
305
11.5
A Worked Example ..............................................
306
11.6
Discussion and Further Reading .................................
314
Acknowledgements .......................................................
315
References
...............................................................
315
11.1
Introduction
Approximate Bayesian computations (ABC) proceed by summarising the
data, simulating from the model, comparing simulated summaries to observed
summaries with an ABC distance function, and accepting the simulated
summaries if they do not diﬀer from the observed summaries by more than
a user-deﬁned ABC tolerance parameter. These steps are repeated in many
Monte Carlo iterations to obtain an approximation to the true posterior den-
sity of the model parameters. The process by which precise ABC tolerances
and ABC distance functions can be obtained is often referred to as ‘ABC cal-
ibrations’. The calibrations, that we describe here, apply to the binary ABC
accept/reject kernel that evaluates to zero or one. They are based on deci-
sion theoretic arguments to construct the ABC accept/reject step, so that the
ABC approximation to the posterior density enjoys certain desirable prop-
erties. This book chapter aims to give an introduction to ABC calibrations
289

290
Handbook of Approximate Bayesian Computation
based on hypothesis testing and the abc.star R package that implements
these for the most commonly occurring scenarios.
In the past 15 years, ABC has become a well known inference tool that
is used across many applied sciences (Pritchard et al., 1999; Beaumont et al.,
2002; Fagundes et al., 2007; Bortot et al., 2007; Ratmann et al., 2007,
Cornuet et al., 2008; Luciani et al., 2009; Csill´ery et al., 2010; Silk et al., 2011).
However, ABC has also been criticised: the choice of summaries remains often
arbitrary, summaries can be compared in many possible ways, and the ABC
tolerances are vaguely deﬁned as ‘small enough’ (Barnes et al., 2012; Blum,
2010; Fearnhead and Prangle, 2012; Silk et al., 2013; Dean et al., 2014).
Prangle (2019) discussed in this book approaches for constructing suitable,
multi-dimensional summary statistics S to calculate real-valued, observed, and
simulated summaries sobs ∈Rq and s ∈Rq. This chapter focuses primarily
on the choice of the ABC tolerances h > 0 that are used in the ABC kernel
to penalise the dissimilarity between the simulated and observed summary
statistics. We will see that the approach, that we describe here to specify
the tolerances, will also provide unambiguous speciﬁcations for comparing
simulated to observed summaries.
Let us, for simplicity, consider observed data x1:n = (x1, . . . , xn) that
consist of n real-valued points xi and which have an intractable likelihood
with parameters θ ∈Rp. ABC approximates the posterior distribution of θ:
π( θ | x1:n ) = p( x1:n | θ ) π(θ)
m(x1:n)
,
(11.1)
where π(θ) denotes the prior distribution of θ and m(x1:n) =

p(x1:n | θ)
π(θ)dθ. To circumvent likelihood calculations, the vanilla ABC accept/reject
sampler simulates data y1:m = (y1, . . . , ym) of m real-valued data points and
proceeds as follows with m set equal to n:
1: Set the tolerance h > 0;
2: and calculate the observed summaries sobs = S(x1:n).
3: for i = 1 to N do
4:
repeat
5:
Sample θ∗∼π(θ);
6:
Simulate y1:m ∼p( · |θ∗);
7:
Calculate the simulated summaries s = S(y1:m);
8:
Choose a user-speciﬁed, real-valued discrepancy function d(s, sobs);
9:
until |d(s, sobs)| < h
10:
Set θ(i) = θ∗.
11: end for
12: return θ(1), . . . , θ(N)
The tolerances h and discrepancy functions d are speciﬁed by the user. In the
limit h →0, the target density of the vanilla ABC sampler approximates the
partial posterior distribution:

Informed Choices: How to Calibrate ABC
291
π( θ | sobs ) = p( sobs | θ ) π(θ)
m(sobs)
,
(11.2)
where m(sobs) =

p( sobs | θ ) π(θ) dθ (Doksum and Lo, 1990; Wood, 2010).
If the summaries are suﬃcient, the target density of the vanilla ABC sampler
approximates in the limit h →0 the posterior distribution (11.1). In most
applications of ABC, h cannot be set to zero because the event that the simu-
lated summaries match the observed summaries is extremely rare. For h > 0,
ABC can be biased (Blum, 2010; Fearnhead and Prangle, 2012), and in ad-
dition, the ABC posterior density is typically broader than (11.1) (Beaumont
et al., 2002).
The computational idea behind the ABC calibrations that we will describe
in this chapter is as follows. First, we will introduce lower and upper tolerances
h−, h+ and aim to specify non-symmetric values that oﬀset any bias in the
vanilla ABC sampler. Second, we will make the acceptance region [h−, h+]
wide enough to obtain a pre-speciﬁed degree of computational eﬃciency.
Third, we will choose m larger than n in order to oﬀset the broadening eﬀect
of the tolerances on the ABC approximation to the posterior density (11.1).
We will describe in this chapter how these properties can be obtained if either
the data or the summaries have a particularly simple structure. If this is the
case, these properties are obtained by (a) choosing speciﬁc d and S in line with
statistical testing procedures and (b) by setting h−, h+, m to speciﬁc values
h−
cali, h+
cali, mcali. We refer to this process as ABC calibration, call h−
cali, h+
cali
the calibrated tolerances, and call mcali the calibrated number of simulations.
ABC calibrations involve a bit of mathematics, but we will proceed gently
here. In the ﬁrst sections, we will assume that the data and simulations are
just real values, x1:n = (x1, . . . , xn) and y1:m = (y1, . . . , ym), and that their
distribution is particularly simple, such as xi ∼N(μ, σ2). The basic math-
ematical idea is to interpret the ABC accept/reject step as the outcome of
a particular statistical decision procedure. In the case of step 9 earlier, the
acceptance region is the interval deﬁned by the tolerances, [h−, h+]. This cor-
responds to the structure of classical hypothesis tests. This chapter elaborates
on this particular correspondence and is therefore limited to ABC algorithms
with the binary accept/reject step. We denote the ABC acceptance event by:
T(y1:m, x1:n) ∈[ h−, h+ ],
(11.3)
where the data x1:n are ﬁxed throughout and y1:m are simulated as in step 6.
Similarly, we denote the accept/reject step in the aforementioned vanilla ABC
sampler that evaluates to either zero or one by:
1

T(y1:m, x1:n) ∈[ h−, h+ ]

.
(11.4)
Here, T is a real-valued hypothesis test statistic that comprises S and d in
step 9 earlier. The lower and upper ABC tolerances h−, h+ deﬁne the rejection
region of the hypothesis test. These tolerances are always such that h−< h+,

292
Handbook of Approximate Bayesian Computation
which corresponds to the case h > 0 in step 1 earlier. In Section 11.2, we review
so-called equivalence hypothesis tests. Section 11.3 explains how equivalence
hypothesis tests ﬁt into ABC. Section 11.4 introduces the abc.star R package,
which provides calibration routines for the most commonly used equivalence
hypothesis tests.
In the ﬁnal Section 11.5, we move from very simple data to a time se-
ries example, illustrating how the calibrations could be applied in real-world
applications. We relax the assumption that the data and simulations are
just real-values following a simple probability law. Instead, we consider ar-
bitrarily complex data and assume there are q observed and simulated sum-
maries that are just real values, for example sobs
i,1:n = (sobs
i,1 , . . . , sobs
i,n ) and
ssim
i,1:m = (ssim
i,1 , . . . , ssim
i,m) for i = 1, . . . , q and m ≥n. Typically, we want
at least as many summaries as model parameters, q ≥q. Next, although
the summaries are statistics of the observed and simulated data, we model
their sampling distribution directly and assume that the sampling distribu-
tion is particularly simple; for example, ssim
i,j ∼N(μi, σ2
i ) for j = 1, . . . , m and
i = 1, . . . , q. The ABC accept-reject step is then a combination of q hypothesis
tests, leading to the multivariate accept/reject step:
1

q
i=1
Ti

ssim
i,1:mi, sobs
i,1:n

∈
	
h−
i , h+
i


.
(11.5)
For each test, the free parameters h−
i , h+
i , mi will be calibrated to speciﬁc
values h−
i,cali, h+
i,cali, mi,cali. We close with a discussion and further reading in
Section 11.6.
11.2
Equivalence Hypothesis Tests
Equivalence hypothesis tests are less well known than standard hypothesis
tests, such as the T-test or the Mann-Whitney test (Lehmann and Romano,
2005). We are interested in these because the behaviour of ABC algorithms
can be quantiﬁed in terms of the type-I error probability, the power function,
and other properties of equivalence hypothesis tests.
To remind us of the basic terminology (Lehmann and Romano, 2005),
consider the following simple scenario. Suppose we have two independent and
identically distributed samples x1:n = (x1, . . . , xn), xi ∼N(θx, σ2), y1:m =
(y1, . . . , ym), yi ∼N(θy, σ2), with n > 1 and m > 1. Here, the two samples are
considered random and the model parameters are ﬁxed, with θx, θy unknown,
and σ2 known. As an example, we consider testing if the population means
θx, θy are similar. To derive a two-sample equivalence test in this setting, the
null and alternative hypotheses are:

Informed Choices: How to Calibrate ABC
293
H0 :
ρ /∈[τ −, τ +],
ρ = θy −θx
H1 :
ρ ∈[τ −, τ +],
(11.6)
where τ −< 0 and τ + > 0. The interval [τ −, τ +] is the equivalence region and
ρ is the discrepancy parameter, reﬂecting the discrepancy between θy and θx.
The point of equality is the discrepancy ρ⋆for which θy equals θx. For (11.6),
ρ⋆= 0. An equivalence test rejects the null hypothesis if the test statistic
T falls into the critical region [h−, h+]. We will more typically refer to the
critical region as the ABC acceptance region. In the context of ABC, h−,
h+, τ −, τ +, and m are free parameters, which we seek to set to particularly
desirable values.
The parameters τ −, τ + are new to ABC. They will be instrumental to
calibrating the tolerances h−, h+. An equivalence test is said to be level-
α if, for α > 0 and given equivalence region [τ −, τ +], there are h−
cali, h+
cali,
such that P( T ∈[h−
cali, h+
cali] | ρ ) ≤α for all ρ ∈H0. It is size-α if, for
given α > 0 and equivalence region [τ −, τ +], there are h−
cali, h+
cali, such that
supρ∈H0 P( T ∈[h−
cali, h+
cali] | ρ ) = α. The power of the size-α test at a given
discrepancy is:
pw(ρ) = P( T ∈[h−
cali, h+
cali] | ρ ).
(11.7)
For the equivalence problem (11.6), a ‘two one-sided’ Z-test can be used,
similar to the two one-sided T-test ﬁrst described by Schuirmann (1981)
and Kirkwood and Westlake (1981) for the more general case where σ2 is
also not known. The bivariate two-sample test statistic is T −(y1:m, x1:n) =

nm/(n + m)(¯y −¯x −τ −)/σ and T +(y1:m, x1:n) =

nm/(n + m)(¯y −¯x −
τ +)/σ. The test rejects the null hypothesis if:
{ u1−α ≤T −(y1:m, x1:n)
and
T +(y1:m, x1:n) ≤uα },
(11.8)
where uα is the lower α-quantile of the normal distribution. As will be ap-
parent later, we are only interested in cases where the power is maximised
at the point of equality ρ∗= 0. For the two one-sided Z-test, this is the case
whenever τ −is set to −τ +, for τ + > 0. In this case, (11.8) simpliﬁes to:
T(y1:m, x1:n) ∈[h−
cali, h+
cali],
where
T(y1:m, x1:n) = ¯y −¯x,
h+
cali = uα
σ

nm/(n + m)
+ τ +,
h−
cali = −h+
cali.
(11.9)
The formula for the ABC acceptance region [h−
cali, h+
cali] is exactly such that
the Z-test is size-α. The power of the Z-test in (11.9) is:

294
Handbook of Approximate Bayesian Computation
P( T ∈[h−
cali, h+
cali] | ρ ) = FN (0,1)

uα + τ + −ρ
σ

nm/(n + m)

−FN (0,1)

u1−α + τ −−ρ
σ

nm/(n + m)

,
(11.10)
where FN (0,1) denotes the cumulative density of the normal distribution.
The Z-test illustrates common features of all equivalence tests that we
will consider for ABC inference. The null hypothesis is rejected if T falls
into the ABC acceptance region, which is the opposite when compared to a
test of equality, such as a standard T-test. The tolerances are chosen such
that the probability, that T is inside the ABC acceptance region, is small
when ρ is large. This is interesting in ABC, because we do not want to
accept an ABC iteration frequently, when in fact the discrepancy between
the proposed and true (unknown) model parameters is large. The power is
a unimodal function that is maximised somewhere in [τ −, τ +], which is also
the opposite compared to a test of equality, where power increases with ρ.
This is interesting, because we want the ABC acceptance probability (i.e. the
probability to reject the equivalence null hypothesis) to be largest when ρ
is small. For these two reasons, we describe the ABC accept/reject step as
an equivalence test rather than the standard point null hypothesis tests. We
will expand on the advantages of interpreting the ABC accept/reject step as
the outcome of an equivalence test in the next section. This will involve cal-
ibrating the free parameters such that the power function satisﬁes particular
properties.
Some features of the Z-test are diﬀerent in other hypothesis testing sce-
narios. For example, we will see in Sections 11.4.2–11.4.3 that the discrepancy
ρ is not necessarily deﬁned as the diﬀerence, and that the point of equality ρ⋆
is not necessarily equal to zero. Further, the ABC acceptance regions that we
consider will not necessarily be symmetric around the point of equality.
11.3
Equivalence Hypothesis Tests within ABC
In this section, we will describe how equivalence tests can be embedded into
ABC, explain how the free parameters τ −, τ + and m are calibrated, and out-
line the resulting ABC approximation to the posterior density. For simplicity,
we will focus in this section on the case where the data and simulations are
just real values from a normal distribution, and we will focus on the earlier
Z-test. In this case, ABC is not needed and estimates of interest, such as
posterior densities and maximum likelihood parameter estimates are readily
available. Even so, it is still of interest to obtain ABC approximations that

Informed Choices: How to Calibrate ABC
295
match the known posterior density closely in this setting, because otherwise
it is diﬃcult to trust ABC in more complex examples.
There is one subtle diﬀerence between most equivalence hypothesis tests
that can be found in the literature (Wellek, 2003), and those required for
ABC. In the literature, test statistics are usually derived for the case where
x1:n and y1:m are two random samples. In ABC, the observed data are ﬁxed.
This means that we are interested in one-sample test statistics for equivalence
hypotheses. Let us consider again scenario (11.6). Instead of θx, we consider a
pre-speciﬁed, ﬁxed reference value ν and test the similarity of θy with ν. The
reference value ν could be chosen in many ways. Since we want the ABC ap-
proximation of the likelihood to match the likelihood, we choose the maximum
likelihood estimate of θx. Here, the maximum likelihood estimate is the sam-
ple mean, ¯x = 1/n n
i=1 xi, and we set ν = ¯x. In the more general case, when
working with summaries, we do not need to know the maximum likelihood
value of the parameter of interest. The reference value will be the maximum
likelihood estimate of a parameter from the auxiliary sampling distribution
of the summaries, such as the sample mean of summaries. Let us also write θ
instead of θy. Within ABC, (11.6) changes to:
H0 :
ρ /∈[τ −, τ +],
ρ = θ −¯x
H1 :
ρ ∈[τ −, τ +],
(11.11)
where as before τ + > 0 and τ −= −τ +. For x1:n ﬁxed, the one-sample Z-test
rejects the null hypothesis:
T(y1:m, x1:n) ∈[h−
cali, h+
cali],
where
T(y1:m, x1:n) = ¯y −¯x,
h+
cali = uα
σ
√m + τ +,
h−
cali = −h+
cali.
(11.12)
The formula for the ABC acceptance region is exactly such that the one-sample
Z-test is size-α. We can set the ABC tolerances to the calibrated values h−
cali,
h+
cali in (11.12). This way, the ABC tolerances are always chosen in such a
way to provide an upper bound α on the misclassiﬁcation probability that an
ABC step is accepted, even though the model parameter used to generate the
simulation is very diﬀerent from the model parameter that underlies the data.
This shows that, being able to express the ABC accept/reject step in terms of
several free parameters, we can begin to control the behaviour of ABC. The
size-α property determines two of the ﬁve free ABC parameters.
Furthermore, these ABC tolerances are desirable for several reasons that
are related to the power function of the test. The power of the size-α one-
sample Z-test in (11.12) is:

296
Handbook of Approximate Bayesian Computation
pw(ρ) = P( T ∈[h−
cali, h+
cali] | ρ )
= FN (0,1)

uα + τ + −ρ
σ
√m

−FN (0,1)

u1−α + τ −−ρ
σ
√m

.
(11.13)
To obtain (11.13), we express the calibrated tolerances h−
cali, h+
cali directly in
terms of the free parameters τ −, τ +, m.
Importantly, the power function is the ABC approximation to the likeli-
hood in terms of the auxiliary discrepancy parameter ρ. To see this, note that
the ABC approximation to the likelihood of the vanilla ABC sampler is, in
our notation:
P(T ∈[h−
cali, h+
cali] | θ)
=

1{ T(y1:m, x1:n) ∈[h−
cali, h+
cali]} p( y1:m | θ ) dy1:m.
(11.14)
Accepting an ABC step for θ is equivalent to rejecting the one-sample test for
ρ = θ−¯x, and so the ABC approximation to the likelihood is the probability to
reject the equivalence null hypothesis, for example, the power. Power functions
have been studied extensively in the context of hypothesis testing theory, and
we can re-use these results in the context of ABC. One such ﬁnding is that
the power function, or ABC approximation to the likelihood, is not necessarily
maximised at ρ∗, that is when θ equals the maximum likelihood estimate ¯x.
The mode of pw(ρ) shifts with the choice of τ −in relation to τ +. It is also
known that for (11.12), pw(ρ) maximises at ρ∗when τ −equals −τ +.
For many other tests, the choice of τ −is less intuitive. Fortunately,
power functions, such as (11.13), are often continuous and monotonic with
respect to the free parameters, and so we can use simple Newton-Raphson-
type algorithms to calibrate the free parameter τ −to a value τ −
cali, such that
P( T ∈[h−
cali, h+
cali] | ρ ) is largest at ρ∗. We use Brent’s method when the
calibration values are not analytically known (Press et al., 2007). Thus, the
location property determines the third out of the ﬁve free parameters.
Next, the power function is also the acceptance probability of the ABC
accept/reject step, again, in terms of ρ. The maximum value of the power
function, or acceptance probability, depends on the width of the equivalence
interval [τ −, τ +]. Let us suppose the free parameter τ −is already calibrated
to a value τ −
cali, such that pw(ρ) maximises at ρ∗(for the Z-test, it is simply
τ −
cali = −τ +). The Z-test is not an unbiased test, and so it can happen for
some m, σ, and narrow equivalence intervals that the maximum acceptance
probability is zero. We calibrate the free parameter τ + to a value τ +
cali, such
that the ABC acceptance probability is large at the point of equality, see
Figure 11.1a. But note that it is not a good idea to calibrate τ +, such that
P(T ∈[h−
cali, h+
cali] | ρ∗) is very close to one, because in this case pw(ρ) plateaus
around ρ∗, see again Figure 11.1a. This would mean that many values of θ
close to ¯x are almost equally likely to get accepted with high probability,

Informed Choices: How to Calibrate ABC
297
0.0
0.2
0.4
0.6
0.8
1.0
−1.0
−0.5
0.0
0.5
1.0
ρ
τ+
0.35
0.4
0.5
0.7
0.9
0
1
2
3
−0.4
0.0
0.4
ρ
m
80
120
180
240
(a)
(b)
FIGURE 11.1
Power function of the Z-test. The power of the equivalence Z-test is unimodal
and monotonically decreasing away from the point of equality ρ∗whenever τ −
is set to −τ +. (a) Power of the Z-test as the equivalence region [τ −, τ +] widens.
In this panel, σ = 1.2, m = n = 80, and τ −ﬁxed to −τ +. Power increases
with the width of the equivalence region. (b) gABC density of the Z-test as
m increases. In this panel, σ = 1.2, n = 80, τ −= −τ +, and τ +, such that
the maximum acceptance probability is 0.9. The gABC density is shown for
increasing m (shades of grey) and compared against the g density (black).
and we would not be able to recover the actual maximum likelihood estimate
with ABC. By default, we suggest calibrating τ + to a value τ +
cali, such that
P(T ∈[h−
cali, h+
cali] | ρ∗) = 0.9. In this case, the power drops relatively sharply
away from ρ∗, which makes the maximum likelihood estimate more easily
identiﬁable from ABC output. The value of τ + for which the power at ρ∗
is 0.9 is not known analytically, so we use Brent’s method to determine it
numerically. This eﬃciency property determines the fourth free parameter.
Finally, the ABC approximation to the likelihood (11.13) is usually broader
than the likelihood. To see this, consider the power as a density in ρ:
gABC( ρ | x1:n ) = P

T ∈[h−
cali, h+
cali] | ρ
  
P

T ∈[h−
cali, h+
cali] | ρ

dρ.
(11.15)
We aim to match it against the likelihood of the data, when considered as a
density in terms of ρ. This is straightforward for the example considered here.

298
Handbook of Approximate Bayesian Computation
From:
g(θ | x1:n) = p(x1:n | θ)
 
p(x1:n | θ)dθ ∝exp

−1
2
n
σ2 (¯x −θ)2

, (11.16)
we obtain through a change of variables:
g( ρ | x1:n ) ∝exp

−1
2
ρ2
σ2/n

.
(11.17)
In our simple Z-test example, σ in (11.17) is known. Let us suppose that
the free parameters τ −, τ + are already calibrated as described earlier.
Figure 11.1b compares the shape of gABC( ρ | x1:n ) to that of g( θ | x1:n ),
initially for m = n and then increasing m. We can calibrate the last remain-
ing free parameter m to a value mcali so that the ABC approximation to the
likelihood matches the shape of the likelihood closely in terms of the Kullback–
Leibler (KL) divergence. We do this calibration step again numerically. Let
us make the dependence of gABC on m through the tolerances and T explicit,
and denote the minimum KL divergence after calibration by:
εcali = min
m KL

g( ρ | x1:n )

 gABC,m( ρ | x1:n )

.
(11.18)
The calibration error εcali is calculated as a by-product of the calibrations.
In the more general case, when working with summaries, we do not need
to know the likelihood with respect to the data as in (11.16). We will use
the likelihood of the summaries under their modelled sampling distribution
instead. This shape property determines the last free ABC parameter m.
We are now ready to plug in the calibrated ABC approximation to the like-
lihood into the ABC posterior density πABC( θ | x1:n ). After the calibrations,
we must transform the auxiliary parameter ρ back to the original parame-
ter of interest, θ. In our example, this transformation is simply the diﬀerence
ρ = θ −¯x, which is one-to-one. The ABC posterior density, that results from
using the calibrated Z-test and substituting ρ for θ, is:
πABC( θ | x1:n ) ∝

FN (0,1)

uα + τ +
cali −θ + ¯x
σ
√mcali

−FN (0,1)

u1−α + τ −
cali −θ + ¯x
σ
√mcali
 
π(θ),
(11.19)
which approximates the posterior density:
π( θ | x1:n ) ∝fN (0,1)
 ¯x −θ
σ
√n

π(θ).
(11.20)

Informed Choices: How to Calibrate ABC
299
Let us ﬁrst consider the overall diﬀerence between π( θ | x1:n ) and πABC( θ |
x1:n ) in terms of the KL divergence. The calibrations focus only on the ABC
approximation to the likelihood, which does not involve the prior density.
The prior will usually not inﬂuence the calibrations substantially, because the
calibration error (11.18) is usually very small (typically well below 0.01), and
the same prior term appears in (11.19) and (11.20). We approximate the KL
divergence between π(θ | x1:n) and πABC(θ | x1:n) with that of g(θ | x1:n) and
gABC(θ | x1:n), which equals that of g(ρ | x1:n) and gABC(ρ | x1:n). Hence, to
a good approximation:
KL

π( θ | x1:n )

 πABC( θ | x1:n )

≈εcali.
(11.21)
This calibration was subject to the constraint that, in terms of ρ, the ABC
maximum likelihood estimate is ρ∗. But then, by the way we chose the refer-
ence value ν in (11.11), it follows that the ABC maximum likelihood estimate
equals the maximum likelihood estimate:
argmax
θ
P( T ∈[h−
cali, h+
cali] | θ ) = argmax
θ
p( x1:n | θ ).
(11.22)
Finally, calibrating such that the tolerances correspond to size-α tests pro-
duces a lower bound on the true positive rate of the ABC algorithm in the
sense that:
P

ρ ∈[τ −
cali, τ +
cali]
 T ∈[h−
cali, h+
cali]

≥1−α

P

T ∈[h−
cali, h+
cali]

, (11.23)
where P( T
∈[h−
cali, h+
cali] ) is the acceptance probability of the ABC
algorithm. If the overall ABC acceptance rate is 10% and α = 0.05, then
(11.23) implies that the ABC true positive rate is at least 50%. On the other
hand, if α = 0.01, then (11.23) implies that the ABC true positive rate is
at least 90%. For this reason, we use by default α = 0.01 to calibrate the
tolerances.
These calibration results for the Z-test (11.12) extend to several other
testing scenarios, as we describe in the following. One pre-requisite of the nu-
merical calibrations is that the power function must be available analytically
or to a good approximation, which is the case for the most commonly occur-
ring testing scenarios (Lehmann and Romano, 2005; Wellek, 2003). A more
important pre-requisite is that the data or summaries follow indeed the sam-
pling distribution that is assumed by the underlying testing procedure. For
example, to apply the Z-test, the data or summaries must be i.i.d. normal.
We will re-visit these issues and how equivalence tests can be combined in
Section 11.5 of this chapter.

300
Handbook of Approximate Bayesian Computation
11.4
A User Guide to the abc.star R Package
This section introduces the numerical calibration routines that are available in
the abc.star R package (Ratmann et al., 2016). The latest version is available
from github and can be installed through:
> library(devtools)
> install_github("olli0601/abc.star")
11.4.1
Testing if locations are similar
Suppose that the data or summaries are normally distributed with known
variance. In this case, the one-sample Z-test from Section 11.3 can be used in
ABC to test for location equivalence. The corresponding calibration routine
is ztest.calibrate.
In this section, we focus on the related case that the data or summaries
are normally distributed with unknown variances. For simplicity, we write
xi ∼N(θ0, σ2
0), yi ∼N(θ, σ2) and avoid the more cumbersome notation for
summaries. The null and alternative hypotheses are (11.11), and the one-
sample test statistic is T(y1:m, x1:n) = ¯y −¯x, where again the ﬁxed reference
value is the observed sample mean ¯x = 1
n
n
i=1 xi, and ¯y =
1
m
m
i=1 yi. The
ABC acceptance region is [h−
cali, h+
cali] where:
h+
cali = tα,m−1
ˆσ
√m + τ +,
h−
cali = −h+
cali,
τ −= −τ +,
(11.24)
and tα,m−1 is the lower α-quantile of the t-distribution with m −1 degrees of
freedom, and ˆσ is an estimate of the sample standard deviation σ2 of y1:m.
The power function is:
P( T ∈[h−
cali, h+
cali] | ρ ) = Ftm−1,√mρ/σ

tα,m−1 + τ + −ρ
ˆσ
√m

−Ftm−1,√mρ/σ

t1−α,m−1 + τ −−ρ
ˆσ
√m

,
(11.25)
where Ftm−1,√mρ/σ is the cumulative distribution of a non-central t-distribution
with m −1 degrees of freedom and non-centrality parameter √mρ/σ. The
non-centrality parameter can be approximated with √mρ/ˆσ (Owen, 1965).
To derive the g( ρ | x1:n ) density, we here need to integrate the additional
parameter σ2
0 out. For the reference prior π(θ, σ2
0) ∝1/σ2
0 which is ﬂat with
respect to θ as in (11.16), we obtain in analogy to (11.16–11.17):
g( ρ | x1:n ) ∝

S2(x1:n) + nρ2 −(n−1)+1
2
,

Informed Choices: How to Calibrate ABC
301
where S2(x1:n) = n
i=1(xi −¯x)2. This means that ρ/S2(x1:n) √n follows
a t-distribution with n −1 degrees of freedom. To illustrate the available
R functions, let:
> require(abc.star)
#observed and simulated data
> xn
<- 60; xmean<- 1; xsigma<- 1
> yn
<- 60; ymean<- 1.85; ysigma<- 1.2
> obs <- rnorm(xn, xmean, xsigma)
> sim <- rnorm(yn, ymean, ysigma)
#to make this example reproducible
> obs <- (obs - mean(obs))/sd(obs) * xsigma + xmean
> sim <- (sim - mean(sim))/sd(sim) * ysigma + ymean.
We will now describe all calibration steps one by one and will end with a
function call that calibrates all free parameters in one go. First, we describe
how to obtain the ABC tolerances in (11.24) for the default choice on the
type-I error bound, α = 0.01, and, for example, τ + = 0.8:
> mutost.calibrate(n.of.y=length(sim), s.of.y=sd(sim),
what='CR', tau.u=0.8, alpha=0.01)
c.l
c.u
-0.4295524
0.4295524.
Here, the CR option stands for ‘critical region’ and instructs the calibration
routine to compute the ABC acceptance region. The output ﬁelds c.l and
c.u return the calibrated lower and upper endpoints of the ABC acceptance
region, h−
cali and h+
cali. To obtain α for user-speciﬁed ABC tolerances, say
h−= −0.6 and h+ = 0.6, we can use:
> mutost.calibrate(n.of.y=length(sim), s.of.y=sd(sim), c.u=0.6,
tau.u=0.8, what='ALPHA')
alpha
0.1008706.
There is a 10% chance that the ABC accept/reject step is accepted when the
underlying population mean of the simulated data diﬀers from the observed
sample mean by more than tau.u=0.8. The power function can be calculated
either from h+ assuming that h−= −h+ or, alternatively, from α and τ +
assuming that h−
cali and h−
cali are set as in (11.24):
> rho
<- seq(-0.7,0.7,0.01)
> s.of.T
<- sd(sim)/sqrt(length(sim))
> accprob <- mutost.pow(rho, df=length(sim), s.of.T=s.of.T,
c.u=0.4295524)
# or
> accprob <- mutost.pow(rho, df=length(sim), s.of.T=s.of.T,
tau.u=0.8, alpha=0.01).

302
Handbook of Approximate Bayesian Computation
(b)
(a)
0
1
2
3
−0.6
−0.3
0.0
0.3
0.6
ρ
0.0
0.2
0.4
0.6
0.8
1.0
−0.4
0.0
0.4
ρ
τ+
0.3
0.4
0.5
0.6
0.9
FIGURE 11.2
Calibrated two one-sided T-test. If the data or summaries are normally dis-
tributed with unknown variance, the one-sample version of the two one-sided
T-test can be used in ABC to test for location equivalence. (a) Corresponding
power function for α = 0.01 and increasing equivalence regions for the simu-
lated dataset in the main text. The lower endpoint of the equivalence region
τ −is set to −τ +. Each line in the plot shows the acceptance probability
of the corresponding ABC accept/reject step as a function of ρ = θ −¯x.
(b) Calibrated gABC density (grey dashed line) for τ −
cali = −0.375, τ +
cali = 0.375,
mcali = 164 versus the g density (black).
Figure 11.2a shows the power function for several values of τ + and the de-
fault α = 0.01. The plot shows the acceptance probability of the accept/
reject step as ρ changes, each line corresponding to diﬀerent equivalence
regions [−τ +, τ +]. Intuitively, the acceptance probability increases with
the width of the equivalence region. If [τ −, τ +] = [−0.4, 0.4], the cali-
brated ABC acceptance region is [h−
cali, h+
cali] = [−0.029, 0.029], and the
acceptance probability is only 15% even when ρ
=
0. On the other
hand, if [τ −, τ +] = [−0.9, 0.9], the calibrated ABC acceptance region is
[h−
cali, h+
cali] = [−0.53, 0.53], and the acceptance probability is essentially
ﬂat for a large set of θ close to ¯x. This means that this ABC accept/
reject step will not be able to distinguish between population means θ
within a relatively large area around ¯x. Hence, we should aim for smaller
ABC tolerances. Finally, if [τ −, τ +] = [−0.6, 0.6], the acceptance region is
[h−
cali, h+
cali] = [−0.23, 0.23]. The acceptance probability is 85% when ρ = 0
and declines markedly as θ departs from ¯x. This means that there is a high
chance to accept when θ is very close to ¯x, and that this ABC accept/reject

Informed Choices: How to Calibrate ABC
303
step will likely be able to diﬀerentiate between population means that are
close to ¯x. This calibration process is automated through:
> mutost.calibrate(n.of.y=length(sim),s.of.y=sd(sim),alpha=0.01,
mx.pw=0.9,what='MXPW')
c.l
c.u
tau.l
tau.u
-2.588859e-01
2.588859e-01 -6.293335e-01
6.293335e-01.
The new output ﬁelds tau.l and tau.u return the calibrated equivalence re-
gion [τ −
cali, τ +
cali]. We can also calibrate the length of the simulations m through
the KL option:
> mutost.calibrate(n.of.x=length(obs), s.of.x=sd(obs),
s.of.y=sd(sim), what='KL')
c.l
c.u
tau.u
KL
n.of.y
-0.155010790
0.155010790
0.375163551
0.002321863
164.
The new output ﬁelds n.of.y and KL return the calibrated number of sim-
ulations mcali and the KL divergence εcali between g and gABC. Figure 11.2b
compares the calibrated ABC approximation of the likelihood when considered
as a density in ρ (the gABC density) to the marginal posterior distribution
of ρ under a reference prior (the g density). The KL divergence is small,
εcali = 0.002. In practice, this is the R function call to be used in ABC.
The other functions illustrate the intermediate calibration steps.
Note that the two one-sided T-test depends on the standard deviation
of the simulated data, ˆσ. As ˆσ typically changes at every ABC step, the
ABC tolerances need to be re-calibrated at every ABC iteration. This is
usually not problematic in real-world applications, because 10,000 calls to
the mutost.calibrate routine take about 1.2 seconds on a standard laptop.
We simulate 3–4 times as many data points as in the observed data, calculate
ˆσ, calibrate h−
cali, h+
cali, mcali, and then use the ﬁrst mcali simulated data points
in step 9 of the ABC sampler shown at the beginning of this chapter.
11.4.2
Testing if dispersions are similar
Suppose again that the data or summaries are normally distributed with
unknown mean and variance, and that we now want to test for dispersion
equivalence. We write yi ∼N(μ, θ), xi ∼N(μ0, θ0). The setup of the test
is as follows. Let ρ = θ/ˆθ0, where ˆθ0 is the maximum likelihood estimate
1
n
n
i=1(x −¯x)2. The point of equality is now ρ∗= 1. The null hypothesis
is H0 : ρ /∈[τ −, τ +] versus H1 : ρ ∈[τ −, τ +], where τ −< ρ∗< τ +. The test
statistic is:
T(y1:m, x1:n) = S2(y1:m)
S2(x1:n) = θ
ˆθ0
1
n
m

i=1
yi −¯y
θ
2
,
(11.26)

304
Handbook of Approximate Bayesian Computation
and the ABC acceptance region is [h−
cali, h+
cali], where h−
cali and h+
cali need to
be found numerically. The power function of the corresponding size-α test is:
P(T ∈[h−
cali, h+
cali] | ρ) = Fχ2
m−1

nh+
cali/ρ

−Fχ2
m−1

nh−
cali/ρ

,
(11.27)
where Fχ2
m−1 is the cumulative density of a χ2 distribution with m−1 degrees
of freedom. Following (11.16–11.17), we ﬁnd:
g( ρ | x1:n ) ∝ρ−(n/2−1)−1 exp
 n
2 / ρ

,
(11.28)
so ρ is inverse gamma distributed with shape n/2−1 and scale n/2. In analogy
to the previous example, the power can be calculated with vartest.pow,
and the various calibration routines are available with vartest.calibrate.
It seems intuitive to use ABC acceptance regions of the form [1/h+, h+],
h+ > 1. It can be shown that such ABC acceptance regions correspond to
equivalence regions [1/τ +, τ +], τ + > 1 (Wellek, 2003). However, Figure 11.3a
(a)
(b)
0.0
0.5
1.0
1.5
2.0
1
2
ρ
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.5
1.0
1.5
2.0
2.5
ρ
τ+
2
3
4
6
8
FIGURE 11.3
Calibrated variance test. If the data or summaries are normally distributed
with unknown mean and variance, the one sample χ2-test can be used to
test for dispersion equivalence. (a) Power function of the χ2-test for α = 0.01
and increasing equivalence regions of the form [1/τ +, τ +]. Each line in the plot
shows the acceptance probability of the corresponding ABC accept/reject step
as a function of ρ for increasingly wider equivalence regions. Note that for the
choice τ −= 1/τ +, the power is not maximised at the point of equality ρ∗= 1
(black squares). (b) Calibrated gABC density (grey) for n = 60, ˆθ0 = 1.422,
τ −
cali = 0.57, τ +
cali = 1.75, mcali = 104 versus the g density (black).

Informed Choices: How to Calibrate ABC
305
reveals that for this choice, the maximum of the power function is not exactly
located at the point of equality (namely, ρ∗= 1). This means that such an
ABC accept/reject step will most often accept values of θ that do not coin-
cide with the maximum likelihood estimate of the observed data. An analytical
solution to τ −such that the power is maximised at ρ∗= 1 is not available,
but we can resort to numerical optimisation, again using Brent’s method.
Therefore, the calibration procedures for the vartest involve one additional
step, when compared to the calibration procedures for the mutost. This
additional numerical calibration step is hidden from the user:
> n.of.x <- 60
> s.of.x <- 1.42
> vartest.calibrate(n.of.x=n.of.x, s.of.x=s.of.x, what='KL')
c.l
c.u
tau.l
tau.u
n.of.y
KL
1.396134e+00 2.196636e+00 5.866913e-01 1.755158e+00 1.050000e+02 8.497451e-03.
Figure 11.3b compares the calibrated ABC approximation to the likelihood
when considered as a density in ρ (the gABC density) to the likelihood when
considered as a density in ρ (the g density). The KL divergence is small, 0.008,
indicating a very good approximation. The resulting ABC acceptance region
[h−
cali, h+
cali] ≈[1.396, 2.196] is far from intuitive, indicating that it would be
diﬃcult to achieve the same degree of accuracy through manual selection of
the tolerances.
In contrast to the mutost, the vartest calibration routine only depends
on the observed data through n and S2(x1:n). This is known before ABC is
started, so that the ABC tolerances have to be calibrated only once before
ABC is run, before step 3 in the sampler at the beginning of this chapter.
11.4.3
Testing if rates are similar
We now suppose that the data or summaries are exponentially distributed
with unknown rates, and that we want to test for rate equivalence. We write
yi ∼Exp(θ), xi ∼Exp(θ0), where θ is the scale parameter (reciprocal of the
rate parameter). The setup of the test is as follows. Let ρ = θ/ˆθ0, where ˆθ0
is the maximum likelihood estimate ¯x = 1/n n
i=1 xi. The point of equality
is ρ∗= 1. The null hypothesis is H0 : ρ /∈[τ −, τ +] versus H1 : ρ ∈[τ −, τ +],
where τ −< ρ∗< τ +. The test statistic is:
T(y1:m, x1:n) = ¯y / ¯x,
(11.29)
and the ABC acceptance region is [h−
cali, h+
cali], where h−
cali and h+
cali need to
be found numerically as well. The power function of the corresponding size-α
test is:
P( T ∈[h−
cali, h+
cali] | ρ ) = FΓm,1

m h+
cali / ρ

−FΓm,1

m h−
cali / ρ

,
(11.30)

306
Handbook of Approximate Bayesian Computation
where FΓm,1 is the cumulative density of a gamma distribution with shape m
and scale 1. Following (11.16–11.17), we ﬁnd:
g( ρ | x1:n ) ∝ρ−(n−1)−1 exp( −n/ρ ),
(11.31)
so ρ is inverse gamma distributed with shape n −1 and scale n. Compar-
ing (11.26) with (11.29), we see that the rate test is very similar to the dis-
persion test. The ABC calibrations can be performed through the function
ratetest.calibrate.
11.5
A Worked Example
In this section, we illustrate the application of ABC calibrations in a real-
world example. We consider weekly counts of inﬂuenza-like-illness (ILI) in the
Netherlands between 1994 and 2009. Figure 11.4 shows weekly counts that
could previously be attributed to inﬂuenza A subtype H3N2 (in short, H3N2),
the most prevalent inﬂuenza subtype over the past 40 years. We investigated
1995
2000
2005
2010
0
100
200
300
400
Year
Counts per week 
per 100,000 individuals
Estimated inﬂuenza H3N2 cases, Netherlands
Mock data, simulated H3N2 cases under model
FIGURE 11.4
Empirical and simulated inﬂuenza-like-illness time series data from the
Netherlands. In the Netherlands, inﬂuenza-like-illness counts are obtained
through sentinel surveillance of general practices, and extrapolated to the na-
tional population. In grey, weekly counts that could be attributed to inﬂuenza
A subtype H3N2 are shown, as reproduced from (Ratmann et al., 2012).
To illustrate the application of ABC calibrations in a real-world example,
we considered mock data from a simple mathematical model and aim to re-
estimate the known model parameters. As a black line, weekly H3N2 incidence
counts that are part of the model output are shown. The simulated data have
overall similar magnitude, but show a much more pronounced biennial pattern.

Informed Choices: How to Calibrate ABC
307
several stochastic simulation models of the H3N2 dynamics previously
(Ratmann et al., 2012), and here we focus on the simplest of these. We created
mock data from this simple model and compare in this section a previously
developed standard ABC inference approach to the calibrated inference
approach in their ability to recover the known, true model parameters.
The model describes H3N2’s disease dynamics in a population stratiﬁed
into susceptible (S), infected, but not yet infectious (E), infectious (I1 and I2),
and immune (R) individuals across two large spatial areas. The stochastic
model is easily simulated from Markov transition probabilities derived from
the deterministic ordinary diﬀerential equations:
dS↓
dt = μ
↓(N
↓−S
↓) −λ
↓
t
S↓
N ↓(I
↓
1 + I
↓
2 + M
↓) + γR
↓
dE↓
dt
= λ
↓
t
S↓
N ↓(I
↓
1 + I
↓
2 + M
↓) −(μ
↓+ φ)E
↓
dI
↓
1
dt = φE
↓−(μ
↓+ 2ν)I
↓
1
dI
↓
2
dt = 2νI
↓
1 −(μ
↓+ 2ν)I
↓
2
dR↓
dt
= 2νI
↓
2 −(μ
↓+ γ)R
↓.
(11.32)
The sink population (indicated by
↓) represents the Netherlands, and the
source population (indicated by ⟳) represents a large viral reservoir in which
the virus persists and evolves. Only the rate equations corresponding to the
sink population are shown. The transition probabilities in the stochastic model
correspond to exponentially distributed event probabilities in a small interval
Δt, with mean equal to the inverse of the rates in Greek letters in (11.32)
(Gillespie, 2007). Two infectiousness compartments, I1 and I2, are used to
obtain gamma-distributed infectious periods for the sake of biological realism.
The transmission rate λ
↓
t = λ(1 + ϕ↓sin(2π(t −t↓))) is seasonally forced with
peaks in the winter months in the sink population, so that only the baseline
transmission rate λ is a free parameter. By contrast, the transmission rate
is constant and equal to λ in the source population. The average incubation
period 1/φ and average infectiousness period 1/ν are informed by sharp priors
from existing data, while the average duration of immunity 1/γ is the second
free parameter. After the summer months, new inﬂuenza seasons are re-seeded
from the viral reservoir by the expected number of infected travellers from
the source population, M ↓= m↓(I
⟳
1 + I
⟳
2 )/N ⟳, where m↓is the number of
travellers. The birth/death rate in the Netherlands μ↓and m↓are set to
estimates from the literature. To ﬁt (11.32) to the ILI time series, we used a
Poisson observation model of new weekly ILI cases with mean ωI
↓+
1 , where I
↓+
1
is the number of newly infected individuals in the sink population per week
and ω is the reporting rate. The third free parameter is ω. To ease intuition,
λ is re-parameterised as the basic re-productive number R0. Thus, the model

308
Handbook of Approximate Bayesian Computation
parameters of interest to us are θ = (R0, 1/γ, ω); i.e. p = 3. Pseudo data x
were generated for θ0 = (3.5, 10 years, 0.08), as shown in Figure 11.4.
To re-estimate θ0, we considered in the standard ABC and calibrated ABC
approach six summary statistics. H3N2 annual attack rates are the cumulative
incidence per winter season divided by population size. The magnitude, vari-
ation, and inter-seasonal correlation in H3N2 annual attack rates are charac-
teristic features of seasonal long-term H3N2 dynamics (Ratmann et al., 2012).
To capture these aspects of the data, we considered annual attack rates of the
reported ILI time series data (aILI), their ﬁrst-order diﬀerences (fdILI), and
estimates of annual population-level attack rates in H3N2 seasons (aINC).
On real data, estimates of aINC are obtained from seroprevalence surveys.
On the mock data considered here, aINC were calculated directly. Figure 11.5
shows that the aILI, fdILI, and aINC of the simulated data are biennial. For
this reason, we formed six summaries corresponding to odd and even values
of the aILI, fdILI, and aINC; i.e. q = 6. Figure 11.5 shows that, once the time
series were split, the sampling distribution of the odd and even values can be
modelled with a normal density.
In the standard ABC approach, we compared the means of these six time
series summaries. These summaries were combined with the intersection ap-
proach, in which an iteration is only accepted when the error between all
simulated and observed summaries is suﬃciently small. Speciﬁcally, let us de-
note the six observed and simulated summaries by sobs
i,1:ni = (sobs
i,1 , . . . , sobs
i,ni)
and ssim
i,1:ni = (ssim
i,1 , . . . , ssim
i,ni), where the index runs over even years for three
summaries and odd years for the other three summaries. We then used the
ABC accept/reject step:
1

q
i=1

h−
i ≤

¯ssim
i
−¯sobs
i

≤h+
i


,
(11.33)
where h−
i , h+
i are the user-deﬁned tolerances, and the sample means of the sim-
ulated and observed summaries, ¯ssim
i
=
1
ni
ni
j=1 ssim
i,j and ¯sobs
i
=
1
ni
ni
j=1 sobs
i,j ,
are compared to each other.
We used broad prior densities R0 ∼U(1, 8), 1/γ ∼U(2, 30), ω ∼U(0, 1)
and implemented an ABC Markov chain Monte Carlo sampler with normal
proposal kernel and annealing on the variance of the proposal kernel and the
tolerances (Gilks et al., 1996). The ABC tolerances were set such that our
ABC MCMC sampler produced an acceptance probability of 5%. In ABC,
acceptance probabilities are usually far lower than the recommended range
(Gilks et al., 1996). On the mock datasets, the estimated 95% credibility
intervals contained θ0. However, the mean squared error of the posterior mean
to θ0 was large (Figure 11.6a).
In the calibrated approach, we used for each of the six summaries the two
one-sided T-test, as described in Section 11.4.1. To verify that this equiva-
lence T-test can be used, we ﬁrst considered the quantile-quantile plots shown
in Figure 11.5b, and then tested at every ABC iteration independence and

Informed Choices: How to Calibrate ABC
309
0
0.5
1.0
1.5
Season
Annual attack rate
(%)
94/95
99/00
04/05
09/10
−4
−3
−2
−1
0
1
2
3
Between this and following season
Log 1st-order diﬀerences
in ILI attack rate
94/95
99/00
04/05
0.0125
0.0129
aILI
10%
50%
90%
Normal
0.157
0.161
aINC
10%
50%
90%
Normal
1.75
1.90
fdILI
10%
50%
90%
Normal
(a)
(b)
FIGURE 11.5
Features of long-term H3N2 dynamics. The cumulative incidence of inﬂuenza H3N2 infections per winter season divided by
population size, the so-called annual attack rate, is a characteristic feature of long-term H3N2 disease dynamics. (a) The top
panel shows reported annual attack rates (aILI) by winter season for the estimated H3N2 cases in the Netherlands (grey)
and the mock data (white bars). The bottom panel shows the ﬁrst-order diﬀerences in reported annual attack rates (fdILI)
as a measure of their inter-seasonal variability. These features show strong biennial patterns in the mock data and weakly
biennial patterns in the real data. To obtain summary statistics with a unimodal sampling distribution, we considered odd
and even seasons separately. (b) Quantile-quantile plots illustrate departures from normality for the three odd summary
statistics calculated on the mock data. Bottom and top curves indicate lower 2.5% and upper 97.5% conﬁdence intervals.
Normality cannot be rejected for any of the odd and even summary statistics.

310
Handbook of Approximate Bayesian Computation
1/ν
8.15
13.76
R0
3.01
4.37
ω
1/ν
R0
ω
0.058
0.1328
9.79
10.07
3.47
3.54
0.0791
0.0808
(a)
(b)
FIGURE 11.6
Comparison of posterior densities obtained with standard ABC and calibrated
ABC. Mock data were generated under the spatial SIR-type model (11.32),
and then a previously published ABC-MCMC algorithm with user-deﬁned
tolerances was used to re-estimate the true model parameters, shown in dashed
vertical lines. We then ran a similar ABC-MCMC algorithm with calibrations
as described in this chapter. (a) Marginal ABC posterior densities with user-
deﬁned tolerances are shown for each of the three model parameters (columns)
on 50 replicate mock data sets that were generated from the same model
parameter. 95% credibility intervals (grey) and their endpoints (numbers)
are highlighted. (b) For comparison, marginal ABC posterior densities using
calibrated mutost test statistics. The calibrations led to substantially more
accurate parameter estimates, see further the main text.
normality of the summary vectors ssim
i,1:m, i = 1, . . . , 6 in a pilot run. The p-
values of these tests were approximately uniformly distributed, indicating that
the two one-sided T-tests are suitable for this application.
From these six size-α hypothesis tests, it is easy to construct a multivari-
ate size-α hypothesis test (Ratmann et al., 2014). Let us denote, for the ith
simulated summaries, the population mean of the corresponding, unknown

Informed Choices: How to Calibrate ABC
311
normal sampling distribution by βi. For the ith observed summaries, the cor-
responding maximum likelihood estimate is the sample mean ¯sobs
i
, which is
straightforward to calculate. In analogy to the discrepancy parameter ρ de-
ﬁned in (11.11), the unknown, multivariate discrepancy parameter is now:
ρ = (ρ1, . . . , ρq) ∈Rq,
ρi = βi −¯sobs
i
,
(11.34)
and the univariate null and alternative hypotheses are:
H0i = { ρ ∈Rq | ρi /∈[τ −, τ +] },
H1i = { ρ ∈Rq | ρi ∈[τ −, τ +] }.
(11.35)
Now consider the multivariate intersection-union hypotheses:
H0 =
q
i=1
H0i,
H1 =
q
i=1
H1i.
(11.36)
The multivariate statistic T = (T1, . . . , Tq), which is the vector of the six two
one-sided T-tests, with ABC acceptance region [h−
1 , h+
1 ] × . . . × [h−
q , h+
q ] is
also level-α and, under further conditions, size-α (Berger, 1982). We suppose
further that the sampling distributions of the test statistics are orthogonal to
each other, so that:
p(sobs | ρ ) =
q

i=1
p(sobs
i,1:n | ρi ),
P

T ∈
	
h−
1 , h+
1

× . . . ×
	
h−
q , h+
q

 ρ

=
q

i=1
P

Ti ∈[h−
i , h+
i ]
ρi

.
(11.37)
This means that the multivariate ABC acceptance region is calibrated when all
univariate acceptance regions are calibrated independently. These calibrations
are easy to do: at every ABC iteration, we simulated a time series three times
as long as the mock data, calibrated h−
i,cali, h+
i,cali, τ −
i,cali, τ +
i,cali, mi,cali for
each summary with the mutost.calibrate function, and discarded the excess
simulations beyond mcali. It is important to discard excess simulations because
otherwise the power function is too tight when compared to the likelihood, as
illustrated in Figure 11.1b. The resulting calibrated ABC accept/reject step is:
1

q
i=1

h−
i,cali ≤

¯ssim
i,cali −¯sobs
i

≤h+
i,cali
 
,
(11.38)
where ¯ssim
i,cali is the sample mean over the mi,cali simulated summaries. Com-
paring (11.33) to (11.38), we see that the intersection accept/reject step can
be interpreted as the outcome of a multivariate equivalence hypothesis test,
with all associated beneﬁts. It also shows that the calibrations can be easily
integrated into more complex Markov chain Monte Carlo or sequential Monte
Carlo ABC algorithms.

312
Handbook of Approximate Bayesian Computation
The marginal ABC posterior densities obtained under the calibration ap-
proach are reported in Figure 11.6b, and are considerably tighter than those
obtained with the previously used standard ABC approach. The mean squared
error of the ABC posterior mean of θ0 over the 50 mock datasets was ap-
proximately 20-fold smaller than previously. The reason for this substantial
improvement in accuracy is that the calibrated tolerances were substantially
smaller than the user-deﬁned tolerances in the standard ABC approach. In ef-
fect, the calibration approach separates statistical considerations from compu-
tational considerations in the ABC approximation. Previously, the tolerances
were set to obtain a pre-speciﬁed acceptance probability. With the automat-
ically determined, substantially smaller tolerances h−
i,cali, h+
i,cali, we had no
choice but to tune the ABC-MCMC sampler further in order to obtain a
similar acceptance probability as before. Note that the power function was
calibrated so that the acceptance probability is high for proposed θ that are
close to the unknown maximum likelihood estimate; but of course, we still
have to propose such θ in the ﬁrst place. We settled on an adaptive block
proposal kernel to obtain an acceptance probability of 5%. With this extra
eﬀort into improved mixing of the MCMC sampler, the calibrated ABC pos-
terior distribution was substantially more accurate than the standard ABC
approach that we used before.
It is important to note that the calibrations only improve the ABC ap-
proximation to the partial posterior density based on the summaries (11.2)
and not the posterior density based on the data (11.1). When the summaries
are not suﬃcient, it is common practice to include as many summaries as pos-
sible or to construct summaries that are optimal in some sense as discussed by
Prangle (2019) in this book. In our example, we opted for the ﬁrst approach.
We used six summaries to estimate three model parameters.
There is one particular recommendation for choosing summaries that
emerges from describing the ABC accept/reject step as the outcome of hy-
pothesis tests. The hypothesis tests describe a statistical decision problem on
the unknown value of discrepancy parameters ρ in (11.34). Of course, the value
of the discrepancies is related to the value of the model parameters θ, but it
is not known how. This function is commonly referred to as the ‘binding func-
tion’ in indirect inference approaches (See Drovandi [2019], Chapter 7, this
volume). The binding function:
b : Rp →Rq,
b(θ) = ρ,
p ≤q,
(11.39)
must be injective in order to extend (11.21) and (11.22) to the more general
case considered here. Intuitively, this property means that we have suﬃciently
many summaries to detect changes in model parameters θ through the dis-
crepancies ρ. Thus, the number of summaries (or hypothesis tests) should at
least equal the number of model parameters, for example, p ≤q. The binding
function typically only maps to a subset of Rq, and on that subset the bind-
ing function is bijective, if it is injective. This means that the inverse of the
binding function is well deﬁned, which we need for ABC inference.

Informed Choices: How to Calibrate ABC
313
It is not so simple to check if high-dimensional binding functions are in-
jective. We can check this condition where it is most important, around the
point of equality ρ⋆, through the relation:
b−1(ρ∗) =
q
i=1
b−1
i (ρ∗
i ),
(11.40)
on the inverse of the binding function. Indeed, the one-dimensional level-sets:
b−1
i (ρ∗
i ) =

θ ∈Rp | ith element of b(θ) equal to ρ∗
i

,
can be easily estimated with local polynomial regression techniques after ABC
has been run (Loader, 1999), and from this, we can calculate their intersection.
If the binding function is injective around ρ⋆, this intersection is just a
single point. Figure 11.7 shows the estimated level sets and their intersections
R0
R0
1/ν
1/ν
ω
ω
(a)
9.8
9.9
10
10.1
0.079
0.0795
0.08
9.8
9.9
10
10.1
0.079
0.0795
0.08
3.48
3.5
3.52
3.54
3.56
3.48
3.5
3.52
3.54
3.56
(b)
FIGURE 11.7
Checking if suﬃciently many summaries are used in ABC. The hypothesis
testing approach provides a particular opportunity for checking if suﬃciently
many summaries are used in ABC. Increasing the number of hypothesis tests,
that are used in ABC, changes the binding function from θ to the discrepancy
parameters ρ. This function must be injective, which can be checked around
ρ⋆through the relation (11.40). We reconstructed the level sets b−1
i (ρ∗
i ) for
the time series example, using local polynomial regression. (a) Level sets for
the odd aILI (black) and the odd fdILI (light grey). The estimated level sets
illustrate which θ map to very small errors ρi around ρ∗
i . Here, the level
sets are highly non-linear and nearly orthogonal to each other. According to
the relation (11.40), we calculate their intersection, which results in multi-
ple paths through θ-space. (b) Intersection of level sets from (a) and level
set for the odd aINC. According to the relation (11.40), we calculate again
their intersection, which results in a very small ball. This indicates that the
pre-image b−1(ρ∗) is indeed a single value and that, the binding function is
injective around ρ∗for the particular choice of summaries that we used.

314
Handbook of Approximate Bayesian Computation
for three of the six odd and even summaries that we used for ABC inference.
The remaining level sets did not change the intersection shown in Figure 11.7b
in dark black. The ﬁnal intersection maps to a small ball, which indicates that
the binding function is indeed injective around ρ∗. If this had not been the
case, we would have concluded that more summaries need to be included into
ABC inference.
11.6
Discussion and Further Reading
In this chapter, we discussed how one-sample equivalence hypothesis tests can
be used within ABC. Their main utility is to inform some of the choices that
ABC users need to make when they apply ABC in practice. Statistical decision
tests can specify how to compare the observed and simulated data, and further
calibrations can be used to specify the free parameters of the test. These
calibrations determine in particular how long to simulate and how to set the
ABC tolerances.
If the data are of a particularly simple form, the calibrated ABC poste-
rior density enjoys the properties (11.21–11.23). The calibrations can also be
extended to the more general case when the data are arbitrarily complex, pro-
vided that multiple summaries (such as the annual attack rates in the time
series example) can be constructed, and that their sampling distribution is
of a simple form. This is not always possible. Where it is, we showed that
the quality of the ABC approximation can be suﬃciently improved through
the calibrations. Particular consideration has to be given that appropriate hy-
pothesis tests are used (i.e. that the sampling distribution of the summaries
warrants the use of particular hypothesis tests) and that suﬃciently many
summaries are used (i.e. so that the underlying binding function is injective).
We also required that the test statistics are independent of each other.
For end-users, the abc.star package makes available the most commonly
used hypothesis tests and their ABC calibration routines. This makes it
straightforward to use the calibrations in practice, but some work is needed
to identify summaries to which the calibrations can be applied. Several other
tests could be implemented and made available for ABC calibrations (Wellek,
2003). For developers, the open source code and package documentation will
provide further details on how to extend the existing calibration functions.
More technical details are also found in Ratmann et al. (2014).
From a more theoretical perspective, the calibrations ﬁt well into the grow-
ing literature that links ABC to indirect inference (See Drovandi [2019] and
Mengersen [2019], Chapters 7 and 12, this volume). In its most basic form, in-
direct inference proceeds by deﬁning an auxiliary probability model for which
maximum-likelihood estimates can be obtained and then transports these es-
timates back to the parameter space of interest (Gouri´eroux et al., 1993). In
ABC, the sampling distribution of the summaries also deﬁnes an auxiliary

Informed Choices: How to Calibrate ABC
315
probability model, and the binding function relates the auxiliary parameters
to the parameters of interest. Many aspects of ABC indirect inference have re-
cently received substantial attention in the community (Drovandi et al., 2011,
2015; Gleim and Pigorsch, 2013; Cabras et al., 2014, 2015; Moores et al.,
2015), and the calibrations of the free ABC parameters can be embedded
into this framework. We only focussed on the requirement that the binding
function must be injective around ρ⋆. Other properties likely inﬂuence compu-
tational and statistical aspects of ABC and could be more fully characterised
along the lines proposed in maximum-likelihood indirect inference (Gallant
and Tauchen, 1996; Jiang and Turnbull, 2004; Heggland and Frigessi, 2004;
Fermanian and Salanie, 2004).
Further work should explore how our calibration assumptions could be re-
laxed. For example, multivariate equivalence hypothesis tests have been formu-
lated (Wellek, 2003) and could obviate the requirement that the test statistics
are independent of each other. Non-parametric tests also exist (Wellek, 1996;
Munk and Czado, 1998), potentially opening up the possibility of calibrating
ABC with summaries whose sampling distribution is not necessarily of the
simple form that we assumed here.
Perhaps the most fundamental conclusion from the ABC calibrations de-
scribed in this chapter is that understanding and modelling the distribution
of the summaries can provide essential insights into ABC inference. If their
distribution is understood, then appropriate statistical decision tests can be
used to improve the accuracy of ABC algorithms, and to improve our under-
standing of the approximations in ABC.
Acknowledgements
OR is supported by the Wellcome Trust (fellowship WR092311MF), AC
by the Medical Research Council (fellowship MR/J01432X/1), and CC by
the Engineering and Physical Sciences Research Council (EP/K026003/1).
We thank the Imperial High Performance Computing Centre, and especially
Simon Burbidge for his support.
References
Barnes, C. P., S. Filippi, M. P. Stumpf, and T. Thorne (2012). Considerate
approaches to constructing summary statistics for ABC model selection.
Statistics and Computing 22(6), 1181–1197.
Beaumont, M., W. Zhang, and D. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162, 2025–2035.

316
Handbook of Approximate Bayesian Computation
Berger, R. (1982). Multiparameter hypothesis testing and acceptance sam-
pling. Technometrics 24(4), 295–300.
Blum, M. G. (2010). Approximate Bayesian computation: A nonparamet-
ric perspective. Journal of the American Statistical Association 105(491),
1178–1187.
Bortot, P., S. Coles, and S. Sisson (2007). Inference for stereological extremes.
Journal of the American Statistical Association 102(9), 84–92.
Cabras, S., M. E. Castellanos, and E. Ruli (2014). A quasi likelihood approxi-
mation of posterior distributions for likelihood-intractable complex models.
METRON 72, 153–167.
Cabras, S., M. E. C. Nueda, and E. Ruli (2015). Approximate Bayesian com-
putation by modelling summary statistics in a quasi-likelihood framework.
Bayesian Analysis 10(2), 411–439.
Cornuet, J.-M., F. Santos, M. A. Beaumont, C. P. Robert, J.-M. Marin, D. J.
Balding, T. Guillemaud, and A. Estoup (2008). Inferring population history
with DIYABC: A user-friendly approach to approximate Bayesian compu-
tation. Bioinformatics 24(23), 2713–2719.
Csill´ery, K., M. G. Blum, O. E. Gaggiotti, and O. Fran¸cois (2010). Approxi-
mate Bayesian computation (ABC) in practice. Trends in Ecology & Evo-
lution 25(7), 410–418.
Dean, T. A., S. S. Singh, A. Jasra, and G. W. Peters (2014). Parameter estima-
tion for hidden Markov models with intractable likelihoods. Scandinavian
Journal of Statistics 41(4), 970–987.
Doksum, K. A. and A. Y. Lo (1990). Consistent and robust Bayes procedures
for location based on partial information. The Annals of Statistics 18(1),
443–453.
Drovandi, C. (2019). ABC and indirect inference. In S. A. Sisson, Y. Fan, and
M. A. Beumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Drovandi, C. C., A. N. Pettitt, and M. J. Faddy (2011). Approximate Bayesian
computation using indirect inference. Journal of the Royal Statistical Soci-
ety: Series C (Applied Statistics) 60(3), 317–337.
Drovandi, C. C., A. N. Pettitt, and A. Lee (2015). Bayesian indirect inference
using a parametric auxiliary model. Statistical Science, 30(1), 72–95.
Fagundes, N. J. R., N. Ray, M. Beaumont, S. Neuenschwander, F. M. Salzano,
S. L. Bonatto, and L. Excoﬃer (2007). Statistical evaluation of alternative
models of human evolution. Proceedings of the National Academy of Sci-
ences USA 104(45), 17614–17619.

Informed Choices: How to Calibrate ABC
317
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 74(3), 419–474.
Fermanian, J.-D. and B. Salanie (2004). A nonparametric simulated maximum
likelihood estimation method. Econometric Theory 20(4), 701–734.
Gallant, A. R. and G. Tauchen (1996). Which moments to match? Economet-
ric Theory 12(4), 657–681.
Gilks, W. R., S. Richardson, and D. J. Spiegelhalter (1996). Markov Chain
Monte Carlo in Practice. Chapman & Hall: Boca Raton, FL.
Gillespie, D. T. (2007). Stochastic simulation of chemical kinetics. Annual
Review of Physical Chemistry 58, 35–55.
Gleim, A. and C. Pigorsch (2013). Approximate Bayesian computation with
indirect summary statistics. Technical report, University of Bonn, Germany.
Gouri´eroux, C., A. Monfort, and E. Renault (1993). Indirect inference. Journal
of Applied Econometrics 8, S85–118.
Heggland, K. and A. Frigessi (2004). Estimating functions in indirect infer-
ence. Journal of the Royal Statistical Society: Series B (Statistical Method-
ology) 66, 447–462.
Jiang, W. and B. Turnbull (2004). The indirect method: Inference based on
intermediate statistics: A synthesis and examples. Statistical Science 19(2),
239–263.
Kirkwood, T. B. and W. Westlake (1981). Bioequivalence testing – a need to
rethink. Biometrics 37(3), 589–594.
Lehmann, E. and J. Romano (2005). Testing Statistical Hypotheses. Springer:
New York.
Loader, C. (1999). Local Regression and Likelihood. Springer: New York.
Luciani, F., S. A. Sisson, H. Jiang, A. R. Francis, and M. M. Tanaka (2009).
The epidemiological ﬁtness cost of drug resistance in Mycobacterium tu-
berculosis. Proceedings of the National Academy of Sciences USA 106(34),
14711–14715.
Mengersen, K. (2019). Synthetic and empirical likelihoods. In S. A. Sisson,
Y. Fan, and M. A. Beumont (Eds.), Handbook of Approximate Bayesian
Computation. Chapman & Hall/CRC Press, Boca Raton, FL.
Moores, M. T., K. Mengersen, and C. P. Robert (2015). Pre-processing for
approximate Bayesian computation in image analysis. Statistics and Com-
puting 25(1), 23–33.

318
Handbook of Approximate Bayesian Computation
Munk, A. and C. Czado (1998). Nonparametric validation of similar distri-
butions and assessment of goodness of ﬁt. Journal of the Royal Statistical
Society: Series B (Statistical Methodology) 60(1), 223–241.
Owen, D. (1965). A special case of a bivariate non-central t-distribution.
Biometrika 52(3/4), 437–446.
Prangle, D. (2019). ABC Summary Statistics. In S. A. Sisson, Y. Fan, and
M. A. Beumont (Eds.), Handbook of Approximate Bayesian Computation.
Chapman & Hall/CRC Press, Boca Raton, FL.
Press, W. H., S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery (2007).
Numerical Recipes: The Art of Scientiﬁc Computing (3rd ed.). Cambridge
University Press: New York.
Pritchard, J., M. Seielstad, A. Perez-Lezaun, and M. Feldman (1999). Pop-
ulation growth of human Y chromosomes: A study of Y chromosome mi-
crosatellites. Journal of Molecular Biology and Evolution 16, 1791–1798.
Ratmann, O., A. Camacho, A. Meijer, and G. Donker (2014). Statistical mod-
elling of summary values leads to accurate approximate Bayesian computa-
tions. arXiv.org, 1305.4283.
Ratmann, O., A. Camacho, H. Sen, and C. Colijn (2016). abc.star: Calibration
procedures for accurate ABC. https://github.com/olli0601/abc.star.
Ratmann, O., G. Donker, A. Meijer, C. Fraser, and K. Koelle (2012). Phylo-
dynamic inference and model assessment with approximate Bayesian com-
putation: Inﬂuenza as a case study. PLoS Computational Biology 8(12),
e1002835.
Ratmann, O., O. Jørgensen, T. Hinkley, M. P. Stumpf, S. Richardson, and
C. Wiuf (2007). Using likelihood-free inference to compare evolutionary
dynamics of the protein networks of H. pylori and P. falciparum. PLoS
Computational Biology 3(11), e230.
Schuirmann, D. (1981). On hypothesis testing to determine if the mean
of a normal distribution is contained in a known interval. Biometrics
37(617), 137.
Silk, D., S. Filippi, and M. P. Stumpf (2013). Optimizing threshold-schedules
for approximate Bayesian computation sequential Monte Carlo samplers:
Applications to molecular systems. Statistical Applications in Genetics and
Molecular Biology 12(5), 603–618.
Silk, D., P. D. Kirk, C. P. Barnes, T. Toni, A. Rose, S. Moon, M. J. Dall-
man, and M. P. Stumpf (2011). Designing attractive models via automated
identiﬁcation of chaotic and oscillatory dynamical regimes. Nature Commu-
nications 2, 489.

Informed Choices: How to Calibrate ABC
319
Wellek, S. (1996). A new approach to equivalence assessment in standard
comparative bioavailability trials by means of the Mann-Whitney statistic.
Biometrical Journal 38(6), 695–710.
Wellek, S. (2003). Testing Statistical Hypotheses of Equivalence. CRC Press:
Boca Raton, FL.
Wood, S. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466(7310), 1102–1104.


12
Approximating the Likelihood in ABC
Christopher C. Drovandi, Clara Grazian, Kerrie Mengersen,
and Christian Robert
CONTENTS
12.1
Introduction ......................................................
322
12.2
Synthetic Likelihood .............................................
322
12.2.1
Classical synthetic likelihood ............................
323
12.2.2
Bayesian synthetic likelihood ............................
325
12.2.3
Accelerating synthetic likelihood ........................
327
12.2.4
Example .................................................
328
12.3
Further Reading ..................................................
338
12.4
Bayesian Empirical Likelihood ...................................
338
12.4.1
Empirical likelihood .....................................
339
12.4.2
Features of empirical likelihood .........................
341
12.4.3
Estimation ...............................................
343
12.4.4
Empirical likelihood in practice .........................
345
12.4.5
The BCel algorithm .....................................
347
12.4.5.1
Example 1 ....................................
348
12.4.5.2
Example 2 ....................................
350
12.4.5.3
Example 3 ....................................
352
12.4.6
Extensions of the BCel algorithm .......................
352
Acknowledgements .......................................................
358
Appendix ................................................................
358
References
...............................................................
361
321

322
Handbook of Approximate Bayesian Computation
12.1
Introduction
Approximate Bayesian computation (ABC) is now a mature algorithm for
likelihood-free estimation. It has been successfully applied to a wide range of
real-world problems for which more standard analytic tools were unsuitable
due to the absence or complexity of the associated likelihood. It has also
paved the way for a range of algorithmic extensions that take advantage of
appealing ideas embedded in other approaches. Despite the usefulness of ABC,
the method does have a number of drawbacks. The approach is simulation
intensive, requires tuning of the tolerance threshold, discrepancy function and
weighting function, and suﬀers from a curse of dimensionality of the summary
statistic. The latter issue stems from the fact that ABC uses a non-parametric
estimate of the likelihood function of a summary statistic (Blum, 2010).
In this chapter, we review two alternative methods of approximating the
intractable likelihood function for the model of interest, both of which aim to
improve computational eﬃciency relative to ABC. The ﬁrst is the synthetic
likelihood [SL, originally developed by Wood (2010)], which uses a multivariate
normal approximation to the summary statistic likelihood. This auxiliary like-
lihood can be maximised directly or incorporated in a Bayesian framework,
which we refer to as BSL. The BSL approach requires substantially less tun-
ing than ABC. Further, BSL scales more eﬃciently with an increase in the
dimension of the summary statistic due to the parametric approximation of
the summary statistic likelihood. However, the BSL approach remains simu-
lation intensive. In chapter 20, Fasiolo et al. (2019) apply BSL to dynamic
ecological models and compare it with an alternative Bayesian method for
state space models. In this chapter, we provide a more thorough review of SL
both in the classical and Bayesian frameworks.
The second approach we consider uses an empirical likelihood (EL) within
a Bayesian framework [BCel, see Mengersen et al. (2013)]. This approach can
in some cases avoid the need for model simulation completely and inherits the
established theoretical and practical advantages of synthetic likelihood. This
improvement in computational eﬃciency is at the expense of speciﬁcation of
constraints and making equivalence statements about parameters under the
diﬀerent models. Of note is that the latter enables, for the ﬁrst time, model
comparison using Bayes factors even if the priors are improper. In summary, in
the Bayesian context, both of these approaches replace intractable likelihoods
with alternative likelihoods that are more manageable computationally.
12.2
Synthetic Likelihood
The ﬁrst approach to approximating the likelihood that is considered in this
chapter is the use of a synthetic likelihood (SL), which was ﬁrst introduced by
Wood (2010). The key idea behind the SL is the assumption that the summary

Approximating the Likelihood in ABC
323
statistic conditional on a parameter value has a multivariate normal distribu-
tion with mean vector μ(θ) and covariance matrix Σ(θ). That is, we assume
that:
p(s|θ) = N(s; μ(θ), Σ(θ)),
where N denotes the density of the multivariate normal distribution. Of
course, in general for models with intractable likelihoods, the distribution
of the summary statistic is unknown and thus μ(θ) and Σ(θ) are generally
unavailable. However, it is possible to estimate these quantities empirically
via simulation. Consider generating n independent and identically distributed
(iid) summary statistic values, s1:n = (s1, . . . , sn), from the model based on
a particular value of θ, s1:n iid
∼p(s|θ). Then the mean and covariance matrix
can be estimated via:
μ(θ) ≈μn(θ) = 1
n
n

i=1
si,
Σ(θ) ≈Σn(θ) =
1
n −1
n

i=1
(si −μn(θ))(si −μn(θ))⊤,
(12.1)
where the superscript ⊤denotes transpose. The likelihood of the observed
summary statistic, sobs, is estimated via pn(sobs|θ) = N(sobs; μn(θ), Σn(θ)).
We use the subscript n on pn(sobs|θ) to denote the fact that the approximate
likelihood will depend on the choice of n. The larger the value of n, the better
the mean and covariance parameters of the multivariate normal distribution
can be approximated. However, larger values of n need more computation to
estimate the likelihood. It is likely that a suitable value of n will be problem
dependent, in particular, it may depend on the actual distribution of the sum-
mary statistic and also the dimension of the summary statistic. The value of
n must be large enough so that the empirical covariance matrix is positive
deﬁnite.
Note that Wood (2010) described some extensions, such as using robust
covariance matrix estimation to handle some non-normality in the summary
statistics and robustifying the SL when the observed summary statistic falls
in the tails of the summary statistic distribution (i.e. when a poor parameter
value is proposed or when the model is mis-speciﬁed).
The SL may be incorporated into a classical or Bayesian framework, which
are both described in the following. Then, attempts in the literature to ac-
celerate the SL method are described. We ﬁnish the section with a real data
example in cell biology.
12.2.1
Classical synthetic likelihood
The approach adopted in Wood (2010) is to consider the following estimator:
ˆθn = arg max
θ
N(sobs; μn(θ), Σn(θ)),
(12.2)

324
Handbook of Approximate Bayesian Computation
which is the maximum SL estimator. We use the subscript n to denote that
the estimator will depend on the value of n, with higher accuracy likely to be
obtained for larger values of n. We note that also because the likelihood is
stochastic, a diﬀerent answer will be obtained for ﬁxed n if a diﬀerent random
seed is applied. Since the optimisation in (12.2) is stochastic, Wood (2010) ap-
plied a Markov chain Monte Carlo (MCMC) algorithm to explore the space of
θ and select the value of θ that produced the highest value of the SL. Some re-
cent applications of the SL method have appeared in Hartig et al. (2014), who
used the FORMIND model for explaining complicated biological processes
that occur in natural forests, and Brown et al. (2014), who considered mod-
els for the transmission dynamics of avian inﬂuenza viruses in diﬀerent bird
types.
The synthetic likelihood approach has a strong connection with indirect in-
ference, which is a classical method for obtaining point estimates of parameters
of models with intractable likelihoods. In the simulated quasi-maximum likeli-
hood (SQML) approach of Smith (1993), an auxiliary model with a tractable
likelihood function, pA(y|φ), where φ is the parameter of that model, is used.
Deﬁne the function φ(θ) as the relationship between the parameter of the
model of interest and the auxiliary model. This is often referred to as the
binding function in the indirect inference literature. The SQML method aims
to maximise the auxiliary likelihood rather than the intractable likelihood of
the model of interest:
ˆθ = max
θ
pA(yobs|φ(θ)).
Unfortunately, the binding function is typically unavailable. However, it can
be estimated by generating n iid datasets, y1, . . . , yn, from the model of in-
terest (the generative model) conditional on a value of θ. Deﬁne the auxiliary
parameter estimate based on the ith simulated dataset as:
φyi = arg max
φ
pA(yi|φ).
Then we have:
φ(θ) ≈φn(θ) = 1
n
n

i=1
φyi.
The binding function is deﬁned as φn(θ) →φ(θ) as n →∞. The SQML
estimator then becomes:
ˆθn = max
θ
pA(yobs|φn(θ)).
The synthetic likelihood falls within the SQML framework, but where yobs has
been reduced to sobs, and the density of the multivariate normal distribution
is used for pA.

Approximating the Likelihood in ABC
325
12.2.2
Bayesian synthetic likelihood
An intuitive approach to incorporating SL into a Bayesian framework involves
combining the prior π(θ) with the synthetic likelihood, which induces the
following approximate posterior:
πn(θ|sobs) ∝N(sobs; μn(θ), Σn(θ))π(θ),
where the subscript n denotes that the approximate posterior depends on the
choice of n. Drovandi et al. (2015) consider a general framework called para-
metric Bayesian indirect likelihood, where the likelihood of some auxiliary
model with parameter φ, pA(yobs|φ(θ)), is used to replace the intractable like-
lihood of the actual or generative model, p(yobs|θ). Since the binding function
is generally not available in closed form, it can be estimated by simulation
via drawing n iid datasets from the generative model and ﬁtting the auxiliary
model to this simulated data (as in the SQML method mentioned previously),
producing φn(θ). Drovandi et al. (2015) demonstrate that the resulting ap-
proximate posterior depends on n, since in general, pA(yobs|φn(θ)) is not an
unbiased estimate of pA(yobs|φ(θ)) even when φn(θ) is an unbiased estimate
of φ(θ). We note that when non-negative and unbiased likelihood estimates
are used within Monte Carlo methods, such as MCMC (Andrieu and Roberts,
2009) and sequential Monte Carlo (Chopin et al. (2013)) algorithms, the re-
sulting target distribution is the posterior based on the originally intended
likelihood function. Such approaches are referred to as pseudo-marginal or
exact-approximate methods in the literature (see Chapter 9, this volume for
a review of such methods). BSL ﬁts within the pBIL framework, but where
the auxiliary model is applied at a summary statistic level rather than the full
data level and that the auxiliary model is the multivariate normal distribu-
tion, so that the auxiliary parameter estimates have an analytic expression as
shown in (12.1). Despite the fact that we use unbiased estimators for μ(θ) and
Σ(θ) (under the normality assumption), it is clear that N(sobs; μn(θ), Σn(θ))
is not an unbiased estimate of N(sobs; μ(θ), Σ(θ)). Therefore, the BSL poste-
rior is inherently dependent on n. However, under the assumption that the
model is able to recover the observed statistic, Price et al. (2018) present ex-
tensive empirical evidence that the BSL posterior is remarkably insensitive
to n. Further, some empirical evidence demonstrates that BSL shows some
robustness to the lack of multivariate normality.
Price et al. (2018) developed a new BSL method that uses an exactly
unbiased estimator of the normal likelihood, which is developed by Ghurye
and Olkin (1969). Using the notation of Ghurye and Olkin (1969), let:
c(k, v) =
2−kv/2π−k(k−1)/4
k
i=1 Γ
 1
2(v −i + 1)
,
and for a square matrix A, write ψ(A) = |A| if A > 0 and ψ(A) = 0 otherwise,
where |A| is the determinant of A and A > 0 means that A is positive deﬁ-
nite. The result of Ghurye and Olkin (1969) shows that an exactly unbiased

326
Handbook of Approximate Bayesian Computation
estimator of N(sobs; μ(θ), Σ(θ)) is (in the case where the summary statistics
are normal and n > d + 3):
ˆpA(sobs|φ(θ)) = (2π)−d/2
c(d, n −2)
c(d, n −1)(1 −1/n)d/2 |Mn(θ)|−(n−d−2)/2
ψ

Mn(θ) −(sy −μn(θ))(sy −μn(θ))⊤/(1 −1/n)
(n−d−3)/2 ,
where Mn(θ) = (n −1)Σn(θ). It is interesting to note that this estimator is a
mixture of a discrete and a continuous random variable (a realisation of the
estimator can be identically 0 with positive probability). Thus, if this estimator
is used within a Monte Carlo method, the target distribution is proportional
to N(sobs; μ(θ), Σ(θ))π(θ) regardless of the value of n (under the multivariate
normality assumption). Price et al. (2018) referred to this method as uBSL,
where ‘u’ denotes unbiased.
To sample from the BSL posteriors, an MCMC algorithm can be used, for
example. We refer to this as MCMC BSL, which is shown in Algorithm 12.1.
Given the insensitivity of the BSL posteriors to the value of n, it is of interest
to maximise the computational eﬃciency of the MCMC method. For large n,
the SL is estimated with high precision, but the cost per iteration is high.
Conversely, for small n, the cost per iteration is low, but the SL is estimated
less precisely, which reduces the MCMC acceptance rate. Price et al. (2018)
found empirically that the value of n that leads to an estimated log SL (at a θ
Algorithm 12.1: MCMC BSL algorithm. The inputs required are
the summary statistic of the data, sobs, the prior distribution,
p(θ), the proposal distribution q, the number of iterations, T ,
and the initial value of the chain θ0. The output is an MCMC
sample (θ0, θ1, . . . , θT ) from the BSL posterior. Some samples
can be discarded as burn-in if required
1: Simulate s1:n
iid
∼p(·|θ0)
2: Compute φ0 = (μn(θ0), Σn(θ0))
3: for i = 1 to T do
4:
Draw θ∗∼q(·|θi−1)
5:
Simulate s∗
1:n
iid
∼p(·|θ∗)
6:
Compute φ∗= (μn(θ∗), Σn(θ∗))
7:
Compute r = min

1,
N (sobs;μn(θ∗),Σn(θ∗))π(θ∗)q(θi−1|θ∗)
N (sobs;μn(θi−1),Σn(θi−1))π(θi−1)q(θ∗|θi−1)

8:
if U(0, 1) < r then
9:
Set θi = θ∗and φi = φ∗
10:
else
11:
Set θi = θi−1 and φi = φi−1
12:
end if
13: end for

Approximating the Likelihood in ABC
327
with high BSL posterior support) with a standard deviation(SD) of roughly 2
produces eﬃcient results. However, Price et al. (2018) also found that there is
a wide variety of n values that lead to similar eﬃciency. When the unbiased
SL is used in place of the SL shown in Algorithm 12.1, the MCMC uBSL
algorithm is obtained. In the examples of Price et al. (2018), MCMC BSL
and MCMC uBSL have a similar eﬃciency. We also note that the MCMC
BSL posteriors appear to exhibit very slow convergence when starting at a
point with negligible posterior support. The reason for this is that the SL is
estimated with a large variance when the observed statistic sobs lies in the tail
of the actual SL. Thus, additional research is required on more sophisticated
methods for sampling from the BSL posteriors.
The BSL method has been applied in the literature. Fasiolo et al. (2019)
used BSL for posterior inference for state space models in ecology and epi-
demiology based on data reduction and compared it with particle Markov
chain Monte Carlo (Andrieu et al., 2010). Hartig et al. (2014) implemented
BSL for a forest simulation model.
BSL could be seen as a direct competitor with ABC, as they are both
simulation-based methods and diﬀer only in the way the intractable summary
statistic likelihood is approximated. Importantly, BSL does not require the
user to select a discrepancy function, as one is naturally induced via the multi-
variate normal approximation. The simulated summary statistics in BSL are
automatically scaled, whereas an appropriate weighting matrix to compare
summary statistics in ABC must be done manually. As noted in Blum (2010)
and Drovandi et al. (2015), ABC uses a non-parametric approximation of
the summary statistic likelihood based on similar procedures used in kernel
density estimation. From this point of view, the ABC approach may be more
accurate when the summary statistic sobs is low dimensional, however, the
accuracy/eﬃciency trade-oﬀis less clear when the summary statistic sobs is
high dimensional. Price et al. (2018) demonstrated on a toy example that
BSL becomes increasingly more computationally eﬃcient than ABC as the
dimension of the summary statistic grows beyond 2. Furthermore, Price et al.
(2018) demonstrated that BSL outperformed ABC in a cell biology application
with 145 summary statistics.
12.2.3
Accelerating synthetic likelihood
As with ABC, the SL method is very simulation intensive. There have been
several attempts in the literature to accelerate the SL method by reducing
the number of model simulations required. Meeds and Welling (2014) as-
sumed that the summary statistics are independent and during their MCMC
BSL algorithm ﬁt a Gaussian process (GP) to each summary statistic out-
put as a function of the model parameter θ. The GP is then used to predict
the model output at proposed values of θ, provided that the prediction is
accurate enough. If the GP prediction cannot be performed with suﬃcient

328
Handbook of Approximate Bayesian Computation
accuracy, more model simulations are taken at that proposed θ, and the GP
is re-ﬁt for each summary statistic. The independence assumption of the sum-
mary statistics is questionable and may overstate the information contained
in sobs.
In contrast, Wilkinson (2014) used a GP to model the SL as a function of
θ directly and used the GP to predict the SL at new values of θ. The GP is
ﬁt using a history matching approach (Craig et al., 1997). Once the ﬁnal GP
ﬁt is obtained, an MCMC algorithm is used with the GP prediction used in
place of the SL.
Moores et al. (2015) considered accelerating Bayesian inference for the
Potts model, which is a complex single parameter spatial model. Simulations
are performed across a pre-deﬁned grid with the mean and standard deviation
of the summary statistic (which turns out to be suﬃcient in the case of the
Potts model, as it belongs to the exponential family) estimated from these
simulations. Non-parametric regressions are then ﬁtted individually to the
mean and standard deviation estimates in order to produce an estimate of
the mappings μ(θ) and σ(θ) across the space of θ, where σ is the standard
deviation of the summary statistic. The regressions are then able to predict
the mean and standard deviation of the summary statistic at θ values not
contained in the grid. Further, the regression also smooths out the mappings,
which are estimated using a ﬁnite value of n. The estimated mapping is then
used in a sequential Monte Carlo Bayesian algorithm.
12.2.4
Example
Cell motility, cell proliferation, and cell-to-cell adhesion play an important role
in collective cell spreading, which is critical to many key biological processes,
including skin cancer growth and wound healing (e.g. Cai et al. (2007); Treloar
et al. (2013)). The main function of many medical treatments is to inﬂuence
the biology underpinning these processes (Decaestecker et al., 2007). In order
to measure the eﬃcacy of such treatments, it is important that estimates of
the parameters governing these cell spreading processes can be obtained along
with some characterisation of their uncertainty. Agent-based computational
models are frequently used to interpret these cell biology processes since they
can produce discrete image-based and movie-based information which is ide-
ally suited to collaborative investigations involving applied mathematicians
and experimental cell biologists. Unfortunately, the likelihood functions for
these models are computationally intractable, so standard statistical inferen-
tial methods for these models are not applicable.
To deal with the intractable likelihood, several papers have adopted an
ABC approach to estimate the parameters (Johnston et al., 2014, Vo et al.,
2015b). One diﬃculty with these cell biology applications is that the observed
data are typically available as sequences of images and therefore it is not
trivial to reduce the dimension of the summary statistic to a suitable level

Approximating the Likelihood in ABC
329
for ABC, while simultaneously retaining relevant information contained in
the images. For example, Johnston et al. (2014) considered data collected
every 5 minutes for 12 hours, but only analysed images at three time points.
Vo et al. (2015a) reduced images initially down to a 15-dimensional summary
statistic, but perform a further dimension reduction based on the approach of
Fearnhead and Prangle (2012) to ensure there is one summary statistic per
parameter.
Here, we will re-analyse the data considered in Treloar et al. (2013) and
Vo et al. (2015a). The data consist of images of spatially expanding human ma-
lignant melanoma cell populations. To initiate each experiment, either 20,000
or 30,000 cells are approximately evenly distributed within a circular barrier,
located at the centre of the well. Subsequently, the barriers are lifted and
population-scale images are recorded at either 24 hours or 48 hours, indepen-
dently. Furthermore, there are two types of experiments conducted. The ﬁrst
uses a treatment in order to inhibit cells giving birth (cell proliferation), while
the second does not use the treatment. Each combination of initial cell density,
experimental elapsed time, and treatment is repeated three times, for a total
of 24 images. The reader is referred to Treloar et al. (2013) for more details on
the experimental protocol. For simplicity, we consider here the three images
related to using 20,000 initial cells, 24 hours elapsed experimental time, and
no cell proliferation inhibitor.
In order to summarise an image, Vo et al. (2015a) considered six sub-
regions along a transect of each image. The position of the cells in these
regions is mapped to a square lattice. The number of cells in each sub-region
is counted, together with the number of isolated cells. A cell is identiﬁed as
isolated if all of its nearest neighbours (north, south, east, and west) are un-
occupied. For each region, these summary statistics are then averaged over
the three independent replicates. We refer to these 12 summary statistics as
{ci}6
i=1 and {pi}6
i=1, where ci and pi are the number of cells and the percent-
age of isolated cells (averaged over the three images) for region i, respectively.
Vo et al. (2015a) also estimated the radius of the entire cell colony using image
analysis. Thus, Vo et al. (2015a) included three additional summary statistics,
(r(1), r(2), and r(3)), which are the estimated and ordered radii for the three
images. For more details on how these summary statistics are obtained, the
reader is referred to Vo et al. (2015a). This creates a total of 15 summary
statistics, which is computationally challenging to deal with in ABC. As men-
tioned earlier, Vo et al. (2015a) found it beneﬁcial to apply the technique of
Fearnhead and Prangle (2012), which uses a regression to estimate the poste-
rior means of the model parameters from the initial summaries, which are then
used as summary statistics in a subsequent ABC analysis. Here, we attempt
to see whether or not BSL is able to accommodate the 15 summary statistics
and compare the results with the ABC approach of Vo et al. (2015a).
Treloar et al. (2013) and Vo et al. (2015a) considered a discretised time and
space (two-dimensional lattice) stochastic model to explain the cell spreading

330
Handbook of Approximate Bayesian Computation
process of melanoma cells. For more details on this model, the reader is re-
ferred to Treloar et al. (2013) and Vo et al. (2015a). The model contains three
parameters: Pm (probability that an isolated agent can move to a neighbouring
lattice site in one time step), Pp (probability that an agent will attempt to
proliferate and deposit a daughter at a neighbouring lattice site within a time
step), and q (the strength of cell-to-cell adhesion, that is, cells sticking to-
gether). These model parameters can then be related to biologically relevant
parameters such as cell diﬀusivity and the cell proliferation rate. Here, we will
report inferences in terms of the parameter θ = (Pm, Pp, q).
Here, we consider a simulated dataset with Pm = 0.1, Pp = 0.0012
and q = 0.2 [same simulated data as analysed in Vo et al. (2015a)] and the
real data. We ran BSL using Algorithm 12.1 with independent U(0, 1) prior
distributions on each parameter. We used a starting value and proposal dis-
tribution for the MCMC based on the results provided in Vo et al. (2015a), so
we do not apply any burn-in. We also applied the uBSL algorithm. The BSL
approaches were run with n = 32, 48, 80, and 112 (the independent simulations
were farmed out across 16 processors of a computer node). To compare the
eﬃciency of the diﬀerent choices of n, we considered the eﬀective sample size
(ESS) for each parameter divided by the total number of model simulations
performed multiplied by a large constant scalar to increase the magnitude of
the numbers (we refer to this as the ‘normalised ESS’).
Marginal posterior distributions for the parameters obtained from BSL and
uBSL for diﬀerent values of n are shown in Figures 12.1 and 12.2, respectively.
It is evident that the posteriors are largely insensitive to n, which is consistent
with the empirical results obtained in Price et al. (2018). The normalised ESS
values and MCMC acceptance rates for the BSL approaches are shown in
Table 12.1 for diﬀerent values of n. The eﬃciency of BSL and uBSL appears
to be similar. The optimal value of n out of the trialled values appears to be
32 or 48. However, even n = 80 is relatively eﬃcient. For n = 112, the increase
in acceptance rate is relatively small given the extra amount of computation
required per iteration.
We also applied the BSL approaches with similar settings to the real data.
The posterior results are presented in Figures 12.3 and 12.4. Again, we found
the results are relatively insensitive to n. Table 12.2 suggests that n = 48 or
n = 80 are the most eﬃcient choices for n out of those trialled. However, it is
again apparent that there are a wide variety of n values that lead to similar
eﬃciency.
The results, in comparison to those obtained in Vo et al. (2015a), are
shown in Figure 12.5 for the simulated data and Figure 12.6 for the real data.
From Figure 12.5, it can be seen that the BSL approaches produced results
similar to that of ABC for the simulated data. It appears that BSL is able to
accommodate the 15 summary statistics directly without further dimension
reduction. However, it is clear that the dimension reduction procedure of Vo
et al. (2015a) performs well. From Figure 12.6 (real data), it is evident that

Approximating the Likelihood in ABC
331
Pm
0
20
40
60
80
100
120
n = 32
n = 80
n = 112
Pp
0
5
10
15
0.08
0.09
0.1
0.11
0.12
0.1
0.15
0.2
0.25
0.3
1
1.1
1.2
1.3
1.4
q
× 10−3
0
2000
4000
6000
8000
10000
FIGURE 12.1
Posterior estimates for Pm, Pp, and q based on the simulated data for the
melanoma cell biology application using MCMC BSL for diﬀerent values of n.
ABC and the BSL approaches produce similar posterior distributions for Pp
and q. For Pm, there is a diﬀerence of roughly 0.01 between the posterior
means of the BSL and ABC approaches and an increase in precision for BSL.
This discrepancy for the real data not apparent in the simulated data requires
further investigation. One potential source of error for BSL is the multivariate
normal assumption. The estimated marginal distributions of the summary
statistics (using n = 200) when the parameter is θ = (0.1, 0.0015, 0.25) is
shown in Figure 12.7. All distributions seem quite stable, but there is an
indication of non-normality for some of the summary statistics. Given the
results in Figures 12.5 and 12.6, it appears that BSL is showing at least some
robustness to this lack of normality.

332
Handbook of Approximate Bayesian Computation
Pm
0
20
40
60
80
100
n = 32
n = 80
n = 112
Pp
0
5
10
15
0.08
0.09
0.1
0.11
0.12
0.1
0.15
0.2
0.25
0.3
q
× 10−3
0
2000
4000
6000
8000
10000
1
1.1
1.2
1.3
1.4
FIGURE 12.2
Posterior estimates for Pm, Pp, and q based on the simulated data for the
melanoma cell biology application using MCMC uBSL for diﬀerent values of n.
TABLE 12.1
Sensitivity of BSL/uBSL to n for the Simulated Data
of the Cell Biology Example with Regards to MCMC
Acceptance Rate, Normalised ESS for Each Parameter
Acceptance
n
Rate (%)
ESS Pm
ESS Pp
ESS q
32
17/17
96/114
86/113
115/126
48
27/32
95/103
93/92
110/115
80
35/37
82/76
74/67
106/89
112
38/40
61/65
61/58
68/70

Approximating the Likelihood in ABC
333
Pm
Pp
0
20
40
60
80
100
n = 32
n = 80
n = 112
0
5
10
15
0.08
0.09
0.1
0.11
0.12
0.15
0.2
0.25
0.3
0.35
0.4
q
× 10−3
1.3
1.4
1.5
1.6
1.7
0
2000
4000
6000
8000
10000
FIGURE 12.3
Posterior estimates for Pm, Pp, and q based on the real data for the melanoma
cell biology application using MCMC BSL for diﬀerent values of n.

334
Handbook of Approximate Bayesian Computation
Pm
0
20
40
60
80
n = 32
n = 80
n = 112
Pp
0
5
10
15
0.08
0.09
0.1
0.11
0.12
0.15
0.2
0.25
0.3
0.35
0.4
q
× 10−3
0
2000
4000
6000
8000
10000
1.3
1.4
1.5
1.6
1.7
FIGURE 12.4
Posterior estimates for Pm, Pp, and q based on the simulated data for the
melanoma cell biology application using MCMC uBSL for diﬀerent values of n.
TABLE 12.2
Sensitivity of BSL/uBSL to n for the Real Data of the Cell
Biology Example with Regards to MCMC Acceptance Rate,
Normalised ESS for Each Parameter
n
Acceptance Rate (%)
ESS Pm
ESS Pp
ESS q
32
8/9
46/51
38/45
41/43
48
17/18
76/71
56/63
70/54
80
27/28
66/64
66/60
68/58
112
32/33
58/60
51/54
54/43

Approximating the Likelihood in ABC
335
ABC
BSL
uBSL
Pm
0
20
40
60
100
120
80
Pp
0
5
10
15
0.08
0.09
0.1
0.11
0.12
0.1
0.05
0.15
0.2
0.25
0.3
0.35
q
× 10−3
0
2000
4000
6000
8000
1.3
1.2
1.1
1
1.4
1.5
FIGURE 12.5
Posterior estimates for Pm, Pp, and q for the melanoma cell biology application
using the ABC approach of Vo et al. (2015a) (solid), BSL (dash), and uBSL
(dot-dash) based on simulated data with Pm = 0.1, Pp = 0.0012, and q = 0.2.
The BSL results are based on n = 48.

336
Handbook of Approximate Bayesian Computation
Pm
0
20
40
60
80
100
120
ABC
BSL
uBSL
Pp
0
5
10
15
0.08 0.09
0.1
0.11 0.12 0.13 0.14 0.15
0.15
0.2
0.25
0.3
0.35
1.2
1.3
1.4
1.5
1.6
1.7
1.8
q
× 10−3
0
2000
4000
6000
8000
FIGURE 12.6
Posterior estimates for Pm, Pp, and q for the melanoma cell biology application
using the ABC approach of Vo et al. (2015a) (solid), BSL (dash), and uBSL
(dot-dash) based on real data. The BSL results are based on n = 48.

Approximating the Likelihood in ABC
337
0
20
40
60
80
100
120
(a)
r(1)
r(2)
r(2)
0
20
40
60
80
100
120
(b)
0
10
20
30
40
50
60
70
80
90
100
(c)
0
0.05
0.1
0.15
0.2
0.25
(d)
p1
p2
p3
p4
p5
p6
0
0.05
0.1
0.15
0.2
0.25
(e)
0
0.05
0.1
0.15
0.2
0.25
(f)
(g)
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
(h)
0
0.05
0.1
0.15
0.2
0.25
0.3
(i)
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
0.02
(j)
c1
c2
c3
c4
c5
c6
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
0.02
(k)
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
0.02
(l)
(m)
(n)
3.285
3.29
3.295
3.3
3.305
3.31
3.315
3.32
3.295
3.3
3.305
3.31
3.315
3.32
3.325
3.295
3.3
3.305
3.31
3.315
3.32
3.325
3.33
4
6
8
10
12
14
16
18
0
0.05
0.1
0.15
0.2
0.25
6
8
10
12
14
16
18
6
8
10
12
14
16
18
20
6
8
10
12
14
16
18
20
6
8
10
12
14
16
18
6
8
10
12
14
16
18
360
380
400
420
440
460
480
500
520
360
380
400
420
440
460
480
500
520
340
360
380
400
420
440
460
480
500
520
360
380
400
420
440
460
480
500
520
540
0
0.005
0.01
0.015
0.02
0.025
360
380
400
420
440
460
480
500
520
540
0
0.005
0.01
0.015
0.02
0.025
360
380
400
420
440
460
480
500
0
0.005
0.01
0.015
0.02
0.025
(o)
FIGURE 12.7
Estimated marginal distributions of the 15 summary statistics (Panels a-o,
with each summary statistic in the x-axis label) using n = 200 for the mela-
noma cell biology applications, when Pm = 0.1, Pp = 0.0015, and q=0.25.

338
Handbook of Approximate Bayesian Computation
12.3
Further Reading
Ong et al. (2018) developed a stochastic optimisation algorithm to obtain a
variational approximation of the BSL posterior. The authors utilise an un-
biased estimator of the log of the multivariate normal density due to Ripley
(1996, p. 56). Ong et al. (2018) demonstrated that signiﬁcant computational
savings can be achieved relative to MCMC BSL, at the expense of resorting
to a parametric approximation of the posterior. This work has been extended
by Ong et al. (2017) to higher dimensional summary statistic and parameter
spaces.
An et al. (2016) and Ong et al. (2017) considered shrinkage estimators of
the covariance matrix of the model summary statistic in order to reduce the
number of simulations required to estimate the synthetic likelihood. Pham
et al. (2014) replaced the ratio of intractable summary statistic likelihoods of
the Metropolis–Hastings ratio in an MCMC algorithm with the outcome of a
classiﬁcation algorithm. Datasets are simulated under the current parameter
and proposed parameter with the former observations labelled as class 1 and
the latter labelled as class 2. A classiﬁer, Pham et al. (2014) used random
forests, is then applied. From the ﬁtted classiﬁer, the odds for the value of
the observed summary statistic sobs is computed and used as a replacement
to the ratio of intractable likelihoods. Pham et al. (2014) noted that BSL is
a special case of this approach when classical quadratic discriminant analysis
is adopted as the classiﬁer.
Everitt et al. (2015) suggested that the SL can be used to perform Bayesian
model selection in doubly intractable models, which contain an intractable
normalising constant that is a function of θ. Such models can occur in complex
exponential family models, such as exponential random graph models for so-
cial networks and the Potts model for image analysis. Everitt et al. (2015)
developed computational algorithms in order to produce an SL approxima-
tion to the evidence p(sobs) =

θ p(sobs|θ)π(θ)dθ for each model.
12.4
Bayesian Empirical Likelihood
ABC is a popular computational method of choice not only when there is
no likelihood, but also when the likelihood is available, but diﬃcult or im-
possible to evaluate. Another popular idea is to replace the likelihood itself
with an empirical alternative. This so-called empirical likelihood (EL) can
be embedded within an ABC algorithm or provide an alternative to ABC.
The approach is appealing even for less complex models if there is a con-
cern that the model is poorly speciﬁed. For instance, if the likelihood is a
mixture, but is mis-speciﬁed as a single normal distribution, the correspond-
ing parameter estimates, intervals, and inferences may exhibit unacceptably
poor behaviour (Chen and Quin, 2003). In this case, normal approximation

Approximating the Likelihood in ABC
339
conﬁdence intervals perform poorly in the area of interest, for example, the
lower tail, but intervals based on an EL are shown to perform as well as
intervals based on a correctly speciﬁed mixture model.
EL has been shown to have good small sample performance compared with
methods that rely on asymptotic normality. Moreover, it enables distribution-
free tests without simulation and provides conﬁdence intervals and regions
that have appealing theoretical and computational properties (Owen, 1988,
2001). Some of these features are discussed in more detail in the following.
Close parallels with the EL approach have been drawn with estimating
equations (Qin and Lawless, 2001; Grendar and Judge, 2007), kernel smooth-
ing in regression (Chen and Van Keilegom 2009a, 2009b, Haardle, 1990; Fan
and Gijbels, 1996), maximum entropy (Rochet, 2012), and functional data
analysis (Lian, 2012). We do not elaborate on these associations in this
chapter, but refer the interested reader to the cited references.
EL approaches have been developed in both frequentist and Bayesian
contexts. This section provides a brief overview of the method under both
paradigms. We then focus on a particular algorithm, BCel, proposed by
Mengersen et al. (2013), which was ﬁrst conceived as part of an ABC
algorithm, but was then developed independently of the ABC architecture.
12.4.1
Empirical likelihood
EL has been a topic of active research and investigation for over a quarter of a
century. Although similar ideas were established earlier [see, e.g. the proposal
of a ‘scale-load’ method for survey sampling by Hartley and Rao (1968)], EL
was formally introduced by Owen (1988) as a form of robust likelihood ratio
test.
Following Owen (1988) and Owen (2001), assume that we have iid data
Yi, i = 1, ..., n from a distribution F. An EL denoted L(F) is given by:
L(F) =
n
	
i=1
F({yi}).
The likelihood ratio and corresponding conﬁdence region are given by,
respectively:
R(F) = L(F)/L( ˆF)
and
{T(F)|R(F) ≥r},
where ˆF is the empirical distribution function and for some appropriate
value of r.
Given parameters of interest θ and an appropriate suﬃcient statistic
T(F) for it, a proﬁle likelihood and corresponding conﬁdence region become,
respectively;
R(θ) = sup {R(F)|T(F) = θ}
and
{θ|R(F) ≥r}.

340
Handbook of Approximate Bayesian Computation
If there are no ties, we let pi = F({yi}), pi > 0, 
n
i=1 pi = 1 and ﬁnd that
L(F) =
n
	
i=1
pi ;
L( ˆF) =
n
	
i=1
1/n
R(F) =
n
	
i=1
npi ;
R(θ) = sup
 n
	
i=1
npi|T(F) = θ

.
Obvious adjustments are made to L(F) and L( ˆF) if there are ties.
A fundamental result obtained by Owen (1988) is that if the mean θ0 of
the distribution F is ﬁnite, and its covariance matrix is ﬁnite with rank q > 0,
then as n →∞:
−2 log R(θ0) →χ2
q.
This is the same as that obtained by Wilks’ theorem for the parametric setup.
Thus, for a 100(1 −α)% conﬁdence region, r = r0 = X2
q,α/2.
As a concrete example of EL, suppose that interest is in estimation of the
mean, for example, θ = E[Y ]. Then, T( ˆF) = n−1 
n
i=1 yi, with conﬁdence
region and proﬁle likelihood given by, respectively:
 n

i=1
piyi|pi ≥0,
n

i=1
pi = 1,
n
	
i=1
npi > r

and
R(θ) = sup
 n
	
i=1
npi|pi > 0,
n

i=1
pi = 1,
n

i=1
piyi = θ

.
Thus, under certain conditions, a (1 −α)-level EL conﬁdence interval for
θ0 = ¯Y is given by:
{θ|r(θ) ≤χ2
1(α)},
where r(θ) = −2 
 log(nˆpi) is the log EL function and χ2
1(α) is the upper α
quantile of the χ2 distribution with one degree of freedom.
The earlier set-up can also be seen as an estimating equation problem,
where the true value θ0 satisﬁes the estimating equation:
EF [m(Y ; θ)] = 0,
with m(Y ; θ) denoting a vector-valued (estimating) function. Hence, we can
take m(Y ; θ) = Y −θ to indicate a vector mean, m(Y ; θ) = IY ∈A −θ for
Pr(Y ∈A), m(Y ; θ) = IY <θ −α for the αth quantile of Y if Y is continuous,
m(Y ; θ) = IY ≤θ −0.5 for the median, and so on.
More
generally,
we
have
one
or
more
constraints
of
the
form
EF [h(Y, θ)] = 0, where the dimension of h sets the number of constraints in
unequivocally deﬁning the parameters of interest θ. Then the EL is deﬁned as:
Lel(θ|y) = max
p
n
	
i=1
pi,

Approximating the Likelihood in ABC
341
for p ∈[0, 1]n, with constraints:
n

i=1
pi = 1;
n

i=1
pih(yi, θ) = 0.
Perhaps surprisingly, there are relatively few Bayesian formulations of EL in
the published literature. An earlier Bayesian ABC approach using an approx-
imation of the EL based on the pairwise score equation was proposed by Pauli
and Adimara (2010). The authors focused on establishing the validity of the
procedure, arguing that its asymptotic properties were preferred over the ap-
proximations employed by Pauli et al. (2011). See also Ruli et al. (2016). Owen
(2001) (Chapter 9) noted some parallels between EL and the Bayesian boot-
strap (Rubin, 1981), and Rochet (2012) has suggested a Bayesian approach
to generalised empirical likelihood, and generalised method of moments, via
a form of maximum entropy. Chaudhuri and Ghosh (2011) describe Bayesian
EL approaches in a spatial modelling context, as discussed in more detail in
the following.
More direct research into Bayesian EL comprise a Monte Carlo study
(Lazar, 2003) and two probabilistic studies (Schennach, 2005; Grendar and
Judge, 2007). In contrast to the reported Bayesian bootstrap-type approaches
of Owen (2001), Schennach (2005), and Ragusa (2006), Grendar and Judge
(2007, 2009) proposed a Bayesian large deviations (law of large numbers)
probabilistic interpretation and justiﬁcation of EL. They showed that, in a
parametric estimating equations setting, the EL method is an asymptotic in-
stance of the Bayesian non-parametric maximum a posteriori approach.
12.4.2
Features of empirical likelihood
Since Owen’s paper in 1988, the properties of EL have been comprehensively
investigated and reviewed (Hall and La Scala, 1990; Owen, 2001).
EL methods have been favourably contrasted with common alternatives
for estimation of complex models. For example, a natural competitor is cali-
bration, which proceeds by choosing, by some method, parameter values that
match selected features of the observed data. This can be diﬃcult for richly
parametrised models with strong correlation structure. EL can be perceived
as a more statistically formal method of calibration in that it uses moments
for matching. Another common competitor, maximum likelihood, requires the
deﬁnition, estimation, and maximisation of a likelihood and can be both an-
alytically and computationally demanding for complex models. In contrast,
EL requires only summary (moment) statistics and can perform inference on
an approximate likelihood, but inherits the properties of standard likelihood
(Owen, 2001). These properties of standard likelihood are principally obtained
by appeal to Wilks’ theorem (Qin and Lawless, 2001).
As described earlier, likelihood ratio conﬁdence regions can be constructed
by EL that often do not require estimation of the variance (Chen and Van
Keilegom, 2009a, 2009b) and have the same order of magnitude error as their

342
Handbook of Approximate Bayesian Computation
parametric counterparts. This also applies for more general regression contexts
(Chen, 1993, 1994; Chen and Cui, 2006; Chen and Gao, 2007). The conﬁdence
regions constructed in this manner respect the boundaries of the support of
the target parameter and are more natural in shape and orientation of the data
since they contour a log-likelihood ratio. In particular, they are often superior
to conﬁdence regions based on asymptotic normality when the sample size is
small. The conﬁdence regions can be further improved by applying Bartlett’s
correction, (1a/n)χ2
q,α, where a involves higher order moments of Y (DiCiccio
et al., 1991).
A key assumption underlying standard EL is that the random variables
are independent with a common distribution. An analogue, the weighted EL,
or exponentially tilted distribution accommodates data that are independent,
but not necessarily identically distributed. This approach was introduced by
Schennach (2005) and has been taken up by a large number of authors (Owen,
2001; Kitamura, 2006; Glenn and Zhao, 2007). Chaudhuri and Ghosh (2011)
contrast the two approaches as follows. They frame the EL as:
l(θ) =
m
	
i=1
ˆwi(θ),
where
ˆw(θ) = arg max
w∈W0
m

i=1
f{wi(θ)},
for some speciﬁed function f. They then consider standard EL as a form of
constrained maximum of a non-parametric likelihood since for a given θ, l(θ)
equals the EL when f(wi) = log(wi) and the exponentially tilted likelihood
as a form of maximum entropy, such that f(wi) = −wi log(wi). As these
authors discussed, the exponentially tilted likelihood can also be seen as a
proﬁle likelihood for θ.
Moreover, Schennach (2005) shows that this re-formulation of the max-
imisation problem of the EL allows for a probabilistic interpretation which
justiﬁes its use in a Bayesian setting. More precisely, the posterior distribu-
tion for a parameter of interest θ may be seen as:
π(θ|y) = π(θ)

Ψ
L(θ, ψ|y)π(ψ|θ)dψ,
where ψ represents a (potentially inﬁnite-dimensional) nuisance parameter,
which absorbs all those aspects of the model not described by the parameter
of interest θ. The information contained in the nuisance parameter may be
discretised by a vector of parameter ξ = (ξ1, . . . , ξN) with N →∞. The nui-
sance parmater ξ may then be given a prior which shares the Dirichlet prior’s
property of providing posteriors which assign probability one to distributions
supported by the sample. Schennach (2005) shows then this reformulation

Approximating the Likelihood in ABC
343
has a computationally convenient representation, for which the posterior of
the parameter of interest θ may be obtained through:
π(θ|y) = π(θ)
n
	
i=1
p⋆
i ,
where p⋆= (p⋆
1, · · · , p⋆
n) are the weights obtained as solution of the maximi-
sation problem:
LBETEL(θ) = max
p⋆
n

i=1
p⋆
i log p⋆
i ,
under constraints p⋆∈[0, 1]n, 
n
i=1 p⋆
i
= 1, 
n
i=1 p⋆
i h(yi, θ) = 0, where
‘BETEL’ stands for ‘Bayesian exponentially tilted likelihood’. This method
may be called ‘Bayesian exponentially tilted EL’, because it uses the expo-
nential tilting proposed in Efron (1981) and has a Bayesian interpretation.
This version of the EL will be used in Section 12.4.5.2.
Glenn and Zhao (2007) examined the robustness properties of the esti-
mates arising from the tilted distribution. For example, whereas the root mean
squared error of the EL estimator for the mean increases as the non-iidness of
the sample increases, the root mean squared error of the weighted EL estima-
tor remains closer to its theoretical value. Other extensions to standard EL,
such as the continuous updating estimator, have also been proposed (Hansen
et al., 1996).
In a Bayesian framework, the standard and exponentially tilted likelihoods
have been shown to be appropriate for Bayesian inference for a range of set-
ups and under certain conditions on the prior, particularly for a prior with
suﬃciently large variance (Monahan and Boos, 1992; Lazar, 2003; Chaudhuri
and Ghosh, 2011).
Notwithstanding these attractions, there are some drawbacks in applying
EL. One substantive issue is the formulation of the estimating equations. The
number of equations is one issue: there should be at least as many as the
dimension of the parameter space, but any more than this (which may be
available and desirable from the perspective of model description) has been
argued to adversely aﬀect inference (Qin and Lawless, 2001). However, it is
suggested by Mengersen et al. (2013) that this concern may not apply in all
circumstances, in a Bayesian set-up; this is illustrated in the g-and-k example
given in the following.
12.4.3
Estimation
The most common approach to estimation of the EL is through the method
of Lagrange multipliers. In general terms, this method aims to maximise f(x)
subject to a (multivariate) constraint g(x) = 0. This is achieved by ﬁnding
x∗= x∗(λ) maximising f(x)-λ′g(x), such that g(x′) = 0. Then x∗solves the

344
Handbook of Approximate Bayesian Computation
constrained problem. Considering again the example of estimating θ = E[Y ],
the aim is to maximise:
logR(p1, .., pn) =
n

i=1
log(npi),
under the constraints:
n
n

i=1
pi(Yi −θ) = 0,
1 −
n

i=1
pi = 0.
We write:
G =
n

i=1
log(npi) −nλ
n

i=1
(Y i −μ) −γ(1 −
n

i=1
pi),
where λ and γ are the Lagrange multipliers. This can be solved to ﬁnd a
unique solution for λ = λ(θ).
There is a range of software for computing the EL, particularly targeted
towards speciﬁc applications. A helpful repository and description of available
code is on Art Owen’s website. A powerful library available in the R software
is the package ‘emplik’ (Zhou and Yang, 2014). The underlying computational
method is based on the Newton–Lagrange algorithm, whereby the Lagrangian
function described earlier is solved by an application of Newton’s method,
which iteratively uses a second order Taylor approximation of f(x) to ﬁnd an
optimal value x∗satisfying f ′(x∗) = 0.
For example, the package el.test in the emplik library conducts a sim-
ple EL ratio test that returns −2 log-likelihood ratio (-2LLR, which has an
approximate chi-squared distribution under the null hypothesis), the associ-
ated p-value, the ﬁnal value of the Lagrange multiplier (lambda), the gradient
at the maximum (grad), the hessian matrix (hess), weights on the observa-
tions (wts), and the number of iterations performed (nits).
The following code, provided in the emplik documentation, illustrates
two tests on a two-dimensional set of data: (i) H0 : μ1 = μ2 and (ii)
H0 : 2μ1 −μ2 = 0.
# generate data
x <- matrix(c(rnorm(50,mean=1), rnorm(50,mean=2)), ncol=2,nrow=50)
y <- 2*x[,1]-x[,2]
# test hypothesis (i)
el.test(x, mu=c(1,2))
# test hypothesis (ii)
el.test(y, mu=0)
In one realisation of this code, the results of the ﬁrst test were returned
after four iterations, with weights ranging between 0.75 and 1.51, and with
−2LL = 1.50 and a p-value of 0.47 under the assumption that −2LL is approx-
imately chi-square under H0. The second null hypothesis returned a p-value
of 0.22.

Approximating the Likelihood in ABC
345
Examples of the use of the emplik library for survival analysis are given
by Zhou (2015). Whereas el.test requires uncensored data, the packages
developed by Zhou and embedded in the emplik library enable estimation of
hazard functions, cumulative distribution functions, and conﬁdence bands for
various types of censored data under a range of survival models.
As an example, the package em.cen.EM can be used to test the hypothesis
H0 :

g(t)dF(t) = μ versus Ha :

g(t)dF(t) ̸= μ, where g(t) is a user
supplied function. For instance, H0 can be the test about the Kaplan–Meier
mean and g(t) = t. The myeloma code in the Appendix illustrates this by
testing H0 : F(10) = 0.2 in the myeloma dataset incorporated in the emplik
library. The code also ﬁnds the upper and lower conﬁdence limit of a Wilks
conﬁdence interval. The output of this analysis provides a value –2LL and a
corresponding p-value.
Bayesian EL methods are typically analysed by solving the EL using a
Lagrange or similar method, then generating observations from the posterior
distribution of the parameters of interest by an MCMC method. A more de-
tailed description of this approach is given in the context of spatial modelling
in the next section. An alternative approach, BCel, which employs the emplik
library to obtain the required likelihood values, is also detailed in a subsequent
section.
12.4.4
Empirical likelihood in practice
The EL approach has been shown to be applicable in a broad range of contexts
(Qin and Lawless, 2001). For example, following its formulation for estima-
tion in linear regression (Owen, 1991), it has been extended to non-linear,
generalised, parameric, non-parametric and semi-parametric models with and
without missing data and censoring, time series models, and varying-coeﬃcient
models; see the review of Chen and Van Keilegom (2009b) and the references
therein. The approach has also been proposed for testing; see again Chen
and Van Keilegom (2009b). Einmahl and McKeague (2003) have proposed
omnibus tests based on EL for a wide range of hypothesis tests, including
symmetry, exponentiality, independence, and change of direction. Tests for
stochastic ordering using EL have been proposed by El Barmi and McKeague
(2013) and El Barmi and McKeague (2015).
Chaudhuri and Ghosh (2011) have proposed an EL approach for small area
estimation and have suggested that the approach is also applicable to general
random and mixed-eﬀects models. As the authors argue, EL overcomes the
distributional assumptions of the more dominant parametric models as well
as the linearity assumptions of the non-parametric models that have been
proposed for this problem. In addition, EL avoids the need for resampling
methods like jacknife and bootstrap to obtain mean squared error estimation.
The authors’ methodology is developed using a multivariate-t prior for the
parameter vector θ and both the regular and exponentially tilted formulations
for the EL.

346
Handbook of Approximate Bayesian Computation
A Bayesian EL approach for constructing intervals for the analysis of sur-
vey data has been explored by Rao and Wu (2010). This work builds on the EL
approaches for complex survey analysis proposed by Chen and Sitter (1999)
and Wu and Rao (2006). Rao and Wu (2010) provide a clear exposition of EL
methods for sample surveys. The authors set up the problem as one in which
Nt denotes the number of units U = {1, 2, ..., Nt}, in a ﬁnite population of size
N = 
T
t=1 Nt, that have the value y∗
t , and nt denotes the number of units
in the sample having this value y∗
t , t = 1, ..., T. The sample data are then
reduced to a set of so-called scale-loads (n1, n2, ..., nT )′, nt ≥0, n = 
T
t=1 nt.
Assuming a negligible sampling fraction, the likelihood can be approximated
by using the multinomial distribution with a log likelihood given by:
l(p) =
T

t=1
ntlog(pt),
with pt = Nt/N, and the MLE of:
¯Y =
T

t=1
ptyn,
is the sample mean:
¯y =
T

t=1
ˆptyn∗,
ˆpt = nt/n.
The authors make the connection with the work of Chen and Sitter (1999) and
argue that this ‘scale-load’ approach is ‘in the same spirit’ as EL as described
by Owen (1988).
As described earlier, survival analysis is another area that lends itself nat-
urally to EL. The popular Kaplan–Meier curve is a non-parametric estimator
of the survival function S(t) = P(T ≥t), where T denotes the time to an
event. It is conceptually straightforward to see that S can be estimated as
a maximum EL estimator. This ﬁeld has been developed by a number of
authors: see, for instance, Wang and Jing (2001) for a general exposition of
the survival model, Murphy and van der Vaart (1997) for doubly censored
data, Qin and Jing (1994) for Cox modelling using EL, and McKeague and
Zhao (2002) for an EL approach to relative survival. The recent text by Zhou
(2015) provides an excellent overview of the ﬁeld, as well as new models and
computational algorithms, with associated R code to facilitate implementa-
tion. A simple illustration of an EL approach to survival analysis is provided
in the next section.
Recent years have also seen an increase in popularity of EL for spatial
modelling. Chaudhuri and Ghosh (2011) pioneered a Bayesian EL approach for
small area estimation. Their model can accommodate continuous and discrete
and area- and unit-level data, random and mixed eﬀects, and the original and
exponentially tilted empirical likelihoods.

Approximating the Likelihood in ABC
347
A similar approach has also been proposed recently by Porter et al. (2015a)
for this purpose. The so-called semi-parametric hierarchical EL (SHEL) model
can be applied to irregular lattices and irregularly spaced point-referenced
data and was shown to have improved mean squared prediction error com-
pared with standard parametric analyses in a simulation study, a large com-
munity survey, and a bird survey. In the SHEL model, EL is employed in
an empirical data model, which is combined with a parametric process model
that accounts for the spatial dependence through a rank-reduced intrinsic con-
ditional autoregressive prior and, ﬁnally, with a model at the highest level of
the hierarchy describing the parameter.
A companion paper by the same authors (Porter et al., 2015b) extends this
work to a multivariate context, with focus on the Fay–Herriot (FH) model,
which is a mainstay in small area estimation. The argument is made that this
approach encompasses spatial correlation (via the Fay–Herriot model), but
avoids the usual restrictive Gaussian distributional assumptions (via EL).
One of the ﬁelds in which EL has been prominent is economics and re-
lated ﬁelds. For example, Riscado (2012) promotes the use of EL as a natural
framework for estimation of dynamic stochastic general equilibrium models
for macroeconomic analysis, since these models represent complex economic
systems as a constrained optimisation problem and can be described as a set of
moment conditions. The authors favourably compare EL with calibration and
ML approaches, since the model parameters have complex correlation struc-
tures that hinder calibration and are typically characterised by non-linear
systems of diﬀerence equations that have no closed form and hence hinder
ML. The likelihood is thus often approximated and then estimated (and max-
imised) using methods such as the Kalman ﬁlter and sequential Monte Carlo.
The authors interpret the EL approach as mapping from the set of moment
conditions to the stochastic processes of the economic variables and then per-
forming estimation by inverting that mapping. As discussed earlier, the im-
portance and very often the diﬃculty of deﬁning a set of ‘good’ moment
conditions, or constraints, is highlighted in this setting.
12.4.5
The BCel algorithm
A Bayesian EL algorithm was proposed by Mengersen et al. (2013). It was orig-
inally designed in the spirit of ABC, in that it avoids computation of the like-
lihood, but during its development, the authors realised that simulation from
the likelihood could also be avoided and replaced with importance sampling.
Thus, the so-called BCel algorithm generates values θi, i = 1, . . . , M from the
prior distribution for θ and uses the values wi = Lel(θi|y) as (unnormalised)
weights in an importance sampling (IS) framework. The basic BCel sampler
is given in the following. Of course, this importance sampling algorithm will
not be eﬃcient if the posterior is very diﬀerent to the prior. Later, we de-
scribe a more sophisticated algorithm based on adaptive multiple importance
sampling [AMIS, Cornuet et al. (2012)].

348
Handbook of Approximate Bayesian Computation
Algorithm 12.2: BCel, Mengersen et al. (2013)
for i = 1 to M do
Generate θi from the prior distribution π(·)
Set the (unnormalised) weight ωi = Lel(θi|y)
end for
12.4.5.1
Example 1
As a concrete example, consider estimation of the population mean θ based
on a sample of observations yi, i = 1, ..., n. In this case, two main decisions
are required: the prior on θ and the constraints. The computation of the EL
Lel(θi|y) can be performed using the el.test package in the emplik library in
R, as described earlier in this chapter. In this case, the unnormalised weight ωi
is taken to be equal to the value of the empirical likelihood, which is calculated
from the value of −2LLR obtained from the el.test function.
Suppose that a sample of size 100 is drawn from an (unknown) distribution
N(10, 1), and the aim is to estimate the population mean θ. A N(−10, 30)
prior is imposed on θ, and a ﬁrst-moment constraint is chosen, for example,
that the sample mean should equal the population mean. For the analysis,
it is decided to run M = 5000 iterations, noting that in practice a smaller
value of M can be used, but care must be taken to check that the weight
has not concentrated too strongly on a small number of sampled values of θ.
A resampling step can be included to mitigate this, although at a cost of
introducing additional variance. In this case, the algorithm becomes:
Algorithm 12.3: BCel Algorithm for Example 1
for i = 1 to M do
Generate θi ∼N(−10, 30)
Obtain −2LL from el.test(y,mu=0)
Let ωi = exp(−0.5 × (−2LL))
end for
Resample θ with probability ω
Calculate summary statistics of the resampled values of θ
Example R code for this algorithm is given in the following.
data = rnorm(100,10,1)
M = 5000; theta.propose=w=rep(0,M)
for (i in 1:M){
theta.propose[i] = runif(1,-10,30)
el = el.test(data,mu=theta.propose[i])
w[i] = exp(-0.5*(el$’-2LLR’))
}

Approximating the Likelihood in ABC
349
theta=sample(theta.propose,M,prob=w,replace=TRUE)
mean(theta); sd(theta); quantile(theta,probs=c(0.1,0.9))
hist(theta, main="",xlab="theta").
As noted earlier, the resampling step could be replaced with a weighted
mean, standard deviation, and quantiles. One realisation of this code provided
the following estimates: ˆθ = 10.08; s.d.(θ) = 0.12; 95% CrI=(9.88, 10.21).
A histogram of the obtained sample of θ is given in Figure 12.8.
Mengersen et al. (2013) comment on the performance of this algorithm
with diﬀerent constraints, namely, one, two, and three central moments. They
observe that one and two constraints work well, but three constraints per-
formed more poorly. This was seen to support the general suggestion by Owen
(2001) that the number of constraints should be equal to the number of pa-
rameters. Interestingly, this was not seen to be the case for the g-and-k dis-
tributions, as described in the next example.
A possible measure of the eﬃciency of the algorithm is the eﬀective sam-
ple size (ESS). The is reportedly a measure of the ‘equivalent number of
independent observations’ in a sample, that is, the value that equates the
obtained variance of the estimator of interest with the equivalent variance
Theta
Frequency
9.6
9.8
10.0
10.2
0
200
400
600
800
1000
1200
FIGURE 12.8
Histogram of draws from the BCel posterior distribution of θ based on data
generated from a N(θ = 10, 1) distribution.

350
Handbook of Approximate Bayesian Computation
assuming an independent sample. For weighted samples as in EL, the ESS
can be estimated as:
ESS = 1/
M

i=1
{wi/
M

j=1
wj}2.
Kish (1965) argues that this substitution (of the EL for the exact likeli-
hood) can be employed in any algorithm that samples from a posterior distri-
bution. For example, it can be employed in composite likelihoods, which are
commonly used in areas such as population genetics, where the likelihoods are
known, but complex, and, hence, computationally diﬃcult. The ‘traditional’
composite likelihood approach decomposes the target distribution π(θ)L(θ|y)
into several multivariate Student t distributions. In the BCel approach, the
EL is used instead. The computation is achieved using AMIS, which can be
parallelised on a multi-core computer. The method can also be tailored for
some non-iid problems such as dynamic models with AR structure, although
the challenge here is in selecting appropriate constraints; see Mengersen et al.
(2013) for details.
12.4.5.2
Example 2
We illustrate the use of BCel by expanding on the discussion by Mengersen
et al. (2013) of quantile distributions. These distributions are appealing for
ABC in general, and BCel in particular: there is typically no closed form
expression for the likelihood, so regular algorithms such as MCMC are not
immediately applicable; and it is fast and easy to obtain simulations from a
quantile function via an inversion algorithm.
There is a body of literature on using ABC for estimation of quantile
distributions. Allingham et al. (2009) proposed an ABC-MCMC algorithm in
which draws of the parameters of the quantile distribution are based on a
Metropolis algorithm with a Gaussian proposal distribution and are accepted
based on the rule ||D −D′|| < h, where D is the entire set of order statistics,
|| · || is the Euclidean norm, and h is heuristically chosen after inspection of a
histogram of ||D−D′|| obtained from a preliminary run using a very large value
of h. Peters and Sisson (2006) also developed an ABC-MCMC algorithm for
complex quantile functions. A range of improvements in the MCMC algorithm,
selecting low-dimensional summary statistics, and methods of choosing h have
since been suggested (Prangle, 2011; McVinish, 2012). Sequential Monte Carlo
approaches for multivariate extensions of quantile distributions have also been
proposed (Drovandi and Pettitt, 2011).
The g-and-k distribution is a popular example of a quantile distribution.
This is a transformation of the standard normal distribution function, as
follows:
Q(z(p); θ) = a + b

1 + c1 −exp(−gz(p))
1 + exp(−gz(p))

(1 + z(p)2)kz(p),

Approximating the Likelihood in ABC
351
where θ = (a, b, g, k) and c is commonly set ﬁxed at 0.8; see Rayner and
MacGillivray (2002). Here, p denotes the pth quantile from the g-and-k dis-
tribution, and z(p) is the corresponding quantile of the standard normal dis-
tribution. Thus, simulation from the g-and-k distribution requires only the
generation of uniform(0, 1) variates.
Figure 12.9 shows the estimated cumulative distribution function (cdf) of
a standard normal distribution based on a g-and-k approximation, using the
basic BCel procedure described in Algorithm 12.2. The parameters of the g-
and-k distribution corresponding to a N(0, 1) distribution are θ = (0, 1, 0, 0).
The analysis was based on 1000 observations, 100,000 iterations, and 10,000 re-
sampled parameter values. The percentiles (0.1, 0.25, 0.5, 0.75, 0.9) were chosen
arbitrarily to form the constraints for EL, and all parameters were generated
from a U[0, 5] prior distribution.
The Bayes factor R code available in the Appendix illustrates the ease with
which Bayes Factors (BF) can be computed for g-and-k distributions using EL.
The example assumes a true model (Model 1) with (A, B, g, k) = (0, 1, 1, 0)
versus two alternatives, (0, 1, 0.5, 0) (Model 2) and (0, 1, 0, 0) (Model 3). Here,
all models have zero mean (A = 0) and unit variance (B = 1), but diﬀer
in the degree of skewness, with Model 3 having no skewness (g = 0) and,
hence, representing a standard normal distribution. The cumulative distribu-
tions functions for these three models are depicted in Figure 12.9. Two sample
sizes of 100 and 500 and ﬁve constraints (0.1, 0.25, 0.5, 0.75, 0.9) are consid-
ered. The resultant boxplots shown in Figure 12.10 conﬁrm that Model 1 is
y
Fn(y)
(A,B,g,k) = (0,1,1,0)
(A,B,g,k) = (0,1,0.5,0)
(A,B,g,k) = (0,1,0,0)
−3
−2
−1
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
FIGURE 12.9
Cumulative distribution functions for three g-and-k distributions.

352
Handbook of Approximate Bayesian Computation
1
2
1700
1720
1740
1760
1780
1800
log BF
1
2
8600
8620
8640
8660
8680
8700
log BF
FIGURE 12.10
Boxplots of Bayes factors comparing three g-and-k distributions; data were
generated from Model 1. On the x-axis: (1) Model 1 versus Model 2 with
sample size n = 100, (2) Model 1 versus Model 2 with sample size n = 500 on
the left and (1) Model 1 versus Model 3 with sample size n = 100, (2) Model 1
versus Model 3 with sample size n = 500 on the right.
preferred over both of the alternative models, with a stronger log BF obtained
for the larger sample size as anticipated.
12.4.5.3
Example 3
Mengersen et al. (2013) also describe a variation on the basic BCel algorithm,
which employs AMIS in order to improve computational eﬃciency over plain
importance sampling. The so-called BCel-AMIS sampler employs multivariate
Student t3(·|m, Σ) distributions (three degrees of freedom, mean m, covariance
matrix Σ) as importance sampling distributions, as described in the following
Algorithm 12.4. The output of this algorithm is a weighted sample θt,i of size
MTM.
12.4.6
Extensions of the BCel algorithm
Since its introduction, the BCel approach has been applied to a range of
problems. For example, Cheng et al. (2014) cite the approach as the founda-
tion for their proposed method for estimating the parameters of the extreme

Approximating the Likelihood in ABC
353
value model of Heﬀernan and Tawn (2004). Through a large simulation study,
the method was found to provide good coverage of credible intervals (CrI),
although one of the parameters needed more informative priors under some
more challenging setups.
In a second example, Grazian and Liseo (2017) discuss the use of BCel for
copula estimation, whereby the marginal likelihood of the quantity of interest
is approximated by the EL.
Copula models are an important tool in multivariate analysis: while a
huge literature exists about methods of estimating univariate marginal distri-
butions, the problem of estimating the dependence structure of a multivariate
distribution is more complex. Copula models allow for separately working with
the univariate marginals and the joint distribution. They are widely used
in many applications, including actuarial sciences (Embrechts et al., 2002),
epidemiology (Clayton, 1978), ﬁnance (Cherubini et al., 2004), hydrology
(Salvadori and De Michele, 2007), among others.
Algorithm 12.4: BCel-AMIS
for i = 1 to M do
Generate θ1,i from the prior distribution π(·).
Set the weight ω1,i = Lel(θ1,i|y).
end for
for t = 2 to TM do
Compute the weighted mean mt and weighted variance matrix Σt of
the θs,i(1 ≤s ≤t −1, 1 ≤i ≤M).
Denote by qt(·) the density of t3(·|mt, Σt).
for (i = 1 to M) do
Generate θt,i from qt(·).
Set ωt,i = π(θt,i)Lel(θt,i|y)/Σt−1
s=1qs(θt,i).
end for
for (r = 1 to t −1) do
for (i = 1 to M) do
Update the weight of θr,i as ωr,i = π(θr,i)Lel(θr,i|y)/Σt−1
s=1qs(θr,i).
end for
end for
end for.
A copula model is a way of representing the joint distribution of a random
vector X = (X1, . . . , Xd). Given a d-variate cumulative distribution function
F which depends on some parameter ψ, it is possible to show (Sklar, 2010)
that there always exists a d-variate function Cψ : [0, 1]d →[0, 1], such that:
F(x1, . . . , xd; λ1, . . . , λd, ψ) = Cψ(F1(x1; λ1), . . . , Fd(xd; λd)),
where Fj is the marginal distribution of Xj, indexed by a parameter λj, and
ψ is a parameter characterising the joint distribution.

354
Handbook of Approximate Bayesian Computation
In other terms, the copula C is a distribution function with uniform mar-
gins on [0, 1], which takes value from the univariate F1, F2, . . . , Fd (which may
be of the same form or may diﬀer in terms of the parameters or of the forms)
in order to produce the d-variate distribution F. The resulting model is very
ﬂexible, because it may utilise diﬀerent types of marginal distributions and
dependence structures.
Many diﬀerent types of copula functions have been proposed in the liter-
ature; see Joe (2015) for a review. An example is the Clayton copula, deﬁned
in the general d-dimension case as:
C(u) = (u−ψ
1
+ u−ψ
2
+ · · · + u−ψ
d
−d + 1)−1
ψ ,
where ψ ∈[−1, ∞) \ {0} is a one-dimensional parameter. The Clayton copula
is characterised by lower-tail dependence (that approaches 1 as ψ →∞) and
no upper-tail dependence. A representation of the Clayton copula (obtained
through simulation) is available in Figure 12.11.
The frequentist standard method of estimating copula models is the ‘infer-
ence from the margins’ (IFM) approach (Joe, 2015), for example a two-step
procedure, where ﬁrst the marginal distribution functions are separately esti-
mated, either in a parametric or in a non-parametric way (depending on the
information available on the marginals), and then the copula function is esti-
mated. Bayesian alternatives have been explored, nevertheless, they are still
limited. The reader may refer to Smith (2013) for a review.
0.0 0.2 0.4 0.6 0.8 1.0
0.0
(a)
(b)
(c)
0.2
0.4
0.6
0.8
1.0
Uniform data
u1
u2
−3 −2 −1
0 1
2
3
−3
−2
−1
0
1
2
3
Normal data
z1
z2
−1 0 1 2 3 4 5
−1
0
1
2
3
4
5
Data from quantile
distributions
Q(z1(p))
Q(z2(p))
FIGURE 12.11
Scatterplots of the ﬁrst two variables in the generation procedure: data from
a Clayton copula with ρ = 0.5, (a) transformed to normal data, (b) and then,
to data from a g-and-k distribution with a = 0, b = 1, g = 0.5, and k = 0 (c).

Approximating the Likelihood in ABC
355
In some cases, the interest of the analysis is in a function of interest θ of the
copula and not in the complete dependence structure; this may be due to weak
information about the type of structure or to the need of a low-dimensional
quantiﬁcation of the dependence. Some typical quantities of interest are, for
example, tail dependence indices, Spearman’s ρ, or Kendall’s τ. While tail de-
pendence indices represent, in the bivariate case, the probability that a random
variable exceeds a certain threshold given that another random variable has
already exceeded that threshold (Großmaß, 2007), Spearman’s ρ and Kendall’s
τ are measures of rank correlation, which are both expressible in terms of the
copula C. For example, the Spearman’s ρ in the bivariate case is deﬁned as:
ρ = 12

[0,1]2 C(u, v) du dv −3 = 12

[0,1]2 uv dC(u, v) −3.
(12.3)
In this case, Grazian and Liseo (2017), in the same spirit of the IFM method,
propose to ﬁrst estimate the marginal distributions and then study the interest
measure of multivariate dependence with an approximate Bayesian approach
based on an estimation of the likelihood of θ via EL (the authors use its
Bayesian modiﬁcation described in Schennach (2005) and in Section 12.4.2).
In this way, it is possible to avoid the complete deﬁnition of the dependence
structure (usually diﬃcult to be determined) and elicite the prior distribution
only for the quantity of interest, in order to reduce the bias derived from wrong
distributional assumptions. Moreover their Bayesian approach avoids the loss
of information of the IFM method and may be proved to be consistent.
The BCOP (‘Bayesian computation for copulas’) algorithm follows and
its ﬁnal output will then be a posterior sample drawn from an approximation
of the posterior distribution of the quantity of interest θ (see Algorithm 12.5).
This approach presents several advantages with respect to classical
approaches to copula estimation. First, it may be applied to a generic
dimension d, while in the literature there is a huge diﬀerence in terms of
consistency results on the proposed estimators between the bivariate and the
multivariate case. The authors have applied the BCOP algorithm to a max-
imum dimension equal to 50 with no loss of precision and with a reasonable
computational expense (it has to be noted that the algorithm may be eas-
ily parallelised in the ﬁrst step of estimation of the marginals). Second, the
method provides a quantiﬁcation of the error of estimation, not easily available
in the classical approach [see Schmid and Schmidt (2007) for the Spearman’s
ρ and Schmidt and Stadtm¨uller (2006) for the tail dependence indices]. Third,
it avoids the speciﬁcation of the particular copula function which describes the
dependence structure; this is particularly important in absence of information
on it, since methods to select the copula function are not yet fully developed.
Since the interest is in small dimension parameter (often only one measure
of dependence), the choice of the constraints should be easy; unfortunately, in
practical applications, these conditions might hold only asymptotically. This
is the case, for example, of the Spearman’s ρ: its sample counterpart ρn is only

356
Handbook of Approximate Bayesian Computation
Algorithm 12.5: BCOP algorithm, Grazian and Liseo (2017)
1 Given a n × d dataset x = {x1, . . . , xn}′ and marginal posterior samples
{λ(s)
1 , . . . , λ(s)
d } for s = 1, · · · , S
for s = 1, . . . , S do
Use the s-th row of the posterior simulation {λ(s)
1 , λ(s)
2 , . . . , λ(s)
d } to
create a matrix of uniformly distributed data u(s)
ij = Fj(xij; λ(s)
j )
u(s) =
⎛
⎜
⎜
⎜
⎜
⎜
⎝
u(s)
11
u(s)
12
. . .
u(s)
1d
u(s)
21
u(s)
22
. . .
u(s)
2d
. . .
. . .
u(s)
ij
. . .
u(s)
n1
u(s)
n2
. . .
u(s)
nd
⎞
⎟
⎟
⎟
⎟
⎟
⎠
.
end for
Given a prior distribution π(θ) for the quantity of interest φ,
for b = 1, . . . , B do
Draw θ(b) ∼π(θ)
for s = 1, . . . , S do
Compute LBEL(θ(b); u(s)) = ωbs
Take the average weight ωb = S−1 
S
s=1 ωbs
end for
end for
Output (θ(b), ωb), b = 1, . . . , B.
an asymptotically unbiased estimator of ρ, so the moment condition is strictly
valid only for large samples.
Grazian and Liseo (2017) also apply the method to a real dataset based
on the study of the dependence among ﬁve Italian ﬁnancial institutes, where
the returns are supposed to marginally follow a generalized autoregressive
conditional heteroskedasticity (GARCH)(1,1) model with Student’s t inno-
vations. They show how it is possible to obtain an approximated posterior
distribution of the Spearman’s ρ of the ﬁnancial asset returns of these insti-
tutes with Algorithm 12.5.
As an application, consider the setting of Section 12.4.5.2, where ﬁve sets of
observations are simulated from g-and-k identical, but not independent quan-
tile distributions with a = 0, b = 1, g = 0.5 and k = 0. The dependence
structure is described by a multivariate Clayton copula (McNeil and
Neˇslehov´a, 2009) with true unknown multivariate ρ equal to 0.5. There are
many ways to extend the bivariate Spearman’s ρ deﬁned in (12.3) to the mul-
tivariate case and they are not in general equivalent; nevertheless it is often of
interest in many ﬁelds of application to describe the dependence with a low-
dimensional quantity, for example, in the multivariate analysis of ﬁnancial

Approximating the Likelihood in ABC
357
asset returns, where there is the need to express the amount of dependence in
a portfolio by a single number. Here, the following is considered:
ρ =

[0,1]d (C(u) −Π(u)) du

[0,1]d (M(u) −Π(u)) du = h(d)

2d

[0,1]d C(u)du −1

,
(12.4)
where M(u) = min(u1, u2, . . . , ud) is the upper Fr´echet–Hoeﬀding bound, and
h(d) = (d+1)/{2d −(d+1)}. For a review of the deﬁnitions of the Spearman’s
ρ in the literature, one may refer to Schmid and Schmidt (2007).
Uniform data have been generated from a multivariate Clayton copula
with ρ = 0.5 and then inverted in order to obtain data from the corresponding
quantile distributions. Figure 12.11 shows the correlation between the ﬁrst two
sets of observations generated with this procedure.
Figure 12.12 described the approximation to the posterior distribution of
ρ, as deﬁned in (12.4), obtained via Algorithm 12.5: it is possible to see that
the posterior distribution is concentrated around the true value from which
the data have been generated.
The R code used is available in the Appendix (‘Copula code’).
As noted earlier, one of the key considerations in developing and imple-
menting BCel is the choice of constraints for the EL. This consideration is not
particular to BCel, but applies to all EL methods. However, the diﬀerence here
is that the selected constraints must be also applicable to the ABC context.
−1.0
−0.5
0.0
0.5
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Density
ρ
FIGURE 12.12
Approximation of the posterior distribution of the Spearman’s ρ as deﬁned in
(12.3) for the data described in Figure 12.11.

358
Handbook of Approximate Bayesian Computation
With this goal in mind, Ruli et al. (2016) advocate the use of scaled compos-
ite likelihood score functions as summary statistics in ABC. The scaling takes
into account a measure of the relative amount of information provided by
the diﬀerent parameters. They argue that the corresponding ABC procedure
is therefore invariant to re-parametrisation and accommodates automatically
the curvature of the posterior distribution. This approach is argued to be an
improvement over that proposed by Pauli et al. (2011) and more ‘fully ABC’
than the BCel approach.
Acknowledgements
Christopher Drovandi was supported by an Australian Research Council’s
Discovery Early Career Researcher Award funding scheme (DE160100741).
Kerrie Mengersen gratefully acknowledges support from the Australian Re-
search Council. Christopher Drovandi is an Associate Investigator and Kerrie
Mengersen is a Chief Investigator of the Australian Centre of Excellence for
Mathematical and Statistical Frontiers (ACEMS).
Appendix
Myeloma code
data(myeloma)
survtimes <- myeloma[,1]
# survival times
censtatus <- myeloma[,2]
# vital status (0=alive, 1=dead)
myfun1 <- function(t){ as.numeric(t <= 10) }
el.cen.EM(fun=myfun1, x=survtimes, d=censtatus, mu=0.2)
Bayes factor code
# test Model 1 (A,B,g,k)=(0,1,1,0) [skew]
# versus Model 2 (0,1,0.5,0) [less skew] and
# Model 3 (0,1,0,0) [standard normal]
# Compare B12=el_1/el_2 and B13=el1/el3
# Two sample sizes: n=100, 1000
library(emplik)
# set qc; traditionally set at 0.8
qc=0.8
# specify the models of interest; qp1 is the ’true’ model
qp1=c(0,1,1,0) ;
qp2=c(0,1,0.5,0) ; qp3=c(0,1,0,0)
# specify the quantiles for each model

Approximating the Likelihood in ABC
359
refp=c(0.1,0.25,0.5,0.75,0.9)
refq=qnorm(refp)
simq1=qp1[1]+qp1[2]*(1+qc*((1-exp(-qp1[3]*refq))/(1+exp(-qp1[3]*refq))))
*((1+refq^2)^qp1[4])*refq
simq2=qp2[1]+qp2[2]*(1+qc*((1-exp(-qp2[3]*refq))/(1+exp(-qp2[3]*refq))))
*((1+refq^2)^qp2[4])*refq
simq3=qp3[1]+qp3[2]*(1+qc*((1-exp(-qp3[3]*refq))/(1+exp(-qp3[3]*refq))))
*((1+refq^2)^qp3[4])*refq
# set sample size
nob=c(100, 500)
# no. observations
lennob=length(nob)
nrep=100
# replicates of BF12
# set up matrices and vectors
BF12=logBF12=BF13=logBF13=matrix(0,nrep,lennob)
th1=th2=th3=rep(0,nrep)
# compute BF using el.test based on true parameters for M1 vs M2, M3
for (nk in 1:lennob){
dth1=dth2=dth3=matrix(0,nrow=nob[nk],ncol=length(refp))
for (repk in 1:nrep){
# generate reference data
zp=qnorm(runif(nob[nk]))
dob=qp1[1]+qp1[2]*(1+qc*((1-exp(-qp1[3]*zp))/
(1+exp(-qp1[3]*zp))))*((1+zp^2)^qp1[4])*zp
for (k in 1:nob[nk]){
for (j in 1:length(refp)){
dth1[k,j] = (dob[k]<simq1[j])*1
dth2[k,j] = (dob[k]<simq2[j])*1
dth3[k,j] = (dob[k]<simq3[j])*1
}}
th1=el.test(dth1,mu=refp)
th2=el.test(dth2,mu=refp)
th3=el.test(dth3,mu=refp)
thll1=th1$’-2LLR’ ;
thll2=th2$’-2LLR’ ;
thll3=th3$’-2LLR’
logBF12[repk,nk] = -0.5*(thll1 - thll2)
logBF13[repk,nk] = -0.5*(thll1 - thll3)
BF12[repk,nk] = exp(logBF12[repk,nk])
BF13[repk,nk] = exp(logBF13[repk,nk])
}}
#end of repk, nk
par(mfrow=c(2,2))
boxplot(logBF123[,c(1,3)],ylim=c(1700,1800),
#xlab="1=M1 v M2,n=100; 2=M1 v M2,n=500; 3=M1 v M3, n=100; 4=M1 v M3,
n=500", ylab="log BF")
boxplot(logBF123[,c(2,4)], ylim=c(8600,8700),
#xlab="1=M1 v M2,n=100; 2=M1 v M2,n=500; 3=M1 v M3, n=100; 4=M1 v M3,
n=500", ylab="log BF")
Copula code
### Function to generate from a quantile function
quantile.fun=function(z,A,B,g,k,c=0.8)
{
val = A + B * ( 1 + c * (1-exp(-g*z)) / (1+exp(-g*z)) ) *
( 1+z^2 )^k * z

360
Handbook of Approximate Bayesian Computation
return(val)
}
### Simulations from the copula with a fixed Spearman’s rho
# Generation from the copula
library(copula)
cc=claytonCopula(d=5,param=1.076)
uu=rCopula(1000,cc)
# Generation from the normal
z=matrix(NA,nrow=1000,ncol=5)
for(i in 1:5)
{
z[,i]=qnorm(uu[,i])
}
# Generation from the quantile distribution
quant.sim=matrix(NA,nrow=1000,ncol=5)
for(i in 1:5)
{
quant.sim[,i]=quantile.fun(z[,i],A=0,B=1,g=0.5,k=0)
}
#### (Nonparametric) estimation of the marginals
n=1000
F.hat=matrix(NA,nrow=1000,ncol=5)
for(i in 1:5)
{
for(j in 1:1000)
{
F.hat[j,i]=sum(quant.sim[,i]<quant.sim[j,i])/n
}
}
#### BCOP for the Spearman’s rho
n=dim(F.hat)[1]
d=dim(F.hat)[2]
S=10^5
# Ranks
U.hat=matrix(NA,ncol=d,nrow=n)
for(i in 1:d)
{
U.hat[,i]=rank(F.hat[,i])/n
}
VV1=apply(1-U.hat,1,prod)
VV2=apply(U.hat,1,prod)
# Frequentist estimate
const=(d+1)/(2^d-(d+1))
estim1=const*(2^d/n*sum(VV1)-1)

Approximating the Likelihood in ABC
361
# BCOP
rho=runif(S, -1,1)
omega=rep(0,S)
for (s in 1:S)
{
est=estim1 - rho[s]
omega1[s]<-exp(-EL(est)$elr)
}
rho.sim=cbind(rho, omega)
plot(rho.sim[,1],rho.sim[,2],type="h",
xlab=expression(rho),ylab="Density",main="",col="grey")
par(mfrow=c(1,3))
plot(uu[,1],uu[,2],xlab=expression(u[1]),ylab=expression(u[2]),
main="Uniform data")
plot(z[,1],z[,2],xlab=expression(z[1]),ylab=expression(z[2]),
main="Normal data")
plot(quant.sim[,1],quant.sim[,2],xlab=expression(Q(z[1](p))),
ylab=expression(Q(z[2](p))),main="Data from quantile distributions")
References
Allingham, D., R. A. R. King, and K. L. Mengersen (2009). Bayesian estima-
tion of quantile distributionss. Statistics and Computing 19, 189–201.
An,
Z.,
L.
F.
South,
D.
J.
Nott,
and
C.
C.
Drovandi
(2016).
Accelerating Bayesian synthetic likelihood with the graphical lasso.
https://eprints.qut.edu.au/102263/.
Andrieu, C., A. Doucet, and R. Holenstein (2010). Particle Markov chain
Monte Carlo methods (with discussion). Journal of the Royal Statistical
Society: Series B (Statistical Methodology) 72(3), 269–342.
Andrieu, C. and G. O. Roberts (2009). The pseudo-marginal approach
for eﬃcient Monte Carlo computations. The Annals of Statistics 37(2),
697–725.
Blum, M. G. B. (2010). Approximate Bayesian computation: A non-
parametric perspective. Journal of the American Statistical Associa-
tion 105(491), 1178–1187.
Brown, V. L., J. M. Drake, H. D. Barton, D. E. Stallknecht, J. D. Brown,
and P. Rohani (2014). Neutrality, cross-immunity and subtype dominance
in avian inﬂuenza viruses. PLoS One 9(2), 1–10.

362
Handbook of Approximate Bayesian Computation
Cai, A. Q., K. A. Landman, and B. D. Hughes (2007). Multi-scale modeling of
a wound-healing cell migration assay. Journal of Theoretical Biology 245(3),
576–594.
Chaudhuri, S. and M. Ghosh (2011). Empirical likelihood for small area esti-
mation. Biometrika 98, 473–480.
Chen, J. and R. R. Sitter (1999). A pseudo empirical likelihood approach
to the eﬀective use of auxiliary information in complex surveys. Statistica
Sinica 9, 385–406.
Chen, S. (1993). On the accuracy of empirical likelihood conﬁdence regions
for linear regression model. Annals of the Institute for Statistical Mathe-
matics 45, 621–637.
Chen, S. (1994). Empirical likelihood conﬁdence intervals for linear regression
coeﬃcients. Journal of Multivariate Analysis 49, 24–40.
Chen, S. and H. Cui (2006). On Bartlett correction of empirical likelihood in
the presence of nuisance parameters. Biometrika 93, 215–220.
Chen, S. and J. Gao (2007). An adaptive empirical likelihood test for paramet-
ric time series regression models. Journal of Econometrics 141, 950–972.
Chen, S. and J. Quin (2003). Empirical likelihood-based conﬁdence intervals
for data with possible zero observations. Statistics & Probability Letters 65,
29–37.
Chen, S. and I. Van Keilegom (2009a). A goodness-of-ﬁt test for paramet-
ric and semi-parametric models in multiresponse regression. Bernoulli 15,
955–976.
Chen, S. and I. Van Keilegom (2009b). A review on empirical likelihood meth-
ods for regression. Test 18, 415–447.
Cheng, L., E. Gilleland, M. Heaton, and A. AghaKouchak (2014). Empirical
Bayes estimation for the conditional extreme value model. Stat 3, 391–406.
Cherubini, U., E. Luciano, and W. Vecchiato (2004). Copula Methods in
Finance. Hoboken, NJ: John Wiley & Sons.
Chopin, N., P. E. Jacob, and O. Papaspiliopoulos (2013). SMC2: An eﬃcient
algorithm for sequential analysis of state space models. Journal of the Royal
Statistical Society: Series B (Statistical Methodology) 75(3), 397–426.
Clayton, D. (1978). A model for association in bivariate life tables and its
application in epidemiological studies of familial tendency in chronic disease
incidence. Biometrika 65(1), 141–151.

Approximating the Likelihood in ABC
363
Cornuet, J., J.-M. MARIN, A. Mira, and C. P. Robert (2012). Adaptive
multiple importance sampling. Scandinavian Journal of Statistics 39(4),
798–812.
Craig, P. S., M. Goldstein, A. H. Seheult, and J. A. Smith (1997). Pressure
matching for hydrocarbon reservoirs: A case study in the use of Bayes lin-
ear strategies for large computer experiments. In Case studies in Bayesian
Statistics, pp. 37–93. New York: Springer-Verlag.
Decaestecker, C., O. Debeir, P. Van Ham, and R. Kiss (2007). Can anti-
migratory drugs be screened in vitro? A review of 2D and 3D assays for the
quantitative analysis of cell migration. Medicinal Research Reviews 27(2),
149–176.
DiCiccio, T., P. Hall, and J. Romano (1991). Empirical likelihood is Bartlett-
correctable. Annals of Statistics 19, 1053–1061.
Drovandi, C. C. and A. N. Pettitt (2011). Estimation of parameters for
macroparasite population evolution using approximate Bayesian computa-
tion. Biometrics 67(1), 225–233.
Drovandi, C. C., A. N. Pettitt, and A. Lee (2015). Bayesian indirect inference
using a parametric auxiliary model. Statistical Science 30(1), 72–95.
Efron, B. (1981). Nonparametric standard errors and conﬁdence intervals.
Canadian Journal of Statistics 9, 139–172.
Einmahl, J. and I. McKeague (2003). Empirical likelihood based hypothesis
testing. Bernoulli 9(2), 267–290.
El Barmi, H. and I. McKeague (2013). Empirical likelihood-based tests for
stochastic ordering. Bernoulli 19(1), 295–307.
El Barmi, H. and I. McKeague (2015). Testing for uniform stochastic ordering
via empirical likelihood. Annals of the Institute of Statistical Mathematics
68, 955–976.
Embrechts, P., A. Mcneil, and D. Straumann (2002). Correlation and de-
pendence properties in risk management: Properties and pitfalls. M. A. H.
Dempster (Ed.), Risk Management: Value at Risk and Beyond, pp. 176–223.
Cambridge, UK: Cambridge University Press.
Everitt, R. G., A. M. Johansen, R. E., and M. Evdemon-Hogan (2015).
Bayesian model comparison with intractable likelihoods. http://arxiv.org/
abs/1504.00298.
Fan, J. and I. Gijbels (1996). Local Polynomial Modelling and its Applications.
London, UK: Chapman & Hall.

364
Handbook of Approximate Bayesian Computation
Fasiolo, M., N. Pya, and S. Wood (2019). Statistical inference for highly non-
linear dynamical models in ecology and epidemiology. Statistical Science
31(1), 96–118.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for ap-
proximate Bayesian computation: Semi-automatic ABC (with discussion).
Journal of the Royal Statistical Society: Series B (Statistical Methodol-
ogy) 74(3), 419–474.
Ghurye, S. G. and I. Olkin (1969). Unbiased estimation of some multivariate
probability densities and related functions. The Annals of Mathematical
Statistics 40(4), 1261–1271.
Glenn, N. and Y. Zhao (2007). Weighted empirical likelihood estimates and
their robustness properties. Computational Statistics and Data Analysis 51,
5130–5141.
Grazian, C. and B. Liseo (2017). Approximate Bayesian computation for cop-
ula estimation. Statistica 75(1), 111–127.
Grendar, M. and G. Judge (2007). A Bayesian large deviations probabilistic
interpretation and justiﬁcation of empirical likelihood. Technical report, De-
partment of Agricultural and Resource Economics, University of California
Berkeley, CA.
Grendar, M. and G. Judge (2009). Asymptotic equivalence of empirical like-
lihood and Bayesian MAP. The Annals of Statistics 37, 2445–2457.
Großmaß, T. (2007). Copulae and tail dependence. PhD thesis, Humboldt
University of Berlin, Germany.
Haardle, W. (1990). Applied Nonparametric Regression. Cambridge, UK:
Cambridge University Press.
Hall, P. and B. La Scala (1990). Methodology and algorithms of empirical
likelihood. International Statistical Review 58, 109–127.
Hansen, L., J. Heaton, and A. Yaron (1996). Finite-sample properties of some
alternative GMM estimators. Journal of Business and Economic Statis-
tics 14, 262–280.
Hartig, F., C. Dislich, T. Wiegand, and A. Huth (2014). Technical note:
Approximate Bayesian parametrization of a process-based tropical forest
model. Biogeosciences 11, 1261–1272.
Hartley, H. and J. Rao (1968). A new estimation theory for sample surveys.
Biometrika 55, 547–557.

Approximating the Likelihood in ABC
365
Heﬀernan, J. E. and J. A. Tawn (2004). A conditional approach for multi-
variate extreme values (with discussion). Journal of the Royal Statistical
Society: Series B (Statistical Methodology) 66(3), 497–546.
Joe, H. (2015). Dependence Modeling with Copulas, Volume 134. Boca Raton,
FL: CRC Press.
Johnston, S. T., M. J. Simpson, D. L. S. McElwain, B. J. Binder, and J. V.
Ross (2014). Interpreting scratch assays using pair density dynamics and
approximate Bayesian computation. Open Biology 4(9), 140097.
Kish, L. (1965). Survey Sampling. New York: John Wiley & Sons.
Kitamura, Y. (2006). Empirical likelihood methods in econometrics: Theory
and practice. Technical report, Cowles Foundation for Research in Eco-
nomics, Yale University, New Haven, CT.
Lazar, N. (2003). Bayesian empirical likelihood. Biometrika 90, 319–326.
Lian, H. (2012). Empirical likelihood conﬁdence intervals for nonparametric
functional data analysis. Journal of Statistical Planning and Inference 142,
1669–1677.
McKeague, I. and Y. Zhao (2002). Simultaneous conﬁdence bands for ratios
of survival functions via empirical likelihood. Statistics and Probability Let-
ters 60, 405–415.
McNeil, A. J. and J. Neˇslehov´a (2009). Multivariate archimedean copulas,
d-monotone functions and l1-norm symmetric distributions. The Annals of
Statistics 37, 3059–3097.
McVinish, R. (2012). Improving ABC for quantile distributions. Statistics and
Computing 22(6), 1199–1207.
Meeds, E. and M. Welling (2014). GPS-ABC: Gaussian process surrogate ap-
proximate Bayesian computation. In N. L. Zhang and J. Tian (Eds.), Un-
certainty in Artiﬁcial Intelligence Proceedings of the Thirtieth Conference,
pp. 593–602. Arlington, VA: AUAI Press.
Mengersen, K., P. Pudlo, and C. Robert (2013). Approximate Bayesian com-
putation via empirical likelihood. Proceedings of the National Academy of
Science 110, 1321–1326.
Monahan, J. and D. Boos (1992). Proper likelihoods for Bayesian analysis.
Biometrika 79(2), 271–278.
Moores, M. T., C. C. Drovandi, K. L. Mengersen, and C. P. Robert (2015).
Pre-processing for approximate Bayesian computation in image analysis.
Statistics and Computing 25(1), 23–33.

366
Handbook of Approximate Bayesian Computation
Murphy, S. and W. van der Vaart (1997). Semiparametric likelihood ratio
inference. Annals of Statistics 25(4), 1471–1509.
Ong, V. M.-H., M.-N. Tran, S. A. Sisson, and C. C. Drovandi (2018). Vari-
ational Bayes with synthetic likelihood. Statistics and Computing 28(4),
971–988.
Ong, V. M. H., D. J. Nott, M.-N. Tran, S. A. Sisson, and C. C. Drovandi
(2017). Likelihood-free inference in high dimensions with synthetic likeli-
hood. https://eprints.qut.edu.au/112213/.
Owen, A. (1988). Empirical likelihood ratio conﬁdence intervals for a single
functional. Biometrika 75, 237–249.
Owen, A. (1991). Empirical likelihood for linear models. Annals of Statis-
tics 19, 1725–1747.
Owen, A. (2001). Empirical Likelihood. New York: Chapman & Hall/CRC
Press.
Pauli, F. and G. Adimara (2010). Bayesian inference with a pairwise likeli-
hood: An approach based on empirical likelihood. Proceedings of the 45th
Scientiﬁc Meeting of the Italian Statistical Society, 53, Padova, Italy.
Pauli, F., W. Racugno, and L. Ventura (2011). Bayesian composite marginal
likelihoods. Statistica Sinica 21, 149–164.
Peters, G. W. and S. A. Sisson (2006). Bayesian inference, Monte Carlo sam-
pling and operational risk. Journal of Operational Risk 1(3), 27–50.
Pham, K. C., D. J. Nott, and S. Chaudhuri (2014). A note on approximating
ABC-MCMC using ﬂexible classiﬁers. Stat 3(1), 218–227.
Porter, A., S. Holan, and C. Wikle (2015a). Bayesian semiparametric hierar-
chical empirical likelihood spatial models. Journal of Statistical Planning
and Inference 165, 78–90.
Porter, A., S. Holan, and C. Wikle (2015b). Multivariate spatial hierar-
chical Bayesian empirical likelihood methods for small area estimation.
STAT 4(1), 108–116.
Prangle, D. (2011). Summary statistics and sequential methods for approxi-
mate Bayesian computation. Technical report, Lancaster University, UK.
Price, L. F., C. C. Drovandi, A. Lee, and D. J. Nott (2018). Bayesian synthetic
likelihood. Journal of Computational and Graphical Statistics 27(1), 1–11.
Qin, J. and B. Jing (1994). Empirical likelihood for cox regression model under
random censorship. Annals of Statistics 22, 300–325.

Approximating the Likelihood in ABC
367
Qin, J. and J. Lawless (2001). Empirical likelihood and general estimating
equations. Communications in Statistics – Simulation and Computation 30,
79–90.
Rao, J. and C. Wu (2010). Bayesian pseudo-empirical-likelihood intervals for
complex surveys. Journal of the Royal Statistical Society, Series B 72,
533–544.
Ragusa, G. (2006). Bayesian likelihoods for moment condition models. Tech-
nical report, University of California, Irvine, CA.
Rayner, G. D. and H. L. MacGillivray (2002). Numerical maximum likelihood
estimation for the g-and-k and generalized g-and-h distributions. Statistics
and Computing 12(1), 57–75.
Ripley, B. D. (1996). Pattern Recognition and Neural Networks. Cambridge
UK: Cambridge University Press.
Riscado, S. (2012). DSGE Models in Macroeconomics: Estimation, Evaluation,
and New Developments (Advances in Econometrics, Volume 28), Chapter
On the Estimation of Dynamic Stochastic General Equilibrium Models: An
Empirical Likelihood Approach. Bingley, UK: Emerald Group Publishing.
Rochet, P. (2012). Bayesian interpretation of generalized empirical likelihood
by maximum entropy. Technical report.
Rubin, D. (1981). Bayesian bootstrap. Annals of Statistics 9, 130–134.
Ruli, E., N. Sartori, and L. Ventura (2016). Approximate Bayesian computa-
tion using composite score functions. Statistics and Computing To appear.
26(3), 679–692.
Salvadori, G. and C. De Michele (2007). On the use of copulas in hydrology:
Theory and practice. Journal of Hydrologic Engineering 12(4), 369–380.
Schennach, S. (2005). Bayesian exponentially tilted empirical likelihood.
Biometrika 92, 31–46.
Schmid, F. and R. Schmidt (2007). Multivariate extensions of Spearman’s rho
and related statistics. Statistics and Probability Letters 77(4), 407–416.
Schmidt, R. and U. Stadtm¨uller (2006). Non-parametric estimation of tail
dependence. Scandinavian Journal of Statistics 33(2), 307–335.
Sklar, M. (2010). Fonctions de r´epartition a n dimensions et leurs marges.
Publications de l’Institut de statistique de l’Universit´e de Paris 54(1–2):
3–6. With an introduction by Denis.
Smith, Jr., A. A. (1993). Estimating nonlinear time-series models using
simulated vector autoregressions. Journal of Applied Econometrics 8(S1),
S63–S84.

368
Handbook of Approximate Bayesian Computation
Smith, M. S. (2013). Bayesian approaches to copula modelling. In P. Damien,
P. Dellaportas, N. G. Polson, and D. A. Stephens (Eds.), Bayesian Theory
and Applications, pp. 336–358. Oxford, UK: Oxford University Press.
Treloar, K. K., M. J. Simpson, P. Haridas, K. J. Manton, D. I. Leavesley,
D. L. S. McElwain, and R. E. Baker (2013). Multiple types of data are
required to identify the mechanisms inﬂuencing the spatial expansion of
melanoma cell colonies. BMC Systems Biology 7(1), 137.
Vo, B. N., C. C. Drovandi, A. N. Pettitt, and G. J. Pettet (2015a). Melanoma
cell colony expansion parameters revealed by approximate Bayesian com-
putation. PLoS Computational Biology 11(12), e1004635.
Vo, B. N., C. C. Drovandi, A. N. Pettitt, and M. J. Simpson (2015b). Quanti-
fying uncertainty in parameter estimates for stochastic models of collective
cell spreading using approximate Bayesian computation. Mathematical Bio-
sciences 263, 133–142.
Wang, Q. and B. Jing (2001). Empirical likelihood for a class of function-
als of survival distribution with censored data. Annals of the Institute of
Statistical Mathematics 53, 517–527.
Wilkinson, R. (2014). Accelerating ABC methods using Gaussian processes.
Journal of Machine Learning Research 33, 1015–1023.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466, 1102–1107.
Wu, C. and J. N. K. Rao (2006). Pseudo-empirical likelihood ratio conﬁdence
intervals for complex surveys. Canadian Journal of Statistics 34, 359–375.
Zhou, M. (2015). Empirical Likelihood Method in Survival Analysis. London,
UK: Chapman & Hall/CRC Press.
Zhou, M. and Y. Yang (2014). emplik: Empirical likelihood ratio for cen-
sored/truncated data. R package version 0.9-9-6.

13
A Guide to General-Purpose ABC Software
Athanasios Kousathanas, Pablo Duchen, and Daniel Wegmann
CONTENTS
13.1
Introduction ......................................................
370
13.2
Toy Models .......................................................
371
13.2.1
Observed data and summary statistics .................
371
13.2.2
Generating simulations ..................................
372
13.3
Parameter Inference ..............................................
373
13.3.1
Rejection algorithm .....................................
374
13.3.2
Post-sampling adjustments ..............................
378
13.3.3
Multi-dimensional posteriors ............................
380
13.3.4
Validation of parameter estimation .....................
382
13.3.4.1
Using a wrong model .........................
382
13.3.4.2
Cross-validation/accuracy of
point estimates ...............................
384
13.3.4.3
Checking for biased posteriors ...............
386
13.4
Model Choice .....................................................
387
13.4.1
Inferring Bayes factors ..................................
388
13.4.2
Model choice validation .................................
390
13.4.3
Choosing summary statistics ............................
392
13.4.3.1
Statistics for parameter inference ............
392
13.4.3.2
Statistics for model choice ....................
394
13.5
Generating Simulations ..........................................
395
13.5.1
Generating simulations for rejection ....................
396
13.5.2
Performing Markov chain Monte Carlo .................
399
13.5.3
A population genetics example ..........................
402
Appendix ................................................................
407
References
...............................................................
409
369

370
Handbook of Approximate Bayesian Computation
13.1
Introduction
There are currently many programs available to conduct ABC analyses
(Table 13.1). However, most programs are speciﬁc to a particular problem,
and the large majority for questions that typically arise in a population-
genetics setting. These include programs to infer demographic histories (e.g.
ONeSAMP, PopABC, msABC, or DIYABC), to infer F-statistics (ABC4F), or
to infer parental contributions in an admixture event (2BAD). However,
there exists also programs for phylogeographic inference (msBayes), Systems
Biology (ABC-SysBio), or the inference under stochastic diﬀerential equations
(the MATLAB® package abc-sde).
A major beneﬁt of such speciﬁc programs is that a model parameterisation
suitable for simulation-based inference has already been worked out, and a
set of summary statistics informative for the problem identiﬁed. However, a
particularly powerful aspect of ABC is its application to almost any inference
problem and model, and we will thus focus here on general purpose ABC
software designed to be helpful in a large array of ABC applications, either to
conduct the whole analysis pipeline or at least speciﬁc parts of it.
Speciﬁcally, we will discuss two similar ABC pipelines, one provided
through the command line program ABCtoolbox (version 2.0, Wegmann et al.,
2010), and the other by means of combining the two R packages abc (version
2.0, Csill´ery et al., 2012) and EasyABC (version 1.4, Jabot et al., 2013). Both
pipelines oﬀer very similar features and build around a similar logic: (1) they
TABLE 13.1
General and Speciﬁc Purpose ABC Software
Software
Purpose
Reference
ABCtoolbox
General
Wegmann et al. (2010)
abc
General
Csill´ery et al. (2012)
ABC-EP
General
Barthelm´e and Chopin (2011)
ABC distrib
General
Beaumont et al. (2002)
ABCreg
General
Thornton (2009)
EasyABC
General
Jabot et al. (2013)
DIYABC
Population genetics
Cornuet et al. (2008)
msABC
Population genetics
Pavlidis et al. (2010)
ONeSAMP
Population genetics
Tallmon et al. (2008)
PopABC
Population genetics
Lopes et al. (2009)
2BAD
Population genetics
Bray et al. (2010)
ABC4F
Population genetics
Foll et al. (2008)
msBayes
Phylogeography
Hickerson et al. (2007)
ABC-SysBio
Systems Biology
Liepe et al. (2010)
abc-sde
Stochastic diﬀerential
equations
Picchini (2014)

A Guide to General-Purpose ABC Software
371
both provide utilities to generate a large set of simulations using external sim-
ulation software that employs a variety of sampling algorithms, (2) they both
oﬀer algorithms to infer parameters from such a set of simulations, (3) they
provide tools to conduct model choice from such sets of simulations performed
under diﬀerent models, and ﬁnally, (4) they both oﬀer a series of functions to
validate estimations as well as model choice. However, these pipelines diﬀer
in speciﬁc implementations of some algorithms, which we will outline in the
following, as well as the general way users interact with them. The packages
EasyABC and abc are used within the statistical software environment R and
are, hence, well suited for people writing their simulation programs in R or
for those familiar with the handling of datasets in this environment. In con-
trast, ABCtoolbox is written purely in C++ and run from the command line,
resulting in generally faster execution and making it particularly well suited
when command-line programs are used to conduct simulations or calculate
summary statistics.
In the remainder of this chapter, we will walk the reader through the
general usage of these two ABC pipelines. In order to give the reader a chance
to replicate our analysis easily, we will use rather simple models and always
give a detailed description of all settings used, along with all the code required
to replicate the described analyses. We will begin with parameter inference,
as we believe this is the step for which the programs discussed here will be
used most often. However, we will also discuss how to use these pipelines to
perform model choice, and how to conduct simulations using existing software.
13.2
Toy Models
We will introduce the usage of the program ABCtoolbox and the R packages
EasyAbc and abc through their application to the problem of inferring the
mean (μ) and variance (σ2) of a normal (model A) and a uniform (model B)
distribution from a random sample. We will then further show how to use
these ABC pipelines to distinguish between these models using model choice.
Using such simple models has two major beneﬁts. First, it will allow us to
compare the ABC estimates with those obtained from full-likelihood solutions.
Second, it is straightforward and quick to generate data under these models
using just a few lines of code, for instance, when using the free statistical pro-
gramming language R, which we will do here. However, note that we will also
discuss how to generate simulations with existing programs in Section 13.5.
13.2.1
Observed data and summary statistics
We will begin by generating a dataset of 100 random samples under model A
(the normal distribution) for which we would like to infer parameters. This is
readily done in R as follows:

372
Handbook of Approximate Bayesian Computation
TABLE 13.2
Observed Statistics of Test Data Set
Mean
Var
Median
Min
Max
Range
Q1
Q3
0.102
1.14
0.0788
−2.02
3.16
5.18
−0.598
0.799
sampleSize <- 100;
data.obs <- rnorm(sampleSize, mean=0, sd=1);
Note that for this test example, we do know the true parameters θ = (μ, σ2)
that we want to estimate. This will allow us to test the accuracy of the esti-
mation.
Next, we will deﬁne a function to calculate summary statistics both on the
observed, as well as simulated datasets. As summary statistics, we will use
here the sample mean, variance, and median, along with the smallest (min),
largest (max) value, the range (max–min), and the ﬁrst and third quartile (Q1
and Q3). A vector containing these summary statistics is readily generated in
R using the following function:
calc.stats <- function (x){
S <- c(mean(x), var(x), median(x), range(x), max(x)-min(x),
quantile(x, probs=c(0.25, 0.75)));
names(S) <- c("mean", "var", "median", "min", "max", "range", "Q1", "Q3")
return(S);
}
This will now allow us to calculate these summary statistics on the observed
data set (object data.obs), save them in the variable Sobs (object S.obs), and
to also save them in a ﬁle called normal.obs.:
S.obs <- calc.stats(data.obs);
write.table(t(S.obs), file="normal.obs", quote=F, row.names=F);
While each run will produce diﬀerent values, we provide the values we obtained
and will use in the following in Table 13.2 to allow for the replication of all
our results.
13.2.2
Generating simulations
We will next generate a large number (10,000) of simulations with parameter
values drawn from prior distributions and calculate the associated summary
statistics for each simulation. In order to allow for a direct comparison be-
tween the models, we will assume uniform prior distributions for the mean
μ ∼U[−1, 1] and variance σ2 ∼U[0.1, 4] for both models. We also set the
internal random number seed generator equal to one so that the reader can
reproduce exactly our results. Simulations for the normal model (model A)
are then generated as follows:

A Guide to General-Purpose ABC Software
373
set.seed(1)
nsim <- 10000;
P.normal <- data.frame(mu=runif(nsim, min=-1, max=1), sigma2=runif(nsim,
min=0.1 , max=4));
S.normal <- data.frame(matrix(data=0, ncol=length(S.obs), nrow=nsim));
names(S.normal) <- names(S.obs);
for ( i in 1:nsim ) {
y <- rnorm(sampleSize, mean = P.normal$mu[i], sd=sqrt(P.normal$sigma2[i])
);
S.normal[i,] <- calc.stats(y);
}
write.table(cbind(P.normal, S.normal), file="simNorm.txt", quote=F, row.
names=F);
Again, we saved the simulations also in a text ﬁle (simNorm.txt) in order to
use them with ABCtoolbox. Note that ABCtoolbox requires the parameters
and statistics in the same ﬁle, which is achieved by binding the data frames
containing the parameters (P.normal) and statistics (S.normal) together us-
ing cbind().
Generating simulations under the uniform model (model B) is achieved
similarly. However, since the R function runif() requires the two limits a, b
of the uniform distribution, rather than the mean and variance, we need to
calculate them from the parameters μ and σ2 after each draw as a = μ−
√
3σ2
and b = μ +
√
3σ2, respectively.
nsim <- 10000;
P.unif <- data.frame(mu=runif(nsim, min=-1, max=1), sigma2=runif(nsim, min
=0 , max=4));
S.unif <- data.frame(matrix(data=0, ncol=length(S.obs), nrow=nsim));
names(S.unif)<-names(S.obs);
for ( i in 1: nsim ) {
y <- runif(sampleSize, min=P.unif$mu[i]-sqrt(3*P.unif$sigma2[i]), max=P.
unif$mu[i]+sqrt(3*P.unif$sigma2[i]));
S.unif[i,] <- calc.stats(y);
}
write.table(cbind(P.unif, S.unif), file="simUnif.txt", quote=F, row.names=F
);
13.3
Parameter Inference
The estimation of posterior distributions is straightforward with both ABC-
toolbox and the R package abc. As a common feature, they both implement
the basic rejection algorithm originally introduced by Tavar´e et al. (1997) and
Pritchard et al. (1999), but they diﬀer in the post-sampling adjustment algo-
rithms they oﬀer. Speciﬁcally, the package abc implements the original post-
sampling adjustment based on a local linear regression initially introduced by
Beaumont et al. (2002), as well as an extension to non-linear models with
heteroscedastic variance (Blum and Fran¸cois, 2010). In contrast, ABCtoolbox

374
Handbook of Approximate Bayesian Computation
oﬀers an implementation of the general linear model adjustment algorithm
(ABC-GLM) introduced by Leuenberger and Wegmann (2010). In this sec-
tion, we will discuss diﬀerences between these algorithms, as well as how to
use them in the present example.
13.3.1
Rejection algorithm
abc
To start using abc, the package has ﬁrst to be installed and loaded in R, which
is done by the following two commands:
install.packages("abc");
library(abc);
To now conduct an ABC rejection on the data simulated under the nor-
mal model (model A), simply use the function abc() with the argument
method="rejection" and by specifying the tolerance to be applied.
rejection <- abc(S.obs,P.normal,S.normal,tol=0.01,method="rejection");
Here, S.obs, P.normal, and S.normal refer to the vector of observed sum-
mary statistics Sobs and the data frames containing the simulated parameters
and summary statistics, respectively, as generated under Section 13.2. The
additional argument tol speciﬁes the fraction of simulations to be retained
based on their distance to the observed summary statistics. A tolerance of
0.01, for example, indicates that the posterior density will be estimated from
the parameter values of the 1% of all simulations that produced summary
statistics closest to the observed summary statistics based on an euclidean
distance metric.
The package abc oﬀers an internal plotting function hist.abc() to display
posterior distributions. Since this function overloads the basic hist() function
of R, it can be called on an abc object by simply typing:
hist(rejection);
Alternatively, it is also possible to use general R functions such as hist()
or density() to plot posterior distributions. The results we obtained for the
observed data shown earlier is plotted using density in Figure 13.1.
ABCtoolbox
In contrast to the R packages discussed here, the program ABCtoolbox is a
program to be used from the command line, preferentially in a UNIX/Linux
environment. While it can be run from the Windows command prompt, it is
recommend to use the cygwin Unix-like interface on a Windows computer to
beneﬁt from all features of ABCtoolbox.
ABCtoolbox accepts input settings both directly from the command line,
as well as through an input ﬁle. A list of all arguments relevant for estimation

A Guide to General-Purpose ABC Software
375
0.5
0.0
True
GLM
Neu
Reg
Rej
True
GLM
Neu
Reg
Rej
0
0.0
0.5
1.0
1.5
2.0
3.0
2.5
(a)
(b)
1
2
Density
Density
3
4
μ
−0.5
−1.0
0.5
1.0
1.0
1.5
σ 2
2.0
2.5
3.0
0.5
1.0
1.5
2.0
3.0
2.5
0.0
(c)
μ
−0.5
−1.0
0.5
1.0
σ 2
0.8
0.8
0.6
0.7
0.3
0.2
0.9
FIGURE 13.1
Posterior densities for the mean (a) and variance (b) parameters of the nor-
mal distribution model produced by a variety of methods. Dashed grey lines
indicate prior densities. (c) Joint posterior density for μ and σ2 produced with
ABCtoolbox. Dashed black lines indicate true parameter values for all panels.
and discussed in this chapter is provided in Table 13.3. To perform parameter
estimation for the normal distribution example, for instance, the following
input ﬁle may be used:
task estimate
simName simNorm.txt
obsName normal.obs
params 1-2
maxReadSims 10000
numRetained 100
writeRetained
maxCor 1.0
Here, the argument task is set to estimate in order to run ABCtoolbox in
estimation mode. Then, the argument simName speciﬁes the name of the ﬁle
containing the performed simulations. This ﬁle is requested to contain the used
model parameter values together with the associated statistics, the names of

376
Handbook of Approximate Bayesian Computation
TABLE 13.3
ABCtoolbox Settings for Estimation
Setting
Type
Setting
Description
Basic
task
Task to be performed. Possible options
are: simulate, estimate, ﬁndStatsMod-
elChoice.
params
Specify the parameter columns in the
ﬁle that contains the simulations.
simName
File containing simulations.
obsName
File
containing
observed
summary
statistics.
numRetained
No. of simulations to retain.
maxReadSims
Maximum number of read simulations.
pruneCorrelated
Stats
Remove statistics that are correlated,
possible
options
0
(retain),
or
1
(remove).
maxCor
Maximum acceptaple correlation coef-
ﬁcient between statistics.
outputPreﬁx
Preﬁx for output ﬁles.
writeRetained
Indicate whether to write retained sim-
ulations which can be used to obtain
ABC rejection posteriors.
standardiseStats
Standardise statistics.
Validation
obsPValue
The number of retained datasets for
testing how well the inferred GLM
model ﬁts the observed data in multi-
dimensional space (Section 13.3.4.1).
tukeyPValue
The number of retained datasets for
performing the Tukey test (Section
13.3.4.1).
modelChoice
Validation
The number of cross-validation repli-
cates
for
validating
model
choice
(Section 13.4.2).
randomValidation
The number of cross-validation repli-
cates for random parameter validation
(Section 13.3.4.3).
retainedValidation
The number of cross-validation repli-
cates for retained parameter valida-
tion (Section 13.3.4.3).
(Continued)

A Guide to General-Purpose ABC Software
377
TABLE 13.3 (Continued)
ABCtoolbox Settings for Estimation
Setting
Type
Setting
Description
Posterior
density
posteriorDensity
Points
Number of points to estimate posterior
density.
diracPeakWidth
Smoothing
parameter
for
posterior
densities.
jointPosteriors
Comma separated list of parameters for
which the joint posterior is to be eval-
uated (Section 13.3.3).
jointPosterior
Density Points
No. of points to evaluate joint posterior
(Section 13.3.3).
which are provided in the ﬁrst line. Similarly, the ﬁle speciﬁed with the ar-
gument obsName should contain the summary statistics Sobs calculated from
the observed data, again with the ﬁrst line of the ﬁle containing the names of
the statistics and the second line the associated values. Using the argument
params, ABCtoolbox is further told which columns of the simulation ﬁle con-
tain the model parameters to be estimated. Note that the simulation ﬁle may
contain an arbitrary number of additional columns that will be ignored if
they are neither speciﬁed to be model parameters with the argument params
nor summary statistics also present in the ﬁle with the observed summary
statistics.
The additional required arguments maxReadSims and numRetained spec-
ify the maximum number of lines (simulations) that will be read from the
simulation ﬁle and the number of simulations to be retained in the rejec-
tion step, respectively. Finally, the argument maxCor speciﬁes the maximal
allowed correlation between summary statistics. If we also add the argument
pruneCorrelatedStats, then the analysis will be performed by using statis-
tics that their pairwise correlation do not exceed the maxCor threshold. We
will discuss the issues with the following correlated statistics Section 13.4.3,
but set this option here to 1 in order to include all statistics in the calculations
and to avoid ABCtoolbox complaining about the presence of highly correlated
statistics in our toy models.
To run ABCtoolbox with this input ﬁle (assuming it was saved under the
name estimate.input), simply run in the command:
./ABCtoolbox estimate.input
Alternatively, the example can be run without using an input ﬁle by specifying
the commands in the command line as:
./ABCtoolbox task=estimate simName=simNorm.txt obsName=normal.obs
params=1-2 maxReadSims=10000 numRetained=100 writeRetained maxCor=1.0

378
Handbook of Approximate Bayesian Computation
TABLE 13.4
ABCtoolbox Estimation Output Files
File Type
File Tag
Content
Basic
MarginalPosterior
Characteristics
Characteristics of marginal posterior distri-
butions (e.g. mode, mean, quantiles).
BestSimsParam
Stats
Retained simulations from ABC-rejection.
MarginalPosterior
Densities
GLM-adjusted marginal posterior densities.
jointPosterior
GLM-adjusted joint posterior estimates.
modelFit
Model choice results including Bayes factors
and posterior support for compared models.
Parameter
RandomValidation
Results from random validation.
validation
RetainedValidation
Results from retained validation.
Model choice
modelChoice
Results for model choice validation.
validation
Validation
The output of such a run is found in a series of ﬁles, the names of which begin
with a preﬁx that can be set with the argument outputPrefix, a tag referring
to its content, and a number referring to the dataset and model for which the
estimation has been conducted. While an exhaustive list of all output ﬁlename
tags discussed in this chapter is given in Table 13.4, we will focus here on the
ﬁle with tag BestSimsParamStats, which contains the retained simulations
and is used to plot the rejection posterior.
The posterior estimates for μ and σ2 obtained from the ABC-rejection
algorithm are readily plotted in R using the density() function.
par(mfrow=c(1,2))
ABCrej<-read.delim("ABC_GLM_model0_BestSimsParamStats_Obs0.txt",sep="\t");
plot(density(ABCrej$mu,from=-1,to=1),main=expression(mu));
plot(density(ABCrej$sigma2,from=0,to=4),main=expression(sigma^2));
The results we obtained for the observed data shown earlier are plotted using
density in Figure 13.1.
13.3.2
Post-sampling adjustments
Posterior distributions estimated with the rejection algorithm tend to be much
broader than the true posterior distributions. This is shown for the normal
model in Figure 13.1, but has been observed generally and is due to the often
relatively large distance thresholds leading to parameter values resulting in
summary statistics rather distant from Sobs to be accepted. Obviously, this loss
of precision can be reduced by being more restrictive in accepting simulations,
but this may require unrealistically computational eﬀorts, particularly in more
complex models.
An alternative is to correct for the eﬀect of using large thresholds by
exploiting the often simpler relationship between model parameters and

A Guide to General-Purpose ABC Software
379
summary statistics locally around the observed summary statistics. In a land-
mark paper, Beaumont et al. (2002) assume a linear relationship between
model parameters and summary statistics locally among the retained simula-
tions and proposed to use this relationship to project the parameter values of
all retained parameter values to Sobs. More recently, Blum and Fran¸cois (2010)
introduced an extension of this approach by ﬁtting a non-linear, heteroscedas-
tic model using neural networks. Both of these algorithms are implemented in
the R package abc.
In contrast, ABCtoolbox oﬀers an implementation of the ABC-General
Linear Model (GLM) algorithm introduced by Leuenberger and Wegmann
(2010) that estimates a local likelihood function instead of directly targeting
the posterior distribution. While potentially slightly slower, this formulation is
ﬂexible in the choice of prior distributions and allows for model choice based
on the marginal density. In practice, however, all mentioned post-sampling
adjustment algorithms tend to give very similar results and the reader is ad-
vised to validate any estimation carefully in which these algorithms produce
diverging estimates.
abc
The two post-sampling adjustments implemented in the R package abc are
used by simply choosing the appropriate method when calling the abc() func-
tion. There are three diﬀerent methods available: loclinear, ridge, and
neuralnet, which correspond, respectively, to the classic regression adjust-
ment introduced by Beaumont et al. (2002), a version of this algorithm using
a ridge regression to deal with extensive collinearity among statistics and
the non-linear, heteroscedastic regression proposed by Blum and Fran¸cois
(2010). When using the loclinear method, if a warning appears regarding the
collinearity of the design matrix, then we recommend to use the ridge method
instead.
The following commands will perform posterior estimation using these
algorithms on the toy model introduced earlier.
regression <- abc(S.obs,P.normal,S.normal,tol=0.01,method="loclinear");
neural <- abc(S.obs,P.normal,S.normal,tol=0.01,method="neuralnet");
The built-in function hist() can then again be used to plot the estimated
posterior distributions.
hist(regression);
hist(neural);
Another function provided by the package abc is plot.abc, which can be used
to plot the densities of the estimated posterior distributions together with
additional, informative plots such as the prior distribution, the distribution
of euclidean distances, and the residuals of the regression. Since this function
overloads the standard R function plot(), it is simply used as follows:

380
Handbook of Approximate Bayesian Computation
plot(regression,param=P.normal);
plot(neural,param=P.normal);
Alternatively, the estimated posterior distributions can also be plotted using
the R function density. For that purpose, one has to access speciﬁc elements
of the object returned by the abc() function, namely the projected model
parameter values as adj.values, as well as their weights weights. The fol-
lowing R commands, for instance, plot the posterior densities obtained via the
regression and neural network adjustment for μ:
plot(density(regression$adj.values[,1], weights=regression$weights/sum(
regression$weights)),main=expression(mu));
plot(density(neural$adj.values[,2], weights=neural$weights/sum(neural$
weights)),main=expression(sigma^2));
Posterior distributions plotted using these functions are compared to those
obtained through other methods in Figure 13.1. Note that the object re-
turned also contains the retained model parameter values in the element
unadj.values that can be used to plot the rejection posterior distribution.
plot(density(regression$unadj.values[,1]),main=expression(mu));
plot(density(regression$unadj.values[,2]),main=expression(sigma^2));
ABCtoolbox
When running ABCtoolbox in estimation mode, the
ABC-GLM ad-
justment introduced by Leuenberger and Wegmann (2010) is performed
automatically
and
the
results
available
in
the
output
ﬁle
with
tag
MarginalPosteriorDensities. To plot the posterior estimates in R, simply
load that ﬁle and use the function density.
par(mfrow=c(1,2))
ABCglm <- read.delim("ABC_GLM_model0_MarginalPosteriorDensities_Obs0.txt");
plot(ABCglm$mu,ABCglm$mu.density,type="l");
plot(ABCglm$sigma2,ABCglm$sigma2.density,type="l");
13.3.3
Multi-dimensional posteriors
abc
Apart from marginal posterior distributions, both the R package abc as well
as ABCtoolbox are capable of estimating multi-dimensional posterior distribu-
tions. In the case of abc, however, the posterior densities have to be estimated
using standard functions of R, such as kde2d() for two-dimensional posterior
distributions. In our toy model, for instance, using:
posterior2d <- kde2d(regression$adj.values[,1],regression$adj.values[,2],n
=100);
contour(posterior2d,xlab=expression(mu),ylab=expression(sigma^2));

A Guide to General-Purpose ABC Software
381
where, regression$adj.values[,1] represents the projected model parame-
ter values for μ, regression$adj.values[,2] represents the projected model
parameter values for σ2, and n=100 speciﬁes the number of marginal grid
points to be used for the density estimation. These R commands will produce
a plot similar to the one in Figure 13.1c.
ABCtoolbox
To generate multi-dimensional posterior densities on a grid, simply add the
argument jointPosteriors, followed by the names of the model parame-
ters for which the multi-dimensional posterior distribution is to be estimated.
In addition, the number of marginal grid points has to be speciﬁed using
jointPosteriorDensityPoints. The joint posterior estimates for the pa-
rameters μ and σ2 of the normal distribution model, for instance, are thus
estimated by simply running ABCtoolbox with a modiﬁed estimate.input
input ﬁle that contains these two additional lines:
jointPosteriors mu,sigma2
jointPosteriorDensityPoints 100
Note that the total number of grid points grows exponentially with the dimen-
sionality. In this previous example, the density will be evaluated at 100×100 =
104 positions. Running such a command for a four-dimensional posterior will
already result in 108 positions at which the density has to be estimated.
When
running
ABCtoolbox
with
the
additional
arguments
jointPosteriors and jointPosterior DensityPoints, the posterior den-
sity at each grid point will be written to an output ﬁle with tag
jointPosterior. The resulting joint posterior of μ and σ2 can then be plotted
in R using the function contour().
plot2D <- read.delim("ABC_GLM_model0_jointPosterior_1_2_Obs0.txt");
x <- unique(plot2D$mu);S.unif$var
y <- unique(plot2D$sigma2);
z_density <- matrix(data=plot2D$density,nrow=length(x),ncol=length(y),byrow
=F);
contour(x,y,z_density,xlab=expression(mu),ylab=expression(sigma^2));
Since densities may be hard to interpret, ABCtoolbox also calculates and prints
the smallest high posterior density interval (HDI) including each grid point
to the same output ﬁle. The HDI corresponds to a posterior credible interval
in the multi-dimensional parameter space and, hence, allows the generation
of contour plots where contour lines indicate posterior credible intervals as
follows:
z_HPD <- matrix(data=plot2D$HDI,nrow=length(x),ncol=length(y),byrow=F);
contour(x,y,z_HPD,xlab=expression(mu),ylab=expression(sigma^2));
The two-dimensional posterior distribution we obtained this way for the nor-
mal distribution example is given in Figure 13.1c.

382
Handbook of Approximate Bayesian Computation
Note that using a grid evaluation is not suitable to estimate multi-
dimensional densities in high dimensions, as the total number of grid points
grows exponentially with the dimensionality. In this earlier example, the den-
sity will be evaluated at 100 × 100 = 104 positions. Running such a command
for a four-dimensional posterior will already result in 108 positions at which
the density has to be estimated. An alternative is to generate samples from
the joint posterior distribution from which densities are estimated using kernel
estimators. To generate samples from high-dimensional posterior distributions
after post-sampling adjustment, ABCtoolbox also implements an MCMC al-
gorithm. While we will not discuss that algorithm here, we refer the user to
the manual of ABCtoolbox for more details.
13.3.4
Validation of parameter estimation
13.3.4.1
Using a wrong model
An essential ﬁrst validation step is to check whether the observed statistics
can be reproduced by the examined model. A failure of the model to reproduce
some of the statistics may indicate that a model is either not reﬂecting reality
close enough or that inappropriate prior distributions have been used (e.g.
too narrow distributions). More importantly, all post-sampling adjustments
assume that the model ﬁtted to the model parameters and summary statistics
can be used to either accurately project retained simulations to Sobs (the
methods implemented in abc), or is an accurate description of the likelihood
of Sobs with the parameter range of the retained simulations (the method
implemented in ABCtoolbox). A violation of these assumptions leads to an
extrapolation to an area of the summary statistics space for which no samples
have been obtained, and, hence, is prone to biased inference.
Checking if the observed summary statistics Sobs are within the range of
summary statistics generated by the model is, however, a bit tricky in higher
dimensions. For instance, consider the marginal summary statistics distribu-
tions shown in Figure 13.2 for the normal and uniform toy models, respectively.
These distributions were plotted in R using the density() function directly
from the simulated data.
plot(density(S.normal$var), col=’black’);
lines(density(S.unif$var), col=’grey’);
abline(v=S.obs[2])
These plots suggest that both summary statistics are readily generated by
both models. However, a mismatch might manifest when looking at com-
binations of summary statistics. To check this we can plot two-dimensional
distributions of pairs of summary statistics using the R functions kde2d and
contour.
d <- kde2d(S.unif$var, S.unif$range, n=100);
contour(d$x, d$y, d$z);

A Guide to General-Purpose ABC Software
383
Range
0.0
0
2
4
6
8
10
1.0
2.0
Var
3.0
0
0.0
0.2
Density
0.4
0.0
0.2
0.1
Density
0.3
0.4
1
2
Var
(a)
(b)
(c)
0
2
4
6
8
12
10
Range
3
4
FIGURE 13.2
The distributions of simulated versus observed statistics variance (a) and
range (b) and their joint distribution (c) for the normal (black) and uniform
(grey) distribution models. Observed data are shown with a black vertical line
in panels a and b, and with a black dot in panel c.
As is shown in the rightmost panel in Figure 13.2, the combination of the two
observed summary statistics variance and range can indeed not be repro-
duced by the uniform model. However, this fact is not visible when looking at
marginal densities only.
ABCtoolbox
Since visual inspection is only fruitful for a limited number of dimensions,
ABCtoolbox oﬀers two statistical tests for assessing whether a given model
can reproduce the observed data Sobs in the multi-dimensional statistics space.
The ﬁrst test compares the marginal density (also called ‘marginal likelihood’)
of the observed data to the marginal density of the retained simulations. The
fraction of retained simulations with smaller or equal marginal density than
the observed data is then provided as the marginal density P-value, where
small values indicate a poor ﬁt of the model to the observed data.
The second test evaluates how central the observed data lay within the
multi-dimensional cloud of retained simulations by reporting the fraction
of retained simulations with smaller or equal Tukey depth than the ob-
served data as the Tukey P-value (Cuesta-Albertos and Nieto-Reyes (2008);

384
Handbook of Approximate Bayesian Computation
TABLE 13.5
Observed P-Value and Tukey P-Value Results for
Normal Distribution Example
Marginal
Marginal
Density
Tukey
Tukey
Model
Density
P-Value
Depth
P-Value
1
1158.75
0.098
0.13
0.96
2
4.16 × 10−12
0
0
0
Adrion et al. (2014)). The Tukey depth is a common measure of centrality
analogous to the median in one dimension and is calculated by ABCtoolbox
for a retained simulation (or the observed data) as the smallest fraction of
retained simulations which can be separated from the rest of the simulations
using a hyper plane through the chosen simulation (or the observed data).
Again, a low Tukey P-value indicates a poor ﬁt of the model, since the ob-
served data appears to be at the periphery of the retained cloud. However,
note that the opposite is not necessarily true. Indeed, even a poor model (e.g. a
model producing summary statistics at random) may be capable of generating
a cloud of summary statistics surrounding Sobs and will thus pass both tests.
To perform these tests, simply call ABCtoolbox with the arguments
marDensPValue and tukeyPValue, where each of them indicates the number of
retained simulations to be used when calculating the respective P-value. When
adding the following two lines to the input ﬁle estimate.input, for instance,
ABCtoolbox will use 1000 retained simulations to evaluate the P-values.
marDensPValue 1000
tukeyPValue 1000
The results we obtained for these tests for our toy models are shown in
Table 13.5. As expected from the visual inspection in Figure 13.2, the uni-
form model is not capable of reproducing the observed data and, hence, fails
both tests.
13.3.4.2
Cross-validation/accuracy of point estimates
The accuracy of posterior point estimates is generally assessed by estimating
the parameters for datasets for which the true parameter values are
known. This is readily done in an ABC setting as a leave-one-out test in
which one of the provided simulations is randomly chosen and all other are
used to infer the parameter estimates for this data (often called ‘pseudo-
observed’ data). The inferred posterior point estimates, such as the maximum
a posteriori (MAP or posterior mode), the posterior mean or the posterior
median are then plotted against the parameter values used to generate the
data (referred to as the ‘true parameters’). This process (also called ‘cross-
validation’) is then repeated for many ‘pseudo-observed’ datasets to obtain a

A Guide to General-Purpose ABC Software
385
general measure of accuracy. The procedure may also be repeated to test spe-
ciﬁc ABC settings such as the eﬀect of the choice of tolerance or the number
of available simulations.
abc
To use this cross-validation algorithm with the R package abc, simply call
the function cv4abc() with the arguments matching those of the estimation
plus the additional argument nval, which speciﬁes how many pseudo-observed
datasets are to be used. However, note that the observed data does not have
to be provided, as they are not used in cross-validation. The following code,
for instance, will conduct cross-validation on the normal distribution example
for the neural network estimation algorithm based on 100 individual pseudo-
observed datasets.
cv.neural <- cv4abc(P.normal, S.normal, tols=0.1, statistic="mode",method="
neuralnet", nval=100);
Such a call will return an object containing both the true parameter values
(element true), as well as the estimated parameter values (element estim),
which can be used to estimate correlations among them and plot for visual
inspection. A plot such as the one shown in Figure 13.3 is generated by:
plot(cv.neural);
ABCtoolbox
ABCtoolbox oﬀers two ﬂavours of this cross-validation algorithm: either by
picking simulations randomly or by picking simulations only among those
True value
0.5
R2 = 0.90
0.5
1.5
2.5
1.5
2.5
0.5
R2 = 0.95
0.5
1.5
2.5
1.5
2.5
0.5
R2 = 0.93
0.5
1.5
2.5
1.5
2.5
0.5
R2 = 0.95
R2 = 0.93
GLM
0.0 0.5
−0.5
−1.0
−1.0
−0.5
0.0
0.5
1.0
1.0
R2 = 0.95
NeuralNet
0.0 0.5
−0.5
−1.0
−1.0
−0.5
0.0
0.5
1.0
1.0
R2 = 0.96
Regression
0.0 0.5
−0.5
−1.0
−1.0
−0.5
0.0
0.5
1.0
1.0
R2 = 0.93
Rejection
0.0 0.5
−0.5
−1.0
−1.0
−0.5
0.0
0.5
1.0
1.0
0.5
1.5
2.5
1.5
2.5
σ  2
μ
Estimated mode
FIGURE 13.3
Parameter validation using diﬀerent methods. The estimated posterior mode
for mean and variance is plotted against the true values.

386
Handbook of Approximate Bayesian Computation
that were retained. The former, which is invoked through the argument
randomValidation, corresponds to picking parameter values from the prior
distribution and is thus informative above the overall accuracy of the ABC
estimation under the chosen model. The latter, which is invoked using the
argument retainedValidation, is informative about the accuracy of the es-
timation for the parameter space leading to similar data as the one observed.
task estimate
simName simNorm.txt
obsName normal.obs
params 1-2
maxReadSims 10000
numRetained 1000
maxCor 1.0
randomValidation 1000
retainedValidation 1000
When running ABCtoolbox with one or both of those arguments, an additional
output ﬁle with tag randomValidation or retainedValidation is generated
that contains the true parameter values along with a series of posterior point
estimates for each parameter, namely the MAP (or mode), as well as the
posterior mean and median. This ﬁle can then be loaded into R to generate
plots such as those shown in Figure 13.3 as follows:
Random_validation <- read.delim("ABC_GLM_model0_RandomValidation.txt");
Retained_validation <- read.delim("ABC_GLM_model0_RetainedValidation_Obs0.
txt");
plot(Random_validation$mu, Random_validation$mu_mode);
plot(Retained_validation$mu, Retained_validation$mu_mode);
13.3.4.3
Checking for biased posteriors
Pseudo-observed datasets can be used equally to detect potential biases in the
marginal posterior distributions. If the posterior distributions of a parameter
were unbiased, the position of the true parameters across many replicates must
be given by the posterior densities. We proposed to test this directly using
the probability integral transform test (PIT histogram or coverage property)
Wegmann et al. (2009); Prangle et al. (2014). This is done by recording the
position of the true parameter value in the cumulative posterior distribution
(the posterior quantile) for each pseudo-observed dataset. In case posteriors
were unbiased, these posterior quantiles must be uniformly distributed be-
tween 0 and 1. Similarly, the smallest high posterior density intervals (HDI)
containing the true parameter value must be distributed uniformly.
ABCtoolbox
The procedure for this is the same as the one described in Section 13.3.4.2.
The same output ﬁle will contain information that allows us to check for
biased posteriors. For instance, the output from these analyses can be used to

A Guide to General-Purpose ABC Software
387
(a)
0.2
0.0
0.4
Density
0.8
1.2
0.0
0.4
0.8
1.2
0.4
0.6
Quantile (p = 0.0121)
HDI (p = 0.3404)
Quantile (p = 0.0655)
HDI (p = 0.0462)
0.0
0.4
Density
0.8
1.2
0.0
0.4
0.8
1.2
Quantile (p = 0.447)
HDI (p = 0.1307)
Quantile (p = 0.0101)
HDI (p = 0.1432)
μ
0.8
0.2
0.4
0.6
σ 2
μ
σ 2
0.8
0.2
0.4
0.6
0.8
0.2
0.4
0.6
0.8
(b)
FIGURE 13.4
Parameter validation testing uniformity of the distribution of posterior quan-
tiles and HDI when using random (a) and retained (b) simulations.
determine whether the posterior quantiles and HDI are uniformly distributed
either by visual inspection or by performing a statistical test such as the
Kolmogorov–Smirnov test:
hist(Random_validation$mu_HDI)
ks.test(Random_validation$mu_HDI,"punif")
The result of the random and retained validation analyses for the normal
distribution example can be seen in Figure 13.4a and b, respectively.
13.4
Model Choice
While model choice is commonly used in Bayesian statistics, it is contentious
in an ABC setting due to the problem that even summary statistics suﬃ-
cient for both models may lead to biased inferences (Didelot et al., 2011;

388
Handbook of Approximate Bayesian Computation
Robert et al., 2011). Nonetheless, ABC model choice has been used success-
fully in practice and both ABC pipelines discussed here oﬀer algorithms to
conduct model choice when simulations from multiple models are available.
However, the user is advised to validate any ABC model choice carefully, and
we will discuss here tools provided by the R package abc, as well as ABCtoolbox
to aid in that crucial step.
13.4.1
Inferring Bayes factors
Bayesian model choice relies on the estimation of model posterior probabilities
or Bayes factors (the ratios of posterior probabilities of competing models).
In standard Bayesian statistics, these are estimated from the marginal densi-
ties (or marginal likelihood) of the compared models, where the marginal den-
sity of model i is deﬁned as the integral of the likelihood function, weighted
by the prior distribution:
P(Mi|D) =

P(D|θi, Mi)P(θi|Mi)dθi.
Importantly, the marginal density is thus aﬀected by the choice of prior dis-
tribution, and, hence, what is evaluated in a Bayesian setting is thus the
combination of a stochastic model and the prior distribution speciﬁed on its
parameters.
In case the likelihood function is not available for analytical evaluation,
both posterior probabilities and Bayes factors can be estimated using ABC.
The algorithm implemented in ABCtoolbox, for instance, ﬁts a likelihood
model to the retained data, and then uses this model to analytically calculate
the marginal density for each model. In contrast, the algorithms available in
the R package abc use the fact that the marginal density is proportional to the
fraction of simulations that resulted in simulations close to the observed data
Sobs when the simulations are generated according to the prior distribution.
The posterior probabilities of the diﬀerent models are thus estimated from the
relative number of simulations being close to Sobs either from direct counting
or through a regression adjustment similar to parameter inference. Note that
it is crucial for both algorithms that the exact same summary statistics have
been calculated under both models.
To illustrate the model choice algorithms implemented, we will attempt
to estimate which of the two toy models introduced earlier (the normal and
uniform model) was used to generate the observed data. We refer the reader
to Section 13.2 for more details on those models.
abc
In order to conduct model choice with abc, the summary statistics of all mod-
els have to be concatenated into a single data frame or matrix. In addition,

A Guide to General-Purpose ABC Software
389
a vector indicating for each simulation the model under which it has been
generated has to be created. For our toy models, this is simply achieved as
follows:
allSimulations <- rbind(S.normal,S.unif);
index <- c(rep("norm",dim(S.normal)[1]),rep("unif",dim(S.unif)[1]));
The actual model choice is then conducted using the function postpr, which
takes as arguments the observed summary statistics Sobs, the object containing
the summary statistics for all models, and the index vector. In addition, the
tolerance for the rejection step, as well as the method for estimating Bayes fac-
tors has to be provided. In total, abc oﬀers three such methods. The simplest
is method rejection, which estimates posterior probabilities of the diﬀerent
models directly from the relative proportions of accepted simulations. The two
other methods, mnlogistic and neuralnet attempt to correct for the often
large tolerance values by estimating the relative densities of retained simula-
tions at Sobs using either a multi-nomial logistic regression Beaumont (2008);
Fagundes et al. (2007) or neural networks Fran¸cois and Guillaume (2011),
respectively.
The following command will run model choice using the neuralnet method
on our toy models and, using the function summary(), print the results to
screen in a nice format.
model.choice <- postpr(S.obs, index=index, sumstat=allSimulations, tol
=0.1, method="neuralnet");
summary(model.choice);
The results for our toy models are shown in Table 13.6. As is expected from the
observation that the uniform model fails to reproduce the observed summary
statistics, the preferred model for this data is the normal model. However,
note that the results for the rejection method, which is also run by default
when performing a mnlogistic or neuralnet estimation, is much less clear
due to the relatively large tolerance applied here.
ABCtoolbox
To perform model choice with ABCtoolbox, simply provide the arguments
simName and params for multiple models using semicolons. To run model
TABLE 13.6
Results of Model Choice by Toy Models
Posterior Probability
Bayes Factor
Model
Normal
Uniform
Normal versus Uniform
abc (rejection)
0.65
0.395
1.53
abc (neuralnet)
1.00
0.00
1.1 × 106
ABCtoolbox (GLM)
1.00
9.79 × 10−13
9.79 × 1013

390
Handbook of Approximate Bayesian Computation
choice on our toy models, for instance, the input ﬁle estimate.input provided
abode is modiﬁed as follows:
task estimate
simName simNorm.txt;simUnif.txt
obsName normal.obs
params 1-2;1-2
maxReadSims 10000
numRetained 1000
maxCor 1.0
When running ABCtoolbox with such an input ﬁle, an additional ﬁle with
tag modelFit is generated. This ﬁle contains the marginal densities, Bayes
factors, and posterior probabilities for each model. The results from this ﬁle
obtained for our toy models are shown in Table 13.6, clearly indicating that
the normal model is a much better ﬁt.
13.4.2
Model choice validation
As was shown recently, model choice conducted with ABC may lead to biased
or even wrong posterior probabilities, even if the summary statistics are suf-
ﬁcient for all models compared (Robert et al. (2011)). Consider two models
M1 and M2 of shared parameters θ. If a set of summary statistics S was
suﬃcient for both models, then the likelihood of the summary statistics and
the likelihood of the full data are proportional for both models:
P(D|θ, M1) = c1P(S|θ, M1)
P(D|θ, M2) = c2P(S|θ, M2).
However, there is no guarantee that the two proportionality constants c1 and
c2 are identical, which leads to the Bayes factors that are oﬀby c1/c2. There-
fore, careful validation is a key and compulsory step of any ABC model choice
analysis. An initial ﬁrst test may be to evaluate the power of choosing the
correct model by means of pseudo-observed datasets. Such a cross-validation,
which is oﬀered by both abc, as well as ABCtoolbox, simply picks random sim-
ulations among those provided from both models, conducts model choice, and
records how frequently the correct model was preferred. In addition, ABCtool-
box provides means to test for biases in the obtained posterior probabilities
by comparing the ABC posterior probability (termed ‘pABC’) against those
empirically expected (pempirical) (Peter et al., 2010).
abc
The R package abc contains the function cv4postpr to conduct cross-
validation for model choice. This function randomly picks one simulation from
the ﬁle containing all simulations, performs model choice using the chosen
simulation as pseudo-observed data, and records which model obtained the
highest posterior probability. This is then repeated many times to determine
the confusion matrix. As an example, consider the following call to cv4postpr

A Guide to General-Purpose ABC Software
391
to conduct 100 such replicates on our toy models using the index vector cre-
ated earlier. To then print the confusion matrix, one may use the function
summary() and to obtain a graphical representation the built in plot() func-
tion as follows.
cv.model.choice <- cv4postpr(index,allSimulations, nval=100, tols=0.1,
method="neuralnet")
summary(cv.model.choice);
plot(cv.model.choice);
ABCtoolbox
To perform model choice validation with ABCtoolbox, simply add the argu-
ment modelChoiceValidation followed by the number of pseudo-observed
datasets to be used to the estimation ﬁle. To use 1000 pseudo-observed
datasets, for instance, you may add the following line to the input ﬁle:
modelChoiceValidation 1000
ABCtoolbox will then perform cross-validation and write the results to two
diﬀerent ﬁles. The ﬁrst has the tag confusionMatrix containing the confu-
sion matrix (fraction of correctly and incorrectly inferred models), as well as
statistics calculated from it. For the toy model, for instance, we learn from this
ﬁle that the normal model is correctly identiﬁed from data generated under
that model in >99% of the cases.
The second ﬁle with tag modelChoiceValidation contains the raw results
from the model choice validation and can be used for a more detailed validation
analyses. For instance, we have recently proposed to compare the estimated
model posterior probabilities with the empirical ones, an analysis that can
reveal biases in ABC model choice (Peter et al., 2010; Chu et al., 2013).
The basic logic of this analysis is that among all pseudo-observed datasets
that resulted in an ABC posterior probability pABC = x in favor of, say,
model 1, a fraction x should have been generated under model 1. To test
for this, data sets are binned according to their ABC posterior probabilities
pABC, and the empirical posterior probabilities pempirical are then estimated
as the fraction of simulations within each bin that were indeed generated with
model 1.
The ABCtoolbox package includes the Rscript Make Model choice power
plot.r to conduct this analysis and to produce the plot shown in Figure 13.5.
For our toy models, it appears that there is a slight bias towards the normal
model. This is evident from the fact that when pABC = 0.5, the datasets
were actually generated from the uniform model in about 70% of the cases.
However, among the datasets that resulted in very high pABC (≥0.99), the
vast majority was generated under that model. Therefore, we have high
conﬁdence in the model choice results of our observed data, which pro-
duced ≥0.99 posterior probability support for the normal distribution model
(Table 13.6).

392
Handbook of Approximate Bayesian Computation
0
0
0.2
0.4
0.6
0.8
1
0.2
0.4
Normal
Uniform
pABC
pempirical
0.6
0.8
1
FIGURE 13.5
Posterior probability for normal and uniform distribution models estimated
by ABCtoolbox (pABC) versus an empirical estimate of the same probability
through simulation (pempirical).
13.4.3
Choosing summary statistics
13.4.3.1
Statistics for parameter inference
The choice of summary statistics is crucial in any ABC inference, in that too
few summary statistics are likely to miss out on important information and
too many introduce harmful noise to the estimation (Wegmann et al., 2009;
Beaumont, 2008; Blum et al., 2013). To date, many methods have been pro-
posed to choose informative summary statistics from a larger set (see Blum
et al. (2013) for a review), but we will focus here on those available through the
ABCtoolbox package, in particular the use of linear combinations of summary
statistics.
The use of such linear combinations was ﬁrst introduced by Wegmann et al.
(2009), who proposed to ﬁnd them by means of partial least squares (PLS)
regression. Broadly speaking, PLS is similar in spirit to a principal component
analysis, but instead of ﬁnding linear combinations that maximise the vari-
ance explained in the summary statistics space, PLS components are chosen
such that they maximise the product of the variance among summary statis-
tics and the covariance between parameters and statistics (Tenenhaus et al.,
1995). Recently, alternative means of ﬁnding linear combinations of summary
statistics have been proposed, such as through boosting (Aeschbacher et al.,
2012) or by regressing summary statistics on to posterior means inferred from
an initial set of simulations (Fearnhead and Prangle, 2012).
While all these methods are readily used with ABCtoolbox once the linear
combinations have been found, we will illustrate the usage of this functionality

A Guide to General-Purpose ABC Software
393
0
0.2
0.4
0.6
0.8
RMSEP
1.0
2
4
No. of components
6
σ2
μ
8
FIGURE 13.6
Number of PLS components versus root mean square error of prediction
(RMSEP) for the normal distribution model.
based on the PLS approach, which is easy to implemevR-package ‘pls’. In fact,
the ABCtoolbox package provides an R-script to perform this analysis taking
as input the simulations ﬁle (simNorm.txt). Performing a PLS analysis on
the simulations from the normal distribution example reveals that two PLS
components are suﬃcient for explaining the variance of the parameters of
the normal distribution (Figure 13.6). This result is expected since the mean
of a sample and the mean and variance of a sample are suﬃcient statistics
for estimating, respectively, the mean and variance parameters of a normal
distribution.
Any deﬁnition of linear combinations resulting from such a PLS or any
other approach can then be used to transform the statistics of a set of simula-
tions and the observed data using ABCtoolbox and then used in parameter in-
ference. The PLS R-script mentioned earlier, for instance, writes the resulting
PLS components to the ﬁle PLSdef.txt, which is then provided to ABCtoolbox
and run in the transform mode as follows:
./ABCtoolbox task=transform linearComb=PLSdef.txt input=simNorm.txt output=
simNorm.pls numLinearComb=2
./ABCtoolbox task=transform linearComb=PLSdef.txt input=normal.obs output=
normal.obs.pls numLinearComb=2
Note that while we provided all arguments to ABCtoolbox on the command
line, they may equally well be given in an input ﬁle. Using the transformed
summary statistics in the estimation step is then straightforward: simply pro-
vide the transformed ﬁles using the arguments simName and obsName. As men-
tioned earlier, using alternative ways to ﬁnd linear combinations is compatible

394
Handbook of Approximate Bayesian Computation
with ABCtoolbox, as long as the linear combinations can be written in a deﬁni-
tion ﬁle as the one created by the PLS script. Alternatively, the statistics may
also be transformed with diﬀerent software and then provided to ABCtoolbox
(or the R package abc) for the estimation step.
One issue with using linear combinations of summary statistics is that
information that arises from non-linear combinations of statistics are not taken
into account. In such situations, it may be beneﬁcial to increase the summary
statistics space through combinations of summary statistics before ﬁnding
linear combinations (Aeschbacher et al., 2012). As outlined with an example
in Section 13.5.3, ABCtoolbox has an option (doBoosting) to also generate
all pairwise products of summary statistics when generating simulations for
this purpose.
13.4.3.2
Statistics for model choice
Finding appropriate combinations of statistics for model choice is particularly
tricky. Just as for parameter inference, too few statistics may fail to capture
important information, while too many are likely adding non-informative noise
leading to large estimation variance and potentially a bias. Unfortunately, the
methods introduced previously for ﬁnding good summary statistics for param-
eter inference are not readily extended to the problem of model choice. If one
aims for using linear combinations, the most obvious choice is linear discrimi-
nant analysis (LDA), as was recently proposed by Estoup et al. (2012). To use
LDA for model choice with the programs discussed here is similar to the use
of linear combinations for parameter inference, in that the summary statistics
of the observed and simulated data have to be transformed as explained in
Section 13.4.3.1 before running either ABCtoolbox or the R package abc to
perform model choice.
As an alternative to LDA, ABCtoolbox oﬀers a greedy search algorithm to
identify the combination of statistics having the largest power to discriminate
between models. This search is done iteratively, by ﬁrstly evaluating the power
of each single statistic and then adding additional statistics until no increase
in power is observed. To perform this type of analysis, ABCtoolbox has to
be run in the findStatsModelChoice mode and by providing the simulation
ﬁles for at least two models, as well as the parameters required to perform the
estimation. In addition, and using the argument modelChoiceValidation,
one also needs to specify the number of simulations to be used as pseudo-
observed data in each iteration to evaluate the power. As an example, consider
the following input ﬁle for performing this type of analysis to ﬁnd summary
statistics appropriate for contrasting the normal versus uniform distribution
toy models. We have added argument maxCorSSFinder, and set it equal to
one in order to include combinations of statistics that are highly correlated in
the greedy search. A lower threshold might be appropriate if many summary
statistics are used in order to speed up the search.

A Guide to General-Purpose ABC Software
395
TABLE 13.7
Combinations of Statistics Sorted by Estimated Power to Distinguish Models
Largest
Rank
Power
Pairwise Correlation
No. Statistics
Statistics
1
1
0.966
3
mean,var,range
6
0.999
0.966
2
var,range
82
0.755
0
1
range
task findStatsModelChoice
simName simNorm.txt;simUnif.txt
obsName simple.obs
maxCor 1.0
maxCorSSFinder 1.0
params 1-2;1-2
numRetained 1000
maxReadSims 10000
outputPrefix ABC_searchStats
modelChoiceValidation 1000
The results of this analysis are written to a ﬁle with tag searchStat
sgreedySearch. Part of this ﬁle is shown in Table 13.7. As shown there,
the power to distinguish between these models is very high for multiple sets of
summary statistics. Generally, it is recommended to choose the smallest among
all sets with highest power, which would be the set consisting of the statistics
var and range. As is shown in Figure 13.2, the two-dimensional distribution
of these two statistics is indeed rather diﬀerent between the models.
13.5
Generating Simulations
For simple models, such as the normal distribution example that we examined
in the previous section, it is relatively easy to perform the simulations using
custom scripts written in scripting languages such as R. However, for realis-
tically complex models, we often rely on specialised programs for performing
simulations. Moreover, for certain ABC variants such as ABC-MCMC, the
simulation and estimation procedures are inherently linked, thus requiring
running the program that performs simulations jointly with the program that
performs ABC. When choosing the appropriate program to do simulations,
we should keep in mind that interpreted languages, such as R, are generally
ineﬃcient. In most cases, compiled languages, such as C, should be preferred.
In this section, we will illustrate how to use the program ABCtoolbox, as

396
Handbook of Approximate Bayesian Computation
well as the R package EasyABC to automate and streamline the simula-
tion process and to perform more sophisticated ABC techniques, such as
ABC-MCMC.
13.5.1
Generating simulations for rejection
We will ﬁrst focus on how to use these two ABC pipelines to generate simula-
tions from parameter values drawn from prior distributions. The such gener-
ated simulations are then ready to be used with all the estimation techniques
introduced earlier.
EasyABC
This R package allows the user to launch simulations from an external pro-
gram and to retrieve the output of these simulations in a format ready for
post-processing or to dynamically perform ABC-MCMC. To achieve this, the
user has to provide both a list containing the deﬁnitions of the prior dis-
tributions, as well as a model deﬁnition. The list containing prior distribu-
tions simply contains the names of the desired distributions, along with their
arguments. For instance, a list deﬁned as:
prior <- list(c("unif",-1,1),c("unif",0.1,4));
will imply that there are two model parameters with uniform priors bounded
at −1 and 1, and 0.1 and 4, respectively.
The model may be either an R function taking the parameters as argu-
ments and returning a vector of summary statistics or the name of an exe-
cutable that will be used to generate the simulation. In case an executable
is given, it is assumed that this executable will read the model parameters
to be used from a ﬁle called input and write the resulting summary statis-
tics to a ﬁle called output. These ﬁles are read and written dynamically as
EasyABC concatenates into a list the parameters sampled from the prior
and the simulated summary statistics. As an example, consider an executable
R-script named generate norm EasyABC.R that wraps a program to run the
simulation of a normal distribution which is a model with two parameters:
#!/usr/bin/Rscript
param<-scan("input")
sampleSize <- 100;
data <- rnorm(sampleSize, mean=param[1], sd=param[2]);
calc.stats <- function (x){
S <- c(mean(x), var(x), median(x), range(x), max(x)-min(x),
quantile(x, probs=c(0.25, 0.75)));
names(S) <- c("mean", "var", "median", "min", "max", "range", "Q1", "Q3")
return(S);
}
sim <- calc.stats(data);
write.table(t(sim), file="output", quote=F, row.names=F,col.names=F);

A Guide to General-Purpose ABC Software
397
The user should make the script executable like this:
chmod +x generate_norm_EasyABC.R
EasyABC is used to generate simulations (in this case 103) with the priors
deﬁned earlier as follows:
ABC_sim <- ABC_rejection(model=binary_model(’./generate_norm_EasyABC.R’),
prior=prior,nb_simul=1000)
which should take approximately 2 minutes to ﬁnish. Note that using the
internal function of R to generate 103 deviates from a normal distribution
would take less than 1 second to complete. Therefore, using an external pro-
gram would be advised only if an R function for performing the simulations
cannot be devised (e.g. for complex population genetics simulations, see the
following).
The earlier command would only generate the simulations. To perform re-
jection and obtain the posterior distribution of parameters, we need to specify
the observed summary statistics with argument summary stat target and the
tolerance value with argument tol as follows:
ABC_sim <- ABC_rejection(model=binary_model(’./generate_norm.R’),prior=
prior,nb_simul=1000,summary_stat_target=sum_stat_obs,tol=0.1);
ABCtoolbox
An even more advanced and feature-rich way of using existing programs
to generate simulations is oﬀered by ABCtoolbox. To do so, ABCtoolbox has
to be run in simulate mode, speciﬁed with the argument task. Similarly
to EasyABC, the user then needs to specify both the model parameters and
their prior distributions, as well as how to use existing programs to generate
simulations using values drawn from the prior.
The model parameters and their priors have to be provided through an
external ﬁle referred to as the est ﬁle, the name of which is provided with
the argument estName. This ﬁle is structured in three distinct sections called
[PARAMETERS], [RULES], and [COMPLEX PARAMETERS]. Only the ﬁrst of those
is mandatory and contains the deﬁnitions of the model parameters for which
estimations are to be carried out. These model parameters and their prior
distributions are declared using multiple columns as explained in Table 13.8.
In brief, the ﬁrst column indicates whether or not a model parameter is to
be truncated to an integer value, the second column lists the name of the pa-
rameter, and the third column the prior distribution function. The remaining
columns contain the parameters for this distribution, for instance the lower
and upper bound, as well as the mean and standard deviation for a normal
prior. The last column speciﬁes whether or not the parameter values are to
be printed to the output ﬁle.

398
Handbook of Approximate Bayesian Computation
TABLE 13.8
Declaration of Parameters in the estName File
Column
Content
1
Indicator 1/0 for being integer or rational number.
2
Name of the parameter.
3
Type of prior (see ABCtoolbox Manual for the types of
supported priors).
4 -
Parameters for prior (for example min,max for uniform prior).
Last
Indicator output/hide for whether to print the parameter in
the output ﬁle.
As an example, consider the following est ﬁle.
[PARAMETERS]
0 PARAM_A unif -1 1 output
0 PARAM_B norm -10 10 1 2 output
[RULES]
PARAM_A > PARAM_B
[COMPLEX PARAMETERS]
0 PARAM_B_SCALED = exp(PARAM_B) / PARAM_A
Here, we made use of the optional [RULES] section to limit the simulations
to cases where PARAM A is larger than PARAM B. In addition, we beneﬁted from
[COMPLEX PARAMETERS] section to deﬁne a new variable PARAM B SCALED,
which will always be set to the exponential of PARAM B, divided by the value of
PARAM A. ABCtoolbox will understand most mathematical symbols and oﬀers a
wide variety of functions in this section, which allows for the deﬁnition of prior
distributions and model parameterisation in a diﬀerent way than required by
the simulation software.
To demonstrate the use of ABCtoolbox to perform simulations, we can use
a slightly modiﬁed simulation script named generate norm ABCtoolbox.R
to generate deviates from a normal distribution similarly to the procedure
described earlier for EasyABC:
#!/usr/bin/Rscript
args = commandArgs(trailingOnly=TRUE)
param1=as.numeric(args[1])
param2=as.numeric(args[2])
sampleSize <- 100;
data <- rnorm(sampleSize, mean=param1, sd=param2);
calc.stats <- function (x){
S <- c(mean(x), var(x), median(x), range(x), max(x)-min(x),
quantile(x, probs=c(0.25, 0.75)));
names(S) <- c("mean", "var", "median", "min", "max", "range", "Q1", "Q3")
return(S);
}
sim <- calc.stats(data);
write.table(t(sim), file="summary_stats-temp.txt", quote=F, row.names=F);

A Guide to General-Purpose ABC Software
399
To specify how ABCtoolbox is to interact with the external simulation
software, the arguments simProgram and simArgs are used, where the former
deﬁnes the name of the executable to be used and the latter the arguments
to be passed to that executable. These arguments may contain tags referring
to model parameters listed in the est ﬁle, as well as any other string. The
appropriate input ﬁle for ABCtoolbox may thus look as follows:
task simulate
obsName normal.obs
estName Rules.est
numSims 1000
simProgram generate_norm_ABCtoolbox.R
simArgs PARAM_A PARAM_B
The Rules.est ﬁle that contains the deﬁnitions of parameters and their
priors for should be speciﬁed like this:
[PARAMETERS]
0 PARAM_A unif -1 1 output
0 PARAM_B unif 0.1 4 output
In this example, the parameters are read by the simulation program directly
from the command line. In case the simulation program reads the parameters
from a speciﬁc input ﬁle, ABCtoolbox can be set up to scan such a ﬁle and
to replace all occurrences of model parameter tags deﬁned in the est ﬁle
with their current values, and to save the result to a new ﬁle, which is then
passed to the simulation program. To make use of this feature, the name of
the input ﬁle has to be speciﬁed with the argument simInputName, and the
tag SIMINPUTNAME may then be used to refer to the newly created input ﬁle
among the arguments passed to the simulation program.
Moreover, the output of the simulation program is stored in a ﬁle named
‘summary stats-temp.txt’ which is read by ABCtoolbox by default, but a dif-
ferent name could be speciﬁed with argument sumStatName. In case the simu-
lation program is generating data instead of directly summary statistics itself,
ABCtoolbox can run additional programs to do extra operations on the out-
put of the simulation program, such as the calculation of summary statistics.
Such a program can be deﬁned with the argument sumStatProgram, and the
command-line arguments for the program are set with sumStatArgs. Note
that sumStatProgram will always run after simProgram. A list of commonly
used arguments when running ABCtoolbox in simulate mode are listed in
Table 13.9.
13.5.2
Performing Markov chain Monte Carlo
Several other likelihood-free algorithms have been proposed that overcome the
inherently low acceptance rates of rejection algorithms, among them a Markov
chain Monte Carlo sampler (ABC-MCMC) ﬁrst introduced by Marjoram
et al. (2003), a Gibbs sampler using parameter-speciﬁc statistics (ABC-PaSS;

400
Handbook of Approximate Bayesian Computation
TABLE 13.9
ABCtoolbox Settings for Simulation
Setting
Type
Setting
Description
Basic
task
Possible options simulate and estimate.
samplerType
Possible
sampler
types
are
standard,
MCMC, PaSS, and PMC.
numSims
No. of simulations to perform.
outName
Preﬁx for output ﬁles.
estName
Filename containing deﬁnitions of priors for
parameters and rules.
simProgram
Program to perform simulations.
simArgs
Arguments for simulation program.
obsName
File containing observed summary
statistics.
sumStatProgram
Program to be run after simProgram. For
example, a script calculating summary
statistics.
sumStatArgs
Arguments for sumStatProgram.
sumStatName
File containing simulated summary
statistics.
doBoxCox
Do boxcox transformation.
linearCombName
File
containing
linear
combinations
for
transformation of statistics. (e.g. PLS com-
ponents).
doBoosting
Use all product combinations of statistics as
additional statistics.
MCMC
numCaliSims
No. of calibration simulations.
thresholdProp
Tolerance proportion of calibration
simulations.
rangeProp
Range of proposals.
startingPoint
Starting location set from a random simula-
tion (random) or the simulation with the
minimum distance to the observed data
(best).
mcmcSampling
Interval between iterations that are printed
in the output ﬁle.
Kousathanas et al. (2016)) and sequential Monte Carlo or particle samplers
(ABC-PMC; (Sisson et al., 2007; Beaumont et al., 2009)). While both the R
package EasyABC, as well as ABCtoolbox oﬀer several types of algorithms,
we will focus here on the use of ABC-MCMC with these tools.
The basic idea of ABC-MCMC is to replace the likelihood ratio in the
Hastings ratio of a classic MCMC by an acceptance-rejection step using some

A Guide to General-Purpose ABC Software
401
tolerance ϵ. Such an ABC-MCMC chain is then generating samples directly
from P(∥S −Sobs)∥< ϵ|θ), where θ is the vector of model parameters, S and
Sobs the simulated and observed vectors of summary statistics, respectively,
and ∥· ∥some distance measure in the summary statistics space. Such an
algorithm was shown to require much less simulations than standard ABC
methods to obtain equally good posterior estimates (Marjoram et al., 2003).
However, it turned out to be relatively tricky to tune this algorithm to per-
form properly since the acceptance rate of such an algorithm is directly given
by the absolute likelihood, rather than the relative likelihood as in standard
MCMC. A result of this is that ABC-MCMC chains may easily get stuck in
regions of low likelihood, requiring a careful choice of both the tolerance ϵ
as well as the initial starting positions. To improve the performance of this
algorithm, we have proposed to tune the ABC-MCMC algorithm by means of
an initial training set of simulations (Wegmann et al., 2009), which has been
adopted by both EasyABC as well as ABCtoolbox. Speciﬁcally, the idea of such
a calibration step is to choose a tolerance value ϵ that will result in suﬃciently
high acceptance rates and to ﬁnd starting values in high likelihood regions. As
with the classic rejection algorithm, it may be useful to transform summary
statistics when calculating distances (Wegmann et al., 2009), and, hence, both
EasyABC as well as ABCtoolbox oﬀer to specify such transformations to be
used during an ABC-MCMC chain.
While generally faster, an important issue with ABC-MCMC as well as
Sequential Monte Carlo algorithms is that their output can not be directly
used for validation. Instead, validation has to be done by repeating the whole
process using pseudo-observed datasets, which may easily eat away the com-
putational beneﬁt of using these methods.
EasyABC
In EasyABC, the ABC-MCMC algorithm is oﬀered through the function
ABC mcmc(), which takes similar arguments as the function to perform the
rejection algorithm, namely a list with prior deﬁnitions as well as a model,
but also requires the vector containing the observed summary statistics to be
speciﬁed using the argument summary stat target. In addition, several argu-
ments for tuning the actual MCMC run are required. As an example, consider
the following R code to generate posterior samples using ABC-MCMC for
our normal toy model, using the function calc.stats(), and the vector of
observed summary statistics S.obs introduced previously:
#define model
toy_model <- function(x){
data <- rnorm(100, x[1], sqrt(x[2]));
return(calc.stats(data));
}
toy_prior <- list(c("unif",-1,1),c("unif",0.1,4));
#run ABC-MCMC
ABC_posterior <- ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_

402
Handbook of Approximate Bayesian Computation
prior, n_between_sampling=1,n_rec=10000, summary_stat_target=S.obs, n_
calibration=10000, tolerance_quantile=0.1, numcomp=2);
Here, the argument n rec speciﬁes that 10,000 samples are to be generated.
Further, the arguments n calibration and tolerance quantile specify that
the ABC-MCMC chain will be calibrated from 10,000 simulations conducted
under the prior, of which a fraction of 0.1 will be retained to calibrate the
MCMC chain. Finally, the argument numcomp speciﬁes that the total set of
summary statistics is to be transformed into two PLS components .
Since an ABC-MCMC run is generating posterior samples, the output can
be used directly to plot posterior distributions.
par(pty="s",mfrow=c(1,2));
plot(density(ABC_posterior$param[,1],from=-1,to=1,adjust=3),main="",xlab=
expression(mu));
plot(density(ABC_posterior$param[,2],from=0.1,to=4,adjust=3),main="",xlab=
expression(sigma^2));
ABCtoolbox
To perform the ABC-MCMC algorithm with ABCtoolbox, a few arguments
have to be added to the input ﬁle shown earlier for standard sampling.
First, the argument samplerType has to be set to MCMC. Then, the argu-
ments numCaliSims, thresholdProp, and rangeProp are used to specify the
number of simulations to be used for calibration, the fraction of those simu-
lations to be used to calibrate the threshold, and the fraction of the standard
deviation of parameter values among these retained simulations to be used
to propose new values during the MCMC chain, respectively. To transform
the summary statistics during the MCMC chain, a ﬁle with the deﬁnition of
linear combinations can be provided with the argument linearCombName. To
use PLS transformations, for instance, an initial set of calibration simulations
can be used to ﬁnd appropriate PLS components as discussed earlier, and the
resulting PLS deﬁnition ﬁle is then provided using this argument. For an ex-
ample of an input ﬁle, we refer the reader to the population genetics example
discussed in the following.
13.5.3
A population genetics example
Here, we will illustrate how to implement techniques described in the previous
sections to estimate important aspects of the recent human demographic his-
tory from an allele frequency data set made publicly available by Boyko et al.
(2008). Speciﬁcally, we will use the site-frequency spectrum (SFS) for synony-
mous sites obtained for a sample of 24 African Americans (from Table S2 in
Boyko et al. (2008)) to infer the parameters of a simple population genetic
model. The SFS is an information rich summary of allele frequency data and

A Guide to General-Purpose ABC Software
403
synonymous sites in a gene are sites where any point mutation would lead to
the same amino acid, thus likely to evolve neutrally, which is an assumption
we have to make for demographic inference. Our model assumes an ances-
tral African population of size NANC, which experienced an instantaneous
change in size t generations ago to NCUR. We note that there are multi-
ple full-likelihood solutions available to infer the parameters of this simple
model from SFS data that might outperform ABC (e.g. Excoﬃer et al., 2013;
Gutenkunst et al. 2009). However, the goal here is to provide a detailed step-
by-step, guide to using ABCtoolbox for demographic inference, for which we
prefer a simple model that is fast to run. The beneﬁt of ABC over the full-
likelihood approaches lies in its ﬂexibility, and working through this rather
simple example will illustrate all aspects necessary to build even more complex
models that may violate the assumptions of available full-likelihood solutions.
In Table 13.10, we provide a look-up table of all the ﬁles that will be described
and used in this example.
Following Boyko et al. (2008), we parameterised the time of the size change
in units of the current population size (τ = t/(2 × NCUR)), and to allow the
simulations to be performed in a time reasonable for an illustrative example,
we downsampled the original data from the original 5 million sites to the SFS
of only 10,000 sites shown in Table 13.11. From this data, we then calculated
the set of classic population genetic summary statistics shown in Table 13.12.
TABLE 13.10
Files Required to Run the Full Population Genetics Example
Filename
Description
Source
popgen.obs
Observed summary
statistics
Section 13.5.3
popgen.est
Rules ﬁle for ABCtoolbox
containing deﬁnition of
priors
Section 13.5.3
popgen.input
ABCtoolbox input ﬁle
Section 13.5.3
fsc25221
fastsimcoal2 executable
http://cmpg.unibe.ch/
software/fastsimcoal2/
popgen.par
fastsimcoal2 input ﬁle
Chapter appendix
calcPopstats.pl
Perl
script
to
calculate
summary statistics from
fastsimcoal2 output
Chapter appendix
ﬁndPLS.r
R-script to ﬁnd PLS
components
https://bitbucket.org/
phaentu/abctoolbox-
public/
PLSdef popgen.txt
ﬁle containing PLS def-
initions generated with
ﬁndPLS.r
Chapter appendix

404
Handbook of Approximate Bayesian Computation
TABLE 13.11
Downsampled Synonymous SFS
Site class
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Site count 9906 7 5 2 0 1 1 0 0 1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
77
TABLE 13.12
Summary Statistics for Synonymous Sites
Statistic
Header Tag
Value
No. of singletons
sfs1
7
No. of segregating sites (S)
S
17
Average pairwise diversity (π)
pi
3.06
Waterson’s theta
theta
4.55
Tajima’s D
taj D
−1.17
These summary statistics should then be stored in the ﬁle popgen.obs for
later usage as follows:
Observed ﬁle popgen.obs.
sfs1 S pi thita taj_D
7 17 3.06 4.55 -1.17
The ﬁrst step always consists of deﬁning the model parameters in the est ﬁle.
For the model concerned here, we will use the ﬁle popgen.est provided in the
following.
Rules ﬁle popgen.est.
[PARAMETERS]
0 LOG10_N_CUR unif 2 6 output
0 LOG10_OMEGA unif -3 3 output
0 TAU unif 0 1 output
0 MUTRATE fixed 2.5e-8 hide
[COMPLEX PARAMETERS]
1 N_CUR = pow10(LOG10_N_CUR) hide
1 T1 = TAU * 2 * N_CUR hide
0 OMEGA = pow10(LOG10_OMEGA) hide
As can be seen from this ﬁle, we decided to put uniform priors on the logarithm
of the current population size NCUR and the relative size of the ancestral pop-
ulation ω = NANC
NCUR , but a uniform prior on the relative age of the population
size change τ.
To generate simulations under this model, we will make use of the program
fastsimcoal2
(v.2.5.2.21 downloaded from http://cmpg.unibe.ch/software
/fastsimcoal2/) that allows to simulate SFSs under various demographic sce-
narios (Excoﬃer et al., 2013) . However, fastsimcoal2 requires the param-
eters to be speciﬁed diﬀerently from our priors, and we thus make use of

A Guide to General-Purpose ABC Software
405
the [COMPLEX PARAMETERS] section to transform our model parameters ap-
propriately. Speciﬁcally, we have to provide NCUR and the population size
change on the natural scale and further the age of the population size changes
in generations. We then prepare the input ﬁle popgen.par for fastsimcoal2
that speciﬁes this model, using the parameter tags deﬁned in the input ﬁle.
While explaining the details of how to use fastsimcoal2 for such a model is
beyond the scope of this chapter, we provide the corresponding input ﬁle in
the Appendix and refer the reader to the manual of fastsimcoal2 for more
details. To calculate summary statistics from the simulated data, we will use
the custom perl script calcPopstats.pl also provided in the Appendix to
this chapter.
In order to use a PLS transformation during the MCMC chain, we ﬁrst
generated an initial set of 1000 simulations using ABCtoolbox using the fol-
lowing input ﬁle:
ABCtoolbox input ﬁle to perform simulations with fastsimcoal2.
task simulate
obsName popgen.obs
estName popgen.est
numSims 1000
outName popgen_PLS
simInputName popgen.par
simProgram ./fsc25221
simArgs -i popgen-temp.par -s 0 -d -n 1 -q -x
sumStatProgram calcPopstats.pl
sumStatArgs popgen-temp/popgen-temp_DAFpop0.obs
doBoosting
We specify how ABCtoolbox is interacting with fastsimcoal2 (executable
fsc25221) with arguments simProgram and simArgs. We further spec-
ify our custom perl script calcPopstats.pl with argument sumStatProgram,
which calculates summary statistics from the output of fastsimcoal2. While
we refer the reader to the manual of fastsimcoal2 for the details on the
command line used, we note that the output written by fastsimcoal2 will
be located in a sub-directory (popgen-temp) and have a speciﬁc name
(popgen-temp DAFpop0.obs). We thus provide the path to this ﬁle to our perl
script calcPopstats.pl via command line arguments (using sumStatArgs).
In contrast to previously discussed input ﬁles, we also added the additional
argument doBoosting, which will tell ABCtoolbox to also add all squares and
pair-wise products of calculated summary statistics as additional summary
statistics. This often proves helpful in exploiting non-linear relationships be-
tween parameters and statistics when ﬁnding linear combinations.
PLS components are then readily identiﬁed by following the steps discussed
in Section 13.4.3.1. By looking at the Root-Mean-Squared Error (RMSE) plot
(Figure 13.7a), we found that 4 PLS components are suﬃcient to capture
the information contained in the total of 20 summary statistics (including the
boosted ones). Having the appropriate PLS deﬁnition ﬁle PLSdef popgen.txt

406
Handbook of Approximate Bayesian Computation
2
0
0.5
0.6
0.7
RMSEP
0.8
0.9
1.0
5
10
No. of components
15
20
0.0
0.5
Density
1.0
1.5
3
4
log10 (NCUR)
log10 (NCUR)
log10 (ω)
τ
5
6
log10 (ω)
0.0
−3
−2
−1
0
1
2
3
0.2
0.4
0.3
0.6
0.2
0.5
0.8
0.9
0.7
0.4
τ
0.6
0.8
1.0
FIGURE 13.7
Root mean squared error of prediction (RMSEP) as a function of the number
of components used for each parameter (top left), marginal posterior estimate
for parameter log10(NCUR) (top right) and joint posterior for τ and log10(ω)
(bottom). Solid contour lines specify highest posterior density intervals.
at hand, we can then set up ABCtoolbox to run an ABC-MCMC chain using
the following input ﬁle:
ABCtoolbox input ﬁle to perform ABC-MCMC with fastsimcoal2 and PLS-
transformed statistics.
task simulate
samplerType MCMC
obsName popgen.obs
estName popgen.est
numSims 10000
outName popgen_MCMC
simInputName popgen.par
simProgram ./fsc25221
simArgs -i popgen-temp.par -s 0 -d -n 1 -q -x
sumStatProgram calcPopstats.pl

A Guide to General-Purpose ABC Software
407
sumStatArgs popgen-temp/popgen-temp_DAFpop0.obs
doBoosting
numCaliSims 1000
thresholdProp 0.1
rangeProp 1
linearCombName PLSdef_popgen.txt
doBoxCox
This input ﬁle diﬀers from the previous one in that the argument samplerType
was added to instruct ABCtoolbox to run an ABC-MCMC chain, and in that
the arguments required for the calibration step (numCaliSims, thresholdProp
and rangeProp), and those to use linear combinations of summary statistics
(linearCombName and doBoxCox) were added. Note that the R-script ﬁnd-
PLS.r to ﬁnd linear combinations provided by ABCtoolbox performs a Box-
Cox transformation on the summary statistics, and, hence, in order to use the
generated PLS deﬁnition ﬁle, ABCtoolbox needs to perform a similar transfor-
mation ﬁrst, which is requested with the argument doBoxCox. If the user does
not wish to perform a PLS transformation and simply use the raw statistics
for inference then they can omit arguments linearCombName and doBoxCox
from the input ﬁle.
While the output of the ABC-MCMC run (popgen MCMC sampling1.txt)
already corresponds to samples taken from the posterior distribution P(∥S −
Sobs∥< ϵ|NCUR, ω, τ), an additional improvement may be achieved by con-
ducting an ABC-GLM estimation with an additional rejection step that will
further reduce the threshold ϵ and, hence, the accuracy of the posterior. Such
an analysis can be conducted as described in Section 13.3.2, and the resulting
posteriors may then be plotted in R.
The posterior estimates we obtained for parameters NCUR, ω, and τ
(Figure 13.7b and c) indicated a large population expansion that happened
∼13,000 generations ago to a present eﬀective population size of ∼32,000. The
credible intervals of the posterior estimates for ω and especially τ are large
(Figure 13.7c) due to the small size of the downsampled dataset. Addition-
ally, the statistics used here seem not to be informative for parameter τ as
indicated by the PLS analysis in Figure 13.7a. However, the more precise es-
timates for NCUR and ω are in good agreement with the ﬁndings of Boyko
et al. (2008), who used a maximum likelihood method on the full data.
Appendix
Here, we provide additional ﬁles required to replicate our population genetics
example. First, we provide the input ﬁle popgen.par for fastsimcoal2 speci-
fying the population genetics model used. Note that we decided to simulate
the SFS using ten independent loci with 1000 sites each.

408
Handbook of Approximate Bayesian Computation
fastsimcoal input ﬁle.
//Number of population samples (demes)
1
//Population effective sizes (number of genes)
N_CUR
//Sample sizes
24
//Growth rates negative growth implies population expansion
0
//Number of migration matrices : 0 implies no migration between demes
0
//historical event: time, source, sink, migrants, new size, new growth rate
,migr.matrix
1 historical events
T1 0 0 1 OMEGA 0 0
//Number of independent loci [chromosome]
10 0
//Per chromosome: Number of linkage blocks
1
//per Block: data type, num loci, rec. rate and mut rate
DNA 1000 0.00000 MUTRATE 0.33
Further, we provide the custom perl script calcPopstats.pl used to calculate
summary statistics from site frequency spectra simulated with the program
fastsimcoal2.
Perl script to calculate statistics from SFS.
#!/usr/bin/perl -w
use strict;
#read fastsimcoal output SFS file
my $sfsfile=$ARGV[0];
open(FILE,"<",$sfsfile) or die "can’t open SFS file";
open (OUT, ">","summary_stats-temp.txt") or die "can’t open sum-stats file"
;
my ($firstline,$header,$sfsline)=(<FILE>,<FILE>,<FILE>);
#split sfsline into sfs
my @SFS=split /\t/,$sfsline;
my @stats;
#calculate stats
my ($sum,$S,$a1,$a2,$taj_D)=(0,0,0,0,0);
my $n=@SFS-2;
my ($b1,$b2)=(($n+1)/(3*($n-1)),2*($n**2+$n+3)/(9*$n*($n-1)));
#No. Segregating. sites S
for (my $i=1;$i<$n;$i++){
$sum=$sum+$i*($n-$i)*$SFS[$i];
$S=$S+$SFS[$i];
($a1,$a2)=($a1+1/$i,$a2+1/$i**2);
}
#Thita and pi
my ($thita,$pi)=($S/$a1,2*$sum/($n*($n-1)));
#Tajima’s D
my ($c1,$c2)=($b1-1/$a1,$b2-($n+2)/($a1*$n)+$a2/($a1**2));
my ($e1,$e2)=($c1/$a1,$c2/($a1**2+$a2));

A Guide to General-Purpose ABC Software
409
if($S>0) {$taj_D=($pi-$S/$a1)/sqrt($e1*$S+$e2*$S*($S-1));}
#print out stats
@stats=($SFS[1],$S,$pi,$thita,$taj_D);
print OUT join("\t","sfs1","S","pi","thita","taj_D"),"\n",join("\t",@stats,
"\n");
close(FILE);close(OUT);system("rm $sfsfile");
Finally, we provide the ﬁle PLSdef popgen.txt specifying the PLS transfor-
mation of the 20 statistics (7 polymorphism statistics + their products) to four
components. The ﬁrst six columns in the ﬁle specify the boxcox transformation
of the statistic, and the remaining 4 columns specify the PLS components.
The ﬁle PLSdef popgen.txt containing the deﬁnitions of the PLS transforma-
tions for ABCtoolbox.
sfs1 1140 0 -17.58 1.06 0.06 0.07 0.22 0.27 -0.16 0.23
S 4478 0 -10.3 1.12 0.12 0.13 0.25 0.1 -0.3 0.11
pi 1730.18 0 -11.52 1.1 0.09 0.11 0.26 0.05 -0.27 0.07
thita 1199.16 0 -10.3 1.12 0.12 0.13 0.25 0.1 -0.3 0.11
taj_D 2.87 -2.19 0.61 1.48 0.51 0.19 0.11 -0.38 -0.53 -0.5
sfs1_X_sfs1 1299600 0 -20 1.02 0.01 0.02 0.21 0.29 0.13 -0.14
sfs1_X_S 5104920 0 -20 1.03 0.01 0.03 0.25 0.16 0.18 -0.12
sfs1_X_pi 1426520 0 -20 1.03 0.02 0.03 0.25 0.12 0.19 -0.11
sfs1_X_thita 1367040 0 -20 1.03 0.01 0.03 0.25 0.16 0.18 -0.12
sfs1_X_taj_D 634.38 -559.99 -0.61 1.48 0.66 0.09 0.15 -0.36 0.45 -0.01
S_X_S 20052500 0 -18.79 1.06 0.04 0.06 0.26 0.03 0.06 -0.08
S_X_pi 7455340 0 -20 1.06 0.03 0.05 0.26 -0.02 0.08 -0.07
S_X_thita 5369820 0 -18.79 1.06 0.04 0.06 0.26 0.03 0.06 -0.08
S_X_taj_D 8737.33 -1796.63 -9.09 1.21 0.61 0.06 0.18 -0.4 0.16 0.14
pi_X_pi 2993510 0 -20 1.05 0.02 0.04 0.26 -0.07 0.12 -0.05
pi_X_thita 1996450 0 -20 1.06 0.03 0.05 0.26 -0.02 0.08 -0.07
pi_X_taj_D 3508.27 -349.33 -13.94 1.14 0.35 0.05 0.18 -0.39 0.07 0.16
thita_X_thita 1437980 0 -18.79 1.06 0.04 0.06 0.26 0.03 0.06 -0.08
thita_X_taj_D 2339.76 -481.12 -9.09 1.21 0.61 0.06 0.18 -0.4 0.16 0.14
taj_D_X_taj_D 8.21 0 -6.67 1.12 0.13 0.12 0.06 -0.25 -0.3 0.78
References
Adrion, J. R., A. Kousathanas, M. Pascual, H. J. Burrack, N. M. Haddad,
A. O. Bergland, H. Machado et al. Drosophila suzukii: The genetic foot-
print of a recent, worldwide invasion. Molecular Biology and Evolution,
31(12):3148–3163, 2014. doi:10.1093/molbev/msu246.
Aeschbacher, S., M. A. Beaumont, and A. Futschik. A novel approach
for choosing summary statistics in approximate Bayesian computation.
Genetics, 192:1027–1047, 2012. doi:10.1534/genetics.112.143164.

410
Handbook of Approximate Bayesian Computation
Barthelm´e, S. and N. Chopin. ABC-EP: Expectation propagation for
likelihood-free Bayesian computation. In Proceedings of the 28th Interna-
tional Conference on Machine Learning, Bellevue, WA, 2011.
Beaumont, M. A. Joint determination of topology, divergence time, and im-
migration in population trees. In S. Matsumura, P. Forster, and C. Renfrew
(Eds.) Simulation, Genetics and Human Prehistory. McDonald Institute for
Archaeological Research, Cambridge, UK, 2008.
Beaumont, M. A., J.-M. Cornuet, J.-M. Marin, and C. P. Robert. Adap-
tive approximate Bayesian computation. Biometrika, 96(4):983–990, 2009.
doi:10.1093/biomet/asp052.
Beaumont, M. A., W. Zhang, and D. J. Balding. Approximate Bayesian com-
putation in population genetics. Genetics, 162:2025–2035, 2002.
Blum, M. G. B. and O. Fran¸cois. Non-linear regression models for approxi-
mate Bayesian computation. Statistics and Computing, 20(1):63–73, 2010.
doi:10.1007/s11222-009-9116-0.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson. A comparative
review of dimension reduction methods in approximate Bayesian computa-
tion. Statistical Science, 28(2):189–208, 2013. doi:10.1214/12-STS406.
Boyko, A. R., S. H. Williamson, A. R. Indap, J. D. Degenhardt, R. D.
Hernandez, K. E. Lohmueller, M. D. Adams et al. Assessing the evolution-
ary impact of amino acid mutations in the human genome. PLoS Genetics,
4(5):e1000083, 2008. doi:10.1371/journal.pgen.1000083.
Bray, T. C., V. C. Sousa, B. Parreira, M. W. Bruford, and L. Chikhi. 2BAD:
An application to estimate the parental contributions during two indepen-
dent admixture events. Molecular Ecology Resources, 10(3):538–541, 2010.
Chu, J. H., D. Wegmann, C. F. Yeh, R. C. Lin, X. J. Yang, F. M. Lei, C. T.
Yao, F. S. Zou, and S. H. Li. Inferring the geographic mode of speciation
by contrasting autosomal and sex-linked genetic diversity. Molecular biology
and evolution, 30(11):2519–2530, 2013. doi:10.1093/molbev/mst140.
Cornuet, J. M., F. Santos, M. A. Beaumont, C. P. Robert, J. M. Marin, D. J.
Balding, T. Guillemaud, and A. Estoup. Inferring population history with
DIY ABC: A user-friendly approach to approximate Bayesian computation.
Bioinformatics, 24(23):2713–2719, 2008.
Csill´ery, K., O. Fran¸cois, and M. G. B. Blum. abc: An R package for approx-
imate Bayesian computation (ABC). Methods in Ecology and Evolution,
3:475–479, 2012.

A Guide to General-Purpose ABC Software
411
Cuesta-Albertos, J. A. and A. Nieto-Reyes. The random tukey depth.
Computational
Statistics
&
Data
Analysis,
52(11):4979–4988,
2008.
doi:10.1016/j.csda.2008.04.021.
Didelot, X., R. G. Everitt, A. M. Johansen, and D. J. Lawson. Likelihood-
free estimation of model evidence. Bayesian Analysis, 6(1):49–76, 2011.
doi:10.1214/11-BA602.
Estoup, A., E. Lombaert, J. M. Marin, T. Guillemaud, P. Pudlo, C. P.
Robert, and J. M. Cornuet. Estimation of demo-genetic model probabil-
ities with Approximate Bayesian Computation using linear discriminant
analysis on summary statistics. Molecular Ecology Resources, 12(5):846–55,
2012. doi:10.1111/j.1755-0998.2012.03153.x.
Excoﬃer, L., I. Dupanloup, E. Huerta-S´anchez, V. C. Sousa, and M. Foll.
Robust demographic inference from genomic and SNP data. PLoS Genetics,
9(10):e1003905, 2013. doi:10.1371/journal.pgen.1003905.
Fagundes, N. J. R., N. Ray, M. A. Beaumont, S. Neuenschwander, F. M.
Salzano, S. L. Bonatto, and L. Excoﬃer. Statistical evaluation of alterna-
tive models of human evolution. Proceedings of the National Academy of
Sciences of the United States of America, 104(45):17614–17619, 2007.
Fearnhead,
P.
and
D.
Prangle.
Constructing
summary
statistics
for
approximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 74(3):419–474, 2012. doi:10.1111/j.1467-9868.2011.01010.x.
Foll, M., M. A. Beaumont, and O. Gaggiotti. An approximate Bayesian
computation approach to overcome biases that arise when using ampli-
ﬁed fragment length polymorphism markers to study population structure.
Genetics, 179:927–939, 2008.
Fran¸cois, O. and G. Laval. Deviance information criteria for model selection
in approximate Bayesian computation. Statistical Applications in Genetics
and Molecular Biology, 10(1):1–25, 2011.
Gutenkunst, R. N., R. D. Hernandez, S. H. Williamson, and C. D. Bustamante.
Inferring the joint demographic history of multiple populations from mul-
tidimensional SNP frequency data. PLoS Genetics, 5(10):e1000695, 2009.
doi:10.1371/journal.pgen.1000695.
Hickerson, M. J., E. Stahl, and N. Takebayashi. msBayes: Pipeline for test-
ing comparative phylogeographic histories using hierarchical approximate
Bayesian computation. BMC Bioinformatics, 8:268, 2007.

412
Handbook of Approximate Bayesian Computation
Jabot, F., T. Faure, and N. Dumoulin. EasyABC: Performing eﬃcient approx-
imate Bayesian computation sampling schemes using r. Methods in Ecology
and Evolution, 4(7):684–687, 2013. doi:10.1111/2041-210X.12050.
Kousathanas,
A.,
C.
Leuenberger,
J.
Helfer,
M.
Quinodoz,
M.
Foll,
and D. Wegmann. Likelihood-free inference in high-dimensional models.
Genetics, 203(2):893–904, 2016. doi:10.1534/genetics.116.187567.
Leuenberger, C. and D. Wegmann. Bayesian computation and model se-
lection without likelihoods. Genetics, 184(1):243–252, 2010. doi:10.1534/
genetics.109.109058.
Liepe, J., C. Barnes, E. Cule, K. Erguler, P. Kirk, T. Toni, and M. P. H.
Stumpf. ABC-SysBio – approximate Bayesian computation in Python with
GPU support. Bioinformatics, 26(14):1797–1799, 2010.
Lopes, J. S., D. Balding, and M. A. Beaumont. PopABC: A program to in-
fer historical demographic parameters. Bioinformatics, 25(20):2747–2749,
2009.
Marjoram, P., J. Molitor, V. Plagnol, and S. Tavar´e. Markov chain Monte
Carlo without likelihoods. Proceedings of the National Academy of Sciences,
100(26):15324–15328, 2003. doi:10.1073/pnas.0306899100.
Pavlidis, P., S. Laurent, and W. Stephan. msABC: A modiﬁcation of Hudson’s
ms to facilitate multi-locus ABC analysis. Molecular Ecology Resources,
10(4):723–727, 2010.
Peter, B. M., D. Wegmann, and L. Excoﬃer. Distinguishing between popu-
lation bottleneck and population subdivision by a Bayesian model choice
procedure. Molecular Ecology, 19(21):4648–60, 2010. doi:10.1111/j.1365-
294X.2010.04783.x.
Picchini, U. Inference for SDE models via approximate Bayesian computation.
Journal of Computational and Graphical Statistics, 23(4):1080–1100, 2014.
Prangle, D., M. G. B. Blum, G. Popovic, and S. A. Sisson. Diagnostic
tools for approximate Bayesian computation using the coverage property.
Australian and New Zealand Journal of Statistics, 56(4):309–329, 2014.
doi:10.1111/anzs.12087.
Pritchard, J. K., M. T. Seielstad, A. Perez-Lezaun, and M. W. Feldman. Pop-
ulation growth of human Y chromosome: A study of Y chromosome mi-
crosatellites. Molecular Biology and Evolution, 16(12):1791–1798, 1999.
Robert, C. P., J. M. Cornuet, J. M. Marin, and N. S. Pillai. Lack of
conﬁdence in approximate Bayesian computation model choice. Proceed-
ings of the National Academy of Sciences, 108(37):15112–15117, 2011.
doi:10.1073/pnas.1102900108.

A Guide to General-Purpose ABC Software
413
Sisson, S. A., Y. Fan, and M. M. Tanaka. Sequential Monte Carlo without
likelihoods. Proceedings of the National Academy of Sciences of the United
States of America, 104(6):1760–1765, 2007. doi:10.1073/pnas.0607208104.
Tallmon, D. A., A. Koyuk, G. Luikart, and M. A. Beaumont. ONeSAMP: A
program to estimate eﬀective population size using approximate Bayesian
computation. Molecular Ecology Resources, 8:299–301, 2008.
Tavar´e, S., D. J. Balding, R. C. Griﬃths, and P. Donnelly. Inferring coalescence
times from DNA sequence data. Genetics, 145:505–518, 1997.
Tenenhaus, M., J. P. Gauchi, and C. M´enardo. R´egression PLS et applications.
Revue de Statistique Appliqu´ee, 43(1):7–64, 1995.
Thornton, K. R. Automating approximate Bayesian computation by local lin-
ear regression. BMC Genetics, 10:35, 2009.
Wegmann, D., C. Leuenberger, and L. Excoﬃer. Eﬃcient approximate
Bayesian computation coupled with Markov chain Monte Carlo without like-
lihood. Genetics, 182(4):1207–1218, 2009. doi:10.1534/genetics.109.102509.
Wegmann, D., C. Leuenberger, S. Neuenschwander, and L. Excoﬃer. ABC-
toolbox: A versatile toolkit for approximate Bayesian computations. BMC
Bioinformatics, 11(1):116, 2010. doi:10.1186/1471-2105-11-116.


14
Divide and Conquer in ABC:
Expectation-Propagation Algorithms
for Likelihood-Free Inference
Simon Barthelm´e, Nicolas Chopin, and Vincent Cottet
CONTENTS
14.1
Introduction ......................................................
416
14.2
Expectation-Propagation Algorithms ............................
417
14.2.1
General presentation ....................................
417
14.2.2
Properties of exponential families .......................
418
14.2.3
Site update ..............................................
419
14.2.4
Gaussian sites ...........................................
420
14.2.5
Order of site updates: Sequential EP, parallel EP, and
block-parallel EP .......................................
420
14.2.6
Other practical considerations ..........................
423
14.2.7
Theoretical properties of expectation propagation ......
423
14.3
Applying Expectation Propagation in ABC .....................
424
14.3.1
Principle .................................................
424
14.3.2
Practical considerations .................................
426
14.3.3
Speeding up parallel expectation propagation-ABC
in the iid case ...........................................
426
14.4
Application to Spatial Extremes .................................
428
14.4.1
Background ..............................................
428
14.4.2
Summary statistics ......................................
429
14.4.3
Numerical results on real data ..........................
429
14.4.4
Expectation-propagation convergence ...................
431
14.5
Conclusion ........................................................
431
Acknowledgements .......................................................
432
References
...............................................................
432
415

416
Handbook of Approximate Bayesian Computation
14.1
Introduction
A standard ABC algorithm samples in some way from the pseudo-posterior:
pstd
ϵ
(θ|y∗) ∝p(θ)

p(y|θ)I{∥s(y)−s(y⋆)∥≤ϵ} dy,
(14.1)
where p(y|θ) denotes the likelihood of data y ∈Y given parameter θ ∈
Θ, y∗is the actual data, s is some function of the data called a ‘summary
statistic’, and ϵ > 0. As discussed elsewhere in this book, there are various
ways to sample from (14.1), for example, rejection, Markov Chain Monte Carlo
(MCMC) (Marjoram et al., 2003), Sequential Monte Carlo (SMC) (Sisson
et al., 2007; Beaumont et al., 2009; Del Moral et al., 2012), and so on, but
they all require simulating a large number of complete datasets yj from the
likelihood p(y|θ), for diﬀerent values of θ. This is typically the bottleneck of
the computation. Another drawback of standard ABC is the dependence on s:
as ϵ →0, pstd
ϵ
(θ|y∗) →p(θ|s(y⋆)) ̸= p(θ|y⋆), the true posterior distribution,
and there is no easy way to choose s such that p(θ|s(y⋆)) ≈p(θ|y⋆).
In this paper, we assume that the data may be decomposed into n ‘chunks’,
y = (y1, . . . , yn), and that the likelihood may be factorised accordingly:
p(y|θ) =
n

i=1
fi(yi|θ),
in such a way that it is possible to sample pseudo-data yi from each factor
fi(yi|θ). The objective is to approximate the pseudo-posterior:
pϵ(θ|y⋆) ∝p(θ)
n

i=1

fi(yi|θ)I{∥si(yi)−si(y⋆
i )∥≤ϵ} dyi

,
where si is a ‘local’ summary statistic, which depends only on yi. We expect
the bias introduced by the n local summary statistics si to be much smaller
than the bias introduced by the global summary statistic s. In fact, there are
practical cases where we may take si(yi) = yi, removing this bias entirely.
Note that we do not restrict to models such that the chunks yi are in-
dependent. In other words, we allow each factor fi to implicitly depend
on other data-points. For instance, we could have a Markov model, with
fi(yi|θ) = p(yi|yi−1, θ), or even a model with a more complicated dependence
structure, say fi(yi|θ) = p(yi|y1:i−1, θ). The main requirement, however, is
that we are able to sample from each factor fi(yi|θ). For instance, in the
Markov case, this means we are able to sample from the model realisations of
variable yi, conditional on yi−1 = y⋆
i−1 and θ.
Alternatively, in cases where the likelihood does not admit a simple factori-
sation, one may replace it by some factorisable pseudo-likelihood; for example,
a marginal composite likelihood:
pMCL(y|θ) =
n

i=1
p(yi|θ),

Divide and Conquer in ABC
417
where p(yi|θ) is the marginal density of variable yi. Then one would take
fi(yi|θ) = p(yi|θ) (assuming we are able to simulate from the marginal distri-
bution of yi). Conditional distributions may be used as well; see Varin et al.
(2011) for a review of composite likelihoods. Of course, replacing the likelihood
by some factorisable pseudo-likelihood adds an extra level of approximation,
and one must determine in practice whether the computational beneﬁts are
worth the extra cost. Estimation based on composite likelihoods is generally
consistent, but their use in a Bayesian setting results in posterior distribu-
tions that are overconﬁdent (the variance is too small, as dependent data are
eﬀectively treated as independent observations).
Many authors have taken advantage of factorisations to speed up ABC.
ABC strategies for hidden Markov models are discussed in Dean et al. (2014)
and Yıldırım et al. (2014); see the review of Jasra (2015). White et al.
(2015) describe a method based on averages of pseudo-posteriors, which in
the Gaussian case reduces to just doing one pass of parallel EP. Ruli et al.
(2016) use composite likelihoods to deﬁne low-dimensional summary statistics.
We focus on expectation-propagation (EP, Minka, 2001), a widely success-
ful algorithm for variational inference. In Barthelm´e and Chopin (2014), we
showed how to adapt EP to a likelihood-free setting. Here, we extend this
work with a focus on a parallel variant of EP (Cseke and Heskes, 2011) that
enables massive parallelisation of ABC inference. For textbook descriptions of
EP, see for example, Section 10.7 of Bishop (2006) or Section 13.8 of Gelman
et al. (2014).
The chapter is organised as follows. Section 14.2 gives a general presenta-
tion of both sequential and parallel EP algorithms. Section 14.3 explains how
to adapt these EP algorithms to ABC contexts. It discusses in particular some
ways to speed up EP-ABC. Section 14.4 discusses how to apply EP-ABC to
spatial extreme models. Section 14.5 concludes.
We use the following notations throughout: bold symbols refer to vectors
or matrices, for example, θ, λ, Σ. For data-points, we use (bold) y to denote
complete datasets and yi to denote data ‘chunks’, although we do not neces-
sarily assume the yi’s to be scalars. The letter p typically refers to probability
densities relative to the model: p(θ) is the prior, p(y1|θ) is the likelihood of
the ﬁrst data chunk, and so on. The transpose of matrix A is denoted At.
14.2
Expectation-Propagation Algorithms
14.2.1
General presentation
Consider a posterior distribution π(θ) that may be decomposed into (n + 1)
factors:
π(θ) ∝
n

i=0
li(θ),

418
Handbook of Approximate Bayesian Computation
where, say, l0(θ) is the prior, and l1, . . . , ln are n contributions to the likeli-
hood. EP (Minka, 2001) approximates π by a similar decomposition:
q(θ) ∝
n

i=0
qi(θ),
where each ‘site’ qi is updated in turn, conditional on the other factors, in a
spirit close to a coordinate-descent algorithm.
To simplify this rather general framework, one often assumes that the qi
belong to some exponential family of distributions Q (Seeger, 2005):
qi(θ) = exp

λt
it (θ) −φ (λi)

,
where λi ∈Rd is the natural parameter, t (θ) is some function Θ →Rd, and
φ is known variously as the log-partition function or the cumulant function:
φ(λ) = log
	
exp {λtt (θ)} dθ

. Working with exponential families is conve-
nient for a number of reasons. In particular, the global approximation q is
automatically in the same family, and with parameter λ = n
i=0 λi:
q(θ) ∝exp
⎧
⎨
⎩
 n

i=0
λi
t
t(θ)
⎫
⎬
⎭.
The next section gives additional properties of exponential families upon which
EP relies. Then Section 14.2.3 explains how to perform a site update, that is,
how to update λi, conditional on the λj, j ̸= i, so as, informally, to make q
progressively closer and closer to π.
14.2.2
Properties of exponential families
Let KL(π||q) be the Kullback–Leibler divergence of q from π:
KL(π||q) =

π(θ) log π(θ)
q(θ) dθ.
For a generic member qλ(θ) = exp {λtt(θ) −φ(λ)} of our exponential
family Q, we have:
d
dλKL(π||qλ) = d
dλφ (λ) −

π(θ)t(θ) dθ,
(14.2)
where the derivative of the partition function may be obtained as:
d
dλφ (λ) =

t(θ) exp

λtt (θ) −φ(λ)

dθ = Eλ {t(θ)} .
(14.3)
Let η = η(λ) = Eλ {t(θ)}; η is called the moment parameter, and there is a
one-to-one correspondence between λ and η; abusing notations, if η = η(λ),

Divide and Conquer in ABC
419
then λ = λ(η). One may interpret (14.2) as follows: ﬁnding the qλ closest
to π (in the Kullback–Leibler sense) amounts to perform moment matching,
that is, to set λ such that the expectation of t(θ) under π and under qλ match.
To make this discussion more concrete, consider the Gaussian case:
qλ(θ) ∝exp

−1
2θtQθ + rtθ

,
λ =

r, −1
2Q

,
t(θ) =

θ, θθt
,
and the moment parameter is η = (μ, Σ + μμt), with Σ = Q−1, μ = Q−1r.
[More precisely, θtQθ = trace(Qθθt) = vect(Q)tvect(θθt), so the second
component of λ [respectively, t(θ)] should be −(1/2)vect(Q) [respectively
vect(θθ′)]. But, for notational convenience, our derivations will be in terms of
matrices Q and θθ′, rather than their vectorised versions.]
In the Gaussian case, minimising KL(π||qλ) amounts to taking λ,
such that the corresponding moment parameter (μ, Σ + μμt) is such that
μ = Eπ[θ], Σ = Varπ[θ]. We will focus on the Gaussian case in this paper
(i.e. EP computes iteratively a Gaussian approximation of π), but we go on
with the more general description of EP in terms of exponential families, as
this allows for more compact notations, and also because we believe that other
approximations could be useful in the ABC context.
14.2.3
Site update
We now explain how to perform a site update for site i, that is, how to update
given λi, assuming (λj)j̸=i is ﬁxed. Consider the ‘hybrid’ distribution:
h(θ) ∝q(θ) li(θ)
qi(θ) = li(θ)

j̸=i
qj(θ)
= li(θ) exp
⎧
⎨
⎩
⎛
⎝
j̸=i
λj
⎞
⎠
t
t(θ)
⎫
⎬
⎭;
that is, h is obtained by replacing site qi by the true factor li in the global ap-
proximation q. The hybrid can be viewed as a ‘pseudo-posterior’ distribution,
formed of the product of a ‘pseudo-prior’ qi and a single likelihood site li. The
update of site i is performed by minimising KL(h||q) with respect to λi (again,
assuming the other λj, j ̸= i, are ﬁxed). Informally, this may be interpreted
as a local projection (in the Kullback–Leibler sense) of π to Q.
Given the properties of exponential families laid out in the previous section,
one sees that this site update amounts to setting λi so that λ = 
j λj matches
Eh[t(θ)], the expectation of t(θ) with respect to the hybrid distribution. In
addition, one may express the update of λi as a function of the current values
of λi and λ, using the fact that 
j̸=i λj = λ−λi, as done in Algorithm 14.1.
In practice, the feasibility of EP for a given posterior is essentially
determined by the diﬃculty to evaluate, or approximate, the integral (14.4).

420
Handbook of Approximate Bayesian Computation
Algorithm 14.1: Generic Site Update in EP
Function SiteUpdate(i, li, λi, λ):
1. Compute:
λnew := λ (Eh[t(θ)]) ,
λnew
i
:= λnew −λ + λi,
where η →λ(η) is the function that maps the moment parameters
to the natural parameters (for the considered exponential family, see
previous section) and:
Eh [t(θ)] =
	
t(θ)li(θ) exp

(λ −λi)t t(θ)

dθ
	
li(θ) exp

(λ −λi)t t(θ)

dθ
.
(14.4)
2. Return λnew
i
, and optionally λnew (as determined by syntax, i.e.
either λnew
i
←SiteUpdate(i, li, λi, λ), or (λnew
i
, λnew) ←SiteUpdate
(i, li, λi, λ)).
Note the simple interpretation of this quantity: this is the posterior expecta-
tion of t(θ), for pseudo-prior q−i and pseudo-likelihood the likelihood factor
li(θ). (In the EP literature, the pseudo-prior q−i is often called the ‘cavity
distribution’, and the pseudo-posterior ∝q−i(θ)li(θ) the ‘tilted or hybrid dis-
tribution’.)
14.2.4
Gaussian sites
In this paper, we will focus on Gaussian approximations; that is, Q is the set
of Gaussian densities:
qλ(θ) ∝exp

−1
2θtQθ + rtθ

,
λ =

r, −1
2Q

,
and EP computes iteratively a Gaussian approximation of π, obtained as a
product of Gaussian factors. For this particular family, simple calculations
show that the site updates take the form given by Algorithm 14.2.
In words, one must compute the expectation and variance of the
pseudo-posterior obtained by multiplying the Gaussian pseudo-prior q−i and
likelihood li.
14.2.5
Order of site updates: Sequential EP, parallel EP, and
block-parallel EP
We now discuss in which order the site updates may be performed; i.e. should
site updates be performed sequentially, or in parallel, or something in between?

Divide and Conquer in ABC
421
Algorithm 14.2: EP Site Update (Gaussian Case)
Function SiteUpdate(i, li, (ri, Qi) , (r, Q)):
1. Compute:
Zh =

q−i(θ)li(θ) dθ
μh = 1
Zh

θq−i(θ)li(θ) dθ
Σh = 1
Zh

θθtq−i(θ)li(θ) dθ −μhμt
h,
where q−i(θ) is the Gaussian density:
q−i(θ) ∝exp

−1
2θt (Q −Qi) θ + (r −ri)t θ

.
2. Return (rnew
i
, Qnew
i
), and optionally (rnew, Qnew) (according to syntax
as in Algorithm 14.1), where:
(Qnew, rnew) =

Σ−1
h , Σ−1
h μh

,
(Qnew
i
, rnew
i
) = (Qi + Qnew −Q, ri + rnew −r) .
The initial version of EP, as described in Minka (2001), was purely
sequential (and will therefore be referred to as ‘sequential EP’ from now on):
one updates λ0 given the current values of λ1, . . . , λn, then one updates λ1
given λ0 (as modiﬁed in the previous update) and λ2, . . . , λn, and so on;
see Algorithm 14.3. Since the function SiteUpdate (i, li, λi, λ) computes the
updated version of both λi and λ = n
j=0 λj, λ changes at each call of
SiteUpdate.
Algorithm 14.3 is typically run until λ = n
i=0 λi stabilises in some sense.
The main drawback of sequential EP is that, given its sequential nature,
it is not easily amenable to parallel computation. Cseke and Heskes (2011)
Algorithm 14.3: Sequential EP
Require: initial values for λ0, . . . , λn
λ ←n
i=0 λi
repeat
for i = 0 to n do
(λi, λ) ←SiteUpdate (i, li, λi, λ)
end for
until convergence
return λ.

422
Handbook of Approximate Bayesian Computation
proposed a parallel EP algorithm, where all sites are updated in parallel,
independently of each other. This is equivalent to update the sum λ = n
i=0 λi
only after all the sites have been updated; see Algorithm 14.4.
Algorithm 14.4: Parallel EP
Require: initial values for λ0, . . . , λn
λ ←n
i=0 λi
repeat
for i = 0 to n do (parallel)
λi ←SiteUpdate (i, li, λi, λ)
end for
λ ←n
i=0 λi
until convergence
return λ.
Parallel EP is ‘embarrassingly parallel’, since its inner loop performs (n+1)
independent operations. A drawback of parallel EP is that its convergence is
typically slower (i.e. requires more complete passes over all the sites) than
sequential EP. Indeed, during the ﬁrst pass, all the sites are provided with the
same initial global approximation λ, whereas in sequential EP, the ﬁrst site
updates allow to reﬁne progressively λ, which makes the following updates
easier.
We now propose a simple hybrid of these two EP algorithms, which we call
‘block-parallel EP’. We assume we have ncore cores (single processing units)
at our disposal. For each block of ncore successive sites, we update these ncore
sites in parallel, and then update the global approximation λ after these ncore
updates; see Algorithm 14.5.
Algorithm 14.5: Block-Parallel EP
Require: initial values for λ0, . . . , λn
λ ←n
i=0 λi
repeat
for k = 1 to ⌈(n + 1)/ncore⌉do
for i = (k −1)ncore to (kncore −1) ∧n do (parallel)
λi ←SiteUpdate (i, li, λi, λ)
end for
λ ←n
i=0 λi
end for
until convergence
return λ.
Quite clearly, block-parallel EP generalises both sequential EP (take ncore = 1)
and parallel EP (take ncore = n + 1). This generalisation is useful in any situ-
ation where the actual number of cores ncore available in a given architecture

Divide and Conquer in ABC
423
is such that ncore ≪(n + 1). In this way, we achieve essentially the same
speed-up as parallel EP in terms of parallelisation (since only ncore cores are
available anyway), but we also progress faster thanks to the sequential nature
of the successive block updates. We shall discuss more speciﬁcally in the next
section the advantage of block-parallel EP over standard parallel EP in an
ABC context.
14.2.6
Other practical considerations
Often, the prior, which was identiﬁed with l0 in our factorisation, already be-
longs to the approximating parametric family: p(θ) = qλ0(θ). In that case, one
may ﬁx beforehand q0(θ) = l0(θ) = p(θ), and update only λ1, . . . , λn in the
course of the algorithm, while keeping λ0 ﬁxed to the value given by the prior.
EP also provides at no extra cost an approximation of the normalising
constant of π: Z =
	
θ
n
i=0 li(θ) dθ. When π is a posterior, this can be used to
approximate the marginal likelihood (evidence) of the model. See, for example,
Barthelm´e and Chopin (2014) for more details.
In certain cases, EP updates are ‘too fast’, in the sense that the up-
date of diﬃcult sites may lead to, for example, degenerate precision matrices
(in the Gaussian case). One well known method to slow down EP is to perform
fractional updates (Minka, 2004); that is, informally, update only a fraction
α ∈(0, 1] of the site parameters; see Algorithm 14.6.
Algorithm 14.6: Generic Site Update in EP (Fractional Version,
Requires α ∈(0, 1])
Function SiteUpdate(i, li, λi, λ):
1. Compute:
λnew := αλ (Eh[t(θ)]) + (1 −α)λ,
λnew
i
:= λi + α {λ (Eh[t(θ)]) −λ}
with Eh[t(θ)] deﬁned in (14.3), see step 1 of 14.1.
2. As Step 2 of Algorithm 14.1.
In practice, reducing α is often the ﬁrst thing to try when EP either diverges
or fails because of non-invertible matrices (in the Gaussian case). Of course,
the price to pay is that with a lower α, EP may require more iterations to
converge.
14.2.7
Theoretical properties of expectation propagation
EP is known to work well in practice, sometimes surprisingly so, but it has
proved quite resilient to theoretical study. In Barthelm´e and Chopin (2014),
we could give no guarantees whatsoever, but since then the situation has

424
Handbook of Approximate Bayesian Computation
improved. The most important question concerns the quality of the approx-
imations produced by EP. Under relatively strong conditions Dehaene and
Barthelm´e (2018) were able to show that Gaussian EP is asymptotically ex-
act in the large-data limit. This means that if the posterior tends to a Gaussian
(which usually happens in identiﬁable models), then EP will recover the exact
posterior. Dehaene and Barthelm (2015) show further that EP recovers the
mean of the posterior with an error that vanishes in O(n−2), where n is the
number of data-points. The error is up to an order of magnitude lower than
what one can expect from the canonical Gaussian approximation, which uses
the mode of the posterior as an approximation to the mean.
However, in order to have an EP approximation, one needs to ﬁnd one in
the ﬁrst place. The various ﬂavours of EP (including the ones described here)
are all relatively complex ﬁxed-point iterations, and their convergence is hard
to study. Dehaene and Barthelm´e (2018) show that parallel EP converges in
the large-data limit to a Newton iteration and inherits the potential instabil-
ities in Newton’s method. Just like Newton’s method, non-convergence in EP
can be ﬁxed by slowing down the iterations, as described earlier.
The general picture is that EP should work very well if the hybrids are
well-behaved (log-concave, roughly). Like any Gaussian approximation, it can
be arbitrarily poor when used on multi-modal posterior distributions, unless
the modes are all equivalent.
Note ﬁnally that the earlier results apply to variants of EP where hybrid
distributions are tractable (meaning their moments can be computed exactly).
In ABC applications that is not the case, and we will incur additional Monte
Carlo error. As we will explain, part of the trick in using EP in ABC settings
is ﬁnding ways of minimising that additional source of errors.
14.3
Applying Expectation Propagation in ABC
14.3.1
Principle
Recall that our objective is to approximate the ABC posterior:
pϵ(θ|y⋆) ∝p(θ)
n

i=1

fi(yi|θ)I{∥si(yi)−si(y⋆
i )∥≤ϵ} dyi

,
for a certain factorisation of the likelihood and for a certain collection of local
summary statistics si. This immediately suggests using EP on the following
collection of sites:
li(θ) =

fi(yi|θ)I{∥si(yi)−si(y⋆
i )∥≤ϵ} dyi,

Divide and Conquer in ABC
425
for i = 1, . . . , n. For convenience, we focus on the Gaussian case (i.e. the li’s
will be approximated by Gaussian factors qi), and assume that the prior p(θ)
itself is already Gaussian, and does not need to be approximated.
From Algorithm 14.2, we see that, in this Gaussian case, it is possible to
perform a site update provided that we are able to compute the mean and
variance of a pseudo-posterior, corresponding to a Gaussian prior q−i, and
likelihood li.
Algorithm 14.7 describes a simple rejection algorithm that may be used
to perform the site update. Using this particular algorithm inside sequential
EP leads to the EP-ABC algorithm derived in Barthelm´e and Chopin (2014).
We stress, however, that one may generally use any ABC approach to per-
form such a site update. The main point is that this local ABC problem is
much simpler than ABC for the complete likelihood for two reasons. First, the
pseudo-prior q−i is typically much more informative than the true prior p(θ),
because q−i approximates the posterior of all the data minus yi. Thus, we are
much less likely to sample values of θ with low likelihood. Second, even for
a ﬁxed θ, the probability that ∥si(yi) −si(y⋆
i )∥≤ϵ is typically much larger
than ∥s(y) −s(y⋆)∥≤ϵ, as si is generally of lower dimension than s.
Algorithm 14.7: Local ABC Algorithm to Perform Site Update
Function SiteUpdate(i, fi, (ri, Qi) , (r, Q)):
1. Simulate θ(1), . . . , θ(M) ∼N(μ−i, Σ−i) where Σ−1
−i = Q −Qi, μ−i =
Σ−i (r −ri).
2. For each m = 1, . . . M, simulate y(m)
i
∼fi(·|θ(m)).
3. Compute
Macc =
M

m=1
I
   si(y(m)
i
) −si(y⋆
i )
   ≤ϵ

ˆμh =
1
Macc
M

m=1
θ(m)I
   si(y(m)
i
) −si(y⋆
i )
   ≤ϵ

ˆΣh =
1
Macc
M

m=1
θ(m) !
θ(m)"t
I
   si(y(m)
i
) −si(y⋆
i )
   ≤ϵ

−ˆμh ˆμt
h.
4. Return (rnew
i
, Qnew
i
), and optionally (rnew, Qnew) (according to syntax
as in Algorithm 14.1), where:
(Qnew, rnew) =
#
ˆΣ−1
h , ˆΣ−1
h ˆμh
$
,
(Qnew
i
, rnew
i
) = (Qi + Qnew −Q, ri + rnew −r) .

426
Handbook of Approximate Bayesian Computation
14.3.2
Practical considerations
We have observed that in many problems the acceptance rate of Algorithm
14.7 may vary signiﬁcantly across sites, so, instead of ﬁxing M, the number
of simulated pairs (θ(m), y(m)
i
), to a given value, we recommend to sample
until the number of accepted pairs (i.e. the number of (θ(m), y(m)
i
), such that
   si(y(m)
i
) −si(y(m)
i
)
   ≤ϵ) equals a certain threshold M0.
Another simple way to improve EP-ABC is to generate the θ(m) us-
ing quasi-Monte Carlo for distribution N(μ−i, Σ−i), we take θm = μ−i +
LΦ−1(um), where Φ−1 is the Rosenblatt transformation (multi-variate quan-
tile function) of the unit normal distribution of dimension dim(θ), LLt = Σ−i
is the Cholesky decomposition of Σ−i, and the u(m) is a low-discrepancy se-
quence, such as the Halton sequence; see, for example, Chapter 5 in Lemieux
(2009) for more background on low-discrepancy sequences and quasi-Monte
Carlo.
Regarding ϵ, our practical experience is that ﬁnding a reasonable value
through trial and error is typically much easier with EP-ABC than with
standard ABC. This is because the yi’s are typically of much lower dimension
than the complete dataset y. However, one more elaborate recipe to calibrate
ϵ is to run EP-ABC with a ﬁrst value of ϵ, then set ϵ to the minimal value such
that the proportion of simulated yi at each site, such that ∥si(yi)−si(y⋆
i )∥≤ϵ
is above, say, 5%. Then one may start over with this new value of ϵ.
Another direction suggested by Mark Beaumont in a personal communica-
tion is to correct the estimated precision matrices for bias, using formula (4)
from Paz and S´anchez (2015).
14.3.3
Speeding up parallel expectation propagation-ABC
in the iid case
This section considers the iid case, for example, the model assumes that the
yi are iid (independent and identically distributed), given θ: then
p(y|θ) =
n

i=1
f1(yi|θ),
where f1 denotes the common density of the yi. In this particular case, each of
the n local ABC posteriors, as described by Algorithm 14.7, will use pseudo-
data from the same distribution (given θ). This suggests recycling these sim-
ulations across sites.
Barthelm´e and Chopin (2014) proposed a recycling strategy based on
sequential importance sampling. Here, we present an even simpler scheme
that may be implemented when parallel EP is used. At the start of itera-
tion t of parallel EP, we sample θ(1), . . . , θ(M) ∼N(μ, Σ), the current global
approximation of the posterior. For each θm, we sample y(m) ∼f1(y|θm).
Then, for each site i, we can compute the ﬁrst two moments of the hybrid

Divide and Conquer in ABC
427
distribution by simply doing an importance sampling step, from N(μ, Σ) to
N(μ−i, Σ−i), which is obtained by dividing the density of N(μ, Σ) by factor
qi. Speciﬁcally, the weight function is:
|Q−i| exp

−1
2θtQ−iθ + rt
−iθ

|Q| exp

−1
2θtQθ + rtθ

= |Q −Qi|
|Q|
exp
1
2θtQiθ −rr
i θ

,
since Q = Qi + Q−i, r = ri + r−i. Note that further savings can be ob-
tained by retaining the samples for several iterations, regenerating only when
the global approximation has changed too much relative to the values used
for sampling. In our implementation, we monitor the drift by computing the
eﬀective sample size of importance sampling from N(μ, Σ) (the distribution
of the current samples) for the new global approximation N(μ′, Σ′).
We summarise the so-obtained algorithm as Algorithm 14.8. Clearly,
recycling allows us for a massive speed-up when the number n of sites is large,
as we re-use the same set of simulated pairs (θ(m), y(m)) for all the n sites. In
turn, this allows us to take a larger value for M, the number of simulations,
which leads to more stable results.
Algorithm 14.8: Parallel EP-ABC with Recycling (iid Case)
Require: M (number of samples), initial values for (ri, Qi)i=0,...,n (note
(r0, Q0) stays constant during the course of the algorithm, as we have
assumed a Gaussian prior with natural parameter (r0, Q0)):
repeat
Q ←n
i=0 Qi, r ←n
i=0 ri, Σ ←Q−1, μ ←Σr
for m = 1, . . . , M do
θ(m) ∼N(μ, Σ)
y(m) ∼f1(y|θ(m))
end for
for i = 1, . . . , n do
for m = 1, . . . , M do
w(m)
←
|Q−Qi|
|Q|
exp
 1
2(θ(m))tQiθ(m) −rt
iθ(m)
I
   si(y(m)
i
) −si(y⋆
i )
   ≤ϵ

end for
ˆZ ←M −1 M
m=1 w(m)
ˆμ ←(M ˆZ)−1 × M
m=1 w(m)θ(m)
ˆΣ ←(M ˆZ)−1 × M
m=1 w(m)θ(m) 
θ(m)
t −ˆμˆμt
ri ←ˆΣ−1 ˆμ −r−i
Qi ←ˆΣ−1 −Q−i
end for
until Stopping rule (e.g. changes in (r, Q) have become small).

428
Handbook of Approximate Bayesian Computation
We have advocated parallel EP in Section 14.2 as a way to paral-
lelise the computations over the n sites. Given the particular structure of
Algorithm 14.8, we see that it is also easy to parallelise the simulation of the
M pairs (θ(m), y(m)) that is performed at the start of each EP iteration; this
part is usually the bottleneck of the computation. In fact, we also observe
that Algorithm 14.8 performs slightly better than the recycling version of
EP-ABC (as described in Barthelm´e and Chopin 2014) even on a non-parallel
architecture.
14.4
Application to Spatial Extremes
We now turn our attention to likelihood-free inference for spatial extremes,
following Erhardt and Smith (2012), see also Prangle (2016).
14.4.1
Background
The data y consist of n iid observations yi, typically observed over time, where
yi ∈Rd represents some maximal measure (e.g. rainfall) collected at d loca-
tions xj (e.g. in R2). The standard modelling approach for extremes is to assign
to yi a max-stable distribution (i.e. a distribution stable by maximisation, in
the same way that Gaussians are stable by addition). In the spatial case, the
vector yi is composed of d observations of a max-stable process x →Y (x)
at the d locations xj. A general approach to deﬁning max-stable processes is
(Schlather, 2002):
Y (x) = max
k
{sk max (0, Zk(x))} ,
(14.5)
where (sk)∞
k=1 is the realisation of a Poisson process over R+ with intensity
Λ(ds) = μ−1s−2ds (if we view the Poisson process as producing a random
set of ‘spikes’ on the positive real line, then s1 is the location of the ﬁrst
spike, s2 the second, etc), (Zk)∞
k=1 is a countable collection of iid realisa-
tions of a zero-mean, unit-variance stationary Gaussian process, with corre-
lation function ρ(h) = Corr(Zk(x), Zk(x′)) for x, x′, such that ∥x −x′∥= h,
and μ = E [max (0, Zk(x))]. Note that Y (x) is marginally distributed accord-
ing to a unit Fr´echet distribution, with Cumulative Density Function (CDF)
F(y) = exp(−1/y).
As in Erhardt and Smith (2012), we will consider the following parametric
Whittle-Mat´ern correlation function:
ρθ(h) = 21−ν
Γ(ν)
h
c
ν
Kν
h
c

,
c, ν > 0,
where Kν is the modiﬁed Bessel function of the third kind. We take θ =
(log ν, log c), so that Θ = R2. (We will return to this logarithmic parametri-
sation later.)

Divide and Conquer in ABC
429
The main issue with spatial extremes is that, unless d ≤2, the likelihood
p(y|θ) is intractable. One approach to estimate θ is pairwise marginal com-
posite likelihood (Padoan et al., 2010). Alternatively, (14.5) suggests a simple
way to simulate from p(y|θ), at least approximately (e.g. by truncating the
domain of the Poisson process to [0, Smax]). This motivates likelihood-free
inference (Erhardt and Smith, 2012).
14.4.2
Summary statistics
One issue, however, with likelihood-free inference for this class of models is
the choice of summary statistics: Erhardt and Smith (2012) compare several
choices and ﬁnd that the one that performs best is some summary of the
clustering of the d(d −1)(d −2)/6 triplet-wise coeﬃcients:
n
n
i=1 {max(yi(xj), yi(xk), yi(xl))}−1 ,
1 ≤j < k < l ≤d.
But computing these coeﬃcients require O(d3) operations, and may actually
be more expensive than simulating the data itself: Prangle (2016) observes
in a particular experiment that the cost of computing these coeﬃcients is
already more than twice the cost of simulating data for d = 20. As a result,
the overall approach of Erhardt and Smith (2012) may take several days to
run on a single-core computer.
In contrast, EP-ABC allows us to deﬁne local summary statistics, si(yi),
that depend only on one data-point yi. We simply take si(yi) to be the
(2-dimensional) OLS (ordinary least squares) estimate of regression:
log |F(yi(xj)) −F(yi(xk))| = a + b log ∥xj −xk∥+ ϵjk,
1 ≤j < k ≤d.
where
F
is
the
unit
Fr´echet
CDF.
The
madogram
function
h
→
E [|Y (x) −Y (x′)|], for ∥x−x′∥= h, or its empirical version, is a common sum-
mary of spatial dependencies (for extremes). Here, we take the F−madogram,
for example, Y (x) is replaced by F(Y (x)) ∼U[0, 1], because Y (x) is Fr´echet
and thus: E [|Y (x)|] = +∞.
14.4.3
Numerical results on real data
We now apply EP-ABC to the rainfall dataset of the SpatialExtremes R pack-
age (available at http://spatialextremes.r-forge.r-project.org/), which records
maximum daily rainfall amounts over the years 1962–2008 occurring during
June–August at 79 sites in Switzerland. We ran sequential EP with recycling
and quasi-Monte Carlo (see discussion in Section 14.3.2). Figure 14.1 plots
the EP-ABC posterior for ϵ = 0.2, 0.05, and 0.02. A N(0, 1) prior was used
for both components of θ = (log ν, log c).
Each run took about 3 hours on our desktop computer and generated
about 105 data-points (i.e. realisations yi ∈Rd, where d is the number of

430
Handbook of Approximate Bayesian Computation
1.4
1.6
1.8
2.0
2.2
2.4
2.6
2.8
0.0
0.5
1.0
1.5
2.0
2.5
Log(c)
Log(ν)
0.02
0.05
0.2
FIGURE 14.1
Fifty percent credible ellipses of the Gaussian approximation of the posterior
computed by EP-ABC for diﬀerent values of ϵ and rainfall dataset.
stations). As a point of comparison, we ran Erhardt and Smith (2012)’s R
package for a week on the same computer, which led to the generation of
5 × 104 complete datasets (i.e. ≈4 × 106 data-points). However, the ABC
posterior approximation obtained from the 100 generated datasets that were
closest to the data, relative to their summary statistics, was not signiﬁcantly
diﬀerent from the prior.
Finally, we discuss the strong posterior correlations between the two pa-
rameters that are apparent in Figure 14.1. Figure 14.2 plots a heat map of
functions (ν, c) →
	
|ρν,c −ρν0,c0| and (log ν, log c) →
	
|ρν,c −ρν0,c0|, for
c
ν
2
4
6
8
10 12 14 16 18 20
2
4
6
8
10
12
14
16
18
20
Log(c)
Log(ν)
0
0.5
1
1.5
2
2.5
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
FIGURE 14.2
Heat map of functions (ν, c) →
	
|ρν,c −ρν0,c0| (left panel) and (log ν, log c) →
	
|ρν,c −ρν0,c0|, for (ν0, c0) = (8, 4) (right panel).

Divide and Conquer in ABC
431
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Log(ν)
Pass
1
2
3
4
5
0
0.5
1
1.5
2
2.5
Log(c)
Pass
FIGURE 14.3
Posterior mean of log ν (left panel) and log c (right panel) as a function of
the number of passes (one pass equals n = 47 site updates) for three runs of
the sequential version (solid grey line) and block-parallel version (ncore = 10,
dashed black line) of EP-ABC applied to rainfall dataset (ϵ = 0.05).
(ν0, c0) = (8, 4). The model appears to be nearly non-identiﬁable, as values
of (ν, c) that are far away may produce correlation functions that are nearly
indistinguishable. In addition, the parametrisation θ = (log ν, log c) has the
advantage of giving an approximately Gaussian shape to contours, which is
clearly helpful in our case given that EP-ABC generates a Gaussian approx-
imation. Still, it is interesting to note that EP-ABC performs well on such a
nearly non-identiﬁable problem.
14.4.4
Expectation-propagation convergence
Finally, we compare the convergence (relative to the number of itera-
tions) of the standard version, and the block-parallel version (described
in Section 14.2.5) of EP-ABC, on the rainfall dataset discussed earlier.
Figure 14.3 plots the evolution of the posterior mean of both parameters ν
(left panel) and c (right panel), relative to the number of site updates, for
three runs of both versions, and for ϵ = 0.05.
We took ncore = 10 (i.e. blocks of ten sites are updated in parallel),
although both algorithms were run on a single core. We see that both algo-
rithms essentially converge at the same rate. Thus, if implemented on a 10-core
machine, the block-parallel version should oﬀer essentially a ×10 speed-up.
14.5
Conclusion
Compared to standard ABC, the main drawback of EP-ABC is that it
introduces an extra level of approximation, because of its EP component.
On the other hand, EP-ABC strongly reduces, or sometimes removes entirely,

432
Handbook of Approximate Bayesian Computation
the bias introduced by summary statistics, as it makes possible to use n local
summaries, instead of just one for the complete dataset. In our experience
[see e.g. the examples in Barthelm´e and Chopin (2014)], this bias reduction
more than compensates the bias introduced by EP. But the main advantage
of EP-ABC is that it is much faster than standard ABC. Speed-ups of more
than 100 are common, as evidenced by our spatial extremes example.
We have developed a MATLAB® package, available at https://sites.
google.com/site/simonbarthelme/software, that implements EP-ABC for sev-
eral models, including spatial extremes. The current version of the package
includes the parallel version described in this paper.
An interesting direction for future work is to integrate current devel-
opments on model emulators into EP-ABC. Model emulators are Machine
Learning (ML) algorithms that seek to learn a tractable approximation of the
likelihood surface from samples (Wilkinson, 2014). A variant directly learns
an approximation of the posterior distribution, as in Gutmann and Corander
(2015). Heess et al. (2013) introduce a more direct way of using emulation
in an EP context. Their approach is to consider each site as a mapping be-
tween the parameters of the pseudo-prior and the mean and covariance of
the hybrid and to learn the parameters of that mapping. In complex, but
low-dimensional, models typical of ABC applications, this viewpoint could be
very useful and deserves to be further explored.
Acknowledgements
We are very grateful to Mark Beaumont, Dennis Prangle, and Markus Hainy
for their careful reading and helpful comments that helped us to improve this
chapter.
The second author is partially supported by ANR (Agence Nationale de
la Recherche) grant ANR-11-IDEX-0003/Labex Ecodec/ANR-11-LABX-0047
as part of Investissements d’Avenir program.
References
Barthelm´e, S. and Chopin, N. (2014). Expectation propagation for likelihood-
free inference. J. Am. Stat. Assoc., 109(505):315–333.
Beaumont, M. A., Cornuet, J.-M., Marin, J.-M., and Robert, C. P. (2009).
Adaptive approximate Bayesian computation. Biometrika, 96(4):983–990.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Information
Science and Statistics. Springer, New York.

Divide and Conquer in ABC
433
Cseke, B. and Heskes, T. (2011). Approximate marginals in latent Gaussian
models. J. Mach. Learn. Res., 12:417–454.
Dean, T. A., Singh, S. S., Jasra, A., and Peters, G. W. (2014). Parameter
estimation for hidden Markov models with intractable likelihoods. Scand.
J. Stat., 41(4):970–987.
Dehaene, G. P. and Barthelm, S. (2015). Bounding errors of expectation-
propagation. In Cortes, C., Lawrence, N. D., Lee, D. D., Sugiyama, M.,
and Garnett, R. (Eds.), Advances in Neural Information Processing Sys-
tems 28: Annual Conference on Neural Information Processing Systems
2015, December 7–12, Montreal, Quebec, Canada, pp. 244–252. Curran As-
sociates, Red Hook, NY.
Dehaene, G. and Simon, B. (2018). Expectation propagation in the large data
limit. J. R. Stat. Soc.: Series B Stat. Methodol., 80(1):199–217.
Del Moral, P., Doucet, A., and Jasra, A. (2012). An adaptive sequential
Monte Carlo method for approximate Bayesian computation. Stat. Com-
put., 22(5):1009–1020.
Erhardt, R. J. and Smith, R. L. (2012). Approximate Bayesian computing for
spatial extremes. Comput. Stat. Data Anal., 56(6):1468–1481.
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin,
D. B. (2014). Bayesian Data Analysis, 3rd ed. Texts in Statistical Science
Series. CRC Press, Boca Raton, FL.
Gutmann, M. U. and Corander, J. (2015). Bayesian optimization for
likelihood-free inference of simulator-based statistical models.
ArXiv
preprint 1501.03291.
Heess, N., Tarlow, D., and Winn, J. (2013). Learning to pass expectation
propagation messages. In Burges, C., Bottou, L., Welling, M., Ghahramani,
Z., and Weinberger, K. (Eds.), Advances in Neural Information Processing
Systems 26, pp. 3219–3227. Curran Associates, Red Hook, NY.
Jasra, A. (2015). Approximate Bayesian computation for a class of time series
models. International Statistical Review, 83:405–435.
Lemieux, C. (2009). Monte Carlo and Quasi-Monte Carlo Sampling (Springer
Series in Statistics). Springer, Berlin, Germany.
Marjoram, P., Molitor, J., Plagnol, V., and Tavar´e, S. (2003). Markov chain
Monte Carlo without likelihoods. Proceedings of the National Academy of
Sciences, 100(26):15324–15328.
Minka, T. (2004). Power EP. Technical report, Department of Statistics,
Carnegie Mellon University, Pittsburgh, PA.

434
Handbook of Approximate Bayesian Computation
Minka, T. P. (2001). Expectation propagation for approximate Bayesian in-
ference. Proceedings of Uncertainty in Artiﬁcial Intelligence, 17:362–369.
Padoan, S. A., Ribatet, M., and Sisson, S. A. (2010). Likelihood-based infer-
ence for max-stable processes. J. Am. Stat. Assoc., 105(489):263–277.
Paz, D. J. and S´anchez, A. G. (2015). Improving the precision matrix for
precision cosmology. Monthly Notices of the Royal Astronomical Society,
454(4):4326–4334.
Prangle, D. (2016). Lazy ABC. Statistics and Computing, 26(1–2), 171–185.
Ruli, E., Sartori, N., and Ventura, L. (2016). Approximate Bayesian com-
putation with composite score functions. Statistics and Computing, 26(3),
679–692.
Schlather, M. (2002). Models for stationary max-stable random ﬁelds.
Extremes, 5(1):33–44.
Seeger, M. (2005). Expectation propagation for exponential families. Technical
report, University of California, Berkeley, CA.
Sisson, S. A., Fan, Y., and Tanaka, M. M. (2007). Sequential Monte
Carlo without likelihoods. Proc. Natl. Acad. Sci. USA, 104(6):1760–1765
(electronic).
Varin, C., Reid, N., and Firth, D. (2011). An overview of composite likelihood
methods. Statist. Sinica, 21(1):5–42.
White, S. R., Kypraios, T., and Preston, S. P. (2015). Piecewise approximate
Bayesian computation: Fast inference for discretely observed Markov models
using a factorised posterior distribution. Stat. Comput., 25(2):289–301.
Wilkinson, R. D. (2014). Accelerating ABC methods using Gaussian processes.
ArXiv preprint 1401.1436.
Yıldırım, S., Singh, S. S., Dean, T., and Jasra, A. (2014). Parameter estima-
tion in hidden Markov models with intractable likelihoods using sequential
Monte Carlo. J. Comput. Graph. Stat., 24(3):846–865.

Part II
Applications


15
Sequential Monte Carlo-ABC Methods
for Estimation of Stochastic Simulation
Models of the Limit Order Book
Gareth W. Peters, Efstathios Panayi, and Francois Septier
CONTENTS
15.1
Introduction to Intractable Likelihood Models for High
Frequency Financial Market Dynamics
.........................
438
15.1.1
Introduction to the limit order book and related
multi-queue simulation models .........................
439
15.1.2
Features of signiﬁcance in limit order book stochastic
processes: Liquidity .....................................
441
15.2
Bayesian Models with Intractable Likelihoods for High
Frequency Financial Market Dynamics
.........................
442
15.2.1
Limit order book agent-based model ....................
443
15.2.1.1
Stochastic agent representation: Liquidity
providers and demanders .....................
445
15.2.2
Bayesian model formulation of the stochastic agent
limit order book model representation .................
451
15.2.2.1
Posterior models for computationally
intractable likelihoods ........................
452
15.2.3
Summary statistics in Bayesian limit order book
models ..................................................
454
15.3
Estimation of Bayesian Limit Order Book Stochastic Agent
Model via Population-Based Samplers ..........................
455
15.3.1
Brief overview of sequential Monte Carlo-based
samplers ................................................
456
15.3.2
Sequential Monte Carlo samplers for intractable
likelihood Bayesian models .............................
458
15.3.2.1
Adaptive schedules: choice of sequence of
ABC distributions via annealed tolerance
schedule .......................................
460
15.3.2.2
Choice of mutation kernel ....................
461
437

438
Handbook of Approximate Bayesian Computation
15.4
Application to Equities Limit Order Book Data: Data
Description .......................................................
464
15.5
Results ...........................................................
465
15.5.1
Estimation algorithm conﬁguration .....................
467
15.5.2
Final particle ﬁtness and distributions
of parameters ...........................................
468
15.5.3
Results comparison to multi-objective evolutionary
algorithm-II procedure
.................................
470
15.6
Conclusion ........................................................
474
References
...............................................................
476
15.1
Introduction to Intractable Likelihood Models for
High Frequency Financial Market Dynamics
In this chapter, we consider classes of models that have been recently
developed for quantitative ﬁnance that involve modelling a highly complex
multi-variate, multi-attribute stochastic process known as the limit order book
(LOB). The LOB is the primary data structure recorded each day intra-daily
for the majority of assets on electronic exchanges around the world in which
trading takes place. As such, it represents one of the most important funda-
mental structures to study from a stochastic process perspective if one wishes
to characterise features of stochastic dynamics for price, volume, liquidity,
and other important attributes for a traded asset. In this paper, we aim to
adopt the model structure recently proposed by Panayi and Peters (2015),
which develops a stochastic model framework for the LOB of a given asset
and to explain how to perform calibration of this stochastic model to real
observed LOB data for a range of diﬀerent assets. One can consider this class
of problems as truly a setting in which both the likelihood is intractable to eval-
uate pointwise, but trivial to simulate, and in addition the amount of data is
massive. This is a true example of big-data application, as for each day and
for each asset one can have anywhere between 100,000–500,000 data vectors
for the calibration of the models.
The class of calibration techniques we will consider here involves an approx-
imate Bayesian computation (ABC) re-formulation of the indirect inference
framework developed under the multi-objective optimisation formulation pro-
posed recently by Panayi and Peters (2015). To facilitate an equivalent com-
parison for the two frameworks, we also adopt a re-formulation of the class
of genetic stochastic search algorithms utilised by Panayi and Peters (2015),
known as NGSA-II (Deb et al., 2002). We adapt this widely utilised stochas-
tic genetic search algorithm from the multi-objective optimisation algorithm
literature to allow it to be utilised as a mutation kernel in a class of sequen-
tial Monte Carlo samplers (SMC sampler) algorithms in the ABC context. We
begin with the problem and model formulation, then we discuss the estimation

SMC-ABC Methods for Estimation of Stochastic Simulation Models
439
frameworks and ﬁnish with some real data simulation results for equity data
from a highly utilised pan-European secondary exchange formerly known as
Chi-X, before it was recently aquired by BATS to form BATS Chi-X Europe
in 2014.∗
15.1.1
Introduction to the limit order book and related
multi-queue simulation models
The structure of a ﬁnancial market dictates the form of interaction between
buyers and sellers. Markets for ﬁnancial securities generally operate either as
quote driven markets, in which specialists (dealers) provide 2-way prices, or
order driven markets, in which participants can trade directly with each other
by expressing their trading interest through a central matching mechanism.
The LOB is an example of the latter, and indicatively, the Helsinki, Hong
Kong, Shenzhen, Swiss, Tokyo, Toronto, and Vancouver Stock Exchanges,
together with Euronext and the Australian Securities Exchange operate as
pure LOBs, while the New York Stock Exchange, NASDAQ, and the London
Stock Exchange also operate a hybrid LOB system (Gould et al., 2013), with
specialists operating for the less liquid securities.
We will consider trading activity in the context of the LOB in this chapter.
Market participants are typically allowed to place two types of orders on the
venue: limit orders, where they specify a price over which they are unwilling
to buy (or a price under which they are unwilling to sell), and market orders,
which are executed at the best available price. Market orders are executed
immediately, provided there are orders of the same size on the opposite side
of the book. Limit orders to buy (sell) are only executed if there is opposite
trading interest in the order book at, or below (above), the speciﬁed limit
price. If there is no such interest, the order is entered into the limit order
book, where orders are displayed by price, then time priority.
Figure 15.1 shows an example snapshot of the order book for a particular
stock, as traded on the Chi-X exchange, at a particular instance of time. A
market order to buy 200 shares would result in three trades: 70 shares at 2,702,
another 100 shares at 2,702, and the remaining 30 at 2,704. A limit order to
sell 300 shares at 2,705, on the other hand, would not be executed immedi-
ately, as the highest order to buy is only at 2,700 cents. It would instead enter
the limit order book on the right hand side, second in priority at 2,705 cents
after the order for 120 shares, which is already in the book.
LOB simulation models aim to generate the trading interactions observed
in such a LOB and allow for a realistic description of the intra-day trad-
ing process. In particular, the models simulate the behaviour of individual
market participants, usually based on the behaviour of various classes of real
traders. The price of the traded ﬁnancial asset is then determined from the
limit and market orders submitted by these traders. Depending on the model,
∗https://www.batstrading.co.uk/

440
Handbook of Approximate Bayesian Computation
Buy
100
100
70
200
120
300
100
100
250
400
200
100
500
50
80
30
500
100
300
Sell
2,702
2,704
2,705
2,708
2,710
2,700
2,699
2,698
2,696
2,693
...
...
FIGURE 15.1
An example of the state of the Chi-X order book. The left hand side of the
book is the buying interest, while the right hand side is the selling interest.
The highest bid (order to buy) is for 100 shares at 2,700 cents, while there are
two lowest oﬀers (orders to sell) for 70 and 100 shares at 2,702. Orders are
prioritised by price, then time.
the instantaneous price is either considered to be the mid-point between the
highest bid price and lowest ask price or the last traded price.
Because of the practical interest of modelling the intra-day dynamics of
both stock prices and available volumes in the LOB, as well as the diﬃculty
of traditional economic models based on rationality to reproduce these dyn-
amics, there have been a multitude of research approaches attempting to
address this gap. On one hand, there have been the zero-intelligence appr-
oaches [e.g. Maslov (2000)], which generally consist of a single, unsophisti-
cated type of trading agent who submits orders randomly, possibly subject
to (very few) constraints, like budget considerations. This minimum amount
of discipline imposed by their actions is therefore often suﬃcient to repro-
duce some commonly observed features of ﬁnancial markets, such as fat
tails in the distribution of returns (Maslov, 2000). Later models (LiCalzi
and Pellizzari, 2003; Fricke and Lux, 2015) also considered more realistic
trading behaviour, where agents act based on their perceived value of the
ﬁnancial asset. However, LiCalzi and Pellizzari (2003) noted that these addi-
tional considerations regarding agent behaviour did not necessarily lead to
a more realistic stock price output, and that it was likely the imposed mar-
ket structure that had the largest eﬀect on reproducing the price features
observed.
One other prominent strand of research pertains to the modelling of the
LOB as a set of queues at each price and on both the buy (bid) and sell (ask)
side. In the models of Cont et al. (2010) and Cont and De Larrard (2013), a
power law characterising the intensities of the limit order processes is found
to be a good emprical ﬁt. However, their assumption of independence between
the activity at each level and for each event type is unlikely to hold in modern
LOBs, due to the presence of algorithmic trading strategies, which induce

SMC-ABC Methods for Estimation of Stochastic Simulation Models
441
diﬀerent types of dependence structures. It is clear from observed empirical
LOB data that non-trivial dependence structures are present, and as such,
ignoring these features in the model formulation will result in inadequate
representations of the stochastic LOB process being modelled.
In the LOB simulation model introduced in Panayi and Peters (2015),
they attempted to provide both a richer description of the LOB market struc-
ture and its constituent agents, but also consider the dependence between
the trading activity at diﬀerent levels. The main components of the proposed
model are detailed in the following sections, before it is extended into an ABC
posterior formulation for estimation and inference purposes.
15.1.2
Features of signiﬁcance in limit order book
stochastic processes: Liquidity
In order to motivate the development of our stochastic representative agent-
based model from a liquidity demand and supply perspective, it is important
to also comment on how most modern electronic exchanges operate. We argue
that it is especially important to understand this from a liquidity perspective
and to incorporate such features into a stochastic model of the LOB. To our
knowledge, there have been no previous attempts to build-agent based models
based around liquidity provision characteristics other than the work of Panayi
and Peters (2015), which we extend into a Bayesian formulation with SMC-
ABC inference in this chapter.
To put this in context, we note that the notion of liquidity can take many
forms in a LOB stochastic process. Indeed, the seminal paper of Kyle (1985)
acknowledged the diﬃculty in capturing the liquidity of a ﬁnancial market in
a single metric, and identiﬁed tightness, depth, and resiliency as three main
properties that characterise the liquidity of a limit order book, see more det-
ailed discussion on these in Panayi et al. (2015b). Tightness and depth have
been mainstays of the ﬁnancial literature (and indeed, are easily captured
through common liquidity measures, such as the spread and depth, respec-
tively) and there have been substantial literature in studying the intra-day
variation and commonality in these measures. In addition, the resilience of
liquidity in the LOB of a ﬁnancial asset has recently begun to receive atten-
tion, see Panayi et al. (2015b), who provided a review of the state of the art
in liquidity resilience and noted that the extant deﬁnitions seemed to be div-
ided into two categories: In the ﬁrst, deﬁnitions provided by Kyle (1985) and
Obizhaeva and Wang (2013) were related to price evolution and, speciﬁcally,
to the return of prices to a steady state. The second category of deﬁnitions,
proposed by Garbade and Garbade (1982) and Harris (2003) was concerned
with liquidity replenishment.
To further understand the role of liquidity in a model for LOB, one must
also be aware of the fact that ﬁnancial exchanges have diﬀerent modes of oper-
ation, or market models, for diﬀerent assets, and Panayi et al. (2015a) provide
an extended discussion of the circumstances under which each is appropriate.

442
Handbook of Approximate Bayesian Computation
The German electronic trading system Xetra supports the following modes, for
example∗: continuous trading in connection with auctions (e.g. opening and
closing auction and, possibly, one or more intra-day auctions); mini-auction
in connection with auctions; and one or more auctions at pre-deﬁned points
in time.
In brief, this is often determined by an asset’s liquidity in the prevailing pe-
riod, and an exchange will endeavour to choose a market model that facilitates
trading in the asset. Xetra, for example, oﬀers continuous trading for the most
liquid assets, while the second most liquid category of assets is supplemented
with a ‘Designated Sponsor’, with market-making obligations, typically inclu-
ding maximum spread, minimum quote size, and eﬀective trading times, they
receive a discount or re-imbursement of transaction fees in return. Certain
securities feature a single market maker, while less liquid assets operate ins-
tead in a ‘continuous auction’ mode, with the assistance of specialist. In order
to decide the market model, Xetra classiﬁes assets quarterly by averaging their
liquidity over the period.
Liquidity provision in the equities and foreign exchange markets has inc-
reasingly become the domain of high-frequency traders. The SEC (Securities
et al., 2010) reports that these traders contribute approximately half of the
total traded volume of all participants. Because these traders operate in the
millisecond domain, we can reasonably assume a high degree of automation
in their trading, and we will try to capture the aggregate liquidity providing
activity of this group of representative agents in our model. Even though for
liquid assets, these ﬁrms have no legal obligation to provide uninterrupted
liquidity, for the period under consideration there are no major structural
breaks, we can assume that this group of liquidity providers will be operating
in the market on the LOB for the assets under consideration throughout the
majority of the trading day.
In this chapter, we develop a LOB stochastic agent model based on liquid-
ity provision for the class of assets operating under a continuous trading mode,
which will be the case for the majority of assets traded on major indices, for
example.
15.2
Bayesian Models with Intractable Likelihoods for
High Frequency Financial Market Dynamics
In this section, we develop a new class of Bayesian models that can be
utilised to study the dynamics of LOB intra-daily. We start by presenting the
stochastic multi-variate order ﬂow model, which we develop as a ‘stochastic
∗Xetra trading models, available at http://www.xetra.com/xetra-en/trading/trading-
models

SMC-ABC Methods for Estimation of Stochastic Simulation Models
443
representative agent’ model framework. This presentation is largely based
on Panayi and Peters (2015), as this is the model we will be working with.
The model is then re-formulated as an intractable likelihood stochastic model
and developed into an approximate Bayesian computational (posterior model).
15.2.1
Limit order book agent-based model
We consider the intra-day LOB activity in ﬁxed intervals of time . . . ,
[t −1, t), [t, t + 1), . . .. For every interval [t, t + 1), we allow the total num-
ber of levels on the bid or ask sides of the LOB to be dynamically adjusted
as the simulation evolves. These LOB levels are deﬁned with respect to two
reference prices, equal to pb,1
t−1 and pa,1
t−1, for example, the price of the highest
bid and lowest ask price at the start of the interval. We consider these ref-
erence prices to be constant throughout the interval [t −1, t), and, thus, the
levels on the bid side of the book are deﬁned at integer number of ticks away
from pa,1
t−1, while the levels on the ask side of the book are deﬁned at integer
number of ticks away from pb,1
t−1.
This does not mean that we expect the best bid and ask prices to remain
constant, just that we model the activity (i.e. limit order arrivals, cancel-
lations, and executions) according to the distance in ticks from these ref-
erence prices during this period. We note that it is of course possible that
the volume at the best bid price is consumed during the interval, and that
limit orders to sell are posted at this price, which would be considered at 0
ticks away from the reference price. To allow for this possibility, we actively
model the activity at −ld + 1, . . . , 0, . . . , lp ticks away from each reference
price. Here, the p subscript will refer to passive orders, for example, orders
which would not lead to immediate execution, if the reference prices remained
constant and d refers to direct, or aggressive orders (those which would be
executed immediately), where it is again understood that they are aggres-
sive with respect to the reference prices at the start of the period. There-
fore, we actively model the activity at a total lt = lp + ld levels on the bid
and ask.
We assume that activity that occurs further away is uncorrelated with
the activity close to the top of the book, and therefore unlikely to have
much of an impact on price evolution and the properties of the volume pro-
cess. Therefore, the volume resting outside the actively modelled LOB levels
(−ld + 1, . . . , 0, . . . , lp) on the bid and ask is assumed to remain unchanged
until the agent interactions brings those levels inside the band of actively
modelled levels, at which time they will again dynamically evolve. Such a set
of assumptions is consistent with observed stylised features of all LOB for all
modern electronic exchanges.
We distinguish diﬀerent order types that agents may perform as follows:
place the order ‘at market’ or ‘at limit’. Market orders provide instruction to
execute, as quickly as possible, a transaction at the present, or market, price.

444
Handbook of Approximate Bayesian Computation
Conversely, a limit order provides instruction to only execute at or under
a purchase price or at or above a sales price. In practice, there are many
diﬀerent variations of such order types, we focus on the most fundamental
vanilla passive and aggressive limit orders and standard immediate eﬀect
market orders.
To present the details of the simulation framework, including the stochas-
tic model components for each agent, for example, liquidity providers and
liquidity demanders, we ﬁrst deﬁne the following notation:
1. V a
t = (V a,−ld+1
t
, . . . , V a,lp
t
) – the random vector for the number of exist-
ing orders resting at each level on the ask side at time t at the actively
modelled levels of the LOB at time t.
2. N LO,a
t
= (N LO,a,−ld+1
t
, . . . , N LO,a,lp
t
) – the random vector for the num-
ber of limit orders entering the limit order book on the ask side at each
level in the interval [t −1, t).
3. N C,a
t
= (N C,a,1
t
, . . . , N C,a,lt
t
) – the random vector for the number of limit
orders cancelled on the ask side in the interval [t −1, t).
4. N MO,a
t
– the random variable for the number of market orders submitted
by liquidity demanders in the interval [t −1, t).
We consider the processes for limit orders and market orders, as well as cancel-
lations to be linked to the behaviour of real market participants in the LOB.
In the following, we model the aggregation of the activity of two classes of liq-
uidity motivated agents, namely liquidity providers and liquidity demanders.
As we model LOB activity in discrete time intervals, we process the aggregate
activity at the end of each time interval in the following order:
1. Limit order arrivals – passive – by the liquidity provider agent.
2. Limit order arrivals – aggressive or direct – by the liquidity provider
agent.
3. Cancellations by the liquidity provider agent.
4. Market orders by the liquidity demander agent.
The rationale for this ordering is that the vast majority of limit order
submissions and cancellations are typically accounted for by the activity of
high-frequency traders, and many resting orders are cancelled before slower
traders can execute against them. In addition, such an ordering allows us to
condition on the state of the LOB, so that we do not have more cancellations
at a particular level than the orders resting at that level. This is generally
appropriate, as the time interval we consider can be made as small as desired
for a given simulation.

SMC-ABC Methods for Estimation of Stochastic Simulation Models
445
15.2.1.1
Stochastic agent representation: Liquidity providers and
demanders
We assume liquidity providers are responsible for all market-making behaviour
(i.e. limit order submissions and cancellations on both the bid and ask side
of the LOB). After liquidity is posted to the LOB, liquidity seeking market
participants, such as mutual funds using some execution algorithm, can take
advantage of the resting volume with market orders. For market makers,
achieving a balance between volume executed on the bid and the ask side
can be proﬁtable. However, there is also the risk of adverse selection, for ex-
ample, trading against a trader with superior information. This may lead to
losses if, for example, a trader posts multiple market orders that consume the
volume on several levels of the LOB. The risk of adverse selection as a result
of asymmetric information is one of the basic tenets of market microstruc-
ture theory (O’hara, 1995). To reduce this risk, market makers cancel and
re-submit orders at diﬀerent prices and/or diﬀerent sizes.
Deﬁnition 15.1 (Limit order submission process for the liquidity pro-
vider agent) Consider the limit order submission process of the liquidity
provider agent to include both passive and aggressive limit orders on the bid
and ask sides of the book, which are assumed to have the following stochastic
model structure:
1. Let the multi-variate path-space random matrix N LO,k
1:T
∈Nlt×T
+
be con-
structed from random vectors for the numbers of limit order placements
N LO,k
1:T
=

N LO,k
1
, N LO,k
2
, . . . , N LO,k
T

. Furthermore, assume these ran-
dom vectors for the number of orders at each level at time t are each condi-
tionally dependent on a latent stochastic process for the intensity at which
the limit orders arrive, given by the random matrix ΛLO,k
1:T
∈Rlt×T
+
and on
the path-space by ΛLO,k
1:T
=

ΛLO,k
1
, ΛLO,k
2
, . . . , ΛLO,k
T

. In the following,
k ∈{a, b} indicates the respective process on the ask and bid side.
2. Assume the conditional independence property for the random vectors
given by:

N LO,k
s
|ΛLO,k
s

⊥⊥

N LO,k
t
|ΛLO,k
t

, ∀s ̸= t, s, t ∈{1, 2, . . . , T} (15.1)
3. For each time interval [t −1, t) from the start of trading on the day, let
the random vector for the number of new limit orders placed in each ac-
tively modelled level of the limit order book, for example, the price points
corresponding to ticks (−ld + 1, . . . , 0, 1, . . . , lp), be denoted by N LO,k
t
=
(N LO,k,−ld+1
t
, . . . , N LO,k,lp
t
), and assume that these random vectors satisfy
the conditional independence property:

N LO,k,s
t
|ΛLO,k,s
t

⊥⊥

N LO,k,q
t
|ΛLO,k,q
t

, ∀s ̸= q,
s, q ∈{−ld + 1, . . . , 0, 1, . . . , lp}
(15.2)

446
Handbook of Approximate Bayesian Computation
4. Assume the random vector N LO,k
t
∈Nlt
+ is distributed according to
a multi-variate generalised Cox process with conditional distribution
N LO,k
t
∼GCP

λLO,k
t

given by:
Pr

N LO,k,−ld+1
t
= n1, . . . , N LO,k,lp
t
= nlt
 ΛLO,k
t
= λLO,k
t

=
lp
	
s=−ld+1

λLO,k,s
t
ns
ns!
exp

−λLO,k,s
t

(15.3)
5. Assume the independence property for random vectors of latent intensities
unconditionally according to:
ΛLO,k
s
⊥⊥ΛLO,k
t
, ∀s ̸= t, s, t ∈{1, 2, . . . , T}
(15.4)
6. Assume that the intensity random vector ΛLO,k
t
∈Rlt
+ is obtained through
an element-wise transformation of the random vector ΓLO,k
t
∈Rlt, where
for each element we have the mapping:
ΛLO,k,s
t
= μLO,k,s
0
F

ΓLO,k,s
t

(15.5)
where we have s
∈
{−ld + 1, . . . , lp}, baseline intensity parameters

μLO,k,s
0

∈R+, and a strictly monotonic mapping F : R →[0, 1].
7. Assume the random vector ΓLO,k
t
∈R is distributed according to a multi-
variate skew-t distribution ΓLO,k
t
∼MSt(mk, βk, νk, Σk) with location
parameter vector mk ∈Rlt, skewness parameter vector βk ∈Rlt, degrees
of freedom parameter νk ∈N+, and lt × lt covariance matrix Σk. Hence,
ΓLO,k
t
has density function:
fΓLO,k
t

γt; mk, βk, νk, Σk
=
cK νk+lt
2
√
(νk+Q(γt,mk))[βk]T [Σk]−1βk

exp (γt−mk)
T[Σk]
−1βk
√
(νk+Q(γt,mk))[βk]T [Σk]−1βk
−νk+lt
2

1+ Q(γt,mk)
νk
 νk+lt
2
(15.6)
where Kv(z) is a modiﬁed Bessel function of the second kind given by:
Kv(z) = 1
2
 ∞
0
yv−1e−z
2 (y+y−1)dy
(15.7)

SMC-ABC Methods for Estimation of Stochastic Simulation Models
447
and c is a normalisation constant. We also deﬁne the function Q(·, ·) as
follows:
Q(γt, mk) = (γt −mk)T 
Σk−1 (γt −mk)
(15.8)
This model admits skew-t marginals and a skew-t copula, see Smith et al.
(2012) for details. Importantly, this stochastic model admits the following
scale mixture representation:
ΓLO,k
t
d= mk + βkW +
√
WZ
(15.9)
with inverse-gamma random variable W ∼IGa

νk
2 , νk
2

and independent
Gaussian random vector Z ∼N

0, Σk
.
8. Assume that for every element N LO,k,s
t
of order counts from the random
vector N LO,k
t
, there is a corresponding random vector OLO,k,s
t
∈NN LO,k,s
t
+
of order sizes. We assume that the element OLO,k,s
i,t
, i ∈

1, . . . , N LO,k,s
t

is distributed as OLO,k,s
i,t
∼H(·). Furthermore, we assume that order sizes
are unconditionally independent OLO,k,s
i,t
⊥⊥OLO,k,s
i′,t
for i ̸= i′, s ̸= s′
and t ̸= t′.
Remark 15.1 Under this proposed model for market maker liquidity activ-
ity, the number of limit orders placed by the liquidity providers in the market
has an appropriate dynamic intensity structure that can evolve intra-daily to
reﬂect the changing nature of liquidity provided by market makers throughout
the trading day. In addition, the number of limit orders placed at each level of
the bid and ask also allow for the model to capture the observed dependence
structures in order placements in each level of the bid and ask regularly seen
in empirical analysis of high-frequency LOB data. The dependence structure
utilised is based on a skew-t copula which allows non-exchangeability of the
stochastic intensity on the bid and ask at each level of the book, as well as
asymmetry in the tail dependence features. This means that when large move-
ments by market makers to replenish liquidity after a liquidity drought occurs
intra-daily, such as after a large market order execution, the model can produce
such replenishment on just the bid or just the ask depending on the situation.
Under the skew-t copula structure used in this model, the liquidity provider
agent does not automatically replenish both sides of the book equally likely, as
would occur under a standard t-copula structure.
We now deﬁne the second component of the liquidity provider agents,
namely, the cancellation process. The cancellation process has the same
stochastic process model speciﬁcation as the aforementioned limit order sub-
mission process, including a skew-t dependence structure between the stochas-
tic intensities at each LOB level on the bid and ask. We therefore only specify

448
Handbook of Approximate Bayesian Computation
the diﬀerences unique to the cancellation process relative to the order place-
ment model deﬁnition in the following speciﬁcation, to avoid repetition.
Deﬁnition 15.2 (Limit order cancellation process for liquidity pro-
vider agent) Consider the limit order cancellation process of the liquidity
provider agent to have an identically speciﬁed stochastic model structure as the
limit order submissions. The exception to this pertains to the assumption that
the number of cancelled orders in each interval at each level is right-truncated
at the total number of orders at that level.
1. As for submissions, we assume for cancellations a multi-variate path-space
random matrix N C,k
1:T ∈Nlt×T
+
constructed from random vectors for the
number of cancelled orders given by N C,k
1:T
=

N C,k
1
, N C,k
2
, . . . , N C,k
T

.
Furthermore, assume for these random vectors for the number of cancelled
orders at each of the lt levels, the latent stochastic process for the intensity
is given by the random matrix ΛC,k
1:T ∈Rlt×T
+
and given on the path-space
by ΛC,k
1:T =

ΛC,k
1
, ΛC,k
2
, . . . , ΛC,k
T

.
2. Assume that for the random vector ˜V k
t for the volume resting in the LOB
after the placement of limit orders we have ˜V k
t = V k
t−1 + N LO,k
t
, and that
the random vector N C,k
t
∈Nlt
+ is distributed according to a truncated multi-
variate generalised Cox process with conditional distribution N C,k
t
| ˜V k
t
=
v ∼GCP

λC,k
t

I(N C,k
t
< v) (with v = (v−ld+1, . . . , vlp)) given by:
Pr

N C,k,−ld+1
t
= n−ld+1, . . . , N C,k,lp
t
= nlp
 ΛC,k
t
= λC,k
t
, ˜V k
t = v

=
lp
	
s=−ld+1
(λC,k,s
t
)ns
ns!
vs
j=0
(λC,k,s
t
)j
j!
(15.10)
3. Assume that for the cancellation count N C,k,s
t
, the orders with highest
priority are cancelled from level s (which are also the oldest orders in
their respective queue). Assume also that cancellations always remove an
order in full, for example, there are no partial cancellations.
Remark 15.2 Cancellations are a critical part of a market makers ability to
modulate and adjust their liquidity activity to avoid large losses in trades that
would otherwise be executed under an adverse selection setting. Under this
proposed model for market maker liquidity removal activity (cancellations),
the number of limit orders cancelled by the liquidity providers in the market
has an appropriate dynamic intensity structure that can evolve intra-daily to
reﬂect the changing nature of liquidity demand throughout the trading day. In
addition, the number of limit orders cancelled at each level of the bid and ask
also allow for the model to capture the observed dependence structures in order

SMC-ABC Methods for Estimation of Stochastic Simulation Models
449
cancellations at each level of the bid and ask. The dependence structure utilised
is based on a skew-t copula which allows non-exchangeability of the stochastic
intensity on the bid and ask at each level of the book, as well as asymmetry
in the tail dependence features. This means that when large price movements
occur in the LOB, market makers need to adjust their LOB volumes and proﬁle
by cancelling existing resting orders and creating new orders. This typically
occurs many times throughout the trading day, and the ability to do this with
an appropriate dependence structure is critical. In addition, the number of
cancelled orders needs to preserve the principle of volume preservation, that
is the upper bound on the total number of limit orders that may be cancelled
at any given time is based on the instantaneous resting volume in the book at
the given time instant.
We complete the speciﬁcation of the representative agents by considering
the speciﬁcation of the liquidity demander agent. In addition to market makers
who are incentivised to place orders intra-daily in the limit order book, by
exchanges in which they operate, there are also other market participants who
trade for other reasons. These other market participants include hedge funds,
pension funds, and other types of large investors, typically we refer to such
groups of traders as liquidity demanders. They absorb liquidity throughout
the day by purchasing resting orders in the limit order book. These purchases
are most often made through market orders or aggressive limit orders. In this
chapter, we assume that all such activities can be adequately modelled by a
stochastic liquidity demander agent making dynamically evolving decisions to
place market orders, as speciﬁed in the following.
Deﬁnition 15.3 (Market order submission process for liquidity dem-
ander agent) Consider a representative agent for the liquidity providers to be
composed of a market order component, which has the following stochastic
structure:
1. Assume a path-space random vector N MO,k
1:T
∈N1×T
+
for the number of
market orders constructed from the random variables for the number of
market orders in each interval N MO,k
1:T
=

N MO,k
1
, N MO,k
2
, . . . , N MO,k
T

.
Furthermore, assume that for these random variables, the latent stochastic
process for the intensity is given by random variable ΛMO,k
1:T
∈Rlt×T
+
and
given on the path-space by ΛMO,k
1:T
=

ΛMO,k
1
, ΛMO,k
2
, . . . , ΛMO,k
T

.
2. Assume the conditional independence property for the random variables:

N MO,k
s
|ΛMO,k
s

⊥⊥

N MO,k
t
|ΛMO,k
t

, ∀s ̸= t, s, t ∈{1, 2, . . . , T}
(15.11)
3. Assume that for the random variable ˜Rk
t for the volume resting on the
opposite side of the LOB after the placement of limit orders and cancella-
tions we have ˜Rk
t = Σlp
s=1

˜V k′,s
t−Δt −N C,k′,s
t

, where k′ = a if k = b, and

450
Handbook of Approximate Bayesian Computation
vice-versa, and that the random variable N MO,k
t
∈N+ is distributed ac-
cording to a truncated generalised Cox process with conditional distribution
N MO,k
t
| ˜Rk
t = r ∼GCP

λMO,k
t

1(N MO,k
t
< r) given by:
Pr

N MO,k
t
= n
 ΛMO,k
t
= λMO,k
t
, ˜Rk
t = r

=
(λMO,k
t
)n
n!
r
j=0
(λMO,k
t
)j
j!
(15.12)
4. Assume the independence property for random vectors of latent intensities
unconditionally according to:
ΛMO,k
s
⊥⊥ΛMO,k
t
, ∀s ̸= t, s, t ∈{1, 2, . . . , T}
(15.13)
5. Assume that for each intensity random variable ΛMO,k
t
∈R+, there is a
corresponding transformed intensity variable ΓMO,k
t
∈R, and the relation-
ship for each element is given by the mapping:
ΛMO,k
t
= μMO,k
0
F

ΓMO,k
t

(15.14)
for some baseline intensity parameter μMO,k
0
∈R+ and strictly monotonic
mapping F : R →[0, 1].
6. Assume that the random variables ΓMO,k
t
∈R, characterising the inten-
sity before transformation of the generalised Cox-process, are distributed
in interval [t−1, t) according to a uni-variate skew-t distribution ΓMO,k
t
∼
St(mMO,k
t
, βMO,k, νMO,k, σMO,k).
7. Assume that for every element N MO,k
t
of market order counts, there is
a corresponding random vector OMO,k,s
t
∈NN MO,k
t
+
of order sizes. We as-
sume that the element OMO,k
i,t
, i ∈

1, . . . , N MO,k
t

is distributed according
to OMO,k
i,t
∼H(·). Assume also that market order sizes are unconditionally
independent OMO,k
i,t
⊥⊥OMO,k
i′,t
for i ̸= i′ or t ̸= t′.
We denote the LOB state for the real dataset at time t on a given day by
the random vector Lt, and this corresponds to the prices and volumes at each
level of the bid and ask. Utilising the stochastic agent-based model speciﬁca-
tion described earlier, and given a parameter vector θ, which will generically
represent all parameters of the liquidity providing and liquidity demanding
agent types, one can then also generate simulations of intra-day LOB activity
and arrive at the synthetic state L∗
t (θ). The state of the simulated LOB at
time t is obtained from the state at time t −1 and a set of stochastic compo-
nents, denoted generically by Xt, which are obtained from a single stochastic
realisation of the following components of the agent-based models:

SMC-ABC Methods for Estimation of Stochastic Simulation Models
451
• Limit order submission intensities ΛLO,b
t
, ΛLO,a
t
, order numbers N LO,b
t
,
N LO,a
t
, and order sizes OLO,a,s
i,t
, OLO,b,s
j,t
, where s = −ld + 1 . . . lp, i =
1 . . . N LO,a,s
t
, j = 1 . . . N LO,b,s
t
.
• Limit order cancellation intensities ΛC,b
t
, ΛC,a
t
, and numbers of cancella-
tions N C,b
t
, N C,a
t
.
• Market order intensities ΛMO,b
t
, ΛMO,a
t
, numbers of market orders N MO,b
t
,
N MO,a
t
,V MO,b
t
,V MO,a
t
, and market order sizes OMO,a
i,t
, OMO,b
j,t
, i
=
1 . . . N MO,a
t
, j = 1 . . . N MO,b
t
.
These stochastic features are combined with the previous state of the LOB,
L∗
t−1 (θ), to produce the new state L∗
t (θ) for a given set of parameters θ,
given by:
L∗
t (θ) = G(L∗
t−1 (θ) , Xt)
(15.15)
G(·) is a transformation that maps the previous state of the LOB and the
activity generated in the current step into a new step, much the same way
as the matching engine updates the LOB after every event. As we model the
activity in discrete intervals, however, the LOB is only updated at the end
of every interval, and the incoming events (limit orders, market orders, and
cancellations) are processed in the order speciﬁed in Section 15.2.1. Condi-
tional then on a realisation of these parameters θ, the trading activity in the
LOB can be simulated for a single trading day, and the complete procedure
is described in the algorithm set out in Panayi and Peters (2015).
15.2.2
Bayesian model formulation of the stochastic agent
limit order book model representation
In this section, we consider the class of LOB stochastic models developed in
the previous section, and we detail a Bayesian model formulation under an
ABC framework. Methods for Bayesian modelling in the presence of com-
putationally intractable likelihood functions are of growing interest. These
methods may arise either because the likelihood is truly intractable to eval-
uate pointwise, or, in our case, it may be that the likelihood is so complex
in terms of model speciﬁcation and costly to evaluate pointwise, that one
has to resort to alternative methods to perform estimation and inference.
Termed likelihood-free samplers or ABC methods, simulation algorithms such
as Sequential Monte Carlo Samplers have been adapted for this setting, see,
for instance, Peters et al. (2012a).
We start by re-calling a few basics. Typically, Bayesian inference proceeds
via the posterior distribution, generically denoted by π(θ|y) ∝f(y|θ)π(θ),
the updating of prior information π(θ) for a parameter θ ∈E through the
likelihood function f(y|θ) after observing data y ∈Y. Numerical algorithms,
such as importance sampling, Markov chain Monte Carlo (MCMC) and SMC,
are commonly employed to draw samples from the posterior π(θ|y).

452
Handbook of Approximate Bayesian Computation
Remark 15.3 (Note on data vector) In the context of this chapter the
data y are the entire order book structure for a given asset over a day as
summarised by:
• Limit order submission order numbers N LO,b
t
, N LO,a
t
, and order sizes
OLO,a,s
i,t
, OLO,b,s
j,t
, where s
=
−ld + 1 . . . lp, i
=
1 . . . N LO,a,s
t
, j
=
1 . . . N LO,b,s
t
.
• Limit order numbers of cancellations N C,b
t
, N C,a
t
.
• Numbers of market orders N MO,b
t
, N MO,a
t
,V MO,b
t
,V MO,a
t
, and market
order sizes OMO,a
i,t
, OMO,b
j,t
, i = 1 . . . N MO,a
t
, j = 1 . . . N MO,b
t
.
The resulting observation vector yt, at time t, is then the concatenation of
all these variables. These stochastic features are obtained at sampling rate t
within the market hours of the trading day, typically say every 5–30 seconds
for the 8.5 hour trading day, producing a total of between 1,000–6,000 vector
valued observations per day.
Clearly, even evaluating a likelihood on this many records, even if it could
be written down, which in many LOB models built on queues like the one in
this chapter will not be the case, would still be a challenging task. Generically,
we will denote in the following the collection of all observations y of the LOB
for an asset on a given day, and by θ, the set of all parameters that are utilised
to parameterise the LOB stochastic model.
There is growing interest in posterior simulation in situations where the
likelihood function is computationally intractable, for example, f(y|θ) may
not be numerically evaluated pointwise. As a result, sampling algorithms
based on repeated likelihood evaluations require modiﬁcation for this task.
They employ generation of auxiliary datasets under the model as a means to
circumvent (intractable) likelihood evaluation.
15.2.2.1
Posterior models for computationally intractable
likelihoods
In essence, likelihood-free methods ﬁrst reduce the observed data, y, to
a low-dimensional vector of summary statistics ty = T(y) ∈T , where
dim(θ) ≤dim(ty) << dim(y). Accordingly, the true posterior π(θ|y) is re-
placed with a new posterior π(θ|ty). These are equivalent if ty is suﬃcient
for θ, and π(θ|ty) ≈π(θ|y) is an approximation, if there is some loss of in-
formation through ty. The new target posterior, π(θ|ty), still assumed to be
computationally intractable, is then embedded within an augmented model
from which sampling is viable. Speciﬁcally, the joint posterior of the model
parameters θ and auxiliary data t ∈T given observed data ty are:
π(θ, t|ty) ∝Kϵ(ty −t)f(t|θ)π(θ)
(15.16)

SMC-ABC Methods for Estimation of Stochastic Simulation Models
453
where t ∼f(t|θ) may be interpreted as the vector of summary statistics t =
T(x) computed from a dataset simulated according to the model x ∼f(x|θ).
Assuming such simulation is possible, data-generation under the model,
t ∼f(t|θ), forms the basis of computation in the likelihood-free setting. The
target marginal posterior πM(θ|ty) for the parameters θ is then obtained as:
πM(θ|ty) = cM

T
Kϵ(ty −t)f(t|θ)π(θ)dt
(15.17)
where (cM)−1 =

E

T Kϵ(ty −t)f(t|θ)π(θ)dtdθ normalises (15.17), such that
it is a density in θ (Reeves and Pettitt, 2005; Sisson et al., 2007; Blum, 2010;
?; Wilkinson, 2013). The function Kϵ(ty −t) is a standard kernel function,
with scale parameter ϵ ≥0, which weights the intractable posterior with high
density in regions t ≈ty, where auxiliary and observed datasets are similar. As
such, πM(θ|ty) ≈π(θ|ty) forms an approximation to the intractable posterior
via (15.17) through standard smoothing arguments (Blum, 2010). In the case
as ϵ →0, so that Kϵ(ty −t) becomes a point mass at the origin (i.e. ty = t)
and is zero elsewhere, if ty is suﬃcient for θ, then the intractable posterior
marginal πM(θ|ty) = π(θ|ty) = π(θ|y) is recovered exactly (although small
h is usually impractical). Various choices of smoothing kernel K have been
examined in the literature (Beaumont et al., 2002; Marjoram et al., 2003;
Peters et al., 2012a).
For our discussion on likelihood-free or ABC samplers, it is convenient to
consider a generalisation of the joint distribution (15.16) incorporating S ≥1
auxiliary summary vectors:
πJ(θ, t1:S|ty) ∝˜Kϵ(ty, t1:S)f(t1:S|θ)π(θ)
where t1:S = (t1, . . . , tS) and t1, . . . , tS ∼f(t|θ) are S independent datasets
generated from the (intractable) model. As the auxiliary datasets are,
by construction, conditionally independent given θ, we have f(t1:S|θ) =
S
s=1 f(ts|θ). We follow Del Moral et al. (2012) and specify the kernel ˜K
as ˜Kϵ(ty, t1:S) = S−1 S
s=1 Kϵ(ty −ts), which produces the joint posterior:
πJ(θ, t1:S|ty) = cJ

1
S
S

s=1
Kϵ(ty −ts)
  S
	
s=1
f(ts|θ)

π(θ)
(15.18)
with cJ > 0 the appropriate normalisation constant, where in (15.18) we ex-
tend the uniform kernel choice of K(ty −ts) by Del Moral et al. (2012) to the
general case. It is easy to see that, by construction,

T S πJ(θ, t1:S|ty)dt1:S =
πM(θ|ty)
admits
the
distribution
(15.17)
as
a
marginal
distribution
(cf. Del Moral et al., 2012). The case S = 1 with πJ(θ, t1:S|ty) = π(θ, t|ty)
corresponds to the more usual joint posterior (15.16) in the likelihood-free
setting. We note that recent studies, such as that by Bornn et al. (2014),
have demonstrated that it may not be beneﬁcial to sample multiple data
replications at each instance of time, for example, in the case of importance

454
Handbook of Approximate Bayesian Computation
sampling and MCMC, it has been found to be better to select S = 1, even
though the individual representation has a higher variance approximation, the
overall computational eﬃciency and accuracy of the ABC method is improved
in such a setting. This may not be true for SMC samplers and remains to be
studied further.
There are two obvious approaches to posterior simulation from πM(θ|ty) ≈
π(θ|ty) as an approximation to π(θ|y). The ﬁrst approach proceeds by sam-
pling directly on the augmented model πJ(θ, t1:S|ty), realising joint samples
(θ, t1:S) ∈E × T S before a posteriori marginalisation over t1:S (i.e. by dis-
carding the ts realisations from the sampler output). In this approach, the
summary quantities t1:S are treated as parameters in the augmented model.
The second approach is to sample from πM(θ|ty) directly, a lower-
dimensional space, by approximating the integral (15.17) via Monte Carlo
integration in lieu of each posterior evaluation of πM(θ|ty). In this case:
πM(θ|ty) ∝π(θ)

T
Kϵ(ty −t)f(t|θ)dt ≈π(θ)
S
S

s=1
Kϵ(ty −ts) := ˆπM(θ|ty)
(15.19)
where t1, . . . , tS ∼f(t|θ). This expression, examined by various authors
(Marjoram et al., 2003; Reeves and Pettitt, 2005; Ratmann et al., 2009;
Toni et al., 2009; Peters et al., 2012a), requires multiple generated datasets
t1, . . . , tS for each evaluation of the marginal posterior distribution πM(θ|ty).
As with standard Monte Carlo approximations, Var[ˆπM(θ|ty)] reduces as S
increases, with limS→∞Var[ˆπM(θ|ty)] = 0. For the marginal posterior distri-
bution, the quantities t1:S serve only as a means to estimate πM(θ|ty) and do
not otherwise enter the model explicitly. The number of samples S directly
impacts on the variance of the estimation.
15.2.3
Summary statistics in Bayesian limit order book
models
In terms of ABC methods, it is important to consider carefully the choice of
summary statistics, and how they should be designed to enter into the ABC
posterior model. Ideally, we would seek suﬃcient statistics for the stochastic
model, however, in many realistic practical settings where ABC is particularly
useful, this may be diﬃcult to achieve, see discussions in Nunes and Bald-
ing (2010). Other alternatives are therefore typically adopted, for instance,
in some cases the model is suﬃciently well speciﬁed that speciﬁc summary
statistics may arise as sensible model-based choices from an interpretation
perspective, such as those discussed in ﬁnancial-and insurance-based exam-
ples in Peters et al. (2012b) and Peters et al. (2010). In other cases, one
may adopt automatic summary statistics procedures, such as those described
in Fearnhead and Prangle (2010) and the literature therein. In Blum and
Fran¸cois (2010) and Fan et al. (2013) regression-based approaches to summary

SMC-ABC Methods for Estimation of Stochastic Simulation Models
455
statistics are utilised, and, in Blum et al. (2013), discussions on dimension red-
uction approaches are considered. In this chapter, we have decided to utilise
model-based summary statistics which are obtained via an application speciﬁc
dimension reduction approach. This was decided due to its practicality for int-
erpretation of practitioners and to make results obtained readily comparable
to the multi-objective indirect inference procedures studied on these LOB
models in Panayi and Peters (2015).
We note that the liquidity provision stochastic representative agent model
for the LOB is a complex model structure which will not readily admit suﬃ-
cient statistics for applications in ABC. It is therefore important to consider
carefully what would be appropriate choices for summary statistics in the
model. In this chapter, we explore the notion of model-based summary statis-
tics based around ﬁrst a dimension reduction of the LOB stochastic process
to a subset of important features representative of key attributes of the LOB
process from the practitioners’ and regulators’ perspective. In this context, the
idea is to take the LOB model stochastic process structure and transform this
stochastic process with multiple components to summary processes through-
out the trading day. It is suggested that in practice these may correspond to
attributes of interest, such as:
• Volume-based processes, total volume on bid, total volume on ask, indi-
vidual volumes on each level of the book for the ask, and bid etc.
• Fair price, for example, mid price induced by LOB stochastic process,
returns process for mid price.
• Round-trip cost-based prices, such as XLM measures of liquidity, as well
as liquidity resilience measures, such as those discussed in detail in Panayi
et al. (2015b).
Having obtained these dimension reductions of the complex LOB stochast
process, one can then construct summary statistics based on a model ﬁt either
regression, kernel density, or, in our case, time series-based regression models.
We provide detailed analysis of our choices in this regard in the results section.
15.3
Estimation of Bayesian Limit Order Book
Stochastic Agent Model via Population-Based
Samplers
Population-based likelihood-free samplers were introduced to circumvent poor
mixing in MCMC samplers (Sisson et al., 2007; Beaumont et al., 2009; Toni
et al., 2009; Del Moral et al., 2012; Peters et al., 2012a). These samplers
propagate a population of particles, θ(1), . . . , θ(N), with associated importance

456
Handbook of Approximate Bayesian Computation
weights W(θ(i)), through a sequence of related densities φ1(θ1), . . . , φT (θT ),
which deﬁnes a smooth transition from the distribution φ1, from which direct
sampling is available, to φT the target distribution.
For
likelihood-free
or
ABC
samplers,
φk
is
deﬁned
by
allowing
Kϵn(ty −t) to place greater density on regions for which ty
≈
t
as k increases (that is, the bandwidth ϵn decreases with n). Hence,
we denote πJ,n(θ, t1:S|ty) ∝
˜Kϵn(ty, t1:S)f(t1:S|θ)π(θ) and πM,n(θ|ty) ∝
π(θ)

T S ˜Kϵn(ty, t1:S)f(t1:S|θ)dt1:S for n = 1, . . . , T, under the joint and
marginal posterior models, respectively. Since it will be assumed that a signif-
icant description of such methodologies is provided in other chapters in this
book, we only brieﬂy discuss this family of sampling methods in the following,
instead focusing on our applications of such methods in this chapter.
15.3.1
Brief overview of sequential Monte Carlo-based
samplers
SMC methods emerged out of the ﬁelds of engineering, probability, and statis-
tics in recent years. Variants of the methods sometimes appear under the
names of particle ﬁltering or interacting particle systems (Doucet et al., 2001;
Del Moral, 2004; Ristic et al., 2004), and their theoretical properties have been
extensively studied by Crisan and Doucet (2002), Del Moral (2004), Chopin
(2004), and K¨unsch (2005). In the last few years, Chopin (2002), Neal (2001),
Del Moral et al. (2006), Peters (2005), Peters et al. (2012a), and Targino et al.
(2015), amongst others, have developed generalisations to the SMC algorithm
to the case where the target distributions πn are all deﬁned on the same
support E, for example, no longer a product space formulation. This gener-
alisation, termed the ‘SMC sampler’, adapts the SMC algorithm to the more
popular setting in which the state space E remains static, typically arising in
applications of MCMC algorithms.
Analogously with standard SMC algorithms, the SMC sampler is devel-
oped to generate weighted samples (termed particles) from a sequence of
distributions πn, for n = 1, . . . , T, where πT may be of particular interest.
We refer to πT as the target distribution, such as a posterior distribution for
model parameters. Hence, given a sequence of distributions {πn(dθ)}T
n=1, the
aim is to develop a large collection of N-weighted random samples at each time
n denoted by

W (i)
n , Θ(i)
n
N
i=1, such that W (i)
n > 0 and N
i=1 W (i)
n = 1. These
importance weights and samples, denoted by

W (i)
n , Θ(i)
n
N
i=1, are known as
particles (hence, the name often given to such algorithms as particle ﬁlters or
interacting particle systems). For such approaches to be sensible, we would
require that the empirical distributions constructed through these samples
should converge asymptotically (N →∞) to the target distribution πn for
each time n. This means that for any πn integrable function, denoted, for
example, by φ(θ) : E →R′, one would have the following convergence:

SMC-ABC Methods for Estimation of Stochastic Simulation Models
457
N

i=1
W (i)
n φ

θ(i)
n
 a.s.
→Eπn

φ(Θ)

(15.20)
In the SMC sampler algorithm is constructed by introducing a sequence of
backward kernels Lk, to obtain new distributions:
πn(θ1, . . . , θn) = πn(θn)
n−1
	
k=1
Lk (θk+1, θk)
(15.21)
may be deﬁned for the path of a particle (θ1, . . . , θn) ∈En through the
sequence π1, . . . , πn. The only restriction on the backward kernels is that
the correct marginal distributions

πn(θ1, . . . , θn)dθ1, . . . , dθn−1 = πn(θn)
are available. Within this framework, one may then work with the constructed
sequence of distributions, πn, under the standard SMC algorithm.
In summary, the SMC Sampler algorithm involves three stages:
1. Mutation, whereby the particles are moved from θn−1 to θn via a mutation
kernel Mn(θn−1, θn).
2. Correction, where the particles are re-weighted with respect to πn via the
incremental importance weight (Equation 15.22).
3. Selection, where according to some measure of particle diversity, commonly
the eﬀective sample size, the weighted particles may be re-sampled in order
to reduce the variability of the importance weights.
In more detail, suppose that at time n −1, the distribution πn−1 can be
approximated empirically by πN
n−1 using N-weighted particles. These parti-
cles are ﬁrst propagated to the next distribution πn using a mutation ker-
nel Mn(θn−1, θn), and then assigned new weights Wn = Wn−1wn (θ1, . . . θn),
where Wn−1 is the weight of a particle at time n−1, and wn is the incremental
importance weight given by:
wn (θ1, . . . , θn) =
πn (θ1, . . . , θn)
πn−1 (θ1, . . . , θn−1) Mn (θn−1, θn)
=
πn (θn) Ln−1 (θn, θn−1)
πn−1 (θn−1) Mn (θn−1, θn)
(15.22)
The resulting particles are now weighted samples from πn. Consequently,
from Equation (15.22), under the SMC sampler framework, one may work
directly with the marginal distributions πn(θn), such that wn(θ1, . . . , θn) =
wn(θn−1, θn). While the choice of the backward kernels Ln−1 is essen-
tially arbitrary, their speciﬁcation can strongly aﬀect the performance of the
algorithm, as will be discussed in the following sub-sections. The basic ver-
sion of the SMC sampler algorithm therefore proceeds explicitly as given in
Algorithm 15.1.

458
Handbook of Approximate Bayesian Computation
Algorithm 15.1: Sequential Monte Carlo samplers
1. Initialise the particle system;
(a) Set n = 1.
(b) For i = 1, . . . , N, draw initial particles Θ(i)
1
∼p(θ).
(c) Evaluate
incremental
importance
weights

w1

Θ(i)
1

using
Equation (15.22) and normalise the weights to obtain

W (i)
1

.
Iterate the following steps through each distribution in sequence {πt}T
n=2.
2. Re-sampling;
(a) If the eﬀective sampling size (ESS) =
1
N
i=1

w(i)
n
2 < Neff is less
than a threshold Neff, then re-sample the particles via the empirical
distribution of the weighted sample either by multi-nomial or strat-
iﬁed methods; see discussions on unbiased re-sampling schemes by
K¨unsch (2005) and Del Moral (2004).
3. Mutation and correction;
(a) Set n = n + 1, if n = T + 1, then stop.
(b) For i = 1, . . . , N draw samples from mutation kernel Θ(i)
n
∼
Mn

Θ(i)
n−1

.
(c) Evaluate
incremental
importance
weights

wn

Θ(i)
n

using
Equation (15.22) and normalise the weights to obtain

W (i)
n

via
W (i)
n
= W (i)
n−1
w(i)
n (Θn−1, Θn)
N
j=1 W (i)
n−1w(i)
n (Θn−1, Θn)
(15.23)
15.3.2
Sequential
Monte
Carlo
samplers
for
intractable
likelihood Bayesian models
Formalising this in the context of SMC samplers for ABC posterior settings,
the particle population θn−1 drawn from the distribution φn−1(θn−1) at time
n−1 is mutated to φn(θn) by the kernel Mn(θn−1, θn). The weights for the mu-
tated particles θn may be obtained as Wn(θn) = Wn−1(θn−1)wn (θn−1, θn),
where, for the marginal model sequence πM,n(θn|ty), the incremental weight is:

SMC-ABC Methods for Estimation of Stochastic Simulation Models
459
wn (θn−1, θn) =
πM,n(θn|ty)Ln−1 (θn, θn−1)
πM,n−1(θn−1|ty)Mn (θn−1, θn) ≈
ˆπM,n(θn|ty)Ln−1 (θn, θn−1)
ˆπM,n−1(θn−1|ty)Mn (θn−1, θn)
(15.24)
where, following (15.19), and setting the kernel bandwidth to an ABC toler-
ance level ϵn, we obtain
ˆπM,n(θn|ty) := π(θ)
S
S

s=1
Kϵn(ty −ts)
which is proportional to an (unbiased) estimate of πM,n(θn|ty) based on S
Monte Carlo draws t1, . . . , tS ∼f(t|θn). Here, Ln−1 (θn, θn−1) is a reverse-
time kernel describing the mutation of particles from φn(θn) at time n to
φn−1(θn−1) at time n−1. As with the ABC-MCMC algorithm, the incremental
weight (15.24) consists of the ‘biased’ ratio ˆπM,n(θn|ty)/ˆπn−1(θM,n−1|ty) for
ﬁnite S ≥1.
If we now consider a sequential Monte Carlo sampler under the joint model
πJ,n(θ, t1:S|ty), with the natural mutation kernel factorisation:
Mn[(θn−1, t1:S
n−1), (θn, t1:S
n )] = Mn(θn−1, θn)
S
	
s=1
f(ts
n|ty)
(and similarly for Ln−1), following the form of (15.24), the incremental weight
is exactly:
wn

(θn−1, t1:S
n−1), (θn, t1:S
n )

=
1
S

s Kϵn(ty −ts
n)π(θn)Ln−1 (θn, θn−1)
1
S

s Kϵn−1(ty −ts
n−1)π(θn−1)Mn (θn−1, θn)
(15.25)
Hence, as the incremental weights (15.24, 15.25) are equivalent, they induce
identical SMC algorithms for both marginal and joint models πM(θ|ty) and
πJ(θ, t1:S|ty). As a result, while applications of the marginal sampler target-
ing πM(θ|y) are theoretically biased for ﬁnite S ≥1, as before, they are in
practice unbiased through association with the equivalent sampler on joint
space targeting πJ(θ, t1:S|ty).
We note that a theoretically unbiased sampler targeting πM(θ|ty), for all
S ≥1, can be obtained by careful choice of the kernel Ln−1(θn, θn−1). For
example, Peters (2005), Peters et al. (2012a), and Targino et al. (2015) all use
the sub-optimal approximate optimal kernel given by:
Ln−1(θn, θn−1) =
πM,n−1(θn−1|ty)Mn(θn−1, θn)

πM,n−1(θn−1|ty)Mn(θn−1, θn)dθn−1
(15.26)
from which the incremental weight (15.24) is approximated by:
wn(θn−1, θn)
=
πM,n(θn|ty)/

πM,n−1(θn−1|ty)Mn(θn−1, θn)dθn−1
≈
ˆπM,n(θn|ty)/
N

i=1
Wn−1(θ(i)
n−1)Mn(θ(i)
n−1, θn)
(15.27)

460
Handbook of Approximate Bayesian Computation
Under this choice of backward kernel, the weight calculation is now unbiased
for all S ≥1, since the approximation ˆπM,n−1(θ|y) in the denominator of
(15.24) is no longer needed.
15.3.2.1
Adaptive schedules: choice of sequence of ABC
distributions via annealed tolerance schedule
In this section, we consider how to take the ABC posterior distribution and
construct the sequence of distributions that are required for the SMC sam-
pler. That is, we address the question of how to develop an ABC-speciﬁc
sequence of target distributions. We have chosen to design this sequence
by following what we call ‘ABC reverse annealing’. In particular, we con-
struct a sequence of target posterior distributions {φn}n≥0, which are con-
structed based on strictly decreasing tolerance values, generically denoted
by the sequence {ϵn}n≥0, such that ϵ1 > ϵ2 > . . . > ϵn > . . . > ϵT .
We obtain this sequence of ABC posterior distributions by considering the
φn, which was deﬁned with respect to the ABC likelihood involving a kernel.
If we consider the kernel to have a decreasing bandwidth given by Kϵn(ty −t),
then we will progressively place greater emphasis, for example, density on
regions for which ty ≈t as n increases (that is, the bandwidth ϵn decreases
with n). Hence, we denote the two possible ABC constructions one may con-
sider under the joint and marginal posterior models respectively, in the SMC
Samplers procedure as follows:
πJ,n(θ, t1:S|ty) ∝˜Kϵn(ty, t1:S)f(t1:S|θ)π(θ)
πM,n(θ|ty) ∝π(θ)

T S
˜Kϵn(ty, t1:S)f(t1:S|θ)dt1:S
(15.28)
Now the aspect of this procedure that makes it adaptive is the selection of
the size of the discrepancy between πn and πn+1, for each n ∈{1, 2 . . . , T},
as well as the ﬁnal stopping point. In this paper, we propose to perform
adaption of the ABC target distribution sequence at every step. The aim
is to progressively select a sequence of distributions online, such that the
discrepancy between the next distribution and the previous, as controlled by
the tolerance ϵn sequence, is controlled by the ‘ﬁtness’ or eﬃciency of the
particle approximation of the previous target distribution in the sequence. A
good approximation would indicate that one may take a larger step, whilst a
poorer approximation indicates that smaller steps should be taken.
Formally, we perform the adaption such that a new tolerance ϵn, at it-
eration n, is generated through a particle system-based quantile matching
procedure. The procedure adopted considers the new tolerance to be obtained
as the solution for ϵ in the following equation:
qn−1 = ϵ
√
2erf−1 [2F (q) −1]
(15.29)

SMC-ABC Methods for Estimation of Stochastic Simulation Models
461
where q is a user speciﬁed quantile level, F is the CDF of a normal distribu-
tion with mean 0, and standard deviation ϵ and qn−1 is the particle population
quantile estimate obtained from the ABC posterior approximation after cor-
rection stage in the SMC sampler ABC algorithm. In this way, the tolerance
schedule is continually adapting to the local particle approximation perfor-
mance. In practice, it is computationally eﬃcient to employ the following
adaptive schedule for the tolerance in the ABC posterior, where we ensure
that the sequence of distributions is designed such that the new tolerance is
calculated as a strictly decreasing schedule given by:
ϵn = min ((1 −α)ϵn−1, ϵ∗)
(15.30)
where α ∈(0, 1).
15.3.2.2
Choice of mutation kernel
There are many choices for mutation kernel that could be considered when
designing an SMC sampler algorithm, see discussions on such choices in, for
instance, references such as Peters (2005), Del Moral et al. (2006), Peters et al.
(2012a), and Targino et al. (2015). The choice of kernel is often critical to
select in order for the algorithm to perform well. In what follows, we present
a particular choice we have developed speciﬁcally for the limit order book
application in this chapter. This is a specialised choice of mutation kernel we
adopted from the genetic search literature (Li and Zhang, 2009) which involves
combination of mutation and cross-over operators for the particle mutation in
the SMC sampler. In order to utilise this class of mutation operator in SMC
sampler settings, we had to formally write down not just the mutation and
cross-over operators in a structural form, as typically speciﬁed in the NGSAII
class of genetic optimisation algorithms, but to also deﬁne their distributional
form.
15.3.2.2.1
Genetic mutation and cross-over operators
In this class of mutation kernel in the SMC sampler, we consider the class
of genetic algorithm type mutations. In particular, we describe the class of
MOEA mutation and cross-over operators widely used in stochastic search
algorithms, introduced in the method of Deb et al. (2002). This class of mu-
tation kernel is the most widely used operator in multi-objective optimisation
and we demonstrate its adaption to the SMC sampler framework.
A disadvantage of the NSGA-II operators is that they are only able
to mutate binary, integer, or real encodings of the output parameter vec-
tors, whereas the stochastic process for the limit order submission activ-
ity by liquidity providers requires the speciﬁcation of a positive deﬁnite
and symmetric covariance matrix for the generation of intensities from a
multi-variate skew-t distribution. The positive deﬁniteness and symmetry

462
Handbook of Approximate Bayesian Computation
constraints of the covariance matrix will not be preserved if one simply
employs the evolutionary operators above to produce new sets of covari-
ance matrix candidate solutions. For this reason, Panayi and Peters (2015)
introduced a new covariance mutation operator, which generates new candi-
date covariance matrices which remains in the manifold of positive deﬁnite
matrices.
15.3.2.2.2
Simulated binary crossover
From two previous particles θ(i)
n−1, θ(j)
n−1, a new solution θ(i)
n
is formed, where
the k-th elements is crossed as follows:
θ(i,k)
n
= 1
2[(1 −¯β)θ(i,k)
n−1 + (1 + ¯β)θ(j,k)
n−1 ]
(15.31)
Here, ¯β is a random sample from a distribution with density:
¯β =

(αu)
1
ηc+1 ,
if u ≤1
α
(
1
2−αu)
1
ηc+1 ,
otherwise
where u ∼U(0, 1) and α = 2 −β−(ηc+1), with:
β = 1 +
2
θ(j,k)
n−1 −θ(i,k)
n−1
min

θ(i,k)
n−1 −θkL

,

θkU −θ(j,k)
n−1

(15.32)
This would produce a mutation kernel for this type of move at SMC sampler
iteration n for the k-th element of the i-th particle vector, which would be
updated according to a density given by:
Mn(θ(i,k)
n
|θ(i,k)
n−1, θ(j,k)
n−1 )
=
2
θ(j,k)
n−1 −θ(i,k)
n−1
⎡
⎢⎣1
θ(i,k)
n
∈

θ(i,k)
n−1 ,
θ(i,k)
n−1 +θ(j,k)
n−1
2


ηc + 1
α
· θ(i,k)
n−1 + θ(j,k)
n−1 −θ(i,k)
n
θ(j,k)
n−1 −θ(i,k)
n−1
ηc
+ 1
θ(i,k)
n
∈

θ(i,k)
n−1 +θ(j,k)
n−1
2
−
1
2(2−α)
1
ηc+1
,θ(i,k)
n−1


ηc + 1
α
· θ(i,k)
n−1 + θ(j,k)
n−1 −θ(i,k)
n
θ(j,k)
n−1 −θ(i,k)
n−1
ηc+2⎤
⎥⎦
We use the cross-over operator with probability pc = 0.7 and a distribution
index ηc = 5. Every element k of the i-th particle vector is crossed with
probability 0.5.
15.3.2.2.3
Polynomial mutation
The mutation operator perturbs elements of the solution, according to the
distance from the boundaries:
θ(i,k)
n
= θ(i,k)
n−1 + ¯δ(θkU −θkL)

SMC-ABC Methods for Estimation of Stochastic Simulation Models
463
where we have for ¯δ:
¯δ =

2γ + (1 −2γ)(1 −δ)ηm+1
1
ηm+1 −1
if γ < 0.5
1 −

2(1 −γ) + 2(γ −0.5)(1 −δ)ηm+1
1
ηm+1
if γ ≥0.5
with
δ = min

θ(i,k)
n
−θkL

,

θkU −θ(i,k)
n

where, γ ∼U(0, 1).
This would produce a mutation kernel for this type of move at SMC sam-
pler iteration n for the k-th element of the i-th particle vector, which would
be updated according to a density given by:
Mn(θ(i,k)
n
|θ(i,k)
n−1) =
1
θkU −θkL
 
1θ(i,k)
n
≤θ(i,k)
n−1
! (ηm + 1)(¯δ + 1)ηm
2(1 −(1 −δ)ηm+1)
"
+
1θ(i,k)
n
>θ(i,k)
n−1
! (ηm + 1)(1 −¯δ)ηm
2(1 −(1 −δ)ηm+1)
"#
The distribution index ηm = 10. The polynomial mutation operator is used
with probability pm = 0.2.
15.3.2.2.4
Covariance mutation operator
In the t-th generation of the MOEA, we generate

Σ(i)
t

, i = 1 . . . N from a
mixture distribution Mn(Σn,i) deﬁned as follows:
Mn(Σ(i)
t ) = (1 −w1)IW(Ψn, p1) + w1IW(Ψ, p2)
where IW denotes the inverse Wishart distribution, p1, p2 are degrees of free-
dom parameters with p2 < p1, and, where w1 is small so that sampling from
the second distribution happens infrequently. Here, Ψ denotes an uninforma-
tive positive deﬁnite matrix, with the eﬀect that sampling from the second
distribution leads to moves away from the local region being explored. Ψt is
also a positive deﬁnite matrix, ﬁtted based on moment matching to the sample
mean of the successfully proposed candidate solutions in the previous stage of
the multi-objective optimisation as follows:
Ψn =
1
n
s=1 ws
n

s=1
ws
1
N
i=1
1
r(i)
s
N

i=1
1
r(i)
s
˜Σ(i)
n
where r(i)
s
is the non-domination rank of the i-th solution in the s-th genera-
tion, and ws with w < 1 is an exponential weighting factor.

464
Handbook of Approximate Bayesian Computation
15.4
Application to Equities Limit Order Book Data:
Data Description
The data employed in this study constitutes the intra-day trading activity
on the European multi-lateral trading facility Chi-X Europe between January
and April 2012. Chi-X Europe operated as an individual entity from 2007,
before being purchased by BATS Europe at the end of the trading period
under consideration. We note that Chi-X Europe is a secondary exchange,
for example, the securities that are traded on the exchange are listed and
primarily traded on national/supranational exchanges, including the London
Stock Exchange, Euronext, Deutsche Boerse, and the SIX Swiss Exchange,
amongst others. However, it maintains a signiﬁcant proportion of the daily
trading activity in each of these markets, between 20% and 35% in most
cases.∗
The complete dataset covers over 1,300 assets, primarily stocks, but also
including exchange-traded funds and American depositary receipts. For the
purposes of this study, we select one of the most commonly traded stocks in
the French CAC 40 Index, namely BNP Paribas SA. Figure 15.2 shows the
evolution of the LOB on a typical day for this asset based on real market ob-
servation data from the LOB. We also present a heatmap of the inside spread
St = P a,1
t
−P b,1
t
over the 2 month period February to March 2012. The inside
spread is the most common measure of ‘liquidity’, for example, the relative
ease with which one can buy or sell a ﬁnancial asset.
Chi-X Europe operates both a visible and a hidden order book, and traders
have the option to route orders to the hidden book, if they meet certain
conditions relating to order type and size. The dataset consists of only data
in the visible book, after it has been processed by the exchange’s matching
engine. That is, while the exchange allows for a range of order types with time-
in-force modiﬁers, the processed data consist of the timestamps and order sizes
of limit order submissions, executions and cancellations. However, this data
are suﬃcient to construct a much more detailed picture of the state of the LOB
than is typically available in previous studies (which only consider aggregate
volume in either the ﬁrst level or the ﬁrst ﬁve levels), as we can disaggregate
the volumes per level up to any depth in the LOB.
The raw, unevenly spaced data are thus used to construct the state of the
LOB at each event timestamp (these are accurate up to millisecond precision).
Because of our interest in ﬁtting the auxiliary models describing price and
volume dynamics (these are outlined in Section 15.5), however, we sub-sample
the process at regular 10 second intervals, in order to then extract the price
and volume variables of interest. Thus, from an irregularly spaced process
∗http://www.liquidmetrix.com/liquidmetrix/battlemap

SMC-ABC Methods for Estimation of Stochastic Simulation Models
465
3,675
(a)
(b)
3,700
3,725
3,750
3,775
3,800
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
1,000
2,000
3,000
Value
0.0
2.5
5.0
7.5
10.0
09:00
12:00
15:00
Time
Spread (cents)
500
1,000
Count
FIGURE 15.2
(a) A representation of real market data intra-day LOB states obtained from
the trading activity for asset BNP Paribas SA on the 5th of March 2012.
The shading of each box indicates the volume available at that price, which
is volume available to buy for light grey-bordered boxes and volume available
to sell for dark grey-bordered boxes. (b) A heatmap of the intra-day spread
for the period February to March 2012 for asset BNP Paribas SA.
typically containing between 50,000 and 500,000 events every day, we extract
a regular timeseries of the auxiliary model variables for the purposes of our
estimation.
15.5
Results
The results presented in this section may be compared to those obtained from
indirect inference procedures as reported in Panayi and Peters (2015). To
achieve comparison we have also provided the results for what they termed
the benchmark ‘reference’ model, which makes a series of assumptions in order
to simplify estimation and model structure.
Benchmark Model Assumptions: The basic reference model is constructed from
the earlier model under the following assumptions, for more details see Section
15.5.1 of Panayi and Peters (2015).
• We assume that the associated limit order submission distributions for the
bid and ask have common parameter value settings. In addition, market
order submission distributions for the bid and ask are also assumed to
have common parameter value settings. This is reasonably consistent with

466
Handbook of Approximate Bayesian Computation
empirical observations for a large number of assets when observing the
submission activity on either side of the LOB throughout the trading day.
• Since the vast majority of orders get cancelled prior to execution, we con-
sider the parameters of the distribution of cancellations to also match the
distribution of limit order placements.
• We also set m = 0 and consider the skewness vector, γ, to take a common
value in all levels of the bid and ask, such that γ = γ1, where 1 is a vector
of ones.
• The monotonic mapping F (·), transforming the random variables ΓLO,k,s,
ΓC,k,s and ΓMO,k into intensity random variables ΛLO,k,s, ΛC,k,s and
ΛMO,k is set as the CDF of the standard normal. This transformation
is necessary in order to ensure that intensities are positive and to bound
the event counts.
• For the baseline intensities of limit order activity at each level, we assume
that they will be the same for the passive limit orders on both sides, for
example, μLO,a,1
0
= · · · = μLO,a,lp
0
= μLO,b,1
0
= · · · = μLO,b,lp
0
= μLO,p
0
,
while aggressive limit orders will have a diﬀerent limit order intensity, for
example, μLO,a,0
0
= · · · = μLO,a,−ld+1
0
= μLO,b,0
0
= · · · = μLO,b,−ld+1
0
=
μLO,d
0
. Market order baseline intensities are also equal on either side, for
example, μMO,a
0
= μMO,b
0
= μMO
0
. The cancellation baseline activity will
be the same as the submission baseline activity.
• Finally, we assume constant order sizes, for example, OLO,k,s
i,t
= c =
OMO,k
j,t
for all i ∈

1, . . . , N LO,k,s
t

, j ∈

1, . . . , N MO,k
t

, k ∈{a, b},
s ∈{−ld + 1, . . . , lp} and t ∈{1, . . . , T}.
This basic reference model has the following parameter vector

μLO,p
0
,
μLO,d
0
, μMO
0
, γ0, ν, σMO
, as well as the covariance matrix Σ to be estimated,
see details in Panayi and Peters (2015). The results will be presented in terms
of the ABC marginal posterior distributions of the individual parameters of
the LOB simulation and in terms of the resulting stochastic agent-based
LOB model to reasonably produce realistic features of the simulated LOB
intra-daily.
In our introduction to likelihood-free methods in Section 15.2.2.1, we dis-
cussed the reduction of the observed data y to a low-dimensional vector of
summary statistics ty. We are interested speciﬁcally in two of the most com-
monly studied LOB characteristics, which correspond to the volatility in the
log returns obtained from the price process dynamic (as obtained from half
the inside spread) and the evolution of the volume resting on the LOB (as
measured by the instantaneous aggregate total volume on the bid and ask
at levels 1 to 5). The summaries we adopt at this stage are less standard in

SMC-ABC Methods for Estimation of Stochastic Simulation Models
467
ABC applications since they employ a functional (i.e. regression model based)
summary of features of observable LOB process. In this case the summary
information becomes the model characterisation (dimensional reduction) cap-
tured by the estimated model parameters ﬁt to the real LOB data and the
simulated LOB data for price or volume dynamic. Speciﬁcally we have:
Auxiliary model 1 - price features: If we denote the mid-price as pmid
t
=
pa,1
t
+pb,1
t
2
, then the log return is deﬁned as
rt = ln pmid
t
pmid
t−Δt
where Δt is a suitable interval, in our case 1 minute. We ﬁt a GARCH(1,1)
model for this aspect of the data parameterised by β1.
Auxiliary model 2 - volume features: We ﬁt an MA(1) model to the detrended
total volume (i.e. an ARIMA(0,1,1) model) in the ﬁrst ﬁve levels on both
the bid and ask side parameterised by β2, in order to capture the time series
structure of the LOB volumes.
The auxiliary models are ﬁt to both the real y and simulated data y∗, and
for the distance, we estimate the Euclidean distances between the auxiliary
parameter vectors
D1 = D

β1 (y) , β1(y∗(θ))

D2 = D

β2 (y) , β2(y∗(θ))

15.5.1
Estimation algorithm conﬁguration
To perform the estimation, there are also a number of inputs to the SMC sam-
pler ABC algorithm that we specify, including the number of particles, the
tolerance schedule forced decrement amount, and the total number of itera-
tions over which to run the estimation. Speciﬁcally, we have for our estimation
procedure:
• The procedure was run for 20 iterations.
• The tolerance schedule employed was the forced decrement schedules spec-
iﬁed in Section 15.3.2.1, with a decrement parameter α = 0.1.
• We obtain results using 50, 100, and 200 particles per iteration.
• We also tested the quality of the results for a series of quantile levels for
the tolerance, for example, q0.5, q0.75, and q0.9.
Carrying out the estimation procedure for each conﬁguration above indicated
that the best results (in terms of the lowest values of D1, D2) were obtained

468
Handbook of Approximate Bayesian Computation
5
10
15
20
0.0
0.5
1.0
1.5
2.0
Iterations
Epsilon
FIGURE 15.3
The adaptively estimated tolerance schedule obtained from multiple SMC
sampler-ABC runs on real data for BNP Paribas on 05/03/2012 speciﬁed in
Section 15.3.2.1.
for a quantile level q0.9 for the tolerance and 200 particles. We repeated the
estimation procedure 20 times with this conﬁguration and the earlier con-
ﬁguration, and Figure 15.3 shows the evolution of the tolerance in the ABC
posterior in the case of the forced tolerance schedule, when the estimation is
run for T = 20 iterations.
We note that the mutation operator for the covariance matrix, speciﬁed in
Section 15.3.2.2, which was composed of both an exploration and a mutation
component, could lead to particle degeneracy in higher dimensions. Conse-
quently, in practice, it can be computationally more eﬃcient to simplify the
mutation kernel for the covariance matrix to a static mutation kernel, which
would eliminate the prior weighting in the numerator and denominator of each
incremental particle weight. When this was performed, it produced particle
systems with less degeneracy issues in higher dimensions.
Secondly, due to the nature of the crossover operator, it is possible for a
particle to cross with an identical particle, for example, if the two particles
were produced in the re-sampling step of the previous iteration. In our esti-
mation, we explicitly exclude this possibility and, where a particle is chosen
to cross with an identical particle, it is instead mutated using the operator
speciﬁed in Section 15.3.2.2.
15.5.2
Final particle ﬁtness and distributions of
parameters
Having run the SMC sampler-ABC algorithm on the BNP Paribas LOB data
for 05/03/2012, we obtained estimates of the posterior for the agent-based
LOB simulation model. The ﬁrst set of results shows the accuracy of the LOB
model to replicate features of the real LOB stochastic process relating to price

SMC-ABC Methods for Estimation of Stochastic Simulation Models
469
0.00
0.25
0.50
0.75
1.00
0.00
0.25
0.50
0.75
1.00
Auxiliary function 1 distance
Auxiliary function 2 distance
0.00
0.25
0.50
0.75
1.00
0.00
0.25
0.50
0.75
1.00
Auxiliary function 1 distance
Auxiliary function 2 distance
Weights
0.05
0.10
0.15
Weights
0.04
0.08
0.12
0.16
FIGURE 15.4
The realised objective function (distance metrics D1 and D2) values from
each particle in the SMC Sampler-ABC algorithm at the ﬁnal iteration for
independent trials on the real data for BNP Paribas on 05/03/2012. The x axis
is the GARCH(1,1) model parameter distance discrepancies for the intra-day
volatility dynamic of the price process. The y axis is the ARIMA(0,1,1) model
parameter distance discrepancies for the intra-day volume process dynamics.
and volume dynamics. This is clearly illustrated in Figure 15.4 in terms of the
values of the objective functions D1, D2 for each of the particles at the ﬁnal
iteration stage of the SMC sampler-ABC algorithm. This is the standard way
in which results for optimisation using MOEAs are presented [see discussion
in Panayi and Peters (2015)], in order to show the Pareto optimal front that
is obtained in that setting, see the discussion in the Section 15.5.3.
We also present realisations of the LOB intra-day evolution for both the
particle with the highest weight and the weighted mean of the particles in
Figure 15.5. We note that there are diﬀerences in the intra-day dynamics
of the simulated ﬁnancial market resulting from diﬀerent repetitions of the
estimation procedure. However, we note that for a subset of particles, we
can recover price and volume dynamics that are similar to those observed
in the real market (an example of which we had seen in Figure 15.2). In
Figure 15.6 we present examples of the simulated LOB order books from
two posterior estimators, the mode Maximum a-posteriori (MAP) estimators
and the mimimum mean squared error (MMSE) posterio mean estimators.
Furthermore, we also present in Figure 15.7 heat maps of the solutions for the
intra day spreads simulated from the LOB solutions.
To complete the analysis, we also illustrate the median of the resulting
marginal posterior distributions for the model parameters obtained from 20
independent runs of the SMC sampler-ABC algorithm for the BNP Paribas
data on 05/03/2012. These results are presented in Figure 15.8.

470
Handbook of Approximate Bayesian Computation
3,450
3,460
3,470
3,480
3,490
3,500
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
1,000
2,000
3,000
4,000
Value
3,500
3,505
3,510
3,515
3,520
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
1,000
2,000
3,000
4,000
Value
3,460
3,480
3,500
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
500
1,000
1,500
Value
3,470
3,480
3,490
3,500
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
500
1,000
1,500
2,000
Value
FIGURE 15.5
Representations of simulated intra-day LOB states obtained from using
the (Top): Maximum a-posteriori (MAP) particle from a single estimation
procedure and (Bottom): Minimum Mean Squared Error (MMSE) particle
estimates.
15.5.3
Results comparison to multi-objective evolutionary
algorithm-II procedure
The method introduced in Panayi and Peters (2015) is a combination of
simulation-based
indirect
inference
(II)
and
multi-objective
optimisa-
tion,
denoted
the
‘multi-objective-II
estimation
framework’.
In
com-
mon with ABC, II is used when one cannot write down the like-
lihood
of
the
data
generating
model
in
closed
form,
but
realisa-
tions
are
easily
obtained
via
simulation
given
model
parameters
θ.
II introduces a new, ‘auxiliary’ model (with parameter vector β), which is ﬁt
to a transform of both the real and simulated data [y and y∗(θ), respectively]
and the objective is to ﬁnd the model parameter vector ˆθ, which minimises
some distance metric D(β(y), β(y∗(θ)).

SMC-ABC Methods for Estimation of Stochastic Simulation Models
471
3,470
3,480
3,490
3,500
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
2,000
4,000
6,000
Value
3,500
3,520
3,540
3,560
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
1,000
2,000
3,000
4,000
Value
3,450
3,500
3,550
3,600
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
1,000
2,000
3,000
4,000
Value
3,400
3,450
3,500
3,550
09:00
12:00
15:00
Time
Price (cents)
Side
Ask
Bid
1,000
2,000
3,000
Value
FIGURE 15.6
Representations of simulated intra-day LOB states obtained from using the
(Top): MAP particle from a single estimation procedure and (Bottom): MMSE
particle estimates.
0.0
(a)
(b)
2.5
5.0
7.5
10.0
09:00
12:00
15:00
Time
Spread (cents)
100
200
300
400
Count
0.0
2.5
5.0
7.5
10.0
09:00
12:00
15:00
Time
Spread (cents)
100
200
300
Count
FIGURE 15.7
Heatmaps of the intra-day value of the spread for (a) The MAP particle from
the estimation procedure and (b) MMSE particle estimates.

472
Handbook of Approximate Bayesian Computation
10
20
30
40
50
0.0
0.2
0.4
0.6
0.8
1.0
Parameter 1
CDF
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
1.0
Parameter 2
CDF
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
1.0
Parameter 3
CDF
−5
0
5
10
0.0
0.2
0.4
0.6
0.8
1.0
Parameter 4
CDF
0
10
20
30
40
50
0.0
0.2
0.4
0.6
0.8
1.0
Parameter 5
CDF
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
1.0
Parameter 6
CDF
FIGURE 15.8
Median of the CDFs for every iteration of the estimation procedure for the
parameters of the model. In the ﬁgures, parameters 1 to 6 correspond to

μLO,p
0
, μLO,d
0
, μMO
0
, γ0, ν, σMO
, respectively.

SMC-ABC Methods for Estimation of Stochastic Simulation Models
473
The multi-objective extension to the standard II procedure pertains to the
objective function D(β(y), β(y∗(θ)). Where standard II procedures consider
a scalar output of the objective function, the multi-objective-II method con-
siders a vector-valued output, where each element of the vector pertains to a
diﬀerent feature of the LOB stochastic process. In this framework, the search
is then for non-dominated parameter vectors, for examples, such that there
is no parameter vector in the search space that can unilaterally improve a
single criterion (objective function element) without worsening another crite-
rion. The procedure uses the same mutation and cross-over kernels outlined
in Section 15.3.2.2 and outputs a set of Pareto optimal solutions, see details
in Panayi and Peters (2015).
Where the SMC-ABC method returns a family of particles and associ-
ated weights, the MOEA-II procedure returns a family of particles and their
non-domination rank. Our comparison is then between the highest weighted
particles returned from the former procedure, and the non-dominated particles
returned from the latter. The results have been found to be comparable be-
tween the two methods, both in terms of achieving similar objective function
values and in terms of producing simulations which resemble real ﬁnancial
markets. That is, while not all highest weight/non-dominated particles will
give rise to realistic ﬁnancial market simulations, there is a subset that do.
While we have tried to provide a fair comparison between the two meth-
ods by utilising the same mutation and cross-over operators, we should high-
light some diﬀerences between the MOEA-II procedure and the SMC-ABC
procedure presented in this paper. Firstly, the MOEA-II procedure did not
suﬀer from particle degeneracy when using the adaptive mutation kernel for
the covariance mutation operator, and, thus, the operator in Section 15.3.2.2
was utilised as described. Secondly, where the probability of crossover be-
tween particles in the MOEA-II procedure was set at the default value of
0.7 in every iteration, this was found to cause additional particle degener-
acy issues and, thus, the probability was reduced to 0.05 (with the addi-
tional exclusion of crossing with identical particles described at the front of
this section).
In addition to these practical implementation considerations, the studies
performed also demonstrated several structural features for the Bayesian LOB
model when we applied the reference ‘Benchmark Model’ from Panayi and
Peters (2015). For instance, under the benchmark model parameterisation, we
found that the Bayesian formulation was able to reproduce LOB daily proﬁles
from MAP or MMSE posterior parameter estimates, which were consistent
with those that one observes in real LOB activity in a trading day. This
gives us conﬁdence that even with the least ﬂexible family of models in our
speciﬁed Bayesian LOB model class, we can capture sensible dynamics for the
LOB when calibrated to real market data and then used to simulate a LOB.
In addition, the particles that were on the leading ﬁrst and second eﬃcient
frontiers and weighted reasonably, when used to simulate the dynamics of the

474
Handbook of Approximate Bayesian Computation
LOB, were also producing implied mid price dynamics and liquidity proﬁles
based on bid and ask volumes commensurate with those one can observe in
practice. This tells us that we can deﬁnitely start to consider such models for
applications, such as market simulators for testing market trading, execution,
and market making strategies.
15.6
Conclusion
This chapter has proposed a stochastic agent-based liquidity supply and
demand-based simulation model to characterise the LOB for an asset traded
on an electronic exchange. The calibration of this model to real market LOB
data has been performed via a posterior inference procedure that adopted an
ABC structure due to the complexity of writing down the resulting likelihood
for the LOB agent simulation model. The estimation of the posterior distribu-
tion was then shown how to be performed via an adaptive SMC sampler-ABC
algorithm. The results were tested on real data and compared to an indirect
inference procedure with multi-objective optimisation features.
Such a model is important for many applications in high frequency ﬁnance
which require the ability to calibrate a realistic model to the LOB stochastic
process on a daily basis. These types of models will ﬁnd important appli-
cations in better understanding and assessing performance of trade strategy
selection and risk assessment, brokerage strategy design, regulation impacts,
and so on. To date, no realistic LOB simulation frameworks have been de-
veloped that take into account the complete structure of the LOB stochastic
process from a constructive and interpretable approach. In this chapter, we
have developed such a structure through a representative agent-based model
that incorporates modern market participants that one ﬁnds in both primary
and secondary MTF electronic exchanges, such features include the presence
of two representative types of agent, the liquidity providers and the liquidity
demanders. Each such representative agent has the ability to place passive
and aggressive limit orders, as well as cancellations and market orders with
each such order type having an associated bid or ask tick level and volume.
The representative agents are modelled via a stochastic process rather than
a simple set of heuristic rules, typically utilised in other agent-based models.
The outputs of the stochastic models for each agent then operate in a mecha-
nistic manner, as would typically occur in agent models to produce an update
to the LOB being simulated.
Since the agent model we adopt is not based on the typical framework
of many agents interacting with simple heuristic rules, but instead, we have a
small set of representative agent populations, each characterised by a stochas-
tic model structure, this model can be calibrated in a statistical manner.

SMC-ABC Methods for Estimation of Stochastic Simulation Models
475
This is an important advantage that the SMC-ABC methodology allows one
to undertake calibration and estimation of the representative agent model for
the LOB in a structured and rigorous manner, unlike typical approaches to
calibration of agent models in the literature. This is where the application
of ABC is critical, typically, the agent models have simple heuristic calibra-
tions because the models are too complex to do formal inference, we believe
that the representative agent-based stochastic models we have developed ﬁnd
a compromise between the attributes an agent model provides and the abil-
ity to rigorously calibrate such models. It is precisely the ability to read-
ily simulate realisations of the order book structure from our parameterised
stochastic agent models, without having to write the likelihood which would
be intractable, that makes it so amenable to ABC-based statistical inference.
Overall, the chapter has demonstrated that even with a simpliﬁed bench-
mark version of the Bayesian LOB simulation model proposed, it can be ﬁtted
accurately to diﬀerent observed LOB regimes on a daily basis via the method-
ology of SMC-ABC. In particular, we have demonstrated that the utilisation
of model-based summary proﬁles of mid price/returns and the volume proﬁle
based LOB summaries carry suﬃcient information to make for accurate prac-
tical calibrations of an ABC model on real LOB equity data. In the future, it
would be important to further extend these characteristic features/summary
models/summary statistics of the observed LOB for use in the SMC-ABC
calibration and simulation.
There are numerous future extensions that could be made to this model
with regard to the application, the methodology, and the study of the model
attributes. We mention a few next. One such class of extensions of this work
could seek to combine the attributes of multi-objective optimisation solutions
with those of the SMC-ABC-based solution. For instance, it would be prac-
tically useful to develop a probabilistic representation of particles on Pareto-
dominated eﬃcient frontiers based on each of the objective functions developed
for assessing a multi-objective optimisation criterion in the LOB simulation
characterisation. Such a combined representation would allow for volume, liq-
uidity, and price-based LOB features to be more readily discerned in their
contribution to the particle weights and probabilitistic representations. In
addition, we believe it would allow for more appropriate probabilistic choice of
points on the frontier, which can then be used in these applications for simula-
tion, scenario analysis, and forecasting. The ability to probabilisitically under-
take these tasks is beneﬁcial for many applications in ﬁnancial mathematics
requiring accurate LOB simulation frameworks, these include assessment of
trading strategies, assessment and development of market making strategies,
exchanges can assess performance statistically of market making behaviours
of designated sponsors to decide renumeration and compensation for such risk
taking activities, assessment of regulatory impacts under new clearing and
exchange regulations from central banks, and of course assessment of optimal
execution and brokerage strategies in diﬀerent market regimes.

476
Handbook of Approximate Bayesian Computation
Other future extensions to the agent model that would be of relevance
to extending this framework would be to include additional order types such
as iceberg orders, ﬁll or kill orders, and so on. In addition, features such as
tick size change at diﬀerent price levels of the mid would be important to
incorporate for practical extensions. In addition, it would be important in
some applications to have a combination of continous trading models, as well
as auction mechanisms built into the model. This would align with features ob-
served in real electronic exchanges, such as Xetra, where they oﬀer a range of
specialised trading models adapted to the needs of its various trading groups,
as well as the diﬀerent assets classes. The models diﬀer according to: mar-
ket type (e.g. number of trading parties); the transparency level of available
information pre- and post-trade; the criteria of the order prioritisation; price
determination rules; and the form of order execution. For equity trading, the
following trading models are supported: continuous trading in connection with
auctions (e.g. opening and closing auction, and possibly, one or more intra-day
auctions); mini-auction in connection with auctions; and one or more auctions
at pre-deﬁned points in time. Future extensions will seek to explore aspects
of these components in the simulation based LOB models.
References
Beaumont, M. A., J.-M. Cornuet, J.-M. Marin, and C. P. Robert. Adaptive
approximate Bayesian computation. Biometrika, 96(4):983–990, 2009.
Beaumont, M. A., W. Zhang, and D. J. Balding. Approximate Bayesian com-
putation in population genetics. Genetics, 162(4):2025–2035, 2002.
Blum, M. G. B. Approximate Bayesian computation: A nonparametric per-
spective. Journal of the American Statistical Association, 105(491):1178–
1187, 2010.
Blum, M. G. B. and O. Fran¸cois. Non-linear regression models for approximate
Bayesian computation. Statistics and Computing, 20(1):63–73, 2010.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson. A comparative
review of dimension reduction methods in approximate Bayesian computa-
tion. Statistical Science, 28(2):189–208, 2013.
Bornn, L., N. Pillai, A. Smith, and D. Woodard. The use of a single
pseudo-sample in approximate Bayesian computation. arXiv preprint
arXiv:1404.6298, 2014.

SMC-ABC Methods for Estimation of Stochastic Simulation Models
477
Chopin, N. A sequential particle ﬁlter method for static models. Biometrika,
89(3):539–552, 2002.
Chopin, N. Central limit theorem for sequential Monte Carlo methods and
its application to Bayesian inference. Annals of statistics, 32(6):2385–2411,
2004.
Cont, R. and A. De Larrard. Price dynamics in a Markovian limit order
market. SIAM Journal on Financial Mathematics, 4 (1):1–25, 2013.
Cont, R., S. Stoikov, and R. Talreja. A stochastic model for order book
dynamics. Operations Research, 58(3):549–563, 2010.
Crisan, D. and A. Doucet. A survey of convergence results on particle ﬁl-
tering methods for practitioners. IEEE Transactions on Signal Processing,
50(3):736–746, 2002.
Deb, K., A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multi-
objective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary
Computation, 6(2):182–197, 2002.
Del Moral, P. Feynman-Kac Formulae. Springer, New York, 2004.
Del Moral, P., A. Doucet, and A. Jasra. Sequential Monte Carlo samplers.
Journal of the Royal Statistical Society: Series B (Statistical Methodology),
68(3):411–436, 2006.
Del Moral, P., A. Doucet, and A. Jasra. An adaptive sequential Monte Carlo
method for approximate Bayesian computation. Statistics and Computing,
22(5): 1009–1020, 2012.
Doucet, A., N. De Freitas, and N. Gordon. An Introduction to Sequential
Monte Carlo Methods. Springer, New York, 2001.
Fan, Y., D. J. Nott, and S. A. Sisson. Approximate Bayesian computation via
regression density estimation. Stat, 2(1):34–48, 2013.
Fearnhead, P. and D. Prangle. Constructing summary statistics for appr-
oximate Bayesian computation: Semi-automatic ABC. arXiv preprint
arXiv:1004.1112, 2010.
Fearnhead, P. and D. Prangle. Constructing summary statistics for appr-
oximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society: Series B (Statisti-
cal Methodology), 74(3):419–474, 2012.
Fricke, D. and T. Lux. The eﬀects of a ﬁnancial transaction tax in an arti-
ﬁcial ﬁnancial market. Journal of Economic Interaction and Coordination,
10(1):119–150, 2015.

478
Handbook of Approximate Bayesian Computation
Garbade, K. D. and K. Garbade. Securities Markets. McGraw-Hill, New York,
1982.
Gould, M. D., M. A. Porter, S. Williams, M. McDonald, D. J. Fenn, and S. D.
Howison. Limit order books. Quantitative Finance, 13(11):1709–1742, 2013.
Harris, L. Trading and Exchanges: Market Microstructure for Practitioners.
Oxford University Press, Oxford, UK, 2003.
K¨unsch, H. R. Recursive Monte Carlo ﬁlters: Algorithms and theoretical anal-
ysis. Annals of Statistics, 33(5):1983–2021, 2005.
Kyle, A. S. Continuous auctions and insider trading. Econometrica: Journal
of the Econometric Society, 53:1315–1335, 1985.
Li, H. and Q. Zhang. Multiobjective optimization problems with complicated
Pareto sets, MOEA/D and NSGA-II. IEEE Transactions on Evolutionary
Computation, 13(2):284–302, 2009.
LiCalzi, M. and P. Pellizzari. Fundamentalists clashing over the book: A study
of order-driven stock markets. Quantitative Finance, 3(6):470–480, 2003.
Marjoram, P., J. Molitor, V. Plagnol, and S. Tavar´e. Markov chain Monte
Carlo without likelihoods. Proceedings of the National Academy of Sciences,
100(26):15324–15328, 2003.
Maslov, S. Simple model of a limit order-driven market. Physica A: Statistical
Mechanics and its Applications, 278(3):571–578, 2000.
Neal, R. M. Annealed importance sampling. Statistics and Computing,
11(2):125–139, 2001.
Nunes, M. A. and D. J. Balding. On optimal selection of summary statistics
for approximate Bayesian computation. Statistical Applications in Genetics
and Molecular Biology, 9(1):1–16, 2010.
Obizhaeva, A.A. and J. Wang. Optimal trading strategy and supply/demand
dynamics. Journal of Financial Markets, 16(1):1–32, 2013.
O’hara, M. Market Microstructure Theory, Volume 108. Blackwell, Cambridge,
MA, 1995.
Panayi, E. and G. W. Peters. Stochastic simulation framework for the Limit
Order Book using liquidity motivated agents. Available at SSRN 2551410,
2015.
Panayi, E., G. W. Peters, J. Danielsson, and J.-P. Zigrand. Designating
market maker behaviour in limit order book markets. arXiv preprint
arXiv:1508.04348, 2015a.

SMC-ABC Methods for Estimation of Stochastic Simulation Models
479
Panayi, E., G. W. Peters, and I. Kosmidis. Liquidity commonality does
not imply liquidity resilience commonality: A functional characterisation
for ultra-high frequency cross-sectional lob data. Quantitative Finance,
15(10):1737–1758, 2015b.
Peters, G. W. Topics in sequential Monte Carlo samplers. M.Sc, University of
Cambridge, Department of Engineering, 2005.
Peters, G. W., Y. Fan, and S. A. Sisson. On sequential Monte Carlo, par-
tial rejection control and approximate Bayesian computation. Statistics and
Computing, 22(6): 1209–1222, 2012a.
Peters, G. W., S. A. Sisson, and Y. Fan. Likelihood-free Bayesian inference for
α-stable models. Computational Statistics & Data Analysis, 56(11):3743–
3756, 2012b.
Peters, G. W., M. V. W¨uthrich, and P. V. Shevchenko. Chain ladder method:
Bayesian bootstrap versus classical bootstrap. Insurance: Mathematics and
Economics, 47(1):36–51, 2010.
Ratmann, O., C. Andrieu, C. Wiuf, and S. Richardson. Model criticism based
on likelihood-free inference, with an application to protein network evo-
lution. Proceedings of the National Academy of Sciences, 106(26):10576–
10581, 2009.
Reeves, R. W. and A. N. Pettitt. A theoretical framework for approximate
Bayesian computation. Proceedings of the 20th International Workshop Sta-
tistical Modelling, Sydney, Australia, pp. 393–396, 2005a.
Ristic, B., S. Arulampalam, and N. Gordon. Beyond the Kalman Filter: Par-
ticle Filters for Tracking Applications, Volume 685. Artech house, Boston,
MA, 2004.
Sisson, S. A., Y. Fan, and M. M. Tanaka. Sequential Monte Carlo without
likelihoods. Proceedings of the National Academy of Sciences, 104(6):1760–
1765, 2007.
Smith, M. S., Q. Gan, and R. J. Kohn. Modelling dependence using skew t
copulas: Bayesian inference and applications. Journal of Applied Economet-
rics, 27(3): 500–522, 2012.
Targino, R. S., G. W. Peters, and P. V. Shevchenko. Sequential Monte Carlo
Samplers for capital allocation under copula-dependent risk models. Insur-
ance: Mathematics and Economics, 61(1):206–226, 2015.
Toni, T., D. Welch, N. Strelkowa, A. Ipsen, and M. P. H. Stumpf. Approximate
Bayesian computation scheme for parameter inference and model selection
in dynamical systems. Journal of the Royal Society Interface, 6(31):187–202,
2009.

480
Handbook of Approximate Bayesian Computation
US Securities, Exchange Commission, the Commodity Futures Trading Com-
mission et al. Findings regarding the market events of May 6, 2010. Report
of the Staﬀs of the CFTC and SEC to the Joint Advisory Committee on
Emerging Regulatory Issues, 2010.
Wilkinson, R. D. Approximate Bayesian computation (ABC) gives exact
results under the assumption of model error. Statistical Applications in
Genetics and Molecular Biology, 12(2):129–141, 2013.

16
Inferences on the Acquisition of Multi-Drug
Resistance in Mycobacterium Tuberculosis
Using Molecular Epidemiological Data
Guilherme S. Rodrigues, Andrew R. Francis, S. A. Sisson,
and Mark M. Tanaka
CONTENTS
16.1
Introduction ......................................................
482
16.2
Data ..............................................................
484
16.3
Model .............................................................
485
16.3.1
New infections ...........................................
490
16.3.2
Cure, recovery, and death ...............................
492
16.3.3
Detection and treatment ................................
492
16.3.4
Acquisition of drug resistance ...........................
493
16.3.5
Mutation of the marker .................................
494
16.3.6
Initial conditions of the model ..........................
495
16.4
Inference with Approximate Bayesian Computation ............
496
16.4.1
Summary statistics ......................................
498
16.4.2
Parameter speciﬁcations and prior distributions
.......
499
16.5
Competing Models of Resistance Acquisition
...................
501
16.5.1
Can resistance to both drugs be acquired
simultaneously? .........................................
503
16.5.2
Is resistance to both drugs acquired at equal rates?
...
504
16.5.3
The relative contribution of transmission and treatment
failure to multi-drug–resistant tuberculosis ............
505
16.6
Conclusions .......................................................
506
Acknowledgements .......................................................
508
References
...............................................................
508
481

482
Handbook of Approximate Bayesian Computation
16.1
Introduction
Tuberculosis (TB) is a lung disease caused by the bacterium Mycobacterium
tuberculosis, which kills around 1.5 million people each year and remains a
serious challenge for global public health (WHO, 2015). Antibiotic drugs for
treating TB have been available since the mid twentieth century, and cur-
rently implemented strategies for TB control rely on the eﬃcacy of these
drugs. Treatment of TB involves combination therapy – in which multiple
drugs are administered together in part to improve killing eﬃcacy. The ‘ﬁrst-
line’ drugs used in combination to treat tuberculosis are rifampicin, isoniazid,
pyrazinamide, ethambutol, and streptomycin.
As with most other pathogens, resistance to antibiotic drugs has rapidly
evolved in M. tuberculosis. Streptomycin was the ﬁrst of the ﬁrst-line drugs to
be developed and deployed in 1943, but resistance was observed before the end
of that decade (Mitchison, 1951; Gillespie, 2002). Of particular concern is the
rise of bacterial strains resistant to multiple drugs, as cases caused by them
are diﬃcult to treat successfully. Multidrug resistance (MDR) is deﬁned as
resistance to both rifampicin and isoniazid. These are the two most eﬀective
drugs against tuberculosis (when the strain is not resistant). Currently, 3.3% of
new TB cases are multi-drug resistant (WHO, 2015). The occurrence of MDR-
TB strains that have additional resistance (called extensively drug resistant
and totally drug resistant) are particularly problematic and have the potential
to cause large outbreaks that are diﬃcult to control (Gandhi et al., 2006).
A better understanding of how multiple drug resistance evolves would aid
eﬀorts to contain resistance and control tuberculosis.
Genetic studies have established that many independent mutation events
have led to resistance (Ramaswamy and Musser, 1998). Although this suggests
that mutation of genes is an important source of resistance, model-based anal-
ysis of molecular data has revealed that among resistant cases, most are due
to the transmission of already-resistant bacteria (Luciani et al., 2009). It is
therefore of interest to investigate whether or not this ﬁnding also holds for
multi-drug resistant tuberculosis.
The rates at which resistance evolves against diﬀerent drugs vary. For
instance, isoniazid resistance is known to be acquired faster than rifampicin re-
sistance (Ford et al., 2013; Gillespie, 2002; Nachega and Chaisson, 2003). The
rates of mutation to resistance per cell generation are low in absolute value,
for example, for isoniazid, the rate is around 3 × 10−8 and for rifampicin, it is
around 2×10−10 (David, 1970; Gillespie, 2002), although there is a high degree
of variation across diﬀerent lineages of M. tuberculosis (Ford et al., 2013). One
might therefore expect that double resistance of these drugs (MDR) evolves
at an exceedingly low rate (Nachega and Chaisson, 2003). However, MDR
strains often occur at appreciable frequencies (Zhao et al., 2012; Anderson
et al., 2014), and a recent study has presented a theoretical model showing
how double resistance can evolve rapidly within hosts (Colijn et al., 2011).

Inferences on the Acquisition of Multi-Drug Resistance
483
Vij
Vij + 1
Vij − 1
Example
2 5 3 5 3 3 2 3 3 4 3 3 3 2 7
2 5 3 5 3 3 2 3 3 4 3 3 4 2 7
FIGURE 16.1
Variable numbers of tandem repeats (VNTRs) loci mutate in a stepwise man-
ner so that the number of repeat units at a locus increases or decreases. In
our analysis, we assume that when mutation occurs at a locus j in genotype
i, the repeat number Vij increases or decreases by a single copy. We further
assume that a single unit (repeat number of 1) is an absorbing boundary. The
hypothetical example shows how mutation at locus number 13 creates a new
VNTR genotype.
It would be useful to establish whether such fast direct acquisition of double
resistance can be detected in bacterial isolates from epidemiological studies.
To characterise patterns of TB transmission and drug resistance in a given
geographic region, bacterial isolates from TB patients are often genotyped
using molecular markers known as variable numbers of tandem repeats (VN-
TRs), which are repeated genetic sequences that exhibit variation across iso-
lates. The source of this variation is mutation at the VNTR genetic loci,
which leads to the expansion or contraction of repeat numbers at those
loci (Figure 16.1). A scheme for discriminating eﬀectively among a set of
isolates involves considering repeat numbers at multiple VNTR sites. This
molecular typing scheme is called multi-locus VNTR analysis; in the context
of tuberculosis epidemiology, it is often known as mycobacterial interspersed
repetitive units-VNTR (Mazars et al., 2001; Supply et al., 2006). Typing tech-
niques such as MLVA have been useful for tracking particular strains and
understanding how drug resistance evolves and disseminates at the epidemio-
logical level (Monteserin et al., 2013; Anderson et al., 2014).
Here, we investigate the rates of drug resistance acquisition in a natu-
ral population using molecular epidemiological data from Bolivia (Monte-
serin et al., 2013). First, we study the rate of direct acquisition of double
resistance from the double sensitive state within patients and compare it
to the rates of evolution to single resistance. In particular, we address
whether or not double resistance can evolve directly from a double sensi-
tive state within a given host. Second, we aim to understand whether the
diﬀerences in mutation rates to rifampicin and isoniazid resistance trans-
late to the epidemiological scale. Third, we estimate the proportion of
MDR TB cases that are due to the transmission of MDR strains compared
to acquisition of resistance through evolution. To address these problems,
we develop a model of TB transmission in which we track the evolution

484
Handbook of Approximate Bayesian Computation
of resistance to two drugs and the evolution of VNTR loci. However,
the available data (see Section 16.2) is incomplete, in that it is recorded
only for a fraction of the population and at a single point in time. The
likelihood function induced by the proposed model is computationally pro-
hibitive to evaluate and accordingly impractical to work with directly.
We therefore approach statistical inference using approximate Bayesian com-
putation techniques.
16.2
Data
The dataset we use is taken from a study of tuberculosis in Bolivia (Monteserin
et al., 2013). Bolivia has a population of 11 million people and a TB incidence
of 120 per 100,000 per year. This rate is comparable to the global incidence of
TB (133 per 100,000 per year) and to the rate in Peru, but is 3–6 times the TB
incidence in neighbouring countries Brazil, Paraguay, Uruguay, Argentina, and
Chile (WHO, 2015). In the molecular epidemiological study, the investigators
genotyped 100 isolates collected in 2010, which represented an estimated 1.1%
of the cases in Bolivia at the time of the study (Monteserin et al., 2013).
Each isolate was tested for drug sensitivity to ﬁve drugs. Here, we focus on
resistance against the two drugs isoniazid and rifampicin used to deﬁne multi-
drug resistance. Of the 100 isolates, 14 were found to be MDR, that is, resistant
to both of these drugs, 78 were sensitive to both drugs and the remaining
8 were resistant to isoniazid, but sensitive to rifampicin. No isolates were
resistant to rifampicin while being sensitive to isoniazid.
In addition to these drug resistance proﬁles, each isolate was genotyped
using 15 VNTR loci. For example, an isolate in the dataset, which was re-
sistant to isoniazid, but sensitive to rifampicin, had the following 15 repeat
numbers for its 15 VNTR loci: 143533233433527, which together constitute its
genotype. Variation in these genotypes occurs through a process of mutation
in which repeat numbers increase or decrease (see Figure 16.1).
Let g be the number of distinct genotypes present in a sample, and label the
resistance proﬁles by (0, INH, RIF, MDR), where 0 denotes sensitivity to both
drugs, INH denotes resistance to isoniazid and sensitivity to rifampicin, RIF
denotes resistance to rifampicin and sensitivity to isoniazid, and MDR denotes
resistance to both drugs. The observed data Xobs are then a g × 4 matrix of
counts, such that each row gives the distribution of isolates across the four
resistance proﬁles for a given genotype and each column gives the distribution
of isolates across genotypes for a given resistance proﬁle. The sum of entries in
a particular row is the number of isolates with that genotype, while the sum
of entries in a particular column is the number of isolates with that resistance
proﬁle. The dataset also includes a g × 15 matrix of repeat numbers from the
VNTR genotyping.

Inferences on the Acquisition of Multi-Drug Resistance
485
The Bolivian dataset is displayed in full in Table 16.1, which shows all
g = 66 distinct genotypes and classiﬁes all 100 isolates according to genotype
and resistance proﬁle. The Xobs matrix is formed by combining the 0, INH,
RIF, and MDR columns.
16.3
Model
In this section, we introduce a model that incorporates both VNTR-based
genotyping and drug resistance states. The dynamic variables of the model
correspond to numbers of cases of untreated and treated tuberculosis, their
resistance states, and VNTR genotypes associated with these infections in the
population. We will now brieﬂy describe processes involved in the model and
provide further details in the following subsections.
An untreated case of TB can become detected and treated, and treatment
involves a combination of drugs including the two in question. Drug sensi-
tive strains can acquire resistance under treatment with some probability and
thereby change their resistance state. Treated and untreated cases can infect
susceptible individuals and convert them to untreated cases. We disregard la-
tent infections for simplicity (although latency is an important feature of the
natural history of tuberculosis) and focus on active infections which are the
larger source of new infections. Treated and untreated individuals can also
recover or die. Treated individuals enjoy an additional probability of recovery
that depends on the eﬃcacy of the drugs, which in turn depends on the sen-
sitivity or resistance of the infecting strain. Treated and untreated cases are
also associated with a VNTR genotype, and this genotype evolves over time
according to a stepwise mutation process for each locus. Figure 16.2 shows the
broad structure of the model with respect to treatment and resistance states,
while suppressing details of transmission, recovery, death, and mutation of the
VNTR loci.
At the end of the period of evolution, a simple random sample of
100 isolates is taken without replacement from the population, which matches
the sample size of the Bolivian dataset. The following provides a full descrip-
tion of the generative process for the observable data.
Let G be the number of distinct genotypes in the population (the number
of distinct genotypes in the sample is g) and L be the number of VNTR loci
used in the genotyping scheme. For the Bolivian dataset L = 15. In the model,
the variable G is unknown and varies dynamically. We maintain three matrices
which change through time: a G × L matrix, V, which describes the VNTR
genotypes; a G×4 matrix, U, which describes the numbers of untreated cases of
tuberculosis classiﬁed according to VNTR genotype and resistance state; and
a G×4 matrix T, which describes the numbers of treated cases of tuberculosis,
again classiﬁed according to VNTR genotype and resistance state. It will be

486
Handbook of Approximate Bayesian Computation
TABLE 16.1
Molecular Dataset Compiled from Monteserin et al. (2013)
Genotype
0
INH
RIF
MDR
Genotype
0
INH
RIF
MDR
253533233433427
4
0
0
0
243413342212437
1
0
0
0
253533233433327
3
0
0
0
233312442212437
1
0
0
0
253533233433527
11
1
0
0
233313441212437
1
0
0
0
253533233433525
3
0
0
0
233413442212248
1
0
0
0
143533233433527
2
1
0
0
233413442212249
1
0
0
0
253333244232232
1
0
0
0
233213442212349
1
0
0
0
25333324423-232
1
0
0
0
231413542212335
1
0
0
0
254333243232342
0
2
0
2
232433242212436
1
0
0
0
263532232423139
3
0
0
0
234413442212436
1
0
0
0
223413442212437
2
0
0
0
434433452212427
1
0
0
0
233413542212347
0
1
0
2
256432342122237
2
1
0
0
244333244232332
0
0
0
1
256433342123236
2
0
0
0
244333244232322
1
0
0
0
247432342122136
1
0
0
0
245333244242332
1
0
0
0
268432252122227
0
1
0
0
254333244232232
0
0
0
1
268632252122227
1
0
0
0
254333244232332
1
0
0
0
221313352122338
0
0
0
1
254333244242332
1
0
0
0
263532233423148
1
0
0
0
253333244242232
1
0
0
0
360332233423138
1
0
0
0
252333243232232
0
0
0
1
263513233523344
1
0
0
0
252333243232332
0
0
0
1
253523233433527
1
0
0
0
251333243242332
1
0
0
0
253533232433527
1
0
0
1
(Continued)

Inferences on the Acquisition of Multi-Drug Resistance
487
TABLE 16.1 (Continued)
Molecular Dataset Compiled from Monteserin et al. (2013)
Genotype
0
INH
RIF
MDR
Genotype
0
INH
RIF
MDR
252333243262222
0
0
0
1
253533232433427
1
0
0
0
244233234222322
1
0
0
0
253523133433527
1
0
0
0
233373242232325
1
0
0
0
253533133433527
1
0
0
0
252343242232524
1
0
0
0
353533233433427
0
0
0
1
25233234423251a
1
0
0
0
253533233433837
1
0
0
0
35234234423251a
1
0
0
0
253533233433237
1
0
0
0
233413442212338
0
1
0
0
254533233433537
0
0
0
1
233413442212335
1
0
0
0
253533233433536
1
0
0
0
233413442212337
1
0
0
0
252533233433428
1
0
0
0
21341344221233a
1
0
0
0
253534233433325
1
0
0
0
213413442212327
0
0
0
1
243533232433737
1
0
0
0
233413442212437
3
0
0
0
242433433433436
1
0
0
0
Note: All isolates were classiﬁed according to their genotype and resistance proﬁle. The symbol ‘a’ represents ten repeat
units and ‘-’ represents missing data. The entries in the four columns sum to the total number of isolates, 100.

488
Handbook of Approximate Bayesian Computation
T0
TINH
TMDR
UMDR
TRIF
URIF
ρINH
ρRIF
ρINH
ρMDR
ρRIF
U0
UINH
τ
τ
τ
τ
Background parameters
δ
death rate
γk
recovery rate
βk
transmission rate
μ
VNTR mutation rate
S
susceptible population
FIGURE 16.2
Model structure for numbers of untreated (Uk) and treated (Tk) cases and
per capita rates of conversion (within-host substitution) among resistance
classes. Rates are ρINH and ρRIF for acquisition of resistance to isoniazid and
rifampicin, respectively, and ρMDR for single step acquisition of resistance to
both drugs. Detection (and treatment) of cases is shown with arrows labelled
with τ. Background parameters are shown in the table to the right, with rates
per capita per unit time, and resistance states k = 0, INH, RIF, MDR. The
mutation process of the VNTR locus is described in Section 16.3.5.
useful to deﬁne a G × 4 matrix, W, whose entries are the total numbers of
both treated and untreated cases: W = U + T.
As it will be helpful to be able to pick out columns of these matrices,
we adopt notation for the standard basis vectors of Rn. Let ei denote the
i-th basis (column) vector, so that ei = (0, . . . , 0, 1, 0 . . . , 0)⊤, with the 1 in
the i-th position. This allows us, for instance, to write the columns of the
matrix T corresponding to each resistance state as T0 = T e1, TINH = T e2,
TRIF = T e3 and TMDR = T e4, with similar notation for other matrices
(note that the dimension of the ei is left open, but inferred from the matrix
multiplication, in this case, they are in R4).
Further, writing 1i for the column vector in Ri whose entries are all 1,
then the product T 14 is a G×1 column vector whose entries are the numbers
of individual cases of each VNTR genotype in the treated population, and
the product 1⊤
G T 14 is the sum of all the entries in T (the size of the treated
population). Thus, we can write the size of the susceptible population, S, as:
S = N −1⊤
G W 14,

Inferences on the Acquisition of Multi-Drug Resistance
489
where 1⊤
G W 14 is the size of the infected population, and where N is the total
population size which remains constant. We treat N as modelling the set of
all individuals who come in contact with infectious cases, and so we exclude
individuals who either do not encounter infectious cases or are otherwise pro-
tected from infection. This variable, therefore, may be smaller than the actual
population size.
The components of each vector Tk for k = 0, INH, RIF, or MDR,
are integers, representing the number of individual cases for each geno-
type. In the schematic diagram of the model in Figure 16.2, we use Tk =
1⊤
G Tk to represent the total population number of treated individuals
with resistance state k, with similar notation Uk = 1⊤
G Uk to represent
the untreated populations. The matrix notation is gathered and shown in
Table 16.2.
The arrows between populations in Figure 16.2 represent the directional
rates of detection and treatment τ and acquisition of resistance to each drug
or set of drugs, so that ρINH and ρRIF represent rates of acquisition of resis-
tance to isoniazid and rifampicin, respectively, and ρMDR the rate of double
acquisition.
In this model time is discrete, and during each time step the following
events take place in sequence.
1. Disease transmission giving rise to new cases;
2. Natural recovery, cure, or death of cases;
3. Detection of cases, which are then treated with drugs;
TABLE 16.2
Summary of Linear Algebra Notation
Symbol
Meaning
V
G × L matrix describing the VNTR genotypes.
U, T, W
G×4 matrices of untreated, treated, and total cases,
respectively, with columns corresponding to resis-
tance proﬁles.
Uk, Tk, Wk
G × 1 column vector for resistance proﬁle k of
untreated, treated, and total cases, respectively.
Uk, Tk, Wk
Total population sizes of untreated, treated, and
total with resistance proﬁle k.
Ui,k, Ti,k, Wi,k
(i, k) entries of the matrices U, T, W: the number
of cases in each category with genotype i and resis-
tance proﬁle k.
1i
i × 1 column vector whose entries are all 1.
ei
Column vector whose entries are 0 except for 1 in
position i. Dimension determined by context.

490
Handbook of Approximate Bayesian Computation
4. Conversion among resistant proﬁles in treated cases due to acquisition of
resistance; and
5. Mutation of the genetic marker (multiple VNTR loci).
The remainder of this section provides details of how each of these events
are modelled. Readers wishing to focus on the statistical aspects of the ABC
inference can skip these subsections and go directly to Section 16.4.
We regard the earlier process as a discrete-time stochastic model rather
than a discrete-time approximation of a continuous-time stochastic process
with rates approximating probabilities, although the latter interpretation be-
comes more appropriate as the time step length decreases. Here, rates of events
will be treated as probabilities, which again is appropriate when time steps
are short. The rate parameters are measured in years, but we make time steps
1/12 of a year.
A summary of all model parameters, both ﬁxed and to be estimated, and
their meanings, is provided in Table 16.3.
16.3.1
New infections
In our model, new infections occur by mass action. The per capita rate at
which a susceptible individual becomes infected by a case with resistance
proﬁle k is given by βk/N times the number of infected cases in state k. The
transmission parameters βk are scaled by 1/N for convenience since realistic
values of βk/N are typically very small, and this ensures that the βk are on
the natural ‘per person per unit time’ scale.
The acquisition of resistance to antibiotics often comes at a cost to the
ﬁtness of the bacterium, and we implement this ﬁtness cost by assuming the
transmission rate is lower for cases that carry resistance. Speciﬁcally, we as-
sume a cost of c ‘per drug’, so that if β0 is the transmission rate of sensitive
cases, then cases resistant to one drug transmit at rate βINH = βRIF = (1−c)β0
and cases resistant to two drugs at βMDR = (1−c)2β0. Here, c = 0.1 is consid-
ered known and ﬁxed based on previous analyses of molecular epidemiological
data (Luciani et al., 2009).
We now construct an expression for the average transmission probability
across the infected population. The matrix W records all infected cases with
diﬀerent resistance states in each column, and the individuals corresponding to
these columns have diﬀerent transmission rates β = (β0, βINH, βRIF, βMDR)⊤.
If we write Dβ for the diagonal matrix whose entries are from β, then the
matrix W Dβ is the infected population matrix W whose columns have been
scaled by the entries of β (the relevant transmission rates). The expression:
p = 1
N 1T
G W Dβ 14,
then gives the average transmission rate per susceptible individual. Since the
population size N is usually large and the time steps are short, the value for

Inferences on the Acquisition of Multi-Drug Resistance
491
TABLE 16.3
Summary of Model Parameters
Symbol
Meaning
Fixed Value
δ
Rate of death and natural recovery
0.52
γ0
Cure rate for resistance proﬁle 0, when treated
0.5
γINH
Cure rate for resistance proﬁle INH, when
treated
0.25
γRIF
Cure rate for resistance proﬁle RIF, when
treated
0.25
γMDR
Cure rate for resistance proﬁle MDR, when
treated
0.05
N
Total susceptible population size in absence of
disease
104
τ
Treatment and detection rate
0.5
c
Cost of resistance
0.1
Symbol
Meaning
Prior
β0
Transmission rate for resistance proﬁle 0
Gamma∗
μ
Mutation rate of VNTR per locus per unit time
U(0, 1)
ρINH
Rate of acquisition of resistance to INH
U(0, 1)
ρRIF
Rate of acquisition of resistance to RIF
U(0, 1)
ρMDR
Rate of acquisition of resistance to INH and RIF
U(0, 1)
Note: The top set of parameters are given ﬁxed values, whereas the bottom
set of parameters are allocated prior distributions and estimated using ABC.
Fixed values and priors are justiﬁed in Section 16.4.2. Rates are in units of
per capita per year, but the time unit is set to 1/12 year in simulations.
∗Speciﬁcally, β0 is assumed to follow a (shifted) gamma prior deﬁned as
β0 −0.68 ∼Gamma(shape = 2, rate = 0.73). See Section 16.4.2 for further
details.
p will nearly always be small. Accordingly, and to ensure that it does not
exceed 1, we model the probability of transmission per susceptible individual
as ˜p = min{1, p}.
At each time step, the number B of new infections is a random variable
distributed as:
B ∼Binomial(S, ˜p).
These B new infections are then allocated across VNTR genotypes and resis-
tance proﬁles according to the proportions represented by the matrix W Dβ.
That is, a multinomial random sample distributes B according to the existing
infected population and their relative transmission rates, so that the resulting
allocation is a G × 4 matrix Δβ. Finally, as new infections are all assumed to
be initially undetected, they are allocated to the untreated subpopulation, so
that the matrix U is updated to U →U + Δβ.

492
Handbook of Approximate Bayesian Computation
16.3.2
Cure, recovery, and death
Infected individuals who are untreated (the population represented by the
counts U) recover or die at rate δ = δr + δd per case per time unit, where
δr > 0 is the rate of recovery and δd > 0 is the rate of death due to any cause.
The rate of cure due to successful treatment may vary according to resistance
proﬁle, so this rate is given by γk for k = 0, INH, RIF, MDR. The number of
cures, recoveries, and deaths in a time step is given by:
R ∼Binomial(U, δ),
for the untreated population, where U = 1⊤
G U 14 is the total number of all
untreated cases, and:
Ck ∼Binomial(Tk, δ + γk),
for the treated population, where Tk is the number of treated individuals with
resistance proﬁle k (as deﬁned at the start of this section). The R untreated
recovered individuals are distributed across both VNTR genotypes and resis-
tance proﬁles with a multinomial distribution according to the counts given in
U. These are recorded in the G × 4 update matrix Δδ (so that the sum of the
entries in Δδ is R = 1⊤
G Δδ 14). Similarly, the Ck treated recovered individuals
of resistance proﬁle k are distributed across the VNTR genotypes according
to the distribution observed in Tk. These recovered counts for all resistance
proﬁles are recorded in the G update matrix Δδ+γ, which is constructed from
the column vectors of recovered treated counts for proﬁle k in the order k = 0,
INH, RIF, and MDR. The matrices U and T are then updated to U →U−Δδ
and T →T −Δδ+γ respectively. If the last instance of any genotype is re-
moved by cure, recovery, or death, the matrices U, T, and V are adjusted
by removing the rows corresponding to those genotypes, and the number of
genotypes is updated with G →G −1.
Similarly to the case of new infections (Section 16.3.1), we assume that
the recovery rate due to treatment depends only on the number of drugs the
infecting strain is resistant to. Speciﬁcally, this implies that γINH = γRIF.
16.3.3
Detection and treatment
In this model, the detection of cases and the commencement of treatment
are combined as a single process. Detected cases are transferred from the
untreated class to the treated class. We denote this combined detection and
treatment rate, per case, per unit time, as τ > 0. With this rate, we draw D
individuals to transfer between untreated and treated populations, where:
D ∼Binomial(U, τ).
These D individuals are then allocated across VNTR genotypes and resistance
proﬁles according to the observed distribution of untreated cases, U. As before,

Inferences on the Acquisition of Multi-Drug Resistance
493
this results in a G×4 update matrix Δτ, which we use to update U →U−Δτ
and T →T + Δτ.
16.3.4
Acquisition of drug resistance
Individual treated cases are able to convert from one resistance proﬁle to
another through adaptive evolution. That is, under drug treatment, natural
selection acts to favour increasing levels of resistance. As a result of this pro-
cess, individuals may move from the k = 0 resistance proﬁle (sensitive to
both drugs) to one of the other three resistance proﬁles: INH, RIF, or MDR
(resistance to one or both drugs). Individuals may also move from resistance
to exactly one of the drugs (INH or RIF) to the multiple drug resistance
proﬁle MDR. We respectively denote the rate of acquisition of resistance to
INH or RIF by ρINH and ρRIF and denote the rate of acquisition of resis-
tance from individuals in the sensitive population to both drugs simultane-
ously by ρMDR. These conversions and rates are illustrated schematically in
Figure 16.2.
To model resistance acquisition, we select individuals to move between
resistance proﬁles in the treated population, for example, between columns
in the matrix T. Acquiring resistance to the drug rifampicin will result in
individuals moving from the column T0 to TRIF and from TINH to TMDR
at a rate ρRIF. Similarly, acquiring resistance to the drug isoniazid results in
individuals moving from the column T0 to TINH and from TRIF to TMDR
at a rate ρRIF. Simultaneous acquisition of resistance to both drugs moves
individuals from the column T0 to TMDR at the rate ρMDR. These movements
occur between columns, but not across rows (infections do not change VNTR
genotypes through this process).
Mechanistically, we can obtain the number of cases of genotype i transi-
tioning from resistance proﬁle k to resistance proﬁle k′, denoted Ai,k→k′, as:
Ai,0→∗∼Multinomial(Ti,0, ρ0→∗)
Ai,INH→MDR ∼Binomial(Ti,INH, ρRIF)
Ai,RIF→MDR ∼Binomial(Ti,RIF, ρINH),
where Ai,0→∗= (Ai,0→INH, Ai,0→RIF, Ai,0→MDR, Ai,0→0)⊤is the vector of
cases transitioning from sensitivity, Ti,k is the entry of the matrix T cor-
responding to the genotype i and resistance proﬁle k (Table 16.2), and
ρ0→∗= (ρINH, ρRIF, ρMDR, 1 −
k ρk)⊤is the vector of probabilities of these
events.
If we denote Δk→k′ as column vectors of counts of movements from resis-
tance proﬁle k to k′ across all G genotypes, we can then construct the overall
G × 4 update matrix:
Δρ = (Δ0 | ΔINH | ΔRIF | ΔMDR),

494
Handbook of Approximate Bayesian Computation
from the column vectors Δk, which denote the total population change for
resistance proﬁle k, where:
Δ0 = −(Δ0→INH + Δ0→RIF + Δ0→MDR)
ΔINH = Δ0→INH −ΔRIF→MDR
ΔRIF = Δ0→RIFΔINH→MDR
ΔMDR = Δ0→MDR + ΔRIF→MDR + ΔINH→MDR.
The population of treated cases is then updated to T →T + Δρ.
16.3.5
Mutation of the marker
The set of L = 15 VNTR loci constitute the genetic marker used to genotype
bacterial isolates (see Section 16.2). Each genotype is a list of numbers of
tandem repeat units at the L loci. The states of all VNTRs in the infected
population are given by the G × L matrix V with elements Vij describing the
repeat number of locus j in genotype i. Each locus mutates through a stepwise
mutation process at rate μ per locus per case per unit time. When mutation
occurs, the repeat number Vij at a locus j of genotype i changes by +1 or −1,
each with probability 0.5. A repeat number of 1 is treated as an absorbing
boundary (i.e. there is zero probability of the repeat number increasing from 1
to 2) because at state 1 there is no longer a genetic sequence that is tandemly
repeated and no mechanism such as replication slippage acts to expand it from
1 to 2.
Mutation of the marker has the eﬀect of moving cases between the rows
of the matrix W. We ﬁrst identify the number of mutation events in the pop-
ulation, M, where M ∼Binomial(S, μ) and S = N −1T
G W 14 is the size
of the susceptible population (see Section 16.3). The M cases are then dis-
tributed across the population of VNTR genotypes and resistance proﬁles,
according to the entries of the matrices T and U. Each individual case un-
dergoing mutation corresponds to a speciﬁc entry in either T or U. This
entry is described by its VNTR genotype Vi = (Vi,1, . . . , Vi,L), where L = 15
for the Bolivian data, and its resistance proﬁle, k = 0, INH, RIF, MDR.
The result of the mutation is a change to the VNTR genotype, which is rep-
resented by a change in the repeat number at a single locus, Vij, by ±1. This
may or may not result in a VNTR genotype that is already present in the
population.
If the new VNTR genotype already appears as a row in the matrix V as
an existing type in the data, then there is no change to V. The matrix T or
U on the other hand is changed by subtracting 1 from one entry and adding
one to another entry in the same column (the resistance proﬁle, k, does not
change). In matrix terms, supposing the change is to a treated case, this can
be described by updating T →T −ei,j + ei,k, where ei,j is the matrix whose
entries are zero except for a 1 in the (i, j)-th position and where the VNTR
genotype changes from row j to row k.

Inferences on the Acquisition of Multi-Drug Resistance
495
If the new VNTR genotype does not already appear in the population, then
the matrix V is expanded to include a new row describing the new genotype,
so that V becomes a (G + 1) × 15 matrix. The update for T or U is the same
as described earlier except that now both matrices are (G+1)×4 dimensional.
Subsequent to this update, we increment G →G + 1. If mutation of a VNTR
genotype removes the last instance of the original genotype from U and T,
the corresponding rows of matrices V, U, and T are deleted, requiring the
update G →G −1.
16.3.6
Initial conditions of the model
The model covers the period from when drugs are introduced at time t = 0
to when sampling occurs. Since the main ﬁrst-line anti-tuberculosis drugs
were discovered/developed in the 1940s to early 1960s, we assumed treatment
commenced around 1960 and ran the simulation for a period of 50 years.
We assumed that both drugs, isoniazid and rifampicin, were introduced at
the same time and are administered together in combination therapy. The
standard course of treatment includes both drugs along with other ﬁrst-line
drugs (WHO, 2015).
We assume that at the start of the process all cases are sensitive to both
drugs, and that the number of cases is at equilibrium in the absence of treat-
ment and resistance. To compute this equilibrium state, we consider the dif-
ferential equation describing the deterministic version of the model ignoring
VNTR genotypes. Namely:
dU
dt = (β0/N)SU −δU,
where S = N −U and t indicates time. Setting dU/dt to zero and solving for
the dynamic variables, we obtain equilibrium values of
ˆU = N

1 −δ
β0

and
ˆS = δN
β0
,
for U > 0.
The basic reproduction number of a pathogen R0 is deﬁned to be the aver-
age number of new infectious cases caused by a single infection in a completely
susceptible population. In our model, before there is any treatment, assuming
all cases are doubly susceptible, a single case on average persists for 1/δ years
and generates Sβ0/N new cases per unit time, but since S = N in a wholly
susceptible population then R0 = β0/δ.
All cases are initially untreated and sensitive. From time t = 0, treatment
in the population commences. To reintroduce into the model genetic variation
at the marker loci, the initial distribution of genotype clusters is a random
sample drawn from the inﬁnite alleles model from population genetic theory
(Ewens, 1972; Hubbell, 2001; Luciani et al., 2008). The inﬁnite alleles model
depends on a single parameter, the diversity parameter, which we set to 2 ˆUμL,

496
Handbook of Approximate Bayesian Computation
where ˆU is the number of cases, taken from the equilibrium value described
earlier, μ is the mutation rate per VNTR locus, and L is the number of VNTR
loci used in genotyping isolates. To initialise the multi-locus VNTR genotypes,
each genotype is a sequence of random integers, of length L, with each VNTR
number Vij drawn from a discrete uniform distribution over {1, . . . , 10}. Al-
though the initial distribution of genotype clusters is set under the inﬁnite
alleles model, the mutation process for VNTRs brings the distribution in line
with the stepwise model over time.
The initial conditions are a function of the parameters which are set ac-
cording to the priors speciﬁed in Section 16.4.2.
16.4
Inference with Approximate Bayesian Computation
For the model in Section 16.3, when the data are only observed at a single
point in time, the cost of evaluating the likelihood function is computationally
prohibitive. This results from the ‘incomplete’ nature of the observed data (see
Section 16.2) in the sense that we only have access to a snapshot of the popu-
lation, via the observed sample, at the time the study was conducted, with no
direct measurements of the system as it progressed. Computing the likelihood
then requires integrating over all potential trajectories the population could
have gone through before reaching its ﬁnal, observed state.
As such, we adopt approximate Bayesian computation (ABC) methods as
a means of performing Bayesian statistical inference for the unknown model
parameters θ = (β0, μ, ρINH, ρRIF, ρMDR)⊤. As observed in other chapters in
this Handbook, the ABC approximation to the true posterior distribution is
given by:
πABC(θ|sobs) ∝π(θ)

Kh(∥s −sobs∥)p(s|θ)ds,
where π(θ) is the prior distribution, s = S(X) is a vector of summary statis-
tics with sobs = S(Xobs), p(s|θ) is the computationally intractable likelihood
function for the summary statistics s, and Kh(u) = K(u/h)/h is a standard
smoothing kernel with scale parameter h > 0. In the following analyses, we
used the uniform kernel on [−h, h] for Kh(u). The quality of the ABC ap-
proximation depends on the information loss in the summary statistics s over
the full dataset X and the size of the kernel scale parameter h with smaller
h producing greater accuracy and increased computational cost. Choice of
both s and h are typically driven by the amount of expert knowledge and
computation available for the analysis.
For the present analysis, we implement a version of a simple ABC
importance sampling algorithm, as outlined in the box. Given a suit-
able importance sampling distribution q(θ), the algorithm produces a set
of weighted samples from the ABC approximation to the true posterior

Inferences on the Acquisition of Multi-Drug Resistance
497
(θ(1), w(1)), . . . , (θ( ˜
N), w( ˜
N)) ∼πABC(θ|sobs). As with standard importance
sampling, suitable choice of q(θ) is important to avoid high variance in
the importance weights and also to avoid needlessly generating datasets
s = S(X(i)), X(i) ∼p(X|θ) for which s(i) and sobs will never be close.
Algorithm 16.1: ABC Importance Sampling Algorithm
Inputs:
• A target posterior density π(θ|Xobs) ∝p(Xobs|θ)π(θ), consisting of a prior
distribution π(θ) and a procedure for generating data under the model
p(Xobs|θ).
• A proposal density q(θ), with q(θ) > 0 if π(θ|Xobs) > 0.
• An integer ˜N > 0.
• An observed vector of summary statistics sobs = S(Xobs).
• A kernel function Kh(u) and scale parameter h > 0.
Sampling:
For i = 1, . . . , ˜N:
1. Generate θ(i) ∼q(θ) from sampling density q.
2. Generate X(i) ∼p(X|θ(i)) from the likelihood.
3. Compute the summary statistics s(i) = S(X(i)).
4. Assign θ(i) the weight w(i) ∝Kh(∥s(i) −sobs∥)π(θ(i))/q(θ(i)).
Output:
A set of weighted parameter vectors {(θ(i), w(i))} ˜
N
i=1 ∼πABC(θ|sobs).
To determine a suitable importance sampling distribution q(θ), we adopt
a two-stage procedure, following the approach of Fearnhead and Pran-
gle (2012). In the ﬁrst stage, we perform a pilot ABC analysis using
a sampling distribution that is diﬀuse enough to easily encompass the
ABC posterior approximation obtained for a moderate value of the ker-
nel scale parameter h. We speciﬁed q(θ) ∝π(θ)I(θ ∈A), which is pro-
portional to the prior, but restricted to the hyper-rectangle A. Here, A
is constructed as the smallest credible hyper-rectangle that we believe
contains the ABC posterior approximation. As such, this q(θ) will iden-
tify the general region in which πABC(θ|sobs) is located. Speciﬁcally, for

498
Handbook of Approximate Bayesian Computation
θ = (β0, μ, ρINH, ρRIF, ρMDR)⊤, we adopt q(θ) = ˜π15(β0) × U(0, .005) ×
U(0, .01) × U(0, .005) × U(0, .001), where ˜π15(β0) is the prior π(β0) for β0
speciﬁed in Section 16.4.2, but truncated to exclude density above the point
β0 = 15.
For posterior distributions with strong dependence between parameters,
deﬁning q(θ) over such a hyper-rectangle may be ineﬃcient, as it will cover
many regions of eﬀectively zero posterior density. Accordingly, we construct
the sampling distribution for the second stage, with the lowest value of h,
as a kernel density estimate of the previous ABC estimate of the posterior
distribution: q(θ) = 
i w(i)L(θ|θ(i)), where L is a suitable kernel density (not
to be confused with the kernel Kh). This approach follows the ideas behind the
sequential Monte Carlo-based ABC samplers of Sisson et al. (2007) and others.
At each stage, the kernel scale parameter h is decreased, and determined as
the value which results in ∼2,000 posterior samples with non-zero weights, for
the given computational budget.
To ensure greater eﬃciency at each stage, we also performed a non-linear
regression adjustment using a neural network with a single hidden layer (see
Blum and Fran¸cois, 2010; Csill´ery et al., 2012; Beaumont et al., 2002), as im-
plemented in the R package abc. The adjustment used logistic transformations
for the response.
For samples drawn from the ﬁnal importance sampling distribution q(θ),
the data generation procedure took on average ∼40 seconds in R. This is com-
putationally expensive from an ABC context and could be reduced by recoding
the simulator in a compiled language such as C or by adapting the ‘lazy ABC’
ideas of Prangle (2016) to terminate early those simulations that are likely to
be rejected. In this implementation, we performed importance sampling from
each distribution q(θ) in parallel on multiple nodes of a computational cluster.
16.4.1
Summary statistics
Considering the matrix structure of the observed data Xobs (see Section 16.2),
we determine the information content in X as if it was the design matrix of a
regression model and summarise it accordingly. Speciﬁcally, we deﬁne the sum-
mary statistics s = S(X) to be the upper-triangular elements of the matrix:
(1g|X)⊤(1g|X),
where the vertical lines denote the addition of an extra column. The added
columns of ones enrich the set of summary statistics by including the row
and column totals of X. Alternatively, these summary statistics can be de-
scribed as:
1. g: the number of distinct genotypes in the sample.
2. nk: the number of isolates with resistance proﬁle k = 0, INH, RIF, and
MDR.

Inferences on the Acquisition of Multi-Drug Resistance
499
3. ck,k′ = (Xk)⊤Xk′: the dot product between the resistance proﬁles of k
and k′ within X.
Note that these summary statistics are over-speciﬁed in that n0 + nINH +
nRIF + nMDR equals the total number of isolates sampled from the population,
which is known and equal to the number of isolates in the observed data sample
(100 for the Bolivian data). Accordingly, and without loss of generality, we
remove nMDR as a summary statistic to avoid collinearity. In combination, this
set of 14 summary statistics eﬃciently encapsulates the available information
about the covariance structure of the original dataset X, the distribution of
the isolates among the diﬀerent resistance proﬁles and the degree of diversity
of isolates within the sample.
For the Bolivian dataset, there are g = 68 distinct genotypes, n0 = 78
sensitive isolates, nINH = 8 isolates resistant to isoniazid only, nRIF = 0
isolates resistant to rifampicin only, and nMDR = 16 doubly resistant isolates
(Table 16.1). The remaining statistics, ck,k′, are computed as:
0
INH
RIF
MDR
0
232
15
0
1
INH
–
10
0
6
RIF
–
–
0
0
MDR
–
–
–
18
Finally, in order to reduce the impact of summary statistics operating on
diﬀerent scales, we compare simulated and observed summary statistics within
the kernel Kh(∥s −sobs∥) via the L 1
2 norm:
∥s −sobs∥= ∥S(X) −S(Xobs)∥=
⎛
⎝
dim(s)

j=1
[S(X)j −S(Xobs)j]
1
2
⎞
⎠
2
,
where dim(s) = 14 is the number of summary statistics. Alternative ap-
proaches could rescale the statistics via an appropriate covariance matrix
(e.g. Luciani et al., 2009; Erhardt and Sisson, 2016) or use other norms; how-
ever the results in the following section proved to be robust to more structured
comparisons, so we did not pursue this further. In particular, the following
results were robust to these choices because of the use of a good (non-linear)
regression adjustment, which greatly improves the ABC posterior approxima-
tion and which has a larger impact on this approximation than the choice of
metric ∥· ∥.
16.4.2
Parameter speciﬁcations and prior distributions
Of the 13 model parameters (Table 16.3), eight of these are known well
enough for the purposes of our analysis to ﬁx their values. Namely, the

500
Handbook of Approximate Bayesian Computation
parameters (δ, γ0, γINH, γRIF, γMDR, N, τ, c)⊤are set to these ﬁxed values.
We justify our choices for these following values. The remaining ﬁve param-
eters θ = (β0, μ, ρINH, ρRIF, ρMDR)⊤are to be estimated and require a prior
distribution speciﬁcation.
The rate of death or recovery, δ, was ﬁxed and set to be δ = 0.52 per case
per year following Dye and Espinal (2001) and Cohen and Murray (2004).
Similarly, following Dye and Espinal (2001), untreated individuals are detected
and treated at rate τ = 0.5 per case per year. The rates of recovery due to
treatment, γk, for resistance proﬁles k = 0, INH, RIF, and MDR, can be
written in terms of the probability of treatment success:
pk =
δr + γk
δd + δr + γk
.
We set the cure rates to be γ0 = 0.5, γINH = γRIF = 0.25, and γMDR = 0.05,
which, by using δr = 0.2 (Dye and Espinal, 2001; Cohen and Murray, 2004),
corresponds to treatment success probabilities of approximately p0 = 0.69,
pINH = pRIF = 0.58, and pMDR = 0.44. These values are within the supported
ranges in the literature, namely, p0 = 0.45 −0.75, pINH = pRIF = 0.3 −0.6,
and pMDR = 0.05 −45 (Blower and Chou, 2004). We chose higher values
within these ranges since Blower and Chou (2004) explored a wide range of
possibilities in models including epidemiologically pessimistic scenarios.
The ﬁtness cost of drug resistance, c, was ﬁxed and set to be c = 0.1
based on estimates by Luciani et al. (2009). To set the total population size
N, we ﬁrst observe that because the sample of 100 isolates represents ∼1.1%
of the population, this implies that the infected population is 9,091. We ex-
pect that the number of susceptible individuals who are exposed to disease
is somewhat higher than this. Accordingly, we assumed that the total size of
the population susceptible to tuberculosis is N = 10,000. Larger total popu-
lation sizes can be used, at the price of greater computational overheads for
generating data under the model.
Previous work estimated rates of resistance acquisition by mutation to be
around 0.0025−0.02 per case per year (Luciani et al., 2009). The rate of muta-
tion of the VNTR loci in M. tuberculosis was estimated to be around 10−3 per
locus per case per year (Reyes and Tanaka, 2010; Aandahl et al., 2012; Ragheb
et al., 2013), but lower estimates have also been found (Wirth et al., 2008;
Supply et al., 2011). All of these mutation rates are much lower than 1. We
treat these mutation rate parameters as probabilities and conservatively set
the standard uniform distribution as a wide prior on each parameter. That is,
for the acquisition of resistance to isoniazid or rifampicin (or both), we spec-
ify priors for the rates of resistance acquisition as ρINH, ρRIF, ρMDR ∼U(0, 1).
Similarly, for the mutation rate of the VNTR molecular marker, μ, we use the
prior μ ∼U(0, 1).
The transmission parameter for doubly sensitive strains β0 is given the
shifted gamma prior:
β0 −0.68 ∼Gamma(shape = 2, rate = 0.73),

Inferences on the Acquisition of Multi-Drug Resistance
501
where the parameters are chosen such that the resulting prior distribution of
the basic reproduction number R0 closely resembles the distribution obtained
in a numerical analysis of tuberculosis dynamics by Blower et al. (1995).
Note that the prior on β0 is shifted in order ensure the realistic condition
that R0 > 1. A value of R0 lower than unity would lead to extinction of
M. tuberculosis.
We reiterate that we interpret the rate parameters as probabilities per time
step and handle the parameters so that their values remain in (0,1). This ap-
proximation increases in accuracy as the time unit decreases. Here, we divide
the natural time unit of one year into new units of 1/12 year per time step.
16.5
Competing Models of Resistance Acquisition
We estimate the rates of acquisition of drug resistance to rifampicin and iso-
niazid by ﬁtting the model described in Section 16.3 to the Bolivian data
(Monteserin et al., 2013) with the ABC method described in Section 16.4.
Additionally, by constraining particular resistance-acquisition parameters ρk
to produce meaningful submodels of the full model, we are able to examine
two speciﬁc biological questions. The relationships between the two submod-
els and the full model are illustrated in Figure 16.3. First, we ask whether it
is possible for multi-drug resistance to evolve directly from doubly sensitive
bacteria or whether this direct conversion does not occur (i.e. ρMDR = 0: Sub-
model 1). Second, we ask whether diﬀerences between rates of mutation to
rifampicin and isoniazid resistance are apparent at the epidemiological scale
(i.e. ρINH = ρRIF = ρsingle: Submodel 2).
Figure 16.4 illustrates the ABC marginal posterior density estimates of
each parameter under the three diﬀerent sets of model assumptions. Under the
ρINH
ρRIF
ρINH
ρRIF
ρMDR
(a)
ρINH
ρINH
ρRIF
ρRIF
(b)
ρsingle
ρsingle
ρsingle
ρsingle
ρMDR
(c)
FIGURE 16.3
Three candidate models of acquisition of multiple drug resistance. (a) The full
model: two diﬀerent rates of conversion leading to acquisition of resistance and
a rate of conversion from resistance proﬁle 0 to resistance proﬁle MDR. This
model is also shown in Figure 16.2. (b) Submodel 1: no direct conversion from
resistance proﬁle 0 to resistance proﬁle MDR (ρMDR = 0). (c) Submodel 2:
same rate of conversion for the two drugs (ρINH = ρRIF = ρsingle).

502
Handbook of Approximate Bayesian Computation
0.000
Parameter
Posterior density
ρINH
ρRIF
ρMDR
μ
ρMDR
ρINH = ρRIF = ρsingle
μ
ρINH
ρRIF
ρMDR = 0
μ
(a)
Posterior density
Posterior density
Posterior density
Full model
Submodel 1
Submodel 2
0.004
0.002
0.000
Parameter
β0
(c)
(d)
0.004
2
4
6
8
10
0.002
0.000
Parameter
(b)
0.004
0.002
FIGURE 16.4
Estimated ABC marginal posterior densities for each estimated parameter
under (a) the full model, (b) Submodel 1 (ρMDR = 0), and (c) Submodel
2 (ρINH = ρRIF = ρsingle). Panel (d) shows the estimated ABC marginal
posterior density of the transmission rate β0 of the sensitive strain for each
model structure.
full model, there is a clear visual diﬀerence between the rates of mutation of
rifampicin and isoniazid resistance, with the latter occurring at a much higher
rate. In contrast, the rate of simultaneous resistance acquisition appears to
be higher than that for rifampicin alone. When eliminating the possibility of
simultaneous acquisition of multiple drug resistance ρMDR = 0 (Submodel 1),
ρINH and ρRIF both increase, relative to the full model, to compensate for the
imposed restriction when ﬁtting to the observed data (Figure 16.4b). Similarly,
when we ﬁx the identity ρINH = ρRIF = ρsingle (Submodel 2) to impose a single
rate of resistance acquisition, the posterior density of this parameter moves to
intermediate values compared to the two distinct rates of acquisition estimated
under the full model (Figure 16.4c). The estimated posterior densities for the

Inferences on the Acquisition of Multi-Drug Resistance
503
TABLE 16.4
ABC Posterior Means with Lower and Upper Limits of the 95% HPD
Credible Intervals for Each Parameter of Each Fitted Model
ρINH
ρRIF
ρMDR
μ
β0
Full model
Posterior mean 1.14 × 10−3 1.67 × 10−4 2.62 × 10−4 1.64 × 10−3 2.85
CI lower limit
3.40 × 10−4 3.82 × 10−6 3.93 × 10−6 1.11 × 10−3 0.97
CI upper limit
1.94 × 10−3 4.28 × 10−4 5.81 × 10−4 2.40 × 10−3 5.33
Submodel l
Posterior mean 1.60 × 10−3 6.37 × 10−4
–
1.59 × 10−3 3.29
CI lower limit
4.55 × 10−4 1.27 × 10−4
–
1.03 × 10−3 1.20
CI upper limit
2.49 × 10−3 1.24 × 10−3
–
2.19 × 10−3 5.78
Submodel 2
Posterior mean 3.46 × 10−4
–
1.56 × 10−4 1.70 × 10−3 2.81
CI lower limit
7.26 × 10−5
–
6.62 × 10−7 1.10 × 10−3 0.86
CI upper limit
6.90 × 10−4
–
3.76 × 10−4 2.54 × 10−3 5.20
transmission (β0) and mutation (μ) parameters are visually similar across all
models. ABC marginal posterior means and highest posterior density (HPD)
credible intervals for all models are reported in Table 16.4.
16.5.1
Can resistance to both drugs be acquired
simultaneously?
To determine whether resistance to both drugs can evolve directly from a dou-
ble sensitive strain within an infection, we compare Submodel 1 (ρMDR = 0)
against the full model. Formal standard Bayesian model comparison typically
occurs through Bayes factors. In the ABC framework, this task is complicated
by the need to perform ABC with summary statistics that are informative for
the model indicator parameter, in addition to those informative for the model
speciﬁc parameters. Such summary statistics can not only be diﬃcult to iden-
tify, but the resulting composite vector of summary statistics can be high
dimensional, which may then produce more inaccurate inference than if each
model was analysed independently. See, for example, Robert et al. (2011),
Marin et al. (2014) and Marin et al. (2019, Chapter 6, this volume) for a dis-
cussion of these issues. A useful alternative is to consider posterior predictive
checks or related goodness-of-ﬁt tests (e.g. Thornton and Andolfatto, 2006;
Csill´ery et al., 2010; Aandahl et al., 2012; Prangle et al., 2014).
Figure 16.5 shows the posterior predictive distribution of the summary
statistics (n0, nINH + nRIF, nMDR) described in Section 16.4.1, for the full
model [panel (a)] and Submodel 1 [panel (b)], where a darker intensity
indicates higher density. This predictive distribution graphically illustrates

504
Handbook of Approximate Bayesian Computation
*
20
40
60
80
100
20
40
60
80
100
20
40
60
80
100
Single
Sensitive
Double
20
40
60
80
100
20
40
60
80
100
20
40
60
80
100
Single
Sensitive
Double
(a)
(b)
*
FIGURE 16.5
Posterior predictive distribution of (n0, nINH + nRIF, nMDR) under the full
model (a) and Submodel 1 (b). Darker intensity indicates higher posterior
density. The asterisk (*) indicates the observed data (78, 8, 16).
each model’s ability to generate the observed summary statistics (78, 8, 16),
indicated by the asterisks, which represent the number of individuals in the
sample sensitive to both drugs (n0), resistant to a single drug (nINH + nRIF),
and resistant to both drugs (nMDR).
The predictive distributions for each model are diﬀuse, particularly for the
full model. This variability is expected given that the sample size is small
(100 isolates) and that the evolution of drug resistance from sensitivity is
a relatively rare stochastic event. In the case of Submodel 1 [Figure 16.5
panel (b)] where we impose the condition ρMDR = 0, the density of samples is
shifted away from the bottom-right corner, which represents double resistance.
This pattern is due to the lack of the direct route to multi-drug resistance.
The observed data (asterisk) is in a region of low posterior predictive density
under Submodel 1, and so we conclude that this model is not particularly
supported by the data. In contrast, the observed data lie more clearly within
a moderately high density region of the posterior predictive under the full
model [Figure 16.5 panel (a)]. This analysis therefore suggests that of the two
competing hypotheses, it is more likely that resistance to both drugs can be
acquired simultaneously (ρMDR > 0) than otherwise. Note, however, that this
direct route is not the only possible path to double resistance, which can still
occur in stages through single resistance.
16.5.2
Is resistance to both drugs acquired at equal rates?
In order to determine whether the rates of acquisition of resistance to the
two drugs are equal (ρINH = ρRIF), we compare Submodel 2 against the full
model. Figure 16.6 depicts the posterior predictive distribution of (nINH, nRIF)

Inferences on the Acquisition of Multi-Drug Resistance
505
0
10
20
30
40
0
10
20
30
40
0
10
20
30
40
0
10
20
30
40
Isolates resistant to rifampicin only
Isolates resistant to isoniazid only
*
(a)
Isolates resistant to rifampicin only
Isolates resistant to isoniazid only
*
(b)
FIGURE 16.6
Posterior predictive distribution of (nINH, nRIF) under the full model (a) and
Submodel 2 (b) Darker intensity indicates higher posterior predictive density.
The asterisk (*) indicates the observed data (8, 0).
under each model – the number of cases resistant only to isoniazid (nINH) and
the number of cases resistant only to rifampicin (nRIF) in the sample. The
observed values of these summary statistics are nINH = 8 for isoniazid and
nRIF = 0 for rifampicin, illustrated as the asterisk in Figure 16.6. As Submodel
2 does not favor any drug over the other, the predictive surface is symmetric
with respect to the line nINH = nRIF. The extra ﬂexibility provided by the full
model shifts the predictive distribution towards the observed data. While the
distribution under the full model comfortably accommodates the empirical
point in a high density region, the predictive distribution under Submodel
2 is much more diﬀuse. This indicates that while the observed data are not
unsupported under Submodel 2, it is far more likely to be observed under the
full model. As a result, we conclude that the evidence favours the drugs being
acquired at diﬀerent rates, speciﬁcally, isoniazid resistance evolves faster than
rifampicin resistance.
16.5.3
The relative contribution of transmission and
treatment failure to multi-drug–resistant tuberculosis
In addition to estimating the rates of acquisition of drug resistance and as-
sessing whether rates diﬀer, we may also consider where doubly resistant cases
come from. That is, estimation of the relative contribution to multi-drug resis-
tant cases of transmission of existing MDR-TB strains compared to treatment
failure leading to evolution of multi-drug resistance. The posterior predicted
samples generated under the full model provide a clear portrait of the relative

506
Handbook of Approximate Bayesian Computation
TABLE 16.5
Contributions to MDR-TB from Alternative Sources
Source
Median
Mean
95% Credible Interval
Transmission
0.9975
0.9655
(0.7826, 0.9999)
Conversion in one step
0.0023
0.0284
(0.0000, 0.1667)
Conversion in two steps
0.0000
0.0060
(0.0000, 0.0073)
Note: This table contains the posterior medians and means and lower and
upper limits of the 95% HPD credibility intervals for the proportion of double
resistance cases originating from each possible source.
contribution of the diﬀerent paths to achieving double resistance (see e.g.
Luciani et al., 2009 for an additional illustration of this procedure).
Table 16.5 shows the means, medians and the 95% HPD credible intervals
for the predicted proportion of cases of double resistance from each potential
source. These proportions are obtained conditionally on there being at least
one case of double resistance in the predictive sample. Simulated samples
of this nature account for 99.67% of all predictive samples. The predictive
distributions of the proportions are highly asymmetric (not shown), making
the median a more reliable point estimate than the mean.
In the overwhelming majority of posterior predictive samples, direct trans-
mission was the main source of acquisition of double resistance, followed by
conversion in a single step directly from a sensitive proﬁle (from proﬁle 0 to
MDR), and conversion in two steps via a state of resistance to a single drug
(from proﬁle 0 to INH to MDR, or from 0 to RIF to MDR). This analysis cor-
roborates the ﬁnding from Section 16.5.1 that ρMDR is most likely positive,
and furthermore, that this path is likely to be of even greater importance than
conversion in two steps.
16.6
Conclusions
In this chapter we have estimated epidemiological parameters describing the
acquisition of multi-drug resistance in M. tuberculosis from molecular epi-
demiological data (Monteserin et al., 2013) using approximate Bayesian com-
putation. The underlying model is intended to capture essential processes
that give rise to the data, namely, transmission of the disease, recovery
or death, and within-host evolution giving rise to drug resistance and new
genotypes at the molecular marker loci. From this analysis, we may draw
three major biological conclusions about the manner in which drug resistance
arises.

Inferences on the Acquisition of Multi-Drug Resistance
507
First, there is an asymmetry in the acquisition of resistance to isoniazid and
rifampicin. Speciﬁcally, isoniazid resistance occurs approximately an order of
magnitude more frequently than resistance against rifampicin (see Table 16.4).
This asymmetry in rates is consistent with in vitro (i.e. through laboratory
experiments) microbiological estimates of mutation rates per cell generation
which ﬁnd around 1 to 2 orders of magnitude diﬀerence between the two rates
(David, 1970; Ford et al., 2013).
Second, the analysis supports the occurrence of direct conversion from
doubly drug sensitive to doubly resistant (MDR) infections. This may be ini-
tially unintuitive because under mutation alone, if mutation occurs at rate
ρ per gene per unit time, the rate of appearance of double mutants is ρ2,
which would be vanishingly small if ρ is low. However, using a mathematical
model, Colijn et al. (2011) argued that direct conversion can occur surpris-
ingly fast because resistant cells are sometimes present at low frequencies in
a within-host population even before treatment commences. Our analysis of
data at the epidemiological level is consistent with that theoretical result.
This direct conversion to double resistance is epidemiologically important,
as it accelerates the accumulation of resistance, in that resistance evolution
does not have to take place sequentially. Once double resistant mutants ap-
pear, transmission of these mutants further increases their prevalence in the
population.
Third, the overwhelming majority of cases of multi-drug resistant tuber-
culosis come from transmission of already multi-drug resistant strains (see
Table 16.5), a ﬁnding that is consistent with those of Luciani et al. (2009).
This large contribution of transmission occurs despite the 10% transmission
cost of each resistance, which results in a ∼20% cost for MDR-TB. This implies
that in controlling drug resistance, although there is widespread concern about
treatment failure leading to rising resistance, most resistant cases may be due
to transmission. Therefore, although it is important to support treatment ad-
herence, public health eﬀorts may beneﬁt from focusing more on preventing
disease transmission. That is, control measures that reduce the incidence of
new cases are likely to help reduce MDR-TB.
By developing epidemiological models with evolutionary processes, we
have been able to estimate parameters describing how drug resistance –
particularly multidrug resistance – emerges in M. tuberculosis. Although there
is existing knowledge of rates of mutation to resistant states in vitro, there is a
need to assess the extent to which those rates translate to the epidemiological
level. Large scale molecular epidemiological models, such as those presented
here, are highly complex and multi-dimensional and, as such, likelihood-based
analyses are not straightforward mathematically or computationally. In such
cases, approximate Bayesian computation methods present a practical and
viable approach to making statistical inferences, particularly as continually ad-
vancing molecular technologies require dynamical models to be extended and
reﬁned.

508
Handbook of Approximate Bayesian Computation
Acknowledgements
GSR is funded by the Coordination for the Improvement of Higher Education
Personnel (CAPES) Foundation via the Science Without Borders program
(BEX 0974/13-7). SAS is supported by the Australian Research Council under
the Discovery Project scheme (DP160102544), and the Australian Centre of
Excellence in Mathematical and Statistical Frontiers (CE140100049). MMT
is supported by grant DP170101917 from the Australian Research Council.
This research includes computations using the Linux computational cluster
Katana supported by the Faculty of Science, UNSW Australia.
References
Aandahl, R. Z., J. F. Reyes, S. A. Sisson, and M. M. Tanaka (2012).
A model-based Bayesian estimation of the rate of evolution of VNTR loci in
Mycobacterium tuberculosis. PLoS Computational Biology 8(6), e1002573.
Anderson, L. F., S. Tamne, T. Brown, J. P. Watson, C. Mullarkey, D. Zenner,
and I. Abubakar (2014). Transmission of multidrug-resistant tuberculosis in
the UK: A cross-sectional molecular and epidemiological study of clustering
and contact tracing. The Lancet Infectious Diseases 14(5), 406–415.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162(4), 2025–2035.
Blower, S. M. and T. Chou (2004). Modeling the emergence of the ‘hot
zones’: Tuberculosis and the ampliﬁcation dynamics of drug resistance.
Nature Medicine 10(10), 1111–1116.
Blower, S. M., A. R. McLean, T. C. Porco, P. M. Small, P. C. Hopewell, M. A.
Sanchez, and A. R. Moss (1995). The intrinsic transmission dynamics of
tuberculosis epidemics. Nature Medicine 1(8), 815–821.
Blum, M. G. B. and O. Fran¸cois (2010). Non-linear regression models for
approximate Bayesian computation. Statistics and Computing 20, 63–73.
Cohen, T. and M. Murray (2004). Modeling epidemics of multidrug-resistant
M. tuberculosis of heterogeneous ﬁtness. Nature Medicine 10(10), 1117–
1121.
Colijn, C., T. Cohen, A. Ganesh, and M. Murray (2011). Spontaneous emer-
gence of multiple drug resistance in tuberculosis before and during therapy.
PLoS One 6(3), e18327.

Inferences on the Acquisition of Multi-Drug Resistance
509
Csill´ery, K., M. G. B. Blum, O. E. Gaggiotti, and O. Fran¸cois (2010). Approxi-
mate Bayesian computation in practice. Trends in Ecology and Evolution 25,
410–418.
Csill´ery, K., O. Fran¸cois, and M. G. B. Blum (2012). abc: An R package for
approximate Bayesian computation (ABC). Methods in Ecology and Evolu-
tion 3(3), 475–479.
David, H. L. (1970). Probability distribution of drug-resistant mutants in
unselected populations of Mycobacterium tuberculosis. Applied Microbiol-
ogy 20(5), 810–814.
Dye, C. and M. A. Espinal (2001). Will tuberculosis become resistant to all
antibiotics? Proceedings of the Royal Society of London B: Biological Sci-
ences 268(1462), 45–52.
Erhardt, R. and S. A. Sisson (2016). Modelling extremes using approxi-
mate Bayesian computation. In D. Dey and J. Yan (Eds.), Extreme Value
Modelling and Risk Analysis: Methods and Applications, Volume 281–306.
New York: Chapman & Hall/CRC Press.
Ewens, W. J. (1972). The sampling theory of selectively neutral alleles.
Theoretical Population Biology 3(1), 87–112.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic approximate Bayesian
computation (with discussion). Journal of the Royal Statistical Society:
Series B 74, 419–474.
Ford, C. B., R. R. Shah, M. K. Maeda, S. Gagneux, M. B. Murray,
T. Cohen, J. C. Johnston, J. Gardy, M. Lipsitch, and S. M. Fortune (2013).
Mycobacterium tuberculosis mutation rate estimates from diﬀerent lineages
predict substantial diﬀerences in the emergence of drug-resistant tubercu-
losis. Nature Genetics 45(7), 784–790.
Gandhi, N. R., A. Moll, A. W. Sturm, R. Pawinski, T. Govender, U. Lalloo,
K. Zeller, J. Andrews, and G. Friedland (2006). Extensively drug-resistant
tuberculosis as a cause of death in patients co-infected with tuberculosis
and HIV in a rural area of South Africa. The Lancet 368(9547), 1575–1580.
Gillespie, S. H. (2002). Evolution of drug resistance in Mycobacterium tu-
berculosis: Clinical and molecular perspective. Antimicrobial Agents and
Chemotherapy 46(2), 267–274.
Hubbell, S. P. (2001). The Uniﬁed Neutral Theory of Biodiversity and Biogeog-
raphy (MPB-32), Volume 32. Princeton, NJ: Princeton University Press.

510
Handbook of Approximate Bayesian Computation
Luciani, F., A. R. Francis, and M. M. Tanaka (2008). Interpreting genotype
cluster sizes of Mycobacterium tuberculosis isolates typed with IS6110 and
spoligotyping. Infection, Genetics and Evolution 8(2), 182–190.
Luciani, F., S. A. Sisson, H. Jiang, A. R. Francis, and M. M. Tanaka (2009).
The epidemiological ﬁtness cost of drug resistance in Mycobacterium tuber-
culosis. Proceedings of the National Academy of Sciences United States of
America 106(34), 14711–14715.
Marin, J.-M., N. Pillai, C. P. Robert, and J. Rousseau (2014). Relevant statis-
tics for Bayesian model choice. Journal of the Royal Statistical Society:
Series B 76, 833–859.
Marin, J.-M., P. Pudlo, and C. P. Robert (2019). Likelihood-free Model
Choice. In S. A. Sisson, Y. Fan, and M. A. Beaumont (Eds.), Handbook of
Approximate Bayesian Computation. Chapman & Hall/CRC Press, Boca
Raton, FL.
Mazars, E., S. Lesjean, A. L. Banuls, M. Gilbert, V. Vincent, B. Gicquel,
M. Tibayrenc, C. Locht, and P. Supply (2001). High-resolution minisatellite-
based typing as a portable approach to global analysis of Mycobacterium
tuberculosis molecular epidemiology. Proceedings of the National Academy
of Sciences of the United States of America 98(4), 1901–1906.
Mitchison, D. A. (1951). The segregation of streptomycin-resistant variants of
Mycobacterium tuberculosis into groups with characteristic levels of resis-
tance. Microbiology 5(3), 596–604.
Monteserin, J., M. Camacho, L. Barrera, J. C. Palomino, V. Ritacco, and
A. Martin (2013). Genotypes of Mycobacterium tuberculosis in patients at
risk of drug resistance in Bolivia. Infection, Genetics and Evolution 17,
195–201.
Nachega, J. B. and R. E. Chaisson (2003). Tuberculosis drug resistance:
A global threat. Clinical Infectious Diseases 36(Supplement 1), S24–S30.
Prangle, D. (2016). Lazy ABC. Statistics and Computing 26(1–2), 171–185.
Prangle, D., M. G. B. Blum, G. Popovic, and S. A. Sisson (2014). Diagnostic
tools for approximate Bayesian computation using the coverage property.
Australia and New Zealand Journal of Statistics 56, 309–329.
Ragheb, M. N., C. B. Ford, M. R. Chase, P. L. Lin, J. L. Flynn, and S. M.
Fortune (2013). The mutation rate of mycobacterial repetitive unit loci
in strains of M. tuberculosis from cynomolgus macaque infection. BMC
Genomics 14, 145.
Ramaswamy, S. and J. M. Musser (1998). Molecular genetic basis of antimicro-
bial agent resistance in Mycobacterium tuberculosis: 1998 update. Tubercle
and Lung Disease 79(1), 3–29.

Inferences on the Acquisition of Multi-Drug Resistance
511
Reyes, J. F. and M. M. Tanaka (2010). Mutation rates of spoligotypes and
variable numbers of tandem repeat loci in Mycobacterium tuberculosis.
Infection, Genetics and Evolution 10(7), 1046–1051.
Robert, C. P., J.-M. Corunet, J.-M. Marin, and N. Pillai (2011). Lack of
conﬁdence in approximate Bayesian computational (ABC) model choice.
Proceedings of the National Academy of Sciences of the United States of
America 108, 15112–15117.
Sisson, S. A., Y. Fan, and M. M. Tanaka (2007). Sequential Monte Carlo
without likelihoods. Proceedings of the National Academy of Sciences of the
United States of America 104(6), 1760–1765. Errata (2009), 106, 16889.
Supply, P., C. Allix, S. Lesjean, M. Cardoso-Oelemann, S. R¨usch-Gerdes,
E. Willery, E. Savine et al. (2006). Proposal for standardization of opti-
mized mycobacterial interspersed repetitive unit-variable-number tandem
repeat typing of Mycobacterium tuberculosis. Journal of Clinical Microbiol-
ogy 44(12), 4498–4510.
Supply, P., S. Niemann, and T. Wirth (2011). On the mutation rates of
spoligotypes and variable numbers of tandem repeat loci of Mycobacterium
tuberculosis. Infection, Genetics and Evolution 11(2), 251–252.
Thornton, K. and P. Andolfatto (2006). Approximate Bayesian inference re-
veals evidence for a recent, severe bottleneck in a Netherlands population
of Drosophila melanogaster. Genetics 172, 1607–1619.
WHO (2015). Global tuberculosis report 2015. Technical report, World Health
Organization.
Wirth, T., F. Hildebrand, C. Allix-B´eguec, F. W¨olbeling, T. Kubica,
K. Kremer, D. van Soolingen et al. (2008). Origin, spread and demog-
raphy of the Mycobacterium tuberculosis complex. PLoS Pathogens 4(9),
e1000160.
Zhao, Y., S. Xu, L. Wang, D. P. Chin, S. Wang, G. Jiang, H. Xia et al. (2012).
National survey of drug-resistant tuberculosis in China. New England Jour-
nal of Medicine 366(23), 2161–2170.


17
ABC in Systems Biology
Juliane Liepe and Michael P.H. Stumpf
CONTENTS
17.1
Introduction ......................................................
513
17.2
Parameter Estimation for Dynamical Systems ..................
515
17.2.1
Inference for dynamical systems ........................
515
17.2.2
Posterior analysis for dynamical systems ...............
517
17.3
ABC Model Selection in Systems Biology .......................
519
17.3.1
Dynamical systems and model selection ................
520
17.3.2
ABC for design ..........................................
522
17.4
Network Analysis and Inference .................................
522
17.4.1
Models of network evolution ............................
523
17.4.2
Distances and summaries of network data for ABC ....
523
17.5
Multi-Scale Models ...............................................
525
17.5.1
Inference for biological multi-scale models ..............
526
17.5.2
ABC models of cell migration ...........................
527
17.6
ABC and Beyond ................................................
532
References
...............................................................
533
17.1
Introduction
Systems biology aims to capture the fundamental molecular and cellular
processes underlying living systems [1]. Mathematical models that describe
how cells, or indeed complex multi-cellular organisms, function are increas-
ingly gaining prominence in biological research. While statistics and probabil-
ity have been pivotal in evolutionary and population biology for well over a
century, mathematical models have entered the cellular and molecular life sci-
ences only relatively recently. In order to understand how complex molecular
machines [2] such as ribosomes and proteasomes, function, or how essential
513

514
Handbook of Approximate Bayesian Computation
cellular processes, such as metabolism, replication, cell-cycle, and response to
environmental signals and stresses, are controlled, we need mathematical mod-
els. They open up the possibility of stating mechanistic hypotheses in concise,
clear, and quantitative terms. Looking at the agreement between suitably cal-
ibrated mathematical models and experimental data is one way in which we
can test our understanding and successively improve our models.
Iteration between experiment and theoretical analysis and prediction has
become a hallmark of systems biology studies. In contrast to the physical
sciences, however, it is typically not possible to use ﬁrst principles to con-
struct suitable mathematical models for biological phenomena. Instead, we
have to look at interaction and relationships between diﬀerent species. Here
species can refer to actual biological species in the contexts of population
biology; diﬀerent cell-types in developmental biology and immunology; or dif-
ferent molecules in biochemistry and molecular biology. Typically, we aim to
characterise their interactions using ordinary, partial, or stochastic diﬀerential
equations, but in many other instances all we can currently do – due to our
current state of understanding and/or the nature of the available data – is
to ﬁnd adequate statistical descriptions for the dependencies among these
species [3,4].
The models that we are dealing with in many biological situations must
really be seen as ﬁrst attempts at modelling these phenomena mathemati-
cally [5,6]. Models are thus under continuous revision, in many cases even the
appropriate modelling framework – for example, ordinary versus stochastic
diﬀerential equations; Boolean networks, stochastic Petri-nets of diﬀerential
equations – is far from clear at the outset. The need to adapt to the challenges
posed by real-world biological systems is quite considerable, and it is rare that
a single mathematical approach suﬃces to make progress in the analysis of
biological systems.
Cutting edge scientiﬁc problems often defy conventional statistical ap-
proaches. But, without sound inference procedures and reliable statistical
analysis, it is in turn hard to make progress in such areas of research. Here,
approximate Bayesian computation (ABC) provides an ideal framework to
progress with challenging research problems [7]. While there is a lot of in-
terest in ABC as an inferential framework in its own right [8–10], here we
stress the utilitarian aspects of ABC: it allows us to solve challenging in-
ference tasks in situations where it is either hard or impossible to evalu-
ate likelihoods. In such situations, it is typically still possible to simulate
the mathematical models and use ABC to compare simulated and observed
data. With this framework in place, it is then possible to, for example, ﬁt
models to data [11–13]; design better, more discriminatory experiments [14];
choose rationally from diﬀerent mechanistic models [16,15]; and investigate
which models (or interventions) are most likely to result in certain types of
behaviour [17].

ABC in Systems Biology
515
17.2
Parameter Estimation for Dynamical Systems
Most computational analyses in systems biology can be divided into two
classes: those aiming to describe and analyse the structure of biological net-
works; and those that model explicitly the temporal behaviour of a biolog-
ical system, such as a signalling or gene regulation network. The former is
typically done using graphical models – with some exceptions discussed in
Section 17.4 – and can therefore be handled with classical or exact Bayesian
approaches. Here, we will therefore deal with the latter.
17.2.1
Inference for dynamical systems
We are interested in how the state of some system, X(t), changes with time t.
Often the state of the (typically vector-valued random variable) X is not
observable directly, and, instead, we observe Y ∼g(X(t) = x(t); η). Both
deterministic and stochastic dynamical systems are considered in systems
biology, while traditionally deterministic approaches, typically implemented
via ordinary diﬀerential equations (ODE), have predominated, more recently,
there has been a noticeable increase in stochastic studies.
For ODEs:
dy(t)
dt
= f(y, t; θ),
(17.1)
a likelihood has to be deﬁned via an error model, and we typically assume
that discrete observations y(ti) for 1 ≤i ≤n are subject to some noise, for
example:
yobs(ti) = y(ti) + ϵ(ti),
where ϵ(ti) is drawn from some suitable probability model [18–20]. For prag-
matic reasons, ϵ ∼N(0, σ2), is the conventional choice, and for such a model,
but also more complicated models, it is straightforward to deﬁne likelihoods
(via the error model) and use conventional Bayesian analyses. ABC methods
have, however, been also applied in this context [21], but their real poten-
tial lies in inference for stochastic dynamical systems, described here and for
multi-scale systems (which are the topic of Section 17.5).
Here, for sake of concreteness, we focus on systems that are described by
stochastic diﬀerential equations [22,70], and we use a state-space representa-
tion where:
dX(t) = f(X(t), t; θ)dt + dWt
(17.2)
Y ∼g(X(t) = x(t); η).
(17.3)
Wt denotes the classical Wiener process, and in many applications a simpliﬁed
form for the observation function g(X, η) is assumed, with the assumption of

516
Handbook of Approximate Bayesian Computation
normal noise being a conventional and attractive choice. The error model,
however, also introduces a probability model for the observed data and,
in applications involving ODEs, can suﬃce to deﬁne a likelihood. For SDEs
(or stochastic processes more generally), however, the evaluation of the likeli-
hood is complicated, especially if suitable approximation schemes, such as the
linear noise approximation [23] cannot be applied. This is typically the case
for highly non-linear dynamics and low molecular abundances.
For data, yobs(ti), observed at discrete time points, τ = {t1, . . . , tn}, we
need to evaluate the transition probabilities, assuming that the state of the
system evolves as a continuous-time Markov process, as:
p (Y (ti+1)) = yobs(ti+1|P(Y (ti)) = yobs(ti).
(17.4)
But this is an integral over all possible paths from the state of the system
at time ti to the state at time ti+1. Even in approximation, the evaluation
of such bridging processes is computationally costly and rarely aﬀordable for
realistic systems of biological interest [25,24]. Thus, the likelihood of such a
system, given by:
p(yobs|θ) =
n−1

i=1
p(Y (ti+1) = yobs(ti+1)|P(Y (ti)) = yobs(ti),
(17.5)
is typically impossible to evaluate, and computation of the posterior:
π(θ|yobs) ∝p(yobs|θ)π(θ),
(17.6)
becomes computationally cumbersome or impossible.
Approximation schemes, such as the linear noise approximation oﬀer some
alternatives, but are typically limited to relatively benign dynamical regimes,
and other approximation to chemical master equations (see e.g. [26,27]) are
also either computationally demanding, capable of dealing only with simpliﬁed
dynamics, or their convergence to the true dynamics is hard to control or
verify.
By contrast, ABC is capable (subject to the constraints discussed in the
following) of coping with simulated data from models with very complicated
dynamics [28]. The appropriate ABC posterior, corresponding to the model
in (17.5) is given by:
πABC(θ|yobs) ∝Kh(||y −yobs||)p(y|θ)π(θ).
(17.7)
This is easy to calculate and allows us to obtain (approximate) posterior
estimates. Quite generally, once the technical parameters have been set up,
ABC works in an essentially straightforward manner. This should not detract,
however, from the fact that getting diﬀerent algorithms, such as ABC-
sequential Monte Carlo (SMC) [29,21], the current work-horse of ABC-based
inference in systems biology, to converge while maintaining good coverage of
the parameter space can be non-trivial.

ABC in Systems Biology
517
17.2.2
Posterior analysis for dynamical systems
Dynamical systems pose considerable inferential challenges, and a rich
literature [30–32] has been building up around concepts such as identiﬁability,
inferability, and sloppiness. Common to these three closely related notions –
even though the relationship is rarely if ever explored – is that local, point-
estimates are: (i) potentially poor representations of the true parameter and
(ii) hide the fact that many similar parameters would be capable of describ-
ing the data equally well. This should be reason enough to consider interval
estimators and, in particular, Bayesian methods from the outset. While no-
tions such as identiﬁability and sloppiness have been considered in depth –
though perhaps not always satisfactorily – in the context of ODE models,
many of the same problems will also carry through to stochastic modelling
approaches [33].
As a simple example, we consider a hypothetical gene regulatory network
(Figure 17.1a). In this model, a protein P1 is produced from its mRNA M.
5
10 20 30 40
M
50 60
0
70
10
Time
(b)
0
15
M
p4+P2p3
P1
p0
p1
p4
p4
P2
P1p2
(a)
FIGURE 17.1
Gene regulatory model. (a) The cartoon depicts the model described by
equations 17.8–17.10. mRNA (M) produces the protein P1, which can be
modiﬁed and results in the production of protein P2. P1 is required to pro-
duce M, while P2 enhances the degradation of M. P1 and P2 are degraded
with a constant rate (the ∅symbol denotes that a reaction is a death process).
(b) Shown are measurements of M over time. The data were generated from
the corresponding ODE model with parameters (p1, ..., p5) = (10.0, 0.5, 10.0,
2.0, 1.0) and initial conditions (M, P1, P2)=(10, 5, 0). This dataset was used
to estimate the model parameters.

518
Handbook of Approximate Bayesian Computation
Once P1 is produced, it allows the production of its own mRNA. P1 can also
be post-translationally modiﬁed and transformed into protein P2, which in
turn degrades M. The production of P1 is therefore self-regulated via post-
translational modiﬁcations and a positive feedback loop. Both proteins, as
well as the mRNA, are furthermore degraded at a constant rate. The described
system contains three species (P1, P2, and M) and ﬁve parameters (p1, . . . , p5).
The corresponding stochastic model using SDEs can be written as Wilkinson
2011 [22]):
dm
dt = P1p2 −M(p4 + P2p3) + dW (1)
t
(17.8)
dP1
dt
= Mp0 −P1(p1 + p4) + dW (3)
t
,
(17.9)
and
dP2
dt
= P1p1 −P2p4 + dW (3)
t
.
(17.10)
We can, for the purpose of this example, collect data for mRNA gener-
ated by the corresponding ODE model using the parameters (p1, . . . , p5) =
(10.0, 0.5, 10.0, 2.0, 1.0) and the initial conditions (M, P1, P2) = (10, 5, 0)
(Figure 17.1b). We now aim to infer the posterior parameter distribution
of this model given the generated data. We use the Python package ABC-
SysbBio [34,35], which implements ABC-SMC. The ﬁtted trajectories are
shown in Figure 17.2a and the resulting posterior distributions in Figure 17.2b.
Simulation of trajectories from the posterior distribution allows us to under-
stand, how much information the data carry about predicting the behaviour
of the three species. The resulting conﬁdence intervals for M are narrow,
as can be seen in Figure 17.2a. This is expected because the data describe
the temporal behaviour of M. On the contrary, we observe larger conﬁdence
intervals for the prediction of P1 and P2. In order to better predict these two
species’ behaviours, we would need to use a more informative dataset [14].
The marginal posterior parameter distributions indicate that p0 and p2 are
not well inferred. However, the pairwise density plot of these two parameters
shows strong non-linear correlations, for example, if one of the two parameters
were to be known, the remaining parameter could be identiﬁed (Figure 17.2b).
This posterior spread seems ubiquituous in parameter inference for dynam-
ical systems [30–32], and while experimental design can increase our ability to
measure parameter – such as diﬀerent initial conditions, knock-out and knock-
down mutants, as well as small molecules that interfere with the dynamics of
a system – not all informative experiments can be carried out for practical or
ethical reasons.

ABC in Systems Biology
519
5
10
Time
p0
0
0.00 0.02
20 40
p2
0
0.0
0.1
20 40
p1
0
0.0 0.4 0.8
4
8
p3
0
0.0 0.4 0.8
4
8
(a)
(b)
40
M
0
60
400
P1
0
800
200
P2
0
400
0
15
5
10
Time
0
15
5
10
Time
0
15
FIGURE 17.2
Analysis of the posterior distributions. (a) Once the posterior parameter distri-
bution is obtained, one can simulate all species of the model based on samples
from the posterior distribution. Shown are the mean (dark black), the 25%
and 75%-iles (dark grey), and the 5% and 95%-iles (light grey) of 500 sim-
ulated trajectories. (b) The marginal posterior distributions (diagonal) and
the pairwise density plots (oﬀ-diagonal) contain insights about identiﬁability
and correlations. Parameter p4 was assumed to be known and is therefore not
inferred.
17.3
ABC Model Selection in Systems Biology
In any ﬂedgling scientiﬁc discipline, quantitative mechanistic models must be
subject to revision and cycles of improvement. In systems biology, ABC has
therefore been attracting considerable attention as a tool for model selection
[36]. Choosing from a set of competing hypotheses (or models) is central to
many systems biology applications [37].

520
Handbook of Approximate Bayesian Computation
17.3.1
Dynamical systems and model selection
Model selection in ABC contexts has been an active ﬁeld of research and
has thrown up some of the most important questions in ABC inference
[8–10,16,38]. When summary statistics, s = s(y), are used, then, even for suf-
ﬁcient summary statistics, it may not be possible to compare diﬀerent models.
Diﬀerent models m1 and m2, corresponding to diﬀerent models f1(y|θ1) and
f2(y|θ2), with potentially quite diﬀerent parameter sets θ1 and θ2, will tend to
have diﬀerent suﬃcient statistics s1 and s2, respectively. As a rule, the union
of these statistics s1 ∪s2 does not oﬀer a suﬃcient statistic across models [9].
This would be the death of ABC model selection save for a relatively
limited class of problems (and one where other exact mechanisms are
available). A range of pragmatic alternative ABC approaches have, however,
been published that promise to extend the use of ABC to model selection prob-
lems. Barnes et al. have developed an information-theoretical framework that
constructs vector-valued summary statistics s = (s1, s2, . . . , sq) that are suﬃ-
cient or nearly suﬃcient (i.e. to within an acceptable or practical limit) within
and across the models to be compared. This set has to be developed in practice
in a greedy fashion [39]. Alternatively, Prangle and colleagues have developed
an eﬃcient algorithm that identiﬁes suitable summary statistics (for parame-
ter inference and model selection) based on a preliminary set of simulation runs
that are used to construct a (nearly) suﬃcient set of summary statistics [8].
The most important set of problems considered by mathematical models in
systems biology relates, however, to the temporal change of molecular abun-
dancies in response to environmental or developmental signals (such as growth
factors in tissues that determine proliferation or diﬀerentiation of cells). For
such dynamical systems, there are no summary statistics that would represent
the data in a meaningful or helpful manner better than the data do themselves.
We are thus able to compare and contrast mechanistic models in systems biol-
ogy for many of the problems of interest. Here, the ability to analyse biological
data in a meaningful manner has, however, also changed the types of problems
considered, and many more experimental studies seek to collect time-resolved
data for that purpose.
For given observations, yobs, and m competing models, mi with fi(y|θi)
(such as diﬀerent ODE or SDE models) and i = 1, 2, . . . , m, we can therefore
evaluate the ABC marginal likelihoods πABC(mi|yobs). There are diﬀerent
ways in which this quantity can be evaluated. Perhaps the easiest way is to
augment the parameter vector by a discrete model indicator [40]. Thus, infer-
ence in ABC-SMC (or any other computational scheme) can proceed on the
joint model-parameter space θ∗= (i, θ), where θ∗now contains all parameters
considered in all the models [16].
We thus have for N draws from:
πABC(mj|yobs) ∝
N

i=1
Kh(||y −yobs||)pi(y|(i, θi))πi(((θi))δi,jπ(mi),
(17.11)

ABC in Systems Biology
521
where δi,j is the normal Kronecker delta, and we assume that the parameter
and model priors can be written as π(θi)π(mi). That is, the fraction of parti-
cles that correspond to model j determines the posterior model probability.
On this joint space, model selection is easily incorporated into ABC-SMC
or other computational frameworks [16]. In practice, the problems of mon-
itoring convergence can be quite considerable, and, ideally, inference across
models should be accompanied by parameter analysis for each model consid-
ered [41]. And, of course, ABC model selection shows the same dependence on
the choice of parameter priors for each model as conventional, exact Bayesian
model selection.
We illustrate an example of ABC-SMC for model selection [35] by re-
turning to the gene regulation model from Section 17.2.1 and the generated
data describing the time course of mRNA. One could ask whether the post-
translational modiﬁcation of P1 resulting in P2 is necessary to explain the
data. A second, simpler model (Figure 17.3a) is then deﬁned as:
dm
dt = P1p2 −Mp4 + dWt
dP1
dt
= Mp0 −P1p4 + dWt
100
P1
P1p2
p4
p0
p4
M
0.2
0.4
P(M|D)
0.6
0.8
0.0
1.0
80
60
Epsilon
(b)
(a)
40
FIGURE 17.3
Model selection in the ABC-SMC framework. (a) A second gene regulation
model was constructed and compared to model 1. The second model does not
contain the post-translational modiﬁcation and is therefore a simpliﬁcation of
model 1: mRNA (M) produces the protein P1, which is required to produce M.
Both, M and P1 are degraded with constant rates. (b) Shown is the evolution
of the posterior model probability for model 1 (dark grey) and model 2 (light
grey) in the ABC-SMC framework. With decreasing tolerance (epsilon), model
1 is more likely to represent the data.

522
Handbook of Approximate Bayesian Computation
Using an initial model probability of (M1, M2)=(0.5, 0.5), we infer the pos-
terior model distribution (Figure 17.3b). We ﬁnd that over the ABC-SMC
populations the data are more likely produced by M1. This is not too sur-
prising, because the data were generated by the corresponding deterministic
model (ODE) of model 1. However, this also means that model 1 can not be
reduced to model 2 in order to describe the dynamical system of interest.
17.3.2
ABC for design
Model selection aims to identify which model among a set of candidates best
explains the available data; in Bayesian model selection, we assign a proba-
bility to each model, p(mi|yobs). In synthetic biology, the aim is to develop
rationally engineered biological systems (or circuits) that are able to carry
out speciﬁc functions [42]. Biosensors that allow cells to signal the presence of
certain environmental conditions are typical examples, as are organisms that
produce desirable high-value compounds using biomolecular pathways that do
not occur naturally. In such a synthetic biology setting, we may have diﬀerent
competing design ideas, which we can also represent in terms of mathemati-
cal models, mi. But instead of data, yobs, we now have a set of objectives or
desired system behaviours [43].
If we can encode such outputs in a convenient way, for example, by
providing surrogate data, y, then we can apply ABC to identify that de-
sign that is best able to satisfy our speciﬁcations. Here, pABC(mi|y) is in
all respects equivalent to the posterior distribution (17.11); the only diﬀer-
ence is that we replace observed data with the data that we would like to
see. In traditional synthetic biology settings, optimisation is often used to
identify models that fulﬁl given design objectives [44], but the Bayesian per-
spective also oﬀers an assessment of the robustness of the diﬀerent design
alternatives [43].
17.4
Network Analysis and Inference
Molecular networks have become a popular organisational tool in systems
biology [45]. They allow researchers to gain a level of control over the diver-
sity of molecular processes occurring inside cells, and they can form the basis
for the mathematical characterisation of biological systems. But because these
networks typically consist of thousands of nodes or vertices v ∈V that are con-
nected by edges eij = (vi, vj) ∈E, the level of analysis is typically more coarse
grained than for the dynamical systems considered earlier. Instead of detailed
mechanistic analysis, we are typically conﬁned to calculation of graph theoreti-
cal summary statistics and statistical dependencies among nodes. Analyses are
now becoming more sophisticated and detailed, especially as the combination

ABC in Systems Biology
523
of diﬀerent types of networks (e.g. transcriptional regulation, protein-protein
interaction and metabolic networks) opens up new perspectives and throws
up new modelling challenges [46].
Here, for concreteness, we will be considering binary networks, where the
entries in the adjacency, A = (aij), are either 1, if an edge is present between
nodes i and j, or zero otherwise. This is particularly useful for protein-
interaction networks, but more generally, we can use this binary representation
for any network structure; any quantitative aspects of interaction strengths
etc. can be speciﬁed via a separate matrix, for example, a weight matrix,
W = (wij), and the whole quantitative network is then given by the Hadamard
product of adjacency and weight matrix, A ◦W.
17.4.1
Models of network evolution
Just as ABC methods ﬁrst emerged in population and evolutionary genetics,
so did ABC inference enter the systems biology arena ﬁrst as a tool to analyse
the evolution of biological networks [47]. The way in which networks evolve
is typically also modelled as a Markov process, although this generally takes
the form of a discrete time Markov process, where each time-step involves
a change to the network structure. In particular, the evolution of protein-
protein interaction networks has attracted much attention. These networks
aim to describe the whole set of potential PPIs in a given organism, data are
available for an increasing number of species, but the most complete networks
are still in brewer’s yeast, Saccharomyces cerevisiae.
The most popular models include: (i) attachment of a new node to the
existing network, where the node is connected to existing nodes by a ﬁxed or
random number of edges; (ii) duplication of an existing node with inheritance
of some or all of its edges; or (iii) ‘rewiring’ of edges [49,48]. Thus, the Markov
process operates on the network or a convenient representation, such as the
adjacency matrix. Early analyses of networks, including their evolution have
focussed on the degree distribution, p(d), the probability for a node to have
degree, d, here, the degree of a node is the number of nodes in the network
that a node is connected to. This is because it is particularly straightforward
to write down a chemical master equation for the degree distribution as new
nodes are added to the network:
pt+1(d) ∝
t

i=0
pt(i)q(d, i) −pt(d)q(i, d),
where q(i, j) is the probability that a node with degree j will become a node
with degree j given the evolutionary process [50].
17.4.2
Distances and summaries of network data for ABC
The degree distribution can, of course, be used to determine a likelihood and
it is indeed possible to use this to deﬁne a composite likelihood. But it only

524
Handbook of Approximate Bayesian Computation
captures a single aspect, and arguably not a very important or decisive one.
For some models it is possible to write down likelihoods of networks, and im-
portance sampling approaches have been used to obtain some insights into the
evolution of networks under a duplication-attachment model [51]. But in ad-
dition to the computational cost of the likelihood evaluation, the likelihood is
not identiﬁed for all network structures, and there remains a core network that
can not further be decomposed in a manner compatible with the duplication
attachment model.
For these reasons, ABC oﬀers an attractive framework in which we can
study the evolution of biological networks (or at least evolutionary models of
the evolution of models). The primary problem is related to the choice of sum-
mary statistics: summary statistics for networks can be expensive to calculate
(many scale O(N 3), where N is the number of nodes in the network), and
only capture aspects of the network; there is, crucially, no suﬃcient summary
statistic for a network.
The ﬁrst attempt at using ABC to determine the parameters of a plausible
model of network evolution therefore relied on a collection of summary statis-
tics. Ratman and colleagues [47] therefore used extensive simulations to ex-
plore the feasibility of their approach – where they also took into consideration
that the available data on protein-protein interactions is incomplete. However,
this adds to the computational complexity, which is already quite considerable.
An alternative way of applying ABC to network evolution has considered
the edit distance between networks [52]. For two networks with adjacency
matrices A1 = (a1
ij) and A2 = (a2
ij) this is deﬁned as:
de =
N

i,j=1

a1
ij −a2
ij
2 .
(17.12)
Equation (17.12) assumes that the nodes are labelled or ordered suitably.
While the nodes in the real data will be labelled, for example, by protein ID,
sequence accession number, or similar, the nodes in the simulated network
are not labelled in a natural or meaningful way. Instead, we would have to
identify the permutation of labels of the nodes of the simulated network G′
that minimises the edit distance between observed adjacency matrix, Aobs
and the adjacency matrix of the simulated network, Aθ. This, however, can
be approximated conveniently by the spectral distance:
dλ =
N

i=1

λ(i)
obs −λ(i)
θ
2
,
(17.13)
which provides a lower bound on the edit distance, dλ ≤de. Thus, with the
help of equation (17.13), we have an approximation to the distance between
the data [52], which is, of course, very diﬀerent from a distance of summary
statistics of the data.
Using the ABC-SMC estimator proposed by Toni et al. [21] we can thus ob-
tain parameter estimates and, for the distance deﬁned by (17.13), also choose

ABC in Systems Biology
525
(a)
(b)
FIGURE 17.4
Examples of network evolution models. (a) The preferential attachment model
has been used to model generic, but non-biological network growth models.
Here, nodes are added to the network and connected to existing nodes propor-
tionally to their degrees. (b) In the duplication-attachment model, networks
grow by duplication of existing nodes and (partial) inheritance of edges by
copies. These are among the simplest models that can and have been used to
investigate network evolution.
from diﬀerent models. For the two simplistic models shown in Figure 17.4,
for example, we ﬁnd that for any real biological network pABC(mDA) ≈1, if
only the preferential attachment model is considered as an alternative. If we
consider more complicated models that include duplication, attachment, and
divergence (rewiring) of edges, then this situation changes: the DA model
retains some posterior probability but is generally [except for yeast, where
pABC(mDA) ≈0.4] loosing out to more complicated models [52]. Here, as
elsewhere, it is important to remember that these models are vast oversimpli-
ﬁcations of a much more complicated and historically contingent evolutionary
process.
17.5
Multi-Scale Models
Observing processes inside living organisms – whether they are bacteria,
archaea single celled eukaryotes, or more complex multi-cellular beings – poses
a number of challenges. Keeping the organism alive during observations is
one of them; while this is not always required, many physiological processes
can only be meaningfully studied in living organisms [53]. This is one, but
certainly not the only reason, for the rise in so-called multi-scale modelling
approaches [54]. Here we adopt a pragmatic deﬁnition of what constitutes a
multi-scale process: one where events at one spatial (or spatio-temporal) scale

526
Handbook of Approximate Bayesian Computation
aﬀect or need to be observed at a diﬀerent, typically higher level. An example
of this is provided by the movement of cells through their environment: we ob-
serve the pattern of migration that is governed by a set of complex molecular
processes occurring inside (or on the surface of) the cell.
17.5.1
Inference for biological multi-scale models
Common to multi-scale models is thus a juncture between the processes that
we can measure and those that we want to understand [54]. From this, stem a
range of practical problems, as well as a formidable inferential problem. The
former includes, for example, the potential need to smooth data.
In discrete time a hidden Markov model (HMM) could represent a two-
scale process (see Figure 17.5), here, however, Xi can represent a biological
network or dynamical system, and Yi is an observation (potentially vector-
valued) at a typically higher level that is shaped by processes aﬀecting Xi.
Yi and Xi are linked by some observation function:
Yi ∼g(Xi; η).
HMMs are widely used in computational statistics (including in computational
biology) and signal processing, and a wealth of statistical techniques have been
developed that allow us to infer the parameters (and structure) of HMMs for
suﬃciently simple Markov processes describing the temporal evolution of Xi.
Here, however, we have potentially much more complicated structures that
determine how Xi changes.
We are after a posterior p(x, θ|y), assuming that the observation function
g(x; η) is suﬃciently simple and well characterised; often, in fact, we can treat
this as a deterministic function that maps Xi ∈Rm to Yi ∈Rn (typically
with n ≪m). Note that Yi may in many cases be a summary statistic –
or should at least be understood as one; for example, there is a potential
deterioration in information about Xi and θ. But generally, evaluation of the
likelihood for multi-scale systems will be diﬃcult or impossible, which makes
ABC approaches an attractive alternative [7].
X1
X2
X3
X4
X5
X6
X7
Y1
Y2
Y3
Y4
Y5
Y6
Y7
FIGURE 17.5
The structure of a hidden Markov model (HMM). Observations of states Yi
need to be linked to the underlying, but non-directly observable state Xi,
which is assumed to be given by a Markov process.

ABC in Systems Biology
527
Analogously to the state-space models discussed in Section 17.2.1 we write
down an approximate posterior of the form:
pABC(θ|yobs) ∝Kh(||y −yobs||)g(y|x)p(x|θ)π(θ),
(17.14)
which assumes that the parameters regarding the observation process, η, are
known – which may be the case, often η can be assumed to be normally
distributed if it represents measurement noise. Otherwise we write:
pABC(θ, η|yobs) ∝Kh(||y −yobs||)g(y|x, η)p(x|θ)π(θ)π(η).
(17.15)
Here, g(y|x, η) typically is a function connecting spaces of diﬀerent dimension-
ality. The mutual information between the random variables A and B tells us
how much knowing the state of the observation A reduces the uncertainty
about B:
I(A, B) = H(A) −H(A|B),
where H(A) is the entropy of A and H(A|B) is the conditional entropy of A
given B. Y will be suﬃcient about the parameters θ if and only if:
I(Y, θ) = I(X, θ);
but since Y is generated from X in a manner dependent on some additional
parameters, η, this will rarely be fulﬁlled.
This oﬀers, we feel, exciting opportunities for future research in ABC.
While this problem is related to the problem of ﬁnding suﬃcient statistics
for ABC inference, the nature of Y is restricted by the experimental and
biological problem. Whereas, we can typically investigate and combine diﬀer-
ent summary statistics until suﬃciency or near-suﬃciency has been achieved
[8,39,55–57], here, we have no or only little choice. This clearly poses challenges
on how to set up, apply, and interpret ABC inference for most multi-scale
problems.
17.5.2
ABC models of cell migration
Perhaps the simplest example of a multi-scale process that is biologically
meaningful is given by cellular migration [13,15,58,59]. Many cells, ranging
from bacteria and amoeba to immune cells in multi-cellular organisms, move
towards (or away) from certain environmental signals. A wound in a multi-
cellular organism, for example, results in the release of cytokines that can
attract immune cells. Here, the two scales are the organism or tissue and the
immune cells, respectively. What makes this problem more tractable than the
models alluded to earlier is that the model for the migrating cells can be rel-
atively simple: for example, a gradient in the attractant can determine the
direction of the next move.

528
Handbook of Approximate Bayesian Computation
Migration and models of migratory processes can, if experimentally
resolved in suﬃcient detail, produce large amounts of data, and there are
many diﬀerent summary statistics that can be used to characterise migra-
tion [60]. Average displacement, its variance, the distribution over angles
between successive moves, directionality coeﬃcients, etc. can all be used to
quantify aspects of the movement. Suﬃciency of these is, however, only given
for some types of models.
We illustrate how ABC aids the analysis of cell migration data using the
example of immune cell migration of macrophages in response to acute in-
jury [13]. At the wound, a cytokine is produced and released into the tissue,
which guides the macrophages towards the wound. We are interested in learn-
ing the diﬀusive behaviour of that cytokine over time based on macrophage
migration data (Figure 17.6). The macrophage is described as a circle centred
at (x, y) with radius r. In presence of the cytokine, the macrophage detects
the concentration on its cell surface and migrates towards higher cytokine
concentration. In our system, we can assume that the cytokine concentra-
tion is constant for a given distance, x, from the wound, which means that
the macrophage can be simpliﬁed to its centre coordinates (x, y), a front
x −r, and a rear x + r. To model the directionality of the macrophage,
we now need to detect the cytokine concentration at the front and back of
the cell. The detection of the concentration can be modelled assuming sim-
ple receptor-ligand binding kinetics, as we assume that this process is much
Distance from source x
Cytokine concentration f(x,t)
Wound
Cytokines
Macrophage
r - radius
R - number of
receptors
FIGURE 17.6
Cell migration model. Cytokines emenating from a wound are sensed by re-
ceptors, R, on the surface of macrophages (modelled as spheres with radius
r, the concentration of the cytokines changes over time and with the distance
to the wound, macrophages need to detect the gradient in order to ﬁnd their
way to the cytokine source.

ABC in Systems Biology
529
faster than the migration of the macrophage itself; we can therefore apply the
steady state description of the bound ligand (the cytokine) to the receptors
with:
C(f(x)) = 1
2 (R + f(x, t) + Kd) −

1
4(R + f(x, t) + Kd)2 −Rf(x, t),
where C is the concentration of cytokine bound to receptors, R is the concen-
tration of receptors at the front and at the rear of the cell, Kd is the diﬀusion
constant, and f(x, t) describes the cytokine concentration at position x and
time t.
The migration behaviour of the macrophage can be modelled as a biased
persistent random walk [61], where for simplicity we describe a cell trajectory
as a sequence of αt, which is the angle between a motion vector of the cell
and the negative x-axis (pointing towards the site of injury):
αt = wNc(αt−1, σp)
	



persistence
+ (1 −w)Nc(0, σb)
	



bias
.
Here, w denotes the weight between the wrapped normal distributions (Nc)
describing the biased and the persistent motion. The strengths of the bias
(σb) and the persistence (σp) depend on the detected diﬀerences in cytokine
concentration at the front and at the back of the macrophage:
△Cmax = argmax
y
(C(f(x, t)) −C(f(x + 2r, t))).
Furthermore we deﬁne:
ρp = pmax

1 + dp
C(f(x −r, t)) −C(f(x + r, t))
△Cmax
−1

,
ρb = bmax

1 + db
C(f(x −r, t)) −C(f(x + r, t))
△Cmax
−1

,
where pmax and bmax describe the maximum possible persistence and bias,
respectively. Finally, we obtain the strength of the bias and persistence via:
σp = −2log(ρp) and σb = −2log(ρb).
From previous studies [13,59], we can know that we can assume the cytokine
distribution follows a diﬀusion type gradient:
f(x) =
A
√4πDc
e−x2/4πDc,
(17.16)
where A is the strength of the cytokine source, and Dc is the diﬀusion coeﬃ-
cient of the cytokine. We now deﬁned a cell migration model described by a
sequence of αt for each cell. From this sequence, one can easily compute the
cell trajectories with coordinates (x, y) over time given the initial coordinates
at time t = 0 and the distribution of the step length, which we deﬁne as:
st ∼
√
dt ∗N +(1, 1),
(17.17)
where N +(1, 1) is a truncated normal distribution, truncated at 0, and
dt = 0.001.

530
Handbook of Approximate Bayesian Computation
The resulting model contains a set of parameters that we aim to infer based
on cell migration data. In the last decade, a genetically modiﬁed zebraﬁsh
has been developed that contains green ﬂuorescent protein (GFP) labelled
macrophages. This allows us to track macrophages over time after wounding
the zebraﬁsh tail in vivo. The cells tracks can be extracted and summarised
using the above mentioned statistics. For this example, we chose to compute
the observed distributions of the directionality coeﬃcient D in dependence of
the distance from the wound (three spatial clusters) and time after wounding
(ﬁve temporal clusters) (see data in Figure 17.7). For each spatio-temporal
cluster we compute the distribution S of the straightness indices S(i)
D for the
extracted trajectories:
S(i)
D = di
li
,
(17.18)
where li is the total length of the trajectory and:
di = |x0, xend|,
is the Euclidian distance between start and end point of each trajectory i,
equation (17.18) can thus be written as:
S(i)
D = |x0, xend|
li
.
(17.19)
In order to compare the distributions we use the Kolmogorov–Smirnov dis-
tance between their respective histograms, the resulting distance function is:
d =
Nt

t=1
Ns

s=1
K(Ss,t, S∗s,t),
T < 3.5h
3.5h < T < 5.0h
5.0h < T < 6.5h
6.5h < T < 8.0h
T > 8.0h
0.0
0.4
D
A
B
C
A
B
C
A
B
C
A
B
C
A
B
C
0.8
0.0
0.4
D
0.8
0.0
0.4
D
0.8
0.0
0.4
D
0.8
0.0
0.4
D
0.8
FIGURE 17.7
Representation of the cell migration data. The cell tracks are summarised
using the directionality coeﬃcient. Shown are the distributions of the direc-
tionality coeﬃcient, D, divided into three diﬀerent clusters according to the
distance from the wound (A: x < 250 μm, B: 250 μm < x < 500 μm, and C:
x > 500 μm) and furthermore clustered according to time, T, post-wounding.

ABC in Systems Biology
531
where S and S∗are the distributions of S for the experimental data and
the simulated data, respectively, Ns and Nt are the number of spatial and
temporal groups (here three and ﬁve), and K is the Kolmogorov–Smirnov dis-
tance for pairs of empirical distribution functions. The Kolmogorov–Smirnov
distance is deﬁned as:
K(S, S∗) = sup
x |S(x) −S∗(x)|,
with S and S∗are the two empirical distribution functions that we aim to
compare.
We now have: (i) a model to describe macrophage migration in response
to wounding, (ii) a dataset described by the distributions of directionality
coeﬃcients, and (iii) a distance function (Kolmogorov–Smirnov distance).
Application of ABC-SMC allows us to estimate the parameters that deﬁne
the cell migration, but also the parameters that describe the cytokine gra-
dient. Sampling from the posterior parameter distribution we can then, for
example, visualise the inferred cytokine gradients for the ﬁve temporal clus-
ters as shown in Figure 17.8, from this analysis we can learn, among other
things, that the cytokine signals are produced at the wound site for up to
7 hours. Such insights provide clues as to how wound signalling gradients
are established and may be managed. Here the analysis was carried out in
embryos (as these are optically transparent), but the inﬂammatory response
to, for example, wounding will also need to be understood in older individ-
uals, where it can be linked to ageing [62]. Mechanistic models will help to
understand better the inﬂammatory response to a wound, which can have
undesirable side-eﬀects, for example, scaring, currently ABC seems to be the
only statistical framework capable of dealing with these problems.
One modelling approach that is gaining popularity in this domain is agent-
based model [63]. They consist of agents – in our context, for example, individ-
ual organisms or cells – that interact with their environment and each other.
Distance from
source x (μm)
0
0.3 0.4
Relative chemokine concentration
0.5 0.6
0.2
0.7
200
T < 3.5h
3.5h < T < 5.0h
5.0h < T < 6.5h
6.5h < T < 8.0h
8.0h > T
400
Distance from
source x (μm)
0
0.3 0.4
Relative chemokine concentration
0.5 0.6
0.2
0.7
200 400
Distance from
source x (μm)
0
0.3 0.4
Relative chemokine concentration
0.5 0.6
0.2
0.7
200 400
Distance from
source x (μm)
0
0.3 0.4
Relative chemokine cconcentration
0.5 0.6
0.2
0.7
200 400
Distance from
source x (μm)
0
0.3 0.4
Relative chemokine concentration
0.5 0.6
0.2
0.7
200 400
FIGURE 17.8
Spatio-temporal characteristics of cytokine gradients. The estimated cytokine
gradients are shown for the ﬁve time intervals post wounding. Dark grey lines
indicate the means of simulations from the posterior parameter distributions,
and light grey lines are the respective 5%-ile and 95%-ile.

532
Handbook of Approximate Bayesian Computation
Interactions can be mediated by direct contact or via the exchange of (e.g.
biochemical) signals that determine how agents behave next. ABC methods
have already been employed to study models of stem cell dynamics, tumour
growth models of stem cells, and cancer dynamics in intestinal crypts (which
are the sites from which intestinal lining tissue is being renewed) [64], as well
as tumour evolution [71]. Determination of a likelihood is typically impossible
for these models and, despite the great cost of simulating such models [65],
ABC approaches are beginning to bear fruit. The main challenge of applying
ABC in this context seems to be the lack of suitably fast simulation software:
mathematical and computational modelling typically involve small to moder-
ate numbers of simulations, whereas simulation-based inference requires orders
of magnitude larger numbers of simulation runs for many diﬀerent parameter
combinations.
17.6
ABC and Beyond
The virtue of ABC is to open up Bayesian inference to problems that defy con-
ventional, exact inference. Where statistical inference that accounts for uncer-
tainty and conﬁdence appropriately [6] is otherwise not possible, optimisation
is often used. ABC is perhaps best used as a stop-gap for problems for which
exact Bayesian inference is (at least for now) computationally too expensive or
not yet applicable. Parameter estimation and especially model selection, which
is possible for dynamical systems as no summary statistics are used, are central
to many problems in systems biology. And for many of these problems, ABC
oﬀers the most direct and convenient way of applying the Bayesian framework.
The central aim of statistical inference in systems biology is to get a bet-
ter understanding of how biological systems – cells, tissues or even whole
organisms—work, through the development of mechanistic models, from these
models testable hypotheses can be distilled that probe our understanding fur-
ther [66]. Even preliminary understanding of these systems (or of our models
of them) may in turn guide the way towards applying exact inference methods,
perhaps on approximate, computationally more amenable models. Examples
of such approximations include the linear noise approximation [23], moment
expansion approaches [26], and ﬁnite state projection approaches [67], which
all provide approximations to the stochastic dynamics normally described by
the chemical master equation [70]. These approaches allow us to simulate the
dynamics at reduced computational cost, but often they also allow us to derive
expressions of tractable likelihoods, that can be used in Bayesian inference.
Now, however, instead of performing approximate inference on ‘exact’ mod-
els, we can employ exact inference on approximate models. Given that these
models are already oversimpliﬁcations or abstractions of a much more com-
plicated reality, it is hard to say which approximation is more problematic.

ABC in Systems Biology
533
Tools to assess how much the assumption of a given model structure aﬀects
further analyses are only now emerging [37], and we can integrate these into
our statistical analysis workﬂows. Nevertheless, there remains the question of
how bad the ABC approximation using the full model is compared to approx-
imating the model to yield a tractable likelihood.
While ABC may only be a stop-gap for many dynamical systems, for multi-
scale problems – at least those that are of biological interest – ABC oﬀers
perhaps the only viable inferential framework that is currently available [72].
Here, however, the question as to whether the available or observable data are
suﬃcient for parameter inference, let alone model selection, remains open, the
answer will probably be very problem speciﬁc. For some migration processes, it
will generally be possible to apply ABC and obtain robust estimates eﬃciently.
For some more complicated multi-scale systems, including many agent-based
models, this problem needs to be carefully assessed.
Multi-scale systems are gaining prominence also outside of systems biol-
ogy and provide rich pickings for statisticians, especially those interested in
ABC inference. Whether we can use ABC as a true approximation to con-
ventional inference, or as a base for an alternative inferential framework, as
has sometimes been suggested, remains to be seen. And addressing the lack
of powerful simulation approaches – or side-stepping simulation in favour of
emulation [68,69] – will be a ﬁrst necessary step in establishing ABC in these
contexts.
References
[1] J Ross and A P Arkin. Complex systems: From chemistry to systems
biology. Proceedings of the National Academy of Sciences of the United
States of America, 106(16):6433–6434, 2009.
[2] D S Goodsell. The Machinery of Life. New York: Springer Science &
Business Media, 2009.
[3] C J Oates and S Mukherjee. Network inference and biological dynamics.
The Annals of Applied Statistics, 6(3):1209–1235, 2012.
[4] T W Thorne, P Fratta, M G Hanna, A Cortese, V Plagnol, E M Fisher,
and M P H Stumpf. Graphical modelling of molecular networks underly-
ing sporadic inclusion body myositis. Molecular Biosystems, 9(7):1736–
1742, 2013.
[5] J Gunawardena. Models in biology: ‘Accurate descriptions of our pathetic
thinking’. BMC Biology, 12(1):29, 2014.
[6] P D W Kirk, A C Babtie, and M P H Stumpf. Systems biology
(un)certainties. Science, 350(6259):386–388, 2015.

534
Handbook of Approximate Bayesian Computation
[7] M P H Stumpf. Approximate Bayesian inference for complex ecosystems.
F1000Prime Reports, 6(60):60, 2014.
[8] P Fearnhead, D Prangle, M P Cox, P J Biggs, and N P French. Semi-
automatic selection of summary statistics for ABC model choice. Statis-
tical Applications in Genetics and Molecular Biology, 13(1):67–82, 2014.
[9] C P Robert, J M Cornuet, J M Marin, and N S Pillai. Lack of conﬁdence
in approximate Bayesian computation model choice. Proceedings of the
National Academy of Sciences, 108(37):15112–15117, 2011.
[10] R D Wilkinson. Approximate Bayesian computation (ABC) gives exact
results under the assumption of model error. Statistical Applications in
Genetics and Molecular Biology, 12(2):129–141, 2013.
[11] M Cohen, A Kicheva, A Ribeiro, R Blassberg, K M Page, C P Barnes, and
J Briscoe. Ptch1 and Gli regulate Shh signalling dynamics via multiple
mechanisms. Nature Communications, 6:6709, 2015.
[12] J Liepe, H G Holzh¨utter, E Bellavista, P M Kloetzel, M P H Stumpf, and
M Mishto. Quantitative time-resolved analysis reveals intricate, diﬀeren-
tial regulation of standard- and immuno-proteasomes. eLife, 4:e07545,
2015.
[13] J Liepe, H Taylor, C P Barnes, M Huvet, L Bugeon, T W Thorne, J R
Lamb, M J Dallman, and M P H Stumpf. Calibrating spatio-temporal
models of leukocyte dynamics against in vivo live-imaging data using ap-
proximate Bayesian computation. Integrative Biology: Quantitative Bio-
sciences from Nano to Macro, 4(3):335–345, 2012.
[14] J Liepe, S Filippi, M Komorowski, and M P H Stumpf. Maximizing the
information content of experiments in systems biology. PLoS Computa-
tional Biology, 9(1):e1002888, 2013.
[15] G R Holmes, S R Anderson, G Dixon, A L Robertson, C C Reyes-
Aldasoro, S A Billings, S A Renshaw, and V Kadirkamanathan. Repelled
from the wound, or randomly dispersed? Reverse migration behaviour of
neutrophils characterized by dynamic modelling. Journal of The Royal
Society Interface, 9(77):3229–3239, 2012.
[16] T Toni and M P H Stumpf. Simulation-based model selection for dynam-
ical systems in systems and population biology. Bioinformatics (Oxford,
England), 26(1):104–110, 2010.
[17] A L Maclean, C Lo Celso, and M P H Stumpf. Population dynamics of
normal and leukaemia stem cells in the haematopoietic stem cell niche
show distinct regimes where leukaemia will be controlled. Journal of the
Royal Society Interface, 10(81):20120968–20120968, 2013.

ABC in Systems Biology
535
[18] N Domedel-Puig, I Pournara, and L Wernisch. Statistical model compar-
ison applied to common network motifs. BMC Systems Biology, 4(1):18,
2010.
[19] P Kirk, T Toni, and M P H Stumpf. Parameter inference for biochemical
systems that undergo a Hopf bifurcation. Biophysical Journal, 95(2):540–
549, 2008.
[20] S Rogers and M Girolami. A Bayesian regression approach to the infer-
ence of regulatory networks from gene expression data. Bioinformatics,
21(14):3131–3137, 2005.
[21] T Toni, D Welch, N Strelkowa, A Ipsen, and M P H Stumpf. Approxi-
mate Bayesian computation scheme for parameter inference and model
selection in dynamical systems. Journal of the Royal Society Interface,
6(31):187–202, 2009.
[22] D J Wilkinson. Stochastic Modelling for Systems Biology. Boca Raton,
FL: CRC Press, 2011.
[23] E W J Wallace, D T Gillespie, K R Sanft, and L R Petzold. Linear noise
approximation is valid over limited times for any chemical system that is
suﬃciently large. IET Systems Biology, 6(4):102–115, 2012.
[24] A Golightly and D Wilkinson. Bayesian sequential inference for stochastic
kinetic biochemical network models. Journal of Computational Biology,
13(3):838–851, 2006.
[25] A Golightly and D J Wilkinson. Bayesian parameter inference for stochas-
tic biochemical network models using particle Markov chain Monte Carlo.
Interface Focus, 1(6):807–820, 2011.
[26] A Ale, M P H Stumpf, and P Kirk. A general moment expansion
method for stochastic kinetic models. The Journal of Chemical Physics,
138(17):174101, 2013.
[27] A Golightly and D J Wilkinson. Bayesian inference for stochastic kinetic
models using a diﬀusion approximation. Biometrics, 61(3):781–788, 2005.
[28] M Secrier, T Toni, and M P H Stumpf. The ABC of reverse engineer-
ing biological signalling systems. Molecular Biosystems, 5(12):1925–1935,
2009.
[29] S A Sisson, Y Fan, and M M Tanaka. Sequential Monte Carlo without like-
lihoods. Proceedings of the National Academy of Sciences, 104(6):1760–
1765, 2007.

536
Handbook of Approximate Bayesian Computation
[30] J F Apgar, D K Witmer, F M White, and B Tidor. Sloppy models,
parameter uncertainty, and the role of experimental design. Molecular
BioSystems, 6(10):1890–1900, 2010.
[31] K Erguler and M P H Stumpf. Practical limits for reverse engineering
of dynamical systems: A statistical analysis of sensitivity and parameter
inferability in systems biology models. Molecular Biosystems, 7(5):1593–
1602, 2011.
[32] R N Gutenkunst, J J Waterfall, F P Casey, K S Brown, C R Myers, and
J P Sethna. Universally sloppy parameter sensitivities in systems biology
models. PLoS Computational Biology, 3(10):1871–1878, 2007.
[33] M Komorowski, M J Costa, D A Rand, and M P H Stumpf. Sensitiv-
ity, robustness, and identiﬁability in stochastic chemical kinetics models.
Proceedings of the National Academy of Sciences of the United States of
America, 108(21):8645–8650, 2011.
[34] J Liepe, C P Barnes, E Cule, K Erguler, P Kirk, T Toni, and M
P H Stumpf. ABC-SysBio–approximate Bayesian computation in Python
with GPU support. Bioinformatics (Oxford, England), 26(14):1797–1799,
2010.
[35] J Liepe, C P Barnes, P Kirk, S Filippi, T Toni, and M P H Stumpf.
A framework for parameter estimation and model selection from experi-
mental data in systems biology using approximate Bayesian computation.
Nature Protocols, 9(2):439–456, 2014.
[36] P Kirk, T W Thorne, and M P H Stumpf. Model selection in systems
and synthetic biology. Current Opinion in Biotechnology, 24(4):767–774,
2013.
[37] A C Babtie, P D W Kirk, and M P H Stumpf. Topological sensitivity
analysis for systems biology. Proceedings of the National Academy of Sci-
ences of the United States of America, 111(52):18507–18512, 2014.
[38] O Ratmann, C Andrieu, C Wiuf, and S Richardson. Model criticism based
on likelihood-free inference, with an application to protein network evo-
lution. Proceedings of the National Academy of Sciences, 106(26):10576–
10581, 2009.
[39] C P Barnes, S Filippi, M P H Stumpf, and T W Thorne. Considerate
approaches to constructing summary statistics for ABC model selection.
Statistics and Computing, 22(6):1181–1197, 2012.
[40] A Grelaud, C P Robert, and J M Marin. ABC methods for model choice
in Gibbs random ﬁelds. Comptes Rendus Mathematique, 347:205–210,
2009.

ABC in Systems Biology
537
[41] T Toni, Y Ozaki, P Kirk, S Kuroda, and M P H Stumpf. Elucidating
the in vivo phosphorylation dynamics of the ERK MAP kinase using
quantitative proteomics data and Bayesian model selection. Molecular
Biosystems, 8(7):1921–1929, 2012.
[42] N Nandagopal and M B Elowitz. Synthetic biology: Integrated gene cir-
cuits. Science, 333(6047):1244–1248, 2011.
[43] C P Barnes, D Silk, and M P H Stumpf. Bayesian design strategies for
synthetic biology. Interface Focus, 1(6):895–908, 2011.
[44] C P Barnes, D Silk, X Sheng, and M P H Stumpf. Bayesian design of
synthetic biological systems. Proceedings of the National Academy of Sci-
ences of the United States of America, 108(37):15190–15195, 2011.
[45] C J Ryan, P Cimermanˇciˇc, Z A Szpiech, A Sali, R D Hernandez, and
N J Krogan. High-resolution network biology: Connecting sequence with
function. Nature Reviews Genetics, 14(12):865–879, 2013.
[46] E D Kolaczyk. Statistical Analysis of Network Data: Methods and Models.
New York: Springer Science & Business Media, 2009.
[47] O Ratmann, O Jørgensen, T Hinkley, M P H Stumpf, S Richardson, and
C Wiuf. Using likelihood-free inference to compare evolutionary dynamics
of the protein networks of H. pylori and P. falciparum. PLoS Computa-
tional Biology, 3(11):e230, 2007.
[48] T A Gibson and D S Goldberg. Improving evolutionary models of protein
interaction networks. Bioinformatics (Oxford, England), 27(3):376–382,
2011.
[49] M P H Stumpf, W P Kelly, T W Thorne, and C Wiuf. Evolution at the
system level: The natural history of protein interaction networks. Trends
in Ecology & Evolution, 22(7):366–373, 2007.
[50] S N Dorogovtsev and J F F Mendes. Evolution of Networks. From Bio-
logical Nets to the Internet and WWW. Oxford, UK: Oxford University
Press, 2013.
[51] C Wiuf, M Brameier, O Hagberg, and M P H Stumpf. A likelihood ap-
proach to analysis of network data. Proceedings of the National Academy
of Sciences, 103(20):7566–7570, 2006.
[52] T W Thorne and M P H Stumpf. Graph spectral analysis of protein
interaction network evolution. Journal of the Royal Society, Interface,
9(75):2653–2666, 2012.
[53] N M Rashidi, M K Scott, N Scherf, A Krinner, J S Kalchschmidt,
K Gounaris, M E Selkirk, I Roeder, and C L Celso. In vivo time-lapse

538
Handbook of Approximate Bayesian Computation
imaging of mouse bone marrow reveals diﬀerential niche engagement
by quiescent and naturally activated hematopoietic stem cells. Blood,
124(1):79–83, 2014.
[54] M A R Ferreira and H K H Lee. Multiscale Modeling. A Bayesian Per-
spective. London, UK: Springer Science & Business Media, 2007.
[55] S Aeschbacher, M A Beaumont, and A Futschik. A novel approach
for choosing summary statistics in approximate Bayesian computation.
Genetics, 192(3):1027–1047, 2012.
[56] P Fearnhead and D Prangle. Constructing summary statistics for ap-
proximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 74:419–474, 2012.
[57] M A Nunes and D J Balding. On optimal selection of summary statis-
tics for approximate Bayesian computation. Statistical Applications in
Genetics and Molecular Biology, 9(1):34, 2010.
[58] G R Holmes, S R Anderson, G Dixon, S A Renshaw, and V Kadirka-
manathan. A Bayesian framework for identifying cell migration dynam-
ics. Conference Proceedings: ... Annual International Conference of the
IEEE Engineering in Medicine and Biology Society. IEEE Engineering
in Medicine and Biology Society. Conference, 2013:3455–3458, 2013.
[59] H B Taylor, J Liepe, C Barthen, L Bugeon, M Huvet, P Kirk, S B Brown,
J R Lamb, M P H Stumpf, and M J Dallman. P38 and JNK have op-
posing eﬀects on persistence of in vivo leukocyte migration in zebraﬁsh.
Immunology and Cell Biology, 91(1):60–69, 2013.
[60] J B Beltman, A F M Mar´ee, and R J de Boer. Analysing immune cell
migration. Nature Reviews Immunology, 9(11):789–798, 2009.
[61] E A Codling, M J Plank, and S Benhamou. Random walk models in
biology. Journal of the Royal Society Interface, 5(25):813–834, 2008.
[62] A M Valdes, D Glass, and T D Spector. Omics technologies and the study
of human ageing. Nature Reviews Genetics, 14(9):601–607, 2013.
[63] H Kaul and Y Ventikos. Investigating biocomplexity through the agent-
based paradigm. Brieﬁngs in Bioinformatics, 16(1):137–152, 2013.
[64] A Sottoriva and S Tavar´e. Integrating approximate Bayesian computa-
tion with complex agent-based models for cancer research. Proceedings of
COMPSTAT’2010 (Chapter 5):57–66, 2010.
[65] M Scianna and L Preziosi. Cellular Potts Models: Multiscale Extensions
and Biological Applications. Boca Raton, FL: CRC Press, 2013.

ABC in Systems Biology
539
[66] T Toni, G Jovanovic, M Huvet, M Buck, and M P H Stumpf. From qual-
itative data to quantitative models: Analysis of the phage shock protein
stress response in Escherichia coli. BMC Systems Biology, 5(1):69, 2011.
[67] B Munsky and M Khammash. The ﬁnite state projection algorithm for
the solution of the chemical master equation. The Journal of Chemical
Physics, 124(4):044104, 2006.
[68] S Conti and A O’Hagan. Bayesian emulation of complex multi-output and
dynamic computer models. Journal of Statistical Planning and Inference,
140(3):640–651, 2010.
[69] C C Drovandi, A N Pettitt, and M J Faddy. Approximate Bayesian com-
putation using indirect inference. Journal of the Royal Statistical Society:
Series C (Applied Statistics), 60(3):317–337, 2011.
[70] C Gardiner. Stochastic Methods: A Handbook For The Natural And So-
cial Sciences. Springer, 2009.
[71] A Sottoriva, H Kang, Z Ma, T A Graham, M P Salomon, J Zhao,
P Marjoram, K Siegmund, M F Press, D Shibata, and C Curtis.
A Big Bang model of human colorectal tumor growth. Nature Genetics,
47(3):209–216, 2015.
[72] P J M Jones, A Sim, H B Taylor, L Bugeon, M J Dallman, B Pereira,
M P H Stumpf, and J Liepe. Inference of random walk models to describe
leukocyte migration. Physical biology, 12(6):066001, 2015.


18
Application of ABC to Infer the Genetic
History of Pygmy Hunter-Gatherer
Populations from Western Central Africa
Arnaud Estoup, Paul Verdu, Jean-Michel Marin,
Christian Robert, Alex Dehne-Garcia, Jean-Marie Cornuet,
and Pierre Pudlo
CONTENTS
18.1
Introduction ......................................................
541
18.2
Simulation of Datasets ...........................................
544
18.2.1
Observed dataset ........................................
544
18.2.2
Models and parameters
.................................
545
18.2.3
Computer programs .....................................
548
18.3
Results and Discussions ..........................................
549
18.3.1
Model choice: ABC random forest ......................
549
18.3.2
Parameter estimation ...................................
555
18.3.3
Model-posterior checking ................................
559
18.4
Conclusions and Perspectives ....................................
562
Acknowledgements .......................................................
563
References
...............................................................
563
18.1
Introduction
Approximate Bayesian computation (ABC; Beaumont et al., 2002) represents
an elaborate approach to model-based inference in a Bayesian setting in which
model likelihoods are diﬃcult to calculate and must be estimated by mas-
sive simulations. We will not detail here the general statistical features of
541

542
Handbook of Approximate Bayesian Computation
ABC, as they have been reviewed in previous publications (Beaumont, 2010;
Bertorelle et al., 2010; Csill´ery et al., 2010; Marin et al., 2012; Sunnaker et al.,
2013) and in other chapters of this book. ABC methods undoubtedly widen
the realm of models for which statistical inference can be considered. The
method arose in population genetics (Tavar´e, 1997; Beaumont et al., 2002)
and is increasingly used in other ﬁelds, including epidemiology, system biol-
ogy, ecology, and agent-based modelling (reviewed in Beaumont, 2010).
Although full-likelihood methods have been developed in evolutionary and
population genetics for some models, they typically rely on Markov chain
Monte Carlo that has problems converging on large datasets and there is a
limited range of model structures that can be analysed (Beaumont, 2010).
By contrast, ABC is very ﬂexible and is, hence, well adapted to investi-
gate complex models of species and population history often involving serial
or independent divergence events, changes of population sizes, and genetic
admixture or migration events (Fagundes et al., 2007; Lombaert et al., 2010).
In an ABC framework, such events can be easily simulated and, hence, incor-
porated into diﬀerent historical and demographic evolutionary models (often
called ‘scenarios’) that can be formally tested against each other with respect
to the observed data. The method can then be used to estimate the poste-
rior distributions of demographic parameters of interest, such as divergence
times, admixture rates, and eﬀective population sizes, in a given scenario
(usually the most likely one). In practice, ABC users in the ﬁeld of popula-
tion and evolutionary biology can base their analysis on simulation programs,
such as SIMCOAL (Laval and Excoﬃer, 2004), ms (Hudson, 2002), or MaCS
(Chen et al., 2009) and then use various statistical software to post-process
their simulation outputs. Several ABC programs have recently been developed
to provide non-specialist users with more integrated computational solutions
varying in user-friendliness (see the list of ABC packages and toolboxes in
Beaumont, 2010; Csill´ery et al., 2010).
In this chapter, we used a set of recent ABC-based methods to thor-
oughly analyse a human microsatellite genetic dataset from Western Central
African Pygmy and non-Pygmy populations. Central Africa and the Congo
Basin are currently peopled by the largest group of forest hunter-gatherer
populations worldwide, which have been historically called ‘Pygmies’ in ref-
erence to the mythical population of short stature described by the ancient
Greek poet Homer (Hewlett, 2014). Each Central African Pygmy group is
in the neighbourhood of several sedentary agricultural populations (hereafter
called ‘non-Pygmies’) with whom they share complex sociocultural and eco-
nomic relationships, including social rules regulating intermarriages between
communities (Verdu et al., 2013; Hewlett, 2014). Due to the lack of ancient
human remains in the equatorial forest, the origins of Pygmies and neigh-
bouring non-Pygmies, including population divergence times, remains largely
unknown (Cavalli-Sforza et al., 1994; Cavalli-Sforza and Feldman, 2003).

Application of ABC to Infer the Genetic History of Pygmy
543
Moreover, Western colonisers from the nineteenth century somewhat arbi-
trarily collapsed into a single ‘Pygmy’ group more than 20 populations that
were, and still are, culturally and geographically isolated in reality, which
further clouded our understanding of evolutionary relationships among these
populations. Thus, whether all Central African Pygmy populations shared
a common or an independent origin, and when during history did popu-
lations diverge from one another and from neighbouring non-Pygmies, was
still largely debated in the anthropology and ethnology communities (Cavalli-
Sforza, 1986; Verdu et al., 2009; Hewlett, 2014). To address these questions,
Verdu et al. (2009) genotyped strongly variable genetic markers (namely, mi-
crosatellite loci) in a dense sample of non-Pygmy and neighbouring Pygmy
populations from Western Central Africa. The resulting genetic dataset was
analysed using ABC techniques to compare a set of possible evolutionary sce-
narios and estimate key parameters under the most likely historical model
identiﬁed.
In the application of ABC methods presented here, we have extended a sub-
set of the Verdu et al. (2009) genetic dataset by adding a European population
sample previously genotyped at the same microsatellite loci and for which the
divergence time was ﬁxed during the inferential process according to previous
estimates (Fagundes et al., 2007; Gravel et al., 2011). By considering a dataset
including such a so-called ‘scaling population’, we hoped to obtain more pre-
cise inferences regarding several original key population parameters of Central
African populations’ history, such as the divergence times between Pygmies
and non-Pygmies (see Excoﬃer et al., 2013 for an illustration of inferences us-
ing a scaling human population in a diﬀerent historical and genetic context).
Additional noticeable novelties of the ABC analysis presented here compared
to Verdu et al. (2009) include the application of ABC random forest algo-
rithms to make model choice (Pudlo et al., 2016) and ABC model-posterior
checking methods to evaluate the goodness of ﬁt between the inferred genetic
history and the observed dataset.
In the following, we ﬁrst describe the observed genetic dataset for which
one wants to make inferences, the set of evolutionary models we compared,
with their respective historical, demographic, and mutational parameters,
their associated prior distributions, and the way datasets were simulated for
ABC analyses. Second, we present the model choice analyses we carried out
using ABC random forest algorithms. Third, we present the estimation of his-
torical and demographic parameters we carried out under the most likely of
the compared models for the peopling of Central Africa, with a particular in-
terest in evaluating the eﬀect (or lack of eﬀect) of using a scaling population to
improve inferences. Finally, we report the model-posterior checking analyses
we carried out to evaluate the goodness of ﬁt between the ﬁnal inferred ge-
netic history and the observed dataset. Each section includes methodological
aspects, results, and elements of discussion.

544
Handbook of Approximate Bayesian Computation
18.2
Simulation of Datasets
18.2.1
Observed dataset
The dataset included the genotyping at 26 microsatellite loci of 183 unre-
lated individuals from four Pygmy groups (i.e. the Baka, Bezan, Kola, and
Koya; 29–32 individuals per group), neighbouring non-Pygmy individuals
(33 individuals) from Cameroon and Gabon (Western Central Africa), and a
European French population (29 individuals) for which genotype data at the
same microsatellite loci was available (Rosenberg et al., 2002). This dataset
corresponds to a subset of the African dataset Verdu et al. (2009) used in
their initial ABC treatments, which originally included the genotyping at 28
microsatellite loci of 400 Pygmy and non-Pygmy individuals from Cameroon
and Gabon (see Figure 18.1; and see Verdu et al., 2009’s Table S1 for details
about geographic location of population samples and their genetic grouping).
In the present study, we considered a reduced sample set as compared to
Verdu et al. (2009) for both computational eﬃciency and to homogenise sam-
ple sizes across Pygmy and non-Pygmy populations. We kept the Bezan, Koya,
and Kola Pygmy samples identical to those used in Verdu et al. (2009) (they
had roughly the same sample sizes i.e. about 30 individuals). We re-sampled
32 Baka Pygmy individuals and 33 non-Pygmy African individuals among the
117 Baka individuals and 194 non-Pygmy Africans considered originally in
Verdu et al. (2009), respectively.
We added European individuals from France as a scaling population
sample, with the hope to obtain more precise ABC inferences about origi-
nal parameters associated to the Central African peopling history, especially
for Pygmy population history, our main topic of interest here. We built
a correspondence table for the allele calls between the datasets of Verdu
et al. (2009) and Rosenberg et al. (2002) by genotyping the 28 microsatellite
loci in ten individuals from the Human Genome Diversity Project (HGDP)-
Centre d’Etude du Polymorphisme Humain (CEPH) panel (Cann et al.,
2002). Allele calls for two loci (D14S1280 and D21S1432) could not be
unambiguously normalised between the two datasets, and these two loci
were thus discarded reducing the marker dataset from 28 microsatellites
used in Verdu et al. (2009), to 26 here. All Central African microsatellite
data originally used in Verdu et al. (2009) are available upon request at
the European Genome-phenome Archive (EGA, http://www.ebi.ac.uk/ega/)
under accession number EGAS00001000652, and all HGDP-CEPH data
at the Marshﬁeld institute (http://research.marshﬁeldclinic.org/genetics/
genotypingData Statistics/humanDiversityPanel.asp). The exact dataset used
in the present study is available upon request to some authors (PV or AE),
following ethical appropriateness.

Application of ABC to Infer the Genetic History of Pygmy
545
18.2.2
Models and parameters
We considered the same set of eight complex evolutionary models, hereafter,
referred to as scenarios, as in Verdu et al. (2009). These scenarios with their
historical and demographic parameters are represented in Figure 18.1, follow-
ing the notation of Verdu et al. (2009).
These eight scenarios formalise two main types of evolutionary histories
debated in the anthropology community. Class 1 scenarios (scenarios 1a,
1b, 1c, and 1d) correspond to a common evolutionary history of the four
Pygmy groups, where they all originate from the same ancestral Pygmy pop-
ulation, which initially diverged from the non-Pygmy population in a more
remote past. Class 2 scenarios (scenarios 2a, 2b, 2c, and 2d) correspond to
an independent evolutionary history of the four Pygmy groups, where they
each originate independently from the non-Pygmy population. Within each
scenario class, the scenarios diﬀer by two types of events: (1) the possibility
or not of recent and ancient asymmetrical admixture events between each
Pygmy population and the non-Pygmy one, as was already suggested by pre-
vious anthropological and genetic studies (Cavalli-Sforza, 1986; Hewlett, 1996;
Destro-Bisol et al., 2004), and (2) the possibility or not of a change of pop-
ulation size in the non-Pygmy population. The European French population,
used for scaling purposes, ﬁrst underwent a demographic bottleneck of dura-
tion DBooa (ooa for ‘Out Of Africa’) during which its size is NFooa and then
reached a stable population size Nooa. Following Excoﬃer et al. (2013, and
see reference therein), this scaling population was assumed to diverge from
the African non-Pygmy population at a time ﬁxed at 50,000 years (i.e. 2,000
generations assuming a generation time of 25 years).
We chose ﬂat prior distributions as in Verdu et al. (2009) for all demo-
graphic parameters: uniform distributions bounded between 100 and 10,000
diploid individuals for all Pygmy populations and ancestral population sizes
(Ni, Nap, Nai, and NA, with i between 1 and 4), between 1,000 and 100,000
for the non-Pygmy (Nnp) and the European French (Nooa) populations, and
between 10 and 1,000 for the number of European founders (NFooa) for a bot-
tleneck duration (DBooa) between 1 and 30 generations. Priors were drawn
from uniform distributions between 1 and 5,000 generations for all divergence
times (tp, tpnp, tpnpi, with i between 1 and 4), for the population size vari-
ation times (tnei, with i between 1 and 4), and for the times of ‘ancient’
introgression of non-Pygmy genes into ancestral Pygmy lineages (tra, and
trai, with i between 1 and 4). For the time of change in eﬀective population
size (tA), considered only in scenarios 1a/1b and 2a/2b, we drew our priors
from a uniform distribution bounded between 1 and 10,000 generations. For
the ‘recent’ introgression times from non-Pygmies into the Pygmy lineages
(tr, and trri, with i between 1 and 4), we chose loguniform prior distributions

546
Handbook of Approximate Bayesian Computation
Scenario 2b
Scenario 2a
Scenario 1b
0
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
0
0
0
0
0
N1
N1
N2
N2
N3
N3
N4
N4
Nnp
Nnp
Nfooa
tooa = 2,000 g
Nooa
DBooa
Nnp
Nnp
NA
Nap
Nap
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
N1
N1
N2
N2
N3
N3
N4
N4
Nnp
Nnp
Nfooa
tooa = 2,000 g
Nooa
DBooa
Nnp
Nnp
NA
Nap
Nap
trr
tp
tra
tpnp
tA
0
trr
tp
tra
tpnp
tA
1-ra
1-rr1
1-rr2
ra
rr1
1-rr3
rr2
1-rr4
rr3
rr4
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
0
0
0
0
0
0
0
0
N1
N2
N3
N4
Na4
Na3
Na2
Na1
Nnp
Nnp
NA
Nfooa
tooa = 2,000 g
Nooa
DBooa
0
trr3
tra3
tpnp3
tne3
trr4
tra4
tpnp4
tne4
trr2
tra2
tpnp2
tne2
trr1
tra1
tpnp1
tA
tne1
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
N1
N2
N3
N4
Na4
Na3
Na2
Na1
Nnp
Nnp
NA
Nfooa
tooa = 2,000 g
Nooa
DBooa
0
trr3
tra3
tpnp3
tne3
trr4
tra4
tpnp4
tne4
trr2
tra2
tpnp2
tne2
trr1
tra1
tpnp1
tA
tne1
ra1
1-rr4 rr4
1-rr3 rr3
1-rr2
rr2
1-rr1 rr1
ra4
ra3
ra2
Scenario 1a
FIGURE 18.1
Eight complex competing scenarios of origin and diversiﬁcation of Pygmy
populations from Western Central Africa. The scenarios and parameters are
similar to those in Verdu et al. (2009) and follow the same notation (Figure
in color available by request from AE). The only exception is the addition
of European individuals from France providing a scaling population sample
which diverged from African non-Pygmies at a time ﬁxed at 50,000 years (i.e.
tooa = 2,000 generations). Scenarios 1a–d correspond to a common origin of
Pygmy populations that diversiﬁed from a single ancestral Pygmy population
at time tp. The ancestral Pygmy population itself diverged at time tpnp from
the non-Pygmy population. Scenarios 2a–d correspond to an independent ori-
gin of Pygmy groups that independently diverged from the non-Pygmy popu-
lation at times ti. We simulated in the eight scenarios, two potential events of
introgression (cf. parameters tri and ri) from the non-Pygmy lineage into each
Pygmy lineage independently. Finally, Scenarios 1a, 1b, 2a, and 2b include a
potential stepwise change of eﬀective population size that occurred in the non-
Pygmy lineage at time tA. Scenarios 1b/2b were identical to scenarios 1a/2a,
except that all introgression rates (ri) were set to zero. Scenarios 1c/2c were
identical to scenarios 1a/2a, but did not consider the potential change in non-
Pygmy eﬀective size. Finally, in scenarios 1d/2d, neither introgression events
nor change in eﬀective size were considered. For all scenarios, Ni indicates the
eﬀective population size of population i. Note that for scenarios 2a–d, split
times were drawn independently for each Pygmy lineage, and, thus, the order
(Continued)

Application of ABC to Infer the Genetic History of Pygmy
547
Scenario 1d
Scenario 2d
Scenario 2c
Scenario 1c
0
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
Pygmy
Non-
Pygmy
European
French
0
0
0
0
0
0
0
0
0
0
0
0
0
N1
N1
N1
N2
N2
N2
N3
N3
N3
N4
N4
Na4
Na3
Na2
Na1
N4
Nnp
Nnp
Nnp
Nnp
Nfooa
Nfooa
tooa = 2,000 g
tooa = 2,000 g
Nooa
Nooa
DBooa
DBooa
Nnp
Nnp
Nap
Nap
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
N1
N1
N2
N2
N3
N3
N4
N4
Nnp
Nnp
Nfooa
tooa = 2,000 g
Nooa
DBooa
Nnp
Nnp
Nap
Nap
trr
tp
tra
tpnp
0
trr
tp
tra
tpnp
0
trr3
tra3
tpnp3
tne3
trr4
tra4
tpnp4
tne4
trr2
tra2
tpnp2
tne2
trr1
tra1
tpnp1
tne1
Pop1
Pop2
Pop3
Pop4
Pop5
Pop6
Pygmy
Non-
Pygmy
European
French
N1
N2
N3
N4
Na4
Na3
Na2
Na1
Nnp
Nnp
Nfooa
tooa = 2,000 g
Nooa
DBooa
0
trr3
tra3
tpnp3
tne3
trr4
tra4
tpnp4
tne4
trr2
tra2
tpnp2
tne2
trr1
tra1
tpnp1
tne1
1-ra
1-rr1
1-rr2
ra
ra1
rr1
1-rr3
rr2
1-rr4
rr3
rr4
1-rr4 rr4
1-rr3 rr3
1-rr2
rr2
1-rr1 rr1
ra4
ra3
ra2
FIGURE 18.1 (Continued)
in which these lineages split is not pre-deﬁned. See main text for details
regarding prior distributions of parameters.
bounded between 1 and 5,000 generations. For the class 1 scenarios, we set the
conditions trr<tp < tra<tpnp. For the class 2 scenarios, we set the conditions
trri<tnei<trai<tpnpi with i between 1 and 4.
For the parameterisation of microsatellite mutation rates, each locus was
assumed to follow a generalised stepwise mutation model with a possible range
of 40 contiguous allelic states (Estoup et al., 2002). The mean mutation rate
(¯μ) was drawn from a uniform distribution bounded between 10−4 and 10−3
(Dib et al., 1996; Estoup et al., 2002), and mutation rates for each locus were
drawn independently from a gamma distribution (mean = ¯μ and shape = 2).
The mean parameter of the geometric distribution (¯p) of the length in num-
ber of repeats of mutation events was drawn from a uniform distribution
bounded between 0.1 and 0.3 (Dib et al., 1996; Excoﬃer et al., 2005), and
the parameters for individual loci were drawn from a gamma distribution
(mean = ¯p and shape = 2). Some allele lengths, measured in base pairs, were
odd and some were even, a pattern implying that there has been an indel muta-
tion, giving a length that is not a multiple of the motif length. In order to sim-
ulate uneven insertion/deletion events that could be suspected for several of
our microsatellite loci based on observed allele sizes, we draw the mutation pa-
rameter μSNI (for single nucleotide instability) from a loguniform distribution

548
Handbook of Approximate Bayesian Computation
with bounds 10−9 and 10−4 and a gamma distribution (mean = μSNI and
shape = 2) for drawing rates of single nucleotide insertion-deletion events at
individual loci.
As for any Bayesian inference, the shape of the priors used for dataset
simulations may aﬀect both the posterior probabilities of scenarios and the
posterior parameter estimation under ABC inference (Sunnaker et al., 2013).
Therefore, in the original Verdu et al. (2009) study, we conducted all ABC
procedures assuming a set of alternative non-ﬂat priors for the simulations (cf.
prior set 2 in Verdu et al., 2009). We found that the posterior probabilities and
distributions were moderately aﬀected by the shape of the prior distribution in
our speciﬁc case (see Verdu et al., 2009 Supplementary Material). For sake of
concision, we did not repeat here this time-consuming, but otherwise necessary
procedure which aims at empirically evaluating the inﬂuence of prior shape
on posterior inferences for each ABC case-study (Bertorelle et al., 2010).
A major interest of ABC methods is their potential to treat complex
and, hence, relatively realistic models. This is why we straightly formalised
and analysed a set of complex evolutionary models (Figure 18.1). However,
the verbally stated main evolutionary question (i.e. independent versus non-
independent histories of the four Pygmy groups) can be drawn, at least
roughly, from a comparison of a lower number of less parameterised (though
less realistic) historical and demographic models than those described earlier
and in Figure 18.1. To illustrate the impact of assuming substantially sim-
pliﬁed models, we considered and analysed a set of two simpliﬁed versions of
our complex scenarios 1a and 2a, in which we removed all introgression events
and assumed that all Pygmy and non-Pygmy populations had the same eﬀec-
tive population size (drawn into a uniform distribution bounded between 100
and 30,000 diploid individuals). Prior distributions for divergence times and
mutational parameters remained the same as for previous complex scenarios.
In the following, we will refer to this pair of simpliﬁed scenarios as ‘the simple
scenario 1’ and ‘the simple scenario 2’ throughout.
18.2.3
Computer programs
For both the simulation of data following the aforementioned model-
prior design and all post-process statistical treatments (with the excep-
tion of the ABC random forest treatments applied for model choice;
Pudlo et al., 2016), we used the package Do It Yourself Approximate
Bayesian Computation (DIYABC) v2.1.0 (Cornuet et al., 2014), freely
available with a detailed user-manual and example projects for academic
and teaching purposes at http://www1.montpellier.inra.fr/CBGP/diyabc.
Brieﬂy, Cornuet et al. (2008, 2010, 2014) developed DIYABC to provide
a user-friendly interface, which allows biologists with little background in
programming to perform inferences via ABC. DIYABC is a coalescent-based
program (Nordborg, 2001), which can consider complex population histo-
ries, including any number of divergence (without migration), admixture, and

Application of ABC to Infer the Genetic History of Pygmy
549
population size variation events, for population samples that may have been
collected at diﬀerent times. The package accepts various types of molecular
data (microsatellites, DNA sequences, and SNP), evolving under various mu-
tation models, and located on various chromosome types (autosomal, X or Y
chromosomes, and mitochondrial DNA). A text ﬁle including the instructions
based on the simple DIYABC coding language (cf. DIYABC user) to make
simulations for the eight complex scenarios of Figure 18.1 (and the simple
scenarios 1 and 2) is available upon request from AE.
Regarding ABC random forest treatments, computations were per-
formed with the random forest statistical framework implemented in the
randomForest package of R (Liaw and Wiener, 2002), with all methodologies
detailed in Pudlo et al. (2016) implemented in the R package abcrf available
on the CRAN. We are currently implementing the ABC-random forest (RF)
algorithms of Pudlo et al. (2016) in the next version of the software DIYABC
to provide a user-friendly interface to implement this promising statistical
method.
18.3
Results and Discussions
As a pre-amble, it is worth stressing that we willingly biased our method-
ological choices towards ABC methods already implemented in the package
DIYABC and the recently developed ABC random forest methodologies. This
bias is explained by the fact that most of the authors of this chapter are di-
rectly involved into the development of such methods and computer program
and are therefore optimally positioned to use, explain, and critically discuss
them. Nevertheless, a number of similar and alternative ABC methods and
computer programs have been developed by other groups and could certainly
have been successfully applied to the presently studied dataset. Useful ref-
erences to alternative ABC methods and programs can be found in recent
reviews on ABC, such as those by Beaumont (2010) and Sunnaker et al. (2013).
For instance, the computer packages ABCtoolbox (Wegmann et al., 2010) and
abc (Csill´ery et al., 2012) provide useful operational and alternative ABC al-
gorithms (e.g. Markov chain Monte Carlo without likelihood, a particle-based
sampler and ABC-generalized linear model (GLM) for ABCtoolbox, neural
network regression-based methods for abc) for making ABC inferences about
complex evolutionary scenarios using various types of molecular data.
18.3.1
Model choice: ABC random forest
Choosing among a ﬁnite set of models (scenarios) is a crucial inferential is-
sue, as it allows the identiﬁcation of major historical and evolutionary fea-
tures formalised into the set of compared scenarios. In the eight complex
scenarios we studied, such features include: whether there is an independent

550
Handbook of Approximate Bayesian Computation
or non-independent origin of Pygmy groups; the possibility of introgression
events between Pygmy and non-Pygmy populations; and the possibility of a
change in size of the non-Pygmy population. Both theoretical arguments and
simulation experiments indicate that model posterior probabilities are poorly
evaluated by ABC, even though the numerical approximations of such proba-
bilities can preserve the proper ordering of the compared models (Robert et al.,
2011; Pudlo et al., 2016). Pudlo et al. (2016) have recently proposed a novel
approach based on a machine learning tool named ‘random forests’ (Breiman,
2001) to conduct selection among the highly complex models covered by ABC
algorithms. In their approach named ‘ABC-RF’, Pudlo et al. (2016) proposed
both to step away from selecting the most probable model from estimated pos-
terior probabilities and to reconsider the very problem of constructing eﬃcient
summary statistics. First, given an arbitrary pool of available statistics, they
completely bypass selecting among these. This new perspective directly pro-
ceeds from machine learning methodology (Breiman, 2001). Second, because
posterior probabilities are poorly evaluated by ABC, ABC-RF postpones the
approximation of model posterior probabilities to a second stage. ABC-RF
analyses, hence, include two successive steps. As a ﬁrst step, ABC-RF predicts
the model that best ﬁts the observed dataset by constructing a (machine learn-
ing) classiﬁer from simulations from the prior predictive distribution, known
as the reference table in ABC (i.e. records of a given number of datasets simu-
lated from the priors under diﬀerent models and summarised with an extensive
pool of statistics). As a second step, Pudlo et al. (2016) demonstrated that
a reliable estimation of posterior probability of the previous selected model
can be obtained through a secondary random forest that regresses the model
selection error in the ﬁrst step over the available summary statistics.
As compared to past ABC implementations for model choice, ABC-RF
oﬀers improvements at least at four levels: (1) on all experiments we studied
(including those detailed in Pudlo et al., 2016), it signiﬁcantly reduces the clas-
siﬁcation error as measured by the probability to choose a wrong model when
drawing model index and parameter values into priors (a quantity, hereafter,
named the prior error rate); (2) it is robust to the number and choice of sum-
mary statistics, as RF can handle many superﬂuous and/or strongly correlated
statistics with no impact on the performance of the method; (3) the comput-
ing eﬀort is considerably reduced, as RF requires a much smaller reference
table compared with alternative methods (i.e. a few thousands of simulated
datasets versus hundred thousand to millions of simulations per compared
model); and (4) it provides a reliable estimate of posterior probability of the
selected model (i.e. the model that best ﬁts the observed dataset).
We ﬁrst used ABC-RF to discriminate among the eight complex scenarios
presented in Figure 18.1 and then computed the posterior probability of the
best supported model. Following Pudlo et al. (2016), ABC-RF analyses were
processed on 80,000 simulated datasets (10,000 per scenario), drawing param-
eter values into the prior distributions detailed in the previous Section 18.2.2.
Since the summary statistics proposed by DIYABC (Cornuet et al., 2014)

Application of ABC to Infer the Genetic History of Pygmy
551
describe genetic variation per population (e.g. number of alleles), per pair
(e.g. genetic distance), or per triplet (e.g. admixture rate) of populations,
averaged over the 26 loci (see the DIYABC 2.1.0 user-manual page 16 for
details about such statistics), we have included 204 of those statistics plus
the seven linear discriminant analysis axes as additional summary statistics
in our ABC-RF treatments. For sake of comparison, we also processed stan-
dard ABC treatments (using a logistic regression approach modiﬁed following
Estoup et al., 2012) for model choice on the present dataset using a sub-
stantially larger number of simulated datasets (i.e. 8 × 106). It should be
noted that the standard ABC treatments for model choice processed in Verdu
et al. (2009) relied on a subset of 48 summary statistics describing genetic
variation within and between populations which were selected based on the
expertise of the authors in population genetics, as well as on a large number
of simulated datasets (i.e. 4 × 106).
The projection of the reference table on the ﬁrst four linear discriminant
analysis axes provides a ﬁrst visual indication about our capacity to discrimi-
nate among the eight compared scenarios (Figure 18.2). Simulations under the
diﬀerent scenarios moderately overlapped, suggesting a rather good power to
discriminate scenarios. In agreement with this, we obtained a probability to
choose a wrong model when drawing model index and parameter values into
priors (i.e. a prior error rate) equal to 0.211. As a ﬁrst inferential clue, one
can note that the location of the observed dataset (indicated by a star sym-
bol in Figure 18.2) suggests, albeit without formal quantiﬁcation, a marked
association with the scenario 1a and, to a lesser extent, with the scenario 2a.
Figure 18.3 shows that RFs are able to automatically determine the (most)
relevant statistics for model comparison. Interestingly, many of them were
not selected by the experts in Verdu et al. (2009), especially some crude es-
timates of admixture rates based on population triplets (i.e. maximum likeli-
hood coeﬃcient of admixture (AML) statistics; Choisy et al., 2004). A possible
explanation is that experts in population genetics are biased towards choos-
ing summary statistics that are informative for parameter estimation under
a given model. However, according to our own experience on this issue, the
most informative statistics for model choice might not be the same as those
that are informative for parameter estimates (see also Robert et al., 2011).
Hence, the set of best statistics found with ABC-RF should not be considered
as an optimal set for further parameter estimates under a given model with
standard ABC techniques (see Section 18.3.2).
The outcome of the ﬁrst step of the ABC-RF statistical treatment applied
to a given target dataset is a classiﬁcation vote for each model which repre-
sents the number of times a model is selected in a forest of n trees. The model
with the highest classiﬁcation vote corresponds to the model best suited to the
target dataset among the set of compared models. Note that there are obvi-
ously a number of other possible models that might ﬁt the data just as well, if
not better than the ‘best’ model found among the present ﬁnite set of models.
In our case study, the classiﬁcation vote estimated for the observed human

552
Handbook of Approximate Bayesian Computation
−4
−2
0
LD2
LD3
2
4
−6
6
−4
−2
0
2
4
6
LD1
LD3
−4
−2
0
2
4
−6
6
−2
0
2
4
−4
6
LD1
LD2
−4
−2
0
2
4
−6
6
−4
−2
0
2
4
−6
6
LD1
LD4
−4
−2
0
2
4
−6
6
−5
0
−10
5
FIGURE 18.2
Projection on the ﬁrst four linear discriminant analysis axes of the microsatel-
lite population datasets simulated under the eight complex scenarios we
compared. Colours correspond to the indices of the scenarios presented in
Figure 18.1. Scenario 1a: chocolate, 1b: red, 1c: blue, 1d: black, 2a: pink, 2b:
green, 2c: orange, and 2d: gold. The location of the additional (observed)
dataset is indicated by a large black star. (Figure in color available by request
from AE).
microsatellite dataset was by far the highest for the scenario 1a (i.e. 430 of the
n = 500 RF-trees selected scenario 1a; see Pudlo et al., 2016 and Breiman, 2001
for a justiﬁcation of considering a forest of n = 500 trees). The evolutionary
scenario selected by our RF method fully agrees with the earlier conclusion
of Verdu et al. (2009), based on approximations of posterior probabilities
with local logistic regression using a substantially higher number of simulated
datasets and a diﬀerent set of summary statistics. As a reminder, scenario
1a corresponds to a common origin of all Western Central African Pygmy

Application of ABC to Infer the Genetic History of Pygmy
553
0
V2P_4&5
V2P_1&5
MGW_5
VAR_5
V2P_5&6
FST_2&5
AML_2_4&5
AML_4_1&5
AML_1_3&5
AML_1_4&5
AML_2_3&5
AML_2_1&5
FST_3&5
AML_3_1&5
AML_3_2&5
AML_4_3&5
AML_1_2&5
AML_4_2&5
AML_5_2&6
AML_5_3&6
AML_3_4&5
FST_4&5
FST_1&5
AML_5_4&6
LD5
AML_5_1&6
LD4
LD3
LD2
LD1
500
1,000
1,500
2,000
MeanDecreaseGini
2,500
3,000
3,500
FIGURE 18.3
Contributions of the 30 most informative statistics to the random forests.
The contribution of a statistic is evaluated with the mean decrease in node
impurity (MeanDecreaseGini) in the trees of the random forest. LDx = linear
discriminant axe x. The meaning of the acronyms of other statistics can be
found in the DIYABC 2.1.0 user-manual.
groups considered, with the ancestral Pygmy populations having diverged
from the non-Pygmy lineage in a more remote past. Furthermore, scenario
1a encompasses both recent and ancient asymmetrical introgression events
from the non-Pygmy gene pool into each Pygmy population considered and a
change of population size in the non-Pygmy lineage.
There is no direct connection between the frequencies of the model alloca-
tions of the data among the tree classiﬁers (i.e. the classiﬁcation vote) and the
posterior probabilities of the competing models (see Figure S2 in Pudlo et al.,
2016). We therefore carried out the second RF analytical step correspond-
ing to the algorithm 3 in Pudlo et al. (2016) to obtain a reliable estimation
of posterior probability of scenario 1a equal to 0.898. This high posterior
probability value provides a strong conﬁdence in selecting the scenario 1A
as the model best suited to the target dataset among the set of eight com-
plex compared models. For comparison, more standard ABC treatments for
model choice (using the 1% closest simulated datasets from a total of 8 × 106
datasets; Estoup et al., 2012) gave a higher, and probably somewhat overop-
timistic, posterior probability of scenario 1a equal to 0.948 (a value close to
that obtained in Verdu et al., 2009, i.e. prob. = 0.960). The latter statistical
treatment required a ca. 100 times longer computational duration than when
using the ABC-RF approach.
Table 18.1 shows that increasing the number of simulated datasets in
the reference table decreases the mean and standard deviation values of the
ABC-RF estimates of both the prior error rate and the posterior probability
of the best supported model. The gain of increasing the number of recorded

554
Handbook of Approximate Bayesian Computation
TABLE 18.1
Estimation Using ABC-RF of Prior Error Rate and Posterior Probability of the Best Supported Model for Diﬀerent Sizes
of the Reference Table and Replicate Analyses
Reference Table Sizea
10,000
40,000
80,000
80,000c
100,000
Replicate Analysis
PER
PPbmb
PER
PPbmb
PER
PPbmb
PER
PPbmb
PER
PPbmb
# 1
0.238
0.812
0.215
0.841
0.212
0.904
0.211
0.814
0.209
0.882
# 2
0.238
0.859
0.218
0.874
0.210
0.920
0.214
0.875
0.209
0.903
# 3
0.231
0.817
0.218
0.866
0.211
0.911
0.212
0.908
0.208
0.908
# 4
0.235
0.882
0.216
0.847
0.210
0.870
0.212
0.854
0.209
0.929
# 5
0.236
0.816
0.219
0.912
0.212
0.911
0.214
0.844
0.208
0.925
# 6
0.233
0.826
0.218
0.924
0.212
0.900
0.212
0.879
0.209
0.895
# 7
0.230
0.940
0.218
0.877
0.211
0.875
0.209
0.870
0.209
0.873
# 8
0.233
0.831
0.217
0.892
0.211
0.878
0.210
0.885
0.209
0.884
# 9
0.235
0.843
0.220
0.844
0.211
0.891
0.213
0.900
0.209
0.908
# 10
0.233
0.934
0.217
0.924
0.209
0.923
0.211
0.921
0.209
0.907
Mean
0.234
0.856
0.218
0.880
0.211
0.898
0.212
0.875
0.209
0.901
SD
0.004
0.048
0.002
0.032
0.001
0.019
0.002
0.032
0.001
0.018
Notes: We here considered the complex modelling set up including eight evolutionary scenarios (Figure 18.1).
Abbreviations: Prior error rate (PER) and posterior probability of the best supported model (PPbm).
a Reference table size in number of records (i.e. datasets compiled under the form of the scenario identity and corre-
sponding summary statistics) simulated from DIYABC.
b The same scenario (i.e. scenario 1a) was the best supported for all reference table sizes and for all
replicate analyses.
Replicate analyses have been processed on the same reference table except for those detailed in the column 80,000.
c Which were processed on diﬀerent reference tables, each one including 80,000 records. Mean and standard deviation
values are in bold characters. Min and max values are in italic characters.

Application of ABC to Infer the Genetic History of Pygmy
555
simulated datasets to build the trees of the random forest is substantial
between 10,000 and 40,000 records and then becomes limited for higher num-
bers of records, especially between 80,000 and 100,000 records. Although not
sizeable, a non-negligible surplus of estimation variance is observed when repli-
cate analyses are processed on diﬀerent reference tables (see the two columns
labelled 80,000 in Table 18.1). This is expected due to the substantial stochas-
tic variation present among reference tables of relatively small size. A practi-
cal lesson of the results in Table 18.1 is that processing an ABC-RF analysis
using 10,000 records per scenario (here 80,000 records) is a sensible choice,
at least in the present case study. Pudlo et al. (2016) reached similar conclu-
sions from a set of other real and controlled datasets analysed using the same
ABC-RF methodology (see the section ‘Practical recommendations regarding
the implementation of the algorithms’ in Pudlo et al., 2016).
The verbally stated main evolutionary question (i.e. independent vs. non-
independent histories of the four Pygmy groups) can be drawn, at least
roughly, from a comparison of only two simpliﬁed (and, hence, less realistic)
models, named scenario 1 and 2 (see Section 18.2.2). The ABC-RF approach
applied on this pair of simpliﬁed scenarios provides the highest classiﬁcation
vote for the scenario 1 (i.e. 328 of the n = 500 RF-trees selected scenario 1).
The posterior probability of this best supported scenario was lower than that
obtained when analysing the set of eight complex scenarios: it was equal to
0.733 and 0.761 for reference tables including 20,000 and 50,000 simulated
datasets, respectively. Such lower posterior probabilities may reﬂect, at least
partly, some noticeable diﬃculties of any of the two simpliﬁed models to ﬁt
with the real history and observed dataset. Nevertheless, in agreement with
previous results, the scenario 1 corresponds to a non-independent history of
the four Pygmy groups.
18.3.2
Parameter estimation
As it is in the case of model selection, the choice of summary statistics is
crucial in parameter estimation by ABC. Standard ABC algorithms might
indeed suﬀer from the curse of dimensionality and correlation among explana-
tory variables (i.e. multi-co-linearity) during the regression step, and, hence,
yield poor results when the number of statistics is large. At least theoretically,
the dimensionality issue might be oﬀset by increasing the number of simula-
tions, but the amount of time needed to do so might be unreasonable for most
concrete applications. Note that it remains highly challenging to assess in a
generic manner to which extent such dimensionality issues may be critical, as
it depends on the analysed observed dataset, the summary statistics chosen,
and/or the scenario settings. The statistical techniques recently developed to
select summary statistics provide noticeable improvements, at least in some
cases (reviewed in Blum et al., 2013). We are currently developing a method
similar in essence to the ABC random forest algorithms developed for model
choice, which would be applicable to the estimation of demographic, historical,

556
Handbook of Approximate Bayesian Computation
and mutation parameters under a given model. We hope that such a method
will allow (more) accurate estimation of parameters with a lower computing
eﬀort (i.e. using a much smaller reference table than for standard ABC infer-
ences), without the need to choose a more or less arbitrary subset of summary
statistics within a large pool of possible ones.
For the sake of simplicity and computation eﬃciency (i.e. statistical
techniques for choosing summary statistics have not been implemented in
DIYABC), we used a standard ABC methodological framework (Beaumont
et al., 2002; Cornuet et al., 2008) applied to the same set of ‘expert-chosen’
statistics as in Verdu et al. (2009) to estimate posterior parameter distribu-
tions under the most likely complex scenario (i.e. scenario 1a). We considered
48 summary statistics in total: the mean number of alleles per locus and
population sample, the mean genetic diversity, the mean allele size variance
expressed in base pairs, and all pairwise F st’s, and genetic distances (δμ)2
between population samples (see the DIYABC 2.1.0 user-manual page 16 for
details about such statistics). Using parameter values drawn from the prior
distributions detailed in Section 18.2.2, we produced a reference table contain-
ing one million simulated datasets. Following Beaumont et al. (2002), we then
used a local linear regression to estimate the parameter posterior distributions.
We took the 10,000 (1%) simulated datasets closest to our observed dataset
for the regression, after applying a logit transformation to parameter values.
Considering instead the 1‰ closest simulated datasets only slightly changed
posterior distribution estimates (results not shown).
We were particularly interested in evaluating the usefulness of adding a
scaling population (here, the French population) to obtain more precise infer-
ences speciﬁcally regarding original divergence time parameters in scenario 1a:
tp (divergence time among Pygmy populations), and tpnp (among the ancestral
Pygmy population and non-Pygmy population). To tackle this question, we
produced a second reference table for the scenario 1a containing one million
simulated datasets, where the Out of Africa divergence time of the French
population was drawn from a uniform distribution bounded between 1 and
5,000 generations instead of being ﬁxed at 2,000 generations as previously
(i.e. 50,000 years). Parameter estimation was carried out in the same way as
earlier. Accuracies in parameter estimates were further compared for the cali-
brated and non-calibrated settings by computing the relative median absolute
deviation (RMedAD) from a set of 10,000 test datasets (i.e. pseudo-observed
datasets for which the true parameter values are known; hereafter, named
‘pods’), with parameters drawn from prior distributions. The RMedAD mea-
sure corresponds to the 50% quantile (over the 10,000 pods) of the median
(over each pod) of the absolute diﬀerence between each value of the pod pos-
terior distribution sample (estimated as earlier) and the true value divided by
the true value. Lower RMedAD values correspond to more precise estimates.
For most historical and demographic parameters of the complex sce-
nario 1a, the posterior distributions do not diﬀer strongly from the priors, ex-
cept for the common separation time of the diﬀerent Pygmy populations (tp),

Application of ABC to Infer the Genetic History of Pygmy
557
0
(a)
(b)
(c)
(d)
1,000
3,000
5,000
0.0000
0.0010
tp
Density
Mode = 195 vs 213
Median = 389 vs 427
90%CI = [76 − 1,485]
vs [84 − 1,570]
0
1,000
3,000
5,000
0.0000
0.0010
tpnp
Density
Mode = 4,230 vs 4,250
Median = 3,190 vs 3,400
90%CI = [1,292 − 4,800]
vs [1,340 − 4,840]
0
1,000
3,000
5,000
0.0000
0.0010
tp
Density
Mode = 620 vs 330
Median = 589 vs 425
90%CI = [224 − 991]
vs [118 − 849]
0
1,000
3,000
5,000
0.0000
0.0010
tpnp
Density
Mode = 840 vs 500
Median = 917 vs 689
90%CI = [461 − 1915]
vs [201 − 2,050]
FIGURE 18.4
Posterior distributions of two historical parameters of interest for both a
scaled and a non-scaled setting of the complex scenario 1a (panels a and b)
and the simple scenario 1 (panels c and d). Plain dark grey curves = posterior
distributions for the scaled settings; plain light grey curves = posterior
distributions for the non-scaled settings; and dotted black curves = prior
distributions. Point estimates and 90% credibility intervals (CI) are indicated
for each parameter (in dark grey and light grey for the scaled and non-scaled
settings, respectively). tp = separation time of the diﬀerent Pygmy popu-
lations from a single ancestral Pygmy population. tpnp = separation time
of the ancestral Pygmy population from the non-Pygmy population. Prior
distributions of tp and tpnp are not ﬂat due to conditions on time events (see
Section 2.2 of the main text).
which shows a clear peak corresponding to a mode at 195 generations (i.e.
ca. 4,900 years assuming a generation time of 25 years; see Figure 18.4).
Moreover, the credibility intervals are large for all parameters. Overall, these
results indicate that the genetic data contain relatively little information con-
cerning most parameters in the model, with the notable exception of the diver-
gence time among Pygmy populations, one of the key parameters of interest
to anthropologists. Interestingly, we found that the posterior distributions
of parameters are similar whether or not we resort to the European scaling
population in the inferential process (see Figure 18.4 for an illustration on

558
Handbook of Approximate Bayesian Computation
divergence times of interest). This suggests that using a scaling population
does not improve parameter estimation under the complex scenario 4a. In
agreement with this, RMedAD values computed from either a scaled or a
non-scaled setting of scenario 1a indicate that the original Pygmy population
parameters are not or only slightly more accurately estimated when using
a scaling population. For all parameters, RMedAD values are only slightly
smaller for the scaling setting (i.e. 0.38%–4.26% smaller). Note that we reached
similar conclusions when computing RMedAD values drawing the pod param-
eter values from the posterior distributions estimated for the observed dataset
rather than from prior distributions (results not shown).
Unlike the scenario 1a, the posterior distributions of historical and demo-
graphic parameters strongly diﬀer from the priors showing nicely shaped peaks
in the simpliﬁed scenario 1 (Figure 18.4). Although credibility intervals largely
overlap, the distribution of the common separation time of the diﬀerent Pygmy
populations (tp) has a higher mode in the simple scenario 1 (i.e. 620 genera-
tions corresponding to ca. 15,500 years) and that of the separation time of the
ancestral Pygmy population from the non-Pygmy population (tpnp) shows a
clear peak around 840 generations (i.e. ca. 21,000 years). Moreover, the pos-
terior distributions of parameters in scenario 1 more clearly diﬀer whether
or not we resort to the European scaling population in the inferential pro-
cess, indicating a signiﬁcant eﬀect of considering a scaling population in this
case (Figure 18.4). In agreement with this, RMedAD values measured from
pods indicate a signiﬁcant gain in precision overall when considering the sim-
pliﬁed scenario 1 (i.e. 11.5%–16.5% smaller RMedAD values for the scaling
setting). This suggests that the high level of complexity of scenario 1a is an
important factor explaining the poor improvement of parameter estimation
observed when using a scaling population. We have further conﬁrmed this
result by additional RMedAD analyses processed on diﬀerent versions of the
complex scenario 1a (results not shown).
It is worth stressing that the historical and demographic simpliﬁcations
assumed in scenario 1 (i.e. absence of introgression events and same eﬀective
population size in all Pygmy and non-Pygmy populations) are to a large ex-
tent incompatible with previous knowledge regarding Pygmy and non-Pygmy
populations and with some of the initial anthropological questioning that mo-
tivated our study. For instance, the assumption that all populations, Pygmy
and non-Pygmy, had the same stable eﬀective population size prevents us
from evaluating possible (and actually likely) diﬀerences in the demographic
histories experienced separately by each population. This is unfortunate, as it
is of major interest to evolutionary biologists to understand whether past de-
mographic changes, such as bottlenecks or expansions, may have signiﬁcantly
shaped the diﬀerent genetic diversity patterns observed today across popu-
lations. Moreover, previous anthropologic, ethnographic, and genetic studies
documented the occurrence of genetic introgression among Central African
populations (Cavalli-Sforza, 1986; Destro-Bisol et al., 2004; Verdu et al., 2009,
2013; Hewlett et al., 2014), a feature consistent with the ﬁnding that the

Application of ABC to Infer the Genetic History of Pygmy
559
complex scenario 1a (which encompasses admixture events among popula-
tions) is much more likely than alternative complex scenarios without admix-
ture events. Therefore, substantial improvement in the accuracy of parameter
estimation through the using of a scaling population seems to be achievable,
in our case study, only at the cost of unrealistic simpliﬁcations of our evolu-
tionary models. Moreover, this casts serious doubts on the relevance in terms
of historical interpretation of the outwardly precise estimates of the histori-
cal parameter obtained with scenario 1 (see also the following Section 18.3.3:
Model-posterior checking).
18.3.3
Model-posterior checking
The ABC methods we considered so far allowed us to select the most likely
model (scenario) among a ﬁnite set of scenarios and to estimate posterior dis-
tributions of parameters under this scenario. However, they do not provide any
goodness-of-ﬁt type information. Bayesian model choice can indeed be under-
stood as a Bayesian testing procedure, but with parametric alternatives. Such
alternatives do not answer the question whether we missed some important
phenomenon in the set of eight complex (or two simple) scenarios we have con-
sidered in the present study. The Bayesian model choice procedure returns the
best model among the set of compared scenarios, but does not assure that the
observed data is typical of datasets produced by the corresponding stochastic
model. In other words, how well the inferred scenario-posterior combination
matches with the observed dataset remains to be evaluated. An established
approach to model criticism in the Bayesian setting involves comparing some
function of the observed data to a reference distribution, such as the posterior
predictive distribution, the latter corresponding to the distribution of future
observations conditional on the observed data (Rubin, 1984; Gelman et al.,
2003).
Here, we used the ABC model-posterior checking method implemented
in DIYABC (Cornuet et al., 2010; see also Csill´ery et al., 2010), which was
largely inspired by Gelman et al. (2003) and Cook et al. (2006). The prin-
ciple is as follows: if a scenario-posterior combination ﬁts the observed data
correctly, then data simulated under this scenario with parameters drawn
from associated posterior distributions should be close to the observed data.
The lack of ﬁt of the model to the data can be measured by determining
the frequency at which test quantities measured on the observed dataset
are extreme with respect to the distributions of the same test quantities
computed from the simulated datasets (i.e. the posterior predictive distri-
butions). In practice, the test quantities are chosen among the large set of
ABC summary statistics proposed in the program DIYABC. For each test
quantity (q corresponding to the chosen summary statistics), a lack of ﬁt
of the observed data with respect to the posterior predictive distribution
can be measured by the cumulative distribution function values of each test
quantity deﬁned as Prob(qsimulated < qobserved). Tail-area probability can be

560
Handbook of Approximate Bayesian Computation
easily computed for each test quantity as Prob(qsimulated < qobserved) and 1.0 –
Prob (qsimulated < qobserved) for Prob (qsimulated < qobserved) ≤0.5 and >0.5,
respectively. Such tail-area probabilities, also named posterior predictive
p-values (i.e. ppp-values), represent the probabilities that the replicated data
(simulated ABC summary statistics) could be more extreme than the ob-
served data (observed ABC summary statistics). Ppp-values should be taken
with caution (Meng, 1994): they aim at checking whether the model, with pos-
terior distribution adjusted on the data, can really ﬁt the data, and therefore
the data are used twice. In practice, ppp-values can be interpreted as a kind of
guideline for tracking model-posterior misﬁt: a few ppp-values around 0.05 are
not necessarily a big deal, whereas the presence of ppp-values around 0.001
is pretty suspect. Hence, too many observed summary statistics falling in the
tails of distributions, especially if some of those ppp-values are pretty low,
cast serious doubts on the adequacy of the model-posterior combination to
the observed dataset. Finally, because ppp-values are computed for a number
of (often non-independent) test statistics, a method such as that of Benjamini
and Hochberg (1995) can be used to control the false discovery rate (Cornuet
et al., 2010). Such multiple-test correction might not be optimal, however,
essentially because ppp-values are not calibrated due to the data being used
twice, even if one will preferentially avoid as test statistics those that have been
used to adjust the parameter posterior distributions of the selected scenario
(Cornuet et al., 2010, and see the following for an application).
We carried out the ABC model-posterior checking analysis on our observed
microsatellite dataset as follows. From the 106 datasets simulated under the
selected scenario (i.e. scenario 1a), we obtained a posterior sample of 104 values
from the posterior distributions of parameters through a rejection step based
on Euclidian distances and a linear regression post-treatment (Beaumont
et al., 2002). We simulated 104 datasets with parameter values drawn with
replacement from this posterior sample. There is a risk of over-estimating
the quality of the ﬁt by using the same statistics twice. This problem, which
clearly arises within an ABC framework, is actually a general issue in statis-
tical inference. As underlined in many text books in statistics (e.g. Gelman
et al., 2003), it is advised not to perform model checking using information
that has already been used for training (i.e. model ﬁtting; see also Cornuet
et al., 2010 for illustrations on simulated datasets). Optimally, model-posterior
checking should be based on test quantities that do not correspond to the
summary statistics which have been used for previous inferential steps. This
is naturally possible with DIYABC, as the package proposes a large choice of
summary statistics. In practice, one will avoid, as a priority, the statistics that
have been used to adjust the parameter posterior distributions of the selected
scenario (here, the 48 statistics of Verdu et al., 2009, described in the previous
section). Our set of test statistics therefore included the 96 remaining single
and pairwise summary statistics available in DIYABC that were not used for
previous ABC parameter estimation (see the DIYABC 2.1.0 user-manual page
16). Note that the ABC random forest method we applied for model choice

Application of ABC to Infer the Genetic History of Pygmy
561
used information from all statistics available in DIYABC, which might be a
problem if one also wants to exclude the statistics involved in this initial infer-
ential step too. However, additional treatments on a subset of test quantities
discarding the most informative statistics in the ABC random forest did not
change our model-posterior checking results (results not shown).
When applying an ABC model checking analysis on the complex
scenario 1a, we found that only two of the 96 test quantities had low ppp-
values (i.e. ppp = 0.028 and 0.034), the latter values being not signiﬁcant
when applying the Benjamini and Hochberg 1995s method as an attempt to
control the false discovery rate. This result supports that the inferred scenario-
posterior combination does not obviously misﬁt the observed dataset. In agree-
ment with this, the projections of the simulated datasets on the principal
component axes from the scenario-posterior combination were relatively well
grouped and centred on the target point corresponding to the observed dataset
(Figure 18.5). It is worth stressing that, due to the modest size of the dataset
(i.e. 26 microsatellite loci), only situations of major inadequacy of the model-
posterior combination to the observed dataset are likely to be identiﬁed. In
agreement with this, only three test quantities had low ppp-values (not sig-
niﬁcant after the Benjamini and Hochberg 1995s correction) when carrying
out the same model-posterior checking analysis on the scenario 2a ranked sec-
ond in model choice, although the latter was found to be far less likely than
scenario 1a. By contrast, some major lack of ﬁt was observed when consider-
ing the scenario 1, which corresponds to a simpliﬁed version of the complex
scenarios 1a. We found that in this case, 31 of the 96 test quantities had
40
30
20
10
0
−10
−10
−8
−6
−4
−2
0
P.C.2 (8.40%)
P.C.1 (68.20%)
2
4
6
8
−20
FIGURE 18.5
Principal component analysis of 96 test quantities when processing model
checking for the scenario 1a. Only the two ﬁrst axes are presented. Empty
small light grey circles = datasets simulated from priors (subset of 2,000 plots)
and plain large dark grey circles = datasets simulated from posteriors (subset
of 2,000 plots). Plain large white circle = observed dataset.

562
Handbook of Approximate Bayesian Computation
low ppp-values (six of them being very low, i.e. ppp < 0.001), with 28 of
them remaining signiﬁcant after applying the Benjamini and Hochberg 1995s
correction. Such a major lack of ﬁt raises serious doubts on the relevance in
terms of historical interpretation of the posterior distributions (albeit, the
latter showed nicely shaped peaks) obtained for several historical parame-
ters under the simple scenario 1 (Figure 18.4). It is worth noting that recent
genetic analyses of human populations relying on substantially larger datasets
often point favourably towards even more complex population models than the
set of eight complex models considered in the present study (e.g. models in-
cluding more reﬁned patterns of migration/introgression and population size
ﬂuctuations; e.g. Excoﬃer et al., 2013).
18.4
Conclusions and Perspectives
Our analysis of a modiﬁed version of the genetic dataset of Verdu et al. (2009)
conﬁrmed the initial historical interpretation of the authors, even though this
new dataset included smaller population sample sizes, a smaller number of
genetic markers, and the addition of a European scaling population sample.
We found a probable common origin of all Western Central African popula-
tions categorised as Pygmies by Western explorers, despite the vast cultural,
morphological, and genetic diversity observed today among these populations
(Hewlett, 2014). Moreover, we found a recent (about 4,900 years before present
(YPB)) common origin for the Western Central African Pygmy populations,
together with a more ancient (about 80,000 YBP) divergence between the an-
cestral Pygmy and non-Pygmy populations. This last result is consistent with
Verdu et al. (2009) results, as well as with two other following studies that
addressed similar questions using ABC approaches applied to autosomal and
mitochondrial sequence data (Patin et al., 2009; Batini et al., 2011). We also
conﬁrmed recent asymmetrical and heterogeneous genetic introgressions from
non-Pygmies into each Pygmy population. Altogether, these results are in
agreement with the ethno-historical scenario proposed by Verdu et al. (2009),
in which the relatively recent expansion of non-Pygmy agriculturalist popu-
lations in Western Central Africa which occurred 2,000–5,000 YBP may have
modiﬁed the pre-existing social relationships in the ancestral Pygmy popula-
tion, in turn resulting in its fragmentation into isolated groups. Since then,
enhanced genetic drift in isolated populations with small eﬀective sizes, and
diﬀerent levels of genetic introgression from non-Pygmies into each Pygmy
population, led to the rapid genetic diversiﬁcation of the various Western
Central African Pygmy populations observed today.
Regarding methodological aspects, our analyses illustrate how the ABC
random forest approach can be useful for picking through diﬀerent highly pa-
rameterised models, how ABC can be used to make inferences about parameter
values in particular models and how model-posterior checking approaches can

Application of ABC to Infer the Genetic History of Pygmy
563
be easily applied. Unfortunately, key divergence time parameters of Pygmy
populations, and, in particular, the original divergence time of ancestral
Pygmy and non-Pygmy populations, were not more precisely estimated than
in Verdu et al. (2009), despite the addition of a European sample used as scal-
ing population. We found that, at least in our case study, the limited beneﬁt
of using a scaling population was due, to some extent, to the low number of
genotyped markers and, to a larger extent, to the complexity of the historical
models considered. To our knowledge, this study is the ﬁrst one that quanti-
tatively evaluates the actual gain of using a scaling population for parameter
estimation.
Finally, we found that many historical and demographic parameters were
overall poorly estimated. This result illustrates the general inferential issue
that one may have, on the one hand, a good power to discriminate among
models and, on the other hand, a poor precision in the estimation of many
parameters under the selected model. This result also indicates that it is of
perennial importance to consider the anthropological interpretations of our re-
sults for what they are: working hypotheses that will imperatively need to be
further elucidated in future studies. Using a much larger number of molecular
markers may provide new clues to reconstruct the widely unknown peopling
history of Central Africa. For instance, Patin et al. (2014) investigated in deep
the timing of the admixture onset between Pygmies and non-Pygmies using
massive genome-wide datasets comprising more than a million markers geno-
typed for each individual. Based on such data, they inferred that complex
admixture processes which started a few thousand years ago left signiﬁcant
signatures in the genome-wide diversity patterns observed in Central African
populations today. This type of study highlights the major potential of increas-
ingly available genome-wide datasets for both model and non-model organisms
for future inference on complex population origins and demographic histories.
More generally, we believe that ABC methods, especially ABC-RF algorithms,
will be of considerable interest for the statistical processing of massive datasets
whose availability rapidly increases in various ﬁelds of research including, but
not limited to, population genetics.
Acknowledgements
We thank Mark Beaumont and one anonymous reviewer for providing helpful
and cogent comments on a previous version of the manuscript.
References
Batini, C., Lopes, J., Behar, D.M. et al. 2011. Insights into the demographic
history of African Pygmies from complete mitochondrial genomes. Mol Biol
Evol 28:1099–1110.

564
Handbook of Approximate Bayesian Computation
Beaumont, M.A. 2010. Approximate Bayesian computation in evolution and
ecology. Annu Rev Ecol Evol Syst 41:379–406.
Beaumont, M.A., Zhang, W.Y., and D.J. Balding. 2002. Approximate
Bayesian computation in population genetics. Genetics 162:2025–2035.
Benjamini, Y. and Y. Hochberg. 1995. Controlling the false discovery rate:
A practical and powerful approach to multiple testing. J Roy Stat Soc B
57:289–300.
Bertorelle, G., Benazzo, A., and S. Mona. 2010. ABC as a ﬂexible framework
to estimate demography over space and time: Some cons, many pros. Mol
Ecol 19:2609–2625.
Blum, M., Nunes, M., Prangle, D., and S. Sisson. 2013. A comparative review
of dimension reduction methods in Approximate Bayesian Computation.
Stat Sci 28:189–208.
Breiman, L. 2001. Random forests. Machine Learning 45:5–32.
Cann, H.M., de Toma, C., Cazes, L. et al. 2002. A human genome diversity
cell line panel. Science 296:261–262.
Cavalli-Sforza, L.L. 1986. African Pygmies: An Evaluation of the State of
Research. Orlando, FL: Academic Press.
Cavalli-Sforza, L.L. and M.W. Feldman. 2003. The application of molecular
genetic approaches to the study of human evolution. Nat Genet 33:266–275.
Cavalli-Sforza, L.L., Menozzi, P., and A. Piazza. 1994. The History and Ge-
ography of Human Genes. Princeton, NJ: Princeton University Press.
Chen, G.K., Marjoram, P., and J.D. Wall. 2009. Fast and ﬂexible simulation
of DNA sequence data. Genome Res 19:136–142.
Choisy, M., Franck, P., and J.-M. Cornuet. 2004. Estimating admixture pro-
portions with microsatellites: Comparison of methods based on simulated
data. Mol Ecol 13:955–968.
Cook, S., Gelman, A., and D.B. Rubin. 2006. Validation of software
for Bayesian models using posterior quantiles. J Comput Graph Stat
15:675–692.
Cornuet, J.-M., Pudlo, P., Veyssier, J. et al. 2014. DIYABC v2.0: A soft-
ware to make Approximate Bayesian Computation inferences about pop-
ulation history using single nucleotide polymorphism, DNA sequence and
microsatellite data. doi:10.1093/bioinformatics/btt1763.
Cornuet, J.-M., Ravigne, V., and A. Estoup. 2010. Inference on population
history and model checking using DNA sequence and microsatellite data
with the software DIYABC (v1.0). BMC Bioinformatics 11:401.

Application of ABC to Infer the Genetic History of Pygmy
565
Cornuet, J.-M., Santos, F., Beaumont, M.A. et al. 2008. Inferring population
history with DIY ABC: A user-friendly approach to Approximate Bayesian
Computation. Bioinformatics 24:2713–2719.
Csill´ery, K., Blum, M.G.B., Gaggiotti, O., and O. Fran¸cois. 2010. Approximate
Bayesian Computation (ABC) in practice. TREE 25:410–418.
Csill´ery, K., Fran¸cois, O., and M.G.B. Blum. 2012. ABC: An R pack-
age for Approximate Bayesian Computation (ABC). Methods Ecol Evol
3:475–479.
Destro-Bisol, G., Donati, F., Coia, V. et al. 2004. Variation of female and
male lineages in sub-Saharan populations: the importance of sociocultural
factors. Mol Biol Evol 21:1673–1682.
Dib, C., Faure, S., Fizames, C. et al. 1996. A comprehensive genetic map of
the human genome based on 5,264 microsatellites. Nature 380:152–154.
Estoup, A., Jarne, P., and J.-M. Cornuet. 2002. Homoplasy and mutation
model at microsatellite loci and their consequences for population genetics
analysis. Mol Ecol 11:1591–1604.
Estoup, A., Lombaert, E., Marin, J.-M. et al. 2012 Estimation of demo-genetic
model probabilities with Approximate Bayesian Computation using linear
discriminant analysis on summary statistics. Mol Ecol Res: 12:846–855.
Excoﬃer, L., Dupanloup, I., Huerta-Sanchez, E., Sousa, V., and M. Foll. 2013.
Robust demographic inference from genomic and SNP data. PLoS Genetics
9:e1003905.
Excoﬃer, L., Estoup, A., and J.-M. Cornuet. 2005. Bayesian analysis of an
admixture model with mutations and arbitrarily linked markers. Genetics
169:1727–1738.
Fagundes, N.J., Ray, N., Beaumont, M. et al. 2007. Statistical evalua-
tion of alternative models of human evolution. Proc Natl Acad Sci USA
104:17614–17619.
Gelman, A., Carlin, J.B., Stern, H.S., and D.B. Rubin. 2003. Bayesian Data
Analysis. London, UK: Chapman & Hall/CRC.
Gravel, S., Henn, B.M., Gutenkunst, R.N. et al. 2011. Demographic history
and rare allele sharing among human populations. Proc Natl Acad Sci USA
108:11983–11988.
Hewlett, B. 1996. Cultural diversity among African Pygmies. In Cultural
Diversity among Twentieth-Century Foragers: An African Perspective,
S. Kent (Ed.), pp. 215–244. Cambridge, UK: Cambridge University
Press.

566
Handbook of Approximate Bayesian Computation
Hewlett, B.S. 2014. Hunter-Gatherers of the Congo Basin: Cultures, Histo-
ries and Biology of African Pygmies. New Brunswick, NJ: Transactions
Publishers, 353 p.
Hudson, R.R. 2002. Generating samples under a Wright-Fisher neutral model.
Bioinformatics 18:337–338.
Laval, G., and L. Excoﬃer. 2004. SIMCOAL 2.0, a program to simulate ge-
nomic diversity over large recombining regions in a subdivided population
with a complex history. Bioinformatics 20:2485–2487.
Liaw, A., and M. Wiener. 2002. Classiﬁcation and regression by randomforest.
R News 2:18–22.
Lombaert, E., Guillemaud, T., Cornuet, J.-M., Malausa, T., Facon, B.,
and A. Estoup. 2010. Bridgehead eﬀect in the worldwide invasion of the
biocontrol harlequin ladybird. PLoS One 5:e9743.
Marin, J.M., Pudlo, P., Robert, C.P., and R.J. Ryder. 2012. Approximate
Bayesian Computational methods. Stat Comput 22:1167–1180.
Meng, X.L. 1994. Posterior predictive p-values. Annals Stat 22:1142–1160.
Nordborg, M. 2001. Coalescent theory. In: Handbook of Statistical Genetics,
D.J. Balding, M. Bishop, and C. Cannings (Eds.), pp. 179–212. Chichester,
UK: John Wiley & Sons.
Patin, E., Laval, G., Barreiro, L.B. et al. 2009. Inferring the demographic
history of African farmers and Pygmy hunter-gatherers using a multilocus
resequencing dataset. PLoS Genet 5:e1000448.
Patin, E., Siddle, K.J., Laval, G. et al. 2014. The impact of agricultural emer-
gence on the genetic history of African rainforest hunter-gatherers and agri-
culturalists. Nat Com 5:3163.
Pudlo, P., Marin, J.M., Estoup, A., Cornuet, J.M., Gautier, M., and C.P.
Robert. 2016. Reliable ABC model choice via random forests. Bioinfor-
matics 32:859–866.
Robert, C.P., Cornuet, J.-M., Marin, J.-M., and N.S. Pillai. 2011. Lack of
conﬁdence in Approximate Bayesian Computation model choice. Proc Natl
Acad Sci USA 108:15112–15117.
Rosenberg, N.A., Pritchard, J.K., Weber, J.L. et al. 2002. Genetic structure
of human populations. Science 298, 2381–2385.
Rubin, D.B. 1984. Bayesianly justifable and relevant frequency calculations
for the applied statistician. Ann Stat 12:1151–1172.

Application of ABC to Infer the Genetic History of Pygmy
567
Sunnaker, M., Busetto, A.G., Numminen, E., Corander, J., Foll, M., and
C. Dessimoz. 2013. Approximate Bayesian Computation. PLoS Comput
Biol 9:e1002803. doi:10.1371/journal.pcbi.1002803.
Tavar´e, S., Balding, D.J., Griﬃths, R.C., and P. Donnelly. 1997. Inferring
coalescence times from DNA sequence data. Genetics 145:505–518.
Verdu, P., Austerlitz, F., Estoup, A. et al. 2009. Origins and genetic diver-
sity of Pygmy hunter-gatherers from Western Central Africa. Curr Biol
19:312–318.
Verdu, P., Becker, N.S., Froment, A. et al. 2013. Sociocultural behavior, sex-
biased admixture, and eﬀective population sizes in Central African Pygmies
and non-Pygmies. Mol Biol Evol 30:918–937.
Wegmann, D., Leuenberger, C., Neuenschwander, S., and L. Excoﬃer. 2010.
ABCtoolbox: A versatile toolkit for approximate Bayesian computations.
BMC Bioinformatics 11:116.


19
ABC for Climate: Dealing with Expensive
Simulators
Philip B. Holden, Neil R. Edwards, James Hensman,
and Richard D. Wilkinson
CONTENTS
19.1
Introduction ......................................................
570
19.2
History Matching and ABC ......................................
573
19.3
Emulation ........................................................
576
19.3.1
Sequential history matching .............................
576
19.3.2
A simple climate example ...............................
579
19.4
Climate Model Case Study ......................................
581
19.4.1
The global carbon cycle .................................
581
19.4.2
Emulator-informed ABC design .........................
582
19.4.3
Applications .............................................
586
19.4.3.1
Probabilistic simulation outputs: The
uncertain response of the carbon cycle to
anthropogenic CO2 emissions ................
586
19.4.3.2
Calibrating model parameters: The strength
of the terrestrial carbon sink .................
587
19.4.3.3
Model understanding: What determines the
spatial distribution of dissolved carbon in the
ocean? .........................................
587
19.4.3.4
Coupling applications: Coupling climate
models and climate change impact models ...
588
19.5
Future Applications ..............................................
589
References
...............................................................
590
569

570
Handbook of Approximate Bayesian Computation
19.1
Introduction
One of the primary challenges faced when calibrating a simulator using
approximate Bayesian computation (ABC) is overcoming the computational
constraints posed by working with limited resource. The requirement to
repeatedly simulate from a model can make inference extremely computa-
tionally expensive. Consequently, much of the methodological development in
ABC has focused on improving computational eﬃciency, either through the
use of more eﬃcient Monte Carlo algorithms or through the use of statistical
methods to ameliorate the eﬀect of using a large tolerance.
The diﬃculty of dealing with limited computer power is felt more keenly
in climate science than in most other disciplines. A major focus of climate
research concerns the construction of ever more accurate and comprehensive
simulators of the climate system. Since the 1970s, global climate models have
evolved from representing only the large-scale circulation of the global atmo-
sphere (Holloway Jr and Manabe, 1971) to models that incorporate complex
dynamic representations of land surface, ocean, sea ice, atmospheric aerosols,
ocean biogeochemistry, vegetation, soils, and atmospheric chemistry (Flato
et al., 2013). Separate Earth system components are coupled through the ex-
change of ﬂuxes, which describe the ﬂow of some quantity between them (e.g.
energy, moisture, CO2) and bypassing any state variables that are needed to
deﬁne boundary conditions (e.g. land surface albedo, sea surface temperature).
‘Intermediate complexity’ models (which use simpliﬁed model components and
lower resolution in return for a more complete description of the Earth system
and higher computational eﬃciency) may also include dynamic representa-
tions of other important elements, such as ice sheets, permafrost, ocean sedi-
ments, and weathering (Flato et al., 2013), but these additional, long-timescale
components require orders of magnitude longer simulations to reach equilib-
rium. Modern climate models are generally, and more accurately, described as
‘Earth system models’ or ESMs.
This evolution in complexity has been accompanied by a 5-fold increase
in spatial resolution, allowing the resolution of important ﬁner scale pro-
cesses. This increased resolution (combined with shorter time-steps that are
required for numerical stability at higher spatial resolution) has alone led to
an O(1,000)-fold increase in computational demands since the 1970s. In gen-
eral, higher resolution allows more direct and more realistic representation of
smaller-scale processes, although this does not guarantee better projections, in
part because more complex models are more challenging to calibrate. A feature
of climate modelling is that multi-decadal climate projections must be used
before data are available to validate them, while past data give only approxi-
mate clues to the expected behaviour of model discrepancy because expected
changes greatly exceed the range of variability in the instrumental period.

ABC for Climate: Dealing with Expensive Simulators
571
It is perhaps inevitable, given the continual striving for more complex
models and the highest possible resolution, that state-of-the-art ESMs will
always be at the limits of what is practicable with available computing power.
The UK Met Oﬃce Hadley Centre’s computer comprises eight ‘supernodes’
of IBM Power775 supercomputer servers, which were installed in 2012 at a
cost of more than £11 million. The ESMs run at the Hadley Center and
at equivalent climate modelling institutions in other countries are extremely
computationally expensive, requiring months of such supercomputing to per-
form a single simulation of order 100 years. Even the intermediate complex-
ity model GENIE-1 (Holden et al., 2013b) used in our case study (Section
19.4) requires several days (on a single central processing unit (CPU) node)
to perform each O(10 kyear) ‘spin-up’ simulation to reach equilibrium, so
that simulation ensembles require implementation on multi-node computing
clusters. The simulated climates are large complex datasets which comprise
temporally resolved three-dimensional spatial arrays of up to ∼100 state vari-
ables. These outputs, in particular the outputs of carefully designed model
inter-comparison projects, are often analysed in great detail, in a comparable
way to how scientists in other ﬁelds analyse the outputs from empirical studies;
model projections are the best and only predictions we have of future climate.
An ESM conﬁguration is determined by the settings of many 100s of
model parameters. These include switches (which determine the precise nu-
merical schemes applied), physical constants that are approximately known,
but vary spatially in the real world (such as the reﬂectivity of ice), and pa-
rameterisations of ‘sub-gridscale’ processes such as cloud formations, which
have ‘tuned’ values that are known to result in reasonable model behaviour.
This complexity (many weakly constrained inputs, high dimensional outputs,
and expensive simulators) has meant that careful statistical calibration (ei-
ther with Bayesian or frequentist approaches) does not have a long history
in climate science. Often diﬀerent modules of an Earth system simulator are
separately ‘tuned’ before being bolted together. For example, the atmospheric
component can be tuned independently of the ocean component by prescribing
sea-surface temperatures with observational values. The components may all
be tuned independently before being coupled, with no guarantee that what was
a good tuning in an isolated module will work well in the coupled model. After
coupling, a small subset of model parameters are adjusted so that the cou-
pled model is consistent with large-scale observational constraints. It has been
shown, perhaps unsurprisingly, that such a tuning process does not produce
a unique solution, so that diﬀerent combinations of parameters can lead to
equally plausible model realisations (Mauritsen et al., 2012).
As statistical methodology develops, scientists are beginning to perform
more careful parameter estimation in their models. More rigorous parameter
estimation methods are often developed with (relatively fast) intermediate
complexity models, for example, Annan et al. (2005), thereby informing ap-
plication to higher-complexity models, for example, Marquis et al. (2014).

572
Handbook of Approximate Bayesian Computation
We can view climate simulators as black boxes which map from parameter
values θ ∈Θ, to climate states f(θ) = Csim. The aim of a Bayesian calibra-
tion, is to ﬁnd the posterior distribution:
π(θ|Cobs) ∝

π(Cobs|Csim)π(Csim|θ)dCsimπ(θ),
(19.1)
where Cobs is a set of observations of the climate system (Kennedy and
O’Hagan, 2001; Rougier, 2007). Here, π(θ) is the prior distribution for θ,
π(Csim|θ) is the simulator likelihood function (which is typically unknown),
and π(Cobs|Csim) is the statistical model relating the simulator to physical cli-
mate. This calculation, however, is typically far too ambitious to perform in
practice. Computational restrictions generally limit us to an ensemble of N
simulator runs {θ(i), C(i)
sim}N
i=1. Typically, N is small, ruling out most Monte
Carlo-based calibration approaches. We are left needing to estimate π(θ|Cobs)
as best we can, often by adding further approximation.
A further problem faced by climate scientists is that simulator discrepancy
(often called ‘model error’) can be considerable (Murphy et al., 2004). And
whilst the physical models of climate, π(Csim|θ), are well developed, statistical
models of the simulator discrepancy relating simulated to observed climate,
π(Cobs|Csim), have only begun to be developed relatively recently (Rougier and
Goldstein, 2014). The large simulator discrepancy makes most simulators in-
capable of reproducing all aspects of the climate record simultaneously and
can mean that the simulator parameters are no longer directly comparable to
their physical namesakes, making prior speciﬁcation challenging.
So what is possible? We know that ABC, given inﬁnite computational re-
sources and a perfect simulator, can in theory produce arbitrarily accurate
posteriors (i.e. the ABC posterior can be made arbitrarily close to the true
posterior). But for many problems, computational resources are often severely
constrained and simulator discrepancy can be signiﬁcant and largely unmod-
elled. Climate science is interesting for the statistician, as it presents extreme
cases of both these issues.
A key idea allowing calibration in many of these expensive simulators
is the idea of replacing the simulator with an emulator (or meta-model),
which is a cheap statistical surrogate used in place of the simulator (Sacks
et al., 1989; Santner et al., 2003; O’Hagan, 2006). Emulation techniques are
attracting considerable interest in the climate community. They are used,
for instance, to approximate probabilistic model outputs (Sans´o et al., 2008;
Rougier et al., 2009; Harris et al., 2013), for parameter estimation (Olson
et al., 2012; Sham Bhat et al., 2012), to facilitate model understanding (Lee
et al., 2012; Holden et al., 2015), and to provide numerically eﬃcient model
surrogates for coupling applications (Castruccio et al., 2014; Holden et al.,
2014; Oyebamiji et al., 2015). The application we will describe here is in the
ABC design of ‘plausible’ simulation ensembles (Holden et al., 2010; Edwards
et al., 2011), using emulation in order to overcome the prohibitive limitations
imposed by simulator cost.

ABC for Climate: Dealing with Expensive Simulators
573
19.2
History Matching and ABC
Climate science presents the double whammy of computationally expensive
simulators, and simulator discrepancy that is too large to ignore, but which is
not well understood or modelled. Both of these issues make a careful Bayesian
calibration (as described by Equation 19.1) diﬃcult. What can be achieved?
Our aim is to compare observations of Earth’s climate Cobs, with simulator
predictions Csim = f(θ), in order to learn about the parameter θ. ABC is an
approach for obtaining a probabilistic calibration and seeks to match simulator
output to observations, approximating the distribution:
πABC(θ|Cobs) ∝

I(ρ(Cobs, Csim) ≤ϵ)π(Csim|θ)dCsimπ(θ).
(19.2)
The acceptance kernel I(ρ(Csim, Cobs) ≤ϵ) implicitly implies a uniform dis-
tribution for the simulator discrepancy (Wilkinson, 2013), but this is usually
viewed as a pragmatic compromise, rather than a modelling decision.
An alternative to a probabilistic calibration is to do a history match
(Williamson et al., 2013), which has been used in studies involving complex
computer models, such as oil reservoir modelling (Craig et al., 1997), cos-
mology (Vernon et al., 2010), epidemiology (Andrianakis et al., 2015), and
climate science (Edwards et al., 2011). History matching, like calibration,
seeks to identify regions of the input space that give acceptable matches be-
tween simulator output, Csim, and observed data, Cobs. But instead of ﬁnd-
ing a probability distribution over Θ, we instead seek merely to rule out
implausible regions of input space, for example, those θ that the simula-
tor suggests could not have lead to Cobs, even after having accounted for
the simulator discrepancy. Often large parts of the input space give sim-
ulated climates that are very diﬀerent from the observed data, and which
can, hence, be ruled to be physically implausible and removed from further
consideration.
We deﬁne PC to be a set of plausible climate states that represent an
acceptable match between simulation and observation. We deﬁne Pθ to be the
subset of the parameter space that leads to plausible simulated climates, for
example:
Pθ = {θ ∈Θ : f(θ) ∈PC}.
Often, the vast majority of the input space gives rise to unacceptable matches
to the observed data (sometimes Pθ = ∅), and it is these regions that we are
trying to rule out as implausible. For example, for an ESM, we might deﬁne PC
to be any simulated climate that has global surface air temperature within 2◦C
of the observed value, the maximum value of Atlantic meridional overturning
circulation, a measure of the large-scale circulation of the ocean, within 5 Sv
(1 Sv = 106m3s−1) of observations, and the global mass of vegetation to be

574
Handbook of Approximate Bayesian Computation
within 200 giga-tonnes carbon of observations, though clearly the choice of
appropriate metrics and acceptance ranges is highly simulator-dependent. Pθ
is then the set of model parameters that would generate plausible climates for
the ESM in question.
Note the similarity to ABC here. If the prior distribution for θ is uniform
on Θ, for example, π(θ) ∝Iθ∈Θ, if f(θ) is deterministic (as is often, at least
approximately, the case in climate science), and if we use If(θ)∈PC as the ABC
acceptance kernel, then:
πABC(θ|C) ∝

1 if θ ∈Pθ
0 otherwise.
If we interpret a posterior probability of zero, as the statement that θ is im-
plausible, then history matching and ABC are thus the same. Note also the
direct relationship between the discrepancy considerations built into PC, and
the way ABC performs ‘Monte Carlo’ exact inference for the model that has
a discrepancy deﬁned by the acceptance kernel (Wilkinson, 2013).
History matching and ABC have in common that they do not use a detailed
model of the discrepancy, but instead characterise it using simple criteria.
A philosophical diﬀerence between the two approaches perhaps lies in the
degree of thought given to the plausible set PC. In history matching, the plausi-
bility criteria are often based on measurement error variances and the expected
magnitude of the simulator discrepancy (Vernon et al., 2010). Consequently,
Pθ consists of those parameter values θ that have not yet been ruled out as
implausible by our knowledge of the simulator and its discrepancy, and the
observed data and measurement error. The result is usually not interpreted
probabilistically, but only as values that we can not yet rule to be implausible
given our current state of knowledge. In contrast, in ABC, the choice of metric
ρ and tolerance ϵ are usually based pragmatically on the characteristics of the
algorithm, rather than on physical aspects of the underlying problem. Often,
ϵ is chosen to generate a speciﬁed number of acceptances. For example, if the
computational budget allows for 108 simulator runs, and we want 104 accepted
values in order to approximate the posterior, we set ϵ to the value that leads
to 0.01% of simulations being accepted (i.e. Biau et al., 2015, interpret ABC
as a nearest neighbour algorithm).
A further diﬀerence lies in the choice of information to include in PC (i.e.
what summary statistics to use). Climate simulators provide a large variety of
outputs, and some of these are better able to reproduce observed climate than
others. For example, temperatures are generally better reproduced than pre-
cipitation, consequently, it is more common to calibrate to the former than the
latter. In contrast, ABC has its roots in genetics, where perhaps the simulator
output is less varied and, consequently, more focus is given to the automatic
selection of summary statistics, often chosen on the basis of what is most
informative for θ (Blum et al., 2013). This approach is unlikely to be suit-
able in climate science. Some outputs for which the simulator discrepancy is

ABC for Climate: Dealing with Expensive Simulators
575
particularly large (precipitation say) may well be very ‘informative’ about θ if
we do not allow for discrepancy, but this would only misguide and may lead us
to incorrectly rule out large swathes of parameter space as implausible. Vari-
ables which are not well simulated are often included in ESMs, either because
they improve the overall simulation through the representation of important
feedbacks, or because they are considered important outputs in their own
right in spite of higher discrepancy associated with the outputs. Whether a
weak calibration constraint on these outputs is appropriate will depend on the
details of the discrepancy. Where a known missing process gives a signiﬁcant
contribution to regional error for instance, such as large precipitation errors
in monsoon regions as a result of unresolved topographic variation, using a
too precise calibration constraint (equivalently too small a model discrepancy)
would distort the rest of the solution.
A key question for any simulator is whether given a set of plausibility con-
ditions, the simulator is capable of producing any plausible simulated climates.
That is, is Pθ empty? If Pθ is empty, it is an indication that we understand
less than we thought about the simulator and system. Either there is an er-
ror in our implementation of the simulator, or we have under-estimated the
magnitude of the simulator discrepancy or measurement error. The fact that
the result of a history match can be to ﬁnd there are no plausible parameter
values should not be seen as a negative aspect of the approach, as it forces us
to confront the cold reality that something is missing from our understanding
of the system. In contrast, likelihood based techniques such as Markov chain
Monte Carlo (and pragmatic ABC applications, where ϵ is chosen to guaran-
tee a particular acceptance rate), result in a posterior distribution π(θ|Cobs)
regardless of how close the simulated climates are to real climate. It is thus
sensible when using these techniques to carefully check that the calibrated
simulator does indeed produce acceptable ﬁts. While it can often be useful to
ﬁnd the distribution π(θ|Cobs) (or an approximation to it) regardless of the
simulator quality, note that if discrepancy is ignored, π(θ|Csim) can often be
more constrained, or equivalently |Pθ| smaller, than is justiﬁed (Brynjarsd´ottir
and O’Hagan, 2014).
Note that even if a probabilistic calibration is required, a history match can
be performed ﬁrst in order to rule out regions of space which are clearly im-
plausible. This can dramatically reduce the area needed to be explored during
the more challenging probabilistic calibration. If using a stochastic simulator,
for which θ may never be completely ruled as implausible (as π(θ|Csim) > 0 for
all θ say), this can still be advantageous. We can rule out parameter regions
for which the likelihood is considerably smaller than at the maximum likeli-
hood estimator (MLE), with only a small increase in the approximation error
(Wilkinson, 2014), again making a subsequent probabilistic calibration easier.
Assuming that Pθ is not empty, the question then becomes, can we ﬁnd
elements of Pθ and, better still, can we characterise all of Pθ? The complexity
of climate science is such that even incomplete speciﬁcations of Pθ are useful,
as discussed in Section 19.4. This is because interest lies not in Pθ, but in

576
Handbook of Approximate Bayesian Computation
what it implies about future climate, for example, in the implied calibrated
distribution for other aspects of the climate system:
π(Cfuture|Cobs) =

π(Cfuture|θ)π(θ|Cobs)dθ,
and so even partial descriptions of Pθ are useful in constraining our beliefs
about future climate behaviour. Our aim is thus, given a limited computational
budget of N simulator evaluations, can we ﬁnd Pθ and the corresponding set
of plausible future climates? ABC applications usually use millions of simu-
lator evaluations. What can we do if instead we can only aﬀord 100 or 1,000
simulator evaluations? The answer is going to be even more approximate than
in ABC, and furthermore, we will necessarily have to make some modelling
assumptions if we wish to make progress. The key tool that has arisen for
doing this is the emulator, or meta-model.
19.3
Emulation
If the simulator, f(θ), is expensive to evaluate, we can instead try to ﬁnd
an approximation, ˜f(θ), called an emulator or meta-model, which provides
a good approximation to f(θ), but which is computationally cheap (Sacks
et al., 1989; O’Hagan, 2006). We can then either use ˜f to answer the question
of interest (e.g. calibrating the simulator) or use it to guide the choice of the
next parameter value at which, to evaluate f.
We start by generating an ensemble of simulator evaluations D
=
{θi, f(θi)}N
i=1, which we then use to build ˜f. Building an emulator is a regres-
sion problem and, consequently, a myriad of diﬀerent techniques have been
used, including linear regression and its variants, neural networks, and Gaus-
sian processes (GPs, also known as ‘Kriging’), with GPs proving the most
popular class of model thus far. The functional form of the simulator is not
known a priori, and so neither is the best regression model, but a reasonable
approximation can usually be found using GPs, as long as the response is a
smooth continuous function of θ. For the purposes of calibration, the key prop-
erties of any emulator are predictive accuracy, quantiﬁcation of uncertainty in
the predictions, and speed of prediction. In climate science, where the output
ﬁelds being modelled are often spatio-temporal ﬁelds, the regression model is
usually combined with a dimension reduction technique, to project the output
onto a lower dimensional manifold (Higdon et al., 2008; Holden and Edwards,
2010; Wilkinson et al., 2010).
19.3.1
Sequential history matching
For many problems, the plausible set Pθ may constitute only a small fraction
of the prior space Θ. Furthermore, Pθ may consist of multiple disconnected

ABC for Climate: Dealing with Expensive Simulators
577
regions. For Monte Carlo methods, this can make designing an eﬀective sam-
pler diﬃcult, as MCMC chains (or particles) can fail to explore all plausible
regions. For emulator methods, the diﬃculty lies in building a model that can
approximate the simulator in all regions of space. For example, stationary co-
variance functions that assume a constant length-scale throughout space are
commonly used in GPs and may be inappropriate. Other problems arise if
f(θ) varies over too wide a range, which is common if f(θ) is a likelihood
function (Wilkinson, 2014). If we need an emulator of f(θ) that is valid in
all of Θ, then we can look to use a non-stationary covariance function or a
more ﬂexible model, such as a treed-GP (Gramacy and Lee, 2008). However,
for calibration, we only need to approximate the simulator when f(θ) is close
to being plausible. In other parts of parameter space, it is only necessary to
say θ is implausible with a high degree of conﬁdence. It does not matter if an
estimate of f(θ) is poor, as long as we are correct in saying f(θ) ̸∈PC.
GP predictions are more accurate in regions rich in data. Thus, the key
issue when building a GP emulator is the choice of the design points, Dθ =
{θi}n
i=1, at which we evaluate the simulator. Space ﬁlling designs, such as
maximin Latin hypercubes (McKay et al., 2000) or low discrepancy sequences
(such as Sobol sequences, Morokoﬀand Caﬂisch, 1994) are the default choice
of design and usually lead to reasonable global approximations. But they are
less well suited to calibration problems, in which we usually want to focus on
just a small region of parameter space.
Instead of a space ﬁlling design, we can seek to build the design sequen-
tially: given the current design, we build an emulator that describes our current
knowledge of f(θ). We then use the emulator to decide where next to run the
simulator and so on. The basic idea is as follows:
1. Start with an a priori plausible set P(0)
θ
= Θ.
2. Choose design D(1)
θ
= {θi ∈Θ : i = 1, . . . , n1}, and run the simulator
to get ensemble D(1) = {(θi, Ci = f(θi) : θi ∈D(1)
θ }.
3. Build emulator ˜f(1) and use it to predict the plausible set ˜P(1)
θ .
4. Choose new design points D(2)
θ , and run the simulator to get D(2).
5. Build emulator ˜f (2) and use it to predict the plausible set ˜P(2)
θ .
6. Etc.
The details of each step vary in each problem. The plausibility criteria are usu-
ally deﬁned so that they become more stringent at each iteration. The ﬁrst
plausibility condition P(1)
C
may be relatively weak, with P(1)
C , P(2)
C , . . . , P(W )
C
slowly approaching the ﬁnal desired criterion P(W )
C
. If the diﬀerence between
P(i)
θ
and P(i+1)
θ
is too large, we may ﬁnd the emulator accuracy is insuﬃ-
cient, causing us to incorrectly rule-out some regions of space (type-I errors).

578
Handbook of Approximate Bayesian Computation
The plausibility criteria can be relaxed by changing the number of measure-
ments we need to match and the closeness of the required match. Note the
superﬁcial similarity to sequential Monte Carlo (SMC)-ABC approaches, in
that the approximation is iteratively improved as we learn.
The emulator used at each stage may be based upon all the previous simu-
lator runs, adding new data points in important regions (see the following for
details), or it can be built from scratch. For example, in Vernon et al. (2010),
they build an emulator, ˜f (i), to predict f(θ) for θ ∈P(i−1)
θ
, the estimated
plausible region from the previous iteration. The emulator is not required to
predict for θ ̸∈P(i−1)
θ
. The beneﬁt of this is that the simulator response is
likely to be less variable within P(i−1)
θ
than in Θ, making it easier to model.
The disadvantage is that if some regions are incorrectly ruled to be implausible
in iteration i −1, this mistake can never be rectiﬁed.
The most important algorithmic decision is the choice of design, D(i)
θ , at
each iteration, for example, given an emulator, how should we choose locations
θ at which to run the simulator? If we only wish the emulator to predict well
in P(i−1)
θ
, then we only need a design in P(i−1)
θ
. Vernon et al. (2010) take
the approach of seeking to use a space ﬁlling design on P(i−1)
θ
, such as a
Latin hypercube. To do this, they create a large design on Θ and then reject
any point not predicted to lie in P(i−1)
θ
by ˜f (i), which is also the approach we
describe in Section 19.4. If we instead seek a global emulator valid for all θ ∈Θ,
but which is accurate in the important regions, then it can be beneﬁcial to add
simulator runs to the design one at a time. The critical regions are those where
the emulator is most uncertain about whether θ ∈Pθ. This is typically either
in regions for which we have no data or near the edge of the plausible region,
where we are unsure if θ ∈Pθ or not given the accuracy of the emulator.
If we use a GP emulator, then our prediction of f(θ) is Gaussian:
f(θ) ∼N(μ(i)(θ), Σ(i)(θ)),
where μ(i) and Σ(i) are the mean and covariance function of ˜f (i). This allows
us to calculate the probability that θ ∈Pθ. For example, if our criterion is
that θ is plausible if D−≤f(θ) ≤D+, then:
p(θ) = P ˜
f (i)(θ ∈Pθ) = Φ
D+ −μ(θ)
Σ(θ)
1
2

−Φ
D−−μ(θ)
Σ(θ)
1
2

.
In some regions p(θ) will be close to zero, indicating that we are conﬁdent
that θ is implausible, and in others close to one, indicating the converse. It
is regions in which we are most uncertain that we wish to target, as these
represent parameter values that we can neither rule in nor out. One approach
to selecting new design points is to choose points to minimise the entropy of
this surface (Hennig and Schuler, 2012; Chevalier et al., 2014). The entropy

ABC for Climate: Dealing with Expensive Simulators
579
represents how close to certain knowledge we are. If we let ¯H be the average
entropy of the emulator prediction of the plausibility surface:
¯H =

−p(θ) log p(θ) −(1 −p(θ)) log(1 −p(θ))dθ,
then we can ask, if we were to add a simulator evaluation at θ, what is the
expected value of ¯H given the expected resulting information? We can then
add θ to the design in order to minimise E( ¯H|D(i−1) ∪{θ}). This approach
places new points in regions that most quickly reduce the uncertainty about
the plausible region Pθ.
19.3.2
A simple climate example
As an illustration of the potential beneﬁt of these techniques, we consider a
relatively simple two-box climate simulator (Emanuel, 2002), which models
atmospheric and ocean heat transport and storage, with water vapour as a
positive feedback. The simulator is useful for the purposes of demonstration,
as 10 years of model time takes approximately 5 seconds of CPU time, allowing
a large number of model runs to be done. MATLAB® code for this simulator
is available online.
We present the results of a simple history-matching task, calibrating two
parameters: DTcrit conv, the critical vertical temperature gradient that trig-
gers convection, which we allowed to vary in the range [30, 50]; and gamma,
the emissivity parameter for water vapour, which we varied in the range [1, 2].
We try to ﬁnd the parameter values that give a global surface temperature
between 294.5 K and 295.5 K once the model is in equilibrium. The CO2
concentration was set to 560 ppm, and all other parameters were set to their
default values (EPcm, 2010). These choices are arbitrary and only intended
for illustration of the methodology.
Applying a simple ABC rejection algorithm and allowing for 1,000 simu-
lator evaluations gave us 106 accepted parameter values, which are shown in
the left-hand plot in Figure 19.1, with the light grey points showing the ten
values accepted after only 100 simulator evaluations. In contrast, the middle
and right-hand plots show the result of using a GP emulator with a maximin
Latin hyper-cube (MLH) design of 10 and 30 simulator evaluations. After ten
simulator evaluations, the emulator has some idea of where the plausible re-
gion is, but with errors, for example, in the bottom right hand corner. After 30
simulator evaluations, it has accurately found all of the plausible region, with
just a little uncertainty at the edge of the region (shown by the grey shading).
This approach, however, relies upon ﬁnding a good design. If an accurate
emulator results, then it will do well at predicting the plausible region. Here we
can see, in the case where we had only ten design points, that no information
is available about the bottom right hand corner of the parameter space, and
consequently the model does less well there. As the design is chosen in advance
of the simulations being run, ﬁnding a good design involves an element of luck.

580
Handbook of Approximate Bayesian Computation
30
1.0
1.2
1.4
GAMMA
GAMMA
GAMMA
1.6
1.8
2.0
ABC samples
35
40
DTcrit_conv
(a)
(b)
(c)
45
50
30
1.0
1.2
1.4
1.6
1.8
2.0
MLH emulator n = 30
35
40
DTcrit_conv
45
50
30
1.0
1.2
1.4
1.6
1.8
2.0
MLH emulatur n = 10
35
285.000
287.500
285.000
290.000
292.000
297.500
290.000
287.500
292.500
297.500
295.000
40
DTcrit_conv
45
50
295.000
FIGURE 19.1
(a) Accepted samples from the rejection ABC algorithm after 100 (light grey)
and 1,000 (dark grey) simulator evaluations. (b and c) The estimated plausible
region using an emulator trained with a maximin Latin hypercube design
(points shown in grey) with 10 (middle) and 30 (right) simulator evaluations.
The shading indicates the estimated value of P(θ ∈Pθ). The contour lines are
the estimated response surface f(θ).
If we instead use a sequential design and add design points one at a time
in order to minimise the expected average entropy of the resulting history
match, then we can signiﬁcantly improve the speed with which we ﬁnd Pθ.
The two plots in Figure 19.2 show the resulting history match after four and
ten simulator evaluations. After only ten simulator evaluations, we have found
Pθ with superior accuracy to that found after 30 simulator evaluations using
the MLH design.
Note that the acceptance rate in the ABC algorithm was approximately
10%, considerably higher than in most problems (we had a 1% acceptance rate

ABC for Climate: Dealing with Expensive Simulators
581
30
1.0
1.2
1.4
GAMMA
1.6
1.8
2.0
35
40
DTcrit_conv
(a)
(b)
Emulator entropic design n = 4
Emulator entropic design n = 10
45
50
30
1.0
1.2
1.4
GAMMA
1.6
1.8
2.0
35
40
DTcrit_conv
45
50
286.500
289.500
286.000
288.000
290.000
292.000
294.000
296.000
298.000
288.000
291.000
294.000
295.500
292.500
FIGURE 19.2
Results from using an entropy based sequential design. The left-hand column
shows the estimated response surface (contours) and P(θ ∈Pθ) (shading), with
the design points overlaid. The large dark grey point is the most recently added
point. The right-hand column shows the entropy surface. The top row uses
four simulator evaluations, and the bottom row uses ten simulator evaluations,
all added according to the entropy criterion.
in the case study described in Section 19.4). As the acceptance rate decreases,
the value of using an emulator to predict Pθ increases, as the emulator is able
to predict where the plausible region is, whereas ABC can only ﬁnd the region
by chance, as it uses no information about the shape of the underlying surface.
In contrast, the major advantage of the Monte Carlo approach is that it is less
prone to errors (although mixing errors commonly occur in practice), unlike
the emulator approach, which can mislead if the ﬁtted model is inaccurate,
and thus requires careful supervision.
19.4
Climate Model Case Study
19.4.1
The global carbon cycle
Human emissions of CO2 into the atmosphere are a principal cause of climate
change. However, this ‘anthropogenic’ CO2 does not remain in the atmosphere
indeﬁnitely. It is taken up by vegetation and by the oceans, and, eventually,
(after many thousands of years) it is deposited as carbonate sediments at
the ocean ﬂoor. Understanding these processes is crucial for future climate
projections. Climate change is driven by changes in CO2 concentration and
it is therefore determined by the interplay between anthropogenic emissions

582
Handbook of Approximate Bayesian Computation
and the carbon cycle. Many carbon cycle processes are highly uncertain.
Projections of year 2100 CO2 concentrations from diﬀerent ESMs driven
by the same assumption of future emissions typically vary by ±100 ppm
(Friedlingstein et al., 2006). This uncertainty range is greater than the
total increase to date (2015) due to all historical anthropogenic emissions
(∼120 ppm).
To investigate uncertainties in the global carbon cycle, we need a model of
appropriate complexity that is capable of resolving the important processes,
but which is suﬃciently numerically eﬃcient. The GENIE-1 intermediate com-
plexity ESM (Holden et al., 2013b) is one such model. The computational
speed of GENIE-1 comes mainly from the use of a very simple two-dimensional
(2D) model of the atmosphere and relatively coarse model resolution (grid
cells of ∼1, 000 × 1, 000 km). The carbon cycle of GENIE-1 comprises a ter-
restrial carbon model, a three-dimensional (3D) dynamic ocean, dynamic sea
ice, ocean biogeochemistry, and ocean sediments. Given appropriate model pa-
rameter choices, GENIE-1 simulates realistic spatial distributions of carbon
storage in vegetation, soil, ocean, and carbonate sediment. However, the future
response of the climate cycle to ongoing emissions depends upon the speciﬁc
parameter choices and will vary even amongst parameter sets that have been
constrained to produce similar (and reasonable) modern climate states. To
quantify this uncertain response, we require an ensemble of simulations that
samples widely from plausible input parameter space.
The timescales for diﬀerent carbon cycle processes vary considerably. Equi-
librium timescales are ∼10s years for vegetation, ∼100s years for soil, ∼1, 000s
years for the ocean and ∼10, 000’s years for carbonate sediments. In or-
der to simulate an Earth with a carbon cycle in approximate equilibrium
(i.e. prior to human interference), a simulation of at least 10,000 years is
required.∗Although several orders of magnitude faster than than state-of-
the-art ESMs, GENIE-1 requires ∼4 CPU days to simulate 10,000 real years.
The exploration of high-dimensional input space and identiﬁcation of plausi-
ble subspaces is therefore a highly demanding computational problem, which
we address through emulator-informed ABC.
19.4.2
Emulator-informed ABC design
The philosophy of the design approach is to vary key model parameters over
the entire range of plausible values and to accept those parameter combina-
tions that lead to climate states that cannot be uncontroversially ruled out
as implausible (Edwards et al., 2011). We are seeking to explore all plausi-
ble simulator realisations in order to capture the range of possible feedback
strengths. The input ranges we apply, Θ, are generally broader than ranges
that are applied in model tuning exercises. This is in part to enable us to fully
quantify model behaviour over plausible parameter space, Pθ, and in part to
∗Shorter spin-ups are suﬃcient for models that neglect sediments.

ABC for Climate: Dealing with Expensive Simulators
583
improve the validity of the ensemble for application to diverse climate states,
such as the Last Glacial Maximum.
The experimental set-up is described in Holden et al. (2013a). We varied
24 model parameters in the ensemble. The choice of parameters was governed
by consideration of the processes that are thought to contribute to the natural
variability of atmospheric CO2 on glacial-interglacial timescales (Kohfeld and
Ridgwell, 2009) and, hence, to which the distribution of carbon may be sen-
sitive in general. Five atmospheric parameters were varied. These parameters
control the spatial distribution of simulated temperature and precipitation
and, hence, drive changes in vegetation, sea-ice coverage, and ocean circula-
tion. Five parameters were varied in the vegetation model, controlling pho-
tosynthesis and respiration rates. Five ocean parameters were varied. These
control ocean circulation and, hence, the spatial distribution of carbon, alkalin-
ity, dissolved oxygen, and nutrients in the ocean. Sea-ice diﬀusivity was varied,
primarily because of its eﬀect on ocean circulation by altering the transport of
freshwater. Nine ocean biogeochemistry parameters were varied. These param-
eters drive changes in the rates of atmosphere-ocean gas exchange, plankton
photosynthesis, and the remineralisation of the organic products of this pho-
tosynthesis. The rate of remineralisation controls the transport of carbon from
the surface of the ocean to the deep.
A 500-member ensemble of 25,000-year simulations was ﬁrst performed
using a MLH design.∗The plausibility of each simulator run was evaluated
using eight diﬀerent output quantities, usually termed metrics in the climate
literature. These simple metrics impose no constraints on the spatial distri-
bution of modelled outputs. They instead provide global-scale constraints on
atmosphere (global average temperature), ocean (strength of North Atlantic
overturning and Antarctic deep water formation), Antarctic sea-ice coverage,
global vegetation carbon, global soil carbon, ocean biogeochemistry (average
dissolved oxygen concentration in the global ocean), and ocean sediments (the
average percentage of CaCO3 in the surface sediment). Only four of the 500
MLH simulations were found to satisfy all eight plausibility constraints, which
given that dim θ=24, is insuﬃcient for any meaningful statistical analysis. The
MLH ensemble took more than ten years of computing to complete, demon-
strating that a naive application of ABC is infeasible for this application.
As described in Section 19.3, we can use emulators to guide the search
to ﬁnd plausible regions of parameter space. Regression-based emulators, in-
cluding linear and quadratic terms, were built for each of the eight metrics
(outputs) speciﬁed earlier. Prior to ﬁtting, variables were linearly mapped
onto the range [−1,1], so that odd and even terms were orthogonal, aiding
variable selection. The models were built using a stepwise model selection
∗We note that while eﬃciencies can be gained in certain applications by initialising each
ensemble member with output from an existing equilibrium simulation, such an approach
is not likely to be useful here as our approach is designed to sample widely diﬀering Earth
system states.

584
Handbook of Approximate Bayesian Computation
scheme, initially using the Akaike information criterion as the selection cri-
terion and then subsequently shrunk further by applying the more stringent
Bayes information criterion. This procedure of ﬁrst growing the model beyond
the Bayes information criterion constraint and then shrinking helps to avoid
local minima in the stepwise search.
Parameters were then sampled uniformly from the a priori plausible region
and the emulators used to predict if they would lead to plausible simulations.
Parameters were accepted as potentially plausible when the emulators pre-
dicted plausible values for all eight metrics. The plausibility ranges used were
based on the observed climate record, the simulator discrepancy, and the em-
ulator accuracy. Each accepted parameter combination was then used as a
design point in a further simulation.
As simulations completed, the emulators were rebuilt using the addition-
ally available data. This process progressively improved the success rate of
the emulator predictions (i.e. the percentage of emulator predicted plausible
parameters that led to plausible simulations) from 24% to 65%. In total, the
simulator was run for 1,000 parameter values predicted to be plausible by the
emulator. This produced 885 completed simulations of which 471 were plausi-
ble (the remaining 115 simulations terminated before completion, a common
occurrence with climate simulators). This 471-member plausible set forms the
Emulator Filtered Plausibility Constrained (EFPC) ensemble. The generation
of these simulations required a further 25 years of computing time. Without
the ∼50-fold increase in eﬃciency gained by using an emulator to predict the
plausible region, this would have required an infeasible amount (more than
1,000 years) of CPU time.
While it is clear that ABC strongly constrains the outputs (metrics) that
are explicitly ﬁltered for, it is worth noting that it indirectly constrains all
aspects of the Earth system and leads to improved simulated magnitudes and
spatial distributions of state variables generally. Figure 19.3 provides an illus-
trative output of the EFPC ensemble and of the beneﬁts of the ABC ﬁltering.
The ﬁgure illustrates cross-sections of ocean alkalinity through the Atlantic
and Paciﬁc Oceans, comparing ensemble means of the unﬁltered MLH simu-
lations (left) and ﬁltered EFPC simulations (centre) with observational data
(right). Ocean alkalinity exerts a strong control on atmospheric carbon diox-
ide by determining the degree to which dissolved carbon dioxide is dissociated
into bicarbonate and carbonate ions, in turn determining the rates of ex-
change of dissolved carbon in the ocean with the atmosphere (carbon dioxide)
and the sediments (calcium carbonate). Alkalinity is not directly constrained
by the ABC metrics, but its distribution is inﬂuenced by them, for instance,
through the constraints imposed on ocean circulation strength and the sed-
iment carbonate concentration. Relative to the MLH ensemble, the EFPC
ensemble shows elevated surface concentrations, decreased concentrations in
the deep Atlantic (apparently associated with the Atlantic overturning circu-
lation in the unﬁltered ensemble), and increased penetration of high alkalinity
towards southern latitudes in the deep Paciﬁc. Although discrepancies with

ABC for Climate: Dealing with Expensive Simulators
585
MLH
Atlantic
EFPS
OBS
Pacific
2100.0
2180.0
2260.0
Alkalinity (micromols/kg)
(a)
(b)
(c)
2340.0
2420.0
2500.0
−90
−60
−30
0
30
60
90
Latitude (°N)
−90
−60
−30
0
30
60
90
Latitude (°N)
−90
−60
−30
0
30
60
90
Latitude (°N)
−90
−60
−30
0
°
°
°
°
30
60
90
Latitude (°N)
−90
−60
−30
0
30
60
90
Latitude (°N)
−90
−60
−30
0
4959.5
3967.0
2974.5
1981.9
989.4
4959.5
3967.0
2974.5
1981.9
989.4
30
60
90
Latitude (°N)
FIGURE 19.3
Cross-sections of ocean alkalinity through the Atlantic (25◦W) and Paciﬁc (155◦W) Oceans. The ﬁgure compares the mean
of the training MLH ensemble (a) and the plausibility ﬁltered EFPC ensemble (b) with observations (c).

586
Handbook of Approximate Bayesian Computation
observations remain, which may reﬂect structural deﬁciencies in the simulator,
each of these trends produces better ensemble-averaged agreement with the
observed distribution.
19.4.3
Applications
Although the use of ABC to derive a posterior distribution is useful in itself,
our primary motivation is to identify a set of plausible parameters for applica-
tion to diverse simulation problems. The EFPC parameter set has been used
in a range of experiments, considering both past and future climate change.
For clarity, it is worth emphasising that while these experiments did not use
ABC directly, they were all rendered tractable by the use of emulator-informed
ABC to design the underlying simulation ensemble. A selection of these ex-
periments are summarised in the following, each with a focus on a diﬀerent
category of application.
19.4.3.1
Probabilistic simulation outputs: The uncertain response
of the carbon cycle to anthropogenic CO2 emissions
We (PBH and NRE) contributed a suite of carbon cycle experiments for the
Fifth Assessment Report (AR5) of the Intergovernmental Report on Climate
Change (IPCC). Fifteen intermediate complexity ESMs from around the world
performed these experiments. The focus was on historical change (Eby et al.,
2013) and long-term future change (Zickfeld et al., 2013), considering long
timescale problems that are not tractable by state-of-the-art ESMs, thus re-
quiring the use of reduced complexity models such as GENIE-1. Forty seven
experiments were performed.
We applied a subset of the EFPC parameter set, in part to aid compu-
tational tractability, in view of the 47 separate experiments required, and, in
part, to eliminate a bias in the transient response of the ensemble. The EFPC
parameter set is constrained to simulate a plausible pre-industrial climate,
but no constraint was imposed upon the dynamic response to anthropogenic
emissions. Four important model parameters were not constrained by prein-
dustrial plausibility, two relating to cultivated vegetation (deforestation for
agriculture was neglected in the preindustrial simulations), a parameter con-
trolling the direct eﬀect of CO2 on photosynthesis (‘CO2 fertilisation’, see
following section), and a parameter controlling the uncertain eﬀect of clouds
on the Earth’s radiation budget in a warmer planet. The dynamic response
was therefore ﬁltered through a historical forcing experiment, which imposed
anthropogenic forcing, including CO2 emissions, since pre-industrial times in
an EFPC ensemble of transient simulations. Twenty parameter sets, selected
at random from the EFPC parameter sets, but constrained to approximately
reproduce the present day atmospheric CO2 concentration, were accepted and
applied to the IPCC experiments.
We do not attempt to summarise the results of these extensive multi-
model comparisons here, but note that the GENIE-1 perturbed-parameter

ABC for Climate: Dealing with Expensive Simulators
587
ensemble was found to provide an unbiased representation of the multi-model
ensemble, being approximately centred on the mean of the 15 models and
with comparable uncertainty. These uncertainties were presented in a related
model intercomparison paper (Joos et al., 2013).
19.4.3.2
Calibrating model parameters: The strength of the
terrestrial carbon sink
The IPCC experiments revealed a general tendency of intermediate complex-
ity ESMs to understate the magnitude of the terrestrial carbon sink (the an-
thropogenic CO2 taken up by vegetation on land). The major uncertainty in
the terrestrial sink relates to CO2 fertilisation. Experimental evidence almost
without exception shows a stimulation of leaf photosynthesis when plants are
exposed to elevated CO2 (K¨orner, 2006). In addition to this direct aﬀect on
photosynthesis, the short timescale physiological eﬀect of reduced stomatal
opening increases water-use eﬃciency and additionally increases the eﬃciency
of photosynthesis (Field et al., 1995). However, the strength of the fertilisation
eﬀect is poorly quantiﬁed, especially under natural conditions. Some studies
have failed to detect a measurable eﬀect in nature, while others suggest that
any eﬀects may be short term, as CO2 is only one of a number of potentially
limiting factors on plant growth (K¨orner, 2006).
We addressed this calibration problem in Holden et al. (2013b). Using out-
put from a 671-member ensemble of transient GENIE-1 simulations derived
from the EFPC parameter sets, we built an emulator of the change in atmo-
spheric CO2 concentration change since the pre-industrial period. We then
applied this emulator to sample the 28-dimensional input parameter space.
A Bayesian calibration suggests that the increase in gross primary productiv-
ity (GPP) in response to a doubling of CO2 from pre-industrial values is very
likely (90% conﬁdence) to exceed 20%, with a most likely value of 40%–60%.
19.4.3.3
Model understanding: What determines the spatial
distribution of dissolved carbon in the ocean?
In Holden et al. (2013a), we applied the EFPC ensemble to a transient experi-
ment over the recent industrial era (1858–2008 AD). The temporal evolution of
atmospheric CO2 and its isotopic composition are known from observational
data, and these simulated quantities were made to follow the observations
through a relaxation term. The objective of the experiment was to better
understand the mechanisms by which the anthropogenic CO2 emissions are
taken up by the ocean.
To achieve this, we analysed the change in distributions of ocean concen-
trations of dissolved inorganic carbon and its stable isotope δ13C, considering
two-dimensional latitudinal-vertical transects through the Atlantic and
Paciﬁc. These two transects were combined into a single vector for each simu-
lation (to ensure inter-basin eﬀects were consistently represented), and these
vectors were combined into an ensemble matrix. Singular vector decomposition

588
Handbook of Approximate Bayesian Computation
was applied to the DIC and δ13C matrices in order to extract the dominant
modes of their spatial variability across the ensemble. Emulators of the com-
ponent scores elicited further understanding of these modes by identifying
which model parameters were driving each mode of variability.
This, together with physical interpretation of the spatial patterns of each
mode, enabled us to identify the principal processes driving them, on the as-
sumption that the dominant parameters governing uncertainty in the response
of each mode could be identiﬁed with the most important parameterised pro-
cesses controlling the respective modes. We showed that the main processes
governing the uptake of anthropogenic CO2 and δ13C are quite distinct: an
important conclusion because observations of the isotopic composition are
used to infer rates of ocean CO2 uptake. Uncertainty in anthropogenic δ13C
uptake is dominated by air-sea gas exchange, which explains 63% of modelled
variance. This mode of variability is largely absent from the ensemble vari-
ability in CO2 uptake, which is instead driven by uncertainties in mixing rates
between the surface and deep oceans.
19.4.3.4
Coupling applications: Coupling climate models and
climate change impact models
The evaluation of climate impacts requires coupling climate models, im-
pact models, and economic models together within an ‘integrated assessment
model’ (IAM) framework. In such couplings, climate data (e.g. regional tem-
perature, precipitation) are passed to the IAM for computation of climate
impact functions, and the IAM passes back anthropogenic forcing (such as
CO2 emissions or land use change). Computational demands mean that it is
generally infeasible to couple complex climate models into IAMs. Various ap-
proaches are taken to address this, using either simpliﬁed models or statistical
representations of more complex models. Recently, eﬀort has focussed on the
use of emulators of climate models as surrogates for the simulator in these
coupling applications.
Economic models provide projections of CO2 emissions. They typically
convert emissions into concentrations through the use of simple ‘box-models’,
describing rates of carbon transfer between the atmospheric, terrestrial and
oceanic reservoirs. We have recently applied the EFPC parameter set to build
an emulator of the GENIE-1 carbon cycle model for incorporation into inte-
grated assessment models (Foley et al., 2016). An 86-member subset of the
EFPC parameter set was used to generate an ensemble of future climate-
carbon cycle experiments, with future emissions prescribed as modiﬁed Cheby-
shev polynomials.
The emulation approach followed the ‘1-step’ dimensionally reduced emu-
lation methodology of Holden et al. (2015), emulating a singular value decom-
position of the ensemble outputs. Emulators of the ﬁrst four component scores
were derived as functions of the 28 model parameters and the 6 concentration
proﬁle coeﬃcients. The emulator outputs are, unsurprisingly, dominated by

ABC for Climate: Dealing with Expensive Simulators
589
the Chebyshev coeﬃcients. However, uncertainty for a given forcing scenario
is generated through emulator dependencies on GENIE-1 parameters. The re-
sulting carbon cycle emulator has been coupled into an integrated assessment
framework that also includes a macroeconometric model of the global econ-
omy E3MG (Mercure et al., 2014), an agent-based model of technology sub-
stitution dynamics future technology transformations (FTT)-power (Mercure,
2012) and a spatiotemporally resolved emulator of the climate system (Holden
et al., 2014). We have applied the framework to assess the impact on the cli-
mate of emissions reduction policies in the electricity sector (Mercure et al.,
2014), addressing the cascade of uncertainty through the coupled system.
19.5
Future Applications
It may never be possible to apply statistical approaches to robustly calibrate
a truly state-of-the-art climate simulator. They are deﬁned by the limits of
available computing power, and, consequently, very few simulations are possi-
ble with these models. This begs the important question of how far could
one go with simulator complexity and still be able apply these methods.
We have demonstrated the application of emulator-informed ABC to gen-
erate a 471-member ensemble of a model that takes ∼10 days to perform each
simulation. The computational constraints ultimately determined the number
of parameters we could vary; a rule of thumb dictates that we use a minimum
of ten ensemble members for each varied active input (Loeppky et al., 2009).
It is worth noting that a useful ensemble varying only, say, 5 parameters would
need ∼50 simulations and could have been achieved for a 10-fold slower model.
The improvements in methodology demonstrated in Section 19.3.2, suggest
eﬃciencies that should signiﬁcantly extend the applicability of the approach.
The use of GP emulation generally allows a better statistical model than lin-
ear regression, and, therefore, would be expected to improve the success rate
of the emulator ﬁltering. This will certainly be the case when a parametric
mean function is used and the GP is applied only to emulate the residual.
The uncertainty estimates provided by the GP should also improve the suc-
cess rate of the emulator ﬁltering, for instance, by only accepting parameters
for which there is a high probability of plausibility. Furthermore, a signiﬁ-
cant improvement arises from the use of a sequential design process, which
was shown to yield a 3-fold increase in eﬃciency in our example. For more
complex simulators, we will want to make use of parallel computation. The
sequential approach then changes from adding one design point at a time, to
adding d, where d is the number of available cores. Finding the d optimal
points that minimise the expected entropy is diﬃcult, and is an area of active
research, but even suboptimal designs can give signiﬁcant improvements over
the default space-ﬁllings designs. For stochastic simulators, many of the same

590
Handbook of Approximate Bayesian Computation
techniques can be applied. The likelihood function now needs to be estimated,
signiﬁcantly increasing the diﬃculty, but progress is being made in this direc-
tion (Meeds and Welling, 2014; Oakley and Youngman, 2014; Wilkinson, 2014;
Gutmann and Corander, 2015).
These improvements in eﬃciency should render application to ‘previous-
generation’ ESMs, such as HadCM3∗tractable on multi-node computing
clusters, certainly so on distributed computing systems, such as climatepredic-
tion.net, which last year facilitated more than 7,500 years of climate modelling
on the personal computers of the general public.
References
A box climate model: EPcm. Model documentation v4. www.sp.ph.ic.
ac.uk/∼aczaja/EP ClimateModel.html, 2010.
Andrianakis, I., I. R. Vernon, N. McCreesh, T. J. McKinley, J. E. Oakley,
R. N. Nsubuga, M. Goldstein, and R. G. White. Bayesian history matching
of complex infectious disease models using emulation: A tutorial and a case
study on hiv in uganda. PLoS Computational Biology, 11(1):e1003968, 2015.
Annan, J., J. Hargreaves, N. Edwards, and R. Marsh. Parameter estimation in
an intermediate complexity earth system model using an ensemble Kalman
ﬁlter. Ocean Modelling, 8(1):135–154, 2005.
Biau, G., F. C´erou, and A. Guyader. New insights into Approximate Bayesian
Computation. Annales de l’Institut Henri Poincar´e, Probabilit´es et Statis-
tiques, 51:376–403, 2015.
Blum, M. G., M. A. Nunes, D. Prangle, and S. A. Sisson. A comparative
review of dimension reduction methods in approximate Bayesian computa-
tion. Statistical Science, 28(2):189–208, 2013.
Brynjarsd´ottir, J., and A. O’Hagan. Learning about physical parameters: The
importance of model discrepancy. Inverse Problems, 30(11):114007, 2014.
Castruccio, S., D. J. McInerney, M. L. Stein, F. Liu Crouch, R. L. Jacob, and
E. J. Moyer. Statistical emulation of climate model projections based on
precomputed GCM runs. Journal of Climate, 27(5):1829–1844, 2014.
Chevalier, C., D. Ginsbourger, J. Bect, E. Vazquez, V. Picheny, and Y. Richet.
Fast parallel kriging-based stepwise uncertainty reduction with application
to the identiﬁcation of an excursion set. Technometrics, 56(4):455–465, 2014.
∗HadCM3 performs more than ten years per CPU day on eight nodes of a linux cluster.

ABC for Climate: Dealing with Expensive Simulators
591
Craig, P. S., M. Goldstein, A. H. Seheult, and J. A. Smith. Pressure matching
for hydrocarbon reservoirs: A case study in the use of Bayes linear strategies
for large computer experiments. In C. Gatsonis, J. S. Hodges, R. E. Kass,
R. McCulloch, P. Rossi, and N. D. Singpurwalla (Eds.), Case Studies in
Bayesian Statistics, pp. 37–93. New york: Springer, 1997.
Eby,
M.,
A.
J.
Weaver,
K.
Alexander,
K.
Zickfeld,
A.
Abe-Ouchi,
A. Cimatoribus, E. Crespin et al. Historical and idealized climate model
experiments: an intercomparison of Earth system models of intermediate
complexity. Climate of the Past, 9:1111–1140, 2013.
Edwards, N. R., D. Cameron, and J. Rougier. Precalibrating an intermediate
complexity climate model. Climate Dynamics, 37(7–8):1469–1482, 2011.
Emanuel, K. A simple model of multiple climate regimes. Journal of Geophys-
ical Research, 107(D9):ACL–4, 2002.
Field, C., R. Jackson, and H. Mooney. Stomatal responses to increased CO2:
Implications from the plant to the global scale. Plant, Cell & Environment,
18(10):1214–1225, 1995.
Flato, G., J. Marotzke, B. Abiodun, P. Braconnot, S. C. Chou, W. Collins,
P. Cox et al. Evaluation of climate models. In Climate Change 2013: The
Physical Science Basis. Contribution of Working Group I to the Fifth
Assessment Report of the Intergovernmental Panel on Climate Change,
pp. 741–866, 2013.
Foley, A.M., P. B. Holden, N. R. Edwards, J.-F. Mercure, P. Salas, H. Politt,
and U. Chewpreecha. Climate model emulation in an integrated assessment
framework: A case study for mitigation policies in the electricity sector.
Earth System Dynamics, 7:119–132, 2016.
Friedlingstein, P., P. Cox, R. Betts, L. Bopp, W. Von Bloh, V. Brovkin,
P. Cadule et al. Climate-carbon cycle feedback analysis: Results from the
C4MIP model intercomparison. Journal of Climate, 19(14):3337–3353, 2006.
Gramacy, R. B., and H. K. Lee. Bayesian treed Gaussian process models with
an application to computer modeling. Journal of the American Statistical
Association, 103(483):1119–1130, 2008.
Gutmann M. U., and J. Corander. Bayesian optimization for likelihood-
free
inference
of
simulator-based
statistical
models.
arXiv
preprint
arXiv:1501.03291, 2015.
Harris, G. R., D. M. Sexton, B. B. Booth, M. Collins, and J. M. Murphy.
Probabilistic projections of transient climate change. Climate Dynamics,
40:2937–2972, 2013.

592
Handbook of Approximate Bayesian Computation
Hennig, P., and C. J. Schuler. Entropy search for information-eﬃcient global
optimization. The Journal of Machine Learning Research, 13(1):1809–1837,
2012.
Higdon, D., J. Gattiker, B. Williams, and M. Rightley. Computer model cali-
bration using high-dimensional output. Journal of the American Statistical
Association, 103(482):570–583, 2008.
Holden, P., and N. Edwards. Dimensionally reduced emulation of an AOGCM
for application to integrated assessment modelling. Geophysical Research
Letters, 37(21):L21707, 2010.
Holden, P., N. Edwards, P. Garthwaite, K. Fraedrich, F. Lunkeit, E. Kirk,
M. Labriet, A. Kanudia, and F. Babonneau. PLASIM-ENTSem v1.0: A
spatio-temporal emulator of future climate change for impacts assessment.
Geoscientiﬁc Model Development, 7(1):433–451, 2014.
Holden, P., N. Edwards, P. Garthwaite, and R. Wilkinson. Emulation and
interpretation of high-dimensional climate model output. Journal of Applied
Statistics, 2015. doi:10.1080/02664763.2015.1016412.
Holden, P., N. Edwards, D. Gerten, and S. Schaphoﬀ. A model-based con-
straint on CO2 fertilisation. Biogeosciences, 10(1):339–355, 2013b.
Holden, P., N. Edwards, S. M¨uller, K. Oliver, R. Death, and A. Ridgwell.
Controls on the spatial distribution of oceanic δ13CDIC. Biogeosciences,
10:1815–1833, 2013a.
Holden, P. B., N. Edwards, K. Oliver, T. Lenton, and R. Wilkinson. A prob-
abilistic calibration of climate sensitivity and terrestrial carbon change in
GENIE-1. Climate Dynamics, 35(5):785–806, 2010.
Holloway Jr., J. L., and S. Manabe. Simulation of climate by a global general
circulation model: I. hydrologic cycle and heat balance. Monthly Weather
Review, 99(5):335–370, 1971.
Joos, F., R. Roth, J. Fuglestvedt, G. Peters, I. Enting, W. von Bloh,
V. Brovkin et al. Carbon dioxide and climate impulse response functions
for the computation of greenhouse gas metrics: A multi-model analysis. At-
mospheric Chemistry and Physics, 13(5):2793–2825, 2013.
Kennedy, M., and A. O’Hagan. Bayesian calibration of computer models (with
discussion). Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 63:425–464, 2001.
Kohfeld, K. E., and A. Ridgwell. Glacial-Interglacial variability in atmospheric
CO2. In C. Quere and E. S. Saltzman (Eds.), Surface Ocean-Lower At-
mosphere Processes, pp. 251–286. Washington, DC: American Geophysical
Union, 2009.

ABC for Climate: Dealing with Expensive Simulators
593
K¨orner, C. Plant CO2 responses: An issue of deﬁnition, time and resource
supply. New phytologist, 172(3):393–411, 2006.
Lee, L., K. Carslaw, K. Pringle, and G. Mann. Mapping the uncertainty in
global CCN using emulation. Atmospheric Chemistry and Physics, 12(20):
9739–9751, 2012.
Loeppky, J. L., J. Sacks, and W. J. Welch. Choosing the sample size of a com-
puter experiment: A practical guide. Technometrics, 51(4):366–376, 2009.
Marquis, J., Y. Richardson, P. Markowski, D. Dowell, J. Wurman, K. Kosiba,
P. Robinson, and G. Romine. An investigation of the Goshen County,
Wyoming, tornadic supercell of 5 June 2009 using EnKF assimilation of
mobile mesonet and radar observations collected during VORTEX2. Part I:
Experiment design and veriﬁcation of the EnKF analyses. Monthly Weather
Review, 142(2):530–554, 2014.
Mauritsen, T., B. Stevens, E. Roeckner, T. Crueger, M. Esch, M. Giorgetta,
H. Haak et al. Tuning the climate of a global model. Journal of Advances
in Modeling Earth Systems, 4(3):M00A01, 2012.
McKay, M. D., R. J. Beckman, and W. J. Conover. A comparison of three
methods for selecting values of input variables in the analysis of output
from a computer code. Technometrics, 42(1):55–61, 2000.
Meeds, E., and M. Welling. GPS-ABC: Gaussian process surrogate approxi-
mate Bayesian computation. arXiv preprint arXiv:1401.2838, 2014.
Mercure, J.-F. FTT: Power: A global model of the power sector with induced
technological change and natural resource depletion. Energy Policy, 48:799–
811, 2012.
Mercure, J.-F, H. Pollitt, U. Chewpreecha, P. Salas, A. M. Foley, P. B. Holden,
and N. R. Edwards. The dynamics of technology diﬀusion and the impacts
of climate policy instruments in the decarbonisation of the global electricity
sector. Energy Policy, 73:686–700, 2014.
Morokoﬀ, W. J., and R. E. Caﬂisch. Quasi-random sequences and their dis-
crepancies. SIAM Journal on Scientiﬁc Computing, 15:1251–1279, 1994.
Murphy, J. M., D. M. Sexton, D. N. Barnett, G. S. Jones, M. J. Webb,
M. Collins, and D. A. Stainforth. Quantiﬁcation of modelling uncertainties
in a large ensemble of climate change simulations. Nature, 430(7001):768–
772, 2004.
Oakley, J. E., and B. D. Youngman. Calibration of complex computer simu-
lators using likelihood emulation. arXiv preprint arXiv:1403.5196, 2014.
O’Hagan, A. Bayesian analysis of computer code outputs: A tutorial. Relia-
bility Engineering & System Safety, 91(10):1290–1300, 2006.

594
Handbook of Approximate Bayesian Computation
Olson, R., R. Sriver, M. Goes, N. M. Urban, H. D. Matthews, M. Haran,
and K. Keller. A climate sensitivity estimate using Bayesian fusion of
instrumental observations and an Earth System model. Journal of Geo-
physical Research: Atmospheres (1984–2012), 117(D4):D04103, 2012.
Oyebamiji, O. K., N. R. Edwards, P. B. Holden, P. H. Garthwaite,
S. Schaphoﬀ, and D. Gerten. Emulating global climate change impacts on
crop yields. Statistical Modelling, 15(6):499–525, 2015.
Rougier, J. Probabilistic inference for future climate using an ensemble of
climate model evaluations. Climatic Change, 81(3–4):247–264, 2007.
Rougier, J. and M. Goldstein. Climate simulators and climate projections.
Annual Review of Statistics and Its Application, 1:103–123, 2014.
Rougier, J., D. M. Sexton, J. M. Murphy, and D. Stainforth. Analyzing the
climate sensitivity of the HadSM3 climate model using ensembles from dif-
ferent but related experiments. Journal of Climate, 22(13):3540–3557, 2009.
Sacks, J., W. J. Welch, T. J. Mitchell, and H. P. Wynn. Design and analysis
of computer experiments. Statistical Science, 4:409–423, 1989.
Sans´o, B., C. E. Forest, D. Zantedeschi. Inferring climate system properties
using a computer model. Bayesian Analysis, 3(1):1–37, 2008.
Santner, T. J., B. J. Williams, and W. I. Notz. The Design and Analysis of
Computer Experiments. New York: Springer Verlag, 2003.
Sham Bhat, K., M. Haran, R. Olson, and K. Keller. Inferring likelihoods and
climate system characteristics from climate models and multiple tracers.
Environmetrics, 23(4):345–362, 2012.
Vernon, I., M. Goldstein, and R. G. Bower. Galaxy formation: A Bayesian
uncertainty analysis. Bayesian Analysis, 5:619–669, 2010.
Wilkinson, R. D. Bayesian calibration of expensive multivariate computer ex-
periments. In L. Biegler, G. Biros, O. Ghattas, M. Heinkenschloss, D. Keyes,
B. Mallick, Y. Marzouk, L. Tenorio, B. van Bloemen Waanders, and
K. Wilcox (Eds.), Large-Scale Inverse Problems and Quantiﬁcation of Un-
certainty, pp. 195–215. Chichester, UK: John Wiley & Sons, 2010.
Wilkinson, R. D. Approximate Bayesian computation (ABC) gives exact re-
sults under the assumption of model error. Statistical Applications in Ge-
netics and Molecular Biology, 12:129–141, 2013.
Wilkinson, R. D. Accelerating ABC methods using Gaussian processes. JMLR
Workshop and Conference Proceedings Volume 33: Proceedings of the Sev-
enteenth International Conference on Artiﬁcial Intelligence and Statistics,
33:1015–1023, 2014.

ABC for Climate: Dealing with Expensive Simulators
595
Williamson, D., M. Goldstein, L. Allison, A. Blaker, P. Challenor, L. Jackson,
and K. Yamazaki. History matching for exploring and reducing climate
model parameter space using observations and a large perturbed physics
ensemble. Climate Dynamics, 41(7–8):1703–1729, 2013.
Zickfeld, K., M. Eby, A. J. Weaver, K. Alexander, E. Crespin, N. R. Edwards,
A. V. Eliseev et al. Long-term climate change commitment and reversibility:
An EMIC intercomparison. Journal of Climate, 26(16):5782–5809, 2013.


20
ABC in Ecological Modelling
Matteo Fasiolo and Simon N. Wood
CONTENTS
20.1
Simulation-Based Methods in Ecology ...........................
597
20.1.1
Intractable ecological models ............................
597
20.1.2
Inference for state space models ........................
600
20.1.3
SL versus tolerance-based ABC .........................
604
20.2
Example: A Chaotic Prey–Predator Model ......................
608
20.2.1
Description of data and priors ..........................
610
20.2.2
Comparison using simulated data .......................
612
20.2.3
Results from the Kilpisjarvi dataset ....................
613
20.3
Discussion ........................................................
616
Acknowledgements .......................................................
619
References
...............................................................
619
20.1
Simulation-Based Methods in Ecology
20.1.1
Intractable ecological models
Ecology aims to understand the abundance and distribution of organisms.
This essentially quantitative task is made diﬃcult by the complex web of
interactions that exist between living things. In the face of such daunting
ecological complexity, dynamic models play an important role in separating
fundamental mechanisms from matters of detail. In particular, they allow
theoretical ideas to be sharpened into well deﬁned quantitative hypotheses,
and this in turn opens up the possibility of testing these hypotheses using
data.
But there is a catch. To be useful, ecological dynamic models must often
resort to ‘cartooning’ of some ecological processes. Simpliﬁcation is essential
if the model is not to become a ‘model-of-everything’, hence, a reasonably
597

598
Handbook of Approximate Bayesian Computation
parsimonious model may not be intended to reproduce the full data yobs in
all its features. For example, while the full data might be characterized by a
spatial or temporal structure, it is often convenient to use a lumped model
that ignores these dimensions. Similarly, when the data contain several classes
of organisms, computational considerations might lead to a model that aggre-
gates key statistics, such as population counts, over diﬀerent classes. Under
these circumstances, reducing the full data to a set of summary statistics,
sobs = S(yobs), might not lead to any loss of information during parameter
estimation or model selection (Hartig et al., 2011).
Basing statistical inference on aggregate summary statistics might be
necessary even when working with individual based models, which are of-
ten used to understand ecological outcomes that depend intricately on the
interactions of individuals within a population. Forest stand growth mod-
els are an example. In these models, individual trees of many species may
be grown to maturity, all competing continuously for light and nutrients as
they do so. Here, the mismatch between data and model is of a diﬀerent
kind. For example, in a real forest, we would obtain data consisting of mea-
surements on individual trees. The same measurements can often be made
on the model trees, but a particular model individual does not correspond
to any real individual. We are left with no choice but to base inference
on summary statistics, which suggests the use of ABC-type methods. One
such example is Hartig et al. (2014) who uses synthetic likelihood (Wood,
2010), an approximate method closely related to ABC, to ﬁt the FORest
Mixture INDividual-based (FORMIND) individual-based forest model to
Ecuadorian tropical forest ﬁeld data. While the model deals with individual
trees, its output is summarised using 112 statistics such as biomass, growth
rate, and tree counts, obtained by aggregating trees over several diameter
classes.
Other reasons for considering the use of summary statistics relate to
highly non-linear dynamics, of the sort that are often found in populations of
small animals, with high rates of fecundity and mortality. Indeed, even if our
models are perfect descriptions of the driving ecological mechanisms, dynamic
irregularity can make reliable inference very diﬃcult to achieve by conven-
tional means. If our models are less perfect, the interaction of such irregular-
ity with small infelicities in the model’s ability to match the data can lead to
substantial inferential errors. Wood (2010) shows that these problems can
arise in ecological systems as simple as the Ricker map (May, 1976) and illus-
trates how the extreme sensitivity of near chaotic systems to small changes in
dynamically important parameters can cause minuscule moves in the parame-
ter space to result in massive changes in likelihood values. In this circumstance,
it is obviously appealing to base inference on summary statistics of the data
that the model should be able to reproduce, rather than on the full data.
Indeed, Wood (2010) and Fasiolo et al. (2014) argue that ABC-type meth-
ods can oﬀer an appealing robustness here, provided that they are used in
conjunction with appropriately robust statistics.

ABC in Ecological Modelling
599
Even in the absence of the diﬃculties just discussed, ecological models can
have tractability problems. Most of the conventional statistical tools used to
ﬁnd the parameter values or models that are most consistent with data (and
possibly with prior knowledge), rely on the likelihood function, p(yobs|θ). Un-
fortunately, for many models of ecological interest, p(yobs|θ) is not available
directly or is otherwise problematic, thus posing an obstacle to the whole in-
ferential process. This diﬃculty can occur for several possible reasons, but
one common problem is the presence of hidden or latent states. Speciﬁcally,
we often know that the dynamics of an observed process yobs are related to
those of other processes n, which are hidden from us. In such cases, the likeli-
hood could ideally be obtained by integrating the latent states out of the joint
probability density of data and hidden states:
p(yobs|θ) =

p(yobs, n|θ) dn.
(20.1)
In practice, this integration problem is usually analytically intractable, while
the eﬃcient implementation of numerical or Monte Carlo integration schemes
often require additional assumptions, such as those detailed in Section 20.1.2.
Classical examples of partially observed systems of ecological interest are
predator-prey systems, where the abundance of one of the two components
is often completely unknown. In Section 20.2, we consider the prey–predator
model proposed by Turchin and Ellner (2000), which has been used to describe
the population dynamics of Fennoscandian voles. In that example trap data
provide noisy estimates of voles abundance, but no such proxy is available
for predatory weasels. A similar example is provided by Kendall et al. (2005),
who evaluate alternative explanations for the regular oscillations in popula-
tion density of insect pest pine looper moths. They consider, among others,
a parasitoid and a food quality model, and they ﬁt them using only data
on moth population density. Given that ecological systems are observed with
noise in most cases, the issue of hidden states is widespread, and it appears
in studies concerned with animal movement (Langrock et al., 2012; Morales
et al., 2004), population abundance estimation (Farnsworth et al., 2007), and
essentially whenever remote tracking data are available (Jonsen et al., 2005).
The rapid growth in computational resources has supported the develop-
ment of several approaches meant to tackle the issue of intractable likelihoods.
Some of these approaches exploit the fact that faster computation makes for-
ward model simulation, that is simulation of data y from p(y|θ), cheap enough
that it can be repeated many thousands of times. In particular, it is possible to
use forward simulations to ﬁnd the set of parameter values or models that are
able to closely reproduce the full data, yobs, or more often some of its most in-
formative features, sobs. ABC represents one class of such methods which, be-
ing based on a Bayesian framework, generally try to address questions regard-
ing parameter estimation or model selection by approximately sampling the
corresponding posteriors p(θ|sobs) and p(Mod|sobs). The rejection sampler de-
scribed in Algorithm 20.1 is probably the simplest exponent of the ABC family.

600
Handbook of Approximate Bayesian Computation
Algorithm 20.1: An ABC Rejection Sampler
The most basic instance of an ABC sampler, targeting an approximation to
p(θ|sobs), is the following rejection algorithm:
1. Sample M parameter vectors θ1, . . . , θM from the prior π(θ).
2. For each parameter vector θi, with i = 1, . . . , M, simulate a corresponding
datasets Y i from p(y|θi).
3. Transform the simulated datasets Y 1, . . . , Y M to vectors of summary
statistics S1 = S(Y 1), . . . , SM = S(Y M).
4. Calculate the distances di = d(sobs, Si), for i = 1, . . . , M, using an appro-
priate distance measure d(·, ·).
5. Store the N ≤M parameter vectors θi1, . . . , θiN , whose corresponding
distances di1, . . . , diN are all lower than a tolerance h > 0.
Notice that θi1, . . . , θiN are eﬀectively a sample from:
πABC(θ|sobs) ∝p{d(sobs, s) < h|θ}π(θ),
which should be a close approximation to π(θ|sobs), if h is suﬃciently small.
In the remainder of this chapter, we focus on a particular family of in-
tractable models: state space models. In Section 20.1.2, we brieﬂy describe
this class of partially observed models, which are very popular in the ecologi-
cal literature, and we introduce two approaches that can be used to perform
statistical inference for such models. In Section 20.1.3, we discuss how one of
these approaches, synthetic likelihood (SL), diﬀers from other ABC methods,
while in Section 20.2, we consider the predator-prey model of Turchin and
Ellner (2000) and compare the available methods using both simulated and
ﬁeld data. Finally, in Section 20.3, we conclude by making some practical con-
siderations regarding the beneﬁts and drawbacks of using ABC or SL, rather
than less approximate methods, when working with state space models.
20.1.2
Inference for state space models
State space models (SSMs) represent a special class of models with hidden or
partially observed states. In these models, the hidden states follow Markov
processes, whose conditional pdf has the following property:
p(nt|n1, . . . , nt−1, θ) = p(nt|nt−1, θ),
(20.2)
where t ∈{1, . . . , T} and θ is a vector of static parameters. Property (20.2)
implies that the future states are statistically independent of the past, upon
conditioning on the present. Generally, the hidden ecological processes are

ABC in Ecological Modelling
601
coupled with an observation process according to which observed data points
are conditionally independent, given the underlying states (King, 2014)
p(yt|nt, y1, . . . , yt−1, θ) = p(yt|nt, θ),
(20.3)
where we deﬁned yt = yobs,t, to simplify the notation. Typically, the term
SSMs is used to indicate partially observed Markov processes with continu-
ous state spaces, while models with discretely valued states are called hidden
Markov models (HMMs). In the following, we focus on SSMs, but most con-
siderations apply also to hidden Markov models.
As for most partially observed systems, the likelihood of SSMs is gener-
ally not available directly. Indeed, for such models p(y1:T |θ), where y1:T =
{y1, . . . , yT }, is available analytically only if both p(nt|nt−1, θ) and p(yt|nt, θ)
are linear and Gaussian (Kalman, 1960). Fortunately, the Markov property
(20.2) mitigates the intractability of these models, because it allows estima-
tion of the likelihood by performing the required T-dimensional integration
eﬃciently. In particular, the Markov property is exploited by particle ﬁlters
(Doucet and Johansen, 2009) to break down the integration problem into T
sequential integration steps. These computational tools can be used to obtain
Monte Carlo estimates ˆp(y1:T |θ) of the full-likelihood function. We describe
the Sequential Importance Re-Sampling (SIR) algorithm, which is the simplest
instance of a particle ﬁlter, in Algorithm 20.2.
A more general solution to the problem of intractable likelihoods is oﬀered
by SL (Wood, 2010). This is a simulation-based and approximate approach,
which is closely related to ABC methods. Rather than approximating the full
likelihood function, SL transforms the data to a set of summary statistics sobs
and approximates p(sobs|θ) parametrically. In particular, SL assumes that the
summary statistics are approximately normally distributed, conditionally on
the parameters:
S ∼N

μ(θ), Σ(θ)

,
(20.4)
where the functions μ(θ) and Σ(θ) are generally unknown. Given that the
parametric density assumption does not hold exactly in general, the resulting
synthetic likelihood, pSL(sobs|θ), should be considered an approximation to
p(sobs|θ). Point-wise estimates of the synthetic likelihood can be obtained by
using the procedure described in Algorithm 20.3.
There exists a strong relationship between SL and the simulation-based
approach of Diggle and Gratton (1984), who proposed to estimate the full
likelihood p(yobs|θ) pointwisely, by simulating data from the model and ap-
proximating its distribution using a non-parametric density estimator. Most
ABC algorithms follow a less likelihood-centric approach, because they gen-
erally aim at sampling from π(θ|sobs) directly. This is the case, for instance,
in ABC rejection, Markov chain Monte Carlo (MCMC) and sequential Monte
Carlo (SMC) algorithms (Beaumont, 2010). Section 20.1.3 discusses how SL
diﬀer from other ABC methods in more details.

602
Handbook of Approximate Bayesian Computation
Algorithm 20.2: Sequential Importance Re-Sampling (SIR)
This algorithm was proposed by Gordon et al. (1993) and has been hugely
successful in the context of SSMs. It implements a sequential importance
sampling procedure, with a re-sampling step that is used to discard particles
with low weights, thus mitigating the particle depletion problem (Doucet and
Johansen, 2009). An estimate of the likelihood at θ can be obtained using the
following steps:
1. Draw particles N i
0, for i = 1, . . . , M, from the prior distribution of the
initial state N i
0 ∼π(n0).
2. For t = 1 to T:
(a) Prediction step: propagate the particles forward in time:
N i
t ∼p(nt|ni
t−1, θ),
for
i = 1, . . . , M.
(b) Update step: calculate the normalised weight of each particle:
wi =
˜wi
N
i=1 ˜wi ,
˜wi = p(yt|ni
t, θ),
for
i = 1, . . . , M.
(c) Estimate the current component of the likelihood:
ˆp(yt|y1:t−1, θ) = 1
M
M

i=1
˜wi.
(d) Re-sample the particles multi-nomially with replacement, using prob-
abilities equal to the normalised weights.
3. Estimate the likelihood using the decomposition:
ˆp(y1:T |θ) = ˆp(y1|θ)
T

t=2
ˆp(yt|y1:t−1, θ).
The point estimates ˆp(yobs|θ) and ˆpSL(sobs|θ), obtained using, respectively,
SIR and SL, can be used within a Metropolis–Hastings (MH) algorithm.
Speciﬁcally, if SL is used, the MH acceptance probability is given by:
α = min

1, ˆpSL(sobs|θ∗)p(θ|θ∗)π(θ∗)
ˆpSL(sobs|θ)p(θ∗|θ)π(θ)
	
,
(20.5)

ABC in Ecological Modelling
603
Algorithm 20.3: Evaluating the Synthetic Likelihood
Point-wise estimates of the synthetic likelihood, at an arbitrary position θp in
the parameter space, can be obtained as follows:
1. Simulate M datasets Y 1, . . . , Y M from the model p(y|θp) and transform
them into d-dimensional summary statistic vectors S1 = S(Y 1), . . . , SM =
(Y M).
2. Estimate mean and covariance matrix of the summary statistics, using
standard estimators:
ˆμ(θp) = 1
M
M

i=1
Si,
ˆΣ(θp) =
1
M −1
M

i=1

Si −ˆμ(θp)

Si −ˆμ(θp)
T ,
or possibly more robust alternatives.
3. Evaluate the corresponding Gaussian density at the observed statistics,
that is:
ˆpSL(sobs|θp) = (2π)−d
2 |ˆΣ(θp)|−1
d
× exp

−1
2

sobs −ˆμ(θp)
T ˆΣ(θp)−1
sobs −ˆμ(θp)

.
where p(θ∗|θ) is the transition kernel and π(θ) is the prior density. When
ˆp(yobs|θ) is used in place of ˆpSL(sobs|θ) in (20.5), the resulting sampler is called
a particle marginal Metropolis–Hastings (PMMH) algorithm (Andrieu et al.,
2010). Under the assumptions detailed by Andrieu and Roberts (2009), this
sampler targets π(θ|yobs), thus representing an exact-approximate algorithm.
When SL is used, the situation is more complex because, unless the statistics
are normally distributed across the parameter space, the resulting synthetic
likelihood Metropolis-Hasting (SLMH) algorithm will target π(θ|sobs) only
approximately.
The main drawback of using SLMH or PMMH is their high computational
cost: the value of the (synthetic) likelihood function at the proposed param-
eters θ∗has to be estimated at each MH step, and this can be expensive for
complex models. For this reason, Wilkinson (2014) and Gutmann and Coran-
der (2015) avoid using SLMH, by explicitly approximating the synthetic like-
lihood function ˆp(sobs|θ) using Gaussian processes. Their approaches clearly
extend to situations where the likelihood is estimated using a particle ﬁlter.
An additional complication of MH algorithms using noisy likelihood estimates
is that they are often aﬀected by poor mixing, because the sampler tends to

604
Handbook of Approximate Bayesian Computation
get trapped when an unusually high estimate of the likelihood is reached (an
ad hoc solution is to simply re-estimate the value of the (synthetic) likelihood
at latest accepted position, θ, at every MH step). This problem is discussed
by Doucet et al. (2015) and Sherlock et al. (2014), who study how to tune
MH algorithms which make use of noisy and unbiased likelihood estimates.
Given the earlier issues, ABC methods might appear to be more eﬃcient
than SLMH or PMMH, because at each iteration they typically simulate only
a single summary statistics vector from p(s|θ). However, the accuracy and
the acceptance ratio of ABC samplers are, respectively, inversely and directly
proportional to the tolerance h. This trade-oﬀmakes it is diﬃcult to formulate
a clear statement about the computational eﬃciency of ABC methods, relative
to SLMH and PMMH.
While in Section 20.1.3, we discuss the merits and drawbacks of SL relative
to other ABC methods, we come back to SLMH and PMMH in Section 20.2,
where we use them to ﬁt the SSM of Turchin and Ellner (2000) to ecological
data.
20.1.3
SL versus tolerance-based ABC
The choice of summary statistics is crucial for the performance of ABC meth-
ods, hence, the topic has been the subject of much research. See Blum et al.
(2013) for a comprehensive review of methods for dimension reduction or
statistics selection. SL and ABC methods share some requirements regarding
the choice of summary statistics. More speciﬁcally, in parameter, estimation
problems, the summary statistics should contain as much information as possi-
ble about the parameters, so that π(θ|yobs) will be approximately proportional
to π(θ|sobs).
Beside this common ground, SL diﬀers from ABC methods in several ways,
and this entails some diverging requirements on the summary statistics. In
particular, reducing the number summary statistics is more critical to ABC
methods than to SL. In fact, the non-parametric approach followed by most
ABC methods, implies that the convergence rate of the resulting posterior
distributions slows down rapidly as the dimension of the statistics vector in-
creases (Blum, 2010). On the other hand, the parametric likelihood estimator
used by SL ensures that this method is much less sensitive to the number of
summary statistics used. This diﬀerence in scalability has important practical
implications. In particular, SL allows practitioners to focus on the challenging
task of identifying informative summary statistics, without having to worry
too much about keeping their number low. Obviously SL’s scalability in the
number of statistics does not come without a cost, but it has to be paid for
in parametric assumptions, whose eﬀect might be hard to quantify.
Another potential issue with ABC algorithms, such as the rejection sam-
pler in Algorithm 20.1, is that they often measure the distance between the
observed and simulated statistics using a squared Mahalanobis distance:

ABC in Ecological Modelling
605
d(sobs, S) = ||sobs, S||2
A = (sobs −S)T A(sobs −S),
where A is a scaling matrix. The choice of A is fundamental when the sum-
mary statistics have very diﬀerent scales or when there are subsets of highly
correlated statistics. A possible solution is to simulate N vectors of summary
statistic at some location θp in the parameters space and use the inverse of
the empirical covariance matrix of the simulated summary statistics as scaling
matrix A = ˆΣ(θp)−1. This simple choice works well in many cases, but it can
lead to unsatisfactory results when the covariance of the summary statistics
varies strongly with model parameters.
As an illustration of this problem, we consider a stochastic version of the
Ricker map:
Yt ∼Pois(φXt),
Nt = rNt−1e−Nt−1+Zt,
Zt ∼N(0, σ2),
where Nt is the population size at time t, r is the intrinsic growth rate of
the population, φ is a scaling parameter, and Zt can be interpreted as envi-
ronmental noise. In the following, we employ the set of 13 summary statistics
proposed by Wood (2010), who used them to ﬁt this model with SL.
In order to quantify the importance of the scaling matrix A in this setting,
we performed the following simulation experiment:
• Deﬁne a sequence of equally spaced values vk, for k = 1, 2, . . . , 50, ranging
from 2.8 to 3.8.
• For each value vk:
1. Simulate a path Y1:T from the Ricker map, using T = 50 and param-
eter values log r = 3.8, σ2 = 0.3, and φ = 10. Deﬁne sobs = S(Y1:T ).
2. Set the initial parameter vector θp to log r = vk, σ2 = 0.3, and φ = 10.
3. Simulate 104 paths from the model using parameters θp, transform
each of them into a vector summary statistics, and calculate their
empirical covariance ˆΣ(θp).
4. Sample πABC(θ|sobs) using the SMC-ABC routine proposed by Toni
et al. (2009), where ˆΣ(θp)−1 is used as scaling matrix. We refer the
reader to Toni et al. (2009) for details about this algorithm, but
point out that this is a sequential scheme where the tolerance h is
reduced at each step and that we terminated the algorithm when the
acceptance ratio of the most recent iteration was below 1%.
We repeated the whole experiment seven times, and the results are illustrated
in Figure 20.1. Here, the x-axis represents the value of log (r) at which the
scaling matrix was estimated, while the y-axis represents the lowest tolerance h
achieved before the termination of the SMC-ABC algorithm. This plot shows
how crucial is the choice of scaling matrix in situations where Σ(θ) varies
widely with θ: if the scaling matrix is not adequate, the tolerance cannot be
reduced enough. In an applied ecological setting, where the true parameters

606
Handbook of Approximate Bayesian Computation
2.8
3.0
3.2
3.4
3.6
3.8
0
20
40
60
80
Log(r)
Final tolerance h
FIGURE 20.1
Lowest achievable tolerance h versus value of log r at which the scaling matrix
is estimated. The grey line is a quadratic regression ﬁt.
are unknown and the model of interest is more complex than the one used
here, this means that a practitioner might struggle to ﬁnd either a reasonable
guess for the scaling matrix or a set of summary statistics whose covariance
is not strongly dependent on θ.
Another choice that has to be made, in order to use tolerance-based ABC
procedures, is the selection of h. The tolerance can be a small scalar constant,
as in the MCMC-ABC algorithm of Marjoram et al. (2003), or it can be a
vector of decreasing tolerances, as in the SMC-ABC algorithm of Toni et al.
(2009). In order to obtain a better approximation to π(θ|sobs), h should be
chosen to be as small as possible, but the acceptance probability will decrease
with the tolerance. A common choice is to select a tolerance that allows a pre-
determined acceptance ratio to be achieved, but in some cases this strategy
can lead to invalid results, as detailed in Silk et al. (2013).
The regression adjustment of Beaumont et al. (2002) can be used to miti-
gate the discrepancy between the observed and the simulated statistics, which
is proportional to the tolerance h. However, the result of this correction is
generally still dependent on h, which controls the bias-variance trade-oﬀof
the regression (Beaumont et al., 2002). Hence, using this procedure does not
necessarily lead to higher accuracy in parameter estimation. For example,
Fearnhead and Prangle (2012) obtained worse results with the regression cor-
rection than from the raw ABC output, using the Ricker model and the same
summary statistics considered here.
SL is not aﬄicted by the diﬃculties just described, because it is tolerance-
free, and the summary statistics are scaled automatically and dynamically
by the empirical covariance matrix ˆΣ(θ). Obviously, this robustness comes
at a cost: a single point-wise synthetic likelihood estimate requires a number

ABC in Ecological Modelling
607
of simulations suﬃcient to estimate the covariance matrix. In addition, even
though for many commonly used statistics the central limit theorem (CLT) as-
sures asymptotic normality, in small samples the normal approximation might
be crude, while in some contexts it might be diﬃcult to devise asymptotically
normal statistics.
As a simple example of the former problem, let us consider a sample of size
N from an exponential distribution with rate α. Here the maximum likelihood
(ML) estimator of α is given by the reciprocal of the sample average:
s = 1
¯x =
N
i=1 xi
N
−1
.
Given that s is a suﬃcient statistic for α, the likelihood function can be
factorised as follows:
p(x|α) = h(x)f(s, α) ∝f(s, α),
hence, the likelihood is proportional to a function of only s and α. By the
CLT, the distribution of s is asymptotically normal, but we want to verify how
well we can approximate the likelihood using SL when N = 10. Figure 20.2
shows the log-likelihood (dashed) and the estimated synthetic log-likelihood
(black) for α ∈[0.5, 2]. The true value of α is 1. With such a small sample
size, the distribution of the simulated statistic is far from normal, and in
fact, the synthetic log-likelihood is quite oﬀtarget. In cases such as this,
where the number of summary statistics is low, it is straightforward to use
α
Synth. log-likelihood
0.5
0.88
1.25
1.62
2
−1.34
−0.6
0.2
0.8
1.3
−14.4
−13.8
−13
−12.4
−11.8
Log-likelihood
FIGURE 20.2
Synthetic log-likelihood function (black line) versus true log-likelihood func-
tion (broken line) for a Exp(α = 1) distribution.

608
Handbook of Approximate Bayesian Computation
transformations to improve to normality assumption, as proposed by Wood
(2010). However, in an higher-dimensional setting, approximate multi-variate
normality might be diﬃcult to assess or improve. More importantly, achieving
multi-variate normality for a certain set of parameters does not assure that
this approximation will hold elsewhere in the parameter space.
20.2
Example: A Chaotic Prey–Predator Model
In order to illustrate the performance of SLMH and PMMH, we consider
a modiﬁed version of the prey–predator model proposed by Turchin and Ell-
ner (2000), which has been used to describe the dynamics of Fennoscandian
voles (Microtus and Clethrionomys). More speciﬁcally, the model was an at-
tempt at explaining the shift in voles abundance dynamics from low-amplitude
oscillations in central Europe and southern Fennoscandia to high-amplitude
ﬂuctuations in the north. One of the possible drivers of this shift is the ab-
sence of generalist predators in the north, where voles are hunted primarily
by weasels (Mustela nivalis) (Turchin and Ellner, 2000). According to this
hypothesis, the lack of the stabilising eﬀect of generalist predators is the main
factor determining the observed instability of vole abundances in the north.
The predator-prey dynamics are given by the following system of diﬀeren-
tial equations (Turchin and Ellner, 2000):
dN
dt = r(1 −e sin 2πt)N −r
K N 2 −
GN 2
N 2 + H2 −CNP
N + D + N
K
dw
dt ,
dP
dt = s(1 −e sin 2πt)P −sQP 2
N ,
(20.6)
where dw(t2) −dw(t1) ∼N[0, σ2(t2 −t1)], with t2 > t1, is a Brownian motion
process with constant volatility σ. The model is formulated in continuous time,
because voles do not reproduce in discrete generations (Turchin and Hanski,
1997). Here N and P indicate vole and weasel abundances, respectively. In
the absence of predators, voles abundance grows at a seasonal logistic rate.
Parameters r and s represents the intrinsic population growth rates of voles
and weasels, while K is the carrying capacity of the former. These param-
eters are averaged over the seasonal component, which is modelled through
a sine function with amplitude e and period equal to one year, with peak
growth achieved in the summer. Generalist predation is modelled through
a type III functional response, under which generalists progressively switch
from alternative prey to hunting voles, as vole density increases. The maximal
rate of mortality inﬂicted by generalists is G, while H is the half saturation
parameter.
Predation by weasels follows a type II response, where C is the maximal
predation rate of individual weasels and D is the half saturation prey density.

ABC in Ecological Modelling
609
No prey-switching behaviour occurs under this functional response, which is
consistent with weasels being specialist predators. Weasel abundance grows at
a seasonal logistic rate, where the carrying capacity depends on prey density.
Parameter Q speciﬁes the number of voles needed to support and replace an
individual weasel, and it determines the ratio of prey to predator densities at
equilibrium.
Diﬀerently from Turchin and Ellner (2000), who include environmental
stochasticity in the system by randomly perturbing all model parameters using
Gaussian noise with pre-speciﬁed volatility, we choose to explicitly perturb the
prey equation using a Brownian motion process and to include its volatility σ
in the vector of unknown parameters.
Vole abundance is not observed directly, but a proxy is provided by trap-
ping data. We assume that the number of trapped voles is Poisson distributed:
Yt ∼Pois(ΦNt),
where t ∈{1, . . . , T} is the set of discrete times when trapping took place.
No such proxy is available for weasels density, hence, predator abundance
represents a completely hidden state.
Following Turchin and Ellner (2000), model (20.6) is not ﬁtted directly to
data, but it is rescaled to a dimensionless form ﬁrst. In particular, if we deﬁne:
n = N
K ,
p = QP
K ,
d = D
K ,
a = C
K , g = G
K ,
h = H
K ,
and
φ = ΦK,
the reduced system is given by:
dn
dt = r(1 −e sin 2πt)n −rn2 −
gn2
n2 + h2 −anp
n + d + ndw
dt ,
dp
dt = s(1 −e sin 2πt)p −sp2
N ,
Yt ∼Pois(φnt).
(20.7)
While Turchin and Ellner (2000) implicitly re-scaled the simulations from the
model, in order to match their means with that of the observed data, we
formally estimate the scaling parameter φ.
Turchin and Ellner (2000) ﬁtted the model by using a method which they
call non-linear forecasting, which is an instance of simulated quasi-maximum
likelihood method (Smith, 1993). One of the drawbacks of their estimation pro-
cedure is that it does not take into account the fact that trapping data provides
noisy estimates of vole density. Another issue is that their method could not
be used to estimate parameters that aﬀect the variance of conditional distri-
butions p(nt|nt−1, nt−2, . . . ), but not their mean (Turchin and Ellner, 2000).

610
Handbook of Approximate Bayesian Computation
20.2.1
Description of data and priors
While Turchin and Ellner (2000) consider several datasets, here we focus on
the time series concerning vole abundance (mainly Clethrionomys rufocanus)
in Kilpisjarvi, Finland. The data, shown in Figure 20.3, consist of 90 data
points collected during the springs (mid-June) (triangles) and autumns
(September) (stars) of each year, between 1952 and 1997. Each data point
represents the number of voles trapped in a speciﬁc trapping season, divided
by the number of hundred trap-nights used in that season. After 1980, the
number of trap-nights was ﬁxed to around 1000, but in earlier years this num-
ber is not available: it varied from a minimum of 500 to more than 1000 (Perry,
2000). This correction for the sampling eﬀort implies that, if the number of
the trapped voles in each season is approximately Poisson distributed, the
trapping index is not.
We have dealt with this problem by multiplying the data in Figure 20.3
by 10 and by rounding each data point to the nearest integer. This solu-
tion should give near-exact results for data collected after 1980, and a good
Observed
Trapping index
SL
Trapping index
1960
1970
1980
1990
0
10
20
30
40
0
10
30
0
10
30
PMMH
Year
1960
1970
1980
1990
Year
1960
1970
1980
1990
Year
(a)
(b)
(c)
Trapping index
FIGURE 20.3
(a) Observed voles trapping index in Kilpisjarvi, between 1952 and 1997.
(b and c) Two realisations (solid and dashed) of model 20.6, using param-
eters equal to the posterior means given by SLMH and PMMH.

ABC in Ecological Modelling
611
TABLE 20.1
Priors Used for the Voles–Weasels Model
Parameter
Prior distribution
r
N(μ = 5, σ = 1)
e
N(μ = 1, σ = 1)
g
Exp(λ = 7)
h
Gamma(κ = 4, θ = 40)
a
N(μ = 15, σ = 15)
d
N(μ = 0.04, σ = 0.04)
s
N(μ = 1.25, σ = 0.5)
σ
Unif(0.5, ∞)
φ
Unif(0, ∞)
approximation for all data points representing a considerable population,
thanks to the normal approximation to the Poisson distribution.
A useful source of prior information is represented by Turchin and Han-
ski (1997), where life history and data from short experiments were used to
estimate the parameters of model (20.7). We report the prior distributions
for each parameter in Table 20.1. The expected values of the prior distribu-
tions have been chosen on the basis of the remarks of Turchin and Hanski
(1997), and we refer the reader to this reference for further details. The spe-
ciﬁc distributions and variabilities used for the priors have been chosen based
on an attempt at quantifying the remarks of Turchin and Hanski (1997) re-
garding their conﬁdence in their independently derived estimates. Admittedly,
this process entails a certain degree of arbitrariness. No prior information was
available for φ and σ, hence, we have used improper uniform priors for both
parameters.
For SL, we used the following set of 17 summary statistics:
• Autocovariances of n1, . . . , nT up to lag 5.
• Mean population ¯n.
• Diﬀerence between mean and median population ¯n −˜n.
• Coeﬃcients β1, . . . , β5 of the regression nt+1 = β1nt + β2n2
t + β3nt−6 +
β4n2
t−6 + β5n3
t−6 + zt.
• Coeﬃcients of a cubic regression of the ordered diﬀerences nt −nt−1 on
their observed values.
• Number of turning points, #n.
This choice of statistics deserves some comments. Notice that, under suitable
assumptions, all the earlier statistics are asymptotically normal as T →∞,
due to the CLT. This provides some asymptotic justiﬁcation to the Gaussian
approximation used by SL. The autocovariances and the coeﬃcient of the

612
Handbook of Approximate Bayesian Computation
polynomial autoregressive model were meant to capture the dynamics of prey
abundance on a short (β1,2) and long (β3,4,5) term basis. The degrees of
the polynomials were choosed visually, by plotting nt against nt−1 and nt−6.
Intermediate lags, such as nt−3, were excluded, because they would have led
to very strong correlations between the regression coeﬃcients. The marginal
distribution of nt is summarised by ¯n and ¯n−˜n, while the cubic regression co-
eﬃcients aim at capturing the marginal structure of nt −nt−1. The number of
turning points was introduced with the intention of capturing the volatility σ2.
This is because increasing σ2 generally leads #n closer to 1/2, which is typical
of random walk behaviour.
20.2.2
Comparison using simulated data
In order to verify the accuracy of SLMH and PMMH for this prey–predator
model, we have simulated 24 datasets of length T = 90, using parameters
values r = 4.5, e = 0.8, g = 0.2, h = 0.15, a = 8, d = 0.06, s = 1, σ = 1.5,
and φ = 100. We have then estimated the parameters with both methods,
using 2.5 × 104 MCMC iteration, the ﬁrst 5 × 103 of which was discarded as
burn-in period, and 103 simulation from the model at each step. All the chains
were initialised at the same parameter values. The resulting root mean squared
errors (RMSEs) and variance-to-squared-bias ratios are reported in Table 20.2.
While the RMSEs are quite similar for most parameters, the Table suggests
that PMMH gives more accurate estimates for the scaling parameter φ and
possibly for the generalist predation rate g. Indeed, SLMH estimates of φ are
biased downward and are around ten times more variable than the estimates
obtained with PMMH. In the case of g, the signiﬁcance of the t-test should not
be over-interpreted, given that it is attributable to PMMH achieving almost
zero error on a single run.
TABLE 20.2
RMSEs and Variance-to-Squared-Bias Ratios (in Parentheses) for SLMH
and PMMH. P-values for Diﬀerences in Log-Squared Errors Have Been
Calculated Using t-Tests
Parameter
RMSE SLMH
RMSE PMMH
P-Value
Best
r
0.33(3.3)
0.25(9.9)
0.49
PMMH
e
0.19(0.1)
0.2(0.1)
0.78
SLMH
g
0.09(0.2)
0.08(0.5)
0.05
PMMH
h
0.04(0.2)
0.03(0.4)
0.15
PMMH
a
2.12(1.3)
1.97(1)
0.48
PMMH
d
0.02(0.5)
0.02(0.6)
0.57
SLMH
s
0.07(18.6)
0.08(10.9)
0.22
SLMH
σ
1.97(2.5)
0.71(2.1)
0.36
PMMH
φ
16.04(3.9)
4.85(7.4)
< 0.001
PMMH

ABC in Ecological Modelling
613
From a computational point of view, the two algorithms performed sim-
ilarly. In particular, on a single 2.50 GHz Intel i7-4710MQ CPU, point-wise
estimates of p(yobs|θ) or pSL(yobs|θ) cost around 1.55 and 1.35 seconds, when
103 particles or simulated statistics are used. This time diﬀerence is marginal,
and probably highly dependent on implementation details. However, it is
worth pointing out that it is much easier to parallelise the computation of
ˆpSL(sobs|θ) than that of ˆp(yobs|θ). This is because of SIR’s re-sampling step,
which breaks the parallelisms at each time-step t (see Algorithm 20.1). For
a review of parallelisation strategies for the re-sampling step, see Li et al.
(2015). A possibly simpler solution is to compute several estimates ˆp1(yobs|θ),
. . . , ˆpC(yobs|θ) in parallel, by running SIR with a fraction of the total num-
ber of particles M on each of the C cores, and then averaging them at each
PMMH step to obtain a single estimate of p(yobs|θ).
20.2.3
Results from the Kilpisjarvi dataset
We ﬁtted the Kilpisjarvi dataset using 1.5 × 105 MCMC iteration, of which
the ﬁrst 104 were discarded as burn-in period. At each step, we used 103 simu-
lations from the model (SLMH) or particles (PMMH). The resulting posterior
means are reported in Table 20.3, while the marginal posterior densities of the
parameters as shown in Figure 20.4.
SLMH and PMMH give similar estimates for most parameters, with sub-
stantial diﬀerences only for σ and φ. Indeed, PMMH’s estimate of the former
parameter is much higher than that obtained using SL. Interestingly, Fasiolo
et al. (2014) encountered a similar pattern when ﬁtting the blowﬂy model of
Wood (2010) to Nicholson’s experimental datasets (Nicholson, 1954, 1957). In
that context, the process noise estimates were much higher under PMMH than
under SL, on all datasets. This biased PMMH’s estimates of the remaining
parameters towards stability, particularly on two of the datasets. As we will
show later in this section, this stabilising eﬀect of high process noise estimates
on the dynamics is less noticeable here.
Figure 20.3 compares the observed data with trajectories simulated from
model (20.6), using parameters equal to the posterior means given by SLMH
TABLE 20.3
Estimated Posterior Means (Standard Deviations) for Model 20.6
r
e
g
h
a
SLMH
4.85(0.63)
0.78(0.12)
0.11(0.11)
0.1(0.05)
8.0(3.3)
PMMH
5.11(0.7)
0.84(0.14)
0.14(0.11)
0.1(0.05)
6.3(2.1)
d
s
σ
φ
SLMH
0.07(0.03)
1.04(0.21)
8.4(2.3)
270.5(63.5)
PMMH
0.08(0.03)
1.04(0.23)
14.8(1.7)
184.2(26.9)

614
Handbook of Approximate Bayesian Computation
r
Density
e
Density
g
Density
h
Density
a
d
Density
s
Density
σ
3
4
5
6
7
8
0.0
0.2
0.4
0.6
0.4 0.6 0.8 1.0 1.2
0.0
1.0
2.0
3.0
Density
0.00
0.10
0.20
Density
0.00
0.10
0.20
0.0 0.2 0.4 0.6 0.8 1.0
0 1 2 3 4 5 6 7
0.0 0.1 0.2 0.3 0.4 0.5
0
2
4
6
8 10
0
5
10
20
30
0.00 0.05 0.10 0.15 0.20
0
5
10
15
0.5
1.0
1.5
2.0
2.5
0.0 0.5 1.0 1.5 2.0
5
10 15 20 25
100
300
500
700
0.000 0.005 0.010 0.015
ϕ 
Density
FIGURE 20.4
Marginal posterior densities for voles model using SLMH (black) and PMMH
(broken). The vertical lines correspond to estimates reported by Turchin and
Ellner (2000), obtained using NLF (available only for ﬁve parameters).
and PMMH. Both methods seem to produce dynamics that are qualita-
tively similar to the observed ones, with the paths simulated using PMMH’s
estimates being slightly more irregular, which is attributable to the higher
process noise estimate.
Besides comparing observed and simulated trajectories, in the context of
SL, it is also advisable to check whether the summary statistics are indeed
approximately normally distributed. In particular, it is important to verify
whether this assumption holds within the highest posterior density region. For
this reason, we simulated M = 104 summary statistics, S1:M = {S1, . . . , SM},
from the model, using parameters equal to the estimated posterior mean. Then
we used the methods of Krzanowski (1988) to produce the normality plots
shown in Figure 20.5. In particular, we transformed S1:M to a variable that
should be χ2(17), under normality of S. Figure 20.5a compares observed and
theoretical log quantiles. Departures on the right end of the plot indicate that

ABC in Ecological Modelling
615
Log χ2(17) Quantiles
Log observed quantiles
(a)
(b)
(c)
N(0,1) Quantiles
Marginal quantiles
1.0
2.0
3.0
1
2
3
4
5
−4
−2
0
2
4
−6 −4 −2
0
2
4
6
−2
−1
0
1
2
−2.5
−1.5
−0.5
0.5
N(0,1) Quantiles
Observed (sobs) quantiles
FIGURE 20.5
Normality plots for the simulated summary statistics. See main text for details.
the normal approximation is poor in the tails. In this case this is not much of a
problem, as the dashed line, which indicates the Mahalonobis distance between
sobs and the sample mean of S1:M, falls within the region where the normal
approximation is adequate. Figure 20.5b shows marginal normal q-q plots for
the simulated statistics. Marginal normality seems to hold reasonably well
for most statistics, with the exception of β5, whose distribution is skewed to
the left. An analogous qq-plot for normalised observed statistics sobs is shown
in Figure 20.5c. This plot is suggestive of departures from normality, but this
approach does not have much power, unless the dimension of sobs is fairly large.
One of the main scientiﬁc questions model (20.6) was meant to address was
whether the observed dynamic in vole densities can be classiﬁed as chaotic.
To answer this question, we have randomly sampled 103 parameter sets from
posterior samples obtained by SLMH and PMMH. We have then used each pa-
rameter set to simulate a trajectory from the deterministic skeleton of model
(20.6) for 105 months, which were discarded in order to let the system leave the
transient, and used additional 104 months of simulation to estimate the max-
imal Lyapunov exponent as in Wolf et al. (1985). By doing this, we obtained
the two approximate posterior densities of the Lyapunov exponent shown in
Figure 20.6. Notice that the posterior produced by PMMH is slightly more
skewed to the left relatively to that obtained with SL, which suggests that the
system dynamics are estimated to be more stable under the former methods.
Together with the high estimate of σ2, this conﬁrms the tendency of PMMH to
inﬂate the noise and to bias the estimated dynamics towards stability. While
this eﬀect was very pronounced under the blowﬂy model studied by Fasiolo
et al. (2014), in this case it is very mild. Indeed, the median Lyapunov expo-
nent is equal to −6×10−4 for SLMH and −0.015 for PMMH. These estimates
are very close to each other and to the one (−0.02) reported by Turchin and
Ellner (2000) for this dataset and provide more model-based evidence sup-
porting the hypothesis that this system lives on the edge of chaos.

616
Handbook of Approximate Bayesian Computation
−0.8
−0.6
−0.4
−0.2
0.0
0.2
0
2
4
6
8
10
12
Lyapunov exponent
Posterior density
FIGURE 20.6
Approximate posterior densities of Lyapunov exponents for SLMH (black) and
PMMH (broken).
20.3
Discussion
The example presented in this work gives the ﬂavour of what can be accom-
plished using SL or particle ﬁlters, in the context of ecological SSMs. Both
approaches provided a sample from the parameters’ posterior distribution,
which is the result of a full Bayesian analysis that incorporates both prior and
likelihood-based information. While Table 20.2 suggests that SL might have
lost information regarding some of the parameters, in Section 20.2.3, we point
out that the estimates provided by PMMH might be slightly biased towards
stability. In essence, PMMH estimates the process noise σ2 to be quite high,
which leads PMMH to explain the observed dynamics using noise, rather than
by moving the system away from stability, using other dynamically important
parameters. When dealing with highly non-linear models, it is worth being
aware of this tendency, because it can lead to system dynamics being classi-
ﬁed as stable even when they are not, as shown by Fasiolo et al. (2014), using
the blowﬂy model of Wood (2010). Fortunately, SLMH and PMMH strongly
agree in classifying the dynamics of the prey–predator system considered in
this work as near-chaotic, hence, either approach could have been used to
answer the main scientiﬁc question underlying model (20.6).
From the point of view of applied ecologists, ease of use and automa-
tion are arguably as important as statistical and computational eﬃciency.

ABC in Ecological Modelling
617
In Section 20.2, we have shown that the choice of scaling matrix can be very
important for ABC methods. Selecting this parameter correctly can be par-
ticularly diﬃcult when little or no prior knowledge about model parameters is
available. From this point of view, SL is at an advantage with respect to other
ABC methods because, once the summary statistics have been selected, there
is very little tuning to do. Obviously, SL pays for this tuning-free property
with a normality assumption, which might result in lower accuracy.
The summary statistics selection process, which SL cannot escape, can
be the most time consuming and arbitrary step of the inferential process.
In the example presented in Section 20.2, we obtained good results, in terms
of parameter accuracy, by using the statistics of Wood (2010) with some
modiﬁcations. In our experience, this is the exception, rather than the rule. In
fact, even though Blum et al. (2013) oﬀer several systematic approaches for
statistics selection, studying the model output by visualising characteristics
such as empirical transition densities, periodicity, and dependencies between
states is still indispensable for most models of reasonable complexity.
ABC methods have become popular tools for dealing with complex phy-
logeographic (Hickerson et al., 2010), phylogenetic (Rabosky, 2009), and in-
dividual based (Hartig et al., 2014) models, but they do not seem to have
been equally successful for dynamical SSMs of ecological interest. The main
reasons for this might be that particle ﬁlters represent an obvious alternative,
and that at the moment it is not clear whether ABC methods can outperform
them along any dimension of the inferential process. In fact, particle ﬁlters
have the important advantage of using the full data, yobs, thus, avoiding both
the information loss and the issue of choosing the summary statistics. On the
other hand, this use of all the data makes ﬁltering more susceptible to model
mis-speciﬁcation problems, in which failure, to capture the data generating
mechanism exactly can have a substantial negative impact on inference.
The robustness properties of methods based on summary or ‘intermediate’
statistics, in particularly the protection they can oﬀer against model
misspeciﬁcation and outliers, has been widely recognised and exploited in
econometrics, but it seems to have attracted less attention in the wider statis-
tical community (Jiang and Turnbull, 2004). Hence, it would be interesting to
verify whether ABC methods share any of the robustness properties of more
traditional statistics-based approaches. If this turns out to be the case, one
possibility is that ABC methods will be used in support of more accurate,
but possibly less robust, methods based on the full likelihood, such as particle
ﬁlters. This was suggested by Fasiolo et al. (2014), in the context of highly
non-linear ecological and epidemiological models, and by Owen et al. (2014),
who propose a hybrid procedure where an ABC sampler is used in support of
a PMMH algorithm. While both works have suggested that ABC methods are
more robust than particle ﬁlters to bad initialisations, the ﬁrst one has also
found that they are less aﬀected by outliers and that they can provide reliable
parameter estimates when dealing with highly non-linear models characterized
by extremely multi-modal full likelihoods.

618
Handbook of Approximate Bayesian Computation
Although the use of summary statistics wastes information and requires
an often time-consuming statistics selection process, ABC methods have some
features that are very appealing from a practical perspective. In fact, they
are purely simulation-based or ‘plug-and-play’ (Bhadra et al., 2011), because
they only require simulation of data from the model and transformation to
summary statistics. This property makes these methods general-purpose, be-
cause they can be used to ﬁt any model for which a simulator is available,
with little or no assumptions required. Hence, ABC methods can potentially
accelerate the model development process: once the summary statistics have
been chosen, testing new model versions requires only updating the simulator.
In addition, this generality allows practitioners to explore models that violate
the assumptions necessary for particle ﬁlters to work, such as Markovian dy-
namics or the tractability of the observational density p(yt|xt).
Similar practical considerations hold also in regard to the programming
eﬀort necessary to implement each method. For models of moderate complex-
ity, no ABC or particle ﬁltering method can be entirely implemented in a
traditional interpreted language (such as R). In fact, any of these methods re-
quires at least part of the code to be written in a compiled language (such as
C/C++). In the case of ABC methods, this is often simple to do, because the
largest share of the computational time is spent simulating data and trans-
forming it to summary statistics, so it is often suﬃcient to write only these
steps in a compiled language. On the other hand, particle ﬁlters generally do
not simulate whole datasets, but work in sequential steps, so it is diﬃcult to
isolate the parts of these algorithms that have to be implemented eﬃciently.
This means that it might be necessary to write these procedures entirely in a
compiled language, which slows down the model development and evaluation
process.
For these reasons, software tools providing frameworks and algorithms for
doing inference for SSMs are very useful to statistical ecologists. One such
example is the pomp R package (King et al., 2014), which we used to set up
the model described in Section 20.2. This package focuses mainly on tools
based on particle ﬁltering, but it oﬀers also several approximate approaches,
and it can greatly reduce the programming eﬀort, if the model of interest ﬁts
the framework provided by the package. While statistical suites are available
for tolerance-based ABC methods and for SL, such as the EasyABC (Jabot
et al., 2014) and the synlik (Fasiolo and Wood, 2014) R packages, these do
not focus on SSMs in particular, thus, reﬂecting the wide range of application
of the underlying statistical methodologies.
In conclusion, ABC methods oﬀer an approach to intractable ecological
models that forgo information in exchange for generality and, possibly, ro-
bustness. While this trade-oﬀhas shown to be fruitful in many branches of
ecological modelling (Hartig et al., 2011), particularly when the model is not
intended to reproduce the data exactly, future work will determine whether
ABC methods will play a major role in the context of SSMs, possibly alongside
less approximate approaches.

ABC in Ecological Modelling
619
Acknowledgements
This work was performed under partial support of the EPSRC grant
EP/I000917/1 and EP/K005251/1.
References
Andrieu, C., A. Doucet, and R. Holenstein (2010). Particle Markov chain
Monte Carlo methods. Journal of the Royal Statistical Society: Series B
(Statistical Methodology) 72(3), 269–342.
Andrieu, C. and G. O. Roberts (2009). The pseudo-marginal approach for ef-
ﬁcient Monte Carlo computations. The Annals of Statistics 37(2), 697–725.
Andrieu, C. and J. Thoms (2008). A tutorial on adaptive MCMC. Statistics
and Computing 18(4), 343–373.
Beaumont, M. A. (2010). Approximate Bayesian computation in evolution and
ecology. Annual Review of Ecology, Evolution, and Systematics 41, 379–406.
Beaumont, M. A., W. Zhang, and D. J. Balding (2002). Approximate Bayesian
computation in population genetics. Genetics 162(4), 2025–2035.
Bhadra, A., E. L. Ionides, K. Laneri, M. Pascual, M. Bouma, and
R. C. Dhiman (2011). Malaria in northwest india: Data analysis via par-
tially observed stochastic diﬀerential equation models driven by l´evy noise.
Journal of the American Statistical Association 106(494), 440–451.
Blum, M. G. B. (2010). Approximate Bayesian computation: A nonparamet-
ric perspective. Journal of the American Statistical Association 105(491),
1178–1187.
Blum, M. G. B., M. A. Nunes, D. Prangle, and S. A. Sisson (2013). A com-
parative review of dimension reduction methods in approximate Bayesian
computation. Statistical Science 28(2), 189–208.
Diggle, P. J. and R. J. Gratton (1984). Monte Carlo methods of inference for
implicit statistical models. Journal of the Royal Statistical Society. Series
B (Statistical Methodology) 46, 193–227.
Doucet, A. and A. M. Johansen (2009). A tutorial on particle ﬁltering
and smoothing: Fifteen years later. Handbook of Nonlinear Filtering 12,
656–704.
Doucet, A., M. Pitt, G. Deligiannidis, and R. Kohn (2015). Eﬃcient imple-
mentation of Markov chain Monte Carlo when using an unbiased likelihood
estimator. Biometrika 102, 295–313.

620
Handbook of Approximate Bayesian Computation
Farnsworth, K. D., U. H. Thygesen, S. Ditlevsen, and N. J. King (2007). How
to estimate scavenger ﬁsh abundance using baited camera data. Marine
Ecology Progress Series 350, 223.
Fasiolo, M., N. Pya, and S. N. Wood (2014). Statistical inference for highly
non-linear dynamical models in ecology and epidemiology. arXiv preprint
arXiv:1411.4564.
Fasiolo, M. and S. N. Wood (2014). An Introduction to Synlik (2014). R Pack-
age Version 0.1.1.
Fearnhead, P. and D. Prangle (2012). Constructing summary statistics for
approximate Bayesian computation: Semi-automatic approximate Bayesian
computation. Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 74(3), 419–474.
Gordon, N. J., D. J. Salmond, and A. F. M. Smith (1993). Novel approach
to nonlinear/non-Gaussian Bayesian state estimation. IEE Proceedings F
(Radar and Signal Processing) 140, 107–113.
Gutmann, M. U. and J. Corander (2015). Bayesian optimization for
likelihood-free
inference
of
simulator-based
statistical
models.
arXiv
preprint arXiv:1501.03291.
Hartig, F., J. M. Calabrese, B. Reineking, T. Wiegand, and A. Huth (2011).
Statistical inference for stochastic simulation models – theory and applica-
tion. Ecology Letters 14(8), 816–827.
Hartig, F., C. Dislich, T. Wiegand, and A. Huth (2014). Technical note:
Approximate Bayesian parameterization of a process-based tropical forest
model. Biogeosciences 11, 1261–1272.
Hickerson, M. J., B. C. Carstens, J. Cavender-Bares, K. A. Crandall, C. H.
Graham, J. B. Johnson, L. Rissler, P. F. Victoriano, and A. D. Yoder (2010).
Phylogeography’s past, present, and future: 10 years after. Molecular Phy-
logenetics and Evolution 54(1), 291–301.
Jabot, F., T. Faure, and N. Dumoullin (2014). EasyABC: Performing Eﬃcient
Approximate Bayesian Computation Sampling Schemes. R package version
1.3.1.
Jiang, W. and B. Turnbull (2004). The indirect method: Inference based on
intermediate statistics – a synthesis and examples. Statistical Science 19(2),
239–263.
Jonsen, I. D., J. M. Flemming, and R. A. Myers (2005). Robust state-space
modeling of animal movement data. Ecology 86(11), 2874–2880.
Kalman, R. E. (1960). A new approach to linear ﬁltering and prediction prob-
lems. Journal of basic Engineering 82(1), 35–45.

ABC in Ecological Modelling
621
Kendall, B. E., S. P. Ellner, E. McCauley, S. N. Wood, C. J. Briggs, W. W.
Murdoch, and P. Turchin (2005). Population cycles in the pine looper moth:
Dynamical tests of mechanistic hypotheses. Ecological Monographs 75(2),
259–276.
King, A. A., E. L. Ionides, C. M. Bret´o, S. P. Ellner, M. J. Ferrari, B. E.
Kendall, M. Lavine et al. (2014). pomp: Statistical Inference for Partially
Observed Markov Processes (R Package).
King, R. (2014). Statistical ecology. Annual Review of Statistics and Its Ap-
plication 1(1), 401–426.
Krzanowski, W. (1988). Principles of Multivariate Analysis. New York: Oxford
University Press.
Langrock, R., R. King, J. Matthiopoulos, L. Thomas, D. Fortin, and J. M.
Morales (2012). Flexible and practical modeling of animal telemetry data:
Hidden Markov models and extensions. Ecology 93(11), 2336–2342.
Li, T., M. Bolic, and P. M. Djuric (2015). Resampling methods for particle
ﬁltering: Classiﬁcation, implementation, and strategies. Signal Processing
Magazine, IEEE 32(3), 70–86.
Marjoram, P., J. Molitor, V. Plagnol, and S. Tavar´e (2003). Markov chain
Monte Carlo without likelihoods. Proceedings of the National Academy of
Sciences 100(26), 15324–15328.
May, R. M. (1976). Simple mathematical models with very complicated dy-
namics. Nature 261(5560), 459–467.
Morales, J. M., D. T. Haydon, J. Frair, K. E. Holsinger, and J. M. Fryxell
(2004). Extracting more out of relocation data: Building movement models
as mixtures of random walks. Ecology 85(9), 2436–2445.
Nicholson, A. J. (1954). An outline of the dynamics of animal populations.
Australian Journal of Zoology 2(1), 9–65.
Nicholson, A. J. (1957). The self-adjustment of populations to change. In Cold
Spring Harbor Symposia on Quantitative Biology, Volume 22, pp. 153–173.
Cold Spring Harbor, NY: Cold Spring Harbor Laboratory Press.
Owen, J., D. J. Wilkinson, and C. S. Gillespie (2014). Scalable infer-
ence for Markov processes with intractable likelihoods. arXiv preprint
arXiv:1403.6886.
Perry, J. N. (2000). Chaos in Real Data: The Analysis of Non-linear Dynamics
from Short Ecological Time Series, Volume 27. Dordrecht, the Netherlands:
Springer.

622
Handbook of Approximate Bayesian Computation
Rabosky, D. L. (2009). Heritability of extinction rates links diversiﬁcation
patterns in molecular phylogenies and fossils. Systematic Biology 58(6),
629–640.
Sherlock, C., A. H. Thiery, G. O. Roberts, J. S. Rosenthal (2014). On the eﬃ-
ciency of pseudo-marginal random walk metropolis algorithms. The Annals
of Statistics 43(1), 238–275.
Silk, D., S. Filippi, and M. P. H. Stumpf (2013). Optimizing threshold-
schedules for sequential approximate Bayesian computation: Applications
to molecular systems. Statistical Applications in Genetics and Molecular
Biology 12(5), 603–618.
Smith, A. A. (1993). Estimating nonlinear time-series models using simulated
vector autoregressions. Journal of Applied Econometrics 8(S1), S63–S84.
Toni, T., D. Welch, N. Strelkowa, A. Ipsen, and M. P. Stumpf (2009). Approx-
imate Bayesian computation scheme for parameter inference and model se-
lection in dynamical systems. Journal of the Royal Society Interface 6(31),
187–202.
Turchin, P. and S. P. Ellner (2000). Living on the edge of chaos: Population
dynamics of fennoscandian voles. Ecology 81(11), 3099–3116.
Turchin, P. and I. Hanski (1997). An empirically based model for latitudinal
gradient in vole population dynamics. The American Naturalist 149(5),
842–874.
Wilkinson, R. D. (2014). Accelerating ABC methods using Gaussian processes.
arXiv preprint arXiv:1401.1436.
Wolf, A., J. B. Swift, H. L. Swinney, and J. A. Vastano (1985). Determining
Lyapunov exponents from a time series. Physica D: Nonlinear Phenom-
ena 16(3), 285–317.
Wood, S. N. (2010). Statistical inference for noisy nonlinear ecological dynamic
systems. Nature 466(7310), 1102–1104.

21
ABC in Nuclear Imaging
Y. Fan, Steven R. Meikle, Georgios I. Angelis, and Arkadiusz Sitek
CONTENTS
21.1
Introduction to Nuclear Imaging
................................
623
21.2
Compartmental Models in PET .................................
627
21.3
Parameter Estimation in Compartmental Models
..............
629
21.4
A Simple ABC Algorithm for Kinetic Models ...................
631
21.5
Application to a Neurotransmitter Response Model ............
632
21.5.1
Prior and sampling distributions ........................
634
21.5.2
Summary statistics selection ............................
636
21.5.3
Tolerance level determination ...........................
638
21.5.4
Comparisons of diﬀerent estimation methods ...........
638
21.6
Conclusions and Discussions .....................................
643
References
...............................................................
644
21.1
Introduction to Nuclear Imaging
Nuclear imaging technologies produce non-invasive measures of a broad range
of physiological functions, using externally detected electromagnetic radiation
originating from radiopharmaceuticals administered to the subject. The main
nuclear imaging modalities PET (positron emission tomography) and SPECT
(single photon emission computed tomography) are the backbones of the ﬁeld
of molecular imaging, where they are used extensively in both clinical settings
and pre-clinical research with animals to study disease mechanisms and test ef-
fectiveness of new therapies. Typical applications include glucose metabolism
studies for cancer detection and evaluation and cardiac imaging, imaging of
blood ﬂow and volume, and it is one of the few methods available to neurosci-
entists to non-invasively study biochemical processes within the living brain,
such as receptor binding, drug occupancy, or neurotransmitter release.
623

624
Handbook of Approximate Bayesian Computation
In nuclear imaging, a subject is administered with a small amount of
radiopharmaceutical called a tracer. Radiation is created when the nuclei of
the tracer decay and produce photons in the range 35–511 keV that are then
detected by radiation sensitive detectors external to the subject. The energy
of the photons must be high enough to allow the photon to leave the subject’s
body, but low enough to allow absorption in the detector. Photons can be
produced either as a direct product of the nuclear reaction that occurred or
indirectly. For example, SPECT is based on single photon detection produced
by the decay of the radioisotopes. A gamma camera (Anger, 1964) is rotated
around the subject and acquires photon counts at diﬀerent projection angles,
typically a full 180 degree set of projections are needed. Figure 21.1 shows two
of the positions during data acquisition. On the contrary, PET is based on in-
direct photon detection produced by positron annihilation, where a radioactive
decay produces a positron which annihilates with an electron and produces a
pair of photons travelling in opposite directions along a straight line path. The
photons are detected by a large number of detectors surrounding the subject,
forming a ring. The PET detector ring is stationary, see Figure 21.2. Basic
physical principles underlying PET and SPECT imaging and instrumentation
for data acquisition can be found in the reviews of Cherry and Dahlbom (2004)
and Wernick and Aarsvold (2004).
The goal of imaging is to study the concentrations of radioactive nu-
clei that are in the imaged object, assuming that they are attached to the
Object
2
1
Rotation
90°
FIGURE 21.1
Data acquisition in SPECT using a dual head scanner. Each of two heads is
an independent gamma camera (Anger, 1964). With this acquisition setup,
the system needs only 90 degree rotation to acquire counts from all directions
in a 2D plane around the object. There are many intermediate steps (in the
order of 64) between conﬁguration on the left and right at which the data
are acquired. Dotted lines illustrate hypothetical paths of gamma photons
which can be absorbed by the object (attenuated) (#2) or scattered and
then detected (#1). These are two examples of many possible interactions.
(Reproduced from Sitek, A., Statistical Computing in Nuclear Imaging, CRC
Press, Boca Raton, FL, 2014. With permission.)

ABC in Nuclear Imaging
625
Gap between blocks
PMT B
PMT A
Block of scintillator crystals
FIGURE 21.2
PET camera comprising 24 PET block detectors. Photomultiplier tubes
(PMTs) are attached to scintillation crystals for signal ampliﬁcation and in-
teraction localisation. Two of the four PMTs per detector block needed to
localise a gamma ray interaction are shown as PMT A and PMT B. (Repro-
duced from Sitek, A., Statistical Computing in Nuclear Imaging, CRC Press,
Boca Raton, FL, 2014. With permission.)
tracer molecules. The description is simpliﬁed by subdividing the imaged vol-
ume into non-overlapping equal sized volume elements called voxels, and only
the numbers of nuclei inside each voxel are considered. In a typical setup of the
inverse problem, the quantity of interest is the expected number of decays per
voxel, which leads to the data being modelled as Poisson distribution. Nuclear
imaging can be extended to so called dynamic imaging, where changes in dis-
tribution of the tracer are investigated over time. This is done by dividing the
time in which the changes are observed (typically in the order of 30 minutes
to an hour) into time frames (about 20 to 60) and reconstruct voxelised time
frames independently. The reconstructed time frames are then analysed by
algorithms, such as the one presented in this chapter.
The voxelised image data are reconstructed from acquired data (counts)
by any one of a number of reconstruction algorithms, see for example Qi
and Leahy (2006). This is called the tomographic reconstruction. The primary
factors limiting reconstructed image quality are detector resolution, which de-
termines the maximum resolution of the reconstructed images; and the total
number of detected counts, which determines the minimum noise level that
can be achieved at the maximum resolution. In the following discussion, we
restrict our attention to model-based reconstruction algorithms, which are

626
Handbook of Approximate Bayesian Computation
of more interest to the statistical community. In model-based reconstruction
approaches, a probabilistic model is used to account for the physical and ge-
ometric factors that aﬀect photon detection. In its simplest form, the image
reconstruction can be seen as a problem of parameter estimation, where the
acquired data (counts) are Poisson random variables with mean equal to a
linear transformation of the parameters. Let y be the measured projection
data and x be the unknown image; x is related to y via:
E(y) = Px.
The projection matrix P models the probability of an emission from each voxel
element in the source image being detected at each detector element. In simple
terms, x is the reconstructed image, where each element of the matrix x cor-
responds to a voxel element in the image. y is the measured count, assumed
to have Poisson distribution. To give an idea of the scale of the problem,
a single 3-dimensional scan could produce 107 −108 counts, with 106 image
parameters to be estimated. Many methods have been proposed for solving
the inverse problem, starting with the expectation maximisation (EM) algo-
rithm of Shepp and Vardi (1982), to the ordered subsets algorithm of Hudson
and Larkin (1994), to many more sophisticated algorithms which deal with
the problem of ill-conditioning often arising in PET applications (where the
solutions to the inverse problem are sensitive to small changes in the data).
Fessler (1996), Leahy and Qi (2000), and Qi and Leahy (2006) provide detailed
reviews on the statistical challenges in model-based reconstruction methods.
Sitek (2014) discusses in depth the statistics of detected counts.
The 3-dimensional images of the radiotracer distributions, when monitored
over time, provide insights into the physiological state of the organism in vivo.
This dynamic imaging, often referred to as functional imaging, focuses on how
tracers accumulate and clear from the tissue, enabling the physiological func-
tion associated with that tissue to be measured. Typically, the changes are
characterised by using models of biological processes occurring in the voxel
or the region of interest (ROI), which is a group of voxels corresponding to a
particular anatomical region. As explained earlier, dynamic data are obtained
by dividing the total acquisition time into intervals or time frames, and the
data acquired in each time frame are reconstructed independently, represent-
ing the average concentration of the tracer in a voxel over the time interval.
It is possible to process the data so that the correlation between time frames
is taken into account, but in practice simpler approaches are used because of
the ease of processing. Analyses of the 4-dimensional spatio-temporal dataset
often proceeds by modelling the changes in concentration of the tracer using
appropriate compartmental models of temporal data at each voxel or averaged
groups of voxels (ROIs). These temporal data are termed the time activity
curve (TAC). Compartmental models provide estimates of biologically mean-
ingful parameters. The parameters of the models can be estimated for each
voxel separately (as opposed to a group of voxels, ROI) to produce para-
metric images (one 3D image for each parameter) that describe important

ABC in Nuclear Imaging
627
physiological information about the subject. An important consideration in
parametric image estimation is robustness to noise, as noise in the voxel TAC
can be high. Additionally, any estimation has to be very fast due to the large
number of voxels associated with each image and large numbers of TACs to
process.
In this chapter, we ﬁrst brieﬂy describe compartmental models in PET
in Section 21.2, we then introduce a simple ABC algorithm in the context
of PET kinetic modelling in Section 21.4. Section 21.5 provides a detailed
example of ABC implementation for a neurotransmitter response model, and
in Section 21.6, we conclude with some discussions about the potential of ABC
in medical imaging.
21.2
Compartmental Models in PET
As discussed, PET is a technique so that given a time sequence of images,
one can monitor the interaction of a particular radiotracer molecule with the
body’s physiological processes. For instance, blood ﬂow can be measured by
using radioactive water (with 15O replacing 16O in water H216O molecules, by
bombarding them with protons) as a tracer, and metabolism can be measured
with a radioactive glucose analog.
Kinetic models for PET typically derive from the one-, two-, or three-
compartment model with a model input function. In PET, one normally as-
sumes that all tissues in the body see the same input function, and this is
typically a measured concentration of radioactivity in the blood plasma dur-
ing the experiment. In compartmental modelling, it is assumed that within
a voxel, whatever radioactive species contribute to the radioactive signal are
in uniform concentration and can be characterised as being in one or more
unique states. Assuming the system is in steady state, each of these states is
assigned a compartment, which in turn is described by the rates of a change in
concentration within a single ordinary diﬀerential equation. The coeﬃcients
of the diﬀerential equations or the kinetic parameters are reﬂective of inher-
ent properties of the particular radiotracer molecule in the system, providing
information about any hypothesised processes.
As an illustration of the compartmental model, consider the example given
in Sitek (2014), Chapter 5. Figure 21.3 illustrates the possible physiological
states of the tracer compound 18FDG, a glucose analog. The compound is
delivered to the blood, and transported into the cells. Three possible states can
be identiﬁed: (1)18F-Fluorodeoxyglucose (18FDG, analog of glucose) within
the plasma, (2) unmetabolised 18FDG present in the cells or the interstitial
spaces between cells, and (3) phosphorylated 18FDG which is trapped in the
cell (Figure 21.3). Compartmental models are then built by describing the
connections between the states of the molecules, describing the inﬂux to, and
eﬄux from each compartment, in the form of ordinary diﬀerential equations.

628
Handbook of Approximate Bayesian Computation
Voxel or ROI
Blood vessel (capillary)
FDG in blood plasma
FDG in extra vascular space
FDG phosphorylated
Cells
FIGURE 21.3
Representation of the voxel or ROI. The tracer (in this example FDG) is
assumed to be in either of three states: in blood plasma, in the extra vascular
space, or in a phosphorylated state within the cell. (Reproduced from Sitek,
A., Statistical Computing in Nuclear Imaging, CRC Press, Boca Raton, FL,
2014. With permission.)
The one-tissue compartmental model is the simplest model that frequently
arises in PET applications, describing the bi-directional ﬂux of tracer between
blood and tissue. See Figure 21.4 for a pictorial depiction of the model. The
one-tissue compartment model is characterised by the tracer concentration in
the tissue over time Ct(t), the arterial blood (or blood plasma input function)
Ca(t), and two ﬁrst-order kinetic rate constants (K1, k2). The tracer ﬂux from
blood to tissue is K1Ca(t) and the ﬂux from tissue to blood is k2Ct(t), so the
net tracer ﬂux into tissue is given by the ordinary diﬀerential equation as:
dCt(t)
dt
= K1Ca(t) −k2Ct(t),
which is solved to obtain:
Ct(t) = K1Ca(t) ⊗exp(−k2t),
(21.1)
where the symbol ⊗denotes the 1-dimensional convolution. For a PET image,
Ct(t) is the measured radioactivity concentration in a voxel or ROI and Ca(t)
Blood
(Ca)
Tissue
(Ct)
K1
K2
FIGURE 21.4
One-tissue compartment model describing the ﬂow of the tracer between
blood (Ca) and tissue (Ct). K1 and k2 are the kinetic rate constants, see
equation 21.1.

ABC in Nuclear Imaging
629
is the arterial blood concentration of the tracer measured in a sample drawn
during a scan. If the PET data are not corrected for physical decay, the param-
eter k2 includes a component of radioactive decay. For further interpretation
of kinetic rate parameters, see Morris et al. (2004).
More complex compartmental models distinguish diﬀerent biochemical or
physiological states of the tracer in tissue. After entering a cell, the tracer
is available for binding in a free form at the concentration C1(t). Free tracer
can speciﬁcally be bound to its target molecule, with concentration C2(t),
but it may also speciﬁcally bind to some cell components that are not known
in detail, C3(t). The system of diﬀerential equations can be derived anal-
ogously to the one-tissue compartment model, but is much more complex,
with six unknown parameters that may be diﬃcult to estimate. In practice
the system is often reduced to a two-compartment model by treating free and
non-speciﬁcally bound tracer as a single compartment, provided that the rates
of exchange between the free and bound states are suﬃciently rapid compared
with the net inﬂux into the combined compartment. Authoritative reviews on
the subject can be found in Morris et al. (2004), Innis et al. (2007), and Gunn
et al. (2015).
21.3
Parameter Estimation in Compartmental Models
The amount of data available to ﬁt the model is relatively small, typically
around 20–40 time points per voxel or ROI. The estimation of parameters
based on these data, sometimes ten or more of them, can be non-trivial. In
more realistic and complex models, parameter identiﬁability becomes an issue
due to the sparsity of data. Therefore, the adoption of a particular model
is by necessity a simpliﬁcation of the truth (Gunn et al., 2002). Robustness
of parameter estimation in the presence of high level of noise, particularly
in voxel-wise estimations, where the noise-to-signal ratio can be high, poses
another diﬃculty. In addition, since a separate estimation procedure has to be
performed for each voxel, this might typically be around one million voxels,
computational speed needs to be taken into consideration.
A typical approach to parameter estimation in kinetic modelling proceeds
via a variety of least squares ﬁtting procedures (Carson, 1986; Feng et al.,
1996), weighted integration (Carson et al., 1986), or basis function techniques
(Gunn et al., 1997). Many authors have commented on the diﬃculties with
using non-linear least squares methods, particularly with noisy data, often fail-
ing to converge, producing estimates with large variances (which can be the
case even in noiseless data) (Gunn et al., 2002; Alpert and Yuan, 2009). This
has led to methods that employ penalised optimisation to stablise parameter
estimates (Zhou et al., 2001; Gunn et al., 2002).
Whilst the limitations of the basis function technique of Gunn et al. (1997)
are well known, its simplicity and ease of implementation has made it a

630
Handbook of Approximate Bayesian Computation
preferred method for parameter estimation of kinetic models for PET data.
The basic idea is to linearise the kinetic equation, and then use (weighted) least
squares methods to obtain parameter estimates. Consider, for example, the
one-tissue compartment model (21.1), the parameter K1 is linear, whilst the
parameter k2 is non-linear. The non-linear term is then dealt with by choosing
a discrete spectrum of parameter values for k2 and forming the corresponding
basis functions:
Bi(t) = Ca(t) ⊗exp(−ki
2t),
for i = 1, . . . , n, where the values of ki
2 are taken from a physiologically plau-
sible range of values for k2. Equation (21.1) then becomes linear in K1, where:
Ci
t(t) = Ki
1Bi(t).
The parameters Ki
1 can now be solved for each basis function Bi(t) using linear
least squares, and the parameter set (Ki
1, ki
2) that produces the minimum
residual sum of squares is taken as the optimal solution, (Cunningham and
Jones, 1993; Meikle et al., 1998). Gunn et al. (1997) reported that in their
experimentation, only 100 basis functions were needed to obtain good results,
making the method very time eﬃcient. It is interesting to note that the idea
of ﬁtting a spectrum of values of ki
2 and then choosing the most likely value
according to some goodness of ﬁt criterion is very similar to ABC, where
ABC formalises the selection of the candidate parameter set with a prior
distribution. Whilst the method of Gunn et al. (1997) is not formally Bayesian,
the authors note the superior performance of the estimation when a constraint
or a bounded region is placed on the non-linear parameters, thus implicitly
placing a prior distribution on the unknown parameters.
The scarcity of data in kinetic modelling lends itself naturally to Bayesian
modelling, where inclusion of priors can provide better estimates. This ap-
proach has been advocated more recently by several authors (Alpert and
Yuan, 2009; Zhou et al., 2013; Malave and Sitek, 2015). Most applications of
Bayesian modelling in medical imaging proceed in a frequentist fashion, that
is, one often simply ﬁnds the maximum a posteriori estimate of the posterior
using any number of optimisation tools, see for example Lin et al. (2014).
Recently, Malave and Sitek (2015) and Sitek (2014) have advocated a proper
treatment of Bayesian inference in the medical imaging community, given that
uncertainty quantiﬁcation is particularly relevant when the observational data
has a very low signal-to-noise ratio.
Typically, the full Bayesian inference proceeds by assuming an error model
for the time activity curve. The most common model is the independent Gaus-
sian error model, with the variance at each time point assumed to be pro-
portional to the observed data point. Markov chain Monte Carlo (MCMC)
is the default posterior sampling method. However, despite its wide usage,
the Gaussian error model is often not appropriate. Zhou et al. (2013) found
that a t-distribution worked better for the examples they studied. In real-
ity, the error distribution is highly positively skewed at time points with low

ABC in Nuclear Imaging
631
activity if a non-negativity constraint is used with reconstruction and more
symmetric at higher activity time points. In simulation studies, Poisson er-
ror is often introduced to the deterministic data. A second diﬃculty is that
MCMC itself requires tuning and convergence assessment. While the former
can be automated to some extent by automatic tuning algorithms (Garthwaite
et al., 2016), the latter would ideally require repeat analyses at dispersed start-
ing points. This can be computationally infeasible when the analyses involves
hundreds of thousands of repeat simulations.
21.4
A Simple ABC Algorithm for Kinetic Models
ABC oﬀers an alternative to MCMC. Traditionally, ABC is used when the
likelihood function is not tractable. In the current setting, ABC oﬀers a way
of computing full Bayesian analyses without the need to specify an exact error
distribution: we only require the ability to simulate summary statistics. The
most obvious advantage is its ease of interpretation and application, which
makes fully Bayesian inference easily achievable for practical users of Bayesian
methodology. In this chapter, we will restrict our attention to the simplest of
ABC algorithms, the standard rejection sampling method. For the parameter
vector θ = (θ1, . . . , θp)′, this is achieved by the following three steps:
1. Sample parameters θi, i
=
1, . . . , p from the sampling distribution,
Uniform(ai, bi)
2. Compute ˆCt(t) using θ, and the corresponding Ssim
3. Retain θ if 
t |St
sim −St
obs| < ϵ
The sampling distributions Uniform(ai, bi) are proportional to the prior dis-
tributions for each parameter, Uniform(a∗
i , b∗
i ), we will discuss how to obtain
a good sampling distribution in Section 21.5.1. ˆCt(t) is the estimated activity
concentration, using the trial value of θ. For example, θ = (K1, k2), if us-
ing Equation (21.1); St
sim and St
obs are the simulated and observed summary
statistics, respectively, at the t-th time point. ϵ is a pre-determined error toler-
ance value. The choice of summary statistics will be discussed in Section 21.5.
It is clear from the above, that in repeated estimations for diﬀerent voxels,
steps 1 and 2 do not need to be repeated. This is because the values ˆCt(t) com-
puted for one voxel can be re-used for others and the additional computational
cost in step 3 is relatively small.
In this algorithm, we have not replicated the noise in the data. Since
we are not interested in estimating the parameters in the error distribution,
those are considered nuisance parameters. What we assume here is that there

632
Handbook of Approximate Bayesian Computation
exist summary statistics that are (nearly) suﬃcient for the kinetic parame-
ters. We will discuss the selection of summary statistics in more detail in the
example section.
This simple form of ABC is similar to the popular basis function approach
of Gunn et al. (1997), where the summary statistics are just taken as the
original data. ABC formalises the constraints on the parameters in the form
of a prior and, instead of using least squares for some of the parameters,
ABC samples all parameters. In addition, the ABC method provides parame-
ter uncertainty estimation by probabilistically retaining some of the sampled
parameters.
21.5
Application to a Neurotransmitter Response Model
Development of neurochemical assays that capture temporal signatures is crit-
ical because the neurotransmitter dynamics may encode both normal and ab-
normal cognitive or behavioural functions in the brain. The elucidation of
speciﬁc patterns of neurotransmitter ﬂuctuations are beneﬁcial to the study
of a wide range of neuropsychiatric diseases, including alcohol and substance
abuse disorders (Morris et al., 2005; Normandin et al., 2012).
Morris et al. (2005) developed a new model, called ntPET, for quantify-
ing time-varying neurotransmitter concentrations. The new model enhances
the standard tracer kinetic model, accounting for both time-varying dynam-
ics of the radiotracer [11C]raclopride and the endogenous neurotransmitter
dopamine that competes with it for the same D2 receptor binding sites. For
the input function, a reference region approach is used instead of arterial
sampling, where the activity concentration measurements in the reference re-
gion of tissue are assumed to contain negligible speciﬁc binding signal (Morris
et al., 2004). Experimental data are acquired in two separate PET scans, one
conducted with the subject at rest and the other immediately following a
stimulus. Normandin et al. (2012) further developed this model to be used
with a single scan session and proposed a basis function approach for the sim-
pliﬁcation of computation; they call the method lp-ntPET (linear parametric-
neurotransmitter PET). In our simulation studies, we will generate simulated
data using ntPET, and ﬁt the model lp-ntPET to the simulated data, since
the latter is a simpliﬁcation of the former.
The operational equation for the lp-ntPET model takes the form:
Ct(t) = R1CR(t) + k2
 t
0
CR(u)du −k2a
 t
0
Ct(u)du −γ
 t
0
Ct(u)h(u)du,
(21.2)
where Ct(t) and CR(t) are the concentration of the tracer in the target tissue
and reference regions, respectively. The parameters R1, k2 and k2a describe

ABC in Nuclear Imaging
633
the kinetics of tracer uptake and retention in the tissue. The parameter γ
describes the neurotransmitter response magnitude.
The function h(t) describes the non-steady state component of the kinetic
model (with γ encoding the magnitude), given by:
h(t) =
 t −tD
tP −tD
α
exp

α

1 −t −tD
tP −tD

u(t −tD),
where u(t) is the unit step function. The variable tD is the delay time at
which the response starts relative to the start of scan, tP is the peak time
of maximal response magnitude, and α is the sharpness of the function. The
lp-ntPET model has seven parameters, four that describe tracer kinetics and
response magnitude (R1, k2, k2a, γ), and three describing the time course of
the neurotransmitter/activation response (tD, tP , α). This formulation is a
simpliﬁcation of the ntPET model which has eleven parameters.
Equation (21.2) can be expressed in matrix form y = Ax, as:
⎡
⎢⎣
Ct(t1)
...
Ct(tm)
⎤
⎥⎦
=
⎡
⎢⎣
CR(t1)
 t1
0 CR(u)du
−
 t1
0 Ct(u)du
−
 t1
0 Ct(u)h(u)du
...
...
...
...
CR(tm)
 tm
0
CR(u)du
−
 tm
0
Ct(u)du
−
 tm
0
Ct(u)h(u)du
⎤
⎥⎦×
⎡
⎢⎢⎣
R1
k2
k2a
γ
⎤
⎥⎥⎦.
(21.3)
So, for ﬁxed values of tP , tD, and α in the function h(t), the earlier represen-
tation can be solved using linear least squares.
Normandin et al. (2012) propose an eﬃcient computational algorithm
for parameter estimation for lp-ntPET. The idea is similar to the basis
function method of Gunn et al. (1997). Setting the basis function to be
Bi(t) =
 t
0 Ct(u)hi(u)du (this corresponds to the last column entry of the
matrix A), then for basis function Bi(t), a solution is obtained for equation
(21.3), where ˆx = (AT WA)−1AT Wy with the weight matrix having diago-
nal elements inversely proportional to the variance of the PET measurement
of Ct in the matching row of the matrix equation, since it is commonly as-
sumed that the variance of the tracer concentration is proportional to the
observed value. A similar assumption is made in most Bayesian models using
Gaussian error assumption, see for example Zhou et al. (2013). Clearly, in the
presence of high noise, such an assumption can lead to poor parameter esti-
mation. Finally, a large library of basis functions are calculated over diﬀerent
combinations of tD, tP , and α, and the parameter set that minimises the resid-
ual sum of squares is then chosen as the ﬁnal estimate. If the non-negativity
constraint is to be used, for example, for the parameter γ, then an iterative
weighted least squares approach is adopted.

634
Handbook of Approximate Bayesian Computation
In the next section, we consider the application of ABC to the problem of
neurotransmitter response modelling described earlier. We obtain simulated
data, using the nt-PET model, and use ABC to ﬁt the simpler lp-ntPET
model to the data at varying levels of noise. The noise is Poisson with a
mean proportional to the simulated activity concentration. Simulation data
are obtained over 60 time frames each with one minute duration.
21.5.1
Prior and sampling distributions
For simplicity, we use the Uniform distributions U(a∗
i , b∗
i ), i = 1, . . . , 7 as the
prior distributions for the seven unknown parameters (R1, k2, k2a, γ, tD, tP , α),
all of which are non-negative. In practice, the investigator may have a rough
idea of the range of plausible values for the parameters. In this example, we set
the priors as U(0, 20), U(0, 10), U(0, 10), U(0, 5) for the ﬁrst four parameters.
For parameters tD, tP , α, Normandin et al. (2012) discussed the choice of priors
for these parameters and found that the response to a stimulus at 20 minutes
should occur before 25 minutes. Here, we use for tD a ﬂat prior around the
value 20, so tD ∼U(15, 25). This is reasonable to do in most cases because
the displacement modelled by h(t) is caused by an external stimulus that
the experimenter controls and commences at a known time, for example, a
drug injection at 20 minutes. We set the priors for tP as U(tD + 1, 35) and
α ∼U(0, 25); these are essentially the largest numerical ranges that produce
sensible simulated data.
For an eﬃcient ABC algorithm, we require a good sampling distribution
U(ai, bi). A good starting point for the sampling distribution is to use the
prior distributions, for example, set ai = a∗
i , bi = b∗
i . This is typically too
diﬀuse for the algorithm to work eﬃciently, unless the prior happens to con-
centrate around the highest density regions of the posterior. Here, we employ
a sequential method of narrowing down the range, for example, ﬁnding values
ai ≥a∗
i and bi ≤b∗
i . We begin by applying the ABC algorithm of Section
21.4, starting with ai = a∗
i and bi = b∗
i , and a large initial tolerance level
of ϵ = 200. The tolerance is gradually reduced to around ten, over several
intermediate steps. With each reduction in the ϵ value, we use the parameter
range obtained from the ABC algorithm at the previous iteration to deﬁne
new ai and bi. The samples after each of the ﬁrst three iterations are plotted
in Figure 21.5, for R1, k2, and k2a. For example, for k2a shown in the right
panel, the ﬁrst iteration used U(0, 10) as the sampling distribution, with a tol-
erance of ϵ = 200. Applying the algorithm of Section 21.4, the range for this
parameter has reduced to between 0 and 0.8, as indicated by the solid line.
At the next iteration, we use U(0, 0.8) as the new sampling distribution, with
a tolerance of ϵ = 50; the dotted line indicates the range for this parameter
after the second iteration, which will then form the sampling distribution for
the next iteration, and so on. The process is then continued until we obtain a

ABC in Nuclear Imaging
635
0
5
10
15
20
0.0
0.1
0.2
0.3
0.4
R1
Density
0
2
4
6
8
10
0.0
0.5
1.0
1.5
2.0
2.5
3.0
k2
Density
0.0
0.5
1.0
1.5
0
5
10
15
k2a
Density
FIGURE 21.5
Samples for R1, k2, and k2a after each of the ﬁrst three iterations, indicated by
solid, dotted, and dashed lines, respectively. Their respective tolerance levels
are ϵ = 200, 50, 10.
reasonably informative range for U(ai, bi). In our simulated dataset, the ﬁnal
sampling distributions were R1 ∼U(0, 5), k2 ∼U(0, 1), k2a ∼U(0, 0.2),
γ ∼U(0, 2). Note that this sequential procedure is valid with the algo-
rithm in Section 21.4, as long as the sampling distribution is proportional
to the prior. A more elaborate sequential sampling scheme can be found in
Sisson et al. (2007).

636
Handbook of Approximate Bayesian Computation
21.5.2
Summary statistics selection
We consider four diﬀerent summary statistics, S1, . . . , S4:
• S1: Spline smoothed data. This is obtained by using the R package’s
smooth.spline function, using cross validation. The discrepancy between
observed and simulated data is taken as the sum of the absolute diﬀer-
ences between the smoothed observed data and the smoothed simulated
data over each time point.
• S2: The full dataset. The discrepancy between observed and simulated data
is taken as the sum of the absolute diﬀerences between the raw observed
data and the simulated data over each time point.
• S3: The scaled dataset. The discrepancy is the sum of the absolute diﬀer-
ences between the raw observed data and the simulated data, where the
error at each time point is now scaled by the empirical estimate of the
standard deviation of the raw diﬀerence.
• S4: The weighted least squares. For each simulated sample of tD, tP , and
α, the weighted least squares estimate of R1, k2, k2a, and γ is estimated
for the observed data and simulated data, the discrepancy is taken as
the sum of the absolute diﬀerence between the four weighed least squares
estimates.
The spline smoothed data can be considered as sample means at each data
point and should be nearly suﬃcient for the parameters of interest. Figure 21.6
(top two rows) shows the TACs for two diﬀerent activation levels (200% of
baseline activation in the top row and 100% in the second row, over three
diﬀerent noise levels, ranging from high to low, shown from left to right). The
dotted lines in the ﬁgures indicate the raw data, the dashed lines are the spline
smoothed estimates of the raw data, and the solid lines are the true (noiseless)
curves. These plots indicate that the spline estimate is very close to the true
curve, particularly in low noise level cases, and even in the case of very high
noise, it still provides very good estimate of the true TAC.
Similarly Figure 21.6 (bottom two rows) shows the simulated full dataset
indicated by dashed lines. The plotted simulated dataset is estimated at a
given set of parameter values (not necessarily optimal for the datasets plotted).
We can see that at large noise levels, the simulated dataset cannot expect to
fully replicate the original dataset, as we do not simulate noise here. Therefore
in any ABC applications, when the raw data are used in this way, we do not
expect the tolerance to be able to go to zero. In the lower noise levels, the
discrepancy between the simulated and observed data is less marked, as would
be expected.
In order to assess which summary statistics performed best, we considered
the use of posterior predictive distributions, Gelman et al. (2004). For each
summary statistic, we obtain 1 million samples from the sampling distribu-
tion and for each statistic, retain the 1,000 samples with the smallest error

ABC in Nuclear Imaging
637
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
FIGURE 21.6
Rows top to bottom correspond to simulated TAC using the model with 200%
and 100% activation. Columns from left to right correspond to high to low
noise levels. True mean curves (solid line), observed noisy data (dotted line),
and smoothed data (dashed line). S1: top two rows. S2: bottom two rows.

638
Handbook of Approximate Bayesian Computation
as samples from the posterior. The initial 1 million samples were obtained
by setting ϵ = 10, based on the Euclidean distance between observed and
simulated data. The nominal value of 10 was used because simulation was
fast at this value of ϵ, while minimising the burden on computational storage.
For each posterior sample, we generated a dataset and plotted the posterior
predictive mean and credibility intervals together with the spline smoothed
observed data in Figure 21.7. The plots show data generated from the model
with 200% activation. Top two rows have a high noise level and the bottom
two rows have a moderate noise level. Solid lines indicate the observed data,
dashed lines indicate the posterior predictive mean, and dotted lines are the
corresponding interval limits for a 95% posterior predictive interval. In both
cases, the spline summary S1 performed very well, both in terms of capturing
the true curve within the 95% interval, as well as the ﬁdelity of the estimated
curve to the true curve. The full dataset, S2 and S3, showed similar perfor-
mances to each other and gave reasonable performance when the noise level
is lower. The weighted least squares estimate S4 performed the worst and has
much more variability in the posterior predictive distribution. In the remain-
der of this chapter, we will work with S1, the spline smoothed summary.
21.5.3
Tolerance level determination
For the determination of ϵ in step 3 of the ABC algorithm, the typical approach
is to gradually decrease the value of ϵ until no further improvements can
be made. Figure 21.8 illustrates the progression of the estimated marginal
posteriors at ϵ ≈7.8, 2.6, 1.7, corresponding approximately to the 0.8, 0.02,
and 0.001 percentiles of the sampled errors in our initial simulation of the one
million samples. The solid line corresponds to the largest error, and the dotted
line is the one with the smallest error. Note that the ﬁgures show marginal
posteriors beyond the range of the prior distributions. This is due to the eﬀect
of smoothing for the purpose of visualisation, the true samples should not go
beyond the prior distributions.
It is evident here that while at larger ϵ values the posterior variance is
inﬂated, the posterior means do not change too much between varying values
of ϵ. Interestingly for parameters γ, tD, tP and α, decreasing the values of ϵ did
not produce more information about the parameters, suggesting that the data
are fairly uninformative about these parameters. In our MCMC simulations,
we observed similar behaviour with these parameters, suggesting that these
parameters of the lp-ntPET model may not be estimable from the data.
21.5.4
Comparisons of diﬀerent estimation methods
In this section, we compare the performances of ABC, WLS, and MCMC
on simulation datasets. Figure 21.9 shows the posterior distribution obtained
from ABC using the smallest ϵ value of 1.7, for a single set of simulated
data. The model used for the simulation has 200% activation and a very high

ABC in Nuclear Imaging
639
0
10
20
30
40
50
60
S1
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
S2
S3
S4
S1
S2
S3
S4
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
−0.2
0.2
0.6
1.0
−0.2
0.2
0.6
1.0
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
Time
Tracer concentration (pmol/ml)
0
10
20
30
40
50
60
Time
Tracer concentration (pmol/ml)
FIGURE 21.7
Posterior predictive plots for model with 200% activation; top two rows at high
noise level and bottom two rows at moderate noise level. Results shown for
the four diﬀerent summary statistics S1 to S4. Solid lines indicate smoothed
observed data, and dashed and dotted lines are mean, 0.025 and 0.975 per-
centiles, respectively, of the posterior predictive distribution.

640
Handbook of Approximate Bayesian Computation
0.0
1.5
3.0
0.0
0.5
1.0
1.5
2.0
R1
Posterior
0.1 0.3 0.5 0.7
0
5
10
15
k2
Posterior
0.00 0.04 0.08
0
20
40
60
80
k2a
Posterior
0.0
1.0
2.0
0
2
4
6
8
10
γ
Posterior
16
20
24
0.00
0.05
0.10
0.15
tD
Posterior
15
25
35
0.00 0.05 0.10 0.15 0.20
tP
Posterior
0 5
15
25
0.00 0.01 0.02 0.03 0.04 0.05 0.06
α
Posterior
FIGURE 21.8
Evolution of the estimated marginal posterior distribution for the seven pa-
rameters, at diﬀerent values of ϵ ≈7.8, 2.6, 1.7 (corresponding to the 0.8, 0.02,
and 0.001 percentiles of the one million samples). Indicated by solid, dashed,
and dotted lines, respectively. × indicates the posterior means.
noise level. Circles indicate the true parameter value used to obtain simu-
lated data, triangles indicate the posterior mean, and pluses are the weighted
least squares (WLS) estimate of Normandin et al. (2012). For WLS, we have
simulated 100,000 values of tD, tP , and α from the same prior used for ABC
and computed the estimate following Normandin et al. (2012). We have also
implemented MCMC assuming an independent Gaussian error distribution
with variances proportional to the observed TAC. However, it turns out that
the MCMC algorithm is highly sensitive to the starting values, and chains
can get stuck easily for many starting points, including those based on the
true values. In addition, the trace plots indicate that the MCMC sampler
has bad mixing behaviour, and these appear to be diﬃcult to overcome using
the standard MCMC sampler. Most of our MCMC samplers were unable to
converge within a reasonable amount of computational time. This may have
been caused by the mis-speciﬁcation of the error model, since the errors in
these data are known to be more complicated than Gaussian. The assumption
that the variance of the error is proportional to the observed TAC, would
likely induce a highly non-smooth likelihood surface, particularly when data
are noisy. The behaviour of the MCMC output for parameters tD, tP , and α

ABC in Nuclear Imaging
641
R1
Posterior
−0.5 0.5
1.5
0.0 0.2 0.4 0.6 0.8 1.0
k2
Posterior
0.10 0.25 0.40
0
1
2
3
4
5
6
7
k2a
Posterior
0.00
0.04
0
5
10 15 20 25
γ
Posterior
0.05
0.15
0
5
10
15
20
tD
Posterior
16
20
24
0.00 0.02 0.04 0.06 0.08 0.10 0.12
tP
Posterior
22 26 30 34
0.0
0.1
0.2
0.3
α
Posterior
0 5
15
25
0.00 0.01 0.02 0.03 0.04 0.05
FIGURE 21.9
Final estimates of the marginal posterior distributions using ABC, at a value
of ϵ ≈1.7. Circles indicate the true parameter value, triangles indicate the
ABC posterior mean, and plusses indicates the weighted least squares estimate
using Normandin et al. (2012).
are erratic; these parameters are essentially un-estimable. Indeed, the poste-
rior distribution of these parameters suggests that the data indeed have very
little information about the values of tD and α, as the posteriors are largely
unchanged from our prior distribution. This is also seen in the results from
ABC, shown in Figure 21.9. We found that MCMC tended to over-estimate
the R1 parameter, while this is underestimated by ABC and WLS in some
cases. MCMC was able to give very precise estimates of tD close to the true
value, while it found it diﬃcult to estimate tP . The situation is reversed for
ABC, which found tD diﬃcult to estimate, while tP was relatively straight-
forward. It is diﬃcult to know the exact reason for these discrepancies, a lack
of convergence in the MCMC sampler could partially explain some of the
diﬀerences, model mis-speciﬁcation is another possibility.
Figure 21.10 shows the posterior mean estimates from ABC (top row) and
least squares estimates for 100 noise realisations (at 100% activation and high-
est noise level). We have excluded results from MCMC simulations due to the
unreliable results obtained. At these noise and activation speciﬁcations, the
parameter estimations were the most problematic. Results in Figure 21.10
demonstrate that ABC estimates are much less variable than WLS, alt-
hough for both algorithms, the parameter R1 is largely underestimated.

642
Handbook of Approximate Bayesian Computation
R1
k2
k2a
γ
ABC
tD
tP
α
0
5
10
20
30
ABC
R1
k2
k2a
γ
−0.5
0.0
0.5
1.0
1.5
−0.5
0.0
0.5
1.0
1.5
WLS
tD
tP
α
0
5
10
20
30
WLS
FIGURE 21.10
Box plots of posterior mean estimates over 100 noise realisations using ABC
(top row), the corresponding WLS estimates (bottom row). Crosses indicate
the true values.
The ABC estimator is more robust for all the parameters, but particularly
so for R1 and the time course response parameters tD, tP , and α, where
the variability of the estimates as demonstrated by the box plots are much
smaller.
We further investigated the cause for the apparently large bias in the R1
estimation in both ABC and WLS. We found that parameter estimates are
somewhat sensitive to the prior speciﬁcation of the parameter α, and using
a smaller range of U(0, 3), we were able to obtain better estimates for both
algorithms. However, this still did not provide a substantial improvement to
the bias in the R1 estimates. Figure 21.11 shows the comparative box plots for
the R1 parameter as estimated by ABC and WLS, over four noise levels and
two diﬀerent activation levels (200% and 100%). While it can be seen that the
estimates of the 200% activation model are generally better than the 100%
activation model, in both cases, the estimates worsen with noise, exhibiting
high bias and high variance. The performance of the ABC estimator in the
higher noise cases are generally superior to WLS. In low noise cases, WLS
are often similar or even better than ABC, suggesting that the beneﬁt of a
Bayesian analysis lies in the more noisy problems.
In terms of the large bias in R1, one possibility is that it could be an inher-
ent bias of the lp-ntPET model, but this seems unlikely to explain away all the

ABC in Nuclear Imaging
643
ABC−1 wls−1 ABC−2 wls−2 ABC−3 wls−3 ABC−4 wls−4
0.0
0.5
1.0
R1
ABC−1 wls−1 ABC−2 wls−2 ABC−3 wls−3 ABC−4 wls−4
−0.5
0.0
0.5
1.0
1.5
R1
FIGURE 21.11
Box plots of posterior mean estimates over 100 noise realisations based on
100% activation model (left) and 200% activation model (right). X-axis cor-
respond to results from ABC and WLS alternately, for four diﬀerent noise
levels (1–4) from highest to lowest noise levels. Horizontal line indicates the
true value at 1.
bias. Figure 21.11 suggests that for lower noise levels, the results are close to
the true value. This suggests that the biases maybe due to the way we handle
the noise. A closer look at Figures 21.6, ﬁrst column of top two rows, suggests
that the spline-based summary deviates from the true TAC, while in lower
noise data, there is much better accordance between the summaries and the
true curve. This suggests that a more robust spline estimator, less sensitive
to the distribution of the noise, may yield better results.
21.6
Conclusions and Discussions
This chapter examined the use of ABC for medical imaging data. In these
types of data, it is often necessary to perform parameter estimation for mul-
tiple datasets, sometimes in the order of tens of thousands. A computational
advantage of ABC in this scenario is that simulation of synthetic datasets

644
Handbook of Approximate Bayesian Computation
within the ABC step will only need to be done once, representing a substantial
computational saving compared with more traditional estimation procedures
such as MCMC.
Our simulation studies comparing ABC, MCMC, and WLS showed that
MCMC was unstable, and diﬃcult to implement under our model assump-
tions. ABC and WLS obtained comparable results and, in most cases, were
able to retrieve the true parameter values. In higher noise problems, ABC
produced more robust estimates than WLS, which will prove more useful for
voxel-wise estimations. In terms of computational time, WLS is the fastest.
Both ABC and MCMC are time consuming, but over multiple datasets, ABC
is substantially faster than MCMC.
We expect that in less noisy datasets, with relatively simple kinetic models,
WLS would perform well, and it would be diﬃcult to justify the use of the
more computationally expensive ABC method. However, even in this case,
there are added beneﬁts from a Bayesian analysis that are often not readily
available from the frequentist approach. For instance, Normandin et al. (2012)
were interested in the signiﬁcance of the magnitude parameter γ. However,
ﬁnding an appropriate statistical test for such a task is diﬃcult. In Bayesian
inference, the posterior distribution of γ from Figure 21.9 readily provides the
credibility interval for the parameter and allows us to assess the signiﬁcance
of a parameter immediately. Alternatively, posterior model comparison can
be carried out relatively straightforwardly; see Chapter 6, in this handbook for
more details on ABC model choice. Finally, the posterior distribution provides
some information on how well the data are able to estimate certain parameters
in a given model, see, for example, parameters tD and α, and this could serve
as an exploratory tool for the development of new models.
The ABC algorithm described in this chapter shares some similarity to the
WLS approach of Normandin et al. (2012), where a basis function approach
is used to estimate the time course response curve. Their WLS can be seen
as a hybrid of Bayesian and frequentist methods. The main diﬀerences are
that ABC requires the selection of a summary statistic and WLS searches
for the modal estimate, while ABC computes the full posterior. In both algo-
rithms, parameters become harder to estimate when the noise level is high.
One possibility in ABC is to consider summaries which are more robust to
noise. Another possible direction is to extend the analysis, currently assuming
voxel independence, to allow borrowing of information from nearby voxels.
It would be interesting to see how this can be performed eﬃciently within the
ABC setting.
References
Alpert, N. M. and F. Yuan (2009). A general method of Bayesian estimation
for parametric imaging of the brain. Neuroimage 45, 1183–1189.

ABC in Nuclear Imaging
645
Anger, H. O. (1964). Scintillation camera with multichannel collimators.
Journal of Nuclear Medicine 65, 515–531.
Carson, R. E. (1986). Positron Emission Tomography and Autoradiogra-
phy: Principles and Applications for the Positron Emission Tomogra-
phy and Autoradiography: Principles and Applications for the Brain and
Heart, Chapter Parameter estimation in positron emission tomography,
pp. 347–390. New York: Raven Press.
Carson, R. E., S. C. Huang, and M. E. Green (1986). Weighted integration
method for local cerebral blood ﬂow measurements with positron emission
tomography. Journal of Cerebral Blood Flow and Metabolism 6, 245–258.
Cherry, S. R. and M. Dahlbom (2004). PET: Molecular Imaging and its Bio-
logical Applications, Chapter PET: Physics, instrumentation and scanners,
pp. 1–124. Berlin, Germany: Springer.
Cunningham, V. J. and T. Jones (1993). Spectral analysis of dynamic PET
studies. Journal of Cerebral Blood Flow and Metabolism 13(1), 15–23.
Feng, D., S. C. Huang, Z. Wang, and D. Ho (1996). An unbiased paramet-
ric imaging algorithm for uniformly sampled biomedical system parameter
estimation. IEEE Transactions on Medical Imaging 15, 521–518.
Fessler, J. A. (1996). Mean and variance of implicitly deﬁned biased estimators
(such as penalized maximum likelihood): Applications to tomography. IEEE
Transactions on Image Processing 5, 493–506.
Garthwaite, P. H., Y. Fan, and S. A. Sisson (2016). Adaptive optimal scal-
ing of Metropolis–Hastings algorithms using the Robbins–Monro process.
Communications in Statistics: Theory and Methods 45, 5098–5111.
Gelman, A., J. B. Carlin, H. S. Stern, and D. B. Rubin (2004). Bayesian
Data Analysis. Texts in Statistical Science. Boca Raton, FL: Chapman &
Hall/CRC Press.
Gunn, R. N., S. R. Gunn, F. E. Turkheimer, J. A. D. Aston, and
V. J. Cunningham (2002). Positron Emission Tomography compartmental
models; A basis pursuit strategy for kinetic modeling. Journal of Cerebral
Blood Flow and Metabolism 22, 1425–1439.
Gunn, R. N., A. A. Lammertsma, S. P. Hume, and V. J. Cunningham (1997).
Parametric imaging of ligand-receptor binding in PET using a simpliﬁed
reference region model. Neroimage 6(4), 279–287.
Gunn, R. N., M. Slifstein, G. E. Searle, and J. C. Price (2015). Quantita-
tive imaging of protein targets in the human brain with PET. Physics in
Medicine and Biology 60, R363–R411.

646
Handbook of Approximate Bayesian Computation
Hudson, H. M. and R. S. Larkin (1994). Accelerated image reconstruction
using ordered subsets of projection data. IEEE Transactions on medical
imaging 13(4), 601–609.
Innis, R.B., V. J. Cunningham, J. Delforge, M. Fujita, A. Gjedde, R. N.
Gunn, J. Holden et al (2007). Consensus nomenclature for in vivo imag-
ing of reversibly binding radioligands. Journal of Cerebral Blood Flow and
Metabolism 27, 1533–1539.
Leahy, R. M. and J. Qi (2000). Statistical approaches in quantitative positron
emission tomography. Statistics and Computing 10, 147–165.
Lin, Y., J. Haldar, Q. Li, P. Conti, and R. Leahy (2014). Sparsity constrained
mixture modeling for the estimation of kinetic parameters in dynamic PET.
IEEE Transactions on Medical Imaging 33, 173–185.
Malave, P. and A. Sitek (2015). Bayesian analysis of a one-compartment ki-
netic model used in medical imaging. Journal of Applied Statistics 42(1),
98–113.
Meikle, S. R., J. C. Matthews, V. J. Cunningham, D. L. Bailey, L. Livieratos,
T. Jones, and P. Price (1998). Parametric image reconstruction using spec-
tral analysis of PET projection data. Physics in Medicine and Biology 43,
651–666.
Morris, E. D., C. J. Enders, K. Schmidt, B. T. Christian, R. F. Muzic, and
R. E. Fisher (2004). Emission Tomography: The Fundamentals of PET
and SPECT, Chapter Kinetic modeling in PET, pp. 499–540. Emission
Tomography: The Fundamentals of PET and SPECT. Amsterdam, the
Netherlands: Academic Press.
Morris, E. D., K. K. Yoder, C. Wang, M. Normandin, Q.-H. Zheng, B. Mock,
R. F. M. Raymond Jr., and J. C. Froehlich (2005). ntPET: A new appli-
cation of PET imaging for characterizing the kinetics of endogenous neuro-
transmitter release. Molevular Imaging 4(4), 473–489.
Normandin, M. D., W. K. Schiﬀer, and E. D. Morris (2012). A linear model for
estimation of neurotransmitter response proﬁles from dynamic PET data.
Neuroimage 59, 2689–2699.
Qi, J. and R. M. Leahy (2006). Iterative reconstruction techniques in emission
computed tomography. Physics in Medicine and Biology 51, 541–578.
Shepp, L. A. and Y. Vardi (1982). Maximum likelihood reconstruction for
emission tomography. IEEE Transactions on medical imaging MI-1(2),
113–122.
Sisson, S. A., Y. Fan, and M. M. Tanaka (2007). Sequential Monte Carlo
without likelihoods. Proceedings of the National Academy of Sciences 104,
1760–1765.

ABC in Nuclear Imaging
647
Sitek, A. (2014). Statistical Computing in Nuclear Imaging. Series in Medical
Physics and Biomedical Engineering. Boca Raton, FL: CRC Press.
Wernick, M. N. and J. N. Aarsvold (2004). Emission Tomography: The Fun-
damentals of PET and SPECT. New York: Academic Press.
Zhou, Y., J. A. D. Aston, and A. M. Johansen (2013). Bayesian model com-
parison for compartmental models with applications in positron emission
tomography. Journal of Applied Statistics 40, 993–1016.
Zhou, Y., S. C. Huang, and M. Bergsneider (2001). Linear ridge regression with
spatial constraint for generation of parameter images in dynamic positron
emission tomography studies. IEEE Transactions on Nuclear Science 48,
125–130.


Index
Note: Page numbers followed by f and t refer to ﬁgures and tables respectively.
A
ABC algorithm, 308. See also
Approximate Bayesian
computation (ABC)
box plots, 642f
computational advantage,
643–644
for expensive simulators, 99
for kinetic models, 631–632
marginal posterior distribution,
641f
MCMC, 199, 203
to perform site update, 425
ABC approximation methods
ﬂexible regression density
estimator, 230–232
Gaussian copula, 219–222, 221f
marginal adjustment strategy,
214–215
multivariate g-and-k model, 222,
224–225, 225f
non-linear multiple quantile
regression analysis,
226–229, 229f
posterior distribution, 213–299
stereological extreme analysis,
232–235
summary statistics, distribution,
229–230
toy model, 215–219, 216f, 217f,
218f
ABC composite parameter (ABC-cp)
approach, 185t, 202–203
ABC importance/rejection sampler
variants, 95
importance sampling, 96–98
marginal ABC samplers,
100–101
rejection-based ABC algorithms,
99
rejection control importance
sampling, 95–96
stopping rule, ABC rejection
sampling with, 99
ABC indirect inference (ABC II)
methods, 180, 184t,
185–189, 191
ABC indirect parameter (ABC IP)
method, 138, 184t, 186–187
ABC indirect score (ABC IS)
approach, 139, 180, 184t,
187
ABC Markov chain Monte Carlo
(ABC-MCMC) algorithm,
246, 399–401
1-hit algorithm, 262
ABCtoolbox, 402
adaptive, 262–263
averaging estimators, 255–257
EasyABC, 401–402
inexact algorithms, 263–264
noiseless algorithm, 250–251
performance measures,
249–250
rates of convergence, 251–253,
253t
rejuvenation, 257–260
samplers, 102–109
stratiﬁcation, 260
649

650
Index
ABC posterior approximations,
22–23, 271–274
binding function eﬀect, 275–276,
275f
checking method, 559
concentration, 272–274, 273f
versus full-likelihood posterior,
40f
for Gamma target distribution,
29f
mean, 279–281
model error, 276, 277f
overview, 277–279
rate of concentration, 274–275,
274f
target distribution, 23f
using summary statistics, 38f
abc R packages, 370–371, 373
cross-validation process, 385
inferring BF, 388–389
methods, 379
multi-dimensional posteriors,
380–381
post-sampling adjustments,
379–380
rejection algorithm, 374
validation, model choice,
390–391
abc.star R package, 300
dispersions testing, 303–305,
304f
locations testing, 300–303
rates testing, 305–306
ABCtoolbox R packages, 370–371,
373–374
ABC-MCMC, 402
arguments in, 375, 377, 384
biased posteriors, checking for,
386–387
cross-validation process, 385–386
estimation settings for,
376t–377t
with fastsimcoal2, 405–406
inferring BF, 389–390
multi-dimensional posteriors,
381–382
normal/uniform distribution
model by, 392f
output ﬁles, 378t
posterior densities, 375f
post-sampling adjustments, 380
rejection algorithm, 374–378
simulations for, 397–399, 398t,
400t
statistical tests, 383
validation, model choice,
391–392
Accelerating SL, 327–328
Adaptive multiple importance
sampling (AMIS), 347, 350
BCel algorithm, 352–353
Agent-based model, 328, 443–444,
531
Approximate Bayesian computation
(ABC), 14–15, 88, 243, 322,
514, 541–542
in 11 Biaka pygmies, 39t
accept/reject decisions in, 30f
approximate posterior
distribution, 15–23, 21f
asymptotics, 269–286
Bayesian approach, 62–64
beneﬁt, 403
BF, 158, 161
calibrations, 289, 291–292
cell biology application, 335f,
336f
cell migration, 527–532
checking analysis, 561
coalescent trees and mutation,
55–59, 57f, 58f
computationally intensive
methods, 60–62
for design, 522
emulator-informed, 582–586
expensive simulators,
rejection-based, 99
g-and-k distribution analysis,
11–14, 12f

Index
651
GLM algorithm, 379
hypothesis testing approach,
313f
importance sampling algorithm,
91–98, 111, 496–497
inference with, 496–501
interpretations, 43–44
iSIR with, 259
k-nn importance sampling
algorithm, 98
levels in approximation, 41–43
likelihood-free intuition, 6–7
marginal posterior densities,
502f, 503t
MCMC algorithm, 350
overview, 3–5
parameter estimation by,
555–559, 557f
in population genetics analysis,
34–41, 35t
posterior. See ABC posterior
approximations
quantile regression forest in, 82
regression approaches, 71–82
rejection sampling algorithm,
17, 25–26, 32–33, 90, 94,
580f, 600
RF model, 549–555, 554t
samplers, 88–117
SMC framework and algorithm,
114–115, 521f
software, 370t
standard versus calibration, 310f
statistical inference, 59–60
stereological extremes analysis,
7–11, 9f
stopping rule, rejection sampling
with, 99
summary statistics in, 23–34,
329–330, 337f
takes oﬀ, 64–65
variants, 395
Z-test for, 294, 296, 297f, 299
Approximate suﬃciency methods,
130
Augmented space ABC-MCMC
samplers, 105–107
Autoregressive (AR) model, 183
Autoregressive moving average
(ARMA) model, 183
Auxiliary likelihood methods, 129,
137, 191
advantages/disadvantages, 140
likelihood distance, 138
MLE, 138
properties, 139–140
scores, 139
B
Bayes Factors (BF), 351
ABC algorithm, 158, 161
boxplots, 352f
inferring, 388–390
Bayesian approach, 62–64
Bayesian calibration, 572–573
Bayesian computational methods, 14
Bayesian computation for copulas
(BCOP) algorithm, 355–356
Bayesian EL, 338–339
Bayesian framework, 322
Bayesian indirect likelihood (BIL),
184t
with parametric auxiliary
model, 189–192
Bayesian inference method, 3, 72
Bayesian likelihood-free methods,
184t–185t
Bayesian modelling, applications,
630
Bayesian SL, 325–327
Bayes suﬃciency, 128
BCel algorithm, 321, 347–352
AMIS, 352–353
extensions, 352–358, 354f
histogram, 349f
R code for, 348–349
BCOP (Bayesian computation for
copulas) algorithm, 355–356
Benchmark model assumptions,
465–466

652
Index
BF. See Bayes Factors (BF)
Biased posteriors, checking for,
386–387
BIL. See Bayesian indirect likelihood
(BIL)
Binary networks, 523
Binding function, 181–182, 275–276,
312
Biosensors, 522
Block-parallel EP, 420–423
Bolivian dataset, 485
Boosting methods, 135
BSL approach, 322, 325
MCMC, 326–327
for posterior inference, 326–327
uBSL, sensitivity, 332t, 334t
Built-in function hist(), 379
C
Carbon cycle processes, 581–582
CARTs (classiﬁcation and regression
trees) algorithm, 164
CDF (Cumulative Density
Function), 428
Cell migration, ABC models, 527
cytokines, 527–528
data, 530f
macrophages, 528–529
model, 528f
spatio-temporal characteristics,
531f
Chaotic prey–predator model,
608–609
data and priors, 610–612
from Kilpisjarvi dataset,
613–616, 613t, 614f
using simulated data, 612–613,
612t
Chi-X Europe, 440f, 464
Classical SL, 323–324
Classiﬁcation and regression trees
(CARTs) algorithm, 164
Climate models, ABC for
case study, 581–589
emulation, 576–581
features, 570
history matching and, 573–576
overview, 570–572
Climate simulators, 574
Coalescent model, 76
Coalescent trees and mutation,
55–59, 57f, 58f
Compartmental models
one-tissue, 628, 628f, 630
parameter estimation in,
629–631
in PET, 627–629
Computational cost, 133
Computationally intensive methods,
60–62
Copula models, 353
Coupling applications, 588–589
Covariance mutation operator, 463
Cross-validation process, 384–386
abc, 385
ABCtoolbox, 385–386
Cumulative Density Function
(CDF), 428
Cumulative distributions function,
351, 351f
Curse of dimensionality, 127, 141
D
Data generation process, 5
Datasets, simulation
computer programs, 548–549
models and parameters, 545–548
observed, 544
Dimension reduction techniques,
134–135
Dirac measure, 4, 88
Direct conversion, 507
Divide and conquer in ABC
EP algorithms, 417–428
overview, 416–417
spatial extremes application,
428–431
Do It Yourself Approximate Bayesian
Computation (DIYABC)
program, 159, 548–549, 560

Index
653
Double exponential distribution, 160
Drug resistance. See also Multidrug
resistance (MDR)
acquisition, 493–494
transmission and, 483
Dynamical systems, parameter
estimation for, 515
inference for, 515–516
and model selection, 520–522
posterior analysis for, 517–519
Dynamic imaging, 625–626
E
Earth system models (ESMs),
570–571
EasyABC R packages, 370–371
ABC-MCMC, 401–402
simulations for rejection,
396–397
Ecological modelling, ABC in
chaotic prey–predator model,
608–616
intractable, 597–600
simulation-based methods in,
597–608
Eﬀective sample size (ESS), 93, 330,
349
Eﬃcient method of moments (EMM)
approach, 183
EFPC. See Emulator Filtered
Plausibility Constrained
(EFPC) ensemble
EGA (European Genome-phenome),
544
EL. See Empirical likelihood (EL)
Ellipsoidal inclusions model, 233f,
234f, 235f
el.test library, 344–345
EM (expectation maximisation)
algorithm, 626
EMM (eﬃcient method of moments)
approach, 183
Empirical likelihood (EL), 322,
339–341
Bayesian, 338–339
BCel algorithm, 347–358
estimation, 343–345
features, 341–343
in practice, 345–347
emplik library, 344–345
Emulation techniques, 572, 576
methods, 577
sequential history matching,
576–579
two-box climate simulator,
579–581, 581f
Emulator Filtered Plausibility
Constrained (EFPC)
ensemble, 584
parameter set, 586–588
Emulator-informed ABC design,
582–586
Entropy/loss minimisation
approaches, 131
EP-ABC (expectation propagation
ABC) algorithm, 156–157
EP algorithms. See
Expectation-propagation
(EP) algorithms
Equivalence hypothesis tests,
292–294
within ABC, 294–299
ESMs (Earth system models),
570–571
ESS (eﬀective sample size), 93, 330,
349
European Genome-phenome Archive
(EGA), 544
Evolutionary models, scenarios,
545–548
Ewens, W., 59
Expectation maximisation (EM)
algorithm, 626
Expectation propagation ABC
(EP-ABC) algorithm,
156–157
Expectation-propagation (EP)
algorithms, 417
block-parallel, 422–423
convergence, 431

654
Index
Expectation-propagation (EP)
algorithms (Continued)
exponential properties, 418–419
feasibility, 419
ﬂavours, 424
Gaussian sites, 420
iid case, 426–428
parallel, 422
practical considerations, 423
presentation, 417–418, 426
principle, 424–425
sequential, 421
site updates, 419–423
theoretical properties, 423–424
F
Fay–Herriot (FH) model, 347
Finite sites models, 59–60
Fitting regression models, 74–76
Flexible regression density estimator,
230–232
Forest stand growth models, 598
Functional imaging, 626
G
g-and-k distribution analysis, 11–14,
12f
GARCH (generalized autoregressive
conditional
heteroskedasticity) model,
356
Gaussian copula ABC method,
219–222, 221f
Gaussian processes (GPs), 327–328,
576
emulation, 589
predictions, 577
Gaussian sites, 420
Generalized autoregressive
conditional
heteroskedasticity
(GARCH) model, 356
General Linear Model (GLM)
algorithm, 379
Generative model, 137
Gene regulatory network, 517, 517f
Generic pseudo-marginal algorithm,
247
Genetic dataset, 542–543
Genetic mutation/cross-over
operators, 461–462
GFP (green ﬂuorescent protein), 530
GLM (General Linear Model)
algorithm, 379
Glucose metabolism, 623
GPs. See Gaussian processes (GPs)
Green ﬂuorescent protein (GFP), 530
Gross primary productivity (GPP),
587
H
H3N2’s disease, ABC calibrations in,
307–308, 309f
HDI (high posterior density
intervals), 386
Hidden Markov models (HMMs),
526, 526f, 601
High-dimensional ABC approaches,
235–236
High posterior density intervals
(HDI), 386
History matching and ABC, 573–574
HMMs (hidden Markov models),
526, 526f, 601
Human population genetics model,
170–172, 171f, 172f, 173f
Hypothesis tests, 312
I
IAM (integrated assessment model),
588
IFM (inference from the margins)
approach, 354–355
IgG (immunoglobulin-G) dataset,
226, 227f
iid. See Independent and identically
distributed (iid)
II method. See Indirect inference (II)
method
ILI (inﬂuenza-like-illness), 306, 306f
Immunoglobulin-G (IgG) dataset,
226, 227f

Index
655
Importance sampling, ABC, 91–95
Independent and identically
distributed (iid), 155–156
datasets, 181, 325
parallel expectation
propagation-ABC in,
426–428
Indirect inference (II) method,
179–180, 470
auxiliary model, 181
developments, 181–185
mapping/binding function, 181
Inexact algorithms, 263–264
Infectious disease model, 196–199,
200f
Inference for SSMs, 600–604
Inference from the margins (IFM)
approach, 354–355
Inference with ABC, 496–498
parameter speciﬁcations and
prior distributions, 499–501
summary statistics, 498–499
Inferring BF, 388
abc, 388–389
ABCtoolbox, 389–390
Inﬁnitely many alleles and sites
model, 34, 56
Inﬂuenza-like-illness (ILI), 306, 306f
Integrated assessment model (IAM),
588
Intergovernmental Report on Climate
Change (IPCC), 586
Intermediate complexity models,
570–571
Intractable ecological models,
597–600
Intractable likelihood stochastic
model, 443
IPCC (Intergovernmental Report on
Climate Change), 586
iSIR algorithm, 259
K
Kaplan–Meier curve, 346
Kernel functions, 16, 16t, 17f
Kingman’s coalescent model, 34
k-nearest neighbours (k-nn) method,
155
Kolmogorov–Smirnov distance,
530–531
Kullback–Leibler (KL) divergence,
222, 223t
L
Laplace distribution, 160
Lasso regression approach, 76
Lazy summary statistic, MCMC
ABC algorithm, 198–199
LDA (linear discriminant analysis),
394, 552f
Likelihood-free methods, 14–15, 452
intuition level, 6–7
rejection sampling algorithm, 7,
10, 13
Likelihood function, 5, 157
synthetic log versus true log,
607, 607f
Limit order book (LOB), 438, 444
agent-based model, 443–451
Bayesian model formulation,
451–454
complex model structure, 455
data description application,
464–465, 465f
and multi-queue simulation
models, 439–441
simulated intra-day
representations, 470f, 471f
stochastic processes, 441–442
summary statistics in Bayesian,
454–455
Limit order cancellation/submission
process, 445–449
Linear algebra notation, 489t
Linear discriminant analysis (LDA),
394, 552f
Linear noise approximation (LNA),
196
Linear parametric-neurotransmitter
PET (lp-ntPET), 632–633

656
Index
Linear regression methods, 134–135
Liquidity, 441–442
demander agent, 449–451
providers/demanders, 445–451
LNA (linear noise approximation),
196
LOB. See Limit order book (LOB)
Local error rates, 144–145
Local regression method, 156
Loclinear method, 379
Logit transformation, 76–77
Log return, 466–467
lp-ntPET (linear parametric-
neurotransmitter PET),
632–633
Lyapunov exponent, posterior
densities, 615, 616f
M
Mahalanobis distance, 13, 31, 88, 203
MAP. See Maximum a posteriori
(MAP) model
Mapping/binding function, 181
Marginal ABC sampler, 100–101
Marginal adjustment approach,
214–219, 216f, 217f, 218f
Market orders, 439, 443–444
Markov chain Monte Carlo (MCMC)
methods, 102–109, 324, 601,
630
ABC algorithm, 350
ABCtoolbox, 402
BSL, 326–327, 331f, 333f
EasyABC, 401–402
Metropolis–Hastings algorithm
in, 4, 338
performing, 399–402
samplers, 640
simulations, 638
uBSL, 327, 332f, 334f
Mass action, new infections by,
490–491, 491t
Maximum a posteriori (MAP)
model, 163, 384
approximating posterior
probability, 165–166
posterior probability estimation,
163–164
RF construction, 164–165
via machine learning, 162–166
Maximum likelihood estimator
(MLE), 138, 184, 187, 575
Max-stable processes, 200–201
MCMC. See Markov chain Monte
Carlo (MCMC) methods
MCWM (Monte Carlo within
Metropolis), 263
MDR. See Multidrug resistance (MDR)
Meta-Gaussian distribution, 219–220
Metropolis–Hastings (MH)
algorithm, 102, 245, 602
MEVDs (multivariate extreme value
distributions), 199
Microsatellite loci, 544
MLE. See Maximum likelihood
estimator (MLE)
Model choice, ABC, 140–141,
153–154, 387–388
algorithm, 155
curse of dimensionality, 141
curse of insuﬃciency, 157–162,
160f, 161f, 162f
encompassing model, 143
inferring BF, 388–390
local error rates, 144–145
local logistic regression
algorithm, 156
mutual information, 143
prior error rate, 169t, 170t
projection/classiﬁcation
methods, 143–144
RF algorithm, 165
simulate only simulate, 155–157
suﬃciency/consistency, 141–142
summary statistics, 392–395,
395t
toy models, 166–170, 168f, 169f,
389t
validation, 390–392

Index
657
modelChoiceValidation argument,
391
Model-posterior checking, 559–562
Molecular dataset, 486t–487t
Moment matching, 419
Monte Carlo error, 42–43, 281–282
Monte Carlo within Metropolis
(MCWM), 263
Most recent common ancestor
(MRCA), 56
ms program, simulations, 36–37
Multi-dimensional posteriors
abc, 380–381
ABCtoolbox, 381–382
Multidrug resistance (MDR), 482
acquisition, 501f
strains, 482
transmission and treatment
failure to TB, 505–506, 506t
Multi-locus VNTR analysis, 483, 496
Multi-objective-II estimation
framework, 470
Multi-scale models, 525–526
inference for, 526–527
Multivariate extreme value
distributions (MEVDs), 199
Multivariate g-and-k model, 222,
224–225, 225f
Mutual information method,
131–132, 143
Mycobacterium tuberculosis, 482, 500
N
Network analysis and inference,
522–523
distances and summaries,
523–525
evolution models, 523, 525f
summary statistics for, 524
neuralnet method, 389
Neurotransmitter response model,
632–634
estimation methods, 638–643,
639f, 640f, 643f
prior and sampling
distributions, 634–635, 635f
summary statistics selection,
636–638
tolerance level determination,
638
Newton–Lagrange algorithm, 344
Noiseless algorithm approximation,
250–251
Noisy likelihood perspective, 244–246
Non-linear multiple quantile
regression analysis,
226–229, 229f
Non-linear regression method, 135
Non-parametric regression
approaches, 212, 328
Non-Pygmies populations, 542–543,
545
divergence time parameters,
556, 563
introgression events, 550
Nuclear imaging, ABC in, 623–627
O
Observed datasets, 544
Ocean alkalinity, 584, 585f
One-tissue compartmental model,
628, 628f, 630
Ordinary diﬀerential equations
(ODE), 515–516
P
Parallel EP, 422, 427
Parameter estimation
in compartmental models,
629–631
in kinetic modelling, 629
model choice, 555–559, 557f
robustness, 629
Parameter inference, 373–374
estimation validation, 382–387
multi-dimensional posteriors,
380–382
post-sampling adjustments,
378–380
rejection algorithm, 374–378
statistics for, 392–394

658
Index
Parameter validation
estimation, 382–387
testing uniformity, 387f
using methods, 385f
Parametric Bayesian indirect
inference (pBII) methods,
180
Parametric Bayesian indirect
likelihood (pBIL), 180,
325
Parametric BIL on the full data level
(pdBIL) method, 185t,
189–190
Parametric BIL on the summary
statistic level (psBIL)
method, 185t, 191
Partial least squares (PLS) methods,
134, 392
analysis, 393
components, 405
versus RMSEP, 393f
transformations, 402
Partial posterior distribution, 72
Particle degeneracy, 109–110
Particle marginal
Metropolis–Hastings
(PMMH) algorithm,
603–604
Lyapunov exponents for,
616f
pBII (parametric Bayesian indirect
inference) methods, 180
pBIL (parametric Bayesian indirect
likelihood), 180, 325
pdBIL (parametric BIL on the full
data level) method, 185t,
189–190
PET. See Positron emission
tomography (PET)
Photons, 624
Phylodynamics model, 76
Pitman–Koopman–Darmois theorem,
128
PLS. See Partial least squares (PLS)
methods
PMMH. See Particle marginal
Metropolis–Hastings
(PMMH) algorithm
Polynomial mutation, 462–463
Positron emission tomography
(PET), 623
compartmental models in,
627–629
detector ring, 624, 625f
kinetic models for, 627
Posterior distributions, 72
analysis, 519f
estimators, 77
Spearman’s ρ, 357, 357f
Posterior predictive p-values
(ppp-values), 560–562
Post-processing techniques, 42
Post-sampling adjustments, 378–379
abc, 379–380
ABCtoolbox, 380
Potts model, Bayesian inference for,
328
ppp-values (posterior predictive
p-values), 560–562
Predator-prey systems, 599
Principal component analysis, 561,
561f
Probabilistic calibration, 573, 575
Probabilistic simulation outputs,
586–587
Projection methods, 129, 134
advantages/disadvantages, 137
boosting, 135
classiﬁcation methods, 143–144
dimension reduction techniques,
134–135
linear regression, 134–135
PLS, 134
training data, 136
Protein-protein interaction networks,
523
psBIL (parametric BIL on the
summary statistic level)
method, 185t, 191
Pseudo-marginal algorithms, 246–248

Index
659
Pseudo-marginal Monte Carlo
methods, 101
Pseudo-observed datasets, 386
Pygmies populations, 542–543, 545
divergence time parameters,
556, 563
introgression events, 550
origin and diversiﬁcation,
546f–547f
Q
Quantile regression analysis, 226–229
R
Radiation, 624
Radiotracer distributions, 3D image,
626
Random forests (RFs) technique,
163–165, 549
ABC model, 549–555, 554t
informative statistics to, 553f
Region of interest (ROI), 626, 628f
Regression adjustment techniques,
71–72
application, 79–80, 79f, 80f, 81f
beneﬁts, 283–285, 283f
ﬁtting regression models, 74–76
homoscedasticity, 74
parameter transformations,
76–77
partial posterior distribution, 72
principle, 73–74, 75f
regression methods, 81–82
rejection algorithm by
adjustment, 73
shrinkage, 77
theoretical results, 77–78
Regression-based emulators, 583
Regularisation approaches, 132
Rejection algorithm
abc, 374
ABCtoolbox, 374–378
by adjustment, 73
Rejection control method, 95–96
Rejection sampling algorithm, 6,
89–91
Relative median absolute deviation
(RMedAD), 556, 558
Resistance acquisition, models,
501–503
drugs at equal rates, 504–505,
505f
posterior predictive distribution,
504f
resistance to drugs, 503–504
Reverse sampler (RS) approach, 192,
194, 195f
RFs. See Random forests (RFs)
technique
Ricker map, 598, 605
RMedAD (relative median absolute
deviation), 556, 558
ROI (region of interest), 626, 628f
Root mean squared errors (RMSEs),
405, 612, 612t
Root mean square error of prediction
(RMSEP), 393f, 406f
R packages, 370–371, 395
abc, 370–371. See also abc R
packages
ABCtoolbox, 370–371. See also
ABCtoolbox R packages
density(), 374, 378, 382
EasyABC, 370–371
hist(), 374
runif(), 373
summary statistics in, 372
RS (reverse sampler) approach, 192,
194, 195f
S
Sample degeneracy, 93
Sea-ice diﬀusivity, 583
Semi-automatic ABC, 135
Semi-parametric hierarchical EL
(SHEL) model, 347
Sequential EP, 421
Sequential history matching, 576–579
Sequential Importance Re-Sampling
(SIR) algorithm, 601–602

660
Index
Sequential importance sampling
(SIS), 110–113
Sequential Monte Carlo (SMC)
algorithm, 4, 109–110, 416,
516, 601
samplers, 113–116. See also
SMC samplers
SIS, 110–113
SFS. See Site-frequency spectrum
(SFS)
SHEL (semi-parametric hierarchical
EL) model, 347
SI (susceptible-infected) model, 196
Simpliﬁcation process, 597–598
Simulated datasets, 133, 159, 636
Simulated quasi-maximum likelihood
(SQML) approach, 182, 324
Simulated versus observed statistics,
383f
Simulation-based methods
inference for SSMs, 600–604
intractable, 597–600
SL versus tolerance-based ABC,
604–608, 606f
Simulations, 395–396
MCMC, 399–402
mechanism, 72
population genetics, 402–407,
403t, 404t
for rejection, 396–399
toy models, ABC, 372–373
Single Nucleotide Polymorphisms
(SNPs), 79, 170–172
Single photon emission computed
tomography (SPECT),
623–624, 624f
SIR (Sequential Importance
Re-Sampling) algorithm,
601–602
SIS (sequential importance
sampling), 110–113
Site-frequency spectrum (SFS),
402–403
Perl script to, 408–409
synonymous, 404t
SL method. See Synthetic likelihood
(SL) method
SLMH. See Synthetic likelihood
Metropolis–Hastings
(SLMH) algorithm
SMC samplers
adaptive schedules, 460–461
algorithm, 458
covariance mutation operator,
463
estimation algorithm
conﬁguration, 467–468, 468f
genetic mutation/cross-over
operators, 461–462
intractable likelihood Bayesian
models, 458–463
mutation kernel choice, 461–463
overview, 456–457
particle ﬁtness/parameters
distributions, 468–470, 469f,
472f
polynomial mutation, 462–463
simulated binary crossover, 462
stages, 457
SNPs (Single Nucleotide
Polymorphisms), 79,
170–172
Spatial extremes application,
199–203, 204f
numerical results on, 429–431,
430f, 431f
overview, 428–429
summary statistics, 429
SPECT (single photon emission
computed tomography),
623–624, 624f
SQML (simulated quasi-maximum
likelihood) approach, 182,
324
State space models (SSMs), 600–601
Statistical inference process, 59–60
Stereological extremes analysis, 7–11,
9f, 232–235
Stochastic agent representation,
445–451

Index
661
Stratiﬁcation strategy, 260
Streptomycin drug, 482
Subset selection methods, 129–130
advantages/disadvantages, 133
approximate suﬃciency, 130
entropy/loss minimisation, 131
mutual information, 131–132
regularisation approaches, 132
related methods, 132
Suﬃcient statistics concept, 128
Summary statistics, 429. See also
Summary statistics
selection methods
in ABC, 23–34, 329–330, 337f
ABC posterior approximations,
38f
in Bayesian LOB, 454–455
data and, 371–372, 372t
inference with ABC, 498–499
mean number, 33, 33t
model choice, 392–395, 395t
for network analysis and
inference, 524
normality plots for, 615f
practical issues with, 28–34
principles, 23–28
in R packages, 372
sampling distribution, ABC,
229–230
selection, 636–638
spatial extremes application,
429
Summary statistics selection
methods, 126–127
ABC model choice, 141–145
asymptotic theory, 132
auxiliary likelihood methods,
137–140
curse of dimensionality, 127
empirical performance, 145–146
projection methods, 134–137
strategies, 129
subset selection methods,
128–133
suﬃcient statistics concept, 128
Susceptible-infected (SI) model, 196
Sweeting, T. J., 65
Synthetic likelihood (SL) method,
230, 322, 600
accelerating, 327–328
Bayesian, 325–327
classical, 323–324
evaluating, 603
technique, 191–192
versus tolerance-based ABC,
604–608, 606f
Synthetic likelihood
Metropolis-Hasting (SLMH)
algorithm, 603–604
Lyapunov exponents for, 616f
posterior densities, 614f
Synthetic log-likelihood function,
607, 607f
Systems biology, ABC in, 532–533
for dynamical systems, 515–519
multi-scale models, 525–532
network analysis and inference,
522–525
overview, 513–514
selection in, 519–522
statistical inference in, 532
T
TAC. See Time activity curve (TAC)
Tail-area probability, 559–560
Terrestrial carbon sink strength
parameters, 587
Threshold parameter, 73, 130
Time activity curve (TAC), 626–627,
636, 637f
Tomographic reconstruction, 625
Toy models, ABC, 371
approximation methods,
215–219, 216f, 217f, 218f
beneﬁts, 371
data and summary statistics,
371–372, 372t
model choice by, 166–170, 168f,
169f, 389t
simulations, 372–373

662
Index
Tracer, nuclear imaging, 624, 628
Tripletwise extremal coeﬃcients,
202–203
True log-likelihood function, 607,
607f
Tuberculosis (TB), acquisition of
MDR in, 482
antibiotic drugs for, 482
conditions, 495–496
cure, recovery, and death,
492
dataset in Bolivia, 484–485
detection and treatment,
492–493
drug resistance, acquisition,
493–494
MDR, 483
mutation of marker, 494–495
patterns, 483
transmission and treatment
failure to MDR, 505–506,
506t
treatment, 482
Tukey P-value, 383–384, 384t
Two one-sided T-test and Z-test,
293–294, 302f
V
Validation, model choice, 390
abc, 390–391
ABCtoolbox, 391–392
Variable numbers of tandem repeats
(VNTRs), 483, 483f
genotypes, 485, 494
loci, 500
model, 485, 488–490, 488f
Voles trapping index, 610, 610f
Voles–weasels model, 611t
Voxel elements, 625–626, 628f
W
Weighted least squares (WLS), 640,
642, 642f, 644
Wilks’ theorem, 341
X
Xetra trading system, 442, 476

