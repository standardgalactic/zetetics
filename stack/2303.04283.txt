FAST AND SLOW PLANNING
A PREPRINT
Francesco Fabiano
University of Parma
francesco.fabiano@unipr.it
Vishal Pallagani
University of South Carolina
vishalp@mailbox.sc.edu
Marianna Bergamaschi Ganapini
Union College
bergamam@union.edu
Lior Horesh
IBM Research
lhoresh@us.ibm.com
Andrea Loreggia
University of Brescia
andrea.loreggia@unibs.it
Keerthiram Murugesan
IBM Research
keerthiram.murugesan@ibm.com
Francesca Rossi
IBM Research
francesca.rossi2@ibm.com
Biplav Srivastava
University of South Carolina
biplav.s@sc.edu
March 9, 2023
ABSTRACT
The concept of Artiﬁcial Intelligence has gained a lot of attention over the last decade. In particular,
AI-based tools have been employed in several scenarios and are, by now, pervading our everyday life.
Nonetheless, most of these systems lack many capabilities that we would naturally consider to be
included in a notion of “intelligence”. In this work, we present an architecture that, inspired by the
cognitive theory known as Thinking Fast and Slow by D. Kahneman, is tasked with solving planning
problems in different settings, speciﬁcally: classical and multi-agent epistemic. The system proposed
is an instance of a more general AI paradigm, referred to as SOFAI (for Slow and Fast AI). SOFAI
exploits multiple solving approaches, with different capabilities that characterize them as either fast
or slow, and a metacognitive module to regulate them. This combination of components, which
roughly reﬂects the human reasoning process according to D. Kahneman, allowed us to enhance the
reasoning process that, in this case, is concerned with planning in two different settings. The behavior
of this system is then compared to state-of-the-art solvers, showing that the newly introduced system
presents better results in terms of generality, solving a wider set of problems with an acceptable
trade-off between solving times and solution accuracy.
Keywords Cognitive Architecture · Planning · Neuro-Symbolic AI
1
Introduction
In the last few years, the AI community has produced several systems and techniques that allow solving autonomously
and efﬁciently intricate problems of various natures. These resolution procedures range from the use of formal logics
to the creation of neural-based structures. The former is an area of study that tries to deﬁne rational behavior for our
systems while the latter, imitating the physiology of our brain, aims to emulate (to some degree) the human behavior.
In this work, we present and analyze an architecture that, exploiting several solving techniques, tackles planning
problems in both the classical and multi-agent epistemic settings. Our contribution is a specialization of the SOFAI
architecture Booch et al. [2021], which, in turn, is inspired by the well-known cognitive theory Thinking Fast and Slow
by Kahneman [2011]. The presented solving approach includes both “fast” and “slow” solvers and a metacognitive
module to orchestrate the two. Slow (or System 2, System-2) solvers are solving problems by reasoning and (usually)
exploiting symbolic techniques, while fast (or System 1, System-1) solvers just employ past experience to identify the
arXiv:2303.04283v1  [cs.AI]  7 Mar 2023

Fast and Slow Planning
A PREPRINT
solution to a given problem. Finally, the metacognitive module provides centralized governance and chooses the best
solver for the problem at hand.
As already mentioned, in this paper, we consider the classical and multi-agent epistemic planning domains. We employ
an instance of the SOFAI architecture that includes i) existing planners as the slow solvers; ii) and both case-based
plan selectors and the so-called Plansformer Pallagani et al. [2022], a Large Language Model (LLM) ﬁne-tuned on
planning problems which is capable of generating satisfying plans, as fast solvers. Experimental results on widely used
planning problem domains show that the behavior of our architecture is better than using the existing planner alone,
both in terms of solved instances and average solving time.
Summarizing, the main contributions of this paper are:
• The deﬁnition of a multi-agent architecture, inspired by the thinking fast and slow theory, to tackle classical
and epistemic planning problems.
• The characterization of fast and slow solvers for the architecture, as well as the metacognitive module.
• Experimental results on planning domains, showing the behavior of the architecture when using different fast
planners.
The paper is structured as follows. After this brief introduction, we introduce the background knowledge on the thinking
fast and slow theory and on classical and epistemic planning. We then describe how to unify the main concepts of the
thinking fast and slow theory in the planning environment, with special emphasis on the metacognitive module and the
solvers. We follow with a description of the experimental setting, tables, and graphs providing the experimental results
showing the behavior of our system on planning problems, and a discussion of such results. We conclude the paper by
summarizing the main contribution and hinting at ongoing work.
2
Background
2.1
Thinking Fast and Slow
Thanks to improved algorithms, techniques, computational power, and dedicated hardware [Marcus, 2020], the various
automated reasoning tools are becoming more and more efﬁcient and reliable in dealing with their areas of interest.
However, all of these tools still lack capabilities that, we humans, naturally consider to be included in a notion of
“intelligence” as, for example, generalizability, robustness, and abstraction. For these reasons, a growing segment of the
AI community is attempting to address these limitations and is trying to create systems that display more “human-like
qualities”. One of the central strategies to tackle this problem, adopted by various research groups Newell [1992], Goel
et al. [2017], Ganapini et al. [2021], envisions tools, usually referred to as cognitive architectures Kotseruba and Tsotsos
[2020], that exploit a combination of both the aforementioned approaches. In particular, in this paper, we explore
classical and multi-agent epistemic planning in the context of one of these architectures that stems from a modern
cognitive theory, i.e., the well-known Thinking Fast and Slow paradigm proposed by D. Kahneman Kahneman [2011].
Kahneman’s theory states that humans’ reasoning capabilities are categorized into two diverse “Systems”, called
System-1 (S1) and System-2 (S2). In particular, S1 identiﬁes the intuitive and imprecise decision-making processes
(“thinking fast”), while S2 provides tools to tackle all those situations where complex decisions need to be taken
following logical and rational thinking (“thinking slow”). Other than problem difﬁculty, S1 and S2 discern which
problem they should tackle based on the experience accumulated on the problem itself. That is, when a new non-trivial
problem has to be solved, it is handled by S2. However, certain problems that initially can be solved only by S2, can
later be solved by S1 after having accumulated a certain amount of experience. The reason is that the procedures used
by S2 to ﬁnd solutions to such problems also accumulate examples that S1 can later use readily with little effort. We
note that S1 and S2 are not systems in the multi-agent sense, but rather they encapsulate two wide classes of information
processing.
2.2
Classical and Multi-agent Epistemic Planning
The idea of automated planning has been present since the birth of AI and it has been widely explored in the computer
science community ever since. This area of research is a branch of artiﬁcial intelligence where the objective is to ﬁnd
plans, that is, sequences of actions, that can lead some acting agent(s) to achieve desired goals.
Its “basic” form is referred to as classical planning. In this setting, in order to have tractable and approachable
problems, domains consider constrained environments, i.e., they have to be i) static; ii) deterministic; and iii) fully
observable [Ghallab et al., 2004]. While is not our intention to provide a detailed explanation of the broad ﬁeld of
2

Fast and Slow Planning
A PREPRINT
classical planning, we address the interested readers to Ghallab et al. [2004], Russell and Norvig [2010], Bolander and
Andersen [2011] for a complete introduction on the topic.
Epistemic planning, on the other hand, is a speciﬁc form of planning where the agents must additionally deal with the
epistemic notions of knowledge and beliefs. In the Multi-agent Epistemic Planning (MEP) problem, there are at least
two planning agents. In what follows, we will only give an intuitive overview of MEP, referring the readers to Fagin
et al. [1995], Baral et al. [2022] for details.
In this setting, we are concerned with ﬁnding the best series of actions that modiﬁes the information ﬂows to enable the
agents to reach goals that refer to physical objects or agents’ knowledge/beliefs Bolander and Andersen [2011]. We will
use the term “knowledge” to encapsulate both the notions of an agent’s knowledge and their beliefs. These concepts are
distinct in Dynamic Epistemic Logic (DEL), which is the underlying basis of the MEP problem, but for simplicity, in
our high-level introduction, we will treat them as one. In an MEP problem, we are concerned with the knowledge of
the agents about the world or about others’ knowledge. This information is expressed through belief formulae, i.e.,
formulae that can express: i) physical properties of the worlds; ii) knowledge of some agent (or group of agents) about
these properties; and iii) nested knowledge about others’ knowledge.
The semantics of DEL formulae is traditionally expressed using pointed Kripke structures Kripke [1963]. The epistemic
action language that we used in our work implements three types of action and three observability relations following
the standard proposed by Baral et al. [2022]. The details of the language are not relevant to present our contribution,
so to avoid unnecessary clutter, we will not present them. Let us just note that each type of action deﬁnes a diverse
transition function and alters an epistemic state in different ways.
Finally, the amount of information carried within a single epistemic state (i.e., a Kripke structure) and the high degree
of liberty derived by complex transition functions (e.g. Baral et al. [2022], Fabiano et al. [2020, 2021]) make planning
in the multi-agent epistemic planning a very heavy-resource process that often brings to the unfeasibility of planning
itself Bolander et al. [2015]. This is in contrast with classical planning where less intricate transition functions and state
representation are used.
3
Thinking Fast and Slow in Planning
Two of the prominent lines of work in AI, i.e., data-driven approaches and symbolic reasoning, seem to embody (even
if loosely) the two Systems presented above. In particular, data-driven approaches shares with S1 the ability to build
(possibly imprecise and biased) models from past experience, often represented by sets of data. For example, perception
activities, such as seeing, that in humans are handled by S1, are currently addressed with machine learning techniques
in AI. Similarly, S2’s capability to solve complex problems using a knowledge-based approach is somewhat emulated
by AI techniques based on logic, search, and planning, which make use of explicit and well-structured knowledge.
While the parallelism data-driven–S1 and symbolic –S2 represent are a starting point in developing an automated fast
and slow AI, we should not assume these two techniques to be the exclusive representative of the respective System.
In this paper, we transpose the concepts derived from the thinking fast and slow paradigm into the classical and
multi-agent epistemic planning settings. We will start by presenting general deﬁnitions for S1 and S2 solvers and then
describe the actual implementations of S1 and S2 reasoners in these settings. We will make use of three models to
represent key modules of our architecture, which from now on we will call Plan-SOFAI. In particular, the model of self
is used to store the experience of the architecture, the model of the world contains the knowledge accumulated by the
system over the external environment and the expected tasks, while the model of others contains the knowledge and
beliefs about other agents who may act in the same environment. Finally, the model updater acts in the background to
keep all models updated as new knowledge of the world, of other agents, or new decisions are generated and evaluated.
The general characterization of a S1 solver, triggered immediately when the problem is presented to Plan-SOFAI, does
not require many factors. These solvers are assumed to rely on the past experience of Plan-SOFAI itself. Moreover, we
assume that the running time for S1 approaches to be independent of the input and, instead, to depend on the experience
accumulated by the overall architecture, in the model of self. Finally, we consider a S1 solver to be an entity that relies
on “intuition” (with a slight abuse of notation). Taking into account these characteristics, the next question that naturally
arises is can classical and epistemic planning ever be considered as S1 tasks, considering that planners, traditionally,
always rely on look-ahead strategies? We considered some ideas that could help us develop a S1 planner. Among those,
only a few were not using search methods (intensively) but rather mostly relied on experience. Finally, we identiﬁed
two feasible, yet functional, ways to exploit experience in the aforementioned planning settings.
The ﬁrst approach makes use of pre-computed plans; that is, S1 can be used to determine which of the plans already
generated by past experiences is the one that “ﬁts the best” the current problem. Of course, determining if an already
computed plan is a good choice or not for the current problem is a difﬁcult research question on its own. Since the
3

Fast and Slow Planning
A PREPRINT
focus of this work is to devise a fast and slow architecture for planning rather than optimizing its internal components,
we decided to use a simple, yet effective, criterion to select the best-ﬁtting plan. In particular, the ﬁrst variation of S1
selects, among past solutions for the same domain, the pre-computed plan that is the closest in terms of Levenshtein
Distance and Jaccard Similarity Rinartha et al. [2018], as we will see in more detail later.
Instead, the latter version of S1, referred to as Plansformer Pallagani et al. [2022], is based on a learning mechanism
using LLMs pre-trained in coding languages such as Python, Java, and Ruby. The intuition behind selecting a code-based
LLM is to inherit the syntactical knowledge, similar to the family of languages used to deﬁne a planning problem.
Plansformer is ﬁne-tuned on CodeT5 [Wang et al., 2021] using planning problem instances and their corresponding
plans. Given a new problem instance, Plansformer is capable of generating valid plans ∼90% of the time, along with
the conﬁdence score for the generated plan. The conﬁdence score is computed using the average non-zero probabilities
of the generated tokens present in the plan given as output by Plansformer.
Our Plan-SOFAI is a S1-by-default architecture: whenever a new problem is presented, a S1 solver with the necessary
skills to solve the problem starts working on it, generating a solution and a conﬁdence level. This allows to minimize
the resource consumption making use of the much faster S1 solving process when there is no need for S2—that is when
the solution proposed by S1 is “good enough”. Nevertheless, as for the human brain, S1 may encounter problems that it
cannot solve, either due to its lack of experience or the inherent intricacy of the problem itself. These situations require,
then, the use of more thought-out resolution processes, generally provided by S2 approaches. Notice that we do not
assume S2 solvers to be always better than S1 solvers: given enough experience, some tasks could be better solved
by S1 solvers. This behavior also happens in human reasoning [Gigerenzer and Brighton, 2009]. Similarly, we don’t
assume S1 to be always more efﬁcient than S2; in fact, if the problem is very simple it is possible that the “well-thought”
process of S2 could take less time than S1.
As for S2 we considered solving procedures, different depending on the setting, that employ traditional planning
strategies. For classical planning, we used the state-of-the-art Fast Downward solver Helmert [2006]. In the case of
MEP, instead, we decided to employ EFP 2.0 by Fabiano et al. [2020].
4
The Fast and Slow Paradigm
4.1
The SOFAI Architecture
As the main contribution of this paper, we present an architecture1 inspired by cognitive theories to solve the classical
and multi-agent epistemic planning problems. In particular, our tool is heavily based on a recent architecture called
SOFAI Ganapini et al. [2021] that is, in turn, inspired by the dual-system proposed by Kahneman [2011]. Following the
ideas of Kahneman, the architecture is equipped with two types of Systems dedicated to computing a solution to an
incoming task, and a third agent in charge of orchestrating the overall reasoning task.
In this architecture, incoming problems are initially handled by S1 solvers that have the required skills to tackle them.
S1 solvers compute a solution relying on the past experience collected by the architecture. The computation is not
affected by the size of the input problem and thus S1 solvers provide a solution in constant time. Past experience is
maintained in the model of the world, while the model of others maintains knowledge and beliefs over other agents that
may act in the same environment. A model updater agent is in charge of keeping all models updated as something new
happens (e.g., new decisions are generated).
The solution computed by the S1 solver (from now on for the sake of simplicity, let us assume it is just one S1 solver)
and the corresponding conﬁdence level is made available to the metacognitive (MC) module which can now choose
between the proposed solution or engaging a S2 solver. An S2 agent is typically a reasoning model that is able to deal
with the current problem, this kind of solver is more demanding in terms of time and other types of resources. For this
reason, only MC agent can decide to activate an S2 solver.
MC agent assessment is based on several checks that are devoted to establishing whether it is worth adopting the
solution proposed by S1 or engaging S2 for a more accurate solution. This allows for minimizing time to action when
there is no need for S2 processing.
4.2
The Metacognitive Module
For our MEP solver, following the SOFAI architecture Ganapini et al. [2021], we also deﬁned a metacognition process.
This means that we want our Plan-SOFAI to be equipped with a set of mechanisms that allows it to both monitor
and control its own cognitive activities, processes, and structures. The goal of this form of control is to improve the
1Link to repository removed to preserve the authors’ anonymity.
4

Fast and Slow Planning
A PREPRINT
quality of the system’s decisions. Metacognition models have been largely studied [Cox, 2005, Kralik et al., 2018,
Kotseruba and Tsotsos, 2020, Posner, 2020] in the past years. Among the various proposed modalities, we envisioned
our Plan-SOFAI to have a centralized metacognitive module that exploits both internal and external data and arbitrates
between S1 and S2 solvers. Let us note that this module is structurally and conceptually different from an algorithm
portfolio selection [Kerschke et al., 2019].
We propose a metacognitive module that itself follows the thinking fast and slow paradigm. This means that our MC
module is comprised of two main phases: the ﬁrst one takes intuitive decisions without considering many factors,
while the second one is in charge of carefully selecting the best-solving strategy, considering all the available elements
whenever the ﬁrst phase did not manage to return an adequate solution. We will refer to the former with MC-1 and to
the latter with MC-2.
MC-1 is in charge of deciding whether to accept the solution proposed by the S1 solver or to activate MC-2. MC-1
takes this decision considering the conﬁdence, among other few factors, of the S1 solver: if the conﬁdence, which
usually depends on the amount of experience, is high enough, MC-1 adopts the S1 solver’s solution.
If MC-1 decides that the solution of the S1 solver is not “good enough”, it engages MC-2. Intuitively, this module
needs to evaluate whether to accept the solution proposed by the S1 solver or which S2 solver to activate for the task. To
do this, MC-2 compares the expected reward for the S2 solver with the expected reward of the S1 one: if the expected
additional reward of running the S2 solver, compared to the S1 one, is large enough, then MC-2 activates the S2 solver.
MC-2, following the human reasoning model [Shenhav et al., 2013], is designed to avoid costly reasoning processes
unless the additional cost is compensated by an even greater expected reward for the solution that the S2 solver will
devise.
5
Metacognition at Work
In what follows, we provide a “concrete” view of the S1/S2 framework for the above-mentioned settings. To do so, we
will make use of Algorithms 1–3.
Before going into detail, let us brieﬂy comment on the input and on the parameters of these algorithms. The process
requires the domain description (D), a particular instance (I) that we want to solve on such domain, and the time
limit (TL) within which the instance needs to be solved. The parameters, instead, represent some internal values
that capture some sort of “inclination” of the architecture towards employing S1. In particular, we have that: i) the
acceptable correctness (A) represents the minimum ratio of solved goals, w.r.t. the total number of them, that deﬁnes
an acceptable solution. Let us note that this measure can also be changed to depend on other factors or to account for
goals’ importance, for example. Its default value is 0.5; ii) T1 represents the minimal amount of experience required
by Plan-SOFAI to consider a solution proposed by S1. Its default value is set to 20; iii) T2 represents the minimum
number of S1 usages after which it will consider S1 accountable for its mistakes. This threshold allows the architecture
to initially try to employ S1 more freely, to augment its experience. Conversely, after the minimum number T2 of
solutions, the metacognition actually uses the previous performances of S1 to check for S1 accountability. Its default
value is set to 20; iv) T3 is a value between 0 and 1 and it is used to represent the risk-aversion of the architecture: the
higher the value the more incline Plan-SOFAI is to use S2. The default value is set to 0.6; v) ϵ is a factor that is used to
scale the probability that S1 solution may actually be employed even if it was not considered convenient. This is added
to increase the number of S1 usages, and consequently its experience, in those situations where the low conﬁdence of
S1 itself may limit it too aggressively. Let us note that the solution proposed by S1 needs to be validated before being
accepted in any case (Line 2 of Algorithm 2). Its default value is 0.1; vi) (M) represents the experience of Plan-SOFAI.
Every time a solution for a problem is found, this is stored in the memory with a series of useful information, e.g., the
correctness value, the employed system (i.e., S1 or S2), the difﬁculty of the instance, the required time, and so on.
We are now ready to describe in more detail Algorithms 1–3. Let us start by presenting Algorithms 1. In particular, we
can identify MC-1 in Lines 1–16, and MC-2 in Lines 17–39. As already mentioned, to better emulate the thinking
fast and slow paradigm, we assume System-1 to automatically start and provide a solution at the beginning of MC-1.
That is why we start the metacognitive process by storing the results of such process in the variables p and cx, which
represent the solution found by S1 and the conﬁdence that S1 has about this solution appropriateness, respectively. The
metacognitive process then proceeds to check whether the experience accumulated by the architecture is enough to
consider S1 reliable (Line 3). If the architecture has enough experience, the metacognition considers the conﬁdence of
S1, adjusted to take into account the previous solutions proposed by S1 itself (Lines 4–12), and determines whether S1’s
conﬁdence is within the tolerated risk, identiﬁed by T3 (Line 13). If the conﬁdence of S1 is enough, then Plan-SOFAI
tries to employ S1’s solution (line 14).
5

Fast and Slow Planning
A PREPRINT
Algorithm 1 Fast and Slow MEP Architecture
Input: Domain (D), Instance (I), Time Limit (TL)
Parameter: Acceptable Correctness (A), T1, T2, T3, ϵ, Memory (M),
Output: Plan (S), Correctness (C)
1: Let p be the solution of I found by S1
2: Let cx be the conﬁdence of S1 on p.
3: if |M.solved_instances(D)| ≥T1 then
4:
if |M.solved_instances(D, S1)| < T2 then
5:
Let K = 0
6:
else
7:
Let avg_corr = 0
8:
for all i ∈M.solved_instances(D, S1) do
9:
avg_corr + = |i.solved_goals()|
|i.tot_goals()|
10:
end for
11:
Let K = 1−avg_corr
12:
end if
13:
if cx × (1 −K) ≥T3 then
14:
return ⟨S,C⟩= try_S1(p, D, I, TL)
15:
end if
16: end if
17: Let diff = I.compute_difficulty()
18: Let est_t = M.avg_t_from_diff(diff)
19: Let rem_t = TL −elapsed_t
20: Let est_cost = est_t
rem_t
21: if est_cost > 1 then
22:
return ⟨S,C⟩= try_S1(p, D, I, TL)
23: else
24:
Let prob = (1 −T3) × ϵ
25:
if prob ≥generate_random_number(0, 1) then
26:
return ⟨S,C⟩= try_S1(p, D, I, TL)
27:
else
28:
C = |I.solved_goals(p)|
|I.tot_goals()|
29:
if C ≥A then
30:
if (1 −(est_cost × (1 −T3)) ≥C × (1 −K) then
31:
return ⟨S, C⟩= solve_with_S2(p,D,I,rem_t)
32:
else
33:
return ⟨S = p,C⟩
34:
end if
35:
else
36:
return ⟨S, C⟩= solve_with_S2(null,D,I,rem_t)
37:
end if
38:
end if
39: end if
If at any point, S1’s solution is considered not appropriate by the metacognitive process—because it violates some
checks—then MC-2 starts. This part of the procedure begins by determining a value that represents the difﬁculty of the
problem instance (derived by various factors such as the number of agents, possible actions, ﬂuents, and so on) at Line
17. This measure is then used to determine the average solving time for a given difﬁculty and to estimate the cost of
solving the given problem (Line 18–20). If the cost exceeds 1 then there is not enough time to call S2 and Plan-SOFAI
tries to employ S1. The system can also adopt S1 with a probability that is related to the risk aversion T3 and a parameter
ϵ, this is done in Lines 24–26, to improve the exploration skill of the architecture itself. Plan-SOFAI evaluates the
solution proposed by S1 and, if it is acceptable (Line 29), whether the extra time required by S2 counterbalanced the
cost (Line 30). If the solution is not acceptable or the increase in correctness is big enough S2 is called (Line 36 and 31,
respectively), otherwise the solution proposed by S1 is used (Line 33).
Algorithms 2 and 3 are instead used to try and adopt the solution proposed by S1 and to try and solve the problem with
S2, respectively. In particular, Algorithms 2 takes the solution proposed by S1 and checks whether it has an acceptable
6

Fast and Slow Planning
A PREPRINT
Algorithm 2 try_S1 function
Input: Plan (p), Domain (D), Instance (I), Time Limit (TL)
Parameter: Acceptable Correctness (A)
Output: Plan (S), Correctness (C)
1: C = |I.solved_goals(p)|
|I.tot_goals()|
2: if C ≥A then
3:
return ⟨S = p, C⟩
4: else
5:
return ⟨S, C⟩= solve_with_S2(null,D,I,TL)
6: end if
Algorithm 3 solve_with_S2 function
Input: Plan (p), Domain (D), Instance (I) Time Limit (TL)
Output: Plan (S)
1: if S2 (D,I) terminates within TL then
2:
return ⟨S = S2.get_plan(), C = 1⟩
3: else if p ! = null then
4:
return ⟨S = p, C = |I.solved_goals(p)|
|I.tot_goals()|
⟩
5: else
6:
OPT-OUT
7: end if
degree of correctness. If it does then the solution is employed, otherwise, Algorithm 3 is called. This function simply
calls the S2 approach (i.e., Fast Downward or EFP 2.0, depending on the setting) on the instance of the problem to solve
and, if it terminates before the available time ends, it returns the plan found by the S2 planner with conﬁdence equal to
1. If S2 cannot ﬁnd the solution within the time limit then the solution from S1, if acceptable, is adopted; otherwise,
Plan-SOFAI returns no solution and terminates.
5.1
S1 and S2 solvers
While in the previous paragraph, we described how our architecture decides which solving approach is the most
appropriate, here we will provide a high-level overview of solving processes themselves. In particular, we designed our
S1 solvers to solely rely on past experience.
The ﬁrst type of S1 solver, which is the case-based one, analyzes the memory and looks, through the various solved
instances (using either S1 itself or S2), which one is the closest to the problem that is being tackled. Once the closest
instance is identiﬁed, S1 returns the plan associated with it as a solution and the distance value as a measure for
conﬁdence. This distance can be calculated in two different ways, generating effectively two different S1 solvers2. The
ﬁrst measure of distance considers the problems as a set of formulae, i.e., the ones that comprise the initial and goal
states, and adopts the well-known Jaccard Similarity Rinartha et al. [2018], that is the ratio between the union and
the intersection of the two sets we are considering, as a metric for ﬁnding similarity between the input problem and
the instances existing in the case library. The second metric is calculated by transforming the two instances into two
distinct strings, once again comprised of all the initial and goal states information (separated by the special characters
“|”), that are then compared using the Levenshtein distance Haldar and Mukhopadhyay [2011] to determine the actual
distance measure. Let us note that since we are considering only instances of the same domain, there is no need to
incorporate other information. Nonetheless, if we would like to compare also instances of different domains, the
domains’ descriptions could easily be added to the representative of each instance.
The other type of S1 takes the domain and problem description of a planning instance and maps it to a sequential prompt
given as input to Plansformer Pallagani et al. [2022]. The output obtained is a plan along with the associated conﬁdence
score. Let us note that this S1 makes use of a pre-computed training set and does not increase its experience during the
solving phase. This is a design choice and we leave the exploration of Plansformer with “dynamic" training as a future
work. Furthermore, Plansformer currently can only handle classical planning problems and not epistemic ones. This is
because of Plansformer’s limitations on the input token length, which is currently 512. In fact, MEP problems given
2We compare the performances of these two S1 solvers later in the paper.
7

Fast and Slow Planning
A PREPRINT
their higher intricacy, when converted to the prompt desired by Plansformer, cross the 512 tokens limit. Once again, we
working to solve this issue is but leave the full integration of Plansformer in MEP as future work.
Finally, while for S1 we needed to implement ad-hoc solutions, the same is not true for S2 planners. In fact, as
mentioned we employed the state-of-the-art classical and epistemic planners, i.e., Fast Downward and EFP 2.0, as our
S2 solvers. Given that explaining how these planners work is beyond the scope of this paper, we can safely assume these
approaches to be black boxes that return the best possible solutions, if exist. Nonetheless, we refer the interested readers
to Helmert [2006], Fabiano et al. [2020] for a detailed explanation of the internal mechanisms of Fast Downward and
EFP 2.0, respectively.
6
Experimental Results and Discussion
6.1
Experimental Setup
In this section, we compare the new architecture introduced as the main contribution of this paper with Fast Down-
ward Helmert [2006] and EFP 2.0 Fabiano et al. [2020] that, to the best of our knowledge, are the state-of-the-art solver
in the respective ﬁelds. All the experiments were performed on a 3.00GHz Intel Core i7-5500U machine with 16GB of
memory.
As benchmarks, we used two distinct domains, depending on the type of planning we wanted to analyze. To evaluate
classical planning we employed the well-known Blocks-World (BW) domain [Gupta et al., 1991]. In this domain,
the acting agent is a mechanical arm that can move blocks and can determine whether it is holding one or not. The
mechanical arm can only hold, and therefore move, one block at the same time; and a block can only be placed on top
of a clear block—a block with no blocks on top of it and that is not held by the mechanical arm—or on the table. The
goals in this domain refer to speciﬁc conﬁgurations of the blocks.
For MEP we employed a small variation of the standard epistemic planning domain known as Coin in the Box
(CB) Kominis and Geffner [2015], Huang et al. [2017], Baral et al. [2022]. In this domain, n ≥2 agents are in one of
two rooms, one of which contains a box with a coin inside. In the initial conﬁguration, everybody knows that: i) none of
the agents know whether the coin lies heads or tails up; ii) the box is locked; iii) only one agent has the key that opens
the box; iv) each agent might be attentive or not w.r.t. to certain actions execution; Moreover, we know that each agent
can execute one of the following actions: 1) move: an agent can move to the other room; 2) open: an agent, if it has the
key, can open the box; 3) peek: to learn whether the coin lies heads or tails up, an agent can peek into the box, but this
requires the box to be open; 4) announce: this will result in all the listening (i.e., attentive) agents to believe that the
coin lies heads or tails up depending on the announced value; 5) distract/signal another agent: these actions will
make an attentive agent no more attentive or vice-versa, respectively. The goals usually consist of some agents knowing
whether the coin lies heads or tails up while other agents know that it knows, or are ignorant about this.
The experiments for classical planning are comprised of 700 different problems that vary the initial state, goal state, and
a number of blocks. Of these, 150 are instances with 4 blocks, 150 with 5, 100 with 10, 100 with 11, 100 with 12, and
100 with 13. Similarly, for epistemic planning, we used a set of 240 different instances of the CB domain3.
Regarding the various input and parameters of the architecture (used in Algorithms 1, 2, 3) we imposed: i) a Time Limit
(TL) of 60 and 90 seconds to solve each instance for classical and epistemic, respectively; ii) an Acceptable Correctness
(A) of 0.5, meaning that at least half of the goals must be satisﬁed for a S1 solution to be considered; iii) the various
thresholds (i.e., T1, T2, T3) and ϵ to have their default values; and iv) the Memory (M) to be initially ﬁlled with 25
already solved problems in the case of classical planning and empty for MEP.
6.2
Results
As a baseline for our experiments, we used the solvers Fast Downward Helmert [2006] and EFP 2.0 Fabiano et al.
[2020]. As mentioned, we let the solvers tackle all the instances with a time-out of 60/90 seconds per instance. The main
idea is that these approaches represent the current capabilities of classical and epistemic planning and are comparable to
a solely S2-based architecture. While these approaches are guaranteed to ﬁnd the best solution, if this exists, they are
not ﬂexible enough to adapt to situations where the resources, namely time, are limited.
We then compared the baseline results with different conﬁgurations of the architecture presented in this paper (Tables 1
and 2). To avoid unnecessary clutter, let us identify the various conﬁgurations, with the following abbreviations:
3Let us note that given the intricacy of epistemic reasoning, we opted for fewer instances to have reasonable testing times.
8

Fast and Slow Planning
A PREPRINT
Figure 1: Time comparison between Mix and Fast Downward.
Figure 2: Time comparison between Jac and EFP 2.0.
• Jac: the conﬁguration of the architecture where the S1 makes use of the Jaccard similarity as a notion of
distance;
• Lev: the conﬁguration where the metric for the distance between problems is deﬁned through Levenshtein
distance (not reported in classical as it performed worse than Jac in every aspect);
• Plf: the conﬁguration where S1 employs Plansformer as S1.
• Mix: the conﬁguration where S1 chooses the most similar instance in the memory, w.r.t. the given problem, by
selecting the highest (normalized) score between the ones calculated with all the available S1 in the architecture
(let us recall that we could not employ Plansformer to tackle MEP problems);
• Rng: the conﬁguration where the S1 randomly picks one of the instances in memory as “most similar”
without even considering a notion of distance. This approach was inserted as a baseline to outperform with a
well-thought S1.
Tables 1 and 2 show that Mix and Jac (for classical and epistemic, respectively) are the best all-around conﬁgurations,
with the most number of solved instances, the lowest average solving times and the highest average correctness of
Plan-SOFAI. To provide further analysis we present, in Figures 1 and 2, the plots that show the resulting times of
these conﬁgurations against Fast Downward and EFP 2.0. In these, the instances (x-axis) are sorted w.r.t. the notion
of “difﬁculty" and, in the particular case of classical planning we grouped the instances with the same number of
blocks4. The results for classical planning show that when the problem is “simple enough" Fast Downward outperforms
Plan-SOFAI but, as soon as the instances grow in difﬁculty, the constant time required by S1 begins to outperform Fast
Downward making Plan-SOFAI a reliable tool to solve the hardest conﬁgurations in a time-constrained environment.
In the epistemic settings, instead, all the solving time of Jac outperforms EFP 2.0 (equal or lower height on the y-axis).
Let us note that the instances which are placed exactly on the top of the plot, i.e., on the 60/90 seconds line, are the ones
that have timed out.
44 in pink, 5 in green, 10 in yellow, 11 in purple, 12 in orange, and 13 in white.
9

Fast and Slow Planning
A PREPRINT
FD
Jac
Plf
Mix
Rng
Solved
586
593
671
671
587
(+5%)
(+19%)
(+19%)
(+0.2%)
Time (avg)
12.289
11.609
18.687
18.480
12.232
Corr (avg)
0.84
0.79
0.89
0.90
0.80
S1 calls
0
151
626
624
68
Table 1: Comparison between Fast Downward (FD) and the diverse conﬁgurations of Plan-SOFAI on various parame-
ters. The row Solved expresses the number of instances, out of the 700, that have been solved with correctness at least
superior to 0.5. Time is expressed in seconds and the correctness (Corr), being the ratio between solved goals and their
total number, is a measure between 0 and 1. All the results also consider the instances that could not be solved, to these
we assigned 60 seconds as time and 0 as correctness.
EFP 2.0
Jac
Lev
Mix
Rng
Solved
149
222
207
197
181
(+49%)
(+39%)
(+32%)
(+21%)
Time (avg)
42.737
14.495
19.608
20.001
27.755
Corr (avg)
0.62
0.81
0.89
0.67
0.66
S1 calls
0
86
74
115
69
Table 2: Comparison between EFP 2.0 and the diverse conﬁgurations of our architecture on various parameters. The
table schema follows Table 1. In this setting, we assigned 90 seconds to the unsolved instances.
6.3
Discussion
Tables 1 and 2 and Figures 1 and 2 highlight some interesting results about our architecture. In particular, thanks to its
ability to “adapt” to resources constraints, our architecture can provide a ﬂexible tool to solve instances even for those
settings where the inherent complexity of the problems (e.g., multi-agent epistemic planning) brings unfeasibility to
the solving process. Our proposal can be seen as a way to exploit the accumulated experience, in a human fashion, to
quickly solve known problems that otherwise would require a lot of effort.
Moreover, the trade-off offered by allowing not-fully correct, but sound, plans is also a way to produce a solution that,
even if partial, can be more useful than no solution at all. Let us note that some of the solved problems by S1, and not by
S2, do not have a solution that can satisfy all the goals. While, for example in MEP, the planning process cannot detect
these situations given the undecidability of MEP Bolander et al. [2015], our architecture simply reports a plan to reach
some of the subgoals, providing once again a better alternative to no plan at all. Nonetheless, the parametric nature of
the architecture allows also us to tweak it so that it only accepts fully correct plans. This can be done by setting the
value of the acceptable correctness (A) to 1. With this small change, the architecture will only return plans that reach the
goal state while still taking advantage of the S1 capabilities of the architecture (albeit S1 solutions would be adopted
fewer times). The same goes for the other internal parameters that easily allow the user to modify the architecture so
that it is more prone to accept less accurate solutions in favor of saving time, and vice-versa.
Another interesting result that we can deduce from Tables 1 and 2 is that the employment of Mix is worse than both Jac
and Lev in epistemic while it is the best conﬁguration in classical. While, at ﬁrst glance, this might seem a contradictory
result it actually shows that the balance between the usage of S1 and S2 need to be preserved by the architecture. In fact,
as Mix, in epistemic, uses the combination of Jac and Lev, the number of times that a solution of S1 is employed is
higher than the two approaches (115 against 86 and 74). This makes it so that the architecture has fewer opportunities to
increase its experience that can be re-used later to solve different problems. Contrarily in classical, Plf does not rely on
the knowledge accumulated during the solving phase and remains a viable tool during all the resolution process making
10

Fast and Slow Planning
A PREPRINT
the additions provided by Jac an enrichment to the overall performances. While it is not easy to ﬁnd the best trade-off
for limiting the employment of S1, it is our intention to deﬁne ways to automatically tune the internal parameters of the
architecture so that it can exploit at maximum its capabilities.
7
Conclusions and Ongoing Work
In this work, we presented an architecture to tackle planning problems, in different settings, that is heavily inspired
by the well-known cognitive theory Thinking Fast and Slow by Kahneman [2011]. This tool builds on the SOFAI
architecture Ganapini et al. [2021], which makes use of a metacognitive process to arbitrate the solving processes, and
two solvers referred to as System-1 and System-2. While S2 is directly derived from the literature the S1 solvers
have been designed ad-hoc for the proposed architecture to exploit past experience. The SOFAI-inspired approach
showed very promising results outperforming the state-of-the-art planners in different metrics. Another advantage of
the proposed architecture is that it can be used to incorporate new solving techniques developed by the community.
In fact, our tool can be easily modiﬁed to employ different S1 or S2, or multiple versions of them. We are currently
working on a version of the architecture that allows for multiple S2 in epistemic planning, in particular both EFP 2.0
and RP-MEP Muise et al. [2015].
References
Grady Booch, Francesco Fabiano, Lior Horesh, Kiran Kate, Jonathan Lenchner, Nick Linck, Andrea Loreggia,
Keerthiram Murugesan, Nicholas Mattei, Francesca Rossi, and Biplav Srivastava. Thinking fast and slow in AI. In
Proceedings of the 35th AAAI conference, pages 15042–15046, 2021.
Daniel Kahneman. Thinking, Fast and Slow. Macmillan, 2011.
Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Lior Horesh, Biplav Srivastava,
Francesco Fabiano, and Andrea Loreggia. Plansformer: Generating symbolic plans using transformers, 2022. URL
https://arxiv.org/abs/2212.08681.
Gary Marcus. The next decade in ai: Four steps towards robust artiﬁcial intelligence, 2020.
Allen Newell. SOAR as a uniﬁed theory of cognition: Issues and explanations. Behavioral and Brain Sciences, 15(3):
464–492, 1992.
Gautam Goel, Niangjun Chen, and Adam Wierman. Thinking fast and slow: Optimization decomposition across
timescales. In 2017 IEEE 56th Annual Conference on Decision and Control (CDC), pages 1291–1298. IEEE, 2017.
Marianna Bergamaschi Ganapini, Murray Campbell, Francesco Fabiano, Lior Horesh, Jon Lenchner, Andrea Loreggia,
Nicholas Mattei, Francesca Rossi, Biplav Srivastava, and Kristen Brent Venable. Thinking fast and slow in AI: the
role of metacognition. CoRR, abs/2110.01834, 2021. URL https://arxiv.org/abs/2110.01834.
Iuliia Kotseruba and John K. Tsotsos. 40 years of cognitive architectures: core cognitive abilities and practical
applications. Artiﬁcial Intelligence Review, 53(1):17–94, Jan 2020. doi:10.1007/s10462-018-9646-y.
Malik Ghallab, Dana Nau, and Paolo Traverso. Automated Planning: theory and practice. Elsevier, 2004.
Stuart J. Russell and Peter Norvig. Artiﬁcial Intelligence - A Modern Approach, Third International Edition. Pearson
Education, 2010. ISBN 978-0-13-207148-2. URL http://vig.pearsoned.com/store/product/1,1207,
store-12521_isbn-0136042597,00.html.
Thomas Bolander and Mikkel Birkegaard Andersen. Epistemic planning for single-and multi-agent systems. Journal of
Applied Non-Classical Logics, 21(1):9–34, 2011. doi:10.1016/0010-0277(83)90004-5.
Ronald Fagin, Yoram Moses, Joseph Y. Halpern, and Moshe Y. Vardi. Reasoning About Knowledge. MIT press, 1995.
ISBN 9780262061629.
Chitta Baral, Gregory Gelfond, Enrico Pontelli, and Tran Cao Son. An action language for multi-agent domains.
Artiﬁcial Intelligence, 302:103601, 2022. ISSN 0004-3702. doi:https://doi.org/10.1016/j.artint.2021.103601. URL
https://www.sciencedirect.com/science/article/pii/S0004370221001521.
Saul A. Kripke. Semantical analysis of modal logic i normal modal propositional calculi. Mathematical Logic Quarterly,
9(5-6):67–96, 1963. doi:10.1002/malq.19630090502.
Francesco Fabiano, Alessandro Burigana, Agostino Dovier, and Enrico Pontelli. EFP 2.0: A multi-agent epistemic
solver with multiple e-state representations. In Proceedings of the Thirtieth International Conference on Automated
Planning and Scheduling, Nancy, France, October 26-30, 2020, pages 101–109. AAAI Press, 2020. URL https:
//aaai.org/ojs/index.php/ICAPS/article/view/6650.
11

Fast and Slow Planning
A PREPRINT
Francesco Fabiano, Alessandro Burigana, Agostino Dovier, Enrico Pontelli, and Tran Cao Son. Multi-agent epistemic
planning with inconsistent beliefs, trust and lies. In PRICAI 2021, Hanoi, Vietnam, November 8-12, 2021, Proceedings,
Part I, volume 13031 of Lecture Notes in Computer Science, pages 586–597. Springer, 2021. doi:10.1007/978-3-030-
89188-6_44.
T. Bolander, M.H. Jensen, and F. Schwarzentruber. Complexity results in epistemic planning. In IJCAI International
Joint Conference on Artiﬁcial Intelligence, volume 2015-January, pages 2791–2797, 2015.
Komang Rinartha, Wayan Suryasa, and Luh Gede Surya Kartika. Comparative analysis of string similarity on dynamic
query suggestions. In 2018 Electrical Power, Electronics, Communications, Controls and Informatics Seminar
(EECCIS), pages 399–404, 2018. doi:10.1109/EECCIS.2018.8692996.
Yue Wang, Weishi Wang, Shaﬁq Joty, and Steven CH Hoi. Codet5: Identiﬁer-aware uniﬁed pre-trained encoder-decoder
models for code understanding and generation. arXiv preprint arXiv:2109.00859, 2021.
G. Gigerenzer and H. Brighton. Homo heuristicus: why biased minds make better inferences. Top Cogn Sci, 1(1):
107–143, Jan 2009. doi:10.1111/j.1756-8765.2008.01006.x.
Malte Helmert. The fast downward planning system. Journal of Artiﬁcial Intelligence Research, 26:191–246, 2006.
Michael T. Cox. Metacognition in computation: A selected research review. Artiﬁcial Intelligence, 169(2):104–141,
2005. ISSN 0004-3702. doi:https://doi.org/10.1016/j.artint.2005.10.009. URL https://www.sciencedirect.
com/science/article/pii/S0004370205001530. Special Review Issue.
Jerald D. Kralik, Jee Hang Lee, Paul S. Rosenbloom, Philip C. Jackson, Susan L. Epstein, Oscar J. Romero,
Ricardo Sanz, Othalia Larue, Hedda R. Schmidtke, Sang Wan Lee, and Keith McGreggor.
Metacognition
for a common model of cognition.
Procedia Computer Science, 145:730–739, 2018.
ISSN 1877-0509.
doi:https://doi.org/10.1016/j.procs.2018.11.046. URL https://www.sciencedirect.com/science/article/
pii/S1877050918323329. Postproceedings of the 9th Annual International Conference on Biologically Inspired
Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in
Prague, Czech Republic.
Ingmar Posner. Robots thinking fast and slow: On dual process theory and metacognition in embodied AI, 2020. URL
https://openreview.net/forum?id=iFQJmvUect9.
Pascal Kerschke, Holger H. Hoos, Frank Neumann, and Heike Trautmann. Automated algorithm selection: Survey and
perspectives. Evol. Comput., 27(1):3–45, 2019. doi:10.1162/evco_a_00242.
Amitai Shenhav, Matthew M. Botvinick, and Jonathan D. Cohen.
The expected value of control: An inte-
grative theory of anterior cingulate cortex function.
Neuron, 79(2):217–240, July 2013.
ISSN 0896-6273.
doi:10.1016/j.neuron.2013.07.007.
Rishin Haldar and Debajyoti Mukhopadhyay. Levenshtein distance technique in dictionary lookup methods: An
improved approach. arXiv preprint arXiv:1101.1232, 2011.
Naresh Gupta, Dana S Nau, et al. Complexity results for blocks-world planning. In AAAI, volume 91, pages 629–633.
Citeseer, 1991.
Filippos Kominis and Hector Geffner. Beliefs in multiagent planning: From one agent to many. In Proceedings of the
Twenty-Fifth International Conference on Automated Planning and Scheduling, ICAPS 2015, Jerusalem, Israel, June
7-11, 2015, pages 147–155. AAAI Press, 2015. URL http://www.aaai.org/ocs/index.php/ICAPS/ICAPS15/
paper/view/10617.
Xiao Huang, Biqing Fang, Hai Wan, and Yongmei Liu. A general multi-agent epistemic planner based on higher-order
belief change. In Proceedings of the Twenty-Sixth International Joint Conference on Artiﬁcial Intelligence, IJCAI
2017, Melbourne, Australia, August 19-25, 2017, pages 1093–1101. ijcai.org, 2017. doi:10.24963/ijcai.2017/152.
Christian J. Muise, Vaishak Belle, Paolo Felli, Sheila A. McIlraith, Tim Miller, Adrian R. Pearce, and Liz Sonenberg.
Planning over multi-agent epistemic states: A classical planning approach. In Proceedings of the Twenty-Ninth AAAI
Conference on Artiﬁcial Intelligence, January 25-30, 2015, Austin, Texas, USA, pages 3327–3334. AAAI Press, 2015.
URL http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9974.
12

