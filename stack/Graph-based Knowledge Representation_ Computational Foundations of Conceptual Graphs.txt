
Advanced Information and Knowledge Processing 
Series Editors 
Professor Lakhmi Jain 
Lakhmi.jain@unisa.edu.au 
Professor Xindong Wu 
xwu@cs.uvm.edu 
For other titles published in this series, go to 
http://www.springer.com/4738

Michel Chein   Marie-Laure Mugnier 
Graph-based 
Knowledge 
Representation 
Computational Foundations of Conceptual Graphs 
ABC

Michel Chein
Laboratory of Informatics, Robotics, and
Micro-electronics (LIRMM)
FRANCE
Marie-Laure Mugnier
Laboratory of Informatics, Robotics, and
Micro-electronics (LIRMM)
FRANCE
AI&KP ISSN 1610-3947
ISBN: 978-1-84800-285-2
e-ISBN: 978-1-84800-286-9
DOI 10.1007/978-1-84800-286-9
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Library of Congress Control Number: 2008937554
c⃝Springer-Verlag London Limited 200
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as per-
mitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the publish-
ers, or in the case of reprographic reproduction in accordance with the terms of licences issued by the
Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be sent to
the publishers.
The use of registered names, trademarks, etc. in this publication does not imply, even in the absence of a
speciﬁc statement, that such names are exempt from the relevant laws and regulations and therefore free
for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the information
contained in this book and cannot accept any legal responsibility or liability for any errors or omissions
that may be made.
Printed on acid-free paper
9 8 7 6 5 4 3 2 1
Springer Science+Business Media
springer.com
9

Preface
This book provides a deﬁnition and study of a knowledge representation and rea-
soning formalism stemming from conceptual graphs, while focusing on the compu-
tational properties of this formalism.
Knowledge can be symbolically represented in many ways. The knowledge
representation and reasoning formalism presented here is a graph formalism –
knowledge is represented by labeled graphs, in the graph theory sense, and rea-
soning mechanisms are based on graph operations, with graph homomorphism at
the core.
This formalism can thus be considered as related to semantic networks. Since
their conception, semantic networks have faded out several times, but have always
returned to the limelight. They faded mainly due to a lack of formal semantics and
the limited reasoning tools proposed. They have, however, always rebounded be-
cause labeled graphs, schemas and drawings provide an intuitive and easily under-
standable support to represent knowledge.
This formalism has the visual qualities of any graphic model, and it is logically
founded. This is a key feature because logics has been the foundation for knowledge
representation and reasoning for millennia. The authors also focus substantially on
computational facets of the presented formalism as they are interested in knowledge
representation and reasoning formalisms upon which knowledge-based systems can
be built to solve real problems. Since object structures are graphs, naturally graph
homomorphism is the key underlying notion and, from a computational viewpoint,
this moors calculus to combinatorics and to computer science domains in which the
algorithmic qualities of graphs have long been studied, as in databases and constraint
networks.
The main notions are intuitively introduced from a knowledge representation
viewpoint, but the authors have also tried to give precise deﬁnitions of these no-
tions along with complete proofs of the theorems (readers only require a few simple
mathematical notions, which are summarized in the appendix).
This book does not present a methodology for knowledge representation nor de-
scribe actual applications (except for one chapter) or software tools. It presents the-
oretical bases that merge numerous previous studies carried out in the conceptual
v

vi
Preface
graph domain since Sowa’s seminal book and links basic reasoning issues to other
fundamental problems in computer science.
In a nutshell, the authors have attempted to answer the following question: “How
far is it possible to go in knowledge representation and reasoning by representing
knowledge with graphs (in the graph theory sense) and reasoning with graph oper-
ations?”
Organization
The book is divided into 3 parts, 13 chapters and 1 appendix.
The ﬁrst part is devoted to the kernel of the formalism. In Chap. 2, Basic concep-
tual Graphs (BGs) are deﬁned. BGs are structured by a subsumption relation deﬁned
by the homomorphism notion between BGs, as well as by elementary specialization
and generalization operations. In Chap. 3, Simple conceptual Graphs (SGs) are in-
troduced. SGs can be sketchily deﬁned as BGs augmented with equality. Chapter 4
is devoted to set and FOL semantics for SGs. The soundness and completeness
of homomorphism with respect to entailment relation and FOL deduction is proven.
Chapter 5 relates BG homomorphism with homomorphisms of other structures (e.g.,
hypergraphs, relational structures, conjunctive database queries) and solving a con-
straint network.
The second part develops computational aspects of basic conceptual graphs.
Chapters 6, and 7 are devoted to algorithms for BG homomorphism. Chapter 8
presents other specialization and generalization operations that are not covered in
the ﬁrst part, e.g., least generalization, maximal join and other extended joins.
The third part pools the kernel extensions. All of these extensions are provided
with logically sound and complete reasoning mechanisms based on graph homo-
morphism. Chapter 9 focuses on nested conceptual graphs, which are hierachically
structured graphs. In Chap. 10, the important rule notion, which allows representa-
tion of implicit knowledge, for instance, is studied. The introduction of rules gives
the powerfulness of a computability model to the formalism. Positive and negative
constraints are considered in Chap. 11, and the BG family of models, combining
facts, rules and constraints, is presented. Chapter 12 is devoted to negation in con-
ceptual graphs. The last chapter presents semantic annotations—a currently favored
and potentially fruitful application.
Finally, the Appendix summarizes the basic mathematical notions used in the
book.
Each chapter begins with an overview of its content. It ends with bibliographical
notes devoted mainly to studies in the conceptual graph domain. Concerning the
references, the authors chose to cite studies from other domains throughout the text
and provide the conceptual graph references in the bibliographical notes.

Preface
vii
Implementation
This book is about a KR formalism that can serve as a theoretical foundation for
knowledge-based systems. A distinction is made between a KR formalism (e.g., a
fragment of ﬁrst order logic) and a KR programming language (e.g., PROLOG).
Even when a KR programming language is based on a KR formalism, the KR lan-
guage presents variations to the KR formalism (limitations, e.g., Horn clauses or ex-
tensions, second order features, etc.), and it has a concrete syntax, contains speciﬁc
programming constructs (e.g., the cut in PROLOG) and is equipped with software
tools. Between a KR formalism and a programming language implementing this
formalism, there may be KR tools and platforms. This is the current situation of the
graph-based KR formalism presented in the book. CoGITaNT [cog01a] contains
a library of C++ classes that implement most of the notions and reasoning mecha-
nisms presented here. CoGITaNT also contains a graphical interface and a client–
server architecture. CoGITaNT thus allows a programmer to build knowledge-based
systems grounded on the formalism presented in this book. Let us also mention
COGUI
[cog01b], a graphical user interface dedicated to the construction of a
knowledge base and which integrates CoGITaNT.
Audience
The book is intended for computer science students, engineers and researchers.
Some of the materials presented in this book have been used for several years at
different academic levels, ranging from AI courses for graduate students to pro-
fessional and research master’s level courses. The mathematical prerequisites are
minimal, and the Appendix outlines the mathematical notions used in the book.
Here are some suggestions for reading paths of this book depending on readers’
speciﬁc interests.
Chapter 1 (introduction), Chap. 2 (basic conceptual graphs), Chap. 3 (simple con-
ceptual graphs), the two ﬁrst sections of Chap. 4 (set and ﬁrst order logic semantics)
are the core chapters and should be considered as the basis.
For programming and algorithmic purposes the following materials can be added
to the base: Chap. 6 (basic algorithms for BG homomorphism), the last section
of Chap. 5 (relationships with constraint programming techniques), Chap. 7 (tech-
niques for trees and other tractable cases), Chap. 8 (algorithms for other specializa-
tion/generalization operations, especially maximal joins), Chap. 10 (rule process-
ing), and Chap. 12 (algorithms for processing BGs with atomic negation).
For modeling purposes the following parts can be added to the base: Chap. 9
(nested conceptual graphs), Chap. 10 (deﬁnition and use of rules), Chap. 11 (deﬁ-
nition and use of constraints and their combination with rules), Chap. 12 (deﬁnition
and use of atomic negation) and Chap. 13 (semantic annotations).
For more theory-oriented readers, expressivity, decidability and complexity re-
sults, as well as stating equivalence with problems of other domains, are presented
throughout the book, except in the last chapter.

viii
Preface
Acknowledgments
We are indebted to John Sowa, who is the founding father of conceptual graphs, and
the present book would not have existed without his pioneering work [Sow84].
We began working on conceptual graphs in 1992, and over the years many of our
colleagues and students have contributed, in one way or another, to this work.
We would like to thank:
Friends and colleagues who have supported our approach over the years: Franz
Baader, Marie-Christine Rousset, Pierre Marquis, Fritz Lehmann, Daniel Kayser,
Michel Habib, Guy Chaty;
Colleagues or students with whom we have directly collaborated on topics cov-
ered in this book: Jean-Franc¸ois Baget, Boris Carbonneill, Olivier Cogis, David
Genest, Olivier Guinaldo, Ollivier Haemmerl´e, Gwen Kerdiles, Michel Lecl`ere,
Anne Preller, Eric Salvat, Genevi`eve Simonet, Rallou Thomopoulos;
Colleagues from the conceptual graph community with whom we have had fruit-
ful discussions: Tru Cao, Fritjof Dau, Gerard Ellis, Jean Fargues, Bikash Gosh,
Fritz Lehmann, Robert Levinson, Dickson Lukose, Guy Mineau, John Sowa, Mark
Willems, Vilas Wuwongse.
Our approach has beneﬁted from numerous collaborations on applied research
projects, and we would like to thank: Christian Baylon, Alain Bonnet, Bernard
Botella, Olivier Corby, Patrick Courounet, Rose Dieng, Steffen Lalande, Philippe
Martin, Patrick Taillibert.
We acknowledge Jean-Franc¸ois Baget, David Genest, Alain Gutierrez, Michel
Lecl`ere, Khalil Ben Mohamed, Nicolas Moreau, Fatiha Sa¨ıs, Eric Salvat, who re-
viewed parts of this book, with special thanks to Genevi`eve Simonet (some of her
comments could be the seeds for a new book ...).
We would also like to thank David Manley for rectifying our Franglais and Bev-
erley Ford and her team at Springer London for their support.
Obviously, all remaining errors are our fault alone. We welcome corrections and
suggestions on all aspects of the book; please send these to us at:
Michel.Chein@lirmm.fr and Marie-Laure.Mugnier@lirmm.fr. A web site compan-
ion to the book can also be queried at:
http://www.lirmm.fr/gbkrbook
La Boissi`ere,
Michel Chein and Marie-Laure Mugnier
March 2008

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Knowledge Representation and Reasoning . . . . . . . . . . . . . . . . . . . . .
1
1.1.1
Knowledge-Based Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.1.2
Requirements for a Knowledge Representation Formalism . .
3
1.2
Conceptual Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.2.1
Basic Notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.2.2
Subsumption and Homomorphism . . . . . . . . . . . . . . . . . . . . . .
9
1.2.3
Formal Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.2.4
Full CGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.3
A Graph-Based Approach to KR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.3.1
Motivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.3.2
Extensions of the Basic Formalism . . . . . . . . . . . . . . . . . . . . . 14
1.3.3
Several Approaches to CGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
Part I Foundations: Basic and Simple Conceptual Graphs
2
Basic Conceptual Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.1
Deﬁnition of Basic Conceptual Graphs (BGs) . . . . . . . . . . . . . . . . . . . 22
2.1.1
Vocabulary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.1.2
Basic Conceptual Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.1.3
SubBGs and PseudoBGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.2
BG Homomorphism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.2.1
Subsumption and Homomorphism . . . . . . . . . . . . . . . . . . . . . . 30
2.2.2
Bijective Homomorphisms and Isomorphisms . . . . . . . . . . . . 33
2.2.3
BG Queries and Answers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.3
BG Subsumption Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.3.1
Subsumption Preorder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.3.2
Irredundant BGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
2.4
Generalization and Specialization Operations . . . . . . . . . . . . . . . . . . . 40
2.4.1
Elementary Generalization Operations for BGs . . . . . . . . . . . 40
2.4.2
Generalization and Homomorphism. . . . . . . . . . . . . . . . . . . . . 42
ix

x
Contents
2.4.3
Elementary Specialization Operations . . . . . . . . . . . . . . . . . . . 45
2.4.4
Specialization and Homomorphism . . . . . . . . . . . . . . . . . . . . . 48
2.5
Normal BGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.5.1
Deﬁnition of Normal BGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.5.2
Elementary Operations for Normal BGs . . . . . . . . . . . . . . . . . 52
2.6
Complexity of Basic Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
2.7
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
3
Simple Conceptual Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.2
Vocabulary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
3.3
Simple Conceptual Graphs (SGs) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
3.4
Generalization and Specialization Operations . . . . . . . . . . . . . . . . . . . 69
3.5
Standard and Normal SGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
3.6
Coref-Homomorphism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
3.7
Antinormal Form and Homomorphism . . . . . . . . . . . . . . . . . . . . . . . . . 76
3.8
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
4
Formal Semantics of SGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.1
Model Semantic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.1.1
Models of SGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.1.2
Soundness and Completeness of (coref) Homomorphism . . . 87
4.2
Logical Semantic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.2.1
The FOL Semantic Φ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.2.2
Model Semantic and Φ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
4.3
Positive, Conjunctive, and Existential Fragment of FOL . . . . . . . . . . 92
4.3.1
Ordered Language and L-Substitution . . . . . . . . . . . . . . . . . . . 93
4.3.2
Soundness and Completeness Revisited. . . . . . . . . . . . . . . . . . 94
4.3.3
Relationships Between SGs and FOL(∧, ∃) . . . . . . . . . . . . . . 95
4.3.4
Another FOL Semantic: Ψ . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
4.4
Note on the Relationships Between Description Logics
and Conceptual Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
4.5
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
5
BG Homomorphism and Equivalent Notions . . . . . . . . . . . . . . . . . . . . . . 105
5.1
Conceptual Graphs and Conceptual Hypergraphs . . . . . . . . . . . . . . . . 107
5.1.1
Conceptual Hypergraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.1.2
Different Kinds of Vocabularies . . . . . . . . . . . . . . . . . . . . . . . . 110
5.2
Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
5.2.1
From Graphs to BGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.2.2
From BGs to Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
5.3
Relational Structures and Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
5.3.1
Relational Structures and BGs . . . . . . . . . . . . . . . . . . . . . . . . . 119
5.3.2
Conjunctive Queries and BGs . . . . . . . . . . . . . . . . . . . . . . . . . . 120
5.4
Constraint Satisfaction Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124

Contents
xi
5.4.1
Deﬁnition of CSP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
5.4.2
From CSP to BGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
5.4.3
From BGs to CSP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
5.5
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
Part II Computational Aspects of Basic Conceptual Graphs
6
Basic Algorithms for BG Homomorphism. . . . . . . . . . . . . . . . . . . . . . . . . 135
6.1
Algorithms for BG Homomorphisms . . . . . . . . . . . . . . . . . . . . . . . . . . 135
6.1.1
Basic Backtrack Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
6.1.2
Backtrack Improvements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
6.2
Constraint Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
6.2.1
A Panorama of Constraint Processing Techniques . . . . . . . . . 151
6.2.2
Arc-Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
6.2.3
Forward Checking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
6.3
Label Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
6.3.1
Basic Data Structures and Algorithms . . . . . . . . . . . . . . . . . . . 163
6.3.2
Related Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
6.3.3
Tree Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
6.3.4
Partition in Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
6.3.5
Lattices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
6.4
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
7
Tractable Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
7.1.1
About Tractability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
7.1.2
The Structure of the Target BG is of No Help . . . . . . . . . . . . . 172
7.2
Tractability Based on the Multigraph-Acyclicity of the Source BG . 174
7.2.1
Acyclic Multigraphs and Trees . . . . . . . . . . . . . . . . . . . . . . . . . 174
7.2.2
BGs Trivially Logically Equivalent to Acyclic BGs . . . . . . . . 184
7.3
Tractability Based on the Hypergraph-Acyclicity of the Source BG . 185
7.3.1
Use of a Join Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
7.3.2
Construction of a Join Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
7.3.3
Equivalence with the Existential Conjunctive Guarded
Fragment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
7.4
Generalizations of Graph-Acyclicity and Hypergraph-Acyclicity . . . 198
7.4.1
Graphs and Treewidth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
7.4.2
Hypergraphs and Hypertreewidth . . . . . . . . . . . . . . . . . . . . . . . 200
7.4.3
Expressivity Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
7.5
What About Labels? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
7.6
Complementary Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204

xii
Contents
8
Other Specialization/Generalization Operations . . . . . . . . . . . . . . . . . . . 207
8.1
The Least Generalization and Greatest Specialization of Two BGs . . 208
8.2
Basic Compatibility Notions and Maximal Joins . . . . . . . . . . . . . . . . . 212
8.2.1
Compatible Node Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
8.2.2
Maximal Join . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
8.3
Compatible Partitions and Extended Join . . . . . . . . . . . . . . . . . . . . . . . 222
8.3.1
Compatible C-Partition and R-Partition . . . . . . . . . . . . . . . . . . 222
8.3.2
Extended Join . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
8.3.3
Join According to a Compatible Pair of C-Partitions . . . . . . . 226
8.4
G-Specializations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
8.4.1
Surjective Homomorphism . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
8.4.2
Union . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
8.4.3
Inductive Deﬁnition of BGs . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
8.4.4
G-Specializations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
8.5
Type Expansion and Contraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
8.6
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
Part III Extensions
9
Nested Conceptual Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
9.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
9.2
Nested Basic Graphs (NBGs). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
9.3
Nested Graphs (NGs) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
9.4
Nested Typed Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
9.5
The Semantics ΦN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
9.5.1
Deﬁnition of ΦN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
9.5.2
Soundness and Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . 265
9.6
Representation of Nested Typed Graphs by BGs . . . . . . . . . . . . . . . . . 267
9.7
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
10
Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
10.1 Deﬁnition and Logical Semantics of a Rule . . . . . . . . . . . . . . . . . . . . . 273
10.1.1 Logical Semantics of a Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
10.1.2 Rule as a Bicolored Graph. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
10.2 Forward Chaining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
10.2.1 Rule Application. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
10.2.2 Derivation and Deduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
10.2.3 Non-Redundant Rule Application . . . . . . . . . . . . . . . . . . . . . . 284
10.2.4 Soundness and Completeness of Forward Chaining . . . . . . . . 286
10.3 Backward Chaining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
10.3.1 Outline of the Backward Chaining Mechanism . . . . . . . . . . . 292
10.3.2 Piece Resolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
10.3.3 Soundness and Completeness of Backward Chaining . . . . . . 298
10.4 Computational Complexity of FR-DEDUCTION with Rules . . . . . . . 301
10.4.1 Semi-Decidability of FR-DEDUCTION with Rules . . . . . . . . 301

Contents
xiii
10.4.2 Decidable Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
10.5 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
11
The BG Family: Facts, Rules and Constraints . . . . . . . . . . . . . . . . . . . . . 311
11.1 Overview of the BG Family . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
11.2 FC: Facts and Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
11.2.1 Positive and Negative Constraints . . . . . . . . . . . . . . . . . . . . . . 313
11.2.2 Translation to FOL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316
11.2.3 Complexity of Consistency and Deduction . . . . . . . . . . . . . . . 318
11.3 Combining Rules and Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
11.3.1 FRC: Constraints and Inference Rules . . . . . . . . . . . . . . . . . . 321
11.3.2 FEC: Constraints and Evolution Rules . . . . . . . . . . . . . . . . . . 325
11.3.3 FREC: Constraints, Inference and Evolution Rules . . . . . . . 326
11.3.4 Complexity of Combining Rules and Constraints . . . . . . . . . . 326
11.4 Complexity in FRC/FEC/FREC for Particular Cases of Rules
and Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
11.4.1 Particular Cases of Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
11.4.2 Particular Cases of Constraints . . . . . . . . . . . . . . . . . . . . . . . . . 330
11.5 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334
12
Conceptual Graphs with Negation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
12.1 Full Conceptual Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
12.1.1 Existential Graphs: a Diagrammatical System for Logics . . . 338
12.1.2 Full Conceptual Graphs (FCGs) . . . . . . . . . . . . . . . . . . . . . . . . 340
12.1.3 Logical Semantics of FCGs. . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
12.1.4 Equivalence of CGs and FOL . . . . . . . . . . . . . . . . . . . . . . . . . . 344
12.1.5 FCG Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
12.1.6 Dau’s FCGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
12.1.7 Kerdiles’ FCGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348
12.2 Conceptual Graphs with Atomic Negation . . . . . . . . . . . . . . . . . . . . . . 350
12.2.1 Polarized Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350
12.2.2 Handling Coreference and Difference . . . . . . . . . . . . . . . . . . . 355
12.2.3 PG-DEDUCTION and Equivalent Problems . . . . . . . . . . . . . . . 359
12.2.4 Complexity of PG-DEDUCTION . . . . . . . . . . . . . . . . . . . . . . . . 360
12.2.5 Special Cases with Lower Complexity for PG-DEDUCTION . 362
12.2.6 Algorithmic Improvements . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367
12.2.7 Querying Polarized Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
12.2.8 Note on Negation and Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
12.3 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375
13
An Application of Nested Typed Graphs: Semantic Annotation Bases 377
13.1 Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
13.1.1 Annotations, Metadata and Resources . . . . . . . . . . . . . . . . . . . 377
13.1.2 Examples of Annotation Base Uses . . . . . . . . . . . . . . . . . . . . . 378
13.1.3 Components of an Annotation System . . . . . . . . . . . . . . . . . . . 380

xiv
Contents
13.2 Annotation Base . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381
13.2.1 Exact Knowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
13.2.2 Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
13.2.3 Plausible Knowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
13.3 Querying an Annotation Base . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385
13.3.1 Exact Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
13.3.2 Approximate Search. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
13.4 Annotation and the Semantic Web . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388
13.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
A
Mathematical Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393
A.1 Sets and Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
A.1.1
Sets and Elements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
A.1.2
Relations and Mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
A.2 Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
A.2.1
Directed Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
A.2.2
Homomorphism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
A.2.3
Different Sorts of Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400
A.2.4
Hypergraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403
A.3 Ordered Sets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403
A.3.1
Basic Notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403
A.3.2
Lattices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
A.4 First Order Logic (FOL) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
A.4.1
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
A.4.2
Semantics and Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408
A.4.3
Clausal Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
A.4.4
Resolution and SLD-Resolution . . . . . . . . . . . . . . . . . . . . . . . . 409
A.5 Algorithm and Problem Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . 410
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423

Chapter 2
Basic Conceptual Graphs
Overview
This chapter presents the kernel of the knowledge representation language, namely
basic conceptual graphs. A basic conceptual graph (BG) has no meaning indepen-
dently from a vocabulary, and both are deﬁned in Sect. 2.1. The fundamental notion
for reasoning with BGs is the subsumption relation. Subsumption is ﬁrst deﬁned by
a homomorphism: Given two BGs G and H, G is said to subsume H if there is such
a BG homomorphism from G to H. Section 2.2 deﬁnes the BG homomorphism, as
well as the particular case of BG isomomorphism. BGs and subsumption provide
a basic query-answering mechanism, as shown at the end of this section. The sub-
sumption properties are studied in Sect. 2.3. Subsumption is not an order as there
may be nonisomorphic equivalent BGs, i.e., BGs that subsume each other. However,
by suppressing redundant parts, any BG can be transformed into an equivalent ir-
redundant BG. Irredundant BGs are unique representatives of all equivalent BGs.
Finally, the subsumption relation restricted to irredundant BGs is not only an order
but also a lattice. Section 2.4 introduces another way of deﬁning the subsumption
relation by sets of elementary graph operations. There is a set of generalization op-
erations and the inverse set of specialization operations. Given two BGs G and H, G
subsumes H if and only if G can be obtained from H by a sequence of generalization
operations (or equivalently, H can be obtained from G by a sequence of specializa-
tion operations). Section 2.5 introduces the issue of equality, which will be a central
topic of the next chapter (Simple Conceptual Graphs). A BG is said to be normal
if it does not possess two nodes representing the same entity. Normal BGs form the
kernel of reasoning based on homomorphism.
In Sect. 2.6, the complexity of BG fundamental problems is studied. In particular,
it is proven that checking whether there is a homomorphism between two BGs is an
NP-complete problem.
21

22
2 Basic Conceptual Graphs
2.1 Deﬁnition of Basic Conceptual Graphs (BGs)
2.1.1 Vocabulary
Basic conceptual graphs (BGs) are building blocks for expressing different sorts of
knowledge: Assertions or facts, queries or goals, rules describing implicit knowl-
edge, rules describing the evolution of some world, constraints and so on. In this
chapter they are used for representing facts and queries, but they will be used for
representing more complex knowledge in further chapters.
A fact is an assertion that some entities exist and that these entities are related by
some relationships. Any entity has a type (e.g., Car, Person, Toy, etc.), and the set
of types is ordered by a subtyping relation, also called a specialization relation or
a-kind-of relation (e.g., the type Boy is a kind of the type Person). “The type t is a
specialization of the type t′,” equivalently “t′ is a generalization of t,” simply means
that any entity of type t is also of type t′. It is assumed that there is a most general
type, called the universal type, denoted ⊤.
Two kinds of entities are considered. An entity may be either a speciﬁc entity
(e.g., that small red car) or an unidentiﬁed entity (e.g., a boy). A speciﬁc entity is
called an individual entity and an unidentiﬁed entity is called a generic entity.
Besides asserting the existence of speciﬁc or unidentiﬁed typed entities, a fact
can assert that relationships hold between these entities (e.g., Paul possesses a teddy
bear, Paul is-the-son-of a person and so on). The relations are structured by a spe-
cialization order as the types of entities are. For example, the relation is-the-son-of
is a specialization of the relation is-the-child-of, which is itself a specialization of the
relation is-a-relative-of. The representation of an entity (of the application domain)
is traditionally called a concept in the conceptual graphs community and we use
this expression hereafter. A basic conceptual graph (BG) is composed of two kinds
of nodes, concept nodes representing entities that occur in the application domain,
and relation nodes representing relationships that hold between these entities. The
ordered set of concept (entity) types is denoted TC. An individual concept is refer-
enced by an individual marker belonging to a set I of individual markers, and there
is a generic marker ∗, which denotes an unspeciﬁed entity. The same marker ∗is
used for denoting a generic entity regardless of type. The set of relations is denoted
TR. An element of TR is called a relation symbol or a relation type. These three sets
compose the vocabulary used for labeling the two kinds of nodes of a BG: A con-
cept node is labeled by a pair composed of a type and either an individual marker or
the generic marker; a relation node is labeled by a relation symbol. A vocabulary is
precisely deﬁned as follows:
Deﬁnition 2.1 (Vocabulary). A BG vocabulary, or simply a vocabulary, is a triple
(TC,TR,I) where:
• TC and TR are ﬁnite pairwise disjoint sets.
• TC, the set of concept types, is partially ordered by a relation ≤and has a greatest
element denoted ⊤.

2.1 Deﬁnition of Basic Conceptual Graphs (BGs)
23
• TR, the set of relation symbols, is partially ordered by a relation ≤, and is parti-
tioned into subsets T 1
R ,...,T k
R of relation symbols of arity 1,...,k, respectively.
The arity of a relation r is denoted arity(r). Any two relations with different
arities are not comparable.
• I is the set of individual markers, which is disjoint from TC and TR. Furthermore,
∗denotes the generic marker, M = I ∪{∗} denotes the set of markers and M
is ordered as follows: ∗is greater than any element in I and elements in I are
pairwise incomparable.
In some works, it is assumed that TC has a speciﬁc structure, such as a tree, a
lattice or a semi-lattice. In this book, having a greatest element is the only property
required for the ordered set TC.
A set TC (resp. TR) of concept (resp. relation) types is also called a hierarchy of
concept (resp. relation) types.
The three sets (concept, relation or marker set) play different roles and are as-
sumed to be pairwise disjoint. A speciﬁc syntax is used for representing elements of
a vocabulary: A concept type begins by an upper case letter, a relation symbol by a
lower case letter, and an individual is a proper name or begins by #. This allows the
user to quickly determine the role of an identiﬁer and to simply differentiate close
identiﬁers playing different roles. For instance, the word father could represent a
concept type (e.g., Paul is an individual of type Father means that Paul is a father), a
binary relation symbol fatherOf could represent the binary relation relating a father
and one of his children (e.g., fatherOf(Paul,July) means that Paul is the father of
July), and if “Father” is the name of the chief of a gang then Father could be used
as an individual marker.
Example. Figure 2.1 is a subset of the concept type set corresponding to the children
photo example (Sect. 1.1.1). Figure 2.2 is a part of the relation type set for the same
example. In this case, for each arity i of relation, there is a greatest element denoted
by ⊤i. ⊤i can be seen as representing any relation of arity i.
Type of Individuals and Relation Signatures
A vocabulary can be considered as the representation of a very simple ontology.
Different kinds of knowledge can be added to a vocabulary. Two simple extensions
are often considered, namely individual typing and relation symbol signatures.
First, individual markers can be typed. The type of an individual marker repre-
sents the most speciﬁc information about the category of the individual referenced
by this marker. A mapping, say τ, from the set of individuals I to the set of con-
cept types TC is thus added with, for an individual m, τ(m) representing the most
speciﬁc type of m. Consequently, in any BG relative to this vocabulary, a concept
node with marker m will have a type greater than or equal to τ(m). For instance,
let us assume that, in some applications, there is an individual marker R2 known to
represent a ToyRobot (without any other details) i.e., τ(R2) = ToyRobot. Individ-
ual concept nodes with marker R2 and type Toy, or Robot, or MobileEntity may
appear. But, if Android < ToyRobot, then no concept node labeled (Android,R2)

24
2 Basic Conceptual Graphs
GeomNotion
3DNotion
MathNotion
Sphere
Cube
Father
Mother
Woman 
Boy
Girl
Man
Child
Adult
Female
Male
Person
Color
Size
Sex
Attribute
Play
Train
Firetruck
RacingCar
CuddlyToy
Table  Chair
PieceOfFurniture
Car
Toy
Painting
BuildingBlock
FluffyRabbit
TeddyBear
Object
T
Location
Action
Fig. 2.1 A concept type set
wash
act3
play3
playTogether
T3
T2
between
give
sisterOf
motherOf   fatherOf
sonOf   daughterOf
lookAt   playWith
possess
act
agt
hold
attr
inst
obj
brotherOf
parentOf
childOf
relativeOf
locObj
near
on     under
Fig. 2.2 A relation symbol set
can appear because Android < τ(R2). Typing the individuals may be a drawback
whenever knowledge about the individuals may evolve. This is typically the case in
a knowledge acquisition context. For instance, R2 may ﬁrst be known as a Toy and
later as a ToyRobot.
The second extension is the introduction of relation symbol signatures. A rela-
tion symbol signature speciﬁes not only the arity of the relation symbol but also
the maximal concept type of each of its arguments. For instance, the signature of
the relation symbol possess could be (Person,Object), which means that the ﬁrst
argument of a relation possess is of type Person and the second argument is of type
Object. Relation signatures are formally deﬁned by a mapping σ, which to every
relation symbol r ∈T j
R, 1 ≤j ≤k associates σ(r) ∈(TC)j; this mapping also has to

2.1 Deﬁnition of Basic Conceptual Graphs (BGs)
25
fulﬁll the following condition: ∀r1,r2 ∈T j
R, r1 ≤r2 ⇒σ(r1) ≤σ(r2), i.e., for all
1 ≤i ≤j, the i-th argument of σ(r1) is less than or equal to the i-th argument of
σ(r2). That is, when a relation symbol r2 is specialized into a relation symbol r1, its
arguments can be specialized but cannot be generalized.
Example. For instance, let us consider the relation symbols ⊤2, relativeOf, par-
entOf, motherOf. Signatures for these relations can be: ⊤2(⊤,⊤), relativeOf(Person,
Person), parentOf(Person, Person), motherOf(Mother, Person). If the ternary rela-
tion play3 is intended to mean that two persons are playing together with a toy then
its signature could be play3(Person, Person, Toy). In the same way, the signature of
the ternary relation give could be give(Person, Person, Object) with the following
intuitive meaning: The ﬁrst person is giving the object to the second person.
In the forthcoming chapters, more complex vocabularies and more complex
knowledge, such as rules or constraints, will be studied. Rules and constraints al-
low the representation, in the conceptual graph model, of “heavyweight” formal
ontologies.
2.1.2 Basic Conceptual Graphs
A basic conceptual graph (BG) is a bipartite multigraph (cf. Chap. A). “Bipartite”
means that a BG has two disjoint sets of nodes and that any edge joins two nodes
from different sets (i.e., an edge cannot join two nodes of the same set). “Multi-
graph” means that a pair of nodes may be linked by several edges. One set of nodes
is called the set of concept nodes (representing entities), and the other set is called
the set of relation nodes (representing relations between entities). If a concept c is
the i-th argument of a relation r then there is an edge between r and c that is labeled i.
Example. Figure 2.3 shows a BG consisting of four concept nodes (the individual
Paul who is a Child, a Car, a Person and the individual Small which is a Size) and
three relations: one ternary relation, play3, whose neighbor list is ([Child: Paul],
[Person], [Car]), and two binary relations, attr and possess, whose neighbor lists
are respectively ([Child: Paul], [Car]) and ([Car], [Size: Small]). This graph can be
considered as representing the following fact: “There is a car, which is small. This
car is possessed by Paul, who is a child. There is a person, and Paul and this person
are playing with that car.” This way of describing the fact puts the emphasis on the
car, but the emphasis could have been put on Paul as the drawing suggests it (e.g.,
“Paul, who is a child, and a person, are playing with a small car that belongs to
Paul”) or any subset of entities. A basic conceptual graph has no privileged nodes.
Figure 2.4 shows another BG that could represent the assertion that “Paul, who is a
child, is washing himself, and he is playing with his mother.” Note the parallel edges
between the concept [Child:Paul] and the relation (wash), indicating that the agent
and the object of the relation (wash) are the same entity, the child Paul. Figure 2.5
shows a BG with more complex cycles, asserting that “a father and his child are

26
2 Basic Conceptual Graphs
playing together on a mat; the mother of the child is looking at them; she is on the
sofa near the mat.”
play3
G
attr
Person
3
2
1
2
1
Size: Small
possess
2
1
Child: Paul
Car
Fig. 2.3 A BG with a ternary relation
Child: Paul
playTogether
2
motherOf
2
1
H
wash
2
1
Person
1
Fig. 2.4 A BG with parallel edges
Every node has a label. A relation node is labeled by a relation symbol and a
concept node is labeled by a concept type and by a marker. Thus, a basic conceptual
graph is built relative to a vocabulary, and it has to satisfy the constraints enforced
by that vocabulary.
Deﬁnition 2.2 (Basic Conceptual Graph). A basic conceptual graph (BG) de-
ﬁned over a vocabulary V = (TC,TR,I), is a 4-tuple G = (C,R,E,l) satisfying the
following conditions:
• (C,R,E) is a ﬁnite, undirected and bipartite multigraph called the underlying
graph of G, denoted graph(G). C is the concept node set, R is the relation node
set (the node set of G is N = C ∪R). E is the family of edges.
• l is a labeling function of the nodes and edges of graph(G) that satisﬁes:
1. A concept node c is labeled by a pair (type(c), marker(c)), where type(c)∈TC
and marker(c)∈I ∪{∗},
2. A relation node r is labeled by l(r) ∈TR. l(r) is also called the type of r and
is denoted by type(r),

2.1 Deﬁnition of Basic Conceptual Graphs (BGs)
27
Child
Woman
2
2
2
2
2
1
2
1
2
2
2
1
1
1
1
1
1
1
Man
playTogether
fatherOf
motherOf
Mat
lookAt
lookAt
Sofa
on
on
near
on
Fig. 2.5 A BG with more complex cycles
3. The degree of a relation node r is equal to the arity of type(r),
4. Edges incident to a relation node r are totally ordered and they are labeled
from 1 to arity(type(r)).
First note that a BG does not need to be a connected graph. It is natural to ques-
tion what the smallest BGs are. The preceding deﬁnition does not prevent a BG
from being empty, that is to be the tuple (∅, ∅, ∅, ∅). For theoretical purposes, it is
sometimes convenient to consider the empty BG. We will denote it by G∅. A BG
may be restricted to a single concept node or several concept nodes. We will call
them isolated concept nodes. But as soon as a BG contains a relation node, it con-
tains at least one concept node, since there are no 0-ary relation symbols. Note also
that, as there may be parallel edges, one has to distinguish between the number of
edges incident to a relation node (this number is given by the arity of its type) and
the number of its neighbors. For instance, the relation (wash) in Fig. 2.4 is incident
to two edges but has only one neighbor.
An important kind of BGs consists of BGs having a single relation node.
Deﬁnition 2.3 (Star BG). A star BG is a BG restricted to a relation node and its
neighbors.
With BGs restricted to single concept nodes, star BGs are the elementary building
blocks of BGs. This point will be speciﬁed in Chap. 8, but let us outline the idea.
First, the set of relation symbols of a BG vocabulary can be described by a set of star
BGs: A relation symbol r of signature (t1,...,tk) is represented by a star BG, the
relation node is labeled r and has k neighbors with the i-th being labeled (ti,∗) (cf.
Fig. 2.6). Then every non-empty BG deﬁnable on this vocabulary can be generated
from this set of star graphs by the so-called specialization operations (if the BG has
isolated concept nodes, one has to add, to the set of star graphs, the graph restricted
to the single concept node [⊤: ∗]).

28
2 Basic Conceptual Graphs
ti
r
i
t1
t2
tk
1
2
k
Fig. 2.6 A star BG associated with the relation symbol r with signature (t1,...,tk)
Notations and Remarks
An edge labeled i between a relation r and a concept c is denoted (r,i,c). The i-
th argument of a relation r is also called the i-th neighbor of r and is denoted r[i]
i.e., (r,i,c) is in G if and only if r[i] = c in G. The neighbor list (c1,...,ck) of a
relation r of arity k is the list such that ci = r[i]. It is said that r(c1,...,ck) is in
G if (c1,...,ck) is the neighbor list of the relation r. The same concept node may
appear several times in the neighbor list of a relation, so strictly speaking a BG is a
multigraph and not a graph.
We will adopt the following classical conventions for BGs. A relation symbol is
also called a relation type even if a concept type and a relation type have different
meanings. A concept type can be considered as a class, i.e., the class of all the en-
tities having this type, but a relation type does not represent a class. Nevertheless,
calling “relation type” a relation symbol allows us to simplify notations by consid-
ering the type of any node, either concept or relation, in a BG. In a BG drawing,
concept nodes are represented by rectangles and relation nodes by ovals. In textual
notation, rectangles are replaced by [] and ovals by (). The generic marker is the
marker by default, and it is generally omitted. Thus a generic concept of type t,
whose label is (t,∗), is simply noted [t]. An individual concept with label (t,m) is
noted [t:m].
For binary relation nodes, numbers on edges can be replaced by directed edges. A
relation node is then incident to exactly one incoming edge and one outgoing edge,
linking it to its ﬁrst and second neighbor, respectively. For example, Fig. 2.7 pictures
the same BG as in Fig. 2.3, with arrows on edges incident to binary relations; the
arrow from [Car] to (attr) stands for an edge labeled 1, and the arrow from (attr) to
[Size : Small] stands for an edge labeled 2.
Relation labels are naturally ordered by the partial order on TR, and concept labels
are ordered as follows:
Deﬁnition 2.4 (Ordered set of concept labels). The set of concept labels, deﬁned
over a given vocabulary, is the set of couples (t,m) such that t ∈TC and m ∈M.
This set is the cartesian product of the two partially ordered sets TC and M, thus it
is (partially) ordered by (t,m) ≤(t′,m′) if and only if t ≤t′ and m ≤m′.
Example. (Boy,Paul)≤(Person,Paul)≤(Person,∗), but (Boy,∗) and (Person,Paul)
are not comparable because Boy < Person and Paul < ∗.

2.1 Deﬁnition of Basic Conceptual Graphs (BGs)
29
play3
attr
Person
3
2
1
Size: Small
possess
Child: Paul
Car
Fig. 2.7 Another drawing of G (cf. Fig. 2.3)
2.1.3 SubBGs and PseudoBGs
We are interested here in subgraphs of a BG that are themselves BGs. We call them
subBGs. Let us begin with their formal deﬁnition before discussing the distinction
between a “subgraph of a BG” and a “subBG.”
Deﬁnition 2.5 (subBG). Let G = (C,R,E,l) be a BG. A subBG of G is a BG G′ =
(C′,R′,E′,l′), such that:
• C′ ⊆C, R′ ⊆R, E′ ⊆E,
• l′ is the restriction of l to C′ ∪R′ ∪E′.
G′ is a strict subBG of G if the number of nodes in G′ is strictly less than the number
of nodes of G.
In graph theory, a subgraph of a graph G is deﬁned as a graph obtained from G
by removing nodes (and edges incident to these nodes). A subBG must be a BG,
thus it is not possible to remove just any nodes. Since the degree of a relation node
has to be equal to the arity of its type, deleting a concept node of G implies deleting
all neighboring relation nodes. Similarly, a graph obtained from a BG by removing
only edges is not a BG; that is if an edge is removed then its incident relation must
be removed too.
Example. G′ in Fig. 2.8 is a subgraph of G in Fig. 2.3. G′ is not a BG because in G′
the relation (play3), which is a ternary relation, has only two neighbors. Thus G′ is
not a subBG of G.
G’
play3
Child : Paul
attr
Size: Small
3
1
Car
Fig. 2.8 G′: a subgraph of G (cf. Fig. 2.4) which is not a subBG
A subBG of G can be obtained from G only by repeatedly deleting a relation or
an isolated concept.

30
2 Basic Conceptual Graphs
Property 2.1. A subgraph G′ of a BG G is a subBG if and only if all neighbors in G
of any relation r in G′ are also neighbors of r in G′.
Deﬁnition 2.6 (Boundary node). A boundary node of a subBG G′ of G is a node
of G′ that has a neighbor outside G′.
As the arity of a relation type is a constant, a boundary node is necessarily a
concept.
If edges or nodes are arbitrarily deleted from a BG, the obtained graph is called
a pseudo-BG. More generally, a pseudo-BG has concept and relation nodes, and
edges connecting concepts to relations, but it might not satisfy other conditions on
a BG.
Deﬁnition 2.7 (Pseudo-BG). A pseudo-BG is obtained from the deﬁnition of a BG
by removing some conditions from the set of conditions 2.
Example. G′ in Fig. 2.8 is a pseudo-BG.
Pseudo-BGs naturally occur during the construction of BGs, using a graph edi-
tor for instance. Indeed, the graphs obtained before the whole completion generally
are only pseudo-BGs and not BGs. More generally, during knowledge acquisition,
any constraint of the model can be a drawback. Pseudo-BGs represent minimal con-
straints that in our opinion have to be enforced: having two kinds of nodes and
preventing edges to connect nodes of the same kind. However, after completion of
a knowledge acquisition step, the constraints of the vocabulary (possibly including
individual types or relation signatures) are useful validation tools.
2.2 BG Homomorphism
2.2.1 Subsumption and Homomorphism
The subsumption relation (denoted ⪰) is the fundamental notion for reasoning with
BGs. Let G and H be two BGs over the same vocabulary. Intuitively, G subsumes
H (noted G ⪰H) if the fact—or the information—represented by H entails the
fact represented by G, or in other words, if all information contained in G is also
contained in H. “G subsumes H” is equivalent to “H is subsumed by G” denoted
by H ⪯G. Let us keep this intuitive meaning for now; we will come back to the
semantic of subsumption later. This subsumption relation can be deﬁned either by a
sequence of elementary operations or by the classical homomorphism notion applied
to BGs (which essentially is a graph homomorphism, with this point being studied
in Chap. 5).
Deﬁnition 2.8 (BG homomorphism). Let G and H be two BGs deﬁned over the
same vocabulary. A homomorphism π from G to H is a mapping from CG to CH
and from RG to RH, which preserves edges and may decrease concept and relation
labels, that is:

2.2 BG Homomorphism
31
• ∀(r,i,c) ∈G,(π(r),i,π(c)) ∈H,
• ∀e ∈CG ∪RG, lH(π(e)) ≤lG(e).
If there is a homomorphism (say π) from G to H, we say that G maps or projects to
H (by π).
Example. Figure 2.9 G maps to H and K.
Remark
In the conceptual graph community a BG homomorphism is traditionally called a
projection. We prefer the term BG homomorphism for two reasons: First, it corre-
sponds to the use of “homomorphism” in mathematics, indeed a BG homomorphism
is a mapping between BGs preserving the BG structure; secondly, in the relational
database model, there is an operation called “projection,” which is rather different
from a BG homomorphism (cf. Chap. A).
Deﬁnition 2.9 (Subsumption relation). Let G and H be two BGs deﬁned over the
same vocabulary. The subsumption relation ⪰is deﬁned by: G ⪰H if there is a
homomorphism from G to H.
Child: Paul
Person
Person
Child: Paul
Person
1
2
motherOf
2
1
2
K
H
G
2
1 playTogether
wash
1
act
Fig. 2.9 Homomorphisms from G to H and K
Example. Let us consider the BGs G and H in Fig. 2.10. There are two homo-
morphisms from G to H, namely h1 and h2, pictured by dashed and dotted lines,
respectively. By h2, [Child] in G is mapped to [Child:Paul] in H, by h1 it is mapped
to [Child]. The relation (act) is mapped to the appropriate relation (playWith). The
other nodes have the same image by both homomorphisms: [Toy] and [Car] are
mapped to [FireTruck], the two relations (on) are mapped to the sole relation (on)
in H, and each remaining node is mapped to the node with same label in H.

32
2 Basic Conceptual Graphs
Child
Child
2
playWith
1
2
1
2
playWith
1
1
1
2
Color:red
1
2
2
Toy
act
1
G
H
1
2
Color:red
1
2
2
Mat
on
Mat
attr
on
FireTruck
Child:Paul
on
attr
h1
h2
Car
sisterOf
Fig. 2.10 G ⪰H
Subsumption emphasizes the fact that a BG is always relative to a given vocab-
ulary and has no meaning independently from it. In other words, the same labeled
graph satisfying the properties of Deﬁnition 2.2 leads to two different BGs if it is
considered relative to two different vocabularies. For instance, let us consider the
BG G in Fig. 2.10, which is relative to the vocabulary V given in Fig. 2.1. If V′ is
obtained from V by deleting the fact that Firetruck < Car, then there is no homo-
morphism from G to H considered as BGs over V′, whereas there is a homomor-
phism from G to H when they are BGs over V.
Deﬁnition 2.10 (Image by homomorphism). Let G = (CG,RG,EG,lG) and H =
(CH,RH,EH,lH) be two BGs and let π be a homomorphism from G to H. The image
of G by π is π(G) = (π(CG),π(RG),E′,l′), with E′ being equal to the edges of EH
with one extremity in π(CG) and the other in π(RG), and l′ being the restriction of
lH. In other words, π(G) is the subgraph of H induced by π(CG)∪π(RG).
It is straightforward to check:
Property 2.2. If G and H are two BGs and π is a homomorphism from G to H, then
π(G) is a subBG of H.
Let us now observe what happens for homomorphism when BGs have several
individual concepts with the same marker. Let us consider the two BGs in Fig. 2.11.
There is clearly a homomorphism from G to H but there is no homomorphism in
the other direction, i.e., from H to G, even if the two BGs have the same intuitive
meaning that is: The individual m has properties r and s. We will discuss this point
in the section about normal BGs (cf. Sect. 2.5).

2.2 BG Homomorphism
33
H
G
r
r
s
s
t:m
t:m
t:m
Fig. 2.11 G ⪰H and H ̸⪰G
2.2.2 Bijective Homomorphisms and Isomorphisms
The notion of BG isomorphism is naturally deﬁned as follows:
Deﬁnition 2.11 (BG isomorphism). An isomorphism from a BG G to a BG H is a
bijection π from CG to CH and from RG to RH, which satisﬁes:
• ∀(r,i,c) ∈G,(π(r),i,π(c)) ∈H,
and
reciprocally,
∀(r′,i,c′) ∈H,
(π−1(r′),i,π−1(c′)) ∈G,
• ∀e ∈CG ∪RG,lG(e) = lH(π(e)).
A bijective BG homomorphism from G to H is an isomorphism from graph(G)
to graph(H), but it is a BG isomorphism only if it furthermore preserves labels (i.e.,
it fullﬁlls condition 2 of the BG isomorphism deﬁnition). Indeed, since a relation is
mapped to a relation of the same arity, a bijective homomorphism π from G to H
always fullﬁls the property that for all r′ and c′ in H, for all c and r in G, such that
c′ = π(c) and r′ = π(r), (π(r),i,π(c)) ∈H implies (r,i,c) ∈G (and reciprocally
by the homomorphism deﬁnition). Thus, the ﬁrst condition in the BG isomorphism
deﬁnition is satisﬁed by a homomorphism as soon as it is bijective.
Examples of bijective BG homomorphisms that are not BG isomorphisms natu-
rally occur when BGs represent data forms to ﬁll in.
A very simple data form schema is represented by DF in Fig. 2.12; F is a par-
tially ﬁlled data form corresponding to DF. It is simple to see that the mapping
represented by dashed arrows is a bijective homomorphism from DF to F.
Property 2.3. For any BG G, a bijective homomorphism from G to itself is an iso-
morphism.
Proof. The sets TC × M of concept labels and TR of relation symbols are partially
ordered.
Let us consider two linear extensions of the dual orders of these partially ordered
sets, both denoted ≤w, i.e., given two labels l1 and l2, ≤w is a total order and if
l1 ≥l2, then l1 ≤w l2.
Assign a weight to each concept and relation, which is the position of its label
in ≥w (starting from 1). It becomes heavier as it becomes more specialized. Then,

34
2 Basic Conceptual Graphs
F
DF
weightOf
heightOf
ageOf
Person: Paul
Person
Height
Weight
Age
KG: 70kgs
CM:180cms
Age
weightOf
heightOf
ageOf
Fig. 2.12 Data form and bijective homomorphism
to a BG, assign a weight (let us denote it w) which is the sum of its relation and
concept weights. Note that if there is an injective homomorphism from a BG G1 to
a BG G2, then w(G1) ≤w(G2). Now let π be a bijective homomorphism from G
to itself. Assume that π strictly restricts the label of at least one relation or concept
of G. Then w(G) < w(π(G)) which is impossible since π(G) = G. Thus π is an
isomorphism.
⊓⊔
2.2.3 BG Queries and Answers
With BGs and subsumption, we can build a basic query-answering mechanism. Let
us consider a KB (knowledge base) B composed of a set of BGs, representing some
assertions about a modeled world, e.g., a set of BGs representing facts about the
children photo example (Sect. 1.1.1). A query made to this base is itself a BG,
say Q. Elements answering Q are intuitively deﬁned as the elements in B that entail
Q, or equivalently, elements that are specializations of Q, or also, elements that are
subsumed by Q.
Girl
Car
possess
1
2
A query BG
Answers
possess
1
2
Girl
possess
1
2
Car
possess
1
2
RacingCar
FireTruck
Girl:Eva
Girl:Judith
Fig. 2.13 A query and possible answers

2.3 BG Subsumption Properties
35
More precisely, a query, hence the notion of answer, can be interpreted in differ-
ent ways:
• A query Q can be seen as a representation of a “yes/no question”: “Is the knowl-
edge represented by Q asserted by the KB?” For instance, the query in Fig. 2.13
may represent the question, “Is there a girl who owns a car?” or, “Is there a car
owned by a girl?” Note that, as a BG does not need to be a connected graph, B
can be seen as composing a single BG. The answer is boolean, which is true if
and only if Q subsumes B.
• A query Q can be seen as a “pattern” allowing us to extract knowledge from the
KB. Generic nodes in the query represent variables to instantiate with individual
or generic nodes in the base. The query Q in Fig. 2.13 would become “ﬁnd all
patterns in which a girl owns a car.” With this interpretation, each homomorphism
from Q to B deﬁnes an answer to Q. An answer can be seen as the homomorphism
itself, which assigns a node of the base to each node of the query. Or it can be
seen as the subgraph of B induced by this homomorphism, i.e., the image of Q
(see Fig.2.13 and also Fig. 2.12, where, assuming that the data form DF is used
as a query, F can be seen as an answer to this query).
Note that distinct homomorphisms from Q to B may produce the same image
graph; thus deﬁning answers as image graphs instead of homomorphisms induces
a potential loss of information. In turn, an advantage of considering image graphs
is that the set of answers can be seen as a BG. We thus have the property that the
results returned by a query are in the same form as the original data. This prop-
erty would be mandatory if we were interested in processing complex queries, i.e.,
queries composed of simpler queries; in this context, the answers to a query would
be seen as a knowledge base, which could be used to process another query.
A simple extension of this basic mechanism is classically considered. A query is
not simply a BG but a BG with distinguished concept nodes deﬁning the part to be
considered to deﬁne an answer. These nodes are usually distinguished by a question
mark (?) added to their marker. Then an answer is given by the part of the homomor-
phism having for domain the set of marked nodes, or by the associated image graph.
With the example in Fig. 2.13, marking the node [Girl] would lead to the query “ﬁnd
all girls who own a car” and, if answers are given as image graphs, would return the
graphs [Girl:Judith], [Girl] and [Girl:Eva]. We then have a mechanism equivalent to
conjunctive queries in databases, see Chap. 5.
2.3 BG Subsumption Properties
2.3.1 Subsumption Preorder
Properties concerning homomorphisms can be directly proven from the deﬁnitions
given above. For instance, it is simple to check the following property:

36
2 Basic Conceptual Graphs
Property 2.4 (Composition of homomorphisms). The composition of two homomor-
phisms is a homomorphism; thus the subsumption relation ⪰is transitive.
This property is also a direct corollary of two known properties: First, the com-
position of two graph homomorphisms is a graph homomorphism (the structure is
preserved). Secondly, order relations are transitive relations (the composition of two
decreases of labels is a decrease of labels).
⪰is also a reﬂexive relation since every BG maps to itself with the identity homo-
morphism. But ⪰is not antisymmetric: Indeed, there are non-isomorphic BGs that
map to each other. For instance, the BGs G and H in Fig. 2.14 are non-isomorphic
whereas G ⪰H and H ⪰G (there is a homomorphism from H to G, which maps
both concept nodes with label l1 to the same node in G). Figure 2.15 presents a more
complex example: Any BG in the ﬁgure subsumes any other.
Deﬁnition 2.12 (Hom-equivalence).
Two BGs G and H are said to be hom-
equivalent if G ⪰H and H ⪰G, also denoted G ≡H.
If G ⪰H and G and H are not hom-equivalent, we say that G is strictly more general
than H and note G ≻H (or H ≺G).
H
G
l1
r
l2
r
l2
r
l1
l1
Fig. 2.14 Two hom-equivalent BGs
An injective homomorphism is a special case of a homomorphism enforcing the
fact that distinct nodes necessarily have distinct images. Let G ⪰i H denote the fact
that there is an injective homomorphism from G to H. In Fig. 2.14 one has G ⪰i H
but not H ⪰i G. It is simple to check that this relation is transitive, reﬂexive and
antisymmetric; thus ⪰i is an order relation.
Property 2.5. ⪰is a preorder on the BGs deﬁned over V (and it is not an order). ⪰i
is an order on the BGs deﬁned over V.
Let G ⪰i H, then there is a bijective homomorphism from G to a subBG of H.
If the injectivity of a homomorphism concerns only the concept nodes, the induced
binary relation is not an order as shown in Fig. 2.16, where r ≤s (however, in this
case, checking “redundancy” becomes simple).
From a knowledge viewpoint, considering ⪰i instead of ⪰can be pertinent when-
ever two different concept nodes always represent two different entities. From a com-
plexity viewpoint, the decision problems “Is there a homomorphism from G to H,”
“Is there an injective homomorphism from G to H?” and “is there a bijective homo-
morphism from G to H?” are all NP-complete (cf. Sect. 2.6). Nevertheless, the two
relations ⪰and ⪰i behave differently from a complexity viewpoint (for instance,

2.3 BG Subsumption Properties
37
G3
G1
G2
G4
t
t
t
t : a
r
r
r
r
r
r
r
r
r
r
t : a
t : a
t : a
t
t
t
t
t
t
Fig. 2.15 Four hom-equivalent BGs
r
r
t
t
t
t
2
2
1
1
2
1
s
Fig. 2.16 Injectivity restricted to concept nodes (r ≤s)
given two BGs T and H, such that T is acyclic, checking whether T ⪰H is a poly-
nomial problem—see Chap. 7—whereas checking T ⪰i H remains NP-complete)
and, contrary to homomorphism, injective homomorphism is not a complete opera-
tion with respect to the formal semantics of BGs studied in Chap. 4.
2.3.2 Irredundant BGs
In this section the equivalence relation associated with the subsumption preorder is
studied. We show that any equivalence class has a distinct representative which is
the “simplest” BG of the class and that this element is unique (up to isomorphism).
Deﬁnition 2.13 (Irredundant and redundant). A BG is called redundant if it is
hom-equivalent to one of its strict subgraphs. Otherwise it is called irredundant.
Let G be a redundant BG. Let us consider a strict subBG H hom-equivalent to G
and having a minimum number of nodes. H is irredundant. Thus,

38
2 Basic Conceptual Graphs
Property 2.6. If a BG G is redundant, then it has an irredundant strict subBG hom-
equivalent to it.
Let G be a BG and H a subBG of G. There is a trivial homomorphism from H
to G, thus a BG is irredundant if and only if there is no homomorphism from it to
one of its strict subBGs. In other words, there is no non-injective (or equivalently
there is no non-surjective) homomorphism from G to itself. Equivalently, every ho-
momorphism from G to itself is a bijective homomorphism. We have proven that
any such homomorphism is in fact an isomorphism (Property 2.3). Thus we have:
Property 2.7. A BG G is irredundant if and only if every homomorphism from G to
itself is an isomorphism (automorphism).
Example. In Fig. 2.14, G is irredundant while H is not; the BGs in Fig. 2.15 are all
hom-equivalent, and G1 is the only irredundant BG.
We now prove that a class of hom-equivalent BGs contains a unique irredundant
BG. Thus this irredundant BG can be taken as the representative of the equivalence
class. For this we use the following property.
Property 2.8. Let G be any BG and H be an irredundant BG. If G is hom-equivalent
to H, then G has a subBG isomorphic to H.
Proof. If G and H are hom-equivalent, there is a homomorphism, say π, from H to
G and a homomorphism, say π′, from G to H. Now consider the homomorphism
π′ ◦π from H to H. π′ ◦π is an isomorphism (by Property 2.7).
Let G′ = π(H). Let us show that π is an isomorphism from H to G′. π is sur-
jective by deﬁnition of G′, and π is injective since π′ ◦π is injective. Thus π is a
bijective homomorphism from H to G′.
Now, for all concept or relation x in H, label(x) ≥label(π(x)) ≥label(π′ ◦
π(x)) = label(x) thus label(x) = label(π(x)). π is thus an isomorphism from H
to G′, which proves the property.
⊓⊔
Theorem 2.1. Each hom-equivalence class contains a unique (up to isomorphism)
irredundant BG which is the BG having the smallest number of nodes.
Proof. Property 2.8 implies that two irredundant BGs are hom-equivalent if and
only if they are isomorphic. Thus an equivalence class contains at most one irre-
dundant BG. Now, given an equivalence class, let us take a BG, say G, of minimal
size (with the size being the number of concepts and relations). G is irredundant,
otherwise it would be hom-equivalent to one of its strict subBGs, which contradicts
the hypothesis on G.
⊓⊔
Example. In Fig. 2.15, each BG contains an irredundant subgraph isomorphic to
G1, to which it is hom-equivalent.
G may contain several irredundant subBGs hom-equivalent to it, but in this case
they are all isomorphic to each other. Any of these subBGs can be taken as the
irredundant form of G. The following property gives more insight into the relation-
ships between a BG and its irredundant form: A redundant BG can be folded to its
irredundant form.

2.3 BG Subsumption Properties
39
Deﬁnition 2.14 (Folding). Let G be a BG, let π be a homomorphism from G to
itself and let G′ = π(G). π is called a folding from G to G′ if each node of G′ is
invariant by π, i.e. ∀x ∈CG′ ∪RG′,π(x) = x.
Property 2.9. Let G be a BG and let G′ be one of its hom-equivalent irredundant
subBGs. Then there is a folding from G to G′.
Proof. By hypothesis there is a homomorphism, say π, from G to G′. Let π′ be the
homomorphism obtained from π by restricting its domain to G′: π′ is an isomor-
phism (from Corollary 2.7). Then π′′ = π′ ◦π is also a homomorphism from G to
G′, which is the identity on G′. π′′ is thus a folding.
⊓⊔
The folding notion is a direct adaptation for BGs of a classical notion in graph
theory. Note that G′ being irredundant is essential to this property: A BG cannot
always be folded into any of its hom-equivalent subBGs.
If a BG G has duplicate relations, then it is redundant since the subgraph obtained
by deleting a duplicate relation is hom-equivalent to it. More generally, if G has two
relations with the same neighbors in the same order, such that one relation has a
type greater or equal to the type of the other, then the relation with the more general
type is redundant. In the absence of redundant relations, G is redundant if and only
if there is a homomorphism from G to itself that maps two concepts to the same
concept, say c1 and c2 to c2; in this case there is a homomorphism from G to the
subBG obtained by deleting c1 and its neighboring relations. Finally, let us point out
that rendering a BG irredundant is generally not a simple task. Indeed, the associated
decision problem, namely “Given a BG G, is G redundant?”, is an NP-complete
problem, as we shall see in Sect. 2.6.
Considering irredundant BGs only, the subsumption relation becomes a special
partial order—it is a lattice.
Property 2.10. Let G be the set of all irredundant BGs deﬁnable over a given vocab-
ulary. Then (G, ⪯) is a lattice.
Proof. The set of BGs over a given vocabulary admits a greatest element: the empty
BG. Should we exclude the empty BG, there is still a greatest element, the BG
restricted to one generic concept with universal type. Now let us consider G and
H two (irredundant) BGs and their disjoint sum G + H. G and H subsume G +
H. And every BG K which is subsumed both by G and H is also subsumed by
G + H (the union of two homomorphisms from G to K and from H to K deﬁnes
a homomorphism from G + H to K). Thus the irredundant BG hom-equivalent to
G + H is the greatest lower bound of G and H. The set of irredundant BGs is thus
an inf-semi-lattice, and since it possesses a greatest element, it is a lattice.
⊓⊔
Note that the previous property is true even if the set of concept node labels is
not a lattice. The only property required, if the empty BG is not admitted, is that the
concept type set has a greatest element. There is no condition on the relation symbol
set.
Example. In Fig. 2.17, the vocabulary given on the left is restricted to a concept
type set, and it should be noted that this set is not a lattice. The lattice on the right

40
2 Basic Conceptual Graphs
represents all irredundant BGs constructible on this vocabulary, except for the empty
BG.
T
T
t1
t2
t3
t4
t3
t2
t4
t1
t2
t1
t4
t3
Fig. 2.17 A lattice of irredundant graphs
2.4 Generalization and Specialization Operations
Transforming a BG into its image by a homomorphism is a global operation between
BGs that can be decomposed into simpler operations. Sets of elementary operations
“equivalent” to homomorphism—in the sense that there is a homomorphism from
G to H if and only there is a sequence of elementary operations transforming G
into H—are presented in this section. Some of these elementary operations are fre-
quently used in applications (e.g., the join in natural language processing). More
complex operations can be deﬁned using these elementary operations (e.g., extended
join and maximal join deﬁned in Chap. 8). Finally, these elementary operations are
used in order to inductively deﬁne BGs (cf. Chap. 8).
There are ﬁve elementary generalization operations and ﬁve inverse operations,
called elementary specialization operations.
2.4.1 Elementary Generalization Operations for BGs
Any generalization operation is a “unary” operation, i.e it has a BG (and some ele-
ments of it) as input and has a BG as output.
Deﬁnition 2.15 (Generalization operations). The ﬁve elementary generalization
operations are:
• Copy. Create a disjoint copy of a BG G. More precisely, given a BG G, copy(G)
is a BG which is disjoint from G and isomorphic to G.
• Relation duplicate. Given a BG G and a relation r of G, relationDuplicate(G,r)
is a BG obtained from G by adding a new relation node r′ having the same type

2.4 Generalization and Specialization Operations
41
and the same list of arguments as r, i.e., the same neighbors in the same order.
Two such relations of the same type and having exactly the same neighbors in
the same order are called twin relations.
• Increase. Increase the label of a node (concept or relation). More precisely,
given a BG G, a node x of G, and a label L ≥l(x) increase(G,x,L) is the BG
obtained from G by increasing the label of x up to L, that is its type if x is a
relation, its type and/or its marker if x is a concept.
• Detach. Split a concept into two concepts. More precisely, let c be a concept
node of G and {A1,A2} be a partition of the edges incident to c, detach(G,c,A1,
A2) is the BG obtained from G by deleting c, creating two new concept nodes c1
and c2, having the same label as c, and by attaching A1 to c1, and A2 to c2 (A1 or
A2 may be empty).
• Substract. Given a BG G, and a set of connected components C1,...,Ck of G,
substract(G,C1,...,Ck) is the BG obtained from G by deleting C1,...,Ck (the
result may be the empty graph).
Remark
Copy and relation duplicate are actually equivalence operations, i.e., they do not
change the semantics of the graph (cf. Chap. 4).
The copy operation is in fact not needed in generalization operations since a copy
of a graph can be obtained by a Relation Duplicate sequence followed by a Detach
sequence ended by a Substract. It is considered as a generalization operation for
symmetry reasons with specialization operations.
The copy operation is also needed because, in some situations, we do not consider
BGs up to isomorphism. For instance, in implementation and drawings two copies
of the same BG must be considered as two different BGs.
The substract operation is deﬁned as the deletion of a set of connected compo-
nents, and not the deletion of only one component, in order to be the inverse of the
disjoint sum, which is an elementary specialization deﬁned later.
Example. The relation duplicate operation is illustrated in Fig. 2.18. The detach
operation is illustrated in Fig. 2.19.
It is now possible to precisely deﬁne what a BG G is a generalization of a BG H
means:
Deﬁnition 2.16 (Generalization). A BG G is a generalization of a BG H if there
is a sequence of BGs G0 = (H),G1,...,Gn = (G), and, for all i = 1,...,n, Gi is
obtained from Gi−1 by a generalization operation.
Example.
Figure 2.20 presents some of the graphs occurring in a generalization sequence
from H to G. H1 is obtained from H by splitting the nodes [Child:Paul] and
[FireTruck] (Detach operation), then deleting the connected component K pictured
in the dashed rectangle (Substract operation). H2 is obtained from H1 by duplicating
the (on) relation (Relation Duplicate operation). H3 is obtained from H2 by splitting

42
2 Basic Conceptual Graphs
f
H=relationDuplicate(G,r1)
f
H
b
b
a
a
k
k
k
2
2
2
1
1
1
r
r
r
G
G=relationSimplify(H,r2)
r1
r2
r1
Fig. 2.18 Relation duplicate and its inverse Relation simplify
G=join(H,c1,c2)
G
H
H=detach(G,c,A1,A2)
l
l
l
A1
A2
c
c1
c2
Fig. 2.19 Detach and its inverse Join
the node [FireTruck] (Detach operation). Finally, H4 isomorphic to G is obtained
by increasing some labels (Increase operation). This generalization sequence can
be associated with the homomorphism h1 in Fig. 2.10. The equivalence between
a homomorphism and a generalization sequence is stated in next properties (Prop-
erty 2.12 and Property 2.13).
Property 2.11. A subBG G′ of a BG G is a generalization of G.
Proof. Any boundary concept of G′ can be split into c1 and c2 in the following way:
The neighbors of c1 are the neighbors of c, which belong to G′, and the neighbors
of c2 are the neighbors of c, which do not belong to G′. Then, all connected compo-
nents having a node outside G′ are removed, and the remaining BG, which has been
obtained from G by generalization, is precisely G′.
⊓⊔
2.4.2 Generalization and Homomorphism
In this section, we prove that G subsumes H if and only if G is a generalization of
H. Thus, homomorphism, which is a global notion (it is a mapping between sets),

2.4 Generalization and Specialization Operations
43
Child
Child
H3
H2
H
1
playWith
2
1
2
1
Color:red
2
1
2
1
playWith
2
playWith
2
1
H4=G
1
act
Toy
2
1
2
1
Child
2
Color:red
1
2
2
1
1
2
2
1
playWith
2
K
1
2
1
Color:red
2
1
1
2
2
1
Color:red
2
1
playWith
H1
playWith
2
1
1
2
Color:red
1
2
on
Child:Paul
FireTruck
Mat
attr
on
FireTruck
on
Child:Paul
FireTruck
on
on
FireTruck
Child:Paul
attr
Mat
on
FireTruck
Child:Paul
sisterOf
Child:Paul
FireTruck
Car
attr
Mat
on
on
attr
Mat
Mat
attr
sisterOf
Fig. 2.20 Generalization from H to G
can be replaced by a sequence of simple operations: Copy and substract are simple
to understand, and the three others are local. Furthermore, the ﬁve operations are
simple to draw.
Property 2.12. If a BG G is a generalization of a BG H, then there is a homomor-
phism from G to H (G ⪰H).
Proof. One ﬁrst proves that if G is obtained from H by an elementary generalization
operation then there is a homomorphism from G to H. It is trivial for the copy
operation since an isomorphism is a homomorphism.
• Relation duplicate. Let r′ be a relation duplicate of a relation r. The mapping π
deﬁned as follows is a homomorphism:
π(r′) = r and ∀x ̸= r, x node of G, π(x) = x.
• Increase. Let G = increase(H,x,L). The mapping which associates to each node
of G its corresponding node in H is a homomorphism (the only difference

44
2 Basic Conceptual Graphs
between G and H is that lG(x) ≥lH(x)).
• Detach. Let c1 and c2 be the concepts resulting from the split of c. The mapping
π deﬁned as follows is a homomorphism:
π(c1) = π(c2) = c and ∀x ∈CG ∪RG \{c1,c2}, π(x) = x.
• Substract. G is equal to a subBG of H and the identity is a homomorphism.
As the composition of two homomorphisms is a homomorphism, one concludes by
recurrence on the length of a generalization sequence.
⊓⊔
Property 2.13. If there is a homomorphism from a BG G to a BG H, then G is a
generalization of H.
Proof. Let π be a homomorphism from G to H. We build a sequence of generaliza-
tion operations from H to G as follows.
1. We ﬁrst build a generalization sequence from H to π(G). As π(G) is a subBG
of H, property 2.11 can be applied: The sequence is composed of a sequence of
Detach on the boundary nodes of π(G) followed by a Substract.
2. for every relation r such that |π−1(r)| = 1, say π−1(r) = {r′}, the label of r is
increased to that of r′.
3. for every relation r such that π−1(r) = {r1,...,rk}, with k ≥2, r is duplicated
k −1 times into s1(= r),...,sk, and for any i, the label of si is increased to that
of ri.
4. for every concept c such that |π−1(c)| = 1, say π−1(c) = {c′}, the label of c is
increased to that of c′.
5. for every concept c such that π−1(c) = {c1,...,ck}, with k ≥2, c is split by a
Detach into k concepts d1,...,dk, and, for any i, the edges incident to di are the
images by π of the edges incident to ci. Furthermore, for any i, the label of di is
increased to lG(ci). We obtain (a BG isomorphic to) G.
⊓⊔
The two previous properties give the following theorem, which justiﬁes the term
generalization for the existence of both a homomorphism and a sequence of ele-
mentary generalization operations.
Theorem 2.2 (Homomorphism and generalization). There is a homomorphism
from a BG G to a BG H (G ⪰H) if and only if G is a generalization of H.
Example. In Fig. 2.20 some graphs of a generalization sequence from a BG H to
a BG G are pictured. This sequence corresponds to the homomorphism h1 from
G to H presented in Fig. 2.10. It follows the proof steps of Property 2.13, except
that all labels are increased at the last step instead of during the construction. More
speciﬁcally, H1 is equal to h1(G); its construction thus corresponds to step 1 of the
proof. Step 2 is delayed. The construction of H2 corresponds to step 3, with the
increase in labels being delayed. Similarly, the construction of H3 corresponds to
step 4, with the increase in labels being delayed. Finally, the construction of H4
gathers all label increases.

2.4 Generalization and Specialization Operations
45
2.4.3 Elementary Specialization Operations
The elementary specialization operations deﬁned in this section are inverse (up to
an abuse of language explained hereafter) operations of the elementary generaliza-
tion operation deﬁned previously. Besides the copy operation, there are three unary
operations and one binary operation.
Deﬁnition 2.17 (Elementary specialization operations). The ﬁve elementary spe-
cialization operations are:
• Copy (already deﬁned as a generalization operation).
• Relation simplify. Given a BG G, and two twin relations r and r′ (relation with
the same type and the same list of neighbors), relationSimpli fy(G,r′) is the BG
obtained from G by deleting r′.
• Restrict. Given a BG G, a node x of G, and a label l ≤l(x) restrict(G,x,l) is the
BG obtained from G by decreasing the label of x to l, which is its type if x is a
relation, its type and/or its marker if x is a concept.
• Join. Given a BG G, and two concepts c1 and c2 of G with the same label,
join(G,c1,c2) is the BG obtained from G by merging c1 and c2 in a new node c,
i.e. the edges incident to c are all edges incident to c1 and to c2 and c1 and c2 are
deleted.
• Disjoint sum. Given two disjoint BGs G = (C,R,E,l) and H = (C′,R′,E′,l′),
G+H is the union of G and H that is the BG (C ∪C′,R∪R′,E ∪E′,l ∪l′). G or
H may be empty.
It is noted in the deﬁnition of the disjoint sum operation that G or H may be
empty. This speciﬁc case is needed in order to obtain any BG from the empty BG G∅,
with G∅being more general than any BG. The Relation simplify and Join operations
are pictured in Fig. 2.18 and Fig. 2.19, together with their inverse generalization
operations, respectively Relation duplicate and Detach.
Example. In reading Fig. 2.20 from G to H, one obtains the sketch of a special-
ization sequence. This sequence corresponds to the homomorphism h1 from G to
H presented in Fig. 2.10. More speciﬁcally, H3 is obtained from G by four re-
strict operations. H2 is obtained from H3 by a join of the concept nodes with label
(FireTruck,∗). A relation simpliﬁcation of a relation with label (on) in H2 yields
H1 = h1(G). Finally, a disjoint sum of H1 and K followed by two joins on the con-
cept nodes with labels, respectively (Child,Paul) and (FireTruck,∗), produces H.
It is straightforward to check the following relationships between elementary
generalization operations and elementary specialization operations:
• If H is obtained from G by the deletion of a relation r′, twin of a relation r, then
G is isomorphic to a BG obtained from H by duplicating r, and conversely.
• If H is obtained from G by restricting to b the label a of a node x, then G can be
obtained from H by increasing the label of x from b to a, and conversely.

46
2 Basic Conceptual Graphs
• If H is obtained from G by joining two nodes x and y into a new node xy, then G
is isomorphic to a BG obtained from H by detaching xy into two nodes x′ and y′
having the same neighboring as x and y in G, and conversely.
• If H is equal to the disjoint sum G + K, then G can be obtained from H by a
substract operation.
Thanks to these relationships, we will make an abuse of language whereby we say
that elementary specialization operations are inverse of elementary generalization
operations.
The direct deﬁnition of a specialization notion inverse to the deﬁnition of a gen-
eralization (cf. Deﬁnition 2.16) for specialization operations is not so simple. This
is due to the operation disjoint sum which is a binary operation which has one new
input BG. Thus, instead of a sequence, we will ﬁrst consider a tree, as illustrated in
Fig. 2.21 and deﬁned below.
Deﬁnition 2.18 (Specialization tree). A specialization tree of a BG G is an anti-
rooted tree T whose nodes are labeled by BGs in such a way that:
• T has an anti-root labeled by G.
• Let x be any node with label H, then
– x is a leaf (i.e., x has no predecessors), or
– x has exactly one predecessor labeled K, and H is obtained from K by one of
the unary specialization operations, or
– x has exactly two predecessors, respectively labeled K1 and K2, and H = K1 +
K2.
K
.
.
.
.
.
.
.
.
.
.
.
join the two nodes [Firetruck]
simplify a relation (on)
disjoint sum of H1 and K
join the two nodes [Firetruck]
join the two nodes [Child:Paul]
H3
8
1
2
3
4
5
6
7
9
10
H=G0
G
restrict Car to Firetruck
restrict * to Paul
restrict Toy to Firetruck
restrict Toy to Firetruck
H2
H1
Fig. 2.21 The specialization tree corresponding to Fig. 2.20

2.4 Generalization and Specialization Operations
47
The transitive closure of an anti-rooted tree is a partial order, and any total or-
dering of the nodes containing that partial order is called a linear extension of the
partial order.
Deﬁnition 2.19 (Specialization). Given a specialization tree of a BG G, the se-
quence of BGs labeling any linear extension of the tree is called a specialization
sequence of G. G is said to be a specialization of any BG H appearing in a special-
ization sequence of G.
Example. In Fig. 2.21, the vertex set of the specialization tree is {1,...,11}. There
are several linear extensions of this tree which differ only by the rank of the vertex
8 labeled by K. In any case, this node has to appear before node 9. For instance
the linear extension (1 ...7 8 9 10 11) yields a specialization sequence of form
(G = H4, ..., H3, ,H2, H1, K, ..., H).
Property 2.14. If G and H are two BGs, then H is a specialization of G if and only
if G is a generalization of H
Proof. Let us consider a specialization sequence from G to H. Then, it is possible
to transform this sequence into a generalization sequence from H to G by replacing
each elementary specialization operation by an elementary generalization operation.
Conversely, any generalization sequence from H to G can be transformed into a
specialization sequence from G to H.
⊓⊔
In some situations, especially when one wants to actually build a BG by a se-
quence of elementary specialization operations, it is interesting to consider a spe-
cialization graph and not only a tree. Let us assume, for instance, that there is a
set of BGs B used as building blocks (cf. Chap. 8). In other words, the leaves of
the specialization tree can be labeled only by elements of B. Then imagine that, to
build a certain BG, one needs twice the “same” subBG G′ (e.g., this BG has two
isomorphic disjoint subgraphs). Assume that a ﬁrst subBG G′ has been built and G′′
isomorphic to G′ is needed. If a specialization tree is considered, a second graph has
to be built from the building blocks in the same way as G′. In a specialization graph,
G′′ can be simply obtained by copying G′.
Deﬁnition 2.20 (Specialization graph). A specialization graph of a BG H is a
directed graph without circuits D whose nodes are labeled by BGs in such a way
that:
• D has an anti-root labeled by H.
• Let x be any node with label G, then
– x is a source (i.e., x has no predecessors), or x has exactly one predecessor
labeled K, and G is obtained from K by one of the unary specialization oper-
ations, or x has exactly two predecessors, respectively labeled K1 and K2, and
G = K1 +K2,
– x may have several successors, but at most one does not correspond to a copy
operation.

48
2 Basic Conceptual Graphs
Property 2.15. Given any specialization graph D of H, there is a specialization tree
T of H with the same set of leaf labels.
Proof. Let us consider a specialization graph D with its anti-root labeled by H and
the set of its leaf labels equal to {L1,...,Lp}. Let us prove the property by recurrence
on the number of nodes having at least two successors. If D has no node with two or
more successors, then D is a tree. Otherwise, let us consider a node x of D having at
least two successors such that all the predecessors of x have exactly one successor.
Let the successor set of x be {y1,...,yk}, k ≥2, with y2,...,yk being obtained from
x by a copy operation. Let us denote by Dx the subgraph of D induced by all the
ascendants of x (x included). The graph D′ obtained from D by creating k−1 disjoint
copies of Dx with anti-roots x2,...,xk, respectively, and by replacing each arc from
x to yi by the arc joining xi to yi, for i = 2,...,k, is a specialization graph with its
anti-root labeled by H and its leaf label set being equal to {L1,...,Lp}. Furthermore,
the number of nodes of D′ having at least two successors is equal to the number of
nodes of D having at least two successors minus one. One concludes by using the
recurrence hypothesis.
⊓⊔
2.4.4 Specialization and Homomorphism
From Property 2.14 and Theorem 2.2, one obtains:
Theorem 2.3 (Homomorphism and Spec./Gen.). Let G and H be two BGs. The
three following propositions are equivalent:
1. G is a generalization of H
2. H is a specialization of G
3. there is a homomorphism from G to H, i.e. G ⪰H
Let us consider a homomorphism π from G to H. We have shown how it is pos-
sible to build a sequence of elementary generalization operations transforming H
into G (cf. proof of property 2.13). Using the duality between generalization and
specialization operations, it is possible to transform this sequence into a sequence of
elementary specialization operations transforming G into H (Property 2.14). For the
sake of completeness, we brieﬂy indicate how a specialization sequence transform-
ing G into H can be directly built from π (i.e., without considering a generalization
sequence from H to G). Note that this sequence is not the exact inverse of the gen-
eralization sequence given in the proof of Property 2.13 because the order in which
label modiﬁcations naturally occur are not the same.
1. For every concept or relation node x in G, the label of x is restricted to the label
of π(x). We obtain G1. Now, all nodes with the same image by π have the same
label.
2. All concept nodes in G1 with the same image in H are joined. More precisely,
for every concept node c′ in H such that π−1(c′) = {c1,...,ck}, k ≥2, all the ci

2.5 Normal BGs
49
are joined. We obtain G2. Now, all relations with the same image by π are twin
relations.
3. A sequence of relation simpliﬁcations is performed on G2 to keep only one re-
lation per set of relations with the same image in H. More precisely, for every
relation r′ in H such that π−1(r′) = {r1,...,rk}, k ≥2, (k−1) relation simplica-
tions on r2, ..., rk (for instance) are performed. The graph obtained, i.e., G3, is
isomorphic to π(G).
4. Let us consider the BG K obtained from H by deleting all nodes of π(G) that are
not boundary nodes. A disjoint sum of G3 and K yields G4.
5. Finally, a sequence of join operations are applied on G4: Each boundary node of
G3 is joined to its corresponding node in K. The BG obtained is (isomorphic to)
H.
Example. Let us consider Fig. 2.20, which sketches a generalization sequence from
H to G guided by the homomorphism h1 in Fig. 2.10. Reading this ﬁgure in the
inverse direction, one obtains the sketch of a specialization sequence from G to H
built from h1 as above. More speciﬁcally, H3, H2 and H1 respectively correspond to
the BG G1, G2 and G3 built at the above steps 1, 2 and 3. The union of H1 and K
corresponds to G4. Finally, H is obtained.
2.5 Normal BGs
2.5.1 Deﬁnition of Normal BGs
Two concept nodes having the same individual marker represent the same entity.
This can be seen as the simplest kind of equality. Introducing the equality between
any kind of concept nodes (i.e., not only individual concepts but also generic con-
cepts) is the main objective of the next chapter, and the present section can be con-
sidered as an introduction to this chapter.
If a BG has several individual concept nodes with the same marker, we would like
to be able to merge these nodes into a single individual concept, while keeping the
same intuitive meaning (and the same formal semantics, see Chap. 4). Note ﬁrst that,
even when there is an obvious way of merging the concepts, the obtained BG is gen-
erally not hom-equivalent to the original BG. This point is illustrated by Fig. 2.22.
Let us consider the BG G, in which the individual marker m appears twice. The
nodes to be merged have exactly the same label, thus merging them simply consists
of performing a Join operation. Let H be the resulting BG. G and H are obviously
semantically equivalent, but H is strictly more speciﬁc than G for the subsumption
relation (indeed there is a homomorphism from G to H but no homomorphism from
H to G). Now, assume for instance, that G represents an assertion and let Q be the
query pictured in the ﬁgure. There is a homomorphism from Q to H but not to G,
thus H answers Q while G does not.

50
2 Basic Conceptual Graphs
G
H
t:m
r
r
r
t:*
t:m
t:m
s
s
s
Q
Fig. 2.22 Homomorphism and normality
Thus, BGs having several individual concept nodes with the same marker do not
have a normal behavior with respect to the subsumption relation, and this naturally
leads to the following deﬁnition of normal BGs:
Deﬁnition 2.21 (Normal BG). A BG is called normal if there is at most one individ-
ual concept with a given marker, i.e., all individual concepts have distinct markers.
Example. H and Q in Fig. 2.22 are normal while G is not. G in Fig. 2.23 is not
normal because the individual Paul occurs in two concept nodes, and norm(G) is a
normal BG semantically equivalent to G.
A second issue concerns the conditions under which any BG can be transformed
into a semantically equivalent normal BG. Let Pc denote the partition of the set
of concept nodes of a BG deﬁned as follows: Any generic concept deﬁnes a class
restricted to itself, and all the individual concepts with the same marker deﬁne a
class. A BG is normal if and only if its partition Pc is the discrete partition. If a BG
is not normal, then one can consider its quotient graph G/Pc deﬁned as follows:
Deﬁnition 2.22 (G/Pc). Let G = (C,R,E,l) be a BG. G/Pc is the graph deﬁned as
follows:
• its set of concept nodes is in bijection with Pc,
• its set of relation nodes is in bijection with R,
• for any (r,i,c) in G, (r′,i,c′) is in G/Pc, where r′ is the relation node correspond-
ing to r, and c′ corresponds to the class containing c.
In order to transform the graph G/Pc into a BG, a label has to be deﬁned for
the classes of Pc. The label of a node corresponding to a trivial class of Pc is the
label of the unique node of that class. The marker associated with a non trivial class
is obviously the individual marker appearing in all nodes of this class. But, if no
conditions are enforced on the types of individual concepts composing the class,
there is no garantee that a type preserving semantic equivalence can be deﬁned.
We shall now enumerate some simple conditions, but, as we shall see, none is
completely satisfactory from a knowledge representation viewpoint.
• Unicity condition
One can impose that all concepts with the same individual marker have the same

2.5 Normal BGs
51
type. Then the label of the node of G/Pc corresponding to a non-trivial class is
the label of any concept in this class. In this case, G and G/Pc have the same
intuitive meaning.
Example. By merging c1 and c2 in G in Fig. 2.23, the normal BG norm(G) is
obtained.
G
play3
norm(G)
play3
1
2
3
Person
Size: Small
possess
attr
c2
Car
1
2
1
2
Person: Paul
c1
Person: Paul
1
2
3
Person
Person: Paul
Size: Small
possess
attr
c1
c2
Car
1
2
1
2
Fig. 2.23 Normalization of a BG
In such cases, G/Pc is a normal BG that is called the normal form of G. The
notation norm(G) is also used. A canonical homomorphism from G to G/Pc can
be deﬁned. This homomorphism associates to any concept node c the node corre-
sponding to the class containing this node, and to any relation its corresponding
relation.
But allowing individual concepts with the same marker and different types could
be useful. For instance, let us consider the following situation where #123 is
a pick-up car. One would like to represent speciﬁc characteristics of the pick-
up #123 (e.g., number of kilometers in the bush, composition of ﬁrst-aid kit,
state of the tires) by an individual concept of type Pickup and marker #123, and
to represent administrative data of the car #123 (e.g., names and addresses of
the successive owners) by another individual concept of type Car and the same
individual marker. In this situation, as Pickup is a subtype of Car, these two
individual concepts could be merged into a single individual concept of type
Pickup while keeping the same semantics. This leads to the following condition.
• Minimality condition
One can relax the unicity condition of types and replace it by a minimality condi-
tion, i.e., for any class A of Pc the set TA of types of concepts in A has a minimal
element min(TA) (within TA). In this case, G and G/Pc have the same intuitive
meaning (with the type of concept in G/Pc associated with the class A being
equal to min(TA)). But this minimality condition is still too strong. Indeed, let

52
2 Basic Conceptual Graphs
us consider a BG having a class A = {c,c′} of Pc with labels l(c) = (t,m) and
l(c′) = (t′,m), and t and t′ incomparable. The minimality condition is not re-
spected, and the two individual concepts cannot be merged, even if m actually
represents an entity of type t′′ less than t and t′. But what happens if {t,t′} has
several minimal elements (within TC)?
This leads to the following condition.
• Greatest lower bound condition
This condition consists of requiring that the set of all concept types of any class
of Pc has a greatest lower bound (glb) in TC. Hence, as Pc is relative to a speciﬁc
BG, generalizing this glb condition to any BG leads us to assume that TC is an
inf-semi-lattice. But in this case, if one wants to keep the BG semantic, one must
assume the following property: If m is a t and m is a t′, then m is a glb(t,t′).
This lattice-theoretic interpretation of the concept type set is discussed in the
next chapter.
• Typing of individual markers
Let us recall that a typing of the individual markers is a mapping τ from the set of
individuals I to the set of concept types TC. For an individual m, all occurrences
of individual concept nodes with marker m must have a type greater than or
equal to τ(m). Having a typing of individual markers comes down to the unicity
condition. Indeed, before any computation with a BG, all types of individual
concepts with marker m can be replaced by τ(m).
In the Simple Conceptual Graphs model presented in the next chapter, we will
see how this problem is tackled and how it is possible to explicitly express that
several concepts, either generic or individual, represent the same entity. Thus the
simple conceptual graph model can be considered as the basic conceptual model
enriched by equality between concepts.
2.5.2 Elementary Operations for Normal BGs
The subsumption relation, deﬁned through the homomorphism notion, is the funda-
mental reasoning tool in conceptual graphs. Thus, normal BGs, which have a nice
behavior relative to homomorphism, are the fundamental class of BGs (and of the
simple conceptual graphs studied in the next chapter). Previous generalization and
specialization operations correspond to homomorphisms between BGs. But can we
take these operations as reference operations on normal BGs? The only ﬂaw is that,
as such, they are not internal operations on normal BGs since a non-normal BG can
be produced from a normal BG. Moreover, given two normal BGs G and H with
G ⪰H, there may be no way of deriving one from the other without producing a
non-normal BG somewhere in the derivation (cf. Fig. 2.24).
If we consider generalization, the guilty operation is the operation detach (when
it splits an individual node). Concerning specialization, there are two guilty opera-
tions, restrict (when it restricts a generic concept to an individual concept, whereas

2.5 Normal BGs
53
r
H
r
s
G
t : b
t : a
2
1
1
2
t : a
t : b
1
2
Fig. 2.24 Every specialization sequence from G to H contains a non-normal BG
the individual marker already appears elsewhere in the BG) and dis joint sum (when
there are individual concepts with the same label in the two BGs).
Let us consider a situation where it is possible to merge individual concepts hav-
ing the same marker. Then the operations detach, restrict and dis joint sum can be
slightly transformed as follows:
• detachnorm. Modify detach as follows: If c is an individual concept, replace the
marker of c2 by a generic marker (which involves an increase).
• restrictnorm. Modify restrict as follows: Let x be a generic concept restricted to
an individual node; if there is already a concept with the same individual marker,
merge these concepts (which involves a restrict of the greater type to the smaller,
if the types of the concepts are not equal, followed by a join).
• disjoint-sumnorm. Modify dis joint sum as follows: A disjoint sum operation is
followed by the merging of the individual concepts having the same marker.
Note that the modiﬁed generalization and specialization operations are internal
operations on normal BGs. It remains to be shown that they deﬁne the same rela-
tionship between normal BGs as the original ones.
Property 2.16. Let G and H be two normal BGs. G is a generalization of H using
detachnorm instead of detach (notation G ⪰norm H) if and only if there is a homo-
morphism from G to H.
Proof. Similar to the proofs of Property 2.12 and Property 2.13 for BGs. Each gen-
eralization operation yielding Gj from Gi deﬁnes a homomorphism from Gj to Gi,
thus by composition of all homomorphisms associated with a derivation from H
to G, one obtains a homomorphism from G to H. Reciprocally, let us consider the
proof of Property 2.13: detachnorm preserves the property that any subBG of H is a
generalization of H (Property 2.11), thus the proof still holds for ⪰norm.
⊓⊔
Property 2.17. Let G and H be two normal BGs. H is a specialization of G (nota-
tion: H ⪯norm G) using restrictnorm instead of restrict and disjoint-sumnorm instead
of disjoint sum if and only if G ⪰norm H.
Proof. Similar to the proof of Property 2.14.
If Gj is obtained from Gi by a relation duplicate operation, then Gi is obtained
from Gj by a relation simplify operation.
If Gj is obtained from Gi by a detachnorm and the marker m of the individual node
c2 becomes a generic marker, then Gi can be obtained from Gj by a restrictnorm of

54
2 Basic Conceptual Graphs
c2 to the marker m.
If Gj is obtained from Gi by an increase operation, then Gi is obtained from Gj by
a restrict operation, therefore by a restrictnorm operation.
If Gj is obtained from Gi by a substract operation, then Gi is obtained from Gj by a
disjoint sum, therefore by a disjoint-sumnorm operation.
It is straightforward to check the other direction.
⊓⊔
Corollary 2.1. Let G and H be two normal BGs. H ⪯norm G if and only if G ⪰norm H.
Theorem 2.4 (⪯norm) and homomorphism). Let G and H be two normal BGs. The
three following propositions are equivalent:
1. H ⪯norm G
2. G ⪰norm H
3. there is a homomorphism from G to H.
2.6 Complexity of Basic Problems
Let us consider the following three basic problems:
•
BG-HOMOMORPHISM: given two BGs G and H, is there a homomorphism from
G (the source) to H (the target)?
•
HOM-EQUIVALENCE: given two BGs, are they equivalent?
•
REDUNDANCY: given a BG, is it redundant?
We will show that they are all NP-complete. Let us ﬁrst stress two points. First,
the fact that these problems are NP-complete does not mean that they cannot be
efﬁciently solved in practice. Chapter 6 is devoted to algorithmic techniques for
ﬁnding homomorphisms. Chapter 7 is devoted to particular cases in which BG-
HOMOMORPHISM can be solved in polynomial time.
Secondly, the really fundamental problem is BG-HOMOMORPHISM, and that ex-
plains why we focus on it throughout this book. Indeed, let us assume that we
have an algorithm for solving BG-HOMOMORPHISM; checking whether two BGs are
hom-equivalent can be done with two calls to this algorithm, and checking whether
a graph G is redundant can be done with a number of calls to this algorithm, which
is linear in the size of G. In the trivial case where G has a redundant relation node
(i.e., a relation node with type t such that there is another relation node with the
same argument list and type t′ ≤t), it is redundant. Otherwise, G is redundant if
and only if it can be mapped to one of its subgraphs G −{x} obtained by deleting
a concept node x and all relation nodes incident to it. There are at most |CG| such
subgraphs. Thus, an efﬁcient algorithm for BG-HOMOMORPHISM directly yields an
efﬁcient algorithm for HOM-EQUIVALENCE and REDUNDANCY.
In practice, we are interested in computing the irredundant form of a graph, and
not only in checking whether it is redundant. Assume that we have an algorithm able
to exhibit a homomorphism from G to H if any. A simple algorithm for computing

2.6 Complexity of Basic Problems
55
the irredundant form of G is as follows: First, delete redundant relation nodes in
G; secondly, check if there is a homomorphism from G to one of its subgraphs
G−{x}; if no, G is its own irredundant form; if yes, let π be a homomorphism from
G to G−{x}: The irredundant form of G is the irredundant form of π(G).
Theorem 2.5. BG-HOMOMORPHISM is NP-complete.
Proof. BG-HOMOMORPHISM is obviously in NP. To prove the completeness we
build a reduction from the well-known 3-SAT problem. The input of 3-SAT is a
propositional formula f in 3-conjunctive normal form (3-CNF), i.e., a conjunction
of disjunctions (or clauses), each with three literals, and the question is whether
there is a truth assignment of the variables in f such that f is true.
1
2
3
1
2
3
...
1
2
3
1
2
3
G
H
val
val
a
val
val
val
val
val
val
b
c
d
at
af
bt
bf
ct
cf
dt
df
C1
C1
C1
C1
C1
C1
C1
C2
C2
C2
C2
C2
C2
C2
a
b
c
d
av
val
val
val
val
C1
C2
dv
cv
bv
Fig. 2.25 Example of transformation from 3-SAT to BG-HOMOMORPHISM
Let f =C1 ∧...∧Ck be an instance of 3-SAT. Without loss of generality, then we
suppose that a variable appears at most once in a clause. Let us create four concept
types for each variable x: x, xf, xt and xv. We also create one relation type Ci for
each clause Ci, and a relation type val. Each concept type xv is greater than xt
and xf, these are the only possible comparisons between distinct types.
We build the graph H(f) as follows: For every variable x in f, we have three
concept nodes [x], [xt] and [xf] in H(f) and two relation nodes typed val
linking the ﬁrst to the latter ones (intuitively, this means that the variable x can be
valuated by true or false). Let us say that the truth value true (resp. false)
is associated with [xt] (resp. [xf]). Then for every clause Ci = (lx ∨ly ∨lz) in
f (where lx, ly and lz are literals over variables x, y and z), we add the 7 relation
nodes typed Ci, having as ﬁrst argument [xt] or [xf], as second argument [yt]
or [yf], and as third argument [zt] or [zf], that correspond to an evaluation
of the clause to true (more precisely, if we replace, in the clause Ci, each positive
(resp. negative) literal l j, 1 ≤j ≤3, by the truth value (resp. the negation of the truth
value) associated with the jth neighbor of the relation node, Ci is evaluated to true).
In graph G(f), two concept nodes [x] and [xv] are created for each variable x
and they are linked by a binary relation (val). For each clause Ci = (lx ∨ly ∨lz),
there is one relation (Ci) linked to [xv], [yv] and [zv]. This question means
“Is there a valuation of variables such that all clauses evaluate to true?”
This transformation from the 3-SAT formula (a ∨b ∨¬c) ∧(¬a ∨c ∨¬d) is il-
lustrated in Fig. 2.25. In graph H, not all edges issued from the clauses have been

56
2 Basic Conceptual Graphs
drawn, for readability reasons. It is immediate to check that, for a formula f, there
is a valuation of its variables such that each clause is evaluated to true if and only if
G(f) can be mapped into H(f).
⊓⊔
Chapter 5 provides other polynomial reductions to BG-HOMOMORPHISM, in par-
ticular from GRAPH-HOMOMORPHISM, CONJUNCTIVE-QUERY-CONTAINMENT,
CONJUNCTIVE-QUERY-EVALUATION and CSP (Constraint Satisfaction Problem).
Deciding whether two BGs G and H are hom-equivalent or checking whether a
graph is redundant could be problems that are simpler than BG-HOMOMORPHISM,
but they are not:
Theorem 2.6. HOM-EQUIVALENCE and REDUNDANCY are NP-complete.
Proof. Let (G,H) be an instance of BG-HOMOMORPHISM. It is easily checked that
there is a homomorphism from G to H if and only if H is hom-equivalent to G+H
(the disjoint sum of G and H), hence we have an immediate reduction from BG-
HOMOMORPHISM to HOM-EQUIVALENCE. Let us now build a reduction from BG-
HOMOMORPHISM to REDUNDANCY. Without loss of generality we assume that G
and H have no redundant relation nodes. We build G′ and H′ from G and H, re-
spectively, by adding some “gadgets” such that (1) G′ and H′ are irredundant, (2)
there is no homomorphism from H′ to G′, and (3) there is a homomorphism from G
to H if and only if there is a homomorphism from G′ to H′. For instance, let r and
s be binary relation types that do not occur in G and H and that are incomparable
to all other relation types. We obtain G′ from G by adding a relation node of type
r between any two distinct concept nodes x and y in G. We obtain H′ from H by
adding a relation node of type r between all concept nodes x and y in H, where x
and y may be the same node, and a relation node of type s between all distinct x and
y in H. Check that G′ and H′ satisfy conditions (1), (2) and (3). Because of (1) and
(2), their disjoint sum G′ +H′ is redundant if and only if there is a homomorphism
from G′ to H′, thus, from (3), if and only if there is a homomorphism from G to H.
⊓⊔
2.7 Bibliographic Notes
In his seminal book [Sow84], Sowa ﬁrst settled a simple model and progressively
added more complex notions. This simple model corresponds to the “basic concep-
tual graphs” studied in this chapter. In [CM92] a ﬁrst study of its properties was
conducted. This basis has evolved over the years. The deﬁnitions and results of this
chapter integrate this evolution, but essentially rely on [Sow84] and [CM92].
The “vocabulary” deﬁned in Sect. 2.1.1 is an evolution of the “support” in
[CM92], itself based on the semantic network in [Sow84]. Originally, the concept
type set was a lattice and relation symbols were not ordered. In addition, a “con-
formity relation” enforced constraints on labels of individual concept nodes. It is
equivalent to the individual typing mapping τ mentioned at the end of Sect. 2.1.1.

2.7 Bibliographic Notes
57
In Sowa’s book, basic conceptual graphs were connected graphs. Specializa-
tion operations, called canonical formation rules, were introduced. It was shown
that a mapping π from G to H, called a projection, could be associated with ev-
ery specialization sequence from G to H. In [CM92] projection was identiﬁed as
a graph homomorphism and its equivalence with a specialization sequence was
stated, by proving the reciprocal property: To every projection a specialization se-
quence can be associated. Generalization operations dual of specialization opera-
tions were also introduced. Equivalence between projection/homomorphism, gen-
eralization and specialization was thus proved (Theorem 2.2 and Theorem 2.3).
Specialization and generalization rules of the present book basically come from the
extension of [CM92] to non-connected graphs in [MC96] (research report [CM95]
for an English version). Other sets of rules have been proposed, we will comment on
them in the bibliographical notes in the Simple Conceptual Graphs chapter, as these
rules consider graphs with equality. The fact that this subsumption is not an order
(contrary to the claim in [Sow84]), but only a preorder had been several times noted
(e.g., [Jac88]). [CM92] introduced irredundancy and proved that each BG equiva-
lence class contains a unique irredundant graph (Theorem 2.1). The additional prop-
erty 2.9 is from [CG95]. In the same paper, an alternative proof of Property 2.3 is
provided. Normal graphs were independently introduced in [MC96] and [GW95].
The NP-completeness of BG-HOMOMORPHISM, HOM-EQUIVALENCE and REDUN-
DANCY was proven in [CM92] (with different proofs).

Chapter 1
Introduction
In Sect. 1.1, we place the book in the “Knowledge Representation and Reasoning”
(KR) Artiﬁcial Intelligence (AI) domain. We ﬁrst brieﬂy outline key concepts of the
KR domain, and then review KR formalism properties that we consider to be essen-
tial. The second section is devoted to an intuitive presentation of Conceptual Graphs
that were initially introduced by Sowa in 1976 [Sow76] and developed in [Sow84].
In the third section, we introduce the graph-based KR formalism that is detailed in
the book. This KR formalism is based on a graph theoretical vision of conceptual
graphs and complies with the main principles delineated in the ﬁrst section.
1.1 Knowledge Representation and Reasoning
Knowledge Representation and Reasoning has long been recognized as a central
issue in Artiﬁcial Intelligence. Very generally speaking, the problem is to sym-
bolically encode human knowledge and reasoning in such a way that this encoded
knowledge can be processed by a computer via encoded reasoning to obtain intelli-
gent behavior. Human knowledge is taken here in a very broad sense. It can be the
knowledge of a single person, of an expert in some domain, shared knowledge of
ordinary people (common sense knowledge), social knowledge accumulated by gen-
erations, e.g., in a scientiﬁc domain, etc. Thus, we will not distinguish the modeling
view of KR, which involves studies on how to computationally represent knowledge
about the world, or the cognitivist view of KR, which assesses how to computation-
ally represent cognitive capacities of a human being.
Moreover, we shall carefully avoid specifying the exact meanings of the notions
of “human knowledge,” “reasoning,” “intelligence” or “representation.” All of these
issues have been discussed by philosophers since the Greek ancient times (at least in
the western world), and a discussion of such topics would be far beyond the scope
of this book.
1

2
1 Introduction
1.1.1 Knowledge-Based Systems
KR is the scientiﬁc domain concerned with the study of computational models able
to explicitly represent knowledge by symbols and to process these symbols in order
to produce new ones representing other pieces of knowledge. Systems built upon
such computational models are called knowledge-based systems. Their main com-
ponents are a knowledge base and a reasoning engine.
Example (a photo of children). Assume we want to represent common sense
knowledge about a photo depicting children playing in a room containing toys and
furniture. The formalism studied in the book can be used to represent elements in
this photo (e.g., there is a girl and a boy, a car is on the table), and knowledge about
elements in the photo (e.g., Mary is the name of the girl, Mary is a sister of the boy).
It is also used to represent general background knowledge (e.g., a building block is
a toy, if a person A is a sister of a person B then A and B are relatives).
Knowledge representation and reasoning formalism can also express problems to
be solved concerning the facts and general knowledge represented. For instance, one
may ask with what kind of toy Mary’s brother is playing. Answering such questions
requires descriptive knowledge but also reasoning capabilities (e.g., modus ponens,
which states that if A holds and if B can be deduced from A, then B holds).
Main Components of a Knowledge Base
A knowledge base (KB) gathers symbolic knowledge representation about an appli-
cation domain. We use the expression “application domain” to denote the part of the
world (which can be real or fantasy, a sophisticated model of a system or a model
of an expert competence) about which we represent knowledge and reasoning.
A KB generally contains different kinds of knowledge, typically an ontology,
facts, rules and constraints. From an epistemological viewpoint, an ontology pro-
vides an answer to the question “What kinds of things exist in the application do-
main?” or expressed in a more generic way, “How can we think about the world ?”
A computational ontology provides a symbolic representation of objects, classes of
objects, properties and relationships between objects used to explicitly represent
knowledge about an application domain. It is the cornerstone of a knowledge rep-
resentation since all other pieces of knowledge (e.g., facts, rules or constraints) are
represented by computational structures built with ontology terms.
Besides a KB, a knowledge-based system contains a reasoning engine. The rea-
soning engine processes knowledge in a KB in order to answer some question or to
solve some goal. A reasoning engine is composed of algorithms processing elements
of the KB in order to construct “new” knowledge, i.e., new symbolic constructs that
are only implicit in the KB. We should stress that in a knowledge-based system
we cannot have knowledge representation without having reasoning mechanisms. A
large part of KR research consists of ﬁnding a tradeoff between expressivity or gen-
erality of knowledge representation formalism and the efﬁciency of the reasoning
mechanisms.

1.1 Knowledge Representation and Reasoning
3
Knowledge Incompleteness
An essential point is that a KB is not assumed to provide a complete picture of the
world. The fundamental reasons are that any real thing, e.g., a human face or a peb-
ble, cannot be described by a ﬁnite set of symbolic structures, and also that a thing
does not exist in isolation but is included in unlimited sets of encompassing con-
texts. Thus, incompleteness of descriptions is a central feature of knowledge-based
systems, and is a main distinction with respect to databases: For some sentences, it
cannot be determined whether they are true or false given the knowledge in the base.
For instance, a KB representing the photo of children can be queried by an unlim-
ited number of questions (e.g., “Is the house where the photo was taken located in a
village?” “How old is the boy?” “Who are the children’s parents?” “In what country
were the toys built?” and so on ad libitum). To be answered, these questions would
need an unlimited amount of knowledge.
1.1.2 Requirements for a Knowledge Representation Formalism
In a nutshell, we are interested in KR formalisms that comply, or aim at complying,
with the following requirements:
1. to have a denotational formal semantic,
2. to be logically founded,
3. to allow for a structured representation of knowledge,
4. to have good computational properties,
5. to allow users to have a maximal understanding and control over each step of the
KB building process and use.
The graph-based KR formalism presented in this book has the ﬁrst three prop-
erties, parts of the formalism have the fourth property, and we think that, at least
for some application domains, it has the last one too. We think that presently there
is no universal KR formalism. Indeed, such a formalism should represent natural
languages, and the present systems are far from being able to do that. Thus, every
existing KR formalism, including the one presented here, can be efﬁciently used
only for speciﬁc reasoning on speciﬁc knowledge (e.g., a privileged application do-
main, namely semantic annotation, will be brieﬂy presented). The end of this section
is devoted to a brief discussion on the previous ﬁve requirements.
1.1.2.1 Denotational Semantics: What Rather than How
A KR formalism should allow us to represent knowledge in an explicit and a declar-
ative way: The meaning of the knowledge represented should be deﬁnable inde-
pendently of the programs processing the knowledge base. Namely, it should not
be necessary to precisely understand how reasoning procedures are implemented to

4
1 Introduction
build a knowledge representation, and one should be able to update the knowledge
base content without modifying any program. Ideally, the result of inferences should
depend only on the semantics of the given data and not on their syntax, i.e., seman-
tically equivalent knowledge bases should lead to semantically equivalent results,
regardless of their syntactical forms. Thus, having a denotational semantics is an
essential KR formalism feature.
A set (or model) semantics is appreciable, particularly whenever the KR for-
malism has to be used by informatics non-specialists. Indeed, the basic notions of
(naive) set theory: element and membership, subset and inclusion, application, rela-
tion, etc., are easily understood by many people. In addition, a set semantics should
provide the notions of truth and entailment, so that what holds in the modeled world
can be determined. This leads us to logic, since logic is the study of entailment, or
in other words, reasoning.
1.1.2.2 Logical Foundations
Generally speaking, doing an inference consists of producing a new expression from
existing ones. The correctness of an inference mechanism can be deﬁned relative
to a logic, and in this book we essentially consider logical entailment, or logical
deduction.
What does it mean for a KR formalism to be logically founded? First, the ex-
pressions of the formalism are translatable into formulas of a logic. Such a mapping
gives a logical semantics to the formalism. Secondly, the reasoning engine contains
an inference mechanism, which should have two essential properties with respect to
deduction in the target logic: soundness and completeness. Let K be a knowledge
base expressed in some KR formalism, and let f be a logical semantics of K, i.e., f
is a mapping from K to formulas of some logic. The inference mechanism is sound
with respect to this semantics if for each expression i inferred from K, f(i) is actu-
ally logically deduced from f(K). It is complete if, for each expression i such that
f(i) is logically deduced from f(K), i is actually inferred from K. In other words, a
procedure P (or algorithm, or system of rules, etc.) is sound with respect to a logi-
cal semantics if every inference made by P corresponds to a logical deduction. It is
complete with respect to a logical semantics if every logical deduction in the logical
language target of the formalism can be done by P.
Soundness is usually ensured. But not all reasoning algorithms are complete. If
an incomplete, nevertheless sound, system answers “yes” to the question “can i be
retrieved from K?” then the answer is correct. If it answers “no,” then because of
incompleteness, it should preferably have answered “I don’t know.” If the system
also computes answers to a query then, if it is sound, all the computed answers are
correct answers, and if it is incomplete some answers can be missed.
The incompleteness of an algorithm can be motivated by efﬁciency concerns
when a complete reasoning is too time consuming. It can also be due to the unde-
cidability of the deduction problem. For instance, deduction in First Order Logic
(FOL) is undecidable, which means that it is not possible to build an algorithm

1.1 Knowledge Representation and Reasoning
5
deciding in ﬁnite time for any pair of formulas (f,g) whether f can be deduced
from g. More precisely, FOL deduction is only semi-decidable: One can build an
algorithm guaranteed to stop in ﬁnite time if the answer is “yes,” but which may
run indeﬁnitely if the answer is “no.” Thus, algorithms that stop in ﬁnite time in all
cases are necessarily incomplete.
Different logics have been developed for KR purposes. FOL has been adopted
as a reference formalism for knowledge representation in the AI community. Its
model semantics is described with simple mathematical objects (sets and relations).
However, its computational complexity has led to study of fragments of it with good
computational properties.
KR formalisms can be compared according to different criteria, such as expres-
siveness, ease of use, computational efﬁciency, etc. Logical semantics facilitate ex-
pressiveness comparisons between KR formalisms and can avoid doing something
that is already known. Indeed, KR deals with knowledge and reasoning, and logic
(not only classical logic) is precisely the study of reasoning. The large corpus of re-
sults and techniques accumulated by logicians for more than two millennia cannot
be ignored.
From a modeling standpoint, other important properties of a KR formalism are its
empirical soundness and its empirical completeness with respect to an application
domain. A formalism is empirically sound if any “true” expression in the formalism
corresponds to a “true” fact of the application domain. It is empirically complete
if any true fact of the application domain can be coded in a true expression of the
KR formalism. Naturally, when there is no mathematical model of the application
domain, these notions are informal, rather subjective and difﬁcult to evaluate. Hav-
ing different mathematical semantics of the KR formalism (e.g., a set semantics and
a logical semantics) can help, since each semantics can be used to study, with dif-
ferent notions, the correspondence between the KR formalism and the application
domain.
1.1.2.3 Knowledge Structuring
A KR formalism should provide a way of structuring knowledge. Knowledge struc-
turing can be motivated by model adequacy (i.e., its “conformity” to the modeling
of the application domain) and by efﬁciency concerns (algorithmic efﬁciency of
reasoning procedures, facility for managing the knowledge base).
One aspect of knowledge structuring is that semantically related pieces of infor-
mation (e.g., information relative to a speciﬁc entity) should be gathered together.
This idea was underlying the ﬁrst KR formalisms, frames and semantic networks,
that were far from logics. Frames have been introduced in [Min75] as record-like
data structures for representing prototypical situations and objects. The key idea
was to group together information relevant to the same situation/object. Semantic
networks were originally developed as cognitive models and for processing the se-
mantics of natural language (cf. [Leh92] for a synthesis on semantic networks in
AI). A semantic network is a diagram that represents connections (relationships)

6
1 Introduction
between objects (entities) or concepts (classes) in some speciﬁc knowledge domain.
Basic links are the ISA link that relates an object and a concept of which it is an
instance, the AKO (A-Kind-Of) link, that relates two concepts (with one being a
kind of the other), and the property link that assigns a property to an object or con-
cept. Inferences are done by following paths in the network. For instance, properties
of an object are inherited following the ISA and AKO links. The main criticism
concerning semantic networks was their lack of a formal semantics: What’s in a
link? [Woo75] What’s in a concept? [Bra77]. The same network could be interpreted
in different ways depending on the user’s intuitive understanding of its diagrammat-
ical representation.
Description logics (DLs), formerly called terminological logics or concept lan-
guages, are rooted in semantic networks, particularly in the KL-ONE system [BS85],
and have been a successful attempt to combine well-deﬁned logical semantics with
efﬁcient reasoning [BCM+03]. This is one of the most prominent KR formalism
families. Let us point out, however, that DLs have lost the graphical aspects of their
ancestors. Conceptual graphs represent another family of formalisms issued from
semantic networks (at least partially, because they are also rooted in other domains),
which we shall consider in more detail in the next section.
Another aspect of knowledge structuring is that different kinds of knowledge
should be represented by different KR formalism constructs. Ontology, facts, rules,
constraints, etc., are distinct sorts of knowledge that are worth being differently
represented. An important distinction is between ontological and factual knowl-
edge. Ontological knowledge is related to general categories, also called concepts
or classes. Factual knowledge makes assertions about a speciﬁc situation (e.g., “this
speciﬁc entity belongs to a certain category, and has a certain relationship with an-
other entity, ...”). This distinction is essential in description logics and conceptual
graphs.
Another kind of knowledge is implicit knowledge described, for instance, by rules
of form “if this then that” (e.g., “if there is a relation r from x to y, then the same
relation r also holds from y to x”). Different kinds of rules can be considered. Some
rules can be included in an ontology (e.g., the transitivity of a binary relation), other
rules, for instance representing possible transformations, are not ontological knowl-
edge. Constraints, i.e., conditions that are to be fulﬁlled by some pieces of knowl-
edge in order to be correctly processed by a reasoning engine, frequently appear in
modeling and should be differentiated from other kinds of knowledge.
1.1.2.4 Good Computational Properties
We are interested in KR formalisms that can be used for building systems able to
solve real problems and not only toy problems. It is thus essential to anchor these
formalisms in a computational domain having a rich set of efﬁcient algorithms. This
is a key point. AI aims at building systems (or agents) for solving complex tasks
and, from a complexity theory viewpoint, one can say that simple AI problems are
computationally difﬁcult to solve—they are often NP-complete or NP-hard. Thus, if

1.1 Knowledge Representation and Reasoning
7
on one hand a KR formalism must ﬁrmly moor to logics in order to avoid reinventing
the wheel, on the other hand it must also moor to a rich algorithmic domain so that
usable systems can be built.
1.1.2.5 Knowledge Programming and the Semantic Gap
A KR system should allow a user to have a maximal understanding and control
over each step of the reasoning process. It should make it easy to enter the different
pieces of knowledge (e.g., ontological knowledge as well as factual knowledge) and
to understand their meaning and the results given by the system, and also (if asked
by the user) how the system computed the results. Any computing system should
have these qualities, i.e., should limit the semantic gap between real problems and
their formulation in a programming language.
The correspondence between knowledge about an application domain and an ex-
pression in the KR formalism representing this knowledge must be as tight as pos-
sible. Due to the importance of natural language and schemas in the description of
knowledge, a KR formalism should allow the user to easily represent simple phrases
in natural language and simple schemas. The ability for describing such a correspon-
dence, i.e., the natural semantics of a formal expression, is a good empirical criteria
for delimiting the usability of the formalism.
As already said, in order to understand the results given by the system, a precise
description of what is obtained (a denotational semantics) is mandatory. However, in
some situations, especially whenever the knowledge deals with a poorly formalized
application domain, it may be useful to understand how the results have been ob-
tained, i.e., to have an operational semantics. This point is important because there
can be a gap between the program and the knowledge represented in the system, i.e.,
a formal system, and the knowledge itself. There should be a tight correspondence
between what is seen by the user and how objects and operations are implemented.
This correspondence should be tight enough to enable faithful modeling of the ac-
tual data and problems, and to understand why and how results have been obtained.
A way to limit the semantic gap is to use a homogeneous model—the same kinds
of object and the same kinds of operation occur at each fundamental level (formal,
user interface, implementation). Such a correspondence is sometimes called an “iso-
morphism,” but this designation can be misleading. Indeed, this correspondence is
not a mathematical function between two mathematical objects but is rather a cor-
respondence between “reality” and a mathematical object. There is a gap between a
reality and the concepts describing it, as well as between a conceptual modeling and
its implementation, i.e., a representation of this modeling by computational objects.
Moreover, as in this book we use “isomorphism” in its usual mathematical sense,
we avoid using it metaphorically.

8
1 Introduction
1.2 Conceptual Graphs
This section provides an intuitive introduction to conceptual graphs. Precise deﬁni-
tions are given in subsequent chapters. The conceptual graph model was introduced
by Sowa in 1976 [Sow76], developed in [Sow84], and then enriched and developed
by the conceptual graph community (cf. the proceedings of the International Con-
ference of Conceptual Structures). It is the synthesis of many works in AI, but its
roots are mainly found in the following areas: natural language processing, seman-
tic networks, databases and logics, especially the existential graphs of Pierce, which
form a diagrammatical system of logics.
We use the term “conceptual graphs” (CGs in short) to denote the family of for-
malisms rooted in Sowa’s seminal work, rather than a precise formalism, and we
use speciﬁc terms—e.g., basic conceptual graphs, simple conceptual graphs, posi-
tive nested conceptual graphs—for notions which are mathematically deﬁned and
studied in this book.
1.2.1 Basic Notions
For an intuitive introduction to CGs, let us consider again the photo of children ex-
ample. We would like to represent some features of this photo and some knowledge
necessary to answer non-trivial questions about the content of the photo.
The basic vocabulary is composed of two partially ordered sets: a partially or-
dered set of concepts or classes (called concept types in the CG community) and
a partially ordered set of relation symbols (also called relation types). The partial
order is interpreted as a specialization or AKO relation: t1 ≤t2 means that t1 is a
specialization of t2 (or t2 is a generalization of t1, t2 subsumes t1, t1 is a subtype
of t2 , or every entity of type t1 is of type t2). There is also a set of names, called
individual markers, used for denoting speciﬁc entities. This basic vocabulary can be
considered as a rudimentary ontology.
A basic conceptual graph (BG) is composed of two kinds of nodes, i.e., concept
nodes representing entities and relation nodes representing relationships between
these entities. Nodes are labeled by types, and one can indicate that a concept node
refers to a speciﬁc entity by adding an individual marker to its label. Otherwise the
concept node refers to an unspeciﬁed entity.
For instance, the conceptual graph K in Fig. 1.1 asserts that:
• there are entities (represented by rectangles): Mary who is a Girl, a Boy, who is
unspeciﬁed, and a Car, which is also unspeciﬁed.
• there are relations (represented by ovals) between the entities: a relation asserting
that Mary is the sister of the Boy, and two relations asserting that Mary and
the Boy play with the Car. The numbers on edges are used to totally order the
neighbors of each relation node. There is also a unary relation asserting that Mary
is smiling.

1.2 Conceptual Graphs
9
K
playWith
playWith
Car
1
2
sisterOf
Boy
1
1
2
2
smile
Girl:Mary
Fig. 1.1 A basic conceptual graph
This BG could be translated by the sentence “Mary (who is a girl) and her brother
are playing with a car; Mary is smiling.”
Important differences between the conceptual graph model and its semantic net-
works ancestors are to be pointed out: Firstly, there is a clear distinction between
ontological knowledge (e.g., concept or relation types) and other kinds of knowl-
edge (such as factual or implicit knowledge); secondly, relations can be of any arity,
whereas the edges of semantic networks represent binary relations only; thirdly,
CGs have a logical semantics in FOL.
1.2.2 Subsumption and Homomorphism
The fundamental notion for studying and using BGs is homomorphism. In the CG
community, a BG homomorphism is traditionally called a projection. We prefer
the term “homomorphism” for two reasons. First, it corresponds to the classical
homomorphism notion in mathematics, and we will see that a BG homomorphism is
a mapping between BGs preserving the BG structure. Secondly, there is an operation
called “projection” in the relational database model, which is quite different from a
BG homomorphism.
A homomorphism from a BG G to a BG H is a mapping from the nodes of G to
the nodes of H, which preserves the relationships between entities of G, and may
specialize the labels of entities and relationships. In graph-theoretic terms, it is a
labeled graph homomorphism that we will precisely describe later. For the moment,
it is only necessary to know that a generalization/specialization relation (or sub-
sumption) over BGs can be deﬁned with this notion: G is more general than H (or
G subsumes H, or H is more speciﬁc than G) if there is a homomorphism from G to
H.
Let us consider the graphs G and K in Fig. 1.2. The following mapping from the
node set of G to the node set of K (pictured in dashed lines) deﬁnes a homomorphism
from G to K:
the concept node [Girl] is mapped to the concept node [Girl: Mary] (the uniden-
tiﬁed girl is specialized into the girl Mary),

10
1 Introduction
the concept node [Child] is mapped to the concept node [Boy], with Boy being a
subtype of Child (the child is specialized into a boy),
the concept node [Toy] is mapped to the concept node [Car], with Car being a
subtype of Toy,
the relation node labeled (relativeOf) is mapped to the relation node (sisterOf)
(the relation “to be a relative of someone” is specialized into the relation “to be a
sister of someone”),
each relation node (actWith) is mapped to a relation node (playWith): The node
(actWith) with a ﬁrst neighbor [Girl] is mapped to the node (playWith) with a
ﬁrst neighbor [Girl:Mary], while the node (actWith) with a ﬁrst neighbor [Child]
is mapped to the node (playWith) with a ﬁrst neighbor [Boy].
G is a generalization of K (or K is a specialization of G) since each node of G is
mapped to a specialized (or identical) node of K, and because the relationships be-
tween concept nodes in G are specialized by (or identical to) relationships between
the image nodes in K.
This homomorphism maps G to a subgraph of K with the same structure as G.
This property is generally not fulﬁlled by a homomorphism, as illustrated by the
graphs H and K in Fig. 1.3: there is a homomorphism from H to K, which maps
both concept nodes [Car] in H to the same node [Car] in K. Graph H states that
“Mary is playing with a car and a boy is playing with a car” and K specializes it by
adding that they play with the same car. Moreover, K contains other relations, which
are not involved in the homomorphism from H to K.
K
G
Car
2
1
2
1
1
2
Girl
Child
relativeOf
actWith
actWith
Toy
1
Girl:Mary
2
sisterOf
Boy
1
1
2
2
smile
playWith
playWith
Fig. 1.2 G is a generalization of K
The fundamental problem for BGs is as follows: Given two BGs G and H, is
G a generalization of H? i.e., is there a homomorphism from G to H? We call
it BG-HOMOMORPHISM. We will see that this problem is NP-complete and pos-
sesses interesting polynomial cases. Furthermore, we will see that it is equivalent to
other fundamental problems in AI and databases, such as the constraint satisfaction
problem, which has been very well studied from an algorithmic viewpoint, or the
conjunctive query inclusion problem in database theory.

1.2 Conceptual Graphs
11
H
K
1
Girl:Mary
playWith
2
1
2
Boy
playWith
1
Girl:Mary
2
sisterOf
Boy
1
1
2
2
smile
playWith
playWith
Car
Car
Car
Fig. 1.3 H is a generalization of K
1.2.3 Formal Semantics
Another essential point is that BGs possess a set semantics and a logical semantics,
with the former corresponding to the model theory of the latter.
Let us brieﬂy outline how we provide BGs with a set semantics. First, one has to
deﬁne a model of a vocabulary. A model of a vocabulary consists of a non-empty
set D (the objects of the application domain), called the domain of the model, and
the deﬁnition δ of the meaning of each element of the vocabulary. δ assigns a part
of D (the set of objects of type t) to any concept type t, δ assigns a k-ary relation
over D (i.e., a part of Dk composed of the tuples of objects which are related by the
relation r) to any relation r of arity k and δ assigns an element of D to any individual
marker. As an example let us consider a situation described by the graphs G and K
in Fig. 1.2.
• The individual marker Mary is translated by an element in the domain D (i.e.,
δ(Mary) is the element in D representing the individual marker Mary).
• The concept types in the vocabulary, Girl, Boy, Car, etc., are translated by subsets
of D (e.g., δ(Girl) is the subset of D representing the concept type Girl).
• The binary relation symbols in the vocabulary, actWith, playWith, sisterOf, rel-
ativeOf, etc., are translated by binary relations over D (e.g., δ(sisterOf) is the
binary relation over D representing the binary relation symbol sisterOf), and the
unary relation symbol smile is represented by a subset δ(smile) of D.
Secondly, we deﬁne BG models and the meaning of a BG that is satisﬁed by a
model (e.g., the type of the individual marker Mary is Girl, thus δ(Mary) must be in
δ(Girl); Mary is smiling, thus (δ(Mary) must be in δ(smile)). Then, an entailment
relation between BGs can be deﬁned and, ﬁnally, its relationships with homomor-
phism is stated: Given two BGs G and H, there is a homomorphism from G to H if
and only if H entails G.
Let us now outline the logical semantics, classically called Φ. The vocabulary
is logically interpreted as follows. A predicate t is assigned to each type t (a unary
predicate to a concept type and a k-ary predicate to a k-ary relation type) and a
constant m to each individual marker m (for simplicity, here we use the same symbol

12
1 Introduction
for an object in the CG world and for its corresponding object in the FOL language,
e.g., a unary predicate t is assigned to a concept type t).
Given two k-ary types t1 and t2, t1 ≤t2 is interpreted by the formula ∀X (t1(X) →
t2(X)), where X is a tuple of k variables, e.g., ∀x (Girl(x) →Child(x)) or ∀x∀y
(sisterOf(x,y) →relativeOf(x,y)). An existentially closed formula is assigned to
a BG, where terms (variables or constants) correspond to concept nodes.
For instance, the formula assigned to G in Fig. 1.1 is:
Φ(G) = ∃x∃y(Girl(Mary)∧Boy(x)∧Car(y)∧smile(Mary)∧sisterOf(Mary,x)∧
playWith(Mary,y)∧playWith(x,y)).
Homomorphism is sound and complete with respect to logical deduction, i.e.,
given two BGs G and H, there is a homomorphism from G to H if and only if the
formula Φ(G) can be deduced from the formula Φ(H) and the logical translation of
the type hierarchies. The BG-HOMOMORPHISM problem can thus be identiﬁed with
a deduction problem. We will show later that basic conceptual graphs strongly cor-
respond to the existential, positive, conjunctive fragment of FOL (which we denote
by FOL(∃, ∧)) 1.
Basic conceptual graphs constitute the kernel of CGs. They can be used as such to
represent facts and queries. They are also basic bricks for more complex constructs,
such as nested graphs or rules, corresponding to more expressive CGs.
1.2.4 Full CGs
The most expressive conceptual graphs we shall consider, and call full conceptual
graphs, were introduced by Sowa in [Sow84] and are inspired from Peirce’s exis-
tential graphs (cf. [Dau02] for a mathematical study of full CGs and [Rob92] for
a presentation of Peirce’s existential graphs). The basic idea of the extension from
BGs to full CGs is that every FOL formula can be written as a formula by solely
using the existential quantiﬁer and the conjunction and negation logical connectors.
By adding to BGs boxes representing negation and lines (called co-reference links)
indicating that two nodes represent the same entity, one obtains the same expressive-
ness as FOL. For instance, the graph of Fig. 1.4 shows that the relation r is transitive
on entities of type t, i.e., for all x, y, z of type t, if r(x, y) and r(y, z) then r(x, z). Its
logical translation is more precisely:
Φ(G) = ¬(∃x ∃y ∃z(t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z)∧¬(r(x,z)))),
which is equivalent to: ∀x∀y∀z((t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z)) →r(x,z))
Peirce’s existential graphs are provided with a sound and complete set of infer-
ence rules that can be adapted to CGs [Sow84] [Wer95a] [Dau02]. However, these
rules do not directly lead to automated reasoning because they heavily rely on hu-
man intuition2.
1 We will see that the universally quantiﬁed formulas associated with the vocabulary can be
dropped without restraining logical expressivity.
2 For instance, the insertion rule allows one to insert any graph (at a place obeying speciﬁc condi-
tions), which leads to an inﬁnite number of choices.

1.3 A Graph-Based Approach to KR
13
G
t
t
t
r
r
t
t
r
For binary relation nodes, directions on edges may replace numbers 1 and 2.
Fig. 1.4 A full CG
In this book, we will only brieﬂy present full CGs, which are unsuitable for our
approach, as will become clear in the next section. Instead, we will build limited
extensions of BGs (e.g., with atomic negation), in an attempt to keep the essential
properties of BGs.
1.3 A Graph-Based Approach to KR
Since 1991 (cf. [CM92]) our aim has been to develop and study a KR formalism
respecting, as far as possible, the ﬁve requirements presented in Sect. 1.1. Our work
belongs to a logical approach to KR (and to the KR scientiﬁc community main-
stream as presented, for instance, by Brachman and Levesque in [BL04] or Baader
in [Baa99]), but it is also graph-based as explained hereafter. The formalism is
based on graphs and graph-theoretic notions and operations. It is logically founded,
but in some way is “autonomous” from (existing) logics. Stated differently, our KR
formalism is a pure graph-theoretic formalism, whose core corresponds to a FOL
fragment, and most extensions of this core correspond to FOL fragments. Since it is
embedded in graph theory, it is easy to deﬁne new operations, simple from a graph
viewpoint, and having simple intuitive semantics, but that do not necessarily have a
formal semantics expressed in a classical logic.
1.3.1 Motivations
Let us ﬁrst outline our motivations for a graph-based approach to KR. They can
be divided into two categories: qualities of graphs for knowledge modeling and
qualities of graphs for computations.

14
1 Introduction
From a modeling viewpoint, we see two essential properties in the basic concep-
tual graph model. The objects, i.e., basic graphs, are easily understandable by users
(typically knowledge engineers or specialists in an application domain), at least if
the graphs are reasonably small (note that it is always possible to split up a large
conceptual graph into smaller ones while keeping its semantics). This feature par-
tially explains the success of semantic networks and, more generally, the success
of graphical models, such as the entity/relationships model, UML, Topic Maps, etc.
Many people, and not only computer scientists, are now familiar with kinds of la-
beled graphs (mainly trees, but not exclusively). This fact is especially important in
knowledge acquisition. In our approach to CGs, this quality does not only concern
the descriptive facet of the formalism. Reasoning mechanisms are also easily un-
derstandable, for two reasons. First, homomorphism is a “global” graph-matching
notion that can be easily visualized (we will also see that homomorphism is equiva-
lent to a sequence of elementary graph operations which are very simple and easy to
visualize). Secondly, the same language is used at interface and computing levels.
In particular, no transformation has to be done on the components of the knowledge
base before reasoning with it.
Thus, reasoning can be explained on the user’s representation itself, and expla-
nations can be given at any level from the user’s level to the implementation level.
At the implementation level, a graph can be represented by a structure with point-
ers, which is a graph too! To sum up, using a graph-based KR should reduce the
semantic gap mentioned in Sect. 1.1.2.
From a computational viewpoint, labeled graph homomorphism ﬁrmly moors
BGs to combinatorics. The graph homomorphism notion (or its variant, relational
structure homomorphism) was recognized in the 90s as a central notion, unifying
complexity results and algorithms obtained in several domains (e.g., cf. [Jea98] and
[FV93]). On the other hand, considering graphs instead of logical formulas provides
another view of knowledge constructs (e.g., some notions like path, cycle, or con-
nected components are natural on graphs) and provides other algorithmic ideas, as
we hope is illustrated throughout this book.
1.3.2 Extensions of the Basic Formalism
Full CGs `a la Peirce are no longer graphs (in the graph theory sense); they are
diagrams. Associated inference rules are not graph-based operations either. In our
opinion, qualities of the BG model from a knowledge representation and reasoning
perspective (as presented above) are at least partially lost: namely, the readability of
objects as well as the easy understanding of the inference mechanism, and relation-
ships with combinatorial problems.
Rather than jumping from BGs to full CGs, we prefer, depending on the kind of
knowledge we would like to represent, to build extensions of the BG model, while
keeping its essential properties. These properties represent our motto and can be
summarized as follows:

1.3 A Graph-Based Approach to KR
15
1. objects are labeled graphs (mathematically deﬁned with graph-theoretic no-
tions),
2. reasoning mechanisms are based on graph-theoretic operations, mainly relying
on graph homomorphism,
3. efﬁcient reasoning algorithms exist for important speciﬁc cases,
4. objects and operations have graphical representations, which make them easily
understandable by users (limitation of the semantic gap),
5. the BG model is logically founded, with the inference mechanism being sound
and complete with respect to FOL semantics.
Let us brieﬂy give an example of extension: BG rules. A rule represents informa-
tion of the type: “if information H is found, then information C can be added.” H is
called the hypothesis of the rule and C its conclusion. This notion of a rule has been
widely used in AI to represent implicit knowledge, which can be made explicit by
applying the rules, on facts for instance.
Rules could be represented as full CGs, but in so doing they would lose their
speciﬁcity and could not be processed in a particular manner. A BG rule can be
deﬁned as a bicolored BG (a more general rule deﬁnition will be given). One color
(white in the ﬁgures) deﬁnes the hypothesis, and the other color deﬁnes the conclu-
sion (gray in the ﬁgures). For instance, the rule in Fig. 1.5 has the same semantics
as the full CG in Fig. 1.4, i.e., it says that the relation r is transitive on type t enti-
ties. A more complex rule is pictured in Fig. 1.6. This rule allows us to decompose
the ternary relation give into simpler relations: If there is a relation give with ﬁrst
argument a Human x, with second argument a Thing y and with third argument an
Animate entity z, then there is a Gi ft act, whose x is the agent, y is the object and z
is the recipient.
The notion of a rule application is very simple. A rule R is said to be applicable
to a BG G if its hypothesis H can be mapped by a homomorphism to G. Then it
can be applied to G: Applying R consists of adding the conclusion of R to G guided
by the homomorphism from H to G. Rules are provided with a logical semantics
extending that of BGs, such that graph mechanisms, namely forward chaining and
backward chaining, are sound and complete. Let us consider a KB K composed
of a set F of BGs representing facts and a set R of rules. A BG is derived from
K if it can be obtained by a sequence of rule applications to the facts. The basic
problem considered is thus as follows: Given a KB K = (F,R) and a BG Q, is a
specialization of Q derivable from K? Due to the soundness and completeness of
the graph mechanisms deﬁned, it can be seen as a deduction problem, called FR-
DEDUCTION. By enriching BGs with rules, we obtain a computability model. This
is an important property but, similar to the fact that no computability model can
be the basis for building a universally good programming language, this does not
mean that this KR formalism is suitable for all KR domains. Moreover, this high
expressivity comes with undecidability of reasoning. That is why properties on rule
sets ensuring decidability of reasoning are studied. A simple example is that of rules
that do not add unspeciﬁed concept nodes (such as the rule in Fig. 1.5, contrary to
the rule in Fig. 1.6 which adds an unspeciﬁed Gift). In this case, FR-DEDUCTION

16
1 Introduction
is NP-complete, thus not more difﬁcult than deduction checking in the BG model,
i.e., BG-HOMOMORPHISM.
r
r
t
t
t
r
Fig. 1.5 A simple rule
agent
object
recept
Gift
Human
give
Animate
Thing
1
2
3
1
2
1
2
1
2
Fig. 1.6 Another rule
Other extensions presented in the book are type conjunctions, nested graphs,
atomic negation, and constraints, as well as a family of models combining rules and
constraints, called the BG-Family.
1.3.3 Several Approaches to CGs
Let us end this section by situating our approach in the CG landscape. Research on
CGs can be roughly classiﬁed according to three axes: CGs can be seen as a dia-
grammatic interface for other formalisms or as a diagrammatic calculus of logics,
or as a graph-based KR formalism.
Many works are mainly focused on the visual qualities of conceptual graphs.
The expressivity and readability of the obtained representations are therefore the
main criteria for evaluating a formalism. We shall not forget that a main motivation
behind conceptual graphs was the processing of natural language semantics: From
this standpoint, the relative easiness in translating a (small) conceptual graph into
a natural language sentence it represents is an important criterion. When reasoning
mechanisms are associated with representations, they are not part of the CG for-
malism: They are performed in a procedural way, or rely on another formalism into
which the CGs are translated. In this approach, conceptual graphs are seen as a dia-
grammatical interface for other formalisms (e.g., the Common Logic Standard and

1.3 A Graph-Based Approach to KR
17
CLIF [CLS07]). They are not a knowledge representation and reasoning formalism
per se, i.e., in the sense of Sect. 1.1.
Other works can be seen as the continuation of Peirce’s work on a diagrammatical
system of logics. Conceptual graphs are then diagrams, and reasoning is based on
diagrammatic operations. In these works, automated reasoning is not the point and
the computational aspect of the formalism is absent.
Finally, the graph-based approach emphasizes the following points (cf. our motto
in Sect. 1.3.2), which distinguishes it from the other two approaches:
• CGs are seen as a KR and reasoning formalism. Thus, they are provided with
their own operations for reasoning.
• Reasoning mechanisms should be sound and complete with respect to a formal
semantics.
• Reasoning operations should be conducted in an efﬁcient way. That is why de-
cidability and complexity studies, as well as the design of efﬁcient algorithms
are important issues.
• Reasoning mechanisms are based on graph-theoretic notions, mainly labeled
graph homomorphism, as the structure underlying objects is a graph.
We became highly interested in CGs when we proved (cf. [Mug92] and [CM92])
that homomorphism on the BG fragment is complete with respect to the FOL seman-
tics. As Sowa in [Sow84] had proven that homomorphism is sound (with respect to
this FOL semantics), the completeness theorem established the graph homomor-
phism notion as a key reasoning tool. It is agreed that graph homomorphism is a
fundamental notion in graph theory and the results we have obtained, as well as
results in other ﬁelds (e.g., cf. [Jea98] and [FV93]), strengthened our belief that
labeled graph homomorphism is a key notion in KR.

Chapter 3
Simple Conceptual Graphs
Overview
Concept nodes representing the same entity are said to be coreferent nodes. In basic
conceptual graphs (BGs) only individual concept nodes may be coreferent. Simple
Conceptual Graphs (SGs) enrich BGs with unrestricted coreference. The introduc-
tion of this chapter develops the discussion concerning equality started in the previ-
ous chapter and presents the conjunctive type and coreference notions. A new deﬁ-
nition of a vocabulary extending the previous one with conjunctive types is given in
Sect. 3.2. Section 3.3 deﬁnes SGs. An SG is simply a BG plus a coreference relation.
The coreference relation is an equivalence relation over the concept node set with
the following meaning: All concept nodes in a given equivalence class represent the
same entity.
SG homomorphisms naturally extend BG homomorphisms. In Sect. 3.4, gener-
alization and specialization operations deﬁned on BGs are extended to SGs. Nor-
mal SGs are introduced in Sect. 3.5. An SG is normal if its coreference relation
is the identity relation, i.e., each node is solely coreferent with itself. A normal
SG can be associated with any SG. In fact, normal SGs and normal BGs can
be identiﬁed, which emphasizes the importance of normal BGs. The notion of
coref-homomorphism, which is speciﬁc to SGs, is introduced in Sect. 3.6. Instead
of mapping concept nodes onto concept nodes as for a homomorphism, a coref-
homomorphism maps coreference classes onto coreference classes. Relationships
between homomorphisms and coref-homomorphisms are studied, and it is shown
that, in the presence of a coreference, the intuitive meaning of generalization or
specialization operations is better captured by coref-homomorphism than by homo-
morphism. The normal form of an SG is in a sense the most compact form of an
SG. The antinormal form studied in the last section can be considered as the most
scattered form of an SG: Each relation node is separated from any other relation
node, and there are no multiple edges.
59

60
3 Simple Conceptual Graphs
3.1 Introduction
The essential difference between basic conceptual graphs (BGs) and simple concep-
tual graphs (SGs) is that in SGs several concept nodes not necessarily individual can
represent the same entity. Nodes representing the same entity are said to be coref-
erent, i.e., they refer to the same entity. Then the ﬁrst question is: Can any pair of
concepts be coreferent?
This question is closely related to the structure and the interpretation of the con-
cept type set. Besides the structure of the ordered concept type set (e.g., a semi-
lattice or lattice), an essential point is how the type hierarchy is interpreted. When
a type is interpreted as a set of entities, the order over the hierarchy is interpreted
as the inclusion. Then, the greatest lower bound (glb) of two types, when it exists,
can be lattice-theoretically or order-theoretically interpreted. In the order-theoretic
interpretation there is nothing more than the interpretation of the subtype relation by
set inclusion. In the lattice interpretation, the interpretation of the glb of two types is
then interpreted as the intersection of these sets. E.g., let Building and OldThing be
two incomparable types, and let HistoricLandmark be their glb (see Fig. 3.1 left).
With both interpretations, every entity of type HistoricLandmark is also of types
Building and OldThing. With the lattice interpretation, every entity of both types
Building and OldThing is necessarily of type HistoricLandmark. With the order-
theoretic interpretation, the glb of two types is simply a subtype, thus a subset of
their intersection; an entity of both types Building and OldThing is not necessarily
a HistoricLandmark (cf. Fig. 3.1 right).
HistoricLandmark
OldThing
Building
HistoricLandmark
Building and OldThing
Building
OldThing
Fig. 3.1 Interpretation of types
The way the concept type set is interpreted has an effect on reasoning.
For instance, let Q be the query [HistoricLandmark:*] (“is there a historic land-
mark?”) and let G be a fact containing the coreferent concept nodes [Building:a]
and [OldThing:a], thus indicating that a is an entity which is a Building and an
OldThing. With the lattice interpretation, G should provide an answer to Q while in
the order-theoretic interpretation it should not.

3.1 Introduction
61
The lattice-theoretic interpretation explicitly requires building all types of inter-
sections (for instance, if an entity of types Building and OldThing is not necessarily
of type HistoricLandmark one has to build their common subtype Buildingand-
OldThing, which is a supertype of HistoricLandmark, see Fig. 3.1 right). Thus it
leads to a number of new and artiﬁcial types which can be exponential in the number
of useful types.
On the other hand, the drawback of the order-theoretic interpretation is that we
lose the possibility of expressing conjunctions of types, e.g., that HistoricLandmark
is exactly the intersection of OldThing and Building. This property could be ex-
pressed by a rule (cf. Chap. 10), stating that every entity of type Building and of
type OldThing is also of type HistoricLandmark. However, coding the conjunction
of types in the hierarchy itself is more efﬁcient than using rules, exactly as coding
the subtype relation in a type hierarchy is more efﬁcient than considering a ﬂat set
of types and representing the hierarchy by rules.
Conjunctive Type
A concept node represents an entity, but an entity can be represented by several
coreferent concept nodes. A way of gathering all or some concept nodes represent-
ing the same entity is desirable to ease the building and understanding of an SG by
a human being.
A simple way to gather these nodes is to merge them into one node. This opera-
tion has to keep the meaning of the original SG. Thus if an entity is represented by
a node of type t and by a node of type t′ there must be a type representing exactly
the entities which are of both types t and t′. More generally, we need to express that
a type is the conjunction of several types. Any subset of (incomparable) primitive
types deﬁnes a conjunctive type. The set of conjunctive types is partially ordered by
an order extending the order deﬁned on primitive types.
However, not all conjunctions of types have a meaning. Thus we need a way of
expressing that the conjunction of two (or more) types is banned, or equivalently that
they cannot have a common subtype. A classical way of doing this is to add a special
Absurd type below disjoint types. But this technique is not always precise enough.
For instance, t1,t2,t3 being direct supertypes of Absurd means that the intersection
of any two of them is empty. We cannot express that t1 and t2 are disjoint as well as
t1 and t3, but that there can be an entity of type t2 and t3 (e.g. t1 = Animal, t2 = Ship,
t3 = Robot, with all being subtypes of MobileEntity).
Giving all acceptable (i.e., non-banned) types in extension is not conceivable
in practice, so we deﬁne the set of acceptable conjunctive types by the primitive
type set and the (maximal) banned conjunctive types. In the previous example, the
types {t1,t2} and {t1,t3} would be banned. Theoretically, the number of banned con-
junctive types can be exponential in the number of primitive types but, practically,
considering banned types of cardinality two seems sufﬁcient and their number is at
most quadratic in the number of primitive types.

62
3 Simple Conceptual Graphs
Coreference
An individual marker is generally considered as a surrogate or an identiﬁer (in the
programming meaning) of an entity. According to the Unique Name Assumption
(UNA) common in knowledge representation, it is thus assumed that two distinct
individual markers represent distinct entities. Hence nodes with distinct individual
markers cannot belong to the same coreference set.
Let us consider two concepts with incomparable types t1 and t2. Can these nodes
be coreferent without any condition on t1 and t2? The answer is positive in many
works. As already said, in our opinion important properties required are, ﬁrst, that
(a) coreferent concepts can always be merged into a single node, secondly, that (b)
the meaning of the obtained graph is the same as that of the original one. With a
lattice-interpretation of concept types these properties are fulﬁlled if the types of
the coreferent nodes have a glb (distinct from the Absurd type), which becomes
the type of the new node. With the order-theoretic assumption, and in the absence
of conjunctive types, the only way to fulﬁll these properties is to require that the
set of types of the coreferent nodes possesses a minimal element in this set itself.
Indeed, let us suppose for instance that there are two coreferent concepts with types
Building and OldThing, respectively. Either these concepts cannot be merged and
(a) is not satisﬁed, or they can and the type of the new node is a subtype of Building
and OldThing and the obtained graph is (in general) strictly more specialized than
the original one. That is why in works where properties (a) and (b) are required, it is
required that coreferent nodes have the same type. In the framework of conjunctive
types proposed here, (a) and (b) are obtained as soon as the conjunction of the
types of the coreferent nodes is not a banned type. Then every SG can be easily
transformed into an equivalent normal SG, which is called its normal form.
Whether a coreference set contains both generic and individual nodes is less im-
portant. Indeed, making a generic node and an individual node coreferent can al-
ways be performed by restricting the marker of the generic concept to the individual
marker of the other node without changing the meaning of the graph.
3.2 Vocabulary
In a conjunctive vocabulary, the set TC of concept types is built with three compo-
nents: a set of primitive concept types, an operation of type conjunction and a set of
banned conjunctive types. A set of primitive concept types has the same structure
as a set of concept types in a vocabulary as deﬁned in Chap. 2, i.e., it is a partially
ordered set with a greatest element.
A conjunctive type is a set of n incomparable primitive types E = {t1,...,tn}. A
conjunctive type is either acceptable or banned. Thus, TC is the set of acceptable con-
junctive types. Let {t1,...,tn} be an acceptable conjunctive type, then every subset
of this set is also an acceptable conjunction. Let {t1,...,tn} be a banned conjunctive

3.2 Vocabulary
63
type, which does not mean that any subset of this conjunction is banned but that
there is no entity with all these types.
Let us assume that incomparability of types in a conjunctive type is not re-
quired. Let {t1,...,tn} be an acceptable conjunctive type with, for instance, ti ≤
t j. Then the conjunction of ti and t j has the same meaning as ti since every
entity of type ti is of type t j, hence t j, the greatest type, is useless. For ex-
ample, let us consider t = {Boy,Person,SmallEntity}, as Boy < Person, t has
the same meaning as t′ = {Boy,SmallEntity}. If the conjunction of {t1,...,tn} is
banned, then t j is useless too, because if there cannot be an entity with types
{t1,...,tn}, there cannot be an entity with types {t1,...,tn} \ {t j} . For example if
t = {RacingCar,Animal,Car} is banned, then as RacingCar < Car, t has the same
meaning has t′ = {RacingCar,Animal} which is banned too.
Thus we restrict conjunctive types to the set of minimal types of a type set,
and if {t1,...,tn} is a set of types, then its associated conjunctive type is denoted
min{t1,...,tn} or t1 ∧...∧tn.
Due to the associativity of the conjunction operator, deﬁned as the minimal op-
erator, a conjunction of conjunctions of primitive types is a conjunction of primitive
types. Therefore, we consider only conjunctions of primitive types.
The set of all acceptable conjunctions of primitive types can be exponentially
bigger than the primitive type set. This is why the set of concept types is not deﬁned
in extension but by means of the primitive type set and a set of assertions stating
which types are banned. Let us deﬁne these notions more formally.
Deﬁnition 3.1 (Primitive concept type set). A primitive concept type set is an or-
dered set (T,≤) with a greatest element denoted by ⊤.
This deﬁnition is the same as the concept type set deﬁnition (cf. Deﬁnition 2.1).
Deﬁnition 3.2 (Conjunctive concept type). A conjunctive concept type is given by
a (non-empty) set of incomparable types {t1,...,tn}. This type is denoted by the set
itself or by t1 ∧...∧tn . Let A be any (non-empty) subset of T, then the conjunctive
type associated with A is deﬁned as the set, min(A), of minimal elements of A (a
minimal element of A is an element t of A such that ∀t′ ∈A,t′ ≮t).
A primitive type t is identiﬁed with the conjunctive type {t}. Conjunctive types
are provided with a natural partial order that extends the order deﬁned between
primitive types: Given two conjunctive types t and s, t is a specialization of s if
every primitive type of s has a specialization (possibly equal to itself) in t.
Deﬁnition 3.3 (Conjunctive concept type set). Let T be a set of primitive concept
types. T ⊓denotes the set of all conjunctive types over T. It is provided with the
following partial order, which extends the partial order on T: Given two types t =
{t1,...,tn} and s = {s1,...,sp}, t ≤s if for every s j ∈s, 1 ≤j ≤p, there is a ti ∈t,
1 ≤i ≤n, such that ti ≤s j.
Example. Let t=BuidingBlock∧Cube∧Small and s=Toy∧Cube. BuidingBlock ≤
Toy and Cube ≤Cube then t ≤s.

64
3 Simple Conceptual Graphs
Property 3.1. (T ⊓, ≤) is a lattice.
The previous property relies on basic results in order theory. In order theory, a
subset of incomparable elements is called an antichain, and it is well-known that
the set of antichains provided with the previous partial order is a lattice: Each pair
of antichains has a greatest lower bound that is the set of minimal elements of the
union of the antichains, and a least upper bound which is the set of minimal elements
of the intersection of the ﬁlters generated by the two antichains. Furthermore, the
inf-irreducible elements of that lattice are exactly the primitive types (cf. Appendix).
Example. Figure 3.2 represents an ordered set and the lattice of its antichains; the
ﬁrst set can be seen as the set T of primitive types and the lattice is then the set T ⊓
of conjunctive types over T.
de
bcd
e
cd
bc
bd
d
c
b
a
e
d
c
b
a
Fig. 3.2 An ordered set and the lattice of its antichains
The property of being a banned conjunctive type is hereditary: If a conjunctive
type A is banned, all conjunctive types less than A are also banned. For instance, if
A = {Car,Animal} is banned then {RacingCar,Animal} is banned too.
Deﬁnition 3.4 (Banned type set). Let B denote a set of conjunctive types. An ele-
ment of T ⊓is said to be banned with respect to B if it is less than or equal to (at
least) an element of B. B∗denotes the set of all banned types: B∗= {t ∈T ⊓| ∃t′ ∈
B,t ≤t′}.
In the ordered sets terminology, B∗is the union of the ideals generated by the banned
types.
Example. Figure 3.3 presents examples of banned and non-banned types. {Building-
Block,Cube,Firetruck} is banned because it is less than {BuildingBlock,Car},
which is itself banned.
The set of non-banned types, i.e., of acceptable types, is obtained from T ⊓by
removing B∗:
Deﬁnition 3.5 (Concept type hierarchy). A concept type hierarchy TC(T, B), is
given by a couple (T, B), where:
• T, the set of primitive concept types, is partially ordered by ≤, with a greatest
element, denoted by ⊤and called the universal type,

3.2 Vocabulary
65
{Toy,Firetruck}
banned type 
{BuildingBlock,Cube,Firetruck}
Car
Acceptable types
Banned type s
{BuildingBlock,Car}
BuildingBlock       Cube
Firetruck
{BuildingBlock,Cube}
Toy
{Father, Mother}
{Red, Blue}
{Action, Object}
{Toy, Attribute}
{Animal, MathNotion}
Fig. 3.3 Examples of banned and acceptable concept types
• B, the set of basic banned conjunctive types, is composed of conjunctive types
over T,
• B complies with T, i.e., for all b ∈B, there is no type t ∈T with t ≤b i.e.,
B∗∩T = ∅.
TC(T, B) is deﬁned as the set T ⊓\ B∗. T ⊓is thus partitioned into the acceptable
types TC(T, B) and the banned types B∗. Whenever there is no risk of ambiguity,
TC(T, B) is simply denoted TC.
An important particular concept type hierarchy is the case where there are no banned
types, i.e., B is empty. In this case TC = T ⊓and TC is a lattice. In general case, TC is
a sup-semi-lattice, i.e., each pair of types has a least upper bound.
A conjunctive vocabulary contains three parts: A hierarchy of concept types, a
hierarchy of relation types, and a set of markers.
Deﬁnition 3.6 (Vocabulary). A conjunctive vocabulary is a triple (TC,TR,I).
• TC,TR,I are pairwise disjoint sets.
• TC is the concept type hierarchy deﬁned by a set T of primitive concept types and
a set B of banned conjunctions.
• TR, the set of relation symbols, is ordered by a relation ≤, and is partitioned into
subsets T 1
R ,...,T k
R of relation symbols of arity 1,...,k respectively. The arity of
a relation r is denoted arity(r). Furthermore, any two relations with different
arities are not comparable.
• I is the set of individual markers.
BGs (cf. Deﬁnition 2.2) can be deﬁned on a conjunctive vocabulary and hereafter
a conjunctive vocabulary is simply called a vocabulary.
The set of ordered concept labels is deﬁned in the same way as in Chap. 2:
Deﬁnition 3.7 (Ordered set of concept labels). The ordered set of concept labels
is the cartesian product of the ordered sets TC and I ∪{∗}.

66
3 Simple Conceptual Graphs
The introduction of conjunctive types gives a semi-lattice structure to the set of
concept labels:
Property 3.2. The ordered set of concept labels on a conjunctive vocabulary is a
sup-semi-lattice.
Proof. TC is a sup-semi lattice since it is obtained from a lattice by removing ele-
ments while keeping the least upper bound of all remaining elements (if t and t′ are
acceptable, then t ∨t′ is acceptable too). I ∪{∗} is a sup-semi-lattice. One concludes
using a (simple) semi-lattice property: The product of two sup-semi-lattices is a sup-
semi-lattice (indeed, let (t,m) and (t′,m′) be two concept labels; it is easy to check
that (lub(t,t′),lub(m,m′)) is equal to lub((t,m),(t′,m′))). Thus TC ×{I ∪{∗}} is a
sup-semi-lattice.
⊓⊔
A set of labels therefore has a least upper bound. An entity of the application
domain can be represented by several concepts. In this case the labels of these con-
cepts have to satisfy two conditions. The ﬁrst condition, already seen in Chap. 2,
corresponds to the Unique Name Assumption: Two distinct individual markers can-
not represent the same entity. The second condition requires that the conjunction of
the types of the concepts representing an entity does not yield a banned type. These
two conditions are fulﬁlled in the following deﬁnition.
Deﬁnition 3.8 (Compatible concept labels).
The concept labels (t1,m1),...,
(tk,mk) are compatible if
• there is at most one individual marker, i.e., |I ∩{m1,...,mk}| ≤1,
• the conjunctive type t′ = min{t1 ∪...∪tk} is in TC.
Property 3.3. The concept labels (t1,m1), ..., (tk,mk) are compatible if and only if
these labels possess a greatest lower bound.
The greatest lower bound of concept labels (t1,m1), ..., (tk,mk) is the concept
label (t′, m′) with t′ = min{t1 ∪... ∪tk} and m′ = min{m1,...,mk}, i.e., m′ is the
generic marker if all mi are generic markers, otherwise m is the only individual
marker appearing in the mi.
Example. (Object,∗),(Cube,C3),(Toy ∧Small,∗) are compatible. Assume that
{Young, Mother} is not banned then (Young, Judy) and (Mother, ∗) are compati-
ble, but (Young, Judy) and (Mother, Mary) are not compatible because Judy and
Mary are different individuals.
3.3 Simple Conceptual Graphs (SGs)
Roughly said, an SG is a BG plus a coreference relation. A coreference relation is
an equivalence relation over the concept set and two equivalent concepts are called
coreferent concepts. The important properties to fulﬁll are, ﬁrst, that coreferent con-
cepts can always be merged, secondly, that the formal semantics of the obtained
graph is equivalent to those of the original one (cf. Chap. 4).

3.3 Simple Conceptual Graphs (SGs)
67
Deﬁnition 3.9 (Compatible concept nodes). A set of compatible concept nodes is
a set of concept nodes such that the set of their labels is compatible, i.e., these labels
possess a greatest lower bound. The label of a compatible concept set X is deﬁned
as l(X) = glb({l(x) | x ∈X}).
Deﬁnition 3.10 (Simple conceptual graph). A simple conceptual graph (in short
SG) over a vocabulary V is a 5-tuple (C,R,E,l,coref), such that:
• (C,R,E,l) is a basic conceptual graph over V.
• coref is an equivalence relation over C, such that:
any coref class is compatible,
if two individual concepts have the same marker then they are in the same
coref class.
In graph drawings, a coreference relation is usually only partially represented by
coreference links (cf. Fig. 3.4). A coreference link connects two coreferent concepts.
Coreference links are usually represented by dashed lines. Note that the coreference
relation is the reﬂexive and transitive closure of the relation, which is the union of the
set of coreference links and the relation linking two individual concept nodes having
the same marker. When it is totally represented in a graph drawing, the coreference
links form a “clique” on concepts belonging to the same coreference class, i.e., each
pair of concepts of a coreference class is connected by a coreference link.
Example. An SG is presented in Fig. 3.4. Its coreference classes are: {c1,c2,c3},
{d1,d2}, and the trivial classes {a}, {b} and {c}. The coreference link between c1
and c3 is not represented, it is obtained by transitive closure.
attr
hold
play3
sisterOf
possess
Toy
Firetruck
Child
Person: Mary
Child: Paul
2
1
2
1
3
c
b
c2
d2
d1
c1
a
c3
2
Car
Boy
Size: Small
1
2
1
2
1
Fig. 3.4 A Simple conceptual graph
What are coreference links useful for? A ﬁrst feature is that they can be exploited
in user interfaces. Indeed, one advantage of BGs is their readability, a quality that
is lost when the BG becomes too big (e.g., too big to be entirely drawn on a screen)

68
3 Simple Conceptual Graphs
or too complex. A BG that is too big can be split into pieces, with each piece being
displayable on a screen. The split can also be performed to decompose a BG into
semantic modules, or to enhance a particular substructure. Coreference links enable
the representation of a BG by several pieces, while keeping its global structure.
A user can build a BG piece by piece, then connect them with coreference links.
Another important case is when a conceptual graph basis has been constructed by
different people or at different times. Finally, coreference links can also be used to
decompose a graph into a simpler structure that can be exploited in algorithms. See
for instance the tree covering notion in Chap. 7.
We will see that it is easy to construct a BG (i.e., to get rid of the coreference re-
lation) that is semantically equivalent to an SG. Thus, even if coreference is a useful
representation tool, it does not add expressivity to BGs. The reasoning mechanisms
deﬁned for BGs can still be used, with the SGs being transformed into BGs before
any computation. Let us point out, however, that coreference will play a more sub-
stantial role in more complex graphs such as nested conceptual graphs (Chap. 9)
and rules (Chap. 10). It will also be a fundamental element in full conceptual graphs
(Chap. 12).
Deﬁnitions concerning BGs can be directly adapted to SGs. Indeed, an SG is a
BG plus a coreference relation on the set of concept nodes. Thus, let P be a notion
concerning BGs, then an extension of this notion to SGs can be obtained as fol-
lows. Let G = (C,R,E,l,coref) be an SG: The notion P is considered for the BG
(C,R,E,l) and a condition taking the coreference relation into account is added. Let
us give some examples.
Deﬁnition 3.11 (subSG). Let G = (C,R,E,l,coref) be an SG. A subSG of G is an
SG G′ = (C′,R′,E′,l′,coref ′), such that:
• (C′,R′,E′,l′) is a subBG of (C,R,E,l).
• coref ′ is the restriction of coref to C′ (i.e., a class of coref ′ is the intersection
of a class of coref with C′).
The homomorphism notion for BGs can also be easily extended to SGs. Two
coreferent concepts must have coreferent images: either the same image (since coref
is a reﬂexive relation) or distinct coreferent images.
Deﬁnition 3.12 (SG homomorphism and ⪰). Let G = (CG,RG,EG,lG,corefG)
and H = (CH,RH,EH,lH,corefH) be two SGs deﬁned on the same vocabulary. A ho-
momorphism π from G to H is a homomorphism from the BG (CG,RG,EG,lG) to the
BG (CH,RH,EH,lH) that preserves the coreference, i.e. ∀x,y ∈CG,corefG(x,y) →
corefH(π(x),π(y)).
G ⪰H means that there is a homomorphism from G to H.
An SG isomorphism is naturally deﬁned as follows:
Deﬁnition 3.13 (SG isomorphism). Let G = (C,R,E,l,coref) and G′ = (C′,R′,
E′,l′,coref ′) be two SGs. G and G′ are isomorphic if ﬁrst, there is a BG isomor-
phism π from (C,R,E,l) to (C′,R′,E′,l′); secondly, π preserves the coref classes,
that is x and y are coreferent in G if and only if π(x) and π(y) are coreferent in G′.

3.4 Generalization and Specialization Operations
69
Before studying the SG homomorphism in more detail it is useful to deﬁne gen-
eralization and specialization operations.
3.4 Generalization and Specialization Operations
In this section, the elementary generalization and specialization operations deﬁned
in Chap. 2 are extended to SGs, i.e., the coreference relation is taken into account.
We will group operations into three clusters: Equivalence operations, (plain) gen-
eralization operations and (plain) specialization operations. By “plain” we mean that
these operations generally do not produce an equivalent SG although they may be
equivalent in some cases. Note that when operations have the same name as for
BGs, they are the same operation, i.e., the coreference relation is not changed by the
operation.
Deﬁnition 3.14 (SG Equivalence operations). The elementary equivalence opera-
tions are:
• Copy. Create a disjoint copy of an SG G. More precisely, given an SG G,
copy(G) is an SG which is disjoint from G and isomorphic to G.
• Relation duplicate. Given an SG G and a relation r of G, relDuplicate(G,r) is
the SG obtained from G by adding a new relation node r′ having the same type
and the same list of arguments as r.
• Relation simplify. Given an SG G, and two twin relations r and r′ (relation
with the same type and the same list of neighbors), relSimpli fy(G,r′) is the SG
obtained from G by deleting r′.
• Concept split. Split a concept into coreferent concepts. Let c be a concept node
of G and {A1,A2} be a partition of the edges incident to c. split(G,c,A1,A2) is
the SG obtained from G by: creating two new concept nodes c1 and c2 with the
same label as c, attaching A1 to c1 and A2 to c2 (A1 or A2 may be empty), adding
c1 and c2 to the coreference class of c, and ﬁnally deleting c.
• Coreferent nodes merge. Given an SG G, and two coreferent concepts c1 and
c2 of G, merge c1 and c2, i.e., create a node c with the label being the greatest
lower bound of c1 and c2 labels, attach to c all edges incident to c1 or c2 (replace
every edge (r,i,c1) or (r,i,c2) with an edge (r,i,c)), add c in the coreference class
of c1 and c2 and delete these nodes.
• Concept label modify. Let c be a concept node in a coreference class X of an SG
G = (C,R,E,l,coref). Change l(c) = L into L′ in such a way that the label of X
is unchanged; otherwise said, the modiﬁcation of the label of c does not change
the glb of the label of concepts in X.
Deﬁnition 3.15 ((plain) SG Generalization operations). The elementary general-
ization operations are:
• Increase. Increase the label of a node (concept or relation). More precisely,
given an SG G, a node x of G, and a label L ≥l(x) increase(G,x,L) is the SG

70
3 Simple Conceptual Graphs
obtained from G by increasing the label of x up to L, i.e., its type if x is a relation,
its type and/or its marker if x is a concept.
• Coreference delete. Split a coreference class into two (non-empty) classes.
• Substract. Given an SG G, and a set of connected components C1,...,Ck of G,
substract(G,C1,...,Ck) is the SG obtained from G by deleting C1,...,Ck (the
result may be the empty graph).
Deﬁnition 3.16 ((plain) SG Specialization operations). The elementary special-
ization operations are:
Restrict. Given an SG G, a node x of G, and a label l ≤l(x) restrict(G,x,l) is
the SG obtained from G by decreasing the label of x to l that is its type if x is a
relation, its type and/or its marker if x is a concept. The compatibility condition
has to be preserved.
Coreference add up. Make the union of two coreference classes of G provided
that their union is a compatible set.
Disjoint sum. Given two disjoint SGs G = (C,R,E,l,coref) and H = (C′,R′,
E′,l′,coref ′), G+H = (C∪C′,R∪R′,E ∪E′,l ∪l′,coref ∪coref ′) (G or H may
be empty).
Generalization and specialization of SGs are deﬁned similar to BGs as a sequence
of elementary operations.
Deﬁnition 3.17 (SG generalization and specialization operations). The set of
generalization operations is composed of equivalence operations and plain gener-
alization operations. The set of specialization operations is composed of equiva-
lence operations and plain specialization operations. Given two SGs G and H, G is
a generalization (resp. specialization) of H if there is a generalization (resp. special-
ization) sequence from G to H.
The disjoint sum operation is not the inverse of the substract operation, but the in-
verse of a substract operation can be performed by a disjoint sum plus a coreference
addition, thus:
Property 3.4. Given two SGs G and H, G is a generalization of H if and only if H
is a specialization of G.
Deﬁnition 3.18 (Gen-Equivalence). Given two SGs G and H they are called gen-
equivalent if G is a generalization (or specialization) of H and reciprocally.
Operations on BGs are naturally included in operations on SGs, either directly
under the same name, or they can be performed by a combination of operations
of the same category on SGs. Indeed, a detach operation for SGs can be obtained
by a split into coreferent nodes followed by a coreference deletion, which are both
generalization operations, and a join for SGs can be obtained by a co-reference
addition followed by a merging of co-referent nodes, which are both specialization
operations.

3.5 Standard and Normal SGs
71
3.5 Standard and Normal SGs
A normal SG is such that coref is the identity relation, i.e., each node is uniquely
coreferent with itself. In the notation of a normal SG, coref is usually omitted; a
normal SG is thus simply denoted by (C,R,E,l), as a (normal) BG. This is a consis-
tent notation because a BG can be considered as an SG with the following implicit
coreference relation: Each generic concept constitutes a class and all individual con-
cepts with the same marker are coreferent.
Thus, normal SGs and normal BGs can be identiﬁed. Furthermore, a normal SG
can be associated with any SG G by considering the SG G/coref, obtained by merg-
ing all concepts belonging to a coreference class. Merging a coreference class X
consists of two successive sequences of elementary specialization operations: First,
all concept labels in X are restricted to l(X) = glb({l(c) | c ∈X}), then the class is
condensed to a single concept by a merge coreferent nodes operation. The ﬁrst step
is called the standardization of an SG G. The result is the standard form of G.
Deﬁnition 3.19 (Standard SG). A standard SG is an SG such that all coreferent
nodes have the same label. The standard form of an SG G, denoted stand(G), is
obtained from G by restricting the label of each concept in a coreference class X to
l(X) = glb({l(x) | x ∈X}).
Example. Figure 3.5 presents the standard form of the SG in Fig. 3.4.
play3
Firetruck,Toy
Firetruck,Toy
Firetruck,Toy
Person: Mary
Child
2
1
2
1
Size: Small
2
sisterOf
Boy: Paul
Boy: Paul
2
2
1
3
1
1
d1
d2
c1
c3
c2
possess
attr
hold
Fig. 3.5 Standard form of the SG in Fig. 3.4
The normal form of an SG G is indifferently denoted norm(G) or G/coref. The
latter notation shows that the normal form can be computed by ﬁrst computing the
(ordinary) quotient graph graph(G)/coref ′, where coref ′ is obtained from coref
by adding trivial classes corresponding to the relation nodes of G (each relation node
constitutes a class), then by giving the correct labels to the nodes.
Deﬁnition 3.20 (G/coref and norm(G)). Let G = (C,R,E,l,coref) be an SG.
G/coref is the normal SG obtained as follows: for any coref class X = {c1,...,ck},

72
3 Simple Conceptual Graphs
all ci are merged into one concept X. G/coref is also called the normal form of G,
and denoted by norm(G).
The normal form of the SG G in Fig. 3.4 is the SG in Fig. 3.6. Note that the
standard and normal forms can be computed in linear time (relative to the size of
the original graph) if the computation of the glb of k concept labels is in O(k).
attr
play3
possess
hold
Person: Mary
Child
1
2
1
2
1
Size: Small
2
, Toy
Firetruck
Boy: Paul
sisterOf
1
3
2
1
2
Fig. 3.6 G/core f
The three SGs G, stand(G) and norm(G) are gen-equivalent in the sense of Def-
inition 3.18.
Property 3.5. For any SG G, the three SGs G, stand(G), and norm(G) are gen-
equivalent.
Proof. One can see that there are sequences of equivalence operations for trans-
forming any SG in {G,stand(G),norm(G)} into any other. stand(G) is obtained
from G by a sequence of concept label modify operations. norm(G) is obtained
from stand(G) by a sequence of coreferent node merge operations, ﬁnally G is
obtained from norm(G) by a sequence of concept split and concept label modify
operations.
⊓⊔
Intuitively, G, stand(G) and norm(G) have the same meaning. We will see later
that their formal semantics are indeed equivalent.
3.6 Coref-Homomorphism
Let us now study the relationships between an SG G, its standard form stand(G)
and its normal form norm(G) with respect to SG homomorphism. The following
property is immediate:

3.6 Coref-Homomorphism
73
Property 3.6. Let G be an SG. There is a homomorphism from G to stand(G) and a
homomorphism from stand(G) to norm(G). Thus: G ⪰stand(G) ⪰norm(G).
The homomorphisms associated with the sequence of equivalence operations de-
scribed above yielding stand(G) and norm(G) are called canonical homomorphisms
from G to stand(G) and norm(G). The former is restricted to the identity (it is a bi-
jective homomorphism) and the latter is the surjective mapping naturally associated
with the quotient operation G/coref. Thus, as natural as it may seem, the SG ho-
momorphism notion is not entirely satisfactory.
The converse homomorphisms do not generally occur (unless G is standard or
normal).
We are faced with the problem we had foreseen on BGs: Due to the presence of
coreferent nodes, graphs with the same intuitive semantic may not be equivalent for
homomorphism. Let us go into further detail.
Property 3.7. Given SGs G and H, there is a bijective mapping between the set of
homomorphisms from G to norm(H) and the set of homomorphisms from norm(G)
to norm(H).
Proof. Let πG be the canonical homomorphism from G to norm(G). Let P be the
mapping that associates the homomorphism π′ = π ◦πG from G to norm(H) with
any homomorphism π from norm(G) to norm(H).
P is injective because, given two distinct homomorphisms π1 and π2 from norm(G)
to norm(H) and any node x of norm(G), if π1(x) ̸= π2(x), then for any node y with
πG(y) = x, π1(πG(y)) ̸= π2(πG(y)).
Let us prove that P is surjective. Let π′ be any homomorphism from G to norm(H),
then we prove that it can be decomposed into π ◦πG, where π is a homomor-
phism from norm(G) to norm(H). Indeed, π is built as follows: For every node
x in norm(G), if x is a node of G, in particular if x is a relation node, then
π(x) = π′(x). Otherwise let c1...cn be the nodes of G merged into x in norm(G);
by deﬁnition of πG, for all these nodes ci, πG(ci) = x, and since π′ is a ho-
momorphism and norm(H) is normal, all ci have the same image by π′, then,
given any ci, one takes π(x) = π′(ci). By deﬁnition of coreference and homomor-
phism, for any i = 1,...,n label(ci) ≥label(π′(ci)) = label(π(x)), so label(x) =
glb({label(ci) | i = 1,...,n}) ≥label(π(x)). Furthermore, let (r,i,x) be in norm(G)
then π(r) = π′(r). If x belongs to G then π(x) = π′(x). As π′ is a homomor-
phism, (π′(r),i,π′(x)) = (π(r),i,π(x)) is in norm(H). Otherwise, x is obtained
from c1...cn and there is a cj, 1 ≤j ≤n, with (r,i,cj) in G. As π′ is a homomor-
phism, (π′(r),i,π′(x)) = (π(r),i,π(x)) is in norm(H). Thus, π is a homomorphism.
Check that π ◦πG = π′.
P is injective and surjective so it is bijective.
⊓⊔
Figure 3.7 shows Property 3.7 as a commutative diagram.
Thus, in order to obtain a “good” SG homomorphism behavior, one only has to
ensure that the target graph H is in normal form, regardless of whether the source
graph G is normal or not.

74
3 Simple Conceptual Graphs
G
norm(H)
norm(G)
G
π ’
π
i
i
i
π
Fig. 3.7 Illustration of Property 3.7
The normal form of an SG always exists and is easily computable, however in
some cases it may be important to keep SGs exactly as they are. For example, con-
sider a set of SGs over the same vocabulary built by different users. If a query is
made on this base the whole base has to be considered to compute the answers,
but the SGs must not be changed. Another example is that of a base distributed on
several sites.
The question now is the following: Why does homomorphism not deal correctly
with coreference? The reason is that it is ﬁrst of all a mapping on concepts; if we
modify it so that it maps coreference classes onto coreference classes, we obtain the
desired notion.
Deﬁnition 3.21 (coref-homomorphism). Let G=(CG,RG,EG,lG,corefG) and H=
(CH,RH,EH,lH,corefH) be two SGs deﬁned on the same vocabulary. A coref-
homomorphism from G to H is a mapping π from corefG to corefH and from RG to
RH, such that:
1. ∀(r,i,c) ∈G , let C be the coreference class of c, then there is a concept c′ ∈π(C)
such that (π(r),i,c′) ∈H,
2. ∀C ∈corefG, let lH(π(C)) be the greatest lower bound of the concept labels in
π(C) then, for all c ∈C, lG(c) ≥lH(π(C)),
3. ∀r ∈RG, lG(r) ≥lH(π(r)).
Each homomorphism deﬁnes a coref-homomorphism, since all coreferent nodes
have their images in the same coreference class. The following property speciﬁes
the relationships between both notions.

3.6 Coref-Homomorphism
75
Property 3.8. Given SGs G and H, there is a bijective mapping between the set of
coref-homomorphisms from G to H and the set of homomorphisms from norm(G)
to norm(H).
Proof. There is a bijection, say b, between concept nodes of norm(G) (resp.
norm(H)) and coreference classes in G (resp. H). Let us show that b deﬁnes the
desired mapping between the set of coref-homomorphisms from G to H and the set
of homomorphisms from norm(G) to norm(H). Let π be a coref-homomorphism
from G to H. Let π′ be the induced mapping from nodes of norm(G) to nodes of
norm(H): For each concept c in norm(G), π′(c) = b−1(π(b(c))) and for each rela-
tion r of norm(G), π′(r) = π(r).
This correspondence is injective. Indeed, let π1 and π2 be two coref-homomor-
phisms from G to H. There is a concept c in norm(G) with π1(c) ̸= π2(c), then
π′
1(c) ̸= π′
2(c).
We check that π′ is a homomorphism from norm(G) to norm(H): For every
edge (r,i,c) in norm(G), there is an edge (r,i,d) in G where d is in the corefer-
ence class b(c), thus, due to condition 1 of the coref-homomorphism, there is an
edge (π′(r),i,d′) in H where d′ is in the coreference class π(b(c)). Thus an edge
(π′(r),i,π′(c)) since π′(c) = b−1(π(b(c))). For every concept c in norm(G), condi-
tion 2 of coref-homomorphism ensures that for all ci ∈b(c), l(ci) ≥l(π′(c)); thus by
deﬁnition of a greatest lower bound, l(c) ≥l(π′(c)). In the same way, we check that
any homomorphism π′ from norm(G) to norm(H) yields a coref-homomorphism π
from G to H using bijection b. For every edge (r,i,cj) in G, let C be the corefence
class of cj, there is an edge (r,i,c) in norm(G), where C = b(c), hence an edge
(r,i,π′(c)) in norm(H), thus an edge (r,i,c′
j) in H such that c′
j belongs to the coref-
erence class b(π′(c)), which is exactly π(C). For every coreference class C in G, for
every c in C, l(c) ≥l(π′(b−1(C))), which is exactly l(π(C)), thus l(c) ≥l(π(C)).
Thus, the correspondence between coref-homomorphisms from G to H and ho-
momorphisms from norm(G) to norm(H) is surjective and injective.
⊓⊔
The following theorem summarizes the “safe” ways of comparing two SGs.
Theorem 3.1. Let G and H be two SGs. There is a bijective mapping between:
• coref-homomorphisms from G to H,
• homomorphisms from norm(G) to norm(H),
• homomorphisms from G to norm(H).
The intuitive meaning of generalization or specialization operations is better cap-
tured by coref-homomorphism than by homomorphism. This is shown in the follow-
ing theorem for SGs, which is similar to the Theorem 2.3 for BGs where homomor-
phism is replaced by coref-homomorphism:
Theorem 3.2. Let G and H be two SGs. The three following propositions are equiv-
alent:
1. H is a specialization of G,
2. G is a generalization of H,

76
3 Simple Conceptual Graphs
3. there is a coref-homomorphism from G to H.
Proof. The equivalence between (1) and (2) has already been stated (cf. Sect. 3.4).
(1) ⇒(3): in a specialization sequence from G to H, each specialization step, say
from Hi to Hi+1, deﬁnes a coref-homomorphism from Hi to Hi+1. By composition
of these coref-homomorphisms, one obtains a coref-homomorphism from G to H.
(3) ⇒(1): Let π be a coref-homomorphism from G to H. Let us show that H
is a specialization of G. From G, one builds norm(G) using the equivalence op-
eration coreferent nodes merge. By Property 3.8, there is a homomorphism from
norm(G) to norm(H). Thus by Theorem 2.3, there is a BG specialization sequence
from norm(G) to norm(H). This BG specialization sequence can be rewritten as an
SG specialisation sequence, with the join operation being replaced either by a coref-
erent nodes merge if the joined nodes are individual nodes, or decomposed into a
coreference addition followed by a coreferent nodes merge if the joined nodes are
generic nodes. By Property 3.5, there is a specialization sequence from norm(H) to
H.
⊓⊔
3.7 Antinormal Form and Homomorphism
The normal form of an SG is, in a sense, the most compact form of an SG. The
antinormal form studied in this section can be considered as the most scattered form
of an SG: Each relation node is disconnected from the other relation nodes and there
are no multiple edges. Thus, a relation node and its neighbors can be considered as a
tuple. The antinormal form of an SG can be considered as a representation of an SG
by tables in the database relational model. Indeed, gathering all tuples correspond-
ing to relation nodes with the same label is equivalent to building a table. Then
usual database systems and operations can be used. The correspondence between
conceptual graphs and relational structures is studied in Chap. 5. In this section, it is
assumed that an SG has no isolated concept node, and it is straightforward to extend
all the results if isolated concepts exist.
Deﬁnition 3.22 (Antinormal SG). An SG is called antinormal if:
• any concept node is incident to exactly one edge,
• it is standard, i.e., all the concept labels in any coref class are identical.
For any SG G antinorm(G) is the SG obtained from G as follows: First it is
standardized; then each concept node c with k > 1 incident edges, say e1,...,ek, is
split into k coreferent nodes c1,...,ck, with each edge ei = (r, j,c) becoming an edge
(r, j,ci). antinorm(G) is obtained from G by a sequence of specialization operations,
moreover:
Property 3.9. Let G be an SG. There is a homomorphism from antinorm(G) to
stand(G), i.e., antinorm(G) ⪰stand(G).

3.7 Antinormal Form and Homomorphism
77
antinorm
x
y
z
x
x
y
y
x
z
y
z
r
s
r
r
r
s
1
2
3
2
1
3
1
2
3
1
2
3
1
2
1
2
Fig. 3.8 An SG and its antinormal form
Example. Figure 3.8 presents an SG and its antinormal form. In this ﬁgure, the
concepts labeled by x (or by y or by z) are coreferent.
Figure 3.9 shows that antinorm(G) does not generally map to G if G is not stan-
dard.
antinorm
antinorm(G)
G
r
s
r
s
t1
t2
t1,t2
t1,t2
Fig. 3.9 antinorm(G) does not map to ⪰G
Note that the relation node sets of antinorm(G) and G are equal, even if G is not
standard.
If an SG is not antinormal then it does not generally map to its antinormal form
by a homomorphism (cf. example given in Fig. 3.8).
The subsumption relation behaves in the same way for the normal forms and
antinormal forms.
Property 3.10. Given two SGs G and H, there is a bijection from the set of ho-
momorphisms from norm(G) to norm(H) to the set of homomorphisms from
antinorm(G) to antinorm(H).
Proof. Let π be a homomorphism from norm(G) to norm(H) and φH be the canon-
ical homomorphism from antinorm(H) to norm(H). A homomorphism π′ from
antinorm(G) to antinorm(H) can be constructed as follows. For any relation node,

78
3 Simple Conceptual Graphs
π′(r) = π(r) since the relation nodes of an SG and its normal form are the same.
Let c be a concept node of antinorm(G). c is in the coreference class of a con-
cept d of norm(G) and is incident to a unique edge (r,i,c). There is a unique con-
cept c′ of antinorm(H), which corresponds to the edge (π(r),i,π(d)) in norm(H).
One takes π′(c) = c′ (cf. Fig. 3.10). If one considers two different homomorphisms
from norm(G) to norm(H) the associated homomorphisms from antinorm(G) to
antinorm(H) are also different. Reciprocally, let π′ be a homomorphism from
antinorm(G) to antinorm(H). The mapping π deﬁned as follows is a homomor-
phism from norm(G) to norm(H). To any relation node r of norm(G) π(r) = π′(r).
Let d be a concept of norm(G). For any (r,i,d) in norm(G) corresponds a single
c in antinorm(G) with (r,i,c) in antinorm(G). (π′(r),i,π′(c)) is in antinorm(H).
One takes π(d) = φH(π′(c)).
This does not depend on the choice of the edge (r,i,d) incident to d since for any
other edge (r′, j,d) in norm(G) corresponding with the node c′ in antinorm(G), we
have φH(π′(c)) = φH(π′(c′)) by the preservation of coreference by π′.
Figure 3.10 illustrates this part of the proof. Indeed, one can say that the dia-
gram in Fig. 3.10 commutes. If one considers two different homomorphisms from
antinorm(G) to antinorm(H), the associated homomorphisms from norm(G) to
norm(H) are also different. The construction is injective in the two directions, so
there is a bijection between the two homomorphism sets.
⊓⊔
antinorm(H)
norm(H)
norm(G)
G
H
antinorm(G)
π ’
π ’
φ
φ
i
π
π
i
i
i
Fig. 3.10 Illustration of Property 3.10

3.7 Antinormal Form and Homomorphism
79
Let us use an example to illustrate the importance for Property 3.10 of the last
condition in Deﬁnition 3.22 of an antinormal SG. Figure 3.11 presents two non-
standard SGs G1 and G2, where the relation types r and s are not comparable. These
SGs satisfy the ﬁrst antinormality condition since they are totally scattered. One has
norm(G1) = norm(G2) = G, but there is neither a homomorphism from G1 to G2
nor from G2 to G1.
G1
norm(G1)=norm(G2)
t1, t2
G2
s
r
t1
t2
t2
t1
s
r
s
r
Fig. 3.11 G1 and G2 are not antinormal SGs
The following property shows the difference between the behavior of the homo-
morphism for the normal form and the antinormal form (cf. Property 3.7).
Property 3.11. Let G and H be two SGs. If antinorm(G) ⪰H, then antinorm(G) ⪰
antinorm(H). When H is standard, the converse is true: If antinorm(G) ⪰
antinorm(H) then antinorm(G) ⪰H.
Proof. Let π be a homomorphism from antinorm(G) to H. A homomorphism π′
from antinorm(G) to antinorm(H) can be constructed as follows. For any relation
node, π′(r) = π(r) since the relation nodes of an SG and its antinormal form are the
same. Let (r,i,c) in antinorm(G). (π(r),i,π(c)) is in H and the label of c is greater
than or equal to the label of π(c). There is a single concept d in antinorm(H) which
is adjacent to an edge numbered i to π(r). The label of π(c) is greater than or equal
to the label of d and one takes π′(c) = d (cf. Fig. 3.12). Let us assume that H is
standard. Property 3.9 and the transitivity of ⪰yield the second part of the property.
⊓⊔
Example. Let us consider an SG H isomorphic to the SG G on the left side in
Fig. 3.9). There is a (trivial) homomorphism from antinorm(G) to antinorm(H) =
antinorm(G), but there is no homomorphism from antinorm(G) to H.

80
3 Simple Conceptual Graphs
H
antinorm(G)
antinorm(H)
π ’
’
π
r
i
π
π
c’
i
i
i
r
r
d
c
Fig. 3.12 Illustration of Property 3.11
3.8 Bibliographic Notes
The notion of a coreference link was introduced in [Sow84], mainly as a means of
representing an anaphoric reference in the context of natural language processing.
In [Sow84] the concept type set is a lattice. In later works, it becomes a partially
ordered set with a greatest element, thus a less constrained structure. The distinction
between lattice-theoretical and order-theoretical interpretations is from [BHP+92]),
and its effect on reasoning with CGs was pointed out in [WL94] and [CCW97].
The framework presented in this chapter is based on [CM04], which itself gathers
and generalizes several previous works. Let us mention [CMS98], in which corefer-
ence (called co-identity) was deﬁned as an equivalence relation on concept nodes.
In this work, coreferent nodes were either individual nodes with the same label,
or generic nodes with the same type, with these restrictions being related to prop-
erties (a) and (b) discussed in the introduction to this chapter. The extension of
generalization and specialization operations to this restricted coreference relation
was presented in [Mug00]. Type conjunction in conceptual graphs was ﬁrst con-
sidered in the context of fuzzy types [CCW97] (and later [TBH03a] [TBH03b]) or
in relationship with description logics [BMT99]. In [Bag01], the set of conjunctive
concept types was deﬁned in intension by a hierarchy of primitive concept types;
type conjunction was also deﬁned for relations, on the condition that these relations
have the same arity. [CM04] mainly added the notion of banned conjunctive type
and coref-homomorphism. Note that if we allow to name conjunctive types, we ob-
tain a simple type deﬁnition mechanism, with conjunction as the only constructor.
More complex type deﬁnition mechanisms are mentioned in Chap. 8.

3.8 Bibliographic Notes
81
According to the unique name assumption, different individual markers represent
different entities. An exception to this common assumption is the framework of
[Dau03a] which allows coreference between concept nodes with different individual
markers. In other words, there are aliases among the individual markers. This case
could be included in our framework with slight modiﬁcations.
The notion of antinormal form of an SG was introduced in [GW95]. The deﬁni-
tion did not include a standardization step. It was thus well-suited to the restricted
case where all coreferent nodes have the same label but not to the general case.

Chapter 4
Formal Semantics of SGs
Overview
The ﬁrst section of this chapter presents a model semantic (or set semantic) for
SGs. First, a model of a vocabulary is deﬁned. It consists of a set, the set of entities
also called a universe, upon which the concept types, the relation types and the
individuals are interpreted. A concept type is interpreted as a subset of the universe,
a relation type is interpreted as a set of tuples of elements of the universe and an
individual is interpreted as an element of the universe. Secondly, a model of an SG
over a vocabulary V is deﬁned. It is a model of V enriched by an interpretation of the
concept nodes as elements of the universe. Then, an entailment relation is deﬁned,
i.e., what it means that an SG H entails an SG G, or equivalently, what means that G
is a consequence of H. The canonical model of a SG G, which plays a speciﬁc role
in the characterization of the SGs consequences of G, is deﬁned. This ﬁrst section
ends by the fundamental theorem stating that if there is a homomorphism from G to
H then H entails G and if H/coref entails G then there is a homomorphism from
H/coref to G (i.e., a soundness and completeness theorem of SG homomorphism
with respect to entailment).
The second section concerns the presentation of a ﬁrst order logical semantic for
SGs. This semantic is deﬁned through a mapping from SGs to FOL formulas called
Φ. First, a FOL language corresponding to the elements of a vocabulary V is deﬁned
and a set of FOL formulas, denoted Φ(V), corresponding to the order relations over
V is deﬁned. Secondly, for any SG G a FOL formula Φ(G), built on the language
associated with V, is deﬁned. Thirdly, it is shown that the classical model theory of
FOL is equivalent to the model semantic presented in the ﬁrst section.
In the third section relationships between SGs and the positive, conjunctive and
existential fragment of FOL are studied. First, we introduce the L-substitution no-
tion and we use it to give another proof of the soundness and completeness theorem.
Secondly, we prove the “equivalence” between the SGs and the positive, conjunc-
tive and existential fragment of FOL. Finally, we present a second FOL semantic,
denoted Ψ, which is less intuitive than Φ but has interesting technical properties.
83

84
4 Formal Semantics of SGs
FOL is used to give a semantic to SGs, but not to reason with them. According to
our claim that SGs have good computational properties, we will build graph-based
deduction algorithms that are not translation of logical procedures. This is developed
in Chap. 6 and Chap. 7.
The ﬁnal section is a note on the relationships between description logics and
conceptual graphs.
4.1 Model Semantic
4.1.1 Models of SGs
In order to provide SGs with a set semantic, one ﬁrst has to deﬁne a model of a vo-
cabulary. A model of a vocabulary consists of a non-empty set D, called the universe
or the domain of the model, and a mapping that associates with any concept type a
subset of D, with any relation type of arity k a k-ary relation over D, i.e., a subset of
Dk, and with any individual i an element of D. A model is also called an interpreta-
tion. Primitive type concepts are interpreted by subsets of D and conjunctive types
respect the set intersection.
Deﬁnition 4.1 (Model of a vocabulary). Let us consider a vocabulary V=(TC(T,B),
TR,I). A model of V is a pair M = (D,δ), where D is a non-empty set called the
domain of M, and δ is a mapping such that:
• ∀p ∈T ∪TR,δ(p) ⊆Darity(p),
• ∀p,q ∈T ∪TR if p ≤q then δ(p) ⊆δ(q),
• ∀i ∈I, δ(i) ∈D.
The mapping δ is extended to TC(T,B) as follows:
∀t = {t1,...,tk} ∈TC, δ(t) is deﬁned by δ(t) = δ(t1)∩...∩δ(tk).
Given a model (D,δ) of a vocabulary V, in order to interpret an SG one must
supplement (D,δ) by a mapping from the concepts of G to D. Therefore, each con-
cept of G is interpreted by an element of the domain, and each k-ary relation of G is
interpreted by the k-tuples of interpretations of its neighbors.
Deﬁnition 4.2 (Model of an SG). Let G = (C,R,E,l,coref) be an SG over a vo-
cabulary V. A model of G is a triple (D,δ,α) such that: (D,δ) is a model of V
and α, called an assignment, is a mapping from C to D, such that ∀c1,c2 ∈C if
coref(c1,c2) then α(c1) = α(c2).
A model of an SG G satisﬁes G if it respects the structure and the labeling of G.
More precisely,
Deﬁnition 4.3 (Model satisfying a SG). Let G = (C,R,E,l,coref) be an SG over
V, and (D,δ,α) be a model of G.
(D,δ,α) is a model satisfying G, noted (D,δ,α) |=sg G, if α is an assignment
such that:

4.1 Model Semantic
85
• for any individual concept c with marker i: α(c) = δ(i),
• ∀c ∈C, α(c) ∈δ(type(c)),
• ∀r ∈R, if (c1,...,ck) is the list of neighbors of r, then (α(c1),...,α(ck)) ∈
δ(type(r)).
Note that if δ(⊤) ̸= D then all the elements that do not belong to δ(⊤) are useless
and can be removed, since they cannot appear in any model satisfying an SG over
V.
Example. Let G be the SG in Fig. 4.1. Let us build a model (D,δ,α) satisfying G.
D contains toys, persons, colors, sizes, etc.
δ(Car) is the subset of D containing all the cars.
δ(Person) is the subset of D containing all the persons, and so on for the different
concept types.
δ(possess) is the subset of D×D containing all the couples (d,d′) such that d is a
person who possesses the object d′.
δ(play3) is the subset of D × D × D containing all the triples (d,d′,d′′) such that
d and d′ are persons who play with the toy d′′, and so on for the different relation
types.
δ(Paul) is the element of D representing Paul, δ(Small) is the element of D repre-
senting the size small, and so on for all other individuals
α(a1) = α(a2) = δ(Paul), α(b1) = α(b2) = α(b3) = u1 ∈D, α(c) = δ(Small),
α(d) = u2 ∈D, α(e) = δ(Mary)
(δ(Paul),u1) ∈δ(possess), (δ(Paul),u2,u1) ∈δ(play3), (u2,δ(Mary)) ∈δ(dau-
ghterOf), (u1,δ(Small)) ∈δ(attr), etc.
e
c
b3
b2
b1
a2
a1
possess
attr
daughterOf
hold
play3
d
Firetruck
Child
Person: Mary
Child: Paul
Toy
2
1
2
1
3
2
Car
Boy
Size: Small
1
2
1
2
1
Fig. 4.1 An SG
Using the notion of an SG model it is now possible to deﬁne an entailment rela-
tion between SGs as follows:
Deﬁnition 4.4 (Entailment and equivalence). Let G and H be two SGs over V.

86
4 Formal Semantics of SGs
• H entails G, or G is a consequence of H, notation H |=sg G, if for any (D,δ)
model of V and for any α such that (D,δ,α) |=sg H, then there is an assignment
β of the concept nodes in G such that (D,δ,β) |=sg G.
• G and H are model-equivalent, notation G ≡sg H, if G |=sg H and H |=sg G.
The previous deﬁnitions ensure that an SG and its normal form have the same
semantic, i.e., are model-equivalent.
Property 4.1. Let G be an SG, then G ≡sg G/coref.
Proof. Let (D,δ,α) be a model satisfying G. If f denotes the mapping from CG
to CG/core f induced by the construction of G/coref, then the relation β = α ◦f −1
is a mapping from CG/core f to D. Indeed, let us consider two coreferent concepts
c1,c2 ∈CG belonging to a coref class X, then β(X) = α(c1) = α(c2). Let us check
that (D,δ,β) is a model satisfying G/coref.
1. If X is an individual concept of G/coref with marker i, then ∃c ∈CG with
marker(c) = i and β(X) = α(f −1(X)) = α(c) = δ(i).
2. If X is a generic concept of G/coref, then f −1(X) = {c1,...,ck}. Let ti =
type(ci), then type(X) = min{t1 ∪... ∪tk}. Furthermore, ∀i = 1,...,k, α(ci) ∈
δ(ti), therefore ∀i = 1,...,k, α(ci) ∈δ(t1) ∩... ∩δ(tk) = δ(min{t1 ∪... ∪tk})
and β(X) = α(ci) ∈δ(type(X)).
3. If r is a relation in G/coref with a list of neighbors X1,...,Xk, then there is a
relation s in G, with type(r) = type(s) = t and with a list of neighbors c1 ...ck
such that for all i = 1...k, Xi = f(ci). By hypothesis (α(c1),...,α(ck)) ∈δ(t),
thus (β(X1),...,β(Xk)) ∈δ(t).
Conversely, if (D,δ,β) is a model satisfying G/coref, then it is simple to check
that (D,δ,α), with α = β ◦f, is a model satisfying G.
⊓⊔
The canonical model of a SG G plays a speciﬁc role in the characterization of the
SGs consequences of G. We ﬁrst deﬁne the canonical model of an SG, then we show
that the canonical model of G is indeed a model satisfying G.
Deﬁnition 4.5 (Canonical model of normal SGs). Let G = (C,R,E,l) be a normal
SG over a vocabulary V. The canonical model of G is the triple MG = (D,κ,id)
deﬁned as follows.
• Domain. D is the set of concept nodes of G supplemented by a new element, i.e.
D = C ∪{z}, where z /∈C.
• Interpretation of individual markers. For any c individual concept of G with
marker i, κ(i) = c, and for any individual marker i which does not appear in
G, κ(i) = z.
• Interpretation of concept types. For any t ∈TC, κ(t) = {c ∈C|type(c) ≤t}.
• Interpretation of relation types. For any relation p ∈TR with arity(p) = k, κ(p) =
{(c1,...,ck)|∃r(c1,...,ck) ∈G,type(r) ≤p}.
• id is the identity over C.

4.1 Model Semantic
87
Example. The SG in Fig. 4.2 is the normal form of the SG in Fig. 4.1. Its canonical
model is the following:
D = {a,b,c,d,e}
κ(Paul) = a, κ(Small) = c, κ({Firetruck,Toy}) = {b}, κ(Child) = {a,d},
κ(Size)={c}, κ(Person)={a,d,e}, κ(play3)={(a,d,b)}, κ(possess)={(a,b)},
κ(attr) = {(b,c)}, κ(daughterOf) = {(d,e)}.
d
possess
play3
attr
hold
a
b
c
e
daughterOf
Child
Person: Mary
2
1
2
3
1
Boy: Paul
Firetruck, Toy
2
Size: Small
1
2
1
2
1
Fig. 4.2 A normal SG
The next property gathers facts simple to check:
Property 4.2 (Properties of canonical models). Let G = (C,R,E,l) be a normal SG,
(C,κ,id) the canonical model of G, satisﬁes:
1. (C,κ,id) |=sg G,
2. let t be a concept type and c ∈κ(t), then c is a concept node of G with type(c) ≤t,
3. let p be a relation type and (c1,...,ck) ∈κ(p), then c1 ...ck is the neighbor list
of some relation node r of G such that type(r) ≤p.
4.1.2 Soundness and Completeness of (coref) Homomorphism
We now prove a soundness and completeness theorem of SG homomorphism with
respect to entailment.
Lemma 4.1. Let G and H be two SGs over the same vocabulary. If there is a homo-
morphism from G to H, then H |=sg G.
Proof. Let π be a homomorphism from G = (CG,RG,EG,lG,corefG) to H = (CH,-
RH,EH,lH,corefH), and (D,δ,α) be a model satisfying H. Let us check that

88
4 Formal Semantics of SGs
(D,δ,β = α ◦π) is a model satisfying G. First, if c1 and c2 are coreferent con-
cepts of G, then their images by π are coreferent concepts of H, therefore β is an
assignment of G. Let us now check that the three conditions of deﬁnition 4.3 are
satisﬁed:
• If c is an individual concept of G with marker i, then its image by a homomor-
phism is an individual concept with the same marker i, thus β(c) = α(π(c)) =
δ(i).
• Let c be a concept of G with π(c) = c′, then type(c′) ≤type(c), and, since (D,δ)
is a model of V, it holds that δ(type(c′)) ⊆δ(type(c)). (D,δ,α) is a model sat-
isfying H, thus α(c′) ∈δ(type(c′)), and one has β(c) = α(π(c)) ∈δ(type(c′)),
therefore β(c) ∈δ(type(c)).
• Let r(c1,...,ck) be in G. (α(π(c1)),...,α(π(ck))) is an element of δ(type(π(r)))
and type(π(r)) ≤type(r), thus (β(c1),...,β(ck)) ∈δ(type(r)).
⊓⊔
Lemma 4.2. Let G and H be two SGs over the same vocabulary. The following
properties are equivalent.
1. H |=sg G.
2. There is an assignment α such that (CH/core f ,κ,α) |=sg G, where (CH/core f ,κ,id)
is the canonical model of H/coref.
3. There is a homomorphism from G to H/coref.
Proof.
1 ⇒2
Since (CH/core f ,κ,id) |=sg H/coref and H/coref |=sg H, there is β such that
(CH/core f ,κ,β) |=sg H. Thus, if H |=sg G, there is α such that (CH/core f ,κ,α) |=sg G.
2 ⇒3
Let H′ denote H/coref. By hypothesis, there is α such that (CH′,κ,α) is a model
satisfying G. We ﬁrst show that α is a mapping from CG to CH′ that respects the
condition of a homomorphism, and then, we show that there is a mapping β from
RG to RH′, such that (α,β) is a homomorphism from G to H′.
• If c is a concept in G, then α(c) ∈κ(typeG(c)). Thus, α(c) is a concept in H′
with typeH′(α(c)) ≤typeG(c). Let c be an individual concept of G with marker
i. Then, H′ contains an individual concept with marker i otherwise κ(i) /∈CH′
and (CH′,κ,α) does not satisfy G. H′ is normal, thus α(c) = κ(i), which is the
only concept of H′ with marker i.
• Let us now show that α can be extended to a homomorphism from G to H. Let
us consider any relation r of G and its neighbors list c1 ...ck. (CH′,κ,α) |=sg G
implies that (α(c1),...,α(ck)) ∈κ(typeG(r)). Therefore, according to the state-
ment 3 of Property 4.2, there is a relation s of H′ such that α(c1)...α(ck) is the
neighbor list of s with typeH′(s) ≤typeG(r). Let us deﬁne the mapping β from
RG to RH′ by β(r) = s. (α,β) is a homomorphism from G to H′.
2 ⇒3
From Lemma 4.1 and Property 4.1.
⊓⊔

4.2 Logical Semantic
89
Note that 1 ⇔2 in the previous lemma shows that deciding whether an SG G
is a consequence of an SG H can be done by considering the canonical model of
H/coref instead of all models satisfying H.
Lemmas 4.1 and 4.2 yield the following soundness and completeness result:
Theorem 4.1. Let G and H be two SGs over the same vocabulary. If there is a
homomorphism from G to H, then H |=sg G. If H/coref |=sg G, then there is a
homomorphism from G to H/coref.
Using the previous theorem and theorem 3.1 one obtains:
Theorem 4.2. Let G and H be two SGs over the same vocabulary. There is a coref-
homomorphism from G to H if and only if H |=sg G.
4.2 Logical Semantic
In this section a logical semantic for the SGs is deﬁned as follows: First, a FOL
language is naturally associated with any vocabulary V and a set of FOL formu-
las, denoted Φ(V), corresponding to the order relations existing over V, is deﬁned.
Secondly, for any SG G over V, a FOL formula Φ(G), built on the language associ-
ated with V, is deﬁned. Thirdly, it is shown that the classical model theory of FOL is
equivalent to the model semantic presented in the ﬁrst section. Therefore, a corollary
of the previous soundness and completeness theorem states that SG homomorphism
is sound and complete with respect to deduction in FOL.
4.2.1 The FOL Semantic Φ
Logical Semantic of a Vocabulary
A FOL language LV can be naturally associated with any SG vocabulary V =
(TC,TR,I). LV is deﬁned as follows: A constant is assigned to each individual
marker, a n-ary predicate is assigned to each n-ary relation type, and a unary predi-
cate is assigned to each primitive concept type.
For simplicity, we consider that each logical constant or predicate has the same
name as the element of the vocabulary it is assigned to, i.e., the logical constant asso-
ciated with the individual marker i is also denoted by i, and the predicate associated
with the type t is also denoted by t.
The ordered facet of the vocabulary V is represented by the following set Φ(V)
of FOL formulas.
Deﬁnition 4.6 (Φ(V)).
Φ(V) is equal to the following set of formulas: ∀x1 ...xk(t2(x1,...,xk) →t1(x1,
...,xk)), for all t1 and t2 primitive concept types or relation types of V such that
t2 < t1, k being the arity of t1 and t2.

90
4 Formal Semantics of SGs
Example. Let wash and act be two binary relation types, with wash < act. Φ(V)
contains the formula ∀x∀y (wash(x,y) →act(x,y)). Let Boy, Child and Person
be three concept types with Boy < Child < Person. Φ(V) contains the formulas
∀x (Boy(x) →Child(x)) and ∀x (Child(x) →Person(x)). It also contains the for-
mula ∀x (Boy(x) →Person(x)), but this formula can be obtained by transitivity
from the two ﬁrst ones. More generally, the covering relation of the order could be
interpreted instead of < itself. However, as reasonings are performed on the graphs
themselves, and not on the associated logical formulas, this question is irrelevant.
Let us consider two conjunctive types t = {t1,...,tn} and s = {s1,...,sp}. Let us
recall that t ≤s if and only if for every s j ∈s, 1 ≤j ≤p, there is a ti ∈t, 1 ≤i ≤n,
such that ti ≤s j. It is straightforward to check the following property:
Property 4.3. Let t = {t1, ..., tn} and s = {s1, ..., sp} be two conjunctive types
with t ≤s, then:
∀x(t1(x)∧...∧tn(x) →s1(x)∧...∧sp(x)) is a consequence of Φ(V).
The previous property explains why only primitive concept types are considered
in Deﬁnition 4.6. The formulas representing the order relation on the non-primitive
types are not explicitely needed since they are consequences of the formulas repre-
senting the order relation on the primitive types.
Logical Semantic of an SG
The mapping Φ transforms any SG over V into a formula of the existential con-
junctive and positive fragment of FOL over the language LV. This fragment is de-
noted FOL(∧, ∃, LV). Roughly said, concepts are translated into terms—variables
or constants—and relations are transformed into atoms (containing these terms).
Since the meaning of an SG cannot be given independently from its vocabulary,
deduction in the logical fragment associated with SGs is relative to Φ(V). That is,
given two formulas f and g of this fragment, the basic question is not whether f is
deducible from g, but rather whether f is deducible from g and Φ(V).
Deﬁnition 4.7 (Φ(G)). Given any SG G, the formula Φ(G) is built as follows.
• A term term(c) is assigned to each concept c in the following way. First, a term
term(X) is assigned to each class X of coref. If X contains an individual marker
i, then term(X) = i. Otherwise, term(X) is a variable, and distinct variables are
associated with different classes. Secondly, if c belongs to the coref class X, then
term(c) = term(X).
• Let c be a concept node with type {t1,...,tn}. The formula t1(term(c)) ∧... ∧
tn(term(c)) is assigned to c.
• The atom r(term(c1),...,term(ck)) is assigned to each relation node x, where r
is its type, k the arity of r, and ci denotes the i-th neighbor of x.
• Let φ(G) be the conjunction of the formulas associated with all the concept and
the relation nodes.
• Finally, Φ(G) is the existential closure of φ(G).

4.2 Logical Semantic
91
Note that if term is one-to-one over the set of coref classes of some SG G, it is
not necessarily the case over the concept set of G. More precisely, term is one-to-
one over the concept set of G if and only if G is normal.
Also note that Φ(G) = Φ(G/coref).
Example. Let G be the SG in Fig. 4.2. Let us build Φ(G). As G is normal, each
coreference class contains exactly one concept node. We assign to the nodes a, b, c,
d and e, respectively, the terms Paul, x, Small, y and Mary, where x and y are the
sole variables. The conjunction of the formulas assigned to the concept nodes is:
A = Boy(Paul)∧Firetruck(x)∧Toy(x)∧Size(Small)∧Child(y)∧Person(Mary).
The conjunction of the formulas assigned to the relation nodes is:
B = possess(Paul,x)∧attr(y,Small)∧play3(Paul,y,x)∧hold(y,x)∧
daughterOf(y,Mary). Finally, Φ(G) = ∃x∃y(A∧B), that is:
Φ(G) = ∃x∃y(Boy(Paul)∧Firetruck(x)∧Toy(x)∧Size(Small)∧Child(y)∧
Person(Mary) ∧possess(Paul,x) ∧attr(y,Small) ∧play3(Paul,y,x) ∧hold(y,x)∧
daughterOf(y,Mary)).
Now, let us consider the non-normal SG in Fig. 4.1, say G′. The normal form of
G′ is G. The coreference classes of G′ are {a1,a2}, {b1,b2,b3}, {c}, {d} and {e}.
Let us assign to these classes Paul, x, Small, y and Mary, i.e., the same terms as
for the corresponding nodes in G. The conjunction of the formulas assigned to the
concept nodes in G′ is A′ = Child(Paul) ∧Boy(Paul) ∧Firetruck(x) ∧Toy(x) ∧
Car(x) ∧Size(Small) ∧Child(y) ∧Person(Mary). Φ(G′) = ∃x∃y(A′ ∧B), where
B is the same as in Φ(G). Note that Φ(V) contains ∀x (Boy(x) →Child(x)) and
∀x (FireTruck(x) →Car(x)), thus the atoms Child(Paul) and Car(x) are redundant
in Φ(G′). More precisely, from Φ(V) it can be deduced that Φ(G′) and Φ(G) are
equivalent.
4.2.2 Model Semantic and Φ
The set semantic proposed in Sect. 4.1 is equivalent to the model theory for the FOL
semantic Φ.
In the following property, a (SG) model satisfying an SG G over a vocabulary
V (cf. Deﬁnition 4.3) is compared to a (FOL) model of LV satisfying the formula
Φ(G).
Property 4.4 (FOL and SG models). Let V be an SG vocabulary, and G and H be
two SGs over V.
1. Let M = (D,δ) be a FOL model of LV. M is a FOL model satisfying Φ(V)if and
only if M is an SG model of V.
2. (D,δ,α) is an SG model satisfying G if and only if (D,δ) is a FOL model satis-
fying Φ(G)∧Φ(V).
3. H |=sg G if and only if Φ(V),Φ(H) |= Φ(G).
Proof. 1. It is immediate to check that an SG model of a vocabulary V (see Deﬁni-
tion 4.1) is a FOL model of LV (cf. Deﬁnition A.23).

92
4 Formal Semantics of SGs
Let M = (D,δ) be a FOL model of LV satisfying Φ(V). If p,q ∈T ∪TR with
p ≤q and δ(p) ⊈δ(q), then the formula ∀x(p(x) →q(x)), which is in Φ(V),
is false (consider an element d ∈δ(p)∖δ(q)). M = (D,δ) is thus an SG model
of V. Conversely, if M = (D,δ) is an SG model of V, then ∀p,q ∈T ∪TR with
p ≤q one has δ(p) ⊆δ(q), and M = (D,δ) satisﬁes Φ(V).
2. If (D,δ,α) is an SG model satisfying G, then (D,δ) is a FOL model of LV and
is a FOL model satisfying Φ(V). Furthermore, the properties of α show that
values in D can be assigned to the existentially quantiﬁed variables of Φ(G) in
such a way that Φ(G) is true. Reciprocally, let us consider a FOL model (D,δ)
satisfying Φ(G) ∧Φ(V). Then, as (D,δ) is a FOL model satisfying Φ(V) it is
a model of V. The assignment α is built as follows: if c is a concept coreferent
to an individual concept with marker i, then α(c) = δ(i); if c is generic, α(c) is
equal to the element of D that can be assigned to the variable associated with c
in the FOL model.
3. The previous result leads to “H |=sg G iff any FOL model satisfying Φ(H) ∧
Φ(V) is a FOL model satisfying Φ(G)”.
⊓⊔
Theorem 4.1 and the previous property gives the following theorem:
Theorem 4.3 (Soundness and completeness of homomorphism with respect to
Φ). Let G and H be two SGs over a vocabulary V with H normal. There is a homo-
morphism from G to H iff Φ(V),Φ(H) |= Φ(G).
4.3 Positive, Conjunctive, and Existential Fragment of FOL
Let L be a FOL language composed of a partially ordered set P of predicate symbols
of arity ≥1 and a set of constants C. Two comparable predicates must have the same
arity. A(L) denotes the set of atoms built over L, and FOL(∧, ∃, L) denotes the ex-
istential conjunctive and positive fragment of FOL over L. Let f be a wff in FOL(∧,
∃, L), atoms(f) (resp. terms(f), vars(f), consts(f)) denotes the set of atoms (resp.
terms, variables, constants) of f. For any f, terms(f) = vars(f) ∪consts(f). Any
f in FOL(∧, ∃, L) is equivalent to the existential closure of the conjunction of
atoms(f). Hereafter, we assume that any wff in FOL(∧, ∃, L) respects this form,
i.e., is in prenex form.
An L-substitution from a subset of A(L) to another one is deﬁned in Sect. 4.3.1.
Then, the L-substitution lemma states that L-substitution is, in a way that will be
speciﬁed, equivalent to logical entailment. Remark that an ordered FOL language
LV can be canonically associated with an SG vocabulary V, in such a way that if G
is an SG built over V then Φ(G) is a wff in FOL(∧, ∃, LV).
The L-substitution lemma is used in Sect. 4.3.2 to give another proof of the
soundness and completeness theorem 4.3. More generally, the L-substitution lemma
can be used to study different FOL semantics of different conceptual graph sorts. We
claimed in the introduction that SGs are “equivalent” to the positive, conjunctive and

4.3 Positive, Conjunctive, and Existential Fragment of FOL
93
existential fragment of FOL without functions. The precise meaning of that claim
is explained in Sect. 4.3.3. Finally, in Sect. 4.3.4 a FOL semantic representing the
whole structure of an SG is presented.
4.3.1 Ordered Language and L-Substitution
Deﬁnition 4.8 (L-substitution). Let g and h be two wffs in FOL(∧, ∃, L), with
vars(g)∩vars(h) = ∅. A L-substitution from g to h is a substitution σ such as: for
any p(⃗e) in atoms(g), there is an atom q(σ(⃗e)) in atoms(h) with q ≤p.
Let Φ(L) be the set of formulas which are the universal closures of q(⃗e) →p(⃗e),
where⃗e is a list of distinct variables, for all q ≤p in L. Let us give some deﬁnitions
about FOL models adapted for FOL(∧, ∃, L) over an ordered language.
Deﬁnition 4.9 (L-Models). Let (D,δ) be a (FOL) model of L.
• An assignment is a mapping α from variables and constants to D such that for
any constant a, α(a) = δ(a).
• A model (D,δ) satisﬁes a wff f if there is an assignment α such that for any
p(⃗e) ∈atoms(f), α(⃗e) is in δ(p).
• A L-model is a model (D,δ) of L respecting the partial order, i.e., if ⃗d ∈δ(q)
and q ≤p then ⃗d ∈δ(p).
One has:
Property 4.5. (D,δ) is a L-model of L if and only if (D,δ) |= Φ(L).
The relationships between L-substitution and logical entailment is stated as fol-
lows:
Lemma 4.3 (L-substitution lemma). Let g and h be two wffs in FOL(∧, ∃, L), with
vars(g)∩vars(h) = ∅. There is an L-substitution from g to h iff Φ(L),h |= g.
Proof. Let σ be a L-substitution from g to h. Let us consider a model (D,δ) satis-
fying h and Φ(L). For any p(⃗e) ∈atoms(g), there is an atom q(σ(⃗e)) ∈atoms(h)
with q ≤p. As (D,δ) satisﬁes h, there is an assignment α, such that for any constant
a, α ◦σ(a) = α(a) = δ(a), and for any atom q(⃗d) ∈atoms(h), α(⃗d) is in δ(q), thus
α(σ(⃗e)) is in δ(q). As (D,δ) also satisﬁes Φ(L), (D,δ) is an L-model, therefore
α(σ(⃗e)) is in δ(p). Thus α ◦σ is a mapping from terms(g) to D such that for any
atom p(⃗e) ∈atoms(g), α ◦σ(⃗e) is in δ(p), therefore (D,δ) is a model of g. Con-
versely, let us assume that Φ(L),h |= g, any model (D,δ) satisfying h and Φ(L), is
an L-model, and it also satisﬁes g. Let us take D = terms(h)∪{constants}, δ(a) = a
for any constant a, and for any predicate p, δ(p) = {⃗e | there is q(⃗e) ∈atoms(h) and
q ≤p}. There is an assignment α such that for any constant a α(a) = δ(a) = a, and
for any p(⃗e) ∈atoms(g), α(⃗e) is in δ(p). By deﬁnition of δ, as α(⃗e) ∈δ(p), there
is q ≤p with q(α(⃗e)) ∈atoms(h), and α is a L-substitution from g to h.
⊓⊔

94
4 Formal Semantics of SGs
One can also simply prove the L-substitution lemma by using the SLD resolution.
Indeed, the clausal forms of h,Φ(L), are composed of Horn clauses, and ¬g is a
negative Horn clause.
4.3.2 Soundness and Completeness Revisited
In this section we do not use the set semantic for studying the logical semantic Φ
as in Sect. 4.2.1, but we directly deal with FOL. More precisely, the L-substitution
lemma shows that the existence of an L-substitution from a formula A to a formula
B is equivalent to the logical entailment from B and the formulas representing the
order over L to A. In order to state a soundness and completeness theorem (of homo-
morphism with respect to logical entailment) we establish relationships between the
existence of a homomorphism from G to H and the existence of an L-substitution
from Φ(G) to Φ(H). Such a technique can be used for any sort of conceptual graphs
equipped with a semantic in FOL(∧, ∃) (e.g., it is used in Chap. 9).
Property 4.6. Let G and H be two SGs deﬁned on V and L the ordered FOL lan-
guage associated with V. If there is a homomorphism from G to H, then there is an
L-substitution from Φ(G) to Φ(H).
Proof. Let π be a homomorphism from G to H, and let g = Φ(G) and h = Φ(H),
with vars(g) ∩vars(h) = ∅. From π, we build a mapping σ from terms(g) to
terms(h) in the following way: for any term e in terms(g), let c be any concept
such that e = term(c), then σ(e) = term(π(c)). Note that σ(e) is uniquely deﬁned
whatever the chosen c is. Indeed, if term(c) = a then the image of c is an individ-
ual concept with marker a, and if c and c′ are two coreferent concept nodes in G
then the same term is associated with their images in H. Let us show that σ is an
L-substitution from Φ(G) to Φ(H).
Let A = t(term(c)) be the atom in g associated with the concept c of G. Let
c′ = π(c) and t′ be the type of c′. t′(term(c′)) = t′(σ(c)) is an atom in h, and
by deﬁnition of homomorphism t′ ≤t. Let A = t(term(c1),...,term(ck)) be the
atom in g associated with the relation r in G. t′(term(c′
1),...,term(c′
k)) is an
atom in h, where for all i, 1 ≤i ≤k, c′
i = π(ci), and t′ is the type of π(r).
t′(term(c′
1),...,term(c′
k)) = t′(σ(c1),...,σ(ck)) and t′ ≤t.
⊓⊔
The converse property is not true in general: If there is an L-substitution from
Φ(G) to Φ(H) there is not necessarily a homomorphism from G to H in the case
where H is not normal. The reason has been previously seen: The mapping Φ does
not translate the whole structure of a BG. If several concepts c1 and c2 have the
same individual marker m, i.e., if a BG is not normal, a relational atom r(...,m,...)
of its logical translation does not keep the information about which concept m comes
from.
Example. Let G and H be the graphs Fig. 4.3.
g = Φ(G) = t(m)∧r(m)∧s(m) and h = Φ(H) = t(m)∧t(m)∧r(m)∧s(m). The
identity mapping is an L-substitution from g to h (since atoms(g) = atoms(h) and

4.3 Positive, Conjunctive, and Existential Fragment of FOL
95
terms(g) = terms(h)) but there is no homomorphism from G to H: A homomor-
phism is a mapping from the set of nodes of G to the set of nodes H; therefore the
individual concept of G cannot be mapped onto the two different individual concepts
of H.
G
t : m
r
s
H
t : m
t : m
r
s
Fig. 4.3 Normality and L-substitution
Property 4.7. Let G and H be two SGs, with H being normal. If ρ is an L-
substitution from Φ(G) to Φ(H), then there is a homomorphism π from G to H.
Moreover, for any concept node c in G associated with the term u in Φ(G), π(c) is
the concept node in H associated with the term ρ(u) in Φ(H).
Proof. Let ρ be an L-substitution from Φ(G) to Φ(H). From ρ we build a mapping
π from G to H. First, let us consider the terms of Φ(G). Since H is normal, there
is a bijection from the concept set of H to the terms of Φ(H). All concepts of G
associated with a speciﬁc term t of Φ(G) have for image by π the unique concept
of H that is associated with ρ(t). The property of ρ about the atoms correspond-
ing to the concept types ensures that π satisﬁes the homomorphism property for
the concepts. Let us now consider the atoms associated with the relations of G. If
r′(ρ(t1),...,ρ(tk)) is the atom associated with r(t1,...,tk) by ρ, then all (duplicate)
relations in G with atom r(t1,...,tk) have for image by π any relation of H with
atom r′(ρ(t1),...,ρ(tk)). Then, π is a homomorphism from G to H.
⊓⊔
The following theorem gathers Property 4.6 and Property 4.7.
Theorem 4.4 (Homomorphism and L-substitution). Let G and H be two SGs de-
ﬁned on V and L the ordered FOL language associated with V. If there is a ho-
momorphism from G to H, then there is an L-substitution from Φ(G) to Φ(H). If
H is normal and if there is an L-substitution from Φ(G) to Φ(H), then there is a
homomorphism from G to H.
The soundness and completeness theorem can now be obtained as a corollary of
the previous theorem and of the L-substitution lemma.
4.3.3 Relationships Between SGs and FOL(∧, ∃)
The precise meaning of the “equivalence” between SGs and FOL(∧, ∃) is now given.

96
4 Formal Semantics of SGs
Let L be a (classical) FOL language, i.e., unordered, without functions and 0-ary
predicates. First, we show that the set of formulas in FOL(∧, ∃, L) can be translated
into the set SG(VL) of SGs over a vocabulary VL, in such a way that deduction is
translated into homomorphism. Then, we show that the set of SGs over a vocabulary
V can be translated into the set of formulas in FOL(∧, ∃, Lflat(L)), in such a way
that homomorphism is translated into deduction.
4.3.3.1 From FOL Formulas to SGs
In order to associate SGs with FOL formulas, the ﬁrst step is to associate an SG vo-
cabulary with a FOL language. Let L be a FOL language (P,C), where P is the set of
predicates and C is the set of individual constants. VL is the vocabulary ({⊤},P,C),
i.e., the vocabulary with a unique concept type ⊤, with the relation type set being
equal to the predicate set of L and the order on P being the discrete order, and with
the individual marker set being equal to the individual constant set of L. Now, f2G
is the mapping from FOL(∧, ∃, L) to the set SG(VL), deﬁned as follows: Any for-
mula f is mapped onto an SG G whose concept node set is in bijection with the
set of terms occurring in f (one node [⊤:
∗] for each variable and one node
[⊤:
a] for each constant a), and whose relation node set is in bijection with the
set of atoms of f (for each atom p(e1, ..., ek) one node (p) whose i-th neighbor
is the node assigned to ei). Figure 4.4 pictures the graph f2G(f) assigned to the
formula f = ∃x(Car(x)∧Toy(x)∧Boy(Paul)∧possess(Paul,x)).
Boy
:
T
Paul
possess
T
Toy
Car
1
2
Fig. 4.4 The mapping f2G
The following property states that f2G transforms deduction into homomor-
phism.
Property 4.8. Let g and h be two formulas of FOL(∧, ∃, L). The mapping f2G
associates with g and h two (normal) SGs G = f2G(g) and H = f2G(h) over the
vocabulary VL such that h ⊨g if and only if there is a homomorphism from G to H.
Proof. Let g′ = Φ(G) and h′ = Φ(H). Check that h ⊨g if and only if h′ ⊨g′. We
conclude using soundness and completeness of homomorphism (Theorem 4.3), and
noticing that Φ(VL) is empty.
⊓⊔
Note that, for any formula f the SG f2G(f) is a normal SG. Furthermore, f2G is a
bijection. More precisely,

4.3 Positive, Conjunctive, and Existential Fragment of FOL
97
Property 4.9. f2G is a bijection from the set FOL(∧, ∃, L) (to within variable re-
naming) to the set of normal SGs without isolated concept nodes (to within isomor-
phism) on the vocabulary VL.
Proof. Let G be a normal SG without isolated concept nodes on VL, and let Φ′(G)
denote the existential closure of the conjunction of all the atoms associated by Φ
with all relation nodes of G. One can check that f2G ◦Φ′ (and Φ′ ◦f2G) is the
identity mapping on its domain.
⊓⊔
Remark that, if we restrict ourselves to normal SGs over VL, the only difference
between f2G−1 and Φ is that f2G−1 does not associate atoms with concept nodes.
If we associate with VL the logical interpretation Φ(VL) = {∀x ⊤(x)} instead of the
empty set, then for any graph G over this vocabulary, one has Φ(VL), f2G−1(G) ⊨
Φ(G) (and of course Φ(G) ⊨f2G−1(G)).
4.3.3.2 From SGs to FOL Formulas
For translation in the other direction, the apparent problem is that formulas assigned
to the vocabulary by Φ are universally quantiﬁed and are used in the deduction pro-
cess. However, we can do without them, replacing the vocabulary by a vocabulary
with only one concept type, and with the order on relation type set being the dis-
crete order (i.e., it is reduced to the equality). We will deﬁne a mapping G2f, which
is a variant of Φ. It maps an SG to an existential formula integrating the needed
knowledge about the vocabulary.
Deﬁnition 4.10 (Flat vocabulary, flat(V) and flat(G)). An SG vocabulary is ﬂat
if its concept type set is reduced to {⊤} and the order on its relation type set is the
discrete order.
• Let V = (TC,TR,I) be an SG vocabulary. flat(V) is the ﬂat vocabulary obtained
from V as follows: The new relation type set is the union of TR and TC \{⊤}, with
the concept types becoming unary relation types ordered by the discrete order;
the new concept type set has a single element ⊤; I is unchanged.
• Let G be an SG on V. flat(G) is the SG over flat(V) obtained from G as follows:
For each concept node c of G of type tc, the new type of c is ⊤, and for each
primitive concept type greater or equal to tc and distinct from ⊤, one adds a
relation node with type tc and neighbor c; for each relation node r of type tr in
G, for each relation type tr′ in V strictly greater than tr, a relation node of type tr′
with the same neighbors as r is added.
It is simple to check that, given two SGs G and H on V, there is a homomorphism
from G to H if and only if there is a homomorphism from flat(G) to flat(H), both
relative to flat(V).
Example. Let V = (TC,TR,I), with: TC = {⊤,Person,Boy,Object,Car,FireTruck}
and Person, Object < ⊤, Boy < Person, Car < Object, FireTruck < Car; TR =
{⊤2, possess}, with possess < ⊤2; I = {Paul}. flat(V) = ({⊤},T ′
R,I) with T ′
R =

98
4 Formal Semantics of SGs
{Person, Boy,Object,Car,FireTruck,⊤2, possess}. Figure 4.5 illustrates the trans-
lation of a graph on V to a graph on flat(V).
Object
Car
FireTruck
T2
Person
Boy
possess
possess
: Paul
T
T
2
1
2
1
2
1
FireTruck
Boy : Paul
G
flat(G)
Fig. 4.5 Flattening an SG
Now, let us deﬁne G2f(G) = Φ(flat(G)). For instance, the formula assigned to
the graph G in Fig. 4.5 is :
∃x(⊤(x)∧FireTruck(x)∧Car(x)∧Object(x)∧⊤(Paul)∧Person(Paul)∧Boy(Paul)
∧possess(Paul,x)∧⊤2(Paul,x)).
G2f transforms homomorphism into deduction.
Property 4.10. Let G and H be two normal SGs on V. The mapping G2f associates
with G and H two formulas of FOL(∧,∃,Lflat(V)), g = G2f(G) and h = G2f(H),
such that there is a homomorphism from G to H if and only if h ⊨g.
Proof. One has g = G2f(G) = Φ(flat(G)) and h = G2f(H) = Φ(flat(H)). Us-
ing soundness and completeness of homomorphism, h ⊨g if and only if flat(G) ⪰
flat(H), since Φ(Lflat(V)) = ∅and flat(G) and flat(H) are normal graphs. It re-
mains to check that flat(G) ⪰flat(H) iff G ⪰H.
⊓⊔
If G and H are two non-isomorphic normal SGs, then flat(G) and flat(H) are
also non-isomorphic, and the two associated formulas are different, thus:
Property 4.11. G2f is an injective application from the set of normal SGs (to within
isomorphism) deﬁned on V to the set FOL(∧,∃,Lflat(V)) (to within variable renam-
ing).
4.3.4 Another FOL Semantic: Ψ
When the FOL semantic Φ is considered, the normality condition for SG homomor-
phism occurs because Φ(G) exactly represents G only when G is normal. Another

4.3 Positive, Conjunctive, and Existential Fragment of FOL
99
FOL semantic, denoted Ψ, can be considered which represents the whole structure
of an SG. In this semantic, two terms are associated with a concept node c. The ﬁrst
term, ¯c represents the coreference class of c as in Φ; it is a constant if c is coreferent
to an individual concept, otherwise it is a variable. The second term, xc, is a variable
representing the node itself. All these variables are pairwise distinct.
If V is a vocabulary, Ψ(V) is deﬁned as Φ(V), except that predicates associated
with concept types become binary. If G is an SG,Ψ(G) is built as follows. Assign the
atom t(¯c,xc) to each concept node c with type t, and assign the atom r(xc1,...,xck)
to each relation node having r for relation type and c1...ck for neighbor list. Ψ(G) is
the existential closure of the conjunction of these atoms.
Example. The formula Ψ(G) associated with the graph G in Fig. 4.2 is obtained as
follows:
The variables corresponding to the ﬁve concept nodes a,b,c,d,e are x1,x2,x3,x4,x5,
respectively. The variables corresponding to the two generic concept nodes b,d are
y1,y2, respectively. The atoms associated with the concepts are:
Boy(Paul,x1), Toy(y1,x2), Firetruck(y1,x2), Size(Small,x3), Child(y2,x4), Person
(Mary,x5).
The atoms associated with the relations are:
possess(x1,x2), attr(x2,x3), daughterOf(x4,x5), hold(x4,x2), play3(x1,x4,x2).
Ψ(G) is the existential closure of the conjunction of the atoms associated with the
concepts and of the atoms associated with the relations.
Now, if an SG is not normal, then it is not logically equivalent to its normal form
anymore. Consider for instance the graphs G and H in Fig. 4.3, G being the nor-
mal form of H. Ψ(G) = ∃x (t(m,x) ∧r(x) ∧s(x)) and Ψ(H) = ∃x1∃x2 (t(m,x1) ∧
t(m,x2)∧r(x1)∧s(x2)). Ψ(H) can be deduced from Ψ(G), but Ψ(G) cannot be de-
duced from Ψ(H), this is in accordance with the fact that there is a homomorphism
from H to G, but not in the opposite direction.
One can show that the homomorphism is sound and complete with respect to the
semantic Ψ without the normality condition.
Theorem 4.5. Let G and H be two SGs on V. There is a homomorphism from G to
H iff Ψ(V),Ψ(H) |=Ψ(G).
Ψ has an interesting behavior with respect to homomorphism, but it is not very
interesting from a modeling viewpoint. Indeed, it is unusual to consider binary pred-
icates to represent types of entities. An atom such that Boy(Paul,x1) means that x1
is a node representing the entity Paul of type Boy. Two sorts of variables must be
considered, one sort for the concepts and one sort for the nodes. Consequence of
this is that the models withΨ are less intuitive than the models with Φ, and usingΨ
instead of Φ increases the distance from a formal expression to a sentence in natural
language.

100
4 Formal Semantics of SGs
4.4 Note on the Relationships Between Description Logics
and Conceptual Graphs
Description Logics (DLs) and Conceptual Graphs are both rooted in frames and
semantic networks. They both remedy two critiques on their ancestors, i.e., the lack
of distinction between factual and ontological knowledge, and the lack of precise
formal semantics. Indeed, in conceptual graphs, there is a clear distinction between
the vocabulary (or support), which represents basic ontological knowledge, and sets
of graphs, which basically represent facts. In description logics, a knowledge base
is split into a so-called terminological component, the TBox, which can be seen as
the ontological part of the KB, and an assertional component, i.e., the ABox, which
contains assertions about individuals. Both formalisms are provided with set and
ﬁrst-order logical semantics. Due to these common properties, their relationships
have often been questioned.
Let us ﬁrst outline the main characteristics of description logics (for an in-depth
presentation of this family of formalisms, see [BCM+03]). DLs represent knowl-
edge in terms of concepts, which denote sets of objects, and roles, which denote
binary relations between concept instances. Starting from atomic concepts (which
can be seen as CG concept types) and atomic roles (which can be seen as binary
CG relation types) and using a set of constructors, complex concepts and roles can
be built. The semantics of the concepts and roles is set-theoretic, which gives a di-
rect translation to FOL. We focus here on the logical translation in order to enhance
relationships with conceptual graphs. A concept is translated into a unary predicate
and a role into a binary predicate.
Let us consider for instance the description logic AL, which is often considered
as the minimal description logic with a practical interest. In this DL, concepts can be
built with the following elements. Among the atomic concepts, there are two special
elements, ⊤and ⊥. The construction rules are (where A is an atomic concept, C and
D are concepts and R is a role): ¬A (atomic negation), C ⊓D (concept intersection),
∀R.C (value restriction) and ∃R.⊤(limited existential quantiﬁcation). ⊤and ⊥are
logically translated into valid and unsatisﬁable formulas, respectively. Any other
concept C can be translated into a logical formula fC(x) with one free variable x as
follows:
fA(x) = A(x) and f¬A(x) = ¬A(x);
fC⊓D(x) = fC(x)∧fD(x);
f∀R.C(x) = ∀y(R(x,y) →fC(y));
f∃R.⊤(x) = ∃yR(x,y).
More expressive DLs are obtained by adding other constructors, e.g., full exis-
tential quantiﬁcation ∃R.C, which is translated as follows:
f∃R.C(x) = ∃yR(x,y)∧fC(y).
For instance, let Man, Course and CSCourse be atomic concepts representing
all men, all courses and all computer science courses, respectively, and let teaches
be an atomic role representing the relationship between a teacher and a course that

4.4 Note on the Relationships Between Description Logics and Conceptual Graphs
101
he/she gives; the following concept represents “men who teach at least one course
and teach only computer science courses”:
Man⊓∃teaches.Course⊓∀teaches.CSCourse
Its logical translation can be:
Man(x)∧∃y(teaches(x,y)∧Course(y))∧∀y(teaches(x,y) →CSCourse(y)).
A DL knowledge base is composed of a TBox T , which is a ﬁnite set of dec-
larations about concepts and roles, and an ABox A, which is a ﬁnite set of asser-
tions about individuals. The declarations allowed in the TBox are inclusions of form
C ⊑D or equalities of form C = D. An inclusion C ⊑D can be logically translated
into an implication: ∀x(fC(x) →fD(x)). An equality C = D is logically translated
into an equivalence: ∀x(fC(x) ↔fD(x)). If, in C = D, C is an atomic concept, this
equality is called a concept deﬁnition: C can be seen as a name for the concept D.
For instance, the following equality deﬁnes the concept CSProfessor:
CSProfessor = ∃teaches.Course⊓∀teaches.CSCourse.
Its logical translation is ∀x(CSProfessor(x) ↔(∃y(teaches(x,y)∧Course(y))∧
∀y(teaches(x,y) →CSCourse(y)))).
The basic inference problem related to the TBox is the subsumption problem:
Given a TBox T and two concepts C and D, is C subsumed by D (which is generally
noted C ⊑D), i.e., can D be considered as more general than C with respect to T ?
In logical terms, if f(T ) denotes the set of formulas translating T and fC(x) and
fD(x) denote formulas assigned to C and D, C is subsumed by D if and only if
f(T ) ⊨∀x(fC(x) →fD(x)).
The ABox is composed of assertions of form C(a) or R(a,b), where C is a con-
cept and R is a role. a and b are logically interpreted as constants. The basic infer-
ence problem in an ABox is the instance checking problem, which asks whether a
given individual a is an instance of a given concept C with respect to A and T . In
logical terms, let f(A) be the conjunction of all assertions in the A-box, then one
asks if f(T ), f(A) ⊨C(a).
CSCourse
teaches
Student
hasChild
enrolled
Date
Man:*x
T(x) =
2
3
1
1
2
1
2
Fig. 4.6 A CG concept type deﬁnition
In CGs, similarly to DLs, a concept (or a relation) type can be deﬁned in terms
of existing ones. It is not deﬁned via constructors, but rather by a BG, with a distin-
guished node (or k distinguished nodes for a k-ary relation), called a (k-ary) λ-BG
(see Sect. 10.1 for precise deﬁnitions related to λ-BGs). For instance, consider the
deﬁnition T = (x)G, where (x)G is the graph of Fig. 4.6. This graph represents a con-
cept type describing all men who teach a computer-science course and have a child
who is enrolled in this course (with the distinguished concept node being marked

102
4 Formal Semantics of SGs
∗x). The formula associated to a λ-BG has as many free variables as distinguished
nodes. For the λ-BG in Fig. 4.6, one has:
Φ((x)G) = ∃y∃z∃t(Man(x)∧CSCourse(y)∧Student(z)∧Date(t)∧teaches(x,y)
∧hasChild(x,z)∧enrolled(z,y,t))
The formula assigned to the deﬁnition of a concept type T is ∀x(T(x) ↔
Φ((x)G)) (and relation type deﬁnitions are similarly translated into a logical equiv-
alence). Although type deﬁnitions were introduced as early as 1984 in Sowa’s book,
their processing received little attention. See Sect. 8.5 for a brief presentation of type
deﬁnitions, and the bibliographic notes in Chap. 8 for further references. Note also
that a type deﬁnition can be seen as a pair of conceptual graph λ-rules, as deﬁned
in Chap. 10.
Since type deﬁnitions rely on BGs (or more precisely λ-BGs), as all kinds of
knowledge, the BG model can be considered as a core for the comparison of CGs
and DLs.
Provided that relations are restricted to binary relations, a BG vocabulary, com-
posed of partially ordered sets of concept types and relation types, can be seen as a
set of inclusions between atomic concepts and atomic roles. It can thus be seen as a
very basic TBox. On the other hand, the ABox of description logics can be seen as
a particular BG without generic concept nodes. If we try to ﬁnd the “intersection”
between DL deﬁnitions and CG deﬁnitions, we have to considerably restrict the ex-
pressiveness of each formalism. For instance, the CG deﬁnition of Fig. 4.6 cannot be
expressed in DL, because of the ternary relation (which cannot be translated directly
into a role), but more fundamentally because it is not possible to translate the cycle,
which says that the CSCourse taught by x and the CSCourse in which his child is
enrolled are the same entity. On the other hand, the DL deﬁnition of a CSProfes-
sor given above cannot be expressed by a CG deﬁnition due to the value restriction
constructor.
A notable work concerning the relationships of CGs and DLs is [BMT99] (which
extends the ﬁrst results of [CF98]). With the aim of characterizing the intersection
of CGs and DLs, the authors identiﬁed two equivalent fragments. On the CG side,
we have rooted BG trees, which are connected graphs with a tree-like structure, with
binary relations only and with one distinguished concept node (like in a unary λ-
BG)1. On the DL side, we have a DL specially tailored for the comparison, called
ELIRO1. The constructors of ELIRO1 are ∃R.C (existential restriction), C ⊓D
(concept intersection), R−(the inverse of the R role), R⊓R′ (role intersection, where
R and R′ are roles) and {i} (unary one-of, where i is an individual). The unary one-of
constructor allows us to integrate speciﬁc individuals in a concept (it corresponds to
the possibility of creating an individual concept node). The precise result is that, if
concepts contain at most one unary one-of constructor in each concept intersection
(which is in accordance with the unique name assumption), then the corresponding
1 By BGs with a tree-like structure, we mean connected BGs that can be transformed into logically
equivalent acyclic multigraphs by splitting individual concept nodes. These graphs are exactly
those without cycles with more than two distinct concept nodes and passing through generic nodes
only (see Sect. 7.2); cycles induced by relations with the same argument lists can be accepted since
they would disappear if conjunctive relation types were considered.

4.4 Note on the Relationships Between Description Logics and Conceptual Graphs
103
syntactic tree can be translated into a rooted BG tree with conjunctive concept types.
Conversely, every rooted BG tree with only binary relation types can be translated
into an ELIRO1 concept. This correspondence result allowed us to transfer the
tractability result for BG-HOMOMORPHISM for BGs that are trees ([MC92], see also
Chap. 7) to ELIRO1, and computation of subsumption by graph homomorphism
was adapted to ELIRO1 and other description logics to solve other inference prob-
lems, namely matching and computing least common subsumers [BK99] [BKM99].
On the other hand, [BMT99] pointed out that tractability can be extended to BGs
that are not trees but are logically equivalent to acyclic multigraphs (see above);
let us point out however that these BGs can be seen as particular cases of acyclic
hypergraphs or, equivalently, of guarded BGs, for which the tractability of homo-
morphism checking still holds (see Chap. 7).
The preceding correspondence shows that, despite their apparent proximity, DLs
and CGs are “orthogonal” formalisms, in the sense that their intersection yields
poor fragments of each of them, in which each formalism loses its interesting fea-
tures: unrestricted cycles of variables and n-ary relations for CGs, and the vari-
ety of constructors for DLs. Other results support this claim. On one hand, it is
known that even the most expressive DLs cannot express the whole FOL(∧, ∃)
fragment [Bor96]. On the other hand, BG homomorphism cannot handle negation
in a logically complete way, even restricted to atomic negation on primitive types
(see Sect. 12.2), thus one cannot add restricted forms of negation “for free” to the
BG model. Let us put forward another argument. One reference DL is ALC which
is a fairly general DL in which subsumption remains decidable. It has been pointed
out that ALC can be translated into L2, the fragment of FOL, which consists of
all formulas without functions, but with equality, that can be constructed using two
variables only [Bor96]. A result of Kolaitis and Vardi implies that acyclic BGs coin-
cide in expressive power with L2 [KV00]. Thus, the “intersection” of BGs and DLs
is not likely to lead to better results than that cited above.
One could consider more complex kinds of CGs, such as special kinds of rules
or of full CGs, with the hope of ﬁnding correspondences with some DLs, but once
again one would have to give up the natural features. For instance, the transitive
closure of a relation cannot be expressed in ALC whereas it can be handled with
a very speciﬁc fragment of CG rules (so-called range-restricted rules) for which
deduction is decidable (and even NP-complete).
If we turn our attention to extensions of DLs allowing us to query knowledge
bases, more relationships between DLs and CGs are to be expected. Indeed, the
instance checking problem can only be seen as a very speciﬁc querying problem,
i.e., asking if a given individual can be considered as belonging to a given concept.
Basic queries in databases are conjunctive queries. These queries are also natural
queries in conceptual graphs, since they correspond to basic conceptual graphs (see
Sect. 5.3). However, extending DLs to cope with conjunctive queries generally has
a high computational cost [BCM+03]. The recent DL-Lite approach is interesting
from this standpoint [CGL+05][CGL+07]. The leading idea of this approach is to
restrict the expressivity of the TBox in order to be able to query the Abox with
conjunctive queries, while staying in the same complexity class as the classical

104
4 Formal Semantics of SGs
conjunctive query answering decision problem. Note that the complexity consid-
ered is data complexity, a notion imported from databases: It is measured in the size
of the ABox only, i.e., the size of the query is considered as a constant because it
is assumed to be considerably smaller than the base. Note also that, in these works
on the DL-Lite family, the size of the TBox is also ignored in the data complexity.
If we take, for instance, the BG-HOMOMORPHISM problem, where the source graph
is a query Q and the target graph is a fact base F, then this problem is NP-complete
in usual complexity, and polynomial in data complexity, since a brute-force algo-
rithm is in O(size(F)size(Q)). The same holds for the classical conjunctive query
answering decision problem. The approach developed throughout this book can be
seen as motivated by similar objectives as the DL-Lite approach, but starting with
a rich assertional component instead of a rich ontological component: The BG/SG
fragment can be seen as allowing a rich assertional base, provided with a query
mechanism equivalent to conjunctive queries, but with a rudimentary ontological
part. We have been trying to extend it by adding constructors, which can be seen as
DL constructors, even when they have not been introduced in reference to DLs (e.g.,
type conjunction, disjointness of types, atomic negation) as well as other kinds of
knowledge (e.g., complex constraints or rules), while keeping their essential combi-
natorial properties.
4.5 Bibliographic Notes
The previous presentation of the model semantic for SGs is mainly issued from
Kerdil`es [Ker01]. Independently from Kerdil`es, the same ideas were developed
in [Bag01]. From an historical viewpoint, the denotation operator introduced by
Sowa [Sow84] can be considered as the ﬁrst step towards the deﬁnition of a model
semantic for SGs, and a deﬁnition of the model semantic was given in [MC96].
The FOL semantic Φ was deﬁned in [Sow84] and the soundness of BG ho-
momorphism with respect to logical deduction was shown. The ﬁrst proof of the
completeness result, based on the resolution method, is in [Mug92] (published
in [CM92]). Preller pointed out that this ﬁrst proof was not correct for all graphs
and her counter-example led us to deﬁne the notion of a normal graph ([CM95]
or [MC96]. This notion was independently deﬁned by Ghosh and Wuwongse, who
provided another proof of completeness [GW95]. Since then, several other proofs
have been provided. In particular, Simonet reformulated the ﬁrst proof in the context
of the Ψ semantic ([Sim98] or [CMS98]).
Concerning Φ, Wermelinger proposed in [Wer95a] another way of interpreting
the universal type. If a concept node c is of type ⊤, the associated atom is not ⊤(idc)
but (idc = idc), i.e., an atom true for all interpretations. Then, for any graph G,
f2G(G) is equivalent to Φ(G) (actually the formulas are equal up to the suppression
of all atoms (idc = idc)). Section 4.3.3 can be considered as stating, for a speciﬁc
case, the relationships between FOL and ordered FOL (cf. [Gal85]).

Chapter 5
BG Homomorphism and Equivalent Notions
Overview
Homomorphism is a key notion for studying algebraic or relational structures,
and many combinatorial problems can be reduced to homomorphism problems. In
this chapter, it is shown that computing BG homomorphisms between two BGs is
“strongly equivalent” to important combinatorial problems in graph theory, algebra,
database theory, and constraint satisfaction networks. In Sect. 5.1, basic concep-
tual hypergraphs (BHs) are introduced, with a BH homomorphism notion, while
highlighting relationships between BG homomorphisms and BH homomorphisms.
The two notions are so close that they can be simply considered as two different
views of the same abstract notion. It is also shown in this section that comput-
ing homomorphims for BGs on any vocabulary is equivalent to computing homo-
morphisms for BGs on speciﬁc vocabularies. BGs are kinds of graphs, thus rela-
tionships between graph homomorphisms and BG homomorphisms are studied in
Sect. 5.2. Section 5.3 concerns relational structures and relational databases. It is
especially shown that two fundamental problems dealing with conjunctive, positive
and non-recursive queries–the query evaluation problem and the query containment
problem–are equivalent to the BG homomorphism problem. Section 5.4 is devoted
to the Constraint Satisfaction Problem (CSP), which is the basic problem in the con-
straint processing domain, and its equivalence to the BG homomorphism problem
is stated. This equivalence, that borrows a lot from techniques developed in the CSP
framework, will be used in Chap. 6.
Equivalent Problems
Before getting into the heart of the matter, basic notions about “equivalent prob-
lems” are brieﬂy reviewed. A decision problem is composed of a set of instances
and of a yes/no question about these instances. A yes-instance is an instance whose
answer to the question is yes, and a no-instance is an instance whose answer to the
question is no. For example, the decision problem concerning BG homomorphism
105

106
5 BG Homomorphism and Equivalent Notions
is:
BG-HOMOMORPHISM
instance: two BGs G and H on the same vocabulary
question: Is there a BG homomorphism from G to H?
If there is a BG homomorphism from G to H, then (G,H) is a yes-instance, and
any BG homomorphism from G to H is a solution. A yes-instance of a decision
problem can have several solutions.
Polynomial reducibility is a fundamental notion in algorithmic complexity. There
are different sorts of polynomial reducibility. The common idea is that, if a compu-
tational problem P1 is polynomially reducible to a problem P2, then any algorithm
for solving P2 can be “simply” transformed into an algorithm for solving P1. There-
fore P1 can be considered as being no more difﬁcult than P2. Karp reducibility is
considered hereafter.
Deﬁnition 5.1 (Reducibility and equivalence of problems).
• A decision problem P1 is polynomially reducible to a decision problem P2 if there
is a transformation τ from the instance set of P1 to the instance set of P2 such that
I1 is a yes-instance of P1 if and only if τ(I1) is a yes-instance of P2 and the
transformation τ is computable in a polynomial time (in the size of an instance
of P1). Such a transformation τ is called a polynomial reduction from P1 to P2.
• Two decision problems P1 and P2 are polynomially equivalent if each of them is
polynomially reducible to the other.
• A parsimonious reduction τ from P1 to P2 is a polynomial reduction from P1 to
P2 such that the number of solutions of any yes-instance I1 of P1 is equal to the
number of solutions of τ(I1).
• Two decision problems P1 and P2 are parsimoniously equivalent if each of them
is parsimoniously reducible to the other.
Thus, if two problems are equivalent, algorithms for solving one problem can be
polynomially transferred to the other one. Furthermore, if there is a parsimonious
reduction, then the (number of) solutions are preserved. Figure 5.1 summarizes the
reductions that are stated in this chapter. The rectangles contain the problem names.
As they all but one, i.e., CSP, deal with homomorphism, the word “homomorphism”
is omitted. A rectangle is labeled by a letter representing the problem (e.g., the rect-
angle corresponding to the problem concerning the existence of a homomorphism
between two (ordinary) graphs is labeled g and the rectangle concerning CSP is
labeled c). An arrow from rectangle x to the rectangle y represents a polynomial re-
duction from problem x to problem y (e.g., g2b is the name of a reduction from the
GRAPH-HOMOMORPHISM problem, i.e., the decision problem concerning the exis-
tence of a homomorphism between two ordinary graphs, to BG-HOMOMORPHISM).
A bold arrow represents a parsimonious reduction. A dotted arrow without name
from x to y represents the fact that problem x is a particular case of problem y, so it
also represents a parsimonious reduction. The central rectangle, labeled b, gathers
the homomorphism problem for BGs and BHs on general, ﬂat or very ﬂat vocabu-
laries. For simplicity, b (resp. h) is used for labeling a reduction to or from any of

5.1 Conceptual Graphs and Conceptual Hypergraphs
107
these three BG homomorphism problems (resp. BH homomorphism problems). The
schema can be completed by transitivity. Indeed, the composition of two polynomial
reductions is a polynomial reduction.
structure
Relational
BG
BH
CSP
BH flat vocabulary
BH very flat vocabulary
Graph
BG flat vocabulary
BG very flat vocabulary
Query evaluation
Query containment
 multigraph
Labeled
b2q
q2b
b2q’
q2b’
r2h
h2r
c2h
h2c
lg2g
b2lg
g2b
BG/BH homomorphism
b
g
lg
q
q’
r
c
Fig. 5.1 Summary of reductions between BG-HOMOMORPHISM and equivalent problems
5.1 Conceptual Graphs and Conceptual Hypergraphs
5.1.1 Conceptual Hypergraphs
BGs are bipartite graphs. But they could also be seen as ordered hypergraphs, which
we call conceptual hypergraphs, using the same vocabularies as BGs.
A (undirected) hypergraph is a pair H = (X, E), such that: X is a set and E is a
family of subsets of X, i.e., the same subset of X can appear several times in E. An
element of X is called a vertex of H, and an element of E is called a hyperedge of
H. An ordered hypergraph is a pair H = (X, E), where E is a family of tuples of
elements in X, i.e. totally ordered subsets of X.
A conceptual hypergraph is deﬁned as follows:
Deﬁnition 5.2 (Conceptual Hypergraphs: BHs). A conceptual hypergraph on a
vocabulary V = (TC,TR,I) is a triple H = (X, E,l), where:
• H = (X, E) is an ordered hypergraph,
• a vertex x is labeled by a pair (type(x), marker(x)), where type(x)∈TC and
marker(x)∈I ∪{∗} (a vertex of a BH is also called a concept node of this BH),
• a hyperedge r is labeled by l(r) ∈TR and the cardinality of hyperedge is equal to
the arity of the relation symbols.

108
5 BG Homomorphism and Equivalent Notions
The correspondence between conceptual hypergraphs and BGs is a simple ex-
tension of a well-known correspondence between hypergraphs and bipartite graphs.
Consider a conceptual hypergraph H = (X, E,l), then h2b(H) = (C,R,E,l) is de-
ﬁned as follows: C is in bijection with X, R is in bijection with E, C and R are labeled
by the labeling function of H and, if x in X is the i-argument of e in E, then there is
an edge labeled i between the concept node associated with x and the relation node
associated with e.
The mapping h2b is a bijection from the set of conceptual hypergraphs on a vo-
cabulary V to the set of BGs on V. The inverse mapping of h2b is denoted b2h. Thus,
all notions introduced for BGs, e.g., coreference relation, can also be introduced for
conceptual hypergraphs. Let us now consider the homomorphism notion between
conceptual hypergraphs.
Deﬁnition 5.3 (Conceptual Hypergraph Homomorphism).
A BH homomor-
phism from the conceptual hypergraph H = (X, E,l) to the conceptual hypergraph
H′ = (X′, E′,l′) is a mapping π from X to X′, such that:
• for any vertex x in H, its label is greater than or equal to the label of π(x), i.e.,
l(x) ≥l′(π(x)),
• for any hyperedge y = (a1,...,ak) in E, there is a hyperedge (π(a1),...,π(ak))
in E′, denoted π(y), such that l(y) ≥l′(π(y)).
It is simple to check that h2b is a polynomial reduction from the decision problem
concerning the existence of a homomorphism between conceptual hypergraphs to
the decision problem BG-HOMOMORPHISM. But this reduction is not parsimonious.
Indeed, there might be exponentially fewer homomorphisms between conceptual
hypergraphs than homomorphisms between the corresponding BGs.
Example. For instance, consider a vocabulary with binary relation symbols r,r1, ,rk,
where r is greater than r1,...,rk, which are pairwise incomparable. Consider the
BGs G and H in Fig. 5.2. H is obtained from G by replacing the relation (r) with k
relations (r1)...(rk) having the same neighbors as (r). There are k homomorphims
from G to H, but all of these homomorphisms are the same on concept nodes, thus
there is only one homomorphism from b2h(G) to b2h(H).
H
1
2
2
2
1
1
G
...
r1
rk
T
T
r
T
T
r ≥r1,...,rk
Fig. 5.2 k BG (and only one BH) homomorphisms from G to H

5.1 Conceptual Graphs and Conceptual Hypergraphs
109
In Fig. 5.3, we consider a BG G′ obtained by repeating m times G and another BG
H′, obtained in the same way by repeating m times H. There are km homomorphisms
from G′ to H′, whereas all homomorphisms are the same on concept nodes, and
there is only one homomorphism from b2h(G′) to b2h(H′). Note that G and H do
not have twin relation nodes, thus redundancy is irrelevant here.
.
..
..
.
H’
G’
1
1
2
2
2
1
2
2
1
2
1
1
1
2
2
2
1
1
...
...
...
rk
r
T
T
T
T
T
r
rk
r1
r1
rk
T
r1
T
T
r
T
T
r ≥r1,...,rk
Fig. 5.3 km BG (and only one BH) homomorphisms from G′ to H′
Nevertheless, even if the reduction is not parsimonious, it is simple to state the
correspondence between the two sets of homomorphisms. The restriction to the node
set of any BG homomorphism from G to H is a BH homomorphism from b2h(G) to
b2h(H). Conversely, let f be a homomorphism from a conceptual hypergraph A to
a conceptual hypergraph B, then it is simple to build all BG homomorphisms from
h2b(A) to h2b(B) having f as a restriction on the concept nodes. Let r be a relation
node of h2b(A) with neighbor list (c1,...,ck). Any relation node r′ in h2b(B), with
neighbor list (f(c1),..., f(ck)) and whose label is less than or equal to the label of
r, can be taken as an image for r.
The two notions of conceptual hypergraphs and of BGs are so similar that we will
often refer to the ﬁrst one as the hypergraph vision of BGs. But when drawings are
considered, graphs are deﬁnitely more appropriate than hypergraphs because read-
able drawings of a hypergraph are generally drawings of its corresponding bipartite
graph. Previous results can be theoretically summarized as follows.

110
5 BG Homomorphism and Equivalent Notions
Theorem 5.1 (Equivalence between BGs and BHs).
• The mapping h2b is a bijection from the set of BHs on V to the set of BGs on V
(b2h denotes the inverse of h2b).
• The restriction to the concept node set of any BG homomorphism from G to H is
a BH homomorphism from b2h(G) to b2h(H).
• Any BH homomorphism f from A to B can be extended to a BG homomorphism
from h2b(A) to h2b(B) having f as restriction on the concept nodes.
•
BG-HOMOMORPHISM and BH-HOMOMORPHISM are polynomially equivalent.
5.1.2 Different Kinds of Vocabularies
The notion of ﬂat vocabulary and the transformation flat, which assigns a ﬂat vo-
cabulary to a vocabulary and transforms a BG on V into a BG on flat(V) while
preserving homomorphisms, have been introduced in Chap. 4. They are reviewed
here and the notion of a very ﬂat vocabulary is introduced.
Deﬁnition 5.4 (Flat and very ﬂat vocabularies). A BG vocabulary V = (TC,TR,I)
is called:
• ﬂat if TC is reduced to {⊤} and the order on TR is the identity (any relation symbol
is only comparable with itself),
• very ﬂat if it is ﬂat and if I is empty.
Let V = (TC,TR,I) be a BG vocabulary, flat(V) = (T ′
C,T ′
R,I) is the flat vocab-
ulary deﬁned as follows:
• T ′
C = {⊤},
• T ′
R = TR ∪(TC \ {⊤}), where the arity of an element of TC considered as a rela-
tion is one, and any two different relation symbols are incomparable (the order
relation on T ′
R is the identity relation),
• the set of individual markers of V and of flat(V) are the same.
Let V = (TC,TR,I) be a vocabulary, vflat(V) = (T ′
C,T ′
R,∅) is the very ﬂat vocabu-
lary deﬁned as follows:
• T ′
C = {⊤},
• T ′
R = TR ∪(TC \{⊤})∪I, where the arity of an element of TC and of an individual
marker considered as a relation symbol is one, and any two different relation
symbols are incomparable (the order relation on T ′
R is the identity relation),
• the set of individual markers of vflat(V) is empty.
Given a BG G on V = (TC,TR,I), flat(G) is the BG on flat(V) obtained from
G as follows: For each concept node x of G of type t, the new type of x is ⊤, and for
each concept type t′ in TC greater than or equal to t and distinct from ⊤, one adds
a unary relation node labeled t′ and linked to x; for each relation node x of type r

5.1 Conceptual Graphs and Conceptual Hypergraphs
111
in G, for each relation type r′ in TR strictly greater than r, a relation node of type r′
with same neighbors as r is added.
Given a BG G on V = (TC,TR,I), vflat(G) is the BG on vflat(V) obtained from
flat(G) as follows: For each individual concept node x with marker i, one adds a
unary relation node labeled by the relation symbol associated with i and linked to x,
and x becomes generic.
Example. An example of the transformations flat and vflat is given in Fig. 5.4.
The transformations flat and vflat are polynomial, and one has:
Property 5.1. The three problems BG-HOMOMORPHISM, BG-HOMOMORPHISM for
BGs on a ﬂat vocabulary and BG-HOMOMORPHISM for BGs on a very ﬂat vocabu-
lary are polynomially equivalent.
Proof. Let us prove the result for vflat. Let G = (CG,RG,EG,lG) and H = (CH,RH,
EH,lH) be two BGs on V and let π be a homomorphism from G to H. Let us deﬁne
a mapping π′ from the node set of vflat(G) to vflat(H) as follows.
1. The concept node set of vflat(G) is equal to the concept node set of G. The
restriction of π′ to the concept node set is deﬁned as identical to π.
2. Let y be a relation node in vflat(G) with the label r ∈TR and having x1,...,xk as
neighbors. There is a relation node z in G having x1,...,xk as neighbors and the
label of z is r′ ≤r. Let u = π(z), i.e., the image of z in H. The label of u is r′′ ≤r′
and the neighbors of u are π(x1),...,π(xk). In vflat(H), there is a relation node
v having π(x1),...,π(xk) for neighbors and with the label r since r′′ ≤r′ ≤r.
One takes π′(y) = v.
Let us now consider the unary relation nodes of vflat(G) corresponding to con-
cept types or individual markers.
3. Let y be a new unary relation node in vflat(G) linked to x and labeled by a
concept type t. t is greater than or equal to the type of x in G. The type of π(x) in
H is less than or equal to the type of x in G, therefore there is also a new unary
relation node y′ in vflat(H) linked to π(x) and labeled by t. One takes π′(y) = y′.
4. Let y be a new unary relation node in vflat(G) linked to x and labeled by an
individual i. π(x) in H is also an individual concept node with marker i and
therefore in vflat(H) there is a new unary relation node y′ labeled i and linked
to π(x). One takes π′(y) = y′.
One can check that π′ is a BG homomorphism from vflat(G) to vflat(H).
Conversely, let π be a BG homomorphism from vflat(G) to vflat(H). A BG
homomorphism π′ from G to H can be deﬁned as follows.
1. For any concept node x in G π′(x) = π(x).
2. Let y be a relation node in G with the label r and having x1,...,xk as neighbors.
There is a relation node z in vflat(G) having x1,...,xk as neighbors and having
the label r. Let u = π(z). The label of u is r and its neighbors are π(x1),...,π(xk).
There is a relation node v in H with a label r′ ≤r and having π(x1),...,π(xk) as
neighbors. One takes π′(y) = v.
One can check that π is a BG homomorphism from G to H.
⊓⊔

112
5 BG Homomorphism and Equivalent Notions
T
T : b
T
T : a
r1
r4
r3
t2
t2
t1 : b
vocabulary
t2
o
t2
o
2
2
2
2
1
1
1
1
3
3
2
2
1
1
r2
r1
r2
r3
t2
T
t1
b
T
T
r5
r4
T
t1
t3
a
o
o
o
o
o
o
o
o
o
o
o
o
r5
o
o
o
o
o
o
o
o
o
o
t3
t1
r4
t1
t2
r3
r2
r1
r2
1
1
2
2
3
3
1
1
1
1
2
2
2
2
t3 : a
ternary
binary
TR
TC
2
1
2
1
3
2
1
r4
r5
r3
r1
r2
T
t2
t1
t3 o
o
o
o
o
o
o
o
o
G
H= flat(G)
H’= vflat(G)
Fig. 5.4 The transformations flat and vflat

5.2 Graphs
113
Note that vflat and flat are not parsimonious.
Example. In Fig. 5.5, where the relations are ordered as r > r′′ > r′, there is only
one homomorphism from G to H and there are three homomorphisms from flat(G)
to flat(H).
flat(H)
H
G
flat(G)
T
T
r
1
2
T
T
r’
1
2
T
T
r
1
2
T
T
r
r’
r’’
1
1
1
2
2
2
Fig. 5.5 flat is not parsimonious
Note also that the problems BG-HOMOMORPHISM on a ﬂat vocabulary and BG-
HOMOMORPHISM on a very ﬂat vocabulary are parsimoniously equivalent.
The same notions can be introduced for conceptual hypergraphs, i.e., one can
consider BHs on ﬂat or very ﬂat vocabularies. With a BH homomorphism deﬁned
as a mapping only from concept nodes, the transformations flat and vflat applied
to BHs are now parsimonious reductions.
Property 5.2. The three problems BH-HOMOMORPHISM, BH-HOMOMORPHISM for
BHs on a ﬂat vocabulary and BH-HOMOMORPHISM for BHs on a very ﬂat vocabu-
lary are parsimoniously equivalent.
5.2 Graphs
BG homomorphism is a key notion in this book. A BG is a kind of labeled graph
and a BG homomorphism is simply an adaptation of the classical graph homomor-
phism notion. We show in this section, that the BG-HOMOMORPHISM problem is
parsimoniously equivalent to the homomorphism problem on ordinary graphs.
Ordinary graphs can be translated into BGs in such a way that the classical graph
homomorphism notion is transformed into BG homomorphism and reciprocally.

114
5 BG Homomorphism and Equivalent Notions
5.2.1 From Graphs to BGs
A (ordinary) directed graph G is a pair (X,U), where X is the vertex set of G and
U ⊆X × X is its arc set. Hereafter we generally consider directed graphs, so we
usually omit the term “directed.” Nevertheless, when undirected graphs are consid-
ered, let us recall (cf. Chap. A) that they can be identiﬁed as directed graphs by
replacing each edge linking vertices x and y by two symmetrical arcs xy and yx.
Let us consider a very simple vocabulary having only two elements, i.e., a concept
type ⊤and a binary relation type ⊤2 (this vocabulary is very ﬂat). A graph G can
be transformed into a BG, denoted g2b(G), on this vocabulary. The concept node
set of g2b(G) is (in bijection with) the vertex set of G and the relation node set of
g2b(G) is (in bijection with) the arc set of G. More precisely, for each vertex x of G,
there is one concept node g2b(x) labeled by (⊤,∗), and for each arc xy in G, there
is one relation node labeled by ⊤2, with ﬁrst neighbor g2b(x) and second neighbor
g2b(y) (cf. Fig. 5.6).
2
g2b(x)
y
x
g2b
1
g2b(y)
2
T
T
T
Fig. 5.6 From graphs to BGs
The transformation g2b is polynomial in the size of G. g2b is injective but not
surjective and this is due to the existence of twin relation nodes in BGs. Neverthe-
less, if one considers directed multigraphs, i.e., an arc may appear several times in
U, instead of directed graphs, then g2b is bijective.
A graph homomorphism h, from a graph G = (XG, UG) to a graph H = (XH, UH),
is a mapping from XG to XH which preserves arcs, i.e. if xy is an arc in UG, then
h(x)h(y) is an arc in UH. The GRAPH-HOMOMORPHISM problem is deﬁned as fol-
lows:
GRAPH-HOMOMORPHISM
instance: two (directed) graphs G and H
question: Is there a homomorphism from G to H?
Example. For instance, let G and H be the graphs in Fig. 5.7. There are several
homomorphisms from G to H, two of them map the vertex 4 onto the vertex a:
h1 = {(4,a),(3,b),(2,c),(1,d)} and h2 = {(4,a),(3,b),(2,c),(1,a)}.
Property 5.3. Let G and H be two directed graphs. There is a bijection from the set
of homomorphisms from G to H to the set of BG homomorphisms from g2b(G) to
g2b(H). Thus, g2b is a parsimonious reduction from GRAPH-HOMOMORPHISM to
BG-HOMOMORPHISM.

5.2 Graphs
115
G
H
d
c
b
a
4
3
2
1
Fig. 5.7 Graph homomorphism
Proof. See the companion Fig. 5.8. Let h be a homomorphism from G to H. From h,
a mapping π from Cg2b(G) to Cg2b(H) can be deﬁned as follows: For all c ∈Cg2b(G),
let x ∈XG such that c = g2b(x), then π(c) = g2b(h(x)). It is extended to a BG
homomorphism from g2b(G) to g2b(H) by assigning, to each relation of Rg2b(G)
image of an arc xy, i.e. a relation with neighbor list (g2b(x),g2b(y)), the relation
image of the arc h(x)h(y), i.e. the relation with neighbor list (π(g2b(x)),π(g2b(y))).
Reciprocally, let π be a BG homomorphism from g2b(G) to g2b(H). The restriction
of π to concept nodes (mapping from Cg2b(G) to Cg2b(H)) deﬁnes a homomorphism
h from G to H as follows, for all x ∈XG h(x) = g2b−1(π(g2b(x))). Let h and h′
be two homomorphisms from G to H and π and π′ the associated homomorphisms
from g2b(G) to g2b(H). If h ̸= h′, then π ̸= π′. It is also simple to check that this
correspondence is surjective.
⊓⊔
g2b(G)
H
g2b(H)
G
c
h
Π
x
h(x) = g2b−1(π(g2b(x))
π(c) = g2b(h(x))
Fig. 5.8 Graph homomorphism and BG-homomorphism
It is well-known that GRAPH-HOMOMORPHISM is an NP-complete problem. For
instance, there is a straightforward reduction from the CLIQUE problem (cf. [GJ79])

116
5 BG Homomorphism and Equivalent Notions
to the GRAPH-HOMOMORPHISM problem, since a graph G contains a k-clique as a
subgraph if and only if there is a homomorphism from the k-clique to G. Therefore,
Corollary 5.1. BG-HOMOMORPHISM is an NP-complete problem.
This corollary is a new proof of Theorem 2.5.
A labeled multigraph is a triple G = (X,U,l), where (X,U) is a multigraph and
l is a labeling of X and U. A general deﬁnition of a labeled multigraph homo-
morphism where labels of corresponding vertices or arcs must be compatible is as
follows:
Deﬁnition 5.5 (Labeled multigraph c-homomorphism).
Let G = (XG,UG,lG)
and H = (XH,UH,lH) be two labeled multigraphs, and let c be a binary (compat-
ibility) relation between labels. A labeled multigraph c-homomorphism from G to
H is a mapping π from XG to XH and from UG to UH, such that:
• for all x ∈XG one has c(lH(π(x)),lG(x)),
• for all u ∈UG having x for origin and y for extremity, π(u) has π(x) for origin
and π(y) for extremity and c(lH(π(u)),lG(u)).
A (labeled multigraph) homomorphism is a (labeled multigraph) c-homomorphism
where c is the equality relation between labels.
Algorithms computing homomorphisms presented in Chaps. 6 and 7 can be trans-
formed into algorithms computing c-homomorphisms by substituting the compati-
bility relation c to the equality relation between labels.
Example. Let us consider the two labeled multigraphs represented in Fig. 5.9. The
application π deﬁned by:
π(x1) = y1, π(x2) = π(x3) = y2, π(x4) = π(x5) = y3
and naturally extended to the arc sets is a labeled multigraph homomorphism from
the multigraph G on the left to the multigraph H on the right.
With a BG being a labeled multigraph with properties on the labels, the deﬁnition
of a labeled multigraph c-homomorphism can be adapted for BGs as follows:
Deﬁnition 5.6 (BG c-homomorphism). Let G and H be two BGs deﬁned on V, and
c be a compatibility relation between labels. A c-homomorphism from G to H is a
mapping π from CG to CH and from RG to RH, such that:
• ∀(r,i,c) ∈G,(π(r),i,π(c)) ∈H,
• ∀e ∈CG ∪RG, one has c(lH(π(e)),lG(e)).
A BG homomorphism is a BG c-homomorphism such that the compatibility re-
lation c is the order relation on the labels, i.e., c(x,y) if and only if x ≤y.
The mapping g2b, from graphs to BGs (on very ﬂat vocabularies), can be easily
extended to a mapping lg2b from labeled multigraphs to BGs (on very ﬂat vocab-
ularies) while preserving Property 5.3. Let us consider a very ﬂat BG vocabulary
having a set of unary symbols corresponding to a set of vertex labels of multigraphs
and a set of binary relation symbols corresponding to a set of arc labels of multi-
graphs. Then BGs on such a vocabulary and labeled multigraphs are, as mathemati-
cal objects, identical.

5.2 Graphs
117
H
G
x5
a
a
a
d
c
b
a
y2
y5
y4
y3
y1
b
c
a
c
x4
x3
x2
x1
d
c
a
a
a
c
c
b
a
Fig. 5.9 π is a labeled multigraph homomorphism from G to H
Property 5.4. lg2b is a bijection from labeled multigraphs to BGs on very ﬂat vocab-
ularies (associated with multigraph label sets). Let G and H be two labeled multi-
graphs. There is a bijection from the set of homomorphisms from G to H to the set of
BG homomorphisms from lg2b(G) to lg2b(H). Thus lg2b is a parsimonious reduc-
tion from LABELED-MULTIGRAPH-HOMOMORPHISM to BG-HOMOMORPHISM.
But, once the vocabulary is enriched, the labeled multigraph homomorphism and
BG homomorphism notions diverge. For instance, if an individual marker is intro-
duced, or if two relation symbols are comparable, then the concept label set (or the
relation label set) becomes a non-trivially ordered set. Thus, BG homomorphisms
and labeled multigraph homomorphisms are no longer equivalent. Nevertheless, it is
possible to encode the order on the label sets into the structure of the graph in such
a way that BGs can be transformed into unlabeled graphs, while transforming BG
homomorphism into (ordinary graph) homomorphism. This is explained hereafter.
5.2.2 From BGs to Graphs
Let us consider BGs on a very ﬂat vocabulary (the transformation from a BG on any
vocabulary to a BG on a very ﬂat vocabulary was studied in the previous section).
A mapping, denoted b2lg, from BGs on a very ﬂat vocabulary to vertex labeled
undirected graphs, which preserves homomorphisms, can be deﬁned as follows.
Let a1,...,an be new labelswith respect to the set of vertex labels.
1. Let k be the arity of a relation node x labeled r. The edges incident to x are
removed, k new nodes, labeled a1,...,ak are added, ai is adjacent to x and to the
i-th neighbor of x.
2. The distinction between concept and relation nodes is no longer considered.

118
5 BG Homomorphism and Equivalent Notions
The graph b2lg(G) is a (ordinary) undirected graph labeled on the vertices.
Example. In Fig. 5.10 the BG H on a very ﬂat vocabulary (cf. Fig. 5.4) and the
labeled graph b2lg(H) are represented.
H=vflat(G)
t2
o
r5
r5
a2
a1
a2
a1
a1
a2
a2
a1
a3
a3
a2
a2
a1
a1
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
t3
t1
T
r4
T
T
b
t1
T
t2
r3
r2
r1
r2
1
2
1
2
2
1
2
1
2
3
1
3
2
1
r2
r1
r2
r3
t2
T
t1
b
T
T
r4
T
t1
t3
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o t2
a
a
b2lg(H)
o
Fig. 5.10 The transformation b2lg
The transformation b2lg(G) is polynomial and one has:
Property 5.5. Let G and H be two BGs on a very ﬂat vocabulary V. There is a bi-
jection between the set of BG homomorphisms from G to H and the set of labeled
graph homomorphisms from b2lg(G) to b2lg(H). Thus, b2lg is a parsimonious re-
duction from BG-HOMOMORPHISM to LABELED-GRAPH-HOMOMORPHISM.
The last transformation, denoted lg2g, only concerns labeled and unlabeled (or-
dinary) multigraphs and is classical in graph theory (cf. [HN04]). As this transfor-
mation is rather long to deﬁne, we only give some hints as to how it works. A set
of k graphs, called replacement graphs, can be associated with any set of k labels.
If a set of replacement graphs fulﬁlls some conditions (e.g., the replacement graphs
are pairwise non-comparable or the identity is the only one homomorphism from a
replacement graph to itself), then it can be shown that replacing each labeled edge
by its associated replacement graph is a parsimonious reduction from LABELED-
GRAPH-HOMOMORPHISM to (unlabeled) GRAPH-HOMOMORPHISM.

5.3 Relational Structures and Databases
119
Property 5.6. lg2g is a parsimonious reduction from LABELED-GRAPH-HOMO-
MORPHISM to (unlabeled) GRAPH-HOMOMORPHISM.
From Property 5.3, Property 5.4 and Property 5.6, one obtains:
Theorem 5.2 (Equivalence between BG-HOMOMORPHISM and GRAPH-HOMO-
MORPHISM). BG-HOMOMORPHISM and GRAPH-HOMOMORPHISM are parsimo-
niously equivalent.
It would be rather inefﬁcient to use this latter result to solve a homomorphism
problem between BGs, that is to ﬁrst transform them into ordinary graphs and then
to use a graph homomorphism algorithm. A more efﬁcient solution is to build algo-
rithms directly considering BGs (cf. Chap. 6 and Chap. 7).
5.3 Relational Structures and Databases
In Sect. 5.1.1, hypergraphs are considered. A hyperedge is a tuple and as tuples
underlie relational structures it is natural to study relational structures and homo-
morphism of relational structures.
5.3.1 Relational Structures and BGs
A (ﬁnite) relational structure C on a ﬁnite set R of relation symbols and a universe
U is equal to a set {rC ⊆Uk | for all relations r ∈R, k being the arity of r} with rC
being the ﬁnite set of tuples of r in C. Any tuple (a1,...,ak) in rC can be represented
by r(a1,...,ak) or by the set of k triples {(r,i,ai)|i = 1,...,k}. Given two structures
C1 and C2 on the same R, a homomorphism h from C1 to C2 is a mapping from
the universe UC1 of C1 to the universe UC2 of C2, such that for all relations r ∈R, if
r(a1, ..., ak) ∈C1 then r(h(a1), ..., h(ak)) ∈C2. Equivalently, h is a homomorphism
if for all k-ary relations r and for all i = 1,...,k if (r,i,ai) is in C1, then (r,i,h(ai))
is in C2. The RELATION-HOMOMORPHISM problem is as follows:
instance: two (ﬁnite) relational structures A and B
question: Is there a homomorphism from A to B?
A relational structure C on R can be transformed, by a mapping denoted r2b,
into a (normal) BH on the very ﬂat vocabulary with R as relation symbol set as
follows. The concept node set of r2b(C) is in bijection with the set of arguments in
the tuples of C, i.e., the set {aj | ∃r∃i(r,i,aj) ∈C}. Any concept node is generic. For
each tuple r(a1,...,ak) in C, a hyperedge e labeled by r is built, the i-th element of e
is the concept node corresponding to ai. C and r2b(C) have the same size, thus r2b
is a polynomial transformation and one can check that there is a bijection from the
set of homomorphisms from C to C′ to the set of BH homomorphisms from r2b(C)
to r2b(C′).

120
5 BG Homomorphism and Equivalent Notions
Conversely, let G be a BH without isolated nodes on a very ﬂat vocabulary having
R as relation symbol set. G can be transformed into a relational structure b2r(G)
as follows. The relation symbol set of b2r(G) is R, the universe of b2r(G) is in
bijection with the concept node set of G and, if e = (c1,...,ck) is a hyperedge in G
labeled r, then b2r(G) contains the tuple r(a1,...,ak), where ai is the element of the
universe corresponding to ci. One can check that if G and H are two BHs without
isolated nodes on a very ﬂat vocabulary, then there is a bijection from the set of BH
homomorphisms from G to H to the set of relation homomorphisms from b2r(G) to
b2r(H).
Theorem 5.3 (Equivalence between RELATION-HOMOMORPHISM and
BH-HOMOMORPHISM).
• r2b is a parsimonious reduction from RELATION-HOMOMORPHISM to BH-HO-
MOMORPHISM on very ﬂat vocabularies.
• b2r is a parsimonious reduction from BH-HOMOMORPHISM (without isolated
nodes) on very ﬂat vocabularies to RELATION-HOMOMORPHISM.
From a computational viewpoint, conceptual hypergraphs and relational struc-
tures are very similar. Nevertheless, there are two kinds of differences:
1. Concerning the structures: Isolated concept nodes and twin (redundant) relation
nodes can occur in conceptual hypergraphs but not in relational structures.
2. Concerning the labels: The vertices are labeled in conceptual hypergraphs, and
the sets of labels (for the vertices and hyperedges) are ordered.
From a knowledge representation viewpoint, the preceding differences can be
important. In BGs, entities are usually considered ﬁrst; then relationships between
entities are taken into account. There can be isolated entities, i.e., entities without
any related entity. It may even be possible that there are only entities with no rela-
tionships between them. This is for instance the case in information retrieval when
documents are represented by a set of keywords and each keyword is represented
by a concept node labeled by the keyword. In relational structures, relations are ﬁrst
considered and they necessarily occur.
Relational structure is the basic mathematical notion in relational database the-
ory. Two fundamental problems concerning relational databases, namely the evalu-
ation of a conjunctive query and the query containment problem, are related to BG
homomorphism in the next section.
5.3.2 Conjunctive Queries and BGs
Let us begin by reviewing some basic deﬁnitions concerning relational databases.
The basic form of a relational database schema S = (R,dom) is composed of a set
R of n-ary relation symbols (n ≥1) and of a countably inﬁnite set dom of constants.
An instance of such a schema is simply a ﬁnite relational structure on R with dom
as universe.

5.3 Relational Structures and Databases
121
A (positive and non-recursive) conjunctive query q on a schema S = (R,dom) is
a rule, q = ans(u) ←r1(u1), ... rn(un), n ≥1, where:
• r1,...,rn belong to R,
• ans is not in R (ans stands for “answer”),
• u1,...,un are tuples of terms (variables or constants of dom), u is a tuple of
variables and for any i the length of ui is equal to the arity of ri, and ∀i ̸= j
ri(ui) ̸= r j(uj),
• each variable of u occurs at least once in u1,...,un.
Given a query q = ans(u) ←r1(u1), ... rn(un) and an instance D of S = (R,dom),
q(D) denotes the set of answers to q in D, i.e., q(D) is the set of tuples µ(u), where
µ is a substitution of the variables of q by dom constants such that for any j in
{1,...,n}, µ(uj) ∈D(r j), where D(r j) is the set of r j-tuples in D. When the arity
of ans is 0, i.e, when u is empty, q can be seen as a boolean query whose answer is
yes or no. If there is a substitution µ such that for any j in {1,...,n}, µ(uj) ∈D(r j),
then q(D) = {()} and the answer is yes. Otherwise, q(D) = ∅and the answer is no.
5.3.2.1 Conjunctive Query Evaluation
The CONJUNCTIVE-QUERY-EVALUATION decision problem is deﬁned as follows:
instance: a database instance D and a conjunctive query q
question: Does D contain an answer to q, i.e. is q(D) not empty?
A ﬂat vocabulary V = ({⊤},R,dom) can be naturally assigned to a schema S =
(R,dom), i.e., the relation symbol set of V is R and the individual marker set of V is
dom. An instance D of S = (R,dom) can be transformed into a BG H = q2b(D). The
concept node set of H is in bijection with the elements of dom appearing in D and the
concept node corresponding to ai is labeled (⊤,ai), thus all concept nodes in H are
individual nodes, H has no isolated nodes and H is normal. Each tuple (a1,...,ak)
of r is represented by a relation node labeled by r and having the concept node
associated with ai for i-th neighbor.
Let q = ans(u) ←r1(u1),...,rn(un) be a query, it can be transformed into a λ-
BG q2b(q) = (c1,...,ck)G as follows. G represents the right part of the query q. A
generic concept node is associated with each variable occurring in a ui, an individual
node is associated with each constant occurring in a ui, and one associates with
each ri(ui) a relation node labeled by ri having concept nodes associated with ui as
neighbor list. Concept nodes corresponding to variables in ans(u) are the λ-concepts
(c1,...,ck) of q2b(q).
Let q2b(q) = (c1,...,ck)G, H = q2b(D) and π be a BG homomorphism from
G to H. Then, the images of the λ-concept nodes constitute an answer to q and,
reciprocally, any tuple of q(D) can be obtained from the images of λ-concepts in a
BG homomorphism from G to H.
Conversely, let us consider a normal BG H without generic nodes nodes on a ﬂat
vocabulary V = ({⊤},TR,I). A schema S = (TR,I) can be associated with V and
an instance of S, denoted b2q(H), can be associated with H.

122
5 BG Homomorphism and Equivalent Notions
A conjunctive query q = b2q(G) can be associated with a normal λ-BG G =
(c1,...,ck)G′ on V, with the right part of q corresponding to G′ (without isolated
nodes) and the left part corresponding to the λ-concepts. Let µ be a substitution that
deﬁnes an answer to q = b2q(G) in b2q(H). Then µ yields a homomorphism from
G to H (since H is normal) and conversely if G has no isolated nodes.
Theorem 5.4 (Equivalence between CONJUNCTIVE-QUERY-EVALUATION and
BG-HOMOMORPHISM). Let D be an instance of a relational schema S and q be a
conjunctive query on S.
• The answer set q(D) is in bijection with the set of tuples (π(c1),...,π(ck)),
where π is a BG homomorphism from q2b(q) to q2b(D) and c1,...,ck are the
λ-concepts of q2b(q).
• Let H be a normal BG without generic concept nodes on a ﬂat vocabulary V
and G a λ-BG without isolated nodes on V. The answer set to q = b2q(G) in
b2q(H) is in bijection with the set of tuples (π(c1),...,π(ck)), where π is a BG
homomorphism from G to H, and c1,...,ck are the λ-concepts of G.
• The problems CONJUNCTIVE-QUERY-EVALUATION and BG-HOMOMORPHISM
are polynomially equivalent.
Note that the number of solutions is not necessarily preserved by these transfor-
mations even if conceptual hypergraphs are considered.
Example. Let us consider an instance D = {r(a,b),r(a,c)} and a query q =
ans(x) ←r(x,y). q2b(D) and q2b(q) are represented in Fig. 5.11. q(D) = {(a)}
whereas there are two homomorphisms from q2b(q) to q2b(D).
q2b(D)
q2b(q)
c1
2
2
1
1
2
1
T:c
T:b
T:a
T
T
r
r
r
y
x
D = {r(a,b),r(a,c)}
q = ans(x) ←r(x,y)
Fig. 5.11 The transformation q2b

5.3 Relational Structures and Databases
123
5.3.2.2 Conjunctive Query Containment
A query q is said to contain a query q′ (q′ ⊆q) if, for any instance D on a schema
S = (R,dom), q′(D) ⊆q(D).
The CONJUNCTIVE-QUERY-CONTAINMENT decision problem is deﬁned as fol-
lows:
instance: two queries q and q′
question: Does q contain q′?
It is well-known that this problem can be reformulated as a query homomorphism
problem, where a homomorphism between queries is deﬁned as follows:
Deﬁnition 5.7 (Query homomorphism). A query homomorphism from q =
ans(u) ←r1(u1), ... rn(un) to q′ = ans′(u′) ←r′
1(u′
1), ... r′
n′(u′
n′) is a substitution θ
of the variables of q by terms (variables or constants of dom) such that θ(u) = u′,
and for any j ∈{1,...,n}, there is i ∈{1,...,n′} with θ(r j(uj)) = r′
i(u′
i).
The (query) homomorphism theorem [AHV95] shows that, given two queries q
and q′, q contains q′ if and only if there is a query homomorphism from q to q′.
T
z
y
x
q2b’(q)
T
T 
T
v
ans
r
3
2
2
1
1
2
1
s
q = ans(x, z) ←r(x, y, z), s(z, v)
Fig. 5.12 The transformation q2b′
Transformations between CONJUNCTIVE-QUERY-CONTAINMENT and BG-HO-
MOMORPHISM, called q2b′ and b2q′ (cf. Fig. 5.12), are similar to transformations
q2b and b2q (and also similar to the transformations f2G and G2f between a logical
language of FOL(∃, ∧) and a BG language (deﬁned in Chap. 4).
1. Transformation from Query containment to BG homomorphism:
Let V = ({⊤},R ∪Ans,dom) be a ﬂat vocabulary where Ans = {ansk| k ≥1},
with ansk being a relation of arity k used to represent the left part of a query
having k variables. Then a mapping q2b′ from conjunctive queries to normal BGs
on V can be deﬁned as follows (cf. Fig. 5.12 for an example). Let q = ans(u) ←
r1(u1),...,rk(uk) be a query, then q2b′(q) = (Cq,Rq,Eq,lq), where,
• Cq is in bijection with the set of terms occurring in u,u1, ..., un, and the node
of Cq assigned to a term e is generic if e is a variable, and otherwise it is an
individual concept with marker e,
• Rq is a set of (n+1) nodes labeled by r1, ..., rn, ansk, with k being the number
of variables in u,

124
5 BG Homomorphism and Equivalent Notions
• if e is the i-th argument of r j (or ans), then the concept node assigned to e is
the i-th neighbor of the relation node assigned to r j (or ans).
One can check that, given two queries q and q′, any query homomorphism from
q to q′ induces a BG homomorphism from q′2b(q) to q′2b(q′), and reciprocally.
2. Transformation from BG homomorphism to Query containment:
Let us consider BGs on a ﬂat vocabulary V = ({⊤},TR,I) and let S = (TR,I)
be the relational schema associated with V. A mapping b2q′ from normal BGs
without isolated concepts on V to (boolean) queries on S can be deﬁned in a
similar way as b2q. More precisely, b2q′(G) = ans() ←r1(u1) ... rn(un), where
ri corresponds to a relation node x in G labeled ri and where ui is the neighbor
list of x. Given two normal BGs without isolated concepts G and H, it can be
checked that there is a query homomorphism from b2q′(G) to b2q′(H) if and
only if there is a BG homomorphism from G to H.
Theorem 5.5 (Equivalence
between
CONJUNCTIVE-QUERY-CONTAINMENT
and BG-HOMOMORPHISM).
• The mapping q2b′ is a parsimonious reduction from CONJUNCTIVE-QUERY-
CONTAINMENT to BG-HOMOMORPHISM.
• The mapping b2q′ is a polynomial reduction from BG-HOMOMORPHISM (without
isolated nodes) on a ﬂat vocabulary to CONJUNCTIVE-QUERY-CONTAINMENT.
• The CONJUNCTIVE-QUERY-CONTAINMENT and BG-HOMOMORPHISM prob-
lems are polynomially equivalent.
5.4 Constraint Satisfaction Problem
5.4.1 Deﬁnition of CSP
The Constraint Satisfaction Problem is the basic problem of the constraint process-
ing research domain. It has been deeply studied from an algorithm viewpoint. Chap-
ter 6 will borrow a lot from techniques developed in the CSP framework.
The input of a constraint satisfaction problem is composed of a set of variables,
with a set of possible values for the variables and a set of constraints on the variables.
A constraint on certain variables deﬁnes what values these variables can simultane-
oulsy take. The question is whether there is an assignment of values to the variables
that satisﬁes the constraints.
We will consider the simplest kind of CSP, where variables have discrete and
ﬁnite domains. In this case, constraints can be described by the enumeration of all
allowed tuples of values. In more general CSPs, variables can have inﬁnite domains
(e.g., the set of integers), or constraints can be deﬁned by a language (e.g., algebraic
inequalities).
Deﬁnition 5.8 (Constraint network). A constraint network is a 3-tuple P = (X, D,
C) composed of:

5.4 Constraint Satisfaction Problem
125
• a set of variables, X = {x1, ... ,xn},
• a set of values, D = D1 ∪... ∪Dn, where Di is the domain of the variable xi,
• a set of constraints, C = {C1, ... ,Cp}, where each constraint Ci is composed of a
totally ordered subset of variables Si, and a relation Ri on Si. Si = {xi1, ..., xiq} ⊆
X is called the scope of Ci. Ri is a subset of the cartesian product Di1 × ... ×Diq
and is called the deﬁnition of Ci. The arity of Ci is q, the size of its scope.
A constraint deﬁnition Ri is often represented as a table, where the columns are
given by Si, and the rows are tuples of Ri. Given a constraint Ci and a variable xj in
its scope, we denote Ri[xj] as the set of values for xj in Ri. Ri[xj] is thus obtained
from the xj column in Ri by deleting duplicate values. In relational terms, it is the
projection of Ri onto xj. More generally, if xj, ..., xk are variables in the scope of
Ci, Ri[xj, ..., xk] denotes the projection of Ri onto xj, ..., xk, i.e., the set of tuples
(aj, ..., ak) obtained by restricting Ri to variables xj, ..., xk.
Note that we allow several constraints with the same scope, and even with the
same scope and the same deﬁnition. These cases are usually not interesting in the
CSP framework, but they bring a simpler correspondence between BGs and con-
straint networks.
a  b  c
b  a  c
b  c  d
C3
C2
C1
x4
x3
x2
x4
x1
a  c
b  c
b  d
x4
x3
x2
a  d  c
x3
x2
x1
x1
b  c   c
a  a  d
Dx1 = Dx2 = {a, b}, Dx3 = Dx4 = {c, d}
Fig. 5.13 A constraint network
When all constraints are binary, i.e., involve exactly two variables, the pair
(X, C) deﬁnes an undirected graph, whose vertices are the variables and edges are
the scopes of the constraints (as in Fig. 5.14). More precisely, it is a multigraph
when several constraints are deﬁned on the same subset of variables. In the general
case, (X, C) deﬁnes a hypergraph (cf. Fig. 5.13).
Figure 5.14 illustrates how a graph coloring problem can be recast as a CSP. The
input of a graph coloring problem is composed of an undirected graph, and a set of
colors. The question is whether a color can be assigned to each vertex of the graph in
such a way that different colors are assigned to vertices connected by an edge. This
problem can be seen as an abstraction of various resource allocation problems. For
instance, the map coloring problem is deﬁned as follows: Given a map of countries
and a set of colors, the question is whether the countries can be colored (with the set
of colors), in such a way that adjacent countries do not have the same color. The map

126
5 BG Homomorphism and Equivalent Notions
c  b
c  a
b  c
a  c
b  a
a  b
xi xj
.
.
.
.
.
x1
x3
x4
.
x5
x5
constraint template
x2
For all variable xi, Dxi = {a, b, c}
All constraints are difference constraints
Fig. 5.14 A binary constraint network
can be abstracted as an undirected graph, where the vertices represent the countries,
with an edge connecting two countries if they are neighbors on the map.
To go from a graph coloring instance to a constraint network, the vertices and
edges of the graph become the variables and constraints of the network, respectively.
All variables have the same domain, which is the set of colors. Finally, all constraints
are “difference” constraints, i.e., their deﬁnitions express the fact that the variables
have to be assigned different values.
A solution to a constraint network P is an assignment of values to the n variables
satisfying all constraints, formally:
It is a mapping S: X →D, with xi →a ∈Di,
and such that for every constraint Cj = (xj1 ... xjq), (S(xj1) ... S(xjq)) ∈Rj.
A constraint network is (globally) consistent if it has at least a solution.
Example. The network in Fig. 5.13 is consistent. It possesses two solutions, Sol1 =
{(x1, a), (x2, a),(x3, d),(x4, c)} and Sol2 = {(x1, a),(x2, b),(x3, c),(x4, c)},
which correspond to the ﬁrst two lines of constraint deﬁnitions C1, C2 and C3, re-
spectively. The network in Fig. 5.14 is inconsistent (this translates the fact that the
graph cannot be colored with three colors).
The CONSTRAINT-SATISFACTION-PROBLEM (CSP) is deﬁned as follows:
instance: a constraint network P
question: Is P consistent, i.e., is there a solution to P?
A lot of combinatorial problems can be expressed as CSP, and BG-HOMOMOR-
PHISM is one of them. It is less obvious that, in turn, CSP can be recast as BG-HO-
MOMORPHISM. Let us begin with this latter side of the equivalence. We call c2h
the transformation from CSP to BG-HOMOMORPHISM, and h2c the transformation
in the opposite direction.

5.4 Constraint Satisfaction Problem
127
5.4.2 From CSP to BGs
Let us ﬁrst outline the idea of the transformation denoted c2h. Consider a constraint
network P = (X, D, C). P is transformed into two BGs G and H, with the following
idea.
G translates the macro-structure of P, i.e., the hypergraph itself. It is built from
X and the constraint scopes in C. Each concept node is generic and corresponds to
a variable, and each relation corresponds to a constraint, with its arguments corre-
sponding to variables in the constraint scope.
H represents the micro-structure of P. It is built from D and the constraint deﬁni-
tions in C. There is an individual concept node for each value of D, and a relation for
each tuple of compatible values. Figure 5.15 illustrates this transformation, showing
the BGs obtained from the network of Fig. 5.13.
Roughly said, the question is whether there is a mapping from variables (con-
cept nodes of G) to values (concept nodes of H) that satisﬁes the constraints (maps
relations of G to relations of H), i.e., is a homomorphism from G to H.
T
T
T
T
H
G
T:b
T:c
T:a
T:d
C1
C1
C1
C2
C3
C3
C3
3
2
1
3
2
1
3
2
1
1
2
2
2
1
1
1
3
2
3
1
2
3
2
1
C2
C2
C1
C2
C3
2
1
3
2
1
3
2
1
Instance obtained by c2h from the network in Fig. 5.13
Fig. 5.15 The transformation c2h
Let us now deﬁne c2h more precisely. A ﬂat vocabulary V = ({⊤},TR,I) is built
from P as follows: TR is in bijection with C, with each relation type having the same
arity as the corresponding constraint, and I is in bijection with D.
G and H are then deﬁned as follows:
• CG is in bijection with X. Each concept node is labeled by (⊤, ∗).
• RG is in bijection withC. Each relation is labeled by the corresponding constraint.
The i-th argument of a relation is the concept node corresponding to the i-th
variable of the constraint scope.
• CH is in bijection with D. Each concept node is labeled by (⊤, a), where a is the
individual associated with the element a of D.
• RH is in bijection with the (disjoint) union of all Ri. In other words, there is one
relation for each tuple in a constraint deﬁnition; this relation is labeled by the

128
5 BG Homomorphism and Equivalent Notions
T
T
T
T
T
T
G
H
T:a
T:b
T:c
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
Instance obtained by c2h (variant) from the network in Fig. 5.14
Fig. 5.16 The transformation c2h (variant)
corresponding constraint, and its i-th argument is the concept node corresponding
to the i-th value.
Remark that the mapping c2h can be considered as a mapping from a CSP to a BH
as well as a mapping from a CSP to a BG.
Note that both graphs G and H are in normal form. It can be simply checked that
any solution to the CSP yields a BG homomorphism from G to H, and reciprocally.
Rather than creating one relation type per constraint, a more concise transforma-
tion can create one relation type per group of constraints having the same deﬁnition
(see for instance Fig. 5.16, which shows the graphs obtained from the network in
Fig. 5.14: All constraints are difference constraints, thus have the same deﬁnition,
which is translated as a single relation type).
5.4.3 From BGs to CSP
The mapping h2c from BGs (or BHs) to CSP is based on the same idea as c2h. The
source BG G provides the macro-structure of the constraint network, while the target
BG H provides the micro-structure. H is supposed to be in normal form. There is
one variable for each concept node of G, and one constraint for each relation node
of G. The set D of domain values is built from the concept nodes of H: There is one
value for each concept node in H. The domain Di of a variable xi is composed of the
a priori possible images for the concept node ci by a BG homomorphism from G
to H. If, for a concept node ci in G, we note poss(ci) = {c′ ∈CH,lG(ci) ≥lH(c′)},
then Di is the set of values assigned to the nodes in poss(ci). The domain of a
variable coming from an individual node of G thus contains at most one value. Also
note that isolated concept nodes are translated into variables beyond the scope of all
constraints. Such variables can be instantiated by any value of their domain.
The deﬁnition of a constraint Ci coming from a relation ri is the set of tuples
given by the neighborhood of the relations in H, which might be images for ri. At

5.4 Constraint Satisfaction Problem
129
H
G
c1
r1
r2
2
2
1
1
c2
c
Fig. 5.17 The case of multiedges
this point, we have to pay attention to the fact that the arguments of a relation are
not necessarily distinct, that is, in graph terms, there may be several edges between
a concept node and a relation node. This case does not occur in a constraint, since
its scope is a set of variables.
For any relation r of arity q in a BG, let Pr denote the partition on {1, ..., q}
induced by the equality of arguments of r, i.e., i and j are in the same class of the
partition if the ith and the jth arguments of r are the same node. For any c argument
of r, Pr[c] denotes the class in Pr corresponding to c, i.e., in graph terms it is the set
of numbers labeling the edges between r and c.
Example. In Fig. 5.17, Pr1 = {{1,2}} and Pr2 = {{1},{2}}. Pr1[c] = {1,2}, Pr2[c1] =
{1}, Pr2[c2] = {2} .
Given two relations r1 and r2 of the same arity, Pr2 is thinner than Pr1 (notation
Pr2 ⊆Pr1) if each Pr2 class is included in (or equal to) a Pr1 class. If a BG homomor-
phism maps a node r to an node r′, then, necessarily, Pr is thinner than Pr′. Indeed,
two nodes can have the same image, whereas a node cannot have two images.
Example. In Fig. 5.17, Pr2 is thinner than Pr1, but the opposite is false. Assuming
that the conditions on labels are satisﬁed, there is a homomorphism from H to G but
not from G to H.
If Pr2 is thinner than Pr1, given any neighbor c of r2, the corresponding neighbor
of c in r1 is the node c′ with Pr2[c] ⊆Pr1[c′]. If a BG homomorphism maps r2 to r1,
then necessarily c is mapped to c′.
Each relation r of arity q is transformed into a constraint of arity n (n ≤q), where
n is the number of distinct neighbors of r. Thus, n is not necessarily equal to q,
the arity of the type of r. n is the number of distinct neighbors of r, which might be
strictly smaller than the number q of edges incident to r. There is a bijection between
the concept nodes of G and the variables of X, thus the scope of a constraint assigned
to a relation node is in bijection with the set of (distinct) neighbors of this relation.
Example. In Fig. 5.18, r is a ternary relation with two distinct neighbors, which
leads to a constraint of arity 2 (transformation 1). The deﬁnition of this constraint is
obtained from poss(r) = {r1, r3}.
Let (ci1,...,cin) be the list of distinct neighbors of r ordered in a certain way (for
instance by increasing order of their ﬁrst occurrence in r(c1,...,cq), with q being
the arity of r). Let poss(r) = {r′ ∈RH|lG(r) ≥lH(r′) and Pr ⊆Pr′}. Let Ci be the

130
5 BG Homomorphism and Equivalent Notions
G’
G
H
a4  a4
a2  a2
x1  x3
x1  x2
a3  a3
a1  a2
r
c2
1
3
a3  a3
a1  a1
c3
c1
2
2
3
a1
r3
r1
r2
r3
r1
Transformation 2
a3  a2  a4
a3  a3  a3
a1  a2  a1
Transformation 1
x1  x2  x3
c2
r
3
2
c1
1
r3
r2
a4
a3
3
2
1
1
r1
a2
All labels are supposed to be compatible.
poss(c1) = poss(c2) = CH
poss(r) = {r1, r3}
Fig. 5.18 h2c: processing multiedges
constraint, with scope Si = (xi1,...,xin), assigned to r. Then, Ri is the set of tuples
(ai1,...,ain) coming from values assigned to the arguments of relations in poss(r).
Thus, two relations with the same label do not necessarily have the same possible
images.
The h2c transformation is ﬁnally deﬁned as follows:
• X is in bijection with CG (we denote h2c(CG) = X),
• D is in bijection with CH (we denote h2c(CH) = D); furthermore for each
c ∈CG, poss(c) is in bijection with Dh2c(c), the domain of h2c(c) (we denote
h2c(poss(c))= Dh2c(C)),
• C is in bijection with RG (we note h2c(RG) = C),
• the scope of each constraint h2c(r) is in bijection with {h2c(c1),...,h2c(cn)}
ordered in a certain way, where c1,...,cn are the distinct arguments of r,
• the deﬁnition of each constraint h2c(r) is built as follows. Let poss(r) = {r′ ∈
RH|lG(r) ≥lH(r′) and Pr ⊆Pr′}. Let c1,...,cn be the list of distinct neighbors
of r (listed in the same order as in the scope of h2c(r)). Then Rh2c(r) is built
from poss(r): Rh2c(r) = {(v1,...,vn)|, r′ ∈poss(r) and for all 1 ≤i ≤n, vi =
h2c(c′
i), where c′
i is the neighbor of r′ corresponding to ci for r} (we denote
h2c(poss(r)) = Rh2c(r)) . If H does not contain several relations with the same
neighbor list, then poss(r) is in bijection with Rh2c(r).

5.4 Constraint Satisfaction Problem
131
It can be simply checked that any BG homomorphism from G to H gives a solu-
tion to the CSP, and reciprocally.
h2c is easily extended to deal with coreference links. In addition to previous
constraints, for each (non-trivial) coreference class of the source BG an equality
constraint is created, i.e., a constraint expressing that all variables in its scope must
be assigned the same value.
Note that, concerning BG homomorphism, the source BG could be processed as
if the arguments of any relation were all distinct. Indeed, a concept node linked to
a relation node by multiedges can be split into as many nodes as edges, with these
nodes being coreferent, while keeping a logically equivalent BG (cf. Fig. 5.18, trans-
formation from G to G′). Thus, each relation could be translated into a constraint
with the same arity, plus an equality constraint per coreference class on its neighbors
(cf. Fig. 5.18, transformation 2).
We have seen that when BGs are considered as graphs, the number of homomor-
phisms from one BG to another can be greater than that with the hypergraph vision
(cf. Sect. 5.1.1). In this case, by the h2c transformation, a solution to the constraint
network can deﬁne several BG homomorphisms from G to H. Therefore, BGs have
to be considered as hypergraphs so that the h2c transformation will keep the number
of solutions.
Example. Let us apply h2c to the BG-HOMOMORPHISM instance (G,H) in Fig. 5.15,
which has been obtained by c2h from the P network in Fig. 5.13. The constraint net-
work obtained, say P′, is similar to P (in other words h2c(c2h(P)) is similar to P),
where all Xis come from the concept nodes of G and a,b,c,d from the concept nodes
of H. The slight difference between P and P′ relies on the domains, since in P′ all
variables have the same domain, which is equal to D.
The properties of the mappings c2h and h2c considered as mappings concerning
BHs instead of BGs lead to the following theorem.
Theorem 5.6 (Equivalence between CSP and BH-HOMOMORPHISM).
• The c2h mapping is a parsimonious reduction from CSP to BH-HOMOMORPHISM
with ﬂat vocabularies.
• The h2c mapping is a parsimonious reduction from BH-HOMOMORPHISM to CSP.
An immediate consequence of the previous result is another proof of NP-
completeness for CSP. Furthermore, by the given transformations, the constraint net-
work and the source BG have the same structure, thus, tractable cases based on the
structure can be translated from one problem into another. CSP has been extremely
well-studied from an algorithm viewpoint. Therefore, importing CSP techniques to
BG homomorphism is a natural idea (cf. Chap. 6). However, let us point out that a
good algorithm for CSP is not necessarily good for computing BG homomorphisms
in practice. Indeed, in the constraint processing ﬁeld great efforts have been made to
design algorithms that perform well on extremely difﬁcult instances, corresponding
to the so-called phase transition. The networks of these instances are very dense, and
generally randomly generated. BGs, at least in a knowledge representation context,
have several characteristics, which are usually not observed in constraint networks.

132
5 BG Homomorphism and Equivalent Notions
First, they are often written or drawn by a human being, thus have a particular struc-
ture: They tend to be of small size, sparse, with a small cyclicity degree (that is with
“simple” cycles). Secondly, there is usually dissymmetry between the source BG
and the target BG; the source BG (which has the same structure as the constraint
network that would be obtained by the h2c transformation) is often smaller and less
complex than the target BG. Query-answering systems are a typical case, indeed in
such a system the source graph is the query and is usually small, and the target graph
is (part of) the knowledge base which can be large.
5.5 Bibliographic Notes
It is shown in [Jea98] that many combinatorial problems can be reduced to homo-
morphism problems. The last transformation in Sect. 5.2.2, allowing us to elimi-
nate the labels, is classical in graph theory (cf.[HN04]). The remark in Sect. 5.1.1
that there might be exponentially fewer homomorphisms from one conceptual hy-
pergraph to another rather than homomorphisms from the corresponding BGs was
pointed out by Baget in [Bag01][Bag03]. The hypergraph approach is also favoured
in the Darmstadt school viewpoint on CGs (cf. [Wil97], [Pre98b], [Dau03a], and
[ABC06], where the equivalence between concept graphs and conceptual graphs is
shown).
There are more relationships between BGs and relational databases than the re-
sults presented in Sect. 5.3.2. Indeed, it can be proven that the query homomor-
phism theorem ([AHV95], 6.2.3) is equivalent to the soundness and complete-
ness theorem for BG homomorphism (cf. Chap. 4) [CM92], the minimization
theorem ([AHV95], 6.2.6) is equivalent to the theorem concerning irredundant sim-
ple graphs (cf.theorem 2.1) [CM92], and the complexity theorem for query deci-
sion problems ([AHV95], 6.2.10) is equivalent to the complexity theorem for BG-
HOMOMORPHISM (cf.corollary 5.1 [CM92]. See [SCM98] for further details on
these equivalences. The translation from the conjunctive query containment prob-
lem (CQC) to BG-HOMOMORPHISM was published in [CMS98]. Independently, in
[KV98] it was shown that CQC and CSP are essentially the same problem because
they can be recast as a relational structure homomorphism problem. Feder and
Vardi stated that directed graph homomorphism and CSP are equivalent problems
in [FV93]. Since the proof of this result was not given in their paper, we built our
own transformations. A ﬁrst version of the correspondences between CSP and BG-
HOMOMORPHISM can be found in [CM95] or in [MC96]. In these previous ver-
sions, correspondences were done between classical labeled graph homomorphism
and binary CSP. In [Mug00] correspondences between the three problems CQC, CSP
and BG-HOMOMORPHISM are presented in a uniﬁed framework. For pointers to the
constraint processing domain, see the bibliographic notes in Chap. 6.

Chapter 6
Basic Algorithms for BG Homomorphism
Overview
In this chapter, we study basic algorithms for computing one or all homomorphisms
from one BG to another. We ﬁrst present the basic backtrack scheme, then improve
it by consistency-maintaining techniques, essentially adapted from the constraint
processing domain (Sect. 6.1). As this book is about conceptual graphs and not
constraint networks, these techniques are applied directly on BGs. However, another
section is entirely devoted to constraint processing (Sect. 6.2), and it is intended for
readers interested in further algorithmic developments. The last section deals with
the problem of node label comparisons. It presents and compares data structures and
associated algorithms for managing orders on types. General orders are considered,
and also orders with a speciﬁc structure, e.g., trees or lattices.
6.1 Algorithms for BG Homomorphisms
The fundamental BG-HOMOMORPHISM problem, takes as input two BGs, G and
H, and asks whether there is a homomorphism from G to H. However, checking
the existence of a homomorphism is often not sufﬁcient. Algorithms able to exhibit
a homomorphism, or all homomorphisms from G to H, are needed. The present
chapter is devoted to this issue.
Before getting to the heart of the matter, let us discuss one point that may not be
central but cannot be ignored. A ﬁrst question arising when designing an algorithm
exhibiting a homomorphism is about the form of the output, i.e., about the con-
structed homomorphism. Basically, the output is a mapping from the source graph
G to the target graph H. Concerning the domain of this mapping, three cases can be
considered: (1) The domain is the set of concepts and relations in G; (2) the domain
is the set of relations in G; (3) the domain is the set of concepts in G.
Case (1) corresponds to the deﬁnition of a BG homomorphism. Case (2) is based
on the fact that the image of a relation determines the images of its arguments; if
135

136
6 Basic Algorithms for BG Homomorphism
G has no isolated concept nodes, a homomorphism is uniquely deﬁned by the re-
striction of its domain to relation nodes. In this case, the algorithms process isolated
nodes apart from other nodes. Case (3) considers that the images of the relations
are of no importance. It is sufﬁcient to know that a relation is preserved in the
image graph; the way it is specialized does not need to be memorized. This view
corresponds to the ordered hypergraph viewpoint of conceptual graphs, in which
concepts are nodes whereas relations are hyperedges. A homomorphism is then a
mapping from the nodes of the source hypergraph to the nodes of the target hyper-
graph, which preserves hyperedges (cf. Sect. 5.1.1).
We have seen that, if G and H are two BGs and g2h is the mapping translat-
ing BGs to hypergraphs, there might be exponentially fewer homomorphisms from
g2h(G) to g2h(H) than homomorphisms from G to H (cf. Sect. 5.1.1). Thus, in what
follows, we will focus on the hypergraph viewpoint and see the domain of a homo-
morphism as the set of concept nodes in the BG source. However the algorithms
presented in this chapter can be easily adapted for returning images for relations as
well, especially since they use propagation techniques that maintain sets of candi-
date images for concepts and relations.
6.1.1 Basic Backtrack Algorithms
H
T
T
s
1
2
G
T
x
2
1
s
T
T
T
y
z
t
a
T
b
c
1
r
r
s
2
1
3
2
1
3
2
There is one homomorphism from G to H: Π = {(x, a),(y, b),(z, c),(t, b)}
Fig. 6.1 Homomorphism
Let us take the classical backtrack scheme as the basis. This scheme consists of try-
ing to successively assign an image to each node of the source BG, while keeping
the following condition true: At a given step, after a certain number of assignments,
the assignments deﬁne a partial solution, i.e., a partial homomorphism. Let us re-
call that we only assign images to concept nodes, but the algorithms can be simply
extended to assign images to relations as well if desired.
Deﬁnition 6.1. A partial homomorphism from G to H is a mapping from a subset
C′ of CG to CH, which is a homomorphism from the subBG induced by C′ to H (the

6.1 Algorithms for BG Homomorphisms
137
subBG induced by C′ is the subgraph of G deﬁned by C′ and relations having all
their arguments in C′).
Example. In Fig. 6.1, f = {(x, a),(y, b),(z, a)} is a mapping from C′ = {x, y, z} to
CH that is not a partial homomorphism. Indeed, the image of the hyperedge (x,y,z)
in G is (a,b,a), which is not a hyperedge in H.
A partial homomorphism with C′ = CG is a homomorphism. Each assignment
of a concept node c has to fulﬁll the condition on labels: If c′ is assigned to c, then
lG(c) ≥lH(c′). After each assignment, it is checked whether this assignment is com-
patible with previous ones, i.e., whether the set of current assignments still deﬁnes
a partial homomorphism. If this is the case, an unassigned node (if any) is then con-
sidered; if all nodes have been successfully assigned, a solution has been found. If
the last assignment is not acceptable, another assignment is tried for c. If all candi-
date assignments for c have been tried without success, a backtrack is performed:
The algorithm comes back to the node which precedes c in the assignment order,
and tries a new assignment for this node, if any exists.
A backtracking search is classically seen as a depth-ﬁrst traversal of a search tree
representing all possible assignments. See Fig. 6.2 for a ﬁrst picture, and this ﬁgure
is discussed in detail in the example below.
t = c
t = b
t = a
t = c
t = b
t = a
y = c
y = b
y = a
z = b
z = a
x = a
z = c
y = c
y = a y = b
x = a
t = c
t = a t = b
Fig. 6.2 Backtracking search
In this tree, each node except the root corresponds to an assignment. The root has
level 0, an assignment occurring at level k is at depth k in the tree. Each path from
the root to a node at level k represents a partial mapping of k nodes. The algorithm
explores this tree, in a depth-ﬁrst search manner. A node is said to be visited by the
algorithm if the algorithm constructs the partial mapping from the root to this node.
The search tree visited by the algorithm is the subtree composed of all visited nodes.
Leaves of the visited search tree correspond either to solutions (the path of length
|CG| from the root to this node deﬁnes a homomorphism) or to dead-ends (the path
to the root to this node yields a mapping which is not a (partial) homomorphism).
All internal nodes deﬁne (strictly) partial homomorphisms.
Example. Let us consider Fig. 6.2, which pictures a part of the search tree explored
by the backtracking algorithm taking the input (G,H) in Fig. 6.1. The concept nodes

138
6 Basic Algorithms for BG Homomorphism
of G are assumed to be considered in the order z t x y, and those of H in the order
a b c. Dotted lines indicate parts of the tree explored by the algorithm (but not com-
pletely drawn). Crosses below leaves mark dead-ends and circles mark solutions. In
this example, there is only one solution; the corresponding assignments are written
in bold. The tree is explored in a depth-ﬁrst manner, from left to right: The ﬁrst
unassigned node considered is z; the ﬁrst assignment tried is z = a, then, for t the
values a, b and c are successively tried without success; the algorithm backtracks to
z and chooses the assignment z = b. The subtree rooted in z = b is explored without
success. The algorithm backtracks again to z and tries the only remaining choice for
z, i.e., z = c. The assignment t = a leads to a failure, thus another assignment for t
is tried, i.e., t = b. Finally, the single homomorphism is found.
Let us now consider the algorithm GenericBacktrack (Algorithm 1). It re-
turns the ﬁrst homomorphism found, if any exists, and otherwise a failure. Note that
the subalgorithms have access to the local variables and parameters of the main al-
gorithm. All further algorithms will be presented in the same way. The role of the
Preprocessing subalgorithm is to prepare the work for the GenericBasic
algorithm (Algorithm 2), which does the backtracking search itself. We present
this search in a recursive way, which is more “natural,” but improvements con-
trolling the way of backtracking (as outlined in Sect. 6.2.1) start mainly from
the iterative version. ChooseUnassignedNode returns an unassigned node.
ComputeCandidates(c) returns the set of possible images for c. Classical im-
plementations of these subalgorithms are given later (Table 6.1).
If all solutions are required, backtracks are performed until the search tree is
exhausted. The generic algorithm is slightly modiﬁed and yields GenericBack-
trackAllSolutions (see Algorithms 3 and 4). This algorithm returns the set
of all homomorphisms from G to H.
Algorithm 1: GenericBacktrack(G,H)
Input: BGs G and H
Output: a homomorphism from G to H if it exists, otherwise Failure
begin
Preprocessing()
return GenericBasic(∅) // see Algorithm 2
end
Several comments can be made concerning these generic algorithms. First, for
an efﬁciency purpose, each connected component in the source BG should be pro-
cessed by a separate call to the backtrack algorithm. Indeed, each connected com-
ponent deﬁnes an independent subproblem. Imagine, for instance, that G has two
connected components C1 and C2. If C2 is processed after C1 but in the same search,
the visited subtree corresponding to C1 will be repeated as many times as they are
successful leaves in the visited subtree of C2, whereas it would be built only once if
C1 and C2 were processed separately. It is thus assumed (but this is not mandatory)
in all backtrack algorithms that the source BG is connected.

6.1 Algorithms for BG Homomorphisms
139
Algorithm 2: GenericBasic(Sol)
subalgorithm of Algorithm 1
Input: a partial homomorphism Sol from G to H
Output: a homomorphism from G to H extending Sol if it exists, otherwise Failure
begin
if |Sol| = |CG| then
return Sol // a homomorphism has been found
else
c ←ChooseUnassignedNode()
candidates ←ComputeCandidates(c)
forall c′ ∈candidates do
Sol′ ←Sol ∪{(c, c′)}
if Sol′ is a partial homomorphism then
S ←GenericBasic(Sol′)
if S ̸= Failure then
return S // S is a homomorphism
return Failure // Sol cannot be extended to include c
end
Algorithm 3: GenericBacktrackAllSolutions(G,H)
Input: BGs G and H
Output: the set of homomorphisms from G to H
begin
Preprocessing()
SetOfSols ←∅
GenericBasicAllSolutions(∅) // see Algorithm 4
return SetOfSols
end
Algorithm 4: GenericBasicAllSolutions(Sol)
subalgorithm of Algorithm 3
Input: a partial homomorphism Sol from G to H
Output: adds to SetOfSols all homomorphisms from G to H extending Sol
begin
if |Sol| = |CG| then
add Sol to SetOfSols // a homomorphism has been found
else
c ←ChooseUnassignedNode()
candidates ←ComputeCandidates(c)
forall c′ ∈candidates do
Sol′ ←Sol ∪{(c, c′)}
if Sol′ is a partial homomorphism then
GenericBasicAllSolutions(Sol′)
end

140
6 Basic Algorithms for BG Homomorphism
Secondly, the order in which nodes are assigned has an inﬂuence on the size of
the subtree visited. Some orderings are obviously bad. If one successively assigns
t and x, and if t and x do not share any relation (as in Fig. 6.1, assuming that z has
not yet been visited), the algorithm will try all assignments on x independently of
those done on t. It is better after t to try a neighbor of t (like z in the Figure), since a
failure can be detected sooner. That is why nodes are often ordered by a traversal of
the BG (depth-ﬁrst search or a breadth-ﬁrst search for instance). This is done in the
preprocessing phase. Then, the ChooseUnassignedNode algorithm returns the
ﬁrst unassigned node following this order. The backtrack search shown in Fig. 6.2
corresponds to the ordering (z t x y), which can be obtained by a traversal from z.
Thirdly, the preprocessing step can be used to compute the set of a priori possi-
ble images for each concept node. Basically, a set of candidates, denoted by poss(c)
is assigned to each concept node c of CG, such that for any of these candidates
y, (c, y) is a partial homomorphism: poss(c) = {y ∈CH|lG(c) ≥lH(c)}. Then
ComputeCandidates(c) returns poss(c). Table 6.1 summarizes the above re-
marks by presenting classical implementations of the backtrack subalgorithms. Sim-
ilarly, a kind of preprocessing can be performed for relations, as we will see in the
next section.
Preprocessing()
1. compute OG = c1, ..., cn a total ordering on CG by a traversal
(depth-ﬁrst and breadth-ﬁrst search) of G
2. for all ci, compute poss(ci) = {y ∈CH|lG(ci) ≥lH(y)}
ComputeCandidates(c)
return poss(c)
ChooseUnassignedNode()
return c|Sol|+1
Table 6.1 Classical implementations of generic algorithms
Let us discuss another point about generic algorithms. After the assignment of a
node c, it has to be checked that the mapping is still a partial homomorphism, which
requires checking that the newly mapped relations (those which have c as argument
and all arguments assigned) are satisﬁed. More precisely, the order on CG induces
a partial order on RG. Let us say that a relation has rank i if its greatest argument
according to the order on concept nodes is ci. After the assignment of node ci, only
relations of rank i have to be checked. This is stated in the following property:
Property 6.1. Let π be a partial homomorphism from G to H, with its domain being
the subset C′ = {c1, ..., ci−1} of CG. Let c′ ∈CH. π ∪{(ci, c′)} is a partial homo-
morphism from G to H if and only if for each relation r(ci1,...,cik) of rank i in G,
there is a relation r′(π(ci1),...,π(cik)) in H with r′ less or equal to r.
Example. Let us consider again Figs. 6.1 and 6.2. With the order on the concept
nodes in G being z t x y, the rank of the relation s(z,t) is 2 (this relation is thus

6.1 Algorithms for BG Homomorphisms
141
checked after each assignment of t), and the rank of the relation r(x,y,z) is 4 (this
relation is thus checked after the assignment of all concept nodes). Taking relations
into account earlier would lead to earlier failure detection. For instance, as soon as
a has been assigned to z, it could be detected that the relation r(x,y,z) can no longer
be mapped. This issue will be discussed later (see Sect. 6.1.2.2).
In case the target BG is very big, or even cannot be globally accessed, the poss
sets can be computed during the search instead of before it. In this case, for k ≥1,
poss(ck) is computed by ComputeCandidates. Instead of CH, the considered
set is computed from the images of ck’s already mapped neighbors: It is basically
the set of concepts sharing at least a relation with these images.
If we replace nodes by variables and relations by constraints (see the transfor-
mation h2c in Chap. 5), we obtain a basic backtrack algorithm for Constraint Sat-
isfaction Problem (CSP) solving. Improvements of the backtrack scheme have been
extensively studied in the CSP community and several approaches for coping with
the problem complexity have been developed. We import some of them into the BG
framework in the next section.
6.1.2 Backtrack Improvements
The improvements proposed in this section are adapted from algorithmic techniques
developed for the CSP. We have selected techniques which are simple and yield
good results in practice (see Sect. 6.2 for further details). First, an adaptation of the
arc-consistency CSP notion, called edge-consistency, is presented. Then this notion
is integrated into the backtracking scheme, yielding a method for computing BG
homomorphisms similar to the forward-checking method for CSP.
Since this book is about conceptual graphs and not constraint networks, all no-
tions will ﬁrst be applied directly on BGs. Then, a whole section is devoted to the
presentation of their CSP counterpart. This section can be skipped by readers not in-
terested in constraint networks. However, readers interested in efﬁcient algorithms
on difﬁcult instances should check out this presentation to ﬁnd out how CSP tech-
niques can be exploited in the BG framework, as a prelude to a more in depth study
of these techniques.
6.1.2.1 Edge-Consistency
Edge-consistency is a necessary, but not sufﬁcient, condition for the existence of a
homomorphism. It will be used in the next section to limit the search space in the
backtracking procedure. Let G be the source BG and H be the target BG. A concept
or relation node x in G can be mapped by a homomorphism to a node x′ in H only if
lG(x) ≥lH(x′). Furthermore, a relation r in G can be mapped by a homomorphism to
a relation r′ in H only if the multi-edges incident to it are also multi-edges incident
to r′: If there are two edges labeled by i and j between r and a concept node c, then

142
6 Basic Algorithms for BG Homomorphism
there must be two edges labeled by i and j between r′ and a concept node c′. Let us
introduce two notations.
Deﬁnition 6.2 (Edge partition associated with a relation node). Let r be a re-
lation node of arity q. Pr is the partition on {1,...,q} (or equivalently, on the set
of edges incident to r) induced by the equality of arguments of r, i.e., i and j are
in the same class of Pr if the ith and the jth arguments of r are the same node. For
any c neighbor of r, Pr[c] denotes the class in Pr corresponding to c, i.e., the set of
numbers labeling edges between r and c.
Deﬁnition 6.3 (Corresponding neighbors). Let r and r′ be two relation nodes in
the same BG or in two different BGs having the same arity and let c be the i-th
neighbor of r (1 ≤i ≤arity(r)). The concept node c′ = corresponding(c,r,r′) is
deﬁned as the i-th neighbor of r′.
A relation node r can be mapped to a relation node r′ only if Pr is thinner than Pr′
(notation Pr ⊆Pr′), i.e., each class of Pr is included in a class of Pr′. When Pr ⊆Pr′,
given any neighbor c of r, c′ = corresponding(c,r,r′) is the unique neighbor of r′
that corresponds to c (i.e. Pr[c] ⊆Pr′[c′]).
A ﬁlter of (G,H) maps each concept c of G to a subset of candidate concepts for
c and each relation r of G to a subset of candidate relations for r.
Deﬁnition 6.4 (candidates and ﬁlters).
A candidate for a concept node c is a concept node c′ such that lG(c) ≥lH(c′).
A candidate for a relation r is a relation r′ such that lG(r) ≥lH(r′) and Pr ⊆Pr′.
Given two BGs G and H, a ﬁlter of (G,H) maps each x in CG +RG to a non-empty
subset of CH +RH of candidates for x. When (G,H) has at least a ﬁlter, the standard
ﬁlter of (G,H) is the maximal ﬁlter of (G,H): It maps each x in CG + RG to all of
its candidates in CH +RH.
The existence of a ﬁlter of (G,H) is a necessary condition for the existence of a
homomorphism from G to H. We are now interested in ﬁlters restricting the sets of
candidates without eliminating homomorphisms. These ﬁlters satisfy the following
properties. For any concept c in G, for any candidate c′ for c, and for any relation
neighbor of c, the partial homomorphism {(c,c′)} can be extended to a partial ho-
momorphism mapping the star graph of r (i.e., r and all its neighbors) to suitable
candidates. Furthermore, for any relation r in G, and for any candidate r′ for r, the
star graph of r can be mapped to the star graph of r′, i.e., for each neighbor c of r,
corresponding(c,r,r′) is a candidate for c. Such ﬁlters are called edge-consistent.
The existence of an edge-consistent ﬁlter of (G,H) is a necessary condition for the
existence of a homomorphism from G to H. The deﬁnition below is based on local
conditions on edges.
Deﬁnition 6.5 (edge-consistent ﬁlter). Given a ﬁlter f of (G,H),
• for a concept c in G, f(c) is edge-consistent if for each c′ ∈f(c), and for each
edge (c, i, r) in G, there is r′ ∈f(r) with an edge (c′, i, r′) in H;

6.1 Algorithms for BG Homomorphisms
143
• for a relation r in G, f(r) is edge-consistent if for each r′ ∈f(r), and for each
edge (c, i, r) in G, there is an edge (c′, i, r′) in H with c′ ∈f(c);
•
f is edge-consistent if for all x, f(x) is edge-consistent.
Note that if all f(r) are edge-consistent, the f(c) can be restricted to values given
by f(r) to obtain an edge-consistent ﬁlter. Indeed, edge-consistency does not restrict
the candidates of isolated nodes.
Example. Let us consider the BGs in Fig. 6.3, where f(c1) = {d1}, f(c2) = {e2},
f(r) = {r1,r2}. f(c1) and f(c2) are edge consistent, but not f(r): r1 ∈f(r) and
there is the edge (r,2,c2) but no edge (r1,2,e2) in H; the same kind of problem
occurs with r2 since there is no edge (r2,1,d1) in H.
e2
2
2
G
H
c1
r
c2
d2
r1
d1
1
1
1
2
r2
e1
f(c1) = {d1}, f(c2) = {e2} and f(r) = {r1,r2}
Fig. 6.3 A non-edge-consistent ﬁlter
Property 6.2. Let f be an edge-consistent ﬁlter of (G,H). Then, for each concept
node c in G, and each concept node c′ in f(c), the partial homomorphism (c,c′) can
be extended to any relation r adjacent to c and its neighbors (i.e., to the star graph
of r).
Proof. Let us denote by π the partial homomorphism from G to H deﬁned by:
π(c) = c′. Let (c,i,r) in G. One takes π(r) = r′, where r′ is any node in f(r) such
that (c′,i,r′) is in H (there is at least one such node). Now consider any concept
node d adjacent to r. There is a j with (d, j,r) in G (note that d may be equal to
c and in this case i = j). There is a only one edge incident to r′ and labeled by j
in H. One takes for π(d) the concept extremity of this edge, i.e., π(d) = Hj(r′)
(Fig. 6.4). Furthermore, if Gj(r) = Gk(r), then Hj(r′) = Hk(r′) since Pr ⊆Pr′, and
it is straightforward to check that π is a partial homomorphism from the star graph
of r to the star graph of r′.
⊓⊔
Given a ﬁlter of (G,H), making it edge-consistent can be seen as a closure oper-
ation (on the dual inclusion order between ﬁlters).
Deﬁnition 6.6 (Edge-consistent closure). The edge-consistent closure f ′ of a ﬁlter
f of (G,H) is the largest edge-consistent ﬁlter f ′ contained in f, more precisely:

144
6 Basic Algorithms for BG Homomorphism
f(d)
f(r)
f(c)
k
i
i
c
r
d
c’
r’
d’
i
j
j
π
π
π
k
Fig. 6.4 Local extension of a partial homomorphism (proof of Property 6.2)
•
f ′ is an edge-consistent ﬁlter of (G,H)
• for all x ∈CG ∪RG, f ′(x) ⊆f(x)
• for all a ∈f(x) \ f ′(x), there is no BG homomorphism from G to H mapping x
onto a
• there is no other edge-consistent ﬁlter f ′′ of (G,H) that contains f ′, i.e., such
that for all x ∈CG ∪RG, f ′(x) ⊆f ′′(x)
Property 6.3. The algorithm EdgeConsistency (Algorithm 5) computes the
edge-consistent closure of the standard ﬁlter of (G,H), if it exists.
Proof. (Hints) Let us say that a ﬁlter f of (G,H) is locally edge-consistent at r ∈
RG if it is edge-consistent for r and for all the neighbors of r. If a ﬁlter is locally
edge-consistent at each relation in G, then it is edge-consistent. Given a ﬁlter f,
CheckRelation(r) computes (if it exists) the largest ﬁlter included in f and
locally edge-consistent at r. The ﬁrst step consists of removing a relation r′ in f(r)
if, for a neighbor c of r, the concept corresponding(c,r,r′) is not in f(c). The second
step consists of removing a concept a in f(c) if c is a neighbor of r, such that there
is no r′ in f(r) with a = corresponding(c,r,r′). The EdgeConsistency(G,H)
procedure ﬁrst computes the standard ﬁlter of (G,H) then it makes this ﬁlter locally
edge-consistent for each relation. If for a relation r, CheckRelation(r) restricts the
candidate set of one of its neighbors c, all relations neighbors of c have to be checked
again. The algorithm terminates because each call to CheckRelation(r), which leads
to adding a relation to Q, removes at least one element in a concept candidate set.
⊓⊔
Property 6.4. The time complexity of EdgeConsistency(G,H) is in O(max
(|CG| × |CH|,mG × |CH| × mH)), thus O(mG × |CH| × mH) if G does not contain
isolated concept nodes.

6.1 Algorithms for BG Homomorphisms
145
Algorithm 5: EdgeConsistency(G,H)
Input: two normal BGs G and H
Output: the edge-consistent closure of the standard ﬁlter of (G,H) if it exists, otherwise
Failure
begin
// 1. compute the standard filter
foreach c in CG do
poss(c) = {c′ ∈CH|lG(c) ≥lH(c′)}
foreach r of RG do
poss(r) = {r′ ∈RH|lG(r) ≥lH(r′) and Pr ⊆Pr′}
// 2. make the filter edge-consistent
Tocheck ←RG
forall c in CG do
Changed[c] ←false
while ToCheck ̸= ∅do
Pick one relation r from ToCheck
result ←CheckRelation(r) // see Algorithm 6
if result = EmptyPoss then
return Failure
if result = Changed then
forall ri ̸= r such that there is c common neighbor of ri and r and
Changed[c]= true do
ToCheck ←ToCheck ∪{ri}
return poss
end
Proof. Step 1. Computing the standard ﬁlter takes |CG| × |CH| label comparisons
for the concept nodes. We assume that label comparison is in constant time. Con-
cerning partitions of the labels of edges incident to a relation, we assume that they
are stored in such a way that the concept node corresponding to an element of the
partition can be found in constant time (we can use, for instance, an array of size
k which, for each index i, refers to the node c extremity of the edge (r,i,c)). Com-
parison of the partitions of two relations with the same arity k can then be done
in O(k), which corresponds to the number of edges incident to each of these re-
lations. For a relation r, at most RH labels are compared with the label of r, and
since the partitions are compared only for relations with the same arity as r, we can
bound the time required for partition comparisons by mH. Thus, we obtain a time
complexity for the standard ﬁlter computation is in O(max(|CG|×|CH|,|RG|×mH).
Step 2. CheckRelation(r) can be implemented in mH. Assume that we use
vectors of size |CH| initialized with special values and used to mark the concept
nodes of CH. Different marks can be used for different uses. The ﬁrst step is done in
arity(r)× poss(r). As it is written, the second step can be very inefﬁciently carried
out. But it can also be performed as follows: For each relation r′ in poss(r), for each
neighbor a of r′, mark a in poss(c) where c is the corresponding neighbor for r.
Assume that we memorize the latest mark used to mark the nodes of a poss(c) set:
A node of H belongs to poss(c) if it is marked by this mark, otherwise it is not in

146
6 Basic Algorithms for BG Homomorphism
Algorithm 6: CheckRelation(r)
subalgorithm of Algorithm 5
Input: a relation r in G
Output: computes the edge-consistent closure of the star graph of r, if it exists, and marks
the concept nodes whose poss set has changed; returns EmptyPoss if a poss(c) has
been emptied, NoChange if no poss(c) has been modiﬁed, otherwise Changed
begin
// 1. remove from poss(r) values not supported by a
poss(c)
foreach concept c neighbor of r do
foreach r′ ∈poss(r) do
let a = corresponding(c,r,r′)
if a ̸∈poss(c) then
remove r′ from poss(r)
// 2. make the poss(c) edge-consistent
result ←NoChange
foreach concept c neighbor of r do
foreach a ∈poss(c) do
if there is no r′ ∈poss(r) such that a = corresponding(c,r,r′) then
remove a from poss(c)
if poss(c) = ∅then
return EmptyPoss
else
result ←Changed
Changed [c] ←true
return result
end
poss(c). The second step is thus done in O(arity(r)×|poss(r)|), which is bounded
by O(mH). Let us now count the number of total calls to CheckRelation. Each
time a candidate of a concept node c is removed, the adjacent relations are added to
the queue. A relation r can be added to the queue due to each of its neighbors, thus
arity(r) × |CH| times, where |CH| is a bound for the poss(c). The total number of
calls to CheckRelation is thus bounded by mG ×|CH|.
We obtain a total complexity of step 2 in O(mG ×|CH|×mH).
⊓⊔
The example in Fig. 6.5 proves that if (G,H) has an edge-consistent ﬁlter there
is not necessarily a homomorphism from G to H. Indeed, the standard ﬁlter is
f(c) = f(d) = f(e) = {a,b} and f(p) = f(q) = f(r) = {u,v} and this ﬁlter is
edge-consistent but there is no homomorphism from G to H. When the source BG
is acyclic, the local consistency deﬁned by edge-consistency implies global consis-
tency, i.e., the existence of a homomorphism. See Chap. 7 devoted to tractable cases
for further details.

6.1 Algorithms for BG Homomorphisms
147
1
2
2
1
v
u
b
a
H
G
c
d
e
p
q
r
1
2
2
1
2
1
All the concept (resp. relation) nodes have the same label
Fig. 6.5 Edge-consistency does not entail the existence of a homomorphism
6.1.2.2 Forward-Checking
Let us now integrate the edge-consistency check inside the backtrack algorithm.
This algorithm can be called in the preprocessing phase to reduce a priori the size
of the search space. It can also be used to reduce the size of the search tree dynam-
ically, i.e., during the search itself. The idea is to propagate the consequences of a
new assignment to the remaining non-assigned nodes, thus restricting their candi-
date sets, and possibly detect a failure sooner. More speciﬁcally, a consistency check
is performed after each assignment. If the check fails, another assignment has to be
tried for the same node, or the algorithm backtracks if all assignments have been
tried for this node. The consistency check itself can be more or less strong. It can
maintain edge-consistency for all nodes or only for nodes directly connected to the
newly assigned node. It can also achieve true edge-consistency, or check each con-
sidered star graph only once. A stronger check potentially prunes the search space
to a greater extent but is more expensive. The consequences of these choices are
investigated more thoroughly in the section about CSP (Sect. 6.2).
The algorithm presented here (Algorithm 7) performs a partial consistency check
and is considered as a good tradeoff between the pruning gain and the overhead cost.
It is an adaptation to BGs of the popular forward checking method for the CSP (more
precisely, the method nFC2 presented in Sect. 6.2).
First, a total ordering c1,...,cn is computed on CG by a traversal of G. Concept
nodes are processed according to this ordering. The homomorphisms (if any) are
built by extending a partial homomorphism deﬁned for c1,...,ck to a partial homo-
morphism deﬁned for c1,...,ck,ck+1 by using the following principle:
(BG FC consistency check): Apply edge-consistency on each relation connect-
ing the current node and at least one non-assigned node, in a single pass.
Example. Figure 6.6 illustrates the algorithm. It refers to the BGs in Fig. 6.1. Re-
calling the search tree explored by the classical backtrack (Fig. 6.2), it shows the
part explored by the forward checking algorithm (dotted lines). Initially, poss(z) =
{a, b, c}. As soon as a value is assigned to z, the consistency check considers both
relations related to z, and restricts all poss sets to one element at most.
Property 6.5. The algorithm AllHomomorphismsByFC(G, H) (Algorithm 7)
computes the set of all homomorphisms from G to H.

148
6 Basic Algorithms for BG Homomorphism
t = c
t = b
t = a
t = c
t = b
t = a
y = c
y = b
y = a
z = b
z = a
x = a
z = c
y = c
y = a y = b
x = a
t = c
t = a t = b
Fig. 6.6 Search tree explored by Forward Checking
Algorithm 7: AllHomomorphismsByFC(G,H)
Input: a source BG G and a target BG H
Output: the set of homomorphisms from G to H
begin
// preprocessing()
// 1. total ordering of CG
Compute OG = c1, ..., cn a total ordering of CG by a traversal of G
// 2. compute the standard filter
foreach c in CG do
poss(c) ←{c′ ∈CH|lG(c) ≥lH(c′)}
foreach r in RG do
poss(r) ←{r′ ∈RH|lG(r) ≥lH(r′) and Pr ⊆Pr′}
// 3. process relations with a unique neighbor
foreach r in RG with |Pr| = 1 do
let c be the neighbor of r
poss(c) ←poss(c)∩{c′|c′ has a neighbor in poss(r)}
if there is x in CG ∪RG with poss(x) = ∅then
return ∅
// 2 and 3 can be replaced by a call to
EdgeConsistency(G,H): if it fails, return ∅
SetOfSols ←∅
for level from 1 to n do
Removed[level] ←∅
RecFC(∅) // see Algorithm 8
return SetOfSols
end
Proof. (Hints) The classical implementations of the subalgorithms of the basic
backtrack (Table 6.1) are considered. The preprocessing step of AllHomomor-
phismsByFC involves: ﬁrst, computing a total ordering on CG; secondly, comput-
ing the standard ﬁlter of (G,H); thirdly, taking into account relations with a single
neighbor, i.e., either unary relations or relations with multi-edges to a single node.
Indeed, the consistency check would never consider them. In this case, the poss
set of a concept node c that is the single neighbor of relations is restricted to the
neighbors of the candidates for these relations.

6.1 Algorithms for BG Homomorphisms
149
Algorithm 8: RecFC(Sol)
subalgorithm of Algorithm 7
Input: a partial homomorphism Sol from G to H
Output: puts in SetOfSols all homomorphisms from G to H extending Sol
begin
k ←|Sol|
if k = |CG| then
add Sol to SetOfSols // a homomorphism has been found
else
inc(k)
c ←ck // ChooseUnassignedNode()
candidates ←poss(c) // ComputeCandidates(c)
forall y ∈candidates do
Sol′ ←Sol ∪{(c, y)}
poss(c) ←{y}
consistent ←true
forall relation r neighbor of c with at least an unassigned neighbor and while
consistent do
consistent ←checkRelationFC(r) // see Algorithm 9
if consistent then
RecFC(Sol′)
// all poss values suppressed due to the choice (c,y)
are restored
forall (x,y) in Removed[k] do
restore y in poss(x)
Removed[k] ←∅
poss(c) ←candidates // restore poss(c)
end
The backtrack is implemented in the recursive algorithm RecFC(Sol) (Algo-
rithm 8), where Sol is a partial homomorphism deﬁned for c1,...,ck. When k = n, a
solution, i.e., a homomorphism, has been computed. The algorithm tries to build an
extension of Sol to ck+1 by searching poss(ck+1) using the FC consistency check.
If it succeeds, it continues but otherwise it backtracks and restores all poss(x) to
the values they had before the extension attempt. For each level k of the tree, corre-
sponding to an assignment of y to ck, a table Removed[k] stores the values deleted
from poss sets due to this assignment (note that the values deleted from poss(ck)
due to the choice of y are not stored in Removed[k], since candidates stores the
value of poss(ck) before the assignment). This table is used to restore poss sets
when the algorithm comes back, and to choose another value for ck or to back-
track to level k −1; for the node ck itself, poss(ck) is restored with candidates.
The subalgorithm CheckRelationFC() (Algorithm 9) is similar to the subalgo-
rithm CheckRelation() in EdgeConsistency (Algorithms 6 and 5) except
that it checks only unassigned concept nodes. Since the consistency check is done
in a single step, this subalgorithm does not note which nodes have seen their poss

150
6 Basic Algorithms for BG Homomorphism
Algorithm 9: CheckRelationFC(r)
subalgorithm of Algorithm 8
Input: a relation r
Output: removes from poss(r) values not supported by a poss(c); returns true if no poss has
been emptied, otherwise false
begin
foreach concept c neighbor of r and rank(c) ≥k do
foreach r′ ∈poss(r) do
let a = corresponding(c,r,r′)
if a ̸∈poss(c) then
remove r′ from poss(r)
add (r,r′) to Removed[k]
// make all poss(c) edge-consistent with respect to
poss(r)
foreach concept c neighbor of r and rank(c) > k do
foreach a ∈poss(c) do
if there is no r′ ∈poss(r) with a = corresponding(c,r,r′) then
remove a from poss(c)
add (c,a) to Removed[k]
if poss(c) = ∅then
return false
return true
end
sets restricted; on the other hand, it stores suppressed values in Removed[k]. More
precisely, when calling CheckRelationFC(r), c1,...,ck−1 have been assigned,
and one checks if it is possible to extend this partial homomorphism by assigning
y to c = ck, and if so the consequences on poss are computed. r is a relation node
neighbor of c with at least one unassigned neighbor. Two searchs are executed over
neighbors of r. During the ﬁrst search, the relations r′ in poss(r) that do not sat-
isfy the edge-consistency condition are deleted from poss(r). One has to consider
the unassigned neighbors of r as well as the newly assigned concept node. For all
deleted r′, the pair (r,r′) is put into Removed[k] in order to be restored when back-
tracking. During the second search, for each unassigned node c neighbor of r, the
concepts a in poss(c) that do not satisfy the edge-consistency condition are deleted
from poss(c). For all deleted a, the pair (c,a) is put into Removed[k] in order to be
restored when backtracking. If a poss set is emptied, then the attempted extension
is impossible.
⊓⊔

6.2 Constraint Processing
151
6.2 Constraint Processing
6.2.1 A Panorama of Constraint Processing Techniques
This section presents an overview of main constraint processing techniques. Let us
ﬁrst mention that some of these techniques are at the heart of constraint processing,
such as constraint propagation, and have been essentially studied in this framework,
while others, such as tree decomposition, are known in various research areas (graph
theory, probabilistic reasoning, databases, etc.).
Constraint Propagation
The central concept of constraint processing is constraint propagation. This term
denotes a set of techniques for propagating the implications of a constraint on one
variable to other variables and constraints. Constraint propagation transforms the
original network into an equivalent network, i.e., with the same set of solutions, but
for which the search space is reduced. Basically, constraint propagation removes
hopeless values from variable domains, but it might also add new constraints. Con-
straint propagation can be seen as a kind of inference.
The basic idea is as follows: If there is a value d in a domain Di, and a con-
straint C including xi, such that d does not appear in the deﬁnition of C, then d can
be eliminated from Di since no solution can contain the assignment xi = d. This
elimination implies the elimination of all tuples containing d as a value for xi in
other constraints, thus in turn suppressions of values in other variables domains,
etc. When no more values can be removed from domains, and if no domain has
been emptied, one obtains a so-called arc-consistent network: Every assignement of
a value to a variable is consistent (relative to the constraints over this variable) and
can be extended with an assignment to another variable in a consistent way. Stronger
forms of consistency can be deﬁned. Generally speaking, constraint propagation en-
sures local consistency, which is more or less local depending on the strength of the
constraint propagation.
Constraint propagation can be used as a ﬁltering technique in the preprocessing
phase. In this case it reduces the size of the a priori search space. It can also be used
during the search to dynamically reduce the size of the search tree. Once an assign-
ment has been chosen, the idea is to propagate the consequences of this assignment
(which can be seen as a restriction of the domain of the assigned variable to exactly
one value) in order to detect failures sooner. A crucial point is that the constraint
propagation should take signiﬁcantly less time than exploring the parts of the tree
avoided by the check. So a trade-off has to be found between the strength of the
consistency check and the complexity of its computation.

152
6 Basic Algorithms for BG Homomorphism
Backtrack Improvements
More generally, most strategies for improving the backtrack algorithm can be di-
vided into the so-called look-ahead and look-back schemes: The ﬁrst ones are con-
cerned with going forward to extend the current partial solution, while the others are
concerned with going back in case of a failure (i.e., when the current partial solution
conﬂicts with every possible value of the next variable).
The look-ahead techniques address the following questions: Which variable
should be assigned next, and which value should be tried for this variable? What
are the implications of the chosen assignment for the remaining unassigned vari-
ables? In the basic backtrack algorithm, variables are assigned according to a static
order. But a natural idea is to choose a variable which restricts future searches as
much as possible since all variables have to be ultimately assigned. This leads to the
“most contrained variable” choice, which consists in choosing a variable with the
smallest remaining domain; a companion heuristic to break ties is the “maximum
degree variable,” which consists in choosing a variable that is involved in the largest
number of constraints containing unassigned nodes. The choice of the next value
to assign is important if we do not search for all solutions (otherwise we have to
consider all values anyway so all orders will do). The idea here is to choose a value
that constrains as little as possible future assignments for the still unassigned vari-
ables. The “least constraining value” heuristic selects a value that constrains future
assignments for the still unassigned variables as less as possible, in other words a
value that removes the fewest values for the neighboring variables.
Look-back techniques aim at preventing the construction of the same hopeless
partial solution. After a failure, the basic backtrack algorithm comes back to the
previous variable following the assignment order so as to try another value for this
variable. It is called “chronological” backtracking because it comes back to the most
recent assigned variable preceding the dead-end. This way of backtracking may
lead to rediscovering the same dead-end. Indeed, let xi be the variable for which no
consistent assignment can be found; the algorithm backtracks to xi−1. Assume xi−1
has remaining values to try. Now, if no constraint relates xi and xi−1, xi−1 has no
role to play in the failure to instantiate xi. The same hopeless values will be tried
again for xi, and this for each remaining value for xi−1. The idea of the so-called
“backjumping” techniques is to come back to a variable, for which we know that it
is not responsible from the failure.
Decomposition of the Network
For many problems, tree structures allow for efﬁcient solving. This is the case for
CSP: When the constraint network has a tree structure, there is a greedy way of in-
stantiating variables, which allows one to ﬁnd a solution, if any exists, in polynomial
time. Relying on the fact that the tree case is easy to solve, the idea is to decompose
the problem structure into a tree.

6.2 Constraint Processing
153
A simple method consists of “cutting cycles.” A subset of variables is extracted
so that the remaining network has no cycle. This subset, called a “cycle cutset,”
deﬁnes a subproblem restricted to these variables, their domains and constraints
with scope in this cutset (let us consider here that constraints are binary, which
allows us to cluster constraints into constraints with scope included in the cutset and
constraints with one variable in the cutset at most). Then, if we have a solution to
this subproblem, it is easy to check whether this solution can be extended to the
whole network, since the remaining network to check is a tree. The idea is thus to
enumerate solutions to the subproblem and check each of them. The algorithm is
exponential in the size of the cutset, since in the worst case all assignments of this
subset have to be tried. Thus if the network is “nearly” a tree, then the cutset will
be small, and this method will be efﬁcient. Finding a smallest cutset is an NP-hard
problem, but efﬁcient approximation algorithms (thus bringing a cutset not much
bigger than a smallest one) are known.
Another family of very general methods used in various research areas is tree
decomposition. These techniques aim at decomposing a structure (e.g., a constraint
network) into a set of substructures as small as possible, whose “intersection” yields
a tree structure, or more generally a hypertree. The precise deﬁnition of a tree de-
composition will be given in Chap. 7. The algorithm is exponential in the size of the
biggest substructure. This size is related to the so-called treewidth of the graph, or
the hypertreewidth of the hypergraph. Unfortunately, ﬁnding a decomposition with
the minimal treewidth or hypertreewidth is NP-hard.
Next Steps
We will ﬁrst focus on constraint propagation, based on the simplest local consis-
tency, i.e., arc-consistency, which we have translated into edge-consistency in the
BG framework. As already explained, this technique can be used in the preprocess-
ing phase or during a search to improve the basic backtrack algorithm. Next, we will
describe a look-ahead algorithm, called forward-checking, which performs the most
limited form of constraint propagation after each assignment: an arc-consistency
check in the neighborhood of the new assigned node. Why these choices? The
challenge when improving the basic backtrack is to ﬁnd a trade-off between the
reduction of the search tree and the overhead introduced by search tree pruning
techniques. For “easy” instances, it is not worthwhile to develop strong consistency
techniques. Arc-consistency as a basic technique seems to be appropriate.
Note that most improvements have been tailored for binary networks. Indeed,
arguing that an n-ary network can always be transformed into an equivalent binary
network (equivalent in the sense that it has the same set of solutions modulo the
transformation), most research has focused on the binary case. The two prevalent
transformations correspond to classical transformation from hypergraphs to graphs,
the incidence bipartite graph (or hidden graph), see Sect. 5.1.1 and the dual graph
(presented in Sect. 7.3) [BCvBW02]. However, these transformations generate new
variables, which make algorithms designed for binary networks inefﬁcient (see for

154
6 Basic Algorithms for BG Homomorphism
instance the discussion in [BMFL02]). The efﬁcient generalization of techniques
developed for binary networks to n-ary networks is an ongoing study in the CSP
community. This issue is particularly relevant to BGs and we will keep it in mind
throughout the next sections.
We now ﬁrst present the notions of arc-consistency and forward-checking as in-
troduced for CSP. The translation is not always as direct as one could imagine. It is
essential to pay attention to “details,” which nevertheless are important for correct-
ness. For instance, as pointed out in the transformation b2c (Sect. 5.4), a variable
can occur at most once in a constraint, while a single concept node can occur several
times in the argument list of a relation.
6.2.2 Arc-Consistency
We recall in this section the so-called arc-consistency technique, in order to clarify
how this technique has been translated into the edge-consistency notion studied pre-
viously. Arc-consistency, as its name suggests, was ﬁrst deﬁned for binary networks.
The word “arc” refers to a directed edge in the constraint graph. The idea is as fol-
lows. Given a binary constraint C on x and y, the arc (x,y) is consistent if for each
value in the x domain there is a value in the y domain which is consistent for C. The
network is arc-consistent if all of its arcs are consistent. Note that for a constraint
C on x and y, both directions (x,y) and (y,x) have to be checked: the subnetwork
restricted to C is consistent if and only if (x,y) and (y,x) are both consistent. This
view of arc-consistency in terms of domains yields a direct generalization to the
n-ary case.
Let us note however that this way of passing from the binary to the n-ary case is
not the only possible one (see for instance the “pairwise consistency” presented in
Chap. 7).
Deﬁnition 6.7 (arc-consistency). Given a variable xi in the scope of a constraint Cj,
a value d of the domain Di of xi has a support in Cj if d appears in Rj as a possible
value for xi, i.e., there is a tuple t in Rj such that t[xj] = d. t is called a support for the
assignment xi ←d. A domain Di is arc-consistent relative to a constraint Cj having
xi in its scope if (1) it is not empty (2) for all d ∈Di, d has a support in Cj. Given a
constraint network P, a domain Di is arc-consistent if it is arc-consistent relative to
all constraints in P. P is arc-consistent if all its domains are arc-consistent.
Alternatively, arc-consistency can be deﬁned on constraints: A constraint Cj is
arc-consistent if all the domains of all its variables are arc-consistent relative to
it. A CSP is arc-consistent if all its domains are non-empty and all constraints are
arc-consistent.
It is implicitly assumed that constraints are deﬁned over the current domains:
If a value is removed from a domain during the consistency check, in constraint
deﬁnitions all tuples containing this value have to be removed (actually tuples are
physically removed only if constraints are deﬁned in extension, which is our case).

6.2 Constraint Processing
155
Thus a network is arc-consistent if and only if no domain is empty and for each
variable xi and also for each constraint Cj involving xi, Di = Rj[xi].
a  b  c
c  c  c
a  b  c
b  a  c
  x   y   z
  y   z   u
c  c  c
C2
C1
C3
a  a  a
Dx = Dy = Dz = Du = Dv= {a,b,c}
c c
a b
a  a
u   v
a  a  b
Fig. 6.7 A non-arc-consistent network
Example. The network in Fig. 6.8 is arc-consistent. The network in Fig. 6.7 is not
arc-consistent. None of the constraints is arc-consistent. Consider for instance C1:
Dz = {a, b, c} is not arc-consistent since the b value has no support in C1. Now, if
this value is suppressed from Dz, C1 becomes arc-consistent. Note that this supres-
sion leads to the removal of the tuple (a b c) in C2.
A network being arc-consistent does not ensure that it is globally consistent (see
for instance Fig. 6.8). But it has no solution if it cannot be made arc-consistent.
Before entering into the details of the arc-consistency computation, let us men-
tion that stronger forms of consistency have been deﬁned. Generally speaking, local
consistency can be extended to subnetworks on k variables. A partial instantiation
(i.e., an assignment of a subset of variables) is consistent if it satisﬁes all constraints
whose scope contains no uninstantiated variables. A CSP is said to be k-consistent
if any consistent assignment of (k −1) variables can be extended to any other kth
variable. 1-consistency is obtained if each variable has a non-empty domain. For bi-
nary networks, 2-consistency is arc-consistency. For binary networks, 3-consistency
is the consistency called path-consistency.
x3
x2
x1
a
b
b
a
x1     x2
C1
a
b
b
a
x1     x3
C2
a
b
b
a
x2     x3
C3
Fig. 6.8 A 2-consistent but not 3-consistent network
For instance the binary network in Fig. 6.8 is 2-consistent but not 3-consistent:
e.g., for the assignment {(x1, a),(x2, b)}, which is consistent as it satisﬁes the con-
straint C1 with scope {x1, x2}, there is no consistent value for x3: the assignment

156
6 Basic Algorithms for BG Homomorphism
(x3, a) satisﬁes C3 but not C2, and conversely for the assignment (x3, b). A network
is strongly k-consistent if it is j-consistent for all j ≤k. If the network has n vari-
ables and is strongly n-consistent, then it is consistent. Of course there is no miracle:
Algorithms to make a network k-consistent are exponential in k in the worst case.
Arc-consistency appears to be a good tradeoff between the strength of the consis-
tency check and the computation time of this check.
If the operation of repeatedly suppressing domain values without support in a
constraint, until achieving stability, does not lead to a failure, only one arc-consistent
network is obtained. More precisely, the arc-consistent closure of P is the network
P′, deﬁned as follows:
• P′ has the same set of solutions as P,
• P′ is arc-consistent,
• for all domain D′i of P′, D′i ⊆Di,
• there is no network P′′ equivalent to P which is arc-consistent and strictly con-
tains P′ (with respect to domain containment).
P′ is thus the maximum subnetwork of P, obtained by restricting domains,
equivalent to P and arc-consistent. A family of algorithms for computing the arc-
consistent closure of a network have been designed. They go from AC-1, the brute-
force one [Mac77], to AC-7 [BFR95]; all of these algorithms have been designed
for binary networks.
The algorithm ArcConsistency (Algorithm 10) is basically AC-3 [Mac77]
adapted to n-ary constraints. It maintains a list (ToCheck) of all constraints whose
consistency has not been checked yet or must be checked again because the domain
of at least one of their variables has been modiﬁed. It stops either with a failure (a
domain has been emptied), or with the arc-consistent closure of the network (in this
case ToCheck is empty). The subalgorithm CheckConstraint (Algorithm 11)
takes a constraint C as input and restricts the domains of its variables to make them
arc-consistent (if possible). More precisely, it computes the arc-consistent closure
of the network restricted to C. Variables whose domain has changed are marked to
be taken into account in the main algorithm.
Example. Let us consider the network in Fig. 6.7. Let ToCheck initially contain
{C1, C2, C3}. The following constraint checks are done:
• Check of C1: there is no support for the assignment z ←b, thus b is removed
from Dz; Dz = {a,c}. C2 would have been inserted into the queue if not already
present.
• Check of C2: the tuple (a, b, c) no longer exists; Dy = {a, c}, Dz is unchanged
and Du = {b,c}. C1 is inserted into the queue (and C3 would have been if not
already present).
• Check of C3: the tuples (a, a) and (a, b) no longer exist; Du = Dv = {c}. C2 is
inserted into the queue. Now ToCheck contain [ C1, C2 ].
• Check of C1: the tuple (a, b, c) is removed; no domain is modiﬁed.
• Check of C2: the tuple (a, a, b) no longer exists; Dy = Dz = {c}. C1 is inserted
into the queue.

6.2 Constraint Processing
157
Algorithm 10: ArcConsistency(P)
Input: a constraint network P = (X,D,C)
Output: computes the arc-consistent closure of P if it exists, otherwise returns Failure
begin
Tocheck ←C
while ToCheck ̸= ∅do
pick one constraint Ci from ToCheck
forall variable x of Ci do
Changed[x] ←false
result ←CheckConstraint(Ci)// see Algorithm 11
if result = EmptyDomain then
return Failure
if result = Changed then
forall Cj ̸= Ci such that there is x ∈Ci ∩Cj and Changed[x] = true do
ToCheck ←ToCheck ∪{Cj}
end
Algorithm 11: CheckConstraint(Ci)
subalgorithm of Algorithm 10
Input: a constraint Ci
Output: makes Ci arc-consistent if possible and marks variables whose domain has
changed; returns EmptyDomain if a domain has been emptied, NoChange if no
domain has been modiﬁed, otherwise Changed
begin
// remove from Ci values which have been suppressed from
domains
foreach variable x of Ci do
remove from Ci every tuple t with t[x] ̸∈D(x)
// make domains arc-consistent with respect to Ci
result ←NoChange
foreach variable x of Ci do
foreach v ∈D(x) do
if v ̸∈Ci[x] then
// v has no support in Ci
remove v from D(x)
if D(x) = ∅then
return EmptyDomain
else
result ←Changed
Changed[x] ←true
return result
end

158
6 Basic Algorithms for BG Homomorphism
• Check of C1: the only remaining tuple is (c, c, c) thus Dx = {c}. The queue is
empty. The network is now arc-consistent with Dx = Dy = Dz = Du = Dv = {c}.
Note that these values deﬁne the only solution to the network.
Property 6.6. The time complexity of this algorithm is in O(m×c×dc+2) where m
is the number of constraints, c the maximal arity of a constraint and d the maximal
size of a domain.
Proof. The complexity of CheckConstraint(Ci) is O(d ×t), where d is the
maximum size of a domain of a variable in the scope of Ci and t is the number of
tuples in Ci, since each value in a domain Dx is compared in the worst case to each
tuple of Ci. t is bounded by dc where c is the arity of Ci. Each time a domain of a
variable x is modiﬁed, the constraints on x are added to the queue. A domain can be
modiﬁed at most d times (since each time a value is removed). A constraint can be
added to the queue due to each of its variables, thus c × d (actually min(c × d,t)).
The number of calls to CheckConstraint is thus bounded by m×c×d. Hence,
an upper bound for the whole algorithm is m×c×dc+2.
⊓⊔
The arc-consistency algorithms from AC-4 to AC-7 yield a better worst-case
complexity. However, AC-3 has the advantage of being independent of the speciﬁc
data structure which would have to be maintained in later algorithms. In addition,
AC-3 is almost better than its successor AC-4 in practice (as shown in [Wal93]).
The connection with BG edge-consistency is straightforward. Indeed, poss(c),
for a concept c, can be viewed as a variable domain, and poss(r), for a relation r,
can be viewed as a constraint deﬁnition (if one does not want to assign images to
relations, instead of having relations in poss(r), one can have the lists of arguments
of these relations, which is close to a constraint deﬁnition).
When the original ﬁlter is the standard ﬁlter, the edge-consistent closure corre-
sponds exactly to the arc-consistent closure of the corresponding constraint network,
as expressed by the following property. Recall that h2c is the transformation from
the BG-HOMOMORPHISM problem to the CSP, and c2h is the transformation in the
converse direction (Chap. 5).
Property 6.7.
• (h2c) Let G and H be normal BGs. Let poss be the standard ﬁlter of (G,H). If its
edge-consistent closure poss′ exists, then the arc-consistent closure of h2c(G,H)
exists, and is obtained by restricting the domains of variables according to poss′:
for each x ∈X, Dx = {h2c(poss′(c))|x = h2c(c)}; otherwise the arc-consistent
closure of h2c(G,H) does not exist either.
• (c2h) Let P be a constraint network. If its arc-consistent closure P′ exists, then the
edge-consistent closure of the standard ﬁlter of c2h(P) exists and is exactly the
standard ﬁlter of c2h(P′); otherwise the edge-consistent closure of the standard
ﬁlter of c2h(P) does not exist either.

6.2 Constraint Processing
159
6.2.3 Forward Checking
In the so-called look-ahead schemes, a consistency check is performed at each new
instantiation, to evaluate the consequences of this assignment on the domains of
unassigned variables. Note that in some presentations of look-ahead algorithms this
check is considered to be performed just after an assignment, while in others it is
done just before an assignment, in order to guide the choice of a value to assign; any-
way, the same actions are done by the algorithms. If we adopt the ﬁrst formulation,
the consistency check can be added to the backtrack algorithm as follows:
(Look-ahead) After assigning the current variable, apply the consistency check.
If successful, continue; otherwise, try another assignment for this variable or back-
track if all assignments have been tried.
This consistency check can be more or less complete. The so-called really full-
look-ahead algorithms maintain true arc-consistency on the current network, i.e., the
network in which the domain of each instantiated variable is reduced to its instanti-
ation. The popular forward-checking (FC) algorithm performs a partial consistency
check considered as a good tradeoff between the pruning gain and the overhead cost.
We will consider this algorithm now.
In what follows, the current variable is the variable just assigned; a past vari-
able is a variable already assigned (the current variable is thus a past variable); a
future variable is a variable not yet assigned. FC was designed by [HE80] for bi-
nary networks. We will denote this algorithm bFC, and nFC its generalization to
n-ary networks. The idea of bFC is to remove from the network all values directly
incompatible with the last assignment. In other words, a future variable cannot have
its domain inconsistent with a past variable. The consistency check performed by
FC() is thus as follows:
(bFC consistency check(1)) Apply arc-consistency on the set of constraints con-
necting one past variable and one future variable.
In the binary case, this check can be very efﬁciently implemented since it sufﬁces
to consider the current variable instead of all past variables and the arc-consistency
check can be done in a single step (thus considering each constraint only once, in
any order). Indeed, let xi be the current variable. Let xp be another past variable,
p < i, and xf be a future variable, f > i. At each instant, the consistency check
ensures that the current partial solution can be extended with an assignment of any
variable, without conﬂicting with already assigned variables. Indeed, if a constraint
has scope {xi,xp} or {xp,xf }, previous consistency checks ensure that it is satisﬁed.
Thus only constraints with scope {xi,xf } have to be checked, possibly reducing Dx f .
(bFC consistency check(2)) Apply arc-consistency on the set of constraints con-
necting the current variable and one future variable, in a single step.
In the n-ary case, the equivalence between the two consistency checks no longer
holds, basically because a constraint with a past variable can have more than one
future variable. Several alternatives hold, which are exhibited in [BMFL02]. The
bFC algorithm can be generalized in different ways depending on the answers to two
questions: (1) when is a constraint checked: when it has at most one uninstantiated
variable or when at least one of its variables is instantiated? The alternatives are as

160
6 Basic Algorithms for BG Homomorphism
follows. Constraints checked might be those connecting at least one past variable
and at least one future variable, or connecting the current variable and at least one
future variable, or the current variable and exactly one future variable (it can be
shown that the option at least one past variable and exactly one future variable is
equivalent to the last one). (2) is arc-consistency computed in a single step (each
constraint is made arc-consistent once) or is true arc-consistency achieved on the
subnetwork considered (which might require multi-steps)?
Let us say that the propagation is immediate if it considers constraints as soon
as one of its variables is instantiated, otherwise it is delayed (it is considered when
all its variables but one has been instantiated). It is local if it considers only con-
straints connecting the current variable, and global if it considers all constraints
with at least one past variable. Finally, it can be done in one step if each constraint
is checked once, or in multi-steps enforcing true consistency on the considered set
of constraints.
Several algorithms can be deﬁned by combining these criteria. The reader is
referred [BMFL02] for an experimental comparison of these algorithms. A good
tradeoff between the pruning effect and the overhead cost is the so-called nFC2
algorithm, with uses local propagation in a single step:
(nFC2 consistency check): Apply arc-consistency on each constraint connecting
the current variable and at least one future variable, in a single pass.
C1
C2
C3
x
z
b a c
a b c
c
c
c
a
a b
a
a
 b c
a
 b
a b c
a
a b
a b c
a b c
a b c
a b c
Dv
Du
Dz
Dy
Dx
a
a
a
 b
a b c
a
a
nFC0
nFC2(1) nFC2(2)
a b c
nFC3
After assignment (y,a)
Dx = Dy = Dz = Du = Dv= {a, b, c}
c c
a b
a a
u v
y
a
y
u
c c c
a b c
a
b
z
a
nFC0: delayed local propagation
nFC2: immediate local propagation in one step,
checking C1 before C2 (nFC2(1)), or in reverse order (nFC2(2))
nFC3: immediate local propagation in multi-steps
Fig. 6.9 n-ary Forward Checking

6.3 Label Comparison
161
Figure 6.9 illustrates the behavior of several alternative algorithms. It again con-
siders the network in Fig. 6.7. Note the arc-consistency closure of this network re-
stricts it to the single solution. But let us assume here that the network is not made
arc-consistent before launching the forward-checking algorithm. In the ﬁgure, the
different ﬁlterings obtained with three variants are shown when y is instantiated with
a. The delayed propagation (nFC0) does not perform any ﬁltering. The immediate
local propagation checks arc-consistency of C1 and C2. nFC2 does the check in one
step and performs a better ﬁltering if C1 is considered before C2. nFC3 does the
check in multi-steps (enforcing arc-consistency on the network restricted to C1 and
C2).
The forward-checking algorithm (AllHomByFC(G,H), Algorithm 7) for ex-
hibiting BG homomorphisms corresponds to the nFC2 strategy.
6.3 Label Comparison
A BG is a graph with a speciﬁc labeling. Thus, a BG homomorphism is a mapping
with two fundamental properties: one dealing with the graph structure, the other
concerning the node labeling. One could say that a BG homomorphism is a dou-
ble homomorphism: It is a (graph) homomorphism for the structure and an (order)
homomorphism for the ordered label sets. The fundamental operation for order ho-
momorphisms is the comparison of two labels. In previous algorithms (Sect. 6.1),
we considered the label comparison as an operation that is computable in constant
time. This section studies its actual complexity, which is related to the data struc-
tures implementing the orders on concept and relation types.
Whenever the type sets are small, comparison between labels takes only a short
time relative to the total time needed for computing the structural part of a BG
homomorphism. When the label sets are large (e.g., when the concept type set cor-
responds to the concepts of a natural language, it can have hundreds of thousands
of items), it is then useful to implement a reasonable data structure to allow quick
computing of the comparison between labels.
We will ﬁrst brieﬂy present classical data structures for representing orders and
simple algorithms for comparing two elements. We will also mention related prob-
lems on orders. In this section, the classical generic notation ≤is used to denote
an order, < denotes its associated strict order and ≺denotes its associated covering
relation. Numerous speciﬁc orders have been studied: interval orders, bipartite or-
ders, lattices, distributive lattices, etc. [Moh89]. We will retain two classes that are
especially important in knowledge representation: trees and lattices. Tree orders are
very often used for representing taxonomic knowledge. We will present a speciﬁc
coding for tree orders, which is both very simple and efﬁcient [Bou71]. When any
two types have a least upper bound (lub) and a greater lower bound (glb) then the
order is a lattice. Lattices are encountered especially when sets of concept types
are built by Formal Concept Analysis techniques [GW99]. Speciﬁc techniques have
been developed when orders are lattices (e.g., [HHN95], [HNR97], [TV97]).

162
6 Basic Algorithms for BG Homomorphism
During the knowledge acquisition phase, especially during construction of the
type sets, the ordering is generally given by a set U of comparable type pairs, i.e.,
by a directed graph on the type set. If this set U is hand-built, then some errors may
occur, namely circuits may be constructed. Detecting circuits in a directed graph is
a simple problem that can be efﬁciently solved (e.g., [CLRS01]), and we suppose
in the sequel that U has no circuit. U may contain transitivity arcs, i.e., arcs (t, t′)
such that there is in U a path of length greater than 1 from t to t′. The order relation
≤is equal to the transitive and reﬂexive closure of U denoted by U∗i.e., t ≤t′ if and
only if (t′,t) ∈U∗. Thus, when U∗is provided, the comparison problem is reduced
to a membership problem. At the other end, the minimum information needed to
compare two elements of an ordered set is given by the covering relation of the
order. Going from the transitive closure to the transitive reduction, the comparison
problem goes from a membership problem in U∗(the maximal representation of the
order) to a path existence problem in Uh (the minimal representation of the order).
In Fig. 6.10 two directed graphs G = (X,U) and G′ = (X,U′) are drawn. They
have the same transitive reduction (X,Uh) and the same reﬂexo-transitive closure
(X,U∗), thus they deﬁne the same order.
6
5
4
3
2
1
U
U’
U
U*
h
7
Fig. 6.10 Transitive reduction and reﬂexo-transitive closure

6.3 Label Comparison
163
6.3.1 Basic Data Structures and Algorithms
There are numerous techniques for coding an ordered set. In [Thi01] for instance,
a dozen codings are studied, including the three basic techniques that are recalled
below, and about twenty other ones are cited. The three basic data structures for
representing orders are: the incidence matrix, the lists of descendants (and/or ascen-
dants), the lists of successors (and/or predecessors). In what follows, n denotes the
cardinality of the ordered set, i.e. n = |X|.
1. Incidence Matrix
Let us suppose that the elements of X are x1,...,xn. The incidence matrix of
(X,≤) is the n×n boolean matrix M, such that M[i, j] = 1 if and only if xi ≤xj,
and 0 otherwise. This coding has a size of n2 bits and the comparison between
two elements can be done in constant time since it corresponds to an access to an
element of the matrix. Whenever a set is represented by its characteristic vector,
the membership problem is reduced to an access to an element of this vector. The
i-th line of M can be seen as the characteristic vector of the set of descendants
of xi, so the incidence matrix can be seen as the characteristic vector of the set
of pairs of comparable elements. It can be proven that under the assumption of a
uniform distribution of the orders over a set X the incidence matrix is asymptoti-
cally optimal in space [Thi01] and we just saw that this coding is optimal in time
for the comparison problem. Thus, whenever the ordered sets are not very large
(if n = 3000 about one megabyte is needed), and there is no speciﬁc information
about the orders, and the problems to solve are based on the comparison prob-
lem, then the incidence matrix is an efﬁcient coding. The following table shows
the incidence matrix representation of the order deﬁned in Fig. 6.10.
1 2 3 4 5 6 7
1 1 1 1 0 1 0 1
2 0 1 1 0 1 0 1
3 0 0 1 0 1 0 1
4 0 1 1 1 1 1 1
5 0 0 0 0 1 0 0
6 0 0 0 0 0 1 1
7 0 0 0 0 0 0 1
2. Lists of Descendants
Instead of representing a set (of couples) by its characteristic vector, it can be
represented by the list of its elements. More precisely, to any element xi ∈X is
associated the list of its descendants, i.e., the elements xj such that xj > xi. If
the order has few comparable elements, then this coding is small in size: It is
in O(|U∗| × log(n)) bits. But comparing two elements requires searching a list,
which can be of length n. This can be improved by sorting the elements of the
list because searching an element in a sorted list L is in O(log(size(L))), in our
case in O(log(n)).

164
6 Basic Algorithms for BG Homomorphism
The descendant list representation of the order in Fig. 6.10 is:
1 : 1,2,3,5,7
2 : 2,3,5,7
3 : 3,5,7
4 : 4,2,3,5,6,7
5 : 5
6 : 6,7
7 : 7
3. Lists of Successors
To any element xi ∈X is associated the list of its successors, i.e., elements xj
such that xj ≺xi. This coding is a representation of the covering relation of the
order. It is the coding with the smallest size among the three classical codings:
Its size is in O(|Uh|×log(n)) bits. But comparing two elements might require a
search of the whole structure and thus is in O(|Uh|).
The successor list representation of the order in Fig. 6.10 is:
1 : 2
2 : 3
3 : 5,7
4 : 2,6
5 :
6 : 7
7 :
If the ordered set is very large, then a variant of the lists of successors is probably
a good choice. There are a lot of variations using these basic structures. For instance,
the time for comparing two elements can be improved by a cache technique for the
last pairs of elements compared, and the incidence matrix or the lists of descendants
can be used for structuring the cache itself.
6.3.2 Related Problems
Let us mention some related problems dealing with graphs and orders. These prob-
lems are deﬁned for general graphs, and we discuss their application to the particular
case of orders, when this particular case yields speciﬁcities.
1. Connected Components
The decomposition of (X,U∗), or equivalently of (X,Uh), in connected com-
ponents can simplify problems concerning orders since two elements are com-
parable only if they belong to the same connected component. There are sim-
ple and efﬁcient algorithms for computing connected components of a graph

6.3 Label Comparison
165
(e.g., [CLRS01]). Other decompositions can be useful for studying ordered sets,
e.g., the decomposition into modules (e.g., [Pau98]).
2. Transitive Closure
When a graph is represented by its incidence matrix, computing its transitive
closure is equivalent to the computation of a product of matrices. More precisely,
the transitive closure of a graph of size n can be computed in O(na) if and only
if the product of two matrices of size n×n can also be computed in O(na). The
well-known Roy-Warshall algorithm is in O(n3) (in [CW87] an algorithm with
a = 2.376 is proposed). With the lists of descendants or of successors, a simple
algorithm performs a depth-ﬁrst search from each vertex keeping track of all
vertices encountered. This algorithm is in O(n×(n+m)) where m is the number
of arcs of the representation (cf. for example [CLRS01]).
Transforming the coding using the lists of successors into the two other ones
corresponds to computation of the transitive closure of the covering relation.
Conversely, transforming the two other codings into the lists of successors corre-
sponds to computation of the transitive reduction.
3. Transitive Reduction
Transitive reduction is the inverse operation of transitive closure, namely the
problem is to reduce the number of arcs while maintaining the existence of paths.
Computing a minimum transitive reduction of a given graph (i.e., a transitive re-
duction with the smallest number of arcs) is a difﬁcult problem in the general
case. Indeed, a minimal transitive reduction (i.e., which does not strictly contain
a transitive reduction) does not necessarily have a minimum number of arcs (cf. K
in Fig. 6.11). Determining whether a graph with n vertices has a transitive reduc-
tion with n arcs is equivalent to checking the existence of a hamiltonian circuit
in this graph, which is an NP-complete problem [GJ79]. The problem becomes
easy on graphs without a circuit. Such a graph has exactly one transitive reduc-
tion. Thus, any algorithm for computing a minimal transitive reduction gives a
minimum transitive reduction for this class of graphs. A naive algorithm is as fol-
lows: For any arc (x,y), perform a depth-ﬁrst from x without using (x,y); if y is
reached (y is thus a a descendant of x), then delete (x,y) (it is a transitivity edge).
This algorithm is in O(m×(n+m), thus O(n2) if m ∈O(n). (cf. also [HMR93]).
Figure 6.11 shows an example, with H and K being minimal reductions of G.

166
6 Basic Algorithms for BG Homomorphism
d
b
a
d
c
b
a
d
c
b
a
H
G
K
c
Fig. 6.11 Two minimal transitive reductions
4. Relations with Circuits
Rather than considering that the existence of a circuit of types is an error, one
can consider that all types belonging to a circuit are in fact equivalent or, stated
otherwise, are aliases of the same type. In this case, the problem is not to ﬁnd the
circuits of the given graph (X,U) but to compute the strongly connected com-
ponents of (X,U) and the associated quotient graph. Indeed, given two elements
x and y, x and y are equivalent if and only if they belong to the same strongly
connected component, and x is a (strict) subtype of y if and only if x is less than
y in the quotient graph (X,U)/SCC, where SCC is the partition of X in strongly
connected components. The quotient graph (X,U)/SCC is a graph without a cir-
cuit. The strongly connected components and the associated quotient graph of
(X,U) can be computed in time O(|X|+|U|) [Tar72].
6.3.3 Tree Orders
Let us call tree order an ordered set (X,≤) such that its covering graph (X,≺) is a
rooted tree. Schubert et al. [SPT83] proposed an elegant and optimal coding for tree
orders. Let n = |X|. The method consists of numbering the elements by 1,2,...,n in
such a way that if num(x) is the numbering of x then for any x the set {num(y)|x ≤y}
is the integer interval [num(x),num(x)+1,...,M(x)]. Building such a numbering is
easy and can be done by a depth-ﬁrst search on the rooted tree (X,≺) from its root.

6.3 Label Comparison
167
Indeed, a simple numbering of vertices according to the order in which they are
visited satisﬁes the property. Performing a depth-ﬁrst search for a tree is in O(n).
Figure 6.12 shows a tree order with a depth-ﬁrst search numbering of the nodes and
the associated intervals.
[8,8]
2
3
4
5
6
7
8
9
1
[7,7]
[6,6]
[5,8]
[4,4]
[9,9]
[3,8]
[2,2]
[1,9]
Fig. 6.12 A simple coding for a tree order
Having such a numbering, comparing two elements is reduced to two integer
comparisons. Indeed, one has: x ≤y if and only if num(x) ≤num(y) ≤M(x). Hav-
ing the rooted tree (X,Uh), the method is in time and space O(n) for building the
functions num,M, then comparing two elements is in constant time.
6.3.4 Partition in Chains
Let us assume that the ordered set X is partitioned in k chains (i.e., linear or total
orders): C1,...,Ck, and c(x) is the subscript of the chain containing x. Let us denote
by ni the cardinality of Ci, then the elements of Ci are numbered by 1,2,...,ni,
and num(x) is the number associated with x. For any x ∈X and i ∈{1,2,...,k}
let t(x,i) = max{num(y)|y ≤x,y ∈Ci} (with max(∅) = 0). The tuple of integers
(t(x,1),t(x,2),...,t(x,k)) is associated with x ∈X. One has: x ≤y if and only if
t(y,c(x)) > num(x). Thus, comparing two elements is in constant time. The size of
the coding is in O(k ×log(n)).
A partition of X in chains has to be built. Dilworth’s theorem states that the min-
imum number of chains which partition an order is equal to its width (i.e., the max-
imum cardinality of an anti-chain) and such a minimum partition can be computed
by a simple algorithm in time O(n3) by transforming it into a maximum matching

168
6 Basic Algorithms for BG Homomorphism
problem. Figure 6.13 shows an order, a chain partition of this order in three chains
and the associated coding. A node x with the labels (i, j) and [l,m,n] means that x
is the j-th node in the chain Ci and [l,m,n] is the coding of x.
[3,0,0]
[0,3,0]
(2,3)
(2,2)
[3,2,3]
[0,0,2]
(1,2)
(2,1)
[3,1,2]
C1
C2
C3
(3,2)
(1,1)
(3,1)
[0,0,1]
(3,3)
[0,0,3]
(1,3)
[2,0,2]
[1,1,1]
Fig. 6.13 The chain partition coding
6.3.5 Lattices
Besides being a tree another usual property for concept or relation hierarchies is
to be a lattice. A classical coding of a lattice consists of using its join-irreducible
elements ([DP02]).
Deﬁnition 6.8 (Join-irreducible elements). Let [L,≤) be a ﬁnite lattice. An ele-
ment j of L is join-irreducible if j covers exactly one element.
Figure 6.14 gives some examples. The join-irreducible elements are pictured in
black.

6.4 Bibliographic Notes
169
M
2
3
4
a
b
c
d
1
L
N
Fig. 6.14 Join-irreducible elements
The covering relation is represented by the lists of predecessors computing the
join-irreducible elements of a lattice of n elements is in O(n). The coding of a lattice
with the join-irreducible elements consists of representing each element x by the set
J(x) of the join-irreducible elements that are greater than or equal to x: J(x) = {y
join-irreducible | y ≤x}. One has:
Property 6.8. Let L be a ﬁnite lattice. For all x and y in L, x ≤y if and only if
J(x) ⊆J(y).
Let us consider the lattice L in Fig. 6.14. Using a vector of length 4 for represent-
ing a set of join-irreducible elements, the coding J of L is as follows:
J(1) = (1,0,0,0), J(2) = (0,1,0,0), J(3) = (0,0,1,0), J(4) = (0,0,0,1)
J(a) = (0,0,0,0), J(b) = (1,1,0,0), J(c) = (1,1,1,0), J(d) = (1,1,1,1)
The lattice N in Fig. 6.14 is a tree supplemented with a minimum element. Coding
it as a lattice is less efﬁcient (for the comparison problem) than coding it as a tree
(plus a minimum element).
Dually, a meet-irreducible element is an element that is covered by exactly one ele-
ment, and meet-irreducible elements can be used for coding a lattice.
6.4 Bibliographic Notes
Several algorithms for computing BG homomorphisms have been proposed in the
conceptual graph literature. The ﬁltering techniques used in these algorithms can be
seen as kinds of local consistency checks, and the notion of edge-consistency ﬁlter
presented in this chapter seems to generalize most of these proposals. Let us cite
in particular [Wil95] with the preprocessing step called polyprojection, [Mug95]
with a preprocessing step based on an edge-covering tree of the source graph,
and [CC06], where BG homomorphism checking is translated into the problem of

170
6 Basic Algorithms for BG Homomorphism
ﬁnding a clique in a graph representing all possible matchings between relation
nodes of both graphs, with the cardinality of this clique being equals to the number
of relation nodes of the source graph.
Baget studied the relevancy of CSP algorithms for computing BG homomor-
phisms (with the hypergraph vision of BGs adopted in this chapter). His evaluating
criteria were as follows: (1) The algorithm must be able to ﬁnd all solutions; (2)
the algorithm must be generic, i.e., has to accept any BG as input; (3) the algorithm
must add as little overhead cost as possible with respect to the backtrack (because
this overcost is offset by a reduction of the explored search tree only on difﬁcult in-
stances, which are unlikely to be encountered in the main uses of conceptual graphs).
This study led to an algorithm presented in [Bag01] (in French) and [Bag03]. Let
us especially point out the efﬁcient data structure proposed to support the dynam-
ical computation of the candidates for a concept node [Bag03]. This structure was
ﬁrst proposed in [BT01] for constraint networks. It allows efﬁcient implementation
of classical constraint processing schemes, i.e., backmarking, forward checking and
backjumping.
The subsumption relation on BGs can be used to structure a large set of BGs
and reduce the number of homomorphism checks when the base is searched. In this
chapter, we did not address retrieval techniques exploiting this structuring. About
this aspect, see in particular Ellis and Levinson ’s work [LE92] [ELR94].
Pointers to constraint processing Literature
References to speciﬁc aspects of constraint processing have been included in the
text. Let us end with general introductions to this domain. For a synthetic presenta-
tion, the reader is referred to the survey in the book [RN03]. The book [Dec03] pro-
vides an in depth presentation, from basic to advanced techniques. The relationships
between constraint networks and relational algebra are particularly emphasized. Fi-
nally, the recent handbook of constraint programming [RvW06] provides numerous
pointers to the state of the art in the domain.

Chapter 7
Tractable Cases
Overview
This chapter presents tractable cases for BG-HOMOMORPHISM. These cases are es-
sentially obtained by restricting the structure of the source BG to an acyclic struc-
ture, with the deﬁnition of acyclicity being more or less restrictive. The simplest
acyclicity studied is multigraph-acyclicity. When the source BG is multigraph-
acyclic, edge-consistency is sufﬁcient to ensure global consistency (i.e., the ex-
istence of a solution). Furthermore, it can be computed more efﬁciently than
in the general case, and the number of solutions can be polynomially counted.
Hypergraph-acyclicity strictly generalizes the previous notion. When the source
BG is multigraph-acyclic, global consistency can be polynomially checked using
the notion of a join tree issued from database theory, and two kinds of consistency,
namely edge-consistency and pairwise-consistency. We give polynomial algorithms
to check the global consistency in these two cases; these algorithms compute a ﬁl-
ter that allows to enumerate the solutions. We point out the equivalence between
hypergraph-acyclic BGs and guarded BGs, which correspond to the guarded frag-
ment of existential conjunctive positive ﬁrst-order logic. We then brieﬂy present
generalizations of acyclicity to bounded treewidth and hypertreewidth, and end with
a panorama of expressivity results for all studied deﬁnitions of acyclicity. We ﬁnally
mention the rare tractability results based on labeling properties of the target BG
and point out that exhibiting tractable cases combining properties on the structure
of BGs and on their labeling is an open challenge.
7.1 Introduction
A tractable case of a difﬁcult problem is a case in which the problem can be
solved in polynomial time. This chapter is essentially devoted to the presentation
of tractable cases for BG-HOMOMORPHISM and associated algorithms. It illustrates
one of our claims (see Chap. 1): Expressing reasoning with graph operations allows
171

172
7 Tractable Cases
us to beneﬁt from important algorithmic results. This chapter also points out the
deep links between particular FOL fragments and graphs with a particular structure.
7.1.1 About Tractability
Tractable cases are classically obtained by restricting the input of the problem to
particular cases, i.e., the target BG or the source BG or both in our case. In this
chapter, we will mainly gather results obtained by restricting the structure of BGs.
Some structures correspond to cases “naturally” occurring in applications and easily
recognizable by a human being. A typical case is that of a tree. This notion is at
the core of this section. We will go from this simple notion to richer structures
decomposable into trees.
Let us, however, keep in mind that we have to distinguish between the theoret-
ical tractability of a problem and efﬁciency of algorithms solving it in practice. A
problem might be NP-complete but its difﬁcult instances might be rarely found in
practice. Conversely, a problem might be polynomial time solvable but the algo-
rithm solving it might have a complexity involving big constants (for instance, a
complexity in c1 × nc2, where n is the size of the input, and c1 and c2 are big con-
stants). There are even polynomial problems for which no polynomial algorithm is
known (see for instance [RS04]).
The algorithms given in this chapter that rely on the multigraph-acyclicity
or hypergraph-acyclicity have a low complexity—their worst-case complexity is
bounded by c × mG × mH, where mG and mH denote the number of edges of the
source and target BGs, and c is a small constant. For more complex notions of
acyclicity such as bounded treewidth and hypertreewidth, the practical tractability
of the problem is less obvious.
Tractable cases are interesting in practice when they correspond to cases fre-
quently found in a real application. For instance, graphs have a simple structure
when they are manually built: They tend to be trees, and the degree of acyclicity
remains small when they have cycles (this notion will become clearer in next sec-
tions).
7.1.2 The Structure of the Target BG is of No Help
Structural properties and the complexity of graph homomorphism have been exten-
sively studied in the graph theory domain (see for instance [HT97][HM01] [HN04]).
The complexity of homomorphism checking has been particularly explored in
the framework of the following problem, called the general coloring problem, or H-
COLORING, where H is a ﬁxed graph: Given a graph G, is there a homomorphism
from G to H? The name H-COLORING reﬂects the fact that classical coloring prob-
lems can be seen as special cases of H-COLORING. Given a set of colors, coloring a

7.1 Introduction
173
graph consists of assigning a color to each of its nodes, such that no adjacent nodes
have the same color. A k-coloring is a coloring using at most k colors; formally,
it is a mapping c from the node set of G into {1 ... k}, such that for all edges xy,
c(x) ̸= c(y). The classical k-COLORING problem takes a graph G as input and asks
whether there is a k-coloring of G. It can be recast as a H-COLORING problem where
H is a clique on k nodes.
GRAPH-HOMOMORPHISM is the problem that takes two graphs G and H as input
and asks if there is a homomorphism from G to H (cf. Chap. 5). As in H-COLORING,
H is not part of the input of the problem, H-COLORING can be seen as a special case
of GRAPH-HOMOMORPHISM where the size of H is bounded by a constant. The H-
COLORING complexity study is focused on the structure of H and tries to determine
the exact conditions on the structure of H which make the problem polynomial.
The answer is known for non-directed graphs: H-COLORING is polynomial if H
is bipartite (or if H has a loop or is restricted to one node) and NP-complete in
all other cases [HN90]. This result also holds for GRAPH-HOMOMORPHISM. About
directed graphs, there are trees H for which H-COLORING is NP-complete [HNZ94].
GRAPH-HOMOMORPHISM, thus BG-HOMOMORPHISM, remains NP-complete even
if H has a tree structure.
Corollary 7.1 (from [HNZ94]). BG-HOMOMORPHISM remains NP-complete in the
case where the underlying graph of H is a tree (and the vocabulary is restricted to
one concept type and one binary relation).
What about considering the structure of the source graph G rather than that of the
target graph H? The question is more relevant to us, since G generally represents
a goal or a query (or a part of a rule or constraint, see Chap. 11), while H often
encodes the fact base; G then has a small size and a less complex structure than H.
The next sections are devoted to this issue.
The tractable cases discussed in the next sections are based on the following
property: If G has the required special structure, an ordering on the nodes of G
can be computed, such that checking the existence of a solution or computing a
solution can be done in a greedy way. In other words, one obtains a “backtrack free”
algorithm.
The special structure is related to the acyclicity of the source graph. Let us point
out that equivalent results have often been found in several domains (databases,
graph theory, CSP, etc.) or transfered from one to the other and enriched. The sim-
plest kind of acyclicity is graph acyclicity (or multi-graph acyclicity since BGs are,
strictly speaking, multigraphs and not simply graphs). We shall begin with graph
acyclicity before considering generalizations of this notion.

174
7 Tractable Cases
7.2 Tractability Based on the Multigraph-Acyclicity
of the Source BG
For simplicity, most algorithms in the sequel will be based on the assumption that
the source BG is connected. Let us however point out that they can be immediately
extended to a non-connected source BG. Indeed, if G is a non-connected BG, a ho-
momorphism from G to any BG H can be seen as a set of homomorphisms from
each connected component of G to H. In addition, if H is not connected, each ho-
momorphism from a connected component of G to H maps this component to a
connected component of H.
7.2.1 Acyclic Multigraphs and Trees
A classical graph is acyclic if it has no cycle. We will say that a BG is multigraph-
acyclic if it has no cycle except those of length 2, derived from multi-edges between
a relation and a concept node. With all deﬁnitions of acyclicity that we shall study,
a tree adds connectivity to acyclicity.
Deﬁnition 7.1 ((multi)graph-acyclic). A BG is multigraph-acyclic if it has no cy-
cle of form (c1 r1 c2 .... cn rn c1), n ≥2, where all ci and cj (resp. ri and r j), i ̸= j,
are distinct nodes. It is a tree if it is multigraph-acyclic and connected.
The multigraph-acyclic property can be linearly checked, as illustrated by Al-
gorithm 12. Starting from any concept node considered as the root, the graph is
traversed, with the multi-edges between two nodes being considered as one edge.
Once a (concept or relation) node is reached from a (relation or concept) node x, it
is marked by it (x is called its predecessor) and put into a queue, which stores nodes
reached but not yet explored. If a node has an already marked neighbor, and this
neighbor is not its predecessor, then a cycle has been detected and the algorithm re-
turns false. If all nodes are explored without having detected a cycle, the algorithm
returns true and the marks deﬁne the rooted trees corresponding to the exploration
made by the algorithm. Note that if G is not connected, it is explored connected
component by connected component: the algorithm ﬁrst tries to take a node in the
queue (thus an already reached node) and, only if the queue is empty, takes a new
node (thus a node from another connected component).
Property 7.1. [MC92] BG-HOMOMORPHISM is polynomial when the source BG is
multigraph-acyclic.
Property 7.3 then provides a proof of this property. Let us consider that the source
BG is a tree. Moreover, and without loss of generality, we will see it as a rooted
tree. The root is any concept node whose role is to induce a direction to edges
that will be used in algorithms. We will distinguish between two relations induced
by this direction: the parent/child relation will be reserved for concept nodes; the

7.2 Tractability Based on the Multigraph-Acyclicity of the Source BG
175
Algorithm 12: CheckGraphAcyclicProperty(G)
Input: a BG G (not necessarily connected)
Output: true if G is (multi)graph-acyclic, otherwise false
begin
StillToExplore ←|CG|+|RG| // number of nodes to explore
forall (concept or relation) node x do
marked[x] ←-1
OK ←true
Choose any concept node c as the root
Let Q be a empty queue// contains nodes reached but not explored
Put c into Q
marked[c] ←0
while OK and StillToExplore ̸= 0 do
if Q is not empty then
pick x in Q
else
let x be any node with marked[x] = -1
marked[x] ←0
StillToExplore ←StillToExplore - 1
forall x′ neighbor of x, with x′ ̸= marked[x] do
if marked[x′] ̸= −1 then
OK ←false
else
marked[x′] ←x
add x′ to Q
return OK
end
predecessor/successor relation will be used for both concept and relation nodes,
according to the direction induced by the root (cf. Fig. 7.1). The successors of a
concept node c are the relation nodes that either have c as sole argument, or link c
to its children. The successors of a relation node are its arguments, except for the
one which is the parent of the others. Given a rooted tree T and any concept node c′
of T, the subtree induced by c′ is the subtree of T with root c′. A leaf is a concept
node without child (but it can have successors, which are relations with this concept
node as sole argument).
The parent/child relation allows us to focus on concept nodes (as in the hyper-
graph vision of BGs cf. Chap. 5), whereas the successor relation considers both
kinds of nodes.
A homomorphism from a rooted tree T to any BG H can be recursively deﬁned,
according to the recursive structure of a tree, as stated in the next property. This
property is illustrated by Fig. 7.2. Recall that the standard ﬁlter of T with respect to
H, denoted by poss, assigns to each node of T the list of its candidate images in H
according to compatibility conditions based on labels and, for relation nodes, on the
partition induced on their neighbors; furthermore, for a neighbor c of a relation r,
and for r′ a relation in poss(r), there is a sole neighbor of r′ corresponding to c for

176
7 Tractable Cases
successors of c
c
r1
successors of r1 and r2
root
r2
= children of c
leaves
Fig. 7.1 Vocabulary for rooted trees
r: It is the node c′ such that for each edge (r,i,c) in T, there is an edge (r′,i,c′) in
H (formally, Pr[c] ⊆Pr′[c′]). We note c′ = corresponding(c,r,r′).
Property 7.2. Let poss be the standard ﬁlter of T with respect to H and let c be the
root of T. A mapping π from the nodes of T to the nodes of H is a homomorphism
if it satisﬁes:
1. π(c) ∈poss(c)
2. for all successors r of c, let r′ = π(r), then r′ ∈poss(r) and Pr[c] ⊆Pr′[π(c)]
(π(c) = corresponding(c,r,r′)), and, for all successor d of r, let d′ be the node
such that Pr[d] ⊆Pr′[d′] (d′ = corresponding(d,r,r′)), then (1) π(d) = d′, and
(2) the restriction of π to the subtree Td rooted in d is a homomorphism from Td
to H.
H
T
c
π
i
i
j
k
j
k
r
d
d’
r’
Fig. 7.2 BG Homomorphism from a rooted tree

7.2 Tractability Based on the Multigraph-Acyclicity of the Source BG
177
The choices made for all subtrees Td are independent since these subtrees do not
share any node. This is the key reason why a homomorphism can be found with a
backtrack-free search. One can also note in the previous deﬁnition that, if the ﬁlter
poss is edge-consistent, a homomorphism can be built by a traversal of the tree from
the root c to the leaves: an image for c is ﬁrst chosen in poss(c); edge-consistency
ensures that there are compatible values in poss(r) and poss(d) for all successors r
of c and all successors d of r. Each d is itself the root of a subtree, thus the same
process is iterated.
Property 7.3. Let G and H be BGs, with G being multigraph-acyclic. There is a
homomorphism from G to H if and only if the standard ﬁlter of G with respect to H
can be made edge-consistent. Furthermore, for any node x and any x′ candidate for
x in this edge-consistent ﬁlter, there is a homomorphism from G to H which maps x
onto x′.
Proof. Without loss of generality let us consider that G is connected. Let us take any
concept node as the root, say c. The property is proven by induction on the depth
of this rooted tree. Let us consider any value c′ in poss(c). If G is restricted to c (G
is thus of depth 0), π = {(c,c′)} is a homomorphism from G to H (by deﬁnition
of a standard ﬁlter). Let us now assume that G is of depth n > 0. Let us consider
any relation r successor of c. Since the ﬁlter is edge-consistent, there is a relation r′
in poss(r) such that the neighbor of r′ corresponding to c is c′ (i.e. Pr[c] ⊆Pr′[c′]),
and for all successors d of r the neighbor of r′ corresponding to d is in poss(d).
There is thus a homomorphism from the subgraph induced by r and its neighbors
to H, mapping c onto c′ (by Property 6.2). Let d be a successor of r, and d′ be the
value chosen for d. By induction hypothesis, there is a homomorphism from the
subtree rooted in d to H. Since G is multigraph-acyclic, the choices of an r′ for all
successors r of c are independent. By making the union of all homomorphisms, we
have a homomorphism from G to H. We have considered any concept node c; now,
if we have to start from a relation, say r, we choose any value r′ in poss(r) and take
a neighbor c of r as root. Since the ﬁlter is edge-consistent, there is a concept c′ in
poss(c) such that c′ is the neighbor of r′ corresponding to c for r and, with the same
arguments as above, we conclude that there is a homomorphism from G to H that
maps r onto r′.
⊓⊔
Edge-consistency thus ensures global consistency (i.e., the existence of a solution)
for the homomorphism problem when G is acyclic. Moreover, it can be more efﬁ-
ciently computed than in general case, as shown by next algorithms. We will give
three versions of algorithms checking edge-consistency (Algorithms 13, 16 and 18).
The ﬁrst algorithm starts from the standard ﬁlter, as the algorithm we have seen
for the general case (Algorithm 5 in Chap. 6). We then give two variants of this
algorithm which are better in practice since they do not precompute the ﬁlter. They
compute the set of candidates for a node during the search, according to the con-
straints induced by its already visited neighbors.
The ﬁrst algorithm starts from the standard ﬁlter (step 1); since G is assumed to
be connected, isolated concept nodes of H are not considered as soon as G possesses

178
7 Tractable Cases
at least a relation. Concept nodes of G are totally ordered by a top-down traversal
of the tree, in such a way that a parent precedes its children (step 1). The level of a
relation is given by the smallest rank in its neighbors. Step 2 considers the concept
nodes in reverse order, i.e., by a bottom-up traversal, making each star graph edge-
consistent. When a node c of rank i is considered by the algorithm, edge-consistency
is checked on all relations of level i, thus all successors of c. After step 2, if Failure
has not been returned, it holds that G can be mapped to H. Indeed, for a node c of
rank i, for all values of poss(c), for any neighboring relation r of level greater or
equal to i, there is a consistent value for r and all its neighbors. However, the ﬁlter
is not necessarily edge-consistent, since the poss sets of deeper nodes may keep
inconsistent values. Actually, at the end of step 2, for each node c, poss(c) contains
all possible images for c by a homomorphism from the subtree of G rooted in c to
H. Thus, an additional traversal of the tree (step 3), top-down this time, has to be
done to clean the poss sets. Note that this second traversal cannot empty a poss set.
Algorithm 14: CheckRelation(r) subalgorithm of Algorithm 13
Input: a relation r in G (and a ﬁlter poss(G,H))
Output: EmptyPoss if a poss(c) has been emptied, otherwise OK and make
the ﬁlter edge-consistent on r star graph
// This subalgorithm is similar to CheckRelation in
EdgeConsistency (Algorithm 5) except that the
Changed[c] booleans need not to be maintained
Algorithm 15: Clean(r) subalgorithm of Algorithm 13
begin
Let p be the predecessor of r
// Remove from poss(r) values incompatible with
poss(p)
forall r′ ∈poss(r) do
let a = corresponding(p,r,r′)
if a ̸∈poss(p) then
remove r′ from poss(r)
// Propagate the effects to the successors of r
forall concept s successor of r do
forall a ∈poss(s) do
if there is no r′ ∈poss(r) such that a = corresponding(s,r,r′)
then
remove a from poss(s)
end
Property 7.4. The time complexity of the algorithm EdgeConsistencyTreev1(G,H)
(Algorithm 13), with G being a tree, is O(|CH|) if G is restricted to one concept
node, otherwise it is O(mG ×mH), where mG and mH are the number of edges of G
and H, respectively.

7.2 Tractability Based on the Multigraph-Acyclicity of the Source BG
179
Algorithm 13: EdgeConsistencyTreev1(G,H)
Input: two BGs G and H, with G being a tree (i.e., connected and multigraph-acyclic)
Output: the edge-consistent ﬁlter of G with respect to H if it exists, otherwise Failure
begin
// Preprocessing
1
if RG ̸= ∅then
let C′
H be obtained from CH by removing isolated nodes
// Computation of the standard filter poss(G,H)
forall c in CG do
poss(c) ←{c′ ∈C′
H|l(c) ≥l(c′)}
if poss(c) = ∅then
return Failure
forall r in RG do
poss(r) = {r′ ∈RH|l(r) ≥l(r′) and Pr ⊆Pr′}
if poss(r) = ∅then
return Failure
// Top-down traversal of G
Choose a concept for the root of G
Order CG such that each parent precedes its children
// Bottom-up traversal of G to make the filter
2
edge-consistent
forall c in CG from rank |CG| to 1 do
forall r in RG of level rank(c) do
result ←CheckRelation(r) // see Algorithm 14
if result = EmptyPoss then
return Failure
// Top-down traversal of G to clean the poss sets
3
forall c in CG from rank 1 to |CG| do
forall r in RG of level rank(c) do
Clean(r) // see Algorithm 15
return poss
4
end
Proof. First see that |RG| ≤mG, |RH| ≤mH and, sinceCG andC′
H contain no isolated
nodes, |CG| ≤mG and |CH| ≤mH. The complexity of step 1 is in O(mG × mH):
Indeed the ordering of |CG| is performed by a traversal of G, which is in O(mG)
and the computation of the standard ﬁlter is in O(mG × mH). The complexity of
CheckRelation(r) is bounded by arity(r) × |poss(r)|. CheckRelation is
called once for each relation of G and |poss(r)| is bounded by |RH|. Thus step 2 is
in O(mG ×|RH|). Clean(r) has same complexity as CheckRelation(r), thus
step 3 is in mG ×|RH| as well. Hence the global complexity of O(mG ×mH).
⊓⊔
Algorithm 16 presents a variant of the previous algorithm, which does not pre-
compute the standard ﬁlter. The poss sets are computed during the search as follows.
For all leaves c, poss(c) is computed from all (not isolated) concept nodes of H. For
a concept c that is not a leaf, poss(c) is computed from the poss(r) for all relations
r that are successors of c. When c is considered by the algorithm, edge-consistency

180
7 Tractable Cases
Algorithm 16: EdgeConsistencyTreev2(G,H)
Input: two BGs G and H, with G being a tree
Output: the edge-consistent ﬁlter of G with respect to H if it exists, otherwise Failure
begin
// Preprocessing
1
if RG ̸= ∅then
let C′
H be obtained from CH by removing isolated nodes
Choose a concept for the root of G
// Top-down traversal of G
Order CG such that each parent precedes its children
// Bottom-up traversal of G to build the poss sets
2
forall c ∈CG from rank |CG| to 1 do
if c is a leaf then
// poss(c) is still empty
poss(c) = {c′ ∈C′
H|l(c) ≥l(c′)}
forall r ∈RG of level rank(c) do
// this includes relations with c as sole neighbor
// compute poss(r) and update the poss sets of its
neighbors
result ←ComputeRelation(r) // see Algorithm 17
if result = EmptyPoss then
return Failure
// Top-down traversal of G to clean the poss sets
3
forall c ∈CG from rank 1 to |CG| do
forall r ∈RG of level rank(c) do
Clean(r) // same as Algorithm 15
return poss
4
end
is checked on all relations with level rank(c), thus all successors of c. The ﬁrst suc-
cessor of c considered initializes poss(c). Then, for each other successor r of c, the
new value of poss(c) is the intersection of the old value of poss(c) and the set of
candidates allowed by poss(r).

7.2 Tractability Based on the Multigraph-Acyclicity of the Source BG
181
Algorithm 17: ComputeRelation(r) subalgorithm of Algorithm 16
begin
poss(r) ←∅
forall neighbor c of r do
possr(c) ←∅
forall r′ in RH do
// check that (1), (2) and (3) are all true
(1): check if l(r) ≥l(r′) and Pr ⊆Pr′
(2): forall successor s of r do
// s already has a computed poss set
check if corresponding(s,r,r′) ∈poss(s)
(3): let p be the predecessor of r
if poss(p) = ∅then
// r is the first sucessor of p considered
by the algorithm
check if l(p) ≥l(corresponding(p,r,r′))
else
check if corresponding(p,r,r′) ∈poss(p)
if (1), (2) and (3) are true then
add r′ to poss(r)
forall neighbor c of r do
add corresponding(c,r,r′) to possr(c)
if poss(r) = ∅then
return EmptyPoss
forall neighbor c of r do
poss(c) ←possr(c)
return Done
end
Algorithm 18 presents a third algorithm which, instead of the leaves, starts from
the root of the tree [MC92] (and [Mug95] for a journal version). The set of candi-
dates for the root is computed, then the poss sets of other nodes are computed by
a top-down traversal of the tree. This technique has two advantages. First, a source
BG often has a natural root: It describes an entity (represented by the root), which
has certain properties, is in relationship with other entities, etc. In this case, a com-
putation starting from the root is more likely to rapidly restrict the candidate sets.
Secondly, this algorithm is adaptable to very big target BGs. In this case, one wants
to precompute as few poss sets as possible. With the previous algorithm, these sets
have to be precomputed for at least all leaves, whereas here only the poss set of the
root is precomputed. Moreover, one might select some possible images for the root,
possibly not all candidates in the target BG.
This algorithm follows the recursive structure of a rooted tree. The recursive
subalgorithm HomomorphismsRec takes a concept c as input and returns the set
of nodes such that there is a homomorphism from the subtree rooted in c to H. It ﬁrst

182
7 Tractable Cases
Algorithm 18: EdgeConsistencyTreev3(G,H)
Input: two BGs G and H, G being a tree
Output: the edge-consistent ﬁlter of G with respect to H if it exists; otherwise Failure
begin
Choose a concept c as the root of G
if RG ̸= ∅then
let C′
H be obtained from CH by removing isolated nodes
if HomomorphismsRec(c, C′
H) = ∅then
// see Algorithm 19
return Failure
else
Clean(c) // see Algorithm 20
return poss
end
computes the set of candidates for the root c. There is no homomorphism if this set
is empty. Otherwise, if the tree is restricted to the root c, the work is done and this set
is returned. If not, the algorithm uses the set of candidates for c to compute the set of
candidates for each successor r of c. In turn, the set of candidates for each r induces
a set of candidates for each successor s of r. The subalgorithm is recursively called
on each s and returns the set of nodes such that there is a homomorphism from
the subtree rooted in s to H. Each of these sets is then used to restrict the set of
candidates for r and c. The new set of candidates for c is ﬁnally returned.
Despite a bit more complex formulation, this algorithm has the same worst-case
time complexity as the previous one. We then show how it can be extended to com-
pute the number of homomorphisms from G to H without overhead complexity. A
speciﬁc notation is introduced. Let c be a concept node of G and c′ be a candidate
for c. For a successor r of c, poss(r)[c→c′] denotes the set of candidates for r if c
is mapped to c′. Then, for a successor s of r (or, equivalently, for a child s of c),
poss(s)[c→c′] denotes the set of candidates for s if c is mapped to c′. It is assumed
in the algorithm that these sets are memorized within the poss structure.

7.2 Tractability Based on the Multigraph-Acyclicity of the Source BG
183
Algorithm 19: HomomorphismsRec(c, set)
subalgorithm of Algorithm 18
Input: c root of a tree Gc and set ⊆CH
Output: returns set restricted to {c′|∃Π : Gc →H,Π(c) = c′}; ﬁlls the poss
structure for the subtree rooted in c and the computed sets
poss(x)[c→c′] are memorized for all x
begin
poss(c) ←{c′ ∈set|l(c) ≥l(c′)}
1
if poss(c) = ∅or c has no successor then
2
return poss(c)
forall relation r successor of c do
3
forall concept c′ ∈poss(c) do
poss(r)[c→c′] ←{r′ ∈RH|l(r) ≥l(r′) and Pr ⊆Pr′ and
c′ = corresponding(c,r,r′)}
if poss(r)[c→c′] = ∅then
remove c′ from poss(c)
if poss(c) = ∅then
return ∅
forall concept s successor of r do
forall concept c′ ∈poss(c) do
poss(s)[c→c′] ←{s′|∃r′ ∈poss(r)[c→c′], s′ =
corresponding(s,r,r′)}
poss(s) ←∪c′∈poss(c)poss(s)[c→c′]
poss(s) ←HomomorphismsRec(s, poss(s))
forall concept c′ ∈poss(c) do
poss(s)[c→c′] ←poss(s)[c→c′] ∩poss(s)
forall relation r′ ∈poss(r)[c→c′] do
if corresponding(s,r,r′) ̸∈poss(s)[c→c′] then
remove r′ from poss(r)[c→c′]
if poss(r)[c→c′] = ∅then
remove c′ from poss(c)
exit this “for loop”
return poss(c)
4
end

184
7 Tractable Cases
Algorithm 20: Clean(c)
subalgorithm of Algorithm 18
begin
forall r successor of c do
poss(r) ←∪c′∈poss(c) poss(r)[c→c′]
forall s successor of r do
poss(s) ←∪c′∈poss(c) poss(s)[c→c′]
Clean(s)
end
Property 7.5. [MC92] The number of homomorphisms from a BG G to a BG H can
be computed in polynomial time when G is multigraph-acyclic.
If G is not connected, the number of homomorphisms from G to H is the product
of the number of homomorphisms from each connected component of G to H. Let
us now assume that G is a tree, and let c be any concept chosen as its root. Given
c′ any node of H, let NB(c,c′) denote the number of homomorphisms from G to H
which map c onto c′. The number of homomorphisms from G to H is the sum of the
NB(c,c′) for all c′ in H. NB(c,c′) is recursively deﬁned as follows.
NB(c ∈G,c′ ∈H) =
0 if c′ is not a candidate for c (c′ ̸∈poss(c))
1 if c has no successor
otherwise, ∏r successor o f c(∑r′∈poss(r)[c→c′] nb(r,r′))
where poss(r)[c→c′] = {r′|r′ ∈poss(r) and c′ = corresponding(c,r,r′)}
and nb(r,r′) =
1 if r has no successor
otherwise, ∏s successor o f r(NB(s, s′)|s′ = corresponding(s,r,r′))
The subalgorithm HomomorphismsRec(c,set) (Algorithm 19) can be adapted
to return the set of pairs (c′,NB(c,c′)) for which NB(c,c′) ̸= ∅rather than just the
subset of concept nodes to which c can be mapped.
Note that we compute the number of homomorphisms by considering both con-
cepts and relations of G. If we are only interested in homomorphisms that are dis-
tinct on the concepts of G, we have to keep only one representative for all relations
in poss(r)[c→c′] with the same list of neighbors, as they induce homomorphisms
which are identical on the successors of r.
7.2.2 BGs Trivially Logically Equivalent to Acyclic BGs
The previous result can be extended to a class of BGs that can be transformed into
logically equivalent acyclic BGs by “cutting cycles”, as pointed out in [BMT99].
The idea is that if we split an individual concept node (as in the elementary operation
detach, see Chap. 2), we obtain a graph logically equivalent to the original one (note

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
185
however that it can be more general with respect to the ⪰relation). See Fig. 7.3: G
is logically equivalent to the tree on the right obtained by splitting the concept node
[⊤:a]. This would not be true with a generic concept node—the new graph would
be logically deducible from the original one but the opposite would be false.
A BG G can be transformed into a logically equivalent acyclic BG by splitting
some individual concept nodes if and only if every cycle of length greater than 2 con-
tains an individual concept node. This property can be checked in polynomial time
as follows: Split each individual node into as many nodes as neighboring relations
and check whether the obtained BG is acyclic. Consequently, BG-HOMOMORPHISM
can then be solved in polynomial time.
Property 7.6. [BMT99] A “true” cycle is a cycle (of length greater than 2) contain-
ing no individual concept node. Deduction is polynomial when the source BG has
no true cycle.
Instead of actually splitting individual nodes, Algorithm 21 performs a traversal
of the graph. The difference with respect to the algorithm for checking multigraph-
acyclicity (Algorithm 12) is that it does not check whether individual concept nodes
are reached several times and does not explore them. More speciﬁcally, when an
individual node is reached, it is not marked and it is not added to the queue Q (thus
its neighbors are not reached from it). Note that even if the graph is connected, one
cannot stop the traversal when the queue is empty, since some paths are broken by
individual nodes. This algorithm has linear time complexity in the size of the BG.
G
T : a
T : a
T : a
r
T
r
T
T
r
r
r
T
r
T
T : a
T
r
r
r
r
Fig. 7.3 Logically equivalent BGs. G has no true cycle.
Let us now study a generalization of the tree case, which is called “acyclic hy-
pergraph” in graph theory and “guarded BG” when translated from guarded logical
formulas.
7.3 Tractability Based on the Hypergraph-Acyclicity
of the Source BG
Let us begin with hypergraph-acyclicity. Early works on cyclicity of hypergraphs
come from combinatorics, relational databases and also probabilistic networks.

186
7 Tractable Cases
Algorithm 21: CheckExtendedTree(G)
Input: a BG G (not necessarily connected)
Output: true if G has no “true” cycle, otherwise false
begin
// let (CG)∗be the set of generic concept nodes in G
if |(CG)∗| = 0 then
return true
StillToExplore ←|(CG)∗|+|RG| // number of nodes to explore
OK ←true
forall concept or relation node x do
marked[x] ←-1
Choose any generic concept node c as the root
Let Q be an empty queue
Put c into Q
marked[c] ←0
while OK and (StillToExplore ̸= 0) do
if Q is not empty then
pick x in Q
else
let x be a generic node or relation with marked[x] = -1
marked[x] ←0
StillToExplore ←StillToExplore - 1
forall x′ neighbor of x, with x′ ̸= marked[x] do
if x′ is a generic node with marked[x′] ̸= −1 then
OK ←false
else
if x′ is not an individual node then
marked[x′] ←x
add x′ to Q
return OK
end
Several deﬁnitions of acyclicity of a hypergraph have been deﬁned, for which some
NP-complete problems on general hypergraphs become polynomial on acyclic in-
stances. All of these deﬁnitions are based on associating a graph with the hyper-
graph; then the notion of acyclicity of the hypergraph is deﬁned by the notion of
acyclicity of the associated graph. For instance, the incidence (bipartite) graph of
a hypergraph corresponds to the underlying graph of a BG: hyperedges are trans-
formed into nodes (the relation nodes in a BG) and related to nodes composing
the hyperedge (concept nodes in a BG); the only difference in the structure is that
the incidence graph does not have multi-edges. Hypergraph-acyclicity based on the
acyclicity of the incidence graph is what we call multigraph-acyclicity.
The most general notion of hypergraph-acyclicity among those proposed in the
literature can be based on the notion of the primal graph of a hypergraph or on
that of its dual graph, with both notions leading to the same notion of hypergraph
acyclicity. When a connected hypergraph is acyclic it can be decomposed into a
join tree, a name derived from databases [BC81] [BG81] (for several equivalent

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
187
notions of hypergraph-acyclicity in the context of databases, see [BFMY83]). Hy-
pergraph acyclicity can be polynomially checked. If the test is satisﬁed, a join tree
can be built in polynomial time and is the basis of a polynomial algorithm for homo-
morphism/homomorphism checking. As we will see, an equivalent notion has been
independently deﬁned on BGs, called a guarded covering in [Ker01], and inspired
from the notion of a guarded ﬁrst-order logical formula [AvBN96].
7.3.1 Use of a Join Tree
Given a hypergraph H = (X,E) the dual graph H = (X,E,χ) of H is the undirected
graph labeled on edges built as follows:
• its nodes are the hyperedges of H: X = E,
• there is an edge between two distinct nodes if they share at least one node of H:
∀E1,E2 ∈E with E1 ̸= E2, E1E2 ∈E if E1 ∩E2 ̸= ∅,
• edges are labeled by the intersection of the hyperedges they connect: ∀E1E2 ∈
E,χ(E1E2) = E1 ∩E2.
An edge E1E2 of the dual graph is said to be removable if there is another path
between E1 and E2, such that the nodes shared by E1 and E2 also belong to all Ei
on this path. A partial graph H′ of the dual graph H is said to have the running
intersection property if, whenever in H the same node x occurs in two hyperedges
E1 and E2, there is in H′ a path between nodes E1 and E2 and x occurs in each
node on this path. In other words, the subgraph of H′ deﬁned by the edges whose
label contains x is connected. One can also say that H′ is obtained from the dual
graph by removing only removable edges. If H′ is a tree, it is called a join tree of H.
Note that if the hypergraphs were not connected, the join tree notion could easily be
adapted—it would become a set of join trees.
When a BG is seen as a hypergraph, its nodes are concept nodes and its hyper-
edges stand for relations and their incident multiedges (see Chap. 5). It is convenient
to consider hyperedges as representing star graphs. The dual graph of a BG G can
thus be deﬁned as follows: Its nodes are the star graphs of G, there is an edge be-
tween two distinct nodes if the corresponding relations share a common concept
node in G, and edges are labeled by the sets of common concept nodes of the star
graphs they connect. Note however that individual concept nodes can be split with-
out changing the logical meaning of the BG (see Sect. 7.2.2). Thus, edges coming
from shared individual concept nodes can be ignored in the construction of the dual
graph. Figure 7.4 shows the dual graph resulting from decomposition of the BG G
and one of its join trees.
Deﬁnition 7.2 (acyclic hypergraph). A connected hypergraph is acyclic if it has a
join tree. A hypergraph is acyclic if each connected component has a join tree.
Property 7.7. If a BG is multigraph-acyclic then it is hypergraph-acyclic. But the
converse is not true.

188
7 Tractable Cases
G
The dual graph of G
A join tree of G
r
r
r
T
T
r
T
r
T
1
2
3
x 
y
z 
t 
p(x,y,z)
xz
z 
z 
z 
z 
z 
z 
r(y,z)
r(z,t)
r(x,z)
xz
r(z,x)
x
x
xz
xy 
r(x,y)
yz
p(x,y,z)
yz
r(x,y)
xy 
r(z,x)
xz
r(x,z)
r(z,t)
r(y,z)
z 
xz
p
Fig. 7.4 Dual Graph and Join Tree
Proof. Let G be a multigraph-acyclic BG. The dual graph of each connected com-
ponent of G is a join tree. For the converse, see the BG G in Fig. 7.4.
⊓⊔
Let us come back to homomorphism checking, with G being the source BG and
H the target BG. Assume that G has a join tree. Intuitively, and roughly speaking,
the edges of this join tree represent constraints on candidates for the concept nodes
in G: If an edge is labeled by c1 ... cp, then the nodes it links (representing two
star graphs sharing concept nodes c1 ... cp) must have compatible candidates for
c1 ... cp. The running intersection property ensures that these constraints are propa-
gated on all star graphs sharing nodes. The overall idea is that if the standard ﬁlter
of G with respect to H can be rendered “consistent” according to the join tree, and
then a homomorphism from G to H can be built. More speciﬁcally, let us consider
Algorithm 22. This algorithm traverses the join tree from its leaves to the root. Edge-
consistency is locally achieved for each star graph composed of a relation r j and its
arguments. The result is propagated to the parent node rk: rk has to “agree” with
r j on their common arguments, which is another kind of consistency (see pairwise-
consistency below). If both kinds of consistency are achieved, the ﬁlter built allows
us to exhibit a homomorphism from G to H. Otherwise there is no homomorphism
from G to H. The algorithm starts from a standard ﬁlter, but it could be adapted to
compute the poss sets during the search as in the algorithm EdgeConsistencyTreev2
(Algorithm 16).

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
189
Algorithm 22: ConsistencyCheckwithJoinTree
Input: two BGs G and H, with G being hypergraph-acyclic and connected; TG a join tree of
G
Output: true if there is a homomorphism from G to H and false otherwise; if true is
returned, the poss structure satisﬁes: for any relation r in G, for any r′ ∈poss(r)
{(r,r′)} can be extended to a homomorphism from the subgraph of G
corresponding to the subtree of TG rooted in r, to H, assigning to each node x an
image in poss(x)
begin
Order the relation nodes of G such that each relation appears before its descendant
relations in TG
Compute the standard ﬁlter of G with respect to H
// Bottom-up traversal of TG
for j from |RG| to 1 do
// Make the filter edge-consistent for the star graph
of rj
Failure ←CheckRelation(rj) // see Algorithm 5 in Chap. 6
if Failure then
return false
// Propagate to the parent relation rk
// In database terms: compute πrk(rj 1 rk)
if j ̸= 1 then
consider the edge (rj,rk) of TG with k < j
forall r′ in poss(rk) do
if there is no r′′ in poss(rj) such that for all c common neighbor of rj
and rk corresponding(c,rj,r′′) = corresponding(c,rk,r′) then
remove r′ from poss(rk)
if poss(rk) = ∅then
return false
return true
end
The kind of consistency achieved on relations which share arguments is related
to a property called “pairwise-consistency” in databases [BFMY83] (see the com-
plementary notes at the end of this chapter).
Deﬁnition 7.3 (pairwise-consistency for BGs). A ﬁlter of G with respect to H, say
poss, is pairwise-consistent if the following condition is fulﬁlled for all relations r
and s of RG sharing at least an argument:
• (consistency of s with respect to r) for all r′ ∈poss(r) there is s′ ∈poss(s),
such that for all c common argument of r and s, corresponding(c,r,r′) =
corresponding(c,s,s′);
• (consistency of r with respect to s) reciprocally, for all s′ ∈poss(s) there is an r′ ∈
poss(r), such that for all c common arguments of r and s, corresponding(c,r,r′) =
corresponding(c,s,s′).
Pairwise-consistency and edge-consistency are generally not related. Clearly,
pairwise consistency does not imply edge-consistency as it does not take the lists

190
7 Tractable Cases
of candidates for concept nodes into account. For instance, if G is restricted to a
star graph, any ﬁlter of G with respect to H is pairwise-consistent. The implication
in the other direction does not hold either, as illustrated by Fig. 7.5: Assume that
all concept (or relation) nodes in G and H have the same labels; the standard ﬁl-
ter of G with respect to H, which associates {c3,c4,c5} to each concept node and
{r3,r4,r5} to each relation node, is edge-consistent but not pairwise consistent. For
instance (all nodes play exchangeable roles), r2 is not pairwise consistent relative to
r1. Indeed, let us consider r3 ∈poss(r1). The common arguments of r1 and r2 are
{c1,c2}. r3 leads to map c1 to c3 and c2 to c4 (i.e., corresponding(c1,r1,r3) = c3 and
corresponding(c2,r1,r3) = c4). But there is no relation in poss(r2) compatible with
this mapping (i.e. there is no r′ ∈poss(r3) such that corresponding(c1,r2,r′) = c3
and corresponding(c2,r2,r′) = c4).
Note however, that if any pair of relations in G share at most one node, edge-
consistency implies pairwise-consistency.
2
G
c2
c1
r1
r2
c3
r3
c4
r4
c5
r5
1
2
2
1
1
1
1
2
H
2
Fig. 7.5 Edge-consistency and pairwise-consistency
Property 7.8. Let G and H be BGs, with G being hypergraph-acyclic. If the standard
ﬁlter of G with respect to H can be made edge-consistent and pairwise-consistent,
then it is globally consistent, i.e., there is a homomorphism from G to H.
Proof. If it cannot be made edge-consistent, there is no homomorphism from G to
H. The same holds for pairwise-consistency.
Actually, Algorithm 22 applies directional (in one step, from the leaves to the
root) edge-consistency and pairwise-consistency; in particular, each r j is made
pairwise-consistent with respect to its parent relation but not the opposite. If the
algorithm ends with success, a homomorphism from G to H can be constructed by
considering the nodes of TG from the root to the leaves: an image is taken for the
root relation in its poss set, and this choice determines the images of its arguments.
The consequences are propagated to the children relations via the arguments they
share. Directional edge-consistency and pairwise-consistency ensure that no poss
set will become empty.
⊓⊔
Algorithm 22 shows that once a join tree has been constructed, homomorphism
checking can be done in polynomial time. The next section shows that, given a

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
191
hypergraph, one can determine in polynomial time (and even in linear time) whether
it is acyclic, and if so a join tree can be built. Thus:
Property 7.9. BG-HOMOMORPHISM is polynomial if the source BG is hypergraph-
acyclic.
7.3.2 Construction of a Join Tree
Given a join tree of the source BG, homomorphism checking takes polynomial time.
But the ﬁrst problem is to build a join tree. A simple technique is based on the
following property:
Property 7.10. [Mai83] If a connected hypergraph is acyclic, then any maximum
spanning tree of its dual graph is a join tree.
p(x,y,z)
r(x,y)
r(z,x)
r(x,z)
r(z,t)
r(y,z)
2
2
2
1
1
2
1
2
1
1
1
1
1
p(x,y,z)
1
2
2
2
2
r(y,z)
r(z,t)
r(x,z)
r(z,x)
r(x,y)
p(x,y,z)
1
2
2
2
2
r(y,z)
r(z,t)
r(x,z)
r(z,x)
r(x,y)
T2
T1
The graph on the left is the dual graph of G in Fig. 7.4, and T1 is the join tree in the same ﬁgure
Fig. 7.6 Maximum spanning trees
This property assumes that the edges of the dual graph are weighted by the num-
ber of shared nodes. A spanning tree is a classical notion of graph theory. A spanning

192
7 Tractable Cases
subgraph of a graph G is a partial graph of G (thus has the same node set as G). A
spanning tree is a spanning subgraph which is a tree. All connected graphs possess
spanning trees. Given a (connected) graph with weighted edges, a maximum span-
ning tree is a spanning tree that maximizes the sum of its edge weights (Fig. 7.6). A
maximum spanning tree can be built by the following greedy algorithm (Kruskal’s
algorithm): (1) totally order the edges by the decreasing order of their weights; (2)
start from the spanning subgraph without edges; (3) consider each edge according
to the order: If this edge produces a cycle, then discard it; otherwise add it to the
subgraph. This simple algorithm produces a maximum spanning tree.
The previous property yields a polynomial algorithm to recognize an acyclic hy-
pergraph and build a join tree, if any: First build a maximum spanning tree, then
check if it has the running intersection property for any two nodes (which can be
done by considering the only path between them and testing if this path satisﬁes the
running intersection property). If the property is not fulﬁlled, the hypergraph is not
acyclic, otherwise one has a join tree.
Another characterization of acyclic hypergraphs relies on properties of the pri-
mal graph of the hypergraph. As this characterization would lead us to algorithmic
techniques beyond the scope of this book, we shall just give pointers to the relevant
literature.
The primal graph of a hypergraph H is the undirected graph built as follows
(Fig. 7.7):
• it has the same set of nodes as H,
• there is an edge between two distinct nodes if they belong to the same hyperedge
of H.
G
y
z
t
x
z
t
1
2
3
The primal graph of G
x
r
T
r
T
T
T
r
r
r
p
y
Fig. 7.7 Primal graph
Every hyperedge of the hypergraph thus becomes a clique of its primal graph.
The characterizing property is as follows:
Property 7.11. [Mai83]: A hypergraph is acyclic if and only if its primal graph is
chordal and it is conformal.

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
193
A chord of a cycle is an edge that connects two nodes of the cycle but does not
belong to the cycle. A graph is chordal if every cycle of length at least 4 has a
chord. Many difﬁcult problems on graphs become easy on chordal graphs, such as
ﬁnding the size of the maximal clique in the graph, which is NP-complete in the
general case, or ﬁnding all maximal cliques (i.e., not included in another clique)
which is NP-hard. A hypergraph is said to be conformal if every maximal clique of
its primal (chordal) graph form a hyperedge of the hypergraph. [TY84] provides a
linear algorithm to check hypergraph-acyclicity and build a join tree based on the
previous property (in the context of databases).
Further References
Properties of chordal graphs have been extensively studied in graph theory. In par-
ticular, [GHP95] gives a simple algorithm with linear complexity for checking the
chordality of a graph and computing a clique-tree if it is chordal; a clique-tree of a
chordal graph is a tree where the nodes are the maximal cliques of the graph and
satisfying the running intersection property (if the primal graph of the hypergraph
is chordal and conformal then the clique tree can be seen as a join tree restricted
to maximal hyperedges of the hypergraph). In the context of constraint networks,
hypergraph acyclicity is discussed in detail and algorithm schemes are given in
[Dec03].
7.3.3 Equivalence with the Existential Conjunctive Guarded
Fragment
Other motives have lead to an equivalent notion of acyclicity (up to split of individ-
ual concept nodes). They take root in the exploration of relationships between BGs
or SGs and a fragment of FOL called the guarded fragment introduced in [AvBN96].
In [Ker01], Kerdiles deﬁnes the notions of the crazed form of a BG and several
kinds of covering of this crazed form, namely acyclic covering1 and guarded cover-
ing. The crazed form of a BG G is the SG obtained from the normal form of G with
a minimum number of concept splits, such that each concept node is adjacent to at
most one relation node. Let us recall that the concept split operation splits a concept
node c into two coreferent nodes c1 and c2 and attaches each relation that was linked
to c to either c1 or c2 (see elementary generalization operations in Chap. 3). To build
the crazed form of G, each concept node in G attached to n relations (n ≥2) is split
n times to obtain n concept nodes attached to one relation. Figure 7.8 shows a BG
G and its crazed form.
1 The name used is “tree covering,” but as the graphs are not necessarily connected we prefer to
use “acyclic” covering.

194
7 Tractable Cases
r
r
r
G
x
z
y
a
x1
x2
y1
y2
a1
a2
r
r
r
r
x3
r
T
T : a
T : a
T
T
T
T
T
T
T
T : a
T
Φ(G) = ∃x∃y∃z⊤(x)∧⊤(y)∧⊤(z)∧⊤(a)∧R(x,y)∧R(y,a)∧R(a,x)∧R(x,z)
Fig. 7.8 A BG and its crazed form
This notion thus slightly differs from the antinormal form, where a concept node
is incident to at most one edge (cf. Fig. 7.9).
t
t
t
2
r
2
1
G
r
antinorm(G)
1
Fig. 7.9 G is in crazed form (but not in antinormal from)
The crazed form of a BG (say G) is unique and has the same logical meaning
as G. Let us call component of the crazed form of G one of its maximal connected
subgraphs without coreferent nodes, i.e., a subgraph composed of one relation node
and its neighbors (a star graph), or an isolated concept node (in this case, the node
was already isolated in G). In the following, it will be convenient to “materialize”
the coreference relation on generic nodes by coreference links (cf. Chap. 3) and to
call the other edges true edges. A covering of G is obtained from the crazed form
of G by removing some coreference links (possibly none) in such a way that the
coreference relation is kept unchanged: If two generic nodes are coreferent in G,
they must be linked by a path of coreference links in the covering. An extended path
is a path in the covering taking true edges as well as coreference links. An acyclic
covering of G is a covering with at most one extended path between two concept
nodes belonging to distinct components. See Fig. 7.8: Consider the crazed form
pictured on the right; an acyclic covering is obtained by removing one coreference
link in the triangle on x1, x2 and x3, for instance the edge x1x3. The acyclic covering
notion characterizes the graphs without true cycles of [BMT99]:
Property 7.12. [Ker01] A BG is transformable into a logically equivalent acyclic
BG by splitting individual concept nodes if and only if it has an acyclic covering.

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
195
Proof. Let T be an acyclic BG equivalent to the BG (say G) and let us build an
acyclic covering of G from T. In the crazed form of T, for each coreference clique
coming from the split of a generic node c of G, we choose one of the copies of c
and keep only the coreference links between this copy and the other copies. Since T
has no cycle, we obtain an acyclic covering of the crazed form. Indeed, if there was
a cyclic extended path in this covering, one would obtain a cycle in T by merging
copies of the same node in T. Conversely, if we merge all generic coreferent nodes
of an acyclic covering, a multigraph-acyclic BG is obtained, which is equivalent to
G.
⊓⊔
It is convenient to consider an abstraction of a covering: It is the multigraph
whose nodes are components of the covering and such that, for each coreference
link in the covering between a node in component Ci and a node in component
Cj, there is an edge between Ci and Cj. A covering is an acyclic covering if its
abstraction has no cycle (even no multiedge). Figure 7.10 shows the abstractions of
the crazed form (on the left) and the acyclic covering (on the right) from Fig. 7.8.
R(x,y)
R(x,z)
R(x,a)
R(y,a)
R(x,y)
R(x,z)
R(x,a)
R(y,a)
Abstractions of the crazed form and the acyclic covering in Fig. 7.8
Atoms stand for components of the crazed form
Fig. 7.10 Covering abstractions
Let us now generalize the notion of an acyclic covering to that of a guarded
covering: the abstraction of a guarded covering is an acyclic multigraph, i.e., the
only cycles authorized are composed of multiedges between two components. More
precisely, there is no cycle of form (C1 C2 ... Ck C1), k > 2, where all Ci, 1 ≤i ≤k,
are distinct.
Figure 7.11 gives an example of a guarded covering (from left to right: a BG G,
a guarded covering of it and the abstraction of this covering). Figure 7.12 shows a
non-guarded BG. Actually its crazed form is its sole covering, which is not guarded.
Deﬁnition 7.4 (guarded BG). A BG is guarded if it has a guarded covering.
The abstraction of the crazed form of a BG has the same structure as the dual
graph of this BG (if edges corresponding to shared individual concept nodes are
ignored). One goes from the dual graph to a join tree (or a set of join trees if it is not
connected) by removing edges while preserving the running intersection property.
Equivalently, one goes from the crazed form to a guarded covering by removing
coreference links while preserving the coreference relation. Hence the following
property.

196
7 Tractable Cases
p
r
r
r
r
r
r
r
r
G
x
x
x
x
y
z
y
y
y
z
z
z
z
x
p
T
T
T
T
T
T
T
T
T
T
T
T
T
T
P(x,y,z)
R(x,y)
R(x,z)
R(y,z)
R(z,x)
3
2
1
Φ(G) = ∃x∃y∃z(⊤(x)∧⊤(y)∧⊤(z)∧R(x,y)∧R(y,z)∧R(z,x)∧R(x,z)∧P(x,y,z))
Fig. 7.11 Guarded covering
r
r
r
r
r
r
T
T
T
T
T
T
T
T
T
crazed form of G
G
Φ(G) = ∃x∃y∃z(⊤(x)∧⊤(y)∧⊤(z)∧R(x,y)∧R(y,z)∧R(z,x))
Fig. 7.12 Non-guarded BG
Property 7.13. Given a connected BG G, any join tree of G can be linearly trans-
formed into the abstraction of a guarded covering of G, and reciprocally.
Proof. To go from the join tree of G to the abstraction of a guarded covering of
G, transform each edge labeled by a set S into |S| edges with the same extremities.
Reciprocally, transform the multiedges (possibly restricted to one edge) between
two nodes into a single edge labeled by the set of concept nodes in G yielding these
multiedges.
⊓⊔
Corollary 7.2. A BG is guarded if and only if it is hypergraph-acyclic.
The notion of a guarded BG is imported from the notion of a guarded FOL for-
mula. The basic idea of the guarded fragment of FOL is to restrict the use of quan-
tiﬁers: Each quantiﬁer Q is “guarded” by an atom that contains at least all free vari-
ables in the subformula generated by Q. Deduction in this fragment is decidable.
This fragment turns out to have interesting properties, such as the ﬁnite model prop-
erty (if a guarded formula has a model, it has a ﬁnite model). Here we give only the
deﬁnition of the guarded fragment of FOL(∃, ∧), i.e., the restriction of FOL(∃, ∧)

7.3 Tractability Based on the Hypergraph-Acyclicity of the Source BG
197
to guarded formulas. Guarded BGs exactly correspond to closed formulas of the
guarded fragment of FOL(∃, ∧).
Deﬁnition 7.5 (Guarded fragment of FOL(∃, ∧)). [Ker01] The guarded fragment
of FOL(∃, ∧), in short gFOL(∃, ∧), is inductively deﬁned as follows:
1. every atomic formula (i.e., every atom) belongs to gFOL(∃, ∧),
2. gFOL(∃, ∧) is closed under conjunction,
3. –let free(f) denote the set of free variables in a formula f–
if α is an atom, called a guard, X ⊆free(α), and f is a formula of gFOL(∃, ∧),
such that free(f) ⊆free(α), then ∃X(α ∧f) is in gFOL(∃, ∧).
Any closed formula f of the guarded fragment of FOL(∃, ∧) can be polynomially
translated into a guarded BG, for instance by the mapping f2G (see Sect. 4.3.3.1).
Reciprocally, any guarded BG together with a guarded covering can be polyno-
mially translated into a closed guarded formula: As such, Φ does not produce a
guarded formula in the general case, but a slight modiﬁcation in its deﬁnition, ar-
ranging quantiﬁers and atoms in a certain order computed from the guarded cov-
ering, produces a trivially equivalent guarded formula. Consider, for instance, the
BG G in Fig. 7.11: Φ(G) is not guarded but the following formula Φ′(G) ob-
tained by taking the atom P(x,y,z) as a guard is a guarded formula: Φ′(G) =
∃x∃y∃z(P(x,y,z) ∧(⊤(x) ∧⊤(y) ∧⊤(z) ∧R(x,y) ∧R(y,z) ∧R(z,x) ∧R(x,z)). The
subformula f = ⊤(x)∧⊤(y)∧⊤(z)∧R(x,y)∧R(y,z)∧R(z,x)∧R(x,z) is a guarded
formula with free variables x, y and z. Thus Φ′(G) = ∃x∃y∃z(P(x,y,z) ∧f) is a
guarded formula.
More generally, let G be any guarded BG. The closed guarded formula Φ′(G)
assigned to G is inductively deﬁned as follows.
• If G is not a connected BG, then Φ′(G) is the conjunction of formulas Φ′(Gi)
associated with each connected component Gi of G. It is guarded if each of these
subformulas is guarded.
• If G is connected and restricted to an isolated concept, Φ′(G) = Φ(G) and Φ(G)
is guarded.
• Otherwise, let us consider one of the guarded coverings of G and choose any of
its components as its root. Each component Ci in this rooted covering is the root
of a subtree, which is the guarded covering of a subSG Gi of G. If Ci is a leaf,
then Φ′(Gi) = ∃x1...xp(Relation(Ci)∧Concepts(Ci)), where Relation(Ci) is the
atom assigned by Φ to the relation of Ci, x1...xp are the variables of Relation(Ci)
that do not occur in the component parent of Ci and Concepts(Ci) is the con-
junction of atoms assigned to the concept nodes of Ci, whose assigned term by
Φ is either a constant or one of the variables x1...xp (atoms on free variables are
not considered in order to avoid duplication of atoms). When G is restricted to
a single component Gi, Φ′(Gi) is thus a closed formula and Relation(Ci) is the
guard of Φ′(Gi). If Ci is not a leaf, let Ci1 ... Cik be its children components.
Φ′(Gi) = ∃x1...xp(Relation(Ci) ∧Concepts(Ci) ∧j:1...k Φ′(Gi j)). By induction,
every Φ′(Gi j) is guarded, and every variable occuring free in Φ′(Gi j) also oc-
curs in Relation(Ci). Φ′(Gi) is thus guarded. Φ′(Gi) is closed if Ci is the root
(i.e., Gi = G).

198
7 Tractable Cases
T
S(z,a)
R(x,y,t)
R(x,y,z)
s
r
r
3
2
1
2
1
3
2
1
a
Abstraction of the covering
G
T
T
t
T
x
z
y
C2
C1
C
T:a
x, y, z, t, a are the terms assigned to concept nodes by Φ
Φ′(G) = ∃x∃y∃z (r(x,y,z)∧⊤(x)∧⊤(y)∧⊤(z)∧(∃t(r(x,y,t)∧⊤(t))∧s(z,a)∧⊤(a)))
Fig. 7.13 From guarded BGs to guarded formulas
Let us consider the example in Fig. 7.13. This ﬁgure pictures a BG G and the
abstraction of a guarded covering of G, with components C, C1 and C2, symbolized
by the atom associated to the relation node by Φ. Φ′(G1) = ∃t(r(x,y,t) ∧⊤(t)).
Φ′(G2) = s(z,a) ∧⊤(a). One obtains Φ′(G) = ∃x∃y∃z (r(x,y,z) ∧⊤(x) ∧⊤(y) ∧
⊤(z)∧(∃t(r(x,y,t)∧⊤(t))∧s(z,a)∧⊤(a)))
Theorem 7.1 (Equivalence of guarded BGs and guarded FOL fragment).
[Ker01] Guarded BGs are equivalent to the (closed) guarded fragment of FOL(∃,∧).
7.4 Generalizations of Graph-Acyclicity
and Hypergraph-Acyclicity
To complete the panorama, let us brieﬂy mention generalizations of graph-acyclicity
and hypergraph-acyclicity. We just provide deﬁnitions and results, without any illus-
trations. Readers interested in further developments are referred to the cited papers.
7.4.1 Graphs and Treewidth
The notion of treewitdh was introduced by Robertson and Seymour in the frame-
work of their fundamental research on graph minors (see, e.g., [RS86]). It has proven
to be of prime importance in complexity theory. Indeed, many well-known combi-
natorial NP-hard problems become polynomially solvable when restricted to graphs
with treewidth bounded by a constant (see, e.g., [Bod93]). This is the case for BG-
HOMOMORPHISM as we shall see later.
The treewidth can be seen as a measure of tree-likehood, or degree of graph-
acyclicity. Roughly, a (connected) graph has small treewidth if it can be decomposed
into a tree structure where each node represents a small subgraph. More precisely, a

7.4 Generalizations of Graph-Acyclicity and Hypergraph-Acyclicity
199
tree decomposition of a graph G is a pair (T,χ), where T = (XT, ET) is a tree and
χ is a labeling function that associates a set of nodes of G to each node x ∈XT such
that the following conditions are satisﬁed:
1. For each node v in G, there exists x ∈XT such that v ∈χ(x),
2. for each edge uv in G, there exists x ∈XT such that u ∈χ(x) and v ∈χ(x),
3. for each node v in G, the set {x ∈XT|v ∈χ(x)} induces a connected subgraph
of T (equivalently: If v ∈χ(x) and v ∈χ(y), then, for every node n in the path
between x and y, v ∈χ(n)).
Conditions 1 and 2 ensure that all nodes and edges of the graph appear in the
decomposition. Condition 3 is the “running intersection property” that we have seen
for join trees. A tree decomposition has width k if the largest subgraph occurring in
it has k + 1 nodes. The treewitdh of a graph is the minimum width in all of its tree
decompositions. In particular, a (connected) graph is acyclic if and only if it has
treewidth 1. A procedure to solve a problem on a graph with bounded treewidth k
generally involves two steps: First, a tree decomposition of width k is computed;
then, an algorithm based on the tree decomposition is applied.
The treewidth of a graph is NP-hard to compute. More precisely, given a graph
G and an integer k, determining whether G has a treewidth less or equal to k is an
NP-complete problem, as shown in [ACP87]. However, the same paper shows that
if k is ﬁxed (i.e., k no longer belongs to the data of the problem, as is the case for
H in the H-COLORING problem, see Sect. 7.1.2), the problem becomes polynomial
time solvable; an algorithm is provided that answers the question, and constructs a
tree decomposition of width less or equal to k if it exists, using O(nk+2) time, where
n is the size of the graph. Algorithms with better theoretical complexity were later
developed (see [Bod96] and the review paper [Bod98] for more references).
Let now consider the BG-HOMOMORPHISM problem (from G to H). Given a
tree decomposition of G of width k, it can be solved in a time exponential in k,
and polynomial in the size of G and H. Indeed, there are at most nk+1
H
homomor-
phisms from a subgraph of G with k + 1 nodes to H (with nH being the number
of nodes of H). From this observation and the preceding result, we conclude that
BG-HOMOMORPHISM is polynomial if k is ﬁxed and G has treewidth bounded by k.
The following result is thus obtained with respect to BG-HOMOMORPHISM:
Corollary 7.3. (from [ACP87]) The following problem “k-tree BG-HOMOMOR-
PHISM” is polynomial: Given a BG G with treewidth at most k, and a BG H, is
there a homomorphism from G to H?
However, if there are polynomial algorithms computing “good” tree decompo-
sitions their practical use is very limited since their complexity contains a large
constant factor and has k in the exponent. In other words, the best algorithms from a
theoretical viewpoint are exponential in the size of the treewitdh. In [KBvH01],
alternatives to these algorithms are studied; they are based on heuristics giving

200
7 Tractable Cases
algorithms that are not exponential in the treewidth (but provide no theoretical guar-
antee on the quality of the result)2.
7.4.2 Hypergraphs and Hypertreewidth
A measure of hypergraph-acyclicity can be obtained by importing the treewidth no-
tion and applying it to a graph associated with the hypergraph (e.g., its primal graph
or incidence graph). In so doing, one obtains classes of hypergraphs whose associ-
ated graphs have a treewidth bounded by a certain k, for which HOMOMORPHISM
is solvable in polynomial time. However, these notions are incomparable with re-
spect to hypergraph-acyclicity [FFG01] (and [FFG02] for a journal version): There
are families of acyclic hypergraphs whose primal graph has unbounded treewidth
and, on the other hand, there are families of hypergraphs whose primal graph has
bounded treewidth that are not hypergraph-acyclic.
Querywidth [CR97] was an attempt to deﬁne a measure of acyclicity on the hy-
pergraph directly, which would play the same role as treewidth for graphs. It gen-
eralizes hypergraph-acyclicity (a hypergraph is acyclic if and only if its querywidth
is 1) and treewidth (in the sense that the querywidth is always less or equal to the
treewidth of the associated primal graph). The negative point is that the problem
of determining whether a hypergraph has a querywidth less or equal to k is NP-
complete for k = 4, as shown by Gottlob, Leone and Scarcello [GLS99]3. Therefore
these authors introduce another notion, i.e., hypertreewidth.
Hypertreewidth is deﬁned as follows. A hypertree for a hypergraph H is a triple
(T, χ, λ), where T = (XT, ET) is a rooted tree and χ and λ are labeling functions
associating two sets with each node x ∈XT: a set χ(x) of nodes of H and a set λ(x) of
hyperedges of H. A hypertree decomposition of H is a hypertree HD = (T, χ, λ),
such that the following conditions are satisﬁed:
1. For each hyperedge h of H, there exists x ∈XT such that the nodes of h belong
to χ(x) (it is said that x covers h),
2. for each node v of H, the set {x ∈XT|v ∈χ(x)} induces a connected subgraph of
T,
3. for each x ∈XT, χ(x) is included in the set of nodes appearing in the hyperedges
of λ(x),
4. for each x ∈XT, let χ(Tx) be the union of the sets χ(y) for all y in the subtree Tx
rooted in x; then, the intersection between the set of nodes appearing in λ(x) and
χ(Tx) is included in χ(x) (due to (3), the inclusion is in fact an equality).
2 See the web page [Bod] for an up-to-date view of practical algorithms and benchmarks related to
tree decompositions.
3 However, as proven in [CR97], the querywidth of a hypergraph can be approximated by the
treewidth of its incidence graph (in particular, it is strictly smaller).

7.4 Generalizations of Graph-Acyclicity and Hypergraph-Acyclicity
201
The width of a hypertree decomposition is the maximum number of edges label-
ing a node (i.e., maxx∈Tx|λ(x)|). The hypertreewidth of a hypergraph is the minimum
width throughout all its hypertree decompositions.
Hypertreewidth has nice properties:
• it generalizes hypergraph-acyclicity and querywidth (if a hypergraph has query-
width ≤k, it also has hypertreewidth ≤k, but the opposite does not hold), thus
generalizing the treewidth (as the treewidth of the primal graph is an upper bound
of the querywidth),
• it is polynomially recognizable (given a hypergraph, determining whether it has
a treewidth less than a constant k can be done in polynomial time),
• (directed) hypergraph homomorphism checking is polynomial on classes of hy-
pergraphs with bounded hypertreewidth.
Corollary 7.4. (from [GLS99]) The following problem “k-hypertree BG Homomor-
phism” is polynomial: Given a BG G with hypertreewidth at most k, and a BG H, is
there a homomorphism from G to H?
Note, however, that this beautiful theoretical result does not necessarily lead to
practical algorithms (see the discussion on treewidth).
7.4.3 Expressivity Results
Let us end this part with some expressivity results. Correspondences between the
treewidth and hypertreewidth notions and fragments of FOL have been established,
which give indications on the expressive power of the BG fragment obtained.
Kolaitis and Vardi [KV00] proved that the class of all conjunctive queries (thus
BGs) having treewidth less than k (i.e., their incidence graphs have treewidth less
than k) are equivalent in expressive power to the k-variable fragment of FOL(∃, ∧),
i.e., the class of FOL(∃, ∧) formulas using at most k variables.
The class of conjunctive queries (SGs) with hypertreewidth at most k coincides
in expressive power with the k-guarded fragment of FOL(∃, ∧) [GLS01]. The k-
guarded fragment is a generalization of the guarded fragment, where k atoms can
jointly (but not solely) act as guards. More precisely, the condition (3) of deﬁni-
tion 7.5 is replaced by:
If α1, ... αj are atoms, with j ≤k, X ⊆
i:1... j free(αi), and f is a k-guarded
formula of FOL(∃, ∧), such that free(f) ⊆
i free(αi), then ∃X(α1 ∧... ∧αj ∧f)
is a k-guarded formula of FOL(∃, ∧). For k = 1, one has the guarded fragment of
FOL(∃, ∧), equivalent to acyclic hypergraphs. Figure 7.14 summarizes the corre-
spondences between classes of BGs and fragments of FOL(∃, ∧).

202
7 Tractable Cases
Without
true cycles
 
Hypergraph−acyclic
Basic conceptual graphs
    FOL
Existential conjunctive
Guarded
Hypertreewidth bounded by k
k−guarded
Treewidth <k 
k−variables
Graph−acyclic
2−variables
Classes of BGs are in plain text and fragments of FOL(∃, ∧) are in italics. The dotted line ﬁgures
the limit between theoretical tractability and intractability of BG-HOMOMORPHISM.
Fig. 7.14 Classes of SGs and fragments of FOL(∃, ∧)
7.5 What About Labels?
All complexity results we have harvested so far were obtained by restricting the
structure of the graphs/hypergraphs. Now, seen as combinatorial objects, BGs are
not only graphs, or hypergraphs; they are labeled. Label diversity in the graphs
encountered in applications is a major reason why practically efﬁcient algorithms
can be built. However, to the best of our knowledge, there are few results about
how properties of the labeling function may inﬂuence the complexity of labeled
graph/hypergraph homomorphism checking.
Let us cite two results, both based on restricting the labeling of the target
graph. The ﬁrst one comes from databases. Recall that the CONJUNCTIVE-QUERY-
CONTAINMENT (CQC) problem takes two conjunctive queries as input, say q1 and
q2, and asks if q1 is contained in q2 or, equivalently, if there is a query homomor-
phism from q2 to q1 (see Chap. 5). In [SY80], it is shown that this problem becomes
polynomial if each atom in q2 has no more than two candidate images in q1 and an
algorithm in O(n2) time is given, where n is the size of the input 4. It is also shown
4 The problem actually considered in this paper is “tableau containment” where tableaux represent
queries closely related to conjunctive queries.

7.5 What About Labels?
203
that the problem remains NP-complete when each atom in q2 has no more than three
candidate images in q1.
It follows from the transformation from CQC to BG-HOMOMORPHISM (detailed
in Chap. 5) that BG-HOMOMORPHISM is polynomial when, after a polynomial ﬁl-
tering step (such as computing the standard ﬁlter and possibly making it edge-
consistent), each relation node in the source BG has at most two candidates. An
obvious case for which this property is true if, assuming that the relations in the vo-
cabulary are not ordered (which occurs frequently in conceptual graph applications),
each relation label occurs at most twice in the target BG.
Let us roughly outline a polynomial algorithm adapted from the algorithm de-
scribed in [SY80]. Assume that we start from a standard ﬁlter of G with respect
to H. For any relation node r in G, let r1 and r2 denote its candidates (r possibly
has only one candidate). Let us begin with the main idea. The algorithm chooses a
relation node r and one of its candidates, say r1. This deﬁnes a partial solution, say
θ = {(r,r1)}. The algorithm will try to extend the domain of θ to all relations in G
for which an image is forced by this choice. Let R be this set. Initially, R contains
{r} and it grows by traversing G from r. Let s be any relation in R explored at a
given step. Each relation s′ outside R that shares at least a neighbor with s is consid-
ered. If only one of the candidates for s′ is compatible with the current θ, the image
of s′ is forced by the assignment {(r,r1)}, thus the corresponding pair is added to θ
and s′ is added to R. If both candidates for s′ are incompatible with the current θ,
then there is no solution with the assignment (r,r1) and the construction of R fails.
Assume R has been successfully built. The property that underlines the algorithm is
as follows: Let h be any homomorphism from GR, the subgraph of G induced by the
relation nodes outside R, to H; the union of θ and h deﬁnes a homomorphism from
G to H. Indeed, let v be a relation in R and let w be a relation outside R. h(w) is one
of the two candidates of w, and by hypothesis it is compatible with θ(v), otherwise
w would have been either forced or declared incompatible during the construction of
R. The algorithm starts from any r and builds a set R for each candidate of r. There
is no solution if the construction of both sets fails. If one construction succeeds,
then the θ built deﬁnes a partial solution. The process is iterated with the remaining
unassigned relation nodes in G.
Finally, let us mention the polynomial reductions between CQC and SAT (Is a
given conjunction of propositional clauses satisﬁable?) described in [Sar95]. More
speciﬁcally, it is shown that the so-called K-CONTAINMENT problem (in which each
atom of q2 has at most k candidates in q1) is essentially the same as the K-SAT
problem (in which each clause contains at most k literals). The particular case men-
tioned above thus corresponds to the 2-SAT problem, for which efﬁcient algorithms
are known.
The second case relies on a simple observation made in a graph framework ap-
plied to machine learning [LB94] [LS98]. An unordered set of labels is considered
and used to label nodes of graphs. The fundamental notion is homomorphism on
these graphs. First note that checking homomorphism from a graph G to a graph H
is polynomial if the nodes of H all have different labels, i.e., the labeling mapping
from the nodes of H to the set of labels is injective. Indeed, each node of G can be

204
7 Tractable Cases
mapped to at most one node of H (we thus have a special case of the preceding cited
case). Such a restriction is too strong to be useful in practice, but let us consider
a weaker restriction: Let us say that the labeling mapping is locally injective if its
restriction to the neighborhood of each node is injective, i.e., all neighbors of a node
have distinct labels. A graph with a locally injective labeling mapping is called a
li-graph. Checking homomorphism from G to H is polynomial if H is a li-graph.
Indeed, as soon as a potential image has been assigned to a node z of G, there is at
most one possibility for each neighbor of z, thus, by iteration, for each other node
of G. Note also that the number of homomorphisms from a li-graph G to a li-graph
H is bounded by the number of nodes in H. Thus all solutions can be exhibited in
polynomial time. Another interesting property is that a connected li-graph is irre-
dundant. Indeed, since the labels of neighbors of a node are not comparable, there
is no folding of the graph (Property 2.9 in Sect. 2.3.2). As for the property of being
a tree, the property of being a li-graph corresponds to a case that can be visually
checked by a user and can be found in practical applications.
Let us translate this property to BGs. Assume again that the relations in the vo-
cabulary are not ordered. Then enforcing local injectivity of the labeling mapping
on concept nodes (i.e., all relations incident to a concept are of different type) in
the target BG yields a tractable case for BG-HOMOMORPHISM. The following less
restrictive condition on the target BG would also be suitable: For all concept nodes
c, if c is the i-th neighbor of two distinct relation nodes r and s, i.e., if there are
edges (r,i,c) and (s,i,c) with r ̸= s, then r and s are of different types.
In conclusion, exhibiting tractable cases combining properties on the structure of
BGs and on their labeling is an open challenge.
7.6 Complementary Notes
References to relevant works have been given throughout this chapter. This note
adds some explanations about the pairwise consistency notion, as it appears in
databases [BFMY83]. A desirable property of a database instance is to be globally
consistent. Intuitively, this means that it can be represented by a global relation on all
attributes, in such a way that each relation is obtained by restriction of this global
relation. More speciﬁcally, let us consider a database schema R = {R1, ..., Rn},
and let I = {I1, ..., In} be a database instance on R. I is globally consistent
if there is a universal relation I over the attributes R1 ∪... ∪Rn such that for all
1 ≤i ≤n, I[Ri] = Ii. If there is such a universal relation, it is obtained by a “full join”
I1 1 I2 ... 1 In; in this case, no tuple of any Ii is lost after this full join. Now, I is said
to be pairwise consistent if, for each pair of relations Ii and Ij in I, Ii and Ij are the
same on their common attributes, i.e., for all 1 ≤i, j ≤n, (Ii 1 Ij)[Ri] = Ii. This en-
sures that no tuple of Ii is lost after a join with Ij. Checking pairwise-consistency can
be done in polynomial time, whereas checking global consistency is NP-complete.
A natural question is thus to determine exactly when checking pairwise-consistency
is sufﬁcient to garantee global consistency. [BFMY83] provided the answer: If the

7.6 Complementary Notes
205
hypergraph corresponding to the database schema is acyclic then, for every database
instance over this schema, pairwise-consistency yields global consistency, and re-
ciprocally.

Chapter 8
Other Specialization/Generalization Operations
Overview
This chapter is about more complex specialization/generalization operations than
the elementary specialization/generalization operations studied in Chap. 2. In order
to focus on the main ideas, the conceptual graphs considered here are BGs, and not
SGs. Moreover, for operations involving compatibility notions (i.e., maximal join
and extended join) we consider conjunctive concept types.
In Sect. 8.1, we show how the greatest specialization (or greatest lower bound)
and the least generalization (or least upper bound) of two BGs can be computed.
Computing the least generalization of two formulas is a fundamental problem in
inductive inference. Computing a common specialization of two (or more) BGs is
required in various applications. The greatest lower bound is usually not a “good”
notion since it does not merge BGs, so several speciﬁc common specializations of
two graphs were deﬁned. They are often designed for speciﬁc applications, and we
give here the main ideas that can be used to deﬁne operations ﬁtted for a given ap-
plication. Computing a common specialization of two graphs G and H consists of
establishing a correspondence between nodes in G and nodes in H, then merging
corresponding nodes. The operations can be distinguished by the kind of correspon-
dence between G and H (e.g., bijection between subsets of concept nodes or general
correspondence between a subgraph of G and a subgraph of H), and by a maximality
property of the correspondence.
In Sect. 8.2, the notion of a compatible set of concept nodes of a graph is re-
viewed and compatible sets of relation nodes are introduced. These notions are used
for deﬁning maximal join operations. A maximal join operation between two BGs
G and H consists of ﬁrst merging a concept node in G and a concept node in H, and
then merging as far as possible neighbors of previously merged nodes. Different
neighborhood search strategies lead to different generalized join operations. Usu-
ally a generalized join operation stops when it is no longer possible to merge two
nodes, so the term “maximal join” is used even though this term represents a set of
operations rather than a precisely deﬁned one.
207

208
8 Other Specialization/Generalization Operations
The third section is devoted to the study of compatible partitions of node sets. We
deﬁne and study compatible partitions of the concept node set of a BG, compatible
partitions of the relation node set and compatible partitions of the whole node set
of a BG. This last notion is strongly related to surjective homomorphisms. These
notions are used for the extended join operation, which generalizes maximal join
operations.
The main result in Sect. 8.4 concerns characterization of BGs that can be ob-
tained from a set of given BGs using elementary specialization operations (some-
times known as “canonical” BGs). As a corollary, one obtains an inductive deﬁnition
of the BGs built on a given vocabulary . This study is done using surjective homo-
morphisms and the union of a set of BGs.
Finally, in Sect. 8.5, the expansion and contraction operations used when consid-
ering deﬁned concept types are presented.
This section is not an in-depth study of problems related to type deﬁnitions. The
aim is only to provide other examples of conceptual graph operations.
8.1 The Least Generalization and Greatest Specialization of Two
BGs
Computing a (or the) least generalization of two or more descriptions is a fundamen-
tal problem in inductive inference, which occurs particularly in machine learning.
This operation can be offered by knowledge-based systems along with classical in-
ference services. Consider, for instance, the tasks of building concept or relation
deﬁnitions, or schemata typically associated with certain concepts or relations, or
rules expressing general properties of certain entities. It may help to start from a
set of descriptions assumed to be examples of the same concept (or relation) and
consider their least generalization as a working basis. Least generalizations can also
be used to organize a large set of descriptions in a hierarchical structure.
If the description language is a BG language, this problem in its basic form takes
two BGs as input, say G and H, and asks for a least generalization of G and H, i.e., a
BG K such that K ⪰G and K ⪰H and for all BG K′, if K′ ⪰G and K′ ⪰H then K′ ⪰
K. If we restrict ourselves to irredundant BGs, K is unique (up to ismorphism): it is
the least upper bound of G and H in the irredundant BG lattice (cf. Sect. 2.3.2). The
categorial product of two graphs (a graph theoretic notion which can be found in the
literature under a variety of other names, e.g., weak product) is used to compute a
least generalization of two BGs. Let us review the categorial product of two ordinary
graphs before considering BGs.
Deﬁnition 8.1 (Categorial Product). The (categorial) product of two (ordinary)
graphs G = (X,U) and H = (Y,V) is the graph G×H = (Z,W) with Z = {(x,y)|x ∈
X and y ∈Y} and W = {((x,y),(z,t))|(x,z) ∈U and (y,t) ∈V}.
Example. Figure 8.1 shows an example of the product of two graphs.

8.1 The Least Generalization and Greatest Specialization of Two BGs
209
3c
°
°
°
°
°
°
°
°
°
°
°
°
1
2
GxH
H
G
°
°
3a
2a
3b
2b
°
2c
1c
1b
1a
c
b
a
3
Fig. 8.1 The categorial product of two graphs
Note that G×H and H ×G are isomorphic. The following properties about ho-
momorphism can be easily observed.
Property 8.1 (Standard properties of the categorial product).
1. There is a homomorphism from G × H to G and a homomorphism from G × H
to H.
2. If there is a homomorphism from K to G and a homomorphism from K to H,
then there is a homomorphism from K to G×H.
3. There is a homomorphism from G to G × H if and only if there is a homomor-
phism from G to H.
Proof. 1. Take the homomorphism from G×H to G (resp. from G×H to H), which
maps each vertex (x,y) to vertex x (resp. y),
2. Take two homomorphisms f : K →G and f ′ : K →H. Then the mapping h : K →
G×H, which maps every vertex x to (f(x), f ′(x)), is a homomorphism,
3. It follows from (1) and (2): If there is a homomorphism from G to G × H, then
by (1) there is a homomorphism from G to H; reciprocally, if there is a homo-
morphism from G to H then, since there is a homomorphism from G to G, by (2)
there is a homomorphism from G to G×H.
⊓⊔
Let us extend the deﬁnition of the graph product to BGs. Labels have to be taken
into account. For ordinary graphs, we had exactly one vertex for each pair of vertices
(x,y), with x in G and y in H. Now the number of nodes created from (x,y), where
x and y are two concept nodes or two relation nodes in G and H respectively, is the
number of minimal upper bounds of x and y labels. Since the concept type set has

210
8 Other Specialization/Generalization Operations
a greatest element, and individual markers are less than the generic marker, every
pair of concept node labels has at least an upper bound. If the concept type set is a
sup-semi-lattice (for instance if conjunctive concept types are considered), all pairs
have a unique minimal upper bound (called their least upper bound, lub); otherwise,
some pairs have several minimal upper bounds.
Pairs of relation labels may have any number of minimal upper bounds (includ-
ing zero). Therefore, if no assumption is made on the structure of the concept and
relation type sets, the size of G×H is no longer bounded by the product of the size
of G and H (which is a rough upper bound) but involves the size of the vocabulary,
and more precisely the maximal number of minimal upper bounds of two concept
or relation types.
For the next deﬁnition, we consider the particular case where two concept labels
have a least upper bound (i.e., a single least generalization) and two relation labels
have either a least upper bound or do not have an upper bound. Then the number
of concept nodes in G×H is |CG|×|CH|, the number of relation nodes is bounded
by the sum of (|Ri
G|×|Ri
H|), where Ri
G and Ri
H denote the set of relation nodes with
arity i occurring respectively in G and in H, and the number of edges is bounded by
the sum of (|Ri
G|×|Ri
H|×i).
Deﬁnition 8.2 (BG product). Let V be a vocabulary where the concept type set is
a sup-semi-lattice and two relation types have at most one minimal upper bound,
and let G and H be two BGs on V. The product of G and H is the BG K = G × H
built as follows:
• CK = {(c,d)|c ∈CG and d ∈CH}, and the label of (c,d) is the lub of lG(c) and
lH(d),
• RK = {(r,s)|r ∈RG, s ∈RH and there is a relation label t with t ≥lG(r) and
t ≥lH(s)} , and the label of (r,s) is the lub of lG(r) and lH(s),
• EK = {((r,s),i,(c,d))|(r,i,c) ∈EG and (s,i,d) ∈EH}.
It can be easily checked that G×H is a BG and that the BG product satisﬁes the
standard properties (cf. property 8.1). This operation can be extended to the product
of n BGs.
Property 8.2. The least upper bound, i.e., the least generalization, of two BGs G and
H is the irredundant form of G×H.
Example. Consider G and H in Fig. 8.2. These BGs are obtained from the graphs in
Fig. 8.1 by transforming the vertices into concept nodes and edges (u,v) into binary
relation nodes, with the node assigned to u for ﬁrst neighbor and the node assigned
to v for second neighbor. All pairs of concept node labels have a lub. Concerning
relation labels, one assumes that r and s have a lub, as well as r and t, but s and t have
no upper bound. Compare the skeleton of G×H to the product graph in Fig. 8.1: the
relation nodes corresponding to the edges (1b,3a) and (2b,3a) do not exist (since s
and t have no upper bound). It can be easily checked that G × H maps to G and to
H (assign to each node i j in G × H the node i in G and the node j in H). One can
check that G×H is not irredundant, the gray part composed of the concept node 1c,

8.1 The Least Generalization and Greatest Specialization of Two BGs
211
G
GxH
GxH
H
s
t4:n
lub(t1,t3)
s
3b
lub(t3,t4)
lub(r,s)
lub(r,s)
lub(t1,t4)
lub(r,s)
t2:m
s
r
s
t1
t4:n
1
2
3
s
t
r
t3
t2
t4:n
c
a
b
s
s
r
lub(r,t)
lub(r,s)
lub(r,s)
lub(r,s)
2b
3b
2c
3c
3a
2a
1a
1c
1b
°
°
°
°
°
°
°
°
°
skeleton of 
1c
3c
1a
2b
1b
2a
2c
lub(t2,t3)
r
lub(t1,t2)
t2
lub(r,t)
lub(t2,t4)
Fig. 8.2 The least generalization of two BGs

212
8 Other Specialization/Generalization Operations
the concept node 2c and its neighbor relation node can be removed (cf. the dashed
arrows in Fig. 8.2). The BG obtained after these deletions is the least generalization
of G and H (check that it is irredundant even if some labels might actually be the
same in some vocabulary).
With the assumption that the concept type set is a sup-semi-lattice, G × H is
normal if G and H are normal. Indeed, an individual concept node (c,d) with marker
m may be created in G × H only if c and d are both individual nodes with marker
m; If G and H are normal, they may each possess at most one node with marker m.
As illustrated in Fig. 8.2, G × H is generally not irredundant, even if G and H are
irredundant. As far as we know, the conditions under which G × H is irredundant
have not been characterized.
Computing a common specialization of two (or more) graphs is required in var-
ious applications. A greater specialization of two BGs is easily built: It sufﬁces to
compute their disjoint sum (see Property 2.10). Hence the property:
Property 8.3. The greatest lower bound of two BGs G and H is the irredundant form
of their disjoint sum G+H.
G + H is generally not normal or irredundant, even though G and H are normal
and irredundant. However, note that given G and H irredundant, G + H is irredun-
dant if and only if there is no connected component of one of the two graphs that
maps to a connected component of the other. Thus, in the case where G and H are
connected irredundant graphs, the greatest lower bound (glb) of G and H is G if H
maps to G, H if G maps to H, and otherwise it is exactly G+H.
The disjoint sum is easily computed but it is generally considered as unsatisfying
because it does not “merge” the two graphs. This has led to the introduction of other
notions of common specializations which rely on more complex operations than the
elementary specialization operations studied in Chap. 2. Among them, the so-called
“maximal join” is the most popular. It is studied in the next section.
8.2 Basic Compatibility Notions and Maximal Joins
In this section, we deﬁne compatible sets of concept nodes and of relation nodes.
A node set can be merged into a single node if and only if it is a compatible set.
Compatible sets are then used for deﬁning the maximal join operation.
8.2.1 Compatible Node Set
Let us review the notion of compatible (or mergeable) concept nodes studied in
Chap. 3, i.e., when conjunctive concept types are considered.
A set of compatible concept nodes (cf. Deﬁnition 3.9) is a set of concept nodes
such that the set of their labels is compatible, i.e., these labels possess a greatest

8.2 Basic Compatibility Notions and Maximal Joins
213
lower bound. The label of a compatible concept node set S is l(S) = glb({l(x) | x ∈
S}).
Compatibility is strongly related to homomorphism: If a set of concept nodes is
compatible, then these nodes may all be mapped to the same node by a homomor-
phism, and conversely.
More precisely, let us consider two BGs G and H and a homomorphism π from
G to H. If y is a concept node in π(G), then S = π−1(y) is a compatible concept
node set of G. Indeed, for any x ∈S one has lG(x) ≥lH(y), thus the label set of S has
a lower bound (i.e., the conjunction of all types appearing in S is not a banned type
and at most one individual marker appears in S), and it has a greatest lower bound.
A set of concept nodes S is compatible if and only the nodes in S can be merged
into a single node. Merging these nodes consists of replacing them by a single node
labeled l(S) and having for neighbors the union of the neighbors of all nodes in
S. In terms of elementary specialization operations: ﬁrst restricting their type to
the conjunction of their types, secondly, if an individual marker m appears in S,
restricting their marker to m, and thirdly joining them.
Property 8.4. Let G be a BG and S be a compatible concept node set of G. The graph
G/S obtained from G by merging S is a BG and there is a (surjective) homomor-
phism from G to G/S.
We shall now deﬁne the compatibility of relation nodes, which is more complex
than the concept node compatibility.
The set of partitions of the integer set {1,...,k} is partially ordered by the usual
order on partitions. Given two relations r1 and r2 of the same arity, Pr2 (i.e., the
edge partition associated with r2, cf. Deﬁnition 6.2) is thinner than Pr1 (notation
Pr2 ⊆Pr1) if each class of Pr2 is included in (or equal to) a class of Pr1. Let π be
a BG homomorphism mapping a relation node r in G to a relation node r′ in G′.
Then, Pr is thinner than Pr′. Indeed, two concept nodes can have the same image,
whereas a node cannot have two images. Moreover, let c′ be a neighbor of r′. For
any neighbor c of r such that Pr[c] ⊆Pr′[c′], one has and π(c) = c′.
Example. Consider Fig. 8.3, where π is a homomorphism from G to G′, r(a,b,c,d,e,
f) is in G, π(r) = r′ and r′(u,v,u,v,w,z) is in G′. Pr = {{1},{2},...,{6}} (it is the
discrete partition), and P′
r = {{1,3},{2,4},{5},{6}}. As Pr[a] = {1} ⊆{1,3} =
Pr′[u] and Pr[c] = {3} ⊆{1,3} = Pr′[u], one has π(a) = π(c) = u.
G’
G
f
e
a
b
c
d
z
w
u
v
π
5
r
3
r’
4
2
1
1
2
4
5
6
6
3
Fig. 8.3 Pr and homomorphism

214
8 Other Specialization/Generalization Operations
Similar to concept nodes, a set of relation nodes is said to be compatible if these
nodes can be merged, i.e., they may all be mapped to the same node by a homomor-
phism.
More precisely, let G and H be two BGs, π a homomorphism from G to H and y a
relation node in π(G). The set of relation nodes A = π−1(y) = {r1,...,rk} satisﬁes:
1. All ri have the same arity and furthermore for any i = 1,...,k one has lG(ri) ≥
lH(y), therefore the set {lG(r1),...,lG(rk)} has a lower bound.
2. For any i = 1,...,k, the partition Pri is thinner than or equal to Py, and thus the
least upper bound P(A) of all the Pri is thinner than or equal to Py.
3. Let C(A) denotes the set of concept nodes which is the union of the neighbors of
all nodes in A. For any class X in P(A), let C(X) be the subset of C(A) containing
concept nodes linked to a node in A by an edge numbered with an integer in X.
Let C(A) = {C(X) | X ∈P(A)}. Every concept node in C(A) belongs to at least a
subset C(X) ∈C(A) and possibly to several such subsets. C(A) is thus a covering
of the set C(A). Let PC(A) denote the thinnest partition of C(A) greater than (or
equal to) this covering, PC(A) is a compatible partition of C(A).
Example. Let us assume that π is the homomorphism from G to H represented in
Fig. 8.4, with π(r1) = π(r2) = r′. A = π−1(r′) = {r1,r2}. Pr1 = {{1,2},{3}}, Pr2 =
{{1},{2},{3}}, C(A) = {a,b,c,d}, P(A)={{1,2},{3}}, C(A)={{a,b,d},{b,c}},
and PC(A) = {{a,b,c,d}}.
G
d
c
H
r’
1,2,3
(d)
3
2
r1
r2
1
3
2
1
a
b
π
π (a) =π(b) = π(c) = π
Fig. 8.4 Two relation nodes with the same image
A set of relation nodes satisfying all the previous properties is called a compatible
relation node set.
Deﬁnition 8.3 (Compatible relation nodes). A compatible relation node set of a
BG G is a set A = {r1,...,rk} of relation nodes in G satisfying the following con-
straints:
• All relations in A must have the same arity; moreover, the set of labels of A must
have a lower bound (in the vocabulary upon which G is built),
• let C(A) denote the set of concept nodes which are neighbor of at least one rela-
tion node in A; let P(A) denote the lub of the partitions Pri, i = 1,...,k; let PC(A)

8.2 Basic Compatibility Notions and Maximal Joins
215
be the least partition containing the covering C(A) of C(A) associated with P(A);
each class of PC(A) must be a compatible set of concept nodes.
As for the concept nodes, if a set of relation nodes is compatible, one can deﬁne
a specialization operation that consists of merging these relation nodes.
Deﬁnition 8.4 (Compatible Relation Nodes Merging). Let A = {r1,...,rk} be a
compatible relation node set of a BG G. The graph G/A obtained from G by merging
A is deﬁned as follows.
• Compute the partition P(A), i.e., the lub of the partitions Pri.
• Compute C(A) = {C(X) | X ∈P(A)} and PC(A), i.e., the thinnest partition of
C(A) greater than or equal to C(A).
• Merge each class of PC(A) (which involves a sequence of concept restrict and
join).
• Restrict the types of the relation nodes in A to l(A), a maximal lower bound of
{l(r1),...,l(rk)} (now, all relation nodes in A are twin relation nodes).
• Merge A into a single relation node labeled l(A) (i.e. remove all but one of the
twin relation nodes in A).
Note that if the relation type set is not an inf-semi-lattice, then a set of types may
have several maximal lower bounds and the operation is not deterministic.
Property 8.5. Let A be a compatible relation node set of a BG G. The graph G/A
obtained from G by merging A is a BG and there is a (surjective) homomorphism
from G to G/A.
Proof. Let A = {r1,...,rk}. Each class of PC(A) is a compatible concept node set;
thus it can be merged (while keeping a BG). Let us check that after step 4 all nodes
in A are twin nodes. They have the same label l(A), so it remains to verify that if x
and y are i-th neighbors of r j and rl, respectively, then they are in the same class of
PC(A) (thus they are merged into a single node in step 3). Indeed, let X be the class
of i in P(A); x and y belong to C(X), which is included in a class of PC(A). Thus
step 5 keeps a BG.
⊓⊔
8.2.2 Maximal Join
Maximal join is an important operation in conceptual graph applications. Intuitively,
the effect of the maximal join operation is to maximally join, or merge, connected
subgraphs of two graphs. It is mainly used to do plausible inference by applying
conceptual schemata, typical patterns, etc., to facts.
Although there is agreement on the intuitive purpose of this operation, a lot of
variants are considered in practice. In this section, we will thus present the general
ideas behind the maximal join, some variations, and give a simple algorithm that
illustrates one way of implementing this operation. Section 8.3 will provide the

216
8 Other Specialization/Generalization Operations
formal foundations required to deﬁne the notion of extended join, with maximal
join (and its variations) being a particular case of it.
Let us start with the simplest way of joining two graphs, the external join opera-
tion (by distinction with the elementary join operation already deﬁned, which is also
sometimes called internal join). The external join consists of merging two concept
nodes of two disjoint graphs, say G and H.
Deﬁnition 8.5 (External join). Let G and H be two (disjoint) BGs and c and d be
two compatible concept nodes in G and H, respectively. The external join of c in G
and d in H is the BG obtained by ﬁrst, computing G + H, secondly, restricting the
labels of c and d to their glb l, then by identifying c and d.
Since an external join can be decomposed into elementary specialization opera-
tions, the graph obtained is a common specialization of G and H.
A way of extending an external join of c in G and d in H consists of searching
mergeable neighbors (i.e., relation nodes) of c and d, then to check if new con-
cept nodes neighbors of these relations can be merged, and so on. Said otherwise,
starting from a pair of compatible concept nodes, the idea is to search, in a greedy
way, mergeable neighbors of previously identiﬁed mergeable nodes. The algorithm
stops when it is impossible to ﬁnd new mergeable nodes. The result is thus locally
“maximal,” hence the name maximal join for this class of operations.
In order to specify a maximal join operation, one has to deﬁne a condition for
merging concept nodes and a condition for merging relation nodes (the nodes must
be at least compatible, but stronger conditions may be enforced) as well as a strategy
for exploring the graphs. Given two mergeable concept nodes as a starting point,
there may be several maximal joins, but computing one of them can be done in
polynomial time, whereas computing a maximal join with a maximum number of
nodes is NP-hard (indeed it admits homomorphism or injective homomorphism as
a special case, cf. Sect. 5.2).
We now describe a very simple maximal join algorithm. The graph exploration
involves extending the initial external join by a breadth-ﬁrst strategy. One seeks
strongly compatible pairs of relation nodes deﬁned as follows:
Deﬁnition 8.6 (Strongly compatible pair of relation nodes). Two relation nodes
r ∈G and s ∈H are strongly compatible with respect to compatible concept nodes
c ∈G and d ∈H if they fulﬁll:
• type(r) = type(s),
• there is an integer i with (r,i,c) ∈G and (s,i,d) ∈H,
• Pr = Ps and for each class of Pr (or Ps) if c′ (resp. d′) is the neighbor of r (resp.
s) associated with this class, then {c′,d′} is a pair of compatible concept nodes.
Starting from the concept node pair (c,d), the algorithm seeks in a greedy way a
maximal set of strongly compatible pairs of relations with respect to c and d: a ﬁrst
pair (r,s) is sought, then another pair disjoint from (r,s) is sought and so on until no
new pair can be built in the neighborhood of c and d. The found relation pairs yield
concept node pairs, which are used as starting points for a new step.

8.2 Basic Compatibility Notions and Maximal Joins
217
An important point is that the compatibility of concept nodes evolves during
the process. For instance, let (c1,c3) and (c2,c3) be two pairs of initially compatible
concept nodes; assume that the process leads to add the pair (c1,c3) to f; the label of
c2 may be incompatible with the label of the node that will be obtained by merging
c1 and c3 (i.e., lG(c2) may be incompatible with glb({lG(c1),lH(c3)}). That is why
the algorithm maintains two labeling functions memorizing the “current label” of
concept nodes: These functions are initially equal to those of the input graphs and,
when a pair of concept nodes is added to f, the current label of these nodes becomes
the glb of their former current labels. A concept node may appear in several pairs,
thus its current label may change several times.
The result of the algorithm is ﬁrst, the pair (f,g), and secondly, new labeling
functions l′
G and l′
H for concept nodes. Effectively computing the maximal join of the
input graphs consists of merging the nodes of f and g pair by pair. No computation
is necessary to obtain the labels of the new nodes: Merged relation nodes have the
same label, and merged concept nodes have the same label by l′
G and l′
H, which is
exactly the label of the new node.
If the relation nodes are ﬁrst merged according to g, there is no need to consider
f, since concept merging follows from relation merging. If the concept nodes are
ﬁrst merged according to f, relation nodes of the same pair become twins, and a
twin per pair has to be removed (i.e., by a sequence of relation simplify operations).
Hereafter we give the schema of a maximal join algorithm.
The set ToExplore contains pairs of concept nodes that have been added to f but
whose neighborhood has not yet been explored. The boolean explored is used to
explore the neighborhood of a given pair (x,y): Initially false, it becomes true when
no new pairs of relation neighbors of x and y can be built.
Example. Figure 8.5 presents two BGs G and H. For simplicity, it is assumed that
all concept nodes have the same label. Starting with concept nodes 1 and a, two
maximal joins that do not have the same number of nodes can be obtained. The ﬁrst
one is deﬁned by the mapping 1 →a, 2 →b, 3 →c, and the second one by 1 →a,
2 →d, 3 →e, 4 →f, 5 →g.
5
4
3
2
2
1
2
1
s
r
1
r
g
f
e
d
c
b
a
2
2
2
1
1
1
s
r
Fig. 8.5 Maximal join

218
8 Other Specialization/Generalization Operations
Algorithm 23: Maxjoin(G,H,c,d)
Input: two BGs G and H, two compatible concept nodes c ∈G and d ∈H
Output: a pair (f,g) deﬁning a maximal join of G and H with respect to (c,d), with f being
the set of concept node pairs and g being the set of relation node pairs; l′
G and l′
H
are labeling functions
begin
l′
G ←lG
l′
H ←lH
g ←∅
f ←{(c,d)}
ToExplore ←{(c,d)}
while ToExplore ̸= ∅do
Remove (x,y) from ToExplore
explored ←false
while not explored do
if there is a pair (r,r′) of strongly compatible relation nodes with respect to
(x,y), l′
G and l′
H, such that r /∈g, r′ /∈g then
g ←g∪{(r,r′)}
foreach neighbor e of r, with e ̸= x do
let e′ = corresponding(e,r,r′)
if (e,e′) ̸∈f then
f ←f ∪{(e,e′)}
ToExplore ←ToExplore∪{(e,e′)}
l′
G(e) ←glb(l′
G(e),l′
H(e′)
l′
G(e′) ←glb(l′
G(e),l′
H(e′)
else
explored ←true
return (f,g), l′
G, l′
H
end
Figure 8.6 shows that the joined subgraphs are not necessarily isomorphic. As-
sume that all concept nodes in G and H have the same label. Starting from (1,a),
each relation neighbor of 1 is matched with the relation of the same label neighbor
of a. Thus g = {(2,b),(3,c),(4,d)} and f = {(1,a),(5,e),(6,e),(7, f),(7,g)}. The
concept nodes 5, 6 and e will be merged into a single node, as well as the concept
nodes 7, 8 and f. In this particular example, G and H are completely joined. Thus
they map entirely to the obtained graph.
Let us use this ﬁgure to illustrate the role of concept node labels. Assume that
(5,e) and (6,e) are pairs of compatible concept nodes, but that {5,6,e} is not a
compatible set. E.g., lG(5) = (t,a), lG(6) = (t,b) and lH(e) = (t,∗). If (2,b) is the
ﬁrst relation pair added to g, then the pair (5,e) is added to f, and the current label
of 5 and e becomes (t,a). Consequently, (6,e) is no longer a compatible pair. Thus
(3,c) is no longer strongly compatible and cannot be added to f. If (3,c) is consid-
ered before (2,b), then (5,e) becomes an incompatible pair. Thus, depending on the
order in which the relation neighbors of 1 and a are considered, different maximal
joins are obtained.

8.2 Basic Compatibility Notions and Maximal Joins
219
G
7
6
5
4
3
2
1
t
s
r
3
2
2
2
1
1
1
78f
56e
4d
3c
2b
1a
t
s
r
3
2
2
2
1
1
1
maxjoin(G,H)
3
1
1
1
2
2
2
r
s
t
a
b
c
d
e
f
g
H
Fig. 8.6 Maximal Join of non isomorphic subgraphs
The algorithm can be seen as deﬁning two homomorphisms from subgraphs of
G and H to the same graph. More precisely, let G′ (resp. H′) be the subgraph of G
deﬁned by all nodes which are ﬁrst (resp. second) components of an ordered pair in
f or g. First, let us point out that G′ and H′ are subBGs of G and H respectively.
Indeed, let r be a relation node in G′. There is a single relation node s in H′ such that
(r,s) is in g and all neighbors of r (resp. s) are ﬁrst (resp. second) components of
f. Thus, all neighbors of a relation node in G′ are also in G′. Therefore G′ is a BG
(the same holds for H′). Let K denote the BG obtained by merging the correspond-
ing nodes in f and g. K is obtained from G′ and H′ by specialization operations,
therefore G′ and H′ map to K. Furthermore, these homomorphisms are injective on
relation nodes, but not necessarily on concept nodes (Indeed, a concept node may
appear in several pairs, as illustrated by Fig. 8.6).
Depending on the properties desired for homomorphisms from G′ and H′ to K,
one can adapt the condition for merging relation or concept nodes. By considering
stronger conditions for node merging, one obtains homomorphisms with stronger
properties, but the number of nodes in G′ and H′ can be smaller. By consider-
ing weaker conditions for node merging, one obtains homomorphisms with weaker
properties, but the number of nodes in G′ and H′ can be greater. Let us give some
examples.
Assume we want to make f injective, so that the joined subgraphs are isomor-
phic. In MAXJOIN, f is initially injective (It is restricted to the ordered pair (c,d)
and c ̸= d). The following condition concerning a pair of relation nodes guarantees
that f remains injective after an execution of the while loop.

220
8 Other Specialization/Generalization Operations
Let G and H be two BGs, and let f be an injective correspondence between some
concept nodes in G and some in H. A pair (r,s) of relation nodes, r in G and s in H,
is strongly compatible with respect to f if (r,s) is strongly compatible and if, for any
neighbor c of r and c′ = corresponding(c,r,s), either (c,c′) is in f or neither c nor c′
appears in f. In MAXJOIN, instead of considering “strongly compatible and disjoint
pairs of relation nodes with respect to (x,y),” let us consider “strongly compatible
with respect to f and disjoint pairs of relation nodes with respect to (x,y)”. The
correspondence f built by the algorithm is now injective and the restrictions of f
and g to nodes in G′ and H′ are bijective. Thus, there are bijective homomorphisms
from G′ to K and from H′ to K that, furthermore, do not restrict the relation node
labels. Note also that the compatibility of concept nodes does not evolve during the
algorithm.
Example. Applying this modiﬁed algorithm to G and H in Fig. 8.6, assuming
that all concept nodes are pairwise compatible, and starting from (1,a) one ob-
tains either K or K′ drawn Fig. 8.7. K is obtained with g = {(2,b),(4,d)} and
f = {(1,a),(5,e),(7,g)}, and K′ with g = {(3,c)} and f = {(1,a),(6,e),(7, f)}.
r
K
4d
7g
5e
2b
1a
3
t
s
3
2
2
2
1
1
1
6
f
s
2
3
c
K’
3c
7f
6e
1a
2
t
s
r
2
2
1
1
1
3
5
g
t
1
2
d
4
2
b
r
1
2
Fig. 8.7 Maximal Joins of isomorphic subgraphs
Instead of reinforcing the condition for merging relation nodes (to obtain bijec-
tive homomorphisms keeping relation node labels), it can be relaxed. For instance,
one can replace the second point in the deﬁnition of a strongly compatible pair of
relation nodes by “ type(r) and type(s) have a lower bound.” In this case (f,g) de-
ﬁnes homomorphisms that are still injective on the relation nodes, but the relation
node labels can be restricted.
Let us end with an example showing how the maximal join can be used to add
plausible information to a BG representing a fact. A schema is a BG associated with
a concept type t gathering typical or plausible information commonly accompanying
the occurrence of an entity of type t (cf. Chap. 13). In Fig. 8.8, H is a schema for the
concept type Drink, with h being its privileged concept node. This schema for Drink
takes meaning in a “baby stories” context, i.e., usually, in a baby stories context, a
drink action has for object milk and for instrument a feeding bottle that contains the
milk. G is a fact containing a concept node c of type Drink. Computing a maximal
join between G and H from an external join between c and h adds plausible relevant
information to G. In the obtained graph, the soft drink has been specialized into
milk, the bottle into a feeding bottle which contains the milk.

8.2 Basic Compatibility Notions and Maximal Joins
221
FeedingBottle
instrument
h
Drink
object
Milk
contain
H
maxjoin(G,H)
G
contain
Man : Leonard
childOf
childOf
Man : Leonard
Drink
agent
object
SoftDrink
instrument
Bottle
Baby : Suzan
Baby : Suzan
instrument
object
agent
Drink
Milk
FeedingBottle
c
Fig. 8.8 Maximal join with a schema
When several schemas are associated with the same concept type, the situation
is more complex. For instance, let us assume that the previous schema H and the
schema H′ shown Fig. 8.9 are both associated with the concept type Drink, with
this second schema being related to a context “detective novels.” Then maximal join
can be used to determine a plausible context of the fact G in Fig. 8.8 as follows. If the
number of matched nodes in max join(G,H) is greater than the number of matched
nodes in max join(G,H′) then “babies stories” is a plausible context of G, otherwise
a plausible context of G is “detective novels.” As the number of matched nodes in
max join(G,H) is 5 whereas the number of matched nodes in max join(G,H′) is 1,
then the fact G more plausibly concerns a babies story than a detective novel.

222
8 Other Specialization/Generalization Operations
Whisky
instrument
h
Drink
object
contain
Glass
H’
Fig. 8.9 Another schema for the concept type Drink
Maximal join operations are particular cases of the extended join that will be
deﬁned at the end of the next section.
8.3 Compatible Partitions and Extended Join
In this section, we ﬁrst study the partition of the node set of a BG induced by a
homomorphism. This notion is then used to deﬁne the extended join of two BGs.
A maximal join of two BGs G and H induces two particular homomorphisms from
G and H to the same graph. Similarly, an extended join of G and H induces homo-
morphisms from G and H to the same graph, but these homomorphisms are more
general. Finally, we consider a particular extended join that merges concept node
only, and is useful, for instance, in rule processing.
8.3.1 Compatible C-Partition and R-Partition
Let us now consider the partitions of the concept and relation node sets of a BG in-
duced by a homomorphism. Let G and H be two BGs and let π be a homomorphism
from G to H. A partition Pπ of the node set of G can be deﬁned as follows: Two
nodes are in the same class of Pπ if they have the same image by π, i.e., two nodes
x and y in G are equivalent modulo Pπ if π(x) = π(y). Pπ is composed of a partition
of the concept node set of G such that any class of this partition is a compatible set
of concept nodes and a partition of the relation node set of G such that any class of
this partition is a compatible set of relation nodes (cf. Sect. 8.2.1).
Conversely, if PC (resp. PR) is a partition of the concept (resp. relation) node set
of a BG G, then we give conditions for the quotient graph G/PC (resp. G/PR) to
be a BG. In this case, there is a (surjective) homomorphism from G to G/PC (resp.
G/PR).
If PR is a partition of the relation node set of a BG G, G/PR is deﬁned like G/PC
(cf. Deﬁnition 2.22). Note that if P is a partition of a subset of the node set of a BG,

8.3 Compatible Partitions and Extended Join
223
one can still consider G/P by supplementing P with classes having a single node
for all nodes that are not in a class of P
Deﬁnition 8.7 (Compatible C-partition). A compatible C-partition of a BG is a
partition P of its concept node set such that any class in P is a compatible concept
node set.
Property 8.6. Let G be a (normal) BG and π be a homomorphism from G to H,
then π induces a compatible C-partition of G. Conversely, let PC be a compatible
C-partition of G, then the graph G/PC obtained by merging each class of PC is a
(normal) BG and there is a surjective homomorphism from G to G/PC.
Proof. The ﬁrst part comes from the deﬁnition of a compatible set of relation nodes.
The second part is obtained by recurrence on the number of classes in PC. Let
PC = {S1,...,Sk}. Then G/S1 satisﬁes property 8.5. One concludes by noting that
G/{S1,...,Sk} = (G/S1)/{S2,...,Sk}.
⊓⊔
Let us now consider the relation nodes.
Deﬁnition 8.8 (Compatible R-partition). A compatible R-partition of a BG is a
partition P = {A1,...,Ak} of its relation node set such that:
• Any class in P is a compatible relation node set,
• the partition PC(PR) which is the lub of all the PC(Ai)′-s is a compatible C-
partition, where PC(Ai)′ denotes the partition of the whole concept node set ob-
tained by completing PC(Ai) by a trivial class for each concept node that does not
belong to a class of PC(Ai).
Example. Consider in the BG of Fig. 8.10, A = {r1,r2}. Then C(A) = {a,b,c,d},
Pr1 = {{1},{2,4},{3,5}}, Pr2 = {{1,2},{3},{4},{5}}, PA = {{1,2,4},{3,5}}
and the covering induces by PA is {{b,c,d},{a,c}}. Thus, PC(A) is equal to
C(A) = {a,b,c,d}. As C(A) is compatible, A is a compatible set of relation nodes.
t
t
t
r
r
r1
r2
t
a
b
c
d
1
3
5
2
1
3
4
5
2
4
Fig. 8.10 {r1,r2} is a compatible set of relation nodes
The following property is obtained with a proof similar to that given for Prop-
erty 8.6:

224
8 Other Specialization/Generalization Operations
Property 8.7. Let G be a (normal) BG and let π be a homomorphism from G to H,
then π induces a compatible R-partition of G. Conversely, let PR be a compatible
R-partition of G, then the graph G/PR obtained by merging each class of PR is a
(normal) BG and there is a surjective homomorphism from G to G/PR.
After considering compatible C-partitions and compatible R-partitions, let us
now consider both the concept and relation node sets.
A compatible partition of a BG is composed of a compatible C-partition and a
compatible R-partition which are not independent.
Deﬁnition 8.9 (Compatible partition of a BG). Let G be a BG, PC a partition of
the concept node set of G and PR a partition of relation node set of G. PC ∪PR is a
compatible partition of G if:
• PR is compatible,
• PC is compatible and PC ⊇PC(PR).
Let P = {PC,PR} be a compatible partition of a (normal) BG G = (C,R,E,l). A
quotient BG G/P is obtained from G and P as follows. First, the (ordinary) quotient
graph G/P is built. Then the node associated with a class of PC is labeled by the glb
of the labels of the class, and the node associated with a class of PR is labeled by a
maximal lower bound of the labels of the class. If there are several such maximal
lower bounds, then several G/P can be deﬁned. They all have the same structure but
the labels of the relation nodes can be different.
Example. Let G be the BG presented Fig. 8.11. It is assumed that PC = {{a,b,c,d, f},
{e}} is a compatible C-partition and that type(r1) = type(r2) and type(r3) =
type(r4). Let us check that PR = {{r1,r2},{r3,r4}} is a compatible R-partition.
Pr1 = {{1}, {2,4},{3,5}}, Pr2 = {{1,2},{3},{4},{5}}, P(r1,r2) = {{1,2,4},
{3,5}}. The covering associated with {r1,r2} is {bcd,ac} thus PC({r1,r2}) =
{abcd}.
Pr3 = {{1},{2}}, Pr4 = {{1},{2}}, P(r3,r4) = {{1},{2}}. The covering associated
with {r3,r4} is {d f,e} thus PC({r3,r4}) = {d f,e}. Finally, PC(R) = PC; therefore
PR is a compatible R-partition and {PC,PR} is a compatible partition of G.
G
3
2
4
2
3
1
2
2
1
1
5
4
1
5
a
b
c
d
e
f
r2
r1
r3
r4
Fig. 8.11 {{r1,r2},{r3,r4}} is a compatible partition of the relation node set

8.3 Compatible Partitions and Extended Join
225
The quotient graph G/P is presented Fig. 8.12.
{e}
{a,b,c,d,f}
{r1,r2}
{r3,r4}
1
2
1,2,3,4,5
Fig. 8.12 The quotient graph G/P associated with G and P in Fig. 8.11
Theorem 8.1. 1. If P is a compatible partition of a BG G then there is a surjective
homomorphism from G to (any) G/P.
2. Let G and H be two BGs. A mapping π from G to H is a BG homomorphism if
and only if the partition of the node set of G induced by the equality of the images
by π is a compatible partition of G.
3. If the only compatible partition of a BG is the trivial partition, i.e., each class is
restricted a single node, then it is irredundant.
Proof. 1. The mapping which associates to any node of G its class in P is a homo-
morphism from G to G/P.
2. If there is a homomorphism from G to H, then the partition of the node set of
G induced by the equality of the images by π is a compatible partition of G. In-
deed, PC and PR are compatible partitions by deﬁnition of a homomorphism, and
PC is greater than PC(PR) by deﬁnition of the underlying graph homomorphism.
Furthermore, there is a bijective homomorphism from G/P to π(G), and for any
class {c1,...,ck} of PC let y be the concept node in H such that for i = 1,..., p,
π(ci) = y then glb({l(ci) | i = 1,..., p} ≥l(y). The same applies for any class of
PR.
3. If the only compatible partition of a BG G is the trivial partition, i.e., each class
is restricted a single node, then G is irredudant. Indeed, if there is a non-injective
homomorphism from G to itself, then there is a non-trivial compatible partition.
⊓⊔
Note that even if a graph is irredundant, it can have non-trivial compatible parti-
tions, as shown in Fig. 8.13 where G is irredundant; nevertheless there is a surjective
homomorphism from G to H, and G has a non-trivial compatible partition.

226
8 Other Specialization/Generalization Operations
t
t
t
r
r
2
1
2
1
G
H
Fig. 8.13 An irredundant graph with a non-trivial compatible partition
8.3.2 Extended Join
We have considered so far two join operations, which build a common specializa-
tion of two BGs by merging parts of them. The external join can be considered
as a merging of two trivial subgraphs (they are restricted to a single node). In the
maximal join algorithm described in Sect. 8.2.2, two connected subgraphs, obtained
by maximally extending an external join, can be merged. In this section, we con-
sider the extended join operation, which generalizes the previous joins, by allowing
subgraphs of any form to be merged.
Deﬁnition 8.10 (Fusionnable BGs). Let G1 and G2 be two BGs. They are fu-
sionnable if there are partitions P1 and P2 respectively compatible on G1 and G2,
such that there is an isomorphism f from G1/P1 to G2/P2, and f fulﬁlls: For any
node x in G1/P1, {x, f(x)} is compatible.
The fusion of two fusionnable BGs G1 and G2 consists of merging any x in
G1/P1 with f(x). Let H be the BG obtained by such a fusion. H can be obtained
from G1/P1 by replacing the label of any node x by glb(l(x),l(f(x))). G1/P1 and
G2/P2 are more general or equal to H, and we have:
Property 8.8. If G1 and G2 are fusionnable then there is a BG H and two surjective
homomorphisms from G1 to H and from G2 to H.
Deﬁnition 8.11 (Extended join). An extended join operation between two BGs
consists of fusionning two of their fusionnable subBGs.
The Fig. 8.14 illustrates the extended join between two BGs L and M. f1 and
f2 are the canonical surjective homomorphisms from G1 to G1/P1 and from G2 to
G2/P2, g1 and g2 are bijective homomorphisms. g1 ◦f1 and g2◦f2 are the surjective
homomorphisms of Prop. 8.8.
8.3.3 Join According to a Compatible Pair of C-Partitions
The join deﬁned in this section can be seen as a generalization of the external join,
and as a particular extended join. With respect to the external join, instead of only

8.3 Compatible Partitions and Extended Join
227
H
G1/P1
G1
G2
M
L
G2/P2
f1
f2
g1
g2
f
Fig. 8.14 Extended join between the BGs L and M
joining a concept c1 in G1 and a concept c2 in G2, several compatible sets of concept
nodes in G1 and in G2 are joined. With respect to the extended join, only concept
nodes are joined.
Deﬁnition 8.12 (Compatible Pair of C-partitions). Let P1 = (p11,..., p1k) and
P2 = (p21,..., p2k) be two ordered partitions with the same cardinality over two
subsets of the concept node sets of two BGs G1 and G2. {P1,P2} is a compatible
pair of C-partitions if for all i, i = 1,...,k, the set p1i ∪p2i is compatible.
Note that if {P1,P2} is a compatible pair of C-partitions, then P1 and P2 are com-
patible C-partitions of subsets of the concept node sets of G1 and G2.
The join of two graphs with respect to a compatible pair of C-partitions is de-
scribed in two steps. The ﬁrst step consists of merging in G1 (resp. G2) the classes
of P1 (resp. P2) using the labels of classes of P2 (resp. P1). More precisely,
Deﬁnition 8.13 (Specialization of a BG with respect to a compatible pair of C-
partitions). Let P1 = (p11,..., p1k) and P2 = (p21,..., p2k) be a compatible pair of
C-partitions of G1 and G2. The specialization of G1 with respect to P1 and P2 is the
graph G1(P1,P2) built from G1 as follows:
• the label of any concept node in a class p1 j of P1 is specialized into glb(p1 j ∪p2 j),
• each class of P1 is merged.

228
8 Other Specialization/Generalization Operations
The join of two graphs with respect to a compatible pair of C-partitions can now
be deﬁned.
Deﬁnition 8.14 (Join of two BGs with respect to a compatible pair of C-parti-
tions). Let P1 and P2 be a compatible pair of C-partitions of G1 and G2. The join
of G1 and G2 with respect to P1 and P2 is the graph obtained from G1 and G2 as
follows. First, build G1(P1,P2) and G2(P2,P1). Then, for all i join c1i and c2i, which
are respectively the node of G1(P1,P2) obtained by merging the i-th class of P1 and
the node of G2(P2,P1) obtained by merging the i-th class of P2.
Said otherwise, the join of G1 and G2 with respect to P1 and P2 is obtained from
G1 +G2 by merging the nodes of each set p1i ∪p2i, 1 ≤i ≤k.
If the C-partitions are empty, the join is simply a disjoint sum of G′
1 and G′
2. If
each C-partition is restricted to a single class with a single node, the join is simply an
external join. Classes of P1 and P2 may contain concept nodes of several connected
components. In such cases, the join can stick several connected components.
The join of two graphs with respect to a compatible pair of C-partitions will be
used for processing rules in backward chaining (see Chap. 10).
8.4 G-Specializations
Let G be a set of BGs. The main goal of this section is to give a computational
characterization of the set of G-specializations. A G-specialization is simply a BG
which can be obtained from G by using a ﬁnite number of elementary specialization
operations (cf. Sect. 3.4). Such a set G is sometimes called a “canonical base” of
BGs and, in this case, a G-specialization is called a “canonical BG.” BGs built on
a given vocabulary can be be considered as canonical BGs generated by star BGs.
Thus an inductive deﬁnition of BGs is stated. In order to achieve Theorem 8.3,
which is the main result of this section, we study surjective homomorphisms and
deﬁne the union of a set of (non-necessarily disjoint) BGs.
8.4.1 Surjective Homomorphism
In this section, the unary specialization operations and their relationships with ho-
momorphism are only considered. We also state an inductive deﬁnition of a BG that
differs from the deﬁnition given in Chap. 2.
Deﬁnition 8.15 (Gα). Let α = {s,r, j} be the set of the unary strict specialization
operations (s for relation simplify, r for restrict, and j for join) and let G be a BG.
Gα is the set of BGs inductively deﬁned by:
• (basis) G ∈Gα,
• (rules) If o ∈α and H ∈Gα then o(H) ∈Gα.

8.4 G-Specializations
229
One has:
Property 8.9. Let G and H be two BGs. There is a surjective homomorphism from
G to H if and only if H is isomorphic to an element of Gα.
Proof. Let H be isomorphic to an element of Gα. If H = o(G) with o ∈α, then
there is a surjective homomorphism π from G to H deﬁned as follows.
1. If o = s and r’ a twin node of r is deleted then π(r′) = r and for all node x ̸= r′
π(x) = x,
2. if o = r then π is the identity,
3. if o = j and c and c′ are identiﬁed then π(c′) = c and for all node x ̸= c′ π(x) = x.
The composition of surjective homomorphisms is a surjective homomorphism,
so one obtains the sufﬁcient condition. Reciprocally, let π be a surjective homo-
morphism from G to H. The following sequence of unary specialization operations
transforms G into H:
1. Let G1 be the BG obtained from G by restricting the label of any concept x to the
label of its image π(x) in H,
2. let G2 be the BG obtained from G1 by successively joining all concepts having
the same image in H,
3. let G3 be the BG obtained from G2 by successively simplifying all relations in
G2 having the same image in H, G3 is isomorphic to H.
⊓⊔
Property 8.10. Let G and H be BGs, then G ⪰H if and only if there is a subBG of
H which is isomorphic to an element of Gα.
Proof. If G ⪰H, let us consider a homomorphism π from G to H. Then there is a
surjective homomorphism from G to π(G), which is a subBG of H. One concludes
with the preceding property for the necessary part. Conversely, let us suppose that
K is a subBG of H, with K being isomorphic to L ∈Gα. Therefore, G ⪰L, K
isomorphic to L, and K ⪰H, yield G ⪰H.
⊓⊔
In graph theory, a homomorphism is called complete if it is faithful and surjective.
As a BG homomorphism is faithful, one can replace surjective homomorphism by
complete homomorphism.
8.4.2 Union
The union of two (not necessarily disjoint) BGs is a partial operation deﬁned as
follows.
Deﬁnition 8.16 (Union of two BGs). Let G=(CG,RG,EG,lG) and H=(CH,RH,EH,
lH) be two BGs such that any node common to G and H has the same label in G and
H. The union of G and H is the BG (CG ∪CH,RG ∪RH,EG ∪EH,lG∪H) where lG∪H
is deﬁned by:

230
8 Other Specialization/Generalization Operations
• if x is a node in G which is not in H, then lG∪H(x) = lG(x),
• if x is a node in H which is not in G, then lG∪H(x) = lH(x),
• if x is a node in G and H, then lG∪H(x) = lH(x) = lG(x).
Property 8.11. Let G = (C,R,E,l) and G′ = (C′,R′,E′,l′) be two BGs such that for
any node or edge x in (C,R,E)∩(C′,R′,E′) l(x) = l′(x) . (C∪C′,R∪R′,E ∪E′,l ∪
l′) is a BG if and only if graph(G)∩graph(G′) provided with the labeling function
l (or l′) is a BG.
Proof. If (C ∪C′,R ∪R′,E ∪E′,l ∪l′) is a BG and r is a relation in graph(G) ∩
graph(G′) all its neighbors must be within G and G′. Otherwise there are two edges
(r,i,c) and (r,i,c′) with c ̸= c′; thus r has two i-ith neighbors in the union of G and
H. Therefore, the intersection of G and G′ is a BG. Reciprocally, let us suppose that
graph(G) ∩graph(G′) is not a BG, even if for any node or edge x in graph(G) ∩
graph(G′) l(x) = l′(x) . Then there is a relation r in graph(G) ∩graph(G′) that
does not have all its neighbors in graph(G)∩graph(G′), and the union of G and G′
is not a BG because r does not fulﬁll the condition of BG.
⊓⊔
Whenever the union operation is deﬁned on a set of BGs it is a specialization
operation. More precisely,
Property 8.12. If a BG G is equal to the union of a set of BGs {G1,...,Gk}, then G
is a specialization of the extended disjoint sum G′
1 +...+G′
k, such that for all i ̸= j
G′
i and G′
j are disjoint and Gi and G′
i are isomorphic for every i = 1,...,k.
Proof. By recurrence on k. The property is true if k = 1. Let us consider a BG
G which is the union of k + 1 BGs G1,...,Gk+1 and let H denote the union of
G1,...,Gk. H is a BG and it is a specialization of G′
1 + ... + G′
k. Let us consider
the union of H and Gk+1. The intersection K of H and Gk+1 is a BG K (cf. Prop-
erty 8.11). Let us consider the disjoint sum H + G′
k+1. By joining the concepts in
H and in G′
k+1 corresponding to a concept in K, and by deleting twin relations, one
obtains the union of H and Gk+1 which is equal to G.
⊓⊔
Property 8.13. Let T be a specialization tree of G with k leaves labeled by H1,...,
Hk. For all i = 1,...,k there is a homomorphism πi from Hi to G such that G =
∪1,...,kπi(Hi).
Proof. For each i = 1,...,k Hi is a generalization of G, therefore there is a homo-
morphism πi from Hi to G, and πi(Hi) is a subBG of G. Let us prove by recurrence
on the number n of nodes of T that the union of these sub-BGs is equal to G. The
property holds if n = 1. If G has only one predecessor H in T then G = op(H),
where op is one of the unary specialization operations. By the recurrence hypothe-
sis, H is equal to ∪1,...,kπ′
i (Hi). One concludes by considering πi = π ◦π′
i where π
is the surjective homomorphism associated with op as deﬁned in property 8.9. If G
is the disjoint sum of two BGs H and K, the set {H1,...,Hk} can be partitioned into
{K1,...,Kl} and {M1,...,Mm}, and by the recurrence hypothesis, H = ∪1,...,lαi(Ki)
and K = ∪1,...,mβi(Mi). Then G is equal to the union of these two unions, which is
precisely ∪1,...,kπi(Hi).
⊓⊔

8.4 G-Specializations
231
8.4.3 Inductive Deﬁnition of BGs
In this paragraph, BGs that can be obtained with specialization operations from a
set of BGs are studied.
Deﬁnition 8.17 ( G-specialization). Let G be a set of BGs. A BG G is called a G-
specialization if it is obtained by a specialization tree whose leaves are all labeled by
BGs in G. Stated otherwise, the set of G-specializations is the set of BGs inductively
deﬁned with:
• (basis) the set G,
• (rules) the elementary specialization operations.
In Sect. 2.1.2 a star BG is deﬁned as a BG restricted to a relation node and its
neighbors (cf. Deﬁnition 2.3). Elementary star BGs are speciﬁc star BGs deﬁned as
follows:
Deﬁnition 8.18 (Elementary Star BG). The elementary star BG associated with
a relation type r of arity k is a BG restricted to a relation node labeled by r and k
neighbors, each labeled by (⊤,∗).
The BGs on V can now be inductively deﬁned as follows.
Theorem 8.2. Let GV denote the set of elementary star BGs associated with a vo-
cabulary V plus a BG, denoted [⊤], reduced to a single concept node labeled by
(⊤,∗). The set of GV-specializations is equal to the set of (non-empty) BGs on the
vocabulary V.
Proof. Any GV-specialization is a BG on V. Let us prove, by recurrence on the
number of relation nodes, that if G is a BG on V then it is a GV-specialization. If G
has no relation node and k concept nodes xi labeled by ai, then G can be obtained
from the BG [⊤] with k −1 disjoint sums, then restricting the labels of k nodes
to a1,...,ak. If a BG G has k ≥1 relation nodes, then let us consider one relation
node r. If H is obtained from G by deleting r, then H can be obtained by a GV-
specialization (recurrence hypothesis). Let us consider the subBG K of G induced
by r. This BG can be obtained from the star BG associated to the type of r by a
sequence of concept restrictions and joins. Finally, one makes the disjoint sum of
H and K, and if (r,i,c) is in G, the node c in H is joined to the i-th neighbor of the
relation in K.
⊓⊔
Note that if the relation types are equipped with signatures (cf. Sect. 2.1.1), then
the elementary star BG associated with the relation type r is the star BG having its
relation node labeled r and its i-th neighbor, for i = 1,...,arity(r), labeled by σ(r),
i.e., the maximal concept type of the i-th neighbor of a relation node labeled r.

232
8 Other Specialization/Generalization Operations
8.4.4 G-Specializations
G-specializations can occur in design problems, particularly in the synthesis or ana-
lysis of complex objects. Let us consider a box with k legs which may represent an
abstraction of a simple physical object, e.g., a piece of a jigsaw, an electronic circuit,
a mechanical device, an atom (see Fig. 8.15). The box type indicates the type of
device, and leg types represent the connections of a box.
Let us assume that boxes can be glued together by means of legs for building
complex objects. In Fig. 8.15, two boxes are represented as well as their gluing by
identical colors.
Red
Red
Black
Pink
Blue
Green
White
Yellow
Black
Black
Black
Red
Red
Blue
Pink
Green
White
Yellow
Fig. 8.15 Boxes with legs
A BG representation of boxes with legs in Fig. 8.15 is given Fig. 8.16. In this
representation, colors are considered as individuals thus gluing by identical colors
corresponds to normalization.

8.4 G-Specializations
233
Color : Y
att
Color : W
Color : G
Color : Ba
Color : R
att
att
att
att
Leg
Leg
Leg
Leg
Leg
5−Leg
1
2
3
4
5
4
3
2
1
4−Leg
att
Leg
Leg
Leg
Leg
att
att
att
Color : B
Color : P
Color : R
Color : Ba
Fig. 8.16 The boxes with legs example represented as BGs
If the rules gathering boxes are elementary specialization rules (or can be deﬁned
by composition from specialization rules), then the complex objects obtainable from
the boxes correspond to the set of BGs over the vocabulary consisting of the box
and leg types (or a part of that BG set). Indeed, such a box with its legs can be
represented by a star BG. If the elementary pieces from which more complex objects
have to be built are not necessarily boxes but any set G of BGs, then the complex
objects are G-specializations.
A BG that is a G-specialization is sometimes called a canonical BG with respect
to the set G, which is called a canon.
The following property can be used to build an algorithm for recognizing a G-
specialization, which is polynomial in the complexity of a BG homomorphism al-
gorithm.
Theorem 8.3. Let G be a set of BGs. A G-cover of a BG G is a set {G1,...,Gp} of
elements of G such that: G = ∪i=1,...,pGi. If a BG G has no isolated concepts, then
the three following properties are equivalent:
1. G is a G-specialization
2. there is a Gα-cover of G
3. for all relations r of G there is a homomorphism π from a Bi ∈G to G with
r ∈π(Bi)

234
8 Other Specialization/Generalization Operations
Proof.
• 1 ⇒2
Let us consider a G-specialization G. There is a specialization tree T of G with
all its leaves labeled with elements of G. Thus, with property 8.9, π(Bi) is an
element of Bα
i , and one concludes with Property 8.13 in which the union is a
Gα-cover.
• 2 ⇒3
Let us consider a BG G having a Gα-cover {G1,...,Gk}. Any relation r of G
belongs to some Gi, a subBG of G which is an element of Gα. One concludes
with Property 8.9.
• 3 ⇒1
Let Br1,...,Brk denote the elements of G associated with relations r1,...,rk of
G, and πi a homomorphism such that r ∈πi(Bri). Each Bri is specialized into
πi(Bri). Then one makes the union of these BGs, which is equal to G (as there
are no isolated concepts in G, a cover of the relations is a cover of the whole BG).
One concludes with property 8.12.
⊓⊔
The third characterization of a G-specialization in Theorem 8.3 leads to the fol-
lowing CANONICAL algorithm for G-specialization recognition.
Let us assume that there is a function HOM(Bi,G,r), where Bi ∈G, G is a BG
and r is a relation node in G, which returns ∅if there is no homomorphism from Bi
to G that maps a relation node in Bi to r, otherwise it returns such a homomorphism
π (and one says that “π covers r”).
Algorithm 24: CANONICAL (G is a BG, G is a canonical base)
Input: a BG G not reduced to a single concept node
Output: returns True if G is a G-specialization, otherwise False
begin
R is the relation node set of G
Rel ←R
// relation nodes not yet covered
while Rel ̸= ∅do
covered ←False
Let r ∈Rel
forall Bi ∈G do
π ←HOM(Bi,G,r)
if π ̸= ∅then
Rel ←Rel \{relation nodes appearing in π}
covered ←True
Exit(For loop)
if ¬covered then
return False
return True
end

8.5 Type Expansion and Contraction
235
Initially, Rel contains all relation nodes in G. The algorithm iteratively tries to
cover a relation node r that has not already been covered (by a graph Bi). Whenever
a homomorphism covering r is found, then other relation nodes can be covered by
the same homomorphism and all these nodes are removed from Rel. If r cannot
be covered, the algorithm returns False. If Rel becomes empty, all relation nodes
have been covered and the algorithm returns True.
The time complexity of CANONICAL can be roughly bounded by |R| × |G| ×
hom, where hom is the maximum complexity of computing a homomorphism from
a BG to another BG that covers a speciﬁc relation node. For known algorithms,
when computing a homomorphism from a BG to another BG the covering condition
does not increase the complexity. Since the problem of a homomorphism between
two graphs is NP-Complete (cf. Sect. 5.2), CANONICAL is exponential here. Nev-
ertheless, one important point is that the complexity of CANONICAL is polyno-
mially related to the complexity of hom. Thus, each time hom is polynomial, so is
CANONICAL.
8.5 Type Expansion and Contraction
The concept and relation types considered so far are primitive types. They are not
explicitly deﬁned, and their meaning is only given by their position in the type hier-
archies and their possible occurrences in relation signatures, rules and other sorts of
knowledge.
If a type t is less than a type t′, this means that every entity of type t is also of
type t′, but nothing is explicitly said about the properties of entities of type t, nor
about what distinguishes a t from any t′. Two kinds of type deﬁnitions have been
proposed for conceptual graphs: By necessary and sufﬁcient conditions, or with a
set of prototypes representing typical instances of the type. With the ﬁrst approach,
an entity is of type t if and only if it fulﬁlls the necessary and sufﬁcient conditions.
With the second approach, an entity is of type t if it is sufﬁciently similar to one
of this prototype (We ﬁnd here one application of the maximal join operations: The
similarity can be related to the ratio of nodes in both graphs that are matched by
a maximal join). The logical translation of the ﬁrst kind of deﬁnition is simply a
logical equivalence, while this is not the case for the second kind of deﬁnition.
In this section, we consider type deﬁnitions by necessary and sufﬁcient condi-
tions. Note that we shall not conduct an in-depth study of type deﬁnitions. Studying
how to classify a deﬁned type, i.e., how to ﬁnd its position in the concept type hi-
erarchy, or extending the specialization/generalization relation between graphs and
studying its relationships with FOL semantics, studying recursive type deﬁnitions
and so on, are beyond the scope of this section. Brieﬂy, in this section we do not
extend the conceptual graph model presented in this book with type deﬁnitions, we
only consider expansion and contraction operations of a deﬁned type.
Furthermore, we describe these operations for concept type deﬁnitions only. Sim-
ilar operations can be provided for relation type deﬁnitions (see the bibliographical

236
8 Other Specialization/Generalization Operations
notes). Finally, let us point out that we consider a classical BG vocabulary, thus
without conjunctive types.
Deﬁnition 8.19 (Concept type deﬁnition). Let V be a BG vocabulary and t be a
symbol which does not belong to V. A concept type deﬁnition of t is a unary λ-BG
(c)Dt, where Dt is connected and c is called the head of Dt. Such a type deﬁnition
is noted t = (c)Dt.
Example. Assume, for instance, that the vocabulary contains the concept type
Woman and the relation type childOf. One wants to deﬁne a new concept type
Mother, by the λ-graph (c)G in Fig. 8.17. This deﬁnition says that an entity m is of
type Mother if and only if m is of type Woman and has a child.
Intuitively, a concept type deﬁnition is a necessary and sufﬁcient condition for
an entity to belong to this deﬁned type. A deﬁnition t = (c)Dt can be considered
as an Aristotelician type deﬁnition by genus and difference. The genus of t is the
type of c; its difference is what completes c in Dt. Logically, the deﬁnition t =
(c)Dt is naturally translated by the formula ∀x(t(x) ↔Φ((c)Dt)), with the term
assigned to c in Φ((c)Dt) being x. For instance, the deﬁnition of the concept type
Mother (Fig. 8.17) is translated into ∀x(Mother(x) ↔∃y(Woman(x)∧Person(y)∧
childOf(y,x))).
Even if one does not describe the modiﬁcation of the ordered type set due to the
addition of a deﬁned type, let us assume that, in the enriched vocabulary, the deﬁned
type t is ≤the type of c (and in general t might be less than other types which are
specializations of, or incomparable with, the type of c).
c
Woman
Person
childOf
Fig. 8.17 Deﬁnition graph of the concept type Mother
In the same way, a relation type deﬁnition is deﬁned as follows.
Deﬁnition 8.20 (Relation type deﬁnition). Let V be a BG vocabulary, r be a sym-
bol that does not belong to V and k an integer ≥1. A k-ary relation type deﬁnition
of r is a k-ary λ-BG (c1,...,ck)Dr.
For instance, if the vocabulary contains the relation types parentOf and sibling,
then the binary relation type cousin can be deﬁned by the λ-graph (c1,c2)G in
Fig. 8.18. A deﬁnition of a relation type of arity k is a necessary and sufﬁcient
condition for k entities to be linked by this deﬁned relation type, e.g., the enti-
ties represented by c1 and c2 are cousins if and only if they have parents who are
siblings. It is translated into logics in the same way as a concept type deﬁnition:
The formula assigned to the deﬁnition r = (c1,...,ck)Dr is ∀x1...xk(r(x1...xk) ↔
Φ(((c1,...,ck)Dr))), where the variables assigned to c1,...,ck are x1,...,xk respec-
tively. For instance, the deﬁnition of the concept type cousin (Fig. 8.18) is translated
into ∀x1∀x2(cousin(x1,x2) ↔∃y∃z(Person(x1)∧Person(x2)∧Person(y)∧Person(z)
∧parentOf(y,x1)∧parentOf(z,x2)∧sibling(y,z))).

8.5 Type Expansion and Contraction
237
Note that cousin and sibling are both symmetrical relations, which can be ex-
pressed by BG rules (cf. Chap. 10).
parentOf
parentOf
sibling
Person
Person
Person
Person
c2
c1
Fig. 8.18 Deﬁnition graph of the relation type cousin
The expansion of a concept type deﬁnition consists of replacing a concept node
with a deﬁned type by the graph deﬁning the type. More precisely:
Deﬁnition 8.21 (Concept type expansion). Let G be a graph containing a concept
node x with a deﬁned type t = (c)Dt. The expansion of t at x is the BG exp(G,x,Dt)
obtained by merging x and c, the label of the new node being (t′,m) where t′ is the
type of c and m is the marker of x.
An example is given in Fig. 8.19.
age
Number:30
Mother:Mary
x
: Paul
Person
worksWith
Number:30
age
Woman
Person
childOf
c
: Paul
Person
worksWith
Person
childOf
Woman:Mary
Fig. 8.19 A concept type expansion
Let us point out the relationships with rules. From a logical viewpoint, a concept
type deﬁnition t = (c)Dt can be considered as equivalent to two speciﬁc BG rules

238
8 Other Specialization/Generalization Operations
(and more precisely, λ-rules, cf. Chap. 10), say R1 and R2. The hypothesis of the
ﬁrst rule is a single generic concept node labeled t, its conclusion is Dt, and the node
in the hypothesis is in correspondence with the head of Dt; the second rule is the
reciprocal rule. See for instance Fig. 8.20, which shows both rules corresponding to
the deﬁnition of the concept type Mother.
At ﬁrst glance, a type expansion looks like an application of the rule R1. However,
there are two differences. First, R1 can be applied to concept nodes with a type less
than t, whereas an expansion can occur only if the concept node has exactly the type
t. Secondly, a rule application cannot generalize the type of an existing node.
Mother
Woman
childOf
Person
R2
R1
THEN
IF
THEN
IF
Woman
Person
childOf
Mother
Fig. 8.20 Rules associated with the deﬁnition of the concept type Mother
A concept type expansion may add redundant information. This added redundant
information can be avoided by a more complex type expansion operation relying on
the piece notion that is deﬁned hereafter. This notion will be generalized in Chap. 10,
where pieces are used in backward chaining of rules.
Deﬁnition 8.22 (Piece). Let G be a BG and let x be a concept node in G. Two nodes
u and v in G belong to the same piece of x if they are in the connected component of
G containing x and if there is a chain between them that does not go through x, i.e.,
there is a chain w0(= u),...,wi,...,wk(= v) such that wi ̸= x for all i = 1,...,k−1.
Note that x belongs to all pieces of x and that x has more than one piece if and only if
x is a cut node of G (i.e., the deletion of x strictly increases the number of connected
components).

8.5 Type Expansion and Contraction
239
The pieces of x can be built as follows. Let H be the connected component of
G containing x, the connected components H1,...,Hk of the graph H −x obtained
from H by deleting x are computed. Then, for i = 1,...,k the piece Ci of x is the BG
obtained from Hi by adding x and all edges in H joining x to a node in Hi. If k = 1
the single piece is H itself.
The BG exp(G,x,Dt) resulting from a concept type expansion can be reduced,
i.e., replaced by an equivalent BG having fewer nodes, by using pieces.
Deﬁnition 8.23 (Extended concept type expansion). The extended concept type
expansion of a deﬁned type t = (c)Dt at x in G is the BG extexp(G,x,Dt) obtained
from exp(G,x,Dt), where x still denote the node resulting of the merging of x and
c, as follows. Let C1,...,Ck be the pieces of x in G and let D1,...,Dl be the pieces
of c in Dt. For all i = 1,...,k and j = 1,...,l, if Dj maps to Ci with c mapped to x,
then Dj is deleted from exp(G,x,Dt).
In Fig. 8.21, G is a BG and Dt is the deﬁnition of the type t of x in G, all concept
nodes are assumed to be generic, and the type t′′ of z in G is less than the type t′ of
c (i.e., the head of Dt) and t. Dt and G are restricted to a single piece with respect to
c and x respectively. G does not map to Dt and Dt does not map to G with c being
mapped to x. Thus, extexp(G,x,Dt) is equal to exp(G,x,Dt). One can also check
that G and Dt are irredundant. Nevertheless, extexp(G,x,Dt) is redundant. Indeed,
by folding z onto xc, extexp(G,x,Dt) is transformed into K, which is equivalent to
the subBG H of G.
Note that the reduction used in the extended concept type expansion can also be
done after any external join. Figure 8.21 can be used to show (consider that Dt is a
BG and not necessarily a type deﬁnition, i.e., x and c have the same labels) that after
such a reduction the obtained BG can be redundant even though the two joined BGs
are irredundant.
Let us now consider the type contraction operation, which can be more or less
considered as inverse to the expansion. In order to deﬁne this contraction opera-
tion, we use the fact that x is a cut node of exp(G,x,Dt), i.e., if x is deleted from
exp(G,x,Dt), two disjoint (not necessarily connected) graphs are obtained, which
correspond to Dt −c and G−x.
Let us assume that a graph G contains a subBG D isomorphic to a concept type
deﬁnition graph Dt. If D is shrunk into a single node, then all neighbors of the nodes
in D that are outside D are linked to the new node resulting from the shrinking of D.
This can add irrelevant information, as shown in Fig. 8.22.
In contracting a subgraph corresponding to a type deﬁnition, one does not want to
add irrelevant information, but one also does not want to lose relevant information.
For instance, if one knows that Paul is a child of the woman Mary, i.e., if G in
Fig. 8.23 is a fact and if we simply contract the deﬁnition of Mother, one obtains
graph H and the fact that Paul is a child of Mary is lost.
To avoid information loss in type contraction, the parts that strictly specialize the
corresponding parts in the type deﬁnition are kept. More precisely,
Deﬁnition 8.24 (Concept type contraction). Let G be a BG and Dt be a concept
type deﬁnition, with head c. Let π be a homomorphism from Dt to G, such that c

240
8 Other Specialization/Generalization Operations
r
r
r
a
a
a
a
r
a
r
K
xcz
y
t’’
Dt
c
t’
t’
z
y
xc
extexp(G,x,Dt)
y
z
x
t
t’’
G
Fig. 8.21 Extended concept type expansion and redundancy
x
Woman
Person
childOf
brotherOf
Person: Eve
brotherOf
Person: Eve
Mother
D
Fig. 8.22 A problematic contraction of a concept type
Mother:Mary
Boy:Paul
Woman:Mary
childOf
x
G
K
Fig. 8.23 A concept type contraction with information loss

8.5 Type Expansion and Contraction
241
and π(c) have the same type. Let x = π(c). The BG contract(G,x,Dt) is obtained
from G by replacing the type of x with t and, for each piece P of x in G that maps to
a piece of c in Dt (without considering the label of x), deleting P−x.
An example is given Fig. 8.24, where a 4-Wheel is a concept type less than the
concept type BigCar.
age
Number:33
LargeCity
4−Wheel
age
Number:33
Bobo : Jack
possess
4−Wheel
LargeCity
BigCar
age
Number:33
liveIn
possess
LargeCity
H= contract(G,x,Dt)
c
Person
BigCar
Definition of the concept type Bobo
Person : Jack
liveIn
possess
liveIn
possess
4−Wheel
possess
Person : Jack
G
exp(contract(G,x,Dt),x,Dt)
Fig. 8.24 Concept type contraction
Note that contract(exp(G,x,Dt),x,Dt) = G. Indeed, the type of x in exp(G,x,Dt)
is t and it is unchanged by the contraction. Furthermore, the homomorphism is a BG
isomorphism, thus no subBG is added by the contraction. When ﬁrst computing a
contraction then an expansion, i.e., exp(contract(G,x,Dt),x,Dt), the graph obtained
is not necessarily equal to G (an example is given in Fig. 8.24 when the type Bobo
is expanded in H). Nevertheless, exp(contract(G,x,Dt),x,Dt) is hom-equivalent to
G since the deleted pieces in G are redundant (they map to pieces in Dt) as well as
the pieces of Dt which are not in G.

242
8 Other Specialization/Generalization Operations
Finally, let us point out that the concept type expansion and contraction opera-
tions, as deﬁned in this chapter, do not change the BG semantics. More precisely,
let G be a BG and G′ be obtained from G by a type expansion or contraction. Let
f be the formula translating the type deﬁnition involved in this operation. Then
Φ(V), f |= (Φ(G) ↔Φ(G′)).
Like the concept type deﬁnition, a relation type deﬁnition can be considered as
equivalent to two reciprocal BG rules and similar relation type expansions and con-
tractions can be deﬁned.
8.6 Bibliographic Notes
In [Sow84] a maximal join operation is proposed that was implemented in the sys-
tem presented in [SW86]. The deﬁnition of a maximal join between two graphs G
and H in [Sow84] relies on the notion of a common generalization of G and H, say
K, and “compatible” homomorphisms from K to G and H respectively, say π1 and
π2. The join is performed according to these homomorphisms by pairwise merging
each node π1(x) and π2(x) for each node x of K. However, the deﬁnition of com-
patibility (Deﬁnition 3.5.6 in [Sow84] ) and the associated result (Theorem 3.5.7
in [Sow84] ) work only if the homomorphisms are injective on the concept node set
of K. Then, there is a bijection between the concept nodes of the joined subgraphs of
G and H. Maximal joins have been used especially in natural language processing
(e.g., cf. [FLDC86]).
Compatible partitions were introduced in [CM92]. Canonical conceptual graphs
were introduced in [Sow84], and the characterization Theorem 8.3 as well as the
recognition algorithm of canonical graphs were given in [MC93].
Type deﬁnitions as well as type expansion and contraction operations were in-
troduced by Sowa [Sow84]. Two kinds of type expansion are deﬁned: the minimal
type expansion, which is the same as ours, and the maximal type expansion, which
essentially extends the minimal type expansion with a maximal join. This second
operation aims at avoiding the creation of redundant parts; but contrary to our ex-
tended type expansion it does not preserve the semantics and might strictly special-
ize the graph. We kept the overall idea of the type contraction operation proposed
by Sowa and precisely deﬁne it with graph operations.
Although type deﬁnitions were introduced as early as 1984, their processing re-
ceived little attention. Let us mention the work of Lecl`ere (cf. [Lec95], [Lec97] and
[Lec98]) extending the framework of BGs to concept and relation type deﬁnitions.
In this framework, recursive type deﬁnitions (direct or indirect) are forbidden and a
primitive type cannot be specialized by a deﬁned type. The specialization relation
between BGs is extended by the type expansion and contraction operations, and it
is shown that soundness and completeness properties are kept, i.e., given two BGs
G and H deﬁned on a vocabulary V, G ⪰norm(H) if and only if Φ(V),Φ(H) ⊨
Φ(G), where Φ(V) is the set of formulas associated with the enriched vocabulary,
which now includes formulas translating type deﬁnitions. A unique expanded form

8.6 Bibliographic Notes
243
obtained by performing type expansion until stability is associated with each BG.
The expanded form is a BG where all types are primitive (i.e., not deﬁned). Thus
two expanded BGs can be compared by homomorphism. Let us add that to the best
of our knowledge type deﬁnitions have never been studied in conceptual graphs
beyond the BG model.

Chapter 9
Nested Conceptual Graphs
Overview
The nested conceptual graph model presented in this chapter is a direct extension
of basic or simple conceptual graphs able to represent notions such as internal and
external information, zooming, partial description of an entity, or speciﬁc contexts.
This model also allows reasoning while taking a tree hierarchical structuring of
knowledge into account. Nestings are represented by boxes. A box is an SG and,
more generally, a box is a typed SG. In full conceptual graphs, a box represents the
negation of the graph inside the box. Thus, for differentiating these negation boxes
from the boxes used in this chapter, these boxes are usually called “positive” boxes.
Nevertheless, since the only kind of boxes considered hereafter are positive boxes,
we omit the term “positive.”
In Sect. 9.1 different notions representable by nested conceptual graphs are pre-
sented. In Sect. 9.2, we introduce Nested Basic Conceptual Graphs (NBGs), whose
boxes consist of BGs. Nested Conceptual Graphs (NGs), which extend NBGs with
coreference links, are presented in Sect. 9.3. Coreference links can relate concept
nodes of the same box (thus boxes become SGs) but also of different boxes. Coref-
erence links in nested graphs are more difﬁcult to manage than in simple graphs.
Indeed, since boxes can represent contexts, it is generally irrelevant to merge all
nodes of a coreference class into a single node. In Sect. 9.4, we deﬁne graph types,
typed SGs, which are SGs with a graph type, and Nested Typed Conceptual Graphs
(NTGs), which generalize NBGs by typing the boxes. All of these nested graphs
classes are provided with homomorphism. The FOL semantics Φ introduced for
SGs is generalized to NTGs in Sect. 9.5 and a homomorphism soundness and com-
pleteness theorem is stated. As this semantics is a formula of the positive, con-
junctive and existential fragment of FOL, nested and non-nested CGs are some-
what equivalent. Finally, we build a mapping ng2bg from nested to non-nested CGs
which preserves homomorphisms. This mapping ng2bg shows, in another way than
through logical semantics, that nested and non-nested CGs have the same descrip-
tive power. It is easy to implement ng2bg and this avoids the construction of speciﬁc
nested graph homomorphism algorithms.
247

248
9 Nested Conceptual Graphs
Nevertheless, from a user viewpoint, NTGs are interesting whenever knowledge
is intrinsically hierarchical, and when reasonings must follow the hierarchical struc-
ture, because in an NTG the hierarchy is explicitly and graphically represented.
Nested graphs can also be interesting whenever large graphs have to be manually
constructed, as the separation of levels of reasoning increases efﬁciency and clarity
when extracting information.
9.1 Introduction
Let us give a ﬂavor of different knowledge representation situations which are rele-
vant to the conceptual graph model presented in this chapter. Consider, for instance,
representing information about a cottage. It is possible to distinguish internal from
external pieces of information about this cottage. The owner’s name can be consid-
ered as an external piece of information concerning the cottage, whereas the dis-
tribution of rooms, the plan of the cottage, is internal information. In information
retrieval, the ISBN number of a book can be considered as an external piece of in-
formation about that book, whereas the subject of the book is an internal piece of
information. In these examples, the internal information can also be called descrip-
tion (of the cottage or book), and more precisely partial description of the given
entity.
Zooming is a related notion. Let us again consider the cottage example. Having
the land registry position of the cottage, one may want to zoom into the cottage, e.g.,
to determine the cottage plan, which can be considered as internal information about
the cottage. Or, at a deeper level, having the cottage plan, one may want to know the
furniture distribution in a speciﬁc room. In the book example, zooming can consist
of obtaining the content of a chapter from a reference to this chapter (e.g., from the
number of this chapter).
The knowledge model presented in this chapter can also be related to the context
notion. An informational context can be deﬁned as the (cultural, historical, social,
geographical, etc.) surroundings or circumstances of a piece of information that are
important to understand the meaning of this piece of information. For instance, in
the previous cottage example, the context of the furniture distribution (in a room) is
precisely the room having this furniture distribution, the context of the content of a
book chapter is precisely this chapter, and so on.
The notion of context is close to the two previous notions of external versus inter-
nal pieces of information, and to zooming. Indeed, zooming takes its full meaning
when one knows the origin of the zooming, and an internal piece of information
takes its full meaning when this origin, which can also be an internal piece of in-
formation, is known. In the forthcoming model, only very simple contexts can be
represented. Indeed, a context will be represented by a path of (nested) concept
nodes. Thus, considering partial description or zooming as an intuitive meaning of
what we aim to represent, seems as relevant as the context.

9.2 Nested Basic Graphs (NBGs)
249
A partial description can be included in another partial description, thus a recur-
sive model is proposed, and the entities are represented by a hierarchical structure.
Similarly to the classical notion of “boxes within boxes” used in document pro-
cessing, we deﬁne a model that consists of “graphs within graphs.” Brieﬂy said,
our model consists of rooted trees of (typed) SGs, and reasoning is based on SG
homomorphisms respecting the tree structure.
9.2 Nested Basic Graphs (NBGs)
Let us consider the graph G in Fig. 9.1, expressing that “a drawing has been made
by the boy Paul.” Suppose one wants to add two pieces of information to G. First,
Drawing
1
madeBy
Boy : Paul
2
Fig. 9.1 A basic conceptual graph
“the drawing is on a table,” and secondly “the drawing represents a green-coloured
train.” These pieces of information can be considered to be of different sorts. The
ﬁrst one can be considered as external information about the drawing, i.e., it is a
fact concerning the drawing taken as a whole, i.e., a black box, with what is drawn
being irrelevant. On the other hand, the fact that a green train is represented on this
drawing can be considered as internal information, or a (partial) description, of the
drawing itself. If one wants to build a representation of these facts while keeping
this difference of status, then one can add “the drawing is on a table” at the same
level as G, and the fact that the drawing represents a green train can be put inside
the node representing the drawing. This latter piece of information can be obtained
by zooming on the drawing node, which is then considered as a glass box. After
adding the fact that the drawing in Fig. 9.1 is on a table, and by zooming on the
node “Drawing,” the nested graph NG represented Fig. 9.2 is obtained. It can also
be said that the piece of information nested in a node is relevant within the context
represented by this node. Thus, the context is represented by a concept node, or
more precisely by a path of concept nodes.
madeBy
Boy : Paul
2
1
Table
on
Color : Green
2
1
attr
Train
2
1
Drawing
Fig. 9.2 A nested conceptual graph

250
9 Nested Conceptual Graphs
Drawings of nested graphs can be quite difﬁcult to read. A dynamic device, e.g.,
a graphical screen, allows nice vizualization of nested graphs by travelling level by
level within the graph, i.e., by zooming in and out. For instance, for representing the
nested graph in Fig. 9.2, a ﬁrst image can show the graph without the description of
the drawing, a graphical mark indicating that the node corresponding to the drawing
has a non-empty description (as in Fig. 9.3). By zooming on a node with a non-
Table
on
1
Drawing
madeBy
Boy : Paul
2
1
2
Fig. 9.3 A nested conceptual graph before zooming
empty description, the description graph appears, and the rest of the graph is shaded
off (as in Fig. 9.4).
Color : Green
2
1
attr
Train
on
1
Drawing
madeBy
2
2
1
Fig. 9.4 A nested conceptual graph after zooming
We hereafter propose two equivalent deﬁnitions of nested graphs corresponding
to different viewpoints of the same model. The ﬁrst deﬁnition is a recursive deﬁni-
tion obtained by adding a third ﬁeld, called a description, to the concept node labels
of a basic conceptual graph (BG), and in the second deﬁnition the recursive facet
is explicitely represented by a tree. The ﬁrst deﬁnition is well ﬁtted for a graphical
user interface since it corresponds to the zoom viewpoint. The second deﬁnition fa-
cilitates the drawing of nested graphs on a sheet of paper because a nested graph is
basically a tree of SGs.
Deﬁnition 9.1 (Nested Basic Graph NBG).
• An elementary NBG G is obtained from a normal BG H by adding a third ﬁeld to
the label of each concept node c equal to ∗∗. The set of boxes of G is boxes(G) =
{H} and the complete concept node set of G is XG =CH. A trivial bijection exists
between elementary NBGs and normal BGs (when no ambiguity occurs we do
not distinguish between them).
• Let H be an NBG and D an elementary NBG. The graph G obtained from H
by substituting D for the third ﬁeld ∗∗of a concept node c in XH is an NBG.
boxes(G) = boxes(H)∪boxes(D), and XG = XH ∪XD.

9.2 Nested Basic Graphs (NBGs)
251
• The third ﬁeld of any concept node c ∈XG is called the description of c and is
denoted Descr(c).
A BG appearing in the construction of an NBG G, i.e., an element of boxes(G),
is called a box of G.
An NBG is denoted G = (CG,RG,EG,lG), where CG,RG,EG are respectively the
concept, relation and edge sets of the ﬁrst elementary NBG, denoted root(G), used
in the construction of G. lG is the labeling function obtained from the labeling func-
tion of root(G) by adding a third ﬁeld with value Descr(c) to the labeling of each
concept node ∈CG.
We distinguish the set CG of concept nodes of an NBG G—i.e., the set of nodes
of root(G)—from the set XG of all concept nodes appearing in G, i.e., the set of
concept nodes of all boxes of G.
We explain in Sect. 9.3 why we consider normal BGs in the previous deﬁni-
tion. Recall that we consider normal BGs and normal SGs as identical objects (cf.
Sect. 3.5).
It is important to note (for the forthcoming deﬁnitions of Tree(G) and XG) that if
a BG or an NBG K is used several times in the construction of a NBG G, we consider
that several copies of K (and not several times the graph K itself) are used in the
construction of G. Note also that a description is not a type deﬁnition (cf. Chap. 8).
First, a description applies to a speciﬁc concept node, whereas a graph deﬁning a
type applies to all concept nodes of this type. Secondly, a type deﬁnition provides
a characterization of a type, i.e., it describes necessary and sufﬁcient conditions for
any object to belong to the type, whereas a description is only a partial information
about an object.
Any NBG G has an associated tree Tree(G) whose nodes are in bijection with
the boxes of G. Before deﬁning Tree(G), let us introduce the notion of a tree of
BGs.
Deﬁnition 9.2 (Tree of BGs). A tree of BGs is a labeled rooted tree T=(VT,UT,lT),
such that:
• VT, the node set of T, is in bijection with a set of pairwise disjoint normal BGs
{G1,...,Gk}. For any i = 1,...,k, the node associated with Gi is labeled Gi (the
set {G1,...,Gk} can be identiﬁed with VT).
• For any arc (Gi,Gj) in UT, lT(Gi,Gj) is a concept node c in Gi, and such a
labeled arc is also denoted (Gi,c,Gj).
• All labels are distinct, i.e. a concept node c appears at most once as an arc label.
The mapping Tree that assigns a tree of BGs to any NBG is deﬁned as follows.
Deﬁnition 9.3 (Tree(G)). Let G be an NBG, the mapping Tree is deﬁned as follows.
If G is an elementary NBG, then Tree(G) is restricted to a single node labeled G.
If G is the NBG obtained from a NBG H by substituting D to ∗∗, which is the Descr
of the concept node c in H, then Tree(G) is built from Tree(H) by adding a node
labeled D successor of the node labeled K, and containing c, in Tree(H). The label
of (K,D) is c.

252
9 Nested Conceptual Graphs
The root of Tree(G) is root(G). Note that for any NBG G, (J,K) is an arc in
Tree(G) labeled c if and only if J and K are nodes in Tree(G) (i.e. are boxes of
G), c is a concept node in J, and K is the label of the root of the tree associated
with Descr(c), i.e., the description graph of c. Otherwise said, the existence of an
arc (J,c,K) in Tree(G) expresses the fact that: “J and K are two boxes of G, c is a
concept node in J, and K is the label of the root of Tree(Descr(c)).”
Example. The boxes and tree of the NBG in Fig. 9.2 are represented in Fig. 9.5.
Color : Green
K
madeBy
2
1
2
1
2
1
J
K
attr
J
On
c
Drawing
Train
Table
Boy: Paul
c
Fig. 9.5 The “tree of boxes” view of the graph in Fig. 9.2
Figure 9.6 presents a more complex example of an NBG. Its boxes are repre-
sented in Fig. 9.7, where G1 is the root, G2 = Descr(d), G3 = Descr(c), G4 =
Descr(e), G5 = Descr(f), G6 = Descr(i), G7 = Descr(h), G8 = Descr(l), G9 =
Descr(n), and its tree is represented in Fig. 9.8.
n
m
o
j
k
l
i
h
c
b
a
g
f
e
d
Fig. 9.6 An NBG
The following property is immediate:
Property 9.1. The mapping Tree is a bijection from NBGs over a vocabulary V to
the trees of BGs over the same vocabulary V.

9.2 Nested Basic Graphs (NBGs)
253
G5
G9
G8
G7
G6
G3
G2
G1
G4
n
o
m
l
k
j
b
a
c
d
h
i
f
g
e
Fig. 9.7 The boxes of the graph in Fig. 9.6
G1
G2
G3
G4
G5
G6
G7
G8
G9
d
e
l
f
n
c
i
h
Fig. 9.8 The tree of the graph in Fig. 9.6

254
9 Nested Conceptual Graphs
Thus, Deﬁnition 9.1 and Deﬁnition 9.2 can be indiscriminately used.
Deﬁnition 9.4 (Depth).
• The depth of an NBG G is the depth of Tree(G), i.e., the maximum number of
arcs of a path beginning at the root.
• The depth of a node x in a NBG G is the depth of the vertex of Tree(G) to which
it belongs, i.e., if x is in root(G) then depth(x) = 0, and if x is in K and (J,c,K)
is an arc of Tree(G), then depth(x) = depth(J)+1.
For instance, in Fig. 9.6 the depth of the nodes m and k is 2, whereas the depth
of f and h is 1, and the depth of d and a is 0 (see also Fig. 9.7, where the depth of
a node in a box is the number of arcs of a path from the root to the box containing
that node).
A complex concept node is a node c in XG with a non-empty Descr(c), i.e., dif-
ferent from ∗∗. Such a node c is also called a context, and more precisely it is called
the context of Descr(c).concept!complex
A homomorphism from an NBG G to an NBG H is deﬁned using the tree deﬁni-
tion of NBGs. It is composed of an ordinary tree homomorphism π0 from the rooted
tree Tree(G) to the rooted tree Tree(H), and by a set of (BG) homomorphisms πi
from any box Gi of G to the box π0(Gi) of H.
Deﬁnition 9.5 (NBG homomorphism). Let G and H be NBGs and Tree(G) =
(VG,UG,lG) and Tree(H) = (VH,UH,lH) be their associated rooted trees. An NBG
homomorphism from G to H is a pair π = (π0,(πG1,...,πGl)), where VG = {G1,...,
Gl}, which satisﬁes:
• π0 is a (tree) homomorphism from Tree(G) to Tree(H), i.e., a mapping from
VG to VH, such that, if (J,K) is in UG, then (π0(J),π0(K)) is in UH, and
π0(root(G)) = root(H),
• ∀K ∈VG,πK is a (BG) homomorphism from (the BG) K to (the BG) π0(K),
• if lG(J,K) = c, then lH(π0(J),π0(K)) = πJ(c).
An example is given Fig. 9.9, where each arrow represents a homomorphism
from the BG origin of the arrow to the BG extremity of the arrow.
A homomorphism π from an NBG G to an NBG H naturally induces a mapping
(also noted π for simplicity) from the set of all nodes appearing in G to the set of all
nodes appearing in H. Let x be a node in a box K of G, π(x) = πK(x).
One can extend the homomorphism deﬁnition by removing the condition that
the root of the source tree has for image the root of the target tree. This extended
deﬁnition is a bit more general since the root of the ﬁrst tree can be mapped to
any node of the target tree. In this case, only the relative depth is respected, more
precisely, if the root of Tree(G) is mapped to a box of depth k in Tree(H) then, for
any concept c of G, depth(π(c)) = depth(c)+k. Let us give an example.
Example. In Fig. 9.10, G1 and G2 are two facts and Q1, Q2 and Q3 are three queries.
Q1 represents the question “Is there a train in the context of a thing?” Q2 represents
the question “Is there a train?” and Q3 represents the question “Is there a train and

9.2 Nested Basic Graphs (NBGs)
255
1
2
2
2
2
3
3
3
3
1
1
1
A2
A
B
C
D
E
F
L
M
N
P
Q
R
T
A1
Fig. 9.9 An example of an NBG homomorphism
a boy?” With the deﬁnition 9.5, G1 answers NO to Q1, YES to Q2 and YES to Q3,
and G2 answers YES to Q1, NO to Q2 and NO to Q3. With the extended deﬁnition,
G1 answers NO to Q1, YES to Q2 and YES to Q3, and G2 answers YES to Q1, YES
to Q2 and NO to Q3. Both deﬁnitions disagree on the answer given by G2 to Q2:
with the ﬁrst deﬁnition, the answer is NO because there is no train at the ﬁrst level,
and with the extended deﬁnition it is YES, and it could be added “in the context of
a drawing.”
Boy: Paul
Train
playWith
1
2
Train
Thing
Train
Train
Boy
realizedBy
Boy: Paul
Color: Green
Drawing
Train
attr
1
2
1
2
Q3
Q2
Q1
G1
G2
Fig. 9.10 Facts and queries
As NBG homomorphisms preserve the (relative) depth of the nodes, they allow
only simple forms of reasoning. Other kinds of reasoning would be useful, espe-
cially reasonings mixing knowledge from different levels. Such reasonings can be

256
9 Nested Conceptual Graphs
deﬁned by ﬁrst deﬁning transformations of graphs, then by using NG homomor-
phisms. The decision homomorphism problem for NBGs, NBG-HOMOMORPHISM,
is NP-complete (with a BG being a particular case of NBG), and an algorithm for
the NBG-HOMOMORPHISM polynomial in the complexity of an algorithm for BG-
HOMOMORPHISM can be simply constructed since computing a homomorphism
from a tree to a tree (or more generally to any graph) is a polynomial problem
(cf. Sect. 7.2.1).
9.3 Nested Graphs (NGs)
In order to express that different nodes appearing in an NBG represent the same
entity, one can add coreferences to NBGs, as we did for for BGs (cf. Deﬁnition 3.10
in Chap. 3).
The following piece of information about a scientiﬁc document that is “an ar-
ticle, whose subject is a wheat food product that is cooked in water, has a result,
whose nutritional observation is that the vitamin content of this wheat food product
decreases, whose biochemical explanation is that this wheat food product contains
hydrosoluble vitamin that is dissolved, and whose nutritional evaluation is that the
nutritional quality of this wheat product is deteriorated” can be represented by the
graph in Fig. 9.11. In this ﬁgure, the coreferent concept nodes are represented by
the named variable ∗x.
shows
has
Nutritional evaluation
Deterioration
Wheat food product : *x
Nutritional quality
undergoes
contains
Biochemaical explanation
Dissolution
Wheat food product : *x
Hydrosoluble vitamin
Decrease
shows 
has
Nutritional observation
Wheat food product : *x
Vitamin content
provides
deals with
Article
Wheat food product : *x
Water cooking
undergoes
Result
Subject
Description
Fig. 9.11 A nested graph with coreferences represented by variables
An abstract example of a nested graph is represented in Fig. 9.12, where the
nodes j,m, p,w are coreferent along with the nodes q,r. In this example, the coref-
erence relation is represented by coreference links.

9.3 Nested Graphs (NGs)
257
l
k
j
o
m
n
i
g
h
f
e
d
c
b
a
w
p
q
r
Fig. 9.12 An abstract nested graph with coreference links
Two coreferent concept nodes represent the same entity in nested graphs as in
SGs. In SGs we have seen how it is possible to shrink each coreference class into a
single node, thus obtaining a graph in normal form. The situation is more compli-
cated for nested graphs. Knowledge is contextualized (by a hierarchical structure)
in a nested graph, and merging two coreferent concept nodes can be done only if the
contextualization is preserved. Two cases can be considered.
First, let us consider two coreferent concept nodes, say a and b, which are in the
same box. These nodes may have descriptions. But, as a and b both represent the
same entity (they are coreferent) in the same context (they are in the same box), one
can merge a and b into a single node without altering the meaning of the graph. The
description of the new node is the disjoint sum of the description of a and of the
description of b.
Secondly, let us consider two coreferent concept nodes, say c and d, which are not
in the same box, thus they are a priori not in the same context. The information
about an entity in a context may be irrelevant in another context and merging two
coreferent concept nodes which are in distinct contexts could entail inconsistencies.
For instance, in Fig. 9.13, the concept nodes c and d are coreferent. They repre-
sent the same boy Paul but in two different contexts. Merging the two descriptions
would state that Paul is dressed up as Zorro while this is stated only on the draw-
ing. Nevertheless, if two coreferent nodes c and d are in the description of a and b,
respectively, and a and b are coreferent nodes belonging to the same box, then after
merging a and b, c and d become coreferent in the same box. In this case, they can
be safely merged.
The simplest way of differentiating coreference links within a box and corefer-
ence links between two boxes is to stress that there is no coreference link within a
box, i.e., each box is a normal SG. Hence the following deﬁnition:
Deﬁnition 9.6 (Nested Conceptual Graph (NG)).
A nested conceptual graph
(NG) (G,coref) is an NBG G enriched by an equivalence relation coref on XG

258
9 Nested Conceptual Graphs
Character: Zorro
Boy: Paul
Drawing
Child
dressUp
1
2
1
2
c
d
madeBy
Fig. 9.13 An example of coreferent concept nodes which should not be merged
(the set of all concept nodes in all boxes of G) such that, for each box K in G, coref
restricted to K is the trivial equivalence, i.e., if (c,c′) ∈coref and c ̸= c′ then c and
c′ are in two different boxes.
Note that any box of an NG is a normal BG. If the box normality condition is
not satisﬁed, i.e., if one considers a pair (G,coref) where G is a NBG and coref an
equivalence relation which does not satisfy the condition in Deﬁnition 9.6, then G
can be transformed into an intuitively semantically equivalent NG when the follow-
ing normalization process is successful. One performs from the root of G a top-down
(e.g., by a depth-ﬁrst search or a breadth-ﬁrst search) normalization of each box as
follows. The normalization of a box consists of merging all coreferent nodes (in
the box) into a single node, whose description is the disjoint sum of merged node
descriptions. A sufﬁcient condition for the normalization process is that each coref
class satisﬁes the condition of a coref class of an SG (cf. Deﬁnition 3.10), but this is
not a necessary condition.
Deﬁnition 9.7 (NG homomorphism). A (NG) homomorphism from an NG G to an
NG H is deﬁned as a homomorphism of the underlying NBGs on condition that two
coreferent nodes of G must have coreferent images in H.
9.4 Nested Typed Graphs
Whenever the universe of discourse can be naturally broken down into independent
parts, some knowledge may possibly concern only some of these parts. In such a
case, pieces of knowledge can be organized so as to respect the universe of dis-
course structure. In the same way, when something can be described using different
viewpoints, each piece of information corresponding to a given viewpoint can be
typed by this viewpoint. Let us give an example about text annotations. Concern-
ing the content of a text, one can make a distinction between the text topic and the
way this topic is presented, i.e., the text rhetoric. One can also consider the structure

9.4 Nested Typed Graphs
259
of the text, the word distribution, or even bibliographical data such as the author’s
name, the publisher or the number of pages. For each of these aspects, a graph can
be constructed, with each graph being labeled by the type of annotation, e.g., topic,
rhetoric, structure, bibliographic data, and so on. Thus, one introduces graph types
and typed graphs, and also sets of typed graphs.
Graph types are especially useful in nested graphs when one wants to consider
different sorts of nesting. A nested typed graph can be considered as an NG in
which a complex concept node can have several typed descriptions. In Chap. 13
nested typed graphs are used for representing document annotations. Let us again
consider the previous text annotation example. An annotation of the text identiﬁed
by T121 and represented by a concept node c labeled (Text, T121) can be composed
of an annotation concerning the text topic and another annotation concerning the text
rhetoric. Then, the (global) annotation of the text is a description of c composed of
a graph A of type topic and a graph B of type rhetoric, i.e., the label of c is the triple
(Text, T121, { (Topic, A), (Rhetoric, B)}).
We deﬁne typed SGs (TGs) before considering nested typed graphs. A TG vo-
cabulary V is an SG vocabulary supplemented by an ordered set of graph types TG,
i.e., V = (TC,TR,TG,I).
Figure 9.14 presents a tree of graph types.
Structure
Comment
Content
Rhetoric
Topic
Annotation
GraphType
Fig. 9.14 A set of graph types
Deﬁnition 9.8 (TG and TG homomorphism). A typed BG (resp.SG) on a TG
vocabulary (TC,TR,TG,I) is an ordered pair (g,G), where g ∈TG and G is a BG
(resp. SG) on (TC,TR,I). A homomorphism π from G to H is a (TG) homomorphism
from (g,G) to (h,H) if h ≤g.
Brieﬂy said, a nested typed graph is a nested graph in which the boxes are no
longer normal BGs but are typed normal BGs. A BG can be considered as a partic-
ular typed BG (there is only one graph type) and, in the same way, an NG can be
considered as a particular nested typed graph deﬁned as follows.
Deﬁnition 9.9 ( Nested Typed Graph (NTG)).

260
9 Nested Conceptual Graphs
• An elementary NTG G is obtained from a typed normal BG (g,H) by adding a
third ﬁeld to the label of each concept node c in H equal to ∗∗. The set of boxes of
G is boxes(G) = {(g,H)} and the complete concept node set of G is XG = CH. A
trivial bijection exists between elementary NTGs and typed normal BGs (when
no ambiguity occurs we do not distinguish between them).
• Let H be an NTG and {(g1,H1),...,(gk,Hk)} a set of elementary NTGs, such
that for any i ̸= j ∈{1,...,k}, gi ̸= gj. The graph G obtained from H by
substituting {(g1,H1),...,(gk,Hk)} for the third ﬁeld ∗∗of a concept node c
in H is an NTG. boxes(G) = boxes(H) ∪{(g1,H1),...,(gk,Hk)}), and XG =
XH ∪XH1 ∪...∪XHk.
• The third ﬁeld of any concept node c ∈XG is called the description of c and is
denoted Descr(c).
• The set XG of all concept nodes appearing in G is provided with an equivalence
relation coref, such that for any box K the restriction of coref to K is the trivial
equivalence (i.e., if (c,c′) ∈coref and c ̸= c′ then c and c′ are in two different
boxes).
The notions deﬁned for nested graphs (NGs) can be extended to nested typed
graphs (NTGs) as follows. First, one can deﬁne a tree of typed SGs by substitut-
ing TGs for BGs in the deﬁnition of a BG tree (cf. Deﬁnition 9.2). Secondly, the
transformation Tree for nested graphs (cf. Deﬁnition 9.3) can be extended to nested
typed graphs. Thirdly, the homomorphism deﬁnition between NGs can be extended
to NTGs.
Deﬁnition 9.10 (Tree of typed BGs). A tree of TGs is a labeled rooted tree T =
(VT,UT,lT), such that:
• VT, the node set of T, is in bijection with a set of pairwise disjoint typed normal
BGs {G1,...,Gk}. For any i = 1,...,k, the node associated with Gi is labeled by
Gi (the set {G1,...,Gk} can be identiﬁed with VT).
• For any arc (Gi,Gj) in UT, lT(Gi,Gj) is a concept node in Gi; such a labeled arc
is also denoted (Gi,c,Gj).
• For all pairs of arcs (Gi,Gj) and (Gi,Gk) with same label c, the graphs Gj and
Gk have a different type.
It is sometimes convenient to label an arc (Gi,c,Gj) not only by c but also by a
pair (c,type(Gj). In this case, the condition 3 of the previous deﬁnition becomes:
All labels are distinct, i.e., if (c,g) and (d,h) are the labels of two distinct arcs, then
c ̸= d or g ̸= h or both.
There are two differences between NTGs and NGs. In NTGs, the boxes are typed,
and a concept node has a description composed of a set of graphs, instead of a single
graph in NGs.
It is now possible to deﬁne a tree of typed BGs associated with an NTG.
Deﬁnition 9.11 (Tree(G)). The mapping Tree assigns to any NTG G a tree of typed
SGs, denoted Tree(G), which is deﬁned as follows.
If G is an elementary NTG, then Tree(G) is restricted to a single node labeled G.

9.4 Nested Typed Graphs
261
If G is the NTG obtained from an NTG H by substituting {G1,...,Gk} for ∗∗,
which is the Descr of the concept node c in H, then Tree(G) is built from Tree(H)
by adding k nodes labeled Gi, i = 1,...,k as successors of the node labeled K in
Tree(H) containing c. Each arc (K,Gi), for i = 1,...,k, is labeled by c.
It can immediately be checked that, as in NBGs, the mapping Tree is a bijection
from the NTGs on a vocabulary V to the trees of typed BGs on V. NTG homomor-
phisms are deﬁned using the tree viewpoint.
Deﬁnition 9.12 (NTG Homomorphism). Let G and H be two NTGs with Tree(G)
= (VG,UG,lG) and Tree(H) = (VH,UH,lH). A (NTG) homomorphism from G to H
is a pair π = (π0,{πG1,...,πGk}), where VG = {G1,...,Gk}, which satisﬁes:
• π0 is an ordinary tree homomorphism from (VG,UG) to (VH,UH) which maps the
root of Tree(G) to the root of Tree(H),
• ∀K ∈VG, πK is a TG homomorphism from K to π0(K),
• ∀(J,K) ∈UG, if lG(J,K) = c then lH(π0(J),π0(K)) = πJ(c)),
• two coreferent nodes of G must have coreferent images in H.
Example. The NTG in Fig. 9.15 is obtained from the NG in Fig. 9.11 by replac-
ing the concept types Description, Nutritional observation, Nutritional evaluation
and Biochemical explanation by graph types. Moreover the root is typed (here by
Annotation).
Result
Subject
Article
deals with
provides
undergoes
Water cooking
Wheat food product : *x
Description
contains
Hydrosoluble vitamin
undergoes
Dissolution
Biochemical explanation
Wheat food product : *x
Decrease
shows 
has
Wheat food product : *x
Vitamin content
Nutritional observation
shows
has
Deterioration
Nutritional evaluation
Wheat food product : *x
Nutritional quality
Annotation
Fig. 9.15 An NTG
Example. In Fig. 9.16, it is assumed that: G is of type g, H of type h, g ≥h, and
the graph types g1 and g2 are greater than or equal to g3. The mapping π such that:

262
9 Nested Conceptual Graphs
π(c1) = d1, π(c2) = d2, π(c3) = π(c4) = d3, π(r1) = s1, π(r2) = s2, π(r3) = s3, is
a homomorphism from (g,G) to (h,H).
r
c2
r1
v
s3
s2
s1
d3
d1
(h,H)
d2
r3
r2
c4
c3
(g,G)
c1
(g1,G1)
(g2,G2)
u
(g3,G3)
t
(g4,G4)
t : a : 
t : a :
t
u
t
t
r
t
t
v
u
v
Fig. 9.16 An NTG homomorphism
9.5 The Semantics ΦN
The FOL semantics ΦN hereafter deﬁned for NGs and NTGs is an extension of
the FOL semantics Φ for SGs (cf. Sect. 4.2.1). The deﬁnition of ΦN for NGs, i.e.,
untyped nested graphs, is based on two ideas. First, ΦN(G) is the conjunction of a
formula deﬁning the tree structure of G with formulas associated with all boxes of
G. Secondly, the formula associated with a box K is obtained from Φ(K) by adding
an argument which is a variable representing K. The FOL semantics ΦN for NTGs

9.5 The Semantics ΦN
263
is built from the FOL semantics for NGs by adding for each box K of type g an
atom g(y) (y being the variable representing K). Thus, we consider only NTGs in
this section. If graph types are useless, i.e., if NGs are considered instead of NTGs,
the soundness and completeness theorem still holds with ΦN for NGs.
After deﬁning ΦN, we prove that the NTG homomorphism notion is sound and
complete with respect to ΦN.
9.5.1 Deﬁnition of ΦN
Let L be the FOL language associated with the vocabulary (TC,TR,I) (cf. Sect. 4.2.1).
The FOL language LN associated with the vocabulary V = (TC,TR,TG, I) on which
NTGs are built is obtained from L by the following transformations:
• a new constant a0 is added to the constants assigned to the individual markers,
• each predicate p of arity n ≥1 in L is transformed into a predicate, still denoted
p, of arity n+1,
• a new ternary predicate descr is added to L,
• for any g ∈TG a new unary predicate, also denoted g, is added to L (useless for
NGs).
Thus, a binary predicate is associated with each concept type in TC, and an (n+
1)-ary predicate is associated with each n-ary relation type. Note that the predicate
descr, which is used for representing the tree structure of any NTG, belongs to any
FOL language LN associated with a vocabulary.
The following set of formulas, denoted ΦN(V), is associated with V = (TC,TR,
TG, I):
∀z∀x1 ... xn(t1(x1, ..., xn,z) →t2(x1, ..., xn,z)), for any t1 and t2 concept type in TC
(in this case n = 1) or relation type of arity n ≥1 in TR such that t1 ≤t2,
∀x(g1(x) →g2(x)), for all g1,g2 in TG such that g1 ≤g2 (useless for NGs).
Let G be an NTG or an NG, and let Tree(G) be its associated tree. A set of
constants a1,...,am is assigned to the coreference classes containing an individ-
ual concept node (the same letter is used to designate an individual marker and its
associated constant), and a0 is assigned to the root box of G. Two disjoint sets of
variables are considered. First, a set of variables x1,...,xn are assigned to the generic
coreference classes, and a set y1,...,yk are assigned to the k boxes of G distinct from
the root box. Hereafter, we often refer to a box by its associated term, and to a coref-
erence class by its associated term. In an NTG, a concept node c is identiﬁed by a
pair (u,y), where u is the term (either a variable xi or a constant ai, i ≥1) associated
with the coreference class of c, and y is the term (either a variable yi or a0) assigned
to the box containing c.
Example. For instance, in Fig. 9.17, the NG in Fig. 9.5 is represented with its asso-
ciated variables. x1 (resp. x2, x3) is the variable assigned to the generic concept node
of type Drawing (resp. Table, Train), a0 is the constant assigned to the root box and

264
9 Nested Conceptual Graphs
y1 is the variable assigned to the box description of the drawing. The fact that Paul
is an individual concept node of type Boy in the root box a0, is represented by the
atom Boy(Paul,a0). The fact that the concept node x3 has a Green attribute in the
box y1 is represented by the atom attr(x3,Green,y1). The fact that in a0 the concept
node x1 has y1 for description is represented by the atom descr(a0,x1,y1). Finally,
the fact that the type of J (resp. K) is Proposition (resp. Subject) is represented by
Proposition(a0) (resp. Subject(y1)).
Color : Green
K
a0
y1
Subject
Proposition
madeBy
2
attr
on
x3
x2
x1
1
2
1
2
1
J
Drawing
Train
Table
Boy: Paul
Fig. 9.17 Variables associated with concept nodes and boxes in an NTG
We require the following notation before giving the deﬁnition of ΦN. Let us re-
call that, given an SG G, φ(G) is the conjunction of all atoms assigned to nodes of
G without quantiﬁcation, while Φ(G) is the existential closure of φ(G) (cf. Deﬁni-
tion 4.7).
Deﬁnition 9.13 (φ(G,u)). Let G be an SG and let u be a term. φ(G,u) is the formula
obtained from φ(G) by adding the argument u to each atom in φ(G).
This transformation can be extended to any FOL formula. For instance, Φ(G,u)
denotes the formula obtained from Φ(G) by adding the argument u to each atom in
Φ(G).
Deﬁnition 9.14 (ΦN(G)). Let G be an NTG with typed boxes (g0,G0),...,(gk,Gk),
(g0,G0) being the root box. Let yi, i = 1,...,k be the variables assigned to the Gi-
s and xi, i = 1,...,n be the variables assigned to the generic coreference classes.
ΦN(G) =
∃y1 ...ykx1 ...xn(φ(Tree(G))∧g0(a0)∧φ(G0,a0)∧...∧gk(yk)∧φ(Gk,yk)), where:
φ(Tree(G)) is the conjunction, for any (J,c,K) arc in Tree(G), of the atoms
descr(vj,ui,yk), where vj is the term assigned to the box J, yk is the variable as-
signed to the box K and ui is the term assigned to the coreference class of c.
Example. The formula associated with the NTG G in Fig. 9.17 is:
ΦN(G) = ∃y1x1x2x3(descr(a0,x1,y1)∧proposition(a0)∧subject(y1)∧
Boy(Paul,a0)∧Drawing(x1,a0)∧Table(x2,a0)∧madeBy(x1,Paul,a0)∧
on(x1,x2,a0)∧Train(x3,y1)∧Color(Green,y1)∧attr(x3,Green,y1))
The formula associated with the NTG H in Fig. 9.18 is:
ΦN(H) = ∃y1x1x2(descr(a0,x1,y1)∧proposition(a0)∧subject(y1)∧Boy(x2,a0)∧

9.5 The Semantics ΦN
265
Drawing(x1,a0)∧madeBy(x1,x2,a0)∧Child(x2,y1)∧Character(Zorro,y1)∧
dressU p(x2,Zorro,y1))
Character: Zorro
Subject
Proposition
y1
y1
a0
a0
Boy
Drawing
1
2
o
o
c
x1
x1
J
K
Child
dressUp
1
2
x2
madeBy
Fig. 9.18 A NTG with coreferent nodes
9.5.2 Soundness and Completeness
Let us show that the homomorphism notion between NGs is sound and complete
with respect to the FOL semantics ΦN. More precisely,
Theorem 9.1. Let G and H be two N(T)Gs. There is a homomorphism from G to H
if and only if ΦN(V),ΦN(H) |= ΦN(G).
Note that there is no normality condition for completeness (contrary to the theorem
for SGs) since we only consider normal boxes in the deﬁnition of nested graphs.
Proof. The proof is based on relationships between NTG homomorphism and L-
substitution and on the L-substitution lemma. Ignoring the graph types, one obtains
a proof for NGs.
Soundness
Let G and H be two NTGs, Tree(G) = (VG,UG,lG), VG = {G1,...,Gk}, and
Tree(H) = (VH,UH,lH), VH = {H1,...,Hl}. Let π = (π0,(πG1,...,πGk)) be a ho-
momorphism from G to H. Then (cf. Deﬁnition 9.12),
1. π0 is a homomorphism from Tree(G) to Tree(H) which maps the root of Tree(G)
to the root of Tree(H),
2. ∀K ∈VG,πK is a homomorphism from K to π0(K),
3. ∀(J,K) ∈UG with lG(J,K) = (c,g), one has lH(π0(J),π0(K)) = (πK(c),h),
where h is the type of π0(K),

266
9 Nested Conceptual Graphs
4. if c and c′ are two coreferent concept nodes in G, then π(c) and π(c′) are coref-
erent in H.
Let us prove that there is a LN-substitution from ΦN(G) to ΦN(H).
ΦN(G) = ∃y1 ...ykx1 ...xm(φ(Tree(G))∧g0(a0)∧φ(G0,a0)∧...∧gk(yk)∧
φ(Gk,yk)), where:
φ(Tree(G)) = {descr(y′
j,ui,yp) | (y′
j,ui,yp) ∈Tree(G)}, where y′
j is either a0 or
a variable yj.
ΦN(H) = ∃z1 ...zlw1 ...wn(φN(Tree(H))∧h0(a0)∧φ(H0,a0)∧...∧hl(zl)∧
φ(Hl,zl)), where:
φ(Tree(H)) = {descr(z′
j,vi,zp) | (z′
j,vi,zp) ∈Tree(H)}, where z′
j is either a0 or a
variable z j.
Let σ be the substitution deﬁned as follows:
for any yi, i = 1,...,k, σ(yi) = z f(i), where z f(i) is the variable assigned to the box
π0(Gi) of H;
for any xi, i = 1,...,m, σ(xi) = wg(i), where wg(i) is the term assigned to the coref-
erence class of π(c), where c is any concept node in the coreference class associated
with xi (the images of coreferent nodes are coreferent nodes, thus wg(i) is well de-
ﬁned).
Let us check that σ is a LN-substitution from ΦN(G) to ΦN(H).
• Let descr(y′
j,ui,yp) be an atom of ΦN(G), then (J,K) ∈UG, K (associated with
yp) is the description of a concept node in J (associated with y′
j), which is in
the coreference class associated with ui. Since π is a homomorphism from G to
H, (π0(J),πJ(c),π0(K)) is in Tree(H), and thus descr(σ(y′
j),σ(ui),σ(yp)) is an
atom of ΦN(H).
• The atom h0(a0) of ΦN(H) corresponds to the atom g0(a0) of ΦN(G).
• Let gi(yi) be an atom of ΦN(G), gi the type of Gi and π0(Gi) = Hπ0(i). Let h be
the type of Hπ0(i) then h ≤gi and h(z f(i)) = h(σ(yi)) is an atom in ΦN(H).
• Let t(u,a0) be an atom of ΦN(G0). It corresponds to a concept node c in G0
which is in the coreference class associated with u. The atom t′(u′,a0) is assigned
to π(c), where u′ is equal to the term associated with the image by π of the
coreference class u. Thus, t′(u′,a0) = t′(σ(u),a0), and t′ ≤t.
• Let t(u,yi) be an atom of ΦN(Gi). It corresponds to a concept node c in Gi, which
is in the coreference class associated with u. The atom t′(u′,z f(i)) is assigned
to π(c), where u′ is equal to the term associated with the image by π of the
coreference class u. Thus, t′(u′,z f(i)) = t′(σ(u),σ(yi)), and t′ ≤t.
• Let p(⃗e,yi) be an atom of ΦN(Gi) corresponding to a relation node r of Gi. The
atom p′(⃗e′,z f(i)) is assigned to π(r), where p′ ≤p and⃗e′ is the term vector asso-
ciated with the nodes which are the images by π of the nodes whose term vector
is⃗e, i.e.⃗e′ = σ(⃗e) . Thus, p′(π(⃗e),z f(i))= p′(σ(⃗e),σ(yi)) is in ΦN(H) and p′ ≤p.
A similar proof can be done for an atom p(⃗e,a0) of ΦN(G0) corresponding to a
relation node in G0. One concludes with the L-substitution lemma.
⊓⊔

9.6 Representation of Nested Typed Graphs by BGs
267
Completeness
Let G and H be two NTGs. Tree(G) = (VG,UG,lG), VG = {G0,G1,...,Gk}, and
Tree(H) = (VH,UH,lH), VH = {H0,H1,...,Hl}. Let us assume that ΦN(V),ΦN(H)
|= ΦN(G), and, using the L-substitution lemma, let σ be a LN-substitution from
ΦN(G) to ΦN(H). From σ, we ﬁrst build a tree homomorphism π0 from Tree(G)
to Tree(H) that maps the root of Tree(G) to the root of Tree(H); then we build a
homomorphism πi from Gi to π0(Gi) for any i = 0,...,k.
One takes π0(G0) = H0. For any i = 1,...,k, π0(yi) is deﬁned by σ(yi). More
precisely if σ(yi) = z f(i) then π0(Gi) = Hf(i). The substitution σ associates to gi(yi)
an atom h(σ(yi)) with h ≤gi. Thus the type of π0(Gi) is ≤type of Gi.
Let us now check that π0 is a tree homomorphism from Tree(G) to Tree(H).
If k = 0, then Tree(G) is restricted to a single node and π0 is a tree homo-
morphism. Let us assume that k ≥1. Let us consider an arc (J,K) in Tree(G)
with lG(J,K) = c. An atom descr(y′
j,ui,yp) in ΦN(G) corresponds to this arc and
descr(σ(y′
j),σ(ui),σ(yp)) is an atom of ΦN(Tree(H)). Thus, (π0(J),π0(K)) is an
arc of Tree(H) and lH(π0(J),π0(K)) = (d,type(π0(K)) where d is the (single) con-
cept node in π0(J) associated with the term σ(ui) (all boxes are normal). This proves
that π0 is a homomorphism from Tree(G) to Tree(H) (and it maps the root of
Tree(G) to the root of Tree(H)).
Let us show that σ is an L-substitution from Φ(Gi) to Φ(π0(Gi)), for i = 0,...,k.
Let p(⃗e) be an atom of Φ(Gi); then there is an atom q(σ(⃗e)) in Φ(π0(Gi)) such that
q ≤p. Indeed, for any i = 0,...,k the atoms of ΦN(Gi) are mapped by σ to atoms
of ΦN(π0(Gi)) with a decrease of the predicate. Thus, the result holds for i = 0. For
any i ∈{1,...,k}, p(⃗e,yi) is an atom of Φ(Gi,yi); therefore it is an atom of ΦN(G)
and there is an atom q(σ(⃗e),σ(yi)) of ΦN(H) with q ≤p. q(σ(⃗e),σ(yi)) is an atom
of Φ(π0(Gi),σ(yi)). Thus q(σ(⃗e)) is an atom of Φ(π0(Gi)) with q ≤p. As σ is
an L-substitution from Φ(Gi) to Φ(π0(Gi)), for i = 0,...,k, then with Property 4.7
there is a homomorphism πi from Gi to π0(Gi) such that for any concept c in Gi
associated with the term u in Φ(Gi), the concept πi(c) is associated with σ(u) in
Φ(π0(Gi)). The last condition of an NTG homomorphism (cf. Deﬁnition 9.12) is
satisﬁed since if lG(J,K) = c (associated with u), then lH(π0(J),π0(K)) = d where
d is the single concept in π0(J) associated with σ(u) and d = πJ(c).
⊓⊔
9.6 Representation of Nested Typed Graphs by BGs
In this section, we deﬁne an injective mapping ng2bg which assigns a BG to a nested
graph. We will see that this mapping preserves the homomorphisms.
A BG (or SG) vocabulary V′ = (TC,TR∪TG∪{cont,descr},I ∪{a0}) is assigned
to a typed graph vocabulary V = (TC,TR,TG,I), where the elements in TG are now
considered as unary relation types, and cont, descr and coref are three new binary
relations and a0 is a new individual marker.

268
9 Nested Conceptual Graphs
Let (G,corefG) be an NTG on V, with Tree(G) = (VG,UG,lG) and VG = {G1,...,
Gk}, G1 being the root. First, for i = 1,...,k, each Gi (on the vocabulary V) is
transformed into an BG G′
i (on the vocabulary V′) as follows. A new concept node
ci is added to Gi and, if i = 1, i.e., Gi is the root of G, then its label is (⊤,a0).
Otherwise its label is (⊤,∗); ci is linked to a new unary relation node labeled by gi
(the type of Gi). For each concept node c in Gi, a new relation node labeled cont is
created with ci as its ﬁrst neighbor and c as its second neighbor.
Secondly, the tree structure has to be coded by the relation descr used as follows.
Whenever Gj is the description of c in Gi, i.e., (Gi,c,Gj) is an arc of Tree(G), then
a new relation node labeled descr is added, which links c in G′
i to cj in G′
j.
Thirdly, corefG is translated by relation nodes of type coref. For each pair
(ci,cj) ∈corefG, we add coref(ci,cj) (as corefG is an equivalence relation, we
also have coref(cj,ci), coref(ci,ci) and coref(cj,cj).
Example. For instance, let G be the NTG in Fig. 9.18, then ng2bg(G) is represented
in Fig. 9.19.
coref
coref
coref
descr
Character:Zorro
dressUp
Child
Drawing
Boy
coref
coref
coref
cont
cont
cont
cont
a0
subject
proposition
madeBy
Fig. 9.19 The SG ng2bg(G) associated with the nested typed graph G in Fig. 9.18
Theorem 9.2. ng2bg is an injective mapping from the set of NTGs on V to the set
of BGs on V′. Furthermore, there is a bijection between the set of (NTG) homo-
morphisms from G to H and the set of (BG) homomorphisms from ng2bg(G) to
ng2bg(H).
Proof. Let G be an NTG on V, with Tree(G) = (VG,UG,lG) and VG = {G1,...,Gk},
G1 being the root and G′ = ng2bg(G). For i = 1,...,k, ci is the node in G′ associated
with Gi and G′
i is the subBG of G′ corresponding to Gi. Let H be an NTG on V,
with Tree(H) = (VH,UH,lH) and VH = {H1,...,Hl}, with H1 being the root and
H′ = ng2bg(H). For i = 1,...,l, di is the node in H′ associated with Hi and H′
i is the
subBG of H′ corresponding to Hi. Let π = (πO,{π1,...,πk}) be a homomorphism

9.6 Representation of Nested Typed Graphs by BGs
269
from G to H where πi is a homomorphism from Gi to Hf(i). A homomorphism π′
from G′ to H′ is built as follows (cf. Fig. 9.20).
• For any i = 1,...,k and any node x in G′
i, π′(x) = πi(x).
• For any ci, i = 1,...,k, π′(ci) = df(i).
• For any unary relation node r (of type lG(Gi)) incident to ci, π′(r) is the unary
relation node (of type lH(Hf(i)) ≤lG(Gi)) incident to π′(ci) = df(i).
• Let r be a binary relation node of type cont in G′ and (ci,c) its neighbor list. π′(r)
is the relation node of type cont in Hf(i) having for neighbor list (π′(ci),π′(c)).
• Let r be a binary relation node of type descr in G′ and (c,cj) its neighbor list.
Let us assume that c is in G′
i. π′(r) is the relation node of type descr in H′ having
for neighbor list (π′(c),df( j)).
• Let r be a binary relation node of type corefG in G′ and (u1,u2) its neighbor list.
Let us assume that u1 and u2 are in G′
i. π′(u1) and π′(u2) are in H′
f(i), and there
is a binary relation node r′ of type corefH in H′
f(i). One takes π′(r) = r′.
One can check that π′ is a homomorphism from G′ to H′, and this mapping from
the (NTG) homomorphisms from G to H to the (BG) homomorphisms from G′ to
H′ is injective and surjective.
⊓⊔
f(c)
cont
cont
desr
gk
ck
dq
hq
descr
cont
cont
f(d)
cont
Fig. 9.20 ng2bg preserves the homomorphisms (proof of Theorem 9.2)
The previous correspondence allows us to transport notions and properties of SGs
to NTGs and, in a way, the nested typed graphs (NTGs) are not more expressive than
simple graphs (SGs). However, even if the transformation ng2bg is simple, the SG
obtained seems more difﬁcult to understand for a human being than the initial NTG.

270
9 Nested Conceptual Graphs
9.7 Bibliographic Notes
It is generally agreed that knowledge has a contextual component, and different for-
malizations have been proposed to deal with knowledge contexts (e.g., cf. [BP83],
[Guh91] and [McC93]).
History of nested conceptual graphs. Nested conceptual graphs were intro-
duced in [Sow84]. Concept nodes representing a proposition can have a referent
that is a graph; the intuitive semantics is that this graph is asserted by, or describes,
the surrounding proposition. After that, several variants of nested conceptual graphs
have been proposed to represent contexts, knowledge description by increasing level
of detail, objects in object oriented programming, or related notions. Natural lan-
guage processing is a main application domain (e.g., [Sow92] [Naz93] [Dic94]).
theme
expr
theme
Believe
agent
expr
theme
Want
Sailor
Marry
Person:Mary
T
Person:Tom
Situation:
Proposition:
 
Fig. 9.21 Nested Graph representing a natural language sentence
For instance, the Fig. 9.21 (due to Sowa, e.g., [Sow99])) represents the sentence
“Tom believes that Mary wants to marry a sailor.” Tom is the experiencer (expr) of
the concept [Believe], which is linked by the relation (theme) to a proposition that
Tom believes. This proposition is described by another graph, which states that Mary
is the experiencer of [Want], whose theme is a situation that Mary hopes will occur.
That situation is described by another graph, which says that Mary (represented by
the concept [⊤]) marries a sailor. The coreference link shows that the concept [⊤]
in the situation concept refers to the same individual as the concept [Person: Mary]
in the proposition concept.
We introduced a combinatorial structure in [CM97], provided with a homomor-
phism called “Graph of graphs,” and showed that the different kinds of nested con-
ceptual graphs found in the CG literature are instantiations of this generic notion,

9.7 Bibliographic Notes
271
and more precisely are trees of speciﬁc graphs. Relationships with category theory
are also pointed out in this paper. Indeed, a kind of graphs provided with a mor-
phism is a concrete category and transformations like ng2bg are functors between
two categories. Note however that this framework did not take coreference links into
account. It was only concerned with the recursive structure of nested graphs.
The model of nested graphs (without coreference) presented in this chapter was
introduced in [MC96] and developed in [CM97]. The latter paper also introduces
typed nestings, to specify relationships between the surrounding node and one of
its descriptions. Note that, in the model presented in this chapter, we shifted nest-
ing types to graph types. This allows us to type graphs at the ﬁrst level, and not
only as descriptions of a concept node. This model was motivated by two appli-
cations in knowledge representation, one concerning simulation (cf. [BBV97]) and
the other concerning document indexing (cf. [Gen00]) Since then it has been used
in other works (e.g., [GC05], [MLCG07] and [TML06] from which the example of
Fig. 9.11 and Fig. 9.15 are extracted). In [CMS98] and [PMC98]) nested graphs
with coreference links are processed and two sound and complete logical semantics
are deﬁned (see below).
Different logical semantics. Sowa extends the mapping Φ (as deﬁned on SGs)
by introducing a special binary predicate descr whose ﬁrst argument is a term and
second argument is a formula. For each complex concept node c with referent a non-
empty graph D, Φ(G) contains the atom descr(e, Φ(D)), where e is the term as-
signed to c. This logical semantics is similar to the semantics of contexts in [Guh91]
[McC93], with descr playing the same role as the ist predicate. Note that the pred-
icate descr takes a formula as argument, thus this logical semantics goes beyond
FOL.
A non-classical logical semantics, with a calculus based on Gentzen-like se-
quents, equivalent to NG homomorphism, was presented in [PMC98]. In [Sim98]
[CMS98], two alternative semantics in classical FOL are given to NGs. The ﬁrst one
extends Φ (as deﬁned on SGs). For homomorphism completeness, the target NG has
to be in so-called k-normal form, where k is the depth of the source NG. Every graph
can be put in k-normal form. The drawback is that putting a graph into k-normal
form may involve increasing the depth of its tree structure. The second semantics
extends Ψ (as deﬁned on SGs, cf. Chap. 4). As for SGs, there is no normality condi-
tion on the target graph. None of these two semantics are entirely satisfying because
they do not translate the notion of context. With Φ, a concept node is simply repre-
sented by the term associated with its coreference class without a term representing
its context. Thus properties attached to a concept node can be equivalently attached
to any coreferent concept node, even if this node is in another context. With Ψ, the
opposite approach is taken: Two coreferent nodes are translated by distinct terms
(plus a term translating the fact that they represent the same entity); consequently,
properties attached to one node cannot be equivalently attached to the second node,
even if these nodes are in the same context. The logical semantics ΦN deﬁned in this
chapter distinguishes between two kinds of coreference, depending on whether it is
intra-context or inter-contexts, and thus can be seen as a combination of previous
semantics Φ and Ψ. The logical semantics for typed nested graphs is new.

272
9 Nested Conceptual Graphs
Other works on nested graphs. In [Bag99], a generalization of nested graphs
(boxed graphs) is deﬁned in which each box contains a BG, and relation nodes can
link concept nodes belonging to different boxes. This extension was mainly done to
reify coreference links. The idea is to replace the coreference relation (or to supple-
ment it) by different relation types translating different coreference relations. Each
type is provided with rules which describe the properties of this coreference rela-
tion. More generally, a boxed graph can be seen as a nested graph with several roots,
added with a set of relation nodes linking concept nodes of different boxes (these re-
lation nodes are said to be out of context). The boxed graph homomorphism does not
necessarily map roots to roots, and a relation node out of context can be mapped to a
node in or out of context, provided that edges are preserved. A transformation from
boxed graphs to simple graphs is given, which, as a side effect, gives another proof
of equivalence between simple and nested graphs (see also [Bag01] (in French)).
In [Ker01], descriptions are named. However, this framework does not provide
operations on nested graphs. A formal declarative semantics is given by an embed-
ding into a nested structure, with an associated notion of truth, from which a notion
of deduction on nested graphs is deﬁned. A transformation from these nested graphs
to simple graphs is exhibited, which preserves deduction.
In [Pre98a] and [Pre00], the NGs studied are without generic nodes. A semantics
(called contextual semantics) in connection with situation theory [BP83] and formal
concept analysis [GW99] is proposed. Triadic power context families, i.e., a kind of
formal context in the sense of formal concept analysis, are deﬁned. The notion of
a standard model built on a triadic power context family and the related notion of
semantic entailment are introduced. An NG G2 is semantically entailed by an NG
G1 if and only if G2 is valid in the standard model of G1. Finally, the framework
is provided with eight sound and complete elementary rules which are sound and
complete with respect to semantic entailment.

Chapter 10
Rules
Overview
In this chapter, we present a strict generalization of basic conceptual graphs (and
nested conceptual graphs). A rule expresses knowledge such as: “If H is present
then C can be added,” where H and C are two graphs with a correspondence be-
tween some of their concept nodes. H is called the hypothesis of the rule, and C
its conclusion. A rule frequently represents implicit or general knowledge, which
can be applied to particular entities, thus making it explicit on these entities. The
following is a typical use. Let F be a basic graph representing facts and let R be a
rule representing general knowledge. F can be enriched by applying R: Each time
the hypothesis of R can be mapped to F (F contains a specialization of the rule
hypothesis), then its conclusion can be added to F according to the mapping.
In the ﬁrst section, we give deﬁnitions and logical semantics of the kind of rules
that are studied in this chapter. The second section is devoted to rule application in
forward chaining. After deﬁning a derivation mechanism, it is proven that this rule
derivation mechanism is sound and complete with respect to the logical semantics.
The third section is devoted to rule application in backward chaining. Backward
mechanism is similar to Prolog resolution. But, since a graph rule is more general
than a deﬁnite clause, the situation is more complex than with Prolog. The graph
structure is used in the backward mechanism proposed. The fourth section deals
with computational complexity results. It is stated that the deduction problem is
non-decidable (i.e., it is only semi-decidable) and decidable cases are exhibited.
10.1 Deﬁnition and Logical Semantics of a Rule
Several deﬁnitions of a rule can be found in the conceptual graph literature. Below
we introduce the classical deﬁnition of a rule as an ordered pair of lambda-BGs.
We shall also give the deﬁnition of a rule as a bicolored graph, which is in some
273

274
10 Rules
sense less expressive, but is interesting for visualization purposes. Let us ﬁrst deﬁne
λ-BGs.
Deﬁnition 10.1 (λ-BG).
• A λ-BG, L = (c1 ... cn) G, n ≥0, consists of a BG G and n distinguished generic
concept nodes of G, c1 ... cn. A BG can be considered as a lambda-BG with
n = 0. L is said to be normal if G is normal.
• The logical semantics of a λ-BG (c1 ... cn) G is obtained from the logical se-
mantics of G by removing the existential quantiﬁcation of all variables asso-
ciated with c1 ... cn (which are thus free variables), i.e., Φ((c1 ... cn) G) =
∃y1 ...∃ykφ(G), where the variables yi-s are associated with the generic concept
nodes distinct from the ci-s and φ(G) is the conjunction of atoms associated with
all nodes in G (cf. deﬁnition 4.7).
IF
play3
play3
H
C
THEN
C
H
play3
play3
THEN
IF
Toy:*x
Person:*y
Person:*z
Toy:*x
2
1
3
2
3
Person
Person
Person
Person
Person:*z
Person:*y
1
2
1
3
1
Toy
Toy
3
2
Fig. 10.1 Two drawings of the same rule
Deﬁnition 10.2 (λ-rule).
• A λ-rule R is an ordered pair of λ-BGs (H = (c11 ... c1n) H′,C = (c21 ... c2n) C′).
There is a bijection from the distinguished nodes of H to the distinguished nodes
of C which associates c1i with c2i for all i = 1,...,n.
• H is called the hypothesis of R, and C is its conclusion.
• The nodes c1i and c2i are called the connection nodes of R. A λ-rule is also
denoted R = (c1 ... cn)H ⇒C or simply R = H ⇒C.

10.1 Deﬁnition and Logical Semantics of a Rule
275
When there is no ambiguity, we simply note ci for c1i and c2i. In drawings,
distinguished concept nodes are often labeled by named generic markers of form
∗x1 ... ∗xn. The bijection between them may also be represented by links connect-
ing each c1i with c2i. Figure 10.1 presents two drawings of the same rule which states
that the relation play3 is symmetrical on its two ﬁrst arguments of type Person: “If
a person z and a person y play together with a toy x, then y and z also play together
with x.” This rule is very simple, since its conclusion is very simple: All concept
nodes are connection nodes and corresponding concept nodes in the hypothesis and
the conclusion have the same type. Its application to a fact only adds a new relation
node between already existing concept nodes. Other kinds of rules are presented in
Fig. 10.2. Rule R1 states that “If a Person x has for uncle a Person y, then there is a
Person who is a parent of x and a brother of y.” Its application adds not only relation
nodes but also a new generic node. Rule R3 states that “If a Person has for uncle the
Person x then x is a Man.” Its application possibly restricts the type of an existing
concept node.
IF
THEN
THEN
R3
IF
IF
THEN
R2
R1
hasUncle
Person:*x
Man:*x
Person
Person:*x
Person:*x
hasBrother
hasUncle
hasParent
Person
Person:*y
Person:*y
hasParent
Person:*x
Person:*x
hasBrother
hasUncle
Person:*y
Person
Person:*y
Fig. 10.2 Rule examples

276
10 Rules
10.1.1 Logical Semantics of a Rule
Brieﬂy, the FOL semantics of a rule states that, for all variables associated with the
connection nodes, if the hypothesis holds true, then the conclusion also holds true.
Deﬁnition 10.3 (FOL semantics of a λ-rule). Let R = H ⇒C be a λ-rule with
H = (c11 ... c1q) H′ and C = (c21 ... c2q) C′. Φ(R) = ∀x1 ... ∀xq (Φ(H) →Φ(C))
where, for i = 1,...,q, xi is the variable assigned to the connection nodes c1i and
c2i, and Φ(H) and Φ(C) are FOL semantics of the λ-BGs H and C (by deﬁnition,
x1 ... xq are free variables in Φ(H) and Φ(C)).
Note that, if for some i, c1i and c2i have the same type, the atom type(xi) associ-
ated with c2i in Φ(C) can be suppressed.
Let xq+1,...,xl1 denote the variables assigned to the generic nodes in H that are
not connection nodes, and y1,...,yl2 denote the variables assigned to generic nodes
in C that are not connection nodes. Then, Φ(R) can be written as follows:
Φ(R) = ∀x1 ... ∀xq (∃xq+1 ...∃xl1φ(H) →∃y1 ...∃yl2φ(C)), where φ(H) and φ(C)
are the conjunction of atoms associated with all nodes in H and C, respectively. This
formula can equivalently be rewritten as:
Φ(R) = ∀x1 ... ∀xl1(φ(H) →∃y1 ...∃yl2φ(C)), where the only existentially quanti-
ﬁed variables are the variables associated with generic nodes of the conclusion that
are not connection nodes.
Example. The formula assigned to the rule in Fig. 10.1 is
∀x∀y∀z(Toy(x)∧Person(y)∧Person(z)∧play3(z,y,x) →play3(y,z,x)).
The formulas assigned to the rules R1 and R2 in Fig. 10.2 are:
Φ(R1) = ∀x∀y(Person(x)∧Person(y)∧hasUncle(x,y) →∃z(Person(z)∧
hasParent(x,z)∧hasBrother(z,y))).
For R2, which is the reciprocal rule of R1, one has:
Φ(R2) = ∀x∀y(∃z(Person(x)∧Person(y)∧Person(z)∧hasParent(x,z)∧
hasBrother(z,y)) →hasUncle(x,y)), or equivalently:
Φ(R2) = ∀x∀y∀z(Person(x)∧Person(y)∧Person(z)∧hasParent(x,z)∧
hasBrother(z,y) →hasUncle(x,y)).
For R3 one has: Φ(R3) = ∀x(∃y(Person(x) ∧Person(y) ∧hasUncle(y,x)) →
Man(x)),
or equivalently Φ(R3) = ∀x∀y(Person(x)∧Person(y)∧hasUncle(y,x) →Man(x)).
The logical formula assigned to a rule can generally not be represented by an
equivalent clause (i.e., a universally quantiﬁed disjunction of positive or negative
literals) because of the existentially quantiﬁed variables in the conclusion (e.g.
Φ(R1)). In the other direction, a clause can be represented by a rule only if it
is a deﬁnite clause (i.e., it possesses exactly one positive literal) with no func-
tion. A deﬁnite clause D is translated into a rule whose logical formula is of form
∀x1 ... ∀xq(⊤(x1) ∧... ∧⊤(xq) ∧conjN →conc), where: x1 ...xq are the vari-
ables of the clause, conjN is the conjunction of atoms that appear negatively in D
and conc is the positive atom in D. The atoms ⊤(xi) are used to type each variable.
For instance, a clause p(x,y,z)∨¬r(x,y)∨¬r(x,z) is translated into a rule logically
interpreted by ∀x∀y∀z(⊤(x)∧⊤(y)∧⊤(z)∧r(x,y)∧r(x,z) →p(x,y,z)).

10.1 Deﬁnition and Logical Semantics of a Rule
277
Before entering the processing of rules, let us deﬁne another representation of
rules.
10.1.2 Rule as a Bicolored Graph
Bicolored basic graphs deﬁned hereafter can be used to deﬁne rules and provide nice
visualizations of them. However, they slightly restrict the expressiveness of rules (in
a sense that we will specify).
Deﬁnition 10.4 (Bicolored BG). A bicolored basic graph (G,l) is a BG G provided
with a coloring l of its nodes with two colors, say 0 and 1.
Deﬁnition 10.5 (Rule as a bicolored BG).
• A bicolored rule R = (G,l) is a bicolored basic graph, which satisﬁes: The sub-
graph H induced by the color 0 nodes is a subBG of G (i.e., if a relation node is
colored by 0 then all its neighbors must also have color 0).
• H is called the hypothesis of the rule.
• Concept nodes of color 0 with at least one neighbor outside the hypothesis part
are the frontier nodes.
• Nodes with color 1 together with the frontier nodes induce a subgraph C called
the conclusion of the rule.
The condition on the hypothesis of the rule prevents the rule application mecha-
nism (as it is deﬁned in deﬁnition 10.6) for producing BGs that would be syntacti-
cally incorrect. The frontier nodes are shared by the rule hypothesis and conclusion.
They correspond to the connection nodes of λ-rules, which are generic nodes, and
to shared individual nodes.
R1
hasUncle
Person
Person
Person
hasParent
hasBrother
Fig. 10.3 Colored graph representation of the rule R1 in Fig. 10.2
In drawings, the hypothesis is shown in white, and the conclusion, except frontier
nodes, in gray. Figure 10.3 shows a bicolored representation of the rule R1 repre-
sented as a pair of λ-graphs in Fig. 10.2.
The logical semantics of these rules is as follows: Let φ(H) and φ(C) be the
conjunctions of atoms associated with the hypothesis H and the conclusion C. Let
x1 ... xn be the variables assigned to generic frontier nodes; let y1 ... yp (resp. z1 ... zq)

278
10 Rules
be the variables assigned to the other generic concept nodes of H (resp. C). Then,
Φ(R) = ∀x1 ... ∀xn (∃y1 ... ∃yp φ(H) →∃z1 ... ∃zq φ(C)).
A bicolored rule with hypothesis H and conclusion C can be seen as a λ-rule
((c1...cn)H,(c1...cn)C), where (c1 ... cn) is any total ordering of the generic frontier
nodes. In the other direction, the λ-rules corresponding to bicolored rules have the
speciﬁc property that all ci1 and ci2 have the same type. Intuitively, a bicolored rule
might add new relation and concept nodes, but it cannot specialize the type of an
existing node. This is not a real loss of expressivity from a logical viewpoint since
concept types can be seen as unary relations. In other words, a knowledge base con-
sisting of facts and λ-rules can be translated into a logically equivalent knowledge
base consisting of facts and bicolored rules with a change of vocabulary. Let us
call t this transformation. Let V be the vocabulary; t(V) is the vocabulary built by
translating all concept types, except the universal type ⊤, into unary relation types,
while keeping the same partial order. The concept type set of t(V) is composed of
the single type ⊤. Any BG on V is transformed into a BG on t(V) as follows: Each
concept node with label l = (t1...tk,m) is translated into a concept node with label
(⊤,m) and, if the type in l is not equal to ⊤, for each ti in l, one incident relation
node with label (ti). The following property is immediate:
Property 10.1. Let G and H be two BGs. There is a homomorphism π1 from G to H
if and only if there is a homomorphism π2 from t(G) to t(H), such that π1 and π2
coincide on concept nodes, i.e., for all c ∈CG,t(π1(c)) = π2(t(c)).
Facts and λ-rules can thus be translated into facts and bicolored rules, while pre-
serving not only the logical semantics of the KB, but also homomorphisms between
objects of the KB.
10.2 Forward Chaining
Generally speaking, there are two classical ways of using rules: forward and back-
ward chaining. Forward chaining starts from the facts and applies rules to the facts
in order to produce new facts; this cycle is repeated until either no rule can be ap-
plied (all factual knowledge deducible from the base has been made explicit) or a
speciﬁed state is reached (for instance a specialization of a goal, or an answer to
a question has been found). Backward chaining starts from a question, classically
called a goal, and tries to build a derivation leading to an answer to this goal in a
backward manner. The idea is that, if a rule conclusion “matches” the goal, i.e., an
application of this rule could possibly answer part of the goal, then the correspond-
ing rule application can be used in a derivation answering the goal, provided that
a new goal, composed of the remaining part of the original goal and the hypothe-
sis of the rule, is answered; the process stops when the new goal is empty (in this
case, the last rule considered has an empty hypothesis—it is a fact—and the goal is
completely mapped to this fact) or all possibilities have been explored.

10.2 Forward Chaining
279
10.2.1 Rule Application
Deﬁnition 10.6 (Rule application). A λ-rule R = H ⇒C is applicable to a BG G if
there is a homomorphism π from the hypothesis H of R to G. In this case, the result
of the application of R to G according to π is the BG G′ = (R,π)G obtained from G
and the conclusion C of R by merging each c2i of C with π(c1i). If normalization is
required, the possible new individual nodes added by C are merged with the possible
individual nodes with the same marker in G.
The node obtained by merging c2i and π(c1i) has the same marker as π(c1i). If
c1i and c2i have the same type (i.e., R could be considered as a bicolored rule), then
its type is exactly the type of π(c1i).
Otherwise, its type is the conjunction of both types. This conjunction can be a
banned type: In this case, despite the fact that the rule is applicable to G according
to π, the result is a BG inconsistent with respect to the vocabulary. The knowledge
base is thus inconsistent and has to be repaired (otherwise, from a logical view-
point, any BG could be deduced from it, which is not desirable from a knowledge
representation viewpoint).
Notes on Particular Cases
Basic vocabularies can also be considered instead of conjunctive vocabularies. In
this case, the type of the obtained node is a maximal common subtype of the type
of c2i and the type of π(c1i). Thus, if the concept type hierarchy is not an inf-semi-
lattice, then there might be several possible new labels, or none if the types have no
common subtype. Let us recall that the set of conjunctive types is a lattice (how-
ever, some of the types might be banned). If bicolored rules are considered instead
of λ-rules, the structure of the concept type set does not matter. Indeed, the rule
application process simply adds the conclusion according to the images of the fron-
tier nodes and cannot specialize the label of existing nodes. In terms of elementary
specialization operations, it makes the disjoint sum of G and the conclusion C of R,
restricts the label of each frontier node c in C to the label of its image π(c), then
joins each c and π(c).
Examples. See rule R in Fig. 10.1 and graphs G and G′ in Fig. 10.4 for the simplest
example: There is only one way of applying R to G, and G′ is the resulting graph.
Let us now consider the abstract example of Fig. 10.5. There are three concept types
t1, t2 and t3, where t1 is greater than t2 and t3, which are both incomparable. Rule
R states that “for all entity x, if x is of type t1 and r(x) holds true, then x is of type
t3.” R is applicable to G, with the connection node of type t1 being mapped to the
node of type t2, which leads to a node of type {t2, t3}. G′ is obtained. Note that
{t2, t3} might be banned. Figure 10.6 shows a more complex rule application: Rule
R4 (which is the conjunction of rules R1 and R3 in Fig. 10.2) is applied to the fact F
yielding F′. It is assumed that Painter ≤Person and Man ≤Person.

280
10 Rules
play3
attr
possess
play3
play3
G
G’
attr
Person
3
1
2
3
2
1
Person
3
1
2
Car
Child: Paul
Size: Small
possess
Size: Small
Car
Child: Paul
The rule in Fig. 10.1 is applied to G yielding G′
Fig. 10.4 A simple rule application
G’
IF
THEN
G
t2
r
t2, t3
r
t1
r
t3
Fig. 10.5 Type restriction by rule application
Painter, Man
F’
F
R4
IF
THEN
2
hasUncle
Person:*x
1
Person:*x
Person:*y
Man:*y
1
2
2
1
2
Person
hasParent
hasBrother
Person
hasParent
2
hasUncle
1
Man:John
1
c4
1
2
2
Painter
hasUncle
1
Man:John
hasBrother
Fig. 10.6 A rule application

10.2 Forward Chaining
281
In Fig. 10.7, the (bicolored) rule R represents the following statement: “If a per-
son x is an employee of a company z, which is managed by a person y, then x gets a
salary s and y decides on s.” Fact F states that B manages company C. It is assumed
that manager is a specialization of employee. There is a homomorphism π from the
hypothesis of R to F, which maps both connection nodes x and y to the same node
B, and z to C. The application of R to F according to π produces the fact F′, which
states that “B, manager of company C, gets a salary and decides on it.”
Company
employee
Person
Person
decide
Salary
get
manager
get
decide
Salary
manager
F
F’
Person : B
Company : C
R
C
x
y
z
B
Fig. 10.7 Another rule application
10.2.2 Derivation and Deduction
Let R be a set of rules. If G′ is obtained from a BG G by application of a rule R
in R, we say that G′ is immediately derived from (G,R) or, from (G,R). G′ is said
to be derived from (G,R) if there is a sequence of BGs G0(= G),G1,...,Gk(= G′)
(k ≥0) such that each Gi+1 (0 ≤i < k) is immediately derived from (Gi,R). Such
a sequence is called an R-derivation (or simply a derivation) from G. When the KB
is composed of facts and rules, the deduction problem, denoted FR-DEDUCTION
(cf. Chap. 11), asks if there is a sequence of rule applications that enrich the facts
such that the goal can be reached, i.e., a derivation from the facts leading to a graph
to which the goal can be mapped. In what follows, a set of facts F is identiﬁed with
a BG F.

282
10 Rules
Deﬁnition 10.7 (Deduction with facts and rules). FR-DEDUCTION takes a KB
K = (F, R) as input, where F is a set of facts and R is a set of rules, and a goal Q,
and asks if Q is deducible from K, i.e., if there is an R-derivation from F to a BG
F′ such that Q ⪰F′.
Q
F’
F
IF
R3
THEN
Man :*y
F’’
THEN
IF
R2
Painter, Man :P
Man
hasFather
hasBrother
Man:John
hasBrother
admires
1
2
hasUncle
2
1
hasUncle
Person:*y
hasUncle
Person:*x
2
1
1
1
2
2
2
2
Man
1
hasUncle
admires
Person
Painter:P
c5
hasBrother
1
hasBrother
Man
2
hasFather
Man:John
1
2
c3
c4
c6
c7
Person:*y
2
1
2
2
2
2
1
1
1
1
Man:John
hasUncle
hasFather
Man
Person:*x
hasBrother
hasBrother
Painter:P
Person
admires
hasBrother
Person:*x
hasParent
Person
Person:*y
c11
c9
c8
1
1
1
1
2
2
2
2
c10
c1
Man:John
1
2
hasUncle
1
2
c2
Entity
1
Fig. 10.8 Graph derivation and deduction
Example. In Fig. 10.8, R = {R2,R3}. F′ is immediately derived from (F,R) by an
application of R2 which maps the sequence of nodes (c3,c4,c5) to (c8,c9,c10). F′′
is derived from (F,R) by a derivation of length 4 (R2 and R3 are each used twice).

10.2 Forward Chaining
283
Q cannot be deduced from F, but it can be deduced from (F,R): Indeed, there is a
homomorphism from Q to F′ (and a fortiori to F′′).
Note on the expressivity of bicolored rules with respect to λ-rules. Ev-
ery instance of FR-DEDUCTION can be transformed into an instance of FR-
DEDUCTION solely using bicolored rules by way of transformation t detailed in
Sect. 10.1.2. A rule R is applicable to a fact F if and only if t(R) is applicable to
t(F). Moreover, it can be immediately checked that the following three graphs are
logically equivalent: F′ immediately derived from (F,R), t(F′) and graph F′′ im-
mediately derived from (t(F),t(R)). They have identical sets of concept nodes. F′′
may contain redundant unary relation nodes, which are easily suppressed, in the
same way as a conjunction of concept types is minimized. The only true difference
between F′ and t(F′) is that F′ can be inconsistent due to a possible banned concept
type occurring in a label. Thus, if the knowledge base is consistent, i.e., no incon-
sistent graph can be derived from it, then λ-rules and bicolored rules can be said to
have the same expressivity.
The forward chaining scheme is presented in Table 25. The algorithm explores
the tree of all derivations from fact F in a breadth-ﬁrst manner. One step (i.e., an
iteration of the “while true” loop) consists of ﬁnding all new homomorphisms from
rule hypotheses to the current F, and performing all rule applications corresponding
to these homomorphisms. The order in which these rule applications are considered
does not matter: The same graph (up to isomorphism) is obtained at the end of the
step for all possible orders. At the beginning of each step, it is checked whether
Q can be mapped to F. If yes, Q is deducible from the knowledge base and the
algorithm returns true. Otherwise the set of all new homomorphisms is computed.
Given a rule R = H ⇒C, a homomorphism from H to F is new if has not been
already computed at a previous step. A simple method for recognizing new homo-
morphisms at step i consists of memorizing the set of nodes Ni−1 added to F, or
modiﬁed (by a type restriction) at step i−1; then a homomorphism from H to F is
new if it maps at least one node of H to a node of Ni−1. If the set of new homo-
morphisms is empty, Q is not deducible from the knowledge base and the algorithm
returns false. Otherwise, F is enriched by all rule applications according to the new
homomorphisms.
If the algorithm returns true, Q is indeed deducible from the KB since a derivation
has been built, which ends with a graph to which Q can be mapped. As the algorithm
explores the space of all possible rule applications in a breadth-ﬁrst manner, and at
a given step, the number of (new) rule applications to F is ﬁnite, it is ensured that
whenever there are some derivations allowing us to deduce Q the algorithm will
build one of these derivations. The algorithm thus returns true if and only if Q is
deducible from the base. If the algorithm returns false, Q is indeed not deducible
from the base: New rule applications can no longer be done; thus the current F
represents all information deducible from the KB (see the notion of a closed graph
in Sect. 10.4.2), and Q cannot be mapped to it. However, the tree of all derivations
may have inﬁnite paths: Thus, when Q is not deducible from the base, the algorithm
might not end. See Sect. 10.4.2 for further details.

284
10 Rules
Algorithm 25: ForwardChaining
Input: a knowledge base K = (F, R) in normal form, and a BG Q
Output: true if and only if Q can be deduced from K otherwise false or inﬁnite calculus
begin
while true do
if there is a homomorphism from Q to F then
return true
ToApply ←∅
forall R: H ⇒C ∈R do
forall new homomorphism π : H →F do
ToApply ←ToApply ∪{(R,π)}
if ToApply = ∅then
return false
forall (R,π) ∈ToApply do
F ←apply R to F according to π
Normalize F if needed
end
10.2.3 Non-Redundant Rule Application
Obviously, it is irrelevant to apply a rule to a graph if this rule does not bring new
information. A trivial case is that if a rule can be applied once, then it can be applied
indeﬁnitely in the same way to the obtained graph. These further applications do
not bring anything new. They are said to be trivially useless. The notion of new ho-
momorphism in the forward chaining algorithm (Table 25) prevents trivially useless
rule applications. Another case of trivial redundancy is that of twin relation nodes,
i.e., relations with the same label and exactly the same arguments in the same or-
der. Consider, for instance, the rule “if r(x,y) then r(x,y).” This rule can be applied
indeﬁnitely according to a new homomorphism each time, but all applications pro-
duce twin relation nodes. More generally, the application of a rule R brings new
information to a graph G if G and (R,π)G are not equivalent. Determining whether
two graphs are equivalent is an NP-complete problem (see Chap. 2). The next prop-
erty allows us to test whether a rule application would add new information with a
local check. Instead of checking whether (R,π)G can be mapped to G, it is indeed
sufﬁcient to check whether the part that would be added to G could be “folded”
onto G.
Property 10.2 (Redundant application). Let G be an irredundant BG, R = H ⇒C
be a rule, and let π be a homomorphism from H to G. Then (R,π)G is equivalent
to G if and only if there is a homomorphism π′ from C to G, such that for each
connection node ci, π′(c2i) = π(c1i).
Proof. Assume that there is a homomorphism from (R,π)G to G. Property 2.9 states
that, if G′ is a redundant graph and K is an irredundant subgraph of G′ equivalent
to G′, then there is a homomorphism π′′ from G′ to K, which keeps every node in

10.2 Forward Chaining
285
K invariant. If we consider G′ = (R,π)G and K = G, we deﬁne π′ as the restriction
of π′′ to the subgraph of G′ corresponding to C; π′ satisﬁes the condition of the
property. Conversely, if there is a homomorphism π′ satisfying the condition of the
property, then there is a homomorphism from (R,π)G to G built as follows: Each
node coming from C is mapped to π′(C); each other node is mapped to itself. Since
there is also a homomorphism from G to (R,π)G (the identity mapping), G and
(R,π)G are equivalent.
⊓⊔
G
R
r
t1
t1
s
s
c
t
r
t1
Fig. 10.9 G needs to be irredundant in Property 10.2
If G is redundant, only the ⇐direction of Property 10.2 is true. In this case, we
only have a sufﬁcient condition for a rule application to be useless. See Fig. 10.9,
where R is pictured as a bicolored rule (“for all x, if t1(x) then r(x)”) and G is
redundant; the application of R to G at node c would yield a graph equivalent to G;
however, there is no homomorphism, from the conclusion of R to G that maps the
concept node of R to c.
Property 10.2 prevents uninteresting rule applications. However, it would be
more interesting to accurately characterize the part of the rule conclusion that adds
new information in order to keep an irredundant graph. Indeed, even if G is irredun-
dant, the previous property does not guarantee that G′ = (R,π)G will be irredundant.
G′ will not be equivalent to G but may contain redundant parts. See for instance
Fig. 10.10, in which t1 ≥t2: G is not redundant; R can be applied at b and at c; the
application at b is avoided because it is a redundant application; the application at c
is not redundant but the obtained graph G′ is redundant (there is a homomorphism
from G′ to one of its strict subgraphs, that maps b to c).
G
R
r
t
r
a
b
c
t2
t1
s
s
t1
Fig. 10.10 Property 10.2 does not prevent redundancy (t1 ≥t2)

286
10 Rules
10.2.4 Soundness and Completeness of Forward Chaining
In this section, we prove the logical soundness and completeness of the forward
mechanism based on rule application, i.e., given a KB K = (F,R), any BG Q is
deducible from K by a rule derivation if and only if its logical translation is de-
ducible from the logical translation of K. As the involved operations rely on homo-
morphism, completeness is submitted to a normality condition. A KB is said to be
normal if the set of facts considered as a single graph (F) is normal.
Theorem 10.1 (Forward chaining soundness and completeness). Let K = (F,R)
be a KB, where F is a set of facts and R a set of rules, and let Q be a BG, with all
being relative to a vocabulary V.
• (soundness) if Q is deducible from K (i.e. there is a BG F′ that can be derived
from K such that Q can be mapped to F′) then Φ(V), Φ(F), Φ(R) |= Φ(Q)
• (completeness) provided that F is normal and the graph obtained at each deriva-
tion step is put into normal form: if Φ(V), Φ(F), Φ(R) |= Φ(Q) then Q is
deducible from K.
As a knowledge base consisting of facts and λ-rules can be translated into a log-
ically equivalent knowledge base consisting of facts and bicolored rules (cf. the last
remark in Sect. 10.1.2), only bicolored rules are considered in the proof.
Proof of soundness
Lemma 10.1. Let F and Q be BGs and let R be a rule over V, such that Q
is immediately derived from F by an application of R, i.e., Q = (R,π)F, then:
Φ(V),Φ(F),Φ(R) |= Φ(Q).
Notations
Φ(F) = ∃x1 ...xl(F)(P1 ∧...Pn(F)).
The connection nodes of R are {c11,...,c1q} and {c21,...,c2q}, xi is the term asso-
ciated with c1i and c2i. H is the hypothesis of R and C its conclusion.
Φ(R) = ∀x1 ...∀xq(∀xq+1 ...∀xl1Q11 ∧...∧Q1m1 →(∃y1 ...yl2Q21 ∧...∧Q2m2)).
The clausal forms of Φ(F) and Φ(R) are:
C(Φ(F)) = {ρ(Pi) | i = 1,...,n(F)} where ρ is the substitution ρ = {(x1,a1),...,
(xl(F),al(F)) with ai-s being skolem constants;
C(Φ(R)) = {¬Q11(x1,...,xl1)∨...∨¬Q1m1(x1,...,xl1)
∨Q2i(x1,...,xl1, f1(x1,...,xl1),..., fl2(x1,...,xl1)) | i = 1,...,m′
2}
where the fi-s are skolem functions. If the atoms Q2i, for i = m′
2 + 1,...,m2, are
atoms associated with connection nodes of the conclusion of R then the clause of
Φ(R) corresponding to Q2i is a tautology and it can be deleted.
Φ(Q(= (R,π)F)) = ∃x1 ...xl(F)(P1∧...Pn(F))∧∃y1 ...yl2(η(Q21(x1,...,xl1,y1,...,
yl2))∧...∧η(Q2m′
2(x1,...,xl1,y1,...,yl2)))
where η is the substitution which assigns to each variable xi associated with the
connection node c1i the term assigned to π(c1i) by Φ, i.e.,

10.2 Forward Chaining
287
η = {(x1,term(π(c11))),...,(xq,term(π(c1q)))}.
cf. Fig. 10.11.
π (H)
yl2
y1
xq+1
F
C
H
zj
c2q
xl1
xq
zl(F)
z1
xq
x1
x1
c21
c1q
c1i
c11
c2i
Fig. 10.11 Terms associated with nodes in forward application of a rule
Lemma Proof technique
We show, by the resolution method, that {Φ(V),Φ(F),Φ(R),¬Φ((R,π)F)} is
inconsistent. More precisely, we show that there is a substitution λ such that any
λ(A) where A ∈atoms((R,π)F) can be obtained by resolution from λ(E), where
E = {Φ(V),Φ(F),Φ(R)}.
Proof. Since π is a homomorphism from H to F, there is a L-substitution σ from
Φ(H) to Φ(F), which satisﬁes (cf. Property 4.6):
For each concept node c in H, σ(term(c)) = term(π(c)),
for all i = 1,...,m1 σ(Q1i) ∈Aug(atoms(Φ(F))).
Let µ be the composition of ρ and σ, then µ satisﬁes:
• For all concept nodes c in H, µ(term(c)) = ρ(σ(term(c))) = ρ(term(π(c))),
• for all i = 1,...,m1, since σ(Q1i) ∈Aug(atoms(Φ(F))) one has µ(Q1i) ∈
Aug(C(Φ(F))).
Let λ be the substitution λ = ρ ∪µ′ where µ′ = {(y1, f1(µ(x1),...,µ(xl1))),...,
(yl2, fl2(µ(x1),...,µ(xl1)))}. cf. Fig. 10.12
Let A ∈atoms(Φ(Q(= (R,π)F))). Let us check that any λ(A) can be obtained
by resolution from λ(E).
If A is associated with a node in F then λ(A) is in C(Φ(F)) thus it is in λ(E).
Otherwise, A is associated with a node, not equal to a connection node, in C and

288
10 Rules
p(H)
π
r
)
(c)
(term(
m(x1)
m(xl1) )
...
fi(
c
p(  )
F
C
xi
yi
ai
Fig. 10.12 The substitution λ
λ(A) = µ′(Q2m). We know that for all i = 1,...,m1 µ(Q1i) ∈Aug(C(Φ(F))).
Therefore, using the clause in Φ(R) containing Q2m all the negative atoms can be
eliminated, and one obtains µ′(Q2m).
⊓⊔
The soundness is proven by recurrence on the number of rule applications using
Lemma 10.1.
Proof of completeness
Notations
Φ(F) = ∃x1 ...xl(F)(P1 ∧...Pn(F)),
C(Φ(F)) = {ρ(Pi) | i = 1,...,n(F)} where ρ is the substitution ρ = {(x1,a1),...,
(xl(F),al(F)) with ai-s being skolem constants;
For any R ∈R:
Φ(R) = ∀xR
1 ...∀xR
q(R)(∀xR
q(R)+1 ...∀xR
l1(R)QR
11 ∧...∧QR
1m1(R) →
(∃yR
1 ...yR
l2(R)QR
21 ∧...∧QR
2m2(R))),
C(Φ(R)) = m′
2(R)
i=1
(¬QR
11(xR
1,...,xR
l1(R))∨...∨¬QR
1m1(R)(xR
1,...,xR
l1(R))
∨QR
2i(xR
1,...,xR
l1(R), f1(xR
1,...,xR
l1(R)),..., fl2(R)(xR
1,...,xR
l1(R))))
where the f R
i -s are skolem functions.
Let E denote the set of ground (or Herbrand) clauses associated with the set
of clauses {C(Φ(V)),C(Φ(H)),C(Φ(R)),C(¬Φ(Q))} and built on I ∪{ai | i =
1,...,l(F)}∪{f R
i | i = 1,...,l2(R),R ∈R}.
Sub(U) is the set of ground substitutions {(x1,t1),...,(xp,tp)} such that the ti-s are
pairwise distinct and do not belong to I. For such a substitution, if the xi-s are asso-
ciated with generic nodes in a graph, then there is a bijection between these nodes
and the ti-s without mix-up with the individual nodes.

10.2 Forward Chaining
289
Proof.
Proof steps
The main steps of the proof are as follows. Since Φ(V), Φ(F), Φ(R) |= Φ(Q),
E is unsatisﬁable and thus there is E′ ⊆E such that E′ is ﬁnite and unsatisﬁable.
Starting from A0 = Aug(C(Φ(F))) a sequence A0 ⊆A1 ⊆... ⊆As = As+1 of
clause sets is built. A sequence (Hn,ρn,Rn,πn) is associated with sequence An as
follows.
H0 = F, ρ0 = ρ and Rn is a rule, πn is a homomorphism from the hypothesis of Rn
to Hn, Hn+1 is the normal form of (Rn,πn)Hn and ρn+1 is a substitution in Sub(U)
obtained from ρn and πn.
Let Hs be the last graph obtained by this construction. One proves that:
1. There is a clause B in C(¬Φ(Q)) with all its atoms in As,
2. let C′(Φ(Hs)) = {ρs(A) | A ∈atoms(Φ(Hs)}, then As = Aug(C′(Φ(Hs))).
Therefore, there is a homomorphism from Q to Hs (and this proves the complete-
ness). Indeed, let p(u1,...,uk) be any atom of Φ(Q), and let σ be the substitution
deﬁned by the clause B, i.e., p(σ(u1),...,σ(uk)) is an atom of B. There is an atom
q(v1,...,vk) in Φ(Hs) such that q ≤p and ρs(vi) = σ(ui) for all i = 1,...,k. There-
fore, there is a V-substitution of Φ(Q) to Φ(Hs), and by using Property 4.6 Q maps
to Hs.
Let us now build the sequences An and (Hn,ρn,Rn,πn), for n = 0,...,s and let us
prove their properties.
Construction of the sequence An
A0 = Aug(C(Φ(F)))
for all n ≥0, if:
• There is R ∈R,
• there is a ground substitution µ =
{(xR
1,t1),...,(xR
l1(R),tl1(R)), (yR
1, f R
1 (t1,...,tl1(R))),...,(yR
l2(R), f R
l2(R)(t1,...,tl1(R)))},
• there is m ∈{1,...,m′
2(R)} such that µ(¬QR
11 ∨...∨¬QR
1m1(R) ∨QR
2m) ∈E′
and, for all i = 1,...,mR
1, µ(QR
1i) ∈An and µ(QR
2m) /∈An
then An+1 = An ∪Aug({µ(QR
2i) | i = 1,...,m2(R)}, otherwise An+1 = An.
At each step a new clause in E′ is chosen and E′ is ﬁnite. Thus the construction
stops at a rank s.
Proof of the ﬁrst property
Let us prove the ﬁrst property, i.e., there is a clause B in C(¬Φ(Q)) with all its
atoms in As. As is a set of ground atoms, therefore we can deﬁne an interpretation v
as follows: v(A) = true if and only if A ∈As. We show by reduction to the absurd
that if the property is not satisﬁed, i.e., if any clause in C(¬Φ(Q)) has an atom that
is not in As, then v(E′) = true and this is absurd since E′ is unsatisﬁable.
Let D be a clause in E′.

290
10 Rules
• Let D ∈C(¬Φ(Q)), then D has at least one atom that is not in As, thus v(D) =
true.
• Let D ∈C(Φ(F)), then D is in A0; thus it is also in As and v(D) = true.
• Let D ∈C(V). D = ¬A ∨A′ and A′ ∈Aug(A). If A ∈As then A′ ∈As because
Aug(As) = As. Therefore, v(A′) = true and v(D) = true. Otherwise v(A) = false
and v(D) = true.
• Let D = µ(¬QR
11 ∨...∨¬QR
1m1(R) ∨QR
2m). If for all i = 1,...,mR
1 µ(QR
1i) ∈As then
µ(QR
2m) is also in As, therefore v(µ(QR
2m)) = true and v(D) = true, otherwise
there is i, 1 ≤i ≤m1(R) with µ(QR
1i) /∈As and v(D) is still equal to true.
Construction of the sequence (Hn,ρn,Rn,πn)
H0 = F and ρ0 = ρ.
For all n = 0,...,s −1 let us consider the clause µ(¬QR
11 ∨... ∨¬QR
1m1(R) ∨QR
2m)
used for building An+1 from An, then Rn = R and µn = µ.
There is a homomorphism π from hypothesis H of R to Hn such that µ(term(c)) =
ρn(term(π(c))) for any c concept node in H. Let πn = π.
Hn+1 = (Rn,πn)Hn, and any variable yRn
i
associated with the generic concept nodes
in the conclusion of Rn is renamed yn
i in order to use different variables for different
nodes (a rule can be used several times).
ρn+1 =
ρn ∪{(yn
1, f R
1 (µn(xR
1),...,µn(xR
l1(R)))),...,(yn
l2(R), f R
l2(R)(µn(xR
1),...,µn(xR
l1(R))))}.
Let C′(Φ(Hn)) = {ρn(B) | B ∈atoms(Φ(Hn))}. Then, one shows by recurrence on
n that: An = Aug(C′(Φ(Hn))) and ρn ∈Sub(U).
This ensures that if n < n0, then πn exists by Property 4.6, and therefore Hn+1 can
be constructed.
For n = 0, one has A0 = Aug(C(Φ(F))) = Aug(C′(Φ(H0))) and ρ0 = ρ ∈Sub(U).
Let us assume that the sequence is constructed until n and that An = Aug(C′(Φ(Hn)))
and ρn ∈Sub(U). Let us consider n+1.
An+1 = An ∪Aug({µn(QR
2i) | i = 1,...,m2(R)}
= Aug(C′(Φ(Hn)))∪Aug({µn(QR
2i) | i = 1,...,m2(R)}
= Aug(C′(Φ(Hn))∪{µn(QR
2i) | i = 1,...,m2(R)})
Lemma 10.2 proved hereafter gives
{ρn+1(B) | B ∈atoms(Φ((Rn,πn)Hn))} =C′(Φ(Hn))∪{µn(QR
2i) | i = 1,...,m2(R)}
then An+1 = Aug({ρn+1(B) | B ∈atoms(Φ((Rn,πn)Hn))}
and An+1 = Aug({ρn+1(B) | B ∈atoms(Φ(Hn+1))} = Aug(C′(Φ(Hn+1))).
It remains to show that for any n ≥0 one has ρn ∈Sub(U). ρ0 = ρ. Thus the
property holds for n = 0. Let us assume that ρn ∈Sub(U), and let us consider n+1.
The terms associated with the generic concept nodes in Hn are pairwise disjoint and
are not in I since ρn ∈Sub(U). The terms associated with the generic concepts ofCR,
which are not connection nodes, are f R
1 (µn(xR
1),...,µn(xR
l1(R))),..., f R
l2(R)(µn(xR
1),
..., µn(xR
l1(R))). They are pairwise disjoint and are not in I. Let us show that if (z,t) ∈
ρn, then t is not equal to a f R
i (µn(xR
1),...,µn(xR
l1(R))). Indeed, otherwise a clause

10.3 Backward Chaining
291
µn(¬QR
11 ∨...∨¬QR
1m1(R) ∨QR
2m) would have been chosen before in the construction
of the sequence An, and this is impossible.
⊓⊔
Lemma 10.2. Let:
• Φ(F) = ∃z1 ...zl(F)(P1 ∧...Pn(F)),
• ρ = {(z1,t1),...,(zl(F),tl(F))} where all ti-s are in Sub(U) (the ti-s are thus in
bijection with the generic concept nodes in F),
• C′(Φ(F)) = {ρ(Pi) | i = 1,...,n(F)},
• R be a rule (H,C) with Φ(R) = ∀x1 ...∀xR
q(∀xq+1 ...∀xl1Q11 ∧...∧QR
1m1 →
∃y1 ...yR
l2Q21 ∧...∧Q2m2)
C(Φ(R)) = m′
2
i=1(¬Q11(x1,...,xl1)∨...∨¬Q1m1(x1,...,xl1)
∨Q2i(x1,...,xl1, f1(x1,...,xl1),..., fl2(x1,...,xl1))),
• π be a homomorphism from the hypothesis of R to F and µ, such that: For any
concept node c in H, µ(term(c)) = ρ(term(π(c))) and ∀m = 1,...,m1 one has
µ(Q1m) ∈Aug(C′(Φ(F))),
• λ be the substitution λ = ρ ∪µ′ where µ′ = {(y1, f1(µ(x1),...,µ(xl1))),...,
(yl2, fl2(µ(x1),...,µ(xl1)))}.
Then, {λ(A) | A ∈atoms(Φ((R,π)F))} = C′(Φ(F))∪{µ(Q2i) | i = 1,...,m′
2}.
Proof. Let A be an atom of Φ((R,π)F). If A is associated with a node of F then
λ(A) = ρ(A) ∈C′(Φ(F)). Conversely, any atom in C′(Φ(F)) is equal to a λ(A).
Let A be associated with a concept node c in C which is not a connection node.
If c is an individual node with marker i and type t, then λ(A) = t(i), and there is
j ∈{1,...,m′
2} with Q2 j = t(i) = µ(Q2 j). If c is a generic concept node having type
t and with yj as its variable, then λ(A) = t(f j(µ(x1),...,µ(xl1))) which is equal to
µ(Q′), where Q′ is the atom Q2 j associated with c.
Let A be associated with a relation node r in C. Let us consider an argument
u of A. If it corresponds to a concept node which is not a connection node then
λ(u) = µ(u). Otherwise it is equal to a connection node c2 j. λ(u) = ρ(term(π(cj)))
and µ(xj) is precisely equal to ρ(term(π(cj))). Finally, one can check that any
µ(Q2i) for i = 1,...,m′
2 is equal to a λ(A) and thus:
{λ(A) | A ∈atoms(Φ((R,π)F))} = C′(Φ(F))∪{µ(Q2i) | i = 1,...,m′
2}.
⊓⊔
10.3 Backward Chaining
We describe a backward chaining mechanism for bicolored rules in this section.
Moreover, it is assumed that every individual marker always occurs with the same
concept type in concept nodes. As a consequence of these restrictions, a rule appli-
cation to a fact F never restricts labels of existing concept nodes in F (either directly,
or indirectly in the normalization step). Its sole effect is to add new nodes. The back-
ward mechanism detailed in this section is based on a graph notion, that of a piece,

292
10 Rules
which is strongly related to this property. To take general λ-rules into account, the
piece notion as well as the uniﬁcation notion would have to be extended, which has
not yet been done. The above restrictions do not lead to a loss of expressivity (see
the note in Sect. 10.2.2).
10.3.1 Outline of the Backward Chaining Mechanism
The global backward mechanism relies on the same ideas as the classical goal res-
olution, as performed by Prolog for instance. It starts from the initial goal Q. An
elementary step consists of ﬁrst determining a part of the current goal Q that could
possibly be obtained by a rule R: If there is such a part, say q, a “uniﬁcation” of q
and the conclusion of R is computed. Secondly, a new goal is built from Q, say Q′,
by deleting q and adding the hypothesis of R. Q is said to be “erased” by Q′. Q′ is
such that, if one applies R to Q′, a specialization of Q is obtained. In other words, if
Q′ is proven to be deducible from the KB, so is Q. A fact is considered as a rule with
an empty hypothesis. It allows us to delete part of the current goal without adding a
new part to prove. The process ends successfully if the last produced goal is empty
(and, in this case, the last operation is a uniﬁcation of the entire goal with a fact).
Let us illustrate the global process of backward chaining on a very simple exam-
ple pictured in Fig. 10.13. The knowledge base is composed of a fact F and a rule
R = H ⇒C (pictured as a λ-rule). Q is the goal. Q is a consequence of the knowl-
edge base since a specialization of Q can be obtained by one application of R to F
(see previous Fig. 10.8: an application of R = R2 to F yields F′ which answers Q).
To proceed backward, a naive idea could be to check if there is a homomorphism
from the goal, or part of the goal, to the conclusion of the rule; if yes, this part of the
goal could be replaced by the hypothesis of the rule (according to the idea that, if the
hypothesis is proven, then a specialization of Q is obtained by applying the rule).
However, homomorphism is not sufﬁcient (indeed, check that there is no homomor-
phism from Q to C). We have to look for a uniﬁer of Q and C, which uniﬁes part of Q
and part of C; more speciﬁcally, this uniﬁer deﬁnes specializations of Q and C with
respect to a compatible pair of C-partitions (cf. Deﬁnition 8.12) on subsets of the
concept node sets in Q and C. Here we consider ({c1},{c2}) for Q and ({c6},{c7})
for C; c1 is thus associated with c6 and c2 with c7. The greatest lower bound of the
labels of c1 and c6 is (Man,John); for c2 and c7, it is (Person,∗); this compatible
pair of C-partitions leads to specializations of C and of Q, which in this example
are the same: See u(C) = u(Q) in Fig. 10.13 (the name u is used for “uniﬁer”). It
remains to prove the hypothesis H of R, and more precisely to prove a specialization
H′ of H according to the uniﬁer: See H′ in Fig. 10.13, which is obtained from H
by specializing the label of c3 into (Man,John). It is the new goal Q′; there are two
uniﬁers of Q′ and F. The ﬁrst one associates c5 in Q′ with c10 in F: Their labels are
restricted to (Painter : P); the second one associates c5 in Q′ with c11 in F and no
label restriction has to be done. In both cases, Q′ is completely proven by F: Since
F is a rule without hypothesis, the new goal is replaced by the empty graph in both

10.3 Backward Chaining
293
cases, which yields two proofs that Q can be deduced from the knowledge base. In
general, backward chaining involves more complex operations. Namely, uniﬁcation
does not consider a whole goal but a part of it, and the kind of specialization per-
formed may be based on a more complex compatible pair of C-partitions, where
classes are not restricted to just a single node, and thus may lead to the merging of
concept nodes of the same graph.
u(C)=u(Q)
H’=Q’
F
R
Q
hasBrother
hasBrother
hasBrother
hasBrother
Man:John
2
1
hasUncle
Man:John
2
1
hasUncle
Person:*x
Person:*y
hasParent
Person
2
1
2
1
c1
c2
c5
Entity
then
c6
c7
c3
c4
if
1
2
Man:John
hasFather
Man
1
2
Painter:P
1
2
Person
admires
1
2
c8
c9
c10
c11
Person
hasUncle
Person:*y
Person:*x
1
2
1
2
Person
hasParent
Man:John
Person
c3
c4
c5
Fig. 10.13 A simple example of backward chaining
The differences between the graph backward mechanism and classical goal res-
olution come from the structure of graph rules, which is more complex than the
structure of deﬁnite clauses, since the conclusion can be any BG and may contain
new generic nodes. The mechanism exploits the graph structure of rules and goals,
and tries to process subgraphs as large as possible without decomposing them into
simpler structures. It relies on the notion of a piece, which is a subgraph of a rule
conclusion (cf. Deﬁnition 8.22 for a general deﬁnition of a piece). A cut point of a
rule conclusion C is either a frontier node or an individual node (that is not shared
with the hypothesis). The pieces of C are deﬁned by its cut points: Two nodes in C
belong to the same piece if there is a path between them that does not go through a
cut point.
The idea behind the piece notion is that it represents a “unit of knowledge”
brought by a rule application. More precisely, each rule R with k pieces in its con-
clusion can be decomposed into an equivalent set of k rules, each with the same

294
10 Rules
hypothesis as R, and a conclusion composed of a single piece. The conclusions of
these rules cannot be further decomposed while keeping the semantics of R. A rule
application to a fact necessarily adds at least one piece to this fact. In backward
chaining, the uniﬁcation between a goal and a rule is thus guided by the pieces of
the rule conclusion, and a uniﬁcation is eligible only if part of the goal correspond-
ing to a piece uniﬁes with an entire piece of the rule conclusion (otherwise this
uniﬁcation would be useless). Thus, the goal is erased by subgraphs corresponding
to pieces.
10.3.2 Piece Resolution
Following our main thread (i.e., the maximal use of graph theoretical notions), in-
stead of splitting the goal into trivial subgraphs (stars) composed of one relation
and its arguments and erasing each of them, subgraphs as large as possible which
can be processed as a whole are determined. Such subgraphs are pieces (cf. Deﬁni-
tion 8.22), whose deﬁnition is reviewed hereafter.
Deﬁnition 10.8 (Rule cut points and conclusion pieces). Let R = H ⇒C be a
rule.
1. A cut point in H is a frontier node.
2. A cut point in C is either a frontier node or an individual concept node in C that
is not shared with H.
3. The pieces of C are deﬁned with respect to the cut points in C.
Two nodes of C belong to the same piece if and only if there is a path between
them that does not go through any cut point (however, a cut point can be an extremity
of such a path). In particular, the arguments of a relation node belong to the same
piece. If C has no cut point, it is itself a piece. Since a fact is a rule without a frontier
node, its pieces are determined by its individual concept nodes.
In the rule R in Fig. 10.13 (pictured as a λ-rule), the cut points are the con-
nection nodes, and the hypothesis as well as the conclusion have only one piece.
Figure 10.14 presents a more complex rule (pictured as a bicolored rule). The cut
points of the hypothesis H are the frontier nodes a and b, the cut points of the con-
clusion C are a, b and the individual node e; H has one piece, and C has four pieces
denoted P1, P2, P3 and P4.
The following notion of a uniﬁer determines part of the current goal Q that could
be answered by an application of a rule R (i.e., a part that could be mapped to a fact
obtained by an application of R). As a rule application may involve merging sev-
eral nodes of C and specializing their labels, one looks for a homomorphism from
a subgraph of Q to a specialization of C, but not to C itself, with this specialization
concerning the cut points of C. This homomorphism determines “pieces” in Q: The
cut points of Q are the nodes mapped to cut points of C. Moreover, this homomor-
phism has to map at least one piece of Q. Otherwise the uniﬁcation would be useless
for the backward proof, as previously explained.

10.3 Backward Chaining
295
P2
P4
c
a
P1
P3
t
t:m
e
b
e
t
a
d
t
t
c
b
t
t
t
t
b
a
d
t
t
b
t
t:m
e
t:m
Fig. 10.14 Cut points and pieces of a rule
The following deﬁnitions use several notions introduced in Chap. 8, i.e., spe-
cialization of a graph with respect to a compatible pair of C-partitions (cf. Deﬁni-
tion 8.13) and join of two graphs with respect to a compatible pair of C-partitions
(cf. Deﬁnition 8.14).
Deﬁnition 10.9 (Uniﬁer). Let Q be a goal and R = H ⇒C be a rule. A uniﬁer
u(Q,R) of Q and R is a triple (PC,PQ,πu) such that:
• PC = (p1
1 ... p1
k) and PQ = (p2
1 ... p2
k) is a (possibly empty) compatible pair of C-
partitions of a subset C′ of cut points of C and a subset C′′ of concept nodes of Q
respectively; let u(C) = s(C,PQ,PC) denote the specialization of C with respect
to these partitions (if PC and PQ are empty, u(C) = C);
• let us call cut points of Q the concept nodes of C′′,
• πu is a homomorphism from a subgraph of Q to u(C), which satisﬁes the follow-
ing conditions:
1. it maps at least one piece of Q to u(C) (only entirely mapped pieces of Q will
be of interest in the backward chaining),
2. it maps all concept nodes appearing in PQ to their corresponding node in u(C):
each concept node in a class p1
i of PQ is mapped to the concept node of u(C)
built from p2
i in PC.
As pointed out in the above deﬁnition, the partitions PC and PQ may be empty.
Assuming that Q is connected, this is the case when πu is a homomorphism from the
whole Q to the conclusion C, such that no concept node of Q is mapped to a cut point
of C. This implies in particular that Q has no individual concept node (otherwise this
node would be mapped to an individual concept node in C, which would be a cut
point).

296
10 Rules
If R is a fact, its cut points are its individual concept nodes, and the label of
these cut points cannot be restricted in u(C) (because of the unique type assumption
on individual markers). In the previous deﬁnition, u(C) is thus obtained from C by
merging individual concept nodes with the same label, i.e., u(C) is a generalization
(or is equal to) the normal form of C. Hence, the following property holds true:
Property 10.3. Let R = ε ⇒C be a rule with an empty hypothesis (i.e., a fact),
Q a goal and u(Q,R) = (PC,PQ,πu) a uniﬁer of Q and R. Then, πu is a coref-
homomorphism from a subBG of Q to C; thus, it yields a homomorphism from
a subBG of Q to the normal form of C.
Let Q be a goal and R be a rule with conclusion C. A backward application of R
to Q can be done if there is a uniﬁer u(Q,R) of Q and R. Roughly said, a new goal
Q′ is built by removing the part of Q that has been uniﬁed with the conclusion of R
and adding the hypothesis of R, which has been specialized according to the uniﬁer.
Deﬁnition 10.10 (Backward chaining elementary step). Given a uniﬁer u(Q,R =
H ⇒C) = (PC,PQ,πu), Q is replaced by Q′ which is built as follows:
1. Build u(Q) = s(Q,PQ,PC) the specialization of Q with respect to PQ and PC; the
cut points of u(Q) are nodes coming from the cut points of Q, and the pieces
of u(Q) are deﬁned by its cut points (thus, they correspond to the pieces of Q
specialized on their cut points);
2. build u(Q)′ by removing from u(Q) the pieces mapped by πu to u(C), except for
the concept nodes whose removal would lead to a subgraph that is not a correct
BG: For all piece p of Q mapped by πu, ﬁrst remove from u(Q) all the relation
nodes of p and all concept nodes of p that are not cut points in u(Q); then remove
a cut point of p only if all pieces it belongs to are removed;
3. let P′
C be obtained from PC by removing the classes containing an individual
node not shared with H (this node does not belong to the frontier of the rule);
let P′
Q = (p2′
1 ... p2′
l ) be obtained from PQ by removing the classes corresponding
to suppressed classes of PC (P′
Q and P′
C thus constitute a compatible pair of C-
partitions); let P′
H = (p3
1 ... p3
l ) be the partition on a subset of the cut points of
H built in a similar way: Let C′
H be the subset of cut points in H (i.e., frontier
nodes) that appear in P′
C; P′
H is the partition of C′
H induced by P′
C: Two nodes of
C′
H are in the same class if and only if their corresponding nodes in C are in the
same class of P′
C (P′
H and P′
Q constitute a compatible pair of C-partitions);
4. build u(H) = s(H,P′
Q,P′
H) the specialization of H with respect to P′
Q and P′
H;
5. join u(Q)′ and u(H) with respect to P′
H and P′
Q. We obtain Q′.
The possible introduction of new individuals in the conclusion of the rule implies
special steps. The removal of parts of Q that unify with C is performed according to
the partition PC on some cut points in C. If these cut points contain individuals not
shared with H, the corresponding classes in the partitions PC and PQ are suppressed,
yielding P′
C and P′
Q. The partition P′
H is computed with respect to P′
C (or equivalently
to P′
Q) and not to PC (or PQ). The new goal is obtained by joining the remaining

10.3 Backward Chaining
297
part of Q and hypothesis H according to P′
H and P′
Q. Step 3 is thus needed only if C
introduces new individuals. Otherwise, in step 4, P′
Q = PQ and P′
H = PH.
If R is a fact, steps 3 and 4 are not needed. Indeed, PC is composed of individ-
ual concept nodes; step 3 computes empty P′
C and P′
H. As H is empty, so is u(H).
Finally Q′ = u(Q)′, which has been computed at step 2. The following property is
immediate:
Property 10.4. The graph Q′, produced by a backward chaining elementary step
with a uniﬁer u(Q,R = H ⇒C), is empty if and only if R is a fact (i.e., H is empty)
and there is a homomorphism from Q to u(C) (thus to the normal form of C).
Deﬁnition 10.11 (Piece resolution).
Let K = (F,R) be a KB, where F is a set of facts and R a set of rules, and let Q
be a BG. A piece resolution of Q in K is a sequence Q = Q0,Q1 ...Qp, p ≥0 such
that for all 1 ≤i ≤p, Qi is obtained by a backward chaining elementary step with
a uniﬁer u(Qi−1,R), where R ∈R∪{F}. The piece resolution ends successfully if
Qp = ∅(and in this case u(Qp−1,R) is such that R = F).
Note that the knowledge base does not need not to be in normal form. How-
ever, if it is in normal form, the uniﬁcation with facts can be performed more efﬁ-
ciently because it is based on a homomorphism instead of a coref-homomorphism
(cf. Proposition 10.3).
Example. Figure 10.15 shows a rule R (that was already used in the rule ap-
plication example of Fig. 10.7), part of a fact F, and a goal Q (which can be
read as: “Does B possess a vehicle, does she/he get a salary and who decides
it?”) Let Q be the initial goal. Q is uniﬁed with R by (PC,PQ,πu), where PC =
({c1},{c2}), PQ = ({c4},{c6}); u(C) is obtained from C by restricting the label
of c4 to (Person : B); let us keep the same names for the nodes in u(C) as in C; πu =
{(c4,c1),(c5,c2),(c6,c3),(r3,r1),(r4,r2)}. The new goal is Q′. Q′ is uniﬁed with F
by (PC,PQ′,πu), where PC = ({c,d}), PQ′ = ({c7,c8}); let e be the node of u(C)
obtained by merging c and d. πu = {(c6,a),(c7,e),(c8,e),(c9,b),(r5,r8),(r6,r8),
(r7,r9)}. See that πu is a homomorphism from Q′ to norm(F). The empty goal is
obtained.
A backward chaining scheme is presented in Table 26. It maintains a set, called
Uniﬁers, of all not yet applied uniﬁers . At each step (i.e., an iteration of the “while
true” loop), it computes uniﬁcations for the current goal and adds them to Uniﬁers. If
Uniﬁers is empty, it returns false (there is no successful resolution). Otherwise, it re-
moves an element in Uniﬁers and performs the corresponding elementary backward
chaining step. If the obtained goal is empty, it returns true (a successful derivation
has been built). Whereas the forward chaining scheme presented in Table 25 builds
derivations by a breadth-ﬁrst exploration of the graph space, no exploration strategy
is imposed here. Backward chaining algorithms usually try to reconstruct deriva-
tions in a depth-ﬁrst manner, with the objective being to decide quicker when the
answer is yes. However, the price to pay is that the algorithm may enter into an
inﬁnite resolution sequence without being able to try others. The strategy is deter-
mined by the way of managing the set Uniﬁers. If it is managed as a stack, we have

298
10 Rules
Salary
Person
Person
manager
employee
Company
get
decide
employee
manager
Company
decide
get
Person
Person :B 
Plane
possess
Vehicle
Person : B
manager
Person : B 
possess
CarBuilder
F
Vehicle
possess
Salary
Q
R
Person :B 
Person
Q’
c2
c1
c3
r1
r2
c6
c4
c5
r3
r4
c6
r5
r6
r7
c8
c7
c9
r8
b
c
a
d
r9
Fig. 10.15 Piece resolution
a depth-ﬁrst exploration. If it is managed as a queue, we have a breadth-ﬁrst explo-
ration, which ensures that no resolution is missed (this guarantees that the algorithm
returns true if Q can be deduced), but it will likely be slower.
10.3.3 Soundness and Completeness of Backward Chaining
The following result is obtained:
Theorem 10.2 (Backward chaining soundness and completeness). Let K=(F,R)
be a KB, where F is a set of facts (not necessarily in normal form) and R a set of
rules, and let Q be a BG. There is a piece resolution of Q that ends successfullyif
and only if Φ(K) ⊨Φ(Q) (where Φ(K) = Φ(V)∪Φ(R)∪Φ(F).

10.3 Backward Chaining
299
Algorithm 26: BackwardChaining
Input: a knowledge base K = (F, R), and a BG Q
Output: true, false or inﬁnite calculus; if true, then Q can be deduced from K and if false,
then Q cannot be deduced from K
begin
Uniﬁers ←∅
while true do
forall R ∈R∪{F} do
forall uniﬁer u(Q,R) do
Uniﬁers ←Uniﬁers ∪u(Q,R)
if Uniﬁers = ∅then
return false
u(Q,R) ←remove an element from Uniﬁers
Q′ ←elementary backward chaining step from Q according to u(Q,R)
if Q′ is the empty graph then
return true
Q ←Q′
end
The soundness and completeness are not proven directly, but rely on the sound-
ness and completeness of the forward chaining: It is shown that Q and R unify, pro-
ducing the new goal Q′, if and only if there is an application of R to Q′ that produces
a specialization of Q. Then, if Q is not the empty graph, and considering that rules in
R have a non-empty hypothesis, a piece resolution of Q that ends successfully nec-
essarily uses F in the end. Let us consider a piece resolution in which F is uniﬁed
with Qp−1 to produce the empty graph Qp , and let Ri0 ...Rip−2 be the rules (in-
cluding facts) used to produce Q1 ...Qp−1. Then there is a derivation sequence that
applies the rules in reverse order, Rip−2 ...Ri0, to F and produces a graph to which
Q can be mapped. Reciprocally, a subsequence can be extracted from a derivation
sequence, from which a piece resolution can be built by considering the rule appli-
cations in reverse order.
Let us now give the main steps of the proof by decomposing it into several lem-
mas.
Lemma 10.3. Let Q be a goal and R = H ⇒C be a rule (possibly with an empty
hypothesis). Let Q′ be obtained by a backward chaining elementary step with a
uniﬁer u(Q,R). Then R can be applied to Q′ to produce a specialization of Q.
Proof. Since H ⪰u(H) and u(H) ⪰Q′, there is a homomorphism from H to Q′, say
π1. π1 can be chosen such that, for each concept node c in H, if c is in a class P3
i of
P′
H, π1(c) is the node obtained from P3
i , otherwise π1(c) is the same node in Q′. Let
Q1 = (R,π1)Q′ be the graph obtained by applying R to Q′. The following mapping
from the nodes in Q to the nodes in Q1 is a homomorphism, say π, from Q to Q1:
For all nodes x, if x belongs to u(Q)′, then π(x) is the corresponding node in Q1
(either the node itself, or the node obtained from its class in PQ if x is a cut point in
PQ that belongs to at least a non-erased piece of Q); otherwise, x is a node in Q that

300
10 Rules
has been erased: Then, x belongs to an erased piece of Q, and we take π(x) = πu(x)
(x is thus mapped to a node in C).
⊓⊔
Lemma 10.4. Let K = (F,R) be a KB, where F is a set of facts and R a set of
rules, and let Q be a BG. If there is a piece resolution of Q that ends successfully
then there is an R-derivation from norm(F) ending with a BG G′ such that G′ is a
specialization of Q.
Proof. By induction on the number of uniﬁcations. If the resolution has one step,
the property is true: There is a homomorphism from Q to norm(F), thus a deriva-
tion F0 = F. Assume this is true for any 1 ≤p < n. Let us consider a successful
piece resolution of length n. The ﬁrst step uniﬁes Q with a conclusion C producing
Q′. With the derivation from Q′ being of length strictly less than n, the induction
hypothesis can be applied: There is an associated rule derivation leading from F to
a G′ to which Q′ can be mapped. Let πQ′ be a homomorphism from Q′ to G′. By
applying the rule R = H ⇒C of the ﬁrst step to Q′ as in Lemma 10.3, one would
obtain a specialization of Q. Let πH be a homomorphism from H to Q′. Let πQ be a
homomorphism from Q to (R,πH)Q′. R can be applied to G′ by the homomorphism
πQ′ ◦πH. Let G′′ be the graph produced. G′′ is obtained from F by an R-derivation.
Check that Q can be mapped to G′′ by the following homomorphism π: For all
nodes x in Q, if πQ(x) comes from a node y in Q′ then π(x) = πQ′(y); otherwise,
π(x) is the node coming from C corresponding to πQ(x).
⊓⊔
Corollary 10.1. Backward chaining is sound.
Proof. From Lemma 10.4 and the soundness of forward chaining (Theorem 10.1).
Lemma 10.5. Let Q be a goal, R = H ⇒C be a rule with a non-empty hypothesis,
and let G be a BG to which R can be applied, producing G′. If there is a homomor-
phism from Q to G′ such that at least one node in Q is mapped to a concept node
of G′ that does not come from G, then there is a piece uniﬁcation of Q and R that
produces a goal Q′ with Q′ ⪰G.
Proof. Let πH be the homomorphism from H to G used in the rule application.
Let π be a homomorphism from Q to G′ that satisﬁes the condition. Let πu be
obtained from π by restricting its domain to the part of Q mapped to the subgraph
of G′ coming from C. A uniﬁer u(Q,R) = (PC,PQ,πu) can be built, where: PQ is
the partition of the set of nodes x which are in the domain of πu such that πu(x) is
a either a πH(y) (i.e., it corresponds to a frontier node of the rule) or an individual
node coming from C; two nodes are in the same class of the partition if and only
if they have the same image by πu; PC is the compatible partition of the subset of
cut points in C corresponding to nodes in G′ that are images of nodes in PQ. There
is a bijection from PQ to PC, which maps a class in PQ whose nodes are mapped
to a node z by πu, to the class in PC, whose nodes are mapped to z by the rule
application. Let us now check that πu maps pieces of Q. By deﬁnition of u(Q,R)
and of cut points, if, for a node x in a piece of Q, πu(x) is in C, then all nodes of
this piece are mapped by πu to C. By hypothesis, there is at least such a node x,

10.4 Computational Complexity of FR-DEDUCTION with Rules
301
thus at least a piece of Q is mapped to C by πu. Let Q′ be the graph obtained with
u(Q,R). There is a homomorphism π′ from Q′ to G built as follows. For each node
x coming from u(Q), π′(x) = π(x). For each node y coming from u(H), its image is
π′(x) = πH(x). If a node comes from both u(Q) and u(H), we have π(x) = πH(x),
hence π′ is a homomorphism from Q′ to G.
⊓⊔
Lemma 10.6. Let K = (F,R) be a KB, where F is a set of facts and R a set of rules,
and let Q be a BG. If there is a derivation from F to F′, a specialization of Q, then
there is a piece resolution of Q that ends successfully.
Proof. By induction of the length of the derivation. The property is true for a deriva-
tion of length 0: If Q can be mapped to F by a homomorphism π, then an elementary
backward chaining step with a uniﬁer built on πu = π produces the empty graph. As-
sume the property is true for any 1 ≤p < n. Let us consider a derivation of length
n: F0 = F,...,Fn = F′. Let π be a homomorphism from Q to Fn and let R = H ⇒C
be the rule applied to go from Fn−1 to Fn. If π(Q) is entirely contained in the sub-
graph of Fn coming from Fn−1, then π yields a homomorphism from Q to Fn−1 and,
by induction hypothesis, there is a successful piece resolution of Q associated with
the derivation F0 = F,...,Fn−1. In this case, the rule application leading from Fn to
Fn−1 is useless to deduce Q. Otherwise, by Lemma 10.5, there is a piece uniﬁcation
of Q and R producing Q′ ⪰Fn−1. By induction hypothesis, there is a successful
piece resolution of Q′ associated with the derivation F0 = F,...,Fn−1; there is thus a
successful piece resolution of Q.
⊓⊔
Corollary 10.2. Backward chaining is complete.
Proof. From Lemma 10.6 and the completeness of forward chaining (Theorem 10.1).
⊓⊔
Corollaries 10.1 and 10.2 prove the theorem.
No mechanism is better than another in the general case. Backward chaining is
much more complex to implement than forward chaining. It is interesting to note
that the rule base can be compiled in such way that forward chaining can be guided
by the goal in the same way as backward chaining (Sect. 10.4.2.2).
10.4 Computational Complexity of FR-DEDUCTION with Rules
10.4.1 Semi-Decidability of FR-DEDUCTION with Rules
In the example of Fig. 10.8, all R-derivations from F are ﬁnite. But it is not true in
general. More precisely, let K = (F, R) be a KB, where F is a set of facts and R is
a set of rules, and let Q be a goal. If the answer to the question “Is Q deducible from
K” is positive, the forward chaining algorithm (Table 25) will produce a specializa-
tion of Q after a ﬁnite number of rule applications. But if the answer is no, there is

302
10 Rules
no guarantee that the algorithm will ever stop. And no algorithm can be guaranteed
to stop in all cases: Indeed, FR-DEDUCTION is undecidable. More precisely, it is
semi-decidable as we will show it in this section: An answer can be computed in ﬁ-
nite time for all positive instances of FR-DEDUCTION but not for all negative ones.
Thus, there is no chance to ﬁnd an algorithm that always stops when the answer is
no.
We have an algorithm that runs in ﬁnite time if Q is deducible from K (see
Table 25). Thus, to prove the semi-decidability of FR-DEDUCTION, we only have
to exhibit a reduction from a problem known to be semi-decidable. Several such
reductions have been exhibited (see bibliographical notes for details). Here we give
a reduction from word problem in a semi-thue system. The proof is interesting in
itself since it proves that, even when rules are of the form “if path p1 then path p2,”
where p1 and p2 share origin and extremity, the problem remains semi-decidable.
Property 10.5. FR-DEDUCTION is semi-decidable.
Proof. When the answer to the problem is “yes,” a breadth-ﬁrst search of the tree
of all derivations from K provides the answer in ﬁnite time (Table 25). Let us prove
that FR-DEDUCTION is not decidable with a reduction from the WORD PROBLEM
IN A SEMI-THUE SYSTEM, which is expressed as follows: Given the two words m
and m′ and Γ = {g1,...,gk} a set of rules, with each rule gi being a pair of words
(αi,βi), the question is whether there is a derivation from m to m′. There is an
immediate derivation from m to m′ (we note m →m′) if, for some gj, m = m1αjm2
and m′ = m1β jm2. A derivation from m to m′ (we note m ; m′) is a sequence
m = m0 →m1 →... →mp = m′.
G(m)
T
U(g)
s
s
s
xk
s
E
s
s
y1
z1
s
s
s
s
s
s
x1
B
yp
T
zq
Fig. 10.16 Transformation from the WORD PROBLEM into FR-DEDUCTION
Let (m,m′,Γ = {g1,...,gk}) be an instance of the previous word problem. A
concept type xi is assigned to each letter xi. There are three other concept types:
B (for “begin”), E (for “end”) and ⊤(for “anything”). ⊤is the greatest concept
type and all other types are pairwise incomparable. There is one relation type s
(for “has successor”). BG G(m) is assigned to any word m = x1 ...xk, and the rule
U(g) is assigned to any rule g = (y1 ...yp, z1 ...zq), as represented in Fig. 10.16.
Let U(Γ ) = {U(g1),...,U(gk)}. By a straightforward proof (a recurrence on the
smallest derivation length), we obtain that to every path from the node typed B to the
node typed E (“begin” to “end”) in a BG derived from (G(m),U(Γ )), corresponds a
word (and not a subword) derivable from m, and reciprocally. It follows that m ; m′
if and only if G(m′) is deducible from (G(m),U(Γ )).
⊓⊔

10.4 Computational Complexity of FR-DEDUCTION with Rules
303
FR-DEDUCTION is not only semi-decidable, it is a computation model, as can be
proven by a reduction from the halting problem of a Turing machine. This reduction
indeed shows that every Turing machine can be simulated by the forward chaining
mechanism. The knowledge base built in the proof has only one rule, which proves
that FR-DEDUCTION remains non-decidable even with one rule (see the biblio-
graphical notes).
10.4.2 Decidable Cases
Let us now summarize the results on decidable cases.
10.4.2.1 Finite Expansion Rule Sets
In what follows, we assume that the rule application mechanism prevents the gen-
eration of trivial redundancies: A rule is never applied twice according to the same
homomorphism from its hypothesis to a fact, and the generation of twin relation
nodes is avoided (cf. Sect. 10.2.3).
Let us say that an irredundant graph H is full with respect to a set of rules R if
every graph that can be obtained by applying one of these rules to H is equivalent to
H. In other words, no rule application can bring new information to the graph. As-
suming that F is an irredundant graph and that graphs obtained by a rule application
are put into irredundant form, if a full graph can be derived from F then it is unique
(up to isomorphism).
A weaker stopping condition for forward chaining, with F and a set of rules
R, can be to stop when a graph is obtained to which no rule can be applied in an
original way (i.e., all possible rule applications have been performed). We call it
a closed graph. More formally, F′ is closed with respect to R and with respect to
an R-derivation F0(= F),...,Fk(= F′) where Fi (1 ≤i ≤k) is the graph obtained
by application of a rule of R to Fi−1 according to a homomorphism πi, if for ev-
ery rule R = H ⇒C of R, for every homomorphism π from H into F′, there is a
homomorphism πi from H to Fi−1 (1 ≤i ≤k), such that π = πi.
Given a set of rules R and a graph F, if a closed graph is R-derivable from F,
then it is unique (up to isomorphism). Moreover, if this graph is derivable with n rule
applications, then n is the maximal length of an R-derivation, and all derivations of
length n lead to it. When it exists, we call it the closure of F with respect to R,
which we denote F∗
R.
If the closure of F exists, its irredundant form is equivalent to the full graph of F.
However, there are cases where the full graph exists but not the closure. Consider,
for instance, a bicolored rule “if H then C” without frontier node (thus H and C are
disconnected), and such that C is a specialization of H. Applying the rule to a fact
consists in adding a new connected component C to this fact. Let F′ be the graph
obtained after the ﬁrst rule application. As C is a specialization of H, the rule can

304
10 Rules
be applied once again by mapping its hypothesis to the newly added C component,
and this indeﬁnitely. All applications after the ﬁrst one produce a graph equivalent
to F′. Thus, the irredundant form of F′ is full.
Informally, the notion of a closed graph translates the fact that nothing can be
added that has not been already added, whereas the notion of a full graph says that
nothing can be added that really adds new information to the graph.
Deﬁnition 10.12 (Finite expansion set). A set of rules R is called a ﬁnite expan-
sion set if, for every BG F, there is a (ﬁnite) R-derivation F ...F′ such that the
irredundant form of F′ is full with respect to R. This full graph is denoted FR.
If R is a ﬁnite expansion set, FR-DEDUCTION becomes decidable. Indeed, in
order to determine whether a BG Q is deducible from a KB (F,R), it sufﬁces to
compute FR, then to check the existence of a homomorphism from Q to FR.
Note however that the ﬁnite expansion set property is not a necessary condition
for decidability. See for instance Fig. 10.17: The set of rules {R} is not a ﬁnite
expansion set, because each application of R leads to a new application of R. Never-
theless, FR-DEDUCTION is decidable for {R}: For any set of facts F, for any goal
Q, the answer can be given after k steps of forward chaining, where k is the maximal
number of relation nodes in a directed path of Q consisting of relations with labels
less or equal to (hasParent).
Human
hasParent
Human
R
Fig. 10.17 A non-f.e.s of rules
Let us now focus on particular cases of ﬁnite expansion set A λ-rule is said
to be range restricted if its application does not create any generic concept node.
Equivalently, its conclusion is restricted to cut points (connection nodes or individ-
ual nodes) and relation nodes. We use this expression by analogy with the so-called
rules in Datalog, where all variables of the head must appear in the body. Such rules
are also called safe in the literature. Consider for instance the rules of Fig. 10.2: R2
and R3 are range-restricted, while R1 is not.
A range restricted rule R = H ⇒C can be decomposed into an equivalent set
of rules with a conclusion restricted to at most one node outside connection nodes.
There is at most one rule for each node in the conclusion of R: For each connection
node c2i in C such that the type of c2i differs from the type of c1i, one rule with
hypothesis H and a conclusion restricted to c2i; for each individual node c in C, one
rule with hypothesis H and a conclusion restricted to c; for each relation node r, one
rule whose hypothesis is the disjoint union of H and all individual concept nodes
of the conclusion of R, and conclusion is r, with the same neighbors as in C. The
logical interpretation of such rules are (function free) range restricted Horn rules. If
a BG Q is deducible from a set of range restricted rules R, then it is deducible from
the set of their decompositions, and reciprocally.

10.4 Computational Complexity of FR-DEDUCTION with Rules
305
Note that, contrary to general ﬁnite expansion sets, the existence of the closure
and of the full graph are equivalent notions in the case of range restricted rules.
Property 10.6. A set of range restricted rules is a ﬁnite expansion set.
Proof. Since facts are maintained in normal form, an individual marker appears at
most once in them. The number of individual nodes created by the set of rules is
bounded by M = |R|×maxR∈R|CR|, where |CR| is the size of the conclusion of the
rule R. The number of relation nodes added to a graph F (no twin relation nodes
are created) is thus bounded by N = ∑k
n=1 Pn(|CF|+M)n, where Pn is the number of
relation types with a given arity n appearing in a rule conclusion, k is the greatest
arity of such a relation type and CF is the set of concept nodes in F. Hence, the
closure of a graph can be obtained with a derivation of length L ≤N +M. We thus
obtain F∗
R (or FR) in ﬁnite time.
⊓⊔
It follows from the proof of Property 10.6 that the length of a derivation from
F to F∗
R or FR is in O(nk+1), where n is the size of (F,R) and k is the great-
est arity of a relation type appearing in a rule conclusion. This rough upper bound
could be reﬁned but it is sufﬁcient to obtain the following property, which will be
used throughout the proofs of complexity results involving range restricted rules (cf.
Property 10.8 and results in Chap. 11).
Property 10.7. Under the assumption that the maximum arity of a relation type is a
constant, given a range restricted set of rules R, the length of an R-derivation from
F is polynomially related to the size of (F,R).
Property 10.8 (Complexity with range restricted rules). Under the assumption that
the maximum arity of a relation type is a constant, when R is a set of range restricted
rules, FR-DEDUCTION is NP-complete.
Another example of a ﬁnite expansion set is that of disconnected rules. A λ-rule
R = (H,C) is disconnected if its set of connection nodes is empty. Equivalently,
a bicolored rule is disconnected if its hypothesis and conclusion are disjoint. We
obtain the same complexity property as for range restricted rules: Under the as-
sumption that the maximum arity of a relation type is a constant, when R is a set of
disconnected rules, FR-DEDUCTION is NP-complete.
Finally, let us point out that the union of two ﬁnite expansion sets is not neces-
sarily a ﬁnite expansion set. Indeed, in the transformation of Proposition 10.5, each
rule can be decomposed into an equivalent set of two rules, with one of these rules
being range restricted and the other one being a disconnected rule (see bibliographic
notes). The next section will present conditions under which ﬁnite expansion sets
can be safely used together (cf. Proposition 10.10).
10.4.2.2 Conditions on the Rule Dependency Graph
The notion of a graph representing dependencies between rules of a given set is
classical in rule-based systems. The basic idea is that a rule R2 depends on a rule

306
10 Rules
R1 if there can be a fact, say F, such that an application of R1 to F leads to new
applications of R2 to the resulting fact, say F′. In other words, there are more homo-
morphisms from the hypothesis of R2 to F′ than to F. As BG rules are more complex
than classical deﬁnite clauses, the dependency notion will be more complex than in
classical rule-based systems.
Deﬁnition 10.13 (Neutral rule). Let R1 : H1 →C1 and R2 : H2 →C2 be two rules.
R1 is neutral for R2 if for every BG F on V, for every homomorphism π : H1 →F,
let F′ = (R,π)F, the set of homomorphisms from H2 to F′ is the same as the set of
homomorphisms from H2 to F. Otherwise, R2 depends on R1.
The next theorem gives an effective characterization of rule dependency. The
framework considered in this result is the same as in the backward chaining mecha-
nism (see Sect. 10.3).
Theorem 10.3. R1 : H1 →C1 and R2 : H2 →C2 be two rules on the same vocabulary,
with a non-empty hypothesis and conclusion. Then, R2 depends on R1 if and only if
H2 and R1 are uniﬁable in the sense of deﬁnition 10.9 (where H2 and R1 respectively
play the role of Q and R).
Proof: cf. the bibliographical notes.
Let R be a set of rules. The graph of rule dependencies of R, notation D(R), is
the directed graph whose nodes are the rules of R, and, for all pair of nodes (R1,R2),
there is an arc (R1,R2) if R2 depends on R1. This graph may contain loops, since a
rule may depend on itself. Facts can be integrated with D(R). By deﬁnition, a fact
does not depend on any rule, i.e., cannot have incoming arcs. We thus consider a
fact F as a rule with an empty hypothesis, and look for the rules that depend on it. A
query can be integrated as well: by deﬁnition, no rule depends on it, thus it cannot
have outgoing arcs. We thus consider a query Q as a rule with an empty conclusion
and look for the rules it depends on. To solve FR-DEDUCTION for a given Q, only
the rules which are on a path from F (where F stands for all facts) to Q are useful.
The subgraph of D(R) induced by these rules is called the simpliﬁed graph of rule
dependencies and denoted by D(R,Q).
Deciding whether a rule depends on another is an NP-complete problem (indeed
a uniﬁcation is a polynomial certiﬁcate and, for particular cases of rules, a uniﬁ-
cation is a homomorphism). Building the graph of rule dependencies thus requires
|R|2 calls to an algorithm solving an NP-complete problem. However, it has two
interests: for algorithmic efﬁciency in practice and for decidability results.
The dependency graph is costly to compute, but it can be used as a compila-
tion of the knowledge base: It is computed once, independently from solving FR-
DEDUCTION, thus the cost of its construction is not the point. Only Q has to be
classiﬁed for each use.
A simple use of the dependency graph in the forward chaining mechanism is as
follows. In the ﬁrst step, all rules that are successors of the source F in the sim-
pliﬁed dependency graph D(R,Q) are considered. Then, at step i, i > 1, the only
rules considered are those depending on a rule that has been applied at step i −1.

10.5 Bibliographic Notes
307
The dependency graph can be further used to improve forward chaining (See the
bibliographic notes for further details).
When D(R,Q) has no circuit, the number of steps is thus bounded by (l + 1)
where l is the length of a longest path in D(R). Hence the following decidability
result:
Property 10.9. If the simpliﬁed dependency graph D(R,Q) has no circuit (including
no loop), then FR-DEDUCTION is decidable.
In this case, the algorithm can be improved by considering rules according to
their level in D(R,Q): the rule level is the maximal length of a path from the source
to it. As D(R,Q) is without a circuit, the maximal length of a path is less than
the number of rules. In the ﬁrst step, the rules of level 1 are considered (thus the
successors of the source). More generally, the rules of level i are considered at step
i, i ≥1. Thus, each rule is checked only once for applicability.
Combining ﬁnite expansion sets and rule dependency leads to a stronger decid-
ability result:
Property 10.10. If each strongly connected component of the simpliﬁed dependency
graph D(R,Q) is a ﬁnite expansion set of rules, then FR-DEDUCTION is decidable.
Let us recall that two vertices x and y of a directed graph are in the same strongly
connected component if there is a path from x to y and a path from y to x. A strongly
connected component of the dependency graph represents a maximal set of rules that
mutually depend (directly or indirectly) on each other. Let C1...Cp be the strongly
connected components of the simpliﬁed dependency graph. Consider the reduced
graph corresponding to the components: there is one vertex ci for each strongly
connected component Ci, and there is an arc cicj if there is an arc from a rule in
Ci to a rule in Cj (i.e., a rule of Cj depends on a rule Ci). Associate with each ci
its level (as explained just above). The rules can be processed by levels: at step i,
each cj of level i is processed; processing the set of rules represented by cj consists
of applying these rules until the closed (or the full) graph is obtained (and it exists
because these rules form a ﬁnite expansion set).
10.5 Bibliographic Notes
The notion of a λ-BG is introduced in [Sow84] (under the name of λ-abstraction).
A CG rule is traditionally seen as a couple of basic conceptual graphs, H and C, with
co-reference links between some nodes of H and some nodes of C (e.g., [Sow84],
[GW95], [SM96]). [BGM99b, BGM99a] deﬁned rules and constraints as bicolored
basic graphs. [SM96] (see also [Sal98]) deﬁned backward chaining operations and
proved associated soundness and completeness results. Note that, albeit rules are
deﬁned as an ordered pair of basic graphs, it is compulsory in this framework that
corresponding distinguished nodes have the same type, thus these rules are equiva-
lent to bicolored rules.

308
10 Rules
Let us emphasize the originality of piece resolution. It is a really graph-based
mechanism, in the sense that it processes goals and rules by subgraphs as large
as possible, i.e., the pieces. Other resolution mechanisms known for CG rules are
more or less translated from logical resolution. To the best of our knowledge, only
one is (and has been proven) sound and complete [GW95]. In this mechanism, the
goal is split into trivial subgraphs, with each composed of one relation node and its
neighbors. Then, uniﬁcation is performed on each trivial subgraph. This mechanism
is thus very similar to classical logical resolution mechanisms, which erase the goal
one atom after another.
Note that pieces are trivial in Prolog, and in rules equivalent to deﬁnite or Horn
clauses in general. A practical comparison between piece resolution and Prolog res-
olution was made in [CS98]. More precisely, the rule and piece notions were trans-
lated into the logical framework, and a straightforward implementation of the ob-
tained piece resolution mechanism was compared to the SLD resolution of Prolog.
Skolemization was used to translate CG rules, or, more precisely from their logical
translation, into Prolog rules. The comparison showed an important gain, sometimes
huge, in the number of backtracks. One reason for this gain is obviously that part
of the backtracks made by Prolog was hidden in the piece uniﬁcation operation. But
there are other reasons. Due to the piece notion, the graph resolution mechanism
can perform uniﬁcations which are guided by the structure of the goal and rules.
Then substitutions that are not piece uniﬁcations are rejected, whereas Prolog uses
them blindly and detects a failure. Of course, if pieces have no more than one rela-
tion node, the piece mechanism is not interesting: In this case, it involves a complex
machinery for no gain at all, since uniﬁcations are the same as in Prolog.
The fact that the logical translation of a CG rule is similar to a tuple-generating
dependency (TGD) in databases was ﬁrst noted by Rousset (oral communication,
1997). Indeed, the only differences between a TGD t (expressed as a logical for-
mula, cf. for instance [AHV95]) and the formula Φ(R) associated with a rule R, are
on one hand that t may contain equality atoms, and on the other hand that Φ(R)
goes with a set of logical formulas translating the partial orders on types in the vo-
cabulary. But t can be (polynomially) transformed into an equivalent set of formulas
without equality (cf. [CS98] based on a result of [BV84]), and we can incorporate
the vocabulary in the graphs (cf. the mapping ﬂat in Chap. 5). The following impli-
cation problem for dependencies has been shown to be semi-decidable on TGDs:
given a set T of TGDs, and a TGD t, is t deducible from T? [Var84]. Coulondre and
Salvat used this result to prove that FR-DEDUCTION is semi-decidable [CS98]. Let
us give here this reduction since it is very simple. Consider an instance of the impli-
cation problem for dependencies. Replace in the TGD t each universally quantiﬁed
variable by a new constant not appearing in t and T. Let t′ be the TGD obtained.
Then t is deducible from the set T if and only if the conclusion of t′ is deducible
from T and the hypothesis of t′. Now, translating TGDs into rules (with the conclu-
sion and hypothesis of t′ being actually translated into BGs), one obtains an instance
of FR-DEDUCTION.
In his thesis [Bag01], Baget proved the semi-decidability of FR-DEDUCTION
with a reduction from the halting problem of a Turing machine, i.e., he proved that

10.5 Bibliographic Notes
309
every Turing machine can be simulated in the FR model. This proves that deduction
with rules is a computation model. The reduction given from the word problem in
a semi-thue system in the present chapter is from [BM02]. The word problem is
introduced in [Thu14] and is proven to be semi-decidable in [Pos47, reduction to
his correspondence Problem].
The complexity of deduction with rules and constraints is studied in detail in
[BM02]). Finite expansion sets are deﬁned in this paper. In particular, it is proven
that the union of two ﬁnite expansion sets is not necessarily a ﬁnite expansion set.
Decidability results concerning the graph of rule dependencies are from [Bag04].
The graph of rule dependencies is ﬁrst introduced in this paper, and studied in more
depth in [BS06]. In particular, the equivalence between the notion of rule depen-
dency and a uniﬁer (as deﬁned in the backward chaining mechanism) is proven in
this latter paper. Uses of the graph of rule dependencies to improve the efﬁciency of
forward chaining as well as backward chaining are also studied in the same paper.

Chapter 11
The BG Family: Facts, Rules and Constraints
11.1 Overview of the BG Family
In this chapter, we present a family of reasoning models which generalizes the mod-
els seen so far. The DEDUCTION problem, expressed in a generic way, takes a knowl-
edge base K and a goal Q as input, and asks whether Q can be deduced from K. De-
pending on the knowledge base composition, different models are obtained. If K is
composed of facts only, we obtain the BG (or SG) model studied in the ﬁrst chapters.
When rules are added, we obtain the model studied in the preceding chapter. Now
we will also consider graph positive and negative constraints, which introduce an-
other problem, i.e., CONSISTENCY (“Is the knowledge base consistent with respect
to the constraints?”) Deduction from inconsistent bases is forbidden. Depending on
how rules and constraints are combined, rules have different semantics and become
inference rules or evolution rules. Inference rules represent implicit knowledge and
evolution rules represent possible actions transforming factual knowledge (which is
possibly enriched by applications of inference rules). Finally, the general form of
a KB is (F,R,E,C), where F is a set of facts, R and E are respectively a set of
inference rules and a set of evolution rules, and C is a set of constraints. When C is
empty, R and E can be confused. The BG family is thus composed of the following
six models.
• The F model for K = (F, ∅, ∅, ∅), in which DEDUCTION asks if Q can be
deduced from F, i.e., if there is a homomorphism from Q to F;
• the FR model for K = (F, R, E, ∅), in which DEDUCTION asks if Q can be
deduced from (F,R∪E), i.e., if there is an R∪E-derivation from F to a BG Fk
such that Q can be deduced from Fk; as the set of constraints is empty, R and E
can be confused, hence the name of the model;
• the FC model for K = (F, ∅, ∅, C), in which DEDUCTION asks if F is consistent
with respect to C and if Q can be deduced from F;
• the FRC model for K = (F, R, ∅, C), in which DEDUCTION asks if (F, R) is
consistent with respect to C and if Q can be deduced from (F, R);
311

312
11 The BG Family: Facts, Rules and Constraints
• the FEC model for K = (F, ∅, E, C), in which DEDUCTION asks if there is an
E-derivation from F to a BG Fk, involving only consistent BGs with respect to
C, and such that Q can be deduced from Fk;
• the FREC model for K = (F, R, E, C), in which DEDUCTION asks if there is
an RE-evolution (this notion will be deﬁned later, let us just now say that it is
a particular derivation involving R and E) from F to a BG Fk, such that (1) for
each Fi in this derivation, (Fi, R) is consistent with respect to C, and (2) Q can
be deduced from (Fk, R).
The hierarchy of these models is represented in Fig. 11.1. The complexity of
the DEDUCTION problem is mentioned when it is decidable. If rules are involved,
DEDUCTION is no longer decidable, as seen in the preceding chapter. We will study
how particular cases of rules and constraints affect the decidability property and
classify the complexity of DEDUCTION when appropriate. Table 11.1 at the end of
the chapter summarizes all complexity results.
NP−complete
Semi−decidable
Undecidable
−complete
FREC
FRC
FEC
FC
FR
F
Π P
2
Fig. 11.1 The BG family
The examples in this chapter are inspired from a resource allocation problem,
where the global aim is to assign ofﬁces to persons of a research group while fulﬁll-
ing some constraints. F describes information about ofﬁce locations, persons and
the group organization. A set R of inference rules describing implicit knowledge
about the domain is added. C represents allocation constraints. F and R can be seen
as describing a world, which is consistent if it fulﬁlls the constraints in C. E is the
set of evolution rules, allowing to go from one world to another. In this particular
example, evolution rules are used to assign an ofﬁce to a person. Finally, given such
a KB, the allocation problem can be modeled as a deduction problem. The goal Q
represents a situation where each person of the group has an ofﬁce. It can be deduced
from the base if there is a world, obtainable from the initial world by the evolution
rules while satisfying the constraints, such that Q can be mapped to this world.

11.2 FC: Facts and Constraints
313
11.2 FC: Facts and Constraints
Let us ﬁrst introduce constraints, which are used to validate knowledge, i.e., to
check its consistency. In the simpler model, the checked knowledge is a set of facts.
In further sections, we will see more complex uses of constraints when the knowl-
edge base includes rules.
11.2.1 Positive and Negative Constraints
A constraint can be positive or negative, expressing a knowledge of form “if A holds,
so must B”, or “if A holds, B must not.” It has the same syntactical form as a rule.
Intuitively, if the constraint is positive, it is satisﬁed by a graph G if each time “A
holds” in G then “B also holds” in G. As usual, “A holds” in G means that there is a
homomorphism from A to G. Thus G satisﬁes the constraint if each homomorphism
from A to G can be extended to a homomorphism from B to G. Symmetrically, G
satisﬁes a negative constraint if no homomorphism from A to G can be extended to
a homomorphism from B to G.
C1
Secretary
C2
Office
Person
Office
Person
HeadOfGroup
in
near
Office
in
in
in
works−with
Fig. 11.2 Constraints
Figure 11.2 represents two constraints (seen as bicolored graphs). The negative
constraint C1 expresses that “two persons working together should not share an of-
ﬁce.” The positive constraint C2 expresses that “the ofﬁce of a head of a group must
be near the ofﬁces of all secretaries.” The BG G in Fig. 11.3 does not satisfy C1 be-
cause “there is a researcher who works with researcher K” (homomorphism from the
condition of C1) “and they share ofﬁce #124” (extension of this homomorphism to
a homomorphism from the whole C1). G satisﬁes C2 because there is no homomor-
phism from the condition of C2 to G (with the natural assumption that Researcher
is not a subtype of HeadOfGroup).
When the KB is composed of a set of facts and a set of constraints, the role
of constraints is to validate the fact base. The KB is said to be consistent if all
constraints are satisﬁed. Deduction is deﬁned only on a consistent base. Provided
that the base is consistent, deduction is performed by a simple homomorphism check

314
11 The BG Family: Facts, Rules and Constraints
in
in
near
Office
Office: #124
Secretary:J
in
G
member
Project
Researcher
member
works−with
Researcher:K
member
Fig. 11.3 G does not satisfy constraint C1 in Fig. 11.2
as in the BG model. Note that even if they have the same form, constraints and rules
Project
R
Researcher
member
Fig. 11.4 Rule versus Constraint
play a different role. Consider, for instance, the bicolored graph R in Fig. 11.4: As
a rule, it says that every researcher is a member of a project. Take the fact F =
[Researcher:K] and the query Q= [Researcher:K] →(member) →[Project] (“is K
member of a project?”). If Q is asked on K = (F,R = {R}), the answer is “yes.”
Now see R as a positive constraint C. It says that every researcher must be a member
of a project. K = (F,C = {C}) is inconsistent, thus nothing can be deduced from it,
including Q. The KB has to be repaired ﬁrst.
Deﬁnition 11.1 (Constraints). A positive (resp. negative) constraint C is a bicol-
ored BG. C(0), the subgraph induced by the nodes of color 0, is called the condi-
tion of constraint, C(1), the subgraph induced by the nodes of color 1 and the fron-
tier nodes, is called its obligation (resp. interdiction). A BG G satisﬁes a positive
(resp. negative) constraint C if every (resp. no) homomorphism from the condition
of C to the irredundant form of G (resp. to G) can be extended to a homomorphism
from C as a whole. A BG G π-violates a positive (resp. negative) constraint C if π is
a homomorphism from the condition of C to the irredundant form of G (resp. to G)
that cannot be extended (resp. that can be extended) to a homomorphism from C as
a whole. G violates C if it π-violates C for some homomorphism π, in other words
G does not satisfy C.
Nothing prevents the condition or the obligation/interdiction of a constraint to
be empty. If the obligation/interdiction is empty, the constraint plays no role. If the
condition is empty, satisfaction can be expressed in a simpler way since the empty

11.2 FC: Facts and Constraints
315
graph can be mapped to any graph. A BG G satisﬁes a positive constraint C+ with
an empty condition if and only if there is a homomorphism from C+
(1) to the normal
form of G. Similarly, G satisﬁes a negative constraint C−with an empty condition
if and only if there is no homomorphism from C−
(1) to G.
C (positive)
H
G
r
r
t
r
t
t
t
Fig. 11.5 Redundancy and constraint violation
Let us point out the importance of the irredundancy condition on the graph to
be validated by positive constraints: Should we omit this condition, there may be
two equivalent BGs, such that one satisﬁes a positive constraint and the other does
not. Figure 11.5 shows an example of such graphs. G satisﬁes C, but the equivalent
(redundant) graph H, obtained by making the disjoint union of G and the condition
of C, does not. A way of avoiding different consistency values for equivalent graphs
is to deﬁne positive constraint satisfaction with respect to the irredundant form of
a BG. This problem does not occur with negative constraints. Indeed, let G1 and
G2 be two equivalent graphs and assume that G1 π-violates a negative constraint C;
since there is a homomorphism from G1 to G2, say π1, π1 ◦π is a homomorphism
from C to G2, thus G2 also violates C.
In the previous deﬁnition, a constraint is deﬁned as a bicolored graph. It can also
be deﬁned in the more general form of a couple of λ-BGs with very slight changes:
The condition is the ﬁrst λ-graph and the obligation/interdiction is the second one.
A BG G satisﬁes a positive constraint C : λ(c1 ... cn)Cc →Oc if, for every homomor-
phism π1 from Cc to the irredundant form of G, there is a homomorphism π2 from
Oc to the irredundant form of G, such that for all i = 1 ... n, π1(c1i) = π2(c2i). G π1-
violates C if there is π1 from Cc to the irredundant form of G with no π2 satisfying
the previous condition.
All results presented here for bicolored constraints hold true for λ-contraints.
Let us give a very simple example to show what λ-constraints may add. Suppose
one wants to deﬁne the signature of relations by constraints (i.e., for each relation
symbol, deﬁne the maximal type of each argument of a relation node typed by this
symbol). The constraint to express is of form “if there is a relation node r of type
tr, then for all i ranging from 1 to the arity p of tr, the i-th neighbor of r has to be
of type less or equal to a certain type ti.” The condition part is made of one relation
node r = (tr) with p neighbors [⊤: ∗], with each concept node being a distinguished
node; the obligation is restricted to the distinguished nodes [t1 : ∗] ... [tp : ∗], where
the ith node corresponds to the ith neighbor of r (see Fig. 11.6). Bicolored graphs
cannot express this constraint (for this particular case, where all distinguished nodes
in the condition are of form [⊤: ∗], they could express it if we removed the require-
ment that the condition part of a constraint has to be a well-formed BG; such an

316
11 The BG Family: Facts, Rules and Constraints
extension could be safely done for constraints, whereas it could not for rules since
the application of a rule could then lead to a graph that is not well-formed).
tr
T
T
T
1
tp
t2
t1
...
...
2
p
Fig. 11.6 A λ-constraint representing a relation signature
Two constraints C1 and C2 are said to be equivalent if any graph that violates C1
also violates C2, and conversely. The following property on negative constraints is
immediate.
Property 11.1. Any negative constraint is equivalent to the negative constraint ob-
tained by coloring all its nodes by 1.
Furthermore, negative constraints can be considered as a particular case of pos-
itive ones: Consider the positive constraint C′ obtained from a negative constraint
C by coloring all nodes of C by 0, then adding a concept node colored by 1, with
type NotThere, where NotThere is incomparable with all other types and does not
appear in any graph of the KB, except in constraints. Then a graph G violates the
negative constraint C if and only if it violates the positive constraint C′. Positive con-
straints strictly include negative constraints, in the sense that the associated consis-
tency problems are not in the same complexity class, as will be shown in Sect. 11.2.3
(cf. Theorems 11.3 and 11.4).
Property 11.2. Unless Π P
2 = co-NP, positive constraints are a strict generalization of
negative constraints.
Since negative constraints can be seen as a particular case of positive ones, we
will now, unless indicated otherwise, let “a set of constraints” denote a set of positive
constraints: Some of them can be equivalent to negative ones.
Deﬁnition 11.2 (Consistency/Deduction in FC). A KB K = (F,C) is consistent if
F satisﬁes all constraints of C. A BG Q can be deduced from K if K is consistent
and Q can be deduced from F. We call FC-CONSISTENCY and FC-DEDUCTION
the associated decision problems.
11.2.2 Translation to FOL
Note ﬁrst that constraints lead to non-monotonic deduction. Indeed, consider a
knowledge base with a consistent set of facts F and a BG Q deducible from F.

11.2 FC: Facts and Constraints
317
If one adds information to F, one may create a constraint violation; since nothing
can be deduced from an inconsistent knowledge base, previous deductions no longer
hold. In particular Q cannot be deduced anymore. This is why as soon as constraints
are involved it is impossible to obtain results of form “Q can be deduced from the
KB K if and only if Φ(K) |= Φ(Q).” However, if deduction cannot be translated to
FOL, consistency (or inconsistency) can, and this is the point studied in this section.
For negative constraints, the correspondence between consistency and logical
deduction is immediate, and relies on homomorphism soundness and completeness
with respect to the semantics Φ (theorem 4.3). Intuitively, a BG G violates a negative
constraint C−if and only if the knowledge represented by C−is deducible from the
knowledge represented by G.
Theorem 11.1. A BG G violates a negative constraint C iff Φ(V),Φ(G) ⊨Φ(C),
where Φ(C) is the logical formula assigned to the BG underlying C.
A ﬁrst way of translating consistency with respect to to positive constraints into
logics consists of translating the “homomorphism” notion into the notion of LV-
substitution on formulas associated with graphs, where LV is the ordered logical
language assigned to V (cf. Sect. 4.2.1).
As a corollary of Theorem 4.4 establishing the equivalence between homomor-
phism and LV-substitution, we obtain:
Property 11.3. A graph G π-violates a positive constraint C if and only if the LV-
substitution σ from Φ(C(0)) to Φ(G) associated with π cannot be extended to a
LV-substitution from Φ(C) to Φ(G), where Φ(C) is the logical formula assigned
to the BG underlying C.
Another bridge can be built using rules. Indeed, a graph G satisﬁes a positive
constraint C if and only if, considering C as a rule, all applications of C to G produce
a graph equivalent to G. Or, more speciﬁcally:
Property 11.4. A BG G π-violates a positive constraint C iff, considering C as a
rule, the application of C to G according to π produces a graph that is not equivalent
to G.
Proof. Let C and G such that G satisﬁes C. If π0 is a homomorphism from C(0) to G,
let us consider the graph G′ obtained by the application of C (considered now as a
rule) to G according to π0. Let us now build the following homomorphism π′ from
G′ to G: for each node v, π′(v) = v if v belongs to G; otherwise, v is a copy of a node
w of C(1), and let π be one of the homomorphisms from C to G that extends π0, we
have π′(v) = π(w). Then π′ is a homomorphism from G′ to G, and since G trivially
maps to G′, they are thus equivalent. This proves the ⇐part of Property 11.4.
For the ⇒part, we use Property 2.9, which states that, for any BG and any of
its irredundant subgraphs equivalent to it, there is a folding from the BG to this
subgraph. Suppose now that G π-violates C. Since constraint violation is deﬁned
with respect to the irredundant form of a graph, we can consider, without loss of

318
11 The BG Family: Facts, Rules and Constraints
generality, that G is irredundant. We denote by G′ the graph obtained by the appli-
cation of C (again, considered now as a rule) to G according to π. We prove that “G′
equivalent to G” leads to a contradiction. If G′ is equivalent to G, then there is a ho-
momorphism from G′ to G. And since G is an irredundant subgraph of G′, there is
a folding f from G′ to G. Consider now π′ the homomorphism from C to G deﬁned
as follows: for any node x in C, if x is in C(0) then π′(x) = π(x), otherwise let x′ be
the copy of x in G′, and let π′(x) = f(x′). Since for all x in C(0), and in particular for
the frontier nodes, f(π(x)) = π(x), π′ is a homomorphism and it extends π. This
contradicts the “G π-violates C” hypothesis. Thus G′ is not equivalent to G.
⊓⊔
Property 11.5. If a BG G satisﬁes a positive constraint C, then any graph in a {C}-
derivation of G is equivalent to G.
Proof. Let G0(= G) ,..., Gk be a {C}-derivation of G. From Property 11.4, each
Gi, 1 ≤i ≤k, is equivalent to Gi−1, thus by transitivity, is equivalent to G.
⊓⊔
Using soundness and completeness of the deduction in FR, and Properties 11.4
and 11.5, one obtains the following relation with FOL deduction.
Theorem 11.2. A BG G violates a positive constraint C if and only if there is a
BG G′ such that Φ(V),Φ(G),Φ(C) ⊨Φ(G′) and not Φ(V),Φ(G) ⊨Φ(G′), where
Φ(C) is the translation of C considered as a rule.
11.2.3 Complexity of Consistency and Deduction
This section is devoted to the complexity of FC-CONSISTENCY and FC-DEDUC-
TION. The complexity is ﬁrst established in the general case, then for particular
constraints, namely negative and disconnected constraints.
Theorem 11.3 (Complexity of consistency in FC). Consistency in FC is Π P
2 -
complete.
Proof. Without change of complexity, one can consider that C is composed of only
one positive constraint, say C. First recall that deciding whether a BG F satisﬁes C
is done on the irredundant form of F. We may consider two ways of integrating the
complexity of making a graph irredundant in the complexity of FC-CONSISTENCY.
One way of doing this is to assume that the irredundant form of F is computed
before the consistency check. This can be achieved with a number of calls to a
homomorphism oracle linear in the size of F (cf. Sect. 2.6). However, since we
then have to solve a function problem (compute the irredundant form of F) instead
of a decision problem (is F irredundant?), we prefer to integrate irredundancy into
the consistency check: Then, for a homomorphism π0 from the condition of C to
F, the homomorphism from C to F we look for does not necessarily extend π0,
but it extends the composition of a homomorphism from F to one of its subgraphs
(possibily equal to F itself) and π0.

11.2 FC: Facts and Constraints
319
FC-CONSISTENCY belongs to Π P
2 since it corresponds to the language L =
{x | ∀y1 ∃y2 R(x, y1, y2)}, where x encodes an instance (F,{C}) of the problem
and (x, y1, y2) ∈R if and only if y1 encodes a homomorphism π0 from C(0) to F
and y2 encodes a homomorphism πF from F to one of its subgraphs and a homo-
morphism π from C to F such that π[C(0)] = πF ◦π0. Note that if F is in irredundant
form, then πF is an automorphism.
Now let us consider the Bc
2 problem: Given a boolean formula E, and a partition
{X1, X2} of its variables, is it true that for any truth assignment for the variables
in X1 there is a truth assignment for the variables in X2 such that is E true? This
problem is Π P
2 -complete, since its complementary B2 is shown to be Σ P
2 -complete
in [Sto77]. In order to build a polynomial reduction to FC-CONSISTENCY, we use a
restriction of this problem to k-CNF, i.e., conjunctions of disjunctions with at most
k literals per clause. Let us call 3-SAT c
2 the special case where E is a 3-CNF, in
other words an instance of 3-SAT. Then 3-SAT c
2 is also Π P
2 -complete. Indeed, in the
same paper (Theorem 4.1) it is shown that B2 with E restricted to a 3-disjunctive
normal form (3-DNF) remains Σ P
2 -complete. Since the negation of a 3-DNF is a
3-CNF, it follows that the complementary problem Bc
2 with E restricted to a 3-CNF
is Π P
2 -complete.
F
...
3
2
1
3
2
1
C
3
2
1
3
2
1
val
av
b
a
C2
C2
C2
C2
C2
C2
C1
C1
C1
C1
C1
C1
C1
df
dt
cf
ct
C2
val
bf
bt
af
at
d
bv
cv
dv
val
val
C1
C2
c
d
c
b
a
val
val
val
val
val
val
val
val
Fig. 11.7 Example of transformation from 3-SAT c
2 to FC-CONSISTENCY
Let us now reduce 3-SAT c
2 to FC-CONSISTENCY. The transformation used is
very similar to that from 3-SAT to BG-DEDUCTION (proof of Theorem 2.5 illus-
trated in Fig. 2.25). Let E be an instance of 3-SAT. Let H(E) and G(E) be the
BGs obtained by the transformation described in the proof of Theorem 2.5. Let
F = H(E). The constraint C is obtained by adding a coloration to G(E): All relation
nodes obtained from a clause (nodes typed Ci) and all nodes obtained from vari-
ables in X2 (concept nodes typed x or xv and relation nodes typed val) are colored
by 1 (i.e., belong to the obligation of C). Once again, having clauses of bounded size
leads to a polynomial transformation. The graph F and the positive constraint C pre-
sented in Fig. 11.7 are obtained from the 3-SAT formula (a∨b∨¬c)∧(¬a∨c∨¬d)
and the partition {X1 = {a,b},X2 = {c,d}}.
Each truth assignment of the variables in E such that E is true naturally yields
a homomorphism from C to F, and reciprocally (as indicated in the proof of Theo-
rem 2.5). Furthermore, any truth assignment for the variables in X1 naturally yields

320
11 The BG Family: Facts, Rules and Constraints
a homomorphism from C(0) to F, and reciprocally. Thus, the question “is it true
that for any truth assignment for the variables in X1 there is a truth assignment for
the variables in X2 such that is E true?” is equivalent to the question “is it true that
for any homomorphism π0 from C(0) to F there is a homomorphism from C to F
extending π0?”
⊓⊔
Corollary 11.1. Deduction in FC is Π P
2 -complete.
The next theorem shows a complexity decrease when only negative constraints
are considered.
Theorem 11.4 (Complexity with negative constraints). If all constraints are neg-
ative, FC-CONSISTENCY is co-NP-complete and FC-DEDUCTION is DP-complete.
Proof. Co-NP-completeness of FC-CONSISTENCY: from NP-completeness of ho-
momorphism checking (theorem 2.5).
DP-completeness of FC-DEDUCTION: this problem can be expressed as “Is it
true that Q maps to F and that no constraint of C maps to F?” Thus it belongs to
DP. Now let us consider that C contains only one constraint. A reduction from 3-
SAT to BG-HOMOMORPHISM (cf. for instance the proof of theorem 2.5) provides
a straightforward reduction from SAT/UNSAT (cf. for instance
[Pap94]) to FC-
DEDUCTION, thus the DP-completeness.
⊓⊔
It would be interesting to exhibit particular cases of constraints, more general
than negative ones, that make this complexity fall into intermediary classes (e.g.,
DP and ∆P
2 for FC-CONSISTENCY). Some syntactic restrictions we deﬁned for rules
are good candidates: Though a ﬁnite expansion set of constraints makes no sense,
let us consider range restricted constraints, i.e., (positive) constraints whose obli-
gation does not contain any generic concept node. Let us also deﬁne disconnected
constraints as (positive) constraints where the condition and obligation are disjoint.
The following property highlights the relationships of these particular cases with
negative constraints:
Property 11.6. Negative constraints are a particular case of both range-restricted
constraints and disconnected constraints.
Proof. As noted previously, a negative constraint is equivalent to a positive con-
straint whose obligation is composed of one concept node of type NotThere, where
NotThere is incomparable with all other types and does not appear in the knowledge
base except in C (it is thus a disconnected constraint). Without loss of generality this
node can be labeled by an individual marker (which, as NotThere, appears only in
C), thus leading to a constraint which is both disconnected and range-restricted.
⊓⊔
Theorem 11.5 (Complexity with disconnected constraints). When C contains
only disconnected constraints, FC-CONSISTENCY and FC-DEDUCTION become
DP-complete.

11.3 Combining Rules and Constraints
321
Proof. FC-INCONSISTENCY belongs to DP, since we must prove that for one
constraint there is a homomorphism from its condition and no homomorphism
from its obligation. Since DP = co-DP, FC-CONSISTENCY belongs to DP, and
DP-completeness is proven with a reduction from SAT/UNSAT (as in proof of
theorem 11.10). For FC-DEDUCTION, we have to independently solve the FC-
CONSISTENCY (DP-complete) and the F-DEDUCTION (NP-complete) problems,
hence the result.
⊓⊔
To the best of our knowledge, there is currently no result about the complexity
of FC-CONSISTENCY with range-restricted constraints. The difﬁculty in classifying
this problem relies on the integration of irredundancy.
11.3 Combining Rules and Constraints
Two different kinds of rule and constraint combinations are considered in this sec-
tion. With the ﬁrst one, yielding the model FRC, rules are considered as inference
rules representing implicit knowledge. Facts and inference rules can be seen as de-
scribing a “world,” and a rule application modiﬁes the explicit description of the
world (i.e., the facts). Constraints deﬁne the consistency of this world. In the second
one, yielding the model FEC, another semantics is given to rules, which are now
called evolution rules: Rules represent possible transitions from facts to other facts,
and all facts have to be consistent. Finally, the model FREC integrates both kinds
of rules. In short, facts and inference rules deﬁne a world that has to be consistent,
and evolution rules deﬁne possible transitions from one world to other worlds, that
have to be consistent.
11.3.1 FRC: Constraints and Inference Rules
In the FRC model, a KB is composed of a set of facts F, a set of inference rules
R, and a set of constraints C. The notion of consistency now has to take rules into
account.
Consider, for instance, the KB K = (F = {G},R = {R1,R2},C = {C2}) where
G is the upper graph in Fig. 11.8, R1 and R2 are the rules in Fig. 11.9, and C2 is
the positive constraint in Fig. 11.2. The fact G alone does not satisfy constraint C2
(there are two violations of C2, because none of the ofﬁces #2 and #3 are known
to be near ofﬁce #1). But it does after a certain number of rule applications. Thus
K is said to be consistent. In this case, it is easy to deﬁne and check consistency
because the world description can be completely explicited by a ﬁnite BG, the full
graph of G with respect to R, represented as H in Fig. 11.8, we just have to check
whether this graph is consistent. In the general case, consistency relies on whether
each “constraint violation” can be repaired by rule applications. Moreover, applying
a rule to F can create inconsistency, but a further application of a rule may restore

322
11 The BG Family: Facts, Rules and Constraints
adjoin
Office:#1
adjoin
adjoin
Office:#3
G
H
adjoin
adjoin
near
near
near
near
near
near
near
Office:#4
Office:#3
Office:#2
Office:#2
adjoin
Office:#4
Office:#1
in
in
Secretary
Secretary:P
HeadOfGroup : H
in
in
in
Secretary
Secretary:P
HeadOfGroup : H
in
Fig. 11.8 Facts: G and its full graph with respect to rules in Fig. 11.9
near
Local
Local
near
Local
Local
R2
R1
adjoin
adjoin
near
Local
Fig. 11.9 Rules
consistency. Let us formalize this notion of consistency restoration. Suppose there
is a π-violation of a positive constraint C in F; this violation (C,π) is said to be
R-restorable if there is an R-derivation from F to a BG F′ such that F′ does not
π-violates C (in other words, there is a homomorphism π′ from F′ to irr(F′), the
irredundant form of F′, such that the homomorphism π′ ◦π from the condition of C
to irr(F′) can be extended to a homomorphism from C as a whole). Note that the R-
restoration can create new violations that must themselves be proven R-restorable.
Deﬁnition 11.3 (Consistency/Deduction in FRC). A KB K = (F,R,C) is consis-
tent if, for any BG F′ that can be R-derived from F, for every constraint C ∈C, for
every π-violation of C in F′, (C,π) is R-restorable. A BG Q can be deduced from K
if K is consistent and Q can be deduced from (F,R). We call FRC-CONSISTENCY
and FRC-DEDUCTION the associated decision problems.
Let us give another example. Consider a KB composed of one fact F= [Per-
son:Mary], one rule and one constraint, both represented by the same bicolored
graph shown in Fig. 11.10. The rule says that “every person has a father and a

11.3 Combining Rules and Constraints
323
hasMother
hasFather
Person
Person
Person
Fig. 11.10 A rule/constraint
mother,” and the constraint says that this must be the case. F violates the constraint
but a rule application can repair this violation, while creating another violation. Fi-
nally, every constraint violation can be repaired by a rule application, thus the KB
is consistent.
Note that the violation of a negative constraint can never be restored. The con-
sistency of a KB with negative constraints only can thus be deﬁned in a simpler
way.
Property 11.7 (Consistency/Deduction in FRC with negative constraints). A KB
K = (F,R,C), where C is composed of negative constraints, is consistent if and
only if, for any BG F′ that can be R-derived from F, (F′,C) is consistent, i.e., there
is no homomorphism from a C ∈C to F′.
Let us also point out the particular case of positive constraints with an empty
condition: (F,R) is consistent with respect to to a positive constraint C+ with C+
(0)
empty if and only if there is a BG F′ that can be R-derived from F and to which
C+
(1) can be mapped.
For both previous particular cases, the translation of FRC consistency to FOL is
immediate and relies on the soundness and completeness of graph derivation in FR.
For the translation in general case, one may try to extend the result obtained for FC
consistency, i.e., a KB composed of facts is inconsistent if and only if there is a BG
(a FOL(∃, ∧) formula) that can be deduced from the facts and the constraints seen
as rules, but cannot be deduced from the facts alone. The next theorem shows that
one direction of the above equivalence holds for a KB composed of facts and rules.
And a counter-example then shows that the other direction does not hold.
Theorem 11.6 (FOL translation: a sufﬁcient condition for FRC inconsistency).
Let K = (F,R,C) be a KB. If there exists a BG F′ such that Φ(V),Φ(F),Φ(R),
Φ(C) ⊨Φ(F′) and not Φ(V),Φ(F),Φ(R) ⊨Φ(F′), where Φ(C) is the translation
of the constraints in C considered as a rules, then K is inconsistent.
Proof. If there is such a BG F′ then there is an (R ∪C)-derivation, where the el-
ements of C are considered as rules, say F0(= F),...,Fk, such that F′ maps to Fk.
See that Fk is not deducible from (F,R) otherwise F′ would also be deducible
from (F,R). Let us consider the ﬁrst Fi in the derivation that is not deducible from
(F,R). Fi is obtained from Fi−1 by applying a rule Cq ∈C according to a homomor-
phism π. Since Fi−1 is deducible from (F,R) there is a BG H and an R-derivation
from F to H such that Fi−1 maps to H by a homomorphism π′. Consider π′′ = π′◦π
the homomorphism from the ﬁrst part of Cq (its condition/hypothesis) to H. We now
prove that (1) H π′′-violates Cq and (2) this violation is not restorable. If (1) or (2)

324
11 The BG Family: Facts, Rules and Constraints
is false, then there is a BG H′ R-derived from H such that π′′ can be extended to
a homomorphism from Cq as a whole to the irredundant form of H′. This is absurd
because there would be a homomorphism from Fi to a BG R-derivable from F, thus
Fi would be deducible from (F,R).
⊓⊔
a rule R
a positive constraint C
a fact G
r
r
t
t
t
s
t
Counter-example to the converse of Theorem 11.6
Fig. 11.11 Counter-example
Property 11.8. The converse of theorem 11.6 is false, as shown in Fig. 11.11.
In Fig. 11.11, check that every graph that can be {R,C}-derived from G can also
be {R}-derived from G. However, the KB is inconsistent: G violates constraint C
and this violation cannot be restored.
We now show that when the set of rules is restricted to a ﬁnite expansion set (cf.
Deﬁnition 10.12), FRC consistency can be translated to FOL in the same way as
FC consistency, i.e., in this particular case the converse of Theorem 11.6 holds.
Let K = (F,R,C) be a KB. Let us ﬁrst point out that if R is a ﬁnite expansion
set, checking the consistency of K is equivalent to checking the consistency of the
full graph FR.
Property 11.9 (Consistency with a ﬁnite expansion set of rules). Let K = (F,R,C)
be a KB where R is a ﬁnite expansion set. K is consistent if and only if (FR,C)
is consistent. Thus, a BG Q can be deduced from (F,R,C) if and only if it can be
deduced from (FR,C).
This property is used to prove that the converse of Theorem 11.6 is true when R
is a ﬁnite expansion set.
Theorem 11.7 (FOL translation of FRC inconsistency with ﬁnite expansion set
of rules). Let K = (F,R,C) be a KB where R is a ﬁnite expansion set. K is inconsis-
tent if and only if there is a BG F′ such that Φ(V),Φ(F),Φ(R),Φ(C) ⊨Φ(F′) and
not Φ(V),Φ(F),Φ(R) ⊨Φ(F′) (where Φ(C) is the translation of the constraints
in C considered as a rules).
Proof. (⇐) holds as a particular case of Theorem 11.6. (⇒) Since K is inconsis-
tent, the previous property asserts that (FR,C) is inconsistent. Theorem 11.2 en-
sures that there is a graph H such that (1) Φ(V),Φ(FR),Φ(C) ⊨Φ(H) and not (2)
Φ(V),Φ(FR) ⊨Φ(H). Since Φ(V),Φ(F),Φ(R) ⊨Φ(FR) (cf. soundness of rule

11.3 Combining Rules and Constraints
325
application in Chap. 10) we have Φ(V),Φ(F),Φ(R),Φ(C) ⊨Φ(H). Let us now
assume that Φ(V),Φ(F),Φ(R) ⊨Φ(H) and prove that it is absurd. In this case,
there would be a graph F′ R-derivable from F such that H maps to F′ (cf. com-
pleteness of rule application in Chap. 10). Since H maps to F′, which maps to FR,
by transitivity H maps to FR. We should have Φ(V),Φ(FR) ⊨Φ(H) (soundness
of BG homomorphism), which contradicts the hypothesis.
⊓⊔
11.3.2 FEC: Constraints and Evolution Rules
Let now now consider another use of rules. The objects and application mechanisms
are the same, but rules are used with another intention: Instead of representing im-
plicit knowledge about a world, they represent possible actions leading from one
world to another. We call them evolution rules. As these rules have the same form
as inference rules, they only add information. It would be worthwhile to generalize
these rules to true transformation rules, also allowing to delete information, but this
has not yet been done. Consider, for instance, the bicolored graph in Fig. 11.12.
Office
Person
in
Fig. 11.12 An evolution rule
Taken as an inference rule, it would say that “all persons are in all ofﬁces.” Taken
as an evolution rule, it states that “when there are a person and an ofﬁce, (try to)
assign this ofﬁce to that person.” Consider a KB composed of facts, evolution rules
and constraints. Facts describe an initial world; evolution rules represent possible
transitions from worlds to other worlds; constraints deﬁne the consistency of each
world; a successor of a consistent world is obtained by an evolution rule applica-
tion; given a BG Q, the deduction problem asks whether there is a path of consistent
worlds evolving from the initial one to a world satisfying Q.
Deﬁnition 11.4 (Deduction in FEC). Let K = (F,E,C) be a KB, and let Q be a
BG. Q can be deduced from K if there is an E-derivation F0(= F)...,Fk such that,
for 0 ≤i ≤k, (Fi,C) is consistent and Q can be deduced from Fk. We call FEC-
DEDUCTION the associated decision problem.
To summarize, in FEC, F is seen as the initial world, root of a potentially inﬁnite
tree of possible worlds, and E describes possible evolutions from worlds to others.
Each world has to be consistent. In FRC, F provided with R is a ﬁnite description
of a “potentially inﬁnite” world, that has to be consistent.

326
11 The BG Family: Facts, Rules and Constraints
11.3.3 FREC: Constraints, Inference and Evolution Rules
The FREC model combines both derivation schemes of the FRC and FEC models.
Now, F describes an initial world, inference rules in R complete the description of
any world, constraints in C deﬁne the consistency of a world, evolution rules in E try
to make evolve a consistent world into a new, consistent one. The deduction problem
asks whether F can evolve into a consistent world satisfying the goal.
Deﬁnition 11.5 (Deduction in FREC). A BG G′ is an immediate RE-evolution
from a BG G if there is an R-derivation from G to to a BG G′′ and an immediate E-
derivation from G′′ to G′. An RE-evolution from a BG G to a BG G′ is a sequence
of BGs G0(= G),...,Gk = G′ such that, for 0 ≤i ≤k, (Gi,R,C) is consistent and,
for 1 ≤i ≤k, Gi is an immediate RE-evolution from Gi−1. Given a KB K = (F,R,
E,C), a BG Q can be deduced from K if there is an RE-evolution F0(= F),...,Fk
such that Q can be deduced from (Fk,R). We call FREC-DEDUCTION the associ-
ated deduction problem.
When E = ∅(resp. R = ∅), one obtains the FRC model (resp. the FEC model).
11.3.4 Complexity of Combining Rules and Constraints
As the deduction in FR is not decidable, this is also the case in FEC and FRC.
And unsurprisingly, the deduction is more difﬁcult in FRC than in FEC.
Theorem 11.8 (Complexity in FEC/FRC). Deduction in FEC is semi-decidable.
Consistency and deduction in FRC are totally undecidable.
Proof. FEC includes FR thus FEC-deduction is not decidable. When Q is de-
ducible from K, a breadth-ﬁrst search of the tree of all derivations from K, each
graph being checked for consistency, ensures that Fk is found in ﬁnite time. For
FRC, we show that checking consistency is totally undecidable. Let K = (F,R,C)
be a KB where C contains a positive constraint C+ and a negative constraint C−,
both with an empty condition. To prove consistency, one has to prove that C−is
not deducible from (F,R), and the algorithm does not necessarily stop in this case
(from semi-decidability of deduction in FR). The same holds for the complemen-
tary problem (proving inconsistency) taking C+ instead of C−. Indeed, since C+
has an empty condition, (F,R) violates C+ if and only if C+ is not deducible from
(F,R). Hence the total undecidability.
⊓⊔
As a generalization of FRC, deduction in FREC is totally undecidable. The
next section exhibits decidable fragments of FREC and classiﬁes some of them in
the polynomial hierarchy.

11.4 Complexity in FRC/FEC/FREC for Particular Cases of Rules and Constraints
327
11.4 Complexity in FRC/FEC/FREC for Particular Cases of
Rules and Constraints
In this section, we study how particular cases of rules and constraints inﬂuence the
decidability and complexity of deduction in models combining rules and constraints,
i.e., FRC, FEC and FREC. In short, we show that considering ﬁnite expansion sets
of rules leads to decidability of deduction in these models. When rules are range-
restricted, all deduction problems can be classiﬁed in the polynomial hierarchy. We
obtain lower complexity if we furthermore restrict constraints to disconnected con-
straints or to more speciﬁc negative constraints.
11.4.1 Particular Cases of Rules
Property 11.10 (Complexity with constraints and ﬁnite expansion sets of rules ).
• When R is a ﬁnite expansion set, deduction in FR is decidable, consistency and
deduction in FRC are decidable, deduction in FREC is semi-decidable.
• When E is a ﬁnite expansion set, deduction in FEC is decidable, but remains
totally undecidable in FREC.
• When R∪E is a ﬁnite expansion set, deduction in FREC is decidable.
Proof. Assume that R is a ﬁnute expansion set. Decidability of deduction in FR
is proven in Chap. 10. Decidability of deduction and consistency in FRC follows
from Property 11.9. In FREC, when the answer is ”yes”, it can be obtained in ﬁnite
time; we proceed as for FEC (cf. proof of Theorem 11.8) but consistency checks
are done on the full graph instead of the graph itself.
Now, assume that E is a ﬁnite expansion set. The full graph FE exists, thus the
derivation tree in FEC is ﬁnite, and consistency checks may only cut some parts
of this tree. Deduction in FREC remains undecidable because when E = ∅, one
obtains the FRC model, in which deduction is undecidable.
Finally, if R ∪E is a ﬁnite expansion set, the full graph FR∪E exists, thus the
derivation tree is ﬁnite, and consistency checks may only cut parts of this tree.
⊓⊔
Note that the condition “R ∪E is a ﬁnite expansion set” is stronger than “both
R and E are ﬁnite expansion sets.” When both R and E are ﬁnite expansion sets,
FREC remains non-decidable (see bibliographical notes).
Let us now consider range restricted rules (cf. Chap. 10). As previously, we as-
sume that the arity of relation types is bounded by a constant.
Theorem 11.9 (Complexity with range restricted rules and constraints). When
E and R are range restricted rules:
• Deduction in FR is NP-complete.
• Consistency and deduction in FRC are Π P
2 -complete.
• Deduction in FEC and FREC is Σ P
3 -complete.

328
11 The BG Family: Facts, Rules and Constraints
Proof. The following results heavily rely on Property 10.7: Since all derivations
involved being of polynomial length, they admit a polynomial certiﬁcate (the se-
quence of homomorphisms used to build the derivation).
NP-completeness of FR-DEDUCTION. Cf. Property 10.8.
Π P
2 -completeness of FRC-CONSISTENCY and FRC-DEDUCTION. Recall that
the consistency check involves the irredundant form of F. In order to lighten the
problem formulation, we assume here that all BGs are irredundant, but irredundancy
can be integrated without increasing the consistency check complexity: See the
proof of Theorem 11.3. FRC-consistency belongs to Π P
2 since it corresponds to the
language L = {x | ∀y1 ∃y2 R(x, y1, y2)}, where x encodes an instance K = (F,R,C)
of the problem and (x, y1, y2) ∈R iff y1 = (d1;π0), with d1 being a derivation
from F to F′, π0 is a homomorphism from the condition of a constraint Ci(0) to F′,
y2 = (d2;π1), d2 is a derivation from F′ to F′′ and π1 is a homomorphism from Ci
to F′′ such that π1[Ci(0)] = π0. R is polynomially decidable and polynomially bal-
anced (since the lengths of d1 and d2 are polynomial in the size of the input). When
R = ∅, one obtains the problem FC-CONSISTENCY, thus the Π P
2 -completeness.
Since the FRC-DEDUCTION consists of solving two independent problems, FRC-
CONSISTENCY (Π P
2 -complete) and FR-DEDUCTION (NP-complete), and since NP
is included in Π P
2 , FRC-DEDUCTION is also Π P
2 -complete.
Σ P
3 -completeness of FEC-DEDUCTION. As for FRC (see above), we assume that
all BGs are irredundant. The question is “Is there a derivation from F to F′ and a
homomorphism from Q to F′, such that for all Fi of this derivation, for all constraint
Cj, for all homomorphism π from Cj(0) to Fi, there is a homomorphism π′ from Cj to
Fi such that π′[Cj(0)] = π?” R is polynomially decidable and polynomially balanced
(since the size of the derivation from F to F′ is polynomially related to the size
of the input). Thus FEC-DEDUCTION is in Σ P
3 . In order to prove the completeness,
we build a reduction from a special case of the problem B3, where the formula is
a 3-CNF (i.e., an instance of 3-SAT): Given a formula E, which is a conjunction
of clauses with three literals, and a partition {X1,X2,X3} of its variables, is there a
truth assignment for the variables in X1, such that for every truth assignment for the
variables of X2, there is a truth assignment for the variables of X3 such that is E true?
This problem is Σ P
3 -complete [Sto77, Theorem 4.1]. Let us call it 3-SAT3.
The transformation we use is illustrated in Fig. 11.13. The 3-SAT formula in this
example is again (a∨b∨¬c)∧(¬a∨c∨¬d), and the partition is X1 = {a,b},X2 =
{c},X3 = {d}. The graph F obtained is the same as in the proof of theorem 11.3,
Fig. 11.7, except that concept nodes [x] corresponding to variables in X1 are not
linked to the nodes [xt] and [xf] representing their possible values.
First check that in this initial world no constraint is violated, but the query Q
is not satisﬁed. By applying the evolution rule E once, we try some valuation of
variables in X1 and obtain a world F1, that contains an answer to Q. But this world
has to satisfy the positive constraint C+, expressing that “For every valuation of the
variables in X1 ∪X2, there must be a valuation of the variables in X3 such that the
formula evaluates to true.” If F1 satisﬁes this constraint, this means that we have
found (by applying E) a valuation of variables in X1 such that for all valuations of
variables in X1 ∪X2 (which can be simpliﬁed in “for all valuations of variables in

11.4 Complexity in FRC/FEC/FREC for Particular Cases of Rules and Constraints
329
1
2
3
1
2
3
...
3
2
1
3
2
1
Q
E
C+
F
val
val
av
bv
val
val
d
c
C2
C1
val
dv
cv
val
val
av
b
a
b
a
val
val
b
bv
c
av
a
val
bv
d
val
b
a
at
af
bt
bf
ct
cf
dt
df
C1
C1
C1
C1
C1
C1
C1
C2
C2
C2
C2
C2
C2
C2
val
Fig. 11.13 Example of transformation from 3-SAT3 to FEC-DEDUCTION
X2,” since there is only one such valuation for X1), there is a valuation of variables in
X3 such that the formula evaluates to true. Then there is an answer yes to the 3-SAT3
problem. Conversely, suppose an answer no to the FEC problem. This means that
for every world F1 that can be obtained by applying the rule E, the constraint C+ is
violated (Otherwise Q could be mapped to F1 and the answer would be yes). Thus
there is no assignment of variables in X1 satisfying the constraint, i.e., the answer to
the 3-SAT3 problem is no.
Σ P
3 -completeness of FREC-DEDUCTION. FREC-deduction stays in the same
complexity class as FEC-deduction. Indeed, the question is “Is there an RE-
derivation from F to F′ and a homomorphism from Q to F′, such that for all Fi
either equal to F or obtained by an E-evolution, for all F′
i derived from Fi by an
R-derivation, for all constraint Cj, for all homomorphism π from Cj(0) to F′
i , there
is an R-derivation from F′
i to F′′
i and a homomorphism π′ from Cj to F′′
i such that
π′[Cj(0)] = π?” and the lengths of all derivations are polynomial in the size of the
input. When R = ∅, one obtains FEC-DEDUCTION, thus the Σ P
3 completeness.
⊓⊔
Let us point out that in the general case deduction is more difﬁcult in FRC
(totally undecidable) than in FEC (semi-decidable), but the converse holds for the
particular case of range-restricted rules.

330
11 The BG Family: Facts, Rules and Constraints
11.4.2 Particular Cases of Constraints
One may consider the case where not only rules but also constraints are restricted.
Let us ﬁrst consider the meaningful category of negative constraints.
Theorem 11.10 (Complexity with negative constraints). Without any assumption
on the rules in E or R, but using only negative constraints:
• Consistency in FC is co-NP-complete.
• Deduction in FC is DP-complete.
• Inconsistency in FRC is semi-decidable.
• Deduction in FEC remains semi-decidable.
• Deduction in FRC and FREC remains totally undecidable.
Proof. Co-NP-completeness of FC-CONSISTENCY and DP-completeness of FC-
DEDUCTION are proven in Theorem 11.4.
Semi-decidability of FRC-INCONSISTENCY: To prove the inconsistency of a
KB, we must ﬁnd some violation of a constraint that will never be restored. But no
violation of a negative constraint can ever be restored (further rule applications can
only add information, thus more possible homomorphisms, and cannot remove the
culprit). So we only have to prove that one constraint of C can be deduced from
(F,R): It is a semi-decidable problem. Undecidability of FRC-DEDUCTION fol-
lows: We must prove that Q can be deduced from (F,R), but that no constraint of
C can.
The arguments proving semi-decidability of deduction in FEC and undecidabil-
ity of deduction in FREC are the same as those used in the proof of Theorem 11.8.
⊓⊔
The restriction to negative constraints decreases the problem complexity in the
FC model, but it does not help much as soon as rules are involved, since prob-
lems remain undecidable. When range restricted rules and negative constraints are
combined, more interesting complexity results are obtained:
Theorem 11.11 (Complexity with range-restricted rules and negative constrai-
nts). If only range-restricted rules and negative constraints are present in the knowl-
edge base:
• Consistency in FRC is co-NP-complete.
• Deduction in FRC is DP-complete.
• Deduction in FEC and FREC is Σ P
2 -complete.
Proof. Inconsistency in FRC admits a polynomial certiﬁcate: A derivation (of poly-
nomial length) from F leading to a graph to which a constraint of C can be mapped,
and this homomorphism. Inconsistency is thus in NP, and completeness follows
from the particular case when R is empty. For deduction, we must prove that no
constraint can be deduced from (F,R), but that Q can. So the problem is in DP.
Completeness follows from the particular case when R is empty.

11.4 Complexity in FRC/FEC/FREC for Particular Cases of Rules and Constraints
331
To prove that FEC-DEDUCTION with range restricted rules and negative con-
straints is Σ P
2 -complete, we will ﬁrst show that it belongs to Σ P
2 , and then exhibit a
reduction from a Π P
2 -complete problem to its co-problem FEC-NON-DEDUCTION
(since co-Σ P
i = Π P
i ).
FEC-DEDUCTION corresponds to the language L = {x | ∃y1∀y2 R(x,y1,y2)},
where x encodes an instance (Q;(F,E,C)) of the problem, and (x,y1,y2) ∈R if y1
encodes an E-derivation from F to F′ and a homomorphism from Q to F′, and y2
encodes a mapping from some constraint of C to F′ that is not a homomorphism
(note that if F′ does not violate any constraint, no graph in the derivation from F to
F′ neither does).
We now exhibit a reduction from the general FC-CONSISTENCY problem to
FEC-NON-DEDUCTION with range restricted rules and negative constraints. Let
(F,C = {C}) be an instance of FC-CONSISTENCY (without loss of generality, we
restrict the problem to consider only one positive constraint). The transformation we
consider builds an instance of FEC-NON-DEDUCTION (Q(C);(F,E(C),C−(C))) as
follows. As for a rule, we call the frontier of the positive constraint C the set of nodes
in the condition (i.e., colored by 0) having at least one neighbor in the obligation.
The deﬁnition of colored graphs implies that frontier nodes are concept nodes (their
neighbors are thus relation nodes). Let us denote these frontier nodes by 1,...,k.
The evolution rule E(C) has for hypothesis the condition of C, and for conclusion
a relation node typed found, where found is a new k-ary relation type that is in-
comparable with all other types. The ith neighbor of this node is the frontier node i.
Check that E(C) is a range restricted rule. The negative constraint C−(C) is the sub-
graph of C composed of its obligation C(1) and the relation node typed found, linked
to the frontier nodes in the same way as above. Finally, the query Q(C) is made of
one relation node typed found and its neighbor frontier nodes. This transformation
is illustrated in Fig. 11.14.
Without loss of generality we can assume that F is irredundant: In this case, FC-
CONSISTENCY is still Π P
2 -complete (See that the transformation used in the proof
of Theorem 11.3 produces an irredundant graph G). Now suppose that (F,C) is
consistent: This means that either the condition of C does not map to F, and in this
case the rule E(C) will never produce the needed found node, or every (existing)
homomorphism from the condition of C to F = irr(F) can be extended to a ho-
momorphism from C as a whole. So every application of E(C) produces a violation
of C−(C). In both cases, Q(C) cannot be deduced from the knowledge base. Con-
versely, suppose that F π-violates C, then the application of E(C) according to π
produces a graph that does not violate C−(C), and we can deduce Q(C).
⊓⊔
The above theorem shows a complexity decrease when general positive con-
straints are restricted to negative ones. FC-CONSISTENCY falls from Π P
2 to co-NP
and, when also considering range restricted rules, FRC-CONSISTENCY falls from
Π P
2 to DP, and FEC-DEDUCTION falls from Σ P
3 to Σ P
2 . It would be interesting to ex-
hibit particular cases of constraints that are more general than negative ones and that
make this complexity fall into intermediary classes. We considered disconnected
constraints and range-restricted constraints in Sect. 11.2.3.

332
11 The BG Family: Facts, Rules and Constraints
2
3
3
2
1
1
2
3
1
1
condition
1
found
2
2
1
3
found
2
frontier
3
3
3
2
1
found
the obtained evolution rule
the obtained negative constraint
the obtained query
C
Fig. 11.14 Transformation from FC-CONSISTENCY to a restricted FEC-NON-DEDUCTION
Theorem 11.12 (Complexity with disconnected constraints). When C contains
only disconnected constraints:
• FC-CONSISTENCY is co-DP-complete.
• FRC-CONSISTENCY and FRC-DEDUCTION remain undecidable, but FRC-
CONSISTENCY is co-DP-complete when rules are range-restricted.
• FEC-DEDUCTION remains semi-decidable, but is Σ P
2 -complete when rules are
range-restricted.
• FREC-DEDUCTION remains undecidable, but is Σ P
2 -complete when rules are
range-restricted.
Proof. FC-INCONSISTENCY belongs to DP, since we must prove that for one con-
straint there is a homomorphism from its condition and no homomorphism from its
obligation. DP-completeness is proven with a reduction from SAT/UNSAT (as in
proof of Theorem 11.10). FC-CONSISTENCY is thus co-DP-complete.
Arguments for undecidability of FRC-CONSISTENCY, FRC-DEDUCTION and
FREC-DEDUCTION, as well as semi-decidability of FEC-DEDUCTION, are the
same as in the proof of Theorem 11.8: The constraints we used were already dis-
connected.
When rules are range-restricted, FRC-INCONSISTENCY belongs to DP: We
must prove that the condition of the constraint can be deduced from (F,R), but not
its obligation. These problems belong to NP and co-NP. DP-completeness comes

11.4 Complexity in FRC/FEC/FREC for Particular Cases of Rules and Constraints
333
from the particular case where R is empty. FRC-CONSISTENCY is thus co-DP-
complete.
FEC-DEDUCTION belongs to Σ P
2 when rules involved are range-restricted. Al-
though this property does not appear with an immediate formulation of the prob-
lem, the problem can be stated as follows: “Is there a sequence of graphs F0(=
F), ..., Fp, Fp+1, where F0(= F), ..., Fp is an E-derivation and Fp+1 is the dis-
joint union of Fp and C(1), a homomorphism from Q to Fp and a homomorphism
from C(1) to Fk, 0 ≤k ≤p + 1 such that for every graph Fi,0 ≤i < k, for every
mapping π from C(0) to Fi, π is not a homomorphism ?” Note that no Fi before Fk
in such a sequence triggers the constraint (C(0) does not map to Fi) and that all Fi
from Fk satisfy it (since C(1) maps to Fi). Thus all Fi of the sequence are consistent.
Fp+1 ensures that C(1) maps to at least one graph of the sequence, which allows the
above formulation of the problem. Completeness follows from the particular case of
negative constraints.
Proof for FREC-DEDUCTION is similar: In the expression of the above prob-
lem, the derivation is now an (E ∪R)-derivation, the Fi considered are only those
obtained after the application of a rule in E, and instead “every mapping π from C(0)
to Fi”, we consider “every mapping π from C(0) to a graph that can be R-derived
from Fi”.
⊓⊔
One may expect consistency checking to be easier with range-restricted con-
straints than with general constraints, but as far as we know there are currently no
results on the complexity of this particular case.
Table. 11.1 summarizes the decidability and complexity results obtained. The
following notations are used: fes and rr for respectively ﬁnite expansion set and
range restricted sets of rules, C−for a set of negative constraints and Cd for a set of
disconnected constraints. The sign / indicates a particular case that is not applicable
to the problem considered.
General
R fes
E fes R∪E R&E
C−
R&E
R&E
case
fes
rr
rr, C−
rr, Cd
F-DED.
NP-C
/
/
/
/
/
/
/
FC-CONS.
Π P
2 -C
/
/
/
/
co-NP-C
co-NP-C co-DP-C
FC-DED.
Π P
2 -C
/
/
/
/
DP-C
DP-C
?
FR-DED.
semi-dec.
dec.
/
dec.
NP-C
/
NP-C
NP-C
FRC-CONS.
undec.
dec.
/
dec.
Π P
2 -C co-semi-dec. co-NP-C co-DP-C
FRC-DED.
undec.
dec.
/
dec.
Π P
2 -C
undec.
DP-C
?
FEC-DED.
semi-dec.
/
dec.
dec.
Σ P
3 -C
semi-dec.
Σ P
2 -C
Σ P
2 -C
FREC-DED.
undec.
semi-dec. undec.
dec.
Σ P
3 -C
undec.
Σ P
2 -C
Σ P
2 -C
Table 11.1 Summary of Complexity Results

334
11 The BG Family: Facts, Rules and Constraints
11.5 Bibliographic Notes
This chapter is essentially based on [BM02], which introduces the BG family and
studies the complexity of problems with rules and contraints in detail. The model
names have been changed for consistency with the notations used in the present
book: BG corresponds to SG in the paper, and the F, FC, FR, FRC, FEC and
FREC models correspond to the SG, SGC, SR, SRC, SEC and SREC models in
the paper.
Let us point out two results of [BM02] that have not been included in this chapter.
First, the tight connection between FC-CONSISTENCY and a problem on constraint
networks called MIXED-SAT in [FLS96]. This latter paper considers a generaliza-
tion of constraint networks, called a mixed-network, in which the set of variables
is decomposed into controllable and uncontrollable variables, say X and ∆. The
MIXED-SAT problem takes a binary mixed-network as input and asks whether it
is consistent, that is: Is it true that every solution to the subnetwork induced by ∆
can be extended to a solution of the whole network? MIXED-SAT is shown to be
Π P
2 -complete. This result provides us with another proof of Π P
2 -completeness for
FC-consistency. Secondly, we mention in this chapter that FREC-DEDUCTION is
not decidable when R and E are both ﬁnite expansion sets (but their union is not a
ﬁnite expansion set). The proof of this result is in [BM02].
Examples throughout this chapter are inspired from the modelling of the SYSI-
PHUS-I case-study presented in [BGM99b] and [BGM99a].
Relations to other constraints.
As already noted for rules, our BG constraints have the same shape as the TGDs
(Tuple Generating Dependencies) in databases. Different forms of constraints can
be found in the conceptual graph literature. To the best of our knowledge, the most
general ones are the minimal/maximal descriptive constraints deﬁned in [DHL98].
BG-constraints are a particular case of these minimal descriptive constraints. A min-
imal descriptive constraint can be seen as a set of BG-constraints with the same
condition A; its intuitive semantics is “If A holds so must B1 or B2 or ... Bk.” A
BG satisﬁes a minimal descriptive constraint if it satisﬁes at least one element of
the set. Note that the “disjunction” does not increase complexity with respect to
BG-constraints. The proof of Theorem 11.3 (complexity of FC -CONSISTENCY)
can be used to show that consistency of minimal descriptive constraints is also Π P
2 -
complete. Particular cases of BG-constraints found in the CG literature are the topo-
logical constraints used by [MM97], which are indeed disconnected constraints. In
this paper non-validity intervals in the BG space (pre)-ordered by specialization are
deﬁned. A non-validity interval is a pair of BGs u and v, such that v ≤u. A graph G
is said to fall within this interval, if G ≤u and not G ≤v. Then it is said to be invalid.
This can be expressed in terms of BG-constraints in the following way: G is invalid
if it violates the disconnected constraint “If u holds, so must v.” Let us add that in

11.5 Bibliographic Notes
335
these CG works constraints are used to solely check the consistency of facts (as in
FC) and not of richer knowledge bases composed of rules (as in FRC) and they are
not integrated in more complex reasoning schemes (as in FEC or in FREC).
Concerning the combined use of rules and constraints, there are related works
about veriﬁcation of knowledge bases composed of logical rules (e.g., Horn rules).
Let us mention in particular [LR96] [LR98], in which constraints are TGDs, so
they have the same form as ours. However, the consistency notion is not deﬁned
in the same way. One major difference is that facts are not part of the knowledge
base, and the veriﬁcation notion for a knowledge base is deﬁned with respect to any
set of facts (satisfying some validity conditions). Finally, evolution rules could be
generalized into transformation rules, i.e., rules that add knowledge but may also
delete knowledge. As part of this programme, it would be interesting to consider the
work on graph transformation rules carried out in the graph grammar domain (cf.
for instance [Roz97]).

Chapter 12
Conceptual Graphs with Negation
Overview
Basic or simple graphs constitute the kernel of conceptual graphs. They can be used
as such, to represent facts or queries. They are also basic bricks for more complex
constructs, corresponding to more expressive conceptual graphs, for instance rules
(cf. Chap. 10). In this chapter, we consider the addition of negation to basic graphs.
Full conceptual graphs (FCGs) are obtained when negation is added without
restriction. FCGs are inspired from Peirce’s existential graphs, which form a dia-
grammatical system for logics. In the ﬁrst section, we ﬁrst brieﬂy present the main
characteristics of existential graphs, then deﬁne Sowa’s full conceptual graphs and
their translation to FOL with an extension of the mapping Φ deﬁned on BGs. By
adding negation to existential quantiﬁcation and conjunction, one obtains the full
expressive power of FOL. A translation Ψ from FOL formulas (without functions)
to FCGs is given. It is shown that for every closed FOL formula f, Φ(Ψ(f)) ≡f.
We mention a variant of FCGs, introduced by Dau, which in our opinion yields sim-
pler diagrams. Dau’s FCGs come with a model semantics and sound and complete
calculus with respect to FOL. The calculus for these two FCG models are both based
on the existential graph calculus. Peirce’s diagrammatical rules, thus FCG rules, are
not adapted to automated reasoning. Thus, we brieﬂy present a third FCG version
introduced by Kerdiles, who proposes an automated reasoning method that mixes a
tableau method with graph homomorphism checks.
FCGs extend BGs with negation, but in a way that does not suit the approach
to knowledge representation developed throughout this book. Sect. 12.1 thus only
brieﬂy outlines FCGs. In our opinion, full FOL is too complicated at the end-user
level, for building knowledge-based systems and understanding how they work, also
from a computational viewpoint. Most conceptual graphs applications are based on
BGs and extensions that keep their intuitive graphical appeal, as nested graphs, rules
and constraints. One advantage of these extensions is to help to distinguish between
different kinds of knowledge—a key issue in knowledge-based systems building.
Note however that these extensions only provide an implicit and very speciﬁc form
of negation.
337

338
12 Conceptual Graphs with Negation
In the second section, we study a limited form of negation, namely atomic nega-
tion. We will see that the graphical aspect is respected but further work is required to
obtain practical computational efﬁciency. Basic graphs plus atomic negation yield
polarized graphs (PGs), which are equivalent to the FOL fragment of existentially
closed conjunctions of positive and negative literals. We also study PG̸=s (resp.
BG̸=s), which are PGs (resp. BGs) added with inequality (also called difference).
We point out the equivalence of PG-DEDUCTION with the containment of conjunc-
tive queries with negation. It is proven that PG-DEDUCTION is Π 2
P-complete, as well
as BG̸=-DEDUCTION (hence PG̸=-DEDUCTION). Special cases for PG-DEDUCTION,
based on the notion of exchangeable literals, are exhibited. Algorithmic improve-
ments of the brute-force algorithm for PG-DEDUCTION are detailed. We then shift
from PG-DEDUCTION to querying PGs. We review both closed-world and open-
world assumptions. With open-world assumption, there may be no answer to a query
in a fact base, even if the query can be deduced from the base. We discuss the role
of the excluded-middle law in this distinction, and propose intuitionistic logic as a
way to translate the notion of answer. Furthermore, with this logic, PG-deduction
and query answering are NP-complete, thus negation is processed without overhead
complexity compared to BGs. We end with a note on new sources of complexity
when PG rules are considered.
12.1 Full Conceptual Graphs
We brieﬂy glance at existential graphs to highlight their main characteristics, and
then get to full conceptual graphs and their equivalence with FOL.
12.1.1 Existential Graphs: a Diagrammatical System for Logics
At the end of the 19th century, the logician Peirce introduced a diagrammatical
system for logics, i.e., existential graphs. Existential graphs are not graphs in the
classical graph theoretical meaning. They are simply diagrams. Thus, to avoid con-
fusion, the existential graphs are called existential diagrams. There are two levels of
existential diagrams: alpha diagrams, corresponding to propositional logic and beta
diagrams corresponding to FOL. There is also an unﬁnished third level, i.e., gamma
diagrams, which introduces various kinds of modalities.
Let us begin with alpha diagrams. An alpha diagram is built from two syntactical
constructs: proposition and cut representing negation. Asserting a diagram consists
of writing it down in an area, called the sheet of assertions. Juxtaposing several
propositions in this area corresponds to asserting them together, i.e., asserting their
conjunction. Encircling a proposition by an oval corresponds to cutting it from the
sheet of assertions, i.e., negating it. The line used to draw the oval is thus called a
cut. The space within a cut is the area of the cut. An area is said to be oddly (resp.

12.1 Full Conceptual Graphs
339
evenly) enclosed if it is enclosed by an odd (resp. even) number of cuts. For instance,
the ﬁrst alpha diagram D in Fig. 12.1 asserts a proposition p and the negation of “p
and the negation of q”. Translated into propositional logic it asserts the formula
(p∧¬(p∧¬q)), i.e., (p∧(p →q)).
q
q
q
D
p
p
q
p
Fig. 12.1 A proof with alpha rules
Existential graph calculus is composed of rules deﬁning diagrammatical trans-
formations. The alpha system is composed of ﬁve rules:
• Erasure: every evenly enclosed diagram can be erased;
• insertion: any diagram can be written in an oddly enclosed area;
• iteration: if a diagram occurs in an area, then a copy of this diagram can be written
in the same area or in any nested area which does not belong to the diagram;
• deiteration: any diagram whose occurrence could be the result of iteration may
be erased: any diagram may be erased if a copy of this diagram occurs in the
same area or in an enclosing area;
• double cut: any double cut may be inserted around or removed from any diagram
of any area (including the empty diagram).
Figure 12.1 shows a proof in the alpha system. It illustrates the modus ponens
reasoning: If p and p →q is true, then q is true. First, the diagram corresponding to
p∧(p →q) is asserted. Secondly, by the deiteration rule, the oddly enclosed propo-
sition p is erased and the second diagram corresponding to p ∧¬¬q is obtained.
Thirdly, the erasure rule deletes p. Forthly, q is obtained by the double cut rule.
In the ﬁrst-order version of diagrams, i.e., beta diagrams, symbols of predicate
with any arity are introduced and lines, called lines of identity, are used to repre-
sent objects, to connect a predicate to objects, as well as to express the identity
between objects. Several connected identity lines form a network, called a ligature,
and represent a single object. There are no variable names. The only—implicit—
quantiﬁer is the existential quantiﬁer, and the universal quantiﬁer is obtained as
the negation of the existential one. For instance, in Fig. 12.2, the diagram has ﬁve
predicate occurrences (let us say ﬁve literals) and several identity lines. Human is
a unary predicate, and hasParent is a binary predicate. A ﬁrst ligature connects the
argument of the literal with predicate Human, and the ﬁrst argument of both literals
with predicate hasParent (arguments are here implicitly ordered from left to right).

340
12 Conceptual Graphs with Negation
Human
hasParent
hasParent
Human
Human
Fig. 12.2 A beta existential diagram
It thus represents one object. Two other identity lines connect, respectively, the sec-
ond argument of a literal with predicate hasParent and the argument of a literal with
predicate Human. These lines are themselves connected by a line that crosses a cut
and thus denotes the non-identity of its extremities. Intuitively, this diagram asserts
that there is no Human who does not have as parents two distinct Human, i.e., every
Human has (at least) two parents who are Human. The associated formula could be
¬(∃x(Human(x)∧¬(∃y∃z(hasParent(x,y)∧hasParent(x,z)∧¬(y = z)))).
Beta rules extend the alpha rules with the treatment of identity lines.
12.1.2 Full Conceptual Graphs (FCGs)
Inspired by Peirce’s existential diagrams, Sowa deﬁnes full CGs (FCGs) from BGs
by adding boxes representing negation, and lines (the coreference links) represent-
ing equality of terms. In drawings, negation is represented by a rectangular box
preceded by a ¬ symbol. For instance, the FCG G in Fig. 12.3 says that the relation
r is transitive on entities of type t, i.e., for all x, y, z of type t, if r(x, y) and r(y, z),
then r(x, z). Its logical translation is as follows (cf. the next section for details):
Φ(G) = ¬(∃x ∃y ∃z (t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z)∧¬r(x,z)))
which is equivalent to: ∀x ∀y ∀z (t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z) →(r(x,z))).
G is equivalent to a bicolored BG rule (cf. Chap. 10). More generally, a λ-rule
R = (c1...cn)H ⇒C is equivalent to an FCG of form ¬[ H ¬C ] with a coreference
link between c1i and c2i for all i = 1...n.
Figure 12.4 shows how inequality is represented. Like the existential diagram in
Fig. 12.2, it says that “Every Human as (at least) two parents”, i.e., for every Human
x there is a Human y and there is a Human z, such that y and z are different and are
both parents of x. To express that y ̸= z, we have to say “No entity exists that is equal
to both y and z.” Note that Dau’s FCGs (cf. Sect. 12.1.6) provide a more readable
way of expressing difference.
Let us now formally deﬁne FCGs. BGs are ﬁrst combined within more complex
structures called graph propositions.

12.1 Full Conceptual Graphs
341
G
t
t
r
r
t
t
r
t
Fig. 12.3 A full CG
G
T
Human
Human
hasParent
hasParent
T
Human
Fig. 12.4 A full CG with inequality
Deﬁnition 12.1 (Graph proposition). A graph proposition on a vocabulary V is:
• either a box [G p1 ... pn], which contains a BG G on V (possibly empty) and
ﬁnitely many graph propositions p1 ... pn, n ≥0. This box is also called the
context of G.
• or a negated graph proposition ¬p. A negated context is a box preceded by a
negation.
All BGs composing a graph proposition are disjoint.
A box [G], where G is a BG, can be identiﬁed with G. A box [G0 [G1],...,[Gn]],
where each Gi is a BG can be identiﬁed with the disjoint sum of the Gi. More
generally, a box in which no negation occurs can be identiﬁed with the disjoint sum
of all BGs appearing in this box.

342
12 Conceptual Graphs with Negation
Note that these contexts should not be confused with the contexts of nested con-
ceptual graphs (cf. Chap. 9). Both kinds of contexts have radically different logical
translations.
Deﬁnition 12.2 (Domination). A context p dominates a context q if q is contained
in p or p = q. By extension, we say that a node of a BG G1 dominates a node of a
BG G2 if the context of G1 dominates the context of G2.
Deﬁnition 12.3 (FCG). A full conceptual graph (FCG) on a vocabulary V is a pair
(p,coref), where:
1. p is a graph proposition on V.
2. Let C(p), called the set of concept nodes of p, be the union of the concept node
set of all BGs composing p. coref is a binary symmetric relation over C(p), such
that (c1, c2) ∈coref implies that c1 dominates c2 or c2 dominates c1. (c1, c2) is
called a coreference link.
This deﬁnition calls for a few comments. Since FCGs are meant to represent
any formula of FOL, coreference links are allowed between concept nodes of any
label: Coreferent nodes are not necessarily compatible (as for coreference deﬁned
on SGs); in particular, there may be two individuals with different markers. Indeed,
in classical FOL, if a and b are two constants, they may be interpreted by the same
element of a domain, thus (a = b) is a well-formed formula; in other words, the
unique name assumption usually made in knowledge representation does not hold
here. Coreference links can link two nodes of the same context (since a context
dominates itself), or of nested contexts.
We now give a precise deﬁnition of the meaning of an FCG by way of a transla-
tion to FOL, which extends the mapping deﬁned for BGs.
12.1.3 Logical Semantics of FCGs
Let us ﬁrst point out that the universal type ⊤is translated in a special way. The
atom assigned to a concept node c = [⊤: m] is not ⊤(term(c)), where term(c) is
the term assigned to c, but the trivial equality term(c) = term(c). This ensures that
the graphs [⊤: ∗] or [⊤: a] are valid (i.e., the associated formulas are valid). By
convention, the empty conceptual graph is translated to true.
Brieﬂy explained, basic graphs occurring in the FCG are ﬁrst translated. Dis-
tinct variables are associated with distinct generic concept nodes. Each basic graph
G is interpreted as a conjunction of atoms α(G) (with the special processing of
⊤), without quantiﬁcation for the moment. Coreference links are processed in the
dominated context: Let (c1, c2) be a coreference link, with c1 dominates c2, and c2
belongs to G; the atom (term(c1) = term(c2)) is added to α(G). Let α′(G) be the
(free) formula obtained.

12.1 Full Conceptual Graphs
343
Now, given an FCG G = (p,coref), Φ(G) = Φ(p), and Φ(p) is deﬁned ac-
cording to the inductive deﬁnition of p. If p is a box [K p1 ... pn] then Φ(p) is
the existential closure of the conjunction of α′(K) and the Φ(pi). If p is a negated
proposition [¬p′], then Φ(p) = ¬Φ(p′). Let us consider the FCG G of Fig. 12.3.
Let us call G1 and G2 the basic graphs composing G, with G1 being the graph in the
outermost context. We ﬁrst assign distinct variables to generic nodes and free for-
mulas to G1 and G2 (cf. Fig. 12.5). α′(G1) = t(x1)∧t(y)∧t(z1)∧r(x1,y)∧r(y,z1)
x1
y
z1
z2
x2
G1
G2
G
t
r
r
t
t
t
t
r
Fig. 12.5 Variables assigned to the FCG of Fig. 12.3
α′(G2) = t(x2)∧t(z2)∧r(x2,z2)∧(x1 = x2)∧(z1 = z2)
The graph proposition underlying G has the following structure: ¬[G1¬[G2]].
The closed formula Φ([G2]) is ∃x2∃z2α′(G2). The closed formula Φ([G1¬[G2]]) is
∃x1 ∃y ∃z1(α′(G1)∧¬(∃x2∃z2α′(G2))). Finally, one obtains
Φ(G) = ¬(∃x1 ∃y ∃z1(t(x1)∧t(y)∧t(z1)∧r(x1,y)∧r(y,z1))∧¬(∃x2∃z2(t(x2)∧
t(z2)∧r(x2,z2)∧(x1 = x2)∧(z1 = z2)))).
This formula can be rewritten in a more classical way as:
Φ(G) = ∀x1 ∀y ∀z1((t(x1) ∧t(y) ∧t(z1) ∧r(x1,y) ∧r(y,z1)) →∃x2∃z2(t(x2) ∧
t(z2)∧r(x2,z2)∧(x1 = x2)∧(z1 = z2))).
It is equivalent to the following formula without equality:
Φ(G) = ∀x ∀y ∀z((t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z)) →r(x,z)).
The FCG in Fig. 12.4 is composed of three BGs, say G1, G2 and G3. G
has the structure ¬[G1¬[G2¬G3]]. Let α′(G1) = Human(x1), α′(G2) = (x2 =
x2) ∧Human(y) ∧Human(z) ∧hasParent(x2,y) ∧hasParent(x2,z), α′(G3) = (v =
v) ∧(y = v) ∧(z = v). The formula associated with the negated proposition ¬G3 is
Φ(¬G3) = ¬∃v((v = v)∧(y = v)∧(z = v)). Φ(¬G3) is equivalent to (y ̸= z). After
removal of trivial equalities, we obtain Φ(¬[G2¬G3]) = ¬(∃x2∃y∃z(Human(y) ∧
Human(z)∧hasParent(x2,y)∧hasParent(x2,z)∧(x1 = x2))). Finally, Φ(G) = ¬∃x1
(Human(x1)∧¬(∃x2∃y∃z(Human(y)∧Human(z)∧hasParent(x2,y)∧
hasParent(x2,z)∧(x1 = x2)))). It is equivalent to the following formula:
∀x(Human(x)→∃y∃z(Human(y)∧Human(z)∧hasParent(x,y)∧hasParent(x,z)
∧(y ̸= z))).
Conversely, every ﬁrst-order formula f (without function) can be translated into
a CG G, such that Φ(G) ≡f, as detailed in the next section.

344
12 Conceptual Graphs with Negation
12.1.4 Equivalence of CGs and FOL
FCGs are equivalent to FOL (without functions) in the sense that every FOL formula
can be translated into an FCG, say by a mapping Ψ, and, reciprocally, every FCG
can be translated to a FOL formula, by Φ, such that the composition of the two
translations keeps logical equivalence: For every FOL formula f, Φ(Ψ(f)) ≡f.
This kind of correspondence allows one to consider FCGs as a diagrammatical rep-
resentation of FOL formulas. For instance FCGs could be used at an interface level:
The user manipulates CGs, which are translated into FOL formulas, on which logi-
cal provers can be used to do reasoning, and the results are translated back into CGs.
Note however that for a formula f we only have equivalence between Φ(Ψ(f)) and
f and not equality. The question of whether using FCGs at an interface level only is
interesting at all is another issue we will not discuss.
Before deﬁning Ψ, we introduce another representation of FCGs. Indeed, as in
positive nested conceptual graphs, coreference links destroy the recursive structure
of conceptual graphs. They are not convenient for proofs of correspondence with
logical formulas. They can be replaced by special variables. Let V be a set of vari-
ables. Let T denote the set V ∪I. An FCG with variables over a vocabulary V and
a set of variables V is a triple (p,id,links) where p is a graph proposition, id is a
mapping which assigns to each node in C(p) its marker if it is individual. Otherwise
a new variable (similarly to Φ), links is a mapping which assigns to each node c in
C(p) a subset of T such that each variable in this set is associated with a concept
node that dominates c.
There are canonical translations between FCGs (with coreference links) and
FCGs with variables. Let G = (p,coref) be an FCG. To obtain an FCG with vari-
ables, deﬁne an arbitrary id (satisfying the condition in the deﬁnition of a CG with
variables) and for each c take links(c) = {id(c′)|c′ dominates c}.
Conversely, let G = (p,id,links) be a CG with variables. Deﬁne coref as follows:
coref = {(c,c′)| c ∈C(p), c′ ∈C(p), id(c′) ∈links(c) or id(c) ∈links(c′)}.
We are led to consider conceptual graphs with free variables. In such graphs, the
condition on links is weakened: If a variable x in links(c) is assigned to a concept
c′ then c′ dominates c. Thus, there are also variables which are not assigned to any
node. These variables are said to be free. Indeed, they are free in Φ(G). And if Ψ is
applied to a formula with free variables, these variables will stay free in the obtained
CG.
Let us now deﬁne Ψ. A conceptual graph vocabulary is obtained from a logical
language as follows. Concept types come from unary predicates and relation types
come from the other predicates. In addition, there is a new universal concept type,
denoted ⊤, which is the maximal concept type. All other concept types are pairwise
incomparable. The same holds for relation types. The individual marker set comes
from the constant set. In addition, there is an inﬁnite set of variables, including those
of the logical language.
Without loss of generality, we can assume that the FOL formulas considered are
built only with ∃, ∧, ¬ and equality, that they are closed, and that each variable is
bound exactly once. Ψ maps such a formula to a CG with variables.

12.1 Full Conceptual Graphs
345
The overall ideas are as follows. Each occurrence of variable or constant e is
translated into a concept node c of type t for an occurrence in an atom t(e); otherwise
(in an atom with an arity greater than one, in an equality or in a quantiﬁcation ∃e)
of type ⊤. If e is a variable x, then id(c) = x only if the occurrence of x considered
is ∃x, otherwise id(c) is a fresh variable, and links is used to relate c to x. If e is a
constant a, then id(c) = a and links is used only if the occurrence of a considered is
in an equality.
Given a formula f in appropriate form, Ψ(f) is recursively deﬁned as follows:
1. Ψ(∃x f ′) = [g⊤Ψ(f ′)] where g⊤is restricted to a concept node c = [⊤: ∗],
id(c) = x and links(c) = ∅;
2. Ψ(f1 ∧f2) = [∅Ψ(f1) Ψ(f2)]
3. Ψ(¬f ′) = ¬Ψ(f ′)
4. Ψ(t(x)) = [gt] where gt is restricted to a concept node c = [t : ∗], id(c) = z and
links(c) = {x} ; z is a fresh variable that does not occur in the formula nor in the
conceptual graph;
5. Ψ(t(a)) = [gt] where gt is restricted to a concept node c = [t : a], id(c) = a and
links(c) = ∅;
6. Ψ(x = y) = [g] where g is restricted to a concept node c = [⊤: ∗], id(c) = z and
links(c) = {x,y} ; z is a fresh variable that does not occur in the formula nor in
the conceptual graph;
7. Ψ(x = a) = [g] where g is restricted to a concept node c = [⊤: a], id(c) = a and
links(c) = {x};
8. Ψ(a = b) = [g] where g is restricted to two concept nodes ca = [⊤: a] and cb =
[⊤: b], id(ca) = a,id(cb) = b, links(ca) = {b} and links(cb) = {a};
9. Ψ(r(e1...en)) is the elementary star graph r(c1,...,cn) with a relation node of type
r and n concept nodes; each ci is of form [⊤: ∗] or [⊤: a], depending of whether
ei is a variable or a constant. If ei is a variable x, then ci = [⊤: ∗], id(ci) = z j and
links(ci) = {x} ; if ei is a constant a, then ci = [⊤: a], id(ci) = a and links(ci) = ∅
; the variables z j are fresh variables that do not occur in the formula nor in the
conceptual graph;
See for example Fig. 12.6, where f = Φ(G), with G is the FCG in Fig.12.3. In
the picture, variables have been replaced by coreference links.
If formula f is closed, then Ψ(f) is a well-formed CG with variables. We are
now able to state the equivalence between FCGs and FOL at a descriptive level:
Theorem 12.1 (Equivalence FCGs and FOL). Let V be a vocabulary and LV the
corresponding ﬁrst-order language (including equality). For each FOL formula f
on LV (possibly with free variables), one has: Φ(Ψ(f)) ≡f.
Hints for a proof. It can be checked that for each basic case in the deﬁnition of
Ψ one has Φ(Ψ(f)) ≡f. By induction on the depth of a formula f, it is proven that
Φ(Ψ(f)) ≡f for any formula f in appropriate form.
⊓⊔
This result shows that FCGs can represent any formula of ﬁrst-order logic with
equality (and without functions). Note however that the graph obtained by Ψ is
completely split into trivial BGs, which are star graphs or isolated concept nodes

346
12 Conceptual Graphs with Negation
z
T
x
T
T
t
T
t
T
t
T
T
T
T
y
r
r
r
Fig. 12.6 Ψ(f) with f = ¬(∃x ∃y ∃z(t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z)∧¬r(x,z)))
(compare for instance the FCGs in Fig. 12.3 and 12.6). It contains one concept node
per occurrence of a term in the formula. To obtain a “true” graph form, one has to
merge coreferent concept nodes (that is individual nodes with the same individual
marker or nodes related by links or coref) belonging to BGs in the same box. Up to
this transformation, CGs can be used as a graph representation for FOL.
12.1.5 FCG Calculus
FCGs are provided with a calculus inspired from Peirce’s alpha and beta systems. A
ﬁrst version of this calculus was proposed by Sowa, and some minor ﬂaws corrected
by Wermelinger. Wermelinger proved the soundness and completeness of his set
of rules (however the proof is not available in English, see bibliographical notes).
Soundness and completeness of the FCG calculus states that FCGs and FOL are
equivalent not only at a descriptive level but also at a reasoning level, i.e., given
two FCGs G and H, G can be derived from H by the FCG calculus if and only if
Φ(V),Φ(H) ⊨Φ(G) (equivalently: given two FOL formulas f and g in appropriate
form, f ⊨g if and only if Ψ(g) can be derived from Ψ(f) by the FCG calculus).
To the best of our knowledge, there is no automated reasoning tool that imple-
ments these rules. The main reason is certainly that Peirce’s rules, thus FCG rules,
are not suited to an automatic proof procedure. Indeed, the construction of a proof
with these rules strongly relies on human intuition. The rule of insertion, which can
be seen as the deduction of ¬(A ∧B) from ¬(A), leads especially to an inﬁnity of
possibilities, by allowing insertion of any graph at a place surrounded by an odd
number of negative contexts. Peirce’s (and FCG) proof system is not analytical, in

12.1 Full Conceptual Graphs
347
the sense it does not allow to build proofs by analyzing/ decomposing the input into
its successive components.
12.1.6 Dau’s FCGs
A notable variant of Sowa’s FCGs was proposed by Dau, who called them concept
graphs. Dau’s FCGs are based on Peirce’s cut notion rather than negative contexts.
Differing from negative contexts, cuts can be drawn around arbitrary subgraphs, and
not necessarily basic graphs. Furthermore, identity is represented by a binary equal-
ity relation, and this relation can be surrounded by a cut, like any other relation. In
a sense, concept graphs are thus more directly related to existential graphs. Figures
12.7 and 12.8 show concept graphs equivalent to the CGs in Fig. 12.3 and 12.4,
respectively. Cuts are drawn as rectangles with round corners. Non-numbered edges
are implicitly directed from left to right.
t
r
t
r
t
r
Fig. 12.7 A concept graph
=
Human
Human
Human
hasParent
hasParent
Fig. 12.8 A concept graph with inequality
Dau’s FCGs are provided with inference rules based on Peirce’s alpha and beta
rules. They have a set semantics, called “contextual semantics” since graphs are

348
12 Conceptual Graphs with Negation
interpreted in structures that are called power context families coming from Formal
Concept Analysis. They have also a translation Φ to ﬁrst-order logic. The rules
are proven to be sound and complete with respect to these semantics. An inverse
mapping Ψ from FOL formulas to concept graphs is given. The logical systems of
concept graphs and FOL are shown to be equivalent via these mappings.
As they are based on Peirce’s rules, concept graph rules are not analytical and,
like FCG rules, not adapted to automated reasoning.
12.1.7 Kerdiles’ FCGs
Kerdiles deﬁned FCGs with a slightly different deﬁnition of coreference links (ex-
tending the one we gave for SGs), and another extension of Φ, which maps (his)
FCGs to FOL without equality. He provided his FCGs with a sound and complete
tableau calculus.
In Kerdiles’ FCGs, coreference is not translated by equality but by multiple oc-
currences of the same term. The coreference relation is not only reﬂexive and sym-
metric, it is also transitive. It is actually an equivalence relation over generic nodes
occurring in the graph proposition. Moreover, in each coreference class, there is at
least one node that dominates all the others (there are possibly several such nodes).
In other words, among the contexts of these nodes, there is at least a dominating
context. These coreference conditions prevent some conﬁgurations of coreference
links such as the one in the FCG of Fig. 12.4, for instance, where coreference is not
transitive. And consequently, these full conceptual graphs can be mapped to FOL
without equality. Roughly said, the translation is done in three steps. First, associate
a term to each coreference class. The term assigned to a generic concept node is
that assigned to its coreference class. Then, for each BG K composing the FCG,
let x1 ... xq be variables associated with its concept nodes coreferent with strictly
dominating nodes, and let xq+1...xs be variables associated with the other generic
nodes. Let α(K) be the conjunction of atoms associated with K. Finally, construct
the whole formula in the following inductive way: If the graph proposition of G
is a box p = [K p1 ... pn], then Φ(G) = ∃xq+1...xs(α(K) ∧Φ(p1) ... ∧Φ(pn))
(note that the variables, if any, corresponding to nodes strictly dominated are not yet
quantiﬁed). If the graph proposition of G is a negated proposition [¬p], Φ(G) is the
negation of Φ(p).
Example. The formula associated with the FCG G in Fig. 12.3 is constructed as
follows. First let x, y and z be the variables respectively assigned to each coreference
class.
α(G1) = t(x)∧t(y)∧t(z)∧r(x,y)∧r(y,z)
α(G2) = t(x)∧t(z)∧r(x,z)
Φ([G2]) = α(G2) since all nodes of G2 are coreferent with strictly dominating
nodes.
Φ([G1¬[G2]]) = ∃x∃y∃z(α(G1)∧¬α(G2)).
Φ(G) = ∀x∀y∀z(α(G1) →α(G2)).

12.1 Full Conceptual Graphs
349
An interesting point is that Kerdiles’ FCGs are provided with a tableau calculus,
thus a potentially efﬁcient procedure, which is sound and complete. Moreover, the
unique aspect relative to other logical tableau methods is that BGs are considered
as basic constructs, thus are never decomposed into more elementary elements. A
branch of a tableau is said to be closed if it contains a node ¬[G] where G is a
BG, and there is a BG H that is possibly obtained by summing several graphs of
the branch, such that G can be mapped into the normal form of H. We just give an
example illustrating the role of BG homomorphism in this method.
G
F
G
GF
Q
F
Q
Q
t : a
t : b
t : a
t : c
t : b
from G
t : b
t : a
t : b
t : a
r
t
r
r
r
r
r
r
t
t
t
r
t
t
r
Fig. 12.9 A tableau
Let G be the BG of Fig. 12.3. Let F be the BG [t : a] →(r) →[t : c] →(r) →[t : b].
And Q is the BG [t : a] →(r) →[t : b]. One wants to prove that Q is deducible from
G (a rule) and F (a fact), i.e., prove that ((G∧F) →Q) is valid. Figure 12.9 shows
a closed tableau for its negation, (G ∧F ∧¬Q). First, this formula is decomposed
into G, F and ¬Q, on the same branch. Then, from G, which is of form ¬[g1g2], one
deduces ¬g1 OR ¬g2, thus splits the branch. Coreferent nodes are instantiated by

350
12 Conceptual Graphs with Negation
the same constant, which in this case may be any constant (new or occurring in the
tableau). The left branch is closed because the leaf graph is the negation of a BG
which maps to F. The right branch is also closed because graph ¬Q is the negation
of a BG that maps to the leaf graph (actually ¬Q is the negation of the leaf graph).
Thus the tableau is closed, which proves that (G ∧F ∧¬Q) is unsatisﬁable (thus
(G∧F →Q) is valid).
12.2 Conceptual Graphs with Atomic Negation
Basic or simple conceptual graphs express conjunctions of positive knowledge. As
explained in the preceding sections, FCGs extend them with negation, but in a way
that does not comply with our approach. We therefore consider here a basic but fun-
damental form of negation, namely atomic negation. The scope of atomic negation
is an atom. Instead of considering conjunctions of atoms, we consider now conjunc-
tions of literals, i.e., atoms or negation of atoms, and keep the existential quantiﬁer.
Atomic negation allows us to express knowledge of form “this relation does not
hold between these entities,” “this entity does not have that property” or “this entity
is not of that type.”
12.2.1 Polarized Graphs
Beside positive relation nodes, we now have negative relation nodes. Such graphs
are said to be polarized. Below we deﬁne polarized graphs as extensions of BGs.
Coreference will be considered with its opposite, i.e., difference, in Sect. 12.2.2.
Negation is deﬁned on relation types only, but as discussed hereafter, the deﬁnitions
and results can be easily extended to concept types.
Deﬁnition 12.4 (Polarized Graph (PG)). A polarized graph (PG) is deﬁned sim-
ilarly to a BG (cf. Deﬁnition 2.2) except that relation nodes are labeled not only by
a type but also by a polarity (denoted + or −). A positive (resp. negative) relation
node is labeled by +r (resp. −r), where r is a relation type. +r can also be noted r.
A negative relation node with label −r and arguments (c1...ck) expresses that
“there is no relation of type r between c1...ck” (or if k = 1, “c1 does not possess the
property r”); it is logically translated by Φ into the literal ¬r(e1...ek), where ei is
the term assigned to ci.
We denote by +r(c1...ck) (resp. −r(c1...ck)) a positive (resp. negative) relation
node with type r and c1...ck being the list of its arguments. FOL{∃,∧,¬a} denotes
the extension of FOL{∃,∧} to negative literals. Translations between BGs and FOL
{∃,∧} presented in Sect. 4.3 are naturally extended to translations between PGs and
FOL{∃,∧,¬a}. PGs are thus equivalent to the FOL{∃,∧,¬a} fragment.

12.2 Conceptual Graphs with Atomic Negation
351
Negation on Concept Types
Although we will not deal with it in this chapter, negation in concept labels can be
deﬁned in a similar way. If conjunctive concept types are considered, a concept node
is labeled by a set {∼t1... ∼tk}, where ∼can be + or −and ti is a primitive concept
type. A concept node labeled by −t is interpreted as “there is an entity that is not of
type t,” and not as “there is not an entity of type t,” i.e., we keep an existential in-
terpretation. Since the universal concept type is supposed to represent all entities, it
cannot be negated. Let us point out that, although negation on concept types is inter-
esting from a modeling viewpoint, it does not add expressiveness. Indeed, concept
types can be processed as unary relation types with a transformation similar to the
mapping from bicolored rules to λ-rules (cf. Sect. 10.1.2). More precisely, consider
BGs on a vocabulary V. Let V′ be the vocabulary built by translating all concept
types, except the universal type ⊤, into unary relation types keeping the same par-
tial order. The concept type set of V′ is composed of the single type ⊤. Then, BGs
on V can be transformed into BGs on V′, while preserving homomorphisms: Each
concept node with label l = ({∼t1... ∼tk},m) is translated into a concept node with
label (⊤,m) and, for each ∼ti in l, with ti ̸= ⊤, one incident relation node with label
∼ti. A simple and uniform way of processing negation on concepts and relations
thus involves applying the transformation sketched above, processing the obtained
graphs with the algorithms of this chapter and, if needed, applying the reverse trans-
formation to present the results. Another solution is to adapt the deﬁnitions and
algorithms presented hereafter, which is straightforward.
Since negation is introduced, a PG can be inconsistent.
Deﬁnition 12.5 (inconsistent PG). A PG is said to be inconsistent if its normal
form contains two relation nodes +r(c1...ck) and −s(c1...ck) with contradictory la-
bels, i.e., with r ≤s. Otherwise it is said to be consistent.
The following property is immediate:
Property 12.1. For any PG G on a vocabulary V, G is inconsistent iff Φ(V) ∪
{Φ(G)} is inconsistent.
Proof. (⇒): trivial. (⇐): see that Φ(V) cannot be inconsistent since it only contains
positive information. Now consider the clausal form of Φ(V) ∪{Φ(G)}: The only
way to deduce the empty clause from it is to have two clauses of form r(e) and ¬s(e)
with same argument list e and r ≤s (which allows us to obtain ¬(r(e)) from ¬s(e)
and Φ(V)).
⊓⊔
The order on relation labels is extended as follows: We set −r1 ≤−r2 if r2 ≤r1.
Deﬁnition 12.6 (Extended order on relation labels). Given two relation labels l1
and l2, l1 ≤l2 if, either l1 and l2 are both positive labels, say l1 = r1 and l2 = r2, and
r1 ≤r2, or l1 and l2 are both negative labels, say l1 = −r1 and l2 = −r2, and r2 ≤r1.
Given this extended order on relation labels, homomorphism can be used without
changing its deﬁnition. It is still logically sound, as expressed by the next property
(which can be seen as a corollary of the forthcoming Theorem 12.2):

352
12 Conceptual Graphs with Negation
Property 12.2. Given two PGs G and H on a vocabulary V, if there is a homomor-
phism from G to H then Φ(V),Φ(H) |= Φ(G).
H
d1
c1
G
−p
t:c
r
t:b
r
+p
t:a
1
2
2
t
r
t
+p
−p
2
1
x
y
1
Fig. 12.10 Atomic negation and homomorphism (1)
H
G
t
t
t:a
t:b
t:d
t:c
2
2
1
2
t
1
2
1
1
r
r
−r
−r
Fig. 12.11 Atomic negation and homomorphism (2)
The bad news is that homomorphism is no longer complete (even if the target
graph is in normal form), as illustrated by Figs. 12.10 and 12.11. In Fig. 12.10,
the formulas assigned to G and H by Φ (here we ignore the atoms associated
with concept nodes) are respectively Φ(G) = ∃x∃y(p(x) ∧¬p(y) ∧r(x, y))) and
Φ(H) = p(a) ∧r(a,b) ∧r(b,c) ∧¬p(c). Φ(G) can be deduced from Φ(H) using
the tautology p(b) ∨¬p(b) (indeed, every model of Φ(H) satisﬁes either p(b) or
¬p(b); if it satisﬁes p(b), then x and y are interpreted as b and c; in the opposite
case, x and y are interpreted as a and b; thus every model of Φ(H) is a model of
Φ(G)). In the second example, illustrated by Fig. 12.11, the target graph is com-
posed of two connected components, one containing positive information only, the
other negative information only. There is no homomorphism from G to H, even if
Φ(G) can be deduced from Φ(H), using the tautology (r(b,c)∨¬r(b,c)).
More generally, negation introduces disguised disjunctive information that can-
not be taken into account by homomorphism. This disjunctive information is related
to the law of the excluded-middle which holds in classical logic: Given a proposi-
tion P, either P is true, or ¬P is true. This leads to reasoning by cases: If a relation is
not asserted in a fact, either it is true or its negation is true. We thus have to consider
all ways of completing the knowledge asserted by a PG. Let us look again at the
example in Fig. 12.10. H does not say whether the unary relation p holds for b. We

12.2 Conceptual Graphs with Atomic Negation
353
thus have to consider two cases: Either a relation node with label +p or a relation
node with label −p can be attached to b. Let H1 and H2 be the graphs respectively
obtained from H (see Fig. 12.12). There is a homomorphism from G to H1 and there
is a homomorphism from G to H2. We conclude that G can be deduced from H.
H1
H2
G
r
r
−p
+p
−p
r
r
2
+p
−p
r
+p
+p
−p
t:b
t:a
t:c
2
1
2
1
t
t:c
2
t
t:b
t:a
1
2
1
1
c1
d1
Fig. 12.12 When the law of the excluded-middle intervenes
The next deﬁnition speciﬁes the notion of completion of a PG relative to a vo-
cabulary V.
Deﬁnition 12.7 (Complete PG). A complete PG on a vocabulary V with relation
type TR is a consistent (normal) PG satisfying the following completion condi-
tion: For each relation type r of arity k in TR, for each k-tuple of concept nodes
(c1,...,ck), where c1,...,ck are not necessarily distinct nodes, there is a relation
+s(c1,...,ck) with s ≤r or (exclusive) there is a relation −s(c1,...,ck) with r ≤s.
A PG is complete with respect to a subset of relation types T ⊆TR if the completion
condition considers only elements of T. If a PG Gc that is complete with respect to
T is obtained by adding relations to a graph G, it is called a T-completion of G (or
simply a completion of G if T is implicit).
Property 12.3. If a relation node is added to a complete PG, either this relation node
is redundant (There is already a relation node with the same argument list and a
label less or equal to it) or it makes the PG inconsistent.
A complete PG is obtained from a consistent PG G by repeatedly adding positive
and negative relations as long as adding a relation brings new information and does
not yield an inconsistency. Since a PG is a ﬁnite graph deﬁned over a ﬁnite vocabu-
lary, the number of different complete PGs that can be obtained from it is ﬁnite. We
can now deﬁne the deduction problem on PGs in terms of completions.
Deﬁnition 12.8 (PG-DEDUCTION). PG-DEDUCTION takes two PGs G and H as in-
put, with H being consistent, and asks whether G can be PG-deduced from H, i.e.,
whether each complete PG Hc obtained from H is such that G ⪰Hc.

354
12 Conceptual Graphs with Negation
The following theorem expresses that PG-DEDUCTION is sound and complete
with respect to the deduction in FOL.
Theorem 12.2. Let G and H be two PGs deﬁned on a vocabulary V. H is a consis-
tent PG. Then G can be PG-deduced from normal(H) if and only if Φ(V),Φ(H) ⊨
Φ(G).
To prove this theorem, we ﬁrst need to extend to PGs some deﬁnitions concerning
BGs. The notion of L-substitution (cf. Deﬁnition 4.8) is extended in a straightfor-
ward way:
Deﬁnition 12.9 (Extension of L-substitution). Let f and g be two formulas of
FOL{∃,∧,¬a} on an ordered language L, with vars(g)∩vars(h) = ∅. A L-substitut-
ion σ from f to g is a substitution such that:
• for all positive literals p(e1,...,ek) in f, there is a positive literal q(σ(e1,...,ek))
in g such that q ≤L p,
• for all negative literals ¬ p(e1,...,ek) in f, there is a negative literal ¬ q(σ(e1,...,
ek)) in g such that q ≥L p.
A good assignment is deﬁned as follows.
Deﬁnition 12.10 (Good assignment). Given a model M = (D,δ) of a logical lan-
guage L, a good assignment α of a FOL{∃,∧,¬a} formula f on L to M is a mapping
α from the terms of f to D, which maps each constant c to δ(c), such that for all
positive literal p(e1,...,ek), α(e1,...,ek) ∈δ(p) and for all negative literal ¬p(e),
α(e) ̸∈δ(p).
It is immediately checked that the equivalence between L-substitution and ho-
momorphism is preserved (extension of Property 4.3).
Property 12.4 (L-substitution and PG Homomorphism Equivalence). Let G and H
be two PGs on a vocabulary V. There is a homomorphism from G to normal(H)
iff there is a LV-substitution from Φ(G) to Φ(H), where LV is the ordered lan-
guage associated with V. Let f and g be two FOL{∃,∧¬a} formulas on an ordered
language L. There is a L-substitution from f to g if and only if there is a homomor-
phism from f2g(f) to f2g(g) (where f2g is the natural extension of the mapping
deﬁned in Sect. 4.3.3.1).
We can now prove Theorem 12.2.
Proof. ⇒Assume that G can be PG-deduced from normal(H) (actually, that the
target graph is normal is not needed in this direction). Let M be a model of
Φ(V),Φ(H). By deﬁnition of complete graphs, there is a complete graph, say H′,
obtained from normal(H), such that M is a model of Φ(H′). By hypothesis there is
a homomorphism from G to H′, thus a LV-substitution from Φ(G) to Φ(H′). The
composition of the assignment from Φ(H′) to M and this LV-substitution deﬁnes a
good assignment from Φ(G) to M. M is thus a model of Φ(G).
⇐Let H′ be any complete PG obtained from normal(H).
Consider M, the canonical model (D,δ) of Φ(H′), in which

12.2 Conceptual Graphs with Atomic Negation
355
• D is the set of terms in Φ(H′),
• δ is the identity over constants and for each k-ary predicate q in L, (e1,...,ek) ∈
δ(q) if and only if there is p(e1,...,ek) in Φ(H′) with p ≤q.
Add the appropriate literals to M such that: For any predicate p of arity k, if
(e1,...,ek) ∈δ(p) then for all q ≥p, (e1,...,ek) ∈δ(q).
M is a model of Φ(H) and Φ(V). Thus it is a model of Φ(G) by hypothe-
sis. There is thus a good assignment from Φ(G) to M, which is here a mapping
from Φ(G) to Φ(H′). This mapping is a LV-substitution from Φ(G) to Φ(H′).
There is thus a homomorphism from G to normal(H′) = H′ (since H′ is built from
normal(H), it is in normal form).
⊓⊔
From now on, we can thus make no distinction between PG-deduction and logical
deduction on the associated formulas, and we will sometimes simply say “deduc-
tion.”
Algorithm 27 presents a brute-force algorithm scheme for PG-DEDUCTION. An
immediate observation for generating the completions Hc is that we do not need to
consider all relation types but only those appearing in G. The algorithm generates
all complete PGs relative to this set of types and for each of them checks whether
G can be mapped to it. A complete graph to which G cannot be mapped can be
seen as a counter-example to the assertion that G is deducible from H. Algorithmic
improvements are studied in Sect. 12.2.6.
Algorithm 27: PG-Deduction(G,H)
Input: PGs G and H, such that H is consistent and normal
Output: true if G can be deduced from H, false otherwise
begin
Compute H the set of complete PGs obtained from H with respect to relation types in G
forall Hc ∈H do
if there is no homomorphism from G to Hc then
return false ;
// Hc is a counter-example
return true
end
12.2.2 Handling Coreference and Difference
In this section, we introduce inequality, also called difference, as a special element
of the CG syntax, called a difference link. A difference link between two nodes c1
and c2 expresses that c1 and c2 represent distinct entities. In Fig. 12.13, difference
links are represented by crossed lines. Due to the unique name assumption, there is
an implicit difference link between nodes having distinct individual markers. For-
mally, difference is added to PGs (or only to BGs or SGs) as a symmetrical and

356
12 Conceptual Graphs with Negation
antireﬂexive relation on concept nodes, called dif. Let us recall that coreference is
represented in SGs as an equivalence relation on concept nodes added to BGs. Sim-
ilar to difference links, we can distinguish between implicit coreference links that
relate concept nodes with the same individual marker, and other links, which are
explicit coreference links. In the next deﬁnitions, we distinguish between the set of
explicit coreference and difference links (Ecore f and Edi f ) and the relations (coref
and di f) obtained from explicit and implicit links. Finally, let us point out that, since
we consider coreference, we also consider conjunctive concept types.
T 
T 
T 
r
r
T 
T 
r
G
H
1
1
2
2
2
1
Fig. 12.13 PG̸=: G is deducible from H
A PG̸= is a PG added with coreference and difference. A BG̸= is a BG added
with coreference and difference. It is a particular PG̸= in which all relation labels
are positive. It can also be seen as an SG added with difference.
Deﬁnition 12.11 (PG̸=, BG̸= ). A PG (resp. BG) with inequality, notation PG̸=
(resp. BG̸=) is a 6-tuple (C, R, E, l, Ecore f , Edi f ), where:
• (C,R, E, l) is a PG (resp. BG),
• Ecore f and Edi f are sets of speciﬁc edges between distinct nodes of C.
Deﬁnition 12.12 (coref relation). The relation coref on a PG̸= G = (C,R,E,l,
Ecore f ,Edi f ) is the equivalence relation over C deﬁned as the reﬂexive and transitive
closure of the union of:
• TShe symmetrical relation induced by Ecore f over C;
• implicit links due to multiple occurrences of individual markers: {{c,c′} | c,c′ ∈
C, marker(c) ̸= ∗and marker(c) = marker(c′)};
Before deﬁning di f, we introduce a relation Di f on the equivalence classes of
coref.
Deﬁnition 12.13 (Di f relation). The relation Di f on a PG̸= G = (C, R, E, l,Ecore f ,
Edi f ) is the symmetrical relation over equivalence classes of coref deﬁned as the
union of:
1. The symmetrical relation induced by Edi f : {{C1,C2} | there are c1 ∈C1, c2 ∈C2
with {c1,c2} ∈Edi f },
2. implicit links due to unique name assumption: {{C1,C2} | there are c1 ∈C1, c2 ∈
C2 with marker(c1) ̸= ∗, marker(c2) ̸= ∗and marker(c1) ̸= marker(c2)},
3. implicit links due to incompatible types: {{C1,C2} | there are c1 ∈C1, c2 ∈C2
such that type(c1) and type(c2) are incompatible },

12.2 Conceptual Graphs with Atomic Negation
357
4. implicit links due to contradictory relations: {(C1,C2) | there are c1 ∈C1, c2 ∈
C2, (c1,c2) /∈coref and +r(d1,...,di,c1,di+1,...,dq),−s(e1,...,ei,c2,ei+1,...,
eq) ∈G such that r ≤s and for all i ∈{1..q}, one has {di,ei} ∈coref}.
Set 4 is illustrated by Fig. 12.14: The relation nodes have opposite labels and
coreferent arguments, except for c and c′; making c and c′ coreferent would lead to
an inconsistent graph. Set 4 can be removed when only BG̸= are considered.
Deﬁnition 12.14 (di f relation). The relation di f on a PG̸= G = (C, R, E, l, Ecore f ,
Edi f ) is the symmetrical relation over C deﬁned as the cartesian product of all pairs
of coref classes belonging to Di f (i.e. if {C1,C2} ∈Di f then for all c1 ∈C1 and
c2 ∈C2, {c1,c2} ∈di f).
T 
T 
T 
T 
r
−r
3
3
2
2
1
1
=
c
c’
Fig. 12.14 Implicit Di f link
For a PG̸= in normal form, one has di f = Di f. A PG̸= is consistent if coref
and di f are not contradictory (i.e. coref ∩di f = ∅). Note that di f and Di f are then
antireﬂexive.
The FOL formula assigned to a PG̸= translates coreference by assigning the same
term (variable or constant) to coreferent nodes, or equivalently, by adding an atom
e1 = e2 for each pair of coreferent nodes with assigned terms e1 and e2. dif is nat-
urally translated by ̸= (i.e. ¬ =). Every consistent PG̸= possesses a normal form
which is obtained by merging all concept nodes of the same coref class and is logi-
cally equivalent to it.
Let us recall how coreference is processed by homomorphism. A homomor-
phism π from an SG G to an SG H has to respect coreference: For all nodes c1
and c2 of G, if {c1,c2} ∈corefG then {π(c1),π(c2)} ∈corefH (where π(c1) and
π(c2) can be the same node). Completeness is obtained only if the target SG is in
normal form. Recall that homomorphism can be replaced by coref-homomorphism
to ensure completeness without this condition. If G and H are BG̸=s (or PG̸=s),
homomorphism has to respect the dif relation as well: For all nodes c1 and c2
in G, if {c1,c2} ∈di fG then {π(c1),π(c2)} ∈di fH. Concerning completeness,
the same discussion as that put forward for negative relations on the use of the
law of excluded middle can apply, as illustrated by Fig. 12.13. Formulas assigned
to H and G are respectively Φ(H) = ∃x∃y∃z (r(x, z) ∧r(y, z) ∧¬(x = y))) and
Φ(G) = ∃x∃y (r(x, y)∧¬(x = y)). Φ(G) can be deduced from Φ(H), using the law
of excluded middle for x = z (i.e., either x = z or x ̸= z) and/or y = z, while there

358
12 Conceptual Graphs with Negation
is no homomorphism from G to H. Difference thus introduces reasoning by cases
as negative relations. Let us say that a consistent BG̸= H is complete if for all c,c′
distinct concept nodes in H, either {c,c′} ∈di fH or {c,c′} ∈corefH. We will also
say that it is di f-complete. A PG̸= is complete if it is complete as a PG (which is
relative to relation types) and complete as a BG̸=, i.e., di f-complete.
Algorithm 28 is a brute-force algorithm computing all di f-completions obtain-
able from H. Computing completions incrementally during deduction checking
would of course be more efﬁcient (see Sect. 12.2.6 about algorithmic improve-
ments). Note that, in the subalgorithm CompleteRec, case 1 updates coref but may
also involve updating di f (due to potential contradictory relations, as illustrated in
Fig. 12.14), while case 2 updates di f only.
Algorithm 28: AllCompleteGraphsForDif(H)
Input: a BG̸= or a PG̸= H
Output: the set of all dif-completions from H
begin
CompleteSet ←∅
CompleteRec(H) // see Algorithm 29
return CompleteSet
end
Algorithm 29: CompleteRec(H) subalgorithm of Algorithm 28
Input: a BG̸= or a PG̸= H
Output: computes recursively the dif-completions of H and adds them to CompleteSet
begin
if di f ∪core f is complete then
// all pair of distinct concept nodes are in di f or core f
CompleteSet ←CompleteSet ∪{H}
else
Choose two (distinct) nodes c,c′ in H such that {c, c′} ̸∈di f ∪core f
// case 1: make them coreferent
let H1 be obtained from H by adding {c,c′} to Ecoref
CompleteRec(H1)
// case 2: make them ‘‘different’’
let H2 be obtained from H by adding {c,c′} to Edif
CompleteRec(H2)
end
A brute-force algorithm for BG̸=-DEDUCTION is obtained from the brute-force
algorithm for PG-DEDUCTION (Algorithm 27), by replacing H by the set of all
dif-completions of H. A brute-force algorithm for PG̸=-DEDUCTION is obtained by
combining the two kinds of completion.

12.2 Conceptual Graphs with Atomic Negation
359
12.2.3 PG-DEDUCTION and Equivalent Problems
As pointed out above, PGs are equivalent to the FOL{∃,∧,¬a} fragment of ﬁrst-
order-logic. Without loss of generality, we can consider formulas in prenex form,
i.e., such that all (existential) quantiﬁers are in front of the formula. PG-DEDUCTION
is thus equivalent to the following problem:
FOL{∃,∧,¬a}-DEDUCTION
Input: existentially closed conjunctions of (positive and negative) literals f1 and f2.
Question: Does f1 |= f2 hold, i.e. is f2 a consequence of f1?
In Chap. 5, we show that the containment problem for positive conjunctive
queries (CQs) is equivalent to BG-DEDUCTION. Let us now consider conjunctive
queries with atomic negation (CQNs), i.e., queries with the following form:
q = ans(u) ←r1(u1), ... rn(un),¬s1(y1), ... ¬sm(ym)
n ≥1, m ≥0
Given a CQN q deﬁned as above and a database instance D, an answer to q in D is a
tuple µ(u), where µ is a substitution of variables in q by constants in D such that for
any i in {1,...,n}, µ(ui) ∈D(ri) and for any j in {1,...,m}, µ(yj) ̸∈D(s j) (in other
words, the query evaluation makes the closed-world assumption, see Sect. 12.2.7).
The containment problem for conjunctive queries with atomic negation is deﬁned
as follows:
CONTAINMENT OF CONJUNCTIVE QUERIES WITH NEGATION (CQNC)
Input: two conjunctive queries with negation q1 and q2.
Question: Is q1 contained in q2 (q1 ⊑q2), i.e., is the set of answers to q1 included in
the set of answers to q2 for any database D?
A CQN on a schema can be naturally seen as a PG on a ﬂat vocabulary, and
reciprocally, by a simple extension of the transformations q′2b and b2q′ detailed in
Chap. 5. Similarly to the extension of BG homomorphism to PG homomorphism,
we can extend the notion of positive query homomorphism to CQN homomorphism
and deﬁne the notions of a consistent CQN and a complete CQN. The following
property expresses the containment of CQNs in a form similar to PG deduction.
The equivalence of CQNC and PG-DEDUCTION follows immediately.
Property 12.5. Given two CQNs q1 and q2 (with q1 being consistent), q1 ⊑q2 if and
only if for each complete query qc
1 generated from q1, there is a CQN homomor-
phism from q2 to qc
1.
Proof. (⇒) Each complete query qc
1 generated from q1 corresponds to a database
(one just has to remove negative literals and the literal ans(u)) that contains a canon-
ical answer to q1: tuple u. By hypothesis, u is also an answer to q2; thus there is a
CQN homomorphism h from q2 to qc
1.
(⇐) By contradiction. Suppose that q1 ̸⊑q2, then there is a database D and a
tuple w such as w ∈q1(D) but w ̸∈q2(D); there is thus a CQN homomorphism h1
from q1 to ans(w) ←Dc−, where Dc−is the negative completion of D obtained
by adding solely negative literals, but there is no CQN homomorphism from q2 to
ans(w) ←Dc−. Let qc
1 be a complete query built from q1 in the following way: For

360
12 Conceptual Graphs with Negation
each relation r in R of arity k and each k-tuple (t1,...,tk) of terms in q1, add a
literal with predicate r, arguments (t1,...,tk) and the same polarity as the literal l
in Dc−with predicate r and arguments (h1(t1),...,h1(tk)). Since Dc−is complete
and consistent, l exists and is unique. By construction, there is a homomorphism hc
from qc
1 to ans(w) ←Dc−. By hypothesis, there is a CQN homomorphism h2 from
q2 to qc
1. Hence, hc ◦h2 is a CQN homomorphism from q2 to ans(w) ←Dc−, which
leads to a contradiction.
⊓⊔
One can identify the notions of substitution on FOL{∃,∧,¬a} formulas (in
prenex form), PG homomorphism and CQN homomorphism. Similarly, one can
identify the notions of canonical model of a FOL{∃,∧,¬a} formula, completion of
a consistent PG and completion of a consistent CQN.
12.2.4 Complexity of PG-DEDUCTION
Theorem 12.3 (PG-DEDUCTION Complexity). PG-DEDUCTION is Π P
2 -complete.
Proof. The way PG-DEDUCTION is stated makes it clear that it is in Π P
2 . Indeed,
it corresponds to the language L = {x | ∀y1 ∃y2 R(x, y1, y2)}, where x encodes an
instance (G,H) of the problem and (x, y1, y2) ∈R if and only if y1 is a completion
of H and y2 encodes a homomorphism π from G to this completion. Note that a
completion has a size exponential in the maximum arity of a relation, but without
loss of generality we can assume that this size is bounded by a constant and even by
2, as n-ary relations can be polynomially transformed into binary relations.
The Π P
2 -completeness is proven by reduction from the following Π P
2 -complete
problem:
GENERALIZED RAMSEY NUMBER [SU02]
Input: an undirected graph K = (V,E), where V is the set of vertices and E the set
of edges; a partial two-coloring σ of E (i.e., a partial function σ : E →{0,1}); and
an integer k.
Question: Does every total extension of σ produce a one-color k-clique1 (i.e., a
k-clique with all edges colored 0 or with all edges colored 1)?
Let (K = (V,E),σ,k) be an instance of GENERALIZED RAMSEY NUMBER. We
build two (consistent) PGs G and H on a very ﬂat vocabulary with set of relation
types {r,d, p}, where r and d are binary relations and p is a unary relation. All
concept nodes are labeled by (⊤,∗).
The set of concept nodes of G is C1 ∪C2 where C1 and C2 are copies of the set
of edges of a k-clique (thus in each Ci there is one concept node x for each edge ab
of a k-clique). There is a r(x,y) if {x,y} ⊆C1 or {x,y} ⊆C2, and x and y represent
distinct edges with a common endpoint in the k-clique. There is a d(x,y) between
all distinct concept nodes x and y in G. There is a p(x) if x ∈C1 and there is a −p(x)
if x ∈C2.
1 A clique is an undirected graph with all edges between distinct vertices. A k-clique is a clique
with k vertices.

12.2 Conceptual Graphs with Atomic Negation
361
Intuitively: G is composed of two components, C1 and C2; for each component,
the concept nodes and the relation nodes labeled by r represent the intersection
graph of the edges of a k-clique; distinct concept nodes anywhere in G are related
by d; the concept nodes in C1 are marked by p, those in C2 are marked by −p. p
can be seen as denoting the color 0 and −p the color 1.
The set of concept nodes of H is C′
1 ∪E ∪C′
2 where, as for G, C′
1 and C′
2 are
copies of the set of edges of a k-clique; E is a copy of the set of edges in G. There
is a r(x,y) if {x,y} ⊆C′
1 or {x,y} ⊆C′
2 or {x,y} ⊆E, and x and y represent distinct
edges with a common endpoint in the k-clique. There is a d(x,y) between distinct
nodes x and y in C′
1 ∪E and between distinct nodes x and y in E ∪C′
2 (actually, it is
not necessary to have d in both directions between C1 and C2 in G, and between C′
1
and E and E and C′2 in H: Instead, d could lead from C1 to C2 in G, and from C′
1 to
E and from E to C′2 in H). There is a p(x) if x ∈C′
1, or x ∈E and σ(x) is deﬁned
and equal to 0; there is a −p(x) if x ∈C′
2, or x ∈E and σ(x) is deﬁned and equal to
1.
Intuitively: H has the same components C1 and C2 as G but, in addition, there is
a component E representing the intersection graph of the edges of G. The elements
in E are marked by p, −p or nothing, depending of the color of the corresponding
edge in G. In G, C1 and C2 are “directly connected” by d; in H they are not: E is
between them.
The construction of G and H is illustrated by Fig. 12.15; in this ﬁgure, all edges
labeled d stand for two symmetrical relation nodes with label d.
Let us now prove that all extensions of σ produce a one-color k-clique if and
only if, for all completions H∗of H, there is a homomorphism from G to H∗.
Let us call subgraph “induced by” a set of concept nodes S the subgraph with set
of concept nodes S plus all relation nodes having all their neighbors in S.
First see that there is a bijection, say b, between an edge-coloring of G extend-
ing σ and a {p}-completion of the subgraph induced by E in H. As the subgraphs
induced by C′
1 and C′
2 are already {p}-complete, such a completion is also a {p}-
completion of H itself. Also note that r and d occur only positively, thus they are
not needed in completions: There is a homomorphism from G to each {r,d, p}-
completion of H if and only if there is a homomorphism from G to each {p}-
completion of H (see Sect. 12.2.6.1).
Let σ′ be an extension of σ that produces a k-clique of color 0 (resp. 1). In b(σ′),
i.e., the completion of H assigned to σ′ by b, the subgraph induced by E contains
concept nodes corresponding to the edges of a k-clique S, with all these nodes being
attached to a p relation node (resp. a −p relation node). Let edges(S) denote this set
of nodes. There is a homomorphism from G to the subgraph of b(σ′) induced by
C′
1 ∪edges(S) (resp. C′
2 ∪edges(S)).
Reciprocally, let H∗be a {p}-completion of H and let h be a homomorphism
from G to H∗. See that h is necessarily injective on the set of concept nodes in G
due to d relation nodes between all distinct concept nodes in G2. h maps G either
2 A homomorphism from a clique C to a graph G is necessarily injective, but it is no longer true
when C and G are replaced by the intersection graphs of their edges. The role of d relation nodes
in the subgraphs induced by C1 and by C2 is to enforce injectivity.

362
12 Conceptual Graphs with Negation
to the subgraph of H∗induced by C′
1 and the nodes corresponding to edges of a
k-clique that are all attached to a −p, or to the subgraph induced by C′
2 and edges of
a k-clique that are all attached to a p. Thus, there is an extension of σ that produces
a k-clique of color 0 or of color 1.
C’1
H
C1
C2
C’2
E
G
p
p
p
p
−p
−p
−p
−p
−p
d
d
d
d
d
d
d
d
d
d
d
d
p
Fig. 12.15 Schema of the reduction in theorem 12.3 proof
The preceding reduction is easily adapted into a reduction to Deduction in
FOL{∃,∧,¬a} or CQNC. Note that PGs obtained in the reduction are built on a
very ﬂat vocabulary and only unary relation nodes are negated. Hence the property:
Property 12.6. PG-DEDUCTION (thus FOL{∃,∧,¬a}-DEDUCTION) remains Π P
2 -
complete if the vocabulary is not ordered and negation concerns only unary relation
nodes. Deduction on BGs augmented with negation on concept types only is Π P
2 -
complete.
The above reduction can be adapted to provide a proof of Π P
2 -completeness of
BG̸=-DEDUCTION (hence PG̸=-DEDUCTION since PG̸=-DEDUCTION is clearly in
Π P
2 ).
Theorem 12.4 (BG̸=-DEDUCTION Complexity). BG̸=-DEDUCTION is Π P
2-complete.
Sketch of proof. The previous transformation is adapted as follows: The p relation
disappears and is replaced by di f links (whose role is to relate nodes of different
color). In G there is a di f link between all nodes x and y, where x is a concept node
in C1 and y is a concept node in C2. In H there is a di f link between all nodes x and
y such that x is in E, and, if x is of color 0 (i.e., was previously marked by p) then y
is in C′
2, and if x is of color 1 (i.e., was previously marked by −p) then y is in C′
1.
12.2.5 Special Cases with Lower Complexity for PG-DEDUCTION
The existence of a PG homomorphism from G to H is a sufﬁcient condition for
G to be deducible from H. However, it is not a necessary condition, as we have
seen before. In this section, we study the question “when is a homomorphism from

12.2 Conceptual Graphs with Atomic Negation
363
G to H a necessary condition for G to be deducible from H?”. Answers to this
question yield particular cases where the theoretical complexity of PG-DEDUCTION
decreases. We shall also identify special subgraphs of G for which there must be a
homomorphism to H when G is deducible from H. These subgraphs can be used as
ﬁlters or guides during the completion algorithm (see Sect. 12.2.6).
Let us ﬁrst identify relation nodes in G that may play a role in the problem com-
plexity, in the sense that they may lead to using the excluded-middle law.
Deﬁnition 12.15 (Opposite relation labels and nodes). Two relation labels are said
to be opposite if they have opposite polarities and if the type r of the positive label
is greater than the type s of the negative label (r ≥s). By extension, two relation
nodes are said to be opposite if they have opposite labels +r and −s.
Let us say that two opposite relation nodes of G are “exchangeable” if they can
have the same list of images for their arguments by homomorphisms to (necessarily
distinct) completions of H.
Deﬁnition 12.16 (Exchangeable relations). Two relations +r(c1,...,ck) and
−s(d1,...,dk) in G are exchangeable with respect to H if (1) they are opposite,
(2) there are two completions of H, say H1 and H2, and two homomorphisms π1
and π2, respectively from G to H1 and from G to H2, such that for all i : 1...k,
π1(ci) = π2(di).
See, for instance, the PG G in Fig. 12.10. Let us consider the opposite relation
nodes r1 = p(c1) and r2 = −p(d1). These nodes are exchangeable, as can be seen in
Fig. 12.12: There is a homomorphism π1 from G to a completion H1 of H and there
is a homomorphism π2 from G to another completion H2 of H, such that π1(c1) =
π2(d1) (and is the concept node in H with marker b).
G
H
r
r
1
2
r
r
r
−p
+p
−p
T
x
y
z
+p
1
2
1
2
1
2
1
2
a
b
c
d
−p
T
T
T:a
T:b
T:c
T:d
Fig. 12.16 Exchangeable and opposite relation nodes
The deﬁnition of exchangeable relations is strictly more restrictive than the deﬁ-
nition of opposite relations. See Fig. 12.16 for instance, where x and y are opposite
nodes, as well as x and z. x and y are exchangeable, which can be seen with the
following two completions of H: In one completion, say H1 , −p(b) is added (and a
homomorphism from G to H1 maps the neighbor of y to b); in another completion,
say H2, p(b) and −p(d) are added (and a homomorphism from G to H2 maps the
neighbor of x to b). It can be checked that x and z are not exchangeable: There are
no two completions such that their argument can be mapped to the same node.

364
12 Conceptual Graphs with Negation
Property 12.7. Let G and H be two PGs, with G having no pair of exchangeable
relations with respect to H, and H being consistent and normal. If G is deducible
from H, then there is a homomorphism from G to H.
Proof. Let Hc+ be a completion of H with solely positive relations, and furthermore
with all possible relations: For all n-ary type p and for all n-tuple u of concept
nodes in H, if there is no relation −q(u) with q ≥p, then +p(u) is added if it
is not already present in H. We call it the maximal positive completion of H. If
there is no homomorphism from G to H but G is deducible from H, then for each
homomorphism from G to Hc+, there is at least one added relation in Hc+, say
p(u), such that a relation p′(v) (p′ ≥p) in G is mapped to p(u). Let us replace
all such p(u) by −p(u). Note that it remains a completion and does not lead to
an inconsistency: Indeed, for all +p′(u) with p′ ≤p, p′(u) is also reversed. Let
Hc′ be this completion. Let h be a homomorphism from G to Hc′ (there is such a
homomorphism since G is deducible from H). h maps a relation −p′′(w) in G to a
relation −p(u) (p′′ ≤p); otherwise there would be a homomorphism from G to H.
By construction, there is a relation p′(v) mapped to p(u) by a homomorphism from
G to Hc+; thus p′(v) and −p′′(w) (one has p′ ≥p′′) are exchangeable relations,
which contradicts the hypothesis on G.
⊓⊔
We thus obtain a case for which PG-DEDUCTION has the same complexity as
homomorphism checking (and is thus NP-complete):
Property 12.8. Let G and H be two PGs, with G having no pair of exchangeable
relations with respect to H, and H being consistent and normal. G is deducible from
H if and only if there is a homomorphism from G to H.
Note also that G is deducible from H if and only if each connected component of
G is deducible from H. Moreover, splitting an individual concept node into several
nodes does not change the logical semantics of the graph and preserves a homomor-
phism from this graph to any other graph. Thus, one can consider each piece of G
(cf. deﬁnition 8.22) with respect to its individual concept nodes, i.e. each connected
subBG of G induced by all concept nodes such that there is a path between them
which does not go through an individual node (however, individual nodes can be
extermities of such a path). Let us call detached form of G the set of its pieces with
respect to its individual concept nodes. Hence the property:
Property 12.9. Let G and H be two PGs, such that each piece of the detached form
of G has no pair of exchangeable relations with respect to H, and H is consistent
and normal. G is deducible from H if and only if there is a homomorphism from
G to H (i.e., there is a homomorphism from each of these connected components
to H).
If the detached form of G is acyclic (more generally has bounded treewidth or
hypertreewidth when seen as a hypergraph) then homomorphism checking is poly-
nomial (see Chap. 7), hence PG-DEDUCTION.
A desirable property is that recognizing exchangeable relations is not difﬁcult
compared to PG-DEDUCTION complexity, which is indeed the case:

12.2 Conceptual Graphs with Atomic Negation
365
Property 12.10. Let EXCHANGEABLE be the problem that takes two PGs G and H
as input and asks if G possess a pair of exchangeable relations with respect to H.
EXCHANGEABLE is NP-complete.
Proof. EXCHANGEABLE is in NP: A polynomial certiﬁcate is given by two relation
nodes of G and two applications from concept nodes of G to concept nodes of H
(assumed to provide the two wanted homomorphisms from G to two completions
of H). For NP-completeness, a reduction is built from BG-HOMOMORPHISM. Let
(G1,G2) be an instance of BG-HOMOMORPHISM. “Gadgets” are added to G1 and
G2, yielding G′
1 and G′
2 respectively, such that there is a homomorphism from G1
to G2 if and only if G′
1 possess exchangeable relations with respect to G′
2. Take, for
instance, the graphs G and H in Fig. 12.10, and choose the types t, r and p such that
they do not occur in G1 and G2. G′
1 (resp. G′
2) is obtained by making the disjoint
sum of G1 and G (resp. of G2 and H). The only candidate exchangeable relation
nodes in G′
1 are the nodes labeled p and −p. This construction is easily adapted to
yield connected graphs if connected graphs are preferred.
⊓⊔
The following property will be used to prove other properties:
Property 12.11. Let G and H be two PGs, where H is consistent and normal, and
G is deducible from H. Let G′ be a subgraph of G having no pair of exchange-
able relation nodes with respect to H. Then there is a completion Hc of H and a
homomorphism from G to Hc that maps G′ entirely to H.
Proof. Consider any maximal completion of H, say Hc (for each n-ary type p and
each n-tuple u of concept nodes in H, either one has +p(u) or one has −p(u)).
Assume that there is no homomorphism from G to Hc that maps G′ to H. For each
homomorphism from G to Hc, there is at least one added relation ∼p(u) in Hc (with
∼stands for + or −) which is the image of a relation in G′ such that H does not
contain a node ∼q(u) with ∼p ≥∼q. Let R be the set of all such relation nodes in
Hc\H for all homomorphisms from G to Hc. Let us inverse the polarity of the nodes
in R. The graph obtained cannot be inconsistent3 and it is of maximum size: Thus
it is again a maximal completion of H. Let Hc′ be this maximal completion. As G′
does not possess exchangeable relations, there is no homomorphism from G to Hc′
that maps a relation node in G′ to a node in R. If there is no homomorphism from
G to Hc′ that maps G′ entirely to H, let R′ be the set of all relation nodes ∼p(u)
in Hc′ \ H which are images of a node in G′ and such that H does not contain a
node ∼q(u) with ∼p ≥∼q. As previously, reverse the polarity of all nodes in R′,
which yields the graph Hc′′. Add the nodes of R′ to R. We thus build a sequence
of maximal completions of H and a set R of relation nodes of these completions
not belonging to H (nor redundant with nodes of H). As R grows strictly from one
3 Indeed, assume we obtain two contradictory relation nodes −q(u) and p(u), with q ≥p. One of
these nodes does not belong to R, otherwise G would have exchangeable nodes. Let x be this node
and y be the node that belongs to R. The label of x in Hc is necessarily more general than the label
of y in Hc (since both nodes were comparable and had the same polarity in Hc). Thus, by inverting
the label of y, it is impossible to obtain an inconsistency.

366
12 Conceptual Graphs with Negation
completion to another, this sequence is ﬁnite. The last graph of this sequence is a
completion satisfying the property.
⊓⊔
If G is PG-deducible from H, for each subgraph of G without exchangeable re-
lations, there must be a homomorphism from this subgraph to H. Moreover, there
must be such a homomorphism that is potentially extensible to a homomorphism
from the entire G to a completion of H. We call it a compatible homomorphism.
−
G
M
G
+
G
v
t
u
w
H
G
x
z
y
x
z
y
x
z
y
x
z
y
1
1
2
2
2
1
+s
2
2
1
−r
+r
1
2
−r
−r
−r
2
1
+s
+r
1
2
−r
2
1
+s
2
2
1
1
1
−r
−r
−r
2
1
+s
2
1
−r
−r
1
2
+s
1
2
2
+r
1
1
1
2
2
Φ(G) = ∃x∃y∃z (s(y,x)∧r(x,z)∧¬r(x,y)∧¬r(y,z))
Φ(H) = ∃u∃t∃v (s(u,t)∧r(v,t)∧s(w,u)∧¬r(u,w)∧¬r(t,u)∧¬r(w,v)∧¬r(t,w))
Fig. 12.17 Special subgraphs of G (G is deducible from H)
Deﬁnition 12.17 (compatible homomorphism). Given two PGs G and H, and G′
any subgraph of G, a homomorphism h from G′ to H is said to be compatible (with
respect to G) if for each relation node x of G that does not belong to G′ but has
all its neighbors in G′, say c1...ck, there is no relation node y with neighbor list
h(c1)...h(ck) in H and with a label contradictory to that of x (i.e. with label −r if the
label of x is +s, or with label +s if the label of x is −r,such that s ≤r).
Example. See Fig. 12.17, where all concept nodes are assumed to have the same
label (⊤,∗) and relation types are incomparable. Let us consider G−, a subgraph
of G. There are three homomorphisms from G−to H: h1 = {x →t,y →u,z →w},
h2 = {x →t,y →w,z →v}, h3 = {x →u,y →w,z →v}. To check the compatibility
of these homomorphisms, we have to consider +s(y,x) and +r(x,z). h1 is not com-
patible because it cannot be extended to +r(x,z) due to the presence of −r(t,w)
in H.

12.2 Conceptual Graphs with Atomic Negation
367
Property 12.12. If G is deducible from H, then there is a compatible homomorphism
from every subgraph of G without exchangeable relations to H.
Proof. Let G′ be any subgraph of G without exchangeable relations. From Prop-
erty 12.11, there is a homomorphism from G to a completion of H which maps G′
entirely to H. By restricting the domain of this homomorphism to G′, we have a
homomorphism from G′ to H, which is compatible with respect to G.
⊓⊔
Let us point out some easily identiﬁable subgraphs without exchangeable rela-
tions. The positive subgraph of G, denoted G+, is the subgraph obtained from G by
selecting all concept nodes and only the positive relation nodes. The negative sub-
graph G−of G is the dual notion, i.e., the subgraph obtained from G by selecting
all concept nodes in G and only the negative relation nodes. Negative and positive
subgraphs are particular cases of subgraphs without opposite relations. A subgraph
of G without opposite relations and maximal for the inclusion is easily built by se-
lecting, for each relation type appearing in G, either all its positive occurrences or
all its negative occurrences, while satisfying the following constraint: If one selects
the positive (resp. negative) occurrences of a relation type r, then the same choice
must be done for all subtypes (resp. supertypes) of r.
Example. In Fig. 12.17, several subgraphs without opposite relations of G are pic-
tured. G+ and G−are respectively the positive and negative subgraphs of G. G has
two subgraphs without opposite nodes maximal for inclusion: G+ and GM.
12.2.6 Algorithmic Improvements
Let us say that a concept or relation label lx occurring in G has a support in H if
there is a label ly in H with ly ≤lx (and ly is said to support lx). By extension, we
say that a node x in G has a support in H if there is a node y in H such that the label
of x is supported by the label of y (and y is said to support x).
A ﬁrst observation is that if a node in G has no support in H then G is not de-
ducible from H. This is trivial for concept nodes. For relation nodes, if this node
is negative (resp. positive), consider a completion of H with solely positive (resp.
negative) relation nodes. There is no homomorphism from G to this completion.
12.2.6.1 Limitation of the Completion Vocabulary
Let us call “completion vocabulary” the set of relation types used to build com-
pletions of H. The size of the completion vocabulary determines the number of
completions of H. The number of completions of H is itself a key element in the
complexity of PG-deduction checking. It is thus essential to decrease the number of
relation types involved in completions as much as possible. One can observe that
the completion vocabulary can be restricted to the relation types occurring in G, and
furthermore to relation types occurring in opposite relations of G:

368
12 Conceptual Graphs with Negation
Property 12.13. Let G and H be two PGs, where H is consistent and normal. G is
deducible from H if and only if G can be mapped to each completion of H with
respect to relation types occurring in opposite relations of G (i.e., r and s such that
there are nodes in G with labels +r and −s and s ≤r).
Proof. Let TR be the set of relation types in the vocabulary, and let T be the set of
relation types occurring in opposite relations in G. (⇐) We prove that if G can be
mapped to each T-completion of H, then it can be mapped to each TR-completion
of H. Indeed, let Hc be any TR-completion of H. Let Hc′ be the graph obtained from
Hc by replacing all relations with types outside T with a set of relations built as
follows: Let r be a node labeled by +t (resp. −t) such that t ̸∈T. Let {t1...tn} be
the types in T greater than t (resp. less than t). If r is positive, consider the minimal
elements of this set, otherwise consider the maximal elements of this set. Let S be
the obtained set. Replace r with |S| relation nodes, each labeled by a type in S,
with the same polarity and the same arguments as r. Hc′ is a T-completion of H.
By construction, there is a homomorphism, say h1, from Hc′ to Hc (which is the
identity on concept nodes). By hypothesis, there is a homomorphism from G to Hc′,
say h. The composition of these homomorphisms h1 ◦h is a homomorphism from G
to Hc.
(⇒) Let G be deducible from H and assume that Hc is a T-completion of H such
that there is no homomorphism from G to Hc. We show that this assumption leads
to a contradiction. From Hc, we build the following TR-completion of H, say Hc′.
For all type t in TR \ T, let us add only (+t) nodes if +t does not support the label
of any node in G; otherwise, add only (−t) nodes if −t does not support the label
of any node in G (if neither +t nor (−t) support node labels in G, relation nodes
typed t can be added with any polarity); if both +t and −t support node labels in
G, there are opposite nodes in G with label +r and −s and r ≥t ≥s, thus r and s
belong to T, and nodes with type t would be redundant in Hc′ thus are not needed to
obtain a completion. Since G is deducible from H, there is a homomorphism from
G to Hc′. By construction, no node in G can be mapped to an added node. Thus this
homomorphism is a homomorphism from G to Hc, which contradicts the hypothesis
on Hc.
⊓⊔
We can even restrict the vocabulary completion to the relation types of exchangeable
relations in G.
Theorem 12.5. Let G and H be two PGs, where H is consistent and normal. G is
deducible from H if and only if G can be mapped to each completion of H with
respect to relation types occurring in exchangeable relations of G with respect to H
(i.e., relation types r such that there is a pair of exchangeable relations in G with
one of the two labeled by +r or −r).
Proof. Let exchangeable(G) denote the types occurring in exchangeable relations
in G.
(⇐) Same as in the proof of Property 12.13, where T is replaced by exchangeable(G).
(⇒) Let Hc be a completion of H with respect to exchangeable(G) such that there

12.2 Conceptual Graphs with Atomic Negation
369
is no homomorphism from G to it. As in the proof of Property 12.13, we build
a completion of H, say Hc′, as follows: For any type t occurring in G but not in
exchangeable(G), let us add only (−t) nodes if −t does not support any label in G,
(+t) nodes if +t does not support any label in G. Let us add it positively if both −t
and +t support labels in G. A homomorphism from G to Hc′ is a homomorphism
to Hc plus the nodes added positively for types supporting both forms. Let us now
inverse the polarity of these latter nodes if they are images of nodes in G. No node in
G can be mapped to these nodes, otherwise their type would be in exchangeable(G).
Thus, we have a homomorphism from G to Hc, which contradicts the hypothesis on
Hc.
⊓⊔
12.2.6.2 Space Algorithm
Consider the space of graphs leading from H to its completions. All graphs in this
space have the same set of concept nodes. The space is ordered as follows: Given
two graphs H1 and H2 in this space, H2 ≤H1 if for each relation x in H1, there
is a relation with the same list of neighbors in H2 and a label less or equal to the
label of x. The question “Is there a homomorphism from G to each completion Hc”
can be reformulated as follows “Is there a covering set of completions, that is a
subset of incomparable graphs of this space {H1, ..., Hk} such that (1) there is a
homomorphism from G to each Hi ; (2) for each Hc there is a Hi with Hc ≤Hi.”
The brute-force algorithm (Algorithm 27) takes the set of all completions of H
as covering set.
The next algorithm (Algorithm 30 and recursive Subalgorithm 31) searches the
space in a top-down way starting from H and tries to build a covering set with partial
completions of H. Reasoning by cases is applied at each step: For a given relation
type r with arity k and a tuple (t1...tk) of concept nodes, such that neither +r nor
−r is supported by the label of a relation node on (t1...tk) in the current partial
completion, two graphs are generated according to each case. Note that if +r or −r
is supported by a ∼s in the current completion, then adding +r(t1...tk) or −r(t1...tk)
to it would lead to a redundancy or an inconsistency.
The algorithm is justiﬁed by the following property:
Theorem 12.6. Let G and H be two PGs, where H is consistent and normal. G is
deducible from H if and only if:
1. There is a homomorphism π from G to H or
2. G is deducible from H′ and H′′ where H′ (resp. H′′) is obtained from H by
adding the positive relation r(t1...tk) (resp. the negative relation −r(t1...tk)) where
r is a relation type of arity k occurring in G (and more speciﬁcally r belongs to the
completion vocabulary) and t1...tk are concept nodes of H such that neither +r nor
−r is supported by the label of a relation node on (t1...tk) in H.
Proof. (sketch) (⇒) Any completion of H′ or H′′ is a completion of H. (⇐) Con-
dition 1 corresponds to Property 12.2. For condition 2, check that {H′,H′′} is a
covering set (of completions of H).
⊓⊔

370
12 Conceptual Graphs with Negation
Subalgorithm 31 is supposed to have direct access to data available in the main
Algorithm 30. The choice of r and t1...tk, in Algorithm 31, can be guided by a
compatible homomorphism from a special subgraph of G.
Algorithm 30: Check by space exploration
Input: Consistent PGs G and H, with H being consistent and normal
Output: true if G is deducible from H, false otherwise
begin
Result ←Filtering()
if (Result ̸= undetermined) then
return Result
Let R be the completion vocabulary
return RecCheck(H); // see algorithm 31
end
The ﬁltering subalgorithm performs “simple” tests corresponding to necessary or
sufﬁcient conditions of deduction that would allow us to conclude without entering
the completion steps:
• If a concept or relation node of G has no support in H, then return false.
• If there is a homomorphism from G to H, then return true.
• Compute some subgraphs of G without exchangeable relations (for instance a
subgraph without opposite relations maximal for the inclusion). If one of these
subgraphs does not map to H by a compatible homomorphism, then return false.
Algorithm 31: RecCheck(H) subalgorithm of Algorithm 30
Input: Consistent and normal PG H
Access: G, R
Output: true if G is deducible from H, false otherwise
begin
if there is a homomorphism from G to H then
return true
if H is complete with respect to R then
return false
(r,t1...tk) ←ChooseRelationTypeToAdd()
/* r is a relation type of R, t1...tk are concept nodes in H
and neither +r nor −r is supported by a the label of a
relation on (t1...tk) in H
*/
Let H′ be obtained from H by adding the relation node r(t1...tk)
Let H′′ be obtained from H by adding the relation node −r(t1...tk)
return (RecCheck(H′) AND RecCheck(H′′))
end
The following property ensures that Algorithm 31 does not generate the same
graph several times, which is a crucial point for complexity. Otherwise the algorithm
could be worse than the brute-force algorithm in the worst-case.

12.2 Conceptual Graphs with Atomic Negation
371
Property 12.14. The subspace explored by Algorithm 31 is a (binary) tree.
Indeed, at each recursive call, {H′, H′′} is a covering set inducing a bipartition of
the covered space: Each graph in this space is below exactly one of these two graphs.
Property 12.15. The time complexity of Algorithm 30 is in O(2(nG)k×|R| ×hom(G,
Hc)), where nG is the number of concept nodes in G, k is the maximum arity of
a relation, R is the completion vocabulary and hom(G,Hc) is the complexity of
checking the existence of a homomorphism from G to Hc. Its space complexity is
in O(max(size(G),size(H),(nG)k ×|R|)).
Proof. The number of completions of H is bounded by 2(nG)k×|R|. Property 12.14
ensures that the number of graphs generated is at most twice the number of comple-
tions of H (in the worst case, all leaves of the generated tree of graphs are complete
graphs). If the relation types are not ordered, all completions have the same number
of relation nodes; the number of their relation nodes typed by an element of R is
∑r∈R(nG)arity(r); checking whether a graph is complete can then be done in con-
stant time if the number of relation nodes typed by an element of R is incrementally
maintained. When relation types are ordered, the size of completions varies accord-
ing to the order in which relation types are considered. One solution is to count the
addition of a relation node ∼r(t1...tk) not for one, but for n, where n is the number
of types s in R, such that ∼s is supported by ∼r and was not before. Computing n
at each node addition can be roughly bound by |R|2, which can be reasonably con-
sidered as less than hom(G,Hc). For space complexity, see that the tree is explored
in depth-ﬁrst way.
⊓⊔
12.2.7 Querying Polarized Graphs
The fundamental problem on BGs, namely deduction, takes two BGs as input and
asks whether there is a homomorphism from the ﬁrst one to the second. Querying
BGs highlights another fundamental problem, namely query answering. The query
answering problem takes as input a knowledge base (KB) composed of BGs repre-
senting facts and a BG Q, which represents a query, and asks for all answers to Q
in the KB. Each homomorphism from Q to a fact deﬁnes an answer. If we consider
the query answering problem in its decision form (“Is there an answer to Q in the
KB?”) we obtain the deduction problem (“Is Q deducible from the KB?”)
Let us now consider query answering on PGs. Classically, there are two ways
of understanding negation in a query. Brieﬂy, when a query asks “ﬁnd the x and y
such that p(x,y) and not r(x,y),” “not” can be understood in several ways. It might
mean “the knowledge r(x,y) cannot be proven” or “the knowledge not r(x,y) can be
proven.” The ﬁrst view is consistent with the closed-world assumption, the second
one with the open-world assumption. Both are of interest in real-world applications.
The closed-world assumption assumes complete knowledge about the world. It fol-
lows that only positive information needs to be coded in the fact base, with negative

372
12 Conceptual Graphs with Negation
information being obtained by difference with the content of the base. not r(x,y)
is then understood as “r(x,y) is not present in the base,” or more generally “r(x,y)
cannot be deduced from the base” (note that the negation by failure used in logic
programming can be seen as an implementation of the closed-world assumption,
where deduction, generally undecidable, is replaced by a decidable proof notion:
not r(x,y) holds if r(x,y) cannot be obtained by a ﬁnite proof). The closed-world
assumption is commonly made in databases because it eases the representation of
knowledge and improves performance (e.g., see the survey [Bid91]). To deﬁne a
property, it is easier to list the individuals satisfying this property than to enumerate
all individuals and indicate, for each of them, whether it satisﬁes the property or not.
It may even be impossible to list all individuals. Consider, for instance, the property
“being a registered user”: Assuming complete knowledge about this property seems
reasonable; any individual who does not appear in the list of registered users should
be considered as not registered. Finally, let us recall that, if this assumption comes
naturally in databases, it is impossible in FOL to infer negative facts ( for instance
not registered(a)) from positive ones. Various non-monotonic logics have been pro-
posed for translating the closed-world assumption (e.g., see the survey in [AB94]).
Closed-world negation can be easily integrated into queries represented as PGs:
By deﬁnition, a query Q is closed-world deducible from a BG or a PG G if it is
deducible from its negative completion, i.e., if there is a homomorphism from Q
to the completion of G with negative relation nodes only. Of course, the negative
completion does not need to be computed effectively: A query Q is closed-world
deducible from a BG or a PG G if there is a homomorphism π from the positive
subPG of Q (i.e., the subPG obtained by deleting negative relation nodes) to G,
which does not contradict any negative relation in Q: For all −r(c1 ... ck) in Q, G
does not contain a positive relation node +s(π(c1) ... π(ck)) with s ≤r. Consider,
for instance, the example of Fig. 12.18. G describes a situation where there is a pile
of three cubes A, B and C; A is blue and C is not blue. Q can be seen as a yes/no
question asking whether there is a blue cube on top of a non-blue cube. It can also be
seen as a query, that asks for exhibiting objects having these properties. Whether B
is blue or not is not speciﬁed. Thus, with closed-world assumption, B is considered
as not blue. There is a homomorphism from the positive part of Q to G, which maps
x to A and y to B. Hence, the answer to Q as a boolean question is “yes,” and the
answer to Q as a query is {(x,A),(y,B)}.
Open-world assumption assumes incomplete knowledge about the world. Conse-
quently, missing information, or more generally information not deducible from the
base, is simply unknown. not r(x,y) is true if it can be deduced from the base. The
value of the property “being a parent,” for instance, might not be known for all in-
dividuals, so an individual not known as being a parent should not be considered as
without children. In turn, the notion of deduction can have several meanings depend-
ing on the logics. In particular, the law of the excluded middle in classical logic has
important consequences for query answering. Let us come back to the pile of cubes
example (Fig. 12.18) with an open-world assumption: Nothing is known about the
color of cube B. What should be answered to Q (as a boolean question or a query)?

12.2 Conceptual Graphs with Atomic Negation
373
Q
G
Color: Blue
1
1
prop
Color: Blue
prop
2
Cube: C
Cube: B
onTop
Cube: A
−prop
onTop
Cube
onTop
−prop
Cube
1
1
A
B
C
x
y
1
2
2
2
2
1
1
2
2
−prop
Fig. 12.18 The pile of cubes example
Let us ﬁrst point out that spontaneously a non-logician (a typical end-user for in-
stance) would say that the answer to the boolean question is no; this intuition corre-
sponds to the observation that there is no answer to the query. However, in classical
FOL, the answer to the boolean question is yes. Indeed the logical formulas assigned
to Q and G by Φ are respectively of form Φ(Q) = ∃x∃y (p(x,Blue)∧¬p(y,Blue)∧
r(x,y)) and Φ(G) = p(A,Blue)∧r(A,B)∧r(B,C)∧¬p(C,Blue) (where p = prop,
r = onTop and atoms assigned to concept nodes are ignored). Φ(Q) can be deduced
from Φ(G) using the valid formula p(B,Blue)∨¬p(B,Blue) (Φ(Q) is obtained by
interpreting x and y as B and C if p(B,blue) holds, and as A and B in the opposite
case). Classical logical deduction thus ensures that there is a “solution” to Q, but it
is not able to construct it. Hence there is no answer to Q as a query. This example
leads to the following observations:
• The assertions “Q is (classically) deducible from G” and “the set of answers to
Q in G is not empty” might disagree. In other words, deduction and the decision
problem associated with query answering are different problems (which is not
the case for BGs).
• The difference between the notions of deduction and the existence of an answer
is due to the use of the law of excluded middle, which states here that “either B
is blue or it is not blue.”
This observation shifts the attention to logics in which the law of excluded middle
does not hold. Let us consider one of these logics, i.e., intuitionistic logic [Fit69],
a well-established logic which differs from classical FOL by admitting only con-
structive proofs. For instance, a proof of (A∨B) is given by a proof of A or a proof
of B; a proof that the falsity of (A∨B) leads to a contradiction (i.e., a reductio-ad-
absurdum proof) does not yield a proof of (A∨B) since it does not determine which
of A or B is true. Each intuitionistic logic theorem is classical logic theorem, but
not conversely. In particular, the theorem (A∨¬A), i.e., the law of excluded middle,
does not hold.
Let us come back to the example in Fig. 12.18. According to intuitionistic logic,
the formula p(B,Blue) ∨¬p(B,Blue) can be considered as true only if it can be
shown that p(B,Blue) is true, or that ¬p(B,Blue) is true. Since none of these two

374
12 Conceptual Graphs with Negation
statements can be proven, Q cannot be deduced; hence the answer to Q as a yes/no
question is no, which corresponds to the fact that there is no answer to Q as a query.
More generally, this logic appears to be completely in line with the notion of
answer: Q is intuitionistically deducible from G if and only if the set of answers to
G is not empty. It has been proven that PG homomorphism is sound and complete
with respect to intuitionistic deduction in the FOL{∃,∧,¬a} logical fragment (cf.
bibliographical notes). More precisely:
Theorem 12.7. Let Q and G be two PGs deﬁned on a vocabulary V, with G being
consistent. Q ⪰normal(G) if and only if Φ(V),Φ(G) ⊩Φ(Q), where ⊩denotes the
intuitionistic deduction .
It follows that atomic negation can be introduced in BGs with no overhead cost
for the query answering problem.
Note that another candidate for translating the existence of an answer would have
been 3-value logic, in which three truth values are considered instead of two: true,
false and undetermined.
Finally, let us point out that, independently of the answer notion, there are real
world situations in which the law of excluded middle is not desirable, or not desir-
able for all properties or relations. Properties or relations might be neither true nor
false because they cannot be determined with certainty (for instance, it might not be
true that a cube is either blue or not blue because its color might be not “really” blue
...) or they intrinsically admit “truth value gaps” (this is the case, for instance, for a
property like “being a sportsperson”: Some people occasionally practice sports, and
cannot be considered as sportspersons nor as non-sportspersons).
12.2.8 Note on Negation and Rules
When we want to integrate atomic negation and rules, i.e., to process rules where
the hypothesis and the conclusion are no longer basic graphs but rather polarized
graphs, there are two intrinsic sources of difﬁculty. First, forward chaining is not
complete in the presence of negation (thus neither is backward chaining). This in-
completeness occurs even if negation occurs only in facts and even in propositional
logic. Consider, for instance, the rule R : A →B and the fact F = ¬B. Proposition
¬A cannot be derived by forward chaining from R and F, but it should be. It could
be derived from F and the contrapositive rule R′ : ¬B →¬A equivalent to R. A
technique for overcoming this incompleteness consists of compiling the rule base
before its use for deduction or query answering [RM00]. The compilation step adds
all rules necessary to achieve completeness. For instance, let R = {r1,r2,r3}, with
r1 = A →B, r2 = A →C and r3 = B∧C →D. Check that ¬A is deducible from R and
F = ¬D, but it is not derivable from R and F. The compilation adds rules obtained
by rewriting r1, r2 and r3 in all forms logically equivalent to their clausal form (i.e.,
¬B →¬A for r1, ¬C →¬A for r2, and B∧¬D →¬C and C ∧¬D →¬B), but also
induced rules like A →D (which is actually not necessary as it can be simulated by

12.3 Bibliographic Notes
375
r1 and r2, then r3) and ¬D →¬A. The size of the new base can be exponential in the
size of the original base. Another source of complexity when passing to ﬁrst-order
is that rule application itself is much more complex: indeed, to check whether a rule
can be applied, i.e., whether its hypothesis can be deduced from the facts, ﬁnding a
homomorphism is not sufﬁcient if we stick to classical deduction.
12.3 Bibliographic Notes
Full Conceptual Graphs
FCGs, and their logical semantics, as well as associated diagrammatical rules of in-
ference, are introduced in [Sow84]. It was claimed that the full FOL was obtained,
with arguments relying on the fact that Peirce’s calculus was sound and complete.
However, no formal proof of soundness and completeness of the calculus was pro-
vided.
Concerning Peirce’s work, see for instance the historical survey [Rob03]. The
version of FCG called concept graphs was introduced by Dau in his PhD thesis
[Dau03b]. Besides the development of concept graphs, Dau’s thesis provides an in-
depth presentation of existential graphs. Concept graphs are also related to Formal
Concept Analysis, cf. [GW99] for an introduction to this area. The version of FCGs
equivalent to FOL without equality, and for which a sound and complete tableau
calculus is deﬁned, is studied in Kerdiles’ Ph.D. thesis [Ker01].
Sowa presents negative contexts as a special case of conceptual graph contexts
(see Chap. 9 about nested graphs). A negative context is seen as a concept with a
graph referent, and a unary relation “NEG” (for negation) attached to it. We disagree
with this view because the semantics of both kinds of concepts is different, and the
NEG relation has to be translated as the logical negation operator.
In [Wer95a], Wermelinger corrected minor mistakes in Sowa’s original deﬁni-
tions. In particular, he pointed out that the universal type ⊤has to be translated in
such a way that the graphs [⊤: ∗] or [⊤: a] are valid. He proposed their transla-
tion into a trivial equality (x = x or a = a). A proof of completeness was given in
his Master’s thesis [Wer95b], but it is not available in English. Wermelinger’s def-
initions took into account higher order concept and relation types that we do not
want to consider. Baader, Molitor and Tobies stripped higher order features from
Werlinger’s deﬁnitions, and proved the equivalence of full CGs with FOL [BMT99]
[BMS98]. Since no calculus over full CGs was considered, equivalence was shown
at a descriptive level. The deﬁnition of full CGs given in this chapter and the as-
sociated Φ translation to logics rely on [BMT99] and the Theorem 12.1 is from
[BMS98].
The (loosely) guarded fragment [vB97], noted lgFOL, is a decidable fragment of
FOL with negation. This fragment has interesting properties, such as the ﬁnite model
property and others [AvBN96]. It contains the FOL translation of many modal log-
ics and description logics. In [BMT99] the authors identify a restricted form of full

376
12 Conceptual Graphs with Negation
conceptual graphs corresponding to lgFOL. One can polynomially check if a con-
ceptual graph is loosely guarded (the graph has to satisfy some syntactic restric-
tions), and compute the lgFOL formula equivalent to G, and reciprocally. Note that
deduction in the loosely guarded fragment does not include deduction in the FR
model, even when rules are restricted to range restricted rules. For instance, the fol-
lowing formula that asserts the transitivity of a binary relation R is not a (loosely)
guarded formula and has no equivalent formula in the loosely guarded fragment
[Gr¨a99]: ∀x∀y∀z(R(x, y)∧R(y, z) →R(x, z)).
Atomic Negation.
Few works have considered BGs with atomic negation. The name “polarized graphs”
is from Kerdiles [Ker01]. Simonet exhibited examples showing that homomorphism
is no longer complete and proposed an algorithm based on an adaptation of the
resolution method (unpublished note, 1998; see also [Mug00]). Kerdiles exhibited
simpler examples (cf. Figs. 12.10 and 12.11) and showed that homomorphism re-
mains complete in a very particular case (brieﬂy when positive and negative rela-
tions are separated into distinct connected components) [Ker01]. Klinger gave ex-
amples of problems related to the introduction of negation on relations (including
equality) in the framework of protoconcept graphs (which can be translated into
PGs) [Kli05]. Lecl`ere and Mugnier discussed different kinds of negation (as well
as difference) in the context of querying BGs and gave sound and complete mecha-
nisms based on homomorphism for each of them [LM06][ML07]. The reduction in
the proof of Π 2
P-completeness of PG-DEDUCTION is essentially due to Bagan, who
built it when he was a Master’s student at Montpellier University in November 2004
(see also [Mug07]). Properties concerning exchangeable relations and algorithmic
improvements were published in [LM07] in the context of the containment prob-
lem of conjunctive queries with negation (CQNC). In this context, the vocabulary
is restricted to a ﬂat set of relation types and a set of individual markers. In this
chapter, we have extended the results of this paper to PGs on general vocabularies
and presented some additional results about exchangeable relations (namely Prop-
erties 12.10 and 12.11). The idea of Property 12.10 is from Thomazo [Tho07] (in
French). In the same work, it is proven that PG-DEDUCTION is NP-complete if the
source graph contains at most one pair of exchangeable relations. The question of
PG-DEDUCTION complexity with a source graph containing two pairs of exchange-
able relations, and more generally a bounded number of such pairs, is open.
Finally, let us mention the proof of Π 2
P-completeness of CQNC in [FNTU07],
which relies on a reduction from the validity problem of a quantiﬁed boolean for-
mula of the form ∀∗∃∗C, where C is a conjunction of 3-clauses. Since CQNC and
PG-DEDUCTION are equivalent, it can be seen as another proof of PG-DEDUCTION
Π 2
P-completeness.

Chapter 13
An Application of Nested Typed Graphs:
Semantic Annotation Bases
Overview
This chapter is devoted to the problem of resource retrieval using resource anno-
tations. This problem is a promising application domain for nested typed graphs.
In the ﬁrst section, semantic annotations are deﬁned as a kind of metadata. Two
applications, information retrieval and editing, are also brieﬂy described, and the
annotation-based resource retrieval (ARR) problem is stated. The main components
of an ARR system are also presented. In the second section, it is shown how modular
vocabularies as well as exact and plausible knowledge can be deﬁned and used in
an ARR system. Ways to answer queries to an annotation base are discussed in the
third section. Finally, relationships between an ARR system and the semantic web
are brieﬂy discussed in the fourth section.
13.1 Annotation
13.1.1 Annotations, Metadata and Resources
An annotation always annotates something. It does not exist in isolation. For in-
stance, an annotation of a text is usually deﬁned as a note, in natural language,
giving explanations or comments about this text. In this chapter, an annotation can
annotate any kind of object. The historical interest of a castle, the rhetoric study of
a political discourse, a critique on a movie, or a description of a painting in modern
art, are annotations about non-textual resources. Such resources can be electronic,
e.g., an html ﬁle, jpeg image or database, or non-electronic, e.g., a book, person or
tourist resort. Thus, in a way, we extend the usual meaning of an annotation, which
is generally restricted to a text annotation. An annotation can annotate anything,
not only texts. But, in another way, we restrict annotations from natural language
notes to formal annotations. In this chapter, formal annotations are well-deﬁned
377

378
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
computational objects, particularly nested typed graphs. In a computational envi-
ronment, an annotation is thus simply a data (sometimes called secondary data)
about a data (sometimes called primary data), i.e., metadata.
Metadata can be roughly classiﬁed into two classes: objective metadata and sub-
jective metadata. The name of a ﬁle, its type, its address or its date of creation are
examples of objective metadata. A comment on a movie, an explanation of the plot
of a detective story, or the description of the content of a book in the bibliographical
system of a library (i.e., indexation of a book), are examples of subjective metadata.
These metadata can be called subjective because they largely depend on the author
of the metadata.
This sort of metadata, i.e., subjective metadata, are usually called semantic anno-
tations. Subjective metadata are generally more complex than objective metadata.
Therefore, any model able to manage subjective metadata should also be able, at
least theoretically, to manage objective metadata, but probably in a less efﬁcient
way. Subjective metadata are simply knowledge, in the Artiﬁcal Intelligence sense,
about resources. Processing such subjective metadata concerns knowledge-based
systems while processing objective metadata is within the scope of database man-
agement systems. Hence, hereafter we focus on subjective metadata.
A resource can be structured, e.g., a book can be divided into chapters, or a
multimedia document can be divided in texts, videos, etc. A set of resources can
also be structured. In classical libraries, documents are classiﬁed by domain (e.g.,
humanities, sciences) or genus (e.g., books, reviews, theses), etc. Even if a document
is not structured, for instance a picture, one can possibly want to decompose it and
annotate each part of it. In what follows, for the sake of simplicity, we consider
that each part of a resource is a resource and that the annotator cannot access the
description of the structure of the resource (or the resource set), which is outside the
annotation base. In other words, if the resource structure must be taken into account
(for instance when querying an annotation base), this structure has to be represented
in the annotation base; a part R′ of a resource R is a resource and in order to consider
this information in the query/answering mechanism one has to represent the fact that
R′ is a part of R in an annotation associated with R or/and with R′.
13.1.2 Examples of Annotation Base Uses
13.1.2.1 Information Retrieval
An Information Retrieval System (IRS) is usually deﬁned as a software system that
helps a user to ﬁnd some required information. However, long ago it was noted that
an IRS generally does not directly give the information needed, but only documents
that should contain that information, and the user has to ﬁnd the sought information
within these documents. Generally, during a search task, an IRS cannot directly
access the documents, it can only access them through metadata about documents

13.1 Annotation
379
(e.g., document content descriptions, data about the author, title of the document,
etc), and these metadata contain references to the document base.
Usually, the relevance of a document is determined solely by a match between a
query and the representation of the document content, so the way the content of a
document is represented is crucial. Simple content representations, called indexes,
are used in many IRSs. Basically, an index consists of a set of weighted words (or
terms, or concepts) chosen within a ﬁnite set. In these systems, queries are often
represented by a boolean expression of terms. Such descriptions by a set of terms
are generally incomplete and imprecise (even if full text indexing is considered). It is
commonly acknowledged that content representation and content-based access are
crucial for improving the precision (the ratio of the number of relevant documents
retrieved to the total number of documents retrieved) and the recall (the ratio of the
number of relevant documents retrieved to the total number of relevant documents
in the document base) of a user’s search.
More precise document content representations and more precise queries can be
obtained by using structures composed of terms enriched by relations between these
terms, i.e., by labeled graphs. We see further how nested typed graphs can be used to
represent document content as well as elementary queries. Graph homomorphisms
are used for computing answers to a query and this approach to the search process
is in line with the logical view of information retrieval. The logical view of infor-
mation retrieval, as stated by van Rijsbergen [vR86], consists of considering that
a document, whose content is represented by a formula d, is relevant to a formula
query q if q can be inferred from d via some logic.
Information retrieval is intrinsically vague because documents are imprecisely
and incompletely represented and also because queries are themselves vague. Thus,
exclusively computing exact answers often leads to too much silence (or to a too low
recall since the silence is the ratio of the number of relevant documents not retrieved
to the total number of relevant documents). Different approaches have been devel-
oped to compute approximate answers and thus account for this intrinsic vagueness.
Contrary to the situation where only exact answers are sought, approximate answers
have to be ordered. Otherwise, any resource could be considered as answering a
query and there would be too much noise. Thus, computing approximate answers
induces the construction of a ranking function. Whenever queries and indexations
are built on the same language, ranking functions are usually based on a measure
of the distance between a query and an indexation. Numerical approaches are gen-
erally used, especially vectorial methods (There are also probabilistic approaches
(cf. [vR79] or [Fuh00]) and fuzzy approaches (cf. [TBH03b])). Nevertheless, com-
binatorial approaches using graph transformations and van Rijsbergen’s uncertainty
principle can also be used (cf. [GC05]).
The main drawback of a labeled graph approach is that it requires (at least par-
tial) manual indexing, since it is hard to automatically build faithful complex index-
ations. This point is discussed in the conclusion. Information retrieval in its present
acceptation described above, i.e., document retrieval, is a speciﬁc resource localiza-
tion problem. A resource localization problem can be described as follows: Given a
set of resources described by a metadata base, and given a query, ﬁnd the resources

380
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
answering the query. More precisely, ﬁnd in a metadata base the metadata satisy-
ing the properties expressed by a query. We focus here on content-search retrieval
or more generally on annotation-based retrieval, i.e., ﬁnd in an annotation base the
annotations (therefore the resources) which satisfy a query. Let us call this the ARR
problem.
13.1.2.2 Editing
The ARR problem is itself important but it can also be a subtask of a very gen-
eral editing problem. Let us assume that one wants to edit a new document using
existing materials rather than from scratch. Materials are then annotated (existing)
documents or document parts. Document annotations are used for retrieving docu-
ments relevant to a new publication speciﬁcation. Thus, in this situation, annotations
are information added to resources in order to transform them into bricks useful
for building new documents. One goal of annotations is then to allow the “recon-
textualization,” the “repurposing,” of the resources. If queries are able to express
publication speciﬁcations then the editing process can be aided by an ARR system.
Finally, an annotation base can be considered as a knowledge base associated with
a set of resources, designed to facilitate editing problems. In this framework, infor-
mation retrieval can be considered as the simplest editing problem. Indeed, it can be
considered like the construction of a new document composed of a list of (existing)
documents responding to a query.
13.1.3 Components of an Annotation System
The main components of an annotation system based on conceptual graphs are
brieﬂy described as follows.
• The data language for representing annotations is composed of nested typed
graphs.
The vocabulary is decomposed into modules and graph types represent sorts of
annotations. Signatures and constraints are used to prevent the construction of
absurd annotations. Rules are used to represent common implicit (and exact)
knowledge. Plausible knowledge, deﬁned by schema graphs, are used to help
annotators. For instance, a schema graph associated with a concept type t gathers
typical or plausible information commonly accompanying the occurrence of an
entity of type t.
• The query language, used for searching annotation bases, is also based on nested
typed graphs.
Elementary queries are graphs with the same form as annotations, i.e., nested
typed graphs on the same vocabulary as the annotations. Elementary queries can
be combined with the usual boolean connectors (and, or, not).

13.2 Annotation Base
381
• Answers are computed by graph operations.
Graph homomorphisms are used for computing exact answers. An exact answer
to a query is composed of all annotations which are specializations of the query.
The soundess and completeness of NTG homomorphism with respect to deduc-
tion in FOL guarantees that this approach complies with the logical view of In-
formation Retrieval. Versatile matching algorithms for computing approximate
answers can be based on graph transformations. A general framework for build-
ing approximate answers is proposed hereafter.
• A graphical user interface is needed because the intended users are not neces-
sarily computer scientists nor engineers. More generally, friendly tools for build-
ing and interrogating annotation bases have to be developed, as well as easily
explainable answering mechanisms. Graphs are especially useful to explain to
end-users how the system works because knowledge and reasonings can be vi-
sualized in a way that is easily interpretable in natural language. Systems aiming
at helping the solution of vague problems such as information retrieval should
allow users to have maximal control over each step of the process:
– entering and understanding the data (labeled graphs),
– understanding results given by the system (labeled graphs),
– understanding how the system computes results (easily vizualizable graph op-
erations).
• When the resources are electronic resources, an important task of an annotation
system involves presenting the resources to the annotator, giving him/her func-
tionalities for decomposing a resource and attaching annotations to the resources.
This task markedly depends on the resource types (e.g., video, image, text docu-
ments, etc.), and this issue is not addressed here.
13.2 Annotation Base
An annotation base is basically composed of a set of annotations that are nested
typed graphs built over a given vocabulary V gathering the notions needed for ade-
quately representing a set of resources. Different kinds of knowledge can be added
to a vocabulary in order to help and to control the work of an annotator. We dis-
tinguish between exact knowledge, which can be automatically used by the system
in the search process or to complete annotations, and plausible knowledge, which
must be validated by the user before being taken into account by the system.

382
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
13.2.1 Exact Knowledge
Exact knowledge consist of rules, relation signatures, constraints, and individual
graphs.
• Rules can represent knowledge of the form “if information is present (within an
annotation) then further information can be added (to this annotation).” This kind
of rule can be represented by the rules studied in Chap. 10. Using rules lighten
the annotation work since they can represent implicit knowledge (e.g., if x is the
mother of y, then y is a child of x).
Rules can be used in two ways. They can be used to automatically complete
an annotation by implicit and general knowledge. They can also be used by the
search process which simultaneously queries an annotation base and a set of rules
without changing the annotations.
• Positive constraints (“if information is present—within an annotation– then fur-
ther information has to be present—in this annotation”) are used to help an an-
notator to not forget to represent important information. When an annotator val-
idates an annotation, if a positive constraint is violated then the missing part is
shown, and the annotation will be accepted only when it will be supplemented
in order to respect the positive constraint. Such positive constraints can be repre-
sented by the constraints studied in Chap. 11.
• Relation signatures and negative constraints (“if information is present—within
an annotation—then further information cannot be present—in this annotation”)
are used to avoid the construction of absurd annotations.
• An individual graph for the individual marker m is an SG with a speciﬁc concept
node having m for marker and called the head of the individual graph. Such a
graph represents general and exact knowledge concerning m. Individual graphs
are considered facts and are added to the annotation base when querying this
base. An individual marker m can have several individual graphs that represent
different ways of describing the entity denoted m. As rules, representing general
information in individual graphs reduces the tedious task of entering the same
information several times.
Deﬁnition 13.1 (Annotation base). An ontology O is composed of a vocabulary
V = (TC(T,B),TR,TG,I), a set C of relation signatures and of constraints over V,
and a set of rules R over V. An annotation base over O is composed of a set A of
nested typed graphs over V and of a set G of individual graphs over V. Furthermore,
the graphs in A and G respect C.
Before presenting prototypical knowledge, we present the module notion, which
is another way to help and control the annotator’s work.

13.2 Annotation Base
383
13.2.2 Modules
Graph types are used to represent different sorts of annotation. Each sort of anno-
tation may use speciﬁc concept and relation types, and these types can be gathered
within a part of V called a module. With the module notion the vocabulary can thus
be restricted to a subset dedicated to representing a speciﬁc kind of annotation. For
instance, let us assume that we have to annotate a collection of 18th century paint-
ings. A part of the annotation can concern the painting technique (e.g., oil on canvas
or watercolors, the palette, the distribution of forms, etc.) and another part can con-
cern the theme (e.g., a battle or peasants in the ﬁelds). In such a situation, terms of
the vocabulary needed to describe painting techniques can be pooled within part of
the vocabulary, while another part can contain the terms needed to describe what is
painted. Such a vocabulary part is called a module. More precisely,
Deﬁnition 13.2 (Module). A module of a vocabulary V = (TC(T,B),TR,TG), where
TC(T,B) is the set of acceptable conjunctive types generated by the primitive type
set T and the banned type set B, is a triple m = (T ′
C(T ′,B′),T ′
R,T ′
G), where:
• T ′ is a subset of T, and B′ is the set of maximal elements of B⊓∩T ′
• T ′
R is a subset of TR
• T ′
G is a subset of TG
T ′
C,T ′
R,T ′
G are ordered by the partial orders on TC,TR,TG respectively. A module
denoted m(g) is associated with any graph type g .
The whole vocabulary V can be considered as a module, so if a graph type g does
not correspond to an annotation sort then V can be associated with g, i.e. m(g) = V.
Otherwise, V is the default module associated with a graph type. Note that if a
vocabulary is equipped with a signature function, then a module is not necessarily
a (sub)vocabulary because the concept types of the signature of a relation in T ′
R can
be outside T ′
C.
The partial order on graph types induces constraints on the associated modules.
Let g and g′ be two graph types with g′ ≤g. An annotation of type g′ is an annotation
of type g, thus a type used in module m(g′) must be interpretable in module m(g).
The simplest way to fulﬁll this condition is to assume that any type in m(g′) is also
in m(g). Let us assume that m(g) = (TC,TR,TG) and m(g′) = (T ′
C,T ′
R,T ′
G), then m(g′)
is included in m(g) if T ′
C ⊆TC, T ′
R ⊆TR, and T ′
G ⊆TG.
Deﬁnition 13.3 (Modular vocabulary). A modular vocabulary is a triple (V,
M,m), where V is a vocabulary, M is a set of modules of V and m is a mapping
from the graph type set of V to M. Moreover, the mapping m satisﬁes the condition:
For any graph types g and g′ if g′ ≤g then m(g′) ⊆m(g), i.e., m is monotonous for
the inclusion order.
An NTG G built over V respects a modular vocabulary (V,M,m) if for each
typed graph (gi,Gi) in a typed box of G, the graph Gi is built over m(gi), i.e., the
module which is associated with the graph type gi.

384
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
Thus, a modular vocabulary allows the restriction of the terms used when con-
structing part of an annotation corresponding to a given viewpoint. It is easy to
check if an annotation respects a modular vocabulary. An annotator tool may also
dynamically control the construction of annotations so that they respect a modular
vocabulary.
13.2.3 Plausible Knowledge
An annotation can be constructed from scratch, i.e., from an empty graph. If there
are several annotators, there may be a great variety among annotations of similar
resources. The schema graph notion aims at directing the construction of an anno-
tation by proposing annotation templates.
A schema graph is associated with a concept type or with a relation type or with a
graph type. A schema deﬁnes a usual or plausible context of a concept, or relation or
graph of some type. Hence, schema graphs are conceptual graphs whose speciﬁcity
is to be used by annotation tools in a particular way. Contrary to exact knowledge,
schemas are not used for reasoning, at least in the system we are describing, but
only to suggest pieces of annotation to a user (i.e., an annotator).
Let us ﬁrst explain how a graph type schema is used. Let g be a graph type
corresponding to a kind of annotation. A schema for g is an NTG which respects
m(g), i.e., the module associated with g. Such a schema is an annotation template, it
consists of general and frequent notions appearing when annotating a resource with
respect to g. Several schemas can be associated with a given graph type g.
When a user begins to annotate a resource with respect to the annotation view-
point g, the system proposes a schema associated with g as a starting point. Note
that this is only a starting point, and a proposal, but the user is free to modify the
proposal at will. Otherwise, if an annotation should specialize any schema of a type
appearing in this annotation, then a schema would be a kind of constraint, i.e., a
kind of exact knowledge.
Example. In a project aimed at annotating ﬁlm interviews of researchers, the way
a language is used by a researcher is described in a rhetoric part of an annotation.
Figure 13.1 is the schema associated with this rhetoric graph type.
In a schema graph for a concept or a relation type t, there is a speciﬁc node, called
the head of the graph, with the type t. Nodes of an annotation whose types have
schemas are called extension nodes. Such a node c of type t is used to propose the
user an extension of the annotation in construction by merging the head of a schema
for t with c. Like graph type schemas, the user is free to transform the obtained
annotation at will. After merging of a relation schema, the head does not respect the
arity condition since it has twice the required number of neighbors. The user has to
modify the thus-obtained graph in order to transform it into a graph respecting the
vocabulary.
Like graph types, a concept type or a relation type can have several schemas,
each schema represents a way of describing an entity or a relation.

13.3 Querying an Annotation Base
385
useFor
Thematic
Speech
KnowledgeLevel
ProfessionalUse
assume
locTmp
Date
partOf
Discussion
objectOf
Fig. 13.1 A schema for the rhetoric graph type
Example. Figure 13.2 shows an example of a schema for the concept type Movi-
eTrip corresponding to a children’s viewpoint.
MovieTrip
Person
agent
agent
Buy
Buy
object
PopCorn
object
Ticket
object
Child
recipient
agent
Eat
childOf
takePart
takePart
Fig. 13.2 A schema graph for the MovieTrip concept type
13.3 Querying an Annotation Base
First we present how exact answers to a query can be computed using graph ho-
momorphisms. Then a method for computing approximate answers, based on graph
transformations and graph homomorphisms and implementing van Risjbergen’s un-
certainty principle, is outlined.

386
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
13.3.1 Exact Search
Let A be an annotation base over O. The simplest form of a query is a nested typed
graph over the vocabulary of O. Let Q be such a query. Different answers of Q over
A can be deﬁned as follows:
• The set spec(Q,A) of elements in A, i.e., annotations, which are specializations
of Q, i.e., spec(Q,A) = {A ∈A | ∃π, homomorphism from Q to A},
• for any element A in spec(Q,A), the set of homomorphisms from Q to A or the
set of images of Q by these homomorphisms,
• the set of resources res(Q,A) which are referenced by the elements in spec
(Q,A).
Q can be decorated in order to ﬁlter the answers (e.g., consider only homomor-
phisms that do not change the labels of some nodes speciﬁed in the query) or to
restrict the answers (e.g., return only images of some nodes speciﬁed in the query).
Simple queries can be combined by boolean operators implemented as set op-
erators on the answer sets. Let Q be a query graph, A an annotation base, and
spec(Q,A) the answer set. The elementary exact search can be simply extended
by the classical boolean operators AND, OR, and NOT as follows.
• spec(Q AND Q′,A) = spec(Q,A)∩spec(Q′,A),
• spec(Q OR Q′,A) = spec(Q,A)∪spec(Q′,A),
• spec(Q AND NOT Q′,A) = spec(Q,A)\spec(Q′,A).
To sum up, the fundamental problem to solve for computing answers in this
framework is to compute the set of homomorphisms from a nested graph to a nested
graph.
13.3.2 Approximate Search
The general approach described in this section has two speciﬁcities. First, it is a
combinatorial approach based on labeled graphs and not a numerical approach as
is usually the case for approximate search, and, secondly, it is a specialization of
the van Rijsbergen’s uncertainty principle for information retrieval and thus it still
complies with the logical view of information retrieval.
Let us ﬁrst recall van Rijsbergen’s Uncertainty Principle, which can be stated as
follows: “Let f and g be two formulas in a logic L, a measure of the uncertainty
of f |= g relative to a knowledge base is determined by the minimal transformation
from g to g′, such that f entails g′ in L.” (cf. [JN98]). Instead of transforming the
conclusion, one can also consider a transformation of the hypothesis, i.e., f.
A way of implementing this very general principle in our graph-based framework
is to deﬁne a set of graph transformations T equipped with a total preorder ⪯. As
already explained in Sect. 13.1.2, a ranking function, i.e., a total (pre)order, of the
answers is mandatory when approximate answers are searched.

13.3 Querying an Annotation Base
387
The total preorder ⪯deﬁned on T is used to deﬁne a ranking function as follows.
Let Q be a query graph over an annotation base A. Let us assume that the answer
set is deﬁned by specT (Q,A) = {A ∈A | ∃t ∈T ,t(A) |= Q}. Let t1 (resp. t2) be
a minimal transformation such that t1(A1) |= Q (resp. t2(A2) |= Q). If t1 ⪯t2, then
A1 is ranked before A2. Note that if the identity transformation is the only minimal
element in T , then the exact answers are ranked before the approximate answers.
Instead of transforming the annotations, we can also transform the query. Trans-
forming the query is frequently used in the Information Retrieval domain (it is called
“query reformulation”). In an annotation-based system, it can be interesting to trans-
form the annotations instead of the queries. Indeed, if a user is satisﬁed by an ap-
proximate answer when querying an annotation base, this answer has been obtained
from a modiﬁed annotation. Then this modiﬁed annotation can be included (or pro-
posed to be included) in the annotation base. Hence, transforming annotations in-
stead of queries in a way makes “living” the annotation base.
With the transformations proposed hereafter, the two approaches can be consid-
ered as equivalent and this is basically due to the fact that annotations and queries are
elements of the same language. If there is a transformation t ∈T such that t(A) |= Q,
then there is a transformation t′ in a set of graph transformations dual to T such that
A |= t′(Q) and conversely.
The transformations are deﬁned as sequences of elementary transformations. An
elementary transformation can be:
• a node label substitution,
• the identiﬁcation of two concept nodes,
• a node adjunction.
For any query Q, by applying such a transformation to an annotation A, the number
of homomorphisms from Q to A may increase. For any query Q and any annotation
A, A can be transformed in such a way that A specializes Q. Thus, if all the se-
quences of elementary transformations are considered, it is always possible to build
transformations t such that the number of homomorphisms from Q to the trans-
formed annotations t(A) is ≥1, i.e., any A (approximately) answers Q. Therefore,
in such an approach, a fundamental problem is to restrict the transformation set to
admissible transformations.
A transformation t is admissible for an annotation A if, whenever A is a relevant
annotation for a resource, then t(A) is also relevant for this resource. t(A) can be
less relevant than A but nevertheless t(A) should still be relevant for the resource
annotated by A. Admissible transformations and ranking functions are difﬁcult to
abstractly deﬁne because these notions are strongly context-dependent. They de-
pend on the ontology qualities (e.g., precision, completeness), on the annotation
base qualities, on the user competence, etc. We only give here the main ideas in a
general way which have to be speciﬁed for any application.
1. Admissible elementary transformations Let us begin with three sorts of elemen-
tary transformations.

388
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
• Label substitution. A way of deﬁning an admissible node label substitution is
to consider the ordered structure of the vocabulary. Note ﬁrst that one only has
to consider the substitution of a label by a non-smaller one since the substi-
tution of a label by a smaller one is taken into account in the homomorphism
notion. Then the precision of the vocabulary as well as that of the annota-
tions have to be taken into account. Let us consider the (concept or relation)
type substitution. Many deﬁnitions can be proposed on the basis of some “dis-
tance” between types. For instance, substituting y for x can be admissible if
there is a path from x to y (e.g., if x and y are concept types, then this is a path
in TC ) having no more than p ascents and q descents (with p and q being two
non-negative integer parameters).
• Identiﬁcation of concept nodes. In the same way, an identiﬁcation of two con-
cept nodes can also be said to be admissible if some distance between the
labels is not too large (a restrictive way is to only allow identiﬁcation of two
concept nodes with the same label).
• Node adjunction. It is harder to propose a general deﬁnition of a natural ad-
missible adjunction. Therefore, if node adjunction is an annotation transfor-
mation worth considering (for instance if it is known that the annotations are
usually incomplete), a solution is to consider admissible the adjunction of a
concept node labeled ⊤or the adjunction of a maximal k-ary relation between
k concepts which are not already linked.
2. Admissible transformations After deﬁning admissible elementary transforma-
tions, admissible transformations have to be deﬁned, i.e., what is an admissible
sequence of elementary transformations. A sequence of elementary transforma-
tions is admissible if it consists of a limited number of admissible elementary
transformations, e.g., no more than α label substitutions, no more than β concept
node identiﬁcations, and no more than γ node adjunctions. All of these numbers
can be ratios relative to the node numbers of A. In this way, the labeling function
and structure of the annotation are only slightly modiﬁed.
3. Total preorder. A total preorder ⪯on the set of admissible transformations now
has to be deﬁned. Functions of the numbers of elementary transformations can be
used, the simplest one is the length of the sequence, but one can also weight the
importance of the elementary transformation (e.g., count a for a label substitu-
tion, b for a node identiﬁcation and c for a node adjunction, with a ≤b ≤c). The
different numerical parameters can be deﬁned by the user or by an annotation
base administrator.
13.4 Annotation and the Semantic Web
The semantic web is the domain in which the term semantic annotation is the most
frequently used. So, let us make a little digression into the semantic web even

13.4 Annotation and the Semantic Web
389
though the approach here described is not specially dedicated to web documents
(cf. [HS03a]).
Usually a semantic annotation of a web document, i.e., a web annotation, is a
RDF (Resource Description Framework) graph associated with the document. RDF
is dedicated to the web (cf.http://www.w3.org/TR/rdf-primer): “RDF is intended to
provide a simple way to make statements about Web resources, e.g., Web pages ...
RDF is based on the idea of identifying things using Web identiﬁers (called Uniform
Resource Identiﬁers, or URIs), and describing resources in terms of simple proper-
ties and property values. This enables RDF to represent simple statements about
resources as a graph of nodes and arcs representing the resources, and their proper-
ties and values.” An RDF graph is a set of RDF statements, and an RDF statement
is a 3-tuple (resource, property, value).
The feasibility of this approach (i.e., associating RDF graphs to a large number
of web documents) has been criticized. The main critiques are as follows: The RDF
model is too complicated for most of users, there is no methodology (no strict tem-
plate structure even if one considers ontology-based semantic annotations) so the
graphs are too author-dependent, it is difﬁcult to assess if an RDF graph is a sufﬁ-
cient and relevant annotation, it is a labor-intensive and time-consuming task even
for users ﬂuent with RDF, one does not know how to build a common vocabulary for
a large part of the web, the size of the RDF graph can be important (e.g., complex-
ity of an RDF graph describing a photo). Despite these criticisms, web annotation
platforms have been constructed (cf. for instance [Ann01], [HS03b]).
Note that besides this mainstream approach there are other approaches to the
semantic web which may seem less ambitious but may be more effective in bringing
some “semantics” into the web (cf. [QV07]).
Naturally, almost all criticisms on RDF can also apply to CGs. Indeed, an RDF
graph is a labeled multigraph and can be easily translated into an SG.
Building vocabularies, rules or constraints for large parts of the web seems un-
feasible in the near future. Thus, we do not recommend replacing RDF graphs by
CGs but rather to use CGs for speciﬁc applications (not “The Web” even though
web resources can be considered) in which the expensive process of construction of
a knowledge base is not too costly relative to the hoped beneﬁt, e.g., aided publica-
tion and editing.
Tim Berners-Lee in [BL01] states: “I think the tendency of the CG examples to
relate to natural language rather than hard logic made it more difﬁcult for someone
of my own leanings toward rigid logical processing for the Sweb to understand what
the CG folks were driving at.” And at the end of the same note: “All in all, there is
a huge overlap, making the two technologies very comparable and hopefully easily
interworkable.”
Since then, studies have compared RDF graphs and CGs (e.g., [ME99], [CDH00]).
An important result was published in 2005 that relates RDF reasonings and graph
homomorphisms (cf. [Bag05]). Simple RDF graphs are provided with a model the-
oretic semantics [Hay04]. This semantic is used to deﬁne an entailment relation:
An RDF graph G entails an RDF graph H iff H is true whenever G is. There is
a ﬁnite procedure characterizing entailments (the Interpolation Lemma [Hay04]),

390
13 An Application of Nested Typed Graphs: Semantic Annotation Bases
which is sound and complete with respect to entailment. It has been extended to
account for more expressive languages (RDF, RDFS [Hay04], and other languages,
e.g., [tH04]). All of these extensions rely on a polynomial-time initial treatment of
graphs, with the hard kernel being the basic simple entailment, which is an NP-hard
problem. Baget [Bag05] has reformulated this fundamental entailment relation as a
graph homomorphism.
The beneﬁts of such a reformulation are frequently mentioned throughout this
book. However, the huge size of the web and its intrinsic unstructured nature mean
that a complete procedure for exact search would likely be unfeasible in the near
future.
13.5 Conclusion
Applications using annotation bases generally require an interactive system to be
built in which a user and the search process communicate. The intrinsic vague-
ness of annotations and sometimes of the user’s goals lead to searches for exact
answers but also approximate answers. In such situations, it is important for the
user to understand the way the system functions. This is hard to achieve for numer-
ical approaches, which are generally used for computing and ranking approximate
answers, but it is one of the main motivations for using graphs. As very often stated
in this book, (simple) graph transformations on (rather) small graphs are easily vi-
sualizable and understandable by non-specialist users.
Conceptual graph systems have been developed (e.g., [CH93], [CH94], [Mar97],
[CDH00]), and the nested conceptual graph framework presented in this chapter was
implemented and used in different applications (e.g., [Gen00],[GC05], [MLCG07]).
Schema graphs were introduced by Sowa [Sow84], who used schemas for plausi-
ble reasoning. In this chapter, schemas are only used to suggest to a human annotator
information that can be useful to introduce in an annotation.
The main drawback of a labeled graph approach is that it requires (at least partial)
manual annotating. As noted in the previous section for RDF annotations, manually
annotating a resource has many drawbacks. Nevertheless, in some cases, automatic
procedures cannot be used, and manual annotation is required in situations such as:
• the documents are not in electronic form or not directly available through the
system (e.g., a traditional book library),
• the documents are images, sounds, videos, etc., so extraction of high level con-
cepts and relations is necessary to take complex queries into account, and there
is no (completely) automatic annotating mechanism which allows extracting of
high level concepts from documents such as videos (e.g., [Fuh00], [Sme00]),
• the documents are texts but more precise representation than sets of keywords
(i.e., those currently obtainable through natural language processing systems) of
the content is required because the users are specialists with speciﬁc tasks (e.g.,
editing, cf. Sect. 13.1.2.2)).

13.5 Conclusion
391
Some experiments have shown that manual annotation with labeled graphs is
not much more difﬁcult than annotating with other manual annotation systems
(cf. [GC97]). The hard part of manual annotating concerns more the analysis of
the document than the annotation language.
Finally, such an approach will be directly usable if one day automatic methods
for extracting high-level, i.e., conceptual, structures from electronic resources are
developed .

Appendix A
Mathematical Background
Overview
The formalization of conceptual graphs relies upon different domains of discrete
mathematics, mainly graph theory, ordered set theory and First Order Logic (FOL).
This appendix is a short summary of the basic mathematical notions needed to un-
derstand the formalization of conceptual graphs presented in the book. More de-
tailed notions are given in the different chapters when necessary.
In Sect. A.1, basic notions concerning the naive set theory (e.g., set operations,
mappings, relations) are reviewed. Different sorts of graphs encountered in the book
(e.g., directed and undirected graphs, trees, bipartite graphs, hypergraphs) are de-
ﬁned in Sect. A.2. Elementary graph theoretical notions and the fundamental notion
of graph homomorphism are also reviewed in Sect. A.2. In conceptual graph models,
node label sets are ordered. Section A.3 deals with ordered sets (basic algorithms
are given in Chap. 6). Section A.4 reviews basic notions in ﬁrst order logic. The last
section is a very sketchy introduction to algorithm and problem complexity.
For readers who wish a deeper presentation of these mathematical notions, here
is a list of background textbooks (with exercises) whose terminology we have gen-
erally followed: Introduction to Graph Theory [Wes96], Introduction to Lattices and
Order [DP02], Mathematical Logic for Computer Science [BA01] and Introduction
to Algorithms [CLRS01].
Our theorization of conceptual graphs is also closely related to several areas
of computer science, especially relational database theory and constraint process-
ing. Notions concerning these two domains are given when needed, especially in
Chap. 5.
393

394
A Mathematical Background
A.1 Sets and Relations
A.1.1 Sets and Elements
We begin with basic notions from (naive) set theory.
A set is a collection of objects called elements of that set. The statement that an
object x is an element of a set S is denoted x ∈S, and x /∈S means that x is not an
element of S. A set S can be described
1. either by listing its elements (e.g., S = {a,b,c} is the ﬁnite set composed of the
three elements a, b and c, the inﬁnite set of positive integers is denoted N =
{1,2,...,n,...}),
2. or by giving a set U and a property p charaterizing, among the elements of U,
those belonging to S, notation S = {x ∈U | p(x)} (e.g., S = {x ∈N | 2 ≤x ≤5}
is the set {2,3,4,5}).
The empty set is the set without any element, it is denoted ∅. The number of
elements of a set S is denoted | S |. A set S is a subset of a set T, in symbols S ⊆T,
if any element of S is also an element of T. The set of subsets of a set S is denoted
2S.
The union of two sets S and T is the set S ∪T = {x | x ∈S or x ∈T}, the inter-
section of S and T is the set S∩T = {x | x ∈S and x ∈T}, the difference of two sets
is the set S \T = {x | x ∈S and x /∈T}. Two sets are disjoint if their intersection is
the empty set.
A set of non-empty subsets of a set S is a partition of S if the union of the subsets
is equal to S and if the subsets are pairwise disjoint. More formally,
Deﬁnition A.1 (Cover and partition). Let P = {S1,...,Sk} be a set of non-empty
subsets of S. P is a cover of S if S = i=k
i=1 Si, if, furthermore, ∀i ̸= j one has Si ∩Sj =
∅, then P is called a partition of S.
Example. Let us consider the content of a child toybox. It can be represented as a
set over which covers and partitions can be deﬁned, e.g., let us assume that the toys
are clustered by colors, if each toy is monocolor, then a partition is obtained, if toys
can have several colors then a cover is obtained.
Values of an attribute about objects (e.g., age of persons) can deﬁne partitions
(e.g., people gathered by age respecting a set of disjoint intervals) or covers (non-
disjoint intervals) over a set of these objects. Usually levels in a taxonomy deﬁne
partitions, e.g., a set of mammals is partitioned into cats, dogs, etc.
A k-tuple, k integer ≥1, over a set S is a sequence of k not necessarily distinct
elements of S, a k-tuple is denoted (x1,...,xk). The cartesian product of ﬁnitely
many sets S1,...,Sn, written S1 × ...× Sk is the set of all k-tuples (x1,...,xk) such
that x1 ∈S1,...,xk ∈Sk.
Example.
Let T = {car,truck,bicycle} and U = {cheap,expensive}.
T ×U = {(car,cheap),(car,expensive),(truck,cheap),(truck,expensive),(bicycle,

A.1 Sets and Relations
395
cheap),(bicycle,expensive)}.
Let I = {a,b} then I ×I = {(a,a),(a,b),(b,b),(b,a)}.
A.1.2 Relations and Mappings
The relation notion is the fundamental notion of relational databases and of ﬁrst
order logic models. A relation is a subset of a cartesian product S1 × ... × Sk. The
number k of sets in the cartesian product is called the arity of the relation. A binary
relation over the same set, i.e., a subset of S×S, is simply called a binary relation.
Example. Kinship relationships concerning a set of persons can be represented by
binary relations, e.g., the relation childOf can be deﬁned by (x,y) ∈childOf if
x is a child of y, also denoted childOf(x,y).
A ternary relation play3 can be deﬁned over C ×C × T, where C is a set of
children and T a set of toys, by (x,y,z) ∈play3 if the children x and y are playing
with the toy z.
Information about a person can be represented by a 5-tuple (name,address,age,-
profession,income), in this case the set of 5-tuples of a group of persons is a relation
of arity 5.
Given sets S and T a partial mapping from S to T is a relation f ⊆S × T such
that for all x ∈S and for all y,z ∈T, if (x,y) ∈f and (x,z) ∈f, then y = z. A partial
mapping is also called a function. If f is a partial mapping, then (x,y) ∈f is also
denoted y = f(x). Let f be a partial mapping from S to T.
The domain of f is the subset of S deﬁned by: dom(f) = {x ∈S | ∃y ∈T,(x,y) ∈
f}, the range of f is the subset of T deﬁned by: range(f) = {y ∈T | ∃x ∈S,(x,y) ∈
f}.
A partial mapping f such that dom(f) = S is called a mapping. A mapping is
also called a total function. A mapping f ⊆S×T is generally denoted f : S →T.
A mapping f from S to T is surjective if range(f) = T. f is injective if for all x
and y in S, f(x) = f(y) implies x = y. An injective and surjective mapping is called
a bijective mapping. An injective (resp.surjective, bijective) mapping is also called
an injection (resp. surjection, bijection). Let f be a bijection from S to T then the
inverse of f, denoted f −1, is the bijection from T to S deﬁned by: f −1(x) = y if
f(y) = x.
More generally, let f be a partial mapping from S to T and let x ∈T, then f −1(x)
is equal to the set {y ∈S | f(y) = x}. f is injective if and only if for all x ∈T,
| f −1(x) |≤1.
Example. Let S be a ﬁnite set of n elements {s1,...,sn}. The mapping f from 2S to
the cartesian product of n times the set {0,1} deﬁned by ∀S′ ⊆S, f(S′) = (x1,...,xn)
with xi = 1 if si ∈S′ and xi = 0, otherwise is a bijection. The image of S′ is called
the characteristic vector of S′.
Let S be a set of companies and phoneNumb be a binary relation, such that
(x,y) is in phoneNumb if y is a phone number of the company x. If a company

396
A Mathematical Background
can have only one phone number, then phoneNumb is a mapping from the set of
companies to the set of phone numbers, otherwise it is a binary relation which is
not a mapping. Furthermore, if two companies cannot have the same phone number
then phoneNumb is injective.
Given a mapping f : S →T and S′ ⊆S the restriction of f to S′ is the mapping
fS′ : S′ →T deﬁned as follows, fS′(x) = f(x) for all x ∈S′. Let f : S →T and
g : U →T be two mappings with S ⊆U. The mapping g is an extension of f if for
all x ∈S, f(x) = g(x), i.e., gS = f.
Let R be a k-ary relation R ⊆S1×...×Sk, and {A1,...,Ak} be a set of k attributes
(or names or variables), a tuple t = (x1,...,xk) of R can be identiﬁed to a mapping,
still denoted t, from the attribute set to the union of the Si deﬁned as follows: for all
i = 1,...,k, t(Ai) = xi. In this situation, Si is called the domain of the attribute Ai
and a relation R can be identiﬁed to a set of mappings from the attribute set to the
union of the domain attributes.
Relations are sets, hence set operations (union, intersection,. . . ) apply to rela-
tions. Three other basic operations are especially important in relational databases:
projection, join, and selection. The cartesian product is not commutative and the
same set can occur several times in a cartesian product, hence the named attributes
are used to deﬁne these operations.
1. Projection. Let R be a k-ary relation with attributes {A1,...,Ak} and {B1,...,Bl}
a subset of {A1,...,Ak}. The projection of R onto {B1,...,Bl} is the set of l-
tuples which are restrictions of all tuples t in R to {B1,...,Bl}, .
2. Join. Let R be a relation with attributes A = {A1,...,Ak,B1,...,Bl} and R′
a relation with attributes A′ = {A′
1,...,A′
k′,B1,...,Bl}, with Ai ̸= A′
j for all i
and j. The join of R and R′, denoted R 1 R′, is the set of tuples t with at-
tributes A′′ = {A1,...,Ak B1,...,Bl,A′
1,...,A′
k′} such that the restriction of t to
{A1,...,Ak,B1,..., Bl} is a tuple of R and the restriction of t to {A′
1,...,A′
k′,B1,
...,Bl} is a tuple of R′.
3. Selection. Let R be a k-ary relation with attributes {A1,...,Ak}, {B1,...,Bl} a
subset of {A1,...,Ak}, and for all i = 1,...,l, ai be an element of the domain of
Bi. The selection of R with respect to (a1,...,al) is the set of tuples t of R, such
that for all i = 1,...,l, t(Bi) = ai.
A binary relation R over a set S is a subset of S×S. Basic properties for a binary
relation R over S are:
• reﬂexivity, i.e., ∀x ∈S (x,x) ∈R,
• transitivity, i.e., ∀x,y,z ∈S if (x,y) ∈R and (y,z) ∈R, then (x,z) ∈R,
• symmetry, i.e., ∀x,y ∈S if (x,y) ∈R , then (y,x) ∈R,
• antisymmetry, i.e., ∀x,y ∈S if (x,y) ∈R and (y,x) ∈R, then x = y.
A reﬂexive, transitive and symmetric relation is called an equivalence relation.
Equivalence relations over a set S and partitions over S are closely related since there
is a bijection between them. Indeed, let R be an equivalence relation over S. The set
of all elements s′ in S equivalent to an element s in S, i.e., such that (s,s′) ∈R,

A.2 Graphs
397
is called the class of s modulo R. The set of classes modulo R is a partition of S.
Reciprocally, to any partition of S an equivalence relation on S can be associated
as follows: two elements are equivalent iff they belong to the same element of the
partition.
A reﬂexive, transitive and antisymmetric relation is called an order or a partial
order. Section A.3 is devoted to order relations which are important in our approach.
A.2 Graphs
A.2.1 Directed Graphs
Deﬁnition A.2 (Directed graph). A directed graph is a notion closely related to a
binary relation over a set since it is pair (X,U) composed of a set X and a binary
relation U over X, i.e., U ⊆(X ×X). An element of X is called a vertex or a node,
an element of U is called an arc.
An arc (x,x) is called a loop. If (x,y) is an arc, then y is a successor of x and x is
a predecessor of y.
One very attractive feature of graphs is that they can be represented by drawings:
a point is assigned to each vertex and an arc (x,y) is represented by a simple curve
from x to y.
Example. Figure A.1 represents two different directed graphs:
G = ({a,b,c},{(a,b),(b,a),(a,c),(b,c),(c,c)}) and
H = ({a,b,c,d},{(a,b),(b,a),(a,c),(b,c),(c,c)}) which have the same arc set.
c
a
d
c
b
a
H
b
G
Fig. A.1 Directed graphs
A directed graph is simply called a graph in the sequel of this section. Let G =
(X,U) be a graph, Y ⊆X and V ⊆U. The subgraph of G induced by Y is the graph
G(Y) = (Y,U ∩(Y ×Y)). A stable set of a graph G = (X,U) is a subset Y of X such
that the subgraph of G induced by Y has no arcs, i.e., U ∩(Y ×Y) = ∅. A partial
graph of a graph G = (X,U) is a graph H = (X,V) where V ⊆U.

398
A Mathematical Background
A path of a graph G = (X,U) is a sequence x1 ...xk of vertices of G such that
k ≥1 and for all i = 1,...,k −1, (xi,xi+1) is an arc of G. An elementary path is
a path having all its vertices distinct. A circuit is a sequence x1 ...xkx1, such that
x1 ...xk is a path and (xk,x1) is an arc. If x1 ...xk is an elementary path, then the
circuit is an elementary circuit.
A vertex y is a descendant of a vertex x if there is a path from x to y, then x is an
ascendant of y. A root r is a vertex which is an ascendant of all vertices, i.e. ∀x ∈X,
there is a path from r to x. An antiroot r is a vertex which is a descendant of all
vertices, i.e. ∀x ∈X, there is a path from x to r.
Let G = (X,U) be a graph. The transitive closure of G is the graph Gt = (X,Ut),
such that (x,y) ∈Ut if there is a path not reduced to a vertex from x to y in G. The
reﬂexive closure of G is Gr = (X,U ∪(X ×X)). The reﬂexo-transitive closure of G
is G∗= Grt.
Example. Figure A.2 presents a graph G and its transitive closure H, r and r′ are
the roots of G.
H
r
r’
G
Fig. A.2 A graph G and its transitive closure H
Deﬁnition A.3 (Quotient graph). Let G = (X,U) be a graph and P = {X1,...,Xk}
be a partition of X. The quotient graph G/P is the graph obtained from G as follows.
For all i = 1,...,k, all vertices in Xi are merged in a new vertex yi whose successors
are the vertices yj such that a vertex in Xj is a successor of a vertex in Xi. Formally,
G/P = ({y1,...,yk},{(yi,yj) | i ̸= j,∃x ∈Xi,∃x′ ∈Xj,(x,x′) ∈U}).
Example. A graph G and its quotient G/P, where P = {{a,b},{c,d},{e, f,g}}, are
drawn in Fig. A.3.

A.2 Graphs
399
X2
X1
g
f
e
d
c
b
a
X3
G/P
G
X1
X2
X3
Fig. A.3 A graph G and the quotient graph G/P, P = {X1,X2,X3}
A.2.2 Homomorphism
The graph homomorphism notion is one of the major mathematical notions used in
the book.
Deﬁnition A.4 (Graph homomorphism). Let G = (X,U) and H = (Y,V) be two
directed graphs. A homomorphism from G to H is a mapping f from X to Y such
that: ∀x,y ∈X, if (x,y) ∈U then (f(x), f(y)) ∈V.
An isomorphism is a bijective homomorphism f such that its inverse f −1 is also
a homomorphism.
Two isomorphic directed graphs have the same structure and only differ by the
names of their vertices.
Example. In Fig. A.4, f deﬁned as follows, f(a) = 2, f(b) = 4, f(c) = 7, f(d) = 5
and f(e) = 6, is an injective homomorphism from G to H.
Let H′ be the subgraph of H obtained by deleting vertices 1 and 3, then f is a
bijective homomorphism from G to H′, which is not an isomorphism.
Let H′′ be the partial subgraph of H obtained by deleting the vertices 1 and 3 and
the arcs (2,6) and (6,7), then f is an isomorphism from G to H′′.
g deﬁned by: g(a) = 4, g(b) = 4, g(c) = 6, g(d) = 5 and g(e) = 6 is a non-
injective homomorphism from G to H.
Let H′′′ be the subgraph of H induced by the vertices 4 and 5 (equivalently,
obtained by deleting from H the vertices 1,2,3 and 6), then h deﬁned by h(a) = 4,
h(b) = 4, h(c) = 4, h(d) = 5 and h(e) = 4 is a surjective homomorphism from G to
H′′′.

400
A Mathematical Background
H
a
c
e
b
1
2
3
4
5
6
7
d
G
Fig. A.4 Homomorphisms
A.2.3 Different Sorts of Graphs
Deﬁnition A.5 (Undirected graph). An undirected graph is a pair (X,E), where
X is a set, called the vertex set, and any element of E, called the edge set, is a subset
of X having either two vertices or one vertex (it is then called a loop).
Paths and cycles are deﬁned for undirected graphs in a similar same way as for
directed graphs, e.g., an elementary path of an undirected graph is a sequence of
distinct vertices such that two consecutive vertices deﬁne an edge.
Deﬁnition A.6 (Connected graph). An undirected graph is connected if there is a
path between any two vertices. A connected component of an undirected graph G is
a connected subgraph H of G, with H being maximal with this property.
Example. The connected components of the graph G in Fig. A.5 are C, D and E
E
C
b
c
e
a
f
d
G
f
e
d
c
b
a
D
Fig. A.5 Connected components
Deﬁnition A.7 (Cut vertex). A cut vertex (or node) is a vertex in a graph whose
deletion increases the number of connected components.

A.2 Graphs
401
Example. In Fig. A.6, the vertex x is a cut vertex. The deletion of x yields a graph
whose connected components are the graphs C, D, E in Fig. A.5.
a
c
e
b
d
f
x
Fig. A.6 Cut vertex
Deﬁnition A.8 (Tree and rooted tree). A tree is an edge minimal connected graph,
i.e., it is a connected graph and the deletion of any edge gives a non-connected graph.
There are numerous characterizations of trees, e.g., between any pair of vertices
there is one and only one path. A rooted tree is an arc minimal directed graph with
a root, i.e., it has a root and the deletion of any arc gives a directed graph without a
root.
A rooted tree T ′ can be obtained from a tree T by choosing a vertex r (its root)
and by transforming each edge into an arc in such a way that for all x the only
(undirected) path from r to x in T is transformed into a (directed) path in T ′.
Whenever only directed graphs are considered, then a rooted tree is often called
a tree.
Undirected graphs are equivalent to symmetric directed graphs. When dealing
with a directed graph (X,U), it can be useful to consider its underlying undirected
graph (X,E), which is deﬁned as follows. Loops of E are loops of U and for x ̸= y,
{x,y} is an edge of E if (x,y) ∈U or (y,x) ∈U.
For instance, it is convenient to ﬁrst deﬁne the connected component notion on
undirected graphs, then to extend this notion to directed graphs: a directed graph is
connected if its underlying undirected graph is connected.
Deﬁnition A.9 (Bipartite graph). A graph G is bipartite if the vertex set is parti-
tioned in two subsets X and Y such that any edge has a vertex in X and the other in
Y.
Bipartite graphs are basic structures underlying conceptual graphs.
Example. In Fig. A.7 G is an undirected graph, H is a tree, H′ is the rooted tree
obtained from H by choosing r for root, and K is a bipartite graph (all these graphs
are connected).

402
A Mathematical Background
r
r
H’
H
G
K
Fig. A.7 Different sorts of graphs
Numerous problems on graphs can be broken down into subproblems on con-
nected components, e.g., a graph is bipartite iff all its connected components are
bipartite. In Fig. A.5, G is not bipartite since D is not bipartite.
Deﬁnition A.10 (k-clique). A k-clique is a graph G = (X,E) such that | X |= k ≥1
and E = {{x,y} | x,y ∈X,x ̸= y}.
If there can be several arcs (or several edges in the undirected case) from x to y,
i.e. if U is no longer a set of ordered pairs but is a family of ordered pairs, then the
structure is called a directed (or undirected) multigraph.
Example. In Fig. A.8, G is a directed multigraph and H an undirected multigraph.
G
H
Fig. A.8 Multigraphs

A.3 Ordered Sets
403
A.2.4 Hypergraphs
Deﬁnition A.11 (Hypergraph).
An hypergraph is a pair (X,E) such that X is a set and E a set of non-empty
subsets of X. X is called the vertex set of the hypergraph and E is called its edge set.
Hypergraphs are a generalization of undirected graphs when an edge can be com-
posed of any non-empty subset of vertices and not necessarily of a pair of vertices
or a loop.
Hypergraphs can be drawn as follows: a point is assigned to each vertex and all
vertices that constitute an edge are enclosed by a closed curve (Venn diagram). If
some vertices belong to several edges, such a diagram can be difﬁcult to draw (and
to read) even though it has a small number of vertices.
Example.
In Fig. A.9, H represents the hypergraph [{a,b,c,d},{{a,b},{a,c},{a,b,c,d}}).
The hypergraph K = ({a,b,c,d},{{a,b},{a,b,c},{a,c},{a,c,d},{b,c},{b,c,d},
{a,b,c,d}}) is more difﬁcult to represent by a Venn diagram.
H
b
c
a
d
Fig. A.9 Hypergraphs
There are different directed hypergraph notions. A directed hypergraph is some-
times deﬁned as an hypergraph whose edges are each split into two subsets, i.e. the
positive and the negative parts of the edge. However, in the book, a directed hyper-
graph is an hypergraph whose edges are each totally ordered (see next section which
deals with ordered sets).
A.3 Ordered Sets
A.3.1 Basic Notions
Deﬁnition A.12 (Order). An ordered set is a pair P = (X,R), such that X is a set
and R is a binary relation on X which is reﬂexive, transitive, and antisymmetric. The

404
A Mathematical Background
binary relation R is called an order (on X). A strictly ordered set is a pair (X,R), such
that X is a set and R is a binary relation on X which is antireﬂexive (i.e., ∀x ∈X one
has (x,x) /∈R), transitive, and antisymmetric. The binary relation R is called a strict
order (on X).
The classical generic notation ≤is used to denote an order, with < denoting its
associated strict order. The notation ≤P is used whenever it is necessary to specify
the order P.
An ordered set is also called a partially ordered set by opposition to a totally or
linearly ordered set which is an ordered set such that any two elements are com-
parable, i.e., ∀x,y ∈X one has x ≤y or y ≤x. A totally ordered set is also called
a chain. An antichain is an ordered set (X,R) restricted to the loops, i.e., such that
R = {(x,x)|x ∈X}. Whenever strict orders are considered, an antichain has an empty
set of arcs.
Deﬁnition A.13 (Dual order). Let P = (X,R) be an ordered set then Pd = (X,Rd)
is called the dual of P, where (x,y) ∈Rd iff (y,x) ∈R.
The dual of ≤is denoted ≥.
Let P = (X,≤) be an ordered set and Y a subset of X. Then Y inherits an order
relation from ≤, precisely deﬁned as follows. Given x,y ∈Y, x ≤y inY iff x ≤y in X.
The restriction of the order relation ≤on Y is still noted ≤and the ordered set Q =
(Y,≤) is called the suborder of P induced by Y. The following sorts of suborders of
an order P are especially important for studying P: chains and antichains, and also
ideals and ﬁlters.
Deﬁnition A.14 (Ideal and ﬁlter). Let P = (X,≤) be an ordered set, an ideal (resp.
a ﬁlter) of P is a suborder (Y,≤) of P, such that: ∀x ∈X and y ∈Y if x ≤y then
x ∈Y (resp.∀x ∈X and y ∈Y if y ≤x then x ∈Y).
In some situations, an order relation on X is given by a set U of comparable
elements, i.e., by a directed graph on X. If this set U is hand-built, then some errors
may occur, especially circuits may be constructed. Detecting circuits in a directed
graph is a simple problem that can be efﬁciently solved (cf. e.g., [CLRS01]), and
we suppose that U is without circuit.
The order relation ≤induced by U is equal to U∗the reﬂexo-transitive closure
of U, i.e., t′ ≤t iff (t,t′) ∈U∗, i.e., t′ is a descendant of t, and t is an ascendant of
t′.
At the other end, the minimum information needed to compare two elements of
an ordered set is given by the covering relation of the order.
Deﬁnition A.15 (Covering relation). Let (X,≤) be an ordered set. The covering
relation of ≤is denoted by ≺and is deﬁned by: t ≺t′ iff t < t′, and for all t′′,
t ≤t′′ < t′ implies t = t′′. If t ≺t′, then t′ is called a successor of t and t is called a
predecessor of t′.

A.3 Ordered Sets
405
The covering relation Uh of an order is also called the transitive reduction of
that order. If an order is given by a binary relation U whose transitive closure is
the order, the transitive reduction can be built directly from U without computing
U∗. The transitive reduction of an order on X is the binary relation on X with the
minimal cardinality such that its reﬂexo-transitive closure is that order. One has
t ≤t′ iff there is a path from t to t′ in the transitive reduction of ≤. (X,Uh) is also
called the Hasse graph of (X,U).
Any V ⊆X ×X such that Uh ⊆V ⊆U∗is a representative of the order since its
transitive closure is equal to the order, i.e. U∗, and its transitive reduction is equal
to Uh. Thus, the set of representatives of an order is a lattice (cf. the next section)
for the set inclusion.
In graph theory terminology, the transitive reduction of the strict order corre-
sponding to a chain is an elementary path, and the strict order corresponding to an
antichain is a stable set.
Theorem A.1 (Dilworth’s Theorem). Let P be an ordered set. The maximum car-
dinality of an antichain of P, called the width of P and denoted w(P), is equal to the
minimum number of chains of P whose union is equal to P.
Deﬁnition A.16 (Max and min). Let P = (X,≤) be an ordered set and Y ⊆X. An
element x of Y is a maximal element of Y if there is no y ∈Y such that x < y. Dually,
x ∈Y is a minimal element of Y if there is no y ∈Y such that y < x. The set of
maximal (resp. minimal) elements of P is denoted by max(P)(resp. min(P)).
Deﬁnition A.17 (Greatest and least elements). Let P = (X,≤) be an ordered set. If
x ∈X is such that ∀y ∈X,y ≤x, then x is called the greatest element (or maximum)
of P (the least element (or minimum) is dually deﬁned).
An ordered set does not necessarily have a greatest (resp.least) element, but if it
has a greatest (resp. least) element then it is unique.
Let P1 = (X1,≤1) and P2 = (X2,≤2) be two ordered sets. Then, (X1 × X2,≤),
where (x,y) ≤(x′,y′) iff x ≤1 x′ and y ≤2 y′) is an ordered set denoted by P1 × P2
and is called the cartesian product of the two ordered sets.
Deﬁnition A.18 (Order homomorphism). Let P = (X,≤P) and Q = (Y,≤Q) be
two ordered sets. An order homomorphism from P to Q is a mapping from X to Y
such that ∀x,y ∈X, if x ≤P y, then f(x) ≤Q f(y). Such a mapping is also called a
monotone mapping or an order-preserving mapping.
Note that an order homomorphism is a graph homomorphism, thus the notions con-
cerning graph homomorphism apply to orders, e.g. an order isomorphism is a graph
isomorphism.
A.3.2 Lattices
Deﬁnition A.19 (Upper and lower bound). Let P = (X,≤) be an ordered set and
Y ⊆X. An element u of P is an upper bound of Y if ∀x ∈Y one has x ≤u. If the

406
A Mathematical Background
set of upper bounds of Y has a least element, then it is called the least upper bound
of Y and is denoted lub(Y). One can dually deﬁne the notions of lower bound and
greatest lower bound denoted glb(Y). If X has a lub, it is the maximum of X, and if
X has a glb it is the minimum of X.
Deﬁnition A.20 (Lattice). An ordered set (X,≤) is a lattice if any pair {x,y} of
elements of X has a lub, denoted x∨y and a glb denoted x∧y.
A.4 First Order Logic (FOL)
A.4.1 Syntax
A ﬁrst order language is a set L = {a1,...,ak, f1,..., fm, p1,..., pn} in which: ai are
constant symbols, fi are function symbols and pi are predicate symbols. Any fi has
an arity, arity(fi), which is an integer ≥1, and any pi has an arity, arity(pi), which
is an integer ≥0
Let L be a ﬁrst order language and X a set of variable symbols. The set of terms
over L and X is inductively deﬁned as follows:
1. a constant or a variable is a (elementary) term,
2. if fi is an n-ary function symbol and if t1,...,tn are terms then fi(t1,...,tn) is a
term.
The well formed formulas (of FOL) can now be inductively deﬁned.
Deﬁnition A.21 (FOL wff). The FOL well formed formulas (wff) are deﬁned as
follows:
1. An atom is either pi if pi is a predicate symbol of arity 0 or pi(t1,...,tn) if pi is
a predicate symbol of arity n ≥1 and if t1,...,tn are terms; an atom is a wff,
2. if A and B are wffs then ¬A, (A∨B), (A∧B), (A →B) and more generally (A∗B)
for any propositional binary connector ∗are wffs,
3. if A is a wff and x is a variable, then ∃xA and ∀xA are wffs.
Syntactical notions can be inductively deﬁned from the previous inductive deﬁ-
nition of wffs, e.g. the syntactic tree of a wff, the depth of a wff, set of sub-wffs of
a wff and so on. Here are examples.
The mapping var which associates to a term or to a wff the set of their variables
is deﬁned as follows.
1. Term. Let t be a term. If t is a constant, then var(t) = ∅; if t is a variable, then
var(t) = {t}; if t = f(t1,...,tn), then var(t) = i=n
i=1 var(ti).
2. wff. Let A be a wff.
a. If A is an atom p(t1,...,tn), then var(A) = i=n
i=1 var(ti) (if arity(p) = 0 then
var(p) = ∅),

A.4 First Order Logic (FOL)
407
b. if A = ¬B, then var(A) = var(B),
c. if A = (B ∗C), then var(A) = var(B) ∪var(C) for any binary propositional
connector ∗,
d. if A = ∃xB or A = ∀xB, then var(A) = var(B)∪{x}.
Having deﬁned var, the mapping free-var (resp. bound-var) which associates to
a wff the set of the variables with free occurrences (resp. bound occurrences) can be
deﬁned as follows:
1. If A is an atom p(t1,...,tn), then free-var(A) = var(A) and bound-var(A) = ∅,
2. if A = ¬B, then free-var(A) = free-var(B) and bound-var(A) = bound-var(B),
3. if A = (B∗C), then free-var(A) = free-var(B)∪free-var(C) and bound-var(A)
= bound-var(B)∪bound-var(C) for any binary propositional connector ∗,
4. if A = ∃xB or A = ∀xB, then free-var(A) = free-var(B) \ {x} and bound-
var(A) = bound-var(B)∪{x}
A closed wff is a wff A such that free-var(A) = ∅.
Let A be a non-closed wff with free-var(A) = {x1,...,xk}. The existential clo-
sure of A is the wff ∃x1 ...∃xkA. The universal closure is deﬁned in the same way
by substituting the universal quantiﬁer for the existential quantiﬁer.
Deﬁnition A.22 (Substitution).
A substitution is a set of pairs {(x1,t1),...,(xn,tn)}, where the xi are distinct
variables and the ti are terms such that for all i = 1,...,n, ti ̸= xi.
Let σ = {(x1,t1),...,(xn,tn)} be a substitution, t a term. The term σ(t) is deﬁned
as follows:
1. if t is a constant, then σ(t) = t,
2. if t is a variable, then if there is i ∈{1,...,n} with t = xi, then σ(t) = ti otherwise
σ(t) = t,
3. if t = f(t1,...,tk), then σ(t) = f(σ(t1),...,σ(tk)).
Let A be a wff, the wff σ(A) is deﬁned as follows:
1. if A = p(t1,...,tk), then σ(A) = p(σ(t1),...,σ(tk)),
2. if A = ¬B, then σ(A) = ¬σ(B),
3. if A = (B∗C), then σ(A) = (σ(B)∗σ(C)),
4. if A = ∃xB or A = ∀xB, then if there is i ∈{1,...,n} with x = xi then σ(A) = A
otherwise σ(A) = ∃xσ(B) or σ(A) = ∀xσ(B).
The
substitution product is deﬁned as follows. Let α = {(xi,ui)}i and β =
{(yj,vj)}j be two substitutions, β ◦α is the substitution equal to
{(x,β(α(x))) | x ∈{xi}i ∪{yj}j,x ̸= β(α(x))}.
A uniﬁer of two terms or of two atoms q and q′ is a substitution σ such that
σ(q) = σ(q′). A most general uniﬁer of q and q′, denoted by mgu(q,q′), is a uniﬁer
of q and q′ such that for any uniﬁer σ′ of q and q′ there is a substitution α such that
σ′ = α ×σ.

408
A Mathematical Background
A.4.2 Semantics and Models
Deﬁnition A.23 (Model). Let L be a ﬁrst order language L = (a1,a2,...,ak, f1, f2,
..., fm, p1, p2,..., pn). A model I, also called an interpretation, of L is a relational
structure:
I = (D,I(a1),I(a2),...,I(ak),I(f1),I(f2),...,I(fm),I(p1),I(p2),...,I(pn)), such that:
• D is a non-empty set called the domain of I,
• for all i = 1,...,k, I(ai) is an element of D,
• for all i = 1,...,m, I(fi) is a mapping from Darity( fi) to D,
• for all i = 1,...,n, I(pi) is a arity(pi)-ary relation on D.
Let t be a term on a language L, I a model of L and s an assignation of the
variables of t, i.e., a mapping from var(t) to D the domain of I. The value of t for I
and s, denoted v(t,I,s), is an element of D inductively deﬁned as follows:
1. if t is a constant, then v(t,I,s) = I(t),
2. if t is a variable, then v(t,I,s) = s(t),
3. if t = f(t1,...,tk), then v(t,I,s) = I(f)(v(t1,I,s),...,v(tk,I,s)).
Let A be a wff on a language L, I a model of L and s an assignation of the
variables of A, i.e. a mapping from var(A) to D the domain of I. The value of A for
I and s, denoted v(A,I,s), is inductively deﬁned as follows:
1. let A be an atom p(t1,...,tk), v(A,I,s) = true iff (v(t1,I,s),...,v(tk,I,s)) ∈I(p),
2. v(¬A,I,s) = true iff v(A,I,s) = false,
3. v((A∧B),I,s) = true iff v(A,I,s) = v(B,I,s) = true,
4. v(∃xA,I,s) = true iff for some d ∈D v(A,I,s(x,d)) = true), where s(x,d) is the
assignment s′ s.t. for any y ̸= x s′(y) = s(y) and s′(x) = d.
Values for other propositional connectives or for the universal quantiﬁer are easily
derived from the previous deﬁnition.
A wff A is satisﬁed by a model I and an assignment s if v(A,I,s) = true, which
is also denoted (I,s) |= A.
A wff is satisﬁable if it is satisﬁed by a model and it is unsatisﬁable otherwise.
A wff is valid if it is satisﬁed by any model and assignment.
Two wffs A and B are equivalent if they have the same value for all I and all s,
i.e. (I,s) |= A iff (I,s) |= B.
A wff C is a logical consequence of a set of wffs H1,...,Hk if for all I and s
such that for all i = 1,...,k (I,s) |= Hi, then (I,s) |= C. The fact that C is a logical
consequence of H1,...,Hk is denoted H1,...,Hk |= C.
Theorem A.2. The following three statements are equivalent:
1. H1,...,Hk |= C.
2. (H1 ∧...∧Hk →C) is a valid wff.
3. (H1 ∧...∧Hk ∧¬C) is an unsatisﬁable wff.

A.4 First Order Logic (FOL)
409
A.4.3 Clausal Form
A literal is either an atom (or positive literal) or the negation of an atom (or negative
literal). A clause is the universal closure of a disjunction of literals. A clause can be
identiﬁed to a set of literals.
Any wff is equivalent to a wff in prenex conjunctive form which is composed
of a sequence of quantiﬁers (existential and universal) preceding a conjunction of
disjunctions of literals, i.e.
Q1x1 ...Qkxk(L11 ∨...∨L1n1) ∧...∧(Lu1 ∨...∨Lunu), where any Qi is either ∃or
∀.
The skolemization of a prenex wff A consists of successively, from left to right,
deleting an existential quantiﬁer, say ∃xi, and applying the substitution (xi, f(x1,...,
xr)), where f is a new n-ary function symbol, and x1,...,xr are the universally
quantiﬁed variables preceding xi. The wff obtained is a skolem form of A.
A wff is in clausal form if it is the conjunction of a set of clauses, therefore
skolemization transforms a wff into a clausal form.
Theorem A.3. A wff A is unsatisﬁable iff any skolem form of A is unsatisﬁable.
Example. Let A = ∃x∃y(person(x)∧boy(y)∧father(x,y)) be a wff on a language
L. Skolemization of A gives the wff: skol(A) = person(a) ∧boy(b) ∧father(a,b)
where a,b are two constants which do not belong to L.
Let A = ∀x∃y(¬person(x) ∨mother(y,x)) be a wff on a language L. skol(A) =
∀x(¬person(x)∨mother(f(x),x)) where f is a unary symbol function /∈L.
A.4.4 Resolution and SLD-Resolution
Let C and C′ be two clauses with no variables in common. If p(U1),..., p(Uk)
is a set of literals of C and ¬p(V1),...,¬p(Vl) is a set of literals of C′ (where
Ui and Vj are term vectors of length arity(p)) and σ is a most general uniﬁer of
p(U1),..., p(Uk), p(V1),..., p(Vl), then applying the resolution rule to C,C′ and σ
consists of building the clause:
{σ(C)\{σ(p(U1),...,σ(p(Uk)}}∪{σ(C′)\{σ(¬p(V1),...,σ(p(Vl)}}.
Theorem A.4 (Soundness and completeness of the resolution method). A clausal
form is unsatisﬁable iff the empty clause can be derived from the initial clauses by
a ﬁnite number of applications of the resolution rule.
Different strategies have been proposed to apply the resolution rule. Especially,
whenever all the clauses are Horn clauses, i.e., clauses with at most one literal that
is an atom, and the other are negation of atoms, then the SLD-resolution can be
applied. This method is described using the logic programming language reviewed
hereafter.
A Horn clause C = H ∨¬B1 ...∨¬Bk, where H is the only atom of C is denoted
by a rule H ←B1,...,Bk. H is called the head of the rule, the body of the rule is

410
A Mathematical Background
the sequence of atoms after the left arrow. A Horn clause restricted to an atom A is
called a fact and is denoted A ←. A set of rules and facts is called a logic program. A
goal is a clause C with no atom, i.e. C = ¬G1 ...∨¬Gk and is denoted ←G1,...,Gk.
Let us consider a logic program P and a goal G =←G1,...,Gk. The SLD-
resolution is deﬁned as a sequence of steps transforming the goal using the facts and
rules of P as follows. The ﬁrst goal is G1 = G. Assume that the goal Gi = H1,...,Hl
has been derived. A SLD-resolution step consists of :
• select a subgoal Hi,
• choose a fact H ←or a rule H ←B1,...,Bk of P,
• compute, if any, a most general uniﬁer σ of Hi and H,
• replace Gi by the new goal:
Gi+1 = σ(H1,...,Hi−1,B1,...,Bk,Hi+1,...,Hl) (note that if a fact is considered,
then the subgoal Hi is deleted).
Theorem A.5 (Soundness and completeness of the SLD-resolution for logic pro-
grams). Let P be a logic program and G =←G1,...,Gk a goal. G1 ∧...∧Gk is a
logical consequence of P iff the empty goal can be derived from P and G by the
SLD-resolution method.
A.5 Algorithm and Problem Complexity
Problem decidability gives results about the solvability of a given decision problem
(a problem which can be stated as a question whose answer is YES or NO). For
instance, deduction in FOL is undecidable nevertheless semi-decidable. This means
that there is no algorithm which stops for any input wff with the answer YES if the
wff is valid and with the answer NO if the wff is not valid, but there are algorithms
which stop with the answer YES given any valid wff (and if the input wff is not
valid they may not stop). Knowing that a problem is decidable does not imply that
this problem can be efﬁciently solved.
Complexity theory provides tools to assess the difﬁculty of a problem and the
efﬁciency of an algorithm. Let us present the basic notions through an example (and
cf. [CLRS01] for a thorough introduction to the domain). Let us consider the ho-
momorphism problem, denoted GRAPH-HOMOMORPHISM between (ﬁnite) graphs.
It is presented as follows:
GRAPH-HOMOMORPHISM
Instance: two (ﬁnite) graphs G and H.
Question: Is there a homomorphism from G to H?
The size of a problem is an integer which is a measure of the number of characters
of a reasonable (not unary) encoding of a problem instance. The sum of numbers of
nodes and vertices of the two graphs is a usual size for the previous example.

A.5 Algorithm and Problem Complexity
411
The time complexity of an algorithm (solving a given problem) is expressed as a
function giving the number of (elementary) operations run by the algorithm in terms
of the size of the instance. This function is generally an asymptotic function (when
the instance size increases) in the worst case instance.
The O-notation is classicaly used for expressing this asymptotic worst-case com-
plexity. Let f be a function of a positive integer parameter n. Saying that an algo-
rithm A for solving a problem P has a time (resp. size) complexity in O(f(n)) means
this: there is a positive constant C and there is a positive integer n0 such that the
number of elementary operations (resp. memory size) of A needed for solving any
instance (of P) whose size is ≥n0 is ≤C f(n).
A problem is in the complexity class P if there is a deterministic algorithm, for
solving this problem, which has a polynomial time complexity. A problem is in the
complexity class NP if there is a non-deterministic algorithm, for solving this prob-
lem, which has polynomial time complexity. P̸=NP is one of the most important
conjectures in Computer Science. The most difﬁcult problems in the NP class are
called NP-complete. If we can show that a problem is NP-complete, then we know
that it is very unlikely that we can solve all instances of this problem in reasonable
time.
It is well-known that typical AI problems are computationally difﬁcult. Hence,
it might seem worthless to analyze the computational complexity of these prob-
lems. Nevertheless, complexity analysis provides insight into the possible sources
of complexity and can be used to direct the search for efﬁcient methods to solve the
problem (e.g., good heuristics or polynomial algorithms for particular cases).

References
[AB94]
K. R. Apt and R. N. Bol. Logic programming and negation: A survey. Journal of
Logic Programming, 19/20:9–71, 1994.
[ABC06]
J.-P. Aubert, J.-F. Baget, and M. Chein. Simple Conceptual Graphs and Simple Con-
cept Graphs. In H. Sch¨arfe et al, editor, Proc. ICCS’06, volume 4068 of LNAI, pages
87–101. Springer, 2006.
[ACP87]
S. Arnborg, D.G. Corneil, and Proskurowski. Complexity of ﬁnding embeddings in a
k-tree. SIAM Journal of Algebraic and Discrete Methods, 8:277–284, 1987.
[AHV95]
S. Abiteboul, R. Hull, and V. Vianu. Foundations of Databases. Addison-Wesley,
1995.
[Ann01]
Annotea. Annotea Project. http://www.w3.org/2001/Annotea/, 2001.
[AvBN96]
H. Andr´eka, J. van Benthem, and I. N´emeti. Modal languages and bounded fragments
of FOL. Research Report ML-96-03, Univ. of Amsterdam, 1996.
[BA01]
M. Ben-Ari. Mathematical Logic for Computer Science. Springer, 2001.
[Baa99]
F. Baader. Logic-based knowledge representation. In M.J. Wooldridge and M. Veloso,
editors, Artiﬁcial Intelligence Today, Recent Trends and Developments, number 1600
in Lecture Notes in Computer Science, pages 13–41. Springer Verlag, 1999.
[Bag99]
J.-F. Baget. A Simulation of Co-Identity with Rules in Simple and Nested Graphs. In
Proc. of ICCS’99, volume 1640 of LNAI, pages 442–455. Springer, 1999.
[Bag01]
J.-F. Baget. Repr´esenter des connaissances et raisonner avec des hypergraphes: de
la projection `a la d´erivation sous contraintes. PhD thesis, Universit´e Montpellier II,
Nov. 2001.
[Bag03]
J.-F. Baget.
Simple Conceptual Graphs Revisited: Hypergraphs and Conjunctive
Types for Efﬁcient Projection Algorithms. In Proc. of ICCS’03, volume 2746 of
LNAI. Springer, 2003.
[Bag04]
J.-F. Baget. Improving the forward chaining algorithm for conceptual graphs rules.
In KR’04, pages 407–414. AAAI Press, 2004.
[Bag05]
J. F. Baget. RDF Entailment as a Graph Homomorphism. In Proc. of ISWC’05, 2005.
[BBV97]
C. Bos, B. Botella, and P. Vanheeghe. Modeling and Simulating Human Behaviors
with Conceptual Graphs. In Proc. of ICCS’97, volume 1257 of LNAI, pages 275–289.
Springer, 1997.
[BC81]
P. A. Bernstein and D.-M. W. Chiu. Using semi-joins to solve relational queries. J.
ACM, 28(1):25–40, 1981.
[BCM+03] F. Baader, D. Calvanese, D. L. McGuinness, D. Nardi, and P. F. Patel-Schneider, ed-
itors. The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press, 2003.
[BCvBW02] F. Bacchus, X. Chen, P. van Beek, and T. Walsh. Binary vs. non-binary constraints.
Artif. Intell., 140(1/2):1–37, 2002.
413

414
References
[BFMY83] C. Beeri, R. Fagin, D. Maier, and M. Yannakakis.
On the desirability of acyclic
database schemes. J. ACM, 30(3):479–513, 1983.
[BFR95]
C. Bessi`ere, E. C. Freuder, and J.-C. R´egin. Using inference to reduce arc consistency
computation. In Proc. IJCAI’95, pages 592–599, 1995.
[BG81]
P. A. Bernstein and N. Goodman. Power of natural semijoins. SIAM J. Comput.,
10(4):751–771, 1981.
[BGM99a]
J.-F. Baget, D. Genest, and M.-L. Mugnier. Knowledge acquisition with a pure graph-
based knowledge representation model—application to the Sisyphus-1 case study. In
Twelfth Workshop on Knowledge Acquisition, Modeling and Management (KAW ’99),
1999.
[BGM99b]
J.-F. Baget, D. Genest, and M.-L. Mugnier. A pure graph-based solution to the SCG-1
initiative. In Proc. ICCS’99, volume 1640 of LNAI, pages 355–376, 1999.
[BHP+92]
C. Beierle, U. Hedtst¨uck, U. Pletat, P. H. Schmitt, and J. H. Siekmann. An order-
sorted logic for knowledge representation systems.
Artif. Intell., 55(2):149–191,
1992.
[Bid91]
N. Bidoit. Negation in rule-based database languages: a survey. Theoretical Computer
Science, 78(1):3–83, 1991.
[BK99]
F. Baader and R. K¨usters. Matching in description logics with existential restrictions.
In Proc. of DL’99, volume 22 of CEUR Workshop Proceedings. CEUR-WS.org, 1999.
[BKM99]
F. Baader, R. K¨usters, and R. Molitor. Computing least common subsumers in de-
scription logics with existential restrictions. In Proc. of IJCAI’99, pages 96–103.
Morgan Kaufmann, 1999.
[BL01]
T.
Berners-Lee.
Conceptual
Graphs
and
the
Semantic
Web.
http://www.w3.org/DesignIssues/CG.html, 2001.
[BL04]
R.J. Brachman and H.J. Levesque. Knowledge, Representation and Reasoning. Else-
vier, 2004.
[BM02]
J.-F. Baget and M.-L. Mugnier. The Complexity of Rules and Constraints. J. of Artif.
Intell. Research (JAIR), 16:425–465, 2002.
[BMFL02]
C. Bessi`ere, P. Meseguer, E. C. Freuder, and J. Larrosa. On forward checking for
non-binary constraint satisfaction. Artif. Intell., 141(1/2):205–224, 2002.
[BMS98]
F. Baader, R. Molitor, and S.Tobies. The guarded fragment of conceptual graphs.
Research Report 98-10, LTCS, 1998.
[BMT99]
F. Baader, R. Molitor, and S. Tobies. Tractable and Decidable Fragments of Concep-
tual Graphs. In Proc. of ICCS’99, volume 1640 of LNAI, pages 480–493. Springer,
1999.
[Bod]
H. L. Bodlaender.
TreewidthLIB: A benchmark for algorithms for treewidth and
related graph problems. http://people.cs.uu.nl/hansb/treewidthlib/index.php.
[Bod93]
H.L. Bodlaender. A tourist guide through treewidth. Acta Cybernetica, 11(1–2):1–21,
1993.
[Bod96]
H.L. Bodlaender. A linear-time algorithm for ﬁnding tree-decompositions of small
treewidth. SIAM Journal of Computing, 25:1305–1317, 1996.
[Bod98]
H. L. Bodlaender. A partial arboretum of graphs with bounded treewidth. Theoretical
Compututer Science, 209(1-2):1–45, 1998.
[Bor96]
A. Borgida. On the relative expressiveness of description logics and predicate logics.
Artif. Intell., 82:353–367, 1996.
[Bou71]
A. Bouchet. Etude combinatoire des ordonn´es ﬁnis. Th`ese de doctorat d’Etat, Uni-
versit´e de Grenoble, 1971.
[BP83]
J. Barwise and J. Perry. Situations and Attitudes. MIT Press, Cambridge, MA, 1983.
[Bra77]
R. Brachman. What’s in a concept: Structural foundations for semantic networks.
International Journal Of Man Machine Studies, 9:127–152, 1977.
[BS85]
R.J. Brachman and J.G. Schmolze. An overview of the kl-one knowledge representa-
tion system. Cognitive Science, 9(2):171–216, 1985.
[BS06]
J.-F. Baget and E. Salvat. Rules dependencies in backward chaining of conceptual
graphs rules. In H. Sch¨arfe et al, editor, Proc. ICCS’06, volume 4068 of LNAI, pages
102–116. Springer, 2006.

References
415
[BT01]
J.-F. Baget and Y. Tognetti. Backtracking through biconnected components of a con-
straint graph. In Proc. IJCAI’01, volume 1, pages 291–296, 2001.
[BV84]
C. Beeri and M.Y. Vardi. A proof procedure for data dependencies. Journal of the
ACM, 31(4):718–741, 1984.
[CC06]
M. Croitoru and E. Compatangelo. A tree decomposition algorithm for conceptual
graph projection. In Proc. of KR’06, pages 271–276. AAAI Press, 2006.
[CCW97]
T. H. Cao, P. N. Creasy, and V. Wuwongse. Fuzzy uniﬁcation and resolution proof
procedure for fuzzy conceptual graph programs. In D. Lukose et al, editor, Proc.
ICCS’97, volume 1257 of LNAI, pages 386–400. Springer, 1997.
[CDH00]
O. Corby, R. Dieng, and C. Hebert. A Conceptual Graph Model for W3C RDF. In
Proceedings of ICCS00, volume 1867 of LNAI, pages 468–482. Springer, 2000.
[CF98]
P. Coupey and C. Faron. Towards correspondence between conceptual graphs and
description logics. In ICCS, volume 1453 of LNCS, pages 165–178. Springer, 1998.
[CG95]
O. Cogis and O. Guinaldo. A linear descriptor for conceptual graphs and a class
for polynomial isomorphism test. In Proc. of ICCS’95, volume 954 of LNAI, pages
263–277. Springer, 1995.
[CGL+05]
D. Calvanese, G. De Giacomo, D. Lembo, M. Lenzerini, and R. Rosati. DL-Lite:
Tractable description logics for ontologies. In AAAI, pages 602–607, 2005.
[CGL+07]
D. Calvanese, G. De Giacomo, D. Lembo, M. Lenzerini, and R. Rosati. Tractable
reasoning and efﬁcient query answering in description logics: The DL-Lite family. J.
Autom. Reasoning, 39(3):385–429, 2007.
[CH93]
B. Carbonneill and O. Haemmerl´e.
Implementing a CG Platform for Ques-
tion/Answer and Database capabilities.
In Proc. 2nd International Workshop on
Peirce, pages 29–32, 1993.
[CH94]
B. Carbonneill and O. Haemmerl´e. Rock: Un syst`eme question/r´eponse fond´e sur le
formalisme des graphes conceptuels. In Actes du 9-i`eme congres RFIA, pages 159–
169, 1994.
[CLRS01]
T. A. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms.
The MIT Press, Cambridge, Ma, USA, 2001.
[CLS07]
Information technology—common logic (cl): a framework for a family of logic-based
languages. ISO/IEC 24707:2007, 2007.
[CM92]
M. Chein and M.-L. Mugnier. Conceptual Graphs: Fundamental Notions. Revue
d’Intelligence Artiﬁcielle, 6(4):365–406, 1992.
[CM95]
M. Chein and M.-L. Mugnier. Conceptual Graphs are also Graphs. Research Report
RR-LIRMM 95-003, LIRMM, 1995. Available at http://www.lirmm.fr/˜mugnier/.
[CM97]
M. Chein and M.-L. Mugnier. Positive Nested Conceptual Graphs. In D. Lukose et al,
editor, Proc. ICCS’97, volume 1257 of LNAI, pages 95–109. Springer, 1997.
[CM04]
M. Chein and M.-L. Mugnier. Concept types and coreference in simple conceptual
graphs. In K. E. Wolff et al, editor, Proc. ICCS’04, volume 3127 of LNAI, pages
303–318. Springer, 2004.
[CMS98]
M. Chein, M.-L. Mugnier, and G. Simonet.
Nested Graphs: A Graph-
based Knowledge Representation Model with FOL Semantics.
In Proc. of
KR’98, pages 524–534. Morgan Kaufmann, 1998.
Revised version available at
http://www.lirmm.fr/˜mugnier/.
[cog01a]
CoGITaNT, 2001. http://cogitant.sourceforge.net/.
[cog01b]
COGUI, 2001. http://www.lirmm.fr/cogui/.
[CR97]
Ch. Chekuri and A. Rajaraman. Conjunctive Query Containment Revisited. In Proc.
ICDT’97, LNCS, vol. 1186, pages 56–70. Springer, 1997.
[CS98]
S. Coulondre and E. Salvat. Piece Resolution: Towards Larger Perspectives. In Proc.
of ICCS’98, volume 1453 of LNAI, pages 179–193. Springer, 1998.
[CW87]
D. Coppersmith and S. Winograd. Matrix multiplication via arithmetic progression.
In Proceedings of 19-th Ann. Symp. on the Theory of Computation, pages 1–6, 1987.
[Dau02]
F. Dau. The Logic System of Concept Graphs with Negation And Its Relationship to
Predicate Logic. PhD thesis, Tech. Univer. Darmstadt, 2002.

416
References
[Dau03a]
F. Dau. Concept graphs without negations: Standardmodels and standardgraphs. In
Proc. ICCS’03, volume 2746 of LNAI. Springer, 2003.
[Dau03b]
F. Dau. The Logic System of Concept Graphs with Negation And Its Relationship to
Predicate Logic, volume 2892 of LNCS. Springer, 2003.
[Dec03]
R. Dechter. Constraint Processing. Morgan Kaufmann Publishers Inc., San Fran-
cisco, CA, USA, 2003.
[DHL98]
J. Dibie, O. Haemmerl´e, and S. Loiseau.
A Semantic Validation of Conceptual
Graphs. In Proc. of ICCS’98, volume 1453 of LNAI, pages 80–93. Springer, 1998.
[Dic94]
J.P. Dick. Using Contexts to Represent Text. In Proc. ICCS’94, volume 835 of LNAI,
pages 196–213, 1994.
[DP02]
B.A. Davey and H.A. Priestley.
Introduction to Lattices and Order.
Cambridge
University Press, Cambridge, UK, 2002.
[ELR94]
G. Ellis, R. Levinson, and P. J. Robinson. Managing Complex Objects in Peirce. Int.
J. Hum.-Comput. Stud., 41(1-2):109–148, 1994.
[FFG01]
J. Flum, M. Frick, and M. Grohe. Query evaluation via tree decomposition. ICDT’01,
1973:22–38, 2001.
[FFG02]
J. Flum, M. Frick, and M. Grohe. Query evaluation via tree-decompositions. J. ACM,
49(6):716–752, 2002.
[Fit69]
M. C. Fitting. Intuitionistic Logic, Model Theory and Forcing. North Holland, Ams-
terdam, 1969.
[FLDC86]
J. Fargues, M.-C. Landau, A. Dugourd, and L. Catach. Conceptual graphs for se-
mantic and information processing.
IBM Journal of Research and Development,
30(1):70–79, 1986.
[FLS96]
H. Fargier, J. Lang, and T. Schiex. Mixed constraint satisfaction: a framework for
decision problems under incomplete knowledge. In Proc. of AAAI’96, pages 175–
180, 1996.
[FNTU07]
C. Farr´e, W. Nutt, E. Teniente, and T. Urp´ı. Containment of conjunctive queries over
databases with null values. In ICDT 2007, volume 4353 of LNCS, pages 389–403.
Springer, 2007.
[Fuh00]
N. Fuhr. Models in information retrieval. In G. Pasi M. Agosti, F. Crestani, edi-
tor, Lecture on Information Retrieval, volume 1980 of Lecture Notes in Computer
Science, pages 21–50. Springer, 2000.
[FV93]
T. Feder and M.Y. Vardi. Monotone Monadic SNP and Constraint Satisfaction. In
Proc. the 25th ACM STOC, pages 612–622, 1993.
[Gal85]
J.H. Gallier. Logic for Computer Science. Wiley, 1985.
[GC97]
D. Genest and M. Chein.
An experiment in document retrieval using conceptual
graphs. In D. Lukose et al, editor, Proc. ICCS’97, volume 1257 of LNAI, pages 489–
504. Springer, 1997.
[GC05]
D. Genest and M. Chein. A content-search information retrieval process based on
conceptual graphs. Knowledge and Information Systems (KAIS), 8:292–309, 2005.
[Gen00]
D. Genest.
Extension du mod`ele des graphes conceptuels pour la recherche
d’informations. PhD thesis, Universit´e Montpellier II, Dec. 2000.
[GHP95]
P. Galinier, M. Habib, and C. Paul. Chordal graphs and their clique graphs. In Proc.
Workshop on Graph-Theoretic Concepts in Computer Science, pages 358–371, 1995.
[GJ79]
M. R. Garey and D. S. Johnson. Computers and Intractability: a Guide to the Theory
of NP-Completeness. W.H. Freeman, 1979.
[GLS99]
G. Gottlob, N. Leone, and F. Scarcello.
Hypertree decompositions and tractable
queries. In Proc. PODS’99, pages 21–32, 1999.
[GLS01]
G. Gottlob, N. Leone, and F. Scarcello.
Robbers, marshals and guards: Game-
theoretic and logical characterizations of hypertree width. PODS’01, 2001.
[Gr¨a99]
E. Gr¨adel.
On the restraining power of guards.
Journal of Symbolic Logic,
64(4):1719–1742, 1999.
[Guh91]
R.V. Guha. Contexts: a formalization and some applications. PhD Thesis, Stanford
University, 1991.

References
417
[GW95]
B. C. Ghosh and V. Wuwongse.
A Direct Proof Procedure for Deﬁnite Concep-
tual Graphs Programs. In Proc. of ICCS’95, volume 954 of LNAI, pages 158–172.
Springer, 1995.
[GW99]
B. Ganter and R. Wille. Formal Concept Analysis. Springer-Verlag, 1999.
[Hay04]
P. Hayes. Rdf semantics. w3c recommendation. http://www.w3.org/TR/2004/REC-
rdf-mt-20040210/, 2004.
[HE80]
R. M. Haralick and G. L. Elliott.
Increasing tree search efﬁciency for constraint
satisfaction problems. Artif. Intell., 14(3):263–313, 1980.
[HHN95]
M. Habib, M. Huchard, and L. Nourine. Embedding partially ordered sets into chain-
products. In Proc. of the International KRUSE Symposium (KRUSE’95, pages 147–
161. University of Santa-Cruz, 1995.
[HM01]
G. Hahn and G. MacGillivray. Graph homomorphisms: Computational aspects and
inﬁnite graphs. Draft, 2001.
[HMR93]
M. Habib, M. Morvan, and X. Rampon. On the calculation of transitive reduction-
closure of orders. Discrete mathematics, 111:289–303, 1993.
[HN90]
P. Hell and J. Neˇsetˇril. On the complexity of H-coloring. J. Combin. Th., (B)(48):33–
42, 1990.
[HN04]
P. Hell and J. Nesetril. Graphs and Homomorphisms, volume 121. Oxford University
Press, 2004.
[HNR97]
M. Habib, L. Nourine, and O. Raynaud. A new lattice-based heuristic for taxonomy
encoding. In Proc. of the International KRUSE Symposium (KRUSE’97), pages 60–
71. University of Vancouver, 1997.
[HNZ94]
P. Hell, J. Neˇsetˇril, and X. Zhu. Duality and Polynomial Testing of Tree Homomor-
phisms. Manuscript, 1994.
[HS03a]
S. Handschuh and S. Staab, editors. Annotation for the Semantic Web, volume 96
of Frontiers in Artiﬁcial Intelligence and Applications. IOS Press, Amsterdam, The
Netherlands, 2003.
[HS03b]
S. Handschuh and S. Staab. Cream—creating metadata for the semantic web. Com-
puter Networks, 42(1):579–598, 2003.
[HT97]
G. Hahn and C. Tardif. Graph homomorphism: structure and symmetry. In G. Hahn
and G.Sabidussi, editors, Graph Symmetry, pages 107–166. Kluwer, 1997.
[Jac88]
M. K. Jackman.
Inference and the Conceptual Graph Knowledge Representation
Language. In Research and Development in Expert Systems IV, 1988.
[Jea98]
P. G. Jeavons. On the algebraic structure of combinatorial problems. Theoretical
Computer Science (TCS), 200:185–204, 1998.
[JN98]
F. Lepage J.Y. Nie. Toward a broader logical model for information retrieval, 1998.
[KBvH01]
A.M.C.A. Koster, H.L. Bodlaender, and S.P.M. van Hoesel. Treewidth: Computa-
tional experiments. Draft, 2001.
[Ker01]
G. Kerdiles. Saying it with Pictures: a logical landscape of conceptual graphs. PhD
thesis, Univ. Amsterdam, Nov. 2001.
[Kli05]
Julia Klinger. Local negation in concept graphs. In Proc. ICCS’05, volume 3596 of
LNAI, pages 209–222, 2005.
[KV98]
P. G. Kolaitis and M. Y. Vardi. Conjunctive-Query Containment and Constraint Sat-
isfaction. In Proc.PODS’98, pages 205–213, 1998.
[KV00]
P. G. Kolaitis and M. Y. Vardi. Conjunctive-Query Containment and Constraint Sat-
isfaction. Journal of Computer and System Sciences, 61:302–332, 2000.
[LB94]
M. Liqui`ere and O. Brissac. A class of conceptual graphs with polynomial isoprojec-
tion. In Suppl. Proc. ICCS’94, 1994. Revised version.
[LE92]
R. Levinson and G. Ellis.
Multilevel hierarchical retrieval.
Knowl.-Based Syst.,
5(3):233–244, 1992.
[Lec95]
M. Lecl`ere. Les connaissances du niveau terminologique du modele des graphes
conceptuels: construction et exploitation. PhD thesis, Universit´e Montpellier II, Dec.
1995.
[Lec97]
M. Lecl`ere. Reasoning with type deﬁnitions. In Proc. ICCS’97, volume 1257 of
LNAI, pages 401–415. Springer, 1997.

418
References
[Lec98]
M. Lecl`ere.
Raisonner avec des d´eﬁnitions de types dans le mod`ele des graphes
conceptuels. Revue d’Intelligence Artiﬁcielle, 12:243–278, 1998.
[Leh92]
F. Lehman. Semantics Networks in Artiﬁcial Intelligence. Pergamon Press, 1992.
[LM06]
M. Lecl`ere and M.-L. Mugnier. Simple conceptual graphs with atomic negation and
difference. In H. Sch¨arfe et al, editor, Proc. ICCS’06, volume 4068 of LNAI, pages
331–345, 2006.
[LM07]
M. Lecl`ere and M.-L. Mugnier. Some algorithmic improvements for the containment
problem of conjunctive queries with negation. In Proc. ICDT’07, volume 4353 of
LNCS, pages 404–418. Springer, 2007.
[LR96]
A. Y. Levy and M.-C. Rousset. Veriﬁcation of Knowledge Bases Based on Contain-
ment Checking. In Proc. of AAAI’96, pages 585–591, 1996.
[LR98]
A. Y. Levy and M.-C. Rousset. Veriﬁcation of Knowledge Bases Based on Contain-
ment Checking. Artiﬁcial Intelligence, 101(1-2):227–250, 1998.
[LS98]
M. Liqui`ere and J. Sallantin.
Structural machine learning with galois lattice and
graphs. In Proc. ICML’98, pages 305–313, 1998.
[Mac77]
A. K. Mackworth. Consistency in networks of relations. Artif. Intell., 8(1):99–118,
1977.
[Mai83]
D. Maier. The Theory of Relational Databases. Computer Science Press, 1983.
[Mar97]
P. Martin. CGKAT: a knowledge acquisition tool and an information retrieval tool
which exploits structured documents, conceptual graphs and ontologies. In Proc.
CGTOOLS’97. Univ. of Washington, 1997.
[MC92]
M.L. Mugnier and M. Chein. Polynomial algorithms for projection and matching. In
H. D. Pfeiffer and T. E. Nagle, editors, Proc. the 7th Workshop on Conceptual Graphs,
volume 754 of LNAI, pages 49–58, New Mexico State University, Las Cruces, New
Mexico, 1992. Springer.
[MC93]
M.L. Mugnier and M. Chein.
Characterization and Algorithmic Recognition of
Canonical Conceptual Graphs. In Proc. ICCS’93, volume 699 of LNAI, pages 294–
311. Springer Verlag, 1993.
[MC96]
M.-L. Mugnier and M. Chein. Repr´esenter des connaissances et raisonner avec des
graphes. Revue d’Intelligence Artiﬁcielle, 10(1):7–56, 1996.
[McC93]
J. McCarthy. Notes on Formalizing Contexts. In Proc. IJCAI’93, pages 555–560,
1993.
[ME99]
P. Martin and P. Eklund. Embedding Knowledge in Web Documents. In Proc. of the
8th Int. World Wide Web Conference (WWW8), pages 1403–1419, 1999.
[Min75]
M. Minsky. A framework for representing knowledge. In P. Winston, editor, The
Psychology of Computer Vision. McGraw-Hill, New York, 1975.
[ML07]
M.-L. Mugnier and M. Lecl`ere. On querying simple conceptual graphs with negation.
Data Knowl. Eng., 60(3):468–493, 2007.
[MLCG07] N. Moreau, M. Lecl`ere, M. Chein, and A. Gutierrez. Formal and Graphical Annota-
tions for Digital Objects. In Proc. of International Workshop on Semantically Aware
Document Processing and Indexing (SADPI’07), volume 259 of ACM Digital Library,
ACM International Conference Proceeding Series, pages 69–78. ACM, 2007.
[MM97]
G. W. Mineau and R. Missaoui. The Representation of Semantic Constraints in Con-
ceptual Graphs Systems. In Proc. of ICCS’97, volume 1257 of LNAI, pages 138–152.
Springer, 1997.
[Moh89]
R.H. Mohring. Computationally tractable classes of ordered sets. Algorithms and
Orders, 255:105–193, 1989.
[Mug92]
M.L. Mugnier.
Contributions algorithmiques pour les graphes d’h´eritage et les
graphes conceptuels. PhD thesis, Univ. Montpellier II, Oct. 1992.
[Mug95]
M.-L. Mugnier. On Generalization / Specialization for Conceptual Graphs. Journal
of Experimental and Theoretical Artiﬁcial Intelligence, 7:325–344, 1995.
[Mug00]
M.-L. Mugnier. Knowledge Representation and Reasoning based on Graph Homo-
morphism. In Proc. ICCS’00, volume 1867 of LNAI, pages 172–192. Springer, 2000.
[Mug07]
M.-L. Mugnier. On the π2
p-completeness of the containment problem of conjunctive
queries with negation and other problems. Research Report 07004, LIRMM, 2007.

References
419
[Naz93]
A. Nazarenko. Representing Natural Language Causality in Conceptual Graphs . In
Proc. ICCS’93, volume 699 of LNAI, pages 205–222, 1993.
[Pap94]
C. H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.
[Pau98]
C. Paul. Parcours en largeur lexicographique : un algorithme de partitionnement.
PhD thesis, Universit´e Montpellier II, 1998.
[PMC98]
A. Preller, M.-L. Mugnier, and M. Chein. Logic for nested graphs. Computational
Intelligence: An International Journal, 14-3:335–357, 1998.
[Pos47]
E. L. Post. Recursive unsolvability of a problem of Thue. Journal of Symbolic Logic,
12(1):1–11, 1947. Reprinted in: M. Davis (Ed.), The Collected Works of Emil L.
Post, Birkhauser, Boston 1994, pp. 503-513.
[Pre98a]
S. Prediger. Kontextuelle Urteilslogik mit Begriffsgraphen. Ein Beitrag zur Restruk-
turierung der Mathematischen Logik. PhD thesis, Technische Universitat Darmstadt,
1998.
[Pre98b]
S. Prediger.
Simple concept graphs: A logic approach.
In M.-L. Mugnier and
M. Chein, editors, Proc. ICCS’98, volume 1453 of LNAI, pages 225–239. Springer,
1998.
[Pre00]
S. Prediger.
Nested concept graphs and triadic power context families.
In Proc.
ICCS’00, volume 1867 of LNAI, pages 249–262, 2000.
[QV07]
V. Quint and I. Vatton. Structured Templates for Authoring Semantically Rich Doc-
uments. In Proc. of International Workshop on Semantically Aware Document Pro-
cessing and Indexing (SADPI’07), volume 259 of ACM Digital Library, ACM Inter-
national Conference Proceeding Series, pages 41–48. ACM, 2007.
[RM00]
O. Roussel and P. Mathieu. The achievement of knowledge bases by cycle search.
Information and Computation(IC), 162:43–58, 2000.
[RN03]
S. J. Russell and P. Norvig. Artiﬁcial Intelligence, A Modern Approach. Prentice
Hall, 2003.
[Rob92]
D.D. Roberts. The Existential Graphs. In F. Lehman, editor, Semantics Networks in
Artiﬁcial Intelligence, pages 639–663. Pergamon Press, 1992.
[Rob03]
D.D. Roberts. The Existential Graphs of Charles S. Peirce. Mouton, La Hague, 2003.
[Roz97]
G. Rozenberg, editor.
Handbook of Graph Grammars and Computing by Graph
Transformations, Volume 1: Foundations. World Scientiﬁc, 1997.
[RS86]
N. Robertson and P. D. Seymour. Graph minors ii. algorithmic aspects of tree-width.
Journal of Algorithms, 7:309–322, 1986.
[RS04]
N. Robertson and P. D. Seymour. Graph minors. xx. wagner’s conjecture. J. Comb.
Theory, Ser. B, 92(2):325–357, 2004.
[RvW06]
F. Rossi, P. van Beek, and T. Walsh, editors. Handbook of Constraint Programming.
Foundations of Artiﬁcial Intelligence. Elsevier Science Publishers, Amsterdam, The
Netherlands, 2006.
[Sal98]
E. Salvat. Theorem proving using graph operations in the conceptual graphs formal-
ism. In Proc. of ECAI’98, pages 356–360, 1998.
[Sar95]
Y. P. Saraiya. On the efﬁciency of transforming database logic programs. J. Comput.
Syst. Sci., 51(1):87–109, 1995.
[SCM98]
G. Simonet, M. Chein, and M.-L. Mugnier. Projection in Conceptual Graphs and
Query Containment in nr-Datalog. R.R. LIRMM, 1998.
[Sim98]
G. Simonet. Two FOL Semantics for Simple and Nested Conceptual Graphs. In Proc.
of ICCS’98, volume 1453 of LNAI, pages 240–254. Springer, 1998.
[SM96]
E. Salvat and M.-L. Mugnier. Sound and Complete Forward and Backward Chainings
of Graph Rules. In Proc. of ICCS’96, volume 1115 of LNAI, pages 248–262. Springer,
1996.
[Sme00]
A. F. Smeaton. Indexing, browsing and searching of digital video and digital audio
information. In G. Pasi M. Agosti, F. Crestani, editor, Lecture on Information Re-
trieval, volume 1980 of Lecture Notes in Computer Science, pages 93–110. Springer,
2000.
[Sow76]
J. F. Sowa.
Conceptual Graphs.
IBM Journal of Research and Development,
20(4):336–357, 1976.

420
References
[Sow84]
J. F. Sowa. Conceptual Structures: Information Processing in Mind and Machine.
Addison-Wesley, 1984.
[Sow92]
J. Sowa. Conceptual graphs as a universal knowledge representation. In F. Lehmann,
editor, Semantic Networks, pages 75–94. Pergamon Press, 1992.
[Sow99]
J. F. Sowa. Knowledge Representation: Logical, Philosophical and Computational
Foundations. Brooks/Cole, 1999.
[SPT83]
L.K. Schubert, M.A. Papalaskaris, and J. Taugher. Determining type, part, color and
time relationships. Computer, 16:53–60, 1983.
[Sto77]
L. J. Stockmeyer. The polynomial-time hierarchy. Theoretical Computer Science,
3:1–22, 1977.
[SU02]
M. Schaefer and C. Umans. Completeness in the polynomial-time hierarchy: A com-
pendium. Sigact News. Available on M. Schaefer’s homepage, 2002.
[SW86]
J. Sowa and E. C. Way. Inplementing a semantic interpreter using conceptual graphs.
IBM Journal of Research and Development, 30(1):57–69, 1986.
[SY80]
Y. Sagiv and M. Yannakakis. Equivalences among relational expressions with the
union and difference operators. J. ACM, 27(4):633–655, 1980.
[Tar72]
R.E. Tarjan. Depth-ﬁrst search and linear graph algorithms. SIAM Journal of Com-
puting, 1(2):146–160, 1972.
[TBH03a]
R. Thomopoulos, P. Buche, and O. Haemmerl´e. Different kinds of comparisons be-
tween fuzzy conceptual graphs.
In Proc. ICCS’03, volume 2746 of LNAI, pages
54–68, 2003.
[TBH03b]
R. Thomopoulos, P. Buche, and O. Haemmerl´e. Representation of weakly structured
imprecise data for fuzzy querying. Fuzzy Sets and Systems, 140(1):111–128, 2003.
[tH04]
H.J. ter Horst. Extending the RDFS Entailment Lemma. In Proc. of the Third In-
ternational Semantic Web Conference (ISWC’04), volume 3298 of LNCS, page 7791.
Springer, 2004.
[Thi01]
E. Thierry.
Sur quelques interactions entre structures de donn´ees et algorithmes
efﬁcaces. PhD thesis, Universit´e Montpellier II, Oct. 2001.
[Tho07]
M. Thomazo.
Complexit´e et propri´et´es algorithmiques de la d´eduction dans les
graphes polaris´es. First year research report, ENS Cachan, 2007.
[Thu14]
A. Thue. Probleme ¨uber Ver¨anderungen von Zeichenreihen nach gegebenen Regeln.
Skr. Viedensk. Selsk. I, 10, 1914.
[TML06]
R. Thomopoulos, M.-L. Mugnier, and M. Lecl`ere. Mapping contexts to vocabular-
ies to represent intentions. In Proceedings of ECAI2006 Workshop on Contexts and
Ontologies: Theory, Practice and Applications, pages 44–46, 2006.
[TV97]
M. Talamo and P. Vocca. A data structure for lattice representation. Theoretical
Computer Science, 175:373–392, 1997.
[TY84]
R.E. Tarjan and M. Yannakakis. Simple linear-time algorithms to test chordality of
graphs, test acyclicity of hypergraphs, and selectively reduce acyclic hypergraphs.
SIAM Journal of Computing, 13(3):566–579, 1984.
[Var84]
M.Y. Vardi. The implication and ﬁnite implication problems for typed template de-
pendencies. Journal of Computer and System Science, 28(1):3–28, 1984.
[vB97]
J. van Benthem. Dynamic bits and pieces. ILLC Research Report LP-1997-01, Univ.
of Amsterdam, 1997.
[vR79]
C.J. van Rijsbergen. Information retrieval. Butterworths, 1979.
[vR86]
C. J. van Rijsbergen. A non-classical logic for information retrieval. The Computer
Journal, 29(6):481–485, 1986.
[Wal93]
R. J. Wallace. Why ac-3 is almost always better than ac4 for establishing arc consis-
tency in csps. In Proc. IJCAI’93, pages 239–247, 1993.
[Wer95a]
M. Wermelinger. Conceptual Graphs and First-Order Logic. In Proc. of ICCS’95,
volume 954 of LNAI, pages 323–337, 1995.
[Wer95b]
M. Wermelinger. Teorica b´asica das estruturas conceptuais. Master’s thesis, Univer-
sidade Nova de Lisboa, 1995.
[Wes96]
D.B. West, editor. Introduction to Graph Theory. Prentice Hall, 1996.

References
421
[Wil95]
M. Willems. Projection and uniﬁcation for conceptual graphs. In Proc. of ICCS’95,
volume 954 of LNCS, pages 278–292. Springer, 1995.
[Wil97]
R. Wille. Conceptual graphs and formal context analysis. In D. Lukose et al, editor,
Proc. ICCS’97, volume 1257 of LNAI, pages 290–303. Springer, 1997.
[WL94]
M. Wermelinger and J. G. Lopes. Basic conceptual structures theory. In M.-L. Mug-
nier and M. Chein, editors, Proc. ICCS’98, volume 835 of LNAI, pages 144–159.
Springer, 1994.
[Woo75]
W.A. Woods. What’s in a link? In D. G. Bobrow and A. M. Collins, editors, Rep-
resentation and Understanding: Studies in Cognitive Science, pages 3–50. Academic
press, 1975.

Index
acceptable type, 62
annotation, 377
base, 382
answer, 35
antinorm, 76
antinormal, 76
arc-consistency, 154
ARR, 380
assignment, 84
good, 354
atomic negation, 350
b2h, 108
b2lg, 117
b2q, 121
b2q′, 123
b2r, 120
backtrack, 136, 173
banned type, 64
BG, 26, 65, 71
acyclic, 174
bicolored, 277
c-homomorphism, 116
canonical, 228
closed, 303
crazed form, 193
elementary star, 231
empty, 27
equivalent, 36
family, 311
fusionnable, 226
greatest lower bound, 212
guarded, 195
homomorphism, 30
hypergraph vision, 109, 136
irredundant, 37
isomorphism, 33
λ-BG, 274
least upper bound, 210
multigraph-acyclic, 174
normal, 50
partial homomorphism, 136
product, 210
query, 34
quotient, 50
redundant, 37
rule, 274
star, 27
tree, 251
type, 259
union, 229
BG-HOMOMORPHISM, 54, 105
BG̸=, 356
BH, 107
homomorphism, 108
boundary node, 30
box, 251
c2h, 127
canonical model, 86
chain partition, 167
closed BG, 303
compatible, 67
BG partition, 224
C-partition, 223
concept node set, 213
homomorphism, 366
pair of C-partitions, 227
R-partition, 223
relation node set, 214
strongly, 216
completion vocabulary, 367
concept, 22
candidate, 142
423

424
Index
label, 26, 28
type, 22
type contraction, 239
type deﬁnition, 236
type expansion, 237
concept graph, 347
conceptual graph
basic, 26
BG, 26
full, 342
SG, 67
conceptual hypergraph, 107
conjunctive type, 61
conjunctive vocabulary, 62
CONJUNCTIVE-QUERY-CONTAINMENT, 123
CONJUNCTIVE-QUERY-EVALUATION, 121
connected, 27
consistency
check, 159
restoration, 322
constraint, 314
disconnected, 320
negative, 314
network, 124
positive, 314
processing, 151
propagation, 151
range restricted, 320
satisfaction problem, 124
contraction
concept type, 239
copy, 40, 45, 69
coref-homomorphism, 74, 75
coreference
add up, 70
class, 67, 70
delete, 70
link, 67
relation, 59, 67, 68, 356
coreferent, 60, 66, 68, 71
corresponding, 142, 176
CQNC, 359
CSP, 141
arc-consistent, 154
CSP, 124
cycle
true, 185
DEDUCTION, 311
deﬁnition
concept type, 236
relation type, 236
description, 251, 260
Descr, 251
Descr(c), 260
detach, 41
detached form, 364
Di f, 356
di f, 357
difference
link, 355
relation, 356, 357
disjoint sum, 45, 70
duplicate, 69
edge
consistency, 141
label, 27
editing, 380
elementary equivalence, 69
concept split, 69
copy, 69
merge, 69
relation duplicate, 69
relation simplify, 69
elementary generalization, 40, 69
copy, 40
coreference delete, 70
detach, 41
increase, 41, 69
relation duplicate, 40
substract, 41, 70
elementary specialization, 45
copy, 45
coreference add up, 70
disjoint sum, 45, 70
join, 45
relation simplify, 45
restrict, 45, 70
entailment, 85
evolution, 326
exchangeable relations, 363
existential graph, 338
expansion
concept type, 237
F model, 311
f2G, 96
FC-consistency, 316
FC-DEDUCTION, 316
FC model, 311
FCG, 342
FEC-DEDUCTION, 325
FEC model, 312
Φ, 89, 90, 343
ﬁlter, 142
closure, 143
edge-consistent, 142, 158

Index
425
edge-consistent closure, 143
pairwise-consistent, 189
standard, 142
ΦN, 264
ﬁnite expansion set, 304
flat, 97, 110
ﬂat vocabulary, 97
FOL
fragment, 201
guarded fragment, 193
FOL( ∧,∃), 95
guarded fragment, 197
k-guarded fragment, 201
k-variable fragment, 201
FOL(∧,∃,L), 92
folding, 39
forward checking, 147, 159
FR-DEDUCTION, 282
FR model, 311
FRC-CONSISTENCY, 322
FRC-DEDUCTION, 322
FRC model, 311
FREC-DEDUCTION, 326
FREC model, 312
full BG, 303
full conceptual graph, 342
Gα, 228
G-specialization, 231
g2b, 114
G2f, 98
G2f, 97
gen-equivalence, 70
generalization, 41
SG, 70
generic marker, 22
good assignment, 354
graph, 114
chordal, 193
individual, 382
li-graph, 204
polarized, 350
primal, 192
product, 208
schema, 384
tree decomposition, 199
treewidth, 199
underlying, 26
graph, 26
GRAPH-HOMOMORPHISM, 114
H-COLORING, 172
h2b, 108
h2c, 128, 130
hierarchy, 23, 64
hom-equivalence, 36
HOM-EQUIVALENCE, 54
homomorphism
BG, 30
BH, 108
compatible, 366
coref, 74
graph, 114
labeled multigraph, 116
NBG, 254
NG, 258
NTG, 261
query, 123
relational structure, 119
SG, 68
TG, 259
hypergraph, 107
acyclic, 187
conformal, 193
dual graph, 187
hypertree, 200
hypertreewidth, 201
incidence graph, 186
join tree, 187
primal graph, 192
running intersection, 187
increase, 41, 69
individual
type, 23
individual graph, 382
information retrieval, 378
irredundant BG, 37
IRS, 378
isomorphism
BG, 33
SG, 68
join, 45
extended, 226
external, 216
internal, 216
maximal, 216
join-irreducible, 168
knowledge
exact, 382
plausible, 384
L-model, 93
L-substitution, 93
L-substitution, 354
label

426
Index
comparison, 161
compatible, 66
modify, 69
labeled multigraph, 116
λ-BG, 274
λ-rule, 274
lattice, 161
lg2b, 116
lg2g, 118
LN, 263
look-ahead, 152, 159
look-back, 152
marker, 22
merge, 69, 71, 215
metadata, 378
model
canonical, 86
equivalence, 85
SG, 84
vocabulary, 84
model-equivalent, 85
module, 383
NBG, 250
depth, 254
homomorphism, 254
NG, 257
homomorphism, 258
ng2bg, 267
norm, 51, 72
normal BG, 50
normal SG, 71, 72
NP-complete, 55
NTG, 259
homomorphism, 261
opposite relation labels, 363
order
concept label, 28
pairwise consistency, 189, 204
PG, 350
complete, 353
consistent, 351
inconsistent, 351
PG-DEDUCTION, 353
PG̸=, 356
piece, 238
polarized graph, 350
Pr, 142
Pr[c], 142
primitive type, 63
problem equivalence, 106
problem reduction, 106
projection, 31
pseudo-BG, 30
Ψ, 99
Ψ FCG, 344
q2b, 121
b2q′, 123
query, 34
answering, 371
conjunctive, 121
containment, 123
homomorphism, 123
quotient BG, 50, 224
R-restorable, 322
r2b, 119
range restricted, 304
RDF, 389
reduction
parsimonious, 106
polynomial, 106
REDUNDANCY, 54
relation
candidate, 142
coreference, 59, 67
duplicate, 40
label, 26
neighbor list, 28
signature, 24
simplify, 45
symbol or type, 22
type, 28
type deﬁnition, 236
relation node
edge partition, 142
negative, 350
positive, 350
relational structure, 119
resource localization, 379
restrict, 45, 70
rooted tree, 174
rule, 273
application, 279
backward chaining, 273, 291
bicolored BG, 277
conclusion, 274, 277
connection node, 274
cut point, 294
dependency, 306
derivation, 282
evolution, 325
FOL semantic, 276
forward chaining, 273, 283

Index
427
frontier node, 277
hypothesis, 274, 277
λ-rule, 274
neutral, 306
piece, 294
piece resolution, 297
safe, 304
schema graph, 384
semantic annotation, 378
semantic web, 388
SG, 60, 66–68
antinormal, 76
entailment, 85
FOL semantic, 90
homomorphism, 68
isomorphism, 68
model, 84
normal, 71
standard, 71
simplify, 69
source BG, 54
specialization, 47
graph, 47
SG, 70
tree, 46
split, 69
stand, 71
standard, 71
star BG, 27
subBG, 29
subSG, 68
substract, 41, 70
subsumption, 31
support, 56
target BG, 54
TG, 259
homomorphism, 259
tractable, 171
tree, 172
TG, 260
Tree, 251, 260
tree order, 161, 166
type
acceptable, 65
acceptable or non-banned, 61
banned, 61, 65
BG, 259
conjunctive, 62, 63
relation, 28
UNA, 62, 66
uniﬁer, 295
vflat, 110, 111
vocabulary, 22, 23, 56, 65
very ﬂat, 110
completion, 367
conjunctive, 62, 65
ﬂat, 97, 110
FOL semantic, 89
model, 84
modular, 383

