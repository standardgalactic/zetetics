A Survey on Causal Discovery:
Theory and Practice
Alessio Zanga1 and Fabio Stella1
1Department of Informatics, Systems and Communication,
University of Milano - Bicocca, Milan, Italy
May 18, 2023
Abstract
Understanding the laws that govern a phenomenon is the core of sci-
entiﬁc progress.
This is especially true when the goal is to model the
interplay between diﬀerent aspects in a causal fashion.
Indeed, causal
inference itself is speciﬁcally designed to quantify the underlying relation-
ships that connect a cause to its eﬀect. Causal discovery is a branch of
the broader ﬁeld of causality in which causal graphs is recovered from
data (whenever possible), enabling the identiﬁcation and estimation of
causal eﬀects. In this paper, we explore recent advancements in a uniﬁed
manner, provide a consistent overview of existing algorithms developed
under diﬀerent settings, report useful tools and data, present real-world
applications to understand why and how these methods can be fruitfully
exploited.
1
Introduction
1.1
A General Overview
One of the mantras that is repeated in every statistical course is that correla-
tion does not imply causation. This is also observed in several disciplines, such
as economics [38], biology [68], computer science [33, 71] and philosophy [27].
Following [32], the main goal of a research study is often to assess the eﬀect, if
any, of an action on some outcome and not measuring a mere correlation. For
example, this is true when it comes to decision making, since deciding which in-
tervention must be taken is not straightforward and must be addressed properly
to avoid any potential side eﬀects. In order to identify and quantify a causal
eﬀect, the set of tools provided by causal discovery must be used accordingly.
Here, the ﬁnal goal is to decompose the total eﬀect of an action into causal and
non-causal eﬀect, removing the bias that is introduced during the estimation
process.
1
arXiv:2305.10032v1  [cs.AI]  17 May 2023

Causal inference itself relies heavily on a formal description on the inter-
actions between the observed variables, i.e.
a casual graph.
Such graphical
representation is na¨ıve in its concept, yet so eﬀective when it comes to explain-
ability. Following [99], it boils down to connect a cause to an eﬀect (outcome)
by drawing arrows from the former to the latter, to obtain a qualitative descrip-
tion of the system under study. This is in stark contrast with black-box tech-
niques, where predictions about an outcome are made with a pure data-driven
approach. Indeed, these methods fall short both in terms of explainability and
decision making, as stated in [8, 28, 32]. Therefore, when causality is empow-
ered through the instrument of graphical models, it is possible to overcome the
current limitations of machine learning and deep learning tools, enabling the
researcher to reach a higher level of understanding.
When the causal graph is unknown, one may recover the cause-eﬀect pairs
by combining available data together with prior knowledge, whenever possi-
ble. The process of learning graphical structures with a causal interpretation
is known as causal discovery. Recently, causal discovery has gained signiﬁcant
traction, especially when experimental data are available. However, this growth
fragmented the landscape into multiple ﬁelds that diﬀer for assumptions, prob-
lems and solutions, while aiming to the same goal. For this reason, this work
summarizes the current status of causal discovery from both a theoretical and
practical point of view, unifying shared concepts and addressing diﬀerences in
the algorithms made available by the specialized scientiﬁc literature.
This survey is structured as follows. In Section 1, the reader is provided a
general introduction to the causal discovery problem, along with an overview
of previous works on the same topic. Section 2 is devoted to provide concepts,
deﬁnitions and problems that are common across diﬀerent approaches presented
in the following pages. Section 3 explores the ﬁrst set of algorithms in the ob-
servational setting, while Section 4 relaxes the acyclicity assumption. In Section
5, the scope is extended to cover the experimental scenario, where multiple in-
teractions with the system of interest are taken into account. Section 6 and 7
report respectively on evaluation techniques and on practical applications of the
discussed methodologies. Finally, Section 8 draws conclusions about the current
landscape of causal discovery.
1.2
Related Works
To the best of our knowledge, six diﬀerent surveys on causal discovery were
published from 2019 to 2022.
In particular, [67] acted as a meta-survey by
checking the contents covered by the others against ﬁve topics, namely: theory,
data, software, metrics and examples. A modiﬁed version of this checklist can be
found in Table 1, which was adapted for a direct comparison with the structure
of our survey.
While every contribution provided adequate background knowledge and the-
oretical deﬁnitions involving the fundamental aspects of causal discovery, only
few examples [27, 63, 66] reported evaluation data sets or metrics, and just
two of them listed both [63, 67]. The landscape is even more fragmented when
2

Related Works
Theoretical
Deﬁnitions
Evaluation
Datasets
Evaluation
Metrics
Software
Packages
Practical
Applications
A Survey of Learning Causality with Data:
Problems and Methods [29]



Causal Inference for Time Series Analysis:
Problems, Methods and Evaluation [63]



Review of Causal Discovery Methods based on
Graphical Models [27]


Causal Discovery in Machine Learning: Theo-
ries and Applications [66]



Toward Causal Representation Learning [86]

Table 1: Comparison of recent surveys on causal discovery in terms of covered
contents.
observed from a practical point of view: only two contributions [66, 67] pre-
sented and discussed the availability of software tools to perform the described
procedures, thus hindering the applicability of causal discovery to researchers
approaching for the ﬁrst time to this topic.
In particular, the work from [29] provides some insights on the discovery pro-
cedure from a deep-learning point of view. Authors in [63] tackled the problem
of recovering the causal graph from time series data sets, while [27] restricted
its attention to the most famous techniques. Moreover, [66] presented a general
survey on the topic without a proper interventional section, as for [86] in the
latent case. Finally, [67] covers causal inference and causal discovery from a
high-level perspective, which is opposed to our in-depth approach focused on
structural learning only.
This survey is designed in the light of the above considerations and aims to
guide the inexpert reader through the forest of causal graphs to avoid common
pitfalls when comparing and assessing the quality of results obtained by diﬀer-
ent causal discovery algorithms. It is worthwhile to mention that this survey is
diﬀerent from those published from 2019 to 2022 with respect to both theory
and practice. Indeed, existing surveys introduce theoretical aspects of causal
discovery while only few of them go into additional details. Another lack of
existing surveys in term of theory is that very few of them discuss the diﬀer-
ence between observational and interventional data. This survey has also many
diﬀerences in terms of practice; i) Only a subset of existing surveys report on
evaluation datasets and metrics, ii) no survey discusses how to tune strategies
for choosing values of algorithm’s hyperparameters, iii) only one survey reports
on software packages, and iv) few surveys discuss practical applications of causal
discovery methods.
3

2
Deﬁnitions and Notation
This section gives the main deﬁnitions, concepts and assumptions on causality,
together with the associated notation. In particular, we give the deﬁnition of
causal model and the deﬁnition of causal discovery problem.
2.1
Notation
We denote mathematical objects with capital letters, such as random variable
X, and collections of objects with capital boldface letters, such as set X.
Deﬁnition 2.1 (Graph). A graph G = (V, E) is a mathematical object repre-
sented by a tuple of two sets: a ﬁnite set of vertices V and a ﬁnite set of edges
E ⊆V × V.
Deﬁnition 2.2 (Directed Graph). A directed graph (DG) G is a graph where
the edge (X, Y ) is distinct from the edge (Y, X).
In particular, a directed edge (X, Y) is graphically represented by an arrow
as X →Y , and induces a set of relationships between the vertices of the graph
G. Given a vertex X, we denote its parents, i.e., the set of vertices that have an
arrow into X, by Pa(X), while we denote its children, i.e., the set of vertices
that have an arrow out of X, by Ch(X). Recursively, any parent and parent
of a parent (child and child of a child) of X is an ancestor An(X) (descendant
De(X)) of X.
The vertices connected to X are said to be adjacent to X and denoted as
Adj(X), while the vertices connected with an undirected edge to X are the
neighbors Ne(X). These two sets of vertices are identical in undirected graphs,
but may be diﬀerent in graphs with other mixed orientations.
Deﬁnition 2.3 (Path). A path π = (X −· · · −Y ) is a tuple of non repeating
vertices, where each vertex is connected to the next in the sequence with an
edge.
Deﬁnition 2.4 (Directed Path). A directed path π = (X →· · · →Y ) is a
tuple of non repeating vertices, where each vertex is connected to the next in
the sequence with a directed edge.
Deﬁnition 2.5 (Cycle). A cycle is a path that starts and ends at the same
vertex.
Deﬁnition 2.6 (Directed Acyclic Graph). A directed acyclic graph (DAG) is
a directed graph G that has no cycles.
2.2
Causal Model
Deﬁnition 2.7 (Causal Graph). A causal graph G [8] is a graphical description
of a system in terms of cause-eﬀect relationships, i.e. the causal mechanism.
4

Deﬁnition 2.8 (Direct and Indirect Cause). For each directed edge (X, Y ) ∈E,
X is a direct cause of Y and Y is a direct eﬀect of X. Recursively, every cause
of X that is not a direct cause of Y , is an indirect cause of Y .
This deﬁnition is formally enforced by the causal edge assumption [28],
where:
Deﬁnition 2.9 (Causal Edge Assumption). The value assigned to each variable
X is completely determined by the function f given its parents:
Xi := f(Pa(Xi))
∀Xi ∈V.
(2.1)
As natural consequence of such deﬁnitions, we can deﬁne models that entail
both the structural representation and the set of functions that regulate the
underlying causal mechanism.
Deﬁnition 2.10 (Structural Causal Model). A structural causal model (SCM)
[8, 56] is deﬁned by the tuple M = (V, U, F, P), where:
• V is a set of endogenous variables, i.e. observable variables,
• U is a set of exogenous variables, i.e. unobservable variables, where V ∩
U = ∅,
• F is a set of functions, where each function fi ∈F is deﬁned as fi :
(V ∪U)p →V, with p the ariety of fi, so that fi determines completely
the value of Vi,
• P is a joint probability distribution over the exogenous variables P(U) =
Q
i P(Ui).
Structural Causal Models are also known as Structural Equation Models
(SEMs).
The joint exogenous distribution P is responsible for the non-deterministic
nature of the model, adding a layer of uncertainty through a set of independent
noise distributions. The unobserved terms U are represented in Figure 2.1 as
dashed vertices with dashed edges.
5

X
Y
Z
UXY
UZ
(a)
M = (V, U, F, P)
V = {X, Y, Z}
U = {UXY , UZ}
F =





fX : X := 2UXY ,
fY : Y := X + UXY ,
fZ : Z := 3Y + UZ
P =
(
UXY ∼N(0, 1),
UZ ∼N(0, 1)
(b)
Figure 2.1: The causal graph G (a) of the related SCM M (b). In (a) X is a
direct cause of Y and an indirect cause of Z, while Y is an eﬀect, a direct eﬀect,
of X. An example of associated SCM is reported in (b), where the functional
set F follows the causal edge assumption.
2.3
The Causal Discovery Problem
The causal discovery problem [100] consists in selecting a causal graph as a
possible explanation for a given data set.
Formally, let G be the set of graphs deﬁned over the variables V of a data
set D and G∗∈G be the true but unknown graph from which D has been
generated.
Deﬁnition 2.11 (Causal Discovery Problem). The causal discovery problem
[99] consists in recovering the true graph G∗from the given data set D.
A causal discovery algorithm is said to solve the causal discovery problem if
and only if it converges to the true graph G∗in the limit of the sample size.
Deﬁnition 2.12 (Soundness and Completeness). A causal discovery algorithm
is sound if it is able to solve the causal discovery problem, while it is complete
if it outputs the most informative causal graph G that can be recovered from
the input data set D, without making further assumptions.
Deﬁnition 2.13 (Consistency of a Causal Graph). A causal discovery algo-
rithm is consistent [27, 99] if it outputs a graph G that induces a probability
distribution consistent with the input data set D.
Deﬁnition 2.14 (Identiﬁability of a Causal Graph). A causal discovery algo-
rithm is said to identify [28] a graph G if it is able to determine the direction
of any edge in G.
In the following pages we will see that some algorithms are able to identify
the causal graph up-to its equivalence class, meaning that setting the direction
6

of any of the remaining undirected edges would not induce a diﬀerent probability
distribution, i.e. it is not possible to choose a speciﬁc direction for that edge
without further assumptions.
Moreover, some of these methods are able to exploit only observational dis-
tributions, i.e. probability distributions that are induced by observation data
set, while others are capable of taking advantage of interventional distributions,
i.e. probability distributions that are generated by experimental data, where we
intervene on the system of interest.
Finally, even though the general formulation of the discovery problem is fo-
cused on the causal graph only, causal discovery algorithms are usually designed
to ﬁnd a solution w.r.t. a speciﬁc set of functions [12, 83, 91, 94], e.g. non-linear
equations.
2.4
Acyclicity and Faithfulness
A graphical model is said to satisfy the Markov property if the associated joint
probability distribution P(V) can be decomposed recursively as:
P(V) =
Y
Xi∈V
P(Xi|Pa(Xi))
(2.2)
The probability factorization expressed in Equation 2.2 relies on the assump-
tion that the relationships encoded by the graph match exactly the underlying
conditional probability independencies:
X ⊥⊥P Y | Z =⇒X ⊥⊥G Y | Z
(2.3)
Essentially, it is assumed that probability independence (⊥⊥P ) implies graph-
ical independence (⊥⊥G), as stated in Equation 2.3.
This assumption is known as d-faithfulness or “directed faithfulness”. In
fact, the graphical model is required to rely on a DAG in order to satisfy the
Markov property. More recently, extensions of the faithfulness assumption to
the cyclic setting have been taken into consideration, e.g. σ-faithfulness [11, 60],
enabling the discovery of general non-acyclic DGs.
In order to test whether a variable X is conditionally independent from Y
given a set Z in any probability distribution P faithful to G, one can use the
d-separation criterion which is based on the concept of blocked path.
In particular, when Z blocks every path between X and Y , we say that X
and Y are d-separated by Z. A path π is blocked depending on the presence of
speciﬁc graphical patterns in it, as given in the following two deﬁnitions.
Deﬁnition 2.15 (Fork, Chain & Collider). Let G be a DG and π be a path on
G. Then, given three vertices X, Y and Z in π, we have the following:
• X ←Y →Z is a fork on π,
• X →Y →Z is a chain on π, and
• X →Y ←Z is a collider on π.
7

Deﬁnition 2.16 (d-separation). Let G be a DG, π be a path on G and Z a
subset of V. The path π is blocked [28] by Z if and only if π contains:
• a fork A ←B →C or a chain A →B →C such that the middle vertex
B is in Z, or
• a collider A →B ←C such that middle vertex B, or any descendant of
it, is not in Z.
The set Z d-separates X from Y if it blocks every path between X and Y 1.
A
B
C
D
E
F
Figure 2.2: In this ﬁgure, A and B are d-separated even without conditioning
on C, since they form a collider. The same does not hold for A and D, given
that they form a chain by means of C, and therefore conditioning (i.e. setting
its value) on the middle vertex C d-separates them.
2.5
Equivalence Classes
In the previous paragraphs we introduced the concept of causal graph as natural
consequence of the causal edge assumption, where the functional set F is mapped
to a directed graph G.
The na¨ıve representation of a DAG does not allow to convey the (lack of)
knowledge that typically arise during a discovery procedure. Here, we deﬁne
formally other graphical representations, along with their interpretations.
Deﬁnition 2.17 (Partially DAG). The graph G is a partially-directed acyclic
graph (PDAG) if it can contain both undirected (−) and directed (→) edges.
This alternative representation allows to distinguish a cause-eﬀect pair (X →
Y ) from a yet unknown relationship (X −Y ), where there is still uncertainty
about the direction of the edge. PDAGs are also called patterns [99].
Deﬁnition 2.18 (Skeleton). Let G be a PDAG. The skeleton of G is the undi-
rected graph resulting from changing any directed edge of G to undirected.
1In a more general setting, d-separation can be extended to set of vertices rather than just
singletons [70]
8

Deﬁnition 2.19 (V-structure). Let G be a PDAG. A v-structure in G is a
triple X →Y ←Z where X and Z are not adjacent. V-structures are also
called unshielded colliders [111].
In the context of PDAGs, v-structures encode the conditional independencies
that shape the associated probability distribution. Any edge that would change,
by either adding or removing, any v-structure when reversed is said to be a
compelled edge, as in Figure 2.3. Any compelled edge, along with the underlying
skeleton, is a constraint for the set of observational distributions compatible with
the given PDAG. Any non-compelled edge is called reversible.
A
B
C
D
E
A
B
C
D
E
Figure 2.3: A DAG on the left and its CPDAG on the right. As we can see,
both graphs have the same underlying structure (i.e. skeleton), but diﬀer from
the orientation of some of the edges. Speciﬁcally, the edges connecting A to B
and C can be rearranged to form diﬀerent chains or a fork. This is not true for
the others edges in the CPDAG, since they are compelled. In fact, modifying
the orientation of one of them would either remove the v-structure formed by
B →D ←C or introduce a new one.
Deﬁnition 2.20 (Observational Equivalence). Two DAGs G and H are obser-
vationally Markov equivalent [111] if they have the same skeleton and the same
v-structures, denoted as G ≡H.
Henceforth, the deﬁnition of equivalence stems from an observational point
of view, where graphs are compared in terms of the observational probability
that is faithful to the given structure. In fact, changing the orientation of an
reversible edge leads to a diﬀerent structure with an equivalent factorization of
the associated probability distribution.
Deﬁnition 2.21 (Observational Equivalence Class). Two DAGs G and H be-
long to the same observational Markov equivalence class (MEC) [60, 61, 112] if
they are Markov equivalent. As generalization, the MEC of a graph G, denoted
by [G], represents the set of possible DAGs that are observationally equivalent.
9

Since MECs are deﬁned in terms of skeletons and v-structures only, edges
that are not part of any v-structure remain undirected, meaning that, given the
limited knowledge, it is not possible to disentangle the relationship between the
two variables.
Deﬁnition 2.22 (Completed PDAG). A PDAG G is said to be completed [99]
if any directed edge is compelled and any undirected edge is reversible w.r.t.
MEC [G].
The usual representation of a MEC is a complete partially-directed acyclic
graph (CPDAG), also called essential graphs [5] or maximally oriented graphs
[58]. Although the discovery problem is focused on recovering the true graph
G∗from a data set D, it is not always possible to retrieve a speciﬁc instance,
but rather its MEC [G∗].
2.6
Suﬃciency vs. Insuﬃciency
In many applications, the collected variables are assumed to be suﬃcient to ﬁnd
the causes of a system of interest. This condition rarely holds true in real world
scenarios [46].
Deﬁnition 2.23 (Causally Suﬃcient Set). The set of variables V is said to be
causally suﬃcient if and only if every cause of any subset of V is contained in
V itself.
That is, there are no unobserved variables U that aﬀect the behaviour of the
causal mechanism generating the data set D. If at least one latent cause exists,
then V is causally insuﬃcient, which means that there exists a non-empty set
of unobserved variables U that contains at least a cause of V. In this case, G
is only a sub-graph of the augmented graph Ga [11, 25] deﬁned over V ∪U, as
depicted in Figure 2.1a.
The equivalence class related to constraint-based causal insuﬃcient methods
relies on the concept of mixed graph and its properties.
Deﬁnition 2.24 (Mixed Graph). The graph G is a mixed graph (MG) [79, 113]
if it can contain undirected (−), directed (→) and bidirected (↔) edges.
In mixed graphs the focus is on the edge endpoints, also called marks, rather
than on the edge itself. For example, the directed edge X →Y is decomposed
in two marks: the one insisting on X−··· and the one insisting on ···→Y . For
this reason, we refer to the former as the tail mark (−) and the latter as the
arrowhead mark (>). Therefore, a bidirected edge is an edge with both marks
set to arrowheads.
In a bidirected edge X ↔Y , X is a spouse of Y and vice versa. Therefore,
the set of vertices connected with a bidirected edge to X is the spouse set Sp(X).
The graphical relationships inherited from partially directed graphs remain the
same.
The fork, chain and collider patterns must be revised in the context of bidi-
rectional edges. Let G be a MG and π a path on G. The pattern X∗→Y ←∗Z
10

is a collider on Y , where ‘∗’ stands for a generic mark. Any other pattern is a
non-collider.
Deﬁnition 2.25 (M-separation). Let G be a MG, π be a path on G and Z a
subset of V. The path π is blocked [22] by Z if and only if π contains:
• a non-collider such that the middle vertex is in Z, or
• a collider such that middle vertex, or any descendant of it, is not in Z.
The set Z m-separates X from Y if it blocks every path between X and Y .
Deﬁnition 2.26 (Ancestral Graph). A mixed graph G is ancestral if:
• G has no (directed) cycle, and
• X ∈Sp(Y ), then X ̸∈An(Y ), and
• X ∈Ne(Y ), then Pa(X) = ∅∧Sp(X) = ∅.
These conditions allow an insightful interpretation of arrowheads in mixed
graphs. In particular, in ancestral graphs, an arrowhead implies non-ancestorship,
which explains why these representations are particularly useful in deﬁning
causal relationships.
Deﬁnition 2.27 (Maximal Ancestral Graph). An ancestral graph is maximal
(MAG) if any pair of non adjacent vertices are graphically separated (in terms
of m-separation).
As for the previous deﬁnition of the Markov equivalence class of DAGs using
a CPDAG, the MEC of a set of MAGs is represented using a partial ancestral
graph (PAG). A mark that is present in the same location in any MAG of a
MEC is called invariant.
Deﬁnition 2.28 (Partial Ancestral Graph). The graph G is a partial ancestral
graph (PAG) if it can contain any combination of the following edge marks: tail
(−), arrowhead (→) and circle (◦). Moreover, let [G] be the MEC associated to
G, then:
• G has the same adjacencies of [G], and
• any arrowhead mark in G is invariant in [G], and
• any tail mark in G is invariant in [G].
As direct consequence of this PAG deﬁnition, any circle mark present in G
represents a variant mark in [G], as for reversible edges of CPDAGs. Thus,
PAGs are the most informative representation of MECs for MAGs, hence, they
satisfy the same completed deﬁnition of CPDAG.
The interpretation of PAGs can be tricky:
1. (X →Y ) - X causes Y and Y does not causes X, there may be an
unobserved confounder,
11

2. (X ↔Y ) - Neither X causes Y nor Y causes X, there is an unobserved
confounder that causes both X and Y ,
3. (X◦→Y ) - Either X causes Y , or there is an unobserved confounder that
causes X and Y . While Y does not causes X.
4. (X ◦−◦Y ) - Exactly one of the following holds: X causes Y or vice versa;
there is an unobserved confounder that causes X and Y ; or both (1) and
(3); or both (2) and (3).
Understanding which causal statement is implied by each equivalence class is
fundamental for a coherent interpretation of its graphical representation.
A
B
C
D
E
A
B
C
D
E
Figure 2.4: A mixed graph on the left and one of its’ possible PAGs on the right.
Depending on additional assumptions, such as homoscedasticity or non-
linearity, some algorithms are able to identify the causal graph beyond its equiv-
alence class and recover a single graph instance [74, 94, 95].
2.7
Adding Prior Knowledge
Sometimes a cause-eﬀect pair is known to exist (or to not exist) a priori, e.g.
through expert’s elicitation.
Following the causal edge assumption, we can
explicitly represent pairs as directed edges, deﬁning a knowledge base composed
of required (or forbidden) causal statements.
Deﬁnition 2.29 (Knowledge Base). A knowledge base K is deﬁned as an or-
dered pair (R, F), where R is the set of required directed edges, while F is the
set of forbidden directed edges.
The knowledge base K is a valid representation for the given background
knowledge. There exists a class of algorithms that are capable of taking advan-
tage of this prior knowledge [58, 61], either by integrating such knowledge before
the actual discovery step or by checking if the resulting graph is consistent a
posteriori.
12

Algorithm
Year
Category
Output
Non-Linear
Insuﬃcient
Cyclic
Intervention
PC [18]
1991
Constraint
CPDAG
FCI [113]
2008
Constraint
PAG

GES [4]
2013
Score
CPDAG
FGES [75]
2017
Score
CPDAG
ARGES [65]
2018
Hybrid
CPDAG
GFCI [69]
2016
Hybrid
PAG

HCR [15]
2018
Score
DAG
bQCD [105]
2020
Asymmetric
PDAG
LiNGAM [34, 94]
2014
Asymmetric
DAG

NOTEARS [114]
2018
Score
DAG
CCD [80]
1996
Constraint
PAG

LiNG [48]
2012
Asymmetric
DG

dseptor [37]
2017
Exact
MG


bcause [77]
2020
Exact
MG


σ-CG [24]
2018
Constraint
σ-CG



GIES [31]
2012
Score
CPDAG

IGSP [112]
2018
Score
CPDAG

UT-IGSP [103]
2020
Score
CPDAG

FCI-JCI [61]
2020
Constraint
PAG



Ψ-PC [40]
2020
Constraint
CPDAG

Ψ-FCI [40]
2020
Constraint
PAG


backShift [82]
2015
Asymmetric
MG



bcause+ [78]
2020
Exact
MG




DCDI [13]
2020
Asymmetric
DAG


Table 2: Algorithms classiﬁed by supported () and unsupported settings.
13

3
Causal Discovery
In this section we introduce the ﬁrst class of causal discovery algorithms. Here,
the hypothetical data set is represented by static observational data samples,
neither interventional information nor time dependencies are taken into account.
A summary of the explored algorithms can be found in Table 2.
3.1
Constraint-based Algorithms
Constraint-based algorithms try to recover the causal graph by exploiting a
set of conditional independence statements (CISs) obtained from a sequence
of statistical tests.
This class of methods translates conditional probability
independence into graphical separation by assuming faithfulness (Subsection
2.4) of the underlying distribution.
Deﬁnition 3.1 (Perfect Map). A graph G is said to be a perfect map [16, 47]
for a probability distribution P if every CIS derived from G can also be derived
from P and vice versa:
X ⊥⊥P Y | Z ⇐⇒X ⊥⊥G Y | Z
(3.1)
Deﬁnition 3.2 (Conditional Independence Test). The null H0 and alternative
hypotheses H1 deﬁned as H0 : X ⊥⊥P Y | Z and H1 : X ̸⊥⊥P Y | Z, let I(X, Y |Z)
to denote a conditional independence (CI) test. The null hypothesis H0 is not
rejected if and only if the resulting p-value is higher than a chosen signiﬁcance
level α:
ˆI(X, Y |Z) > α =⇒X ⊥⊥P Y | Z
(3.2)
When faithfulness is assumed, probability independence implies graphical
separation2. The main limitation of this approach is related to the exponential
growth of the conditioning set Z. Indeed, given the pair (X, Y ), in the worst case
scenario where X is dependent on Y (or vice-versa), the algorithm is required
to test for
2(V\{X,Y }) conditioning sets.
Constraint-based methods are generally capable of integrating prior knowl-
edge into the learning process.
Conditional Independence with Mixed Data
Constrain-based techniques
are essentially agnostic of the speciﬁc conditional independence test that is be-
ing used. Indeed, it is possible to take advantage of such approaches in a wide
variety of scenarios, as long as the assumptions of the said test are satisﬁed.
While the main focus of causal discovery studies has been into either discrete or
continuous settings, recent advances in conditional independence testing [6, 107]
extend existing tests to mixed-data.
2Here the term separation is used as a placeholder for a generic graphical separation, which
is intended as d-separation for directed graphs and m-separation for mixed graphs.
14

Peter-Clark (PC)
One of the most studied algorithm that leverages the CISs
is the Peter-Clark (PC) algorithm [99] with its variants [18, 49].
The ﬁrst step of the procedure consists in deﬁning a complete undirected
graph over the variables of the given data set D. Subsequently, a sequence of
conditional independence (CI) tests are performed following an heuristic strategy
[18], in order to minimize the number of tests needed. For instance, it is known
that the power of CI test decreases when the size of the conditioning set increases
[51], due to the curse of dimensionality. A common approach consists in selecting
an upper limit to the size of the conditioning set, discarding computational-
intensive time-wasting tests with low signiﬁcance levels.
The obtained independence statements are then used to remove the associ-
ated edges and identify the underlying skeleton. Finally, the remaining edges are
oriented according to a set of rules [58] that leverages the identiﬁed v-structures
and acyclicity property.
The resulting equivalence class is returned as a CPDAG, where the remain-
ing undirected edges are reversible for the given observational distribution that
arises from the data.
Fast Causal Inference (FCI)
A ﬁrst extension of the PC algorithm to the
causal insuﬃcient setting (Subsection 2.6) is represented by the Fast Causal
Inference (FCI) [102, 113] algorithm. Speciﬁcally, the FCI algorithm relaxes
both the assumption of no latent confounding [32] and no selection bias [50]
in the observational setting, pushing the causal discovery problem a step closer
to real-world scenarios. In this context, the authors leverage the deﬁnition of
discriminating path to derive a new set of orientation rules.
Deﬁnition 3.3 (Discriminating Path). Let G be an ancestral graph, a path
π = (X, . . . , W, Z, Y ) between X and Y is a discriminating path for Z if (i) π
contains at least three edges, (ii) X is not adjacent to Y , (iii) Z is adjacent to
Y , and (iv) every vertex between X and Z is a collider on π and parent of Y .
Discriminating paths are closely related to the separation sets identiﬁed by
the PC algorithm: if a path π between X and Y is discriminating for Z, then
Z is a collider on π iﬀevery set that separates X and Y does not contains Z,
otherwise it is a non-collider iﬀevery set that separates X and Y contains Z.
3.2
Score-based Algorithms
Score-based algorithms are usually structured around the maximization of a
measure of ﬁtness of a graph G through a space of possible graphs G for the
observed samples D, following a deﬁned scoring criterion S(G, D) [17]:
G∗= argmax
G∈G
S(G, D)
(3.3)
In the next few paragraphs, a set of properties for scoring criteria are intro-
duced, before shifting the focus on an optimal two-step procedure for the causal
suﬃcient scenario.
15

Deﬁnition 3.4 (Decomposable Score). A scoring criterion S(G, D) is decom-
posable if it can be deﬁned as a sum of the scores over a vertex and its parents:
S(G, D) =
X
Xi∈V
S(Xi, Pa(Xi), D)
(3.4)
As direct consequence of this property, during the discovery procedure, the
score computation can be simpliﬁed in terms of local diﬀerences of the causal
graph.
Moreover, the comparison of scores of two DAGs G and H can be handled
by taking into account only the vertices that have diﬀerent parent sets.
Deﬁnition 3.5 (Equivalent Score). A scoring criterion S(G, D) is score equiv-
alent if S(G, D) = S(H, D), for each pair of graphs G and H in the same
equivalence class.
A graph G is said to contain a probability distribution P if there exists an
independence model associated with G that represents P exactly, i.e. G is a
perfect map of P.
Deﬁnition 3.6 (Consistent Score). Let D be a data set associated with a
probability distribution P and let G and H be two graphs. A scoring criterion
S is said to be consistent in the limit of the number of samples if and only if:
• If only G contains P, then S(G, D) > S(H, D),
• If both G and H contain P and the model associated with H has fewer
parameters that the one with G, then S(G, D) < S(H, D).
If a scoring criterion is both decomposable and consistent, then it is locally
consistent.
Deﬁnition 3.7 (Locally Consistent Score). Let G be a graph and H the graph
resulting from addition of the edge X →Y to G. A scoring criterion S(G, D)
is said to be locally consistent if and only if:
• X ⊥⊥P Y | Pa(X) =⇒S(G, D) < S(H, D),
• X ̸⊥⊥P Y | Pa(X) =⇒S(G, D) > S(H, D).
Explicitly, if a scoring criterion is locally consistent then the score:
• Increases when any edge that eliminates an independence constraint that
does not hold in the generative distribution is added, and
• Decreases when any edge that does not eliminate such a constraint is
added.
This property guarantees that any deletion of an unnecessary edge will produce a
higher score value, allowing the deﬁnition of a optimal greedy search algorithm.
We report a brief list of scores for reference, such as the Akaike Informa-
tion Criterion (AIC) [3], the Bayesian Information Criterion (BIC) [87], the
Bayesian Dirichlet equivalent uniform (BDeu) [26] and the Bayesian Dirichlet
sparse (BDs) [89].
16

Deﬁnition 3.8 (Optimal Equivalence Class). Let [G]∗be the equivalence class
that is a perfect map of the probability distribution P and D the associated
data set. In the limit of the number of samples:
S([G]∗, D) > S([G], D)
∀[G] ̸= [G]∗
(3.5)
Greedy Equivalent Search (GES)
The Greedy Equivalence Search (GES)
[4, 57] is optimal in the limit of the number of samples [17]. The ﬁrst step of the
algorithm consists in the initialization of the empty graph G. The algorithm is
composed by two phases: the forward search and the backward search. In the
forward search phase, (i) G is modiﬁed by repeatedly adding the edge that has
the highest delta score, until there is no such edge that increases the score. In
the backward search phase, (ii) the edge that again achieves the highest delta
score is repeatedly removed. The algorithm terminates once it reaches a local
maximum during the backward search phase.
This algorithm is designed to work under causal suﬃciency.
When this
assumption no longer holds, the procedure is known to introduce extra edges as
a compensation behaviour for the unobserved relationships. For example, when
a fork (X ←Y →Z) is present and the middle vertex is indeed latent, GES
will likely add an edge between the other two observed vertices of the structure,
even if such edge is not present in the true graph. Any algorithm that is based
on this technique and does not address the issue directly displays such pattern.
Fast GES (FGES)
Score-based algorithms are as fast as the computation of
the chosen scoring criterion is. Leveraging the properties of the score function, it
is possible to minimize the number of computations needed by storing previous
intermediate evaluations. Not only this optimizations reduce the computation
time considerably, but also allow the application of these methods to high-
dimensional data sets [6, 75]. This “fast” variant of GES (FGES) caches partial
graph scores (i.e. delta scores), signiﬁcantly increasing the memory usage, since
relevant fragments of the graph may be considered. Moreover, computationally
expensive sections of the algorithm can be parallelized, taking advantage of high
performance computing (HPC) settings.
3.3
Hybrid Algorithms
With the term “hybrid” algorithms we refer to the class of methods that combine
constraint-based and score-based approaches to mitigate their drawbacks.
Adaptively Restricted GES (ARGES)
Consistency of constraint- and
score-based algorithms is usually proved in low-dimensional use cases, where the
number of samples is orders of magnitude greater than the number of variables.
Hybrid approaches generally lacks a formal and rigorous proof of consistency,
leading to undeﬁned behaviour. For this reason, an adaptively restricted variant
of GES (ARGES) [65] has been developed, targeting speciﬁcally the consistency
weakness in both low- and high-dimensional spaces.
17

The novelty of this hybrid version of GES stems from the concept of admis-
sible edge. Let G be a CPDAG and X and Y be a pair of non adjacent vertices
on it. Adding an edge between X and Y is admissible for the graph G if (i) X
and Y are adjacent in the (estimated) skeleton of G or (ii) there exists a node
Z such that X →Z ←Y is a v-structure in G.
From the deﬁnition of admissible edge, an equal admissible move consists in
adding such edge to the graph and obtain a new equivalent CPDAG. This point
is suﬃcient to prove that the resulting forward phase of ARGES is consistent
when restricted to admissible moves (i.e. it is an independence map for the
given observational probability distribution [17]).
Greedy FCI (GFCI)
Score-based causal discovery algorithms such as GES
and FGES are asymptotically correct, but are not designed to work in a causal
insuﬃcient scenario, where unmeasured confounders are present in the true
graph. Constraint-based causal search algorithms, such as FCI, are asymptot-
ically correct even with unmeasured confounders, but often perform poorly on
small samples. The Greedy Fast Causal Inference (GFCI) [69] algorithm com-
bines score-based and constraint-based algorithms improving over the previous
results while being asymptotically correct under causal insuﬃciency.
Speciﬁcally, the initial skeleton is obtained by un-orienting the CPDAG re-
sulting from the execution of FGES. Then, the orientation rules of FCI are
applied, with only a few slight modiﬁcations that rely on original FGES output.
This approach leads to an improved accuracy over the distinct constraint- and
score-based approaches. As a side eﬀect, additional requirements arise from the
union of these methods. For example, not only the conditional independence
test is required to be consistent by FCI, but also the associated score must be lo-
cally consistent due to FGES. This constraint reduces the practical applications
to settings where indeed such score exists.
3.4
Other Methods
Hidden Compact Representation (HCR)
Causal discovery methods for
discrete and mixed variables have gained renovated interested in the last few
years [6, 107]. Although additive noise models have been widely used in the
context of continuous variables, it is diﬃcult to justify their application with
categorical data, where the addition operator between the levels of variables is
not well deﬁned.
For this reason, authors in [15] developed a new low-dimensional embedding
for discrete variables, allowing a (hidden) compact representation (HCR) of the
discrete states of such variables. The method follows a two-stage procedure:
at ﬁrst, a discrete variable is deterministically mapped into a low-cardinality
representation (e.g. binary), which acts as a proxy for the information contained
in the original variable; then, a set of samples are drawn for the new proxy
variable using a probabilistic mapping. The overall complexity of the model
in controlled using the BIC score, balancing between total ﬁtness and size of
parameters.
18

The authors address the problem of identiﬁability of the model and prove
that, under mild conditions, the causal graph recovered from observational data
is identiﬁable. The method is tested against both synthetic and real-world data,
providing reference values for performance metrics. In these experiments, HCR
outperforms linear models in terms of accuracy and sensitivity, especially when
the additive noise assumption does not hold.
Quantile Causal Discovery (bQCD)
The quantile causal discovery (bQCD)
[105] technique is designed to uncover cause-eﬀect pairs in the bivariate setting.
By re-expressing independence statements in light of the minimum description
length (MDL) [81], the authors build a discovery procedure by using quantile
scoring.
Following [41], let X and Y be two random variables with joint, marginal
and conditional distributions denoted by F, FX and FX|Y respectively. The key
concept here is that a lower complexity follows from a correct causal orientation
of the (X, Y ) pair, since it is a more informative representation of the associated
data.
Hence, the Kolmogorov complexity K(F) is deﬁned as the length of the
shortest program that outputs F(X). Since K(F) measures the information con-
tained in F, authors in [104] state that if X causes Y , then K(FX)+K(FY |X) ≤
K(FY )+K(FX|Y ). The problem is that K(F) cannot be computed in practice.
Therefore, the authors relies on the MDL principle as a proxy for the Kol-
mogorov complexity. Such an approximation can be performed by estimating
the population quantiles through nonparametric quantile regression.
The resulting procedure is robust to outliers and can be generalized to a
wide range of distributions, although it requires that all population quantiles
must be computable, which could be a limiting factor in real-world applications.
Linear Non-Gaussian Acyclic (LiNGAM)
In the context of linear causal
models, when causal suﬃciency holds, the observed variables can be expressed
as a linear combination of the noise terms:
x = Bx + e
(3.6)
Here, the exogenous distribution is assumed to be made of mutually independent
(possibly non-Gaussian) variables. Solving for x reduces to the identiﬁcation of
the matrix A such that:
x = (I −B)−1e = Ae
(3.7)
The LiNGAM [94, 95] algorithm relies on independent component analysis
(ICA) [20] to identify a possible solution for A. In fact, multiple mixing ma-
trices A are feasible solutions for the given joint probability distribution. This
technique is essentially focused on discovering asymmetries in the sample dis-
tribution to determine the correct causal ordering.
Once such ordering has
been discovered, the causal graph is built by recovering all and only the edges
coherent with the order.
19

The LiNGAM method has been extended later for causally insuﬃcient set-
tings [34].
Let f be the vector of latent variables and Λ the matrix of the
connections strength between f and x, then:
x = Bx + Λf + e
(3.8)
The proposed model can be solved with a variant of ICA, called overcomplete
ICA, which takes into account the presence of unobserved eﬀects.
The LiNGAM algorithm consistently estimates the connection matrix B.
While standard ICA does not scale well in high-dimensional settings, approxi-
mated variants of ICA can be used to compute the components with a predeﬁned
ﬁx number of iterations with reasonable precision. This leads to a eﬃcient so-
lution in presence of non-gaussian noise and causally insuﬃcient data sets.
Continuous Optimization (NOTEARS)
In the “DAGs with NO TEARS”
[114] algorithm, the causal discovery problem is reduced to a continuous opti-
mization problem. The acyclicity constraint is expressed as an equality con-
straint h(W) = 0, where h is a smooth diﬀerentiable function that measures
the “DAG-ness” (i.e. a quantiﬁcation of the acyclicity violations) of a given
adjacency matrix W. When W is binary then:
h(W) = tr(eW◦W) −n = 0
(3.9)
where tr, is the trace operator, ◦is the Hadamard product, e∗is the matrix
exponential and n the size of W. Moreover, this function has a rather simple
associated gradient:
∇h(W) = (eW◦W)T ◦2W
(3.10)
Coeﬃcients smaller than a ﬁxed threshold ω > 0 are set to zero, rounding the
solution with an arbitrary precision. The evaluation of the matrix exponential
is O(n3), i.e. cubic in the number of vertices. Given the low computational
complexity, NOTEARS outperforms existing methods when both the in-degree
and the sample size are large.
4
Causal Discovery with Cycles
4.1
Cyclic SCM
In a SCM, the causal graph induces a functional set F where equations follows
the decomposition enforced by the causal edge assumption, Subsection 2.9. If
the causal graph is acyclic, then the SCM itself is called acyclic, or recursive
SEM. The concept of recursion is linked to the hierarchical order that arises
from the topological ordering of the underlying DAG. Indeed, it is possible to
deﬁne a sequence X1, X2, . . . , Xn of vertices over V such that for any Xi and
Xj where i < j, Xj is not a cause of Xi [9].
Therefore, in a non-recursive SEM, or cyclic SCM, some endogenous vari-
ables are connected to each other, forming cycles that do not allow a recursive
20

decomposition. Still, the causal edge assumption is satisﬁed, since its deﬁnition
is consistent even in the presence of cycles.
4.2
No Acyclicity Assumption
Conditional independencies arising from cyclic SCMs are entailed by the cyclic
graphs [80]. It can be shown that, in general, there is no DAG encoding the
conditional independencies which hold in such SCM [64]. Nonetheless, cyclic
SCMs are widely used to model systems with feedback, and are applied in soci-
ology, economics and biology, making this class of models a relevant target of
interest for causal discovery techniques.
To test for such independencies, d-separation can be adapted to the cyclic
setting under the assumption of causal suﬃciency [101]. In causally insuﬃcient
scenarios, d-separation can be replaced with σ-separation [24, 25] applied to
directed mixed graphs (DMGs), i.e.
mixed graph (Subsection 2.24) without
undirected edges.
Deﬁnition 4.1 (Strongly Connected Component). Let G be a DG and X a
vertex in G. The strongly connected component [24] of a vertex X is deﬁned as:
SCC(X) = An(X) ∩De(X)
(4.1)
that is, the set of vertices that are both ancestors and descendants of X, includ-
ing X itself.
Deﬁnition 4.2 (σ-separation). Let G be a DMG, π be a path on G and Z a
subset of V. The path π is blocked [24, 25] by Z if and only if π contains:
• a collider A∗→B ←∗C where B ̸∈An(Z), or
• a non-collider A ←B ∗−∗C (or A ∗−∗B →C) where B ∈An(Z) and A
(respectively C) is part of SCC(B) (Equation 4.1).
The set Z σ-separates X from Y if it blocks every path between X and Y .
The above graphical criterion implies d-separation and reduces to it in the
case of DAGs.
Cyclic Causal Discovery (CCD)
The Cyclic Causal Discovery (CCD) al-
gorithm [80] has been the only provably sound (Subsection 2.12) approach to
general directed graphs until the development of LiNG [48]. CCD is a constraint-
based algorithm that follows the same initial procedure as the one of the PC
algorthm, with ﬁve diﬀerent orientation rules. CCD outputs a PAG G which
diﬀer from the output of FCI for a couple of additional patterns:
• underlining triples (X ∗−∗Y ∗−∗Z), where Y is an ancestor of at least one
of X or Z in every graph in [G], and
• dotted underlining triples (X∗→Y...←∗Z), where Y is not a descendant of
a common child of X and Z.
21

These additional patterns arise from a fundamental problem: the algorithms is
not complete, and, therefore, there may be features common to all graphs in the
same equivalence class that are not present in the output PAG (i.e. it is not
the most informative PAG). While not being complete in the same sense of the
previous algorithms, CDD is d-separation complete, meaning that the resulting
PAG represents an equivalence class with a single graph, i.e.
it encodes all
the needed conditional independecies. Therefore, CCD is useful when one is
interested in querying the resulting graph about dependencies, but lacks the
capability to represent every causal edge by deﬁnition, in contrast to others
algorithms. This limitation makes it less suitable for the deﬁnition of SCMs,
especially when one is interested in the form of the functional set.
Linear Non-Gaussian (LiNG)
The LiNGAM algorithm can be adapted to
the cyclic setting by weakening the acyclicity assumption. Speciﬁcally, instead
of targeting a DAG, LiNG (or LiNG-D family) [48] try to recover a simple graph
(i.e. without self-loops) by forcing all entries on the diagonal of the B matrix
to be zero.
While LiNGAM output could be seen as a set of admissible models that
contains a single model (i.e. the model is identiﬁable), the cyclic variant usually
admits more than one causal graph at the time. In fact, the acyclicity assump-
tion that allowed to ﬁnd the row-permutation of B that best ﬁts the given data
set is missing. The authors then suggest to limit the discovery procedure to the
k-th best assignment, following the intuition that permutations associated to
inadmissible models would score poorly asymptotically. This approach selects
one single model from the equivalent class (i.e. returning set).
LiNG inherits both limits and strengths of the original method: approximate
(or sparse) ICA can be a valid alternative if running the full ICA is computa-
tionally expensive for the considered task.
σ-Connection Graphs
From the concept of σ-separation, one can derive a
MG where conditional independencies are expressed in the presence of cycles
and latent variables, namely a σ-Connection Graph (σ-CG). An algorithm to
learn this structures from data has been developed [24] as a natural extension
of the work presented in [36]. The causal discovery problem is re-casted as a
continuous optimization problem based on the following loss function:
L(G, S) =
X
λi(1λi>0 −1Xi⊥⊥GYi|Zi)
(4.2)
where S is a set of conditional independence statements expressed as S =
 (Xi, Yi, Zi, λi)
n
i=1, where Xi, Yi and Zi are variables in V and λi ∈R ∪
{−∞, +∞} encodes the conﬁdence of probabilistic conditional independence
Xi ⊥⊥P Yi|Zi as a constraint.
The λi weights are evaluated using the indicator function 1 to constrain the
conditional dependence between variables.
Therefore, Equation 4.2 quantify
the amount of observations against the proposed causal graph based on the ob-
served data. During the experimental evaluation, authors relied on the weights
22

proposed in [53]:
λi = log pi −log α
(4.3)
with pi representing the p-value of a statistical test for conditional independence
and α being a signiﬁcance level.
Minimizing the loss function may lead to multiple optimal solutions, where
each solution G is an instance of the actual equivalence class [G]. Indeed, as
for d-separation and CPDAGs, the σ-separation criterion and the associated
σ-CGs take into account possible undirected edges that are invariant for any
causal graph belonging to the same equivalence class.
This algorithm has been benchmarked against synthetic data in low-dimensional
setting. While the recovery metrics show consistent performances across the ex-
periments, especially when increasing the number of interventions, it is clear
that the main limitation of this approach is linked with the σ-separation en-
coding, as noted by [78]. Indeed, the separation checks are preformed using
Answer Set Programming (ASP), a declarative logic programming language,
which slows down the learning procedure.
bcause
The procedures described so far are essentially approximate algo-
rithms that reduce the search space (i.e.
the number of conditionally inde-
pendence tests) by using previously computed test results. In fact, edges that
are tested in later phases rely on adjacent vertices that are selected in earlier
steps of the algorithm. During the last few years, exact search approaches have
been developed in a branch-and-bound fashion.
The bcause algorithm [77] explores the search space in a tree-like visit guided
by an objective function that determines the weight of a potential solution.
During the discovery phase, any edge of an intermediate result G is either absent,
present or undecided. Before the actual branching step, the lower bound of the
given objective function for the current partial solution G′ is computed. If such
bound is higher than the weight obtained by the previous solution G, the branch
can be closed and the algorithm backtracks. Otherwise, if G′ contains at least
one undecided edge, the procedure branches recursively in two directions: one in
which said edge is set as present and the other marked as absent. Finally, if the
branch cannot be closed and G has no undecided edge, then the current solution
G′ is updated if and only if the evaluation of the objective function results in a
lower weight. The search procedure will return G as a globally optimal solution.
Since the causal discovery problem is inherently exponential, an exact search
algorithm is unfeasible in the general setting. However, if both the objective
function and its lower bound can be eﬃciently evaluated, a constrained space
for a low dimensional problem can be eﬀectively explored. For example, the
authors benchmark their method under diﬀerent conditions, showing that as-
suming acyclicity result in a lower execution time.
Moreover, the algorithm
maintains a set of constraints satisﬁed by the local solution and updates them
incrementally. Therefore, any incompatible extension of the current solution is
ruled out by leveraging a linear programming solver, reducing the total number
of evaluation needed.
23

Layer
Question
Method
Observational
How would seeing X change my
belief in Y ?
Un/Supervised
Learning
Interventional
What happens to Y if I do X?
Reinforcement
Learning
Counterfactual
What would have happened to Y
if I had done X′ instead of X?
Structural
Causal Model
Table 3: Layers of causation with associated questions, practical examples and
methods.
5
Causal Discovery with Interventions
This section is focused on the diﬀerence between learning causal models using
either observational or interventional data. While the former setting has been
explored extensively in the past decades, only recently solutions for properly
handling experimental data have been proposed.
5.1
Observational vs. Interventional
In order to grasp the added value of experimental data, we will introduce the
concept of ladder of causality [8, 72] as a reference framework.
The Ladder of Causation
The ladder of causation, also called the causal
hierarchy, is an ordered structure of composed by three layers, where each layer
is mapped to a cognition level: observational, interventional and counterfactual.
A level inherently deﬁnes the set of potential queries that can be answered with
the given information associated to it.
In practice, the observational layer is composed by associational or factual
data, while the interventional layer is related to data that are generated by an
intervention on the system, i.e. an experiment. Interacting with the system
itself is the reason why these two levels are diﬀerent. The counterfactual layer
is the highest level of cognition, where one may ask what would have happened
if a diﬀerent intervention had been performed, opposed to the one that factu-
ally altered the system. This hypothetical scenario is strongly opposed to the
observational one, being in the counter-factual space.
Even if the three layers represent diﬀerent information levels, they are not
distinct. In fact, each layer is a generalization of the previous one, e.g. the
observational setting can be seen as a special case of the interventional scenario,
where no intervention is performed. Therefore, the interventional layer subsumes
the observational one. The same happens with the counterfactual layer w.r.t.
the interventional one, provided that the former allows to deﬁne hypothetical
actions that were not present in the latter, as expressed in Table 3.
At this point, one may ask how to formally represent the concepts expressed
by this hierarchy, to operatively exploit the informative gap between the layers.
24

The answer is provided by do-calculus [70].
do-calculus
Queries that are usually expressed in natural language can be
rephrased in terms of probability distribution by introducing the do operator,
whenever possible3.
Deﬁnition 5.1 (Rules of do-calculus). Let G be a causal graph and P the
probability distribution induced by G. For any disjoint subset of variables X,
Y, Z and W, the following three rules apply:
1. Insertion and deletion of observations:
P(Y | do(X), Z, W) = P(Y | do(X), W)
(5.1)
if (Y ⊥⊥Z | X, W) holds true in GX,
2. Exchange of observations and interventions:
P(Y | do(X), do(Z), W) = P(Y | do(X), Z, W)
(5.2)
if (Y ⊥⊥Z | X, W) holds true in GX,Z,
3. Insertion and deletion of interventions:
P(Y | do(X), do(Z), W) = P(Y | do(X), W)
(5.3)
if (Y ⊥⊥Z | X, W) holds true in GX,Z(W),
where GX is the subgraph of G where the incoming edges into X are re-
moved, GZ is the analogous for the outgoing edges from Z, and ﬁnally Z(W) is
Z \ An(W) w.r.t. the subgraph GX.
With these rules, which are correct and complete, a causal eﬀect can be
identiﬁed if there exists a ﬁnite sequence of applications of such rules leading to
a do-free expression of the considered probability distribution.
5.2
Types of Interventions
Deﬁnition 5.2 (Perfect Intervention). An intervention is said to be perfect (or
hard) if it removes the causal dependencies (i.e. the incoming causal edges, as
in Subsection 2.9) that aﬀect the intervention target.
Indeed, do-calculus enables us to express perfect interventions in a operative
framework, but there are other types of interventions that cannot be expressed
using this notation.
3We restrict ourselves to a minimal introduction of the do-calculus, aiming to formally
represent the set of concepts that are essential for the causal discovery scenario. For a broader
discussion on identiﬁcation and estimation of the causal eﬀect, refer to [96]
25

Deﬁnition 5.3 (Imperfect Intervention). An intervention is said to be imperfect
(or parametric, soft) [55] if it does not remove the causal dependence that aﬀects
the intervention target, but alters the functions that represents such dependence.
For instance, an imperfect intervention on an SCM could be a change in the
parameters that quantify the strength of the causal relationships, while a perfect
intervention would result in hard setting them to zero. In this sense, perfect
interventions are a subset of imperfect interventions, where some variables are
removed from the equations of the functional set as a special case.
Mechanism Change
Imperfect interventions itself are a formal deﬁnition of
a broader concept called mechanism change [106]. For a SCM M with a causal
graph G and a set of parameters Θ associated to the function set F. A mechanism
change is a mapping from M to M ′, where the new set of parameters is deﬁned
as Θ′ = Ψ′∪(Θ \ Ψ), with the new subset Ψ′ that diﬀers from the original subset
Ψ. The change aﬀects the behaviour of the function set F, inducing a set F′.
5.3
Deﬁning the Intervention Target
We can rephrase perfect and imperfect interventions under a single uniﬁed
framework through the concept of intervention target [31].
Deﬁnition 5.4 (Intervention Target). Let G be a causal graph. A subset I ⊂V
is said to be an intervention target if it contains all and only the variables
associated to an intervention over G.
Therefore, a single-variable intervention is an intervention target that con-
tains only one variable, while in a multi-variable intervention it contains more
than one. As a special case, when I = ∅the intervention target represents
the observational case. A set of multiple intervention targets {I0, I1, . . . , In} is
called an intervention family and it is denoted with the calligraphic letter I.
Deﬁnition 5.5 (Conservative Family). A family of targets I is conservative if
for each vertex X in V there exists at least one intervention target in I that
does not contain X:
∃I : X ̸∈I ∈I,
∀X ∈V
(5.4)
Essentially, a conservative family is a family that allows the existence of at
least one intervention target which does not intervene on an speciﬁc variable.
This property guarantees that there is at least one experiment in the family
which does not alter the behaviour of such variable if performed.
In this settings, a conservative family allows to observe the inﬂuence of a
(known) set of targets on at least one unaﬀected variable, enabling the possibility
of disentangling such eﬀect, especially when compared to the other experiments
in the whole family.
Deﬁnition 5.6 (Intervention Graph). Let G be a causal graph and I be an
intervention target deﬁned over G. The intervention graph G(I) = (V, E(I)) is
26

the causal graph obtained by removing any directed edge that points to a vertex
in I from G:
E(I) = {(X, Y ) | (X, Y ) ∈E ∧Y ̸∈I}
(5.5)
This deﬁnition of intervention graph is coherent with the intervened graph
resulting from a do-intervention [70], also known as graph surgery or graph
manipulation.
We can now formally express the interventional distribution associated to
an intervention graph.
Deﬁnition 5.7 (Interventional Distribution). Let G be a causal graph and I
be an intervention target. The interventional distribution P (I) can be expressed
using the factorization formula:
P (I) =
Y
Xi∈I
P (I) Xi|Pa(Xi)
 Y
Xi̸∈I
P (∅) Xi|Pa(Xi)

(5.6)
where P (∅) is the observational distribution of the variables which were not
included in the intervention target, if any.
In case of perfect interventions, the interventional distribution can also be
expressed using the do-notation:
P (I) =
Y
Xi∈I
P (I) Xi | do(I)
 Y
Xi̸∈I
P (∅) Xi|Pa(Xi)

(5.7)
Deﬁnition 5.8 (Interventional Equivalence). Let G and H be two causal graphs
and I be an intervention family. G and H are interventionally Markov equivalent
w.r.t. the family I (i.e. I-equivalent) if the associated intervention graphs G(I)
and H(I) have the same skeleton and the same v-structures for each intervention
target of the family:
G ≡I H =⇒G(I) ≡H(I),
∀I ∈I
(5.8)
In other terms, interventional equivalence can be decomposed in a set of
equivalence statements of intervention graphs, where each observational equiv-
alence statement is formulated against a single intervention target contained in
the given family.
Deﬁnition 5.9 (Interventional Equivalence Class). Two causal graphs G and H
belong to the same interventional Markov equivalence class w.r.t. the interven-
tion family I (I-MEC) [40, 45] if they are I-equivalent. As for the observational
setting, the I-MEC of a graph G, denoted by [G]I, represents the set of possible
causal graphs that are interventionally equivalent.
An intervention family I induces a classiﬁcation of the edges of an interven-
tion graphs depending on the eﬀect on the underlying interventional distribu-
tion.
27

Deﬁnition 5.10 (I-covered edge). An edge (X →Y ) in G is I-covered if:
Pa(X) = Pa(Y ) \ {X} ∧P ({X})(Y ) = P (∅)(Y )
when the intervention target {X} is in I.
Deﬁnition 5.11 (I-contradictory edge). An edge (X →Y ) in G is I-contradictory
if as least one of the following conditions holds:
• ∃S ⊂Ne(Y ) \ {X} such that ∀I ∈IX\Y we observe P (I)(Y | S) = P (∅)(Y | S),
or
• ∀S ⊂Ne(X) \ {Y } such that ∃I ∈IY \X we observe P (I)(X | S) ̸= P (∅)(X | S).
I-contradictory edges are particularly of interest since they diﬀers among
interventional equivalence classes, i.e.
they violate the I-Markov property,
highlighting the possibility for a consistent exploitation during the discovery
procedure.
5.4
Learning with Interventions
Sometimes researchers want to observe the eﬀect of an intervention on one single
variable at the time, but there are settings in which this is not possible or it
is inconvenient. Therefore, multi-variable interventions must be addressed as a
special case of a generic intervention target.
Single vs. Multi-Variable Interventions
When each intervention target
contains a single variable at the time, the number of experiments needed to
collect enough evidence to identify the causal graph is n−1, with n the number
of variables [23]. Indeed, if one intervention would enable the identiﬁcation of
the causal edges incoming into the only variable contained in the intervention
target, then the n-th intervention would be redundant.
In the case of intervention targets with more then one variable, only ⌊log(n)⌋+
1 interventions are necessary and suﬃcient in the worst case scenario [23], where
the causal graph is the complete graph. Since this worst case is improbable,
O(log log(n)) can be achieved as lower bound with high probability in the multi-
variable setting with a randomized intervention scheme [35], that is, it is possible
to plan the experimental design in advance to minimize the number of interven-
tions.
Unknown Intervention Targets
An other problem that one may face dur-
ing structural learning with interventional data is the uncertainty related to the
interventional targets. There are scenarios in which it is known that an inter-
vention has been performed, but it is unclear which is the exact set of variables
that has been aﬀected by such intervention. In this case, an additional layer of
complexity is added in order to properly handle the less informative setting of
unknown intervention targets.
28

5.5
Interventional Algorithms
Interventional GES (GIES)
By leveraging the similarity between obser-
vational causal graphs and their interventional counterparts, authors in [31]
proposed a generalization of the GES algorithm to the interventional setting.
This new score-based variant, called Greedy Interventional Equivalence Search
(GIES), follows the same two step approach of the original procedure, traversing
the search space using forward- and backward- phases, until a (local) maximum
score is reached.
A major contribution of this work is related to formalization of the inter-
ventional setting. Indeed, while the algorithm itself does not diﬀer signiﬁcantly
from the observational one in terms of overall design, the performance improve-
ments are relevant, as expected by transitioning from the ﬁrst to the second
layer of the causal hierarchy. This is an interesting example of how observa-
tional techniques can be adapted to the interventional setting with ease, once
the theoretical aspects of both the intervention distribution and the intervention
targets are addressed properly.
Interventional Greedy Permutation (IGSP)
While GIES focuses its at-
tention on perfect interventions, a ﬁrst extension to general interventions is pre-
sented in [112], with the Interventional Greedy Sparsest Permutations (IGSP),
an interventional variant of the GSP [97]. In this case, the greedy approach con-
sists in the optimization of a score function, coupled with a permutation-based
strategy that guides the traversal of the I-MECs space.
Formally, let ρ be a permutation of vertices of a causal graph G. The space
on which such permutation lays is a polytope called permutahedron. A possible
representation of this mathematical object is indeed another graph, where each
vertex corresponds to a permutation ρ and each edge between two permutations
encodes a transposition of the vertices. The goal of a permutation-base causal
discovery algorithm is to ﬁnd a permutation ρ∗, consistent with the topolog-
ical order of the true causal graph G∗, that optimizes a given score function.
The search procedure traverses the permutahedron using a depth-ﬁrst approach
starting from an initial permutation ρ. For each permutation τ visited, if Gτ
yields a better score than Gρ then ρ is set to τ. The traversal is restarted from
the updated ρ, until no such τ is found.
In order to leverage the advantages of the interventional data, IGSP limits
the vertices transposition to the neighbors that are connected by I-covered
edges, restricting the search space to permutations that are coherent with the
intervention targets. An other characteristic of this search strategy is given by
the prioritization of I-covered edges that are also I-contradictory, given that
they represent a transition of I-MEC, which could lead to an improvement of
the total score.
An extended version of this algorithm, named UT-IGSP, has been presented
in [103] in order to tackle the unknown target scenario. The main contribution
of this work is linked to the new deﬁnition of I-covered edges in light of partially
unknown intervention targets.
29

IGSP (and later UT-IGSP) has been compared to GIES under diﬀerent
conditions, showing that the former achieves better performances than the latter
when the dimensionality of the problem is limited (i.e. lower than 10 vertices).
This limit is coherent with others traversal-based approaches: although GIES is
not consistent in general, its score function is more eﬃcient in pooling together
the various interventional datasets when it comes to high-dimensionality spaces.
Joint Causal Inference with FCI (FCI-JCI)
Another formal approach,
similar to the one introduced in the previous subsection, is presented under
the name of Joint Causal Inference (JCI) [61]. This method aims to pool to-
gether multiple observations collected during diﬀerent experiments (i.e. con-
texts), hence, the name joint causal inference.
In this framework, the set of observed variables is split into two disjoint sets:
system variables X and context variables C. While the former set contains the
variables that have been observed during an experiment, the latter set describes
under which conditions such system has been observed, following the classical
distinction between endogenous and exogenous variables respectively.
Context variables can be used as intervention variables, even if this might not
always be the case: here the term is related to the notion of change of context,
which is a broader scope than simply intervene on the system. Doing so, it is
possible to obtain a more ﬂexible representation of the system of interest, where
external forces are represented as internal characteristics of a meta-system. This
approach relaxes the boundary between experiments performed under diﬀerent
conditions, allowing researchers to join data with a coherent causal description.
Before diving into JCI itself, there are a couple of assumptions that can be
(optionally) taken into consideration to understand the purpose of the entire
context framework:
0. The underlying mechanism that generates the data is represented by a
SCM M, where the observed variables are split in system variables and
context variables.
1. No system variable is cause of any context variable, i.e. exogeneity as-
sumption.
2. No system variable is confounded with any context variable, i.e. random-
ized context.
3. Let GC be the context graph induced by the context variables C over the
causal graph G associated with the SCM M. For each pair of context
variables (Ci, Cj) in the context graph the following holds true:
(Ci ↔Cj) ∈GC ∧(Ci →Cj) ̸∈GC
(5.9)
that is, no context variable is a direct cause of another context variable,
but there is a hidden confounder between each pair of context variables,
i.e. generic context.
30

While assumptions (0), (1) and (2) are usually considered mild in the interven-
tional setting, assumption (3) might need to be clariﬁed further: if the goal of
the causal discovery is to disentangle the causal relationships using the context
variables as guidance, rather than focusing on the connections of the context
graph, then assumption (3) can be enforced if (1) and (2) were also assumed.
This approach allows the algorithm to restrict the search space to the graphs
that satisfy this last assumption, speeding-up the learning process.
The generic JCI procedure can adapted to any observational causal discovery
algorithm by following four steps: (i) add the context variables, (ii) pool data
together by setting the values of the context variables, (iii) address faithfulness
violations between contexts, if any, (iv) execute the selected observational learn-
ing algorithm. Authors provide reference adaptations for multiple algorithms,
such as FCI.
The FCI-JCI variant is particularly of interest, provided that it inherits the
strength points of FCI in the causally insuﬃcient setting. Various combinations
of the three assumptions were tested, showing that FCI123 (i.e. all three as-
sumptions made) is less accurate in general, but signiﬁcantly faster than others
solutions, allowing its application in more complex scenarios with a sensible
number of variables.
Unknown Intervention Targets using Ψ-FCI
Authors in [40] adapted
both PC and FCI algorithms to the causal discovery setting under imperfect
interventions with unknown intervention targets. The fundamental contribution
of this work is the extension of the I-MEC to a more general Ψ-MEC that is
capable of representing intervention graphs with unknown intervention targets.
The key idea is that a pair of intervention targets I, J ∈I can be used
to identify a unique interventional mechanism that encompasses both targets.
Let G be a causal graph and I an intervention family.
The induced set of
interventional probability distributions P (I) = {P (I0), P (I1), . . . , P (In)} satisﬁes
the Ψ-Markov property if the following holds true for any disjoint subsets of
variables Y, Z and W:
1. Insertion and deletion of observations:
P (I)(Y | Z, W) = P (I)(Y | W)
(5.10)
if (Y ⊥⊥Z | W) holds true in G for all I ∈I,
2. Invariance of interventions:
P (I)(Y | W) = P (J)(Y | W)
(5.11)
if
 Y ⊥⊥K | (W \ WK)

holds true in GWKR(W) for all I, J ∈I, where
K is the symmetric diﬀerence of I and J, WK = W ∩K, R = K \ WK
and ﬁnally R(W) = R \ An(W) w.r.t. G.
While Equation 5.10 is essentially derived from observational Markov equiva-
lence, Equation 5.11 is related to the distributional invariances across pairs if
31

intervention targets w.r.t. the associated intervention graph. Indeed, if I and
J are the true intervention targets for P (I) and P (J), they must satisfy the in-
variance for the interventional distributions when separation holds in a given
intervention graph.
Moreover, the Ψ-Markov property does not require any assumption about
the experimental setting in which such interventions are performed. Speciﬁcally,
it could happen that a subset of experiments were not carried out exactly in the
same way, e.g. not in a controlled environment. Therefore, even if interventions
targets were known a priori, Ψ-Markov would still be more general than the
I-Markov property.
The authors then recast the augmented graph proposed by [11, 25], adding
a set of utility vertices that are analogous to the context vertices proposed by
[61]. Therefore, the output of the former can be compared to the latter using
the related augmented graph, showing that the accuracy of the edge orientations
recovered by their Ψ-FCI variant is superior then the one proposed by FCI-JCI.
backShift
Continuing in the unknown targets setting, the backShift [82] algo-
rithm is a causal discovery approach that recovers linear (possibly cyclical) mod-
els under causal insuﬃciency. It focuses on shift interventions with unknown
targets, a subset of imperfect interventions where the eﬀect of such perturbation
yields a ﬁxed shift of the intervened variable. Both the targets and the shift
value can be estimated from the data.
The key idea of this technique is to represent the the target SCM M as:
(I −B)x = c + e
(5.12)
where x is a random vector, B is the adjacency matrix of the casual graph asso-
ciated to M, e is the noise vector and c is the random shift vector that models
the shift intervention on the system. Then, a joint matrix diagonalization is ap-
plied to the diﬀerences between the covariance matrices ∆ΣΣΣ of each experiment
I ∈I:
eD = argmin
D′∈D
X
I∈I
L(D′∆ΣΣΣ(I)D′T )
(5.13)
where D = I −B, L is the sum-of-squared loss function and I the family of
targets.
This approach assumes that data represent observation at the equilibrium,
the D matrix is invertible and the cycle product [82] is strictly smaller than one.
Moreover, noises, interventions between variables and between experiments are
assumed to be uncorrelated.
Authors compare their solution to the LiNG observational alternative, taking
advantage of the interventional asymmetries arising from the additional infor-
mation contained in the data. The results show that backShift is capable of
dealing with both interventions and latent variables under mild assumptions,
outperforming LiNG in both observational and interventional setting. More-
over, the computational complexity is O(|I| · n2 · m), with n representing the
number of the variables and m representing the sample size, which allows its
application in high-dimensional settings.
32

bcause+
An extension of the bcause algorithm to interventional data, called
bcause+, is proposed in [78]. When multiple experimental datasets are avail-
able, the core-base estimation of the lower bound of each branch of the exact
search can be improved by taking into account the variables aﬀected by the
intervention.
In particular, the graphical separation statements checks by the observa-
tional variant (using either d-separation or σ-separation) are extended to con-
sider the constraints induced by an intervention target. By assuming the absence
of edges oriented into vertices that are part of an intervention target, the search
procedure can avoid to check for separation, e.g. in case of perfect interventions.
In this sense, intervention targets can be used to derive linear programming
constraints by considering the subsets of intervened variables that aﬀect the
separation statements.
The improved version of the previous algorithm is also evaluated on non-
linear cyclic causal models, showing its capability to deal with non-linear rela-
tionships. However, even with the added constraints, the exponentially-increasing
execution time prohibits its application in high-dimensional contexts, which is
a well known limitation for exact search methods.
Diﬀerentiable Causal Discovery with Interventions (DCDI)
Under
regularity assumption, authors in [13] propose a general diﬀerentiable causal
discovery algorithm that is capable of learning causal graphs from interven-
tional data with both perfect and imperfect interventional targets, even in the
case of unknown interventions.
The key idea of this algorithm is to maximize a score function deﬁned as
follows:
SI(G) = sup
φ
X
I∈I
EX log f (I)(X; B, R, φ) −λ|G|
(5.14)
where φ are the weights of the estimator used to maximize the score function
(i.e.
neural networks in this case), X follows the interventional distribution
P (I), f (I) is the interventional density function, B the binary adjacency matrix
of G, R the binary interventional matrix (i.e. Rij = 1 if Xi ∈Ij).
Essentially, the score function is built upon the conditional interventional
distribution to recover the invariant edges across interventions. In fact, vertices
that are not in any intervention target are characterized by a conditional prob-
ability distribution which is invariant across interventions, as for conservative
families of interventions. Relying on conditional invariance, the causal graph
ˆG = argmaxG∈G SI(G) is I-equivalent (Subsection 5.8) to the true graph G∗,
for λ > 0 small enough. In case of unknown intervention targets, an additional
−λR|I| regularization term is added to the score function.
The DCDI algorithm has been tested against IGSP and GIES with known
interventions and JCI-PC and UT-IGSP for unknown interventions, showing
marginal advantages in terms of structural recovery. As for others continuous
optimization methods [114], the major strength point is represented by its scal-
ability: it takes O(n3) to compute the matrix exponential during each training
33

step, making it the only causal discovery algorithm that supports non-linear
relationships in the interventional setting in a high-dimensional setting.
6
Evaluation and Tuning
This section tackles the evaluation and tuning step typical of any practical appli-
cation. A collection of reference data sets is listed, both real-world and synthetic
generated ones, serving as benchmarking resources for discovery methods. In
order to evaluate diﬀerent solutions resulting from a set of conﬁgurations (i.e.
hyperparameter) we report comparison metrics found in the specialized litera-
ture, both in terms of structure and entailed causal statements. Finally, tuning
strategies and software packages are explored as support for new developed
techniques.
6.1
Evaluation Datasets
Cause-Eﬀect Pairs (Tuebingen)
Ever-growing data set [62, 105] designed
to benchmark discovery algorithms against bi-variate settings with known ground
truth. The latest version reported by the change-log (December 20, 2017) in-
cludes 108 pairs. Each pair is composed by a data ﬁle with two columns (cause
and eﬀect respectively), a short description of the data sampling procedure, and
a 2D scatter plot.
Robotic Manipulation (CausalWorld)
Simulator [2] for causal structure
and transfer learning in a robotic manipulation environment. The environment
is a simulation of an open-source robotic platform capable of constructing 3D
shapes from a given set of blocks.
Single-Cell Flow Cytometry (Sachs)
Flow cytometry measurements [84]
of 11 proteins and phospholipids. The data set is split in diﬀerent experiments,
with nine stimulatory or inhibitory interventions.
The study compares new
learned model against ground truth obtained by reference literature on signaling
networks with intervention points.
Single-Cell RNA-Sequencing (Klein)
Single-cell RNA-sequencing (scRNA-
seq) data set [44] of ∼3000 mouse embryonic stem cells after leukemia inhibitory
factor (LIF) withdrawal. The ground truth model is obtained by querying the
TRRUST database [30] for the related causal relationships.
Single-Cell Gene Expression (Perturb-Seq)
Measurements of gene ex-
pression [21] composed by 992 observational and 13.435 interventional obser-
vations from eight close-to-perfect interventions, each corresponding to a gene
deletion using the CRISPR/Cas9 technique applied to bone marrow-derived
dendritic cells.
34

Dataset
Type
URL
Tuebingen [62]
Real-world
Here
CausalWorld [2]
Synthetic
Here
Sachs [84]
Real-world
Here
Klein [44]
Real-world
Here
Perturb-Seq [21]
Real-world
Here
SynTReN [110]
Synthetic
Here
DREAM4 [92]
Synthetic
Here
Table 4: Static datasets by type and availability.
Synthetic Gene Expression (SynTReN)
Network generator [110] that
creates synthetic transcriptional regulatory networks. The models are paired
with kinetics simulations in order to sample gene expression data that approxi-
mate observed experimental data.
Synthetic mRNA Expression (DREAM4)
The DREAM4 challenge [92]
provides ﬁve datasets simulated from ﬁve biologically plausible gene regulatory
networks with 10 genes [54]. Each dataset is composed by both observational
and interventional data sampled by applying small random noise perturbations,
single-gene knockdowns and single-gene knockouts, resulting in time series with
unknown interventions.
6.2
Evaluation Metrics
In the context of causal discovery, the deﬁnitions of true positive (TP), true
negative (TN), false positive (FP) and false negative (FN) have the same inter-
pretation of the metrics referred to a binary classiﬁer, which try to predict the
edge orientation.
Adjacency Precision (AP) & Recall (AR)
A ﬁrst set of evaluation met-
rics for graphical models is made of the adjacency precision (AP) and adjacency
recall (AR) [85]. These metrics are computed as the ratio between the number
of correctly predicted adjacent vertices over the total predicted ones for AP and
true predicted ones for AR. Formally, once the confusion matrix associated with
the presence of edges is computed, the two metrics are deﬁned as follows:
AP =
TP
TP + FP
(6.1)
AR =
TP
TP + FN
(6.2)
Arrowheads Precison (AHP) & Recall (AHR)
While metrics related to
adjacency can deliver insights on the general structure (i.e. skeleton) quality,
arrowheads metrics [6, 85] focus on highlighting inferred relationships perfor-
mance.
This class of metrics is particularly useful when there are multiple
arrowhead marks that encode diﬀerent causal statements, such as in PAGs.
35

Here, classical adjacency metrics fail to account for invariant marks that might
be interpreted as a head or a tail, overestimating the algorithm performance.
As for adjacency metrics, arrowheads precision (AHP) and recall (AHR) are
deﬁned as the ratio between correctly predicted arrowheads over total predicted
arrowheads, and correctly predicted arrowheads over true arrowheads:
AHP =
TP
TP + FP
(6.3)
AHR =
TP
TP + FN
(6.4)
where TP, FP and FN refer to the confusion matrix entries computed over the
predicted arrowheads, not only the presence/absence of an edge.
Structural Hamming Distance (SHD)
It measures the diﬀerences be-
tween two graphical models in terms of their edges. Formally, let G and H
be two graphs and E(G, U) the symmetric diﬀerence between the edge sets
E(G) and E(U), the SHD [109] counts the number of necessary operations to
transform G into H:
SHD(G, H) =
V2
X
(X,Y ), X<Y





1
(X, Y ) ∈E(G, U),
1
(Y, X) ∈E(U, G),
0
Otherwise.
(6.5)
where the allowed operations consist in addition, deletion and reversal of an
edge.
Structural Intervention Distance (SID)
It is a pre-metric deﬁned over
the interventional distributions. Formally, the SID [73] counts the number of
wrongly inferred interventional distributions. This measure relies on the notion
of adjustment set [96] and it is strongly related to the SHD.
6.3
Parameter Tuning
Strategies to perform parameter/s turning are rarely found in surveys, even
tough casual discovery algorithms may have multiple parameters that regu-
late the search procedure. Here, we report three general and ﬂexible practices
described in the specialized literature that can be applied to any technique
described so far.
Minimizing Model Complexity (BIC & AIC)
A ﬁrst approach for pa-
rameter/s tuning is related to model complexity. The goal is to ﬁnd the pa-
rameter/s conﬁguration that minimizes the complexity of the associated causal
graph. As a measure of complexity one can rely on the Bayesian Information
Criterion (BIC) [87] or the Akaike Information Criterion (AIC) [3]. This tuning
strategy is particularly eﬀective when coupled with score-based approaches that
are able to exploit the same function, allowing to reuse the intermediate scores
for a faster evaluation. The most general form of model complexity minimiza-
tion is implemented as a grid search over all parameters conﬁgurations for the
ranges.
36

Stability Approach to Regularization Selection (StARS)
The StARS
[52] approach is based on selecting the parameters conﬁguration that minimizes
the graph instability when small perturbations are applied to the data. The
instability of an edge is the probability of presence of said edge when the causal
graph is learned from a subsample of the data (without replacement). Hence,
the graph instability of a given parameters’ conﬁguration h is the average of
the edge instabilities computed w.r.t. h. In order to avoid conﬁgurations that
lead to trivial graphs, e.g. the empty graph or the complete graph, the authors
introduce a β parameter that acts as a threshold for the acceptable level of insta-
bility. In the end, this method measures the sensitivity of a speciﬁc parameters’
conﬁguration h as a function of the underlying data distribution.
Out-of-sample Causal Tuning (OCT & OCTs)
While previous approaches
focused on metrics related to the causal structure alone, authors in [10] propose
to employ the resulting model for its prediction capabilities, reducing the prob-
lem into an evaluation of a predictor. This approach works in a out-of-sample
fashion, hence the name Out-of-sample Causal Tuning (OCT). The main ad-
vantages of such method are (i) the lack of parametric assumptions about the
distribution of the data and (ii) the generalization to cases where the BIC and
AIC scores are not deﬁned, i.e. discrete models with hidden variables.
6.4
Software Packages
Stable and reliable implementations of discovery methods are fundamental to
achieve reproducibility of the experimental results. In the following paragraphs,
a list of notable tools is presented.
Causal Discovery Toolbox (CDT)
The Causal Discovery Toolbox [42] is
a Python front-end that acts as a bridge between diﬀerent subpackages, pooling
together multiple discovery algorithms. For example, one may ﬁnd constrained-
based algorithms such as PC, Max-Min Parents & Children (MMPC) [109],
score-based algorithms as GES and variants (GIES), and non linear approaches
as LiNGAM, Causal Additive Models (CAM) [14], and others.
bnlearn
The bnlearn [88] package is an R package developed for bayesian in-
ference and structural learning. While both PC and MMPC are implemented,
algorithms such as Incremental Association Markov Blanket (IAMB) [108] and
its variants are present too. Moreover, the underlying implementation is well
suited for large scale application due to the optimized support for parallel com-
puting [90].
pcalg
The pcalg [43] package is a R utility for causal discovery and causal in-
ference using graphical models. The algorithms provided here are PC and vari-
ants (CPC, PC Select), FCI and variants (RFCI [19], Anytime FCI [98], Adap-
tive Anytime FCI [19, 98], FCI-JCI), GES and variants (AGES [65], ARGES,
37

GIES) and LiNGAM. Given the wide variety of FCI-based algorithms and the
integrated tools for causal inference, this package is particularly well suited for
causal insuﬃcient settings.
TETRAD
While previous packages where intended for command line usage,
TETRAD [76] is a causal discovery package developed in Java with a graphical
user interface. It follows a pipeline paradigm, where the user can drag & drop
boxes from the side bar and connect them together to form data pipelines. The
user can choose from a wide range of options, such as PC (PCStable, CPC &
CPCStable [18], PCMax), FCI (RFCI, RFCI-BSC [39], GFCI), GES (FGES,
FGES-MB, IMaGES), LiNGAM, and others. Given the simplicity of interface,
it is well suited for researcher with limited programming experience.
7
Practical Applications
7.1
Causal Discovery in Economics
Emissions, Production and Energy Use
Authors in [1] explore the inter-
actions between growth in CO2 emissions, economic production and energy use,
both at the global and multi-regional levels over the period 1990–2014. In order
to recover the causal relationship between variables, a modiﬁed version of the
PC algorithm for time-series is used.
The output of the discovery step showed that CO2 emissions, energy and
economic activity are linked by a set of non-linear dependencies. At the global
level, this graph suggests that a too rapid transition to net-zero emissions in
the energy sector may hinder the global economic growth. When the regional
level is taken into account, it is shown that regions are fully integrated into the
system, which argues for coordinated policies across regions.
7.2
Causal Discovery in Medicine
Alzheimer’s Pathophysiology
Researchers in [93] employed data made avail-
able by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) coupled with
biological markers and clinical assessment to study the biological mechanism be-
hind the Alzheimer’s Disease. Two causal discovery algorithms (FCI and FGES)
were compared against the gold standard graph retrieved from literature.
The methods were executed both with and without trivial background knowl-
edge, e.g. patient’s age is not aﬀected by any biomarker. A signiﬁcant improve-
ment was observed with the addition of the knowledge base. Finally, longitu-
dinal data were included, discovering more edges and removing the incorrect
ones. The performance of the constraint-based was lower and less stable across
the bootstrap samples than the score-based one.
Unmet Treatments in Schizophrenia
Authors in [59] selected the GFCI
algorithm to identify the causes of functional outcomes of patients aﬀected by
38

schizophrenia during the critical window for early intervention. The algorithm
was applied to the Recovery After an Initial Schizophrenia Episode Early Treat-
ment Program (RAISE-ETP) trial at two time-points, i.e. baseline and after
6-months. Social and occupational functioning metrics were derived from the
Quality of Life Scale (QLS). The retrieved causal graph was used to build a
SCM in order to quantify the magnitude of the eﬀects.
The estimated eﬀects shed light over the interaction between both social
and occupational functioning with the socio-aﬀective capacity, which in turn
aﬀects the motivation of the subject. Moreover, an extended analysis of time
dependencies revealed several causal cycles over the 6-months time-frame.
7.3
Causal Discovery in Psychology
Alcohol Use and Anxiety Disorder
Psychopathology researchers in [7]
used graphical modeling algorithms to identify causal relationships within and
between manifestations of psychiatric disorders. In this context, such methods
are employed to identify symptoms that are part of a causal chain of “medi-
ators”. The main target of the study was to test whether drinking motivated
by the goal of reducing negative aﬀect (i.e. drinking to cope, DTC) served as a
mediator in comorbid alcohol use and anxiety disorder in a causally insuﬃcient
setting.
The resulting graph showed that the most important causal inﬂuence of
drinking was drinking craving, which was in turn inﬂuenced by DTC. However,
there was still a degree of ambiguity in the direction of depression’s associa-
tions with social anxiety and stress, suggesting the possible presence of latent
variables.
8
Conclusions and Discussion
8.1
A Brief Summary
Causal inference depends heavily on the construction of a reference model that
crystallizes the acquired knowledge. To meet such requirement, causal discovery
provides a set of methods that are able to recover a graphical description of the
underlying mechanism, exploiting both collected data and prior knowledge. In
this work, we presented a list of algorithms, evaluation criteria and software
tools, trying to cover a wide range of theoretical and practical scenarios in a
coherent and uniﬁed manner. Moreover, we compared these resources against
challenging problems, such as the presence of unobserved variables, cyclical
dependencies, non-linear relationships and unknown interventions, highlighting
the strengths and weaknesses of each solution. Finally, we reported a set of
parameters tuning strategies and publicly available data sets to explore properly
the described techniques and to test new ones.
39

8.2
Future Directions
In terms of opportunities for future extensions, in this contribution we did not
explore the implications of applying such method to time series, which would
add an additional layer of complexity. Indeed, the representation of the causal
dependencies in time are diﬀerent from the one expressed in a static scenario
and deserves a separated discussion on its own, especially when combined with
the other topics introduced during the discussion.
Funding
Alessio Zanga was granted a Ph.D. scholarship by F. Hoﬀmann-La Roche Ltd.
References
[1] Peter Martey Addo, Christelle Manibialoa, and Florent McIsaac.
Exploring
nonlinearity on the co2 emissions, economic production and energy use nexus:
A causal discovery approach. Energy Reports, 7:6196–6204, 2021.
[2] Ossama Ahmed, Frederik Tr¨auble, Anirudh Goyal, Alexander Neitz, Yoshua
Bengio, Bernhard Sch¨olkopf, Manuel W¨uthrich, and Stefan Bauer. Causalworld:
A robotic manipulation benchmark for causal structure and transfer learning,
2020.
[3] H. Akaike. A new look at the statistical model identiﬁcation. IEEE Transactions
on Automatic Control, 19(6):716–723, 1974.
[4] Juan I Alonso-Barba, Jose A G´amez, Jose M Puerta, et al. Scaling up the greedy
equivalence search algorithm by constraining the search space of equivalence
classes. International journal of approximate reasoning, 54(4):429–451, 2013.
[5] Steen A Andersson, David Madigan, and Michael D Perlman. A characterization
of markov equivalence classes for acyclic digraphs.
The Annals of Statistics,
25(2):505–541, 1997.
[6] Bryan Andrews, Joseph Ramsey, and Gregory F Cooper.
Learning high-
dimensional directed acyclic graphs with mixed data-types. In The 2019 ACM
SIGKDD Workshop on Causal Discovery, pages 4–21. PMLR, 2019.
[7] Justin J. Anker, Erich Kummerfeld, Alexander Rix, Scott J. Burwell, and
Matt G. Kushner. Causal network modeling of the determinants of drinking
behavior in comorbid alcohol use and anxiety disorder. Alcoholism: Clinical and
Experimental Research, 43(1):91–97, 2019.
[8] Elias Bareinboim, Juan David Correa, Duligur Ibeling, and Thomas F. Icard.
On pearl’s hierarchy and the foundations of causal inference. 2021.
[9] William D Berry. Nonrecursive causal models. Number 37. Sage, 1984.
[10] Konstantina V Biza, I. Tsamardinos, and Soﬁa Triantaﬁllou.
Tuning causal
discovery algorithms. In PGM, 2020.
[11] Stephan Bongers, Patrick Forr´e, Jonas Peters, and Joris M. Mooij. Foundations
of structural causal models with cycles and latent variables, 2021.
40

[12] Stephan Bongers and Joris M. Mooij. From random diﬀerential equations to
structural causal models: the stochastic case, 2018.
[13] Philippe Brouillard, S´ebastien Lachapelle, Alexandre Lacoste, Simon Lacoste-
Julien, and Alexandre Drouin.
Diﬀerentiable causal discovery from interven-
tional data, 2020.
[14] Peter B¨uhlmann, Jonas Peters, and Jan Ernest. Cam: Causal additive models,
high-dimensional order search and penalized regression. The Annals of Statistics,
42(6):2526–2556, 2014.
[15] Ruichu Cai, Jie Qiao, Kun Zhang, Zhenjie Zhang, and Zhifeng Hao.
Causal
discovery from discrete data using hidden compact representation. Advances in
neural information processing systems, 2018:2666, 2018.
[16] Enrique Castillo, Jose M Gutierrez, and Ali S Hadi. Expert systems and proba-
bilistic network models. Springer Science & Business Media, 2012.
[17] David Maxwell Chickering. Optimal structure identiﬁcation with greedy search.
Journal of machine learning research, 3(Nov):507–554, 2002.
[18] Diego Colombo and Marloes H. Maathuis. Order-independent constraint-based
causal structure learning, 2013.
[19] Diego Colombo, Marloes H. Maathuis, Markus Kalisch, and Thomas S. Richard-
son. Learning high-dimensional directed acyclic graphs with latent and selection
variables. The Annals of Statistics, 40(1), Feb 2012.
[20] Pierre Comon. Independent component analysis, a new concept?
Signal pro-
cessing, 36(3):287–314, 1994.
[21] Atray Dixit, Oren Parnas, Biyu Li, Jenny Chen, Charles P Fulco, Livnat Jerby-
Arnon, Nemanja D Marjanovic, Danielle Dionne, Tyler Burks, Raktima Ray-
chowdhury, et al. Perturb-seq: dissecting molecular circuits with scalable single-
cell rna proﬁling of pooled genetic screens. cell, 167(7):1853–1866, 2016.
[22] Mathias Drton and Thomas S Richardson. Iterative conditional ﬁtting for gaus-
sian ancestral graph models. arXiv preprint arXiv:1207.4118, 2012.
[23] Frederick Eberhardt, Clark Glymour, and Richard Scheines. On the number
of experiments suﬃcient and in the worst case necessary to identify all causal
relations among n variables, 2012.
[24] Patrick Forr´e and Joris M Mooij. Constraint-based causal discovery for non-
linear structural causal models with cycles and latent confounders.
arXiv
preprint arXiv:1807.03024, 2018.
[25] Patrick Forr´e and Joris M. Mooij. Markov properties for graphical models with
cycles and latent variables, 2017.
[26] Dan Geiger and David Heckerman. Learning gaussian networks. In Uncertainty
Proceedings 1994, pages 235–243. Elsevier, 1994.
[27] Clark Glymour, Kun Zhang, and Peter Spirtes.
Review of causal discovery
methods based on graphical models. Frontiers in genetics, 10:524, 2019.
[28] Madelyn Glymour, Judea Pearl, and Nicholas P Jewell.
Causal inference in
statistics: A primer. John Wiley & Sons, 2016.
[29] Ruocheng Guo, Lu Cheng, Jundong Li, P. Richard Hahn, and Huan Liu. A
survey of learning causality with data: Problems and methods. ACM Computing
Surveys, 53(4):1–37, Jul 2021.
41

[30] Heonjong Han, Jae-Won Cho, Sangyoung Lee, Ayoung Yun, Hyojin Kim, Da-
som Bae, Sunmo Yang, Chan Yeong Kim, Muyoung Lee, Eunbeen Kim, et al.
Trrust v2: an expanded reference database of human and mouse transcriptional
regulatory interactions. Nucleic acids research, 46(D1):D380–D386, 2018.
[31] Alain Hauser and Peter B¨uhlmann.
Characterization and greedy learning of
interventional markov equivalence classes of directed acyclic graphs. The Journal
of Machine Learning Research, 13(1):2409–2464, 2012.
[32] MA Hern´an and JM Robins. Causal Inference: What If. Boca Raton: Chapman
& Hall/CRC, 2020.
[33] Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal
of Computational and Graphical Statistics, 20(1):217–240, 2011.
[34] Patrik O. Hoyer, Shohei Shimizu, and Antti J. Kerminen. Estimation of linear,
non-gaussian causal models in the presence of confounding latent variables, 2006.
[35] Huining Hu, Zhentao Li, and Adrian R Vetta. Randomized experimental design
for causal graph discovery. Advances in neural information processing systems,
27, 2014.
[36] Antti Hyttinen, Frederick Eberhardt, and Matti J¨arvisalo.
Constraint-based
causal discovery: Conﬂict resolution with answer set programming.
In UAI,
pages 340–349, 2014.
[37] Antti Hyttinen, Paul Saikko, Matti J¨arvisalo, et al. A core-guided approach to
learning optimal causal graphs. In Proceedings of the 26th International Joint
Conference on Artiﬁcial Intelligence (IJCAI 2017). International Joint Confer-
ences on Artiﬁcial Intelligence, 2017.
[38] Guido W Imbens. Nonparametric estimation of average treatment eﬀects under
exogeneity: A review. Review of Economics and statistics, 86(1):4–29, 2004.
[39] Fattaneh Jabbari, Joseph Ramsey, Peter Spirtes, and Gregory Cooper. Discov-
ery of causal models that contain latent variables through bayesian scoring of
independence constraints. In Joint European Conference on Machine Learning
and Knowledge Discovery in Databases, pages 142–157. Springer, 2017.
[40] Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim.
Causal discovery from soft interventions with unknown targets: Characterization
and learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin,
editors, Advances in Neural Information Processing Systems, volume 33, pages
9551–9561. Curran Associates, Inc., 2020.
[41] Dominik Janzing and Bernhard Sch¨olkopf. Causal inference using the algorith-
mic markov condition. IEEE Transactions on Information Theory, 56(10):5168–
5194, 2010.
[42] Diviyan Kalainathan and Olivier Goudet. Causal discovery toolbox: Uncover
causal relationships in python, 2019.
[43] Markus Kalisch, Martin M¨achler, Diego Colombo, Marloes H. Maathuis, and
Peter B¨uhlmann. Causal inference using graphical models with the R package
pcalg. Journal of Statistical Software, 47(11):1–26, 2012.
[44] Allon M Klein, Linas Mazutis, Ilke Akartuna, Naren Tallapragada, Adrian Veres,
Victor Li, Leonid Peshkin, David A Weitz, and Marc W Kirschner. Droplet
barcoding for single-cell transcriptomics applied to embryonic stem cells. Cell,
161(5):1187–1201, 2015.
42

[45] Murat Kocaoglu, Amin Jaber, Karthikeyan Shanmugam, and Elias Bareinboim.
Characterization and learning of causal graphs with latent variables from soft
interventions. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc,
E. Fox, and R. Garnett, editors, Advances in Neural Information Processing
Systems, volume 32. Curran Associates, Inc., 2019.
[46] Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimen-
tal design for learning causal graphs with latent variables. In Nips, 2017.
[47] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and
techniques. MIT press, 2009.
[48] Gustavo Lacerda, Peter L Spirtes, Joseph Ramsey, and Patrik O Hoyer. Discov-
ering cyclic causal models by independent components analysis. arXiv preprint
arXiv:1206.3273, 2012.
[49] Thuc Duy Le, Tao Hoang, Jiuyong Li, Lin Liu, Huawen Liu, and Shu Hu.
A fast pc algorithm for high dimensional causal discovery with multi-core
pcs. IEEE/ACM Transactions on Computational Biology and Bioinformatics,
16(5):1483–1495, Sep 2019.
[50] Sanghack Lee, Juan D Correa, and Elias Bareinboim. Generalized transporta-
bility: Synthesis of experiments from heterogeneous domains. In Proceedings of
the 34th AAAI Conference on Artiﬁcial Intelligence, 2020.
[51] Chun Li and Xiaodan Fan. On nonparametric conditional independence tests for
continuous variables. Wiley Interdisciplinary Reviews: Computational Statistics,
12(3):e1489, 2020.
[52] Han Liu, Kathryn Roeder, and Larry Wasserman. Stability approach to regu-
larization selection (stars) for high dimensional graphical models, 2010.
[53] Sara Magliacane, Tom Claassen, and Joris M. Mooij. Ancestral causal inference,
2017.
[54] Daniel Marbach, Thomas Schaﬀter, Claudio Mattiussi, and Dario Floreano. Gen-
erating realistic in silico gene networks for performance assessment of reverse
engineering methods. Journal of computational biology, 16(2):229–239, 2009.
[55] Florian Markowetz, Steﬀen Grossmann, and Rainer Spang. Probabilistic soft
interventions in conditional gaussian networks. In Robert G. Cowell and Zoubin
Ghahramani, editors, Proceedings of the Tenth International Workshop on Arti-
ﬁcial Intelligence and Statistics, volume R5 of Proceedings of Machine Learning
Research, pages 214–221. PMLR, 06–08 Jan 2005. Reissued by PMLR on 30
March 2021.
[56] Adam Massmann, Pierre Gentine, and Jakob Runge. Causal inference for process
understanding in earth sciences. arXiv preprint arXiv:2105.00912, 2021.
[57] Christopher Meek. Graphical Models: Selecting causal and statistical models.
PhD thesis, PhD thesis, Carnegie Mellon University, 1997.
[58] Christopher Meek. Causal inference and causal explanation with background
knowledge. arXiv preprint arXiv:1302.4972, 2013.
[59] Kathleen Miley, Piper Meyer-Kalos, Sisi Ma, David J. Bond, Erich Kummerfeld,
and Sophia Vinogradov. Causal pathways to social and occupational function-
ing in the ﬁrst episode of schizophrenia: uncovering unmet treatment needs.
Psychological Medicine, page 1–9, 2021.
43

[60] Joris M Mooij and Tom Claassen. Constraint-based causal discovery using par-
tial ancestral graphs in the presence of cycles. In Conference on Uncertainty in
Artiﬁcial Intelligence, pages 1159–1168. PMLR, 2020.
[61] Joris M. Mooij, Sara Magliacane, and Tom Claassen. Joint causal inference from
multiple contexts, 2020.
[62] Joris M Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard
Sch¨olkopf. Distinguishing cause from eﬀect using observational data: methods
and benchmarks. The Journal of Machine Learning Research, 17(1):1103–1204,
2016.
[63] Raha Moraﬀah, Paras Sheth, Mansooreh Karami, Anchit Bhattacharya, Qianru
Wang, Anique Tahir, Adrienne Raglin, and Huan Liu. Causal inference for time
series analysis: Problems, methods and evaluation. Knowledge and Information
Systems, pages 1–45, 2021.
[64] Mario Nagase and Yutaka Kano. Identiﬁability of nonrecursive structural equa-
tion models. Statistics & Probability Letters, 122:109–117, 2017.
[65] Preetam Nandy, Alain Hauser, and Marloes H. Maathuis.
High-dimensional
consistency in score-based and hybrid structure learning, 2018.
[66] Ana Rita Nogueira, Jo˜ao Gama, and Carlos Abreu Ferreira. Causal discovery in
machine learning: Theories and applications. Journal of Dynamics & Games,
8(3):203, 2021.
[67] Ana Rita Nogueira, Andrea Pugnana, Salvatore Ruggieri, Dino Pedreschi, and
Jo˜ao Gama. Methods and tools for causal discovery and causal inference. Wiley
Interdisciplinary Reviews: Data Mining and Knowledge Discovery, page e1449,
2022.
[68] Cross-Disorder Group of the Psychiatric Genomics Consortium et al. Identi-
ﬁcation of risk loci with shared eﬀects on ﬁve major psychiatric disorders: a
genome-wide analysis. The Lancet, 381(9875):1371–1379, 2013.
[69] Juan Miguel Ogarrio, Peter Spirtes, and Joe Ramsey. A hybrid causal search
algorithm for latent variable models. In Conference on Probabilistic Graphical
Models, pages 368–379. PMLR, 2016.
[70] Judea Pearl. Causal diagrams for empirical research. Biometrika, 82(4):669–688,
1995.
[71] Judea Pearl. Theoretical impediments to machine learning with seven sparks
from the causal revolution. arXiv preprint arXiv:1801.04016, 2018.
[72] Judea Pearl and Dana Mackenzie. The Book of Why: The New Science of Cause
and Eﬀect. Basic Books, Inc., USA, 1st edition, 2018.
[73] Jonas Peters and Peter B¨uhlmann. Structural intervention distance for evaluat-
ing causal graphs. Neural computation, 27(3):771–799, 2015.
[74] Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Elements of causal
inference: foundations and learning algorithms. The MIT Press, 2017.
[75] Joseph Ramsey, Madelyn Glymour, Ruben Sanchez-Romero, and Clark Gly-
mour. A million variables and more: the fast greedy equivalence search algo-
rithm for learning high-dimensional graphical causal models, with an application
to functional magnetic resonance images. International journal of data science
and analytics, 3(2):121–129, 2017.
44

[76] Joseph D Ramsey, Kun Zhang, Madelyn Glymour, Ruben Sanchez Romero,
Biwei Huang, Imme Ebert-Uphoﬀ, Savini Samarasinghe, Elizabeth A Barnes,
and Clark Glymour. Tetrad—a toolbox for causal discovery. In 8th International
Workshop on Climate Informatics, 2018.
[77] Kari Rantanen, Antti Hyttinen, and Matti J¨arvisalo. Discovering causal graphs
with cycles and latent confounders: An exact branch-and-bound approach. In-
ternational Journal of Approximate Reasoning, 117:29–49, 2020.
[78] Kari Rantanen, Antti Hyttinen, and Matti J¨arvisalo. Learning optimal cyclic
causal graphs from interventional data. In International Conference on Proba-
bilistic Graphical Models, pages 365–376. PMLR, 2020.
[79] Thomas Richardson and Peter Spirtes. Ancestral graph markov models. The
Annals of Statistics, 30(4):962–1030, 2002.
[80] Thomas S Richardson. A discovery algorithm for directed cyclic graphs. arXiv
preprint arXiv:1302.3599, 2013.
[81] Jorma Rissanen. Modeling by shortest data description. Automatica, 14(5):465–
471, 1978.
[82] Dominik Rothenh¨ausler, Christina Heinze, Jonas Peters, and Nicolai Mein-
shausen.
Backshift: Learning causal cyclic graphs from unknown shift inter-
ventions. arXiv preprint arXiv:1506.02494, 2015.
[83] Paul K. Rubenstein, Stephan Bongers, Bernhard Schoelkopf, and Joris M. Mooij.
From deterministic odes to dynamic structural causal models, 2018.
[84] Karen Sachs, Omar Perez, Dana Pe’er, Douglas A Lauﬀenburger, and Garry P
Nolan. Causal protein-signaling networks derived from multiparameter single-
cell data. Science, 308(5721):523–529, 2005.
[85] Richard Scheines and Joseph Ramsey. Measurement error and causal discovery.
In CEUR workshop proceedings, volume 1792, page 1. NIH Public Access, 2016.
[86] Bernhard Sch¨olkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal
Kalchbrenner, Anirudh Goyal, and Yoshua Bengio. Toward causal representation
learning. Proceedings of the IEEE, 109(5):612–634, 2021.
[87] Gideon Schwarz. Estimating the dimension of a model. The annals of statistics,
pages 461–464, 1978.
[88] Marco Scutari. Learning bayesian networks with the bnlearn R package. Journal
of Statistical Software, 35(3):1–22, 2010.
[89] Marco Scutari.
An empirical-bayes score for discrete bayesian networks.
In
Conference on probabilistic graphical models, pages 438–448. PMLR, 2016.
[90] Marco Scutari. Bayesian network constraint-based structure learning algorithms:
Parallel and optimized implementations in the bnlearn R package. Journal of
Statistical Software, 77(2):1–20, 2017.
[91] Amirhossein Shahbazinia, Saber Salehkaleybar, and Matin Hashemi.
Par-
alingam: Parallel causal structure learning for linear non-gaussian acyclic mod-
els. arXiv preprint arXiv:2109.13993, 2021.
[92] Paul Shannon. Dream4: Synthetic expression data for gene regulatory network
inference from the 2009 dream4 challenge, 2021. R package version 1.30.0.
45

[93] Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon.
Challenges
and opportunities with causal discovery algorithms: application to alzheimer’s
pathophysiology. Scientiﬁc reports, 10(1):1–12, 2020.
[94] Shohei Shimizu. Lingam: Non-gaussian methods for estimating causal struc-
tures. Behaviormetrika, 41(1):65–98, 2014.
[95] Shohei Shimizu and Patrick Bl¨obaum.
Recent Advances in Semi-Parametric
Methods for Causal Discovery, chapter 5, pages 111–130. 2020.
[96] Ilya Shpitser and Judea Pearl. Complete identiﬁcation methods for the causal
hierarchy. Journal of Machine Learning Research, 9(9), 2008.
[97] Liam Solus, Yuhao Wang, and Caroline Uhler. Consistency guarantees for greedy
permutation-based causal inference algorithms, 2021.
[98] Peter Spirtes. An anytime algorithm for causal inference. In International Work-
shop on Artiﬁcial Intelligence and Statistics, pages 278–285. PMLR, 2001.
[99] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Cau-
sation, prediction, and search. MIT press, 2000.
[100] Peter Spirtes and Kun Zhang. Causal discovery and inference: concepts and
recent methodological advances. In Applied informatics, volume 3, pages 1–28.
SpringerOpen, 2016.
[101] Peter L. Spirtes. Directed cyclic graphical representations of feedback models,
2013.
[102] Peter L. Spirtes, Christopher Meek, and Thomas S. Richardson. Causal inference
in the presence of latent variables and selection bias. 2013.
[103] Chandler Squires, Yuhao Wang, and Caroline Uhler. Permutation-based causal
structure learning with unknown intervention targets, 2020.
[104] Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M Mooij, and Bernhard
Sch¨olkopf. Probabilistic latent variable models for distinguishing between cause
and eﬀect. Advances in neural information processing systems, 23:1687–1695,
2010.
[105] Natasa Tagasovska, Val´erie Chavez-Demoulin, and Thibault Vatter. Distinguish-
ing cause from eﬀect using quantiles: Bivariate quantile causal discovery. In
International Conference on Machine Learning, pages 9311–9323. PMLR, 2020.
[106] Jin Tian and Judea Pearl. Causal discovery from changes, 2013.
[107] Michail Tsagris, Giorgos Borboudakis, Vincenzo Lagani, and Ioannis Tsamardi-
nos. Constraint-based causal discovery with mixed data. International journal
of data science and analytics, 6(1):19–30, 2018.
[108] Ioannis Tsamardinos, Constantin F Aliferis, Alexander R Statnikov, and Er Stat-
nikov. Algorithms for large scale markov blanket discovery. In FLAIRS confer-
ence, volume 2, pages 376–380. St. Augustine, FL, 2003.
[109] Ioannis Tsamardinos, Laura E Brown, and Constantin F Aliferis. The max-min
hill-climbing bayesian network structure learning algorithm. Machine learning,
65(1):31–78, 2006.
[110] Tim Van den Bulcke, Koenraad Van Leemput, Bart Naudts, Piet van Remortel,
Hongwu Ma, Alain Verschoren, Bart De Moor, and Kathleen Marchal. Syntren:
a generator of synthetic gene expression data for design and analysis of structure
learning algorithms. BMC bioinformatics, 7(1):1–12, 2006.
46

[111] Thomas Verma, Judea Pearl, et al. Equivalence and synthesis of causal models.
1991.
[112] Karren Yang, Abigail Katcoﬀ, and Caroline Uhler. Characterizing and learning
equivalence classes of causal dags under interventions. In International Confer-
ence on Machine Learning, pages 5541–5550. PMLR, 2018.
[113] Jiji Zhang. On the completeness of orientation rules for causal discovery in the
presence of latent confounders and selection bias. Artiﬁcial Intelligence, 172(16-
17):1873–1896, 2008.
[114] Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric P Xing.
Dags
with no tears: Continuous optimization for structure learning. arXiv preprint
arXiv:1803.01422, 2018.
47

