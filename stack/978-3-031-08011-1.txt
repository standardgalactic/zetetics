Pierre Schaus (Ed.)
LNCS 13292
Integration of Constraint Programming, 
Artificial Intelligence, 
and Operations Research
19th International Conference, CPAIOR 2022
Los Angeles, CA, USA, June 20–23, 2022
Proceedings

Lecture Notes in Computer Science
13292
Founding Editors
Gerhard Goos
Karlsruhe Institute of Technology, Karlsruhe, Germany
Juris Hartmanis
Cornell University, Ithaca, NY, USA
Editorial Board Members
Elisa Bertino
Purdue University, West Lafayette, IN, USA
Wen Gao
Peking University, Beijing, China
Bernhard Steffen
TU Dortmund University, Dortmund, Germany
Moti Yung
Columbia University, New York, NY, USA

More information about this series at https://link.springer.com/bookseries/558

Pierre Schaus (Ed.)
Integration of Constraint Programming,
Artiﬁcial Intelligence,
and Operations Research
19th International Conference, CPAIOR 2022
Los Angeles, CA, USA, June 20–23, 2022
Proceedings

Editor
Pierre Schaus
UCLouvain
Louvain-la-Neuve, Belgium
ISSN 0302-9743
ISSN 1611-3349 (electronic)
Lecture Notes in Computer Science
ISBN 978-3-031-08010-4
ISBN 978-3-031-08011-1 (eBook)
https://doi.org/10.1007/978-3-031-08011-1
© Springer Nature Switzerland AG 2022
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, expressed or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
This volume contains the papers that were presented at the 19th International Conference
on the Integration of Constraint Programming, Artiﬁcial Intelligence, and Operations
Research (CPAIOR 2022), held in Los Angeles, USA, as a hybrid physical/virtual
conference.
The conference received a total of 73 submissions, including 60 regular papers and
13 extended abstract submissions. The regular papers reﬂect original unpublished work,
whereas the extended abstracts contain either original unpublished work or a summary
of work that was published elsewhere. Each regular paper was reviewed by at least three
Program Committee members. The reviewing phase was followed by an author response
period and a general discussion by the Program Committee. The extended abstracts were
reviewed for appropriateness for the conference. At the end of the review period, 28
regular papers were accepted for presentation during the conference and publication in
this volume, and 13 abstracts were accepted for a short presentation at the conference.
In addition to the regular papers and extended abstracts, three invited talks, whose
abstracts can be found in this volume, were given by André Cire (University of Toronto,
Canada), Carla Gomez (Cornell University, USA), and Vinod Nair (Deepmind, UK).
The conference program included a Master Class on the topic “Bridging the Gap
between Machine Learning and Optimization”, organized by Adam Elmachtoub and
Elias Khalil, with invited talks by Brandon Amos (Facebook AI Research, USA),
Priya Donti (Carnegie Mellon University, USA), Paul Grigas (University of California,
Berkeley, USA), Tias Guns (KU Leuven, Belgium), Bryan Wilder (Carnegie Mellon
University and Harvard University, USA), Angela Zhou (University of California,
Berkeley, and University of Southern California, USA). Of the regular papers accepted
to the conference, a committee - comprising of myself and Mark Wallace (Monash
University, Australia) - selected for the Best Paper Award the paper “Shattering
Inequalities for Learning Optimal Decision Trees” by Justin Boutilier, Carla Michini,
and Zachary Zhou and selected for the Best Student Paper Award the paper “A
MinCumulative Resource Constraint” by Yanick Ouellet and Claude-Guy Quimper.
We acknowledge the main local organizers Bistra Dilkina, Sven Koening, and Pheve
Vayanos (University of Southern California, USA).
We also acknowledge the generous support of our sponsors including, at the time of
writing, the USC Daniel J. Epstein Department of Industrial and Systems Engineering,
the USC Epstein Institute, the USC-Meta Center for Research and Education in AI and
Learning, Gurobi, Google, Nextmv, Kinaxis, The Optimization Firm, Lindo, Cosling,
and Springer.
April 2022
Pierre Schaus

Organization
General Chairs
Bistra Dilkina
University of Southern California, USA
Sven Koenig
University of Southern California, USA
Phebe Vayanos
University of Southern California, USA
Program Chair
Pierre Schaus
UCLouvain, Belgium
DEI Chair
Phebe Vayanos
University of Southern California, USA
Master Class Chairs
Adam Elmachtoub
Columbia University, USA
Elias Khalil
University of Toronto, Canada
Sponsorship Chair
Thiago Serra
Bucknell University, USA
Program Committee
Beste Basciftci
University of Iowa, USA
Chris Beck
University of Toronto, Canada
Nicolas Beldiceanu
LS2N, IMT Atlantique, France
David Bergman
University of Connecticut, USA
Armin Biere
Albert-Ludwigs-Universität Freiburg, Germany
Quentin Cappart
Ecole Polytechnique de Montréal
Carlos Cardonha
University of Connecticut, USA
Mats Carlsson
RISE, Sweden
Andre Augusto Cire
University of Toronto, Canada
Simon de Givry
MIAT INRAE, France
Emir Demirovi´c
Delft University of Technology, The Netherlands
Guillaume Derval
Université de Liège, Belgium
Pierre Flener
Uppsala University, Sweden

viii
Organization
Tias Guns
Vrije Universiteit Brussel, Belgium
Emmanuel Hebrard
LAAS-CNRS, France
John Hooker
Carnegie Mellon University, USA
Serdar Kadioglu
Brown University, USA
Roger Kameugne
University of Maroua, Cameroon
George Katsirelos
MIA Paris, INRAE, AgroParisTech, France
Joris Kinable
Amazon, USA
Zeynep Kiziltan
University of Bologna, Italy
Christophe Lecoutre
CRIL, Université d’Artois, France
Jiaoyang Li
University of Southern California, USA
Andrea Lodi
Cornell Tech, USA
Michele Lombardi
DISI, University of Bologna, Italy
Pierre Lopez
LAAS-CNRS, Université de Toulouse, France
Arnaud Malapert
Université Côte d’Azur, CNRS, I3S, France
Ciaran McCreesh
University of Glasgow, UK
Laurent Michel
University of Connecticut, USA
Nysret Musliu
TU Wien, Austria
Margaux Nattaf
G-SCOP, Grenoble INP, France
Barry O’Sullivan
University College Cork, Ireland
Marie Pelleau
Université Côte d’Azur, CNRS, I3S, France
Laurent Perron
Google, France
Gilles Pesant
Polytechnique Montréal, Canada
Claude-Guy Quimper
Laval University, Canada
Jean-Charles Regin
University Nice-Sophia Antipolis CNRS, I3S,
France
Andrea Rendl
Satalia, Austria
Louis-Martin Rousseau
CIRRELT, Canada
Elina Rönnberg
Linköping University, Sweden
Domenico Salvagnin
University of Padua, Italy
Pierre Schaus
UCLouvain, Belgium
Thomas Schiex
INRAE, France
Paul Shaw
IBM, France
Mohamed Siala
INSA Toulouse and LAAS-CNRS, France
Helmut Simonis
University College Cork, Ireland
Christine Solnon
INSA Lyon, France
Willem-Jan Van Hoeve
Carnegie Mellon University, USA
Hélène Verhaeghe
Polytechnique Montréal, Canada
Petr Vilím
CoEnzyme, Czech Republic
Mark Wallace
Monash University, Australia
Roland Yap
National University of Singapore, Singapore

Organization
ix
Additional Reviewers
Matteo Cacciola
Polytechnique Montréal, Canada
Shao-Hung Chan
University of Southern California, USA
JingkaiChen
Massachusetts Institute of Technology, USA
Timothy Curry
University of Connecticut, USA
Julien Ferry
LAAS-CNRS, France
Emilio Gamba
Vrije Universiteit Brussel, Belgium
Tobias Geibinger
TU Wien, Austria
Yong Lai
Massachusetts Institute of Technology, USA
Jayanta Mandi
Vrije Universiteit Brussel, Belgium
Florian Mischek
TU Wien, Austria
Pierre Montalbano
MIAT INRAE, France
Maxime Mulamba
Vrije Universiteit Brussel, Belgium
Magnus Rattfeldt
Tomologic, Sweden
Philippe Refalo
IBM, France

Abstract of Keynote Speakers

Decision Diagrams for Deterministic and Stochastic
Optimization
Andre A. Cire
University of Toronto, Canada
andre.cire@Rotman.utoronto.ca
Abstract. In this talk we will discuss alternative solution techniques for
discrete and stochastic optimization based on decision diagrams (DDs).
A DD, in our context, is a graph-based extended formulation of an
optimization problem that exposes network structure, leading to novel
bounding and branching mechanisms that complement classical model-
based approaches. We will investigate the principles of DD modeling for
combinatorial problems and develop the intrinsic connections between
DDs and (approximate) dynamic programming. We will then leverage
links with mathematical programming and polyhedral theory to propose
stronger formulations, cutting-plane methods, and new decomposition
approaches for difﬁcult combinatorial and stochastic discrete problems.
The talk will highlight examples in routing, scheduling, and planning,
while also emphasizing new applications and future research in the area.

Combining Reasoning and Learning for Discovery
Carla P. Gomez
Computer Science Department, Cornell, USA
gomes@cs.cornell.edu
Abstract. Artiﬁcial Intelligence (AI) is a rapidly advancing ﬁeld inspired
by human intelligence. AI systems are now performing at human and
even superhuman levels on various tasks, such as image identiﬁcation
and face and speech recognition. The tremendous AI progress that
we have witnessed in the last decade has been largely driven by
deep learning advances and heavily hinges on the availability of large,
annotated datasets to supervise model training. However, often we only
have access to small datasets and incomplete data. We amplify a few
data examples with human intuitions and detailed reasoning from ﬁrst
principles and prior knowledge for discovery. I will talk about our work
on AI for accelerating the discovery for new solar fuels materials, which
has been featured in Nature Machine Intelligence, in a cover article
entitled, Automating crystal-structure phase mapping by combining
deep learning with constraint reasoning [1]. In this work, we propose an
approach called Deep Reasoning Networks (DRNets), which seamlessly
integrates deep learning and reasoning via an interpretable latent space
for incorporating prior knowledge. and tackling challenging problems.
DRNets requires only modest amounts of (unlabeled) data, in sharp
contrast to standard deep learning approaches. DRNets reach super-
human performance for crystal-structure phase mapping, a core, long-
standing challenge in materials science, enabling the discovery of
solar-fuelsmaterials.DRNetsprovideageneralframeworkforintegrating
deep learning and reasoning for tackling challenging problems. For an
intuitive demonstration of our approach, using a simpler domain, we
also solve variants of the Sudoku problem. The article DRNets can
solve Sudoku, speed scientiﬁc discovery [2], provides a perspective for a
general audience about DRNets. DRNets is part of a SARA, the Scientiﬁc
Reasoning Agent for materials discovery [3]. Finally, I will also talk about
the effectiveness of a novel curriculum learning with restarts strategy
to boost a reinforcement learning framework [4]. We show how such a
strategy can outperform specialized solvers for Sokoban, a prototypical
AI planning problem.

Combining Reasoning and Learning for Discovery
xv
References
1. Chen, D., et al.: Automating crystal-structure phase mapping by combining deep
learning with constraint reasoning. Nat. Mach. Intell. 3(9), 812-822 (2021)
2. Fleischman, T.: DRNets can solve Sudoku, speed scientiﬁc discovery, Cornell
Chronicle, 17 September 2021. https://news.cornell.edu/stories/2021/09/drnets-can-
solve-sudoku-speed-scientiﬁc-discovery
3. Ament, S., et al.: Autonomous materials synthesis via hierarchical active learning of
nonequilibrium phase diagrams. Sci. Adv. 7(51), eabg4930 (2021)
4. Feng, D., Gomes, C.P., Selman, B.: A novel automated curriculum strategy to solve
hardsokobanplanninginstances.Adv.NeuralInf.Process.Syst.33,3141–3152(2020)

Deep Learning and Neural Network Accelerators
for Combinatorial Optimization
Vinod Nair
DeepMind
vinair@google.com
Abstract. Deep Learning has been used to construct heuristics for
challenging combinatorial optimization problems. It has two advantages:
a) expressive neural network models can learn custom heuristics from
data by exploiting the structure in a given application’s distribution of
problem instances, and b) once learned, the models can be executed
on accelerators such as GPUs and TPUs with high throughput for
computations such as matrix multiplication. In this talk we’ll present
two works that illustrate these advantages. In the ﬁrst work, we apply
Deep Learning to solving Mixed Integer Programs by learning a Branch
and Bound variable selection heuristic and a primal heuristic. We show
resultsondatasetsfromreal-worldapplications,includingtwoproduction
applications at Google. In the second work, we use a class of neural
networks called Restricted Boltzmann Machines to deﬁne a stochastic
search heuristic for Maximum Satisﬁability that is well-suited to run on
a large-scale TPU cluster. Results on a subset of problem instances from
annual MaxSAT competitions for the years 2018 to 2021 show that the
approach achieves better results than competition solvers with the same
wall-clock budget across all four years.

Contents
A Two-Phase Hybrid Approach for the Hybrid Flexible Flowshop
with Transportation Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
Eddie Armstrong, Michele Garraffa, Barry O’Sullivan,
and Helmut Simonis
A SAT Encoding to Compute Aperiodic Tiling Rhythmic Canons . . . . . . . . . . . .
14
Gennaro Auricchio, Luca Ferrarini, Stefano Gualandi,
Greta Lanzarotto, and Ludovico Pernazza
Transferring Information Across Restarts in MIP . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
Timo Berthold, Gregor Hendel, and Domenico Salvagnin
Towards Copeland Optimization in Combinatorial Problems . . . . . . . . . . . . . . . . .
34
Sidhant Bhavnani and Alexander Schiendorfer
Coupling Different Integer Encodings for SAT . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
Hendrik Bierlee, Graeme Gange, Guido Tack, Jip J. Dekker,
and Peter J. Stuckey
Model-Based Algorithm Conﬁguration with Adaptive Capping and Prior
Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
Ignace Bleukx, Senne Berden, Lize Coenen, Nicholas Decleyre,
and Tias Guns
Shattering Inequalities for Learning Optimal Decision Trees . . . . . . . . . . . . . . . . .
74
Justin J. Boutilier, Carla Michini, and Zachary Zhou
Learning Pseudo-Backdoors for Mixed Integer Programs . . . . . . . . . . . . . . . . . . . .
91
Aaron Ferber, Jialin Song, Bistra Dilkina, and Yisong Yue
Leveraging Integer Linear Programming to Learn Optimal Fair Rule Lists . . . . .
103
Ulrich Aïvodji, Julien Ferry, Sébastien Gambs, Marie-José Huguet,
and Mohamed Siala
Solving the Extended Job Shop Scheduling Problem with AGVs –
Classical and Quantum Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
120
Marc Geitz, Cristian Grozea, Wolfgang Steigerwald, Robin Stöhr,
and Armin Wolf
Stochastic Decision Diagrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
138
J. N. Hooker

xviii
Contents
Improving the Robustness of EPS to Solve the TSP . . . . . . . . . . . . . . . . . . . . . . . . .
155
Nicolas Isoart and Jean-Charles Régin
Efﬁcient Operations Between MDDs and Constraints . . . . . . . . . . . . . . . . . . . . . . .
173
Victor Jung and Jean-Charles Régin
Deep Policy Dynamic Programming for Vehicle Routing Problems . . . . . . . . . . .
190
Wouter Kool, Herke van Hoof, Joaquim Gromicho, and Max Welling
Learning a Propagation Complete Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
214
Petr Kuˇcera
A FastMap-Based Algorithm for Block Modeling . . . . . . . . . . . . . . . . . . . . . . . . . .
232
Ang Li, Peter Stuckey, Sven Koenig, and T. K. Satish Kumar
Packing by Scheduling: Using Constraint Programming to Solve
a Complex 2D Cutting Stock Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
Yiqing L. Luo and J. Christopher Beck
Dealing with the Product Constraint . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
266
Steve Malalel, Victor Jung, Jean-Charles Régin, and Marie Pelleau
Multiple-choice Knapsack Constraint in Graphical Models . . . . . . . . . . . . . . . . . .
282
Pierre Montalbano, Simon de Givry, and George Katsirelos
A Learning Large Neighborhood Search for the Staff Rerostering Problem . . . . .
300
Fabio F. Oberweger, Günther R. Raidl, Elina Rönnberg, and Marc Huber
A MinCumulative Resource Constraint . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
318
Yanick Ouellet and Claude-Guy Quimper
Practically Uniform Solution Sampling in Constraint Programming . . . . . . . . . . .
335
Gilles Pesant, Claude-Guy Quimper, and Hélène Verhaeghe
Training Thinner and Deeper Neural Networks: Jumpstart Regularization . . . . . .
345
Carles Riera, Camilo Rey, Thiago Serra, Eloi Puertas, and Oriol Pujol
Hybrid Ofﬂine/Online Optimization for Energy Management
via Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
358
Mattia Silvestri, Allegra De Filippo, Federico Ruggeri,
and Michele Lombardi
Enumerated Types and Type Extensions for MiniZinc . . . . . . . . . . . . . . . . . . . . . . .
374
Peter J. Stuckey and Guido Tack

Contents
xix
A Parallel Algorithm for GAC Filtering of the Alldifferent Constraint . . . . . . . . .
390
Wijnand Suijlen, Félix de Framond, Arnaud Lallouet, and Antoine Petitet
Analyzing the Reachability Problem in Choice Networks . . . . . . . . . . . . . . . . . . . .
408
Piotr Wojciechowski, K. Subramani, and Alvaro Velasquez
Model-Based Approaches to Multi-attribute Diverse Matching . . . . . . . . . . . . . . .
424
Jiachen Zhang, Giovanni Lo Bianco, and J. Christopher Beck
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
441

A Two-Phase Hybrid Approach
for the Hybrid Flexible Flowshop
with Transportation Times
Eddie Armstrong1, Michele Garraﬀa2,3, Barry O’Sullivan2,3,
and Helmut Simonis2,3(B)
1 Johnson and Johnson Research Centre, Limerick, Ireland
2 Conﬁrm SFI Research Centre for Smart Manufacturing, Limerick, Ireland
helmut.simonis@insight-centre.org
3 School of Computer Science and IT, University College Cork, Cork, Ireland
Abstract. We present a two-phase heuristic approach for the Hybrid
Flexible Flowshop with Transportation Times (HFFTT) which combines
a metaheuristic with constraint programming (CP). In the ﬁrst phase an
adapted version of a state-of-the-art metaheuristic for the Hybrid Flow-
shop [15] generates an initial solution. In the second phase, a CP app-
roach reoptimizes the solution with respect to the last stages. Although
this research is still in progress, the initial computational results are very
promising. In fact, we show that the proposed hybrid approach outper-
forms both the adapted version of [15] and earlier CP approaches.
Keywords: Metaheuristics · Constraint Programming · Scheduling ·
Hybrid Flowshop
1
Introduction
Real world scheduling problems are generally tackled by means of two diﬀerent
types of approaches. On one hand, mixed integer linear programming (MILP)
and constraint programming (CP) approaches put the focus on modelling the
scheduling problem, instead of developing a solution algorithm from scratch. This
approach shortens the development time and provides a high level of ﬂexibility
in the case where the problem formulation needs to be adjusted to take into
account new characteristics. In that case, an optimization specialist just needs
to adapt the MILP/CP model, then a modern solver will provide high quality
solutions by exploiting many years of algorithmic improvements. On the other
hand, metaheuristic algorithms have been widely studied, since they can exploit
problem-speciﬁc properties to perform the search very eﬃciently. In many cases,
this leads to achieving high quality results, at the cost of a higher development
time and a reduction in the ﬂexibility/generality of the solution approach.
The combination of both approaches, so called hybrid heuristics, has been
receiving signiﬁcant attention from the research community since the early 2000 s
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 1–13, 2022.
https://doi.org/10.1007/978-3-031-08011-1_1

2
E. Armstrong et al.
(see [2] for a survey about the topic). Most hybrid heuristics rely on eﬃcient
MILP solvers, due to their use of powerful mathematical programming tech-
niques. However, the performance of MILP solvers is typically poor in cases
where the model has a weak linear relaxation, e.g. due to the use of big-M vari-
ables to represent logical constraints. MILP-based hybrid heuristics are generally
known as “matheuristics” [6,9], and they have been widely used for scheduling
problems [3–5,8]. On the other hand, CP solvers rely on the expressive power of
global constraints, and on the eﬀectiveness of propagation algorithms and auto-
matic search heuristics. One of the best known commercial CP solvers, CP Opti-
mizer by IBM [7], oﬀers support for eﬃciently solving many types of scheduling
problems. It provides a model-and-run paradigm, which is quite simple to master
and is more generic than the one provided by MILP solvers, since non-linearities
and logical constraints can be easily included.
In this paper we propose a hybrid heuristic for a real-world scheduling prob-
lem, which combines a metaheuristic with a local search procedure relying on
CP Optimizer. Hybrid heuristics based on CP for scheduling problems are not
very common, but they have been considered [12,14]. The motivation behind
hybridizing CP with another type of solution approach is usually to exploit the
complementarity of the two in order to achieve a better performance than each
of the two approaches separately. The problem considered in this study is the
Hybrid Flexible Flowshop with Transportation Times (HFFTT) which arises in
modern production facilities and has been recently introduced [1]. The problem
is an extension of the Hybrid Flowshop Problem (HFP) [13] and of the Hybrid
Flexible Flowshop (HFF) [10] where transportation times between the machines
for the diﬀerent production steps of each job are assumed to be non-negligible.
The HFFTT is deﬁned as follows. Let J be a set of jobs, M a set of machines
and S a set of production stages. We denote as pj,s the processing time of a job
j ∈J to complete a stage s ∈S. All jobs complete the stages in the same order
but some of the stages may be skipped by some jobs. We indicate with Sj ⊆S
the subset of the production stages performed by job j ∈J, while we indicate
with Js ⊆J the set of all jobs that complete a stage s ∈S. The successor
stage of a stage s ∈S with respect to a job j ∈J is denoted as succ(s, j). The
transportation time required to move a job j ∈J from a machine m ∈Ms to
another machine m′ ∈Ms′, where s, s′ ∈S and s′ = succ(s, j), is represented
by δm,m′. Finally, the problem objective is to minimize the makespan.
The paper is organized as follows. Section 2 describes the CP model of
the problem using the global constraints available in CP Optimizer. Section 3
describes an iterated greedy method, IGT NEH, which is an adaptation of a state-
of-the-art metaheuristic for the HFP [15]. Section 4 presents a novel two-phase
hybrid approach to solve the HFFTT. Section 5 presents a computational assess-
ment of the diﬀerent approaches, using the benchmarks deﬁned in [1].

A Two-Phase Hybrid Approach for the HFFTT
3
2
The Constraint Programming Model
This section presents a CP model of the problem, analogous to the model based
on interval variables presented in [1], and was encoded by using the OPL API
of CP Optimizer [7]. The model is based on the following variables:
– Optional interval variables tmm,j for each j ∈J and m ∈M;
– Interval variables tss,j for each j ∈J and s ∈Sj;
– Integer variables machines,j for each j ∈J and s ∈Sj, with feasible values
in the range {1, · · · , |M|}.
The variables tmm,j are optional interval variables representing the execution of
a job on a certain machine. Given a stage s ∈S and a job j ∈J, only one of
these variables is active, which is constrained to be equal to tss,j. The variables
machines,j are linked to the machine used to performed a job j ∈J at stage
s ∈S.
The CP model of the HFFTT is as follows:
min
max
s∈S,j∈Js endOf(tss,j)
(1)
subject to:
(machines,j = m) =⇒presenceOf(tmm,j)
∀j ∈J, s ∈Sj, m ∈Ms
(2)
alternative(tss,j, {tmm,j : m ∈Ms})
∀j ∈J, s ∈Sj
(3)
endBeforeStart(tmm,j, tmm′,j, δm,m′)
∀j, s ∈Sj, m ∈Ms, m′ ∈Msucc(s,j)
(4)
endBeforeStart(tss,j, tssucc(s,j),j))
∀j ∈J, s ∈Sj : succ(s, j) ̸= ∅
(5)
noOverlap({tmm,j : j ∈J})
∀m ∈M
(6)
cumulative({tss,j : j ∈Js}, |Ms|)
∀s ∈S
(7)
The objective (1) indicates that we minimize the makespan. Constraints 2
deal with assigning a job j ∈J to one machine m ∈Ms at each stage s ∈Sj,
and setting the corresponding interval variable tmm,j to active. Constraints 3
link the interval variables tmm,j and the interval variables tss,j. Constraints 4
indicate that a job j ∈J can start being processed by a machine m′ ∈Msucc(s,j)
after being completed by the previous one m ∈Ms and spending δm,m′ time
units for the transportation. Constraints 5 are ﬂowshop constraints, meaning
that each job j ∈J can perform the next stage succ(s, j) ∈Sj after completing
the previous one s ∈Sj. Constraints 6 state that each machine can process

4
E. Armstrong et al.
one job at a time. Constraints 7 are redundant, requiring that the maximum
number of jobs performing simultaneously at stage s ∈S is equal to the number
of machines |Ms| available at that stage.
3
Metaheuristic Approach
State-of-the-art metaheuristic approaches for the HFP, e.g. [15], can be easily
adapted to solve instances of the HFFTT. These approaches are based on forward
scheduling. Given a certain jobs permutation γ, they follow these two steps:
– Assign the jobs by following the order in γ, to the earliest available machine
(ﬁrst stage);
– Assign the earliest available job to the earliest available machine (each of the
other stages).
A random choice is taken in case of ties. In such a way, a feasible solution
to the HFP can be generated given a reference permutation. The adaptation
needed to use forward scheduling on the HFFTT is to consider the transportation
times. We do not consider the transportation time when we compute the earliest
available job, since the job is available once it has been processed by a certain
machine. However, we consider the transportation time when performing the
machine assignment. In this case, we do not evaluate the machines according to
their earliest available time because the job may not be able to reach the machine
at that time. We rank the machines according to the maximum between the:
– Earliest time when the machine is available;
– Earliest time when the job can reach the machine.
This change allows us to replicate approaches based on forward scheduling on
the HFFTT.
In the following, we describe our adaptation of the approach denoted as IGT
(Iterated Greedy with ﬁxed temperature T) [15]. We denote our approach as
IGT NEH. The most important changes with respect to IGT are:
– IGT NEH considers transportation times when applying forward scheduling;
– IGT NEH computes the initial solution using a diﬀerent procedure.
Section 3.1, Sect. 3.2 and Sect. 3.3 describe the main components of the
IGT NEH heuristic, while its structure is discussed in Sect. 3.4.
3.1
Computation of the Initial Solution
The NEH heuristic [11] is one of the most common constructive heuristics used for
scheduling problems. It takes its name from the three authors who proposed it for
the ﬁrst time (Nawaz, Enscore and Ham). The approach is quite generic: only the

A Two-Phase Hybrid Approach for the HFFTT
5
evaluation strategy and the initial sorting criteria change from one problem to
another. First, the sum of the processing times on all stages, indicated as TPj =

s∈S pj,s, is computed for each j ∈J. The jobs are then sorted by decreasing
order of TPj, in order to have a good job reference permutation γ. The ﬁrst job γ1
of the permutation is selected to establish a partial solution of length one. Then
the other jobs in γ are sequentially inserted into the output permutation γout one
by one. At the i-th iteration, the job γi is chosen and tentatively inserted into all
the i possible positions of γout, it is then inserted at the position resulting in the
best makespan value. Each evaluation of a permutation is performed by means
of forward scheduling and considering the makespan as the objective. Once the
n-th iteration is reached, the solution constructed is provided as an output.
We now brieﬂy discuss why we used NEH as a method to compute initial
solutions, instead of the approach denoted as GRASP NEH in [15]. The computa-
tional complexity of NEH and GRASP NEH is diﬀerent (O(n3m) vs O(n4m)). In
our preliminary computational experiments, we explored both variants in the
metaheuristic approach. According to our results, spending too much time on
computing the initial solution aﬀected the results in large instances (n ≥200),
while the two approaches showed quite similar performance in smaller instances.
For this reason, we decided to use NEH as a method to compute the initial
solution.
3.2
Local Search Approaches
The local search moves used in IGT NEH are guided by a reference jobs permu-
tation. They are the same as used in IGT, with the only diﬀerence that for-
ward scheduling takes into account the transportation times as explained at the
beginning of Sect. 3. These procedures are denoted by RIS (Referenced Insertion
Scheme) and RSS (Referenced Swap Scheme). Given a reference permutation γ
and an initial permutation γin – the job permutation used to generate the initial
solution – we iteratively select a job from γ. In RIS, we remove the job from γin
and re-insert it in the best position. In RSS, we try to swap the selected job
with the others in γin and choose the swap leading to the best objective. The
authors in [15] discuss the fact that a reference permutation associated with a
high-quality solution can improve the performance of the local search moves.
Both local search routines stop whenever n iterations with no improvements are
performed. The best solution found is then provided as an output.
3.3
Deconstruction and Reconstruction
The deconstruction-reconstruction procedure, denoted as DEC REC, is straight-
forward. First, dS random jobs are removed from the initial permutation γ, then
they are re-inserted one by one at the best possible position. Again, the only
diﬀerence with IGT is that the transportation times are taken into account when
applying forward scheduling.

6
E. Armstrong et al.
3.4
General Structure of IGT NEH
The IGT NEH procedure is an iterated greedy procedure, which starts from an ini-
tial solution and iteratively applies some local search moves, followed by a shak-
ing step to escape local minima. First, an initial solution is computed by using the
function NEH. Then, a while loop iterates until a time limit Tmax
2
is reached. The
loop starts with the deconstruction-reconstruction procedure DEC REC, where dS
jobs are removed from the current permutation and re-inserted to optimality.
Afterwards, one of the local search moves RIS and RSS is chosen, the ﬁrst one
with probability jP and the second one with probability 1 −jP. If the solu-
tion computed by the local search is better than the solution considered at the
beginning of the current iteration, the next iteration continues the search from
that solution. Otherwise, the output of the local search is considered as a start-
ing point of the next iteration with probability exp(−(f(Π′) −f(Π))/g(I, τP)),
where g(I, τP) =

j∈J

s∈S pj,s
|J||S|10
×τP. The best solution found is updated when-
ever is necessary and it is provided as an output when the time limit is reached.
The pseudocode of the procedure is given in Algorithm 1.
Algorithm 1. The IGT NEH approach
Function IGT NEH is
Input: Time limit Tmax, Parameters dS, τP, jP
Output: Solution Πbest
Π, γ ←NEH();
Πbest ←Π;
γbest ←γ;
while time limit Tmax not reached do
γ′′ ←DEC REC(γ, dS);
r ←random value between 0 and 1;
if r < jP then
Π′, γ′ ←RIS(γbest, γ′′);
else
Π′, γ′ ←RSS(γbest, γ′′);
if f(Π′) < f(Π) then
Π ←Π′;
γ ←γ′;
if f(Π′) < f(Πbest) then
Πbest ←Π′;
γbest ←γ′;
else
if r < exp −(f(Π′) −f(Π))/g(I, τP) then
Π ←Π′;
γ ←γ′;
return Πbest, γbest;

A Two-Phase Hybrid Approach for the HFFTT
7
4
Hybrid Approach
IGT NEH implements a very diﬀerent type of search compared to CP-based
approaches. In fact, reference-based heuristics generate a new solution from
scratch each time a diﬀerent job permutation is considered, which occurs many
times in the diﬀerent local search moves. This is the reason why these local search
moves are not suitable for embedding into a CP system. Moreover, reference-
based heuristics do not perform any local search that is devoted to optimizing
the makespan by purely modifying how jobs are scheduled at the last stages. As
an alternative, CP-based approaches branch on speciﬁc decisions, taken at each
stage and consist of assigning a job to a machine such that the job starts on a
certain time point.
The idea of the proposed hybrid approach is to exploit IGT NEH to quickly ﬁnd
high quality solutions, while CP is used to intensify the search over the last stages
of the schedule. The approach is based on two phases. The ﬁrst phase consists
of running IGT NEH until the time limit Tmax
2
is reached. Hence, we consider the
CP model of the problem and we impose that the solution is identical to the
one computed at the ﬁrst phase up to stage ρ. The second phase consists of
solving the resulting CP model, which basically re-optimizes the best solution
found at the ﬁrst phase, with respect to the stages that are successive to stage
ρ. The model is solved using CP Optimizer, and its black-box search routine.
This simpliﬁes development compared to using the best performing solver in
[1], which is SICStus Prolog, for which we would have to write a new speciﬁc
search routine. The time limit of the second phase is Tmax
2
, such that the overall
time limit of the approach is equal to Tmax. Figure 1 depicts the structure of the
proposed approach, which we denote as HYBRID.
5
Computational Experiments
This section describes the experiments conducted to assess the performance of
IGT NEH and HYBRID. The instances considered are the ones in [1], which refer
to a realistic lane scenario in industry with 8 stages, where Stages 4 and 8 may
be skipped by some jobs.
All experiments were performed on an Intel(R) Xeon(R) E5620 processor
running at 2.40 GHz with 32 GB of memory. Please note that this machine is
slightly slower than the machine used for the experiments in [1]. IGT NEH was
run by using the same parameter conﬁguration as the one used in [15] (dS = 2,
τP = 0.5, jP = 0.4). For the sake of performing a fair comparison, HYBRID is
run in single-thread mode. Table 1 and Table 2 show the results obtained when
the overall time limit is set to Tmax = 300 s both for IGT NEH and HYBRID. The
values of each row of both tables are averages over 25 instances and 5 seeds.

8
E. Armstrong et al.
Fig. 1. Structure of the approach HYBRID.
Please note that a dash indicates that the corresponding experiments have not
been conducted. Table 1 includes:
– the average objective value (obj value),
– the number of runs where an improvement was achieved with respect to
IGT NEH run for one half of the time limit (imp.),
for IGT NEH run for 300 s, and HYBRID run for 300 s with ρ ∈{0, 4, 6}. Only the
average objective values are reported for NEH, and for IGT NEH run for 150 s. Fur-
thermore, the last two columns of both tables indicate the best results obtained
with the diﬀerent CP approaches published in [1], and the average of the lower
bounds of the instances; see [1] for a description of the procedure used to compute
these bounds.

A Two-Phase Hybrid Approach for the HFFTT
9
Table 1. Average objective value and number of improved solutions per approach on
diﬀerent instance sizes, with the time limit Tmax = 300 s.
NEH
IGT NEH
Tmax
2
IGT NEH
Tmax
HYBRID
Tmax, ρ = 0
HYBRID
Tmax, ρ = 4
HYBRID
Tmax, ρ = 6
n
obj
obj
obj
imp.
obj
imp.
obj
imp.
obj
imp.
CP21
LB
20
66.72
62.78
62.76
3
62.75
4
62.77
2
62.776
1
62.72
61.88
25
68.84
64.32
64.26
7
64.26
8
64.16
6
64.30
3
64.16
62.84
30
72.52
66.81
66.68
16
66.74
8
66.59
26
66.78
4
66.68
64.12
40
78.2
72.37
72.26
14
72.18
21
71.74
66
72.12
40
72.56
65.32
50
85.42
78.94
78.81
21
78.31
20
77.72
82
78.12
43
78.4
67.24
100 115.56 109.78 109.51
29
-
-
108.90
74
109.26
54
113.04 94.72
200 176.24 171.69 170.08
73
-
-
169.8
87
170.98
60
176.72 153.08
300 239.12 238.54 234.21
93
-
-
235.24
113
240.96
75
240.96 214.96
400 298.82 298.82 298.54
32
-
-
296.1
98
298.07
61
303.16 275.36
Table 2 shows the average percentage (optimality) gap from the lower bound
for each approach. It is interesting to note that, as with the previous CP results,
the largest gap occurs for 50 or 100 jobs, while the optimality gap shrinks again
for larger problem sizes.
The ﬁrst key point that we can notice from Table 1 and Table 2 is that HYBRID
is the best performing approach for most of the instance sizes. The best of its
versions is the one with ρ = 4 stages for all the instances, but the ones that are
very small (n = 20). Please note that in those instances the results published
in [1] are slightly better, probably because of a more favorable computational
setting (more powerful CPU, use of multiple threads). We can also note that
IGT NEH achieves a better result than HYBRID only for n = 300.
Table 3 provides an explanation for this, showing the average sum of squared
deviation of the achieved objective values of runs performed with diﬀerent seeds.
This value is generally quite low, but very high for n = 300 and again very low
for n = 400. For n = 300, the time limit stopped the search before the diﬀerent
runs converge to a common value, while for n = 400 there was not even enough
time to ﬁnd initial, but very variable, improvements in the local search routine
over NEH.
Table 4 shows some experiments, performed with just one seed for an
increased time limit, showing that HYBRID ﬁnds even better solutions given more
time, and still outperforms IGT NEH for the same time limit. Table 3 shows that
we achieve a much lower average sum of squared deviations for n = 300, when
the time limit is set to Tmax = 2400 s. Thus, an extension of the time limit
helps improve the quality of the solutions provided by the proposed approaches
and reduces the variance in the results. A closely related research question is to
establish what is the best way to split the time limit in HYBRID, which we will
cover in our future studies.
Figure 2 shows how the approaches perform on the ﬁrst instance with n = 100
when diﬀerent time limits are used, with the exception of NEH which is exe-
cuted once, until the procedure is completed. We notice that HYBRID outperforms
IGT NEH after 200 s and maintains its lead for larger time limits. Figure 3 shows

10
E. Armstrong et al.
Table 2. Average percentage gap from the lower bound per approach on diﬀerent
instance sizes, with the time limit Tmax = 300 s.
n
NEH
IGT NEH
Tmax
2
IGT NEH
Tmax
HYBRID
Tmax, ρ = 0
HYBRID
Tmax, ρ = 4
HYBRID
Tmax, ρ = 6
CP21
20
7.25%
1.44%
1.40%
1.40%
1.41%
1.43%
1.34%
25
8.72%
2.30%
2.22%
2.20%
2.06%
2.26%
2.06%
30
11.58%
4.02%
3.84%
3.93%
3.71%
3.98%
3.84%
40
16.47%
9.74%
9.60%
9.50%
8.94%
9.43%
9.98%
50
21.28%
14.82%
14.68%
14.14%
13.48%
13.93%
14.23%
100 18.03%
13.72%
13.51%
-
13.02%
13.31%
16.21%
200 13.14%
10.84%
10.00%
-
9.85%
10.47%
13.38%
300 10.10%
9.89%
8.22%
-
8.62%
10.79%
10.79%
400
7.85%
7.85%
7.76%
-
7.00%
7.62%
9.17%
Table 3. Average sum of squared deviation of the objective for IGT NEH runs with
diﬀerent seeds on diﬀerent instance sizes, with time limits Tmax = 300 s and Tmax =
2400 s.
n
IGT NEH (Tmax = 300) IGT NEH (Tmax = 2400)
20
0.064
-
25
0.272
-
30
0.336
-
40
0.464
-
50
0.544
-
100
0.88
-
200
8.624
0.624
300
38.56
3.616
400
0.688
5.588
Table 4. Average objective values and gaps obtained with IGT NEH and HYBRID on
diﬀerent instance sizes, with time limit Tmax = 2400 s.
IGT NEH (Tmax)
HYBRID(Tmax, ρ = 4 )
n
Obj value
Gap
Obj value
Gap
LB
200
168.56
10.11%
167.12
8.40%
153.08
300
230.52
7.24%
229.4
6.75%
214.96
400
291.36
5.81%
291.32
5.48%
275.36
that improvements for the diﬀerent runs of HYBRID are less common after a time
limit of 1000 s, which justiﬁes the limit of 1200+1200 s for the experiments in
Table 4.

A Two-Phase Hybrid Approach for the HFFTT
11
0
200
400
600
800
1,000
106
108
110
112
Time (s)
Cmax
IGT_NEH
HYBRID
NEH
Fig. 2. Comparing average Cmax values for IGT NEH and HYBRID over time for a single
instance with 100 jobs
0
500
1,000
1,500
2,000
104
106
108
110
112
Time (s)
Cmax
Fig. 3. Comparing Cmax value over time for ﬁve runs of HYBRID for a single instance
with 100 Jobs
In conclusion, the experiments are show a clear beneﬁt in hybridizing IGT NEH
with a CP-based step, since HYBRID outperforms both approaches. This is prob-
ably due to the complementarity of the two approaches, which use diﬀerent opti-
mization strategies. In fact, the second phase of HYBRID, based on CP, intensiﬁes
the search on the last stages of the schedule. This aspect is not taken into account
by reference-guided heuristics.

12
E. Armstrong et al.
6
Conclusions and Future Work
This paper proposed a novel hybrid heuristic for the HFFTT problem, which
combines a metaheuristic with constraint programming. Despite its simplicity,
the proposed approach allowed us to improve the results obtained in [1] by means
of diﬀerent CP frameworks. At the same time, the hybrid also outperformed the
state-of-the-art metaheuristic for the HFS, adapted to this problem variant.
An interesting research direction is to study how similar hybrid techniques
perform on other variants of hybrid ﬂowshop problems, including the HFP, by
considering instances in reference datasets. The proposed hybrid approach can be
seen as a CP-based decomposition heuristic, where the problem is decomposed
with respect to the stages. Other alternative CP-based hybrid schemes may also
be considered. One is to decompose the problem with respect to the jobs, ﬁxing
the ﬁrst jobs for all stages to the value in the initial solution, and then reschedul-
ing for the remaining jobs, even for the initial stages. Another alternative is to
decompose the problem with respect to a certain time instant, by ﬁxing all the
tasks, regardless of stage, starting before, and solving the remaining problem.
These and other decompositions will be explored in our future studies.
Acknowledgements. This publication has emanated from research conducted with
the ﬁnancial support of Science Foundation Ireland under Grant Numbers 16/RC/3918
(Conﬁrm) and 12/RC/2289-P2 (Insight), and co-funded under the European Regional
Development Fund. The research also received ﬁnancial support from Johnson and
Johnson Research Centre.
References
1. Armstrong, E., Garraﬀa, M., O’Sullivan, B., Simonis, H.: The hybrid ﬂexible ﬂow-
shop with transportation times. In: Michel, L.D. (ed.) 27th International Confer-
ence on Principles and Practice of Constraint Programming (CP 2021), vol. 210,
pp. 16:1–16:18. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik, Dagstuhl, Ger-
many (2021). https://doi.org/10.4230/LIPIcs.CP.2021.16
2. Blum, C., Puchinger, J., Raidl, G.R., Roli, A.: Hybrid metaheuristics in combinato-
rial optimization: A survey. Appl. Soft Comput. 11(6), 4135–4151 (2011). https://
doi.org/10.1016/j.asoc.2011.02.032
3. Della Croce, F., Garraﬀa, M., Salassa, F., Borean, C., Di Bella, G., Grasso, E.:
Heuristic approaches for a domestic energy management system. Comput. Ind.
Eng. 109, 169–178 (2017)
4. Della Croce, F., Grosso, A., Salassa, F.: Minimizing total completion time in the
twomachine noidle nowait ﬂow shop problem. Journal of Heuristics (2019). https://
doi.org/10.1007/s1073201909430z
5. Fanjul-Peyro, L., Perea, F., Ruiz, R.: Models and matheuristics for the unrelated
parallel machine scheduling problem with additional resources. European Journal
of Operational Research 260(2), 482–493 (2017). https://doi.org/10.1016/j.ejor.
2017.01.002
6. Kergosien, Y., Mendoza, J.E., T’kindt, V.: Special issue on matheuristics. J. Heuris-
tics 27, 1–3 (2021)

A Two-Phase Hybrid Approach for the HFFTT
13
7. Laborie, P., Rogerie, J., Shaw, P., Vil´ım, P.: IBM ILOG CP optimizer for scheduling.
Constraints 23(2), 210–250 (2018). https://doi.org/10.1007/s10601-018-9281-x
8. Lin, S.W., Ying, K.C.: Optimization of makespan for no-wait ﬂowshop scheduling
problems using eﬃcient matheuristics. Omega, 64, 115–125 (2015)
9. Maniezzo, V., St¨utzle, T., Voß, S. (eds.) Matheuristics - Hybridizing Metaheuristics
and Mathematical Programming, Annals of Information Systems, vol. 10. Springer
(2010). https://doi.org/10.1007/978-1-4419-1306-7
10. Naderi, B., Gohari, S., Yazdani, M.: Hybrid ﬂexible ﬂowshop problems: models
and solution methods. Appl. Math. Model. 38(24), 5767–5780 (2014). https://doi.
org/10.1016/j.apm.2014.04.012
11. Nawaz, M., Enscore, E.E., Ham, I.: A heuristic algorithm for the m-machine, n-
job ﬂow-shop sequencing problem. Omega 11(1), 91–95 (1983). https://doi.org/
10.1016/0305-0483(83)90088-9
12. Rendl, A., Prandtstetter, M., Hiermann, G., Puchinger, J., Raidl, G.: hybrid heuris-
tics for multimodal homecare scheduling. In: Beldiceanu, N., Jussien, N., Pinson,
´E. (eds.) Integration of AI and OR Techniques in Constraint Programming for
Combinatorial Optimization Problems, pp. 339–355. Springer, Berlin Heidelberg
(2012). https://doi.org/10.1007/978-3-642-29828-8 22
13. Ruiz, R., V´azquez Rodr´ıguez, J.A.: The hybrid ﬂow shop scheduling problem.
European Journal of Operational Research 205, 1–18 (2010). https://doi.org/10.
1016/j.ejor.2009.09.024
14. Tang, T.Y., Beck, J.C.: CP and hybrid models for two-stage batching and schedul-
ing. In: Hebrard, E., Musliu, N. (eds.) Integration of Constraint Programming,
Artiﬁcial Intelligence, and Operations Research, pp. 431–446. Springer Interna-
tional Publishing, Cham (2020). https://doi.org/10.1007/978-3-030-58942-4 28
15. ¨Oztop, H., Fatih Tasgetiren, M., Eliiyi, D.T., Pan, Q.K.: Metaheuristic algorithms
for the hybrid ﬂowshop scheduling problem. Comput. Oper. Res. 111, 177–196
(2019). https://doi.org/10.1016/j.cor.2019.06.009

A SAT Encoding to Compute Aperiodic
Tiling Rhythmic Canons
Gennaro Auricchio1
, Luca Ferrarini1,2,3(B)
, Stefano Gualandi1
,
Greta Lanzarotto1,2,3,4
, and Ludovico Pernazza1
1 Department of Mathematics, University of Pavia, Pavia, Italy
2 Department of Mathematics and its Applications, University of Milano-Bicocca,
Milan, Italy
l.ferrarini3@campus.unimib.it
3 INdAM, Rome, Italy
4 University of Strasbourg, IRMA, Strasbourg, France
Abstract. In Mathematical Music theory, the Aperiodic Tiling Comple-
ments Problem consists in ﬁnding all the possible aperiodic complements
of a given rhythm A. The complexity of this problem depends on the size
of the period n of the canon and on the cardinality of the given rhythm
A. The current state-of-the-art algorithms can solve instances with n
smaller than 180. In this paper we propose an ILP formulation and a SAT
Encoding to solve this mathemusical problem, and we use the Maplesat
solver to enumerate all the aperiodic complements. We validate our SAT
Encoding using several diﬀerent periods and rhythms and we compute
for the ﬁrst time the complete list of aperiodic tiling complements of
standard Vuza rhythms for canons of period n = {180, 420, 900}.
Keywords: Mathematical models for music · Aperiodic tiling
rhythms · SAT encoding · Integer linear programming
1
Introduction
Mathematical Music Theory is the study of Music from a mathematical point
of view. Many connections have been discovered, some of which albeit having
already a long tradition, are still oﬀering new problems and ideas to researchers,
whether they be music composers or computer scientists. The ﬁrst attempt to
produce music through a computational model dates back to 1957, when the
authors composed a string quartet, also known as the Illiac Suite, through ran-
dom number generators and Markov chains [11]. Since then, a plethora of other
works have explored how computer science and music can interact: to compose
music [20,21], to analyse existing compositions and melodies [7–9], or even to
represent human gestures of the music performer [18]. In particular, Constraint
Programming has been used to model harmony, counterpoint and other aspects
of music (e.g., see [4]), to compose music of various genres as described in the
book [3], or to impose musical harmonization constraints in [16].
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 14–23, 2022.
https://doi.org/10.1007/978-3-031-08011-1_2

A SAT Encoding to Compute Aperiodic Tiling Rhythmic Canons
15
In this paper, we deal with Tiling Rhythmic Canons, that are purely rhythmic
contrapuntal compositions. It is well-known that all canons are periodic: for a
ﬁxed period n, a tiling rhythmic canon is then represented by a couple of sets
A, B ⊆{0, 1, 2, . . . , n −1} where A deﬁnes the sequence of beats (of a constant
metre) played by every voice, B the oﬀsets at which the voices start to play, and
such that at every beat there is exactly one voice playing. If one of the sets, say
A, is given, it is well-known that the problem of ﬁnding a complement B has
in general no unique solution. It is very easy to ﬁnd tiling canons in which at
least one of the set is periodic, i.e. it is built repeating a shorter rhythm. From
a mathematical point of view, the most interesting canons are therefore those
in which both sets are aperiodic (the problem can be equivalently rephrased as
a research of tessellations of a special kind). To enumerate all aperiodic tiling
canons one has to overcome two main hurdles: on one side, the problem lacks the
algebraic structure of other ones, such as those involving ring or group theory; on
the other side, the combinatorial size of the domain becomes very soon enormous.
From a theoretical point of view, starting from the ﬁrst works in the 1940 s s
research has gradually shed some light on the problem; from a more concrete
point of view, several heuristics and algorithms that allow to compute tiling
complements have been introduced. A complete solution appears however to be
still out of reach.
Contributions. The main contributions of this paper are the Integer Linear Pro-
gramming (ILP) model and the SAT Encoding to solve the Aperiodic Tiling
Complements Problem presented in Sect. 3. Using a modern SAT solver we are
able to compute the complete list of aperiodic tiling complements of a class of
Vuza rhythms for periods n = {180, 420, 900}.
Outline. The outline of the paper is as follows. Section 2 reviews the main notions
on Tiling Rhythmic Canons and deﬁnes formally the problem. In Sect. 3, we
introduce an ILP model and a SAT Encoding of the Aperiodic Tiling Comple-
ments Problem expressing the tiling and the aperiodicity constraints in terms
of Boolean variables. Finally, in Sect. 4, we include our computational results
to compare the eﬃciency of the aforementioned ILP model and SAT Encoding
with the previous state-of-the-art algorithms.
2
The Aperiodic Tiling Complements Problem
We begin ﬁxing some notation and giving the main deﬁnitions. In the following,
we conventionally denote the cyclic group of remainder classes modulo n by Zn
and its elements with the integers {0, 1, . . . , n −1}, i.e. identifying each class
with its smallest non-negative member.
Deﬁnition 1. Let A, B ⊆Zn. Let us deﬁne the application
σ : A × B →Zn(a, b) →a + b.

16
G. Auricchio et al.
0
1
2
3
4
5
6
7
8
Fig. 1. A = {0, 1, 5} is the inner voice;
B = {0, 3, 6} is the outer voice.
0
1
5
2
3
4
6
7
8
Fig. 2. This time, B = {0, 3, 6} is the
inner voice, and A = {0, 1, 5} is the
outer voice.
We set A + B := Im(σ); if σ is bijective we say that A and B are in direct
sum, and we write
A ⊕B := Im(σ).
If Zn = A ⊕B, we call (A, B) a tiling rhythmic canon of period n; A is
called the inner voice and B the outer voice of the canon. In this case, we
also say that B is a complement of A, and vice versa.
Remark 1. It is easy to see that the tiling property is invariant under transla-
tions, i.e. if A is a tiling complement of some set B, any translate A + z of A
is a tiling complement of B, too (and any translate of B is a tiling complement
of A). In fact, suppose that A ⊕B = Zn; for every k, z ∈Zn by deﬁnition there
exists one and only one pair (a, b) ∈A × B such that k −z = a + b. Conse-
quently, there exists one and only one pair (a + z, b) ∈(A + z) × B such that
k = (a + z) + b, that is (A + z) ⊕B = Zn. In view of this, without loss of
generality, we shall consider equivalence classes under translation and limit our
investigation to rhythms containing 0.
Example 1. Let us consider period n = 9 and the two rhythms A = {0, 1, 5} ⊂Z9
and B = {0, 3, 6} ⊂Z9 in Fig. 1 and Fig. 2. The inner voice is represented with
a sequence of black boxes in a row of length n. The outer voice is represented by
the starting black box in each row. A and B provide the canon A⊕B = Z9, since
{0, 1, 5} ⊕{0, 3, 6} = {0, 3, 6, 1, 4, 7, 5, 8, 2}, where the last number is obtained
by (5 + 6) mod 9 = 2.
Deﬁnition 2. A rhythm A ⊆Zn is periodic (of period z) if and only if there
exists an element z ∈Zn, z ̸= 0, such that z + A = A. In this case, A is also
called periodic modulo z ∈Zn. A rhythm A ⊆Zn is aperiodic if and only if it
is not periodic.
Remark 2. Going back to Example 1, it is easy to note the periodicity z = 3 in
rhythm B = {0, 3, 6}: and indeed, 3+B = B. The rhythm A = {0, 1, 5}, instead,
is not periodic with respect to any period. Notice that if A is periodic of period
z, z must be a strict divisor of the period n of the canon.
Tiling rhythmic canons can be characterised using polynomials. This char-
acterization allows to translate the tiling property into linear constraints and,
therefore, to approach the problem through a SAT encoding.

A SAT Encoding to Compute Aperiodic Tiling Rhythmic Canons
17
Lemma 1. Let A be a rhythm in Zn and let pA(x) be the characteristic poly-
nomial of A, that is, pA(x) = 
k∈A xk. Given B ⊆Zn and its characteristic
polynomial pB(x), we have that
pA(x) · pB(x) ≡
n−1

k=0
xk,
mod (xn −1)
(1)
if and only if pA(x), pB(x) are polynomials with coeﬃcients in {0, 1} and A⊕B =
Zn.
Example 2. Let us consider the tiling canon introduced in Example 1. In this
case, the characteristic polynomial of A is pA(x) = x5 + x + 1, while the char-
acteristic polynomial of B is pB(x) = x6 + x3 + 1. A simple computation shows
that
mod (x9 −1)
pA(x)pB(x) = x11 + x8 + x7 + x6 + x5 + x4 + x3 + x + 1 ≡
8

k=0
xk,
since x11 = x9x2 ≡x2
mod (x9 −1).
Deﬁnition 3. A tiling rhythmic canon (A, B) in Zn is a Vuza canon if both
A and B are aperiodic.
Remark 3. Note that a set A is periodic modulo z if and only if it is periodic
modulo all the non-trivial multiples of z dividing n. For this reason, when it
comes to check whether A is periodic or not, it suﬃces to check if A is periodic
modulo m for every m in the set of maximal divisors of n. We denote by Dn this
set:
Dn :=

n/p | p is a prime factor of n

.
We also denote with kn the cardinality of Dn, so that n = pα1
1 pα2
2 . . . pαkn
kn
is the
unique prime factorization of n, where α1, . . . , αkn ∈N+ .
For a complete and exhaustive discussion on tiling problems, we refer the
reader to [2]. In this paper, we are interested in the following tiling problem.
Deﬁnition 4. Given a period n ∈N and a rhythm A ⊆Zn, the Aperiodic
Tiling Complements Problem consists in ﬁnding all its aperiodic comple-
ments B i.e., all subsets B of Zn such that A ⊕B = Zn.
Some problems very similar to the decision of tiling (i.e., the tiling decision
problem DIFF in [13]) have been shown to be NP-complete; a strong lower bound
for computational complexity of the tiling decision problem is to be expected,
too.
3
A SAT Encoding
In this section, we present in parallel an ILP model and a new SAT Encoding
for the Aperiodic Tiling Complements Problem that are both used to enumerate
all complements of A. We deﬁne two sets of constraints: (i) the tiling constraints
that impose the condition A ⊕B = Zn, and (ii) the aperiodicity constraints that
impose that the canon B is aperiodic.

18
G. Auricchio et al.
Tiling constraints. Given the period n and the rhythm A, let a = [a0, . . . , an−1]⊺
be its characteristic (column) vector, that is, ai = 1 if and only if i ∈A. Using
vector a we deﬁne the circulant matrix T ∈{0, 1}n×n of rhythm A, that is, each
column of T is the circular shift of the ﬁrst column, which corresponds to vector
a. Thus, the matrix T is equal to
T =
⎡
⎢⎢⎢⎣
a0
an−1 an−2 . . . a1
a1
a0
an−1 . . . a2
...
...
...
... ...
an−1 an−2 an−3 . . . a0
⎤
⎥⎥⎥⎦.
We can use the circulant matrix T to impose the tiling conditions as follows. Let
us introduce a literal xi for i = 0, . . . , n −1, that represents the characteristic
vector of the tiling rhythm B, that is, xi = 1 if and only if i ∈B. Note that
a literal is equivalent to a 0–1 variable in ILP terminology. Then, the tiling
condition can be written with the following linear constraint:

i∈{0,...,n−1}
Tijxi = 1,
∀j = 0, . . . , n −1.
(2)
Notice that the set of linear constraints (2) imposes that exactly one variable
(literal) in the set {xn+i−j
mod n}j∈A is equal to one. Hence, we encode this
condition as an Exactly-one constraint, that is, exactly one literal can take the
value one. The Exactly-one constraint can be expressed as the conjunction of
the two constraints At-least-one and At-most-one, for which standard SAT
encoding exist (e.g., see [6,17]). Hence, the tiling constraints (2) are encoded
with the following set of clauses depending on i = 0, . . . , n −1:

j∈A

xn−(j−i)
mod n


k,l∈A,k̸=l

¬xn−(k−i)
mod n ∨¬xn−(l−i)
mod n

.
(3)
Aperiodicity constraints. In view of Deﬁnition 2, if there exists a b ∈B such
that (d+b) mod n ̸= b, then the canon B is not periodic modulo d. Notice that
by Remark 3 we need to check this condition only for the values of d ∈Dn.
We formulate the aperiodicity constraints introducing auxiliary variables
yd,i, zd,i, ud,i ∈{0, 1} for every prime divisor d ∈Dn and for every integer
i = 0, . . . , d −1. We set
ud,i = 1 ⇔
⎛
⎝
n/d−1

k=0
xi+kd = n
d
⎞
⎠∨
⎛
⎝
n/d−1

k=0
xi+kd = 0
⎞
⎠,
(4)
for all d ∈Dn, i = 0, . . . , d −1, with the condition
d−1

i=0
ud,i ≤d −1,
∀d ∈Dn.
(5)

A SAT Encoding to Compute Aperiodic Tiling Rhythmic Canons
19
Similarly to [5], the constraints (4) can be linearized using standard refor-
mulation techniques as follows:
0 ≤
n/d

k=0
xi+kd −n
d yd,i ≤n
d −1
∀d ∈Dn, i = 0, . . . , d −1,
(6)
0 ≤
n/d

k=0
(1 −xi+kd) −n
d zd,i ≤n
d −1
∀d ∈Dn, i = 0, . . . , d −1,
(7)
yd,i + zd,i = ud,i
∀d ∈Dn, i = 0, . . . , d −1.
(8)
Notice that when ud,i = 1 exactly one of the two incompatible alternatives in
the right hand side of (4) is true, while whenever ud,i = 0 the two constraints
are false. Correspondingly, the constraint (8) imposes that the variables yd,i and
zd,i cannot be equal to 1 at the same time. On the other hand, constraint (5)
imposes that at least one of the auxiliary variables ud,i be equal to zero.
Next, we encode the previous conditions as a SAT formula. To encode the
if and only if clause, we make use of the logical equivalence between C1 ⇔C2
and (¬C1 ∨C2) ∧(C1 ∨¬C2). The clause C1 is given directly by the literal ud,i.
The clause C2, expressing the right hand side of (4), i.e. the constraint that the
variables must be either all true or all false, can be written as
C2 =
⎛
⎝
n/d

k=0
xi+kd
⎞
⎠∨
⎛
⎝
n/d

k=0
¯xi+kd
⎞
⎠,
∀d ∈Dn.
Then, the linear constraint (5) can be stated as the SAT formula:
¬

ud,0 ∧ud,1 ∧· · · ∧ud(d−1)

=
d−1

l=0
¯ud,l,
∀d ∈Dn.
Finally, we express the aperiodicity constraints using
d−1

i=0
[(¬C2 ∨ud,i) ∧(C2 ∨¯ud,i)] ∧
d−1

l=0
¯ud,l, ∀d ∈Dn.
(9)
Note that joining (2), (6)–(8) with a constant objective function gives a complete
ILP model, which can be solved with a modern ILP solver such as Gurobi to
enumerate all possible solutions. At the same time, joining (3) and (9) into a
unique CNF formula, we get our complete SAT Encoding of the Aperiodic Tiling
Complements Problem. (see Sect. 4 for computational results).
3.1
Existing Solution Approaches
For the computation of all the aperiodic tiling complements of a given rhythm
the two most successful approaches already known are the Fill-Out Procedure
[14] and the Cutting Sequential Algorithm [5].

20
G. Auricchio et al.
The Fill-Out Procedure. The Fill-Out Procedure is the heuristic algorithm intro-
duced in [14]. The key idea behind this algorithm is the following: given a rhythm
A ⊆Zn such that 0 ∈A, the algorithm sets P = {0} and starts the search for
possible expansions of the set P. The expansion is accomplished by adding an
element α ∈Zn to P according to the reverse order induced by a ranking function
r(x, P), which counts all the possible ways in which x can be covered through
a translation of A. Once every element of Zm\(A ⊕P) has been ranked, the
algorithm tries to add the element with the lowest rank. Adding a new element
deﬁnes a new set, namely ˜P ⊃P, which is again expanded until either it can
no longer be expanded or the set becomes a tiling complement. The search ends
when all the possibilities have been explored. The algorithm ﬁnds also periodic
solutions that must removed in post-processing, as well as multiple translations
of the same rhythm.
The Cutting Sequential Algorithm (CSA). In [5], the authors formulate the Ape-
riodic Tiling Complements Problem using an Integer Linear Programming (ILP)
model that is based on the polynomial characterization of tiling canons. The ILP
model uses auxiliary 0–1 variables to encode the product pA(x) · pB(x) which
characterizes tiling canons. The aperiodicity constraint is formulated analogously
to what done above. The objective function is equal to a constant and has no
inﬂuence on the solutions found by the model. The ILP model is used within a
sequential cutting algorithm that adds a no-good constraint every time a new
canon B is found to prevent ﬁnding solutions twice. In addition, the sequential
algorithm sets a new no-good constraints for every translation of B; hence, in
contrast to the Fill-Out Procedure, the CSA Algorithm needs no post-processing.
4
Computational Results
First, we compare the results obtained using our ILP model and SAT Encoding
with the runtimes of the Fill-Out Procedure and of the CSA Algorithm. We use
the canons with periods 72, 108, 120, 144 and 168 that have been completely
enumerated by Vuza [19], Fripertinger [10], Amiot [1], Kolountzakis and Matolcsi
[14]. Table 1 shows clearly that the two new approaches outperform the state-
of-the-art, and in particular, that SAT provides the best solution approach. We
then choose some periods n with more complex prime factorizations, such as
n = p2q2r = 180, n = p2qrs = 420, and n = p2q2r2 = 900. To ﬁnd aperiodic
rhythms A, we apply Vuza’s construction [19] with diﬀerent choices of parameters
p1, p2, n1, n2, n3. Thus, having n and A as inputs, we search for all the possible
aperiodic complements and then we ﬁlter out the solutions under translation.
Since the post-processing is based on sorting canons, it requires a comparatively
small amount of time. We report the results in Table 2: the solution approach
based on the SAT Encoding is the clear winner. It is also noteworthy that, from a
Music theory perspective, this is the ﬁrst time that all the tiling complements of
the studied rhythms are computed (their number is reported in the last column
of the two tables).

A SAT Encoding to Compute Aperiodic Tiling Rhythmic Canons
21
Table 1. Aperiodic tiling complements for periods n ∈{72, 108, 120, 144, 168}.
n
Dn
p1 n1 p2 n2 n3
runtimes (s)
#B
FOP
CSA
SAT
ILP
72
{24, 36}
2
2
3
3
2
1.59
0.10 < 0.01
0.03
6
108
{36, 54}
2
2
3
3
3
896.06
7.84
0.09
0.19
252
120 {24, 40, 60} 2
2
5
3
2
24.16
0.27
0.02
0.04
18
2
2
3
5
2
10.92
0.14
0.01
0.04
20
144
{48, 72}
4
2
3
3
2
82.53
2.93
0.02
0.11
36
2
2
3
3
4 > 10800.00 > 10800.00
11.04 46.96 8640
2
2
3
3
4
7.13
0.10 < 0.01
0.05
6
2
4
3
3
2
80.04
0.94
0.02
0.08
60
168 {24, 56, 84} 2
2
7
3
2
461.53
17.61
0.04
0.20
54
2
2
3
7
2
46.11
0.91
0.02
0.07
42
Table 2. Aperiodic tiling complements for periods n ∈{180, 420, 900}.
n
Dn
p1 n1 p2 n2 n3
runtimes (s)
#B
SAT
ILP
180
{36, 60, 90}
2
2
5
3
3
2.57
5.62
2052
3
3
5
2
2
0.07
0.14
96
2
2
3
5
3
1.25
2.23
1800
2
5
3
3
2
0.05
0.16
120
2
2
3
3
5
8079.07 > 10800.00 281232
420 {60, 84, 140, 210}
7
5
3
2
2
2.13
3.57
720
5
7
3
2
2
1.52
4.08
672
7
5
2
3
2
7.73
16.11
3120
5
7
2
3
2
1.63
4.18
1008
7
3
5
2
2
4.76
7.45
864
3
7
5
2
2
12.78
32.19
6720
7
3
2
5
2
107.83
1186.21
33480
3
7
2
5
2
0.73
2.36
840
7
2
5
3
2
11.14
21.19
1872
2
7
5
3
2
17.31
52.90
10080
7
2
3
5
2
89.97
691.56
22320
2
7
3
5
2
1.17
4.13
1120
900
{180, 300, 450}
2
25
3
3
2
43.60
110.65
15600
5
10
3
3
2
107.36
741.79
15840
2
9
5
5
2
958.58 > 10800.00 118080
6
3
5
5
2
5559.76 > 10800.00 123840
3
6
5
5
2
486.39
8290.35
62160

22
G. Auricchio et al.
Implementation Details. We have implemented in Python the ILP model and
in PySat [12] the SAT Encoding discussed in Sect. 3. We use Gurobi 9.1.1 as
ILP solver and Maplesat [15] as SAT solver. The experiments are run on a Dell
Workstation with a Intel Xeon W-2155 CPU with 10 physical cores at 3.3GHz
and 32 GB of RAM. The source code and the datasets is freely available on
GitHub at https://github.com/LucaFerra94/tiling-rhytmic-canons.
Conclusions and Future Work. It is thinkable to devise an algorithm that,
for a given n, ﬁnds all the pairs (A, B) that give rise to a Vuza canon of period
n. This could provide in-depth information on the structure of Vuza canons.
Moreover, due to the nature of the problem, it looks like a binary encoder
could improve further the performances and allow us to approach even harder
instances.
Acknowledgements. The authors thank the unknown referees for their valuable
comments and suggestions. This research was partially supported by: Italian Ministry
of Education, University and Research (MIUR), Dipartimenti di Eccellenza Program
(2018–2022) - Dept. of Mathematics “F. Casorati”, University of Pavia; Dept. of Math-
ematics and its Applications, University of Milano-Bicocca; National Institute of High
Mathematics (INdAM) “F. Severi”; Institute for Advanced Mathematical Research
(IRMA), University of Strasbourg.
References
1. Amiot, E.: New perspectives on rhythmic canons and the spectral conjecture. J.
Math. Music 3(2), 71–84 (2009)
2. Amiot, E.: Structures, algorithms, and algebraic tools for rhythmic canons. Per-
spect. New Music 49(2), 93–142 (2011)
3. Anders, T.: Compositions Created with Constraint Programming. The Oxford
Handbook of Algorithmic Music, Oxford University Press, London (2018)
4. Anders, T., Miranda, E.R.: Constraint programming systems for modeling music
theories and composition. ACM Comput. Surv. (CSUR) 43(4), 1–38 (2011)
5. Auricchio, G., Ferrarini, L., Lanzarotto, G.: An integer linear programming model
for tilings. arXiv preprint. arXiv:2107.04108 (2021)
6. Bailleux, O., Boufkhad, Y.: Eﬃcient CNF encoding of boolean cardinality con-
straints. In: Rossi, F. (ed.) CP 2003. LNCS, vol. 2833, pp. 108–122. Springer,
Heidelberg (2003). https://doi.org/10.1007/978-3-540-45193-8 8
7. Chemillier, M., Truchet, C.: Two musical csps. In: CP 01 Workshop on Musical
Constraints, pp. 1–1 (2001)
8. Courtot, F.: A Constraint-Based Logic Program for Generating Polyphonies.
Michigan Publishing, University of Michigan Library, Ann Arbor, MI (1990)
9. Ebcio˘glu, K.: An expert system for harmonizing four-part chorales. Comput. Music
J. 12(3), 43–51 (1988)
10. Fripertinger, H., Reich, L., et al.: Remarks on Rhythmical Canons. Citeseer (2005)
11. Hiller Jr, L.A., Isaacson, L.M.: Musical composition with a high speed digital
computer. In: Audio Engineering Society Convention 9. Audio Engineering Society
(1957)

A SAT Encoding to Compute Aperiodic Tiling Rhythmic Canons
23
12. Ignatiev, A., Morgado, A., Marques-Silva, J.: PySAT: a Python toolkit for proto-
typing with SAT oracles. In: Beyersdorﬀ, O., Wintersteiger, C.M. (eds.) SAT 2018.
LNCS, vol. 10929, pp. 428–437. Springer, Cham (2018). https://doi.org/10.1007/
978-3-319-94144-8 26
13. Kolountzakis, M.N., Matolcsi, M.: Complex hadamard matrices and the spectral
set conjecture. Collectanea Math. Extra 57, 281–291 (2006)
14. Kolountzakis, M.N., Matolcsi, M.: Algorithms for translational tiling. J. Math.
Music 3(2), 85–97 (2009)
15. Liang, J.H.: Machine learning for SAT solvers. Ph.D. thesis. University of Waterloo,
December 2018
16. Pachet, F., Roy, P.: Musical harmonization with constraints: a survey. Constraints
6(1), 7–19 (2001). https://doi.org/10.1023/A:1009897225381
17. Philipp, T., Steinke, P.: PBLib – a library for encoding pseudo-boolean constraints
into CNF. In: Heule, M., Weaver, S. (eds.) SAT 2015. LNCS, vol. 9340, pp. 9–16.
Springer, Cham (2015). https://doi.org/10.1007/978-3-319-24318-4 2
18. Radicioni, D.P., Lombardo, V.: A constraint-based approach for annotating music
scores with gestural information. Constraints 12(4), 405–428 (2007). https://doi.
org/10.1007/s10601-007-9015-y
19. Vuza, D.T.: sets and regular complementary unending canons (part one, two, three,
four). Perspectives of New Music (1991–93)
20. Wiggins, G., Harris, M., Smaill, A.: Representing music for analysis and composi-
tion. In: Proceedings of the 2nd IJCAI AI/Music Workshop, pp. 63–71 (1989)
21. Zimmermann, D.: Modelling musical structures. Constraints 6(1), 53–83 (2001).
https://doi.org/10.1023/A:1009801426289

Transferring Information Across Restarts
in MIP
Timo Berthold1(B)
, Gregor Hendel1, and Domenico Salvagnin2
1 Fair Isaac Germany GmbH, Stubenwald -Allee 19, 64625 Bensheim, Germany
{timoberthold,gregorhendel}@fico.com
2 University of Padova, Via Gradenigo 6/B, 35131 Padova, Italy
salvagni@dei.unipd.it
Abstract. Restarting a solver gives us the chance to learn from things
that went good or bad in the search until the restart point. The beneﬁts
of restarts are often justiﬁed with being able to employ diﬀerent, better
strategies and explore diﬀerent, more promising parts of the search space.
In that light, it is an interesting question to evaluate whether carrying
over detected structures and collected statistics across a restart beneﬁts
the subsequent search, or even counteracts the anticipated diversiﬁcation
from the previous, unsuccessful search.
In this paper, we will discuss four diﬀerent types of global information
that can potentially be re-used after a restart of a mixed-integer pro-
gramming (MIP) solver, present technical details of how to carry them
through a represolve after a restart, and show how such an information
transfer can help to speed up the state-of-the-art commercial MIP solver
FICO Xpress by 7% on the instances where a restart is performed.
Keywords: mixed integer programming · restart · global search
1
Introduction
Restarts have been used in SAT solvers for over 20 years [21]. It was quickly
picked up by the MIP community in the form of root restarts [2,3] and in other
areas of optimization, like global optimization [17]. For an overview on restarting
algorithms in the areas of CP, AI, and OR, see [23]. In this paper we consider
the solution of mixed-integer programs (MIPs), which are optimization problems
of the form
x⋆∈argmin{cT x | Ax ≥b, xj ∈Z for all j ∈I},
with A ∈Rm×n, b ∈Rm, c ∈Rn, and I ⊆{1, . . . , n}.
For some time, restarts for MIP have primarily revolved around the rule
of thumb of restarting the root node processing in the case enough variables
have been globally ﬁxed so that another round of full presolving seems beneﬁ-
cial [2]. More recently, restarts of the tree search have gained attention in the
MIP community, see, e.g., [6], and most MIP solvers employ them nowadays
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 24–33, 2022.
https://doi.org/10.1007/978-3-031-08011-1_3

Transferring Information Across Restarts in MIP
25
[11,13,18]. Unlike root restarts, tree restarts are often based on an extrapo-
lation of the remaining time until the tree search is ﬁnished [16]. In contrast
to SAT solving, aggressive periodic restarts of the tree search have not proven
advantageous for MIP in the vast majority of cases for a few reasons:
1. Solving the initial root problem of a MIP is often orders of magnitude more
expensive than solving a local node. This makes tree restarts in the early
phase of the search way more expensive than their SAT counterpart.
2. While in SAT the set of learned conﬂicts completely describes the search
space already explored, at least until conﬂict purging kicks in, the same does
not apply to the MIP case, where the search strategy is hardly ever a pure
DFS and conﬂict clauses are not always learnt. Thus, a tree restart inevitably
leads to some redundant work being performed.
3. MIPs are only very rarely feasibility problems, where a tree restart might just
be beneﬁcial because it makes the algorithm ﬁnd a feasible solution sooner
that it would have done without. The optimality proof requires a certain
amount of search to be performed no matter what, making restarts in a later
phase of the search unattractive, if not harmful.
For those reasons, MIP solvers typically apply very few tree restarts (only
one in most cases) and aim at addressing diﬀerent types of problems with the
solver behavior before and after said restarts. The solvers use settings aimed
at easy problems in the ﬁrst phase. Those will typically spare some expensive
subroutines and make those problems solve faster. If a restart is conducted, the
solver is aware that this problem is relatively hard to solve and will require a
certain amount of tree search. Thus, it can adapt and employ more aggressive
settings and expensive additional techniques right from the beginning of the
subsequent searches. Furthermore, a restart might help in mitigating and even
exploiting performance variability eﬀects [19].
Given that one of the primary purposes of tree restarts is to make the search
after the restart diﬀerent from the one before, it is not obvious to which extent
information from a given tree search should be carried over to be used in the
next search second run, and which type of information is most suitable for such
a transfer. The goal of this paper is to address these questions and evaluate
the impact of global information transfer, taking the solver restart strategy as a
given.
2
Global Information
A main diﬀerence between MIP and CP solvers is how constraints interact with
each other. In CP solvers, the variables’ domain is the central communication
object, and each constraint individually contributes to tightening the domain
store and guiding the search by propagation. Hence, information is processed
very locally, on a constraint-by-constraint level. In MIP solvers, the central object
is the LP relaxation, which is solved to optimality, considering all constraints
simultaneously.

26
T. Berthold et al.
This is our role model for what we would like to call global information. The
data structures that we consider for transfers across restarts have in common that
they can connect pieces of information from multiple constraints into a single
structure, and the information contained therein is globally valid for the problem
at hand. Some of them are gained during the search, like cutting planes [25] and
pseudo-costs [8], and they depend on algorithmic choices of the solver. Hence,
rerunning the search with slightly diﬀerent start conditions would lead to con-
structing a diﬀerent object. Others, like the implication graph [24], are detected
in presolving or during root node processing. These structures might only be
partially created for large input problems as the involved detection procedures
use certain work limits. Again, a slight change in start conditions would lead
to a diﬀerent result, and we cannot simply recollect the exact same information
after a restart.
We will now brieﬂy sketch each type of global information relevant to the
present work. For an introduction to how global structures can be used for
primal heuristics, see [14].
The Conﬂict Pool. MIP solvers attempt to create conﬂicts whenever pruning a
node due to infeasibility or cutoﬀ. They are generated by analyzing the sequence
of branching decisions and propagations that led to the node being pruned, with
the aim of extracting a small subset of those bound changes as an explanation
for the infeasibility. From such a conﬂict, we can derive a conﬂict clause which is
typically formulated as a disjunction of bounds [1]. A conﬂict clause is a globally
valid, not necessarily linear, constraint that states that at least one of the bounds
in the conﬂict must take a diﬀerent value than in the infeasible subproblem. Note
that it is equivalent to state the conﬂict as a conjunction of the bound changes
that led to infeasibility. This is how Xpress stores conﬂict clauses. MIP solvers
typically collect conﬂicts in a pool, see, e.g., [29] and only keep them for a certain
number of nodes. The content of this pool highly depends on the search tree,
and how much of it has already been traversed.
Cutting Planes. Throughout the search, and in particular at the root node, MIP
solvers generate cutting planes to tighten the LP relaxation, improve the dual
bound, and reduce the number of fractional variables. For an overview on cuts
in MIP, see [20,27,30]. Globally valid cutting planes, as those separated at the
root, can be either directly added to the current LP relaxation or added to a
so-called cut pool, from which they can be separated again on demand, e.g.,
at subsequent nodes [25]. Transferring globally valid cuts after restarts can be
eﬀective in a twofold way: a) we can warmstart the root cutloop with a set of
cuts which have proven useful at the previous root node and b) if we take them
into account while represolving they can lead to further reductions.
The Implication Graph. An implication is a relation between two variables that
state that a bound change in one variable leads to a bound change in another
variable. E.g., for y ≤ax+b, it holds that a tightened upper bound on x implies
an upper bound on y, which is potentially tighter than the current upper bound.

Transferring Information Across Restarts in MIP
27
The set of all such (known) relations for a MIP can be represented as a directed
graph, where each arc represents an implication and each node represents a
bound change on a variable [24]. Implications might be directly deduced from
single constraints but, much more interestingly, we might ﬁnd them by probing,
i.e., the process of tentatively changing the bound of a variable and propagating
this bound change. Since probing is relatively expensive, it is typically not done
on all variables but only on a few promising ones under tight working limits.
Pseudo-costs. On MIP problems with a nonzero objective function, branching
decisions that raise the LP objective, and hence the node dual bound in the
created children, are essential to prune subproblems and thus create small search
trees quickly. The pseudo-costs [8] of a variable xj summarize the average change
of the LP objective observed after branching on xj. Prioritizing variables based
on their recorded pseudo-costs is still a state-of-the-art selection strategy because
it provides a good selection quality that is computationally cheap to evaluate.
For a recent overview on branching in MIP, see [12]. The main disadvantage of
pseudo-costs is that they are uninitialized at the beginning of the search, when
the most crucial top-level branching decisions have to be made. The typical
remedy is to perform an explicit look-ahead called strong branching [22] for a
number of times [5,15], to make an informed branching selection and initialize
the pseudo-costs of the tested candidates. In the context of tree restarts, pseudo-
costs from the ﬁrst run can be transferred to have branching statistics available
right from the beginning of the subsequent search.
3
Implementation Details
This section highlights the algorithmic choices in FICO Xpress [11] regarding the
transfer of global information across restarts. Trivially, we always transfer the
primal and dual bounds from a previous run. Further, we preserve the incumbent
solution, although it may not remain feasible for the remaining search problem
due to additional presolving, in which variables might be ﬁxed to solution values
that diﬀer from their value in the incumbent solution, e.g., by dual reductions [4]
or even reduced cost ﬁxing.
Mapping Between Presolve Spaces. Whether in the tree or at the root, one
major eﬀect of a restart is that the problem gets (re)-presolved another time.
To transfer a piece of information across a restart, we need to be able to map a
mathematical object involving variables in the presolve space before the restart
to the corresponding mathematical object (if any) involving variables in the
presolve space after the restart.
We compute a mapping between the two presolve spaces in the following way.
Independent of restarts, the solver maintains a stack with the presolve reduc-
tions applied so far, as this is needed, among other things, to map presolved
solutions back to the original space. When represolving, new reductions are sim-
ply appended to the very same stack. To compute a mapping between the two

28
T. Berthold et al.
spaces, we initialize the mapping to the identity and then process the new pre-
solve reductions, in the order in which they were added to the stack, and update
the mapping accordingly, depending on the logic of each individual reduction.
In particular, for each variable in the old presolve space, we distinguish the
following cases:
1. the variable got ﬁxed to some value and hence removed from the problem. In
this case, we mark the variable as ﬁxed in the mapping and store the value
it was ﬁxed to.
2. the variable was carried through unmodiﬁed but has potentially a diﬀerent
index in the new presolved space. We simply store the new index of the
variable.
3. the variable changed meaning (e.g., it changed type) or was eliminated in
such a way that its value can only be computed a-posteriori during the post-
solve phase. In this case, we mark the variable as unmappable. Any object
involving an unmappable variable will become unmappable itself and thus
not transferred across a restart.
Another essential piece of information that we need for a correct transfer is
scaling [26]. However, scaling itself is not considered a presolve reduction in
FICO Xpress, and thus it does not contribute to the stack. Still, we need to
keep track of the scaling factors (w.r.t. the original problem) before and after
represolve to compute the intermediate scaling factors between the two presolve
spaces. Note, however, that integer variables are never scaled.
Pseudo-costs. For each variable that is still mappable after a represolve, we con-
dense the entire pseudo-costs from both strong branches and regular branches
on a variable x from the old run into a single pseudo-cost record, in the spirit
of [9]. As a result, we have initialized pseudo-costs available from the beginning
of the search in the new run. They are not considered reliable [5] yet, such that
also these variables will eventually be subject to further strong branching eval-
uations. When recording new branching information during the new run, the
obtained, more recent pseudo-cost information eventually outweighs the trans-
ferred information.
The transfer of the variable branching history follows the intuition that the
transferred information is still accurate when the problem does not change too
much during a represolve. Following this logic, we keep track of the relative
change in the number of rows, columns, and matrix nonzero elements after the
restart. If one of these numbers changes by more than 10% (5% in the case
of rows), we discard the collected pseudo-costs and start the search with all
pseudo-costs uninitialized.
Conﬂicts. Conﬂicts stored in the conﬂict pool are processed one by one, using
the mapping and scaling factors computed after represolve. Given a conﬂict in
conjunctive form, each bound change is mapped to the new space individually,
leading to one of the following cases:

Transferring Information Across Restarts in MIP
29
1. the bound change is on an unmappable variable: the conﬂict will be dropped;
2. the bound change is on a ﬁxed variable: depending on the ﬁxing value, we can
either drop the bound change from the conﬂict (because it is always satisﬁed)
or drop the conﬂict itself (the condition is never satisﬁed and thus the conﬂict
would be useless);
3. the bound change is on another variable: simply update to the new index.
If a conﬂict survives the mapping process, it is ﬁnally dealt with as follows:
1. if the conﬂict is now empty, the problem is infeasible, and we can stop imme-
diately;
2. if the conﬂict has size one, we turn it into a globally valid bound change;
3. otherwise, the conﬂict is added to the new conﬂict pool.
Implication Table. Processing of the implication table is by far and large similar
in spirit to the processing of the conﬂict pool. Each implication in the table is
mapped individually, and the outcome depends on a few cases:
1. if either the implying or the implied variable is unmappable, then the impli-
cation itself is discarded;
2. if either the implying or the implied variable is ﬁxed, then we can turn the
implication into a globally valid bound on the other variable. If both variables
got ﬁxed, the implication either directly proves infeasibility or is redundant
and can be discarded.
3. if both variables survived, we map the implication by updating the indices of
the involved variables and recomputing the coeﬃcients using the intermediate
scaling factors.
Cuts. While we could implement the mapping of globally valid cutting planes
with the same logic that we used for conﬂicts and implications, the represolve
of cuts follows a completely diﬀerent logic for historical and technical reasons.
In particular:
1. ﬁrst, cuts are temporarily added to the problem before represolve, as if they
were regular constraints in the model;
2. then, we execute the represolve;
3. ﬁnally, the (surviving) cuts are removed again from the model and added to
the new global cut pool.
There are advantages and disadvantages to this strategy: on the one hand, the
presence of cutting planes in the model might hinder some reductions, like col-
umn domination; on the other hand, their presence could also lead to a stronger
presolved model, as bound tightening can in principle derive tighter bounds
exploiting the additional constraints for propagation. In general, cutting planes
prevent those reductions that would make the cuts themselves unmappable,
which again can be argued both for and against. We did not experiment with
alternative approaches, as our current strategy works well in practice: however,
that is certainly an interesting direction for future research.

30
T. Berthold et al.
4
Computational Experiments
In this section, we evaluate the transfer of global information across represolves
computationally. To this end, we perform two runs with the recently released
FICO Xpress 8.13 solver, with the transfer of global information enabled and
disabled, respectively. As benchmark set we use a mix of publicly available and
customer MIP instances that also serves as one of the main test sets in our
daily Xpress MIP development. In order to mitigate the eﬀect of performance
variability, we solve three permutations of each of these 619 MIP instances,
resulting in a testbed of 1857 instances in total: the unpermuted model and two
cyclic permutations [10] characterized by a diﬀerent initial random seed used for
perturbing the rows, columns, and integer variables of the instance.
Both runs are performed on a cluster of 64 identical machines, each equipped
with 2 Intel(R) Xeon(R) CPUs E5-2640 v4 @ 2.40 GHz and 64 GB of memory.
We set a time limit of 4 h, equaling 14400 s, and allow each job to use 20 parallel
threads.
Table 1. Computational results obtained when enabling or disabling the transfer of
global information across restarts.
no-transfer
transfer
relative
Class
N
Solved
Time
Nodes
Solved
Time
Nodes
Time Nodes
all
1857
1844
72.97
760
1846
71.03
694
0.97
0.91
[10,14400}
1802
1798 108.22
1039
1800 104.97
952
0.97
0.91
[100,14400}
685
681 409.56
4167
683 390.44
3615
0.95
0.87
aﬀected instances
all
670
662 113.77
8781
664 105.97
6841
0.93
0.78
[10,14400}
565
561 165.65
17191
563 153.08
13638
0.92
0.79
[100,14400}
338
334 434.21
44505
336 393.87
33397
0.91
0.75
We summarize the results of this experiment in Table 1. The table shows
solved instances, time, and nodes for both tested versions for diﬀerent instance
classes. The top part of the table shows the results for subsets of the entire
instance bed. The bottom part of the table shows the results only for aﬀected
instances, i.e., instances on which the transferred global information aﬀects the
solver behavior after the restart. The instance class all in the ﬁrst row shows the
results for the entire testbed. For each class, the number of involved instances
is shown in column N. We also present the results for two bracketed subsets
[10, 14400} and [100, 14400}. A bracketed subset consists of all instances that
could be solved by at least one of the two tested versions, and the slower of the
two solves took at least 10 or 100 s or timed out, respectively. The bracketing
convention is helpful to ﬁlter instances that are solved fast by both versions.
Time and node results use a shifted geometric mean [2] with shift values of 10 s
and 100 nodes.

Transferring Information Across Restarts in MIP
31
The overall results suggest that transferring global information is valuable
for the search procedure across the considered subsets of instances, yielding an
overall time improvement of 3 % and node improvement of 9 %. The table shows
that the number of aﬀected instances amounts to roughly one-third of the test
set, which is almost all instances for which FICO Xpress actually performs a
restart.
On the aﬀected instances, the performance improvements are naturally more
pronounced. Overall, we see a gain of 7% time and 22% nodes. The observed
improvement amounts to 9% time and 25% nodes on the most challenging
bracket. All time and node improvements are signiﬁcant according to a Wilcoxon
signed rank test [28] with a conﬁdence level of 95%.
Especially the reduction in the solving nodes is a clear indication that the
transfer of global information helps the search to make better decisions in the
second run. When comparing the relative reduction in time and nodes, we see
that the transferred global information comes at a cost. Especially the transferred
cutting planes increase the size of the matrix, which increases the time to solve
the node LP relaxations in the second run.
When testing the transfer of individual pieces of global information, we found
that transferring cutting planes across represolves leads to the most substantial
improvements. Transferring cutting planes alone causes a change in the solution
path on almost all of the aﬀected instances in Table 1, and is responsible for a
speed up of 3 %, across all of the considered brackets. Transferring pseudo-costs
only also gives a signiﬁcant speedup, albeit a bit smaller than the one from
cutting planes. A reason for this is that fewer instances (194) are aﬀected by the
change: this is partially due to the fact that pseudo-cost transfer will only aﬀect
tree restarts, but not root restarts, and partially due to the employed limits on
the relative change in the represolved problem. However, if we restrict to the set
of instances aﬀected by the change, transferring pseudo-costs is responsible for
a speed up of 5 %. As for the two remaining types of global information, namely
conﬂicts and implications, our experiments show a performance-neutral result
or slightly detrimental performance impact when transferred across restarts.
In particular, transferring the implication graph is performance-neutral to 1%
improvement, depending on the bracket you consider. Our interpretation is that
many of the implications would be rediscovered in presolving and probing in the
second run anyway, so there is not much value. This was also a reason for not
yet trying to transfer the clique table, which is similar in nature. Finally, for
conﬂicts, we observed slightly detrimental behavior, which surprised us because
conﬂicts carry global information that cannot be easily, and cheaply, recomputed.
Our explanation for this is that the transfer of old conﬂicts together with the
strict limits on the overall conﬂicts pool size prevents fresh conﬂicts from being
learned. This clearly asks for a more careful re-tuning which is part of future
work.

32
T. Berthold et al.
5
Conclusion and Outlook
In this paper we showed that transferring some pieces of global information
across a restart can be quite beneﬁcial for the performance of a state of the art
MIP solver, both in terms of average runtime and size of the resulting enumer-
ation tree.
As future work we plan to investigate why transferring some of the global
structures, namely conﬂicts and implications, did not result in a measurable
performance improvement, and extend the transfer to additional structures, most
notably the cliques in the global clique table [7].
References
1. Achterberg, T.: Conﬂict analysis in mixed integer programming. Discrete Optim.
4(1), 4–20 (2007)
2. Achterberg, T.: Constraint integer programming. Ph.D. thesis, Technische Univer-
sit¨at Berlin (2007)
3. Achterberg, T.: SCIP: solving constraint integer programs. Math. Programm. Com-
put. 1(1), 1–41 (2009). https://doi.org/10.1007/s12532-008-0001-1
4. Achterberg, T., Bixby, R.E., Gu, Z., Rothberg, E., Weninger, D.: Presolve reduc-
tions in mixed integer programming. Informs J. Comput. 32(2), 473–506 (2020)
5. Achterberg, T., Koch, T., Martin, A.: Branching rules revisited. Oper. Res. Lett.
33(1), 42–54 (2005)
6. Anderson, D., Hendel, G., Le Bodic, P., Viernickel, M.: Clairvoyant restarts in
branch-and-bound search using online tree-size estimation. Proc. AAAI Conf. Artif.
Intell. 33(01), 1427–1434 (2019)
7. Atamt¨urk, A., Nemhauser, G.L., Savelsbergh, M.W.: Conﬂict graphs in solving
integer programming problems. Eur. J. Ope. Res. 121(1), 40–55 (2000)
8. B´enichou, M., Gauthier, J.M., Girodet, P., Hentges, G., Ribi`ere, G., Vincent, O.:
Experiments in mixed-integer programming. Math. Programm. 1, 76–94 (1971)
9. Berthold, T., Feydy, T., Stuckey, P.J.: Rapid learning for binary programs. In:
Lodi, A., Milano, M., Toth, P. (eds.) CPAIOR 2010. LNCS, vol. 6140, pp. 51–55.
Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-13520-0 8
10. Berthold, T., Hendel, G.: Learning to scale mixed-integer programs. Proc. AAAI
Conf. Artif. Intell. 35(5), 3661–3668 (2021)
11. FICO
Xpress
Optimization
(2021).
https://www.ﬁco.com/en/products/ﬁco-
xpress-optimization
12. Gamrath, G.: Enhanced predictions and structure exploitation in branch-and-
bound. Ph.D. thesis, Technical University Berlin (2020)
13. Gamrath, G., et al.: The SCIP Optimization Suite 7.0. Technical report 20–10,
ZIB (2020)
14. Gamrath, G., Berthold, T., Heinz, S., Winkler, M.: Structure-driven ﬁx-and-
propagate heuristics for mixed integer programming. Math. Programm. Comput.
11(4), 675–702 (2019). https://doi.org/10.1007/s12532-019-00159-1
15. Hendel, G.: Enhancing MIP branching decisions by using the sample variance of
pseudo costs. In: Michel, L. (ed.) CPAIOR 2015. LNCS, vol. 9075, pp. 199–214.
Springer, Cham (2015). https://doi.org/10.1007/978-3-319-18008-3 14
16. Hendel, G., Anderson, D., Le Bodic, P., Pfetsch, M.E.: Estimating the size of
branch-and-bound trees. Informs J. Comput. 34(2), 934–952 (2021)

Transferring Information Across Restarts in MIP
33
17. Hu, X., Shonkwiler, R., Spruill, M.C.: Random restarts in global optimization.
Technical report, Georgia Institute of Technology (2009)
18. ILOG CPLEX Optimization Studio 12.10.0 (2019). https://www.ibm.com/docs/
en/icos/12.10.0?topic=v12100-changes-log
19. Lodi, A., Tramontani, A.: Performance variability in mixed-integer programming.
In: Theory Driven by Inﬂuential Applications, pp. 1–12. INFORMS (2013)
20. Marchand, H., Martin, A., Weismantel, R., Wolsey, L.A.: Cutting planes in integer
and mixed integer programming. Discrete Appl. Math. 123(124), 391–440 (2002)
21. Moskewicz, M.H., Madigan, C.F., Zhao, Y., Zhang, L., Malik, S.: Chaﬀ: engineering
an eﬃcient SAT solver. In: Proceedings of the 38th Annual Design Automation
Conference, pp. 530–535. DAC 2001. Association for Computing Machinery (2001)
22. Nemhauser, G.L., Wolsey, L.A.: Integer programming and combinatorial opti-
mization Wiley. Chichester. GL Nemhauser, MWP Savelsbergh, GS Sigismondi
(1992).Constraint Classiﬁcation for Mixed Integer Programming Formulations.
COAL Bulletin, vol. 20, pp. 8–12 (1988)
23. Pokutta, Sebastian: Restarting algorithms: sometimes there is free lunch. In:
Hebrard, Emmanuel, Musliu, Nysret (eds.) CPAIOR 2020. LNCS, vol. 12296, pp.
22–38. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58942-4 2
24. Savelsbergh, M.W.P.: Preprocessing and probing techniques for mixed integer pro-
gramming problems. ORSA J. Comput. 6(4), 445–454 (1994)
25. Savelsbergh, M.W.P., Sigismondi, G.C., Nemhauser, G.L.: Functional description
of MINTO, a mixed integer optimizer. Technische Universiteit Eindhoven (1991)
26. Tomlin, J.A.: On scaling linear programming problems. In: Balinski, M.L., Heller-
man, E. (eds) Computational practice in mathematical programming. Mathemati-
cal Programming Studies vol. 4, pp. 146–166. Springer, Berlin, Heidelberg (1975).
https://doi.org/10.1007/BFb0120718
27. Tramontani, A.: Enhanced mixed integer programming techniques and rout-
ing problems. Ph.D. thesis, Springer (2011). https://doi.org/10.1007/s10288-010-
0140-x
28. Wilcoxon, F.: Individual comparisons by ranking methods. Biometrics Bull. 1, 80–
83 (1945)
29. Witzig, J., Berthold, T., Heinz, S.: Experiments with conﬂict analysis in mixed
integer programming. In: Salvagnin, D., Lombardi, M. (eds.) CPAIOR 2017. LNCS,
vol. 10335, pp. 211–220. Springer, Cham (2017). https://doi.org/10.1007/978-3-
319-59776-8 17
30. Wolter, K.: Implementation of cutting plane separators for mixed integer programs.
Master’s thesis, Technische Universit¨at Berlin (2006)

Towards Copeland Optimization
in Combinatorial Problems
Sidhant Bhavnani1
and Alexander Schiendorfer2(B)
1 University of Glasgow, Glasgow, Scotland
2482327b@student.gla.ac.uk
2 Technische Hochschule Ingolstadt, Ingolstadt, Germany
alexander.schiendorfer@thi.de
Abstract. Traditional approaches to fairness in operations research and
social choice, such as the egalitarian/Rawlsian, the utilitarian or the
proportional-fair rule implicitly assume that the voters’ utility functions
are – to a certain degree – comparable. Otherwise, statements such as
“maximize the worst-oﬀvoter’s utility” or “maximize the sum of utili-
ties” are void. But what if the diﬀerent valuations should truly not be
compared or converted into each other? Voting theory only relies on
ordinal information and can help to provide democratic rules to deﬁne
winning solutions. Copeland’s method is a well-known generalization of
the Condorcet criterion in social choice theory and asks for an outcome
that has the best ratio of pairwise majority duel wins to losses. If we
simply ask for a feasible solution to a combinatorial problem that maxi-
mizes the Copeland score, we are at risk to encounter intractability (due
to having to explore all solutions) or suﬀer from (the lack of) irrelevant
alternatives. We present ﬁrst results from optimizing for a Copeland
winner to a constraint problem formulated in MiniZinc in a local search
fashion based on a changing solution pool. We investigate the eﬀects of
diversity constraints on the quality of the estimated Copeland score as
well as the gap between the best reported Copeland scores to the actual
Copeland scores.
Keywords: Constraint Programming · Social Choice Theory · OR
1
Solving Combinatorial Problems by Voting
Many constraint problems involve the preferences of multiple (human or soft-
ware) agents – at times even a large number of them in a committee that needs
to make joint decisions. Think of designing a new transport network with sev-
eral bus lines that need to connect stops or agreeing on a travel itinerary subject
to time windows of availability of sights. In such cases, each voter n ∈N has
their own preference ordering ⪯n over the set of possible outcomes O which
This research has been sponsored by DAAD Research Internships in Science and Engi-
neering (RISE).
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 34–43, 2022.
https://doi.org/10.1007/978-3-031-08011-1_4

Towards Copeland Optimization in Combinatorial Problems
35
SoluƟons
ValuaƟons
Ballots / Preference Proﬁle
Voter 1
#1
#2
#3
#4
#5
Ranks
Voter 2
Voter 3
Pairwise Majority Tournament
3:0
2:1
2:1
2:1
1
4
2
1
2
Copeland 
scores
Fig. 1. The problem considered in this paper. Left: Solutions to a combinatorial prob-
lem (infeasible ones are grayed out) are valued using classical objective functions by
three voters. All use a completely diﬀerent domain of values – satisfaction degrees
in [0, 1], costs to minimize, or sets of violated constraints. Center: The solutions are
ranked ordinally according to the voters’ valuations. Right: A tournament where an
edge indicates which option wins a duel; θ3 has the highest Copeland score.
is the solution space of a constraint satisfaction problem. Classical approaches
in operations research and optimization then turn to utility functions (fn)n∈N
and apply (i) the utilitarian rule [17]: maximizex

n∈N fn(x), (ii) the egalitar-
ian or Rawlsian rule [24]: maximizex minn∈N fn(x), or (iii) the proportional-fair
rule [1,19] which chooses x such that 
n∈N
fn(x′)−fn(x)
fn(x)
is negative for all other
x′. All of these rules assume the utilities to map to a comparable “scale” to be
semantically well-deﬁned.
But in many applications, the domains of these valuations need not be com-
parable (see Fig. 1) – even if they are expressed quantitatively: A (normalized)
value of 0.9 for voter i, e.g., is not necessarily “better” than 0.8 for agent j ̸= i.
Instead of trying to convert one agent’s “utility units” into another one’s, we
strive for a purely ordinal approach. The ﬁeld of social choice theory [2], in
particular voting theory, oﬀers a mathematical framework to aggregate several
individual orderings into a single ordering representing the group through social
welfare functions (SWF) or social choice functions (SCF) such as the methods by
Condorcet, Copeland, Borda, or majority-based rules. For example, Copeland’s
method asks to ﬁnd a candidate that wins the highest number of pairwise major-
ity duels with other candidates (called the Copeland score – see Fig. 1 right).
Most often, SWFs and SCFs are considered over small ﬁnite sets of outcomes
(also called “candidates” due to the heritage of politics). If we aim to apply SCF-
s/SWFs to a large set of candidates such as the solution space of a combinatorial
problem, enumerating them all is out of the question.
In this paper, we present a sampling-based algorithm that sequentially adds
new solutions to (and deletes old ones from) a solution pool to maximize an
approximate underlying true Copeland score (see Fig. 2). Since this solution pool
represents – statistically speaking – a sample of the set of all feasible solutions
that would be required to determine the actual Copeland score, during optimiza-
tion we face a “moving target”, i.e., a solution might have a high Copeland score
on this particular sample but not overall and the objective value (i.e., Copeland)
changes as we explore more solutions. Hence, this paper contributes:

36
S. Bhavnani and A. Schiendorfer
– A formulation of Copeland optimization as a novel modeling method for com-
binatorial problems involving several voters (see Sect. 2).
– The sampling-based meta-search algorithm with a solver-independent imple-
mentation using MiniZinc (see Sect. 3).
– An experimental study that investigates how techniques from constraint pro-
gramming (diversity maximization [13]) can aid in selecting a high-quality
solution pool for reliable Copeland estimates (see Sect. 4).
1.1
Related Work
The strong connections between collective decision making and constraint rea-
soning have been pointed out by Rossi in 2014 [20], most notably leading to a
sequential voting procedure [6,7] to connect social choice theory and constraint
solving. Since then the CP community has reached a higher level of maturity in
its constraint solvers and, especially, its modeling languages such as OPL [12],
Essence [10], or MiniZinc [18]. Simple Condorcet-voting on top of MiniZinc has
been shown to remove bias introduced by weight aggregation in [22]. Of course,
pure multi-criteria optimization deals with multiple objectives, most notably
via ﬁnding Pareto frontiers or minimizing distances to Utopian points [8]. Every
stakeholder’s preference needs to be encoded as one of the utility functions. Solv-
ing for a large number of objectives, however, leads to very indecisive optimiza-
tion criteria [22]. Along those lines, [4] discuss Rawlsian and Utilitarian utility
aggregation in a socially desirable sense but work with a common currency that
we want to avoid. Copeland voting has been applied in combinatorial optimiza-
tion [3] but with a focus on hyperparameter/heuristics selection for evolutionary
algorithms, not as the objective of the modeled optimization problem itself.
Finally, while the distributed constraint optimization (DCOP) community has
produced remarkable results in transferring search and propagation algorithms
to distributed computing environments [9], there has been little discussion about
what to optimize for other than a sum of utilities.
2
Foundations: Social Choice and (Soft) CSPs
A constraint satisfaction problem (CSP) is deﬁned by a ﬁnite set of variables X
with their associated domains of possible values (Dx)x∈X where at least some
domain is discrete, and a set of constraints C. A (variable) assignment θ is a map
X →D such that θ(x) ∈Dx, for every variable x. It is feasible if θ |= c holds for
every constraint c ∈C and then called a solution. Finding a solution to a CSP
is, in general, NP-complete [21]. A CSP usually becomes a constraint optimiza-
tion problem (COP) by adding an objective function f : [X →D] →(F, ≥F )
where F represents a (at least partially) ordered set, usually (R, ≥). We seek
an assignment θ∗with either maximal or minimal value f(θ∗). Especially in the
context of (algebraic) soft constraints that can be abstracted to a c-semiring or
(partial) valuation structure taking the role of F, several formalisms other than
real-valued objective functions have been motivated and investigated [14,16].

Towards Copeland Optimization in Combinatorial Problems
37
Examples include sets of violated constraints, satisfaction degrees, or valuation
tuples in the case of Pareto and lexicographic combinations [11]. If we have
multiple objective functions (fi)i∈N for a set of voters/agents N, we face a
multi-objective COP with potentially |N| diﬀerent valuation domains (Fi)i∈N –
then also frequently called utility functions. To combine the several orders over
solutions emerging from these objective functions in a purely ordinal way, we
turn to social choice theory:
Let N = {1, . . . , n} be a set of voters and O a ﬁnite set of outcomes. For
every voter i ∈N, we assume a linear preorder ⪰i (ties allowed) over O where
o1 ⪰i o2 indicates that voter i prefers o1 over o2. We call (⪰n)n∈N a preference
proﬁle. The pairwise majority relation ≥μ over O is deﬁned by:
o1 ≥μ o2
if and only if
|{i | i ∈N ∧o1 ⪰i o2}| ≥|{i | i ∈N ∧o2 ⪰i o1}|
A social choice function SCF takes a preference proﬁle and returns a set of
winners W = SCF((⪰n)n∈N) ⊆O. It satisﬁes the Condorcet criterion if W =
{oc} for all proﬁles where oc is a Condorcet winner, i.e., an option that wins all
pairwise duels: oc ≥μ o, ∀o ̸= oc ∈O. A Condorcet winner needs not exist due
to cycles in the pairwise majority relation [2].
There are several extensions to the Condorcet criterion. A rather straight-
forward extension is the (asymmetric) Copeland score C which awards one point
for each won pairwise majority duel and a half point for ties:
C(o) = |{o′ ∈O | o >μ o′}| + 1
2|{o′ ∈O | o′ =μ o}|
It is natural to ask for an SCF that picks the Copeland winners as outcomes, i.e.,
those with the highest Copeland score – then called Copeland’s rule [5]. Note
that Copeland rewards an outcome for each victory – regardless of the margin.
When we return to our original problem, we set O = [X →D], i.e., each
solution is a possible outcome to a voting problem and have
θ1 ⪰i θ2 ⇔fi(θ1) ≥Fi fi(θ2)
for every voter i ∈N. This is a well-deﬁned preference proﬁle over solutions –
albeit a potentially exponential number of outcomes. Asking for a solution
θ∗
C = arg max
θ
C(θ)
that maximizes the Copeland score is not a classical objective function f : [X →
D] →F which only depends on the variable assignments but must be mea-
sured with respect to – in theory – all solutions. In our experiments, we use a
normalized variant of C and call it ¯C with ¯C(o) = C(o)
|O| .
3
Sampling Approach
To solve for θ∗
C exactly, we would have to explore all solutions to the underlying
CSP. For many problems, this set is prohibitively large. We, therefore, suggest
a sampling-based approach, as shown in Fig. 2.

38
S. Bhavnani and A. Schiendorfer
Sample Solution Pool
Voter 1
#1
#2
#3
Voter 2
Voter 3
Sample Ballots
Sample Tournament
0
2
1
3:0
2:1
3:0
Delete weak solutions
Explore new solutions
Updated Solution Pool
Diversity Constraints
Default Search
0
Fig. 2. An iterative approach to approximately searching a Copeland winner. The solu-
tion pool is a sample from all solutions (cf. Figure 1) and maintaining a representative
sample is essential to reliably estimate Copeland scores.
We start with a CSP formulated in a modeling language – MiniZinc in our
case. The valuations (fn)n∈N are modeled as decision variables that are appro-
priately constrained1. That way, we get a linear preorder ⪰n (due to possible
ties) over solutions for every voter n even though, initially, the feasible solutions
are not known.
In every iteration, new solutions are explored and weak solutions are deleted
from a sample (called the solution pool) – both ratios are adjustable parameters.
It is known [2] that SWFs/SCFs based on pairwise majority such as Copeland
may suﬀer from irrelevant alternatives which may change the relative ordering
of two options, that is, if o1, o2 ∈O and o1 ∈WSCF(O) it might be that o1 ̸∈
WSCF(O∪O′) for some alternatives O′ with O′ ∩O = ∅. This can become an issue
for the proposed sampling approach: if we (unfortunately) picked a solution pool
purely consisting of bad solutions in terms of the underlying Copeland scores,
a solution that looks excellent in this pool might be far oﬀthe true Copeland
winners’ scores. Being aware of these theoretical limitations, we hope to mitigate
them “in practice” by optimizing the chosen solution pool – ideally to be a
representative sample of the whole search space.
To do so, we instruct solvers to maximize the diversity to existing solutions,
using a modular model fragment similar to an approach presented in [13]:
array[int] of var int: vars; % variables
of
interest
that
should be
diverse
array[int , index_set(vars )] of int: pool; % old
solutions
as
parameter
array[ index_set_1of2(pool), index_set(vars )] of var int: div_abs_dists ;
constraint
forall(i in
index_set_1of2(pool), j in
index_set_2of2(pool ))(
div_abs_dists [i, j] = abs(pool[i, j] - vars[j])
);
% Offered
objective
function
as
decision
variables
- can be
maximized
var int: diversity_abs = sum( div_abs_dists );
This diversity fragment can be tied to any MiniZinc model by equating the
vars array to the actual variables of interest and maximizing div abs dists.
The next found solution maximizes the sum of absolute distances to the the
1 Our implementation indeed uses integer variables for utilities that need to be maxi-
mized but nothing prohibits more general “is-better” predicates.

Towards Copeland Optimization in Combinatorial Problems
39
previously found solutions. Additionally, it has been pointed out that demanding
full independence of irrelevant alternatives might be too restrictive in the face
of many (substitutable) alternatives [15].
4
Experimental Evaluation
We implemented the proposed sampling approach and evaluated it on several
typical combinatorial benchmark problems: Vehicle routing with time windows,
Job-shop scheduling with agents as job-owners, project-to-student assignment,
and photo placement with friends and enemies. We selected a range of instances
for all models, each with randomly generated preferences that were automatically
converted into preference proﬁles over solutions2.
We ran our experiments using the Gecode solver [23] to generate all solutions
for the CSPs and MiniZinc-Python API to sample the solutions and run our
approach. All instances were designed suﬃciently small (150–5000 solutions)
that we can calculate the underlying Copeland scores exactly to compare them
against the sampling approach.
Figure 3 shows an example traversal for one scheduling instance that demon-
strates challenges and opportunities the sampling approach faces:
– High-quality solutions in terms of the (normalized) Copeland scores ¯C appear
ﬁrst in the default search traversal of the solver. But this becomes known
only after all solutions have been explored! Much of their “Copeland weight”
stems from bad solutions that appear very late in the search. When such an
“elite group” of solutions is presented to the sampling-approach, bad solutions
within the pool might be underestimated with respect to all solutions.
– Conversely, had the search started (due to an unfortunate heuristic) in the
bad region, the best among the worst might look very promising although it
only wins against bad overall solutions.
– The Copeland scores of the feasible solutions tend to follow a normal dis-
tribution but every sample adjacent in the chronological ordering is highly
skewed. Estimating the Copeland score based on such a sample might be oﬀ.
While this short paper only examines the basic feasibility of the sampling app-
roach to ﬁnd high-quality Copeland solutions, we emphasize that the distri-
butions we examined showed interesting regularities (Gaussian, Poisson) that
should be exploited further.
4.1
Evaluation Metrics
To evaluate our approach, we compute the normalized Copeland Scores on all
solutions produced by the CSP and refer to this as the “ground truth” ¯CGT. We
also measure the sample Copeland scores ¯CSP with respect to the solutions in
the sampled pool. The overall winning solution is consequently called θ∗
¯CGT and
2 Source code: https://github.com/s1db/Local-Search-Copeland-Method.

40
S. Bhavnani and A. Schiendorfer
Fig. 3. An example (full) traversal of the search space of a scheduling instance. Nor-
malized Copeland scores are shown (calculated a posteriori) for the solutions in chrono-
logical order. The distribution of the scores tends to follow a normal distribution.
the winner with respect to the (ﬁnal) sample pool is called θ∗
¯CSP. Using this we
deﬁne the following metrics:
The Copeland Gap measures how far oﬀthe Copeland score of the selected
winner is from the true winner’s Copeland score. It measures quality of the
selected solution.
| ¯CGT(θ∗
¯CSP) −¯CGT(θ∗
¯CGT )|
¯CGT(θ∗
¯CGT )
The Copeland Error measures how far oﬀthe Copeland score of the selected
winner is from its own ground truth Copeland score. It measures quality of the
Copeland score estimate.
| ¯CGT(θ∗
¯CSP) −¯CSP(θ∗
¯CSP)|
¯CGT(θ∗
¯CSP)
With those two metrics, we can make judgments about the sampling approach.
Does it ﬁnd solutions close to the true Copeland winner’s scores even under
a budget (10%–25% of all solutions)? Is the estimated Copeland score reliably
close to the true one? It might, e.g., happen that the sampling approach picks a
winner that has a good overall Copeland score (low Copeland gap) but it under-
/overestimates its true Copeland score (high Copeland error). When inspecting
the results in Table 1, we ﬁrst observe that the sampling approach with default
search selects solutions whose Copeland gap is below 35% for all considered
instances – often considerably closer. Diversity maximization can aid on some
problems more than others. In vehicle routing, e.g., it was able to select the
true Copeland winner through a broader exploration and with low Copeland
error. However, it can also be misleading: For example, diversity maximization
on instance 7 of photo placement picked a solution with a GT Copeland score
of 0.579 (best possible was 0.997) but that solution was estimated highly within
the pool (0.97) – resulting in high Copeland error and gap. Better management
of the solution pool is needed. We suspect that our naive diversity maximization

Towards Copeland Optimization in Combinatorial Problems
41
Table 1. Comparison of the sampling approach with or without diversity maximization
on several combinatorial problems. Instance names are consistent with the respository
– too large or small instances have been ignored.
Problem
# Solutions
Diversity Maximization
Default Search
Gap
Error
Gap
Error
Scheduling 4
2185
0.233
0.252
0.095
0.184
Scheduling 5
2528
0.134
0.063
0.047
0.043
Photo Placement 6
720
0.062
0.0339
0.175
0.176
Photo Placement 7
2520
0.420
0.677
0.031
0.023
Photo Placement 8
5040
0.234
0.27
0.095
0.026
Vehicle Routing 3
133
0
0.042
0.345
0.180
Vehicle Routing 4
133
0
0.043
0.174
0.227
Project assignment 2
996
0.266
0.291
0.026
0.009
Project assignment 3
996
0.083
0.11
0.336
0.485
does not account well for the actual distribution of Copeland scores but produces
diﬀerently skewed samples – a problem that needs signiﬁcant future research.
5
Conclusion and Future Work
We presented the ﬁrst results towards Copeland optimization of combinatorial
problems. Certainly, this work asks more questions than it succeeds to answer.
Most importantly, the quality of the solution pool in terms of representativity
and high-quality solutions is paramount. It would be interesting to assess the
sample distributions using statistical methods and apply learning techniques to
predict whether a sample winner is going to be strong on the ground truth. This
could lead to a proper termination criterion for the sampling approach or give
bounds on the sample Copeland scores future solutions need to achieve. This
can be propagated as a constraint. Also, the Copeland score (or other pairwise
social choice scores) is prone to manipulation via the selection of the sample
to exploit irrelevant alternatives. Attacks of that kind should be mitigated. To
perform these analyses of relevant problem sizes, we need to take care of com-
putational aspects. Since many similar instances have to be explored, learning
solving technologies such as lazy clause generation [25] could be well-suited.
Finally, our approach can be easily extended to other SCFs such as Borda or
implement more general strategies in weighted tournaments and made accessible
for MiniZinc – which we look forward to.
Acknowledgments. We thank Guido Tack and Alexander Knapp for initial discus-
sions that led to the idea of this paper.

42
S. Bhavnani and A. Schiendorfer
References
1. Bertsimas, D., Farias, V.F., Trichakis, N.: The price of fairness. Oper. Res. 59(1),
17–31 (2011)
2. Brandt, F., Conitzer, V., Endriss, U., Lang, J., Procaccia, A.D.: Handbook of
Computational Social Choice. Cambridge University Press, Cambridge (2016)
3. de Carvalho, V.R., Sichman, J.S.: Applying copeland voting to design an agent-
based hyper-heuristic. In: Proceedings of the 16th Conference on Autonomous
Agents and Multiagent Systems, pp. 972–980 (2017)
4. Chen, V.X., Hooker, J.: Combining leximax fairness and eﬃciency in a mathemat-
ical programming model. Eur. J. Oper. Res. 299(1), 235–248 (2022)
5. Copeland, A.H.: A reasonable social welfare function. Technical report, mimeo.
University of Michigan (1951)
6. Cornelio, C., Pini, M.S., Rossi, F., Venable, K.B.: Multi-agent soft constraint
aggregation via sequential voting: theoretical and experimental results. Auton.
Agent. Multi-Agent Syst. 33(1), 159–191 (2019). https://doi.org/10.1007/s10458-
018-09400-y
7. Dalla Pozza, G., Rossi, F., Venable, K.B.: Multi-agent soft constraint aggregation:
a sequential approach. In: Proceedings 3rd International Conference Agents and
Artiﬁcial Intelligence ICAART’11, vol. 11 (2010)
8. Ehrgott, M.: Multicriteria Optimization, vol. 491. Springer Science & Business
Media, Heidelberg (2005)
9. Fioretto, F., Yeoh, W., Pontelli, E., Ma, Y., Ranade, S.J.: A distributed constraint
optimization (DCOP) approach to the economic dispatch with demand response.
In: Proceedings 16th International Conference Autonomous Agents and Multiagent
Systems (AAMAS 2017), pp. 999–1007. International Foundation for Autonomous
Agents and Multiagent Systems (2017)
10. Frisch, A.M., Harvey, W., Jeﬀerson, C., Mart´ınez-Hern´andez, B., Miguel, I.:
Essence: a constraint language for specifying combinatorial problems. Constraints
13(3), 268–306 (2008). https://doi.org/10.1007/s10601-008-9047-y
11. Gadducci, F., H¨olzl, M., Monreale, G.V., Wirsing, M.: Soft constraints for lexi-
cographic orders. In: Castro, F., Gelbukh, A., Gonz´alez, M. (eds.) MICAI 2013.
LNCS (LNAI), vol. 8265, pp. 68–79. Springer, Heidelberg (2013). https://doi.org/
10.1007/978-3-642-45114-0 6
12. van Hentenryck, P.: The OPL Optimization Programming Language. MIT Press,
Cambridge (1999)
13. Ingmar, L., de la Banda, M.G., Stuckey, P.J., Tack, G.: Modelling diversity of
solutions. In: Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol.
34, pp. 1528–1535 (2020)
14. Knapp, A., Schiendorfer, A., Reif, W.: Quality over quantity in soft constraints. In:
Proceedings 26th International Conference Tools with Artiﬁcial Intelligence (ICTAI
2014), pp. 453–460 (2014)
15. McFadden, D., et al.: Conditional Logit Analysis of Qualitative Choice Behavior
(1973)
16. Meseguer, P., Rossi, F., Schiex, T.: Soft constraints. In: Rossi, F., van Beek, P.,
Walsh, T. (eds.) Handbook of Constraint Programming, chap. 9. Elsevier (2006)
17. Moulin, H.: Fair Division and Collective Welfare. MIT press, Cambridge (2004)
18. Nethercote, N., Stuckey, P.J., Becket, R., Brand, S., Duck, G.J., Tack, G.: MiniZinc:
towards a standard CP modelling language. In: Bessi`ere, C. (ed.) CP 2007. LNCS,
vol. 4741, pp. 529–543. Springer, Heidelberg (2007). https://doi.org/10.1007/978-
3-540-74970-7 38

Towards Copeland Optimization in Combinatorial Problems
43
19. Nicosia, G., Paciﬁci, A., Pferschy, U.: Price of fairness for allocating a bounded
resource. Eur. J. Oper. Res. 257(3), 933–943 (2017)
20. Rossi, F.: Collective decision making: a great opportunity for constraint reasoning.
Constraints 19(2), 186–194 (2013). https://doi.org/10.1007/s10601-013-9153-3
21. Rossi, F., Van Beek, P., Walsh, T.: Handbook of Constraint Programming. Elsevier,
Amsterdam (2006)
22. Schiendorfer, A., Reif, W.: Reducing bias in preference aggregation for multiagent
soft constraint problems. In: Schiex, T., de Givry, S. (eds.) CP 2019. LNCS, vol.
11802, pp. 510–526. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
30048-7 30
23. Schulte, C., Lagerkvist, M.Z., Tack, G.: Gecode: generic constraint development
environment. In: INFORMS Annual Meeting (2006)
24. Sen, A.: Collective Choice and Social Welfare. Harvard University Press, Cam-
bridge (2017)
25. Stuckey, P.J.: Lazy clause generation: combining the power of SAT and CP (and
MIP?) solving. In: Lodi, A., Milano, M., Toth, P. (eds.) CPAIOR 2010. LNCS,
vol. 6140, pp. 5–9. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-
642-13520-0 3

Coupling Diﬀerent Integer Encodings
for SAT
Hendrik Bierlee1,2(B)
, Graeme Gange1
, Guido Tack1,2
,
Jip J. Dekker1,2
, and Peter J. Stuckey1,2
1 Department of Data Science and AI, Monash University, Melbourne, Australia
{hendrik.bierlee,graeme.gange,guido.tack,jip.dekker,
peter.stuckey}@monash.edu
2 ARC Training Centre in Optimisation Technologies, Integrated Methodologies,
and Applications (OPTIMA), Melbourne, Australia
Abstract. Boolean
satisﬁability
(SAT)
solvers
have
dramatically
improved their performance in the last twenty years, enabling them to
solve large and complex problems. More recently MaxSAT solvers have
appeared that eﬃciently solve optimisation problems based on SAT. This
means that SAT solvers have become a competitive technology for tack-
ling discrete optimisation problems.
A challenge in using SAT solvers for discrete optimisation is the many
choices of encoding a problem into SAT. When encoding integer vari-
ables appearing in discrete optimisation problems, SAT must choose an
encoding for each variable. Typical approaches ﬁx a common encoding
for all variables. However, diﬀerent constraints are much more eﬀective
when encoded with a particular encoding choice. This inevitably leads to
models where variables have diﬀerent variable encodings. These models
must then be able to couple encodings, either by using multiple encod-
ing of single variables and channelling between the representations, or
by encoding constraints using a mix of representations for the variables
involved. In this paper we show how using mixed encodings of integers
and coupled encodings of constraints can lead to better (Max)SAT mod-
els of discrete optimisation problems.
1
Introduction
Within the last twenty years, Boolean satisﬁability (SAT) solving has increased
in terms of scalability and performance. More recently optimisation approaches
based on SAT, so called MaxSAT technology, have been rapidly developing.
SAT and MaxSAT solvers now provide a viable alternative solving technology
for many discrete optimisation problems.
Translating discrete optimisation problems to (Max)SAT is a diﬃcult task.
Currently, expert SAT modellers build models directly from clauses, or use
libraries to encode common constraints such as at-most-one, cardinality or
pseudo-Boolean constraints [15,23]. Alternatively, SAT compilers such as Fzn-
Tini [13] and Picat-SAT [33], or some modelling languages such as Essence [21],
determine a translation of a high-level model.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 44–63, 2022.
https://doi.org/10.1007/978-3-031-08011-1_5

Coupling Diﬀerent Integer Encodings for SAT
45
The ﬁrst fundamental choice a SAT modeller or compiler faces is how an
integer decision variable x should be translated to Boolean decisions. At least
three possibilities arise: the direct encoding, introducing a Boolean that repre-
sents x = d for each value d in the domain of x; the order encoding, introducing a
Boolean that represents x ≥d for each value d in the domain of x; or the binary
encoding, introducing a Boolean that represents a bit in the (two’s complement)
binary encoding of x.
Which encoding should be used for each variable in a discrete optimisation
problem is a non-trivial question. The answer may depend on the constraints in
which the variable appears, and how important they are to solving the overall
problem. In the existing approaches, the variable encoding choices made by the
SAT compiler or modeller are hard or impossible to change, since the encoding
of every constraint depends on it. Some constraints will be more eﬀective if
encoded using a particular variable choice, and if these choices are not all the
same for the problem of interest we inevitably have to couple diﬀerent integer
encodings. This can be managed by encoding an integer variable in two ways
and channelling the two encodings, or directly encoding constraints that couple
diﬀerent encodings of the variables involved.
In this paper we show that choosing mixed encodings of integer variables
in the model can lead to better solving performance. We investigate new pos-
sibilities for channelling and coupling encodings of constraints, and also show
how (partial) views can be used to extend coupling encodings. The experimen-
tal results show how the novel channel, coupling, and view constraints enable
unique encodings that outperform existing SAT encoding approaches for discrete
optimisation problems of interest.
2
Preliminaries
2.1
Constraint Programming
A constraint satisfaction problem (CSP) P = (X, Di, C) consists of a set of
variables X, with each x ∈X restricted to take values from some initial domain
Di(x). For this paper we assume domains are ordered sets of integers, and denote
by lb(x) and ub(x) the least and greatest values in Di(x). We will use interval
notation l..u to represent the set of integers {l, l +1, .., u}. A set of constraints C
expresses relationships between the variables. A constraint optimisation problem
(COP) is a CSP P together with objective function o, w.l.o.g. to be maximised.
Constraint programming solvers work by propagation over atomic con-
straints. An atomic constraint is (for our purposes) a unary constraint from
a given language (which includes the always false constraint false). The usual
atomic constraints for CP are x = d, x ̸= d, x ≥d and x ≤d. A propagator f
for constraint C takes a current domain D given as a set of atomic constraints,
and determines a set of new atomic constraints. These are a consequence of the
current domain and C, i.e., a ∈f(D) implies that D ∧C →a.
A propagator f is propagation complete for constraint C and a language of
atomic constraints L iﬀfor any D ⊆L and new atom a ∈L, a ̸∈D: if D∧C →a

46
H. Bierlee et al.
then a ∈f(D). That is, the propagator ﬁnds all atomic constraints in L that are
consequences of the constraint and the current domain.
Let DIRECT(x) be the language of atomic constraints {false} ∪{x = d, x ̸=
d | x ∈X, d ∈Di(x)}. A propagator is domain consistent if it is propagation
complete for L = DIRECT(x). Let ORDER(x) be the language of atomic con-
straints {false} ∪{x ≤d, x ≥d | x ∈X, d ∈Di(x)}. A propagator is bounds(Z)
consistent [6] if it is propagation complete for L = ORDER(x).
CSPs and COPs are typically expressed using a modelling language such
as MiniZinc [18]. To illustrate, we show a model for the popular Knight’s tour
problem in which we are looking for a trajectory of n2 legal knight moves around
an n × n board. The knight starts and ends at the top-left square (numbered 1),
visiting each square exactly once.
The variable x[p] gives the next position (in 1..n2) to move to from position
p. MiniZinc allows us to specify the integer variable domains exactly according
to legal knight moves (shown in the ﬁgure above). The symmetry breaking con-
straints reduce the domains of two variables to single, ﬁxed values. The global
constraint circuit constrains the x variables to describe a single Hamiltonian
circuit traversal of the graph. The constraint may be implemented directly by
the solver or deﬁned in terms of basic constraints using the standard library,
or a library specialised for a particular solver. For a given target solver, MiniZ-
inc ﬂattens the high-level model into low-level FlatZinc consisting of built-in
constraints.
2.2
Boolean Satisﬁability
A Boolean Satisﬁability (SAT) problem can be seen as a special case of a CSP,
where the domain for all variables x is Di(x) ∈{0, 1}, representing the values
false (0) and true (1). In SAT problems, we usually talk about literals, which are
either a Boolean variable x or its negation ¬x. We extend the negation operation

Coupling Diﬀerent Integer Encodings for SAT
47
to operate on literals, i.e., ¬l = ¬x if l = x and ¬l = x if l = ¬x. We use the
notation l = v where l is a literal and v ∈{0, 1} to encode the appropriate form
of the literal, i.e., if v = 1 it is equivalent to l and if v = 0 it is equivalent to
¬l. The notation l ̸= v is deﬁned similarly to encode ¬(l = v). A clause is a
disjunction of literals. In a SAT problem P, the constraints C are clauses.
MaxSAT problems are a subclass of COP. A MaxSAT problem1 (P, o) is a
SAT problem P and a (usually non-negative) weight ob associated to each b ∈X.
The aim is to minimise 
b∈X obb.
The core operation of SAT solvers is unit propagation. Given a set of currently
true literals φ, if there is a clause C = l1 ∨· · ·∨ln where ¬li ∈φ for all 1 ≤i ≤n
then unit propagation detects failure. Similarly, if ¬li ∈φ for all 1 ≤i ̸= j ≤n
then unit propagation adds literal lj to the current partial assignment φ.
3
Encoding Integer Variables
In order to use MaxSAT solvers for an arbitrary COP (P, o), we need to encode
the variables, constraints, and objective of the COP as a MaxSAT problem. We
ﬁrst examine encoding the variables.
Given an integer x with (possibly non-contiguous) initial domain Di(x) =
{d1, d2, . . . , dm}, we will now deﬁne three encoding methods: the direct encoding,
the order encoding, and the binary encoding. Each encoding method maps x to
a set of Boolean encoding variables. Additionally, consistency constraints on
the encoding variables ensure that they correctly represent an integer. We use
consistent semantic brackets to name the encoding Booleans, where Boolean [[f]]
is true iﬀthe formula f holds.
The direct encoding of x introduces m encoding variables [[x = v]], v ∈Di(x).
[[x = v]] is true iﬀx is assigned value v. A propagation complete [19] encoding
of the exactly-one consistency constraint is posted on the encoding variables,

d∈Di(x)
[[x = d]] = 1
(1)
to ensure that the separate Booleans faithfully encode an integer (which must
take a single value). Unit propagation of Eq. (1) is propagation complete for the
constraint x ∈D(x) and the language of atomic constraints DIRECT(x).
The order encoding of x introduces m −1 encoding variables [[x ≥v]], v ∈
{d2, . . . , dm}. [[x ≥v]] is true iﬀx is assigned a value greater or equal to v. The
decreasing consistency constraint
∀3 ≤i ≤m. ([[x ≥di]] →[[x ≥di−1]])
(2)
enforces that the encoding variables give a consistent view on the integer. Unit
propagation on Eq. (2) is propagation complete for constraint x ∈D(x) and the
1 The usual deﬁnition of MaxSAT makes use of soft clauses with weights but is
functionally equivalent to the deﬁnition here, and indeed internally many MaxSAT
solvers treat the problem in the form we deﬁne here.

48
H. Bierlee et al.
language of atomic constraints ORDER(x). The order encoding is also known
as the ladder, regular, or thermometer encoding.
We extend our semantic brackets notation to make it easier to describe a
broader range of bounds constraints as follows: [[x ≥d]] ≡1, d ≤d1; [[x ≥d]] ≡
[[x ≥di+1]], di < d ≤di+1; [[x ≥d]] ≡0, d > dm; [[x > d]] ≡[[x ≥d + 1]];
[[x < d]] ≡¬[[x ≥d]]; and [[x ≤d]] ≡¬[[x > d]].
The binary encoding of x introduces n encoding variables [[bit(x, k)]], k ∈
0..n −1. Then, [[bit(x, k)]] is true iﬀthe kth most signiﬁcant bit in the two’s
complement binary representation of the value assigned to x is true, i.e., in C
notation: bit(x, k) =(x >> k) & 1. We consider two cases: where x is known
to be non-negative (d1 ≥0), and where it may take both positive and negative
values. In the ﬁrst case the number of bits required n = ⌈log(ub(x) + 1)⌉) is
given by the upper bound of x. In the second case the number of required bits
n = max(⌈log(−lb(x))⌉, ⌈log(ub(x) + 1)⌉) + 1 is determined by the lower and
upper bounds of x. Let B(x) = 0..n −1 and let R(x) be the set of representable
integers for the binary encoding of x. In the ﬁrst case R(x) = 0..2n −1 and in
the second R(x) = −2n−1..2n−1 −1.
The consistency constraint for the binary encoding enforces that the Boolean
representation can only represent values in the initial domain Di(x). It is the SAT
encoding of the constraints (a) x ≥d1 if d1 > 0 or 0 > d1 > −2−n−1, (b) x ≤dm
if d1 ≥0∧dm < 2n−1 or d1 < 0∧dm < 2n−2 (c) x ̸= d for each d1 < d < dm, d ̸∈
Di(x). Constraints (a) and (b) are encoded using lexicographic decompositions,
while (c) can be simply encoded as a clause ∨k∈B(x)[[bit(x, k)]] ̸= bit(d, k). For
highly sparse domains more eﬃcient approaches are possible for (c). We return
to this later. Unfortunately, unit propagation on encodings of these consistency
constraints does not achieve propagation completeness on the language of atomic
constraints BINARY (x) = {false} ∪{bit(x, k), ¬bit(x, k) | x ∈X, k ∈B(x)}.
The binary encoding is also known as the log(arithmic) encoding. A crucial
advantage of the binary encoding is that it is exponentially smaller than the
other encodings.
4
Encoding Constraints
Encoding constraints into clauses is a rich area of research. Even for simple con-
straints deﬁned on Boolean variables such as at-most-one, cardinality, or psuedo-
Boolean constraints there are dozens of papers [2,3,19,26,29]. Here we consider
encoding constraints over integers. A key consideration is that the encoding of a
constraint crucially depends on how the integers it constrains are encoded. We
will indicate whether the direct, order or binary encoding is used for a particular
integer x as x:D, x:O or x:B, respectively.
Most encodings of constraints are uniform, that is they expect all the inte-
gers involved in the constraint to be encoded in the same way (e.g., x:O ≤y:O).
But diﬀerent constraints will prefer diﬀerent integer encodings. The cardinality
constraints, such as global cardinality, count how many times particular values
occur in an array. Hence, they essentially prescribe a direct encoding of integers

Coupling Diﬀerent Integer Encodings for SAT
49
in the array. Similarly, linear constraints involving large domains essentially blow
up in encoding size unless we use binary encoded integers. Many discrete opti-
misation models will therefore need to deal with diﬀerent integers being encoded
in diﬀerent ways. Hence, somewhere in the model we must encode constraints
with non-uniform encodings of integers (e.g., x:O ≤y:B). We call these coupling
encodings.
There is little existing work on coupling encodings except for channelling
constraints, that is, coupling encodings of equality and coupling encodings of
linear inequality constraints [27].
4.1
Coupling Equality Constraints
We can couple diﬀerent integer encodings by allowing a variable x to have multi-
ple encodings, such as x:D and x:O, and adding a channelling equality constraint
between them to our model (e.g., x:D = x:O). We now discuss the three coupling
encodings of the integer equality constraint x = y.
x:D = y:O This is the most common channelling constraint. Its encoding
amounts to just deﬁning [[x = k]] in terms of the order variables, for all k ∈Di(x):
∀d∈Di(x)[[x = d]] ↔[[y ≥d]] ∧[[y ≤d]].
(3)
Having introduced this for all d, we no longer need consistency constraints on
the direct encoding. It is easy to show [22] that unit propagation for Eq. (2)
for y and (3) is propagation complete for x ∈D(x) ∧x = y ∧y ∈D(y) and
L = DIRECT(x) ∪ORDER(y). Hence, we can omit the exactly-one constraint,
Eq. (1) on x.
x:D = y:B For this constraint, there is a trade-oﬀbetween propagation strength
and the size of the encoding. This encoding was initially devised in the context
of encoding at-most-one [9,19,24] constraints, where channelling to the binary
representation implicitly prevents two [[x = d]] literals from becoming true:
∀d∈Di(x),k∈B(y)[[x = d]] →[[bit(y, k)]] = bit(d, k).
(4)
It is extended by Frisch and Peugniez [9] to exactly-one by adding channelling
from the binary representation back to the equality literals:
∀d∈Di(x)

k∈B(y)
[[bit(y, k)]] = bit(d, k) →[[x = d]].
(5)
This encoding does not enforce domain consistency between the two repre-
sentations. For example, consider the case where we have removed all the even
values from D(x). In order to achieve domain consistency, we replace this second
set of clauses with the modiﬁed ones, for each k ∈B(y), v ∈{0, 1}:
[[bit(y, k)]] = v →

d∈Di(x),bit(d,k)=v
[[x = d]].
(6)

50
H. Bierlee et al.
This ensures that once all values consistent with bit(x, d) = v are eliminated,
[[bit(x, k)]] is set to ¬v.
As with x:D = y:O, the x:D = y:B constraint allows us to drop consistency
constraints: both the exactly-one (for direct), and all the binary encoding con-
sistency constraints.
Theorem 1. Unit propagation on the clauses of Eqs. (4) and (6) is propagation
complete for constraint x ∈D(x) ∧x = y ∧y ∈D(y) and L = DIRECT(x) ∪
BINARY (y). Hence, it enforces domain consistency on x.
⊓⊔
x:O = y:B We are not aware of any previous channelling between order and
binary representations. The information that can be exchanged between the
order and binary representations is necessarily limited, and can only propagate
in two cases. If the lower/upper bound rests on a value d which is inconsistent
with some ﬁxed bit [[bit(y, k)]], we can adjust the bound to the nearest value d′
such that bit(d′, k) = [[bit(y, k)]]; and if a bit is constant for all values within the
current bounds, we can ﬁx the corresponding variable. A stable segment l..u for
binary bit k is a range l..u ⊆R(y) such that bit(d, k) is the same for all d ∈l..u.
We can handle both of these cases by posting, for each segment rl..ru ⊆R(y)
which is stable for bit k, the constraint:
[[bit(y, k)]] = bit(rl, k) ∨[[x < rl]] ∨[[x > ru]].
(7)
Example 1. Consider a variable y with Di(y) = 0..6. In the binary representa-
tion, the second last bit is ﬁxed for ranges of size 2: {{0, 1}, {2, 3}, {4, 5}, {6}}.
The channelling constraints for the second last bit, k = 1, are
¬[[bit(y, 1)]] ∨[[x ≥2]],
[[bit(y, 1)]] ∨[[x ≤1]] ∨[[x ≥4]],
¬[[bit(y, 1)]] ∨[[x ≤3]] ∨[[x ≥6]], and
[[bit(y, 1)]] ∨[[x ≤5]].
The Order-Binary channelling constraints are propagation complete, and
require O(|B(y)||Di(x)|) ternary clauses. We can omit the outer bounds consis-
tency constraints on the binary encoding since they are enforced by the channel.
Theorem 2. Unit propagation on the clauses of Eqs. (2) and (7) is propagation
complete for constraint x ∈lb(x)..ub(x) ∧x = y and language L = ORDER(x) ∪
BINARY (y). Hence, it enforces the initial bounds on x. Note that these equations
do not enforce (nor can the encoding variables represent) domain consistency on
the domain of x.
⊓⊔
4.2
Coupling Inequality Constraints
While the channelling constraints above are propagation complete, introducing
a dual representation of a variable and its channelling constraint introduce over-
head. When we can avoid this and directly encode a constraint that couples two
representations we can get more compact models.

Coupling Diﬀerent Integer Encodings for SAT
51
Indeed, linear inequality constraints have a simple approach to coupling
encodings, which is perhaps folklore. Each encoding can represent the linear term
ax as a linear pseudo-Boolean term: direct a×d1 ×[[x = d1]]+· · ·+a×dm ×[[x =
dm]], order a × d1 + a × (d2 −d1) × [[x ≥d2]] + · · · + a × (dm −dm−1) × [[x ≥dm]],
or binary a × [[bit(x, 0)]] + 2a × [[bit(x, 1)]] + · · · + 2ka × [[bit(x, k)]]. Hence, an
arbitrary linear constraint can be mapped to a linear pseudo-Boolean constraint
which is then encoded in any number of ways. Note that we can similarly encode
arbitrary integer linear objectives into a pseudo-Boolean objective required for
MaxSAT.
Diet-Sugar [27] improves on this simple approach for order+binary coupling2
of ax + b1y1 + b2y2 + bnyn ≤c by essentially encoding the constraints adi[[x ≥
di]]+b1y1+b2y2+bnyn ≤c for each di ∈Di(x) separately, using a BDD to encode
each resulting pseudo-Boolean. Although they do not prove it, using the Com-
pletePath encoding (from [1]) of the resulting BDDs will guarantee propagation
completeness on the language ORDER(x)∪BINARY (y1)∪· · ·∪BINARY (yn).
We consider the simpler inequality coupling constraint x:O ≤y:B, which we
can encode directly as follows.
For each lb(x) < d ≤ub(x) we post the constraint
[[x ≥d]] →

k∈B(x),¬bit(d−1,k)
[[bit(y, k)]]
(8)
The intuition behind this is that the binary representation for d satisﬁes this
because adding any positive amount to d −1 will ﬂip at least one bit from false
to true. The encoding consists of O(|ub(x) −lb(x)|) clauses of size O(|B(y)|). If
Di(x) is not a range then many clauses within domain gaps become redundant.
To complete the encoding we need to enforce the initial bounds using the lexi-
cographic encoding of y ≥lb(x) and the unit clause encoding of x ≤ub(y). To
extend to ranges with negative numbers we treat the sign bit [[bit(x, n −1)]] as
if it were negated, but omit details here.
Example 2. Consider encoding x:O ≤y:B for variables x and y with Di(x) =
1..7, Di(y) = 0..6. This will result in the following clauses from Eq. (8), shown
with the relevant bit representation on the left.
001
[[x ≥2]] →[[bit(y, 2)]] ∨[[bit(y, 1)]]
010
[[x ≥3]] →[[bit(y, 2)]] ∨
[[bit(y, 0)]]
011
[[x ≥4]] →[[bit(y, 2)]]
100
[[x ≥5]] →
[[bit(y, 1)]] ∨[[bit(y, 0)]]
101
[[x ≥6]] →
[[bit(y, 1)]]
The encoding also requires y ≥1 encoded as [[bit(y, 0)]] ∨[[bit(y, 1)]] ∨[[bit(y, 2)]]
and x ≤6 encoded as ¬[[x ≥7]]. We see that for example [[x ≥4]], which forces
[[bit(y, 2)]] true, means that it never occurs for later literals. This relies on the
order encoding, since [[x ≥5]] implies [[x ≥4]].
2 Their approach handles any number of order encoded variables, we restrict to one
for simplicity of explanation.

52
H. Bierlee et al.
If we suppose instead Di(x) = {1, 2, 6, 7}, then we keep only the ﬁrst, third
and last clauses, since the others are subsumed (i.e., [[x ≥3]] ≡[[x ≥4]] ≡[[x ≥
5]] ≡[[x ≥6]]).
⊓⊔
This encoding is propagation complete for x ≤y.
Theorem 3. Unit propagation on the clauses of Eqs. (2) and (8) and clauses for
lexicographic encoding of y ≥lb(x) and together with the clause ¬[[x ≥ub(y)+1]]
is propagation complete for x ≤y for the language L = ORDER(x) ∪
BINARY (y).
⊓⊔
Interestingly the encoding of Diet-Sugar applied to the constraint x:O ≤
y:B produces a strict superset of our encoding clauses, adding many redundant
clauses.
We can enforce the reverse x:O ≥y:B similarly. Apart from the initial bounds
constraints x ≥lb(y) and y ≤ub(x) we generate the clauses for lb(y) < d ≤ub(x)
¬[[x ≥d]] →

k∈B(y),bit(d,k)
¬[[bit(y, k)]].
(9)
We can of course use the conjunction of inequalities, x:O ≥y:B ∧x:O ≤y:B,
to enforce equality x:O = y:B, but this inequality channel does not enforce
propagation completeness.
4.3
Coupling Element Constraints
Element constraints are an important component of many CP models. They
enable array look-up using a variable index with y = A[x]. Our encoding makes
use of the fact that the equality constraint x = d for ﬁxed integer d is a conjunc-
tion of literals for the direct, order or binary encoding: [[x = d]], [[x ≥d]]∧[[x ≤d]],
or 
k∈B(x)[[bit(x, k)]] = bit(d, k), respectively. Consequently, we can deﬁne a cou-
pling encoding of element constraint for any encoding choices for y, A and x with
for all d ∈Di(x), (x = d) →(A[d] = y). In other words, the equality constraint
A[d] = y is conditional on the conjunction of literals, x = d.
Example 3. Consider the coupling for y:O = A:B[x:D]. The clauses take the form
¬[[x = d]] ∨([[bit(A[d], k)]] = bit(rl, k)) ∨[[y < rl]] ∨[[y > ru]]
for d ∈Di(x) and stable ranges rl..ru ⊆R(y) for bit k.
⊓⊔
When x has the direct encoding and A is ﬁxed, the encoding can be made
propagation complete similar to Eq. (6) by adding a backwards clauses for every
distinct value u in A: (y = u) →
d∈Di(x),u=A[d][[x = d]].
5
Views
Views [25] are a crucial feature in modern CP solvers. For speciﬁc constraints,
views can simplify propagation construction using an interface to the variable
operations. In SAT, whenever an equivalence or negation arises between diﬀerent
expressions, we can represent both with the same Boolean variable. This allows
greater scope for views on SAT encoded integers compared to CP integers.

Coupling Diﬀerent Integer Encodings for SAT
53
Aﬃne Transformations. The most important view constraint is the aﬃne trans-
formation y = ax + b for ﬁxed integers a and b. For the direct encoding, we
have for every d ∈D(x) ∪D(y) that [[y = ad + b]] ≡[[x = d]], so we can use
the same Boolean variable to represent both. For the order encoding, we have
for non-negative a that [[y ≥ad + b]] ≡[[x ≥d]] (if a is negative, one ≥ﬂips
to ≤). For the binary encoding, aﬃne views can be applied in some but not all
cases [34].
Minimum/Maximum. Boolean encoding also raises the possibility of partial
views where only some Boolean variables are reused. In y = max(x, m) for ﬁxed
integer m (and similar for min), after enforcing y ≥m we ﬁnd a partial view for
the order encoding ∀ub(y)
d=m [[y ≥d]] ≡[[x ≥d]]. For the direct encoding, we have
one less equivalence: ∀ub(y)
d=m+1[[y = d]] ≡[[x = d]]. We require one new Boolean
variable for [[y = m]], which is constrained by ∀m
d=lb(x)[[x = d]] →[[y = m]].
Element. Certain compositions of ﬁxed A allow for views. For y:D = A[x:D],
every unique value A[d] has binary backwards clause [[y = A[d]]] →[[x = d]],
so [[x = d]] ≡[[y = A[d]]]. For y:O = A[x:O], we have for all d ∈Di(x) that
[[x ≥d]] →[[y ≥A[d]]] if A[d] ≤A[e] holds for all e > d. Similarly, [[x ≤d]] →
[[y ≤A[d]]] if A[c] ≤A[d] holds for all c < d. If both conditions hold, then
[[x ≥d]] ≡[[y ≥A[d]]]. If A is strictly monotone, both conditions hold for all
elements and y becomes a total view of x. When the inequalities are ﬂipped,
we have negated views [[x ≥d]] ≡[[y < A[d]]], which are total if A is strictly
antitone.
Views allow us to extend our coupling encodings straightforwardly. For exam-
ple, we can encode x:O + d ≤y:B by using a view to construct (x + d):O and
then using the inequality coupling.
6
Experimental Results
To validate the beneﬁt of coupling diﬀerent integer encodings, we created the
MiniZinc-SAT framework, an extension of MiniZinc. Through MiniZinc’s anno-
tations, the user can declare the integer variable encodings. For example in the
knight’s tour model, given in Sect. 2.1, we can choose direct encoding for each
variable x r c in x by adding an annotation as follows.
var neighbours: x r c :: direct encoded;
Since annotations are ﬁrst class objects, the user can specify more complex
encoding schemes based on, for example, the variable’s domain size, its existing
encodings, or any other contextual rules. If no encodings are speciﬁed, default
choices are made. During compilation, MiniZinc-SAT resolves mixed encoding
constraints by coupling if possible, or by channelling if necessary. Additionally,
views are used whenever the constraint and variable encodings allow it.
Using MiniZinc-SAT, we create various encodings of realistic problems to see
if we can improve solver performance. We also compare with Picat-SAT 3.1 [33],

54
H. Bierlee et al.
a solver that maps MiniZinc to SAT using binary encoding, and Chuﬀed 0.10.4 [7]
a lazy clause generation solver, using lazy direct-order encoding.
Results are given for SAT models and MaxSAT models running Open-WBO
2.1 [16] on a single-core Intel Xeon 8260 CPU (non-hyperthreaded) with a 10-
minute solving timeout and up to 64 GB of RAM. The results are visualised in
cactus plots, in which for each conﬁguration the solved instances are sorted by
solve time (measured from when the SAT or LCG solver is started). Instances
which are not solved (SAT) or proved optimal (MaxSAT) within the time limit
are omitted.
Source code, models, instances and run logs are available online3.
(a)
(b)
Fig. 1. Cactus plots for solved (a) knights instances, and (b) orienteering instances.
Knight’s Tour. The ﬁrst example is the knights model shown in Sect. 2.1 for
instances n = 8, 10, ..., 22. The model contains n2 variables x with relatively
sparse domains of up to size 8, but to prevent sub-cycles the circuit decompo-
sition introduces another n2 variables y with contiguous domains of 1..n2 that
represent the order in which positions are visited. The encodings of x and y are
coupled through element constraints, extended by a view on the result variable
(e.g., y:O[xi:D] = (yi−1 + 1):O, ∀1 < i ≤n). The results for the three uniform
and three sensible mixed encoding choices for x and y are shown in Fig. 1a.
Uniform order and binary encodings do not succeed beyond the two easi-
est instances. This is unsurprising since the circuit constraint prescribes x:D.
However, since the y variables reason about the order of visits, we see that y:O is
clearly preferred over the uniform approach, y:D. The worst choice is y:B, which
has the additional disadvantage that it cannot use the aﬃne transformation view.
Creating a redundant order encoding for x variables (x:D:O) does not seem to
make much diﬀerence. Chuﬀed and Picat-SAT both far outperform MiniZinc-
SAT, since they have native circuit propagator and encoding [32] respectively.
3 https://github.com/hbierlee/cpaior-2022-coupling-sat.

Coupling Diﬀerent Integer Encodings for SAT
55
Orienteering. The orienteering problem is a COP concerning a complete graph
with edge distances di,j and node rewards. The aim is to ﬁnd a path from start
to ﬁnish node that maximises the sum of the rewards of the visited nodes, but
which is limited by a linear inequality on the distances of the traversed edges.
The principal subcircuit constraint is encoded similarly to circuit in knights
by two sets of variables x and y, coupled through element constraints. Given
the results from knights, we will use x:D and y:O. However, we will experiment
with all possible (non-redundant) encodings on a new set of coupled variables
zi = di[xi] which appear in the linear inequality on the maximum distance. The
linear objective can be directly encoded using the x:D variables.
A cactus plot comparing encodings is shown in Fig. 1b. Of the mixed encod-
ings, z:B is clearly the best, since it makes the path length constraint compact.
While both Chuﬀed and Picat-SAT again have native subcircuit propagator and
encoding, Picat-SAT is now outperformed by the best MiniZinc-SAT encoding.
It seems that its subcircuit encoding is less eﬀective than the MiniZinc standard
decomposition using element coupling.
(a)
(b)
Fig. 2. Cactus plots for solved jsswet instances of (a) variant where 40% of jobs are
high priority, and of (b) variant with limited average job length.
Job-Shop scheduling with Weighted Earliness/Lateness. Here, we examine a job-
shop scheduling problem jsswet over n jobs, each with m tasks, with start time
variables x. Every task j of job i runs on a diﬀerent machine for its full duration
di,j. Tasks of the same job must ﬁnish in sequence (xi,j + di,j ≤xi,j+1), and
must not overlap (disjunctive) with the tasks of other jobs that run on the
same machine. The objective is to minimise the sum of the penalties over all
jobs. A job’s penalty is its ﬁnal task’s earliness or lateness to its deadline ti,
weighted by its earliness ei or lateness li penalty coeﬃcients, respectively. The
order encoding combines aﬃne transformations and max views for the objective:
ei × max(0, ti −xi,m + di):O + li × max(0, xi,m + di −ti):O.
In preliminary results not shown here we found that if the schedule’s horizon
is small, the order encoding works best thanks to its propagation strength. How-
ever, when the horizon becomes large this approach will run out of memory due

56
H. Bierlee et al.
Fig. 3. Cactus plots for solved table-layout instances.
to the sheer number of order encoding variables, and only the binary encoding
remains viable. So each encoding has beneﬁts and drawbacks. We now consider
two variants of the problem.
In the ﬁrst variant, we consider a large horizon, but designate the ﬁrst 40%
of jobs as high priority jobs which must ﬁnish within 500 time steps of their
deadline, and have much higher penalties. Eﬀectively, this splits the variables
into those with small and large domains. We consider encoding all variables
with order, or binary, or a mix which uses order for small and binary for large
domains. For high priority job-task xa,j and low priority job-task xb,k assigned to
the same machine, the disjunctive constraint couples the (potentially) mixed
encodings via ((xa,j + da,j):O ≤xb,k:B) ∨(xb,k:B ≤(xa,j −db,k):O). The results
in Fig. 2a show that the mixed encoding outperforms the other solvers and uni-
form encodings.
For the other variant we consider a smaller horizon, which allows a full order
encoding of all tasks. However, now the average run time of all jobs is limited
by parameter M (2.5 times the sum of all minimal job durations). To eﬀec-
tively constrain this linear inequality n
i=1 xi,m −xi,1 ≤M, the mixed encod-
ing adds a redundant binary encoding to the ﬁrst and last task of each job:
xi,1:O:B, xi,2:O, . . . , xi,m−1:O, xi,m:O:B.
The results in Fig. 2b show the mixed encoding convincingly outperforms
the other solvers and uniform encodings. The redundant encodings are coupled
with xi,1:O = xi,1:B, but coupling with xi,1:O ≤xi,1:B ∧xi,1:O ≥xi,1:B or just
xi,1:O ≤xi,1:B produces similar results.
Table Layout. Finally, we consider the table-layout problem. For a table com-
posed of n × m cells, our task is to assign a width-height conﬁguration variable
xi,j for each cell at row i, column j. The conﬁguration will determine for cell
i, j its cell-width wi,j = W[xi,j] and cell-height hi,j = H[xi,j] through element
constraints. These variables are combined in n row-height variables ri, where
m
j=1 ri ≥hi,j, and m column-width variables cj, where m
i=1 cj ≥wi,j. The

Coupling Diﬀerent Integer Encodings for SAT
57
objective is then to minimise the table’s height n
i=1 ri, without the table’s
width m
j=1 cj exceeding a given maximum width.
We chose this problem to test two unexplored properties. First, Hi,j and Wi,j
are guaranteed to be respectively monotone and antitone, since the width-height
conﬁgurations represent sorted, optimal text layouts. Consequently, the element
constraint establishes a view between the order encoding variables [[xi,j ≥k]],
[[hi,j ≥Hi,j,k]] and [[wi,j ≤Wi,j,k]]. Secondly, D(hi,j) is sparse whereas D(ri)
is contiguous. Thus, the coupling hi,j:O ≤ri:B requires far fewer clauses for
the domain gaps in hi,j, while also skipping a large order encoding of ri. We
compare this very compact encoding against an order encoded objective (using
simple binary clauses for hi,j:O ≤ri:O). A third approach creates an order
encoding for the width (wi,j:O ≤cj:O) as well, but still redundantly channels
cj:O = cj:B for the linear inequality.
The results in Sect. 6 show that solver performance suﬀers greatly if we couple
x:O to a binary encoded objective r:B rather than using straightforward order
encoded objective r:O. The coupling perhaps overcomplicates the objective com-
pared to using binary clauses. Furthermore, channelling rather than coupling to
c:B seems to be marginally better as well. The domain sizes of the table-layout
instances are too large for the more compact coupling to pay oﬀ(in contrast to
jsswet). For r:O, the pseudo-Boolean objective is unweighted, which means
Open-WBO can use its core-guided Part-MSU3 algorithm. This makes the mod-
els solve almost instantly. Chuﬀed does equally well, while Picat-SAT solves all
instances but requires more time.
7
Related Work
The choice of variable encoding is a critical decision when encoding CSPs to SAT,
and unsurprisingly has seen considerable attention. Most CSP-to-SAT converters
ﬁx one of the encodings described in Sect. 3 as their core representation, and
convert all variables/constraints based on that encoding. Binary encoding is
a popular choice (in two’s complement [12] or sign-magnitude [33] variants)
despite its relatively weak propagation strength, as it can reliably cope with
very large domains. Order encoding, conversely, is adopted by some encoders [17,
28] despite the risk of blow-up due to its eﬀectiveness on primitive arithmetic
constraints [30]. This is sometimes paired with a channelled direct encoding for
ﬂexibility [5,14]. Not to be confused with our order-binary channelling, some
works propose new integer encodings which mix features of the order and binary
encoding [20,31].
Some works are concerned with picking the right encoding for the right vari-
able. Proteus [14] attempts to predict, for a given instance, which encoding of
variables (and constraints) will be most eﬀective, then commits to that encod-
ing for the whole instance. Satune [11] selects encodings on a per-variable basis,
and optimises the domain representation, based on a training phase for a class of
instances. However, it does not resolve the coupling problem, instead requiring
connected variables to share a common representation. A more radical app-
roach, adopted by current lazy clause generation solvers [7,8,10] is to implicitly

58
H. Bierlee et al.
maintain a partial representation of the direct-order encoding, introducing new
literals and channelling as necessary.
Diet-Sugar [27] is the only other work that we are aware of that consid-
ers encoding non-uniform constraints. It directly introduces coupled order and
binary encodings of linear constraints. The SAT translation chooses a single
encoding for each variable using a heuristic that leads to an overall small and
eﬀective encoding of the constraints. The resulting mixed encodings are shown
to yield signiﬁcant improvement.
General compilers that support MiniZinc have been developed using binary
encoding, namely FznTini [12,13] (two’s complement) and Picat-SAT [33] (sign-
and-magnitude). Notably, the binary encoding despite theoretically lower prop-
agation strength has continued to prove itself in the Picat-SAT compiler in the
yearly MiniZinc competition. It is clear that the black box compilers such as
Picat-SAT essentially introduce other forms of integer encoding in some global
constraint decompositions [32]. Savile Row [21] similarly converts a high-level
model (speciﬁed in Essence’) into SAT. Savile Row commits to a channelled
direct-order encoding for variables, allowing each constraint to choose its pre-
ferred uniform encoding, though they apply some transformations [4] to improve
the generated SAT encoding.
BEE [17] is an approach to compiling integer models to SAT using only
order encoding. It goes beyond our view approach by searching for all Boolean
variable equivalences (using a SAT solver) in order to simplify the resulting SAT
model. BEE would automatically discover the (partial) views we deﬁne on order
encoded variables, but none of them are covered by its ad hoc methods.
8
Conclusion
In conclusion, while compilation to SAT is a competitive approach to tackling
discrete optimisation problems, eﬃcient encoding of discrete optimisation prob-
lems into SAT is challenging. To create the best encodings possible we must allow
diﬀerent representations of integers to be used in the encoding, which means the
problem of coupling encodings arises. In this paper we show how we can cre-
ate coupled models by using channelling equalities, or directly by using coupled
encodings of element or inequality constraints. Total and partial views extend
the coupling constraints we can encode. We show that coupling encodings can
be required for getting the best resulting SAT encoding.
Acknowledgements. This research was partially funded by the Australian Gov-
ernment through the Australian Research Council Industrial Transformation Train-
ing Centre in Optimisation Technologies, Integrated Methodologies, and Applications
(OPTIMA), Project ID IC200100009.

Coupling Diﬀerent Integer Encodings for SAT
59
A
Proofs
Theorem 1. Unit propagation on the clauses of Eqs. (4) and (6) is propagation
complete for constraint x ∈D(x) ∧x = y ∧y ∈D(y) and L = DIRECT(x) ∪
BINARY (y). Hence, it enforces domain consistency on x.
Proof. First we show that unit propagation enforces the exactly-one constraint.
If we have [[x = d]] and [[x = d′]] true simultaneously, then Eq. (4) will force one
binary variable in y to take two values, thus failing. If all variables [[x = d′]] are
set false except one [[x = d]], then Eq. (6) will set the correct bits of y in the
remaining solution (via setting the negation to false). The forward direction will
then propagate [[x = d]].
Next we show that the unit propagation is propagation complete with respect
to the binary variables and missing values in the original domain. Suppose S ⊆
D(x) are the remaining values in the domain. Then ¬[[x = d]] is set for d ∈
Di(x) −S. Suppose that there is no support for [[bit(y, k)]] in S. Then unit
propagation of Eq. (6) will set ¬[[bit(y, k)]].
Finally, we show that unit propagation is propagation complete on the
encoding variables. Given the subset of the current assignment literals L ⊆φ
restricted to the direct encoding variables for x and binary encoding vari-
ables of y. Let S ⊂D(x) be the set of possible domain values remaining, i.e.
S = {d | d ∈D(x), ¬[[x = d]] ̸∈L}. Clearly the direct encoding variables are
consistent with this by deﬁnition, and if S is a singleton, by the ﬁrst argument
[[x = d]] is set true. We now consider each bit variable [[bit(y, k)]]: if [[bit(y, k)]] ∈L
then by Eq. (4) each value in d ∈S has bit(d, k) is true, hence it is supported;
similarly if ¬[[bit(y, k)]] ∈L. Finally, if variable [[bit(y, k)]] does not appear in
L, then there must be values in S with both truth values, otherwise one of the
equations in Eq. (6) would have propagated.
Theorem 2. Unit propagation on the clauses of Eqs. (2) and (7) is propagation
complete for constraint x ∈lb(x)..ub(x) ∧x = y and language L = ORDER(x) ∪
BINARY (y). Hence, it enforces the initial bounds on x. Note that these equations
do not enforce (nor can the encoding variables represent) domain consistency on
the domain of x.
Proof. Given the subset of the current assignment literals L ⊆φ restricted to
the order encoding variables for x and binary encoding variables for x, we show
there is support for each possible value deﬁned by L. Since each bound or bit is
supported or propagated, propagation completeness follows. The order literals in
L deﬁne a range l..u given by l = max{i | [[x ≥i]] ∈L} and u = min{i−1 | ¬[[x ≥
i]] ∈L}. The order consistency Eq. (2) enforces that ¬[[x ≥i]] ∈L for i > u
and [[x ≥i]] ∈L for i < l. We show l and u are supported. Suppose that
[[bit(x, b)]] ̸= bit(l, b) ∈L for some bit b. Then there is some stable segment for
this bit including l, say rl..ru. Then the clause [[bit(x, b)]] ∨[[x < rl]] ∨[[x > ru]]
will ﬁre enforcing [[x > ru]] and hence l cannot be the lower bound. A similar
argument applies to the upper bound.

60
H. Bierlee et al.
We now show each possible value for each binary encoding variable [[bit(x, b)]]
is supported in the range l..u. Suppose to the contrary that w.l.o.g. [[bit(x, b)]] is
not true for any x ∈l..u. Then there is a stable segment rl..ru at least as large
as l..u for ¬[[bit(x, b)]]. Then the clause ¬[[bit(x, b)]] ∨[[x < rl]] ∨[[x > ru]] will
propagate ¬[[bit(x, b)]], which then must be in L. The same reasoning holds for
the negation.
The channelling also enforces the outer bounds on the binary encoding vari-
ables. Clearly d1 ≤l ≤u ≤dm so the arguments for support of binary encoding
variables automatically take into account the initial bounds.
Theorem 3. Unit propagation on the clauses of Eqs. (2) and (8) and clauses for
lexicographic encoding of y ≥lb(x) and together with the clause ¬[[x ≥ub(y)+1]]
is propagation complete for x ≤y for the language L = ORDER(x) ∪
BINARY (y).
Proof. Suppose D ∧x ≤y →[[x ≤d]] we show that unit propagation will enforce
this. The initial case given by y ≤ub(x) is enforced by the last clause. Let d be
the maximum value y can take given D, then we know that ¬[[bit(y, k)]] ∈D for all
k ∈B(y), bit(d, k) = 0 otherwise y could take a larger value. The clause Eq. (8) for
[[x ≥d + 1]] has right-hand side 
k∈B(y),¬bit(d,k)[[bit(y, k)]] and hence propagates
¬[[x ≥d + 1]] as required.
Let Y be the set of all possibly values that y can take given the D. Suppose
D ∧x ≤y →[[bit(y, k)]] for some k ∈B(y). We show that unit propagation will
enforce this. If x still sits at its initial lower bound this will be forced by the
encoding of y ≥lb(x). Otherwise, this propagation was caused by [[x ≥d]] in the
current domain, where d > min(Y )
So clearly (A) bit(v, k) = 1 for all v ∈Y ∩d.. max(y). Let (B) d′ =
max{d′′ | d′′ ∈Y, bit(d′′, k) = 0}. Clearly such a d′ exists otherwise we would
already have propagated [[bit(y, k)]], and, since d′ < d, [[x ≥d′ + 1]] is propa-
gated by Eq. (2). We claim the clause 8 for [[x ≥d′ +1]] will propagate [[bit(y, k)]].
Suppose to the contrary then there is another bit k′ where bit(d′, k′) = 0 where
¬[[bit(y, k′)]] ̸∈D. Then d′ + 2k′ ∈Y and either d′ + 2k′ ≥d contradicting (A),
or d′ + 2k′ < d contradicting (B).
While it is not possible for D ∧x ≤y →¬[[bit(y, k)]] since a lower bound
can never force a negative bit (although this can happen subsequently from the
clauses for constraint y ≤ub(y)).
References
1. Ab´ıo, I., Gange, G., Mayer-Eichberger, V., Stuckey, P.J.: On CNF encodings of
decision diagrams. In: Quimper, C.-G. (ed.) CPAIOR 2016. LNCS, vol. 9676, pp.
1–17. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-33954-2 1
2. Ab´ıo, I., Nieuwenhuis, R., Oliveras, A., Rodr´ıguez-Carbonell, E.: A parametric
approach for smaller and better encodings of cardinality constraints. In: Schulte,
C. (ed.) CP 2013. LNCS, vol. 8124, pp. 80–96. Springer, Heidelberg (2013). https://
doi.org/10.1007/978-3-642-40627-0 9

Coupling Diﬀerent Integer Encodings for SAT
61
3. Ab´ıo,
I.,
Nieuwenhuis,
R.,
Oliveras,
A.,
Rodr´ıguez-Carbonell,
E.,
Mayer-
Eichberger, V.: A new look at BDDs for pseudo-Boolean constraints. J. Artif.
Intell. Res. 45, 443–480 (2012). https://doi.org/10.1613/jair.3653
4. Ans´otegui, C., et al.: Automatic detection of at-most-one and exactly-one relations
for improved SAT encodings of pseudo-Boolean Constraints. In: Schiex, T., de
Givry, S. (eds.) CP 2019. LNCS, vol. 11802, pp. 20–36. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-30048-7 2
5. Barahona, P., H¨olldobler, S., Nguyen, V.: Eﬃcient sat-encoding of linear CSP con-
straints. In: International Symposium on Artiﬁcial Intelligence and Mathematics,
ISAIM 2014, Fort Lauderdale, FL, USA, 6–8 January 2014 (2014). http://www.
cs.uic.edu/pub/Isaim2014/WebPreferences/ISAIM2014 Barahona etal.pdf
6. Choi, C.W., Harvey, W., Lee, J.H.M., Stuckey, P.J.: Finite domain bounds con-
sistency revisited. In: Sattar, A., Kang, B.-H. (eds.) AI 2006. LNCS (LNAI), vol.
4304, pp. 49–58. Springer, Heidelberg (2006). https://doi.org/10.1007/11941439 9
7. Chu, G.: Improving combinatorial optimization. Ph.D. thesis, University of Mel-
bourne, Australia (2011). http://hdl.handle.net/11343/36679
8. Feydy, T., Stuckey, P.J.: Lazy clause generation reengineered. In: Gent, I.P. (ed.)
CP 2009. LNCS, vol. 5732, pp. 352–366. Springer, Heidelberg (2009). https://doi.
org/10.1007/978-3-642-04244-7 29
9. Frisch, A.M., Peugniez, T.J.: Solving non-Boolean satisﬁability problems with
stochastic local search. In: Nebel, B. (ed.) Proceedings of the Seventeenth Interna-
tional Joint Conference on Artiﬁcial Intelligence, IJCAI 2001, Seattle, Washington,
USA, 4–10 August 2001, pp. 282–290. Morgan Kaufmann (2001)
10. Gange, G., Berg, J., Demirovi´c, E., Stuckey, P.J.: Core-guided and core-boosted
search for CP. In: Hebrard, E., Musliu, N. (eds.) CPAIOR 2020. LNCS, vol. 12296,
pp. 205–221. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58942-
4 14
11. Gorjiara, H., Xu, G.H., Demsky, B.: Satune: synthesizing eﬃcient SAT encoders. In:
Proceedings of the ACM Programming Languages 4(OOPSLA), pp.146:1–146:32
(2020)
12. Huang, J.: Universal Booleanization of constraint models. In: Stuckey, P.J. (ed.)
CP 2008. LNCS, vol. 5202, pp. 144–158. Springer, Heidelberg (2008). https://doi.
org/10.1007/978-3-540-85958-1 10
13. Huang, J.: Search strategy simulation in constraint booleanization. In: Thirteenth
International Conference on the Principles of Knowledge Representation and Rea-
soning (2012)
14. Hurley, B., Kotthoﬀ, L., Malitsky, Y., O’Sullivan, B.: Proteus: a hierarchical port-
folio of solvers and transformations. In: Simonis, H. (ed.) CPAIOR 2014. LNCS,
vol. 8451, pp. 301–317. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-
07046-9 22
15. Ignatiev, A., Marques-Silva, J., Morgado, A.: A python library for prototyping
with sat oracles (2021). https://pypi.org/project/python-sat/
16. Martins, R., Manquinho, V., Lynce, I.: Open-WBO: a modular MaxSAT solver,.
In: Sinz, C., Egly, U. (eds.) SAT 2014. LNCS, vol. 8561, pp. 438–445. Springer,
Cham (2014). https://doi.org/10.1007/978-3-319-09284-3 33
17. Metodi, A., Codish, M., Stuckey, P.J.: Boolean equi-propagation for concise and
eﬃcient SAT encodings of combinatorial problems. J. Artif. Intell. Res. 46, 303–341
(2013). https://doi.org/10.1613/jair.3809, http://www.jair.org/papers/paper3809.
html

62
H. Bierlee et al.
18. Nethercote, N., Stuckey, P.J., Becket, R., Brand, S., Duck, G.J., Tack, G.: MiniZinc:
towards a standard CP modelling language. In: Bessi`ere, C. (ed.) CP 2007. LNCS,
vol. 4741, pp. 529–543. Springer, Heidelberg (2007). https://doi.org/10.1007/978-
3-540-74970-7 38
19. Nguyen, V., Mai, S.T.: A new method to encode the at-most-one constraint into
SAT. In: Thang, H.Q., et al. (eds.) Proceedings of the Sixth International Sym-
posium on Information and Communication Technology, Hue City, Vietnam, 3–4
December 2015. pp. 46–53. ACM (2015). https://doi.org/10.1145/2833258.2833293
20. Nguyen, V., Velev, M.N., Barahona, P.: Application of hierarchical hybrid encod-
ings to eﬃcient translation of CSPS to SAT. In: 25th IEEE International Confer-
ence on Tools with Artiﬁcial Intelligence, ICTAI 2013, Herndon, VA, USA, 4–6
November 2013, pp. 1028–1035. IEEE Computer Society (2013). https://doi.org/
10.1109/ICTAI.2013.154
21. Nightingale, P., Spracklen, P., Miguel, I.: Automatically improving SAT encoding
of constraint problems through common subexpression elimination in Savile row.
In: Pesant, G. (ed.) CP 2015. LNCS, vol. 9255, pp. 330–340. Springer, Cham (2015).
https://doi.org/10.1007/978-3-319-23219-5 23
22. Ohrimenko, O., Stuckey, P.J., Codish, M.: Propagation via lazy clause genera-
tion. Constraints Int. J. 14(3), 357–391 (2009). https://doi.org/10.1007/s10601-
008-9064-x
23. Philipp, T., Steinke, P.: PBLib – A Library for Encoding Pseudo-Boolean Con-
straints into CNF. In: Heule, M., Weaver, S. (eds.) SAT 2015. LNCS, vol. 9340,
pp. 9–16. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-24318-4 2
24. Prestwich, S.: Finding Large Cliques using SAT Local Search, chap. 15, pp. 269–
274. John Wiley, Hoboken (2007)
25. Schulte, C., Tack, G.: Views and iterators for generic constraint implementa-
tions. In: Hnich, B., Carlsson, M., Fages, F., Rossi, F. (eds.) Recent Advances in
Constraints, pp. 118–132. Springer, Berlin Heidelberg, Berlin, Heidelberg (2006).
https://doi.org/10.1007/11754602 9
26. Sinz, C.: Towards an optimal CNF encoding of Boolean cardinality constraints. In:
van Beek, P. (ed.) CP 2005. LNCS, vol. 3709, pp. 827–831. Springer, Heidelberg
(2005). https://doi.org/10.1007/11564751 73
27. Soh, T., Banbara, M., Tamura, N.: A hybrid encoding of CSP to SAT integrating
order and log encodings. In: 27th IEEE International Conference on Tools with
Artiﬁcial Intelligence, ICTAI 2015, Vietri sul Mare, Italy, 9–11 November 2015, pp.
421–428. IEEE Computer Society (2015). https://doi.org/10.1109/ICTAI.2015.70
28. Tamura, N., Banbara, M.: Sugar: a CSP to SAT translator based on order encoding.
In: Proceedings of the Second International CSP Solver Competition, pp. 65–69
(2008)
29. Tamura, N., Banbara, M., Soh, T.: Compiling pseudo-boolean constraints to SAT
with order encoding. In: 25th IEEE International Conference on Tools with Artiﬁ-
cial Intelligence, ICTAI 2013, Herndon, VA, USA, 4–6 November 2013, pp. 1020–
1027. IEEE Computer Society (2013). https://doi.org/10.1109/ICTAI.2013.153
30. Tamura, N., Taga, A., Kitagawa, S., Banbara, M.: Compiling ﬁnite linear CSP into
SAT. Constraints 14(2), 254–272 (2009)
31. Tanjo, T., Tamura, N., Banbara, M.: A compact and eﬃcient SAT-encoding of ﬁnite
domain CSP. In: Sakallah, K.A., Simon, L. (eds.) SAT 2011. LNCS, vol. 6695, pp.
375–376. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-21581-
0 36

Coupling Diﬀerent Integer Encodings for SAT
63
32. Zhou, N.-F.: In pursuit of an eﬃcient SAT encoding for the Hamiltonian cycle
problem. In: Simonis, H. (ed.) CP 2020. LNCS, vol. 12333, pp. 585–602. Springer,
Cham (2020). https://doi.org/10.1007/978-3-030-58475-7 34
33. Zhou, N.-F., Kjellerstrand, H.: The Picat-SAT compiler. In: Gavanelli, M., Reppy,
J. (eds.) PADL 2016. LNCS, vol. 9585, pp. 48–62. Springer, Cham (2016). https://
doi.org/10.1007/978-3-319-28228-2 4
34. Zhou, N.-F., Kjellerstrand, H.: Optimizing SAT encodings for arithmetic con-
straints. In: Beck, J.C. (ed.) CP 2017. LNCS, vol. 10416, pp. 671–686. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-66158-2 43

Model-Based Algorithm Conﬁguration
with Adaptive Capping and Prior
Distributions
Ignace Bleukx(B), Senne Berden, Lize Coenen, Nicholas Decleyre,
and Tias Guns
KU Leuven, Leuven, Belgium
{ignace.bleukx,senne.berden,lize.coenen,
nicholas.decleyre,tias.guns}@kuleuven.be
Abstract. Many advanced solving algorithms for constraint program-
ming problems are highly conﬁgurable. The research area of algorithm
conﬁguration investigates ways of automatically conﬁguring these solvers
in the best manner possible. In this paper, we speciﬁcally focus on algo-
rithm conﬁguration in which the objective is to decrease the time it takes
the solver to ﬁnd an optimal solution. In this setting, adaptive capping
is a popular technique which reduces the overall runtime of the search
for good conﬁgurations by adaptively setting the solver’s timeout to the
best runtime found so far. Additionally, sequential model-based opti-
mization (SMBO)—in which one iteratively learns a surrogate model
that can predict the runtime of unseen conﬁgurations—has proven to
be a successful paradigm. Unfortunately, adaptive capping and SMBO
have thus far remained incompatible, as in adaptive capping, one cannot
observe the true runtime of runs that time out, precluding the typical
use of SMBO. To marry adaptive capping and SMBO, we instead use
SMBO to model the probability that a conﬁguration will improve on
the best runtime achieved so far, for which we propose several decom-
posed models. These models also allow deﬁning prior probabilities for
each hyperparameter. The experimental results show that our DeCaprio
method speeds up hyperparameter search compared to random search
and the seminal adaptive capping approach of ParamILS.
Keywords: Algorithm conﬁguration · Adaptive capping · Sequential
model-based optimization · Prior distributions
1
Introduction
Constraint solvers are used on a daily basis for solving combinatorial optimiza-
tion problems such as scheduling, packing and routing. Because of the advanced
nature of constraint solvers today, the runtime of a solver on even a single prob-
lem instance can vary tremendously depending on its hyperparameter conﬁgu-
ration.
Ignace Bleukx and Senne Berden—These authors contributed equally.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 64–73, 2022.
https://doi.org/10.1007/978-3-031-08011-1_6

Model-Based Algorithm Conﬁguration with Adaptive Capping and Priors
65
In algorithm conﬁguration, the goal is to ﬁnd a well-performing hyperparam-
eter conﬁguration automatically. In this ﬁeld, sequential model-based optimiza-
tion (SMBO) is a highly successful paradigm [2,9,11]. Applications of SMBO
approaches aim to optimize a black-box function that evaluates a conﬁguration
by running a solver with that conﬁguration and returning the runtime. These
techniques sequentially approximate this function by observing runtimes during
the search and updating a probabilistic estimate [2]. This model can then be
exploited to direct the search towards good conﬁgurations.
However, to obtain these runtimes during the search, one is required to allow
the solver to execute until completion, regardless of the quality of the conﬁgura-
tion considered. This stands in stark contrast with adaptive capping, a technique
for optimising runtime in which solver runs using unfruitful conﬁgurations are
stopped from the moment the runtime surpasses that of the best conﬁguration
found so far [3,4,7].
This work is motivated by the observation that with adaptive capping in
place, one is especially keen on ﬁnding good conﬁgurations sooner rather than
later, as this allows decreasing the runtime timeout of all subsequent runs;
thereby reducing the runtime of the search as a whole.
To marry adaptive capping with SMBO, we step away from the idea of a
model that can estimate a conﬁguration’s runtime. Instead, our models are
related to the probability that a conﬁguration will be better than any of the
already considered ones. More speciﬁcally, we consider probabilistic models that
can be decomposed for each individual hyperparameter independently. They are
easy to compute and update, thereby keeping the overhead in between solve calls
small, and allowing to scale to an arbitrarily large number of hyperparameters.
One further beneﬁt of this decomposition is that we can now deﬁne prior
probabilities for each hyperparameter. These can overcome the cold start problem
by guiding the candidate selection from the very ﬁrst iteration. To the best of our
knowledge, prior information is only used in SMBO within advanced machine
learning models, often in the form of transfer learning techniques [14].
As a ﬁrst step, we focus in this paper on hyperparameter conﬁguration search
over a ﬁnite grid of discrete hyperparameters, and on ﬁnding the best runtime
for a single problem instance. Extensions to multiple instances and more are
discussed in the conclusion.
Our contributions are summarized as follows:
– We propose a sequential model-based optimization (SMBO) approach with
adaptive capping: DeCaprio1;
– We propose several decomposable probabilistic models that assign a high
probability to conﬁgurations that are likely to improve on the current best
runtime, and that can be updated cheaply using counting-based mechanisms;
– We propose a methodology for computing independent prior distributions for
each hyperparameter, based on a heterogeneous dataset of instances; and we
discuss how to use these prior distributions in SMBO;
1 DEcomposable adaptive CApping with PRIOrs.

66
I. Bleukx et al.
Algorithm 1. generic Sequential Model-Based Optimization, from [2]
function SMBO(f, M 0, T, S)
H ←∅
for t ←1 to T do
ˆx ←argmaxx S(x, M t−1)
Evaluate f(ˆx)
▷Expensive step
H ←H ∪{(ˆx, f(ˆx))}
Fit a new model M t to H
return H
– We show that using these decomposed distributions, especially with informed
prior probabilities, leads to faster hyperparameter conﬁguration grid search
with adaptive capping than both a random grid search baseline and the sem-
inal ParamILS approach.
2
SMBO for Hyperparameter Conﬁguration
Algorithm 1 shows a generic Sequential Model-Based Optimization [2]. It takes as
input an unknown (black-box) function f, a model M also called the surrogate
model that aims to estimate f based on the past evaluations H, a maximum
number of iterations T and a scoring function S, also called acquisition function,
that uses M t−1 to evaluate how promising it is to choose a conﬁguration ˆx as
the next conﬁguration to run.
SMBO techniques diﬀer in the way they instantiate the four inputs. For
algorithm conﬁguration of constraint solvers, the typical choice is to have f be
the runtime, objective value or optimality gap [8]; and M a machine learning
model that estimates f, such as Gaussian processes [2], tree parzen estimators
[2] or random forests [9].
An eﬀective technique from non-SMBO-based algorithm conﬁguration is to
do adaptive capping [3,7] of the runtime, with the best runtime known so far.
However, in standard SMBO, this would complicate the use of machine learning
to build a model M t of f, as one would no longer observe the real f, but a
potentially truncated version of it. So instead, to marry SMBO and adaptive
capping, we build a surrogate model M t that can be used to obtain a con-
ﬁguration ˆx that is likely to improve on the current best runtime (i.e., where
f(ˆx) < min(x,f(x))∈Hf(x)), without having to estimate ˆx’s runtime itself.
For simplicity and eﬃciency, we keep away from feature-based machine learn-
ing methods that can be costly to (re)train and that have many hyperparameters
of their own. Instead, we further decompose the surrogate over the individual
hyperparameters and use counting-based models that can be updated incremen-
tally as explained in the next section.
Another important diﬀerence with generic SMBO is that we assume a ﬁnite
grid of possible conﬁgurations X that can be exhaustively searched over. We
mimic the property of grid search that a conﬁguration is never visited twice, by
computing argmaxx S(x, M t−1) over unseen conﬁgurations only (i.e. conﬁgura-
tions not in H).

Model-Based Algorithm Conﬁguration with Adaptive Capping and Priors
67
3
Surrogate Models M and Scoring Functions S
We consider models for which we can compute M t based on M t−1 and whether
the just run conﬁguration ˆx improved the runtime or not, i.e. whether f(ˆx) <
min(x,f(x))∈Hf(x) is true.
3.1
Hamming Similarity: Searching Near the Current Best
A ﬁrst scoring function S is inspired by local search algorithms like ParamILS [7].
In local search, we ﬁrst explore conﬁgurations which are in the direct neighbor-
hood of x∗, the best conﬁguration seen so far. This allows us to deﬁne M t as
follows
M t ←ˆx if f(ˆx) improved the runtime, else M t−1
(1)
The scoring function is then the Hamming similarity between the current best
conﬁguration M t and each of the unseen conﬁgurations x. Let H be the set of
all possible hyperparameters, and let value(h, x) be the value of hyperparameter
h ∈H in conﬁguration x. We can then write the Hamming similarity score as
S(x, M t) =

h∈H
[[value(h, x) = value(h, M t)]]
(2)
where [[·]] is the Iverson bracket which converts True/False into 1/0.
3.2
Beta Distribution
In this ﬁrst probabilistic scheme, we associate a probability P t(X = x) with
every conﬁguration x. Model M t decomposes P t(X) into a separate indepen-
dent Bernoulli distribution P t(Xh,v) for every value v of every hyperparameter
h, where Xh,v is a binary random variable whose value denotes whether hyper-
parameter h takes value v. The score function then becomes
S(x, M t) = P t(X = x) =

h∈H
P t(Xh,value(h,x) = 1)
(3)
If Xh,v ∼B(ph,v), we can consider ph,v itself as uncertain—as is common
in Bayesian statistics—and use an appropriate prior distribution for ph,v, rather
than a point probability. For this purpose, we take a beta distribution, as it is
a conjugate prior for a Bernoulli distribution. This means that when the beta
prior is updated with a Bernoulli likelihood, the resulting posterior is again a
beta distribution.
A beta distribution is characterized by parameters α and β, which can be
thought of as respectively representing a number of successes (i.e. improvements
to the current best time) and failures (i.e. timeouts due to adaptive capping).
P t(Xh,v = 1) = E(ph,v) =
αt
h,v
αt
h,v + βt
h,v
(4)

68
I. Bleukx et al.
So, for every hyperparameter-value combination (h, v), we count the number
of successes αh,v and failures βh,v, which are both initialised to 1. Updating the
model M t with respect to a chosen ˆx then amounts to updating these counts
based on whether ˆx improved the current timeout rt−1 or not:
αt
h,value(h,ˆx) ←αt−1
h,value(h,ˆx) + [[f(ˆx) < rt−1]]
(5)
βt
h,value(h,ˆx) ←βt−1
h,value(h,ˆx) + [[f(ˆx) ≥rt−1]]
(6)
3.3
Dirichlet Distribution
A disadvantage of the above approach is that by maintaining a separate beta
distribution for every value, we do not utilize the knowledge that in any conﬁg-
uration, every hyperparameter takes only a single value.
In what follows, model M t instead decomposes P t(X) into a separate inde-
pendent categorical distribution P t(Xh) for every hyperparameter h, where Xh
is a random variable that denotes the value of h. The score function then becomes
S(x, M t) =

h∈H
P t
h(Xh = value(h, x))
(7)
For any hyperparameter h with k distinct values v1 . . . vk, the associated cat-
egorical distribution is characterized by parameters ph,v1 . . . ph,vk. We can again
consider these uncertain and use a prior distribution. For this purpose, we use a
Dirichlet distribution, as it is a conjugate prior for the categorical distribution.
A Dirichlet distribution is characterized by parameters αh,v1 . . . αh,vk, which can
again be thought of as success counts.
P t
h(v) = E(ph,v) =
αt
h,v
k
j=1 αt
h,vj
(8)
For every hyperparameter-value combination (h, v), we count the number of
successes αh,v, which are all initialised to 1. When a considered conﬁguration ˆx
improves the current timeout rt−1, the model M t is updated by incrementing
the appropriate counts:
αt
h,value(h,ˆx) =

αt−1
h,value(h,ˆx) + 1
if f(ˆx) improved the runtime
αt−1
h,value(h,ˆx)
otherwise
(9)
When ˆx does not improve the current timeout, we add a success count for
every other hyperparameter value, thereby discounting the values of ˆx.
While this score function can be used on its own, it can also be used as a tie
breaker when multiple conﬁgurations have the same Hamming score. This was
also considered for the beta-distribution-based model, but empirically proved to
be less eﬀective.

Model-Based Algorithm Conﬁguration with Adaptive Capping and Priors
69
4
Learning Priors
The previously described approaches all start with a uniform initial distribution
and learn which hyperparameters are better during search. However, this leaves
them with a cold start problem, meaning that the ﬁrst choices are uninformed.
However, in the adaptive capping setting, the ﬁrst conﬁgurations are the most
crucial, as any improvement in runtime saves time in all subsequent runs. Hence,
we determine the ﬁrst runtime cap using the default conﬁguration.
We now aim to take this one step further. Our goal is to learn a prior probabil-
ity distribution that plays well with the above models, that is, a prior distribution
that is decomposed for each of the hyperparameters independently. We model
each hyperparameter h’s prior as a Dirichlet distribution, which is characterized
by a pseudocount value αh,v for each value v.
To determine an informed prior, we propose to make use of a heterogeneous
set of problems K on which the solver can be run. We refer to this set as the prior
set. To cope with the sensitivity of modern solvers’ runtimes [5], and to account
for the existence of equivalent optimal conﬁgurations, we propose not to base
the priors solely on the best conﬁguration for a model (i.e. xk = argminxf k(x)).
Instead, to make the priors more robust, we propose to collect all conﬁgurations
whose runtime is at most 5% worse than the best one. Let us denote this set as
Ok for any individual problem k ∈K:
Ok = {x ∈X | f k(x) ≤1.05 · minx′∈X (f k(x′))}
(10)
This gives us a set of best conﬁgurations, on which we compute Dirichlet
pseudocounts ˆαh,v using the relative number of times hyperparameter h’s value
v was used in Ok, across all k:
ˆαh,v =

k∈K
|{x ∈Ok | value(h, x) = v}|
|Ok|
(11)
The resulting pseudocounts will have a magnitude that depends on the size
of K, which could make individual updates during SMBO insigniﬁcant if K is
large. So, to use these pseudocounts as a Dirichlet prior, we ﬁrst normalize and
scale them as αh,v = |V alues(h)| · ˆαh,v/ 
v′∈V alues(h) ˆαh,v′, where V alues(h)
denotes the set of all possible values of hyperparameter h.
5
Experiments
In this section, we empirically answer the following research questions:
Q1 How do the diﬀerent scoring functions compare in their ability to ﬁnd good
conﬁgurations quickly?
Q2 Does the use of an informed prior improve the ability to ﬁnd good conﬁgu-
rations quickly?
Q3 How does DeCaprio perform against ParamILS, a seminal hyperparameter
conﬁgurator?

70
I. Bleukx et al.
5.1
Experimental Setup
All algorithms were implemented in Python3 and run on a Intel Xeon 4214
CPU. We used a collection of 190 heterogeneous CP models2 modelled in the
CPMpy library [6]. They have a runtime3 ranging from 1 ms to 2 s when solved
using the default parameters of OR-Tools’ CP-SAT Solver v9.1 [13]. On each of
the instances, we conﬁgured 9 CP-SAT hyperparameters, totalling to a grid of
13608 conﬁgurations. All code, models and data are available in the repository
accompanying this paper4.
For the surrogates that use an informed prior, we use leave-one-out cross
validation to split the models into prior and test set. To compare results across
diﬀerent models, we introduce a metric that denotes the relative improvement
of the timeout. Here, the default’s runtime has value 0, while value 1 denotes
the runtime of the optimal conﬁguration. All results are averages over all 190
instances and 10 random seeds.
5.2
Comparison of Models and Surrogates
We want to ﬁnd good conﬁgurations as soon as possible. In Fig. 1, this corre-
sponds to an early rising curve. As baseline we use a uniform random search.
Table 1. Rel. improvement on full grid
Iteration
10
102
103
104
Random uniform 0.67 0.87 0.95 1.00
Hamming
0.56 0.92 0.99 1.00
Beta
0.63 0.87 0.97 1.00
Dirichlet
0.64 0.88 0.95 1.00
Hamm + D
0.58 0.93 0.99 1.00
Sample prior
0.79 0.92 0.98 1.00
Sorted prior
0.74 0.87 0.98 1.00
Dirichlet prior
0.81 0.87 0.94 1.00
Hamm + D prior 0.82 0.94 0.99 1.00
From Fig. 1 (left), one can conclude
that most surrogates perform more or
less equally at the start of the search.
However, further into the search, both
Hamming and Hamming + Dirichlet
tiebreaker surrogates clearly outper-
form the alternatives. This can also
be seen in Table 1. This answers Q1.
Using the same metric, we ana-
lyze the performance of the surrogates
with an informed prior. We introduce
two additional baseline algorithms:
Sample prior and Sorted prior. These
respectively sample and take the argmax of the prior probabilities. Neither algo-
rithm updates its model during the search. The results of these baseline algo-
rithms clearly show the importance of a good update rule. Figure 1 (right) and
Table 1 show that using an informed prior clearly yields better performance early
in the search. This answers Q2.
5.3
Comparison with ParamILS
We cannot compare to SMBO techniques like SMAC [10] as they do not support
adaptive capping and hence would have unwieldy large total runtimes. ParamILS
2 From H˚akan Kjellerstrand’s collection: http://www.hakank.org/cpmpy/.
3 The number of threads was limited to 1 for every solver call.
4 https://github.com/ML-KULeuven/DeCaprio.

Model-Based Algorithm Conﬁguration with Adaptive Capping and Priors
71
Fig. 1. Relative improvement per iteration. Left: no prior, Right: informed prior
is a seminal algorithm conﬁguration method supporting adaptive capping [7].
Still, its computational overhead is signiﬁcant on small instances so we have to
compare on a smaller grid of 200 conﬁgurations. We use the same settings used
by the original authors and calculate the relative improvement based on the
global best runtime found.
Table 2. Small grid
Iteration
10
50
100
200
Random uniform 0.71 0.94 0.97 1.00
Hamm + D
0.77 0.98 0.99 1.00
Hamm + D prior 0.89 0.98 0.99 1.00
ParamILS
0.76 0.98 0.99 1.00
The results of this experiment
are summarized in Table 2. Here, we
notice that ParamILS performs about
equally well as the uninformed Ham-
ming + Dirichlet. When comparing
with an informed prior, however, our
method obtains notably better per-
formance in the ﬁrst iterations (and
hence in the total solve time, not
shown).
6
Conclusion and Future Work
In this paper we proposed a scheme for marrying SMBO-based approaches with
adaptive capping in the context of algorithm conﬁguration, by using decompos-
able models and surrogates related to the probability of a runtime improvement.
To make more informed decisions in early iterations we show how to obtain
and use Dirichlet priors per hyperparameter. Using such prior knowledge showed
big improvements over all other methods. Their decomposed nature also means
they are easy to extend and combine with new hyperparameters and values, and
we envision solver developers to precompute these on their own benchmarks.
In general, algorithm conﬁguration techniques, even SMBO ones, make exten-
sive use of sampling and our light-weight prior-based approach can replace or
be combined with current (often random) sampling schemes used, potentially
guiding the methods better in their early iterations.
Many directions for future work remain, including evaluating our method on
larger datasets with more solvers and models and extending it to conﬁguration
over multiple instances, where racing and successive halving [1,12] are orthogonal
techniques that can be combined with the ideas presented in this paper.

72
I. Bleukx et al.
Acknowledgments. This research was partly funded by the Flemish Government (AI
Research Program), the Research Foundation - Flanders (FWO) projects G0G3220N
and S007318N and the European Research Council (ERC) under the EU Horizon 2020
research and innovation programme (Grant No 101002802, CHAT-Opt).
A
Adapted SMBO
Algorithm 2. our Sequential Model-Based Optimization
function SMBO(f, M 0, X, S, xdefault, ˆT)
ˆx ←xdefault
r ←f(xdefault)
H ←∅
T ←min(|X|, ˆT)
for t ←1 to T do
ˆx ←argmaxx∈X\H S(x, M t−1)
Evaluate f(ˆx), cap runtime at r
▷Expensive step
Fit a new model M t by updating M t−1 with (ˆx, [f(ˆx) < r])
H ←H ∪{ˆx}
r ←min(r, f(ˆx))
return H
References
1. Anastacio, M., Hoos, H.: Model-based algorithm conﬁguration with default-guided
probabilistic sampling. In: B¨ack, T. (ed.) PPSN 2020. LNCS, vol. 12269, pp. 95–
110. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58112-1 7
2. Bergstra, J., Bengio, Y.: Algorithms for hyper-parameter optimization. In: In NIPS,
pp. 2546–2554 (2011)
3. C´aceres, L.P., L´opez-Ib´a˜nez, M., Hoos, H., St¨utzle, T.: An experimental study of
adaptive capping in irace. In: Battiti, R., Kvasov, D.E., Sergeyev, Y.D. (eds.) LION
2017. LNCS, vol. 10556, pp. 235–250. Springer, Cham (2017). https://doi.org/10.
1007/978-3-319-69404-7 17
4. De Souza, M., Ritt, M., L´opez-Ib´a˜nez, M.: Capping methods for the automatic
conﬁguration of optimization algorithms. Comput. Oper. Res. 139, 105615 (2021)
5. Fichte, J.K., Hecher, M., McCreesh, C., Shahab, A.: Complications for computa-
tional experiments from modern processors. In: 27th International Conference on
Principles and Practice of Constraint Programming (CP 2021). Schloss Dagstuhl-
Leibniz-Zentrum f¨ur Informatik (2021)
6. Guns, T.: Increasing modeling language convenience with a universal n-dimensional
array, cppy as python-embedded example. In: Proceedings of the 18th workshop
on Constraint Modelling and Reformulation, Held with CP, vol. 19 (2019)
7. Hutter, F., Hoos, H., Leyton-Brown, K., St¨utzle, T.: Paramils: an automatic algo-
rithm conﬁguration framework. J. Artif. Intell. Res. (JAIR) 36, 267–306 (2009)

Model-Based Algorithm Conﬁguration with Adaptive Capping and Priors
73
8. Hutter, F., Hoos, H.H., Leyton-Brown, K.: Automated conﬁguration of mixed inte-
ger programming solvers. In: Lodi, A., Milano, M., Toth, P. (eds.) CPAIOR 2010.
LNCS, vol. 6140, pp. 186–202. Springer, Heidelberg (2010). https://doi.org/10.
1007/978-3-642-13520-0 23
9. Hutter, F., Hoos, H.H., Leyton-Brown, K.: Sequential model-based optimization
for general algorithm conﬁguration. In: Coello, C.A.C. (ed.) LION 2011. LNCS,
vol. 6683, pp. 507–523. Springer, Heidelberg (2011). https://doi.org/10.1007/978-
3-642-25566-3 40
10. Hutter, F., Hoos, H.H., Leyton-Brown, K.: Sequential model-based optimization for
general algorithm conﬁguration. In: Coello, C.A.C. (ed.) Learning and Intelligent
Optimization, pp. 507–523. Springer, Berlin Heidelberg, Berlin, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-25566-3 40
11. Kerschke, P., Hoos, H.H., Neumann, F., Trautmann, H.: Automated algorithm
selection: survey and perspectives. Evol. Comput. 27(1), 3–45 (2019). https://doi.
org/10.1162/evco a 00242
12. L´opez-Ib´a˜nez, M., Dubois-Lacoste, J., C´aceres, L.P., Birattari, M., St¨utzle, T.:
The irace package: iterated racing for automatic algorithm conﬁguration. Oper.
Res. Perspect. 3, 43–58 (2016)
13. Perron, L., Furnon, V.: Or-tools. https://developers.google.com/optimization/
14. Yogatama, D., Mann, G.: Eﬃcient transfer learning method for automatic hyper-
parameter tuning. In: Artiﬁcial Intelligence and Statistics, pp. 1077–1085. PMLR
(2014)

Shattering Inequalities for Learning
Optimal Decision Trees
Justin J. Boutilier, Carla Michini, and Zachary Zhou(B)
Department of Industrial and Systems Engineering,
University of Wisconsin-Madison, Madison, WI, USA
{jboutilier,michini,zzhou246}@wisc.edu
Abstract. Recently, mixed-integer programming (MIP) techniques
have been applied to learn optimal decision trees. Empirical research
has shown that optimal trees typically have better out-of-sample perfor-
mance than heuristic approaches such as CART. However, the underlying
MIP formulations often suﬀer from slow runtimes, due to weak linear
programming (LP) relaxations. In this paper, we ﬁrst propose a new
MIP formulation for learning optimal decision trees with multivariate
branching rules and no assumptions on the feature types. Our formula-
tion crucially employs binary variables expressing how each observation
is routed throughout the entire tree. We then introduce a new class of
valid inequalities for learning optimal multivariate decision trees. Each
inequality encodes an inclusion-minimal set of points that cannot be shat-
tered by a multivariate split, and in the context of a MIP formulation,
the inequalities are sparse, involving at most the number of features plus
two variables. We leverage these valid inequalities within a Benders-like
decomposition, where the master problem determines how to route each
observation to a leaf node to minimize misclassiﬁcation error, and the
subproblem checks whether, for each branch node of the decision tree, it
is possible to construct a multivariate split that realizes the given rout-
ing of observations; if not, the subproblem adds at least one of our valid
inequalities to the master problem. We demonstrate through numerical
experiments that our MIP approach outperforms (in terms of training
accuracy, testing accuracy, solution time, and relative gap) two other
popular MIP formulations, and is able to improve both in and out-of-
sample performance, while remaining competitive in terms of solution
time to a wide range of popular approaches from the literature.
Keywords: Decision trees · Mixed-integer programming · Machine
learning
1
Introduction
Decision trees are among the most popular techniques for interpretable machine
learning [9]. In addition to their use as a standalone method, decision trees form
the foundation for several more sophisticated machine learning algorithms such
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 74–90, 2022.
https://doi.org/10.1007/978-3-031-08011-1_7

Shattering Inequalities
75
0
1
2
3
4
5
0
1
2
3
4
5
0
1
2
3
4
5
0
1
2
3
4
5
0
1
2
3
4
5
0
1
2
3
4
5
0
1
2
3
4
5
0
1
2
3
4
5
(a)
(b)
(c)
(d)
Fig. 1. (a) Eight univariate branching rules are required to correctly separate the black
and white observations; (b) only one multivariate branching rule suﬃces. For a slightly
diﬀerent toy dataset: (c) and (d) show how the feature space is partitioned when using
univariate and multivariate branching rules, respectively.
as random forest [8,23]. Although there are many ways to express a decision
tree, the majority of the literature, including this paper, focuses on binary trees.
In a binary decision tree, each internal node, referred to as a branch node, has
exactly two children and observations are routed to the left or right child node
according to a branching rule. Terminal nodes in the tree are referred to as leaf
nodes and each leaf node is assigned a class k such that any observation routed
to that leaf node is classiﬁed as belonging to class k. Almost all algorithms
(heuristic and exact) that generate decision trees focus on univariate branching
rules, which check if the value of a single feature exceeds a prescribed thresh-
old. In this work, we instead focus on multivariate branching rules, which are
separating hyperplanes checking several features at a time. Multivariate branch-
ing rules are less easily interpretable, however they provide more ﬂexibility than
univariate branching rules, which can only resort to axis-aligned hyperplanes.
As a consequence, multivariate branching rules can yield much more compact
decision trees. In other words, even if the tests performed at the branching nodes
are more complex, the total number of tests needed to achieve a target accuracy
can be dramatically smaller; see the toy example in Fig. 1.
Related Work. The problem of learning optimal decision trees is NP-hard
[20]. As a result, there exist several famous top-down induction algorithms for
learning decision trees such as CART [9] and ID3 [28]. These heuristic methods
do not provide any guarantee on the quality of the decision trees computed. More
recently, a number of exact approaches have been proposed that typically aim at
minimizing the training error and possibly some measure of the tree complexity.
One stream of work uses mixed-integer programming (MIP) to compute opti-
mal decision trees. Motivated by algorithmic advances in integer optimization,
Bertsimas and Dunn [7] ﬁrst formulated the problem of learning an optimal
decision tree as a MIP. Their work spurred a series of subsequent papers that
propose a variety of MIP tools to model and solve the problem of learning optimal
decision trees [1,2,12,16,34,35,37]. One main advantage of MIP approaches is
their ﬂexibility: the problem objective can be easily modiﬁed to enhance feature
selection and/or tree size, and the feasible set can be modiﬁed by adding addi-
tional constraints of practical interest [1,16]. Moreover, MIP formulations can

76
J. J. Boutilier et al.
easily handle multivariate branching rules [7,37]. Typically, MIP formulations
contain two key components: 1) a framework to model the routing of observa-
tions through the decision tree to leaf nodes, and 2) a framework that properly
constructs the tree by devising branching rules at each branch node. Most MIP
approaches employ big-M constraints to unify these two components in a single
optimization problem [7,34,37], but this modeling technique suﬀers from the fact
that big-M constraints notoriously lead to poor LP relaxations [36]. One notable
exception is the work of Aghaei et al. [2], who consider datasets with binary fea-
tures and formulate the problem of routing observations through a ﬁxed decision
tree with univariate branching rules as a max-ﬂow problem. Thanks to these two
key assumptions – having binary features and restricting to univariate branching
rules – they can avoid using big-M constraints. Moreover, their formulation is
amenable to a Benders decomposition, where the master problem is tasked with
constructing the decision tree, and the routing of observations to leaf nodes is
accomplished by solving a subproblem for each observation that adds optimality
cuts to the master. Unfortunately, their ﬂow-based approach does not generalize
if we relax either of the two key assumptions.
Another stream of work uses Boolean satisﬁability (SAT) [5,22,26,29], con-
straint programming (CP) [32,33], and dynamic programming [3,4,13,19,25,27]
to compute optimal decision trees. These methods address the scalability issues
of general MIP methods by using a diﬀerent range of techniques to explore the
search space, such as sub-sampling, branch and bound search, and caching. Some
of these algorithms are tailored to the speciﬁc structure of decision trees, which
is used to speed-up computation. However, 1) all of them assume binary features
or use binarization techniques to transform numerical features into binary ones
in a preprocessing step, which can dramatically increase the size of the input
(causing memory problems) and is not guaranteed to preserve optimality [24];
2) most of them are designed and/or implemented to work only for binary clas-
siﬁcation; and 3) all of them are only suited to construct decision trees with
univariate branching rules.
Our Contribution. We ﬁrst propose a new MIP formulation for learning opti-
mal decision trees with multivariate branching rules and no assumptions on the
feature types. Our formulation employs only binary variables to (i) express how
each observation is routed in the decision tree and (ii) express the objective func-
tion as a weighed sum of the training accuracy and the size of the tree. Moreover,
we exploit the structure of decision trees and use a geometric interpretation of the
optimal decision tree problem to devise a specialized class of valid inequalities,
called shattering inequalities, which intuitively detect problematic sub-samples
of the dataset that cannot be linearly separated. We leverage these inequalities
within a Benders-like decomposition [6] to decompose our formulation into a
master problem that determines how to route each observation to a leaf node,
and a collection of linear programming (LP) feasibility subproblems that certify
whether, for each branch node of the decision tree, it is possible to construct a
multivariate branching rule that realizes the given routing of observations. If it
is not possible to realize the routing, then we add one of our valid inequalities to

Shattering Inequalities
77
the master problem as a feasibility cut. Each of our inequalities encodes a mini-
mal set of points that cannot be shattered by a multivariate branching rule and
in the context of a MIP formulation, the inequalities are sparse, with at most the
number of features plus two variables. Our approach does not require big-M con-
straints, but generates sparse cuts that capture the combinatorial structure of the
problem to strengthen the LP relaxation and decrease training time. Although
we use these cuts in a decomposition algorithm for our formulation, they can be
directly applied as valid inequalities to other MIP formulations that may not be
suited to decomposition (e.g., OCT-H [7] and SVM1-ODT [37]). We demonstrate
through numerical experiments that our MIP approach outperforms (in terms
of training accuracy, testing accuracy, solution time, and relative gap) two other
popular MIP formulations, and is able to improve both in and out-of-sample
performance, while remaining competitive in terms of solution time to a wide
range of popular approaches from the literature.
2
The Optimal Decision Tree Problem
In this section, we formally introduce the problem setting, our notation, and our
formulation.
2.1
The Optimal Decision Tree Problem
We ﬁrst deﬁne our data, which includes a training set of N observations, each
of which has p numerical features and belongs to one of K classes. For n ∈N,
we denote by [n] the set {1, . . . , n}. Without loss of generality, we normalize
the training set so that all features are scaled to [0, 1]. Thus, each observation
i ∈[N] is a vector (xi, yi) ∈[0, 1]p × [K].
As noted in Sect. 1, we focus on learning optimal binary decision trees with
multivariate branching rules, which we refer to as multivariate splits. Each node
in the tree is either a branch node or a leaf node. Note that the ﬁrst node in the
tree is colloquially referred to as the root node (even though it is a branch node).
The model is built upon a binary tree where every branch node has exactly two
children and the leaves are all on the same level. The maximum depth of the
decision tree D ∈N is deﬁned as the length of the path from the root to any leaf.
We denote the set of branch nodes as B = {1, . . . , 2D −1}. Each branch node
t corresponds to a multivariate split deﬁned by learned parameters at ∈Rp
and bt ∈R. The multivariate split is applied as follows: for each observation
x ∈[0, 1]p, if a⊤
t x ≤bt, then x is sent to the left child of t, denoted by 2t;
otherwise it is sent to the right child, denoted by 2t + 1. The key diﬀerence
between multivariate and univariate splits is that a univariate split allows only
one component of at to be non-zero. We denote the set of leaf nodes by L =
{2D, . . . , 2D+1 −1}. Each leaf node t is a terminal node (i.e., it has no children)
and is assigned a class k ∈[K]. All observations routed to leaf t are classiﬁed as
belonging to class k.
The max depth D ∈N is often used as a hyperparameter to control the
complexity and size of the tree. To deter the model from constructing a full

78
J. J. Boutilier et al.
binary tree of depth D, we use another hyperparameter α ≥0 that penalizes the
number of leaf nodes in our objective function (more on this in Sect. 2.2).
2.2
Problem Formulation
We now present a formulation for learning an optimal decision tree – the training
problem – that includes a set of complicating constraints. For each branch node
t ∈B, we can either deﬁne a branching rule establishing whether an incoming
observation should be sent to the left or to the right child of t, in which case we
say that node t applies a split, or we can direct all of the incoming observations
to the left child of t. Correspondingly, we introduce a binary variable dt that is
equal to 1 if t applies a split, and to 0 otherwise. The decision variables d thus
deﬁne the tree topology. For each t ∈B we have p + 1 variables (at, bt) deﬁning
the multivariate split associated with the branch node. If t does not apply a
split, it is feasible to set these variables to (0, 0).
For each observation i ∈[N] and for each node t ∈B ∪L of the decision tree,
we introduce a binary variable wit that is equal to 1 if observation i is sent to
node t, and to 0 otherwise. The decision variables w thus deﬁne how to route
the observations from the root node to the leaf nodes.
For each class k ∈[K] and leaf node t ∈L, we introduce a binary decision
variable ckt that is equal to 1 if t is assigned class label k, and to 0 other-
wise. Finally, for each observation i ∈[N] and leaf node t ∈L, we introduce a
binary-valued decision variable zit that is equal to 1 if i is sent to leaf t and is
correctly classiﬁed as yi, and to 0 otherwise. We will later see that the integrality
constraints on z can be relaxed. Our formulation for the training problem is
minimize
c,d,w,z,a,b
1
N
N

i=1

1 −

t∈L
zit

+ α

t∈B
dt
(1a)
subject to

t∈L
wit = 1
∀i ∈[N],
(1b)
wit = wi,2t + wi,2t+1
∀i ∈[N], t ∈B,
(1c)
wi,2t+1 ≤dt
∀i ∈[N], t ∈B,
(1d)
K

k=1
ckt = 1
∀t ∈L,
(1e)
zit ≤wit
∀i ∈[N], t ∈L,
(1f)
zit ≤cyi,t
∀i ∈[N], t ∈L,
(1g)
ckt ∈{0, 1}
∀k ∈[K], t ∈L,
(1h)
dt ∈{0, 1}
∀t ∈B,
(1i)
wit ∈{0, 1}
∀i ∈[N], t ∈B ∪L,
(1j)
zit ∈R
∀i ∈[N], t ∈L,
(1k)
(at, bt) ∈Ht(w)
∀t ∈B,
(1l)

Shattering Inequalities
79
where, for each branch node t ∈B and integral w satisfying (1b)–(1d), the set
Ht(w) is deﬁned as
Ht(w) =

(at, bt) ∈Rp+1 : a⊤
t xi + 1 ≤bt
∀i ∈[N] : wi,2t = 1,
(2)
a⊤
t xi −1 ≥bt
∀i ∈[N] : wi,2t+1 = 1} .
(3)
Note that, for a ﬁxed w, the set Ht(w) is a (possibly empty) polyhedron in
Rp+1.
The objective function (1a) is derived from CART’s cost-complexity mea-
sure: for ﬁxed i ∈[N], the term 1 −
t∈L zit is 1 if observation i is misclas-
siﬁed, 0 otherwise, therefore the misclassiﬁcation rate over the training set is
1
N
N
i=1

1 −
t∈L zit

; the second term weights the number of leaf nodes (to
which at least one observation is directed), which is equal to the number of
branch nodes (that apply a nontrivial split) plus one.
Constraints (1b) ensure that each observation is mapped to exactly one leaf,
while constraints (1c) guarantee that each observation routed to a branch node
t is sent to either the left or the right child of t. For a branch node t that does
not apply a split, constraints (1d) automatically send any incoming observations
to the left child of t. Constraints (1e) assign each leaf node a class in [K].
Constraints (1f) and (1g) enforce the condition that if zit = 1, then wit = 1 and
cyi,t = 1 (i.e., observation i is sent to leaf t and is correctly classiﬁed as yi).
Note that integrality constraints are not required for the z variables, since they
are implied by the integrality of w and c, and by the fact that at an optimal
solution constraints (1f) and (1g) hold with equality. Complicating constraints
(1l) are the only ones involving variables (at, bt), t ∈B, which ensure that the
routing deﬁned by w can be realized by multivariate splits. This is possible if
and only if for each branch node t we have Ht(w) ̸= ∅.
We highlight some technical diﬀerences between our formulation and other
MIP models in the literature. First, we focus on an alternative means to char-
acterizing the set of feasible routings w. As mentioned in Sect. 1, most MIP
formulations link the w and (at, bt), t ∈B variables using big-M constraints.
However, we have formulated the problem in such a way that these big-M con-
straints are not necessary. Second, we deﬁne w over all nodes of the decision
tree, while previous literature deﬁnes w over only the leaf nodes [7,16,37]. Our
primary motivation for deﬁning additional (roughly double) w variables is that
we can exploit these additional variables to create stronger valid inequalities for
characterizing the set of feasible routings. A secondary reason for the introduc-
tion of w variables over the branch nodes is that these extra variables give us the
option to formulate a model using big-M constraints, but with far fewer of them
than existing formulations. For instance, OCT and OCT-H [7] require 2DND
big-M constraints for deﬁning the feasible routings w, whereas we only require
N(2D+1 −2). Finally, we penalize the total number of splits used as part of our
objective function. Unlike the univariate setting where CART’s cost-complexity
measure can be directly used as a template, the multivariate setting has no uni-
versally accepted objective. For example, OCT-H [7] penalizes the total number

80
J. J. Boutilier et al.
of features used over all splits in the tree and SVM1-ODT [37] penalizes the ℓ1
norm of at over all splits in the tree.
3
Shattering Inequalities
In this section, we propose a new class of valid inequalities for (1), called shat-
tering inequalities, which correspond to subsets of observations that cannot be
shattered by a multivariate split, and we propose a separation algorithm to gen-
erate these inequalities.
Let C be a family of binary classiﬁers in Rp. A set of observations is shattered
by C if, for any assignment of binary labels to these observations, there exists
some classiﬁer in C that can perfectly separate all the observations. The maxi-
mum number of observations that can be shattered by C is called the Vapnik-
Chervonenkis (VC) dimension of C [31].
We now consider the family of binary classiﬁers H consisting of the multivari-
ate splits in Rp. Let I be a collection of subsets I ⊆[N] of observations such that

xi	
i∈I cannot be shattered by H. For each I ∈I, denote by Λ(I) ⊂{−1, 1}I
the assignments of binary labels to observations in I so that they cannot be per-
fectly separated by any multivariate split in Rp. Then, the following inequalities
are valid for (1):

i∈I:λi=−1
wi,2t +

i∈I:λi=+1
wi,2t+1 ≤|I| −1,
∀I ∈I, λ ∈Λ(I), t ∈B.
(4)
The shattering inequalities (4) have the form of packing constraints [11] and
impose the condition that at least one observation in I is not routed to the chil-
dren of t as prescribed by the label assignment λ. We can restrict our attention
to the minimal (w.r.t. set inclusion) subsets of I. Indeed, if I ∈I is not minimal,
then each inequality (4) associated to I is implied by an inequality (4) associated
to some I′ ⊂I in I.
Moreover, if I is a minimal set of observations in Rp that cannot be shattered
by H, then |I| ≤p + 2. This follows from the fact that the VC dimension of H is
p+1. Note that we might still be unable to perfectly split |I| < p+2 observations
in Rp if there exists an hyperplane that contains more than p points. For example,
for p = 2, three points on a line labeled (in sequence) 1, −1, 1 cannot be perfectly
split. As a consequence, the support of inequalities (4) corresponding to minimal
sets of observations in Rp that cannot be shattered by H, is at most p + 2. In
particular, if p ≪N, these inequalities are sparse.
Figure 2 shows an example using a dataset with points xi = (xi
1, xi
2) ∈R2,
where for the ﬁrst four observations, x1 = (0, 0), x2 = (0, 1), x3 = (1, 0), x4 =
(1, 1); the full dataset may contain many more observations. I = {1, 2, 3, 4} is
an example of a minimal subset of observations that cannot be shattered by H;
no hyperplane is capable of separating {x1, x4} from {x2, x3}, however I \ {i}
can be shattered for any i ∈I. We can derive the shattering inequalities:
w2,2t + w3,2t + w1,2t+1 + w4,2t+1 ≤3,
∀t ∈B
(5)

Shattering Inequalities
81
)
b
(
)
a
(
Fig. 2. I = {1, 2, 3, 4} is a minimal subset of observations that cannot be shat-
tered by H. Λ(I) contains exactly two vectors λ = (λ1, λ2, λ3, λ4). (a) shows λ =
(+1, −1, −1, +1), which is used to derive (5); (b) shows λ = (−1, +1, +1, −1), which is
used to derive (6).
and
w1,2t + w4,2t + w2,2t+1 + w3,2t+1 ≤3,
∀t ∈B.
(6)
3.1
Decomposition and Separation
We decompose (1) into a master problem and an LP feasibility subproblem. The
master problem is obtained from (1) by removing the complicating constraints
(1l) and by (possibly) adding some valid inequalities (4). Thus, the master prob-
lem is a MIP with decision variables c, d, w, z. The LP feasibility subproblem
includes decision variables (at, bt), t ∈B, and veriﬁes that, for a given assign-
ment of w, Ht(w) is a nonempty polyhedron for all t ∈B. Intuitively, the master
problem attempts to ﬁnd an optimal routing of the observations to the leaves
deﬁned by w, and the LP feasibility subproblem attempts to ﬁnd, at each branch
node t, a multivariate split (at, bt) that realizes this routing. If at some branch
node there is no multivariate split that is able to route the incoming observations
according to w, then our goal is to generate an inequality (4) that is violated
by w. This inequality is added to the master problem as a feasibility cut, and
the process is repeated until the subproblem becomes feasible, meaning that w
satisﬁes all inequalities (4).
Next we show how to dynamically generate inequalities (4). As we shall see
later, this process can be interpreted as an application of combinatorial Benders
(CB) cuts [10,18] to the decomposition of (1) outlined above. Let (c, d, w, z) be a
solution to the master problem. For each t ∈B, deﬁne I(t) = {i ∈[N] : wit = 1}
as the set of observations arriving at node t, and consider the partition of I(t)
into I(2t) and I(2t + 1). From (2) we have that Ht(w) ̸= ∅if and only if
the observations in I(2t) can be perfectly separated from the observations in
I(2t + 1) by a multivariate split, i.e., if and only if the following system of linear
inequalities in variables (at, bt) is feasible:

82
J. J. Boutilier et al.

a⊤
t xi + 1 ≤bt, ∀i ∈I(2t),
a⊤
t xi −1 ≥bt, ∀i ∈I(2t + 1).
(7)
Our goal is to either certify that system (7) is feasible for all t ∈B or, if (7) is
infeasible for some t ∈B, to return an inclusion-minimal subset of observations
I′ ⊆I(t), such that I′ ∩I(2t) cannot be perfectly separated from I′ ∩I(2t+1) by
a multivariate split. Each such subset I′ corresponds to an Irreducible Infeasible
Subsystem (IIS) of the infeasible system (7), which is deﬁned as a subsystem of
(7) that would become feasible by discarding one arbitrary inequality. Once we
have found an IIS of (7) indexed by I′ ⊆I(t), we add the following cut to the
master problem:

i∈I′∩I(2t)
wi,2t +

i∈I′∩I(2t+1)
wi,2t+1 ≤|I′| −1.
(8)
Inequality (8) is clearly violated by w, and is a shattering inequality (4).
To ﬁnd an IIS of the infeasible system (7), we construct a dual polyhedron
Qt which is obtained by applying Farkas’ lemma to (7):
Qt =
⎧
⎨
⎩q ∈RI(t)
+
:

i∈I(2t)
qixi =

i∈I(2t+1)
qixi,

i∈I(2t)
qi =

i∈I(2t+1)
qi = 1
⎫
⎬
⎭.
(9)
In fact, there is a one-to-one correspondence between the IISs of (7) and the
vertices of Qt [15]. Speciﬁcally, the indices of the inequalities appearing in an
IIS of (7) correspond to the support of a vertex of Qt, and vice versa. We
remark that the polyhedron Qt has a very nice geometric interpretation. The
decision variables q are associated with the observations indexed by I(t) =
I(2t) ∪I(2t + 1), and they can be interpreted as the coeﬃcients of two convex
combinations, one on the observations in I(2t) and the other on the observations
in I(2t+1). It is evident from (9) that Qt is nonempty if and only if there exists
a point that is both in the convex hull of

xi	
i∈I(2t) and in the convex hull of

xi	
i∈I(2t+1).
Based on the above discussion, we can deﬁne a separation algorithm to
dynamically generate the shattering inequalities (4). This algorithm receives as
input a feasible solution (c, d, w, z) of the master problem, and it either estab-
lishes that w satisﬁes all inequalities (4), or it returns an inequality of family
(4) that is violated by w. Precisely, for each t ∈B, the algorithm checks the fea-
sibility of the dual polyhedron Qt. If Qt is empty for all t ∈B, then by Farkas’
Lemma system (7) is feasible for all t ∈B, thus the LP subproblem is feasible
and we can construct an optimal solution to (1) which realizes the routing pre-
scribed by w. If Qt is nonempty for some t ∈B, then by Farkas’ Lemma system
(7) is infeasible, and from each vertex of Qt we can construct an IIS of (7) and
a corresponding shattering inequality (8) that is violated by w. In practice, it
is possible to eﬃciently generate multiple inequalities (8) by ﬁnding multiple
vertices of Qt. One method for ﬁnding multiple vertices is to optimize over Qt

Shattering Inequalities
83
multiple times with diﬀerent objective functions. For instance, let f ∈ZI(t)
+
be
a counter for the number of inequalities (8) that each observation in I(t) has
appeared in thus far. One can repeatedly solve max{f ⊤q : q ∈Qt}, each time
updating f as a cut is added.
The separation algorithm can be implemented via LP with a run time that is
polynomial in 2D and size(X), where X is the N ×p matrix encoding the features
of the observations in the training set and size(X) is deﬁned as the number of
bits required to encode X [30]. Note that there is an exponential dependence
with respect to the depth parameter D. However, the number of variables and
constraints of our MIP formulation (as well as the other formulations from the
literature) are already exponential in D and in practice, we want D to be small
so that we can obtain a more interpretable decision tree.
We conclude this section by observing that our formulation (1) and its decom-
position can be used to generate the shattering inequalities (8) as CB cuts. CB
cuts are a specialization of Hooker’s logic-based Benders decomposition [18].
They are formally introduced by Codato and Fischetti [10], who study MIP
problems that can be decomposed into a master problem with binary variables,
and an LP subproblem whose feasibility depends from the solution of the master
problem.
The shattering inequalities (8) can be interpreted as CB cuts by enforcing
the complicating constraints (1l) through the following logical constraints (note
that left children have an even index, while right children have an odd index):
∀i ∈[N], t ∈B ∪L \ {1}, wit = 1 =⇒

(at/2)⊤xi + 1 ≤bt/2
if t is even
(a⌊t/2⌋)⊤xi −1 ≥b⌊t/2⌋
if t is odd.
After solving the master problem, if the inequality system given by the activated
logical constraints (i.e., those where wit = 1) is infeasible, the IISs of the system
can be used to derive CB cuts. A key observation is that, in our setting, each IIS
involves only the components of w that pertain to a speciﬁc branch node t ∈B.
As a result, we can separately consider the inequality systems (7) associated
with each individual branch node t ∈B.
4
Experiments
In this section, we provide two sets of numerical experiments to benchmark two
implementations of our approach (S-OCT-FULL and S-OCT-BEND) with four
approaches from the literature: OCT and OCT-H [7], MIP models for learning
optimal univariate and multivariate trees respectively, implemented by Inter-
pretable AI [21]; FlowOCT (solved using Benders decomposition) [2], MIP mod-
els for learning univariate trees on datasets with binary features; and DL8.5 [3],
an itemset mining-based approach that uses branch-and-bound and caching.
4.1
Experimental Setup
We applied all decision tree implementations to the following ﬁfteen commonly
used datasets obtained from the UCI Machine Learning Repository [14]: (A)

84
J. J. Boutilier et al.
Balance Scale, (B) Banknote Authentication, (C) Blood Transfusion, (D) Breast
Cancer, (E) Climate Model Crashes, (F) Congressional Voting Records, (G)
Glass Identiﬁcation, (H) Hayes-Roth, (I) Image Segmentation, (J) Ionosphere,
(K) Iris, (L) Parkinsons, (M) Soybean (Small), (N) Tic-Tac-Toe Endgame, and
(O) Wine. Since FlowOCT and DL8.5 require binary features, we perform an
additional bucketization step for the numerical datasets [25]; for every feature j,
we sort the observations according to this feature, ﬁnd consecutive observations
with diﬀerent class labels (and diﬀerent values for feature j), and deﬁne a binary
feature that has value 1 if and only if xj is less than the average of the two
adjacent feature values. Aside from this peculiarity, we perform the standard
one-hot encoding for categorical features and normalize numerical features to
the [0, 1] interval.
We partitioned each dataset so that 75% of the observations are used for
training and 25% for testing. We tuned the complexity hyperparameter α for S-
OCT and FlowOCT1 by partitioning the training set so that two-thirds is truly
used for training and one-third is used for validation. We searched over ﬁve α
values: {0.00001, 0.0001, 0.001, 0.01, 0.1}. Interpretable AI automatically tunes α
for OCT and OCT-H. There is no α for DL8.5.
Our experiments were programmed using Python 3.8.10 and all optimization
problems were solved using Gurobi 9.5 [17] on a machine with a 3.00 GHz 6-
core Intel Core i5-8500 processor and 16 GB RAM. A 10-minute time limit was
imposed for all optimization problems. Our code can be found at https://github.
com/zachzhou777/S-OCT.
Direct MIP Comparison. Our entire approach is grounded in formulation (1),
which crucially uses the binary variables w to model how observations are routed
throughout the decision tree. A straightforward way to turn our formulation (1)
into a MIP formulation is to use big-M constraints to model constraints (1l)
(we test the implementation without big-M constraints in the next section).
We call the corresponding MIP formulation S-OCT-FULL. Our ﬁrst goal is to
test the strength of S-OCT-FULL against two other MIP formulations, namely
OCT-H and FlowOCT. Note that OCT-H uses multivariate branching rules,
while FlowOCT is tailored to datasets with binary features and uses univariate
branching rules. When dealing with datasets having numerical features, we apply
the preprocessing step described in Sect. 4.1 before applying FlowOCT. Note
that since (in this experiment) we focus on comparing the strength of the MIP
formulation rather than its eﬃcacy as practical machine learning method, we
do not employ warm starts or early stopping (as we do in the comprehensive
experiments).
Comprehensive Comparison. In the second set of experiments, we com-
pare the practical performance of our approach against a wider range of other
1 We modify the FlowOCT objective to 1) minimize error rate plus a regularization
term and 2) use α rather than λ ∈[0, 1) for regularization, to be consistent with
other models.

Shattering Inequalities
85
methods, both within and outside of MIP. Besides S-OCT-FULL, we also con-
sider the decomposition approach that uses shattering inequalities described in
Sect. 3.1, which we call S-OCT-BEND. We compare S-OCT-FULL and S-OCT-
BEND against OCT and OCT-H (as implemented by Interpretable AI [21]),
FlowOCT, and DL8.5. Our goal is to assess the performance of these models,
even given limited training time. Oftentimes, MIP-based decision trees are able
to produce near-optimal solutions within seconds, and additional solving time
produces marginal improvements (if any). Therefore, for the MIP models (aside
from OCT and OCT-H, as Interpretable AI’s implementations of these are a
black box), we terminate the solve if 60 s pass without a new incumbent solu-
tion being found. We also feed the MIP models a warm start; for FlowOCT, we
feed CART’s solution, and for S-OCT, we feed the results of a top-down greedy
induction where an S-OCT stump (a tree with depth 1) is applied at each branch
node so as to maximize training accuracy (similar to [7]).
4.2
Results
Direct MIP Comparison. Figure 3 displays boxplots of the training accuracy,
testing accuracy, solution time, and the relative gap for S-OCT-FULL, OCT-H,
and FlowOCT at depth 2 and 3. The average ± standard deviation training
(testing) accuracy was 0.938 ± 0.122 (0.870 ± 0.136) for S-OCT-FULL, 0.912
± 0.146 (0.836 ± 0.145) for OCT-H, and 0.833 ± 0.139 (0.811 ± 0.137) for
FlowOCT. The average solution time (relative gap) was 158.7±255.1 (0.237 ±
0.408) for S-OCT-FULL, 194.5 ± 258.8 (0.289 ± 0.453) for OCT-H, and 312.5
± 269.1 (0.463 ± 0.366) for FlowOCT. Across all 30 instances (15 for each
depth), S-OCT-FULL timed out for seven instances, OCT-H timed out for eight
instances, and FlowOCT timed out for eighteen instances. Overall, we ﬁnd that
S-OCT-FULL achieved the highest average training and testing accuracy across
all 15 datasets with the fastest average solution time and the smallest average
relative gap.
Comprehensive Comparison. Table 1 provides a detailed comparison of the
numerical results for each dataset and for six diﬀerent model implementations.
We ﬁrst compare the results between S-OCT-FULL and S-OCT-BEND to high-
light the improvement in solution time oﬀered by our benders implementation.
Both models achieved similar training accuracy (0.960 ± 0.088 for S-OCT-FULL
and 0.951 ± 0.105 for S-OCT-BEND), while S-OCT-FULL achieved a higher
testing accuracy (0.901 ± 0.115 vs. 0.876 ± 0.145) and S-OCT-BEND achieved
a faster solution time (44.6 ± 10.7 vs. 29.2 ± 9.9). These diﬀerences are likely
due to the early stopping criteria used as part of our S-OCT-BEND imple-
mentation, which allows us to achieve similar testing performance with shorter
solution times as compared to S-OCT-FULL. However, even in instances where
both S-OCT-FULL and S-OCT-BEND solved to optimality, the in-sample and
out-of-sample accuracy may diﬀer due to the existence of multiple optimal solu-
tions. Note that these models optimize a combination of in-sample accuracy and

86
J. J. Boutilier et al.
Fig. 3. Boxplots of the training accuracy, testing accuracy, solution time, and the
relative gap for S-OCT, OCT-H, and FlowOCT at depth 2 and 3.
a regularization term on the number of branch nodes being used; hence even the
in-sample accuracy may diﬀer between S-OCT-FULL and S-OCT-BEND.
Next, we compare the in-sample accuracy achieved by all models. We ﬁnd
that S-OCT-FULL performed best (0.960 ± 0.088), followed by S-OCT-BEND
(0.951 ± 0.105) and OCT-H (0.948 ± 0.086). The remaining models all per-
formed signiﬁcantly worse: OCT (0.882 ± 0.118), DL8.5 (0.883 ± 0.121), and
FlowOCT (0.859 ± 0.140). We observe that the multivariate models (S-OCT-
FULL, S-OCT-BEND, and OCT-H) signiﬁcantly outperform the univariate
models (DL8.5, FlowOCT, OCT). Intuitively, this makes sense because univari-
ate models require more depth to achieve comparably complex branching rules
(see Fig. 1).
We ﬁnd similar results for out-of-sample accuracy, where S-OCT-FULL per-
formed best (0.901 ± 0.115), followed closely by OCT-H (0.885 ± 0.115) and
S-OCT-BEND (0.876 ± 0.145). The remaining models achieve an average test-
ing accuracy of 0.849 ± 0.125 (OCT), 0.846 ±0.126 (DL8.5), and 0.821 ± 0.155
(FlowOCT). Finally, we compare solutions times between all approaches. The
average solution time was 44.6 ± 56.3 for S-OCT-FULL, 29.2 ± 30.0 for S-OCT-
BEND, 0.7 ± 1.7 for OCT, 15.0 ± 18.6 for OCT-H, 18.0 ± 46.1 for DL8.5, and
57.4 ± 38.6 for FlowOCT. Although our models had the second and third slow-
est solutions times, they are able to ﬁnd the (provably) optimal solution in 9/15
instances.
Figure 4 displays line plots of the training accuracy, testing accuracy, and
solution time across all 15 datasets (sorted for clarity) and for all six models
at depth four. The line plots visualize the results in Table 1 for depth four;
we see that both S-OCT-FULL and S-OCT-BEND achieve the highest training

Shattering Inequalities
87
accuracy for all datasets and the highest testing accuracy for 12/15 datasets.
Our models are comparable in terms of solution time for 9/15 datasets; for the
remaining seven datasets, our models are slightly slower.
5
Conclusion
We proposed a new MIP formulation for the optimal decision tree problem. Our
approach directly deals with numerical features and leverages the higher mod-
eling power of multivariate branching rules. We also introduced a new class of
valid inequalities and an exact decomposition approach that uses these inequal-
ities as feasibility cuts. These inequalities exploit the structure of decision trees
and express the geometrical properties of the dataset at hand. We demonstrate
through numerical experiments that our MIP approach outperforms (in terms
of training accuracy, testing accuracy, solution time, and relative gap) two other
popular MIP formulations, and is able to improve both in and out-of-sample
performance, while remaining competitive in terms of solution time to a wide
range of popular approaches from the literature. Finally, we note that our for-
mulation and the shattering inequalities (4) are general and can be extended to
any binary classiﬁer used to implement the branching rules. When the branching
rules are implemented via multivariate splits, the separation of the shattering
inequalities can be performed eﬃciently. However, the separation may become
more challenging if we consider more complex classiﬁers.
Fig. 4. Line plots across all 15 datasets (sorted for clarity) of the training accuracy,
testing accuracy, and solution time for all six models at depth four.

88
J. J. Boutilier et al.
Table 1. Detailed summary of comprehensive comparisons.
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
(K)
(L)
(M)
(N)
(O)
Observations (N) 468
1029
561
426
405
326
160
132
210
263
112
146
35
718
133
Features (p)
20
4
4
30
18
48
9
15
19
34
4
22
72
27
13
Buckets
N/A
1303
105
3499
1149
N/A
487
N/A
1657
1779
35
892
N/A
N/A
456
Classes (K)
3
2
2
2
2
2
6
3
7
2
3
2
4
2
3
Results for D = 2
In-sample accuracy (%)
SOCTFULL
100.0
100.0 80.57
100.0 99.26
100.0 70.0
90.91
57.14
100.0
100.0 100.0
100.0 100.0 100.0
SOCTBEND
100.0
100.0 80.57
100.0 100.0 100.0 74.38
90.91
57.14
100.0
100.0 97.26
100.0 100.0 100.0
OCT
68.59
93.0
79.5
96.01
93.33
95.4
69.38
60.61
57.14
90.87
96.43
91.1
100.0 65.74
93.98
OCTH
99.79
99.51
82.17
97.18
98.02
100.0 73.12
90.15
57.14
95.82
96.43
97.26
97.14
100.0 96.99
DL8.5
68.59
93.0
79.68
96.01
93.83
96.01
69.38
60.61
57.14
91.25
96.43
91.1
100.0 72.14
96.99
FLOWOCT
68.59
91.55
78.07
94.13
91.11
95.4
64.38
60.61
42.86
90.87
96.43
91.1
100.0 72.14
96.99
Out-of-sample accuracy (%)
SOCTFULL
98.73
100.0 73.26
95.1
95.56 97.25 59.26
78.57
56.14
90.91
97.37 79.59
100.0 95.83 97.78
SOCTBEND
98.73
100.0 73.26
95.1
93.33
97.25 59.26
82.14
55.57
88.64
97.37 77.55
100.0 95.83 97.78
OCT
66.88
91.84
70.59
94.41
94.07
96.33
55.56
67.86
56.57
92.05
89.47
89.8
100.0 64.17
84.44
OCTH
98.09
98.54
75.94
96.5
94.81
89.91
53.7
78.57
56.57
92.05
89.47
93.88
91.67
95.42
95.56
DL8.5
66.88
91.55
69.52
94.41
94.07
95.41
55.56
75.0
56.52
90.91
89.47
93.88
100.0 65.83
95.56
FLOWOCT
66.88
91.55
70.59
93.01
92.59
96.33
55.56
67.86
42.71
92.05
89.47
91.84
100.0 65.83
95.56
Computational time (s)
SOCTFULL
1.27
6.36
108.15 4.55
55.49
0.81
149.88 8.68
1.03
109.04 0.2
33.28
0.21
10.69
0.28
SOCTBEND
0.64
5.48
106.57 3.71
11.39
0.43
98.43
20.65
19.34
30.55
0.14
137.43 0.16
9.69
0.18
OCT
8.48
0.76
0.16
0.54
0.29
0.3
0.09
0.07
0.19
0.33
0.03
0.17
7.83
0.33
0.09
OCTH
25.0
10.3
3.01
15.81
10.9
19.06
2.72
2.39
4.38
14.69
0.39
4.64
3.62
50.55
2.49
DL8.5
0.0
4.5
0.03
35.93
3.56
0.01
0.59
0.0
8.27
6.94
0.0
1.64
0.0
0.01
0.33
FLOWOCT
1.07
65.23
60.13
65.97
64.45
2.75
60.41
0.47
60.72
72.15
0.23
93.48
0.51
61.5
61.9
Results for D = 3
In-sample accuracy (%)
SOCTFULL
100.0
100.0 81.46
100.0 100.0 100.0 90.62
90.91
98.57
100.0
100.0 95.21
100.0 100.0 100.0
SOCTBEND
100.0
100.0 81.46
100.0 99.26
100.0 85.0
90.91
57.14
100.0
100.0 100.0
100.0 100.0 100.0
OCT
73.08
97.76
80.57
98.36
95.56
95.4
76.25
72.73
84.76
93.54
98.21
98.63
100.0 75.63
99.25
OCTH
100.0
100.0 82.53
99.3
99.01
100.0 83.12
89.39
93.33
98.1
96.43
100.0
100.0 99.44
97.74
DL8.5
74.15
93.68
81.64
96.48
93.58
97.85
80.0
74.24
65.24
92.02
100.0 100.0
100.0 78.69
100.0
FLOWOCT
73.72
93.97
80.75
95.54
96.3
97.24
74.38
74.24
57.14
92.4
100.0 95.89
100.0 76.6
99.25
Out-of-sample accuracy (%)
SOCTFULL
98.73
100.0 73.26
95.1
93.33
97.25 70.37
85.71
93.0
89.77
97.37 87.76
100.0 95.83
97.78
SOCTBEND
98.73
100.0 73.26
95.1
95.56 97.25 53.7
71.43
56.0
88.64
97.37 81.63
100.0 95.83
97.78
OCT
68.79
96.5
74.87
95.8
93.33
96.33
64.81
75.0
81.43
92.05
97.37 97.96
91.67
72.92
97.78
OCTH
95.54
100.0 77.54
95.1
94.07
92.66
61.11
82.14
83.57
96.59
89.47
97.96
91.67
96.25 86.67
DL8.5
71.97
92.42
72.73
90.91
90.37
93.58
68.52
89.29
63.71
89.77
97.37 95.92
100.0 73.75
93.33
FLOWOCT
71.97
93.0
75.4
91.61
91.85
93.58
62.96
89.29
56.67
92.05
97.37 93.88
91.67
71.67
91.11
Computational time (s)
SOCTFULL
2.28
6.96
97.09
6.3
13.52
1.68
182.6
51.54
148.03 88.04
0.43
109.17 0.32
12.57
0.48
SOCTBEND
0.98
5.87
97.63
3.89
82.26
0.56
89.06
60.94
60.54
20.63
0.2
20.55
0.17
9.91
0.27
OCT
0.5
0.65
0.19
1.0
0.51
0.46
0.16
0.1
0.32
0.73
0.04
0.26
0.05
0.69
0.14
OCTH
21.18
10.97
4.07
23.19
16.58
19.12
4.37
3.03
10.66
24.26
0.49
7.56
2.97
77.92
2.99
DL8.5
0.02
0.01
2.69
2.19
1.35
0.13
244.93 0.01
0.53
2.67
0.01
54.99
0.0
0.06
3.07
FLOWOCT
77.7
88.52
60.61
109.1
62.81
63.15
61.36
20.59
75.47
66.38
4.08
87.22
0.01
60.79
60.86
Results for D = 4
In-sample accuracy (%)
SOCTFULL
100.0
100.0 82.0
100.0 100.0 100.0 97.5
90.91
99.05
99.62
100.0 95.21
100.0 100.0 100.0
SOCTBEND
100.0
100.0 82.0
100.0 100.0 100.0 93.12
90.91
100.0
100.0
100.0 100.0
100.0 100.0 100.0
OCT
75.64
99.71
80.57
97.89
95.56
97.55
85.62
84.09
92.38
92.78
96.43
96.58
100.0 84.96
99.25
OCTH
100.0
100.0 82.53
97.42
99.01
100.0 85.62
90.91
99.52
98.48
96.43
100.0
100.0 100.0 97.74
DL8.5
78.85
97.47
83.96
98.59
96.05
99.39
78.75
84.09
82.86
97.34
100.0 100.0
100.0 87.19
100.0
FLOWOCT
75.0
96.31
78.43
99.3
95.56
95.4
79.38
67.42
70.48
94.68
100.0 84.93
100.0 85.1
100.0
Out-of-sample accuracy (%)
SOCTFULL
98.73
100.0 72.73
95.1
93.33
97.25 66.67
82.14
92.1
85.23
97.37 87.76
100.0 95.83
97.78
SOCTBEND
98.73
100.0 72.73
95.1
93.33
97.25 53.7
71.43
90.24
88.64
97.37 77.55
100.0 95.83
97.78
OCT
71.97
98.83
74.87
95.8
93.33
93.58
70.37
82.14
87.9
92.05
89.47
95.92
91.67
82.08
91.11
OCTH
95.54
100.0 78.07
96.5
94.81 92.66
68.52
67.86
89.52
93.18
89.47
91.84
100.0 96.67 86.67
DL8.5
73.89
95.34
72.19
91.61
88.89
90.83
62.96
89.29
77.48
92.05
97.37 97.96
83.33
80.83
95.56
FLOWOCT
70.7
93.29
70.59
90.91
93.33
96.33
66.67
35.71
69.05
88.64
97.37 91.84
91.67
82.08
82.22
Computational time (s)
SOCTFULL
6.05
10.74
92.25
8.37
15.42
4.43
128.31 120.29 147.42 120.64 0.54
121.07 0.55
18.08
0.94
SOCTBEND
1.53
6.63
90.82
4.29
11.81
0.83
89.9
60.61
98.44
15.82
0.32
25.06
0.19
11.12
0.36
OCT
0.72
0.85
0.29
1.17
0.6
0.63
0.22
0.15
0.42
0.71
0.05
0.31
0.06
1.44
0.18
OCTH
27.4
10.22
4.79
20.29
21.87
19.23
6.11
3.49
19.57
34.92
0.49
8.72
2.63
91.83
3.02
DL8.5
0.15
0.05
142.38 97.92
30.4
2.07
0.96
0.03
9.28
103.14 0.01
47.48
0.0
0.72
2.44
FLOWOCT
128.38 86.22
168.05 77.36
61.6
60.54
71.92
133.35 62.13
68.93
0.03
35.45
0.01
60.25
0.37

Shattering Inequalities
89
References
1. Aghaei, S., Azizi, M.J., Vayanos, P.: Learning optimal and fair decision trees for
non-discriminative decision-making (2019)
2. Aghaei, S., Gomez, A., Vayanos, P.: Learning optimal classiﬁcation trees: strong
max-ﬂow formulations (2020)
3. Aglin, G., Nijssen, S., Schaus, P.: Learning optimal decision trees using caching
branch-and-bound search. Proc. AAAI Conf. Artif. Intell. 34(04), 3146–3153 (2020)
4. Aglin, G., Nijssen, S., Schaus, P.: Pydl8.5: a library for learning optimal decision
trees. In: Bessiere, C. (ed.) Proceedings of the Twenty-Ninth International Joint
Conference on Artiﬁcial Intelligence, IJCAI-20, pp. 5222–5224. International Joint
Conferences on Artiﬁcial Intelligence Organization, demos (2020)
5. Avellaneda, F.: Eﬃcient inference of optimal decision trees. Proc. AAAI Conf.
Artif. Intell. 34(04), 3195–3202 (2020)
6. Benders, J.F.: Partitioning procedures for solving mixed-variables programming
problems. Numer. Math. 4(1), 238–252 (1962)
7. Bertsimas, D., Dunn, J.: Optimal classiﬁcation trees. Mach. Learn. 106(7), 1039–
1082 (2017). https://doi.org/10.1007/s10994-017-5633-9
8. Breiman, L.: Random forests. Mach. Learn. 45(1), 5–32 (2001). https://doi.org/
10.1023/A:1010933404324
9. Breiman, L., Friedman, J., Stone, C.J., Olshen, R.A.: Classiﬁcation and Regression
Trees. CRC Press, Boca Raton (1984)
10. Codato, G., Fischetti, M.: Combinatorial benders’ cuts for mixed-integer linear
programming. Oper. Res. 54(4), 756–766 (2006)
11. Cornu´ejols, G.: Combinatorial optimization: packing and covering. CBMS-NSF
Regional Conference Series in Applied Mathematics, Society for Industrial and
Applied Mathematics (2001)
12. Dash, S., G¨unl¨uk, O., Wei, D.: Boolean decision rules via column generation (2020)
13. Demirovi´c, et al.: Murtree: optimal classiﬁcation trees via dynamic programming
and search (2021)
14. Dua, D., Graﬀ, C.: UCI machine learning repository (2017). http://archive.ics.uci.
edu/ml
15. Gleeson, J., Ryan, J.: Identifying minimally infeasible subsystems of inequalities.
INFORMS J. Comput. 2, 61–63 (1990)
16. Gunluk, O., Kalagnanam, J., Li, M., Menickelly, M., Scheinberg, K.: Optimal gen-
eralized decision trees via integer programming (2019)
17. Gurobi Optimization, L.: Gurobi optimizer reference manual (2021). http://www.
gurobi.com
18. Hooker, J., Ottosson, G.: Logic-based benders decomposition. Math. Prog. 96
(2001)
19. Hu, H., Siala, M., Hebrard, E., Huguet, M.J.: Learning optimal decision trees with
maxsat and its integration in adaboost. In: Bessiere, C. (ed.) Proceedings of the
Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence, IJCAI-20,
pp. 1170–1176. International Joint Conferences on Artiﬁcial Intelligence Organiza-
tion (2020)
20. Hyaﬁl, L., Rivest, R.L.: Constructing optimal binary decision trees is np-complete.
Inf. Process. Lett. 5(1), 15–17 (1976)
21. Interpretable
AI,
L.:
Interpretable
ai
documentation
(2021).
https://www.
interpretable.ai

90
J. J. Boutilier et al.
22. Janota, M., Morgado, A.: SAT-based encodings for optimal decision trees with
explicit paths. In: Pulina, L., Seidl, M. (eds.) SAT 2020. LNCS, vol. 12178, pp.
501–518. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-51825-7 35
23. Liaw, A., Wiener, M., et al.: Classiﬁcation and regression by randomforest. R News
2(3), 18–22 (2002)
24. Lin, J., Zhong, C., Hu, D., Rudin, C., Seltzer, M.: Generalized and scalable optimal
sparse decision trees. In: International Conference on Machine Learning, pp. 6150–
6160. PMLR (2020)
25. Lin, J.J., Zhong, C., Hu, D., Rudin, C., Seltzer, M.I.: Generalized and scalable
optimal sparse decision trees. In: ICML (2020)
26. Narodytska, N., Ignatiev, A., Pereira, F., Marques-Silva, J.: Learning optimal deci-
sion trees with sat. In: Proceedings of the Twenty-Seventh International Joint
Conference on Artiﬁcial Intelligence, IJCAI-18, pp. 1362–1368. International Joint
Conferences on Artiﬁcial Intelligence Organization (2018)
27. Nijssen, S., Fromont, E.: Mining optimal decision trees from itemset lattices. In:
Proceedings of the 13th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 530–539. KDD 2007, Association for Computing
Machinery, New York (2007)
28. Quinlan, J.R.: Induction of decision trees. Mach. Learn. 1(1), 81–106 (1986)
29. Schidler, A., Szeider, S.: Sat-based decision tree learning for large data sets. Proc.
AAAI Conf. Artif. Intell. 35(5), 3904–3912 (2021)
30. Schrijver, A.: Theory of Linear and Integer Programming. Wiley, Chichester (1986)
31. Vapnik, V.: Statistical Learning Theory. Wiley, New York (1998)
32. Verhaeghe, H., Nijssen, S., Pesant, G., Quimper, C.-G., Schaus, P.: Learning
optimal decision trees using constraint programming. Constraints 25(3), 226–250
(2020). https://doi.org/10.1007/s10601-020-09312-3
33. Verhaeghe, H., Nijssen, S., Pesant, G., Quimper, C.G., Schaus, P.: Learning optimal
decision trees using constraint programming (extended abstract). In: Bessiere, C.
(ed.) Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial
Intelligence, IJCAI-20, pp. 4765–4769. International Joint Conferences on Artiﬁcial
Intelligence Organization (2020)
34. Verwer, S., Zhang, Y.: Learning optimal classiﬁcation trees using a binary linear
program formulation. In: Proceedings of the Thirty-Third AAAI Conference on
Artiﬁcial Intelligence (AAAI-19), pp. 1625–1632. 27 Jan 2019—01 Feb 2019. AAAI
Press (2019)
35. Verwer, S., Zhang, Y.: Learning decision trees with ﬂexible constraints and objec-
tives using integer optimization. In: Salvagnin, D., Lombardi, M. (eds.) Integration
of AI and OR Techniques in Constraint Programming, pp. 94–103. Springer Inter-
national Publishing, Cham (2017). https://doi.org/10.1007/978-3-319-59776-8 8
36. Wolsey, L.: Integer Programming. Wiley Series in Discrete Mathematics and Opti-
mization, Wiley, Hoboken (1998)
37. Zhu, H., Murali, P., Phan, D.T., Nguyen, L.M., Kalagnanam, J.: A scalable mip-
based method for learning optimal multivariate decision trees. In: Larochelle, H.,
Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) Advances in Neural Informa-
tion Processing Systems 33: Annual Conference on Neural Information Processing
Systems 2020, NeurIPS 2020 6–12 December 2020, virtual (2020)

Learning Pseudo-Backdoors for Mixed
Integer Programs
Aaron Ferber1(B)
, Jialin Song2
, Bistra Dilkina1
, and Yisong Yue3
1 University of Southern California, Los Angeles, USA
{aferber,dilkina}@usc.edu
2 NVIDIA, Santa Clara, USA
jialins@nvidia.com
3 California Institute of Technology, Pasadena, USA
yyue@caltech.edu
Abstract. We propose a machine learning approach for quickly solving
Mixed Integer Programs (MIPs) by learning to prioritize sets of branch-
ing variables at the root node which result in faster solution times, which
we call pseudo-backdoors. Learning-based approaches have seen success
in combinatorial optimization by ﬂexibly leveraging common structures
in a given distribution of problems. Our approach takes inspiration from
the concept of strong backdoors, which are small sets of variables such
that only branching on these variables yields an optimal integral solu-
tion and a proof of optimality. Our notion of pseudo-backdoors corre-
sponds to a small set of variables such that prioritizing branching on
them when possible leads to faster solve time. A key advantage of pseudo-
backdoors over strong backdoors is that they retain the solver’s optimal-
ity guarantees and are amenable to data-driven identiﬁcation. Our pro-
posed method learns to estimate the relative solver speed of a candidate
pseudo-backdoor and determine whether or not to use it. This pipeline
can be used to identify high-quality pseudo-backdoors on unseen MIP
instances for a given MIP distribution. We evaluate our method on ﬁve
problem distributions and ﬁnd that our approach can eﬃciently iden-
tify high-quality pseudo-backdoors. In addition, we compare our learned
approach against Gurobi, a state-of-the-art MIP solver, demonstrating
that our method can be used to improve solver performance.
1
Introduction
Mixed integer programs (MIPs) are ﬂexible combinatorial optimization problems
[8], which consist of setting variables to optimize a linear objective function sub-
ject to both linear and integrality constraints. MIPs can be solved via the branch-
and-bound algorithm [30], which explores the solution space using tree search
by branching on decision variables and pruning provably suboptimal subtrees.
Many heuristic components of MIP solvers impact runtime such as node selec-
tion, primal heuristics, cut generation, and variable selection [1]. Recent work
has focused on data-driven machine learning approaches for variable selection to
dynamically recommend which variable to branch on throughout the search pro-
cess, based on features computed at each search node [4,16,25,34]. We examine
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 91–102, 2022.
https://doi.org/10.1007/978-3-031-08011-1_8

92
A. Ferber et al.
a diﬀerent problem of predicting high-priority variables at the top of the branch-
and-bound tree, leveraging the concept of backdoors, which represent variables
that are core to solving a given combinatorial problem. Backdoors are intro-
duced in [40] for solving Constraint Satisfaction Problems (CSPs), with “weak
backdoors” being a small set of variables that satisfy the following property:
there exists an assignment to this subset of variables such that the remaining
unassigned CSP subproblem can be solved in polynomial time. In a “strong
backdoor” any setting of the backdoor variables leads to a polynomially-solvable
subproblem. Later, backdoors are generalized to combinatorial optimization and
MIPs [10,11], where a strong backdoor is a subset of integer variables such that
only branching on them yields a provably optimal solution, making the problem
complexity dependent on backdoor size rather than problem size. While back-
doors have theoretical and practical limitations in CSP and SAT [23,24,36],
recent work has shown that prioritizing “backdoor” sets of branching variables
can speed up MIP solving [15,27]. Prioritizing “backdoor” sets of branching vari-
ables at the start of tree search means that they take precedence for branching
when possible. As a result, if the MIP is not solved by only branching on “back-
door” variables, the solver can ﬁnish by using non-backdoor variables. Thus, a
set of prioritized variables resulting in fast runtimes may not strictly be a strong
or weak backdoor and to clarify this distinction, we refer to a fast-solving set of
integer variables as a pseudo-backdoor.
Our goal in ﬁnding pseudo-backdoors is to quickly solve MIPs. In a MIP we
need to ﬁnd real values for n decision variables x ∈Rn, maximizing a linear
objective function cT x, subject to m linear constraints Ax ≤b, with a subset
I ⊆[n] of variables required to be integral xi ∈Z ∀i ∈I. Formally we solve
min{cT x|Ax ≤b, xj ∈Z ∀i ∈I}. Given a MIP P = (c, A, b, I), we aim to
ﬁnd a pseudo-backdoor B ⊆I which quickly solves the MIP. We consider a
distributional MIP solving setting where we train a pseudo-backdoor identiﬁer
on training instances to quickly solve unseen MIPs.
We propose a data-driven approach to identifying pseudo-backdoors for MIP
distributions by learning a scoring model to select a pseudo-backdoor with
fast runtime and a classiﬁcation model to predict whether the selected pseudo-
backdoor will beat the default solver. If suggested, we instruct the MIP solver to
branch on pseudo-backdoor variables before other variables. We represent MIPs
as featurized bipartite graphs with variable and constraint nodes as in [16], using
graph attention networks [39] with global attention pooling [32] to learn both
models. We evaluate empirically on neural network veriﬁcation [17], facility loca-
tion [9], and the generalized independent set problem (gisp) [7], showing that our
models identify pseudo-backdoors that quickly solve MIPs compared to Gurobi.
2
Related Work
Backdoors in SAT & MIP: Backdoors were introduced to represent the core
hardness in Constraint Satisfaction Problems (CSP) [40], where the authors ana-
lyzed CSP time complexity assuming various sized backdoors exist. [10] extend

Learning Pseudo-Backdoors for MIP
93
the deﬁnition of backdoors to general combinatorial optimization problems. Both
works study the practical existence of backdoors, ﬁnding small backdoors for
realistic problems. [28] propose collecting highly-branched variables for iden-
tifying backdoors in SAT. In MIP, [12] study fracture backdoors which are
variables whose removal would result in a natural MIP decomposition. Addi-
tionally, [15] identify MIP pseudo-backdoors by solving a set covering problem,
and observe that prioritizing branching on pseudo-backdoors can quickly solve
some MIPLIB [29] instances. Recent work uses Monte Carlo Tree Search to sam-
ple pseudo-backdoors for a given MIP [27]. These approaches identify pseudo-
backdoors from scratch in individual MIP instances rather than MIP distribu-
tions, and can’t operate on new instances without re-running the entire proce-
dure. Our method is the ﬁrst data-driven attempt to predict pseudo-backdoors
using labeled data which frontloads the computational overhead of ﬁnding fast-
solving pseudo-backdoors on a training set for deployment on unseen instances
without rerunning pseudo-backdoor search.
Learning in Combinatorial Optimization: Machine learning has shown
promise improving combinatorial optimization. In exact MIP solving, machine
learning operates in various heuristic components like selecting variables at
search nodes [4,16,25], running primal heuristics [26], or performing neural div-
ing [34]. These algorithms operate inside the solver, and can complement our
approach which treats the solver as a black box, whether learning-augmented or
not. Several approaches improve runtime by learning performant solver conﬁgu-
rations [2,21,22]. Our approach leverages the structural connection between the
MIP formulation and a set of hyperparameters, the variable branching priorities,
to improve solve time rather than predicting global hyperparamters.
3
Learning Pseudo-Backdoors
We use two learned models: a scorer that ranks subsets of integer variables
according to their runtime, and a classiﬁer that predicts whether the best-scoring
subset will improve solve time compared to running a default solver. The clas-
siﬁer ensures that even when it is hard to sample pseudo-backdoors we can still
algorithmically run the default solver.
Figure 1 illustrates our method’s deployment. Given an unseen MIP, we ran-
domly sample ﬁxed-sized subsets of integer variables according to their LP frac-
tionality as in [10], scoring the sampled subsets and predicting the best-scoring
subset to be a pseudo-backdoor. The classiﬁer then predicts whether the identi-
ﬁed pseudo-backdoor is faster than the default solver. If so, we assigning higher
branching priorities to variables in the pseudo-backdoor and solve; otherwise,
we use the default solver. The scorer S(P, B; θS) has neural network parameters
θS, using the MIP P and candidate subset B to score B based on runtime. The
classiﬁer C(P, B; θC) has neural network parameters θC taking the same input
(P, B) to predict whether B will outperform the default solver.

94
A. Ferber et al.
LP Relaxation
MIP
Pseudo-Backdoor 
samples
Scoring module
(GAN + Attention Pooling)
Classification module
Solve with 
or gurobi?
(GAN + Attention Pooling)
Solve with 
Gurobi
using 
Solve with
Gurobi
Fig. 1. The pseudo-backdoor pipeline for a single MIP instance consisting of a scorer
S(P, B; θS) and classiﬁer C(P, B; θC). k pseudo-backdoor sets of decision variables
B1, . . . , Bk are sampled according to LP fractionality. These candidate sets are ranked
by the scoring module S(P, B; θS) to predict the best pseudo-backdoor B∗. The clas-
siﬁcation module determines whether or not to run the solver using B∗based on the
predicted pseudo-backdoor success probability C(P, B∗; θC).
3.1
MIP and Backdoor Data Representation
We want to ensure that our architecture can operate on variable-sized MIP
instances, incorporate pseudo-backdoor information B, and yield predictions
invariant to unimportant changes in MIP formulations such as variable or con-
straint permutations. Thus, we represent the MIP as a bipartite graph as in [16].
The bipartite graph representation ensures the MIP encoding is invariant to vari-
able and constraint permutation. Additionally, we can use a variety of predic-
tive models designed for variable-sized graphs, enabling deployment on problems
with varying numbers of variables and constraints. The MIP is represented as
a featurized bipartite graph P = (G, C, E, V), with graph G containing variable
nodes and constraint nodes. Additionally, there is an edge (i, j) ∈E between a
variable node i and a constraint node j iﬀthe variable i appears in constraint j
with nonzero coeﬃcient i.e. Ai,j ̸= 0. Constraint, variable, and edge features are
represented as matrices C ∈Rm×c, E ∈R|E|×e, V ∈Rn×v, and are described
in Table 1. Pseudo-backdoor sets B are represented with a binary variable fea-
ture which is 1 for variables in B and 0 otherwise. Encoding the input (P, B) as
a featurized bipartite graph allows us to leverage state-of-the-art techniques in
making predictions on variable-sized graphs.
3.2
Neural Network Architecture
Given the graph encoding of the MIP and candidate backdoor set, we can apply
a variety of graph prediction methods such as those in the pytorch geometric
library [14]. These approaches generate high-level node embeddings via message
passing, where a node’s embedding is an aggregation of those of it’s neighbors.
Previous work used the Graph Convolutional Network (GCN) [16] to predict
branching scores on individual variable nodes at a given branch and bound node.
However, we were unable to train a GCN model to predict either scores or suc-
cess probabilities. Alternatively, we found that Graph Attention Network (GAT)

Learning Pseudo-Backdoors for MIP
95
Table 1. Variable, constraint, and edge features that encode a MIP instance.
Category
Name (count) Description
V Vars
type (3)
Variable type (continuous, binary, integer)
obj coef
The decision variable’s objective coeﬃcient
has lb
Does the variable have a lower bound?
has ub
Does the variable have an upper bound?
root lp at lb
Variable at it’s lower bound in the root LP?
root lp at ub
Variable at it’s upper bound in the root LP?
root lp frac
Is the variable fractional in the root LP?
lp basis (4)
Variable root LP status (basic, lower, upper, superbasic)
E Edges
coef
Constraint coeﬃcient
C Constrs
obj cos sim
Cosine similarity of objective and constraint
bias
Constant bias
root lp tight
Constraint tightness in the root LP
root lp dual
Dual value In the root LP
sense (3)
Constraint direction (≤, ≥, =)
worked in our setting [39]. Here a node’s high-level embedding is a weighted
aggregation of the embeddings of its neighbors and edges, where the weights
are themselves predicted via a network layer as done in attention-based models
[38], thus allowing the model to attend to variable or constraint nodes which
are most useful for generating the next iteration’s embedding. Formally, the
GAT performs the message passing iteration in Eq. 1 to compute embeddings x′
i
for graph node i based on the neighbors of i, N(i) with attention weights αi,j
using neural network weights θ. The attention weights are given by Eq. 2 using
learnable parameters a on node embeddings x and edge features E.
x′
i = αi,iθxi +

j∈N(i)
αi,jθxj
(1)
αi,j =
exp

LeakyReLU

aT [θxi∥θxj∥θeEi,j]


k∈N(i)∪{i} exp (LeakyReLU (aT [θxi∥θxk∥θeEi,j]))
(2)
Importantly, the attention weights αi,j sum to 1 for source node i and are non-
negative so the embeddings x′
i are a weighted average of adjacent node embed-
dings. At the ﬁrst message passing iteration, the node features V, C are used.
After several iterations of message passing, we aggregate the node embeddings
into a global feature vector representing the MIP using global attention pool-
ing [32], which similarly computes a weighted average of node embeddings with
weights given by neural network layer. This ﬁxed-length graph representation
vector is then passed to a leaky-relu activated MLP to produce a single scalar
output representing the score for the scoring module or logit for the classiﬁcation
module. Obtaining node embeddings followed by aggregation across the entire
MIP enables us to use the same network architecture for MIPs of various sizes.

96
A. Ferber et al.
3.3
Learning the Scorer Model
We train the scorer to rank candidate backdoors by solver runtime when pri-
oritizing pseudo-backdoor variables, which we label by setting high branching
priority and solving to optimality. For a MIP P and a pair of candidate sets
B1, B2, the model estimates scores s1 = S(P, B1; θS), s2 = S(P, B2; θS) to match
ranking label y which is −1 if solving with B1 is faster than with B2, and 1 other-
wise. We train with the margin ranking loss on all pairs of pseudo-backdoors for a
given MIP, L(s1, s2, y) = max(0, −y(s1 −s2)+m) [37] for margin value m = 0.1.
Learning to rank has been pioneered in data-driven information retrieval systems
[6,33] and in our use case, it is suﬃcient that we rank pseudo-backdoors correctly
for each MIP rather than model the intricacies of runtime. At deployment time,
we sample several candidate backdoors and score them, taking the best-scoring
pseudo-backdoor for deployment. This best-scoring pseudo-backdoor can then
be deployed on its own by prioritizing the variables in the pseudo-backdoor, rep-
resenting our scorer model. We initially experimented with predicting normal-
ized runtime as well as the probability that the candidate backdoor outperforms
Gurobi, but found that these losses weren’t tuning the model toward isolating
high-quality pseudo-backdoors for a given MIP as top-scorers. Ultimately, the
approach of learning to rank closely aligned our model’s loss with the overall
deployment problem of identifying the fastest-solving pseudo-backdoor.
3.4
Learning the Classiﬁer Model
For a given MIP instance, it may be diﬃcult to sample high-quality pseudo-
backdoors. As a result, we learn a classiﬁer to determine whether to use the
best-scoring pseudo-backdoor or the default MIP solver. The classiﬁer has the
same architecture as the scoring model, taking in the MIP and candidate sub-
set encoding (P, B), and outputting an estimated probability that the pseudo-
backdoor outperforms the standard MIP solver. We train the model to minimize
a binary cross-entropy loss between the model outputs and labels indicating
whether the scorer’s best-scoring pseudo-backdoor beat the default solver. At
test time we use a threshold of 0.5 to determine whether to use the best-scoring
pseudo-backdoor or the default solver. scorer+cls denotes the combined scorer
and classiﬁer identifying the best pseudo-backdoor and whether it beats Gurobi.
4
Experiment Results
4.1
Problem Domains
Many real-world setting require solving a homogeneous family of problems,
where instances share similar structures, diﬀering slightly in the problem size
or numerical coeﬃcients. We evaluate the two components of our method on

Learning Pseudo-Backdoors for MIP
97
problem instances drawn from three domains1. We refrained from evaluating
our methodology on heterogeneous MIP datasets like MIPLIB [29] as we found
diﬃculty sampling fast-solving pseudo-backdoors to train with for a variety of
realistic MIP distributions, and we target homogeneous settings where latent
problem information that would normally require domain knowledge to extract
may help automatically identify high-quality pseudo-backdoors.
Neural Network Veriﬁcation:
Neural network veriﬁcation determines
a ﬁxed network’s robustness to input data perturbation. Previous work [17]
formulates a MIP that bounds the perturbation required to fool a neural network.
Our MIP instances are a random subset from [34] which considers veriﬁcation
of MNIST images against a small convolutional neural network.
Facility Location:
Capacitated Facility Location asks which facilities to
open and how to route limited facility supply to satisfy customer demand. The
goal is to minimize facility setup cost and per-unit cost transporting between
facilities and customers. As in [16], we generate MIPs according to [9] having
100 facilities supplying 200 (easy) and 400 (hard) customers.
Generalized Independent Set Problem: The Generalized Independent
Set Problem (GISP) is a graph optimization problem proposed for forestry man-
agement [20]. The input consists of a graph, a subset of removable edges with
deletion cost, and revenues for each vertex upon selection. The goal is to select a
set of vertices and removable edges that maximize the net proﬁt of total vertex
revenues minus total edge costs such that the selected vertices are independent
in the modiﬁed subgraph. We randomly generate GISP instances from two hard-
ness settings with nodes between 150 (easy) and 175 (hard), with node reward
r = 100 and edge removal cost c = 1. Erd˝os-R´enyi graphs [13] are generated with
edge probability p = 0.3, and are made removable with probability α = 0.25.
4.2
Data Generation and Model Evaluation
Each setting uses 300 MIPs: 100 Ds for training the scorer, 100 Dc for training
the classiﬁer, and 100 Dt for testing. To train our two models, we ﬁrst generate
candidate pseudo-backdoors for each instance by randomly sampling p% of inte-
ger variables proportional to their fractionality in the LP relaxation as in [10].
We weight variables by their absolute distance to the nearest integer, with more
fractional decision variables having higher probability. Note that this sampling
method is done only at the root node rather than fractionality branching during
branch-and-bound which is shown to perform poorly [1]. On the contrary, in [10]
the authors successfully found backdoors using LP fractionality sampling. From
initial experiments sampling variables of size 1%, 3%, 5% on NNVerify and GISP
easy, we found that sampling 1% of the decision variables yielded high-quality
pseudo-backdoors on training data. As a result, our models are trained using
1 Other domains: We initially collected data on two hardness settings of set cover
[3], combinatorial auctions [31], and maximum independent set [5] but found that
the best sampled backdoors underperformed Gurobi, meaning that no matter how
accurate our models, they could never outperform standard Gurobi.

98
A. Ferber et al.
pseudo-backdoors with p = 1% of the decision variables, presuming that smaller
pseudo-backdoors yield faster runtimes due to the more limited search trees. For
each MIP, we label performance on 50 random candidate backdoors, yielding a
dataset of 15,000 pseudo-backdoors. We ﬁnd that the best sampled backdoors
yield average runtime improvements of 44%, 30%, 16%, and 37% for NNVerify,
Facilities easy and hard, and GISP easy and hard respectively, meaning that cor-
rectly identifying pseudo-backdoors has the potential for large runtime improve-
ments. This improvement ﬁrstly indicates that high-quality pseudo-backdoors
exist in our datasets, and secondly that there is potential beneﬁt for an algo-
rithm that correctly identiﬁes these pseudo-backdoors.
We evaluate the pipeline in Fig. 1 on the test set Dt, by sampling subsets
using the LP relaxation, predicting the best pseudo-backdoor with the scorer,
and ﬁnally determining whether or not to use the selected pseudo-backdoor
with the classiﬁer. The backdoor set is deployed by setting Gurobi’s Branch-
Priority to be 2 for variables in the pseudo-backdoor and 1 for other variables.
As noted in Gurobi documentation [18] the BranchPriority is the primary cri-
terion for selecting fractional branching variables, with higher-priority variables
always taking precedence over lower-priority variables with ties being broken
using internal variable selection criteria. We consider the runtime of the full
pipeline including solving the LP relaxation, LP-based sampling, batched infer-
ence on sampled sets to obtain a pseudo-backdoor, classiﬁcation of the predicted
pseudo-backdoor, and solving the MIP. As Gurobi doesn’t allow access the ini-
tial LP relaxation, we need to re-solve the LP from scratch incurring additional
runtime which would not be present with deeper solver integration. We solve
MIPs with single-threaded Gurobi 9.1 [19] (avoiding conﬂicts between parallel
solves) on ﬁve 32-core machines with Intel 2.1 GHz cpus and 264 GB of memory.
Neural Networks are trained with Pytorch [35] on 4 GTX 1080 Ti GPUs.
4.3
Main Results
We present results on 100 test MIPs Dt in Table 2. We evaluate the standalone
score model (scorer), which uses the candidate backdoor with best predicted
score, and the full scorer and classiﬁcation pipeline (scorer+cls). The table
presents win/tie/loss over Gurobi and runtime in seconds comprised of solving
the root LP, sampling, and model inference. When scorer+cls suggests using
Gurobi we record a “tie” to give insight into model predictions even though it is a
slight loss in runtime. Overall, batched model inference takes 50ms on average to
compute scores for all 50 candidate backdoors and predict success probability on
the best-scoring pseudo-backdoor. The root LP solve times average 0.02, 0.08,
1.2, and 1.9 s for GISP, nnverify, facilities easy, and facilities hard, incurring
runtime which could be avoided with tighter solver integration.
As shown in Table 2, scorer quickly solves many MIPs, with lower average
runtime than Gurobi on facilities easy (6%) and GISP hard (9%). Additionally,
scorer outperforms Gurobi at diﬀerent percentiles for NNVerify while losing
on average. Importantly, the win/tie/loss demonstrates that scorer can often
identify quality pseudo-backdoors. In NNVerify, facilities hard, and GISP easy,

Learning Pseudo-Backdoors for MIP
99
Table 2. Runtime (secs) of standard Gurobi (grb), the score model (scorer), and the
joint score and classify model (scorer+cls). We report mean and standard deviation,
25th, 50th, and 75th percentiles. Finally, we report Win/Tie/Loss vs Gurobi.
dataset
solver mean stdev 25 pct median 75 pct W/T/L vs grb
nnverify
grb 6.5
7.9
2.9
4.3
6.1
0 / 100 / 0
nnverify
scorer 7.0
12.8
2.5
3.5
5.1
68 / 0 / 31
nnverify scorer+cls 5.6
7.4
2.6
3.3
5.0
62 / 18 / 20
facilities easy
grb 27.4
21.6
14.0
22.1
32.7
0 / 100 / 0
facilities easy
scorer 24.9
18.2
12.9
19.7
32.1
65 / 0 / 35
facilities easy scorer+cls 22.8
18.8
11.7
22.7
29.3
55 / 33 / 12
facilities hard
grb 46.9
31.6
26.2
37.1
55.2
0 / 100 / 0
facilities hard
scorer 56.0
42.5
29.3
42.5
69.1
28 / 0 / 72
facilities hard scorer+cls 44.5
30.9
25.2
35.5
52.7
25 / 74 / 1
gisp easy
grb 611
182
488
580
681
0 / 100 / 0
gisp easy
scorer 960
755
515
649
915
41 / 0 / 59
gisp easy scorer+cls 601
247
481
568
663
24 / 70 / 6
gisp hard
grb 2533
939
1840
2521
2976
0 / 100 / 0
gisp hard
scorer 2373
855
1721
2262
2926
47 / 0 / 53
gisp hard scorer+cls 2326 855
1654
2215
2866
41 / 39 / 20
the increased average runtime is partially explained by the higher standard devi-
ation. Additionally, in facilities hard, scorer suﬀers 72 losses to Gurobi.
scorer+cls is faster than Gurobi across all distributions on average and at
most quantiles. The scorer+cls pipeline outperforms Gurobi on mean solve
time by 14%, 17%, 5%, 2% and 8% on NNVerify, facilities easy, facilities hard,
GISP easy and GISP hard respectively. In terms of win/tie/loss, scorer+cls
retains most of scorer’s wins and only incorrectly selects the pseudo-backdoor
in 20 of 100 instances. Furthermore, scorer+cls’s variability is reduced in
NNVerify, Facilities hard, and GISP easy to be comparable with Gurobi. Overall,
scorer identiﬁes performant pseudo-backdoors, and scorer+cls leverages the
pseudo-backdoors for consistently faster solving by deciding when to run Gurobi.
5
Conclusion
We present a method for learning pseudo-backdoors for faster MIP solving.
Inspired by previous work showing that small sets of variables can sometimes
improve MIP solving, our method is comprised of two parts: an initial scorer
which ranks candidate pseudo-backdoors according to how fast they solve a
given MIP, and a classiﬁer to predict whether the selected pseudo-backdoor will
improve over a standard solver. We ablate these models on several realistic MIP
distributions, demonstrating that fast-solving pseudo-backdoors sometimes exist

100
A. Ferber et al.
for the examined MIP distributions, the scorer can identify pseudo-backdoors,
and the classiﬁer can determine when these pseudo-backdoors speed up MIP
solving.
Acknowledgments. AF and BD were partially supported by NSF AI Institute for
Advances in Optimization Award #2112533 and Qualcomm. JS and YY were partially
supported by NSF #1763108, Raytheon, Beyond Limits, and JPL.
References
1. Achterberg, T., Wunderling, R.: Mixed integer programming: analyzing 12 years of
progress. In: J¨unger, M., Reinelt, G. (eds) Facets of Combinatorial Optimization,
pp. 449–481. Springer, Berlin (2013). https://doi.org/10.1007/978-3-642-38189-
8 18
2. Ans´otegui, C., Malitsky, Y., Samulowitz, H., Sellmann, M., Tierney, K.: Model-
based genetic algorithms for algorithm conﬁguration. In: International Conference
on Artiﬁcial Intelligence, pp. 733–739 (2015)
3. Balas, E., Ho, A.: Set covering algorithms using cutting planes, heuristics, and
subgradient optimization: a computational study. In: Padberg, M.W. (eds) Com-
binatorial Optimization, pp. 37–60. Springer, Berlin (1980). https://doi.org/10.
1007/BFb0120886
4. Balcan, M.F., Dick, T., Sandholm, T., Vitercik, E.: Learning to branch. In: Inter-
national Conference on Machine Learning (ICML) (2018)
5. Bergman, D., Cire, A.A., Hoeve, W.J., Hooker, J.: Decision Diagrams for Opti-
mization, 1st edn. Springer Publishing Company Inc., Cham (2016). https://doi.
org/10.1007/978-3-319-42849-9
6. Burges, C., et al.: Learning to rank using gradient descent. In: Proceedings of the
22nd International Conference on Machine learning, pp. 89–96 (2005)
7. Colombi, M., Mansini, R., Savelsbergh, M.: The generalized independent set prob-
lem: polyhedral analysis and solution approaches. Eur. J. Oper. Res. 260(1), 41–55
(2017)
8. Conforti, M., Cornu´ejols, G., Zambelli, G., et al.: Integer Programming. Springer,
Cham (2014). https://doi.org/10.1007/978-3-319-11008-0
9. Cornu´ejols, G., Sridharan, R., Thizy, J.M.: A comparison of heuristics and relax-
ations for the capacitated plant location problem. Eur. J. Oper. Res. 50(3), 280–297
(1991)
10. Dilkina, B., Gomes, C.P., Malitsky, Y., Sabharwal, A., Sellmann, M.: Backdoors
to combinatorial optimization: feasibility and optimality. In: van Hoeve, W.-J.,
Hooker, J.N. (eds.) CPAIOR 2009. LNCS, vol. 5547, pp. 56–70. Springer, Heidel-
berg (2009). https://doi.org/10.1007/978-3-642-01929-6 6
11. Dilkina, B., Gomes, C.P., Sabharwal, A.: Backdoors in the context of learning. In:
Kullmann, O. (ed.) SAT 2009. LNCS, vol. 5584, pp. 73–79. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-3-642-02777-2 9
12. Dvoˇr´ak, P., Eiben, E., Ganian, R., Knop, D., Ordyniak, S.: Solving integer linear
programs with a small number of global variables and constraints. In: International
Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 607–613 (2017)
13. Erd˝os, P., R´enyi, A.: On the evolution of random graphs. Publ. Math. Inst. Hung.
Acad. Sci 5(1), 17–60 (1960)

Learning Pseudo-Backdoors for MIP
101
14. Fey, M., Lenssen, J.E.: Fast graph representation learning with PyTorch geometric.
In: ICLR Workshop on Representation Learning on Graphs and Manifolds (2019)
15. Fischetti, M., Monaci, M.: Backdoor branching. In: G¨unl¨uk, O., Woeginger, G.J.
(eds.) IPCO 2011. LNCS, vol. 6655, pp. 183–191. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-20807-2 15
16. Gasse, M., Ch´etelat, D., Ferroni, N., Charlin, L., Lodi, A.: Exact combinatorial
optimization with graph convolutional neural networks. In: Advances in Neural
Information Processing Systems (NeurIPS) (2019)
17. Gowal, S., et al.: On the eﬀectiveness of interval bound propagation for training
veriﬁably robust models (2018). arXiv preprint http://arxiv.org/abs/1810.12715
18. Gurobi Optimization, L.: Gurobi optimizer reference manual (2021). www.gurobi.
com/documentation/9.1/refman/branchpriority.html
19. Gurobi Optimization, L.: Gurobi optimizer reference manual (2021). http://www.
gurobi.com
20. Hochbaum, D.S., Pathria, A.: Forest harvesting and minimum cuts: a new approach
to handling spatial constraints. For. Sci. 43(4), 544–554 (1997)
21. Hoos, H.H.: Automated algorithm conﬁguration and parameter tuning. In:
Hamadi, Y., Monfroy, E., Saubion, F. (eds.) Auton. Search, pp. 37–71. Springer,
Heidelberg (2011). https://doi.org/10.1007/978-3-642-21434-9 3
22. Hutter, F., Hoos, H.H., Leyton-Brown, K., St¨utzle, T.: Paramils: an automatic
algorithm conﬁguration framework. J. Artif. Intell. Res. 36, 267–306 (2009)
23. J¨arvisalo, M., Junttila, T.: Limitations of restricted branching in clause learning.
In: Bessi`ere, C. (ed.) CP 2007. LNCS, vol. 4741, pp. 348–363. Springer, Heidelberg
(2007). https://doi.org/10.1007/978-3-540-74970-7 26
24. J¨arvisalo, M., Niemel¨a, I.: The eﬀect of structural branching on the eﬃciency of
clause learning sat solving: an experimental study. J. Algorithms 63(1–3), 90–113
(2008)
25. Khalil, E., Le Bodic, P., Song, L., Nemhauser, G., Dilkina, B.: Learning to branch in
mixed integer programming. In: AAAI Conference on Artiﬁcial Intelligence (2016)
26. Khalil, E.B., Dilkina, B., Nemhauser, G., Ahmed, S., Shao, Y.: Learning to run
heuristics in tree search. In: International Joint Conference on Artiﬁcial Intelligence
(IJCAI) (2017)
27. Khalil, E.B., Vaezipoor, P., Dilkina, B.: Finding backdoors to integer programs: a
monte carlo tree search framework (2022)
28. Kilby, P., Slaney, J., Thi´ebaux, S., Walsh, T.: Backbones and backdoors in satisﬁ-
ability. In: AAAI, pp. 1368–1373 (2005)
29. Koch, T., et al.: Miplib 2010. Math. Program. Comput. 3(2), 103–163 (2011).
https://doi.org/10.1007/s12532-011-0025-9
30. Land, A.H., Doig, A.G.: An automatic method for solving discrete programming
problems. In: J¨unger, M. (ed.) 50 Years of Integer Programming 1958-2008, pp.
105–132. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-540-68279-
0 5
31. Leyton-Brown, K., Pearson, M., Shoham, Y.: Towards a universal test suite for
combinatorial auction algorithms. In: ACM Conference on Electronic Commerce,
pp. 66–76 (2000)
32. Li, Y., Zemel, R., Brockschmidt, M., Tarlow, D.: Gated graph sequence neural
networks. In: ICLR (2016)
33. Liu, T.Y., et al.: Learning to rank for information retrieval. Found. Trends R
⃝Inf.
Retrieval 3(3), 225–331 (2009)
34. Nair, V. et al.: Solving mixed integer programs using neural networks (2020)

102
A. Ferber et al.
35. Paszke, A., et al.: An imperative style, high-performance deep learning library. In:
Wallach, H., Larochelle, H., Beygelzimer, A., d’ Alch´e-Buc, F., Fox, E., Garnett,
R. (eds.) Advances in Neural Information Processing Systems 32, pp. 8024–8035.
Curran Associates, Inc. (2019). http://papers.neurips.cc/paper/9015-pytorch-an-
imperative-style-high-performance-deep-learning-library.pdf
36. Semenov, A., Zaikin, O., Otpuschennikov, I., Kochemazov, S., Ignatiev, A.: On
cryptographic attacks using backdoors for SAT. In: AAAI Conference on Artiﬁcial
Intelligence (2018)
37. Tsochantaridis, I., Joachims, T., Hofmann, T., Altun, Y., Singer, Y.: Large margin
methods for structured and interdependent output variables. J. Mach. Learn. Res.
6(9) (2005)
38. Vaswani, A., et al.: Attention is all you need. Advances in neural information
processing systems, vol. 30 (2017)
39. Veliˇckovi´c, P., Cucurull, G., Casanova, A., Romero, A., Li`o, P., Bengio, Y.: Graph
attention networks. In: International Conference on Learning Representations
(ICLR) (2018). https://openreview.net/forum?id=rJXMpikCZ, accepted as poster
40. Williams, R., Gomes, C.P., Selman, B.: Backdoors to typical case complexity. In:
International Joint Conference on Artiﬁcial Intelligence (IJCAI), vol. 3, pp. 1173–
1178 (2003)

Leveraging Integer Linear Programming
to Learn Optimal Fair Rule Lists
Ulrich A¨ıvodji1, Julien Ferry2(B), S´ebastien Gambs3, Marie-Jos´e Huguet2,
and Mohamed Siala2
1 ´Ecole de Technologie Sup´erieure, Montr´eal, Canada
2 LAAS-CNRS, Universit´e de Toulouse, CNRS, INSA, Toulouse, France
jferry@laas.fr
3 Universit´e du Qu´ebec `a Montr´eal, Montr´eal, Canada
Abstract. Fairness and interpretability are fundamental requirements
for the development of responsible machine learning. However, learning
optimal interpretable models under fairness constraints has been identi-
ﬁed as a major challenge. In this paper, we investigate and improve on a
state-of-the-art exact learning algorithm, called CORELS, which learns rule
lists that are certiﬁably optimal in terms of accuracy and sparsity. Sta-
tistical fairness metrics have been integrated incrementally into CORELS
in the literature. This paper demonstrates the limitations of such an
approach for exploring the search space eﬃciently before proposing an
Integer Linear Programming method, leveraging accuracy, sparsity and
fairness jointly for better pruning. Our thorough experiments show clear
beneﬁts of our approach regarding the exploration of the search space.
Keywords: Fairness · Interpretability · Rule lists · Machine learning
1
Introduction
The combination of the availability of large datasets as well as algorithmic and
computational progress has led to a signiﬁcant increase in the performance of
machine learning models. Despite their usefulness for numerous applications,
the use of such models also raises several issues when their outcome impacts
individuals’ lives (e.g., credit scoring or scholarships granting). Fairness and
interpretability are key properties for the development of trustworthy machine
learning and have become legal requirements deﬁned in legislative texts [14].
The interpretability of a machine learning model is deﬁned in [10] as “the
ability to explain or to present in understandable terms to a human”. This
deﬁnition is quite general, and its precise instantiation depends on the task at
hand, the context considered and the target of the explanation. Several methods
have been proposed to explain machine learning models’ predictions, which can
be categorized into two main families. On one side, black-box explanations [15]
Julien Ferry—First author.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 103–119, 2022.
https://doi.org/10.1007/978-3-031-08011-1_9

104
U. A¨ıvodji et al.
can be useful in non-sensitive contexts to provide a posteriori explanations of
a black-box, but can be manipulated [24]. On the other side, transparent-box
design [21] aims at building inherently interpretable models (e.g., rule-based or
tree-based models of reasonable size) [13,21].
Fairness is a central requirement for high-stake decision systems. Indeed,
learning algorithms try to extract useful correlations from the training data but
real-world datasets may include negative biases that should not be captured
(e.g., historical discrimination). Several fairness notions have been proposed to
address this issue [6,7,26]. Among them, statistical fairness metrics ensure that
a given statistical measure has similar values between groups as determined by
the value of a sensitive feature. They are widely used as they can implement
legal requirements and are easily quantiﬁable. Several approaches to fair learn-
ing have emerged in the literature, categorized into three main families. Prepro-
cessing techniques [20] directly modify the training data to remove undesirable
correlations so that any classiﬁer trained on this data does not learn such correla-
tions. Postprocessing approaches [16] modify the outputs of a previously trained
classiﬁer to meet some fairness criteria. Finally, algorithmic modiﬁcation tech-
niques [27] directly incorporate the fairness requirements into the learning algo-
rithm and output a model satisfying a given fairness deﬁnition. In this paper, we
focus on statistical fairness metrics using algorithmic modiﬁcation approaches,
which usually oﬀer the best trade-oﬀs between accuracy and fairness [6].
While many heuristic approaches for learning have been proposed, exact
approaches oﬀer a considerable advantage as a lack of optimality can have soci-
etal implications [4]. For instance, CORELS [3,4] produces rule lists that are certiﬁ-
ably optimal in terms of accuracy and sparsity. It relies on a branch-and-bound
algorithm leveraging several dedicated bounds to prune the search space eﬃ-
ciently. FairCORELS [1,2] is a bi-objective extension of CORELS handling both
statistical fairness and accuracy. FairCORELS consists in an ϵ-constraint method
that leverages CORELS’ original search tree and bounds for the accuracy objec-
tive and considers the fairness objective as a constraint. However, handling such
constraints modiﬁes the set of acceptable solutions, which makes the exploration
considerably harder. Indeed, learning optimal interpretable machine learning
models under constraints (e.g., fairness constraints) has been identiﬁed as one
of the main technical challenges towards interpretable machine learning [25].
In this paper, we address this issue and propose a method that harnesses the
fairness constraints to eﬃciently prune the search space and optionally guide
exploration. More precisely, we argue that CORELS’ original bounds are not suﬃ-
cient to eﬃciently explore the search space in this bi-objective setup. To address
this, we design Integer Linear Programming (ILP) models combining both accu-
racy and fairness requirements for well-known statistical fairness metrics. These
models are incorporated into FairCORELS through eﬀective pruning mechanisms
and can also be used to guide the exploration towards fair and accurate rule lists.
Our large experimental study using three datasets with various fairness mea-
sures and requirements demonstrates clear beneﬁts of the proposed approaches
in terms of search exploration, memory consumption and learning quality.

Leveraging ILP to Learn Optimal Fair Rule Lists
105
The outline of the paper is as follows. First, we provide the relevant back-
ground and notations in Sect. 2. Then in Sect. 3, after describing the fair learning
algorithm used, we discuss the theoretical claims motivating the necessity of eﬃ-
cient pruning. Afterwards, in Sect. 4, we propose pruning approaches based on
ILP models, before evaluating empirically their eﬃciency and quality in Sect. 5
through a large experimental study. Finally, we conclude in Sect. 6.
2
Technical Background and Notations
In this section, we introduce the necessary background as well as the diﬀerent
notations used throughout the paper.
2.1
Rule Lists and Associated Notations
In supervised machine learning, the purpose of a classiﬁcation problem is to
learn a classiﬁer function that maps as accurately as possible an input space to an
output space. We use F = {f1, . . . , fG} to denote a set of G binary features, all of
them take their value in {0, 1}. The training data, denoted by E = {e1, . . . , eM},
is a set of M examples. The examples in E are partitioned into E+ and E−,
which correspond respectively to positive examples and negative ones. Precisely,
an example ej ∈E is represented as a 2-tuple (xj, yj), in which xj ∈{0, 1}G
denotes the value vector for all binary features associated with the example and
yj ∈{0, 1} is the label indicating its class. We have ej ∈E+ if yj = 1 and
ej ∈E−if yj = 0.
We consider classiﬁers that are expressed as rule lists [23], which are formed
by an ordered list of if-then rules, followed by a default prediction. More precisely,
a rule list is a tuple d = (δd, q0) in which δd = (r1, r2, . . . , rk) is d’s preﬁx,
and q0 ∈{0, 1} is a default prediction. A preﬁx is an ordered list of k distinct
association rules ri = ai →qi. Each rule ri is composed of an antecedent ai
and a consequent qi ∈{0, 1}. Each antecedent ai is a Boolean assertion over
F evaluating either to true or false for each possible input x ∈{0, 1}G. If ai
evaluates to true for example ej, we say that rule ri captures ej. Similarly, if at
least one of the rules in δd captures ej, we say that preﬁx δd captures example
ej. Rule list 1.1 predicts whether a given individual has a [low] or [high] salary.
Its preﬁx is composed of ﬁve rules, and its default decision is [low].
Rule list 1.1. found by FairCORELS on the Adult Income dataset.
i f
[ occupation : Blue−Collar ]
then
[ low ]
else
i f
[ occupation : S e r v i c e ]
then
[ low ]
else
i f
[ c a p i t a l
gain : > 0 ]
then
[ high ]
else
i f
[ not ( workclass : Government ) ]
then
[ low ]
else
i f
[ education : Masters / Doctorate ]
then
[ high ]
else
[ low ]
Using a rule list d = (δd, q0) to classify an example e is straightforward
as rules in δd are applied sequentially. If e is not captured by preﬁx δd, then
the default prediction q0 is returned. Finally, remark that rule list ((), q0) is
well deﬁned, and simply consists of a default prediction (hence representing a
constant classiﬁer).

106
U. A¨ıvodji et al.
Table 1. Summary of four statistical fairness metrics widely used in the literature.
Metric
Statistical Measure
Mathematical Formulation
Statistical Parity
(SP)
Probability of Positive
Prediction

TP c
E,p + FP c
E,p
|Ep|
−
TP c
E,u + FP c
E,u
|Eu|
 ≤ϵ
Predictive Equality
(PE)
False Positive Rate

FP c
E,p
|Ep ∩E−| −
FP c
E,u
|Eu ∩E−|
 ≤ϵ
Equal Opportunity
(EOpp)
False Negative Rate

FNc
E,p
|Ep ∩E+| −
FNc
E,u
|Eu ∩E+|
 ≤ϵ
Equalized Odds (EO)
PE and EOpp
Conjunction of PE and EOpp
2.2
Statistical Fairness
The rationale of statistical fairness notions is to ensure that a given statisti-
cal measure has similar values between several protected groups, deﬁned by the
value(s) of some sensitive feature(s) of F. The underlying principle is that such
sensitive features (e.g., race, gender, . . . ) should not inﬂuence predictions. While
the exact formulation of such metrics would enforce equality for the given mea-
sure over the protected groups, a common relaxation consists of bounding the
diﬀerence. Depending on the particular value being equalized across groups, sev-
eral metrics have been proposed in the literature. In this paper, we consider the
four most commonly used metrics: Statistical Parity [12] (SP), Predictive Equal-
ity [9] (PE), Equal Opportunity [16] (EOpp) and Equalized Odds [16] (EO).
Let E denote a training set and c a classiﬁer. Throughout the paper, we
assume that E is partitioned into two groups: a protected group Ep and an
unprotected group Eu (this partition depends on the value of the sensitive fea-
ture(s)). Let also ϵ ∈[0, 1] denote the unfairness tolerance (i.e., the maximum
acceptable value for the unfairness measure). Thus, the fairness requirement gets
harder as ϵ gets smaller. For a classiﬁer c, among a group Eh, with h ∈{p, u},
we denote by TP c
E,h the number of true positives, TN c
E,h the number of true
negatives, FP c
E,h the number of false positives and FN c
E,h the number of false
negatives. Table 1 gives the deﬁnition of the four metrics considered.
3
CORELS and FairCORELS
CORELS [4] is a state-of-the-art supervised learning algorithm that outputs a
certiﬁably optimal rule list minimizing the following objective function on a
given training dataset E:
obj(d, E) = misc(d, E) + λ · Kd,
(1)
in which misc(d, E) ∈[0, 1] denotes the training classiﬁcation error of the rule
list d, Kd is the length of d (i.e., number of association rules in d) and λ is a
regularization hyper-parameter for sparsity. CORELS is a branch-and-bound algo-
rithm, representing the search space of rule lists R as a preﬁx tree. Each node is

Leveraging ILP to Learn Optimal Fair Rule Lists
107
a preﬁx in this tree, and each child node is an extension of its parent, obtained
by adding exactly one rule at the end of the parent’s preﬁx. Finally, the root
node corresponds to the empty preﬁx. Each node is a possible solution (i.e.,
rule list), obtained by adding a default decision (based on majority prediction)
to the preﬁx associated with this node. While this search space corresponds
to an exhaustive enumeration of the candidate solutions, CORELS leverages sev-
eral bounds to prune it eﬃciently. Thanks to these bounds, along with several
smart data structures, CORELS is able to ﬁnd optimal solutions with a reasonable
amount of time and memory. The set of antecedents A is pre-mined and given as
input to the algorithm. While CORELS is agnostic to the rule mining procedure
used as preprocessing, an overview of existing techniques can be found in [8].
FairCORELS [1,2] is a bi-objective extension of CORELS jointly addressing
accuracy and statistical fairness, integrating several metrics from the literature.
Formally, given a statistical fairness notion, whose violation by a rule list d
on dataset E is quantiﬁed by an unfairness function unf(d, E) and a maximum
acceptable violation ϵ, FairCORELS solves the following optimization problem:
arg min
d∈R
obj(d, E)
(2)
such that unf(d, E) ≤ϵ
FairCORELS is presented in Algorithm 1. In this algorithm, dc denotes the
current best solution and zc is its objective value. Moreover, a priority queue Q
of preﬁxes is used to store its exploration frontier. The priority queue ordering
deﬁnes the exploration heuristic. The function b(δ, E) (coming from the CORELS
algorithm) gives an objective lower bound for any rule list built upon preﬁx
δ on the dataset E. At each iteration of the main loop, a preﬁx δ is removed
from the priority queue (Line 4). When the lower bound of δ is less than the
current best objective value (Line 5), two operations are considered. First, the
rule list d formed by preﬁx δ along with a default prediction is accepted as a
new best solution if it improves the current best objective value while respecting
the unfairness tolerance (Line 9). Second, extensions of δ using the antecedents
not involved in δ’s rules are added to the queue (Line 12).
The constrained optimization formulation of the fair learning problem used
in FairCORELS allows for the construction of diﬀerent trade-oﬀs between accu-
racy and fairness using a simple ϵ-constraint method [22]. However, the fairness
constraints modify the set of acceptable solutions and the resulting search space
is considerably harder to work with. Indeed, CORELS’ original bounds are less eﬃ-
cient as the fairness constraint gets stronger. In addition, some data structures
used by CORELS to speed up the exploration are no longer usable. For instance,
a preﬁx permutation map that reduces considerably the running time and the
memory consumption [3,4] does not apply anymore. This symmetry-aware map
ensures that only the best permutation of each set of rules containing the same
antecedents is kept. However, it cannot be used within FairCORELS without sac-
riﬁcing optimality. Indeed, a given permutation may allow for better objective
function values than others but may not lead to solutions meeting the fairness

108
U. A¨ıvodji et al.
Algorithm 1. FairCORELS
Input: Training data E with set of pre-mined antecedents A; unfairness tolerance ϵ;
initial best known rule list d0 such that unf(d0, E) ≤ϵ
Output: (d∗, z∗) in which d∗is a rule list with the minimum objective function value
z∗such that unf(d∗, E) ≤ϵ
1: (dc, zc) ←(d0, obj(d0, E))
2: Q ←queue(())
▷Initially the queue contains the empty preﬁx ()
3: while Q not empty do
▷Stop when the queue is empty
4:
δ ←Q.pop()
5:
if b(δ, E) < zc then
6:
d ←(δ, q0)
▷Set default prediction q0 to minimize training error
7:
z ←obj(d, E)
8:
if z < zc and unf(d, E) ≤ϵ then
9:
(dc, zc) ←(d, z)
▷Update best rule list and objective
10:
for a in A\{ai | ∃ri ∈δ, ri = ai →qi} do ▷Antecedent a not involved in δ
11:
r ←(a →q)
▷Set a’s consequent q to minimize training error
12:
Q.push(δ ∪r)
▷Enqueue extension of δ with r
13: (d∗, z∗) ←(dc, zc)
requirement. In this situation, one could miss solutions that exhibit lower objec-
tive function values and meet the fairness requirement. Since we are interested
in preserving the guarantee of optimality, we cannot use such a data structure.
However, we note that a weaker permutation map can be designed and used with-
out losing the guarantee of optimality (we precisely do that later in Sect. 5.3).
Overall, both observations motivate the need for a new pruning approach, lever-
aging both the objective function value and the fairness constraint to eﬃciently
explore FairCORELS’ search space.
4
The Proposed Pruning Approach
This section presents our proposition to prune the search space by reasoning
about the number of well-classiﬁed examples and fairness. The main idea is to
discard preﬁxes that cannot improve the current objective while satisfying the
fairness requirement before being treated. To realize this, one has to guarantee
that for any preﬁx discarded, none of its extensions can satisfy both require-
ments, which is the purpose of Sect. 4.1. Afterwards, Sect. 4.2 exploits this prop-
erty in the presentation of our proposition.
4.1
A Suﬃcient Condition to Reject Preﬁxes
Let E be a training set and d be a rule list. We use W d
E to denote the number of
examples of dataset E well classiﬁed by d:
W d
E = TP d
E,p + TP d
E,u + TN d
E,p + TN d
E,u
(3)
= TP d
E,p + TP d
E,u + |Ep ∩E−| −FP d
E,p + |Eu ∩E−| −FP d
E,u
(4)

Leveraging ILP to Learn Optimal Fair Rule Lists
109
We slightly extend the notation introduced in Sect. 2. For a preﬁx δ, among a
group Eh with h ∈{p, u}, we denote by TP δ
E,h (respectively TN δ
E,h, FP δ
E,h and
FN δ
E,h) the number of true positives (respectively true negatives, false positives
and false negatives) among the examples of E captured by δ. Similarly, we deﬁne
W δ
E as the number of examples well classiﬁed by δ, among the examples of E
that δ captures. Clearly, W δ
E = TP δ
E,p + TP δ
E,u + TN δ
E,p + TN δ
E,u.
We deﬁne σ(δ) to be the set of all rule lists whose preﬁxes start with δ:
σ(δ) = {(δd, q0) | δd starts with δ}. Formally, we say that δd starts with δ (a
preﬁx of length K) if and only if the K ﬁrst rules of δd are precisely those of δ,
appearing in the same order.
Consider d = (δd, q0) such that d ∈σ(δ). On the one hand, some examples
of E cannot be captured by δ. On the other hand, all examples of E captured by
δ are captured by δd and have the same prediction as with δ.
Proposition 1. Given a preﬁx δ, a rule list d ∈σ(δ) and h ∈{p, u}, we have:
TP δ
E,h ≤TP d
E,h ≤|Eh ∩E+| −FN δ
E,h
FP δ
E,h ≤FP d
E,h ≤|Eh ∩E−| −TN δ
E,h
Proof. The lower bounds are an immediate consequence of the fact that all exam-
ples captured by δ are captured by d’s preﬁx and have the same predictions that
in δ. Concerning the upper bounds, we show the proof for the ﬁrst inequality
as the second can be proven using a similar argument. Deﬁne T as the set of
examples in Eh ∩E+ that are not determined by δ. When constructing d from δ,
the maximum possible augmentation of true positives within protected group h
is to predict all the examples correctly in T. The size of the set containing true
positives of δ and T is equal to |Eh ∩E+| −FN δ
E,h. Hence the upper bound.
⊓⊔
As a consequence of Proposition 1, W d
E ≥W δ
E . We now deﬁne four integer
decision variables that are used in our Integer Linear Programming (ILP) models.
These variables are used to model the confusion matrix of any rule list whose
preﬁx starts with δ as well as to deﬁne constraints modelling accuracy and
fairness requirements over such matrix.
xT PE,p ∈[TP δ
E,p, |Ep ∩E+| −FN δ
E,p], xT PE,u ∈[TP δ
E,u, |Eu ∩E+| −FN δ
E,u],
xF PE,p ∈[FP δ
E,p, |Ep ∩E−| −TN δ
E,p], xF PE,u ∈[FP δ
E,u, |Eu ∩E−| −TN δ
E,u].
Consider the following constraint in which L and U are two integers such
that 0 ≤L ≤U ≤|E|:
L ≤xT PE,p + xT PE,u + |Ep ∩E−| −xF PE,p + |Eu ∩E−| −xF PE,u ≤U.
(5)
We deﬁne ILP(δ, E, L, U) to be the ILP model deﬁned by the four variables
xT PE,p, xF PE,p, xT PE,u, xF PE,u and Constraint (5).
Proposition 2. Given a preﬁx δ and 0 ≤L ≤U ≤|E|, if ILP(δ, E, L, U) is
unsatisﬁable then we have:
∄d ∈σ(δ) | L ≤W d
E ≤U

110
U. A¨ıvodji et al.
Proof. Assume that there exists some d ∈σ(δ) such that L ≤W d
E ≤U. Then,
xT PE,p = TP d
E,p, xT PE,u = TP d
E,u, xF PE,p = FP d
E,p and xF PE,u = FP d
E,u is
a solution to ILP(δ, E, L, U). Indeed, Constraint (5) is satisﬁed by hypothesis,
and the bounds of the four variables are respected due to Proposition 1 and the
fact that d is an extension of δ. Finally, if ∃d ∈σ(δ) | L ≤W d
E ≤U, then
ILP(δ, E, L, U) is satisﬁable, which completes the proof by contrapositive.
⊓⊔
In the following paragraph, we show how the ILP(δ, E, L, U) model can be
extended to include the diﬀerent considered statistical fairness metrics (deﬁned
in Table 1). For the sake of conciseness, we detail the procedure for the Statistical
Parity metric and provide the key elements for the three other metrics. Note that
propositions similar to Proposition 3 can be adapted and proved for the three
other metrics, following the same reasoning.
Integrating Statistical Parity. We introduce a constant C1 = ϵ × |Ep| × |Eu|
and the following constraint:
−C1 ≤|Eu| × (xT PE,p + xF PE,p) −|Ep| × (xT PE,u + xF PE,u) ≤C1.
(6)
Let ILPSP (δ, E, L, U, ϵ) be the Integer Linear Programming model deﬁned
by the four variables xT PE,p, xF PE,p, xT PE,u, xF PE,u and Constraints (5) and (6).
Proposition 3. Given a preﬁx δ, an unfairness tolerance ϵ ∈[0, 1], and 0 ≤
L ≤U ≤|E|, if ILPSP (δ, E, L, U, ϵ) is unsatisﬁable then we have:
∄d ∈σ(δ) | L ≤W d
E ≤U and unfSP (d, E) ≤ϵ
Proof. Assume that there exists some d ∈σ(δ) such that L ≤W d
E
≤U
and unfSP (d, E) ≤ϵ. First, observe that Constraint (6) is equivalent to the
mathematical formulation of the Statistical Parity condition deﬁned in Table 1.
Indeed, unfSP (d, E) ≤ϵ if and only if −C1 ≤|Eu| × (TP d
E,p + FP d
E,p) −|Ep| ×
(TP d
E,u + FP d
E,u) ≤C1. Then, xT PE,p = TP d
E,p, xT PE,u = TP d
E,u, xF PE,p = FP d
E,p
and xF PE,u = FP d
E,u is a solution to ILPSP (δ, E, L, U, ϵ). Finally, if ∃d ∈σ(δ) |
L ≤W d
E ≤U and unfSP (d, E) ≤ϵ, then ILPSP (δ, E, L, U, ϵ) is satisﬁable, which
completes the proof by contrapositive.
⊓⊔
Integrating Other Statistical Fairness Metrics. Consider a preﬁx δ, an
unfairness tolerance ϵ ∈[0, 1] and 0 ≤L ≤U ≤|E|. We deﬁne the following
useful constants C2 = ϵ×|Eu∩E−|×|Ep∩E−|, and C3 = ϵ×|Ep∩E+|×|Eu∩E+|.
Predictive Equality. Consider the following constraint:
−C2 ≤|Eu ∩E−| × xF PE,p −|Ep ∩E−| × xF PE,u ≤C2.
(7)
Let ILPP E(δ, E, L, U, ϵ) be the ILP model deﬁned by the four variables
xT PE,p, xF PE,p, xT PE,u, xF PE,u and Constraints (5) and (7). If ILPP E(δ, E, L, U, ϵ)
is unsatisﬁable, then: ∄d ∈σ(δ) | L ≤W d
E ≤U and unfP E(d, E) ≤ϵ.

Leveraging ILP to Learn Optimal Fair Rule Lists
111
Equal Opportunity. Consider the following constraint:
−C3 ≤|Ep ∩E+| × xT PE,u −|Eu ∩E+| × xT PE,p ≤C3.
(8)
Let ILPEOpp(δ, E, L, U, ϵ) be the ILP model deﬁned by the four variables
xT PE,p, xF PE,p, xT PE,u, xF PE,u and Constraints (5) and (8). If ILPEOpp(δ, E,
L, U, ϵ) is unsatisﬁable, then: ∄d ∈σ(δ) | L ≤W d
E ≤U and unfEOpp(d, E) ≤ϵ.
Equalized Odds. Since the Equalized Odds metric is the conjunction of Equal
Opportunity and Predictive Equality, we simply use the conjunction of Con-
straints (7) and (8) to integrate it.
Let ILPEO(δ, E, L, U, ϵ) be the ILP model deﬁned by the four variables
xT PE,p, xF PE,p, xT PE,u, xF PE,u and Constraints (5), (7) and (8). If ILPEO(δ, E, L,
U, ϵ) is unsatisﬁable then: ∄d ∈σ(δ) | L ≤W d
E ≤U and unfEO(d, E) ≤ϵ.
4.2
Integration Within FairCORELS
We have proposed a suﬃcient condition to reject preﬁxes that do not respect a
given fairness metric within a requirement of well-classiﬁed examples. One can
use this property to reject preﬁxes before being they are treated in the main
loop of FairCORELS. This pruning idea can be integrated using two approaches.
The ﬁrst one called the eager approach, checks the suﬃcient condition before
adding an extension of a preﬁx to the priority queue (before Line 12 with δ ∪r
being the preﬁx given in the ILP). The second approach called the lazy approach,
checks the suﬃcient condition when a preﬁx is removed from the priority queue
and passed the branch and bound lower bound test at Line 5 with δ being the
preﬁx tested. If the corresponding ILP (called with valid bounds) is unsatisﬁable,
then the preﬁx δ being tested can safely be discarded since no rule list whose
preﬁx starts with δ can satisfy the conjunction of fairness and well-classiﬁed
examples requirements. The diﬀerence between the two approaches can be seen
as the trade-oﬀbetween memory consumption and computational time. Indeed,
given the same inputs and exploration strategies, the eager approach consumes
less memory than the lazy approach as it prunes preﬁxes before adding them to
the queue. However, it requires more calls to the ILP solver.
Finally, we also consider using the ILP models to guide exploration. To realize
this, we add an objective to the previously deﬁned ILP, maximizing xT PE,p −
xF PE,p + xT PE,u −xF PE,u. The ILP is then called as in the eager approach, just
before adding an extension of a preﬁx to the priority queue (before Line 12).
Whenever it is unsatisﬁable, the corresponding preﬁx is pruned. However, when
it is satisﬁable, we additionally get the best accuracy reachable (e.g., a lower
bound on the objective function value) while also meeting the fairness constraint
and improving the objective function. We use this value to order the priority
queue Q and deﬁne the ILP-Guided search heuristic. Intuitively, it guides the
exploration towards the preﬁxes whose fairness may conﬂict least with accuracy
(those with highest ILP objective function).
When building the ILP models, we use tight lower and upper bounds on the
number of well-classiﬁed examples, whose computations are detailed hereafter.

112
U. A¨ıvodji et al.
Lower Bound Computation. Let L(k, d, E) = |E|·(1−(misc(d, E)+λ·(Kd −k))).
Proposition 4. Consider a rule list d2. A rule list d1 = (δd1, q0) has better
objective value on E than d2 if and only if W d1
E
> L(|δd1|, d2, E), in which |δd1|
is the length of d1’s preﬁx.
Proof. obj(d1, E) < obj(d2, E)
⇐⇒
misc(d1, E) + λ · Kd1 < misc(d2, E) + λ ·
Kd2 ⇐⇒|E| · (1 −misc(d1, E)) > |E| · (1 −(misc(d2, E) + λ · (Kd2 −|δd1|))) ⇐⇒
W d1
E
> L(|δd1|, d2, E)
⊓⊔
Consider the preﬁx δ and the current best solution dc of the main loop. Let
d = (δd, q0) ∈σ(δ). Using Proposition 4, we have d has a better objective value
than dc if and only if W d
E > L(|δd|, dc, E) ≥L(|δ|, dc, E) because |δd| ≥|δ|.
Therefore L(|δ|, dc, E) is a valid lower bound for the ILP, ensuring that rule list
d improves over the current best objective value.
Upper Bound Computation. We leverage two observations to compute a tight
value U(δ, E) such that ∀d ∈σ(δ), W d
E ≤U(δ, E). First, the examples captured
and misclassiﬁed by δ will always be misclassiﬁed for any d ∈σ(δ). Second,
among the examples not captured by δ, some may conﬂict (i.e., have the same
features vector associated with diﬀerent labels) and can never be simultane-
ously predicted correctly. This computation corresponds to the Equivalent Points
Bound of CORELS (described in details in Sect. 3.14 of [4]).
5
Experimental Study
The purpose of this section is two-fold. First, after describing our experimental
setup, we show the eﬃciency of the proposed pruning approaches using two
biased datasets and the four considered fairness metrics of Table 1. Afterwards,
we demonstrate the scalability of our method as well as its complementarity with
a new preﬁx permutation map, using a larger real-world dataset.
5.1
Experimental Protocol
We implement and solve the ILP models in C++ using the ILOG CPLEX 20.10
solver1, with an eﬃcient memoisation mechanism. Sensitive features are used for
measuring and mitigating unfairness but are not used in the model’s construction
in order to prevent disparate treatment [27]. For each dataset, we generate 100
diﬀerent training sets by randomly selecting 90% of the dataset’s instances, with
reported values being averaged over the 100 instances. Test values are measured
1 Source code of this enhanced version of the FairCORELS Python package is available
on https://github.com/ferryjul/fairCORELSV2. The use of the CPLEX solver is
possible but not mandatory, as our released code also embeds an open-source solver
(whose conﬁguration has been tuned to handle our pruning problem eﬃciently). This
solver is Mistral-2.0 [17,19], in its version used for the Minizinc Challenge 2020.

Leveraging ILP to Learn Optimal Fair Rule Lists
113
on the remaining 10% instances for each random split. All experiments are run
on a computing grid over a set of homogeneous nodes using Intel Xeon E5-2683
v4 Broadwell @ 2.1GHz CPU.
We use three exploration heuristics: a best-ﬁrst search ILP-Guided, a best-
ﬁrst search guided by CORELS’s objective and a Breadth-First-Search (BFS). The
former inherently comes with an eager pruning. For the latter two, we compare
the original FairCORELS (no ILP pruning), as well as lazy and eager integrations
of our pruning approach. Then, we evaluate the seven exploration settings. How-
ever, results for the three best-ﬁrst searches guided by CORELS’s objective are
omitted because they consistently provided worst performances (considering all
evaluated criteria) than the BFS with equivalent pruning integration. This can
be explained by the fact that this approach guides exploration towards accurate
solutions ﬁrst, which conﬂicts with fairness in practice.
5.2
Evaluation of the Proposed ILP-Based Pruning Approaches
To empirically assess the eﬀectiveness of our proposed pruning on FairCORELS,
we perform experiments for the four metrics of Table 1 using two well-known
classiﬁcation tasks of the literature with several fairness requirements. The ﬁrst
task consists in predicting which individuals from the COMPAS dataset [5] will
re-oﬀend within two years. We consider race (African-American/Caucasian) as
the sensitive feature. Features are binarized using one-hot encoding for categor-
ical ones and quantiles (with 5 bins) for numerical ones. Rules are generated as
single features without minimum support. The resulting preprocessed dataset
contains 18 rules and 6150 examples.
The second task consists in predicting whether individuals from the German
Credit dataset [11] have a good or bad credit score. We consider age (low/high)
as the sensitive feature, with both groups separated by the median value. Fea-
tures are binarized using one-hot encoding for categorical ones and quantiles (2
bins) for numerical ones. Rules are generated as single features with minimum
support of 0.25 or conjunctions of two features with minimum support of 0.5.
Gender-related features were excluded. The resulting preprocessed dataset con-
tains 49 rules and 1000 examples. For experiments on the COMPAS (respectively
German Credit) dataset, the maximum running time is set to 20 min (respec-
tively 40 min). For each experiment, the maximum memory use is ﬁxed to 4 Gb.
Due to the limited space available, we detail our evaluation for the Statistical
Parity metric. Results for all other metrics show similar trends.
Figure 1(a) displays the proportion of instances solved to optimality as a
function of the fairness requirement (which gets harder as 1−ϵ increases) to illus-
trate the joint action of CORELS’ bounds and the proposed ILP-based pruning.
For low fairness requirements, all evaluated methods reach optimality, thanks to
the action of CORELS’ bounds. However, these bounds are less eﬀective for strong
fairness requirements, and without the ILP pruning, optimality can hardly be
reached. Conversely, the higher the value of 1 −ϵ, the larger the pruning of the
search space. Hence, optimality is reached most of the time when performing

114
U. A¨ıvodji et al.
Fig. 1. Experimental results (left: COMPAS, right: German Credit).
an eager pruning (eager BFS or ILP-Guided). This joint eﬀect is particularly
visible with the lazy BFS approach on the COMPAS dataset.
Figures 1(b) and 1(c) are generated using high fairness requirements (unfair-
ness tolerances ranging between 0.005 and 0.02). Figure 1(b) presents the solving
time as a function of the proportion of instances solved to optimality (lower is
better). It shows a clear dominance of the proposed pruning approaches. For
COMPAS, the original FairCORELS does not prove optimality to any of the

Leveraging ILP to Learn Optimal Fair Rule Lists
115
Table 2. Learning quality evaluation (ϵ ∈[0.005, 0.05]): Proportion of instances for
which each method led to the best train (resp. test) accuracy, and average violation of
the fairness constraint at test time.
Dataset
UNF
BFS Original
BFS Lazy
BFS Eager
ILP Guided
Train
Acc
Test
Acc
Unf
viol.
Train
Acc
Test
Acc
Unf
viol.
Train
Acc
Test
Acc
Unf
viol.
Train
Acc
Test
Acc
Unf
viol.
COMPAS
dataset
SP
.951
.971
.009
1
.98
.009
1
.981
.009
1
.98
.009
PE
.927
.956
.033
1
.977
.034
1
.977
.034
1
.977
.034
EOpp
.941
.961
.03
1
.98
.031
1
.983
.031
1
.983
.031
EO
.897
.934
.035
.997
.974
.036
1
.976
.036
1
.974
.036
German
Credit
dataset
SP
.567
.799
.045
.994
.77
.045
.999
.783
.045
.996
.779
.045
PE
.967
.914
.138
1
.914
.137
1
.914
.138
.997
.927
.138
EOpp
.683
.816
.056
.99
.799
.055
1
.806
.055
.991
.829
.054
EO
.52
.759
.158
.979
.751
.161
.997
.741
.16
1
.771
.159
instances, whereas all pruning methodologies prove optimality to all instances.
For German Credit, similar trends are observed. Overall, the eager approach
appears more suitable to prove optimality, as it keeps the size of the queue
as small as possible. For experiments with German Credit, the ILP-Guided
approach eﬀectively speeds up convergence and proof of optimality by guid-
ing exploration towards fair and accurate solutions. This is not the case when
using COMPAS, but the approach is still able to reach the best solutions, thanks
to the performed pruning. Figure 1(c) shows the learning time as a function of
the objective function quality (normalized objective score proposed in [18]). The
proposed pruning allows ﬁnding better solutions within the time and memory
limits after a slow start. Indeed, the pruning slows the beginning of the explo-
ration, but pays oﬀ, given enough time, by eﬀectively limiting the growth of the
priority queue. The lazy approach is faster than the eager one at the beginning
of the exploration. However, this trend is inverted given suﬃcient time. Again,
the ILP-Guided approach speeds up convergence on German Credit, but worsens
it on COMPAS.
Finally, the reported results illustrate the eﬃciency of the proposed pruning
approaches to speed up the exploration of the preﬁx tree. The lazy approach less
slows exploration at the beginning, but the eager approach gives better results
given suﬃcient time. The ILP-Guided strategy showed an ability to speed up
convergence, but its performances depend on the problem at hand.
Test results are reported in Table 2, and suggest that building optimal models
does not result in worsening accuracy nor fairness generalization.
5.3
Scalability and Complementarity with the Permutation Map
As discussed in Sect. 3, a preﬁx permutation map speeds up the CORELS algo-
rithm by leveraging symmetries but cannot be used within FairCORELS without
compromising optimality. We modify it to enforce a weaker symmetry-breaking
mechanism while maintaining the guarantee of optimality. More precisely, the

116
U. A¨ıvodji et al.
Fig. 2. Results of our experiments on the Adult Income dataset.
proposed new preﬁx permutation map (PMAP) considers that two preﬁxes of
equal length are equivalent if and only if they have exactly the same confusion
matrix and their rules imply the same antecedents. It pushes a new preﬁx to the
priority queue Q (Line 12) only if Q contains no equivalent preﬁx.
To evaluate the scalability of our pruning approaches, we consider Adult
Income [11], a larger dataset that gathers records of individuals from the 1994
U.S. census. We consider the task of predicting whether an individual earns more
than 50, 000$ per year, with gender (male/female) being the sensitive attribute.
Categorical attributes are one-hot encoded and numerical ones are discretized
using quantiles (3 bins). The resulting dataset contains 48, 842 examples and
47 rules (attributes or their negation), with a minimum support of 0.05. We
consider only the Statistical Parity metric, as the three others do not conﬂict
strongly with accuracy in this setting as observed in Fig. 1(a) of [1]. Experiments
are performed with and without the new PMAP. The maximum running time
is set to two hours, with a maximum memory use of 8 Gb. Results for the ILP-
Guided approach are excluded as they show no clear improvement over the eager
pruning, suggesting that the guidance was not beneﬁcial overall.

Leveraging ILP to Learn Optimal Fair Rule Lists
117
Table 3. Learning quality evaluation (Adult Income dataset, ϵ ∈[0.005, 0.1])
BFS Original
BFS Lazy
BFS Eager
ϵ
Map Type
Train
Acc
Test
Acc
Test
Unf viol.
Train
Acc
Test
Acc
Test
Unf viol.
Train
Acc
Test
Acc
Test
Unf viol.
All
No PMAP
.938
.942
-.004
.963
.966
-.004
.964
.967
-.004
PMAP
.966
.97
-.004
.998
.987
-.004
1
.989
-.004
< 0.02
No PMAP
.815
.835
.0
.89
.907
.001
.892
.91
.001
PMAP
.897
.91
.001
.993
.96
.001
1
.968
.001
Results are summarized in Fig. 2. The left plot of Fig. 2(a) shows the pro-
portion of instances solved to optimality, for ϵ ∈[0.005, 0.02]. For these strong
fairness requirements, the approaches not using the new PMAP were never able
to prove optimality (as can be seen in the right plot) and are not represented.
The complementarity with our pruning approach is particularly visible, with
the methods using both the PMAP and the ILP pruning having the best per-
formances, both in terms of objective function quality (Fig. 2(b), left plot) and
proof of optimality. This is also observed in terms of memory use in Fig. 2(b)
(right plot). Indeed, the PMAP considerably reduces the size of the queue, lever-
aging the preﬁx tree symmetries. However, its eﬀect is weakened for strong fair-
ness constraints. The use of the ILP pruning mitigates this trend and for very
strong fairness requirements, the eager pruning alone proposes lower memory
consumption than the PMAP alone, to reach the same solutions. Finally, learn-
ing quality results are provided in Table 3 and conﬁrm these observations. More
precisely, they consistently show that the approaches improving train accuracy
also improve test accuracy, without impacting fairness violation.
6
Conclusion
We propose eﬀective ILP models leveraging accuracy and fairness jointly to prune
the search space of FairCORELS. Our large experimental study shows clear ben-
eﬁts of our approach to speed-up the learning algorithm on well-known datasets
from the literature. This gain is illustrated on three dimensions: achieving better
training objective function values (without loss of the learning quality), using less
memory footprint (i.e., reduced cache size) and certifying optimality in limited
amounts of time and memory. Combined with a proposed simple data structure,
the ILP pruning approaches allow the learning of optimal rule lists under fairness
constraints for datasets of realistic size.
Thanks to the declarative nature of our pruning approach, our framework is
ﬂexible and can simultaneously handle multiple fairness criteria for any number
of sensitive groups. Indeed, each group’s confusion matrix is modelled using two
variables in our ILP. Considering more than two groups would require declaring
additional variables, along with desired constraints using these variables.

118
U. A¨ıvodji et al.
Overall, our work illustrates the fact that statistical fairness and accuracy,
when considered jointly, can be leveraged to reduce the scope of acceptable solu-
tions eﬃciently. In the future, it would be interesting to pursue this line of work
by considering other learning algorithms and machine learning requirements.
Guiding the exploration by leveraging on the ILP models (as attempted with
the ILP-Guided approach) also seems to be a promising direction.
References
1. A¨ıvodji, U., Ferry, J., Gambs, S., Huguet, M.J., Siala, M.: Learning fair rule lists
(2019). arXiv preprint http://arxiv.org/abs/1909.03977
2. A¨ıvodji, U., Ferry, J., Gambs, S., Huguet, M.J., Siala, M.: Faircorels, an open-
source library for learning fair rule lists. In: Proceedings of the 30th ACM Inter-
national Conference on Information & Knowledge Management, pp. 4665–4669.
CIKM 2021, Association for Computing Machinery, New York (2021). https://doi.
org/10.1145/3459637.3481965
3. Angelino, E., Larus-Stone, N., Alabi, D., Seltzer, M., Rudin, C.: Learning certiﬁ-
ably optimal rule lists. In: Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 35–44. KDD 2017,
Association for Computing Machinery (2017). https://doi.org/10.1145/3097983.
3098047
4. Angelino, E., Larus-Stone, N., Alabi, D., Seltzer, M., Rudin, C.: Learning certi-
ﬁably optimal rule lists for categorical data. J. Mach. Learn. Res. 18(234), 1–78
(2018). http://jmlr.org/papers/v18/17-716.html
5. Angwin, J., Larson, J., Mattu, S., Kirchner, L.: Machine bias: there’s software
used across the country to predict future criminals and it’s biased against blacks.
propublica (2016). ProPublica, 23 May 2016
6. Barocas, S., Hardt, M., Narayanan, A.: Fairness and machine learning (2019).
http://www.fairmlbook.org
7. Caton, S., Haas, C.: Fairness in machine learning: a survey (2020). arXiv preprint
http://arxiv.org/abs/2010.04053
8. Chikalov, I., et al.: Logical analysis of data: theory, methodology and applications,
pp. 147–192. Springer, Berlin Heidelberg (2013). https://doi.org/10.1007/978-3-
642-28667-4 3
9. Chouldechova, A.: Fair prediction with disparate impact: a study of bias in recidi-
vism prediction instruments. Big Data 5(2), 153–163 (2017). https://doi.org/10.
1089/big.2016.0047
10. Doshi-Velez, F., Kim, B.: Towards a rigorous science of interpretable machine learn-
ing (2017). arXiv preprint http://arxiv.org/abs/1702.08608
11. Dua, D., Graﬀ, C.: UCI machine learning repository (2017). http://archive.ics.uci.
edu/ml
12. Dwork, C., Hardt, M., Pitassi, T., Reingold, O., Zemel, R.: Fairness through aware-
ness. In: Proceedings of the 3rd Innovations in Theoretical Computer Science Con-
ference, pp. 214–226. ITCS 2012, Association for Computing Machinery, New York
(2012). https://doi.org/10.1145/2090236.2090255
13. Freitas, A.A.: Comprehensible classiﬁcation models: a position paper. SIGKDD
Explor. Newsl. 15(1), 1–10 (2014). https://doi.org/10.1145/2594473.2594475
14. Goodman, B., Flaxman, S.: European union regulations on algorithmic decision-
making and a “right to explanation”. AI Mag. 38(3), 50–57 (2017)

Leveraging ILP to Learn Optimal Fair Rule Lists
119
15. Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., Pedreschi, D.:
A survey of methods for explaining black box models. ACM Comput. Surv. 51(5),
1–42 (2018). https://doi.org/10.1145/3236009
16. Hardt, M., Price, E., Price, E., Srebro, N.: Equality of opportunity in super-
vised learning. In: Advances in Neural Information Processing Systems, vol. 29.
Curran Associates, Inc. (2016). https://proceedings.neurips.cc/paper/2016/ﬁle/
9d2682367c3935defcb1f9e247a97c0d-Paper.pdf
17. Hebrard, E.: Mistral, a constraint satisfaction library. Proc. Third Int. CSP Solver
Competition 3(3), 31–39 (2008)
18. Hebrard, E., Siala, M.: Explanation-based weighted degree. In: Salvagnin, D., Lom-
bardi, M. (eds.) CPAIOR 2017. LNCS, vol. 10335, pp. 167–175. Springer, Cham
(2017). https://doi.org/10.1007/978-3-319-59776-8 13
19. Hebrard, E., Siala, M.: Solver engine (2017). https://www.cril.univ-artois.fr/
CompetitionXCSP17/ﬁles/Mistral.pdf
20. Kamiran, F., Calders, T.: Data preprocessing techniques for classiﬁcation with-
out discrimination. Knowl. Inf. Syst. 33(1), 1–33 (2012). https://doi.org/10.1007/
s10115-011-0463-8
21. Lipton, Z.C.: The mythos of model interpretability: in machine learning, the con-
cept of interpretability is both important and slippery. Queue 16(3), 31–57 (2018).
https://doi.org/10.1145/3236386.3241340
22. Miettinen, K.: Nonlinear Multiobjective Optimization, International Series in
Operations Research & Management Science, vol. 12. Springer, Boston (2012).
https://doi.org/10.1007/978-1-4615-5563-6
23. Rivest, R.L.: Learning decision lists. Mach. Learn. 2(3), 229–246 (1987). https://
doi.org/10.1007/BF00058680
24. Rudin, C.: Stop explaining black box machine learning models for high stakes
decisions and use interpretable models instead. Nat. Mach. Intell. 1(5), 206–215
(2019). https://doi.org/10.1038/s42256-019-0048-x
25. Rudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L., Zhong, C.: Interpretable
machine learning: fundamental principles and 10 grand challenges (2021). arXiv
preprint http://arxiv.org/abs/2103.1125
26. Verma, S., Rubin, J.: Fairness deﬁnitions explained. In: Proceedings of the Inter-
national Workshop on Software Fairness, pp. 1–7. FairWare 2018, Association
for Computing Machinery, New York (2018). https://doi.org/10.1145/3194770.
3194776
27. Zafar, M.B., Valera, I., Gomez Rodriguez, M., Gummadi, K.P.: Fairness beyond
disparate treatment & disparate impact: learning classiﬁcation without disparate
mistreatment. In: Proceedings of the 26th International Conference on World Wide
Web, pp. 1171–1180. WWW 2017, International World Wide Web Conferences
Steering Committee, Republic and Canton of Geneva, CHE (2017). https://doi.
org/10.1145/3038912.3052660

Solving the Extended Job Shop
Scheduling Problem with AGVs –
Classical and Quantum Approaches
Marc Geitz1, Cristian Grozea2(B)
, Wolfgang Steigerwald1, Robin St¨ohr1,
and Armin Wolf2
1 Telekom Innovation Laboratories, Berlin, Germany
{marc.geitz,wolfgang.steigerwald}@telekom.de
2 Fraunhofer FOKUS, Berlin, Germany
{cristian.grozea,armin.wolf}@fokus.fraunhofer.de
Abstract. In this article we approach an extended Job Shop Scheduling
Problem (JSSP). The goal is to create an optimized duty roster for a set
of workpieces to be processed in a ﬂexibly organized workshop, where the
workpieces are transported by one or more Autonomous Ground Vehicles
(AGV), that are included in the planning.
We are approaching this extended, more complex variant of JSSP
(still NP-complete) using Constraint Programming (CP) and Quantum
Annealing (QA) as competing methods.
We present and discuss: a) the results of our classical solution
based on CP modeling and b) the results with modeling as quadratic
unconstrained binary optimisation (QUBO) solved with hybrid quantum
annealers from D-Wave, as well as with tabu search on current CPUs.
The insight we get from these experiments is that solving QUBO mod-
els might lead to solutions where some immediate improvement is achiev-
able through straight-forward, polynomial time postprocessing. Further
more, QUBO proves to be suitable as an approachable modelling alterna-
tive to the expert CP modelling, as it was possible to obtain for medium
sized problems similar results, but requiring more computing power.
While we show that our CP approach scales now better with increased
problem size than the hybrid Quantum Annealing, the number of qubits
available for direct QA is increasing as well and might eventually change
the winning method.
Keywords: Constraint Programming · Job Shop Scheduling ·
Quadratic Unconstrained Boolean Optimization Problem · Quantum
Annealing · Quantum Computing · Sequence-Dependent Setup-Times
The presented work was funded by the German Federal Ministry for Economic
Aﬀairs and Climate Action within the project “PlanQK” (BMWi, funding number
01MK20005) [7].
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 120–137, 2022.
https://doi.org/10.1007/978-3-031-08011-1_10

Extended Job Shop Scheduling with AGVs – Classical and Quantum
121
Fig. 1. Sample use case scenario: 4 machines, one AGV
1
Introduction
1.1
Problem Motivation and Description
The calculation of duty rosters is, since many years, a special subject in the
departments of Operations Research. JSSP is NP-hard, which means that with
each additional node in the manufacturing sequence the solution space expands
exponentially. Based on a project about campus networks combined with edge
computing at an OSRAM factory [17] we introduce and solve here an extension
where one or more Autonomous Ground Vehicles (AGVs) transport the work
pieces between the machines. The individualized transport of the work pieces
on the shop ﬂoor within the paradigms of Industry 4.0 increases the complexity
tremendously. For this reason we derive here a use case including several realis-
tic aspects (specialized machine functions, heterogeneous processing times and
number of processing steps).
2
Use Case Scenario
For the sample scenario Set1 (depicted in Fig. 1) we consider four machines with
diﬀerent tool settings where an Autonomous Ground Vehicle (AGV) is used to
transport the workpieces on the shopﬂoor. The scenario can be up-scaled with
more machines and several AGVs. We solve in the experiments described below
problems with up to 10 work pieces, 2 AGVs and 100 tasks.
2.1
Deﬁnitions and Process Requirements
– Each machine has a speciﬁc functionality.
– Each workpiece must be processed in a predeﬁned sequence of steps (i.e.
processing tasks), named “job”. Multiple processing tasks requiring the same
machine inside a job are allowed.
– Each machine has unlimited storage for workpieces at input and output.

122
M. Geitz et al.
– The individual processing tasks and transportation tasks are non-preemptive.
– At most one workpiece can be processed on a machine at any time.
– For each processing task the processing sequence and the duration is given.
– Every processing task must be executed exactly once.
– Every processing task inside a job can only start after the previous one.
– The transportation of the workpieces is performed by one of the AGVs.
– The AGVs and all the workpieces are positioned at the beginning on the start
point (“Start”) and at the end on the target point (“Target”). There can be
several start and target points.
– Each AGV can carry at most one workpiece on each transportation task
between two nodes: from “Start” to a machine, from a machine to another
machine, and from a machine to “Target”.
– The required transit time between every two nodes must be incorporated
during the planning and optimization of the duty roster.
– The transit times between every two nodes are known in advance.
– The total processing time should be minimized. The total processing time is
the time consumed for all parts being manufactured during their processing
tasks, according to the duty roster, including transport.
A sample scenario is presented schematically in Fig. 1.
3
The Extended Job Shop Scheduling Problem
with AGVs – Deﬁnition
In this section the considered extended JSSP with AGVs problem is formally
deﬁned. In detail the ﬁxed parameters of this constrained optimization problem,
the decision variables to be determined, the constraints to be satisﬁed and the
objective to be optimized are speciﬁed.
3.1
Parameters
There are machines m = 0, . . . , M where some machines represent start locations
like machine m = 0 in Fig. 1 and some machines represent target locations like
machine m = M in Fig. 1. For any two machines m and m′ the transition
duration d(m, m′) from machine m to machine m′ is given. For any machines
m, m′ and m′′ it holds that
d(m, m) = 0,
d(m, m′) ≥0
and
d(m, m′′) ≤d(m, m′) + d(m′, m′′)
(1)
These conditions are in general satisﬁed in real world scenarios, as the transition
duration are directly proportional with according distances (for constant speed)
and the distance is a metric.
There are jobs j = 1, . . . , J, one for each work piece j. Each job j has
Fj +1 processing tasks: tj,0, tj,2 . . . , tj,2·Fj. By convention we use even indices to
identify them as processing tasks, because there are transportation tasks – with
odd indices – between them (see below). Each processing task tj,2·i is processed

Extended Job Shop Scheduling with AGVs – Classical and Quantum
123
on machine mj,i where for each job the ﬁrst machine mj,0 is its start location
and the last machine mj,Fj is its target location. For each processing task tj,2i its
processing time on machine mj,i is pj,i. In particular, for each job j the processing
time at its start location and its target location is zero: pj,0 = pj,Fj = 0.
Further, each job j has of Fj transportation tasks: tj,1, tj,3, . . . , tj,2·(Fj−1)+1.
By convention we use odd indices to identify them as transportation tasks.
For each transportation task tj,2·i+1 its processing time is the travelling time
d(mj,i, mj,i+1) from machine mj,i to machine mj,i+1.
Further there are AGVs v = M + 1, . . . , M + V transporting work pieces
between machines.For each AGV v there is a (dummy) transportation task tv,1
performed by this AGV. Its zero processing time is the zero travelling time
d(mv, mv) at its start location, i.e. at machine mv, where the AGV v is located
initially. Its start time s(tv,1) = 0 by deﬁnition.
3.2
Variables
For each processing or transportation task t its start time s(t) ∈{0, . . . , T}
has to be determined where T is the scheduling horizon1 and further for each
transportation task tj,2·i+1 the transporting AGV v(j, i) ∈{M + 1, . . . , M + V }
must be determined, too.
3.3
Constraints
For each job j = 1, . . . , J it must hold that the the corresponding tasks – either
for work or transport – are in linear order:
s(tj,0) + pj,0 ≤s(tj,1) ∧s(tj,1) + d(mj,0, mj,1) ≤s(tj,2)
∧. . . ∧s(tj,2·Fj−1) + d(mj,Fj−1, mj,Fj) ≤s(tj,2·Fj).
(2)
For each machine m = 0, . . . , M and at each time τ ∈{0, . . . , T} it must
hold that at most one processing task is performed by this machine:

j ∈{1, . . . , J} ∧i ∈{0, . . . , M} ∧
mj,i = m ∧s(tj,2·i) ≤τ < s(tj,2·i) + pj,i
1 ≤1,
(3)
i.e. the processing tasks on each machine will be processed sequentially.
For each AGV v = M + 1, . . . , M + V and at each time τ ∈{0, . . . , T} it
must hold that at most one transportation task is performed by this AGV:

v ∈{M + 1, . . . , M + V } ∧j ∈{1, . . . , J} ∧i ∈{0, . . . , M} ∧
v(j, i) = v ∧s(tj,2·i+1) ≤τ < s(tj,2·i+1) + d(mj,i, mj,i+1)
1 ≤1,
(4)
1 An upper bound of the scheduling horizon is the sum of all processing times and all
transition durations.

124
M. Geitz et al.
i.e. the transportation tasks will be processed sequentially by each AGV. Further,
there must be time for empty drives between the destinations and departures of
successive transportation tasks:
For any two successive transportation tasks tj,2·i+1 and tj′,2·i′+1 performed
by the same AGV it must hold that there is enough time for an empty drive
between the machines, i.e. if there is an AGV v ∈{M +1, . . . , M +V } such that
v(j, i) = v = v(i′, j′) ∧s(tj,2·i+1) + d(mj,i, mj,i+1) ≤s(tj′,2·i′+1),
(5)
then it must hold that
s(tj,2·i+1) + d(mj,i, mj,i+1) + d(mj,i+1, mj′,i′) ≤s(tj′,2·i′+1).
(6)
3.4
Objective
The objective is to determine the variables deﬁned in Sect. 3.2 such that the
constraints in Sect. 3.3 are satisﬁed and the make-span, i.e. the latest start time
(and thus end time by deﬁnition) of the last tasks of all jobs at the target location
and thus the overall completion time of all jobs
max
j=1,...,J s(tj,2M)
is minimized.
(7)
4
Related Work
Our extension to JSSP adds additional transportation tasks to be scheduled on
alternative exclusive resources (namely AGVs) with sequence-dependent setup /
transition times. All these scheduling problems are NP-hard [6].
In optimization problems, like extended JSSP with AGVs, we are trying to
ﬁnd the best solution from all feasible solutions. We can convert those problems
into energy minimization problems and use the eﬀects of quantum physics to
ﬁnd the solution of the lowest potential energy [9]. In quantum annealing we
have, instead of classical bits, so-called qubits, which on top of being in a state
of 0 or 1, those can also be in a superposition, which corresponds to both states
at the same time.
Quantum Annealing (QA) assumes a system in full superposition being in
its lowest energy state. The system is then slowly (adiabatically) conveyed to
an energy function describing the optimization problem - the adiabatic theorem
[30] assures that the system will remain on its lowest energy state during the
transition. At the end of the annealing process, the system has turned from a
fully superimposed quantum state to a classical state, where the qubits can easily
be read out.
The basic JSSP has been solved using the technique of simulated anneal-
ing [8,35,36]. A quantum annealing solution has ﬁrst been introduced in [25]
where the JSSP has been modelled as cost or energy function to be minimized
(QUBO, see below). A basic implementation for a D-Wave quantum annealer

Extended Job Shop Scheduling with AGVs – Classical and Quantum
125
is presented in [10,18]. The modelling or implementation of a more complicated
JSSP problem, especially with the introduction of AGVs or robots to transport
goods between machines on the shopﬂoor has not been done previously, as far
as we could ﬁnd.
A quadratic unconstrained binary optimization problem (QUBO) is a mini-
mization problem of this form:
min
x∈{0,1}N

i
Qi,ixi +

i<j
Qi,jxixj
(8)
where x = (xi)i=1...N are binary variables and the real-valued matrix Q of size
N × N fully deﬁnes the QUBO instance. The matrix Q is by convention upper
diagonal. Thanks to the similarity of the QUBO formula to the Ising Model [11],
QUBO matrices can be transformed trivially into Ising Hamiltonian matrices and
thus solutions for the QUBO problems can be produced by quantum annealers
like those of D-Wave. The constraints of the problems to be modelled as QUBOs
are integrated into the objective function as additional terms that achieve their
minimum only when the respective constraints are satisﬁed.
A quantum computer will compute the minimum of the QUBO function,
hence solve the optimization problem with all constraints fulﬁlled.
Constraint Programming (CP) deals with discrete decision and optimization
problems combining pruning algorithms known from Operations Research (OR)
reducing the search space and heuristic tree search algorithms, known from Arti-
ﬁcial Intelligence (AI) in order to explore the search space. The advantage of CP
is that each decision during search will be used to prune branches in the search
tree. Using specialized OR pruning algorithms, CP is an appropriate approach
for solving resource scheduling problems [3] like extended JSSP with AGVs.
Compared to local search approaches, e.g., Simulated Annealing or Quantum
Annealing, CP oﬀers several advantages:
– The solutions found (schedules) always satisfy the speciﬁed constraints, which
is not always the case in local search, where the violation of the constraints
is only minimized.
– Whereas both approaches can ﬁnd good or even optimal solutions (depending
on the error surface, in the case of the local search), in the case of CP, the
optimality of the best solutions can be proven with complete search.
In CP there exist highly eﬃcient methods for reducing the ﬁnite value ranges
of the decision variables (start times, durations, end times, possible resources
etc.) of activities on exclusive resources. Some of those are: overload checking,
forbidden regions, not-ﬁrst/not-last detection, detectable precedences and edge
ﬁnding [4,27,31]. Some recent version of those pruning methods and related
approaches support (sequence-dependent) setup/transition times [1,2,14,24,26,
28] and pruning for optional activities [5,29,32]. Optional activities (that can be
optionally scheduled, but must not necessarily) are the basis for certain modelling
approaches for scheduling activities on alternatively exclusive resources [34]. Such
activities are in our case the transport tasks, that can be scheduled on alternative

126
M. Geitz et al.
available AGVs. However these activities change the locations of the AGV which
has to be respected: Transition times occur between two consecutive transport
tasks when the destination of the ﬁrst transport task diﬀers from the origin of
the second one. In those cases the used AGV has to travel (empty) from one
location to another.
Optimization in CP is generally done by Branch-and-Bound (B&B), i.e.
through an iterative search for ever better solutions. The optimization follows
either a monotonous or a dichotomous bounding strategy combined with a
mostly problem speciﬁc one, generally full depth search [16]. This combined
strategy (B&B with full depth search) guarantees that the best solutions are
found and their optimality is proven. Furthermore, dichotomous bounding allows
to quantify the quality of already found, intermediate solutions.
Recent advances in CP follow a hybrid approach that combines search space
pruning with the satisﬁability problem solving (SAT Solving) for classical propo-
sitional logic [23]. There, clauses are generated during constraint processing
(propagation) and further processed by SAT Solving [13]. Promising results show
that this hybrid approach is ideally suitable for solving scheduling problems in
a classical way [19–22].
5
Methods
5.1
Solving the Extended JSSP with AGVs Using Constraint
Programming
We use the Constraint Programming library firstCS [33] to model and solve the
extended JSSP with AGVs. We handle the linear order of the tasks in the jobs (cf.
Eq. (2)) either by order constraints between consecutive tasks stating that the
start time plus the duration, i.e. the end time of the predecessor task is less than
or equal to the start time of the successor task or more globally while using an
implementation of global diﬀerence constraints for the same order conditions [12].
The firstCS library oﬀers objects and algorithms adopted from [27,29,31] to
handle task scheduling constraints on unary, single resp. exclusive resources.
We use these objects and algorithms to schedule the processing tasks on the
machines satisfying the constraints deﬁned in Eq. (3) and also to schedule the
transportation tasks sequentially on one AGV (cf. Eq. (4)). We handle sequence-
dependent transition times (cf. Eq. (5) and (6)) either on the modeling level
(see below) or alternatively, we handle sequential scheduling of transportation
tasks with sequence-dependent transition times on AGVs while using a rather
new approach presented in [24]. Even though this approach supports optional
activities and thus can be generalized to schedule tasks alternatively on several
resources, we currently use this approach only to schedule transportation tasks
on one AGV. For extended JSSP with several AGVs we adapted the approach
presented in [34] to deal with such alternative exclusive resources (cf. Eq. (4)).
On the modeling level we handle sequence-dependent transition times on
AGVs alternatively to the approach presented in [24]. In this case, we assume
that an AGV must perform the transportation tasks in T = {t1, . . . , tn} between

Extended Job Shop Scheduling with AGVs – Classical and Quantum
127
some locations in L = {L0, . . . , Lm}, i.e. of the machines of the extended JSSP
with AGVs. If the destination and the departure locations between two consec-
utive transportation tasks are diﬀerent, then some additional transitions (empty
drives) have to be performed. Further, let d(P, Q) be the travel time between any
two locations P, Q ∈L (of machines). Then, it is assumed that the Conditions (1)
are satisﬁed, i.e.
d(L, L) = 0, d(P, Q) ≥0 and d(P, Q) ≤d(P, R) + d(R, Q)for L, P, Q, R ∈L.
(9)
Each transportation task ti ∈T is annotated by its departure location Pi ∈L
(of a machine) where the AGV picks up a workpiece and its destination loca-
tion Qi ∈L (of a machine) where the AGV releases a workpiece, i.e. let ti =
ti(Pi, Qi). Further, let si = si(Pi) be the (variable) start time of the transporta-
tion task ti(Pi, Qi) at location Pi and ei = ei(Qi) be the (variable) end time of
the transportation task ti(Pi, Qi) at location Qi. Further let di = d(Pi, Qi) be
the duration of task ti(Pi, Qi) determined by the travel time d(Pi, Qi) between
both locations (between the machines) such that
si(Pi) + d(Pi, Qi) = ei(Qi) holds for i = 1, . . . , n.
(10)
The transportation tasks in T of an AGV must be scheduled in linear order;
i.e. T = {t1, . . . , tn} must be ordered in such a way that
ei(Qi) + d(Qi, Pi+1) ≤si+1(Pi+1) holds for i = 1, . . . , n −1.
(11)
There, d(Qi, Pi+1) is the transition time for the empty drive between the destina-
tion location Qi of the i-th transportation task and the departure location Pi+1
of the successive (i + 1)-th transportation task. In order to satisfy these tran-
sition times for empty drives on an AGV, i.e. an exclusively available resource
we adapted the approach presented in [32] where additional exclusively avail-
able resources – one for each location – are introduced as well as additional
transportation tasks: For each “real” transportation task ti(Pi, Qi) and each
location L we consider an additional “virtual” transportation tasks tL
i to be
scheduled on the “virtual” resource L having start and end times
sL
i = si(Pi) + d(Pi, L) and eL
i = ei(Qi) + d(Qi, L).
It matters that each “virtual” task is well-deﬁned: the duration of each “virtual”
task tL
i namely eL
i −sL
i = ei(Qi)+d(Qi, L)−si(Pi)−d(Pi, L) = si(Pi)+d(Pi, Qi)+
d(Qi, L)−si(Pi)−d(Pi, L) = d(Pi, Qi)+d(Qi, L)−d(Pi, L) is always non-negative
due to the triangle inequality (cf.Conditions (9)). The important point is that
we proved for an AGV with more than two transportation tasks that
ei(Qi) + d(Qi, Pj) ≤sj(Pj) ⇐⇒eL
i ≤sL
j
(12)
holds for any two diﬀerent transportation tasks ti, tj ∈T , ti ̸= tj and for each
location L ∈L.2 This means that scheduling the “virtual” tasks tL
i in the same
2 Details on the proof of this equivalence can be found in [32].

128
M. Geitz et al.
Fig. 2. The interrelationship between “real” transportation tasks (bottom line) with
empty drives in between and their according “virtual” tasks (having the same color in
the upper part with one line, i.e. exclusive resource, for each location) scheduled in the
same linear order.
linear order on each “virtual” resource L ∈L results in a schedule where the
“real” transportation tasks are scheduled in the same order respecting the nec-
essary transition times for empty drives between diﬀerent locations as shown in
Fig. 2. Consequently, we force such a scheduling with the same linear order of
the “real” and the“virtual” tasks when using this approach.
For several alternative AGVs, optional tasks (a.k.a. optional activities) are
used, such that pruning related to these tasks will be performed when a task
is assigned to one of the alternative AGVs. The presented constraint models
and the according ﬁltering algorithms for pruning the search space are used
together with a branch-and-bound tree-search based on domain reduction [15]
for minimizing the make-span (cf. Eq. (7)).
5.2
Solving the Extended JSSP with AGVs on a Quantum Annealer
We model our problem as a quadratic unconstrained binary optimization problem
(QUBO, cf. (8)).
Variable Deﬁnitions and Notations: let T be the planning horizon and I be
the number of processing tasks. A safe, but usually overestimating choice for the
planning horizon is the sum of the processing time of all tasks. We use here lower
guesses that we increase until we reach one that produces admissible solutions
(i.e. with all constraints satisﬁed). Starting with the variable structure used in
[25], we index our variable array x by processing task index i and running time
0 ≤t < T: xi,t = 1 if and only if processing task Oi starts at time t, where
Oi denotes the processing task number i. The processing tasks are ordered in
a lexicographical way, starting from the ﬁrst processing task of the ﬁrst job,
going to the last processing task of the last job. Additionally we denote the
processing time of the processing task i with pi, and with kn the index of the
last processing task of the job jn. Let W = (wa,b) be the point-to-point transition
duration matrix, where wa,b stores the time the AGV needs from machine a to
machine b.
Transport Tasks: we model the start point and the end point as two additional
machines and add to each job dummy processing tasks of null duration at the
beginning and end. Therefore we can assume the workpieces are at start time

Extended Job Shop Scheduling with AGVs – Classical and Quantum
129
at the (pseudo)machine where they are ﬁrst needed. To include the AGV move-
ments into the model, we introduce transport tasks in addition to the standard
processing tasks. Between every two successive standard processing tasks of a
job, we add B transport tasks, where B denotes the number of AGVs. The indi-
vidual transport tasks are denoted with ξ. All B transport tasks between two
standard processing tasks are combined in a set that we name “the transport
task group”. One of these transport tasks groups, denoted with Ψ, will have the
structure Ψx = (ξx0, ξx1, ...). From each transport tasks group, a single trans-
port task must be picked, to transport the piece. Individual transport tasks are
deﬁned as a tuple ξx = (b, wmsme, ms, me) where b is the AGV executing this
operation, ms is the start machine the workpiece needs to be picked up from
and me is the end machine the piece needs to be delivered to. Those tasks are
appended at the end of the standard processing tasks in our indexing. Addition-
ally we deﬁne Ωi as the predecessor transport task of the standard processing
task i. This contains the transport tasks of all AGVs, that come directly before
i. For those indices i for which Oi is the ﬁrst task of a job, Ωi is an empty set,
as that task is dummy and only has the role to ensure the transport following it
starts in the start point. We deﬁne Φi as the standard processing task, previous
to the transport task i. Im is deﬁned to be the set of all processing tasks executed
on machine m. Ib is deﬁned to be the set of all transport tasks executed by the
AGV b. IΨ is the set of all transport tasks in the group Ψ.
We need to account for the following constraints:
h1 Every processing task must run exactly once. With a planning horizon T,
our variables for the processing task Oi would consist of xi,0, xi,1, . . . , xi,T −1.
Here we need to enforce, that exactly one of these variables is 1, and the rest are
0. That means we want to increase the penalty, when none, or more than one of
them is 1. We can do that by iterating over the set of all tasks I, and for each
i ∈I we subtract 1 from the sum oﬀall t ∈T, and square the result. This way
the penalty term for this constraint is 0 if exactly one time slot is assigned for
each task, and higher than that otherwise, which will enforce exactly one time
slot being picked for each task: h1(¯x) = I−1
i=0
T −1
t=0 xi,t −1
2
.
h2 Every machine can only work on one task at a time:
h2(¯x) = M−1
m=0

(i,t,i′,t′)∈Rm xi,txi′,t′, where Rm is the set that contains all
indices of task i with its corresponding starting time t and a second task i′ with
its time t′, both to be scheduled on the same machine, for which scheduling them
as such leads to an overlap: Rm = {(i, t, i′, t′) : (i, i′) ∈Im ×Im, i ̸= i′, 0 ≤t, t′ ≤
T, 0 ≤t′ −t < pi}
h3 The processing tasks of a job cannot overlap. For this constraint, we need
to iterate over all jobs n, and pick the tasks i and execution start times t and t′,
for which the sum of the processing time of i with its execution start time t is
larger than the execution start time of the next processing task t′, and therefore
violates the constraint: h3(¯x) = N−1
n=0

t,t′;i,i+1∈Im;t+pi>t′ xi,txi+1,t′.
The objective function is built by introducing a set of”upper bound” vari-
ables Ut such that exactly one of them is true. Together they model a virtual

130
M. Geitz et al.
ﬁnite domain variable V with the domain 0 . . . T, such that V = t if and only if
Ut = 1, i.e. T
t=0 Ut = 1.
h4 Exactly one of the variables Ut is set. Enforcing this is done by adding
the following quadratic constraint to the target function: h4( ¯U) = (T
t=0 Ut−1)2.
h5 No planned task ends after the upper bound. The index t where Ut = 1 is
understood to be an upper bound of the whole schedule, therefore we impose
that no i, t1, t2 exist such that xi,t1 = 1, Ut2 = 1 and t1 +pi > t2 (no planed task
ends after the upper bound). Enforcing this condition can be done by adding
this penalty term to the target function h5(¯x, ¯U) = 
i,t1,t2;t1+pi>t2 xi,t1Ut2.
With those, we can introduce the core of the objective function o( ¯U) =
N
t=0 tUt. Its meaning is fairly straightforward: by minimizing o( ¯U) one gets a
lowest upper bound that is also minimum amongst all consistent solutions (solu-
tions satisfying all constraints) thus the solution that guarantees the shortest
make-span.
h6
For each transport between two processing tasks , exactly one transport
task must be picked. Here we also make sure that for all tasks belonging to the
same transport tasks group and for all times, there is only one variable xi,t, that
will have the value 1, which means one and exactly one of the AGVs is selected
to perform that transport: h6(¯x) = I−1
j=0
Ωj̸=∅

i∈Ωj
T −1
t=0 xi,t −1
2
.
h7 AGVs must have enough time to switch to the next machine. Here we
iterate over all transport tasks of each AGV, denoted as Ib. For all possible
tasks of these AGVs, we make sure that the starting time of the task i′ ∈Ib,
is not before the task i ∈Ib is ﬁnished, plus the time the AGV needs to switch
machines. In here, me(i) deﬁnes the machine end of transport task i or the fourth
element in the tuple. ms(i′) deﬁnes the machine start of the transport task i′,
or the third element in the tuple:
h7(¯x) = B−1
b=0

i,i′∈Ib
i̸=i′

t,t′
t‘>t
xi,txi′,t′max

t + pi + wme(i)ms(i′) −t′, 0

.
h8
A processing task can only be scheduled at time t, if the corresponding
transport task is ﬁnished before or at t. Using our previously deﬁned Prede-
cessor Transport Task, we iterate through all processing tasks and their
corresponding
transport
tasks,
and
apply
a
penalty
if
the
transport
task i′
is ﬁnished after the time t of the processing task: h8(¯x)
=
I−1
i=0

i′∈Ωi

t,t′ xi,txi′,t′max (t′ + pi′ −t, 0).
h9
A transport task can only be picked at time t, if the corresponding pro-
cessing task is ﬁnished before or at t. This will be the inverse of h8. Using the
Predecessor Processing Task, we iterate through all transport tasks and their
corresponding processing tasks and apply a penalty if the the previous process-
ing task starting at time t′ with its individual processing time, is not ﬁnished
before or at t: h9(¯x) = I−1
j=0

i∈Ωj

t,t′ xi,txΦi,t′max (t′ + pΦi −t, 0).
Final QUBO. We add the constraints weighted with α (chosen to satisfy α >
T) to the core of the objective function, to get the ﬁnal target function for the

Extended Job Shop Scheduling with AGVs – Classical and Quantum
131
Table 1. Empirical results based on the firstCS implementation (MS=Make-Span)
Id
problem size
GD
B&B
model-based trans. times
algorithm-based trans. times
MS
runtime
proof of opt.
MS
runtime
proof of opt.
Set1
4x4x24x1
−
M
65
3064 sec.
—
82
2156 sec.
—
−
D
58
20313 sec.
20531 sec.
63
503 sec.
—
+
M
58
151 sec.
164 sec.
58
112 sec.
131 sec.
+
D
58
34 sec.
54 sec.
58
36 sec.
68 sec.
Set2
4x8x24x1
−
M
57
1636 sec.
1638 sec.
57
2509 sec.
2532 sec.
−
D
57
167 sec.
167 sec.
57
723 sec.
723 sec.
+
M
57
37 sec.
38 sec.
57
9 sec.
9 sec.
+
D
57
7 sec.
7 sec.
57
2 sec.
2 sec.
Set3
4x4x24x1
−
M
90
3527 sec.
—
108
264 sec.
—
−
D
58
620 sec.
748 sec.
62
879 sec.
—
+
M
58
131 sec.
149 sec.
58
347 sec.
603 sec.
+
D
58
57 sec.
75 sec.
58
335 sec.
710 sec.
Set4
4x4x21x1
−
M
57
3299 sec.
—
59
57 sec.
—
−
D
58
1954 sec.
—
81
0.165 sec.
—
+
M
48
38 sec.
41 sec.
48
36 sec.
57 sec.
+
D
48
15 sec.
18 sec.
48
22 sec.
39 sec.
Set5
4x4x21x1
−
M
57
3304 sec.
—
59
55 sec.
—
−
D
58
1847 sec.
—
81
0.092 sec.
—
+
M
48
46 sec.
50 sec.
48
25 sec.
40 sec.
+
D
48
17 sec.
21 sec.
48
20 sec.
35 sec.
Set6
4x4x24x2
−
M
39
192 sec.
1629 sec.
—
−
D
39
134 sec.
1599 sec.
—
+
M
39
162 sec.
1695 sec.
—
+
D
39
155 sec.
1802 sec.
—
Id
problem size
GD B&B
MS
runtime
Id
problem size
GD B&B
MS
runtime
Set7
10x10x120x1
−
M
412
1263 sec.
Set8
10x10x120x2
−
M
224
238 sec.
−
D
467
167 sec.
−
D
241
84 sec.
+
M
412
2274 sec.
+
M
224
1049 sec.
+
D
467
331 sec.
+
D
241
236 sec.
extended JSSP with AGVs: HT (¯x, ¯U) = α 
i=1..9 hi + o( ¯U). This is now an
unconstrained minimization problem in binary variables, as the constraints have
been integrated into the objective function – a QUBO problem.
6
Results
6.1
Experimental Results Using the Constraint Programming
Approach
We performed runtime experiments with CP-based solutions of the extended
JSSP with AGVs (cf. Sec. 5.1). The experiments were performed on a Intel(R)
Xeon(R) CPU E5-2695 v4 @ 2.10 GHz (in single core mode) running Ubuntu
20.04.2 and using OpenJDK 1.8.0 302. The results of the experiments are shown

132
M. Geitz et al.
Table 2. Empirical comparison of the results on various quantum, quantum inspired
and classical platforms. The quantum approaches processed for each problem the same
QUBO matrix. In parentheses the make-span before eliminating the gaps, when avail-
able. All times are time budgets, except for the CPU-based constraints based optimi-
sation (CBO) with firstCS, where they are measured durations.
Problem Method
Time Make-span
Set1
QC D-Wave Leap Hybrid v2 (5000 qubits)
2 min. 58 (62)
Quantum-inspired Fujitsu DAU (8192 sim qubits)
15 min. 59 (62)
CPU Tabu Search (single core)
20 min. 58 (63)
CPU-based CBO firstCS (single core)
34 sec. 58
Set2
QC D-Wave Leap Hybrid v2 (5000 qubits)
1 min. 57 (62)
CPU Tabu Search (32 cores)
120 min. 57
CPU-based CBO firstCS (single core)
2 sec. 57
Set3
QC D-Wave Leap Hybrid v2 (5000 qubits)
5 min. 59 (60)
CPU Tabu Search (32 cores)
60 min. 58
CPU-based CBO firstCS (single core)
57 sec. 58
Set4
QC D-Wave Leap Hybrid v2 (5000 qubits)
5 min. 53 (57)
CPU Tabu Search (single core)
10 sec. 48 (59)
CPU-based CBO firstCS (single core)
15 sec. 48
Set5
QC D-Wave Leap Hybrid v2 (5000 qubits)
5 min. 53 (58)
CPU Tabu Search (32 cores)
60 min. 48
CPU-based CBO firstCS (single core)
17 sec. 48
Set6
QC D-Wave Leap Hybrid v2 (5000 qubits)
60 min. 42 (58)
Quantum-inspired Fujitsu DAU (8192 sim. qubits)
15 min 43 (53)
CPU Tabu Search (32 cores)
120 min. 39
CPU-based CBO firstCS (single core)
134 sec. 39
Set7
QC D-Wave Leap Hybrid v2 (5000 qubits)
Failure: QUBO
(95403
too dense
qubits ) CPU-based CBO firstCS (single core)
21 min. 412
in Table 1. The ﬁrst column contains the problem identiﬁers, the second column
the problem sizes consisting of #machines x #jobs x #tasks x #AGVs.3 Col-
umn 3 shows whether the global diﬀerence constraints (GD) are used (+) or not
(−). Column 4 shows whether dichotomous (D) or monotonous (M) branch-and-
bound (B&B) was performed for minimizing the make-spans shown in columns 5
and 8. Optimal make-spans are in bold. Make-spans in italic are the best ones
found within one hour search. Columns 6 and 9 shows the runtimes to ﬁnd the
schedules with the presented make-spans. We made experiments based on the
modelling approach (columns 5–7) presented in Sect. 5.1 to deal with transition
3 The data is available at https://github.com/cgrozea/Data4ExtJSSAGV.

Extended Job Shop Scheduling with AGVs – Classical and Quantum
133
times between transportation tasks and based on the alternative algorithmic
approach presented in [24] (columns 8–10). Please note, that the algorithmic
approach is only applied to problems with one AGV, an extension for multiple
AGVs is not yet available. Columns 7 and 10 shows the total runtimes for prov-
ing the optimality of found best solutions, i.e., including time for the exhaustive
search for even better solutions.
The applied B&B optimization is based on diﬀerent kinds of problem-speciﬁc,
depth-ﬁrst search: For the rather small, single AGV problem instances (Set1–
Set5) the transport tasks on the AGV are sequentially ordered ﬁrst, then the
start times of all tasks are determined by successively splitting the domains of
the start time variables in “earlier” and “later” subsets starting with the smallest
domain. For problem instances with two AGVs (Set6 and Set8) the transport
tasks are assigned to the AGVs beforehand. For the larger problem instances
(Set7 and Set8) the ordering decisions on transport tasks on the AGVs during
search is omitted. Not any solution was found using algorithmic approach for
Set 7 within one hour, thus we presented for Set7 and Set8 only the make-spans
and runtimes for the modelling approach. Further, B&B optimization starts with
two trivial bounds of the make-span: the sum of all transport durations between
the machines divided by the number of AGVs as an initial lower bound and the
sum of all task durations plus the longest travel time between all machines as
an initial upper bound.
6.2
Experimental Results Using the Quantum Approach
We have run several experiments, their results are summarized in Table 2. Solving
each problem has been attempted on D-Wave Leap Hybrid v2 (which included
running subproblems on the D-Wave quantum annealer) and with Tabu search
(using the qbsolv library on CPU). For two of the problems we had temporarily
access to the quantum-inspired Fujitsu digital annealer as well. A special note
about the way we proceeded with the tabu search: we ﬁrst attempted to solve
the problem on a single core, when this did not produce good results we ﬁrst
increased the time limit, and when this failed to led to improvement we ran
multiple instances in parallel and kept the best run – in each case we report
the best result achieved. The problem Set7 leads to a QUBO matrix of 95403
qubits that is too dense for D-Wave Leap Hybrid v2 and requires too much RAM
to attempt to solve it with qbsolv. The problem Set8 is even larger, thus it was
not attempted with QUBO-based methods. We examined multiple solution plots
with the diﬀerent approaches. In the case of optimality, the solutions are very
similar, mostly they are only diﬀering in the start times/end time of the drives
that allow such variations.

134
M. Geitz et al.
Fig. 3. Set1 - A tabu search solution with make-span 63 containing gaps, e.g. at time
unit 11. It can be compacted to a solution wit make-span 58 (optimal) by simply elim-
inating the gaps. A color per workpiece, special machines 0=start, 5=target, 6=AGV.
Fig. 4. Comparison of the solution quality for the same running time budget. The
smooth versions were computed using the scipy function gaussian ﬁlter1d with σ = 2.
7
Discussion and Conclusion
An interesting behavior of all optimizers applied on the QUBO matrices (thus
not of the CP) is the presence of obviously unnecessary gaps in the produced
solutions. We have found out that by simply eliminating those gaps by doing
any action as soon as the prerequisites are fulﬁlled, one obtains clearly better
solutions, sometimes even the optimal ones. An example is given in Fig. 3.
Quantum solvers are capable of ﬁnding similar results to those produced by
the classical methods for small problem sizes. These solutions prove the QUBO
models working but currently there is limited beneﬁt for real life use cases.
We used a simple problem to test the scalability: a single machine, a single
AGV, two jobs, each with two tasks (durations: 0, 1), both to be executed on
the single machine. As we increase the required number of qubits and qubit
couplings by increasing the horizon, we observe a degrading of the quantum
results versus the classical results (Figure 4). The winner in this comparison is
the CP-based approach, which delivers constantly within 250 ms the optimum
make-span value.

Extended Job Shop Scheduling with AGVs – Classical and Quantum
135
To conclude, in this work we were able to model an extended JSSP using CP
and as QUBO that is automatically converted to Ising Hamiltonian for adiabatic
quantum computers or simulators. The model has been extended to incorporate
the transport of workpieces through multiple AGVs. The QUBO problems have
been minimized on several solvers, including Tabu Search, and adiabatic quan-
tum computers. As a contrast, the original problem (not converted to QUBO)
has been solved also with CP-based optimisation. The problem sizes that we are
currently able to address are below business relevance and can be executed on
classical computers with similar performance. It is uncertain right now, when
the quantum computers will bring advantages for practical decision or optimiza-
tion applications. Once that happens, it is likely that quantum computers will
replace classical computers, on specialized problems like optimization problems,
that have often exponential time complexity.
References
1. Artigues, C., Belmokhtar, S., Feillet, D.: A New Exact Solution Algorithm for the
Job Shop Problem with Sequence-Dependent Setup Times. In: R´egin, J.C., Rue-
her, M. (eds.) Integration of AI and OR Techniques in Constraint Programming for
Combinatorial Optimization Problems First International Conference, CPAIOR
2004, Nice, France, April 20–22, 2004. Proceedings. Lecture Notes in Computer
Science, vol. 3011, pp. 37–49. Springer-Verlag (2004). https://doi.org/10.1007/
978-3-540-24664-0 3, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.
460.8724&rep=rep1&type=pdf
2. Artigues, C., Feillet, D.: A branch and bound method for the job-shop problem
with sequence-dependent setup times. Ann. Oper. Res. 159(1), 135–159 (2008).
https://doi.org/10.1007/s10479-007-0283-0
3. Baptiste, P., le Pape, C., Nuijten, W.: Constraint-Based Scheduling: Applying
Constraint Programming to Scheduling Problems. No. 39 in international series in
operations research & management science. Kluwer Academic Publishers (2001)
4. Baptiste, P., Pape, C.L.: Edge-ﬁnding constraint propagation algorithms for dis-
junctive and cumulative scheduling. In: Proceedings 15th Workshop of the U.K.
Planning Special Interest Group (1996)
5. Bart´ak, R., ˇCepek, O.: Incremental propagation rules for a precedence graph with
optional activities and time windows. Transactions of the Institute of Measurement
and Control 32(1), 73–96 (2010). https://doi.org/10.1177/0142331208100099
6. Brucker, P. (ed.): Scheduling Algorithms. Springer, Berlin, Heidelberg (2007).
https://doi.org/10.1007/978-3-540-69516-5
7. Bundesministerium f¨ur Wirtschaft und Energie: Plattform und ¨Okosystem f¨ur
Quantenunterst¨utzte K¨unstliche Intelligenz. https://planqk.de
8. Chakraborty, S., Bhowmik, S.: Job shop scheduling using simulated annealing. In:
Proceedings of the First International Conference on Computation and Commu-
nication Advancement. pp. 69–73. McGrawHill Publication, JIS College of Engi-
neering, Kalyani, India, January 2013
9. D-Wave Systems Inc.: Introduction to quantum annealing. https://docs.dwavesys.
com/docs/latest/c gs 2.html. Accessed 4 May 2020
10. D-Wave Systems Inc.: Job shop scheduling. https://github.com/dwave-examples/
job-shop-scheduling. Accessed 4 May 2020

136
M. Geitz et al.
11. D-Wave Systems Inc.: Problem formulations: Ising and qubo. https://docs.
dwavesys.com/docs/latest/c gs 3.html. Accessed 4 May 2020
12. Feydy, T., Schutt, A., Stuckey, P.J.: Global diﬀerence constraint propagation for
ﬁnite domain solvers. In: Proceedings of the 10th International ACM SIGPLAN
Symposium on Principles and Practice of Declarative Programming - PPDP ’08. p.
226. ACM Press, Valencia, Spain (2008). DOI: https://doi.org/10.1145/1389449.
1389478
13. Feydy, T., Stuckey, P.J.: Lazy clause generation reengineered. In: Gent, I.P. (ed.)
CP 2009. LNCS, vol. 5732, pp. 352–366. Springer, Heidelberg (2009). https://doi.
org/10.1007/978-3-642-04244-7 29
14. Focacci, F., Laborie, P., Nuijten, W.: Solving scheduling problems with setup times
and alternative resources. In: Proceedings of the AIPS-2000, p. 10. AAAI (2000)
15. Goltz, H.-J.: Reducing domains for search in CLP(FD) and its application to job-
shop scheduling. In: Montanari, U., Rossi, F. (eds.) CP 1995. LNCS, vol. 976, pp.
549–562. Springer, Heidelberg (1995). https://doi.org/10.1007/3-540-60299-2 33
16. Hofstedt, P., Wolf, A.: Einf¨uhrung in die Constraint-Programmierung: Grundla-
gen, Methoden, Sprachen, Anwendungen. eXamen. press, Springer-Verlag, Berlin
Heidelberg (2007). https://doi.org/10.1007/978-3-540-68194-6
17. Lambrecht, J., Steﬀens, E.J., Geitz, M., Vick, A., Funk, E., Steigerwald, W.: Cog-
nitive edge for factory: a case study on campus networks enabling smart intralogis-
tics. In: 2019 24th IEEE International Conference on Emerging Technologies and
Factory Automation (ETFA). pp. 1325–1328, September 2019. https://doi.org/10.
1109/ETFA.2019.8869394
18. Lobe, E.: L¨osen von QUBO-Problemen auf einem Adiabatischen Quanten-
Annealer. GOR Workshop. 19 May 2017
19. Schutt, A., Feydy, T., Stuckey, P.J.: Explaining time-table-edge-ﬁnding propaga-
tion for the cumulative resource constraint. In: Gomes, C., Sellmann, M. (eds.)
CPAIOR 2013. LNCS, vol. 7874, pp. 234–250. Springer, Heidelberg (2013). https://
doi.org/10.1007/978-3-642-38171-3 16
20. Schutt, A., Feydy, T., Stuckey, P.J., Wallace, M.G.: Explaining the cumulative
propagator. Constraints 16(3), 250–282 (2011). https://doi.org/10.1007/s10601-
010-9103-2
21. Schutt, A., Feydy, T., Stuckey, P.J., Wallace, M.G.: Solving RCPSP/max by
lazy clause generation. J. Sched. 16(3), 273–289 (2013). https://doi.org/10.1007/
s10951-012-0285-x
22. Schutt, A., Stuckey, P.J.: Explaining producer/consumer constraints. In: Rueher,
M. (ed.) CP 2016. LNCS, vol. 9892, pp. 438–454. Springer, Cham (2016). https://
doi.org/10.1007/978-3-319-44953-1 28
23. Stuckey, P.J.: Lazy clause generation: combining the power of SAT and CP (and
MIP?) solving. In: Lodi, A., Milano, M., Toth, P. (eds.) CPAIOR 2010. LNCS,
vol. 6140, pp. 5–9. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-
642-13520-0 3
24. Van Cauwelaert, S., Dejemeppe, C., Schaus, P.: An eﬃcient ﬁltering algorithm
for the unary resource constraint with transition times and optional activities. J.
Sched. 23(4), 431–449 (2020). https://doi.org/10.1007/s10951-019-00632-8
25. Venturelli, D., Marchand, D.J.J., Rojo, G.: Quantum annealing implementation
of job-shop scheduling. October 2016. http://arxiv.org/abs/1506.08479, comment:
p. 15, 6 ﬁgure, Presented at Constraint Satisfaction Techniques for Planning and
Scheduling (COPLAS) Workshop of the 26th International Conference on Auto-
mated Planning and Scheduling (2016)

Extended Job Shop Scheduling with AGVs – Classical and Quantum
137
26. Vil´ım, P.: Batch processing with sequence dependent setup times: new results. In:
Proceedings of the 4th Workshop of Constraint Programming for Decision and
Control, CPDC’02, p. 6. Gliwice, Poland (2002)
27. Vil´ım, P.: O(nlogn) ﬁltering algorithms for unary resource constraint. In: R´egin,
J.-C., Rueher, M. (eds.) CPAIOR 2004. LNCS, vol. 3011, pp. 335–347. Springer,
Heidelberg (2004). https://doi.org/10.1007/978-3-540-24664-0 23
28. Vil´ım, P.: Batch processing with sequence dependent setup times. In: Van Henten-
ryck, P. (ed.) CP 2002. LNCS, vol. 2470, pp. 764–764. Springer, Heidelberg (2002).
https://doi.org/10.1007/3-540-46135-3 62
29. Vil´ım, P., Bart´ak, R., ˇCepek, O.: Unary resource constraint with optional activities.
In: Wallace, M. (ed.) CP 2004. LNCS, vol. 3258, pp. 62–76. Springer, Heidelberg
(2004). https://doi.org/10.1007/978-3-540-30201-8 8
30. Wittek, P.: Quantum Machine Learning: What Quantum Computing Means to
Data Mining. Elsevier, Amsterdam (2014)
31. Wolf, A.: Pruning while sweeping over task intervals. In: Rossi, F. (ed.) CP 2003.
LNCS, vol. 2833, pp. 739–753. Springer, Heidelberg (2003). https://doi.org/10.
1007/978-3-540-45193-8 50
32. Wolf, A.: Constraint-based task scheduling with sequence dependent setup times,
time windows and breaks. In: Fischer, S., Maehle, E., Reischuk, R. (eds.). In: Pro-
ceedings of the Informatik 2009: Im Focus Das Leben, Beitr¨age Der 39. Jahresta-
gung Der Gesellschaft F¨ur Informatik e.V. (GI), 28.9.-2.10.2009, L¨ubeck. Lecture
Notes in Informatics (LNI) - Proceedings Series of the Gesellschaft F¨ur Informatik
(GI), vol. 154, pp. 3205–3219. Gesellschaft f¨ur Informatik e.V. (2009)
33. Wolf, A.: ﬁrstCS—New Aspects on Combining Constraint Programming with
Object-Orientation in Java. KI - K¨unstliche Intelligenz 26(1), 55–60 (2012).
https://doi.org/10.1007/s13218-011-0161-4
34. Wolf, A., Schlenker, H.: Realising the alternative resources constraint. In: Seipel,
D., Hanus, M., Geske, U., Bartenstein, O. (eds.) INAP/WLP -2004. LNCS (LNAI),
vol. 3392, pp. 185–199. Springer, Heidelberg (2005). https://doi.org/10.1007/
11415763 12
35. Yamada T., N.R.: Job-shop scheduling by simulated annealing combined with
deterministic local search. In: Osman, I.H., Kelly, J.P. (eds.) Meta-Heuristics, pp.
237–248. Springer, Boston, MA (1996). https://doi.org/10.1007/978-1-4613-1361-
8 15
36. Zhang, R.: A simulated annealing-based heuristic algorithm for job shop scheduling
to minimize lateness. International Journal of Advanced Robotic Systems (2013).
https://doi.org/10.5772/55956

Stochastic Decision Diagrams
J. N. Hooker(B)
Carnegie Mellon University, Pittsburgh, USA
jh38@andrew.cmu.edu
Abstract. We introduce stochastic decision diagrams (SDDs) as a gen-
eralization of deterministic decision diagrams, which in recent years have
been used to solve a variety of discrete optimization and constraint sat-
isfaction problems. SDDs allow one to extend the relaxation techniques
of deterministic diagrams to stochastic dynamic programming problems
in which optimal controls are state-dependent. In particular, we develop
suﬃcient conditions under which node merger operations applied during
top-down compilation of the SDD yield a valid relaxed SDD whose size
can be limited as desired. The relaxed SDD provides bounds on the opti-
mal value that can be used to evaluate the quality of solutions obtained
heuristically or to accelerate the search for an optimal solution. This
results in a general and completely novel method for obtaining optimiza-
tion bounds for stochastic dynamic programming, and the only method
that can be applied to the original state space. We report computational
experience on stochastic maximum clique (equivalently, maximum inde-
pendent set) problem instances.
Keywords: stochastic decision diagrams · stochastic dynamic
programming · relaxed decision diagrams · maximum clique problem
1
Introduction
Decision diagrams have proved to be a useful tool for solving a variety of
discrete optimization and constraint programming problems [1,5,8,9,14,16–
20,23,28,31]. One of their distinctive features is that they are naturally suited
for dynamic programming (DP) formulations and provide an alternative to tra-
ditional state space enumeration as a means to solving them. They do so by
creating a novel framework for branch-and-bound search [8] and a discrete relax-
ation method for calculating bounds [7]. Yet many, if not most, useful DP models
are stochastic [29]. This suggests that it may be beneﬁcial to extend the concept
of a decision diagram to the stochastic case by introducing probabilities. Such
is the goal of the present paper.
Stochastic decision diagrams (SDDs) can represent a very general class of dis-
crete stochastic DP models with state-dependent transitions and controls. This
is because the state transition graph of the DP model can be interpreted as an
SDD. Despite this, the concept of an SDD is very diﬀerent from that of a state
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 138–154, 2022.
https://doi.org/10.1007/978-3-031-08011-1_11

Stochastic Decision Diagrams
139
transition graph, partly because the nodes of the SDD need not correspond to
states. In addition, a DP model can sometimes be radically simpliﬁed by recon-
ceiving the transition graph as a decision diagram (without state information)
and applying well-known reduction techniques to the diagram [24]. Perhaps more
importantly, an SDD-based perspective opens the door to relaxation techniques
that have been developed for decision diagrams, such as node merger and node
splitting. Decision-diagram-based relaxation is attractive in that it does not pre-
suppose linearity or convexity, and it allows one to obtain bounds of any desired
quality by controlling the size of the relaxed diagram. It has already been widely
applied to deterministic models, as recounted in [9].
We therefore focus on how to build relaxed SDDs, using node merger in
particular. We develop suﬃcient conditions under which nodes can be merged
during top-down compilation of an SDD so as to yield a valid relaxed SDD.
The relaxed SDD can then provide bounds on the optimal value of the original
problem. A complicating element of this analysis is that an optimal solution of a
stochastic DP is not simply an assignment of values to variables, but a policy for
selecting an optimal control in any state one happens to reach. Nonetheless, the
analysis yields a general and completely novel method for bounding stochastic
dynamic programming models. Such bounds are essential for judging the quality
of a heuristic solution, and they can be very helpful for accelerating the search
for an exact solution by excluding unpromising regions of the search space.
We assess the quality of SDD-based bounds experimentally using a stochastic
version of the maximum clique problem, which is equivalent to the maximum
independent set (maximum stable set) problem deﬁned on the complementary
graph. We select this problem because decision diagrams have already been eval-
uated as a bounding mechanism for the deterministic case, using the well-known
DIMACS instance set [7]. It was found that decision diagrams supply tighter
bounds, in less time, than the full cutting plane resources of a commercial inte-
ger programming solver. This suggests that bounds from an SDD may likewise
be useful for the stochastic case, even while they cannot be directly compared
with an integer programming model because no such practical model exists. As a
test bed, we use a variety of random and DIMACS instances. We ﬁnd that SDD-
based bounds degrade rather modestly as one reduces the size of the relaxed
SDD and consequently the time invested in building it, even when the time is
reduced to a few seconds. These results suggest that SDDs can provide useful
bounds of continuously adjustable quality.
2
Related Work
Decision diagrams were introduced as an optimization method in [21,22]. The
idea of a relaxed diagram ﬁrst appears in [1] as a technique for enhancing prop-
agation in constraint programming, by means of both node splitting and node
merger. Relaxed diagrams were ﬁrst used to obtain optimization bounds in [7,10],
and much subsequent work is described in [9]. Suﬃcient conditions under which
node merger creates a relaxed diagram are presented in [25]. They are simpler

140
J. N. Hooker
than the conditions developed below for SDDs because there is no need to accom-
modate solutions in the form of policies. Relaxed decision diagrams are combined
with Lagrangian methods in [6,14,26].
Dynamic programming, both deterministic and stochastic, is credited to Bell-
man [3,4]. Various DP techniques are described in [12,13]. Due to the astronomi-
cal size of state spaces often encountered in stochastic DP, practitioners generally
resort to approximate DP, which estimates the cost-to-go, rather than attempt-
ing to establish valid bounds [12,29]. Connections between decision diagrams
and deterministic DP, including nonserial DP [11], are discussed in [24].
When DP bounds are desired, they are traditionally obtained by state space
relaxation, which approximates the original state space with a smaller, computa-
tionally feasible space [2,15,27,30]. It diﬀers in fundamental ways from relaxation
based on decision diagrams. A relaxed decision diagram uses the same variables
and state space as the original problem, rather than mapping the problem into
a smaller space. This allows the relaxed diagram to provide a branching frame-
work for an exact branch-and-bound method [8]. Furthermore, the relaxation is
constructed dynamically during compilation rather than speciﬁed a priori and is
thereby potentially more sensitive to problem structure. It can be tightened by
ﬁltering techniques and Lagrangian methods. Finally, the relaxed diagram can
be sized to provide a bound of any desired quality.
3
Stochastic Decision Diagrams
A decision diagram can be deﬁned as a directed, acyclic multigraph in which the
nodes are partitioned into layers. Each arc of the graph is directed from a node
in layer i to a node in layer i + 1 for some i ∈{1, . . . , n}. We let Li represent
the set of nodes in layer i. Layers 1 and n + 1 contain a single node, namely the
root r and the terminus t, respectively. Each layer i is associated with a variable
xi with ﬁnite domain Xi. The arcs leaving any node in layer i have labels in Xi,
representing possible values of xi (controls) at that node.
Conventional decision diagrams are deterministic, meaning that the control
at a given node determines a transition to particular node on the next layer. A
path from r to t deﬁnes a sequence of controls x = (x1, . . . , xn) as indicated by
the arc labels on the path. A decision diagram is weighted if there is a length
(cost) associated with each arc.
Any discrete optimization problem of the form minx∈X {n
i=1 ci(xi)} with
ﬁnite-domain variables x1, . . . , xn and feasible set X can be represented by a
weighted decision diagram.1 The diagram is constructed so that its r–t paths
correspond to feasible solutions x ∈X, and the length of any r–t path is the
cost of the corresponding solution. The optimal value of the problem is the length
of a shortest r–t path.
A stochastic decision diagram (SDD) associates probabilities as well as labels
and costs with the arcs. An SDD is signiﬁcantly diﬀerent from a deterministic
diagram in that a given control xi at a node u does not, in general, determine
1 Decision diagrams can also represent problems with nonseparable cost functions c(x)
as described in [24]. However, this generalization is not relevant here.

Stochastic Decision Diagrams
141
Fig. 1. Graph for a small maximum clique problem.
Fig. 2. SDD for a small stochastic maximum clique problem. Transition probabilities
less than 1 are shown on the arcs. Zero-cost solid arcs from layer 4 to the terminus are
not shown. States and maximum expected costs-to-go are indicated at nodes.
a transition to a particular node in the next layer. Rather, control xi can lead
to any of several possible outcomes ω, each with a probability piω(u, xi) and
cost ciω(u, xi). We suppose, without loss of generality, that the same set Ωi of
outcomes is available at each node in layer i, although many of the outcomes
may have probability zero. Each outcome ω at node u with positive probability
gives rise to an arc (u, u′) that leads to a node u′ = φiω(u, xi).
Due to the probabilistic nature of transitions, a sequence of controls x =
(x1, . . . , xn) does not correspond to a single r–t path. Furthermore, the control
exercised in layer i may depend on which node is reached in that layer. We
therefore deﬁne a policy π rather than a vector x of controls for SDDs, where
πi(u) is the speciﬁed control at node u ∈Li. The policy is feasible if πi(u) ∈Xi(u)
for all u ∈Li and all i, where Xi(u) is the set of permissible controls at node u.

142
J. N. Hooker
As an example, consider a stochastic maximum clique problem associated
with the graph of Fig. 1. Each edge of the graph appears with probability 0.6.
The objective is to ﬁnd a clique of maximum expected size, without knowing
in advance which edges are present. The problem is represented by the SDD
in Fig. 2. There are two controls xi in each layer i, with xi = 1 indicating a
decision to include vertex i in the clique (solid arcs), and xi = 0 a decision
to exclude vertex i (dashed arcs). There are two solid arcs leaving most nodes,
because there are two possible outcomes when xi = 1: vertex i can be added to
the clique (ω = 1), or it cannot be added (ω = 0). The former occurs when all
the edges from vertex i to vertices currently in the clique exist. This outcome
has probability 0.6m, where m is the size of the clique, while outcome ω = 0 has
probability 1−0.6m. The resulting probabilities are indicated next to the arcs in
Fig. 2 when they are less than 1. For readability, zero-cost solid arcs from layer
4 to the terminus (those corresponding to ω = 0) are not shown in the ﬁgure.
Arc costs are also indicated in Fig. 2, where arcs with cost 1 correspond to
outcome ω = 1 and those with cost 0 to outcome ω = 0. We seek a policy
that maximizes expected cost; i.e., maximizes the expected size of the resulting
clique. A policy π consists of a decision πi(u) at each node u ∈Li as to whether
vertex i should included in the clique. Thus one can consider the outcome of
previous controls when deciding whether to include a given vertex.
The expected cost c(D, π) of a policy π on a stochastic diagram D can be
computed with the recursion
hi(u, π) =

ω∈Ωi
piω

u, πi(u)

ciω

u, πi(u)

+ hi+1

φiω(u, πi(u)), π

for i = n, n −1, . . . , 1, where hn+1(t, π) = 0 and c(D, π) = h1(r, π). A policy
π∗is optimal if it minimizes c(D, π) over all feasible policies π. The minimum
expected cost can be computed with the recursion
hi(u) =
min
xi∈Xi(u)
 
ω∈Ωi
piω(u, xi)

ciω(u, xi) + hi+1

φiω(u, xi)
	
(1)
for i = n, n −1, . . . , 1, where hn+1(t) = 0. Here, hi(u) is the optimal expected
cost-to-go at node u in layer i. The overall optimal cost is c(D) = h1(r). An
optimal policy π∗is obtained by setting π∗
i (u) to an optimizing value of xi in
(1) for each i and each u ∈Li.
Optimal expected costs-to-go for the example are shown at the nodes in
Fig. 2 (along with the corresponding states, to be discussed in the next section).
They are computed by maximizing rather than minimizing in (1), since we seek
a maximum clique. The maximum expected cost for this problem instance is
2.056. This means that if an optimal choice is made at every node, the resulting
clique will have size 2.056 on the average. Note that at the root node, either
choice is optimal. At both nodes in layer 2, the optimal choice is to add vertex
2, and so forth.

Stochastic Decision Diagrams
143
4
Stochastic Dynamic Programming
Stochastic decision diagrams can represent a very general class of stochastic
dynamic programming (DP) problems in which costs, probabilities and controls
are state-dependent. Let piω(Si, xi) be the probability of outcome ω ∈Ωi in
state Si under control xi, and ciω(Si, xi) the cost of that outcome.2 Outcome ω
eﬀects a transition from state Si to state φiω(Si, xi). A solution of the problem
is a policy π = (π1, . . . πn) that maps each possible state Si to a control πi(Si).
A policy π is feasible if πi(Si) is an available control for every state Si; that is,
πi(Si) ∈Xi(Si). The expected cost of policy π is h1(S1, π), where
hi(Si, π) =

ω∈Ωi
piω

Si, πi(Si)

ciω

Si, πi(Si)

+hi+1

φiω(Si, πi(Si)), π

(2)
for i = n, n−1, . . . , 1. There is a single initial state S1 and a single terminal state
Sn+1, with hn+1(Sn+1, π) = 0. We refer to hi(Si, π) as the expected cost-to-go
of state Si under policy π. A policy π∗is optimal if it minimizes h1(S1, π) over
all feasible policies π. An optimal solution can be found with the recursion
hi(Si) =
min
xi∈Xi(Si)
 
ω∈Ωi
piω(Si, xi)

ciω(Si, xi) + hi+1

φiω(Si, xi)
	
(3)
with hn+1(Sn+1) = 0 and h1(S1) equal to the optimal expected cost. An optimal
policy can be obtained by setting πi(Si) to an optimizing value of xi in (3) for
each state Si.
An SDD corresponding to model (3) contains a node in layer i for every state
Si that can be reached with positive probability under some policy. We let Si(u)
refer to the state associated with node u ∈Li. For each node u ∈Li and each
control xi ∈X(Si(u)), there is an outgoing arc to a node associated with state
φiω(Si(u), xi) for every outcome ω with positive probability in state Si. Each
of these arcs has label xi, probability piω(Si, xi), and cost ciω(Si, xi). Several
arcs may connect the same two nodes, but they must have diﬀerent labels. An
optimal policy can be computed in the SDD using (1).
In the DP model (3) for the stochastic maximum clique problem, the min
operator is max, and each state Si is the set Si of vertices currently in the
clique. The state corresponding to each node of the SDD is shown in Fig. 2. The
transitions and probabilities are as follows:
piω(Si, xi) =
⎧
⎨
⎩
pi(Si),
if (xi, ω) = (1, 1)
1 −pi(Si), if (xi, ω) = (1, 0)
ω,
if xi = 0
(4)
φiω(Si, xi) =

Si ∪{i}, if (xi, ω) = (1, 1)
Si,
if ω = 0
(5)
ciω(Si, xi) = ω for xi = 0, 1 and all Si
(6)
where pi(Si) = 
j∈Si pij and pij is the probability of edge (i, j).
2 Following convention in the DP literature, the subscript i in Si does not index the
state but indicates that control xi is applied in state Si.

144
J. N. Hooker
As a second example, we consider a stochastic job sequencing problem with
time windows. Each job j has release time rj and due date dj. Its processing
time is a random variable, and each possible processing time tjω corresponds to
an outcome ω ∈Ωi. The set Ωi can in principle be inﬁnite, but for the purpose
of building an SDD, we suppose it is ﬁnite. We also suppose that the outcome
probabilities are state-independent, so that the probability of a processing time
tjω is pjω regardless of which jobs have been scheduled so far. The objective is
to minimize total tardiness, where the tardiness of a job j that starts at time sj
is (sj +tjω −dj)+, and where we use the notation α+ for max{0, α}. The control
xi in stage i is which job will be ith in the sequence.
In the DP model (3) for the problem, each state Si is a tuple (Si, fi), where
Si is the set of jobs scheduled so far, and fi is the ﬁnish time of the last job
scheduled. The recursion is deﬁned by
piω

(Si, fi), xi

= pxiω
(7)
φiω

(Si, fi), xi

=

Si ∪{xi}, max{rxi, fi} + txiω

(8)
ciω

(Si, fi), xi

=

max{rxi, fi} + txiω −dxi
+
(9)
The nodes of the an SDD representing the problem correspond to the states
(Si, fi). Each arc with label xi leaving state (Si, fi) is generated by an outcome
ω with positive probability piiω and has cost ciω((Si, fi), xi).
5
Relaxed SDDs
In the deterministic case, a decision diagram ¯D relaxes a diagram D when every
r–t path of D occurs in ¯D with equal or smaller cost. Since policies rather
than paths represent solutions in the stochastic case, it is convenient to deﬁne
a relaxed SDD in terms of its optimal expected cost, rather than the cost of
individual paths. This, of course, ensures that a relaxed SDD provides a valid
bound on the optimal value of the original SDD. Thus, if two diagrams D and ¯D
have the same number of layers, and the same possible controls and outcomes,
then ¯D relaxes D if the minimum expected cost c(D) of D is at least the minimum
expected cost c( ¯D) of ¯D.
Under suitable conditions, a relaxed SDD can be obtained by node merger
during top-down compilation, as in the deterministic case. That is, when a given
layer i is created from the previous layer, some of the nodes in layer i are merged,
so as to reduce the size of the diagram. A larger number of mergers yield a
smaller diagram but, in general, a weaker relaxation. When two nodes u, u′ ∈Li
are merged, the state associated with the resulting node is obtained by applying
a merger operation Si(u)⊕Si(u′) to the states associated with the merged nodes.
Layer i + 1 is then created on the basis of the resulting states in layer i.
In the maximum clique problem, we can use the merger operation Si ⊕S′
i =
Si ∩S′
i. We will see in the next section that this yields a valid relaxed SDD.
Figure 3 displays the relaxed SDD that results from merging two particular nodes
in the maximum clique SDD of Fig. 2, namely the nodes in layer 3 with states

Stochastic Decision Diagrams
145
Fig. 3. Relaxed SDD that results from the merger of two nodes in the SDD of Fig 2.
{2} and {1, 2}. The maximum expected cost of the relaxed SDD is 2.4736, which
is an upper bound on the optimal expected cost of 2.056 of the original problem.
In the job sequencing problem, we can use the merger operation
(Si, fi) ⊕(S′
i, f ′
i) =

Si ∩S′
i, min{fi, f ′
i}

(10)
We likewise show in the next section that this creates a valid relaxed SDD.
6
Conditions for Node Merger
We now develop suﬃcient conditions under which a merger operation yields a
relaxed SDD. We again suppose that a concept of relaxation is deﬁned for states.
We assume that relaxation has the property that state ¯Si relaxes state Si only
if
piω(Si, xi)ciω(Si, xi) ≥piω( ¯Si, xi)ciω( ¯Si, xi)
(11)
for any control xi ∈Xi and any outcome ω ∈Ωi, and for i = 1, . . . , n. Let the
expected immediate cost of a state Si under control xi be
ci(Si, xi) =

ω∈Ωi
piω(Si, xi)ciω(Si, xi)
Thus, we have from (11)

146
J. N. Hooker
Lemma 1. Relaxing a state does not increase its expected immediate cost.
We will show that node merger yields a valid relaxed SDD if the merger
operation ⊕and transition function φ satisfy the following conditions for i =
1, . . . , n:
(C1) For any two states Si and S′
i, state Si ⊕S′
i relaxes both Si and S′
i.
(C2) If state ¯Si relaxes state Si, then φiω( ¯Si, xi) relaxes φiω(Si, xi) for any
ω ∈Ωi and any xi ∈Xi.
(C3) If state ¯Si relaxes state Si, then given any control xi ∈Xi and any set of
{ηω | ω ∈Ωi} of numbers, there is a control ¯xi ∈Xi such that

ω∈Ωi
piω(Si, xi)

ciω(Si, xi) + ηω

≥

ω∈Ωi
piω( ¯Si, ¯xi)

ciω( ¯Si, ¯xi) + ηω

(12)
The argument to follow is simpliﬁed if we suppose, without loss of generality,
that a given diagram and its relaxation are fully articulated. This means that the
diagrams contain nodes representing all possible states, even those that cannot
be reached with positive probability. This device will allow us to merge nodes
by changing only the arc probabilities, with no change in the structure of the
diagram. Thus each layer Li+1 of a fully articulated diagram contains all states
Si+1 such that Si+1 = φiω(Si(u), xi) for some node u ∈Li, outcome ω ∈Ωi,
and control xi ∈Xi, even if the probability piω(Si, xi) of reaching Si+1 from u
is zero for all ω, xi.
When two nodes u, u′ ∈Li+1 are merged to form node ˆu, we leave all nodes
in place but change only the probabilities on arcs from nodes in layer Li to u,
u′, and ˆu. That is, we transfer the probability on any arc (v, u) to an arc (v, ˆu)
with the same label, and similarly for any arc (v, u′). Thus, if u = φiω(v, xi) and
ˆu = φiˆω(v, xi), we set piˆω(v, xi) = piω(v, xi) and then set piω(v, xi) to zero, and
similarly for any arc (v, u′). The following lemma is key.
Lemma 2. If conditions (C2) and (C3) are satisﬁed, and state ¯Sk relaxes state
Sk, then the optimal cost to go of Sk is at least the optimal cost to go of ¯Sk.
Proof. It suﬃces to show by induction that
hi(Si) ≥hi( ¯Si)
(13)
for i = n, n−1, . . . , k. Claim (13) is true for i = n by virtue of Lemma 1, because
hn(Sn, xn) = cn(Sn, xn) for any control xn ∈Xn. We now suppose (13) is true
for i+1 and show it is true for i. It suﬃces to show that for any control xi ∈Xi,
there is a control ¯xi ∈Xi for which

ω∈Ωi
piω(Si, xi)

cij(Si, xi) + hi+1(φiω(Si, xi))

≥

ω∈Ωi
piω( ¯Si, ¯xi)

ciω( ¯Si, ¯xi) + hi+1(φiω( ¯Si, ¯xi))

(14)
We have from condition (C2) that φiω( ¯Si, ¯xi) relaxes φiω(Si, xi) for all ω ∈Ωi.
This and the induction hypothesis imply hi+1(φiω(Si, xi)) ≥hi+1(φiω( ¯Si, ¯xi))
for ω ∈Ωi. Thus to show (14) it suﬃces to show

Stochastic Decision Diagrams
147

ω∈Ωi
piω(Si, xi)

ciω(Si, xi) + hi+1(φiω(Si, xi))

≥

ω∈Ωi
piω( ¯Si, ¯xi)

ciω( ¯Si, ¯xi) + hi+1(φiω(Si, xi))

(15)
But (15) follows from condition (C3) by setting ηω = hi+1(φiω(Si, xi)) for each
ω ∈Ωi.
□
Theorem 1. If conditions (C1)–(C3) are satisﬁed, the merger of nodes during
compilation of diagram D results in a relaxation of D.
Proof. Suppose without loss of generality that D is fully articulated, and let ¯D
be the fully articulated diagram that results from top-down compilation with
node merger. Also let ¯Dk be the compiled diagram that results when nodes are
merged only in levels 1, . . . , k. It suﬃces to show the following inductively for
k = 1, . . . , n:
c(D) ≥c( ¯Dk)
(16)
This is trivially true for k = 1 because D1 = ¯D1. We therefore suppose (16)
is true for k and show it is true for k + 1. Due to the induction hypothesis, it
suﬃces to show
c( ¯Dk) ≥c( ¯Dk+1)
(17)
Let πk be an optimal policy for ¯Dk, so that c( ¯Dk) = h1(S1, πk). We will suppose
that only two nodes u, u′ in layer k+1 of ¯Dk are merged to obtain a node ˆu, since
the argument can be repeated for additional mergers. The merger transfers the
transition probabilities on arcs to nodes u and u′ to the arcs to ˆu. In addition,
by condition (C1), state Sk+1(ˆu) is a relaxation of both Sk+1(u) and Sk+1(u′).
Thus, by Lemma 2, the optimal cost to go at ˆu is no larger than the optimal
cost to go at u and u′. That is,
hk+1

Sk+1(ˆu)

≤hk+1

Sk+1(u)

hk+1(Sk+1

ˆu)

≤hk+1

Sk+1(u′)

(18)
Now due to (18) and the redistribution of transition probabilities into level k +1
of ¯Dk+1, the cost-to-go hk(v, πk) at any node v in layer k under policy πk is no
less in ¯Dk than in ¯Dk+1. This means that the optimal cost h( ¯Dk) of ¯Dk is no
less than the expected cost h1(S1, π) of ¯Dk+1 under policy πk, and is therefore
no less than the optimal cost of ¯Dk+1. This establishes (17), as desired.
□
We can now verify that the merger operations used earlier in the maximum
claim and job sequencing problems yield valid relaxed SDDs.
Corollary 1. The merger operation Si ⊕S′
i = Si ∩S′
i results in a relaxed SDD
for the maximum clique problem.
Proof. In this problem, a state Si is the set Si of vertices already selected. We
will say that ¯Si relaxes Si when ¯Si ⊆Si. We ﬁrst observe that the deﬁnitional

148
J. N. Hooker
requirement (11) for a relaxation is satisﬁed, by substituting the values given in
(4)–(6) into (11) for the four cases (xi, ω) = (1, 1), (1, 0), (0.1), (0.0).
Now, due to Theorem 1, it suﬃces to show that conditions (C1)–(C3) are
satisﬁed. Condition (C1) is obviously satisﬁed, since Si∩S′
i ⊆Si and Si∩S′
i ⊆S′
i.
To show (C2), we suppose that ¯Si ⊆¯Si. Then φi0( ¯Si) = ¯Si ⊆Si = φi0(Si) and
φi1( ¯Si) = ¯Si∪{i} ⊆Si∪{i} = φi1(Si). Thus, φiω( ¯Si) relaxes φiω(Si) for ω = 0, 1.
We now show (C3) with the sense of the inequality reversed, since we are
maximizing rather than minimizing. We note that

ω∈Ωi
piω(Si, xi)

ciω(Si, xi) + ηω

=
η0,
if xi = 0

1 −pi(Si)

η0 + pi(Si)(1 + η1), if xi = 1

ω∈Ωi
piω( ¯Si, ¯xi)

ciω( ¯Si, ¯xi) + ηj

=
η0,
if ¯xi = 0

1 −pi( ¯Si)

η0 + pi( ¯Si)(1 + η1), if ¯xi = 1
If xi = 0, we select the control ¯xi = 0, and (12) becomes η0 ≥η0, which
is obviously satisﬁed. If xi = 1, we consider two cases. We ﬁrst suppose that
η0 ≥1 + η1, in which case we select ¯xi = 0. Then (12) becomes

1 −pi(Si)

η0 + pi(Si)(1 + η1) ≤η0
which simpliﬁes to η0 ≤1 + η1 or η0 ≤η0, and (12) is therefore satisﬁed. We
now suppose η0 < 1 + η1, in which case we select ¯xi = 1. Then (12) becomes

1 −pi(Si)

η0 + pi(Si)(1 + η1) ≤

1 −pi( ¯Si)

η0 + pi( ¯Si)(1 + η1)
Since pi( ¯Si) ≥pi(Si), this simpliﬁes to η0 ≤1 + η1 or 0 ≤0, and (12) is again
satisﬁed.
□
The conditions for a valid relaxation simplify when transition probabilities
are state-independent. In this case, it suﬃces to satisfy (C1) and (C2).
Corollary 2. If conditions (C1) and (C2) are satisﬁed, and transition probabil-
ities are state independent, then merger of nodes during compilation results in a
relaxed SDD.
Proof. Due to Theorem 1, it suﬃces to show that condition (C3) is satisﬁed as
well as (C1) and (C2). In fact, we can show that for any control xi ∈Xi and any
set {ηω | ω ∈Ωi}, (12) holds for ¯xi = xi. Since transition probabilities are state
independent, we have piω(Si, xi) = piω( ¯Si, xi), and (12) becomes

ω∈Ωi
piω(Si, xi)ciω(Si, xi) + piω(Si, xi)ηω ≥

ω∈Ωi
piω( ¯Si, xi)ciω( ¯Si, xi) + piω(Si, xi)ηω
This follows immediately from (11), and (C3) is therefore satisﬁed.
□
Corollary 3. The merger operation (10) results in a relaxed SDD for the
stochastic job sequencing problem.

Stochastic Decision Diagrams
149
Proof. In this problem, we say that a state ( ¯Si, ¯fi) relaxes a state (Si, fi) when
¯Si ⊆Si and ¯fi ≤fi. To show that this relaxation satisﬁes (11), it suﬃces to
show
ciω

(Si, fi), xi

≥ciω

( ¯Si, ¯fi), xi

for any xi and ω, because the transition probabilities are state-independent. But
due to (9), this becomes

max{rxi, fi} + txiω −dxi
+ ≥

max{rxi, ¯fi} + txiω −dxi
+
which holds because fi ≥¯fi. Conditions (C1) and (C2) can be checked in a
similar manner, and the claim follows due to Corollary 2.
□
7
Computational Evaluation
The primary challenge in computational evaluation of SDD bounds is ﬁnding
nontrivial instances that can be solved to optimality, so that the tightness of
bounds can be assessed. Unfortunately, the DIMACS instances of the maximum
clique problem are much harder to solve as a stochastic problem, and nearly
all are intractable. We were able to solve only ﬁve instances, three of which are
too trivial for evaluation of bounds, and one of which ran for almost 24 h. We
therefore generated a number of random instances that are calibrated in size to be
both tractable and nontrivial. Since state-space enumeration is the only currently
available method for optimal solution, we solved the instances to optimality by
generating an exact SDD, which is essentially state-space enumeration with an
intelligent variable ordering heuristic. We performed tests on both random and
DIMACS instances, the latter mostly without comparison with optimal values.
We generated graphs for random instances by selecting each possible edge
with a speciﬁed probability (which determines the average density of the result-
ing graphs). We then randomized the graphs by assigning each edge (i, j) prob-
ability pij = 0.5 + 17ij mod(50)/100. Thus, all probabilities were drawn from
the interval [0.5, 1]. Probabilities were assigned to edges in DIMACS instances
in the same manner.
The size of the relaxed SDDs is controlled by placing an upper bound on
the width (the maximum number of node in a layer). The SDDs are compiled
using the same heuristics as in [7]. In particular, the least attractive nodes on a
given layer are merged until the desired width is obtained, where attractiveness
is measured by the length of the longest path from the root in the deterministic
problem. The rationale for this is that unattractive nodes are less likely to be part
of an optimal solution and can therefore be merged without aﬀecting the value of
that solution. We do not check whether the state resulting from a merger already
occurs at a node in the layer, because such a check is quite time consuming,
although this can result in slightly weaker bounds.
Figure 4 displays the results for the random instances. Each plot shows the
bounds that result from three random instances of diﬀerent sizes. The bounds are
plotted against the time invested in compiling relaxed SDDs of various widths

150
J. N. Hooker
Table 1. DIMACS Instances Tested
Instance
Vertices
Density
Instance
Vertices
Density
brock200 1
200
0.7417
hamming6-2
64
0.8906
cfat200-1
200
0.0767
johnson8-4-4
70
0.7571
cfat500-1
500
0.0357
keller4
171
0.6453
c125.9
125
0.8913
p hat300-1
300
0.2430
DSJC500 5
500
0.5010
san200 0.7 1
200
0.6965
gen200 p0.9 44
200
0.8955
sanr 0.7
200
0.6934
Fig. 4. Bound vs. time investment for random maximum clique instances. The smallest
(rightmost) bound shown for each instance is the optimal value.

Stochastic Decision Diagrams
151
Fig. 5. Bound vs. time investment for two DIMACS instances solved to optimality.
Fig. 6. Bound vs. time investment for various DIMACS instances, none of which are
solved to optimality.
and computing the optimal expected clique size for each. Each point results from
setting the maximum width to a certain value. The bound is plotted against
the resulting computation time rather than the max width, because this better
indicates the cost of obtaining the bound.3 Nearly all of the computational cost
is incurred by generating and merging nodes. The right-most data point for each
instance represents an optimal solution. The plots indicate that the quality of
the bound degrades rather modestly as the time investment ranges over about
three orders of magnitude. The relationship is not entirely monotone, as would
3 Detailed computational results, including speciﬁed max widths, are posted at pub-
lic.tepper.cmu.edu/jnh/CPAIOR2022data.pdf.

152
J. N. Hooker
be expected because the quality of the bound depends on the chance eﬀects of
the merger heuristic.
Tables 1 lists the DIMACS instances tested. Figure 5 shows bound-vs.-time
plots for the two nontrivial DIMACS instances solved to optimality. The bound
degradation is again gradual, and it is almost the same over a comparable time
span for the large, diﬃcult instance as for the small, easy instance. Figure 6
contains plots for various additional DIMACS instances, none of which could be
solved to optimality. With one exception, they show a similar pattern of gradual
and roughly logarithmic bound improvement as the time investment increases.
8
Conclusion
We introduced a concept of stochastic decision diagrams (SDDs) and showed how
they can represent discrete stochastic dynamic programming (DP) problems.
In particular, we indicated how state-dependent policies can be understood in
a decision diagram context. Due to the diﬃculty and importance of deriving
valid bounds for DP models, we focused on extending relaxation technology
that has been developed for deterministic decision diagrams to the stochastic
case, so that these bounds can be available for DP applications. We established
suﬃcient conditions under which a node merger operation applied during top-
down compilation yields valid relaxed SDDs. These provide optimization bounds
whose quality can be adjusted at will by controlling the size of the relaxed SDD.
As corollaries, we showed that simple node merger rules for stochastic maximum
clique and job sequencing problems satisfy these conditions.
To test the performance of SDD bounding in practice, we computed bounds
for random and benchmark instances of the stochastic maximum clique prob-
lem. We found that the bound quality degrades only gradually as the SDD size
(and the time investment) is reduced. The time-quality relationship is roughly
logarithmic in most cases, which allows one to estimate how much the bound
would improve with further time investment after computing bounds for a few
sample SDD widths.
A number of research directions can be pursued at this point, but two are
particularly interesting. One is to extend to stochastic diagrams the decision-
diagram-based branch-and-bound procedure introduced in [8]. This would pro-
vide a novel alternative to traditional state-space enumeration as an exact solu-
tion method for stochastic DP problems of moderate size.
A second direction is to investigate SDD-derived bounds on costs-to-go in
approximate stochastic DP. The cost-to-go at any state in any stage of the DP
recursion can be bounded by building an SDD that begins with that state at
its root node. The solution of the DP problem would still be calculated on the
basis of estimated costs-to-go, as in traditional approximate DP. Then one would
compute the expected cost of this same policy using SDD-based bounds on the
cost-to-go rather than estimates of the cost-to-go. This would provide a bound
on the quality of the policy obtained by approximate DP.

Stochastic Decision Diagrams
153
References
1. Andersen, H.R., Hadzic, T., Hooker, J.N., Tiedemann, P.: A constraint store based
on multivalued decision diagrams. In: Bessi`ere, C. (ed.) CP 2007. LNCS, vol.
4741, pp. 118–132. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-
540-74970-7 11
2. Baldacci, R., Mingozzi, A., Roberti, R.: New state-space relaxations for solving
the traveling salesman problem with time windows. INFORMS J. Comput. 24(3),
356–371 (2012)
3. Bellman, R.: The theory of dynamic programming. Bull. Am. Math. Soc. 60, 503–
516 (1954)
4. Bellman, R.: Dynamic Programming. Priceton University Press, Princeton, NJ
(1957)
5. Bergman, D., Cir´e, A.A.: Discrete nonlinear optimization by state-space decompo-
sitions. Manag. Sci. 64, 4700–4720 (2018)
6. Bergman, D., Cire, A.A., van Hoeve, W.-J.: Improved constraint propagation via
lagrangian decomposition. In: Pesant, G. (ed.) CP 2015. LNCS, vol. 9255, pp.
30–38. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-23219-5 3
7. Bergman, D., Cir´e, A.A., van Hoeve, W.J., Hooker, J.N.: Optimization bounds
from binary decision diagrams. INFORMS J. Comput. 26, 253–268 (2013)
8. Bergman, D., Cir´e, A.A., van Hoeve, W.J., Hooker, J.N.: Discrete optimization
with binary decision diagrams. INFORMS J. Comput. 28, 47–66 (2014)
9. Bergman, D., Cire, A.A., van Hoeve, W.-J., Hooker, J.: MDD-based constraint pro-
gramming. In: Decision Diagrams for Optimization. AIFTA, pp. 157–181. Springer,
Cham (2016). https://doi.org/10.1007/978-3-319-42849-9 9
10. Bergman, D., van Hoeve, W.-J., Hooker, J.N.: Manipulating MDD relaxations for
combinatorial optimization. In: Achterberg, T., Beck, J.C. (eds.) CPAIOR 2011.
LNCS, vol. 6697, pp. 20–35. Springer, Heidelberg (2011). https://doi.org/10.1007/
978-3-642-21311-3 5
11. Bertele, U., Brioschi, F.: Nonserial Dynamic Programming. Academic Press, New
York (1972)
12. Bertsekas, D.P.: Dynamic programming and optimal control: approximate dynamic
programming, vol. 2, 4th edn. Athena Scientiﬁc, Nashua, NH (2012)
13. Bertsekas, D.P.: Dynamic Programming and Optimal Control, vol. 1, 4th edn.
Athena Scientiﬁc, Nashua, NH (2017)
14. Castro, M.P., Cir´e, A.A., Beck, J.C.: An MDD-based Lagrangian approach to
the multicommodity pickup-and-delivery TSP. INFORMS J. Comput. 32, 263–
278 (2020)
15. Christoﬁdes, N., Mingozzi, A., Toth, P.: State-space relaxation procedures for the
computation of bounds to routing problems. Networks 11(2), 145–164 (1981)
16. Cir´e, A.A., van Hoeve, W.J.: Multivalued decision diagrams for sequencing prob-
lems. Oper. Res. 61, 1411–1428 (2013)
17. Cir´e, A.A., van Hoeve, W.J.: MDD propagation for disjunctive scheduling. In: Pro-
ceedings of the Twenty-Second International Conference on Automated Planning
and Scheduling (ICAPS) (2012). AAAI Press
18. Gentzel, R., Michel, L., van Hoeve, W.-J.: HADDOCK: A language and architec-
ture for decision diagram compilation. In: Simonis, H. (ed.) CP 2020. LNCS, vol.
12333, pp. 531–547. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
58475-7 31

154
J. N. Hooker
19. Gonz´alez, J.E., Cir´e, A.A., Lodi, A., Rousseau, L.M.: BDD-based optimization for
the quadratic stable set problem. Discrete Optim. 44, 100610 (2020)
20. Gonz´alez, J.E., Cire, A.A., Lodi, A., Rousseau, L.-M.: Integrated integer program-
ming and decision diagram search tree with an application to the maximum inde-
pendent set problem. Constraints 25(1), 23–46 (2020). https://doi.org/10.1007/
s10601-019-09306-w
21. Hadˇzi´c, T., Hooker, J.N.: Discrete global optimization with binary decision dia-
grams. In: GICOLAG 2006. Vienna, Austria, December 2006
22. Hadˇzi´c, T., Hooker, J.N.: Cost-bounded binary decision diagrams for 0-1 program-
ming. In: Van Hentenryck, P., Wolsey, L. (eds.) CPAIOR 2007. LNCS, vol. 4510,
pp. 84–98. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-72397-
4 7
23. Hoda, S., van Hoeve, W.-J., Hooker, J.N.: A systematic approach to MDD-based
constraint programming. In: Cohen, D. (ed.) CP 2010. LNCS, vol. 6308, pp. 266–
280. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-15396-9 23
24. Hooker, J.N.: Decision diagrams and dynamic programming. In: Gomes, C., Sell-
mann, M. (eds.) CPAIOR 2013. LNCS, vol. 7874, pp. 94–110. Springer, Heidelberg
(2013). https://doi.org/10.1007/978-3-642-38171-3 7
25. Hooker, J.N.: Job sequencing bounds from decision diagrams. In: Beck, J.C. (ed.)
CP 2017. LNCS, vol. 10416, pp. 565–578. Springer, Cham (2017). https://doi.org/
10.1007/978-3-319-66158-2 36
26. Hooker, J.N.: Improved job sequencing bounds from decision diagrams. In: Schiex,
T., de Givry, S. (eds.) CP 2019. LNCS, vol. 11802, pp. 268–283. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-30048-7 16
27. Mingozzi, A.: State space relaxation and search strategies in dynamic program-
ming. In: Koenig, S., Holte, R.C. (eds.) SARA 2002. LNCS (LNAI), vol. 2371, pp.
51–51. Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-45622-8 4
28. O’Neil, R.J., Hoﬀman, K.: Decision diagrams for solving traveling salesman prob-
lems with pickup and delivery in real time. Oper. Res. Lett. 47, 197–201 (2019)
29. Powell, W.B.: Approximate Dynamic Programming: Solving the Curses of Dimen-
sionality, 2nd edn. Wiley-Interscience, Hoboken (2011)
30. Righini, G., Salani, M.: New dynamic programming algorithms for the resource
constrained shortest path problem. Networks 51, 155–170 (2008)
31. Tjandraatmadja, C., van Hoeve, W.-J.: Incorporating bounds from decision dia-
grams into integer programming. Math. Program. Comput. 13(2), 225–256 (2020).
https://doi.org/10.1007/s12532-020-00191-6

Improving the Robustness of EPS
to Solve the TSP
Nicolas Isoart and Jean-Charles R´egin(B)
Universit´e Cˆote d’Azur - I3S - CNRS, 2000, route des Lucioles - Les Algorithmes -
Euclide B, BP 121, 06903 Sophia Antipolis Cedex, France
{nicolas.isoart,jean-charles.regin}@univ-cotedazur.fr
Abstract. Embarrassingly Parallel Search (EPS) parallelizes the search
for solutions in CP by decomposing the initial problem into a huge num-
ber of sub-problems that are consistent with propagation. Then, each
waiting worker takes a sub-problem and solves it. The process is repeated
until all the sub-problems have been solved. EPS is based on the idea
that if there are many sub-problems to solve then the solving times of the
workers will be balanced even if the solving times of the sub-problems
are not. This approach gives rather good results for solving the Trav-
eling Salesman Problem (TSP). Unfortunately, for some instances, sub-
problems with extremely diﬀerent solving times appear, for example one
requiring a huge part of the total solving time. In this case the load
balancing is poor. We show that a general increase in the number of
sub-problems does not solve this imbalance. We present a method that
identiﬁes the presence of diﬃcult sub-problems during the solving pro-
cess and decompose them again. This method keeps the advantages of
EPS: the communication is very reduced (the workers do not communi-
cate with each other) and it is independent of the solver. Experimental
results for the TSP show a good improvement of load balancing and a
better scaling with hundred of cores.
1
Introduction
The Traveling Salesman Problem (TSP) consists in searching for a single cycle
covering a graph such that the sum of the cost of the edges of the cycle is mini-
mized. This problem has been widely studied as there is a huge number of direct
applications such as routing problems, school bus problems, etc. and indirect
applications such as scheduling where cities are tasks and arcs are transition
times. There are very eﬃcient methods to ﬁnd near optimal solutions such as
LKH algorithm [8,20]. Therefore, when we solve the problem in parallel, we can
consider TSP as a satisfaction problem rather than an optimization problem.
In constraint programming there are two main approaches for solving a prob-
lem in parallel: the search space splitting method (i.e., the work-stealing app-
roach) and problem decomposition (i.e., embarrassingly parallel search).
The work-stealing method dynamically splits the search space during the
solving [1,4]. When a worker has ﬁnished exploring a sub-problem, it asks other
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 155–172, 2022.
https://doi.org/10.1007/978-3-031-08011-1_12

156
N. Isoart and J.-C. R´egin
workers for another sub-problem. If another worker agrees to the demand, then
it dynamically splits its current sub-problem into two disjoint sub-problems and
sends one sub-problem to the starving worker. The starving worker “steals”
some work from the busy one. Several implementation of work stealing approach
have been designed
[22,27]. The most recent ones, like Bobpp tries to be as
independent as possible from the solver [3,16].
The Embarrassingly Parallel Search (EPS) [21,23,25] is a more recent
method. It statically decomposes the initial problem into a huge number of
sub-problems that are consistent with propagation (i.e. running the propaga-
tion mechanism on them does not detect any inconsistency). Then, each waiting
worker takes a sub-problem and solves it until all the sub-problems have been
solved. The assignment of the sub-problems to workers is dynamic, and there is
no communication between the workers. EPS is based on the idea that if there
is a large number of sub-problems to solve then the solving times of the workers
will be balanced even if the solving times of the sub-problems are not. In other
words, load balancing should be automatically obtained in a statistical sense.
EPS seems to be more robust and to outperform the work-stealing approach.
As EPS gives very good results on many problems, it was legitimate to try it
to solve the TSP [12]. In order to use it, some modiﬁcations of the EPS decom-
position mechanism have been required for two reasons. First, the model of the
TSP in CP contains a set-variable with the mandatory edges as lower bound
and optional edges as upper bound. Decomposing with a set-variable is not as
trivial as a classical Cartesian product, because the order must be carefully han-
dled while enumerating. Second, the most eﬃcient strategy is LCFirst: it selects
one node from the graph according to a heuristic and keeps branching on the
node until there are no more candidates around it, no matter if we backtrack or
not. This strategy is a depth-ﬁrst process unlike the decomposition mechanism
of EPS which is a depth-bounded. The ﬁrst change due to the set-variable is
minor. For the second issue the method Bound-Backtrack-and-Dive has been
introduced [12]. It proceeds in two steps. A sequential solving of the problem
with a bounded number of backtracks is run in order to extract key information
from LCFirst. Then, the EPS decomposition uses that information rather than
LCFirst. The experimental results shown that almost a linear gain on the num-
ber of cores is obtained and that Bound-Backtrack-and-Dive may considerably
reduce the number of backtracks performed for some problems. It is important
to note that without this method it is possible to observe a degradation of per-
formance according to the number of cores.
The authors give experimental results with a classical laptop nowadays, i.e.
with four cores with hyperthreading. The results are quite good. For many prob-
lems, the same kind of results are obtained when increasing the number of cores.
Unfortunately, this is not true for all problems and often not the case for very
diﬃcult problems. It is precisely for those problems that we would like to be able
to use the combined power of many computational cores.
The objective of this article is to propose a method to detect this kind of
diﬃcult problems and to improve their solving in parallel. In other words, we

Improving the Robustness of EPS to Solve the TSP
157
propose to slightly modify EPS in order to improve its robustness. EPS has
many qualities, such as its simplicity, its independence from the solvers used
and search strategies, the absence of communication between workers and weak
communication between the master and the workers. It is important to respect
these advantages and not to make any changes that could jeopardize them.
The study of EPS, as deﬁned in [12], with a hundred cores for the solving of
the TSP showed rather unexpected results. Three major issues were observed:
1. Unstable decomposition. The decomposition is no longer stable in the sense
that decomposing more may lead to a strong degradation of the performance.
This happens with the TSP because the best strategy is a depth ﬁrst strat-
egy whereas the decomposition mechanism can be seen has a breadth ﬁrst
process. In other words, in sequential solving the CP model uses the previous
calculations, whereas in parallel solving, the decomposition makes the sub-
problems independent and they are solved in a diﬀerent order than sequential
solving would have done. This means that the decomposition can interact
unfavorably with the increase in the number of cores. In other words, increas-
ing the number of cores can lead to no improvement. For instance, problem
pcb442 of the TSPLib requires 91,137 s to be solved sequentially whereas EPS
(with #sppw = 30) requires 10,645 s with 24 workers, 7,458 s with 48 workers,
12,808 s with 72 workers and 11,025 s with 96 workers.
2. Non-monotonic decomposition. The decomposition is diﬃcult to comprehend
because sometimes decomposing more leads to more problems and sometimes
it leads to fewer problems [12]. In addition, the succession of the two phe-
nomena can be observed during the same decomposition.
3. Extremely heterogeneous sub-problems. A very small number of sub-problems
can take a very large part of the overall solving time. For instance, the decom-
position of the problem gr431 of the TSPLIB [26] into 300 sub-problems, leads
to 5 sub-problems which take 50% of the overall solving time. The consequence
is that at the end of the solving, only 5 workers remain active, independently
of the number of the available workers.
In order to remedy these issues, we propose to reduce the number of sub-problems
that are considered during the decomposition and to re-decompose the remaining
unsolved sub-problems if needed, and to repeat this process while the whole
problem is unsolved. Indeed, a re-decomposition allows a better redistribution
of the work and so a better load balancing.
However, this approach triggers new questions:
– When should we re-decompose? Under which conditions? If we wait too long
then the risk is that very few workers, or even one, will be left to solve a
problem while all the others have no more work to do.
– When a worker is aborted, it has already performed some computations, how
can we avoid redoing the same computations that has just been done?
– How should we re-decompose? What is the right number of sub-problems per
worker to consider for a decomposition? Should it evolve?

158
N. Isoart and J.-C. R´egin
We will answer all these questions and show how to deﬁne the right param-
eters in order to obtain a worthwhile re-decomposition.
The article is organized as follows. First, we recall the CP model of the TSP
and we introduce EPS. Then, we discuss some problems arising when a hundred
cores are used. Next, we present a new method based on re-decompositions
when needed. At last, we give some experiments showing the advantages of our
approach and we conclude.
2
Preliminaries
2.1
TSP Model in CP
One of the most eﬃcient models in constraint programming for solving the TSP
is based on the Weighted Circuit Constraint (WCC) associated with the k-
cutset constraint and the mandatory Hamiltonian path constraint coupled with
a branch-and-bound procedures [9]. The WCC is composed of a Lagrangian
relaxation of a minimum 1-tree [6,7,11] (i.e. a special minimum spanning tree)
plus two minimum cost edges and degree constraints. The k-cutsets constraint
ﬁnd all sizes 2 and 3 cutsets in the graph and imposes that an even number of
edges for each cutset is mandatory [10,14]. The mandatory Hamiltonian path
constraint stops the search when a non optimal hamiltonian subpath of the tour
is found [13]. A single undirected graph variable where all nodes are mandatory
is used to represent the graph. The branch-and-bound considers only the edges,
it consists in making a binary search where a left branch is an edge assignment
and a right branch is an edge removal.
In addition, this TSP model uses a search strategy integrating a graph inter-
pretation of Last Conﬂict heuristics [5,18], named LCFirst [2]. This search strat-
egy selects one node from the graph according to a heuristic and keeps branching
on the node until there are no more candidates around it, no matter if we back-
track or not. One of the most eﬃcient heuristic and the one used by default is
minDeltaDegree. It selects the edges for which the sum of the endpoint degrees in
the upper bound minus the sum of the endpoint degrees in the set-variable lower
bound is minimal. Hence, this search strategy learns from previous branching
choices and tends to keep those that previously caused a failure. Results in [2]
show that LCFirst clearly outperforms all other search strategies, it is the only
one that really exploits the graph structure. So far, LCFirst beats all other search
strategies by one or more orders of magnitude.
2.2
EPS
Embarrassingly Parallel Search (EPS) decomposes the initial problem into a
huge number of sub-problems that are consistent with propagation. Then, each
waiting worker takes a sub-problem and solves it until all sub-problems have
been solved. It is usually considered that a good number of sub-problems per
worker is between 30 to 300 [21,23,25].

Improving the Robustness of EPS to Solve the TSP
159
The generation of q sub-problems is not straightforward because the num-
ber of sub-problems consistent with the propagation may not be related to the
Cartesian product of some domains. A simple algorithm could be to perform
a Breadth First Search (BFS) in the search tree until the desired number of
sub-problems consistent with the propagation is reached. Unfortunately, it is
not easy to perform a BFS eﬃciently mainly because BFS is not an incremental
algorithm like Depth-First Search (DFS). Therefore, EPS uses a process resem-
bling an iterative deepening depth-ﬁrst search [15]: we consider a set Y ⊆X
of variables: we only assign the variables of Y and we stop the search when
they are all assigned. In other words, we never try to assign a variable that is
not in Y . This process is repeated until all assignments of Y consistent with
the propagation has been found. Each branch of a search tree computed by this
search deﬁnes an assignment (i.e. a sub-problem). To generate q sub-problems,
we repeat the previous method by adding variables to Y if necessary, until the
number of sub-problems is greater than or equal to q.
In some cases, frequently encountered with the TSP, the increase of variables
in Y leads to a reduction in the number of generated sub-problems. This phe-
nomenon is named: non-monotonic decomposition. If suddenly many branches
fail in the search tree, it may be possible that more problems have been removed
than generated. For special cases such as this one, it is preferable to stop the
decomposition because the number of sub-problems generated can start to oscil-
late without really progressing globally. Thus, a stopping criterion other than
the number of sub-problems generated has been deﬁned [12]: if there are two
successive additions of variables in Y for a decrease of the number of generated
sub-problems is observed, then the decomposition is stopped.
When we consider a set Y ⊆X of variables, we pay attention to the set-
variables. A classical variable is instantiated by a single value, whereas for a set-
variable we will determine how many of its values should be instantiated at most.
For instance, a set variable can be instantiated with at most 1, 2 or 3 values. Its
cardinality deﬁnes only the maximum because we search for partial assignments.
In general, all but one set-variable of Y will be potentially instantiated with their
maximum possible values (i.e. the maximum cardinality).
Note that the decomposition is also performed in parallel.
As the best search strategy for the TSP is LCFirst which is depth-ﬁrst based
whereas the decomposition is depth-bounded, in previous work [12] we intro-
duced the method Bound-Backtrack-and-Dive that partially solve this issue. It
proceeds in two steps. First, a sequential solving of the problem with a bounded
number of backtracks is run in order to extract key information from LCFirst.
Then, the EPS decomposition uses that information rather than LCFirst. The
experimental results shown a strong improvement with this method.
3
Performance with a Hundred Cores
The modiﬁed version of EPS performed well with the TSP model when there
are 4 cores [12]. As it is usual in parallelism, one has the right to wonder if

160
N. Isoart and J.-C. R´egin
the scaling we observe for a few cores can be veriﬁed in practice with about a
hundred cores. EPS has already been modiﬁed for improving its scaling while
used on data centers [24].
When using hundred cores, we observe the three issues mentioned in Intro-
duction: unstable decomposition, non-monotonic decomposition and extremely
heterogeneous sub-problems. As we already mentioned, the non-monotonic
decomposition problem is solved by introducing a stopping criterion other than
the number of generated sub-problems. We will now focus on the other two
issues.
In order to remedy the unstable decomposition issue we suggest to consider
it carefully and to avoid decomposing too much. That is instead of trying to
decompose in a lot of sub-problems, we suggest to consider fewer sub-problems.
The risk of reducing the number of sub-problems is that it can be diﬃcult to
ensure a good load balancing between the workers. However, when there are a
hundred workers it is less important to have 2, 5 or 10 workers that are not active
than when you have only 4 workers. On the other hand, the second problem we
have to solve is that of extremely heterogeneous sub-problems which therefore
lead de facto to bad load balancing.
In order to remedy the bad load balancing caused by the presence of
extremely heterogeneous sub-problems, we have no choice but to re-decompose
these sub-problems into many other sub-problems which are more homogeneous.
In other words, we have to be prepared to do several decomposition steps.
All this must be done without disturbing the functioning of EPS for prob-
lems that do not show these behaviors and that are very well solved by EPS
even with a hundred cores. Therefore, systematically performing several decom-
position steps worsens the results. One must identify if there are some extremely
heterogeneous sub-problems and in this case prepare to restart a decomposition.
This also must be done while keeping the advantages of EPS: a very reduced
communication (the workers do not communicate with each other) and an inde-
pendence from the solver used.
4
Re-decomposition
First, we try to estimate under which conditions it could be worthwhile to re-
decompose the unsolved sub-problems. Then, we try to avoid redoing the same
work when the solving of a sub-problem is interrupted in order to re-decompose.
The challenge can be resumed as follows: if we wait too long for performing
a decomposition then the risk is that very few workers, or even one, will be
left to solve a problem while all the others have no more work to do. However,
re-decomposing for better distribution means losing part of the previous com-
putations already done and requires a certain minimum time that may not be
proﬁtable.
Notation 1 (known values) and Notation 2 (unknown values) describe some
information about the search.

Improving the Robustness of EPS to Solve the TSP
161
Notation 1
• w: total number of workers.
• a: number of active workers (i.e. workers which are currently solving a sub-
problem).
• cR: wall clock solving time of the set of the unsolved sub-problems R. Precisely,
this is the solving time already done for the remaining sub-problems.
Notation 2
• tR: wall clock total solving time for the set of remaining sub-problems R. It
is the sum of the solving times of the sub-problems not yet solved.
• dR: wall clock time needed to decompose the set of remaining sub-problems R.
We also called it the time to re-decompose.
• rtR: wall clock time needed to solve the set of remaining sub-problems R after
a re-decomposition.
We immediately have the following property:
Proposition 1. The
minimum
remaining
computation
time
without
re-
decomposition is: tR−cR
a
This is a lower bound of the real value because it assumes that the remaining
time for the set of the remaining sub-problems is perfectly distributed among
the workers if a = w and if a < w then it means that the remaining computation
time for each sub-problem is the same.
Proposition 2. The minimum remaining computation time for re-decomposing
and solving the remaining sub-problems is: rtR
w + dR
From these two properties we propose a new property:
Proposition 3. Performing a re-decomposition may become worthwhile if
rtR
w + dR < tR −cR
a
(1)
If after a decomposition all the computations performed by a stopped worker
are lost, then it means that cR = 0 and rtR = tR. On the other hand, if all the
computations previously made are not redone, then we have rtR = tR−cR. Unfor-
tunately, it is very diﬃcult to obtain this result because EPS is independent from
the solver and from the search. Nevertheless we can expect to have rtR < tR.
Simplifying this inequality is not simple because we are faced with several
unknown variables. We do not know precisely tR, nor rtR, nor dR and we have
no guarantee that the solving process will be perfectly homogeneous.
Therefore, we propose to make some assumptions:
– We will consider that rtR can be rewritten as tR −qcR with 0 ≤q ≤1 and
q corresponds to the proportion of computations already made that we can
avoid redoing. For practical reasons, we suggest to simply estimate the value
of q from the previous calculations. Let us consider a sub-problem p ∈R, we

162
N. Isoart and J.-C. R´egin
look for the value qp. While solving p, if the search tree proved that k values
can be safely removed from the initial domain of some variables, then we know
that we were trying a (k + 1)th value when solving. Avoiding reconsidering
the kth values allow to avoid redoing qp = k/(k + 1) from the calculations
previously made. However, we do not know where we were in the solving of
the (k+1)th branch. On average, we can consider that we were halfway in the
solving of this branch. It means that we will avoid redoing qp = k/(k + 0.5)
from the previous calculations. Thus, we suggest to take as q the average of
the values of qp for each sub-problem p.
– We also observed that the decomposition time does not really change between
decompositions. We will therefore consider that it is constant dR = d. In
practice, we will consider that a re-decomposition will take the time of the
previous decomposition.
– Since no solving time is lost when a = w, we only consider a re-decomposition
when a < w.
We can rewrite the previous property:
Proposition 4. Performing a re-decomposition may become worthwhile if
tR > (w −aq)cR + wad
w −a
(2)
Proof. With Notation 1, Eq. 1 can be rewritten as tR−qcR
w
+ d < tR−cR
a
which is
equivalent to (w −a)tR > (w −aq)cR + wad. Since a < w we have (w −a) > 0
and the property holds.
⊓⊔
The main issue is that we do not know the value of tR. However, for a given value
of a we can check whether Eq. 2 is satisﬁed or not and stop the computation when
it is satisﬁed. First of all we know that tR ≥cR. Next, during a wall clock period
of time T of computations performed by a active workers the total solving time
computed is aT and so we have tR ≥aT + cR. Thus if aT + cR > (w−aq)cR+wad
w−a
then we know that Eq. 2 is satisﬁed. So we can compute the value of T for
which Eq. 2 is satisﬁed. This value will become the maximum timeout we accept
without performing a new decomposition.
aT + cR > (w−aq)cR+wad
w−a
⇔aT > (w−aq)cR+wad
w−a
−cR
⇔aT > (a−aq)cR+wad
w−a
⇔aT > a(1−q)cR+wad
w−a
⇔T > (1−q)cR+wd
w−a
Proposition 5. Assume that after T units of computation no new sub-problem
is solved. It is worthwhile to re-decompose if
T > (1 −q)cR + wd
w −a
(3)
Proof. If after T1 < T units of time we solve 1 task s1 then we can compute
the new inequality. We decrement the number of active workers and work with
R1 = R −{s1} and cR1 = cR + aT1 −t(s1).

Improving the Robustness of EPS to Solve the TSP
163
Equation 3 suggests that we should wait a certain amount of time to be sure
that we should decompose. However, waiting that time may have a cost that
leads to poorer results. Thus, we propose to use T as an upper bound of the
waiting time before re-decomposing.
Indeed, on the one hand, we do not know how to avoid redoing all the cal-
culations performed (we cannot avoid cr, but only qcr) and, on the other hand,
we do not calculate with the power of all the workers, which means that we
lose a certain amount if the decision is to decompose again. However, if we re-
decompose too early when we should not have, we will also lose time. Therefore,
instead of directly using the formula in Eq. 3, it is more interesting to introduce
a decision factor α, with 0 ≤α ≤1. The idea behind this value corresponds to
a kind of risk sharing. We have the ﬁnal property:
Proposition 6. Assume that after T units of computation no sub-problem is
solved. The current active workers are stopped and a decomposition is performed
if
T > α(1 −q)cR + wd
w −a
(4)
This leads to Algorithm 1. Equation 4 will evolve as sub-problems are solved.
Algorithm 1: checkDecomposition algorithm
checkDecomposition(d, α, q): boolean
// The sub-problems are currently run in parallel ;
Wait until it remains only a = w −1 active workers ;
stopT ime ←wallClockTime() ;
R ←set of remaining sub-problems ;
C ←Sum of current solving times of the remaining sub-problems ;
timeout ←α (1−q)C+wd
w−a
;
for each sub-problem p ∈R solved before timeout do
// the timeout evolves according to the solved sub-problems ;
R ←R −{p} ;
T ←wallClockTime() −stopT ime ;
stopT ime ←wallClockTime() ;
C ←C + aT −t(p); // t(p) is the solving time of the sub-problem p ;
a ←a −1 ;
timeout ←min(timeout −T, α (1−q)C+wd
w−a
) ;
if all sub-problems are solved then return false;
Abort all the remaining active workers ;
return true; // A re-decomposition will be performed ;
Moreover, we need to make sure that each inequality holds. Indeed, when
a problem p of R is solved, we compute a new inequality of Eq. 4 for R −{p}.
However, the time between the last task solved and p can be huge. Therefore,
the new timeout must verify the old inequality (i.e. timeout −T) and the new
computed inequality. Thus, we take min(timeout −T, α (1−q)cR+wd
w−a
) as the new
timeout. Note that Function checkDecomposition is run in the main loop of
the EPS master which manages the workers and the sub-problems. If it returns
true then a re-decomposition is performed.

164
N. Isoart and J.-C. R´egin
4.1
How to Avoid Redoing Calculations?
When a worker is aborted, it has already performed some work. How can we
avoid redoing the same work that has just been done?
In order to avoid redoing part of the previously performed calculations, we
could memorize the boundary of the search already made. Nogoods recording
methods [17,19] can be used for managing the savings and the restarts. However,
we introduce a simple and general method that requires little intervention in the
solver and practically no more transmission of information. In addition, it allows
to estimate the proportion of computations that we can avoid redoing. Like the
nogoods recording methods, we only assume that the search can be described
by a set of decisions and rejections of decisions. Conceptually, the search tree
can be viewed as a binary tree where a node has two children: one applies the
decision and the other rejects the decision (usually by imposing the opposite).
When a sub-tree resulting from a decision is completely ﬁnished then we know
that the exploration of that part is completely ﬁnished and we do not need to do
it again. Thus, we propose to no longer consider the nodes linked to the root of
which only the refutation of the decision remains. This is easy to express because
it simply corresponds to the suppression of values in variable domains. In the
case of TSP, it corresponds to a set of edges that should no longer be used for
the tour. In other words, we simply deﬁne a new sub problem whose domains
are included in the initial one and we transmit it to the EPS master.
4.2
Discussion
Instead of an overall decomposition, it is also possible to study the behavior
of EPS at the level of each of the sub-problems. Thus, one can try to deﬁne
criteria to try to know whether a sub-problem should or should not be re-
decomposed and then proceed to a speciﬁc individual re-decomposition for some
sub-problems. We tried this method, but it is not advantageous and raises many
questions: when should we look to see if the sub-problems are particularly dif-
ﬁcult? Should they be stopped immediately? Moreover, this method leads to
a succession of decompositions (one per sub-problem) which quickly becomes
expensive and does not bring any particular gain. In fact, EPS always tries to
consider the solving of sub-problems as global and there seems to be little inter-
est in questioning this point of view. In addition, only the master can use such
a criteria because we search for sub-problems that are more diﬃcult than others
and only the master can have this information. A worker has no information
about the other workers. This is why it is preferable to let the master manage
the solving of the diﬀerent workers, even if it means interrupting some of them.
5
Experiments
We experimentally show that EPSrd, the re-decomposition method we propose,
allows obtaining better solving times and more robustness than the classical EPS
method (denoted by EPS).

Improving the Robustness of EPS to Solve the TSP
165
The algorithms have been implemented in Java 11 in a locally developed CP
solver. The experiments were performed on 4 Clear Linux machines, each using
two Intel Xeon E5-2696v2 and 64 GB of RAM. Thus the experiments use 96
identical cores. The reference instances are from the TSPLIB [26], a library of
reference graphs for the TSP and the set of instances is based on the set given by
Fages et al. [2] that can be seen as state-of-the-art instances. Some more diﬃcult
instances have been added. The name of each instance is suﬃxed by its number
of nodes. All given times are wall clock time (usually in seconds).
5.1
Satisfaction vs Optimization
Table 1. LKH bound when k-opt is limited to 3-opt.
optimal bound
LKH bound
LKH time (s)
seq. time (s)
a280
2378
2378
0.48
8.1
ali535
202339
202339
3.19
13013.9
d198
15780
15780
0.7
7
d493
35002
35002
1.2
4989.9
gil262
2378
2378
0.48
2042.2
gr229
134602
134602
0.28
41.2
gr431
171414
171428
1.62
520.6
gr666
294358
294361
4.05
14719.6
kroA200
29368
29368
0.19
63.7
kroB150
26130
26130
0.22
8.7
kroB200
29437
29437
0.14
15.1
lin318
42029
42029
0.53
6.4
pcb442
50778
50778
0.8
91137.7
pr136
96772
96772
0.11
8.9
pr264
49135
49135
0.17
3.8
pr299
48191
48191
0.66
1595.5
rat195
2323
2323
0.33
17.9
rd400
15281
15281
0.53
6721
si175
21407
21407
0.78
100.7
tsp225
3916
3916
0.27
23.5
As shown in Table 1, the famous LKH heuristic [8,20] allows to ﬁnd very quickly
a solution whose value is very close to the optimal one (they are the same except
for gr431 and gr666). Thus, for the purpose of parallelization, the TSP problem
can be seen more as a satisfaction problem than as an optimization problem.
5.2
Comparison for a Given Number of Sub-problems
We search for the best conﬁguration for EPS and EPSrd. In Table 2, we consider
the number of sub-problems per workers (#sppw). We observe that #sppw = 100
for EPS and #sppw = 10 for EPSrd (with α = 0.1) are the best conﬁgurations.
We observe that most of the time EPSrd improves the results of EPS. EPS is
based on the idea that for having a good load balancing we need to have a certain

166
N. Isoart and J.-C. R´egin
number of sub-problems. The experiments support this idea, even if sometimes
decomposing too much may be time consuming. For instance, pcb442 is solved
in 22,800 s with #sppw = 10, 11,025 s with #sppw = 30, 7,686 s with #sppw = 50
and 5,168.8 s with #sppw = 100. However, if we carefully look at the results, we
can reﬁne this principle. We observe that when the load balancing is not an issue
for a problem (such as gr229 where #sppw = 10 is the best), then a small value
of #sppw is perfectly ﬁne. This means that we need to have a greater value only
when the load balancing is an issue. However, we have no information about the
load balancing before the solving. Conversely, EPSrd tries to identify during the
solving whether the load balancing is an issue or not. If it detects such an issue,
then it performs a re-decomposition. Thus, EPSrd has advantage to start with
a low #sppw. Note that this approach can be seen as a dynamic increase of the
#sspw value. We observe that the mean solving times of EPSrd with #sppw = 10
is 2.3 times faster than with other #sspw values. In addition, the problems with
a huge load balancing issue such as pcb442 are well solved with EPSrd (5,166.8 s
for EPS and 159.5 s for EPSrd). Finally, we observe that the best conﬁguration
for EPSrd in this table is 5.3 times faster than the best one for EPS.
Table 2. Comparison between EPS and EPSrd for diﬀerent values of #sppw.
Instances
EPS(s)
EPSrd(s)
EPS/EPSrd
#sppw
#sppw
#sppw
10
30
50
100
10
30
50
100
10
30
50
100
a280
1.8
9.8
17.4
1.7
1.6
1.6
18.3
1.6
1.1
6.2
0.9
1.0
ali535
3,436.0
4,045.6 3,945.4 4,056.3
463.9 1,108.1
560.5
617.5
7.4
3.7
7.0
6.6
d198
12.2
14.6
15.2
14.5
13.3
12.9
12.6
13.5
0.9
1.1
1.2
1.1
d493
4,188.8
4,426.0 3,810.6 2,247.2 1,084.5 1,449.3 2,259.1 3,708.3
3.9
3.1
1.7
0.6
gil262
75.7
79.1
68.9
113.6
30.6
88.5
75.5
106.9
2.5
0.9
0.9
1.1
gr229
12.4
20.3
19.7
41.4
16.2
30.0
35.1
41.3
0.8
0.7
0.6
1.0
gr431
77.6
82.2
105.3
169.4
82.6
91.8
106.3
168.3
0.9
0.9
1.0
1.0
gr666
4,588.5
1,653.5 1,749.0 1,555.2
926.0
998.3 1,122.8 1,075.8
5.0
1.7
1.6
1.4
kroA200
6.4
6.2
7.5
6.1
7.3
7.1
7.4
6.4
0.9
0.9
1.0
0.9
kroB150
2.5
2.3
2.6
2.5
2.6
2.6
2.4
2.5
1.0
0.9
1.1
1.0
kroB200
6.2
5.2
4.4
4.4
6.6
5.6
4.7
4.5
0.9
0.9
0.9
1.0
lin318
3.6
3.9
3.4
3.6
3.4
3.3
3.3
3.7
1.1
1.2
1.0
1.0
pcb442
22,800.1 11,025.4 7,686.4 5,166.8
159.5
289.7
408.9
331.0 143.0 38.1 18.8 15.6
pr136
1.4
1.6
1.8
1.7
1.7
1.6
1.7
1.6
0.8
1.0
1.1
1.1
pr264
11.9
13.8
13.9
12.8
16.5
13.3
13.1
13.8
0.7
1.0
1.1
0.9
pr299
1,345.2
2,183.9 3,807.3 3,160.6
211.3
220.8
303.4
396.8
6.4
9.9 12.6
8.0
rat195
5.9
5.1
5.1
4.8
5.7
4.9
4.4
4.3
1.0
1.0
1.1
1.1
rd400
706.2
496.2
477.7
560.9
135.9
215.9
244.8
816.1
5.2
2.3
2.0
0.7
si175
4.6
6.9
12.2
15.0
5.0
6.7
10.6
13.5
0.9
1.0
1.2
1.1
tsp225
10.5
9.0
8.3
8.8
9.6
8.2
8.1
8.0
1.1
1.1
1.0
1.1
mean
1,864.9
1,204.5 1,088.1
857.4
159.2
228.0
260.1
366.8
5.3
The α Value
In Table 3, we consider the α parameter for EPSrd with #sppw = 10. We note
s.d. the standard deviation of the solving times. We notice that the importance

Improving the Robustness of EPS to Solve the TSP
167
of the alpha value relies on the number of re-decompositions. For instance, gr229
is re-decomposed between 0 and 1 time for each alpha value. Then, all the
solving times are close to each other, and the standard deviation is quite low
(2.2). Conversely, the standard deviation for gr666 is equal to 54.7 and we have
between 5 and 11 re-decompositions for each alpha value. We also notice that,
the more the number of re-decompositions is high the more the alpha value is
important. Nevertheless, the alpha value does not have an impact as important
as #sppw. Finally, considering the mean, α = 0.3 is the best alpha value whereas
considering the geometric mean α = {0.1, 0.5, 0.7} are the best alpha values.
Table 3. Impact of the α value on the solving times in seconds.
α
0.1
0.3
0.5
0.7
0.9
#re-decomp.
s.d.
a280
1.6
5.2
1.6
1.5
1.5
0
1.6
ali535
463.9
415.2
467.9
471.1
500.0
4 to 7
30.6
d198
13.3
14.5
16.0
12.9
13.2
0 to 2
1.3
d493
1,084.5
1,033.7
1,135.9
1,048.8
1,101.6
6 to 11
41.0
gil262
30.6
26.9
30.0
34.0
31.4
1 to 3
2.6
gr229
16.2
16.4
12.8
11.8
12.6
0 to 1
2.2
gr431
82.6
95.1
86.1
87.2
94.7
1 to 4
5.5
gr666
926.0
822.5
786.9
807.9
810.8
5 to 11
54.7
kroA200
7.3
7.2
7.0
6.8
6.7
0
0.3
kroB150
2.6
2.7
2.7
2.6
2.8
0
0.1
kroB200
6.6
5.6
4.9
6.2
6.7
0
0.8
lin318
3.4
3.3
4.0
3.2
3.5
0
0.3
pcb442
159.5
210.6
243.1
270.4
314.2
5 to 8
58.7
pr136
1.7
1.4
1.8
1.5
1.6
0 to 1
0.2
pr264
16.5
12.0
11.6
11.7
12.9
0 to 1
2.0
pr299
211.3
237.4
236.3
248.3
317.4
8 to 14
40.0
rat195
5.7
5.9
5.0
5.9
6.3
0
0.5
rd400
135.9
132.5
134.0
135.7
140.4
4 to 6
3.0
si175
5.0
5.2
5.5
6.2
4.9
0 to 1
0.5
tsp225
9.6
9.7
10.5
10.4
10.2
0
0.4
mean
159.2
153.1
160.2
159.2
169.7
6.0
geo mean
24.5
25.5
24.5
24.5
25.5
5.4
Computations that Have Already Been Made
By avoiding to redo computations already done after a re-decomposition we gain
between a factor 2 (for pcb442) and a few percent (rd400). We generally gain
between 10% and 20%.
5.5
Solving Evolution
In Table 4, we study the behavior of EPS and EPSrd when the best conﬁguration
is set. That is #sppw = 100 for EPS and #sppw = 10 and alpha = 0.1 for EPSrd.
This experiment shows some drawbacks of EPS for some problems.

168
N. Isoart and J.-C. R´egin
For EPS, we give some wall clock times (in s): the decomposition time, the
wall clock time of the solving time when all workers are active, the wall clock
time of the solving time when some (or most) workers are inactive and the wall
clock time to solve the problem (total). Note that the wall clock time is the sum
of “decomp.”, “all workers are active” and “not all workers are active” times.
Next, we give some information about EPSrd: the decomposition time, the wall
clock time performed between the end of the ﬁrst decomposition and the start
of the ﬁrst re-decomposition, the wall clock time of the solving time when all
workers are active, the wall clock time of the solving time when some (or most)
workers are inactive and the wall clock time to solve the problem (total). We can
see that EPSrd obtains a better load balancing. For instance, with EPS gr666
spends 304.8 s when all the workers are active and 1,101 s when some workers are
not active. Conversely, with EPSrd gr666 spends 401.6 s when all the workers
are active and 142.9 s when some workers are not active. Then, when the load
balancing is going to be bad, EPSrd quickly performs a ﬁrst re-decomposition
avoiding spending a lot of time with some inactive workers.
Table 4. Solving evolution of EPS and EPSrd. “W.A.” stands for “workers are active”
EPS time(s)
EPSrd time(s)
Instances
decomp.
all
not all
total
decomp.
before ﬁrst
all
not all
total
W.A.
W.A.
re-decomp.
W.A.
W.A.
a280
1.3
0.0
0.3
1.7
1.3
0.3
0.0
0.3
1.6
ali535
30.1
3.7
4,022.5
4,056.3
141.6
9.9
238.9
83.3
463.9
d198
9.3
1.0
4.2
14.5
9.4
3.4
2.4
1.5
13.3
d493
135.7
8.6
2,102.9
2,247.2
178.5
16.6
801.4
104.6
1,084.5
gil262
105.4
6.7
1.5
113.6
17.8
3.8
6.5
6.3
30.6
gr229
20.7
19.2
1.4
41.4
10.8
4.4
3.9
1.6
16.2
gr431
146.4
5.9
17.1
169.4
63.8
8.8
6.8
12.0
82.6
gr666
149.4
304.8
1,101.0
1,555.2
381.5
56.8
401.6
142.9
926.0
kroA200
5.6
0.3
0.1
6.1
6.7
0.6
0.5
0.1
7.3
kroB150
2.3
0.0
0.2
2.5
2.3
0.2
0.1
0.2
2.6
kroB200
4.2
0.2
0.1
4.4
6.1
0.5
0.2
0.3
6.6
lin318
3.4
0.0
0.3
3.6
3.3
0.1
0.0
0.1
3.4
pcb442
80.9
58.5
5,027.4
5,166.8
51.2
18.2
67.8
40.4
159.5
pr136
1.5
0.1
0.2
1.7
1.0
0.7
0.1
0.6
1.7
pr264
10.4
1.1
1.4
12.8
12.0
4.0
2.8
1.7
16.5
pr299
112.9
5.8
3,041.9
3,160.6
80.6
5.4
85.3
45.4
211.3
rat195
4.6
0.1
0.1
4.8
5.5
0.2
0.1
0.2
5.7
rd400
241.2
25.0
294.6
560.9
60.4
17.0
50.5
24.9
135.9
si175
12.7
0.7
1.7
15.0
3.3
1.6
0.9
0.8
5.0
tsp225
8.0
0.2
0.5
8.8
9.0
0.7
0.2
0.4
9.6

Improving the Robustness of EPS to Solve the TSP
169
5.6
Overall Results
Table 5. Comparison between EPS and EPSrd.
Instances
Sequential(s)
EPS(s)
Seq./EPS
EPSrd(s)
Seq./EPSrd
EPS/EPSrd
a280
8.1
1.7
4.8
1.6
5.0
1.0
ali535
13,013.9
4,056.3
3.2
463.9
28.1
8.7
d198
7.0
14.5
0.5
13.3
0.5
1.1
d493
4,989.9
2,247.2
2.2
1,084.5
4.6
2.1
gil262
2,042.2
113.6
18.0
30.6
66.7
3.7
gr229
41.2
41.4
1.0
16.2
2.5
2.6
gr431
520.6
169.4
3.1
82.6
6.3
2.0
gr666
14,719.6
1,555.2
9.5
926.0
15.9
1.7
kroA200
63.7
6.1
10.5
7.3
8.7
0.8
kroB150
8.7
2.5
3.5
2.6
3.3
1.0
kroB200
15.1
4.4
3.4
6.6
2.3
0.7
lin318
6.4
3.6
1.8
3.4
1.9
1.1
pcb442
91,137.7
5,166.8
17.6
159.5
571.5
32.4
pr136
8.9
1.7
5.1
1.7
5.2
1.0
pr264
3.8
12.8
0.3
16.5
0.2
0.8
pr299
1,596.5
3,160.6
0.5
211.3
7.6
15.0
rat195
17.9
4.8
3.7
5.7
3.1
0.8
rd400
6,721.0
560.9
12.0
135.9
49.5
4.1
si175
100.7
15.0
6.7
5.0
20.2
3.0
tsp225
23.5
8.8
2.7
9.6
2.4
0.9
mean
6,752.3
857.4
5.5
159.2
40.3
4.2
In Table 5, we show the general results obtained by EPS and EPSrd with their
best conﬁgurations. Compared to the mean sequential solving times, an improve-
ment by a factor 5.5 is observed for EPS and an improvement by a factor 40.3
is observed for EPSrd. Therefore, EPSrd is much more eﬃcient than EPS (the
mean improvement ratio is of 4.2).
5.7
Robustness
In Table 6, we compare the robustness of EPS and EPSrd. We run several times
each instance and we compare the minimum solving time, the maximum solving
time, the mean solving time and the standard deviation of the solving times.
For EPS, most instances have quite a large variation between min and max and
therefore a huge standard deviation. For instance, with EPS the min and the
max solving times of gr666 are respectively 1,003 s and 1,555 s. It leads to a
standard deviation of 229.1. Moreover, the max solving time is 55% slower than
the min solving time. With EPSrd, the min and the max solving times of gr666
are respectively 855 s and 930 s with a standard deviation of 30.1. Then, the
max solving time is 9% slower than the min solving time. Finally, the ratio of
max/min for EPS is between 1.0 and 7.2 whereas it is between 1.1 and 1.3 for
EPSrd. Then, EPSrd brings more robustness in the solving times than EPS.

170
N. Isoart and J.-C. R´egin
Table 6. Comparison of the robustness of EPS and EPSrd.
EPS
EPSrd
min
max
mean
s.d.
max/min
min
max
mean
s.d.
max/min
a280
1.5
2.0
1.7
0.2
1.3
1.6
1.9
1.7
0.1
1.2
ali535
3,827.2
4,400.1
4,072.5
241.2
1.1
447.5
561.7
478.3
47.0
1.3
d198
13.4
40.0
19.2
11.6
3.0
13.1
14.7
13.8
0.6
1.1
d493
2,247.2
4,784.6
3,229.2
1,175.3
2.1
858.0
1,092.2
979.8
104.8
1.3
gil262
106.0
125.3
115.3
7.0
1.2
28.1
35.1
30.9
2.8
1.2
gr229
39.6
41.4
40.9
0.7
1.0
16.2
18.0
17.0
0.7
1.1
gr431
169.4
180.8
173.8
4.4
1.1
78.9
84.8
82.2
2.6
1.1
gr666
1,003.2
1,555.2
1,180.0
229.1
1.6
854.8
930.0
904.2
30.1
1.1
kroA200
6.1
8.1
6.6
0.9
1.3
5.9
7.3
6.6
0.7
1.2
kroB150
2.5
2.6
2.5
0.0
1.0
2.5
3.0
2.7
0.2
1.2
kroB200
4.2
4.6
4.4
0.1
1.1
5.4
6.6
6.0
0.4
1.2
lin318
3.4
3.6
3.5
0.1
1.1
3.3
4.2
3.5
0.4
1.3
pcb442
3,288.8
23,783.8
11,776.5
8,244.6
7.2
159.5
195.1
180.8
16.4
1.2
pr136
1.7
1.7
1.7
0.0
1.0
1.3
1.7
1.5
0.2
1.3
pr264
12.8
14.2
13.6
0.5
1.1
15.3
17.5
16.3
0.8
1.1
pr299
1,412.1
3,160.6
2,222.7
656.9
2.2
189.9
211.3
198.8
10.1
1.1
rat195
4.5
4.9
4.8
0.2
1.1
5.3
6.4
5.7
0.4
1.2
rd400
560.9
759.9
644.9
74.7
1.4
130.6
142.3
137.6
4.5
1.1
6
Conclusion
In this paper, we focused on the parallel solving of diﬃcult TSP problems with
EPS. We identiﬁed three major issues: unstable decomposition, non-monotonic
decomposition and extremely heterogeneous sub-problems. It has been shown
that the use of a stopping criterion while decomposing can solve the non-mo-
notonic decomposition issue [12]. We have shown that EPSrd, which uses a
re-decomposition, improves EPS by solving the two other issues. Indeed, a re-
decomposition allows the use of a small ﬁrst decomposition and it allows avoiding
the case of too small a proportion of workers working because of some extremely
heterogeneous problems. Experimentally, we have been able to deﬁne that a
small number of sub-problems per worker leads the best results when using
EPSrd because the load balancing is managed by the re-decomposition.
References
1. Burton, F.W., Sleep, M.R.: Executing functional programs on a virtual tree of
processors. In: Proceedings of the 1981 Conference on Functional Programming
Languages and Computer Architecture, FPCA 1981, pp. 187–194. ACM, New York
(1981)
2. Fages, J., Lorca, X., Rousseau, L.: The salesman and the tree: the importance of
search in CP. Constraints 21(2), 145–162 (2016)
3. Galea, F., Le Cun, B.: Bob++: a framework for exact combinatorial optimiza-
tion methods on parallel machines. In: International Conference High Performance
Computing & Simulation 2007 (HPCS 2007) and in conjunction with The 21st
European Conference on Modeling and Simulation (ECMS 2007), pp. 779–785,
June 2007

Improving the Robustness of EPS to Solve the TSP
171
4. Halstead, R.: Implementation of multilisp: lisp on a multiprocessor. In: Proceedings
of the 1984 ACM Symposium on LISP and Functional Programming, LFP 1984,
pp. 9–17. ACM, New York (1984)
5. Haralick, R., Elliot, G.: Increasing tree search eﬃciency for constraint satisfaction
problems. Artif. Intell. 14, 263–313 (1980)
6. Held, M., Karp, R.M.: The traveling-salesman problem and minimum spanning
trees. Oper. Res. 18(6), 1138–1162 (1970)
7. Held, M., Karp, R.M.: The traveling-salesman problem and minimum spanning
trees: Part II. Math. Program. 1(1), 6–25 (1971)
8. Helsgaun, K.: An eﬀective implementation of the Lin-Kernighan traveling salesman
heuristic. Eur. J. Oper. Res. 126(1), 106–130 (2000)
9. Isoart, N.: The traveling salesman problem in constraint programming. Ph.D. the-
sis, Universit´e Cˆote d’Azur (2021)
10. Isoart, N., R´egin, J.-C.: Integration of structural constraints into TSP models. In:
Schiex, T., de Givry, S. (eds.) CP 2019. LNCS, vol. 11802, pp. 284–299. Springer,
Cham (2019). https://doi.org/10.1007/978-3-030-30048-7 17
11. Isoart, N., R´egin, J.-C.: Adaptive CP-based Lagrangian relaxation for TSP solving.
In: Hebrard, E., Musliu, N. (eds.) CPAIOR 2020. LNCS, vol. 12296, pp. 300–316.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58942-4 20
12. Isoart, N., R´egin, J.-C.: Parallelization of TSP solving in CP. In: Simonis, H. (ed.)
CP 2020. LNCS, vol. 12333, pp. 410–426. Springer, Cham (2020). https://doi.org/
10.1007/978-3-030-58475-7 24
13. Isoart, N., R´egin, J.: A k-opt based constraint for the TSP. In: Michel, L.D. (ed.)
27th International Conference on Principles and Practice of Constraint Program-
ming, CP 2021, Montpellier, France (Virtual Conference), 25–29 October 2021.
LIPIcs, vol. 210, pp. 30:1–30:16. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Infor-
matik (2021)
14. Isoart, N., R´egin, J.: A linear time algorithm for the k-cutset constraint. In: Michel,
L.D. (ed.) 27th International Conference on Principles and Practice of Constraint
Programming, CP 2021, Montpellier, France (Virtual Conference), 25–29 October
2021. LIPIcs, vol. 210, pp. 29:1–29:16. Schloss Dagstuhl - Leibniz-Zentrum f¨ur
Informatik (2021)
15. Korf, R.: Depth-ﬁrst iterative-deepening: an optimal admissible tree search. Artif.
Intell. 27, 97–109 (1985)
16. Le Cun, B., Menouer, T., Vander-Swalmen, P.: Bobpp (2007). http://forge.prism.
uvsq.fr/projects/bobpp
17. Lecoutre, C., Sais, L., Tabary, S., Vidal, V., et al.: Nogood recording from restarts.
In: IJCAI, vol. 7, pp. 131–136 (2007)
18. Lecoutre, C., Sa¨ıs, L., Tabary, S., Vidal, V.: Reasoning from last conﬂict(s) in
constraint programming. Artif. Intell. 173(18), 1592–1614 (2009)
19. Lee, J., Schulte, C., Zhu, Z.: Increasing nogoods in restart-based search. In: Pro-
ceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 30 (2016)
20. Lin, S., Kernighan, B.: An eﬀective heuristic algorithm for the traveling-salesman
problem. Oper. Res. 21, 498–516 (1973)
21. Malapert, A., R´egin, J., Rezgui, M.: Embarrassingly parallel search in constraint
programming. J. Artif. Intell. Res. (JAIR) 57, 421–464 (2016)
22. Perron, L.: Search procedures and parallelism in constraint programming. In: Jaf-
far, J. (ed.) CP 1999. LNCS, vol. 1713, pp. 346–360. Springer, Heidelberg (1999).
https://doi.org/10.1007/978-3-540-48085-3 25

172
N. Isoart and J.-C. R´egin
23. R´egin, J.-C., Malapert, A.: Parallel constraint programming. In: Hamadi, Y., Sais,
L. (eds.) Handbook of Parallel Constraint Reasoning, pp. 337–379. Springer, Cham
(2018). https://doi.org/10.1007/978-3-319-63516-3 9
24. R´egin, J.-C., Rezgui, M., Malapert, A.: Improvement of the embarrassingly parallel
search for data centers. In: O’Sullivan, B. (ed.) CP 2014. LNCS, vol. 8656, pp. 622–
635. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-10428-7 45
25. R´egin, J.-C., Rezgui, M., Malapert, A.: Embarrassingly parallel search. In: Schulte,
C. (ed.) CP 2013. LNCS, vol. 8124, pp. 596–610. Springer, Heidelberg (2013).
https://doi.org/10.1007/978-3-642-40627-0 45
26. Reinelt, G.: TSPLIB-a traveling salesman problem library. ORSA J. Comput. 3(4),
376–384 (1991)
27. Vidal, V., Bordeaux, L., Hamadi, Y.: Adaptive K-parallel best-ﬁrst search: a simple
but eﬃcient algorithm for multi-core domain-independent planning. In: Proceed-
ings of the Third International Symposium on Combinatorial Search. AAAI Press
(2010)

Eﬃcient Operations Between MDDs
and Constraints
Victor Jung(B) and Jean-Charles R´egin
Universit´e Cˆote d’Azur, CNRS, I3S, Sophia-Antipolis, France
{victor.jung,jean-charles.regin}@univ-cotedazur.fr
Abstract. Many problems can be solved by performing operations
between Multi-valued Decision Diagrams (MDDs), for example in music
or text generation. Often these operations involve an MDD that repre-
sents the result of past operations and a new constraint. This approach is
eﬃcient, but it is very diﬃcult to implement with some constraints such
as alldifferent or cardinality constraints because it is often impossible
to represent them by an MDD because of their size (e.g. a permutation
constraint involving n variables requires 2n nodes).
In this paper, we propose to build on-the-ﬂy MDDs of structured con-
straints as the operator needs them. For example, we show how to realise
the intersection between an MDD and an alldifferent constraint by
never constructing more than the parts of the alldifferent constraint
that will be used to perform the intersection. In addition we show that
we can anticipate some reductions (i.e. merge of MDD nodes) that nor-
mally occur after the end of the operation.
We prove that our method can be exponentially better than building
the whole MDD beforehand and we present a direct application of our
method to construct constraint MDDs without having to construct some
intermediate states that will be removed by the reduction process.
At last, we give some experimental results conﬁrming the gains of our
approach in practice.
1
Introduction
Multi-valued and binary decision diagrams (MDDs/BDDs) took an important
place in modern optimisation techniques. From the theory to the applications,
MDDs have shown a large interest in operational research and optimisation
[1,2,7,10,15,18]. They oﬀer a broad range of modeling and solving possibilities,
from being a basic block of constraint solvers [6,13], to the development of MDD-
based solvers [3,9,19].
MDDs are a very eﬃcient graph-based data structure to represent a set of
solutions in a compressed way. The fundamental reasons of their use is their
exponential compression power. A polynomial size MDD have the capacity to
represent an exponential size set of tuples. For example in a music schedul-
ing problem [16], an MDD having 14, 000 nodes and 600, 000 arcs stored 1090
meaningful tuples of size one hundred. Unlike trees, where each leaf represent a
solution, an MDD can have much fewer nodes and arcs than solutions.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 173–189, 2022.
https://doi.org/10.1007/978-3-031-08011-1_13

174
V. Jung and J.-C. R´egin
MDDs are also often reduced, that is a reduction operation is applied to
them. The reduction operation of an MDD merges equivalent nodes until a ﬁx
point is reached. It may reduce the size of an MDD by an exponential factor.
Several other operators are available to combine MDDs without decompress-
ing them. The most important are the intersection, which corresponds to a con-
junction of two constraints, and the union, which corresponds to a disjunction
of two constraints and the negation.
Some problems can be solved by a succession of operations applied on MDDs
[8,14,16]. In other words, there is no search procedure that is used. To do so,
the diﬀerent constraints are represented by MDDs, and they are combined by
applying operators between these diﬀerent MDDs. In this way, all solutions can
be computed at once. However, even if the ﬁnal solution can ﬁt into memory,
it is possible that the memory explodes during the intermediate computation
steps - worse, it is even quite frequent that the MDD of the constraints are
themselves too big to ﬁt in memory because they are exponential, as for most
cardinality constraints (e.g. alldifferent and global cardinality constraints).
One solution to be able to represent such constraints is to relax them [4,10]: we
gain memory in exchange for the loss of information. Usually, a relaxed MDD is
an MDD representing a super set of the solutions of an exact MDD. Preferably,
these relaxed MDDs are smaller than their exact versions. In general in such
techniques, the total size is a ﬁxed given parameter, which has a strong impact
on the quality of the relaxation. Even if this approach is eﬃcient, it can still be
unsatisfactory to a certain extent. The ideal would be to be able to perform the
computations while remaining exact. This is what interests us in this article: to
be exact. In particular, we are interested in being able to perform operations
without having to represent the whole constraint’s MDD in order to avoid the
problem of the intermediate representation.
More precisely the question we consider in this paper is: how can we compute
an operation between a given MDD and the MDD of a constraint without con-
suming too much memory? We need to answer this question even if the MDD
of the constraint cannot ﬁt into memory. A simple example is the intersection
between an MDD involving ﬁfty variables and the MDD representing an alld-
ifferent constraints on these variables. This latter MDD will have 250 nodes
(i.e. 1, 000, 000 Giga nodes) and so is too big to ﬁt in memory.
The main ideas of this paper are to avoid building the MDD of the constraint
before applying the operation and to anticipate the reduction of the obtained
MDD.
The ﬁrst idea can be implemented by using operators that proceed by layer
[14] because we can avoid building in advance the MDD of the constraint. Dur-
ing the operation, if a node can hold all the information necessary to build its
children in a way that satisﬁes the constraint, then we do not need to retain all
previous nodes. Thus, we can perform the construction having only at most two
layers in memory (the current layer and the next one being built). Furthermore,
if an arc does not exist in the ﬁrst MDD, then it does not need to exist in the

Eﬃcient Operations Between MDDs and Constraints
175
constraint’s MDD: building the MDD during the operation allows us to have
more gain by only representing what is necessary to be represented.
The second idea is based on the remark that a constraint is useless when
we can make sure that it will always be satisﬁed. For instance if 3 variables
remains and if we know that they have disjoint domains then an alldifferent
constraints between these variables is useless. Thus, we can avoid deﬁning the
constraint’s MDD and we can immediately merge some nodes that would have
been merged by the reduction process and so gaining some space in memory.
The advantage of this approach is that it can provably gain an exponential
factor in space. It has also a direct application to construct constraint MDDs
without having to construct all intermediate states. This allows either to build
constraint MDDs that cannot be built otherwise, or to build them much faster.
We also show that processing several constraints simultaneously is not advan-
tageous compared to doing the operations successively for each constraint. This
is due to the lack of reduction which is normally performed after each operation
and which can strongly reduce the resulting.
The paper is organised as follows. First, we enrich the classical internal data
of an MDD with several notions: we introduce the notion of node states allowing
to represent the information associated with the node with respect to a certain
constraint, the notion of transition function δC(s, v) and the notion veriﬁca-
tion function VC(s) allowing respectively to make the state of a node evolve by
performing a transition of value v and to verify if a state is satisfying the con-
straint (absence of violation). Then, we elaborate on the importance of perform-
ing merges to have some control over the growing behavior of some constraints,
by giving for each constraint described in the article the conditions to perform a
merge. In addition, we try to convey some intuition of the potential gain behind
these merges, which might greatly depend on the constraint’s parameters. Next,
we give for each of these constraints a possible implementation of the state and
functions δC(s, v) and VC(s), as well as a generic algorithm allowing to perform
an on-the-ﬂy intersection operation based on the notions described. We also
give the size of the MDD representing each constraint. Afterwards, we prove
that building the constraint’s MDD on the ﬂy can be exponentially better than
building the whole MDD beforehand. Finally, we present a direct application to
compute constraint MDDs and we give some experimental results, notably for
the car sequencing problem and we study the generalisation of our method for
a set of constraints. At last, we conclude.
2
Preliminaries
2.1
Constraint Programming
A ﬁnite constraint network N is deﬁned as a set of n variables X = {x1, . . . , xn},
a set of current domains D = {D(x1), . . . , D(xn)} where D(xi) is the ﬁnite set
of possible values for variable xi, and a set C of constraints between variables.
We introduce the particular notation D0 = {D0(x1), . . . , D0(xn)} to represent
the set of initial domains of N on which constraint deﬁnitions were stated. A

176
V. Jung and J.-C. R´egin
constraint C on the ordered set of variables X(C) = (xi1, . . . , xir) is a subset
T(C) of the Cartesian product D0(xi1)×· · ·×D0(xir) that speciﬁes the allowed
combinations of values for the variables xi1, . . . , xir. An element of D0(xi1)×· · ·×
D0(xir) is called a tuple on X(C). A value a for a variable x is often denoted by
(x, a). Let C be a constraint. A tuple τ on X(C) is valid if ∀(x, a) ∈τ, a ∈D(x).
C is consistent iﬀthere exists a tuple τ of T(C) which is valid. A value a ∈D(x)
is consistent with C iﬀx ̸∈X(C) or there exists a valid tuple τ of T(C) with
(x, a) ∈τ. We denote by #(a, τ) the number of occurrences of the value a in a
tuple τ.
We present some constraints that we will use in the rest of this paper.
Deﬁnition 1. Given X a set of variables and [l, u] a range, the sum constraint
ensures that the sum of all variables x ∈X is at least l and at most u.
sum(l, u) = {τ | τ is a tuple on X(C) and l ≤
i=0 τi ≤u}.
A global cardinality constraint (gcc) constrains the number of times every
value can be taken by a set of variables. This is certainly one of the most useful
constraints in practice. Note that the alldifferent constraint corresponds to
a gcc in which every value can be taken at most once.
Deﬁnition 2. A global cardinality constraint is a constraint C in which
each value ai ∈D(X(C)) is associated with two positive integers li and ui with
li ≤ui deﬁned by
gcc(X, l, u) = {τ|τ is a tuple on X(C) and ∀ai ∈D(X(C)) : li ≤#(ai, τ) ≤
ui}.
2.2
Multi-valued Decision Diagram
The decision diagrams considered in this paper are reduced, ordered multi-valued
decision diagrams (MDD) [2,12,17], which are a generalisation of binary decision
diagrams [5]. They use a ﬁxed variable ordering for canonical representation and
shared sub-graphs for compression obtained by means of a reduction operation.
an MDD is a rooted directed acyclic graph (DAG) used to represent some multi-
valued functions f : {0...d −1}n →true, false. Given the n input variables, the
DAG contains n + 1 layers of nodes, such that each variable is represented at a
speciﬁc layer of the graph. Each node on a given layer has at most d outgoing arcs
to nodes in the next layer of the graph. Each arc is labeled by its corresponding
integer. The arc (u, a, v) is from node u to node v and labeled by a. Sometimes
it is convenient to say that v is a child of u. All outgoing arcs of the layer n
reach tt, the true terminal node (the false terminal node is typically omitted).
There is an equivalence between f(a1, ..., an) = true and the existence of a path
from the root node to the tt whose arcs are labeled a1, ..., an.
The reduction of an MDD is an important operation that may reduce the
MDD size by an exponential factor. It consists in removing nodes that have
no successor and merging equivalent nodes, i.e. nodes having the same set of
children associated with the same labels. This means that only nodes of the
same layer can be merged.

Eﬃcient Operations Between MDDs and Constraints
177
3
Generalisation of the Construction Process
Perez and R´egin [14] have explained how an MDD can be built directly from
functions deﬁning an automaton or a pattern. The general principle is to deﬁne
states and to link them by a transition function, which can be deﬁned globally or
for each level. In order to be more general and less dependent on automata theory,
we propose to generalize the previous concepts and to introduce a veriﬁcation
function. This is similar to what is done in [9,11].
By doing so, the notion of state, the function of transition δC(s, v) as well as
the veriﬁcation function VC(s), form a lightweight and general scheme allowing
an eﬃcient on the ﬂy construction of a constraint’s MDD.
3.1
State, Transition and Veriﬁcation
The notion of state holds some information in an MDD node about the constraint
representation, giving it an actual meaning: for the sum constraint, a state will
hold the value of the sum for the current node. Given that piece of information,
we will be able to build all the valid successors of a node.
In order to build the MDD layer by layer, i.e. to build the children of a node,
we deﬁne a transition function on the nodes: this transition function takes into
account the current state s of a node and the constraint C. Given a certain state,
we need to build all successors of a node such that the state of each successor
satisﬁes the constraint C.
Let δC(s, v) be the transition function that builds a new state from a state
s and a label v and VC(s) the veriﬁcation function that checks whether a state
s satisﬁes the constraint or not.
Thanks to these notions we can deﬁne the following property:
Property 1. Nodes of the same layer with the exact same state can be merged.
Proof. The transition function δC takes into account the constraint C and the
current state s to build the successors of a node. The constraint C being invariant
during the construction process, it means that for a given layer if s1 = s2, then
δC(s1) = δC(s2). In an MDD, two nodes can be merged if they have the same
successors: therefore, we can merge two nodes having the same state.
⊓⊔
Immediate Merges. If during the construction of the MDD, we can clearly
see that some nodes will be merged during the reduce operation, then we can
immediately merge some states. However, merging states will result in the loss
of precision concerning the information represented. For instance, if two nodes
representing a sum s1 and s2 are merged, the result of this merge is the set
{s1, s2}. The node holding this state could be considered to be in both state s1
and s2 at the same time. Now, let’s imagine that we must have a sum satisfying
the range [10, 15], and that we have a merged state of [14, 15] for a given node:
can we add 1? The answer is yes when considering 14, and no when considering
15. This shows that, in order not to lose information about the constraint (i.e.

178
V. Jung and J.-C. R´egin
solutions), we have to be careful about what we merge - we cannot do it blind-
folded. In a general way, a node holding a merged state would mean that the
state of this node represents less information than the initial constraint (which
is the case for the gcc constraint), or in extreme cases that the state of the node
does not matter anymore (which is the case for the sum constraint).
For each constraint described in this article, we will detail: the total number of
states for the constraint, the conditions to perform a merge and its consequences
for the size of the MDD. Please note that the impact of the merges on the size
highly depends on the constraint and its parameters.
We will now present a possible implementation for the sum, gcc, and alld-
ifferent constraints. Henceforth, we will refer to the transition function δ as
createState and the veriﬁcation function VC as isValid.
3.2
Sum
Fig. 1. Merged states in the
sum, with min = 4 and max
= 9. The merged path (red)
necessarily lead to tt, what-
ever the value taken.
Representation. The sum constraint is simply
represented by the minimum min and maximum
max value of the sum. For convenience purposes,
we also add the minimum vmin and maximum vmax
value of D, the union of the domains of the variables
involved in the constraint.
The state is represented by a single integer sum
(Fig. 1).
Transition and Validity. Creating a state means
to add the label’s value to the current sum, and a
transition is valid if the obtained sum belongs in the
constraint’s bounds (See Algorithm 1).
Number of States. The number of states at layer i is at most i × (vmax −
vmin + 1). The total number of states in the MDD is therefore at most:
2 +
n−1

i=1
i × (vmax −vmin + 1) = 2 + (n −1)2 + (n −1)
2
× (vmax −vmin + 1)
This upper bound is achieved when the set of values D is an integer range. This
number can also be bounded by the upper and lower bounds of the sum.
Merging Condition. Let s be the state representing a sum. If min ≤s + (n −
layer) × vmin and s + (n −layer) × vmax ≤max, then we are certain to satisfy
the constraint no matter what values we assign next. Therefore, we can drop the
state of the node. Table 1 gives some experimental results of immediate merges.

Eﬃcient Operations Between MDDs and Constraints
179
Algorithm 1. Sum State
createState(constraint, state, label, layer, n): state
nextState.sum ←state.sum + label;
return nextState;
isValid(constraint, state, label, layer, n): boolean
minReach ←state.sum + label + (n −layer) × constraint.vmin;
maxReach ←state.sum + label + (n −layer) × constraint.vmax;
// We cannot reach the minimum sum or go below the maximum
if (maxReach < constraint.min ∨minReach > constraint.max) then
return false;
return true;
Table 1. Impact of immediate merges on the number of nodes created and memory
consumption for the sum constraint
With merges
Without merges
min max
n
|V | #nodes memory (MB) #nodes memory (MB)
20
200
50
10
6204
29
7914
35
124
480
200
14
82349
448
87047
472
500 1000 200
10
117864
456
131504
506
500 1000 200
20
161720
1192
168051
1242
3.3
GCC
Representation. To represent the gcc constraint, we need: the set V of con-
strained values, and the minimum lbv and maximum ubv occurrences of each
speciﬁc value v ∈V . To represent the state, we only need a array count that
contains the number of occurrences of each value v ∈V . We also deﬁne another
variable named minimum that counts the minimum number of layers required
to reach all the lower bounds of values.
Transition and Validity. Creating a new state means adding 1 to the counter
of the value of the label we take if this value is constrained. A transition is valid
if we can reach the lower bounds with the remaining layers, and if the added
value of the label is not greater than its upper bound (always true if the value
is not constrained, of course). Algorithm 2 is a possible implementation.
Notation 1
• n is number of variables and layer the index of the current layer.
• ∀v ∈V : cv is the number of times v is assigned, lbv the lower bound of v and
ubv the upper bound of v.

180
V. Jung and J.-C. R´egin
Number of States. The number of states in a gcc is at most:

v∈V
ubv
because this is the number of count tuples that can be represented by the numeral
system deﬁned by the gcc.
Merging Condition
Property 2. We can remove the count cv of value v from the state iﬀ:
(n −layer ≤ubv −cv) ∧(lbv ≤cv + max(0, (n −layer) −

i̸=v
(ui −ci)))
If the number of variables left to assign is less than the number of times we can
assign the value v, and if the lower bound lbv is reached, then it means that,
no matter how many times we assign the value v to the future variables, we are
certain to be in the range [lbv, ubv].
Example: Let the bound [lbv, ubv] = [10, 20], cv = 10 and n−layer = 10. Then,
we can have a merged state [cv, cv + i] = [10, 10 + i] up to i = n −layer = 10.
In that case, the value v can be ignored (i.e. deleted) by the state because, no
matter what choices we make, we are assured to satisfy the constraint: there is
therefore no need to take into account v.
Table 2 gives some experimental results of immediate merges.
Table 2. Impact of immediate merges on the number of nodes created and memory
consumption for the gcc constraint
With merges
Without merges
#nodes memory (MB) #nodes memory (MB)
405081
3308
543196
4300
58385
450
100341
715
5064
44
40558
266
430076
3584
470801
3849
3.4
AllDiﬀerent
Representation. The alldifferent constraint is simply a gcc constraint for
which the set of values V contains all values and each value can only be assigned
once. We represent the state by the set of previously assigned values.
Transition and Validity. A transition is valid if the label is not already
assigned. To create a new state, we simply copy the current state (i.e. the set of
assigned values) and add to it the new label (See Algorithm 3).

Eﬃcient Operations Between MDDs and Constraints
181
Algorithm 2. GCC State
createState(constraint, state, label, layer, n): state
count ←∅;
min ←state.minimum;
potential ←n −layer −1;
for each value v ∈state.count do
if state.count[v] < constraint.min[v] then count[v] ←state.count[v]
if state.count[v] + potential > constraint.max[v] then
count[v] ←state.count[v]
if label ∈count then
if state.count[label] < constraint.min[label] then min ←min −1;
// If we are sure to satisfy the constraint for the label
if (constraint.min[label] ≤count[label]+1)∧(count[label]+n−layer ≤
constraint.max[label]) then count.remove(label);
else count[label] ←count[label] + 1
nextState.count ←count;
nextState.minimum ←min;
return nextState;
isValid(constraint, state, label, layer, n): boolean
potential ←n −layer −1;
min ←state.minimum;
if label /∈state.count.values then return min ≤potential;
value ←state.count[label];
if value < constraint.min[label] then min ←min −1;
return (min ≤potential) ∧(value + 1 ≤constraint.max[label]);
Number of States. The number of states in the ith layer for a given set of
constrained values V is
|V |
i

. Therefore, the total number of nodes in the MDD
is:
2n ≤
n

i=0
|V |
i

≤2|V |
Merging Condition. The alldifferent constraint can be seen as a gcc
constraint where all values v ∈V are associated with the range [0, 1]. Thus, the
merging conditions for the alldifferent constraint is the same as the gcc
under the described parameters: it means that we can only merge during the
last layer, which is negligible.
3.5
Generic Constraint Intersection Function
This function is a possible implementation of the generic constraint intersection
function. It is based on Functions deﬁned in [14]. It shows that we do not need to
store the full MDDc and that we build the next layer only knowing the current
layer.

182
V. Jung and J.-C. R´egin
Algorithm 3. alldifferent State
createState(constraint, state, label, layer, n): state
values ←∅;
for each v ∈state.values do values.append(v);
if label ∈constraint.values then values.append(label);
nextState.values ←values;
return nextState;
isValid(constraint, state, label, layer, n): boolean
return label /∈state.values
Algorithm 4. Generic Constraint Intersection Function.
applyInter(mdd1, constraint, rootc): MDD
// When creating a node, we associate it with one node from each MDD
root ←createNode(root(mdd1), rootc) ;
L[0] ←{root} // L[i] is the set of nodes in layer i. ;
C[0] ←{rootc};
for each i ∈1..n do
L[i] ←∅; C[i] ←∅;
for each node x ∈L[i −1] do
get x1 and x2 from x = (x1, x2) ;
for each v ∈childOf(x1) do
if v ̸∈childOf(x2)∧isValid(constraint, x2.state, v, i −1, r)
then
y2 ←createNode();
y2.state ←createState(constraint, x2.state, v, i −1, r);
addChild(x2, v, y2);
C[i].append(y2);
// Add the arc between x and the node deﬁned by y = (y1, y2)
// The node y will be added to the MDD if it is not yet in it.
addArcAndNode(L, i, x, v, y1, y2) ;
destroy(C[i −1]) // Remove previous constraint layer from memory ;
merge all nodes of L[n] into t;
pReduce(L) ;
return root ;
4
Exponential Gain
Theorem 1. Building the MDD of a constraint on the ﬂy can be exponentially
better in terms of space and time than building the whole MDD beforehand.
Proof. We show how to perform an intersection between MDDx, an MDD, and
MDDAD the MDD of an alldifferent constraint. Let x be a number of sets,
MDDx is built as follows (See Fig. 2 for x = 3 and |X| = 3):
– Step 1 - Generate MDDU(X) a universal MDD with domain X. This means
that the variables can take any value in X.

Eﬃcient Operations Between MDDs and Constraints
183
– Step 2 - Copy the MDD from step 1 for x sets having a cardinality equal to
|X| and make the union of them. We denote by MDDV the obtained MDD.
– Step 3 - Copy x times MDDV , and concatenate them.
Fig. 2. Final step. For
convenience
purposes,
we represent only one
arc for a whole set of
values.
The size of MDDAD is exponential (i.e. at least 2n).
So, when n is large, it is not possible to build it. However,
the size of MDDx ∩MDDAD is exponentially smaller
than the size of MDDAD, and our method is able to
compute this intersection as shown by the following pro-
cess:
1. The number of nodes in the MDDAD involving all the
variables is 2|X|×x, being (2|X|)x.
2. MDDV is the union of x universal MDDs. The inter-
section between a universal MDD and MDDC (i.e. the
MDD of a constraint C) is MDDC. So, for any set X,
the intersection between MDDU(X) and MDDAD is
equal to MDDAD which has 2|X| nodes.
3. We can simplify by stating that each MDDU(X) is
an arc. The shape of our MDD is therefore the one of
a universal MDD. Thus, the same observation that in
2. applies: the simpliﬁed MDD intersecting with the
alldifferent constraint is the MDD of the alld-
ifferent constraint. It is denoted by metaMDDAD.
4. If we know the number of arcs in our metaMDDAD,
we can deduce the number of nodes created during
the intersection.
5. The layer i of metaMDDAD contains
x
i

nodes.
6. Each node in the layer i has (x – i) out-going arcs
(because we already chose i values of the x possible).
7. By combining (5) and (6), the total number of arcs
in our metaMDDAD is x
i=0
x
i

× (x −i) = x × 2x−1
8. By combining (2) and (7), the total number of nodes
in our metaMDDAD is x×2x−1×2|X| = x×2|X|+x−1,
because each arc of metaMDDAD is an MDDAD(X)
involving |X| variables.
9. The diﬀerence between (8) x × 2|X|+x−1 and (1)
(2|X|)x is exponential.
⊓⊔
We perform some benchmarks to experimentally conﬁrm this gain.
4.1
Building the AllDiﬀerent’s MDD
Table 3 shows that the alldifferent constraint quickly becomes impossible to
construct: after barely 24 values it is impossible to represent the constraint.

184
V. Jung and J.-C. R´egin
Table 3. Construction of the alldifferent MDD with size variation
|V|
Memory (MB)
Time (s) Layer
20
8840
12.363
20
21
18789
27.476
21
22
39675
62.850
22
23
83619
134.696
23
24
Out of memory (≥100 GB)
160.894
13
4.2
Performing the Construction on the Fly
The results of Table 4 show that by constructing the alldifferent’s MDD on
the ﬂy, it is possible to compute intersections with a lot of values (here between
|V | = 25 and |V | = 100) very eﬃciently. We notice that, when we increase the
number of sets, the intersection becomes more and more diﬃcult to compute:
this testiﬁes to the exponential behaviour of the constraint.
Table 4. Evolution of Time (ms) and Memory (MB) consumption for MDDAD inter-
section according to the variation of the number and size of sets (A, B, C in Fig. 2).
The number of variables is equal to Number × Size.
)
B
M
(
y
r
o
m
e
M
)
s
m
(
e
m
i
T
Number
Size
5
6
7
8
9
10
5
6
7
8
9
10
5
8
16
36
84
192
424
50
22
53
128
284
665
6
19
36
132
212
492
1096
53
58
167
348
852
2042
7
44
96
224
524
1232
2748
101
151
374
930
2312
5613
8
101 257
548 1273 2993
8129
216
403
984
2456
6116
15433
9
241 564 1397 3384 7814 15957
543 1010 3042 6605 16012 50836
10
556 1348 3144 7116 16649 39073 1211 3079 6600 15308 37723 137917
The second test (Table 5) is a variant of the ﬁrst one (Table 4). Arcs are added
randomly between several sets, which as a consequence drastically increases the
number of states in the MDD. The result is that intersection becomes impossible
very quickly: for 6 sets and 6 values by set, we have a factor of 5 200 in time.
Table 5. Evolution of Time (ms) and Memory (MB) consumption for the alldiffer-
ent MDD intersection according to the variation of the number and size of sets with
random arcs added between sets
Number
Size
5
6
Time Memory #Arcs Time Memory #Arcs
5
322
107
6
2753
505
6
6
7059
2513
6
187061
53981
7

Eﬃcient Operations Between MDDs and Constraints
185
5
Application: Construction of the MDD of Constraints
In this section, we show that our method can be useful to build the MDD of
some constraints and not only to perform some intersections.
Consider C a constraint. Suppose that the construction of MDDC, the MDD
of C, is problematic because a very large number of intermediate states are
generated but do not appear in the reduced MDDC. As the reduction can gain
an exponential factor this case is quite conceivable. It occurs, for example, with
a bounded sum of variables that can take very diﬀerent values. The number
of states created is therefore huge, but it is quite possible that the reduction
induced by the bounds on the sum removes a large part of them.
This kind of constraint can either prevent us from building the MDD due to
lack of memory to store all the intermediate states, or require a lot of time to
compute. To remedy these problems we propose to use successively our method
on relaxations of MDDC allowing to deal with smaller MDDs.
This approach assumes that it is possible to deﬁne diﬀerent relaxations of
MDDC more or less strong. We recall that an MDD is a relaxation of an MDD
if it represents a super set of the solutions of the exact MDD. In addition,
we assume that the relaxation has fewer nodes. This is achievable by merging
nodes for relaxing the MDD, which is quite usual. Thus, we suppose that we
have MDDs noted Relax(MDDC,p) which are relaxations of MDDC according
to a parameter p such that p < q implies Relax(MDDC,p) is smaller than or
equal to Relax(MDDC,q). The value of p can be ad hoc. For example, for a
sum constraint, a relaxation is simply to consider the numbers up to a given p
precision. Thus we can merge many more states and the greater the precision
the less the MDD is relaxed.
For convenience we will consider that Relax(MDDC,n) is MDDC. Then, we
can compute MDDC by applying the following process named OTF Inc:
1. Let M ←Relax(MDDC,p)
2. Compute M ′ by performing the intersection on the ﬂy between M and
Relax(MDDC,p + 1)
3. Set p ←p + 1, and M ←M ′
4. If p < n then goto 2 else return M
6
Experiments
6.1
Constraint Building
We consider the following stochastic problem: there are n variables with domains
having the same size. The values represent the chance for an event to appear. A
solution is a combination of events such that their chance to happen simultane-
ously is above a certain threshold, for instance 75%. This problem is equivalent
to a bounded product of variables. The goal is to build the MDD containing all
the solutions. It is equivalent to building the MDD of CΠ the constraint deﬁning

186
V. Jung and J.-C. R´egin
a bounded product of variables. The diﬃculty is that values are quite diﬀerent
(because computed from other elements) leading to the lack of collision.
We propose to compute the MDD of this problem by using the process OTF
Inc deﬁned in Sect. 5. We deﬁne Relax(MDDCΠ,p) by the MDD of CΠ for which
the variables have been rounded to a precision p (i.e. the number of decimal
places after the decimal point).
We test the method on diﬀerent sets of data (available upon request). Each
set involves values between 0.95 and 1 with at least 4 digits. The combined
probability must be greater than 0.9. We compare the time and memory needed
to compute the MDD using OTF Inc and the MDD directly computed (Base),
both for a ﬁnal precision p = 8, starting from p = 0. Table 6 shows that we
obtain a factor of at least 9 both in time and in memory. We achieve up to a
factor of 77.55 in time (181.5 s vs 2.6 s) and 19 in memory (405 MB vs 7 617 MB)
for the hardest dataset (set 5).
Table 6. Time (ms) and memory (MB) needed to compute the exact MDD.
Time (ms)
Memory (MB)
Set
OTF Inc
Base
Ratio OTF Inc
Base
Ratio
Set 1
1 131
10 235
9.05
136
1 423 10.46
Set 2
1 877
17 970
9.57
266
2 584
9.71
Set 3
1 405
25 528
18.17
189
1 869
9.89
Set 4
1 974
61 904
31.36
289
3 854 13.34
Set 5
2 642
181 468 77.55
405
7 617 18.81
6.2
The Car Sequencing Problem
A number of cars are to be produced. There are diﬀerent options available to
customise a car, and it is possible that a car has to be built with several options
(paint job, sunroof, ABS, etc.). Each option is installed in a station that has
a maximum handling capacity: if, for example, a station installing an option A
can only handle one car in any two, then the assembly line must be designed in
such a way that there are never two cars in a row requiring the option A. This
constraint must be satisﬁed for each station. This problem is NP-complete.
All instances used in this article are available on csplib: https://www.csplib.
org/Problems/prob001/data/data.txt.html
We will use the following methods:
• OTF: On The Fly, the method presented in this article.
• OTF×: OTF performing operations with multiple constraints at once.
• Classic: The method that builds the MDD then performs the operation.
For the car sequencing problem it means that the ﬁnal MDD is built as follows:
for the classic method, we build the MDD containing all sequence constraints,

Eﬃcient Operations Between MDDs and Constraints
187
then we build the MDD of the gcc, and we perform the intersection between
these two MDDs. For the OTF method, we do the same as the classic method,
but the intersection with the gcc is done on the ﬂy (we do not build the gcc
MDD). Finally, for the OTF×, we directly compute the intersection between the
sequence and gcc, without building them explicitly.
Table 7. Problem 4/72 (Regin & Puget #1), Problem 19/71 (Regin & Puget #4) and
Problem 60-02 from CSPLib. Time measured in ms and Memory in MB.
Problem 4/72
Problem 19/71
#options Method
Time
Memory Layer Time Memory Layer
2
OTF
1042
187
100
915
127
100
OTF×
3435
712
100
5858
1274
100
Classic
5177
1684
100
4845
1356
100
3
OTF
665 628
90 614
100
73 019
15 724
100
OTF×
2 736 002 224 931
691∗
847 006 114 448
100
Classic
957 063
231 213
382∗
819 905 214 445
382∗
Problem 60-02
2
OTF
41 129
9 043
100
OTF×
315 825
33 986
100
Classic
51 975
11 059
100
3
OTF
1 960 854 212 669
413∗
OTF×
2 763 521 172 543
311∗
Classic
957 063
231 213
382∗
1∗: MO during intersection of sequence + gcc
2∗: MO during the construction of the gcc, after the sequence intersection
3∗: MO during the gcc intersection
Table 7 shows that it is possible to build an MDD that is not possible to
build otherwise (because the gcc explodes in memory). Thus, we can conclude
that an instance has no solution (Problem 19/71), which we could not do before.
In the case of larger problems, we still manage to observe a strong progression,
even if it remains insuﬃcient: where we could only build 38 layers of the gcc,
we manage to carry out the intersection with it up to layer 41 (Problem 60-02).
These results clearly show the advantage of this intersection method.
We notice that OTF× is systematically worse than the method doing them
one by one (Problem 4/72, Problem 60-02), and even worse in some cases than
Classic (Problem 60-02). This can be explained by the fact that the complexity
is proportional to the number of states constructed for each constraint. How-
ever, by making successive intersections, we observe a reduction in the number
of solutions, which can imply (and does imply in a general case) a reduction of
states. Performing several operations at the same time is therefore not interest-
ing, especially if the MDDs are easy to construct, i.e. they are not exponential
in memory like would be alldifferent or gcc.

188
V. Jung and J.-C. R´egin
7
Conclusion
This article shows that building constraints’ MDD during an operation is more
advantageous in every way than building the complete constraint’s MDD ﬁrst,
even if it does not prevent an explosion of memory. Moreover, this method shows
a major impact in performance for solving some well known problems or build-
ing MDDs of constraints. However, doing multiple constraints at once is not
necessarily better, and is shown to be worse most of times.
References
1. Andersen, H.R.: An Introduction to Binary Decision Diagrams (1999)
2. Bergman, D., Cir´e, A.A., van Hoeve, W., Hooker, J.N.: Decision Diagrams for Opti-
mization. Artiﬁcial Intelligence: Foundations, Theory, and Algorithms. Springer,
Heidelberg (2016). https://doi.org/10.1007/978-3-319-42849-9
3. Bergman, D., Cire, A.A., Van Hoeve, W.J., Hooker, J.N.: Discrete optimization
with decision diagrams. INFORMS J. Comput. 28(1), 47–66 (2016)
4. Bergman, D., van Hoeve, W.-J., Hooker, J.N.: Manipulating MDD relaxations for
combinatorial optimization. In: Achterberg, T., Beck, J.C. (eds.) CPAIOR 2011.
LNCS, vol. 6697, pp. 20–35. Springer, Heidelberg (2011). https://doi.org/10.1007/
978-3-642-21311-3 5
5. Bryant, R.E.: Graph-based algorithms for Boolean function manipulation. IEEE
Trans. Comput. 35(8), 677–691 (1986). https://doi.org/10.1109/TC.1986.1676819
6. Cheng, K.C.K., Yap, R.H.C.: An MDD-based generalized arc consistency algorithm
for positive and negative table constraints and some global constraints. Constraints
15(2), 265–304 (2010). https://doi.org/10.1007/s10601-009-9087-y
7. Davarnia, D., van Hoeve, W.: Outer approximation for integer nonlinear programs
via decision diagrams. Math. Program. 187(1), 111–150 (2021). https://doi.org/
10.1007/s10107-020-01475-4
8. Demassey, S.: Compositions and hybridizations for applied combinatorial optimiza-
tion. Habilitation `a Diriger des Recherches (2017)
9. Gentzel, R., Michel, L., van Hoeve, W.-J.: HADDOCK: a language and architec-
ture for decision diagram compilation. In: Simonis, H. (ed.) CP 2020. LNCS, vol.
12333, pp. 531–547. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
58475-7 31
10. Hadzic, T., Hooker, J.N., O’Sullivan, B., Tiedemann, P.: Approximate compilation
of constraints into multivalued decision diagrams. In: Stuckey, P.J. (ed.) CP 2008.
LNCS, vol. 5202, pp. 448–462. Springer, Heidelberg (2008). https://doi.org/10.
1007/978-3-540-85958-1 30
11. Hoda, S., van Hoeve, W.-J., Hooker, J.N.: A systematic approach to MDD-based
constraint programming. In: Cohen, D. (ed.) CP 2010. LNCS, vol. 6308, pp. 266–
280. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-15396-9 23
12. Kam, T., Brayton, R.K.: Multi-valued decision diagrams. Technical report.
UCB/ERL M90/125, EECS Department, University of California, Berkeley.
http://www2.eecs.berkeley.edu/Pubs/TechRpts/1990/1671.html
13. Perez, G., R´egin, J.-C.: Improving GAC-4 for table and MDD constraints. In:
O’Sullivan, B. (ed.) CP 2014. LNCS, vol. 8656, pp. 606–621. Springer, Cham
(2014). https://doi.org/10.1007/978-3-319-10428-7 44

Eﬃcient Operations Between MDDs and Constraints
189
14. Perez, G., R´egin, J.C.: Eﬃcient operations on MDDs for building constraint pro-
gramming models. In: International Joint Conference on Artiﬁcial Intelligence,
IJCAI 2015, Argentina, pp. 374–380 (2015)
15. Perez, G., R´egin, J.C.: Soft and cost MDD propagators. In: The Thirty-First AAAI
Conference on Artiﬁcial Intelligence (AAAI 2017) (2017)
16. Roy, P., Perez, G., R´egin, J.-C., Papadopoulos, A., Pachet, F., Marchini, M.:
Enforcing structure on temporal sequences: the Allen constraint. In: Rueher, M.
(ed.) CP 2016. LNCS, vol. 9892, pp. 786–801. Springer, Cham (2016). https://doi.
org/10.1007/978-3-319-44953-1 49
17. Srinivasan, A., Ham, T., Malik, S., Brayton, R.K.: Algorithms for discrete function
manipulation. In: 1990 IEEE International Conference on Computer-Aided Design.
Digest of Technical Papers, pp. 92–95 (1990). https://doi.org/10.1109/ICCAD.
1990.129849
18. Tjandraatmadja, C., van Hoeve, W.-J.: Incorporating bounds from decision dia-
grams into integer programming. Math. Program. Comput. 13(2), 225–256 (2020).
https://doi.org/10.1007/s12532-020-00191-6
19. Verhaeghe, H., Lecoutre, C., Schaus, P.: Compact-MDD: eﬃciently ﬁltering (s)
MDD constraints with reversible sparse bit-sets. In: IJCAI, pp. 1383–1389 (2018)

Deep Policy Dynamic Programming
for Vehicle Routing Problems
Wouter Kool1,2(B)
, Herke van Hoof1
, Joaquim Gromicho1,2
,
and Max Welling1
1 University of Amsterdam, Amsterdam, The Netherlands
w.w.m.kool@uva.nl
2 ORTEC, Zoetermeer, The Netherlands
Abstract. Routing problems are a class of combinatorial problems with
many practical applications. Recently, end-to-end deep learning methods
have been proposed to learn approximate solution heuristics for such
problems. In contrast, classical dynamic programming (DP) algorithms
guarantee optimal solutions, but scale badly with the problem size. We
propose Deep Policy Dynamic Programming (DPDP), which aims to
combine the strengths of learned neural heuristics with those of DP algo-
rithms. DPDP prioritizes and restricts the DP state space using a policy
derived from a deep neural network, which is trained to predict edges
from example solutions. We evaluate our framework on the travelling
salesman problem (TSP), the vehicle routing problem (VRP) and TSP
with time windows (TSPTW) and show that the neural policy improves
the performance of (restricted) DP algorithms, making them competi-
tive to strong alternatives such as LKH, while also outperforming most
other ‘neural approaches’ for solving TSPs, VRPs and TSPTWs with
100 nodes.
Keywords: Dynamic Programming · Deep Learning · Vehicle Routing
1
Introduction
Dynamic programming (DP) [7] is a powerful framework for solving optimization
problems by solving smaller subproblems through the principle of optimality [4].
Famous examples are Dijkstra’s algorithm [16] for the shortest route between
two locations, and the classic Held-Karp algorithm for the travelling salesman
problem (TSP) [5,26]. Despite their long history, dynamic programming algo-
rithms for vehicle routing problems (VRPs) have seen limited use in practice,
primarily due to their bad scaling performance. More recently, a line of research
has attempted the use of machine learning (especially deep learning) to auto-
matically learn heuristics for solving routing problems [6,9,36,50,64]. While the
results are promising, most learned heuristics are not (yet) competitive to ‘tra-
ditional’ algorithms such as LKH [27] and lack (asymptotic) guarantees on their
performance.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 190–213, 2022.
https://doi.org/10.1007/978-3-031-08011-1_14

Deep Policy Dynamic Programming for Vehicle Routing Problems
191
In this paper, we propose Deep Policy Dynamic Programming (DPDP) as a
framework for solving vehicle routing problems. The key of DPDP is to combine
the strengths of deep learning and DP, by restricting the DP state space (the
search space) using a policy derived from a neural network. In Fig. 1 it can be
seen how the neural network indicates promising parts of the search space as a
heatmap over the edges of the graph. This heatmap used by the DP algorithm
to ﬁnd a good solution. DPDP is more powerful than some related ideas [8,25,
42,69,70] as it combines supervised training of a large neural network with just
a single model evaluation at test time, to enable running a large scale guided
search using DP. The DP framework is ﬂexible as it can model a variety of
realistic routing problems with diﬃcult practical constraints [22]. We illustrate
this by testing DPDP on the TSP, the capacitated VRP and the TSP with (hard)
time window constraints (TSPTW).
Fig. 1. Heatmap predictions (red) and solutions (colored) by DPDP (VRP depot edges
omitted for clarity). The heatmap indicates only a small fraction of all edges as promis-
ing, while including (almost) all edges from the solution. (Color ﬁgure online)
Fig. 2. DPDP for the TSP. A GNN creates a (sparse) heatmap indicating promising
edges, after which a tour is constructed using forward dynamic programming. In each
step, at most B solutions are expanded according to the heatmap policy, restricting
the size of the search space. Partial solutions are dominated by shorter (lower cost)
solutions with the same DP state: the same nodes visited (marked grey) and current
node (indicated by dashed rectangles).

192
W. Kool et al.
In more detail, the starting point of our proposed approach is a restricted
dynamic programming algorithm [22,46], which heuristically reduces the search
space by retaining at most B solutions per iteration. The selection process is
important as it deﬁnes the part of the DP state space considered and, thus, the
quality of the solution found (see Fig. 2). DPDP deﬁnes the selection using a
(sparse) heatmap of promising route segments, obtained by pre-processing the
problem instance using a (deep) graph neural network (GNN) [32]. This brings
the power of neural networks to DP, inspired by the success of neural networks
that improved tree search [57] or branch-and-bound algorithms [21,49].
In this work, we thus aim for a ‘neural boost’ of DP algorithms, by using
a GNN for scoring partial solutions. Prior work on ‘neural’ vehicle routing has
focused on auto-regressive models [6,15,36,64], but they have high computa-
tional cost when combined with (any form of) search, as the model needs to be
evaluated for each partial solution considered. Instead, we use a model to pre-
dict a heatmap indicating promising edges [32], and deﬁne the score of a partial
solution as the ‘heat’ of the edges it contains (plus an estimate of the ‘heat-to-go’
or potential of the solution). As the neural network only needs to be evaluated
once for each instance, this enables a much larger search (deﬁned by B), making
a good trade-oﬀbetween quality and computational cost. Additionally, we can
apply a threshold to the heatmap to deﬁne a sparse graph on which to run the
DP algorithm, reducing the runtime by eliminating many solutions.
Figure 2 illustrates DPDP. In Sect. 4, we show that DPDP signiﬁcantly
improves over ‘classic’ restricted DP algorithms. Additionally, we show that
DPDP outperformes most other ‘neural’ approaches for TSP, VRP and TSPTW
and is competitive with the highly-optimized LKH solver [27] for VRP, while
achieving similar results much faster for TSP and TSPTW. For TSPTW, DPDP
also outperforms the best open-source solver we could ﬁnd [12], illustrating the
power of DPDP to handle diﬃcult hard constraints (time windows).
2
Related Work
DP [7] has a long history as an exact solution method for routing problems
[38,59], e.g. the TSP with time windows [17] and precedence constraints [48],
but is limited to small problems due to the curse of dimensionality. Restricted DP
(with heuristic policies) has been used to address, e.g., the time dependent TSP
[46], and has been generalized into a ﬂexible framework for VRPs with diﬀerent
types of practical constraints [22]. DP approaches have also been shown to be
useful in settings with diﬃcult practical issues such as time-dependent travel
times and driving regulations [35] or stochastic demands [51]. For more examples
of DP for routing (and scheduling), see [28]. For sparse graphs, alternative, but
less ﬂexible, formulations can be used [10].
Despite the ﬂexibility, DP methods have not gained much popularity com-
pared to heuristic approaches such as R&R [56], ALNS [55], LKH [27], HGS
[62,63] or FILO [1], which, while eﬀective, have limited ﬂexibility as special
operators are needed for diﬀerent types of problems. While restricted DP was

Deep Policy Dynamic Programming for Vehicle Routing Problems
193
shown to have superior performance on realistic VRPs with many constraints
[22], the performance gap of around 10% for standard (benchmark) VRPs (with
time windows) is too large to popularize this approach. We argue that the miss-
ing ingredient is a strong but computationally cheap policy for selecting which
solutions to consider, which is the motivation behind DPDP.
In the machine learning community, deep neural networks (DNNs) have
recently boosted performance on various tasks [39]. After the ﬁrst DNN model
was trained (using example solutions) to construct TSP tours [64], many
improvements have been proposed, e.g. diﬀerent training strategies such as rein-
forcement learning (RL) [6,14,33,37] and model architectures, which enabled the
same idea to be used for other routing problems [15,18,36,45,50,54,67]. Most
constructive neural methods are auto-regressive, evaluating the model many
times to predict one node at the time, but other works have considered pre-
dicting a heatmap of promising edges at once [19,32,52], which allows a tour
to be constructed (using sampling or beam search) without further evaluat-
ing the model. An alternative to constructive methods is ‘learning to search’,
where a neural network is used to guide a search procedure such as local search
[9,20,29,30,34,41,43,66,68]. Scaling to instances beyond 100 nodes remains chal-
lenging [19,44].
The combination of machine learning with DP has been proposed in limited
settings [25,69,70]. Most related to our approach, a DP algorithm for TSPTW,
guided by an RL agent, was implemented using an existing solver [8], which is
less eﬃcient than DPDP (see Sect. 4.3). Also similar to our approach, a neural
network predicting edges has been combined with tree search and local search
for maximum independent set (MIS) [42]. Whereas DPDP directly builds on the
idea of predicting promising edges [32,42], it uses these more eﬃciently through
a policy with potential function (see Sect. 3.2), and by using DP rather than
tree search or beam search, we exploit known problem structure in a principled
and general manner. As such, DPDP obtains strong performance without using
extra heuristics such as local search. For a wider view on machine learning for
routing problems and combinatorial optimization, see [3,47,61].
3
Deep Policy Dynamic Programming
DPDP uses an existing graph neural network [32], suitably adapted for VRP
and TSPTW, to predict a heatmap of promising edges. This heatmap is used
in the DP algorithm in two ways: 1) to exclude edges with a value below the
heatmap threshold of 10−5 from the graph and 2) to deﬁne a scoring policy
to select candidate solutions in each iteration. In more detail, as illustrated in
Fig. 2, the DP algorithm starts with a beam of a single initial (empty) solution,
and proceeds by iterating the following steps: (1) all solutions on the beam are
expanded, (2) dominated solutions are removed for each DP state, (3) the B best
solutions according to the scoring policy deﬁne the beam for the next iteration.
The objective function is used to select the best solution from the ﬁnal beam.
The resulting algorithm is a beam search over the DP state space, with beam size

194
W. Kool et al.
B. This is diﬀerent from a ‘standard’ beam search, which considers the solution
space by not removing dominated solutions. DPDP is asymptotically optimal
as using B = n · 2n for a TSP with n nodes guarantees optimal results, but by
choosing a smaller B, DPDP can trade oﬀperformance for computational cost.
DPDP is a generic framework that can be applied to diﬀerent problems, by
deﬁning the following ingredients: (1) the variables to track while constructing
solutions, (2) the initial solution, (3) feasible actions to expand solutions,
(4) rules to deﬁne dominated solutions and (5) the scoring policy, based on
the neural network, for selecting the B solutions to keep. A solution is always
deﬁned by a sequence of actions, which allows the DP algorithm to construct
the ﬁnal solution by backtracking. In the next sections, we describe the neural
network and deﬁne the DPDP ingredients for the TSP, VRP and TSPTW.
3.1
The Graph Neural Network
We use the original (pre-trained) model from [32] (which we describe in detail
in Appendix 1 for self-containment) for the TSP, but we modify the neural net-
work architecture and train new models to support the VRP and TSPTW, as
we describe in Sects. 3.3 and 3.4. In general, the resulting model uses problem-
speciﬁc node input features and edge input features, which get transformed
into initial representations of the nodes and edges. These representations then
get updated sequentially using a number of graph convolutional layers, which
exchange information between the nodes and edges. The ﬁnal edge representa-
tion is used to make the prediction whether the edge is promising, i.e. whether
it has a high probability of being part of the optimal solution.
The model is trained using a large training dataset of problem instances with
optimal (or high-quality) solutions, obtained using an existing solver. While it
takes a signiﬁcant amount of resources to create this dataset and train the model
(each of which can take up to a number of days on a single machine), training
of the model is, in principle, only required once given a speciﬁc distribution
of problem instances. We consider only instances with n = 100 nodes, but the
model can handle instances of diﬀerent graph sizes, although good generalization
may be limited to graphs with sizes close to the size trained for [33,36].
3.2
Travelling Salesman Problem
We implement DPDP for Euclidean TSPs with n nodes on a (sparse) graph,
where the cost for edge (i, j) is given by cij, the Euclidean distance between the
nodes i and j. The objective is to construct a tour that visits all nodes (and
returns to the start node) and minimizes the total cost of its edges.
For each partial solution, deﬁned by a sequence of actions a, the variables
we track are cost(a), the total cost (distance), current(a), the current node,
and visited(a), the set of visited nodes (including the start node). Without
loss of generality, we let 0 be the start node, so we initialize the beam at step
t = 0 with the empty initial solution with cost(a) = 0, current(a) = 0 and
visited(a) = {0}. At step t, the action at ∈{0, ..., n −1} indicates the next
node to visit, and is a feasible action for a partial solution a = (a0, ..., at−1)

Deep Policy Dynamic Programming for Vehicle Routing Problems
195
if (at−1, at) is an edge in the graph and at ̸∈visited(a), or, when all nodes are
visited, if at = 0 to return to the start node. When expanding the solution to
a′ = (a0, ..., at), we can compute the tracked variables incrementally as:
cost(a′) = cost(a) + ccurrent(a),at, current(a′) = at, visited(a′) = visited(a) ∪{at}.
(1)
A (partial) solution a is a dominated solution if there exists a (dominating)
solution a∗such that visited(a∗) = visited(a), current(a∗) = current(a) and
cost(a∗) < cost(a). We refer to the tuple (visited(a), current(a)) as the DP state,
so removing all dominated partial solutions, we keep exactly one minimum-cost
solution for each unique DP state1. A solution can only dominate other solutions
with the same set of visited nodes, so we only need to remove dominated solutions
from sets of solutions with the same number of actions. This is why the DP
algorithm can be executed in iterations (as explained): at step t all solutions in
the beam have t actions and t + 1 visited nodes (including the start node). The
resulting memory need is thus limited to O(B) states, with B the beam size.
We deﬁne the scoring policy using the pretrained model from [32], which
takes as input node coordinates and edge distances to predict a raw heatmap
value ˆhij ∈(0, 1) for each edge (i, j). The model was trained to predict optimal
solutions, so ˆhij can be seen as the probability that edge (i, j) is in the optimal
tour. We force the heatmap to be symmetric thus we deﬁne hij = max{ˆhij, ˆhji}.
The policy is deﬁned using the heatmap values, in such a way to select the
(partial) solutions with the largest total heat, while also taking into account the
(heat) potential for the unvisited nodes. The policy thus selects the B solutions
which have the highest score, deﬁned as score(a) = heat(a) + potential(a), with
heat(a) = t−1
i=1 hai−1,ai, i.e. the sum of the heat of the edges, which can be
computed incrementally when expanding a solution. The potential is added as
an estimate of the ‘heat-to-go’ (similar to the heuristic in A∗search) for the
remaining nodes, and avoids the ‘greedy pitfall’ of selecting the best edges while
skipping over nearby nodes, which would prevent good edges from being used
later. It is deﬁned as potential(a) = potential0(a) + 
i̸∈visited(a) potentiali(a)
with potentiali(a) = wi

j̸∈visited(a)
hji
n−1
k=0 hki , where wi is the node potential
weight given by wi = (maxj hji) · (1 −0.1(
ci0
maxj cj0 −0.5)). By normalizing the
heatmap values for incoming edges, the (remaining) potential for node i is ini-
tially equal to wi but decreases as good edges become infeasible due to neighbors
being visited. The node potential weight wi is equal to the maximum incoming
edge heatmap value (an upper bound to the heat contributed by node i), which
gets multiplied by a factor 0.95 to 1.05 to give a higher weight to nodes closer to
the start node, which we found helps to encourage the algorithm to keep edges
that enable to return to the start node. The overall heat + potential function
identiﬁes promising partial solutions and is computationally cheap. It is a heuris-
1 If we have multiple partial solutions with the same state and cost, we can arbitrarily
choose one to dominate the other(s), for example the one with the lowest index of
the current node.

196
W. Kool et al.
tic estimate of the total heat of the complete solution, but it is not an estimate
of the cost objective (which has a diﬀerent unit), neither it is a bound on the
total heat or cost objective.
3.3
Vehicle Routing Problem
For the VRP, we add a special depot node dep to the graph. Node i has a
demand di, and the goal is to minimize the cost for a set of routes that visit all
nodes. Each route must start and end at the depot, and the total demand of its
nodes cannot exceed the vehicle capacity denoted by capacity.
Additionally to the TSP variables cost(a), current(a) and visited(a), we
keep track of capacity(a), which is the remaining capacity in the current
route/vehicle. A solution starts at the depot, so we initialize the beam at step
t = 0 with the empty initial solution with cost(a) = 0, current(a) = dep,
visited(a) = ∅and capacity(a) = capacity. For the VRP, we do not consider
visiting the depot as a separate action. Instead, we deﬁne 2n actions, where
at ∈{0, ..., 2n −1}. The actions 0, ..., n −1 indicate a direct move from the
current node to node at, whereas the actions n, ..., 2n −1 indicate a move to
node at −n via the depot. Feasible actions are those that move to unvisited
nodes via edges in the graph and obey the following constraints. For the ﬁrst
action a0 there is no choice and we constrain (for convenience of implementation)
a0 ∈{n, ..., 2n −1}. A direct move (at < n) is only feasible if dat ≤capacity(a)
and updates the state similar to TSP but reduces remaining capacity by dat. A
move via the depot is always feasible (respecting the graph edges and assuming
di ≤capacity ∀i) as it resets the vehicle capacity before subtracting demand,
but incurs the ‘via-depot cost’ cdep
ij
= ci,dep + cdep,j. When all nodes are visited,
we allow a special action to return to the depot. This somewhat unusual way
of representing a VRP solution has desirable properties similar to the TSP for-
mulation: at step t we have exactly t nodes visited, and we can run the DP in
iterations, removing dominated solutions at each step t.
For VRP, a partial solution a is a dominated solution dominated by a∗
if visited(a∗) = visited(a) and current(a∗) = current(a) (i.e. a∗corresponds
to the same DP state) and cost(a∗) ≤cost(a) and capacity(a∗) ≥capacity(a),
with at least one of the two inequalities being strict. This means that for each DP
state, given by the set of visited nodes and the current node, we do not only keep
the (single) solution with lowest cost (as in the TSP algorithm), but keep the
complete set of pareto-eﬃcient solutions in terms of cost and remaining vehicle
capacity. This is because a higher cost partial solution may still be preferred if
it has more remaining vehicle capacity, and vice versa.
For the VRP scoring policy, we modify the model [32] (described in
Appendix 1) to include the depot node and demands. We mark the depot as a
special node type, which aﬀects the initial node representation similarly to edge
types, and we add additional edge types for connections to the depot. Addition-
ally, each node gets an extra input (next to its coordinates) corresponding to
di/capacity (where we set ddep = 0). The model is trained on example solutions
from LKH [27] (see Sect. 4.2), which are not optimal, but still provide a useful

Deep Policy Dynamic Programming for Vehicle Routing Problems
197
training signal. Compared to TSP, the deﬁnition of the heat is slightly changed
to accommodate for the ‘via-depot actions’ and is best deﬁned incrementally
using the ‘via-depot heat’ hdep
ij
= hi,dep · hdep,j · 0.1, where multiplication is used
to keep heat values interpretable as probabilities and in the range (0, 1). The
additional penalty factor of 0.1 for visiting the depot encourages the algorithm
to minimize the number of vehicles/routes. The heat of the initial state is 0 and
when expanding a solution a to a′ using action at, the heat is incremented with
either hcurrent(a),at (if at < n) or hdep
current(a),at−n (if at ≥n). The potential is
deﬁned similarly to TSP, replacing the start node 0 by dep.
3.4
Travelling Salesman Problem with Time Windows
For the TSPTW, we also have a special depot/start node 0. The goal is to create
a single tour that visits each node i in a time window deﬁned by (li, ui), where
the travel time from i to j is equal to the cost/distance cij, i.e. we assume a speed
of 1 (w.l.o.g. as we can rescale time). It is allowed to wait if arrival at node i is
before li, but arrival cannot be after ui. We minimize the total cost (excluding
waiting time), but to minimize makespan (including waiting time), we only need
to train on diﬀerent example solutions. Due to the hard constraints, TSPTW is
typically considered more challenging than plain TSP, for which every solution
is feasible.
The variables we track and initial solution are equal to TSP except that
we add time(a) which is initially 0 (= l0). Feasible actions at ∈{0, ..., n −1}
are those that move to unvisited nodes via edges in the graph such that the
arrival time is no later than uat and do not directly eliminate the possibility to
visit other nodes in time2. Expanding a solution a to a′ using action at updates
the time as time(a′) = max{time(a) + ccurrent(a),at, lat}.
For each DP state, we keep all eﬃcient solutions in terms of cost and time, so a
partial solution a is a dominated solution dominated by a∗if a∗has the same
DP state (visited(a∗) = visited(a) and current(a∗) = current(a)) and is strictly
better in terms of cost and time, i.e. cost(a∗) ≤cost(a) and time(a∗) ≤time(a),
with at least one of the two inequalities being strict.
The model [32] for the scoring policy is adapted to include the time windows
(li, ui) as node features (scaled to correspond to a speed of 1 for the input
distances and coordinates, which are scaled to the range [0, 1]), and we use a
special embedding for the depot similar to VRP. Due to the time dimension, a
TSPTW solution is directed, and edge (i, j) may be good whereas (j, i) may be
not, so we adapt the model to enable predictions hij ̸= hji (see Appendix 1).
We generated example training solutions using (heuristic) DP with a large beam
size, which was faster than LKH. Given the heat predictions, the score (heat +
potential) is exactly as for TSP.
2 E.g., arriving at node i at t = 10 is not feasible if node j has uj = 12 and cij = 3.

198
W. Kool et al.
4
Experiments
We implement DPDP using PyTorch [53] to leverage GPU computation. For
details, see Appendix 2. Our code is publicly available.3 DPDP has very few
hyperparameters, but the heatmap threshold of 10−5 and details like the func-
tional form of e.g. the scoring policy are ‘educated guesses’ or manually tuned on
a few validation instances and can likely be improved. The runtime is inﬂuenced
by implementation choices which were tuned on a few validation instances.
4.1
Travelling Salesman Problem
In Table 1 we report our main results for DPDP with beam sizes of 10K (10
thousand) and 100K, for the TSP with 100 nodes on a commonly used test set of
10000 instances [36]. We report cost and gap to the optimal solution found using
Concorde [2] (following [36]) and compare against LKH [27] and Gurobi [24], as
well as recent results of the strongest methods using neural networks (‘neural
approaches’) from literature. Running times for solving 10000 instances after
training should be taken as rough indications as some are on diﬀerent machines,
typically with 1 GPU or a many-core CPU (8 - 32). The costs indicated with
* are not directly comparable due to slight dataset diﬀerences [19]. Times for
generating heatmaps (if applicable) is reported separately (as the ﬁrst term)
from the running time for MCTS [19] or DP. DPDP achieves close to optimal
results, strictly outperforming the neural baselines achieving better results in
less time (except the Attention Model trained with POMO [37], see Sect. 4.2).
4.2
Vehicle Routing Problem
For the VRP, we train the model using 1 million instances of 100 nodes, generated
according to the distribution described by [50] and solved using one run of LKH
[27]. We train using a batch size of 48 and a learning rate of 10−3 (selected as
the result of manual trials to best use our GPUs), for (at most) 1500 epochs
of 500 training steps (following [32]) from which we select the saved checkpoint
with the lowest validation loss. We use the validation and test sets by [36].
Table 1 shows the results, where the gap is relative to Hybrid Genetic Search
(HGS)4, a SOTA heuristic VRP solver [62,63]. HGS is faster and improves
around 0.5% over LKH [27], which is typically considered the baseline in related
work. We present the results for LKH, as well as the strongest neural approaches
and DPDP with beam sizes up to 1 million. Some results used 2000 (diﬀerent)
instances [43] and cannot be directly compared5. DPDP outperforms all other
neural baselines, except the Attention Model trained with POMO [37], which
delivers good results very quickly by exploiting symmetries in the problem.
3 https://github.com/wouterkool/dpdp.
4 https://github.com/vidalt/HGS-CVRP.
5 The running time of 4000 h (167 days) is estimated from 24 min/instance [43].

Deep Policy Dynamic Programming for Vehicle Routing Problems
199
Table 1. Mean cost, gap and total time to solve 10000 TSP/VRP test instances.
Problem
TSP100
VRP100
Method
Cost
Gap
Time
Cost
Gap
Time
Concorde [2]
7.765
0.000% 6m
Hybrid Genetic Search [62,63]
15.563 0.000% 6h11m
Gurobi [24]
7.776
0.151% 31m
LKH [27]
7.765
0.000% 42m
15.647 0.536% 12h57m
GNN Heatmap + Beam Search [32]
7.87
1.39%
40m
Learning 2-opt heuristics [11]
7.83
0.87%
41m
Merged GNN Heatmap + MCTS [19]
7.764* 0.04%
4m + 11m
Attention Model + Sampling [36]
7.94
2.26%
1h
16.23
4.28%
2h
Step-wise Attention Model [67]
8.01
3.20%
29s
16.49
5.96%
39s
Attn. Model + Coll. Policies [34]
7.81
0.54%
12h
15.98
2.68%
5h
Learning improv. heuristics [66]
7.87
1.42%
2h
16.03
3.00%
5h
Dual-Aspect Coll. Transformer [45]
7.77
0.09%
5h
15.71
0.94%
9h
Attention Model + POMO [37]
7.77
0.14%
1m
15.76
1.26%
2m
NeuRewriter [9]
16.10
3.45%
1h
Dynamic Attn. Model + 2-opt [54]
16.27
4.54%
6h
Neur. Lrg. Neighb. Search [30]
15.99
2.74%
1h
Learn to improve [43]
15.57* -
4000h
DPDP 10K
7.765
0.009%
10m + 16m
15.830 1.713%
10m + 50m
DPDP 100K
7.765
0.004%
10m + 2h35m 15.694 0.843%
10m + 5h48m
DPDP 1M
15.627 0.409%
10m + 48h27m
However, as it cannot (easily) improve further with additional runtime, we con-
sider this contribution orthogonal to DPDP. DPDP is competitive to LKH (see
also Sect. 4.4).
More Realistic Instances. We also train the model and run experiments with
instances with 100 nodes from a more realistic and challenging data distribution
[60]. This distribution, commonly used in the routing community, has greater
variability, in terms of node clustering and demand distributions. LKH failed to
solve two of the test instances, which is because LKH by default uses a ﬁxed
number of routes equal to a lower bound, given by
 n−1
i=0 di
capacity

, which may be infea-
sible6. Therefore we solve these instances by rerunning LKH with an unlimited
number of allowed routes (which gives worse results, see Sect. 4.4).
DPDP was run on a machine with 4 GPUs, but we also report (estimated)
runtimes for 1 GPU (1080Ti), and we compare against 16 or 32 CPUs for HGS
and LKH. In Table 2 it can be seen that the diﬀerence with LKH is, as expected,
6 For example, three nodes with a demand of two cannot be assigned to two routes
with a capacity of three.

200
W. Kool et al.
slightly larger than for the simpler dataset, but still below 1% for beam sizes of
100K–1M. We also observed a higher validation loss, so it may be possible to
improve results using more training data. Nevertheless, ﬁnding solutions within
1% of the specialized SOTA HGS algorithm, and even closer to LKH, is impres-
sive for these challenging instances, and we consider the runtime (for solving
10K instances) acceptable, especially when using multiple GPUs.
Table 2. Mean cost, gap and total time to solve 10000 realistic VRP100 instances.
Method
Cost Gap
Time (1 GPU or 16 CPUs) Time (4 GPUs or 32 CPUs)
HGS [62,63] 18050 0.000% 7h53m
3h56m
LKH [27]
18133 0.507% 25h32m
12h46m
DPDP 10K
18414 2.018% 10m + 50m
2m + 13m
DPDP 100K 18253 1.127% 10m + 5h48m
2m + 1h27m
DPDP 1M
18168 0.659% 10m + 48h27m
2m + 12h7m
4.3
TSP with Time Windows
For the TSP with hard time window constraints, we use the data distribution by
[8] and use their set of 100 test instances with 100 nodes. These were generated
with small time windows, resulting in a small feasible search space, such that even
with very small beam sizes, our DP implementation solves these instances opti-
mally, eliminating the need for a policy. Therefore, we also consider a more dif-
ﬁcult distribution similar to [12], which has larger time windows which are more
diﬃcult as the feasible search space is larger7 [17]. For details, see Appendix 1.
For both distributions, we generate training data and train the model exactly as
we did for the VRP.
Table 3 shows the results for both data distributions, which are reported in
terms of the diﬀerence to General Variable Neighborhood Search (GVNS) [12],
the best open-source solver for TSPTW we could ﬁnd8, using 30 runs. For the
small time window setting, both GVNS and DPDP ﬁnd optimal solutions for
all 100 instances in just 7 s (in total, either on 16 CPUs or a single GPU). LKH
fails to solve one instance, but ﬁnds close to optimal solutions, but around 50
times slower. BaB-DQN* and ILDS-DQN* [8], methods combining an existing
solver with an RL trained neural policy, take around 15 min per instance (orders
of magnitudes slower) to solve most instances to optimality. Due to complex set-
up, we were unable to run BaB-DQN* and ILDS-DQN* ourselves for the setting
with larger time windows. In this setting, we ﬁnd DPDP outperforms both LKH
(where DPDP is orders of magnitude faster) and GVNS, in both speed and
solution quality. This illustrates that DPDP, due to its nature, is especially well
suited to handle constrained problems.
7 Up to a limit, as making the time windows inﬁnite size reduces the problem to plain
TSP.
8 https://github.com/sashakh/TSPTW.

Deep Policy Dynamic Programming for Vehicle Routing Problems
201
Table 3. Mean cost, gap and total time to solve TSPTW100 instances.
Problem
Small time windows [8] (100 inst.) Large time windows [12] (10K inst.)
Method
Cost
Gap
Fail
Time
Cost
Gap
Fail Time
GVNS 30x [12]
5129.58 0.000%
7s
2432.112 0.000%
37m15s
GVNS 1x [12]
5129.58 0.000%
<1s
2457.974 1.063%
1m4s
LKH 1x [27]
5130.32 0.014% 1.00% 5m48s
2431.404 −0.029%
34h58m
BaB-DQN* [8]
5130.51 0.018%
25h
ILDS-DQN* [8] 5130.45 0.017%
25h
DPDP 10K
5129.58 0.000%
6s + 1s
2431.143 −0.040%
10m + 8m7s
DPDP 100K
5129.58 0.000%
6s + 1s
2430.880 −0.051%
10m + 1h16m
4.4
Ablations
Scoring Policy. To evaluate the value of diﬀerent components of DPDP’s GNN
Heat + Potential scoring policy, we compare against other variants. GNN
Heat is the version without the potential, whereas Cost Heat + Potential
and Cost Heat are variants that use a ‘heuristic’ ˆhij =
cij
maxk cik instead of the
GNN. Cost directly uses the current cost of the solution, and can be seen as
‘classic’ restricted DP. Finally, BS GNN Heat + Potential uses beam search
without dynamic programming, i.e. without removing dominated solutions. To
evaluate only the scoring policy, each variant uses the fully connected graph
(no heatmap threshold). Figure 3a shows the value of DPDP’s potential func-
tion, although even without it results are still signiﬁcantly better than ‘classic’
heuristic DP variants using cost-based scoring policies. Also, it is clear that using
DP signiﬁcantly improves over a standard beam search (by removing dominated
solutions). Lastly, the ﬁgure illustrates how the time for generating the heatmap
using the neural network, despite its signiﬁcant value, only makes up a small
portion of the total runtime.
(a) Diﬀerent scoring poli-
cies, as well as ‘pure’ beam
search, for beam sizes 1, 10,
100, 1000, 10K, 100K.
(b) Beam sizes 10K, 25K,
50K, 100K, 250K, 500K,
1M, 2.5M compared against
LKH(U) with 1, 2, 5 and 10
runs.
(c) Sparsities with heatmap
thresholds 0.9, 0.5, 0.2, 0.1,
10−2, 10−3, 10−4, 10−5 and
knn = 5, 10, 20, 50, 99.
Beam size 100K.
Fig. 3. DPDP ablations on 100 validation instances of VRP with 100 nodes.

202
W. Kool et al.
Beam Size. With DPDP, we can trade oﬀthe performance vs. the runtime using
the beam size B (and the graph sparsity, see below). Figure 3b illustrates this
trade-oﬀ, where we evaluate DPDP on 100 validation instances for VRP, with
diﬀerent beam sizes from 10K to 2.5M. We also report the trade-oﬀcurve for
LKH(U), which is the strongest baseline that can also solve diﬀerent problems.
We vary the runtime using 1, 2, 5 and 10 runs (returning the best solution).
LKHU(nlimited) is the version which allows an unlimited number of routes (see
Sect. 4.2). It is hard to compare GPU vs CPU, so we report (estimated) runtimes
for diﬀerent hardware, i.e. 1 or 4 GPUs (with 3 CPUs per GPU) and 16 or 32
CPUs. We report the diﬀerence (i.e. the gap) with HGS, analogous to how results
are reported in Table 1. We emphasize that in most related work (e.g. [36]), the
strongest baseline considered is one run of LKH, so we compare against a much
stronger baseline. Also, our goal is not to outperform HGS (which is SOTA and
speciﬁc to VRP) or LKH, but to show DPDP has reasonable performance, while
being a ﬂexible framework for other (routing) problems.
Graph Sparsity. Using the heatmap threshold, the DP algorithm uses a sparse
graph to deﬁne feasible expansions, which reduces the runtime but may also
sacriﬁce solution quality. For most edges, the model conﬁdently predicts close to
0, such that they are ruled out, even using the default (low) heatmap threshold
of 10−5. We may rule out even more edges by increasing the threshold, which
can be seen as a secondary way (besides varying the beam size) to trade oﬀthe
performance and computational cost of DPDP. While this can be seen as a form
of learned problem reduction [58], we also consider a heuristic alternative of using
the K-nearest neighbor (knn) graph.9 In Fig. 3c, we experiment with diﬀerent
heatmap thresholds from 10−5 to 0.9 and diﬀerent values for knn from 5 to 99
(fully connected). The heatmap threshold strategy clearly outperforms the knn
strategy as it yields the same results using sparser graphs (and lower runtimes).
This illustrates that the heatmap threshold strategy is more informed than the
knn strategy, conﬁrming the value of the neural network predictions.
5
Discussion
In this paper we introduced Deep Policy Dynamic Programming, which combines
machine learning and dynamic programming for solving vehicle routing prob-
lems. The method yields close to optimal results for TSPs with 100 nodes and is
competitive to the highly optimized LKH [27] solver for VRPs with 100 nodes.
On the TSPTW, DPDP also outperforms LKH, being signiﬁcantly faster, as
well as GVNS [12], the best open source solver we could ﬁnd. Given that DPDP
was not speciﬁcally designed for TSPTW, and thus can likely be improved, we
consider this an impressive and promising achievement.
9 For the symmetric TSP and VRP, we add knn edges in both directions. For the
VRP, we also connect each node to the depot (and vice versa) to ensure feasibility.

Deep Policy Dynamic Programming for Vehicle Routing Problems
203
The constructive nature of DPDP (combined with search) naturally supports
hard constraints such as time windows, which are typically considered challeng-
ing in neural combinatorial optimization [6,36] and are also diﬃcult for local
search heuristics (as they need to maintain feasibility while adapting a solu-
tion). Given our results on TSP, VRP and TSPTW, and the ﬂexibility of DP as
a framework, we think DPDP has great potential for solving many more variants
of routing problems, and possibly even other problems that can be formulated
using DP (e.g. job shop scheduling [23]). We hope that our work brings machine
learning research for combinatorial optimization closer to the operations research
(especially vehicle routing) community, by combining machine learning with DP
and evaluating the resulting new framework on diﬀerent data distributions used
by diﬀerent communities [8,12,50,60].
Scope, Limitations and Future Work. Deep learning for combinatorial optimiza-
tion is a recent research direction, which could signiﬁcantly impact the way
practical optimization problems get solved in the future. Currently, however, it
is still hard to beat most SOTA problem speciﬁc solvers from the OR community.
Despite our success for TSPTW, DPDP is not yet a practical alternative in gen-
eral, but we do consider our results as highly encouraging for further research. We
believe such research could yield signiﬁcant further improvement by addressing
key current limitations: (1) the scalability to larger instances, (2) the depen-
dency on example solutions and (3) the heuristic nature of the scoring function.
First, while 100 nodes is not far from the size of common benchmarks (100–1000
for VRP [60] and 20–200 for TSPTW [12]), scaling is a challenge, mainly due
to the ‘fully-connected’ O(n2) graph neural network. Future work could reduce
this complexity following e.g. [40]. The dependency on example solutions from
an existing solver also becomes more prominent for larger instances, but could
potentially be removed by ‘bootstrapping’ using DP itself as we, in some sense,
have done for TSPTW (see Sect. 3.4). Future work could iterate this process to
train the model ‘tabula rasa’ (without example solutions), where DP could be
seen analogous to MCTS in AlphaZero [57]. Lastly, the heat + potential score
function is a well-motivated but heuristic function that was manually designed
as a function of the predicted heatmap. While it worked well for the three prob-
lems we considered, it may need suitable adaption for other problems. Training
this function end-to-end [13,65], while keeping a low computational footprint,
would be an interesting topic for future work.
Acknowledgement. We would like to thank Jelke van Hoorn and Johan van Rooij
for helpful discussions. Also we would like to thank anonymous reviewers for helpful
suggestions. This work was carried out on the Dutch national e-infrastructure with the
support of SURF Cooperative.
Appendix 1 The Graph Neural Network Model
For the TSP, we use the exact model from [32], which we describe here for
self-containment. The model uses node input features and edge input features,

204
W. Kool et al.
which get transformed into initial representations of the nodes and edges. These
representations then get updated sequentially using a number of graph convolu-
tional layers, which exchange information between nodes and edges, after which
the ﬁnal edge representation is used to predict whether the edge is part of the
optimal solution.
Input Features and Initial Representation. The model uses input features for
the nodes, consisting of the (x, y)-coordinates, which are then projected into H-
dimensional initial embeddings x0
i (H = 300). The initial edge features e0
ij are
a concatenation of a H
2 -dimensional projection of the cost (Euclidean distance)
cij from i to j, and a H
2 -dimensional embedding of the edge type: 0 for normal
edges, 1 for edges connecting K-nearest neighbors (K = 20) and 2 for self-loop
edges connecting a node to itself (which are added for ease of implementation).
Graph Convolutional Layers. In each of the L = 30 layers of the model, the node
and edge representations xℓ
i and eℓ
ij get updated into xℓ+1
i
and eℓ+1
ij
[32]:
xℓ+1
i
= xℓ
i + ReLU
⎛
⎝BN
⎛
⎝W ℓ
1xℓ
i +

j∈N(i)
σ(eℓ
ij)

j′∈N(i) σ(eℓ
ij′) ⊙W ℓ
2xℓ
j
⎞
⎠
⎞
⎠
(2)
eℓ+1
ij
= eℓ
ij + ReLU

BN

W ℓ
3eℓ
ij + W ℓ
4xℓ
i + W ℓ
5xℓ
j

.
(3)
Here N(i) is the set of neighbors of node i (in our case all nodes, including i,
as we use a fully connected input graph), ⊙is the element-wise product and
σ is the sigmoid function, applied element-wise to the vector eℓ
ij. ReLU(·) =
max(·, 0) is the rectiﬁed linear unit and BN represents batch normalization [31].
W1, W2, W3, W4 and W5 are trainable parameter matrices, where we ﬁx W4 = W5
for the symmetric TSP.
Output Prediction. After L layers, the ﬁnal prediction hij ∈(0, 1) is made inde-
pendently for each edge (i, j) using a multi-layer perceptron (MLP), which takes
eL
ij as input and has two H-dimensional hidden layers with ReLU activation and
a 1-dimensional output layer, with sigmoid activation. We interpret hij as the
predicted probability that the edge (i, j) is part of the optimal solution, which
indicates how promising this edge is when searching for the optimal solution.
Training. For TSP, the model is trained on a dataset of 1 million optimal solu-
tions, found using Concorde [2], for randomly generated TSP instances. The
training loss is a weighted binary cross-entropy loss, that maximizes the predic-
tion quality when hij is compared to the ground-truth optimal solution. Gener-
ating the dataset takes between half a day and a few days (depending on number
of CPU cores), and training the model takes a few days on one or multiple GPUs,
but both are only required once given a desired data distribution.

Deep Policy Dynamic Programming for Vehicle Routing Problems
205
1.1 Predicting Directed Edges for the TSPTW
The TSP is an undirected problem, so the neural network implementation10 by
[32] shares the parameters W l
4 and W l
5 in Eq. (3), i.e. W l
4 = W l
5, resulting in
el
ij = el
ji for all layers l, as for l = 0 both directions are initialized the same.
While the VRP also is an undirected problem, the TSPTW is directed as the
direction of the route determines the times of arrival at diﬀerent nodes. To allow
the model to make diﬀerent predictions for diﬀerent directions, we implement W l
5
as a separate parameter, such that the model can have diﬀerent representations
for edges (i, j) and (j, i). We deﬁne the training labels accordingly for directed
edges, so if edge (i, j) is in the directed solution, it will have a label 1 whereas
the edge (j, i) will not (for the undirected TSP and VRP, both labels are 1).
1.2 Dataset Generation for the TSPTW
We found that using our DP formulation for TSPTW, the instances by [8] were
all solved optimally, even with a very small beam size (around 10). This is
because there is very little overlap in the time windows as a result of the way
they are generated, and therefore very few actions are feasible as most of the
actions would ‘skip over other time windows’ (advance the time so much that
other nodes can no longer be served)11. We conducted some quick experiments
with a weaker DP formulation, that only checks if actions directly violate time
windows, but does not check if an action causes other nodes to be no longer
reachable in their time windows. Using this formulation, the DP algorithm can
run into many dead ends if just a single node gets skipped, and using the GNN
policy (compared to a cost based policy as in Sect. 4.4) made the diﬀerence
between good solutions and no solution at all being found.
We made two changes to the data generation procedure by [8] to increase the
diﬃculty and make it similar to [12], deﬁning the ‘large time window’ dataset.
First, we sample the time windows around arrival times when visiting nodes in
a random order without any waiting time, which is diﬀerent from [8] who ‘prop-
agate’ the waiting time (as a result of time windows sampled). Our modiﬁcation
causes a tighter schedule with more overlap in time windows, and is similar to
[12]. Secondly, we increase the maximum time window size from 100 to 1000,
which makes that the time windows are in the order of 10% of the horizon12.
This doubles the maximum time window size of 500 used by [12] for instances
with 200 nodes, to compensate for half the number of nodes that can possibly
overlap the time window.
To generate the training data, for practical reasons we used DP with the
heuristic ‘cost heat + potential’ strategy and a large beam size (1M), which in
many cases results in optimal solutions being found.
10 https://github.com/chaitjo/graph-convnet-tsp/blob/master/models/gcn layers.py.
11 If all time windows are disjoint, there is only one feasible solution. Therefore, the
amount of overlap in time windows determines to some extent the ‘branching factor’
of the problem and the diﬃculty.
12 Serving 100 customers in a 100 × 100 grid, empirically we ﬁnd the total schedule
duration including waiting (the makespan) is around 5000.

206
W. Kool et al.
Appendix 2 Implementation
We implement the dynamic programming algorithm on the GPU using PyTorch
[53]. While mostly used as a Deep Learning framework, it can be used to speed
up generic (vectorized) computations.
2.1 Beam Variables
For each solution in the beam, we keep track of the following variables (storing
them for all solutions in the beam as a vector): the cost, current node, visited
nodes and (for VRP) the remaining capacity or (for TSPTW) the current time.
As explained, these variables can be computed incrementally when generating
expansions. Additionally, we keep a variable vector parent, which, for each solu-
tion in the current beam, tracks the index of the solution in the previous beam
that generated the expanded solution. To compute the score of the policy for
expansions eﬃciently, we also keep track of the score for each solution and the
potential for each node for each solution incrementally.
We do not keep past beams in memory, but at the end of each iteration, we
store the vectors containing the parents as well as last actions for each solution
on the trace. As the solution is completely deﬁned by the sequence of actions,
this allows to backtrack the solution after the algorithm has ﬁnished. To save
GPU memory (especially for larger beam sizes), we store the O(Bn) sized trace
on the CPU memory.
For eﬃciency, we keep the set of visited nodes as a bitmask, packed into
64-bit long integers (2 for 100 nodes). Using bitwise operations with the packed
adjacency matrix, this allows to quickly check feasible expansions (but we need to
unpack the mask into boolean vectors to ﬁnd all feasible expansions explicitly).
Figure 4a shows an example of the beam (with variables related to the policy
and backtracking omitted) for the VRP.
2.2 Generating Non-dominated Expansions
A solution a can only dominate a solution a′ if visited(a) = visited(a′) and
current(a) = current(a′), i.e. if they correspond to the same DP state. If this is
the case, then, if we denote by parent(a) the parent solution from which a was
expanded, it holds that
visited(parent(a)) = visited(a) \ {current(a)}
= visited(a′) \ {current(a′)}
= visited(parent(a′)).
This means that only expansions from solutions with the same set of visited
nodes can dominate each other, so we only need to check for dominated solutions
among groups of expansions originating from parent solutions with the same
set of visited nodes. Therefore, before generating the expansions, we group the

Deep Policy Dynamic Programming for Vehicle Routing Problems
207
Fig. 4. Implementation of DPDP for VRP (Color ﬁgure online)
current beam (the parents of the expansions) by the set of visited nodes (see
Fig. 4). This can be done eﬃciently, e.g. using a lexicographic sort of the packed
bitmask representing the sets of visited nodes13.
Travelling Salesman Problem. For TSP, we can generate (using boolean
operations) the B ×n matrix with boolean entries indicating feasible expansions
13 For eﬃciency, we use a custom function similar to torch.unique, and argsort the
returned inverse after which the resulting permutation is applied to all variables in
the beam.

208
W. Kool et al.
(with n action columns corresponding to n nodes, similar to the B × 2n matrix
for VRP in Fig. 4), i.e. nodes that are unvisited and adjacent to the current
node. If we ﬁnd positive entries sequentially for each column (e.g. by calling
torch.nonzero on the transposed matrix), we get all expansions grouped by
the combination of action (new current node) and parent set of visited nodes, i.e.
grouped by the DP state. We can then trivially ﬁnd the segments of consecutive
expansions corresponding to the same DP state, and we can eﬃciently ﬁnd the
minimum cost solution for each segment, e.g. using torch scatter14.
Vehicle Routing Problem. For VRP, the dominance check has two dimen-
sions (cost and remaining capacity) and additionally we need to consider 2n
actions: n direct and n via the depot (see Fig. 4). Therefore, as we will explain,
we check dominances in two stages: ﬁrst we ﬁnd (for each DP state) the sin-
gle non-dominated ‘via-depot’ expansion, after which we ﬁnd all non-dominated
‘direct’ expansions (see Fig. 4b).
The DP state of each expansion is deﬁned by the expanded node (the new
current node) and the set of visited nodes. For each DP state, there can be only
one15 non-dominated expansion where the last action was via the depot, since all
expansions resulting from ‘via-depot actions’ have the same remaining capacity
as visiting the depot resets the capacity (see Fig. 4b). To ﬁnd this expansion, we
ﬁrst ﬁnd, for each unique set of visited nodes in the current beam, the solution
that can return to the depot with lowest total cost (thus including the cost to
return to the depot, indicated by a dashed green rectangle in Fig. 4). The single
non-dominated ‘via-depot expansion’ for each DP state must necessarily be an
expansion of this solution. Also observe that this via-depot solution cannot be
dominated by a solution expanded using a direct action, which will always have
a lower remaining vehicle capacity (assuming positive demands) as can bee seen
in Fig. 4b. We can thus generate the non-dominated via-depot expansion for each
DP state eﬃciently and independently from the direct expansions.
For each DP state, all direct expansions with cost higher (or equal) than the
via-depot expansion can directly be removed since they are dominated by the via-
depot expansion (having higher cost and lower remaining capacity, see Fig. 4b).
After that, we sort the remaining (if any) direct expansions for each DP state
based on the cost (using a segmented sort as the expansions are already grouped
if we generate them similarly to TSP, i.e. per column in Fig. 4). For each DP
state, the lowest cost solution is never dominated. The other solutions should be
kept only if their remaining capacity is strictly larger than the largest remaining
capacity of all lower-cost solutions corresponding to the same DP state, which
can be computed using a (segmented) cumulative maximum computation (see
Fig. 4b).
14 https://github.com/rusty1s/pytorch scatter.
15 Unless we have multiple expansions with the same costs, in which case can pick one
arbitrarily.

Deep Policy Dynamic Programming for Vehicle Routing Problems
209
TSP with Time Windows. For the TSPTW, the dominance check has two
dimensions: cost and time. Therefore, it is similar to the check for non-dominated
direct expansions for the VRP (see Fig. 4b), but replacing remaining capacity
(which should be maximized) by current time (to be minimized). In fact, we could
reuse the implementation, if we replace remaining capacity by time multiplied
by −1 (as this should be minimized). This means that we sort all expansions for
each DP state based on the cost, keep the ﬁrst solution and keep other solutions
only if the time is strictly lower than the lowest current time for all lower-cost
solutions, which can be computed using a cumulative minimum computation.
2.3 Finding the Top B Solutions
We may generate all ‘candidate’ non-dominated expansions and then select the
top B using the score function. Alternatively, we can generate expansions in
batches, and keep a streaming top B using a priority queue. We use the latter
implementation, where we can also derive a bound for the score as soon as we
have B candidate expansions. Using this bound, we can already remove solutions
before checking dominances, to achieve some speedup in the algorithm.16
2.4 Performance Improvements
There are many possibilities for improving the speed of the algorithm. For exam-
ple, PyTorch lacks a segmented sort so we use a much slower lexicographic sort
instead. Also an eﬃcient GPU priority queue would allow much speedup, as we
currently use sorting as PyTorch’ top-k function is rather slow for large k. In
some cases, a binary search for the k-th largest value can be faster, but this
introduces undesired CUDA synchronisation points.
References
1. Accorsi, L., Vigo, D.: A fast and scalable heuristic for the solution of large-scale
capacitated vehicle routing problems. Transp. Sci. 55(4), 832–856 (2021)
2. Applegate, D., Bixby, R., Chvatal, V., Cook, W.: Concorde TSP Solver (2006).
http://www.math.uwaterloo.ca/tsp/concorde
3. Bai, R., et al.: Analytics and machine learning in vehicle routing research. arXiv
preprint arXiv:2102.10012 (2021)
4. Bellman, R.: On the theory of dynamic programming. Proc. Natl. Acad. Sci. U.S.A.
38(8), 716 (1952)
5. Bellman, R.: Dynamic programming treatment of the travelling salesman problem.
J. ACM (JACM) 9(1), 61–63 (1962)
6. Bello, I., Pham, H., Le, Q.V., Norouzi, M., Bengio, S.: Neural combinatorial opti-
mization with reinforcement learning. arXiv preprint arXiv:1611.09940 (2016)
16 This may give slightly diﬀerent results if the scoring function is inconsistent with
the domination rules, i.e. if a better scoring solution would be dominated by a worse
scoring solution but is not since that solution is removed using the score bound
before checking the dominances.

210
W. Kool et al.
7. Bertsekas, D.: Dynamic Programming and Optimal Control, vol. 1. Athena Scien-
tiﬁc (2017)
8. Cappart, Q., Moisan, T., Rousseau, L.M., Pr´emont-Schwarz, I., Cire, A.: Com-
bining reinforcement learning and constraint programming for combinatorial opti-
mization. In: AAAI Conference on Artiﬁcial Intelligence (AAAI) (2021)
9. Chen, X., Tian, Y.: Learning to perform local rewriting for combinatorial opti-
mization. In: Advances in Neural Information Processing Systems (NeurIPS), pp.
6281–6292 (2019)
10. Cook, W., Seymour, P.: Tour merging via branch-decomposition. INFORMS J.
Comput. 15(3), 233–248 (2003)
11. da Costa, P.R.d.O., Rhuggenaath, J., Zhang, Y., Akcay, A.: Learning 2-opt heuris-
tics for the traveling salesman problem via deep reinforcement learning. In: Asian
Conference on Machine Learning (ACML) (2020)
12. Da Silva, R.F., Urrutia, S.: A general VNS heuristic for the traveling salesman
problem with time windows. Discret. Optim. 7(4), 203–211 (2010)
13. Daum´e, H., III., Marcu, D.: Learning as search optimization: approximate large
margin methods for structured prediction. In: International Conference on Machine
Learning (ICML), pp. 169–176 (2005)
14. Delarue, A., Anderson, R., Tjandraatmadja, C.: Reinforcement learning with com-
binatorial actions: an application to vehicle routing. In: Advances in Neural Infor-
mation Processing Systems (NeurIPS), vol. 33 (2020)
15. Deudon, M., Cournut, P., Lacoste, A., Adulyasak, Y., Rousseau, L.-M.: Learning
heuristics for the TSP by policy gradient. In: van Hoeve, W.-J. (ed.) CPAIOR
2018. LNCS, vol. 10848, pp. 170–181. Springer, Cham (2018). https://doi.org/10.
1007/978-3-319-93031-2 12
16. Dijkstra, E.W.: A note on two problems in connexion with graphs. Numer. Math.
1(1), 269–271 (1959)
17. Dumas, Y., Desrosiers, J., Gelinas, E., Solomon, M.M.: An optimal algorithm for
the traveling salesman problem with time windows. Oper. Res. 43(2), 367–371
(1995)
18. Falkner, J.K., Schmidt-Thieme, L.: Learning to solve vehicle routing problems with
time windows through joint attention. arXiv preprint arXiv:2006.09100 (2020)
19. Fu, Z.H., Qiu, K.B., Zha, H.: Generalize a small pre-trained model to arbitrarily
large tsp instances. In: AAAI Conference on Artiﬁcial Intelligence (AAAI) (2021)
20. Gao, L., Chen, M., Chen, Q., Luo, G., Zhu, N., Liu, Z.: Learn to design the heuris-
tics for vehicle routing problem. In: International Workshop on Heuristic Search
in Industry (HSI) at the International Joint Conference on Artiﬁcial Intelligence
(IJCAI) (2020)
21. Gasse, M., Chetelat, D., Ferroni, N., Charlin, L., Lodi, A.: Exact combinatorial
optimization with graph convolutional neural networks. In: Advances in Neural
Information Processing Systems (NeurIPS) (2019)
22. Gromicho, J., van Hoorn, J.J., Kok, A.L., Schutten, J.M.: Restricted dynamic
programming: a ﬂexible framework for solving realistic VRPs. Comput. Oper. Res.
39(5), 902–909 (2012)
23. Gromicho, J.A., Van Hoorn, J.J., Saldanha-da Gama, F., Timmer, G.T.: Solving
the job-shop scheduling problem optimally by dynamic programming. Comput.
Oper. Res. 39(12), 2968–2977 (2012)
24. Gurobi Optimization, LLC: Gurobi Optimizer Reference Manual (2021). https://
www.gurobi.com
25. van Heeswijk, W., La Poutr´e, H.: Approximate dynamic programming with neural
networks in linear discrete action spaces. arXiv preprint arXiv:1902.09855 (2019)

Deep Policy Dynamic Programming for Vehicle Routing Problems
211
26. Held, M., Karp, R.M.: A dynamic programming approach to sequencing problems.
J. Soc. Ind. Appl. Math. 10(1), 196–210 (1962)
27. Helsgaun, K.: An extension of the Lin-Kernighan-Helsgaun TSP solver for con-
strained traveling salesman and vehicle routing problems: Technical report (2017)
28. van Hoorn, J.J.: Dynamic programming for routing and scheduling. Ph.D. thesis
(2016)
29. Hottung, A., Bhandari, B., Tierney, K.: Learning a latent search space for routing
problems using variational autoencoders. In: International Conference on Learning
Representations (ICML) (2021)
30. Hottung, A., Tierney, K.: Neural large neighborhood search for the capacitated
vehicle routing problem. In: European Conference on Artiﬁcial Intelligence (ECAI)
(2020)
31. Ioﬀe, S., Szegedy, C.: Batch normalization: accelerating deep network training by
reducing internal covariate shift. In: International Conference on Machine Learning
(ICML), pp. 448–456 (2015)
32. Joshi, C.K., Laurent, T., Bresson, X.: An eﬃcient graph convolutional network
technique for the travelling salesman problem. In: INFORMS Annual Meeting
(2019)
33. Joshi, C.K., Laurent, T., Bresson, X.: On learning paradigms for the travelling
salesman problem. In: Graph Representation Learning Workshop at Neural Infor-
mation Processing Systems (NeurIPS) (2019)
34. Kim, M., Park, J., Kim, J.: Learning collaborative policies to solve NP-hard rout-
ing problems. In: Advances in Neural Information Processing Systems (NeurIPS)
(2021)
35. Kok, A., Hans, E.W., Schutten, J.M., Zijm, W.H.: A dynamic programming heuris-
tic for vehicle routing with time-dependent travel times and required breaks. Flex.
Serv. Manuf. J. 22(1–2), 83–108 (2010)
36. Kool, W., van Hoof, H., Welling, M.: Attention, learn to solve routing problems!
In: International Conference on Learning Representations (ICLR) (2019)
37. Kwon, Y.D., Choo, J., Kim, B., Yoon, I., Gwon, Y., Min, S.: Pomo: policy opti-
mization with multiple optima for reinforcement learning. In: Advances in Neural
Information Processing Systems (NeurIPS) (2020)
38. Laporte, G.: The vehicle routing problem: an overview of exact and approximate
algorithms. Eur. J. Oper. Res. (EJOR) 59(3), 345–358 (1992)
39. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436–444
(2015)
40. Lee, J., Lee, Y., Kim, J., Kosiorek, A., Choi, S., Teh, Y.W.: Set transformer: a
framework for attention-based permutation-invariant neural networks. In: Interna-
tional Conference on Machine Learning (ICML), pp. 3744–3753. PMLR (2019)
41. Li, S., Yan, Z., Wu, C.: Learning to delegate for large-scale vehicle routing. In:
Advances in Neural Information Processing Systems (NeurIPS) (2021)
42. Li, Z., Chen, Q., Koltun, V.: Combinatorial optimization with graph convolutional
networks and guided tree search. In: Advances in Neural Information Processing
Systems (NeurIPS), p. 539 (2018)
43. Lu, H., Zhang, X., Yang, S.: A learning-based iterative method for solving vehicle
routing problems. In: International Conference on Learning Representations (2020)
44. Ma, Q., Ge, S., He, D., Thaker, D., Drori, I.: Combinatorial optimization by
graph pointer networks and hierarchical reinforcement learning. In: AAAI Inter-
national Workshop on Deep Learning on Graphs: Methodologies and Applications
(DLGMA) (2020)

212
W. Kool et al.
45. Ma, Y., et al.: Learning to iteratively solve routing problems with dual-aspect
collaborative transformer. In: Advances in Neural Information Processing Systems
(NeurIPS) (2021)
46. Malandraki, C., Dial, R.B.: A restricted dynamic programming heuristic algorithm
for the time dependent traveling salesman problem. Eur. J. Oper. Res. (EJOR)
90(1), 45–55 (1996)
47. Mazyavkina, N., Sviridov, S., Ivanov, S., Burnaev, E.: Reinforcement learning for
combinatorial optimization: a survey. arXiv preprint arXiv:2003.03600 (2020)
48. Mingozzi, A., Bianco, L., Ricciardelli, S.: Dynamic programming strategies for the
traveling salesman problem with time window and precedence constraints. Oper.
Res. 45(3), 365–377 (1997)
49. Nair, V., et al.: Solving mixed integer programs using neural networks. arXiv
preprint arXiv:2012.13349 (2020)
50. Nazari, M., Oroojlooy, A., Snyder, L., Takac, M.: Reinforcement learning for solv-
ing the vehicle routing problem. In: Advances in Neural Information Processing
Systems (NeurIPS), pp. 9860–9870 (2018)
51. Novoa, C., Storer, R.: An approximate dynamic programming approach for the
vehicle routing problem with stochastic demands. Eur. J. Oper. Res. (EJOR)
196(2), 509–515 (2009)
52. Nowak, A., Villar, S., Bandeira, A.S., Bruna, J.: A note on learning algorithms
for quadratic assignment with graph neural networks. In: Principled Approaches
to Deep Learning Workshop at the International Conference on Machine Learning
(ICML) (2017)
53. Paszke, A., et al.: Pytorch: an imperative style, high-performance deep learning
library. In: Advances in Neural Information Processing Systems (NeurIPS), vol.
32, pp. 8026–8037 (2019)
54. Peng, B., Wang, J., Zhang, Z.: A deep reinforcement learning algorithm using
dynamic attention model for vehicle routing problems. In: Li, K., Li, W., Wang,
H., Liu, Y. (eds.) ISICA 2019. CCIS, vol. 1205, pp. 636–650. Springer, Singapore
(2020). https://doi.org/10.1007/978-981-15-5577-0 51
55. Ropke, S., Pisinger, D.: An adaptive large neighborhood search heuristic for the
pickup and delivery problem with time windows. Transp. Sci. 40(4), 455–472 (2006)
56. Schrimpf, G., Schneider, J., Stamm-Wilbrandt, H., Dueck, G.: Record breaking
optimization results using the ruin and recreate principle. J. Comput. Phys. 159(2),
139–171 (2000)
57. Silver, D., et al.: A general reinforcement learning algorithm that masters chess,
shogi, and go through self-play. Science 362(6419), 1140–1144 (2018)
58. Sun, Y., Ernst, A., Li, X., Weiner, J.: Generalization of machine learning for prob-
lem reduction: a case study on travelling salesman problems. OR Spectr. 43(3),
607–633 (2020). https://doi.org/10.1007/s00291-020-00604-x
59. Toth, P., Vigo, D.: Vehicle Routing: Problems, Methods, and Applications. SIAM
(2014)
60. Uchoa, E., Pecin, D., Pessoa, A., Poggi, M., Vidal, T., Subramanian, A.: New
benchmark instances for the capacitated vehicle routing problem. Eur. J. Oper.
Res. (EJOR) 257(3), 845–858 (2017)
61. Vesselinova, N., Steinert, R., Perez-Ramirez, D.F., Boman, M.: Learning combi-
natorial optimization on graphs: a survey with applications to networking. IEEE
Access 8, 120388–120416 (2020)
62. Vidal, T.: Hybrid genetic search for the CVRP: open-source implementation and
swap* neighborhood. arXiv preprint arXiv:2012.10384 (2020)

Deep Policy Dynamic Programming for Vehicle Routing Problems
213
63. Vidal, T., Crainic, T.G., Gendreau, M., Lahrichi, N., Rei, W.: A hybrid genetic
algorithm for multidepot and periodic vehicle routing problems. Oper. Res. 60(3),
611–624 (2012)
64. Vinyals, O., Fortunato, M., Jaitly, N.: Pointer networks. In: Advances in Neural
Information Processing Systems (NeurIPS), pp. 2692–2700 (2015)
65. Wiseman, S., Rush, A.M.: Sequence-to-sequence learning as beam-search opti-
mization. In: Conference on Empirical Methods in Natural Language Processing
(EMNLP), pp. 1296–1306 (2016)
66. Wu, Y., Song, W., Cao, Z., Zhang, J., Lim, A.: Learning improvement heuristics
for solving routing problems. IEEE Trans. Neural Netw. Learn. Syst. (2021)
67. Xin, L., Song, W., Cao, Z., Zhang, J.: Step-wise deep learning models for solving
routing problems. IEEE Trans. Ind. Inform. (2020)
68. Xin, L., Song, W., Cao, Z., Zhang, J.: NeuroLKH: combining deep learning model
with Lin-Kernighan-Helsgaun heuristic for solving the traveling salesman problem.
In: Advances in Neural Information Processing Systems (NeurIPS) (2021)
69. Xu, S., Panwar, S.S., Kodialam, M., Lakshman, T.: Deep neural network approxi-
mated dynamic programming for combinatorial optimization. In: AAAI Conference
on Artiﬁcial Intelligence (AAAI), vol. 34, pp. 1684–1691 (2020)
70. Yang, F., Jin, T., Liu, T.Y., Sun, X., Zhang, J.: Boosting dynamic program-
ming with neural networks for solving np-hard problems. In: Asian Conference
on Machine Learning (ACML), pp. 726–739. PMLR (2018)

Learning a Propagation Complete
Formula
Petr Kuˇcera(B)
Department of Theoretical Computer Science and Mathematical Logic,
Faculty of Mathematics and Physics, Charles University, Prague, Czech Republic
kucerap@ktiml.mff.cuni.cz
Abstract. Propagation complete formulas were introduced by Bor-
deaux and Marques-Silva (2012) as a possible target language for knowl-
edge compilation. A CNF formula is propagation complete (PC) if for
every partial assignment, the implied literals can be derived by unit
propagation. Bordeaux and Marques-Silva (2012) proposed an algorithm
for compiling a CNF formula into an equivalent PC formula which is
based on incremental addition of so-called empowering implicates. In
this paper, we propose a compilation algorithm based on the implica-
tional structure of propagation complete formulas described by Kuˇcera
and Savick´y (2020) and the algorithm for learning a deﬁnite Horn formula
with closure and equivalence queries introduced by Atserias et al. (2021).
We have implemented both approaches and compared them experimen-
tally. Babka et al. (2013) showed that checking if a CNF formula admits
an empowering implicate is an NP-complete problem. We propose a par-
ticular CNF encoding which allows us to use a SAT solver to check
propagation completeness, or to ﬁnd an empowering implicate.
Keywords: propagation complete formula · satisﬁability · consistency
checking · empowering clause · learning algorithm
1
Introduction
The class of propagation complete formulas was introduced in [11] as a possible
target language for knowledge compilation. A CNF formula ϕ is propagation
complete (PC), if for any partial assignment α, we can check the consistency
of ϕ ∧α by unit propagation and if ϕ ∧α is consistent, then unit propagation
derives the literals implied by ϕ ∧α.
PC encodings with existentially quantiﬁed auxiliary variables were used as
a target compilation language for a compilation from decision diagrams in [1].
Decomposable negation normal forms (DNNFs) introduced in [17] can be com-
piled into a PC encoding in polynomial time [28] and [30] showed that PC
encodings have the same properties as DNNFs with respect to query answering
and transformations according to the knowledge compilation map [19].
Propagation completeness can be characterized using the notion of empow-
erment [11,35]. In particular, a formula is not propagation complete if and only
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 214–231, 2022.
https://doi.org/10.1007/978-3-031-08011-1_15

Learning a Propagation Complete Formula
215
if it admits an empowering implicate [11]. To compile a CNF into a PC formula,
we can thus use an incremental approach suggested in [11] in which we keep
adding empowering clauses to a formula, until it becomes propagation complete.
In this approach, we can use the fact that the clauses learned by a CDCL SAT
solver when called on the formula are empowering [35]. We can also look for an
empowering implicate using a SAT solver [7]. To keep a formula compact, we
can remove the clauses that are absorbed [4] by the others. Following [11], we
refer to this step as minimization.
Two other approaches to the automatic construction of a PC formula were
described in [14,21]. Both of these approaches are based on considering all partial
assignments and are usable only for formulas on a very small number of variables.
The authors of [29] introduced the notion of an implicational dual rail encod-
ing associated with a given CNF formula ϕ. It uses the well-known dual rail
encoding of partial assignments [9,15,25,32,34] to simulate unit propagation in
ϕ in the same way as [8,10]. If ψ is a PC formula equivalent to ϕ, then the
deﬁnite Horn part of the implicational dual rail encoding of ψ deﬁnes a partic-
ular deﬁnite Horn function and the compilation of ϕ into a PC formula can be
described as learning a representation of this deﬁnite Horn function. An algo-
rithm for learning a deﬁnite Horn formula using membership and equivalence
queries was described in [2]. Later, [3] described an algorithm that learns a def-
inite Horn formula using closure and equivalence queries. In our case, a closure
query corresponds to ﬁnding all literals implied by a given partial assignment,
this query can be thus answered using a SAT solver on the input CNF. In an
equivalence query, we are looking for a negative example in form of a partial
assignment α and a literal l which is implied by ϕ ∧α, but it is not derived
by unit propagation. This is same as asking if ϕ an empowering implicate. We
describe an encoding that allows us to use a SAT solver to answer an equivalence
query. Our encoding exploits the structure of a directed graph associated with
the implicational dual rail encoding in a way similar to the encodings of ASP to
SAT (see for example [22]). The encoding is usually substantially harder to solve
than the input CNF. The equivalence query is thus more “expensive” than the
closure query. We verify experimentally that the learning approach based on the
algorithm from [3] uses substantially smaller number of the SAT based checks
of propagation completeness than the incremental approach and is thus a more
eﬃcient approach to the compilation of a CNF into a PC formula.
2
Propagation Complete Formulas
We assume the reader is familiar with the basics of propositional logic, especially
with the notion of entailment |= and the notation related to formulas in con-
junctive normal form (CNF formulas). We treat a clause as a set of literals and
a CNF formula as a set of clauses. We use lit(x) to denote the set of literals (x,
¬x) over the set of variables x. A set of literals α that contains a complementary
pair of literals is called contradictory, otherwise, it is a partial assignment. If an
assignment is clear from the context, we use simply x = 0 or x = 1 to denote
the value of a variable x in the assignment. We use ⊥to represent the empty
clause or a contradiction.

216
P. Kuˇcera
We use ϕ ⊢1 l to denote the fact that a literal l can be derived from formula
ϕ by unit propagation or, in other words, by an iterative use of unit resolution
rule which derives clause C given clauses C ∨e and ¬e for a literal e. Let ϕ be
a CNF formula on variables x and let α ⊆lit(x) be a set of literals. We deﬁne
the unit propagation closure of α with respect to ϕ as the set of literals we can
derive from ϕ ∧α with unit propagation, i.e.
Uϕ(α) = {l ∈lit(x) | ϕ ∧α ⊢1 l}.
Note that if ϕ does not contain the empty clause and ϕ ∧α ⊢1 ⊥, then Uϕ(α) is
a contradictory set of literals. It is not hard to check that U is a closure operator
(extensive, monotone, and idempotent).
We say that a clause C is an implicate of a formula ϕ if ϕ |= C. If f is the
boolean function represented by ϕ, then we also say that C is an implicate of f.
Clause C is a prime implicate of ϕ (resp. f) if no proper subclause of C is an
implicate of ϕ (resp. f). A CNF is prime if it consists only of prime implicates.
We say that implicate C is 1-provable by ϕ if ϕ ∧
l∈C ¬l ⊢1 ⊥.
The notion of a propagation complete CNF formula was introduced in [11].
Deﬁnition 1 (Propagation complete formula).
Let ϕ be a CNF formula
on a set of variables x. We say that ϕ is propagation complete (PC), if for every
partial assignment α ⊆lit(x) and for each l ∈lit(x), such that ϕ ∧α |= l we
have ϕ ∧α ⊢1 l or ϕ ∧α ⊢1 ⊥.
It was shown in [11] that propagation complete formulas can be characterized
using the notions of empowerment [35] and absorption [4]. We extend these
notions to non-implicates, since this is useful for algorithmic purposes. A non-
empty clause C is empowering with respect to a CNF formula ϕ if for some
literal (called empowered literal) l ∈C we have that ϕ ∧
e∈C\{l} ¬e ̸⊢1 l and
ϕ ∧
e∈C\{l} ¬e ̸⊢1 ⊥, and C is absorbed by ϕ otherwise. It was shown in [11]
that a CNF formula ϕ is propagation complete if and only if it does not admit
any empowering implicate or, equivalently, every non-empty implicate of ϕ is
absorbed by ϕ. Moreover, if ϕ is a PC formula and C ∈ϕ is such that C
is absorbed by ϕ′ = ϕ\{C}, then ϕ′ is a PC formula equivalent to ϕ. Since
testing absorption can be done in polynomial time, this can be used to obtain in
polynomial time an inclusion-wise minimal subformula ϕ′ of ϕ that is equivalent
to ϕ and which deﬁnes the same closure operator Uϕ′ as Uϕ. Following [11], we
refer to this step as minimization of ϕ. The clauses learned by a CDCL SAT
solver when run on ϕ are empowering [35].
We say that a boolean function f(x) is nontrivial if it is not a constant 0 or 1
function. Assume f(x) is a nontrivial boolean function on variables x and assume
ϕ is a CNF representation of f. We say that a partial assignment α ⊆lit(x) is a
partial model of f, if it can be extended to a model of f, in other words, ϕ∧α is
satisﬁable. The semantic closure of a set of literals α ⊆lit(x) is deﬁned as the
set of literals implied by ϕ ∧α (the backbone literals of ϕ ∧α)
Sf(α) = {l | ϕ ∧α |= l}.

Learning a Propagation Complete Formula
217
Note that if α is not a partial model (i.e. ϕ ∧α is unsatisﬁable), then Sf(α) =
lit(x). It follows that Uϕ(α) ⊆Sf(α). It is not hard to check that ϕ is propa-
gation complete if and only if for every set of literals α we have that Uϕ(α) is
contradictory, or Uϕ(α) = Sf(α). The following stronger property holds.
Lemma 1. Let f(x) be a nontrivial boolean function on variables x. Let ϕ be
a CNF representation of f(x). Then ϕ is PC if and only if Uϕ(α) = Sf(α) for
every partial model α ⊆lit(x) of f.
Proof. (only if ) Assume ϕ is PC and α is a partial model of f. It follows that
ϕ ∧α ̸⊢1 ⊥and thus Uϕ(α) is not contradictory and thus Uϕ(α) = Sf(α).
(if ) Assume that ϕ is not PC. We will show that there is a partial model
α ⊆lit(x) of f such that Uϕ(α) ⊊Sf(α). Since ϕ is not PC, there is an implicate
C of f which is empowering with respect to ϕ. Consider a prime subimplicate
C′ ⊆C, it was shown in [7] that C′ is empowering with respect to ϕ. It follows
that there is a literal l ∈C′ such that ϕ ∧
e∈C′\{l} ¬e ̸⊢1 l. On the other hand,
since C′ is an implicate of ϕ, we have ϕ ∧
e∈C′\{l} ¬e |= l. Set α = {¬e | e ∈
C′\{l}}. Because C′ is a prime implicate of f, we have that α is a partial model
of f. It follows that l ∈Sf(α)\Uϕ(α) and thus Uϕ(α) ⊊Sf(α).
The authors of [30] considered PC encodings with existentially quantiﬁed
auxiliary variables as a target compilation language in the sense of the knowledge
compilatiom map [19]. PC encodings allow consistency checking (CO), clausal
entailment (CE), and model enumeration (ME) queries. If we consider PC for-
mulas without existentially quantiﬁed variables, we also gain validity (VA) and
implicant check (IM) (because we consider CNF formulas), sentential entail-
ment (SE) and equality (EQ) (because the formulas are propagation complete).
PC formulas support conditioning (CD) and singleton forgetting (SFO), but for
forgetting (FO) and (bounded) disjunction, auxiliary variables are needed. In
addition, PC formulas can be used to compute the backbone literals relative to
a partial assignment in linear time. Model counting is hard for PC formulas (as
it is already hard for monotone CNF formulas), however, we believe that in some
applications, ME and VA might be suﬃcient.
3
Implicational Systems
Let us brieﬂy recall the notion of an implicational dual rail encoding introduced
in [29]. Assume a CNF formula ϕ that does not contain an empty clause. We
associate a variable l with every literal l on a variable from ϕ. The implicational
dual rail encoding DR(ϕ) associated with ϕ then contains deﬁnite Horn clause
representing the implications 
e∈C\{l}¬e
=⇒
l for every clause C ∈ϕ
and every literal l ∈C. This implication represents the fact that C is used to
derive l by unit propagation. In addition, DR(ϕ) contains clauses ¬x ∨¬¬x
to capture the fact that any model of DR(ϕ) represents a consistent set of literals
of ϕ. It was shown in [29] that if ψ is a PC formula equivalent to ϕ, then ϕ is
PC if and only if DR(ϕ) is equivalent to DR(ψ).

218
P. Kuˇcera
Assume a CNF ϕ, the deﬁnite Horn part of DR(ϕ) can be also interpreted
as an implicational system on literals Φ which consists of implications σ →τ
where both the body σ and tail τ are sets of literals. For every clause C ∈ϕ
and every literal l ∈C, we introduce body σ = {¬e | e ∈C\{l}}. For each
such body, Φ contains implication σ →τ with tail τ = {l | (
e∈σ ¬e ∨l) ∈ϕ}.
A single implication σ →τ in Φ thus corresponds to a conjunction of clauses

l∈τ(
e∈σ ¬e∨l). For example, clauses ¬a∨¬b∨c and ¬a∨¬b∨d introduce an
implication {a, b} →{c, d} with body {a, b} and tail {c, d}. Also, if l1, . . . , lk are
all literals in the unit clauses of ϕ, then Φ contains implication ∅→{l1, . . . , lk}.
We deﬁne the forward chaining closure FΦ(α) of a set of literals α ⊆lit(x)
in Φ as a minimal set of literals which satisﬁes that α ⊆FΦ(α) and if σ ⊆FΦ(α)
for some implication σ →τ ∈Φ, then also τ ⊆FΦ(α). If implication σ →τ is
used to add a literal e ∈τ during an iterative construction of the closure, we
say that it ﬁres for e. It follows that FΦ(α) = Uϕ(α). Implicational systems on
literals Φ and Ψ are equivalent if and only if FΦ(α) = FΨ(α) for every set of
literals α ⊆lit(x).
Note that an implicational system can be represented using diﬀerent bases.
The one that is so-called left-saturated and has a minimum number of impli-
cations is called Guigues-Duquenne (GD) basis and was introduced in [24]. A
body minimal representation can be constructed in polynomial time [31] and it
can be made irredundant as well [13].
We will use the following characterization of propagation completeness.
Lemma 2. Assume ϕ is a prime CNF representation of a boolean function f(x).
Let ψ be a prime PC representation of f and let Φ and Ψ be the implicational
systems associated with ϕ and ψ respectively. Then the following propositions
are equivalent:
(i) ϕ is PC.
(ii) Φ is equivalent to Ψ.
(iii) FΦ(α) = FΨ(α) for every partial model α ⊆lit(x) of f.
Proof. The equivalence of (i) and (ii) follows from the results of [12,29] as noted
above. The equivalence of (i) and (iii) follows by Lemma 1.
4
Checking Propagation Completeness by SAT
Let us ﬁx a boolean function f(x) on n variables x and a CNF representation
ϕ of f(x). We describe a CNF encoding E which is satisﬁable if and only if ϕ
admits a 1-provable empowering implicate C. By [7], this is equivalent to the
fact that ϕ is not PC. The encoding is built using the implicational system Φ
deﬁned in Sect. 3. We will assume that Φ = {σj →τj | j = 1, . . . , m}.
Given the implicational system Φ, we can rephrase the task as looking for
a partial assignment α and a literal l ∈α such that FΦ(α) is contradictory
(i.e. clause C = 
e∈α ¬e is 1-provable) and α′ = α\{l} is closed under forward
chaining in Φ (i.e. α′ = FΦ(α′)). Since ¬l ̸∈α′ = FΦ(α′), we have that C is

Learning a Propagation Complete Formula
219
empowering with empowered literal ¬l. We can assume that α′ is closed under
forward chaining without loss of generality, because adding literals derivable by
forward chaining to α′ does not change its forward chaining closure.
To encode the partial assignment α, we introduce the set of variables v =
{v[e] | e ∈lit(x)}. Literal l is selected by picking a variable in this literal using
s = {s[x] | x ∈x}. We use the following clauses to encode this semantics.
(C1) ¬v[x] ∨¬v[¬x]
for every x ∈x.
(C2) Clauses encoding the exactly one constraint on variables s.
A model of E then speciﬁes a partial assignment αE = 
e:v[e]=1 e, a clause
CE = 
e:v[e]=1 ¬e and a unique variable xE such that s[xE] = 1. The encoding
implies that there is a literal lE ∈α on variable xE.
Section 4.1 describes clauses representing the fact that CE is empowering
with respect to ¬lE. Section 4.2 describes the encoding of 1-provability of CE. In
Sect. 4.3, we will discuss how to put these parts together.
4.1
Encoding Empowerment
In this section, we describe the part of the encoding that ensures that CE is
empowering with empowered literal ¬lE. Denote α′
E = αE\{xE, ¬xE}, we encode
the fact that α′
E is not contradictory and it is closed under unit propagation in
ϕ (in particular, FΦ(α′
E) = α′
E). To this end, we introduce variable p[l] for every
literal l ∈lit(x) and clauses representing the following subformulas.
(E1) p[l] ⇐⇒¬s[x] ∧v[l] for every variable x ∈x and every literal l ∈{x, ¬x}.
(E2) 
e∈σj p[e] =⇒p[l] for every implication σj →τj ∈Φ and every l ∈τj.
Assume a model of E. Clauses of group (E1) ensure that the set of literals l for
which p[l] = 1 is exactly α′
E. Since α′
E ⊆αE, we have that α′
E is not contradictory
by using clauses (C1). Clauses (E2) ensure that FΦ(α′
E) = α′
E.
4.2
Encoding 1-Provability
In this section, we describe the part of the encoding which ensures that FΦ(αE)
is contradictory, in other words CE is 1-provable. The idea of our encoding is
based on the encodings of ASP to SAT (see for example [22]).
We associate a directed graph G = (V, E) with the system of implications Φ.
The set of vertices of G is V = lit(x) and a pair of literals l1, l2 ∈lit(x) forms
an edge (l1, l2) ∈E iﬀl1 ∈σj and l2 ∈τj for some implication σj →τj in Φ.
A strongly connected component (SCC) of G is an inclusion-wise maximal
set of nodes S such that G contains a directed path between any pair of nodes
of S. Let S1, . . . , Sq be the list of all strongly connected components (SCCs) of
G. Due to maximality requirement, the SCCs in the list are pairwise disjoint.
Every literal e ∈lit(x) thus belongs to exactly one SCC whose index is denoted

220
P. Kuˇcera
scc(e). We will assume that the SCCs are topologically ordered, in particular,
for every edge (l1, l2) ∈E we have scc(l1) < scc(l2).
For an SCC Si, i = 1, . . . , q, we use ni = | var(Si)| to denote the number of
diﬀerent variables in the literals within Si. For a literal e ∈lit(x), we deﬁne
ℓ(e) =

nscc(e)
scc(e) = scc(¬e)
nscc(e) −1
otherwise
For an SCC Si we also deﬁne n′
i = maxe∈Si ℓ(e). In particular, n′
i = ni if Si is
contradictory, otherwise n′
i = ni −1.
A level mapping λ assigns every literal e ∈lit(x) an integer satisfying 0 ≤
λ(e) ≤ℓ(e). Consider a set of literals L ⊆lit(x). We say that a literal e ∈L is
proven by implication σj →τj ∈Φ with λ, if
(i) e ∈τj,
(ii) σj ⊆L, and
(iii) λ(a) < λ(e) for every literal a ∈σj ∩Sscc(e).
We say that λ proves L with respect to a partial assignment α ⊆lit(x), if
every literal e ∈L\α is proven by some implication from Φ. The encoding of
1-provability is based on the following characterization.
Theorem 1. Let α ⊆lit(x) be a partial assignment. Then FΦ(α) is contradic-
tory, if and only if there is a contradictory set of literals L ⊆FΦ(α) and a level
mapping λ such that λ proves L with respect to α.
A similar characterization is known in the area of ASP [22], however, there
are two diﬀerences. Firstly, the bound ℓ(e) can be strictly smaller than |Sscc(e)|.
Secondly, our goal is to detect if a contradiction is derived, not a particular
literal. Theorem 1 directly follows from Lemma 3 and Lemma 4 below.
Lemma 3. Assume α ⊆lit(x) is a partial assignment and let L be a set of
literals which is proven by some level mapping λ with respect to α. Then L ⊆
FΦ(α).
Proof. Consider a literal e ∈L. If e ∈L ∩α, then clearly e ∈FΦ(α). Otherwise,
there is an implication σj →τj that proves e. We shall show by induction on
scc(e) and the value of λ(e) that e ∈FΦ(α).
Assume ﬁrst that e ∈S1 and λ(e) = 0. Since S1 is the ﬁrst in the topological
order, we have σj ⊆S1 and by (iii) we have σj = ∅. It follows that e ∈FΦ(α).
Suppose now that e ∈Si for i > 1 or λ(e) > 0. If σj = ∅, then trivially
e ∈FΦ(α). Otherwise, let a ∈σj be arbitrary and let us show that a ∈FΦ(α).
By (ii) we have that a ∈L. Since (a, e) ∈E, we get by (iii) that scc(a) < scc(e)
or λ(a) < λ(e). By induction hypothesis, we can conclude that σj ⊆FΦ(α) and
using σj →τj we obtain e ∈FΦ(α).
Lemma 4. Assume α ⊆lit(x) is a partial assignment and assume that FΦ(α)
is contradictory. Then there is a contradictory set of literals L ⊆FΦ(α) and a
level mapping λ such that λ proves L with respect to α.

Learning a Propagation Complete Formula
221
Proof. Set λ(a) = 0 for every literal a ∈α and initialize L = α. Then start
forward chaining derivation. While L is not contradictory, pick an implication
σj →τj such that σj ⊆L and τj ̸⊆L. Every literal e ∈τj\L is added to L and
we set λ(e) = 0 if σj ∩Sscc(e) = ∅and 1 + maxa∈σj∩Sscc(e) λ(a) otherwise. After
L becomes contradictory, we set λ(b) = 0 for every literal b ̸∈L.
Let Si be an SCC such that Si ∩L ̸= ∅and let l be the ﬁrst literal of Si
added to L. Then either l ∈α, or l is added due to implication σj →τj such
that σj ∩Si = ∅and l ∈τj. In both cases we have λ(l) = 0. If Si ∩L is not
contradictory, then the literals in Si ∩L are on pairwise disjoint variables. These
literals thus have at most ni diﬀerent levels. Since the smallest level is 0, we
have that λ(e) ≤ni −1 ≤ℓ(e) for every literal e ∈Si ∩L. Assume now that
Si ∩L is contradictory and assume that e is the last literal from Si added to L.
Denote S′
i = (Si ∩L)\{e}. Then S′
i is not contradictory and all literals a ∈S′
i
have levels λ(a) ≤ni −1 ≤ℓ(a). Since S′
i becomes contradictory after adding e,
we have that ¬e ∈Si and that λ(e) ≤ni = ℓ(e).
The encoding of 1-provability encodes the fact that there is a level mapping
which proves a contradictory set of literals L with respect to α. We consider
two ways of representing a level of a literal. In the unary representation, we use
an indicator variable of property λ(e) ≤k for every literal e and every possible
level λ(e) ∈{0, . . . , ℓ(e)}. In the binary representation, we represent the binary
representation of level λ(e) with a logarithmic number of bits. In both cases, we
associate an output variable out[e] with every literal e ∈lit(x) which indicates
if e ∈L. Set L is required to be contradictory by adding clausal encoding of the
following subformula.
(L1) 
x∈x out[x] ∧out[¬x]
We use the following observation in the description of the encodings.
Lemma 5. For every implication σj →τj ∈Φ, there is at most one SCC Si
such that Si ∩σj ̸= ∅and Si ∩τj ̸= ∅.
Proof. Assume there are two diﬀerent SCCs Si1 and Si2 satisfying the assump-
tion. Let a1 ∈Si1 ∩σj, a2 ∈Si2 ∩σj, b1 ∈Si2 ∩τj, and b2 ∈Si2 ∩τj. By having
σj →τj ∈Φ there is a path from a1 to b2, using Si2, there is a path from b2 to
a2. By having σj →τj ∈Φ, there is a path from a2 to b1 and using Si1, there is
a path from b1 to a1. Nodes a1, b2, a2, b1 thus belong to the same SCC which is
a contradiction with the assumption that Si1 is not equal to Si2.
We shall call the SCC Si satisfying the assumption of Lemma 5 the main
SCC of implication σj →τj. We shall use ms(j) to denote the main SCC of
implication σj →τj, or ∅if the implication does not have a main SCC.
In both versions of the encoding, we introduce a variable ﬁre[j] for every
implication σj →τj, such that τj\ms(j) ̸= ∅. It is an indicator variable of the
property that σj →τj can ﬁre for literals in τj\ms(j) regardless of the level.
This semantic is captured by the following clauses.

222
P. Kuˇcera
(F1) Unit clause ﬁre[j]
. . . for every implication σj →τj with σj = ∅.
(F2) ﬁre[j] =⇒
a∈σj out[a]
. . . for every implication σj →τj such that τj\ms(j) ̸= ∅.
Note that if σj = {a} for a single literal a, then ﬁre[j] can be identiﬁed with
out[a] and the corresponding subformula (F2) is not needed.
Unary Representation of Levels. We introduce variable drv[e, k] for every
literal e ∈lit(x) and every level k = 0, . . . , ℓ(e). It is an indicator variable of the
property that e was derived at level λ(e) ≤k. Variable drv[e, ℓ(e)] is identiﬁed
with the output variable out[e].
We also introduce variable ﬁreU[j, k] for every implication σj →τj ∈Φ which
has a main SCC Si and every k = 0, . . . , n′
i −1. It is an indicator variable of the
property that σj →τj can ﬁre for any literal e ∈τj ∩ms(j) at level λ(e) ≥k +1.
We use the clauses representing the following subformulas in the encoding.
(U1) ﬁreU[j, k] =⇒
a∈σj\ms(j) out[a] ∧
b∈σj∩ms(j) drv[b, k]
. . . for every k = 0, . . . , n′
i −1 assuming ms(j) = Si.
(U2) drv[e, 0] =⇒v[e] ∨
j : e∈τj\ms(j) ﬁre[j]
. . . for every literal e ∈lit(x).
(U3) drv[e, k] =⇒drv[e, k −1] ∨
j : e∈τj∩ms(j) ﬁreU[j, k −1]
. . . for every literal e ∈lit(x) and every level value k = 1, . . . , ℓ(e).
Recall that out[e] is identiﬁed with drv[e, ℓ(e)] for every literal e ∈lit(x) and
thus the respective implication (U3) captures the necessary requirements on the
derivability of e when out[e] = 1. Note that if σj = {a} for a single literal a, then
ﬁreU[j, k] can be identiﬁed with drv[a, k] and subformula (U1) is not needed.
Binary Encoding with Direct Inequalities. With every literal e ∈lit(x),
we associate a bitvector B[e] which represents the binary representation of level
λ(e). The width of bitvectors of literals in an SCC Si is set to wi = ⌈log2(n′
i+1)⌉.
In addition to the previously deﬁned variables, we introduce variable
ﬁreB[j, e] for every implication σj →τj and every literal e ∈τj ∩ms(j). It
is an indicator variable of the fact that the implication σj →τj can ﬁre for
literal e.
We use the clauses representing the following subformulas in the encoding.
(D1) ﬁreB[j, e] =⇒
a∈σj out[a] ∧
a∈σj∩ms(j) B[e] > B[a]
. . . for every implication σj →τj and every literal e ∈τj ∩ms(j).
(D2) out[e] =⇒v[e] ∨
j : e∈τj\ms(j) ﬁre[j] ∨
j : e∈τj∩ms(j) ﬁreB[j, e]
. . . for every literal e ∈lit(x).
It is also possible to require B[e] ≤n′
scc(e) for every literal e ∈lit(x), but this
inequality is not needed for the correctness.

Learning a Propagation Complete Formula
223
4.3
Putting the Parts Together
We deﬁne two CNF encodings. They share the base clauses for subformulas (C1),
(C2), (E1)–(E2), (L1), and (F1)–(F2). The unary encoding Eu contains the base
clauses and the clauses for subformulas (U1)–(U3). The binary direct encoding
Ed contains the base clauses and the clauses for subformulas (D1)–(D2).
Recall that n = |x| and m denotes the number of implications in Φ (which
is bounded by ∥ϕ∥= 
C∈ϕ |C|). Denote ℓm = max{n′
i | i = 1, . . . , q}. Then Eu
has Θ(n + (m + n)ℓm) variables and Ed has O(n + t + (n + |E|) log2 ℓm) variables
where t = m
j=1 τj and E is the set of edges of the graph G associated with the
implicational system Φ (the estimate includes the auxiliary variables needed to
encode the inequalities on bitvectors in subformulas (D1)).
Value of ℓm can be as much as n, but can also be much smaller if the graph
G has only small SCCs. The exact sizes of the encodings thus depend on the
structure of the formula ϕ and its associated implicational system Φ. To increase
the eﬃciency of a SAT-based PC check, we use the following approach. The
compiler maintains a bound δ initialized with value 1. When a PC check should
be executed, we use δ as a level bound in the following way. In the unary encoding
Eu, we use additional restriction λ(e) ≤δ. In the binary direct encoding Ed, δ
limits the bit width of the bitvectors B[e]. If no empowering literal with the
restricted encoding is found, another attempt is performed without using the
additional restriction. If no empowering literal is found in this second check,
then the formula is propagation complete, otherwise, we use the empowering
implicate found in this way and we increase the bound by 1. The process ends
when δ reaches the maximum level bound—ℓm in the case of the unary encoding
Eu, and max{wi | i = 1, . . . , q} = ⌈log2(ℓm + 1)⌉in the case of the binary direct
encoding Ed.
Using this approach, we limit the size of the encoding in the most SAT based
PC checks which makes the process much more eﬃcient.
5
The Learning Approach to Compilation
In this section, we shall describe how the algorithm for learning a GD basis of
an implicational system with equivalence and closure queries [3] can be used to
construct a PC representation of a given boolean function f(x) given by its CNF
representation ϕ. Consider a PC formula ψ representing f(x) and let Ψ be the
implicational system associated with ψ. Following Lemma 2, our goal is to modify
ϕ in such a way that its associated implicational system Φ is equivalent to Ψ. To
answer a closure query, we need to compute FΨ(α) for a partial assignment α.
This step can be carried out by a SAT solver using ϕ, because FΨ(α) = Sf(α) due
to propagation completeness of ψ. To answer the equivalence query, we can use
SAT on the encoding described in Sect. 4. The overall structure of our approach
is described in Algorithm 1 which closely follows the algorithm from [3].
Preprocessing in Step 1 starts with ﬁnding backbone literals, propagating and
removing them from the CNF. The next step involves turning ϕ into a prime
CNF and minimizing ϕ by removing absorbed clauses.

224
P. Kuˇcera
Input: A CNF ϕ representing a boolean function f(x)
Output: A propagation complete CNF representing f(x).
1 ϕ ←preprocess(ϕ)
2 Γ ←empty list of implications
3 while next negative(α) do
4
forall σ →τ ∈Γ in order do
5
β ←α ∩σ
6
if β ⊊α and β ⊊Sf(β) then
7
Replace σ →τ with β →Sf(β) in Γ
8
add implication(ϕ, β →Sf(β))
9
break
10
if no implication was replaced then
11
Add α →Sf(α) as the last implication of Γ
12
add implication(ϕ, α →Sf(α))
13 return ϕ
Algorithm 1: Learning a PC representation
The algorithm maintains the hypothesis in two forms. The CNF ϕ and the
implicational system Γ represented as a list of implications. The implications in
Γ are kept in the order in which they are added to the hypothesis. The order is
important for the proof of correctness and complexity of the algorithm, see [3] for
more details. Implicational system Γ is initially empty. During the work of the
algorithm, both the CNF ϕ and the implicational system Γ are being updated.
Implicational system Γ is not necessarily equivalent to the implicational system
Φ associated to ϕ. However, at any moment we have for every partial assignment
α that FΓ (α) ⊆FΦ(α) ⊆Sf(α). In particular, when Γ is equivalent to Ψ, then
also Φ is equivalent to Ψ and thus ϕ is propagation complete. To avoid SAT
based PC checks which would improve Γ but not Φ, we try to keep Γ as close
to Φ as possible. We use ϕ to answer closure queries, i.e. to compute Sf(α).
Function next negative(α) represents the equivalence query. It looks for a
negative example in form of a partial model α for which α = FΓ (α) ⊊Sf(α). If
no negative example is found, the compilation ﬁnishes and ϕ is PC.
An important feature of the learning algorithm is that if α is a negative
example, then the corresponding implication α →Sf(α) is not directly added
to Γ, but the algorithm ﬁrst tries to use α to reﬁne an existing implication of
Γ at steps 4–9. Only if no existing implication can be reﬁned, the implication is
added to Γ using function add implication().
Function add implication(ϕ, σ →τ) is used to add the clauses corre-
sponding to the implication σ →τ to ϕ. This step is important to have that
Φ always lies between Γ and Ψ. For every literal l ∈τ we construct clause
C = (
e∈σ ¬e ∨l). We check if C is empowering for ϕ and if so, then a prime
subimplicate of C is added to ϕ. After adding a certain amount of clauses to ϕ,
we run minimization on ϕ to remove clauses that are absorbed by the others.
We use the following sources of negative examples in our implementation.

Learning a Propagation Complete Formula
225
(i) The initial list of candidates on negative examples is extracted from the
input CNF ϕ. The default is to use all bodies in a body minimal represen-
tation of the implicational system Φ.
(ii) Whenever a clause C is being added to ϕ using add implication(), we
check for every l ∈C, if a partial assignment αl = 
e∈C\{l} ¬e is a nega-
tive example. Note that αl is a partial model, because we only add prime
implicates C to ϕ. This way, we keep Γ to Φ as close as possible.
(iii) When an implication of Γ is being replaced during the reﬁnement (steps 4–
9), both σ and α are checked if they are negative examples.
(iv) When a SAT solver is used on ϕ, we collect the learned clauses and use
them as a source of possible negative examples as in (ii).
(v) We use random checks of propagation completeness in which we try a ran-
dom partial assignment α′ and check if we can obtain a negative example
of it.
– If α′ is a partial model, then we check if α = FΓ (α′) ⊊Sf(α′).
– If C = 
e∈α′ ¬e is an implicate of f, then we ﬁnd a prime subimplicate
C′ of C and we try to ﬁnd a negative example based on C′ as in (ii).
(vi) We use SAT based checks of propagation completeness using the encod-
ing described in Sect. 4. In the construction of the encoding, we use Γ to
encode empowerment as described in Sect. 4.1. However, the encoding of
1-provability (described in Sect. 4.2) is based on the implicational system
Φ associated with ϕ as it is potentially stronger than Γ.
It follows by the results of [3] that the number of equivalence queries needed
by the algorithm is bounded by O(mn) where m is the number of implications
in a GD basis of Ψ and n = |x|. Each negative example found by one of the ways
listed above counts as an equivalence query. The fact that we have a bound on
the number of equivalence queries needed to compile the formula is the main
motivation for using Algorithm 1, because our goal is to minimize the number
of SAT based checks of propagation completeness.
6
Experiments
We have implemented the learning algorithm as part of the tool pccompile
which can be accessed through the project web pages [27]. The program uses
SAT solver Glucose 4.1 [5,6] which is based on MiniSat 2.2 [20]. All experiments
were executed on a computational server with CPU Intel R⃝Xeon R⃝CPU E5–
2420 v2 @ 2.20 GHz and with 32 of memory.
We have also implemented the incremental approach which follows the idea
proposed in [11]. After the preprocessing (which is the same as in Algorithm 1),
the incremental algorithm keeps adding empowering implicates to the input CNF
formula ϕ, until it becomes PC. In addition to the SAT based PC checks, we use
the clauses learned during the SAT calls on ϕ (e.g. when ﬁnding a prime subim-
plicate of a clause) as a source of empowering implicates. Formula is regularly

226
P. Kuˇcera
Table 1. Results on random CNF formulas. See the description of the instances and
columns in the text.
set
A
t
tc
p+
t+
p
p−
t−
p
modgen60.1 I
66.11 s
42.07 s
431
37.26 s 4
26.38 s
L
54.66 s
30.98 s
134
25.76 s 4
25.79 s
LR
49.40 s
26.20 s
54
18.68 s 4
25.11 s
modgen60.2 I
541.10 s 373.08 s 1084
322.20 s 5
193.75 s
L
484.75 s 280.57 s
309
241.67 s 5
223.77 s
LR
525.30 s 237.80 s
171
197.58 s 5
245.46 s
modgen80
I
1000.09 s 671.66 s 1478
582.33 s 5
356.45 s
L
842.53 s 537.15 s
438
466.29 s 5
308.42 s
LR
751.48 s 448.24 s
237
373.98 s 5
322.84 s
minimized by removing absorbed clauses. We have not performed any experi-
ments with the algorithms introduced in [14,21], because these approaches are
only suitable for formulas with a small number of variables.
In the ﬁrst set of experiments, we used three sets of random 3-CNF formu-
las generated using the modularity based generator [23]. Each set contains 50
instances generated with the following settings: modgen60.1 (60 variables, 120
clauses, 4 communities, PC formulas with 497 clauses on average), modgen60.2
(60 variables, 150 clauses, 3 communities, PC formulas with 1008 clauses on aver-
age), modgen80 (80 variables, 200 clauses, 4 communities, PC formulas with 1377
clauses on average).
Table 1 contains the results of experiments on these instances. Column “A”
contains the version of the algorithm where “I” stands for incremental, “L” for
the learning algorithm. We have run the learning algorithm twice—with (“LR”)
and without (“L”) using the randomly generated negative examples (obtained
by (v)). Column t contains the total running time, tc contains the time of com-
pilation without including the last SAT based PC check (as the last SAT based
PC check is present in both algorithms, it makes sense to compare the time
of compilation without it). Columns p+ and t+
p contain the number and total
time of the SAT based PC checks with result SAT (i.e. those which found an
empowering implicate or a negative example). Columns p−and t−
p contains the
number of total time of the SAT based PC checks with result UNSAT. In all
cases, we used the unary encoding Eu, the binary direct encoding Ed was about
3 to 4 times slower.
We can see that the learning algorithm has substantially smaller number of
SAT based PC checks, which is even smaller with using randomly generated
negative examples. The diﬀerence in tc is also signiﬁcant, although not as much
as the diﬀerence in the number of SAT based PC checks would suggest. This is
because the learning algorithm is more complex than the incremental algorithm.
In the second set of experiments, we have run pccompile on some of the
benchmark formulas obtained from [16]. The results are contained in Table 2.

Learning a Propagation Complete Formula
227
Table 2. Results on benchmark CNF formulas. See the description of the instances
and columns in the text.
instance
A
n
m
nb
mout
t
tc
p+
t+
p
C169 FV
I
1411
1982
50
1404
0.03 s
0.01 s
1
0.01 s
L
1411
1982
50
1404
0.06 s
0.04 s
0
0
s
C169 FW
I
1411
1982
50
1404
0.04 s
0.02 s
2
0.01 s
L
1411
1982
50
1404
0.06 s
0.04 s
0
0
s
C171 FR
I
1758
4005
451
2921
184.61 s
159.11 s
177
145.59 s
L
1758
4005
451
2921
117.25 s
83.75 s
11
13.69 s
C211 Fs
I
1635
3662
247
3068
1049.31 s 1031.47 s 1972
758.04 s
L
1635
3662
247
3070
93.51 s
71.49 s
3
1.53 s
C211 FW
I
1665
5929
341
5347
6980.68 s 6789.70 s 3433
3760.19 s
L
1665
5929
341
5354
2852.89 s 2633.81 s
73
443.54 s
C250 FV
I
1465
2356
129
1470
4.31 s
4.07 s
52
3.48 s
L
1465
2356
129
1471
1.02 s
0.73 s
0
0
s
C250 FW
I
1465
2356
129
1470
4.19 s
3.93 s
52
3.33 s
L
1465
2356
129
1471
1.03 s
0.75 s
0
0
s
sat-grid-pbl-0010 I
110
191
102
297
4.42 s
4.00 s
127
3.01 s
L
110
191
102
297
2.46 s
1.52 s
1
0.04 s
sat-grid-pbl-0015 L
240
436
232
15984
7261.54 s 4249.99 s
17
2112.25 s
log-1
I
939
3785
308
1294
1412.17 s
655.78 s
386
564.69 s
L
939
3785
308
1280
587.50 s
189.45 s
33
113.51 s
ais6
I
61
581
59
1955
2971.50 s 2927.32 s 4025
973.85 s
L
61
581
59
1948
966.39 s
928.25 s
922
634.62 s
Formulas C169 FV to C250 FW belong to the Conﬁguration category, formu-
las sat-grid-pbl-0010 and sat-grid-pbl-0015 belong to BayesianNetwork, log-1
belongs to Planning, and ais6 belongs to the Handmade category. We have used
the unary encoding Eu on ais6 (we were not able to compile the formula with
using Ed). For the rest of formulas, we list the results for the binary-direct encod-
ing Ed as it performed better. In addition to the columns already used in Table 1,
we use the following columns: Columns n and m contain the number of variables
and clauses in the instance. Column nb contains the number of variables after
propagating and removing the backbone literals (the instances we consider usu-
ally have lots of backbones which are removed in the preprocessing and ignored
for the rest of the compilation). Column mout contains the number of clauses in
the output PC formula (including the unit clauses for the backbone literals).
In all cases, the learning algorithm outperforms the incremental one. The
diﬀerence in the number of SAT based PC checks is quite signiﬁcant in all cases
as well, this is especially true for the C211 FS and C211 FW instances. We have
been able to compile sat-grid-pbl-0015 only using the learning algorithm. The
incremental algorithm did not ﬁnish computation within 15 h (it made 12 518
SAT based PC checks within this time).

228
P. Kuˇcera
7
Conclusion
Although the learning approach generally outperforms the incremental one, it
has the following main limitations.
(A) The output formula can be much bigger than the input formula.
(B) Checking propagation completeness with SAT is hard.
Related to (A) is the fact that there are even Horn CNF formulas, for which
any equivalent PC formula is necessarily exponentially bigger [29]. By using the
learning algorithm, we make sure that the size of the output PC formula is
within a polynomial factor from the size of a smallest equivalent PC formula.
To tackle (B), we have designed an encoding that limits the necessary number
of levels of unit propagation. It is possible that a better upper bound on the
number of levels of unit propagation could be derived from the structure of the
formula. This would lead to a smaller encoding of 1-provability, possibly making
SAT based PC checks easier.
The algorithm is based on an assumption that the SAT on the input formula
is easy and thus answering the closure query is easy. This is satisﬁed by most
of the instances in [16]. Let us also note that if a CNF formula is hard for SAT,
it is also presumably far from being PC which is related to (A). When a SAT
solver is run on a hard formula, it takes a long time, but the solver also learns a
lot of clauses that can be used as a source of negative examples in the algorithm.
We have to admit that most of the benchmark formulas in [16] are currently
out of reach for the method presented in the paper. For this reason, we have
included the results of experiments only on a handful of formulas which we were
able to successfully compile. For the same reason, we used random formulas
to compare the incremental approach with the learning approach. Modularity
based generator [23] was used to introduce some structure into the formulas.
The compilers from a CNF into a d-DNNF such as D4 [26] or c2d [18] can
successfully compile much more formulas than pccompile. Let us note, however,
that if we run D4 on C171 FR, we obtain a Decision DNNF with 483486 nodes
while the formula output by pccompile has length (i.e. the sum of the lengths
of the clauses) only 4731. Similarly, for C211 FW we get a Decision DNNF
with 635993 nodes and PC CNF has length 15563. Thus for some instances, our
approach can produce substantially smaller formulas than D4.
As a direction of future research, we would like to consider adding auxiliary
variables to the formula, e.g. using a variant of bounded variable addition [33].
Acknowledgements. The author acknowledges the support by Grant Agency of the
Czech Republic (grant No. GA19–19463S). The author would like to thank Pierre
Marquis, Jean-Marie Lagniez, Gilles Audemard, and Stefan Mengel (from CRIL, U.
Artois, Lens, France) who proposed the problem of compilation of a CNF into a PC
formula. Last, but not least, the author would like to thank Petr Savick´y for lots of
discussions that helped to ﬁnish this paper and, in particular, for the suggestion to use
the learning algorithm for the compilation.

Learning a Propagation Complete Formula
229
References
1. Ab´ıo, I., Gange, G., Mayer-Eichberger, V., Stuckey, P.J.: On CNF encodings of
decision diagrams. In: Quimper, C.-G. (ed.) CPAIOR 2016. LNCS, vol. 9676, pp.
1–17. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-33954-2 1
2. Angluin, D., Frazier, M., Pitt, L.: Learning conjunctions of Horn clauses. Mach.
Learn. 9(2), 147–164 (1992). https://doi.org/10.1007/BF00992675
3. Arias,
M.,
Balc´azar,
J.L.,
Tˆırn˘auc˘a,
C.:
Learning
deﬁnite
Horn
formulas
from closure queries. Theor. Comput. Sci. 658, 346–356 (2017). https://doi.
org/10.1016/j.tcs.2015.12.019, https://www.sciencedirect.com/science/article/pii/
S0304397515011809. Horn formulas, directed hypergraphs, lattices and closure sys-
tems: related formalism and application
4. Atserias, A., Fichte, J.K., Thurley, M.: Clause-learning algorithms with many
restarts and bounded-width resolution. J. Artif. Int. Res. 40(1), 353–373 (2011)
5. Audemard, G., Simon, L.: Predicting learnt clauses quality in modern SAT solvers.
In: Twenty-ﬁrst International Joint Conference on Artiﬁcial Intelligence (2009)
6. Audemard, G., Simon, L.: Glucose 4.1. https://www.labri.fr/perso/lsimon/glucose.
Accessed 14 Apr 2022
7. Babka, M., Balyo, T., ˇCepek, O., Gursk´y, ˇS., Kuˇcera, P., Vlˇcek, V.: Com-
plexity issues related to propagation completeness. Artif. Intell. 203, 19–
34 (2013). https://doi.org/10.1016/j.artint.2013.07.006, http://www.sciencedirect.
com/science/article/pii/S0004370213000726
8. Bessiere, C., Katsirelos, G., Narodytska, N., Walsh, T.: Circuit complexity and
decompositions of global constraints. In: Proceedings of the Twenty-First Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI-09), pp. 412–418 (2009)
9. Bonet, M.L., Buss, S., Ignatiev, A., Marques-Silva, J., Morgado, A.: MaxSAT res-
olution with the dual rail encoding. In: Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, vol. 32, no. 1, April 2018. https://ojs.aaai.org/index.php/
AAAI/article/view/12204
10. Bordeaux, L., Janota, M., Marques-Silva, J., Marquis, P.: On unit-refutation com-
plete formulae with existentially quantiﬁed variables. In: Proceedings of the Thir-
teenth International Conference on Principles of Knowledge Representation and
Reasoning, KR 2012, pp. 75–84. AAAI Press (2012). http://dl.acm.org/citation.
cfm?id=3031843.3031854
11. Bordeaux, L., Marques-Silva, J.: Knowledge compilation with empowerment. In:
Bielikov´a, M., Friedrich, G., Gottlob, G., Katzenbeisser, S., Tur´an, G. (eds.) SOF-
SEM 2012. LNCS, vol. 7147, pp. 612–624. Springer, Heidelberg (2012). https://
doi.org/10.1007/978-3-642-27660-6 50
12. Boros,
E.,
ˇCepek,
O.,
Kogan,
A.,
Kuˇcera,
P.:
Exclusive
and
essential
sets of implicates of boolean functions. Discrete Appl. Math. 158(2), 81–
96 (2010). https://doi.org/10.1016/j.dam.2009.08.012, http://www.sciencedirect.
com/science/article/B6TYW-4XBP93T-1/2/dfeacfe4911d5f1e5aed44f1ea8dc6bb
13. Boros, E., ˇCepek, O., Makino, K.: Strong duality in horn minimization. In: Klas-
ing, R., Zeitoun, M. (eds.) FCT 2017. LNCS, vol. 10472, pp. 123–135. Springer,
Heidelberg (2017). https://doi.org/10.1007/978-3-662-55751-8 11
14. Brain, M., Hadarean, L., Kroening, D., Martins, R.: Automatic generation of prop-
agation complete SAT encodings. In: Jobstmann, B., Leino, K.R.M. (eds.) VMCAI
2016. LNCS, vol. 9583, pp. 536–556. Springer, Heidelberg (2016). https://doi.org/
10.1007/978-3-662-49122-5 26

230
P. Kuˇcera
15. Bryant, R.E., Beatty, D., Brace, K., Cho, K., Sheﬄer, T.: COSMOS: a com-
piled simulator for MOS circuits. In: Proceedings of the 24th ACM/IEEE Design
Automation Conference, DAC 1987, pp. 9–16. Association for Computing Machin-
ery, New York (1987). https://doi.org/10.1145/37888.37890
16. Compile! Project: Benchmarks. https://www.cril.univ-artois.fr/KC/benchmarks.
html. Accessed 14 Apr 2022
17. Darwiche, A.: Compiling knowledge into decomposable negation normal form. In:
Proceedings of the 16th International Joint Conference on Artiﬁcal Intelligence,
IJCAI 1999, vol. 1, pp. 284–289. Morgan Kaufmann Publishers Inc., San Francisco
(1999)
18. Darwiche, A.: New advances in compiling CNF to decomposable negation nor-
mal form. In: Proceedings of the 16th European Conference on Artiﬁcial Intelli-
gence, ECAI 2004, pp. 318–322. IOS Press, Amsterdam (2004). http://dl.acm.org/
citation.cfm?id=3000001.3000069
19. Darwiche, A., Marquis, P.: A knowledge compilation map. J. Artif. Intell. Res. 17,
229–264 (2002)
20. E´en, N., S¨orensson, N.: An extensible SAT-solver. In: Giunchiglia, E., Tacchella,
A. (eds.) SAT 2003. LNCS, vol. 2919, pp. 502–518. Springer, Heidelberg (2004).
https://doi.org/10.1007/978-3-540-24605-3 37
21. Ehlers, R., Palau Romero, F.: Approximately propagation complete and conﬂict
propagating constraint encodings. In: Beyersdorﬀ, O., Wintersteiger, C.M. (eds.)
SAT 2018. LNCS, vol. 10929, pp. 19–36. Springer, Cham (2018). https://doi.org/
10.1007/978-3-319-94144-8 2
22. Fandinno, J., Hecher, M.: Treewidth-aware complexity in ASP: not all positive
cycles are equally hard. In: Thirty-Fifth AAAI Conference on Artiﬁcial Intelligence,
AAAI 2021, Thirty-Third Conference on Innovative Applications of Artiﬁcial Intel-
ligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artiﬁcial
Intelligence, EAAI 2021, Virtual Event, 2–9 February 2021, pp. 6312–6320. AAAI
Press (2021). https://ojs.aaai.org/index.php/AAAI/article/view/16784
23. Gir´aldez-Cru, J., Levy, J.: A modularity-based random SAT instances generator.
In: Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence (2015)
24. Guigues, J.L., Duquenne, V.: Familles minimales d’implications informatives
r´esultant d’un tableau de donn´ees binaires. Math. Sci. Hum. 95, 5–18 (1986)
25. Ignatiev, A., Morgado, A., Marques-Silva, J.: On tackling the limits of resolution
in SAT solving. In: Gaspers, S., Walsh, T. (eds.) SAT 2017. LNCS, vol. 10491, pp.
164–183. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-66263-3 11
26. Jean-Marie Lagniez, P.M.: An improved decision-DNNF compiler. In: Proceed-
ings of the Twenty-Sixth International Joint Conference on Artiﬁcial Intelligence,
IJCAI-17, pp. 667–673 (2017). https://doi.org/10.24963/ijcai.2017/93
27. Kuˇcera, P.: Program pccompile. http://ktiml.mﬀ.cuni.cz/∼kucerap/pccompile
(2021), accessed: 2022–04-14
28. Kuˇcera, P., Savick´y, P.: Propagation complete encodings of smooth DNNF theories.
arXiv preprint arXiv:1909.06673 (2019)
29. Kuˇcera, P., Savick´y, P.: Bounds on the size of PC and URC formulas. J. Artif.
Intell. Res. 69, 1395–1420 (2020)
30. Kuˇcera, P., Savick´y, P.: Backdoor decomposable monotone circuits and propaga-
tion complete encodings. In: Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, vol. 35, no. 5, pp. 3832–3840 (2021). https://ojs.aaai.org/index.php/
AAAI/article/view/16501
31. Maier, D.: Minimal covers in the relational database model. J. ACM 27, 664–674
(1980)

Learning a Propagation Complete Formula
231
32. Manquinho, V.M., Flores, P.F., Silva, J.P.M., Oliveira, A.L.: Prime implicant com-
putation using satisﬁability algorithms. In: Proceedings Ninth IEEE International
Conference on Tools with Artiﬁcial Intelligence, pp. 232–239, November 1997.
https://doi.org/10.1109/TAI.1997.632261
33. Manthey, N., Heule, M.J.H., Biere, A.: Automated reencoding of boolean formulas.
In: Biere, A., Nahir, A., Vos, T. (eds.) HVC 2012. LNCS, vol. 7857, pp. 102–117.
Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-39611-3 14
34. Morgado, A., Ignatiev, A., Bonet, M.L., Marques-Silva, J., Buss, S.: DRMaxSAT
with MaxHS: ﬁrst contact. In: Janota, M., Lynce, I. (eds.) SAT 2019. LNCS, vol.
11628, pp. 239–249. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
24258-9 17
35. Pipatsrisawat, K., Darwiche, A.: On the power of clause-learning SAT solvers as
resolution engines. Artif. Intell. 175(2), 512–525 (2011). https://doi.org/10.1016/
j.artint.2010.10.002, http://dx.doi.org/10.1016/j.artint.2010.10.002

A FastMap-Based Algorithm for Block
Modeling
Ang Li1(B), Peter Stuckey2, Sven Koenig1, and T. K. Satish Kumar1
1 University of Southern California, Los Angeles, CA 90007, USA
{ali355,skoenig}@usc.edu, tkskwork@gmail.com
2 Monash University, Wellington Road, Clayton, VIC 3800, Australia
peter.stuckey@monash.edu
Abstract. Block modeling algorithms are used to discover important
latent structures in graphs. They are the graph equivalent of clustering
algorithms. However, existing block modeling algorithms work directly
on the given graphs, making them computationally expensive and less
eﬀective on large complex graphs. In this paper, we propose a FastMap-
based algorithm for block modeling on single-view undirected graphs.
FastMap embeds a given undirected graph into a Euclidean space in near-
linear time such that the pairwise Euclidean distances between vertices
approximate a desired graph-based distance function between them. In
the ﬁrst phase, our FastMap-based block modeling (FMBM) algorithm
uses FastMap with a probabilistically-ampliﬁed shortest-path distance
function between vertices. In the second phase, it uses Gaussian Mix-
ture Models (GMMs) for identifying clusters (blocks) in the resulting
Euclidean space. FMBM outperforms other state-of-the-art methods on
many benchmark and synthetic instances, both in eﬃciency and solution
quality. It also enables a perspicuous visualization of clusters (blocks) in
the graphs, not provided by other methods.
Keywords: Community Detection and Block Modeling · Graph
Embeddings · FastMap
1
Introduction
Finding inherent groups in graphs, i.e., the “graph” clustering problem, has
important applications in many real-world domains, such as identifying com-
munities in social networks [8], analyzing the diﬀusion of ideas in them [13],
identifying functional modules in protein-protein interactions [11], and under-
standing the modular design of brain networks [2]. In general, identifying the
This work at the University of Southern California is supported by DARPA under grant
number HR001120C0157 and by NSF under grant numbers 1409987, 1724392, 1817189,
1837779, 1935712, and 2112533. The views, opinions, and/or ﬁndings expressed are
those of the author(s) and should not be interpreted as representing the oﬃcial views
or policies of the sponsoring organizations, agencies, or the U.S. Government. This
research was partially supported by the OPTIMA ARC training centre IC200100009.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 232–248, 2022.
https://doi.org/10.1007/978-3-031-08011-1_16

A FastMap-Based Algorithm for Block Modeling
233
(a) a core-periphery graph in the air-
port domain
(b) a FastMap embedding of the
graph on the left
Fig. 1. The left side shows a core-periphery graph in the airport domain with edges
representing ﬂight connections, red vertices representing “hub” airports at the core,
and blue vertices representing “local” airports at the periphery. The right side shows a
FastMap embedding of the graph in Euclidean space, in which the red and blue vertices
correctly appear in the core and periphery, respectively. (Color ﬁgure online)
groups involves mapping each vertex in the graph to a group (cluster), where
vertices in the same group share important properties in the underlying graph.
The conditions under which two vertices are deemed to be similar and there-
fore belonging to the same group are popularly studied in community detection
and block modeling [1]. In community detection, a group (community) implicitly
requires its vertices to be more connected to each other than to vertices of other
groups. Although this is justiﬁed in many real-world domains, such as social
networks, it is not always justiﬁed in general.
Block modeling uses more general criteria for identifying groups (blocks)
where community detection fails. For example, block modeling can be used to
correctly identify groups in core-periphery graphs characterized by a core of ver-
tices tightly connected to each other and a peripheral set of vertices loosely con-
nected to each other but well connected to the core.1 Core-periphery graphs are
common in many real-world domains, such as ﬁnancial networks and ﬂight net-
works [1,19]. Figure 1a shows a core-periphery graph in an air ﬂight domain [5].
Existing block modeling algorithms work directly on the given graphs and are
ineﬃcient. They typically use matrix operations that incur cubic time complex-
ities even within their inner loops. For example, FactorBlock [3], a state-of-the-
art block modeling algorithm, uses matrix multiplications in its inner loop and
an expectation-maximization-style outer loop. Due to their ineﬃciency, existing
block modeling algorithms are not scalable and result in poor solution qualities
on large complex graphs.
In this paper, we propose a FastMap-based algorithm for block modeling on
single-view2 undirected graphs. FastMap embeds a given undirected graph into
a Euclidean space in near-linear time such that the pairwise Euclidean distances
1 The conditions used in community detection prevent the proper identiﬁcation of
peripheral groups.
2 In a single-view graph, there is at most one edge between any two vertices.

234
A. Li et al.
between vertices approximate a desired graph-based distance function between
them. In general, graph embeddings have been used in many diﬀerent contexts,
such as for shortest-path computations [4], multi-agent meeting problems [12],
and social network analysis [18]. They are useful because they facilitate geometric
interpretations and algebraic manipulations in vector spaces.
FastMap [4,12] is a recently developed graph embedding algorithm that runs
in near-linear time3. While it has thus far been used to create Euclidean embed-
dings that approximate pairwise shortest-path distances between vertices, it can
also be extended to creating Euclidean embeddings that approximate more gen-
eral pairwise graph-based distances between vertices. In particular, for the pur-
pose of block modeling in this paper, we propose a novel distance function that
probabilistically ampliﬁes the shortest-path distances between vertices.
Our FastMap-based block modeling algorithm (FMBM) works in two phases.
In the ﬁrst phase, FMBM uses FastMap to eﬃciently embed the vertices of
a given graph in a Euclidean space, preserving the probabilistically-ampliﬁed
shortest-path distances between them. In the second phase, FMBM identiﬁes
clusters (blocks) in the resulting Euclidean space using standard methods from
unsupervised learning. Therefore, the ﬁrst phase of FMBM eﬃciently reformu-
lates the block modeling problem from a graphical space to a Euclidean space,
as illustrated in Fig. 1b; and the second phase of FMBM leverages any tech-
nique that is already known or can be developed for clustering in Euclidean
space. In our current implementation of FMBM, we use Gaussian Mixture Mod-
els (GMMs) for identifying clusters in the Euclidean space.
We empirically show that, in addition to the theoretical advantages of
FMBM, it outperforms other state-of-the-art methods on many benchmark and
synthetic test cases. We report on the superior performance of FMBM both in
terms of eﬃciency and solution quality. We also show that it enables a per-
spicuous visualization of clusters in the graphs, beyond the capabilities of other
methods.
2
Preliminaries and Background
In this section, we review some preliminaries of block modeling and provide a
background description of FastMap.
2.1
Block Modeling
Let G = (V, E) be an undirected graph with vertices V = {v1, v2 . . . vn} and
edges E = {e1, e2 . . . em} ⊆V × V . Let A ∈{0, 1}n×n be the adjacency matrix
representation of G, where Aij = 1 iﬀ(vi, vj) ∈E.
A block model decomposes G into a set of k vertex partitions representing
the blocks (groups), for a given value of k. The partitions are represented by
the membership matrix C ∈{0, 1}n×k, where Cij = 0 and Cij = 1 represent ver-
tex vi being absent from and being present in partition j, respectively. Therefore,
3 i.e., linear time after ignoring logarithmic factors

A FastMap-Based Algorithm for Block Modeling
235
Fig. 2. The ﬁgure, borrowed from [4], illustrates how coordinates are computed and
recursion is carried out in FastMap. (Color ﬁgure online)
k
j=1 Cij = 1 for all 1 ≤i ≤n. An image matrix is a matrix M ∈[0, 1]k×k,
where Mij represents the likelihood of an edge between a vertex in partition i
and a vertex in partition j. The block model decomposition of G, as discussed
in [3], tries to approximate A by CMC⊤with the best choice for C and M. In
other words, the objective is
min
C,M ∥A −CMC⊤∥2
F ,
(1)
where ∥· ∥F is the Frobenius norm. An improved objective function is also
considered in [3] to account for the imbalance of edges to non-edges4 in A, since
real-world graphs are typically sparse with signiﬁcantly more non-edges than
edges. The revised objective is
min
C,M ∥(A −CMC⊤) ◦(A −R)∥2
F ,
(2)
where R ∈[0, 1]n×n, Rij = m
n2 , and ◦represents element-wise multiplication.
The above formalization can be generalized to directed graphs and multi-
view graphs [19]. It can also be generalized to soft partitioning, where each
vertex partially belongs to each partition, i.e., C ∈[0, 1]n×k with k
j=1 Cij = 1
for all 1 ≤i ≤n.
2.2
FastMap
FastMap [6] was introduced in the Data Mining community for automatically
generating Euclidean embeddings of abstract objects. For many complex objects
(such as long DNA strings), multi-media datasets (like voice excerpts or images),
or medical datasets (like ECGs or MRIs), there is no geometric space in which
4 i.e., a pair of vertices not connected by an edge

236
A. Li et al.
they can be naturally visualized. However, there is often a well-deﬁned distance
function between every pair of objects in the problem domain. For example,
the edit distance between two DNA strings is well-deﬁned although an individual
DNA string cannot be conceptualized in geometric space.
FastMap embeds a collection of abstract objects in an artiﬁcially cre-
ated Euclidean space to enable geometric interpretations, algebraic manipu-
lations, and downstream machine learning algorithms. It gets as input a col-
lection of abstract objects O, where D(Oi, Oj) represents the domain-speciﬁc
distance between objects Oi, Oj ∈O. A Euclidean embedding assigns a K-
dimensional point ⃗pi ∈RK to each object Oi. For ⃗pi = ([⃗pi]1, [⃗pi]2 . . . [⃗pi]K)
and ⃗pj
=
([⃗pj]1, [⃗pj]2 . . . [⃗pj]K), we deﬁne the Euclidean distance χij
=
K
r=1([⃗pj]r −[⃗pi]r)2. A good Euclidean embedding is one in which χij between
any two points ⃗pi and ⃗pj closely approximates D(Oi, Oj).
FastMap creates a K-dimensional Euclidean embedding of the abstract
objects in O for a user-speciﬁed value of K. In the very ﬁrst iteration, FastMap
heuristically identiﬁes the farthest pair of objects Oa and Ob in linear time. Once
Oa and Ob are determined, every other object Oi deﬁnes a triangle with sides
of lengths dai = D(Oa, Oi), dab = D(Oa, Ob), and dib = D(Oi, Ob), as shown in
Fig. 2a. The sides of the triangle deﬁne its entire geometry, and the projection
of Oi onto the line OaOb is given by
xi = (d2
ai + d2
ab −d2
ib)/(2dab).
(3)
FastMap sets the ﬁrst coordinate of ⃗pi, the embedding of Oi, to xi. In the
subsequent K −1 iterations, the same procedure is followed for computing the
remaining K −1 coordinates of each object. However, the distance function is
adapted for diﬀerent iterations. For example, for the ﬁrst iteration, the coordi-
nates of Oa and Ob are 0 and dab, respectively. Because these coordinates fully
explain the true distance between these two objects, from the second iteration
onward, the rest of ⃗pa and ⃗pb’s coordinates should be identical. Intuitively, this
means that the second iteration should mimic the ﬁrst one on a hyperplane that
is perpendicular to the line OaOb, as shown in Fig. 2b. Although the hyperplane
is never constructed explicitly, its conceptualization implies that the distances
for the second iteration should be changed for all i and j so that:
Dnew(O′
i, O′
j)2 = D(Oi, Oj)2 −(xi −xj)2.
(4)
Here, O′
i and O′
j are the projections of Oi and Oj, respectively, onto this hyper-
plane, and Dnew(·, ·) is the new distance function.
FastMap can also be used to embed the vertices of a graph in a Euclidean
space to preserve the pairwise shortest-path distances between them. The idea is
to view the vertices of a given graph G = (V, E) as the objects to be embedded.
As such, the Data Mining FastMap algorithm cannot be directly used for gener-
ating an embedding in near-linear time. This is so because it assumes that the
distance dij between any two objects Oi and Oj can be computed in constant

A FastMap-Based Algorithm for Block Modeling
237
time, independent of the number of objects in the problem domain. However,
computing the shortest-path distance between two vertices depends on the size
of the graph.
The near-linear time complexity of FastMap can be retained as follows: In
each iteration, after we heuristically identify the farthest pair of vertices Oa
and Ob, the distances dai and dib need to be computed for all other vertices Oi.
Computing dai and dib for any single vertex Oi can no longer be done in constant
time but requires O(|E| + |V | log |V |) time instead [7]. However, since we need
to compute these distances for all vertices, computing two shortest-path trees
rooted at each of the vertices Oa and Ob yields all necessary distances in one
shot. The complexity of doing so is also O(|E|+|V | log |V |), which is only linear
in the size of the graph5. The amortized complexity for computing dai and dib
for vertex Oi is therefore near-constant time.
The foregoing observations are used in [12] to build a graph-based version of
FastMap that embeds the vertices of a given undirected graph in a Euclidean
space in near-linear time. The Euclidean distances approximate the pairwise
shortest-path distances between vertices. A slight modiﬁcation of this FastMap
algorithm, presented in [4], can also be used to preserve consistency and admis-
sibility of the Euclidean distance approximation, which is important when using
it as a heuristic in A* search for shortest-path computations. In both [4] and [12],
K is user-speciﬁed, but a threshold parameter ϵ is introduced to terminate with
a smaller value of K once diminishing returns on the accuracy of approximating
pairwise shortest-path distances are detected.
3
FastMap-Based Block Modeling Algorithm (FMBM)
In this section, we describe FMBM, our novel algorithm for block modeling
based on FastMap [12]. As mentioned before, FMBM works in two phases.
In the ﬁrst phase, FMBM uses FastMap to eﬃciently embed vertices in a K-
dimensional Euclidean space, preserving the probabilistically-ampliﬁed shortest-
path distances between them. In the second phase, FMBM identiﬁes the required
blocks in the resulting Euclidean space using GMM clustering.
To facilitate the description of FMBM, we ﬁrst examine what happens when
FastMap is used naively in the ﬁrst phase, i.e., when it is used to embed the
vertices of a given undirected graph in a K-dimensional Euclidean space for
preserving the pairwise shortest-path distances. This naive attempt fails even in
relatively simple cases. For example, Figs. 3a–3d show that it fails on a bipartite
graph and a core-periphery graph. This is so because preserving the pairwise
shortest-path distances in Euclidean space does not necessarily help GMM clus-
tering to identify the two blocks (partitions). In fact, in a bipartite graph, the
closest neighbors of a vertex are in the other partition.
5 unless |E| = O(|V |), in which case the complexity is near-linear in the size of the
input because of the log |V | factor

238
A. Li et al.
Fig. 3. The ﬁgure shows two simple graphs that guide the design of a proper FastMap
distance function for block modeling. (a) shows a fully-connected bipartite graph with
the red and blue vertices indicating the two partitions. (b) shows a core-periphery graph
with the red vertices indicating the core and the blue vertices indicating the periphery.
All pairs of red vertices are connected by edges (not all shown to avoid clutter). (c) and
(d) show the FastMap Euclidean embeddings of the graphs in (a) and (b), respectively,
using the shortest-path distance function. This naive FastMap distance function fails
for block modeling. Red and blue points correspond to red and blue vertices of the
graphs, respectively. Many vertices are mapped to the same point. (e) and (f) show the
FastMap Euclidean embeddings of the graphs in (a) and (b), respectively, when using
the probabilistically-ampliﬁed shortest-path distance function. This FastMap distance
function is appropriate for block modeling. (Color ﬁgure online)
3.1
Probabilistically-Ampliﬁed Shortest-Path Distances
From the foregoing discussion, it is clear that the shortest-path distance between
two vertices vi and vj is not a viable distance function for block modeling.
Therefore, in this subsection, we create a new distance function D(vi, vj) for pairs
of vertices based on the following intuitive guidelines: (a) the smaller the shortest-
path distance between vi and vj, the smaller the distance D(vi, vj) should be;
(b) the more paths exist between vi and vj, the smaller the distance D(vi, vj)
should be; and (c) the complement graph6 ¯G of the given graph G should yield the
same distance function as G: The distance function should be independent of the
arbitrary choice of representing a relationship between two vertices as either an
edge or a non-edge. Intuitively, these guidelines capture an eﬀective “resistance”
6 The complement graph ¯G has the same vertices as the original graph G but represents
every edge in G as a non-edge and every non-edge in G as an edge.

A FastMap-Based Algorithm for Block Modeling
239
between vertices and facilitate the subsequent embedding to represent relative
“potentials” of vertices in Euclidean space. The eﬀectiveness of these guidelines
is validated through test cases in this section and comprehensive experiments in
the next section.
We
deﬁne
a
new
distance
function
DP (vi, vj),
referred
to
as
the probabilistically-ampliﬁed shortest-path distance (PASPD) between vi and
vj, as:

G∈Gset
dG(vi, vj).
(5)
Here, dG(vi, vj) represents the shortest-path distance between vi and vj in an
undirected graph G. Gset represents a collection of undirected graphs derived
from the given graph G or its complement ¯G. In particular, each graph in Gset
is an edge-induced subgraph of either G or ¯G.7 The edge-induced subgraphs are
created by probabilistically dropping edges from G or ¯G.
Intuitively, the use of shortest-path distances on multiple graphs that are
probabilistically derived from the same input graph G accounts for DP (·, ·).
Indeed, the smaller dG(vi, vj), the smaller DP (vi, vj) also is. Similarly, the more
paths between vi and vj in G, the more likely it is for such paths to survive in its
edge-induced subgraphs, and the smaller DP (vi, vj) consequently is. Moreover,
since the subgraphs in Gset are derived from both G and ¯G, DP (·, ·) satisﬁes all
these intuitive guidelines mentioned above. From an eﬃciency perspective, the
use of multiple graphs does not create much overhead if the number of graphs
does not depend on the size of G. However, ¯G can have signiﬁcantly more edges
than G if G is sparse. In such cases, if G has n vertices and m <
n
2

/2 edges,
¯G itself is probabilistically derived from G by randomly retaining only m out
of the
n
2

−m edges that it would otherwise have. This keeps the size of ¯G
upper-bounded by the size of the input.
Although more details on FMBM are presented in the next subsection,
the beneﬁts of using a probabilistically-ampliﬁed distance function are visually
apparent in Figs. 3e and 3f. In both cases, the red and blue vertices are mapped
to linearly-separable red and blue points, respectively, in Euclidean space. Its
beneﬁts can also be seen in Fig. 1b, where the core red vertices are mapped to a
core set of red points and the peripheral blue vertices are mapped to a periph-
eral set of blue points, respectively, in Euclidean space. In this case, although
the red and blue points are not linearly separable, GMM clustering [15] in the
second phase of FMBM is capable of separating them using two overlapping but
diﬀerent Gaussian distributions.
3.2
Main Algorithm
Algorithm 1 shows the pseudocode for computing the PASPD function DP (·, ·)
parameterized by L and F. Like the shortest-path distance function, it, too, can
be computed eﬃciently (in one shot) for all pairs (vs, vi), for a speciﬁed source
vs and all vi ∈V . On Lines 3–15, the algorithm populates Gset with L lineages
7 An edge-induced subgraph of G has the same vertices as G but a subset of its edges.

240
A. Li et al.
Algorithm 1. SS-PASPD: Single-Source Probabilistically-Ampliﬁed Shortest-Path
Distance Function
Input: G = (V, E) and vs ∈V
Parameters: L and F
Output: dsi for each vi ∈V
1: Let ¯G = (V, ¯E) be the complement graph of G.
2: Gset ←{} and Tset ←{}.
3: for l = 1, 2 . . . L do
4:
G ←G and ¯G ←¯G.
5:
if | ¯E| > |E| then
6:
Drop | ¯E| −|E| randomly chosen edges from ¯G.
7:
end if
8:
Gset ←Gset ∪{G} and f ←|E|/F.
9:
while G has edges do
10:
Drop f randomly chosen edges from G to obtain ˆG.
11:
Gset ←Gset ∪{ ˆG}.
12:
G ←ˆG.
13:
end while
14:
Repeat lines 8-13 for ¯G.
15: end for
16: for Gi ∈Gset do
17:
Ti ←SS-ShortestPathDistance(Gi, vs).
18:
Tset ←Tset ∪{Ti}.
19: end for
20: for each vj ∈V do
21:
dsj ←
Ti∈Tset Ti(vj).
22: end for
23: return dsi for each vi ∈V .
of F nested edge-induced subgraphs of G and ¯G. On Lines 5–7, the algorithm
constructs the complement graph ¯G but probabilistically retains at most |E|
of its edges. On Lines 16–23, it uses the single-source shortest-path distance
function to compute and return the sum of the shortest-path distances from vs
to vi in all G ∈Gset, for all vi ∈V . If vs and vi are disconnected in any graph
G ∈Gset, dG(vs, vi) is technically equal to +∞. However, for practical reasons
in such cases, dG(vs, vi) is set to twice the maximum shortest-path distance from
vs to any other vertex connected to it in G. Ti on Line 17 refers to the array
of shortest-path distances from vs in Gi. Ti(vj) on Line 21 is the array element
that corresponds to vertex vj.
Algorithm 2 shows the pseudocode for FMBM. On Lines 3–25, it essentially
implements FastMap as described in [12] but calls the SS-PASPD distance func-
tion in Algorithm 1 instead of the regular single-source shortest-path distance
function. As in FastMap [12], K represents the user-speciﬁed upper bound on
the dimensionality of the Euclidean embedding, ϵ represents the user-speciﬁed
threshold to recognize an accurate embedding, and Q represents a small constant
number of pivot changes used to heuristically identify the farthest pair of ver-

A FastMap-Based Algorithm for Block Modeling
241
Algorithm 2. FMBM: FastMap-Based Block Modeling
Input: G = (V, E) and k
Parameters: L, F, T, K, Q, and ϵ
Output: ci for each vi ∈V
1: MinObj ←+∞and BestC ←∅.
2: for t = 1, 2 . . . T do
3:
for r = 1, 2 . . . K do
4:
Choose va ∈V randomly and let vb ←va.
5:
for q = 1, 2 . . . Q do
6:
{dai : vi ∈V } ←SS-PASPD(G, va).
7:
vc ←argmaxvi{d2
ai −r−1
j=1([⃗pa]j −[⃗pi]j)2}.
8:
if vc == vb then
9:
Break.
10:
else
11:
vb ←va and va ←vc.
12:
end if
13:
end for
14:
{dai : vi ∈V } ←SS-PASPD(G, va).
15:
{dib : vi ∈V } ←SS-PASPD(G, vb).
16:
d′
ab ←d2
ab −r−1
j=1([⃗pa]j −[⃗pb]j)2.
17:
if d′
ab < ϵ then
18:
Break.
19:
end if
20:
for each vi ∈V do
21:
d′
ai ←d2
ai −r−1
j=1([⃗pa]j −[⃗pi]j)2.
22:
d′
ib ←d2
ib −r−1
j=1([⃗pi]j −[⃗pb]j)2.
23:
[⃗pi]r ←(d′
ai + d′
ab −d′
ib)/(2

d′
ab).
24:
end for
25:
end for
26:
P ←[⃗p1, ⃗p2 . . . ⃗p|V |].
27:
C ←GMM(P, k).
28:
Obj ←GetObjectiveValue(G, C).
29:
if Obj ≤MinObj then
30:
MinObj ←Obj.
31:
BestC ←C.
32:
end if
33: end for
34: return ci for each vi ∈V according to BestC.
tices. L and F are simply passed to Algorithm 1 in the function call SS-PASPD.
Because Algorithm 2 employs randomization, it qualiﬁes as a Monte-Carlo algo-
rithm. It implements an outer loop to boost the performance of FMBM using
T independent trials. On Lines 26–32, each trial invokes the GMM clustering
algorithm and evaluates the results on the objective function in Eq. 2,8 keeping
8 M can be computed from A and C in O(|E|+k2) time while evaluating the objective
function in Eq. 2.

242
A. Li et al.
record of the best value. The results of the best trial, i.e., the block assignment
ci for each vi ∈V , are returned on Line 34.9
A formal time complexity analysis of FMBM is evasive since Line 27 of Algo-
rithm 2 calls the GMM clustering procedure, which has no deﬁned time com-
plexity. Therefore, we only claim to be able to reformulate the block modeling
problem on graphs to its Euclidean version in O(LFK(|E| + |V | log |V |)) time
in each of the T iterations. Here, the factor LF comes from the cardinality of
Gset in Algorithm 1, and the factor K(|E|+|V | log |V |) comes from the complex-
ity of FastMap, that uses SS-PASPD on Lines 3–25 of Algorithm 2. The time
complexity of GetObjectiveValue on Line 28 is technically O(|V |2k+|V |k2),
where k is the user-speciﬁed number of blocks, also passed to the GMM clustering
algorithm. This time complexity comes from the matrix multiplication CMC⊤
in Eq. 2. The factor |V |2 in this matrix multiplication, and more generally in
Eq. 2, can be reduced to O(|E|) by evaluating |E| entries corresponding to edges
and min(|E|,
|V |
2

−|E|) randomly chosen entries corresponding to non-edges in
the matrix expression (A −CMC⊤) ◦(A −R). The matrix multiplication CM
takes O(|V |k2) time and results in a |V | × k matrix. |E| + min(|E|,
|V |
2

−|E|)
entries in the multiplication of this matrix with C⊤can be computed in O(|E|k)
time. Overall, therefore, the reformulation to Euclidean space can be done in
near-linear time, i.e., linear in |V | and |E|, after ignoring logarithmic factors.
4
Experiments
In this section, we present empirical results on the comparative performances of
FMBM and three other state-of-the-art solvers for block modeling: Graph-Tool,
DANMF, and CPLNS. We also compared against two other solvers for block
modeling: FactorBlock [3] and ASBlock [19]. However, they are not competitive
with the other solvers; and we exclude them from Tables 1, 2, 3, 4, and 5 to
save column space. Graph-Tool [17] uses an agglomerative multi-level Markov
Chain Monte Carlo algorithm and has been largely ignored in the computer
science literature on block modeling; DANMF [20] uses deep autoencoders; and
CPLNS [14] uses constraint programming with large neighborhood search.
We used the following hyperparameter values for FMBM:10 L = 4, F = 10,
T = 10, K = 4, Q = 10, and ϵ = 10−4. The value of k, i.e., the number of
blocks, was given as input for all the solvers in the experiments.11 We used three
metrics for comparison: the value of the objective function stated in Eq. 2, the
9 The domain of each ci is {1, 2 . . . k}. Block Bh refers to the collection of all vertices
vi ∈V such that ci = h.
10 These values are only important as ballpark estimates. We observed that the perfor-
mance of FMBM often stays stable within broad ranges of hyperparameter values,
imparting robustness to FMBM. Moreover, only a few diﬀerent hyperparameter set-
tings had to be examined to determine the best one.
11 Although Graph-Tool does not require a user-speciﬁed value of k, it has a tendency
to produce trivial solutions with k = 1, resulting in 0 NMI values when the value of
k is not explicitly speciﬁed.

A FastMap-Based Algorithm for Block Modeling
243
Table 1. Real-World Single-View Undirected Graphs.
Test Case Size (|V |, |E|)
FMBM
Graph-Tool
DANMF
CPLNS
Objective
NMI
Time Objective
NMI Time Objective
NMI
Time Objective
NMI
Time
adjnoun
(112, 425)
616.86 0.0025
6.11
612.98 0.2978 0.04
636.75 0.0083
1.62
591.76 0.0154
1.51
baboons
(14, 23)
11.97 0.0158
0.54
11.49 0.2244 0.00
15.49 0.1341
0.97
12.81 0.0172
0.87
football
(115, 613)
665.97 0.5608
9.22
343.32 0.9150 0.03
863.91 0.2574
1.55
558.94 0.6991
83.33
karate
(34, 78)
74.66 0.6127
1.47
64.67 0.2512 0.00
81.94 0.1672
0.77
75.43 0.2228
1.06
polblogs
(1,490, 16,715) 98,788.53 0.0098 239.33 99,014.21 0.4668 2.14 101,195.89 0.0465 404.02 95,859.73 0.0543 506.29
polbooks
(105, 441)
522.33 0.5329
6.20
496.02 0.5462 0.02
590.20 0.3177
1.98
531.48 0.2073
2.09
Table 2. Complement Graphs of the Graphs in Table 1.
Test Case
Size (|V |, |E|)
FMBM
Graph-Tool
DANMF
CPLNS
Objective
NMI
Time Objective
NMI Time Objective
NMI
Time Objective
NMI
Time
adjnoun
(112, 5,791)
611.04 0.0048
25.34
636.34 0.0168
0.41
641.40 0.0000
8.34
591.54 0.0169
1.85
baboons
(14, 68)
12.64 0.0547
0.62
12.86 0.0416
0.01
15.46 0.0500
1.23
13.35 0.0316
0.86
football
(115, 5,944)
595.52 0.5899
27.53
344.38 0.9111
0.17
815.71 0.2229
9.56
525.54 0.7040
82.11
karate
(34, 483)
72.73 0.7625
2.46
77.31 0.2065
0.02
84.23 0.0914
1.78
75.00 0.2439
1.04
polblogs
(1,490, 1,094,951) 26,896.52 0.0153 3155.33 26,048.04 0.0454 49.90
-
- > 1 hour 25,871.42 0.0541 470.48
polbooks
(105, 5,019)
509.88 0.5409
21.55
606.96 0.0867
0.13
631.77 0.0141
8.09
531.65 0.2056
2.15
Table 3. Sparse Single-View Undirected Graphs Using Generative Model 1.
Test Case Size (|E|)
FMBM
Graph-Tool
DANMF
CPLNS
Objective
NMI
Time
Objective
NMI
Time Objective
NMI
Time Objective
NMI
Time
V0400b04
6,722
9,355.91 0.1622
83.22
8,385.61 0.6565
1.49
9,465.48 0.0111
10.88
9,400.46 0.0534
39.74
V0800b04
14,723
24,201.35 0.1775
199.14
22,848.79 0.6599
3.99 24,387.24 0.0019
62.50 24,303.43 0.0394
195.08
V1600b04
25,103
45,849.52 0.2357
391.92
44,598.02 0.9667
7.04 46,379.74 0.0043
753.62 46,292.59 0.0206
1018.54
V3200b04
70,973 134,217.82 0.0348 1,376.41 131,751.34 0.6654 108.08
-
- > 1 hour
-
- > 1 hour
V0400b10
3,246
5,461.99 0.1217
40.9
4,728.69 0.8542
0.63
5,489.8 0.0509
7.25
5,364.07 0.1289
101.01
V0800b10
7,499
13,623.69 0.0425
108.69
12,612.44 0.9596
2.01 13,636.29 0.0156
47.49 13,485.93 0.0734
423.03
V1600b10
15,118
28,782.35 0.0691
272.65
27,828.70 0.8556
4.82 28,829.58 0.0117
537.27 28,682.31 0.0384
2019.76
V3200b10
36,170
70,292.36 0.0369
782.44
68,653.51 0.9173
17.62 70,315.35 0.0074 3,272.65
-
- > 1 hour
V0400b20
2,297
4,048.03 0.1639
29.66
3,632.92 0.6256
0.54
4,064.77 0.1859
8.03
-
- > 1 hour
V0800b20
5,049
9,451.30 0.0848
72.92
8,960.16 0.5857
1.90
9,460.80 0.0828
62.32
-
- > 1 hour
V1600b20
11,575
22,305.01 0.0457
251.06
21,591.83 0.6718
3.91 22,315.63 0.0445
444.49
-
- > 1 hour
V3200b20
24,639
48,321.14 0.0212
579.90
47,650.73 0.6067
12.89
-
- > 1 hour
-
- > 1 hour
Table 4. Dense Single-View Undirected Graphs Using Generative Model 1.
Test Case Size (|E|)
FMBM
Graph-Tool
DANMF
CPLNS
Objective
NMI
Time Objective
NMI Time Objective
NMI
Time Objective
NMI Time
V0100b06
4,125
815.58 0.1308
20.06
818.83 0.1291 0.46
829.20 0.0829
5.85
750.28 0.2727
3.50
V0300b06
41,771
4,702.6 0.2061 176.65
4,819.43 0.0311 1.93
4,828.49 0.0149 143.10
4,746.32 0.0629 18.14
V0500b06
118,536
10,473.0 0.0537 513.31 10,489.79 0.0193 4.86 10,497.63 0.0053 658.45 10,419.98 0.0411 41.13
V0100b08
4,212
782.91 0.2182
19.23
761.68 0.3024 0.33
807.05 0.1532
6.02
712.92 0.3331
4.59
V0300b08
42,078
4,468.67 0.0944 175.55
4,487.12 0.0443 1.48
4,498.23 0.0151 144.96
4,397.28 0.0895 19.95
V0500b08
120,166
8,188.55 0.1503 505.41
8,278.07 0.0267 4.94
8,290.82 0.0056 680.16
8,175.52 0.0582 59.04
V0100b10
4,268
731.61 0.3446
19.22
720.38 0.3290 0.32
779.34 0.1570
6.41
662.42 0.4100
6.93
V0300b10
42,385
4,069.42 0.1652 171.93
4,126.01 0.0569 1.47
4,141.94 0.0292 146.23
4,009.88 0.1160 29.28
V0500b10
120,366
7,931.97 0.1174 516.16
7,985.47 0.0347 4.03
8,000.60 0.0000 616.74
7,872.77 0.0761 60.22
Normalized Mutual Information (NMI) value with respect to the ground truth,
and the running time in seconds. Unlike other methods, FMBM is an anytime
algorithm since it uses multiple trials. Each trial takes roughly (1/T)’th, i.e.,
one-tenth, of the time reported for FMBM in the experimental results. For each
method and test case, we averaged the results over 10 runs. All experiments were
conducted on a laptop with a 3.1GHz Quad-Core Intel Core i7 processor and
16GB LPDDR3 memory. Our implementation of FMBM was done in Python3
with NetworkX [10].

244
A. Li et al.
Table 5. Single-View Undirected Graphs Using Generative Model 2.
Test Case Size (|E|)
FMBM
Graph-Tool
DANMF
CPLNS
Objective
NMI
Time
Objective
NMI Time Objective
NMI
Time Objective
NMI
Time
V0400b04
7,176
9,843.84 0.0327
75.09
9,444.48 0.8214
1.77
9,855.97 0.0116
12.23
9,786.67 0.0246
34.55
V0800b04
16,780
27,040.21 0.0087
192.97
26,982.65 0.0698
5.67 27,053.24 0.0008
69.68 26,945.04 0.0087
243.28
V1600b04
28,183
51,531.41 0.0146
386.32
51,556.38 0.0043
8.04 51,559.96 0.0025
684.58 51,467.00 0.0073 1,098.12
V3200b04
72,182
136,376.53 0.0087 1,196.30 135,967.24 0.5287 32.92
-
- > 1 hour
-
- > 1 hour
V0400b10
7,069
9,729.49 0.0639
73.76
9,349.76 0.4827
1.52
9,753.04 0.0625
10.69
9,585.60 0.0837
127.68
V0800b10
15,613
25,528.33 0.0385
181.56
25,022.25 0.4893
4.05 25,553.52 0.0274
86.58
25,353.08 0.0418
494.10
V1600b10
32,294
58,279.85 0.0195
428.40
58,244.14 0.0305 13.92 58,305.57 0.0157
687.84 58,103.92 0.0224
2459.38
V3200b10
79,173 148,741.84 0.0082 1,307.21
148,745.65 0.0065 32.88
-
- > 1 hour
-
- > 1 hour
V0400b20
6,829
9,453.81 0.1425
72.78
9,139.14 0.2039
1.38
9,506.35 0.1790
9.98
-
- > 1 hour
V0800b20
15,106
24,810.19 0.0784
176.60
24,521.35 0.1251
3.49 24,866.54 0.0918
62.93
-
- > 1 hour
V1600b20
30,462
55,265.42 0.0436
420.49
55,207.39 0.0366
9.38
55,310.7 0.0440
606.39
-
- > 1 hour
V3200b20
67,675
128,267.45 0.0232 1,199.32 128,234.10 0.0168 40.91
-
- > 1 hour
-
- > 1 hour
Although the underlying theory of FMBM can be generalized to directed
graphs with weighted edges [9] and to multi-view graphs, the current version of
FMBM is operational only on singe-view undirected graphs, suﬃcient to illus-
trate the power of FastMap embeddings. Therefore, only such test cases are
borrowed from other commonly used datasets [16,19]. However, we also created
new synthetic test cases to be able to do a more comprehensive analysis.12
The synthetic test cases were generated according to two similar stochastic
block models [1] as follows. In Generative Model 1, given a user-speciﬁed number
of vertices |V | and a user-speciﬁed number of blocks k, we ﬁrst assign each vertex
to a block chosen uniformly at random to obtain the membership matrix C,
representing the ground truth. The image matrix M is drafted using certain
“block structural characteristics” designed for that instance with a parameter p.
Each entry Mij is set to either p or 10p according to a rule explained below. If
Mij is set to p (10p), the two blocks Bi and Bj are weakly (strongly) connected
to each other with respect to p. The adjacency matrix A, representing the entire
graph, is constructed from C and M by connecting any two vertices vs ∈Bi and
vt ∈Bj with probability Mij. In Generative Model 2, each entry Mij is set to
cp, where c is an integer chosen uniformly at random from the interval [1, 10].
Tables 1, 2, 3, 4, and 5 show the comparative performances of FMBM, Graph-
Tool, DANMF, and CPLNS.13 Table 1 contains commonly used real-world test
cases from [16] and [19]. Here, FMBM outperforms DANMF and CPLNS with
respect to the value of the objective function on 3 out of 6 instances, despite
the fact that it uses the expression in Eq. 2 only for evaluation on Line 28 of
Algorithm 2. Graph-Tool performs well on all the instances. Table 2 shows the
comparative performances on the complement graphs of the graphs in Table 1.
This is done to test the robustness of the solvers against encoding the same
relationships between vertices as either edges or non-edges. While the value of
the objective function and the running time are expected to change, the NMI
value is expected to be stable. We observe that FMBM and CPLNS are the only
solvers that convincingly pass this test. Moreover, FMBM outperforms the other
12 https://github.com/leon-angli/Synthetic-Block-Modeling-Dataset
13 DANMF did not assign any block membership to a few vertices in some synthetic
test cases. We assign Block B1 by default to such vertices.

A FastMap-Based Algorithm for Block Modeling
245
solvers on more instances than in Table 1. Tables 1 and 2 do not test scalability
since |V | is small in these test cases.
Table 3 contains synthetic sparse test cases from Generative Model 1, named
“Vnbk”, where n indicates the number of vertices and k indicates the number of
blocks. These test cases have the following block structural characteristics. Each
block is strongly connected to two other randomly chosen blocks and weakly
connected to the remaining ones (including itself). We set p = (ln |V |)/|V |,
making |E| = O(|V | log |V |) in expectation. After generating A, we also add some
noise to it by ﬂipping each of its entries independently with probability 0.05/|V |.
FMBM outperforms DANMF and CPLNS with respect to both the value of the
objective function and the NMI value on 8 out of 12 instances. We also begin
to see FMBM’s advantages in scalability. However, Graph-Tool outperforms all
other methods by a signiﬁcant margin on all the instances. Table 4 contains
synthetic dense test cases from Generative Model 1 constructed by setting p =
(ln |V |)/|V |, modifying each entry Mij to 1 −Mij, and adding noise, as before.
We observe that the performance of Graph-Tool is poor on such dense graphs.
FMBM outperforms DANMF and CPLNS with respect to the NMI value on 6
out of 9 instances. Although CPLNS produces marginally better values of the
objective function, its performance on large sparse graphs in Table 3 is bad.
Table 5 contains synthetic test cases from Generative Model 2 constructed
by setting p = (ln |V |)/|V |. FMBM outperforms DANMF and CPLNS with
respect to the value of the objective function on 6 out of 12 instances. It also
outperforms DANMF and CPLNS with respect to the NMI value on a diﬀerent
set of 6 instances. Graph-Tool performs comparatively well on all the instances
but occasionally produces low NMI values.
4.1
Visualization
In addition to identifying blocks, their visualization is important for uncovering
trends, patterns, and outliers in large graphs. A good visualization aids human
intuition for gauging the spread14 of blocks, both individually and relative to each
other. In market analysis, for example, a representative element can be chosen
from each block with proper visualization. Figure 4 shows that FMBM provides a
much more perspicuous visualization compared to a standard graph visualization
procedure in NetworkX15 used with Graph-Tool, even though Graph-Tool shows
good overall performance in Tables 1, 3, and 5. This is so because FMBM solves
the block modeling problem in Euclidean space, while other approaches use
abstract methods that are harder to visualize.
14 The spread here refers to how a block extends from its center to its periphery.
15 https://networkx.org/documentation/stable/reference/generated/networkx.
drawing.nx pylab.draw.html

246
A. Li et al.
(a) standard graph visualization
of blocks in an instance with
1, 600 vertices and 4, 353 edges
(b)
FMBM
visualization
of
blocks in Euclidean space for
the instance from 4a
(c) standard graph visualization
of blocks in an instance with
1, 600 vertices and 25, 103 edges
(d)
FMBM
visualization
of
blocks in Euclidean space for
the instance from 4c
Fig. 4. The left column shows a visualization of two diﬀerent instances with four blocks
obtained by a standard graph visualization procedure in NetworkX used with Graph-
Tool. The right column shows a visualization of the same two instances obtained in
the Euclidean embedding by FMBM. Four diﬀerent colors are used to indicate the four
diﬀerent blocks. The FMBM visualization is more helpful for gauging the spread of
blocks, both individually and relative to each other. (Color ﬁgure online)
5
Conclusions and Future Work
In this paper, we proposed FMBM, a FastMap-based algorithm for block mod-
eling. In the ﬁrst phase, FMBM adapts FastMap to embed a given undirected
graph into a Euclidean space in near-linear time such that the pairwise Euclidean
distances between vertices approximate a probabilistically-ampliﬁed graph-based
distance function between them. In doing so, it avoids having to directly work on
the given graphs and instead reformulates the graph block modeling problem to a
Euclidean version. In the second phase, FMBM uses GMM clustering for identi-
fying clusters (blocks) in the resulting Euclidean space. Empirically, FMBM out-
performs other state-of-the-art methods like FactorBlock, Graph-Tool, DANMF,
and CPLNS on many benchmark and synthetic test cases. FMBM also enables a
perspicuous visualization of blocks in the graphs, not provided by other methods.

A FastMap-Based Algorithm for Block Modeling
247
In future work, we will generalize FMBM to work on directed graphs and
multi-view graphs. We will also apply FMBM and its generalizations to real-
world graphs from various domains, including social and biological networks.
References
1. Abbe, E.: Community detection and stochastic block models: recent developments.
J. Mach. Learn. Res. 18, 6446–6531 (2017)
2. Antonopoulos, C.G.: Dynamic range in the C. elegans brain network. Chaos: Inter-
disc. J. Nonlinear Sci. 26(1), 013102 (2016)
3. Chan, J., Liu, W., Kan, A., Leckie, C., Bailey, J., Ramamohanarao, K.: Discovering
latent blockmodels in sparse and noisy graphs using non-negative matrix factori-
sation. In: Proceedings of the ACM International Conference on Information &
Knowledge Management (2013)
4. Cohen, L., Uras, T., Jahangiri, S., Arunasalam, A., Koenig, S., Kumar, T.K.S.:
The FastMap algorithm for shortest path computations. In: Proceedings of the
International Joint Conference on Artiﬁcial Intelligence (2018)
5. Davis, T.: USAir97 (2014). https://www.cise.uﬂ.edu/research/sparse/matrices/
Pajek/USAir97
6. Faloutsos, C., Lin, K.I.: FastMap: a fast algorithm for indexing, data-mining and
visualization of traditional and multimedia datasets. In: Proceedings of the ACM
SIGMOD International Conference on Management of Data (1995)
7. Fredman, M.L., Tarjan, R.E.: Fibonacci heaps and their uses in improved network
optimization algorithms. J. ACM (JACM) 34, 596–615 (1987)
8. Girvan, M., Newman, M.E.: Community structure in social and biological networks.
Natl. Acad. Sci. 99, 7821–7826 (2002)
9. Gopalakrishnan, S., Cohen, L., Koenig, S., Kumar, T.K.S.: Embedding directed
graphs in potential ﬁelds using FastMap-D. In: Proceedings of the International
Symposium on Combinatorial Search (2020)
10. Hagberg, A., Swart, P., Chult, D.S.: Exploring network structure, dynamics, and
function using NetworkX. Technical report, Los Alamos National Lab, Los Alamos,
NM (United States) (2008)
11. Lee, J., Gross, S.P., Lee, J.: Improved network community structure improves
function prediction. Sci. Rep. 3, 1–9 (2013)
12. Li, J., Felner, A., Koenig, S., Kumar, T.K.S.: Using FastMap to solve graph prob-
lems in a Euclidean space. In: Proceedings of the International Conference on
Automated Planning and Scheduling (2019)
13. Lin, S., Hu, Q., Wang, G., Yu, P.S.: Understanding community eﬀects on infor-
mation diﬀusion. In: Cao, T., Lim, E.-P., Zhou, Z.-H., Ho, T.-B., Cheung, D.,
Motoda, H. (eds.) PAKDD 2015. LNCS (LNAI), vol. 9077, pp. 82–95. Springer,
Cham (2015). https://doi.org/10.1007/978-3-319-18038-0 7
14. Mattenet, A., Davidson, I., Nijssen, S., Schaus, P.: Generic constraint-based block
modeling using constraint programming. J. Artif. Intell. Res. 70, 597–630 (2021)
15. Murphy, K.P.: Machine Learning: A probabilistic perspective. The MIT Press,
Cambridge (2012)
16. Newman, M.E.: Finding community structure in networks using the eigenvectors
of matrices. Phys. Rev. E 74(3), 036104 (2006)

248
A. Li et al.
17. Peixoto, T.P.: Eﬃcient Monte Carlo and greedy heuristic for the inference of
stochastic block models. Phys. Rev. E 89(1), 012804 (2014)
18. Perozzi, B., Al-Rfou, R., Skiena, S.: DeepWalk: online learning of social represen-
tations. In: Proceedings of the ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining (2014)
19. Ramteke, R., et al.: Improving single and multi-view blockmodelling by algebraic
simpliﬁcation. In: Proceedings of the International Joint Conference on Neural
Networks (IJCNN) (2020)
20. Ye, F., Chen, C., Zheng, Z.: Deep autoencoder-like nonnegative matrix factoriza-
tion for community detection. In: Proceedings of the ACM International Confer-
ence on Information and Knowledge Management (2018)

Packing by Scheduling: Using Constraint
Programming to Solve a Complex 2D
Cutting Stock Problem
Yiqing L. Luo and J. Christopher Beck(B)
Department of Mechanical and Industrial Engineering, University of Toronto,
Toronto, ON M5S 3G8, Canada
{louisluo,jcb}@mie.utoronto.ca
Abstract. We investigate the novel Two-stage Cutting Stock Problem
with Flexible Length and Flexible Demand (2SCSP-FF): orders for rect-
angular items must be cut from rectangular stocks using guillotine cuts
with the objective to minimize waste. Motivated by our industrial part-
ner and diﬀerent from problems in the literature, the 2SCSP-FF allows
both the length of individual items and the total area of orders to vary
within customer-speciﬁed intervals. We develop constraint programming
(CP) and mixed-integer programming models, with the most success-
ful coming from the adaptation of CP scheduling techniques. Numerical
results show that this CP model has orders of magnitude smaller mem-
ory requirements and is the only model-based approach investigated that
can solve industrial instances.
Keywords: Cutting Stock Problem · Guillotine Cuts · Constraint
Programming · Mixed-Integer Linear Programming · Optimization
1
Introduction
As scheduling is one of the most successful application areas of Constraint Pro-
gramming (CP) [17,19], we are interested in investigating whether CP scheduling
approaches can be adapted to other combinatorial problems that share similar
substructure. In this paper, we explore this idea for a complex, novel packing
problem from the rolled-metal industry: the Two-stage Cutting Stock Problem
with Flexible Length and Flexible Demand (2SCSP-FF), a generalization of
the classic Two-stage Two-Dimensional Cutting Stock Problem with Guillotine
Constraints (2SCSP). While the literature on 2SCSP is rich, our problem consid-
ers ﬂexibility in item dimensions and total fulﬁllment, two characteristics that
are commonplace in this industry [34], but have received limited attention in
the literature. We approach these complications from a scheduling perspective,
drawing inspiration from batch scheduling and the single resource transforma-
tion, a recently proposed CP modelling technique to handle the choice of alter-
native resources [3]. We conduct experiments over both generated and real-life
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 249–265, 2022.
https://doi.org/10.1007/978-3-031-08011-1_17

250
Y. L. Luo and J. C. Beck
Fig. 1. A visualization of 2SCSP-FF. Each order is represented by its total quantity
(left) and the partitions assigned to it (middle), as illustrated by the double-arrow.
Dashed lines and the dotted ﬁlls indicate ﬂexibility in the associated parameter. Orange
and blue lines represent the ﬁrst and second stage cuts, respectively. (Color ﬁgure
online)
instances and demonstrate our approach’s computational advantages over alter-
native modelling approaches in CP, mixed integer programming (MIP), and a
custom greedy heuristic.
Our contributions are as follows:
1. We introduce the novel 2SCSP-FF problem.
2. We adapt the single resource CP model to the 2SCSP-FF. This compact for-
mulation increases the size of the instances that can be solved within memory
and time limits by an order of magnitude.
3. We propose and experiment with alternative MIP and CP models and a two-
stage heuristic.
2
Problem Deﬁnition
The 2SCSP-FF (Fig. 1) is a novel generalization of the Two-stage Two-
Dimensional Cutting Stock Problem with Guillotine Constraints (2SCSP). Given
a set of orders for rectangular items and a set of larger stock rectangles, the clas-
sic Two-Dimensional Cutting Stock Problem (2DCSP) fulﬁlls orders by cutting
items from stocks. A more constrained variant, the 2SCSP only allows stocks to
be processed using guillotine cuts, a cut that runs from one edge of the object
to another. All cuts must also be executed in two stages, each consisting of a set
of parallel guillotine cuts performed on a rectangle obtained from the previous
stage. Without loss of generality, we let the direction of the ﬁrst stage cuts be
widthwise and that of the second stage ones lengthwise. The rectangles produced
in the ﬁrst stage are referred to as levels, following the literature [7], and those
produced in the second stage as partitions. On top of 2SCSP, the 2SCSP-FF has
the following characteristics arising from our application:

Packing by Scheduling: 2SCSP-FF
251
– Flexible Length: The length of an item is ﬂexible within some integer inter-
val. If a level contains items from diﬀerent orders, its length must lie in the
intersection of the item-length intervals. In our application, items are subse-
quently rolled into cylindrical coils used as feedstock for downstream process-
ing. The maximum length requirement ensures a maximum coil diameter to
enable mounting it on a downstream machine. The minimum length require-
ment comes from the desire to limit the number of coils.
– Flexible Demand: Consistent with real-world manufacturing practices, each
order can tolerate a percentage deviation from the total area demanded. For
example, an order may request items totalling 10000 ± 15% units of area.
– Maximum Partition Count per Level: To reﬂect the limitations of an
industrial cutter, the maximum number of partitions on each level is ﬁxed.
– Limited Stocks with Variable Widths: Stock rectangles of various widths
are available in limited quantities.
– Cost Minimization: The goal is to minimize cost: a weighted diﬀerence
between the area of the stocks used and the area of the orders fulﬁlled.
Formally, we are given a set of stock rectangles K, whose types are character-
ized by set H. Each rectangle k ∈K has width Wk and length L. Stock rectangles
with identical dimensions belong to the same type, Kh, K = 
h∈H Kh. We are
also given a set of orders, N, where each order i ∈N has a required area inter-
val of [qmin
i
, qmax
i
]. Each item belonging to order i should have a ﬁxed width
wi and a length within the interval [ρmin
i
, ρmax
i
]. Due to the ﬂexible length, the
total number of items belonging to order i must be within an integer inter-
val [nmin
i
, nmax
i
] = [⌈qmin
i
ρmax
i
⌉, ⌊qmax
i
ρmin
i
⌋]. For order i, we denote its set of necessary
items as Ai = {1, . . . , nmin
i
}, its set of possible, but not necessary items as
Bi = {nmin
i
+ 1, . . . , nmax
i
}, and all possible items as Ci = Ai
 Bi. Lastly, we
let α and β be the weights associated with the area of stocks used and the area
of orders fulﬁlled, respectively, and seek to minimize this weighted diﬀerence.
Since all stocks share the same length, a stock k can take on at most ¯j =
⌊
L
mini∈N ρmin
i
⌋levels; we denote the set of possible numbers of levels of any stock
as J = {0, . . . ,¯j}. There must also be no more than η partitions on each level.
We let P = {1, . . . , η} be the set of partitions on a given level, and Pi = {l ∈P |
l ≤nmax
i
} be the set of partitions on a given level assuming they are all assigned
to order i. A partition of a stock that is assigned to an order becomes an item.
The 2SCSP-FF can easily be reduced to the 2SCSP if the quantity demanded
of each order and the length of each item are ﬁxed. As the 2SCSP is NP-hard
[7], the 2SCSP-FF problem is at least NP-hard.
3
Literature Review
The 2SCSP was formalized by Gilmore and Gomory [9], who proposed a dynamic
program and the well-known exponential-sized model solved via column gener-
ation. Since then, MIP has been the dominant approach in model-based stud-
ies. Limited to a single stock rectangle, Lodi and Monaci [22] proposed a com-
pact formulation that restricts levelwise assignments for each item to reduce

252
Y. L. Luo and J. C. Beck
symmetry. Silva et al. [29] proposed a pseudo-polynomial formulation based on
the idea of cuts and residual plates for a 2SCSP with identical stocks. Furini
et al. [7] extended both of these models to include diﬀerent stock sizes while also
proposing a branch-and-price algorithm based on Gilmore and Gomory’s model.
Macedo et al. [24] developed an arc ﬂow formulation based on item positioning.
Dincbas and Simonis proposed the ﬁrst CP-based approach [6] to the 2SCSP,
generating stock patterns using a combination of backtrack search and a ﬁnite
domain model. Later, Beldiceanu and Contejean introduced diffn [1,2], a global
constraint with an option to enforce guillotine cuts; however, no experimental
results related to guillotine cuts were provided. Since then, CP has largely been
investigated in other packing contexts. For the two-dimensional optimal rect-
angle packing problem, Korf [15,16] considered solving a constraint satisfaction
problem using the absolute positions of items. Moﬃtt and Pollack [26] studied
the same satisfaction problem from a relative placement perspective, focusing
on the pairwise relationships between items. For the same problem, Clautiaux
et al. [5] considered a scheduling approach, representing the width and length of
items as two interval variables. This was improved by Mesyagutov et al. [25], who
integrated linear-programming-based pruning rules to propagate the constraints.
Simonis and O’Sullivan investigated CP search strategies to pack squares into
rectangles using the Cumulative global constraint [30,31]. For 1D packing,
Shaw [28] proposed a global constraint Pack. For a comprehensive review of 2D
packing problems, we refer the reader to surveys by Lodi et al. [21], W¨ascher
et al. [33] and Iori et al. [12].
While the 2SCSP has been widely studied, we could ﬁnd only one work
addressing item ﬂexibility in the 2D setting. Lee et al. [20] considered a variant
of the 2SCSP with ﬂexible width and length and proposed a multi-stage heuristic
to iteratively pack items and adjust level dimensions. They also proposed a non-
linear model but did not investigate its performance.
CP techniques have been widely adopted in scheduling [17,19]. In relation
to our main approach, we discuss the literature on two types of problem: batch
scheduling and vehicle routing. Batch scheduling arises when a set of jobs with
common characteristics need to be processed together. Tang and Beck [32] pro-
posed a CP formulation using interval variables for a multi-stage tool layup line
problem. Ham and Cakici [10] used interval variables and state functions to
represent a ﬂexible job shop scheduling problem with parallel batch processing
machines. Vehicle Routing Problems (VRP) optimize the routes of vehicles while
some criteria associated with each route are satisﬁed. A number of CP models
for VRP [4,8,13] represent the problem from a scheduling perspective with the
trip-to-vehicle assignments modelled with some form of the Alternative con-
straint. Recently, Booth and Beck [3] introduced the single resource model, where
multiple resources are uniﬁed into a single resource on an expanded time horizon.
They show that their formulation yields computation advantage over traditional
modelling constructs in a capacity- and time-constrained routing problem.

Packing by Scheduling: 2SCSP-FF
253
Fig. 2. Illustration of the CP SR model. The length of the stock rectangles are concate-
nated along the horizontal axis. Here, a level is a vertical strip. The smaller rectangles
and the dashed lines represent items and guillotine cuts, respectively.
4
The Single Resource CP Formulation
In this section, we present our main contribution: the Single Resource CP model,
CPSR. Our model poses the 2SCSP-FF as a scheduling problem composed of
three main components: a uniﬁed domain of stock length, a state function for
guillotine cuts, and cumulative functions tracking widthwise resources.
Uniﬁed Lengthwise Domain. Our model adapts the single resource transforma-
tion [3], a CP modelling technique that uniﬁes alternative resources into a single
horizon, to the 2SCSP-FF. CPSR concatenates the stock rectangles so that the
total length of the stocks is analogous to a temporal horizon on which items
belonging to all orders need to be allocated (Fig. 2a). For each possible item
p ∈Ci belonging to order i, we introduce an optional interval variable xip. In
CP scheduling, an optional interval variable is a variable whose domain is a sub-
set of {⊥} {[s, ϵ)|s, ϵ ∈Z, s ≤ϵ}, where s and ϵ are the start and end times of
the interval, and ⊥is a special value indicating absence. In our case, the start
time of xip represents an item’s leftmost lengthwise coordinate, and the dura-
tion of xip its length, which we further restrict to be within [ρmin
i
, ρmax
i
]. For
necessary items (i.e., in set Ai), we remove {⊥} from the domain of xip for all
p ∈Ai and simply declare them as interval variables.
To avoid an item spanning multiple stocks in the uniﬁed horizon, we insert a
dummy unit of forbidden space between adjacent stocks to create an infeasible
region (Fig. 2a, hatched). The horizon is thus augmented from L|K| to (L +

254
Y. L. Luo and J. C. Beck
1)|K|, and no items can be placed in the infeasible region ¯F = 
k∈K[Lk, (L +
1)(k)]. We denote the augmented horizon as H = [0, L|K| + (|K| −1)] and use
ForbidExtent to exclude ¯F from the domain of the item variables xip.
Guillotine State Function. We draw inspiration from batch scheduling to model
guillotine cuts: we treat each level in a stock rectangle as a batch so that the
level’s lengthwise endpoints coincide with the corresponding endpoints of the
items. We ﬁrst introduce a state function, g, a variable whose domain is a set
of non-overlapping intervals (Fig. 2b). Then, we associate the items with a level
using an AlwaysConstant constraint, which coerces their interval variables to
align with an interval in g. Thus, items can only be on the same level if they
belong to the same interval in the state function.
Cumulative Resource Function Expressions. The width of stocks and a level’s
partition count limit are interpreted as widthwise resources. Typical of CP
scheduling, we use cumulative functions and pulses: the former are expressions
that represent the sum of individual contributions of intervals over time, while
the latter are expressions that indicate each interval’s contribution. We let Ω,
a cumulative function, be the net widthwise capacity over the horizon. In Ω,
we generate a pulse with magnitude Wk for each stock rectangle k and a pulse
with magnitude −wi for every item belonging to order i (Fig. 2c). As long as Ω
is non-negative, the widthwise capacity is satisﬁed. A similar construct is used
to express the limit on the number of partitions on each level (Fig. 2d), where a
positive pulse with unit magnitude is generated for each item. We constrain the
total cumulative function of these unit pulses, Γ, to be within η.
Overall, our decision variables are as follows:
– xip := (interval) lengthwise interval of item p belonging to order i.
– ck := (interval) lengthwise interval representing stock k.
– g := (state function) guillotine state function.
CPSR is deﬁned in Model 1, using the syntax of IBM’s CP Optimizer [11].
Objective (1a) deﬁnes our cost, the weighted diﬀerence between the areas of
stocks used and orders fulﬁlled. Expressions PresenceOf and SizeOf are used
to access the presence and the duration of an interval variable. If the variable is
not present, both expressions evaluate to 0. Constraints (1b) and (1c) deﬁne the
widthwise usage of each stock. The last two parameters in the AlwaysIn con-
straint respectively dictate the minimum and maximum values that the cumula-
tive function Ω can take on over the horizon H. Constraints (1d) and (1e) deﬁne
the restriction on the number of partitions on each level. Constraint (1f) deﬁnes
the guillotine cut restrictions. The last two parameters in AlwaysConstant
ensure that the start and end times of the variables xip are aligned with those
of the intervals within the state function g. Constraints (1g) and (1h) ensure
that the total quantity of the order fulﬁlled is within the demand tolerance.
Constraint (1i) ensures that no partition is assigned across two stock rectangles.
The remaining constraints declare the decision variables.

Packing by Scheduling: 2SCSP-FF
255
min α

k∈K
LWkPresenceOf(ck)
(CPSR)
(1a)
−β

i∈N

p∈Ci
wiPresenceOf(xip)SizeOf(xip)
s.t. Ω =

k∈K
Pulse(ck, Wk) −

i∈N

p∈Ci
Pulse(xip, wi)
(1b)
AlwaysIn(Ω, H, 0, max
k∈K Wk)
(1c)
Γ =

i∈N

p∈Ci
Pulse(xip, 1)
(1d)
AlwaysIn(Γ, H, 0, η)
(1e)
AlwaysConstant(g, xip, True, True)
∀i ∈N, p ∈Ci
(1f)

p∈Ci
SizeOf(xip) ≥qmin
i
/wi
∀i ∈N
(1g)

p∈Ci
SizeOf(xip) ≤qmax
i
/wi
∀i ∈N
(1h)
ForbidExtent(xip, ¯F)
∀i ∈N, p ∈Ci
(1i)
xip : IntervalVar(H, [ρmin
i
, ρmax
i
])
∀i ∈N, p ∈Ai
(1j)
xip : OptIntervalVar(H, [ρmin
i
, ρmax
i
])
∀i ∈N, p ∈Bi
(1k)
ck : IntervalVar([(L + 1)(k −1), (L + 1)k −1], L) ∀k ∈K
(1l)
g : StateFunction()
(1m)
5
Alternative Approaches
We also propose integer-based CP and MIP models and a two-stage heuristic.
5.1
Integer-Based CP Formulations
Counting-Based CP Model. Due to the two-stage cuts, partitions assigned
to the same order on a level must be identical; hence, we can count them. For a
given level j from stock k, we use an integer variable xijk to denote the number
of partitions assigned to order i. We use an integer variable yjk to represent the
length of level j on stock k. As the position of the lengthwise cut is not restricted
to be integral, we magnify the domain using a precision parameter P equal to
some power of ten, so that yjk represents the ﬁrst log10 P decimal places of the
actual length. More formally, our decision variables are as follows:
– xijk := (integer) # of partitions on level j of stock k assigned to order i
– yjk := (integer) length of level j of stock k magniﬁed by P

256
Y. L. Luo and J. C. Beck
min α

k∈K
LWkck −β

i∈N

j∈J

k∈K
wixijkyjk/P
(CPCO)
(2a)
s.t.

i∈N
xijkwi ≤Wksjk
∀j ∈J, k ∈K
(2b)
yjk/P ≤ρmax
i
+ (xijk == 0) max
n∈N(ρmax
n
)
∀i ∈N, j ∈J, k ∈K
(2c)
yjk/P ≥ρmin
i
(xijk ≥1)
∀i ∈N, j ∈J, k ∈K
(2d)

j∈J

k∈K
yjkxijk/P ≥qmin
i
/wi
∀i ∈N
(2e)

j∈J

k∈K
yjkxijk/P ≤qmax
i
/wi
∀i ∈N
(2f)

j∈J
yjk/P ≤Lck
∀k ∈K
(2g)
sjk = Any([xijk > 0, ∀i ∈N])
∀j ∈J, k ∈K
(2h)
ck = Any([sjk = 1, ∀j ∈J])
∀k ∈M
(2i)
xijk ∈{0, ..., η}
∀i ∈N, j ∈J, k ∈K
(2j)
yjk ∈{0, min
i∈N ρmin
i
P, . . . , max
i∈N ρmax
i
P}
∀j ∈J, k ∈K
(2k)
Model 2 formalizes CPCO. Objective (2a) describes the cost. Since yjk is
magniﬁed, we divide it by P to recover its actual length. Constraint (2b) restricts
the width of the stocks. Constraints (2c) and (2d) restrict the length of a level
by the tightest interval determined by the allotted orders. Constraints (2e) and
(2f) ensure that partitions of each order fulﬁlled satisfy the total quantity range
demanded. Constraint (2g) restricts the length of the stocks in use. Constraints
(2h) and (2i) describe if a level and a stock is used, respectively.
Stock-Based CP Model. Extending the standard integer-based CP model
for one-dimensional bin packing [14], the stock-based CP model, CPST , takes
advantage of the limited number of possible partitions on a level, matching each
partition to some order. Speciﬁcally, we deﬁne integer variables xjkl representing
the index of the order to which the lth partition of the jth level on the kth stock is
assigned. As not all partitions are always needed, we deﬁne a dummy order that
serves as a placeholder. Formally, the dummy order, indexed by D = |N| + 1,
has width wD = 0 and length interval [ρmin
D
, ρmax
D
] = [0, max
i∈N (ρmax
i
)]. We use
N = N {D} to denote the set of original orders plus the dummy order; w to
denote the set of widths of original orders union the dummy width wD; ρmin
and ρmax to denote the lengthwise bounds of orders union the dummy bounds
ρmin
D
and ρmax
D
. Similar to CPCO, we let yjk be the length of level j on stock k
and magnify its domain using P.

Packing by Scheduling: 2SCSP-FF
257
minimize

k∈K
LWkck −

j∈J

k∈K

l∈P
wxjklyjk/P
(CPST )
(3a)
s.t.

l∈P
wxjkl ≤Wksjk
∀j ∈J, k ∈K
(3b)
yjk/P ≤ρmaxxjkl
∀j ∈J, k ∈K, l ∈P (3c)
yjk/P ≥ρminxjkl
∀j ∈J, k ∈K, l ∈P (3d)

j∈J

k∈K

l∈P
(xjkl == i)yjk/P ≥qmin
i
/wi
∀i ∈N
(3e)

j∈J

k∈K

l∈P
(xjkl == i)yjk/P ≤qmax
i
/wi
∀i ∈N
(3f)
sjk = Any([xjkl ̸= D, ∀l ∈P])
∀j ∈J, k ∈K
(3g)
xjkl ∈N
∀j ∈J, k ∈K, l ∈P (3h)
(2g), (2i), (2k)
Model 3 formalizes CPST . Objective (3a) minimizes the cost. Constraint (3b)
ensures that the widthwise capacity is satisﬁed on each stock. In particular, w
is indexed by xjkl using the Element constraint. Constraints (3c) and (3d)
constrain the length of a level by the items assigned on it. Constraints (3e) and
(3f) satisfy the total area of each order. Constraint (3g) instantiates intermediate
parameters indicating level usage.
Modelling Considerations
Symmetry-Breaking: The problem has a number of inherent symmetries due to
the homogenous items, levels, and stock rectangles. Hence, we augment CPCO
and CPST with the following symmetry-breaking constraints:
yjk ≥y(j+1)k
∀j ∈J′, k ∈K
(4a)
ck ≥ck+1
∀k ∈K′
h, h ∈H
(4b)
These constraints break the symmetry between the lengths of consecutive lev-
els on the same stock and the presence of homogeneous stocks, respectively. We
use a prime to indicate an ordered set without its last element: J′ = J \{|J|}. For
CPST , we also specify a lexicographic ordering of the order indices on consecutive
levels of the same stock via Lexicographic([xjkl, ∀l ∈P], [x(j+1)kl, ∀l ∈P]).
Item-Based CP Model: Using Pack [28], we can also construct an integer-based
CP model that decides on the level that an item is assigned to. Two such struc-
tures exist in 2SCSP-FF: the packing of items into levels and that of levels into
stocks. While the former can be represented by Pack, the latter cannot due
to the lengthwise ﬂexibility and is represented by constraints that decompose
Pack. The model is omitted due to poor computational performance.

258
Y. L. Luo and J. C. Beck
5.2
Mixed-Integer Formulation
We also introduce a mixed-integer program, MIP, that uses binary variables to
assign partitions on each level to orders. Formulating a strong MIP model is
challenging, as determining the area of each order requires information related
to two independent decisions: the order-to-level assignment and the level length
given order assignments. In MIP, we linearize this relationship at the expense of
introducing new variables, each one packing an item of an order into a level of a
stock. While it is tempting to decompose them into independent orders-to-levels
and levels-to-stocks decisions similar to the compact formulation in Furini et al.
[7], representing both the area of each order and the variable length of each level
using linear constraints is nontrivial. Here, we do not investigate this further.
More formally, our decision variables are as follows:
– xijkl := (binary) 1 if the lth partition from the jth level of the kth stock is
assigned to the ith order, else 0.
– yjk := (continuous) the length of the jth level on the kth stock.
– aijkl := (continuous) the area occupied by the lth partition of the jth level on
the kth stock belonging to order i.
– ck := (binary) 1 if the kth stock is used, else 0.
MIP is deﬁned in Model 5. Objective (5a) describes the cost. Constraint (5b)
restricts the stocks’ width. Constraint (5c) limits the number of lengthwise cuts.
Constraint (5d) ensures that the lengthwise capacity of each stock is satisﬁed.
Constraints (5e) and (5f) assert that the level’s length must respect the mini-
mum and maximum length of items assigned to it. Constraints (5g) and (5h)
ensure that the quantity of each order assigned across all stocks is satisfactory.
Constraints (5i), (5j), and (5k) deﬁne the area of each partition on a level.
min α

k∈K
LWkck −β

i∈N,j∈J,k∈K,l∈Pi
aijkl
(MIP)
(5a)
s.t.

i∈N,l∈Pi
wixijkl ≤Wkck
∀j ∈J, k ∈K
(5b)

i∈N,l∈Pi
xijkl ≤ηck
∀j ∈J, k ∈K
(5c)

j∈J
yjk ≤Lck
∀k ∈K
(5d)
yjk ≥ρmin
i
xijkl
∀i ∈N, j ∈J, k ∈K, l ∈Pi
(5e)
yjk ≤ρmax
i
xijkl + max
i′∈N(ρmax
i′
)(1 −xijkl)
∀i ∈N, j ∈J, k ∈K, l ∈Pi
(5f)

l∈Pi,j∈J,k∈K
aijkl ≥qmin
i
∀i ∈N
(5g)

l∈Pi,j∈J,k∈K
aijkl ≤qmax
i
∀i ∈N
(5h)
aijkl ≤wiyjk
∀i ∈N
(5i)
aijkl ≥wiyjk −ρmax
i
wi(1 −xijkl)
∀i ∈N
(5j)
aijkl ≤ρmax
i
wixijkl
∀i ∈N, j ∈J, k ∈K, l ∈Pi
(5k)

Packing by Scheduling: 2SCSP-FF
259
xijkl ∈{0, 1}
∀i ∈N, j ∈J, k ∈K, l ∈Pi
(5l)
yjk ∈R+
∀j ∈J, k ∈K
(5m)
aijkl ∈R+
∀i ∈N, j ∈J, k ∈K, l ∈Pi
(5n)
ck ∈{0, 1}
∀k ∈K
(5o)
Modelling Considerations
Symmetry-Breaking: We can again add symmetry-breaking constraints (4a) and
(4b) to MIP similar to CPCO and CPST . Furthermore, we add constraints (6a)
and (6b) to break the symmetry between partitions on the same level belonging
to the same order and the length of the ﬁrst level of identical stocks, respectively.
xijkl ≥xijk(l+1)
∀i ∈N, j ∈J, k ∈K, l ∈P ′
i
(6a)
y0k ≥y0(k+1)
∀k ∈K′
h, h ∈H
(6b)
One-Hot Encoded Formulation: In order to retain linearity, MIP treats the
assignment of diﬀerent partitions on the same level to an order as individual
decisions. Alternatively, we can one-hot encode the number of partitions assigned
to the level so that each binary variable xijkl takes the value 1 if and only if
there are l partitions (with identical dimensions) on level j of stock k assigned to
order i. This formulation underperforms MIP in our experiments and is omitted.
5.3
First-Fit Based Heuristic
In addition to the mathematical models, we develop a two-stage ﬁrst-ﬁt-based
heuristic, FFMH . The ﬁrst stage sorts the orders’ items in a lexicographically
decreasing order based on their width and length interval size and packs each
one into a level. The intuition is that orders with less lengthwise ﬂexibility and
larger width should be packed into a level ﬁrst, as they can be more diﬃcult to
pack into a partial solution. A new level or stock is opened if an item cannot ﬁt
into the previous level or stock. Packing an item into a stock’s level only narrows
its length interval: another decision is required to obtain its exact length and
thereafter each order’s total area. For simplicity, we pack items of an order until
the sum of the average possible area of each item is not less than the middle of
the required area interval for that order. In the second stage, given the complete
item-to-level assignment, we solve a linear program (Model 7) to determine each
level’s length, while minimizing cost.1
1 The form of this two-stage heuristic suggests that a classical Benders decomposition
approach may be worth investigation in future work.

260
Y. L. Luo and J. C. Beck
max

i∈N,j∈J,k∈K
wiΦijkyjk
(7a)
s.t.

j∈J
yjk ≤L
∀k ∈K
(7b)
yjk ≥Φind
ijk ρmin
i
∀i ∈N, j ∈J, k ∈K
(7c)
yjk ≤Φind
ijk ρmax
i
+ (1 −Φind
ijk ) max
i′∈N(ρmax
i′
)
∀i ∈N, j ∈J, k ∈K
(7d)

j∈J,k∈K
wiΦijkyjk ≥qmin
i
∀i ∈N
(7e)

j∈J,k∈K
wiΦijkyjk ≤qmax
i
∀i ∈N
(7f)
yjk ∈R+
∀j ∈J, k ∈K
(7g)
The only variables in Model 7 are the continuous variables yjk describing
the length of the jth level on the kth stock. The parameter Φijk is the number
of partitions on the jth level of the kth stock that belongs to order i, and the
parameter Φind
ijk is a 0-1 indicator for Φijk > 0. We simplify the cost minimiza-
tion objective to maximize total fulﬁllment (7a) because the number of stocks
used is ﬁxed given the item-to-level assignment. Constraint (7b) constrains the
stock length. Constraints (7c) and (7d) satisfy the length speciﬁcations of the
partitions. Constraints (7e) and (7f) ensure the total fulﬁllment of each order to
be within tolerance limits. Constraint (7g) declares the variable domain.
6
Numerical Results
We conduct our analysis on a combination of 50 generated problem instances
and 4 real-life instances provided by our industry partner (Table 1).
For the generated instances, we draw from distributions provided by our
industrial collaborator (Table 2), generating 10 instances for each parameter
combination in the set {(|N|, |K|)} ∈{(4, 8), (8, 16), (16, 32), (32, 64), (64, 128)}.
For 5 out of these 10 instances, we halve the total area tolerances to provide
variability. In the rare case that, for some order i, ρmax
i
≤ρmin
i
is generated, we
swap the two values.
Table 1. Mean of the parameter combinations from the four industrial instances.
|N| |K| Wk
wi
ρmin
i
ρmax
i
qmin
i
qmax
i
19
42
48
22.2 112.9 180.2 1.3e5 1.7e5
21
172 45.2 16.3 56.6
94.6
9.7e4 1.3e5
47
149 43.3 10.4 68.2
134.1 1.6e5 2.1e5
149 636 44.6 13.3 74.4
134.4 2.5e5 3.4e5

Packing by Scheduling: 2SCSP-FF
261
Table 2. Data distributions for each parameter.
Parameter Distribution
∀order i ∈N
qi
Exponential(λ=5.608e-0.5)
qmax
i
Constant, 0.85 qi
qmin
i
Constant, 1.15 qi
wi
Integer Uniform(a=1, b=20)
ρmax
i
Integer Uniform(a=70, b=115)
ρmin
i
Integer Uniform(a=85, b=130)
∀stock k ∈K
Wk
Integer Uniform(a=36, b=50) with 50% chance of duplicating previous stock
L
Constant, 400
Fig. 3. Comparison of the number of variables, the number of constraints, and the
model memory before search over instance sizes. Note the scales of the y-axes.
All experiments are implemented in Python 3.8, and computations were per-
formed on individual nodes of the SciNet Niagara cluster [23,27]. We use CPLEX
and CP Optimizer from the CPLEX Optimization Studio version 20.1.0 via the
DOcplex library. Each model is given 16 GB of RAM and runs that exceed this
size are aborted. All experiments are single-threaded with default search and
inference settings. A one-hour time limit is used.
For the CP integer-based models, we set P, the magnifying parameter, to 1,
as increasing it led to poor performance. We set α and β, the objective weights,
to 0.3 and 0.7, respectively, to reﬂect the industrial use case.
Model Size Comparison. Figure 3 compares the mean model sizes based on the
number of variables, the number of constraints, and the model memory (before
search). The memory usage of MIP is not accessible from the solver. A data
point is omitted if the corresponding model fails to initialize in memory within
the one hour time limit. The CPSR formulation is signiﬁcantly smaller than the

262
Y. L. Luo and J. C. Beck
Fig. 4. (Left) Number of generated and industrial instances with a feasible solution
by each model. (Right) The average run time required to ﬁnd a feasible solution for a
given model at an instance size.
Fig. 5. % optimality gap for generated and industrial instances. Instances that are not
solved by an approach are not included in that approach’s measure.
other models across all three measures, especially as the instances scale up. For
the largest industrial instances, no other models could be loaded before timing
out. For the largest generated instances, (64, 128), the CPCO model requires
about 800MB of memory, while CPSR only needs 20MB.
Feasibility Analysis. Figure 4 reports the number of instances for which a feasible
solution was found and the average time to feasibility or termination. Only
CPSR and FFMH found a feasible solution to all instances. In particular, CPSR
reached feasibility the fastest amongst all methods, requiring less than 100 s for
the largest industrial instance, while FFMH , the second fastest, needed almost
the entire one-hour run time. Notably, MIP failed to ﬁnd feasible solutions for
generated and industrial instances with |N| ≥32 and |N| ≥21, respectively.
Solution Quality. Figure 5 displays the optimality gap of each approach calcu-
lated from Eq. (8). Here, z(n; i) is the objective value of approach n for instance
i, and lb(i) is the best lower bound of instance i across all approaches. For a
given solution approach, we omit any unsolved instances from the visualization;
hence, CPSR is penalized for ﬁnding solutions to harder instances compared to
approaches that did not do so.
%OptGap(n; i) = 100z(n; i) −lb(i)
lb(i)
(8)

Packing by Scheduling: 2SCSP-FF
263
MIP demonstrated the strongest performance for generated instances with
|N| ≤16. It proved optimality for three generated instances, the only ones
proven optimal across all models. For larger instances (|N| ≥32), MIP scaled
poorly, failing to ﬁnd a feasible solution within the time limit. Both CPCO
and CPST struggle to ﬁnd competitive solutions to the generated instances past
N = 4, eventually encountering loading time issues for larger instances. Notably,
CPCO found similar solutions to MIP for the smallest generated instances, but
could not prove optimality due to a weaker lower bound. CPSR consistently
outperformed MIP and the other CP models for all but the smaller instances. A
similar trend is observed on the industrial instances, where CPSR was the only
model-based approach that found a feasible solution to more than one instance.
For both sets of instances, CPSR consistently found better solutions than the
heuristic in less time. We also observe that the optimality gaps of the larger
instances that only CPSR can solve are of the same order of magnitude as the
gaps of the smaller ones. The lower bounds of these large instances are generated
by CPSR, but their values are non-trivial, a rare feat for typical CP approaches.
We note that CP Optimizer computes the lower bound using an automatic LP-
based relaxation of the scheduling constraints [18], a feature not available in
some other CP solvers.
7
Discussion and Conclusion
In this paper, we create a CP scheduling approach for a novel packing prob-
lem: the Two-stage Cutting Stock Problem with Flexible Length and Flexible
Demand (2SCSP-FF). Using optional intervals, state functions, and cumulative
functions, our model, CPSR, has signiﬁcant computational and performance
advantages over two alternative CP models, a MIP model, and a two-stage
heuristic on large generated and industrial instances.
The memory eﬃciency of CPSR can be attributed to the compact representa-
tion of the complicated substructures. To represent the guillotine cuts, CPSR is
the only model that does not enumerate over the set of levels J, instead using just
a state function and a AlwaysConstant constraint. Similarly, CPSR restricts
the widthwise capacities and the partition counts without levelwise constraints.
By using the fewest variables and constraints, the CPSR model has at least an
order-of-magnitude savings in its memory usage. As the instances scale up, this
advantage increases.
Accordingly, only CPSR found a feasible solution to more than one industrial-
scale instance. The short time-to-feasibility, however, diﬀers from the results
for routing problems [3], where the model struggled to ﬁnd feasible solutions
quickly. We suspect that this disparity is due to the looser constraints on interval
variables for our problem compared to the routing formulation.
Overall, our success here suggests that the ﬂexibility of CP scheduling tools
provides a promising approach to attacking complex real-world problems beyond
traditional scheduling ones.

264
Y. L. Luo and J. C. Beck
Acknowledgements. We thank anonymous reviewers for their valuable feedback.
This research was partially supported by Visual Thinking International Ltd (Visual8)
and the Natural Sciences and Engineering Research Council of Canada.
References
1. Beldiceanu, N., Carlsson, M., Flener, P., Pearson, J.: On the reiﬁcation of global
constraints. Constraints 18, 1–6 (2012)
2. Beldiceanu, N., Contejean, E.: Introducing global constraints in chip. Math. Com-
put. Model. 20(12), 97–123 (1994)
3. Booth, K.E.C., Beck, J.C.: A constraint programming approach to electric vehicle
routing with time windows. In: Rousseau, L.-M., Stergiou, K. (eds.) CPAIOR 2019.
LNCS, vol. 11494, pp. 129–145. Springer, Cham (2019). https://doi.org/10.1007/
978-3-030-19212-9 9
4. Cappart, Q., Schaus, P.: Rescheduling railway traﬃc on real time situations using
time-interval variables. In: Salvagnin, D., Lombardi, M. (eds.) CPAIOR 2017.
LNCS, vol. 10335, pp. 312–327. Springer, Cham (2017). https://doi.org/10.1007/
978-3-319-59776-8 26
5. Clautiaux, F., Jouglet, A., Carlier, J., Moukrim, A.: A new constraint programming
approach for the orthogonal packing problem. Comput. Oper. Res. 35(3), 944–959
(2008). Part Special Issue: New Trends in Locational Analysis
6. Dincbas, M., Simonis, H., Hentenryck, P.V.: Solving a cutting-stock problem with
the constraint logic programming language CHIP. Math. Comput. Model. 16, 95–
105 (1992)
7. Furini, F., Malaguti, E.: Models for the two-dimensional two-stage cutting stock
problem with multiple stock size. Comput. Oper. Res. 40(8), 1953–1962 (2013)
8. Gedik, R., Kirac, E., Milburn, A.B., Rainwater, C.: A constraint programming
approach for the team orienteering problem with time windows. Comput. Ind.
Eng. 107, 178–195 (2017)
9. Gilmore, P.C., Gomory, R.E.: Multistage cutting stock problems of two and more
dimensions. Oper. Res. 13(1), 94–120 (1965)
10. Ham, A.M., Cakici, E.: Flexible job shop scheduling problem with parallel batch
processing machines: MIP and CP approaches. Comput. Ind. Eng. 102, 160–165
(2016)
11. IBM: CP optimizer user manual. https://www.ibm.com/docs/en/icos/20.1.0?
topic=optimizer-cp-users-manual
12. Iori, M., de Lima, V.L., Martello, S., Miyazawa, F.K., Monaci, M.: Exact solution
techniques for two-dimensional cutting and packing. Eur. J. Oper. Res. 289(2),
399–415 (2021)
13. Kinable, J., van Hoeve, W.-J., Smith, S.F.: Optimization models for a real-world
snow plow routing problem. In: Quimper, C.-G. (ed.) CPAIOR 2016. LNCS, vol.
9676, pp. 229–245. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-
33954-2 17
14. Kong, V.L.: IBMDecisionOptimization: Docplex-Examples/Trimloss.py (2020).
https://github.com/IBMDecisionOptimization/docplex-examples/blob/master/
examples/cp/basic/trimloss.py
15. Korf, R.E.: Optimal rectangle packing: initial results. In: Proceedings of the Thir-
teenth International Conference on Automated Planning and Scheduling (ICAPS
2003), pp. 287–295. AAAI (2003)

Packing by Scheduling: 2SCSP-FF
265
16. Korf, R.E.: Optimal rectangle packing: new results. In: Proceedings of the Four-
teenth International Conference on Automated Planning and Scheduling (ICAPS
2004), pp. 142–149. AAAI (2004)
17. Ku, W., Beck, J.C.: Mixed integer programming models for job shop scheduling: a
computational analysis. Comput. Oper. Res. 73, 165–173 (2016)
18. Laborie, P., Rogerie, J.: Temporal linear relaxation in IBM ILOG CP optimizer.
J. Sched. 19(4), 391–400 (2016)
19. Laborie, P., Rogerie, J., Shaw, P., Vil´ım, P.: IBM ILOG CP optimizer for scheduling
- 20+ years of scheduling with constraints at IBM/ILOG. Constraints 23(2), 210–
250 (2018)
20. Lee, J., Kim, B.I., Johnson, A.L.: A two-dimensional bin packing problem with
size changeable items for the production of wind turbine ﬂanges in the open die
forging industry. IIE Trans. 45, 1332–1344 (2013)
21. Lodi, A., Martello, S., Monaci, M.: Two-dimensional packing problems: a survey.
Eur. J. Oper. Res. 141(2), 241–252 (2002)
22. Lodi, A., Monaci, M.: Integer linear programming models for 2-staged two-
dimensional knapsack problems. Math. Program. 94(2–3), 257–278 (2003)
23. Loken, C., et al.: SciNet: lessons learned from building a power-eﬃcient top-20
system and data centre. In: Journal of Physics: Conference Series, vol. 256, p.
012026 (2010)
24. Macedo, R., Alves, C., de Carvalho, J.M.V.: Arc-ﬂow model for the two-
dimensional guillotine cutting stock problem. Comput. Oper. Res. 37(6), 991–1001
(2010)
25. Mesyagutov, M., Scheithauer, G., Belov, G.: LP bounds in various constraint pro-
gramming approaches for orthogonal packing. Comput. Oper. Res. 39(10), 2425–
2438 (2012)
26. Moﬃtt, M.D., Pollack, M.E.: Optimal rectangle packing: a meta-CSP approach.
In: Proceedings of the Sixteenth International Conference on Automated Planning
and Scheduling, (ICAPS 2006), pp. 93–102. AAAI (2006)
27. Ponce, M., et al.: Deploying a top-100 supercomputer for large parallel workloads:
the Niagara supercomputer. In: Proceedings of the Practice and Experience in
Advanced Research Computing on Rise of the Machines (Learning), PEARC 2019,
Chicago, IL, USA, 28 July–01 August 2019, pp. 34:1–34:8. ACM (2019)
28. Shaw, P.: A constraint for bin packing. In: Wallace, M. (ed.) CP 2004. LNCS,
vol. 3258, pp. 648–662. Springer, Heidelberg (2004). https://doi.org/10.1007/978-
3-540-30201-8 47
29. Silva, E., Alvelos, F., Val´erio de Carvalho, J.: An integer programming model for
two- and three-stage two-dimensional cutting stock problems. Eur. J. Oper. Res.
205(3), 699–708 (2010)
30. Simonis, H., O’Sullivan, B.: Search strategies for rectangle packing. In: Stuckey, P.J.
(ed.) CP 2008. LNCS, vol. 5202, pp. 52–66. Springer, Heidelberg (2008). https://
doi.org/10.1007/978-3-540-85958-1 4
31. Simonis, H., O’Sullivan, B.: Almost square packing. In: Achterberg, T., Beck, J.C.
(eds.) CPAIOR 2011. LNCS, vol. 6697, pp. 196–209. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-21311-3 19
32. Tang, T.Y., Beck, J.C.: CP and hybrid models for two-stage batching and schedul-
ing. In: Hebrard, E., Musliu, N. (eds.) CPAIOR 2020. LNCS, vol. 12296, pp. 431–
446. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58942-4 28
33. W¨ascher, G., Haußner, H., Schumann, H.: An improved typology of cutting and
packing problems. Eur. J. Oper. Res. 183(3), 1109–1130 (2007)
34. Yang, D., et al.: Flexibility in metal forming. CIRP Ann. 67(2), 743–765 (2018)

Dealing with the Product Constraint
Steve Malalel(B), Victor Jung, Jean-Charles R´egin, and Marie Pelleau
Universit´e Cˆote d’Azur, CNRS, I3S, Nice, France
{steve.malalel,victor.jung,jean-charles.regin,
marie.pelleau}@univ-cotedazur.fr
Abstract. The product constraint ensures that the product of some
variables will be greater than a given value, that is Πn
i=1xi ≥w. With
the emergence of stochastic problems, this constraint appears more and
more frequently in practice. The variables are most often probability
variables that represent the probability that an event will occur and the
minimum bound is the minimum probability that must be satisﬁed. This
is often done to guarantee a certain level of security or a certain quality of
service. To deal with this constraint, it is tempting as proposed by many
authors to take the logarithm of the sum and the bound in order to
transform the product into a sum. In this article we show that this idea
creates many problems and forbids an exact calculation. We propose
and compare diﬀerent representations allowing to compute the set of
solutions of this problem exactly or up to a certain precision. We also
give an eﬃcient method to represent that constraint by a Multi-valued
Decision Diagram (MDD) in order to combine this constraint with some
others MDDs.
1
Introduction
More and more problems involve uncertain data associated with probabilities.
For quality of service or security reasons, it is frequently imposed that any solu-
tion must be associated with a minimum probability. This kind of problem is
naturally modeled by deﬁning for each variable x representing uncertain values,
a variable px which represents the probabilities of these values. Then, the vari-
ables x and px are linked together (i.e. x = a ⇔px = p(a)) and the constraint
Πn
i=1pxi ≥w is added to the model in order to guarantee that each solution will
be associated with a probability higher than a given value.
We are mainly interested in deﬁning the multi-valued decision diagram
(MDD) of this constraint as it is classically made for a sum constraint. We
assume that the values of variables are decimal with a given precision.
Usually, the product constraint is modeled by taking the logarithm of both
terms, and so by transforming it into the sum n
i=1 log(pxi) ≥log(w). It seems
more convenient because the product of variables is not easy to manage in con-
straint programming solvers due to overﬂows. However, using a logarithm has
a major drawback: we lose the possibility to make exact calculations because
the logarithm function cannot be represented exactly in a computer as it can
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 266–281, 2022.
https://doi.org/10.1007/978-3-031-08011-1_18

Dealing with the Product Constraint
267
return a transcendental number. Thus, ﬂoating-point numbers have to be used
and errors in the representation have to be managed.
In this paper we study several methods for deﬁning the MDD of this con-
straint. The ﬁrst one is based on the sum of the logarithm. The second one com-
putes the exact MDD of the product of variables. Unfortunately, this method
may need a lot of memory. Therefore we propose to relax the previous MDD up
to a certain precision. On the other hand, we present a method that builds the
MDDs by successive iterations and further compresses it, taking into account
the bound imposed on the constraint. Each iteration corresponds to a precision
that is higher than the previous one. The main idea is to stop considering the
parts of the MDD that will always be satisﬁed when the precision of the com-
putation is increased. For instance, no matter the precision, we will always have
(0.95... × 0.95...) > 0.9.
The paper is organised as follows. First, we recall some deﬁnitions. Then, we
present diﬀerent methods to compute the MDD of the product constraint. Next,
we experiment with these methods. At last, we conclude.
2
Preliminaries
2.1
Constraint Programming
A ﬁnite constraint network N is deﬁned as a set of n variables X = {x1, . . . , xn},
a set of current domains D = {D(x1), . . . , D(xn)} where D(xi) is the ﬁnite set
of possible values for variable xi, and a set C of constraints between variables.
We introduce the particular notation D0 = {D0(x1), . . . , D0(xn)} to represent
the set of initial domains of N on which constraint deﬁnitions were stated. A
constraint C on the ordered set of variables X(C) = (xi1, . . . , xir) is a subset
T(C) of the Cartesian product D0(xi1)×· · ·×D0(xir) that speciﬁes the allowed
combinations of values for the variables xi1, . . . , xir. An element of D0(xi1) ×
· · ·×D0(xir) is called a tuple on X(C) denoted by τ. In a tuple τ, the assignment
of the ith variable is denoted by τi.
We present some constraints that we will use in the rest of this paper.
Deﬁnition 1. Given X a set of variables and w a value, the sum constraint
ensures that the sum of all variables x ∈X is greater than or equal to w.
sum(l, u) = {τ | τ is a tuple on X(C) and 
i=0 τi ≥w}
Deﬁnition 2. Given X a set of variables and w a value, the product constraint
ensures that the product of all variables x ∈X is greater than or equal to w.
product(l, u) = {τ | τ is a tuple on X(C) and Πi=0τi ≥w}
Use of Logarithm Function. Using mathematical functions in CP imposes
to have some guarantees on the values that are computed. In this case, two
important concepts are considered: the correctness and the completeness.
Consider M a model of a problem P, that can use diﬀerent types of numbers
like ﬂoating-point and real numbers. We say that a model M satisﬁes the cor-
rectness condition iﬀall solutions found by the solver are solutions of P. In other

268
S. Malalel et al.
words, there is no solution of M that is not a solution of P. The completeness
condition is satisﬁed iﬀall solutions of P are solutions of M. If both conditions
are met then we say that P is exactly solved.
Unfortunately, the log function may be very complex to calculate exactly,
mainly because the discrete logarithm problem (given real numbers a and
b, the logarithm logb(a) is a number x such that bx = a) is considered to
be computationally intractable. Note that computing the log function with a
ﬁxed precision is equivalent to the discrete logarithm problem. Therefore, we
need to compute an approximation of log. Consider log (resp. log) a lower
bound (resp. upper bound) of the log function. If the product constraint
is modeled by n
i=1 log(pxi) ≥log(w) then the model is correct, because
n
i=1 log(pxi) ≥n
i=1 log(pxi) ≥log(w) ≥log(w). If the product constraint
is modeled by n
i=1 log(pxi) ≥log(w) then the model is complete because
n
i=1 log(pxi) ≥n
i=1 log(pxi) and log(w) ≥log(w).
As the ﬁltering algorithms in CP are based on the deletion of values that do
not belong to a solution, it is fundamental to guarantee that at least all solutions
of the problem are considered and thus that the model is complete. This means
that we need to be able to compute both a lower and an upper bound of the log.
Unfortunately, the properties of the log functions available in a language, like
Java, or in a library is not always provided. However, modern implementation
of elementary functions are at least faithful [7], i.e., they return one of the two
ﬂoating-point numbers surrounding the exact value log(x). Thus, with ﬂoating-
point representation, a lower bound can be obtained by subtracting one machine
epsilon to the value returned by the log function and an upper bound can be
obtained by adding one machine epsilon to the value returned by the log function.
Use of Decimal Variables. Decimal variables impose a certain precision in
their representation and in the calculations involving them. If they are repre-
sented by ﬂoating-point variables IEEE754 rounding modes can be managed for
ensuring the safeness of some operations (in order to guarantee the completeness
of the model). Note that some programming languages, like Java, do not oﬀer
this possibility.
We will use the following notations:
Notation 1
• δ is the precision of a decimal variable, i.e. the number of decimal digits that
are taking in account (after the decimal separator).
• ϵ is the computational precision between decimal numbers.
2.2
Multi-valued Decision Diagram
The decision diagrams considered in this paper are reduced ordered multi-valued
decision diagrams (MDD) [1,6,8], which are a generalisation of binary decision
diagrams [2]. They use a ﬁxed variable ordering for canonical representation and

Dealing with the Product Constraint
269
shared sub-graphs for compression obtained by means of a reduction operation.
An MDD is a rooted directed acyclic graph (DAG) used to represent some multi-
valued functions f : {0...d −1}n →true, false. Given the n input variables, the
DAG contains n + 1 layers of nodes, such that each variable is represented at a
speciﬁc layer of the graph. Each node on a given layer has at most d outgoing arcs
to nodes in the next layer of the graph. Each arc is labeled by its corresponding
integer. The arc (u, a, v) is from node u to node v and labeled by a. Sometimes
it is convenient to say that v is a child of u. The set of outgoing arcs from node u
is denoted by ω+(u). All outgoing arcs of the layer n reach tt, the true terminal
node (the false terminal node is typically omitted). There is an equivalence
between f(a1, ..., an) = true and the existence of a path from the root node to
the tt whose arcs are labeled a1, ..., an.
The reduction of an MDD is an important operation that may reduce the
MDD size by an exponential factor. It consists in removing nodes that have
no successor and merging equivalent nodes, i.e., nodes having the same set of
neighbors associated with the same labels. This means that only nodes of the
same layer can be merged.
Construction of MDDs. The classical approach to build MDD(C), the MDD
of a constraint C, is to use states. When building MDD(C), we assign an infor-
mation representing the current state s(x) of the constraint C to each node x.
Given (u, a, v) an arc, s(u) the state of the node u and a transition function, we
are able to produce s(v) the state of the node v and to know if this state satisﬁes
the constraint C or not. If two diﬀerent nodes a and b have the same state (i.e.
s(a) = s(b)), they can be merged into one node ab with s(ab) = s(a) = s(b)
during the building process. As we try to build the MDD of a constraint we add
a validity function that anticipates the fact that a state cannot lead to at least
one solution. This function, noted isValid returns false if we can guarantee that
a state will never satisfy the constraint. This function is called before creating
a state. For a given layer i it computes the maximum value from the next layer
to tt denoted by vMax[i + 1].
In the case of the sum (resp. product) constraint, the state represents the
current sum (resp. product) of the current node. The creation of a new state is
given by function createState. The transition function is simply the addition
(resp. multiplication) between the current sum (resp. product) and the label,
therefore we will not explicit them.
3
Product Constraint as a Sum of Logarithms
There are two possible ways to build the MDD of the constraint depending
on the representation of the decimal/ﬂoating-point variable: either by ﬂoating-
point or by integers. In any case, a faithful log function has to be used and the
rounding errors of the sum have to be managed. In the ﬁrst case, the MDD of
the constraint is just the MDD of the sum constraint on ﬂoating-point variables.
The latter case deserves more attention.

270
S. Malalel et al.
Algorithm 1: Integer Logarithm Representation
createState(state, label) : State
newState ←createState()
newState.sum ←state.sum + label
return newState
isValid(C, state, label, layer) : Boolean
newSum ←state.sum + label
maxPotential ←newSum + vMax[layer + 1]
return maxPotential ≥C.min
signature(C, state, label, layer, size) : Integer
return ⌈(state.sum + label)/10δ−ϵ⌉
merge(C, state1, state2)
if state2.sum < state1.sum then state1.sum ←state2.sum
The logarithm is computed up to a certain precision λ, that is to say the
number of digits taken into account after the decimal point [3]. This value can
be diﬀerent than δ (the precision of decimal variables). It is therefore important
to take a precision value such that the integer representation of the sum does
not cause an overﬂow: n × 10λ+d ≤2b, with d the maximum number of digits
required to represent the integer value of the logarithm, n the number of variables
and b the number of bits used to represent the integer (32 for an int, 64 for a
long). We will denote this representation Integer Logarithm Representation.
Algorithm 1 gives a possible implementation of the required functions to build
the MDD of the product constraint, with vMax[i] = n
j=i max(Dj). Algorithm
1 also gives a possible implementation of the merging conditions. To perform
merges during the construction process, we introduce a signature function
that will behave as a hash: if two nodes have the same signature, then we merge
them according to the merge function. This allows us to keep a slightly more
precise sum variable, while still being able to merge nodes and save some space.
4
Exact Representation of the Product Constraint
This method aims to be as accurate as possible by representing the result of
consecutive multiplications without loss. First, the decimal variables are trans-
formed into integer variables. We choose a value for δ (i.e., the number of decimal
we want to take into account for representing the values of variables) and then
we turn decimals into their corresponding integers (for example with the deci-
mal 0.98 and δ = 4, we obtain 9800). Afterward, knowing w, the minimum value
of the product of variables, and n the number of variables in the scope of the
constraint, we calculate the minimal threshold min = ⌊w × 10(n×δ)⌋.
The state of a node contains the value prod which is the product of the labels
of the arcs from the root node to the current node. The prod value of the root
is 1. Algorithm 2 gives a possible implementation for the createState and
isValid functions. isValid is deﬁned using vMax[i] = n
j=i max(Dj).

Dealing with the Product Constraint
271
Algorithm 2: Exact Product Implementation
createState(state, label)
newState ←createState()
newState.prod ←state.prod × label
return newState
isValid(C, state, label, layer) : Boolean
newProd ←state.prod × label
maxPotential ←newProd × vMax[layer + 1]
return maxPotential ≥C.min
Unfortunately, the use of integers is limited when representing big numbers:
multiplying all the integers together can quickly cause an overﬂow. In order to
address this issue, a speciﬁc data structure that can represent really big numbers
must be used. Most programming languages oﬀer such data structures (e.g. Big-
Integer in Java). However, these data structures have two important drawbacks
that can prevent their use in practice: they quickly run out of memory during
the computation, and the computation of the multiplication takes more time as
the product value increases. It is therefore necessary to study a more relaxed
representation.
5
Relaxed Product Constraint
In order to decrease the memory consumption and the computation time, we
can deliberately lose accuracy during the computation by truncating and round-
ing the result correctly, depending on a given precision ϵ. Therefore, instead of
computing the exact MDD by performing basic multiplications, relaxed multi-
plications are performed, which will as a result compute a relaxed MDD. This
means that the MDD can either be complete, correct, or both (but both can-
not be guaranteed). We note this multiplication ×ϵ with ϵ the precision such
that ⌈x ×ϵ y⌉= ⌈(x × y)/10ϵ⌉and ⌊x ×ϵ y⌋= ⌊(x × y)/10ϵ⌋. For example
⌈9800 ×4 9780⌉= 9585. Similarly we note ϵ the product using ×ϵ. Note that
for the following part the rounding is done to guarantee only the completeness,
but it can also be done to guarantee only the correctness by doing a switch
between the ﬂoor rounding and the ceiling rounding. The MDD is built follow-
ing the same ﬁrst steps deﬁned for the Exact Product: we choose the precision
ϵ and turn ﬂoating-point numbers into their corresponding integers.
However, the minimal threshold is diﬀerent: it is now deﬁned as min =
⌊w × 10ϵ⌋. The way the value vMax[i] is calculated for each layer is modiﬁed to
take this change into account i, vMax[i] = ⌈ϵn
j=imax(Dj)⌉.
The state of a node x still holds the value prod, but it now represents the
consecutive relaxed multiplications between the labels of the arc from the node
root to the node x. We initialise the root value as 10ϵ, which is the equivalent of
1 in ϵ precision.
Algorithm 3 gives a possible implementation of the createState and
isValid functions.

272
S. Malalel et al.
Algorithm 3: Relaxed Product Implementation
createState(state, label) : State
newState ←createState()
newState.prod ←⌈state.prod ×ϵ label⌉
return newState
isValid(C, state, label, layer) : Boolean
newProd ←⌈state.prod ×ϵ label⌉
maxPotential ←⌈newProd ×ϵ vMax[layer + 1]⌉
if maxPotential < C.min then return false
return true
Even if this method cannot ensure both the completeness and the correctness
at the same time, it allows us to balance between performance and accuracy
of the solutions. Indeed the smaller ϵ is, the more equivalent states we have.
Therefore, we obtain more merges resulting in less computational resources to
build the MDD.
6
Incremental Precision Reﬁnement
In this section we present an Incremental Precision Reﬁnement of the set of
solutions (IPR). This method aims at computing the MDD of the constraint for
a precision ϵ by computing successive MDDs of the constraint having a lower
precision. Let MDDϵ be the MDD for the precision ϵ. The idea is to start by
building MDD1 and then build MDDk from MDDk−1. The advantage of this
approach is that it avoids creating intermediate states that are not in the ﬁnal
reduced MDD.
We can classify the solutions computed in a relaxed MDD in two categories,
the “sure solutions” and the “relaxed solutions”. The “sure solutions” are the solu-
tions that no matter the precision are valid. For instance (0.95...×0.95...) is greater
than 0.9 no matter the precision k > 2. The “relaxed solutions” are the solutions
for which a higher precision is required in order to determine if they are solutions.
For instance the fact that (0.94... × 0.95...) is greater than 0.9 is uncertain and
requires a higher precision (0.948 × 0.955 > 0.9 and 0.940 × 0.950 < 0.9).
This method is based on the fact that “sure solutions” in MDDk are solutions
in all the following iterations. Thus the method focuses only on the part of the
MDD containing “uncertain solutions” to improve the precision at a lower cost.
6.1
Extracting Suspicious Arcs
The ﬁrst step of the algorithm is to identify and extract arcs and nodes that
are part of at least one “relaxed solution”. In order to do so, we use the scheme
introduced in [4] to propagate the bounds of the product constraint to each node
of the MDD. In our case, the property associated with a node is the current
possible sum interval for the sum constraint and the current possible product
interval for the product constraint. A bottom-up propagation is performed

Dealing with the Product Constraint
273
Algorithm 4: Extraction
extraction(mdd, w) : MDD
mddM ←createMDD()
mdd.root.value ←0
mdd.root.x1 ←mddM.root
L[0] ←{mddM.root}
foreach i ∈0..r −1 do
foreach Node x ∈L[i] do
foreach label ∈ω+(x) do
y ←x.getChild(label)
v ←x.value + label
if y.property[0] + v < w then
x1 ←x.x1
y1 ←y.x1
if y1 is nil then
y1 ←createNode()
y.x1 ←y1
addNode(L, y1, i + 1)
addArc(x1, label, y1)
y.value ←min(y.value, v)
merge all nodes of L[r] into t
pReduce(L)
return mddM
(instead of the top-down propagation presented in the cited paper). Starting from
the tt node the propagation computes for each node the interval of the minimal
values, called property, needed to be part of a “sure solution”. After the bottom-
up propagation, a top-down propagation of properties is performed. Starting
from the root node, each outgoing arcs (source, v, destination) is checked. If the
value v of the arc combined with the property p of the destination is below
the threshold w, then we cannot be certain that this arc only leads to “sure
solutions”. This arc is thus added to the marked MDDM containing all arcs
and nodes marked “suspicious”. When such an arc is marked, the value of the
node destination is updated to the lowest value between its current value and
the value of source combined with the value of the arc v. At the end of the
algorithm, we obtain the MDDM containing all arcs and nodes appearing in at
least one “relaxed solution”.
The implementation of the algorithm is given Algorithm 4. The algorithm
takes as input an MDD mdd and the lower bound w.
Note that the algorithm only deals with a lower bound w, but can easily be
adapted to deal with an upper bound, or both a lower and upper bound.
Proposition 1. After executing Algorithm 4 MDDM contains all the “suspi-
cious” arcs and nodes.

274
S. Malalel et al.
Proof. Let the root node with property p < w. This means that at least one
“relaxed solution” pass by the root node, which means that at least one “relaxed
solution” pass by one of its children. Let pc be the value of the property of the
child c, and v be the value of the arc from c to root. If pc + v < w, it means
that at least one “relaxed solution” pass by the arc (root, v, c), because taking it
makes the property go below the threshold. Now, suppose that each node holds
the value of the lowest path from the root. Consider the arc (x, label, y) where
x has a value vx below the threshold w, and y has a property py. py + label + vx
correspond to the lowest possible path taking the arc (x, label, y). If this value is
below the threshold w, then it means that at least one “relaxed solution” pass
by this arc.
6.2
On the Fly Intersection
After extracting MDDM containing all “relaxed solutions”, we need to improve
the precision in order to only have solutions. To do so, we perform the intersection
between the MDD with higher precision and MDDM, but without computing
the entire constraint: we only need the parts in common with MDDM. In order
to do so, we perform the on the ﬂy intersection [5]. This allows us to compute
higher precision only for the parts of the MDD that need it, without wasting
time and memory to recompute a large amount of solutions.
6.3
IPR Algorithm
We give a possible implementation of the global algorithm (Algorithm 5) that
computes the MDD of the product constraint using the diﬀerent schemes pre-
sented in this section. The algorithm will stop once it reaches an equilibrium, or
when the maximum precision allowed is reached.
Algorithm 5: IPR Algorithm
IPR(w, ϵ, D) : MDD
mddc ←createMDD(0, w, D)
mddM ←extraction(mddc, w)
mddS ←mddc −mddM
foreach e in 1..ϵ do
mddc ←performIntersection(mddM, C, e)
mddM ←extraction(mddc, w)
if mddM is empty then return mddS
mddS ←mddS ∪(mddc −mddM)
return mddS ∪mddc
The ﬁrst step of the algorithm is to compute the initial MDDc (with lowest
precision). Once this MDD is created, we execute the extract function (Algorithm
4) and retrieve the associated MDDM. Then, we compute the diﬀerence between
the MDDc and MDDM, basically ﬁltering the initial MDD from all uncertain

Dealing with the Product Constraint
275
solutions. We store all good solutions in an accumulator MDDS. We then repeat
the same steps over MDDM: we intersect it with the MDD of the constraint C
with higher precision e (performIntersection), then extract, ﬁlter, and add
solutions to MDDS. The algorithm stops when MDDM is empty or when the
maximum precision allowed is reached.
Note that, even if very unlikely, it is possible that MDDc = MDDM. This
cannot be a stop criterion for the algorithm as it would still be possible that all
solutions of MDDc require a higher precision to decide if they belong to MDDS
or not.
7
Experiments
The algorithms presented in this paper have been implemented in Java 11. The
experiments were performed on a machine having four E7-4870 Intel processors,
each having 10 cores with 256 GB of memory and running under Scientiﬁc Linux.
All the experiments were run in sequential.
First we use ﬁxed data sets, then we study the impact of varying some param-
eters (number of variables, domain size, w value). The ﬁxed data sets, denoted
by data1... data10, involve 10 variables with a domain of size 10. Each value
represents a probability between 95% and 100% to ensure that there exist solu-
tions for the instances. Each resolution was made with our minimum threshold
w representing 90%. All the data used in this paper are available upon request.
7.1
Exact Product Method
Table 1. Time (ms) and Memory (MB) needed to compute the exact MDD using the
Exact Product method.
Data set #Solutions Time (ms) Memory (MB)
data1
341 051
7 403
2 268
data2
902 485
14 134
3 383
data3
1 819 820
24 629
6 508
data4
489 297
5 469
1 807
data5
104 506
2 373
879
data6
882 970
13 567
3 394
data7
4 049 230
98 740
14 072
data8
510 291
23 077
4 121
data9
5 473 625
389 801
25 273
data10
797 484
37 497
4 689
The Exact Product method behaves exactly as expected: we obtain the exact
MDD at a high cost both in term of memory consumption and time (Table 1).
This method is nonetheless interesting because it serves as a proof of the total
number of solutions, which will be helpful to compare the relative accuracy of
other methods (Table 2).

276
S. Malalel et al.
7.2
Logarithm and Relaxed Methods
Comparison of the Methods. Concerning the number of solutions produced
by the Logarithm method (both Integer and Library) and Relaxed Product
method, we notice an interesting phenomenon: the more we increase the precision
ϵ, the less we improve the lower bound and thus the accuracy of the solutions
at each iteration (Table 2). Even worse, the time needed to compute the MDD
does not scale at all with the number of solutions (Table 3). For instance, the
time needed to compute 5 473 669 solutions is about 13 s (Table 2 and Table 3)
for ϵ = 7, while the time needed to compute 5 473 625 solutions is about 103 s
for ϵ = 8. On this data, the computation time is 8 times slower when ϵ = 8
than when ϵ = 7 for a diﬀerence of 44 solutions. It means that the trade-oﬀ
between precision and computational resources is not worth it. It is nevertheless
complicated to determine the correct ϵ such that we do not spend too much
time on computation for a relatively good approximation of the exact MDD.
Furthermore, the “relaxed” solutions introduced by the relaxation are very close
to the deﬁned threshold w (as shown by the lower bounds in Table 2). However,
we notice that it is faster to build the MDD using the logarithm than using
the Exact Method; we obtain the exact MDD at ϵ = 8 for a time of 103 s
(compared to almost 400 s). This diﬀerence is explained by the heaviness of the
exact representation.
Table 2. Comparison of the number of solutions generated depending on the precision
ϵ for data9. Number of exact solutions: 5 473 625.
ϵ
Logarithm Lower Bound
Relaxed Product Lower Bound
1
9 800 000 000 ≈0.628
10 000 000 000 ≈0.628
2
261 007 356 ≈0.762
213 455 660 ≈0.821
3
9 193 737 ≈0.886
9 222 380 ≈0.891
4
5 731 323 ≈0.899
5 770 914 ≈0.8992
5
5 493 720 ≈0.8999
5 498 953 ≈0.8999
6
5 474 681 ≈0.89999
5 476 117 ≈0.89999
7
5 473 669 ≈0.899999
5 473 844 ≈0.899999
8
5 473 625 ≈0.90
5 473 649 ≈0.8999999
9
5 473 625 ≈0.90
5 473 627 ≈0.89999999
Table 3 also shows that the method using a sum of logarithm based on a log
function call from a library and using ﬂoats (Library Log), the method using a
log sum represented as an integer and whose precision is controlled (Integer Log)
and the method of relaxing the MDD of the exact product of variables constraint
(RelaxProd) give very close results as soon as one chooses a computational preci-
sion higher than 4 decimals. However, the IntegerLog method seems to be faster
and to consume a little less memory than the other two methods.

Dealing with the Product Constraint
277
Table 3. Time (ms) and memory (MB) needed to compute the MDD of data9 for a
given ϵ depending on the representation used.
Time (ms)
Memory (MB)
ϵ
Library Log Integer Log RelaxProd
Library Log Integer Log RelaxProd
1
49
49
46
4
3
3
2
60
56
68
4
4
4
3
92
78
109
6
4
7
4
197
174
240
19
17
31
5
566
509
801
110
106
166
6
2 752
2 546
4 558
609
598
830
7
13 604
13 165
25 848
2 556
2 377
2 915
8
103 460
102 079
181 015
6 852
6 756
7 251
9
324 239
313 094
337 803
9 929
9 838
7 854
7.3
Incremental Precision Reﬁnement (IPR)
Tables 4 and 5 clearly show the advantages of the IPR routine. IPR L is the
application of the IPR routine to the Library Log model, IPR IL is the applica-
tion of the IPR routine to the Integer Log model and IPR RP is the application
of the IPR routine to the RelaxProd model.
Table 4. Time (ms) and Memory (MB) comparison between the Exact Product
method, the Library Log method with ϵ = 9 and the methods with the IPR routine in
order to compute the exact MDD.
Time (ms)
Memory (MB)
Data set Lib Log IPR L IPR IL IPR RP Exact Prod
Lib Log IPR L IPR IL IPR RP Exact Prod
data1
5 708
872
904
1 145
7 403
808
113
113
173
2 268
data2
12 067 1 075
1 095
1 628
14 134
1 496
154
153
229
3 383
data3
23 069
1 883
1 869
2 420
24 629
2 062
258
257
397
6 508
data4
4 629
859
858
1 127
5 469
811
109
105
173
1 807
data5
1 930
616
609
825
2 373
378
65
65
105
879
data6
10 359
980
1 018
1 424
13 567
1 494
142
137
221
3 394
data7
81 257 2 357
2 526
2 945
98 740
5 775
345
345
495
14 072
data8
21 990
954
974
1 343
23 077
1 642
133
129
205
4 121
data9
324 239 2 962
3 085
3 715
389 801
9 929
438
437
619
25 273
data10
31 717 1 182
1 200
1 614
37 497
1 552
154
153
250
4 689
The IPR routine improves the computation up to a factor 131 in time and 60
in memory (data9 in Table 4). Furthermore, contrary to the direct computation
of the MDD at a given precision ϵ, it is possible to guarantee the exactitude
of the MDD if the IPR routine stopped before reaching the maximum allowed
precision. Moreover, we can see that the diﬀerences between all IPR methods

278
S. Malalel et al.
and the exact method or the Library Logarithm method are in the same order
of magnitude. This shows that the IPR routine is generalisable to any form of
relaxed representation.
Table 5. Time (ms) and Memory (MB) comparison between the diﬀerent methods
depending on the variations of the parameters, with n the number of variables, |D| the
size of each domain and w the threshold. The ﬁrst line corresponds to data10 in other
benchmarks. MO = 30 GB. All solving methods have the same number of solutions.
Parameters
Time (ms)
Memory (MB)
n |D|
w
IPR L IPR IL IPR RP Exact
IPR L IPR IL IPR RP Exact
10 10
0.77
80 932 74 697
91 505
-
7 996
8 640
11 357
MO
10 15
0.65
8 779
9 091
9 186
-
1 262
1 267
1 351
MO
10 15
0.90
9 090
8 857
13 773
-
1 421
1 420
1 893
MO
15 10
0.85
248 596 256 005 276 118
- 24 672 24 557
24 572
MO
15 10
0.90
1 615
1 684
2 222 49 986
217
218
277 7 176
15 15
0.92
12 139 11 329
16 273
-
1 647
1 643
2 136
MO
15 15
0.90
178 285 185 549 205 604
- 20 050 20 046
22 914
MO
20
5
0.9
32 363
32 598
44 197
-
4 270
4 263
5 108
MO
Variations of Data Set Parameters. Table 5 shows the behaviour of the
building process depending on the diﬀerent parameters such as the number of
variables n, the size of the domains |D| or the threshold w. The results seem
to show that, the more we increase n and |D|, the more diﬃcult the problem is
to resolve, which is an expected result. The Exact Product method is only able
to close one instance, which is the easiest one (n = 15, |D| = 10, w = 0.90).
Nonetheless, the results are conﬁrming yet again that the IPR method dominates
the classical building approach. When comparing the eﬃciency of the methods,
we ﬁnd the same results as in Table 3: the logarithm approach is better than
the relaxed product in terms of time and memory. Even though very close,
the Library Logarithm (L) seems to be better at solving these instances than
the Integer Logarithm (IL). However, the variation of the eﬀect of w seems
interesting: for some instances, lowering it makes the problem more diﬃcult (1
615ms for n = 10 |D| = 15 w = 0.90 compared to 248 596 for w = 0.85) while it
makes it easier for others (n = 10, |D| = 15).
When focusing particularly on the variation of w, we in fact observe a bell-
shaped curve evolution for the time and memory (Figs. 1 and 2). The top of
the curve seems to be achieved for the value w such that it cuts the set of all
possible combinations in half (Table 3). For instance, the ﬁrst line (n = 10, |D| =
10, w = 0.77) of Table 5 is very close to the top of the curve (Fig. 1), resulting in
a factor 60 in time when comparing with w = 0.90 for the same data set (data10
in Table 4).

Dealing with the Product Constraint
279
Fig. 1. Evolution of the time (ms) needed to compute the MDD for data1 depending
on the parameter w.
Fig. 2. Evolution of the memory (MB) needed to compute the MDD for data1 depend-
ing on the parameter w
Fig. 3. Evolution of the number of solutions for data1 depending on the parameter w.

280
S. Malalel et al.
8
Conclusion
In this paper we studied several methods for deﬁning the MDD of the product
constraint of decimal variables. The ﬁrst and most popular one is based on the
sum of the logarithm (using either ﬂoating point or integer numbers) with a
given precision. The second one computes the exact MDD of the product of
variables. The last one relaxes the previous MDD up to a certain precision.
We showed that an exact representation is not that expensive in terms of
computational resources. More importantly we showed that models based on a
precision can be accurate when using at least 5 decimals.
We also presented an incremental precision reﬁnement method that eﬃciently
computes an MDD for a given precision. It relies on the fact that if a solution
is correct (a solution of the constraint) at a given precision it is also a correct
solution at a higher precision. Thus this method only reﬁnes the precision on
the uncertain parts of the MDD. In addition, when this method stops before
reaching the ﬁxed precision, it guarantees that the resulting MDD is exact. We
showed that this method is very eﬃcient both in terms of computational time
and memory consumption no matter the method used to compute the logarithm.
In a future work it would be interesting to see if the obtained results on the
logarithm are still the same when values are represented as interval of proba-
bilities. Another very interesting development would be to study what are the
necessary conditions for the use of the incremental precision reﬁnement method,
and what kind of constraints meet them.
Acknowledgments. This work has been supported by the French government,
through the 3IA Cˆote d’Azur Investments in the Future project managed by the
National Research Agency (ANR) with the reference number ANR-19-P3IA-0002.
References
1. Bergman, D., Cir´e, A.A., van Hoeve, W., Hooker, J.N.: Decision Diagrams for Opti-
mization. Artiﬁcial Intelligence: Foundations, Theory, and Algorithms, Springer,
Heidelberg (2016). https://doi.org/10.1007/978-3-319-42849-9
2. Bryant, R.E.: Graph-based algorithms for boolean function manipulation. IEEE
Trans. Comput. 35(8), 677–691 (1986). https://doi.org/10.1109/TC.1986.1676819
3. Goldberg, M.: Computing logarithms digit-by-digit. Int. J. Math. Educ. Sci. Tech-
nol. 37(1), 109–114 (2006)
4. Jung, V., R´egin, J.-C.: Checking constraint satisfaction. In: Stuckey, P.J. (ed.)
CPAIOR 2021. LNCS, vol. 12735, pp. 332–347. Springer, Cham (2021). https://
doi.org/10.1007/978-3-030-78230-6 21
5. Jung, V., R´egin, J.C.: Eﬃcient operations between mdds and constraints. Techni-
cal report, Submitted to the International Conference on Integration of Constraint
Programming, Artiﬁcial Intelligence, and Operations Research (2022)
6. Kam,
T.,
Brayton,
R.K.:
Multi-valued
decision
diagrams.
Technical
report
UCB/ERL M90/125, EECS Department, University of California, Berkeley (1990).
http://www2.eecs.berkeley.edu/Pubs/TechRpts/1990/1671.html

Dealing with the Product Constraint
281
7. Muller, J.M.: Elementary Functions, Algorithms and Implementation, 2nd edn.
Birkh¨auser (2006)
8. Srinivasan, A., Ham, T., Malik, S., Brayton, R.K.: Algorithms for discrete function
manipulation. In: 1990 IEEE International Conference on Computer-Aided Design.
Digest of Technical Papers, pp. 92–95 (1990). https://doi.org/10.1109/ICCAD.1990.
129849

Multiple-choice Knapsack Constraint
in Graphical Models
Pierre Montalbano1
, Simon de Givry1(B)
, and George Katsirelos2
1 Universit´e F´ed´erale de Toulouse, ANITI, INRAE, UR 875, 31326 Toulouse, France
{pierre.montalbano,simon.de-givry}@inrae.fr
2 Universit´e F´ed´erale de Toulouse, ANITI, INRAE, MIA Paris, AgroParisTech,
75231 Paris, France
gkatsi@gmail.com
Abstract. Graphical models, such as cost function networks (CFNs),
can compactly express large decomposable functions, which leads to eﬃ-
cient inference algorithms. Most methods for computing lower bounds
in Branch-and-Bound minimization compute feasible dual solutions of a
speciﬁc linear relaxation. These methods are more eﬀective than solving
the linear relaxation exactly, with better worst-case time complexity and
better performance in practice. However, these algorithms are specialized
to the structure of the linear relaxation of a CFN and cannot, for exam-
ple, deal with constraints that cannot be expressed in extension, such as
linear constraints of large arity.
In this work, we show how to extend soft local consistencies, a set of
approximate inference techniques for CFNs, so that they handle linear
constraints, as well as combinations of linear constraints with at-most-
one constraints. We embedded the resulting algorithm in toulbar2, an
exact Branch-and-Bound solver for CFNs which has demonstrated supe-
rior results in several graphical model competitions and is state-of-the-
art for solving large computational protein design (CPD) problems. We
signiﬁcantly improved performance of the solver in CPD with diversity
guarantees. It also compared favorably with integer linear programming
solvers on knapsack problems with conﬂict graphs.
Keywords: graphical model · cost function network · knapsack
problem
1
Introduction
A Graphical Model (GM) may express an arbitrary complex function on several
variables as a combination of smaller local functions on subsets of the variables.
GMs have been used to reason about logic and probabilities. A deterministic GM
can represent a Constraint Satisfaction Problem (CSP) where each local function
This research was funded by the French “Agence Nationale de la Recherche” through
grants ANR-18-EURE-0021 and ANR-19-P3IA-0004.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 282–299, 2022.
https://doi.org/10.1007/978-3-031-08011-1_19

Multiple-choice Knapsack Constraint in Graphical Models
283
is a constraint evaluating to true (satisﬁed) or false (unsatisﬁed) and the com-
bination operator is Boolean conjunction. It can also represent a Cost Function
Network (CFN), where each function evaluates to a cost and the combination
operator is addition [14]. A probabilistic GM represents a probability distribution
on random variables. Local functions may correspond to conditional probability
distributions as in Bayesian Networks (BN) or potentials as in Markov Ran-
dom Fields (MRF) [28]. They are combined by multiplication. In the following,
we focus on CFNs. It can be shown that ﬁnding the Maximum A Posteriori
assignment on MRFs (MAP/MRF) or the Most Probable Explanation on BNs
(MPE/BN) can be cast as ﬁnding a solution of minimum cost in an appropriate
CFN [13]. By allowing inﬁnite costs to represent infeasibility, CFNs can be seen
as a strict generalization of CSPs.
Exact methods to solve GMs/CFNs mostly rely on Branch-and-Bound
(B&B) algorithms [20,36]. These methods have proved useful in many GM appli-
cations, such as resource allocation [10], image analysis [23], or computational
biology [1,4]. For those, it has been shown to outperform other approaches,
including Integer Linear Programming (ILP), MaxSAT and Constraint Program-
ming (CP) [25].
CFNs have no native way to express linear constraints. This is in large part
due to the algorithms used to compute lower bounds in B&B, which require that
all constraints be expressed in extension. In many cases, having the ability to
add such constraints would signiﬁcantly improve the usefulness of CFNs. For
example, when searching for diverse solutions, the Hamming distance constraint
is naturally expressed as a linear constraint. There are ways to work around this
[39,40] but, as we show later, they come with a non-trivial performance penalty.
The lack of linear constraints is even more severe when the constraints have
large coeﬃcients, as in the knapsack problem with a conﬂict graph (KPCG).
In this case, there is no workaround for the lack of linear constraints and CFN
technology cannot be applied.
Contributions. Here, we show how to extend soft local consistency algorithms,
a set of approximate inference techniques for CFNs, to deal with Pseudo-Boolean
linear constraints (PB constraints for short), i.e., linear constraints over 0/1 vari-
ables. In the presence of unary cost functions (a cost function coupling a cost
to each value), these correspond to knapsack constraints. We additionally con-
sider the combination of PB constraints with Exactly-One (EO) or At-Most-One
(AMO) constraints, which correspond to multiple-choice knapsack constraints
[37], allowing ﬁnite-domain variables.
This new ability enables more modeling options for GM/CFN users, which
we demonstrate by applying it to generating diverse solutions for Computational
Protein Design (CPD). Here, the objective function has quadratic and linear
terms that can be decomposed in a sum of binary cost functions on pairs of
variables (the quadratic terms) and unary cost functions on single variables
(linear terms). Searching for diverse solutions introduces linear constraints in
the model (see Sect. 5.1). Our approach also compared favorably with a state-
of-the-art ILP solver on knapsack problems with conﬂict graphs.

284
P. Montalbano et al.
2
Related Work
Problems deﬁned by PB constraints are a generalization of the SAT problem.
Solvers for PB SAT typically use SAT-inspired constraint learning techniques,
either by direct translation to Conjunctive Normal Form (CNF) [41] or by gen-
eralizing the clause learning mechanism to PB constraints [19]. These solvers
typically do not compute lower bounds during search and have to rely on con-
ﬂict reasoning only to prove bounds. A notable exception is RoundingSAT [26],
which uses a Linear Programming (LP) solver to compute bounds during search
and learn constraints from bound violations, but limits the number of iterations
given to the LP solver in order to keep the runtime overhead of the solver reason-
able. This is in contrast to our approach, which uses a suboptimal LP solver, but
places no resource bounds on it. Also, PB solvers are usually restricted to a lin-
ear objective, whereas our approach can combine PB constraints with non-linear
quadratic (or more) cost functions. PB solvers can also exploit the presence of
AMO or EO constraints to strengthen propagation of PB constraints [5,7].
ILP solvers are well suited to solve CFNs, given the local polytope. Their LP
solving is not limited to a speciﬁc form of LP, like soft local consistency algo-
rithms such as Existential Directional Arc Consistency (EDAC) [21] and Virtual
AC (VAC) [12] are, therefore they have no issue reasoning with other linear con-
straints, as well as combinations with AMO/EO constraints. However, previous
evaluations [25] showed that the size of the linear program that speciﬁes that
local polytope is often too large even for such highly optimized implementations
and therefore they perform worse than a dedicated CFN solver in such problems.
On the CFN side, there has been work on clique constraints [22], a special case
of PB constraints. Dlask and Werner [16,17] have shown how to handle arbitrary
LPs using BCA algorithms, based on a generalization of VAC. However, despite
recent advances [49], BCA algorithms remain too costly for use at every node of
a B&B. Many (soft) global constraints can be described by a set of (soft) linear
constraints, but require an LP solver [34]. In addition, maintaining (weak) EDAC
and the coupling with the other local cost functions can be costly in practice.
This was also the case for other soft global constraints exploiting ﬂow-based
or dynamic programming algorithms [33,35]. In our approach, we propose a
simple and eﬀective soft local consistency called Full ∅-Inverse Consistency for
PB constraints. Finally, we can decompose linear constraints using cost functions
of arity 3 and intermediate variables [3], similar to CNF encodings used by PB
solvers. However, the size of the domains of the intermediate variables increases
linearly with the value of the coeﬃcients of the PB constraints.
3
Preliminaries
Deﬁnition 1. A Cost Function Network (CFN) P is a tuple (X, D, C, ⊤)
where X is a set of variables, with ﬁnite domain D(x) for x ∈X. C is a
set of constraints. Each constraint c ∈C is deﬁned over a subset of variables
called its scope (scope(c) ⊆X). ⊤is a maximum cost indicating a forbidden
assignment.

Multiple-choice Knapsack Constraint in Graphical Models
285
The size of the scope of a constraint is its arity. Unary (resp. binary) cost
functions have arity 1 (resp. 2). A partial assignment τ is an assignment of all
the variables xi in its scope (scope(τ)) to a value of its domain D(xi). The set
of all the partial assignments on a scope S is denoted τ(S). A constraint over a
scope S is denoted cS. The cost of a partial assignment τ for a constraint cS is
denoted cS(τ) with S ⊆scope(τ). Without loss of generality, we assume all costs
are positive integers, bounded by ⊤, a special constant signifying infeasibility.
Hence if cS(τ) = ⊤then the assignment τ is not a feasible solution. A constraint
cS is hard if for all τ ∈τ(S), cS(τ) ∈{0, ⊤}, otherwise it is soft. A CFN P that
contains only hard constraints is a constraint network (CN). In the following, we
use the term cost function interchangeably with the term constraint. An assign-
ment τ with scope(τ) = X is a complete assignment. The cost of a complete
assignment τ is given by cP (τ) = 
cS ∈C cS(τ). The Weighted Constraint Sat-
isfaction Problem (WCSP) asks, given a CFN P, to ﬁnd a complete assignment
minimizing cP (τ). This task is NP-hard [14]. When the underlying CFN is a CN,
the problem is the CSP, which we call crisp CSP here. In the following, we use
WCSP to refer both to the optimization task and the underlying CFN.
In this paper, we assume there exists exactly one unary constraint for each
variable and we say that the unary cost of xi = v for some v ∈D(xi) is ci(v). We
also assume the existence of a constraint c∅with empty scope, which represents
a constant in the objective function and, since there exist no negative costs, it
is a lower bound on the cost of all possible assignments.
Exact methods to solve GMs/CFNs mostly rely on Branch-and-Bound
(B&B) algorithms [20,36]. At every node of the B&B tree, the solver com-
putes a bound and closes the node if that bound is higher than the cost of the
incumbent solution or if it represents infeasibility. Typical bounding algorithms
compute either static memory-intensive bounds [15] or memory-light ones [12]
better suited to dynamic variable orderings. The latter, on which we focus here,
are called Soft Arc Consistencies (SAC) because they reason on each non-unary
cost function one by one, in a generalization of propagation in CSP.
Soft arc consistencies use c∅as the lower bound and compute a reparame-
terization of the instance with a higher c∅. A reparameterization P ′ of a WCSP
P is a WCSP with an identical structure, i.e., one where there exist constraints
over the same scopes, the costs assigned by each individual cost function may
diﬀer, but cP (τ) = cP ′(τ) for all complete assignments τ.
Procedure MoveCost(cS1, cS2, τ1, α): Move α units of cost between the
tuple τ1 of scope S1 and tuples τ2 that extend τ1 in scope S2
Data: Scopes S1 ⊂S2
Data: τ1 ∈τ(S1)
Data: cost α to move
1 cS 1(τ1) ←cS 1(τ1) + α
2 foreach τ2 ∈τ(S2) | τ2[S1] = τ1 do
3
cS 2(τ2) ←cS 2(τ2) −α

286
P. Montalbano et al.
All reparameterizations that we study here are computed as a sequence of
local Equivalence Preserving Transformations (EPTs). Let S1 ⊂S2 be two
scopes with corresponding cost functions cS1 and cS2. Procedure MoveCost
describes how a cost α moves between the corresponding cost functions. To
see its correctness, observe if τ1 is used in a complete assignment, then exactly
one extension of τ1 to S2 will be used. Therefore, the sum of cS1 and cS2
remains unaﬀected whether the cost α is attributed to τ1 in cS1 or to all of
its extensions τ2 in cS2. As an example, it is clear that adding a cost α on
cx(a) and subtracting a cost α on c{x,y}({x = a, y = b}) for all b ∈D(y)
preserves problem equivalence. Indeed, paying α when we assign x = a (cost
function cx(a) = α) or when we assign x = a and y = b (∀b ∈D(y)) (cost
function c{x,y}({x = a, y = b}) = α, ∀b ∈D(y)) is equivalent. As a mat-
ter of terminology, when α > 0, cost moves from the larger arity cost func-
tion cS2 to the smaller arity cS1 and the move is called a projection, denoted
project(cS1, cS2, τ1, α). When α < 0, cost moves to the larger arity cost function
cS2 and the move is called an extension, denoted extend(cS1, τ1, cS2, −α), equiv-
alent to MoveCost(cS1, cS2, τ1, α). When S1 = ∅and |S2| = 1, with S2 = {xi},
the move is called a unary projection, denoted unaryProject(ci, α), equivalent
to MoveCost(c∅, ci, ∅, α). We never perform extensions from c∅, so it monoton-
ically increases during the run of an algorithm and as we descend a branch of
the search tree.
Finding which cost moves lead to an optimal reparameterization, which
means one that derives the optimal increase in the lower bound, is not obvi-
ous. It has been shown that any reparameterization can be derived by a set of
local cost moves [29] and that the optimal reparameterization (with α rational) –
and, equivalently, the optimal set of cost moves – can be found from the optimal
dual solution of the following linear relaxation of the WCSP [12], whose feasible
region is called the local polytope:
min

cS ∈C ,τ∈τ(S )
cS (τ) × yτ
s.t.
yτ1 =

τ2∈τ(S 2),τ2[S 1]=τ1
yτ2
∀cS 1, cS 2 ∈C , S1 ⊂S2,
τ1 ∈τ(S1), |S1| ≥1

τ∈τ(S )
yτ = 1
∀cS ∈C , |S| ≥1
However, solving this LP to optimality is often prohibitively expensive
because the worst-case complexity of an exact LP algorithm is O(N 2.5) [50], with
N ∈O(ed+nd) for binary WCSPs, where e is the number of distinct binary cost
functions, n is the number of WCSP variables and d is the maximum domain size.
The poor asymptotic complexity matches empirical observation [25]. Moreover,
the particular structure of this LP does not allow for a more eﬃcient solving
algorithm, as it has been shown that solving LPs of this form is as hard as solv-
ing any LPs [38]. Instead, work has focused on producing good but potentially

Multiple-choice Knapsack Constraint in Graphical Models
287
suboptimal feasible dual solutions. Various algorithms have been proposed for
this, going all the way back to Schlesinger [44], who ﬁrst expressed the prob-
lem as linear optimization and gave a speciﬁc algorithm for optimizing the dual.
Since Schlesinger, a long line of algorithms has been pursued both in areas like
image analysis [29,30,45–47,51], where Block-Coordinate Ascent (BCA) algo-
rithms were developed, and constraint programming [12,21,31,43,53], where
they are called soft local consistencies. Notably, the strongest algorithms from
both lines of research, such as TRWS [29] and VAC [12] converge on ﬁxpoints
with the same properties.
We do not describe all the existing local consistency algorithms but we need
the following consistency properties:
Deﬁnition 2. A WCSP P is Node Consistent (NC) [31] if for every variable
xi ∈X there exists a value v ∈D(xi) such that ci(v) = 0 and for every value
v′ ∈D(xi), c∅+ ci(v′) < ⊤.
In the following, we assume that a WCSP is NC before our propagator runs.
Deﬁnition 3. A WCSP P is ∅-Inverse Consistent (∅IC) [53] if for every cost
function cS ∈C there exists a tuple τ ∈τ(S) such that cS(τ) = 0.
Deﬁnition 4. A WCSP P is Existential Arc Consistent (EAC) [21] if it is NC
and for every xi ∈X there exists a value v ∈D(xi) such that ci(v) = 0 and
for every cost function cS ∈C, xi ∈S, |S| > 1, there exists a tuple τ ∈τ(S)
verifying τ[xi] = {v} (i.e., xi = v in τ) and cS(τ) + 
xj∈S cj(τ[xj]) = 0. Value
v is called an EAC support.
This last deﬁnition applies only to binary cost function networks.1 A weaker
notion of EAC has been deﬁned on global cost functions in order to avoid cost
oscillation [33]. Given a variable xi, it relies on a partition of the unary cost
functions cj(τ[xj]), xj ∈X such that each part is associated to some non-unary
cost function cS related to xi (xi ∈S).
We follow another weakening approach related to ∅IC. We strengthen the
previous deﬁnition to take into account unary costs as in EAC.
Deﬁnition 5. A WCSP is Full ∅-Inverse Consistent (F∅IC) if for every cost
function cS ∈C there exists τ ∈τ(S) such that cS(τ) + 
xj∈S cj(τ[xj]) = 0.
Compared to existing notions of consistency, F∅IC is weaker than T-DAC [2].
It is also weaker than EAC on binary cost function networks, but it is incompa-
rable with weak EAC [33] on non-binary networks.
Example 1. Consider two variables x, y with D(x) = D(y) = {a, b, c} and three
cost functions cx, cy, c{x,y} such that the only non-zero costs are cx(a) = cy(a) =
1, c{x,y}({x = b, y = b}) = c{x,y}({x = b, y = c}) = c{x,y}({x = c, y = b}) = 1,
and c{x,y}({x = c, y = c}) = 2.
1 An extension to ternary cost functions has been proposed [42] but it requires man-
aging all scope intersections and not only unary cost functions.

288
P. Montalbano et al.
Let ∀u ∈D(x), αu = minv∈D(y)(c{x,y}({x = u, y = v}) + cy(v)) and ∀v ∈
D(y), βv = maxu∈D(x)(αu−c{x,y}({x = u, y = v})). We apply project(cx, c{x,y},
{x = u}, αu) for each value u ∈D(x) and extend(cy, {y = v}, c{x,y}, βv) for each
value v ∈D(y). These cost moves will result in adding a cost βv −αu to every
tuple in c{x,y}. We have αa = 0, αb = αc = 1 and βa = 1, βb = βc = 0. All
the costs remain positive (proof in [32]). The reparameterized cost functions are
cx(a) = cx(b) = cx(c) = 1, c{x,y}({x = a, y = a}) = c{x,y}({x = c, y = c}) = 1,
the rest being equal to 0. We can now increase c∅by 1 using unaryProject(cx, 1).
The resulting WCSP is EAC.
For each of the consistencies we deﬁned above, there exist corresponding
algorithms that compute parametrization that satisfy them in polynomial-time2.
Given the connection to linear programming, these reparameterizations map to
feasible dual solutions of the local polytope. However, these algorithms rely on
all constraints being expressed in extension, meaning that for all constraints the
cost of every partial assignment must be explicitly written. This is not the case
for many constraints that are typically used in modeling in CP, namely global
constraints, i.e., those whose deﬁnition does not imply a ﬁxed arity. In order to
enforce these soft local consistencies in instances that contain global constraints,
we need to deﬁne bespoke algorithms. In contrast with crisp CSPs, these algo-
rithms must do more than prune values that appear in no feasible solution.
They must compute a reparameterization such that the constraint satisﬁes the
appropriate consistency, F∅IC here.
Here, we deal with pseudo-Boolean (PB) linear constraints and their general-
izations. These are constraints of the form 
xi∈S wixi△C, where S is a scope, all
xi ∈S are Boolean variables, wi and C are constants and △∈{<, ≤, ̸=, ≥, >}.
A PB constraint is normalized if wi, C ≥0 and △is ≥. Any PB constraint
can be written as a combination of normalized PB constraints. It is possible to
detect in linear time whether this constraint is satisﬁable in a crisp CSP, by
testing if 
xi∈S max(0, wi) ≥C. It is also possible to detect values that appear
in no solutions by computing all partial sums of |S| −1 variables, in linear time.
A PB constraint is an at-most-one (AMO) constraint if it has the form

xi∈S xi ≤1, normalized as 
xi∈S −xi ≥−1. It is an exactly-one (EO) con-
straint if it has the form 
xi∈S xi = 1.
4
Pseudo-Boolean Constraints in CFNs
The speciﬁc constraint we consider here is a pseudo-Boolean constraint

xi∈S wixi ≥C along with a partition of its variables into sets A1, . . . , Ak such
that there exists an EO constraint among the variables of each partition Ai.
Reformulations.
This formulation allows us to express PB constraints
over multi-valued variables. Let S be a scope over a set of WCSP vari-
ables with arbitrary domains, and wiv weights for each value. The constraint
2 E.g., EDAC [21], an extension of EAC property, is maintained in O(ed2 max(nd, ⊤))
for a WCSP with n variables, maximum domain size d, and e binary cost functions.

Multiple-choice Knapsack Constraint in Graphical Models
289

xi∈S,v∈D(xi) wivxiv ≥C, where xiv is the 0/1 variable which takes the value 1
if xi = v, matches the pattern described above, with partitions Ai = {xiv | v ∈
D(Xi)}.
Finally, this formulation admits the case where there exists an AMO con-
straint over some partitions: we add another 0/1 variable in each such partition
and give it weight 0, so that this partition now has an EO constraint.
Constraint Representation. We will focus here on F∅IC as the soft consis-
tency we aim to enforce. But ﬁrst, we need an appropriate encoding that can
represent the state of the constraint after a series of cost moves to and from
unary cost functions, without storing a cost for each of the exponentially (in the
arity of the constraint) many tuples. Observe ﬁrst that the cost of any given
tuple starts out at 0 for allowed tuples and ⊤for tuples that violate the con-
straint. After some cost moves, the cost of each tuple is the sum of costs that
have been moved to or from the values it contains. Therefore, it can be expressed
as a linear function. Let δiv be the total cost that has been moved between the
constraint and the corresponding unary cost and δ∅the cost we have moved from
this constraint to c∅. Therefore, initially δ∅= 0 and δiv = 0 for all i, v. We use
the following integer program as the representation of the constraint.
min 
xi∈S,v∈D(xi) δivxiv −δ∅
(1)
s.t. 
xi∈S,v∈D(xi) wivxiv ≥C
(2)

v∈D(xi) xiv = 1,
∀xi ∈S
(3)
xiv ∈{0, 1},
∀xi ∈S, v ∈D(xi)
(4)
We call this ILP∅. The main property of ILP∅is that the cost of any feasible
complete assignment is equal to the cost of the corresponding tuple in cS after
any sequence of cost moves. Hence, opt(ILP∅) > 0, if and only if cS is not ∅IC,
and we can move some cost to c∅: project(c∅, cS, ∅, opt(ILP∅)).
However, for the purposes of detecting violations of F∅IC, it is not enough to
look at the cost of tuples of the constraint, as we must also take unary costs into
account. Therefore, while ILP∅remains the representation of the constraint, the
propagator considers the problem with the modiﬁed objective
min

xi∈S,v∈D(xi)
(δiv + ci(v))xiv −δ∅
(5)
Let this problem be ILPF ∅. cS is F∅IC if and only if opt(ILPF ∅) = 0. In the
following, we write piv = δiv + ci(v) for compactness, when it does not matter
how much of the coeﬃcient came from δiv and how much came from ci(v). In
contrast with ILP∅, if opt(ILPF ∅) > opt(ILP∅), we cannot move opt(ILPF ∅)
units of cost to c∅. Instead, we ﬁrst have to move some cost from unary cost

290
P. Montalbano et al.
functions into the constraint before we can project it to c∅. In this case, the
composition of piv from δiv and ci(v) is signiﬁcant.
Unfortunately, ILP∅and ILPF ∅have the knapsack problem as a special case,
hence it is NP-hard to determine whether a PB constraint is ∅IC or F∅IC.
Therefore, we detect only a subset of cases where the constraint is not F∅IC by
relaxing the integrality constraint (4) into 0 ≤xiv ≤1 and solving the resulting
linear programs, called LP∅and LPF ∅, respectively. This forgoes the guarantee
that opt(LPF ∅) = 0 if and only if the constraint is F∅IC, and satisﬁes only the
’only if’ part. More simply, if opt(LPF ∅) > 0 then the constraint is not F∅IC,
and similarly for LP∅and ∅IC.
LPF ∅has a special structure. It is a Multiple-Choice Knapsack Problem
(MCKP) [37], or a knapsack problem with special ordered sets [27]. These can be
solved more eﬃciently than arbitrary LPs, a fact that we use in our propagator.
4.1
Solving the Knapsack LP
We obtain an optimal solution x∗of the primal LPF ∅by applying Pisinger’s
greedy algorithm [37]. This gives a x∗in time O(N log N)3, with N = |x∗|, such
that either x∗has no fractional value or it has exactly two fractional values. In
the latter case, the WCSP variable xk ∈S, verifying ∃s, s′ ∈D(xk) such that
0 < x∗
ks, x∗
ks′ < 1, is called a split class and xks, xks′ are the split variables. We
denote by o = 
xi∈S,v∈D(xi) pivx∗
iv −δ∅, the optimal solution cost of LPF ∅.
Consider now the dual of LPF ∅:
max C × ycc + 
xi∈S yi
(6)
s.t.
ycc × wiv + yi ≤piv ∀xi ∈S, v ∈D(xi)
ycc ≥0
where ycc is the dual variable corresponding to the capacity constraint and yi
corresponds to the EO constraint of xi. From the optimal primal solution, it is
easy to compute the optimal dual solution. Let xk be the split class, xks, xks′
the split variables and for i ̸= k, deﬁne the variable xis as the variable used in
the optimal solution, i.e., x∗
is = 1.
ycc = pks −pks′
wks −wks′
yk = pks −ycc × wks = pks′ −ycc × wks′
yi = pis −ycc × wis ∀xi ∈S\{xk}
From the dual solution y, we compute the reduced cost rcy(xiv) of every
variable xiv, i.e., the slack of the dual constraint that corresponds to x. When
context makes it clear, we omit y and write rc(xiv).
3 The Dyer-Zemel algorithm [18,52] can compute a solution in O(N) time, but we have
not yet implemented it.

Multiple-choice Knapsack Constraint in Graphical Models
291
The reduced cost of a variable x can be interpreted as the amount by which
we must decrease the coeﬃcient of x in the objective function in order to have
x > 0 in the optimal solution. We explain later that this implies that we can
project some cost to unary cost functions.
In the speciﬁc case of LPF ∅, we have:
rc(xks) = rc(xks′) = 0
rc(xis) = 0 ∀xi ∈S\{xk}
rc(xiv) = piv −ycc × wiv −yi ∀xi ∈S, v ̸= s
Observation 1. Consider the linear program LP ′
F ∅which is identical to LPF ∅
but has p′
iv = piv −rc(xiv). Then opt(LP ′
F ∅) = opt(LPF ∅).
Proof. The optimal solution x∗of LPF ∅has the same cost o in LPF ∅and LP ′
F ∅,
as the coeﬃcients of the variables that are greater than 0 are unchanged. The
optimal dual solution x∗remains feasible in LP ′
F ∅, as the slack in the dual of
LPF ∅matches exactly the reduction in the right-hand side. Moreover, as the
dual objective did not change, it has the same cost and matches the primal cost,
so opt(LP ′
F ∅) = o = opt(LPF ∅).
⊓⊔
Example 2. Consider the following problem:
min 40x11 + 55x12 + 85x13 + 47x21 + 95x22
s.t.
4x11 + 14x12 + 24x13 + 16x21 + 40x22 ≥40

v∈D(xi)
xiv = 1
∀xi ∈{x1, x2}
0 ≤xiv ≤1
∀xi ∈{x1, x2}, v ∈D(xi)
Pisinger’s algorithm gives the optimal primal solution x∗= {0, 1, 0, 7
12, 5
12}
with cost o = 55 + 7
12 × 47 + 5
12 × 95 = 122.
We deduce the following dual optimal solution : ycc = 2, y1 = 55 −2 × 14 =
27, y2 = 47 −2 × 16 = 15.
The following reduced costs are obtained : rc(x12) = rc(x21) = rc(x22) = 0
and rc(x11) = 5, rc(x13) = 10, we deduce that replacing the previous objective
function by the following one does not change the cost of the optimal solution:
min 35x11 + 55x12 + 75x13 + 47x21 + 95x22
We observe that the solution x∗= {0, 1, 0, 7
12, 5
12} is still optimal.
4.2
Propagation
Given a PB constraint and the associated unary costs, it is possible to increase
the lower bound by at least opt(LPF ∅). Our goal is to extend as little cost
as possible from the unary cost functions in order to make opt(LP∅) = o =
opt(LPF ∅) and then project o to c∅.

292
P. Montalbano et al.
Procedure TransformPB(cS, ycc, yi, o)
Data: cS : PB constraint
Data: ycc, yi, o: optimal dual solution of LPF ∅
1 for all the variables xiv do
2
ci(v) ←ci(v) −ycc × wiv −yi + δiv
3
δiv ←ycc × wiv + yi
4 c∅←c∅+ o
5 δ∅←δ∅+ o
If we move |ci(v) −rc(xiv)| between the constraint and each unary cost
function and value, then opt(LP∅) = o and we can project o to c∅. Indeed
we have |ci(v) −rc(xiv)| = |(ycc × wiv + yi) −δiv|, we thus obtain the EPTs
performed by Procedure TransformPB.
Theorem 1. Algorithm TransformPB preserves equivalence.
Proof. Recall that piv = ci(v) + δiv and that rc(xiv) ≥0. If ci(v) −rc(xiv) ≥0
then the cost move is an extension of less than ci(v), it is valid. If ci(v)−rc(xiv) <
0 then the cost move is a projection, while the cost of any solution x′ with x′
iv = 1
is at least o −ci(v) + rc(xiv). This operation is also valid.
Finally, to check that our sequence of EPTs justiﬁes the increase of c∅by
o, we compute the optimum of LP∅. From Observation 1, opt(LP∅) = o, which
means we can project o to c∅and increase δ∅to bring opt(LP∅) = opt(LPF ∅) =
0.
⊓⊔
We can improve on this by observing that the integer optimum must be
integral. Therefore, we can increase c∅by ⌈o⌉. In this case, it is also necessary
to round up all cost moves. By rounding up, we can no longer rely on Observation
1, but it still holds that opt(LP∅) = 0. We also approach ∅IC by verifying that
for any value xab we have δab + min 
xi∈S\xa,v∈D(xi)(δiv + ci(v))xiv −δ∅= 0.
If this is not the case, we can project a positive cost to ca(b).
Procedure Propagate is the entry point to the propagator. It enforces domain
consistency on the PB constraint, then solves LPF ∅. If there is more than one
optimal solution we prefer the one minimizing the reduced cost of the EAC
support of each variable. Finally, it uses Procedure TransformPB, to perform
cost moves.
Theorem 2. Procedure Propagate runs in O(nd log nd) time where n is the
number of WCSP variables involved and d the maximum domain size.
Proof. Pisinger’s algorithm dominates the complexity, as it runs in O(N log N),
where N is the number of LP variables. In our case, N = nd, so it takes
O(nd log nd) time. Domain consistency on the linear inequality can be performed
in linear time. Finally, Procedure TransformPB iterates once over all variables
and values and performs constant time operations on each. Hence, the total
complexity is O(nd log nd).
⊓⊔

Multiple-choice Knapsack Constraint in Graphical Models
293
Procedure Propagate(cS)
Data: cS : PB constraint with EO partitions
1 DomainConsistency(cS )
2 (ycc, yi, o) = DualSolve(LPF ∅)
3 TransformPB(cS , ycc, yi, o)
Example 3. Returning to Example 2, where cS is the PB constraint with EO
partitions over two WCSP variables x1 and x2, we had the following reduced
costs: rc(x12) = rc(x21) = rc(x22) = 0, rc(x11) = 5, rc(x13) = 10, the optimal
cost was 122. We deduce the following cost moves:
– extend(c1, {x1 = 1}, cS, 35)
– extend(c1, {x1 = 2}, cS, 55)
– extend(c1, {x1 = 3}, cS, 75)
– extend(c2, {x2 = 1}, cS, 47)
– extend(c2, {x2 = 2}, cS, 95)
– project(c∅, cS, ∅, 122)
It implies the resulting costs: δ11 = 35, δ12 = 55, δ13 = 75, δ21 = 47, δ22 = 95,
δ∅= 122. The unary costs after these operations are c1(2) = c2(1) = c2(2) = 0,
c1(1) = 5, c1(3) = 10. If we construct the table of possible assignments of
LP∅obtained after the extensions, we can see that cS({x1 = 1, x2 = 2}) = 8,
cS({x1 = 2, x2 = 2}) = 28, cS({x1 = 3, x2 = 1}) = 0, cS({x1 = 3, x2 = 2}) =
48, and all the other assignments don’t satisfy the constraint. We observe that
the optimal solution is 0, hence our extensions justify the increase of c∅.
Now assume that other EPTs outside the PB constraint have modiﬁed the
unary costs: c1(1) →c1(1) + 16 = 21, c1(2) →c1(2) + 30 = 30, c1(3) →
c1(3) −9 = 1. We want to compute a new lower bound for the PB constraint by
solving LPF ∅:
min 56x11 + 85x12 + 76x13 + 47x21 + 95x22 −122
s.t.
4x11 + 14x12 + 24x13 + 16x21 + 40x22 ≥40

v∈D(xi)
xiv = 1
∀xi ∈{x1, x2}
0 ≤xij ≤1
∀xi ∈{x1, x2}, v ∈D(xi)
The optimal solution is x∗= {0, 0, 1, 1, 0} and its cost is o = 76 + 47 −
122 = 1. We deduce the dual optimal solution ycc = 1, y1 = 52, y2 = 31
with reduced costs rc(x11) = rc(x13) = rc(x21) = 0 and rc(x12) = 19,
rc(x22) = 24. We carry out the following cost moves: extend(c1, {x1 = 1}, cS, 21),
extend(c1, {x1 = 2}, cS, 11), extend(c1, {x1 = 3}, cS, 1), project(c2, cS, {x2 =
2}, 24), project(c∅, cS, ∅, 1), with δ11 = 56, δ12 = 66, δ13 = 76, δ21 = 47,
δ22 = 71, δ∅= 123.

294
P. Montalbano et al.
5
Experimental Results
We implemented our approach in toulbar2, an exact WCSP solver in C++,4
winner of past UAI-2008, 2014 competitions. toulbar2 default variable order-
ing heuristic is the weighted degree heuristic [8], in order to gain information
from PB constraints, we adapted an explanation-based weighted degree for lin-
ear inequality presented by Hebrard and Siala [24]. For all the tests we imposed
a time limit of 30 min (except for CPD with 1 h) on a single core of an Intel
Xeon E5-2680 v3 at 2.50 GHz and 256 GB of RAM. We compared our PB
propagator with other modeling approaches in protein design. We compared
toulbar2 to state-of-the-art ILP solver cplex 20.1 on knapsack problems with
conﬂict graphs. We also compared toulbar2 on pseudo-Boolean Competition
2016 (previously out of reach by toulbar2) but the results were not competitive
with recent PB solvers (not reported here for the lack of space).
5.1
Sequence of Diverse Solutions for CPD
A protein is a chain of simple molecules called amino acids. This sequence deter-
mines how the protein will fold into a speciﬁc 3D shape. The Computational
Protein Design (CPD) [4] problem consists of identifying the sequence of amino
acids that should fold into a given 3D shape. This problem can be modeled as
a CFN5 with unary and binary cost functions representing the energy of the
protein but the criteria only approximate the reality, thus producing a sequence
of diverse solutions increases the chance of ﬁnding the correct real sequence of
amino acids. Each time a solution is found, a Hamming distance constraint is
added to the model to enforce the next solution to be diﬀerent from the previous
ones. This Hamming distance can be directly encoded as a PB linear constraint,
in the form of Eq. (2), with EO partitions associated to domains (Eq. (3)). For
each variable, a negative weight of −1 is associated to the value found in the
last solution (other values having a zero-weight) and the weighted sum in Eq. (2)
must be greater than or equal to −(|X|−ζ), where ζ corresponds to the required
minimum Hamming distance.
This
has
been
implemented
in
toulbar2
and
compared
to
previ-
ous automata-based encoding approaches (ternary, hidden, and dual encod-
ings from [40]) on 30 instances [48].6 Selected instances have from 23 to
97 residues/variables with maximum domain size going from 48 to 194
4 https://github.com/toulbar2/toulbar2 version 1.2.
5 Other paradigms such as ILP or Max-SAT have been tested but the exper-
imental
results
using
their
corresponding
state-of-the-art
solvers
were
infe-
rior to the CFN approach using toulbar2 [1,4]. E.g., for CPD instance
1BK2.matrix.24p.17aa.usingEref self digit2 (n = 24, d = 182, e = 300), cplex 20.1
solves it in 42.84 s, toulbar2 in 0.37 s. RoundingSAT [26] timed out after 10 h.
6 http://genoweb.toulouse.inra.fr/∼tschiex/CPD-AIJ/Last35-instances. We removed
5 instances (1ENH.matrix.36p.17aa, 1STN.matrix.120p.18aa, HHR.matrix.115p.
19aa, 1PGB.matrix.31p.17aa, 2CI2.matrix.51p.18aa) on which toulbar2 timed out
after 9,000 s even without diversity constraints [1].

Multiple-choice Knapsack Constraint in Graphical Models
295
Fig. 1. Cactus plot of CPU solving time (log scale) for diﬀerent encodings of Hamming
distance constraints on CPD.
rotamers/values. The number of unary and binary cost functions goes from
276 to 4, 753. For each instance, the time limit was 1 h and the solver halts
after ﬁnding a greedy sequence of 10 diverse solutions, the Hamming distance
is ζ = 10, and we enforce VAC on unary and binary cost functions in prepro-
cessing (options -A -d: -a = 10 -div = 10 -divm = (0 for dual, 1 for hidden, 2
for ternary, and 3 for the PB encoding)). Figure 1 reports the solving time of
each encoding. The dual and ternary encodings failed to give 10 diverse solutions
for one instance, while the PB and hidden encodings didn’t. Moreover the PB
encoding is faster for 29 instances and it solves 23 of them in less than 30 s while
dual, hidden, and ternary encodings solve respectively 12, 13, and 4 instances
in less than 30 s. Note that we are computing a greedy sequence of solutions,
the diﬀerent encodings do not return the exact same sequence (except for 7/30
instances). We also compared for each instance the number of backtracks and
time (not reported here) of the previous toulbar2 default encoding (dual) with
the PB encoding. In all the instances the PB encoding needs fewer backtracks
than the dual encoding and except for one instance, the PB encoding is also
faster. Automata-based encodings have the ﬂaw of introducing extra variables
that can disturb the variable ordering heuristic (by default, min domain size
over weighted degree [9])7 and local consistency algorithm (by default, EDAC
during search, except partial F∅IC for PB constraints). While the PB encoding
directly encodes the Hamming distance, it is heavier to propagate as we can see
by comparing the number of backtracks per second (170 for PB encoding and
1060 for dual encoding).
7 Additionally, the PB constraint provides ﬁner-grain weights using explanations [24]
when linear coeﬃcients are not all equal as it is the case in the KPCG benchmark.

296
P. Montalbano et al.
Table 1. Number of solved instances (left) and number of times a solver found the
best solution within the time limit (right) for six diﬀerent classes of KPCG.
tb2 cplext cplexd
tb2 cplext cplexd
C1
718
689
720
720
701
720
C3
597
487
614
718
513
639
C10 490
318
457
633
346
547
R1 720
705
720
720
705
720
R3 720
573
682
720
589
691
R10 571
365
519
665
384
583
5.2
Knapsack Problem with a Conﬂict Graph
We compare here toulbar2 and cplex on Knapsack with Conﬂict Graph
(KPCG) [6,11], a knapsack problem combined with binary constraints represent-
ing conﬂicts between pairs of variables. We use 6 diﬀerent classes C1,C3,C10,R1,
R3,R10. In three of them the weight and the proﬁt of each variable are corre-
lated (class C) otherwise the proﬁt is random between [1, 100] (class R). The
numbers 1, 3, 10 correspond to a multiplying coeﬃcient of the capacity, which
has the eﬀect of making the instances harder as the multiplier increases. In each
class half of the instances have capacity 150, weights are uniformly distributed in
[20, 100], and the number of Boolean variables varies between 120, 250, 500, and
1000. For the other half, the capacity is 1000, weights are uniformly distributed
in [250, 500], and the number of Boolean variables varies between 60, 120, 349,
and 501. Additionally, the density of the conﬂict graph varies from 0.1 to 0.9.
In total, each class has 720 instances. We used a direct encoding for toulbar2.
For cplex, we tried with both tuple and direct encodings (tuple encoding cor-
responds to the local polytope with integer variables) [25]. Table 1 reports the
number of instances solved by each solver. toulbar2 was more eﬃcient than
cplex with the tuple encoding and competitive with cplex using the direct
encoding for four out of six classes. Moreover, toulbar2 ﬁnds the best solu-
tions for the largest number of instances in every class.
6
Conclusion and Future Work
It is now possible to model pseudo-Boolean linear constraints in deterministic
and probabilistic graphical models. This provides greater modeling ﬂexibility and
allows a WCSP solver like toulbar2 to solve more problems, such as compu-
tational protein design problems with diversity guarantee or knapsack problems
with conﬂict graphs. One of the weaknesses of our approach is that the algorithm
fundamentally produces a suboptimal solution to the linear program, because
it propagates the pseudo-Boolean linear constraints one by one and does not
take into account other constraints (except at-most-one constraints). There are
several ways to improve this, including adapting work previously done in this
context on Lagrangian relaxation [30] or an approach closer to VAC [16]. It also
opens up possibilities for other uses of linear constraints in the WCSP frame-
work, such as the generation of cuts.

Multiple-choice Knapsack Constraint in Graphical Models
297
References
1. Allouche, D., et al.: Cost function networks to solve large computational pro-
tein design problems. In: Masmoudi, M., Jarboui, B., Siarry, P. (eds.) Opera-
tions Research and Simulation in Healthcare, pp. 81–102. Springer, Cham (2021).
https://doi.org/10.1007/978-3-030-45223-0 4
2. Allouche, D., et al.: Tractability-preserving transformations of global cost func-
tions. Artif. Intell. 238, 166–189 (2016)
3. Allouche, D., et al.: Filtering decomposable global cost functions. In: Proceedings
of AAAI-12. Toronto, Canada (2012)
4. Allouche, D., et al.: Computational protein design as an optimization problem.
Artif. Intell. 212, 59–79 (2014)
5. Ans´otegui, C., et al.: Automatic detection of at-most-one and exactly-one relations
for improved SAT encodings of pseudo-boolean constraints. In: Schiex, T., de Givry,
S. (eds.) CP 2019. LNCS, vol. 11802, pp. 20–36. Springer, Cham (2019). https://
doi.org/10.1007/978-3-030-30048-7 2
6. Bettinelli, A., Cacchiani, V., Malaguti, E.: A branch-and-bound algorithm for
the knapsack problem with conﬂict graph. INFORMS J. Comput. 29(3), 457–473
(2017)
7. Boﬁll, M., Coll, J., Suy, J., Villaret, M.: An MDD-based SAT encoding for pseudo-
boolean constraints with at-most-one relations. Artif. Intell. Rev. 53(7), 5157–5188
(2020)
8. Boussemart, F., Hemery, F., Lecoutre, C., Sais, L.: Boosting systematic search by
weighting constraints. In: ECAI, vol. 16, p. 146 (2004)
9. Boussemart, F., Hemery, F., Lecoutre, C., Sais, L.: Boosting systematic search by
weighting constraints. In: Proceedings of ECAI-04, vol. 16, p. 146 (2004)
10. Cabon, B., de Givry, S., Lobjois, L., Schiex, T., Warners, J.: Radio link frequency
assignment. Constraints 4(1), 79–89 (1999)
11. Coniglio, S., Furini, F., San Segundo, P.: A new combinatorial branch-and-bound
algorithm for the knapsack problem with conﬂicts. Eur. J. Oper. Res. 289(2),
435–455 (2021)
12. Cooper, M.C., de Givry, S., S´anchez, M., Schiex, T., Zytnicki, M., Werner, T.: Soft
arc consistency revisited. Artif. Intell. 174(7–8), 449–478 (2010)
13. Cooper, M.C., de Givry, S., Schiex, T.: Graphical models: queries, complexity,
algorithms (tutorial). In: Proceedings of 37th International Symposium on Theo-
retical Aspects of Computer Science (STACS-20). LIPIcs, vol. 154, pp. 4:1–4:22.
Montpellier, France (2020)
14. Cooper, M.C., de Givry, S., Schiex, T.: Valued constraint satisfaction problems.
In: Marquis, P., Papini, O., Prade, H. (eds.) A Guided Tour of Artiﬁcial Intel-
ligence Research, pp. 185–207. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-06167-8 7
15. Dechter, R., Rish, I.: Mini-buckets: a general scheme for bounded inference. J.
ACM (JACM) 50(2), 107–153 (2003)
16. Dlask, T., Werner, T.: Bounding linear programs by constraint propagation: appli-
cation to max-SAT. In: Simonis, H. (ed.) CP 2020. LNCS, vol. 12333, pp. 177–193.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58475-7 11
17. Dlask, T., Werner, T.: On relation between constraint propagation and block-
coordinate descent in linear programs. In: Simonis, H. (ed.) CP 2020. LNCS, vol.
12333, pp. 194–210. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
58475-7 12

298
P. Montalbano et al.
18. Dyer, M.E.: An o(n) algorithm for the multiple-choice knapsack linear program.
Math. Program. 29(1), 57–63 (1984)
19. Elﬀers, J., Nordstr¨om, J.: Divide and conquer: towards faster pseudo-boolean solv-
ing. In: Proceedings of IJCAI, Stockholm, Sweden, pp. 1291–1299 (2018)
20. de Givry, S., Schiex, T., Verfaillie, G.: Exploiting tree decomposition and soft local
consistency in weighted CSP. In: Proceedings of AAAI-06, Boston, MA (2006)
21. de Givry, S., Heras, F., Zytnicki, M., Larrosa, J.: Existential arc consistency: get-
ting closer to full arc consistency in weighted CSPs. In: Proceedings of IJCAI-05,
Edinburgh, Scotland, pp. 84–89 (2005)
22. de Givry, S., Katsirelos, G.: Clique cuts in weighted constraint satisfaction. In:
Beck, J.C. (ed.) CP 2017. LNCS, vol. 10416, pp. 97–113. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-66158-2 7
23. Haller, S., Swoboda, P., Savchynskyy, B.: Exact map-inference by conﬁning com-
binatorial search with LP relaxation. In: Proceedings of AAAI-18, New Orleans,
Louisiana, USA, pp. 6581–6588 (2018)
24. Hebrard, E., Siala, M.: Explanation-based weighted degree. In: Salvagnin, D., Lom-
bardi, M. (eds.) CPAIOR 2017. LNCS, vol. 10335, pp. 167–175. Springer, Cham
(2017). https://doi.org/10.1007/978-3-319-59776-8 13
25. Hurley, B., et al.: Multi-language evaluation of exact solvers in graphical model
discrete optimization. Constraints 21(3), 413–434 (2016). https://doi.org/10.1007/
s10601-016-9245-y
26. Jo Devriendt, A.G., Nordstr¨om, J.: Learn to relax: integrating 0–1 integer linear
programming with pseudo-boolean conﬂict-driven search. In: Proceedings of CP-
AI-OR 2020, Vienna, Austria (2020)
27. Johnson, E.L., Padberg, M.W.: A note of the knapsack problem with special
ordered sets. Oper. Res. Lett. 1(1), 18–22 (1981)
28. Koller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Tech-
niques. MIT Press, Cambridge (2009)
29. Kolmogorov, V.: Convergent tree-reweighted message passing for energy minimiza-
tion. IEEE Trans. Pattern Anal. Mach. Intell. 28(10), 1568–1583 (2006)
30. Komodakis, N., Paragios, N., Tziritas, G.: MRF energy minimization and beyond
via dual decomposition. IEEE Trans. Pattern Anal. Mach. Intell. 33(3), 531–552
(2010)
31. Larrosa, J.: On arc and node consistency in weighted CSP. In: Proceedings of AAAI
2002, Edmondton, CA, pp. 48–53 (2002)
32. Larrosa, J., Schiex, T.: In the quest of the best form of local consistency for
weighted CSP. In: Proceedings of IJCAI-03, vol. 3, pp. 239–244 (2003)
33. Lee, J.H.M., Leung, K.L.: Consistency techniques for ﬂow-based projection-safe
global cost functions in weighted constraint satisfaction. J. Artif. Intell. Res. 43,
257–292 (2012)
34. Lee, J.H., Leung, K.L., Shum, Y.W.: Consistency techniques for polytime linear
global cost functions in weighted constraint satisfaction. Constraints 19(3), 270–
308 (2014)
35. Lee, J.H., Leung, K.L., Wu, Y.: Polynomially decomposable global cost functions
in weighted constraint satisfaction. In: Proceedings of AAAI-12, Toronto, Canada
(2012)
36. Marinescu, R., Dechter, R.: AND/OR branch-and-bound for graphical models. In:
Proceedings of IJCAI-05, Edinburgh, Scotland, pp. 224–229 (2005)
37. Pisinger, D., Toth, P.: Knapsack problems. In: Du, D.Z., Pardalos, P.M. (eds.)
Handbook of Combinatorial Optimization, pp. 299–428. Springer, Boston (1998).
https://doi.org/10.1007/978-1-4613-0303-9 5

Multiple-choice Knapsack Constraint in Graphical Models
299
38. Prusa, D., Werner, T.: Universality of the local marginal polytope. In: Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1738–
1743 (2013)
39. Ruﬃni, M., Vucinic, J., de Givry, S., Katsirelos, G., Barbe, S., Schiex, T.: Guar-
anteed diversity & quality for the weighted CSP. In: 2019 IEEE 31st International
Conference on Tools with Artiﬁcial Intelligence (ICTAI), pp. 18–25. IEEE (2019)
40. Ruﬃni, M., Vucinic, J., de Givry, S., Katsirelos, G., Barbe, S., Schiex, T.: Guaran-
teed diversity and optimality in cost function network based computational protein
design methods. Algorithms 4(6), 168 (2021)
41. Sakai, M., Nabeshima, H.: Construction of an ROBDD for a PB-constraint in
band form and related techniques for PB-solvers. IEICE Trans. Inf. Syst. 98(6),
1121–1127 (2015)
42. S´anchez, M., de Givry, S., Schiex, T.: Mendelian error detection in complex pedi-
grees using weighted constraint satisfaction techniques. Constraints 13(1), 130–154
(2008)
43. Schiex, T.: Arc consistency for soft constraints. In: Dechter, R. (ed.) CP 2000.
LNCS, vol. 1894, pp. 411–425. Springer, Heidelberg (2000). https://doi.org/10.
1007/3-540-45349-0 30
44. Schlesinger, M.: Sintaksicheskiy analiz dvumernykh zritelnikh signalov v usloviyakh
pomekh (Syntactic analysis of two-dimensional visual signals in noisy conditions).
Kibernetika 4, 113–130 (1976)
45. Sontag, D., Choe, D., Li, Y.: Eﬃciently searching for frustrated cycles in MAP
inference. In: Proceedings of UAI, Catalina Island, CA, USA, pp. 795–804 (2012)
46. Sontag, D., Meltzer, T., Globerson, A., Weiss, Y., Jaakkola, T.: Tightening LP
relaxations for MAP using message-passing. In: Proceedings of UAI, Helsinki, Fin-
land, pp. 503–510 (2008)
47. Tourani, S., Shekhovtsov, A., Rother, C., Savchynskyy, B.: Taxonomy of dual
block-coordinate ascent methods for discrete energy minimization. In: Proceed-
ings of AISTATS 2020, Palermo, Sicily, Italy, pp. 2775–2785 (2020)
48. Traor´e, S., et al.: A new framework for computational protein design through cost
function network optimization. Bioinformatics 29(17), 2129–2136 (2013)
49. Tr¨osser, F., de Givry, S., Katsirelos, G.: Relaxation-aware heuristics for exact opti-
mization in graphical models. In: Hebrard, E., Musliu, N. (eds.) CPAIOR 2020.
LNCS, vol. 12296, pp. 475–491. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-58942-4 31
50. Vaidya, P.: Speeding-up linear programming using fast matrix multiplication. In:
30th Annual Symposium on Foundations of Computer Science, pp. 332–337 (1989)
51. Werner, T.: A linear programming approach to max-sum problem: a review. IEEE
Trans. Pattern Recogn. Mach. Intell. 29(7), 1165–1179 (2007)
52. Zemel, E.: An o(n) algorithm for the linear multiple choice knapsack problem and
related problems. Inf. Process. Lett. 18(3), 123–128 (1984)
53. Zytnicki, M., Gaspin, C., de Givry, S., Schiex, T.: Bounds arc consistency for
weighted CSPs. J. Artif. Intell. Res. 35, 593–621 (2009)

A Learning Large Neighborhood Search
for the StaﬀRerostering Problem
Fabio F. Oberweger1(B), G¨unther R. Raidl1, Elina R¨onnberg2,
and Marc Huber1
1 Institute of Logic and Computation, TU Wien, Vienna, Austria
fabio.oberweger@gmail.com, {raidl,mhuber}@ac.tuwien.ac.at
2 Department of Mathematics, Link¨oping University, Link¨oping, Sweden
elina.ronnberg@liu.se
Abstract. To eﬀectively solve challenging staﬀrerostering problems, we
propose to enhance a large neighborhood search (LNS) with a machine
learning guided destroy operator. This operator uses a conditional gen-
erative model to identify variables that are promising to select and com-
bines this with the use of a special sampling strategy to make the actual
selection. Our model is based on a graph neural network (GNN) and takes
a problem-speciﬁc graph representation as input. Imitation learning is
applied to mimic a time-expensive approach that solves a mixed-integer
program (MIP) for ﬁnding an optimal destroy set in each iteration. An
additional GNN is employed to predict a suitable temperature for the
destroy set sampling process. The repair operator is realized by solving a
MIP. Our learning LNS outperforms directly solving a MIP with Gurobi
and yields improvements compared to a well-performing LNS with a
manually designed destroy operator, also when generalizing to schedules
with various numbers of employees.
Keywords: Staﬀrerostering · Large neighborhood search · Imitation
Learning · Machine Learning
1
Introduction
Large neighborhood search (LNS) [33,38] is a powerful meta-heuristics for solv-
ing combinatorial optimization problems (COP). It has been successfully applied
to many complex problems, including vehicle routing [38], facility location [18],
and project scheduling [28]. A common LNS design is to deﬁne a neighborhood
search by a destroy and repair operator pair that is applied in each iteration
[33]. The destroy operator partially destructs the incumbent solution by freeing
This work is part of the pre-study Decision support for railway crew planning sup-
ported by KAJT (Capacity in the Railway Traﬃc System). It is also partially funded
by the Doctoral Program Vienna Graduate School on Computational Optimization,
Austrian Science Foundation (FWF), grant W1260-N35, and the Center for Industrial
Information Technology (CENIIT), Project-ID 16.05.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 300–317, 2022.
https://doi.org/10.1007/978-3-031-08011-1_20

A Learning Large Neighborhood Search for the SRRP
301
unassign
temperature τ
destroy set
sampling
destroy set
probability for each employee-
d1 d2 d3
n1
n2
n3
day pairs to be destroyed
repair
solution
d1 d2 d3
n1
n2
n3
d1 d2 d3
n1
n2
n3
evaluate, update incumbent, and repeat
d1 d2 d3
n1
n2
n3
create
solution
E
E
E
E
E
E
E
E
F
F
F
F
F
F
F
F
D
D
D
D
D
D
D
D
N
N
N
N
N
N
N
N
N
incumbent sol.
problem instance
partial solution
new solution
Fig. 1. Principle of the LNS applying trained ML models in the destroy operation.
a subset of the decision variables while ﬁxing the others to their current values.
A subproblem is hereby induced, and its space of feasible solutions forms a (large)
neighborhood. By exactly or heuristically solving this subproblem, the repair
operator tries to improve the previous solution by ﬁnding better assignments for
these “destroyed” variables. If a new solution with an improved objective value
is found, it becomes the new incumbent solution.
The destroy operator has a signiﬁcant impact on the performance of an LNS.
Frequently, a simple random selection of the variables is applied, which, however
rarely gives the best results. Manually designing more eﬀective destroy opera-
tors often is time-consuming and challenging. Recently, machine learning (ML)
based techniques have been suggested to perform this task [2,14,39,40]. These
techniques reduce or even eliminate the need for a manual design and have the
potential to unveil connections that human experts might not see.
The staﬀrerostering problem (SRRP) is COP that deals with optimizing and
reconstructing work schedules aﬀected by disruptions, e.g., unplanned absences
of employees or changes in demand for staﬀ. Inspired by Sonnerat et al. [40], we
propose an ML-based LNS consisting of a learning-based destroy operator and
the use of a mixed-integer program (MIP) solver as repair method for heuristi-
cally solving challenging SRRP instances. Imitation learning is applied to train a
conditional generative model predicting weights that indicate which elements of
a solution are promising to destroy. Based on these weights, we propose a SRRP-
speciﬁc sampling strategy for actually choosing the elements to destroy. More-
over, an additional ML model is used to obtain a suitable temperature parameter
steering the sampling process. We employ graph neural networks (GNN) utiliz-
ing a SRRP-speciﬁc graph structure that enables eﬃcient learning and inference
for this highly constrained COP. Figure 1 shows our LNS scheme.
Experimental results show that our ML-based LNS outperforms both solv-
ing the respective MIP with Gurobi1 and applying a well-performing LNS with
a meaningful manually constructed destroy operator. While our approach is
designed speciﬁcally for the SRRP, it may be generalized to other problems as
well. The components requiring a problem-speciﬁc design are the graph structure
for the GNN and the destroy set sampling process. Since these may be tailored
1 https://www.gurobi.com.

302
F. F. Oberweger et al.
to the needs of a particular problem, we believe that our approach might perform
well on various types of COPs.
In Sect. 2, related work is reviewed and our approach is compared to existing
ML-based LNS. The SRRP is introduced in Sect. 3 and the LNS framework
is discussed in Sect. 4. Section 5 provides the details of our ML-based destroy
operator. Experimental results are presented in Sect. 6 and concluding comments
are given in Sect. 7. This work is based on the ﬁrst author’s master thesis [31].
2
Related Work
The SRRP is a generalization of the nurse rerostering problem (NRRP). Moz
and Pato [25] were the ﬁrst to formally deﬁne the NRRP, which deals with
adapting an existing work schedule given employee absences on speciﬁc days.
While the NRRP only considers employee-based disruptions, e.g., caused by
illness, the SRRP also considers changes in demand. Already the NRRP with
the single objective of minimizing the diﬀerences from the original schedule is
NP-hard [27]. The SRRP and the NRRP are both extensions of the classical
nurse rostering problem (NRP). For reviews of the NRP, we refer to Ernst et al.
[8] and Van den Bergh et al. [5]. The NRRP is not as well studied as the NRP,
but has been considered in several works [22,23,25–27,32,43].
Recently, many researchers have explored the application of ML in combina-
torial optimization. ML techniques to learn heuristics for COPs in an end-to-end
fashion [1,3,16,19,42] have been steadily improving. Nonetheless, they are usu-
ally still outperformed by state-of-the-art classical optimization methods, espe-
cially on problems with complex side constraints. For closing this performance
gap, a new paradigm often referred to as “learning to search” [39] has evolved.
This paradigm generally deals with the usage of NL-based heuristics within other
methods. For example, learnable heuristics were used for guiding beam search
[17,30], deciding on how to branch in branch-and-bound (B&B) algorithms
[10,13,20,29], and learning destroy or repair operators in LNS [2,7,14,39,41].
Song et al. [39] proposed an ML-based destroy operator for a decomposition-
based LNS solving general MIPs. In this LNS variant, one iteration consists
of splitting all variables into disjoint sets and destroying and repairing each
variable set one after the other. The authors use reinforcement learning (RL)
and imitation learning to train a model performing the variable splits. To obtain
data for the imitation learning, they randomly sample multiple decompositions
for each solution and take the best. In contrast to the ﬁxed variable subsets in
the decomposition-based LNS, Addanki et al. [2] use RL to train a GNN for
iteratively selecting one variable at a time until a destroy set of predetermined
size is found. A current state in the optimization of a MIP is in [2] modeled by
a graph structure called Constraint-Variable Incidence Graph (CVIG). A CVIG
consists of one node for each variable and one node for each constraint, and edges
represent the occurrence of variables in constraints. Sonnerat et al. [40] avoid the
high overhead of one neural network (NN) inference step for each selection of a
variable by training a conditional generative model with imitation learning. This

A Learning Large Neighborhood Search for the SRRP
303
model predicts a distribution over all nodes, which they use to sample a destroy
set. The authors also employ a CVIG as input to their GNN. To generate training
data, they use a local-branching [9] based mixed-integer programming approach
that computes optimal destroy sets. All of the above approaches [2,39,40] rely
on a MIP solver for repairing solutions.
We build on the approach of Sonnerat et al. [40] but modify it in the following
ways. Since CVIGs are huge for the highly constrained SRRPs, they dramati-
cally slow down training and inference already for instances of moderate sizes.
Instead, we propose to use a more compact problem-speciﬁc graph that eﬃ-
ciently represents the choices to be made by the destroy operator, together with
a generalized sampling strategy to choose the destroy set. Moreover, we employ
an additional NN predicting suitable values of the temperature parameters for
the destroy set sampling process.
3
StaﬀRerostering Problem
The SRRP is deﬁned on a set of employees N, a set of days D, and a set of
shifts S, which we assume to be an early shift (7 am to 3 pm), the day shift
(3 pm to 11 pm), the night shift (11 pm to 7 am), and the free shift modeling
oﬀ-days. We treat the SRRP as an assignment problem, where each employee
n ∈N shall be assigned to a shift s ∈S on each day d ∈D. To represent a
solution to an SRRP instance, we introduce decision variables xnds ∈{0, 1},
where xnds = 1 if and only if employee n ∈N is scheduled to work shift s ∈S
on day d ∈D. A solution is feasible if it satisﬁes to following hard constraints:
– Each employee must be assigned to exactly one working shift per day or the
free shift.
– An employee has to rest at least 11 h after each working shift.
– An employee must not be assigned to less than a minimum or more than a
maximum number of working shifts in the scheduling period.
– An employee must not be assigned to less than a minimum or more than a
maximum number of consecutive working shifts.
– An employee must not have less than a minimum or more than a maximum
number of assignments to a shift type in the scheduling period.
– An employee must not have less than a minimum or more than a maximum
number of consecutive assignments to a shift type.
– Employees cannot be assigned to a working shift if they are absent for the
time of this shift on this day.
Since the SRRP deals with disruptions to an existing schedule, such as absences
of employees and changes in the demand for employees, the goal of the SRRP is
to comply with the following soft constraints:
– The staﬃng requirements per day and shift should be met as well as possible.
– The original schedule should be modiﬁed as little as possible.
For a detailed formal deﬁnition of the SRRP, we refer to [31].

304
F. F. Oberweger et al.
4
Large Neighborhood Search
We now deﬁne the repair operator used in each LNS applied in this work and
propose a reasonable manually crafted destroy operator that serves as a baseline
for comparison in our computational experiments. The construction heuristic
(inspired by [35]) used to create an initial solution for the LNS simply takes
the provided original schedule and, when an employee is absent on a working
shift, changes the assignments to a free shift. The obtained initial solution will
therefore typically be infeasible and this has to be considered in the LNS design.
4.1
Random Destroy Operator
Due to the constraints regulating the consecutive number of working shifts and
the consecutive assignments per shift type, the repair operator has a greater
chance to produce improvements if variables associated with consecutive days
are unassigned in the destroy operator. Therefore, our baseline destroy operator
randomly selects an employee n ∈N and a day d ∈D forming an employee-day
pair (n, d). In addition, a period P = {max(1, d−z2), . . . , d, . . . , min(|D|, d+z2)}
is deﬁned containing the days ranging from z2 days before d to z2 days after d,
respecting that one is the index of the ﬁrst and |D| the index of the last day.
Then, for the selected employee n and day d all variables xnd′s for d′ ∈P are
destroyed. This process is repeated z1 times for each application of the destroy
operator; the selection is done without replacement. Both, z1 ∈N0 and z2 ∈N0
are ﬁxed strategy parameters. The selection is done without replacement.
4.2
Repair Operator
The repair operator is to apply the Gurobi solver to a MIP representing an SRRP
sub-instance induced by the destroy operator. Thus, a given partial solution is
repaired by searching for best values for the unassigned variables while the other
variables are considered ﬁxed to their current values. As mentioned previously,
the construction heuristic may return infeasible solutions. Moreover, the destroy
operator might not select all the relevant variables required to turn the solution
feasible with one repair operator application. As a consequence, we have to deal
with infeasible solutions during the repair operation and the LNS in general.
Therefore, an additional MIP is used, where a majority of the hard constraints
are transformed into soft constraints. The constraints that are not relaxed are
those that ensure that each employee is assigned to exactly one shift per day
and that a working shift cannot be assigned to an absent employee. As a result,
a solution to this relaxed model can violate the other hard constraints at the
cost of additional penalization. The penalization is designed in such a way that
infeasible solutions always have a worse objective values than feasible solutions.
We refer to [31] for details on the MIP-formulations.
The repair operator uses the MIP with relaxed hard constraints as long as
the incumbent solution before the destroy operation was infeasible. When the
incumbent solution is feasible, the MIP with the regular hard constraints is

A Learning Large Neighborhood Search for the SRRP
305
employed. Thus, the two separate MIP in the repair operator put the focus
eﬀectively ﬁrst on making an infeasible solution feasible and only then to further
improve the objective value with respect to the remaining soft constraints.
5
Learning-Based Destroy Operator
The concept of our learning-based destroy operator is to utilize a NN that,
given an SRRP instance and a current solution represented by features, returns
weights to select promising employee-day pairs (n, d) ∈N × D for which the
respective decision variables xnds, s ∈S, are unassigned, i.e., “destroyed”. Let
πθ represents the destroy set model, where θ is the learnable parameters. The
model takes a featurized version of a state st at step t of an LNS run, consisting
of an SRRP instance I and its current solution x = (xnds)n∈N, d∈D, s∈S, as an
input. The model πθ outputs a value μnd for each (n, d) ∈N × D indicating
the probability that this employee-day pair is in an optimal destroy set, i.e., a
destroy set that when realized yields, after an optimal repair, a solution with a
minimum objective value. Note that we consider the size of the destroy set to be
ﬁxed to z1 ·(2z2 +1) employee-day pairs, just as in the random destroy operator
from Sect. 4.1. More speciﬁcally, πθ consists of two independently trained NNs:
one handling states containing infeasible solutions and one dealing with states
containing feasible solutions. This distinction is made as we observed that the
behavior to learn can be quite diﬀerent for feasible and infeasible solutions. Also,
more training data is created for feasible solutions since the LNS spends more
time in the feasible space. By considering two NNs, problems arising from the
imbalance in training data are thus avoided. The only diﬀerence between the
models in πθ is the data used to train them. Hence, to improve readability, we
will only refer to πθ indicating the respective NNthroughout this whole section.
Another important aspect of our learning-based destroy operator is the tem-
perature τ which is a parameter regulating the inﬂuence of πθ’s output in the
destroy set sampling process. To choose a meaningful τ dynamically in depen-
dence of the progress of the LNS, we use a second model πT
φ, which receives a
state st and the output of πθ as inputs and predicts a temperature τ for the
current situation. Again, πT
φ consists of two independently trained NNs, one for
infeasible and one for feasible solutions, and for the sake of readability, we will
only refer to πT
φ.
The next step in our learning-based destroy operator is the destroy set sam-
pling process. Here, we use πθ’s output and the predicted temperature τ to
actually select the employee-day pairs to be unassigned in the current solution.
5.1
Markov Decision Process Formulation
A Markov decision process (MDP) [15] is represented by a 4-tuple consisting of
the set of states ST, the set of actions A, a transition function T, and a reward
function. In our setting, we deﬁne a state st ∈ST at step t of an episode to consist
of an SRRP instance I and its current solution xt. An action at ∈{0, 1}|N×D| at

306
F. F. Oberweger et al.
step t represents the selection of employee-day pairs to be destroyed. A positive
assignment at
nd = 1 for an employee-day pair (n, d) indicates that it is chosen
for the destroy set and, for all s ∈S, the variables xt
nds are unassigned in
the current solution. Given a state st and an action at, the transition function
T : ST × A →ST determines the next state st+1 = T(st, at). Here, T(st, at)
is reached by destroying all variables associated with at in solution xt and then
repairing the partial solution with the repair operator. We do not deﬁne a reward
function since it does not play a role in our method.
5.2
Destroy Set Prediction as Conditional Generative Modeling
Inspired by Nair et al. [29], we propose a conditional generative model represent-
ing the distribution of actions (i.e., destroy sets) in a current state. For step t in
an LNS run, consider a state st ∈ST, an action at ∈A, and the transition func-
tion T. Moreover, let c : ST →R represent a function returning the objective
value of a current solution xt of state st ∈ST. Deﬁne the energy function
E(at; st) =

c(T(st, at))
if c(T(st, at)) < c(st),
∞
otherwise,
(1)
over the actions at of state st, which as in Nair et al. [29] deﬁnes the conditional
distribution
π(at|st) =
e−E(at;st)

(a′)t e−E((a′)t;st) .
(2)
Our learning eﬀorts aim to approximate the conditional distribution in (2) utiliz-
ing a model πθ(at|st) parameterized by θ. By using the unscaled energy function
as presented in (1), destroy sets that leads to solutions with better (lower) objec-
tive values after being repaired get a higher probability. Furthermore, destroy
sets not leading to improvements in objective value get zero probability. How-
ever, since our goal is to generate the best action in each state, we re-scale the
energy function such that we assign probability π((a∗)t|st) = 1 to an optimal
action (a∗)t and a probability of zero to each other action in state st. Sonnerat
et al. [40] adapted the conditional generative modeling design from Nair et al.
[29] in the same way. As a consequence, we only have to consider training data
containing optimal actions.
5.3
Sampling Destroy Sets
In Sect. 4.1, we introduced the baseline random destroy operator, which selects
z1 employee-day pairs (n, d) ∈N × D and destroys all the variables associated
with employee-day pairs within the range of z2 days before to z2 days after d.
Remember that z1 ∈N0 and z2 ∈N0 are strategy parameters. Moreover, we
described that selecting employee-day pairs without this range does not give
good results since the SRRP contains constraints regarding consecutive working

A Learning Large Neighborhood Search for the SRRP
307
assignments. Although in our learning-based destroy operator, the NN πθ out-
puts a value for each employee-day pair describing its probability to be in the
destroy set, the same issues remain. Therefore, we propose a new destroy set
sampling strategy, where blocks of consecutive employee-day pairs are selected.
Each pair (n, d) ∈N × D is assigned an aggregated weight
wnd =
min(|D|, d+z2)

d′=max(1, d−z2)
(πθ(at
nd′ = 1 | st) + ε)
1
τ · I[(n, d′) ∈U],
(3)
where τ a temperature parameter to strengthen or weaken the inﬂuence of the
NN, ε > 0 is an oﬀset to give every pair a non-zero weight, and U is the destroy
set selected so far. These weights can be interpreted as the sum of all NN outputs
for employee n in a window of 2z2 + 1 consecutive days around day d, specifying
the importance to add this range of employee-day pairs to the destroy set. We
randomly select an employee-day pair (n, d) proportional to these weights wnd,
add pairs (n, d′) for all d′ ∈{max(1, d −z2), . . . , d, . . . , min(|D|, d + z2)} to U,
and repeat this process z1 times. Eventually, for each (n, d) ∈U, we unassign
variables xt
nd′s for each shift s ∈S in the current solution.
5.4
Neural Networks
A GNN [12,36] is a NN architecture taking a graph as an input. It is typically
independent of a speciﬁc graph size and able to represent underlying structural
properties of a given graph by mapping it to a graph embedding expressed as
vectors of values on the graph’s nodes. We propose the following custom graph
representation for the SRRP, which is not a reformulation of the SRRP as a
graph problem but reﬂects a knowledge graph containing information for choos-
ing suitable employee-day pairs. We deﬁne this graph as G = (V, E, X), where
V is the set of nodes, E the set of edges, and X ∈R|V |×p a node feature matrix
assigning each node v ∈V a p-dimensional feature vector Xv = (Xv,1 . . . Xv,p).
The set of nodes V = Vemp ∪Vassign ∪Vday is composed of three diﬀerent
types which are employee Vemp = {n | n ∈N}, assignment Vassign = {(n, d) | n ∈
N, d ∈D}, and day Vday = {d | d ∈D} nodes. The assignment nodes repre-
sent the employee-day pairs. There are edges between an assignment node and
its associated employee and day nodes. Moreover, since the days represent a
sequence, we add edges between consecutive days.
There are thus O(|N| · |D|) nodes and edges, which is substantially less than
in a CVIG for the underlying MIP (e.g., as used in [2]). A reasonably fast training
and inference can therefore be expected. The interpretation of this representation
is that an employee is involved in an assignment and this assignment takes place
on a speciﬁc day in the planning horizon. A state st ∈ST, consisting of an
SRRP instance and its current solution xt, holds all the required information to
create such a graph structure. If we later use a state directly as an input to our
NN, we implicitly assume that it is ﬁrst transformed into such a graph.

308
F. F. Oberweger et al.
f1f2f3· · ·
fp
f1f2f3· · ·
fp
f1f2f3· · ·
fp
f1f2f3· · ·
fp
f1f2f3· · ·
fp
f1f2f3· · ·
fp
H(L)
v1
GNN
MLP
Node Features
Ouput Representation
∈[0, 1]
Node Values
H(L)
v2
H(L)
v3
H(L)
v4
H(L)
v5
H(L)
v6
∈[0, 1]
∈[0, 1]
∈[0, 1]
∈[0, 1]
Fig. 2. Simpliﬁed representation of the NN architecture for the destroy set model πθ;
ﬁgure inspired by [6].
Naturally, we have diﬀerent kinds of features with respect to employees, days,
and assignments. For example, employee node features include the number of
assignments to each shift s ∈S of an employee, day node features include the
total number of assignments to each shift s ∈S on a given day, and assign-
ment node features include the currently and originally assigned shift for an
employee-day pair. For the complete list of the features used, we refer to [31]. To
provide all these features to the GNN, one possibility would be to associate the
individual features with the respective types of nodes in the graph representa-
tion and to apply the relational graph convolutional network (R-GCN) [37] for
handling such an inhomogeneous graph with diﬀerent feature types on diﬀerent
node types. However, similar to Chalumeau et al. [6], we use a simpler app-
roach enabling us to employ more general GNNs for homogeneous graphs. Let
femp
1
, . . . , femp
qemp be the employee features, fassign
1
, . . . , fassign
qassign the assignment features,
and fday
1
, . . . , fday
qday the day node features, where qemp, qassign, qday are the number
of employee, assignment, and day node features, respectively. Then each feature
vector xv of a node v, independent of the node type, is of the form
(femp
1
, . . . , femp
qemp, fassign
1
, . . . , fassign
qassign, fday
1
, . . . , fday
qday, fenc
1
, fenc
2
, fenc
3
)
(4)
where fenc
1
, fenc
2
, fenc
3
∈{0, 1} is the mentioned one-hot encoding indicating whether
the node is an employee, assignment, or day node, respectively. For example, if
a node is an employee node, its feature vector contains the employee’s values
for femp
1
, . . . , femp
qemp, zeros for the assignment and day features, and the associated
one-hot encoding.
Architectures. So far, we have established the underlying graph structure.
Figure 2 shows a simpliﬁed representation of the NN architecture of πθ. First,
we employ a GNN similar to the neural network for graphs from [24]. Our GNN
updates the feature representation H(l) in a layer l by applying the update
function
H(l) = σ

H(l−1)W (l)
1
+ AH(l−1)W (l)
2
+ b(l)
,
(5)

A Learning Large Neighborhood Search for the SRRP
309
where H(0) = X, A is the adjacency matrix, σ is a non-linear activation function,
b(l) ∈Rq is the learnable bias, and W (l)
1 , W (l)
2
∈Rm×q denote the weight matri-
ces for layer l, where m, q ∈N0 are the input and output feature dimensions,
respectively. Applying the GNN to an input yields the node embedding H(L) of
the graph, where H(L)
v
is a vector for each node v ∈V . These vectors from the
GNN are further processed by a traditional MLP utilizing a sigmoid activation
in the last layer to yield a value in [0,1] for each node. We only require the ﬁnal
output for the assignment nodes.
To make the connection to our conditional generative modeling approach and
the conditional distribution π from Eq. (2) in Sect. 5.2, let πθ be our previously
presented NN, where θ are all the learnable parameters, including the GNN
and MLP weights. Remember that an action at
nd at step t indicates whether an
employee-day pair (n, d) ∈N × D is contained in the destroy set (at
nd = 1) or
not (at
nd = 0). Also, remember that the sets Vassign and N × D are isomorphic,
meaning that there is a one-to-one correspondence between each assignment
node and employee day pair (n, d) = v ∈Vassign. As Nair et al. [29] and Sonnerat
et al. [40], we deﬁne πθ to be a conditional-independent model of the form
πθ(at | st) =

(n,d)∈Vassign
πθ(at
nd | st),
(6)
which, given a state st, predicts the probability of an employee-day pair (n, d)
being contained in an optimal destroy set independently of the other employee-
day pairs. The probability πθ(at
nd | st) is a Bernoulli distribution, and we com-
pute its success probability μnd as
tnd = MLP(H(L)
(n,d); θ),
(7)
μnd = πθ(at
nd = 1 | st) =
1
1 + e−tnd .
(8)
As pointed out by Nair et al. [29], it is not possible to accurately model a multi-
modal distribution using the assumption of conditional independence. Despite
that, they reported strong empirical results. Mathematically more accurate alter-
natives are autoregressive models [4] or inferring one employee-day pair at a time
by repeatedly evaluating the NN. However, this increased accuracy comes at the
cost of substantially slower inference times [29,40], which are not reasonable in
our setting.
The architecture of the temperature NN πT
φ is similar to the architecture of
the destroy set model πθ but there are some key diﬀerences. The temperature
model πT
φ shall predict how strongly πθ shall inﬂuence the destroy set sampling
process in a speciﬁc state st. Therefore, we add the output of πθ as an additional
feature to the node features of the graph representation. More speciﬁcally, we
append the common node feature vector with μnd = πθ(at
nd = 1 | st) for assign-
ment nodes (n, d) = v ∈Vassign and zero for every other node v ∈Vemp ∪Vday.
Another diﬀerence is that a read-out layer is applied on the ﬁnal node represen-
tations HT,(L)
v
. This read-out layer aggregates the information over all nodes into

310
F. F. Oberweger et al.
a single vector by applying 
v∈V HT,(L)
v
. Finally, we employ an MLP with a soft-
max function in the last layer on this vector to return a probability for each tem-
perature in a predeﬁned set T = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 5}
to be the best selection. This classiﬁcation-based approach turned out to be more
eﬀective in practice than a regression model.
5.5
Training
The training set Dtrain = {(s
1:Tj
(j) , a
1:Tj
(j) )}M
j=1 for the destroy set model πθ contains
the data from M sampled trajectories of an expert strategy. For each such tra-
jectory j ∈{1, . . . , M} consisting of Tj steps, let {st
(j)}
Tj
t=1 be the states and
{at
(j)}
Tj
t=1 be the corresponding expert actions in the form of optimal destroy
sets. We learn the weights θ of our model πθ by minimizing the loss function
L(θ) = −
M

j=1
Tj

t=1
log πθ(at
(j) | st
(j)),
(9)
which is the negative log likelihood of the expert actions.
The training set DT
train = {(s
1:Tj
(j) , o
1:Tj
(j) , y
1:Tj
(j) )}MT
j=1 for the temperature model
πT
φ contains the outputs {ot
(j)}
Tj
t=1 of πθ in the respective states {st
(j)}
Tj
t=1 for each
sampled trajectory j = 1, . . . , M T. The associated labels {yt
(j)}
Tj
t=1 consist of a one-
hot encoding of the temperature found to be best by the expert for each time
step t of a trajectory j. Eventually, we optimize the weights φ by minimizing the
cross-entropy loss
LT(φ) = −
M T

j=1
Tj

t=1
yt
(j) log πT
φ(st
(j), ot
(j)).
(10)
We perform each training in mini-batches of size 32. In addition to Dtrain and
DT
train, we also create validation sets of the same form as the respective training
sets containing about a fourth of the total generated trajectories. This data is
hold out from Dtrain and DT
train to evaluate the progress on unseen data during
training. Furthermore, we apply early stopping [11, p. 246] to avoid overﬁtting.
As optimizer, we use ADAM [21] with a learning rate of 0.001 and an exponential
decay rate of 0.9 for the ﬁrst and 0.999 for the second momentum.
5.6
Training Data Generation
Our data generation process is inspired by the expert policy from Sonnerat et al.
[40], which uses local branching [9] to create optimal destroy sets in a given state.
In local branching, a constraint is added to the MIP that allows at most a certain
number of decision variables to change compared to a given incumbent solution.
In the following, we refer to the MIP extended with such a local branching
constraints as extended or local branching-based MIP. If this extended MIP is
solved to optimality in a current state st, an optimal destroy set can be derived

A Learning Large Neighborhood Search for the SRRP
311
by comparing the old solution xt with the new solution xt+1 and collecting the
variables with changed values. Since our destroy sets do not directly consist of
decision variables but employee-day pairs, the local branching constraint is in
our case

(n,d,s)∈N×D×S: xt
nds=0
xt+1
nds +

(n,d,s)∈N×D×S: xt
nds=1
(1 −xt+1
nds) ≤2η,
(11)
which ensures that at most η employee-day pairs change. Note that one employee-
day pair change always implies the change of two xnds variables, since each
employee must be assigned to exactly one shift, including the free shift, on each
day. In the following, we refer to iteratively solving the local branching-based
MIP and extracting the associated destroy set as our expert policy π∗.
To generate training samples for the destroy set model πθ, we apply the
Dataset Aggregation (DAGGER) algorithm which is an extension of classical
behavior cloning [34]. In the ﬁrst iteration, the expert policy is used to sample
trajectories for training instances. Sampling a trajectory using a policy ˆπ means
that in each state st at step t of an episode (LNS run), we store state st and the
expert action π∗(st) as a tuple in a dataset D, use ˆπ to create a destroy set at,
and move to the next state st+1 = T(st, at). Then, a model ˆπ1 is trained on the
expert actions for all the encountered states in D, to mimic the expert policy. In
the second iteration, we use ˆπ1 to sample more trajectories and add more data
to D. For this learned policy ˆπ1, we apply the destroy set sampling strategy from
Sect. 5.3 with temperature τ = 1 to generate a destroy set at in a current state
st. This process is in general iterated a certain number of times. Eventually, D
is the ﬁnal dataset which is used to train the destroy set model πθ.
The idea behind this algorithm is that trained models may encounter very
diﬀerent states than the expert strategy and it is also important to train on those.
Preliminary results showed in our case that DAGGER iterations slightly improve
the result, although we ultimately decided to only perform two iterations as our
expert policy is very time-consuming due to the iterative solving of the extended
MIP. To further speed up the data generation, we took the following additional
measures. First, we terminate the solving of the local branching-based MIP after
a deﬁned time limit, yielding a destroy set that is not guaranteed to be optimal.
Second, we execute the trajectory sampling for each SRRP training instance in
parallel. Lastly, we only create a training sample for every third visited state
when sampling trajectories with a trained model if the solution is feasible. See
[31] for more details on these reﬁnements.
Concerning the temperature model πT
φ, that steer the diversity of the ran-
domized employee-day pair selection process by choosing a value of τ. A lower
value increases the impact of πθ, while a higher one decreases it. We may also
interpret πT
φ as an evaluator of πθ. If the output of πθ for a speciﬁc state st
is highly promising/reliable, a lower temperature should be predicted for τ to
increase the inﬂuence of πθ. Vice versa, higher temperatures should be predicted
if the current output of πθ is not so likely to yield an improvement of the incum-
bent solution. To collect training data for πT
φ, we produce multiple trajectories

312
F. F. Oberweger et al.
using πθ, where each temperature τ ∈T is applied to sample three destroy sets
in a state st at step t of an episode. Let τ ∗
t be the temperature giving the best
destroy sets on average in a state st. The best average performance is determined
as follows: If the solution has been improved, we consider the objective value of
the newly created solution, otherwise the objective value of the initially con-
structed solution is used. At each step t, we add st, πθ(st), and τ ∗
t to a dataset
DT. Then, we move to the next state T(st, at
τ ∗
t ) using an action sampled with τ ∗
t
and repeat this process until the termination of the LNS.
6
Experimental Evaluation
All algorithms were implemented in Julia2 1.6.1 and all MIPs were solved by
Gurobi 9.1.0. The experiments were executed in single-threaded mode on a
machine with an Intel Xeon E5–2640 processor with 2.40 GHz and a memory
limit of 16 GB. Since it is essential to ﬁnd high-quality solutions fast in practice,
we worked with a time limit of 900 s to evaluate our optimization algorithms.
We use %-gap, an optimality gap in percent, to evaluate computational perfor-
mance. For an objective value o, the value of %-gap is 100·(o−lb)/o, where lb is
a lower bound for the optimal value obtained by solving the original MIP with
Gurobi for three hours.
A time limit of ﬁve seconds is applied for solving the sub-MIP in a call of
the repair operator of each LNS. For both the random and the learning-based
destroy operator, the values z1 = 150 and z2 = 2 are used since they gave a good
performance in preliminary experiments with the random destroy operator.
As baselines for our computational comparisons, we solved the MIP with
Gurobi and used the LNS with the random destroy operator. In the following
ﬁgures and tables, we will refer to these approaches as ILP and LNS RND,
respectively, while LNS NN denotes the ML-based LNS. As the training data
generation is time-consuming, we trained the NN of LNS NN on data generated
from a random single schedule with |N| = 110 employees and various sets of
disruptions only. In total, we used 200 and 150 random sets of disruptions for this
schedule to generate training trajectories for the destroy set and the temperature
model, respectively. To accelerate the training data generation, a time limit of
30 minutes and η = 375 was used for solving the extended MIP.
In the following experiment, we aim to show the strong performance of
LNS NN and its ability to generalize to diﬀerent schedules with diﬀerent num-
bers of employees despite the rather restricted training data generation. For
testing, we randomly created four schedules with 120, 130, 140, and 150 employ-
ees. For each of these schedules, 30 random sets of disruptions are sampled such
that there is a total of 120 SRRP instances. The time horizon is four weeks, i.e.,
|D| = 28. The instance generation and training process are detailed in [31].
Table 1 presents the results including average %-gaps and respective standard
deviations, average objective values, average numbers of performed iterations,
grouped according to the instance size |N|. It is clear that LNS NN performs
2 https://julialang.org.

A Learning Large Neighborhood Search for the SRRP
313
Table 1. Average results of the trained LNS NN, the LNS RND, and the ILP. For each
number of employees |N|, there are 30 SRRP instances. Objective values are divided
by 103 for improved readability.
LNS NN
LNS RND
ILP
|N|
%-gap
obj. val. iter.
%-gap
obj. val. iter.
%-gap
obj. val.
120 3.42 ± 0.53
926
118.93 4.36 ± 0.57
935
127.27 34.18 ± 13.74 1, 418
130 4.45 ± 0.40 1,079
113.30 5.22 ± 0.51 1, 088
128.10 28.51 ± 13.48 1, 495
140 8.04 ± 0.60 1,314
99.77 9.20 ± 0.58 1, 331
105.43 31.31 ± 11.79 1, 817
150 5.74 ± 0.41 1,427
95.57 6.87 ± 0.46 1, 446
100.97 26.71 ± 11.30 1, 880
(a)
(b)
Fig. 3. (a) Boxplots for the %-gaps ﬁnally obtained by LNS RND and LNS NN in
dependence of the numbers of employees |N|. (b) Solution quality development over
time, aggregated over all runs/instances; note that %-gaps are here presented in log-
scale.
better than LNS RND for each of these instance classes even if it is trained only
on the main schedule with |N| = 110. On average, LNS NN improves the gap
of LNS RND by about one percent for each instance class. In total, LNS RND
only reached better solutions than LNS NN for two of the 120 instances from
this experiment. LNS NN performs less iterations than LNS RND. This decrease
in iterations primarily comes from the fact that LNS NN ﬁnds more meaningful
destroy sets requiring more time to be repaired. These outcomes are even more
substantial considering that already LNS RND is a well-performing approach,
which clearly surpassing the pure MIP solving. Considering optimality gap on
average, LNS NN outperforms ILP by factors between 3.89 and 9.99 across all
instance groups.
Figure 3a visualizes the dominance of LNS NN over LNS RND and the sig-
niﬁcance of the diﬀerences with boxplots. Finally, Fig. 3b shows how the solution

314
F. F. Oberweger et al.
quality develops over time for LNS NN and LNS RND, aggregated over all runs
for all benchmark instances. Most important to note is that in the beginning
of the search, LNCS NN ﬁnds improving solutions much faster than LNS RND
does. While LNS NN reaches an optimality gap of less than 10% after 271 s on
average, it takes LNS RND 420 s. Also, LNS NN ﬁnds feasible solutions after
approximately 190 s and LNS RND only after 310 s on average. Last but not
least, remarkable are also the small standard deviations shown by the shaded
areas, indicating the robustness of both LNS variants.
7
Conclusion and Future Work
We proposed a learning LNS for solving the SRRP, where the destroy operator is
guided by a ML model trained upfront on representative problem instances with
an imitation learning approach. More speciﬁcally, a conditional generative model
predicts weights for all employee-day pairs, which are used in a randomized sam-
pling strategy based on consecutive day selection to derive high-quality destroy
sets. We use a custom graph structure modeling a current solution to the SRRP
as an input to a GNN. Other so far proposed learning LNS approaches employ
CVIG, resulting in prohibitively huge graphs for problems like the SRRP. In
addition to the main NN predicting the employee-day pair weights, a second NN
predicts a temperature value that controls the diversity of the destroy set sam-
pling process. Experimental results clearly indicate the beneﬁts of the learning
LNS over a reasonably designed and already well working classical LNS in terms
of solution quality and speed of solution improvement. Noteworthy also is the
excellent generalization capability to unseen and even larger SRRP instances.
The proposed learning LNS provides a scheme that may also be promising for
other classes of highly constrained COPs.
In future work, training and testing of the approach on more diverse and even
larger SRRP instances would be interesting. Investigating diﬀerent variants of
GNNs may lead to further improvements. Finally, ﬁnding ways to apply RL to
optimize a performance metric directly instead of relying on the time-expensive
imitation learning is a promising research direction.
References
1. Abe, K., Xu, Z., Sato, I., Sugiyama, M.: Solving NP-hard problems on graphs with
extended AlphaGo zero. arXiv preprint arXiv:1905.11623 (2020)
2. Addanki, R., Nair, V., Alizadeh, M.: Neural large neighborhood search. In: Learn-
ing Meets Combinatorial Algorithms at Conference on Neural Information Pro-
cessing Systems (2020)
3. Bello, I., Pham, H., Le, Q.V., Norouzi, M., Bengio, S.: Neural combinatorial opti-
mization with reinforcement learning. In: Workshop Proceedings of the 5th Inter-
national Conference on Learning Representations. OpenReview.net (2017)
4. Bengio, Y., Bengio, S.: Modeling high-dimensional discrete data with multi-layer
neural networks. In: Advances in Neural Information Processing Systems, vol. 12,
pp. 400–406. MIT Press (1999)

A Learning Large Neighborhood Search for the SRRP
315
5. Van den Bergh, J., Beli¨en, J., De Bruecker, P., Demeulemeester, E., De Boeck, L.:
Personnel scheduling: a literature review. Eur. J. Oper. Res. 226, 367–385 (2013)
6. Chalumeau, F., Coulon, I., Cappart, Q., Rousseau, L.-M.: SeaPearl: a constraint
programming solver guided by reinforcement learning. In: Stuckey, P.J. (ed.)
CPAIOR 2021. LNCS, vol. 12735, pp. 392–409. Springer, Cham (2021). https://
doi.org/10.1007/978-3-030-78230-6 25
7. Chen, M., Gao, L., Chen, Q., Liu, Z.: Dynamic partial removal: a neural network
heuristic for large neighborhood search. arXiv preprint arXiv:2005.09330 (2020)
8. Ernst, A.T., Jiang, H., Krishnamoorthy, M., Sier, D.: Staﬀscheduling and roster-
ing: a review of applications, methods and models. Eur. J. Oper. Res. 153, 3–27
(2004)
9. Fischetti, M., Lodi, A.: Local branching. Math. Program. 98, 23–47 (2003)
10. Gasse, M., Chetelat, D., Ferroni, N., Charlin, L., Lodi, A.: Exact combinatorial
optimization with graph convolutional neural networks. In: Advances in Neural
Information Processing Systems, vol. 32, pp. 15554–15566. Curran Associates, Inc.
(2019)
11. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press, Cambridge
(2016)
12. Gori, M., Monfardini, G., Scarselli, F.: A new model for learning in graph domains.
In: 2005 Proceedings of the IEEE International Joint Conference on Neural Net-
works, vol. 2, pp. 729–734. IEEE (2005)
13. He, H., Daume, H., III., Eisner, J.M.: Learning to search in branch and bound
algorithms. Adv. Neural. Inf. Process. Syst. 27, 3293–3301 (2014)
14. Hottung, A., Tierney, K.: Neural large neighborhood search for the capacitated
vehicle routing problem. In: Proceedings of the 24th European Conference on Arti-
ﬁcial Intelligence. FAIA, vol. 325, pp. 443–450. IOS Press (2020)
15. Howard, R.A.: Dynamic Programming and Markov Processes. Wiley, Hoboken
(1960)
16. Huang, J., Patwary, M., Diamos, G.: Coloring big graphs with AlphaGo zero. arXiv
preprint arXiv:1902.10162 (2019)
17. Huber, M., Raidl, G.R.: Learning beam search: utilizing machine learning to guide
beam search for solving combinatorial optimization problems. In: Machine Learn-
ing, Optimization, and Data Science - 7th International Conference, LOD 2021.
LNCS, vol. 11943. Springer (2021, to appear)
18. Jatschka, T., Oberweger, F.F., Rodemann, T., Raidl, G.R.: Distributing battery
swapping stations for electric scooters in an urban area. In: Olenev, N., Evtushenko,
Y., Khachay, M., Malkova, V. (eds.) OPTIMA 2020. LNCS, vol. 12422, pp. 150–
165. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-62867-3 12
19. Khalil, E., Dai, H., Zhang, Y., Dilkina, B., Song, L.: Learning combinatorial opti-
mization algorithms over graphs. In: Advances in Neural Information Processing
Systems, vol. 30, pp. 6348–6358. Curran Associates, Inc. (2017)
20. Khalil, E.B., Bodic, P.L., Song, L., Nemhauser, G.L., Dilkina, B.N.: Learning to
branch in mixed integer programming. In: Proceedings of the 30th AAAI Confer-
ence on Artiﬁcial Intelligence, pp. 724–731. AAAI Press (2016)
21. Kingma, D.P., Ba, J.: Adam: a method for stochastic optimization. In: Proceedings
of the 3rd International Conference on Learning Representations (2015)
22. Maenhout, B., Vanhoucke, M.: An evolutionary approach for the nurse rerostering
problem. Comput. Oper. Res. 38, 1400–1411 (2011)
23. Maenhout, B., Vanhoucke, M.: Reconstructing nurse schedules: computational
insights in the problem size parameters. Omega 41, 903–918 (2013)

316
F. F. Oberweger et al.
24. Micheli, A.: Neural network for graphs: a contextual constructive approach. IEEE
Trans. Neural Netw. 20, 498–511 (2009)
25. Moz, M., Pato, M.V.: An integer multicommodity ﬂow model applied to the reros-
tering of nurse schedules. Ann. Oper. Res. 119, 285–301 (2003)
26. Moz, M., Pato, M.V.: Solving the problem of rerostering nurse schedules with
hard constraints: new multicommodity ﬂow models. Ann. Oper. Res. 128, 179–
197 (2004)
27. Moz, M., Pato, M.V.: A genetic algorithm approach to a nurse rerostering problem.
Comput. Oper. Res. 34, 667–691 (2007)
28. Muller, L.F.: An adaptive large neighborhood search algorithm for the resource-
constrained project scheduling problem. In: 2009 Proceedings of the VIII Meta-
heuristics International Conference (2009)
29. Nair, V., et al.: Solving mixed integer programs using neural networks. arXiv
preprint arXiv:2012.13349 (2020)
30. Negrinho, R., Gormley, M.R., Gordon, G.J.: Learning beam search policies via
imitation learning. In: Advances in Neural Information Processing Systems, vol.
31, pp. 10675–10684. Curran Associates Inc. (2018)
31. Oberweger, F.F.: A learning large neighborhood search for the staﬀrerostering
problem. Diploma thesis, Institute of Logic and Computation, TU Wien, Austria
(2021)
32. Pato, M.V., Moz, M.: Solving a bi-objective nurse rerostering problem by using a
utopic pareto genetic heuristic. J. Heurist. 14, 359–374 (2008)
33. Pisinger, D., Ropke, S.: Large neighborhood search. In: Gendreau, M., Potvin, J.Y.
(eds.) Handbook of Metaheuristics. International Series in Operations Research &
Management Science, vol. 146, pp. 399–419. Springer, Boston (2010). https://doi.
org/10.1007/978-1-4419-1665-5 13
34. Pomerleau, D.A.: ALVINN: an autonomous land vehicle in a neural network. In:
Advances in Neural Information Processing Systems, vol. 1, pp. 305–313. MIT
Press (1988)
35. R¨onnberg, E., Larsson, T., Bertilsson, A.: Automatic scheduling of nurses: what
does it take in practice? In: Pardalos, P., Georgiev, P., Papajorgji, P., Neugaard,
B. (eds.) Systems Analysis Tools for Better Healthcare Delivery. Springer Opti-
mization and Its Applications, vol. 74, pp. 151–178. Springer, New York (2012).
https://doi.org/10.1007/978-1-4614-5094-8 8
36. Scarselli, F., Gori, M., Tsoi, A.C., Hagenbuchner, M., Monfardini, G.: The graph
neural network model. IEEE Trans. Neural Netw. 20, 61–80 (2008)
37. Schlichtkrull, M., Kipf, T.N., Bloem, P., van den Berg, R., Titov, I., Welling, M.:
Modeling relational data with graph convolutional networks. In: Gangemi, A., et
al. (eds.) ESWC 2018. LNCS, vol. 10843, pp. 593–607. Springer, Cham (2018).
https://doi.org/10.1007/978-3-319-93417-4 38
38. Shaw, P.: Using constraint programming and local search methods to solve vehicle
routing problems. In: Maher, M., Puget, J.-F. (eds.) CP 1998. LNCS, vol. 1520, pp.
417–431. Springer, Heidelberg (1998). https://doi.org/10.1007/3-540-49481-2 30
39. Song, J., Lanka, R., Yue, Y., Dilkina, B.: A general large neighborhood search
framework for solving integer linear programs. In: Advances in Neural Information
Processing Systems, vol. 33, pp. 20012–20023. Curran Associates, Inc. (2020)
40. Sonnerat, N., Wang, P., Ktena, I., Bartunov, S., Nair, V.: Learning a large
neighborhood search algorithm for mixed integer programs. arXiv preprint
arXiv:2107.10201 (2021)

A Learning Large Neighborhood Search for the SRRP
317
41. Syed, A.A., Akhnoukh, K., Kaltenhaeuser, B., Bogenberger, K.: Neural network
based large neighborhood search algorithm for ride hailing services. In: Moura
Oliveira, P., Novais, P., Reis, L.P. (eds.) EPIA 2019. LNCS (LNAI), vol. 11804, pp.
584–595. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-30241-2 49
42. Vinyals, O., Fortunato, M., Jaitly, N.: Pointer networks. In: Advances in Neural
Information Processing Systems, vol. 28, pp. 2692–2700. Curran Associates, Inc.
(2015)
43. Wickert, T.I., Smet, P., Berghe, G.V.: The nurse rerostering problem: strategies
for reconstructing disrupted schedules. Comput. Oper. Res. 104, 319–337 (2019)

A MinCumulative Resource Constraint
Yanick Ouellet and Claude-Guy Quimper(B)
Universit´e Laval, Qu´ebec, Canada
yanick.ouellet.2@ulaval.ca, claude-guy.quimper@ift.ulaval.ca
Abstract. The CUMULATIVE constraint is the key to the success of Constraint
Programming in solving scheduling problems with cumulative resources. It limits
the maximum amount of a resource consumed by the tasks at any time point.
However, there are few global constraints that ensure that a minimum amount
of a resource is consumed at any time point. We introduce such a constraint, the
MINCUMULATIVE. We show that ﬁltering the constraint is NP-Hard and propose
a checker and a ﬁltering algorithm based on the fully elastic relaxation used for
the CUMULATIVE constraint. We also show how to model MINCUMULATIVE
using the SOFTCUMULATIVE constraint. We present experiments comparing the
different methods to solve MINCUMULATIVE using Constraint Programming.
1
Introduction
Businesses and organizations often face scheduling problems where they must schedule
tasks while satisfying various resources constraints. In the Constraint Programming
community, with the CUMULATIVE constraint [1], signiﬁcant work [3,16,17] has been
devoted to scheduling problems where the resource usage of the tasks must not exceed
the capacity of the resource. The reverse case, where a resource must have a minimum
usage did not receive as much attention. However, many businesses and organizations
need to solve scheduling problems where they need to ensure that a sufﬁcient number
of employees are working at any given time.
We introduce MINCUMULATIVE, a new global constraint that enforces that a min-
imum amount of the resource is used at any time. We show that applying domain or
bounds consistency for this new constraint is NP-Hard. We propose a relaxed rule, the
UnderloadCheck, to detect failures and a ﬁltering algorithm related to this rule. We
also show how to model the MINCUMULATIVE using the SOFTCUMULATIVE con-
straint, a soft version of the CUMULATIVE. This allows us to use the strong energetic
reasoning rules of the CUMULATIVE.
We present relevant background in Sect. 2 and introduce the MINCUMULATIVE in
Sect. 3. We present the UnderloadCheck rule and checker algorithm in Sect. 4 while
Sect. 5 introduces the ﬁltering algorithm. We show how to model the MINCUMULA-
TIVE constraint using the SOFTCUMULATIVE constraint in Sect. 6. We compare the
difference in strength between the different approaches in Sect. 7. Finally, experimental
results are shown in Sect. 8 and Sect. 9 concludes the work.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 318–334, 2022.
https://doi.org/10.1007/978-3-031-08011-1_21

A MinCumulative Resource Constraint
319
2
Constraint Scheduling Background
A scheduling problem consists in scheduling a set I of n tasks over the time points
T = 0..hor −1. Each task i ∈I needs to execute without preemption for pi units of
processing time between its earliest starting time esti and its latest completion time lcti
and consumes hi units of a renewable resource, which are called height. A task i can
be described using the tuple ⟨i, esti, lcti, pi, hi⟩. One can compute the latest starting
time lsti = lcti −pi and the earliest completion time ecti = esti + pi of task i. We
say that task i has a compulsory part in the interval [lsti, ecti) if lsti < ecti. A task is
necessarily executing during its compulsory part, regardless of its starting time.
One can model a scheduling problem using a starting time variable Si for each task
i with domain dom(Si) = [esti, lsti]. Additional constraints can be added depending
on the particularity of the problem (e.g., constraints limiting the amount of resource
used, predecessor constraints, etc.). We say that task i is ﬁxed if there is only one value
in dom(Si). Thus we have Si = esti = lsti.
Signiﬁcant efforts have been made in the constraint programming community to
efﬁciently solve scheduling problems for which the capacity of the resource is limited.
The CUMULATIVE constraint [1] enforces that, at any time t, the sum of the heights of
the tasks in execution does not exceed the capacity C of the resource. Deciding whether
the CUMULATIVE constraint admits a solution is strongly NP-Complete [1]. Hence,
checker and ﬁltering algorithms for this constraint cannot apply domain or bounds con-
sistency and must instead rely on rules to partially detect failures or partially ﬁlter the
domains. Many such rules have been developed over the years, including the Overload
Check [9,27], the Time Tabling [3], the Edge Finding [14,17,26] and the Energetic Rea-
soning [2,5,16,19,25]. By using lazy clause generations [10,18] with the CUMULATIVE
constraint, Schutt et al. [23,24] closed many instances of hard scheduling problems.
Baptiste et al. [2] introduced a relaxation used in many rules for the CUMULATIVE
constraint: the fully elastic relaxation. This relaxation allows the energy ei = pi · hi
of a task to be spent anywhere in the interval [esti, lcti), regardless of the task’s height
or its non-preemption. For instance, on a resource of capacity 2, a task with esti = 0,
lcti = 4, pi = 4, and hi = 1 could execute using 2 units of the resource at time 0, one
unit at time 2 and one unit at time 3 for a total of pi · hi = 2 · 2 = 4 units of energy.
One of the strongest rules using the fully elastic relaxation is the energetic rea-
soning [2,16]. This rule, as the name suggests, is based on the notion of minimum
energy in an interval [l, u). The left shift of a task i in the interval, noted LS(i, l, u) =
hi · max(0, min(u, ecti) −max(l, esti)), is the amount of energy the task consumes
in the interval when it is scheduled at its earliest. Conversely, the right shift of task i
in interval [l, u), noted RS(i, l, u) = hi · max(0, min(u, lcti) −max(l, lsti)), is the
amount of energy in the interval when the task is scheduled at its latest. The minimum
intersection MI(i, l, u) = min(LS(i, l, u), RS(i, l, u)) is the minimum between the left
and right shift. It represents the minimum amount of energy that the task consumes in
the interval regardless of when it starts. The sum of the minimum intersection of all
tasks, noted MI(I, l, u) = 
i∈I
MI(i, l, u), is a fully elastic lower bound on the amount
of energy consumed in an interval. The energetic reasoning detection rule (1) states that
if there exists an interval such that the minimum intersection is greater than the energy

320
Y. Ouellet and C.-G. Quimper
available on the resource, i.e. C · (u −l), the CUMULATIVE constraint cannot be satis-
ﬁed. Baptiste et al. [2] showed that it is sufﬁcient to consider a subset of O(n2) intervals
said of interest to apply the rule.
∃[l, u) | MI(I, l, u) > C · (u −l) =⇒fail
(1)
Many industrial problems require that a resource has a minimum usage instead of,
or in addition to, a maximum. This is the case for the shifts scheduling [8] and the nurse
rostering [4] problems. Both problems consist in scheduling the shifts of employees or
nurses to satisfy a demand while minimizing the cost of exceeding it.
2.1
Global Cardinality Constraint
The Global Cardinality Constraint [13,15,22] GCC([X1, . . . , Xn], [v1, . . . , vm],
[l1, . . . , lm], [u1, . . . , um]) ensures that each value vi is assigned to at least li and at
most ui variables in X. If all tasks have a processing time pi = 1 and share the same
height, the GCC can be used to model the minimum usage of a resource. The variable
Xi represents the starting time of the task i. The values are the time points. When the
parameters uj are set to inﬁnity, the GCC forces each time point to be assigned a min-
imum number of times. However, there is currently no global constraint to handle the
general case where tasks have distinct processing times or distinct heights.
2.2
Generalized Cumulative
Beldiceanu and Carlsson [3] introduced a generalization of the CUMULATIVE con-
straint, presented in (2). The GENERALIZEDCUMULATIVE constraint supports tasks
with negative heights and an operator op ∈{≤, ≥} that allows the capacity of the
resource to be either a maximum that must not be exceeded or a minimum that must be
reached. One can use this generalization to model a problem where tasks must meet a
demand vector d = [d0, . . . , dhor−1]. The demand dt is the minimum amount of energy
that must be spent by the tasks at time t. We show how this can be done in Sect. 3. We
describe the portion of their algorithm that ensures that a minimum is reached.
GENERALIZEDCUMULATIVE(S, p, h, C, op)
def
⇐⇒

t

i
hi · boolToInt(Si ≤t < Si + pi) op C
(2)
To ﬁlter the GENERALIZEDCUMULATIVE constraint, Beldiceanu and Carlsson pro-
posed a sweep algorithm that performs a Time-Tabling reasoning. The main idea behind
the algorithm is to compute an upper bound of the resource usage at each time point and
check whether that upper bound satisﬁes the minimum capacity.
Let GOOD(t) = {i ∈I | hi > 0∧esti ≤t < lcti} be the set of tasks with positive
height that can execute at time point t. These tasks increase the usage of the resource
and thus can contribute to meet the minimum capacity. Let BAD(t) = {i ∈I | hi <
0 ∧lsti ≤t < ecti} be the set of tasks with a negative height that have a compulsory
part at time point t and therefore must execute at that time point. These tasks decrease

A MinCumulative Resource Constraint
321
the usage and thus make the minimum capacity harder to reach. The checker rule for
Beldiceanu and Carlsson’s algorithm is presented in (3). Recall that C is the constant
representing the capacity of the resource.
∃t

i∈GOOD(t)
hi +

i∈BAD(t)
hi < C =⇒Failure
(3)
The optimistic scenario occurs where, at a time point t, all GOOD(t) tasks that can
execute do so, and only the BAD(t) tasks that must execute due to their compulsory
parts do so. This means that if, at any time point, the sum is not enough to satisfy
the capacity, the constraint cannot be satisﬁed. Note that this rule does not take the
processing time of the tasks into account.
The ﬁltering rule (4) ﬁlters GOOD tasks based on this idea. Consider a task j and
a time point t. If the lower bound on the resource usage at time point t is insufﬁcient
to meet the minimum capacity without the contribution of task j, then task j must be
executing at time t. The domain of Sj is changed for dom(Sj) ∩[t −pi + 1, t].
∀t ∀j ∈GOOD(t)

i∈GOOD(t)
hi +

i∈BAD(t)
hi −hj < C =⇒lstj ≤t < ectj
(4)
2.3
SoftCumulative
De Clerc et al. [7] and Ouellet and Quimper [20] proposed checker and ﬁltering algo-
rithms for the SOFTCUMULATIVE constraint, a version of the CUMULATIVE constraint
where it is possible to overload the resource but at a cost. The deﬁnition of SOFTCU-
MULATIVE (5) generalizes the CUMULATIVE constraint by adding the overcost variable
Z, an upper bound on the cost incurred by overloading the resource. Note that it is not
an equality. Generally, the cost is either minimized or subject to another constraint.
Ouellet and Quimper [20] introduced a generic cost function, but, for the sake of
simplicity, we assume the cost function is linear in this paper. That is, overloading the
resource by x units of resources always costs x units.
SOFTCUMULATIVE(S, p, h, C, Z)
def
⇐⇒
Z ≥

t
max(0,

i
hi · boolToInt(Si ≤t < Si + pi) −C)
(5)
Ouellet and Quimper adapted the energetic reasoning for the SOFTCUMULATIVE
constraint. Instead of searching for one interval with an overload, their algorithm
searches for a partition of the time line into contiguous intervals such that the sum of
the overload in each interval is maximized. That sum is a lower bound on the overcost.
The partition can be computed in O(|T|2) steps using dynamic programming, where
T is the set of time points to partition. If the set T corresponds to the lower and upper
bounds of the intervals of interest, there is O(n2) time points and thus, computing the
partition is in O(n4). This is not reasonable for an algorithm that is called thousands of
times during the search. However, Ouellet and Quimper proposed to consider a set with
only 4n time points, which correspond to the est, ect, lst, and lct of the tasks. By doing

322
Y. Ouellet and C.-G. Quimper
so, the algorithm enforces a weaker ﬁltering, but the complexity is better. Neverthe-
less, they showed that, when used on the hard version of the CUMULATIVE constraint
(with Z = 0), the algorithm using only 4n time points applies the Time-Tabling and the
Edge-Finding rules of the CUMULATIVE constraint.
3
Min-Cumulative
We introduce the MINCUMULATIVE constraint that ensures that the sum of the heights
of the tasks in execution at each time point t is greater than or equal to the demand dt.
MINCUMULATIVE( [S1, . . . , Sn], [p1, . . . , pn],
[h1, . . . , hn], [d0, . . . , dhor−1]) ⇐⇒∀t ∈T

i∈I:Si≤t<Si+pi
hi ≥dt
(6)
This constraint is a special case of the GENERALIZEDCUMULATIVE constraint pre-
sented by Beldiceanu and Carlsson, but a specialized version allows the design of more
specialized and stronger checker and ﬁltering algorithms. One can model the MIN-
CUMULATIVE with GENERALIZEDCUMULATIVE by adding ﬁxed tasks of negative
heights to the problem to represent the demand. For each interval [l, u) of maximal
length such that dt = dt+1 ∀t ∈{l..u −2}, we created a ﬁxed task i with esti = l,
lcti = u, pi = u −l, and hi = −dl. For instance, a demand of [1, 1, 2, 2] in MINCU-
MULATIVE can be represented by two tasks with est1 = 0, lct1 = est2 = 2, lct2 = 4,
p1 = p2 = 2, h1 = −1, and h2 = −2. By ﬁxing the capacity C = 0 and using operator
op = ≥, the GENERALIZEDCUMULATIVE encodes the MINCUMULATIVE.
We can generalize the constraint where processing times and heights are variables
rather than constants. The algorithms we present can substitute the height and the pro-
cessing time by the maximum value in the domain of these variables.
Theorem 1. Deciding whether the MINCUMULATIVE constraint admits a solution is
NP-Complete even when domains are intervals.
Proof. Deciding whether MINCUMULATIVE is feasible is a special case of the strongly
NP-Complete unrestricted-output 3-Partition problem (3-Part-UO) [12]. Recall that
3-Part-UO is the problem of deciding whether it is possible to partition the multiset R
containing n = 3 m integers with a total sum of m · T into m multisets, each of sum T.
For each integer Ri, we declare a task with dom(Si) = [1, m], pi = 1, hi = Ri. The
demand is T at each of the m time points. The starting times of the tasks correspond to
the index of the set in which the matching integer is partitioned. The sum of the heights
of all tasks is m · T and there is m time points of demand T. Hence, each of the m time
points must have a usage of exactly T and corresponds to one of the m multisets.
⊓⊔
Since deciding the feasibility of MINCUMULATIVE is NP-Complete even when
domains are intervals, propagators cannot apply either bounds or domain consistency
and must instead rely on relaxed rules to detect failures or ﬁlter variables.
To enforce the MINCUMULATIVE, it is sufﬁcient to use a decomposition with sum-
mations and inequality constraints, as in (6). This method has the disadvantage of
requiring a number of constraints and variables that is function of the horizon. In prob-
lems with a large horizon, this solution may not scale. We propose solutions that scale
with the number of time points and that ﬁlters more than the decomposition.

A MinCumulative Resource Constraint
323
4
Underload Check
We introduce the underload check rule that detects when MINCUMULATIVE is unfea-
sible. This new rule is inspired from the overload check [27] and the fully elastic relax-
ation. As with the overload check, the underload check is not sufﬁcient to enforce the
MINCUMULATIVE. It needs to be paired with another rule, such as the time-tabling.
The underload detection rule is based on the rule for the lower-bound constraint, a
special case of the GCC constraint [22] where values must occur a minimum number of
times within a vector of variables. The detection rule ﬁnds a non-empty subset U ⊆T
of time points for which the energy of the tasks that can be spent at these time points is
not enough to satisfy the demand. When such a set exists, too much energy is spent in
T \U and not enough in U. We say that T \U is overloaded while U is underloaded.
Underload Detection Rule: The underload detection rule fails iff there exists a set of
time points U whose demand exceeds the energy of the tasks that can be executed
during U:
∃U ⊆T

t∈U
dt >

i∈I:[esti,lcti)∩U̸=∅
ei =⇒Failure
(7)
To apply the rule, we design a greedy algorithm (Algorithm 2) that schedules the
energy of the tasks, in non-decreasing order of lct, as early as possible. The algorithm
wastes the demand at a given time point only if there is no other option. We call that
waste overﬂow. Once all tasks are scheduled, time points where the demand was not
met are included in the set U. If there is none, U is empty. If U ̸= ∅, the constraint
cannot be satisﬁed.
The algorithm uses the time line data structure [9] which efﬁciently schedules tasks
according to the fully elastic relaxation. We begin by presenting a slightly modiﬁed
version of the time line. Since the time line was designed for the CUMULATIVE, we
replace the maximum capacity of the resource by the demand. We also prevent the
algorithm from allocating energy that is not used to fulﬁll the demand.
The time line is ﬁrst initialized with a vector of critical time points T C that con-
tains, in increasing order, the est and lct of the tasks without duplicates. We deﬁne
a vector of demand Δ of dimension |T C| −1. A critical time point T C[j] has an
associated demand Δ[j] = T C[j+1]−1
k=T C[j]
dk equal to the sum of the demand of the
time points in the semi-open interval [T C[j], T C[j + 1]). Two vectors, Mest and Mlct
map a task i to the index of its est and lct in T C such that esti = T C[Mest[i]] and
lcti = T C[Mlct[i]]. The time line uses a disjoint set (also called union-ﬁnd) data struc-
ture [11] S upon the integers 1..|T C| containing the indexes of the critical time points.
The operation S.union(i, j) merges the set containing i with the set containing j. The
operation S.findGreatest(i) returns the greatest element of the set containing i. It
has the same complexity as the classic find operation and is implemented by keeping a
map of the greatest element of each set and updating it when union is called. The time
line supports the operation ScheduleTask(i) (Algorithm 1), which schedules task i as
early as possible. Since the data structure is based on the fully elastic relaxation, the

324
Y. Ouellet and C.-G. Quimper
task can be preempted and can take more than its height at any given time point. It
overﬂows at a time point only if it has to.
ScheduleTask(i) is implemented differently than in [9]. The algorithm computes
the energy ei = hi·pi that needs to be scheduled (line 1). Using the disjoint set S, line 2
ﬁnds the ﬁrst time point j that is greater than or equal to esti whose the demand is not
yet satisﬁed. The while loop schedules as much energy as possible at that time point,
but no more than the demand. If the demand of the current critical time point is fulﬁlled
(Δt = 0), the algorithm merges, on line 3, the sets of indices containing j with the one
containing j + 1. This allows for future calls to S.findGreatest to return the next
time point with unfulﬁlled demand. The process is repeated until all the task’s energy
is scheduled or the demand in the interval [esti, lcti) is fulﬁlled.
Algorithm 1: ScheduleTask(i)
1 e ←hi · pi;
j ←Mest[i];
t1 ←−∞;
while e > 0 ∧t1 < lcti do
2
j ←S.findGreatest(j);
t1 ←T C[j];
τ ←min(Δ[j], e);
e ←e −τ;
Δ[j] ←Δ[j] −τ;
if Δ[j] = 0 then
3
S.union(j, j + 1);
Algorithm 2: UnderloadCheck(I, d)
InitializeTimeline(I, d);
for i ∈I sorted by
non-decreasing lct do
ScheduleTask(i);
1 return
S.findGreatest(1) = |T C|;
We present the UnderloadCheck (Algorithm 2). Once the time line is initialized, the
algorithm schedules each task in order of non-decreasing lct. The algorithm greedily
spends the task’s energy e = pi · hi as early as possible, but no more than the demand
at each time point. If the loop stops because of the condition t1 < lct, the unscheduled
energy of the task cannot be used to ﬁll the demand, because it would be scheduled after
the latest completion time of the task. Thus, the energy is lost and we say that the task
overﬂowed. Once all tasks are processed, the algorithm checks, on line 1, if all the sets
have been merged together. If so, the demand of all time points is met and the check
passes. Otherwise, the demand of at least one time point is not met and the check fails.
Example 1. Recall a task is deﬁned by ⟨i, esti, lcti, pi, hi⟩. Given the three tasks
⟨1, 2, 4, 2, 1⟩, ⟨2, 2, 5, 2, 1⟩, ⟨3, 0, 6, 2, 1⟩and a demand of 1 for each time point in
[0, 6), the UnderloadCheck computes the vector T C = [0, 2, 4, 5, 6] of critical time
points. In the disjoint sets data structure S, all these time points are in separate sets:
{0}, {2}, {4}, {5}, {6} (in this example, we use the time point values instead of indexes
for the sake of clarity). The demand vector is initialized to Δ = [2, 2, 1, 1].
The algorithm begins by scheduling task 1, which has the smallest lct, in interval
[2, 4) (see Fig. 1). Since all the demand for critical time point 2 is met, the disjoint set
{2} is merged with disjoint set {4}. The UnderloadCheck then processes task 2, which
has the second smallest lct. The algorithm ﬁnds the greatest time point greater than or

A MinCumulative Resource Constraint
325
1
2
3
Unmet
0
1
2
3
4
5
6
Overﬂow
Fig. 1. Visual representation of the time line after the execution of the UnderloadCheck. One
unit of demand has not been met in [5, 6).
equal to est2 = 2, which is 4. Hence, it schedules one unit at time point 4 and merges
the set {2, 4} with {5}. However, since lct2 = 5, the remaining unit of energy of task
2 is lost, causing an overload. The UnderloadCheck then processes the last task, 3. As
the greatest time point greater than or equal to est3 = 0 is 0, the algorithm schedules 2
units of energy of task 3 in the interval [0, 2), before merging the set {0} with {2, 4, 5}.
Once all tasks have been scheduled, we have S = {0, 2, 4, 5}, {6}. There is more than
one disjoint set in S, which means that the demand has not been completely met, leading
to a failure.
Theorem 2. UnderloadCheck returns true if and only if the underload detection
rule (7) does not fail.
Proof. (=⇒) When the algorithm decrements Δ[j], it schedules the task i to spend
its energy within [T C[j], T C[j + 1]) ⊆[esti, lcti). Once all tasks are scheduled, if
Δ = 0 (or equivalently S.findGreatest(1) = |T C|), all the demand is satisﬁed and
the elastic schedule built by the algorithm disproves the existence of a non-empty set U
that satisﬁes the underload check detection rule.
(⇐=) If the algorithm returns false, we show that there exists a set U that satisﬁes
the condition in (7). We associate a time interval τi to every task i. If task i does not
overﬂow, we set τi = ∅. If task i overﬂows, the critical index Mlct[i] belongs to a set A
in S forming an interval τi = [T C[min(A)], T C[max(A)]). The demand is completely
fulﬁlled in the time interval τi since Δ[j] = 0 for all critical points T C[j] ∈τi. Whether
task i overﬂows or not, we have 
j:[estj,lctj)⊆τi ej ≥
t∈τi dt.
Let U = [1, m]\ 
i∈I τi. Consider a task j such that [estj, lctj) ∩U ̸= ∅. Its
energy was fully spent inside U. Indeed, all the non-empty intervals τi such that lcti <
lctj were fulﬁlled before j was processed. Its energy was therefore spent before or
after τi. For non-empty intervals τi such that lcti ≥lctj, we necessarily have estj <
min(τi) and since the task is scheduled at its earliest, it was ﬁrst scheduled outside of
τi. Moreover, it could not be scheduled in τi as the time point Mest[i] would have been
merged to the set A that deﬁned τi, which contradicts estj < min(τi). Therefore, none
of the energy of j was scheduled within τi. Since all the energy of the tasks j such that
[estj, lctj)∩U ̸= ∅was scheduled in U and that this energy does not fulﬁll the demand,
the condition in (7) holds.
⊓⊔
Theorem 3. UnderloadCheck has a complexity of Θ(n) provided that the tasks are
already sorted by their latest completion times.

326
Y. Ouellet and C.-G. Quimper
Proof. Fahimi et al. [9] showed that ScheduleTask executes in O(1) amortized time
when |T C| ∈O(n). As our modiﬁcations only make it run faster since the energy of a
task is not always fully scheduled, the complexity remains unchanged. ScheduleTask
is called n times hence Θ(n).
⊓⊔
5
Underload Filtering
We can derive a ﬁltering rule from the UnderloadCheck by ﬁxing the starting time of
a task, as shown in (8). If the UnderloadCheck fails when task i starts at time t, then
task i obviously cannot start at time t and we can remove t from dom(Si).
¬UnderloadCheck(I\{i} ∪{⟨t, t + pi, pi, hi⟩}) =⇒Si ̸= t
(8)
By studying the set of time points U that makes the underload check fail, one can
derive a ﬁltering rule that prunes more than a single value from the domain of Si.
∃U ⊆T : &D > E
=⇒ecti ≥min{t ∈U | t ≥ecti} +
D −E
hi

where D =

t∈U
dt
E =

j∈I\{i}:[estj,lctj)∩U̸=∅
ej
(9)
To ﬁlter a given task i, the rule (9) uses a set of time points U for which the sum
of the demand D = 
t∈U
dt exceeds the energy E =

j∈I\{i}:[estj,lctj)∩U̸=∅
ej of the
tasks that can spend energy in U (except task i). If the energy of the tasks without i is
insufﬁcient to cover the demand for U by D −E units, then task i must spend D −E
units of energy in U. Thus, we can ﬁlter the earliest completion time such that i ends at
its earliest in U by the missing units.
5.1
Naive Algorithm
Algorithm 3 naively applies rule (8). For each task i, it ﬁxes the starting time to esti,
then it executes the UnderloadCheck. If the check fails, it increases the starting time
by one and executes the UnderloadCheck again. It repeats until it ﬁnds a starting time
t for which the check passes or there is a starting time that exceeds the latest starting
time of the task. In the ﬁrst case, it ﬁlters the earliest starting time of task i to t. In the
second case, it returns a failure. Filtering the latest completion time is symmetric.
This algorithm can fail even if the UnderloadCheck passes since the ﬁltering algo-
rithm, contrary to the UnderloadCheck, ﬁxes the current task, preventing it from hav-
ing elastic energy. Hence, the check performed by the ﬁltering algorithm is stronger.

A MinCumulative Resource Constraint
327
Algorithm 3: NaiveFiltering(I, D)
for i ∈I do
t ←lcti;
lcti ←ecti //Temporarily ﬁx i to its earliest;
while esti ≤lsti ∧
¬UnderloadCheck(I) do
esti ←esti +1;
lcti ←lcti +1;
if esti ≤lsti then
lcti ←t //Restore i to its original lcti;
else
return false // Failure;
return true // Consistent;
We call this algorithm naive because, although it is simple, it requires for each task,
in the worst case, lsti −esti calls to the UnderloadCheck, leading to a worst-case time
complexity of O(|T | · n2), which depends on the number of time points. However, this
does not make the algorithm irrelevant in practice. The best-case complexity is Θ(n2)
and it happens when there is no ﬁltering done. Furthermore, for a given task i, the
algorithm executes the UnderloadCheck 1 + k times, where k is the number of values
removed from the domain of S. Hence, the complexity of the algorithm increases only
if it ﬁlters, which is generally not frequent though essential.
5.2
Overﬂow Algorithm
We improve upon the naive algorithm by ﬁltering the earliest starting time of a task i
by more than one unit at a time, allowing the algorithm to directly apply rule (9). Let
δ =

j∈T C|T C
j ≥esti
Δ[T C
j ] be the amount of demand not met at or after esti after a call to
UnderloadCheck. Let j be the task with the smallest estj that overﬂowed such that
estj ≥esti. If such a task exists, let τ = estj otherwise let τ = esti. The starting time
of i can be ﬁltered such that esti ≥τ +

δ
hi

.
We now explain the intuition behind that ﬁltering. In the ﬁrst case, τ = esti. We
know that there are δ units to ﬁll after esti. Moving the task by one unit can free at most
hi units of energy (it can come from the overﬂow of either i or another task that will its
place). We need to move i by

δ
hi

to gain enough energy to satisfy the demand.
The second case occurs when τ > esti. In that case, we move i after the estj of the
task that overﬂowed, by an amount corresponding to the missing energy δ. This allows
j to take the place of i. The energy of i can then be used to fulﬁll the missing demand.
Example 2. Given two tasks ⟨1, 0, 6, 3, 1⟩and ⟨2, 0, 4, 3, 1⟩and a demand of 1 for each
time point in [0, 6), the overﬂow algorithm begins by ﬁltering task 1. It temporarily ﬁxes
task 1 such that lct1 = 3 before running the UnderloadCheck. Since the temporary

328
Y. Ouellet and C.-G. Quimper
lct1 is smaller than lct2 = 4, the UnderloadCheck starts by scheduling task 1 in [0, 3)
(see Fig. 2). Then, it schedules task 2. There are 3 units of energy to schedule and the
task can only be scheduled in [0, 4). The algorithm schedules one unit at time 3 and the
two remaining units are wasted. All tasks are scheduled, but two units of demand are
not met (δ = 2), as shown on Fig. 2. Since the UnderloadCheck fails, the overﬂow
algorithm ﬁlters task 1. As task 2 overﬂowed, we have τ = est2 = 0. The algorithm
ﬁlters est1 to τ +

δ
h1

= 0 + 2
1 = 2. Hence, the overﬂow algorithm increased the est1
by two units with a single call to UnderloadCheck.
The algorithm iteratively applies this rule until the UnderloadCheck passes (or
a failure is detected). Its worst-case complexity is as the naive algorithm’s but it
increments the esti by more than one unit, reducing the number of calls to the
UnderloadCheck.
6
Model with SoftCumulative
We show how to encode the MINCUMULATIVE using the SOFTCUMULATIVE. By
doing so, we can use the strong energetic reasoning rules from the algorithms intro-
duced by Ouellet and Quimper [20] for the SOFTCUMULATIVE.
Let I′ be a set of ﬁxed tasks that cover the horizon. For each interval [l, u) of
maximal length such that dj = dj+1 ∀j ∈{l..u −2}, we create a task i ∈I′ with
esti = l, lcti = u, pi = u −l, and hi = maxt(dt) −dl. We have this equivalence.
MINCUMULATIVE([Si | i ∈I], [pi | i ∈I], [hi | i ∈I], d) ⇐⇒
SOFTCUMULATIVE([Si | i ∈I ∪I′], [pi | i ∈I ∪I′], [hi | i ∈I ∪I′],
max
t (dt),

i
ei −

t
dt)
(10)
Lemma 1. The MINCUMULATIVE can be encoded as a SOFTCUMULATIVE as in (10).
Proof. The SOFTCUMULATIVE is associated to a resource of capacity maxt(dt) over
a horizon hor. The constraint allows an overﬂow of at most 
i∈I ei −
t dt units of
1
2
Unmet demand
0
1
2
3
4
5
6
Overﬂow
Fig. 2. Visual representation of the time line after the ﬁrst call to the UnderloadCheck by the
overﬂow algorithm, when ﬁltering task 1. Task 1 is scheduled in [0, 3). Task 2 has one unit
scheduled in [3, 4) and two units overﬂowed. Two units of demand are not met in [4, 6).

A MinCumulative Resource Constraint
329
energy. So at most maxt(dt)·hor+
i∈I ei −
t dt units of energy can be scheduled.
The energy of the tasks matches this bound meaning that the resource is fully used.

i∈I
ei +

i∈I′
ei =

i∈I
ei +

l
(max
t (dt) −dl) =

i∈I
ei + hor · max
t (dt) −

l
dl
Since the tasks in I′ consume maxt(dt) −dl units of energy at time l, the tasks in I
consume the remaining dl (and can overﬂow) as required by the MINCUMULATIVE.
The converse holds using the same argument.
⊓⊔
7
Comparing the Rules
We compare the check rules of the Time-Tabling (TT), the Underload Check (UC),
and the Energetic Reasoning (ER). The Underload Check rule, as mentioned earlier, is
insufﬁcient to enforce the MINCUMULATIVE constraint, as illustrated in Example 3.
Example 3. Consider an instance with two ﬁxed tasks such that est1 = 0, est2 = 1,
lct1 = 2, lct2 = 3, p1,2 = 2, h1,2 = 1 and a demand d = [1, 1, 2]. The Underload
Check rule ﬁnds no underloaded set since it schedules the ﬁrst unit of energy of task 1
at time point 1, the second unit at time point 2 and the two units of task 2 at time point
3. Even when the tasks are ﬁxed, the Underload Check relaxes the heights of the tasks.
On the other hand, the Time-Tabling ﬁnds that there are not enough tasks at time point
3 to satisfy the demand of 2. Similarly, the energetic reasoning ﬁnds that the minimum
intersection in the interval [1, 3) is 3. Since the demand in the interval is 2, there is one
unit of overcost. The sum of the energy of the tasks is 4 and the sum of the demand is 4
so the SOFTCUMULATIVE allows no overcost, hence the detection of the failure.
While the weakness of the Underload Check is to relax the height of the tasks, the
weakness of the Time-Tabling is that it does not take the processing time of the tasks
into account, as demonstrated by Example 4
Example 4. Consider a task (est1 = 0, lct1 = 5, p1 = 1, h1 = 1) and a demand
d = [1, 1, 1, 1]. The Time-Tabling notices that task 1 can cover the demand of each
time point individually and passes. The Underload Check and the Energetic Reasoning
quickly ﬁnd that there is not enough energy in task 1 to satisfy the overall demand.
Examples 3 and 4 show that the Underload Check and the Time-Tabling are incom-
parable when comes the time to detect infeasibility, as it is the case for the CUMULA-
TIVE. Lemma 2 shows that the energetic reasoning is stronger than the Time-Tabling.
Lemma 2. If the Time-Tabling checker fails, then the SOFTCUMULATIVE model using
the energetic reasoning checker also fails.
Proof. Suppose the Time-Tabling fails because the total height of the tasks at time t
is less than dt. Consider the partition T = [0, t) ∪[t, t + 1) ∪[t + 1, hor). From
Lemma 1, the resource is fully used. If it is underused in interval [t, t+1), it is overused
in [0, t)∪[t+1, hor). The energetic reasoning will therefore detect an overﬂow greater
than 
i ei −
t dt in the intervals [0, t) ∪[t + 1, hor) and thus, detect failure.
⊓⊔

330
Y. Ouellet and C.-G. Quimper
Lemma 3. If the Underload Check fails, then the SOFTCUMULATIVE model using the
energetic reasoning checker also fails.
Proof. Suppose that the Underload Check returns a failure when checking the set U.
The same reasoning as with Lemma 2 applies; the intervals in T \U have an overcost
greater than 
i ei −
t dt. Thus the SOFTCUMULATIVE fails.
⊓⊔
The SOFTCUMULATIVE with its energetic checker is stronger than the Underload
Check and Time-Tabling. In fact, it is strictly stronger, as shown in Example 5.
Example 5. Consider a demand d = [1, 3, 1] and two tasks: est1 = est2 = 0, lct1 = 2,
lct2 = 3, p1 = 2, p2 = 1, h1 = 2, and h2 = 1. The Time-Tabling passes since, when
considered individually, there can be three units of height at time points 0 and 1 and one
unit at time point 2. The Underload Check passes since the four units of energy of task
1 cover the demand of the ﬁrst two time points and the single unit of task 2 covers the
demand of the last time point. However, the SOFTCUMULATIVE model fails. Indeed, we
have MI(I, 0, 1) = 2, but the demand in [0, 1) is only 1. Hence, we have an overcost of
1 in that interval, but no overcost is allowed since 
i∈I ei −
t dt = (4 + 1) −5 = 0.
Hence the SOFTCUMULATIVE detects the failure.
8
Experiments
We tested our algorithm on two benchmarks. The ﬁrst contains randomly generated
instances of a simple problem with one MINCUMULATIVE constraint. The tasks have
a variable height in {0, 1} indicating whether a task is activated or not. The goal is to
satisfy the demand while minimizing the number of activated tasks. The instances are
available on Github1 and upon request to the second author. The Work Shift Schedul-
ing Benchmark is an industrial benchmark introduced by [6]. The problem consists in
scheduling the work shifts of employees while satisfying the demand. The benchmark
has instances with up to 10 activities, but we only use the instances with one activity.
Employee e ∈E can work between 6 to 8 hours. An employee e starts at time Se,1,
takes a 15-min break, resumes at Se2, takes a 1-hour lunch, resumes at Se,3, takes a 15-
min break, and resumes at Se,4. The 4 work periods are at least one hour. The demand
can vary at each 15-min time step. We minimize the number of employees. The model
for the decomposition of our constraint in smaller binary constraints is given in (11)–
(17). We replace (15) by the MINCUMULATIVE constraint for the other conﬁgurations.
We break symmetries with (16) and (17). The upper limit on the number of employees
is set to |E| = 10. This gives two unsatisﬁable instances, which allows us to observe the
behaviour of the algorithms on both satisﬁable and unsatisﬁable instances. The search
heuristic branches on the minimum value of He, then Pe, and ﬁnally Se,p.
minimize 
e∈E He subject to
(11)
Se,p + Pe,p + δ = Se,p+1
∀e ∈E, (p, δ) ∈{(1, 1), (2, 4), (3, 1)}
(12)
Se,4 + Pe,4 + 4 ≤|T|
∀e ∈E
(13)
1 https://github.com/yanickouellet/min-cumulative-paper-public.

A MinCumulative Resource Constraint
331
24 ≤

p∈{1..4}
Pe,p ≤32
∀e ∈E
(14)

e∈E,p∈{1..4}
He · (Se,p ≤t < Se,p + Pe,p) ≥dt
∀t ∈T
(15)
He ≤He−1 ∧Se−1,2 ≤Se,2
∀e ∈1..|E| −1
(16)
He = 0 =⇒Se,p = s
∀e ∈E, (p, s) ∈{(1, 0), (2, 5), (3, 13), (4, 18)}
(17)
We implemented our algorithms in Java using Choco solver version 4.10.6 [21]. We
ran the experiments on an Intel Xeon Silver 4110 (2.10 GHz). All models were imple-
mented in MiniZinc. Experiments for the random benchmark were done with a timeout
of 20 min. Since there are fewer instances, experiments for the Work Shift Scheduling
Benchmark were done with a timeout of 1 h.
We report the time taken to solve instances of the Work Shift Scheduling Bench-
mark in Table 1. We experimented two versions of the problem, one with variable pro-
cessing time and one with processing times ﬁxed to 6 periods. For solved instances,
the difference between the algorithms were similar, but we report only the latter since
few instances were solved to optimality in the former. We tested the following con-
ﬁgurations: the Decomposition (D), Time-Tabling ﬁltering (TT), Time-Tabling with
Underload Check (TT + UC), Time-Tabling with Underload Filtering (TT + UF), Time-
Tabling with Energetic Reasoning Check (TT + EC) and Energetic Filtering (EF). We
did not test the Underload algorithms alone since they are not sufﬁcient to enforce the
MINCUMULATIVE. Note that instances 7 and 10 are unsatisﬁable instances.
The decomposition (D) is the conﬁguration with the slowest solving times and it
can solve to optimality only half of the instances within one hour. Time-Tabling alone
is faster, but worse than when it is combined with Underload Check or Underload Fil-
tering. The combination of Time-Tabling and Underload Check is clearly the best con-
ﬁguration. It solves all instances to optimality and is faster on every instance than all
other conﬁgurations. The combination of Time-Tabling and Underload Filtering is the
second-best conﬁguration. However, the added cost of ﬁltering does not seem to be
worth the reduction in the search space it provides. Both Energetic Reasoning conﬁg-
urations are slower on this benchmark. They reduce the search space more than the
Underload Check conﬁgurations, but their high complexity is not worth it.
We report the results of the random benchmark in Table 2. The ﬁrst number in
the name of each instance indicates the number of tasks. We report only instances for
which at least one conﬁguration found the optimality within 20 min. We can see that the
Decomposition and Time-Tabling struggle on this benchmark, having difﬁculties solv-
ing instances of more than 20 tasks. On smaller instances, Time-Tabling combined with
Underload Check performs better than other conﬁgurations, while, on larger instances,
Time-Tabling combined with Energetic Check is better. The latter is the only conﬁgu-
ration able to solve all instances. We conclude that, as the problem becomes harder, the
combination of Time-Tabling and Energetic Checker becomes more interesting, even
with a slower complexity. However, as for the Work Shift Scheduling Benchmark, the
added cost of the Energetic Filtering is not worth the increased ﬁltering.

332
Y. Ouellet and C.-G. Quimper
Table 1. Time (s) and thousands of backtracks (bt) to optimally solve the work shift scheduling
problem. A dash (-) means that the optimal was not proved within 1 h. Instances 7 and 10 are
unsatisﬁable.
Instance
D
TT
TT + UC
TT + UF
TT + EC
EF
time (s)
bt
time (s)
bt
time (s)
bt
time (s)
bt
time (s)
bt
time (s)
bt
1
3.7
5.5
0.8
6.3
0.7
3.3
0.8
1.6
1.6
3.3
3.3
2.3
2
729.8
139.9
45.4
1,528.2
4.4
128.9
15.6
86.7
39.2
93.3
131.7
54.6
3
-
-
3,106.7
103,275.4
560.7
21,395.7
2,798.7
16.3
-
-
-
-
4
-
-
2,503.2
114,540.2
242.3
9,592.2
1,035.7
6,564.2
1,637.4
3,668.9
-
-
5
542.3
1,083.1
32.0
1,154.5
6.7
221.0
23.7
145.1
54.6
146.8
188.3
77.2
6
-
-
945.2
41,763.3
144.9
5,635.7
671.6
4,067.2
2,731,462.0
1.1
-
-
7
-
-
-
-
488.3
20,286.2
2,140.0
14,867.0
1,255.1
3,928.8
-
8
87.0
146.0
6.2
156.3
1.7
30.4
4.0
18.4
9.7
27.1
29.5
15.2
9
1.4
550.0
0.2
0.7
0.3
0.3
0.4
0.2
0.5
0.3
0.6
0.2
10
-
-
-
-
28.8
1,113.0
114.5
649.9
44.7
144.4
181.2
57.5
Table 2. Time (s) and thousands of backtracks (bt) to optimally solve random instances. (-) means
the optimal solution was not proved within 20 min. The ﬁrst number in the name of the instance
is the number of tasks.
Instance
D
TT
TT + UC
TT + UF
TT + EC
EF
time (s)
bt
time (s)
bt
time (s)
bt
time (s)
bt
time (s)
bt
time (s)
bt
20 1
87.4
3,776.6
125.5
12,900.0
0.3
12.6
0.9
12.6
1.3
8.7
3.9
8.4
20 2
0.5
0.9
0.4
7.9
0.1
2.4
0.4
2.4
0.2
1.3
1.3
1.2
20 3
0.3
0.3
0.2
1.1
0.1
1.0
0.3
1.0
0.2
0.8
0.9
0.8
20 4
31.8
1,463.6
248.0
20,035.1
0.2
6.2
0.5
6.3
0.4
3.7
2.3
2.8
20 5
512.9
2,1434.8
1,205.6
138,626.8
0.2
2.2
0.4
2.2
0.3
2.0
455.0
1,080.3
20 6
0.0
0.1
0.2
7.1
0.4
8.5
1.1
8.5
0.7
7.4
3.6
7.3
20 7
0.2
0.5
0.9
34.8
0.6
26.6
2.1
26.2
0.9
9.0
3.9
7.7
20 8
0.1
0.2
0.2
2.0
0.2
2.1
0.4
2.1
0.3
1.8
1.0
1.8
20 9
0.1
1.0
0.5
25.1
0.5
30.2
0.8
8.3
1.3
6.7
3.6
7.0
20 10
4.0
170.3
7.1
302.1
0.3
1.5
0.4
1.5
0.4
1.1
1.3
1.1
30 1
-
-
-
-
3.6
309.4
29.0
285.1
8.4
5.4
119.3
52.7
30 2
-
-
-
-
2.1
210.5
16.3
204.1
9.1
68.6
110.8
53.4
30 3
15.8
523.1
-
-
-
-
-
-
3.5
25.6
44.1
19.7
30 4
-
-
-
-
0.4
7.8
2.2
7.7
0.9
4.4
6.8
4.2
30 5
-
-
-
-
0.8
27.7
4.2
27.7
0.5
2.3
4.3
2.3
30 6
-
-
-
-
1,390.1
142,143.5
-
-
213.8
2,340.3
43.7
23.6
30 7
-
-
-
-
20.4
1,393.0
178.4
1,371.7
23.7
186.0
263.6
181.9
30 8
-
-
-
-
2.1
116.4
16.1
115.9
13.3
97.1
178.4
94.1
30 9
-
-
-
-
2.5
151.9
18.3
151.5
17.3
147.2
231.3
143.2
30 10
2.2
59.0
406.0
17,834.6
5.9
336.9
34.1
336.7
7.6
42.5
67.5
39.4
40 1
-
-
-
-
-
-
-
-
668.9
3,028.2
-
-
40 2
-
-
-
-
724.1
35,924.8
-
-
36.5
106.5
435.6
77.3
40 3
-
-
-
-
1,973.2
191,817.2
-
-
1,423.0
6,603.5
-
-
40 4
-
-
-
-
-
-
-
-
4.1
11.6
59.0
10.1
40 5
-
-
-
-
1,312.8
127,012.2
-
-
1,112.2
4,452.5
-
-
40 6
-
-
-
-
-
-
-
-
9.7
33.6
108.3
21.3
40 7
-
-
-
-
-
-
-
-
2,573.3
8,849.2
-
-
40 8
-
-
-
-
-
-
-
-
2,899.0
12,032.3
-
-

A MinCumulative Resource Constraint
333
9
Conclusion
The MINCUMULATIVE enforces tasks to cover a minimum demand. It is NP-Complete
to test for feasibility. We proposed a checker algorithm, the UnderloadCheck, and
two ﬁltering algorithms based on the checker: the Naive ﬁltering algorithm, and the
Overﬂow ﬁltering algorithm. MINCUMULATIVE can be encoded with a SOFTCUMU-
LATIVE. We compared the strength of the different checking rules. The combination of
Time-Tabling and Underload Check performs best in practice.
References
1. Aggoun, A., Beldiceanu, N.: Extending chip in order to solve complex scheduling and place-
ment problems. Math. Comput. Model. 17(7), 57–73 (1993)
2. Baptiste, P., Le Pape, C., Nuijten, W.: Constraint-Based Scheduling. Kluwer Academic Pub-
lishers (2001)
3. Beldiceanu, N., Carlsson, M.: A new multi-resource cumulatives constraint with negative
heights. In: Van Hentenryck, P. (ed.) CP 2002. LNCS, vol. 2470, pp. 63–79. Springer, Hei-
delberg (2002). https://doi.org/10.1007/3-540-46135-3 5
4. Burke, E.K., De Causmaecker, P., Berghe, G.V., Van Landeghem, H.: The state of the art of
nurse rostering. J. Sched. 7(6), 441–499 (2004)
5. Carlier, J., Sahli, A., Jouglet, A., Pinson, E.: A faster checker of the energetic reasoning for
the cumulative scheduling problem. Int. J. Prod. Res. 1–16 (2021)
6. Cˆot´e, M.C., Gendron, B., Quimper, C.G., Rousseau, L.M.: Formal languages for integer
programming modeling of shift scheduling problems. Constraints 16(1), 54–76 (2011)
7. De Clercq, A., Petit, T., Beldiceanu, N., Jussien, N.: A soft constraint for cumulative prob-
lems with over-loads of resource. In: Doctoral Programme of the 16th International Confer-
ence on Principles and Practice of Constraint Programming (CP 2010), pp. 49–54 (2010)
8. Ernst, A.T., Jiang, H., Krishnamoorthy, M., Owens, B., Sier, D.: An annotated bibliography
of personnel scheduling and rostering. Ann. Oper. Res. 127(1–4), 21–144 (2004)
9. Fahimi, H., Ouellet, Y., Quimper, C.-G.: Linear-time ﬁltering algorithms for the disjunctive
constraint and a quadratic ﬁltering algorithm for the cumulative not-ﬁrst not-last. Constraints
23(3), 272–293 (2018). https://doi.org/10.1007/s10601-018-9282-9
10. Feydy, T., Stuckey, P.J.: Lazy clause generation reengineered. In: Gent, I.P. (ed.) CP 2009.
LNCS, vol. 5732, pp. 352–366. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-
642-04244-7 29
11. Gabow, H.N., Tarjan, R.E.: A linear-time algorithm for a special case of disjoint set union. J.
Comput. Syst. Sci. 30(2), 209–221 (1985)
12. Garey, M.R., Johnson, D.S.: Computers and Intractability, vol. 174. Freeman, San Francisco
(1979)
13. Jean-Charles, R.E.: Generalized arc consistency for global cardinality constraint. In: Ameri-
can Association for Artiﬁcial Intelligence (AAAI 1996), pp. 209–215 (1996)
14. Kameugne, R., Fotso, L.P., Scott, J., Ngo-Kateu, Y.: A quadratic edge-ﬁnding ﬁltering algo-
rithm for cumulative resource constraints. Constraints 19(3), 243–269 (2014)
15. Katriel, I., Thiel, S.: Complete bound consistency for the global cardinality constraint. Con-
straints 10(3), 191–217 (2005)
16. Lopez, P., Esquirol, P.: Consistency enforcing in scheduling: A general formulation based on
energetic reasoning. In: 5th International Workshop on Project Management and Scheduling
(PMS 1996) (1996)

334
Y. Ouellet and C.-G. Quimper
17. Mercier, L., Van Hentenryck, P.: Edge ﬁnding for cumulative scheduling. INFORMS J. Com-
put. 20(1), 143–153 (2008)
18. Ohrimenko, O., Stuckey, P.J., Codish, M.: Propagation via lazy clause generation. Con-
straints 14(3), 357–391 (2009)
19. Ouellet, Y., Quimper, C.-G.: A O(n log2 n) checker and O(n2 log n) ﬁltering algorithm for
the energetic reasoning. In: van Hoeve, W.-J. (ed.) CPAIOR 2018. LNCS, vol. 10848, pp.
477–494. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-93031-2 34
20. Ouellet, Y., Quimper, C.G.: The softcumulative constraint with quadratic penalty. In: AAAI
Conference on Artiﬁcal Intelligence proceeding (2022, to appear)
21. Prud’homme, C., Fages, J.G., Lorca, X.: Choco solver documentation. TASC, INRIA
Rennes, LINA CNRS UMR 6241 (2016)
22. Quimper, C.G., Golynski, A., L´opez-Ortiz, A., Van Beek, P.: An efﬁcient bounds consistency
algorithm for the global cardinality constraint. Constraints 10(2), 115–135 (2005)
23. Schutt, A., Feydy, T., Stuckey, P.J.: Explaining time-table-edge-ﬁnding propagation for the
cumulative resource constraint. In: Gomes, C., Sellmann, M. (eds.) CPAIOR 2013. LNCS,
vol. 7874, pp. 234–250. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-
38171-3 16
24. Schutt, A., Feydy, T., Stuckey, P.J., Wallace, M.G.: Explaining the cumulative propagator.
Constraints 16(3), 250–282 (2011)
25. Tesch, A.: A nearly exact propagation algorithm for energetic reasoning in O(n2 log n). In:
Rueher, M. (ed.) CP 2016. LNCS, vol. 9892, pp. 493–519. Springer, Cham (2016). https://
doi.org/10.1007/978-3-319-44953-1 32
26. Vil´ım, P.: Timetable edge ﬁnding ﬁltering algorithm for discrete cumulative resources. In:
Achterberg, T., Beck, J.C. (eds.) CPAIOR 2011. LNCS, vol. 6697, pp. 230–245. Springer,
Heidelberg (2011). https://doi.org/10.1007/978-3-642-21311-3 22
27. Wolf, A., Schrader, G.: O(n log n) overload checking for the cumulative constraint and its
application. In: Umeda, M., Wolf, A., Bartenstein, O., Geske, U., Seipel, D., Takata, O. (eds.)
INAP 2005. LNCS (LNAI), vol. 4369, pp. 88–101. Springer, Heidelberg (2006). https://doi.
org/10.1007/11963578 8

Practically Uniform Solution Sampling
in Constraint Programming
Gilles Pesant1, Claude-Guy Quimper2, and H´el`ene Verhaeghe1(B)
1 Polytechnique Montr´eal, Montreal, Canada
{gilles.pesant,helene.verhaeghe}@polymtl.ca
2 Universit´e Laval, Quebec City, Canada
claude-guy.quimper@ift.ulaval.ca
Abstract. The ability to sample solutions of a constrained combinatorial space
has important applications in areas such as probabilistic reasoning and hard-
ware/software veriﬁcation. A highly desirable property of such samples is that
they should be drawn uniformly at random, or at least nearly so. For combina-
torial spaces expressed as SAT models, approaches based on universal hashing
provide probabilistic guarantees about sampling uniformity. In this short paper,
we apply that same approach to CP models, for which hashing functions take the
form of linear constraints in modular arithmetic. We design an algorithm to gen-
erate an appropriate combination of linear modular constraints given a desired
sample size. We evaluate empirically the sampling uniformity and runtime efﬁ-
ciency of our approach, showing it to be near-uniform at a fraction of the time
needed to draw from the complete set of solutions.
1
Introduction
Many important yet difﬁcult problems can be expressed on a constrained combinato-
rial space: ﬁnding a satisfying element (i.e. a solution) in that space and looking for an
optimal one according to some criterion are perhaps the most common tasks but count-
ing how many solutions there are and sampling solutions uniformly at random also
have important applications. Examples of the latter occurs in probabilistic planning [3],
Bayesian inference [10], code veriﬁcation [4], as well as other applications [5].
Model counters which follow an approach based on universal hashing beneﬁt from
probabilistic guarantees about the quality of the approximate count they provide. In the
context of SAT models expressed through Boolean variables, such universal hashing
takes the form of randomly generated parity (XOR) constraints [2]. In the wider context
of ﬁnite-domain variables and CP models the latter generalize to randomly generated
linear equality constraints in modular arithmetic, as recently investigated by Pesant et
al. [9]. Because hashing-based model counting operates by partitioning the solution
space into nearly-equal-size cells, it also offers an approach to solution sampling, which
has been exploited for SAT [7]. Even though in principle sampling the solutions of a
CP model could be achieved by ﬁrst translating the model into SAT, it would be much
preferable to do it directly in CP.
Vavrille et al. [11] recently proposed a solution sampler for CP inspired by that idea
of splitting the search space into cells and focusing on one such cell—adding random
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 335–344, 2022.
https://doi.org/10.1007/978-3-031-08011-1_22

336
G. Pesant et al.
TABLE constraints to a CP model—but unfortunately without any theoretical guaran-
tee about the quality of the sampling nor admittedly any generally-observed sampling
uniformity in practice. In this short paper, we add certain linear modular constraints—
sharing the same probabilistic guarantees as XOR constraints for SAT—in order to sam-
ple the solutions of a CP model. We show that in practice we achieve almost uniform
sampling. As in [11] our approach is independent of the actual CP model being sam-
pled and can be applied as long as the underlying CP solver supports such constraints.
Additionally it is very simple to use, without any parameters to tune.
The literature is scarce on the problem of sampling CP models. Gogate and Dechter
achieve uniform sampling on a CSP by ﬁrst expressing it as a factored probability dis-
tribution over its solutions, which requires that each constraint be given as a set of
allowed tuples [6]. Perez and R´egin sample solutions according to a given probability
distribution but require that the model be encoded as a single MDD constraint [8]. As
previously mentioned Vavrille et al. add randomly generated TABLE constraints to a
CP model thereby reducing the search space in a controlled manner prior to sampling
[11]. Parameters v and p respectively control the arity of a table and the probability of
a tuple being included. In practice v is chosen much smaller than the number of vari-
ables in order to keep in check the exponential growth of the tables, thus sacriﬁcing
uniformity in sampling.
In the rest of the paper Sect. 2 describes how a system of linear modular constraints
can be used to partition the search space and offer guarantees on the quality of the
sampling. We also give an algorithm to generate these constraints. Section 3 presents an
empirical evaluation and a comparison to the state of the art in constraint programming.
2
Solution Sampling
The core idea of our sampling algorithm, borrowed from an approach to approximate
model counting, is to employ pairwise-independent hash functions to partition the solu-
tion space into roughly equal-size cells of solutions. By aiming for a cell size corre-
sponding to the desired number of samples, we then focus on one such cell and exhaus-
tively enumerate its solutions. Note that while we could in principle enumerate solu-
tions up to the desired number from a much larger cell, this would either introduce a
bias in the sampling process from the branching heuristic used or require that we use
a totally random branching heuristic to the detriment of better-performing ones and
with poor uniformity as observed in [11]. Enumerating from an appropriately-sized cell
also means a smaller search space, which could bring computational savings. Finally,
because our samples come from the enumeration of a single smaller solution space, we
are guaranteed there will be no duplicates.
Such near-uniform partitioning of the solutions can be achieved by adding a system
of m linear modular equalities in n integer ﬁnite-domain variables
Ax = b
(mod p)
where x is a vector of n integer ﬁnite-domain variables, A an m × n matrix whose
elements belong to [p] ≜{0, 1, . . . , p−1}, b a vector of m elements from [p], and p the
modulus. Linear modular equalities are closely related to universal hash functions—we

Uniform Sampling in CP
337
recall two important properties [1]. Let modulus p be a prime number, x1, x2 ∈[p]n,
A, b be ﬁlled uniformly at random, and Pr[e] denote the probability of event e:
uniform partitioning of solutions: Pr[Ax1 = b (mod p)] =
1
pm
pairwise independence: Pr[Ax1 = b (mod p) | Ax2 = b (mod p)] =
1
pm
Another advantage of choosing p to be prime is that we can use Gauss-Jordan Elim-
ination (GJE) to simplify and solve our system of linear equations: when p is prime
every element of the ﬁnite ﬁeld Fp has a multiplicative inverse, which is required in
order to apply that algorithm. The system of linear equalities Ax = b (mod p) is thus
rewritten in parametric form. Then we encode its set of solutions—obtained by iterat-
ing through the domains of the parametric variables—as a TABLE constraint on all of
x. This way we can efﬁciently achieve domain consistency for the system by using e.g.
the compact table propagator. Details of the whole ﬁltering algorithm can be found in
[9].
Because the number of tuples for the TABLE constraint may be impractically large,
we postpone adding the constraint until certain conditions are met. In this work we used
the following:
– the size of the Cartesian product of the domains of the parametric variables falls
below a given threshold (here, 1000);
– the likelihood that the non-parametric variables (denoted as x′′) support a given
combination of parametric values, estimated as 
x∈x′′ |domain(x)|/p, falls below
a given threshold (here, 0.5).
Whenever either one of these conditions is met during search, a TABLE constraint is
added dynamically, and retracted upon backtracking.
So ultimately for ﬁltering we use TABLE constraints but, in contrast to Vavrille
et al. [11]: (i) we express them over the whole set of variables instead of some randomly-
chosen small subset; (ii) our tuples originate from hash functions with theoretical guar-
antees instead of being randomly selected according to some probabilistic threshold;
(iii) we generate TABLE constraints dynamically during search.
While linear modular constraints provide us with a way to distribute solutions fairly
evenly and independently among the partition of the search space into cells, we still
need to control the size of a cell so that it likely contains the desired number of solu-
tions. Simply adding an integral number m of linear modular equalities only provides
limited control on cell size especially when p is large: each cell amounts to 1/pm of
the search space. To correct this, linear modular inequalities can be added as well since
they provide a ﬁner control on cell size.
2.1
Systems of Linear Modular Inequalities
As we just saw, we need to handle systems of linear modular inequalities Ax + b ≤c
(mod p)1 in order to produce a cell containing about as many solutions as the desired
1 i.e. each congruent to one of {0, 1, . . . , c[i]}. We need to add b in the inequalities because
otherwise the probability that e.g. the null solution x = 0 satisﬁes the inequality would be
equal to 1.

338
G. Pesant et al.
number of samples. While the probabilistic guarantees of such systems were given in
Lemma 1 of Pesant et al. [9], namely
Pr[Ax + b ≤c] = Pr[Ax + b ≤c | Ay + b ≤c] =
m
i=1(c[i] + 1)
pm
,
no ﬁltering algorithm was provided for them. We now outline one that essentially recasts
this in terms of equalities. For notational convenience, we ﬁrst drop b by considering
that it has been appended to A and a variable ﬁxed to 1 appended to x. Transform
system Ax ≤c, seen as a conjunction of disjunctions of equalities (one conjunct per
constraint), into the equivalent disjunction of systems of equalities

0≤c′[i]≤c[i], 1≤i≤m
Ax = c′
by pushing in the conjunction. There will be (c[i]+1) disjuncts that we can represent
compactly as Ax “=” C with C being the m × (c[i] + 1) matrix representing the
right-hand side of each disjunct. We then proceed as in the case of equalities, applying
Gauss-Jordan Elimination on this augmented system and eventually enumerating tuples
to be fed to a TABLE constraint.
2.2
Sampling Algorithm
Algorithm 1 describes our sampling algorithm. It takes as input the desired size of the
sample expressed as a fraction λ of the number of solutions and a set of variables x
spanning the search space of the CP model. The latter are typically the branching vari-
ables, which totally determine a solution, and not necessarily all the model variables. In
particular auxiliary (i.e. dependent) variables need not be included. The algorithm ﬁrst
selects an appropriate value for p (e.g. from a precomputed table of prime numbers): p
should be large enough both to achieve (i) the previously-mentioned probabilistic guar-
antees and (ii) the desired cell size by offering at least a few possibilities in the choice
of right-hand side c for inequalities (with p = 3 the only option is c = 1). It then adds
to the CP model a suitable mix of m linear modular equality and inequality constraints
on x so that
m′
i=1(c[i] + 1)
pm
≈λ,
m′ ≤m,
as directed by Algorithm 2 described below. Finally it enumerates and returns all the
solutions in the resulting cell (i.e. the original CP model with the added linear modular
constraints). Note that it is sufﬁcient to branch on the parametric variables of the system
of equality constraints since assigning these ﬁxes the non-parametric variables as well.
We chose to specify the sample size relative to the number of solutions because it
does not require some approximation of the latter. If such an approximation is avail-
able, generating some given absolute number of samples can easily be done as well by
deriving the corresponding fraction.
The success of our approach relies on two factors: an even partition of solutions
into cells, provided by the linear modular constraints we use, and a relative cell size

Uniform Sampling in CP
339
Algorithm 1: Sampling algorithm
Input: sample fraction λ, model variables x
Output: set of sampled solutions
1 ℓ←largest domain value among x
2 p ←smallest prime ≥max(ℓ, 5)
3 m, F ←partition(λ, p)
4 m≤←|F|
5 m= ←m −m≤
6 if m= > 0 then
7
for i ←1 to m= do
8
b[i] ←U[p]
// choose uniformly at random from [p]
9
for j ←1 to |x| do A[i][j] ←U[p]
10
post Ax = b (mod p)
11
x′ ←parametric variables of Ax = b (mod p)
// from GJE solved form
12 else x′ ←x
13 if m≤> 0 then
14
for i ←1 to m≤do
15
remove a factor f from F
16
c[i] ←f −1
17
b[i] ←U[p]
18
for j ←1 to |x′| do A[i][j] ←U[p]
19
post Ax′ + b ≤c (mod p)
20 return all solutions of the resulting CP model, branching on x′
close to sample fraction λ. For the latter, we seek an expression whose denominator
is determined by m (given p) and whose numerator can be decomposed into at most
m factors all less than p (Algorithm 3), each giving rise to a corresponding inequality.
Algorithm 2 computes a suitably accurate combination of linear modular equalities and
inequalities to restrict the search space to a cell of the desired size. It repeatedly attempts
to reach the target accuracy (given by parameter ϵ, set to 0.01 in our experiments) while
keeping the numerator of our approximation to λ below threshold νmax (set to 100)
because it corresponds to the number of disjuncts in the translation of the system of
inequalities we will generate (Sect. 2.1), doubling parameter ϵ after each attempt until
we succeed. In practice it only requires a few attempts. In each attempt we consider,
for increasing values of m, a potential factorization of integral numerators ⌊ν⌋and ⌈ν⌉,
where ν is the exact rational numerator such that ν/pm = λ, provided that the resulting
approximation of λ would be accurate enough. For example partition(λ = 0.02, p =
11) requires two attempts, settling on m = 3 and F = ⟨9, 3⟩with a relative error below
0.015.
Algorithm 2 always terminates. Indeed, the inner loop increases ν on line 7 and
eventually exits the loop on line 9 if ν becomes too large. The outer loop increases ϵ on
line 12 and terminates on line 8 if it becomes too large.
Algorithm 3 decomposes integer a into the fewest factors (and no more than d),
none of them larger than f. Failing this, it returns an empty list. It is an adaptation of

340
G. Pesant et al.
Algorithm 2: partition(λ, p)
Input: sample fraction λ, modulus p
Output: number of constraints m and list of factors F
1 F ←⟨⟩
2 repeat
3
m ←0
4
ν ←λ
5
while F = ⟨⟩do
6
m ←m + 1
7
ν ←ν × p
8
if |ν−1|
ν
≤ϵ then return m, ⟨⟩
// equalities are sufficient
9
if ν > νmax then break
// numerator too large; try bigger ϵ
10
if ν−⌊ν⌋
ν
≤ϵ then F ←factorize(⌊ν⌋, p −1, m)
11
if F = ⟨⟩∧⌈ν⌉−ν
ν
≤ϵ then F ←factorize(⌈ν⌉, p −1, m)
12
ϵ ←2ϵ
13 until ν ≤νmax
14 return m, F
Algorithm 3: factorize(a, f, d)
Input: integer a to factorize, largest possible factor f, maximum number of factors d
Output: list F of factors
1 F ←⟨⟩
2 while a > 1 ∧f > 1 do
3
while a mod f = 0 do
4
add f to F
5
a ←a ÷ f
6
f ←f −1
7 if a = 1 ∧|F| ≤d then return F
8 else return ⟨⟩
the simple Trial division algorithm2 in which we instead try factors in decreasing order
to minimize the number of factors and thus maximize the number of equality constraints
we will use, which contributes to reduce the number of branching variables x′. Because
a ≤νmax and f < p using a more efﬁcient algorithm is not worthwhile.
3
Experiments
In this section we evaluate the sampling uniformity and computational efﬁciency of our
approach using benchmark instances from the literature. The java.util.Random
random number generator is used in all our experiments. The random table app-
2 https://en.wikipedia.org/wiki/Trial division.

Uniform Sampling in CP
341
roach [11] is evaluated using the authors’ own code. The code for our approach is
available as well.3
3.1
Benchmark Problems
For all our experiments, we based ourselves on four problems. The N-Queens problem
(used in [11]), the Feature Models problem (software conﬁguration problem, used in
[11]), a Synthetic n d problem (n variables of domain size d, composed of two sub-
problems, the total number of solutions is computable analytically, used and deﬁned
in [9]), and the Myciel problem (graph coloring, used in [9]). For the instances with a
low number of solutions (Feature Models, 9-Queens, Synthetic 10 5) we aim to gen-
erate as many samples as 30 times the number of solutions. For our approach we use
fraction λ ∈{0.01, 0.05, 0.25} (it is hard to go below 1% with that few solutions).
For the other instances (Myciel 4, 15-Queens, Synthetic 10 10) we perform 100 runs
with λ = 10−5. For the random table approach we use the best combination of param-
eters reported for instances appearing in [11] and their generally-recommended values
(κ = 16, p = 1/32) otherwise.
3.2
Quality of Sampling
As in [11], we evaluate the statistical quality of the sampling by computing the p-value
of Pearson’s χ2 statistic. Given the number of solutions to the problem nSol, the num-
ber of samples nSample, the number of occurrences nOcck of a solution k in the sam-
ples and P the expected number of occurrences of a given solution assuming a uniform
distribution (P = nSample
nSol
), we compute
zexp = nSol
k=1
(nOcck−P )2
P
.
The p-value is computed based on this expression.4 The closer to 1 the p-value is, the
closer to a uniform distribution the sampling is.
Figure 1 shows the evolution of this p-value as samples are drawn. We compare our
approach (Lin Mod) to that of [11] (Rnd table) as well as to an oracle (Oracle) that
simulates random sampling from the pool of all solutions by generating a sequence
of random integers between 1 and nSol. As pointed out in [11], this generator is not
perfect. Our study of the evolution of the p-value conﬁrms it.
For 9-Queens the random table approach had achieved very good uniformity for
some combinations of its parameters [11]. We achieve even nearer uniformity for all
three values of λ. On Synthetic, the random tables over 2 variables perform very well
(however, not as well over 4 variables) but our approach is practically perfect. Feature
Models is an instance for which it was reported that the random table approach did not
3 The sampling method is implemented in the MiniCPBP solver https://github.com/
PesantGilles/MiniCPBP and our examples on how to use the method are available https://
github.com/363734/UniformSampling.
4 The statistical library used is “Apache Commons Mathematics Library” (https://commons.
apache.org/proper/commons-math/).

342
G. Pesant et al.
(a) Feature (CSP)
(b) Feature (obj ≥17738)
(c) Myciel 4
(d) NQueens 9
(e) Synthetic 10 5
(f) Synthetic 10 10
Fig. 1. Evolution of the p-value for competing sampling approaches on six benchmark instances.
perform well. On the contrary we see that our approach yields very good uniformity,
even outperforming the oracle on the version with an unbounded objective. There is
also a marked difference in quality on Myciel, whose model features 21 variables.
So on these benchmarks our sampling approach generally leads to better uniformity
than the random table approach and even the oracle. Uniformity generally increases
with λ, which is expected since the number of samples drawn at a time increases as
well and these are necessarily distinct by design (we enumerate solutions in a more
constrained space) whereas the oracle sampler may generate the same solution multiple
times. A typical λ would be closer to 0.01 than to 0.25.
3.3
Runtime Efﬁcency of Our Sampling Approach
In the previous section we gave empirical evidence that our approach newly contributes
near-uniform sampling. But it remains to show that it is less time-consuming than the
brute-force approach of enumerating all solutions and then sampling uniformly at ran-
dom from them (i.e. the oracle). When the number of solutions is small the latter may
indeed be sufﬁcient but in a realistic setting we sample from a large pool of solu-
tions. Table 1 reports for the larger instances the runtime ratio between enumerating
the solutions in the whole search space and in a cell approximately 10−5 of its size
(our approach). In each case we observe computational savings, even by a few orders

Uniform Sampling in CP
343
Table 1. Runtime ratio between the other two approaches considered and ours to sample about
0.001% of solutions (for random table we use κ = 16, p = 1/32).
Instance
#solutions
#solutions
|search space|
Runtime ratio
Oracle
Random table
v = 2
v = 3
v = 4
15-Queens
2.28e+6
5.2e-12
5.4
2e-3
3e-3
1e-2
Myciel 4
1.42e+8
3.0e-07
12.6
0.9
1.3
4.8
Synthetic 10 5
1.53e+5
1.6e-02
105.1
4.7
5.3
5.3
Synthetic 10 10
9.92e+8
1.0e-01
1183.9
2.7
13.3
137.9
of magnitude, without being close to an ideal 105 ratio from the corresponding reduc-
tion in search space because there is an overhead in handling linear modular constraints
and recall that active domain ﬁltering through TABLE constraints occurs lower in the
search tree once they are posted. Better ratios appear to have more to do with the higher
density of solutions than the actual number of solutions (see Table 1, second and third
column). We also report the runtime ratio with the random table approach even though
its sampling is not nearly as uniform. Except for 15-Queens, it is not faster either.
4
Conclusion
We described a novel approach to sample the set of solutions of any CP model. It is
based on adding linear modular constraints to the model, thereby reducing its search
space while preserving the proportion of solutions, and then exhaustively exploring
that reduced search space. The amount of reduction being applied corresponds to
the fraction of solutions one wishes to sample. Experiments on benchmark problems
provided empirical evidence that our approach offers computationally-efﬁcient near-
uniform sampling.
Acknowledgements. We thank the anonymous reviewers for their constructive criticism which
helped us improve the original version of the paper. Financial support for this research was pro-
vided in part by NSERC Discovery Grants 218028/2017 and 05953/2016.
References
1. Chakraborty, S., Meel, K.S., Mistry, R., Vardi, M.Y.: Approximate probabilistic inference via
word-level counting. In: Schuurmans, D., Wellman, M.P. (eds.) Proceedings of the Thirtieth
AAAI Conference on Artiﬁcial Intelligence, 12–17 February 2016, Phoenix, Arizona, USA,
pp. 3218–3224. AAAI Press (2016)
2. Chakraborty, S., Meel, K.S., Vardi, M.Y.: A scalable approximate model counter. In: Schulte,
C. (ed.) CP 2013. LNCS, vol. 8124, pp. 200–216. Springer, Heidelberg (2013). https://doi.
org/10.1007/978-3-642-40627-0 18
3. Domshlak, C., Hoffmann, J.: Probabilistic planning via heuristic forward search and
weighted model counting. J. Artif. Intell. Res. 30, 565–620 (2007)

344
G. Pesant et al.
4. Dutra, R.T.: Efﬁcient sampling of SAT and SMT solutions for testing and veriﬁcation. Ph.D.
thesis, University of California, Berkeley (2019)
5. Fichte, J.K., Hecher, M., Hamiti, F.: The model counting competition 2020. J. Exp. Algo-
rithmics (JEA) 26, 1–26 (2021)
6. Gogate, V., Dechter, R.: A new algorithm for sampling CSP solutions uniformly at ran-
dom. In: Benhamou, F. (ed.) CP 2006. LNCS, vol. 4204, pp. 711–715. Springer, Heidelberg
(2006). https://doi.org/10.1007/11889205 56
7. Meel, K.S., et al.: Constrained sampling and counting: universal hashing meets SAT solving.
In: Darwiche, A. (ed.) Beyond NP, Papers from the 2016 AAAI Workshop, Phoenix, Arizona,
USA, 12 February 2016, volume WS-16-05 of AAAI Workshops. AAAI Press (2016)
8. Perez, G., R´egin, J.-C.: MDDs: sampling and probability constraints. In: Beck, J.C. (ed.) CP
2017. LNCS, vol. 10416, pp. 226–242. Springer, Cham (2017). https://doi.org/10.1007/978-
3-319-66158-2 15
9. Pesant, G., Meel, K.S., Mohammadalitajrishi, M.: On the usefulness of linear modular arith-
metic in constraint programming. In: Stuckey, P.J. (ed.) CPAIOR 2021. LNCS, vol. 12735,
pp. 248–265. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-78230-6 16
10. Sang, T., Beame, P., Kautz, H.A.: Performing Bayesian inference by weighted model count-
ing. In: AAAI, vol. 5, pp. 475–481 (2005)
11. Vavrille, M., Truchet, C., Prud’homme, C.: Solution sampling with random table constraints.
In: Michel, L.D. (ed.) 27th International Conference on Principles and Practice of Con-
straint Programming, CP 2021, Montpellier, France (Virtual Conference), 25–29 October
2021. LIPIcs, vol. 210, pp. 56:1–56:17. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik
(2021)

Training Thinner and Deeper Neural
Networks: Jumpstart Regularization
Carles Riera1(B), Camilo Rey1(B), Thiago Serra2(B), Eloi Puertas1(B),
and Oriol Pujol1(B)
1 Universitat de Barcelona, Barcelona, Spain
crieramo8@alumnes.ub.edu, camilorey@gmail.com,
{epuertas,oriol pujol}@ub.edu
2 Bucknell University, Lewisburg, USA
thiago.serra@bucknell.edu
Abstract. Neural networks are more expressive when they have multi-
ple layers. In turn, conventional training methods are only successful if
the depth does not lead to numerical issues such as exploding or vanish-
ing gradients, which occur less frequently when the layers are suﬃciently
wide. However, increasing width to attain greater depth entails the use of
heavier computational resources and leads to overparameterized models.
These subsequent issues have been partially addressed by model compres-
sion methods such as quantization and pruning, some of which relying
on normalization-based regularization of the loss function to make the
eﬀect of most parameters negligible. In this work, we propose instead to
use regularization for preventing neurons from dying or becoming linear,
a technique which we denote as jumpstart regularization. In comparison
to conventional training, we obtain neural networks that are thinner,
deeper, and—most importantly—more parameter-eﬃcient.
Keywords: Deep learning · Model compression · ReLU networks
1
Introduction
Leap, and the net will appear.
Anonymous
Artiﬁcial neural networks are inspired by the simple, yet powerful idea that
predictive models can be produced by combining units that mimic biological
neurons. In fact, there is a rich discussion on what should constitute each unit
and how the units should interact with one another. Units that work in parallel
form a layer, whereas a sequence of layers transforming data unidirectionally
deﬁne a feedforward network. Deciding the number of such layers—the depth of
the network—is yet a topic of debate and technical challenges.
A neural network is trained for a particular task by minimizing the loss
function associated with a sample of data in order for the network to learn a
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 345–357, 2022.
https://doi.org/10.1007/978-3-031-08011-1_23

346
C. Riera et al.
function of interest. Although several universal approximation results show that
mathematical functions can generally be approximated to arbitrary precision by
single-layer feedforward networks, these results rely on using a very large number
of units [12,26,43]. Moreover, simple functions such as XOR cannot be exactly
represented with a single layer using the most typical units [45].
In fact, it is commonly agreed that depth is important in neural networks
[7,38]. In the popular case of feedforward networks in which each unit is a Rec-
tiﬁed Linear Unit (ReLU) [18,21,38,47], the neural network models a piecewise
linear function [3]. Under the right conditions, the number of such “pieces”—the
linear regions—may grow exponentially on the depth of the network [46,48,67].
Depending on the total number of units and size of the input, the number of
linear regions is maximized with more or less layers [58]. Similarly, there is an
active area of study on bounding the number of layers necessary to model any
function that a given type of network can represent [3,14,20,27,45,69].
Although shallow networks present competitive accuracy results in some
cases [4], deep neural networks have been established as the state-of-the-art over
and again in areas such as computer vision and natural language processing [13,
24,29,30,37,39,62,70] thanks to the the development and popularization of back-
propagation [41,54,71]. However, Stochastic Gradient Descent (SGD) [53]—the
training algorithm associated with backpropagation—may have diﬃculties to
converge to a good model due to exploding or vanishing gradients [6,28,35,49].
Exploding and vanishing gradients are often attributed to excessive depth,
inadequate choice of parameters for the learning algorithm, or inappropriate
scaling between network parameters, inputs, and outputs [17,32]. This issue
has also inspired unit augmentations [25,44,60], additional connections across
layers [23,30], and output normalization [32,52]. Indeed, it is somewhat intuitive
that gradient updates, depth, and parameter scaling may aﬀect one another.
In lieu of reducing depth, we may also increase the number of neurons per
layer [22,64–66,72]. That leads to models that are considerably more complex,
and which are often trained with additional terms in the loss function such as
weight normalization to induce simpler models that hopefully generalize better.
In turn, that helps model compression techniques such as network pruning meth-
ods to remove several parameters with only minor impact to model accuracy.
Nonetheless, vanishing gradients may also be caused by dead neurons when
using ReLUs. If dead, a ReLU only outputs zero for every sample input. Hence, it
does not contribute to updates during training and neither to the expressiveness
of the model. To a lesser but relevant extent, similar issues can be observed with
a RELU which never outputs zero, which we refer to as a linear neuron.
In this work, we aim to reverse neurons which die or become linear during
training. Our approach is based on satisfying certain constraints throughout the
process. For a margin deﬁned for each unit, at least one input from the sample is
above and another input is below. For each layer and input from the sample, at
least one unit in the layer has that input above such a margin and another unit
has it below. In order to use SGD for training, these constraints are dualized as
part of the loss function and thus become a form of regularization that would
prevent converging with the original loss function to spurious local minima.

Training Thinner and Deeper Neural Networks: Jumpstart Regularization
347
2
Background
We consider a feedforward neural network modeling a function ˆy = fθ(x) with
an input layer x = h0 = [h0
1 h0
2 . . . hl
n0]T , L hidden layers, and each layer ℓ∈
L = {1, 2, . . . , L} having nℓunits indexed by i ∈Nℓ= {1, 2, . . . , nℓ}. For each
layer ℓ∈L, let W ℓbe the nℓ× nℓ−1 matrix in which the j-th row corresponds
to the weights of neuron j in layer ℓand bℓbe vector of biases of layer ℓ. The
preactivation output of unit j in layer ℓis gℓ
i = W ℓ
j hℓ−1 + bℓ
j and the output
is hℓ
j = σ(gℓ
j) for an activation function σ, which if not nonlinear would allow
hidden layer ℓto be removed by directly connecting layers ℓ−1 and ℓ+ 1 [55].
We refer to gℓ(χ) and hℓ(χ) as the values of gℓand hℓwhen x = χ.
For the scope of this work, we consider the ReLU activation function σ(u) =
max{0, u}. Typically, the output of a feedforward neural network is produced by
a softmax layer following the last hidden layer [10], ˆy = ρ(hL) with ρ(hL)j =
ehL
j / nL
k=1 ehL
k ∀j ∈{1, . . . , nL}, which is a peripheral aspect to our study.
The neural network is trained by minimizing a loss function L over a
parameter set θ := {(W ℓ, bℓ)}L
ℓ=1 based on the N samples of a training set
X := {(xi)}N
i=1 to yield predictions {ˆyi := fθ(xi)}N
i=1 that approximate the sam-
ple labels {yi}N
i=1 using metrics such as least squares or cross entropy [19,59]:
min
θ
L

θ,

(ˆyi, yi)
N
i=1

(1)
s.t.
ˆyi = fθ(xi)
∀i ∈{1, 2, . . . , N}
(2)
whereas a neural network is not typically trained through constrained optimiza-
tion, we believe that our approach is more easily understood under such a mind-
set, which aligns with further work emerging from this community [8,15,31].
3
Death, Stagnation, and Jumpstarting
Every ReLU is either inactive if gℓ
i ≤0 and thus hℓ
i = 0 or active if gℓ
i > 0 and
thus hℓ
i = gℓ
i > 0. If a ReLU does not alternate between those states for diﬀerent
inputs, then the unit is considered stable [68] and thus the neural network models
a less expressive function [56]. In certain cases, those units can be merged or
removed without aﬀecting the model [55,57]. We consider in this work a superset
of such units—those which do not change of state at least for the training set:
Deﬁnition 1. For a training set X, unit j in layer ℓis dead if hℓ
j(xi) = 0 ∀i ∈
{1, 2, . . . , N}, linear if hℓ
j(xi) > 0 ∀i ∈{1, 2, . . . , N}, or nonlinear otherwise.
Layer ℓdead or linear if all of its units are dead or linear, respectively.
Figures 1a to 1c illustrate geometrically the classiﬁcation of the unit based
on the training set. If dead, a unit impairs the training of the neural network
because it always outputs zero for the inputs in the training set. Unless the
units preceding a dead unit are updated in such a way that the unit is no longer
dead, then the gradients of its output remain at zero and the parameters of the

348
C. Riera et al.
(a) Dead unit
(b) Linear unit
(c) Nonlinear unit
(d) Dead point
(e) Linear point
(f) Nonlinear point
Fig. 1. A unit j in layer ℓseparates the input space hℓ−1 into an open half-space
W ℓ
j hℓ−1 + bℓ
j > 0 in which the unit is active and a closed half-space W ℓ
j hℓ−1 + bℓ
j ≤0
in which the unit is inactive. The arrow in each case points to the active side. The unit
is dead if the inputs from training set X lie exclusively on the inactive side (a); linear
if exclusively on the active side (b); and nonlinear otherwise (c). In turn, an input is
considered a dead point if it is in the closed half-space W ℓ
j hℓ−1 + bℓ
j ≤0 in which
each and every unit j ∈Nℓis inactive (d); a linear point if it is in the open half-space
W ℓ
j hℓ−1 + bℓ
j > 0 in which each and every unit j ∈Nℓis active (e); and a nonlinear
point otherwise (f).
dead unit are no longer updated [42,61], which eﬀectively reduces the modeling
capacity. If a layer dies, then the training stops because the gradients are zero.
For an intuitive and training-independent discussion, we consider incidence
of dead layers at random. If the probability that a unit is dead upon initialization
is p, as reasoned in [42], then layer ℓis dead with probability pnℓand at least
one layer is dead with probability 1 −L
ℓ=1(1 −p)nℓ. If a layer is too thin or the
network is too deep, then the network is more likely to be untrainable. We may
discard dead unit initializations, but that ignores the impact on the training set:
Deﬁnition 2. For a hidden layer ℓ∈L, an input x is considered a dead point
if hℓ(x) = 0, a linear point if hℓ(x) > 0, and a nonlinear point otherwise.
Figures 1d to 1f illustrate geometrically the classiﬁcation of a point based
on the activated units. If xi ∈X is a dead point at layer ℓ, then there is no
backpropagation associated with xi to the hidden layers 1 to ℓ−1. Hence, its
contribution to training is diminished unless a subsequent gradient update at a
preceding unit reverts the death. If ℓ= L, then xi is eﬀectively not part of the
training set. If all points die, regardless of the layer, then training halts.
If we also associate a probability q for xi not activating a unit, then xi is dead
for layer ℓwith probability qnℓand for at least one layer of the neural network
with probability 1 −L
ℓ=1(1 −q)nℓ. Unlike p, q is bound to be signiﬁcant.

Training Thinner and Deeper Neural Networks: Jumpstart Regularization
349
We may likewise regard linear units and linear points as less desirable than
nonlinear units and nonlinear points. A linear unit limits the expressiveness of
the model, since it always contributes the same linear transformation to every
input in the training set. A linear point can be more diﬃcult to discriminate
from other inputs, in particular if those inputs are also linear points.
Inspired by the prior discussion, we formulate the following constraints:
max
xi∈X gℓ
j(xi) ≥1
∀ℓ∈L, j ∈Nℓ
(3)
min
xi∈X gℓ
j(xi) ≤−1
∀ℓ∈L, j ∈Nℓ
(4)
max
j∈Nℓgℓ
j(xi) ≥1
∀ℓ∈L, xi ∈X
(5)
min
j∈Nℓgℓ
j(xi) ≤−1
∀ℓ∈L, xi ∈X
(6)
Dead and linear units are respectively prevented by the constraints in (3) and
(4). Dead and linear points are prevented by the constraints in (5) and (6). Then
we dualize those constraints and induce their satisfaction through the objective:
min
θ
L

θ,

(ˆyi, yi)
N
i=1

+ λP(ξ+, ξ−, ψ+, ψ−)
(7)
s.t.
ˆyi = fθ(xi)
∀i ∈{1, 2, . . . , N}
(8)
ξ+
jℓ= max

0, 1 −max
xi∈X gℓ
j(xi)
	
∀ℓ∈L, j ∈Nℓ
(9)
ξ−
jℓ= max

0, −1 −min
xi∈X gℓ
j(xi)
	
∀ℓ∈L, j ∈Nℓ
(10)
ψ+
iℓ= max

0, 1 −max
j∈Nℓgℓ
j(xi)
	
∀ℓ∈L, xi ∈X
(11)
ψ−
iℓ= max

0, −1 −min
j∈Nℓgℓ
j(xi)
	
∀ℓ∈L, xi ∈X
(12)
We denote by ξ+, ξ−, ψ+, and ψ−the nonnegative deﬁcits associated with the
corresponding constraints in (3)–(6) which are not satisﬁed. These deﬁcits are
combined and weighted against the original loss function L through a function P,
for which we have considered the arithmetic mean as well as the 1 and 2-norms.
We can apply this to convolutional neural networks [16,39] with only minor
changes, since they are equivalent to a feedforward neural network with param-
eter sharing and which is not fully connected. The main diﬀerence to work with
them directly is that the preactivation of the unit is a matrix instead of a scalar.
We compute the margin through the maximum or minimum over those values.

350
C. Riera et al.
4
Computational Experiments
Our ﬁrst experiment (Fig. 2) is based on the MOONS dataset [51] with 85 points for
training and 15 for validation. We test every width in {1, 2, 3, 4, 5, 10, 15, 20, 25}
with every depth in {1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, . . . , 150}. We
chose a simpler dataset to limit the inference of factors such as overﬁtting, under-
ﬁtting, or batch size issues. The networks are implemented in Tensorflow [1]
and Keras [11] with Glorot uniform initialization [17] and trained using Adam
[34] for 5000 epochs, learning rate of ϵ = 0.01, and batch size of 85. For each
depth-width pair, we train a baseline network and a network with jumpstart
using 1-norm as the aggregation function P and loss coeﬃcient λ = 10−4.
With jumpstart, we successfully train networks of width 3 with a depth up to
60 instead of 10 for the baseline and width 25 with a depth of up to 100 instead
of 30. Hence, there is an approximately 5-fold increase in trainable depth.
(a) Train accuracy with baseline
(b) Train accuracy with jumpstart
Fig. 2. Heatmap contrasting accuracy for neural networks trained on MOONS with depth
between 1 and 150 and width between 1 and 25. The left plot is the baseline and the
right plot shows the results when using jumpstart. The accuracy ranges from a low of
0.5 (black) to a high of 1.0 (beige), with the former corresponding to random guessing
since the dataset has two balanced classes. (Color ﬁgure online)
Our second experiment (Table 1) evaluates convolutional neural networks
trained on the MNIST dataset [40]. We test every depth from 2 to 68 in incre-
ments of 4 with every width in {2, 4, 8}, where the width refer to the number of
ﬁlters per layer. The networks are implemented as before, but with a learning
rate of 0.001 over 50 epochs, batch size of 1024, kernel dimensions (3, 3), padding
to produce an output of same dimensions as the input, Glorot uniform initializa-
tion [17], ﬂattening before the output layer and using a baseline and a jumpstart
network with 1-norm as the aggregation function P and loss coeﬃcient λ = 10−8.

Training Thinner and Deeper Neural Networks: Jumpstart Regularization
351
Table 1. Summary of the results for the convolutional neural networks trained on the
MNIST dataset without jumpstart (baseline) and with jumpstart.
Baseline
Jumpstart
Training
Validation
Training
Validation
Best overall accuracy
0.999467
0.9885
0.999533
0.9911
Successful model
18
18
54
54
Best for depth-width pair
8
11
45
41
With jumpstart, we successfully train networks combining all widths and
depths in comparison to only up to depth 12 for widths 2 and 4 and only up to
depth 24 for width 8 in the baseline. In other words, only 18 baseline network
trainings converge, which we denote as the successful models in Table 1.
Our third experiment (Figs. 3 and 4) evaluates convolutional networks trained
on CIFAR-10 and CIFAR-100 [36]. For CIFAR-10, we test every depth in
{10, 20, 30} with every width in {2, 8, 16, 32, 64, 96, 192}. For CIFAR-100, we test
depths in {10, 20} with widths in {8, 16, 32, 64}. The networks are implemented
in Pytorch [50], with learning rates ε ∈{0.001, 0.0001} over 400 epochs, batch
size of 128, same kernel dimensions and padding, Kaiming uniform initialization
[24], global max-avg concat pooling before the output layer, and jumpstart with
2-norm (P = L2) and λ ∈{0.001, 0.1} or mean (P = ¯x) and λ ∈{0.1, 1}.
With jumpstart, we successfully train networks for CIFAR-10 with depth up
to 30 in comparison to no more than 20 in the baseline. The best performance—
0.766 for jumpstart and 0.734 for baseline—is observed for both with ε = 0.001,
where the validation accuracy of each jumpstart experiment exceeds the baseline
in 18 out of 21 depth-width pairs in one case and 20 out of 21 in another. The
baseline is comparatively more competitive with ε = 0.0001, but the overall val-
idation accuracy drops signiﬁcantly. For CIFAR-100, the jumpstart experiments
exceed the baseline in 12 out of 16 combinations of depth, width, and learning
rate. The accuracy improves by 1 point in networks with 10 layers and 7.8 points
in networks with 20 layers. The maximum accuracy attained is 0.37 for the base-
line and 0.38 with jumpstart. The training time becomes 1.33 times greater in
CIFAR-10 and 1.47 in CIFAR-100. The use of the precomputed pre-activations
on the forward pass involves a similar memory cost: around 50% more.
The source code is at https://github.com/blauigris/jumpstart-cpaior.

352
C. Riera et al.
Fig. 3. Scatter chart of the number of parameters by accuracy for training (top)
and validation (bottom) of convolutional neural networks trained on CIFAR-10. Some
depth-width pairs are shown above the plots for reference and the gridlines are solid for
depth 30, dashed for 20, and dotted for 10. The results of this experiment are plotted
in this format due to their greater variability in comparison to the second experiment,
which permits evaluating parameter eﬃciency. With same number of units but fewer
parameters, the results for 20 × 8 are better than 10 × 16 and likewise for 20 × 32 when
compared with 10 × 64.

Training Thinner and Deeper Neural Networks: Jumpstart Regularization
353
Fig. 4. Scatter chart of number of parameters by accuracy for training (top) and vali-
dation (bottom) of convolutional neural networks trained on CIFAR-100. Some depth-
width pairs are shown above the plots for reference and the gridlines are dashed for
depth 20 and dotted for 10. Once certain capacity is reached at 640 units, we ﬁnd
that the performance for 20 × 32 is competitive with that of 10 × 64 while using less
parameters.
5
Conclusion
We have presented a regularization technique for training thinner and deeper
neural networks, which leads to a more eﬃcient use of the dataset and to neural
networks that are more parameter-eﬃcient. Although massive models are cur-
rently widely popular in theory [33] and practice [2], their associated economical
barriers and environmental footprint [63] as well as societal impact [5] are known
concerns. Hence, we present a potential alternative to lines of work such as model

354
C. Riera et al.
compression [9] by avoiding to operate with larger models. Whereas deeper net-
works are often pursued, trainable thinner networks are surprisingly not.
Acknowledgements. Thiago Serra was supported by the National Science Founda-
tion (NSF) grant IIS 2104583.
References
1. Abadi, M., et al.: TensorFlow: large-scale machine learning on heterogeneous sys-
tems (2015). https://www.tensorﬂow.org/
2. Amodei, D., Hernandez, D., Sastry, G., Clark, J., Brockman, G., Sutskever, I.: AI
and compute (2018). https://openai.com/blog/ai-and-compute/. Accessed 23 Dec
2020
3. Arora, R., Basu, A., Mianjy, P., Mukherjee, A.: Understanding deep neural net-
works with rectiﬁed linear units. In: ICLR (2018)
4. Ba, J., Caruana, R.: Do deep nets really need to be deep? In: NeurIPS (2014)
5. Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S.: On the dangers of
stochastic parrots: can language models be too big? In: FAccT (2021)
6. Bengio, Y., Simard, P., Frasconi, P.: Learning long-term dependencies with gradient
descent is diﬃcult. IEEE Trans. Neural Netw. 5(2), 157–166 (1994)
7. Bengio, Y., Courville, A., Vincent, P.: Representation learning: a review and new
perspectives (2014)
8. Bienstock, D., Mu˜noz, G., Pokutta, S.: Principled deep neural network training
through linear programming. CoRR abs/1810.03218 (2018)
9. Blalock, D., Ortiz, J., Frankle, J., Guttag, J.: What is the state of neural network
pruning? In: MLSys (2020)
10. Bridle, J.S.: Probabilistic interpretation of feedforward classiﬁcation network out-
puts, with relationships to statistical pattern recognition. In: Souli´e, F.F., H´erault,
J. (eds.) Neurocomputing. NATO ASI Series, vol. 68, pp. 227–236. Springer, Berlin
Heidelberg, Berlin, Heidelberg (1990). https://doi.org/10.1007/978-3-642-76153-
9 28
11. Chollet, F., et al.: Keras (2015). https://keras.io
12. Cybenko, G.: Approximation by superpositions of a sigmoidal function. Math.
Control Signals Syst. (MCSS) 2(4), 303–314 (1989). https://doi.org/10.1007/
BF02551274, http://dx.doi.org/10.1007/BF02551274
13. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep
bidirectional transformers for language understanding, 13 p. (2018). http://arxiv.
org/abs/1810.04805
14. Eldan, R., Shamir, O.: The power of depth for feedforward neural networks (2016)
15. Fischetti, M., Stringher, M.: Embedded hyper-parameter tuning by simulated
annealing. CoRR abs/1906.01504 (2019)
16. Fukushima, K., Miyake, S.: Neocognitron: a self-organizing neural network model
for a mechanism of visual pattern recognition. In: Amari, S.I., Arbib, M.A. (eds.)
Competition and Cooperation in Neural Nets. Lecture Notes in Biomathematics,
vol. 45, pp. 267–285. Springer, Heidelberg (1982). https://doi.org/10.1007/978-3-
642-46466-9 18
17. Glorot, X., Bengio, Y.: Understanding the diﬃculty of training deep feedforward
neural networks. In: Proceedings of the International Conference on Artiﬁcial Intel-
ligence and Statistics (AISTATS 2010). Society for Artiﬁcial Intelligence and Statis-
tics (2010)

Training Thinner and Deeper Neural Networks: Jumpstart Regularization
355
18. Glorot, X., Bordes, A., Bengio, Y.: Deep sparse rectiﬁer neural networks. In: AIS-
TATS (2011)
19. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press (2016). http://
www.deeplearningbook.org
20. Gribonval, R., Kutyniok, G., Nielsen, M., Voigtlaender, F.: Approximation spaces
of deep neural networks (2020)
21. Hahnloser, R., Sarpeshkar, R., Mahowald, M., Douglas, R., Seung, S.: Digital selec-
tion and analogue ampliﬁcation coexist in a cortex-inspired silicon circuit. Nature
405, 947–951 (2000)
22. Hasanpour, S.H., Rouhani, M., Fayyaz, M., Sabokrou, M., Adeli, E.: Towards
principled design of deep convolutional networks: introducing SimpNet. CoRR
abs/1802.06205 (2018). http://arxiv.org/abs/1802.06205
23. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
CoRR abs/1512.03385 (2015). http://arxiv.org/abs/1512.03385
24. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectiﬁers: surpassing human-
level performance on ImageNet classiﬁcation. 2015 IEEE International Conference
on Computer Vision (ICCV), pp. 1026–1034 (2015)
25. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectiﬁers: surpass-
ing human-level performance on ImageNet classiﬁcation. CoRR abs/1502.01852
(2015). http://arxiv.org/abs/1502.01852
26. Hecht-Nielsen, R.: Kolmogorov’s mapping neural network existence theorem. In:
Proceedings of the International Conference on Neural Networks, vol. 3, pp. 11–14.
IEEE Press, New York (1987)
27. Hertrich, C., Basu, A., Summa, M.D., Skutella, M.: Towards lower bounds on the
depth of ReLU neural networks (2021)
28. Hochreiter, S.: Untersuchungen zu dynamischen neuronalen netzen. Diploma Tech.
Univ. M¨unchen 91(1) (1991)
29. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8),
1735–1780 (1997)
30. Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q.: Densely connected
convolutional networks. In: CVPR, pp. 2261–2269. IEEE Computer Society (2017).
http://dblp.uni-trier.de/db/conf/cvpr/cvpr2017.html#HuangLMW17
31. Toro Icarte, R., Illanes, L., Castro, M.P., Cire, A.A., McIlraith, S.A., Beck, J.C.:
Training binarized neural networks using MIP and CP. In: Schiex, T., de Givry, S.
(eds.) CP 2019. LNCS, vol. 11802, pp. 401–417. Springer, Cham (2019). https://
doi.org/10.1007/978-3-030-30048-7 24
32. Ioﬀe, S., Szegedy, C.: Batch normalization: accelerating deep network training by
reducing internal covariate shift. CoRR abs/1502.03167 (2015). http://arxiv.org/
abs/1502.03167
33. Jacot, A., Gabriel, F., Hongler, C.: Neural tangent kernel: convergence and gener-
alization in neural networks. In: Proceedings of the 32nd International Conference
on Neural Information Processing Systems, NIPS 2018, pp. 8580–8589. Curran
Associates Inc., Red Hook (2018)
34. Kingma, D.P., Ba, J.: Adam: a method for stochastic optimization. CoRR
abs/1412.6980 (2014). http://arxiv.org/abs/1412.6980
35. Kolen, J.F., Kremer, S.C.: Gradient ﬂow in recurrent nets: the diﬃculty of learning
long-term dependencies, pp. 237–243. Wiley-IEEE Press (2001). https://doi.org/
10.1109/9780470544037.ch14
36. Krizhevsky, A.: Learning multiple layers of features from tiny images, pp. 32–33
(2009). https://www.cs.toronto.edu/∼kriz/learning-features-2009-TR.pdf

356
C. Riera et al.
37. Krizhevsky, A., Sutskever, I., Hinton, G.E.: ImageNet classiﬁcation with deep con-
volutional neural networks. In: Pereira, F., Burges, C.J.C., Bottou, L., Weinberger,
K.Q. (eds.) Advances in Neural Information Processing Systems, vol. 25, pp. 1097–
1105. Curran Associates, Inc. (2012). http://papers.nips.cc/paper/4824-imagenet-
classiﬁcation-with-deep-convolutional-neural-networks.pdf
38. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436–444
(2015).
https://doi.org/10.1038/nature14539,
http://dx.doi.org/10.1038/nature
14539
39. LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P.: Gradient-based learning applied to
document recognition. In: Proceedings of the IEEE, vol. 86, pp. 2278–2324 (1998).
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665
40. LeCun, Y., Cortes, C.: MNIST handwritten digit database (2010). http://yann.
lecun.com/exdb/mnist/
41. LeCun, Y., Touresky, D., Hinton, G., Sejnowski, T.: A theoretical framework
for back-propagation. In: Proceedings of the 1988 Connectionist Models Summer
School, vol. 1, pp. 21–28 (1988)
42. Lu, L., Shin, Y., Su, Y., Karniadakis, G.E.: Dying ReLU and initialization: theory
and numerical examples. arXiv preprint arXiv:1903.06733 (2019)
43. Lu, Z., Pu, H., Wang, F., Hu, Z., Wang, L.: The expressive power of neural net-
works: a view from the width (2017)
44. Maas, A.L., Hannun, A.Y., Ng, A.Y.: Rectiﬁer nonlinearities improve neural net-
work acoustic models. In: in ICML Workshop on Deep Learning for Audio, Speech
and Language Processing (2013)
45. Minsky, M., Papert, S.: Perceptrons: An Introduction to Computational Geometry.
MIT Press, Cambridge (1969)
46. Mont´ufar, G., Pascanu, R., Cho, K., Bengio, Y.: On the number of linear regions
of deep neural networks. In: NeurIPS (2014)
47. Nair, V., Hinton, G.: Rectiﬁed linear units improve restricted Boltzmann machines.
In: ICML (2010)
48. Pascanu, R., Mont´ufar, G., Bengio, Y.: On the number of response regions of deep
feedforward networks with piecewise linear activations. In: ICLR (2014)
49. Pascanu, R., Mikolov, T., Bengio, Y.: On the diﬃculty of training recurrent neural
networks (2013)
50. Paszke, A., et al.: PyTorch: an imperative style, high-performance deep learning
library. In: Wallach, H., Larochelle, H., Beygelzimer, A., d’Alch´e-Buc, F., Fox, E.,
Garnett, R. (eds.) Advances in Neural Information Processing Systems, vol. 32, pp.
8024–8035. Curran Associates, Inc. (2019). http://papers.neurips.cc/paper/9015-
pytorch-an-imperative-style-high-performance-deep-learning-library.pdf
51. Pedregosa, F., et al.: Scikit-learn: machine learning in Python. J. Mach. Learn.
Res. 12, 2825–2830 (2011)
52. Pooladian, A., Finlay, C., Oberman, A.M.: Farkas layers: don’t shift the data, ﬁx
the geometry. CoRR abs/1910.02840 (2019). http://arxiv.org/abs/1910.02840
53. Robbins, H., Monro, S.: A stochastic approximation method. Ann. Math. Stat.
22(3), 400–407 (1951)
54. Rumelhart, D.E., Hinton, G.E., Williams, R.J.: Learning representations by back-
propagating errors. Nature 323, 533–536 (1986)
55. Serra, T., Kumar, A., Ramalingam, S.: Lossless compression of deep neural net-
works. In: Hebrard, E., Musliu, N. (eds.) CPAIOR 2020. LNCS, vol. 12296, pp.
417–430. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58942-4 27
56. Serra, T., Ramalingam, S.: Empirical bounds on linear regions of deep rectiﬁer
networks. In: AAAI (2020)

Training Thinner and Deeper Neural Networks: Jumpstart Regularization
357
57. Serra, T., Kumar, A., Yu, X., Ramalingam, S.: Scaling up exact neural network
compression by ReLU stability (2021)
58. Serra, T., Tjandraatmadja, C., Ramalingam, S.: Bounding and counting linear
regions of deep neural networks (2018)
59. Shalev-Shwartz, S., Ben-David, S.: Understanding Machine Learning: From Theory
to Algorithms. Cambridge University Press, USA (2014)
60. Shang, W., Sohn, K., Almeida, D., Lee, H.: Understanding and improving
convolutional neural networks via concatenated rectiﬁed linear units. CoRR
abs/1603.05201 (2016). http://arxiv.org/abs/1603.05201
61. Shin, Y., Karniadakis, G.E.: Trainability and data-dependent initialization of over-
parameterized ReLU neural networks. CoRR abs/1907.09696 (2019). http://arxiv.
org/abs/1907.09696
62. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
image recognition. CoRR abs/1409.1556 (2014). http://arxiv.org/abs/1409.1556
63. Strubell, E., Ganesh, A., McCallum, A.: Energy and policy considerations for deep
learning in NLP. In: ACL (2019)
64. Szegedy, C., et al.: Going deeper with convolutions. CoRR abs/1409.4842 (2014).
http://arxiv.org/abs/1409.4842
65. Tan, M., Le, Q.V.: EﬃcientNet: rethinking model scaling for convolutional neural
networks. CoRR abs/1905.11946 (2019). http://arxiv.org/abs/1905.11946
66. Tan, M., Le, Q.V.: EﬃcientNetV2: smaller models and faster training. CoRR
abs/2104.00298 (2021). https://arxiv.org/abs/2104.00298
67. Telgarsky, M.: Representation beneﬁts of deep feedforward networks. CoRR
abs/1509.08101 (2015)
68. Tjeng, V., Xiao, K., Tedrake, R.: Evaluating robustness of neural networks with
mixed integer programming. In: ICLR (2019)
69. Vardi, G., Reichman, D., Pitassi, T., Shamir, O.: Size and depth separation in
approximating benign functions with neural networks (2021)
70. Vaswani,
A.,
et
al.:
Attention
is
all
you
need.
In:
Guyon,
I.,
et
al.
(eds.) Advances in Neural Information Processing Systems, vol. 30. Cur-
ran
Associates,
Inc.
(2017).
https://proceedings.neurips.cc/paper/2017/ﬁle/
3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
71. Werbos, P.J.: Applications of advances in nonlinear sensitivity analysis. In: Pro-
ceedings of the 10th IFIP Conference, 31.8 - 4.9, NYC, pp. 762–770 (1981)
72. Zagoruyko, S., Komodakis, N.: Wide residual networks. CoRR abs/1605.07146
(2016). http://arxiv.org/abs/1605.07146

Hybrid Oﬄine/Online Optimization
for Energy Management
via Reinforcement Learning
Mattia Silvestri(B), Allegra De Filippo, Federico Ruggeri,
and Michele Lombardi
DISI, University of Bologna, Bologna, Italy
{mattia.silvestri4,allegra.defilippo,federico.ruggeri6,
michele.lombardi2}@unibo.it
Abstract. Constrained decision problems in the real world are subject
to uncertainty. If predictive information about the stochastic elements is
available oﬄine, recent works have shown that it is possible to rely on an
(expensive) parameter tuning phase to improve the behavior of a simple
online solver so that it roughly matches the solution quality of an antici-
pative approach but maintains its original eﬃciency. Here, we start from
a state-of-the-art oﬄine/online optimization method that relies on opti-
mality conditions to inject knowledge of a (convex) online approach into
an oﬄine solver used for parameter tuning. We then propose to replace
the oﬄine step with (Deep) Reinforcement Learning (RL) approaches,
which results in a simpler integration scheme with a higher potential
for generalization. We introduce two hybrid methods that combine both
learning and optimization: the ﬁrst optimizes all the parameters at once,
whereas the second exploits the sequential nature of the online problem
via the Markov Decision Process framework. In a case study in energy
management, we show the eﬀectiveness of our hybrid approaches, w.r.t.
the state-of-the-art and pure RL methods. The combination proves capa-
ble of faster convergence and naturally handles constraint satisfaction.
Keywords: Deep reinforcement learning · Oﬄine/online
optimization · Uncertainty · Constrained optimization
1
Introduction
Real world constrained decision problems often mix oﬄine and online elements.
In many cases, a substantial amount of information about the uncertainty (e.g.
in the form of historical solutions, event logs or probability distributions) is avail-
able before it is revealed, i.e. before the online execution starts. This information
generally allows to make both strategic (oﬄine) and operational (online) deci-
sions: in production scheduling, for example, we may devise an initial plan to be
revised at run time in case of disruptions; or in Energy Management Systems
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 358–373, 2022.
https://doi.org/10.1007/978-3-031-08011-1_24

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
359
(EMS) the electrical load should be planned the day ahead, while power ﬂow
balance should be maintained hour by hour.
The interplay of these oﬄine and online phases has received attention in
the last years [8]. Recent works [8,9] show that whenever distinct oﬄine and
online phases are present, a tighter integration can lead to substantial improve-
ments in terms of both solution quality and computational costs. In particular,
since in many application domains, eﬃcient suboptimal algorithms for online
optimization are already available or easy to design (e.g. greedy heuristics or
myopic declarative models), such works exploit the available oﬄine informa-
tion to rely on a (typically expensive) parameter tuning phase to improve the
behavior of the online solver, maintaining its original eﬃciency. [9] is based
on the idea of injecting knowledge of a (convex) online approach into an oﬄine
solver. This is achieved by formulating the Karush-Kuhn-Tucker (KKT) optimal-
ity conditions for the online solver and adding them as constraints in a (oﬄine)
Mixed-Integer Programming (MIP) problem. The resulting model can be used to
perform (oﬄine expensive) parameter tuning. However, formulating optimality
conditions is not trivial and requires operations research expertise. Moreover,
KKT conditions introduce non-linearity to the initial model which dramatically
reduces scalability. Finally, in this method, the uncertainty is managed by sam-
pling, introducing approximations.
In this paper, we explore the idea of using learning-based approximations
to lift this limitation. In particular, we employ Deep Reinforcement Learning
(DRL) approaches as black-box solvers to perform (instance-speciﬁc) parameter
tuning in a simpler integration scheme without requiring convexity for the online
optimization problem.
We propose two hybrid approaches that combine both learning and optimiza-
tion. The ﬁrst one selects the parameters all at once, while the second approach
exploits the sequential nature of the online problem by using the Markov Deci-
sion Process (MDP) framework.
Based on an Energy Management System case study, we show the eﬀec-
tiveness of our hybrid approaches, both compared to the (tuning) optimization
problem from [7,9]. To demonstrate the advantages over full RL-based solutions,
we have developed and compared RL end-to-end counterparts of our proposed
methods. We show that the resulting hybrid approach beneﬁts from powerful
learning algorithms and is well suited to deal with operational constraints.
The rest of the paper is organized as follows. In Sect. 2 we provide a brief
introduction on RL. Section 3 describes the proposed case study and the state-
of-the-art approach for oﬄine/online optimization grounded on it. Section 4
presents our proposed two hybrid approaches that combine both learning and
optimization. Section 5 provides an analysis of results. Section 6 discusses the
main approaches proposed in the literature focused on Deep RL, hybrid meth-
ods that combine both learning and optimization, and methods for hybrid
oﬄine/online optimization. Concluding remarks are in Sect. 7.

360
M. Silvestri et al.
2
Background
Reinforcement Learning (RL) is a paradigm to solve sequential decision-making
problems, deﬁned on top of the MDP mathematical framework. Formally, a
fully-observable MDP is deﬁned by a tuple (S, A, p, r, γ), where S is the set of
states, A is the set of actions, p(·|s, a) is the probability distribution of next
states, r(·|s, a) is the probability distribution of the reward and γ ∈[0, 1], called
discount factor, controls the impact of future rewards.
The sequential decision making problem is then cast down to a recurrent
process where the RL agent interacts with the environment by performing actions
according to its behavior policy πθ(at|st). Consequently, these actions provoke
the agent’s state transitions. Based on the action outcome, a reward signal may
be attributed to the RL agent. The learning process is then formulated as the
maximization problem of cumulative rewards along state-action trajectories τ,
dictated by πθ(at|st).
J(θ) = Eτ∼pθ(τ)
 T
t=1
γtr(st, at)

(1)
pθ(τ) = pθ(s1, a1, . . . , sT , aT ) = p(s1)
T
t=1
πθ(at|st)p(st+1|st, at)
(2)
where T is the trajectory time horizon.
RL algorithms can be classiﬁed into two main categories: model-free and
model-based RL. Model-free RL algorithms try to ﬁnd the optimal policy π∗
such that the expected cumulative discounted reward from the initial state st=1 is
maximized. The idea of model-based RL is to learn the model of the environment,
i.e. the transition probabilities p(·|s, a), rather than the optimal policy and then
use the learned model to choose the optimal actions.
Within the model-free family, Policy Gradient algorithms are widely used
when the actions space is continuous. One such an example is REINFORCE [20]:
given a parametric policy πθ, the parameters θ are optimized by gradient ascent
to directly maximize J(θ).
∇θJ(θ) = Eτ∼πθ(τ)
 T

t=1
∇θ log πθ(at|st)
	  T

t=1
r(st, at)
	
(3)
Policy gradient algorithms are known to suﬀer from high variance. several
non-mutually exclusive solutions can be employed to mitigate this issue, such
as baseline subtraction to correctly isolate positive actions. Among the possible
baselines, Actor-Critic (AC) methods are particularly eﬀective in reducing vari-
ance. Instead of using a state-dependent baseline, one can reduce the variance
by computing the advantage of taking an action at in state st. The advantage is
deﬁned as A(st, at) = r + γV (st+1) −V (st), where Vπ(st) = Eπ [J(τ)|s = st] is
the value function, r is the reward and st+1 is the next state. Thus, the actor is
represented by the policy, whereas the value function acts as the critic.

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
361
Modern RL approaches take advantage of deep learning models as power-
ful tools for representation learning [15]. More precisely, neural networks are
employed to approximate the policy πθ and Vθ(·). The scientiﬁc community usu-
ally refers to this research ﬁeld as Deep Reinforcement Learning (DRL).
3
Problem Description
In this section, we present the details of the application scenario of an Energy
Management System, and we illustrate the state-of-the-art oﬄine/online app-
roach grounded on it.
3.1
Energy Management Case Study
As a practical use case, we consider an Energy Management System (EMS)
that requires allocating the minimum-cost power ﬂows from diﬀerent Distributed
Energy Resources (DERs). The uncertainty stems from uncontrollable deviations
from the planned loads of consumption and the presence of Renewable Energy
Sources (RES). Based on actual energy prices and on the availability of DERs,
the EMS decides: 1) how much energy should be produced; 2) which generators
should be used for the required energy; 3) whether the surplus energy should
be stored or sold to the energy market. Unlike in most of the existing litera-
ture, we acknowledge that in many practical cases [8] some parameters can be
tuned oﬄine, while the energy balance should be maintained online by managing
energy ﬂows among the grid, the renewable and traditional generators, and the
storage systems. Intuitively, handling these two phases in an integrated fashion
should lead to some beneﬁts, thus making the EMS a good benchmark for our
integrated approach.
In our case study, it is desirable to encourage the online heuristic to store
energy in the battery system when the prices of the Electricity Market are cheap
and the loads are low, in anticipation of future higher users’ demand. Storing
energy has no proﬁt so the online (myopic) solver always ends up in selling all the
energy on the market. However, by deﬁning a virtual cost parameter related to
the storage system, it is possible to associate a proﬁt (negative cost) to storing
energy, which enables addressing this greedy limitation. Then, based on day-
ahead RES generation and electric demand forecasts, we can ﬁnd the optimal
virtual costs related to the storage system to achieve better results in terms of
solution quality (management costs of the energy system).
3.2
State-of-the-Art Oﬄine/Online Approach
We refer to the integrated oﬄine/online optimization method proposed in [7,9]
that assumes exogenous uncertainty, and that is composed of two macro steps: an
oﬄine two-stage stochastic optimization model based on sampling and scenarios;
and an online parametric algorithm, implemented within a simulator, that tries
to make optimal online choices, by building over the oﬄine decisions. The authors

362
M. Silvestri et al.
assume that the online parametric algorithm is based on a convex optimization
model. Based on some conﬁguration parameters of the online model, an oﬄine
parameter tuning step is applied. In this way, the authors can take advantage of
the convexity of the online problem to obtain guaranteed optimal parameters. In
particular, convexity implies that any local minimum must be a global minimum.
Local minima can be characterized in terms of the KKT optimality conditions.
Essentially, those conditions introduce a set of constraints that must be satisﬁed
by any solution that is compatible with the behavior of the online heuristic. They
can exploit this property by formulating the tuning phase as a Mathematical
Program that is not a trivial task for every constrained real-world problem.
The online step is composed by a greedy (myopic) heuristic that minimizes
the cost and covers the energy demand by manipulating the ﬂows between the
energy sources. We underline that this is a typical approach to handle the online
optimization of an EMS [1]. The heuristic can be formulated as an LP model:
min
n

k=1

g∈G
ck
gxk
g
(4)
s.t. ˜Lk =

g∈G
xk
g
(5)
0 ≤γk + ηxk
0 ≤Γ
(6)
xg ≤xk
g ≤xg
(7)
For each stage k up to n, the decision variables xg are the power ﬂows between
nodes in g ∈G and cg are the associated costs. All ﬂows must satisfy the lower
and upper physical bounds xg and xg. Index 0 refers to the storage system and
the index 1 to the RES generators. Hence the virtual costs associated with the
storage system are ck
0. The battery charge, upper limit and eﬃciency are γ, Γ
and η. The EMS must satisfy the user demand at each stage k referred to as ˜Lk.
The baseline oﬄine problem is modeled via MIP and relies on the KKT
conditions to deﬁne a model for ﬁnding the optimal values of ck
0 for the set of
sampled scenarios ω ∈Ω. Such model is given by:
min 1
|Ω|

ω∈Ω

g∈G
n

k=1
ck
gxk
g,ω
(8)
s.t. ˜Lk
ω =

g∈G
xk
g,ω
∀ω ∈Ω, ∀k = 1, · · · , n
(9)
xg ≤xk
g,ω ≤xg
∀ω ∈Ω, ∀k = 1, · · · , n
(10)
0 ≤γk
ω ≤Γ
∀k = 1, · · · , n
(11)
γk+1
ω
= γk
ω + ηxk
0,ω
∀ω ∈Ω, ∀k = 1, · · · , n −1
(12)
xk+1
1,ω = ˆRk + ξk
R,ω
∀ω ∈Ω, ∀k = 1, · · · , n
(13)
˜Lk+1
ω
= ˆLk + yk + ξk
L,ω
∀ω ∈Ω, ∀k = 1, · · · , n
(14)

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
363
ˆRk and ˆLk are the estimated RES production and load, and ξk
R and ξk
L are the
corresponding random variables representing the prediction errors. yk are opti-
mal load shifts and are considered as ﬁxed parameters. The authors assume that
the errors follow roughly a Normal distribution N(0, σ2) and that the variance σ2
is such that 95% conﬁdence interval corresponds to ±10% of the estimated value.
˜Lk
ω is the observed user load demand for stage k of the scenario ω. Equations
(12) to (14) model the transition functions.
The above formulation is free to assign variables (as long as the constraints
are satisﬁed), whereas all decisions that are supposed to be made by the heuristic
can not rely on future information. We account for this limitation by introducing,
as constraints, the KKT optimality conditions for our convex online heuristic.
The model achieves integration at the cost of oﬄine computation time, because
of the additional variables introduced and the presence of non-linearities.
In the following we show the KKT conditions formulation for the online
heuristic in a single scenario:
−ck
g = λk
ω + μk
g,ω −νk
g,ω
∀g ∈G
(15)
μk
g,ω(xk
g,ω + xg) = 0
∀g ∈G
(16)
νk
i,ω(xg −xt
g,ω) = 0
∀g ∈G
(17)
ˆμk
ω(ηxk
0,ω + γk −Γ) = 0
(18)
ˆνk
ω(ηxk
0,ω + γk) = 0
(19)
μk
g,ω, νk
g,ω ≥0
∀g ∈G
(20)
ˆμk
ω, ˆνk
ω ≥0
(21)
where μk
g,ω and νk
g,ω are the multipliers associated to the physical ﬂow bounds,
while ˆμk
ω and ˆνk
ω are associated to the battery capacity bounds. Injecting the
conditions in the oﬄine model yields:
min
1
|Ω|

ω∈Ω

g∈G
n

k=1
ck
gxk
g,ω
s.t. Eq. (9)−(14)
– offline problem constraints –
Eq. (15)−(21)
∀ω ∈Ω, ∀k = 1, . . . n
– KKT conditions –
where the decision variables are xk
g,ω, μk
g,ω, νk
g,ω, ˆμk
ω, ˆνk
ω. To those, the authors
add the cost ck
0 associated with the ﬂow from and to the storage system (the
only parameter they allow the solver to adjust). This method allows the oﬄine
solver to associate a virtual proﬁt for storing energy, which enables addressing
the original limitation at no online computational cost.
4
Proposed Methods
Due to the limitations in terms of convexity assumption and scalability presented
in Sect. 3, we devise an alternative to the tuning approach of [7,9]. Decision-
focused learning approaches are not directly applicable since the cost function

364
M. Silvestri et al.
Fig. 1. In the single-step version, the policy π provides the set of {Ck
0 }n
k=1 all at
once.
employed in the optimization problem takes also into account the (virtual) costs
related to the storage system ck
0, whereas the real cost to be minimized does not.
In particular, we propose a hybrid method that employs DRL as a black-box tool
to ﬁnd the optimal ck
0. The major beneﬁt over the tuning version of [7,9] is that
we do no longer require the greedy heuristic to be convex but we are still able to
compensate for its myopic behavior.
In the following sections, we will ﬁrst describe our RL-based version of the
tuning algorithm. Then, to show the beneﬁts of a hybrid approach that com-
bines both learning and optimization, we will outline an alternative end-to-end
RL method that directly provides the power ﬂows.
4.1
RL-Based TUNING
We devise two viable ways to formulate the Reinforcement Learning problem.
As shown in Fig. 1, in the ﬁrst formulation (referred to as single-step), the
policy π : Rn×2 −→Rn maps the day-ahead photovoltaic generation ˆRk and
electric demand forecasting ˆLk to the set of all the virtual costs ck
0 for k =
{1, . . . , n}. Once ck
0 are provided, a solution {xk
g}n
k=1 is found solving the online
optimization problem deﬁned in Eqs. (4) to (7) and the reward is the negative
real cost computed as:
−
n

k=1

g∈G
g̸=0
ck
gxk
g
The second formulation (referred to as mdp) exploits the sequential nature of
the online step and ﬁts the MDP framework and it is shown in Fig. 2. The policy
π is a function π : Rn×3+1 −→R. The state sk keeps track of the battery charge
γk and it is updated accordingly to the input and output storage ﬂows. At each
stage k, the agent’s action ak is the virtual cost ck
0 and the corresponding online
optimization problem is solved. Then the environment provides as observations
the battery charge γk, the set of forecasts ˜R1,...,n and ˜L1,...,n, and a one-hot
encoding of the stage k. The reward is again the negative real cost but for the
only current stage k:
−

g∈G
g̸=0
ck
gxk
g

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
365
Fig. 2. In the MDP formulation, the agent sets the cost associated to the storage
step-by-step, for each stage in the range from 1 to n.
The two formulations have complementary advantages and drawbacks. The
single-step version is less prone to ﬁnd suboptimal behaviors since it is rewarded
with the actual real cost at the end of all the optimization steps. Instead, mdp
receives a reward for each stage which makes it challenging to ﬁnd a tradeoﬀ
between maximizing both immediate and far-in-time rewards. On the other hand,
the task to be learned for mdp is simpler than for single-step because it has
only to set one virtual cost at a time rather than deciding them all at once.
4.2
End-to-End RL
As for the hybrid approaches, we have developed both the single episode and
sequential versions of the RL problem. Directly providing a feasible solution is
extremely hard because the actions must satisfy all the constraints. To simplify
the task, we make some architectural choices that allow for reducing the actions
space.
For both the formulations, the observations are the same as for the corre-
sponding counterparts described in Sect. 4.1. In the version equivalent to single-
step, the output of the policy is a vector of dimension n×(|G|−1) corresponding
to the power ﬂows xk
g for each stage k from 1 to n. Since one of the power ﬂows
has no upper bound xg, we have set its value so that the power balance con-
straint of Eq. (9) is satisﬁed, reducing the actions space and making the task
for RL easier. We refer to this decision variable as xk
2. In the MDP version, the
policy provides a (|G| −1)-dimensional vector corresponding to the power ﬂows
for a single stage. The actions are clipped in the range [−1, 1] and then rescaled
in their feasible ranges

xg, xg

.
Despite adopting these architectural constraints, the actions provided by the
agent may still be infeasible: the storage constraint of Eq. (12) and the lower
bound x2 can be violated. Since the solutions’ cost is in the range [0, 3000],
the policy network is rewarded with a value of −10000 when infeasible actions
are selected to encourage the search for feasible solutions. The full RL version
of single-step has the same reward of single-step itself. Unfortunately, this
approach never founds a feasible solution during training. This is reasonable
since the actions space is huge and the task extremely hard. Due to its poor
performance, we do not consider this method for further investigation. In the
MDP version, instead, the reward is non-zero only for the last stage and it is

366
M. Silvestri et al.
computed as the negative cumulative real cost. In following of the paper, we only
consider this full RL method and refer to it as rl.
5
Experimental Results
Fig. 3. Mean and standard deviation of the photovoltaic production and load demand
forecasts obtained from the Public Dataset.
Training and test of the methods are performed on real data based on a Public
Dataset1. From this dataset, we assume electric load demand and photovoltaic
production forecasts, upper and lower limits for generating units and the initial
status of storage units. During training of all the methods with an RL compo-
nent, ˜R and ˜L are obtained from the forecasts by adding noise from a normal
distribution as described in Sect. 3.2. The dataset presents individual proﬁles of
load demand with a time step of 5 min resolution from 00:00 to 23:00. We con-
sider aggregated proﬁles with a timestamp of 15 min and use them as forecasted
load. The photovoltaic production is based on the same dataset with proﬁles for
diﬀerent sizes of photovoltaic units but the same solar irradiance (i.e. the same
shape but diﬀerent amplitude due to the diﬀerent sizes of the panels used). Also
in this case photovoltaic production is adopted as forecast.
To assess the variability of the dataset, in Fig. 3 we show the mean and
standard deviation of photovoltaic production and user load demand regarding
the hour of the day. Photovoltaic production has not a high variance and this is
reasonable since it mainly depends on the solar irradiance. On the other hand,
the load demand is extremely variable proving the robustness of the benchmark.
1 www.enwl.co.uk/lvns.

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
367
The electricity demand hourly prices have been obtained based on data
from the Italian national energy market management corporation2 (GME) in
e/MWh. The diesel price is taken from the Italian Ministry of Economic Devel-
opment3 and is assumed as a constant for all the time horizon (one day in our
model) as assumed in literature [1] and from [11].
In the following, we will refer to the version of tuning based on perfect
information (i.e. without scenario sampling) as oracle. For single-step, mdp
and rl, we have employed the Advantage Actor Critic (A2C) algorithm4 since
it is robust and it can deal with a continuous actions space. All the code and
dataset to reproduce the results are publicly available at the following link5.
Both training and evaluation were performed on a laptop with an Intel i7 CPU
with 4 cores and 1.5 GHz clock frequency.
Since hyperparameter search was outside the scope of this paper, we employ a
quite standard architecture. The policy is represented by a Gaussian distribution
for each action dimension, parametrized by a feedforward fully-connected Neural
Network with two hidden layers, each of 32 units and a hyperbolic tangent
activation function. The critic is again a deep neural network with the same
hidden architecture of the policy. Parameters are updated using Adam optimizer
with a learning rate of 0.01, which is larger than the usual 0.001: we choose this
value because it improves the speed of convergence without compromising the
ﬁnal results for our use case. Observations are rescaled in the same range [0, 1]
dividing by their maximum values. We have used a batch size of 100 for all the
methods but mdp for which we have preferred a larger batch size of 9600 to have
a comparable number of episodes for each training epoch.
For the evaluation, we randomly select 100 pairs of load demand and pho-
tovoltaic production forecasts, referred to as instances in the following of the
section. Each method with a learning component (i.e. single-step, mdp and
rl) is trained on each instance individually. Here we focus on probing the eﬀec-
tiveness of the proposed method and we intend to investigate the generalization
capabilities in future work.
5.1
Cost Value over Computation Time
We start by comparing the mean cost on the generated realization during each
training epoch as a function of the computation time, averaging the results con-
sidering the set of 100 instances. Since the optimal cost may be diﬀerent among
the instances, we normalize it by the best value found (i.e. the one provided by
oracle). To make a fair comparison with tuning, we train the methods with
a learning phase choosing a number of epochs such that the computation time
is similar. The mean epoch duration on the 100 instances, the number of epochs
2 http://www.mercatoelettrico.org/En/Default.aspx.
3 http://dgsaie.mise.gov.it/.
4 A2C algorithm was implemented with the TensorFlow version of the garage [5]
library.
5 https://github.com/matsilv/rl-oﬄine-online-opt.

368
M. Silvestri et al.
Fig. 4. Cost comparison of the methods w.r.t. the computational time.
and the total computation time required for all the methods are reported in
Table 1.
Table 1. Mean epoch duration, number of epochs and total duration for the methods.
Method
Epoch duration (sec) Num. of epochs Total duration (sec)
single-step 9.85
37
364.45
mdp
19.28
19
366.32
rl
0.33
1085
358.05
oracle
–
–
74.13
tuning
–
–
360.21
heuristic
–
–
0.66
In the upper part of Fig. 4, RL is compared to oracle: despite the agent
is actually minimizing the cost, it is far from being optimal. The results are
so poor that we do not make a further comparison with the other methods. In
the lower part of Fig. 4, our devised approaches (single-step and mdp) are
compared with the greedy heuristic, tuning and oracle. Since there is no
learning for these last three methods, the solution found is used as a reference
value and a simple horizontal line is plotted. Despite being extremely fast, the
greedy heuristic provides considerably worse results than the oracle, due to its
myopic behavior. Among our proposed methods, single-step provides better

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
369
results and a faster convergence; in addition, it also outperforms the state-of-
the-art tuning in almost the same computation time and without requiring
a convex online optimization problem. oracle ﬁnds the optimal solution and
it is faster than our proposed methods. On the other hand, it requires perfect
information so it is not applicable to real-world problems and here it is only used
as a reference value to evaluate the performance of the other methods.
5.2
Decision Variables
Next, we proceed by comparing the power ﬂows and storage capacity for each
method (shown in Fig. 5). Since we introduce a virtual cost related to the battery
system, our discussion focuses on storage usage. The end-to-end RL approach is
only learning to satisfy the power balance and storage constraints and it does
not take smarter actions to reduce the cost. One possible reason for this poor
performance is the challenging exploration of the huge actions space. As one
would expect, the greedy (and myopic) heuristic uses all the available energy in
the storage and does not further charge the battery since it is not directly prof-
itable. The hybrid approaches (single-step and mdp) have similar behaviors
and extensively use the storage whereas tuning focuses on the only hours close
to the users demand peaks. The smartest decisions are taken by oracle which
frequently resorts to the battery system but keeps the storage fully loaded for
the ﬁrst part day when the load demand is low.
Fig. 5. Mean and standard deviation of the power ﬂows and storage capacity w.r.t. the
time for all the described methods.
6
Related Work
In this section we initially describe some recent Deep Reinforcement Learning
approaches to solve combinatorial optimization problems. Then we illustrate the
predict-then-optimize framework which has several properties in common with
the method we have devised. The section ends with a brief overview of hybrid
oﬄine/online optimization approaches.

370
M. Silvestri et al.
6.1
Deep Reinforcement Learning for Combinatorial Optimization
Recently, there has been an increasing interest in combining learning and opti-
mization [13] with particular emphasis on DRL to solve combinatorial optimiza-
tion problems [14]. Handcrafted heuristics are often used in place of exact solvers
to ﬁnd high-quality solutions in a reasonable time, but they require expert knowl-
edge to be designed. Instead, DRL can learn its heuristic from a simple reward
signal without any supervision. In the following, we describe the state-of-the-art
methods adopting the same taxonomy proposed in [14].
Principal Learning. In principal learning, the agent directly provides a solu-
tion or takes actions that are part of the solution. One of the ﬁrst attempts to
solve Combinatorial Optimization problems with DRL has been made in [2] and
mainly addresses the Traveling Salesman Problem. In particular, a Pointer Net-
work [19] iteratively builds a tour by choosing the most probable remaining city
at each step. The network is trained with an Actor-Critic algorithm using the
negative tour length as a reward. Experimental results show that this method
can achieve near-optimal solutions for tours with up to 100 nodes. In [12], the
authors improve the results of [2] by replacing the Pointer Network with the
Transformer architecture [18]. Similarly, [16] further extends [2] to the family of
Vehicle Routing Problem (VRP). In [6], the authors develop a meta-algorithm
to solve combinatorial optimization problems deﬁned over graphs. The state is
a partial solution and the set of actions is represented by the set of all possible
nodes that can be added.
Generally, DRL approaches have trouble dealing with combinatorial struc-
tures: this issue could be addressed by injecting knowledge of the online solver
into the policy itself, either by making the solver part of the environment, or by
using Diﬀerentiable Programming to embed the online solver in the structure of
the deep neural network. In this perspective, here we take advantage of the pow-
erful learning framework provided by RL and rely on Declarative Optimization
to deal with operational constraints.
Joint Training. Alternatively to principal learning, the policy can be jointly
trained with an oﬀ-the-shelf solver to improve the solution quality or other
performance metrics. For instance, in [3] DRL is employed as a value-selection
heuristic to improve Constraint Programming searching strategy. Rather than
constructing a solution, one can think of using RL to improve an already existing
one, similarly to Local Search. For example, NeuRewriter [4] is an Actor Critic
algorithm that learns a solution improvement heuristic by iteratively re-writing
part of the solution until convergence is reached. Two policies are learned simul-
taneously: the region-picking and rule-picking policies. The region-picking policy
chooses which part of the solution should be re-written, whereas the rule-picking
policy selects the re-writing rule.
Despite the RL algorithm being trained end-to-end with the online solver, our
proposed method is diﬀerent from the approaches described above: the agent is
not directly integrated into a step of the solutions process of a pre-deﬁned solver.

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
371
Instead, it applies a parameters tuning phase separated from the optimization
step and that guides the solver.
6.2
Predict-then-Optimize
Our approach is related to the family of decision-focused learning. Many real-
world problems require a predictive model whose predictions are given as input to
a combinatorial optimization problem. In decision-focused learning, the training
of the predictive model is improved by taking into account the solutions of the
optimization problem.
One such example is the Smart “Predict, then Optimize” (SPO) framework
[10]: rather than simply minimizing the prediction error, the model is trained
to provide estimates such that optimal solutions are found. Training is usually
performed in a supervised fashion and the major challenge of this kind of app-
roach is ﬁnding a diﬀerentiable and computational-eﬃcient loss function, like the
SPO+ that was proposed in [10].
Our method diﬀers from decision-focused learning since we allow for a dis-
crepancy between the true cost that needs to be minimized and the cost function
technically employed in the optimization problem. As an additional beneﬁt, we
do not require diﬀerentiability on the cost function. This is the reason why we
adopt RL rather than a supervised method in the learning stage.
6.3
Hybrid Oﬄine/Online Optimization
Stochastic optimization problems are usually solved via oﬄine or online methods.
Oﬄine approaches ﬁnd a robust solution taking into account future uncertainty
in advance but they are computationally expensive. On the other side, online
algorithms take decisions once uncertainty is revealed but the solution quality
is strictly aﬀected by the available amount of computation time.
In many real-world cases, a large amount of information about the stochastic
variables is available before the uncertainty is revealed. For example, in the
energy management case study, historical data about past user demands can be
used to model the uncertainty. This motivates the interest in developing hybrid
oﬄine/online approaches and taking advantage of both worlds to improve in
terms of solution quality and computational cost.
If we model an n-stage stochastic optimization problem as a Markov Decision
Process [17] then Dynamic Programming can be seen as a hybrid oﬄine/online
optimization approach. The policy and its corresponding value-function are iter-
atively improved oﬄine, simulating executions, and then the resulting policy can
be eﬃciently executed online.
When fast but sub-optimal, online algorithms are available (e.g. greedy
heuristic), their behavior can be improved via a parameter tuning procedure
without introducing additional computational cost during the online phase.
In [7,9], the authors propose a method to inject knowledge about a con-
vex online solver in the oﬄine problem. In practice, this is achieved by adding

372
M. Silvestri et al.
the KKT optimality conditions for the online solver as constraints in the oﬄine
problem. The method achieves positive results in cost/quality tradeoﬀby tak-
ing advantage of the oﬄine/online integration. However, formulating optimality
conditions is not trivial requiring experience and domain knowledge. Moreover,
KKT conditions introduce non-linearity to the initial model and dramatically
reduce scalability. Finally, in this method, the uncertainty is managed by sam-
pling, introducing approximations.
The major beneﬁt of our learning/optimization hybrid methods over the
tuning version of [7,9] is that we do no longer require the greedy heuristic to be
convex but we are still able to compensate for its myopic behavior.
7
Conclusions
This paper makes a signiﬁcant step towards hybrid learning/optimization
approaches for oﬄine/online optimization under uncertainty.
We start from a state-of-the-art oﬄine/online optimization method that
makes oﬄine parameter tuning by relying on optimality conditions to inject
knowledge of a (convex) online approach into an oﬄine solver. Then, we propose
two approaches to replace this oﬄine parameter tuning phase, by using DRL as
a black-box solver. We present two hybrid methods that combine both learning
and optimization: the ﬁrst one optimizes all the parameters at once, whereas
the second approach exploits the sequential nature of the online problem via the
MDP framework.
In a case study in energy management, we show the eﬀectiveness of our
hybrid approaches w.r.t. the state-of-the-art methods. We also experimentally
assess that a full RL-based approach struggles to ﬁnd feasible solutions and its
performance are poor compared to the state-of-the-art and our devised methods.
The combination of RL and optimization proves capable of faster convergence
and naturally handles constraint satisfaction. In contrast to current state-of-
the-art approaches for oﬄine/online optimization, our hybrid method has the
potential to generalize: we leave probing generalization as an open question and
future research direction.
Acknowledgements. This work has been partially supported by European ICT-48-
2020 Project TAILOR (g.a. 952215). We thank professor Michela Milano (University
of Bologna) for the valuable discussions.
References
1. Aloini, D., Crisostomi, E., Raugi, M., Rizzo, R.: Optimal power scheduling in a vir-
tual power plant. In: 2011 2nd IEEE PES International Conference and Exhibition
on Innovative Smart Grid Technologies, pp. 1–7 (2011)
2. Bello, I., Pham, H., Le, Q.V., Norouzi, M., Bengio, S.: Neural combinatorial opti-
mization with reinforcement learning. arXiv preprint arXiv:1611.09940 (2016)

Hybrid Oﬄine/Online Optimization via Reinforcement Learning
373
3. Cappart, Q., Moisan, T., Rousseau, L.M., Pr´emont-Schwarz, I., Cire, A.: Com-
bining reinforcement learning and constraint programming for combinatorial opti-
mization. arXiv preprint arXiv:2006.01610 (2020)
4. Chen, X., Tian, Y.: Learning to perform local rewriting for combinatorial opti-
mization (2019)
5. Garage contributors, T.: Garage: a toolkit for reproducible reinforcement learning
research (2019). https://github.com/rlworkgroup/garage
6. Dai, H., Khalil, E.B., Zhang, Y., Dilkina, B., Song, L.: Learning combinatorial
optimization algorithms over graphs. arXiv preprint arXiv:1704.01665 (2017)
7. De Filippo, A., Lombardi, M., Milano, M.: Methods for oﬀ-line/on-line optimiza-
tion under uncertainty. In: IJCAI, pp. 1270–1276 (2018)
8. De Filippo, A., Lombardi, M., Milano, M.: The blind men and the elephant: inte-
grated oﬄine/online optimization under uncertainty. In: IJCAI (2020)
9. De Filippo, A., Lombardi, M., Milano, M.: Integrated oﬄine and online decision
making under uncertainty. J. Artif. Intell. Res. 70, 77–117 (2021)
10. Elmachtoub, A.N., Grigas, P.: Smart “predict, then optimize”. Manag. Sci. 68,
9–26 (2021)
11. Espinosa, A., Ochoa, L.: Dissemination document “low voltage networks models
and low carbon technology proﬁles.” University of Manchester, Technical report
(2015)
12. Kool, W., Van Hoof, H., Welling, M.: Attention, learn to solve routing problems!
arXiv preprint arXiv:1803.08475 (2018)
13. Lodi, A., Zarpellon, G.: On learning and branching: a survey. TOP 25(2), 207–236
(2017). https://doi.org/10.1007/s11750-017-0451-6
14. Mazyavkina, N., Sviridov, S., Ivanov, S., Burnaev, E.: Reinforcement learning for
combinatorial optimization: a survey. Comput. Oper. Res. 134, 105400 (2021)
15. Mnih, V., et al.: Human-level control through deep reinforcement learning. Nature
518(7540), 529–533 (2015)
16. Nazari, M., Oroojlooy, A., Snyder, L.V., Tak´aˇc, M.: Reinforcement learning for
solving the vehicle routing problem. arXiv preprint arXiv:1802.04240 (2018)
17. Puterman, M.L.: Markov Decision Processes: Discrete Stochastic Dynamic Pro-
gramming. John Wiley & Sons, Hoboken (2014)
18. Vaswani, A., et al.: Attention is all you need. In: Advances in Neural Information
Processing Systems, pp. 5998–6008 (2017)
19. Vinyals,
O.,
Fortunato,
M.,
Jaitly,
N.:
Pointer
networks.
arXiv
preprint
arXiv:1506.03134 (2015)
20. Williams, R.J.: Simple statistical gradient-following algorithms for connectionist
reinforcement learning. Mach. Learn. 8(3), 229–256 (1992)

Enumerated Types and Type Extensions
for MiniZinc
Peter J. Stuckey(B)
and Guido Tack
Department of Data Science and Artiﬁcial Intelligence, Monash University,
Melbourne, Australia
{peter.stuckey,guido.tack}@monash.edu
Abstract. Discrete optimisation problems often reason about ﬁnite sets
of objects. While the underlying solvers will represent these objects as
integer values, most modelling languages include enumerated types that
allow the objects to be expressed as a set of names. Data attached to an
object is made accessible through given arrays or functions from object to
data. Enumerated types improve models by making them more self doc-
umenting, and by allowing type checking to point out modelling errors
that may otherwise be hard to track down. But a frequent modelling pat-
tern requires us to add new elements to a ﬁnite set of objects to repre-
sent extreme or default behaviour, or to combine sets of objects to reason
about them jointly. Currently this requires us to map the extended object
sets into integers, thus losing the beneﬁts of using enumerated types. In
this paper we introduce enumerated type extension, a restricted form of
discriminated union types, to extend enumerated types without losing
type safety, and default expressions to succinctly capture cases where we
want to access data of extended types. The new language features allow
for more concise and easily interpretable models that still support strong
type checking and compilation to eﬃcient solver-level models.
1
Introduction
Discrete optimisation models often reason about a set of given objects, and make
use of data deﬁned on those objects. In MiniZinc [9] (and other CP modelling
languages) the core way of representing this information is as an enumerated type
deﬁning the objects, and arrays indexed by the enumerated type to store the
data. Given that debugging constraint models can be quite diﬃcult, particularly
if the solver simply fails after a large amount of computation, an important role
of enumerated types in modelling languages is to provide type safety. Many subtle
errors can be avoided if we use strong type checking based on the enumerated
types. Indeed MiniZinc and other languages such as Essence [4] provide strong
type checking of enumerated types.
One of the greatest strengths of constraint programming modelling languages
is the use of variable index lookups, i.e., looking up an array with a decision
variable, supported in CP solvers by the element constraint. Variables in CP
models are often declared speciﬁcally for this purpose. Accessing an array with an
© Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 374–389, 2022.
https://doi.org/10.1007/978-3-031-08011-1_25

Enumerated Types and Type Extensions for MiniZinc
375
incorrect index is one of the most common programming mistakes, and replacing
integer index sets with enumerated types is a powerful technique that turns
these mistakes into static compiler errors. This means that in order to index
arrays with variables, we require variables that range over an enumerated type.
Note that in the relational semantics [3] used by MiniZinc, the undeﬁnedness
from looking up an array at a non-existing index leads to falsity rather than a
runtime abort, which may be diﬃcult to detect if it does not occur in a root
context (where the constraints have to hold). Hence, enumerated types and type
checking are arguably even more important for constraint modelling languages.
However, real models are usually more complex, and quickly reach the limits
of the current support for enumerated types. Although we deﬁne a set of objects
to reason about, often modellers need to (a) add additional objects to the set
to represent extreme or exceptional cases, and/or (b) reason about two sets of
objects jointly. Currently we can resolve this problem by mapping the objects
to integers and reasoning about index sets which are subsets of integers. But in
doing so we lose the advantages of strong type checking.
In this paper we introduce mechanisms into MiniZinc that enable enumerated
types to be deﬁned by extending or joining other enumerated types, in a type-
safe way. A review of the MiniZinc benchmark library reveals that many models
can beneﬁt from these new features.
2
Preliminaries
We give a brief introduction to MiniZinc in order to help parse the example
code in the paper. A model consists of a set of variable declarations, con-
straints and predicate/function deﬁnitions, as well as an optional objective.
Basic types (for our purposes) are integers, Booleans and enumerated types.
MiniZinc also supports sets of these types. MiniZinc uses the notation l..u
to indicate the integer interval from l to u including the endpoints. We can
deﬁne parameters and variables of these types, using a declaration [var] T:
varname [= value] where T is a basic or set type or interval. Variable sets
must be over integers or enumerated types. The optional value part can be used
to initialise a parameter or variable. We can deﬁne multi-dimensional arrays
in the form array[indexset1, indexset2, .., indexsetn] of [Var] T: arrayname
where each indexseti must be a range of either integers or an enumerated type.
One of the most important constructs in MiniZinc are array comprehensions
written [ e | generator(s) ], where e is the expression to be generated. Generator
expressions can be i in S where i is a new iterator variable and S is a set, or
i in a where a is an array. These cause i to take values in order from the set
or array. Optionally they can have a where cond expression which limits the
generation to iterator values that satisfy the condition cond. We concatenate
one dimensional arrays together using the ++ operator.
Generator call expressions of the form f( generators )( e ) are syntactic sugar
for f([ e | generators ]). The most important functions used in generator call
expressions are forall (conjoining the elements of the array), exists (disjoining
the elements of the array) and sum (summing up the array elements).

376
P. J. Stuckey and G. Tack
Conditionals are of the form if cond then thenexpr else elseexpr endif.
They evaluate as thenexpr if cond is true and elseexpr otherwise. Note that cond
need not be a ﬁxed Boolean expression, but may be decided by the solver [10].
Finally we occasionally use array slicing notation. In a two dimensional array
a the expression a[i, ..] returns the one dimensional array [a[i, j] | j ∈indexset2]
where indexset2 is the second (declared) index set of array a.
3
Enumerated Types
An enumerated type is a simple type consisting of a named set of objects. Enu-
merated types are common to almost all programming languages as well as
many modelling languages. They can be just syntactic sugar for integers, as in
C; or they can be treated as distinct types by the type checker, as in Haskell,
TypeScript, or MiniZinc, giving stronger checking of programs and models. Enu-
merated types are a special case of discriminated union types.
This section gives an overview of the existing enumerated type support in
MiniZinc. Enumerated types are declared using the keyword enum. For example
an enumerated type of colours might be
enum COLOUR = { Red, Orange, Yellow, Green, Blue, Violet };
which declares not only the type COLOUR, but six constant colour identiﬁers.
These identiﬁers can then be used throughout the model. A model can also
simply deﬁne the name of an enumerated type:
enum COLOUR;
which is then speciﬁed in a data ﬁle as
COLOUR = { Red, Orange, Yellow, Green, Blue, Violet };
Alternatively an anonymous enumerated type may be constructed using
anon enum. For example, imagine we are colouring a graph with n colours, we
may use
COLOUR = anon_enum(n);
to specify the colours.
Deﬁnition 1. In MiniZinc, an enumerated type is deﬁned using the syntax
⟨enum-declaration⟩→enum id [= ⟨enum⟩]
⟨enum⟩→{ ⟨list-of-id⟩}
⟨enum⟩→anon enum ( ⟨expr⟩)
⟨list-of-id⟩→⟨list-of-id⟩, id
⟨list-of-id⟩→id
where id is a MiniZinc identiﬁer and expr is an (integer) expression. The iden-
tiﬁers deﬁned in diﬀerent enumerated types are required to be distinct.
⊓⊔

Enumerated Types and Type Extensions for MiniZinc
377
Values of an enumerated type naturally represent a set of diﬀerent, ordered
(as given in the list) objects. Operators such as =, !=, <, >= and functions such
as min and max have the natural deﬁnition on enumerated types. MiniZinc also
supports the partial function enum succ (the next element in the type) and
enum prev (the previous element in the type).
The most common use of enumerated types is as a set to iterate over in
constraints. For example a simple knapsack problem can be deﬁned by
enum PRODUCT;
int: budget;
array[PRODUCT] of int: price;
array[PRODUCT] of int: profit;
array[PRODUCT] of var bool: chosen;
constraint sum(i in PRODUCT)(price[i]*chosen[i]) <= budget;
solve maximize sum(i in PRODUCT)(profit[i]*chosen[i]);
One of the great strengths of CP modelling is the use of global constraints.
While global constraints are deﬁned on integers, we often want to apply them
to enumerated types. In MiniZinc this is accomplished by treating enumerated
types as subtypes of integers, and automatically coercing them to integers when
required. For example in the model where we are ordering people in a line
enum PERSON;
enum ORDER = anon_enum(card(PERSON));
array[ORDER] of var PERSON: x;
constraint alldifferent(x);
the alldifferent constraint acts on PERSON which are automatically coerced
into the integers {1, . . . , n} where n is the number of elements in PERSON. This
also applies when we apply arithmetic operations, e.g. the successor function
is similar in eﬀect to x + 1, which has the eﬀect of taking an enumerated
type value x, coercing it to an integer and adding one, returning an integer.
In order to map back from integers, MiniZinc supports the to enum partial func-
tion which maps an integer back to an enumerated value (when possible), e.g.
x = to enum(PERSON, y+1) returns the successor of PERSON y. According to
the relational semantics of MiniZinc, to_enum will become false in the enclos-
ing Boolean context if the given integer is outside of the valid values of the
enumerated type.
One of the reasons that enumerated types are critically important to CP
modelling languages is the use of variable array lookups. Frequently CP models
make use of the fact that we can build constraints where array lookups depend
on variables (implemented in solvers by the element constraint). Consider an
alternate knapsack model where we are restricted to take exactly k items:
int: k; int: budget;
enum PRODUCT;
array[PRODUCT] of int: price;
array[PRODUCT] of int: profit;
array[1..k] of var PRODUCT: chosen;

378
P. J. Stuckey and G. Tack
constraint alldifferent(chosen);
constraint sum(i in 1..k)(price[chosen[i]]) <= budget;
solve maximize sum(i in 1..k)(profit[i]);
Note the second last line where we use a variable of enumerated type to look up
the price of a product. This is a powerful feature of CP modelling languages.
In a language without strict type checking for enumerated types, this model
will run and give seemingly meaningful answers (as long as there are more than
k products). With strong type checking, a type error is reported, illustrating
that the last line should read
solve maximize sum(i in 1..k)(profit[chosen[i]]);
4
Type Extensions
Enumerated types are a powerful modelling tool, and strict type checking has
signiﬁcant beneﬁts, since the kind of errors that can arise without it may not nec-
essarily be obvious to track down during the solving of the model. But together
they may make it hard to express some reasonably common modelling patterns.
One such modelling pattern is that we often want to reason about two or more
sets of objects in the same way.
Example 1. Consider the usual objects for a vehicle routing problem:
enum CUSTOMER;
% set of customers to be served
enum TRUCK;
% set of trucks to deliver
The common grand tour modelling of such problems constructs a set of nodes:
one node for each customer and two for each truck, a start node representing
its leaving the depot, and an end node representing its return. Currently to
represent such nodes we are forced to use integers, e.g.
set of int: NODE = 1..card(CUSTOMER)+2*card(TRUCK);
array[NODE] of var NODE:
next;
% next node after this one
array[NODE] of var TRUCK: truck; % truck visiting node
This means we give up on type checking, risking the possibility of subtle mod-
elling errors, particularly when doing arithmetic to access the truck nodes.
⊓⊔
In order to avoid moving to integers, we propose enumerated type extensions.
They allow us to create new enumerated types by mapping existing enumerated
types using type constructors and possibly adding new elements.
4.1
Syntax and Examples
Deﬁnition 2. An enumerated type extension is deﬁned by extending the syntax
⟨enum⟩→id ( ⟨enum⟩)
⟨enum⟩→⟨enum⟩++ ⟨enum⟩
The ﬁrst rule builds a new enumerated type from an existing one via a constructor
function, while the second rule allows concatenation of enumerated types.
⊓⊔

Enumerated Types and Type Extensions for MiniZinc
379
Example 2. To express the node type using type extension we would write
enum NODE = C(CUSTOMER) ++ S(TRUCK) ++ E(TRUCK);
The new enumerated type has one element per customer and two per truck. We
can access the names of the elements using the constructor functions, so e.g. the
node for customer c is C(c) and the end node for truck t is E(t).
⊓⊔
The order of the elements in the extension types is given by the order in
the deﬁnition. In the example, customer nodes are before start nodes, which are
before end nodes. The deﬁnition automatically creates the constructor function
and its inverse, e.g. C(.) and C−1(.).1 The inverse functions are partial. For
example, C−1(S(t)), which attempts to map the start node of truck t back to
a customer, will become false in its enclosing Boolean context. We extend the
constructor function to also work on sets of the base type, e.g. C(CUSTOMER)
returns all the customer nodes.
Example 3. Given the NODE type deﬁned in Example 2, we can set up the con-
straints on the trucks visiting each node as follows:
constraint forall(n in NODE diff E(TRUCK))
(truck[next[n]] = truck[n]);
constraint forall(t in TRUCK)(truck[S(t)] = t /\ truck[E(t)] = t);
That is, the truck visiting a node also visits its successor for all but the end
nodes. And each truck visits its own start and end nodes.
⊓⊔
Note how the rules for type extension support concatenation of arbitrary
enumerated types, not just the new constructor functions. This allows us to add
“extra” elements to an enumerated type, as shown in the following example.
Example 4. A common modelling trick for vehicle routing problems where not
every customer needs to be visited is to add a dummy truck, and all non-visited
customers are “visited” by this truck. We can extended the enumerated type as
enum TRUCKX = T(TRUCK) ++ { DUMMYT };
The NODE type would then use TRUCKX instead of TRUCK. Now imagine we need
to check that the individual trucks each visit between mincust and maxcust
customers, and no more than misscust are not visited.
int: mincust;
% minimum customers visited by each truck
int: maxcust;
% maximum customers visited by each truck
int: misscust; % maximum missed customers
array[NODE] of var TRUCKX: truck; % truck or dummy visiting node
constraint global_cardinality_low_up([ truck[C(c)] | c in CUSTOMER],
TRUCKX,
[ mincust | t in TRUCK ] ++ [0],
[ maxcust | t in TRUCK ] ++ [misscust]);
1 This can be written both in ASCII as C^-1 or using the Unicode character for −1.

380
P. J. Stuckey and G. Tack
The global cardinality constraint restricts the lower and upper bounds of the
number of customers visited by each truck (including the dummy).
⊓⊔
Type extension is also useful for anonymous enumerated types, in particular
if we have two or more anonymous enumerated types that we need to treat both
separately and together.
Example 5. Consider a model for a graceful bipartite graph [5] deﬁned as:
int: left;
enum LEFT = anon_enum(left);
int: right; enum RIGHT = anon_enum(right);
array[LEFT,RIGHT] of var bool: e;
% edges
var int: m = count(e);
% number of edges
enum NODE = L(LEFT) ++ R(RIGHT);
array[NODE] of var 0..left*right: label; % node label
constraint forall(n in NODE)(label[n] <= m);
constraint alldifferent(label);
constraint alldifferent_except_0([ e[l,r]*abs(label[L(l)] - label[R(r)])
| l in LEFT, r in RIGHT ]);
The left and right nodes in the bipartite graph are separate anonymous enumer-
ated types. The graph itself is represented by a 2D array of Booleans indicating
which edges exist. We need to label nodes with diﬀerent values from 0 to m
where m is the number of edges. But the nodes are from two diﬀerent classes,
LEFT and RIGHT, so the NODE type is instrumental to deﬁning the model. Finally
each (existing) edge should be labelled with a diﬀerent number from 1 to m. ⊓⊔
4.2
Pattern Matching and Range Notation
We extend the generator syntax of MiniZinc to include pattern matching, to make
it easier to reason about diﬀerent cases. In MiniZinc one can write a generator
x in a where a is an array, so x takes the value of all elements of the array in
turn. Once we have extended enumerated types it is worth extending this syntax
to allow pattern matching: P(x) in a iterates through all elements of the form
P(b) in a, setting pattern variable x to b for each such element.
Example 6. Consider a model for scheduling search and rescue teams of up to
size members made up of humans, robots, and dogs. Each dog must be paired
with their handler, and a robot requires a team member qualiﬁed to run them.
int: size;
set of int: TEAM = 1..8;
enum PERSON;
enum DOG;
array[DOG] of PERSON: handler;
enum ROBOT;
array[PERSON] of set of ROBOT: skills;
enum MEMBER = P(PERSON) ++ D(DOG) ++ R(ROBOT) ++ { NOONE };
enum ZONE; % Zone to be searched

Enumerated Types and Type Extensions for MiniZinc
381
array[ZONE,TEAM] of var MEMBER: x;
% Each dog is paired with their handler
constraint forall(z in ZONE, D(d) in x[z,..])
(exists(t in TEAM)(x[z,t] = P(handler[d])));
% Each robot is in a team with the skills to run it
constraint forall(z in ZONE, R(r) in x[z,..])
(exists(P(p) in x[z,..])(r in skills[p]));
The constraints for dogs iterate over the zones and apply a constraint to team
members matching the pattern D(d). The robot constraints use pattern matching
twice: to match the robots in a team, and to ﬁnd the matching person.
⊓⊔
4.3
Implementing Enumerated Type Extension
Enumerated type extension allows for type safe construction of new types. Inter-
estingly we can implement this feature entirely as syntactic sugar, i.e., by auto-
matically rewriting extended enumerated types into standard MiniZinc.
In order to implement this feature, the MiniZinc lexer and parser need to
be extended so that they recognise the new syntax. The type checking phase of
the compiler is extended to introduce the new enumerated type, the constructor
functions and inverse constructors. It makes use of the fact that we can always
map enumerated types to integers.
Example 7. Consider the NODE type deﬁned in Example 2. This is translated to
a series of deﬁnitions:
int: nc = card(CUSTOMER);
int: nt = card(TRUCK);
enum NODE = anon_enum(nc + nt + nt);
function var NODE: C(var CUSTOMER: c) = to_enum(NODE,c);
function var NODE: S(var TRUCK: t) = to_enum(NODE,nc + t);
function var NODE: E(var TRUCK: t) = to_enum(NODE,nc + nt + t);
function var CUSTOMER: C−1(var NODE: n) = to_enum(CUSTOMER,n);
function var TRUCK: S−1(var NODE: n) = to_enum(TRUCK,n - nc);
function var TRUCK: E−1(var NODE: n) = to_enum(TRUCK,n - nc - nt);
We introduce a new anonymous enumerated type of the right size. Each of the
constructor functions coerces the original enumerated types to nodes using the
to enum function. Each of the inverse constructor functions performs the reverse
coercion. Note that to enum(E, i) is a partial function which is undeﬁned if the
integer second argument i is outside 1..card(E). This gives exactly the right
behaviour for the partial inverse constructors. In the implementation we extend
the constructors to also work on sets, and return sets, and generate specialized
versions for when the input argument is ﬁxed at compile time.
⊓⊔
Pattern matching expressions are again treated as syntactic sugar. The
expression [ g(x)
|
P(x) in a ] where x has type T is mapped to
[ if e in P(T) then g(P−1(e)) else <> endif | e in a ]

382
P. J. Stuckey and G. Tack
The absent value <> acts as an identity element for the operator applied to
the array, for more details see [8]. For special cases, in particular where a has
par type (i.e., the test whether an element in a has the constructor P can be
performed at compile time), we can avoid the creation of an array containing <>
elements, but we leave out the details for brevity.
Example 8. The pattern matching in Example 6 is translated to
constraint forall(z in ZONE, e in x[z,..])
( if e in D(DOG) then
exists(t in TEAM)(x[z,t] = P(handler[D−1(e)]))
else true endif);
constraint forall(z in ZONE, e in x[z,..])
( if e in R(ROBOT) then
exists(f in x[z,..])
( if f in P(PERSON) then R−1(e) in skills[P−1(f)]
else false endif )
else true endif);
where the compiler has replaced the absent value <> by the correct identity
elements, false for the exists, and true for the two forall functions.
⊓⊔
5
Defaults
In MiniZinc, objects represented as enumerated types are usually implemented
via arrays indexed by an object identiﬁer. Type safety will check that we only
access these arrays with the correct type. But this will often require us to guard
the access to avoid undeﬁnedness.
Example 9. In the vehicle routing problem, a critical part of the model is decid-
ing arrival times at each node, based on some travel time matrix. Given data on
customers and locations
enum LOCATION;
% set of locations of interest
array[CUSTOMER] of LOCATION: loc;
% location of customer
LOCATION: depot;
% depot location
array[LOCATION,LOCATION] of int: tt; % travel time loc -> loc
array[CUSTOMER] of int: service;
% service time at customer
A model could decide the arrival time at each node as follows.
int: maxtime; set of int: TIME = 0..maxtime;
array[NODE] of var TIME: arrival;
% arrival time at node
constraint forall(t in TRUCK)(arrival[S(t)] = 0);
% start nodes
constraint forall(n in NODE diff E(TRUCK))(
arrival[next[n]] >= arrival[n] +
if n in C(CUSTOMER) then service[C−1(n)] else 0 endif +
tt[if n in C(CUSTOMER) then loc[C−1(n)] else depot endif,
if next[n] in C(CUSTOMER) then loc[C−1(next[n])] else depot endif]
);

Enumerated Types and Type Extensions for MiniZinc
383
Note that we need to guard the lookup of the service time and location arrays to
check that the node represents a customer, and then extract the customer from
the node name.
⊓⊔
5.1
The default Operator
The guarding of data lookups, as well as the use of the inverse constructor to
extract the subtype information is verbose. In order to shorten models and make
them more readable we introduce default expressions into MiniZinc. Default
expressions are not directly related to type extensions, rather they are a way of
capturing undeﬁnedness. However, they become particularly useful due to the
addition of (partial) inverse enum constructors.
In MiniZinc expressions can be undeﬁned, and take the value ⊥, as a result
of division by zero, or by accessing an array out of bounds. The undeﬁned value
percolates up the expression, making all enclosing expressions also undeﬁned
⊥until a Boolean expression is reached where the undeﬁnedness is interpreted
as false; thus following the relational semantics treatment of undeﬁnedness in
modelling languages [3].
Many languages feature similar functionality. For example, C/C++ program-
mers may use a ternary operator to guard against nullptr. Haskell programmers
would use the maybe function, and in Rust you might use unwrap or.
Deﬁnition 3. The default expression x default y takes the value x if x is
deﬁned (not equal to ⊥) and y otherwise. If x and y are both ⊥the expression
evaluates to ⊥.
⊓⊔
Example 10. With default expressions we can drastically shorten the arrival time
reasoning shown in Example 9:
constraint forall(n in NODE diff E(TRUCK))(
arrival[next[n]] >= arrival[n] +
service[C−1(n)] default 0 +
tt[loc[C−1(n)] default depot, loc[C−1(next[n])] default depot]
)
The partial function C−1(n) results in undeﬁnedness when node n is not a cus-
tomer node. This also makes the resulting array lookup undeﬁned, which is then
replaced by the default value.
⊓⊔
Default expressions are also useful for guarding other undeﬁnedness
behaviour. For example to calculate the minimum positive value occurring in
a list, or return 0 if there are none, we can write
var int: minval = min([x | x in xs where x > 0]) default 0;
Defaults can also be useful for simplifying integer reasoning.
Example 11. A frequent idiom in constraint models over 2D representations of
space is to use a matrix indexed by ROW and COL(umn). But then care has to be
taken when indexing into the matrix. Imagine choosing k diﬀerent positions in
a matrix where the sum of (orthogonally) adjacent positions is non-negative. A
model encoding this is

384
P. J. Stuckey and G. Tack
int: nrow; set of int: ROW = 1..nrow;
int: ncol; set of int: COL = 1..ncol;
array[ROW,COL] of int: m;
% given matrix
array[1..k] of var ROW: y; % row position chosen
array[1..k] of var COL: x; % col position chosen
constraint alldifferent([y[i]*ncol + x[i] | i in 1..k]);
constraint forall(i in 1..k)
(sum(dr in -1..1, dc in -1..1 where abs(dr)+abs(dc) = 1)
(if y[i]+dr in ROW /\ x[i]+dc in COL
then m[y[i]+dr,x[i]+dc] else 0 endif) >= 0);
Notice that the model has to guard against the possibility that the position
chosen is on one of the extreme rows or columns, e.g. y[i] = 1, since when
dr = -1 the lookup of m will fail and the relational semantics [3] will make
the sum false. We can replace the sum if-then-else-endif expression simply by
m[y[i]+dr,x[i]+dc] default 0.
⊓⊔
5.2
Implementing Defaults
A naive implementation would simply replace the expression x default y by
if defined(x) then x else y endif
given a suitable built-in function defined. Internally, the MiniZinc compiler
already evaluates each expression into a pair of values: the result value of the
expression, and a Boolean that signals whether the result is deﬁned. We therefore
chose to implement the default operator as a special built-in operation that can
directly access the partiality component.
For the use case where the undeﬁnedness arises from array index value out
of bounds, the motivating case we consider, the MiniZinc compiler can choose
to implement the default in a more eﬃcient way than using if-then-else-endif.
For an expression a[i] default y where i may possibly be outside the index
set I of a we can build an extended array ax over the index set lb(i)..ub(i), where
ax[i] = y for i ̸∈I, where lb(i) (ub(i)) is the least (greatest) value in the declared
domain of i.
We can extend this rewriting also to expressions of the form a[f(i)] default y
where f is a (possibly partial) function, by building an array ax over the index
set lb(i)..ub(i) where ax[i] = y for f(i) ̸∈I (including the case that f(i) is not
deﬁned) and ax[i] = a[f(i)] otherwise.
Example 12. This is particularly useful for undeﬁnedness that results from the
use of inverse constructors. Here we extend the array type to the full supertype
NODE. Consider the arrival time constraint shown in Example 10. The automatic
translation of defaults as extended arrays would then be
array[NODE] of int: servicex = array1d(NODE,
[ if n in C(CUSTOMER) then service[C−1(n)] else 0 endif | n in NODE]);
array[NODE] of LOCATION: locx = array1d(NODE,
[ if n in C(CUSTOMER) then loc[C−1(n)] else depot endif | n in NODE]);
constraint forall (n in NODE where not (n in E(TRUCK))) (
arrival[next[n]] >= arrival[n] + servicex[n] +
tt[locx[n],locx[next[n]]]);

Enumerated Types and Type Extensions for MiniZinc
385
This is essentially equivalent to how an expert might write the model using
integer indices.
⊓⊔
We can use the same approach for higher-dimensional arrays (as in Exam-
ple 11). Note that if the bounds of the index variable i are substantially larger
than the original index set of the array, the compilation approach may produce
very large arrays (particularly for multi-dimensional arrays). Currently we limit
the compilation of default expressions on arrays to no more than double the size
of the original array, otherwise the if-then-else-endif interpretation is used.
6
Experiments
The ﬁrst experiment is qualitative, examining how valuable the language exten-
sions we propose here are likely to be. Considering all the models used in the
MiniZinc challenge2 as a representation of a broad range of constraint program-
ming models, we examined each of the models to determine (a) if the model could
be improved with (more) enumerated types; and (b) if the model could beneﬁt
from extensions and defaults. Note that some models used in the challenge were
written before enumerated types were available in MiniZinc. In addition expert
modellers (particularly those used to modelling directly for solvers) who submit
models to the challenge often use integer domains even when an enumerated
type might be suggested from the problem.
Of the 129 models used in the challenge over its history we ﬁnd 15 that
could make use of enumerated type extensions to improve type safety. Another
64 models could improve type safety simply by using enumerated types. Clearly
the extensions we develop here are not restricted to a very special class of models.
As an example of a model that could be improved using enumerated type
extensions we illustrate parts of the freepizza model. In the problem you must
purchase a set of pizzas each with a given price, but you have vouchers that can
be used, e.g. buy 2 get 1 free. A voucher is enabled by buying enough pizzas for
it, then it can be used to get some free pizzas, but the free pizzas must always
be no more expensive than the enabling bought pizzas. The key decisions in the
original model are how you bought each pizza, expressed as follows.
int: m; % no of vouchers
set of int: VOUCHER = 1..m;
set of int: ASSIGN = -m .. m; % -i pizza is used to buy voucher
%
i pizza is for free using
%
0 no voucher used on pizza
array[PIZZA] of var ASSIGN: how;
2 https://github.com/minizinc/minizinc-benchmarks.

386
P. J. Stuckey and G. Tack
A key constraint in the model ensures that pizzas that enable a voucher are no
less expensive than pizzas obtained for free:
constraint forall(p1, p2 in PIZZA)
((how[p1] < how[p2] /\ how[p1] = -how[p2])
-> price[p2] <= price[p1]);
The ASSIGN set used in this model is an ideal case for an extended enumerated
type. We can rewrite the model in a type-safe way as
int: m; % no of vouchers
enum VOUCHER = anon_enum(m);
% strong type check for VOUCHER
set of int: ASSIGN = Buy(VOUCHER) ++
% pizza is used to buy voucher v
{ NOVOUCHER } ++ % no voucher used on pizza
Free(VOUCHER);
% pizza is for free using voucher v
array[PIZZA] of var ASSIGN: how;
The critical constraint is now simply
constraint forall(p1, p2 in PIZZA)
(Free(Buy−1(how[p1])) = how[p2]
-> price[p2] <= price[p1]);
The partiality of the inverse constructors is used to trivially satisfy the implica-
tion. We would argue that the resulting model is far easier to understand than the
original, and compared to the set -m..m, the extended type is self-documenting.
Indeed a version of the original model has been used as a debugging exercise,
since it is quite hard to reason about it. Note that because the original model
uses negation to indicate that a voucher is bought, it represents those vouchers
in the reverse order compared to the extended enum. The solver may therefore
perform a diﬀerent search, which results in diﬀerent runtime behaviour (faster
for some instances, slower for others). If negation -v in the original model is
replaced by v-m-1, the two models behave identically.
Our second experiment demonstrates that translating array access expres-
sions with defaults by extending the array with the default elements can lead
to improvements in solving time. We ran a version of the capacitated vehicle
routing problem from the MiniZinc benchmarks repository,3 which we modiﬁed
to use enumerated types and defaults. Table 1 shows the solving time and num-
ber of variables of defaults implemented as if-then-else-endif expressions4 versus
the extended arrays as explained in Example 12. For the experiments, we used
the Chuﬀed solver with a timeout of 10 min, A-n64-k9 and B-n45-k5 data ﬁles,
reduced to 8 and 9 customers to enable complete solving within the timeout.
The results show an average improvement in solving time of 20%–30%, and a
small reduction in the number of generated variables.
3 https://github.com/minizinc/minizinc-benchmarks.
4 Compiled as described in [10].

Enumerated Types and Type Extensions for MiniZinc
387
Table 1. Solving times and number of generated variables for Chuﬀed on several
CVRP instances with 8 and 9 customers, extended arrays (x[y]) versus if-then-else
expressions (i-t-e).
Instance/Customer set Solving time (sec) No. of variables
x[y]
i-t-e x[y]
i-t-e
B-n45-k5/1–8
1.724
2.060 39 794 40 122
B-n45-k5/9–16
1.776
2.217 39 722 40 050
A-n37-k5/1–8
6.997
8.251 38 372 38 700
A-n37-k5/17–24
9.432
10.726 37 894 38 222
B-n45-k5/25–32
9.545
12.340 41 262 41 590
A-n37-k5/9–16
10.115
14.727 33 104 33 432
B-n45-k5/17–24
13.290
24.691 43 556 43 884
A-n37-k5/25–32
20.608
35.316 33 834 34 162
B-n45-k5/1–9
31.266
43.143 47 683 48 065
B-n45-k5/19–27
125.936
177.199 54 928 55 183
B-n45-k5/28–36
159.009
209.935 50 427 50 809
A-n37-k5/1–9
174.749
223.807 46 499 46 881
B-n45-k5/10–18
169.007
229.181 45 787 46 169
A-n37-k5/19–27
189.714
265.302 42 611 42 993
A-n37-k5/10–18
254.691
346.922 47 647 48 029
A-n37-k5/28–36
262.204
366.466 42 347 42 729
7
Related Work
Most programming languages support enumerated types in some form, it being
a critical feature to avoid “magic constants”. Enumerated type extension corre-
sponds to using discriminated unions, for languages where those are available.
No modelling language we are aware of except Zinc [7] supports such types, but
Zinc does not support variables of such types, defeating one of the key purposes
for introducing enumerated type extension.
AMPL [2] supports using sets of strings to deﬁne a form of enumerated types.
Since the strings are only ever used as ﬁxed parameters (there are no variables
of type string) the language checks correct array lookups for arrays indexed by
sets of strings during model compilation.
Similarly, OPL [11] does not support enumerated types, rather it supports
the string data type, and the eﬀect of enumerated types is mimicked by using
sets of strings. Again since there are no variables of string type, the array index
lookup for string indices is restricted to ﬁxed parameters and checked during
model compilation. Note that using strings to encode enumerated types has the
advantage that one can simply build an array indexed by the union of two sets
of strings, but this is not that helpful in the NODE example where we want to

388
P. J. Stuckey and G. Tack
associate two nodes to each TRUCK. OPL does support arrays indexed by more
complex types such as tuples which can signiﬁcantly improve some models.
Essence [4] supports enumerated types that are very similar to MiniZinc’s.
They can be explicitly deﬁned by sets of identiﬁers, in the model or the data, or
deﬁned as anonymous new types by size. Enumerated types can be used almost
anywhere in the complex type language of Essence which includes parametric
types for sets, multisets, functions, tuples, relations, partitions and matrices.
Enumerated types support equality, ordering, and successor and predecessor
functions. Essence is strongly typed, ensuring that all uses of enumerated types
are correct. Currently there is no way to coerce an enumerated value to an
integer within Essence. In order to make use of global constraints on enumerated
types the mapping of enumerated types to integers is performed during the
translation of Essence to Essence’ by Conjure. Because of this restriction there
is no way to write an Essence model for the VRP using enumerated types, since
one cannot associate enumerated types with (even integer) node values. This
means an Essence model for VRP will be forced to use integers for all types
CUSTOMER, TRUCK and NODE, thus losing strong type checking. We believe that
the Essence type system can be extended to support the concepts presented here.
There are a number of constraint modelling languages with a focus on object
orientation, where complex data is given as sets of objects as opposed to arrays
indexed by enumerated types, and subclassing provides another approach to
eﬀectively reason about multiple diﬀerent types of objects simultaneously.
In s-COMMA [1] one can deﬁne classes which include constraints across their
ﬁelds, and (single inheritance) subclassing. Enumerated types are supported as
base types (which cannot be subclasses). There are no variables that range across
objects, meaning that the issues we address here don’t arise.
ConfSolve [6] is an object-oriented modelling language aimed at specifying
conﬁguration problems. Again it supports enumerated types as base types that
cannot be extended. The class system supports reference types which allow for
powerful modelling of complicated relationships. This allows for similar kinds
of subclass reasoning as extended enumerated types. It is not clear exactly how
much type checking is applied to ConfSolve models. Interestingly the models are
compiled to MiniZinc to actually run, essentially mapping object identiﬁers to
integers and using arrays to represent ﬁelds and pointers to other objects.
8
Conclusion
Enumerated types are critical for type safety of models that manipulate objects.
Type extension allows us to have the same safety properties for models that
manipulate two sets of objects together, or need to extend a set of objects to
deﬁne extreme cases. This is a frequent modelling pattern in complex constraint
programming models. Hence we believe all CP modelling languages should sup-
port them. In this paper we show how they are implemented in MiniZinc, with
enough detail so that other modelling language authors can translate the ideas
to their own language.

Enumerated Types and Type Extensions for MiniZinc
389
We believe the use of enumerated types by modellers should be strongly
encouraged, since we know that debugging models can be very challenging, and
strong type checking of array access and function arguments can prevent very
subtle errors when the model is solved.
Future work. The concept of enumerated type extension should generalise to
tuple and record types, although the interactions of these types with arrays and
decision variables are more diﬃcult to handle in the compiler. Such an extension
would make it much easier to interface MiniZinc models with object-oriented
programming languages and data sources.
Acknowledgments. This research was partially supported by the OPTIMA ARC
training centre IC200100009.
References
1. Chenouard, R., Granvilliers, L., Soto, R.: Model-driven constraint programming.
In: Proceedings of the 10th International ACM SIGPLAN Symposium on Prin-
ciples and Practice of Declarative Programming, PPDP 2008 (2008). https://doi.
org/10.1145/1389449.1389479
2. Fourer, R., Kernighan, B.: AMPL: A Modeling Language for Mathematical Pro-
gramming. Duxbury (2002)
3. Frisch, A.M., Stuckey, P.J.: The proper treatment of undeﬁnedness in constraint
languages. In: Gent, I.P. (ed.) CP 2009. LNCS, vol. 5732, pp. 367–382. Springer,
Heidelberg (2009). https://doi.org/10.1007/978-3-642-04244-7 30
4. Frisch, A.M., Harvey, W., Jeﬀerson, C., Hern´andez, B.M., Miguel, I.: Essence:
a constraint language for specifying combinatorial problems. Constraints 13(3),
268–306 (2008)
5. Golomb, S.W.: How to number a graph. In: Graph Theory and Computing. Aca-
demic Press (1972)
6. Hewson, J.A.: Constraint-based speciﬁcation for system conﬁguration. Ph.D. the-
sis, University of Edinburgh (2013)
7. Marriott, K., Nethercote, N., Rafeh, R., Stuckey, P., Garcia de la Banda, M.,
Wallace, M.: The design of the Zinc modelling language. Constraints 13(3), 229–
267 (2008). https://doi.org/10.1007/s10601-008-9041-4
8. Mears, C., Schutt, A., Stuckey, P.J., Tack, G., Marriott, K., Wallace, M.: Mod-
elling with option types in MiniZinc. In: Simonis, H. (ed.) CPAIOR 2014. LNCS,
vol. 8451, pp. 88–103. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-
07046-9 7
9. Nethercote, N., Stuckey, P.J., Becket, R., Brand, S., Duck, G.J., Tack, G.: MiniZinc:
towards a standard CP modelling language. In: Bessi`ere, C. (ed.) CP 2007. LNCS,
vol. 4741, pp. 529–543. Springer, Heidelberg (2007). https://doi.org/10.1007/978-
3-540-74970-7 38
10. Stuckey, P.J., Tack, G.: Compiling conditional constraints. In: Schiex, T., de Givry,
S. (eds.) CP 2019. LNCS, vol. 11802, pp. 384–400. Springer, Cham (2019). https://
doi.org/10.1007/978-3-030-30048-7 23
11. Van Hentenryck, P.: The OPL Optimization Programming Language. MIT Press
(1999)

A Parallel Algorithm for GAC Filtering
of the Alldiﬀerent Constraint
Wijnand Suijlen(B)
, F´elix de Framond, Arnaud Lallouet
,
and Antoine Petitet
Huawei Technologies France, Paris Research Center, CSI, Boulogne-Billancourt,
France
{wijnand.suijlen,arnaud.lallouet,antoine.petitet}@huawei.com
Abstract. In constraint programming the Alldiﬀerent constraint is one
of the oldest and most used global constraints. The algorithm by R´egin
enforces generalized arc-consistency, which is the strongest level of con-
sistency for a single constraint. It is also the most time consuming despite
several optimizations that were developed by others.
This paper parallelizes the Alldiﬀerent generalized arc-consistent ﬁl-
tering algorithm, which is one of the ﬁrst attempts for any global con-
straint. It does so by using a parallel graph search algorithm for two major
parts of R´egin’s algorithm: ﬁnding a maximum matching and ﬁnding the
strongly connected components. Most eﬀective known optimizations are
also ported. Experiments solving a large N-queens problem or a resource
constrained scheduling problem show that generalized arc-consistent ﬁl-
tering can be signiﬁcantly sped-up on a 64-core shared-memory system
and on a 200-core distributed-memory system. We discuss also several sce-
narios where this algorithm should be applied or not.
1
Introduction
A major strength of Constraint Programming is the availability of global con-
straints. First, they provide a meaningful modeling element natural to the user,
because it either occurs frequently in models or because it is strongly related to a
speciﬁc application. The Alldiﬀerent constraint falls in the ﬁrst category, while,
for example, the Cumulative constraint falls in the second one. Also, they speed
up the programming process, because they encapsulate complex algorithms.
Alldiﬀerent is one of the most useful and widely used global constraints.
It ensures that a vector of variables will take diﬀerent values. Stating
Alldiﬀerent(x1, x2, x3) is equivalent to stating the conjunction x1 ̸= x2, x2 ̸= x3,
and x1 ̸= x3. Such conditions often arise as pigeonhole argument in optimization
problems where resources are assigned exclusively. The particular interest of this
constraint as modeling brick has attracted a lot of attention to its ﬁltering algo-
rithm [16], from the simple decomposition into a clique of diﬀerences to the full,
generalized arc-consistent ﬁltering algorithm by R´egin [28]. In combination with
precedence constraints, more eﬀective ﬁltering algorithms also exist [3]. For an
extensive survey of the various consistencies and algorithms, we refer the reader
to [16] and the original works [22–24,27,28]. In practice, choosing a proper level
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 390–407, 2022.
https://doi.org/10.1007/978-3-031-08011-1_26

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
391
of consistency can reduce the resolution time considerably, but this is highly
problem dependent and out of the scope of this paper.
R´egin [28] describes a GAC ﬁltering algorithm which operates on the bipartite
graph connecting variables and values. It can be rephrased in three major steps:
ﬁnd a maximum matching to get a support, interpret this matching as a ﬂow
and compute its residual, ﬁnd its strongly connected components and remove
inter-component arcs. This algorithm is a major contribution to Constraint Pro-
gramming and has paved the way to a vast literature on global constraints [17].
Yet, while subsequent authors have developed several optimizations [11,26,37],
all previous work only considers a sequential or a very limited (SIMD) parallel
[21] environment, which begs the question what a more general parallel environ-
ment can add, focusing only on the ﬁltering algorithm itself.
This paper proposes to parallelize the algorithm’s two main components:
maximal matching (MM) and strongly connected components (SCC). We use
the Ford-Fulkerson algorithm with Breadth-First Search (BFS) as basis of the
matching algorithm because it was found to be faster than the original Hopcroft-
Karp algorithm by [11]. Both MM and SCC can be expressed in terms of reacha-
bility queries which can be parallelized. Our ﬁrst version of the parallel algorithm
uses a regular, single source BFS and we present two optimizations. The ﬁrst one
replaces BFS by a diﬀerent traversal we call Local-First Search that gives priority
to local data. The second one performs multiple search queries in parallel; i.e., a
multi-source query. In the experimental evaluation, that studies the algorithm in
isolation from other parallelization techniques, such as parallel search or parallel
propagation, we observe the algorithm performance on two applications that are
varied in size, vertex degree, and the amount of backtracking required.
The structure of the paper is as follows. Section 2 summarizes R´egin’s GAC
ﬁltering algorithm whose sequential algorithm forms the basis of ours. As intro-
duction to parallel programming, Sect. 3 brieﬂy treats the Bulk Synchronous
Parallel model. Then, Sect. 4 develops the parallel algorithm. Experiments are
conducted in Sect. 5 whose results are discussed and related to other work in
Sect. 6.
2
R´egin’s Alldiﬀerent Filtering Algorithm
The ﬁltering algorithm by [28] represents the problem as the bipartite variable-
value graph G = (X ∪D, E). It has a vertex for each variable and for each
domain value. Between every variable x ∈X and domain value d ∈Dx, there is
an edge (x, d) ∈E. Now, the act of ﬁltering coincides with removing edges from
this graph. In order to decide which edges to remove, the algorithm proceeds in
four steps:
1. Find a maximum matching (Fig. 1a). In ﬁltering rounds after initial propa-
gation, the maximum matching from the previous round can be reused. If
none of the variables lost a value that was also in the previous matching, the
same matching can be reused straight away. Otherwise, the matching should
be repaired by ﬁnding augmenting paths. If one or more variables cannot be
matched, the domain is inconsistent (Fig. 1b).

392
W. Suijlen et al.
a
b
c
1
2
3
4
(a)
a
b
c
1
2
3
4
(b)
a
b
c
1
2
3
4
s
t
(c)
a
b
c
1
2
3
4
s
t
(d)
Fig. 1. Example graphs for variables X = {a, b, c} and domain D = {1, 2, 3, 4}: (a)
Maximum matching, (b) domain failure, (c) residual ﬂow graph, (d) strongly connected
components
2. Interpret the maximum matching as a maximum ﬂow through the digraph
Gf = (X ∪D ∪{s, t}, A) with arcs from the source vertex s to all variables,
from all domain values to the sink vertex t, and from each variable to each
domain value that is in its domain. Now, the maximum matching deﬁnes a
maximum ﬂow through Gf and so the residual ﬂow graph Gr (Fig. 1c) can
be constructed by reversing those arcs that appear in the maximum ﬂow.
3. Find all strongly connected components (SCCs) in Gr (Fig. 1d).
4. The arcs which are not in the matching while their endpoints lie in diﬀerent
SCCs, cannot be part in any (other) maximum matching. Thus, these can be
removed.
For a correctness proof the reader is referred to [11] and [16].
Several algorithms exist that can ﬁnd a maximum matching. Empirical study
[11] showed that an application of the Ford-Fulkerson algorithm in breadth-
ﬁrst search order, denoted by the abbreviation FF-BFS, is often the quickest.
A BFS has time complexity O(X + D + E) in the worst case and FF-BFS
requires X of those traversals. Hence, the time complexity for ﬁnding a maximum
matching initially is O(X(X +D +E)), while each incremental reparation for m
removed edges from the matching requires O(m(X + D + E)) time. For ﬁnding
SCCs, Tarjan’s algorithm [33] is a very eﬃcient sequential algorithm with a
O(X + D + E) time complexity. It requires only one depth-ﬁrst search (DFS)
graph traversal.
The main workload of both algorithms is the graph traversal itself and is
mainly bottlenecked by memory access. By reducing these memory footprint
to a minimum, e.g. by exploiting the particular structure of the graph and by
encoding the graph eﬃciently, raw processing speed can be optimized. In order to
evaluate our parallel Alldiﬀerent ﬁltering algorithm, we implemented the sequen-
tial algorithm too. Not only did we focus on good raw processing eﬃciency, but
we also applied more sophisticated optimizations as described in [11]. In par-
ticular, we implemented incremental matching and exploiting strongly connected
components. Pseudo code of the sequential ﬁltering algorithm appears below as
Procedure 1 (SeqAllDiﬀFilter).
Exploiting strongly connected components is a form of decomposition. It rec-
ognizes that during the next incremental matching an augmenting path cannot
cross SCCs, and that therefore SCCs can only split and never join. Eﬀectively,

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
393
each SCC can be regarded as an independent Alldiﬀerent constraint on only the
variables and domain values that constitute that SCC.
Procedure 1: SeqAllDiﬀFilter(X, U, D, M, S)
In: Variables X, updated variables U ⊆X.
In/Out: Domains (Dx)x∈X (GAC output), matching M, SCC Gr partition S.
Data: Gr: the residual ﬂow graph that matches the matching M
1 foreach SCC S ∈S with S ∩U ̸= ∅do
2
foreach x ∈S not in M do
/* Repair matching with FF-BFS */
3
BFS of augmenting path in Gr starting from x;
4
If unsuccessful, return “Inconsistent”;
5
Otherwise, update M and Gr with the augmenting path;
6
end
7
foreach x ∈S still unvisited by Tarjan do
/* Tarjan’s algorithm */
8
DFS traversal of S in Gr starting from x;
9
Split SCC S into the SCCs that were found by above DFS ;
10
Remove edges from E that cross SCCs and are not in matching M;
11
Update variable domains Dx for each x ∈S and update Gr;
12
end
13 end
14 return “Consistent”;
3
Bulk Synchronous Parallel Model
Since the main motivation of parallel computing is to increase processing speed,
it is essential to have a model that can analyze the time complexity of a parallel
algorithm. We choose the Bulk Synchronous Parallel (BSP) bridging model [35],
because it is simple and accurate up to small constant factors. It describes how
a parallel workload can be mapped to any parallel computer.
The BSP model assumes a BSP computer with three types of components:
P processors with local memory, a communications network that can route mes-
sages between individual processors, and a synchronization facility that can syn-
chronize all processors at once. Operations on these components cost time. The
model counts g time units for the transmission of each word, while it counts ℓ
time units for the synchronization of all processors at once.
Time 
1. Computation
2. Communication
3. Synchronisation
and so forth...
Superstep S S+1
Processor 1
P
2
...
Fig. 2. Time-activity diagram of any BSP program

394
W. Suijlen et al.
Such a BSP computer can be programmed in direct mode with a BSP pro-
gram, whose execution proceeds through supersteps. Each superstep consists of
two phases: a computation phase, in which each processor s works Ws time
alone, and a communication phase, in which processors send and receive at most
Hs data. Between each superstep, the BSP computer synchronizes all processors
(see Fig. 2 for an illustration of activity in a BSP program over time). The time
to complete a superstep is hence maxs Ws + maxs Hsg + ℓ.
Notations. The algorithms that follow in subsequent sections are listed as Single
Program Multiple Data (SPMD) procedures, meaning that the same code is
executed on every process using s as process identiﬁer (0 ≤s < P). All data
held by variables indexed with s and iteration variables are local to the process.
The s index is omitted for data which are known to be the same on all processes,
even if their implementation is done by a diﬀerent variable on each process. Data
can only be shared by explicit communication.
4
A Parallel Alldiﬀerent Filtering Algorithm
We propose a parallel ﬁltering algorithm for the Alldiﬀerent constraint that
follows the same ideas as R´egin’s sequential algorithm [28]. Main workload of
his algorithm is ﬁnding a maximum matching and ﬁnding all SCCs.
Observe that maximum matching and SCCs can both be found through
reachability queries. The Ford-Fulkerson method relies on identiﬁcation of aug-
menting paths, which is a reachability problem. For ﬁnding SCCs, Tarjan’s
algorithm is avoided, because depth-ﬁrst search is hard to parallelize eﬃciently.
Instead, the membership of a vertex to the SCC of another vertex can be decided
by reachability queries in both forward and backward direction of the arcs. Then,
in a divide-and-conquer fashion, all SCCs in a graph are identiﬁed by repeatedly
removing SCCs.
ParAllDiﬀFilter. The basis of our parallel Alldiﬀerent ﬁltering algorithm is out-
lined as Procedure 2 (ParAllDiﬀFilter). This SPMD procedure engages all pro-
cessors in the same computation, that removes all inconsistent domain values,
while each processor stores an equal part of the graph. It traverses each SCC
that contains a modiﬁed variable, picks an unmatched variable vertex (line 2),
restores the matching in parallel using FindAugmentingPath (Procedure 3) and
ﬁnds the SCCs with the parallel procedures ForwardReachable (Procedure 7) and
BackwardReachable. Note that the deﬁnition of BackwardReachable is identi-
cal to ForwardReachable but follows arcs in the reverse direction. The initial
propagation calls this procedure with ParAllDiﬀFilter(X, X, D, ∅, {X}).
Some improvements to ParAllDiﬀFilter are not explored. SCCs are not pro-
cessed in parallel (the foreach-loop lines 1–12), because the Search procedure
is already parallel and experiments suggest that there is usually one non-trivial
SCC, which contains all the undecided variables. For the same reason, the pos-
sibility to ﬁnd multiple SCCs (lines 7–11) simultaneously, see e.g. [5], is not
explored.

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
395
Procedure 2: ParAllDiﬀFilter(X, U, D, M, S)
In: Variables X evenly assigned to all processes, updated variables U ⊆X.
In/Out: Domains (Dx)x∈X (GAC output), matching M, SCC Gr partition S.
Data: Gr residual ﬂow graph from matching M; t sink vertex; S′ new SCCs
1 foreach SCC S ∈S with S ∩U ̸= ∅do
2
foreach x ∈S ∩X\M do
/* Repair matching */
3
path A ←FindAugmentingPath(Gr, x, t);
4
if A = ∅then return “Inconsistent”;
5
update M and Gr with the (augmenting) path A
6
end
7
while S ̸= ∅do
/* Find SCCs and filter domains */
8
Pick v ∈S;
9
T ←ForwardReachable(Gr, v) ∩BackwardReachable(Gr, v);
10
S′ ←S′ ∪{T};
11
S ←S\T; foreach x ∈T ∩X do Dx ←Dx ∩T ;
12
end
13 end
14 S ←S′;
15 return “Consistent”;
FindAugmentingPath. FindAugmentingPath is used to restore a matching for
a variable x. It proceeds in two steps. First it calls Procedure 4 (Search) that
returns a tree rooted by x in which appears the target t. Then, starting from the
target, it repeatedly gets the parent node from the process which owns it until
the augmenting path a is gathered (lines 3 to 7).
Search. The Search procedure builds a tree in Ts whose arcs are again distributed
over the processes. For this, it performs a parallel breadth-ﬁrst search traversal
through the residual graph from the root r, until the target t is found. Parallel
BFS is a work-eﬃcient algorithm because its total number of operations is pro-
portional to the best sequential algorithm. Parallel algorithms with lower time
Procedure 3: FindAugmentingPath(G, r, t)
In: Graph G, source vertex r, target vertex t
Out: The augmenting path a to the target t if it was found or ∅otherwise
1 Ts ←∅; a ←∅; v ←t;
2 if Search(G, r, t, Ts) then
3
while v ̸= r do
4
if process s owns v then pick ws s.t. (v, ws) ∈Ts and broadcast it;
5
Synchronize;
6
Receive broadcast as w;
7
a ←a ∪{(w, v)}; v ←w;
8
end
9 end
10 return a;

396
W. Suijlen et al.
Procedure 4: Search(G, r, t, Ts)
In: Graph G, root vertex r, target vertex t
Out: Boolean found whether vertex t was found; local arcs Ts of spanning tree
Data: A visited status visiteds[v] ∈{0, 1} for each local vertex v, the
parent-child vertex pair sets Js and Ks for the current and next levels
1 found ←0; visiteds[v] ←0 for each local vertex v;
2 if r is local vertex then Js ←{(⊥, r)} else Js ←∅;
3 repeat
4
Ks ←∅; fs ←0;
5
foreach (i, j) ∈Js do VisitLocal(G, i, j, t, Ts, visiteds[], fs, Ks);
6
foreach (j, k) ∈Ks do Send (j, k) to process assigned to k ;
7
Start global logical-or found ←P −1
r=0 fr;
8
Synchronize;
9
Js ←union of all received child-parent vertex pairs;
10 until found or 
0≤s<P Js = ∅;
11 return found;
complexity exist, but require many more (super-linear) processors. The result
of a BFS on a graph is a tree. The paths from the leaves to the root of that
tree coincide with the minimum length paths between the respective vertices
in the graph. The presence of the sink vertex as a leaf testiﬁes, therefore, its
reachability from the root.
The level-synchronous BFS starts by visiting the root vertex and then con-
tinues to visit all its children in parallel. From then on, this pattern repeats itself:
all of its grandchildren are visited in parallel, all of its great grandchildren, and
so on. Of course, when the number of available processors is limited, some of
its grandchildren will have to be visited after some of the others, but that does
not matter in a level-synchronous BFS. The Boolean visiteds[v] is used to keep
track of the visited vertices. While the whole tree is returned in Ts, the Search
procedure uses two intermediate sets: Js contains the current level to be explored
and Ks contains the child vertices. Procedure VisitLocal is used to ﬁll Ks. It is
implemented as classical BFS in Procedure 5 and with an internal local BFS we
call Local-First Search (LFS) in Procedure 6.
Procedure 5: VisitLocal(G, i, j, t, Ts, visiteds, fs, Ks) for BFS
In: Graph G, parent vertex i, child vertex j, target vertex t
In/Out: visiteds[] status, target found fs, child edges for next round Ks
Out: Local arcs Ts of spanning tree
1 if ¬fs ∧¬visiteds[j] then
2
Ts ←Ts ∪{(i, j)}; visiteds[js] ←1;
3
if j = t then fs ←1;
4
else foreach neighbor k of j s.t. ¬visiteds[k] do Ks ←Ks ∪{k};
5 end

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
397
Any measure to reduce communication may speed up the search. Recall that
the variables and domain values, and therefore also the graph’s vertices, are
evenly assigned to all processes. The idea is that if a vertex is visited, all reachable
vertices on the same process are visited in BFS order ﬁrst, before continuing the
traversal from the adjacent vertices on other processes. This may eﬀectively
reduce the number of synchronizations in practice, although it does not change
the worst case complexity.
When the target vertex has been found by a local process, the local Boolean
fs is set to true and the search has to be stopped. This is done by broadcasting
these Booleans and gathering their global OR.
Procedure 6: VisitLocal(G, i, j, t, Ts, visiteds, fs, Ks) for LFS
In: Graph G, parent vertex i, child vertex j, target vertex t
In/Out: visiteds[] status, target found fs, child edges for next round Ks
Out: Local arcs Ts of spanning tree
1 Initialize queue Js ←{(i, j)};
2 while ¬fs ∧Js ̸= ∅do
3
Dequeue (a, b) from Js;
4
if ¬visiteds[b] then
5
Ts ←Ts ∪{(a, b)}; visiteds[b] ←1;
6
if b = t then
7
fs ←1;
8
break
9
end
10
Ns ←{(b, c) | c ∈neighbors of b ∧¬visiteds[c]};
11
Rs ←{(b, c) ∈Ns | c not assigned to process s};
12
Ks ←Ks ∪Rs;
13
Enqueue Ns\Rs to Js;
14
end
15 end
ForwardReachable and BackwardReachable. These procedures are used in the
SCC computation and reuse BFS Procedure 4.
Procedure 7: ForwardReachable(G, r)
In: Graph G, set of source vertices r
Out: All vertices U that are reachable from root
1 Ts ←{r};
2 Search(G, r, Ts);
3 Broadcast Ts;
4 Synchronize ;
5 T ←gather broadcast of all visited vertices;
6 return {child | (parent, child) ∈T};

398
W. Suijlen et al.
Complexity. On a graph with diameter δ and V vertices with maximum degree d,
Procedure 4 (Search) requires at most δ rounds of the outer loop (lines 3–10) and
hence δ synchronizations. Each process has no more than V/P vertices, because
variables and domain values are evenly distributed. Each vertex has at most d
neighbors and, therefore, Ks will have no more than V d/P entries. Hence, the
number of outgoing messages is bounded by V d/P. Likewise, Js will not receive
more than V d/P entries. Therefore, the total time is TBFS(V, δ) = O(δ( V d
P g +
ℓ)). This bound is tight for the unlucky but possible case where neighbors are
on another process each time. Complexity of Procedure 2 ParAllDiﬀFilter is
TParAllDiﬀFilter = 
S∈S TBFS(VS, δS).
Parallel Multi-source LFS. At initial propagation a new augmenting path has
to be discovered for every variable, which costs XTBF S time. Again, this time
will be dominated by synchronization. To reduce this cost, we have developed a
multi-source search which ﬁnds multiple vertex disjoint augmenting paths simul-
taneously. Of course, it will generally not be possible to ﬁnd a maximum match-
ing in one pass, but it is guaranteed to ﬁnd at least one augmenting path, so
that it can be repeated a few times until the matching is indeed maximum. The
algorithm is not included here for space reasons.
5
Experimental Evaluation
The performance characteristics of the presented parallel algorithm is quite dif-
ferent from the original sequential algorithm. Firstly, the parallel algorithm is
more susceptible to data-dependent performance variations. The diameter δ and
the maximum degree d of the bipartite graph directly aﬀect the inter-process
communication necessary to perform a graph traversal. Since communication is
almost all that it does, it strongly aﬀects the total running time. Secondly, there
is a special penalty associated with each call of the propagator, namely a syn-
chronization of all processes, which is, even on the tightest parallel machines, an
order of magnitude slower than a local memory access. We use for experiments
a multicore system and a cluster as described in Table 1.
Table 1. Parallel systems used for testing
Feature
Epyc64
Ivy200
OS/Compiler
openEuler 20.03/GCC 7.3.0
CentOS 7/GCC 7.3.0
BSPlib
MulticoreBSP for C 2.0.4 [36]
Intel MPI 2018 &
BSPonMPI 1.1 [32]
CPU
AMD Epyc 7452 @ 2.35GHz
Intel E5-2690v2 @ 3GHz
Architecture
Zen 2
Ivybridge
Memory
256 GB DDR4∗
10× 256 GB DDR3∗
Interconnect
Inﬁnity Fabric
EDR Inﬁniband
P
32 × 2 × 1 = 64 ♯
10 × 2 × 10 = 200 ♯
Inverse bandwidth g
120 ns/word †
7600 ns/word †
Sync latency ℓ
37 μs †
4831 μs †
∗Conﬁgured with maximal bandwidth [1,19].
♯P = Number of Cores × Sockets × Server Nodes.
† Estimated to 2 signiﬁcant digits with 95% conﬁdence by randomly probing com-
munication patterns of up to 32KB with 16-byte messages [32].

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
399
Hence the experimental question presents itself how the total running time
compares with respect to three diﬀerent parameters of a given problem: the
size, the amount of backtracking required, and the degree. Note that degree is
correlated to the diameter.
The benchmark suite used by other Alldiﬀerent studies [11,37], contains only
CSPs where the Alldiﬀerent constraints have small scopes and always require a
considerable amount of backtracking search. Certainly, on those problems the
parallel ﬁltering algorithm is not competitive with the sequential algorithm.
For that reason we choose diﬀerent CSPs for our experiments: An N-Queens
satisfaction problem to evaluate running time as function of problem size, an
N-Queens counting problem to evaluate backtracking speed, and a scheduling
problem to evaluate running time as function of degree.
5.1
Data Structures, Data Distribution, and CP Solver Integration
Our algorithms assume a distributed address space. Data on a remote process
can only be modiﬁed through explicit communication. Since all algorithms can
broadcast any modiﬁcations cheaply, it is possible to maintain exact copies of
the entire solver state on all processes. However, that would mean that total
memory use would increase by a factor P.
By far, most storage is needed for the variable domains, whose memory
requirement tends to grow quadratically with the number of variables. As a
simple solution, this paper proposes to store a variable domain only on the
process that the variable is assigned to, analogous to a 1D distribution of the
adjacency matrix in parallel graph computations. Variables are assigned to pro-
cesses cyclically. All other data, which is either only proportional to the number
of variables, domains, or processes, can remain replicated. The residual ﬂow
graph does not need separate storage, as it can be directly read and altered via
the variable domains and the current matching. In our experiments, we store
variable domains in Sparse Sets [6], the SCCs in a backtrackable variable set
partition [11], and the matching in an array with backtrackable entries.
The CP-solver in which this ﬁltering algorithm is integrated, called HPCS,
is original but essentially not much diﬀerent from its contemporaries. There
are variables, domains, views, propagators, a state trail, an event queue, and
search. Only the domains and their trail are distributed. The solver has only
a few constraints so far, among which is the Alldiﬀerent constraint. Like the
propagators, the HPCS solver is also an SPMD-style program. All processes are
executing the exact same source code all the time but on diﬀerent parts of the
data. To ensure that they remain on the same control-ﬂow path, information has
to be broadcast regularly, which implies regular synchronization. Indeed, in the
variable and value selection heuristics each process can only view the domains
of the variables that are assigned to it. All processes have to communicate in
order to collectively agree on the chosen variable and value for every decision.

400
W. Suijlen et al.
5.2
N-Queens
The N-Queens problem is to place N queens on an N ×N chessboard so that no
queen can attack another. The simplest variant starts with an empty chessboard
and just asks to construct one solution. This is a constant time problem, because
a solution exists for N ≥4, while a solution can be constructed analytically. A
hard variant is to count the number of solutions. The CSP can be deﬁned with
three Alldiﬀerent constraints, as is shown in Fig. 3.
Domain
D = {0, 1, . . . , N −1}
Variables
Q0, Q1, . . . , QN−1 ∈D
Constraints
Alldiﬀerent(Q0, Q1, . . . , QN−1)
Alldiﬀerent(Q0 + 0, Q1 + 1, . . . , QN−1 + N −1)
Alldiﬀerent(Q0 −0, Q1 −1, . . . , QN−1 −N + 1).
Fig. 3. CSP of N-queens problem. Each Qi describes the column in which the queen
on the i-th row is placed.
Problem Size. When N is a multiple of 6, the N-queen problem has an analytic
solution [9] of the form:
Qi =

2i + 1
0 ≤i < N/2
2i −N
N/2 ≤i < N
In the ﬁrst experiment, we use this solution as heuristic in order to reach the
ﬁrst solution without backtracking and only measure the propagation time. The
parallel version is tested with the four parallel graph search traversals, namely
single source (SS) or multi-source (MS) BFS or LFS. These are compared to
our sequential implementation and to the sequential N-queens implementation
in Gecode [10] using three distinct constraints. On this problem, Gecode’s
number of executed propagators, number of failures, and search tree depth match
exactly with our solver. Results are presented in Fig. 4.
0
2000
4000
6000
8000
0
5
10
15
20
Epyc64
Time to solution (min.)
Number of queens
0
2000
4000
6000
8000
0
20
40
60
80
Ivy200
Time to solution (min.)
Number of queens
MS-LFS
MS-BFS
SS-LFS
SS-BFS
Sequential
Gecode
Fig. 4. Time required by Gecode and HPCS using either sequential or parallel algo-
rithm to ﬁnd the analytic solution to N-queens

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
401
In these experiments, we observe that BFS with single-source search performs
the worst and is the only parallel setting slower than sequential. LFS is a crit-
ical improvement because it reduces the number of synchronizations. The high
synchronization time in the cluster gives advantage to the sequential algorithm
up to a large number of queens. The speed of our sequential implementation
compared to Gecode has to be relativized by the fact that Gecode is far more
generic.
Backtracking. To compare backtracking speed, the solvers are instructed to enu-
merate all solutions of the N-queens problems until a set number of failures has
been reached. The total running time is measured for a range of failure number
limits. Results are presented in Fig. 5.
0
2000
4000
6000
8000
10000
0
5
10
15
20
25
Epyc64, N = 2400
Time until failure limit (min.)
Failure limit after first solution
0
500
1000
1500
2000
0
20
40
60
80
100
120
140
Ivy200, N = 6000
Time until failure limit (min.)
Failure limit after first solution
MS-LFS
MS-BFS
SS-LFS
SS-BFS
Sequential
Gecode
Fig. 5. Time required by Gecode and HPCS using either sequential or parallel algo-
rithm to reach failure limit while counting N-queens solutions
We can see that Gecode time appears constant because it is really fast on
backtracking and fails at a rate this granularity is not able to measure. In con-
trast, backtracking comes at a high synchronization cost for any version of our
parallel algorithm.
5.3
Scheduling
As scheduling problem, a collection of tasks of unit time linked by precedence
constraints is to be scheduled on a number of parallel machines. The goal is to
ﬁnd a schedule with a minimum makespan. The CSP is given in Fig. 6.

402
W. Suijlen et al.
Let T = {0, . . . , n−1} be a set of n tasks to be scheduled on m machines before a time
horizon t, a set of dependencies D ⊂T × T and a compatibility set Mi ⊆[0..m −1]
that allows the task i to be executed only on a machine in Mi.
Variables
Time
T1, T2, . . . , Tn ∈[0, t −1]
Machine
M1, M2, . . . , Mn ∈[0, m −1]
Slot
S1, S2, . . . , Sn ∈[0, tm −1]
Constraints
Compatibility
∀i ∈T , Mi ∈Mi
Precedence
∀(i, j) ∈D, Ti < Tj
Resource
∀i ∈T , Si = Ti × m + Mi
Alldiﬀerent(S1, S2, . . . , St)
Fig. 6. The CSP of the task scheduling problem
In this CSP, there are many precedence constraints to handle. If these were to
be handled as separate binary constraints, the parallel solver would lose a lot of
time in synchronizations. Instead, we choose to handle this network of less-than
constraints as one global constraint. At initial propagation, the longest path
between each pair of tasks is computed by repeatedly squaring the adjacency
matrix, which costs ⌈log T⌉(T 3/P + T 2g + ℓ), ignoring small constant factors.
After that, global bounds of task start times can be found by scattering locally
found bounds and then gathering them to processes that own the tasks that
are concerned. If t variables per process changed, then, ignoring small constant
factors, one round of propagation costs no more than tT + Tg + ℓ. This is listed
as Procedure 8.
Procedure 8: ParLessThanFilter(X, Us, D, ¯A, ¯B,)
In: Variables X, updated local variables Us, closures ¯A and ¯B of the less-than
constraint network for lower and upper bound relations, respectively.
In/Out: Domains (Dx)x∈X (GAC output)
Data: Arrays lbs[] and ubs[] store locally found lower and upper bounds
1 foreach x ∈X do
2
lbs[x]= maxy∈Us{min Dy + ¯Ay,x} ; ubs[x]= miny∈Us{max Dy + ¯By,x}
3 end
4 Scatter lbs[x] and ubs[x] to process to whom x is assigned;
5 Synchronize;
6 foreach local x ∈X do
7
Gather lbv ←max0≤s<P lbs[x] ; Gather ubv ←min0≤s<P ubs[x] ;
8
Dx ←{v ∈Dx | lbv ≤v ≤ubv};
9 end
Degree. This last experiment randomly samples generated task graphs with a
ﬁxed number of tasks n, a constant out degree d = 2 (except for the start

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
403
and end vertices), and an expected square shape, which means that the longest
dependency chain is as about as long as there are tasks that can run in parallel
[34]. Figure 7 shows a sample of some such task graphs of small size.
start
task0
task2
task3
task5
task6
end
task4
task1
task9
task8
task10
task7
task15
task12
task14
task11
task13
start
task0
task1
task2
task4
task6
task14
end
task8
task3
task7
task5
task9
task10
task11
task12
task13
task15
start
task0
task1
task2
task3
task4
task11
end
task8
task6
task7
task5
task9
task12
task13
task14
task15
task10
Fig. 7. A sample of three random task graphs with 16 tasks
Each task is compatible with μ randomly drawn machines. A small μ will
result in a low-degree variable-value graph in the Alldiﬀerent ﬁltering algorithm,
while a large μ results in a high-degree graph. A high-degree graph will have
smaller diameter δ but also more arcs to process. While μ varies, the CP solver
is instructed to ﬁnd a solution with minimal makespan using the list-schedule
heuristic [13]. The results are presented in Fig. 8 using m = 10 and t = 660.
As can be expected, the sequential algorithm performs best on the low-degree
problems, while the parallel algorithm also beneﬁts from a low diameter.
2
4
6
8
10
0
1
2
3
4
5
Epyc64, Tasks = 2400
Time to solution (min.)
Number of compatible machines per task
2
4
6
8
10
5
10
15
20
25
Ivy200, Tasks = 6000
Time to solution (min.)
Number of compatible machines per task
MS-LFS
MS-BFS
SS-LFS
SS-BFS
Sequential
Gecode
Fig. 8. Time required by Gecode and HPCS using either sequential or parallel algo-
rithm to solve scheduling problems of various degree
6
Related Work and Discussion
Survey papers [12,29] describe the state of parallel inference and ﬁltering. Most
works [14,15,25,30,31] concern the execution of multiple propagators in par-
allel. This includes one work [7] which also implements a parallel propagator
for the table constraint. Their propagator for Alldiﬀerent is based on its binary
decomposition, hence unable to guarantee GAC, and uses parallel propagation.

404
W. Suijlen et al.
A SIMD algorithm is proposed by [21], which also parallelizes graph search in
R´egin’s algorithm. Their proposed search algorithms [8] assume that the graphs
are dense and, therefore, only parallelize the lookup of unvisited vertex neighbors,
which may cause scalability issues on large problems. Like these two attempts,
our solution does not exclude the possibility of running multiple propagators
in parallel. Additionally, parallel search methodologies, like EPS, may also be
combined, if suﬃcient memory is available. Parallel search requires much more
memory, because it requires duplication of the search state for each search-tree
branch that is explored in parallel.
Most of the aforementioned works mention that a major drawback of par-
allel propagation is its synchronization cost, which is also conﬁrmed by our
experiments. This is inevitable whenever multiple processes have to come to a
collective conclusion. Synchronizations generally happen in two places: during
ﬁxed-point iteration of the propagators and when making a new decision. While
P-completeness of arc-consistency on binary constraint networks [20] testiﬁes
the existence of a worst-case scenario, it is possible to avoid too many ﬁxed-
point iterations by grouping several constraints together in order to propagate
domain updates more quickly. We used this trick with the global less-than con-
straint in the scheduling application. Alternatively, it may be possible to use
hardware that has very low synchronization costs, such as the integrated vector
instructions in modern CPUs. On the contrary, avoiding a synchronization for
every decision seems less obvious. Backtracking search is therefore much slower
than in a sequential environment. That is not a reason to avoid parallel ﬁltering,
however. Their main application area are large problems for which backtrack-
ing search is infeasible anyway. Large problems require good heuristics so that
backtracking search is limited to a minimum.
Important algorithmic improvements have been studied by Gent et al. [11].
Our algorithm implements most of them, including the use of domain iterators as
adjacency lists, although that last optimization does not improve performance
much [26]. We did not include the most recently described improvement [37],
which ﬁlters some domain values already while ﬁnding a maximum matching, so
that SCC ﬁnding is less work.
Our parallel algorithms for maximum matching and SCCs are simplistic and
are vulnerable to some worst-case inputs. Those worst-case inputs did not occur
in our experiments. Much more robust algorithms are available for SCC ﬁnd-
ing [5] and maximum matching [2]. The best time bound for a work-eﬃcient
maximum matching algorithm remains Hopcroft-Karp [18]. The ideas for our
maximum matching algorithm are based on [4, exercise 5.9].
7
Conclusion
The Alldiﬀerent constraint is one of the most often used global constraints in
constraint programs. CP solvers may choose to use one of several ﬁltering algo-
rithms, each of which reaches a particular level of consistency. The strongest
algorithms today are based on R´egin’s GAC ﬁltering algorithm. Its weak point,
however, is that it is relatively time consuming.

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
405
This paper presents a parallel algorithm that can signiﬁcantly speed up ﬁlter-
ing for Alldiﬀerent constraints with large scopes and domains. It uses a parallel
multi-source graph search to parallelize the two main phases of R´egin’s algo-
rithm: ﬁnding the maximum matching and ﬁnding the SCCs. Although worst-
case time complexity is not better than the sequential algorithm, experiments
demonstrate that CSPs with large Alldiﬀerent constraints can be solved much
faster, provided that a good heuristic is in place. The start-up cost for each invo-
cation of the algorithm makes it less suitable for problems that require extensive
backtracking search, if GAC is to be maintained at each decision.
There are many ways possible to reduce start-up cost, especially if one is
willing to make system speciﬁc optimizations. Alternatively, it is possible to
change to the sequential algorithm at runtime after the variable domains have
been reduced below a certain threshold.
In any case, complete search is usually not a feasible strategy for large prob-
lems because of the exponential size of the search tree. Therefore, large problems
are necessarily only feasible if a good search heuristic is available. Indeed, if a
CP solver’s time is mostly spent on Alldiﬀerent constraint ﬁltering, then the
presented algorithm can reduce that time signiﬁcantly.
References
1. AMD: Memory population guidelines for AMD EPYC processors. Tech. Rep.
56301, revision 1.1, Advanced Micro Devices (2018)
2. Azad, A., Bulu¸c, A., Pothen, A.: Computing maximum cardinality matchings in
parallel on bipartite graphs via tree-grafting. IEEE Trans. Parallel Distrib. Syst.
28(1), 44–59 (2016). https://doi.org/10.1109/TPDS.2016.2546258
3. Bessiere, C., Narodytska, N., Quimper, C.-G., Walsh, T.: The alldiﬀerent constraint
with precedences. In: Achterberg, T., Beck, J.C. (eds.) CPAIOR 2011. LNCS, vol.
6697, pp. 36–52. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-
21311-3 6
4. Bisseling, R.H.: Parallel Scientiﬁc Computing: A Structured Approach Using BSP.
2nd edn. Oxford University Press (2020)
5. Blelloch, G.E., Gu, Y., Shun, J., Sun, Y.: Parallelism in randomized incremen-
tal algorithms. In: Proceedings of the 28th ACM Symposium on Parallelism in
Algorithms and Architectures, p. 467–478. SPAA 2016, Association for Comput-
ing Machinery, NY (2016). https://doi.org/10.1145/2935764.2935766
6. Briggs, P., Torczon, L.: An eﬃcient representation for sparse sets. ACM Lett. Pro-
gram. Lang. Syst. 2(1–4), 59–69 (1993). https://doi.org/10.1145/176454.176484
7. Campeotto, F., Dal Pal`u, A., Dovier, A., Fioretto, F., Pontelli, E.: Exploring the
use of GPUs in constraint solving. In: Flatt, M., Guo, H.-F. (eds.) PADL 2014.
LNCS, vol. 8324, pp. 152–167. Springer, Cham (2014). https://doi.org/10.1007/
978-3-319-04132-2 11
8. Cheriyan, J., Mehlhorn, K.: Algorithms for dense graphs and networks on the
random access computer. Algorithmica 15(6), 521–549 (1996). https://doi.org/10.
1007/BF01940880
9. Erbas, C., Tanik, M.M.: Generating solutions to the N-queens problem using
2-circulants. Math. Mag. 68(5), 343–356 (1995). http://www.jstor.org/stable/
2690923

406
W. Suijlen et al.
10. Gecode Team: Gecode: generic constraint development environment (2019). http://
www.gecode.org
11. Gent, I.P., Miguel, I., Nightingale, P.: Generalised arc consistency for the alld-
iﬀerent constraint: an empirical survey. Artif. Intell. 172(18), 1973–2000 (2008).
https://doi.org/10.1016/j.artint.2008.10.006
12. Gent, I.P., et al.: A review of literature on parallel constraint solving. The-
ory Pract. Logic Program. 18(5–6), 725–758 (2018). https://doi.org/10.1017/
S1471068418000340
13. Graham, R.L.: Bounds on multiprocessing timing anomalies. SIAM J. Appl. Math.
17(2), 416–429 (1969). https://doi.org/10.1137/0117039
14. Granvilliers, L., Hains, G.: A conservative scheme for parallel interval narrow-
ing. Inf. Process. Lett. 74(3–4), 141–146 (2000). https://doi.org/10.1016/S0020-
0190(00)00048-X
15. Hamadi, Y.: Optimal distributed arc-consistency. Constraints 7(3–4), 367–385
(2002). https://doi.org/10.1023/A:1020594125144
16. van Hoeve, W.-J.: The alldiﬀerent constraint: a survey. CoRR cs.PL/0105015
(2001). https://arxiv.org/abs/cs/0105015
17. van Hoeve, W.-J., Katriel, I.: Global constraints. In: Rossi, F., van Beek, P.,
Walsh, T. (eds.) Handbook of Constraint Programming, Foundations of Artiﬁcial
Intelligence, vol. 2, pp. 169–208. Elsevier (2006). https://doi.org/10.1016/S1574-
6526(06)80010-6
18. Hopcroft, J.E., Karp, R.M.: A n5/2 algorithm for maximum matchings in bipartite.
In: 12th Annual Symposium on Switching and Automata Theory, SWAT 1971, pp.
122–125 (1971). https://doi.org/10.1109/SWAT.1971.1
19. Huawei: Tecal RH2288H v2 rack server v100r002. Tech. rep., Huawei Technologies
Co., Ltd. (2013), issue 01
20. Kasif, S.: On the parallel complexity of discrete relaxation in constraint satisfac-
tion networks. Artif. Intell. 45(3), 275–286 (1990). https://doi.org/10.1016/0004-
3702(90)90009-O
21. Van Kessel, P., Quimper, C.-G.: Filtering algorithms based on the word-ram model.
In: Hoﬀmann, J., Selman, B. (eds.) Proceedings of the Twenty-Sixth AAAI Con-
ference on Artiﬁcial Intelligence, 22–26 July 2012, Toronto, Ontario, AAAI Press
(2012). http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5135
22. Leconte, M.: A bounds-based reduction scheme for constraints of diﬀerence. In:
Second International Workshop on Constraint-Based Reasoning, Key West, FL, p.
19–28 (1996)
23. L´opez-Ortiz, A., Quimper, C.-G., Tromp, J., van Beek, P.: A fast and simple algo-
rithm for bounds consistency of the alldiﬀerent constraint. In: Gottlob, G., Walsh,
T. (eds.) IJCAI-03, Proceedings of the Eighteenth International Joint Conference
on Artiﬁcial Intelligence, Acapulco, 9–15 August 2003, pp. 245–250. Morgan Kauf-
mann (2003). http://ijcai.org/Proceedings/03/Papers/036.pdf
24. Mehlhorn, K., Thiel, S.: Faster algorithms for bound-consistency of the sortedness
and the alldiﬀerent constraint. In: Dechter, R. (ed.) CP 2000. LNCS, vol. 1894, pp.
306–319. Springer, Heidelberg (2000). https://doi.org/10.1007/3-540-45349-0 23
25. Nguyen, T., Deville, Y.: A distributed arc-consistency algorithm. Sci. Comput.
Program. 30(1–2), 227–250 (1998). https://doi.org/10.1016/S0167-6423(97)00012-
9
26. Nightingale, P.: Are adjacency lists worthwhile in alldiﬀerent. Tech. rep., Citeseer
(2009)

A Parallel Algorithm for GAC Filtering of the Alldiﬀerent Constraint
407
27. Puget, J.: A fast algorithm for the bound consistency of alldiﬀconstraints. In:
Mostow, J., Rich, C. (eds.) Proceedings of the Fifteenth National Conference on
Artiﬁcial Intelligence and Tenth Innovative Applications of Artiﬁcial Intelligence
Conference, AAAI 98, IAAI 98, 26–30 July 1998, Madison, Wisconsin, pp. 359–366.
AAAI Press/The MIT Press (1998). http://www.aaai.org/Library/AAAI/1998/
aaai98-051.php
28. R´egin, J.-C.: A ﬁltering algorithm for constraints of diﬀerence in csps. In: Hayes-
Roth, B., Korf, R.E. (eds.) Proceedings of the 12th National Conference on Arti-
ﬁcial Intelligence, Seattle, WA, 31 July–4 August 1994, vol. 1, pp. 362–367. AAAI
Press/The MIT Press (1994). http://www.aaai.org/Library/AAAI/1994/aaai94-
055.php
29. R´egin, J.-C., Malapert, A.: Parallel constraint programming. In: Handbook of Par-
allel Constraint Reasoning, pp. 337–379. Springer, Cham (2018). https://doi.org/
10.1007/978-3-319-63516-3 9
30. Rolf, C.C., Kuchcinski, K.: Parallel consistency in constraint programming. In:
Arabnia, H.R. (ed.) Proceedings of the International Conference on Parallel and
Distributed Processing Techniques and Applications, PDPTA 2009, Las Vegas,
Nevada, 13–17 July 2009, 2 vols, pp. 638–644. CSREA Press (2009)
31. Ruiz-Andino, A., Araujo, L., S´aenz-P´erez, F., Ruz, J.J.: Parallel arc-consistency
for functional constraints. In: Sagonas, K. (ed.) Proceedings of the International
Workshop on Implementation Technology for Programming Languages Based on
Logic, held in conjunction with the Joint International Conference and Symposium
on Logic Programming, Manchester, UK, 20 June 1998, pp. 86–100 (1998)
32. Suijlen, W.J.: BSPonMPI - BSPlib implementation on top MPI (2019). https://
github.com/wijnand-suijlen/bsponmpi, version 1.1
33. Tarjan, R.E.: Depth-ﬁrst search and linear graph algorithms. SIAM J. Comput.
1(2), 146–160 (1972). https://doi.org/10.1137/0201010
34. Topcuoglu, H., Hariri, S., Wu, M.: Performance-eﬀective and low-complexity task
scheduling for heterogeneous computing. IEEE Trans. Parallel Distrib. Syst. 13(3),
260–274 (2002). https://doi.org/10.1109/71.993206
35. Valiant, L.G.: A bridging model for parallel computation. Commun. ACM 33(8),
103–111 (1990)
36. Yzelman, A.N., Bisseling, R.H., Roose, D., Meerbergen, K.: MulticoreBSP for C: a
high-performance library for shared-memory parallel programming. Int. J. Parallel
Prog. 42(4), 619–642 (2013). https://doi.org/10.1007/s10766-013-0262-9
37. Zhang, X., Li, Q., Zhang, W.: A fast algorithm for generalized arc consistency of the
alldiﬀerent constraint. In: Lang, J. (ed.) Proceedings of the Twenty-Seventh Inter-
national Joint Conference on Artiﬁcial Intelligence, IJCAI 2018, 13–19 July 2018,
Stockholm, Sweden, pp. 1398–1403. ijcai.org (2018). https://doi.org/10.24963/
ijcai.2018/194

Analyzing the Reachability Problem
in Choice Networks
Piotr Wojciechowski1, K. Subramani1(B), and Alvaro Velasquez2
1 LDCSEE, West Virginia University, Morgantown, WV, USA
{pwojciec,k.subramani}@mail.wvu.edu
2 Information Directorate, AFRL, Rome, NY, USA
alvaro.velasquez.1@us.af.mil
Abstract. In this paper, we investigate the problem of determining s−t
reachability in choice networks. In the traditional s −t reachability
problem, we are given a weighted network tuple G = ⟨V, E, c, s, t⟩, with
the goal of checking if there exists a path from s to t in G. In an optional
choice network, we are given a choice set S ⊆E × E, in addition to
the network tuple G. In the s −t reachability problem in choice net-
works (OCRD), the goal is to ﬁnd whether there exists a path from
vertex s to vertex t, with the caveat that at most one arc from each
arc-pair (ei, ej) ∈S is used in the path. OCRD ﬁnds applications in
a number of domains including routing in wireless networks and
sensor placement. We analyze the computational complexities of the
OCRD problem and its variants from a number of algorithmic perspec-
tives. We show that the problem is NP-complete and its optimization
version is NPO PB-complete. Additionally, we show that the problem
is ﬁxed-parameter tractable in the cardinality of the choice set S. We
also consider weighted versions of the OCRD problem and detail their
computational complexities; in particular, the optimization version of
the WOCRD problem is NPO-complete.
1
Introduction
This paper is concerned with the s −t reachability in choice networks. Choice
networks diﬀer from traditional networks in that there is a choice set. The choice
set is a binary relation on the arc set of the network. It consists of arc pairs. If
one arc from an arc pair is used in the construction of a path, then the second
arc cannot be used. The s −t reachability problem in such networks is called
the Optional Choice Reachability problem (OCRD). It is important to note that
paths are not required to intersect the choice set S at all.
The OCRD problem is a variant of the resource-constrained shortest path
problem (RCSP), which has been widely studied in the operations research and
K. Subramani—This research was supported in part by the Air-Force Oﬃce of Scien-
tiﬁc Research through Grant FA9550-19-1-0177 and in part by the Air-Force Research
Laboratory, Rome through Contract FA8750-17-S-7007.
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 408–423, 2022.
https://doi.org/10.1007/978-3-031-08011-1_27

Analyzing the Reachability Problem in Choice Networks
409
theoretical computer science communities. Our interest in this problem stems
from applications in wireless routing [18], sensor placement [25], air-force logistics
[26] and program veriﬁcation [15].
2
Statement of Problems
In this section, we deﬁne the problems studied in this paper. We will be studying
the complexity of a variant of reachability known as optional choice reachability.
This variant examines reachability in choice networks.
Deﬁnition 1 (Choice Network). A Choice Network G = ⟨V, E, S, s, t, c⟩con-
sists of the following: 1. Vertex set V . 2. Arc set E ⊆V × V . 3. Choice set
S ⊆E × E. 4. Start vertex s ∈V . 5. Target vertex t ∈V . 6. Arc cost vector
c ∈Z|E|.
Throughout this paper, we use n to denote the cardinality of the vertex set
V and we use m to denote the cardinality of the arc set E.
In a choice network, the choice set S is used to determine whether a path p
is valid.
Deﬁnition 2 (Valid Path). A path p in a choice network G is valid, if for
each pair Si ∈S, p contains at most one arc in Si.
We can now deﬁne the reachability problem in choice networks.
Deﬁnition 3 (OCRD). The Optional Choice Reachability (OCRD) problem:
given a choice network G, does G have a valid path from s to t?
s
v1
v2
v3
v4
v5
t
S1
S1
S2
S2
S3
S3
S4
S4
Fig. 1. Choice network G. Each arc is labeled according to its pair
Example 1. Consider the choice network G in Fig. 1.
Consider a path p in G. Any path that leaves s must go through v1 or v2. If
p goes through v1, then it includes the arcs (s, v1) and (v1, v3). Thus, p cannot
include arc (v3, v4) or (v5, t). Consequently, there is no valid path from s to t
going through v1.

410
P. Wojciechowski et al.
If p goes through v2, then it includes the arcs (s, v2) and (v2, v3). Thus, p
cannot include arc (v3, v5) or (v4, t). Consequently, there is no valid path from
s to t going through v2.
This means that there is no valid path in G from s to t.
In addition to the OCRD problem, we also study the complexity of ﬁnding
shortest paths in choice networks. We do this for both weighted and unweighted
networks.
Deﬁnition 4 (OCROpt). The Optional Choice Shortest Path (OCROpt) prob-
lem: given a choice network G, what is the valid path in G from s to t with the
fewest arcs?
Deﬁnition 5 (WOCROpt). The Weighted Optional Choice Shortest Path
(WOCROpt) problem: given a choice network G, what is the valid path in G
from s to t with the lowest total cost?
In this paper we relate problems to the complexity classes NPO and NPO
PB.
The principal contributions of this paper are as follows:
1. Establishing that the OCRD problem is NP-complete (see Sect. 4.1). 2.
Designing an O∗(1.42|S|) parameterized algorithm for the OCRD and OCROpt
problems (see Sect. 4.2). 3. A O(2n) time exact exponential algorithm for the
OCRD problem (see Sect. 4.3). 4. Showing that the OCROpt problem is NPO
PB-complete (see Sect. 4.4). 5. A proof that there cannot be a o(1.18|S|) algo-
rithm for the OCRD problem unless the Strong Exponential Time Hypothesis
(SETH) fails (see Sect. 6).
3
Motivation and Related Work
The s −t reachability problem and hence the single-source shortest paths prob-
lem is one of the most well-studied problems in operations research and theoret-
ical computer science [1,2,7]. Several algorithms have been proposed for various
variants of the problem, including the case where the arcs are non-negatively
weighted, the arcs are real-weighted, and so on. The s −t reachability problem
also plays a fundamental role in the modeling of complexity theoretic issues as
evidenced by [21]. Likewise, constrained shortest path problems or more gen-
erally resource-constrained shortest path problems have been investigated for
quite some time owing to their wide applicability [3]. One of the earliest works
in constrained shortest paths is described in [22]. Since then, there have been
multiple variants of constrained shortest paths that have been studied in the lit-
erature [5,23]. Needless to say, most resource constrained shortest path problems
are NP-hard [11]. Variants of this problem are amenable to the approximation
guarantees [12] and exact approaches [8]. Probabilistic versions of the constrained
shortest path problem are discussed in [19]. Additionally, this problem has been
studied for paths with forbidden pairs of vertices [10,16,17,27]. However, in this

Analyzing the Reachability Problem in Choice Networks
411
paper, we examine the problem for forbidden pairs of arcs. While these two
problems are closely related, transforming one problem into another will involve
increasing the size of the graph.
A restricted version of this problem, known as the reachability problem in
graphs with forbidden transitions was studied in [24]. In this restriction, each
pair of arcs must consist of two arcs such that the tail of one arc is the head
of the other. This restricted version is NP-complete [24]. In [14], this result
was extended and the reachability problem in graphs with forbidden transitions
was shown to be NP-complete even for grid graphs. A variant of this problem,
in which the arcs in a path must alternate direction, was shown to be NP-
complete [4]. In this paper, we study a more general problem. However, we are
able to establish results for even more restricted forms of graphs.
4
Reachability in Choice Networks
In this section, we study the OCRD and OCROpt problems.
4.1
Computational Complexity
First, we show that the OCRD problem is NP-complete. Given a path from
s to t in a choice network G, it is easy to check if the path is valid. Thus, the
OCRD problem is in NP. All that remains is to show NP-hardness. This will
be done by a reduction from 3-SAT.
Let Φ be a 3-CNF formula. We construct the corresponding choice network
G as follows:
1. For each variable xi we create the structure shown in Fig. 2. Note that Xi is
the set of arcs paired with the arcs in the upper path through the structure.
Similarly, ¯
Xi is the set of arcs paired with the arcs in the lower path through
the structure.
In Fig. 2, the dashed lines connect the arcs which are in the same pair. If a
valid path p traverses the lower path, then, since each of the arcs in the set ¯
Xi
are paired with an arc in p, none of the arcs in set ¯
Xi can be in p. Similarly,
if p traverses the upper path, then none of the arcs in the set Xi can be in
p. Note that |Xi| is the number of clauses in Φ with the literal xi and | ¯
Xi| is
the number of clauses in Φ with the literal ¬xi. Note that the arcs in the sets
Xi and ¯
Xi are not part of the variable gadget but are used to construct the
clause gadgets.
2. Using the arcs in the sets Xi and ¯
Xi we now construct a gadget for each clause
φ in Φ. The clause gadget corresponding to a clause of the form (xi, ¬xj, xk)
is made using the arcs from the sets Xi, ¯Xj, and Xk. The resultant gadget is
shown in Fig. 2.
We construct the choice network G by combining the gadgets as shown in
Fig. 3.

412
P. Wojciechowski et al.
· · ·
· · ·
¯
Xi
Xi
Xk
Xi
¯
Xj
Fig. 2. Variable gadget corresponding to the variable xi and clause gadget correspond-
ing to the clause (xi, ¬xj, xk).
s
. . .
. . .
. . .
. . .
. . .
. . .
t
Fig. 3. Choice network corresponding to 3-CNF formula Φ.
Theorem 1. OCRD is NP-hard.
Proof. Let Φ be a 3-CNF formula and let G be the corresponding choice network.
First, we assume that Φ is satisﬁable. Let x be a truth assignment that
satisﬁes Φ. We use x to construct the valid path p. For each variable xi assigned
a value of true, p will traverse the lower path of the corresponding variable
gadget. This prevents any of the arcs in ¯
Xi from being on p. Similarly, for each
variable xi assigned a value of false the path will traverse the upper path of the
corresponding variable gadget. This prevents any of the arcs in Xi from being
on the path.
Let (xi, ¬xj, xk) be an arbitrary clause in the system. At least one literal
in this clause is assigned a value of true. Since the three paths through the
corresponding gadget correspond to the sets Xi, ¯Xj, and Xk, at least one path
through the gadget can still be traversed by p. Thus, we can construct a valid
path from s to t in G.
Now assume that there is a valid path p from s to t in G. We use p to
construct the assignment x as follows: for each variable xi, if p traverses the
upper path of the gadget corresponding to xi, then set xi to true, otherwise set
xi to false.
Consider a clause φ of Φ and look at how p traverses the corresponding gadget
in G. p either uses an arc in the set Xi for a literal xi in φ, or p uses an arc in
the set ¯
Xi for a literal ¬xi in φ. If p uses an arc in the set Xi, then p cannot
traverse the lower path of the gadget corresponding to xi. Thus, p must traverse

Analyzing the Reachability Problem in Choice Networks
413
the upper path of the gadget. Consequently, xi is assigned a value of true and
x satisﬁes the clause φ.
If p uses an arc in the set ¯
Xi, then p cannot traverse the upper path of the
gadget corresponding to xi. Thus, p must traverse the lower path of the gadget.
Consequently, xi is assigned a value of false and x satisﬁes the clause φ. Since
φ was an arbitrarily chosen clause, x satisﬁes Φ as desired.
⊓⊔
We now use structural properties of the graph G to strengthen Theorem 1.
Corollary 1. The OCRD problem is NP-complete for bipartite, acyclic graphs
with path-width 2.
Proof. By construction G is both bipartite and acyclic. Additionally, G has
path-width 2. Thus, the OCRD problem is still NP-complete even for such
restricted networks.
⊓⊔
4.2
A Fixed-Parameter Algorithm
Now, we show that there exists a O∗(1.42|S|) time FPT algorithm for the OCRD
and OCROpt problems.
First, we provide a O∗(2|S|) time algorithm for solving these problems.
For each set Si ∈S, we know that no valid path can traverse both arcs in
Si. Thus, if a valid path exists and we consider every possible way to remove
one arc from each pair Si, t will be reachable from s in at least one resultant
network.
This gives us the brute force approach in Algorithm 4.1.
Algorithm 4.1. Brute force algorithm for OCRD.
Input: Choice network G
Output: true if G has a valid path from s to t, false otherwise.
1: procedure OCR-Dec(G)
2:
for (C = 0 to (2|S| −1)) do
3:
for (i = 1 to |S|) do
4:
if (C mod 2i ≥2i−1) then
▷The ith bit of C is 1.
5:
Remove the ﬁrst arc of Si from G.
6:
else
7:
Remove the second arc of Si from G.
8:
if (t is reachable from s in G) then
▷G has a valid path from s to t.
9:
return true.
10:
return false.
Algorithm 4.1 can be easily modiﬁed to ﬁnd shortest paths by performing a
shortest path check for each resultant network instead of a reachability check.
We now deﬁne several reduction rules which can be used to both reduce the
size of G and the number of pairs in S. These rules are as follows: 1. Remove

414
P. Wojciechowski et al.
all vertices not reachable from s: If a vertex vj is not reachable from s, then vj
cannot be part of a valid path from s to t. Thus, vj can be removed from G
without aﬀecting any valid paths from s to t. 2. Remove all vertices from which
t is not reachable: If t is not reachable from a vertex vj, then vj cannot be part
of a valid path from s to t. Thus, vj can be removed from G without aﬀecting
any valid paths from s to t.
In particular, these rules can be performed each time an arc is removed from
G in Algorithm 4.1. If a reduction rule removes an arc belonging to a pair Si,
then that pair no longer matters since there is no way for any path from s to
t to use both arcs in Si. Thus, we can also remove the pair Si from G without
aﬀecting the validity of any paths from s to t.
For choice network G and arc e in G, let R(e, G) be the number of pairs
removed from G by the above reduction rules if e is removed from G. Also let
G(e, G) be the choice network formed by applying the above reduction rules
after arc e is removed from G.
For each pair Si = (eSi,1, eSi,2), we can calculate both R(eSi,1, G) and
R(eSi,2, G). We now show that if G has no valid path from s to t, then there
always exists either:
1. A pair Si such that R(eSi,1, G) ≥1 and R(eSi,2, G) ≥1.
2. A pair Si such that removing eSi,1 from G also removes eSi,2 from G (or vice
versa).
Lemma 1. If choice network G has no valid path from s to t, then there always
exists a pair Si such that either:
1. R(eSi,1, G) ≥1 and R(eSi,2, G) ≥1.
2. Removing eSi,1 from G also removes eSi,2 from G (or vice versa).
Proof. Let G be a choice network with no valid paths from s to t. We can assume
without loss of generality that s is reachable from t. Additionally, assume that
there is no pair Si that satisﬁes the desired conditions. We will show that this
always results in a contradiction by induction on |S|.
If |S| = 1, then there is only one pair S1 = (eS1,1, eS1,2) in S. Since G has
no valid path from s to t, any path from s to t must use both eS1,1 and eS1,2.
Thus, removing eS1,1 from G, will also remove eS1,2 from G when applying the
reduction rules to generate G(eS1,1, G).
Now let us assume that the lemma holds when |S| = k. Let G with |S| =
k + 1 be a choice network with no valid paths from s to t. If for every pair
Si = (eSi,1, eSi,2), R(eSi,1, G) = 0 or R(eSi,2, G) = 0, then either removing eSi,1
will not make any vertex unreachable from s or removing eSi,2 will not make
any vertex unreachable from s. Thus, t is still reachable from s in G(eSi,1, G),
or in G(eSi,2, G) for every i. Consequently, G has a valid path from s to t.
⊓⊔
Lemma 1 lets us construct the improved parameterized algorithm Algorithm
4.2 for the OCRD problem.
We can now analyze the running time of Algorithm 4.2. Note that Algorithm
4.2 only recurses on multiple graphs if for some Si ∈S, R(eSi,1, G) ≥1 and

Analyzing the Reachability Problem in Choice Networks
415
Algorithm 4.2. Improved FPT algorithm for OCRD.
Input: Choice network G, start vertex s, and target vertex t.
Output: true if G has a valid path from s to t, false otherwise.
1: procedure OCR-FPT(G, s, t)
2:
if (|S| = 1) then
3:
if (t ̸∈G(eS1,1, G) and t ̸∈G(eS1,2, G)) then ▷Any path from s to t must
use both eS1,1 and eS1,2.
4:
return false.
5:
return true.
6:
for (i = 1 to |S|) do
7:
if (R(eSi,1, G) ≥1 and R(eSi,2, G) ≥1) then
8:
res1 := OCR-FPT(G(eSi,1, G), s, t).
9:
res2 := OCR-FPT(G(eSi,2, G), s, t).
10:
return res1 ∨res2.
11:
if (eSi,2 ̸∈G(eSi,1, G)) then
12:
res1 := OCR-FPT(G(eSi,2, G), s, t).
13:
return res1.
14:
if (eSi,1 ̸∈G(eSi,2, G)) then
15:
res1 := OCR-FPT(G(eSi,1, G), s, t).
16:
return res1.
17:
return true.
▷By Lemma 1, there is a valid path from s to t in G
R(eSi,2, G) ≥1. Observe that in G(eSi,1, G) the size of the choice set has been
reduced by (R(eSi,1, G)+1) since Si and at least one other element of the choice
set have been removed. Similarly, in G(eSi,2, G) the size of the choice set has
been reduced by (R(eSi,2, G)+1). Thus, in both G(eSi,1, G) and G(eSi,2, G) the
size of the choice set has been reduced by at least 2.
Let T(|S|) be the running time of Algorithm 4.2 on a choice network with
choice set S. Note that for each i, R(eSi,1, G), R(eSi,2, G), G(eSi,1, G), and
G(eSi,2, G) can be calculated in time O(m+n). Since Algorithm 4.2 only recurses
when the size of the choice set decreases by at least 2, the running time of
Algorithm 4.2 is governed by the recurrence relation T(|S|) ≤T(|S| −2) +
T(|S| −2) + O(|S| · (m + n)).
From [6], Algorithm 4.2 runs in time O(|S| · (m + n) · 1.42|S|). This is an
improvement over the running time of the brute force approach of Algorithm
4.1.
We now prove the correctness of Algorithm 4.2.
Theorem 2. Algorithm 4.2 returns true, if and only if G has a valid path from
s to t.
Proof. First, assume that Algorithm 4.2 returns false. Algorithm 4.2 can return
false on Line 4, Line 10, Line 13, or Line 16. We will prove that G has no valid
path from s to t through induction on the size of the choice set S.
Assume that |S| = 1. In this case, Algorithm 4.2 can only return false on
Line 4. Thus, the if statement on Line 3 must be satisﬁed. This means that

416
P. Wojciechowski et al.
t ̸∈G(eS1,1, G) and t ̸∈G(eS1,2, G). Since t ̸∈G(eS1,1, G), t is not reachable
from s if eS1,1 is removed from G. Thus, any path from s to t must use eS1,1.
Similarly, since t ̸∈G(eS1,1, G), any path from s to t must use eS1,2. Thus, any
path from s to t must use both arcs in S1. Consequently, G does not have a
valid path from s to t.
Now assume that if Algorithm 4.2 returns false on a choice network G with
|S| < k, then G has no valid path from s to t. Suppose we run Algorithm 4.2 on
a choice network G with |S| = k.
If Algorithm 4.2 returns false on line 10, then, for some pair Si, both OCR-
FPT(G(eSi,1, G), s, t) and OCR-FPT(G(eSi,2, G), s, t) returned false. Since
OCR-FPT(G(eSi,1, G), s, t) returned false, then by the inductive hypothesis,
there is no valid path from s to t in G(eSi,1, G). Note that G(eSi,1, G) is made
by removing eSi,1 from G and then removing all vertices made unreachable from
s. Thus, any valid path from s to t in G must use eSi,1. Similarly, since OCR-
FPT(G(eSi,2, G), s, t) returned false, any valid path from s to t in G must use
eSi,2. However, by deﬁnition no valid path can use both eSi,1 and eSi,2. Thus, G
has no valid path from s to t.
If Algorithm 4.2 returns false on line 13, then, for some pair Si, the arc eSi,2
is not in the graph G(eSi,1, G) and OCR-FPT(G(eSi,2, G), s, t) returned false.
Since eSi,2 ̸∈G(eSi,1, G), then, after removing eSi,1 from G, the arc eSi,2 is not
on any path from s to t. Assume that G has a valid path p from s to t. If p uses
eSi,2 then, by deﬁnition, p cannot use eSi,1. However, this path would remain
in the graph after removing eSi,1. Since eSi,2 ̸∈G(eSi,1, G), this cannot happen.
Thus, p cannot use eSi,2. Consequently, p is a valid path in G(eSi,2, G). By
the inductive hypothesis, OCR-FPT(G(eSi,2, G), s, t) could not have returned
false. Since OCR-FPT(G(eSi,2, G), s, t) does return false, G has no valid path
from s to t. Similarly, if Algorithm 4.2 returns false on line 16, then G has no
valid path from s to t.
Now, assume that Algorithm 4.2 returns true. Algorithm 4.2 can return true
on Line 5, Line 10, Line 13, Line 16, or Line 17. We will prove that G has a
valid path from s to t through induction on the size of the choice set S.
Assume that |S| = 1. In this case, Algorithm 4.2 can only return true on
Line 5. Thus, t ∈G(eS1,1, G) or t ∈G(eS1,2, G). If t ∈G(eS1,1, G) then there is
a path from s to t in G that does not use eS1,1. Since S1 = (eS1,1, eS1,2) is the
only pair in G this path is, by deﬁnition, a valid path from s to t. Similarly, if
t ∈G(eS1,2, G), then G has a valid path from s to t.
Now assume that if Algorithm 4.2 returns true on a choice network G with
|S| < k, then G has a valid path from s to t. Suppose we run Algorithm 4.2 on
a choice network G with |S| = k.
If Algorithm 4.2 returns true on Line 10, Line 13, or Line 16, then either
OCR-FPT(G(eSi,1, G), s, t) or OCR-FPT(G(eSi,2, G), s, t) returns true for
some pair Si. If OCR-FPT(G(eSi,1, G), s, t) returns true, then by the induc-
tive hypothesis, G(eSi,1, G) has a valid path from s to t. Note that this path
is also a valid path in G. Thus, G has a valid path from s to t. Similarly,
OCR-FPT(G(eSi,2, G), s, t) returns true, then G has a valid path from s to t.

Analyzing the Reachability Problem in Choice Networks
417
If Algorithm 4.2 returns true on Line 17, then there is no pair Si that satisﬁes
either condition 1 or condition 2 in Lemma 1. Thus, by Lemma 1, G must have
a valid path from s to t.
⊓⊔
4.3
Exact Exponential Algorithm
We now look at a diﬀerent way of analyzing Algorithm 4.2.
Let T ′(n) be the running time of Algorithm 4.2 on a choice network with
n vertices. Observe that the reduction rules in Sect. 4.2 only reduce the size of
the choice set if vertices are removed from G. Additionally, Algorithm 4.2 only
recurses if the size of the choice set is reduced by the reduction rules. Thus,
if Algorithm 4.2 recurses on choice Si, then both G(eSi,1, G) and G(eSi,2, G)
have fewer vertices than G. Consequently, the running time of Algorithm 4.2 is
governed by the recurrence relation T ′(n) ≤T ′(n−1)+T ′(n−1)+O(|S|·(m+n)).
From [6], Algorithm 4.2 runs in time O(|S| · (m + n) · 2n). Thus, Algorithm
4.2 is also an exact exponential algorithm for OCRD.
4.4
Approximation Complexity
We now show that the OCROpt problem is NPO PB-complete.
Note that a valid path p in a choice network has at most n arcs. Additionally,
recall that the validity of a path can be veriﬁed in polynomial time. Thus the
OCROpt is in NPO PB. All that remains is to show NPO PB-hardness. This
is done by a reduction from the Min-Ones problem.
The Min-Ones problem is deﬁned as follows: Given a 3-CNF formula Φ, what
is the satisfying assignment to Φ with the fewest variables set to true. This
problem is known to be NPO PB-complete [13]. We will modify the network
construction used in Sect. 4.1 to prove the inapproximability of OCROpt.
Let Φ be a 3-CNF formula with m′ clauses over n′ variables and let G be
the choice network corresponding to Φ as per the construction in Sect. 4.1. From
Sect. 4.1, G has the following properties: 1. In each variable gadget, the upper
path has (|Xi| + 1) arcs where |Xi| is the number of clauses in Φ with the literal
xi. 2. In each variable gadget, the lower path has (| ¯
Xi|+1) arcs where | ¯
Xi| is the
number of clauses in Φ with the literal ¬xi. 3. In each clause gadget, each path
through the gadget has two arcs. From G, we construct the choice network G′
by adding unpaired arcs to the end of each path through each variable gadget,
until:
1. The upper path in each variable gadget has m′ arcs.
2. The lower path in each variable gadget has m′ · (n′ + 3) arcs.
This gives the network G′ the following properties:
1. The shortest path from s to t has m′ · (n′ + 2) arcs. This path uses the upper
path in each variable gadget (a total of m′ · n′ arcs) and any path through
each clause gadget (an additional 2 · m′ arcs). Note that this path is valid if
and only if Φ is satisﬁed by the all false assignment.

418
P. Wojciechowski et al.
2. Each time a path from s to t uses the lower path through a variable gadget,
the length of the path increases by m′ · (n′ + 2) arcs.
We can now relate the length of paths in G′ to the number of true variables
in a satisfying assignment to Φ.
Theorem 3. G′ has a valid path p from s to t with (k + 1) · m′ · (n′ + 2) arcs if
and only if Φ has a satisfying assignment in which k variables are set to true.
Proof. From Theorem 1, G′ has a valid path p from s to t if and only if Φ has
a satisfying assignment x. In each variable gadget, p takes the lower path if and
only if x assigns that variable to true. Note that every satisfying assignment to
Φ corresponds to such a valid path.
Let x be a satisfying assignment to Φ with k variables set to true. Thus,
(n′ −k) variables are set to false.
Let p the the corresponding valid path from s to t in G′. Note that p takes
the upper path through (n′ −k) variable gadgets and the lower path through k
variable gadgets. This means that p has length
(n′ −k) · m′ + k · m′ · (n′ + 3) + 2 · m′ = (k + 1) · m′ · (n′ + 2).
Thus G′ has a valid path p from s to t with (k + 1) · m′ · (n′ + 2) arcs if and
only if Φ has a satisfying assignment in which k variables are set to true.
⊓⊔
Thus, the reduction from Min-Ones to OCROpt is approximation preserving.
Since the Min-Ones problem is NPO PB-complete so is the OCROpt problem.
Thus, the OCROpt problem cannot be approximated to within a polylogarithmic
factor unless P = NP.
5
Weighted Reachability in Choice Networks
In this section, we study the WOCROpt problem.
5.1
Approximation Complexity
We now show that the WOCROpt problem is NPO-complete.
Recall that the validity of a path can be veriﬁed in polynomial time. Thus the
WOCROpt problem is in NPO. All that remains is to show NPO-hardness.
This is done by a reduction from the Weighted Min-Ones problem.
The Weighted Min-Ones problem is deﬁned as follows: Given a 3-CNF for-
mula Φ and variable weight function w, what is the satisfying assignment to
Φ with the least weight of variables set to true. This problem is known to be
NPO-complete [20]. We will modify the network construction used in Sect. 4.1
to prove the inapproximability of WOCROpt.

Analyzing the Reachability Problem in Choice Networks
419
Let Φ be a 3-CNF formula with m′ clauses over n′ variables and let G be
the choice network corresponding to Φ as per the construction in Sect. 4.1. We
weight the arcs in G as follows: 1. In each clause gadget in G, give every arc a
cost of 0. 2. In the variable gadget corresponding to variable xi, give every arc
a cost of 0 except for the unpaired arc on the lower path, which gets a cost of
w(xi). This is shown in Fig. 4.
· · ·
· · ·
¯
Xi
Xi
0
w(xi)
0
0
0
0
0
0
0
0
0
0
Fig. 4. Weighted variable gadget corresponding to the variable xi.
We can now relate the costs of paths in G to the weight of true variables in
satisfying assignments to Φ.
Theorem 4. G has a valid path p from s to t with cost k if and only if Φ has
a satisfying assignment in which the weight of variables set to true is k.
Proof. From Theorem 1, G has a valid path p from s to t if and only if Φ has
a satisfying assignment x. In each variable gadget, p takes the lower path if and
only if x assigns that variable to true. Note that every satisfying assignment to
Φ corresponds to such a valid path.
Let x be a satisfying assignment to Φ in which the total weight of variables
set to true is k. Let p the the corresponding valid path from s to t in G′.
For every variable xi set to true in x, p has one arc of cost w(xi). All other
arcs in p have cost 0. This means that p has total cost k.
Thus G has a valid path p from s to t with cost k if and only if Φ has a
satisfying assignment in which the weight of variables set to true is k.
⊓⊔
Thus, the reduction from Weighted Min-Ones to WOCROpt is approximation
preserving. Since the Weighted Min-Ones problem is NPO-complete so is the

420
P. Wojciechowski et al.
WOCROpt problem. Thus, the WOCROpt problem cannot be approximated to
within a polynomial factor unless P = NP.
6
Lower Bounds for OCRD
We now use the Strong Exponential Time Hypothesis (SETH) to establish lower
bounds on the running time of any algorithm for the OCRD problem.
Let Φ be a CNF formula with n′ variables. We construct the corresponding
choice network G as follows:
For each variable xi we create the structure shown in Fig. 5.
¯
Xi
Xi
Fig. 5. Variable gadget corresponding to the variable xi.
In Fig. 5 the dashed lines connect the arcs which are in the same pair. If a
valid path p traverses the left path, then both of the arcs in the set ¯
Xi are paired
with an arc in p. Thus, neither of the arcs in set ¯
Xi can be in p. Similarly, if p
traverses the right path, then neither of the arcs in the set Xi can be in p.
l1 ∈X1
l2 ∈¯
X2
Fig. 6. Clause gadget corresponding to
the clause (x1, ¬x2).
Using the arcs in the sets Xi and ¯
Xi
we now construct a gadget for each clause
φ in Φ. The clause gadget correspond-
ing to a k-literal clause φj has k possible
paths through the gadget corresponding
to the variables in φj. The path corre-
sponding to the variable xi ∈φj is made
using the arc li ∈Xi if the literal xi is
in φj, or the arc li ∈¯
Xi if the literal ¬xi
is in φj. An example of such a gadget is
shown in Fig. 6.
We construct the choice network G by combining the gadgets as they were
combined in Sect. 4.1. Thus, any valid path from s to t must traverse all the
variable gadgets, followed by all the clause gadgets.
Theorem 5. G has a valid path from s to t if and only if Φ is satisﬁable.
Proof. First, we assume that Φ is satisﬁable. Let x be a truth assignment that
satisﬁes Φ. We use x to construct the valid path p. For each variable xi assigned

Analyzing the Reachability Problem in Choice Networks
421
a value of true, p will traverse the left path of the corresponding variable gadget.
This prevents any of the arcs in ¯
Xi from being on p. Similarly, for each variable xi
assigned a value of false the path will traverse the right path of the corresponding
variable gadget. This prevents any of the arcs in Xi from being on the path.
Let (xi, ¬xj, xk) be an arbitrary clause in the system. At least one literal
in this clause is assigned a value of true. Since the three paths through the
corresponding gadget correspond to the sets Xi, ¯Xj, and Xk, at least one path
through the gadget can still be traversed by p. Thus, we can construct a valid
path from s to t in G.
Now assume that there is a valid path p from s to t in G. We use p to
construct the assignment x as follows: for each variable xi, if p traverses the left
path of the gadget corresponding to xi, then set xi to true, otherwise set xi to
false.
Consider a clause φ of Φ and look at how p traverses the corresponding gadget
in G. p either uses an arc in the set Xi for a literal xi in φ, or p uses an arc in
the set ¯
Xi for a literal ¬xi in φ. If p uses an arc in the set Xi, then p cannot
traverse the right path of the gadget corresponding to xi. Thus, p must traverse
the left path of the gadget. Consequently, xi is assigned a value of true and x
satisﬁes the clause φ.
If p uses an arc in the set ¯
Xi, then p cannot traverse the left path of the
gadget corresponding to xi. Thus, p must traverse the right path of the gadget.
Consequently, xi is assigned a value of false and x satisﬁes the clause φ. Since
φ was an arbitrarily chosen clause, x satisﬁes Φ as desired.
⊓⊔
Note that G has |S| = 4 · n′ pairs of arcs. Thus, if an algorithm solved the
OCRD problem in time o(1.18|S|) time, then that algorithm would solve SAT
in time o(1.184·n′) ⊆o(1.94n′). This would violate the Strong Exponential Time
Hypothesis.
7
Conclusion
In this paper, we investigated algorithmic issues associated with the reachability
problem in choice networks (OCRD) and its variants. The OCRD problem is a
special case of the Resource-Constrained Shortest path (RCSP) problem. The lit-
erature on RCSP specializations is immense. As mentioned before, this problem
ﬁnds applications in a number of diﬀerent domains such as transportation logis-
tics and program veriﬁcation. The three principal contributions of this paper
are showing that OCRD is NP-complete, OCROpt is NPO PB-complete
and that OCRD/OCROpt are ﬁxed-parameter tractable in the cardinality
of the choice set. We also studied the WOCROpt problem and derived algorith-
mic and complexity results for the same. From our perspective, the following
problem is worth investigating: A lower bound on the algorithmic complexity of
the WOCROpt problem - We are in the process of showing that no algorithm for
this problem can run in o(n2 · 2n) time unless the Traveling Salesman problem
can be solved in o(n2 · 2n) time. The Heldman-Karp bound of Ω(n2 · 2n) time
has not seen improvement in the last ﬁve decades [9].

422
P. Wojciechowski et al.
References
1. Ahuja, R.K., Magnanti, T.L., Orlin, J.B.: Network Flows: Theory, Algorithms and
Applications. Prentice-Hall (1993)
2. Ahuja, R.K., Mehlhorn, K., Orlin, J.B., Tarjan, R.E.: Faster algorithms for the
shortest path problem. J. ACM 37(2), 213–223 (1990)
3. Bajaj, C.P.: Some constrained shortest-route problems. Unternehmensforschung
15(1), 287–301 (1971)
4. Bang-Jensen, J., Bessy, S., Jackson, B., Kriesell, M.: Antistrong digraphs. J. Comb.
Theory Ser. B 122, 68–90 (2017)
5. Beasley, J.E., Christoﬁdes, N.: An algorithm for the resource constrained shortest
path problem. Networks 19(4), 379–394 (1989)
6. Cygan, M., et al.: Parameterized Algorithms. Springer, Cham (2015). https://doi.
org/10.1007/978-3-319-21275-3
7. Deo, N., Pang, C.Y.: Shortest-path algorithms: taxonomy and annotation. Net-
works 14(2), 275–323 (1984)
8. Ferone, D., Festa, P., Guerriero, F.: An eﬃcient exact approach for the constrained
shortest path tour problem. Optim. Methods Softw. 35(1), 1–20 (2020)
9. Fomin, F.V., Kratsch, D., Woeginger, G.J.: Exact (exponential) algorithms for the
dominating set problem. In: Hromkoviˇc, J., Nagl, M., Westfechtel, B. (eds.) WG
2004. LNCS, vol. 3353, pp. 245–256. Springer, Heidelberg (2004). https://doi.org/
10.1007/978-3-540-30559-0 21
10. Gabow, H.N., Maheswari, S.N., Osterweil, L.J.: On two problems in the generation
of program test paths. IEEE Trans. Software Eng. 2(3), 227–231 (1976)
11. Garey, M.R., Johnson, D.S.: Computers and Intractability: A Guide to the Theory
of NP-Completeness. W.H. Freeman Company, San Francisco (1979)
12. Horv´ath, M., Kis, T.: Multi-criteria approximation schemes for the resource con-
strained shortest path problem. Optim. Lett. 12(3), 475–483 (2017). https://doi.
org/10.1007/s11590-017-1212-z
13. Kann, V.: Polynomially bounded minimization problems that are hard to approx-
imate. Nordic J. Comput. 1(3), 317–331 (1994)
14. Kant´e, M.M., Moataz, F.Z., Mom`ege, B., Nisse, N.: Finding paths in grids with
forbidden transitions. In: Mayr, E.W. (ed.) WG 2015. LNCS, vol. 9224, pp. 154–
168. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53174-7 12
15. B¨uning, H.K., Wojciechowski, P., Subramani, K.: Finding read-once resolution
refutations in systems of 2CNF clauses. Theor. Comput. Sci. 729, 42–56 (2018)
16. Kolman, P., Pangr´ac, O.: On the complexity of paths avoiding forbidden pairs.
Discret. Appl. Math. 157(13), 2871–2876 (2009)
17. Kov´ac, J.: Complexity of the path avoiding forbidden pairs problem revisited.
Discret. Appl. Math. 161(10–11), 1506–1512 (2013)
18. Kukunuru, N.: Secure and energy aware shortest path routing framework for WSN.
In: Balas, V.E., Sharma, N., Chakrabarti, A. (eds.) Data Management, Analytics
and Innovation. AISC, vol. 808, pp. 379–390. Springer, Singapore (2019). https://
doi.org/10.1007/978-981-13-1402-5 29
19. Hosseini Nodeh, Z., Babapour Azar, A., Khanjani Shiraz, R., Khodayifar, S.,
Pardalos, P.M.: Joint chance constrained shortest path problem with Copula the-
ory. J. Comb. Optim. 40(1), 110–140 (2020)
20. Orponen, P., Mannila, H.: On approximation preserving reductions: complete prob-
lems and robust measures. Technical report, Department of Computer Science,
University of Helsinki (1987)

Analyzing the Reachability Problem in Choice Networks
423
21. Christos, H.: Papadimitriou. Computational Complexity. Addison-Wesley, New
York (1994)
22. Saigal, R.: Letter to the editor - a constrained shortest route problem. Oper. Res.
16(1), 205–209 (1968)
23. Sivakumar, R.A., Batta, R.: The variance-constrained shortest path problem.
Transp. Sci. 28(4), 309–316 (1994)
24. Szeider, S.: Finding paths in graphs avoiding forbidden transitions. Discret. Appl.
Math. 126(2–3), 261–273 (2003)
25. Wang, N., Li, J.: Shortest path routing with risk control for compromised wireless
sensor networks. IEEE Access 7, 19303–19311 (2019)
26. Wojciechowski, P., Williamson, M., Subramani, K.: On ﬁnding shortest paths in
arc-dependent networks. In: Ba¨ıou, M., Gendron, B., G¨unl¨uk, O., Mahjoub, A.R.
(eds.) ISCO 2020. LNCS, vol. 12176, pp. 249–260. Springer, Cham (2020). https://
doi.org/10.1007/978-3-030-53262-8 21
27. Yinnone, H.: On paths avoiding forbidden pairs of vertices in a graph. Discret.
Appl. Math. 74(1), 85–92 (1997)

Model-Based Approaches
to Multi-attribute Diverse Matching
Jiachen Zhang(B), Giovanni Lo Bianco(B), and J. Christopher Beck(B)
Department of Mechanical and Industrial Engineering, University of Toronto,
Toronto, ON M5S 3G8, Canada
{jasonzjc,giolb,jcb}@mie.utoronto.ca
Abstract. Bipartite b-matching is a classical model that is used for
utility maximization in various applications such as marketing, health-
care, education, and general resource allocation. Multi-attribute diverse
weighted bipartite b-matching (MDWBM) balances the quality of the
matching with its diversity. The recent paper by Ahmadi et al. (2020)
introduced the MDWBM but presented an incorrect mixed integer
quadra-tic program (MIQP) and a ﬂawed local exchange algorithm. In
this work, we develop two constraint programming (CP) models, a binary
quadratic programming (BQP) model, and a quadratic unconstrained
binary optimization (QUBO) model for both the unconstrained and con-
strained MDWBM. A thorough empirical evaluation using commercial
solvers and specialized QUBO hardware shows that the hardware-based
QUBO approach dominates, ﬁnding best-known solutions on all tested
instances up to an order of magnitude faster than the other approaches.
CP is able to achieve better solutions than BQP on unconstrained prob-
lems but under-performs on constrained problems.
Keywords: Specialized hardware · QUBO · Constraint
programming · Digital Annealer · Diverse matching
1
Introduction
Bipartite matching problems assign an agent on one side of a market to an agent
on the other side. Weighted bipartite b-matching generalizes such problems to
the setting where matches have real-valued weights and agents on one side of
the market can be matched to at most b agents on the other side. The weighted
bipartite b-matching problem serves as the core of applications such as general
resource allocation [6] and recommender systems [18].
The Multi-attribute Diverse Weighted Bipartite b-Matching (MDWBM)
problem has been recently introduced to simultaneously maximize the quality
and diversity of a bipartite b-matching [1]. The quality is measured by weighted
costs of assignments and the diversity is calculated in terms of diﬀerences across
multiple feature classes. Ahmadi et al. [1] proved that MDWBM is NP-hard
and tackled it with a mixed integer quadratic programming (MIQP) model
and an exact local exchange algorithm. However, there are ﬂaws in both of
c
⃝Springer Nature Switzerland AG 2022
P. Schaus (Ed.): CPAIOR 2022, LNCS 13292, pp. 424–440, 2022.
https://doi.org/10.1007/978-3-031-08011-1_28

Model-Based Approaches to MDWBM
425
these approaches. In this work, we address MDWBM and its constrained vari-
ant with three model-based paradigms: Constraint Programming (CP), Binary
Quadratic Programming (BQP), and Quadratic Unconstrained Binary Opti-
mization (QUBO). We make three primary contributions:
1. We propose two CP models, a BQP model, and a QUBO model of MDWBM.
2. By adding several practical constraints, we introduce constrained MDWBM.
3. We obtain state-of-the-art results for the standard and constrained MDWBM
on software-based solvers with the CP and BQP models and on specialized
hardware with the QUBO model, demonstrating that recent hardware archi-
tectures can be harnessed for combinatorial optimization problems.
2
Diverse Matching
A matching market often aims to maximize quality subject to some fairness
constraints, such as assuring equal opportunity amongst agents. Benabbou et
al. [5] study the trade-oﬀbetween social welfare and diversity for the Singapore
housing allocation, modeling diversity with constraints added to a model of an
extension of the classic assignment problem.
Diverse bipartite b-matching [2] represents the trade-oﬀbetween eﬃciency
and diversity, where a matching provides good coverage over diﬀerent varieties
of agents. Diversity has been generally measured by some expression of cover-
age of the space of possible variation. Mathematically, researchers have used
submodular functions, which encode the diminishing returns of similarity. For
example, submodular diversity metrics are used in information retrieval com-
munities, including determinantal point processes [21] and Maximum Marginal
Relevance (MMR) [7]. Multi-attribute diverse weighted bipartite b-matching is
a more general problem as it deals with multiple classes of features. The goal is
to form diverse matchings with respect to all feature classes.
To our knowledge, there is no work on constrained diverse matching in the
literature other than that on conﬂict and degree constraints in non-diverse bipar-
tite b-matching in e-commerce [8] and vehicular networks [14].
2.1
Multi-attribute Diverse Weighted Bipartite b-Matching
In
the
Multi-attribute
Diverse
Weighted
Bipartite
b-Matching
problem
(MDWBM) [1], there are two sets of nodes U and V in a bipartite graph. Every
node in V has multiple features, each of which belongs to a diﬀerent feature
class. Let F be the set of feature classes, for example in a worker-team assign-
ment context, F = {Gender, Nationality}. For each f ∈F, we use Gf to denote
the set of values for class f, such as GNationality = {France, Canada}. The set of
nodes in V with feature value gf for feature f is denoted by F gf
f . A b-matching
on a bipartite graph allows a node from U to be connected to multiple (b) nodes
in V via edges. An example of the bipartite b-matching is illustrated in Fig. 1.
Each edge is weighted by a cost, hence connecting nodes comes with the cost.
The purpose of MDWBM is to minimize the weighted sum of cost and diversity.

426
J. Zhang et al.
Fig. 1. Bipartite 2-matching.
For MDWBM, the objective function to be minimized is:
obj = S + W =

f∈F

u∈U

gf ∈Gf

λf ·

cu,f,gf
2 + λ0 · wu,f,gf · cu,f,gf

,
(1)
where S represents the similarity of the matching and W represents the weighted
assignment cost. cu,f,gf denotes the number of nodes in V connected to node
u ∈U having value gf for feature class f. Accordingly, if Sf is the similarity of
a matching w.r.t. feature class f, then S can also be represented by:
S =

f∈F
λf · Sf =

f∈F
λf ·

u∈U

gf ∈Gf

cu,f,gf
2 .
(2)
where λf ∈Z+ is a weight expressing the importance of feature f. Minimizing S,
namely the supermodular similarity function1 w.r.t. multiple features, has been
proved to be NP-hard [1].
A weight is associated with a connection between a feature value gf to a node
u ∈U. Speciﬁcally, the weight wu,f,gf ∈Z+ represents the cost of assigning a
node in V whose feature class f value is gf to node u ∈U. The costs are assumed
to be integers [1]. The total cost of a matching is
W = λ0

f∈F

u∈U

gf ∈Gf
wu,f,gf · cu,f,gf
(3)
where λ0 ∈Z+.
Each node u ∈U has a degree of du, specifying that the number of nodes
in V connected to u is exactly du in a matching. Each node v ∈V can only be
connected to at most one node in U. Ahmadi et al. address problems with these
degree constraints, a special case of the general MDWBM.
Constraints. Assignment/allocation problems often contain constraints that,
to our knowledge, have not been included in any formulations of MDWBM. In
this paper, we address six types of constraints as follows.
1 The negative submodular diversity is equivalent to the supermodular similarity.

Model-Based Approaches to MDWBM
427
– Conﬂict (C): Two nodes v1, v2 ∈V cannot both be assigned to a node u ∈U.
Consider an example in the worker-team assignment context: two workers
cannot be assigned to the same team due to a personal conﬂict.
– Binding (B): Nodes v1, v2 ∈V must be assigned to the same node u ∈U.
– Conﬂict Assignment (CA): A node v ∈V cannot be assigned to a node u ∈U.
For example in the paper review context, a reviewer cannot be assigned to a
paper due to the conﬂict of interest.
– Binding Assignment (BA): A node v ∈V must be assigned to a node u ∈U.
For example, a particular reviewer must be assigned to a speciﬁc paper.
– Must-Have (MH): A node u ∈U must be assigned at least one node v ∈V
with a speciﬁc value gf ∈Gf. For instance, in an engineering course project,
a team must have at least one student who is good at coding.
– Not-Alone (NA): A node u ∈U is assigned either 0 or at least E (E ≥2)
nodes in V , which have value gf ∈Gf. For example in engineering course
projects, each group must have either 0 or at least two female students.
We call the multi-attribute diverse matching with degree constraints the stan-
dard MDWBM and the extension including any of the six practical constraints
the constrained MDWBM.
2.2
Related Work
There is only one work in the literature that studied the MDWBM. Ahmadi et
al. [1] proposed an mixed integer quadratic programming (MIQP) model for the
standard MDWBM and also introduced an local exchange algorithm based on
negative cycle detection. However, both the model and the algorithm are ﬂawed.
The key problem of the MIQP model is that it uses cu,f,gf deﬁned above as the
decision variable. However, cu,f,gf does not represent an assignment but rather
the number of nodes with a particular feature value assigned to a node. Thus,
there is no bijection between the set of assignments and the set of solutions to the
MIQP model. In fact, the decision variable choice decouples the combination of
feature values from an assignment and hence can provide superoptimal solutions
(i.e. the model is a relaxation of the true problem).
The local exchange algorithm uses the identiﬁcation of negative cycles to
improve a matching. A series of moves that leads to a decrease in the objective is
called a negative cycle. In each iteration, the algorithm evaluates a neighborhood
of solutions via node movement and detects the existence of negative cycles. The
algorithm stops when it cannot ﬁnd any negative cycle. The authors claimed and
proved that the algorithm terminates at a global optimum [1]. However, the claim
is false as there exists potential objective decrease that cannot be captured by
the negative cycles.
The detailed information and counterexamples for both the model and the
algorithm ﬂaws are provided in the online appendix.2
2 https://tidel.mie.utoronto.ca/pubs/Appendix Matching CPAIOR22.pdf.

428
J. Zhang et al.
3
Constraint Programming Models for MDWBM
We propose two constraint programming (CP) models for MDWBM. The ﬁrst
is based on integer assignment variables, like most CP models for bin packing
problems. The second model manipulates a list of integer selection variables
for each node u ∈U, requiring more eﬀort to link variables and parameters. For
convenience, we use assignment CP (ACP) and selection CP (SCP), respectively,
to represent the two models.
3.1
Assignment CP Model
The ACP is as follows:
min
x
W + S
(4a)
s.t. cardinality({x1, ..., x|V |}, {0, 1, ..., |U|}, {|V | −

u∈U
du, d1, ..., d|U|}),
(4b)
knapsack(xf,gf , {c0,f,gf , ..., c|U|,f,gf }, {1, ..., 1}), ∀f ∈F, ∀gf ∈Gf,
(4c)
spread({cu,f,1, ..., cu,f,|Gf |}, du
|Gf|, σu,f), ∀u ∈U, ∀f ∈F,
(4d)
W = λ0

v∈V
Axv,v,
(4e)
S =

f∈F

u∈U
λf ·

σ2
u,f · |Gf| + d2
u
|Gf|

,
(4f)
xv ∈{0, 1, ..., |U|}, ∀v ∈V,
(4g)
cu,f,gf ∈{0, 1, ..., du}, ∀u ∈U ∪{0}, ∀f ∈F, ∀gf ∈Gf,
(4h)
xv1 ̸= xv2, ∀(v1, v2) ∈CC,
(4i)
xv1 = xv2, ∀(v1, v2) ∈CB,
(4j)
xv ̸= u, ∀(u, v) ∈CCA,
(4k)
xv = u, ∀(u, v) ∈CCB,
(4l)
cu,f,gf ≥1, ∀(u, f, gf) ∈CMH,
(4m)
cu,f,gf ∈{0, E, E + 1, ..., du}, ∀(u, f, gf, E) ∈CNA.
(4n)
The integer decision variable xv = u if the node v is assigned to node u, and
0 if the node u is assigned to a dummy node 0 /∈U. The dummy node does not
have a ﬁxed upper bound on degree and is used when some node in V is not
matched to any node in U. The integer variable cu,f,gf represents the number
of nodes in V connected to node u ∈U ∪{0} having value gf for feature class
f. In our implementation, the dummy node is assigned the last index instead of
the ﬁrst one to better ﬁt the typical default search algorithm of CP solvers.
In the model, constraint (4b) is the global cardinality constraint (gcc) ensuring
the number of nodes in V matched to node u ∈U is exactly du. The rest of
the nodes are matched to the dummy node, which has degree |V | −	
u∈U du.

Model-Based Approaches to MDWBM
429
Constraint (4c) is the multi-knapsack constraint that links variables x and c
together. The variable set xf,gf contains all the xv, where node v has gf as the
feature value of feature class f. Constraint (4d) is the spread constraint to obtain
the standard deviation σu,f of cu,f,gf (excluding the dummy node) over gf ∈Gf.
Note that the mean value of cu,f,gf over gf ∈Gf is the constant du/|Gf| as there
are exactly du nodes in V that are matched to u.
Constraint (4e) represents the assignment cost of the matching, which is also
the ﬁrst component of the objective function to minimize.3 The (u, v) entry of
the matrix A is the cost of assigning v to u, which is pre-calculated by
Au,v =

(f,gf ) if v∈F
gf
f
wu,f,gf .
(5)
Constraint (4f) expresses the similarity of the matching, which is equivalent to
term (2). Constraints (4g) and (4h) address the variable ranges.
The standard MDWBM is modeled by objective (4a) and constraints (4b)–
(4h), while constraints (4i)–(4n) are for constrained MDWBM. Constraint (4i)
is the conﬂict constraint where CC contains pairs of conﬂict nodes in V . Con-
straint (4j) is the binding constraint where CB contains pairs of binding nodes
in V . Constraint (4k) is the conﬂict assignment constraint where CCA contains
node pairs that cannot be connected. Constraint (4l) is the binding assignment
constraint where CBA contains node pairs that must be connected by the assign-
ment. Constraint (4m) is the must-have constraint where CMH contains the 3-
tuples ⟨node in U, feature class, feature value⟩. Constraint (4n) is the not-alone
constraint where CNA contains the 4-tuples ⟨node in U, feature class, feature
value, the number of eligible nodes in V ⟩. Note that constraints (4k) - (4n) are
implemented via direct domain pruning in the model.
3.2
Selection CP Model
The SCP is as follows:
min
x
W + S
(6a)
s.t. alldiﬀerent({xu,k, ∀u ∈U, ∀k = 1, ..., du}),
(6b)
table(T, xu,k, {z1
u,k, ..., z|F |
u,k}), ∀u ∈U, ∀k = 1, ..., du,
(6c)
cardinality({{zf
u,1, ..., zf
u,du}, {1, ..., |Gf|}, {cu,f,1, ..., cu,f,|Gf |}}),
∀u ∈U, ∀f ∈F,
(6d)
spread({cu,f,1, ..., cu,f,|Gf |}, du
|Gf|, σu,f), ∀u ∈U, ∀f ∈F,
(6e)
W = λ0

u∈U

1≤k≤du
Au,xu,k,
(6f)
3 We use (4e) instead of (3) according to the superior results in our experiments.

430
J. Zhang et al.
S =

f∈F

u∈U
λf ·

σ2
u,f · |Gf| + d2
u
|Gf|

,
(6g)
xu,k ∈{1, ..., |V |}, ∀u ∈U, ∀k = 1, ..., du,
(6h)
cu,f,gf ∈{0, 1, ..., du}, ∀f ∈F, ∀gf ∈Gf,
(6i)
count({xu,1, ..., xu,du}, v1) + count({xu,1, ..., xu,du}, v2) ≤1,
∀u ∈U, ∀(v1, v2) ∈CC,
(6j)
count({xu,1, ..., xu,du}, v1) = count({xu,1, ..., xu,du}, v2),
∀u ∈U, ∀(v1, v2) ∈CB,
(6k)
xu,k ̸= v, ∀k = 1, ..., du, ∀(u, v) ∈CCA,
(6l)
count({xu,1, ..., xu,du}, v) = 1, ∀(u, v) ∈CCB,
(6m)
cu,f,gf ≥1, ∀(u, f, gf) ∈CMH,
(6n)
cu,f,gf ∈{0, E, E + 1, ..., du}, ∀(u, f, gf, E) ∈CNA.
(6o)
The integer decision variable xu,k = v if v is the k-th node selected by node
u. The integer variable cu,f,gf is the same as in ACP. In the model, constraint
(6b) is the all-diﬀerent constraint guaranteeing that nodes in U select distinct
nodes in V . Constraint (6c) is the table constraint that links x and z. T is the
feature matrix, where the (v, f) entry is the value of feature f of node v. Then,
zf
u,k represents the feature value of the k-th node matched to u. Constraint (6d)
is the gcc constraint that links c and z. Constraint (6e) is the same as (4d) and
constraint (6f) represents the assignment cost of the matching, with the same
cost matrix A as in ACP. Constraint (6g) is the same as (4f). Constraints (6h)
and (6i) express the variable ranges.
The standard MDWBM is modeled by (6a)–(6i), while constraints (6j)–(6o)
are for the constrained MDWBM. Similar to ACP, constraints (6j), (6k), (6l),
(6m), (6n), and (6o) represent the conﬂict, binding, conﬂict assignment, binding
assignment, must-have, and not-alone constraints, respectively.
4
Quadratic Models for MDWBM
In this section, we propose a Binary Quadratic Programming (BQP) model and
a Quadratic Unconstrained Binary Optimization (QUBO) model for MDWBM.
4.1
BQP Model
We introduce a BQP model with binary assignment variables. The decision vari-
able xu,v = 1 if node v ∈V is assigned to node u ∈U, and 0 otherwise. Based
on the feature values of each node v ∈V , we can generate a feature matrix
B = {bv,f,gf } where bv,f,gf = 1 if node v has value gf for feature f, and 0 oth-
erwise. Similarly, we can generate a weighted cost matrix C = {cu,v,f} based on
weighted cost parameters wu,f,gf . We use cu,v,f to represent the cost for feature
class f if node v ∈V is assigned to node u ∈U. We set cu,v,f = wu,f,gf if node
v has value gf for feature class f and 0 otherwise. In addition, we also add a

Model-Based Approaches to MDWBM
431
dummy node indexed by 0 to deal with situations where a node in V might not
be matched to any node in U. Our BQP model is shown below.
min
x
λ0 ·

f∈F

u∈U

v∈V
cu,v,f · xu,v+
(7a)

f∈F
λf ·

u∈U

gf ∈Gf


v∈V
bv,f,gf · xu,v
2
(7b)
s.t.

v∈V
xu,v = du, ∀u ∈U,
(7c)

u∈U∪{0}
xu,v = 1, ∀v ∈V,
(7d)
xu,v1 + xu,v2 ≤1, ∀u ∈U, ∀(v1, v2) ∈CC,
(7e)
xu,v1 = xu,v2, ∀u ∈U, ∀(v1, v2) ∈CB,
(7f)
xu,v = 0, ∀(u, v) ∈CCA,
(7g)
xu,v = 1, ∀(u, v) ∈CBA,
(7h)

v∈V
bv,f,gf · xu,v ≥1, ∀(u, f, gf) ∈CMH,
(7i)

v∈V
bv,f,gf · xu,v ≥E · yu,f,gf , ∀(u, f, gf, E) ∈CNA,
(7j)

v∈V
bv,f,gf · xu,v ≤du · yu,f,gf , ∀(u, f, gf, E) ∈CNA,
(7k)
xu,v ∈{0, 1}, ∀u ∈U ∪{0}, ∀v ∈V,
(7l)
yu,f,gf ∈{0, 1}, ∀u ∈U ∪{0}, ∀f ∈F, ∀gf ∈Gf.
(7m)
Term (7a) represents the weighted cost of the assignment. Term (7b) rep-
resents the supermodular similarity w.r.t. all feature classes. Constraint (7c)
guarantees that node u ∈U (excluding the dummy node) has a degree of du.
Constraint (7d) ensures that each node in V is only assigned to one node in U.
These components form the BQP model for the standard MDWBM. Constraints
(7e) to (7i) model the conﬂict constraints to must-have constraints, respectively.
Constraints (7j) and (7k) represent the not-alone constraints. The variable
yu,f,gf = 0 if node u is not matched to any node in V with feature value gf of
feature f and yu,f,gf = 1 if the number of such nodes matched to u is greater
than or equal to E.
4.2
Quadratic Unconstrained Binary Optimization
The recent emergence of specialized hardware has opened up new ways to solve
speciﬁc computational tasks, such as combinatorial optimization problems [26].
Including adiabatic and gate-based quantum computers [23] and CMOS anneal-
ers [3], these novel technologies represent a variety of designs and underlying
models of computation. Many of the designs for combinatorial optimization

432
J. Zhang et al.
target problems formulated as an Ising model or equivalently as a Quadratic
Unconstrained Binary Optimization (QUBO) model [9], which is the following
problem:
min y = 1
2

i

j̸=i
Wi,jxixj +

i
bixi + c,
(8)
where x ∈{0, 1}n are binary decision variables, W ∈Mn,n(R) is a symmetric
weight matrix, b ∈Rn is a bias vector, and c ∈R is a constant [20]. QUBO
has been used to represent problems in combinatorial scientiﬁc computing [26],
machine learning [10], and ﬁnance [25]. With multiple feature classes, the super-
modular similarity function of MDWBM is naturally quadratic, suggesting that
it might be a good candidate for such novel hardware.
In our QUBO model, we use the same binary assignment variables xu,v as in
the BQP model. The QUBO model of MDWBM is shown below.
min
x
λ0 ·

f∈F

u∈U

v∈V
cu,v,f · xu,v+
(9a)

f∈F
λf ·

u∈U

gf ∈Gf


v∈V
bv,f,gf · xu,v
2
+
(9b)
p1 ·

u∈U


v∈V
xu,v −du
2
+
(9c)
p2 ·

v∈V
⎛
⎝

u∈U∪{0}
xu,v −1
⎞
⎠
2
+
(9d)
p3 ·

(v1,v2)∈CC

u∈U
xu,v1 · xu,v2+
(9e)
p4 ·

(v1,v2)∈CB
|U|

u=1
(xu,v1 −xu,v2)2 +
(9f)
p5 ·

(u,v)∈CCA
xu,v+
(9g)
p6 ·

(u,v)∈CBA
(xu,v −1)2+
(9h)
p7 ·

(u,f,gf )∈CMH


v∈V
bv,f,gf · xu,v −1 −s7
2
+
(9i)
p8 ·

(u,f,gf ,E)∈CNA


v∈V
bv,f,gf · xu,v + s8 −du · yu,f,gf
2
.
(9j)
Term (9a) and (9b) are the same as (7a) and (7b). p1 to p8 are penalty
coeﬃcients that are set to 10 ∗|F|. Terms (9c) to (9i) are the penalized terms of

Model-Based Approaches to MDWBM
433
constraints (7c) to (7i). Take (7c) and (9c) as an example; as we are minimizing
the overall objective function, we want (9c) to evaluate to 0 when constraint
(7c) is satisﬁed and to a non-zero value proportional to its violation when it is
not. In term (9i), s7 is the non-negative slack variable. The lower bound of s7 is
0 and the upper bound is |V | −1. Thus, we use binary variables z1, ..., z|V |−1 to
represent s7 in QUBO, i.e., s7 = z1 +· · ·+z|V |−1. Similarly, s8 = z1 +...+zdu−E
is the slack variable in term (9j) for not-alone constraints. Note that yu,f,gf is
the same indicator variable as in ACP.
5
Empirical Evaluation
In this section, we present our experimental results on standard and constrained
MDWBM with the commercial constraint programming solver CP Optimizer
(CPO) v20.1.0, the commercial mathematical programming solver Gurobi v9.5.0,
a multistart tabu search algorithm for QUBO [24], and a computer architecture
designed for QUBO: the Fujitsu Digital Annealer. CPO/Gurobi are the state-
of-the-art for general purpose constraint/mathematical programming. Though
the multistart tabu search was developed more than 10 years ago, according to
recent work, it is still one of the best metaheuristic approaches to QUBO [13].
We use the software-based implementation of the multi-start tabu search version
2 by D-Wave [11].
5.1
Fujitsu Digital Annealer
The Fujitsu Digital Annealer (DA) is a recent computer architecture designed for
solving QUBO problems [22]. The third generation DA (DA3), a hybrid system
of hardware and software, can represent QUBOs with up to 100000 variables. For
our DA environment,4 the integer coeﬃcients for the quadratic terms range from
−262 to 262 and those for the linear terms range from −273 to 273 [16]. The DA
algorithm is based on Simulated Annealing (SA), however it takes advantage
of the massive parallelization provided by the custom CMOS hardware. The
diﬀerence between the SA and DA algorithm are as follows:
– DA utilizes parallel tempering that runs a number of problem solving pro-
cesses (replicas) in parallel with diﬀerent temperatures [12]. Replicas swap
temperatures to diversify the search. In each replica, each Monte Carlo step
considers all possible one-bit ﬂips in parallel [4].
– DA employs a dynamic oﬀset to raise the energy of a state to escape local
minima.
– DA supports a dedicated bit ﬂip mechanism, over a subset of variables belong-
ing to one-hot equivalent constraints when using DA3.
– DA can deal with inequality constraints that are not modeled in QUBO. As
a consequence, the terms (9i) and (9j) are not included in the QUBO model
when using DA3. Instead, they are represented as the following constraints:
4 All experiments were conducted on the Digital Annealer environment prepared exclu-
sively for the research at the University of Toronto.

434
J. Zhang et al.
1 −

v∈V
bv,f,gf · xu,v ≤0, ∀(u, f, gf) ∈CMH.
(9i’)
E · yu,f,gf ≤

v∈V
bv,f,gf · xu,v ≤du · yu,f,gf , ∀(u, f, gf, E) ∈CNA.
(9j’)
In our experiments, we run the DA3 on a remote computer and do not include
the communication time in our runtime limits and results. The programs (for
running DA, CPO, Gurobi, and tabu search) are written in Python 3.7 and
conducted on a Window PC with Intel(R) Core(TM) i7-8700K CPU @3.20 GHz
with 16 GB RAM.
5.2
Experimental Setting
The proposed QUBO model is tested with three solvers (Gurobi, DA, and tabu
search), while the proposed CP and BQP models are tested with CPO and
Gurobi, respectively. The six model-solver combinations are each run for 600 s
for each instance.
Since the runtime limits are the same for the six approaches, we use the best
objective value, the time of ﬁnding the best objective, and the mean relative
error as performance measures. Denote by Bi,t,a the best solution attained by
runtime t of approach a for instance i. The relative error at time t for approach
a on instance i is given by
RE(i, t, a) = Bi,t,a −Bi
Bi
(11)
where Bi represents the best solution over all approaches at the end of runtime.
For a minimization problem, this expression is always non-negative. The mean
relative error of approach a at time t, MRE(t, a), can be computed as
MRE(t, a) = 1
|I|

i∈I
RE(i, t, a).
(12)
5.3
Experiments on Standard MDWBM
For standard MDWBM, we ﬁrst run the paper review [17] benchmark dataset
from UIUC [19] that were used by Ahmadi et al. It contains 73 papers accepted
by SIGIR 2007, 189 prospective reviewers, and 25 major topics. For each paper, a
25-dimensional label is provided based on its relevance to those topics. Similarly
for the 189 reviewers, a 25-dimensional expertise representation is provided.
Following Ahmadi et al., we ﬁrst use spectral clustering to divide reviewers
into ﬁve clusters based on their topic vectors. We treat the cluster label as the
ﬁrst feature. The assignment cost of a reviewer to a paper is calculated as the
relevance of each cluster for each paper. We take the average cosine similarity of
label vectors of reviewers in that cluster and the paper. The reviewer demand

Model-Based Approaches to MDWBM
435
of each paper is set to 4 (b = 4) and no reviewer is assigned to more than 1
paper. Again, following the methodology of Ahmadi et al., to increase the dataset
size and the feature number, we create a copy of each reviewer and invert the
gender in the copy. The gender is considered as the second feature. We set
λ0 = λ1 = λ2 = 1000 and round the assignment costs after multiplying by λ0 as
DA only supports integral coeﬃcients. The results are summarized in Table 1.
The number of bits is the number of xu,v variables in the QUBO model.
Table 1. Objective results of UIUC paper review instances.
Parameters
Exact methods
Non-exact methods
|U| |V |
|F| #bits ACP
SCP
GBQP
GBQB
DA3
TABU
3
378 2
1512
45911
45911
45911
45911
45911
45911
13
378 2
5292
201139
201139
201139
201139
201139
201139
23
378 2
9072
356652
356652
356652
357927
356652
356652
33
378 2
12852 512177
512177
512177
513621
512177
512177
43
378 2
16632 669264
669264
669264
676947
669264
MemOut
53
378 2
20412 824742
824742
824742
MemOut 824742
MemOut
63
378 2
24192 979525
979525
979525
MemOut 979525
MemOut
73
378 2
27972 1136424 1136424 1136424 MemOut 1136424 MemOut
GBQP and GBQB represent Gurobi with the BQP and QUBO models,
respectively. The results show that ACP, SCP, GBQP, and DA3 achieve the
same solutions, but none proves optimality for any instance. TABU ﬁnds the
same solutions for the ﬁrst four instances, but runs out of memory on larger
problems. GBQB is outperformed by all other approaches.
Fig. 2. MRE plot of UIUC paper review instances.
MRE comparisons are shown in Fig. 2. To avoid inﬁnite MREs, for instances
that induce a memory error, we use a simple heuristic to ﬁnd an initial solution

436
J. Zhang et al.
and use it for each time point during the generation of MRE plots. The heuristic
assigns reviewer {1, 2, 3, 4} to the ﬁrst paper, reviewer {5, 6, 7, 8} to the second
paper, and so forth. From the MRE plot we see that the non-exact methods,
TABU and DA3, reach solutions immediately and rarely improve the quality
after 10 s, though DA3 is much better than TABU. The exact methods gradually
increase their solution quality, with ACP, SCP, and GBQP eventually ﬁnding
the same solutions as DA3. The performance of GBQB, however, never surpasses
DA3 at 10 s. While we have shown that the two solution approaches of Ahmadi
et al. are incorrect in the online appendix, we note that that their reported
runtimes are up to 4 orders of magnitude longer than the runtime of DA3.
These numeric results, therefore lead to very diﬀerent conclusions w.r.t. solving
MDWBM problems in practice.
Table 2. MRE of randomly generated instances.
Parameters
Exact
Non-exact
ID
|U| |V |
|F|
#bits ACP
SCP
GBQP
GBQB DA3
TABU
1–5
25
100 10
2600
0.027 0.032 0.011
0.016
0.000 0.028
6–10
25
100 100 2600
0.030 0.035 0.006
0.008
0.000 0.014
11–15 50
200 10
10200 0.049 0.052 0.115
0.019
0.000 0.030
16–20 50
200 100 10200 0.073 0.065 MemOut 0.009
0.000 0.018
In the UIUC dataset, there are only two feature classes. In other application
contexts such as machine learning [15], the number of feature classes can be
very large. We hence uniformly randomly generated instances with more feature
classes [27]. The newly generated instances are of the sizes in terms of |V | × |U|:
{100×25, 200×50}, and the number of feature classes |F|: {10, 100}. The assign-
ment costs are uniformly distributed from 1 to 5. Each feature class randomly
has 2 to 10 diﬀerent values. Each node in U needs to have a degree of 4 (b = 4).
We generate 5 instances for each size and set λ0 = λ1 = . . . = λ|F | = 1. The
MRE results are shown in Table 2 and Fig. 3.
Fig. 3. MRE plot of randomly generated instances.

Model-Based Approaches to MDWBM
437
For the 20 randomly generated instances, DA3 remains the best solution app-
roach. Unlike for UIUC instances, DA3 gradually improves its solution quality,
though the improvement is small. For these instances, QUBO-based methods are
much better than CP/BQP-based methods, as Gurobi and CPO at 600s do not
produce a better solution than DA3/TABU/GBQB at 60s. CPO with both CP
models is worse than GBQP initially, but achieves better performance after 280s.
Also note that the performance of CP approaches degrades when the problem
size or the number of feature classes increases.
5.4
Experiments on Constrained MDWBM
In this section, we test constrained MDWBM. Focusing more on the constraints,
we consider the multi-class instances with IDs 1, 2, 6, and 7. Due to limited
paper space, we select four diﬀerent constraint patterns according to the number
of each type of constraints, as shown in Table 3.
Table 3. Number of constraints in diﬀerent patterns.
Constraint
Pattern C
B
CA BA MH NA
PT1
5
5
5
5
5
5
PT2
10 10 10
10
10
10
PT3
0
20 0
0
20
20
PT4
50 0
50
0
0
0
MDWBM with PT2 is more constrained than that with PT1. PT3 and PT4
are practically interesting constraint patterns. PT3 illustrates the situation that
nodes in V have binding preferences while nodes in U need to meet speciﬁc
requirements, while PT4 reﬂects the circumstances when there are only conﬂict
constraints. The constraints are randomly generated. The results of the con-
strained MDWBM are shown in Table 4 and Fig. 4.
Table 4. MRE of instances with constraints.
Constraint Exact
Non-exact
ID
Pattern
ACP
SCP
GBQP GBQB DA3
TABU
1,2,6,7 PT1
0.032 0.026 0.004
0.040
0.000 0.035
1,2,6,7 PT2
0.027 0.026 0.006
0.071
0.000 0.065
1,2,6,7 PT3
0.028 0.019 0.004
0.114
0.000 0.127
1,2,6,7 PT4
0.043 0.034 0.008
0.014
0.000 0.016

438
J. Zhang et al.
For constrained MDWBM, though DA3 with QUBO models is still the state-
of-the-art, CP/BQP-based methods perform better than other QUBO-based
methods. One of the reasons is that CP/BQP models can naturally deal with
constraints while QUBO has to convert constraints to penalty terms. Surpris-
ingly, though designed for constrained optimization, CP approaches are worse
than GBQP and DA3. We speculate that CPO might not deal with the six
types of constraints eﬃciently as they are not expressed in terms of global con-
straints with eﬀective ﬁltering algorithms. TABU and GBQB are worse than
DA3 by around 6%. Though TABU and GBQB improve the solution quality
during their runs, the solutions at 600s are still far from competitive.
Fig. 4. MRE plot of instances with constraints.
6
Conclusions
We have developed two constraint programming, a binary quadratic program-
ming, and a quadratic unconstrained binary optimization models for the multi-
attribute diverse weighted bipartite b-matching problem and introduced practi-
cal constraints into the models. Experiments on the standard and constrained
MDWBM show that novel hardware DA3 with the QUBO model has an advan-
tage over CP Optimizer with the CP models, Gurobi with the BQP and QUBO
models, and tabu search on the QUBO model. We have also identiﬁed ﬂaws in
existing approaches for standard MDWBM [1].
As traditional computers suﬀer from the end of Moore’s law, it is increas-
ingly important to understand how AI and OR problems can beneﬁt from novel
hardware and computation architectures. Our work has demonstrated that for
multi-attribute diverse weighted bipartite b-matching, state-of-the-art perfor-
mance can be delivered by such hardware using a natural model.

Model-Based Approaches to MDWBM
439
Acknowledgement. The authors would like to thank Fujitsu Ltd. and Fujitsu Con-
sulting (Canada) Inc. for providing ﬁnancial support and access to the Digital Annealer
at the University of Toronto. Partial funding for this work was provided by Fujitsu Ltd.
and the Natural Sciences and Engineering Research Council of Canada.
References
1. Ahmadi, S., Ahmed, F., Dickerson, J.P., Fuge, M., Khuller, S.: An algorithm for
multi-attribute diverse matching. In: Proceedings of the 29th International Joint
Conference on Artiﬁcial Intelligence (IJCAI), pp. 3–9. AAAI Press (2020)
2. Ahmed, F., Dickerson, J.P., Fuge, M.: Diverse weighted bipartite b-matching. In:
Proceedings of the 26th International Joint Conference on Artiﬁcial Intelligence
(IJCAI), pp. 35–41. AAAI Press (2017)
3. Aramon, M., Rosenberg, G., Valiante, E., Miyazawa, T., Tamura, H., Katzgraber,
H.G.: Physics-inspired optimization for quadratic unconstrained problems using a
digital annealer. Front. Phys. 7, 48 (2019)
4. Bagherbeik, M., Ashtari, P., Mousavi, S.F., Kanda, K., Tamura, H., Sheikholeslami,
A.: A permutational Boltzmann machine with parallel tempering for solving com-
binatorial optimization problems. In: B¨ack, T., Preuss, M., Deutz, A., Wang, H.,
Doerr, C., Emmerich, M., Trautmann, H. (eds.) PPSN 2020. LNCS, vol. 12269, pp.
317–331. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-58112-1 22
5. Benabbou, N., Chakraborty, M., Ho, X.V., Sliwinski, J., Zick, Y.: Diversity
constraints in public housing allocation. In: 17th International Conference on
Autonomous Agents and MultiAgent Systems, AAMAS 2018 (2018)
6. Bertsimas, D., Papalexopoulos, T., Trichakis, N., Wang, Y., Hirose, R., Vageﬁ,
P.A.: Balancing eﬃciency and fairness in liver transplant access: tradeoﬀcurves
for the assessment of organ distribution policies. Transplantation 104(5), 981–987
(2020)
7. Carbonell, J., Goldstein, J.: The use of MMR, diversity-based reranking for reorder-
ing documents and producing summaries. In: Proceedings of the 21st Annual Inter-
national ACM SIGIR Conference on Research and Development in Information
Retrieval, pp. 335–336 (1998)
8. Chen, C., Zheng, L., Srinivasan, V., Thomo, A., Wu, K., Sukow, A.: Conﬂict-aware
weighted bipartite b-matching and its application to e-commerce. IEEE Trans.
Knowl. Data Eng. 28(6), 1475–1488 (2016)
9. Coﬀrin, C., Nagarajan, H., Bent, R.: Evaluating ising processing units with integer
programming. In: Rousseau, L.-M., Stergiou, K. (eds.) CPAIOR 2019. LNCS, vol.
11494, pp. 163–181. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
19212-9 11
10. Cohen, E., Senderovich, A., Beck, J.C.: An ising framework for constrained clus-
tering on special purpose hardware. In: Hebrard, E., Musliu, N. (eds.) CPAIOR
2020. LNCS, vol. 12296, pp. 130–147. Springer, Cham (2020). https://doi.org/10.
1007/978-3-030-58942-4 9
11. D-Wave System Inc.: D-wave tabu (2021). https://docs.ocean.dwavesys.com/
projects/tabu/en/latest/, Accessed 21 July 2021
12. Dabiri, K., Malekmohammadi, M., Sheikholeslami, A., Tamura, H.: Replica
exchange MCMC hardware with automatic temperature selection and parallel trial.
IEEE Trans. Parallel Distrib. Syst. 31(7), 1681–1692 (2020)

440
J. Zhang et al.
13. Dunning, I., Gupta, S., Silberholz, J.: What works best when? A systematic evalu-
ation of heuristics for Max-Cut and QUBO. INFORMS J. Comput. 30(3), 608–624
(2018)
14. Fazliu, Z.L., Chiasserini, C.F., Malandrino, F., Nordio, A.: Graph-based model for
beam management in mmwave vehicular networks. In: Proceedings of the Twenty-
First International Symposium on Theory, Algorithmic Foundations, and Protocol
Design for Mobile Networks and Mobile Computing, pp. 363–367 (2020)
15. Fern, X.Z., Brodley, C.E., et al.: Cluster ensembles for high dimensional clustering:
an empirical study. Technical Report CS06-30-02, Oregon State University (2006)
16. Fujitsu Limited: The third generation of the digital annealer (2021). https://
www.fujitsu.com/jp/group/labs/en/documents/about/resources/tech/techintro/
3rd-g-da en.pdf, Accessed 20 Aug 2021
17. de Givry, S., Schiex, T., Schutt, A., Simonis, H.: Modelling the conference paper
assignment problem. In: 19th Workshop on Constraint Modeling and Reformula-
tion, ModRef-20 (2020)
18. Kadıo˘glu, S., Kleynhans, B., Wang, X.: Optimized item selection to boost explo-
ration for recommender systems. In: Stuckey, P.J. (ed.) CPAIOR 2021. LNCS, vol.
12735, pp. 427–445. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-
78230-6 27
19. Karimzadehgan, M., Zhai, C.: Constrained multi-aspect expertise matching for
committee review assignment. In: Proceedings of the 18th ACM conference on
Information and knowledge management, pp. 1697–1700 (2009)
20. Kochenberger, G., et al.: The unconstrained binary quadratic programming prob-
lem: a survey. J. Comb. Optim. 28(1), 58–81 (2014). https://doi.org/10.1007/
s10878-014-9734-0
21. Kulesza, A., Taskar, B.: Determinantal point processes for machine learning. arXiv
preprint arXiv:1207.6083 (2012)
22. Matsubara, S., et al.: Digital annealer for high-speed solving of combinatorial opti-
mization problems and its applications. In: 2020 25th Asia and South Paciﬁc Design
Automation Conference, ASP-DAC, pp. 667–672. IEEE (2020)
23. Mohseni, M., et al.: Commercialize quantum technologies in ﬁve years. Nature
News 543(7644), 171 (2017)
24. Palubeckis, G.: Multistart tabu search strategies for the unconstrained binary
quadratic optimization problem. Ann. Oper. Res. 131(1), 259–282 (2004)
25. Rosenberg, G., Haghnegahdar, P., Goddard, P., Carr, P., Wu, K., De Prado, M.L.:
Solving the optimal trading trajectory problem using a quantum annealer. IEEE
J. Sel. Top. Signal Process. 10(6), 1053–1060 (2016)
26. Tran, T.T., et al.: Explorations of quantum-classical approaches to scheduling a
mars lander activity problem. In: Workshops at the Thirtieth AAAI Conference
on Artiﬁcial Intelligence (2016)
27. Zhang, J., Lo Bianco, G., Beck, J.C.: MDWBM Instances (2021). https://github.
com/JasonZhangjc/mdwbm-instances, Accessed 11 Feb 2022

Author Index
Aïvodji, Ulrich
103
Armstrong, Eddie
1
Auricchio, Gennaro
14
Beck, J. Christopher
249, 424
Berden, Senne
64
Berthold, Timo
24
Bhavnani, Sidhant
34
Bierlee, Hendrik
44
Bleukx, Ignace
64
Boutilier, Justin J.
74
Coenen, Lize
64
De Filippo, Allegra
358
de Framond, Félix
390
de Givry, Simon
282
Decleyre, Nicholas
64
Dekker, Jip J.
44
Dilkina, Bistra
91
Ferber, Aaron
91
Ferrarini, Luca
14
Ferry, Julien
103
Gambs, Sébastien
103
Gange, Graeme
44
Garraffa, Michele
1
Geitz, Marc
120
Gromicho, Joaquim
190
Grozea, Cristian
120
Gualandi, Stefano
14
Guns, Tias
64
Hendel, Gregor
24
Hooker, J. N.
138
Huber, Marc
300
Huguet, Marie-José
103
Isoart, Nicolas
155
Jung, Victor
173, 266
Katsirelos, George
282
Koenig, Sven
232
Kool, Wouter
190
Kuˇcera, Petr
214
Kumar, T. K. Satish
232
Lallouet, Arnaud
390
Lanzarotto, Greta
14
Li, Ang
232
Lo Bianco, Giovanni
424
Lombardi, Michele
358
Luo, Yiqing L.
249
Malalel, Steve
266
Michini, Carla
74
Montalbano, Pierre
282
O’Sullivan, Barry
1
Oberweger, Fabio F.
300
Ouellet, Yanick
318
Pelleau, Marie
266
Pernazza, Ludovico
14
Pesant, Gilles
335
Petitet, Antoine
390
Puertas, Eloi
345
Pujol, Oriol
345
Quimper, Claude-Guy
318, 335
Raidl, Günther R.
300
Régin, Jean-Charles
155, 173, 266
Rey, Camilo
345
Riera, Carles
345
Rönnberg, Elina
300
Ruggeri, Federico
358
Salvagnin, Domenico
24
Schiendorfer, Alexander
34
Serra, Thiago
345
Siala, Mohamed
103

442
Author Index
Silvestri, Mattia
358
Simonis, Helmut
1
Song, Jialin
91
Steigerwald, Wolfgang
120
Stöhr, Robin
120
Stuckey, Peter
232
Stuckey, Peter J.
44, 374
Subramani, K.
408
Suijlen, Wijnand
390
Tack, Guido
44, 374
van Hoof, Herke
190
Velasquez, Alvaro
408
Verhaeghe, Hélène
335
Welling, Max
190
Wojciechowski, Piotr
408
Wolf, Armin
120
Yue, Yisong
91
Zhang, Jiachen
424
Zhou, Zachary
74

