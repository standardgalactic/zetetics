Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=ucha20
CHANCE
ISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/ucha20
Bernoulli’s Fallacy
Eric-Jan Wagenmakers
To cite this article: Eric-Jan Wagenmakers (2021) Bernoulli’s Fallacy, CHANCE, 34:4, 37-38, DOI:
10.1080/09332480.2021.2003642
To link to this article:  https://doi.org/10.1080/09332480.2021.2003642
Published online: 17 Nov 2021.
Submit your article to this journal 
Article views: 2855
View related articles 
View Crossmark data

CHANCE
37
Bernoulli’s Fallacy
Aubrey Clayton
Softcover: 360 pages
Publisher: Columbia  
University Press, 2021
ISBN: 978-0-231-19994-0
Reviewed by Eric-Jan Wagenmakers
If Ed Jaynes were to rise from the grave to lambast 
frequentist statistics one last time, Bernoulli’s Fallacy is 
the kind of book he would want to write. To say that 
the author does not pull any punches is an understate-
ment. The author is out for blood and does not hide it, 
as witness the first and last paragraphs of the preface:
“Since this book risks being accused of relitigating 
old arguments about statistics and science, let us first 
dispense with the idea that those arguments were 
ever settled. The “statistics wars” never ended; in 
some ways they have only just begun …”
Consider this, instead, a piece of wartime pro-
paganda, designed to be printed on leaflets and 
dropped from planes over enemy territory to win 
the hearts and minds of those who may as yet be 
uncommitted to one side or the other. My goal with 
this book is not to broker a peace treaty; my goal is 
to win the war. 
True to his mission statement, the author exposes 
and ridicules orthodox methods that form the bed-
rock of statistical practice among the empirical  
sciences. Committed frequentists may view Bernoul-
li’s Fallacy as slanderous. Statistical practitioners may 
doubt that the author could possibly be correct, given 
that frequentist statistics have dominated empirical 
practice for almost a century. However, as a Bayesian, 
I find myself in broad agreement with the author. 
The main premise of Bernoulli’s Fallacy is that 
sampling probabilities (i.e., aleatory probabilities: 
given the state of nature, what are the predicted data?) 
should not be confused with inferential probabilities 
(i.e., epistemic probabilities: Given the observed 
data, what is the probable state of nature?). The 
mistaken idea that sampling probabilities alone can 
address questions of inference is what the author calls  
“Bernoulli’s fallacy.” Throughout the book, the author 
demonstrates how tempting it is to confuse the two 
probabilities, how the seeds for this confusion were 
sown from the very beginning, and how the confusion 
is partly responsible for the recent replication crisis 
throughout the empirical disciplines.  
Bernoulli’s Fallacy takes the reader on a fascinating 
historical journey that spans about 300 years. Along 
the way, the author explains the nature of probability, 
Bayesian reasoning (with its “pathway probabilities”), 
the birth of frequentism, and more. The author is on 
a mission, and I find the book to be well-researched 
and extremely well-written.
In his unbridled enthusiasm, the author throws 
the kitchen sink at everything that looks like it might 
be frequentist (or may have frequentist friends). Not 
all complaints are equally compelling. For instance, 
the author dislikes null-hypothesis testing because, 
supposedly, the null is never exactly true. This is a 
popular critique that I find somewhat superficial;  
Jeffreys dealt with it already in the late 1930s. With-
out the null-hypothesis test, statistical practice would 
be at odds with common-sense scientific reasoning, 
where, in the words of Jeffreys, “the onus of proof 
is always on the advocate of the more complicated 
hypothesis.” The fact that the author is ill at ease 
with hypothesis testing is perhaps the price for being 
a Jaynesian rather than a Jeffrean (but see Hudson, 
2021, for a counterexample). 
The author emphasizes the fact that the frequentist 
founders Francis Galton, Karl Pearson, and Ronald 
Fisher were also fanatic eugenicists: “Racism, aris-
tocratic class panic, anti-Semitism, xenophobia, and 
ableism are all original sins of modern statistics. The 
real sins, though, were the greed for scientific authority 
supported by unassailably objective methods and the 
arrogance to believe such a thing could exist” (p. 177). 
According to the author, what started as an honest 
mistake—or perhaps even a correct Bayesian answer, 
under a vague prior—was elevated to statistical dogma 
to push the eugenics agenda on a general audience. 
This claim is as bold as it is speculative. 
An alternative perspective is that the frequency 
interpretation of probability (however flawed and 
limiting it may be upon closer inspection) does have 
considerable intuitive appeal. Frank Ramsey stated 
that “much the simplest and least controversial inter-
pretation of the calculus [of  probabilities] is one in 
terms of frequencies” (1926/1964, p. 63), and Jimmy 
Savage wrote that “[i]t is completely understandable 
that a frequentist concept of probability should have 
come to the fore” (1961, p. 575). Furthermore, in the 
pre-computer era, the frequentist methods were more 

VOL. 34.4, 2021
38
practical, and more effectively promoted, than their 
Bayesian counterparts.
I am also not certain about the extent to which 
the replication crisis is due to the use of the p-value. 
Although it is certainly a contributing factor, I 
personally believe the root cause is that the data 
analyst is usually fully invested in the outcome, and 
has every incentive imaginable to obtain the most 
flattering result. 
All in all, I believe a book as belligerent and 
instantly controversial as Bernoulli’s Fallacy deserves 
an appendix in which some of the claims are debated 
with other statisticians (cf. Berger & Wolpert, 1988).
My final misgiving is that the author occasionally 
gives Ed Jaynes a little too much credit. For instance, 
the notion that all probability statements are condi-
tional on prior knowledge is found in Keynes (1921), 
and both Jeffreys and Lindley consistently condi-
tioned on “H.” (for “history”) or “K” (for “knowledge”) 
before Jaynes. Similarly, the idea that Bayesian infer-
ence is a logic of partial beliefs predates Jaynes—it 
goes back at least to De Morgan (1847/2003), Ramsey 
(1926), and de Finetti (1974).
Despite these minor misgivings, this book comes 
highly recommended. Bernoulli’s Fallacy elegantly 
connects the past to the present in an attempt to 
dismantle the reigning statistical orthodoxy. Buy this 
book, and give it to your students so they may learn 
about Bayesian inference and the history of statistics; 
give it to your colleagues working in the empirical 
sciences so they will understand that the frequentist 
emperor is scantily dressed; give it to your frequentist 
friends as a provocation. Or read it yourself, so you will 
be prompted to think more deeply about the founda-
tions of statistical inference.   
Further Reading
Berger, J.O., and Wolpert, R.L. 1988. The Likelihood 
Principle (2nd ed.). Hayward, Institute of Math-
ematical Statistics.
de Finetti, B. 1974. Theory of Probability, Vol. 1 and 2. 
New York: John Wiley & Sons.
De Morgan, A. 1847, 2003. Formal Logic: The Calculus 
of Inference, Necessary and Probable. Honolulu: Uni-
versity Press of the Pacific.
Hudson, T.E. 2021. Bayesian Data Analysis for the 
Behavioral and Neural Sciences. Cambridge: Cam-
bridge University Press.
Keynes, J.M. 1921. A treatise on Probability. London: 
Macmillan & Co.
Ramsey, F.P. 1926. Truth and probability. Reprinted 
1964: Studies in Subjective Probability, Kyburg, Jr., 
H.E., and Smokler, H.E. (Eds.). New York: John 
Wiley & Sons. 63–92.
Savage, L.J. 1961. The foundations of statistics recon-
sidered. In Neyman, J. (Ed.). Proceedings of the 
Fourth Berkeley Symposium on Mathematical Statis-
tics and Probability, Vol. 1. Berkeley, CA: University 
of California Press. 575–585.
A History of Data 
Visualization and 
Graphic Communication
Michael Friendly and Howard Wainer
Publisher: Harvard  
University Press, 2021
Reviewed by Leland Wilkinson
Some statisticians think statistical graphics can be 
ignored; at most, they may give a cursory look at resid-
ual plots. Some computer scientists, even visualization 
experts, think statistical graphics were invented in the 
last few decades; judging by their citations, they seem 
to think they were devised mainly by computer sci-
entists. Both subgroups, and quite a few others, need 
to read Friendly and Wainer’s book carefully and pay 
attention to its premise. These authors have shown 
us that almost every graphic we use today has a long 
history and is an essential asset for data scientists. 
Much of the material in this book has been adapted 
from the numerous papers these authors have pub-
lished elsewhere, including some in CHANCE. Here 
they have woven them into a coherent story that 
conveys both the span of this particular history and 
its major themes—and because each author has edited 
the other’s contributions, the book has a single voice. 
Further, they have avoided the extremes of dry his-
toriography and fanciful storytelling. Their style is 
engaging throughout.

