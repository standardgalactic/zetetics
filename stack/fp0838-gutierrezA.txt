Cooperative Concurrent Games
Julian Gutierrez
University of Oxford
Oxford, UK
Julian.Gutierrez@cs.ox.ac.uk
Sarit Kraus
Bar-Ilan University
Ramat Gan, Israel
sarit@cs.biu.ac.il
Michael Wooldridge
University of Oxford
Oxford, UK
mjw@cs.ox.ac.uk
ABSTRACT
In rational verification, one is interested in understanding which
temporal logic properties will hold in a concurrent game, under the
assumption that players choose strategies that form an equilibrium.
Players are assumed to behave rationally in pursuit of individual
goals, typically specified as temporal logic formulae. To date, ratio-
nal verification has only been studied in noncooperative settings. In
this paper, we extend the rational verification framework to cooper-
ative games, in which players may form coalitions to collectively
achieve their goals. We base our study on the computational model
given by concurrent game structures and focus on the core as our
basic solution concept. We show the core of a concurrent game
can be logically characterised using ATL*, and study the computa-
tional complexity of key decision problems associated with the core,
which range from problems in PSPACE to problems in 3EXPTIME.
We also discuss a number of variants of the main definition of the
core, leading to the issue of credible coalition formations, and a
possible implementation of the main reasoning framework.
KEYWORDS
Concurrent Games; Cooperative Games; Logic; Formal Verification
ACM Reference Format:
Julian Gutierrez, Sarit Kraus, and Michael Wooldridge. 2019. Cooperative
Concurrent Games. In Proc. of the 18th International Conference on Au-
tonomous Agents and Multiagent Systems (AAMAS 2019), Montreal, Canada,
May 13–17, 2019, IFAAMAS, 9 pages.
1
INTRODUCTION
Concurrent games have become established as a key semantic model
for concurrent and multi-agent systems, in both the multi-agent
systems/AI community and the verification/computer science com-
munity [1, 13, 14, 29]. A concurrent game [1] is a finite-state envi-
ronment, populated by a collection of independent agents. A game
operates over an infinite sequence of rounds, where at each round,
each agent chooses an action to perform. Preferences in concur-
rent games are typically modelled by assuming that each agent is
associated with a temporal logic goal formula [8], which it desires
to see satisfied. The infinite plays generated by a game (modelling
the computation runs of a concurrent and multi-agent system) will
either satisfy or fail to satisfy each player’s goal, and since the
satisfaction of a player’s goal is dependent on the choices of other
players, then they must make choices strategically.
In all previous studies that we are aware of, concurrent games
are assumed to be noncooperative: players act alone, and binding
Proc. of the 18th International Conference on Autonomous Agents and Multiagent Sys-
tems (AAMAS 2019), E. Elkind, M. Veloso (eds.), May 13–17, 2019, Montreal, Canada.
© 2019 International Foundation for Autonomous Agents and Multiagent Systems
(www.ifaamas.org). All rights reserved.
agreements between players are assumed to be impossible. The so-
lution concepts used in previous studies of concurrent games have
therefore been noncooperative – primarily Nash equilibrium and re-
finements thereof. In such a noncooperative setting, the basic ques-
tions that we ask of a concurrent game are, for example, whether
a particular temporal logic property holds in some computation
of the system that could arise through players selecting strategies
that form a Nash equilibrium (the E-Nash problem) or whether
a property holds on all such computations (A-Nash) [13, 14, 29].
These problems can be understood as game-theoretic counterparts
of the conventional model checking problem [7]. The complexity
of decision problems surrounding such problems in concurrent
games modelling the behaviour of multi-agent systems have been
extensively studied, and software tools are available that support
the analysis of concurrent games using these concepts [3, 15, 19].
The aim of the present paper is to extend the study of concur-
rent games to include cooperative solution concepts [20, 23]. Thus,
we assume there is some (exogenous) mechanism through which
players in a concurrent game can reach binding agreements and
form coalitions in order to collectively achieve goals (although
we emphasise that the nature of such a mechanism is beyond the
scope of the present work). The possibility of binding cooperation
and coalition formation eliminates some undesirable equilibria that
arise in noncooperative settings, and makes available a range of
outcomes that cannot be achieved without cooperation. We focus
on the core as our key solution concept. The basic idea behind the
core is that a game outcome is said to be core-stable if no subset
of players could benefit by collectively deviating from it; the core
of a game is the set of core-stable outcomes. Now, in conventional
cooperative games (characteristic function games with transferable
utility [4]), this intuition can be given a simple and natural for-
mal definition, and as a consequence the core is probably the most
widely-studied solution concept for cooperative games. However,
the conventional definition of the core does not naturally map into
our concurrent game setting, because in such games, coalitions are
subject to externalities: whether or not a coalition has a beneficial
deviation depends not just on the makeup of that coalition, but on
the behaviour of the remaining players in the game too.
We begin by introducing the framework of concurrent games,
and then proceed to define two variations of the core for such
settings. In the first, a coalition of players are assumed to have a
beneficial deviation if they have some course of action available to
them which they would benefit from no matter what the remaining
players did. This “worst case” analysis is easily defined, but requires
a deviation to be beneficial against all courses of action by the
remaining players – even those that the remaining agents would not
rationally choose (cf., the concept of the α-core in the game theory
literature). This motivates a second definition, where a deviation
is only required to be beneficial against all courses of action by

remaining players that are credible, in the sense that they would be
no worse off than they were originally. In each case, we formally
define the solution concept, identify some of its key computational
properties, give logical characterisations, and where possible also
complexity results, which range from properties that can be checked
in PSPACE to properties that can be checked in 3EXPTIME. We also
study model theoretic properties related to the core: in particular,
whether it is never empty in the model of games we consider, and
whether temporal logic properties hold across bisimilar systems
over plays (computation runs) induced by elements in the core, a
desirable property from a formal verification viewpoint.
Structure of the paper. The rest of this paper is organised as
follows. In Section 2 we provide necessary background on logic
and games and in Section 3 we define the core and the main compu-
tational properties associated with it. In Section 4 we present our
main results and in Section 5 we study the issue of credible coalition
formations, with associated complexity results. Then, in Section 6
we present some concluding remarks and related work, along with
a discussion about different issues related to the core, including its
implementation in practice using model checking techniques.
2
PRELIMINARIES
Given any set S = {s,q,r, . . .}, we use S∗, Sω, and S+ for, respec-
tively, the sets of finite, infinite, and non-empty finite sequences
of elements in S. If w1 = s′s′′ . . .sk ∈S∗and w2 is any other
(finite or infinite) sequence, we write w1w2 for their concatena-
tion s′s′′ . . .skw2. For Q ⊆S, we write S−Q for S \ Q and S−i if
Q = {i}. We extend this notation to tuples u = (s1, . . . ,sk, . . . ,sn)
in S1 × · · · × Sn, and write u−k for (s1, . . . ,sk−1,sk+1, . . . ,sn), and
similarly for sets of elements, that is, by u−Q we mean u without
each sk, for k ∈Q. Given a sequence w, we write w[t] for the
element in position t + 1 in the sequence; for instance, w[0] is
the first element of w. We also write w[l . . .m] for the sequence
w[l] . . .w[m], and w[l . . .m) for w[l] . . .w[m −1]; if m = 0, we
let w[l . . .m) be the empty sequence, denoted ϵ.
Games. Let Ag = {1, . . . ,n} be a set of players and St a set of
states. For each player i ∈Ag we have a set of actions Aci and
with every state s and player i we associate a subset Aci(s) ⊆Aci
of actions that i can perform at s. We write Ac for Ð
i ∈Ag Aci and
assume that the sets Aci form a partition of Ac. We call a profile
of actions (a1, . . . ,an) ∈Ac1 × · · · × Acn a direction, and denote
it by d. We let D be the set of directions—also called decisions—
with respect to Ac, and write di for the ai of d that is in Aci. The
dynamics of a game are modelled via a (deterministic) transition
function δ : St × Ac1 × · · · × Acn →St, which indicates how the
system behaves when d = (a1, . . . ,an) is performed at a state s. A
state s′ is accessible from another state s whenever there is somed =
(a1, . . . ,an) such that δ(s,a1, . . . ,an) = s′. A run is an infinite
sequence ρ = s0s1s2 . . . such that for every t ≥0 we have that st+1
is accessible from st . The set of runs is denoted by R. By a (finite)
history we mean a finite sequence π = s0s1s2 . . .sk of accessible
states. By prefix(ρ) we denote the set of finite prefixes of ρ, i.e.,
prefix(ρ) = {π ∈St∗: ρ = πρ′ for some ρ′ ∈Stω }. Given π ∈
St+, by last(π) we denote the last state in π, i.e., if π = π ′s, then
last(π) = s. By s0 ∈St we denote the initial state associated with St.
A strategy for a player i is a function fi : St+ →Aci such that
fi(πs) ∈Aci(s) for every π ∈St∗and s ∈St. That is, a strategy for
a player i specifies for every finite history π an action available
to i in last(π). The set of strategies for player i is denoted by Fi. A
strategy profile is a tuple ®f = (f1, . . . , fn) in F1 × · · · × Fn. Observe
that given a states and a transition functionδ : St×Ac1×· · ·×Acn →
St, each strategy profile ®f defines a unique run ρ where ρ[0] = s and
ρ[t + 1] = δ(ρ[t], f1(ρ[0 . . .t]), . . . , fn(ρ[0 . . .t])), for all t ≥0. We
write ρ( ®f ,s) for such a run, and simply ρ( ®f ) if s = s0. Furthermore,
each player i has an associated dichotomous preference relation
over runs, which is modelled as a subset Γi of the set of runs R.
Intuitively, a player i strictly prefers all runs in Γi to those that are
not in Γi and is indifferent otherwise. Thus, Γi represents the goal
of player i. Below, we will use formulae of temporal logic to specific
player’s goals. We write ρ ≿i ρ′ to indicate that player i weakly
prefers run ρ to ρ′ and ρ ≻i ρ′ for playeri strictly preferring ρ to ρ′,
i.e., if ρ ≿i ρ′ but not ρ′ ≿i ρ. A game is played by each player i
selecting a strategy fi with the aim that the induced run ρ( ®f )
belongs to its goal set Γi. If ρ( ®f ) ∈Γi we say that i has its goal
satisfied. Otherwise, we say that i does not have its goal satisfied.
Logics. Alternating-time Temporal Logic (ATL∗[1]) is an exten-
sion of CTL∗[9], a branching-time temporal logic, that allows for
reasoning about games and strategies. More specifically, given a
set of atomic propositions AP and a set of agents Ag, the language
of ATL∗formulae is given by the following grammar:
ϕ
::=
p | ¬ϕ | ϕ ∨ϕ | Xϕ | ϕ Uϕ | ⟨⟨C⟩⟩ϕ
such that p ∈AP and C ⊆Ag, and the formulae X and U are in the
scope of ⟨⟨C⟩⟩, that is, are subformulae of a ⟨⟨C⟩⟩-formula. We use
the following abbreviations: we write ⊤for p ∨¬p, ⊥for ¬⊤, Fϕ
for ⊤Uϕ, Gϕ for ¬ F ¬ϕ, Eϕ for ⟨⟨Ag⟩⟩ϕ, Aϕ for ⟨⟨∅⟩⟩ϕ, and [[C]]ϕ
for ¬ ⟨⟨C⟩⟩¬ϕ; we also use the conventional abbreviations for other
classical propositional logic operators. We write ϕ ∈L(AP, Ag)
if ϕ is an ATL∗formula in this language. When either AP or Ag,
or both, are known, we may omit them. With AP′ ⊆AP, we may
write ϕ|AP′ if ϕ ∈L(AP′, Ag) for some set of agents Ag.
The semantics of ATL∗formulae are given by concurrent game
structures [1]. A concurrent game structure, M, is given by a tu-
ple M = (AP, Ag, Ac, St,s0, λ,δ), where λ : St →2AP is a labelling
function, and all other components of M are as defined before. The
size of M is defined to be |St| × |Ac||Ag|.
We write R∗s and Rωs for, respectively, the finite and infinite runs
of M that start at state s. We simply write R∗and Rω if s = s0.
Moreover, we will write ®fC for (fi, . . . , fk), with C = {i, . . . ,k} ⊆
Ag, that is, a joint strategy for the players in C. Similarly, we will
write ®д−C for a joint strategy for the players in Ag−C. For simplicity,
we will assume that all strategies are defined on all finite runs of M,
and hence at all states. We define the set of ®fC-runs from state s to
be {ρ′ ∈Rωs : ρ′ = ρ( ®fC(s), ®д−C(s)) for some ®д−C for Ag−C }.
We can now define the semantics of ATL∗formulae based on the
rules given below. Let M be a concurrent game structure, ρ ∈Rω
be an infinite run, and t ∈N be a temporal index. The semantics of
ATL∗formulae is defined by the following rules:

ρ,t |=M p
iff
p ∈λ(ρ[t])
ρ,t |=M ¬ϕ
iff
ρ,t |=M ϕ does not hold
ρ,t |=M ϕ ∨ϕ′
iff
ρ,t |=M ϕ or ρ,t, π |=M ϕ′
ρ,t |=M Xϕ
iff
ρ,t + 1 |=M ϕ
ρ,t |=M ϕ Uϕ′
iff
ρ,t ′ |=M ϕ′ , for some t ′ ≥t, and
ρ,k |=M ϕ , for all t ≤k < t ′
ρ,t |=M ⟨⟨C⟩⟩ϕ
iff
there is some ®fC such that
for all ®fC-runs ρ′ from state ρ[t],
it is the case that ρ′, 0 |=M ϕ holds.
We say that M is a model of ϕ (commonly written as M |= ϕ) if
ρ, 0 |=M ϕ for all ρ ∈Rω such that ρ[0] = s0. We also say that ϕ is
satisfiable if M |= ϕ for some CGS M. Moreover, we say that ϕ is
equivalent to ϕ′ if M |= ϕ ⇐⇒M |= ϕ′ for all M, and define the
size of ϕ as its number of subformulae. Finally, we define LTL as
the sublogic of ATL∗given by all formulae Aϕ, where formula ϕ
does not contain the “coalition” quantifiers ⟨⟨C⟩⟩or [[C]].
LTL Concurrent Games. An LTL concurrent game is given by
a tuple G = (M,γ1, . . . ,γn), such that M is a concurrent game
structure where Ag = {1, . . . ,n} in which γi, with i ∈Ag, is the
LTL goal of player i that defines i’s preference relation over runs.
Such a set of runs, for each player i, is defined as follows:
Γi = {ρ ∈Rω | ρ, 0 |=M γi }.
An outcome ofG is a strategy profile ®f = (f1, . . . , fn) in F1×· · ·×Fn
for the set of all agents (the grand coalition). In an LTL concurrent
game (an LTL game hereafter) we can identify a set of “winners”
and a set of “losers” for each outcome ®f . LetW ( ®f ) denote the set of
players that would get their goal achieved if the outcome ®f resulted
(the “winners”) and let L( ®f ) denote the set of players that not:
W ( ®f )
=
{i ∈Ag | ρ( ®f ) |= γi }
L( ®f )
=
Ag \W ( ®f ).
Before proceeding, it is useful to define the noncooperative solution
concept of Nash equilibrium with respect to LTL concurrent games.
An outcome ®f is said to be a Nash equilibrium if there is no player
i ∈Ag and strategy f ′
i for i such that i ∈L( ®f ) and i ∈W ( ®f−i, f ′
i ).
That is, ®f is a Nash equilibrium if no player can benefit by uni-
laterally changing its strategy component of ®f . Let NE(G) denote
the Nash equilibria of G. We emphasise that Nash equilibrium only
considers unilateral deviations, i.e., deviations by individual play-
ers. Our aim in what follows is to consider deviations that admit
coalitions of players, in a cooperative setting.1
3
COOPERATIVE RATIONAL VERIFICATION
Defining the Core. We want to define counterparts of the ratio-
nal verification problems E-Nash and A-Nash, as studied in [13, 14],
but for cooperative settings. For this, we need a version of the core
for our cooperative game settings. The core is probably the best-
known solution concept in cooperative game theory. Like Nash
equilibrium in the noncooperative setting, the core defines a notion
of stability for games, but whereas Nash equilibrium only requires
that an outcome is stable in the sense that it admits no individual
beneficial deviations, the core requires that an outcome admits no
1We recall that the concept strong Nash equilibrium also admits deviations by groups
of players, but in a noncooperative setting.
beneficial deviations by coalitions. In the “standard” model of coop-
erative games, this intuition is easily formalised, but in concurrent
games, there is an important difficulty. Suppose a coalition of play-
ers C∗⊆Ag are contemplating an outcome ®f , and in particular,
are attempting to determine whether they have a cooperative bene-
ficial deviation from ®f . Now, as they consider possible beneficial
deviations – collective strategies ®fC∗– what assumptions should
C∗make about the behaviour of the remaining players Ag \ C∗? In
particular, assuming that the remaining players will not alter their
strategy is implausible in a cooperative setting:2 rational players
who can cooperate will respond to the deviation rationally and in a
cooperative way against the players in C∗. And, crucially, whether
or not C∗’s putative deviation is in fact beneficial may well depend
upon the behaviour of the remaining players. In game theoretic
terms, our concurrent game setting is subject to externalities: the
performance of the coalition C∗depends not just on the coalition
C∗, but on the behaviour of the remaining players.
It is well-known that cooperative solution concepts are difficult
to define in the presence of externalities [4]. In particular, there
is no universally accepted definition of the core for games with
externalities. Our first definition of the core for concurrent games,
therefore, captures worst case reasoning. Thus, when coalition C is
contemplating a deviation, it requires that this deviation will be ben-
eficial no matter what the remaining players do. This idea has been
explored in the concept of the α-core in cooperative games [28]. To
make this idea formal, we need to define the notion of a deviation
and a beneficial deviation. A deviation is a joint strategy ®fC∗for the
set of players C∗⊆Ag, with C∗, ∅. Where ®f is an outcome, we
say ®f ′C∗is a beneficial deviation from ®f if:
(1) C∗⊆L( ®f )
(2) For all ®f ′−C∗, we have C∗⊆W (( ®f ′C∗, ®f ′−C∗)).
In other words, ®f ′C∗is said to be a beneficial deviation from ®f if the
players in C∗would be better off choosing strategies ®f ′C∗, rather
than their part of ®f , no matter what strategies the players outside
C∗chose. The core of a game G, denoted core(G), is then defined to
be the set of outcomes of G that admit no beneficial deviation.
Example 3.1. Consider the following game, which contains a
poor quality Nash equilibrium that is not in the core: the ability to
cooperate makes it possible for agents to avoid the undesirable equi-
librium. The game contains two players, Ag = {1, 2} and two vari-
ables AP = {p,q}, with player 1’s action set being Ac1 = {pt,pf }
and player 2’s action set being Ac2 = {qt,qf }, satisfying that, for
every reachable state, if player 1/2 plays pt/qt then p/q will hold,
and will not hold if pf /qf is played instead (i.e., player 1 “controls”
the value of p and player 2 the value of q). Their goals are identical
(and so the game is a coordination game): γ1 = γ2 = G(p ∧q).
Now, consider the strategy profile ®f in which both players sim-
ply fix their respective variables to be false forever (i.e., play pf
and qf forever). Neither player will have their goal achieved by
such a strategy profile. However, the strategy profile forms a Nash
equilibrium, because unilateral deviation cannot improve the situa-
tion: neither player has an alternative strategy which would make
2This is the kind of behaviour that one has to assume to define strong Nash equilibrium,
a noncooperative solution concept.

them better off. In fact, there are infinitely many such poor quality
Nash equilibria in this game, where neither player gets their goal
achieved. However, this strategy profile is not in the core, because
there is a cooperative beneficial deviation to the strategy profile in
which both players fix their variables to be true forever (i.e., play
pt and qt forever). And, in fact, in every core-stable outcome, both
players get their goal achieved. Thus, using the core instead of
Nash equilibrium eliminates poor quality equilibria from the game,
leading to socially more desirable outcomes.
Decision Problems. In Rational Verification [13, 14, 29] we are
mainly interested in checking which temporal logic properties a
game satisfies by its stable outcomes. Typically, in the noncoopera-
tive setting, such outcomes have been characterised by the set of
Nash equilibria NE(G) of the game G. In the cooperative setting,
as introduced here, such outcomes are characterised, instead, by
the set of outcomes in the core of the game, that is, by the strategy
profiles in core(G). The two main decision problems in rational
verification are checking whether a temporal logic formula is satis-
fied by some/every stable outcome of the game. For the core, these
problems are defined as follows—cf. [13, 14, 29].
E-CORE:
Given: Game G, LTL formula ϕ.
Question: Does ∃®f ∈core(G). ρ( ®f ) |= ϕ hold?
A-CORE:
Given: Game G, LTL formula ϕ.
Question: Does ∀®f ∈core(G). ρ( ®f ) |= ϕ hold?
In addition to the two above decision problems, the third main
decision problem in rational verification is checking whether, given
a game G, its set of stable outcomes—the core of G in this case—is
non-empty. As will be shown in the next sections, in our setting,
the core of every game G is never empty, a desirable game-theoretic
property as it ensures the existence of stable outcomes for every
game, making them rationally implementable in practice.
We will also be interested in two decision problems specifically
related with the nature core-stable outcomes (that is, of outcomes in
the core of a game), namely, checking whether a given outcome—
a strategy profile for the grand coalition—is in the core (CORE
Membership), and checking whether a given deviation is beneficial
with respect to a given outcome of a game (Beneficial Deviation).
These two decision problems are formally defined as follows.
CORE Membership:
Given: Game G, outcome ®f .
Question: Is it the case that ®f ∈core(G)?
Beneficial Deviation:
Given: Game G, outcome ®f , deviation ®f ′C∗.
Question: Is ®f ′C∗a beneficial deviation from ®f ?
One might think that every coalition that has a beneficial devia-
tion from some outcome of the game will get their goals achieved in
a core-stable outcome, but that actually is not the case. To formalise
this idea, let us introduce the concept of fulfilled coalition. We say
that a coalition of players is fulfilled if they are able to achieve their
goals irrespective of what other players do. Formally, we say that
a coalition of players C is fulfilled if there is a joint strategy ®fC
for C ⊆Ag such that for all joint strategies ®f−C for Ag \C we have
ρ(( ®fC, ®f−C)) |=
Û
i ∈C
γi .
In other words, a fulfilled coalition has a winning strategy to col-
lectively achieve their goals. Since we are considering cooperative
games, the issue/question is whether such a coalition will form.
Using the above definition, we can make some useful observations
about (fulfilled) coalitions and core-stable outcomes. These observa-
tions are formally presented in the following lemma, which relates
winning strategies and the core in a critical way.
Lemma 3.2 (coalitions).
(1) There are games G, with outcomes ®f ∈core(G), containing
fulfilled coalitions C ⊆Ag such that C ⊈W ( ®f ).
(2) For every game G, outcome ®f ∈core(G), and fulfilled coali-
tion C, we have that C ∩W ( ®f ) , ∅.
(3) For every game G and fulfilled coalitionC, if core(G) , ∅, then
there is ®f ∈core(G) such that C ⊆W ( ®f ).
Informally, the first part of the lemma says that the fact that
a coalition is fulfilled does not mean that every player in such a
coalition is guaranteed to get its goal achieved in an arbitrary core-
stable outcome. The second part of the lemma says that, however, in
any core-stable outcome, some members of every fulfilled coalition
must get their goals achieved. And, the third part of the lemma
says that for every fulfilled coalition the core contains a core-stable
outcome in which every member of this coalition gets its goal
achieved. Because fulfilled coalitions can help us understand the
coalition formation power in a game, we will also be interested in
the following decision problem about coalitions.
Fulfilled Coalition:
Given: Game G, coalition C ⊆Ag.
Question: Is C a fulfilled coalition of G?
In the next section, we will investigate the decision problems
defined here as well as some model-theoretic properties of the core.
4
REASONING ABOUT THE CORE
In this section we will study the computational complexity of the
decision problems defined in the previous section, and will show
some other properties of the core of an LTL game, in particular,
that such a set is never empty and that the satisfaction of an LTL
property on some/every outcome in the core is a bisimulation-
invariant property [16]. These two results sharply contrast with the
Rational Verification problem for noncooperative games in which,
with respect to stable outcomes given by the set of Nash equilibria
of a game (also given by strategy profiles for Ag), neither such a
set of stable outcomes is guaranteed to always be non-empty [13]
nor bisimulation-invariance holds in the general case [12].
The first decision problem we will consider in this section is
Fulfilled Coalition, which we solve in the general case through
a logical characterisation using ATL∗.
Theorem 4.1. Fulfilled Coalition is PSPACE-complete for one-
player games, and it is 2EXPTIME-complete for games with more than
one player.

Proof. For membership we observe that given a game G =
(M,γ1, . . . ,γn) and a coalition C ⊆Ag, it is the case that C is
fulfilled if and only if M |= ⟨⟨C⟩⟩Ó
i ∈C γi holds [1]. Since such a
formula can be model checked in PSPACE if Ag is a singleton set and
in 2EXPTIME if |C| > 1, then the two upper bounds immediately
follow. For the lower bounds, we can reduce the problem of checking
for the existence of a winning strategy in a two-player game with
LTL goals as defined in [2] for 2EXPTIME-hardness and existential
LTL model checking for PSPACE-hardness [27].
□
Fulfilled coalitions give an indication of which stable coalitions
may form, but are insufficient to characterise the core, and therefore,
to check E-CORE and A-CORE properties of a multi-agent system.
To do this, we follow a different strategy and show that these two
decision problems are, in general, also 2EXPTIME-complete.
Theorem 4.2. E-CORE and A-CORE are PSPACE-complete for
one-player games and 2EXPTIME-complete for games with more than
one player.
Proof. Let us consider E-CORE first. For membership we ob-
serve that given a game G = (M,γ1, . . . ,γn) and an LTL formula ϕ,
it is the case that (G,ϕ) ∈E-CORE if and only if M |= ϕE-CORE(G,ϕ)
holds, such that ϕE-CORE(G,ϕ) is the following ATL∗formula:
Ü
W ⊆Ag
  ⟨⟨Ag⟩⟩(ϕ ∧
Û
i ∈W
γi ∧
Û
j ∈Ag\W
¬γj) ∧
Û
L⊆Ag\W
[[L]]
Ü
j ∈L
¬γj

which states that there is a path in M that satisfies ϕ and the goals
of a set of players W (the “winners”) – subformula ⟨⟨Ag⟩⟩(ϕ ∧
Ó
i ∈W γi ∧Ó
j ∈Ag\W ¬γj)∧... – and that for every subset of players
L that do not get their goals achieved in such a path (the “losers”),
it is not the case that those players have a beneficial deviation from
the path – subformula ⟨⟨Ag⟩⟩(...) ∧Ó
L⊆Ag\W [[L]] Ô
j ∈L ¬γj. As in
the case of fulfilled coalitions, when Ag is a singleton set, the ques-
tion becomes an LTL model checking problem, which can be solved
in PSPACE, and otherwise it is an ATL∗model checking problem,
which can be solved in 2EXPTIME, with the representation size of
the game being exponential in the number of agents. For the lower
bounds, it is sufficient to show that (G,ϕ) ∈E-CORE if and only
if (G, {1}) ∈Fulfilled Coalition, whenever γ1 = ϕ and γj = ¬ϕ,
for every j ∈Ag\ {1}, which can be proved using Lemma 3.2. Since
this is true even if Ag is a singleton set, both lower bounds follow
from Theorem 4.1, that is, PSPACE-hardness in case of one-player
games, and 2EXPTIME-hardness even for two-player games.
Finally, for A-CORE, we observe that (G,ϕ) < A-CORE if and
only if (G, ¬ϕ) ∈E-CORE. Since both PSPACE and 2EXPTIME are
deterministic complexity classes, we can conclude that A-CORE is
PSPACE-complete if |Ag| = 1 and 2EXPTIME-complete if |Ag| > 1,
as it is for E-CORE.
□
We now study CORE Membership and Beneficial Deviation.
For these two problems we first need to define how we will represent
outcomes, as at present they are defined as infinite-state objects
that map finite histories to players’ actions. Following standard
practice in the concurrent games literature, we model strategies
as finite state machines with output (transducers) [13, 14]. Note
that, for players with LTL goals, such strategies are sufficient: no
more powerful model of strategies is necessary [13, 14]. Formally,
a strategy for player i is a structure σi = (Qi,q0
i ,ιi,υi), where
• Qi is a finite and non-empty set of strategy states,
• q0
i ∈Qi is the initial strategy state,
• ιi : Qi × St →Qi is a transition function, and
• υi : Qi →Aci is an output function, which satisfies that, for
all (q,s,q′) ∈ιi, we have υi(q) ∈Aci(s).
With this definition in place, we can now establish the complexity
of CORE Membership and Beneficial Deviation. Formally, we
have the following result.
Theorem 4.3. CORE Membership is PSPACE-complete for one-
player games and 2EXPTIME-complete for games with more than one
player.
Proof. For membership we first compute the winners and losers
with respect to ®σ = (σ1, . . . ,σn), the outcome of the game. This
can be done in PSPACE (it is equivalent to LTL model checking
over a “product automata” or “concurrent program” [18]). Once we
have computed W , we can check, for every L ⊆Ag \W , whether L
has a beneficial deviation. This is true if and only if L is a fulfilled
coalition. Because this can be checked in PSPACE for one-player
games and in 2EXPTIME for games with more than one player,
the two upper bounds immediately follow. For the lower bounds,
we use Lemma 3.2 and Theorem 4.1 again. Consider the following
game. Let ϕ be a satisfiable LTL formula and ®σ an outcome that
does not satisfy ϕ. Then, (G, ®σ) ∈CORE Membership if and only
if (G, {1}) < Fulfilled Coalition, whenever γ1 = ϕ and γj = ¬ϕ,
for every player j ∈Ag \ {1}.
□
Let us now consider Beneficial Deviation. This is the only
“easy” problem for multi-player games, as it can be solved in PSPACE.
To show this, we again need to find a different proof strategy. Con-
sider any input instance (G, ®σ, ®σ ′
C∗) of the problem. We observe
that, because ®σ ′
C∗is fixed, we can make it part of the arena where
the game is played, and then check if players not in C∗have a joint
strategy for Ô
j ∈C∗¬γj. Due to the definition of beneficial deviation,
we also need to check if ρ(®σ) |= Ó
j ∈C∗¬γj holds or not.
In other words, the reason why this problem can be solved in
PSPACE for multi-player games, unlike all other decision problems
we have studied so far (which, in general, can be solved in doubly
exponential time), is that this decision problem can be reduced to
a one-player game (given by coalition Ag \ C∗) with an LTL goal
(given by γAg\C∗= Ô
j ∈C∗¬γj) over a “product arena” (denoted
by MC∗) built from a concurrent game structure M and the joint
strategy ®f ′C∗that we want to check.
Theorem 4.4. Beneficial Deviation is PSPACE-complete, even
for one-player games.
Proof. Checking that ρ(®σ) |= Ó
j ∈C∗¬γj holds can be done in
PSPACE. Again, this is equivalent to model checking LTL formulae
over a “product automata” or “concurrent program” [18]). If the
statement does not hold, then, by definition, ®σ ′
C∗is not a beneficial
deviation, as at least one player in C∗already has its goal satisfied
by ®σ. If the statement holds, then we check that ρ( ®f ′
−C∗, ®σ ′
C∗) |=
Ó
j ∈C∗γj holds, for all joint strategies ®f ′
−C∗for players not inC∗. We
do this in PSPACE by checking whether it is not the case that MC∗|=
Ô
j ∈C∗¬γj holds, where MC∗= (AP′, Ag′, Ac′, St′,s0′, λ′,δ ′) is the
“concurrent program” or “product automata” defined as follows:

• AP′ = AP, Ag′ = {0}, Ac′ = Πi ∈Ag\C∗Aci;
• St′ = St × Πj ∈C∗Qj;
• s0′ = (s0,q0x, . . . ,q0y), such that σz = (Qz,q0z,ιz,υz), ®σ ′
C∗=
(σx, . . . ,σy), and z ∈{x, . . . ,y};
• λ′(s,qx, . . . ,qy) = λ(s); and
• δ ′((s,qx, . . . ,qy), (a, . . . ,b)) = (s′,q′x, . . . ,q′y) such that
– s′ = δ(s,υ(qx), . . . ,υ(qy),a, . . . ,b), and
– q′z = ι(qz,s), with z ∈{x, . . . ,y}.
In other words, MC∗transitions just like M save that it is restricted
to the behaviour already defined by ®σ ′
C∗.
For the lower bound we use LTL model checking.
□
In addition to the above complexity results, we also have two
model-theoretic results, one ensuring that the core is never empty
and another one stating that checking whether an LTL formula is
satisfied by some outcome in the core is a bisimulation-invariant
property.3 The latter result is easy, and follows directly from the
membership proof of E-CORE.
Corollary 4.5. Let G = (M,γ1, . . . ,γn) be a game, ϕ be an LTL
formula, and M′ be a concurrent game structure that is bisimilar to
M. Then, (G,ϕ) ∈E-CORE if and only if (G′,ϕ) ∈E-CORE, where
G′ = (M′,γ1, . . . ,γn).
Proof. Because ATL∗is a bisimulation-invariant temporal logic,
and the core can be characterised in ATL∗using ϕE-CORE, as de-
fined in the membership proof of E-CORE. More specifically, it
follows from the fact that M |= ϕE-CORE(G,ϕ) if and only if M′ |=
ϕE-CORE(G′,ϕ).
□
To finish this section, we show an important property of the
core, namely, that it is never empty.
Theorem 4.6. core(G) , ∅, for every game G.
Proof. Take any run ρ in the game G = (M,γ1, . . . ,γn). Ei-
ther ρ, 0 |=M
Ó
i ∈Ag γi holds or not. If the former, then the core
is not empty: every outcome ®f such that ρ = ρ( ®f ) is in the core.
If the latter, then there is a set of players L1 that do not get their
goals achieved in ρ. If no subset of L1 is fulfilled, then, again, ev-
ery outcome ®f such that ρ = ρ( ®f ) is in the core, since no set of
losers would be able to beneficially deviate. Otherwise, there is
a set of players C1 ⊆L1 that have a joint strategy ®fC1 such that
ρ( ®fC1, ®f ′−C1) |= Ó
i ∈C1 γi, for all joint strategies ®f ′−C1 for Ag \C1.
Now, take any outcome ( ®fC1, ®f ′−C1), that is, any outcome such
that C1 ⊆W ( ®fC1, ®f ′−C1). Let L2 = L( ®fC1, ®f ′−C1). Again, if no
subset of L2 is fulfilled, then ( ®fC1, ®f ′−C1) ∈core(G). Otherwise,
there are players C2 ⊆L2 that have a joint strategy ®fC2 such that
ρ( ®fC1, ®fC2, ®f ′−(C1∪C2)) |=
Û
i ∈C1∪C2
γi
for all joint strategies ®f ′−(C1∪C2) for Ag \ (C1 ∪C2).
We can now reason recursively and take this time any outcome
( ®fC1, ®fC2, ®f ′−(C1∪C2)), that is, any outcome such that (C1 ∪C2) ⊆
W ( ®fC1, ®fC2, ®f ′−(C1∪C2)), and let L3 = L( ®fC1, ®fC2, ®f ′−(C1∪C2)). Same
3The reader is referred to [12] for the definition of bisimulation-invariance over the
model of concurrent game structures.
reasoning above applies, and since L1 ⊃L2 ⊃L3 ⊃... is at most of
length |Ag|, we know that either Lk, with 1 ≤k ≤|Ag|, is not empty
and an element in the core was found, essentially, any outcome
( ®fC1, ®fC2, . . . , ®fCk−1, ®f ′−Ð
1≤i <k Ci ) or Lk is empty, in whose case
the strategy profile ( ®fC1, ®fC2, . . . , ®fCk ) is necessarily in the core,
which concludes the proof. Note that while any outcome in the core
of the form ( ®fC1, ®fC2, . . . , ®fCk−1, ®f ′−Ð
1≤i <k Ci ) satisfies the goals of
all players in Ð
1≤i<k Ci, any outcome ( ®fC1, ®fC2, . . . , ®fCk ) in the
core satisfies all of players’ goals.
□
Theorem 4.6, ensuring that the core is never empty, can be used
to strengthen numeral 3 of Lemma 3.2.
Corollary 4.7. For every game G and fulfilled coalition C, there
is ®f ∈core(G) such that C ⊆W ( ®f ).
5
ON CREDIBLE COALITION FORMATION
As we noted above, our definition of the core assumes worst-case
reasoning: a deviation must be beneficial against all counterpart
behaviours. This definition is robust in the sense that any core-
stable outcome is stable in a very strong sense, but one could argue
that in some cases it is too strong. In particular, when a coalition
C∗is contemplating a deviation ®fC∗, it can surely assume that the
remaining players will not act against their own interests. Thus,
one could argue that a deviation need not be beneficial for all
behaviours of the remaining players, but only those behaviours
that are credible, in the sense that the remaining players might
rationally choose them according to their own preferences.
To make this discussion concrete, consider a two-player game
G containing only three infinite runs (see Figure 1), ρ∅, ρ{1}, ρ{2},
and four outcomes ®fa1a2, ®fa1b2, ®fb1a2, ®fb1b2, where ρ( ®fa1a2) = ρ{1},
ρ( ®fa1b2) = ρ{2}, ρ( ®fb1a2) = ρ∅= ρ( ®fb1b2), such that only ρ{1}
satisfies γ1 and only ρ{2} satisfies γ2. Now, in this game, ®fa1a2 ∈
core(G) holds, but with the use of an incredible (punishing) strategy
by player 1. Notice that the only possible deviation from ®fa1a2 for
player 2 is to ®fa1b2 and hence the only possible response for player 1
is to ®fb1b2. Although this behaviour would prevent player 2 from
achieving its goal, such a way of playing can be regarded as not
rational for player 1 given his preference relation: player 1 certainly
prefers ρ{1} over the other two runs, but he is indifferent otherwise.
s0
s0
s2
s2
s1
s1
s3
s3
⇤
⇤
⇤
⇢{1}
⇢{;}
⇢{2}
a1a2
a1b2
b1b2
b1a2
Figure 1: A game with an incredible strategy.
Motivated by this phenomenon, we propose a stronger definition
for the core in which the way that deviating players are punished

is more credible. More specifically, with this new definition we
require that if a coalition C∗wants to deviate from a given outcome
®f using a joint strategy ®f ′C∗, the coalition of players outsideC∗can
credibly threaten C∗only if players outside C∗have a joint strategy
®f ′−C∗with which both at least one player inC∗does not get its goal
achieved and every winner in ®f remains a winner in ( ®f ′−C∗, ®f ′C∗),
that is, they act in accordance with their preference relations. We
then reformulate the definition of a beneficial deviation and say
that a deviation ®f ′C∗is a beneficial deviation from ®f if:
(1) C∗⊆L( ®f ), and
(2) C∗⊆W ( ®f−C∗, ®f ′C∗), and
(3) for every joint strategy ®f ′−C∗for Ag \ C∗we have
W ( ®f ) ⊆W ( ®f ′−C∗, ®f ′C∗) ⇒C∗⊆W ( ®f ′−C∗, ®f ′C∗).
With this definition in place we can say that the strong core of a game
(CORE+), denoted core+(G), is the set of outcomes of G that admit
no beneficial deviation as above. Then, we see that while ®fa1a1 is
in core(G), it is not the case that ®fa1a1 is in core+(G), since player 2
can now beneficially deviate from ®fa1a1 to ®fa1b1.
Note on credible threats in games with externalities: The game the-
ory literature on this topic is vast. The reason is that the existence of
externalities leads to many different definitions of stable behaviour
(see, e.g., [10, 23, 28, 30] for many variants of the core). Here, we
propose one definition but by no means we claim it is the strongest
anyone may wish to consider. Essentially, with our definition, we
require that for a punishing joint strategy to be credible, winners
must remain winners after the presenting the threat.
We will now study the complexity of the decision problems
defined in previous sections, but with respect to CORE+. There are
four decision problems whose definition depends on the nature of
the core: E-CORE, A-CORE, CORE Membership, and Beneficial
Deviation. To simplify notations, we will call them here in the same
way but with the understanding that results in this section are with
respect to CORE+. As we will show next, these four problems have
the same complexities as with core, but require a more complex
logical characterisation, which we provide here using the two-
alternation fragment of Strategy Logic (SL [21, 22]).4
SL extends LTL with two strategy quantifiers, ⟨⟨x⟩⟩and [[x]],
and an agent binding operator (i,x), where i is an agent and x is
a variable. These operators can be read as “there exists a strategy
x”, “for every strategy x”, and “bind agent i to the strategy associated
with variable x”, respectively. Formally, SL formulae are inductively
built from a set of propositions AP, variables Var, and agents Ag,
using the following grammar, where p ∈AP, x ∈Var, and i ∈Ag:
ϕ ::= p | ¬ϕ | ϕ ∧ϕ | Xϕ | ϕ Uϕ | ⟨⟨x⟩⟩ϕ | [[x]]ϕ | (i,x)ϕ.
We can now present the semantics of SL, where Str denotes the
set of all strategies. Given a concurrent game structure M, for all
SL formulae ϕ, states s ∈St in M, and assignments χ ∈Asg =
(Var ∪Ag) →Str, mapping variables and agents to strategies, the
relation M, χ,s |= ϕ is defined as follows:
(1) For the Boolean and temporal cases, the semantics is standard
(2) For all formulae ϕ and variables x ∈Var we have:
(a) M, χ,s |= ⟨⟨x⟩⟩ϕ if ∃f ∈Str. M, χ[x 7→f ],s |= ϕ;
4A logical characterisation of CORE+ using ATL∗was not found. In fact, we believe
that such a logical characterisation in ATL∗is not possible for multi-player games.
(b) M, χ,s |= [[x]]ϕ if ∀f ∈Str. M, χ[x 7→f ],s |= ϕ;
(3) For every agent i ∈Ag and variable x ∈Var,
if M, χ[i 7→χ(x)],s |= ϕ then M, χ,s |= (i,x)ϕ .
For a sentence ϕ, that is, a formula with no free variables and
agents [21, 22], we say that M satisfies ϕ, and write M |= ϕ in
that case, if M, ∅,s0 |= ϕ, where ∅is the empty assignment. We
use the following abbreviations: ⟨i⟩ϕ for ⟨⟨x⟩⟩(i,x)ϕ and [i]ϕ for
[[x]](i,x)ϕ, which can be intuitively understood as “there is a strat-
egy for agent i such that ϕ holds” and “ϕ holds, for all strategies of
agent i”, respectively. We extend this notation to sets of players and
write, for instance, ⟨C⟩ϕ instead of ⟨i⟩. . . ⟨j⟩ϕ, whereC = {i, . . . , j},
and similarly for the universal quantifier operator. Then, with ⟨C⟩ϕ
we mean that “coalition C has a joint strategy such that ϕ holds.”
We then find that for a game G = (M,γ1, . . . ,γn) and LTL for-
mula ϕ, we have (G,ϕ) ∈E-CORE if and only if M |= ϕ+
E-CORE(G,ϕ),
where ϕ+
E-CORE(G,ϕ) is the SL formula:
ϕ+
E-CORE(G,ϕ)
=
Ô
W ⊆Ag⟨Ag⟩ ϕ ∧Ó
i ∈W γi ∧Ó
j ∈Ag\W ¬γj∧
Ó
C∗⊆Ag\W ϕNoBD(G,W ,C∗) 
ϕNoBD(G,W ,C∗)
=
[C∗]  Ó
j ∈C∗γj →
⟨Ag \ C∗⟩(Ó
i ∈W γi ∧Ô
j ∈C∗¬γj)
This SL formula expresses that in the concurrent game structure
there exists a path (⟨Ag⟩...) satisfying that formula ϕ holds, some
players get their goals achieved (Ó
i ∈W γi) – the winners, the re-
maining players do not (Ó
j ∈Ag\W ¬γj) – the losers, and no coalition
of losers have a beneficial deviation (Ó
C∗⊆Ag\W ϕNoBD(G,W ,C∗)).
In addition, a coalition of losersC∗not having a beneficial deviation
is expressed with the SL formula ϕNoBD(G,W ,C∗) as follows. For
every joint strategy ofC∗(formula [C∗]...), if with such a joint strat-
egy every player in C∗is better off (Ó
j ∈C∗γj – for condition (2)
of beneficial deviation) then the coalition of players outside C∗
have a joint strategy (⟨Ag \ C∗⟩...) such that both the winners in
the original outcome remain winners after the threat is presented
(Ó
i ∈W γi), and at least one player in the deviating coalition, C∗,
does not get its goal achieved (Ô
j ∈C∗¬γj) – for condition (3) of the
definition of beneficial deviation with respect to CORE+.
At this point, we would like to make a couple of observations.
First, that the complexity of checking SL formulae is non-elementary
and depends on the alternation-depth of the formula ([21]): SL for-
mulae of alternation-depth n can be checked in (n + 1)-EXPTIME,
and in PSPACE for formulae that are semantically equivalent to
CTL∗formulae. Since ϕ+
E-CORE(G,ϕ) is an SL formula with two
alternations, it can be checked in 3EXPTIME (and in PSPACE if
|Ag| = 1). Second, we also would like to recall that finite-state
machine strategies, as those we use here, can be characterised in
LTL using the technique presented in [13, 14]. Using these logical
characterisations, we can show the following complexity results.
Theorem 5.1. For multi-player games, while E-CORE and A-CORE
are in 3EXPTIME, CORE Membership is 2EXPTIME-complete and
Beneficial Deviation is PSPACE-complete. For one-player games,
all problems are PSPACE-complete.
Because CORE+ was characterised using SL (which is not a
bisimulation-invariant logic), we cannot conclude that the satis-
faction of LTL properties by outcomes in core+ is a bisimulation-
invariant property. We believe that this is not the case. Furthermore,

we do not know whether core+ is never empty or not. As a partial
result, we show that such a set is not empty in two-player games.
Proposition 5.2. core+ , ∅, for two-player games.
Proof. For a contradiction, let us suppose that for some game
G, the set of outcomes core+(G) is empty. This means that for
every outcome either player 1 or player 2 or both have a beneficial
deviation. Then, we know that no outcome can satisfy both goals,
γ1 and γ2. Let us then consider the three remaining possible cases:
outcomes that only satisfy γ1 (case 1), outcomes that only satisfy
γ2 (case 2), and outcomes that satisfy neither γ1 nor γ2 (case 3). Let
®f = (f1, f2) be an outcome, f ′
1 be a deviation by player 1, and f ′
2 be
a deviation by player 2, and consider the three cases above. In case 1,
only player 2 would deviate. Then, outcome (f1, f ′
2 ) only satisfies
γ2. Because (f1, f ′
2 ) is not in the core either, from this outcome
only player 1 would deviate, to another outcome (f ′
1 , f ′
2 ). Then,
outcome (f ′
1 , f ′
2 ) only satisfiesγ1. But, then, we have a contradiction,
since this means that (f1, f2) would be in core+(G). We can reason
symmetrically to show that case 2 is not possible either. For case 3
we note that only single deviations would be possible. But any such
deviations would be to an outcome that either only satisfies γ1 or
only satisfies γ2, which are no longer possible. Since no other cases
are possible, we have to reject our assumption and conclude that,
for two-player games, core+(G) is not empty.
□
6
DISCUSSION AND RELATED WORK
Coalition formation in cooperative games. Coalition forma-
tion with externalities has been studied in the cooperative game-
theory literature [10, 28, 30]. They considered several concepts of
the core. For instance, α-core takes the pessimistic approach that re-
quires that all members of a deviating coalition, S, will benefit from
the deviation regardless of the behaviour of the other coalitions that
may be formed. Our first definition of the core follows this approach.
Contrarily, β-core takes an optimistic approach and requires that
the members of a deviating coalition S will benefit from at least
one possibility of coalition formation of the rest of the players. In
addition, γ-core [5, 6] assumes that the coalition structure that will
be created after a deviation will include the deviating coalition S
and the rest of the coalition structure will consist of all singletons.
The “worth” of S is now defined as equal to its payoff in the Nash
equilibrium between S and the other players acting individually,
in which the members of S play their joint best response strategy
against the individually best response strategies of the remaining
players. It is well-known that α- and β-characteristic functions
lead to large cores [25], which is consistent with our observation
that, with respect to our first definition, the core is never empty.
Coalition formation is important in multi-agent system [26]. How-
ever, even though Coalition formation with externalities is very
common in multi-agent systems, not much work has studied the
concept of stability in multi-agent coalition formation with exter-
nalities. Instead, in artificial intelligence and multi-agent systems,
most research has focused on the structure formation itself [24].
Quantitative reasoning in concurrent games. In this paper,
we studied games where players goals and preferences are defined
using LTL formulae. This led to a very general qualitative analysis
of their rational behaviour, in particular, regarding the coalitions
they may form. Another criteria to decide whether a coalition of
players might form is with the use of quantitative information, for
instance, when considering mean-payoff functions, or some other
kind of utility functions instead. More specifically, to investigate this
quantitative setting, one could associate states in a concurrent game
structure with ann-tuple (v1, . . . ,vn) of positive real values, one for
each agent i in the game, through a value function val(i) : St →R.
Games will be played in the same way, and hence produce infinite
runs ρ = s0s1s2 . . . which each will induce an infinite sequence of
values for each player: vali(ρ) = v0v1 . . ., where for each i ∈Ag,
we have a mapvali : Rω →Rω. The payoff of a playeri, denoted by
mpi, on a given outcome ®f will be the mean-payoff of the infinite
sequence of values associated with the run induced by such an
outcome, which is formally defined as follows:
mpi(vali(ρ( ®f ))) = lim infk→∞
1
k
k
Õ
t=0
vali[t] .
Preference relations are defined in the obvious way. Player i strictly
prefers outcome ®f over outcome ®f ′ if and only ifmpi( ®f ) > mpi( ®f ′),
and is indifferent otherwise. On this basis, for a set of players C∗⊆
Ag, a deviation ®f ′C∗is a beneficial deviation from ®f if and only if, for
each i ∈C∗, we have mpi( ®f ′C∗, ®f ′−C∗) > mp( ®f ), for every ®f ′−C∗
of Ag \ C∗. Then, the core of a game G with quantitative payoffs
would be the set of outcomes ofG that admit no beneficial deviation.
With these definitions in place one can now ask the main questions
studied before, namely, E-CORE, A-CORE, CORE Membership, and
Beneficial Deviation, but in an unexplored quantitative setting.
We believe that without LTL goals associated with the players in
the game, this setting may lead to better complexity results, but
this is something that still has to be fully investigated.
Rational verification of concurrent games. The formal ver-
ification of temporal logic properties of multi-agent systems, while
assuming rational behaviour of the agents in such a system, has
been studied for almost a decade now; see, for instance, [11, 13, 14,
17, 29]. However, to the best of our knowledge, all these studies have
considered a non-cooperative setting, even if coalitional power is
allowed, for instance, as in a strong Nash equilibrium. Nonetheless,
also in such non-cooperative settings, the complexity of checking
whether a temporal logic property is satisfied in a stable outcome
of the game is a 2EXPTIME-complete problem, even for two-player
zero-sum games where only trivial coalitions can be formed. On
the positive side, cooperative games seem to have better model
theoretic properties in the rational verification framework: with
respect to our first definition of the core (which corresponds to the
concept of α-core in the literature of cooperative games), a witness
in the core is always guaranteed (since the core is never empty),
preserved across bisimilar systems, and easily checked in practice
in an efficient way using ATL∗model checking techniques, which
are supported by a number of verification tools, e.g., MCMAS [19],
an automated formal verification tool that supports ATL∗model
checking and specifications of concurrent game structures in ISPL.
Acknowledgment. This research has been partly supported
by the Ministry of Science and Technology, Israel, and the Japan
Science and Technology Agency (JST).

REFERENCES
[1] Rajeev Alur, Thomas A. Henzinger, and Orna Kupferman. 2002. Alternating-time
temporal logic. Journal of the ACM 49, 5 (2002), 672–713.
[2] Rajeev Alur and Salvatore La Torre. 2004. Deterministic generators and games
for LTL fragments. ACM Transactions on Computational Logic 5, 1 (2004), 1–25.
[3] Romain Brenguier. 2013. PRALINE: A Tool for Computing Nash Equilibria in
Concurrent Games. In CAV (Lecture Notes in Computer Science), Vol. 8044. Springer,
890–895.
[4] Georgios Chalkiadakis, Edith Elkind, and Michael Wooldridge. 2011. Computa-
tional Aspects of Cooperative Game Theory. Morgan-Claypool.
[5] Parkash Chander. 2007. The gamma-core and coalition formation. International
Journal of Game Theory 35, 4 (2007), 539–556.
[6] Parkash Chander et al. 2010. Cores of games with positive externalities. CORE
DP 2010/4 (2010).
[7] Edmund M. Clarke, Orna Grumberg, and Doron A. Peled. 2002. Model Checking.
MIT Press.
[8] E. Allen Emerson. 1990. Temporal and Modal Logic. In Handbook of Theoretical
Computer Science, Volume B: Formal Models and Sematics (B). MIT Press, 995–1072.
[9] E. Allen Emerson and Joseph Y. Halpern. 1986. "Sometimes" and "Not Never"
revisited: on branching versus linear time temporal logic. Journal of the ACM 33,
1 (1986), 151–178.
[10] Michael Finus and Bianca Rundshagen. 2003. A Non-Cooperative Foundation
of Core-Stability in Positive Externality NTU-Coalition Games. Nota Di Lavoro
31.2003. Economics Energy Environment (2003).
[11] Dana Fisman, Orna Kupferman, and Yoad Lustig. 2010. Rational Synthesis. In
TACAS (Lecture Notes in Computer Science), Vol. 6015. Springer, 190–204.
[12] Julian Gutierrez, Paul Harrenstein, Giuseppe Perelli, and Michael Wooldridge.
2017. Nash Equilibrium and Bisimulation Invariance. In CONCUR (LIPIcs), Vol. 85.
Schloss Dagstuhl, 17:1–17:16.
[13] Julian Gutierrez, Paul Harrenstein, and Michael Wooldridge. 2015. Iterated
Boolean games. Information and Computation 242 (2015), 53–79.
[14] Julian Gutierrez, Paul Harrenstein, and Michael Wooldridge. 2017. From model
checking to equilibrium checking: Reactive modules for rational verification.
Artificial Intelligence 248 (2017), 123–157.
[15] Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, and Michael Wooldridge.
2018. EVE: A Tool for Temporal Equilibrium Analysis. In ATVA (Lecture Notes in
Computer Science), Vol. 11138. Springer, 551–557.
[16] Matthew Hennessy and Robin Milner. 1985. Algebraic Laws for Nondeterminism
and Concurrency. Journal of the ACM 32, 1 (1985), 137–161.
[17] Orna Kupferman, Giuseppe Perelli, and Moshe Y. Vardi. 2016. Synthesis with
rational environments. Annals of Mathematics and Artificial Intelligence 78, 1
(2016), 3–20.
[18] Orna Kupferman, Moshe Y. Vardi, and Pierre Wolper. 2000. An automata-theoretic
approach to branching-time model checking. Journal of the ACM 47, 2 (2000),
312–360.
[19] Alessio Lomuscio, Hongyang Qu, and Franco Raimondi. 2017. MCMAS: an open-
source model checker for the verification of multi-agent systems. STTT 19, 1
(2017), 9–30.
[20] Michael Maschler, Eilon Solan, and Shmuel Zamir. 2013. Game Theory. Cambridge
University Press.
[21] Fabio Mogavero, Aniello Murano, Giuseppe Perelli, and Moshe Y. Vardi. 2014.
Reasoning About Strategies: On the Model-Checking Problem. ACM Transactions
on Computational Logic 15, 4 (2014), 34:1–34:47.
[22] Fabio Mogavero, Aniello Murano, Giuseppe Perelli, and Moshe Y. Vardi. 2017.
Reasoning about Strategies: on the Satisfiability Problem. Logical Methods in
Computer Science 13, 1 (2017).
[23] Martin J. Osborne and Ariel Rubinstein. 1994. A Course in Game Theory. MIT
Press.
[24] Talal Rahwan, Tomasz Michalak, Michael Wooldridge, and Nicholas R Jennings.
2012. Anytime coalition structure generation in multi-agent systems with positive
or negative externalities. Artificial Intelligence 186 (2012), 95–122.
[25] Debraj Ray and Rajiv Vohra. 1997. Equilibrium binding agreements. Journal of
Economic theory 73, 1 (1997), 30–78.
[26] Onn Shehory and Sarit Kraus. 1998. Methods for task allocation via agent coalition
formation. Artificial intelligence 101, 1 (1998), 165–200.
[27] A. Prasad Sistla and Edmund M. Clarke. 1985. The Complexity of Propositional
Linear Temporal Logics. Journal of the ACM 32, 3 (1985), 733–749.
[28] Metin Uyanık. 2015. On the nonemptiness of the α-core of discontinuous games:
Transferable and nontransferable utilities. Journal of Economic Theory 158 (2015),
213–231.
[29] Michael Wooldridge, Julian Gutierrez, Paul Harrenstein, Enrico Marchioni,
Giuseppe Perelli, and Alexis Toumi. 2016. Rational Verification: From Model
Checking to Equilibrium Checking. In Proc. of AAAI. AAAI Press, 4184–4191.
[30] Sang-Seung Yi. 1997. Stable coalition structures with externalities. Games and
economic behavior 20, 2 (1997), 201–237.

