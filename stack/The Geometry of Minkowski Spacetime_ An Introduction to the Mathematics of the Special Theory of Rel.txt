
Applied Mathematical Sciences
Volume 92
Editors
S.S. Antman
Department of Mathematics
and
Institute for Physical Science and Technology
University of Maryland
College Park, MD 20742-4015
USA
ssa@math.umd.edu
P. Holmes
Department of Mechanical and Aerospace Engineering
Princeton University
215 Fine Hall
Princeton, NJ 08544
pholmes@math.princeton.edu
L. Sirovich
Laboratory of Applied Mathematics
Department of Biomathematical Sciences
Mount Sinai School of Medicine
New York, NY 10029-6574
lsirovich@rockefeller.edu
K. Sreenivasan
Department of Physics
New York University
70 Washington Square South
New York City, NY 10012
katepalli.sreenivasan@nyu.edu
Advisors
L. Greengard J. Keener J. Keller
R. Laubenbacher B.J. Matkowsky A. Mielke
C.S. Peskin A. Stevens A. Stuart
For further volumes:
http://www.springer.com/series/34

     
     

Gregory L. Naber
The Geometry of
Minkowski Spacetime
An Introduction to the Mathematics
of the Special Theory of Relativity
Second Edition
With 66 Illustrations

ISBN 978-1-4419-7837-0
e-ISBN 978-1-4419-7838-7
DOI 10.1007/978-1-4419-7838-7
Springer New York Dordrecht Heidelberg London
Library of Congress Control Number: 2011942915
Mathematics Subject Classiﬁcation (2010): 83A05, 83-01
All rights reserved. This work may not be translated or copied in whole or in part without the written
permission of the publisher (Springer Science+Business Media, LLC, 233 Spring Street, New York,
NY 10013, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in
connection with any form of information storage and retrieval, electronic adaptation, computer software,
or by similar or dissimilar methodology now known or hereafter developed is forbidden.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if they are
not identiﬁed as such, is not to be taken as an expression of opinion as to whether or not they are subject
to proprietary rights.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)
© Springer Science+Business Media, LLC 2012
gln22@drexel.edu
Gregory L. Naber
Department of Mathematics
Drexel University
USA
Korman Center
Philadelphia, Pennsylvania
3141 Chestnut Street
19104-2875

For Debora

     
     
     
     

Preface
It is the intention of this monograph to provide an introduction to the spe-
cial theory of relativity that is mathematically rigorous and yet spells out in
considerable detail the physical signiﬁcance of the mathematics. Particular
care has been exercised in keeping clear the distinction between a physi-
cal phenomenon and the mathematical model which purports to describe
that phenomenon so that, at any given point, it should be clear whether we
are doing mathematics or appealing to physical arguments to interpret the
mathematics.
The Introduction is an attempt to motivate, by way of a beautiful theo-
rem of Zeeman [Z1], our underlying model of the “event world.” This model
consists of a 4-dimensional real vector space on which is deﬁned a nondegen-
erate, symmetric, bilinear form of index one (Minkowski spacetime) and its
associated group of orthogonal transformations (the Lorentz group).
The ﬁrst ﬁve sections of Chapter 1 contain the basic geometrical infor-
mation about this model including preliminary material on indeﬁnite inner
product spaces in general, elementary properties of spacelike, timelike and
null vectors, time orientation, proper time parametrization of timelike curves,
the Reversed Schwartz and Triangle Inequalities, Robb’s Theorem on measur-
ing proper spatial separation with clocks and the decomposition of a general
Lorentz transformation into a product of two rotations and a special Lorentz
transformation. In these sections one will also ﬁnd the usual kinematic dis-
cussions of time dilation, the relativity of simultaneity, length contraction,
the addition of velocities formula and hyperbolic motion as well as the con-
struction of 2-dimensional Minkowski diagrams and, somewhat reluctantly,
an assortment of the obligatory “paradoxes.”
Section 6 of Chapter 1 contains the deﬁnitions of the causal and chrono-
logical precedence relations and a detailed proof of Zeeman’s extraordinary
theorem characterizing causal automorphisms as compositions T ◦K ◦L,
where T is a translation, K is a dilation, and L is an orthochronous orthogonal
vii

viii
Preface
transformation. The proof is somewhat involved, but the result itself is used
only in the Introduction (for purposes of motivation) and in Appendix A to
construct the homeomorphism group of the path topology.
Section 1.7 is built upon the one-to-one correspondence between vectors
in Minkowski spacetime and 2 × 2 complex Hermitian matrices and contains
a detailed construction of the spinor map (the two-to-one homomorphism of
SL(2, C) onto the Lorentz group). We show that the fractional linear trans-
formation of the “celestial sphere” determined by an element A of SL(2, C)
has the same eﬀect on past null directions as the Lorentz transformation
corresponding to A under the spinor map. Immediate consequences include
Penrose’s Theorem [Pen1] on the apparent shape of a relativistically mov-
ing sphere, the existence of invariant null directions for an arbitrary Lorentz
transformation, and the fact that a general Lorentz transformation is com-
pletely determined by its eﬀect on any three distinct past null directions. The
material in this section is required only in Chapter 3 and Appendix B.
In Section 1.8 (which is independent of Sections 1.6 and 1.7) we introduce
into our model the additional element of world momentum for material parti-
cles and photons and its conservation in what are called contact interactions.
With this one can derive most of the well-known results of relativistic particle
mechanics and we include a sampler (the Doppler eﬀect, the aberration for-
mula, the nonconservation of proper mass in a decay reaction, the Compton
eﬀect and the formulas relevant to inelastic collisions).
Chapter 2 introduces charged particles and uses the classical Lorentz
World Force Law

FU = m
e
dU
dτ

as motivation for describing an electromag-
netic ﬁeld at a point in Minkowski spacetime as a linear transformation F
whose job it is to tell a charged particle with world velocity U passing through
that point what change in world momentum it should expect to experience
due to the presence of the ﬁeld. Such a linear transformation is necessarily
skew-symmetric with respect to the Lorentz inner product and Sections 2.2,
2.3 and 2.4 analyze the algebraic structure of these in some detail. The essen-
tial distinction between regular and null skew-symmetric linear transforma-
tions is described ﬁrst in terms of the physical invariants
⇀
E ·
⇀
B and |
⇀
B|2−|
⇀
E|2
of the electromagnetic ﬁeld (which arise as coeﬃcients in the characteristic
equation of F) and then in terms of the existence of invariant subspaces. This
material culminates in the existence of canonical forms for both regular and
null ﬁelds that are particularly useful for calculations, e.g., of eigenvalues and
principal null directions.
Section 2.5 introduces the energy-momentum transformation for an arbi-
trary skew-symmetric linear transformation and calculates its matrix entries
in terms of the classical energy density, Poynting 3-vector and Maxwell stress
tensor. Its principal null directions are determined and the Dominant Energy
Condition is proved.
In Section 2.6, the Lorentz World Force equation is solved for charged
particles moving in constant electromagnetic ﬁelds, while variable ﬁelds are
introduced in Section 2.7. Here we describe the skew-symmetric bilinear form

Preface
ix
(bivector) associated with the linear transformation representing the ﬁeld and
use it and its dual to write down Maxwell’s (source-free) equations. As sample
solutions to Maxwell’s equations we consider the Coulomb ﬁeld, the ﬁeld of a
uniformly moving charge, and a rather complete discussion of simple, plane
electromagnetic waves.
Chapter 3 is an elementary introduction to the algebraic theory of spinors
in Minkowski spacetime. The rather lengthy motivational Section 3.1 traces
the emergence of the spinor concept from the general notion of a (ﬁnite di-
mensional) group representation. Section 3.2 contains the abstract deﬁnition
of spin space and introduces spinors as complex-valued multilinear function-
als on spin space. The Levi-Civita spinor ϵ and the elementary operations
of spinor algebra (type changing, sums, components, outer products, (skew-)
symmetrization, etc.) are treated in Section 3.3.
In Section 3.4 we introduce the Infeld-van der Waerden symbols (essen-
tially, normalized Pauli spin matrices) and use them, together with the spinor
map from Section 1.7, to deﬁne natural spinor equivalents for vectors and cov-
ectors in Minkowski spacetime. The spinor equivalent of a future-directed null
vector is shown to be expressible as the outer product of a spin vector and its
conjugate. Reversing the procedure leads to the existence of a future-directed
null “ﬂagpole” for an arbitrary nonzero spin vector.
Spinor equivalents for bilinear forms are constructed in Section 3.5 with the
skew-symmetric forms (bivectors) playing a particularly prominant role. With
these we can give a detailed construction of the geometrical representation
“up to sign” of a nonzero spin vector as a null ﬂag (due to Penrose). The
sign ambiguity in this representation intimates the “essential 2-valuedness”
of spinors which we discuss in some detail in Appendix B.
Chapter 3 culminates with a return to the electromagnetic ﬁeld. We intro-
duce the electromagnetic spinor φAB associated with a skew-symmetric lin-
ear transformation F and ﬁnd that it can be decomposed into a symmetrized
outer product of spin vectors α and β. The ﬂagpoles of these spin vectors are
eigenvectors for the electromagnetic ﬁeld transformation, i.e., they determine
its principal null directions. The solution to the eigenvalue problem for φAB
yields two elegant spinor versions of the “Petrov type” classiﬁcation theorems
of Chapter 2. Speciﬁcally, we prove that a skew-symmetric linear transforma-
tion F on M is null if and only if λ = 0 is the only eigenvalue of the associated
electromagnetic spinor φAB and that this, in turn, is the case if and only if
the associated spin vectors α and β are linearly dependent. Next we ﬁnd that
the energy-momentum transformation has a beautifully simple spinor equiv-
alent and use it to give another proof of the Dominant Energy Condition.
Finally, we derive the elegant spinor form of Maxwell’s equations and brieﬂy
discuss its generalizations to massless free ﬁeld equations for arbitrary spin
1
2n particles.
Chapter 4, which is new to this second edition, is intended to serve
two purposes. The ﬁrst is to provide a gentle Prologue to the steps one
must take to move beyond special relativity and adapt to the presence of

x
Preface
gravitational ﬁelds that cannot be considered negligible. Section 4.2 describes
the philosophy espoused by Einstein for this purpose. Implementing this phi-
losophy, however, requires mathematical tools that played no role in the ﬁrst
three chapters so Section 4.3 provides a very detailed and elementary intro-
duction to just enough of this mathematical machinery to accomplish our
very modest goal. Thus supplied with a rudimentary grasp of manifolds,
Riemannian and Lorentzian metrics, geodesics and curvature we are in a
position to introduce, in Section 4.4, the Einstein ﬁeld equations (with cos-
mological constant Λ) and learn just a bit about one remarkable solution.
This is the so-called de Sitter universe dS and it is remarkable for a number
of reasons. It is a model of the universe as a whole, that is, a cosmological
model. Indeed, we will see that, depending on one’s choice of coordinates, it
can be viewed as representing an instance of any one of the three standard
Robertson-Walker models of relativistic cosmology. Taking Λ to be zero, dS
can be viewed as a model of the event world in the presence of a mass-energy
distribution due to a somewhat peculiar “ﬂuid” with positive density, but
negative pressure. On the other hand, if Λ is a positive constant, then dS
models an empty universe and, in this sense at least, is not unlike Minkowski
spacetime. The two have very diﬀerent properties, however, and one might be
tempted to dismiss dS as a mathematical curiosity were it not for the fact that
certain recent astronomical observations suggest that the expansion of our
universe is actually accelerating and that this weighs in on the side of the de
Sitter universe rather than the Minkowski universe. Thus, this ﬁnal chapter
is also something of an Epilogue to our story in which the torch is, perhaps,
passed to a new main character. Section 4.5 delves brieﬂy into a somewhat
more subtle diﬀerence between the Minkowski and de Sitter worlds that one
sees only “at inﬁnity.” Following Penrose [Pen2] we examine the asymptotic
structures of dS and M by constructing conformal embeddings of them into
the Einstein static universe. Penrose developed this technique to study mass-
less spinor ﬁeld equations such as the source-free Maxwell equations and the
Weyl neutrino equation with which we concluded Chapter 3.
The background required for an eﬀective reading of the ﬁrst three chap-
ters is a solid course in linear algebra and the usual supply of “mathematical
maturity.” In Chapter 4 we will require also some basic material from real
analysis such as the Inverse Function Theorem. For the two appendices we
must increment our demands upon the reader and assume some familiar-
ity with elementary point-set topology. Appendix A describes, in the spe-
cial case of Minkowski spacetime, a remarkable topology devised by Hawk-
ing, King and McCarthy [HKM] and based on ideas of Zeeman [Z2] whose
homeomorphisms are just compositions of translations, dilations and Lorentz
transformations. Only quite routine point-set topology is required, but the
construction of the homeomorphism group depends on Zeeman’s Theorem
from Section 1.6.
In Appendix B we elaborate upon the “essential 2-valuedness” of spinors
and its signiﬁcance in physics for describing, for example, the quantum
mechanical state of a spin 1/2 particle, such as an electron. Paul Dirac’s

Preface
xi
ingenious “Scissors Problem” is used, as Dirac himself used it, to suggest, in
a more familiar context, the possibility that certain aspects of a physical sys-
tem’s state may be invariant under a rotation of the system through 720◦, but
not under a 360◦rotation. To fully appreciate such a phenomenon one must
see its reﬂection in the mathematics of the rotation group (the “conﬁguration
space” of the scissors). For this we brieﬂy review the notion of homotopy
for paths and the construction of the fundamental group. Noting that the
3-sphere S3 is the universal cover for real projective 3-space RP 3 and
that RP 3 is homeomorphic to the rotation group SO(3) we show that
π1(SO(3)) ∼= Z2. One then sees Dirac’s demonstration as a sort of physi-
cal model of the two distinct homotopy classes of loops in SO(3). But there
is a great deal more to be learned here. By regarding the elements of SU 2
(Section 1.7) as unit quaternions we ﬁnd that, topologically, it is S3 and
then recognize SU 2 and the restriction of the spinor map to it as a concrete
realization of the covering space for SO(3) that we just used to calculate
π1(SO(3)). One is then led naturally to SU 2 as a model for the “state space”
(as distinguished from the “conﬁguration space”) of the system described
in Dirac’s demonstration. Recalling our discussion of group representations
in Section 3.1 we ﬁnd that it is the representations of SU 2, i.e., the spinor
representations of SO(3), that contain the physically signiﬁcant information
about the system. So it is with the quantum mechanical state of an electron,
but in this case one requires a relativistically invariant theory and so one
looks, not to SU 2 and the restriction of the spinor map to it, but to the full
spinor map which carries SL(2, C) onto the Lorentz group.
Lemmas, Propositions, Theorems and Corollaries are numbered sequen-
tially within each section so that “p.q.r” will refer to result #r in Section
#q of Chapter #p. Exercises and equations are numbered in the same way,
but with equation numbers enclosed in parentheses. There are 232 exercises
scattered throughout the text and no asterisks appear to designate those that
are used in the sequel; they are all used and must be worked conscientiously.
Finally, we shall make extensive use of the Einstein summation convention
according to which a repeated index, one subscript and one superscript, indi-
cates a sum over the range of values that the index can assume. For example,
if a and b are indices that range over 1, 2, 3, 4, then
xaea =
4

a=1
xaea = x1e1 + x2e2 + x3e3 + x4e4,
Λa
bxb =
4

b=1
Λa
bxb = Λa
1x1 + Λa
2x2 + Λa
3x3 + Λa
4x4,
ηabυawb = η11υ1w1 + η12υ1w2 + η13υ1w3 + η14υ1w4
+ η21υ2w1 + · · · + η44υ4w4,
and so on.
Gregory L. Naber

     
     

Acknowledgments
Some debts are easy to describe and acknowledge with gratitude. To the
Departments of Mathematics at the California State University, Chico, and
Drexel University, go my sincere thanks for the support, ﬁnancial and other-
wise, that they provided throughout the period during which the manuscript
was being written. On the other hand, my indebtedness to my wife, Debora,
is not so easily expressed in a few words. She saw to it that I had the time
and the peace to think and to write and she bore me patiently when one or
the other of these did not go well. She took upon herself what would have
been, for me, the onerous task of mastering the software required to produce
a beautiful typescript from my handwritten version and, while producing it,
held me to standards that I would surely have abandoned just to be done
with the thing. Let it be enough to say that the book would not exist were
it not for Debora. With love and gratitude, it is dedicated to her.
xiii

     
     

Contents
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
vii
Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1
Geometrical Structure of M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.1
Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.2
Minkowski Spacetime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.3
The Lorentz Group . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.4
Timelike Vectors and Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
1.5
Spacelike Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
1.6
Causality Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
1.7
Spin Transformations and the Lorentz Group . . . . . . . . . . . . . .
68
1.8
Particles and Interactions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
2
Skew-Symmetric Linear Transformations
and Electromagnetic Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
2.1
Motivation via the Lorentz Law . . . . . . . . . . . . . . . . . . . . . . . . . .
93
2.2
Elementary Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
2.3
Invariant Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
2.4
Canonical Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
2.5
The Energy-Momentum Transformation . . . . . . . . . . . . . . . . . . . 109
2.6
Motion in Constant Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
2.7
Variable Electromagnetic Fields . . . . . . . . . . . . . . . . . . . . . . . . . . 117
3
The Theory of Spinors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
3.1
Representations of the Lorentz Group . . . . . . . . . . . . . . . . . . . . . 135
3.2
Spin Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
3.3
Spinor Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
3.4
Spinors and World Vectors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
xv

xvi
Contents
3.5
Bivectors and Null Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
3.6
The Electromagnetic Field (Revisited) . . . . . . . . . . . . . . . . . . . . 186
4
Prologue and Epilogue: The de Sitter Universe . . . . . . . . . . . 199
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
4.2
Gravitation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
4.3
Mathematical Machinery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
4.4
The de Sitter Universe dS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
4.5
Inﬁnity in Minkowski and de Sitter Spacetimes . . . . . . . . . . . . . 255
Appendix A
Topologies For M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
A.1 The Euclidean Topology. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
A.2 E-Continuous Timelike Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . 280
A.3 The Path Topology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
Appendix B
Spinorial Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
B.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
B.2 The Spinning Electron and Dirac’s Demonstration . . . . . . . . . . 294
B.3 Homotopy in the Rotation and Lorentz Groups. . . . . . . . . . . . . 296
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317

Introduction
All beginnings are obscure. Inasmuch as the mathematician operates
with his conceptions along strict and formal lines, he, above all, must
be reminded from time to time that the origins of things lie in greater
depths than those to which his methods enable him to descend.
Hermann Weyl, Space, Time, Matter
Minkowski spacetime is generally regarded as the appropriate arena within
which to formulate those laws of physics that do not refer speciﬁcally to
gravitational phenomena. We would like to spend a moment here at the
outset brieﬂy examining some of the circumstances which give rise to this
belief.
We shall adopt the point of view that the basic problem of science in gen-
eral is the description of “events” which occur in the physical universe and
the analysis of relationships between these events. We use the term “event,”
however, in the idealized sense of a “point-event,” that is, a physical occur-
rence which has no spatial extension and no duration in time. One might
picture, for example, an instantaneous collision or explosion or an “instant”
in the history of some (point) material particle or photon (to be thought
of as a “particle of light”). In this way the existence of a material particle
or photon can be represented by a continuous sequence of events called its
“worldline.” We begin then with an abstract set M whose elements we call
“events.” We shall provide M with a mathematical structure which reﬂects
certain simple facts of human experience as well as some rather nontrivial
results of experimental physics.
Events are “observed” and we will be particularly interested in a certain
class of observers (called “admissible”) and the means they employ to describe
events. Since it is in the nature of our perceptual apparatus that we identify
events by their “location in space and time” we must specify the means by
which an observer is to accomplish this in order to be deemed “admissible.”
, 
: An Introduction 
, Applied Mathematical Sciences 92,
G.L. Naber The Geometry of Minkowski Spacetime
to the Mathematics 
1
of the Special Theory of Relativity
DOI 10.1007/978-1-4419-7838-7_ , © Springer Science+Business Media, LLC 2012
0

2
Introduction
Each admissible observer presides over a 3-dimensional, right-handed,
Cartesian spatial coordinate system based on an agreed unit of length
and relative to which photons propagate rectilinearly in any direction.
A few remarks are in order. First, the expression “presides over” is not
to be taken too literally. An observer is in no sense ubiquitous. Indeed, we
generally picture the observer as just another material particle residing at
the origin of his spatial coordinate system; any information regarding events
which occur at other locations must be communicated to him by means we
will consider shortly. Second, the restriction on the propagation of photons
is a real restriction. The term “straight line” has meaning only relative to a
given spatial coordinate system and if, in one such system, light does indeed
travel along straight lines, then it certainly will not in another system which,
say, rotates relative to the ﬁrst. Notice, however, that this assumption does
not preclude the possibility that two admissible coordinate systems are in
relative motion. We shall denote the spatial coordinate systems of observers
O, ˆO, . . . by Σ(x1, x2, x3), ˆΣ(ˆx1, ˆx2, ˆx3), . . . .
We take it as a fact of human experience that each observer has an innate,
intuitive sense of temporal order which applies to events which he experiences
directly, i.e., to events on his worldline. This sense, however, is not quantita-
tive; there is no precise, reliable sense of “equality” for “time intervals.” We
remedy this situation by giving him a watch.
Each admissible observer is provided with an ideal standard clock based
on an agreed unit of time with which to provide a quantitative temporal
order to the events on his worldline.
Notice that thus far we have assumed only that an observer can assign a
time to each event on his worldline. In order for an observer to be able to
assign times to arbitrary events we must specify a procedure for the place-
ment and synchronization of clocks throughout his spatial coordinate system.
One possibility is simply to mass-produce clocks at the origin, synchronize
them and then move them to various other points throughout the coordinate
system. However, it has been found that moving clocks about has a most
undesirable eﬀect upon them. Two identical and very accurate atomic clocks
are manufactured in New York and synchronized. One is placed aboard a
passenger jet and ﬂown around the world. Upon returning to New York it is
found that the two clocks, although they still “tick” at the same rate, are no
longer synchronized. The travelling clock lags behind its stay-at-home twin.
Strange, indeed, but it is a fact and we shall come to understand the reason
for it shortly.
To avoid this diﬃculty we shall ask our admissible observers to build their
clocks at the origins of their coordinate systems, transport them to the de-
sired locations, set them down and return to the master clock at the origin.
We assume that each observer has stationed an assistant at the location of

Introduction
3
each transported clock. Now our observer must “communicate” with each
assistant, telling him the time at which his clock should be set in order that
it be sychronized with the clock at the origin. As a means of communication
we select a signal which seems, among all the possible choices, to be least
susceptible to annoying ﬂuctuations in reliability, i.e., light signals. To per-
suade the reader that this is an appropriate choice we shall record some of
the experimentally documented properties of light signals, but ﬁrst, a little
experiment. From his location at the origin O an observer O emits a light
signal at the instant his clock reads t0. The signal is reﬂected back to him
at a point P and arrives again at O at the instant t1. Assuming there is no
delay at P when the signal is bounced back, O will calculate the speed of
the signal to be distance (O, P)/ 1
2(t1 −t0). This technique for measuring the
speed of light we call the Fizeau procedure in honor of the gentleman who
ﬁrst carried it out with care (notice that we must bounce the signal back to
O since we do not yet have a clock at P that is synchronized with that at O).
For each admissible observer the speed of light in vacuo as determined
by the Fizeau procedure is independent of when the experiment is per-
formed, the arrangement of the apparatus (i.e., the choice of P), the
frequency (energy) of the signal and, moreover, has the same numer-
ical value c (approximately 3.0 × 108 meters per second) for all such
observers.
Here we have the conclusions of numerous experiments performed over the
years, most notably those ﬁrst performed by Michelson-Morley and Kennedy-
Thorndike (see Ex. 33 and Ex. 34 of [TW] for a discussion of these exper-
iments). The results may seem odd. Why is a photon so unlike an electron
whose speed certainly will not have the same numerical value for two ob-
servers in relative motion? Nevertheless, they are incontestable facts of na-
ture and we must deal with them. We shall exploit these rather remarkable
properties of light signals immediately by asking all of our observers to mul-
tiply each of their time readings by the constant c and thereby measure time
in units of distance (light travel time, e.g., “one meter of time” is the amount
of time required by a light signal to travel one meter in vacuo). With these
units all speeds are dimensionless and c = 1. Such time readings for observers
O, ˆO, . . . will be designated x4(= ct), ˆx4(= cˆt), . . . .
Now we provide each of our observers with a system of synchronized clocks
in the following way: At each point P of his spatial coordinate system place
a clock identical to that at the origin. At some time x4 at O emit a spherical
electromagnetic wave (photons in all directions). As the wavefront encounters
P set the clock placed there at time x4+ distance (O, P) and set it ticking,
thus synchronized with the clock at the origin.
At this point each of our observers O, ˆO, . . . has established a frame of
reference S(x1, x2, x3, x4), ˆS(ˆx1, ˆx2, ˆx3, ˆx4), . . . . A useful intuitive visualiza-
tion of such a reference frame is as a latticework of spatial coordinate lines
with, at each lattice point, a clock and an assistant whose task it is to record

4
Introduction
locations and times for events occurring in his immediate vicinity; the data
can later be collected for analysis by the observer.
How are the
ˆS-coordinates of an event related to its S-coordinates?
That is, what can be said about the mapping F : R4 →R4 deﬁned by
F(x1, x2, x3, x4) = (ˆx1, ˆx2, ˆx3, ˆx4)? Certainly, it must be one-to-one and onto.
Indeed, F−1 : R4 →R4 must be the coordinate transformation from hat-
ted to unhatted coordinates. To say more we require a seemingly innocuous
“causality assumption.”
Any two admissible observers agree on the temporal order of any two
events on the worldline of a photon, i.e., if two such events have coor-
dinates (x1, x2, x3, x4) and

x1
0, x2
0, x3
0, x4
0

in S and (ˆx1, ˆx2, ˆx3, ˆx4) and

ˆx1
0, ˆx2
0, ˆx3
0, ˆx4
0

in ˆS, then x4 −x4
0 and ˆx4 −ˆx4
0 have the same sign.
Notice that we do not prejudge the issue by assuming that Δx4 and Δˆx4 are
equal, but only that they have the same sign, i.e., that O and ˆO agree as to
which of the two events occurred ﬁrst. Thus, F preserves order in the fourth
coordinate, at least for events which lie on the worldline of some photon.
How are two such events related? Since photons propagate rectilinearly with
speed 1, two events on the worldline of a photon have coordinates in S which
satisfy
xi −xi
0 = vi 
x4 −x4
0

, i = 1, 2, 3,
for some constants v1, v2 and v3 with (v1)2 + (v2)2 + (v3)2 = 1 and
consequently

x1 −x1
0
2 +

x2 −x2
0
2 +

x3 −x3
0
2 −

x4 −x4
0
2 = 0.
(0.1)
Geometrically, we think of (0.1) as the equation of a “cone” in R4 with
vertex at

x1
0, x2
0, x3
0, x4
0

(compare (z −z0)2 = (x −x0)2 + (y −y0)2 in R3).
But all of this must be true in any admissible frame of reference so F must
preserve the cone (0.1). We summarize:
The coordinate transformation map F : R4 →R4 carries the cone (0.1)
onto the cone

ˆx1 −ˆx1
0
2 +

ˆx2 −ˆx2
0
2 +

ˆx3 −ˆx3
0
2 −

ˆx4 −ˆx4
0
2 = 0
(0.2)
and satisﬁes ˆx4 > ˆx4
0 whenever x4 > x4
0 and (0.1) is satisﬁed.
Being simply the coordinate transformation from hatted to unhatted co-
ordinates, F −1 : R4 →R4 has the obvious analogous properties. In 1964,
Zeeman [Z1] called such a mapping F a “causal automorphism” and proved
the remarkable fact that any causal automorphism is a composition of the
following three basic types:
1. Translations: ˆxa = xa + Λa, a = 1, 2, 3, 4, for some constants Λa.
2. Positive scalar multiples: ˆxa = kx a, a = 1, 2, 3, 4, for some positive
constant k.

Introduction
5
3. Linear transformations
ˆxa = Λabxb,
a = 1, 2, 3, 4,
(0.3)
where the matrix Λ = [Λab]a,b=1,2,3,4 satisﬁes the two conditions
ΛT ηΛ = η,
(0.4)
where T means “transpose” and
η =
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0 −1
⎤
⎥⎥⎦,
and
Λ44 ≥1.
(0.5)
This result is particularly remarkable in that it is not even assumed at
the outset that F is continuous (much less, linear). We provide a proof in
Section 1.6.
Since two frames of reference related by a mapping of type 2 diﬀer only
by a trivial and unnecessary change of scale we shall banish them from fur-
ther consideration. Moreover, since the constants Λa in maps of type 1 can
be regarded as the ˆS-coordinates of S’s spacetime origin we may request
that all of our observers cooperate to the extent that they select a common
event to act as origin and thereby take Λa = 0 for a = 1, 2, 3, 4. All that
remain for consideration then are the admissible frames of reference related
by transformations of the form (0.3) subject to (0.4) and (0.5). These are the
so-called “orthochronous Lorentz transformations” and, as we shall prove in
Chapter 1, are precisely the maps which leave invariant the quadratic form
(x1)2 + (x2)2 + (x3)2 −(x4)2 (analogous to orthogonal transformations of
R3 which leave invariant the usual squared length x2 + y2 + z2) and which
preserve “time orientation” in the sense described immediately after (0.2). It
is the geometry of this quadratic form, the structure of the group of Lorentz
transformations and their various physical interpretations that will be our
concern in the text.
With this we conclude our attempt at motivation for the deﬁnitions that
confront the reader in Chapter 1. There is, however, one more item on the
agenda of our introductory remarks. It is the cornerstone upon which the
special theory of relativity is built.
The Relativity Principle: All admissible frames of reference are com-
pletely equivalent for the formulation of the laws of physics.
The Relativity Principle is a powerful tool for building the physics of spe-
cial relativity. Since our concern is primarily with the mathematical structure

6
Introduction
of the theory we shall have few occasions to call explicitly upon the Principle
except for the physical interpretation of the mathematics and here it is vital.
We regard the Relativity Principle primarily as an heuristic principle assert-
ing that there are no “distinguished” admissible observers, i.e., that none
can claim to have a privileged view of the universe. In particular, no such
observer can claim to be “at rest” while the others are moving; they are all
simply in relative motion. We shall see that admissible observers can disagree
about some rather startling things (e.g., whether or not two given events are
“simultaneous”) and the Relativity Principle will prohibit us from preferring
the judgment of one to any of the others. Although we will not dwell on
the experimental evidence in favor of the Relativity Principle it should be
observed that its roots lie in such commonplace observations as the fact that
a passenger in a (smooth, quiet) airplane travelling at constant groundspeed
in a straight line cannot “feel” his motion relative to the earth, i.e., that no
physical eﬀects are apparent in the plane which would serve to distinguish it
from the (quasi-) admissible frame rigidly attached to the earth.
Our task then is to conduct a serious study of these “admissible frames
of reference”. Before embarking on such a study, however, it is only fair to
concede that, in fact, no such thing exists. As is the case with any intellec-
tual construct with which we attempt to model the physical universe, the
notion of an admissible frame of reference is an idealization, a rather fanciful
generalization of circumstances which, to some degree of accuracy, are en-
countered in the world. In particular, it has been found that the existence of
gravitational ﬁelds imposes severe restrictions on the “extent” (both in space
and in time) of an admissible frame. Knowing this we will intentionally avoid
the diﬃculty (until Chapter 4) by restricting our attention to situations in
which the eﬀects of gravity are “negligible.”

Chapter 1
Geometrical Structure of M
1.1 Preliminaries
We denote by V an arbitrary vector space of dimension n ≥1 over the real
numbers. A bilinear form on V is a map g : V × V →R that is linear
in each variable, i.e., such that g(a1v1 + a2v2, w) = a1g(v1, w) + a2g(v2, w)
and g(v, a1w1 + a2w2) = a1g(v, w1) + a2g(v, w2) whenever the a’s are real
numbers and the v’s and w’s are elements of V. g is symmetric if g(w, v) =
g(v, w) for all v and w and nondegenerate if g(v, w) = 0 for all w in V implies
v = 0. A nondegenerate, symmetric, bilinear form g is generally called an
inner product and the image of (v, w) under g is often written v · w rather
than g(v, w). The standard example is the usual inner product on Rn: if v =
(v1, . . . , vn) and w = (w1, . . . , wn), then g(v, w) = v ·w = v1w1 +· · ·+vnwn.
This particular inner product is positive deﬁnite, i.e., has the property that if
v ̸= 0, then g(v, v) > 0. Not all inner products share this property, however.
Exercise 1.1.1 Deﬁne a map g1 : Rn × Rn →R by g1(v, w) = v1w1 +
v2w2 +· · ·+ vn−1wn−1 −vnwn. Show that g1 is an inner product and exhibit
nonzero vectors v and w such that g1(v, v) = 0 and g1(w, w) < 0.
An inner product g for which v ̸= 0 implies g(v, v) < 0 is said to be negative
deﬁnite, whereas if g is neither positive deﬁnite nor negative deﬁnite it is said
to be indeﬁnite.
If g is an inner product on V, then two vectors v and w for which
g(v, w) = 0 are said to be g-orthogonal, or simply orthogonal if there
is no ambiguity as to which inner product is intended. If W is a sub-
space of V, then the orthogonal complement W⊥of W in V is deﬁned by
W⊥= {v ∈V : g(v, w) = 0 for all w ∈W}.
Exercise 1.1.2 Show that W⊥is a subspace of V.
The quadratic form associated with the inner product g on V is the map
Q : V →R deﬁned by Q(v) = g(v, v) = v · v (often denoted v2). We ask
, 
: An Introduction 
, Applied Mathematical Sciences 92,
G.L. Naber The Geometry of Minkowski Spacetime
to the Mathematics 
of the Special Theory of Relativity
DOI 10.1007/978-1-4419-7838-7_ , © Springer Science+Business Media, LLC 2012
7
1

8
1 Geometrical Structure of M
the reader to show that distinct inner products on V cannot give rise to the
same quadratic form.
Exercise 1.1.3 Show that if g1 and g2 are two inner products on V which
satisfy g1(v, v) = g2(v, v) for all v in V, then g1(v, w) = g2(v, w) for all v and
w in V. Hint: The map g1 −g2 : V × V →R deﬁned by (g1 −g2)(v, w) =
g1(v, w)−g2(v, w) is bilinear and symmetric. Evaluate (g1 −g2)(v+w, v+w).
A vector v for which Q(v) is either 1 or −1 is called a unit vector. A ba-
sis {e1, . . . , en} for V which consists of mutually orthogonal unit vectors is
called an orthonormal basis for V and we shall now prove that such bases
always exist.
Theorem 1.1.1 Let V be an n-dimensional real vector space on which is de-
ﬁned a nondegenerate, symmetric, bilinear form g : V × V →R. Then there
exists a basis {e1, . . . , en} for V such that g(ei, ej) = 0 if i ̸= j and
Q(ei) = ±1 for each i = 1, . . . , n. Moreover, the number of basis vectors
ei for which Q(ei) = −1 is the same for any such basis.
Proof:
We begin with an observation. Since g is nondegenerate there exists
a pair of vectors (v, w) for which g(v, w) ̸= 0. We claim that, in fact, there
must be a single vector u in V with Q(u) ̸= 0. Of course, if one of Q(v) or
Q(w) is nonzero we are done. On the other hand, if Q(v) = Q(w) = 0, then
Q(v+w) = Q(v)+2g(v, w)+Q(w) = 2g(v, w) ̸= 0 so we may take u = v+w.
The proof of the theorem is by induction on n. If n = 1 we select any u in
V with Q(u) ̸= 0 and deﬁne e1 = (|Q(u)|)−1/2u. Then Q(e1) = ±1 so {e1} is
the required basis.
Now we assume that n > 1 and that every inner product on a vector space
of dimension less than n has a basis of the required type. Let the dimension
of V be n. Again we begin by selecting a u in V such that Q(u) ̸= 0 and
letting en = (|Q(u)|)−1/2u so that Q(en) = ±1. Now we let W be the orthog-
onal complement in V of the subspace Span {en} of V spanned by {en}. By
Exercise 1.1.2, W is a subspace of V and since en is not in W, dim W < n.
The restriction of g to W × W is an inner product on W so the induction
hypothesis assures us of the existence of a basis {e1, . . . , em}, m = dim W,
for W such that g(ei, ej) = 0 if i ̸= j and Q(ei) = ±1 for i = 1, . . . , m. We
claim that m = n −1 and that {e1, . . . , em, en} is a basis for V.
Exercise 1.1.4 Show
that
the
vectors
{e1, . . . , em, en}
are
linearly
independent.
Since the number of elements in the set {e1, . . . , em, en} is m + 1 ≤n, both of
our assertions will follow if we can show that this set spans V. Thus, we let v be
an arbitrary element of V and consider the vector w = v −(Q(en)g(v, en))en.
Then w is in W since g(w, en) = g(v −(Q(en)g(v, en))en, en) = g(v, en) −
(Q(en))2g(v, en) = 0. Thus, we may write v = w1e1 + · · · + wmem +
(Q(en)g(v, en))en so {e1, . . . , em, en} spans V.

1.2 Minkowski Spacetime
9
To show that the number r of ei for which Q(ei) = −1 is the same for
any orthonormal basis we proceed as follows: If r = 0 the result is clear since
Q(v) ≥0 for every v in V, i.e., g is positive deﬁnite. If r > 0, then V will
have subspaces on which g is negative deﬁnite and so will have subspaces of
maximal dimension on which g is negative deﬁnite. We will show that r is the
dimension of any such maximal subspace W and thereby give an invariant
(basis-independent) characterization of r. Number the basis elements so that
{e1, . . . , er, er+1, . . . , en}, where Q(ei) = −1 for i = 1, . . . , r and Q(ei) = 1
for i = r + 1, . . . , n. Let X = Span{e1, . . . , er} be the subspace of V spanned
by {e1, . . . , er}. Then, since g is negative deﬁnite on X and dim X = r, we
ﬁnd that r ≤dim W. To show that r ≥dim W as well we deﬁne a map
T : W →X as follows: If w = n
i=1 wiei is in W we let Tw = r
i=1 wiei.
Then T is obviously linear. Suppose w is such that Tw = 0. Then for each
i = 1, . . . , r, wi = 0. Thus,
Q(w) = g
⎛
⎝
n

i=r+1
wiei,
n

j=r+1
wjej
⎞
⎠=
n

i,j=r+1
g(ei, ej)wiwj =
n

i=r+1
(wi)2
which is greater than or equal to zero. But g is negative deﬁnite on W so
we must have wi = 0 for i = r + 1, . . . , n, i.e., w = 0. Thus, the null space
of T is {0} and T is therefore an isomorphism of W onto a subspace of X.
Consequently, dim W ≤dim X = r as required.
■
The number r of ei in any orthonormal basis for g with Q(ei) = −1 is called
the index of g. Henceforth we will assume that all orthonormal bases are
indexed in such a way that these ei appear at the end of the list and so are
numbered as follows:
{e1, e2, . . . , en−r, en−r+1, . . . , en}
where Q(ei) = 1 for i = 1, 2, . . . , n−r and Q(ei) = −1 for i = n−r+1, . . . , n.
Relative to such a basis if v = viei and w = wiei, then we have
g(v, w) = v1w1 + · · · + vn−rwn−r −vn−r+1wn−r+1 −· · · −vnwn.
1.2 Minkowski Spacetime
Minkowski spacetime is a 4-dimensional real vector space M on which is
deﬁned a nondegenerate, symmetric, bilinear form g of index 1. The elements
of M will be called events and g is referred to as a Lorentz inner product on
M. Thus, there exists a basis {e1, e2, e3, e4} for M with the property that if
v = vaea and w = waea, then
g(v, w) = v1w1 + v2w2 + v3w3 −v4w4.

10
1 Geometrical Structure of M
The elements of M are “events” and, as we suggested in the Introduction,
are to be thought of intuitively as actual or physically possible point-events.
An orthonormal basis {e1, e2, e3, e4} for M “coordinatizes” this event world
and is to be identiﬁed with a “frame of reference”. Thus, if x = x1e1 +x2e2 +
x3e3 + x4e4, we regard the coordinates (x1, x2, x3, x4) of x relative to {ea}
as the spatial (x1, x2, x3) and time (x4) coordinates supplied the event x by
the observer who presides over this reference frame. As we proceed with the
development we will have occasion to expand upon, reﬁne and add additional
elements to this basic physical interpretation, but, for the present, this will
suﬃce.
In the interest of economy we shall introduce a 4 × 4 matrix η deﬁned by
η =
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
−1
⎤
⎥⎥⎦,
whose entries will be denoted either ηab or ηab, the choice in any particular
situation being dictated by the requirements of the summation convention.
Thus, ηab = ηab = 1 if a = b = 1, 2, 3, −1 if a = b = 4 and 0 otherwise.
As a result we may write g(ea, eb) = ηab = ηab and, with the summation
convention, g(v, w) = ηabvawb.
Since our Lorentz inner product g on M is not positive deﬁnite there exist
nonzero vectors v in M for which g(v, v) = 0, e.g., v = e1 + e4 is one such
since g(v, v) = Q(e1) + 2g(e1, e4) + Q(e4) = 1 + 0 −1 = 0. Such vectors are
said to be null (or lightlike, for reasons which will become clear shortly) and
M actually has bases which consist exclusively of this type of vector.
Exercise 1.2.1 Construct a null basis for M, i.e., a set of four linearly
independent null vectors.
Such a null basis cannot consist of mutually orthogonal vectors, however.
Theorem 1.2.1 Two nonzero null vectors v and w in M are orthogonal if
and only if they are parallel, i.e., iﬀthere is a t in R such that v = tw.
Exercise 1.2.2 Prove Theorem 1.2.1. Hint: The Schwartz Inequality for R3
asserts that if x = (x1, x2, x3) and y = (y1, y2, y3), then
(x1y1 + x2y2 + x3y3)2 ≤((x1)2 + (x2)2 + (x3)2)((y1)2 + (y2)2 + (y3)2)
and that equality holds if and only if x and y are linearly dependent.
■
Next consider two distinct events x0 and x for which the displacement vector
v = x −x0 from x0 to x is null, i.e., Q(v) = Q(x −x0) = 0. Relative to any
orthonormal basis {ea}, if x = xaea and x0 = xa
0ea, then

x1 −x1
0
2 +

x2 −x2
0
2 +

x3 −x3
0
2 −

x4 −x4
0
2 = 0.
(1.2.1)

1.2 Minkowski Spacetime
11
Fig. 1.2.1
But we have seen this before. It is precisely the condition which, in the
Introduction, we decided describes the relationship between two events that
lie on the worldline of some photon. For this reason, and because of the formal
similarity between (1.2.1) and the equation of a right circular cone in R3, we
deﬁne the null cone (or light cone) CN(x0) at x0 in M by
CN(x0) = {x ∈M : Q(x −x0) = 0}
and picture it by suppressing the third spatial dimension x3 (see Figure 1.2.1).
CN(x0) therefore consists of all those events in M that are “connectible to
x0 by a light ray”. For any such event x (other than x0 itself) we deﬁne the
null worldline (or light ray) Rx0,x containing x0 and x by
Rx0,x = {x0 + t(x −x0) : t ∈R}
and think of it as the worldline of that particular photon which experiences
both x0 and x.
Exercise 1.2.3 Show that if Q(x −x0) = 0, then Rx,x0 = Rx0,x.
CN(x0) is just the union of all the light rays through x0. Indeed,
Theorem 1.2.2 Let x0 and x be two distinct events with Q(x−x0) = 0. Then
Rx0,x = CN(x0) ∩CN(x).
(1.2.2)
Proof:
First let z = x0 + t(x −x0) be an element of Rx0,x. Then z −x0 =
t(x−x0) so Q(z−x0) = t2Q(x−x0) = 0 so z is in CN(x0). With Exercise 1.2.3
it follows in the same way that z is in CN(x) and so Rx0,x ⊆CN(x0) ∩CN(x).

12
1 Geometrical Structure of M
To prove the reverse containment we assume that z is in CN(x0) ∩CN(x).
Then each of the vectors z −x, z −x0 and x0 −x is null. But z −x0 =
(z−x)−(x0−x) so 0 = Q(z−x0) = Q(z−x) −2g(z−x, x0 −x)+Q(x0−x) =
−2g(z −x, x0 −x). Thus, g(z −x, x0 −x) = 0. If z = x we are done. If z ̸= x,
then, since x ̸= x0, we may apply Theorem 1.2.1 to the orthogonal null
vectors z −x and x0 −x to obtain a t in R such that z −x = t(x0 −x) and
it follows that z is in Rx0,x as required.
■
For reasons which may not be apparent at the moment, but will become
clear shortly, a vector v in M is said to be timelike if Q(v) < 0 and spacelike
if Q(v) > 0.
Exercise 1.2.4 Use an orthonormal basis for M to construct a few vectors
of each type.
If v is the displacement vector x −x0 between two events, then, relative to
any orthonormal basis for M, Q(x −x0) < 0 becomes (Δx1)2 + (Δx2)2 +
(Δx3)2 < (Δx4)2 (x −x0 is inside the null cone at x0). Thus, the (squared)
spatial separation of the two events is less than the (squared) distance light
would travel during the time lapse between the events (remember that x4 is
measured in light travel time). If x−x0 is spacelike the inequality is reversed,
we picture x −x0 outside the null cone at x0 and the spatial separation of x0
and x is so great that not even a photon travels quickly enough to experience
both events.
If {e1, e2, e3, e4} and {ˆe1, ˆe2, ˆe3, ˆe4} are two orthonormal bases for M, then
there is a unique linear transformation L : M →M such that L(ea) = ˆea for
each a = 1, 2, 3, 4. As we shall see, such a map “preserves the inner product
of M”, i.e., is of the following type: A linear transformation L : M →M is
said to be an orthogonal transformation of M if g(Lx, Ly) = g(x, y) for all x
and y in M.
Exercise 1.2.5 Show that, since the inner product on M is nondegener-
ate, an orthogonal transformation is necessarily one-to-one and therefore an
isomorphism.
Lemma 1.2.3 Let L : M →M be a linear transformation. Then the fol-
lowing are equivalent:
(a) L is an orthogonal transformation.
(b) L preserves the quadratic form of M, i.e., Q(Lx) = Q(x) for all x in M.
(c) L carries any orthonormal basis for M onto another orthonormal basis
for M.
Exercise 1.2.6 Prove Lemma 1.2.3. Hint: To prove that (b) implies (a)
compute L(x + y) · L(x + y) −L(x −y) · L(x −y).
■
Now let L : M →M be an orthogonal transformation of M and
{e1, e2, e3, e4} an orthonormal basis for M. By Lemma 1.2.3, ˆe1 = Le1, ˆe2 =
Le2, ˆe3 = Le3 and ˆe4 = Le4 also form an orthonormal basis for M. In

1.2 Minkowski Spacetime
13
particular, each eu, u = 1, 2, 3, 4, can be expressed as a linear combination
of the ˆea:
eu = Λ1
uˆe1 + Λ2
uˆe2 + Λ3
uˆe3 + Λ4
uˆe4 = Λa
uˆea,
u = 1, 2, 3, 4,
(1.2.3)
where the Λau are constants. Now, the orthogonality conditions g(ec, ed) = ηcd,
c, d = 1, 2, 3, 4, can be written
Λ1
cΛ1
d + Λ2
cΛ2
d + Λ3
cΛ3
d −Λ4
cΛ4
d = ηcd
(1.2.4)
or, with the summation convention,
ΛacΛbdηab = ηcd,
c, d = 1, 2, 3, 4.
(1.2.5)
Exercise 1.2.7 Show that (1.2.5) is equivalent to
Λa
cΛb
dηcd = ηab,
a, b = 1, 2, 3, 4.
(1.2.6)
We deﬁne the matrix Λ = [Λab]a,b=1,2,3,4 associated with the orthogonal
transformation L and the orthonormal basis {ea} by
Λ =
⎡
⎢⎢⎣
Λ11
Λ12
Λ13
Λ14
Λ21
Λ22
Λ23
Λ24
Λ31
Λ32
Λ33
Λ34
Λ41
Λ42
Λ43
Λ44
⎤
⎥⎥⎦.
Observe that Λ is actually the matrix of L−1 relative to the basis {ˆea}.
Heuristically, conditions (1.2.5) assert that “the columns of Λ are mutually
orthogonal unit vectors”, whereas (1.2.6) makes the same statement about
the rows.
We regard the matrix Λ associated with L and {ea} as a coordinate trans-
formation matrix in the usual way. Speciﬁcally, if the event x in M has co-
ordinates x = x1e1 +x2e2 +x3e3 +x4e4 relative to {ea}, then its coordinates
relative to {ˆea} = {Lea} are x = ˆx1ˆe1 + ˆx2ˆe2 + ˆx3ˆe3 + ˆx4ˆe4, where
ˆx1 = Λ1
1x1 + Λ1
2x2 + Λ1
3x3 + Λ1
4x4,
ˆx2 = Λ21x1 + Λ22x2 + Λ23x3 + Λ24x4,
ˆx3 = Λ31x1 + Λ32x2 + Λ33x3 + Λ34x4,
ˆx4 = Λ41x1 + Λ42x2 + Λ43x3 + Λ44x4,
which we generally write more concisely as
ˆxa = Λabxb,
a = 1, 2, 3.4.
(1.2.7)
Exercise 1.2.8 By performing the indicated matrix multiplications show
that (1.2.5) [and therefore (1.2.6)] is equivalent to
ΛT ηΛ = η,
(1.2.8)
where T means “transpose”.

14
1 Geometrical Structure of M
Notice that we have seen (1.2.8) before. It is just equation (0.4) of the
Introduction, which perhaps seems somewhat less mysterious now than it
did then. Indeed, (1.2.8) is now seen to be the condition that Λ is the
matrix of a linear transformation which preserves the quadratic form of
M. In particular, if x −x0 is the displacement vector between two events
for which Q(x −x0) = 0, then both (Δx1)2 + (Δx2)2 + (Δx3)2 −(Δx4)2
and (Δˆx1)2 + (Δˆx2)2 + (Δˆx3)2 −(Δˆx4)2, where the Δˆxa are, from (1.2.7),
Δˆxa = ΛabΔxb, are zero. Physically, the two observers presiding over the
hatted and unhatted reference frames agree that x0 and x are “connectible
by a light ray”, i.e., they agree on the speed of light.
Any 4 × 4 matrix Λ that satisﬁes (1.2.8) is called a general (homogeneous)
Lorentz transformation. At times we shall indulge in a traditional abuse of
terminology and refer to the coordinate transformation (1.2.7) as a Lorentz
transformation. Since the orthogonal transformations of M are isomorphisms
and therefore invertible, the matrix Λ associated with such an orthogonal
transformation must be invertible [also see (1.3.6)]. From (1.2.8) we ﬁnd that
ΛT ηΛ = η implies ΛT η = ηΛ−1 so that Λ−1 = η−1ΛT η or, since η−1 = η,
Λ−1 = ηΛTη.
(1.2.9)
Exercise 1.2.9 Show that the set of all general (homogeneous) Lorentz
transformations forms a group under matrix multiplication, i.e., that it is
closed under the formation of products and inverses. This group is called the
general (homogeneous) Lorentz group and we shall denote it by LGH .
We shall denote the entries in the matrix Λ−1 by Λa
b so that, by (1.2.9),
⎡
⎢⎢⎣
Λ1
1
Λ2
1
Λ3
1
Λ4
1
Λ1
2
Λ2
2
Λ3
2
Λ4
2
Λ1
3
Λ2
3
Λ3
3
Λ4
3
Λ1
4
Λ2
4
Λ3
4
Λ4
4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
Λ11
Λ21
Λ31
−Λ41
Λ12
Λ22
Λ32
−Λ42
Λ13
Λ23
Λ33
−Λ43
−Λ14
−Λ24
−Λ34
Λ44
⎤
⎥⎥⎦.
(1.2.10)
Exercise 1.2.10 Show that
Λa
b = ηacηbdΛc
d,
a, b = 1, 2, 3, 4,
(1.2.11)
and similarly
Λab = ηacηbdΛc
d,
a, b = 1, 2, 3, 4.
(1.2.12)
Since we have seen (Exercise 1.2.9) that Λ−1 is in LGH whenever Λ is it must
also satisfy conditions analogous to (1.2.5) and (1.2.6), namely,
Λa
cΛb
dηab = ηcd,
c, d = 1, 2, 3, 4,
(1.2.13)
and
Λa
cΛb
dηcd = ηab,
a, b = 1, 2, 3, 4.
(1.2.14)

1.3 The Lorentz Group
15
The analogues of (1.2.3) and (1.2.7) are
ˆeu = Λu
aea,
u = 1, 2, 3, 4,
(1.2.15)
and
xb = Λa
bˆxa,
b = 1, 2, 3, 4.
(1.2.16)
1.3 The Lorentz Group
Observe that by setting c = d = 4 in (1.2.5) one obtains

Λ44
2 = 1 +

Λ14
2 +

Λ24
2 +

Λ34
2 so that, in particular,

Λ44
2 ≥1. Consequently,
Λ44 ≥1 or Λ44 ≤−1
(1.3.1)
An element Λ of LGH
is said to be orthochronous
if Λ44 ≥1 and
nonorthochronous if Λ44 ≤−1. Nonorthochronous Lorentz transforma-
tions have certain unsavory characteristics which we now wish to expose.
First, however, the following extremely important preliminary.
Theorem 1.3.1 Suppose that v is timelike and w is either timelike or null
and nonzero. Let {ea} be an orthonormal basis for M with v = vaea and
w = waea. Then either
(a) v4w4 > 0, in which case g(v, w) < 0, or
(b) v4w4 < 0, in which case g(v, w) > 0.
Proof:
By assumption we have g(v, v)=(v1)2 + (v2)2 + (v3)2 −(v4)2 < 0
and (w1)2 + (w2)2 + (w3)2−(w4)2 ≤0 so (v4w4)2 > ((v1)2 + (v2)2 +
(v3)2)((w1)2 +(w2)2 +(w3)2) ≥(v1w1 +v2w2 +v3w3)2, the second inequality
following from the Schwartz Inequality for R3 (see Exercise 1.2.2). Thus, we
ﬁnd that
v4w4 >
v1w1 + v2w2 + v3w3,
so, in particular, v4w4 ̸= 0 and, moreover, g(v, w) ̸= 0. Suppose that
v4w4 > 0. Then v4w4 = |v4w4| > |v1w1+v2w2+v3w3| ≥v1w1+v2w2 +v3w3
and so v1w1 + v2w2 + v3w3 −v4w4 < 0, i.e., g(v, w) < 0. On the other hand,
if v4w4 < 0, then g(v, −w) < 0 so g(v, w) > 0.
■
Corollary 1.3.2 If a nonzero vector in M is orthogonal to a timelike vector,
then it must be spacelike.
We denote by τ the collection of all timelike vectors in M and deﬁne a
relation ∼on τ as follows: If v and w are in τ, then v ∼w if and only if
g(v, w) < 0 (so that v4 and w4 have the same sign in any orthonormal basis).

16
1 Geometrical Structure of M
Exercise 1.3.1 Verify that ∼is an equivalence relation on τ with precisely
two equivalence classes. That is, show that ∼is
1. reﬂexive (v ∼v for every v in τ),
2. symmetric (v ∼w implies w ∼v),
3. transitive (v ∼w and w ∼x imply v ∼x)
and that τ is the union of two disjoint subsets τ + and τ−with the property
that v ∼w for all v and w in τ+, v ∼w for all v and w in τ −and v /∼w if
one of v or w is in τ + and the other is in τ−.
Fig. 1.3.1
We think of the elements of τ+ (and τ−) as having the same time orientation.
More speciﬁcally, we select (arbitrarily) τ+ and refer to its elements as future-
directed timelike vectors, whereas the vectors in τ−we call past-directed.
Exercise 1.3.2 Show that τ + (and τ−) are cones, i.e., that if v and w are
in τ +(τ −) and r is a positive real number, then rv and v + w are also in
τ+(τ −).
For each x0 in M we deﬁne the time cone CT(x0), future time cone C+
T (x0)
and past time cone C−
T (x0) at x0 by
CT (x0) = {x ∈M : Q(x −x0) < 0} ,
C+
T (x0) =

x ∈M : x −x0 ∈τ +
= CT(x0) ∩τ +,
and
C−
T (x0) =

x ∈M : x −x0 ∈τ −
= CT(x0) ∩τ −.
We picture CT (x0) as the interior of the null cone CN(x0). It is the disjoint
union of C+
T (x0) and C−
T (x0) and we shall adopt the convention that our
pictures will always be drawn with future-directed vectors “pointing up” (see
Figure 1.3.1).

1.3 The Lorentz Group
17
We wish to extend the notion of past- and future-directed to nonzero null
vectors as well. First we observe that if n is a nonzero null vector, then
n · v has the same sign for all v in τ +. To see this we suppose that there
exist vectors v1 and v2 in τ + such that n · v1 < 0 and n · v2 > 0. We may
assume that |n · v1| = n · v2 since if this is not the case we can replace
v1 by (n · v2/|n · v1|)v1, which is still in τ + by Exercise 1.3.2 and satisﬁes
g(n, (n·v2/|n·v1|)v1) = (n·v2/|n·v1|)g(n, v1) = −n·v2. Thus, n·v1 = −n·v2
so n·v1+n·v2 = 0 and therefore n·(v1+v2) = 0. But, again by Exercise 1.3.2,
v1 + v2 is in τ + and so, in particular, is timelike. Since n is nonzero and null
this contradicts Corollary 1.3.2. Thus, we may say that a nonzero null vector
n is future-directed if n · v < 0 for all v in τ + and past-directed if n · v > 0 for
all v in τ +.
Exercise 1.3.3 Show that two nonzero null vectors n1 and n2 have the same
time orientation (i.e., are both past-directed or both future-directed) if and
only if n4
1 and n4
2 have the same sign relative to any orthonormal basis for M.
For any x0 in M we deﬁne the future null cone at x0 by C+
N(x0) =
{x ∈CN(x0) : x −x0 is future-directed} and the past null cone at x0 by
C−
N(x0) = {x ∈CN(x0) : x −x0 is past-directed}. Physically, event x is in
C+
N(x0) if x0 and x respectively can be regarded as the emission and recep-
tion of a light signal. Consequently, C+
N(x0) may be thought of as the history
in spacetime of a spherical electromagnetic wave (photons in all directions)
whose emission event is x0 (see Figure 1.3.2).
The disagreeable nature of nonorthochronous Lorentz transformations is
that they always reverse time orientations (and so presumably relate reference
frames in which someone’s clock is running backwards).
Theorem 1.3.3 Let
Λ = [Λab]a,b=1,2,3,4
be
an
element
of
LGH
and
{ea}a=1,2,3,4 an orthonormal basis for M. Then the following are equivalent:
(a) Λ is orthochronous.
(b) Λ preserves the time orientation of all nonzero null vectors, i.e., if v =
vaea is a nonzero null vector, then the numbers v4 and ˆv4 = Λ4bvb have
the same sign.
(c) Λ preserves the time orientation of all timelike vectors.
Proof:
Let v = vaea be a vector which is either timelike or null and nonzero.
By the Schwartz Inequality for R3 we have

Λ41v1 + Λ42v2 + Λ43v32 ≤
 3

i=1

Λ4i
2
  3

i=1

vi2

.
(1.3.2)
Now, by (1.2.6) with a = b = 4, we have

Λ41
2 +

Λ42
2 +

Λ43
2 −

Λ44
2 = −1
(1.3.3)

18
1 Geometrical Structure of M
Fig. 1.3.2
and so

Λ44
2 >

Λ41
2+

Λ42
2+

Λ43
2. Moreover, since v is either timelike
or null, (v4)2 ≥(v1)2 + (v2)2 + (v3)2. Since v is nonzero, (1.3.2) therefore
yields

Λ41v1 + Λ42v2 + Λ43v32 <

Λ44v42, which we may write as

Λ4
1v1 + Λ4
2v2 + Λ4
3v3 −Λ4
4v4 
Λ4
1v1 + Λ4
2v2 + Λ4
3v3 + Λ4
4v4
< 0.
(1.3.4)
Deﬁne w in M by w = Λ41e1 + Λ42e2 + Λ43e3 + Λ44e4. By (1.3.3), w is
timelike. Moreover, (1.3.4) can now be written
(v · w)ˆv4 < 0.
(1.3.5)
Consequently, v · w and ˆv4 have opposite signs.
We now show that Λ44 ≥1 if and only if v4 and ˆv4 have the same sign.
First suppose Λ44 ≥1. If v4 > 0, then, by Theorem 1.3.1, v · w < 0 so ˆv4 > 0
by (1.3.5). Similarly, if v4 < 0, then v·w > 0 so ˆv4 < 0. Thus, Λ44 ≥1 implies
that v4 and ˆv4 have the same sign. In the same way, Λ44 ≤−1 implies that
v4 and ˆv4 have opposite signs.
■
Notice that we have actually shown that if Λ is nonorthochronous, then it
necessarily reverses the time orientation of all timelike and nonzero null vec-
tors. For this reason we elect to restrict our attention henceforth to the or-
thochronous elements of LGH . Since such a Lorentz transformation never
reverses the time orientation of a timelike vector we may also limit ourselves
to orthonormal bases {e1, e2, e3, e4} with e4 future-directed. At this point
the reader may wish to return to the Introduction with a somewhat better
understanding of why the condition Λ44 ≥1 appeared in Zeeman’s Theorem.

1.3 The Lorentz Group
19
There is yet one more restriction we would like to impose on our
Lorentz transformations. Observe that taking determinants on both sides
of (1.2.8) yields (det ΛT)(det η)(det Λ) = det η so that, since det ΛT =
det Λ, (det Λ)2 = 1 and therefore
det Λ = 1
or
det Λ = −1.
(1.3.6)
We shall say that a Lorentz transformation Λ is proper if det Λ = 1 and
improper if det Λ = −1.
Exercise 1.3.4 Show that an orthochronous Lorentz transformation is im-
proper if and only if it is of the form
⎡
⎢⎢⎣
−1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦Λ,
(1.3.7)
where Λ is proper and orthochronous.
Notice that the matrix on the left in (1.3.7) is an orthochronous Lorentz
transformation and, as a coordinate transformation, has the eﬀect of chang-
ing the sign of the ﬁrst spatial coordinate, i.e., of reversing the spatial orienta-
tion (left-handed to right-handed or right-handed to left-handed). Since there
seems to be no compelling reason to make such a change we intend to restrict
our attention to the set L of proper, orthochronous Lorentz transformations.
Having done so we may further limit the orthonormal bases we consider by
selecting an orientation for the spatial coordinate axes. Speciﬁcally, we de-
ﬁne an admissible basis for M to be an orthonormal basis {e1, e2, e3, e4}
with e4 timelike and future-directed and {e1, e2, e3} spacelike and “right-
handed”, i.e., satisfying e1 × e2 · e3 = 1 (since the restriction of g to the
span of {e1, e2, e3} is the usual dot product on R3, the cross product and dot
product here are the familiar ones from vector calculus). At this point we
fully identify an “admissible basis” with an “admissible frame of reference”
as discussed in the Introduction. Any two such bases (frames) are related by
a proper, orthochronous Lorentz transformation.
Exercise 1.3.5 Show that the set L of proper, orthochronous Lorentz trans-
formations is a subgroup of LGH , i.e., that it is closed under the formation
of products and inverses.
Generally, we shall refer to L simply as the Lorentz group and its elements
as Lorentz transformations with the understanding that they are all proper
and orthochronous. Occasionally it is convenient to enlarge the group of coor-
dinate transformations to include spacetime translations (see the statement
of Zeeman’s Theorem in the Introduction), thereby obtaining the so-called
inhomogeneous Lorentz group or Poincar´e group. Physically, this amounts to
allowing “admissible” observers to use diﬀerent spacetime origins.

20
1 Geometrical Structure of M
The Lorentz group L has an important subgroup R consisting of those
R = [Rab] of the form
R =
⎡
⎢⎢⎣
0

Rij

0
0
0
0
0
1
⎤
⎥⎥⎦,
where [Rij]i,j=1,2,3
is a
unimodular
orthogonal matrix,
i.e.,
satisﬁes
det[Rij] = 1 and [Rij]T = [Rij]−1. Observe that the orthogonality con-
ditions (1.2.5) are clearly satisﬁed by such an R and that, moreover, R44 = 1
and det R = det[Rij] = 1 so that R is indeed in L. The coordinate transfor-
mation associated with R corresponds physically to a rotation of the spatial
coordinate axes within a given frame of reference. For this reason R is called
the rotation subgroup of L and its elements are called rotations in L.
Lemma 1.3.4 Let Λ = [Λab]a,b=1,2,3,4 be a proper, orthochronous Lorentz
transformation. Then the following are equivalent:
(a) Λ is a rotation,
(b) Λ14 = Λ24 = Λ34 = 0,
(c) Λ41 = Λ42 = Λ43 = 0,
(d) Λ44 = 1.
Proof:
Set c = d = 4 in (1.2.5) to obtain

Λ1
4
2 +

Λ2
4
2 +

Λ3
4
2 −

Λ4
4
2 = −1.
(1.3.8)
Similarly, with a = b = 4, (1.2.6) becomes

Λ41
2 +

Λ42
2 +

Λ43
2 −

Λ44
2 = −1.
(1.3.9)
The equivalence of (b), (c) and (d) now follows immediately from (1.3.8) and
(1.3.9) and the fact that Λ is assumed orthochronous. Since a rotation in L
satisﬁes (b), (c) and (d) by deﬁnition, all that remains is to show that if Λ
satisﬁes one (and therefore all) of these conditions, then

Λij

i,j=1,2,3 is a
unimodular orthogonal matrix.
Exercise 1.3.6 Complete the proof.
■
Exercise 1.3.7 Use Lemma 1.3.4 to show that R is a subgroup of L, i.e.,
that it is closed under the formation of inverses and products.
Exercise 1.3.8 Show that an element of L has the same fourth row as
[Λab]a,b=1,2,3,4 if and only if it can be obtained from [Λab] by multiplying on
the left by some rotation in L. Similarly, an element of L has the same fourth
column as [Λab] if and only if it can be obtained from [Λab] by multiplying
on the right by an element of R.

1.3 The Lorentz Group
21
There are 16 parameters in every Lorentz transformation, although, by
virtue of the relations (1.2.5), these are not all independent. We now derive
simple physical interpretations for some of these parameters. Thus, we con-
sider two admissible bases {ea} and {ˆea} and the corresponding admissible
frames of reference S and ˆS. Any two events on the worldline of a point
which can be interpreted physically as being at rest in ˆS have coordinates in
ˆS which satisfy Δˆx1 = Δˆx2 = Δˆx3 = 0 and Δˆx4 = the time separation of the
two events as measured in ˆS. From (1.2.16) we ﬁnd that the corresponding
coordinate diﬀerences in S are
Δxb = Λa
bΔˆxa = Λ4
bΔˆx4.
(1.3.10)
From (1.3.10) and the fact that Λ44 and Λ4
4 are nonzero it follows that the
ratios
Δxi
Δx4 = Λ4
i
Λ4
4 = −Λ4i
Λ44
,
i = 1, 2, 3,
are constant and independent of the particular point at rest in ˆS we choose
to examine. Physically, these ratios are interpreted as the components of the
ordinary velocity 3-vector of ˆS relative to S:
⇀u = u1e1 + u2e2 + u3e3, where ui = Λ4
i
Λ4
4 = −Λ4i
Λ44
, i = 1, 2, 3
(1.3.11)
(notice that we use the term “3-vector” and the familiar vector notation
to distinguish such highly observer-dependent spatial vectors whose physical
interpretations are not invariant under Lorentz transformations, but which
are familiar from physics). Similarly, the velocity 3-vector of S relative to ˆS is
⇀
ˆu = ˆu1ˆe1 + ˆu2ˆe2 + ˆu3ˆe3, where ˆui = Λi4
Λ44
−Λi
4
Λ4
4 ,
i = 1, 2, 3.
(1.3.12)
Next observe that 3
i=1(Δxi/Δx4)2 = (Λ44)−2 3
i=1(Λ4i)2 = (Λ44)−2 ·
[(Λ44)2 −1]. Similarly, 3
i=1(Δˆxi/Δˆx4)2 = (Λ44)−2[(Λ44)2 −1]. Physically,
we interpret these equalities as asserting that the velocity of ˆS relative to S
and the velocity of S relative to ˆS have the same constant magnitude which
we shall denote by β. Thus, β2 = 1 −(Λ44)−2, so, in particular, 0 ≤β2 < 1
and β = 0 if and only if Λ is a rotation (Lemma 1.3.4). Solving for Λ44 (and
taking the positive square root since Λ is assumed orthochronous) yields
Λ4
4 = (1 −β2)−1
2 (= Λ4
4).
(1.3.13)
The quantity (1 −β2)−1/2 will occur frequently and is often designated γ.
Assuming that Λ is not a rotation we may write
⇀u as
⇀u = β
⇀
d = β(d1e1 + d2e2 + d3e3),
di = ui/β,
(1.3.14)

22
1 Geometrical Structure of M
where
⇀
d is the direction 3-vector of ˆS relative to S and the di are interpreted
as the direction cosines of the directed line segment in  along which the
observer in S sees ˆ moving. Similarly,
⇀
ˆu = β
⇀
ˆd = β( ˆd1ˆe1 + ˆd2ˆe2 + ˆd3ˆe3),
ˆdi = ˆui/β.
(1.3.15)
Exercise 1.3.9 Show that the di are the components of the normalized
projection of ˆe4 onto the subspace spanned by {e1, e2, e3}, i.e., that
di =
⎛
⎝
3

j=1
(ˆe4 · ej)2
⎞
⎠
−1
2
(ˆe4 · ei),
i = 1, 2, 3,
(1.3.16)
and similarly
ˆdi =
⎛
⎝
3

j=1
(e4 · ˆej)2
⎞
⎠
−1
2
(e4 · ˆei),
i = 1, 2, 3.
(1.3.17)
Exercise 1.3.10 Show that ˆe4 = γ(β
⇀
d +e4) and, similarly, e4 = γ(β
⇀
ˆd +ˆe4)
and notice that it follows from these that e4 · ˆe4 = ˆe4 · e4 = −γ.
Comparing (1.3.11) and (1.3.14) and using (1.3.13) we obtain
Λ4
i = −Λ4i = β(1 −β2)−1
2 di,
i = 1, 2, 3,
(1.3.18)
and similarly
Λi4 = −Λi
4 = β(1 −β2)−1
2 ˆdi,
i = 1, 2, 3.
(1.3.19)
Equations (1.3.13), (1.3.18) and (1.3.19) give the last row and column of Λ
in terms of physically measurable quantities and even at this stage a number
of interesting kinematic consequences become apparent. Indeed, from (1.2.7)
we obtain
Δˆx4 = −βγ

d1Δx1 + d2Δx2 + d3Δx3
+ γΔx4
(1.3.20)
for any two events. Let us consider the special case of two events on the
worldline of a point at rest in S. Then Δx1 = Δx2 = Δx3 = 0 so (1.3.20)
becomes
Δˆx4 = γΔx4 =
1

1 −β2 Δx4.
(1.3.21)
In particular, Δˆx4 = Δx4 if and only if Λ is a rotation. Any relative motion
of S and ˆS gives rise to a time dilation eﬀect according to which Δˆx4 > Δx4.
Since our two events can be interpreted as two readings on one of the clocks
at rest in S, an observer in ˆS will conclude that the clocks in S are running
slow (even though they are, by assumption, identical).

1.3 The Lorentz Group
23
Exercise 1.3.11 Show that this time dilation eﬀect is entirely symmetrical,
i.e., that for two events with Δˆx1 = Δˆx2 = Δˆx3 = 0,
Δx4 = γΔˆx4 =
1

1 −β2 Δˆx4.
(1.3.22)
We shall return to this phenomenon of time dilation in much greater detail
after we have introduced a geometrical construction for picturing it. Never-
theless, we should point out at the outset that it is in no sense an illusion;
it is quite “real” and can manifest itself in observable phenomena. One such
instance occurs in the study of cosmic rays (“showers” of various types of
elementary particles from space which impact the earth). Certain types of
mesons that are encountered in cosmic radiation are so short-lived (at rest)
that even if they could travel at the speed of light (which they cannot) the
time required to traverse our atmosphere would be some ten times their nor-
mal life span. They should not be able to reach the earth, but they do. Time
dilation, in a sense, “keeps them young”. The meson’s notion of time is not
the same as ours. What seems a normal lifetime to the meson appears much
longer to us. It is well to keep in mind also that we have been rather vague
about what we mean by a “clock”. Essentially any phenomenon involving ob-
servable change (successive readings on a Timex, vibrations of an atom, the
lifetime of a meson, or a human being) is a “clock” and is therefore subject
to the eﬀects of time dilation. Of course, the eﬀects will be negligibly small
unless β is quite close to 1 (the speed of light). On the other hand, as β →1,
(1.3.21) shows that Δˆx4 →∞so that as speeds approach that of light the
eﬀects become inﬁnitely great.
Another special case of (1.3.20) is also of interest. Let us suppose that our
two events are judged simultaneous in S, i.e., that Δx4 = 0. Then
Δˆx4 = −βγ

d1Δx1 + d2Δx2 + d3Δx3
.
(1.3.23)
Again assuming that β ̸= 0 we ﬁnd that, in general, Δˆx4 will not be zero,
i.e., that the two events will not be judged simultaneous in ˆS. Indeed, S and
ˆS will agree on the simultaneity of these two events if and only if the spatial
locations of the events in  bear a very special relation to the direction in
 along which ˆ is moving, namely,
d1Δx1 + d2Δx2 + d3Δx3 = 0
(1.3.24)
(the displacement vector in  between the locations of the two events is
either zero or nonzero and perpendicular to the direction of ˆ’s motion in
). Otherwise, Δˆx4 ̸= 0 and we have an instance of what is called the
relativity of simultaneity. Notice, incidentally, that such disagreement can
arise only for spatially separated events. More precisely, if in some admissible
frame S two events x and x0 are simultaneous and occur at the same spatial
location, then Δxa = 0 for a = 1, 2, 3, 4 so x −x0 = 0. Since the Lorentz
transformations are linear it follows that Δˆxa = 0 for a = 1, 2, 3, 4, i.e., the
events are also simultaneous and occur at the same spatial location in ˆS.
Again, we will return to this phenomenon in much greater detail shortly.

24
1 Geometrical Structure of M
It will be useful at this point to isolate a certain subgroup of the Lorentz
group L which contains all of the physically interesting information about
Lorentz transformations, but has much of the unimportant detail pruned
away. We do this in the obvious way by assuming that the spatial axes
of S and ˆS have a particularly simple relative orientation. Speciﬁcally, we
consider the special case in which the direction cosines di and ˆdi are given
by d1 = 1, ˆd1 = −1 and d2 = ˆd2 = d3 = ˆd3 = 0. Thus, the direction vectors
are
⇀
d = e1 and
⇀
ˆd = −ˆe1. Physically, this corresponds to the situation in
which an observer in S sees ˆ moving in the direction of the positive x1-axis
and an observer in ˆS sees  moving in the direction of the negative ˆx1-axis.
Since the origins of the spatial coordinate systems of S and ˆS coincided at
x4 = ˆx4 = 0, we picture the motion of these two systems as being along their
common x1-, ˆx1-axis. Now, from (1.3.13), (1.3.18) and (1.3.19) we ﬁnd that
the Lorentz transformation matrix Λ must have the form
Λ =
⎡
⎢⎢⎣
Λ11
Λ12
Λ13
−βγ
Λ21
Λ22
Λ23
0
Λ31
Λ32
Λ33
0
−βγ
0
0
γ
⎤
⎥⎥⎦.
Exercise 1.3.12 Use the orthogonality conditions (1.2.5) and (1.2.6) to
show that Λ must take the form
Λ =
⎡
⎢⎢⎣
γ
0
0
−βγ
0
Λ22
Λ23
0
0
Λ32
Λ33
0
−βγ
0
0
γ
⎤
⎥⎥⎦,
(1.3.25)
where

Λij

i,j=2,3 is a 2 × 2 unimodular orthogonal matrix, i.e., a rotation of
the plane R2.
To discover the diﬀerences between these various elements of L we con-
sider ﬁrst the simplest possible choice for the 2 × 2 unimodular orthogo-
nal matrix [Λij]i,j=2,3, i.e., the identity matrix. The corresponding Lorentz
transformation is
Λ =
⎡
⎢⎢⎣
γ
0
0
−βγ
0
1
0
0
0
0
1
0
−βγ
0
0
γ
⎤
⎥⎥⎦
(1.3.26)
and the associated coordinate transformation is
ˆx1 = (1 −β2)−1
2 x1 −β(1 −β2)−1
2 x4,
ˆx2 = x2,
ˆx3 = x3,
ˆx4 = −β(1 −β2)−1
2 x1 + (1 −β2)−1
2 x4.
(1.3.27)

1.3 The Lorentz Group
25
Fig. 1.3.3
By virtue of the equalities ˆx2 = x2 and ˆx3 = x3 we view the physical re-
lationship between  and ˆ as shown in Figure 1.3.3. Frames of reference
with spatial axes related in the manner shown in Figure 1.3.3 are said to be
in standard conﬁguration. Now it should be clear that any Lorentz transfor-
mation of the form (1.3.25) will correspond to the physical situation in which
the ˆx2- and ˆx3-axes of ˆS are rotated in their own plane from the position
shown in Figure 1.3.3.
By (1.2.10) the inverse of the Lorentz transformation Λ deﬁned by
(1.3.26) is
Λ−1 =
⎡
⎢⎢⎣
γ
0
0
βγ
0
1
0
0
0
0
1
0
βγ
0
0
γ
⎤
⎥⎥⎦
(1.3.28)
and the corresponding coordinate transformation is
x1 = (1 −β2)−1
2 ˆx1 + β(1 −β2)−1
2 ˆx4,
x2 = ˆx2,
x3 = ˆx3,
x4 = β(1 −β2)−1
2 ˆx1 + (1 −β2)−1
2 ˆx4.
(1.3.29)
Any Lorentz transformation of the form (1.3.26) or (1.3.28), i.e., with Λ24 =
Λ34 = Λ42 = Λ43 = 0 and

Λij

i,j=2,3 equal to the 2 × 2 identity matrix, is
called a special Lorentz transformation. Since Λ and Λ−1 diﬀer only in the
signs of the (1,4) and (4,1) entries it is customary, when discussing special

26
1 Geometrical Structure of M
Lorentz transformations, to allow −1 < β < 1. By choosing β > 0 when
Λ14 < 0 and β < 0 when Λ14 > 0 all special Lorentz transformations can be
written in the form (1.3.26) and we shall henceforth adopt this convention.
For each real number β with −1 < β < 1 we therefore deﬁne γ = γ(β) =
(1 −β2)−1/2 and
Λ(β) =
⎡
⎢⎢⎣
γ
0
0
−βγ
0
1
0
0
0
0
1
0
−βγ
0
0
γ
⎤
⎥⎥⎦.
The matrix Λ(β) is often called a boost in the x1-direction.
Exercise 1.3.13 Deﬁne matrices which represent boosts in the x2- and x3-
directions. One can deﬁne a boost in an arbitrary direction by ﬁrst rotating,
say, the positive x1-axis into that direction and then applying Λ(β).
Exercise 1.3.14 Suppose −1 < β1 ≤β2 < 1. Show that
(a)

β1 + β2
1 + β1β2
 < 1. Hint: Show that if a is a constant satisfying −1 < a < 1,
then the function f(x) = x + a
1 + ax is increasing on −1 ≤x ≤1.
(b)
Λ(β1)Λ(β2) = Λ
 β1 + β2
1 + β1β2

.
(1.3.30)
It follows from Exercise 1.3.14 that the composition of two boosts in the
x1-direction is another boost in the x1-direction. Since Λ−1(β) = Λ(−β) the
collection of all such special Lorentz transformations forms a subgroup of L.
We point out, however, that the composition of two boosts in two diﬀerent
directions is, in general, not equivalent to a single boost in any direction.
By referring the three special Lorentz transformations Λ(β1), Λ(β2) and
Λ(β1)Λ(β2) to the corresponding admissible frames of reference one arrives
at the following physical interpretation of (1.3.30): If the speed of ˆS relative
to S is β1 and the speed of ˆˆS relative to ˆS is β2, then the speed of ˆˆS relative
to S is not β1 + β2 as one might expect, but rather
β1 + β2
1 + β1β2
,
which is always less than β1 + β2 provided β1β2 ̸= 0. Equation (1.3.30) is
generally known as the relativistic addition of velocities formula. It, together
with part (a) of Exercise 1.3.14, conﬁrms the suspicion, already indicated by
the behavior of (1.3.21) as β →1, that the relative speed of two admissible
frames of reference is always less than that of light (that is, 1). Since any ma-
terial object can be regarded as at rest in some admissible frame we conclude
that such an object cannot attain (or exceed) the speed of light relative to
an admissible frame.

1.3 The Lorentz Group
27
Despite this “nonadditivity” of speeds in relativity it is often convenient to
measure speeds with an alternative “velocity parameter” θ that is additive.
An analogous situation occurs in plane Euclidean geometry where one has
the option of describing the relative orientation of two Cartesian coordinate
systems by means of angles (which are additive) or slopes (which are not).
What we would like then is a measure θ of relative velocities with the property
that if θ1 is the velocity parameter of ˆS relative to S and θ2 is the velocity
parameter of ˆˆS relative to ˆS, then the velocity parameter of ˆˆS relative to S,
is θ1 + θ2. Since θ is to measure relative speed, β will be some one-to-one
function of θ, say, β = f(θ). Additivity and (1.3.30) require that f satisfy
the functional equation
f(θ1 + θ2) = f(θ1) + f(θ2)
1 + f(θ1) f(θ2).
(1.3.31)
Being reminiscent of the sum formula for the hyperbolic tangent, (1.3.31)
suggests the change of variable
β = tanh θ
or
θ = tanh−1 β.
(1.3.32)
Observe that tanh−1 is a one-to-one diﬀerentiable function of (−1, 1) onto
R with the property that β →±1 implies θ →±∞, i.e., the speed of light
has inﬁnite velocity parameter. If this change of variable seems to have been
pulled out of the air it may be comforting to have a uniqueness theorem.
Exercise 1.3.15 Show that there is exactly one diﬀerentiable function β =
f(θ) on R (namely, tanh) which satisﬁes (1.3.31) and the requirement that,
for small speeds, β and θ are nearly equal, i.e., that
lim
θ→0
f(θ)
θ
= 1.
Hint: Show that such an f necessarily satisﬁes the initial value problem
f ′(θ) = 1−(f(θ))2, f(0) = 0 and appeal to the standard Uniqueness Theorem
for solutions to such problems. Solve the problem to show that f(θ) = tanh θ.
Exercise 1.3.16 Show that if β = tanh θ, then the hyperbolic form of the
Lorentz transformation Λ(β) is
L(θ) =
⎡
⎢⎢⎣
cosh θ
0
0
−sinh θ
0
1
0
0
0
0
1
0
−sinh θ
0
0
cosh θ
⎤
⎥⎥⎦.
Earlier we suggested that all of the physically interesting behavior of
proper, orthochronous Lorentz transformations is exhibited by the special
Lorentz transformations. What we had in mind is the following theorem
which asserts that any element of L diﬀers from some L(θ) only by at most
two rotations. This result will also be important in Section 1.7.

28
1 Geometrical Structure of M
Theorem 1.3.5 Let Λ = [Λab]a,b=1,2,3,4 be a proper, orthochronous Lorentz
transformation. Then there exists a real number θ and two rotations R1 and
R2 in R such that Λ = R1L(θ)R2.
Proof:
Suppose ﬁrst that Λ14 = Λ24 = Λ34 = 0. Then, by Lemma 1.3.4,
Λ is itself a rotation and so we may take R1 = Λ, θ = 0 and R2 to be
the 4 × 4 identity matrix. Consequently, we may assume that the vector

Λ14, Λ24, Λ34

in R3 is nonzero. Dividing by its magnitude in R3 gives a
vector
⇀u 1 = (α1, α2, α3) of unit length in R3. Let
⇀u 2 = (β1, β2, β3) and
⇀u 3 = (γ1, γ2, γ3) be vectors in R3 such that {
⇀u 1,
⇀u 2,
⇀u 3} is an orthonormal
basis for R3. Then
⎡
⎣
α1
α2
α3
β1
β2
β3
γ1
γ2
γ3
⎤
⎦
is an orthogonal matrix in R3 which, by a suitable ordering of the basis
{
⇀u 1,
⇀u2,
⇀u 3}, we may assume unimodular, i.e., to have determinant 1.
Thus, the matrix
R1
′ =
⎡
⎢⎢⎣
α1
α2
α3
0
β1
β2
β3
0
γ1
γ2
γ3
0
0
0
0
1
⎤
⎥⎥⎦
is a rotation in R and so R1
′Λ is in L. Now, since
⇀u 2 and
⇀u 3 are orthogonal
in R3, the product R1
′Λ must be of the form
R1
′Λ =
⎡
⎢⎢⎣
a11
a12
a13
a14
a21
a22
a23
0
a31
a32
a33
0
Λ41
Λ42
Λ43
Λ44
⎤
⎥⎥⎦,
where a14 = α1Λ14 + α2Λ24 + α3Λ34 =

Λ14
2 +

Λ24
2 +

Λ34
2  1
2 > 0.
Next consider the vectors
⇀v 2 = (a21, a22, a23) and
⇀v 3 = (a31, a32, a33)
in R3. Since R1
′Λ is in L,
⇀v 2 and
⇀v 3 are orthogonal unit vectors in R3.
Select
⇀v 1 = (c1, c2, c3) in R3 so that {
⇀v 1,
⇀v 2,
⇀v 3} is an orthonormal basis
for R3. As for R1
′ above we may relabel if necessary and assume that
R2
′ =
⎡
⎢⎢⎣
c1
a21
a31
0
c2
a22
a32
0
c3
a23
a33
0
0
0
0
1
⎤
⎥⎥⎦
is a rotation in R. Thus, B = R1
′ΛR2
′ is also in L.
Exercise 1.3.17 Use the available orthogonality conditions (the fact that
R1
′Λ and R2
′ are in L) to show that

1.3 The Lorentz Group
29
B =
⎡
⎢⎢⎣
b11
0
0
a14
0
1
0
0
0
0
1
0
b41
0
0
Λ44
⎤
⎥⎥⎦,
where b11 = a11c1 + a12c2 + a13c3 and b41 = Λ41c1 + Λ42c2 + Λ43c3.
Thus, from the fact that B is in L we obtain
b11a14 −b41Λ44 = 0,
(1.3.33)
b2
11 −b2
41 = 1.
(1.3.34)
a2
14 −

Λ44
2 = −1.
(1.3.35)
Exercise 1.3.18 Use (1.3.33), (1.3.34) and (1.3.35) to show that neither b11
nor b41 is zero.
Thus, (1.3.33) is equivalent to Λ44/b11 = a14/b41 = k for some k, i.e., Λ44 =
kb11 and a14 = kb41. Substituting these into (1.3.35) gives k2 
b2
11 −b2
41

= 1.
By (1.3.34), k2 = 1, i.e., k = ±1. But k = −1 would imply det B = −1,
whereas we must have det B = 1 since B is in L. Thus, k = 1 so
B =
⎡
⎢⎢⎣
Λ44
0
0
a14
0
1
0
0
0
0
1
0
a14
0
0
Λ44
⎤
⎥⎥⎦.
Now, it follows from (1.3.35) that Λ44 + a14
=

Λ44 −a14
−1
so
ln

Λ44 −a14

= −ln

Λ44 + a14

. Deﬁne θ by
θ = −ln

Λ4
4 + a14

= ln(Λ4
4 −a14).
Then eθ = Λ44 −a14 and e−θ = Λ44 +a14 so cosh θ = Λ44 and sinh θ = −a14.
Consequently, B = L(θ). Since B = R1
′ΛR2
′ = L(θ), we ﬁnd that if R1 =

R1
′−1 and R2 =

R2
′−1 then Λ = R1L(θ)R2 as required.
■
The physical interpretion of Theorem 1.3.5 goes something like this: The
Lorentz transformation from S to ˆS can be accomplished by (1) rotating the
axes of S so that the x1-axis coincides with the line along which the relative
motion of ˆ and  takes place (positive x1-direction coinciding with the
direction of motion of ˆ relative to ), (2) “boosting” to a new frame whose
spatial axes are parallel to the rotated axes of S and at rest relative to ˆ (via
L(θ)) and (3) rotating these spatial axes until they coincide with those of ˆS.
In many elementary situations the rotational part of this is unimportant and
it suﬃces to restrict one’s attention to special Lorentz transformations.
The special Lorentz transformations (1.3.27) and (1.3.29) correspond to a
physical situation in which two of the three spatial coordinates are the same

30
1 Geometrical Structure of M
in both frames of reference. By suppressing these two it is possible to produce
a simple, and extremely useful, 2-dimensional geometrical representation of
M and of the eﬀect of a Lorentz transformation. We begin by labeling two
perpendicular lines in the plane “x1” and “x4”. One should take care, how-
ever, not to attribute any physical signiﬁcance to the perpendicularity of
these lines. It is merely a matter of convenience and, in particular, is not
to be identiﬁed with orthogonality in M. Each event then has coordinates
relative to e1 and e4 which can be obtained by projecting parallel to the
opposite axis. The ˆx4-axis is to be identiﬁed with the set of all events with
ˆx1 = 0, i.e., with x1 = βx4 (= (tanh θ)x4) and we consequently picture the
ˆx4-axis as coinciding with this line. Similarly, the ˆx1-axis is taken to lie along
the line ˆx4 = 0, i.e., x4 = βx1. In Figure 1.3.4 we have drawn these axes
together with one branch of each of the hyperbolas (x1)2 −(x4)2 = 1 and
(x1)2 −(x4)2 = −1.
Fig. 1.3.4
Since the transformation (1.3.27) leaves invariant the quadratic form on M
and since ˆx2 = x2 and ˆx3 = x3, it follows that the hyperbolas (x1)2−(x4)2 = 1
and (x1)2 −(x4)2 = −1 coincide with the curves (ˆx1)2 −(ˆx4)2 = 1 and
(ˆx1)2 −(ˆx4)2 = −1 respectively. From this it is clear that picturing the ˆx1-
and ˆx4-axes as we have has distorted the picture (e.g., the point of intersection
of (x1)2−(x4)2 = 1 with the ˆx1-axis must have hatted coordinates (ˆx1, ˆx4) =
(1, 0)) and necessitates a change of scale on these axes. To determine precisely
what this change of scale should be we observe that one unit of length on
the ˆx1-axis must be represented by a segment whose Euclidean length in the
picture is the Euclidean distance from the origin to the point (ˆx1, ˆx4) =

1.3 The Lorentz Group
31
(1, 0). This point has unhatted coordinates (x1, x4) = ((1 −β2)−1
2 ,
β(1 −β2)−1
2 ) (by (1.3.29)) and the Euclidean distance from this point to
the origin is, by the distance formula, (1 + β2)
1
2 (1 −β2)−1
2 . A similar ar-
gument shows that one unit of time on the ˆx4-axis must also be represented
by a segment of Euclidean length (1 + β2)
1
2 (1 −β2)−1
2 . However, before we
can legitimately calibrate these axes with this unit we must verify that all
of the hyperbolas (x1)2 −(x4)2 = ±k2 (k > 0) intersect the ˆx1- and ˆx4-axes
a Euclidean distance k(1 + β2)
1
2 (1 −β2)−1
2 from the origin (the calibration
must be consistent with the invariance of these hyperbolas under (1.3.27)).
Exercise 1.3.19 Verify this.
With this we have justiﬁed the calibration of the axes shown in Figure 1.3.5.
Fig. 1.3.5
Exercise 1.3.20 Show that with this calibration of the ˆx1- and ˆx4-axes the
hatted coordinates of any event can be obtained geometrically by projecting
parallel to the opposite axis.
From this it is clear that the dotted lines in Figure 1.3.5 parallel to the ˆx1-
and ˆx4-axes and through the points (ˆx1, ˆx4) = (0, 1) and (ˆx1, ˆx4) = (1, 0)
are the lines ˆx4 = 1 and ˆx1 = 1 respectively.
Exercise 1.3.21 Show that, for any k, the line ˆx4 = k intersects the hyper-
bola (x1)2 −(x4)2 = −k2 only at the point (ˆx1, ˆx4) = (0, k), where it is, in
fact, the tangent line. Similarly, ˆx1 = k is tangent to (x1)2 −(x4)2 = k2 at
(ˆx1, ˆx4) = (k, 0) and intersects this hyperbola only at that point.

32
1 Geometrical Structure of M
Next we would like to illustrate the utility of these 2-dimensional
Minkowski diagrams, as they are called, by examining in detail the basic
kinematic eﬀects of special relativity (two of which we have already en-
countered). Perhaps the most fundamental of these is the so-called relativity
of simultaneity which asserts that two admissible observers will, in general,
disagree as to whether or not a given pair of spatially separated events were si-
multaneous. That this is the case was already clear in (1.3.23) which gives the
time diﬀerence in ˆS between two events judged simultaneous in S. Since, in
a Minkowski diagram, lines of simultaneity (x4 = constant or ˆx4 = constant)
are lines parallel to the respective spatial axes (Exercise 1.3.20) and since the
line through two given events cannot be parallel to both the x1- and ˆx1-axes
(unless β = 0), the geometrical representation is particularly persuasive (see
Figure 1.3.6).
Notice, however, that some information is lost in such diagrams. In partic-
ular, the two lines of simultaneity in Figure 1.3.6 intersect in what appears
to be a single point. But our diagram intentionally suppresses two spatial
dimensions so the “lines” of simultaneity actually represent “instantaneous
3-spaces” which intersect in an entire plane of events and both observers judge
all of these events to be simultaneous (recall (1.3.24)). One can visualize at
least an entire line of such events by mentally reinserting one of the missing
spatial dimensions with an axis perpendicular to the sheet of paper on which
Figure 1.3.6 is drawn. The lines of simultaneity become planes of simultaneity
which intersect in a “line of agreement” for S and ˆS.
And so, it all seems quite simple. Too simple perhaps. One cannot escape
the feeling that something must be wrong. Two events are given (for dramatic
eﬀect, two explosions). Surely the events either are, or are not, simultaneous
Fig. 1.3.6

1.3 The Lorentz Group
33
and there is no room for disagreement. It seems inconceivable that two equally
competent observers could arrive at diﬀerent conclusions. And it is diﬃcult to
conceive, but only, we claim, because very few of us have ever met “another”
admissible observer. We are, for the most part, all conﬁned to the same frame
of reference and, as is often the case in human aﬀairs, our experience is too
narrow, our view too parochial to comprehend other possiblities. We shall
try to remedy this situation by moving the events far away from our all-
too-comfortable earthly reference frame. Before getting started, however, we
recommend that the reader return to the Introduction to review the procedure
outlined there for synchronizing clocks as well as the properties of light signals
enumerated there. In addition, it will be important to keep in mind that
“simultaneity” becomes questionable only for spatially separated events. All
observers agree that two given events either are, or are not, “simultaneous at
the same spatial location”.
Thus we consider two events (explosions) E1 and E2 occurring deep in
space (to avoid the psychological inclination to adopt any large body nearby
as a “standard of rest”). We suppose that E1 and E2 are observed in two
admissible frames S and ˆS whose spatial axes are in standard conﬁguration
(Figure 1.3.3). Let us also suppose that when the explosions take place they
permanently “mark” the locations at which they occur in each frame and,
at the same time, emit light rays in all directions whose arrival times are
recorded by local “assistants” at each spatial point within the two frames.
Naturally, an observer in a given frame of reference will say that the events
E1 and E2 are simultaneous if two such assistants, each of whom is in the
immediate vicinity of one of the events, record times x4
1 and x4
2 for these events
which, when compared later, are found to be equal. It is useful, however, to
rephrase this notion of simultaneity in terms of readings taken at a single
point. To do so we let 2d denote the distance between the spatial locations of
E1 and E2 as determined in the given frame of reference and let M denote the
midpoint of the line segment in that frame which joins these two locations:
Fig. 1.3.7
Since x4
1 = x4
2 if and only if x4
1 + d = x4
2 + d and since x4
1 + d is, by deﬁnition,
the time of arrival at M of a light signal emitted with E1 and, similarly, x4
2+d
is the arrival time at M of a light signal emitted with E2 we conclude that E1
and E2 are simultaneous in the given frame of reference if and only if light
signals emitted with these events arrive simultaneously at the midpoint of the
line segment joining the spatial locations of E1 and E2 within that frame.
Now let us denote by A and ˆA the spatial locations of E1 in S and ˆS
respectively and by B and ˆB the locations of E2 in S and ˆS. Thus, the points
A and ˆA coincide at the instant E1 occurs (they are the points “marked”

34
1 Geometrical Structure of M
by E1) and similarly B and ˆB coincide when E2 occurs. At their convenience
the two observers O and ˆO presiding over S and ˆS respectively collect all
of the data recorded by their assistants for analysis. Each will inspect the
coordinates of the two marked points, calculate from them the coordinates
of the midpoint of the line segment joining these two points in his coordinate
system (denote these midpoints by M and ˆ
M) and inquire of his assistant
located at this point whether or not the light signals emitted from the two
explosions arrived simultaneously at his location. In general, of course, there
is no reason to expect an aﬃrmative answer from either, but let us just
suppose that in this particular case one of the observers, say O, ﬁnds that the
light signals from the two explosions did indeed arrive simultaneously at the
midpoint of the line segment joining the spatial locations of the explosions in
. According to the criteria we have established, O will therefore conclude
that E1 and E2 were simultaneous so that, from his point of view, A and
ˆA, M and ˆ
M and B and ˆB all coincide “at the same time”.
Fig. 1.3.8
Continuing to analyze the situation as it is viewed from S we observe that, by
virtue of the ﬁnite speed at which the light signals propagate, a nonzero time
interval is required for these signals to reach M and that, during this time
interval, M and ˆ
M separate so that the signals cannot meet simultaneously
at ˆ
M.
Fig. 1.3.9
Indeed, if the motion is as indicated in Figures 1.3.8 and 1.3.9, the light from
E2 will clearly reach ˆ
M before the light from E1. Although we have reached
this conclusion by examining the situation from the point of view of O, any
other admissible observer will necessarily concur since we have assumed that
all such observers agree on the temporal order of any two events on the

1.3 The Lorentz Group
35
worldline of a photon (consider a photon emitted at E2 and the two events
on its worldline corresponding to its encounters with ˆ
M and the light signal
emitted at E1). In particular, ˆO must conclude that E2 occurred before E1
and consequently that these two events are not simultaneous. When O and ˆO
next meet they compare their observations of the two explosions and discover,
much to their chagrin, that they disagree as to whether or not these two
events were simultaneous. Having given the matter some thought, O believes
that he has resolved the diﬃculty. The two events were indeed simultaneous
as he had claimed, but they did not appear so to ˆO because ˆO was moving
(running toward the light signal from E2 and away from that of E1). To this
ˆO responds without hesitation “I wasn’t moving — you were! The explosions
were not simultaneous, but only appeared so to you because of your motion
toward E1 and away from E2”. This apparent impasse could, of course, be
easily overcome if one could determine with some assurance which of the two
observers was “really moving”. But it is precisely this determination which
the Relativity Principle disallows: One can attach no objective meaning to
the phrase “really at rest”. The conclusion is inescapable: It makes no more
sense to ask if the events were “really simultaneous” than it does to ask if O
was “really at rest”. “Simultaneity”, like “motion” is a purely relative term.
If two events are simultaneous in one admissible frame of reference they will,
in general, not be simultaneous in another such frame.
The relativity of simultaneity is not easy to come to terms with, but it
is essential that one do so. Without it even the most basic contentions of
relativity appear riddled with logical inconsistencies.
Exercise 1.3.22 Observer ˆO is moving to the right at constant speed β rel-
ative to observer O (along their common x1-, ˆx1-axes with origins coinciding
at x4 = ˆx4 = 0). At the instant O and ˆO pass each other a ﬂashbulb emits
a spherical electromagnetic wavefront. O observes this spherical wavefront
moving away from him with speed 1. After x4
0 meters of time the wavefront
will have reached points a distance x4
0 meters from him. According to O, at
the instant the light has reached point A in Figure 1.3.10 it has also reached
point B. However, ˆO regards himself as at rest with O moving so he will also
observe a spherical wavefront moving away from him with speed 1. But as the
light travels to A, ˆO has moved a short distance to the right of O so that the
spherical wavefront observed by ˆO is not concentric with that observed by O.
In particular, when the light arrives at A, ˆO will contend that it also reaches
(not B yet, but) C. They cannot both be right. Resolve the “paradox”. Hint:
There is an error in Figure 1.3.10. Compare it with Figure 1.3.11 after you
have ﬁlled in the blanks.
To be denied the absolute, universal notion of simultaneity which the
rather limited scope of our day-to-day experience has led us to accept uncriti-
cally is a serious matter. Disconcerting enough in its own right, this relativity
of simultaneity also necessitates a profound reevaluation of the most basic
concepts with which we describe the world. For example, since our observers

36
1 Geometrical Structure of M
Fig. 1.3.10
O and ˆO need not agree on the time lapse between two events even when one
of them measures it to be zero, one could scarcely expect them to agree on
the elapsed time between two arbitrarily given events. And, indeed, we have
already seen in (1.3.20) that Δx4 and Δˆx4 are generally not equal. This eﬀect,
known as time dilation, has a particularly nice geometrical representation in
a Minkowski diagram (see Figure 1.3.12). E1 (resp., E2) can be identiﬁed
physically with the appearance of the reading “1” on the clock at the origin
of S (resp., ˆS). In S, E1 is simultaneous with E3 which corresponds to a
reading strictly less than 1 on the clock at the origin in ˆS. Since the clocks
at the origins of S and ˆS agreed at x4 = ˆx4 = 0, O concludes that ˆO’s
clock is running slow. Indeed, (1.3.21) and (1.3.22) show that each observes
the other’s time dilated by the same constant factor γ = (1 −β2)−1
2 . The
moral of the story, perhaps a bit too tersely stated, is that “moving clocks
run slow”.
Exercise 1.3.23 Pions are subatomic particles which decay spontaneously
and have a half-life (at rest) of 1.8 × 10−8 sec (= 5.4m). A beam of pions
is accelerated to a speed of β = 0.99. One would expect that the beam
would drop to one-half its original intensity after travelling a distance of
(0.99)(5.4m) = 5.3m. However, it is found experimentally that the beam
reaches one-half intensity after travelling approximately 38m. Explain! Hint:
Let S denote the laboratory frame of reference, ˆS the rest frame of the pi-
ons and assume that S and ˆS are related by (1.3.27) and (1.3.29). Draw a
Minkowski diagram which represents the situation.
Return for a moment to Figure 1.3.12 and, in particular, to the line ˆx4 = 1.
Each point on this line can be identiﬁed with the appearance of the reading
“1” on a clock that is stationary at some point in ˆ. These all occur “simul-
taneously” for ˆO because his clocks have been synchronized. However, each
of these events occurs at a diﬀerent “time” in S so O will disagree. Clocks at
diﬀerent locations in ˆ read 1 at diﬀerent “times” so, according to O, they
cannot be synchronized.
Here is an old, and much abused, “paradox” with its roots in the phe-
nomenon of time dilation, or rather, in a basic misunderstanding of that
phenomenon. Suppose that, at (0, 0, 0, 0), two identical twins part company.

1.3 The Lorentz Group
37
Fig. 1.3.11
One remains at rest in the admissible frame in which he was born. The other
is transported away at some constant speed to a distant point in space where
he turns around and returns at the same constant speed to rejoin his brother.
At the reunion the stationary twin ﬁnds that he is considerably older than his
more adventurous brother. Not surprising; after all, moving clocks run slow.
However, is it not true that, from the point of view of the “rocket” twin, it
is the “stationary” brother who has been moving and must, therefore, be the
younger of the two?
Fig. 1.3.12

38
1 Geometrical Structure of M
The error concealed in this argument, of course, is that it hinges upon a
supposed symmetry between the two twins which simply does not exist. If
the stationary twin does, in fact, remain at rest in an admissible frame, then
his brother certainly does not. Indeed, to turn around and return midway
through his journey he must “transfer” from one admissible frame to another
and, in practice, such a transfer would require accelerations (slow down, turn
around, speed up) and these accelerations would be experienced only by the
traveller and not by his brother. Nothing we have done thus far equips us
to deal with these accelerations and so we can come to no conclusions about
their physical eﬀects (we will pursue this further in Section 1.4). That they
do have physical eﬀects, however, can be surmised even now by idealizing the
situation a bit. Let us replace our two twins with three admissible frames: S
(stationary twin), ˆS (rocket twin on his outward journey) and ˆˆS (rocket twin
on his return journey). What this amounts to is the assumption that the two
individuals involved compare ages in passing (without stopping to discuss it)
at the beginning and end of the trip and that, at the turnaround point, the
traveller “jumps” instantaneously from one admissible frame to another (he
cannot do that, of course, but it seems reasonable that, with a suﬃciently
durable observer, we could approximate such a jump arbitrarily well by a
“large” acceleration over a “small” time interval). Figure 1.3.13 represents
the outward journey from O to the turnaround event T .
Fig. 1.3.13
Notice that, in ˆS, T is simultaneous with the event P on the worldline
of the stay-at-home. In S, P is simultaneous with some earlier event on the
worldline of the traveller. Each sees the other’s time dilated. Figure 1.3.14
represents the return journey. Notice that, in ˆˆS, T is simultaneous with (not
P, but) the event Q on the worldline of the stationary twin, whereas, in S, Q
is simultaneous with some later event on the traveller’s worldline. Each sees
the other’s time dilated. Now, put the two pictures together in Figure 1.3.15

1.3 The Lorentz Group
39
Fig. 1.3.14
and notice that in “jumping” from ˆS to ˆˆS, our rocket twin has also jumped
over the entire interval from P to Q on the worldline of his brother; an interval
over which his brother ages, but he does not. The lesson to be learned is that,
while all motion is indeed relative, it is not all physically equivalent.
Exercise 1.3.24 Account, in a sentence or two, for the “missing” time in
Figure 1.3.15. Hint:
2β
1 + β2 > β for 0 < β < 1.
There is one last kinematic consequence of the relativity of simultaneity,
as interesting, as important and as surprising as time dilation. To trace its
origins we return once again to the explosions E1 and E2, observed by S and
ˆS and discussed on pages 33–36. Recall that the points A in  and ˆA in ˆ
coincided when E1 occurred, whereas B in  and ˆB in ˆ coincided when E2
occurred. Since the two events were simultaneous in S, the observer O will
conclude that A coincides with ˆA at the same instant that B coincides with
ˆB and, in particular, that the segments AB and ˆA ˆB have the same length
(see Figure 1.3.8). However, in ˆS, E2 occurred before E1 so B coincides
with ˆB before A coincides with ˆA and ˆO must conclude that the length
of ˆA ˆB is greater than the length of AB. More generally, two objects (say,
measuring rods) in relative motion are considered to be equal in length if,
when they pass each other, their respective endpoints A, ˆA and B, ˆB coincide
simultaneously. But, “simultaneously” according to whom? Here we have two
events (the coincidence of A and ˆA and the coincidence of B and ˆB) and we
have seen that if one admissible observer claims that they are simultaneous
(i.e., that the lengths AB and ˆA ˆB are equal), then another will, in general,
disagree and we have no reason to prefer the judgment of one such observer to
that of another (Relativity Principle). “Length”, we must conclude, cannot
be regarded as an objective attribute of the rods, but is rather simply the
result of a speciﬁc measurement which we can no longer go on believing
must be the same for all observers. Notice also that these conclusions have

40
1 Geometrical Structure of M
nothing whatever to do with the material construction of the measuring rods
(in particular, their “rigidity”) since, in the case of the two explosions, for
example, there need not be any material connection between the two events.
This phenomenon is known as length contraction (or Lorentz contraction)
and we shall now look into the quantitative side of it.
Fig. 1.3.15
To simplify the calculations and to make available an illuminating
Minkowski diagram we shall restrict our discussion to frames of reference
whose spatial axes are in standard conﬁguration (see Figure 1.3.3) and whose
coordinates are therefore related by (1.3.27) and (1.3.29). For the picture let
us consider a “rigid” rod resting along the ˆx1-axis of ˆS with ends ﬁxed at
ˆx1 = 0 and ˆx1 = 1. Thus, the length of the rod as measured in ˆS is 1. The
worldlines of the left and right ends of the rod are the ˆx1-axis and the line
ˆx1 = 1 respectively. Geometrically, the measured length of the rod in S is
the Euclidean length of the segment joining two points on these worldlines at
the same instant in S (“locate the ends of the rod simultaneously and com-
pute the length from their coordinates at this instant”). Since the Euclidean
length of such a segment is clearly the same as the x1-coordinate of the point
P in Figure 1.3.16 and since this is clearly less than 1, length contraction is
visually apparent.
For the calculation we will be somewhat more general and consider a rod
lying along the ˆx1-axis of ˆS between ˆx1
0 and ˆx1
1 with ˆx1
0 < ˆx1
1 so that its
measured length in ˆS is Δˆx1 = ˆx1
1 −ˆx1
0. The worldline of the rod’s left- (resp.,
right-) hand endpoint has ˆS-coordinates

ˆx1
0, 0, 0, ˆx4
(resp.,

ˆx1
1, 0, 0, ˆx4
),
with −∞< ˆx4 < ∞. S will measure the length of this rod by locating
its endpoints “simultaneously”, i.e., by ﬁnding one event on each of these
worldlines with the same x4 (not ˆx4). But, for any ﬁxed x4, the transformation
equations (1.3.27) give
ˆx1
0 = (1 −β2)−1
2 x1
0 −β(1 −β2)−1
2 x4,
ˆx1
1 = (1 −β2)−1
2 x1
1 −β(1 −β2)−1
2 x4,

1.3 The Lorentz Group
41
Fig. 1.3.16
so that Δˆx1 = (1 −β2)−1
2 Δx1 and therefore
Δx1 = (1 −β2)
1
2 Δˆx1.
(1.3.36)
Since (1 −β2)
1
2 < 1 we ﬁnd that the measured length of the rod in S is less
than its measured length in ˆS by a factor of

1 −β2. By reversing the roles
of S and ˆS we again ﬁnd that this eﬀect is entirely symmetrical.
Exercise 1.3.25 Return to Exercise 1.3.23 and oﬀer another explanation
based, not on time dilation, but on length contraction.
As it is with time dilation, the correct physical interpretation of the
Lorentz contraction often requires rather subtle and delicate argument.
Exercise 1.3.26 Imagine a barn which, at rest, measures 8 meters in length.
A (very fast) runner carries a pole of rest length 16 meters toward the barn
at such a high speed that, for an observer at rest with the barn, it appears
Lorentz contracted to 8 meters and therefore ﬁts inside the barn. This ob-
server slams the front door shut at the instant the back of the pole enters
the front of the barn and so encloses the pole entirely within the barn. But
is it not true that the runner sees the barn Lorentz contracted to 4 meters
so that the 16 meter pole could never ﬁt entirely within it? Resolve the diﬃ-
culty! Hint: Let S and ˆS respectively denote the rest frames of the barn and
the pole and assume that these frames are related by (1.3.27) and (1.3.29).
Calculate β. Suppose the front of the pole enters the front of the barn at
(0, 0, 0, 0). Now consider the two events at which the front of the pole hits
the back of the barn and the back of the pole enters the front of the barn.

42
1 Geometrical Structure of M
Finally, think about the maximum speed at which the signal to stop can be
communicated from the front to the back of the pole.
The underlying message of Exercise 1.3.26 would seem to be that the
classical notion of a perfectly “rigid” body has no place in relativity, even as
an idealization. The pole must compress since otherwise the signal to halt
would proceed from the front to the back instantaneously and, in particular,
the situation described in the exercise would, indeed, be “paradoxical”, i.e.,
represent a logical inconsistency.
1.4 Timelike Vectors and Curves
Let us now consider in somewhat more detail a pair of events x0 and x for
which x −x0 is timelike, i.e., Q(x −x0) < 0. Relative to any admissible basis
{ea} we have (Δx1)2 + (Δx2)2 + (Δx3)2 < (Δx4)2. Clearly then, Δx4 ̸= 0
and we may assume without loss of generality that Δx4 > 0, i.e., that x −x0
is future-directed. Thus, we obtain
((Δx1)2 + (Δx2)2 + (Δx3)2)
1
2
Δx4
< 1.
Physically, it is therefore clear that if one were to move with speed
((Δx1)2 + (Δx2)2 + (Δx3)2)
1
2
Δx4
relative to the frame S corresponding to {ea} along the line in  from

x1
0, x2
0, x3
0

to (x1, x2, x3) and if one were present at x0, then one would also
experience x, i.e., that there is an admissible frame of reference ˆS in which
x0 and x occur at the same spatial point, one after the other. Speciﬁcally, we
now prove that if one chooses β = ((Δx1)2 + (Δx2)2 + (Δx3)2)1/2/Δx4 and
lets d1, d2 and d3 be the direction cosines in  of the directed line segment
from

x1
0, x2
0, x3
0

to (x1, x2, x3), then the basis {ˆea} for M obtained from
{ea} by performing any Lorentz transformation whose fourth row is Λ4i =
−β(1−β2)−1/2 di, i = 1, 2, 3, and Λ44 = (1−β2)−1/2 = γ, has the property
that Δˆx1 = Δˆx2 = Δˆx3 = 0.
Exercise 1.4.1 There will, in general, be many Lorentz transformations
with this fourth row. Show that deﬁning the remaining entries by Λi4 =
−βγdi, i = 1, 2, 3, and Λij = (γ −1)didj + δij, i, j = 1, 2, 3 (δij being the
Kronecker delta) gives an element of L.
To prove this we compute Δˆx4 = Λ4bΔxb. To simplify the calculations we
let Δ
⇀x = ((Δx1)2+(Δx2)2+(Δx3)2)1/2. We may clearly assume that Δ
⇀x ̸= 0
since otherwise there is nothing to prove. Thus, β2 = Δ
⇀x 2/(Δx4)2, γ =
Δx4/

−Q(x −x0), βγ = Δ
⇀x/

−Q(x −x0) and di = Δxi/Δ
⇀x for i =
1, 2, 3. From (1.3.20) we therefore obtain

1.4 Timelike Vectors and Curves
43
Δˆx4 = −
Δ
⇀x

−Q(x −x0)
(Δ
⇀x) +
(Δx4)2

−Q(x −x0)
=

−Q(x −x0).
Consequently, Q(x −x0) = −(Δˆx4)2. But, computing Q(x −x0) relative to
the basis {ˆea} we ﬁnd that Q(x −x0) = (Δˆx1)2 + (Δˆx2)2 + (Δˆx3)2 −(Δˆx4)2
so we must have (Δˆx1)2 + (Δˆx2)2 + (Δˆx3)2 = 0, i.e., Δˆx1 = Δˆx2 = Δˆx3 = 0
as required.
For any timelike vector v in M we deﬁne the duration τ(v) of v by τ(v) =

−Q(v). If v is the displacement vector v = x −x0 between two events x0
and x, then, as we have just shown, τ(x −x0) is to be interpreted physically
as the time separation of x0 and x in any admissible frame of reference in
which both events occur at the same spatial location.
A subset of M of the form {x0+t(x−x0) : t ∈R}, where x−x0 is timelike,
is called a timelike straight line in M. A timelike straight line which passes
through the origin is called a time axis. We show that the name is justiﬁed
by proving that if T is a time axis, then there exists an admissible basis {ˆea}
for M such that the subspace of M spanned by ˆe4 is T. To see this we select
an event ˜e4 on T with ˜e4 · ˜e4 = −1 and let Span {˜e4} be the linear span of
˜e4 in M. Next let Span {˜e4}⊥be the orthogonal complement of Span {˜e4}
in M. By Exercise 1.1.2, Span {˜e4}⊥is also a subspace of M. We claim that
M = Span{˜e4} ⊕Span {˜e4}⊥(recall that a vector space V is the direct sum
of two subspaces W1 and W2 of V , written V = W1 ⊕W2, if W1 ∩W2 = {0}
and if every vector in V can be written as the sum of a vector in W1 and a
vector in W2). Since every nonzero vector in Span {˜e4} is timelike, whereas,
by Corollary 1.3.2, every nonzero vector in Span {˜e4}⊥is spacelike, it is clear
that these two subspaces intersect only in the zero vector. Next we let v
denote an arbitrary vector in M and consider the vector w = v + (v · ˜e4)˜e4
in M. Since w · ˜e4 = v · ˜e4 + (v · ˜e4)(˜e4 · ˜e4) = 0 we ﬁnd that w is in Span
{˜e4}⊥. Thus, the expression v = −(v · ˜e4)˜e4 + w completes the proof that
M = Span{˜e4} ⊕Span{˜e4}⊥. Now, the restriction of the M-inner product
to Span {˜e4}⊥is positive deﬁnite so, by Theorem 1.1.1, we may select three
vectors ˜e1, ˜e2 and ˜e3 in Span {˜e4}⊥such that ˜ei · ˜ej = δij for i, j = 1, 2, 3.
Thus, {˜e1, ˜e2, ˜e3, ˜e4} is an orthonormal basis for M. Now let us ﬁx an
admissible basis {ea} for M. There is a unique orthogonal transformation
of M that carries ea onto ˜ea for each a = 1, 2, 3, 4. If the corresponding
Lorentz transformation is either improper or nonorthochronous or both we
may multiply ˜e1 or ˜e4 or both by −1 to obtain an admissible basis {ˆea}
for M with Span {ˆe4} = T and so the proof is complete. Any time axis is
therefore the x4-axis of some admissible coordinatization of M and so may be
identiﬁed with the worldline of some admissible observer. Since any timelike
straight line is parallel to some time axis we view such a straight line as the
worldline of a point at rest in the corresponding admissible frame (say, the
worldline of one of the “assistants” to our observer).

44
1 Geometrical Structure of M
Exercise 1.4.2 Show that if T is a time axis and x and x0 are two events,
then x −x0 is orthogonal to T if and only if x and x0 are simultaneous in
any reference frame whose x4-axis is T .
Exercise 1.4.3 Show that if x −x0 is timelike and s is an arbitrary non-
negative real number, then there is an admissible frame of reference in which
the spatial separation of x and x0 is s. Show also that the time separation of
x and x0 can assume any real value greater than or equal to τ(x −x0). Hint:
Begin with a basis {ea} in which Δx1 = Δx2 = Δx3 = 0 and Δx4 = τ(x−x0).
Now perform the special Lorentz transformation (1.3.27), where −1 < β < 1
is arbitrary.
According to Exercise 1.4.3, τ(x −x0) is a lower bound for the temporal
separation of x0 and x and, for this reason, it is often called the proper
time separation of x0 and x; when no reference to the speciﬁc events under
consideration is required τ(x −x0) is generally denoted Δτ.
Any timelike vector v lies along some time axis so τ(v) can be regarded
as a sort of “temporal length” of v (the time separation of its tail and tip
as recorded by an observer who experiences both). It is a rather unusual
notion of length, however, since the analogues of the basic inequalities one is
accustomed to dealing with for Euclidean lengths are generally reversed.
Theorem 1.4.1 (Reversed Schwartz Inequality) If v and w are timelike vec-
tors in M, then
(v · w)2 ≥v2w2
(1.4.1)
and equality holds if and only if v and w are linearly dependent.
Proof:
Consider the vector u = av −bw, where a = v ·w and b = v ·v = v2.
Observe that u · v = av 2 −bv · w = v2(v · w) −v2(v · w) = 0. Since v
is timelike, Corollary 1.3.2 implies that u is either zero or spacelike. Thus,
0 ≤u2 = a2v2 + b2w2 −2abv · w, with equality holding only if u = 0.
Consequently, 2abv · w ≤a2v2 + b2w2, i.e.,
2v2(v · w)2 ≤v2(v · w)2 + (v2)2w2,
2(v · w)2 ≥(v · w)2 + v2w2
(since v2 < 0),
(v · w)2 ≥v2w2,
and equality holds only if u = 0. But u = 0 implies av −bw = 0 which, since
a = v · w ̸= 0 by Theorem 1.3.1, implies that v and w are linearly dependent.
Conversely, if v and w are linearly dependent, then one is a multiple of the
other and equality clearly holds in (1.4.1).
■
Theorem 1.4.2 (Reversed Triangle Inequality) Let v and w be timelike vec-
tors with the same time orientation (i.e., v · w < 0 ). Then
τ(v + w) ≥τ(v) + τ(w)
(1.4.2)
and equality holds if and only if v and w are linearly dependent.

1.4 Timelike Vectors and Curves
45
Proof:
By Theorem 1.4.1, (v · w)2 ≥v2w2 = (−v2)(−w2) so |v · w| ≥
√
−v2√
−w2. But (v · w) < 0 so we must have v · w ≤−
√
−v2√
−w2 and
therefore
−2v · w ≥2

−v2
−w2.
(1.4.3)
Now, by Exercise 1.3.2, v + w is timelike. Moreover, −(v + w)2 = −v2 −2v ·
w −w2 ≥−v2 + 2
√
−v2√
−w2 −w2 by (1.4.3). Thus,
−(v + w)2 ≥

−v2 +

−w2
2
,

−(v + w)2 ≥

−v2 +

−w2,

−Q(v + w) ≥

−Q(v) +

−Q(w),
τ(v + w) ≥τ(v) + τ(w),
as required. If equality holds in (1.4.2), then, by reversing the preceding steps,
we obtain
−2v · w = 2
√
v2
−w2
and therefore (v · w)2 = v2w2 so, by Theorem 1.4.1, v and w are linearly
dependent.
■
To extend Theorem 1.4.2 to arbitrary ﬁnite sums of similarly oriented
timelike vectors (and for other purposes as well) we require:
Lemma 1.4.3 The sum of any ﬁnite number of vectors in M all of which
are timelike or null and all future-directed (resp., past-directed) is timelike
and future-directed (resp., past-directed) except when all of the vectors are
null and parallel, in which case the sum is null and future-directed (resp.,
past-directed).
Proof:
It suﬃces to prove the result for future-directed vectors since the
corresponding result for past-directed vectors will then follow by changing
signs. Moreover, it is clear that any sum of future-directed vectors is, indeed,
future-directed.
First we observe that if v1 and v2 are timelike and future-directed, then
v1 · v1 < 0, v2 · v2 < 0 and v1 · v2 < 0 so (v1 + v2) · (v1 + v2) = v1 · v1 + 2v1 ·
v2 + v2 · v2 < 0 and therefore v1 + v2 is timelike.
Exercise 1.4.4 Show that if v1 is timelike, v2 is null and both are future-
directed, then v1 + v2 is timelike and future-directed.
Next suppose that v1 and v2 are null and future-directed. We show that v1+v2
is timelike unless v1 and v2 are parallel (in which case, it is obviously null).
To this end we note that (v1 + v2) · (v1 + v2) = 2v1 · v2. By Theorem 1.2.1,
v1 · v2 = 0 if and only if v1 and v2 are parallel. Suppose then that v1 and
v2 are not parallel. Fix an admissible basis {ea} for M and let v1 = va
1ea
and v2 = va
2ea. For each n = 1, 2, 3, . . ., deﬁne wn in M by wn = v1
1e1 +
v2
1e2 + v3
1e3 +

v4
1 + 1
n

e4. Then each wn is timelike and future-directed.

46
1 Geometrical Structure of M
By Theorem 1.3.1, 0 > wn · v2 = v1 · v2 −1
nv4
2, i.e., v1 · v2 < 1
nv4
2 for every n.
Thus, v1 · v2 ≤0. But v1 · v2 ̸= 0 by assumption so v1 · v2 < 0 and therefore
(v1 + v2) · (v1 + v2) < 0 as required.
Exercise 1.4.5 Complete the proof by induction.
■
Corollary 1.4.4 Let v1, . . . , vn be timelike vectors, all with the same time
orientation. Then
τ(v1 + v2 + · · · + vn) ≥τ(v1) + τ(v2) + · · · + τ(vn)
(1.4.4)
and equality holds if and only if v1, v2, . . . , vn are all parallel.
Proof:
Inequality (1.4.4) is clear from Theorem 1.4.2 and Lemma 1.4.3. We
show, by induction on n, that equality in (1.4.4) implies that v1, . . . , vn are
all parallel. For n = 2 this is just Theorem 1.4.2. Thus, we assume that the
statement is true for sets of n vectors and consider a set v1, . . . , vn, vn+1 of
timelike vectors which are, say, future-directed and for which
τ(v1 + · · · + vn + vn+1) = τ(v1) + · · · + τ(vn) + τ(vn+1).
v1 + · · · + vn is timelike and future-directed so, again by Theorem 1.4.2,
τ(v1 + · · · + vn) + τ(vn+1) ≤τ(v1) + · · · + τ(vn) + τ(vn+1).
We claim that, in fact, equality must hold here. Indeed, otherwise we have
τ(v1 + · · · + vn) < τ(v1) + · · · + τ(vn) and so (Theorem 1.4.2 again) τ(v1 +
· · · + vn−1) < τ(v1) + · · · + τ(vn−1). Continuing the process we eventually
conclude that τ(v1) < τ(v1) which is a contradiction. Thus,
τ(v1 + · · · + vn) = τ(v1) + · · · + τ(vn)
and the induction hypothesis implies that v1, . . . , vn are all parallel. Let
v = v1 +· · ·+vn. Then v is timelike and future-directed. Thus, τ(v +vn+1) =
τ(v)+τ(vn+1) and one more application of Theorem 1.4.2 implies that vn+1 is
parallel to v and therefore to all of v1, . . . , vn and the proof is complete.
■
Corollary 1.4.5 Let v and w be two nonparallel null vectors. Then v and w
have the same time orientation if and only if v · w < 0.
Proof:
Suppose ﬁrst that v and w have the same time orientation. By
Lemma 1.4.3, v + w is timelike so 0 > (v + w) · (v + w) = 2v · w so v · w < 0.
Conversely, if v and w have opposite time orientation, then v and −w have
the same time orientation so v · (−w) < 0 and therefore v · w > 0.
■
The reason that the sense of the inequality in Theorem 1.4.2 is “reversed”
becomes particularly transparent by choosing a coordinate system relative to
which v = (v1, v2, v3, v4), w = (w1, w2, w3, w4) and v+w = (0, 0, 0, v4+w4)
(this simply amounts to taking the time axis through v + w as the x4-axis).
For then τ(v) = ((v4)2 −(v1)2 −(v2)2 −(v3)2)
1
2 < v4 and τ(w) < w4, but
τ(v + w) = v4 + w4.

1.4 Timelike Vectors and Curves
47
A timelike straight line is regarded as the worldline of a material particle
that is “free” in the sense of Newtonian mechanics and consequently is at rest
in some admissible frame of reference. Not all material particles of interest
have this property (e.g., the “rocket twin”). To model these in M we will
require a few preliminaries. Let I ⊆R be an open interval. A map α : I →M
is a curve in M. Relative to any admissible basis {ea} for M we can write
α(t) = xa(t)ea for each t in I. We will assume that α is smooth, i.e., that
each component function xa(t) is inﬁnitely diﬀerentiable and that α’s velocity
vector
α′(t) = dxa
dt ea
is nonzero for each t in I.
Exercise 1.4.6 Show that this deﬁnition of smoothness does not depend on
the choice of admissible basis. Hint: Let {ˆea} be another admissible basis,
L the orthogonal transformation that carries ea onto ˆea for a = 1, 2, 3, 4 and
[Λab] the corresponding element of L. If α(t) = ˆxa(t)ˆea, then ˆxa(t) = Λabxb(t)
so dˆxa
dt = Λab dx b
dt . Keep in mind that [Λab] is nonsingular.
A curve α : I →M is said to be spacelike, timelike or null respectively if its
velocity vector α′(t) has that character for every t in I, that is, if α′(t) · α′(t)
is > 0, < 0 or = 0 respectively for each t. A timelike or null curve α is future-
directed (resp., past-directed) if α′(t) is future-directed (resp., past-directed)
for each t. A future-directed timelike curve is called a timelike worldline or
worldline of a material particle. We extend all of these deﬁnitions to the
case in which I contains either or both of its endpoints by requiring that
α : I →M be extendible to an open interval containing I. More precisely,
if I is an (not necessarily open) interval in R, then α : I →M is smooth,
spacelike, . . . if there exists an open interval ˜I containing I and a curve
˜α : ˜I →M which is smooth, spacelike, . . . and satisﬁes ˜α(t) = α(t) for each
t in I. Generally, we will drop the tilda and use the same symbol for α and
its extension.
If α : I →M is a curve and J ⊆R is another interval and h : J →I,
t = h(s), is an inﬁnitely diﬀerentiable function with h′(s) > 0 for each s in
J, then the curve β = α ◦h : J →M is called a reparametrization of α.
Exercise 1.4.7 Show that β′(s) = h′(s)α′(h(s)) and conclude that all of
the deﬁnitions we have given are independent of parametrization.
We arrive at a particularly convenient parametrization of a timelike worldline
in the following way: If α : [a, b] →M is a timelike worldline in M we deﬁne
the proper time length of α by
L(α) =
 b
a
|α′(t) · α′(t)|
1
2 dt =
 b
a

−ηab
dxa
dt
dxb
dt dt.

48
1 Geometrical Structure of M
Exercise 1.4.8 Show that the deﬁnition of L(α) is independent
of
parametrization.
As the appropriate physical interpretation of L(α) we take
The Clock Hypothesis: If α :
[a, b] →M is a timelike worldline in M,
then L(α) is interpreted as the time lapse between the events α(a) and α(b)
as measured by an ideal standard clock carried along by the particle whose
worldline is represented by α.
The motivation for the Clock Hypothesis is at the same time “obvious” and
subtle. For it we shall require the following theorem which asserts that two
events can be experienced by a single admissible observer if and only if some
(not necessarily free) material particle has both on its worldline.
Theorem 1.4.6 Let p and q be two points in M. Then p−q is timelike and
future-directed if and only if there exists a smooth, future-directed timelike
curve α : [a, b] →M such that α(a) = q and α(b) = p.
We postpone the proof for a moment to show its relevance to the Clock
Hypothesis. We partition the interval [a, b] into subintervals by a = t0 <
t1 < . . . < tn−1 < tn = b. Then, by Theorem 1.4.6, each of the displace-
ment vectors vi = α(ti) −α(ti−1) is timelike and future-directed. τ(vi) is
then interpreted as the time lapse between α(ti−1) and α(ti) as measured by
an admissible observer who is present at both events. If the “material parti-
cle” whose worldline is represented by α has constant velocity between the
events α(ti−1) and α(ti), then τ(vi) would be the time lapse between these
events as measured by a clock carried along by the particle. Relative to any
admissible frame,
τ(vi) =

−ηabΔxa
i Δxb
i =

−ηab
Δxa
i
Δti
Δxb
i
Δti
Δti.
By choosing Δti suﬃciently small, Δx4
i can be made small (by continuity
of α) and, since the speed of the particle relative to our frame of reference
is “nearly” constant over “small” x4-time intervals, τ(vi) should be a good
approximation to the time lapse between α(ti−1) and α(ti) measured by the
material particle. Consequently, the sum
n

i=1

−ηab
Δxa
i
Δti
Δxb
i
Δti
Δti
(1.4.5)
approximates the time lapse between α(a) and α(b) that this particle mea-
sures. The approximations become better as the Δti approach 0 and, in the
limit, the sum (1.4.5) approaches the deﬁnition of L(α).
The argument seems persuasive enough, but it clearly rests on an assump-
tion about the behavior of ideal clocks that we had not previously made
explicit, namely, that acceleration as such has no eﬀect on their rates, i.e.,

1.4 Timelike Vectors and Curves
49
that the “instantaneous rate” of such a clock depends only on its instanta-
neous speed and not on the rate at which this speed is changing. Justifying
such an assumption is a nontrivial matter. One must perform experiments
with various types of clocks subjected to real accelerations and, in the end,
will no doubt be forced to a more modest proposal (“The Clock Hypothesis is
valid for such and such a clock over such and such a range of accelerations”).
For the proof of Theorem 1.4.6 we will require the following preliminary
result.
Lemma 1.4.7 Let α : (A, B) →M be smooth, timelike and future-directed
and ﬁx a t0 in (A, B). Then there exists an ε > 0 such that (t0 −ε, t0 + ε)
is contained in (A, B), α(t) is in the past time cone at α(t0) for every t
in (t0 −ε, t0) and α(t) is in the future time cone at α(t0) for every t in
(t0, t0 + ε).
Proof:
We prove that there exists an ε1 > 0 such that α(t) is in C+
T (α(t0))
for each t in (t0, t0 + ε1). The argument to produce an ε2 > 0 with α(t) in
C−
T (α(t0)) for each t in (t0 −ε2, t0) is similar. Taking ε to be the smaller of
ε1 and ε2 proves the lemma.
Fix an admissible basis {ea} and write α(t) = xa(t)ea for A < t < B.
Now suppose that no such ε1 exists. Then one can produce a sequence t1 >
t2 > · · · > t0 in (t0, B) such that limn→∞tn = t0 and such that one of the
following is true:
(I) Q(α(tn) −α(t0)) ≥0 for all n (i.e., α(tn) −α(t0) is spacelike or null for
every n), or
(II) Q(α(tn) −α(t0)) < 0, but α(tn) −α(t0) is past-directed for every n (i.e.,
α(tn) is in C−
T (α(t0)) for every n).
We show ﬁrst that (I) is impossible. Suppose to the contrary that such a
sequence does exist. Then
Q
α(tn) −α(t0)
tn −t0

≥0
for all n so
Q
x1(tn) −x1(t0)
tn −t0
, . . . , x4(tn) −x4(t0)
tn −t0

≥0.
Thus,
lim
n→∞Q
x1(tn) −x1(t0)
tn −t0
, . . . , x4(tn) −x4(t0)
tn −t0

≥0,
Q

lim
n→∞
x1(tn) −x1(t0)
tn −t0
, . . . , lim
n→∞
x4(tn) −x4(t0)
tn −t0

≥0,
Q
dx1
dt (t0), . . . , dx4
dt (t0)

≥0,
Q (α′(t0)) ≥0,
and this contradicts the fact that α′(t0) is timelike.

50
1 Geometrical Structure of M
Exercise 1.4.9 Apply a similar argument to g(α(tn)−α(t0), α′(t0)) to show
that (II) is impossible.
We therefore infer the existence of the ε1 as required and the proof is
complete.
■
Proof of Theorem 1.4.6: The necessity is clear. To prove the suﬃciency we
denote by α also a smooth, future-directed timelike extension of α to some
interval (A, B) containing [a, b]. By Lemma 1.4.7, there exists an ε1 > 0 with
(a, a + ε1) ⊆(A, B) and such that α(t) is in C+
T (q) for each t in (a, a + ε1).
Let t0 be the supremum of all such ε1. Since b < B it will suﬃce to show
that t0 = B and for this we assume to the contrary that A < t0 < B.
According to Lemma 1.4.7 there exists an ε > 0 such that (t0−ε, t0+ε) ⊆
(A, B), α(t) ∈C−
T (α(t0)) for t in (t0 −ε, t0) and α(t) ∈C+
T (α(t0)) for t in
(t0, t0 + ε). Observe that if α(t0) were itself in C+
T (q), then for any t in
(t0, t0 + ε), (α(t0) −q) + (α(t) −α(t0)) = α(t) −q would be future-directed
and timelike by Lemma 1.4.3 and this contradicts the deﬁnition of t0. On
the other hand, if α(t0) were outside the null cone at q, then for some t’s in
(t0 −ε, t0), α(t) would be outside the null cone at q and this is impossible
since, again by the deﬁnition of t0, any such α(t) is in C+
T (q). The only
remaining possibility is that α(t0) is on the null cone at q. But then the past
time cone at α(t0) is disjoint from the future time cone at q and any t in
(t0 −ε, t0) gives a contradiction. We conclude that t0 must be equal to B
and the proof is complete.
■
As promised we now deliver what is for most purposes the most useful
parametrization of a timelike worldline α : I →M. First let us appeal to
Exercises 1.4.7 and 1.4.8 and translate the domain of α in the real line if
necessary to assume that it contains 0. Now deﬁne the proper time function
τ(t) on I by
τ = τ(t) =
 t
0
|α′(u) · α′(u)|
1
2 du.
Thus, dτ
dt = |α′(t)·α′(t)|1/2 which is positive and inﬁnitely diﬀerentiable since
α is timelike. The inverse t = h(τ) therefore exists and dh
dτ =
 dτ
dt
−1 > 0 so we
conclude that τ is a legitimate parameter along α (physically, we are simply
parametrizing α by time readings actually recorded along α). We shall abuse
our notation somewhat and use the same name for α and its coordinate
functions relative to an admissible basis when they are parametrized by τ
rather than t:
α(τ) = xa(τ)ea.
(1.4.6)
Exercise 1.4.10 Deﬁne α : R →M by α(t) = x0 + t(x −x0), where
Q(x −x0) < 0 and t is in R. Show that τ = τ(x −x0)t and write down
the proper time parametrization of α.
The velocity vector α′(τ) =
dx a
dτ ea of α is called the world velocity (or
4-velocity) of α and denoted U = U aea. Just as the familiar arc length

1.4 Timelike Vectors and Curves
51
parametrization of a curve in R3 has unit speed, so the world velocity of a
timelike worldline is always a unit timelike vector.
Exercise 1.4.11 Show that
U · U = −1
(1.4.7)
at each point along α.
The second proper time derivative α′′(τ) = d2xa
dτ 2 ea of α is called the world
acceleration (or 4-acceleration) of α and denoted A = Aaea. It is always
orthogonal to U and so, in particular, must be spacelike if it is nonzero.
Exercise 1.4.12 Show that
U · A = 0
(1.4.8)
at each point along α. Hint: Diﬀerentiate (1.4.7) with respect to τ.
The world velocity and acceleration of a timelike worldline are, as we shall
see, crucial to an understanding of the dynamics of the particle whose world-
line is represented by α. A given admissible observer, however, is more likely
to parametrize a particle’s worldline by his time x4 than by τ and so will
require procedures for calculating U and A from this parametrization. First
observe that since α(τ) = (x1(τ), . . . , x4(τ)) is smooth, x4(τ) is inﬁnitely dif-
ferentiable. Since α is future-directed, dx 4
dτ is positive so the inverse τ = h(x4)
exists and h′(x4) = ( dx 4
dτ )−1 is positive. Thus, x4 is a legitimate parameter
for α. Moreover,
dτ
dx4 =
α′(x4) · α′(x4)

1
2
=
 
!
!
"1 −
#dx1
dx4
2
+
dx2
dx4
2
+
dx3
dx4
2$
=

1 −β2(x4),
where we have denoted by β(x4) the usual instantaneous speed of the particle
whose worldline is α relative to the frame S(x1, x2, x3, x4). Thus,
dx4
dτ = (1 −β2(x4))−1
2
which we denote by γ = γ(x4). Now, we compute
U i = dxi
dτ = dxi
dx4
dx4
dτ = γ dxi
dx4 ,
i = 1, 2, 3,
and
U 4 = γ,

52
1 Geometrical Structure of M
so
U = U aea = γ dx1
dx4 e1 + γ dx2
dx4 e2 + γ dx3
dx4 e3 + γe4
which it is often more convenient to write as

U 1, U 2, U 3, U 4
= γ
dx1
dx4 , dx2
dx4 , dx3
dx4 , 1

(1.4.9)
or, even more compactly as
(U 1, U 2, U 3, U 4) = γ(
⇀u, 1),
(1.4.10)
where
⇀u is the ordinary velocity 3-vector of α in S. Similarly, one computes
Ai = γ d
dx4

γ dxi
dx4

,
i = 1, 2, 3,
and
A4 = γ d
dx4 (γ),
so that
(A1, A2, A3, A4) = γ d
dx4 (γ
⇀u, γ).
(1.4.11)
Exercise 1.4.13 Using (in this exercise only) a dot to indicate diﬀerentia-
tion with respect to x4 and E : R3 × R3 →R for the usual positive deﬁnite
inner product on R3, prove each of the following in an arbitrary admissible
frame of reference S:
(a) ˙γ = γ3β ˙β.
(b) E(
⇀u,
⇀u) = |
⇀u|2 = β2.
(c) E(
⇀u,
˙⇀u) = E(
⇀u,
⇀a) = β ˙β (
⇀a =
˙⇀u is the usual 3-acceleration in S).
(d) g(A, A) = γ4E(
⇀a,
⇀a) + γ6β2( ˙β)2 = γ4|
⇀a|2 + γ6β2( ˙β)2.
At each ﬁxed point α(τ0) along the length of a timelike worldline α, U(τ0)
is a future-directed unit timelike vector and so may be taken as the timelike
vector e4 in some admissible basis for M. Relative to such a basis, U(τ0) =
(0, 0, 0, 1). Letting x4
0 = x4(τ0) we ﬁnd from (1.4.9) that
 dxi
dx4

x4=x4
0
= 0,
i = 1, 2, 3,
and so β

x4
0

= 0 and γ

x4
0

= 1. The reference frame corresponding to
such a basis is therefore thought of as being “momentarily

x4 = x4
0

at rest”
relative to the particle whose worldline is α. Any such frame of reference

1.4 Timelike Vectors and Curves
53
is called an instantaneous rest frame for α at α(τ0). Notice that Exer-
cise 1.4.12(d) gives
g(A, A) = |
⇀a|2
(1.4.12)
in an instantaneous rest frame. Since g(A, A) is invariant under Lorentz trans-
formations we ﬁnd that all admissible observers will agree, at each point along
α, on the magnitude of the 3-acceleration of α relative to its instantaneous
rest frames.
As an illustration of these ideas we will examine in some detail the follow-
ing situation. A futuristic explorer plans a journey to a distant part of the
universe. For the sake of comfort he will maintain a constant acceleration of
1g (one “earth gravity”) relative to his instantaneous rest frames (assuming
that he neither diets nor overindulges his “weight” will remain the same as on
earth throughout the trip). We begin by calculating the explorer’s worldline
α(τ). As usual we denote by U(τ) and A(τ) the world velocity and world
acceleration of α respectively. Thus, (1.4.7), (1.4.8) and (1.4.12) give
U · U = −1,
(1.4.13)
U · A = 0,
(1.4.14)
A · A = g2
(a constant).
(1.4.15)
We examine the situation from an admissible frame of reference in which the
explorer’s motion is along the positive x1-axis. Thus, U 2 = U 3 = A2 = A3 = 0
and (1.4.13), (1.4.14) and (1.4.15) become
(U 1)2 −(U 4)2 = −1,
(1.4.16)
U 1A1 −U 4A4 = 0,
(1.4.17)
(A1)2 −(A4)2 = g2.
(1.4.18)
Exercise 1.4.14 Solve these last three equations for A1 and A4 to obtain
A1 = gU 4 and A4 = gU 1.
The result of Exercise 1.4.14 is a system of ordinary diﬀerential equations for
U 1 and U 4. Speciﬁcally, we have
dU 1
dτ
= gU 4
(1.4.19)
and
dU 4
dτ
= gU 1.
(1.4.20)
Diﬀerentiate (1.4.19) with respect to τ and substitute into (1.4.20) to obtain
d2U 1
dτ2 = g2U 1.
(1.4.21)

54
1 Geometrical Structure of M
The general solution to (1.4.21) can be written
U 1 = U 1(τ) = a sinh gτ + b coshgτ.
Assuming that the explorer accelerates from rest at τ = 0(U 1(0) = 0,
A1(0) = g) one obtains
U 1(τ) = sinh gτ.
(1.4.22)
Equation (1.4.19) now gives
U 4(τ) = cosh gτ.
(1.4.23)
Integrating (1.4.22) and (1.4.23) and assuming, for convenience, that x1(0) =
1/g and x4(0) = 0, one obtains
⎧
⎪
⎨
⎪
⎩
x1 = 1
g cosh gτ,
x4 = 1
g sinh gτ.
(1.4.24)
Observe that (1.4.24) implies that (x1)2 −(x4)2 = 1/g2 so that our explorer’s
worldline lies on a hyperbola in the 2-dimensional representation of M (see
Figure 1.4.1).
Exercise 1.4.15 Assume that the explorer’s point of departure (at x1 =
1/g) was the earth, which is at rest in the frame of reference under consid-
eration. How far from the earth (as measured in the earth’s frame) will the
explorer be after
Fig. 1.4.1

1.5 Spacelike Vectors
55
(a) 40 years as measured on earth? (How much time will have elapsed on the
rocket?) Answers: 39 light years (4.38 years).
(b) 40 years as measured on the rocket? (How much time will have elapsed
on earth?) Answers: 1017 light years (1017 years).
Hint: It will simplify the arithmetic to measure in light years rather than
meters. Then g ≈1 (light year)−1.
We conclude this section with a theorem which asserts quite generally
that an accelerated observer such as the explorer in the preceding discussion
of hyperbolic motion or the “rocket twin” in the twin paradox must always
experience a time dilation not experienced by those of us who remain at rest
in an admissible frame.
Theorem 1.4.8 Let α : [a, b] →M be a timelike worldline in M from
α(a) = q to α(b) = p. Then
L(α) ≤τ(p −q)
(1.4.25)
and equality holds if and only if α is a parametrization of a timelike straight
line joining q and p.
Proof:
By Theorem 1.4.6, p −q is timelike and future-directed so we may
select a basis {ea} with q = x1
0e1 + x2
0e2 + x3
0e3 + x4
qe4, p = x1
0e1 + x2
0e2 +
x3
0e3 + x4
pe4 and τ(p −q) = x4
p −x4
q = Δx4. Now parametrize α by x4. Then
L(α) =
 x4
p
x4q
 
!
!
"1 −
#dx1
dx4
2
+
dx2
dx4
2
+
dx3
dx4
2$
dx4
≤
 x4
p
x4q
dx4 = Δx4 = τ(p −q).
Moreover, equality holds if and only if
dx i
dx 4 = 0 for i = 1, 2, 3, that is, if
and only if xi is constant for i = 1, 2, 3 and this is the case if and only if
α(x4) = x1
0e1 + x2
0e2 + x3
0e3 + x4e4 for x4
q ≤x4 ≤x4
p as required.
■
1.5 Spacelike Vectors
Now we turn to spacelike separations, i.e., we consider two events x and x0
for which Q(x −x0) > 0. Relative to any admissible basis we have (Δx1)2 +
(Δx2)2 +(Δx3)2 > (Δx4)2 so that x−x0 lies outside the null cone at x0 and
there is obviously no admissible basis in which the spatial separation of the
two events is zero, i.e., there is no admissible observer who can experience
both events (to do so he would have to travel faster than the speed of light).
However, an argument analogous to that given at the beginning of Section 1.4
will show that there is a frame in which x and x0 are simultaneous.

56
1 Geometrical Structure of M
Exercise 1.5.1 Show that if Q(x −x0) > 0, then there is an admissible
basis {ˆea} for M relative to which Δˆx4 = 0. Hint: With {ea} arbitrary, take
β = Δx4
Δ
⇀
x and di = Δxi
Δ
⇀
x and proceed as at the beginning of Section 1.4.
Exercise 1.5.2 Show that if Q(x−x0) > 0 and s is an arbitrary real number
(positive, negative or zero), then there is an admissible basis for M relative
to which the temporal separation Δx4 of x and x0 is s (so that admissible
observers will, in general, not even agree on the temporal order of x and x0).
Since ((Δx1)2 + (Δx2)2 + (Δx3)2)
1
2 =

(Δx4)2 + Q(x −x0) in any admis-
sible frame and since (Δx4)2 can assume any non-negative real value, the
spatial separation of x and x0 can assume any value greater than or equal
to

Q(x −x0); there is no frame in which the spatial separation is less than
this value. For any two events x and x0 for which Q(x −x0) > 0 we deﬁne
the proper spatial separation S(x −x0) of x and x0 by
S(x −x0) =

Q(x −x0),
and regard it as the spatial separation of x and x0 in any frame of reference
in which x and x0 are simultaneous.
Fig. 1.5.1
Let T be an arbitrary timelike straight line containing x0. We have seen
that T can be identiﬁed with the worldline of some observer at rest in an
admissible frame, but not necessarily stationed at the origin of the spatial
coordinate system of this frame (we consider the special case of a time axis
shortly). Let x in M be such that x−x0 is spacelike and let x1 and x2 be the
points of intersection of T with CN(x) as shown in Figure 1.5.1. We claim that
S2(x −x0) = τ(x0 −x1)τ(x2 −x0)
(1.5.1)

1.5 Spacelike Vectors
57
(a result ﬁrst proved by Robb [R]). To prove (1.5.1) we observe that, since
x −x1 is null,
0 = Q(x −x1) = Q((x0 −x1) + (x −x0)),
0 = −τ 2(x0 −x1) + 2(x0 −x1) · (x −x0) + S2(x −x0).
(1.5.2)
Similarly, since x2 −x is null,
0 = −τ2(x2 −x0) −2(x2 −x0) · (x −x0) + S2(x −x0).
(1.5.3)
There exists a constant k > 0 such that x2 −x0 = k(x0 −x1) so τ2(x2 −
x0) = k2τ 2(x0 −x1). Multiplying (1.5.2) by k and adding the result to (1.5.3)
therefore yields
−(k + k2)τ 2(x0 −x1) + (k + 1)S2(x −x0) = 0.
Since k + 1 ̸= 0 this can be written
S2(x −x0) = kτ 2(x0 −x1)
= τ(x0 −x1)(kτ(x0 −x1))
= τ(x0 −x1)τ(x2 −x0)
as required.
Suppose that the spacelike displacement vector x−x0 is orthogonal to the
timelike straight line T . Then (with the notation as above) (x0−x1)·(x−x0) =
(x2 −x0) · (x −x0) = 0 so (1.5.2) and (1.5.3) yield S(x −x0) = τ(x2 −x0) =
τ(x0 −x1) which we prefer to write as
S(x −x0) = 1
2(τ(x0 −x1) + τ(x2 −x0)).
(1.5.4)
In particular, this is true if T is a time axis. We have seen that, in this
case, T can be identiﬁed with the worldline of an admissible observer O and
the events x and x0 are simultaneous in this observer’s reference frame. But
then S(x −x0) is the distance in this frame between x and x0. Since x0
lies on T we ﬁnd that (1.5.4) admits the following physical interpretation:
The O-distance of an event x from an admissible observer O is one-half the
time lapse measured by O between the emission and reception of light signals
connecting O with x.
Exercise 1.5.3 Let x, x0 and x1 be events for which x −x0 and x1 −x are
spacelike and orthogonal. Show that
S2(x1 −x0) = S2(x1 −x) + S2(x −x0)
(1.5.5)
and interpret the result physically by considering a time axis T which is
orthogonal to both x −x0 and x1 −x.

58
1 Geometrical Structure of M
Suppose that v and w are nonzero vectors in M with v · w = 0. Thus
far we have shown the following: If v and w are null, then they must
be parallel (Theorem 1.2.1). If v is timelike, then w must be spacelike
(Corollary 1.3.2). If v and w are spacelike, then their proper spatial lengths
satisfy the Pythagorean Theorem S2(v+w) = S2(v)+S2(w) (Exercise 1.5.3).
Exercise 1.5.4 Can a spacelike vector be orthogonal to a nonzero null
vector?
1.6 Causality Relations
We begin by deﬁning two order relations ≪and < on M as follows: For x
and y in M we say that x chronologically precedes y and write x ≪y if
y −x is timelike and future-directed, i.e., if y is in C+
T (x). We will say that x
causally precedes y and write x < y if y −x is null and future-directed, i.e.,
if y is in C+
N(x). Both ≪and < are called causality relations because they
establish a causal connection between the two events in the sense that the
event x can inﬂuence the event y either by way of the propagation of some
material phenomenon if x ≪y or some electromagnetic eﬀect if x < y.
Exercise 1.6.1 Prove that ≪is transitive, i.e., that x ≪y and y ≪z
implies x ≪z, and show by example that < is not transitive.
It is an interesting, and useful, fact that each of the relations ≪and < can
be deﬁned in terms of the other.
Lemma 1.6.1 For distinct points x and y in M,
x < y if and only if
)
x ̸≪y
and
y ≪z
implies x ≪z.
Proof:
First suppose x < y. Then Q(y−x) = 0 so x ̸≪y is clear. Moreover,
if y ≪z, then z −y is timelike and future-directed. Since y −x is null and
future-directed, Lemma 1.4.3 implies that z −x = (z −y)+(y −x) is timelike
and future-directed, i.e., x ≪z.
For the converse we suppose x ≮y and show that either x ≪y or there
exists a z in M with y ≪z, but x ̸≪z. If x ≮y and x ̸≪y, then y−x is either
timelike and past-directed, null and past-directed or spacelike. In the ﬁrst case
any z with x < z has the property that z−y = (z−x)+(x−y) is timelike and
future-directed (Lemma 1.4.3 again) so y ≪z, but x ̸≪z. Finally, suppose
y−x is either null and past-directed or spacelike (see Figure 1.6.1 (a) and (b)
respectively). In each case we produce a z in M with y ≪z, but x ̸≪z in the
same way. Fix an admissible basis {ea} for M with x = xaea and y = yaea.
If y−x is null and past-directed, then x4−y4 > 0. If y−x is spacelike we may

1.6 Causality Relations
59
Fig. 1.6.1
choose {ea} so that x4−y4 > 0 (Exercise 1.5.2). Now, for each n = 1, 2, 3, . . .,
deﬁne zn in M by zn = y1e1 + y2e2 + y3e3 +

y4 + 1
n

e4. Then zn −y = 1
ne4
is timelike and future-directed so y ≪zn for each n. However,
Q(zn −x) = ((zn −y) + (y −x))2
= Q(zn −y) + 2(zn −y) · (y −x) + Q(y −x)
= −1
n2 + 2
n(x4 −y4) + Q(y −x)
= Q(y −x) + 1
n

2(x4 −y4) −1
n

.
Since Q(y −x) ≥0 and x4 −y4 > 0 we can clearly choose n suﬃciently large
that Q(zn −x) > 0. For this n, z = zn satisﬁes y ≪z, but x ̸≪z.
■
Exercise 1.6.2 Show that, for distinct x and y in M,
x ≪y if and only if
)
x ≮y
and
x < z < y
for some z in M.
A map F : M →M is said to be a causal automorphism if it is one-to-one,
onto and both F and F −1 preserve <, i.e., x < y if and only if F(x) < F(y).
Note that, in particular, F is not assumed to be linear (or even continuous).
We will eventually prove that this actually follows from the deﬁnition.
Exercise 1.6.3 Show that a one-to-one map F of M onto M is a causal
automorphism if and only if both F and F −1 preserve ≪, i.e., x ≪y if and
only if F(x) ≪F(y).

60
1 Geometrical Structure of M
We propose next to embark upon a proof of the remarkable result of
Zeeman [Z1] to which we referred in the Introduction.1 For the statement
of the theorem we deﬁne a translation of M to be a map T : M →M of
the form T (v) = v + v0 for some ﬁxed v0 in M and a dilation to be a map
K : M →M such that K(v) = kv for some positive real number k. An or-
thogonal transformation L : M →M is said to be orthochronous if x·Lx < 0
for all timelike or null and nonzero x.
Exercise 1.6.4 Show that any translation, dilation, orthochronous orthog-
onal transformation, or any composition of such mappings is a causal auto-
morphism.
Zeeman’s Theorem asserts that we have just enumerated them all.
Theorem 1.6.2 Let F : M →M be a causal automorphism of M. Then
there exists an orthochronous orthogonal transformation L : M →M, a
translation T : M →M and a dilation K : M →M such that F = T ◦K ◦L.
For the proof we will require a sequence of ﬁve lemmas, the ﬁrst of which, at
least, is easy.
Lemma 1.6.3 A causal automorphism F : M →M maps light rays to light
rays. More precisely, if x < y and Rx,y is the light ray through x and y, then
F(Rx,y) = RF (x),F (y).
Proof:
Since both F and F −1 preserve <, F maps null cones to null cones
so F(CN(x)) = CN(F(x)) and F(CN(y)) = CN(F(y)). By Theorem 1.2.2,
Rx,y = CN(x) ∩CN(y) and RF (x),F (y) = CN(F(x)) ∩CN(F(y)). Thus,
F(Rx,y) = F(CN(x) ∩CN(y))
= F(CN(x)) ∩F(CN(y))
= CN(F(x)) ∩CN(F(y))
= RF (x),F (y).
■
Lemma 1.6.4 A causal automorphism F : M →M maps parallel light rays
onto parallel light rays.
Proof:
Let R1 and R2 be two distinct parallel light rays in M and P the
(2-dimensional) plane containing them. Any plane in M is the translation of
a plane through the origin which contains 0, 1 or 2 independent null vectors
(depending on whether the plane is outside the null cone to each of its points,
tangent to these null cones or intersects all of its time cones). Only the second
two cases are relevant to P however.
1The proof is considerably more demanding than anything we have attempted thus far and
might reasonably be omitted on a ﬁrst reading.

1.6 Causality Relations
61
Suppose ﬁrst that P contains two independent null directions. Then it
contains two families {Rα} and {Sβ} of light rays with all of the Rα parallel
to R1 and R2 and all of the Sβ parallel to some light ray which intersects
both R1 and R2. Thus, the families {F(Rα)} and {F(Sβ)} are two families
of light rays in M with the following properties:
1. No two of the F(Rα) intersect.
2. No two of the F(Sβ) intersect.
3. Each F(Rα) intersects every F(Sβ).
To show that F(R1) and F(R2) are parallel it will suﬃce (since they do not
intersect) to show them coplanar. Suppose not. Then F(R1) and F(R2) lie
in some 3-dimensional aﬃne subspace R3 of M. Since each F(Sβ) intersects
both F(R1) and F(R2), it too must lie in R3. Thus, by #3 above, all of the
F(Rα) are contained in R3. We claim that, as a result, no F(Rα) can be
coplanar with either F(R1) or F(R2) (unless α = 1 or α = 2). For suppose
to the contrary that some F(Rα) were coplanar with, say, F(R1). Every
F(Sβ) intersects both F(Rα) and F(R1) so it too must lie in this plane.
Since F(R2) does not (by assumption) lie in this plane it can intersect the
plane in at most one point. Thus, F(R2) intersects at most one F(Sβ) and
this contradicts #3 above. Consequently, we may select an F(R3) such that
no two of {F(R1), F(R2), F(R3)} are coplanar. Since {F(Sβ)} is then the
family of straight lines in R3 intersecting all of {F(R1), F(R2), F(R3)} it
is the family of generators (rulings) for a hyperboloid of one sheet in R3
(this old, and none-too-well-known, result in analytic geometry is proved on
pages 105–106 of [Sa]). In the same way one shows that {F(Rα)} is the other
family of rulings for this hyperboloid. But then each F(Rα) would be parallel
to some F(Sβ) and this again contradicts #3 above.
Finally, we consider the case in which P contains only one independent
null direction (and so is tangent to each of its null cones). Any point in M has
through it a light ray parallel to both R1 and R2. Since the tangent space to
the null cone at each point of R1 is (only) 3-dimensional and since the same
is true of R2 we may select a light ray R3 parallel to both R1 and R2 and not
in either of these tangent spaces. Thus, the argument given above applies to
R1 and R3 as well as R2 and R3. Consequently, F(R1) and F(R2) are both
parallel to F(R3) and so are parallel to each other.
■
Let Rx,y = {x + r(y −x) : r ∈R} be a light ray and F(Rx,y) = {F(x) +
s(F(y) −F(x)) : s ∈R} its image under F. We regard s as a function
of r : s = f(r). Our next objective is to show that f is linear, i.e., that
f(r + t) = f(r) + f(t) and f(tr) = tf (r) for all r and t in R. First though,
a few preliminaries. A map g : Rx,y →Rx,y is called a translation of Rx,y if
there exists a ﬁxed t in R such that
g(x + r(y −x)) = x + (r + t)(y −x)

62
1 Geometrical Structure of M
for all r in R. We shall say that a translation g of a light ray R lifts to F(R)
if there is a translation e : F(R) →F(R) such that the diagram
commutes, i.e., such that F ◦g = e ◦F. We show next that, in fact, every
translation of R lifts to F(R).
Lemma 1.6.5 Let R be a light ray, g:R →R a translation of R and F:M →
M a causal automorphism. Then g lifts to a translation e : F(R) →F(R)
of F(R).
Proof:
For the proof we will construct a family of translations of R which
clearly do lift and then prove that this family exhausts all the translations
of R.
Select a light ray R1 parallel to R and such that the plane of R and
R1 contains two independent null directions. This plane therefore contains
a family {Sβ} of parallel light rays all of which meet R and R1. The family
{Sβ} therefore determines an obvious parallel displacement map g1 of R onto
R1 (see Figure 1.6.2). Since F carries parallel light rays to parallel light rays
there is a parallel displacement e1 of F(R) onto F(R1) for which the diagram

1.6 Causality Relations
63
Fig. 1.6.2
commutes. Now choose a light ray R2 parallel to R1 (and therefore to R) such
that the planes of R1 and R2 and of R and R2 both contain two independent
null directions. Construct g2, e2 and g3, e3 as above so that all of the following
diagrams commute.
Now compose to get

64
1 Geometrical Structure of M
Observe that if R, R1 and R2 were all coplanar, then g and e would both
necessarily be the identity. As it is g and e, being compositions of parallel
displacements, are translations of R and F(R) respectively. Consequently,
any translation g of R constructed in this way as a composition of three such
parallel displacements lifts to F(R).
We claim now that the proof will be complete if we can show that
for some particular light ray ˜R every translation of
˜R is realizable as
such a composition. Indeed, if this has been proved for some ˜R we show
that it is also true for R as follows: Select some composition G of a
translation and an orthochronous orthogonal transformation that carries R
onto ˜R (convince yourself that this can be done, or see Theorem 1.7.2).
Since G is aﬃne, a translation g of R gives rise to a translation ˜g =
G ◦g ◦G−1 of ˜R. Now represent ˜g as a composition ˜g = ˜g3 ◦˜g2 ◦˜g1 of par-
allel displacements as indicated above. Then g = G−1 ◦˜g3 ◦˜g2 ◦˜g1 ◦G =
(G−1 ◦˜g3 ◦G) ◦(G−1 ◦˜g2 ◦G) ◦(G−1 ◦˜g3 ◦G). Moreover, since G and G−1
are causal automorphisms and so preserve parallel light rays by Lemma 1.6.4,
we have produced a decomposition
R = G−1( ˜R) −−−−→
g1
G−1( ˜R1) −−−−→
g2
G−1( ˜R2) −−−−→
g3
G−1( ˜R) = R
of g into a composition of parallel displacements gi = G−1 ◦˜gi ◦G as required.
The particular light ray we choose to focus our attention on is obtained as
follows: Fix an admissible basis {ea} and take ˜R to be the light ray through
x = (0, 0, 0, 0) and y = (0, 0, 1, 1). Now consider a translation ˜g of ˜R deﬁned
by ˜g(x+r(y−x)) = ˜g(0, 0, r, r) = (0, 0, r+t, r+t). In particular, ˜g carries x =
(0, 0, 0, 0) to ˜g(x) = (0, 0, t, t). Let x1 = (0, −t, 0, t) and x2 = (0, 0, 0, 2t) and
take ˜R1 and ˜R2 to be the light rays parallel to ˜R and through x1 and x2
respectively. We claim that the required parallel displacements ˜g1, ˜g2 and ˜g3
are deﬁned and moreover that
x −−−−→
˜g1
x1 −−−−→
˜g2
x2 −−−−→
˜g3
˜g(x)
(1.6.1)
so that ˜g(x) = (˜g3 ◦˜g2 ◦˜g1)(x). Since ˜g3 ◦˜g2 ◦˜g1 is a translation of ˜R that
agrees with ˜g at x = (0, 0, 0, 0) it follows that ˜g = ˜g3 ◦˜g2 ◦˜g1. All the veriﬁ-
cations in (1.6.1) are the same so we illustrate by showing that ˜g1(x) = x1

1.6 Causality Relations
65
Fig. 1.6.3
(see Figure 1.6.3). Note that the plane of ˜R and ˜R1 can contain at most two
families of parallel light rays. The light rays parallel to ˜R (and ˜R1) form one
such family. Since the line joining x and x1 is also null and not parallel to ˜R
it must be in the second family. Thus, ˜g1 exists and, obviously, ˜g1(x) = x1.
■
With Lemma 1.6.5 we can show that a causal automorphism is linear on
each light ray. More precisely, we prove:
Lemma 1.6.6 Let R = {x + r(y −x) : x < y, r ∈R} be a light ray,
F : M →M a causal automorphism and F(R) = {F(x) + s(F(y) −F(x)) :
s ∈R} the image of R under F. Then, regarding s as a function of r, say,
s = f(r), we have f(r + t) = f(r) + f(t) and f(tr) = tf (r) for all r and t
in R.
Proof:
Observe ﬁrst that f(0) = 0. Now, ﬁx a t in R. We wish to show
that, for any r in R, f(r + t) = f(r) + f(t), i.e., that
F(x + (r + t)(y −x)) = F(x) + (f(r) + f(t))(F(y) −F(x)).
(1.6.2)
Let g : R →R denote the translation of R by t, i.e., g(x+r(y−x)) = x+(r+
t)(y−x). By Lemma 1.6.5, there exists a translation e : F(R) →F(R) of F(R)
such that F ◦g = e◦F. Suppose that e is the translation of F(R) by u = u(t),
i.e., that e(F(x) + s(F(y) −F(x))) = F(x) + (s + u(t))(F(y) −F(x)). Then

66
1 Geometrical Structure of M
F(x + (r + t)(y −x)) = F(g(x + r(y −x)))
= F ◦g(x + r(y −x))
= e ◦F(x + r(y −x))
= e(F(x) + f(r)(F(y) −F(x)))
= F(x) + [f(r) + u(t)](F(y) −F(x))
so that f(r+t) = f(r)+u(t) for any r. Setting r = 0 gives f(t) = f(0)+u(t) =
u(t) so we obtain f(r + t) = f(r) + f(t) as required.
In particular, f(2r) = f(r + r) = f(r) + f(r) = 2f(r) and, by induction,
f(nr) = nf (r) for n = 0, 1, 2, . . .. Moreover, f(r) = f(−r + 2r) = f(−r) +
2f(r) so f(−r) = −f(r) and, again by induction, f(nr) = nf (r) for n = 0,
±1, ±2, . . .. If m is also an integer and n is a nonzero integer, nf
 m
n r

=
f(mr) = mf (r) so f
 m
n r

=
m
n f(r). Thus, f(tr) = tf (r) for any rational
number t. Finally, observe that, since F preserves < in M, f preserves < in
R and is therefore continuous on R. Since any real number t is the limit of
a sequence of rational numbers we ﬁnd that f(tr) = tf (r) for any t in R and
the proof is complete.
■
We conclude from Lemma 1.6.6 that if Rx,y = {x + r(y −x) : r ∈R}
is a light ray and F is a causal automorphism, then there exists a nonzero
constant k such that F(Rx,y) = {F(x)+kr(F(y)−F(x)) : r ∈R}. However,
since r = 1 on Rx,y gives y, r = 1 on F(Rx,y) must give F(y) and so k = 1
and we have F(Rx,y) = {F(x) + r(F(y) −F(x)) : r ∈R}.
Lemma 1.6.7 Let F : M →M be a causal automorphism. Then F is an
aﬃne mapping, i.e., its composition with some translation of M (perhaps the
identity) is a linear transformation.
Proof:
By ﬁrst composing with a translation if necessary we may assume
that F(0) = 0 and so the problem is to show that F is linear (the compo-
sition of a causal automorphism and a translation is clearly another causal
automorphism).
Select a basis {v1, v2, v3, v4} for M consisting of null vectors (Exercise
1.2.1). Deﬁne a map G : M →M by
G(y) = G
 4

i=1
yivi

=
4

i=1
yiF(vi)
for each y = 4
i=1 yivi (for the remainder of this proof we temporarily sus-
pend the summation convention and use a  whenever a summation is in-
tended). G is obviously linear and we shall prove that F is linear by showing
that, in fact, F = G. For each i = 1, 2, 3, 4 we let Mi denote the subspace
of M spanned by {vj : j ≤i}. Thus, M1 is a light ray and M4 is all of
M. We prove F | Mi = G | Mi for all i = 1, 2, 3, 4. For i = 1 this is clear

1.6 Causality Relations
67
Fig. 1.6.4
since F(v1) = G(v1) and, by Lemma 1.6.6, F is linear on M1. Now assume
that i = 2, 3 or 4 and that F | Mi−1 = G | Mi−1. We show from this that
F | Mi = G | Mi as follows: Any y in Mi can be uniquely represented as
y = x + yivi, where x is in Mi−1 and there is no sum over i in yivi. Thus,
y −x = yivi is null since vi is null. We consider two light rays, the ﬁrst (R1)
through x and y and the second (R2) through 0 and yivi (see Figure 1.6.4).
R1 and R2 are parallel so F(R1) and F(R2) are parallel by Lemma 1.6.4.
Consequently,
F(R1) = {F(x) + r(F(y) −F(x)) : r ∈R}
and
F(R2) =

F(0) + r(F(yivi) −F(0)) : r ∈R

= {0 + r(F(yivi) −0) : r ∈R}.
Since F(R1) and F(R2) are parallel and r = 0 gives 0 on F(R2) and F(x)
on F(R1), translation of F(R2) by F(x) gives F(R1). For r = 1 this gives
F(x) + [0 + (F(yivi) −0)] = F(x) + (F(y) −F(x)),
that is,
F(yivi) = F(y) −F(x).

68
1 Geometrical Structure of M
Thus,
F(y) = F(x) + F(yivi)
= G(x) + F(yivi)
since x ∈Mi−1
= G(x) + yiF(vi)
by Lemma 1.6.6
= G(x) + yiG(vi)
= G(x + yivi)
= G(y)
and the proof is complete.
■
Finally, we are prepared for:
Proof of Theorem 1.6.2: According to Lemma 1.6.7 there is a transla-
tion, which we write T −1 : M →M, such that T −1◦F is linear. To complete
the proof we need only produce a positive constant 1
k such that 1
k T −1 ◦F
preserves the quadratic form on M. For then, by Lemma 1.2.3, 1
k T −1 ◦F is
a (necessarily orthochronous) orthogonal transformation L. Denoting by K
the dilation K(v) = kv,
1
k T −1 ◦F = L therefore gives F = T ◦K ◦L as
required.
Since both T −1 ◦F and its inverse take 0 to 0 and preserve <, T −1 ◦F
must carry the null cone CN(0) onto itself, i.e., Q(x) = 0 if and only if
Q(T −1 ◦F(x)) = 0. Since T −1◦F is linear, both Q(x) and Q(T −1◦F(x)) are
quadratic forms and, as we have just observed, they have the same kernel,
i.e., vanish for the same x’s. But two indeﬁnite quadratic forms with the same
kernel diﬀer at most by a multiplicative constant (Theorem 14.10 of [K]) so
there exists a constant k′ such that Q(x) = k′Q(T −1 ◦F(x)) for all x. But
T −1 ◦F is a causal automorphism and so preserves the upper time cone. In
particular, Q(x) < 0 if and only if Q(T −1 ◦F(x)) < 0, so k′ must be positive.
Letting k = (k′)−1/2 we therefore have Q(x) = Q
 1
kT −1 ◦F(x)

so 1
k T −1◦F
preserves the quadratic form on M and the proof is complete.
■
Remark:
For those with some basic topology, [Nan] contains a simple
argument that reduces the proof of linearity in Zeeman’s Theorem to an
appeal to the so-called Fundamental Theorem of Projective Geometry.
1.7 Spin Transformations and the Lorentz Group
In this section we develop a new and very powerful technique for the con-
struction and investigation of Lorentz transformations. The principal tool is
a certain homomorphism (called the “spinor map”) from the group of 2 × 2
complex matrices with determinant 1 onto the Lorentz group L. With it we
uncover a remarkable connection between Lorentz transformations and the

1.7 Spin Transformations and the Lorentz Group
69
familiar fractional linear transformations of complex analysis. This, in turn,
has some rather startling things to say about the Lorentz group and the
phenomenon of length contraction.
We begin by establishing some notation. C 2×2 denotes the set of all 2 × 2
matrices
A = [aij] =
*
a11
a12
a21
a22
+
with complex entries. Using an overbar to designate complex conjugation,
the conjugate transpose ACT of A is deﬁned by
ACT =
*¯a11
¯a21
¯a12
¯a22
+
.
An H in C 2×2 is said to be Hermitian if HCT = H and we denote by H2
the set of all such.
Exercise 1.7.1 Show that any Hermitian H in C 2×2 is uniquely expressible
in the form
H =
* x3 + x4
x1 + ix2
x1 −ix2
−x3 + x4
+
,
(1.7.1)
where xa, a = 1, 2, 3, 4, are real. Show, moreover, that the representation
(1.7.1) is equivalent to
H = x1σ1 + x2σ2 + x3σ3 + x4σ4,
(1.7.2)
where σi, i = 1, 2, 3, are the Pauli spin matrices
σ1 =
*0 1
1 0
+
,
σ2 =
* 0
i
−i 0
+
,
σ3 =
*1
0
0
−1
+
and σ4 is the 2 × 2 identity matrix.
We denote by SL(2, C) the set of all A in C 2×2 with determinant 1. SL(2, C) is
called the special linear group of order 2 and is, indeed, a group of matrices,
that is, closed under the formation of products and inverses. Elements of
SL(2, C) are often called spin transformations. Each A in SL(2, C) gives rise
to a mapping MA : H2 →H2 deﬁned by
MA(H) = AHACT
for every H in H2(MA(H) is in H2 since (AH ACT)CT
= (ACT)CT ·
(AH )CT = AH CTACT = AH ACT). Moreover, det MA(H) = det(AH ACT)
= (det A)(det H)(det ACT) = det H. But MA(H) can be uniquely written in
the form
MA(H) =
*
ˆx3 + ˆx4
ˆx1 + iˆx2
ˆx1 −iˆx2
−ˆx3 + ˆx4
+
(1.7.3)

70
1 Geometrical Structure of M
for some real numbers ˆxa, a = 1, 2, 3, 4. Computing the determinants in
(1.7.1) and (1.7.2) therefore gives
(ˆx1)2 + (ˆx2)2 + (ˆx3)2 −(ˆx4)2 = (x1)2 + (x2)2 + (x3)2 −(x4)2.
(1.7.4)
Thus, the mapping [xa] →[ˆxa] deﬁned by
*
ˆx3 + ˆx4
ˆx1 + iˆx2
ˆx1 −iˆx2
−ˆx3 + ˆx4
+
= A
*
x3 + x4
x1 + ix 2
x1 −ix 2
−x3 + x4
+
ACT,
(1.7.5)
which is clearly linear, preserves the quadratic form ηabxaxb. According to
Lemma 1.2.3, the matrix of this map is therefore a general, homogeneous
Lorentz transformation. We intend to construct this matrix explicitly from
the entries of
A =
*α
β
γ
δ
+
.
Letting h11 = x3 + x4, h12 = x1 + ix 2, h21 = x1 −ix 2, h22 = −x3 + x4 (and
ˆh11 = ˆx3 + ˆx4, etc.) we have
⎡
⎢⎢⎣
h11
h12
h21
h22
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
0
1
1
1
i
0
0
1
−i
0
0
0
0
−1
1
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦
which we will write more compactly as
[hij ] = G [xi]
and similarly for [ˆhij ]. Moreover, it is easy to check that
G−1 = 1
2
⎡
⎢⎢⎣
0
1
1
0
0
−i
i
0
1
0
0 −1
1
0
0
1
⎤
⎥⎥⎦.
Exercise 1.7.2 Write out the product
AHACT =
*
α β
γ
δ
+ *
h11
h12
h21
h22
+ *
¯α
¯γ
¯β
¯δ
+
explicitly and show that MA(H) = AHACT is equivalent to
⎡
⎢⎢⎣
ˆh11
ˆh12
ˆh21
ˆh22
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
α¯α
α¯β
¯αβ
β ¯β
α¯γ
α¯δ
β¯γ
β¯δ
¯αγ
¯βγ
¯αδ
¯βδ
γ¯γ
γ¯δ
¯γδ
δ¯δ
⎤
⎥⎥⎦
⎡
⎢⎢⎣
h11
h12
h21
h22
⎤
⎥⎥⎦

1.7 Spin Transformations and the Lorentz Group
71
which we will write more concisely as
,
ˆhij
-
= RA [hij ].
Consequently, the map [xa] →[ˆxa] deﬁned by (1.7.5) is given by
[xa] −−−−→
G
[hij ] −−−−→
RA
[ˆhij ] −−−−→
G−1 [ˆxa]
(1.7.6)
and the Lorentz transformation ΛA determined via (1.7.5) [or (1.7.6)] by A is
ΛA = G−1RAG.
Exercise 1.7.3 Calculate the product G−1RAG explicitly to show that the
entries Λab of ΛA are given by
Λ11 = 1
2(α¯δ + ¯βγ + β¯γ + ¯αδ),
Λ12 = i
2(α¯δ + ¯βγ −β¯γ −¯αδ),
Λ21 = i
2(−α¯δ + ¯βγ −β¯γ + ¯αδ),
Λ22 = 1
2(α¯δ −¯βγ −β¯γ + ¯αδ),
Λ31 = 1
2(α¯β −γ¯δ + ¯αβ −¯γδ),
Λ32 = i
2(α¯β −γ¯δ −¯αβ + ¯γδ),
Λ41 = 1
2(α¯β + γ¯δ + ¯αβ + ¯γδ),
Λ42 = i
2(α¯β + γ¯δ −¯αβ −¯γδ),
Λ13 = 1
2(α¯γ + ¯αγ −β¯δ −¯βδ),
Λ14 = 1
2(α¯γ + ¯αγ + β¯δ + ¯βδ),
Λ23 = i
2(−α¯γ + ¯αγ + β¯δ −¯βδ),
Λ24 = i
2(−α¯γ + ¯αγ −β¯δ + ¯βδ),
Λ33 = 1
2(α¯α −γ¯γ −β ¯β + δ¯δ),
Λ34 = 1
2(α¯α −γ¯γ + β ¯β −δ¯δ),
Λ43 = 1
2(α¯α + γ¯γ −β ¯β −δ¯δ),
Λ44 = 1
2(α¯α + β ¯β + γ¯γ + δ¯δ).
(1.7.7)
Observe that the (4,4)-entry of ΛA is positive so ΛA is orthochronous. More-
over, det ΛA = det(G−1RAG) = (det G−1)(det RA)(det G) = det RA and
one shows by direct calculation that det RA = (αδ −βγ)2(¯α¯δ −¯β¯γ)2 = 1 so
that ΛA is proper. The map A →ΛA of SL(2, C) to L is called the spinor
map. Note that if A and B are both in SL(2, C), then
ΛAΛB = (G−1RAG)(G−1RBG) = G−1(RARB)G.
(1.7.8)
But since MAB(H) = (AB)H(AB)CT = ABHBCTACT = A(BHB CT)ACT
= MA(BHB CT) = MA(MB(H)) = MA ◦MB(H) we conclude that MAB =
MA ◦MB and so RAB = RARB. Thus, (1.7.8) gives ΛAΛB = G−1RABG
and so
ΛAΛB = ΛAB.
(1.7.9)

72
1 Geometrical Structure of M
Thus, the spinor map preserves matrix multiplication, i.e., is a group
homomorphism of SL(2, C) to L. It is not one-to-one since it is clear from
(1.7.7) that both A and −A have the same image in L. In fact, we claim that it
is precisely two-to-one, i.e., that if A and B are in SL(2, C) and ΛA = ΛB, then
A = ±B. To see this note that AB−1 is in SL(2, C) and, since the spinor map
is a homomorphism, ΛAB −1 = ΛAΛB−1 = ΛA(ΛB)−1 = ΛA(ΛA)−1 = identity
matrix.
Exercise 1.7.4 Let AB−1 =
*
α β
γ δ
+
and use (1.7.7) for ΛAB−1 (= identity)
to show that AB −1 = ±
*1 0
0 1
+
, i.e., that A = ±B.
Exercise 1.7.5 For each real number θ deﬁne a 2 × 2 matrix A(θ) by
A(θ) =
#
cosh θ
2
−sinh θ
2
−sinh θ
2
cosh θ
2
$
.
Show that A(θ) is in SL(2, C) and that
ΛA(θ) = L(θ) =
⎡
⎢⎢⎣
cosh θ
0
0
−sinh θ
0
1
0
0
0
0
1
0
−sinh θ
0
0
cosh θ
⎤
⎥⎥⎦.
An element A =
*
α β
γ δ
+
of SL(2, C) is said to be unitary if A−1 = ACT, i.e., if
*
α
β
γ
δ
+ *
¯α
¯γ
¯β
¯δ
+
=
*
α¯α + β ¯β
α¯γ + β¯δ
¯αγ + ¯βδ
γ¯γ + δ¯δ
+
=
*
1
0
0
1
+
.
(1.7.10)
The set of all such matrices is denoted SU 2 and is a subgroup of SL(2, C),
i.e., SU 2 is also closed under the formation of products and inverses.
Exercise 1.7.6 Verify this.
Notice that if A is in SU 2, then, by (1.7.10), the (4,4)-entry of ΛA is 1
2(α¯α +
β ¯β + γ¯γ + δ¯δ) = 1
2(1 + 1) = 1 and so ΛA is a rotation in L by Lemma 1.3.4.
Thus, the spinor map carries SU 2 into the rotation subgroup R of L. We
show that, in fact, it maps SU 2 onto R. To do this we borrow a result from
linear algebra (or mechanics, depending on one’s ﬁeld) which asserts that any
3 × 3 rotation matrix

Rij

i,j=1,2,3 can be represented in terms of its “Euler
angles” φ1, θ and φ2 as

1.7 Spin Transformations and the Lorentz Group
73

Rij

=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
cos φ2 cos φ1
−cosφ2 sin φ1
sin φ2 sin θ
−cosθ sin φ1 sin φ2
−cosθ cos φ1 sin φ2
sin φ2 cos φ1
−sin φ2 sin φ1
−cos φ2 sin θ
+ cosθ sin φ1 cos φ2
+ cosθ cos φ1 cos φ2
sin θ sin φ1
sin θ cos φ1
cos θ
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
(this is proved, for example, in [GMS]).
Exercise 1.7.7 Show that
A =
#
cos θ
2e
1
2 i(φ1+φ2)
i sin θ
2e−1
2 i(φ2−φ1)
i sin θ
2e
1
2 i(φ2−φ1)
cos θ
2e−1
2 i(φ1+φ2)
$
is in SU 2 and maps onto
⎡
⎢⎢⎣
0

Rij

0
0
0
0
0
1
⎤
⎥⎥⎦under the spinor map.
With this we can now show that the spinor map is surjective, i.e., that ev-
ery proper, orthochronous Lorentz transformation Λ is Λ±A for some A in
SL(2, C). By Theorem 1.3.5, there exists a real number θ and two rotations
R1 and R2 in L such that Λ = R1L(θ)R2. There exist elements A1 and A2
of SU 2 ⊆SL(2, C) which the spinor map carries onto R1 and R2 respec-
tively. Moreover, A(θ) (as deﬁned in Exercise 1.7.6) maps onto L(θ). Since
the spinor map is a homomorphism, A1A(θ)A2 maps onto R1L(θ)R2 = Λ
and the proof is complete.
And so the elements of SL(2, C) generate Lorentz transformations. But
they do other things as well, perhaps more familiar. Speciﬁcially, each 2 × 2
complex unimodular matrix deﬁnes a (normalized) fractional linear transfor-
mation of the Riemann sphere (extended complex plane). There is, in fact, a
rather surprising connection between these two activities which we intend to
explore since it sheds much light on both the mathematics and the kinematics
of the Lorentz group. First though, a few preliminaries.
Thus far we have thought of a Lorentz transformation Λ exclusively as a
coordinate transformation matrix; what some call a passive transformation
(leaving points ﬁxed, but changing coordinate systems). It will be useful
now, however, to realize that Λ admits an equally natural interpretation as
an active transformation (leaving the coordinate system ﬁxed, but moving
points about). More precisely, let us consider an orthogonal transformation
L : M →M and ﬁx a basis {ea}. Then {ˆea} = {Lea} is the image basis and,
if we write eb = Λab ˆea, then the corresponding Lorentz transformation Λ is
deﬁned by

74
1 Geometrical Structure of M
Λ =
⎡
⎢⎢⎣
Λ11
Λ12
Λ13
Λ14
Λ21
Λ22
Λ23
Λ24
Λ31
Λ32
Λ33
Λ34
Λ41
Λ42
Λ43
Λ44
⎤
⎥⎥⎦.
We emphasize again that Λ is the matrix of L−1 relative to the basis {ˆea}.
Now, for each x in M we may write x = xaea = ˆxaˆea, where [ˆxa] = Λ[xa].
Thus, we think of Λ as acting on the coordinates of a ﬁxed point to give the
coordinates of the same point in a new coordinate system. However, observe
that L−1x = L−1(ˆxaˆea) = ˆxaL−1ˆea = ˆxaea so we may equally well view Λ as
acting on the coordinates [xa] of some point relative to {ea} and yielding the
coordinates [ˆxa] of a new point (namely, L−1x) in the same coordinate system.
It will be crucial somewhat later to observe that, with this new interpretation
of Λ, L−1x has the same position and time in S that x has in ˆS.
We will be much concerned in the remainder of this section with “past
null directions” and the eﬀect had on them by Lorentz transformations. For
each x in the past null cone C−
N(0) at 0 in M we deﬁne the past null direction
R−
x through x by
R−
x = {αx : α ≥0}.
Future null directions are deﬁned analogously and all of our results will have
obvious “future duals”. The null direction through x is the set of all real
multiples of x, i.e., R0,x. Obviously, if y is any positive scalar multiple of x,
then R−
y = R−
x . Observe that if L : M →M is an orthogonal transformation
corresponding to any orthochronous Lorentz transformation Λ, then x ∈
C−
N(0) implies Lx ∈C−
N(0) so R−
Lx is deﬁned. Moreover, L (R−
x ) = L({αx :
α ≥0}) = {L(αx) : α ≥0} = {αLx : α ≥0} = R−
Lx, i.e.,
L

R−
x

= R−
Lx.
(1.7.11)
Consequently, L (and therefore L−1 and so Λ also) can be regarded as a map
on past null directions.
In order to unearth the connection between Lorentz and fractional linear
transformations we observe that there is a natural one-to-one correspondence
between past null directions and the points on a copy of the Riemann sphere.
Speciﬁcally, we ﬁx an admissible basis {ea} for M and denote by S−the
intersection of the past null cone C−
N(0) at 0 with the hyperplane x4 = −1:
S−=

x = xaea : x ∈C−
N(0),
x4 = −1

.
Observe that, since x ∈C−
N(0) if and only if (x1)2 + (x2)2 + (x3)2 =
(x4)2, S−= {x = xaea : (x1)2 + (x2)2 + (x3)2 = 1} and so is a copy of the
ordinary 2-sphere S2 in the instantaneous 3-space x4 = −1 (see Figure 1.7.1).

1.7 Spin Transformations and the Lorentz Group
75
Fig. 1.7.1
Exercise 1.7.8 Show that any past null direction intersects S−in a single
point.
Conversely, every point on S−determines a unique past null direction in M.
To obtain an explicit representation for this past null direction we wish to
regard S−as the Riemann sphere, that is, we wish to identify the points
of S−with extended complex numbers via stereographic projection (see, for
example, [A]). To this end we take N = (0, 0, 1, −1) in S−as the north
pole and project onto the 2-dimensional plane C in x4 = −1 given by
x3 = 0 (see Figure 1.7.2). The relationship between a point P(x1, x2, x3, −1)
other than N on S−and its image ζ in the complex plane C under stereo-
graphic projection from N is easily calculated and is summarized in (1.7.12)
and (1.7.13):
ζ = x1 + ix2
1 −x3 ,
(1.7.12)
x1 = ζ + ¯ζ
ζ ¯ζ + 1,
x2 =
ζ −¯ζ
i(ζ ¯ζ + 1),
(1.7.13)
x3 = ζ ¯ζ −1
ζ ¯ζ + 1,
x4 = −1.

76
1 Geometrical Structure of M
Fig. 1.7.2
Of course, the north pole N(0, 0, 1, −1) on S−corresponds to the point at
inﬁnity in the extended complex plane ¯C. In order to avoid the need to deal
with the point at inﬁnity we prefer to represent extended complex numbers
ζ in so-called “projective homogeneous coordinates”, that is, by a pair
* ξ
η
+
of complex numbers, not both zero, which satisfy
ζ = ξ
η
(any pair
* ξ
0
+
with ξ ̸= 0 gives the point at inﬁnity).
Exercise 1.7.9 Show that if ζ = ξ′
η′ also, then ξ′ = λξ and η′ = λη for some
nonzero complex number λ.
In terms of
* ξ
η
+
, (1.7.13) becomes
x1 = ξ¯η + ¯ξη
ξ¯ξ + η¯η ,
x2 =
ξ¯η −¯ξη
i(ξ¯ξ + η¯η),
(1.7.14)
x3 = ξ¯ξ −η¯η
ξ¯ξ + η¯η ,
x4 = −1.

1.7 Spin Transformations and the Lorentz Group
77
Reversing our point of view we ﬁnd that any pair
,ξ
η
-
of complex numbers,
not both zero, gives rise to a point P(x1, x2, x3, −1) on S−given by (1.7.14).
Being on S−(and therefore on C−
N(0)) this point determines a past null
direction R−
P which, for emphasis, we prefer to denote R−,
ξ
η
-. Multiplying
P by the positive real number ξ¯ξ + η¯η gives rise to another point X on
C−
N(0) : X = Xaea, where
X1 = ξ¯η + ¯ξη,
X3 = ξ¯ξ −η¯η,
X2 = 1
i (ξ¯η −¯ξη),
X4 = −(ξ¯ξ + η¯η).
(1.7.15)
X, of course, also determines a past null direction R−
X and, indeed,
R−
X = R−,ξ
η
-.
(1.7.16)
Finally, we are in a position to tie all of these loose ends together. We
begin with an element A =
,α β
γ δ
-
of SL(2, C). Then A deﬁnes a map which
carries any pair
*
ξ
η
+
, not both zero, onto another such pair which we denote
*ˆξ
ˆη
+
= A
*ξ
η
+
=
*α
β
γ
δ
+ *ξ
η
+
=
*αξ + βη
γξ + δη
+
.
(1.7.17)
Observe that, thought of as a mapping on S−(or ¯C), (1.7.17) deﬁnes a
fractional linear transformation. Indeed, in terms of the extended complex
number ζ = ξ/η, (1.7.17) is equivalent to
ˆζ = αζ + β
γζ + δ .
Now,
,ˆξ
ˆη
-
determines an ˆX in C−
N(0) by (1.7.15) (with hats) and this, in turn,
determines a past null direction R−
ˆ
X = R−,ˆξ
ˆη
-. On the other hand, A also gives
rise, via the spinor map, to a proper, orthochronous Lorentz transformation
ΛA which, regarded as an active transformation, carries X onto a point ΛAX
on C−
N(0). Our objective is to prove that ˆX and ΛAX are, in fact, the same
point so that, in particular, the eﬀect of the fractional linear transformation
(1.7.17) determined by A on past null directions is the same as the eﬀect of
the Lorentz transformation ΛA determined by A, i.e.,

78
1 Geometrical Structure of M
R−
⎡
⎣ˆξ
ˆη
⎤
⎦
= R−
ΛAX.
(1.7.18)
To prove all of this we proceed as follows: Begin by solving (1.7.15) for the
four products ξ¯η, ¯ξη, ξ¯ξ and η¯η to obtain
ξ¯ξ = 1
2

X3 + X4
,
ξ¯η = 1
2(X1 + iX2),
¯ξη = 1
2

X1 −iX2
,
η¯η = 1
2(−X3 + X4),
so that
1
2
*
X3 + X4
X1 + iX2
X1 −iX2
−X3 + X4
+
=
*
ξ¯ξ
ξ¯η
¯ξη
η¯η
+
=
*
ξ
η
+ ¯ξ
¯η

.
(1.7.19)
Now perform the unimodular transformation (1.7.17) to obtain
*ˆξ
ˆη
+
. The
corresponding point ˆX =
ˆXaea given by (1.7.15) with hats must satisfy
(1.7.19) with hats, i.e.,
1
2
* ˆX3 + ˆX4
ˆX1 + i ˆX2
ˆX1 −i ˆX2
−ˆX3 + ˆX4
+
= 1
2
* ˆX3 + ˆX4
ˆX1 + i ˆX2
ˆX1 −i ˆX2
−ˆX3 + ˆX4
+CT
=
**ˆξ
ˆη
+ ,¯ˆξ ¯ˆη
-+CT
=
,¯ˆξ ¯ˆη
-CT *ˆξ
ˆη
+CT
=
*ˆξ
ˆη
+ *
A
*ξ
η
++CT
= A
*ξ
η
+ *ξ
η
+CT
ACT
= A
**
ξ
η
+
[¯ξ ¯η]
+
ACT
= 1
2A
* X3 + X4
X1 + iX 2
X1 −iX 2
−X3 + X4
+
ACT.
Thus,
* ˆX3 + ˆX4
ˆX1 + i ˆX2
ˆX1 −i ˆX2
−ˆX3 + ˆX4
+
= A
*
X3 + X4
X1 + iX 2
X1 −iX 2
−X3 + X4
+
ACT.
(1.7.20)
Comparing (1.7.20) and (1.7.5) and the deﬁnition of ΛA we ﬁnd that, indeed,
ˆX = ΛAX,
so that (1.7.18) is proved.

1.7 Spin Transformations and the Lorentz Group
79
Since the spinor map is surjective, every element of L is ΛA for some A in
SL(2, C) and so every element of L determines a fractional linear transfor-
mation of S−which has the same eﬀect on past null directions (±A give rise
to the same fractional linear transformation). Conversely, since the past null
vectors span M (reconsider Exercise 1.2.1 and select only past-directed vec-
tors), a Lorentz transformation is completely determined by its eﬀect on past
null directions. Some consequences of this correspondence between elements
of L and fractional linear transformations of S−are immediate.
Theorem 1.7.1 A proper, orthochronous Lorentz transformation, if not the
identity, leaves invariant at least one and at most two past null directions.
This follows at once from the familiar fact that any fractional linear trans-
formation of the Riemann sphere, if not the identity, has two (possibly co-
incident) ﬁxed points (see [A]). Another well-known property of fractional
linear transformations is that they are completely determined by their values
on any three distinct points in the extended complex plane (see [A]). Hence:
Theorem 1.7.2 A proper, orthochronous Lorentz transformation is com-
pletely determined by its eﬀect on any three distinct past null directions. More
precisely, given two sets of three distinct past null directions there is one and
only one element of L which carries the ﬁrst set (one-to-one) onto the sec-
ond set.
As our ﬁnal application we will derive a remarkable result of Penrose
[Pen1] related to what has been called the “invisibility of the Lorentz contrac-
tion”. An admissible observer O “observes” in a quite speciﬁc and well-deﬁned
way. One pictures the observer’s frame of reference as a spatial coordinate
grid with clocks located at the lattice points of the grid and either recording
devices or assistants stationed with the clocks to take all of the required local
readings. O then “observes”, say, a moving sphere by either turning on the
devices or alerting the assistants to record the arrival times at their locations
of various points on the sphere. When things have calmed down again O will
collect all of this data for analysis. He may then, for example, construct a
“picture” of the sphere by selecting (arbitrarily) some instant of his time,
collecting together all of the locations in his frame which recorded the pas-
sage of a point on the boundary of the sphere at that instant and “plotting”
these points in his frame. In this way he will ﬁnd himself constructing, not a
sphere, but an ellipsoid due to length contraction in the direction of motion.
What our observer O actually “sees” (through his eye or a camera lens),
however, is not so straightforward. We wish to construct an (admittedly ide-
alized) geometrical representation in M of this “ﬁeld of vision”.
It is a clear evening and, as you stroll outside, you glance up and see
the Big Dipper. More precisely, you direct the surface of your eye toward a
group of incoming photons (idealize and assume one from each star in the
constellation). Regardless of when they left their sources these photons arrive
at this surface simultaneously (in your reference frame) and thereby create

80
1 Geometrical Structure of M
a pattern (image) which is recorded by your brain. This pattern is what
you “see”. Where can we ﬁnd it in M? Each of the photons you see has a
worldline in M which lies along the past null cone C−
N(0) (you are located
at the origin of your coordinate system and the image is registered in your
brain at x4 = 0). Just slightly before x4 = 0 the photons impacted the surface
of your eye and formed their image. At x4 = −1 the photons were all on a
sphere of radius 1 about the origin of your coordinate system and formed on
this sphere the same pattern that your eye registered a bit later. Projecting
this image down to the plane x4 = −1 in M we ﬁnd the worldlines of these
photons intersecting S−in the very image that you “see”. As a geometrical
representation of what you see (at the event x1 = x2 = x3 = x4 = 0) we
therefore take the intersections with S−of the worldlines of all the photons
that trigger your brain to record an image at x4 = 0.
Now we ask the following question. Suppose that what you see is not the
Big Dipper, but something with a circular outline, e.g., a sphere at rest in
your reference frame. What is seen by another admissible observer, moving
relative to your frame, but momentarily coincident with you at the origin?
According to the new observer the sphere is moving and so certainly must
“appear” contracted in the direction of motion. Surely, he must “see” an
elliptical, not a circular image.
But he does not! We propose to argue that, despite the Lorentz contraction
in the direction of motion, the sphere will still present a circular outline
to ˆO (although, in a degenerate case, the circle may “appear” straight).
Indeed, this is merely a reﬂection of yet another familiar property of fractional
linear transformations of the Riemann sphere: they carry circles onto circles.
Thus, if Λ is the Lorentz transformation relating S and ˆS, then, regarded
as an active transformation on past null directions, it carries any family of
such null directions which intersect S−in a circle onto another such family.
In somewhat more detail we recall (page 74) that, for each x in M, Λ(x)
(= L−1(x)) has the same position and time in S that x has in ˆS. In particular,
Λ(x) ∈S−if and only if x ∈ˆS−. Thus, Λ (R−
x ) = R−
Λ(x) “looks the same”
to O at ˆx4 = 0 as R−
x “looks” to ˆO at ˆx4 = 0 (same relative position in the
sky). Now, if we have a family N of past null directions (forming a certain
“image” for O at x4 = 0) it follows that the appearance of this image for ˆO
at ˆx4 = 0 will be the same as the appearance of Λ(N) to O at x4 = 0. If
the rays in N present a circular outline to O at x4 = 0, so will Λ(N) and
therefore ˆO will also see a circular outline at x4 = 0. O and ˆO both “see” a
circular outline.
Exercise 1.7.10 Describe the “degenerate case” in which the circle
“appears” straight.
Exercise 1.7.11 Oﬀer a plausible physical explanation for this “invisibility
of the Lorentz contraction”. Hint: For O the photons which arrive simul-
taneously at the surface of his eye to form their image also left the sphere
simultaneously. Is this true for ˆO?

1.8 Particles and Interactions
81
1.8 Particles and Interactions
A billiard ball rolling with constant speed in a straight line collides with
another billiard ball, initially at rest, and the two balls rebound from the
impact. The actual physical mechanisms involved in such an interaction are
quite complicated, having to do with the electrical repulsion between elec-
trons in the atoms at the surfaces of the two balls. Nevertheless, much can
be said about the motion which results from such a collision even without
detailed information about this electromagnetic interaction. What makes this
possible is the idea (one of the most profound and powerful in all of physics)
that such situations are often governed by conservation laws. Speciﬁcally,
the conservation of Newtonian momentum has immediate implications for
the motion of our billiard balls (for example, that, assuming the collision is
glancing rather than head-on, they will separate along paths that form a right
angle) and these predictions were well borne out by observation, at least until
the 20th century. However, Newtonian physics would make precisely the same
predictions if the billiard balls were replaced by protons travelling at speeds
comparable to that of light and here the observational evidence does not
support these conclusions (e.g., the protons generally separate along paths
which form an angle less than 90◦). In this section we shall investigate the
relativistic alternative to the classical principles of the conservation of mo-
mentum and energy and draw some elementary consequences from it. First,
though, some deﬁnitions.
A material particle in M is a pair (α, m), where α : I →M is a timelike
worldline parametrized by proper time τ and m is a positive real number
called the particle’s proper mass (and is to be identiﬁed intuitively with the
“inertial mass” of the particle from Newtonian mechanics). (α, m) is called a
free material particle if α is of the form α(τ) = x0 + τU for some ﬁxed event
x0 and unit timelike vector U. Recall that, for any timelike worldline α(τ)
the proper time derivative α′(τ) is called the world velocity of α and denoted
U = U(τ). The world momentum (or 4-momentum) of (α, m) is denoted P
and deﬁned by
P = P(τ) = mU (τ).
Notice that, since U · U = −1 (Exercise 1.4.11), we have
P · P = −m2.
(1.8.1)
Now ﬁx an arbitrary admissible basis {ea}. Writing P = P aea and using
notation analogous to that established in (1.4.9) and (1.4.10) we have
P = (P 1, P 2, P 3, P 4) = mγ(
⇀u, 1) = (
⇀p, mγ),
where
⇀p = (P 1, P 2, P 3) is called the relative 3-momentum of (α, m) in {ea}.
Notice that if γ = ( 1 −β2)−1
2 is near 1, i.e., if the speed of (α, m) relative to
{ea} is small, then
⇀p is approximately equal to m
⇀u, the classical Newtonian

82
1 Geometrical Structure of M
momentum of (α, m) in {ea}. The quantity mγ =
m
√
1−β2 is sometimes re-
ferred to as the “relativistic mass” of (α, m) relative to {ea} since it permits
one to retain a formal similarity between the Newtonian and relativistic def-
initions of momentum (“mass times velocity”). Inertial mass was regarded
in classical physics as a measure of the particle’s resistance to acceleration.
From the relativistic point of view this resistance must become unbounded
as β →1 and mγ certainly has this property. We prefer, however, to avoid
the quite misleading attitude that “mass increases with velocity” and simply
abandon the Newtonian view that momentum is a linear function of velocity.
We shall denote by |
⇀p| the usual Euclidean magnitude of the relative
3-momentum in {ea}, i.e., |
⇀p|2 = (P 1)2 + (P 2)2 + (P 3)2. To see more clearly
the relationship between P and more familiar Newtonian concepts we use the
binomial expansion
γ = (1 −β2)−1
2 = 1 + 1
2β2 + 3
8β4 + · · ·
(1.8.2)
of γ (valid since | β | < 1) to write
P i = mγui = mui + 1
2muiβ2 + · · · , i = 1, 2, 3, and
(1.8.3)
P 4 = mγ = m + 1
2mβ2 + · · · .
(1.8.4)
The nonlinear terms in (1.8.3) are absent from the Newtonian deﬁnition, but
are crucial to the relativistic theory since they force |
⇀p| to become unbounded
as β →1, i.e., they impose the “speed limit” on material particles relative to
admissible frames of reference.
The physical interpretation of (1.8.4) is much more interesting. Notice,
in particular, the appearance of the term 1
2mβ2 corresponding to the clas-
sical kinetic energy. The presence of this term leads us to call P 4 the total
relativistic energy of (α, m) in {ea} and denote it E.
E = −P · e4 = P 4 = mγ = m + 1
2mβ2 + · · · .
(1.8.5)
Exercise 1.8.1 Show that, relative to any admissible basis {ea},
m2 = E2 −|
⇀p|2.
(1.8.6)
A few words of caution are in order here. The concept of “energy” in clas-
sical physics is quite a subtle one. Many diﬀerent types of energy are de-
ﬁned in diﬀerent situations, but each is in one way or another intuitively
related to a system’s “ability to do work”. Now, simply calling P 4 the total
relativistic energy of our particle does not ensure that this intuitive inter-
pretation is still valid. Whether or not the name is appropriate can only be
determined experimentally. In particular, one should determine whether or

1.8 Particles and Interactions
83
not the presence of the term m in (1.8.5) is consistent with this interpreta-
tion. Observe that when β = 0 (i.e., in the instantaneous rest frame of the
particle) P 4 = E = m (= mc2 in traditional units) so that even when the
particle is at rest relative to an admissible frame it still has “energy” in this
frame, the amount being numerically equal to m. If this is really “energy”
in the classical sense, it should be capable of doing work, i.e., it should be
possible to “liberate” (and use) it. That this is indeed possible is demon-
strated daily in particle physics laboratories and, fortunately not so often, in
the explosion of atomic and nuclear bombs.
It is remarkable that the classically distinct concepts of momentum, energy
and mass ﬁnd themselves so naturally integrated into the single relativistic
notion of world momentum (energy-momentum). We ask the reader to show
that the process was indeed natural in the sense that if one believes that
relativistic momentum should be represented by a vector in M and that the
ﬁrst three components of P = mU are “right”, then one has no choice about
the fourth component.
Exercise 1.8.2 Show that two vectors v and w in M with the same spatial
components relative to every admissible basis (i.e., v1 = w1, v2 = w2 and
v3 = w3 for every {ea}) must, in fact, be equal. Hint: It will be enough to
show that a vector whose ﬁrst three components are zero in every admissible
coordinate system must be the zero vector.
Special relativity is of little interest to those who study colliding billiard
balls (the relative speeds are so small that any “relativistic eﬀects” are negli-
gible). On the other hand, when the colliding objects are elementary particles
(protons, neutrons, electrons, mesons, etc.) these relativistic eﬀects are the
dominant features. Such interactions between elementary particles, however,
very often involve not only material particles, but photons as well and we wish
to include these in our study. Now, a photon is, in many ways, analogous to
a free material particle. Relative to any admissible frame of reference it trav-
els along a straight line with constant speed, i.e., it has a linear worldline.
Since this worldline is null, however, it has no proper time parametrization
and so no world velocity. Nevertheless, photons do possess “momentum” and
“energy” and so should have a “world momentum” (witness, for example, the
photoelectric eﬀect in which photons collide with and eject electrons from
their orbits in an atom). Unlike a material particle, however, the photon’s
characteristic feature is not mass, but energy (frequency, wavelength) and
this is highly observer-dependent (e.g., wavelengths of photons emitted from
the atoms of a star are “red-shifted” (lengthened) relative to those measured
on earth for the same atoms because the stars are receding from us due to the
expansion of the universe). A hint as to how these features can be modelled
in M is provided by:

84
1 Geometrical Structure of M
Exercise 1.8.3 Let N be a future-directed null vector in M and {ea} an
admissible basis with N = N aea. Show that
N = ϵ(
⇀e + e4),
(1.8.7)
where ϵ = −N · e4 = N 4 and
⇀e is the direction 3-vector of N relative to
{ea}, i.e.,
⇀e = ((N 1)2 + (N 2)2 + (N 3)2)−1
2 (N 1e1 + N 2e2 + N 3e3).
Now, we deﬁne a photon2 in M to be a pair (α, N), where N is a future-
directed null vector called the photon’s world momentum (or 4-momentum)
and α : I →M (I an interval in R containing 0) is given by α(t) = x0 + tN
for some ﬁxed event x0 in M and all t in I. Relative to any admissible basis
{ea} the positive real number
ϵ = −N · e4 = N 4
is called the energy of (α, N) in {ea} (see Figure 1.8.1). The frequency ν and
wavelength λ of (α, N) in {ea} are deﬁned by ν = ϵ/h and λ = 1/ν, where h
is a constant (called Planck’s constant).
Fig. 1.8.1
2No quantum mechanical subtleties are to be inferred from our use of the term “photon”.
Our deﬁnition is intended to model any “massless” particle travelling at the speed of light.

1.8 Particles and Interactions
85
It is interesting to compare the energies of a photon (α, N) in two diﬀerent
frames of reference. Thus, we let {ea} and {ˆea} be two admissible bases
and write N = ϵ(
⇀e + e4) = ˆϵ(
⇀
ˆe + ˆe4), where ϵ = −N · e4 and ˆϵ = −N · ˆe4.
Exercise 1.8.4 Show that ˆϵ = γϵ (1 −β(
⇀e ·
⇀
d)). Hint: Use Exercise 1.3.10.
But
⇀e and
⇀
d both lie in the subspace spanned by e1, e2 and e3 and the
restriction of the Lorentz inner product to this subspace is just the usual
positive deﬁnite inner product on R3. Thus,
⇀e ·
⇀
d = cos θ, where θ is the
angle in  (the spatial coordinate system of the frame corresponding to {ea})
between the direction of the photon and the direction of ˆ. We therefore
obtain
ˆϵ
ϵ = ˆν
ν = γ(1 −β cos θ) = 1 −β cos θ

1 −β2
(1.8.8)
which is the relativistic formula for the Doppler eﬀect. Using the binomial
expansion (1.8.2) for γ gives
ˆϵ
ϵ = ˆν
ν = (1 −β cos θ) + 1
2β2(1 −β cos θ) + · · · .
(1.8.9)
The ﬁrst term 1−β cos θ is the familiar classical formula for the Doppler eﬀect,
whereas the remaining terms constitute the relativistic correction contributed
by time dilation. Three special cases of (1.8.8) are of particular interest.
θ = 0(so
⇀
d =
⇀e ) =⇒ˆν
ν =

1 −β
1 + β ,
(1.8.10)
θ = π(so
⇀
d = −
⇀e ) =⇒ˆν
ν =

1 + β
1 −β ,
(1.8.11)
θ = π
2 (so
⇀e ·
⇀
d = 0) =⇒ˆν
ν =
1

1 −β2 .
(1.8.12)
The classical theory predicts no Doppler shift in the case θ = π/2 so that
the formula (1.8.12) for the so-called transverse Doppler eﬀect represents a
purely relativistic phenomenon. Experimental veriﬁcation of (1.8.12) was ﬁrst
accomplished by Ives and Stilwell [IS] and is regarded as direct conﬁrmation
of the reality of time dilation.
Next we wish to compare the angles θ and ˆθ deﬁned by cos θ =
⇀e ·
⇀
d
and cos ˆθ =
⇀
ˆe ·
⇀
ˆd.
Exercise 1.8.5 Let
⇀
ˆu denote the velocity 3-vector of S relative to
ˆS
((1.3.12) and (1.3.15)) and show that
⇀
ˆu = −γβ(
⇀
d + βe4).
(1.8.13)

86
1 Geometrical Structure of M
From (1.8.13) we conclude that
⇀
ˆd = −γ(
⇀
d + βe4).
(1.8.14)
Since N = ϵ(
⇀e + e4) = ˆϵ(
⇀
ˆe + ˆe4) we obtain from the deﬁnitions of θ and ˆθ
⇀
d · N = ϵ cosθ
and
⇀
ˆd · N = ˆϵ cos ˆθ.
(1.8.15)
Now, ˆϵ cos ˆθ =
⇀
ˆd · N = −γ(
⇀
d · N + βe4 · N) = −γ(ϵ cosθ −βϵ) = −γϵ cosθ +
γβϵ. Thus,
ˆϵ
ϵ cos ˆθ = γ(β −cos θ)
Fig. 1.8.2
which, by (1.8.8), we may write as
γ(1 −β cos θ) cos ˆθ = γ(β −cos θ),
or
cos ˆθ = β −cos θ
1 −β cos θ.
(1.8.16)
Generally, however, one would be more interested in comparing the angles θ
and θ′ = π −ˆθ, e.g., when the spatial axes are in standard orientation as in
Figure 1.8.2. Since cos θ′ = −cos ˆθ, (1.8.16) becomes the standard relativistic
aberration formula
cos θ′ = cos θ −β
1 −β cos θ .
(1.8.17)
At this point we have assembled enough machinery to study some of the
physical interactions to which the special theory of relativity is routinely

1.8 Particles and Interactions
87
applied. Henceforth, we shall use the term free particle to refer to either a
free material particle or a photon. If A is a ﬁnite set of free particles, then
each element of A has a unique world momentum vector. The sum of these
vectors is called the total world momentum (or total 4-momentum) of A.
A contact interaction in M is a triple (A, x, ˜
A), where A and ˜
A are two
ﬁnite sets of free particles, neither of which contains a pair of particles with
linearly dependent world momenta, and x is an event such that
(a) x is the terminal point of all the particles in A (i.e., for each (α, m) in A
with α : [a, b] →M, we have α(b) = x),
(b) x is the initial point of all the particles in ˜
A, and
(c) the total world momentum of A equals the total world momentum of ˜
A.
Intuitively, the event x should be regarded as the collision of all the particles
in A, from which emerge all the particles in ˜
A (which may be physically
quite diﬀerent than those in A, e.g., it has been observed that the collision of
two electrons can result in three electrons and a positron). The prohibition
on pairs of particles with linearly dependent world momenta in the same set
is based on the presumption that two such particles would be physically in-
distinguishable. Property (c) is called the conservation of world momentum
and contains the appropriate relativistic generalizations of two classical con-
servation principles: the conservation of momentum and the conservation of
energy.
Several conclusions concerning contact interactions can be drawn directly
from the results we have available. Consider, for example, an interaction
(A, x, ˜
A) in which ˜
A consists of a single photon. Then the total world mo-
mentum of ˜
A is null so the same must be true of A. Since the world momenta
of the individual particles in A are all either timelike or null and all are future-
directed, Lemma 1.4.3 implies that all of these world momenta must be null
and parallel. Since A cannot contain two distinct photons with parallel world
momenta, A must also consist of a single photon which, by (c), must have the
same world momentum as the photon in ˜
A. In essence, “nothing happened
at x”. We conclude that no nontrivial interaction of the type modelled by our
deﬁnition can result in a single photon and nothing else.
A contact interaction (A, x, ˜
A) is called a disintegration or decay if A
consists of a single free particle.
Exercise 1.8.6 Analyze a disintegration (A, x, ˜
A) in which A consists of a
single photon.
Suppose that A consists of a single free material particle of proper mass
m0 and ˜
A consists of two material particles with proper masses m1 and m2
(such disintegrations do, in fact, occur in nature, e.g., in α-emission). Let
P0, P1 and P2 be the world momenta of the particles with masses m0, m1
and m2 respectively. Appealing to (1.8.1), the Reversed Triangle Inequality

88
1 Geometrical Structure of M
(Theorem 1.4.2) and the fact that P1 and P2 are linearly independent we
ﬁnd that
m0 > m1 + m2.
(1.8.18)
The excess mass m0 −(m1 + m2) of the initial particle is regarded as a
measure of the amount of energy required to split m0 into two pieces. Stated
somewhat diﬀerently, when the two particles in ˜
A were held together to form
the single particle in A the “binding energy” contributed to the mass of this
latter particle, while, after the decay, the diﬀerence in mass appears in the
form of kinetic energy of the generated particles.
Exercise 1.8.7 Show that a free electron cannot emit or absorb a photon.
Hint: The contradiction arises from the constancy of the proper mass me
of an electron. A more complicated system such as an atom or molecule
whose proper mass can vary with its energy state (these being determined
by the principles of quantum mechanics) is not prohibited from absorbing or
emitting photons.
Next we consider two examples of more detailed calculations for speciﬁc
interactions, each of which models an important reaction in particle physics.
We should emphasize at the outset, however, that the conservation of world
momentum alone is almost never suﬃcient to determine all of the details of
the resulting motion. Additional conservation laws (e.g., of “spin”) can reduce
the degree of indeterminacy, but quantum mechanics imposes a positive lower
bound on the extent to which this is possible. As ﬁnal preparation for our
examples we will need to record the conservation of world momentum in
component form relative to an arbitrary admissible basis {ea}. Thus we write

A
mγui +

A
hνei =

˜
A
˜m˜γ˜ui +

˜
A
h˜ν˜ei,
i = 1, 2, 3,
(1.8.19)

A
mγ +

A
hν =

˜
A
˜m˜γ +

˜
A
h˜ν,
(1.8.20)
where the ﬁrst and third sums in each are over all the material particles in
A and ˜
A respectively, whereas the second and fourth sums are over all of the
photons in A and ˜
A respectively.
In our ﬁrst example we describe the so-called Compton eﬀect. The physical
situation we propose to model is the following: A photon collides with an
electron and rebounds from it (generally with a diﬀerent frequency), while
the electron recoils from the collision. Thus, we consider a contact interaction
(A, x, ˜
A), where A consists of a photon with world momentum N and a
material particle with proper mass me and world velocity U and ˜
A consists
of a photon with world momentum ˜N and a material particle with proper
mass me and world velocity ˜U. We analyze the interaction in a frame of
reference in which the material particle in A is at rest (time axis parallel
to the worldline of the particle). In this frame the conservation of world
momentum equations (1.8.19) and (1.8.20) become (since ui = 0, γ = 1)

1.8 Particles and Interactions
89
Fig. 1.8.3
me˜γ˜ui + h˜ν˜ei = hνei,
i = 1, 2, 3,
(1.8.21)
me˜γ + h˜ν = me + hν.
(1.8.22)
Let ξ = ˜ν/ν and k = hν/me. We denote by θ the angle between the direction
vectors of the two photons in the given frame of reference, i.e., cos θ = e1˜e1 +
e2˜e2 + e3˜e3 (see Figure 1.8.3). With this notation (1.8.21) and (1.8.22) can
be written
˜γ˜ui = kei −ξk˜ei,
i = 1, 2, 3,
(1.8.23)
˜γ −1 = k(1 −ξ).
(1.8.24)
Since ˜β2 = (˜u1)2 + (˜u2)2 + (˜u3)2 = 1 −˜γ−2, when we (Euclidean) dot each
side of (1.8.23) with itself we obtain
˜γ2 ˜β2 = k2(1 −2ξ cos θ + ξ2) = ˜γ2 −1.
Thus,
˜γ + 1 = k2(1 −2ξ cos θ + ξ2)
˜γ −1
= k(1 −2ξ cos θ + ξ2)
1 −ξ
(1.8.25)
by (1.8.24). Subtracting (1.8.24) from (1.8.25) we next obtain
2 = k(1 −2ξ cos θ + ξ2) −k(1 −ξ)2
1 −ξ
= k(2ξ −2ξ cos θ)
1 −ξ
= 2kξ(1 −cos θ)
1 −ξ
= 4kξ sin2  θ
2

1 −ξ
.

90
1 Geometrical Structure of M
Thus, 2kξ sin2  θ
2

= 1−ξ and therefore ξ =
1
1+2k sin2(θ/2) so ˜ν =
ν
1+2k sin2(θ/2).
From this we compute
˜λ −λ = 1
˜ν −1
ν = 1 + 2k sin2  θ
2

ν
−1
ν = 2k sin2  θ
2

ν
.
We conclude that
˜λ −λ = 2h
me
sin2  θ
2

(1.8.26)
which gives the change in wavelength of the photon as a function of the angle
θ through which it is deﬂected (in the frame in which the electron is initially
at rest). Observe that this change in wavelength does not depend on the
wavelength λ of the incident photon, but only on the angle through which
it is deﬂected. Moreover, this diﬀerence ranges from a minimum of 0 when
θ = 0 (the photon and electron do not interact physically) to a maximum of
Δλmax = 2h
me
(1.8.27)
when θ = π (the photon is thrown straight back). This maximum change in
wavelength is a characteristic feature of the electron; the quantity h/me is
called the Compton wavelength of the electron.
Next we consider an inelastic collision between two material particles.
The situation we have in mind is as follows: two free material particles with
masses m1 and m2 collide and coalesce to form a third material particle of
mass m3. Classically it is assumed that m3 = m1+m2 and on the basis of this
assumption (and the conservation of Newtonian momentum) one ﬁnds that
kinetic energy is lost during the collision. In Newtonian mechanics this lost
kinetic energy disappears entirely from the mechanical picture in the sense
that it is viewed as having taken the form of heat in the combined particle and
therefore cannot be discussed further by the methods of mechanics. We shall
see that this rather unsatisfactory feature of Newtonian mechanics is avoided
in relativistic mechanics by observing that conservation of world momentum
(which includes the conservation of energy) requires that the “hot” combined
particle have a proper mass which is greater than the sum of the two masses
from which it is formed, the diﬀerence m3 −(m1 + m2) being a measure of
the energy required to bind the two particles together; this energy “acts like
mass” in the combined particle.
We shall therefore consider a contact interaction (A, x, ˜
A), where A con-
sists of two free material particles with proper masses m1 and m2 and world
velocities U1 and U2 respectively and ˜
A consists of one free material particle
with proper mass m3 and world velocity U3. Conservation of world momen-
tum requires that
m3U3 = m1U1 + m2U2.
(1.8.28)

1.8 Particles and Interactions
91
Again observe that the Reversed Triangle Inequality (Theorem 1.4.2) gives
m3 > m1 + m2. Moreover, since U1 · U1 = U2 · U2 = U3 · U3 = −1 we obtain
(by dotting both sides of (1.8.28) with itself and using any admissible frame
of reference)
m2
3 = m2
1 + m2
2 −2m1m2U1 · U2,
m2
3 = m2
1 + m2
2 −2m1m2γ1γ2(
⇀u 1, 1) · (
⇀u 2, 1),
(1.8.29)
m2
3 = m2
1 + m2
2 + 2m1m2γ1γ2(1 −
⇀u 1 ·
⇀u 2),
which yields the resultant mass m3 in terms of m1, m2 and the quantities ui
1
and ui
2, i = 1, 2, 3, which can be measured in the given frame of reference.
From (1.8.28) one can then compute U3.
We wish to obtain an approximate formula for m3 which can be compared
with the Newtonian expression for the loss in kinetic energy. Assume that β1
and β2 are small so that γ1 and γ2 are approximately 1 (the frame of reference
is then no longer arbitrary, of course). We will eventually take γ1γ2 ≈1, but
ﬁrst we consider the somewhat better approximations
γj ≈1 + 1
2β2
j ,
j = 1, 2,
obtained from the binomial expansion (1.8.2). Then
γ1γ2 ≈

1 + 1
2β2
1
 
1 + 1
2β2
2

= 1 + 1
2β2
1 + 1
2β2
2 + 1
4β2
1β2
2,
γ1γ2 ≈1 + 1
2β2
1 + 1
2β2
2.
(1.8.30)
Exercise 1.8.8 Show that (1.8.29) and (1.8.30) yield
m2
3 ≈(m1 + m2)2 + m1m2

β2
1 + β2
2 −2γ1γ2(
⇀u 1 ·
⇀u 2)

.
(1.8.31)
Now taking γ1γ2 ≈1 in (1.8.31) we obtain
m2
3 ≈(m1 + m2)2 + m1m2|
⇀v |2,
(1.8.32)
where |
⇀v |2 is the squared magnitude of the relative velocity
⇀v =
⇀u 1 −
⇀u 2
of the two particles in A as measured in the given frame. From (1.8.32) we
obtain
m3 ≈m1 + m2 +
m1m2
m1 + m2 + m3
|
⇀v |2.
Assuming that m3 ≈m1 + m2 in the denominator we arrive at
m3 ≈m1 + m2 + 1
2
m1m2
m1 + m2
|
⇀v |2,
(1.8.33)
where the last term represents the approximate gain in proper mass as a
result of the collision.

92
1 Geometrical Structure of M
Now, in Newtonian mechanics it is assumed that m3 = m1 + m2 so that
conservation of Newtonian momentum requires that
(m1 + m2)
⇀u 3 = m1
⇀u 1 + m2
⇀u 2.
(1.8.34)
Taking the Euclidean dot product of each side of (1.8.34) with itself then
yields
(m1 + m2)2|
⇀u 3|2 = m2
1|
⇀u 1|2 + m2
2|
⇀u 2|2 + 2m1m2(
⇀u 1 ·
⇀u 2).
(1.8.35)
Exercise 1.8.9 Use (1.8.35) to show that the classical loss in kinetic energy
due to the collision is given by
1
2m1|
⇀u 1|2 + 1
2m2|
⇀u 2|2 −1
2(m1 + m2)|
⇀u 3|2 = 1
2
m1m2
m1 + m2
|
⇀v |2,
where |
⇀v |2 = |
⇀u 1 −
⇀u 2|2.
Consequently, the Newtonian expression for the lost kinetic energy coincides
with the relativistic formula (1.8.33) for the approximate gain in proper mass
of the combined particle.

Chapter 2
Skew-Symmetric Linear
Transformations and
Electromagnetic Fields
2.1 Motivation via the Lorentz Law
A charged particle in M is a triple (α, m, e), where (α, m) is a material
particle and e is a nonzero real number called the charge of the particle.
A free charged particle is a charged particle (α, m, e), where (α, m) is a free
material particle. Charged particles do two things of interest to us. By their
very presence they create electromagnetic ﬁelds and they also respond to the
ﬁelds created by other charges. Our objective in this chapter is to isolate the
appropriate mathematical object with which to model an electromagnetic
ﬁeld in M, derive many of its basic properties and then investigate these two
activities.
Charged particles “respond” to the presence of an electromagnetic ﬁeld
by experiencing changes in world momentum. The quantitative nature of
this response is expressed by a diﬀerential equation relating the proper time
derivative of the particle’s world momentum to the ﬁeld. This equation of
motion is generally taken to be the so-called Lorentz World Force Law (or
Lorentz 4-Force Law) which expresses the rate at which the particle’s world
momentum changes at each point on the worldline as a linear function of the
particle’s world velocity:
dP
dτ = eFU ,
(2.1.1)
where U = U(τ) is the particle’s world velocity, P = mU its world momentum
and, at each point, F : M →M is a linear transformation deﬁned in terms of
the classical “electric and magnetic 3-vectors
⇀
E and
⇀
B” at that point ((2.1.1)
is an abbreviated version of the somewhat more accurate and considerably
more cumbersome
dP(τ)
dτ
= eF α(τ)(U(τ)), where Fα(τ) is the appropriate
linear transformation at α(τ) ∈M). We should point out that (2.1.1) can
be regarded as an appropriate equation of motion for charged particles in an
, 
: An Introduction 
, Applied Mathematical Sciences 92,
G.L. Naber The Geometry of Minkowski Spacetime
to the Mathematics 
of the Special Theory of Relativity
DOI 10.1007/978-1-4419-7838-7_2, © Springer Science+Business Media, LLC 2012
93

94
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
electromagnetic ﬁeld only if the charges whose motion is to be governed by it
have negligible contribution to the ambient ﬁeld. It must be possible to regard
the ﬁeld as “given” and the charged particles as “test charges”. The much
more diﬃcult question of the interactions between the given ﬁeld and the
ﬁelds created by the moving charges will not be considered here (see [Par]).
We argue now that the form of the Lorentz Law (2.1.1) suggests that the
linear transformations F must be of a particular type (“skew-symmetric”).
Indeed, rewriting (2.1.1) at each ﬁxed point of M as
FU = m
e
dU
dτ
and dotting both sides with U gives
FU · U = m
e
dU
dτ · U = m
e A · U = 0
since a material particle’s world velocity and world acceleration are always
orthogonal (Exercise 1.4.12). Since any unit timelike vector u ∈M is the
world velocity of some charged particle (construct one!) we ﬁnd that, for any
such u, Fu·u = 0. Linearity therefore implies that Fv · v = 0 for all timelike v.
Now, if u and v are timelike and future-directed, then u + v is also timelike
and so 0 = F(u + v) · (u + v) = (Fu + Fv) · (u + v) = Fu · v + Fv · u = Fu · v +
u · Fv. Thus, Fu · v = −u · Fv. But M has a basis of future-directed timelike
vectors so it follows that F must satisfy
Fx · y = −x · Fy
(2.1.2)
for all x and y in M. A linear transformation F : M →M which satisﬁes
(2.1.2) for all x and y in M is said to be skew-symmetric (with respect to
the Lorentz inner product on M).
At each ﬁxed point in M we therefore elect to model an electromagnetic
ﬁeld by a skew-symmetric linear transformation F whose job it is to assign
to the world velocity U of a charged particle passing through that point
the change in world momentum dP
dτ = eFU that the particle should expect
to experience due to the ﬁeld. One would picture the electromagnetic ﬁeld
in toto therefore as a smooth assignment of such a linear transformation
to each point in (some region of) M (although we shall ﬁnd that nature
imposes a condition—Maxwell’s Equations—on the manner in which such an
assignment can be made). In the next four sections we carry out a general
investigation of skew-symmetric linear transformations on M and then turn
to some physical applications in the last two sections.

2.2 Elementary Properties
95
2.2 Elementary Properties
Throughout this section F will represent a nonzero, skew-symmetric linear
transformation on M. The most obvious consequence of the deﬁnition (2.1.2)
of skew-symmetry is that
Fx · x = x · Fx = 0
(2.2.1)
for all x in M. If {ea}4
a=1 is an arbitrary admissible basis for M and we write
Feb = F abea = F 1be1 + F 2be2 + F 3be3 + F 4be4, then (2.2.1) implies F aa = 0
for a = 1, 2, 3, 4, i.e., the diagonal entries in the matrix of F are all zero. In
addition, for i, j = 1, 2, 3, F ji = −F ij, whereas F 4i = F i4. Thus, the matrix
of F relative to any admissible basis has the form
[F a
b ] =
⎡
⎢⎢⎣
0
F 12
F 13
F 14
−F 12
0
F 23
F 24
−F 13
−F 23
0
F 34
F 14
F 24
F 34
0
⎤
⎥⎥⎦.
(2.2.2)
Observe that, due to the fact that the inner product on M is indeﬁnite,
the matrix of a skew-symmetric linear transformation on M is not a skew-
symmetric matrix (in the “time” part).
In order to establish contact with the notation usually used in physics we
introduce, in each admissible basis {ea}, two 3-vectors
⇀
E = E1e1 + E2e2 +
E3e3 and
⇀
B = B1e1 + B2e2 + B3e3, where E1 = F 14, E2 = F 24, E3 =
F 34, B1 = F 23, B2 = −F 13 and B3 = F 12. Thus, (2.2.2) can be written
[F ab] =
⎡
⎢⎢⎣
0
B3
−B2
E1
−B3
0
B1
E2
B2
−B1
0
E3
E1
E2
E3
0
⎤
⎥⎥⎦.
(2.2.3)
If F is thought of as describing an electromagnetic ﬁeld at some point of
M, then
⇀
E and
⇀
B are regarded as the classical electric and magnetic ﬁeld
3-vectors at that point as measured in {ea}.
We consider two simple examples which, in Section 2.4, we will show to be
fully and uniquely representative in the sense that for any skew-symmetric
F : M →M there exists a basis relative to which the matrix of F has one
of these forms, but no basis in which it has the other. First ﬁx an admissible
basis {ea} and a positive real number α and deﬁne a linear transformation
FN on M whose matrix relative to this basis is
⎡
⎢⎢⎣
0
0
0
0
0
0
α
0
0
−α
0
α
0
0
α
0
⎤
⎥⎥⎦.

96
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
Then FN is clearly skew-symmetric,
⇀
E = αe3 and
⇀
B = αe1, so an observer in
this frame measures electric and magnetic 3-vectors that are perpendicular
and have the same magnitude.
Next, ﬁx an admissible basis {ea} and two non-negative real numbers δ
and ϵ and let FR : M →M be the linear transformation whose matrix
relative to {ea} is
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦.
Again, FR is skew-symmetric. Moreover,
⇀
E = ϵe3 and
⇀
B = δe3 so an ob-
server in this frame will measure electric and magnetic 3-vectors in the same
direction and of magnitude ϵ and δ respectively.
Relative to another admissible basis {ˆea} all of the ˆF ab, ˆEi and ˆBi are
deﬁned in the same way. Thus, if Λ is the Lorentz transformation associated
with the orthogonal transformation L that carries {ea} onto {ˆea}, i.e., the
matrix of L−1 relative to {ˆea}, then the matrix of F relative to {ˆea} is
Λ [F ab] Λ−1, i.e., ˆF ab = ΛaαΛb
βF αβ.
Exercise 2.2.1 With [F ab] as in (2.2.3) and Λ = Λ(β) for some β in (−1, 1),
show that
ˆE1 = E1,
ˆE2 = γ(E2 −βB3),
ˆE3 = γ(E3 + βB2),
ˆB1 = B1,
ˆB2 = γ(βE3 + B2),
ˆB3 = −γ(βE2 −B3).
(2.2.4)
Exercise 2.2.2 Show that, for FN, any other admissible observer mea-
sures electric and magnetic 3-vectors that are perpendicular and have the
same magnitude. Hint: This is clear if the Lorentz transformation Λ relating
the two frames is a rotation. Verify the statement for Λ(β) and appeal to
Theorem 1.3.5.
Exercise 2.2.3 Show that, for FR, another admissible observer will, in gen-
eral, not measure
⇀
E and
⇀
B in the same direction.
Of particular interest is the special case of (2.2.4) when either
⇀
B or
⇀
E is
zero (so that O observes either a purely electric or a purely magnetic ﬁeld):
If
⇀
B =
⇀
O, then
ˆE1 = E1,
ˆE2 = γE2,
ˆE3 = γE3,
ˆB1 = 0,
ˆB2 = βγE3,
ˆB3 = −βγE2.
(2.2.5)
If
⇀
E =
⇀
O we have
ˆE1 = 0,
ˆE2 = −βγB3,
ˆE3 = βγB2,
ˆB1 = B1,
ˆB2 = γB2,
ˆB3 = γB3.
(2.2.6)

2.2 Elementary Properties
97
The essential feature of (2.2.5) and (2.2.6) is that “purely electric” and
“purely magnetic” are not relativistically meaningful notions since they are,
in general, not invariant under Lorentz transformations. How much of an
electromagnetic ﬁeld is “electric” and how much “magnetic” depends on the
frame of reference from which it is being observed. This is the familiar phe-
nomemon of electromagnetic induction. For example, a charge deemed “at
rest” in one frame will give rise to a purely electric ﬁeld in that frame, but,
viewed from another frame, will be “moving” and so will induce a nonzero
magnetic ﬁeld as well.
Since
⇀
E and
⇀
B are spacelike one can, beginning with any admissible ba-
sis {e1, e2, e3, e4}, choose a right-handed orthonormal basis {ˆe1, ˆe2, ˆe3} for
Span{e1, e2, e3} such that
⇀
E and
⇀
B both lie in Span{ˆe1, ˆe2} (so that ˆE3 =
ˆB3 = 0). Choosing a rotation

Rij

i,j=1,2,3 in this 3-dimensional Euclidean
space that accomplishes the change of coordinates ˆxi = Rijxj, i = 1, 2, 3,
the corresponding rotation [Rab]a,b=1,2,3,4 in L yields a new admissible coor-
dinate system in which the third components of
⇀
E and
⇀
B are zero. The gist
of all this is that one can, with little extra eﬀort, work in a basis relative to
which the matrix of F has the form
⎡
⎢⎢⎣
0
0
−B2
E1
0
0
B1
E2
B2
−B1
0
0
E1
E2
0
0
⎤
⎥⎥⎦.
(2.2.7)
Next we collect a few facts that will be of use in the remainder of the chap-
ter. We deﬁne the range and kernel (null space) of a linear transformation
T : M →M by
rng T = {y ∈M : y = Tx for some x ∈M}
and
ker T = {x ∈M : Tx = 0}.
Both rng T and ker T are obviously subspaces of M and, consequently, so
are their orthogonal complements (rng T )⊥and (ker T )⊥(Exercise 1.1.2).
Proposition 2.2.1 If F : M →M is any nonzero, skew-symmetric linear
transformation on M, then
(a) ker F = (rng F)⊥,
(b) rng F = (ker F)⊥,
(c) dim(ker F) is either 0 or 2 so dim(rng F) is either 4 or 2, respectively.
Proof:
(a) First let x ∈(rng F)⊥. Then x · Fy = 0 for all y in M. Thus,
Fx · y = 0 for all y in M. But the inner product on M is nondegenerate
so we must have Fx = 0, i.e., x ∈ker F. Next suppose x ∈ker F. Then
Fx = 0 implies Fx · y = 0 for all y in M so x · Fy = 0 for all y in M, i.e.,
x ∈(rng F)⊥.

98
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
Exercise 2.2.4 Show that, for any subspace U of M, (U⊥)⊥= U and
conclude from (a) that (b) is true. Hint: Use the fact that U and U⊥have
complementary dimensions, i.e., dim U + dim U⊥= dim M (see Theorem 16,
Chapter 4 of [La]).
(c) Without loss of generality select a basis {ea} relative to which the matrix
of F has the form (2.2.7). Then, for any v ∈M, Fv has components given by
⎡
⎢⎢⎣
0
0
−B2
E1
0
0
B1
E2
B2
−B1
0
0
E1
E2
0
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
−B2v3 + E1v4
B1v3 + E2v4
B2v1 −B1v2
E1v1 + E2v2
⎤
⎥⎥⎦
which is zero if and only if
.−B2v3 + E1v4 = 0,
B1v3 + E2v4 = 0
and
.B2v1 −B1v2 = 0,
E1v1 + E2v2 = 0.
Notice that the determinant of the coeﬃcient matrix in the ﬁrst system is
−
⇀
E ·
⇀
B and, in the second,
⇀
E ·
⇀
B. If
⇀
E ·
⇀
B ̸= 0 both systems have only the
trivial solution so the kernel of F consists of 0 alone and dim(ker F) = 0. Since
4 = dim M = dim(ker F) + dim(rng F), dim(rng F) = 4. If
⇀
E ·
⇀
B = 0, each
system has nontrivial solutions, say, (v3, v4) =

v3
0, v4
0

and (v1,v2) =

v1
0, v2
0

.
Since F ̸= 0, all of the nontrivial solutions to the ﬁrst system are of the form
b

v3
0, v4
0

, b ∈R, and, for the second, a(v1
0, v2
0), a ∈R. Thus, the kernel of
F is the set of
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦= a
⎡
⎢⎢⎣
v1
0
v2
0
0
0
⎤
⎥⎥⎦+ b
⎡
⎢⎢⎣
0
0
v3
0
v4
0
⎤
⎥⎥⎦,
so dim(ker F) = 2 and therefore dim(rng F) = 2.
■
Recall that a real number λ is an eigenvalue of F if there exists a nonzero
x ∈M such that Fx = λx and that any such x is an eigenvector of F
corresponding to λ. The eigenspace of F corresponding to λ is {x ∈M :
Fx = λx}, i.e., the set of eigenvectors for λ together with 0 ∈M, and it is
indeed a subspace of M. A subspace U of M is said to be invariant under F
if F maps U into U, i.e., if FU ⊆U. Any eigenspace of F is invariant under
F since Fx = λx implies F(Fx) = F(λx) = λFx.
Proposition 2.2.2 If F : M →M is any nonzero, skew-symmetric linear
transformation on M, then
(a) Fx = λx implies that either λ = 0 or x is null (or both),
(b) FU ⊆U implies F(U⊥) ⊆U⊥.

2.3 Invariant Subspaces
99
Proof:
(a) Fx = λx implies Fx · x = λ(x · x) so λ(x · x) = 0 and either
λ = 0 or x · x = 0.
(b) Suppose FU ⊆U and let v ∈U⊥. Then, for every u ∈U, Fv · u = −v ·
Fu = 0 because Fu ∈U and v ∈U⊥. Thus, Fv ∈U⊥as required.
■
The eigenvalues of a linear transformation are found by solving its char-
acteristic equation. For a skew-symmetric linear transformation on M and
with the notation established in (2.2.3) this equation is easy to write down
and quite informative.
Theorem 2.2.3 Let F : M →M be a skew-symmetric linear transforma-
tion and {ea}4
a=1 an arbitrary admissible basis for M. With the matrix [F ab]
written in the form (2.2.3) and I the 4 × 4 identity matrix we have
det ([F ab] −λI) = λ4 +

|
⇀
B|2 −|
⇀
E|2
λ2 −(
⇀
E ·
⇀
B)2 ,
(2.2.8)
where |
⇀
E|2 = (E1)2 + (E2)2 + (E3)2, |
⇀
B|2 = (B1)2 + (B2)2 + (B3)2 and
⇀
E ·
⇀
B = E1B1 + E2B2 + E3B3.
Exercise 2.2.5 Prove Theorem 2.2.3.
■
Consequently, the eigenvalues of F are the real solutions to
λ4 +

|
⇀
B|2 −|
⇀
E|2
λ2 −(
⇀
E ·
⇀
B)2 = 0.
(2.2.9)
Since the roots of the characteristic polynomial are independent of the choice
of basis and since the leading coeﬃcient on the left-hand side of (2.2.9) is
one it follows that, while
⇀
E and
⇀
B will, in general, be diﬀerent in diﬀerent
admissible bases, the algebraic combinations |
⇀
B|2−|
⇀
E|2 and
⇀
E·
⇀
B are Lorentz
invariants, i.e., the same in all admissible frames. In particular, if both are
zero (i.e., if
⇀
E and
⇀
B are perpendicular and have the same magnitude) in
one frame, the same will be true in any other frame. We shall say that F is
null if |
⇀
B|2 −|
⇀
E|2 =
⇀
E ·
⇀
B = 0 in any (and therefore every) admissible basis;
otherwise, F is regular. As deﬁned earlier in this section, FN is null and FR
is regular.
Exercise 2.2.6 Show that F is invertible iﬀ
⇀
E ·
⇀
B ̸= 0.
2.3 Invariant Subspaces
Our objective in this section is to obtain an intrinsic characterization of
“null” and “regular” skew-symmetric linear transformations on M that will
be used in the next section to derive their “canonical forms”. Speciﬁcally,
we will show that every skew-symmetric F : M →M has a 2-dimensional

100
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
invariant subspace and that F is regular if and only if U ∩U⊥= {0} for
some such subspace U (so F is null if and only if U ∩U⊥̸= {0} for every
2-dimensional invariant subspace U).
We begin with a few observations on invariant subspaces in general. Let V
be a real vector space of dimension at least 2 and T : V →V a nonzero linear
transformation. Observe that if the characteristic equation det(T −λI) = 0
has a real root λ, then T has an eigenvector, i.e., there is a nonzero v ∈V
such that Tv = λv. Consequently, Span{v} is a non-trivial invariant subspace
for T . If there are no real roots the situation is less simple.
Lemma 2.3.1 Let V be a real vector space of dimension greater than or
equal to 2 and T : V →V a nonzero linear transformation. If det(T −λI) = 0
has a complex solution λ = α + βi, β ̸= 0, then there exist nonzero vectors x
and y in V such that
Tx = αx −βy
and
Ty = αy + βx.
(2.3.1)
In particular, Span{x, y} is a nontrivial invariant subspace for T .
Proof:
Select a basis for V and let [aij ]i,j=1,...,n be the matrix of T in this
basis. Since det(T −λI) = 0 when λ = α + βi, the system
⎧
⎪
⎨
⎪
⎩
a11z1 + · · · + a1nzn = (α + βi)z1
...
...
...
an1z1 + · · · + annzn = (α + βi)zn
as a nontrivial complex solution z1 = x1 + iy1, . . . , zn = xn + iyn. Thus,
⎧
⎪
⎨
⎪
⎩
a11(x1 + iy1) + · · · + a1n(xn + iyn) = (α + βi)(x1 + iy1)
...
...
...
an1(x1 + iy 1) + · · · + ann(xn + iyn) = (α + βi)(xn + iyn) .
Separating into real and imaginary parts gives
⎧
⎪
⎨
⎪
⎩
a11x1 + · · · + a1nxn = αx1 −βy1
...
...
...
an1x1 + · · · + annxn = αxn −βyn
(2.3.2)
and
⎧
⎪
⎨
⎪
⎩
a11y1 + · · · + a1nyn = αy1 + βx1
...
...
...
an1y1 + · · · + annyn = αyn + βxn.
(2.3.3)
Let x and y be the vectors in V whose components relative to our basis are
x1, . . . , xn and y1, . . . , yn respectively. Then Tx = αx−βy and Ty = αy +βx
as required. Notice that neither x nor y is zero since if x = 0, (2.3.2) and the

2.3 Invariant Subspaces
101
fact that β ̸= 0 imply y = 0 so z1 = · · · = zn = 0, which is a contradiction.
Similarly, y = 0 implies x = 0 so, in fact, neither can be zero.
■
In order to apply this result to the case of interest to us we require two ﬁnal
preliminary results.
Lemma 2.3.2 Let A and B be real numbers with B ̸= 0. Then the equation
λ4 + Aλ2 −B2 = 0 has a complex solution.
Proof:
Regard λ4 + Aλ2 −B2 = 0 as a quadratic in λ2 to obtain λ2 =
1
2(−A±
√
A2 + 4B2). Choosing the minus sign gives a negative λ2 and there-
fore complex λ.
■
Lemma 2.3.3 Let F : M →M be a nonzero, skew-symmetric linear trans-
formation. If the characteristic equation
λ4 + (|
⇀
B|2 −|
⇀
E|2)λ2 −(
⇀
E ·
⇀
B)2 = 0
has two distinct nonzero, real solutions, then there exists a 2-dimensional
subspace U of M which is invariant under F and satisﬁes U ∩U⊥= {0}.
Proof:
Let λ1 and λ2 be the two distinct nonzero real eigenvalues. Then
there exist nonzero vectors x and y such that Fx = λ1x and Fy = λ2y. By
Proposition 2.2.2(a), x and y are null. Observe next that x and y are linearly
independent. Indeed, ax + by = 0 implies
aFx + bFy = 0,
a(λ1x) + b(λ2y) = 0,
λ1(ax) + λ2(by) = 0,
λ1(ax) + λ2(−ax) = 0,
(λ1 −λ2)ax = 0.
Since λ1 −λ2 ̸= 0, ax = 0, but x is nonzero so a = 0. Similarly, b = 0 so x
and y are independent. Thus, U = Span{x, y} is 2-dimensional; it is clearly
invariant under F. Now suppose ax + by ∈U ∩U⊥. Then, in particular,
(ax + by) · x = 0,
a(x · x) + b(x · y) = 0,
b(x · y) = 0.
But x and y are null and nonparallel so x · y ̸= 0 and therefore b = 0.
Similarly, a = 0 so U ∩U ⊥= {0}.
■
Theorem 2.3.4 Let F : M →M be a nonzero, skew-symmetric linear
transformation on M. If F is regular, then there exists a 2-dimensional sub-
space U of M which is invariant under F and satisﬁes U ∩U⊥= {0}.

102
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
Proof:
Relative to any admissible basis, at least one of
⇀
E ·
⇀
B or |
⇀
B|2 −|
⇀
E|2
must be nonzero and F’s characteristic equation is
λ4 + (|
⇀
B|2 −|
⇀
E|2)λ2 −(
⇀
E ·
⇀
B)2 = 0.
(2.3.4)
We consider four cases:
1.
⇀
E ·
⇀
B = 0 and |
⇀
B|2 −|
⇀
E|2 < 0.
In this case (2.3.4) becomes λ2(λ2 + (|
⇀
B|2 −|
⇀
E|2)) = 0 and the solutions
are λ = 0 and λ = ±

|
⇀
E|2 −|
⇀
B|2. The latter are two distinct, nonzero real
solutions so Lemma 2.3.3 yields the result.
2.
⇀
E ·
⇀
B = 0 and |
⇀
B|2 −|
⇀
E|2 > 0.
The solutions of (2.3.4) are now λ = 0 and λ = ±βi, where β =

|
⇀
B|2 −|
⇀
E|2.
Lemma 2.3.1 implies that there exist nonzero vectors x and y in M such that
Fx = −βy
and
Fy = βx.
(2.3.5)
We claim that x and y are linearly independent. Indeed, suppose ax +by = 0
with, say, b ̸= 0. Then y = kx, where k = −a/b. Then Fx = −βy implies
Fx = (−βk)x. But F’s only real eigenvalue is 0 and β ̸= 0 so k = 0 and
therefore y = 0, which is a contradiction. Thus, b = 0. Since x ̸= 0, ax = 0
implies a = 0 and the proof is complete.
Thus, U = Span{x, y} is a 2-dimensional subspace of M that is invariant
under F. We claim that U ∩U⊥= {0}. Suppose ax + by ∈U ∩U⊥.
Then ax + by is null so (ax + by) · (ax + by) = 0, i.e.,
a2(x · x) + 2ab(x · y) + b2(y · y) = 0.
But x · y = x · (−1
β Fx) = −1
β(x · Fx) = 0 so
a2(x · x) + b2(y · y) = 0,
a2x ·
 1
β Fy

+ b2y ·

−1
β Fx

= 0,
a2
β

x · Fy −
b2
β

y · Fx = 0,
a2
β

x · Fy +
b2
β

x · Fy = 0,
a2 + b2
β

x · Fy = 0.
Now, if a2 + b2 ̸= 0, then x · Fy = 0 so x · (βx) = 0 and x · x = 0. Similarly,
y · y = 0 so x and y are orthogonal null vectors and consequently parallel.
But this is a contradiction since x and y are independent. Thus, a2 + b2 = 0
so a = b = 0 and U ∩U ⊥= {0}.

2.3 Invariant Subspaces
103
3.
⇀
E ·
⇀
B ̸= 0 and |
⇀
B|2 −|
⇀
E|2 = 0.
In this case (2.3.4) becomes λ4 = (
⇀
E ·
⇀
B)2 so λ2 = ±|
⇀
E ·
⇀
B|. λ2 = |
⇀
E ·
⇀
B|
gives two distinct, nonzero real solutions so the conclusion follows from
Lemma 2.3.3.
4.
⇀
E ·
⇀
B ̸= 0 and |
⇀
B|2 −|
⇀
E|2 ̸= 0.
Lemma 2.3.2 implies that (2.3.4) has a complex root α + βi(β ̸= 0). Thus,
Lemma 2.3.1 yields nonzero vectors x and y in M with
Fx = αx −βy
and
Fy = αy + βx.
There are two possibilities:
i. x and y are linearly dependent. Then, since neither is zero, y = kx for
some k ∈R with k ̸= 0. Thus, Fx = αx−βy = αx−kβx = (α−kβ)x and
Fy = αy + βx = αy + β
k y =

α + β
k

y. Since α + β
k ̸= α −kβ and since
0 is not a solution to (2.3.4) in this case we ﬁnd that F has two distinct,
nonzero real eigenvalues and again appeal to Lemma 2.3.3.
ii. x and y are linearly independent. Then U = Span{x, y} is a 2-dimensional
subspace of M that is invariant under F.
Exercise 2.3.1 Complete the proof by showing that U ∩U⊥= {0}.
■
To complete our work in this section we must show that a nonzero null
skew-symmetric F : M →M has 2-dimensional invariant subspaces and that
all of these intersect their orthogonal complements nontrivially. We address
the question of existence ﬁrst.
Proposition 2.3.5 Let F : M →M be a nonzero, null, skew-symmetric
linear transformation on M. Then both ker F and rng F
= (ker F)⊥
are 2-dimensional invariant subspaces of M and their intersection is a
1-dimensional subspace of M spanned by a null vector.
Proof:
ker F and rng F are obviously invariant under F. Since F is null,
⇀
E ·
⇀
B = 0 so, by Exercise 2.2.6, F is not invertible. Thus, dim(ker F) ̸= 0.
Proposition 2.2.1(c) then implies that dim(ker F) = 2 and, consequently,
dim(rng F) = 2.
Now, since rng F ∩ker F = rng F ∩(rng F)⊥by Proposition 2.2.1(a), if
this intersection is not {0}, it can contain only null vectors. Being a subspace
of M it must therefore be 1-dimensional. We show that this intersection
is, indeed, nontrivial as follows: For a null F the characteristic polynomial
(2.3.4) reduces to λ4 = 0. The Cayley-Hamilton Theorem (see [H]) therefore
implies that
F 4 = 0
(F null).
(2.3.6)

104
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
Next we claim that ker F ⊊ker F 2. ker F ⊆ker F 2 is obvious. Now, suppose
ker F = ker F 2, i.e., Fx = 0 iff F 2x = 0. Then
F 3x = F 2(Fx) = 0 =⇒Fx ∈ker F 2 = ker F
=⇒F(Fx) = 0
=⇒F 2x = 0
=⇒Fx = 0
by assumption,
so F 3x = 0 =⇒Fx = 0 and we conclude that ker F 3 = ker F. Repeating the
argument gives ker F 4 = ker F. But by (2.3.6), ker F 4 = M so ker F = M
and F is identically zero, contrary to hypothesis. Thus, ker F ⊊ker F 2 and
we may select a nonzero v ∈M such that F 2v = 0, but Fv ̸= 0. Thus,
Fv ∈rng F ∩ker F as required.
■
Exercise 2.3.2 Show that if F : M →M is a nonzero, null, skew-symmetric
linear transformation on M, then F 2v is null (perhaps 0) for every v ∈M.
Hint: Begin with (2.3.6).
All that remains is to show that if F is null, then every 2-dimensional invari-
ant subspace U satisﬁes U ∩U⊥̸= {0}.
Lemma 2.3.6 Let F : M →M be a nonzero, skew-symmetric linear trans-
formation on M. If there exists a 2-dimensional invariant subspace U for F
with U ∩U⊥= {0}, then U⊥is also a 2-dimensional invariant subspace for
F and there exists a real number α such that F 2u = αu for every u ∈U.
Proof:
U⊥is a subspace of M (Exercise 1.1.2) and is invariant under F
(Proposition 2.2.2(b)). Notice that the restriction of the Lorentz inner prod-
uct to U cannot be degenerate since this would contradict U ∩U⊥= {0}.
Thus, by Theorem 1.1.1, we may select an orthonormal basis {u1, u2} for U.
Now, let x be an arbitrary element of M. If u1 and u2 are both spacelike,
then v = x −[(x · u1)u1 + (x · u2)u2] ∈U⊥and x = v + [(x · u1)u1 + (x · u2)u2]
so x ∈U + U⊥.
Exercise 2.3.3 Argue similarly that if {u1, u2} contains one spacelike and
one timelike vector, then any x ∈M is in U + U⊥and explain why this is
the only remaining possibility for the basis {u1, u2}.
Since U ∩U⊥= {0} we conclude that M = U / U⊥so dim U⊥= 2.
Now we let {u1, u2} be an orthonormal basis for U and write Fu1 = au1 +
bu2 and Fu2 = cu1 + du2. Then, since neither u1 nor u2 is null, we have
0 = Fu1 · u1 = (au1 + bu2) · u1 = ±a so a = 0 and, similarly, d = 0.
Thus, Fu1 = bu2 and Fu2 = cu1, so F 2u1 = F(bu2) = bFu2 = bcu1 and
F 2u2 = bcu2. Let α = bc. Then, for any u = βu1 + γu2 ∈U we have
F 2u = βF 2u1 +γF 2u2 = β(αu1)+γ(αu2) = α(βu1 +γu2) = αu as required.
■

2.4 Canonical Forms
105
With this we can show that if F is null and nonzero and U is a 2-
dimensional invariant subspace for F, then U ∩U⊥̸= {0}. Suppose, to the
contrary, that U ∩U ⊥= {0}. Lemma 2.3.6 implies the existence of an α ∈R
such that F 2u = αu for all u in U. Thus, F 4u = F 2(F 2u) = F 2(αu) =
αF 2u = α2u for all u ∈U. But, by (2.3.6), F 4u = 0 for all u ∈U so α = 0
and F 2 = 0 on U. Again by Lemma 2.3.6 we may apply the same argument
to U⊥to obtain F 2 = 0 on U⊥. Since U and U⊥are 2-dimensional and
U ∩U⊥= {0}, M = U / U⊥so F 2 = 0 on all of M. But then, for every
u ∈M, F 2u ·u = 0 so Fu ·Fu = 0, i.e., rng F contains only null vectors. But
then dim(rng F) = 1 and this contradicts Proposition 2.2.1(c) and we have
proved:
Theorem 2.3.7 Let F : M →M be a nonzero, skew-symmetric linear
transformation on M. If F is null, then F has 2-dimensional invariant sub-
spaces and every such subspace U satisﬁes U ∩U⊥̸= {0}.
Combining this with Theorem 2.3.4 gives:
Corollary 2.3.8 Let F : M →M be a nonzero, skew-symmetric linear
transformation on M. Then F has 2-dimensional invariant subspaces and F
is regular i f f there exists such a subspace U such that U ∩U⊥= {0} (so F is
null i f f U ∩U⊥̸= {0} for every such subspace).
2.4 Canonical Forms
We now propose to use the results of the preceding section to prove that, for
any skew-symmetric linear transformation F : M →M, there exists a basis
for M relative to which the matrix of F has one of the two forms
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦
or
⎡
⎢⎢⎣
0
0
0
0
0
0
α
0
0
−α
0
α
0
0
α
0
⎤
⎥⎥⎦,
depending on whether F is regular or null respectively. We begin with the
regular case.
Thus, we suppose F : M →M is a nonzero, skew-symmetric linear trans-
formation and that (Corollary 2.3.8) there exists a 2-dimensional subspace U
of M which satisﬁes FU ⊆U and U ∩U⊥= {0}. Then (Lemma 2.3.6) U⊥is
also a 2-dimensional invariant subspace for F and there exist real numbers α
and β such that
F 2u = αu
for all u ∈U and
(2.4.1)
F 2v = βv
for all v ∈U⊥.
(2.4.2)

106
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
Since M = U / U⊥and U⊥⊥= U we may assume, without loss of generality,
that the restriction of the Lorentz inner product to U has index 1 and its
restriction to U⊥has index 0.
We claim now that α ≥0 and β ≤0. Indeed, dotting both sides of (2.4.1)
with itself gives F 2u ·u = α(u ·u), or −Fu ·Fu = α(u ·u) for any u in U. Now
if u ∈U is timelike, then Fu is spacelike or zero so u · u < 0 and Fu · Fu ≥0
and this implies α ≥0. Thus, we may write α = ϵ2 with ϵ ≥0 so (2.4.1)
becomes
F 2u = ϵ2u
for all u ∈U.
(2.4.3)
Exercise 2.4.1 Show that, for some δ ≥0,
F 2v = −δ2v
for all v ∈U⊥.
(2.4.4)
Now, select a future-directed unit timelike vector e4 in U. Then Fe4 is
spacelike or zero and in U so we may select a unit spacelike vector e3 in U
with Fe4 = ke3 for some k ≥0. Observe that ϵ2e4 = F 2e4 = F(Fe4) =
F(ke3) = kFe3. Thus,
kFe3 · e4 = ϵ2e4 · e4,
k(−e3 · Fe4) = ϵ2(−1),
k(e3 · (ke3)) = ϵ2,
k2e3 · e3 = ϵ2,
so k2 = ϵ2 and k = ϵ (since k ≥0 and ϵ ≥0). Thus, we have
Fe4 = ϵe3.
(2.4.5)
Notice that {e3, e4} is an orthonormal basis for U.
Exercise 2.4.2 Show that, in addition,
Fe3 = ϵe4.
(2.4.6)
Now, let e2 be an arbitrary unit spacelike vector in U⊥. Then Fe2 is space-
like or zero and in U⊥so we may select another unit spacelike vector e1 in
U⊥and orthogonal to e2 with Fe2 = ke1 for some k ≥0 (if e1 × e2 · e3 is −1
rather than 1, then relabel e1 and e2).
Exercise 2.4.3 Show that k = δ.
Thus,
Fe2 = δe1
(2.4.7)
and, as for (2.4.6),
Fe1 = −δe2.
(2.4.8)

2.4 Canonical Forms
107
Now, {e1, e2, e3, e4} is an orthonormal basis for M and any basis constructed
in this way is called a canonical basis for F. From (2.4.5)–(2.4.8) we ﬁnd that
the matrix of F relative to such a basis is
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦.
(2.4.9)
This is just the matrix of the FR deﬁned in Section 2.2. In a canonical basis
an observer measures electric and magnetic ﬁelds in the x3-direction and of
magnitudes ϵ and δ respectively. We have shown that such a frame exists
for any regular F. Observe that |
⇀
B|2 −|
⇀
E|2 = δ2 −ϵ2 and
⇀
E ·
⇀
B = δϵ.
Since these two quantities are invariants, δ and ϵ can be calculated from the
electric and magnetic 3-vectors in any frame. The canonical form (2.4.9) of
F is particularly convenient for calculations. For example, the fourth power
of the matrix (2.4.9) is easily computed and found to be
⎡
⎢⎢⎣
δ4
0
0
0
0
δ4
0
0
0
0
ϵ4
0
0
0
0
ϵ4
⎤
⎥⎥⎦,
so that, unlike the null case, F 4 ̸= 0. The eigenvalues of F are of some interest
and are also easy to calculate since the characteristic equation (2.3.4) becomes
λ4+(δ2−ϵ2)λ2−δ2ϵ2 = 0 i.e., (λ2−ϵ2)(λ2+δ2) = 0 whose only real solutions
are λ = ±ϵ. The eigenspace corresponding to λ = ϵ is obtained by solving
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
ϵv1
ϵv2
ϵv3
ϵv4
⎤
⎥⎥⎦,
i.e.,
⎡
⎢⎢⎣
δv2
−δv1
ϵv4
ϵv3
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
ϵv1
ϵv2
ϵv3
ϵv4
⎤
⎥⎥⎦.
If ϵ = 0 and δ ̸= 0, then v1 = v2 = 0, whereas v3 and v4 are arbitrary. Thus,
the eigenspace is Span{e3, e4}. Similarly, if ϵ ̸= 0 and δ = 0, v1 = v2 = 0
and v3 = v4 so the eigenspace is Span{e3 + e4}. If ϵδ ̸= 0, δv2 = ϵv1 and
−δv1 = ϵv2 again imply v1 = v2 = 0; in addition, v3 = v4 so the eigenspace
is Span{e3 + e4}. In the ﬁrst case the eigenspace contains two independent
null directions (those of e3 + e4 and e3 −e4), whereas in the last two cases,
there is only one (e3 + e4). For λ = −ϵ, the result is obviously the same in

108
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
the ﬁrst case, while in the second and third the eigenspace is spanned by
e3 −e4. The null directions corresponding to e3 ± e4 are called the principal
null directions of F.
Now we turn to the case of a nonzero, null, skew-symmetric linear trans-
formation F : M →M and construct an analogous “canonical basis”. Begin
with an arbitrary future-directed unit timelike vector e4 in M.
Exercise 2.4.4 Show that Fe4 is spacelike. Hint: Fe4 = 0 would imply
e4 ∈(rng F)⊥.
Thus, we may select a unit spacelike vector e3 in M such that e3 ·e4 = 0 and
Fe4 = αe3
(2.4.10)
for some α > 0. Observe that e3 = F
 1
αe4

∈rng F. Next we claim that
Fe3 is a nonzero vector in rng F ∩ker F. Fe3 ̸= 0 is clear since Fe3 = 0 =⇒
e3 ∈rng F ∩ker F, but e3 is spacelike and this contradicts Proposition 2.3.5.
Fe3 ∈rng F is obvious. Now, by Exercise 2.3.2, F 2e3 is either zero or null and
nonzero. F 2e3 = 0 implies F(Fe3) = 0 so Fe3 ∈ker F as required. Suppose,
on the other hand, that F 2e3 is null and nonzero. Fe3 ·F 2e3 = 0 implies that
Fe3 is not timelike. Fe3·e3 = 0 implies that Fe3 is not spacelike since then rng
F would contain a null and two orthogonal spacelike vectors, contradicting
Proposition 2.3.5. Thus, Fe3 is null and nonzero. But then {e3, Fe3} is a
basis for rng F and Fe3 is orthogonal to both so Fe3 ∈(rng F)⊥= ker F as
required.
Now we wish to choose a unit spacelike vector e2 such that e2 · e4 = 0,
e2 · e3 = 0 and Span{e2 + e4} = rng F ∩ker F. To see how this is done select
any null vector N spanning rng F ∩ker F such that N · e4 = −1. Then let
e2 = N −e4. It follows that e2 · e2 = (N −e4) · (N −e4) = N · N −2N · e4 +
e4·e4 = 0−2(−1)−1 = 1 so e2 is unit spacelike. Moreover, e2+e4 = N spans
rng F ∩ker F. Also, e2 · e4 = (N −e4) · e4 = N · e4 −e4 · e4 = −1 −(−1) = 0.
Finally, e2 +e4 ∈(rng F)⊥implies 0 = (e2 +e4)·e3 = e2 ·e3 +e4 ·e3 = e2 ·e3
and the construction is complete. Now, there exists an α′ > 0 such that
Fe3 = α′(e2 + e4). But α = e3 · (αe3) = e3 · Fe4 = −e4 · [α′(e2 + e4)] =
−α′[e4 · e2 + e4 · e4] = −α′[0 −1] = α′ so
Fe3 = α(e2 + e4).
(2.4.11)
Next we compute Fe2 = F(N −e4) = FN −Fe4 = 0 −αe3 so
Fe2 = −αe3.
(2.4.12)
Finally, we select a unit spacelike vector e1 which is orthogonal to e2, e3 and
e4 and satisﬁes e1 × e2 · e3 = 1 to obtain an admissible basis {ea}4
a=1.
Exercise 2.4.5 Show that
Fe1 = 0.
(2.4.13)
Hint: Show that Fe1 · ea = 0 for a = 1, 2, 3, 4.

2.5 The Energy-Momentum Transformation
109
A basis for M constructed in the manner just described is called a canon-
ical basis for F. The matrix of F relative to such a basis (read oﬀfrom
(2.4.10)–(2.4.13)) is
⎡
⎢⎢⎢⎣
0
0
0
0
0
0
α
0
0
−α
0
α
0
0
α
0
⎤
⎥⎥⎥⎦
(2.4.14)
and is called a canonical form for F. This is, of course, just the matrix of the
transformation FN introduced in Section 2.2 and we now know that every
null F takes this form in some basis. An observer in the corresponding frame
sees electric
⇀
E = αe3 and magnetic
⇀
B = αe1 3-vectors that are perpendicular
and have the same magnitude α.
Exercise 2.4.6 Calculate the third power of the matrix (2.4.14) and im-
prove (2.3.5) by showing
F 3 = 0 (F null).
(2.4.15)
For any two vectors u and v in M deﬁne a linear transformation u∧v : M →
M by u ∧v(x) = u(v · x) −v(u · x).
Exercise 2.4.7 Show that, if F is null, then, relative to a canonical basis
{ea}4
a=1,
F = Fe3 ∧e3.
(2.4.16)
The only eigenvalue of a null F is, of course, λ = 0.
Exercise 2.4.8 Show that, relative to a canonical basis {ea}4
a=1, the
eigenspace of F corresponding to λ = 0, i.e., ker F, is Span{e1, e2 + e4}
and so contains precisely one null direction (which is called the principal null
direction of F).
2.5 The Energy-Momentum Transformation
Let F : M →M be a nonzero, skew-symmetric linear transformation on M.
The linear transformation T : M →M deﬁned by
T = 1
4π
*1
4tr(F 2)I −F 2
+
,
(2.5.1)
where F 2 = F ◦F, I is the identity transformation I(x) = x for every x
in M and tr(F 2) is the trace of F 2, i.e., the sum of the diagonal entries
in the matrix of F 2 relative to any basis, is called the energy-momentum

110
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
transformation associated with F. Observe that T is symmetric with respect
to the Lorentz inner product, i.e.,
Tx · y = x · Ty
(2.5.2)
for all x and y in M.
Exercise 2.5.1 Prove (2.5.2).
Moreover, since tr(I) = 4, T is trace-free, i.e.,
tr T = 0.
(2.5.3)
Relative to any admissible basis for M the matrix [T ab] of T has entries
given by
T a
b =
1
4π
 1
4F α
β F β
α δa
b −F a
α F α
b

,
a, b = 1, 2, 3, 4.
(2.5.4)
Although not immediately apparent from the deﬁnition, T contains all of
the information relevant to describing the classical “energy” and “momen-
tum” content of the electromagnetic ﬁeld represented by F in each admissible
frame. To see this we need the matrix of T in terms of the electric and mag-
netic 3-vectors
⇀
E and
⇀
B.
Exercise 2.5.2 With the matrix of F relative to {ea} written in the form
(2.2.3), calculate the matrix of F 2 relative to {ea} and show that it can be
written as
⎡
⎢⎢⎢⎢⎣
(E1)2 −(B2)2 −(B3)2
E1E2 + B1B2
E1E3 + B1B3
E2B3 −E3B2
E1E2 + B1B2
(E2)2 −(B1)2 −(B3)2
E2E3 + B2B3
E3B1 −E1B3
E1E3 + B1B3
E2E3 + B2B3
(E3)2 −(B1)2 −(B2)2 E1B2 −E2B1
E3B2 −E2B3
E1B3 −E3B1
E2B1 −E1B2
|
⇀
E|2
⎤
⎥⎥⎥⎥⎦
(2.5.5)
Now,
1
4π times the oﬀ-diagonal entries in (2.5.5) are the oﬀ-diagonal entries
in [T ab]. Adding the diagonal entries in (2.5.5) gives tr(F 2) = 2(|
⇀
E|2 −|
⇀
B|2)
so 1
4tr(F 2) = 1
2((E1)2 +(E2)2 +(E3)2 −(B1)2 −(B2)2 −(B3)2). Subtracting
the diagonal entries in (2.5.5) from the corresponding diagonal entries in
1
4tr(F 2)I gives 4π times the diagonal entries in [T ab]. Thus,
T 1
1 =
1
8π[−(E1)2 + (E2)2 + (E3)2 −(B1)2 + (B2)2 + (B3)2],
T 2
2 =
1
8π[(E1)2 −(E2)2 + (E3)2 + (B1)2 −(B2)2 + (B3)2],
T 33 =
1
8π[(E1)2 + (E2)2 −(E3)2 + (B1)2 + (B2)2 −(B3)2],
(2.5.6)
T 44 = −1
8π

|
⇀
E|2 + |
⇀
B|2
.
Notice once again that the nonzero index of the Lorentz inner product has
the unfortunate consequence that the matrix of a symmetric linear transfor-
mation on M is not (quite) a symmetric matrix.

2.5 The Energy-Momentum Transformation
111
In classical electromagnetic theory the quantity
1
8π[|
⇀
E|2 + |
⇀
B|2]

= −T 44

is called the energy density measured in the given frame of reference for the
electromagnetic ﬁeld with electric and magnetic 3-vectors
⇀
E and
⇀
B. The
3-vector
1
4π
⇀
E ×
⇀
B = (E2B3 −E3B2)e1 + (E3B1 −E1B3)e2 + (E1B2 −
E2B1)e3 = T 14e1 + T 24e2 + T 34e3 = −

T 41e1 + T 42e2 + T 43e3

is called
the Poynting 3-vector and describes the energy density ﬂux of the ﬁeld. Fi-
nally, the 3 × 3 matrix

T ij

i,j=1,2,3 is known as the Maxwell stress tensor
of the ﬁeld in the given frame. Thus, the entries in the matrix of T relative
to an admissible basis all have something to say about the energy content of
the ﬁeld F measured in the corresponding frame.
Notice that the (4, 4)-entry in the matrix [T ab] of T relative to {ea} is
T 44 = −Te4·e4 = −1
8π[|
⇀
E|2+|
⇀
B|2]. Thus, we deﬁne, for every future-directed
unit timelike vector U, the energy density of F in any admissible basis with
e4 = U to be TU · U. In the sense of the following result, the energy density
completely determines the energy-momentum transformation.
Theorem 2.5.1 Let S and T be two nonzero linear transformations on M
which are symmetric with respect to the Lorentz inner product, i.e., satisfy
(2.5.2). If SU · U = TU · U for every future-directed unit timelike vector U,
then S = T .
Proof:
Observe ﬁrst that the hypothesis, together with the linearity of S
and T imply that SV · V = TV · V for all timelike vectors V . Now select a
basis {Ua}4
a=1 for M, consisting exclusively of future-directed unit timelike
vectors (convince yourself that such things exist). Thus, SU a ·Ua = TU a ·Ua
for each a = 1, 2, 3, 4. Next observe that, for all a, b = 1, 2, 3, 4, Lemma 1.4.3
implies that Ua + Ub is timelike and future-directed so that
S(Ua + Ub) · (Ua + Ub) = T (Ua + Ub) · (Ua + Ub),
SU a · Ua + 2SU a · Ub + SU b · Ub = TU a · Ua + 2TU a · Ub + TU b · Ub,
SU a · Ub = TU a · Ub.
Exercise 2.5.3 Show that
Sx · y = Tx · y
(2.5.7)
for all x and y in M.
Now, let {ea}4
a=1 be an orthonormal basis for M. Then (2.5.7) gives
Sea · eb = Tea · eb
(2.5.8)
for all a, b = 1, 2, 3, 4. But (2.5.8) shows that the matrices of S and T relative
to {ea} are identical so S = T .
■
We investigate the eigenvalues and eigenvectors of T by working in a canon-
ical basis for F. First suppose F is regular and {ea} is a canonical basis for
F. Then the matrix [F ab] of F relative to {ea} has the form (2.4.9) and a
simple calculation gives

112
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
[F ab]2 =
⎡
⎢⎢⎣
−δ2
0
0
0
0
−δ2
0
0
0
0
ϵ2
0
0
0
0
ϵ2
⎤
⎥⎥⎦
so tr(F 2) = 2(ϵ2 −δ2) and therefore [T ab] =
1
4π[ 1
4tr(F 2)I −[F ab]2] is given by
[T ab] = 1
8π (ϵ2 + δ2)
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
−1
0
0
0
0
−1
⎤
⎥⎥⎦.
det(T −λI) = 0 therefore gives (λ+ ϵ2+δ2
8π )2(λ−ϵ2+δ2
8π )2 = 0 so λ = ± ϵ2+δ2
8π
=
∓T 44 (the energy density). The eigenvectors corresponding to λ = ϵ2+δ2
8π
are
obtained by solving
ϵ2 + δ2
8π
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
−1
0
0
0
0
−1
⎤
⎥⎥⎦
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦= ϵ2 + δ2
8π
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦,
i.e.,
⎡
⎢⎢⎣
v1
v2
−v3
−v4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦,
so v3 = v4 = 0, whereas v1 and v2 are arbitrary. Thus, the eigenspace is
Span{e1, e2} which contains only spacelike vectors. Similarly, the eigenspace
corresponding to λ = −ϵ2+δ2
8π
is Span{e3, e4} which contains two independent
null directions (e3 ± e4) called the principal null directions of T .
If F is null and {ea} is a canonical basis, then [F ab] has the form (2.4.14) so
[F a
b]2 =
⎡
⎢⎢⎣
0
0
0
0
0
−α2
0
α2
0
0
0
0
0
−α2
0
α2
⎤
⎥⎥⎦
and therefore tr F 2 = 0 so
[T ab] = −1
4π [F ab]2 = α2
4π
⎡
⎢⎢⎣
0
0
0
0
0
1
0
−1
0
0
0
0
0
1
0
−1
⎤
⎥⎥⎦.

2.6 Motion in Constant Fields
113
Exercise 2.5.4 Show that λ = 0 is the only eigenvalue of T and that the
corresponding eigenspace is Span{e1, e3, e2 + e4}, which contains only one
null direction (that of e2 + e4), again called the principal null direction of T.
Exercise 2.5.5 Show that every eigenvector of F is also an eigenvector of
T (corresponding to a diﬀerent eigenvalue, in general).
Exercise 2.5.6 Show that the energy-momentum transformation T satisﬁes
the dominant energy condition, i.e., has the property that if u and v are
timelike or null and both are future-directed, then
Tu · v ≥0.
(2.5.9)
Hint: Work in canonical coordinates for the corresponding F.
2.6 Motion in Constant Fields
Thus far we have concentrated our attention on the formal mathematical
structure of the object we have chosen to model an electromagnetic ﬁeld at
a ﬁxed point of M, that is, a skew-symmetric linear transformation. In or-
der to reestablish contact with the physics of relativistic electrodynamics we
must address the issue of how a given collection of charged particles gives
rise to these linear transformations at each point of M and then study how
the worldline of another charge introduced into the system will respond to
the presence of the ﬁeld. The ﬁrst problem we defer to Section 2.7. In this
section we consider the motion of a charged particle in the simplest of all
electromagnetic ﬁelds, i.e., those that are constant. Thus, we presume the
existence of a system of particles that determines a single skew-symmetric
linear transformation F : M →M with the property that any charged par-
ticle (α, m, e) introduced into the system will experience changes in world
momentum at every point on its worldline described by (2.1.1). More partic-
ularly, we have in mind ﬁelds with the property that there exists a frame of
reference in which the ﬁeld is constant and either purely magnetic (
⇀
E =
⇀
0)
or purely electric (
⇀
B =
⇀
0). To a reasonable degree of approximation such
ﬁelds exist in nature and are of considerable practical importance. Such a
ﬁeld, however, can obviously not be null (without being identically zero) so
we shall restrict our attention to the regular case and will work exclusively
in a canonical basis.
Suppose then that F : M →M is nonzero, skew-symmetric and regular.
Then there exists an admissible basis {ea}4
a=1 for M and two real numbers
ϵ ≥0 and δ ≥0 so that the matrix of F in {ea} is

114
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
[F ab] =
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦,
so that
⇀
E = ϵe3 and
⇀
B = δe3. Let (α, m, e) be a charged particle with world
velocity U = U(τ) = U a(τ)ea which satisﬁes
dU
dτ = e
mFU
(2.6.1)
at each point of α. Thus,
⎡
⎢⎢⎣
dU 1/dτ
dU 2/dτ
dU 3/dτ
dU 4/dτ
⎤
⎥⎥⎦= e
m
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
U 1
U 2
U 3
U 4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
ωU 2
−ωU 1
νU 4
νU 3
⎤
⎥⎥⎦,
where ω = δe
m and ν = ϵe
m. Thus, we have
⎧
⎪
⎪
⎨
⎪
⎪
⎩
dU 1
dτ
= ωU 2
dU 2
dτ
= −ωU 1
(2.6.2)
and
⎧
⎪
⎪
⎨
⎪
⎪
⎩
dU 3
dτ
= νU 4
dU 4
dτ
= νU 3.
(2.6.3)
We (temporarily) assume that neither ϵ nor δ is zero so that ων ̸= 0. Diﬀer-
entiating the ﬁrst equation in (2.6.2) with respect to τ and using the second
equation gives
d2U 1
dτ 2
= −ω2U 1
(2.6.4)
and similarly for (2.6.3),
d2U 3
dτ 2
= ν2U 3.
(2.6.5)
The general solution to (2.6.4) is
U 1 = A sin ωτ + B cos ωτ
(2.6.6)
and, since U2 = 1
ω
dU 1
dτ ,
U 2 = A cos ωτ −B sin ωτ.
(2.6.7)

2.6 Motion in Constant Fields
115
Similarly,
U3 = C sinh ντ + D cosh ντ
(2.6.8)
and
U 4 = C cosh ντ + D sinh ντ.
(2.6.9)
Exercise 2.6.1 Integrate (2.6.6) and (2.6.7) and show that the result can
be written in the form
x1(τ) = a sin(ωτ + φ) + x1
0
(2.6.10)
and
x2(τ) = a cos(ωτ + φ) + x2
0,
(2.6.11)
where a, φ, x1
0 and x2
0 are constants and a > 0.
Integrating (2.6.8) and (2.6.9) gives
x3(τ) = C
ν cosh ντ + D
ν sinh ντ + x3
0
(2.6.12)
and
x4(τ) = C
ν sinh ντ + D
ν cosh ντ + x4
0.
(2.6.13)
Observe now that if ϵ = 0 and δ ̸= 0, (2.6.10) and (2.6.11) are unchanged,
whereas dU 3
dτ = dU 4
dτ
= 0 imply that (2.6.12) and (2.6.13) are replaced by
x3(τ) = C3τ + x3
0
(ϵ = 0)
(2.6.14)
and
x4(τ) = C4τ + x4
0
(ϵ = 0).
(2.6.15)
Similarly, if ϵ ̸= 0 and δ = 0, then (2.6.12) and (2.6.13) are unchanged, but
(2.6.10) and (2.6.11) become
x1(τ) = C1τ + x1
0
(δ = 0)
(2.6.16)
and
x2(τ) = C2τ + x2
0
(δ = 0).
(2.6.17)
Now we consider two special cases. First suppose that ϵ = 0 and δ ̸= 0
(so that an observer in {ea} sees a constant and purely magnetic ﬁeld in the
e3-direction). Then (2.6.10), (2.6.11), (2.6.14) and (2.6.15) give
α(τ) =

a sin(ωτ + φ) + x1
0, a cos(ωτ + φ) + x2
0, C3τ + x3
0, C4τ + x4
0

so that
U(τ) = (aω cos(ωτ + φ), −aω sin(ωτ + φ), C3, C4).

116
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
Now, U · U = −1 implies a2ω2 + (C3)2 −(C4)2= −1. Since C4 = U4 = γ > 0,
C4 = (1 + a2ω2 + (C3)2)
1
2 so
α(τ) =

x1
0, x2
0, x3
0, x4
0

+ (a sin(ωτ + φ), a cos(ωτ + φ),
C3τ, (1 + a2ω2 + (C3)2)
1
2 τ).
(2.6.18)
Note that

x1 −x1
0
2 +

x2 −x2
0
2 = a2. Thus, if C3 ̸= 0, the trajectory in
{e1, e2, e3}-space is a spiral along the e3-direction (i.e., along the magnetic
ﬁeld lines). If C3 = 0, the trajectory is a circle. This latter case is of some
practical signiﬁcance since one can introduce constant magnetic ﬁelds in a
bubble chamber in such a way as to induce a particle of interest to follow
a circular path. We show now that by making relatively elementary mea-
surements one can in this way determine the charge-to-mass ratio
e
m for the
particle. Indeed, with C3 = 0, (2.6.18) yields by diﬀerentiation
U(τ) =

aω cos(ωτ + φ), −aω sin(ωτ + φ), 0, (1 + a2ω2)
1
2

.
(2.6.19)
But U = γ(
⇀u, 1) by (1.4.10) so
⇀u =

aω
γ cos(ωτ + φ), −aω
γ sin(ωτ + φ), 0

and thus
β2 = |
⇀u|2 = a2ω2
γ2
=
a2ω2
1 + a2ω2 =
1
m2
a2e2δ2 + 1
.
Exercise 2.6.2 Assume e > 0 and β > 0 and solve for
e
m to obtain
e
m =
1
a|δ|
β

1 −β2 .
Finally, we suppose that δ = 0 and ϵ ̸= 0 (constant and purely electric
ﬁeld in the e3-direction). Then (2.6.12), (2.6.13), (2.6.16) and (2.6.17) give
α(τ) =

C1τ + x1
0, C2τ + x2
0, C
ν cosh ντ + D
ν sinh ντ + x3
0 ,
C
ν sinh ντ + D
ν cosh ντ + x4
0

.
Consequently,
U(τ) = (C1, C2, C sinh ντ + D cosh ντ, C cosh ντ + D sinh ντ).
We consider the case in which α(0) = 0 so that x1
0 = x2
0 = 0, x3
0 = −C
ν
and x4
0 = −D
ν . Next we suppose that
⇀u(0) = e1 (the initial velocity
of the particle relative to {ea}4
a=1 has magnitude 1 and direction per-
pendicular to that of the ﬁeld
⇀
E= ϵe3). Then C1 = 1, C2 = 0 and
D = 0, i.e., U(τ) = (1, 0, C sinh ντ, C cosh ντ). Moreover, U · U = −1 gives

2.7 Variable Electromagnetic Fields
117
−1 = 12 + 02 + C2 sinh2 ντ −C2 cosh2 ντ = 1 −C2 so C2 = 2. Since
C = γ(0) > 0, we have C =
√
2. Thus,
α(τ) =

τ, 0,
√
2
ν (cosh ντ −1),
√
2
ν sinh ντ

.
The trajectory in {e1, e2, e3}-space is the curve τ →

τ, 0,
√
2
ν (cosh ντ −1)

.
Thus, x3 =
√
2
ν (cosh(νx1) −1), i.e.,
x3 = m
√
2
eϵ

cosh
eϵ
mx1
−1

which is a catenary in the x1x3-plane (see Figure 2.6.1).
Fig. 2.6.1
2.7 Variable Electromagnetic Fields
Most electromagnetic ﬁelds encountered in nature are not constant. That is,
the linear transformations that tell a charged particle how to respond to the
ﬁeld generally vary from point to point along the particle’s worldline. To
discuss such phenomena we shall require a few preliminaries.
A subset R of M is said to be open in M if, for each x0 ∈R, there
exists a positive real number ε such that the set NE
ε (x0) =

x ∈M :
(

x1 −x1
0
2 +

x2 −x2
0
2 +

x3 −x3
0
2 +

x4 −x4
0
2)
1
2 < ε

is contained
entirely in R (in Section A.1 of Appendix A we show that this deﬁnition

118
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
does not depend on the particular admissible basis relative to which the co-
ordinates are calculated). This is the usual Euclidean notion of an open set
in R4 so, intuitively, one thinks of open sets in M as those sets which do not
contain any of their “boundary points”. Open sets in M will be called regions
in M. A real-valued function f : R →R deﬁned on some region R in M
is said to be smooth if it has continuous partial derivatives of all orders and
types with respect to x1, x2, x3 and x4 for any (and therefore all) admissi-
ble coordinate systems on M. For convenience, we shall denote the partial
derivative
∂f
∂xa of such a function by f,a. Now, suppose we have assigned to
each point p in some region R of M a linear transformation F(p) : M →M.
Relative to an admissible basis each F(p) will have a matrix [F ab(p)]. If the
entries in this matrix are smooth on R we say that the assignment p
F
−→F(p)
itself is smooth. If each of the linear transformations F(p) is skew-symmetric,
the smooth assignment p
F
−→F(p) is a reasonable ﬁrst approximation to the
deﬁnition of an “electromagnetic ﬁeld on R”. However, nature does not grant
us so much freedom as to allow us to make such assignments arbitrarily. The
rules by which we must play the game consist of a system of partial diﬀer-
ential equations known as “Maxwell’s equations”. In regions that are free of
charge and in terms of the electric and magnetic 3-vectors
⇀
E and
⇀
B these
equations require that
div
⇀
E = 0,
curl
⇀
B −∂
⇀
E
∂x4 =
⇀
0,
div
⇀
B = 0,
curl
⇀
E + ∂
⇀
B
∂x4 =
⇀
0,
(2.7.1)
where div and curl are the familiar divergence and curl from vector analysis
in R3. We now translate (2.7.1) into the language of Minkowski spacetime.
A mapping V : R →M which assigns to each p in some region R of M
a vector V (p) in M is called a vector ﬁeld on R. Relative to any admissible
basis {ea} for M we write V (p) = V a(p)ea, where V a : R →R, a = 1, 2, 3, 4,
are the component functions of V relative to {ea}. A vector ﬁeld is said to
be smooth if its component functions relative to any (and therefore every)
admissible basis are smooth. Now consider a smooth assignment p
F
−→F(p)
of a linear transformation to each p ∈R. We deﬁne a vector ﬁeld div F, called
the divergence of F, by specifying that its component functions relative to
any {ea} are given by
(div F)b = ηbβF αβ,α,
b = 1, 2, 3, 4.
(2.7.2)
Thus, (div F)i = F αi,α for i = 1, 2, 3 and (div F)4 = −F α4,α.

2.7 Variable Electromagnetic Fields
119
Exercise 2.7.1 A vector v in M has components relative to two admissible
bases that are related by ˆva = Λabvb. Show that (2.7.2) does indeed deﬁne a
vector in M by showing that it has the correct “transformation law”:


div F
a
= Λab(div F)b,
a = 1, 2, 3, 4,
(2.7.3)
where (
div F)a = ηaγ ˆF αγ,α and ˆF ab,c =
∂
∂ˆxc ˆF ab. Hint: Use the change of
basis formula
ˆF ab = ΛaαΛb
βF αβ
(2.7.4)
and the chain rule to show ﬁrst that
ˆF ab,c = ΛaαΛb
βΛc
γF αβ,γ.
(2.7.5)
Exercise 2.7.2 Show that if p
F
−→F(p) and p
G
−→G(p) are two smooth as-
signments of linear transformations to points in the region R and F + G is
deﬁned at each p ∈R by (F + G)(p) = F(p) + G(p), then
div(F + G) = div F + div G.
(2.7.6)
Exercise 2.7.3 Show that, if each F(p) is skew-symmetric, then, in terms
of the 3-vectors
⇀
E and
⇀
B,
(div F)i =
* ∂
⇀
E
∂x4 −curl
⇀
B
+
· ei,
i = 1, 2, 3,
(2.7.7)
(div F)4 = −div
⇀
E.
(2.7.8)
We conclude from Exercise 2.7.3 that the ﬁrst pair of equations in (2.7.1) is
equivalent to the single equation
div F = 0,
(2.7.9)
where 0 is, of course, the zero vector in M.
The second pair of equations in (2.7.1) is most conveniently expressed in
terms of a mathematical object closely related to F, but with a matrix that
is skew-symmetric. Thus, we deﬁne for each skew-symmetric linear transfor-
mation F : M →M an associated bilinear form
0F : M × M →R
by
0F(u, v) = u · Fv
(2.7.10)
for all u and v in M. Then 0F is skew-symmetric, i.e., satisﬁes
0F(v, u) = −0F(u, v).
(2.7.11)

120
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
The matrix [Fab] of 0F relative to an admissible basis {ea} has entries given by
Fab = 0F(ea, eb) = ea · Feb = ηacF cb
(2.7.12)
and is clearly a skew-symmetric matrix (notice how the position of the indices
is used to distinguish the matrix of 0F from the matrix of F).
Exercise 2.7.4 Show that if u = uaea and v = vbeb, then 0F(u, v) =
Fabuavb.
The entries Fab are often called the components of 0F in the basis {ea}. If {ˆea}
is another admissible basis, related to {ea} by the Lorentz transformation
[Λab], then the components of 0F in the two bases are related by
ˆFab = Λa
αΛb
βFαβ,
a, b = 1, 2, 3, 4.
(2.7.13)
To prove this we observe that, by deﬁnition, ˆFab = ηac ˆF cb = ηacΛcγΛb
βF γβ.
Now, (1.2.12) gives Λcγ = ηcρηγαΛρ
α so ˆFab = ηacηcρηγαΛρ
αΛb
βF γβ =
ηacηcρΛρ
αΛb
β (ηγαF γβ) = δρ
aΛρ
αΛb
βFαβ = Λa
αΛb
βFαβ as required.
Computing the quantities ηacF cb in terms of
⇀
E and
⇀
B gives
[Fab] =
⎡
⎢⎢⎣
0
B3 −B2 E1
−B3
0
B1 E2
B2 −B1
0
E3
−E1 −E2 −E3 0
⎤
⎥⎥⎦.
(2.7.14)
Every smooth assignment p
F
−→F(p) of a skew-symmetric linear transfor-
mation to each point in some region in M therefore gives rise to an assignment
p
0F
−→0F(p) which is likewise smooth in the sense that the entries in the matrix
(2.7.14) are smooth real-valued functions. As usual, we denote the derivatives
∂Fab/∂xc by Fab,c.
Exercise 2.7.5 Show that the second pair of equations in (2.7.1) is equiv-
alent to
Fab,c + Fbc,a + Fca,b = 0,
a, b, c = 1, 2, 3, 4.
(2.7.15)
Now we deﬁne an electromagnetic ﬁeld on a region R in M to be a smooth
assignment p
F
−→F(p) of a skew-symmetric linear transformation to each
point p in R such that it and its associated assignment p
0F
−→0F(p) of skew-
symmetric bilinear forms satisfy Maxwell’s equations (2.7.9) and (2.7.15).
We remark in passing that a skew-symmetric bilinear form is often referred
to as a bivector and a smooth assignment of one such to each p in R is called a
2-form on R. In the language of exterior calculus the left-hand side of (2.7.15)
speciﬁes what is called the exterior derivative of 0F (a 3-form) and denoted
d 0F. Then (2.7.15) becomes
d 0F = 0.

2.7 Variable Electromagnetic Fields
121
Since most modern expositions of electromagnetic theory are phrased in terms
of these diﬀerential forms and because it will be of interest to us in Chap-
ter 3, we show next that the ﬁrst pair of equations in (2.7.1) (or equivalently,
(2.7.9)) can be written in a similar way. Indeed, the reader may have no-
ticed a certain “duality” between the ﬁrst and second pairs of equations in
(2.7.1). Speciﬁcally, the ﬁrst pair can be obtained from the second by for-
mally changing the
⇀
B to an
⇀
E and the
⇀
E to −
⇀
B (and adjusting a sign). This
suggests deﬁning the “dual” of the 2-form 0F to be a 2-form ∗0F whose matrix
at each point is obtained from (2.7.14) by formally making the substitutions
Bi →Ei and Ei →−Bi so that the ﬁrst pair of equations in (2.7.1) would be
equivalent to d∗0F = 0. In order to carry out this program rigorously we will
require a few preliminaries. First we introduce the Levi-Civita symbol ϵabcd
deﬁned by
ϵabcd =
⎧
⎪
⎨
⎪
⎩
1
if abcd is an even permutation of 1234
−1
if abcd is an odd permutation of 1234
0
otherwise.
Thus, for example, ϵ1234 = ϵ3412 = ϵ4321 = 1, ϵ1324 = ϵ3142 = −1 and ϵ1224 =
ϵ1341 = 0. The Levi-Civita symbol arises most naturally in the theory of
determinants where it is shown that, for any 4×4 matrix M = [M ab]a,b=1,2,3,4,
M αa M βb M γc M δd ϵαβγδ = ϵabcd(det M).
(2.7.16)
Exercise 2.7.6 Let F be a skew-symmetric linear transformation on M and
0F its associated bilinear form. For a, b = 1, 2, 3, 4 deﬁne
∗Fab = −1
2ϵαβab F αβ,
(2.7.17)
where F αβ = ηαμ ηβν Fμν. Show that, in terms of
⇀
E and
⇀
B, the matrix [∗Fab]
is just (2.7.14) after the substitutions Bi →Ei and Ei →−Bi have been
made, e.g., ∗F12 = E3. Hint: Just calculate −1
2ϵαβab F αβ in terms of
⇀
E and
⇀
B for various choices of a and b and use the skew-symmetry of ∗Fab and Fab
to minimize the number of such choices you must make.
Exercise 2.7.7 Let {ea} and {ˆea} be two admissible bases for M, F a
skew-symmetric linear transformation on M and 0F its associated bilinear
form. Deﬁne ∗Fab = −1
2ϵαβab F αβ and ∗ˆFab = −1
2ϵαβab ˆF αβ, where ˆF αβ =
ηαμ ηβν ˆFμν and ˆFμν = ημσ ˆF σν. Show that for any two vectors u = uaea =
ˆuaˆea and v = vbeb = ˆvbˆeb in M,
∗Fab ua vb = ∗ˆFab ˆua ˆvb.
(2.7.18)
Hint: First show that (2.7.13) is equivalent to
ˆF ab = Λaα Λbβ F αβ
(2.7.19)
and use (2.7.16).

122
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
The equality in (2.7.18) legitimizes the following deﬁnition: If F is a skew-
symmetric linear transformation on M and 0F is its associated bilinear form
we deﬁne the dual of 0F to be the bilinear form ∗0F : M × M →R whose
value at (u, v) ∈M × M is
∗0F(u, v) = ∗Fabuavb.
(2.7.20)
Exercise 2.7.7 assures us that this deﬁnition is independent of the partic-
ular admissible basis in which the calculations are performed. Moreover,
Exercise 2.7.6 and the above-mentioned duality between the ﬁrst and sec-
ond pairs of equations in (2.7.1) make it clear that the ﬁrst of Maxwell’s
equations (2.7.9) is equivalent to
∗Fab,c + ∗Fbc,a + ∗Fca, b = 0,
a, b, c = 1, 2, 3, 4,
(2.7.21)
or, more concisely,
d∗0F = 0.
We should point out that the linear transformation F, its associated bilinear
form 0F and the dual ∗0F of 0F all contain precisely the same information
from both the mathematical and the physical points of view (examine their
matrices in terms of
⇀
E and
⇀
B). Some matters are more conveniently discussed
in terms of F. For others, the appropriate choice is 0F or ∗0F. Some calculations
are simplest when carried out with the F ab, whereas for others one might
prefer to work with Fab, or F ab, or ∗Fab. One must become comfortable with
this sort of shifting perspective. In particular, one must develop a facility
for the “index gymnastics” that, as we have seen already in this section, are
necessitated by such a shift. To reinforce this point, to prepare gently for
Chapter 3 and to derive a very important property of the energy-momentum
transformation, we pause to provide a bit more practice.
Exercise 2.7.8 Show that, for any skew-symmetric linear transformation
F : M →M,
1
2FabF ab = |
⇀
B|2 −|
⇀
E|2 and 1
4
∗FabF ab =
⇀
E ·
⇀
B.
Next we consider a skew-symmetric linear transformation F : M →M
and its associated energy-momentum transformation T : M →M given by
(2.5.1). Deﬁne a bilinear form 0T : M × M →R by 0T(u, v) = u · Tv for all
(u, v) ∈M × M. Then 0T is symmetric, i.e., 0T(v, u) = 0T(u, v) by (2.5.2).
Now let {ea} be an admissible basis and [T ab] the matrix of T relative to this
basis (see (2.5.4)). For all a, b = 1, 2, 3, 4, we let Tab = T (ea, eb) = ea · Teb =
ηaγ T γb. Then, if u = uaea and v = vbeb, we have T (u, v) = Tabuavb just as
in Exercise 2.7.4. As an exercise in index manipulation and because we will
need the result in Chapter 3 we show that Tab can be written in the form
Tab =
1
4π

Faα Fb
α −1
4 ηab Fαβ F αβ
,
(2.7.22)

2.7 Variable Electromagnetic Fields
123
where Fb
α = ηbμ F μα. Begin with (2.5.4).
4π Tab = 4π ηaγ T γb = ηaγ
 1
4 F αβ F βα δγ
b −F γα F αb

= 1
4F αβ F βα (ηaγ δγ
b ) −(ηaγ F γα) F αb
= 1
4F αβ F βα ηab −Faα F αb
= 1
4ηab(ηαγ Fγβ)(ηασ F βσ) −Faα ηbγ F αγ
= 1
4ηab(ηαγ ηασ)Fγβ F βσ + Faα ηbγ F γα
= 1
4ηab δγ
σ Fγβ F βσ + Faα Fb
α = 1
4 ηab Fγβ F βγ + Faα Fb
α
= Faα Fb
α −1
4 ηab Fγβ F γβ = Faα Fb
α −1
4 ηab Fαβ F αβ
as required.
Exercise 2.7.9 Show that if u = uaea and v = vbeb are timelike or null and
both are future-directed, then the dominant energy condition (2.5.9) can be
written
Tab ua vb ≥0.
Now let p
F
−→F(p) be an electromagnetic ﬁeld on some region R in M.
Assign to each p in R a linear transformation T (p) which is the energy-
momentum transformation of F(p).
Exercise 2.7.10 Show that the assignment p
T
−→T (p) is smooth and that
div T = 0.
(2.7.23)
Hints: From (2.5.4) and the product rule show that 4πT ab,c = −F aαF αb,c −
F αbF aα,c +
1
4

F αβF βα,c + F βαF αβ,c

δa
b . Next show that 4πT ab,a
=
−F aα,aF αb −F aαF αb,a + 1
2F αβ,bF βα. Finally, observe that F aαF αb,a =
F aαFαb,a(F aα−F αa)=−1
2F αa(Fαb,a−Fab,α) and F aα,aF αb= (ηcγF aγ,a) Fcb.
With the deﬁnitions behind us we can now spend some time looking at
examples and applications. Of course, we have already encountered several
examples since any assignment of the same skew-symmetric linear transfor-
mation to each p in R is obviously smooth and satisﬁes Maxwell’s equations
and these constant electromagnetic ﬁelds were investigated in Section 2.6.
As our ﬁrst nontrivial example we examine the so-called Coulomb ﬁeld of a
single free charged particle.
We begin with a free charged particle (α, m, e). Since α : R →M we may
let W = α(R). Then W is a timelike straight line which we may assume,
without loss of generality, to be a time axis with α(0) = 0. Let {ea}4
a=1 be
an admissible basis with W = Span{e4}, i.e., a rest frame for the particle.
We deﬁne an electromagnetic ﬁeld F on M−W by specifying, at each point,
its matrix relative to {ea} and decreeing that its matrix in any other basis

124
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
is obtained from the change of basis formula (2.7.4). Thus, at each point of
M −W we deﬁne the matrix of the Coulomb ﬁeld F = F(x1, x2, x3, x4) of
(α, m, e) relative to a rest frame for (α, m, e) to be
[F a
b] = e
⎡
⎢⎢⎣
0
0
0
x1/r3
0
0
0
x2/r3
0
0
0
x3/r3
x1/r3
x2/r3
x3/r3
0
⎤
⎥⎥⎦,
(2.7.24)
where r3 = ((x1)2 + (x2)2 + (x3)2)3/2. Thus,
⇀
B =
⇀
0 and
⇀
E =
e
r3
⇀r , where
⇀r = x1e1 + x2e2 + x3e3. Thus, |
⇀
E|2 = ( e2
r6 )
⇀r ·
⇀r = e2
r4 so |
⇀
E| = |e|
r2 . Any two
bases {ea} and {ˆea} with W = Span{e4} are related by a rotation in R (by
Lemma 1.3.4). We ask the reader to show that our deﬁnition of the Coulomb
ﬁeld is invariant under rotations and so the ﬁeld is well-deﬁned.
Exercise 2.7.11 Suppose R = [Rab]a,b=1,2,3,4 ∈R is a rotation and ˆxa =
Rabxb, a = 1, 2, 3, 4. Show that ˆr2 = (ˆx1)2 + (ˆx2)2 + (ˆx3)2 = r2 and that
the matrix [ ˆF ab] = R [F ab] R−1 of the Coulomb ﬁeld (2.7.24) in the hatted
coordinate system is
e
⎡
⎢⎢⎣
0
0
0
ˆx1/ˆr3
0
0
0
ˆx2/ˆr3
0
0
0
ˆx3/ˆr3
ˆx1/ˆr3
ˆx2/ˆr3
ˆx3/ˆr3
0
⎤
⎥⎥⎦.
To justify referring to the Coulomb ﬁeld as an electromagnetic ﬁeld we must,
of course, observe that it is smooth on the region M−W and verify Maxwell’s
equations (2.7.9) and (2.7.15). Since (div F)b = ηbβF αβ,α we obtain, from
(2.7.24), (div F)i = ηβiF αβ,α = F αi,α = F 1i,1 + F 2i,2 + F 3i,3 + F 4i,4 =
0 + 0 + 0 + 0 = 0. Moreover,
(div F)4 = ηβ4F α
β,α = −F α
4,α
= −e
* ∂
∂x1
x1
r3

+
∂
∂x2
x2
r3

+
∂
∂x3
x3
r3

+ 0
+
= −e
r6
*
r3 −x1

3r2 ∂r
∂x1

+ r3 −x2

3r2 ∂r
∂x2

+ r3 −x3

3r2 ∂r
∂x3
+
= −e
r6
*
3r3 −x1

3r2
 x1
r

−x2

3r2
x2
r

−x3

3r2
 x3
r
+
= −e
r6 [3r3 −3r((x1)2 + (x2)2 + (x3)2)]
= −e
r6 [3r3 −3r3] = 0.

2.7 Variable Electromagnetic Fields
125
Next observe that, from (2.7.24) and (2.7.14) we obtain
[Fab] = e
⎡
⎢⎢⎣
0
0
0
x1/r3
0
0
0
x2/r3
0
0
0
x3/r3
−x1/r3
−x2/r3
−x3/r3
0
⎤
⎥⎥⎦.
Thus, (2.7.15) is automatically satisﬁed if all of a, b and c are in {1, 2, 3}. The
remaining possibilities are all easily checked one-by-one, e.g., if a = 1, b = 2
and c = 4 we obtain
F12, 4 + F24, 1 + F41, 2 =
∂
∂x4 (0) +
∂
∂x1
x2
r3

+
∂
∂x2

−x1
r3

= 0 + x2

−3r−4
x1
r

+ x1

3r−4
x2
r

= 0.
Exercise 2.7.12 Calculate the matrix of the energy-momentum transfor-
mation (2.5.1) for the Coulomb ﬁeld (2.7.24) in its rest frames and show, in
particular, that T 44 = −
e2
8πr4 .
Recalling that −T 44 is interpreted as the energy density of the electromag-
netic ﬁeld F as measured in the given frame of reference, we seem forced to
conclude from Exercise 2.7.12 that the total energy contained in a sphere of
radius R > 0 about a point charge (which would be obtained by integrating
the energy density over the sphere) is
 2π
0
 π
0
 R
0
e2
8πr4 r2 sin φ dr dφ dθ = e2
2
 R
0
1
r2 dr
and this is an improper integral which diverges. The energy contained in such
a sphere would seem to be inﬁnite. But then (1.8.6) would suggest an inﬁnite
mass for the charge in its rest frames. This is, of course, absurd since ﬁnite
applied forces are found to produce nonzero accelerations of point charges.
Although classical electromagnetic theory is quite beautiful and enormously
successful in predicting the behavior of physical systems there are, as this
calculation indicates, severe logical diﬃculties at the very foundations of the
subject and, even today, these have not been resolved to everyone’s satisfac-
tion (see [Par] for more on this).
As an application we wish to calculate the ﬁeld of a uniformly moving
charge. Special relativity oﬀers a particularly elegant solution to this problem
since, according to the Relativity Principle, it matters not at all whether we
view the charge as moving relative to a “ﬁxed” frame of reference or the
frame as moving relative to a “stationary” charge. Thus, in eﬀect, we need
only transform the Coulomb ﬁeld to a new reference frame, moving relative to
the rest frame of the charge. More speciﬁcally, we wish to calculate the ﬁeld

126
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
due to a charge moving uniformly in a straight line with speed β relative
to some admissible frame ˆS at the instant the charge passes through that
frame’s spatial origin. We may clearly assume, without loss of generality, that
the motion is along the negative ˆx1-axis and that the charge passes through
(ˆx1, ˆx2, ˆx3) = (0, 0, 0) at ˆx4 = 0. If S is the frame in which the charge is at rest
we need only transform the Coulomb ﬁeld to ˆS with a boost Λ(β) and evaluate
at x4 = ˆx4 = 0. The Coulomb ﬁeld in S has Ei = e(xi/r3), i = 1, 2, 3, and
Bi = 0, i = 1, 2, 3, so, from Exercise 2.2.1,
ˆE1 = e
x1
r3

,
ˆE2 = eγ
x2
r3

,
ˆE2 = eγ
x3
r3

,
ˆB1 = 0,
ˆB2 = eβγ
x3
r3

,
ˆB3 = −eβγ
x2
r3

.
We wish to express these in terms of measurements made in ˆS. Setting ˆx4 = 0
in (1.3.29) gives x1 = γˆx1, x2 = ˆx2 and x3 = ˆx3 so that r2 = (x1)2 + (x2)2 +
(x3)2 = γ2(ˆx1)2 + (ˆx2)2 + (ˆx3)2, which we now denote ˜r2. Thus,
ˆE1 = eγ(ˆx1/˜r3),
ˆE2 = eγ(ˆx2˜r3),
ˆE3 = eγ(ˆx3/˜r3),
ˆB1 = 0,
ˆB2 = eβγ(ˆx3/˜r3),
ˆB3 = −eβγ(ˆx2/˜r3),
so
⇀
ˆE = eγ
˜r3

ˆx1ˆe1 + ˆx2ˆe2 + ˆx3ˆe3

= eγ
˜r3
⇀
ˆr
and
⇀
ˆB = eγ
˜r3

0 · ˆe1 + βˆx3ˆe2 −βˆx2ˆe3

= eγ
˜r3

βˆx3ˆe2 −βˆx2ˆe3

= eγ
˜r3

ˆe1
ˆe2
ˆe3
−β
0
0
ˆx1
ˆx2
ˆx3

= eγ
˜r3

β(−ˆe1) ×
⇀
ˆr

= eγ
˜r3
⇀
ˆu ×
⇀
ˆr

.
Observe that, in the nonrelativistic limit (γ ≈1) we obtain
⇀
ˆE ≈e
ˆr3
⇀
ˆr
(γ ≈1)
and
⇀
ˆB ≈e
ˆr3
⇀
ˆu ×
⇀
ˆr

(γ ≈1).

2.7 Variable Electromagnetic Fields
127
The ﬁrst of these equations asserts that the ﬁeld of a slowly moving charge
is approximately the Coulomb ﬁeld, whereas the second is called the Biot-
Savart Law.
Observe that the Coulomb ﬁeld is certainly regular at each point of M−W
since |
⇀
B|2−|
⇀
E|2 = 0−|e|
r2 = −|e|
r2 which is nonzero. As a nontrivial example of
an electromagnetic ﬁeld that is null we consider next what are called “simple,
plane electromagnetic waves”.
Let K : M →M denote some ﬁxed, nonzero, skew-symmetric linear
transformation on M and S : M →R a smooth, nonconstant real-valued
function on M. Deﬁne, for each x ∈M, a linear transformation F(x) :
M →M by F(x) = S(x)K. Then the assignment x
F
−→F(x) is obviously
smooth and one could determine necessary and suﬃcient conditions on S
and K to ensure that F satisﬁes Maxwell’s equations and so represents an
electromagnetic ﬁeld. We limit our attention to a special case. For this we
begin with a smooth, nonconstant function P : R →R and a ﬁxed, nonzero
vector k ∈M. Now take S(x) = P(k · x) so that
F(x) = P(k · x)K.
(2.7.25)
Observe that F takes the same value for all x ∈M for which k · x is a con-
stant, i.e., F is constant on the 3-dimensional hyperplanes {x ∈M : k · x =
r0} for some real constant r0. We now set about determining conditions on
P, k and K which ensure that (2.7.25) deﬁnes an electromagnetic ﬁeld on M.
Fix an admissible basis {ea}4
a=1. Let k = kaea and x = xaea and suppose
the matrix of K relative to this basis is [Kab]. Then F ab = P(k · x)Kab =
P(ηαβ kα xβ)Kab. First we consider the equation div F = 0. Now, (div F)i =
F αi,α, i = 1, 2, 3 and (div F)4 = −F α4,α. But
F ab,c =
∂
∂xc (P(k · x)Kab)
= P ′(k · x) ∂
∂xc (k · x)Kab
so
F a
b,i = P ′(k · x)kiKa
b,
i = 1, 2, 3,
and
F a
b,4 = −P ′(k · x)k4Ka
b.
Now, for i = 1, 2, 3,
(div F)i = F 1i,1 + F 2i,2 + F 3i,3 + F 4i,4
= P ′(k · x)k1K1
i + P ′(k · x)k2K2
i + P ′(k · x)k3K3
i −P ′(k · x)k4K4
i
= P ′(k · x)

k1K1i + k2K2i + k3K3i −k4K4i

.

128
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
But P ′(k · x) is not identically zero since P is not constant so (div F)i = 0
implies
k1K1
i + k2K2
i + k3K3
i −k4K4
i = 0,
i = 1, 2, 3,
that is,
ηabkaKbi = 0,
i = 1, 2, 3.
Exercise 2.7.13 Show that (div F)4 = 0 requires that ηabkaKb4 = 0.
Thus, div F = 0 for an F given by (2.7.25) becomes
ηabkaKb
c = 0,
c = 1, 2, 3, 4.
(2.7.26)
Next we consider (2.7.15). For this we observe that [Fab] = [P(k · x)Kab] so
Fab,c =
∂
∂xc (P(k · x)Kab) = P ′(k · x) ∂
∂xc (k · x)Kab and therefore
Fab, i = P ′(k · x)kiKab
and
Fab, 4 = −P(k · x)k4Kab.
Thus, Fab, c + Fbc, a + Fca, b = 0 implies
P ′(k · x)
*
Kab
∂
∂xc (k · x) + Kbc
∂
∂xa (k · x) + Kca
∂
∂xb (k · x)
+
= 0.
Again, P ′(k · x) ̸≡0 so the expression in brackets must be zero, i.e.,
Kab
∂
∂xc (k · x) + Kbc
∂
∂xa (k · x) + Kca
∂
∂xb (k · x) = 0.
If a, b and c are chosen from {1, 2, 3} this becomes
Kab kc + Kbc ka + Kca kb = 0,
a, b, c = 1, 2, 3.
(2.7.27)
If any of a, b or c is 4, then the terms with a k4 have a minus sign. This, and
(2.7.26) also, become easier to write if we introduce the notation
kb = ηabka,
b = 1, 2, 3, 4.
Thus, ki = ki for i = 1, 2, 3, but k4 = −k4. Now (2.7.26), (2.7.27) and the
equation corresponding to (2.7.27) when a, b or c is 4 can be written
kbKbc = 0,
c = 1, 2, 3, 4,
(2.7.28)
and
Kab kc + Kbc ka + Kca kb = 0,
a, b, c = 1, 2, 3, 4,
(2.7.29)
and we have proved:

2.7 Variable Electromagnetic Fields
129
Theorem 2.7.1 Let K : M →M be a nonzero, skew-symmetric linear
transformation of M, k a nonzero vector in M and P : R →R a smooth,
nonconstant function. Then F(x) = P(k · x)K deﬁnes a smooth assignment
of a skew-symmetric linear transformation to each x ∈M and satisﬁes
Maxwell’s equations if and only if (2.7.28) and (2.7.29) are satisﬁed.
Any F(x) of the type described in Theorem 2.7.1 for which (2.7.28) and
(2.7.29) are satisﬁed is therefore an electromagnetic ﬁeld and is called a simple
plane electromagnetic wave. We have already observed that such ﬁelds are
constant on hyperplanes of the form
k1x1 + k2x2 + k3x3 −k4x4 = r0
(2.7.30)
and we now investigate some of their other characteristics. First observe that
if x and x0 are two points in the hyperplane, then the displacement vector
x −x0 between them is orthogonal to k since (x −x0) · k = x · k −x0 · k =
r0 −r0 = 0. Thus, k is the normal vector to these hyperplanes. We show next
that k is necessarily null. Begin with (2.7.29). Multiply through by kc and
sum as indicated.
Kabkc kc + Kbc ka kc + Kcakbkc = 0,
a, b = 1, 2, 3, 4.
Thus,
Kab(k · k) + (Kbckc)ka + (Kcakc)kb = 0,
a, b = 1, 2, 3, 4.
(2.7.31)
But now observe that, by (2.7.28),
0 = Kb
ckb = ηbβKβcηαbkα
= (ηβbηαb)Kβckα = δβ
αKβckα
= Kαckα = Kbckb = −Kbckc.
Thus, Kbckc = 0 = Kcakc, so (2.7.31) gives Kab(k · k) = 0, for all a, b =
1, 2, 3, 4. But for some choice of a and b, Kab ̸= 0 so
k · k = 0
and so k is null.
Next we show that a simple plane electromagnetic wave F(x) = P(k ·x)K
is null at each point x. Indeed, suppose x0 ∈M and F(x0) = P(k · x0)K
is regular (and, in particular, nonzero). Then P(k · x0) ̸= 0 so K must be
regular (compute
⇀
E ·
⇀
B and |
⇀
B|2 −|
⇀
E|2). Relative to a canonical basis for K
we have

130
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
[Kab] =
⎡
⎢⎢⎣
0
K12
0
0
K21
0
0
0
0
0
0
K34
0
0
K43
0
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
δ
0
0
−δ
0
0
0
0
0
0
ϵ
0
0
ϵ
0
⎤
⎥⎥⎦.
We write out (2.7.28) for c = 1, 2, 3 and 4:
c = 1 :
kbKb1 = 0 = k2K21 = −δk2,
c = 2 :
kbKb
2 = 0 = k1K1
2 = δk1,
c = 3 :
kbKb3 = 0 = k4K43 = ϵk4,
c = 4 :
kbKb4 = 0 = k3K34 = ϵk3.
Now, k is null so k4 ̸= 0 and therefore ϵ = 0. Thus, δ ̸= 0 so k1 = k2 = 0.
Next we write out (2.7.29) with a = 1, b = 2 and c = 3:
K12k3 + K23k1 + K31k2 = 0,
K12k3 = 0,
δk3 = 0.
But δ = 0 would imply K = 0 and k3 = 0 would imply k4 = 0 and so k = 0.
Either is a contradiction so F must be null at each point.
Next we tie these last two bits of information together and show that the
null vector k is actually in the principal null direction of the null transforma-
tion K. We select a canonical basis for K so that
[Ka
b] =
⎡
⎢⎢⎣
0
0
0
0
0
0
α
0
0
−α
0
α
0
0
α
0
⎤
⎥⎥⎦
(α ̸= 0).
Now we write out (2.7.28) for c = 2 and 3 (c = 1 contains no information
and c = 4 is redundant):
c = 2 :
kbKb2 = 0 = −α k3 =⇒k3 = 0,
c = 3 :
kbKb3 = 0 = α k2 + α k4 =⇒k4 = −k2.
Thus, k3 = 0 and k4 = k2 so k null implies k1 = 0, i.e., k = k2(e2 + e4)
in canonical coordinates. But e2 + e4 is in the principal null direction of K
(Exercise 2.4.8) so we have proved half of the following theorem.
Theorem 2.7.2 Let K : M →M be a nonzero, skew-symmetric linear
transformation of M, k a nonzero vector in M and P : R →R a smooth
nonconstant function. Then F(x) = P(k · x)K deﬁnes a simple plane elec-
tromagnetic wave (i.e., satisﬁes Maxwell’s equations (2.7.28) and (2.7.29))
if and only if K is null and k is in the principal null direction of K.

2.7 Variable Electromagnetic Fields
131
Proof:
We have already proved the necessity. For the suﬃciency we assume
K is null and k is in its principal null direction. Relative to canonical co-
ordinates, the only nonzero entries in [Kab] and [Kab] are K23 = K34 =
K43 = −K32 = α and K23 = K34 = −K43 = −K32 = α. Moreover, k is
a multiple of e2 + e4, say, k = m(e2 + e4) so k1 = k3 = k1 = k3 = 0 and
k2 = k4 = k2 = −k4 = m.
Exercise 2.7.14 Verify (2.7.28) and (2.7.29).
■
Thus, we can manufacture simple plane electromagnetic waves by begin-
ning with a nonzero null K : M →M, ﬁnding a nonzero null vector k in the
principal null direction of K, selecting any smooth, non-constant P : R →R
and setting F(x) = P(k · x)K. In fact, it is even easier than this for, as we
now show, given an arbitrary nonzero null vector k we can produce a nonzero
null K : M →M which has k as a principal null direction. To see this, select
a nonzero vector l in Span{k}⊥and set K = k ∧l (see Exercise 2.4.7). Thus,
for every v ∈M, Kv = (k ∧l)v = k(l · v) −l(k · v).
Exercise 2.7.15 Show that, relative to an arbitrary admissible basis
{ea}, Kab = kalb −lakb and Kab = kalb −lakb.
Now one easily veriﬁes (2.7.28) and (2.7.29). Indeed, kbKbc = kb(kblc −lbkc) =
(kbkb)lc −(kblb)kc = (k · k)lc −(k · l)kc = 0 · lc −0 · kc = 0 since k is null and
l ∈Span{k}⊥.
Exercise 2.7.16 Verify (2.7.29).
Since K is obviously skew-symmetric we may select an arbitrary smooth
nonconstant P : R →R and be assured that F(x) = P(k · x)K represents
a simple plane electromagnetic wave. Most choices of P : R →R, of course,
yield physically unrealizable solutions F. One particular choice that is im-
portant not only because it gives rise to an observable ﬁeld, but also because,
mathematically, many electromagnetic waves can be regarded (via Fourier
analysis) as superpositions of such waves, is
P(t) = sin nt,
where n is a positive integer. Thus, we begin with an arbitrary nonzero, null,
skew-symmetric K : M →M and let {ea} be a canonical basis for K. Then
k = e2 + e4 is along the principal null direction of K so
F(x) = sin(nk · x)K
= sin(n(e2 + e4) · x)K
= sin(n(x2 −x4))K

132
2 Skew-Symmetric Linear Transformations and Electromagnetic Fields
deﬁnes a simple plane electromagnetic wave. For some nonzero α in R,
[F a
b] =
⎡
⎢⎢⎣
0
0
0
0
0
0
α sin(n(x2 −x4))
0
0
−α sin(n(x2 −x4))
0
α sin(n(x2 −x4))
0
0
α sin(n(x2 −x4))
0
⎤
⎥⎥⎦.
Thus,
⇀
E = α sin(n(x2 −x4))e3 and
⇀
B = α sin(n(x2 −x4))e1. F is constant on
the 3-dimensional hyperplanes x2 −x4 = r0. At each ﬁxed instant x4 = x4
0
an observer in the canonical reference frame sees his instantaneous 3-space
layered with planes x2 = x4
0 + r0 on which F is constant (see Figure 2.7.1).
Next, ﬁx not x4, but x2 = x2
0 so that
⇀
E = α sin

n

x2
0 −x4
e3 and
⇀
B =
α sin

n

x2
0 −x4
e1. Thus, at a given location,
⇀
E and
⇀
B will always be in
the same directions (except for reversals when sin changes sign), but the
intensities vary periodically with time.
Fig. 2.7.1
Exercise 2.7.17 Show that, for any electromagnetic ﬁeld, each of the func-
tions Fab satisﬁes the wave equation
∂2Fab
(∂x1)2 + ∂2Fab
(∂x2)2 + ∂2Fab
(∂x3)2 = ∂2Fab
(∂x4)2 .
(2.7.32)

2.7 Variable Electromagnetic Fields
133
Hints: Diﬀerentiate (2.7.15) with respect to xμ, multiply by ημc and sum as
indicated. Then use (2.7.9) to show that two of the three terms must vanish.
Of course, not everything that satisﬁes a wave equation is “wavelike”
(e.g., constant ﬁelds satisfy (2.7.32)). However, historically the result of
Exercise 2.7.17 ﬁrst suggested to Maxwell that there might exist electromag-
netic ﬁelds with wavelike characteristics (and which propagate with speed 1).
Our last examples are obviously of this sort and the electromagnetic theory
of light is based on the study of such solutions to Maxwell’s equations.


Chapter 3
The Theory of Spinors
3.1 Representations of the Lorentz Group
The concept of a “spinor” emerged from the work of E. Cartan on the repre-
sentations of simple Lie algebras. However, it was not until Dirac employed a
special case in the construction of his relativistically invariant equation for the
electron with “spin” that the notion acquired its present name or its current
stature in mathematical physics. In this chapter we present an elementary
introduction to the algebraic theory of spinors in Minkowski spacetime and
illustrate its utility in special relativity by recasting in spinor form much
of what we have learned about the structure of the electromagnetic ﬁeld in
Chapter 2. We shall not stray into quantum mechanics and, in particular,
will not discuss the Dirac equation (for this, see the encyclopedic monograph
[PR] of Penrose and Rindler). Since it is our belief that an intuitive appreci-
ation of the notion of a spinor is best acquired by approaching them by way
of group representations, we have devoted this ﬁrst section to an introduction
to these ideas and how they arise in special relativity. Since this section is
primarily motivational, we have not felt compelled to prove everything we say
and have, at several points, contented ourselves with a reference to a proof
in the literature.
A vector v in M (e.g., a world momentum) is an object that is decribed in
each admissible frame of reference by four numbers (components) with the
property that if v = vaea = ˆvaˆea and [Λab] is the Lorentz transformation
relating {ea} and {ˆea} (i.e., eb = Λabˆea), then the components va and ˆva are
related by the “transformation law”
ˆva = Λabvb, a = 1, 2, 3, 4.
(3.1.1)
A linear transformation L : M →M (e.g., an electromagnetic ﬁeld) is an-
other type of object that is again described in each admissible basis by a set
of numbers (the entries in its matrix relative to that basis) with the property
, 
: An Introduction 
, Applied Mathematical Sciences 92,
G.L. Naber The Geometry of Minkowski Spacetime
to the Mathematics 
of the Special Theory of Relativity
DOI 10.1007/978-1-4419-7838-7_ , © Springer Science+Business Media, LLC 2012
135
3

136
3 The Theory of Spinors
that if [Lab] and [ˆLab] are the matrices of L in {ea} and {ˆea}, then
ˆLab = ΛaαΛb
βLαβ,
a, b = 1, 2, 3, 4,
(3.1.2)
where

Λa
b
is the inverse of [Λab], i.e., ΛaαΛb
α = Λα
aΛαb = δa
b ((3.1.2) is just
the familiar change of basis formula). As we found in Chapter 2, it is often
convenient to associate with such a linear transformation a corresponding
bilinear form ˜L : M × M →R deﬁned by ˜L(u, v) = u · Lv. Again, ˜L is
described in each admissible basis by its set of components Lab = ˜L(ea, eb)
and components in diﬀerent bases are related by a speciﬁc transformation law:
ˆLab = Λa
αΛb
βLαβ,
a, b = 1, 2, 3, 4.
(3.1.3)
Such bilinear forms can, of course, arise naturally of their own accord without
reference to any linear transformation. The Lorentz inner product is itself
such an example. Indeed, if we deﬁne g : M × M →R by
g(u, v) = u · v,
then, in all admissible bases, gab = g(ea, eb) = ea · eb = ηab = g(ˆea, ˆeb) = ˆgab.
In this very special case the components are the same in all admissible bases,
but, nevertheless, (1.2.14) shows that the same transformation law is satisﬁed:
ˆgab = Λa
αΛb
βgαβ,
a, b = 1, 2, 3, 4.
The point of all of this is that examples of this sort abound in geometry
and physics. In each case one has under consideration an “object” of geomet-
rical or physical signiﬁcance (an inner product, a world momentum vector,
an electromagnetic ﬁeld transformation, etc.) which is described in each ad-
missible basis by a set of numerical “components” and with the property that
components in diﬀerent bases are related by a speciﬁc linear transformation
law that depends on the Lorentz transformation relating the two bases. Dif-
ferent “types” of objects are distinguished by their number of components
in each basis and by the precise form of the transformation law. Classically,
such objects were called “world tensors” or “4-tensors” (we give the precise
deﬁnition shortly). World tensors are well suited to the task of expressing
“Lorentz invariant” relationships since, for example, a statement which as-
serts the equality, in some basis, of the components of two world tensors of
the same type necessarily implies that their components in any other basis
must also be equal (since the “transformation law” to the new basis compo-
nents is the same for both). This is entirely analogous to the use of 3-vectors
in classical physics and Euclidean geometry to express relationships that are
true in all Cartesian coordinate systems if they are true in any one. For
many years it was tacitly assumed that any valid Lorentz invariant state-
ment (in particular, any law of relativistic physics) should be expressible as
a world tensor equation. Dirac put an end to this in 1928 when he proposed

3.1 Representations of the Lorentz Group
137
a law (equation) to describe the relativistic electron with spin that was man-
ifestly Lorentz invariant, but not expressed in terms of world tensors. To
understand precisely what world tensors are and why they did not suﬃce for
Dirac’s purposes we must take a more careful look at “transformation laws”
in general.
Observe that if v is a vector with components va and ˆva in two admis-
sible bases and if we write these components as column vectors, then the
transformation law (3.1.1) can be written as a matrix product:
⎡
⎢⎢⎣
ˆv1
ˆv2
ˆv3
ˆv4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
Λ11
Λ12
Λ13
Λ14
Λ21
Λ22
Λ23
Λ24
Λ31
Λ32
Λ33
Λ34
Λ41
Λ42
Λ43
Λ44
⎤
⎥⎥⎦
⎡
⎢⎢⎣
v1
v2
v3
v4
⎤
⎥⎥⎦.
By virtue of their linearity the same is true of (3.1.2) and (3.1.3). For example,
writing the Lab and ˆLa
b as column matrices, (3.1.2) can be written in terms
of the 16 × 16 matrix

ΛaαΛb
β
as
⎡
⎢⎢⎢⎣
ˆL11
ˆL12
...
ˆL44
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
Λ11Λ1
1
Λ11Λ1
2
· · · Λ14Λ1
4
Λ11Λ2
1
Λ11Λ2
2
· · · Λ14Λ2
4
...
...
...
Λ41Λ4
1
Λ41Λ4
2
· · · Λ44Λ4
4
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
L11
L12
...
L44
⎤
⎥⎥⎥⎦.
Exercise 3.1.1 Write (3.1.3) as a matrix product.
In this way one can think of a transformation law as a rule which assigns
to each Λ ∈L a certain matrix DΛ which transforms components in one
basis {ea} to those in another {ˆea}, related to {ea} by Λ. Observe that, for
each of the examples we have considered thus far, these rules Λ →DΛ carry
the identity matrix in L onto the corresponding identity “transformation
matrix” (as is only fair since, if the basis is not changed, the components
of the “object” should not change). Moreover, if Λ1 and Λ2 are in L and
Λ1Λ2 is their product (still in L), then Λ1Λ2 →DΛ1Λ2 = DΛ1 DΛ2 (this is
obvious for (3.1.1) since DΛ = Λ and follows for (3.1.2) and (3.1.3) either
from a rather dreary calculation or from standard facts about change of
basis matrices). This also makes sense, of course, since the components in
any basis are uniquely determined so that changing components from basis
#1 to basis #2 and then from basis #2 to basis #3 should give the same
result as changing directly from basis #1 to basis #3. In order to say all of
this more eﬃciently we introduce some terminology.
Let n be a positive integer. A matrix group of order n is a collection G of
n × n invertible matrices that is closed under the formation of products and
inverses (i.e., if G, G1, and G2 are in G, then G−1 and G1G2 are also in G).
We have seen numerous examples, e.g., the Lorentz group L is a matrix group
of order 4, whereas SL(2, C) is a matrix group of order 2. The collection of

138
3 The Theory of Spinors
all n × n invertible matrices (with either real or complex entries) clearly also
constitutes a matrix group and is called the general linear group of order n
and written either GL(n, R) or GL(n, C) depending on whether the entries are
real or complex. Observe that a matrix group of order n necessarily contains
the n × n identity matrix In = I since, for any G in the group, GG−1 = I.
If G is a matrix group and G′ is a subset of G, then G′ is called a subgroup
of G if it is closed under the formation of products and inverses, i.e., if it is
itself a matrix group. For example, the set R of rotations in L is a subgroup
of L (Exercise 1.3.7), SU 2 is a subgroup of SL(2, C) (Exercise 1.7.6) and,
of course, any matrix group is a subgroup of some general linear group. A
homomorphism from one matrix group G to another H is a map D : G →H
that preserves matrix multiplication, i.e., satisﬁes D(G1G2) = D(G1)D(G2)
whenever G1 and G2 are in G. As is customary we shall often write the image
of G under D as DG rather than D(G) and denote the action of D on G by
G →DG. If G has order n and H has order m, then D necessarily carries
In onto Im since D(In) = D(InIn) = D(In)D(In) so that D(In)(D(In))−1 =
D(In)D(In)(D(In))−1 and therefore Im = D(In)Im = D(In).
Exercise 3.1.2 Show that a homomorphism D : G →H preserves inverses,
i.e., that D(G−1) = (D(G))−1 for all G in G.
Exercise 3.1.3 Show that if D : G →H is a homomorphism, then its image
D(G) = {D(G) : G ∈G} is a subgroup of H.
A homomorphism of one matrix group G into another H is also called a (ﬁnite
dimensional) representation of G. For reasons that will become clear shortly,
we will be particularly concerned with the representations of L and SL(2, C).
If H is of order m and Vm is an m-dimensional vector space (over C if the
entries in H are complex, but otherwise arbitrary), then the elements of H
can, by selecting a basis for Vm, be regarded as linear transformations or,
equivalently, as change of basis matrices on Vm. In this case the elements of
Vm are called carriers of the representation. M itself may be regarded as a
space of carriers for the representation D : L →GL(4, R) of L correspond-
ing to (3.1.1), i.e., the identity representation Λ →DΛ = Λ. Similarly, the
vector space of linear transformations from M to M and that of bilinear
forms on M act as carriers for the representations [Λab] →

ΛaαΛb
β
and
[Λab] →

Λa
αΛb
β
corresponding to (3.1.2) and (3.1.3), respectively. It is
rather inconvenient, however, to have diﬀerent representations of L acting on
carriers of such diverse type (vectors, linear transformations, bilinear forms)
and we shall see presently that this can be avoided.
The picture we see emerging here from these few examples is really quite
general. Suppose that we have under consideration some geometrical or phys-
ical quantity that is described in each admissible basis/frame by m uniquely
determined numbers and suppose furthermore that these sets of numbers cor-
responding to diﬀerent bases are related by linear transformation laws that
depend on the Lorentz transformation relating the bases (there are objects

3.1 Representations of the Lorentz Group
139
of interest that do not satisfy this linearity requirement, but we shall have no
occasion to consider them). In each basis we may write the m numbers that
describe our object as a column matrix T = col[T1 · · · Tm]. Then, associated
with every Λ ∈L there will be an m×m matrix DΛ whose entries depend on
those of Λ and with the property that ˆT = DΛT if {ea} and {ˆea} are related
by Λ. Since the numbers describing the object in each basis are uniquely de-
termined, the association Λ →DΛ must carry the identity onto the identity
and satisfy Λ1Λ2 →DΛ1Λ2 = DΛ1DΛ2, i.e., must be a representation of the
Lorentz group. Thus, the representations of the Lorentz group are precisely
the (linear) transformation laws relating the components of physical and ge-
ometrical objects of interest in Minkowski spacetime. The objects themselves
are the carriers of these representations. Of course, an m × m matrix can be
thought of as acting on any m-dimensional vector space so the precise math-
ematical nature of these carriers is, to a large extent, arbitrary. We shall ﬁnd
next, however, that one particularly natural choice recommends itself.
We denote by M∗the dual of the vector space M, i.e., the set of all real-
valued linear functionals on M. Thus, M∗= {f : M →R : f(αu + βv) =
αf(u) + βf(v) ∀u, v ∈M and α, β ∈R}. The elements of M∗are called
covectors. The vector space structure of M∗is deﬁned in the obvious way,
i.e., if f and g are in M∗and α and β are in R, then αf + βg is deﬁned
by (αf + βg)(u) = αf(u) + βg(u). If {ea} is an admissible basis for M, its
dual basis {ea} for M∗is deﬁned by the requirement that ea(eb) = δa
b for
a, b = 1, 2, 3, 4. Let {ˆea} be another admissible basis for M and {ˆea} its dual
basis. If Λ is the element of L relating {ea} and {ˆea}, then
ˆea = Λa
αeα,
a = 1, 2, 3, 4,
(3.1.4)
and
ˆea = Λa
αeα,
a = 1, 2, 3, 4.
(3.1.5)
We prove (3.1.5) by showing that the left- and right-hand sides agree on
the basis {ˆeb} ((3.1.4) is just (1.2.15)). Of course, ˆea(ˆeb) = δa
b . But also
Λaαeα(ˆeb) = Λaαeα 
Λb
βeβ

= ΛaαΛb
βeα(eβ) = ΛaαΛb
βδα
β = ΛaαΛb
α = δa
b
since [Λaα] and

Λb
β
are inverses.
Recall that each v ∈M gives rise, via the Lorentz inner product, to a
v∗∈M∗deﬁned by v∗(u) = v · u for all u ∈M. Moreover, if v = vaea, then
v∗= vaea, where va = ηaαvα since va = v∗(ea) = v·ea = (vαeα)·ea = vα(eα·
ea) = ηaαvα. Moreover, relative to another basis, v∗= ˆvaˆea = ˆva (Λaαeα) =
(Λaαˆva) eα so vα = Λaαˆva and, applying the inverse, ˆva = Λa
αvα.
With this we can show that all of the representations of L considered thus
far can, in a very natural way, be regarded as acting on vector spaces of
multilinear functionals (deﬁned shortly). Consider ﬁrst the collection T 0
2 of
bilinear forms L : M × M →R on M. If L, T ∈T 0
2 and α ∈R, then
the deﬁnitions (L + T )(u, v) = L(u, v) + T (u, v) and (αL)(u, v) = αL(u, v)
are easily seen to give T 0
2 the structure of a real vector space. For any two

140
3 The Theory of Spinors
elements f and g in M∗we deﬁne their tensor product f ⊗g : M × M →R
by f ⊗g(u, v) = f(u)g(v). Then f ⊗g ∈T 0
2 .
Exercise 3.1.4 Show that, if {ea} is the dual of an admissible basis, then
{ea ⊗eb : a, b = 1, 2, 3, 4} is a basis for T 0
2 and that, for any L ∈T 0
2 ,
L = L(ea, eb)ea ⊗eb = Labea ⊗eb.
(3.1.6)
Now, in another basis, L(ˆea, ˆeb) = L

Λa
αeα, Λb
βeβ

= Λa
αΛb
βL(eα, eβ) so
ˆLab = Λa
αΛb
βLαβ.
(3.1.7)
Thus, components relative to bases of the form {ea ⊗eb : a, b = 1, 2, 3, 4} for
T 0
2 transform under the representation [Λab] →

Λa
αΛb
β
of (3.1.3) and we
may therefore regard the bilinear forms in T 0
2 as the carriers of this represen-
tation. Elements of T 0
2 are called world tensors of contravariant rank 0 and
covariant rank 2 (we will discuss the terminology shortly).
Next we consider the representation [Λab] →

ΛaαΛb
β
of L appropriate to
(3.1.2). Let T 1
1 denote the set of all real-valued functions L : M∗× M →R
that are linear in each variable, i.e., satisfy L(αf + βg, u) = αL(f, u) +
βL(g, u) and L(f, αu + βv) = αL(f, u) + βL(f, v) whenever α, β ∈R, f, g ∈
M∗and u, v ∈M. The vector space structure of T 1
1 is deﬁned in the obvious
way: If L, T ∈T 1
1 and α, β ∈R, then αL + βT ∈T 1
1 is deﬁned by (αL +
βT)(f, u) = αL(f, u) + βT(f, u). For u ∈M and f ∈M∗we deﬁne u ⊗f :
M∗× M →R by u ⊗f (g, v) = g(u)f(v). Again, it is easy to see that
u ⊗f ∈T 1
1 , that {ea ⊗eb : a, b = 1, 2, 3, 4} is a basis for T 1
1 and that, for
any L in T 1
1 ,
L = L(ea, eb)ea ⊗eb = Labea ⊗eb.
(3.1.8)
In another basis, L(ˆea, ˆeb) = L

Λaαeα, Λb
βeβ

= ΛaαΛb
βL(eα, eβ) =
ΛaαΛb
βLαβ so
ˆLa b = ΛaαΛb
βLαβ.
(3.1.9)
Thus, components relative to bases of the form {ea ⊗eb : a, b = 1, 2, 3, 4}
transform under the representation [Λab] →

ΛaαΛb
β
of (3.1.2) so that the
elements of T 1
1 are a natural choice for the carriers of this representation. The
elements of T 1
1 are called world tensors of contravariant rank 1 and covariant
rank 1.
The appropriate generalization of these ideas should by now be clear. Let
r ≥0 and s ≥0 be integers. Denote by T r
s the set of all real-valued functions
deﬁned on
M∗× · · · × M∗
1
23
4
r factors
× M × · · · × M
1
23
4
s factors
that are linear in each variable separately (these are called multilinear
functionals). T r
s is made into a real vector space by the obvious pointwise

3.1 Representations of the Lorentz Group
141
deﬁnitions of addition and scalar multiplication. If u1, . . . , ur ∈M and
f1, . . . , fs ∈M∗one deﬁnes u1 ⊗· · · ⊗ur ⊗f1 ⊗· · · ⊗fs in T r
s by
u1 ⊗· · · ⊗ur ⊗f1 ⊗· · · ⊗fs(g1, . . . , gr, v1, . . . , vs)
= g1(u1) · · · gr(ur) · f1(v1) · · · fs(vs)
and ﬁnds that the set of ea1 ⊗· · ·⊗ear ⊗eb1 ⊗· · ·⊗ebs, a1, . . . , ar = 1, 2, 3, 4
and b1, . . . , bs = 1, 2, 3, 4, form a basis for T r
s . Moreover, if L ∈T r
s , then
L = L(ea1, . . . , ear, eb1, . . . , ebs)ea1 ⊗· · · ⊗ear ⊗eb1 ⊗· · · ⊗ebs
= La1···ar b1···bsea1 ⊗· · · ⊗ear ⊗eb1 ⊗· · · ⊗ebs.
(3.1.10)
Relative to another basis,
L(ˆea1, . . . , ˆear, ˆeb1, . . . , ˆebs)
= L

Λa1
α1eα1, . . . , Λar
αreαr, Λb1
β1eβ1, . . . , Λbs
βseβs

= Λa1
α1 · · · Λar
αrΛb1
β1 · · · Λbs
βsL(eα1, . . . , eαr, eβ1, . . . , eβs)
so
ˆLa1··· ar b1··· bs = Λa1
α1 · · · Λar
αrΛ β1
b1 · · · Λbs
βsLα1··· αr β1···βs.
(3.1.11)
The elements of T r
s are called world tensors (or 4-tensors) of contravariant
rank r and covariant rank s. “Contravariant rank r” refers to the r indices
a1, . . . , ar that are written as superscripts in the expression for the compo-
nents and which appear in the transformation law attached to an entry in Λ
(rather than Λ−1). Covariant indices are written as subscripts in the compo-
nents and transform under Λ−1. An element of T r
s has 4r+s components and
if these are written as a column matrix, then the transformation law (3.1.11)
can be written as a matrix product thus giving rise to an assignment
[Λa
b] →
,
Λa1α1 · · · Λar αrΛb1
β1 · · · Λbs
βs-
to each element of L of a 4r+s × 4r+s matrix which can be shown to be a
representation of L and is called the world tensor (or 4-tensor) representation
of contravariant rank r and covariant rank s. Notice that even the identity
representation of L corresponding to (3.1.1) is included in this scheme (with
r = 1 and s = 0). The carriers, however, are now viewed as linear functionals
on M∗, i.e., we are employing the standard isomorphism of M onto M∗∗
(x ∈M →x∗∗∈M∗∗deﬁned by x∗∗(f) = f(x) for all f ∈M∗). The
elements of T 1
0 are sometimes called contravariant vectors, whereas those of
T 0
1 are covariant vectors or covectors.
World tensors were introduced by Minkowski in 1908 as a language in
which to express Lorentz invariant relationships. Any assertion that two world

142
3 The Theory of Spinors
tensors L and T are equal would be checked in a given admissible basis/frame
by comparing their components La1··· ar b1··· bs and T a1··· ar b1··· bs in that basis
and, if these are indeed found to be equal in one basis, then the components
in any other basis must necessarily also be equal since they both transform
to the new basis under (3.1.11). World tensor equations are true in all admis-
sible frames if and only if they are true in any one admissible frame, i.e., they
are Lorentz invariant. World tensors were introduced, in analogy with the
3-vectors of classical mechanics, to serve as the basic “building blocks” from
which to construct the laws of relativistic (i.e., Lorentz invariant) physics. So
admirably suited were they to this task that it was not until attempts got
under way to reconcile the principles of relativistic and quantum mechanics
that it was found that there were not enough “building blocks”. The reason
for this can be traced to the fact that the underlying physically signiﬁcant
quantities in quantum mechanics (e.g., wave functions) are described by com-
plex numbers ψ, whereas the result of a speciﬁc measurement carried out on
a quantum mechanical system is a real number that depends only on quan-
tities of the form ψ ¯ψ and these last quantities are insensitive to changes in
sign, i.e., (−ψ)(−ψ) = ψ ¯ψ. Consequently, ψ and −ψ give rise to precisely the
same predictions as to the result of any experiment and so must represent the
same state of the system. As a result, transforming the state’s description in
one admissible frame to that in another (related to it by Λ) can be accom-
plished by either one of two matrices ±DΛ. As we shall see in Section 3.5 this
ambiguity in the sign is often an essential feature of the situation and cannot
be consistently removed by making one choice or the other. This fact leads
directly to the notion of what Penrose [PR] has called a “spinorial object”
and which we shall discuss in some detail in Appendix B. For the present we
will only take these remarks as motivation for introducing what are called
“two-valued representations” of the Lorentz group (intuitively, assignments
Λ →±DΛ of two component transformation matrices, diﬀering only by sign,
to each Λ ∈L).
In Section 1.7 we constructed a mapping of SL(2, C) onto L called the
spinor map which we now designate
Spin : SL(2, C) →L.
Spin was a homomorphism of the matrix group SL(2, C) onto the matrix
group L that mapped the unitary subgroup SU 2 of SL(2, C) onto the rota-
tion subgroup R of L and was precisely two-to-one, carrying ±G in SL(2, C)
onto the same element of L (which we denote either Spin(G) = Spin(−G) or
ΛG = Λ−G). Next we observe that any representation ˜D : L →H “lifts” to
a representation of SL(2, C). More precisely, we deﬁne D : SL(2, C) →H
by D =
˜D ◦Spin. Of course, D has the property that, for every G ∈
SL(2, C), D−G = ˜D(Spin(−G)) = ˜D(Spin(G)) = DG. Conversely, suppose

3.1 Representations of the Lorentz Group
143
D : SL(2, C) →H is a representation of SL(2, C) with the property that
D−G = DG for every G ∈SL(2, C). We deﬁne ˜D : L →H as follows:
Let Λ ∈L. Then there exists a G ∈SL(2, C) such that ΛG = Λ. Deﬁne
˜D(Λ) = ˜D(ΛG) = DG. Then ˜D is a representation of L since ˜D(Λ1Λ2) =
˜D(ΛG1ΛG2) = ˜D(ΛG1G2) = DG1G2 = DG1 DG2 = ˜D(Λ1) ˜D(Λ2). Thus, there
is a one-to-one correspondence between the representations of L and the rep-
resentations of SL(2, C) that satisfy D−G = DG for all G ∈SL(2, C).
Before proceeding with the discussion of those representations of SL(2, C)
for which D−G ̸= DG we introduce a few more deﬁnitions. Thus, we let G
and H be arbitrary matrix groups and D : G →H a representation of G.
If the order of H is m, we let Vm stand for any space of carriers for D. A
subspace S of Vm is said to be invariant under D if each DG, thought of as
a linear transformation of Vm, carries S into itself, i.e., satisﬁes DGS ⊆S.
For example, Vm itself and the trivial subspace {0} of Vm are obviously
invariant under any D. If {0} and Vm are the only subspaces of Vm that are
invariant under D, then D is said to be irreducible; otherwise, D is reducible.
It can be shown (see [GMS]) that all of the representations of SL(2, C) can
be constructed from those that are irreducible. Finally, two representations
D(1) : G →H1 and D(2) : G →H2, where H1 and H2 have the same order,
are said to be equivalent if there exists an invertible matrix P such that
D(2)
G = P −1D(1)
G P
for all G ∈G. This is clearly equivalent to the requirement that, if Vm is a
space of carriers for both D(1) and D(2), then there exist bases {v(1)
a } and
{v(2)
a } for Vm such that, for every G ∈G, the linear transformation whose
matrix relative to {v(1)
a } is D(1)
G
has matrix D(2)
G
relative to {v(2)
a }.
Theorem 3.1.1 (Schur’s Lemma) Let G and H be matrix groups of order
n and m respectively and D : G →H an irreducible representation of G. If
A is an m × m matrix which commutes with every DG, i.e., ADG = DGA
for every G ∈G, then A is a multiple of the identity matrix, i.e., A = λI for
some (in general, complex) number λ.
Proof:
We select a space Vm of carriers and regard A and all the DG as
linear transformations on Vm. Let S = ker A. Then S is a subspace of
Vm. For each s ∈S, As = 0 implies A(DGs) = DG(As) = DG(0) = 0 so
DGs ∈S, i.e., S is invariant under D. Since D is irreducible, either S = Vm
or S = {0}. If S = Vm, then A = 0 = 0 · I and we are done. If S = {0},
then A is invertible and so has a nonzero (complex) eigenvalue λ. Notice that
(A −λI)DG = ADG −(λI)DG = DGA −DG(λI) = DG(A −λI) so A −λI
commutes with every DG. The argument given above shows that A −λI is
either 0 or invertible. But λ is an eigenvalue of A so A −λI is not invertible
and therefore A −λI = 0 as required.
■

144
3 The Theory of Spinors
Corollary 3.1.2 Let G be a matrix group that contains −G for every G ∈G
and D : G →H an irreducible representation of G. Then
D−G = ±DG.
(3.1.12)
Proof:
−G = (−I)G so D−G = D(−I)G = D−IDG and it will suﬃce to
show that D−I = ±I. For any G′ ∈G, D−IDG′ = D(−I)G′ = DG′(−I) =
DG′D−I so D−I commutes with each DG′, G′ ∈G. By Schur’s Lemma,
D−I = λI for some λ. But D−ID−I = D(−I)(−I) = DI = I so (λI)(λI) =
λ2 I = I. Thus, λ2 = 1 so λ = ±1 and D−I = ±I.
■
Since SL(2, C) clearly contains −G for every G ∈SL(2, C), we ﬁnd that
every irreducible representation D of SL(2, C) satisﬁes either D−G = DG
or D−G = −DG. As we have seen, those of the ﬁrst type give representa-
tions of the Lorentz group. Although those that satisfy D−G = −DG cannot
legitimately be regarded as representations of L (not being single-valued),
it has become customary to refer to such a representation of SL(2, C) as a
two-valued representation of L and we shall adhere to the custom.
The problem of determining the ﬁnite-dimensional, irreducible represen-
tations of SL(2, C) is thus seen to be a matter of considerable interest in
mathematical physics. As it happens, these representations are well-known
and rather easy to describe. Moreover, such a description is well worth the ef-
fort required to produce it since it leads inevitably to the notion of a “spinor”,
which will be our major concern in this chapter.
In order to enumerate these representations of SL(2, C) it will be conve-
nient to reverse our usual procedure and specify ﬁrst a space of carriers and a
basis and then describe the linear transformations whose matrices relative to
this basis will constitute our representations. If m ≥0 and n ≥0 are integers
we denote by Pmn the vector space of all polynomials in z and ¯z with complex
coeﬃcients and of degree at most m in z and at most n in ¯z, i.e.,
Pmn = {p(z, ¯z) = p00 + p10z + p01¯z + p11z¯z + · · ·
+ pmnzm¯zn = prszr¯zs : prs∈C},
with the usual coeﬃcientwise addition and scalar multiplication, i.e., p(z, ¯z)+
q(z, ¯z) = [p00 + p10z + · · · + pmnzm¯zn] + [q00 + q10z + · · · + qmnzm¯zn] =
[p00 + q00] + [p10 + q10]z + · · · + [pmn + qmn]zm¯zn and αp(z, ¯z) = (αp00) +
(αp10)z + · · · +(αpmn)zm¯zn. The basis implicit here is {1, z, ¯z, z¯z, . . . , zm¯zn}
so dim Pmn = (m+1)(n+1). Now, for each G =
*
a
b
c
d
+
∈SL(2, C) we deﬁne
D( m
2 , n
2 )
G
: Pmn →Pmn by
D( m
2 , n
2 )
G
(p(z, ¯z)) = D( m
2 , n
2 )
G
(prszr¯zs) = (bz + d)m(¯b¯z + ¯d)np(w, ¯w),

3.1 Representations of the Lorentz Group
145
where
w = az + c
bz + d.
Then D( m
2 , n
2 )
G
is clearly linear in p(z, ¯z) and maps Pmn to Pmn. Although
algebraically a bit messy it is straightforward to show that D( m
2 , n
2 )
G
has the
properties required to determine a representation of SL(2, C). We leave the
manual labor to the reader.
Exercise 3.1.5 Show that D( m
2 , n
2 )
I
is the identity transformation on Pmn
and that if G1 and G2 are in SL(2, C), then
D( m
2 , n
2 )
G1G2
= D( m
2 , n
2 )
G1
◦D( m
2 , n
2 )
G2
.
Thus, the matrices of the linear transformations D( m
2 , n
2 )
G
relative to the basis
{1, z, ¯z, . . . , zm¯zn} for Pmn constitute a representation of SL(2, C) which we
also denote
G −→D( m
2 , n
2 )
G
and call the spinor representation of type (m, n). Although it is by no means
obvious the spinor representations are all irreducible and, in fact, exhaust all
of the ﬁnite-dimensional, irreducible representations of SL(2, C) (we refer the
interested reader to [GMS] for a proof of Theorem 3.1.3).
Theorem 3.1.3 For all m, n = 0, 1, 2, . . ., the spinor representation D( m
2 , n
2 )
of SL(2, C) is irreducible and every ﬁnite-dimensional irreducible representa-
tion of SL(2, C) is equivalent to some D( m
2 , n
2 ).
We consider a few speciﬁc examples. First suppose m = 1 and n = 0 : P10 =
{p(z, ¯z) = p00 + p10z : prs ∈C}. For G =
*a
b
c
d
+
∈SL(2, C),
D( 1
2 ,0)
G
(p(z, ¯z)) = (bz + d)1(¯b¯z + ¯d)0p(w, ¯w)
= (bz + d)

p00 + p10
az + c
bz + d

= (bz + d)p00 + (az + c)p10
= (cp10 + dp00) + (ap10 + bp00)z
= ˆp00 + ˆp10z,
where
*
ˆp10
ˆp00
+
=
*
a
b
c
d
+ *
p10
p00
+
.

146
3 The Theory of Spinors
Thus, the representation G →D( 1
2 ,0)
G
is given by
*a
b
c
d
+
−→D( 1
2 ,0)
*
a b
c d
+ =
*a
b
c
d
+
,
i.e., D( 1
2 ,0) is the identity representation of SL(2, C).
Exercise 3.1.6 Show in the same way that D(0, 1
2) is the conjugation rep-
resentation
*
a
b
c
d
+
−→D(0, 1
2)
*
a b
c d
+ =
*
¯a
¯b
¯c
¯d
+
.
Exercise 3.1.7 Show that D( 1
2 ,0) and D(0, 1
2) are not equivalent represen-
tations of SL(2, C), i.e., that there does not exist an invertible matrix P
such that P −1GP = ¯G for all G ∈SL(2, C). Hint: Let G =
*i 0
0 −i
+
and
P =
*
0 i
−i 0
+
. Show that P −1GP = ¯G and that P and its nonzero scalar mul-
tiples are the only matrices for which this is true. Now ﬁnd a G′ ∈SL(2, C)
for which P −1G′P ̸= G′.
Before working out another example we include a few more observations
about D( 1
2 ,0) and D(0, 1
2). First note that if G →DG is any representation
of SL(2, C), then the assignment G →

D−1
G
T =

DT
G
−1 of the trans-
posed inverse of DG to each G is also a representation of SL(2, C) since
I
→

D−1
I
T
= (I−1)T
= IT
= I and G1G2 →((DG1G2)−1)T
=
((DG1DG2)−1)T =

D−1
G2D−1
G1
T =

D−1
G1
T 
D−1
G2
T (note that inversion or
transposition alone would not accomplish this since each reverses products).
Applying this, in particular, to the identity representation D( 1
2 ,0) gives
G =
*a
b
c
d
+
−→(G−1)T = (GT )−1 =
* d
−c
−b
a
+
.
Letting ϵ =
*
0 −1
1 0
+
it is easily checked that ϵ−1 = −ϵ and
(G−1)T = ϵ−1Gϵ.
Thus, G →(G−1)T = (GT)−1 is equivalent to D( 1
2 ,0) and we shall denote
it ˜D( 1
2 ,0). Similarly, one can deﬁne a representation ˜D(0, 1
2) equivalent to
conjugation by
G −→( ¯G−1)T = ( ¯GT )−1 = ϵ−1 ¯Gϵ.

3.1 Representations of the Lorentz Group
147
These equivalent versions of D( 1
2 ,0) and D(0, 1
2) as well as analogous versions
of D( m
2 , n
2 ) are often convenient and we shall return to them in the next
section.
Now let m = n = 1. Then P11 = {p(z, ¯z) = p00 + p10z + p01¯z + p11z¯z :
prs ∈C} and for each G =
*
a b
c d
+
∈SL(2, C) one has
D( 1
2 , 1
2)
G
(p(z, ¯z)) = (bz + d)1( ¯d¯z + ¯d)1(p00 + p10w + p01 ¯w + p11w ¯w),
where w = az+c
bz+d. Multiplying out and rearranging yields
D( 1
2 , 1
2)
G
(p(z, ¯z)) = ˆp00 + ˆp10z + ˆp01¯z + ˆp11z¯z,
where
⎡
⎢⎢⎣
ˆp11
ˆp10
ˆp01
ˆp00
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
a¯a
a¯b
¯ab
b¯b
a¯c
a ¯d
b¯c
b ¯d
¯ac
¯bc
¯ad
¯bd
c¯c
c ¯d
¯cd
d ¯d
⎤
⎥⎥⎦
⎡
⎢⎢⎣
p11
p10
p01
p00
⎤
⎥⎥⎦,
(3.1.13)
so that
D( 1
2 , 1
2)
*
a b
c d
+ =
⎡
⎢⎢⎣
a¯a
a¯b
¯ab
b¯b
a¯c
a ¯d
b¯c
b ¯d
¯ac
¯bc
¯ad
¯bd
c¯c
c ¯d
¯cd
d ¯d
⎤
⎥⎥⎦.
Proceeding in this manner with the notation currently at our disposal would
soon become algebraically unmanageable. For this reason we now introduce
new and powerful notational devices that will constitute the language in
which the remainder of the chapter will be written. First we rephrase the
example of D( 1
2 , 1
2) in these new terms. We begin by rewriting each p(z, ¯z) as
a sum of terms of the form
φA ˙XzA¯z
˙X,
where A = 1, 0 and ˙X = ˙1, ˙0 (the dot is used only to indicate a power of ¯z
rather than z and ˙1, ˙0 are treated exactly as if they were 1, 0, i.e., ¯z ˙0 = 1,
¯z ˙1 = ¯z, ˙0 + ˙1 = ˙1, etc.). Thus,
p00 + p10z + p01¯z + p11z¯z = φ0˙0z0¯z ˙0 + φ1˙0z1¯z ˙0 + φ0˙1z0¯z ˙1 + φ1˙1z1¯z ˙1,
where φ0˙0 = p00, φ1˙0 = p10, φ1˙1 = p11. With the summation convention
(over A = 1, 0,
˙X = ˙1, ˙0),
p(z, ¯z) = φA ˙XzA¯z
˙X.
To set up another application of the summation convention we henceforth
denote the entries in G ∈SL(2, C) as

148
3 The Theory of Spinors
G =

GA
B
=
#
G1
1
G1
0
G0
1
G0
0
$
and write the conjugate ¯G of G as
¯G =
,
¯G ˙X
˙Y -
=
# ¯G˙1
˙1
¯G˙1
˙0
¯G˙0
˙1
¯G˙0
˙0
$
.
Convention: Henceforth, conjugating a term with undotted indices dots them
all and introduces a bar, whereas conjugating a term with dotted indices
undots them and removes the bar. Whenever possible we will select undotted
index names from the beginning of the alphabet (A, B, C, . . .) and dotted
indices from the end (. . . , ˙X, ˙Y , ˙Z).
Now, if we let D( 1
2 , 1
2)
G
(φA ˙XzA¯z ˙X) = ˆφA ˙XzA¯z ˙X we ﬁnd from (3.1.13) that
⎡
⎢⎢⎢⎢⎣
ˆφ1˙1
ˆφ1˙0
ˆφ0˙1
ˆφ0˙0
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
G1
1 ¯G˙1
˙1
G1
1 ¯G˙1
˙0
G1
0 ¯G˙1
˙1
G1
0 ¯G˙1
˙0
G1
1 ¯G˙0
˙1
G1
1 ¯G˙0
˙0
G1
0 ¯G˙0
˙1
G1
0 ¯G˙0
˙0
G0
1 ¯G˙1
˙1
G0
1 ¯G˙1
˙0
G0
0 ¯G˙1
˙1
G0
0 ¯G˙1
˙0
G0
1 ¯G˙0
˙1
G0
1 ¯G˙0
˙0
G0
0 ¯G˙0
˙1
G0
0 ¯G˙0
˙0
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
φ1˙1
φ1˙0
φ0˙1
φ0˙0
⎤
⎥⎥⎥⎥⎦
(3.1.14)
which all collapses quite nicely with the summation convention to
ˆφA ˙X = GA
B ¯G ˙X
˙Y φB ˙Y ,
A = 1, 0,
˙X = ˙1, ˙0.
(3.1.15)
For D( 1
2 ,0) we would write p00 + p10z
= φ0z0 + φ1z1
= φAzA and
D( 1
2 ,0)
G
(φAzA) = ˆφAzA, where
ˆφA = GA
BφB,
A = 1, 0.
(3.1.16)
Similarly, for D(0, 1
2), p00+p01¯z = φ˙0¯z ˙0+φ˙1¯z ˙1 = φ ˙X ¯z ˙X and D(0, 1
2)
G
(φ ˙X ¯z ˙X) =
ˆφ ˙X ¯z ˙X, where
ˆφ ˙X = ¯G ˙X
˙Y φ ˙Y ,
˙X = ˙1, ˙0.
(3.1.17)
Notice that the 4 × 4 matrix in (3.1.14) is precisely D( 1
2 , 1
2)
G
and that anal-
ogous statements would be true of (3.1.16) and (3.1.17) if these were written
as matrix products. The situation changes somewhat for larger m and n so
we wish to treat one more example before describing the general case. Thus,
we let m = 2 and n = 1. An element p(z, ¯z) = p00 + p10z + · · · + p21z2¯z is
to be written as a sum of terms of the form φA1A2 ˙XzA1zA2¯z ˙X. For example,
the constant term p00 is written φ00˙0z0z0¯z ˙0 so φ00˙0 = p00 and p10z becomes
φ10˙0z1z0¯z ˙0 + φ01˙0z0z1¯z ˙0 and we take φ10˙0 = φ01˙0 = 1
2p10, and so on. The
result is

3.1 Representations of the Lorentz Group
149
p(z, ¯z) = φ00˙0z0z0¯z
˙0 + φ10˙0z1z0¯z
˙0 + φ01˙0z0z1¯z
˙0
+ φ00˙1z0z0¯z
˙1 + φ10˙1z1z0¯z
˙1 + φ01˙1z0z1¯z
˙1
+ φ11˙0z1z1¯z
˙0 + φ11˙1z1z1¯z
˙1,
where we take
φ00˙0 = p00,
φ10˙0 = φ01˙0 = 1
2p10, φ00˙1 = p01,
φ10˙1 = φ01˙1 = 1
2p11,
φ11˙0 = p20,
φ11˙1 = p21,
so that, in particular, φA1A2 ˙X is symmetric in A1 and A2, i.e., φA2A1 ˙X =
φA1A2 ˙X for A1, A2 = 1, 0. Thus, with the summation convention,
p(z, ¯z) = φA1A2 ˙XzA1zA2 ¯z
˙X = φA1A2 ˙XzA1+A2 ¯z
˙X.
Now,
D( 2
2 , 1
2)
G
(p(z, ¯z)) =

G1
0z + G0
02 
¯G˙1
˙0¯z + ¯G˙0
˙01
(φA1A2 ˙XwA1+A2 ¯w
˙X),
where
w = G1
1z + G0
1
G1
0z + G0
0 ,
so
D( 2
2 , 1
2)
G
(p(z, ¯z)) = φA1A2 ˙X

G1
1z + G0
1A1+A2 
G1
0z + G0
02−A1−A2
·

¯G˙1
˙1¯z + ¯G˙0
˙1 ˙X 
¯G˙1
˙0¯z + ¯G˙0
˙01−˙X
= φ00˙0

G1
0z + G0
0 
G1
0z + G0
0 
¯G˙1
˙0¯z + ¯G˙0
˙0
+ φ10˙0

G1
1z + G0
1 
G1
0z + G0
0 
¯G˙1
˙0¯z + ¯G˙0
˙0
+ φ01˙0

G1
1z + G0
1 
G1
0z + G0
0 
¯G˙1
˙0¯z + ¯G˙0
˙0
+ φ11˙0

G1
1z + G0
1 
G1
1z + G0
1 
¯G˙1
˙0¯z + ¯G˙0
˙0
+ φ00˙1

G1
0z + G0
0 
G1
0z + G0
0 
¯G˙1
˙1¯z + ¯G˙0
˙1
+ φ10˙1

G1
1z + G0
1 
G1
0z + G0
0 
¯G˙1
˙1¯z + ¯G˙0
˙1
+ φ01˙1

G1
1z + G0
1 
G1
0z + G0
0 
¯G˙1
˙1¯z + ¯G˙0
˙1
+ φ11˙1

G1
1z + G0
1 
G1
1z + G0
1 
¯G˙1
˙1¯z + ¯G˙0
˙1
.

150
3 The Theory of Spinors
Multiplying out and collecting terms gives D( 2
2 , 1
2)
G
(φA1A2 ˙XzA1+A2 ¯z ˙X) =
ˆφA1A2 ˙XzA1+A2 ¯z ˙X, where
ˆφA1A2 ˙X = GA1
B1GA2
B2 ¯G ˙X
˙Y φB1B2 ˙Y ,
A1, A2 = 1, 0,
˙X = ˙1, ˙0.
(3.1.18)
Exercise 3.1.8 Write out all terms in the expansion of D( 2
2 , 1
2)
G
(p(z, ¯z)) that
contain z2¯z and show that they can be written in the form
G1
B1G1
B2 ¯G˙1
˙Y φB1B2 ˙Y zB1zB2 ¯z
˙Y
and so verify (3.1.18) for A1 = A2 = 1,
˙X = ˙1. Similarly, ﬁnd the constant
term and the terms with z, z2, ¯z and z¯z to verify (3.1.18) for all A1, A2 and ˙X.
Now observe that by writing the ˆφA1A2 ˙X as a column matrix [ˆφA1A2 ˙X] =
col[ˆφ11˙1 ˆφ10˙1 ˆφ01˙1 ˆφ00˙1 ˆφ11˙0 ˆφ10˙0 ˆφ01˙0 ˆφ00˙0], and similarly for the φB1B2 ˙Y ,
(3.1.18) can be written as a matrix product
⎡
⎢⎢⎢⎢⎢⎣
ˆφ11˙1
ˆφ10˙1
...
ˆφ00˙0
⎤
⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎣
G1
1G1
1 ¯G˙1
˙1
G1
1G1
0 ¯G˙1
˙1
G1
0G1
1 ¯G˙1
˙1
· · ·
G1
1G0
1 ¯G˙1
˙1
G1
1G0
0 ¯G˙1
˙1
G1
0G0
1 ¯G˙1
˙1
· · ·
...
...
...
G0
1G0
1 ¯G˙0
˙1
G0
1G0
0 ¯G˙0
˙1
G0
0G0
1 ¯G˙0
˙1
· · ·
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
φ11˙1
φ10˙1
...
φ00˙0
⎤
⎥⎥⎥⎥⎦
.
Unlike (3.1.14), however, the 8 × 8 coeﬃcient matrix here is not D( 2
2 , 1
2)
G
. In-
deed, the representation G →[GA1
B1GA2
B2 ¯G ˙X
˙Y ] which assigns this matrix
to G is not even equivalent to the spinor representation of type (2,1) since
the latter has order (2 + 1)(1 + 1) = 6, not 8. The reason is that, in writing
the elements of P21 in the form φA1A2 ˙XzA1zA2 ¯z ˙X, we are not ﬁnding com-
ponents relative to the basis {1, z, ¯z, . . . , z2¯z} since, for example, z1z0¯z ˙1 and
z0z1¯z ˙1 are both z¯z. Nevertheless, it is the transformation law (3.1.18) that
is of most interest to us.
The general case proceeds in much the same way. Pmn consists of all
p(z, ¯z) = p00 + p10z + · · · + pmnzm¯zn = prszr¯zs, r = 0, . . . , m, s = 0, . . . , n.
Each of these is written as a sum of terms of the form
φA1···Am ˙X1··· ˙XnzA1 · · · zAm ¯z
˙X1 · · · ¯z
˙Xn,
where A1, . . . , Am
=
1, 0 and
˙X1, . . . , ˙Xn
=
˙1, ˙0, and φA1...Am ˙X1... ˙Xn
is completely symmetric in A1, . . . , Am (i.e., φA1···Ai···Aj···Am ˙X1··· ˙Xn
=
φA1···Aj···Ai···Am ˙X1··· ˙Xn for all i and j) and completely symmetric in the
˙X1, . . . , ˙Xn. For example,

3.1 Representations of the Lorentz Group
151
p22z2¯z2 = φ110···0˙1˙1˙0···˙0 z1z1z0 · · · z0
1
23
4
m
¯z
˙1¯z
˙1¯z
˙0 · · · ¯z
˙0
1
23
4
n
+ φ1010···0˙1˙0˙1˙0···˙0z1z0z1z0 · · · z0¯z
˙1¯z
˙0¯z
˙1¯z
˙0 · · · ¯z
˙0
+ · · · + φ00···011˙0˙0···˙0˙1˙1z0z0 · · · z0z1z1¯z
˙0¯z
˙0 · · · ¯z
˙0¯z
˙1¯z
˙1.
There are

m
2
 
n
2

terms in the sum so we may take
φA1···Am ˙X1··· ˙Xn =
1

m
2
 
n
2
p22,
where A1+· · ·+Am = 2 and ˙X1+· · ·+ ˙Xn = ˙2. Similarly, for each 0 ≤r ≤m
and 0 ≤s ≤n, if A1, . . . , Am take the values 1 and 0 with A1 + · · · + Am = r
and ˙X1, . . . , ˙Xn take the values ˙1 and ˙0 with ˙X1 + · · · + ˙Xn = ˙s, we deﬁne
φA1···Am ˙X1··· ˙Xn =
1
m
r
 n
s
prs.
Then
prszr¯zs =

A1 + · · · + Am = r
˙X1 + · · · + ˙Xn = ˙s
Ai = 1, 0
˙Xi = ˙1, ˙0
φA1···Am ˙X1··· ˙XnzA1 · · · zAm¯z
˙X1 · · · ¯z
˙Xn,
where there is no sum on the left. Summing over all r = 0, . . . , m and s =
0, . . . , n and using the summation convention on both sides gives
p(z, ¯z) = prszr¯zs = φA1···Am ˙X1··· ˙XnzA1 · · · zAm¯z
˙X1 · · · ¯z
˙Xn
= φA1···Am ˙X1··· ˙XnzA1+···+Am ¯z
˙X1+···+ ˙Xn.
Again we observe that the φ’s are symmetric in A1, . . . , Am and symmetric
in ˙X1, . . . , ˙Xn. Applying the transformation D( m
2 , n
2 )
G
to p(z, ¯z) yields
D( m
2 , n
2 )
G

φA1···Am ˙X1··· ˙XnzA1+···+Am ¯z
˙X1+···+ ˙Xn

= ˆφA1···Am ˙X1··· ˙XnzA1+···+Am ¯z
˙X1+···+ ˙Xn,
(3.1.19)
where
ˆφA1···Am ˙X1··· ˙Xn = GA1
B1 · · · GAm
Bm ¯G ˙X1
˙Y1 · · · ¯G ˙Xn
˙YnφB1···Bm ˙Y1··· ˙Yn,
(3.1.20)

152
3 The Theory of Spinors
and the sum is over all r = 0, . . . , m, B1+· · ·+Bm = r with B1, . . . , Bm = 1, 0
and all s = 0, . . . , n, ˙Y1 + · · · + ˙Yn = ˙s with ˙Y1, . . . , ˙Yn = ˙1, ˙0.
The transformation law (3.1.20) is typical of a certain type of “spinor”
(those of “valence”
 0
0
m n

) that we will deﬁne in the next section. For the
precise deﬁnition we wish to follow a procedure analogous to that employed
in our deﬁnition of a world tensor. The idea there was that the underlying
group being represented (L) was the group of matrices of orthogonal trans-
formations of M relative to orthonormal bases and that a world tensor could
be identiﬁed with a multilinear functional on M and its dual. By analogy
we would like to regard the elements of SL(2, C) as matrices of the structure
preserving maps of some “inner-product-like” space ß and identify “spinors”
as multilinear functionals. This is, indeed, possible, although we will have to
stretch our notion of “inner product” a bit.
Since the elements of SL(2, C) are 2 × 2 complex matrices, the space ß
we seek must be a 2-dimensional vector space over C. Observe that if
*φ1
φ0
+
and
*
ψ1
ψ0
+
are two ordered pairs of complex numbers and G =

GA
B
is in
SL(2, C) and if we deﬁne
*ˆφ1
ˆφ0
+
and
* ˆψ1
ˆψ0
+
by
#ˆφ1
ˆφ0
$
=
#
G1
1
G1
0
G0
1
G0
0
$ #
φ1
φ0
$
=
#
G1
1φ1 + G1
0φ0
G0
1φ1 + G0
0φ0
$
and similarly for
* ˆψ1
ˆψ0
+
, then

ˆφ1
ˆψ1
ˆφ0
ˆψ0
 =

#
G1
1
G1
0
G0
1
G0
0
$ #
φ1
ψ1
φ0
ψ0
$
=

G1
1
G1
0
G0
1
G0
0


φ1
ψ1
φ0
ψ0

=

φ1
ψ1
φ0
ψ0

and so
ˆφ1 ˆψ0 −ˆφ0 ˆψ1 = φ1ψ0 −φ0ψ1.
(3.1.21)
Conversely, if (3.1.21) is satisﬁed, then G must be in SL(2, C). Thus, if we
deﬁne on the vector space
C2 =
.
φ =
*φ1
φ0
+
: φA ∈C
for A = 1, 0
5

3.2 Spin Space
153
a mapping
< , >: C2 × C2 →C
by
< φ, ψ > = φ1ψ0 −φ0ψ1,
then the elements of SL(2, C) are precisely the matrices that preserve < , >.
Exercise 3.1.9 Verify the following properties of < , >.
1. < , > is bilinear, i.e., < φ, aψ + bξ > = a < φ, ψ > + b < φ, ξ > and
< aφ
+
bψ, ξ > = a < φ, ξ > + b < ψ, ξ > for all a, b ∈C and
φ, ψ, ξ ∈C2.
2. < , > is skew-symmetric, i.e., < ψ, φ > = −< φ, ψ >.
3. < φ, ψ > ξ + < ξ, φ > ψ + < ψ, ξ > φ = 0 for all φ, ψ, ξ ∈C2.
With these observations as motivation we proceed in the next section with
an abstract deﬁnition of the underlying 2-dimensional complex vector space
ß whose multilinear functionals are “spinors”.
3.2 Spin Space
Spin space is a vector space ß over the complex numbers on which is deﬁned
a map < , >: ß × ß →C which satisﬁes:
1. there exist φ and ψ in ß such that < φ, ψ > ̸= 0,
2. < ψ, φ > = −< φ, ψ > for all φ, ψ ∈ß,
3. < aφ + bψ, ξ > = a < φ, ξ > + b < ψ, ξ > for all φ, ψ, ξ ∈ß and all
a, b ∈C,
4. < φ, ψ > ξ + < ξ, φ > ψ + < ψ, ξ > φ = 0 for all φ, ψ, ξ ∈ß.
An element of ß is called a spin vector. The existence of a vector space of the
type described was established in Exercise 3.1.9.
Lemma 3.2.1 Each of the following holds in spin space.
(a) < φ, φ > = 0 for every φ ∈ß.
(b) < , > is bilinear, i.e., in addition to #3 in the deﬁnition we have
< φ, aψ + bξ > = a < φ, ψ > + b < φ, ξ > for all φ, ψ, ξ ∈ß and
all a, b ∈C.
(c) Any φ and ψ in ß which satisfy < φ, ψ > ̸= 0 form a basis for ß. In
particular, dim ß = 2.
(d) There exists a basis {s1, s0} for ß which satisﬁes < s1, s0 > = 1 =
−< s0, s1 > (any such basis is called a spin frame for ß).
(e) If {s1, s0} is a spin frame and φ = φ1s1 + φ0s0 = φAsA, then φ1 =
< φ, s0 > and φ0 = −< φ, s1 >.
(f) If {s1, s0} is a spin frame and φ = φAsA and ψ = ψAsA, then
< φ, ψ >=

φ1
ψ1
φ0
ψ0
 = φ1ψ0 −φ0ψ1.

154
3 The Theory of Spinors
(g) φ and ψ in ß are linearly independent if and only if < φ, ψ > ̸= 0.
(h) If {s1, s0} and {ˆs1,ˆs0} are two spin frames with s1 = G1
1ˆs1 + G0
1ˆs0 =
GA
1ˆsA and s0 = G1
0ˆs1 + G0
0ˆs0 = GA
0ˆsA, i.e.,
sB = GA
BˆsA,
B = 1, 0,
(3.2.1)
then G =

GA
B
=
*G1
1
G1
0
G0
1
G0
0
+
is in SL(2, C).
(i) If {s1, s0} and {ˆs1,ˆs0} are two spin frames and φ = φAsA = ˆφAˆsA, then
#ˆφ1
ˆφ0
$
=
#
G1
1
G1
0
G0
1
G0
0
$ #
φ1
φ0
$
,
i.e.,
ˆφA = GA
BφB,
A = 1, 0,
(3.2.2)
where the GA
B are given by (3.2.1).
(j) A linear transformation T
: ß →ß preserves < , > (i.e., satisﬁes
< T φ, T ψ > = < φ, ψ > for all φ, ψ ∈ß) if and only if the matrix of
T relative to any spin frame is in SL(2, C).
Proof:
Exercise 3.2.1 Prove (a) and (b).
(c) From (a) and (b) it follows that < λφ, φ > = < φ, λφ > = 0 for all λ ∈C
and all φ ∈ß. Consequently, if < φ, ψ > ̸= 0, neither φ nor ψ can be a
multiple of the other, i.e., they are linearly independent. Moreover, for
any ξ ∈ß, #4 gives < φ, ψ > ξ = −< ξ, φ > ψ −< ψ, ξ > φ so, since
< φ, ψ > ̸= 0, ξ is a linear combination of φ and ψ so {φ, ψ} is a basis
for ß.
(d) Suppose < φ, ψ > ̸= 0. By switching names if necessary and using #2
we may assume < φ, ψ > > 0. By (c), φ and ψ form a basis for ß and
therefore so do s1 = < φ, ψ >−1
2 φ and s0 =< φ, ψ >−1
2 ψ. But then
bilinearity of < , > gives < s1, s0 >= 1 and so, by #2, < s0, s1 > = −1.
(e) φ = φ1s1 + φ0s0 ⇒< φ, s0 > = φ1 < s1, s0 > + φ0 < s0, s0 > = φ1, and,
similarly, < φ, s1 > = −φ0.
(f) < φ, ψ > = < φ1s1 + φ0s0, ψ1s1 + ψ0s0 > = φ1ψ1 < s1, s1 > + φ1ψ0
< s1, s0 > + φ0ψ1 < s0, s1 > + φ0ψ0 < s0, s0 > = φ1ψ0−φ0ψ1.
(g) < φ, ψ > ̸= 0 implies φ and ψ linearly independent by (c). For the converse
suppose < φ, ψ > = 0. If φ = 0 they are obviously dependent so assume
φ ̸= 0. Select a spin frame {s1, s0} and set φ = φAsA and ψ = ψAsA.
Suppose φ1 ̸= 0 (the proof is analogous if φ0 ̸= 0). By (f), < φ, ψ > = 0
implies φ1ψ0 −φ0ψ1 = 0 so ψ0 = (φ0/φ1)ψ1 and therefore
*
ψ1
ψ0
+
= ψ1
φ1
*
φ1
φ0
+
,
so ψ = (ψ1/φ1)φ and φ and ψ are linearly dependent.

3.2 Spin Space
155
(h) < s1, s0 > = 1 implies 1 = < G1
1ˆs1 + G0
1ˆs0, G1
0ˆs1 + G0
0ˆs0 > = G1
1G1
0
< ˆs1, ˆs1 > + G1
1G0
0 < ˆs1, ˆs0 > + G0
1G1
0 < ˆs0, ˆs1 > + G0
1G0
0
< ˆs0, ˆs0 > = G1
1G0
0 −G0
1G1
0 = det G as required.
(i) ˆφ1ˆs1 + ˆφ0ˆs0 = φ1s1 + φ0s0 = φ1

G1
1ˆs1 + G0
1ˆs0
+φ0

G1
0ˆs1 + G0
0ˆs0
=

G1
1φ1 + G1
0φ0

ˆs1 +

G0
1φ1 + G0
0φ0

ˆs0 so the result follows by equat-
ing components.
(j) Let T : ß →ß be a linear transformation and {s1, s0} a spin frame. Let

TA
B
be the matrix of T relative to {s1, s0}. Then, for all φ and ψ in ß,
T φ = TA
BφB, T ψ = TA
BψB and
< φ, ψ > =

φ1
ψ1
φ0
ψ0
 .
Now compute
< T φ, T ψ > =

T1
1φ1 + T1
0φ0
T1
1ψ1 + T1
0ψ0
T0
1φ1 + T0
0φ0
T0
1ψ1 + T0
0ψ0

=

#
T1
1
T1
0
T0
1
T0
0
$ #
φ1
ψ1
φ0
ψ0
$
=

T1
1
T1
0
T0
1
T0
0


φ1
ψ1
φ0
ψ0
 .
Thus, < T φ, T ψ > = < φ, ψ > if and only if det

TA
B
= 1, i.e., if and only
if

TA
B
∈SL(2, C).
■
Comparing (3.2.2) and (3.1.16) we see that spin vectors are a natural
choice as carriers for the identity representation D( 1
2 ,0) of SL(2, C). To ﬁnd
an equally natural choice for the carrier space of the equivalent representation
˜D( 1
2 ,0) we denote by ß∗the dual of the vector space ß and by {s1, s0} the
basis for ß∗dual to the spin frame {s1, s0}. Thus,
sA(sB) = δB
A,
A, B = 1, 0.
(3.2.3)
The elements of ß∗are called spin covectors. For each φ ∈ß we deﬁne
φ∗∈ß∗by
φ∗(ψ) = < φ, ψ >
for every ψ ∈ß (φ∗is linear by (b) of Lemma 3.2.1).
Lemma 3.2.2 Every element of ß∗is φ∗for some φ ∈ß.
Proof:
Let f ∈ß∗. Select a spin frame {s1, s0} and deﬁne φ ∈ß by
φ = f(s0)s1 −f(s1)s0. Then, for every ψ ∈ß, φ∗(ψ) = < φ, ψ > = <
f(s0)s1 −f(s1)s0, ψ > = f(s0) < s1, ψ > −f(s1) < s0, ψ > = −f(s0) <
ψ, s1 > + f(s1) < ψ, s0 > = f(s1)ψ1+f(s0)ψ0. But f(ψ) = f(ψ1s1+ψ0s0) =
ψ1f(s1) + ψ0f(s0) = φ∗(ψ) so f = φ∗.
■

156
3 The Theory of Spinors
Now, for every φ ∈ß, we may write φ = φAsA and φ∗= φAsA for some con-
stants φA and φA, A = 1, 0. By (3.2.3), φ∗(s1) = (φAsA)(s1) = φ1s1(s1) =
φ1 and, similarly, φ∗(s0) = φ0. On the other hand, φ∗(s1) = < φ, s1 > =
< φ1s1 + φ0s0, s1 > = −φ0 and, similarly, φ∗(s0) = φ1 so we ﬁnd that
)
φ1 = −φ0
φ0 = φ1.
(3.2.4)
Now, if {ˆs1, ˆs0} is another spin frame with sB = GA
BˆsA as in (3.2.1), then,
by (i) of Lemma 3.2.1, we have
#ˆφ1
ˆφ0
$
=
#
G1
1
G1
0
G0
1
G0
0
$ #
φ1
φ0
$
for every φ = φAsA = ˆφAˆsA in ß. Letting
#
G11
G10
G01
G00
$
=
#
G0
0
−G0
1
−G1
0
G1
1
$
=

GA
B−1T
,
we ﬁnd that
#
G11
G10
G01
G00
$ #
φ1
φ0
$
=
#
G0
0
−G0
1
−G1
0
G1
1
$ #
−φ0
φ1
$
=
#
−G0
BφB
G1
BφB
$
=
#
−ˆφ0
ˆφ1
$
=
#ˆφ1
ˆφ0
$
,
so
ˆφA = GABφB,
A = 1, 0.
(3.2.5)
Consequently, spin covectors have components relative to dual spin frames
that transform under ˜D( 1
2 ,0) so ß∗is a natural choice for a space of carriers
of this representation of SL(2, C).
Exercise 3.2.2 Verify that GACGB
C = GC
AGC B = δA
B and show that
ˆsA = GA
BsB
(3.2.6)
and
ˆsA = GA
BsB
(3.2.7)
and therefore
sB = GABˆsA.
(3.2.8)

3.2 Spin Space
157
Exercise 3.2.3 For each φ ∈ß deﬁne φ∗∗: ß∗→C by φ∗∗(f) = f(φ) for
each f ∈ß∗. Show that φ∗∗is a linear functional on ß∗, i.e., φ∗∗∈(ß∗)∗, and
that the map φ →φ∗∗is an isomorphism of ß onto (ß∗)∗.
From Exercise 3.2.3 we conclude that, just as the elements of ß∗are linear
functionals on ß, so we can regard the elements of ß as linear functionals on
ß∗. Of course, the transformation law for components relative to a double
dual basis for (ß∗)∗is the same as that for the spin frame it came from since
one takes the transposed inverse twice. The point is that we now have carrier
spaces for D( 1
2 ,0) and ˜D( 1
2 ,0) that are both spaces of linear functionals (on
ß∗and ß, respectively).
Next consider a bilinear functional on, say, ß∗× ß∗: ξ : ß∗× ß∗→
C. If {s1, s0} is a spin frame and {s1, s0} its dual, then for all φ∗=
φAsA and ψ∗= ψAsA in ß∗we have ξ(φ∗, ψ∗) = ξ(φAsA, ψBsB) =
ξ(sA, sB)φAψB. Letting ξAB = ξ(sA, sB) we ﬁnd that ξ(φ∗, ψ∗) = ξABφAψB.
Now, if {ˆs1, ˆs0} is another spin frame with dual {ˆs1, ˆs0}, then ˆξAB
=
ξ(ˆsA, ˆsB) = ξ

GA
CsC, GB
DsD

= GA
CGB
Dξ(sC, sD) = GA
CGB
DξCD
which we write as
ˆξA1A2 = GA1
B1GA2
B2ξB1B2,
A1, A2 = 1, 0,
(3.2.9)
and recognize as being the transformation law (3.1.20) with m = 2 and n = 0.
Multilinear functionals on larger products ß∗× ß∗× · · · × ß∗will, in the same
way, have components which transform according to (3.1.20) for larger m and
n = 0 (we will consider nonzero n shortly). For a bilinear ξ
: ß × ß →C
we ﬁnd that ξ(φ, ψ) = ξ(φAsA, ψBsB) = ξ(sA, sB)φAψB = ξABφAψB and,
in another spin frame,
ˆξC1C2 = GC1D1GC2D2ξD1D2,
C1, C2 = 1, 0,
(3.2.10)
and similarly for larger products.
Exercise 3.2.4 Verify (3.2.10). Also show that if ξ : ß∗×ß →C is bilinear,
{sA} and {ˆsA} are spin frames with duals {sA} and {ˆsA}, ξA
C = ξ(sA, sC)
and ˆξA
C = ξ(ˆsA, ˆsC), then, for any φ = φAsA = ˆφAˆsA ∈ß and ψ∗= ψAsA =
ˆψAˆsA ∈ß∗we have ξ(ψ∗, φ) = ξA
CψAφC = ˆξAC ˆψA ˆφC and
ˆξA1
C1 = GA1
B1GC1D1ξB1
D1,
A1, C1 = 1, 0.
(3.2.11)
All of this will be generalized shortly in our deﬁnition of a “spinor”, but
ﬁrst we must construct carriers for D(0, 1
2) and ˜D(0, 1
2). For this we shall
require a copy ¯ß of ß that is distinct from ß. For example, we might take
¯ß = ß × {1} so that each element of ¯ß is of the form (φ, 1) for some φ ∈ß. We
denote by ¯φ the element (φ, 1) ∈¯ß. Thus,
¯ß = {¯φ : φ ∈ß}.

158
3 The Theory of Spinors
We deﬁne the linear space structure on ¯ß as follows: For ¯φ, ¯ψ and ¯ξ in ¯ß and
c ∈C we have
¯φ + ¯ψ = φ + ψ
and
c¯φ = ¯cφ
(this last being equivalent to ¯λ¯φ = λφ, where ¯c and ¯λ are the usual conjugates
of the complex numbers c and λ). Thus, the map φ →¯φ of ß to ¯ß, which is
obviously bijective, is a conjugate (or anti-) isomorphism, i.e., satisﬁes
φ + ψ −→¯φ + ¯ψ
and
cφ −→¯c¯φ.
The elements of ¯ß are called conjugate spin vectors.
Let {s1, s0} be a spin frame in ß and denote by ¯s˙1 and ¯s˙0 the images of s1
and s0 respectively under φ →¯φ. Then {¯s˙1, ¯s˙0} is a basis for ¯ß. Moreover,
if φ = φ1s1 + φ0s0 is in ß, then ¯φ = ¯φ˙1¯s˙1 + ¯φ˙0¯s˙0 (recall our notational
conventions from Section 3.1 concerning dotted indices, bars, etc.). Now, if
{ˆs1, ˆs0} is another spin frame, related to {sA} by (3.2.6), and {¯ˆs˙1, ¯ˆs˙0} is
its image under φ →¯φ, then ˆs1 = G1BsB = G11s1 + G10s0 implies ¯ˆs˙1 =
¯G ˙1 ˙1¯s˙1 + ¯G ˙1 ˙0¯s˙0 and similarly for ¯ˆs˙0 so
¯ˆs
˙X = ¯G
˙X ˙Y ¯s
˙Y ,
˙X = ˙1, ˙0,
(3.2.12)
and so
¯s
˙Y = ¯G ˙X
˙Y ¯ˆs
˙X,
˙Y = ˙1, ˙0.
(3.2.13)
It follows that if ¯φ = ¯φ ˙Y ¯s ˙Y = ¯ˆφ ˙X¯ˆs ˙X, then
¯ˆφ ˙X = ¯G ˙X
˙Y ¯φ ˙Y ,
˙X = ˙1, ˙0,
(3.2.14)
and
¯φ ˙Y = ¯G
˙X ˙Y
¯ˆφ ˙X,
˙Y = ˙1, ˙0.
(3.2.15)
The elements of the dual ¯ß∗of ¯ß are called conjugate spin covectors and the
bases dual to {¯s ˙X} and {¯ˆs ˙X} are denoted {¯s ˙X} and {¯ˆs ˙X} respectively. Just
as before we have
¯ˆs ˙X = ¯G ˙X
˙Y ¯s ˙Y ,
˙X = ˙1, ˙0,
(3.2.16)
and
¯s ˙Y = ¯G
˙X
˙Y ¯ˆs ˙X,
˙Y = ˙1, ˙0.
(3.2.17)

3.2 Spin Space
159
For each φ∗= φAsA = ˆφAˆsA ∈ß∗we deﬁne ¯φ∗∈¯ß∗by ¯φ∗= ¯φ ˙X¯s ˙X =
¯ˆφ ˙X ¯ˆs ˙X. Then
¯ˆφ
˙X = ¯G
˙X ˙Y ¯φ
˙Y ,
˙X = ˙1, ˙0,
(3.2.18)
and
¯φ
˙Y = ¯G ˙X
˙Y ¯ˆφ
˙X,
˙Y = ˙1, ˙0.
(3.2.19)
Before giving the general deﬁnitions we once again illustrate with a speciﬁc
example. Thus, consider a multilinear functional ξ : ß × ¯ß × ß∗× ¯ß∗→C.
If φ = φAsA, ¯ψ = ¯ψ ˙X¯s ˙X, ζ = ζBsB and ¯ν = ¯ν ˙Y ¯s ˙Y are in ß, ¯ß, ß∗and ¯ß∗
respectively, then
ξ(φ, ¯ψ, ζ, ¯ν) = ξ(φAsA, ¯ψ ˙X¯s
˙X, ζBsB, ¯ν
˙Y ¯s ˙Y )
= ξ(sA, ¯s
˙X, sB, ¯s ˙Y )φA ¯ψ ˙XζB¯ν
˙Y
= ξA ˙X
B ˙Y φA ¯ψ ˙XζB¯ν
˙Y ,
where ξA ˙X
B ˙Y = ξ(sA, ¯s ˙X, sB, ¯s ˙Y ) are the components of ξ relative to the
spin frame {s1, s0} (and the related bases for ¯ß, ß∗and ¯ß∗). In another spin
frame {ˆs1, ˆs0} we have ξ(φ, ¯ψ, ζ, ¯ν) = ˆξA ˙X
B ˙Y ˆφA ¯ˆψ ˙X ˆζB¯ˆν ˙Y , where
ˆξA ˙X
B ˙Y = ξ(ˆsA, ¯ˆs
˙X, ˆsB, ¯ˆs ˙Y )
= ξ

GAA1 sA1, ¯G
˙X ˙X1 ¯s
˙X1, GB
B1 sB1, ¯G ˙Y
˙Y1 ¯s ˙Y1

= GAA1 ¯G
˙X ˙X1 GB
B1 ¯G ˙Y
˙Y1 ξA1 ˙X1
B1 ˙Y1
which, as we shall see, is the transformation law for the components relative
to a spin frame of a “spinor of valence

1
1
1
1

”. With this we are ﬁnally
prepared to present the general deﬁnitions.
A spinor of valence

r
s
m n

, also called a spinor with m undotted lower
indices, n dotted lower indices, r undotted upper indices, and s dotted upper
indices is a multilinear functional
ξ : ß × · · · × ß
1
23
4
r factors
× ¯ß × · · · × ¯ß
1
23
4
s factors
× ß∗× · · · × ß∗
1
23
4
m factors
× ¯ß∗× · · · × ¯ß∗
1
23
4
n factors
−→C.
If {s1, s0} is a spin frame (with associated bases {¯s˙1, ¯s˙0}, {s1, s0} and {¯s˙1, ¯s˙0}
for ¯ß, ß∗and ¯ß∗), then the components of ξ relative to {sA} are deﬁned by
ξA1···Ar ˙X1··· ˙Xs
B1···Bm ˙Y1··· ˙Yn = ξ

sA1, . . . , sAr, ¯s
˙X1, . . . , ¯s
˙Xs,
sB1, . . . , sBm, ¯s ˙Y1, . . . , ¯s ˙Yn

,
A1, . . . , Ar, B1, . . . , Bm = 1, 0,
˙X1, . . . , ˙Xs, ˙Y1, . . . , ˙Yn = ˙1, ˙0.
(3.2.20)

160
3 The Theory of Spinors
Exercise 3.2.5 Show that, if {ˆs1, ˆs0} is another spin frame, then
ˆξA1···Ar ˙X1··· ˙Xs
B1···Bm ˙Y1··· ˙Yn = GA1C1 · · · GAr Cr ¯G
˙X1
˙U1 · · · ¯G
˙Xs
˙UsGB1
D1 · · ·
GBm
Dm ¯G
˙V1
˙Y1
· · · ¯G
˙Vn
˙Yn
ξC1···Cr ˙U1··· ˙Us
D1···Dm ˙V1··· ˙Vn.
(3.2.21)
It is traditional, particularly in the physics literature, to deﬁne a “spinor
with r contravariant and m covariant undotted indices and s contravariant
and n covariant dotted indices” to be an assignment of 2r+m+s+n complex
numbers {ξA1···Ar ˙X1··· ˙
Xs
B1···Bm ˙Y1··· ˙Yn} to each spin frame (or, rather, an as-
signment of two such sets of numbers {± ξA1...Ar ˙X1··· ˙Xs
B1···Bm ˙Y1··· ˙Yn} to each
admissible basis for M) which transform according to (3.2.21) under a change
of basis. Although our approach is more in keeping with the “coordinate-free”
fashion that is currently in vogue, most calculations are, in fact, performed
in terms of components and the transformation law (3.2.21). Observe also
that, when r = s = 0, (3.2.21) coincides with the transformation law (3.2.20)
for the carriers of the representation D( m
2 , n
2 ) of SL(2, C). There is a dif-
ference, however, in that the φA1···Am ˙X1··· ˙Xn constructed in Section 3.1 are
symmetric in A1, . . . , Am and symmetric in
˙X1, . . . , ˙Xn and no such sym-
metry assumption is made in the deﬁnition of a spinor of valence
 0
0
m
n

.
The representations of SL(2, C) corresponding to the transformation laws
(3.2.21) will, in general, be reducible, unlike the irreducible spinor represen-
tations of Section 3.1. One ﬁnal remark on the ordering of indices is apropos.
The position of an index in (3.2.20) indicates the “slot” in ξ into which the
corresponding basis element is to be inserted for evaluation. For two indices
of the same type (both upper and undotted, both lower and dotted, etc.) the
order in which the indices appear is crucial since, for example, there is no
reason to suppose that ξ(s1, s0, . . .) and ξ(s0, s1, . . .) are the same. However,
since slots corresponding to diﬀerent types of indices accept diﬀerent sorts
of objects (e.g., spin vectors and conjugate spin covectors) there is no reason
to insist upon any relative ordering of diﬀerent types of indices and we shall
not do so. Thus, for example, ξA1A2 ˙X1B1 = ξA1 ˙X1A2B1 = ξA1B1
A2 ˙X1 etc., but
these need not be the same as ξA2A1 ˙X1 B1, etc.
3.3 Spinor Algebra
In this section we collect together the basic algebraic and computational tools
that will be used in the remainder of the chapter. We begin by introducing
a matrix that will ﬁgure prominantly in many of the calculations that are
before us. Thus, we let ϵ denote the 2 × 2 matrix deﬁned by

3.3 Spinor Algebra
161
ϵ =
*0
−1
1
0
+
=
*ϵ11
ϵ10
ϵ01
ϵ00
+
= [ϵAB].
Depending on the context and the requirements of the summation convention
we will also denote the entries of ϵ in any of the following ways:
ϵ = [ϵAB] = [ϵAB] = [¯ϵ ˙X ˙Y ] = [¯ϵ
˙X ˙Y ].
Observe that ϵ−1 = −ϵ. Moreover, if φ and ψ are two spin vectors and {s1, s0}
is a spin frame with φ = φAsA and ψ = ψBsB, then, with the summation
convention, ϵABψAφB = ϵ10ψ1φ0 + ϵ01ψ0φ1 = φ1ψ0 −φ0ψ1 = < φ, ψ >. Also
let φ∗= φAsA and ψ∗= ψAsA be the corresponding spin covectors.
Exercise 3.3.1 Verify each of the following:
< φ, ψ > = ϵABψAφB = −ϵABφAψB,
(3.3.1)
φA = ϵABφB = −φBϵBA,
(3.3.2)
φA = φBϵBA = −ϵABφB,
(3.3.3)
φAψA = < φ, ψ > = −φAψA,
(3.3.4)
ϵAC ϵBC = δA
B = ϵCAϵCB,
(3.3.5)
(ϵCBφB)ϵCA = φA and ϵAC (φBϵBC) = φA,
(3.3.6)
ϵABϵAB = 2 = ϵABϵAB.
(3.3.7)
Of course, each of the identities (3.3.1)–(3.3.7) has an obvious “barred and
dotted” version, e.g., (3.3.6) would read (¯ϵ ˙Z ˙Y ¯φ ˙Y )¯ϵ ˙Z ˙X = ¯φ ˙X. In addition to
these we record several more identities that will be used repeatedly in the
sequel.
ϵABϵCD + ϵAC ϵDB + ϵADϵBC = 0,
A, B, C, D = 1, 0.
(3.3.8)
To prove (3.3.8) we suppose ﬁrst that A = 1. Thus, we consider ϵ1BϵCD +
ϵ1CϵDB + ϵ1DϵBC. If B = 1 this becomes ϵ1CϵD1 + ϵ1Dϵ1C. C = 1 or D = 1
gives 0 for both terms. For C = 0 and D = 0 we obtain ϵ10ϵ01 + ϵ10ϵ10 =
(−1)(1) + (−1)(−1) = 0. On the other hand, if B = 0 we have ϵ10ϵCD +
ϵ1CϵD0 + ϵ1Dϵ0C. C = D gives 0 for each term. For C = 0 and D = 1 we
obtain ϵ10ϵ01 + ϵ10ϵ10 + ϵ11ϵ00 = (−1)(1) + (−1)(−1) + 0 = 0. If C = 1 and
D = 0, ϵ10ϵ10 + ϵ11ϵ00 + ϵ10ϵ01 = (−1)(−1) + 0 + (−1)(1) = 0. Thus, (3.3.8)
is proved if A = 1 and the argument is the same if A = 0. Next we show that
if G =

GA
B
∈SL(2, C), then
GA
A1GB
B1ϵA1B1 = ϵAB,
A, B = 1, 0.
(3.3.9)

162
3 The Theory of Spinors
This follows from
GA
A1GB
B1ϵA1B1 = GA
1GB
0ϵ10 + GA
0GB
1ϵ01
= GA
0GB
1 −GA
1GB
0
=
⎧
⎪
⎨
⎪
⎩
0
,
if A = B
det G,
if A = 0, B = 1
−det G,
if A = 1, B = 0
= ϵAB(det G)
= ϵAB
since det G = 1. Similarly, if G = [GAB] = ([GA
B]−1)T ,
GA
A1GB
B1ϵA1B1 = ϵAB,
A, B = 1, 0,
(3.3.10)
and both (3.3.9) and (3.3.10) have barred and dotted versions. Observe
that the bilinear form < , > : ß × ß →C is, according to our deﬁnitions in
Section 3.2, a spinor of valence
2
0
0
0

and has components in any spin
frame given by < sA, sB > = −ϵAB and that (3.2.10), with ˆϵAB = ϵAB, sim-
ply conﬁrms the appropriate transformation law. In the same way, (3.3.9)
asserts that the ϵAB can be regarded as the (constant) components of a
spinor of valence

0
0
2
0

, whereas the barred and dotted versions of these
make similar assertions about the ¯ϵ ˙X ˙Y and ¯ϵ ˙X ˙Y .
Exercise 3.3.2 Write out explicitly the bilinear forms (spinors) whose com-
ponents relative to every spin frame are ϵAB, ¯ϵ ˙X ˙Y and ¯ϵ ˙X ˙Y .
The ﬁrst equality in (3.3.2) asserts that, given a spin vector φ and the
corresponding spin covector φ∗, then, relative to any spin frame, the com-
ponents of φ∗= φAsA are mechanically retrievable from those of φ = φBsB
by forming the sum ϵABφB. This process is called raising the index of φB.
Similarly, obtaining the φA from the φB according to (3.3.3) by computing
φBϵBA is termed lowering the index of φB. Due to the skew-symmetry of
the ϵAB care must be exercised in arranging the order of the factors and the
placement of the indices when carrying out these processes. As an aid to the
memory, one “raises on the left and lowers on the right” with the summed in-
dices “adjacent and descending to the right”. The equalities in (3.3.6) assert
that these two operations are consistent, i.e., that lowering a raised index or
vice versa returns the original component. The operations of raising and low-
ering indices extend easily to higher valence spinors. Consider, for example, a

3.3 Spinor Algebra
163
spinor ξ of valence
2 0
1 0

. In each spin frame ξ has components ξAB
C and
we now deﬁne numbers ξA
B
C in this frame by
ξA
B
C = ξA1B
CϵA1A.
In another spin frame we have ˆξABC = ˆξA1BCϵA1A and we now show that
ˆξA
B
C = GA
A1GB
B1GC
C1ξA1
B1
C1,
(3.3.11)
so that the ξABC transform as the components of a spinor of valence

1
0
2
0

.
This last spinor we shall say is obtained from ξ by “lowering the ﬁrst (undot-
ted) upper index”. To prove (3.3.11) we use (3.3.9) and the transformation
law for the ξAB
C as follows:
ˆξABC = ˆξA1BCϵA1A =

GA1A2GBB1GC
C1ξA2B1C1
 
GA1A3GA
A4ϵA3A4

=

GA1A2GA1
A3 
GBB1GC
C1GA
A4 
ξA2B1
C1ϵA3A4

= δA3
A2

GBB1GC
C1GA
A4 
ξA2B1 C1ϵA3A4

=

GB
B1GC
C1GA
A4 
ξA3B1
C1ϵA3A4

= GBB1GC
C1GA
A4ξA4
B1
C1
= GA
A4GB
B1GC
C1ξA4
B1
C1
= GA
A1GBB1GC
C1ξA1
B1
C1
as required.
Exercise 3.3.3 With ξ as above, let ξABC = ϵCC 1ξAB
C1 in each spin frame.
Show that ˆξABC = GAA1GBB1GCC1ξA1B1C1 and conclude that the ξABC
determine a spinor of valence
3
0
0
0

.
The calculations in these last examples make it clear that a spinor of any
valence can have any one of its lower (upper) indices raised (lowered) to yield
a spinor with one more upper (lower) index. Applying this to the constant
spinors ϵAB and ϵAB and using (3.3.5) yields the following useful identities.
ϵAB = ϵBCϵAC = δB
A
(3.3.12)
and
ϵAB = ϵACϵCB = −δA
B.
(3.3.13)

164
3 The Theory of Spinors
We derive a somewhat less obvious identity by beginning with (3.3.8) and
ﬁrst raising C.
ϵABϵCD + ϵACϵDB + ϵADϵBC = 0,
ϵAB(ϵCEϵED) + (ϵCEϵAE)ϵDB + ϵAD(ϵCEϵBE) = 0,
ϵABϵCD + ϵACϵDB + ϵADϵBC = 0,
−ϵABδC
D + δC
AϵDB + ϵADδC
B = 0.
Now, raise D.
−ϵAB

ϵDEδC
E

+ δC
A(ϵDEϵEB) + (ϵDEϵAE)δC
B = 0,
−ϵABϵDC + δC
AϵDB + ϵADδC
B = 0,
−ϵABϵDC −δC
AδD
B + δD
A δC
B = 0.
Using ϵDC = −ϵCD we ﬁnally obtain
ϵABϵCD = δC
AδD
B −δD
A δC
B,
A, B, C, D = 1, 0.
(3.3.14)
It will also be useful to introduce, for each [GA
B] =
*G1
1
G1
0
G0
1
G0
0
+
in SL(2, C),
an associated matrix [GAB] =
*G11
G01
G10
G00
+
, where
GAB = ϵAA1GA1
B1ϵB1B,
A, B = 1, 0.
Exercise 3.3.4 Show that
#
G11
G01
G10
G00
$
=
#
−G0
0
G1
0
G0
1
−G1
1
$
= −
#
G11
G01
G10
G00
$
(3.3.15)
and that
GA
A1GB
B1ϵA1B1 = ϵAB,
A, B = 1, 0.
(3.3.16)
As usual, all of these have obvious barred and dotted versions.
We shall denote by ßrs
mn the set of all spinors of valence
 r
s
m n

. Being a
collection of multilinear functionals, ßrs
mn admits a natural “pointwise” vector
space structure. Speciﬁcally, if ξ, ζ ∈ßrs
mn and
1
φ, . . . ,
r
φ ∈ß,
1¯ψ, . . . ,
s¯ψ ∈
¯ß,
1μ, . . . ,
mμ ∈ß∗and
1¯ν, . . . ,
n¯ν ∈¯ß
∗, then
(ξ + ζ)
 1
φ, . . . ,
n¯ν

= ξ
1
φ, . . . ,
n¯ν

+ ζ
1
φ, . . . ,
n¯ν


3.3 Spinor Algebra
165
and, for α ∈C,
(αξ)
1
φ, . . . ,
n¯ν

= α

ξ
 1
φ, . . . ,
n¯ν

.
If {s1, s0} is a spin frame, {s1, s0} its dual basis for ß∗, {¯s˙1, ¯s˙0} the corre-
sponding conjugate basis for ¯ß and {¯s˙1, ¯s˙0} its dual, we deﬁne sA1 ⊗. . .⊗sAr ⊗
¯s ˙X1 ⊗· · ·⊗¯s ˙Xs ⊗sB1 ⊗· · ·⊗sBm ⊗¯s ˙Y1 ⊗· · ·⊗¯s ˙Yn, abbreviated sA1 ⊗· · ·⊗¯s ˙Yn, by
sA1 ⊗· · · ⊗¯s
˙Yn
 1
φ, . . . ,
n¯ν

= sA1
1
φ

· · · ¯s
˙Yn n¯ν

=
1
φ A1 · · ·
n¯ν ˙Yn.
Thus, for example, in ß11
10 we have s1 ⊗¯s˙0 ⊗s0 deﬁned by s1 ⊗¯s˙0 ⊗s0 (φ, ¯ψ, μ)
= s1(φ)¯s˙0( ¯ψ)s0(μ) = φ1 ¯ψ˙0μ0, where φ = φAsA, ¯ψ = ¯ψ ˙X¯s ˙X and μ = μAsA.
For ξ ∈ßrs
mn we deﬁne
ξA1··· ˙Xs
B1··· ˙Yn = ξ

sA1, . . . , ¯s
˙Xs, sB1, . . . , ¯s ˙Yn

(3.3.17)
for Ai, Bi = 1, 0 and ˙Xi, ˙Yi = ˙1, ˙0.
Exercise 3.3.5 Show that the elements sA1 ⊗· · · ⊗¯s ˙Yn of ßrs
mn are linearly
independent and that any ξ ∈ßrs
mn can be written
ξ = ξA1··· ˙Xs
B1··· ˙YnsA1 ⊗· · · ⊗¯s ˙Xs ⊗sB1 ⊗· · · ⊗¯s
˙Yn.
From Exercise 3.3.5 we conclude that the sA1 ⊗· · · ⊗¯s ˙Yn form a basis for
ßrs
mn which therefore has dimension 2r+s+m+n. For each ξ ∈ßrs
mn the numbers
ξA1··· ˙Xs
B1··· ˙Yn deﬁned by (3.3.17) are the components of ξ relative to the basis
{sA1 ⊗· · · ⊗¯s ˙Yn} and, in terms of them, the linear operations on ßrs
mn can be
expressed as
(ξ + ζ)A1··· ˙Xs
B1··· ˙Yn = ξA1··· ˙Xs
B1··· ˙Yn + ζA1··· ˙Xs
B1··· ˙Yn
and
(αξ)A1··· ˙Xs
B1··· ˙Yn = αξA1··· ˙Xs
B1··· ˙Yn.
The next algebraic operation on spinors that we must consider is a general-
ization of the procedure we just employed to construct a basis for ßrs
mn from a
spin frame. Suppose ξ is a spinor of valence
 r1
s1
m1
n1

and ζ is a spinor of va-
lence
 r2
s2
m2
n2

. The outer product of ξ and ζ is the spinor ξ ⊗ζ of valence

166
3 The Theory of Spinors
 r1+r2
s1+s2
m1+m2
n1+n2

deﬁned as follows. If
1
φ, . . . ,
r1+r2
φ
∈ß,
1¯ψ, . . . ,
s1+s2
¯ψ
∈
¯ß,
1μ, . . . ,
m1+m2
μ
∈ß∗and
1¯ν, . . . ,
n1+n2
¯ν
∈¯ß∗, then
(ξ ⊗ζ)

1
φ, . . . ,
r1+r2
φ ,
1¯ψ, . . . ,
s1+s2
¯ψ ,
1μ, . . . ,
m1+m2
μ
,
1¯ν, . . . ,
n1+n2
¯ν

= ξ

1
φ, . . . ,
r1
φ,
1¯ψ, . . . ,
s1¯ψ,
1μ, . . . ,
m1
μ ,
1¯ν, . . . ,
n1¯ν

× ζ

r1+1
φ , . . . ,
r1+r2
φ ,
s1+1
¯ψ , . . . ,
s1+s2
¯ψ ,
m1+1
μ , . . . ,
m1+m2
μ
,
n1+1
¯ν , . . . ,
n1+n2
¯ν

.
It follows immediately from the deﬁnition that, in terms of components,
(ξ ⊗ζ)A1···Ar1+r2 ˙X1··· ˙Xs1+s2 B1···Bm1+m2 ˙Y1··· ˙Yn1+n2 =

ξA1···Ar1 ˙X1··· ˙Xs1
B1···Bm1 ˙Y1··· ˙Yn1

ζ
Ar1+1···Ar1+r2 ˙Xs1+1··· ˙Xs1+s2
Bm1+1···Bm1+m2 ˙Yn1+1··· ˙Yn1+n2

.
Moreover, outer multiplication is clearly associative ((ξ ⊗ζ)⊗v = ξ ⊗(ζ ⊗v))
and distributive (ξ⊗(ζ +v) = ξ⊗ζ +ξ⊗v and (ξ+ζ)⊗v = ξ⊗v+ζ ⊗v), but
is not commutative. For example, if {s1, s0} is a spin frame, then s1 ⊗s0 does
not equal s0 ⊗s1 since s1 ⊗s0(φ∗, ψ∗) = φ1ψ0, but s0 ⊗s1(φ∗, ψ∗) = φ0ψ1
and these are generally not the same.
Next we consider a spinor ξ of valence

r
s
m
n

and two integers k and l
with 1 ≤k ≤r and 1 ≤l ≤m. Then the contraction of ξ in the indices Ak
and Bl is the spinor Ckl(ξ) of valence
 r−1
s
m−1
n

whose components relative
to any spin frame are obtained by equating Ak and Bl in those of ξ and
summing as indicated, i.e., if
ξ = ξA1···Ak···Ar ˙X1··· ˙Xs
B1···Bl···Bm ˙Y1··· ˙YnsA1 ⊗· · · ⊗¯s
˙Yn,
then
Ckl(ξ) = ξA1···A···Ar ˙X1··· ˙Xs
B1···A···Bm ˙Y1··· ˙YnsA1 ⊗· · · ⊗¯s
˙Yn,
(3.3.18)
where, in this last expression, it is understood that sAk and sBl are missing
in sA1 ⊗· · · ⊗¯s ˙Yn. Thus, for example, if ξ is of valence
1
1
1
0

with
ξ = ξA1 ˙X1B1sA1 ⊗¯s ˙X1 ⊗sB1

3.3 Spinor Algebra
167
and k = l = 1, then C11(ξ) is the spinor of valence
0
1
0
0

given by
C11(ξ) = ξA ˙X1
A¯s ˙X1 =

ξ1 ˙X1
1 + ξ0 ˙X1
0

¯s ˙X1.
Unlike our previous deﬁnitions that were coordinate-free, contractions are
deﬁned in terms of components and so it is not immediately apparent that
we have deﬁned a spinor at all. We must verify that the components of Ckl(ξ)
as deﬁned by (3.3.18) transform correctly, i.e., as the components of a spinor
of valence
 r−1
s
m−1
n

. But this is clearly the case since, in a new spin frame,
ˆξA1···A···Ar ˙X1··· ˙Xs
B1···A···Bm ˙Y1··· ˙Yn
= GA1C1 · · · GA
Ck · · · GAr Cr ¯G
˙X1 ˙U1 · · · ¯G
˙Xs ˙UsGB1
D1 · · · GA
Dl · · ·
GBm
Dm ¯G ˙Y1
˙V1 · · · ¯G ˙Yn
˙VnξC1···Ck···Cr ˙U1··· ˙Us
D1···Dl···Dm ˙Y1··· ˙Yn
=

GACkGA
Dl
GA1C1 · · · ¯G ˙Yn
˙VnξC1···Ck···Cr ˙U1··· ˙Us
D1···Dl···Dm ˙Y1··· ˙Yn
= δDl
CkGA1C1 · · · ¯G ˙Yn
˙VnξC1···Ck···Cr ˙U1··· ˙Us
D1···Dl···Dm ˙Y1··· ˙Yn
= GA1C1 · · · ¯G ˙Yn
˙VnξC1···A···Cr ˙U1··· ˙Us
D1···A···Dm ˙Y1··· ˙Yn.
One can, in the same way, contract a spinor ξ of valence
 r
s
m n

in two
dotted indices ˙k and ˙l, one upper and one lower, to obtain a spinor C ˙k˙l(ξ) of
valence
 r
s−1
m
n−1

. Observe that the processes of raising and lowering indices
discussed earlier are actually outer products (with an ϵ spinor) followed by a
contraction.
Exercise 3.3.6 Let φ be a spinor of valence
0
0
2
0

and denote its compo-
nents in a spin frame by φAB. Show that
1. φ1
1 = −φ10, φ0
0 = φ01, φ1
0 = φ11, φ0
1 = −φ00,
2. φ11 = φ00, φ00 = φ11, φ10 = −φ01, φ01 = −φ10,
3. φABφAB = 2 det
*φ11
φ10
φ01
φ00
+
= 2 det
*φ1
1
φ1
0
φ0
1
φ0
0
+
,
4. φAC φB C =
⎧
⎨
⎩
0,
A = B
det[φAB],
A = 0,
B = 1
−det[φAB],
A = 1,
B = 0.
Let ξ denote a spinor with the same number of dotted and undotted indices,
say, of valence
*r
r
0
0
+
. We deﬁne a new spinor denoted ¯ξ and called the

168
3 The Theory of Spinors
conjugate of ξ by specifying that its components ¯ξ ˙A1··· ˙ArX1···Xr in any spin
frame are given by
¯ξ
˙A1··· ˙ArX1···Xr = ξA1···Ar ˙X1··· ˙Xr
(here we must depart from our habit of selecting dotted/undotted indices
from the end/beginning of the alphabet). Thus, for example, if ξ has compo-
nents ξA ˙X, then the components of ¯ξ are given by ¯ξ ˙01 = ξ0˙1, ¯ξ ˙11 = ξ1˙1, etc.
Exercise 3.3.7 Show that we have actually deﬁned a spinor of the required
type by verifying the appropriate transformation law, i.e.,
¯ˆξ
˙A1··· ˙ArX1···Xr = ¯G
˙A1 ˙C1 · · · ¯G
˙Ar ˙CrGX1U1 · · · GXr Ur ¯ξ
˙C1··· ˙CrU1···Ur.
Entirely analogous deﬁnitions and results apply regardless of the positions
(upper or lower) of the indices, provided only that the number of dotted
indices is the same as the number of undotted indices. We shall say that
such a spinor ξ is Hermitian if ¯ξ = ξ. Thus, for example, if ξ is of va-
lence

r
r
0
0

, then it is Hermitian if ¯ξA1···Ar ˙X1··· ˙Xr = ξA1···Ar ˙X1··· ˙Xr for all
A1, . . . , Ar, ˙X1, . . . , ˙Xr, i.e., if
ξ ˙A1··· ˙ArX1···Xr = ξA1···Ar ˙X1··· ˙Xr,
e.g., if r = 1, ξ ˙01 = ξ0˙1, ξ0˙0 = ξ ˙00, etc.
As a multilinear functional a spinor ξ operates on four distinct types of
objects (elements of ß, ¯ß, ß∗and ¯ß
∗) and, if the valence is
 r
s
m n

, has
r + s + m + n “slots” (variables) into which these objects are inserted for
evaluation, each slot corresponding to an index position in our notation
for ξ’s components. If ξ has the property that, for two such slots of the
same type, ξ(. . . , p, . . . , q, . . .) = ξ(. . . , q, . . . , p, . . .) for all p and q of the
appropriate type, then ξ is said to be symmetric in these two variables (if
ξ(. . . , p, . . . , q, . . .) = −ξ(. . . , q, . . . , p, . . .), it is skew-symmetric). It follows at
once from the deﬁnition that ξ is symmetric (skew-symmetric) in the vari-
ables p and q if and only if the components of ξ in every spin frame are
unchanged (change sign) when the corresponding indices are interchanged.
We will be particularly interested in the case of spinors with just two indices.
Thus, for example, a spinor φ of valence
0
0
2
0

is symmetric (in its only two
variables) if and only if, in every spin frame, φBA = φAB for all A, B = 1, 0; φ
is skew-symmetric if φBA = −φAB for all A and B. On the other hand, an
arbitrary spinor ξ of valence
0
0
2
0

has a symmetrization whose components
in each spin frame are given by
ξ(AB) = 1
2(ξAB + ξBA)

3.4 Spinors and World Vectors
169
and a skew-symmetrization given by
ξ[AB] = 1
2(ξAB −ξBA).
The symmetrization (skew-symmetrization) of ξ clearly deﬁnes a spinor, also
of valence
0
0
2
0

, that is symmetric (skew-symmetric).
Exercise 3.3.8 Let α and β be two spin vectors. The outer product α ⊗β
is a spinor of valence

0
0
2
0

whose components in any spin frame are given
by αAβB, A, B = 1, 0. Let φ be the symmetrization of α ⊗β so that
φAB = α(AβB) = 1
2(αAβB + αBβA).
Show that φAB = 1
2(αAβB + αBβA) and that
φABφAB = −1
2 < α, β >2 .
3.4 Spinors and World Vectors
In this section we will establish a correspondence between spinors of valence
1
1
0
0

and vectors in Minkowski spacetime (also called world vectors
or 4-vectors). This correspondence, which we have actually seen before
(in Section 1.7), is most easily phrased in terms of the Pauli spin matrices.
Exercise 3.4.1 Let σ1 =
*0
1
1
0
+
, σ2 =
* 0
i
−i 0
+
, σ3 =
*1
0
0
−1
+
, and σ4 =
*
1
0
0
1
+
. Verify the following commutation relations:
σ12 = σ22 = σ32 = σ42 = σ4,
σ1σ2 = −σ2σ1 = −iσ3,
σ1σ3 = −σ3σ1 = iσ2,
σ2σ3 = −σ3σ2 = −iσ1.
For what follows it will be convenient to introduce a factor of
1
√
2 and some
rather peculiar looking indices, the signiﬁcance of which will become clear
shortly. Thus, for each A = 1, 0 and ˙X = ˙1, ˙0, we deﬁne matrices
σaA ˙X =
#
σa1˙1
σa1˙0
σa0˙1
σa0˙0
$
,
a = 1, 2, 3, 4,

170
3 The Theory of Spinors
by
σaA ˙X =
1
√
2σa,
a = 1, 2, 3, 4.
Thus,
σ1A ˙X =
1
√
2
*0
1
1
0
+
,
σ2A ˙X =
1
√
2
* 0
i
−i 0
+
,
σ3A ˙X =
1
√
2
*
1
0
0
−1
+
,
σ4A ˙X =
1
√
2
*
1
0
0
1
+
.
We again adopt the convention that the relative position of dotted and undot-
ted indices is immaterial so σaA ˙X = σa
˙XA. Undotted indices indicate rows;
dotted indices number the columns. Observe that each of these is a Hermitian
matrix, i.e., equals its conjugate transpose (Section 1.7).
Now we describe a procedure for taking a vector v ∈M, an admissible
basis {ea} for M and a spin frame {sA} and constructing from them a spinor
V of valence

1
1
0
0

. We do this by specifying the components of V in every
spin frame and verifying that they have the correct transformation law. We
begin by writing v = vaea. Deﬁne the components V A ˙X of V relative to
{sA} by
V A ˙X = σa
A ˙Xva,
A = 1, 0,
˙X = ˙1, ˙0.
(3.4.1)
Thus,
V 1˙1 =
1
√
2(v3 + v4),
V 1˙0 =
1
√
2(v1 + iv 2),
V 0˙1 =
1
√
2(v1 −iv 2),
(3.4.2)
V 0˙0 =
1
√
2(−v3 + v4)
(cf. Exercise 1.7.1). Now, suppose {ˆs1, ˆs0} is another spin frame, related to
{sA} by (3.2.1) (sB = GA
BˆsA) and (3.2.6) (ˆsA = GABsB). We deﬁne the
components ˆV A ˙X of V relative to {ˆsA} as follows: Let Λ = ΛG = Spin(G) be
the element of L that G maps onto under the spinor map and ˆva = Λabvb, a =
1, 2, 3, 4. Now let
ˆV A ˙X = σaA ˙Xˆva,
A = 1, 0,
˙X = ˙1, ˙0.
(3.4.3)

3.4 Spinors and World Vectors
171
That we have actually deﬁned a spinor of valence
1
1
0
0

is not obvious, of
course, since it is not clear that the V A ˙X transform correctly. To show this
we must prove that
ˆV A ˙X = GAB ¯G
˙X ˙Y V B ˙Y ,
A = 1, 0,
˙X = ˙1, ˙0.
(3.4.4)
For this we temporarily denote the right-hand side of (3.4.4) by ˜V A ˙X, i.e.,
˜V A ˙X = GAB ¯G ˙X
˙Y V B ˙Y . Writing this as a matrix product gives
⎡
⎢⎢⎢⎢⎢⎣
˜V 1˙1
˜V 1˙0
˜V 0˙1
˜V 0˙0
⎤
⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎣
G11 ¯G ˙1
˙1
G11 ¯G ˙1
˙0
G10 ¯G ˙1
˙1
G10 ¯G ˙1
˙0
G11 ¯G ˙0
˙1
G11 ¯G ˙0
˙0
G10 ¯G ˙0
˙1
G10 ¯G ˙0
˙0
G01 ¯G ˙1
˙1
G01 ¯G ˙1
˙0
G00 ¯G ˙1
˙1
G00 ¯G ˙1
˙0
G01 ¯G ˙0
˙1
G01 ¯G ˙0
˙0
G00 ¯G ˙0
˙1
G00 ¯G ˙0
˙0
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
V 1˙1
V 1˙0
V 0˙1
V 0˙0
⎤
⎥⎥⎥⎥⎥⎦
.
(3.4.5)
But if we let
G =
#
G11
G10
G01
G00
$
=
*α
β
γ
δ
+
,
then (3.4.5) becomes
⎡
⎢⎢⎢⎣
˜V 1˙1
˜V 1˙0
˜V 0˙1
˜V 0˙0
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
α¯α
α¯β
¯αβ
β ¯β
α¯γ
α¯δ
β¯γ
β¯δ
¯αγ
¯βγ
¯αδ
¯βδ
γ¯γ
γ¯δ
¯γδ
δ¯δ
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
V 1˙1
V 1˙0
V 0˙1
V 0˙0
⎤
⎥⎥⎥⎦.
(3.4.6)
Now, using (3.4.2) and the corresponding equalities for ˆV A ˙X it follows from
Exercise 1.7.2 (with the appropriate notational changes) that the right-hand
side of (3.4.6) is equal to
1
√
2
⎡
⎢⎢⎣
ˆv3 + ˆv4
ˆv1 + iˆv2
ˆv1 −iˆv2
−ˆv3 + ˆv4
⎤
⎥⎥⎦=
⎡
⎢⎢⎢⎣
ˆV 1˙1
ˆV 1˙0
ˆV 0˙1
ˆV 0˙0
⎤
⎥⎥⎥⎦,
where the ˆva are the images of the va under Λ = ΛG. Substituting this into
(3.4.6) then gives [ ˜V A ˙X] = [ ˆV A ˙X] and this proves (3.4.4). Observe that, since
#
G11
G10
G01
G00
$
= −
#
G11
G10
G01
G00
$
,
(3.4.4) can also be written as
ˆV A ˙X = GA
B ¯G
˙X ˙Y V B ˙Y ,
A = 1, 0,
˙X = ˙1, ˙0.
(3.4.7)

172
3 The Theory of Spinors
We conclude then that the procedure we have described does indeed deﬁne a
spinor of valence
1 1
0 0

which we shall call the spinor equivalent of v ∈M
(somewhat imprecisely since V depends not only on v, but also on the initial
choices of {ea} and {sA}). Observe that the conjugate ¯V of V has components
¯V A ˙X = V ˙AX = σa
˙AXva = σa
˙AXva = σaA ˙Xva = V A ˙X since the matrices
σaA ˙X are Hermitian and the va are real. Thus, the spinor equivalent of any
world vector is a Hermitian spinor.
With (3.4.4) we can now justify the odd arrangement of indices in the
symbols σaA ˙X by showing that the σaA ˙X are constant under the combined
eﬀect of a G ∈SL(2, C) and the corresponding Λ = ΛG in L, i.e., that
Λa
bGAB ¯G
˙X
˙Y σbB ˙Y = σaA ˙X,
a = 1, 2, 3, 4, A = 1, 0,
˙X = ˙1, ˙0
(3.4.8)
(one might say that the σaA ˙X are the components of a constant “spinor-
covector”). To see this we select an arbitrary admissible basis and spin frame.
Fix A and ˙X. Now let v = vaea be an arbitrary vector in M. Then V A ˙X =
σaA ˙Xva. In another spin frame, related to the original by G, we have
ˆV A ˙X = σa
A ˙Xˆva.
But also,
ˆV A ˙X = GAB ¯G
˙X
˙Y V B ˙Y = GAB ¯G
˙X
˙Y

σbB ˙Y vb
= GA
B ¯G
˙X
˙Y σb
B ˙Y 
δb
cvc
= GAB ¯G
˙X
˙Y σbB ˙Y 
Λa
bΛacvc
= Λa
bGAB ¯G
˙X
˙Y σbB ˙Y (Λacvc)
= Λa
bGAB ¯G
˙X
˙Y σbB ˙Y ˆva.
Thus,
Λa
bGAB ¯G
˙X
˙Y σbB ˙Y ˆva = σaA ˙Xˆva.
But v was arbitrary so we may successively select v’s that give (ˆv1, ˆv2, ˆv3, ˆv4)
equal to (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) and (0, 0, 0, 1) and thereby obtain
(3.4.8) for a = 1, 2, 3 and 4, respectively. Since

GAB

= −

GAB

we again
ﬁnd that (3.4.8) can be written
Λa
bGAB ¯G
˙X
˙Y σbB ˙Y = σaA ˙X,
a = 1, 2, 3, 4, A = 1, 0,
˙X = ˙1, ˙0.
(3.4.9)
Exercise 3.4.2 Show that
GAB ¯G
˙X
˙Y σaB ˙Y = ΛαaσαA ˙X,
a = 1, 2, 3, 4, A = 1, 0,
˙X = ˙1, ˙0.
(3.4.10)

3.4 Spinors and World Vectors
173
From all of this we conclude that the σaA ˙X behave formally like a combined
world covector and spinor of valence
1
1
0
0

. Treating them as such we raise
the index a and lower A and ˙X, i.e., we deﬁne
σa
A ˙X = ηab
σb
B ˙Y ϵBA

¯ϵ ˙Y ˙X
for a = 1, 2, 3, 4, A = 1, 0 and ˙X = ˙1, ˙0. Thus, for example, if a = 1, σ1
A ˙X =
η1b 
σbB ˙Y ϵBA

¯ϵ ˙Y ˙X = η11 
σ1B ˙Y ϵBA

¯ϵ ˙Y ˙X = σ1B ˙Y ϵBA¯ϵ ˙Y ˙X. If A = 1, this
becomes σ1
1 ˙X = σ1B ˙Y ϵB1¯ϵ ˙Y ˙X = σ10 ˙Y ϵ01¯ϵ ˙Y ˙X = σ10 ˙Y ¯ϵ ˙Y ˙X = σ10˙1¯ϵ˙1 ˙X +
σ10˙0¯ϵ˙0 ˙X. Thus, for
˙X = ˙1, σ1
1˙1 = σ10˙1¯ϵ˙1˙1 + σ10˙0¯ϵ˙0˙1 = σ10˙0 = 0 and, for
˙X = ˙0, σ1
1˙0 = σ10˙1¯ϵ˙1˙0 + σ10˙0¯ϵ˙0˙0 = −σ10˙1 = −1
√
2. Similarly, σ1
0˙1 = −1
√
2
and σ1
0˙0 = 0 so
σ1
A ˙X =
*σ1
1˙1
σ1
1˙0
σ1
0˙1
σ1
0˙0
+
= −1
√
2
*0
1
1
0
+
= −σ1A ˙X.
Exercise 3.4.3 Continue in this way to prove the remaining equalities in
σ1
A ˙X = −σ1A ˙X = −1
√
2
*
0
1
1
0
+
,
σ2
A ˙X = σ2A ˙X =
1
√
2
*
0
i
−i 0
+
,
σ3
A ˙X = −σ3A ˙X = −1
√
2
*
1
0
0
−1
+
,
σ4
A ˙X = −σ4A ˙X = −1
√
2
*1
0
0
1
+
.
(3.4.11)
We enumerate a number of useful properties of these so-called Infeld-van der
Waerden symbols σaA ˙X and σa
A ˙X.
σa
A ˙X = ηab¯ϵ
˙X ˙Y 
ϵABσb
B ˙Y

,
(3.4.12)
σa
A ˙Xσb
A ˙X = −δb
a,
(3.4.13)
σaA ˙Xσa
B ˙Y = −δA
Bδ
˙X
˙Y ,
(3.4.14)
σaA ˙Xσa
B ˙Y σbB ˙Y = −σbA ˙X.
(3.4.15)
For the proof of (3.4.12) we insert σb
B ˙Y = ηbc(σcC ˙ZϵCB)¯ϵ ˙Z ˙Y into the right-
hand side to obtain
ηab¯ϵ
˙X ˙Y 
ϵABσb
B ˙Y

= ηab¯ϵ
˙X ˙Y ϵABηbcσcC ˙ZϵCB¯ϵ ˙Z ˙Y
= (ηabηbc)(¯ϵ
˙X ˙Y ¯ϵ ˙Z ˙Y )(ϵABϵCB)σcC ˙Z

174
3 The Theory of Spinors
= δc
aδ
˙X
˙Z δA
CσcC ˙Z
= σaA ˙X,
where we have used (3.3.5) and its barred and dotted equivalent.
Exercise 3.4.4 Prove (3.4.13), (3.4.14) and (3.4.15).
Similar exercises in index gymnastics yield the analogues of (3.4.8) and
(3.4.10):
ΛabGA
B ¯G ˙X
˙Y σb
B ˙Y = σa
A ˙X
(3.4.16)
and
GA
B ¯G ˙X
˙Y σa
B ˙Y = Λα
aσα
A ˙X.
(3.4.17)
Exercise 3.4.5 Prove (3.4.16) and (3.4.17) and use (3.4.16) to show that
GAB ¯G
˙X ˙Y σa
A ˙X = Λabσb
B ˙Y .
(3.4.18)
Given v ∈M, {ea} and {sA} we have constructed a spinor V A ˙X =
σaA ˙Xva. The σa
A ˙X allow us to retrieve the va from the V A ˙X. Indeed, mul-
tiplying on both sides of V A ˙X = σbA ˙Xvb by σa
A ˙X and summing as indi-
cated gives
V A ˙Xσa
A ˙X = σa
A ˙XσbA ˙Xvb
= −δa
b vb
= −va,
so
va = −V A ˙Xσa
A ˙X,
a = 1, 2, 3, 4.
(3.4.19)
Note that if the V A ˙X were the components of an arbitrary spinor of valence
1
1
0
0

, then the numbers −V A ˙Xσa
A ˙X would, in general, be complex and
so would not be the components of any world vector. However, we show
next that if V A ˙X is Hermitian, then the −V A ˙Xσa
A ˙X are real and, moreover,
determine a world vector. Indeed,
V A ˙Xσa
A ˙X = V 1˙1σa
1˙1 + V 1˙0σa
1˙0 + V 0˙1σa
0˙1 + V 0˙0σa
0˙0
= V 1˙1σa
1˙1 + V 1˙0σa
1˙0 + V 0˙1σa
0˙1 + V 0˙0σa
0˙0
= V ˙11σa
1˙1 + V ˙01σa ˙01 + V ˙10σa ˙10 + V ˙00σa
0˙0
= ¯V 1˙1¯σa
1˙1 + ¯V 0˙1¯σa
0˙1 + ¯V 1˙0¯σa
1˙0 + ¯V 0˙0¯σa
0˙0
= V 1˙1σa
1˙1 + V 0˙1σa
0˙1 + V 1˙0σa
1˙0 + V 0˙0σa
0˙0
= V A ˙Xσa
A ˙X
and so V A ˙Xσa
A ˙X is real.

3.4 Spinors and World Vectors
175
Exercise 3.4.6 Show that if V A ˙X is a spinor that satisﬁes ¯V A ˙X = −V A ˙X,
then V A ˙Xσa
A ˙X is pure imaginary so iV A ˙X is Hermitian.
Now, given a Hermitian spinor V of valence

1 1
0 0

, a spin frame {sA} and an
admissible basis {ea}, we deﬁne a vector v ∈M by specifying its components
in every admissible basis in the following way: Write V = V A ˙XsA ⊗¯s ˙X and
deﬁne the components va of v relative to {ea} by
va = −V A ˙Xσa
A ˙X,
a = 1, 2, 3, 4.
Next suppose {ˆea} is another admissible basis for M, related to {ea} by
Λ ∈L. Let Λ = Λ±G = Spin(±G) and let {ˆsA} be the spin frame related to
{sA} by G (or −G). Then V = ˆV A ˙X ˆsA ⊗¯ˆs ˙X, where ˆV A ˙X = GAB ¯G ˙X
˙Y V B ˙Y
(−G gives the same components). We deﬁne the components of v relative to
{ˆea} by
ˆva = −ˆV A ˙Xσa
A ˙X,
a = 1, 2, 3, 4.
To justify the deﬁnition we must, as usual, verify that the va transform
correctly, i.e., that Λabvb = −ˆV A ˙Xσa
A ˙X. But
−ˆV A ˙Xσa
A ˙X = −GA
B ¯G
˙X ˙Y V B ˙Y σa
A ˙X
= −

GAB ¯G
˙X ˙Y σa
A ˙X

V B ˙Y
= −

Λabσb
B ˙Y

V B ˙Y
by
(3.4.18)
= Λab

−V B ˙Y σb
B ˙Y

= Λabvb
as required. We summarize:
Theorem 3.4.1 Let {ea} be an admissible basis for M and {sA} a spin
frame for ß. The map which assigns to each vector v ∈M (v = vaea) its
spinor equivalent (V = V A ˙XsA ⊗¯s ˙X, where V A ˙X = σaA ˙Xva) is one-to-one
and onto the set of all Hermitian spinors of valence

1
1
0
0

.
Recall (Section 3.1) that every v ∈M gives rise to a v∗∈M∗(the
dual of M) deﬁned by v∗(u) = v · u and that every element of M∗, i.e.,
every covector, arises in this way from some v ∈M. Moreover, if {ea} is an
admissible basis for M and {ea} is its dual basis for M∗and if v = vaea,
then v∗= vaea, where va = ηaαvα. Now, for A = 1, 0 and ˙X = ˙1, ˙0, deﬁne
VA ˙X = σa
A ˙Xva.
(3.4.20)

176
3 The Theory of Spinors
Exercise 3.4.7 Show that
VA ˙X = V B ˙Y ϵBA¯ϵ ˙Y ˙X,
(3.4.21)
where V B ˙Y = σbB ˙Y vb.
Since V B ˙Y are the components, relative to a spin frame {sA}, of a spinor of
valence
1
1
0
0

and (3.4.21) exhibits the VA ˙X as the result of two successive
contracted outer products of this spinor (with ϵ and ¯ϵ), we conclude that
the VA ˙X are the components, relative to {sA}, of a spinor of valence
0
0
1
1

which we call the spinor equivalent of the covector v∗.
Exercise 3.4.8 Show that, in another spin frame {ˆsA} related to {sA} by
(3.2.1) and (3.2.6),
ˆVA ˙X = σa
A ˙Xˆva,
(3.4.22)
where ˆva = Λa
bvb, Λ being Λ±G.
Theorem 3.4.2 Let {ea} be an admissible basis for M and {sA} a spin
frame for ß. The map which assigns to each covector v∗∈M∗(v∗= vaea)
its spinor equivalent (VA ˙XsA ⊗¯s ˙X, where VA ˙X = σa
A ˙Xva) is one-to-one and
onto the set of all Hermitian spinors of valence
0
0
1
1

.
Exercise 3.4.9 Complete the proof of Theorem 3.4.2.
■
Now, let us ﬁx an admissible basis {ea} and a spin frame {sA}. Let v =
vaea and u = uaea be in M and V = V A ˙XsA ⊗¯s ˙X and U = U A ˙XsA ⊗¯s ˙X the
spinor equivalents of v and u. We compute UA ˙XV A ˙X = (σa
A ˙Xua)(σbA ˙Xvb) =
(uavb)(σa
A ˙XσbA ˙X) = uavb(−δa
b ) = −uava = −ηabubva = −u · v so
UA ˙XV A ˙X = −u · v.
(3.4.23)
Observe that if we let
[V A ˙X] =
#
V 1˙1
V 1˙0
V 0˙1
V 0˙0
$
=
1
√
2
*
v3 + v4
v1 + iv 2
v1 −iv 2
−v3 + v4
+
,
then det[V A ˙X] = −1
2v · v so
VA ˙XV A ˙X = 2 det[V A ˙X] = −v · v.
(3.4.24)
Consequently, if v is null, det[V A ˙X] = 0 so, assuming v ̸= 0, [V A ˙X] has
rank 1.

3.4 Spinors and World Vectors
177
Exercise 3.4.10 Show that if
*a
b
c
d
+
is a 2 × 2 complex matrix of rank 1,
then there exist pairs (φ1, φ0) and (ψ1, ψ0) of complex numbers such that
*a
b
c
d
+
=
*φ1
φ0
+ ,
¯ψ ˙1
¯ψ ˙0-
=
#
φ1 ¯ψ ˙1
φ1 ¯ψ ˙0
φ0 ¯ψ ˙1
φ0 ¯ψ ˙0
$
.
Consequently, if v ∈M is null and nonzero we may write V A ˙X = φA ¯ψ ˙X for
A = 1, 0 and ˙X = ˙1, ˙0. Observe that, in another spin frame,
ˆV A ˙X = GAB ¯G
˙X
˙Y V B ˙Y
= GAB ¯G
˙X
˙Y φB ¯ψ
˙Y
=

GABφB 
¯G
˙X
˙Y ¯ψ
˙Y 
.
Thus, if we deﬁne ˆφA = GABφB and ¯ˆψ ˙X = ¯G ˙X
˙Y ¯ψ ˙Y , then
ˆV A ˙X = ˆφA ¯ˆψ
˙X.
Consequently, if we let φ be the spin vector whose components in {sA} are φA
and ¯ψ be the conjugate spin vector whose components in {¯sA} are ¯ψ ˙X, then
V is the outer product φ ⊗¯ψ of φ and ¯ψ. Even more can be said, however.
Exercise 3.4.11 Suppose z1 and z2 are two complex numbers for which
z1¯z2 is real. Show that one of z1 or z2 is a real multiple of the other.
Now, V 1˙1 and V 0˙0 are both real (±v3 + v4) so φ1 ¯ψ ˙1 and φ0 ¯ψ ˙0 are real
and, since v is null, but not zero, not both can be zero. Exercise 3.4.11 gives
an r1 ∈R such that either ψ1 = r1φ1 or φ1 = r1ψ1 and also an r0 ∈R such
that either ψ0 = r0φ0 or φ0 = r0ψ0. Since at least one of r1 or r0 is nonzero
we may assume without loss of generality that
*
ψ1
ψ0
+
=
*
r1φ1
r0φ0
+
.
We claim that, in fact, there exists a single real number r such that
*
ψ1
ψ0
+
= r
*
φ1
φ0
+
.
(3.4.25)
To prove this we ﬁrst suppose φ1 = 0. Then ψ1 = 0 so
*ψ1
ψ0
+
=
* 0
ψ0
+
=
r0
*
0
φ0
+
= r0
*
φ1
φ0
+
. Similarly, if φ0 = 0, then
*
ψ1
ψ0
+
= r1
*
φ1
φ0
+
. Now, suppose
neither φ1 nor φ0 is zero. Then, since V 1˙0 = V 0˙1,

178
3 The Theory of Spinors
φ1 ¯ψ ˙0 = φ0 ¯ψ ˙1,
¯φ
˙1ψ0 = φ0 ¯ψ ˙1,
(3.4.26)
¯φ˙1
φ0 ψ0 = ¯ψ
˙1.
Thus, ¯ψ ˙1 = 0 would give ψ0 = 0 and ψ1 = 0 so [V A ˙X] =
*0
0
0
0
+
and this gives
v1 = v2 = v3 = v4 = 0, contrary to our assumption that v ̸= 0. Similarly,
ψ0 = 0 implies v = 0, again a contradiction. Thus, ψ1 and ψ0 are nonzero so
(3.4.26) gives
¯φ˙1
φ0 =
¯ψ ˙1
ψ0 = r1 ¯φ˙1
r0φ0
(since r1 ∈R). Consequently, r1 = r0 so
*ψ1
ψ0
+
=
*r1φ1
r1φ0
+
= r1
*φ1
φ0
+
and
(3.4.25) is proved with r = r1. From this it follows that
V A ˙X = φA ¯ψ
˙X = φA(r ¯φ
˙X)
= ±

|r|
1
2 φA 
|r|
1
2 ¯φ
˙X
(+ if r > 0 and −if r < 0). Now we deﬁne a spin vector ξ by ξA = |r|
1
2 φA
(relative to {sA}). Then ¯ξ ˙X = |r|
1
2 ¯φ ˙X since |r|
1
2 is real. Thus,
V A ˙X = ±ξA ¯ξ
˙X.
Finally, observe that v3 + v4 = V 1˙1 = rφ1 ¯φ˙1 and −v3 + v4 = V 0˙0 = rφ0 ¯φ˙0 so
v4 = 1
2r

|φ1|
1
2 + |φ0|
1
2

and, in particular, r > 0 if and only if v4 > 0. We have therefore proved
Theorem 3.4.3 Let {ea} be an admissible basis for M and {sA} a spin
frame for ß. Let v ∈M be a nonzero null vector, v = vaea, and V its spinor
equivalent, V = V A ˙XsA ⊗¯s ˙X = (σaA ˙Xva)sA ⊗¯s ˙X. Then there exists a spin
vector ξ such that:
(a) If v is future-directed, then
V A ˙X = ξA ¯ξ
˙X,
and,
(b) If v is past-directed, then
V A ˙X = −ξA ¯ξ
˙X.

3.5 Bivectors and Null Flags
179
Notice that ξ in the theorem is certainly not unique since if νA = eiθξA
(θ ∈R), then ¯ν ˙X = e−iθ ¯ξ ˙X so νA¯ν ˙X = ξA ¯ξ ˙X = V A ˙X.
Observe that the process we have just described can be reversed as well.
That is, given a nonzero spin vector ξA we deﬁne the spinor V A ˙X = ξA ¯ξ ˙X.
Then det[V A ˙X] = ξ1 ¯ξ ˙1ξ0 ¯ξ ˙0 −ξ1 ¯ξ ˙0ξ0 ¯ξ ˙1 = 0 so the vector equivalent va =
−σa
A ˙XV A ˙X gives a null vector v ∈M and, moreover, v4 = −V A ˙Xσ4
A ˙X =
−

−1
√
2
 
V 1˙1σ4
1˙1 + V 0˙0σ4
0˙0

=
1
√
2(V 1˙1 + V 0˙0) =
1
√
2(ξ1 ¯ξ ˙1 + ξ0¯ξ ˙0) =
1
√
2(|ξ1|2 + |ξ0|2) > 0 so v is future-directed. Thus, every nonzero spin vector
ξ gives rise in a natural way to a future-directed null vector v which we will
call the ﬂagpole of ξ and which will play a prominant role in the geometrical
representation of ξ that we construct in the next section.
3.5 Bivectors and Null Flags
We recall (Section 2.7) that a bivector on M is a real-valued bilinear form
˜F : M × M →R that is skew-symmetric ( ˜F(u, v) = −˜F(v, u) for all u
and v in M). Thus, ˜F is a skew-symmetric world tensor of covariant rank
2 and contravariant rank 0. We have already seen that bivectors are useful
for the description of electromagnetic ﬁelds and will return to their role in
electromagnetic theory in the next section. For the present our objective
is to ﬁnd a “spinor equivalent” for an arbitrary bivector, show how a spin
vector gives rise, in a natural way, to a bivector and construct from it a
geometrical representation (“up to sign”) for an arbitrary nonzero spin vector.
This geometrical picture of a spin vector, called a “null ﬂag”, emphasizes
what is perhaps its most fundamental characteristic, that is, an essential
“two-valuedness”.
Now ﬁx an admissible basis {ea} for M and a spin frame {sA} for ß.
The components of ˜F relative to {ea} are given by Fab = ˜F(ea, eb) and, by
skew-symmetry, satisfy
Fab = 1
2(Fab −Fba) = F[ab].
(3.5.1)
For A, B = 1, 0 and ˙X, ˙Y = ˙1, ˙0 we deﬁne
FA ˙XB ˙Y = FAB ˙X ˙Y = σa
A ˙Xσb
B ˙Y Fab
and take these to be the components of the spinor equivalent of
˜F relative
to {sA}. Thus, in another spin frame {ˆsA}, related to {sA} by (3.2.1) and
(3.2.6),
ˆFA ˙XB ˙Y = GA
A1 ¯G
˙X1
˙X
GB
B1 ¯G
˙Y1
˙Y
FA1 ˙X1B1 ˙Y1
= GA
A1 ¯G
˙X1
˙X
GB
B1 ¯G
˙Y1
˙Y

σα
A1 ˙X1σβ
B1 ˙Y1Fαβ


180
3 The Theory of Spinors
=

GA
A1 ¯G
˙X1
˙X
σα
A1 ˙X1
 
GB
B1 ¯G
˙Y1
˙Y
σβ
B1 ˙Y1

Fαβ
= (Λa
ασa
A ˙X)

Λb
βσb
B ˙Y

Fαβ
by (3.4.17)
= σa
A ˙Xσb
B ˙Y

Λa
αΛb
βFαβ

,
where Λ = ΛG. Thus,
ˆFA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y ˆFab.
(3.5.2)
We list some useful properties of the spinor equivalent of a bivector.
Fab = σaA ˙XσbB ˙Y FA ˙XB ˙Y ,
a, b = 1, 2, 3, 4,
(3.5.3)
¯FA ˙XB ˙Y = FA ˙XB ˙Y ,
i.e., FA ˙XB ˙Y is Hermitian,
(3.5.4)
FB ˙Y A ˙X = −FA ˙XB ˙Y .
(3.5.5)
The proof of (3.5.5) proceeds as follows: FB ˙Y A ˙X
= σa
B ˙Y σb
A ˙XFab
=
σa
B ˙Y σb
A ˙X(−Fba) = −σb
A ˙Xσa
B ˙Y Fba = −σa
A ˙Xσb
B ˙Y Fab = −FA ˙XB ˙Y .
Exercise 3.5.1 Prove (3.5.3) and (3.5.4).
Now we use (3.5.5) to write
FA ˙XB ˙Y = 1
2[FA ˙XB ˙Y −FB ˙Y A ˙X]
= 1
2[FA ˙XB ˙Y −FB ˙XA ˙Y + FB ˙XA ˙Y −FB ˙Y A ˙X]
= 1
2[FA ˙XB ˙Y −FB ˙XA ˙Y ] + 1
2[FB ˙XA ˙Y −FB ˙Y A ˙X].
Observe that by (3.3.14), ϵABϵCDFC ˙XD ˙Y
=

δC
AδD
B −δD
A δC
B

FC ˙XD ˙Y
=
FA ˙XB ˙Y −FB ˙XA ˙Y and, similarly, ¯ϵ ˙X ˙Y ¯ϵ ˙U ˙V FB ˙UA ˙V = FB ˙XA ˙Y −FB ˙Y A ˙X so
FA ˙XB ˙Y = 1
2ϵABϵCDFC ˙XD ˙Y + 1
2¯ϵ ˙X ˙Y ¯ϵ
˙U ˙V FB ˙UA ˙V
= ϵAB
 1
2ϵCDFC ˙XD ˙Y

+ ¯ϵ ˙X ˙Y

1
2ϵ
˙U ˙V FB ˙UA ˙V

= ϵAB
 1
2FC ˙X
C
˙Y

+ ¯ϵ ˙X ˙Y

1
2FB ˙UA
˙U
FA ˙XB ˙Y = ϵAB
 1
2FC ˙X
C
˙Y

+ ¯ϵ ˙X ˙Y

1
2F ˙UB
˙U
A

(3.5.6)
Now deﬁne φAB by
φAB = 1
2F ˙UA
˙U
B,
A, B = 1, 0.

3.5 Bivectors and Null Flags
181
Then we claim that
φBA = φAB
(3.5.7)
and
¯φ ˙X ˙Y = 1
2FC ˙X
C
˙Y .
(3.5.8)
To prove (3.5.7) we compute
φBA = 1
2F ˙UB
˙U
A = −1
2F
˙U
A ˙UB
by (3.5.5)
= −1
2
,
¯ϵ
˙U ˙V F ˙V A
˙W
B¯ϵ ˙W ˙U
-
= −1
2
,
F ˙V A
˙W
B

¯ϵ
˙U ˙V ¯ϵ ˙W ˙U
-
= −1
2
,
F ˙V A
˙W
B

−¯ϵ
˙U ˙V ¯ϵ ˙U ˙W
-
= −1
2
,
F ˙V A
˙W
B

−δ
˙V
˙W
-
= 1
2F ˙V A
˙V
B = φAB.
Exercise 3.5.2 Prove (3.5.8).
With this we may write (3.5.6) as
FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y .
(3.5.9)
We observe next that the process which just led us from ˜F to FA ˙XB ˙Y to
φAB can be reversed in the following sense: Given a symmetric spinor φAB
of valence

0
0
2
0

we can deﬁne FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y and obtain a
spinor of valence
0
0
2
2

which satisﬁes (3.5.4) since ¯FA ˙XB ˙Y = (F ˙AX ˙BY ) =
(FX ˙AY ˙B) = (ϵXY ¯φ ˙A ˙B + φXY ¯ϵ ˙A ˙B) = ¯ϵ ˙X ˙Y φAB + ¯φ ˙X ˙Y ϵAB = ϵAB ¯φ ˙X ˙Y +
φAB¯ϵ ˙X ˙Y = FA ˙XB ˙Y , and (3.5.5) since FB ˙Y A ˙X = ϵBA ¯φ ˙Y
˙X + φBA¯ϵ ˙Y ˙X =
(−ϵAB)¯φ ˙X ˙Y + φAB(−¯ϵ ˙X ˙Y ) = −FA ˙XB ˙Y . Now deﬁne Fab by (3.5.3), i.e.,
Fab = σaA ˙XσbB ˙Y FA ˙XB ˙Y .
Relative to another spin frame {ˆsA}, related to {sA} by (3.2.1) and (3.2.6),
ˆFA ˙XB ˙Y = GA
A1 ¯G ˙X
˙X1GB
B1 ¯G ˙Y
˙Y1FA1 ˙X1B1 ˙Y1.
Exercise 3.5.3 Show that σaA ˙XσbB ˙Y ˆFA ˙XB ˙Y = Λa
αΛb
βFαβ, where Λ = ΛG.
Thus, deﬁning ˆFab = σaA ˙XσbB ˙Y ˆFA ˙XB ˙Y , we ﬁnd that the Fab transform as
the components of a bivector and we may deﬁne ˜F : M × M →R by

182
3 The Theory of Spinors
˜F(u, v) = ˜F(uaea, vbeb)
= ˜F(ea, eb)uavb
= Fabuavb
relative to any admissible basis. Thus, every symmetric spinor φ of valence
0
0
2
0

gives rise, in a natural way, to a bivector ˜F.
Next we use the information accumulated thus far to construct a geomet-
rical representation (“up to sign”) of an arbitrary nonzero spin vector ξ. We
begin, as at the end of Section 3.4, by constructing the ﬂagpole v of ξ (the
future-directed null vector equivalent of V A ˙X = ξA ¯ξ ˙X). Observe that every
spin vector in the family {eiθξ : θ ∈R} has the same ﬂagpole as ξ since, if ξA
is replaced by eiθξA, then ¯ξ ˙X becomes e−iθ ¯ξ ˙X and (eiθξA)(e−iθ ¯ξ ˙X) = ξA ¯ξ ˙X.
We call eiθ the phase factor of the corresponding member of the family.
Exercise 3.5.4 Show that, conversely, if ψ is a spin vector with the same
ﬂagpole as ξ, then ψA = eiθξA for some θ ∈R. Hint: Write out v1, v2, v3 and
v4 in terms of ξA and ψA, show that ψ1 = eiθ1ξ1 and ψ0 = eiθ0ξ0 and then
show θ1 = θ0 + 2nπ for some n = 0, ±1, . . ..
Our geometrical representation of ξ must therefore contain more than just
the ﬂagpole if it is to distinguish spin vectors which diﬀer only by a phase
factor. To determine this additional element in the picture we now observe
that ξ also determines a symmetric spinor φ of valence
0
0
2
0

deﬁned by
φAB = ξAξB.
As we saw in the discussion following (3.5.9), φAB gives rise to a spinor of
valence
0
0
2
2

deﬁned by
FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y ,
which satisﬁes (3.5.4) and (3.5.5) and which, in turn, determines a bivector
˜F given by Fab = σaA ˙XσbB ˙Y FA ˙XB ˙Y , i.e.,
Fab = σaA ˙XσbB ˙Y (ϵAB ¯ξ ˙X ¯ξ ˙Y + ξAξB¯ϵ ˙X ˙Y ).
(3.5.10)
To simplify (3.5.10) we select a spin vector η which, together with ξ, form a
spin frame {ξ, η} with
< η, ξ > = ξAηA = 1 = −ξAηA.
Exercise 3.5.5 Show that
ξAηB −ξBηA = ϵAB
(3.5.11)

3.5 Bivectors and Null Flags
183
and
¯ξ ˙X ¯η ˙Y −¯ξ ˙Y ¯η ˙X = ¯ϵ ˙X ˙Y .
(3.5.12)
Substitute (3.5.11) and (3.5.12) into (3.5.10) to obtain
Fab = σaA ˙XσbB ˙Y [(ξAηB −ξBηA)¯ξ ˙X ¯ξ ˙Y + (¯ξ ˙X ¯η ˙Y −¯ξ ˙Y ¯η ˙X)ξAξB]
= σa
A ˙Xσb
B ˙Y ξAηB ¯ξ ˙X ¯ξ ˙Y −σa
A ˙Xσb
B ˙Y ξBηA ¯ξ ˙X ¯ξ ˙Y
+ σaA ˙XσbB ˙Y ¯ξ ˙X ¯η ˙Y ξAξB −σaA ˙XσbB ˙Y ¯ξ ˙Y ¯η ˙XξAξB
=

σaA ˙XξA ¯ξ ˙X
 
σbB ˙Y ηB ¯ξ ˙Y + σbB ˙Y ξB ¯η ˙Y

−

σbB ˙Y ξB ¯ξ ˙Y
 
σaA ˙XηA ¯ξ ˙X + σaA ˙XξA¯η ˙X

= vaσbB ˙Y (ηB ¯ξ ˙Y + ξB ¯η ˙Y ) −vbσaA ˙X(ηA ¯ξ ˙X + ξA¯η ˙X).
Now deﬁne a spinor of valence
0
0
1
1

by
WA ˙X = ηA ¯ξ ˙X + ξA¯η ˙X
and observe that WA ˙X is Hermitian since ¯
WA ˙X = W ˙AX = (¯η ˙AξX + ¯ξ ˙AηX) =
ηA ¯ξ ˙X + ξA¯η ˙X = WA ˙X. Consequently (Theorem 3.4.2), we may deﬁne a cov-
ector w∗∈M∗by
wa = −σaA ˙XWA ˙X = −σaA ˙X(ηA ¯ξ ˙X + ξA¯η ˙X).
Thus, our expression for Fab now becomes
Fab = vbwa −vawb.
(3.5.13)
Notice that, by (3.4.22),
v · w = −V A ˙XWA ˙X = −ξA ¯ξ
˙X(ηA ¯ξ ˙X + ξA¯η ˙X)
= −ξAηA(¯ξ
˙X ¯ξ ˙X) −¯ξ
˙X ¯η ˙X(ξAξA)
= −(−1)(0) −(−1)(0)
= 0.
Thus, w is orthogonal to v. Since v is null, w is spacelike.
Exercise 3.5.6 Show that, in fact, w · w = 2.
Thus far we have found that the spin vector ξ determines a future-directed
null vector v (its ﬂagpole) and a bivector Fab = vbwa −vawb, where w is a
spacelike vector orthogonal to v. However, w is not uniquely determined by ξ
since our choice for the “spinor mate” η for ξ is not unique. We now examine
the eﬀect on w of making a diﬀerent selection ˜η for η (still with < ˜η, ξ > = 1).

184
3 The Theory of Spinors
But < η, ξ > = < ˜η, ξ > = 1 implies < η −˜η, ξ > = < η, ξ > −< ˜η, ξ > =
1 −1 = 0 so, by (g) of Lemma 3.2.1 and the fact that ξ is not the zero
element of ß, ˜η −η = λξ for some λ ∈C, i.e.,
˜η = η + λξ.
The new vector ˜w is then determined by
˜wa = −σaA ˙X(˜ηA ¯ξ ˙X + ξA¯˜η ˙X)
= −σa
A ˙X((ηA + λξA)¯ξ ˙X + ξA(¯η ˙X + ¯λ¯ξ ˙X))
= −σa
A ˙X(ηA ¯ξ ˙X + ξA¯η ˙X) −(λ + ¯λ)σa
A ˙XξA ¯ξ ˙X
= wa + (λ + ¯λ)va,
Fig. 3.5.1
so
˜w = w + (λ + ¯λ)v.
(3.5.14)
It follows that ˜w lies in the 2-dimensional plane spanned by v and w and is
a spacelike vector orthogonal to v (again, ˜w · ˜w = 2). Thus, ξ uniquely de-
termines a future-directed null vector v and a 2-dimensional plane spanned
by v and any of the spacelike vectors w, ˜w, . . . determined by (3.5.14). This
2-dimensional plane lies in the 3-dimensional subspace (Span{v})⊥, which is
tangent to the null cone along v. In a 3-dimensional picture, the null cone
and (Span{v})⊥appear 2-dimensional so this 2-dimensional plane is a line.
However, to stress its 2-dimensionality we shall draw it as a “ﬂag” along v
as in Figure 3.5.1. The pair consisting of v and this 2-dimensional plane in

3.5 Bivectors and Null Flags
185
(Span{v})⊥is called the null ﬂag of ξ and is, we claim, an accurate geomet-
rical representation of ξ “up to sign”. To see this we examine the eﬀect of a
phase change
ξA −→eiθξA
(θ ∈R).
Of course, the ﬂagpole v is unchanged, but ¯ξ ˙X
→e−iθ ¯ξ ˙X so Fab
→
σaA ˙XσbB ˙Y (e−2θiϵAB ¯ξ ˙X ¯ξ ˙Y + e2θiξAξB¯ϵ ˙X ˙Y ). A spinor mate for eiθξA must
have the property that its ß-inner product with eiθξA is 1. Since dim ß = 2,
it must be of the form
e−iθηA + kξA
for some k ∈C. Thus,
wa −→−σaA ˙X[(e−iθηA + kξA)(e−iθ ¯ξ ˙X) + (eiθξA)(eiθ¯η ˙X + ¯k¯ξ ˙X)]
= −σaA ˙X[e−2θiηA ¯ξ ˙X + ke−iθξA ¯ξ ˙X + e2θiξA¯η ˙X + ¯keiθξA ¯ξ ˙X]
= −σaA ˙X(e2θiξA¯η ˙X + e−2θiηA ¯ξ ˙X) −(ke−iθ + ¯keiθ)(σaA ˙XξA ¯ξ ˙X)
= −σaA ˙X[(cos 2θ + i sin 2θ)ξA¯η ˙X + (cos 2θ −i sin 2θ)ηA ¯ξ ˙X] + rva
= cos 2θ

−σaA ˙X(ξA¯η ˙X + ηA ¯ξ ˙X)

+ sin 2θ

−σaA ˙Xi(ξA¯η ˙XηA ¯ξ ˙X)

+ rva,
where r = ke−iθ + ¯keiθ = ke−iθ + (ke−iθ) ∈R. Now, −σaA ˙X(ξA¯η ˙X+ηA¯ξ ˙X) =
wa. Moreover, observe that if UA ˙X = ξA¯η ˙X −ηA ¯ξ ˙X, then ¯UA ˙X = −UA ˙X
so, by Exercise 3.4.6, iU A ˙X is Hermitian and therefore, by Theorem 3.4.2,
ua = −σaA ˙XiU A ˙X deﬁnes a covector u∗in M∗. Thus, wa →wa cos 2θ +
ua sin 2θ + rv a so the phase change ξA →eiθξA leaves v alone and gives a
new w of
w −→(cos 2θ)w + (sin 2θ)u + rv.
Exercise 3.5.7 Compute waua, vaua and uaua to show that u is orthogonal
to w and v and satisﬁes u · u = 2.
Thus, we picture w and u as perpendicular spacelike vectors in the 3-space
(Span{v})⊥tangent to the null cone along v. Then (cos 2θ)w + (sin 2θ)u
is a spacelike vector in the plane of w and u making an angle of 2θ with
w. After a phase change ξA →eiθξA the new w is in the plane of v and
(cos 2θ)w+(sin 2θ)u. The 2-plane containing v and this new w is the new ﬂag.
Thus, a phase change ξA →eiθξA leaves the ﬂagpole v unchanged and rotates
the ﬂag by 2θ in the plane of w and u (in Figure 3.5.2 we have drawn the
ﬂagpole vertically even though it lies along a null line). Notice that if θ = π,
then the phase change ξA →eπiξA = −ξA carries ξ to −ξ, but the null ﬂag
is rotated by 2π and so returns to its original position. Thus, ξ determines a
unique null ﬂag, but the null ﬂag representing ξ also represents −ξ. Hence,
null ﬂags represent spin vectors only “up to sign”. This is a reﬂection of what
might be called the “essential 2-valuedness” of spinors, which has its roots in

186
3 The Theory of Spinors
the fact that the spinor map is two-to-one and which has been used to model
some quite startling physical phenomena. We shall take up these matters in
somewhat more detail in Appendix B.
Fig. 3.5.2
3.6 The Electromagnetic Field (Revisited)
In this section we shall reexamine some of our earlier results on electromag-
netic ﬁelds at a point and ﬁnd that, in the language of spinors, they often
achieve a remarkable elegance and simplicity. We begin with a nonzero skew-
symmetric linear transformation F : M →M (i.e., the value of an electro-
magnetic ﬁeld at some point in M). Select a ﬁxed, but arbitrary admissible
basis {ea} and spin frame {sA}. The bivector ˜F associated with F is de-
ﬁned by (2.7.10) and has components in {ea} given by Fab = ˜F(ea, eb). The
spinor equivalent of ˜F is deﬁned by FA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y Fab. Associated
with FA ˙XB ˙Y is a symmetric spinor φAB of valence

0
0
2
0

such that
FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y .
(3.6.1)
We call φAB the electromagnetic spinor associated with F.

3.6 The Electromagnetic Field (Revisited)
187
Exercise 3.6.1 Show that if ξ is any spin vector, then φABξAξB is an in-
variant, i.e., that, relative to another spin frame,
ˆφAB ˆξA ˆξB = φABξAξB.
Our ﬁrst objective is to obtain a canonical decomposition of φAB into
a symmetrized outer product of spin vectors. To this end we compute the
invariant in Exercise 3.6.1 for spin vectors of the form
*ξ1
ξ0
+
=
*z
1
+
, where
z ∈C.
φABξAξB = φ11ξ1ξ1 + φ10ξ1ξ0 + φ01ξ0ξ1 + φ00ξ0ξ0
= φ11z2 + φ10z + φ01z + φ00
= φ11z2 + 2φ10z + φ00
since φ01 = φ10. Notice that this is a quadratic polynomial in the complex
variable z with coeﬃcients in C. Consequently, it factors over C, i.e., there
exist α1, α0, β1, β0 ∈C such that
φ11z2 + 2φ10z + φ00 = (α1z + α0)(β1z + β0)
(3.6.2)
(these are not unique, of course, since replacing αA by αA/γ and βA by γβA
for any nonzero γ ∈C also gives a factorization). Equating coeﬃcients in
(3.6.2) gives
φ11 = α1β1 = 1
2(α1β1 + α1β1)
φ00 = α0β0 = 1
2(α0β0 + α0β0)
φ10
= 1
2(α1β0 + α0β1).
Since φ01 = φ10 this last equality may be written
φ01
= 1
2(α0β1 + α1β0).
Thus, for all A, B = 1, 0, we have
φAB = 1
2(αAβB + αBβA).
(3.6.3)
Next observe that if, in another spin frame, we deﬁne ˆαA = GA
A1αA1 and
ˆβB = GB
B1βB1, i.e., if we regard α and β as spin vectors, then

188
3 The Theory of Spinors
1
2(ˆαA ˆβB + ˆαB ˆβA) = 1
2

GA
A1αA1
 
GB
B1βB1

+

GB
B1αB1
 
GA
A1αA1

= 1
2GA
A1GB
B1(αA1βB1 + αB1βA1)
= GA
A1GB
B1φA1B1
= ˆφAB.
Consequently, φ is the symmetrized outer product of the spin vectors α and
β, i.e., in any spin frame,
φAB = 1
2(αAβB + αBβA) = α(AβB).
(3.6.4)
Although we will have no need to do so this argument, which depends only
on the symmetry of φ, extends easily to produce analogous decompositions
of higher valence symmetric spinors.
The spin vectors α and β are intimately connected with the electromag-
netic ﬁeld F. We will eventually show that our characterization of null and
regular F’s (Corollary 2.3.8) has a remarkably simple reformulation in terms
of α and β (Corollary 3.6.2 asserts that F is null if and only if α and β are
parallel). For the present we will content ourselves with showing that the
future-directed null vectors associated with α and β (i.e., their ﬂagpoles) are
eigenvectors of the electromagnetic ﬁeld F (see Section 2.4). Thus, we deﬁne
future-directed null vectors v and w by
va = −σa
A ˙XαA ¯α
˙X
and
wa = −σa
A ˙XβA ¯β
˙X.
The null directions determined by v and w are called the principal null di-
rections of φAB. Letting F ab = ηacFcb denote the entries in the matrix of F
relative to {ea} we compute
F a
bvb = ηacFcbvb = ηacσc
A ˙Xσb
B ˙Y FA ˙XB ˙Y vb
= −ηacσcA ˙XσbB ˙Y (ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y )

σb
D ˙ZαD ¯α
˙Z
= −ηacσc
A ˙X 
σb
B ˙Y σb
D ˙Z

(ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y )αD ¯α
˙Z
= −ηacσcA ˙X 
−δB
Dδ
˙Y
˙Z

(ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y )αD ¯α
˙Z
= ηacσcA ˙X(ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y )αB ¯α
˙Y
= ηacσc
A ˙X ,
(ϵABαB)(¯φ ˙X ˙Y ¯α
˙Y ) + (φABαB)(¯ϵ ˙X ˙Y ¯α
˙Y )
-
F abvb = ηacσcA ˙X ,
(−αA)(¯φ ˙X ˙Y ¯α
˙Y ) + (φABαB)(−¯α ˙X)
-
.
(3.6.5)

3.6 The Electromagnetic Field (Revisited)
189
Exercise 3.6.2 Show that φABαB =
1
2(α1β0 −α0β1)αA and ¯φ ˙X ˙Y ¯α ˙Y =
1
2(α1β0 −α0β1)¯α ˙X.
Letting μ = 1
2(α1β0 −α0β1) we obtain, from Exercise 3.6.2,
φABαB = μαA
(3.6.6)
and
¯φ ˙X ˙Y ¯α
˙Y = ¯μ¯α ˙X,
(3.6.7)
which we now substitute into (3.6.5).
F abvb = −ηacσcA ˙X(αA(¯μ¯α ˙X) + (μαA)¯α ˙X)
= −ηacσcA ˙X(μ + ¯μ)(αA ¯α ˙X)
= −(μ + ¯μ)ηac(σcA ˙XαA ¯α ˙X)
= −(μ + ¯μ)ηacvc
= −(μ + ¯μ)va.
If we let
λ = −(μ + ¯μ) = −2Re(μ) = −2Re
 1
2(α1β0 −α0β1)

= −Re(α1β0 −α0β1)
= −Re < α, β >,
we obtain
F a
bvb = λva = −Re < α, β > va,
(3.6.8)
or, equivalently,
Fv = λv = −Re < α, β > v,
(3.6.9)
so v is an eigenvector of F with eigenvalue λ = −Re < α, β >.
Exercise 3.6.3 Show in the same way that
Fw = −λw = Re < α, β > w.
(3.6.10)
We conclude that the ﬂagpoles of α and β are two (possibly coincident)
future-directed null eigenvectors of F with eigenvalues −Re < α, β > and
Re < α, β > respectively.
Let us rearrange (3.6.6) a bit.
φAC αC = μαA,
φAC (ϵCBαB) = μαA,
(φAC ϵCB)αB = μαA,
(−ϵBCφAC )αB = μαA,
φA
BαB = −μαA.
(3.6.11)

190
3 The Theory of Spinors
Thinking of
*
φA
B
+
as the matrix, relative to {sA}, of a linear transformation
φ : ß →ß on spin space motivates the following deﬁnitions. A complex number
λ is an eigenvalue of φAB if there exists a nonzero spin vector α ∈ß, called
an eigenspinor of φAB, such that φA
BαB = λαA. Such an α will exist if and
only if λ satisﬁes
det
**φ1
1
φ1
0
φ0
1
φ0
0
+
−λ
*1
0
0
1
++
= 0,
which, when expanded, gives
λ2 −

φ1
1 + φ0
0
+ det
,
φA
B-
= 0.
(3.6.12)
However, #1 of Exercise 3.3.6 and the symmetry of φAB gives φ1
1 +φ0
0 = 0,
whereas #3 of that same Exercise gives det
,
φA
B-
= det [φAB] = 1
2φABφAB,
so the solutions to (3.6.12) are
λ = ±(−det[φAB])
1
2 = ±

−1
2φABφAB 1
2 .
(3.6.13)
The physical signiﬁcance of these eigenvalues of φAB will emerge when we
compute det[φAB] in terms of the 3-vectors
⇀
E and
⇀
B, which we accomplish
by means of (2.7.14). First observe that
φAB = 1
2F ˙UA
˙U
B = 1
2
,
F˙1A
˙1
B + F˙0A
˙0
B
-
= 1
2
,
¯ϵ
˙1 ˙XF˙1A ˙XB + ¯ϵ
˙0 ˙XF˙0A ˙XB
-
= 1
2
,
¯ϵ
˙1˙0F˙1A˙0B + ¯ϵ
˙0˙1F˙0A˙1B
-
= 1
2[−F˙1A˙0B + F˙0A˙1B] = 1
2[FA˙0B ˙1 −FA˙1B ˙0].
Thus, for example,
φ11 = 1
2[F1˙01˙1 −F1˙11˙0] = 1
2[F1˙01˙1 −(−F1˙01˙1)]
= F1˙01˙1 = σa
1˙0σb
1˙1Fab.
Now, if a = b the corresponding term in this sum is zero since Faa = 0. The
a = 3, 4 and b = 1, 2 terms vanish by the deﬁnitions of the σa
A ˙X. Thus, only
the ab = 13, 14, 23, 24 terms survive so

3.6 The Electromagnetic Field (Revisited)
191
φ11 = σ1
1˙0σ3
1˙1F13 + σ1
1˙0σ4
1˙1F14 + σ2
1˙0σ3
1˙1F23 + σ2
1˙0σ4
1˙1F24
=

−1
√
2
 
−1
√
2

F13 +

−1
√
2
 
−1
√
2

F14
+

i
√
2
 
−1
√
2

F23 +

i
√
2
 
−1
√
2

F24
= 1
2(−B2) + 1
2(E1) −1
2i(B1) −1
2i(E2)
φ11 = 1
2[(E1 −B2) −i(E2 + B1)].
(3.6.14)
Exercise 3.6.4 Continue in the same way to show
φ10 = φ01 = 1
2(−E3 + iB3)
(3.6.15)
and
φ00 = 1
2[−(E1 + B2) + i(−E2 + B1)].
(3.6.16)
Exercise 3.6.5 Compute φ11φ00–φ10φ01 from (3.6.14)–(3.6.16) to show that
det[φAB] = 1
4

|
⇀
B|2 −|
⇀
E|2
+ 1
2(
⇀
E ·
⇀
B)i.
(3.6.17)
Returning now to (3.6.13) we ﬁnd that the eigenvalues of the electromagnetic
spinor φAB are given by
λ = ±
,
−1
4(|
⇀
B|2 −|
⇀
E|2) −1
2(
⇀
E ·
⇀
B)i
- 1
2 .
(3.6.18)
But then λ = 0 if and only if |
⇀
B|2 −|
⇀
E|2 =
⇀
E ·
⇀
B = 0 so F is null if and only
if the only eigenvalue of φAB is 0 and we have proved:
Theorem 3.6.1 Let F : M →M be a nonzero, skew-symmetric linear
transformation, ˜F its associated bivector, FA ˙XB ˙Y the spinor equivalent of
˜F and φAB the symmetric spinor for which FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y .
Then F is null if and only if λ = 0 is the only eigenvalue of φAB.
Another equally elegant form of this characterization theorem is:
Corollary 3.6.2 Let F : M →M be a nonzero, skew-symmetric linear
transformation, ˜F its associated bivector, FA ˙XB ˙Y the spinor equivalent of
˜F, φAB the symmetric spinor for which FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y , and
α and β spin vectors for which φAB = α(AβB). Then F is null if and only if
α and β are linearly dependent.

192
3 The Theory of Spinors
Proof:
First we compute
φABφAB = 1
2 (αAβB + αBβA) 1
2

αAβB + αBβA
= 1
4

αAαA 
βBβB
+

αAβA 
βBαB
+

αBβB 
βAαA
+

αBαB 
βAβA
= 1
4[(0)(0) + < β, α > < α, β > + < β, α > < α, β > + (0)(0)]
= 1
4[−< α, β > < α, β > −< α, β > < α, β >]
= −1
2 < α, β >2 .
Thus, (3.6.13) gives
λ = ±
 1
4 < α, β >2 1
2 = ± 1
2 < α, β > .
Theorem 3.6.1 therefore implies that F is null if and only if < α, β > = 0
which, by Lemma 3.2.1 (g), is the case if and only if α and β are linearly
dependent.
■
We have deﬁned the spinor equivalent of a bivector in Section 3.5, but
the same deﬁnition yields a spinor equivalent of any bilinear form on M.
Speciﬁcally, if we ﬁx an admissible basis {ea} and a spin frame {sA} and let
H : M × M →R be a bilinear form on M, then the spinor equivalent of H
is the spinor of valence
0
0
2
2

whose components in {sA} are given by
HA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y Hab,
where Hab = H(ea, eb).
Exercise 3.6.6 Show that, in another spin frame {ˆsA}, related to {sA} by
(3.2.1) and (3.2.6), ˆHA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y ˆHab, where ˆHab = Λa
αΛb
βHαβ, Λ
being ΛG.
A particularly important example of a bilinear form is the Lorentz inner
product itself: g : M × M →R, deﬁned by g(u, v) = u · v. Relative to any
{ea}, the components of g are
g(ea, eb) = ea · eb = ηab.
The spinor equivalent of g is deﬁned by
gA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y ηab
gA ˙XB ˙Y = σ1
A ˙Xσ1
B ˙Y + σ2
A ˙Xσ2
B ˙Y + σ3
A ˙Xσ3
B ˙Y −σ4
A ˙Xσ4
B ˙Y .
(3.6.19)

3.6 The Electromagnetic Field (Revisited)
193
We claim that
gA ˙XB ˙Y = −ϵAB¯ϵ ˙X ˙Y .
(3.6.20)
One veriﬁes (3.6.20) by simply considering all possible choices for A, B, ˙X
and ˙Y . For example, if either (i) A and B are the same, but ˙X and ˙Y are
diﬀerent, or (ii)
˙X and ˙Y are the same, but A and B are diﬀerent, then
both sides of (3.6.20) are zero (every σa
A ˙X has either σa
1˙1 = σa
0˙0 = 0 or
σa
1˙0 = σa
0˙1 = 0, so all of the σa
A ˙Xσa
B ˙Y in (3.6.19) are zero). All that
remain then are the cases in which (iii) A = B and ˙X = ˙Y , or (iv) A ̸= B
and ˙X ̸= ˙Y , i.e., A ˙XB ˙Y = 1˙11˙1, 1˙01˙0, 0˙10˙1, 0˙00˙0, 1˙10˙0, 1˙00˙1, 0˙11˙0, 0˙01˙1.
For example,
g1˙00˙1 = σ1
1˙0σ1
0˙1 + σ2
1˙0σ2
0˙1 + σ3
1˙0σ3
0˙1 −σ4
1˙0σ4
0˙1
= σ1
1˙0σ1
0˙1 + σ2
1˙0σ2
0˙1 =

−1
√
2
 
−1
√
2

+

i
√
2
 
−i
√
2

= 1
2 −1
2i2 = 1
2 + 1
2
= 1
= −ϵ10¯ϵ˙0˙1.
Exercise 3.6.7 Verify the remaining cases.
The energy-momentum transformation T : M →M of an electromagnetic
ﬁeld F : M →M also has an associated (symmetric) bilinear form ˜T :
M×M →R deﬁned by ˜T(u, v) = u·Tv and with components Tab = T (ea, eb)
given, according to Exercise 2.7.8, by
Tab =
1
4π

FaαFb
α −1
4ηabFαβF αβ
.
(3.6.21)
We show next that the spinor equivalent of ˜T takes the following particularly
simple form:
TA ˙XB ˙Y =
1
2πφAB ¯φ ˙X ˙Y ,
(3.6.22)
where φAB is the electromagnetic spinor associated with F. By deﬁnition,
the spinor equivalent of ˜T is given by
TA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y Tab =
1
4πσa
A ˙Xσb
B ˙Y

FaαFb
α −1
4ηabFαβF αβ
=
1
4π

σa
A ˙Xσb
B ˙Y FaαFb
α −1
4

σa
A ˙Xσb
B ˙Y ηab

FαβF αβ
TA ˙XB ˙Y =
1
4π

σa
A ˙Xσb
B ˙Y FaαFb
α + 1
4ϵAB¯ϵ ˙X ˙Y (FαβF αβ)

(3.6.23)
by (3.6.20). We begin simplifying (3.6.23) with two observations:
FαβF αβ = FC ˙ZD ˙W F C ˙ZD ˙W
(3.6.24)

194
3 The Theory of Spinors
and
σa
A ˙Xσb
B ˙Y FaαFb
α = −FA ˙XC ˙ZFB ˙Y
C ˙Z.
(3.6.25)
For the proof of (3.6.24) we compute
FC ˙ZD ˙W F C ˙ZD ˙W = FC ˙ZD ˙W ϵCC 1¯ϵ
˙Z ˙Z1ϵDD1¯ϵ
˙W ˙W1FC1 ˙Z1D1 ˙W1
=

σa
C ˙Zσb
D ˙W Fab

ϵCC 1¯ϵ
˙Z ˙Z1ϵDD1¯ϵ
˙W ˙W1 
σα
C1 ˙Z1σβ
D1 ˙W1(ηαμηβνF μν)

=

ϵCC 1¯ϵ
˙Z ˙Z1ημασα
C1 ˙Z1
 
ϵDD1¯ϵ
˙W ˙W1ηνβσβ
D1 ˙W1

σa
C ˙Zσb
D ˙W FabF μν
= σμC ˙ZσνD ˙W σa
C ˙Zσb
D ˙W FabF μν =

σμC ˙Zσa
C ˙Z
 
σνD ˙W σb
D ˙W

FabF μν
=

−δa
μ
 
−δb
ν

FabF μν = FabF ab.
Exercise 3.6.8 Prove (3.6.25).
Substituting (3.6.24) and (3.6.25) into (3.6.23) gives
TA ˙XB ˙Y =
1
4π
,
−FA ˙XC ˙ZFB ˙Y
C ˙Z + 1
4ϵAB¯ϵ ˙X ˙Y FC ˙ZD ˙W F C ˙ZD ˙W -
.
(3.6.26)
Now we claim that if FA ˙XB ˙Y = ϵAB ¯φ ˙X ˙Y + φAB¯ϵ ˙X ˙Y , then
FC ˙ZD ˙W F C ˙ZD ˙W = 2

φCDφCD + ¯φ ˙Z ˙W ¯φ
˙Z ˙W 
(3.6.27)
and
FA ˙XC ˙ZFB ˙Y
C ˙Z = −2φAB ¯φ ˙X ˙Y + ϵAB ¯φ ˙X ˙Z ¯φ ˙Y
˙Z + ¯ϵ ˙X ˙Y φAC φB
C.
(3.6.28)
We prove (3.6.27) as follows:
FC ˙ZD ˙W F C ˙ZD ˙W =

ϵCD ¯φ ˙Z ˙W + φCD¯ϵ ˙Z ˙W
 
ϵCD ¯φ
˙Z ˙W + φCD¯ϵ
˙Z ˙W 
=

ϵCDϵCD 
¯φ ˙Z ˙W ¯φ
˙Z ˙W 
+

ϵCDφCD 
¯φ ˙Z ˙W ¯ϵ
˙Z ˙W 
+

φCDϵCD 
¯ϵ ˙Z ˙W ¯φ
˙Z ˙W 
+

φCDφCD 
¯ϵ ˙Z ˙W ¯ϵ
˙Z ˙W 
.
But observe that, by symmetry of φ, ϵCDφCD = ϵ10φ10 + ϵ01φ01 = −φ10 +
φ01 = 0 and, similarly, ¯ϵ ˙Z ˙W ¯φ ˙Z ˙W = 0. Moreover, by (3.3.7), ϵCDϵCD =
¯ϵ ˙Z ˙W ¯ϵ ˙Z ˙W = 2 so
FC ˙ZD ˙W F C ˙ZD ˙W = 2¯φ ˙Z ˙W ¯φ
˙Z ˙W + 0 + 0 + 2φCDφCD
which gives (3.6.27).

3.6 The Electromagnetic Field (Revisited)
195
Exercise 3.6.9 Prove (3.6.28).
With (3.6.27) and (3.6.28), (3.6.26) becomes
TA ˙XB ˙Y =
1
4π
,
2φAB ¯φ ˙X ˙Y −ϵAB ¯φ ˙X ˙Z ¯φ ˙Y
˙Z −¯ϵ ˙X ˙Y φAC φB
C
+ 1
2ϵAB¯ϵ ˙X ˙Y

φCDφCD + ¯φ ˙Z ˙W ¯φ
˙Z ˙W -
.
TA ˙XB ˙Y =
1
4π
,
2φAB ¯φ ˙X ˙Y −ϵAB ¯φ ˙X ˙Z ¯φ ˙Y
˙Z −¯ϵ ˙X ˙Y φAC φB
C
+ (det[φAB])ϵAB¯ϵ ˙X ˙Y + (det[¯φ ˙X ˙Y ])ϵAB¯ϵ ˙X ˙Y

,
(3.6.29)
where we have appealed to part (3) of Exercise 3.3.6 and its conjugated ver-
sion. For the remaining simpliﬁcations we use part (4) of this same exercise.
If either A = B or ˙X = ˙Y all the terms on the right-hand side of (3.6.29)
except the ﬁrst are zero so TA ˙XB ˙Y =
1
2πφAB ¯φ ˙X ˙Y and (3.6.22) is proved. The
remaining cases are A ˙XB ˙Y = 1˙10˙0, 1˙00˙1, 0˙11˙0 and 0˙01˙1 and all are treated
in the same way, e.g.,
T1˙10˙0 =
1
4π
,
2φ10 ¯φ˙1˙0 −ϵ10 ¯φ˙1 ˙Z ¯φ˙0
˙Z −¯ϵ˙1˙0φ1Cφ0
C
+ (det[φAB])ϵ10¯ϵ˙1˙0 + (det[¯φ ˙X ˙Y ])ϵ10¯ϵ˙1˙0

=
1
4π[2φ10 ¯φ˙1˙0 −(−1)(−det[¯φ ˙X ˙Y ]) −(−1)(−det[φAB])
+ (det[φAB])(−1)(−1) + (det[¯φ ˙X ˙Y ])(−1)(−1)]
=
1
4π[2φ10 ¯φ˙1˙0]
=
1
2πφ10 ¯φ˙1˙0.
Exercise 3.6.10 Check the remaining cases to complete the proof of
(3.6.22).
We use the spinor equivalent TA ˙XB ˙Y
=
1
2πφAB ¯φ ˙X ˙Y
of the energy-
momentum T of F to give another proof of the dominant energy condition
(Exercise 2.5.6) that does not depend on the canonical forms of F. Begin
with two future-directed null vectors u = uaea and v = vbeb in M. By The-
orem 3.4.3, the spinor equivalents of u and v can be written U A ˙X = μA¯μ ˙X
and V A ˙X = νA¯ν ˙X, where μ and ν are two spin vectors. Thus, we may write
ua = −σa
A ˙XμA¯μ ˙X and vb = −σb
B ˙Y νB¯ν ˙Y so that
Tu · v = Tabuavb = Tab

−σa
A ˙XμA¯μ
˙X 
−σB
B ˙Y νB¯ν
˙Y 
=

σa
A ˙Xσb
B ˙Y Tab

μA¯μ
˙XνB¯ν
˙Y
= TA ˙XB ˙Y μA¯μ
˙XνB¯ν
˙Y
=
1
2πφAB ¯φ ˙X ˙Y μA¯μ
˙XνB ¯ν
˙Y
=
1
2π(φABμAμB)(¯φ ˙X ˙Y ¯μ
˙X ¯ν
˙Y ),

196
3 The Theory of Spinors
so
Tu · v =
1
2π|φABμAνB|2.
(3.6.30)
In particular, Tu · v ≥0.
Exercise 3.6.11 Show that Tu ·v ≥0 whenever u and v are timelike or null
and both are future-directed. Hint: Any future-directed timelike vector can
be written as a sum of two future-directed null vectors.
We recall from Section 2.5 that, for any future-directed unit timelike vector
U, TU · U =
1
8π[|
⇀
E|2 + |
⇀
B|2] is the energy density in any admissible frame
with e4 = U. Consequently, if F is nonzero, Tu · u ̸= 0 for any timelike
vector u. We now investigate the circumstances under which Tv · v = 0 for
some future-directed null vector v. Suppose then that v is null and future-
directed and Tv · v = 0. Write va = −σa
A ˙XνA¯ν ˙X for some spin vector ν
(Theorem 3.4.3). Then, by (3.6.30), φABνAνB = 0. Using the decomposition
(3.6.4) of φ this is equivalent to
(αAβB + αBβA)(νAνB) = 0,
(αAνA)(βBνB) + (αBνB)(βAνA) = 0,
2 < ν, α > < ν, β > = 0
which is the case if and only if either < ν, α > = 0 or < ν, β > = 0. But
< ν, α > = 0 if and only if ν is a multiple of α (Lemma 3.2.1(g)) and similarly
for < ν, β > = 0. But if ν is a multiple of either α or β, then v is a multiple of
one of the two null vectors determined by α or β, i.e., v is along a principal
null direction of φAB. Thus, a future-directed null vector v for which Tv·v = 0
must lie along a principal null direction of φAB. Moreover, by reversing the
steps above, one ﬁnds that the converse is also true so we have proved that a
nonzero null vector v satisﬁes Tv · v = 0 if and only if v lies along a principal
null direction of φAB.
Exercise 3.6.12 Let F : M →M be a nonzero, skew-symmetric linear
transformation, ˜F the associated bivector and ∗˜F the dual of ˜F (Section 2.7).
By (2.7.16) (with M = Λ), the Levi-Civita symbol ϵabcd deﬁnes a (con-
stant) covariant world tensor of rank 4. We deﬁne its spinor equivalent by
ϵA ˙XB ˙Y C ˙ZD ˙W = σa
A ˙Xσb
B ˙Y σc
C ˙Zσd
D ˙Wϵabcd. Show that
ϵA ˙XB ˙Y C ˙ZD ˙W = i(ϵACϵBD¯ϵ ˙X ˙W ¯ϵ ˙Y ˙Z −ϵADϵBC¯ϵ ˙X ˙Z¯ϵ ˙Y ˙W)
and then raise indices to obtain
ϵA ˙XB ˙Y
C ˙ZD ˙W = i

δC
AδD
B δ
˙W
˙X δ
˙Z
˙Y −δD
A δC
Bδ
˙Z
˙Xδ
˙W
˙Y

.
Now show that the spinor equivalent of ∗˜F is given by
∗FA ˙XB ˙Y = i(ϵAB ¯φ ˙X ˙Y −φAB¯ϵ ˙X ˙Y ).

3.6 The Electromagnetic Field (Revisited)
197
Exercise 3.6.13 Deﬁne the spinor equivalent of an arbitrary world tensor
(Section 3.1) of contravariant rank r and covariant rank s, being sure to verify
the appropriate transformation law, and show that any such spinor equivalent
is Hermitian. Find an “inversion formula” analogous to (3.4.19) and (3.5.3)
that retrieves the world tensor from its spinor equivalent. For what type of
spinor can this process be reversed to yield a world tensor equivalent?
We conclude our discussion of electromagnetic theory by deriving the el-
egant spinor form of the source-free Maxwell equations. For this we ﬁx an
admissible basis {ea} and a spin frame {sA} and let F denote an electro-
magnetic ﬁeld on (a region in) M. As usual, we denote by Fab = ηaαF αb
the components of the corresponding bivector ˜F, all of which are functions of
(x1, x2, x3, x4). Then the spinor equivalent of ˜F is FA ˙XB ˙Y = σa
A ˙Xσb
B ˙Y Fab
and the electromagnetic spinor φAB is given by
φAB = 1
2F ˙UA
˙U
B = 1
2[FA˙0B ˙1 −FA˙1B ˙0].
Next we introduce “spinor equivalents” for the diﬀerential operators ∂a =
∂
∂xa , a = 1, 2, 3, 4. Speciﬁcally, we deﬁne, for each A = 1, 0 and ˙X = ˙1, ˙0, an
operator ∇A ˙X by
∇A ˙X = σaA ˙X∂a = σaA ˙X(ηaα∂α).
Thus, for example,
∇1˙1 = σa1˙1∂a = σ11˙1∂1 + σ21˙1∂2 + σ31˙1∂3 + σ41˙1∂4
= σ31˙1∂3 + σ41˙1∂4 =
1
√
2∂3 +
1
√
2∂4
=
1
√
2(∂3 −∂4).
Exercise 3.6.14 Prove the remaining identities in (3.6.31):
∇1˙1 =
1
√
2(∂3 −∂4),
∇1˙0 =
1
√
2(∂1 + i∂2),
∇0˙1 =
1
√
2(∂1 −i∂2),
∇0˙0 = −1
√
2(∂3 + ∂4).
(3.6.31)
With this notation we claim that all of the information contained in the
source-free Maxwell equations (2.7.15) and (2.7.21) can be written con-
cisely as
∇A ˙XφAB = 0,
A = 1, 0,
˙X = ˙1, ˙0.
(3.6.32)
Equations (3.6.32) are the spinor form of the source-free Maxwell equations.
To verify the claim we write
φ11 = 1
2[(F13 + F14) + i(F32 + F42)],
φ10 = φ01 = 1
2[F43 + iF 12],
φ00 = 1
2[(F41 + F13) + i(F42 + F23)]

198
3 The Theory of Spinors
(see (3.6.14)–(3.6.16)). Now compute, for example,
∇A˙1φA0 = ∇1˙1φ10 + ∇0˙1φ00 =
1
2
√
2 {(∂3 −∂4)(F43 + iF 12)
+ (∂1 −i∂2)((F41 + F13) + i(F42 + F23))}
=
1
2
√
2 {[−(F14,1 + F24,2 + F34,3) + (F13,1 + F23,2 −F43,4)]
+ i[(F12,3 + F31,2 + F23,1) −(F12,4 + F41,2 + F24,1)]}
=
1
2
√
2
6,
−div
⇀
E −
,
(curl
⇀
B) · e3 −∂E3
∂x4
--
+ i
,
div
⇀
B −
,
(curl
⇀
E) · e3 + ∂B3
∂x4
--7
.
Exercise 3.6.15 Calculate, in the same way, ∇A˙1φA1,
∇A˙0φA1, and
∇A˙0φA0, and show that (3.6.32) is equivalent to Maxwell’s equations.
Generalizations of (3.6.32) are used in relativistic quantum mechanics as
ﬁeld equations for various types of massless particles. Speciﬁcally, if n is a
positive integer and φA1A2···An is a symmetric spinor of valence
0
0
n 0

, then
∇A ˙XφAA2···An = 0,
A2, . . . , An = 1, 0,
˙X = ˙1, ˙0,
is taken to be the massless free-ﬁeld equation for arbitrary spin 1
2n particles
(see 5.7 of [PR]). In particular, if n = 1, then φA is a spin vector and one
obtains the Weyl neutrino equation
∇A ˙XφA = 0,
˙X = ˙1, ˙0,
which suggested the possibility of parity nonconservation in weak interactions
years before the phenomenon itself was observed (see [LY]).

Chapter 4
Prologue and Epilogue: The de Sitter
Universe
4.1 Introduction
In this ﬁnal chapter we would like to take one small step beyond the special
theory of relativity in order to brieﬂy address two issues that have been con-
scientiously swept under the rug to this point. These are related, although
perhaps not obviously so. The ﬁrst is the issue of gravitation which we quite
explicitly eliminated from consideration very early on. We have proposed
Minkowski spacetime as a model of the event world only when the eﬀects of
gravity are “negligible”, that is, for a universe that is eﬀectively “empty”, but
it is doubtful that anything in our development has made it clear why such a
restriction was necessary. Here we will attempt to provide an explanation as
well as a gentle prologue to how one adapts to the presence of gravitational
ﬁelds. Then, as an epilogue to our story, we will confront certain recent astro-
nomical observations suggesting that, even in an empty universe, the event
world may possess properties not reﬂected in the structure of Minkowski
spacetime, at least on the cosmological scale. Remarkably, there is a viable
alternative, nearly 100 years old, that has precisely these properties and we
will devote a little time to becoming acquainted with it.
4.2 Gravitation
An electromagnetic ﬁeld is a 2-form on Minkowski spacetime M that satisﬁes
Maxwell’s equations. A charged particle responds to the presence of such a
ﬁeld by experiencing changes in 4-momentum speciﬁed by the Lorentz 4-Force
Law. This is how particle mechanics works. A physical agency that aﬀects the
shape of a particle’s worldline is isolated and described mathematically and
then equations of motion are postulated that quantify this eﬀect. It would
seem then that the next logical step in such a program would be to carry
, 
: An Introduction 
, Applied Mathematical Sciences 92,
G.L. Naber The Geometry of Minkowski Spacetime
to the Mathematics 
of the Special Theory of Relativity
DOI 10.1007/978-1-4419-7838-7_4, © Springer Science+Business Media, LLC 2012
199

200
4 Prologue and Epilogue: The de Sitter Universe
out an analogous procedure for the gravitational ﬁeld. In the early days of
relativity theory many attempts were made (by Einstein and others) to do
just this, but they all came to naught. However one chose to model a gravi-
tational ﬁeld on M and however the corresponding equations of motion were
chosen, the numbers simply did not come out right; theoretical predictions
did not agree with the experimental facts (an account of some of these early
attempts is available in Chapter 2 of [MTW]). In hindsight, the reason for
these failures appears quite simple (once it is pointed out to you by Einstein,
that is). An electromagnetic ﬁeld is something “external” to the structure of
spacetime, an additional ﬁeld deﬁned on and (apparently) not inﬂuencing the
mathematical structure of M. Einstein realized that a gravitational ﬁeld has
a very special property which makes it unnatural to regard it as something
external to the nature of the event world. Since Galileo it has been known
that all objects with the same initial position and velocity respond to a given
gravitational ﬁeld in the same way (i.e., have identical worldlines) regardless
of their material constitution (mass, charge, etc.). This is essentially what
was veriﬁed at the Leaning Tower of Pisa and contrasts markedly with the
behavior of electromagnetic ﬁelds. These worldlines (of particles with given
initial conditions of motion) seem almost to be natural “grooves” in space-
time that anything will slide along once placed there. But these “grooves”
depend on the particular gravitational ﬁeld being modeled and, in any case,
M simply is not “grooved” (its structure does not distinguish any collection
of curved worldlines). One suspects then that M itself is somehow lacking,
that the appropriate mathematical structure for the event world may be more
complex when gravitational eﬀects are nonnegligible.
To see how the structure of M might be generalized to accommodate the
presence of gravitational ﬁelds let us begin again as we did in the Introduction
with an abstract set M whose elements we call “events”. One thing at least is
clear. In regions that are distant from the source of any gravitational ﬁeld no
accommodation is necessary and M must locally “look like” M. But a great
deal more is true. In his now famous Elevator Experiment Einstein observed
that any event has about it a suﬃciently small region of M which “looks
like” M. To see this we reason as follows. Imagine an elevator containing an
observer and various other objects that is under the inﬂuence of some uniform
external gravitational ﬁeld. The cable snaps. The contents of the elevator are
now in free fall. Since all of the objects inside respond to the gravitational
ﬁeld in the same way they will remain at relative rest throughout the fall.
Indeed, if our observer lifts an apple from the ﬂoor and releases it in mid-air
it will appear to him to remain stationary. You have witnessed these things
for yourself. While it is unlikely that you have had the misfortune of seeing a
falling elevator you have seen astronauts at play inside their space capsules
while in orbit (i.e., free fall) about the earth. The objects inside the elevator
(capsule) seem then to constitute an archetypical inertial frame. By estab-
lishing spacetime coordinates in the usual way our observer thereby becomes
an admissible observer, at least within the spatial and temporal constraints

4.2 Gravitation
201
imposed by his circumstances. Now, picture an arbitrary event. There are any
number of vantage points from which the event can be observed. One is from
a freely falling elevator in the immediate spatial and temporal vicinity of the
event and from this vantage point the event receives admissible coordinates.
There is then a local admissible frame near any event in M.
The operative word is local. The “spatial and temporal constraints” to
which we alluded arise from the non-uniformity of any real gravitational ﬁeld.
For example, in an elevator that falls freely in the earth’s gravitational ﬁeld,
all of the objects inside are pulled toward the earth’s center so that they do,
in fact, experience some slight relative acceleration (toward each other). Such
motion, of course, goes unnoticed if the elevator falls neither too far nor too
long. Indeed, by restricting our observer to a suﬃciently small region in space
and time these eﬀects become negligible and the observer is indeed inertial.
But then, what is “negligible” is in the eye of the beholder. The availability of
more sensitive measuring devices will require further restrictions on the size
of the spacetime region that “looks like” M and so one might say that M is
locally like M in the same sense that the sphere x2 + y2 + z2 = 1 is locally
like the plane R2. In the 19th century this would have been expressed by
saying that each point of the sphere has about it an “inﬁnitesimal neighbor-
hood” that is identical to the plane. Today we prefer to describe the situation
in terms of local coordinate systems and tangent planes, but the idea is the
same.
What appears to be emerging then as the appropriate mathematical struc-
ture for M is something analogous to a smooth surface, albeit a 4-dimensional
one. As it happens there is in mathematics a notion (that of a “smooth man-
ifold”) that generalizes the deﬁnition of a smooth surface to higher dimen-
sions. With each point in such a manifold is associated a ﬂat “tangent space”
analogous to the tangent plane to a surface. These are equipped with inner
products, varying smoothly from point to point, with which one can compute
magnitudes of tangent vectors that can then be integrated to obtain lengths of
curves. Such a smoothly varying family of inner products is called a “metric”
(“Riemannian” if the inner products are positive deﬁnite and “Lorentzian”
if they have index one) and with such a thing one can do geometry. In par-
ticular, one can introduce a notion of “curvature” which, just as for surfaces,
describes quantitatively the extent to which the manifold locally deviates
from its tangent spaces, that is, from ﬂatness. In the particular manifolds of
interest in relativity (called “Lorentzian manifolds” or “spacetimes”) these
deviations are taken to represent the eﬀects of a non-negligible gravitational
ﬁeld. An object in free fall in such a ﬁeld is represented by a curve that is
“locally straight” since it would indeed appear straight in a nearby freely
falling elevator (local inertial frame). These are called “geodesics” and cor-
respond to the “grooves” to which we referred earlier (the analogous curves
on the sphere are its great circles). Not every Lorentzian metric represents
a physically realistic gravitational ﬁeld any more than every 2-form on M

202
4 Prologue and Epilogue: The de Sitter Universe
represents an electromagnetic ﬁeld and Einstein postulated ﬁeld equations
(analogous to Maxwell’s equations) that should be satisﬁed by any metric
worthy of physical consideration.
The study of these spacetime manifolds and their physical interpretation
and implications is called the General Theory of Relativity. The subject is
vast and beautiful, but our objective in this chapter is modest in the extreme.
We will introduce just enough mathematics to describe a few of the most
elementary examples and study them a bit. We will ﬁnd, remarkably enough,
that the ﬁeld equations of general relativity admit solutions that correspond
to an “empty” universe, but diﬀer from Minkowski spacetime and it is one of
these that we will brieﬂy consider as a possible alternative to the model we
have been investigating.
4.3 Mathematical Machinery
In truth, the mathematical machinery required to study general relativity
properly is substantial (a good place to begin is [O’N]), but our goal here
is not so lofty. The examples of interest to us are rather simple and we will
introduce just enough of this machinery to understand these and gain some
sense of what is required to proceed further. We begin with a synopsis of some
standard results from real analysis taking [Sp1] as our guide and reference.
For n ≥1 we denote by Rn the n-dimensional real vector space of ordered
n-tuples of real numbers.
Rn = {p = (p1, . . . , pn) : p1, . . . , pn ∈R}
The standard basis for Rn will be written e1 = (1, 0, . . . , 0, 0), . . . , en =
(0, 0, . . . , 0, 1) and, for i = 1, . . . , n, the standard coordinate functions
ui : Rn →R
are deﬁned by
ui(p) = ui(p1, . . . , pn) = pi.
The usual Euclidean inner product on Rn is deﬁned by
⟨p, q⟩= p1q1 + · · · + pnqn
and its corresponding norm ∥∥and distance function d are given by
∥p ∥2= ⟨p, p⟩
and
d(p, q) = ∥q −p ∥.

4.3 Mathematical Machinery
203
For any p ∈Rn and any ε > 0 the open ball of radius ε about p is
Uε(p) = {q ∈Rn : d(p, q) < ε}.
A subset U of Rn is said to be open in Rn if, for each p ∈U, there is an ε > 0
such that Uε(p) ⊆U. A subset K of Rn is closed in Rn if its complement
Rn −K is open in Rn. More generally, if X is an arbitrary subset of Rn,
then U ′ ⊆X is said to be open in X if there is an open set U in Rn with
U ′ = U ∩X. A subset K′ of X is closed in X if X −K′ is open in X and
this is the case if and only if there is a closed set K in Rn with K′ = K ∩X.
If X ⊆Rn and Y ⊆Rm, then any mapping F : X →Y has coordinate
functions F i, i = 1, . . . , m, deﬁned by
F(x) = (F 1(x), . . . , F m(x))
for every x ∈X. F is continuous on X if, for every open set V ′ in Y, F −1(V ′)
is open in X and this is the case if and only if each F i : X →R is a
continuous real-valued function on X. If U ⊆Rn is open, then a continuous
map F : U →Rm of U into Rm is said to be smooth (or C∞) on U if
its coordinate functions F i : U →R, i = 1, . . . , m, have continuous partial
derivatives of all orders and types at every point of U. More generally, if X
is an arbitrary subset of Rn and F : X →Rm, then F is said to be smooth
(or C∞) on X if, for each x ∈X, there is an open set U in Rn containing
x and a smooth map ˆF : U →Rm such that ˆF | U ∩X = F | U ∩X. A
bijection F : X →Y is called a homeomorphism if F and F −1 : Y →X are
both continuous; if F and F −1 are both smooth, then F is a diﬀeomorphism.
We will leave it to the reader to check that identity maps are smooth and
restrictions and compositions of smooth maps are smooth.
We are, in fact, not particularly interested in arbitrary subsets of Euclidean
spaces, but only in rather special ones. As motivation for the deﬁnition to
come we will ﬁrst work out an example. The n-dimensional sphere Sn is the
subset of Rn+1 consisting of all points p with ∥p ∥2= 1.
Sn = {p = (p1, . . . , pn, pn+1) ∈Rn+1 :∥p ∥2 = 1}
The north pole of Sn is the point N = (0, . . . , 0, 1) and the south pole is
S = (0, . . . , 0, −1). We deﬁne two open subsets US = Sn −{N} and UN =
Sn −{S} of Sn and two maps
ϕS : US −→Rn
and
ϕN : UN −→Rn.
Geometrically, these maps are quite simple. For each p ∈US, ϕS(p) is the
intersection with the coordinate hyperplane un+1 = 0 of the straight line in
Rn+1 from N through p (see Figure 4.3.1).

204
4 Prologue and Epilogue: The de Sitter Universe
N
p
S
'S (p)
Fig. 4.3.1
A simple computation gives
ϕS (p) = ϕS (p1, . . . , pn, pn+1)
(4.3.1)
=

p1
1 −pn+1 , . . . ,
pn
1 −pn+1

= (x1, . . . , xn).
Notice that ϕS is clearly smooth on US. It is, in fact, a bijection onto Rn
since it is a simple matter to check that its inverse
ϕ−1
S
: Rn −→US
is given by
ϕ−1
S (x) = ϕ−1
S (x1, . . . , xn) =
1
1+ ∥x ∥2 (2x1, . . . , 2xn, ∥x ∥2 −1).
(4.3.2)
Since ϕ−1
S
is clearly also smooth we ﬁnd that ϕS is a diﬀeomorphism of US
onto Rn and so ϕ−1
S
is a diﬀeomorphism of Rn onto US.
Similarly, for each p ∈UN, ϕN(p) is the intersection with un+1 = 0 of the
straight line in Rn+1 from S through p (see Figure 4.3.2). One ﬁnds that
ϕN(p) = ϕN(p1, . . . , pn, pn+1)
(4.3.3)
=

p1
1 + pn+1 , . . . ,
pn
1 + pn+1

= (y1, . . . , yn)

4.3 Mathematical Machinery
205
N
p
S
'N (p)
Fig. 4.3.2
which is a smooth bijection with inverse
ϕ−1
N : Rn −→UN
given by
ϕ−1
N (y) = ϕ−1
N (y1, . . . , yn) =
1
1+ ∥y ∥2 (2y1, . . . , 2yn, 1−∥y ∥2)
(4.3.4)
and this is also smooth. Consequently, ϕN : UN →Rn and ϕ−1
N : Rn →UN
are also inverse diﬀeomorphisms.
We think of the diﬀeomorphism ϕS as identifying US with Rn and thereby
supplying the points of US with n coordinates, called (x1, . . . , xn) above.
Similarly, ϕN provides points in UN with n coordinates (y1, . . . , yn). Notice
that a point p in US ∩UN = Sn−{N, S} is therefore supplied with two sets of
coordinates. These are related by the coordinate transformations ϕN ◦ϕ−1
S
:
ϕS(US ∩UN) →ϕN(US ∩UN) and ϕS ◦ϕ−1
N
: ϕN(US ∩UN) →ϕS(US ∩
UN). But
ϕS(US ∩UN) = ϕN(US ∩UN) = Rn −{(0, . . . , 0)}
and it is easy to check that
ϕN ◦ϕ−1
S (x) = ϕN ◦ϕ−1
S (x1, . . . , xn) =
1
∥x ∥2 (x1, . . . , xn)
(4.3.5)

206
4 Prologue and Epilogue: The de Sitter Universe
and
ϕS ◦ϕ−1
N (y) = ϕS ◦ϕ−1
N (y1, . . . , yn) =
1
∥y ∥2 (y1, . . . , yn).
(4.3.6)
The essential content of all this is that Sn is “locally diﬀeomorphic to Rn”
in the sense that each point of Sn is contained in an open subset of Sn that
is diﬀeomorphic to Rn. This is the prototype for our next deﬁnition.
Let n and m be positive integers with n ≤m. A subset M of Rm is called
an n-dimensional smooth manifold (or smooth n-manifold) if, for each p ∈M,
there is an open set U in M containing p and a diﬀeomorphism ϕ : U →ϕ(U)
of U onto an open subset ϕ(U) of Rn. Thus, Sn is an n-dimensional smooth
manifold in Rn+1.
Remark:
There is a more general deﬁnition of “smooth manifold” that does
not require M to be a subset of a Euclidean space (see Chapter 5 of [N3]),
but this will suﬃce for our purposes.
Exercise 4.3.1 Show that every open ball in Rn is diﬀeomorphic to Rn and
conclude that every point in a smooth n-manifold M is contained in an open
subset of M that is diﬀeomorphic to all of Rn.
The pair (U, ϕ) is called a chart on M. A smooth n-manifold is just a subset
M of some Euclidean space for which there exists a family {(Uα, ϕα) : α ∈A}
of charts
ϕα : Uα −→ϕα(Uα) ⊆Rn
with 8
α∈A Uα = M. Each ϕα supplies the points of Uα with n coordinates,
namely, those of its image in ϕα(Uα). If Uα ∩Uβ ̸= ∅, then a point p ∈Uα ∩Uβ
is supplied with two sets of coordinates, say,
ϕα (p) = (x1, . . . , xn)
and
ϕβ (p) = (y1, . . . , yn).
These are related by the transformation equations
ϕα ◦ϕ−1
β
: ϕβ(Uα ∩Uβ) −→ϕα(Uα ∩Uβ)
(x1, . . . , xn) =

ϕα ◦ϕ−1
β

(y1, . . . , yn)
and
ϕβ ◦ϕ−1
α
: ϕα(Uα ∩Uβ) −→ϕβ(Uα ∩Uβ)
(y1, . . . , yn) =

ϕβ ◦ϕ−1
α

(x1, . . . , xn).
Rn is itself a smooth n-manifold with a global chart (Rn, idRn). The corre-
sponding coordinates are just the standard coordinates u1, . . . , un. The same

4.3 Mathematical Machinery
207
is true of any open subset of Rn. To produce more interesting examples we
will need to develop a technique for manufacturing charts. One particularly
simple case is contained in the following exercise.
Exercise 4.3.2 Let V be an open set in Rn and g : V →R a smooth
real-valued function on V . Show that the graph {(x, g(x)) : x ∈V } of g in
Rn+1 = Rn × R is a smooth n-manifold with a global chart.
The sphere Sn is not the graph of a function of n variables, but it can
be covered by open sets each of which is the graph of a function, e.g., the
hemispheres with ui > 0 and ui < 0 for i = 1, . . . , n + 1. These functions
“parametrize” the hemispheres of Sn and the projections back onto the do-
mains provide charts. There are, however, many other ways of parametrizing
regions on the sphere. For example, the map
χ : [0, π] × [0, 2π] −→R3
deﬁned by
χ(φ, θ) = (sin φ cos θ, sin φ sin θ, cos φ)
(4.3.7)
maps into (in fact, onto) the 2-sphere S2 in R3 and parametrizes S2 by
standard spherical coordinates. The geometrical interpretation of φ and θ is
N
f
q
( sin f cos q, sin f sin q, cos f )
S
Fig. 4.3.3
the usual one from calculus (see Figure 4.3.3). Notice that χ is one-to-one on
(0, π) × (0, 2π) and covers all of S2 except the north and south poles and
the longitudinal curve at θ = 0 (or θ = 2π) joining them. On this open set
in S2, χ has an inverse and this has a chance of being a chart. In this case
one can actually calculate this inverse explicitly and show that it is, indeed,
smooth and therefore a chart. To obtain a chart covering the longitudinal

208
4 Prologue and Epilogue: The de Sitter Universe
curve joining the north and south poles (but not N and S themselves) one
can use the same map χ, but on the open set (0, π) × (−π, π). To cover N
and S themselves one simply deﬁnes an analogous map, but measuring the
angle φ from a diﬀerent axis. It is customary to be a bit sloppy and refer to
all of these collectively as “spherical coordinates” on S2.
We would like to apply this same idea in much more generality. Given
a subset M of Rm we will ﬁnd parametrizations of regions in M and hope
to “invert” them to obtain charts. More often than not, however, such in-
verses are diﬃcult or impossible to compute explicitly. Fortunately, there is a
remarkable result from real analysis that can often relieve one of the responsi-
bility of doing this. We will now state this result in the form most convenient
for our purposes and refer to [Sp1] for details.
If U is an open set in Rn and F : U →Rm is a smooth map we will write
F = (F 1, . . . , F m) for the coordinate functions of F, DjF i for the jth partial
derivative of F i and, for each a ∈U, the Jacobian of F at a will be written
F ′(a) = (Dj F i (a))1 ≤i ≤m
1 ≤j ≤n
=
⎛
⎜
⎝
D1F 1(a) · · · DnF 1(a)
...
...
D1F m(a) · · · DnF m(a)
⎞
⎟
⎠.
The Inverse Function Theorem applies to the special case in which m = n
and says that when the Jacobian F ′(a) is nonsingular, then F is a local
diﬀeomorphism near a. More precisely, we have
The Inverse Function Theorem: Let U be an open subset of Rn and
F : U →Rn a smooth map. Suppose a ∈U and F ′(a) is nonsingular (i.e.,
detF ′(a) ̸= 0). Then there exist open sets V and W in Rn with a ∈V ⊆U
and F(a) ∈W ⊆Rn such that the restriction of F to V
F | V : V −→W
is a diﬀeomorphism onto W, i.e., a smooth bijection with a smooth inverse
(F | V )−1 : W −→V.
Moreover,

(F | V )−1′
(F (a)) = (F | V )′ (a) .
Now let us suppose that we did not wish to go to the trouble of inverting
the spherical coordinate parametrization
χ : (0, π) × (0, 2π) −→R3
χ(φ, θ) = (sin φ cos θ, sin φ sin θ, cos φ)
explicitly on its image in S2. We would like to use the Inverse Function
Theorem to conclude nevertheless that it provides a chart at each point in
the image. Let’s write χ in more familiar notation as

4.3 Mathematical Machinery
209
x = sin φ cos θ
y = sin φ sin θ.
(4.3.8)
z = cos φ
Then the Jacobian of χ is given by
χ′(φ, θ) =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
∂x
∂φ
∂x
∂θ
∂y
∂φ
∂y
∂θ
∂z
∂φ
∂z
∂θ
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
=
⎛
⎜
⎜
⎜
⎝
cos φ cos θ
−sin φ sin θ
cos φ sin θ
sin φ cos θ
−sin φ
0
⎞
⎟
⎟
⎟
⎠.
We claim that, at each (φ, θ) ∈(0, π) × (0, 2π), χ′(φ, θ) has maximal rank
(namely, 2). To see this we compute the determinants of the various 2 × 2
submatrices.

∂x
∂φ
∂x
∂θ
∂y
∂φ
∂y
∂θ

= cos φ sin φ

∂x
∂φ
∂x
∂θ
∂z
∂φ
∂z
∂θ

= −sin2 φ sin θ

∂y
∂φ
∂y
∂θ
∂z
∂φ
∂z
∂θ

= sin2 φ cos θ
For φ ∈(0, π), sin φ ̸= 0 so, for any (φ, θ) ∈(0, π) × (0, 2π), at least one
of these is nonzero. Let’s suppose we are at a point a = (φ0, θ0) at which

∂x
∂φ(a)
∂x
∂θ (a)
∂y
∂φ(a)
∂y
∂θ (a)

̸= 0
(the other cases are treated in the same way). Deﬁne an open set
˜U = (0, π) × (0, 2π) × R

210
4 Prologue and Epilogue: The de Sitter Universe
in R3 and extend χ to a smooth map
˜χ : ˜U −→R3
by
˜χ(φ, θ, t) = (x(φ, θ), y(φ, θ), z(φ, θ) + t)
= (sin φ cos θ, sin φ sin θ, cos φ + t).
The Jacobian of ˜χ is
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
∂x
∂φ
∂x
∂θ
0
∂y
∂φ
∂y
∂θ
0
∂z
∂φ
∂z
∂θ
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
and this is nonsingular at (a, 0) = (φ0, θ0, 0) ∈R3. Since ˜χ(a, 0) = χ(a),
the Inverse Function Theorem implies that there are open sets V and W in
R3 with (a, 0) ∈V ⊆˜U and χ(a) ∈W ⊆R3 such that ˜χ|V : V →W is
a diﬀeomorphism. The restriction of this diﬀeomorphism to V ∩((0, π) ×
(0, 2π)×{0}) is therefore a diﬀeomorphism of an open set in (0, π)×(0, 2π)
(identiﬁed with (0, π) × (0, 2π) × {0}) containing a onto the intersection of
the image of χ : (0, π) × (0, 2π) →R3 with W. But this intersection is an
open set in S2 containing χ(a) so the inverse of this last diﬀeomorphism is a
chart for S2 at χ(a).
The bottom line here is this. The smooth parametrization (4.3.8) has
maximal rank at each point of (0, π) × (0, 2π) and from this alone the
Inverse Function Theorem implies that it can be smoothly inverted on an
open set about any point in (0, π) × (0, 2π), thus providing a chart in S2
near the image of that point. This is a very powerful technique that we will
use repeatedly, but one should not get carried away. Had we not known in
advance that χ : (0, π) × (0, 2π) →R3 is one-to-one, this would in no way
follow from what we have done with the Inverse Function Theorem, which
guarantees invertibility only near a point where the Jacobian is nonsingular.
Of course, since we do know that χ is one-to-one on (0, π)×(0, 2π) our argu-
ments show that its inverse is smooth (a map on S2 is smooth, by deﬁnition,
if it is smooth on some open set about each point).
In order to avoid repeating the same argument over and over again we
will now prove a general result that can be applied whenever we need to
manufacture a chart. Thus, let us suppose that M is a subset of some Rm, U
is an open set in Rn, where n ≤m, and
χ : U −→Rm

4.3 Mathematical Machinery
211
is a smooth map with χ(U) ⊆M. Write x1, . . . , xn for the standard
coordinates on Rn and χ1, . . . , χn, . . . , χm for the coordinate functions of χ.
Suppose a ∈U is a point at which the Jacobian χ′(a) has rank n. Then some
n × n submatrix of χ′(a) is nonsingular and, by renumbering the coordinates
if necessary, we may assume that
⎛
⎜
⎝
D1χ1(a)
· · ·
Dnχ1(a)
...
...
D1χn(a)
· · ·
Dnχn(a)
⎞
⎟
⎠= ∂(χ1, . . . , χn)
∂(x1, . . . , xn) (a)
is nonsingular. If m = n, then the Inverse Function Theorem implies that χ
gives a chart at χ(a). Now assume n < m, deﬁne ˜U = U × Rm−n and let
˜χ : ˜U −→Rm
be deﬁned by
˜χ(x, t) = ˜χ(x1, . . . , xn, t1, . . . , tm−n)
= (χ1(x), . . . , χn(x), χn+1(x) + t1, . . . , χm(x) + tm−n).
Then ˜χ is smooth and its Jacobian at (a, 0) is
⎛
⎜
⎜
⎜
⎝
∂(χ1, . . . , χn)
∂(x1, . . . , xn) (a)
O
∂(χn+1, . . . , χm)
∂(x1, . . . , xn)
(a)
I
⎞
⎟
⎟
⎟
⎠,
where O is the n × (m −n) zero matrix and I is the (m −n) × (m −n)
identity matrix. This is nonsingular so the Inverse Function Theorem implies
that there exist open sets V and W in Rm with (a, 0) ∈V ⊆˜U and ˜χ(a, 0) =
χ(a) ∈W ⊆Rm such that ˜χ|V : V →W is a diﬀeomorphism. The restriction
of this diﬀeomorphism to V ∩(U × {0}) is therefore a diﬀeomorphism of an
open set in U (identiﬁed with U × {0}) containing a onto the intersection of
the image of χ : U →Rm with W. But this intersection is an open set in M
containing χ(a) so the inverse of this last diﬀeomorphism is a chart for M
at χ(a). We will refer to a smooth map χ : U →M ⊆Rm, where U is open
in Rn and χ′(a) is nonsingular for each a in U, as a coordinate patch for M.
Thus, each point in the image χ(U) ⊆M is contained in an open subset of
M on which χ−1 is a chart for M.
We will have occasion to use a great variety of charts (i.e., coordinate
systems) on the manifolds of interest to us so we will pause now to write out
some of these.
Example 4.3.1 We begin with a simple, but useful generalization of the
spherical coordinate parametrization of S2. We deﬁne a map
χ : [0, π] × [0, π] × [0, 2π] −→R4

212
4 Prologue and Epilogue: The de Sitter Universe
by
χ(φ1, φ2, θ) = (sin φ1 cos φ2, sin φ1 sin φ2 cos θ, sin φ1 sin φ2 sin θ, cos φ1).
Thus,
u1 = sin φ1 cos φ2
u2 = sin φ1 sin φ2 cos θ
u3 = sin φ1 sin φ2 sin θ
(4.3.9)
u4 = cos φ1.
A little trigonometry shows that (u1)2 + (u2)2 + (u3)2 + (u4)2 = 1 so χ maps
into (in fact, onto) S3. The Jacobian is
⎛
⎜
⎜
⎜
⎜
⎝
cos φ1 cos φ2
−sin φ1 sin φ2
0
cos φ1 sin φ2 cos θ
sin φ1 cos φ2 cos θ
−sin φ1 sin φ2 sin θ
cos φ1 sin φ2 sin θ
sin φ1 cos φ2 sin θ
sin φ1 sin φ2 cos θ
−sin φ1
0
0
⎞
⎟
⎟
⎟
⎟
⎠
.
Computing the determinants of all of the 3 × 3 submatrices we obtain
sin2 φ1 cos φ1 sin φ2
−sin3 φ1 sin2 φ2 sin θ
sin3 φ1 sin2 φ2 cos θ
−sin3 φ1 sin φ2 cos φ2.
Note that φ1 = 0 gives the point N = (0, 0, 0, 1) and φ1 = π gives S =
(0, 0, 0, −1) and that all of the 3 × 3 determinants vanish at these points.
These determinants also vanish when φ2 = 0 and φ2 = π. For (φ1,, φ2) ∈
(0, π) × (0, π) one of the second or third determinants above is nonzero. We
conclude, in particular, that each point of (0, π)×(0, π)×(0, 2π) is contained
in an open set on which χ is a diﬀeomorphism onto an open set in S3 and the
inverse of this is a chart on S3 with coordinate functions (φ1,, φ2, θ). As for
S2 one obtains charts at the remaining points of S3 by either replacing (0, 2π)
with (−π, π) or interchanging the roles of some of the standard coordinates
on R4 and these charts are collectively called spherical (or hyper-spherical)
coordinates on S3. An obvious modiﬁcation provides, for any ρ > 0, spherical
coordinates
u1 = ρ sin φ1 cos φ2
u2 = ρ sin φ1 sin φ2 cos θ
u3 = ρ sin φ1 sin φ2 sin θ
(4.3.10)
u4 = ρ cos φ1

4.3 Mathematical Machinery
213
on the sphere
(u1)2 + (u2)2 + (u3)2 + (u4)2 = ρ2
of radius ρ in R4.
Exercise 4.3.3 Show that, for ρ > 0 and for φ1, φ2 and θ exactly as in the
case of S3, (4.3.10) determines a chart at each point of R4 except the origin.
Next we turn to the manifold that will occupy most of our time. It is a 4-
dimensional manifold in R5 and upon it we will build the de Sitter universe.
Various diﬀerent coordinate systems on it elucidate diﬀerent aspects of its
geometrical and physical structure so we will spend some time introducing a
number of them.
We consider the subset D of R5 given in terms of standard coordinates
u1, u2, u3, u4, u5 by
(u1)2 + (u2)2 + (u3)2 + (u4)2 −(u5)2 = 1.
Notice that the intersection of D with u5 = 0 is just S3 and, more generally,
setting u5 equal to some constant value u5
0 gives a slice of D that is just a
3-sphere of radius

1 + (u5
0)2.
Exercise 4.3.4 Show that, in fact, D is diﬀeomorphic to S3 × R. Hint:
Consider the map F : D →S3 × R given by
F(u1, u2, u3, u4, u5) =

1 + (u5)2−1
2 u1,

1 + (u5)2−1
2 u2,

1 + (u5)2−1
2 u3,

1 + (u5)2−1
2 u4, u5
.
By virtue of the analogy between D and x2 + y2 −z2 = 1 in R3 we picture D
as a “hyperboloid” in R5 whose cross-sections at constant u5 are 3-spheres
rather than circles (see Figure 4.3.4).
Example 4.3.2 Our ﬁrst parametrization of D is the most natural one in
light of this picture. We view D as a family of 3-spheres, one for each −∞<
u5 < ∞, with radii evolving hyperbolically and each such sphere parametrized
as in (4.3.10). Speciﬁcally, we deﬁne
u1 = cosh tG sin φ1 cos φ2
u2 = cosh tG sin φ1 sin φ2 cos θ
u3 = cosh tG sin φ1 sin φ2 sin θ
(4.3.11)
u4 = cosh tG cos φ1
u5 = sinh tG

214
4 Prologue and Epilogue: The de Sitter Universe
u5
S3
Fig. 4.3.4
for 0 ≤φ1 ≤π, 0 ≤φ2 ≤π, 0 ≤θ ≤2π, and −∞< tG < ∞. Then
(u1)2 + (u2)2 + (u3)2 + (u4)2 −(u5)2 = 1 and the image of the map is all
of D. For any ﬁxed t0
G, the slice at u5 = sinh t0
G is the spherical coordinate
parametrization of the 3-sphere of radius cosh t0
G.
Exercise 4.3.5 Write out the Jacobian of the map (4.3.11) and show that
it has rank 4 on
0 < φ1 < π, 0 < φ2 < π, 0 < θ < 2π, −∞< tG < ∞
and
0 < φ1 < π, 0 < φ2 < π, −π < θ < π, −∞< tG < ∞
and so provides a chart at the image of each such point. Note that charts
at points with φ1 = 0, π and φ2 = 0, π can be obtained by interchanging
standard coordinates on R5.
We conclude that each point of D is contained in an open set on which
(φ1, φ2, θ, tG) are local coordinates and for this reason they are often called
global coordinates for D, although the charts themselves are not globally
deﬁned on D. The motivation behind the remaining parametrizations of D
that we intend to introduce now may appear rather obscure, but will become
clear after we have introduced some geometry into our picture.

4.3 Mathematical Machinery
215
Example 4.3.3 The parametrization of D we introduce here diﬀers from
the global coordinates (φ1, φ2, θ, tG) only in that we will replace tG by a
new fourth coordinate tC that we would like to be related to tG by
dtG
dtC
= cosh tG
tC = 0 ⇐⇒tG = 0
(the reason we would like this will emerge shortly). Separating variables,
integrating the equation and using the initial condition gives
tC = 2 arctan(etG) −π
2
(4.3.12)
so that
−π
2 < tC < π
2 .
Exercise 4.3.6 Show that
cosh tG =
1
cos tC
for −π
2 < tC < π
2 .
It follows that the mapping (φ1, φ2, θ, tC) →(φ1, φ2, θ, tG) is smooth with
nonsingular Jacobian for −π
2 < tC < π
2 and is therefore a local diﬀeomor-
phism. Composing this with the global coordinate parametrization of D we
ﬁnd that each point of D is contained in an open set on which (φ1, φ2, θ, tC)
are coordinates. For reasons that we will describe in Section 4.5 these are
called conformal coordinates.
Example 4.3.4 Next we introduce what are called planar coordinates.
These are denoted (tP , x1, x2, x3) and cover only half of D. They arise
from the mapping
χ : R4 −→R5
deﬁned by
u1 = x1 etP
u2 = x2 etP
u3 = x3 etP
(4.3.13)
u4 = cosh tP −1
2

x12 +

x22 +

x32
etP
u5 = sinh tP + 1
2

x12 +

x22 +

x32
etP .
It is easy to check that (u1)2 + (u2)2 + (u3)2 + (u4)2 −(u5)2 = 1, but in this
case
u4 + u5 = etP

216
4 Prologue and Epilogue: The de Sitter Universe
so only the portion u4 + u5 > 0 of D is covered by the image. For these,
tP = ln(u4 + u5) and so
x1 =
u1
u4 + u5
x2 =
u2
u4 + u5
(4.3.14)
x3 =
u3
u4 + u5
tP = ln(u4 + u5).
We will denote by D+ this portion of D. The tP = t0
P slices of D+ are the
intersections with D+ of the hyperplanes u4 + u5 = et0
P (see Figure 4.3.5).
u4 + u5 = eto
P
u4 + u5  = 0
u5
Fig. 4.3.5
Exercise 4.3.7 Compute the Jacobian of (4.3.13) and show that it has rank
4 at each point of R4.
Thus, each point of D+ is contained in an open subset of D+ on which
(x1, x2, x3, tP ) are coordinates.

4.3 Mathematical Machinery
217
Example 4.3.5 Our ﬁnal parametrization of D provides it with what are
called hyperbolic coordinates (φ, θ, ψ, tH). We will leave the details to the
reader.
Exercise 4.3.8 Deﬁne a smooth map of R4 into R5 by
u1 = cos φ sinh tH sinh ψ
u2 = sin φ cos θ sinh tH sinh ψ
u3 = sin φ sin θ sinh tH sinh ψ
(4.3.15)
u4 = cosh tH
u5 = sinh tH cosh ψ
(a) Verify that (u1)2 + (u2)2 + (u3)2 + (u4)2 −(u5)2 = 1.
(b) Let t0
H be a constant and consider the tH = t0
H slice of D. Show that if
t0
H = 0 this slice is a point and if t0
H ̸= 0 the points on the slice have
u4 = cosh t0
H and
(u1)2 + (u2)2 + (u3)2 −(u5)2 = −sinh2 t0
H.
(c) Let t0
H and ψ0 be two nonzero constants and consider the set of points in
D with tH = t0
H and ψ = ψ0. Show that u4 and u5 are constant and φ
and θ parametrize a 2-sphere in (u1, u2, u3)-space.
(d) Compute the Jacobian of (4.3.15) and show that it is nonsingular for
0 < φ < π, 0 < θ < 2π, ψ ̸= 0, and tH ̸= 0.
With these examples in hand we now return to the general development.
Each point on a smooth surface in R3 has associated with it a 2-dimensional
“tangent plane” consisting of all the velocity vectors to all smooth curves
in the surface through that point. The analogous construction on a smooth
n-manifold M in Rm proceeds as follows. We will write u1, . . . , um for the
standard coordinates in Rm and use x1, . . . , xn for standard coordinates in
Rn. If I ⊆R is a (nondegenerate) interval, then a continuous map
α : I −→M
α(t) = (u1(t), . . . , um(t))
is called a curve in M. α is said to be smooth if each ui(t), i = 1, . . . , m, is
C∞and if α’s velocity vector (or tangent vector)
α′(t) =
du1
dt , . . . , dum
dt

is nonzero for each t in I. Useful examples of smooth curves can be con-
structed from a coordinate patch
χ : U −→M ⊆Rm
χ(x1, . . . , xn) = (u1(x1, . . . , xn), . . . , um(x1, . . . , xn)).

218
4 Prologue and Epilogue: The de Sitter Universe
For each i = 1, . . . , n, the ith coordinate curve of χ is obtained by holding
all xj, j ̸= i, ﬁxed (so t = xi); its velocity vector is denoted
χi = ∂χ
∂xi =
∂u1
∂xi , . . . , ∂um
∂xi

.
If p = χ

x1
0, . . . , xn
0

we will write χi(p) rather than the more accurate
χi

x1
0, . . . , xn
0

and adopt the usual custom of picturing χi(p) with its tail
at p in Rm (Figure 4.3.6). The χi are called coordinate velocity vectors corre-
sponding to χ. Being columns of the Jacobian these are linearly independent
at each p ∈χ(U) and so span an n-dimensional linear subspace of Rm called
the tangent space to M at p and denoted
Tp(M) = Span {χ1(p), . . . , χn(p)}.
−1( p)
j( p)
i( p)
(U )
p
IRn
xi

U
xj
M ⊆ IRm
Fig. 4.3.6
To see that the subspace Tp(M) does not depend on the particular coordinate
patch χ with which it is deﬁned we will obtain a more intrinsic description
of it. Let α : I →M be a smooth curve in M that passes through p at
t = t0 (α(t0) = p). By continuity of α there is some subinterval J of I
containing t0 which α maps entirely into the image χ(U) of the coordinate
patch χ. Then χ−1 ◦α is a smooth curve t →(x1(t), . . . , xn(t)) in U so α can
be written
α(t) = χ(x1(t), . . . , xn(t)),
t ∈J.
By the chain rule,
α′(t0) = dx i
dt (t0)χi(p).
(4.3.16)
Thus, the velocity vector to every smooth curve in M through p is in Tp(M).

4.3 Mathematical Machinery
219
Exercise 4.3.9 Show that, conversely, every nontrivial linear combina-
tion of χ1(p), . . . , χn(p) is the velocity vector of some smooth curve in M
through p.
Thus, Tp(M) can be identiﬁed with the set of velocity vectors to smooth
curves in M through p (together with the zero vector which one can think
of as the velocity vector to the, admittedly nonsmooth, constant curve in
M through p). In particular, the coordinate velocity vectors for any other
coordinate patch
˜χ : ˜U −→M
with p ∈˜χ( ˜U) lie in Tp(M) and so span the same subspace of Rm.
Exercise 4.3.10 Let x1, . . . , xn and ˜x1, . . . , ˜xn denote the coordinates in U
and ˜U, respectively, and χ : U →M and ˜χ : ˜U →M coordinate patches
with χ(U) ∩˜χ( ˜U) ̸= ∅. Then on χ−1(χ(U) ∩˜χ( ˜U)) the map ˜χ−1 ◦χ gives
˜x1, . . . , ˜xn as functions of x1, . . . , xn
˜xi = ˜xi(x1, . . . , xn),
i = 1, . . . , n,
and
χ(x1, . . . , xn) = ˜χ(˜x1(x1, . . . , xn), . . . , ˜xn(x1, . . . , xn)).
Show that, at each point of χ−1(χ(U) ∩˜χ( ˜U)),
χi = ∂˜xj
∂xi ˜χj,
i = 1, . . . , n.
Show, moreover, that if p ∈χ(U) ∩˜χ( ˜U) and v ∈Tp(M) with v = viχi(p)
and v = ˜vj ˜χj(p), then
˜vj = ∂˜xj
∂xi (χ−1(p))vi,
j = 1, . . . , n.
The elements of Tp(M) are called tangent vectors to M at p.
Since we have determined that the event world is “locally like M” at each
of its points we elect to model it by a smooth 4-manifold whose tangent spaces
are all provided with the structure of Minkowski spacetime, i.e., a Lorentz
inner product. A smooth assignment of an inner product to each tangent
space of a manifold is called a “metric” on M (not to be confused with the
term used in topology for a “distance function”, although there are some
connections). More precisely, a metric (or metric tensor) g on a manifold M
is an assignment to each tangent space Tp(M), p ∈M, of an inner product
gp = ⟨, ⟩p such that the component functions gij deﬁned by
gij (x1, . . . , xn) = gp(χi(p), χj(p)) = ⟨χi(p), χj(p)⟩p
are smooth on U for each coordinate patch χ : U →M. If each inner
product gp has index zero, g is called a Riemannian metric on M; if each

220
4 Prologue and Epilogue: The de Sitter Universe
gp has index 1, then g is a Lorentzian (or Lorentz) metric. A spacetime is
a smooth 4-manifold on which is deﬁned a Lorentzian metric. In Euclidean
space Rn, for example, one can take the identity map χ = idRn as a global
chart so that χ1, . . . , χn are constant and equal to the standard basis vectors
e1, . . . , en for Rn. Each Tp(Rn) can therefore be identiﬁed with Rn and one
can deﬁne a Riemannian metric g on Rn by simply taking gp = ⟨, ⟩for
each p ∈Rn. Then gij (p) = δij , i, j = 1, . . . , n, for each p. On R4 one can
deﬁne a Lorentzian metric g by specifying that the inner product gp on each
Tp(R4) = R4 satisﬁes gp (χi(p), χj(p)) = gp(ei, ej) = ηij , i, j = 1, 2, 3, 4. The
resulting spacetime is often denoted R3,1 although, morally at least, it is just
Minkowski spacetime M.
Exercise 4.3.11 Suppose M is a manifold and g is a metric deﬁned on
M. Let χ : U →M and ˜χ : ˜U →M be coordinate patches for M with
χ(U) ∩˜χ( ˜U) ̸= ∅and with coordinates x1, . . . , xn on U and ˜x1, . . . , ˜xn on ˜U.
Show that
˜gij = ∂xk
∂˜xi
∂xl
∂˜xj gkl,
i, j = 1, . . . , n.
and conclude that, if the gkl are smooth, then so are the ˜gkl. Thus, at any
point it is enough to check smoothness in a single coordinate patch.
The examples of interest to us here (but certainly not all interesting ex-
amples) arise in a very simple way. If M is an n-manifold in Rm, then one
can endow Rm with various inner products and simply “restrict” these to
each Tp(M). We will illustrate the idea ﬁrst for S2 ⊆R3.
Consider a spherical coordinate parametrization
χ(φ, θ) = (sin φ cos θ, sin φ sin θ, cos φ)
of S2(x1 = φ, x2 = θ). The coordinate velocity vectors (columns of the
Jacobian) are
χ1 = χφ = (cos φ cos θ, cos φ sin θ, −sin φ)
and
χ2 = χθ = (−sin φ sin θ, sin φ cos θ, 0).
At each point in the image of χ these are tangent vectors which we can regard
as vectors in R3 and compute the R3-inner products
⟨χ1, χ1⟩= cos2 φ cos2 θ + cos2 φ sin2 θ + sin2 φ = 1
⟨χ2, χ2⟩= sin2 φ sin2 θ + sin2 φ cos2 θ = sin2 φ
⟨χ1, χ2⟩= ⟨χ2, χ1⟩= 0.
Thus, if we deﬁne a (Riemannian) metric g on S2 by taking gp(v, w) = ⟨v, w⟩
for each p ∈S2 and all v, w ∈Tp(S2) ⊆R3 the components gij , i, j = 1, 2,
are given by

4.3 Mathematical Machinery
221
g11
g12
g21
g22

=
1
0
0
sin2 φ

(4.3.17)
and these are certainly smooth.
Exercise 4.3.12 Deﬁne a Riemannian metric on S3 by restricting the usual
Euclidean inner product ⟨, ⟩on R4 to each Tp(S3), p ∈S3. Show that the
metric components gij, i, j = 1, 2, 3, relative to the spherical coordinates
x1 = φ1, x2 = φ2, x3 = θ given by (4.3.9) are
⎛
⎝
g11
g12
g13
g21
g22
g23
g31
g32
g33
⎞
⎠=
⎛
⎝
1
0
0
0
sin2 φ1
0
0
0
sin2 φ1 sin2 φ2
⎞
⎠.
To obtain examples of Lorentz metrics in this way we will need to be-
gin with an inner product of index one on some Rm to restrict to a man-
ifold M ⊆Rm. This can be done in any dimension, but we will restrict
our attention to the one example we would like to understand, that is, the
de Sitter spacetime. For this we begin with the 5-dimensional analogue of
Minkowski spacetime. Speciﬁcally, on R5 with standard coordinate functions
u1, . . . , u4, u5 we introduce an inner product denoted ( , ) and deﬁned by
(p, q) = ((p1, . . . , p4, p5), (q1, . . . , q4, q5))
= p1q1 + · · · + p4q4 −p5q5
= ηij piqj,
where
ηij =
⎧
⎪
⎨
⎪
⎩
1 ,
i = j = 1, 2, 3, 4
−1 ,
i = j = 5
0 ,
i ̸= j
(using η for this as well as the corresponding matrix for M should lead to no
confusion since the context will always indicate which is intended). We will
denote by M5 the real vector space R5 with this inner product. Notice that
the manifold D in R5 is just the set of points p in M5 with
(p, p) = 1.
We now appropriate for M5 all of the basic terminology and notation in-
troduced for Minkowski spacetime, e.g., v ∈M5 is spacelike if (v, v) > 0,
timelike if (v, v) < 0 and null if (v, v) = 0, the null cone CN(x0) at any
x0 ∈M5 is the set CN(x0) = {x ∈M5 : (x −x0, x−x0) = 0}, the time cone
at x0 is CT (x0) = {x ∈M5 : (x −x0, x −x0) < 0}, and so on. Indeed, all of
the basic geometry of M is completely insensitive to the number of “spatial
dimensions” and so generalizes immediately to M5. Use the following few
exercises as an opportunity to persuade yourself that this is true.

222
4 Prologue and Epilogue: The de Sitter Universe
Exercise 4.3.13 Prove that two nonzero null vectors v and w in M5 are
orthogonal if and only if they are parallel.
Exercise 4.3.14 Let {e1, . . . , e4, e5} be any orthonormal basis for M5
((ei, ej) = ηij ). Show that if v = viei is timelike and w = wjej is either
timelike or null and nonzero, then either
(a) v5w5 > 0, in which case (v, w) < 0, or
(b) v5w5 < 0, in which case (v, w) > 0.
With this last exercise one can introduce time orientations (future-directed
and past-directed) for timelike and nonzero null vectors in M5 in precisely
the same way as it was done in Minkowski spacetime (Section 1.3).
Exercise 4.3.15 Prove that the sum of any ﬁnite number of vectors in M5,
all of which are timelike or null and all future-directed (resp., past-directed)
is timelike and future-directed (resp., past-directed) except when all of the
vectors are null and parallel, in which case the sum is null and future-directed
(resp., past-directed).
The causality relations ≪and < are deﬁned on M5 just as they are on
M (x ≪y ⇐⇒y −x is timelike and future-directed and x < y ⇐⇒y −x is
null and future-directed) and all of their basic properties are proved in the
same way.
Exercise 4.3.16 Show that, for distinct points x and y in M5,
x < y
if and only if
)
x /≪y
and
y ≪z
=⇒
x ≪z .
An orthogonal transformation of M5 is a linear transformation L : M5 →
M5. satisfying (Lx, Ly) = (x, y) for all x, y ∈M5 and these have matri-
ces Λ =

Λij

i,j=1,2,3,4,5 relative to orthonormal bases deﬁned exactly as in
M (Section 1.2) which satisfy ΛTηΛ = η, where η = (ηij )i,j=1,2,3,4,5. Those
which satisfy, in addition, Λ55 ≥1 are called orthochronous and these pre-
serve the time orientation of all timelike and nonzero null vectors and so pre-
serve the causality relations (x ≪y ⇐⇒Lx ≪Ly and x < y ⇐⇒Lx < Ly).
Just as in M, ΛT ηΛ = η implies det Λ = ±1 and we single out those with
det Λ = 1 to refer to as proper. The collection
L5 =
6
Λ =

Λi
j

i,j=1,2,3,4,5 : ΛTηΛ = η, Λ5
5 ≥1, det Λ = 1
7
is the analogue in M5 of the proper, orthochronous Lorentz group L.
And so the story goes. Essentially everything purely geometrical that we
have said about M and L is equally true of M5 and L5. Indeed, even
Zeeman’s Theorem 1.6.2 remains true for M5. More precisely, a bijection
F : M5 →M5 satisfying x < y if and only if F(x) < F(y) (or, equivalently,

4.3 Mathematical Machinery
223
x ≪y if and only if F(x) ≪F(y)) is called a causal automorphism and one
proves, essentially as in Section 1.6, that any such is the composition of an
orthochronous orthogonal transformation of M5, a translation of M5 and
a dilation of M5. We will not belabor this point any further here, but will
simply leave it to the skeptical reader to check that when we need a result
proved for M to be true in M5, it is.
Of course, something is lost in moving from M to M5 and that is the
physical interpretation (the event world is, to the best of our knowledge,
4-dimensional, not 5-dimensional). To return to physics we must return to
D ⊆M5.
Our intention is to do for D ⊆M5 what we did for S2 ⊆R3 and S3 ⊆R4,
that is, restrict the inner product of the ambient space to each tangent space
of the manifold, thereby deﬁning a metric.
Remark:
The fact that we actually get a metric in this way is not as obvious
as it was in the positive deﬁnite case. The restriction of ( , ) to each Tp(D)
is surely bilinear and symmetric, but is not obviously nondegenerate nor is
it obviously of index one. That it is, in fact, nondegenerate and of index one
will follow from the calculations we are about to perform.
We will describe the metric components ﬁrst in global coordinates (x1 = φ1,
x2 = φ2, x3 = θ, x4 = tG). The coordinate velocity vectors are, from
Example 4.3.2,
χ1 = χφ1 = (cosh tG cos φ1 cos φ2, cosh tG cos φ1 sin φ2 cos θ,
cosh tG cos φ1 sin φ2 sin θ, −cosh tG sin φ1, 0)
χ2 = χφ2 = (−cosh tG sin φ1 sin φ2, cosh tG sin φ1 cos φ2 cos θ,
cosh tG sin φ1 cos φ2 sin θ, 0, 0)
χ3 = χθ = (0, −cosh tG sin φ1 sin φ2 sin θ,
cosh tG sin φ1 sin φ2 cos θ, 0, 0)
χ4 = χtG = (sinh tG sin φ1 cos φ2, sinh tG sin φ1 sin φ2 cos θ,
sinh tG sin φ1 sin φ2 sin θ, sinh tG cos φ1, cosh tG).
Thus, for example,
g11 = (χ1, χ1) = cosh2 tG cos2 φ1 cos2 φ2 + cosh2 tG cos2 φ1 sin2 φ2 cos2 θ
+ cosh2 tG cos2 φ1 sin2 φ2 sin2 θ + cosh2 tG sin2 φ1 −0
= cosh2 tG [cos2 φ1 cos2 φ2 + cos2 φ1 sin2 φ2 + sin2 φ1]
= cosh2 tG
g44 = (χ4, χ4) = sinh2 tG sin2 φ1 cos2 φ2 + sinh2 tG sin2 φ1 sin2 φ2 cos2 θ
+ sinh2 tG sin2 φ1 sin2 φ2 sin2 θ + sinh2 tG cos2 φ1
−cosh2 tG

224
4 Prologue and Epilogue: The de Sitter Universe
= sinh2 tG

sin2 φ1 cos2 φ2 + sin2 φ1 sin2 φ2 cos2 θ
+ sin2 φ1 sin2 φ2 sin2 θ + cos2 φ1

−cosh2 tG
= sinh2 tG −cosh2 tG
= −1
g23 = (χ2, χ3) = 0 −cosh2 tG sin2 φ1 sin φ2 cos φ2 sin θ cos θ
+ cosh2 tG sin2 φ1 sin φ2 cos φ2 sin θ cos θ
= 0
Exercise 4.3.17 Compute the rest and show that the only nonzero
gij , i, j = 1, 2, 3, 4, are
g11 = cosh2 tG
g22 = cosh2 tG sin2 φ1
g33 = cosh2 tG sin2 φ1 sin2 φ2
g44 = −1
Notice that the restriction of the M5 inner product does, indeed, deﬁne a
Lorentz metric on D since, at each point p ∈D, there is a basis e1, e2, e3, e4
for the tangent space Tp(D) satisfying g(ei, ej) = ηij , i, j = 1, 2, 3, 4. Indeed,
one can take e4 = χ4(p) and let e1, e2, e3 be the normalized versions of
χ1, χ2, χ3, i.e.,
e1 =
1
cosh tG
χ1(p)
e2 =
1
cosh tG sin φ1
χ2(p)
e3 =
1
cosh tG sin φ1 sin φ2
χ3(p).
With this Lorentz metric, D is called the de Sitter spacetime and will be
denoted dS.
Before recording more examples we will introduce a more traditional and
generally more convenient means of displaying the metric components. We
will illustrate the idea ﬁrst for the 2-sphere S2. To facilitate the notation we
will (temporarily) denote the standard spherical coordinates φ and θ on S2
by x1 and x2, respectively.
χ : (0, π) × (0, 2π) −→S2
χ(x1, x2) = (sin(x1) cos(x2), sin(x1) sin(x2), cos(x1))

4.3 Mathematical Machinery
225
Let α : [a, b] →S2 be a smooth curve in S2 given by
α(t) = χ(x1(t), x2(t))
= (sin(x1(t)) cos(x2(t)), sin(x1(t)) sin(x2(t)), cos(x1(t))).
For each t in [a, b], the Chain Rule gives
α′(t) = dx 1
dx χ1(x1(t), x2(t)) + dx 2
dt χ2 (x1(t), x2(t))
= dx i
dt χi(x1(t), x2(t)).
The Riemannian metric g we have deﬁned on S2 allows us to compute the
squared magnitude of α′(t) as follows.
g(α′(t), α′(t)) = g

dx i
dt χi, dx j
dt χj

= dx i
dt
dx j
dt g(χi, χj)
= gij
dx i
dt
dx j
dt
The square root of g(α′(t), α′(t)) is the curve’s “speed” which, when inte-
grated from a to t gives the arc length s = s(t). Consequently,
ds
dt
2
= gij
dx i
dt
dx j
dt
which it is customary to write more succinctly in “diﬀerential form” as
ds2 = gij dx i dx j.
Reverting to φ and θ and substituting the values of gij that we have computed
((4.3.17)) gives
ds2 = dφ2 + sin2 φdθ2.
(4.3.18)
This is generally called the line element of S2. We regard it as a horizontal
display of the metric components g11 = 1, g22 = sin2 φ, g12 = g21 = 0 and a
convenient way to remember how to compute arc lengths.
Remark:
The symbols in (4.3.18) can all be given precise meanings in the
language of diﬀerential forms, but we will have no need to do so.
The same notational device is employed for any Riemannian or Lorentz
metric. For example, writing x1 = x, x2 = y, x3 = z for the standard
coordinates on R3 one has
ds2 = dx 2 + dy2 + dz 2

226
4 Prologue and Epilogue: The de Sitter Universe
(g11 = g22 = g33 = 1 and gij = 0 for i, j = 1, 2, 3, i ̸= j), whereas, in spherical
coordinates on R3,
ds2 = dρ2 + ρ2(dφ2 + sin2 φdθ2).
(4.3.19)
For R3,1 it would be
ds2 = (dx 1)2 + (dx 2)2 + (dx 3)2 −(dx 4)2,
(4.3.20)
while for S3 with spherical coordinates φ1, φ2, θ,
ds2 = dφ2
1 + sin2 φ1

dφ2
2 + sin2 φ2dθ2
.
(4.3.21)
Finally, for de Sitter spacetime in global coordinates, Exercise 4.3.17 gives
ds2 = cosh2 tG

dφ2
1 + sin2 φ1

dφ2
2 + sin2 φ2dθ2
−dt2
G.
(4.3.22)
Exercise 4.3.18 Show that the line element for de Sitter spacetime, written
in conformal coordinates (φ1, φ2, θ, tC) is
ds2 =
1
cos2 tC

dφ2
1 + sin2 φ1

dφ2
2 + sin2 φ2dθ2
−dt2
C

.
Exercise 4.3.19 Show that the line element for de Sitter spacetime, written
in planar coordinates (x1, x2, x3, tP ) is ds2 = e2tP ((dx 1)2 + (dx 2)2 +
(dx 3)2) −dt2
P , or, using spherical coordinates for x1, x2, x3,
ds2 = e2tP (dρ2 + ρ2(dφ2 + sin2 φdθ2)) −dt2
P .
Exercise 4.3.20 Show that the line element for de Sitter spacetime, written
in hyperbolic coordinates (φ, θ, ψ, tH) is
ds2 = sinh2 tH(dψ2 + sinh2 ψ(dφ2 + sin2 φdθ2)) −dt2
H.
One should notice, however, that in the case of dS (or any other Lorentz
manifold) the interpretation of the line element requires some care. Just as
in Minkowski spacetime, a curve in dS might well have a velocity vector that
is null at each point so that gij dx i
dt
dx j
dt is zero everywhere and its “arc length”
is zero. If the velocity vector is timelike everywhere, then
 ds
dt
2 = gij dx i
dt
dx j
dt
would make ds
dt pure imaginary. To exercise the proper care we mimic our
deﬁnitions for M.
If M is a spacetime, then a smooth curve α : I →M is said to be spacelike,
timelike, or null if its tangent vector α′(t) satisﬁes gα(t)(α′(t), α′(t)) > 0,
gα(t)(α′(t), α′(t)) < 0, or gα(t)(α′(t), α′(t)) = 0 for each t ∈I. If I has
an endpoint t0 we require that these conditions be satisﬁed there as well in
the sense that any smooth extension of α to an open interval about t0 has a
tangent vector at t0 satisfying the required condition. Notice that in dS this

4.3 Mathematical Machinery
227
simply amounts to the requirement that each α′(t), regarded as a vector in
M5 is spacelike, timelike or null in M5. We will say that a timelike or null
curve in dS is future-directed (resp., past-directed) if each α′(t), regarded as
a vector in M5, is future-directed (resp., past-directed).
Remark:
The notion of a spacetime, as we have deﬁned it, is very general
and there are examples in which it is not possible to deﬁne unambiguous
notions of future-directed and past-directed (see [HE], page 130). This is
essentially a sort of “orientability” issue analogous to the fact that, for some
surfaces in R3 such as the M¨obius strip, it is impossible to deﬁne a continuous
nonzero normal vector ﬁeld over the entire surface. We care only about M
and dS and so the issue will not arise for us.
A future-directed timelike curve in dS is called a timelike worldline and we
ascribe to such a curve the same physical interpretation we did in M (the
worldline of some material particle). Just as in M one can deﬁne the proper
time length L(α) of such a curve α : [a, b] →dS by
L(α) =
 b
a

−(α′(t), α′(t)) dt
and a proper time parameter τ = τ(t) along α by
τ = τ(t) =
 t
a

−(α′(u), α′(u)) du.
We will go even further and induce causality relations on dS from those on
M5. Speciﬁcally, for distinct points x and y in dS we will deﬁne x ≪y if and
only if y −x is timelike and future-directed in M5 and x < y if and only if
y −x is null and future-directed in M5.
Remark:
Although we will have no need of the result, we point out that,
with these deﬁnitions, Zeeman’s Theorem 1.6.2 remains true in dS in the
following sense. A bijection F : dS →dS that preserves < in both directions
also preserves ≪in both directions and is, in fact, the restriction to dS of
some orthochronous orthogonal transformation of M5 (see [Lest]).
Let us think for a moment about the sort of timelike curve in dS that
should model the worldline of a material particle that is “free”, i.e., in free
fall. As we saw in Section 4.2, at each point on such a worldline there is a
local inertial frame (freely falling elevator) from which it can be observed
and that, relative to such a frame, the worldline will appear (approximately)
“straight.” Curves in a manifold with (Riemannian or Lorentz) metric that
are “locally straight” are called geodesics. There are various approaches to the
formulation of a precise deﬁnition, but we will follow a path that is adapted
to the simplicity of the examples we wish to consider. The motivation for our
approach is most easily understood in the context of smooth surfaces in R3
so we will ﬁrst let the reader work through some of this.

228
4 Prologue and Epilogue: The de Sitter Universe
Exercise 4.3.21 Let M be a smooth surface (i.e., 2-manifold) in R3 with
Riemannian metric g obtained by restricting the R3-inner product ⟨, ⟩to each
tangent space. Let χ : U →M ⊆R3 be a coordinate patch for M and let
α = α(t) be a smooth curve in M whose image is contained in χ(U). At each
t the tangent vector α′(t) is, by deﬁnition, in Tα(t)(M), but the acceleration
α′′(t) in general will not lie in Tα(t)(M) since it will have both tangential and
normal components, i.e.,
α′′(t) = α′′
tan(t) + α′′
nor(t),
where α′′
tan(t) ∈Tα(t)(M) and ⟨α′′
nor(t), v⟩= 0 for every v ∈Tα(t)(M).
(a) Write α(t) = χ(x1(t), x2(t)) and show that
α′′(t) = d2xi
dt 2 χi(x1(t), x2(t)) + dx i
dt
dx j
dt χij (x1(t), x2(t)),
where
χij =
∂
∂xj χi =
 ∂2u1
∂xj∂xi ,
∂2u2
∂xj∂xi ,
∂2u3
∂xj∂xi

.
(b) Show that the cross product χ1 × χ2 is nonzero at each point of χ(U)
and so N = χ1 × χ2/∥χ1 × χ2∥is a unit normal vector to each point
of χ(U). Note: This normal vector ﬁeld generally exists only locally on
χ(U). There are surfaces (such as the M¨obius strip) on which it is not
possible to deﬁne a continuous, nonvanishing ﬁeld of normal vectors.
(c) Resolve χij into tangential and normal components to obtain
χij = Γr
ij χr + Lij N,
where ⟨χij , χk⟩= Γr
ij grk and Lij = ⟨χij , N⟩.
(d) Deﬁne Γr,ij = grlΓl
ij and show that
∂gij
∂xk = Γi,jk + Γj,ik.
(4.3.23)
(e) Denote by (gij ) the inverse of the matrix (gij ) and show that
Γr
ij = 1
2grk
∂gik
∂xj + ∂gjk
∂xi −∂gij
∂xk

.
(4.3.24)
Hint: Permute the indices i j k in (4.3.23) to obtain expressions for each
of the derivatives in (4.3.24) and combine them using the symmetries
Γi,jk = Γi,kj , i, j, k = 1, 2.

4.3 Mathematical Machinery
229
(f) Conclude that
α′′
tan(t) =
d2xr
dt2 + Γr
ij (x1(t), x2(t))d xi
dt
d xj
dt

χr(x1(t), x2(t))
and
α′′
nor(t) = Lij (x1(t), x2(t)) N(x1(t), x2(t)).
If, in Exercise 4.3.21, t = s is the arc length parameter for α, then α′′(s) is
the curvature vector of α. One regards α′′
nor as that part of α’s curvature that
it must possess simply by virtue of the fact that it is constrained to remain
in M, whereas α′′
tan is the part α contributes on its own by “curving in M.”
Curves with α′′
tan = 0 are thought to “curve only as much as they must to
remain in M” and so are the closest thing in M to a straight line (we will
see shortly that in S2 these are just constant speed parametrizations of great
circles, i.e., intersections of S2 with planes through the origin in R3).
There is only one obstacle to carrying out the entire calculation in
Exercise 4.3.21 for any χ(U) on an n-manifold M in Rm and that is ex-
istence of the unit normal ﬁeld N. In Rm, m > 3, there is no natural
concept of a cross product and, in any case, the tangent space Tp(M) is
not spanned by just two vectors. For the simple examples of interest to us,
however, the obstacle is easily overcome. At each point p on the n-sphere
Sn ⊆Rn+1, for instance, the vector p in Rn+1 is itself a unit normal vector
to Tp(Sn). Indeed, if α is any smooth curve in Sn through p at t = t0, then
α(t) = (u1(t), . . . , un+1(t)) implies
(u1(t))2 + · · · + (un+1(t))2 = 1
so
2u1(t)du1
dt + · · · + 2un+1(t)dun+1
dt
= 0
which, at t = t0, gives
⟨p, α′(t0)⟩= 0.
Similarly, if p ∈dS ⊆M5 and α(t) = (u1(t), · · · , u5(t)) is a smooth curve in
dS with α(t0) = p, then
(u1(t))2 + · · · + (u4(t))2 −(u5(t))2 = 1
gives
(p, α′(t0)) = 0
so p is a unit normal vector to Tp(dS) (“unit” and “normal” now refer to the
Lorentz metric of dS, of course).

230
4 Prologue and Epilogue: The de Sitter Universe
In either of these cases the calculations in Exercise 4.3.21 (with N replaced
by N(p) = p) can be repeated verbatim to resolve the acceleration α′′(t) of
a smooth curve into tangential and normal components with
α′′
tan(t) =
d2xr
d t2 + Γr
ij
d xi
dt
d xj
dt

χr
(4.3.25)
in any coordinate patch, where
Γr
ij = 1
2grk
∂gik
∂xj + ∂gjk
∂xi −∂gij
∂xk

(4.3.26)
(these are called the Christoﬀel symbols of the metric in the given coordinate
system).
Those curves for which α′′
tan(t) = 0 for each t are called geodesics and they
satisfy
d2xr
dt 2 + Γr
ij
d xi
dt
d xj
dt
= 0
(4.3.27)
in any coordinate patch.
Remark:
Geodesics can be introduced in many ways and in much more
general contexts, but the end result is always the system (4.3.27) of ordinary
diﬀerential equations. Notice that equations (4.3.27) are trivially satisﬁed by
any constant curve α(t) = p ∈M. Even though such constant curves are not
smooth in our sense we would like them to “count” and so we will refer to
them as degenerate geodesics.
To get some sense of the complexity of the equations (4.3.27) we should
write them out in the case of most interest to us. Thus, we consider de Sitter
spacetime dS in global coordinates x1 = φ1, x2 = φ2, x3 = θ, x4 = tG. From
Exercise 4.3.17,
(gij ) = diag(cosh2 tG, cosh2 tG sin2 φ1, cosh2 tG sin2 φ1 sin2 φ2, −1)
so (gij ) is the diagonal matrix whose entries are the reciprocals of these.
Because both of these are diagonal and independent of x3 = θ, the Christoﬀel
symbols (4.3.26) simplify a bit to
Γr
ij = 1
2grr
∂gir
∂xj + ∂gjr
∂xi −∂gij
∂xr

,
where there is no sum over r, all x3-derivatives vanish and all gkl with k ̸= l
are zero. We compute a few of these.
Γ4
11 = 1
2g44

0 + 0 −∂g11
∂x4

= 1
2(−1)(−2 cosh tG sinh tG)
= cosh tG sinh tG

4.3 Mathematical Machinery
231
Γ1
22 = 1
2g11

0 + 0 −∂g22
∂x1

= 1
2

1
cosh2 tG

(cosh2 tG(−2 sin φ1 cos φ1))
= −sin φ1 cos φ1
Γ3
43 = 1
2g33

0 + ∂g33
∂x4 −0

= 1
2

1
cosh2 tG sin2 φ1 sin2 φ2

·

2 cosh tG sinh tG sin2 φ1 sin2 φ2

= sinh tG
cosh tG
Γ2
21 = 1
2g22
∂g22
∂x1 + 0 −0

= 1
2

1
cosh2 tG sin2 φ1

·
cosh2 tG(2 sin φ1 cos φ1)
= cos φ1
sin φ1
.
Exercise 4.3.22 Show that the only nonvanishing Christoﬀel symbols for
dS in global coordinates are as follows.
Γ4
11 = cosh tG sinh tG
Γ4
22 = cosh tG sinh tG sin2 φ1
Γ4
33 = cosh tG sinh tG sin2 φ1 sin2 φ2
Γi
4i = Γi
i4 = sinh tG
cosh tG
, i = 1, 2, 3
Γ1
22 = −sin φ1 cos φ1
Γ1
33 = −sin φ1 cos φ1 sin2 φ2
Γ2
33 = −sin φ2 cos φ2
Γ2
21 = Γ2
12 = cos φ1
sin φ1
= Γ3
31 = Γ3
13
Γ3
32 = cos φ2
sin φ2
= Γ3
23.
With these one can write out the geodesic equations (4.3.27) for r = 1, 2, 3, 4.
For example, if r = 1,
d2x1
dt2 + Γ1
ij
dxi
dt
dxj
dt = 0
becomes
d2x1
dt2 + Γ1
22
dx2
dt
2
+ Γ1
33
dx3
dt
2
+ 2Γ1
41
dx4
dt
dx1
dt
= 0,

232
4 Prologue and Epilogue: The de Sitter Universe
or
d2φ1
dt2 −sin φ1 cos φ1
dφ2
dt
2
−sin φ1 cos φ1 sin2 φ2
dθ
dt
2
+ 2 sinh tG
cosh tG
dtG
dt
dφ1
dt
= 0.
Exercise 4.3.23 Write out the r = 2, 3, and 4 equations to obtain a system
of four coupled second order ordinary diﬀerential equations for the geodesics
of dS.
The problem of explicitly solving the geodesic equations can be formidable.
However, a few basic facts about systems of ordinary diﬀerential equations
(and some inspired guesswork) will relieve us of this burden. For instance,
(4.3.27) is nothing more that a system of second order ordinary diﬀerential
equations for the functions xi(t) so that standard existence and uniqueness
theorems for such systems imply that, for any given initial position α(t0) and
initial velocity α′(t0) there is a unique solution α(t) deﬁned on some interval
about t0 satisfying these initial conditions. More precisely, one obtains the
Existence
and
Uniqueness
Theorem: Let M be a manifold with
(Riemannian or Lorentzian) metric g and ﬁx some t0 ∈R. Then for any
p ∈M and any v ∈Tp(M) there exists a unique geodesic αv : Iv →M
such that
1. αv(t0) = p, α′
v(t0) = v, and
2. the interval Iv is maximal in the sense that if α : I →M is any geodesic
satisfying α(t0) = p and α′(t0) = v, then I ⊆Iv and α = αv | I.
We will ﬁnd the uniqueness asserted in this result particularly useful since
it assures us that if we have somehow managed to conjure up geodesics in
every direction v at p, then we will, in fact, have all the geodesics through p.
We will apply this procedure to a few examples shortly (e.g., by “guessing”
that the geodesics of S2 should be great circles). First, however, we must
come to understand that a geodesic is more than its image in M, which must
be parametrized in a very particular way if it is to satisfy (4.3.27). First we
show that a given geodesic can be reparametrized in only a rather trivial way
if it is to remain a geodesic.
Lemma 4.3.1 Let M be a manifold with (Riemannian or Lorentzian) metric
g and let α : I →M be a nondegenerate geodesic. Suppose J ⊆R is an
interval and h : J →I, t = h(s), is a smooth function with h′(s) > 0 for
each s ∈J. Then the reparametrization
β = α ◦h : J −→M
of α is a geodesic if and only if h(s) = as + b for some constants a and b.

4.3 Mathematical Machinery
233
Proof:
The Chain Rule gives
β′(s) = α′(h(s)) h′(s)
and
β′′(s) = α′′(h(s))(h′(s))2 + α′(h(s)) h′′(s)
so
β′′
tan(s) = α′(h(s)) h′′(s)
(α is a geodesic). Thus, β is a geodesic if and only if α′(h(s))h′′(s) = 0. Since
α is a nondegenerate geodesic, α′ is never zero (otherwise uniqueness would
imply that α is the constant curve). Thus, h′′(s) = 0 for every s in J so
h(s) = as + b for some constants a and b.
■
We can say much more about the parametrizations of a geodesic, however.
We will now prove that geodesics are always constant speed curves.
Theorem 4.3.2 Let M be a manifold with (Riemannian or Lorentzian) met-
ric g. Suppose α : I →M is a geodesic. Then g(α′(t), α′(t)) is constant on I.
Proof:
We will show that
d
dt g(α′(t), α′(t)) = 0 at each t in I. It will clearly
suﬃce to focus our attention on some subinterval of I that maps into χ(U) for
some coordinate patch χ : U →M ⊆Rm. Writing α(t) = χ(x1(t), . . . , xn(t))
we have
d
dt (g(α′(t), α′(t))) = d
dt

gij (x1(t), . . . , xn(t))d xi
dt
d xj
dt

.
To simplify the notation we will drop the arguments x1(t), . . . , xn(t) and
compute
d
dt

gij
dxi
dt
dxj
dt

= gij
dxi
dt
d2xj
dt2 + gij
dxj
dt
d2xi
dt 2 + dgij
dt
dxi
dt
dxj
dt
d
dt

gij
dxi
dt
dxj
dt

= 2gij
dxi
dt
d2xj
dt2 + ∂gij
∂xk
dxk
dt
dxi
dt
dxj
dt
(4.3.28)
Now, d2xj
dt2 = −Γj
ab
dx a
dt
dx b
dt since α is a geodesic so
2 gij
d xi
dt
d2 xj
dt2
= −2 gijΓj
ab
d xi
dt
d xa
dt
d xb
dt .
Moreover,
gij Γj
ab = 1
2gij gjk
∂gak
∂xb + ∂gbk
∂xa −∂gab
∂xk

= 1
2δk
i
∂gak
∂xb + ∂gbk
∂xa −∂gab
∂xk

= 1
2
∂gai
∂xb + ∂gbi
∂xa −∂gab
∂xi


234
4 Prologue and Epilogue: The de Sitter Universe
so
2 gij
d xi
dt
d2 xj
dt2
= −
∂gai
∂xb + ∂gbi
∂xa −∂gab
∂xi
 d xi
dt
d xa
dt
d xb
dt
= −∂gai
∂xb
d xb
dt
d xi
dt
d xa
dt

−
∂gib
∂xa −∂gab
∂xi
 d xb
dt
d xi
dt
d xa
dt

.
Notice that the second term is skew-symmetric in a and i so the sum vanishes.
Consequently,
2 gij
dx i
dt
d2xj
dt2 = −∂gai
∂xb
dx b
dt

dx i
dt
dx a
dt

= −∂gij
∂xk
dx k
dt
dx i
dt
dx j
dt
so (4.3.28) gives
d
dt

gij dx i
dt
dx j
dt

= 0 as required.
■
Remark:
It follows, in particular, from Theorem 4.3.2 that a geodesic in
a spacetime manifold has the same causal character (spacelike, timelike, or
null) at each point. This is, of course, not true of an arbitrary smooth curve.
Example 4.3.6 No inspired guesswork is required to compute the geodesics
of Rn, or R3,1, or any manifold with a global chart in which the metric
components gij are constant. Here the Christoﬀel symbols Γr
ij are all zero
so the geodesic equations reduce to
d2xr
dt2
= 0 and the solutions are linear
functions of the coordinates.
Example 4.3.7 We consider the 2-sphere S2 with the Riemannian metric g
obtained by restricting the Euclidean inner product ⟨, ⟩to each Tp(S2). Thus,
Tp(S2) = {v ∈R3 : ⟨p, v⟩= 0}.
We determine all of the geodesics of S2 through a ﬁxed, but arbitrary point p.
Of course, the degenerate geodesic is α0 : R →S2, deﬁned by α0(t) = p for
each t ∈R. Now ﬁx some nonzero v ∈Tp(S2). Then e = v/⟨v, v⟩
1
2 is a unit
vector in R3 orthogonal to the unit vector p. Thus,
Span{e, p} = {ae + bp : a, b ∈R}
is a 2-dimensional plane through the origin in R3. Its intersection with S2 is
the great circle on S2 consisting of all ae + bp with ⟨ae + bp, ae + bp⟩= 1,
i.e., a2 + b2 = 1. If we parametrize this circle by
αv(t) = (sin kt)e + (cos kt)p, −∞< t < ∞,

4.3 Mathematical Machinery
235
where k = ⟨v, v⟩
1
2 , then
αv(0) = p
α′
v(0) = ke = v.
Fig. 4.3.7
Moreover, g (α′
v(t), α′
v(t)) = k2 = ⟨v, v⟩is constant and α′′
v(t) = −k2αv(t) =
−⟨v, v⟩αv(t) is everywhere normal to S2. Thus, αv(t) is the unique geodesic
of S2 through p in the direction v. Since p and v were arbitrary we have found
all of the geodesics of S2.
Remark:
Two of the fundamental undeﬁned terms of classical plane
Euclidean geometry are “point” and “straight line.” Identifying these un-
deﬁned terms with “point on S2” and “geodesic of S2,” respectively, one
obtains a system in which all of the axioms of plane Euclidean geometry
are satisﬁed except the so-called Parallel Postulate (any two “straight lines”
in S2 intersect; see Figure 4.3.7). This is Riemann’s spherical model of
non-Euclidean geometry.
Exercise 4.3.24 Show in the same way that the nondegenerate geodesics
of the 3-sphere S3 are the constant speed parametrizations of its great circles
(intersections with S3 of 2-dimensional planes through the origin in R4).
Example 4.3.8 Next we consider the de Sitter spacetime dS with the
Lorentz metric g obtained by restricting the 5-dimensional Minkowski in-
ner product of M5 to each tangent space. According to the Remark follow-
ing Theorem 4.3.2, we must now expect geodesics of three types (spacelike,
timelike, and null), but the procedure for ﬁnding them is virtually identical
to what we have done for S2.

236
4 Prologue and Epilogue: The de Sitter Universe
Fix some p ∈dS and a nonzero v ∈Tp(dS) (the zero vector in Tp(dS)
clearly determines the degenerate geodesic through p). The tangent vector v
could be spacelike, timelike, or null in Tp(dS) and we consider these possibil-
ities in turn. We have already observed that, in any case, p ∈M5 is itself a
unit (spacelike) vector in M5 orthogonal to v.
Suppose v is spacelike. Then e2 = v/gp(v, v)
1
2 = v/(v, v)
1
2 is a unit space-
like vector in M5 orthogonal to p so p and e2 form an orthonormal basis for
the 2-dimensional plane
Span {p, e2} = {ap + be2 : a, b ∈R}
through the origin in M5 = R5. Its intersection with dS consists of all ap+be2
with (ap + be2, ap + be2) = 1, i.e., a2 + b2 = 1. Letting k = (v, v)
1
2 we
parametrize this circle in Span{p, e2} by
αv(t) = (cos kt)p + (sin kt)e2,
−∞< t < ∞,
to obtain a smooth curve with αv(0) = p, α′
v(0) = ke2 = v, g (α′
v(t), α′
v(t)) =
k2 = (v, v) for every t, and α′′
v(t) = −k2αv(t) for every t. Thus, α′′
v is every-
where normal to dS and so αv(t) is the unique geodesic of dS through p in
the direction v. It is, of course, spacelike (see Figure 4.3.8).
au
p
dS
u (spacelike)
Fig. 4.3.8
Remark:
Do not be deceived by the “elliptical” appearance of αv which is
due solely to the fact that the picture is drawn in the plane of the page. It is
a circle in the geometry of the plane Span{p, e2}.

4.3 Mathematical Machinery
237
Next suppose v is timelike. Then e4 = v/(−gp(v, v))
1
2 = v/(−(v, v))
1
2 is
a unit timelike vector orthogonal to p in M5 so
Span {p, e4} = {ap + be4 : a, b ∈R}
is a 2-dimensional plane through the origin in M5 and its intersection with
dS consists of those points with (ap+be4, ap+be4) = 1, i.e., a2−b2 = 1. This
consists of both branches of a hyperbola in Span{p, e4}. We parametrize the
branch containing p by
αv(t) = (cosh kt)p + (sinh kt)e4,
−∞< t < ∞,
where k = (−(v, v))
1
2 . Then αv(0) = p, α′
v(0) = ke4 = v, gp (α′
v(t), α′
v(t)) =
k2(sinh2 kt −cosh2 kt) = (v, v) for every t, and α′′
v(t) = k2αv(t) for every t.
Again, α′′
v is everywhere normal to dS so αv(t) is the unique geodesic of dS
through p in the direction v (see Figure 4.3.9).
dS
u (timelike)
p
au
Fig. 4.3.9
Finally, we suppose that v is null. Then {p, v} is an orthogonal basis for
Span{p, v} = {ap + bv : a, b ∈R} and the intersection with dS consists
of those ap + bv with (ap + bv, ap + bv) = 1, i.e., a2 = 1, so a = ±1.
Thus, the intersection consists of two null straight lines {p + bv : b ∈R} and
{−p + bv : b ∈R}. Parametrizing the line containing p by
αv(t) = p + tv,
−∞< t < ∞,

238
4 Prologue and Epilogue: The de Sitter Universe
we ﬁnd that αv(0) = p, α′
v(0) = v, g (α′
v(t), α′
v(t)) = (v, v) = 0 for each t,
and α′′
v(t) = 0 ∈M5 for each t. Thus, αv is the unique geodesic of dS through
p in the direction v. It is, in fact, just a null straight line in M5 that happens
to live in dS (see Figure 4.3.10).
Notice that, although the Existence and Uniqueness Theorem guarantees
only the local existence of a geodesic on some interval, the examples we have
found thus far are all deﬁned on all of R. A manifold with (Riemannian or
Lorentzian) metric is said to be complete if each of its maximal geodesics is
deﬁned on all of R. Notice also that in S2 and S3 any two points can be
joined by a geodesic (because they are contained in a great circle). In the
Riemannian case this property is actually equivalent to completeness (see
Theorem 18, Chapter 9, of [Sp 2], Volume I). We show now that this is not
the case for Lorentzian manifolds. In fact, we will use what we have just
proved about the geodesics of dS to determine precisely when two distinct
points p and q can be joined by a geodesic.
dS
u (null)
p
au
Fig. 4.3.10
First notice that two antipodal points p and −p of dS never lie on the
same timelike or null geodesic (e.g., p and −p are on disjoint branches of the
hyperbolas determining timelike geodesics through p). However, if e ∈Tp(dS)
is any unit spacelike vector at p, then the spacelike geodesic
αe(t) = (sin t)e + (cos t)p,
−∞< t < ∞,

4.3 Mathematical Machinery
239
satisﬁes αe(0) = p and αe(π) = −p. Thus, antipodal points can be joined by
(many) spacelike geodesics.
Now suppose p and q are distinct, non-antipodal points in dS. Being in
dS, p and q are independent and so determine a unique 2-dimensional plane
Π = Span {p, q}
through the origin in M5. By what we have proved about the geodesics of dS,
the only geodesic that could possibly join p and q is some parametrization
of (a part of) dS ∩Π. Now, the restriction of the M5-inner product to Π,
which we continue to denote ( , ), is clearly symmetric and bilinear. It may
be degenerate, or it may be nondegenerate and either of index zero or index
one. We consider these possibilities one at a time.
Suppose ﬁrst that the restriction of ( , ) to Π is positive deﬁnite. Since p
and q are unit spacelike vectors, dS ∩Π is a circle and the parametrization
αq(t) = (cos t)p + (sin t)q,
−∞< t < ∞,
is a geodesic satisfying αq(0) = p and αq
 π
2

= q. In this case we claim that
we must have −1 < (p, q) < 1. To see this note that p ± q are nonzero so
that, since ( , ) is positive deﬁnite on Π,
0 < (p + q, p + q) = (p, p) + 2 (p, q) + (q, q) = 2 + 2 (p, q)
implies −1 < (p, q) and, similarly, 0 < (p −q, p −q) gives (p, q) < 1.
Next suppose that the restriction of ( , ) to Π is nondegenerate of index one.
Then dS ∩Π consists of two branches of a hyperbola. We show that p and q lie
on the same branch if and only if (p, q) > 1 (in which case p and q are joined
by a timelike geodesic) and on diﬀerent branches if and only if (p, q) < −1 (in
which case no geodesic joins p and q). To see this we choose an orthonormal
basis {e1, e2, e3, e4, e5} for M5 with (e5, e5) = −1 and Π = Span{e1, e5}.
Then dS ∩Π = {x1e1 +x5e5 : (x1)2 −(x5)2 = 1} and the two branches of the
hyperbola are given by x1 ≥1 and x1 ≤−1. We parametrize these branches
by α1(t) = (cosh t)e1 + (sinh t)e5 and α2(t) = (−cosh t)e1 + (sinh t)e2. Now,
if p and q are on the same branch, then for some i = 1, 2, p = αi(t0) and
q = αi(t1) for some t0 ̸= t1 in R. Thus,
(p, q) = cosh t0 cosh t1 −sinh t0 sinh t1 = cosh (t0 −t1) > 1.
On the other hand, if p and q are on diﬀerent branches, then p = αi(t0) and
q = αj(t1), where i ̸= j, so
(p, q) = −cosh t0 cosh t1 −sinh t0 sinh t1 = −cosh(t0 + t1) < −1
as required.
Finally, suppose that the restriction of ( , ) to Π is degenerate. Then dS ∩Π
consists of two parallel null straight lines

240
4 Prologue and Epilogue: The de Sitter Universe
α1(t) = p + tv
α2(t) = −p + tv,
where v ∈Tp(dS) satisﬁes (p, v) = 0 and (v, v) = 0. If p and q are on the
same line, then q = p + t0v for some t0 ∈R so
(p, q) = (p, p + t0v) = (p, p) + t0(p, v) = 1.
and, if p and q are on diﬀerent lines, then q = −p + t0v for some t0 ∈R so
(p, q) = (p, −p + t0v) = (p, −p) + t0(p, v) = −1.
Now, since the conditions −1 < (p, q) < 1, (p, q) = 1, (p, q) > 1, and
(p, q) ≤−1 are mutually exclusive we can summarize all of this as follows.
Theorem 4.3.3 Let p and q be distinct points of dS and denote by ( , ) the
Minkowski inner product on M5. Then
(a) If p and q are antipodal points of dS(q = −p), then p and q cannot be
joined by a timelike or null geodesic, but there are inﬁnitely many spacelike
geodesics joining p and q.
If p and q are not antipodal points, then
(b) (p, q) > 1 ⇐⇒p and q lie on a unique geodesic of dS which is timelike,
(c) (p, q) = 1 ⇐⇒p and q lie on a unique geodesic of dS which is null,
(d) −1 < (p, q) < 1 ⇐⇒p and q lie on a unique geodesic of dS which is
spacelike,
(e) (p, q) ≤−1 ⇐⇒there is no geodesic of dS joining p and q.
It is worth pointing out that, for p, q ∈dS, one has (p−q, p−q) = 2(1−(p, q))
so that
(p, q) = 1 ⇐⇒(p −q, p −q) = 0
(p, q) > 1 ⇐⇒(p −q, p −q) < 0
−1 < (p, q) < 1 ⇐⇒0 < (p −q, p −q) < 4
(p,q) ≤−1 ⇐⇒(p −q, p −q) ≥4.
We will leave it to the reader to carry out a similar analysis of the important
example of hyperbolic 3-space H3(r).
Exercise 4.3.25 M will denote (ordinary, 4-dimensional) Minkowski space-
time and we will write x · y for the Minkowski inner product of x, y ∈M.
Standard admissible coordinates on M will be written x1, x2, x3, x4. For
any positive real number r we let H3(r) denote the subset of M deﬁned by
H3(r) = {x ∈M : x · x = −r2, x4 > 0},

4.3 Mathematical Machinery
241
that is,
(x1)2 + (x2)2 + (x3)2 −(x4)2 = −r2, x4 > 0.
(a) Show that H3(r) is diﬀeomorphic to R3.
(b) Deﬁne a smooth map from R3 to M(= R4) by
x1 = r cos φ sinh ψ
x2 = r sin φ cos θ sinh ψ
x3 = r sin φ sin θ sinh ψ
x4 = r cosh ψ.
Verify that (x1)2+(x2)2+(x3)2−(x4)2 = −r2 and ﬁnd appropriate ranges
for φ, θ, and ψ to ensure that each point in H3(r) is contained in an open
subset of H3(r) on which (φ, θ, ψ) are coordinates.
H3(r)
Fig. 4.3.11
(c) Restrict the Minkowski inner product of M to each tangent space
Tp(H3(r)) to deﬁne a metric g on H3(r) and show that this metric is
Riemannian with line element
ds2 = r2 
dψ2 + sinh2 ψ(dφ2 + sin2 φ dθ2)

.
(d) Show that Tp(H3(r)) = {v ∈M : p · v = 0} and conclude that every
element of Tp(H3(r)) is spacelike in M.
(e) For each p ∈H3(r) and each v ∈Tp(H3(r)) determine the geodesic αv of
H3(r) with αv(0) = p and α′
v(0) = v.
(f) Describe the tH = constant slices of de Sitter spacetime in hyperbolic
coordinates (Example 4.3.5).
We arrive now at the ﬁnal item in our agenda of mathematical tools. It is
arguably the most fundamental concept in both geometry and relativity, but
it is subtle. The issue involved, however, is not subtle at all. Let us compare
for a moment the sphere
S2 = {(x, y, z) ∈R3 : x2 + y2 + z2 = 1}

242
4 Prologue and Epilogue: The de Sitter Universe
and the cylinder
C = {(x, y, z) ∈R3 : x2 + y2 = 1}
in R3 (see Figure 4.3.12). From our vantage point in R3 both appear “curved,”
but there is a very real sense in which this vantage point is misleading us in
regard to the cylinder. Each is a 2-manifold, of course, and so is “locally like”
S2
C
Fig. 4.3.12
the plane, i.e., locally diﬀeomorphic to R2, but C is “more like” the plane
than S2. Intuitively, at least, one can see this as follows. Cutting the cylinder
vertically along a straight line one can then ﬂatten it out onto the plane
and, in the process, all distances, angles, areas, and, indeed, all of the basic
ingredients of geometry, are unaltered (see Figure 4.3.13). The sphere is a
diﬀerent matter. However small a region of S2 one chooses to examine any
“ﬂattening out” onto the plane must distort distances, angles, and areas.
Since all of the geometry of a surface is ultimately deﬁned from the metric
g of the surface one can say this more precisely as follows. Each point of the
cylinder is contained in an open set on which there exist coordinates x1 and
x2 relative to which the metric components gij are the same as those of the
plane in standard coordinates, i.e., gij = δij , i, j = 1, 2, but no such local
coordinates exist on S2. The cylinder is “locally ﬂat”, but the sphere is not.
Exercise 4.3.26 Show that χ : [0, 2π] × (−∞, ∞) →R3 deﬁned by
χ(x1, x2) = (cos (x1), sin (x1), x2)
parametrizes the cylinder C. Let g be the Riemannian metric on C obtained
by restricting the R3-inner product ⟨, ⟩to each tangent space Tp(C). Show
that the metric components relative to χ are gij = δij , i, j = 1, 2.

4.3 Mathematical Machinery
243
Fig. 4.3.13
How does one prove that S2 is not locally ﬂat? Is there a computation one
can perform that will decide the issue of whether or not a given surface in R3
is locally ﬂat? The answer has been provided by Gauss who deﬁned a certain
real-valued function κ on the surface, the vanishing of which on an open set
is equivalent to the existence of local coordinates relative to which the metric
components are gij = δij . The function is called the Gaussian curvature of
the surface and can be described in a coordinate patch χ by
κ = det (Lij )
det (gij ) ,
where the Lij are deﬁned in Exercise 4.3.21 (c).
Remark:
It is not immediately apparent that this deﬁnition of κ is inde-
pendent of the coordinate patch from which it is computed, but this is true
so κ can actually be regarded as a function on the surface.
Exercise 4.3.27 Show that the Gaussian curvature of the cylinder C is
identically zero and the Gaussian curvature of S2 is equal to one at each point.
One can ask exactly the same question in higher dimensions. Given a
smooth n-manifold M with (Riemannian or Lorentzian) metric g, when will
there exist local coordinates on M relative to which the metric components
are gij = δij (or ηij in the case of a spacetime)? When n ≥3, however, the
question cannot be decided by a single real-valued function. It can be decided,
but the object one must compute to do so (called the “Riemann curvature
tensor”) is considerably more complicated than the Gaussian curvature so we
will take a moment to see where it comes from.
We consider a smooth n-manifold M in Rm with Riemannian metric g
(we leave it to the reader to make the modest alterations required in the
Lorentzian case). Let χ : U →M be a coordinate patch with coordinates
x1, . . . , xn and in which the metric components are gij = g(χi, χj), i, j =
1, . . . , n. Then the matrix (gij ) is nonsingular at each point and we denote its
inverse by (gij ). Now let us suppose that there is another coordinate patch
˜χ : ˜U →M with coordinates ˜x1, . . . , ˜xn such that χ(U) ∩˜χ( ˜U) ̸= ∅and in

244
4 Prologue and Epilogue: The de Sitter Universe
which the metric components ˜gij are ˜gij = δij (so that the line element is
ds2 = (d˜x1)2 + · · · + (d˜xn)2). According to Exercise 4.3.11,
gij = ∂˜xa
∂xi
∂˜xb
∂xj ˜gab
= ∂˜xa
∂xi
∂˜xb
∂xj δab
gij =
n

a=1
∂˜xa
∂xi
∂˜xa
∂xj , i, j = 1, . . . , n
(4.3.29)
on the intersection. Now, (4.3.29) is equivalent to the matrix equation
(gij ) =
∂˜xa
∂xi
⊤∂˜xa
∂xj

.
(4.3.30)
For any invertible matrices A and B,
A = B⊤B =⇒A−1 = B−1(B⊤)−1 =⇒BA−1 B⊤= id
so (4.3.30) implies
∂˜xa
∂xj

(gij )
∂˜xa
∂xi
⊤
= id.
Written out in detail this gives
∂˜xa
∂xi gij ∂˜xb
∂xj = δab,
a, b = 1, . . . , n.
(4.3.31)
Now diﬀerentiate (4.3.29) with respect to xk to obtain
∂gij
∂xk =
n

a=1
∂˜xa
∂xj
∂2˜xa
∂xi∂xk + ∂˜xa
∂xi
∂2˜xa
∂xj∂xk

.
Exercise 4.3.28 Write out similar expressions for ∂gik
∂xj and ∂gjk
∂xi and combine
them to get
1
2
∂gij
∂xk + ∂gik
∂xj −∂gjk
∂xi

=
n

a=1
∂2˜xa
∂xj∂xk
∂˜xa
∂xi .
(4.3.32)
Next ﬁx some index b = 1, . . . , n and multiply on both sides of (4.3.32) by
giβ ∂˜xb
∂xβ
(summed over β = 1, . . . , n)

4.3 Mathematical Machinery
245
and then sum over i as required by the summation convention to obtain
*1
2 gβi
∂gij
∂xk + ∂gik
∂xj −∂gjk
∂xi
+ ∂˜xb
∂xβ =
n

a=1
∂˜xa
∂xi giβ ∂˜xb
∂xβ

∂2˜xa
∂xj∂xk
=
n

a=1
δab
∂2˜xa
∂xj ∂xk
=
∂2˜xb
∂xj∂xk .
Thus,
∂2˜xb
∂xj∂xk = Γβ
jk
∂˜xb
∂xβ ,
b, j, k = 1, . . . , n.
(4.3.33)
Now ﬁx an index b = 1, . . . , n and let
Jb = (Jb1, . . . , Jbn) =
∂˜xb
∂x1 , . . . , ∂˜xb
∂xn

be the vector whose components are the entries in the bth row of the Jacobian.
Then (4.3.33) can be written
∂Jbj
∂xk = Γβ
jk Jbβ,
j, k = 1, . . . , n.
For each j, k, l = 1, . . . , n, we must have
∂2Jbj
∂xl ∂xk = ∂2Jbj
∂xk∂xl
so
∂
∂xl

Γβ
jk Jbβ

=
∂
∂xk

Γβ
jl Jbβ

Γβ
jk
∂Jbβ
∂xl +
∂Γβ
jk
∂xl Jbβ = Γβ
jl
∂Jbβ
∂xk +
∂Γβ
jl
∂xk Jbβ
Γβ
jk Γγ
βl Jbγ +
∂Γγ
jk
∂xl Jbγ = Γβ
jl Γγ
βk Jbγ +
∂Γγ
jl
∂xk Jbγ

∂Γγ
jl
∂xk + Γβ
jl Γγ
βk −
∂Γγ
jk
∂xl −Γβ
jk Γγ
βl

Jbγ = 0.
(4.3.34)
Now for some notation. For each γ, j, k, l = 1, . . . , n, let
Rγ
jkl =
∂Γγ
jl
∂xk + Γβ
jlΓγ
βk −
∂Γγ
jk
∂xl −Γβ
jkΓγ
βl.
(4.3.35)

246
4 Prologue and Epilogue: The de Sitter Universe
Then we can write (4.3.34) as
Rγ
jkl Jbγ = 0,
j, k, l = 1, . . . , n.
We conclude that
Rγ
jkl
∂˜xb
∂xγ = 0,
b, j, k, l = 1, . . . , n.
(4.3.36)
Now, for any ﬁxed j, k, l = 1, . . . , n, (4.3.36) can be regarded as a homoge-
neous system of linear equations in
R1
jkl, . . . , Rn
jkl
and, since the Jacobian

∂˜xb
∂xγ

is nonsingular, we conclude that
Rγ
jkl = 0,
γ, j, k, l = 1, . . . , n.
(4.3.37)
The conclusion of this long and rather annoying calculation is this. If there
exist coordinates ˜x1, . . . , ˜xn on some open set ˜χ( ˜U) in M relative to which
the metric components are ˜gij = δij , i, j = 1, . . . , n, then, for any other co-
ordinates x1, . . . , xn on some open set χ(U) with χ(U) ∩˜χ( ˜U) ̸= ∅, the
functions Rγ
jkl of x1, . . . , xn deﬁned by (4.3.35) must vanish identically on
χ−1(χ(U) ∩˜χ( ˜U)).
Remarkably enough, the converse is also true, in the following sense.
Rather than supposing the existence of coordinates ˜x1, . . . , ˜xn with ds2 =
(d˜x1)2 + · · · + (d˜xn)2 and regarding (4.3.29) as a consequence, let us think of
n

a=1
∂˜xa
∂xi
∂˜xa
∂xj = gij ,
i, j = 1, . . . , n.
(4.3.38)
as a system of partial diﬀerential equations to be solved for ˜x1, . . . , ˜xn.
A solution would provide the transformation equations to a new system of
coordinates in which ˜gij = δij and it can be shown that a solution exists
whenever the “integrability conditions” Rγ
jkl = 0, γ, j, k, l = 1, . . . , n, are sat-
isﬁed (see pages 200–204 of [Sp2], Volume III).
Consequently, the 4n functions Rγ
jkl deﬁned by (4.3.35) are the replacement
for the Gaussian curvature of a surface in dimensions greater than or equal
to 3. These are called the components (relative to χ) of the Riemann curvature
tensor R for M.
Remark:
We have not deﬁned the unmodiﬁed term “tensor” and will have
no need to do so. However, our experience with 4-tensors in Section 3.1
should leave little room for doubt as to the proper deﬁnition. Recall that
a 4-tensor of contravariant rank 1 and covariant rank 3 can be thought of
as an object described in each admissible frame of reference by 44 = 256

4.3 Mathematical Machinery
247
numbers T a
bcd, a, b, c, d = 1, 2, 3, 4, with the property that if two admissible
frames are related by ˆxa = Λabxb, a = 1, 2, 3, 4, then the numbers that
describe the 4-tensor in the two frames are related by
ˆT a
bcd = Λaα Λb
β Λc
γ Λd
δ T α
βγδ,
a, b, c, d = 1, 2, 3, 4. Noting that Λaα = ∂ˆxa
∂xα and Λb
β = ∂xβ
∂ˆxb , etc., this can be
written
ˆT a
bcd = ∂ˆxa
∂xα
∂xβ
∂ˆxb
∂xγ
∂ˆxc
∂xδ
∂ˆxd T α
βγδ.
The transformation law for the metric in Exercise 4.3.11 together with a very
healthy supply of persistence gives an entirely analogous transformation law
˜Ra
bcd = ∂˜xa
∂xα
∂xβ
∂˜xb
∂xγ
∂˜xc
∂xδ
∂˜xd Rα
βγδ
for the components of R and it is this transformation law that qualiﬁes R as
a “tensor.”
In dimension 4 the Riemann curvature tensor has 44 = 256 components in
every coordinate system, although various symmetries reduce the number of
independent components to 20. Computing even one of these directly from the
deﬁnition (4.3.35) is, needless to say, an arduous task in general. Nevertheless,
everyone should do it once in their lives.
Example 4.3.9 We consider the de Sitter spacetime dS in global coordi-
nates x1 = φ1, x2 = φ2, x3 = θ and x4 = tG. The nonvanishing Christoﬀel
symbols (from Exercise 4.3.22) are
Γ4
11 = cosh tG sinh tG
Γ4
22 = cosh tG sinh tG sin2 φ1
Γ4
33 = cosh tG sinh tG sin2 φ1 sin2 φ2
Γi
4i = Γi
i4 = sinh tG
cosh tG
,
i = 1, 2, 3
Γ1
22 = −sin φ1 cos φ1
Γ1
33 = −sin φ1 cos φ1 sin2 φ2
Γ2
33 = −sin φ2 cos φ2
Γ2
21 = Γ2
12 = Γ3
31 = Γ3
13 = cos φ1
sin φ1
Γ3
32 = Γ3
23 = cos φ2
sin φ2
.
We will compute
R4
343 = ∂Γ4
33
∂x4 + Γβ
33Γ4
β4 −∂Γ4
34
∂x3 −Γβ
34Γ4
β3.

248
4 Prologue and Epilogue: The de Sitter Universe
First note that
∂Γ4
33
∂x4 =
∂
∂tG
(cosh tG sinh tG sin2 φ1 sin2 φ2)
= (cosh2 tG + sinh2 tG) sin2 φ1 sin2 φ2
and
∂Γ4
34
∂x3 = ∂
∂θ(0) = 0.
Next we have
Γβ
33Γ4
β4 = Γ1
33Γ4
14 + Γ2
33Γ4
24 + Γ3
33Γ4
34 + Γ4
33Γ4
44 = 0
since each Γ4
β4 = 0. Finally,
Γβ
34Γ4
β3 = Γ1
34Γ4
13 + Γ2
34Γ4
23 + Γ3
34Γ4
33 + Γ4
34Γ4
43
= 0 + 0 + Γ3
34Γ4
33 + 0
=
 sinh tG
cosh tG

(cosh tG sinh tG sin2 φ1 sin2 φ2)
= sinh2 tG sin2 φ1 sin2 φ2.
Thus,
R4
343 = cosh2 tG sin2 φ1 sin2 φ2.
Exercise 4.3.29 Show that, for the de Sitter spacetime in global coordi-
nates,
Ri
4i4 = −1
for i = 1, 2, 3.
Remark:
Observe that, in dS,
δ4
4g33 −δ4
3g34 = g33 = cosh2 tG sin2 φ1 sin2 φ2 = R4
343
(δa
b = 1 if a = b and 0 if a ̸= b is just the Kronecker delta). Also,
δi
ig44 −δi
4g4i = g44 = −1 = Ri
4i4
for i = 1, 2, 3. As it happens, one can show that
Rγ
jkl = δγ
kgjl −δγ
l gjk
(4.3.39)
for all γ, i, j, k = 1, 2, 3, 4. Thus, for example, setting k = γ and summing
over γ gives
Rγ
jγl = δγ
γgjl −δγ
l gjγ = 4gjl −gjl = 3gjl.
Remark:
A manifold M with metric g is said to have constant (sectional)
curvature if there is a constant K such that
Rγ
jkl = K (δγ
kgjl −δγ
l gjk)

4.4 The de Sitter Universe dS
249
in any local coordinate system. de Sitter spacetime dS therefore has constant
curvature K = 1. We will encounter this notion again in the next section.
The Riemann curvature tensor contains all of the information about a
manifold’s local deviations from “ﬂatness” and, in the case of a spacetime,
this is precisely what we mean by a gravitational ﬁeld (see Section 4.1). It is,
however, a rather cumbersome creature and one can often make due (both
mathematically and physically) with somewhat simpler objects that we now
introduce. For any n-manifold M with (Riemannian or Lorentzian) metric g
we deﬁne, in any local coordinate system on M, the components of the Ricci
tensor Rij by
Rij = Rγ
iγj
(sum over γ = 1, . . . , n)
for i, j = 1, . . . , n. The scalar curvature R of M is then deﬁned by
R = gij Rij
(sum over i, j = 1, . . . , n).
According to the previous Remark, the Ricci tensor of de Sitter spacetime
dS is
Rij = 3gij
and so
R = gij Rij = gij(3gij) = 3gijgji = 3δj
j = 3(4) = 12.
Remark:
The scalar curvature is generally a real-valued function on M,
but in the case of dS happens to be a constant function.
Finally, we deﬁne, in any local coordinate system for M, the components of
the Einstein tensor Gij by
Gij = Rij −1
2 Rgij
for i, j = 1, . . . , n. Thus, for dS,
Gij = 3gij −1
2(12) gij = −3gij.
Exercise 4.3.30 Show that Gij = 0 for all i, j = 1, . . . , n if and only if
Rij = 0 for all i, j = 1, . . . , n. Hint: Assuming Gij = 0, consider gij Gij .
4.4 The de Sitter Universe dS
A spacetime, as we have deﬁned it, is a 4-dimensional manifold with a Lorentz
metric. The motivation behind the deﬁnition was an attempt to model the
event world when gravitational eﬀects cannot be regarded as negligible. It
is certainly not the case, however, that every spacetime represents some

250
4 Prologue and Epilogue: The de Sitter Universe
physically realistic gravitational ﬁeld. Einstein’s idea was that the space-
time should be “determined” by the mass-energy distribution giving rise to
the gravitational ﬁeld and he struggled for many years to arrive at equations
that speciﬁed just how the latter determined the former. The end result of
the struggle was a set of ten coupled nonlinear partial diﬀerential equations
for the metric components gij called the Einstein ﬁeld equations. It is with
these that the general theory of relativity begins and we will not be so bold
as to oﬀer a precis of their derivation. We simply record the equations, make
a few unremarkable observations and then move on to their relevance to our
story. A spacetime M with Lorentz metric g is said to satisfy the Einstein
ﬁeld equations if, in any local coordinate system,
Rij −1
2Rgij + Λgij = 8πTij ,
i, j = 1, 2, 3, 4,
(4.4.1)
where Rij −1
2 Rgij = Gij is the Einstein tensor, Λ is a constant, called the
cosmological constant, and Tij is called the energy-momentum tensor and is
a direct analogue of the energy-momentum transformation for the electro-
magnetic ﬁeld on Minkowski spacetime that we introduced in Section 2.5.
The role of Tij is to describe the mass-energy distribution giving rise to the
gravitational ﬁeld being modeled by gij. The equations relate the geometry
of the spacetime, described by the left-hand side, to the mass-energy distri-
bution, described by the right-hand side. Together with the so-called geodesic
hypothesis that free particles have worldlines in M that are timelike or null
geodesics, (4.4.1) contains essentially the entire content of general relativity.
The left-and right-hand sides of (4.4.1) have the same transformation law
to a new system of local coordinates

˜Fij = ∂xk
∂˜xi
∂xl
∂˜xj Fkl

so, if they are
satisﬁed for one set of charts covering M, they are satisﬁed in any coordinate
system (they are “tensor equations”). In particular, it makes sense to deﬁne
an empty space solution to Einstein’s equations to be a spacetime satisfying
(4.4.1) with Tij = 0, i, j = 1, 2, 3, 4.
Exercise 4.4.1 Show that the de Sitter spacetime dS is an empty space
solution to the Einstein equations with Λ = 3.
Remark:
It may strike the reader as peculiar that we introduce “empty
space solutions” since our motivation has been to model nontrivial gravita-
tional ﬁelds. Let us explain. When Λ = 0 the empty space equations are
Gij = 0 which, by Exercise 4.3.30, are the same as
Rij = 0.
(4.4.2)
Manifolds satisfying (4.4.2) are said to be Ricci ﬂat and, in general relativ-
ity, they are regarded as an analogue of the source free Maxwell equations
introduced in Section 2.7. Solutions describe gravitational ﬁelds in regions of
spacetime in which the mass-energy giving rise to the ﬁeld is “elsewhere.”

4.4 The de Sitter Universe dS
251
The best known example is the Schwarzschild solution describing the ﬁeld
exterior to a spherically symmetric mass/star (see Chapter Six of [Wald]).
On the other hand, when Λ ̸= 0, the empty space equations are
Gij + Λgij = 0
(4.4.3)
and here the interpretation is more subtle. One might, for example, rewrite
(4.4.3) as
Gij = 8π

−Λ
8πgij

(4.4.4)
and regard
T vac
ij
= −Λ
8πgij
(4.4.5)
as an energy-momentum tensor for some unspeciﬁed mass-energy distribution
and (4.4.4) as the Einstein equations with cosmological constant zero. In this
interpretation, (4.4.5) is often thought of as the energy-momentum of the vac-
uum, due perhaps to quantum ﬂuctuations of the vacuum state required by
quantum ﬁeld theory. In this guise, T vac
ij
is often attributed to what has come
to be called “dark energy.” Alternatively, one could simply regard the cosmo-
logical term Λgij in Einstein’s equations (4.4.1) as a necessary ingredient in
the basic laws of physics, independent of any mass-energy interpretation. In
this case one has solutions like dS representing a genuinely “empty” universe,
but which are, nevertheless, not ﬂat (dS has nonzero curvature tensor). Such
solutions therefore represent alternatives to Minkowski spacetime with very
diﬀerent mathematical and, as we shall see, physical properties.
It is not the usual state of aﬀairs, of course, to be given a spacetime and an
energy-momentum tensor and be asked to check (as in Exercise 4.4.1) that
together they give a solution to the Einstein equations. Rather, one would
begin with some physical distribution of matter and energy (an electromag-
netic ﬁeld, a single massive object such as a star, or an entire universe full
of galaxies) and one would attempt to solve the equations (4.4.1) for the
metric. Aside from the enormous complexity of the equations (express Rij
and R directly in terms of gij and substitute into (4.4.1)) there are subtleties
in this that may not be apparent at ﬁrst glance. The Einstein equations are
written in coordinates, but coordinates on what? The objective is to con-
struct the manifold and its metric so neither can be regarded as given to
us. To solve (4.4.1) one must begin with a guess (physicists prefer the term
“ansatz”) based on one’s physical intuition concerning the ﬁeld being mod-
eled as to what at least one coordinate patch on the sought after manifold
might look like. Even if one should succeed in this, the end result will be no
more than a local expression for the metric in one coordinate system; the
rest of the manifold is still hidden from view. Moreover, it is the metric it-
self that determines the spacetime measurements in the manifold. Since one
cannot describe energy and momentum without reference to space and time
measurements, even Tij cannot be regarded as given, but depends on the un-
known metric components gij. Even the true physical meaning of the ansatz
coordinates cannot be known until after the equations are solved.

252
4 Prologue and Epilogue: The de Sitter Universe
All of these subtleties add spice to the problem of solving the Einstein
equations, but this is not really our concern here. We would, however, like to
say a few words about the ansatz appropriate to what are called cosmological
models (spacetimes intended to model the global structure of the universe as
a whole). For this we need just one more mathematical tool.
Let M1 and M2 be two smooth manifolds and F : M1 →M2 a smooth
map. At each point p ∈M, we deﬁne the derivative F∗p of F at p to be
the map
F∗p : Tp(M1) →TF (p) (M2)
that carries the velocity vector of a smooth curve α in M1 through p to the
velocity vector of its image F ◦α under F, i.e.,
F∗p(α′ (t0)) = (F ◦α)′ (t0).
In this way smooth maps carry tangent vectors in the domain to tangent
vectors in the range. Now suppose M1 and M2 have metrics g1 and g2, re-
spectively (both Riemannian or both Lorentzian) and that F : M1 →M2 is
a diﬀeomorphism. Then F is called an isometry if it preserves inner products
at each point, i.e., if
g1(α′ (t0), β′ (t1)) = g2 ((F ◦α)′ (t0), (F ◦β)′ (t1))
for all smooth curves α and β in M1 with α(t0) = β(t1). In particular,
an isometry of a manifold M with metric onto itself is the analogue of an
orthogonal transformation of a vector space with inner product onto itself. In
particular, the collection of all such form a group, called the isometry group
of M. For dS this group is precisely the set of restrictions to dS of orthogonal
transformations of M5 and is called the de Sitter group (this result is not
obvious, but we do not need it and so will not prove it). For spacetimes,
isometries are our new Lorentz transformations.
The two most basic physical assumptions that go into the construction of a
cosmological model in general relativity are called “spatial homogeneity” and
“spatial isotropy.” Intuitively, these assert that, at any “instant”, all points
and all directions in “space” should “look the same.” Since “instant” and
“space” are the very things that relativity forbids us ascribing a meaning to
independent of some observer, it is not so clear what this is supposed to mean.
We will attempt a somewhat more precise statement of what is intended. A
spacetime M is said to be spatially homogeneous and isotropic if the following
conditions are satisﬁed (see Figure 4.4.1).
(A) There exists a family of free observers (future-directed, timelike
geodesics) with worldlines ﬁlling all of M (for each p ∈M there exists
one and only one of these geodesics αp with αp(tp) = p for some value
tp of proper time on αp.

4.4 The de Sitter Universe dS
253
(B) There exists a 1-parameter family of spacelike hypersurfaces Σt (3-
dimensional manifolds in M on which the restriction of the spacetime
metric g is positive deﬁnite) that are pairwise disjoint and ﬁll all of M.
(C) If p ∈M is in Σtp, then α′
p(tp) is orthogonal to Tp(Σtp) (so that the
hypersurfaces can be regarded as common “instantaneous 3-spaces” for
the observers).
(D) If p, q ∈Σt, then there is an isometry of M onto itself that carries p to
q (“at each instant all points of space look the same”).
(E) If p = αp(tp) is in Σtp and u1 and u2 are two directions (unit vectors)
in Tp(Σtp), then there is an isometry of M onto itself that leaves p and
α′
p(tp) ﬁxed, but “rotates” u1 onto u2 (“at each instant all directions
at any point in space look the same to the observer experiencing that
event”).
ap(tp)
p
ap
q
Σtp
Fig. 4.4.1
As it happens, these conditions are quite restrictive. Based on them one
can show (see Section 5.1 of [Wald]) that each of the spacelike hypersurfaces
Σ in (B), with the metric obtained by restricting g to Σ, is a manifold of
constant curvature (see the Remark following (4.3.39)). Now, up to certain
“topological” variations that are not relevant to our purpose here, one can
enumerate all of the 3-dimensional Riemannian manifolds of constant curva-
ture. They are 3-spheres (K > 0), 3-dimensional Euclidean spaces (K = 0)
and hyperbolic 3-spaces (K < 0), all of which we have seen before.
The idea behind the “cosmological ansatz” can then be described as fol-
lows. Select one of the spacelike hypersurfaces Σ and choose coordinates on it
so that its line element is of one of the following forms (we will use the same
names for the coordinates in all cases in order to exhibit the similarities).

254
4 Prologue and Epilogue: The de Sitter Universe
dψ2 + sin2 ψ(dφ2 + sin2 φ dθ2)
(Σ = S3)
dψ2 + ψ2(dφ2 + sin2 φdθ2)
(Σ = R3)
dψ2 + sinh2 ψ(dφ2 + sin2 φ dθ2)
(Σ = H3(1))
Each of our free observers has a worldline that intersects Σ at, without loss
of generality, t = 0. Now “move” the coordinates of Σ along these worldlines
by ﬁxing each observer’s spatial coordinates ψ, φ, θ at the values they have
at t = 0 on Σ and taking the fourth coordinate of each event to be the proper
time t of the observer that experiences that event. Allowing the “scale” of the
spatial cross sections to (perhaps) vary with t and recalling that the observer
worldlines are orthogonal to these cross sections we conclude that, in these
coordinates, the line element of M should have one of the forms
−dt 2 + a2(t)
⎧
⎪
⎨
⎪
⎩
dψ2 + sin2 ψ(dφ2 + sin2 φdθ2)
dψ2 +
ψ2(dφ2 + sin2 φdθ2)
dψ2 + sinh2 ψ(dφ2 + sin2 φdθ2)
where a(t) is some positive function of t. These are called Robertson-Walker
metrics and our conclusion (or, rather, now our ansatz) is that a spatially
homogeneous and isotropic spacetime should admit coordinate systems in
which the spacetime metric g assumes one of these forms.
If we were in the business of doing cosmology (which we are not) we
would choose one of these, substitute into the Einstein equations (for some
choice of Λ and some Tij ) and determine the scale function a(t). Our inter-
est in the Robertson-Walker metrics is that we have seen them all before
and all in the same place. Indeed, except for the names of the variables,
the metric for dS in global coordinates given by (4.3.22) is the Robertson-
Walker metric with spherical spatial cross sections and a(t) = cosh t; in
planar coordinates, Exercise 4.3.19 gives the same metric as a Robertson-
Walker metric with ﬂat spatial cross sections and a(t) = e2t; in hyperbolic
coordinates, Exercise 4.3.20 exhibits the metric of dS as a Robertson-
Walker metric with spatial cross sections that are hyperbolic 3-spaces and
a(t) = sinh t. These three represent very diﬀerent physical situations, of
course, but they are all simply diﬀerent descriptions of the same underlying
spacetime (or a part of it).
It is certainly interesting, but perhaps not so terribly surprising that
entirely diﬀerent physical pictures of the universe can be modeled in a sin-
gle spacetime. Certain things about a spacetime manifold are “absolute”,
i.e., independent of observer. The geodesics, for example, and the Riemann
curvature tensor, as well as the causality relations between events are all de-
termined entirely by the manifold and its metric. However, a spacetime such
as dS admits many families of timelike geodesics ﬁlling the manifold (e.g., the
tG−, tp−, and tH–coordinate curves), each with as much right as the other to
claim for itself the title of “cosmic observer” and determine its own “instan-
taneous 3-spaces.” This is entirely analogous to the situation in Minkowski

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
255
spacetime where diﬀerent admissible observers disagree as to which sets of
events count as instantaneous 3-spaces (although in this case they all agree
that “space” is R3).
Perhaps more interesting is the fact that all of these various observers agree
that they are in an empty universe (Exercise 4.4.1), not unlike an admissible
observer in Minkowski spacetime, but they see the world quite diﬀerently
than their Minkowskian colleague. Aside from the fact that they may see
“space” as spherical or hyperbolic, they also see it as expanding (indeed,
expanding at an exponentially increasing rate) due to the presence of the
scale factors a(t) = cosh t, e2t, and sinh t. Any two observers in the family
of cosmic observers have ﬁxed spatial coordinates, but even so their spatial
separation is increasing exponentially with t (in the spherical case one might
picture a balloon being blown up). Remarkably enough, recent astronomical
observations suggest that the expansion of our universe is, indeed, accelerat-
ing and this has prompted a renewed interest in the de Sitter universe as a
potential alternative to Minkowski spacetime (see, for example, [CGK]). As
we have seen, these two models of the empty universe have quite diﬀerent
properties and we will conclude by describing yet one more such property,
this one related to the asymptotic behavior of worldlines.
4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
We propose to oﬀer a precise deﬁnition of “inﬁnity” in both Minkowski and
de Sitter spacetimes and then show how the two diﬀer in the behavior of
their timelike and null curves “at inﬁnity.” This will lead to the notions of
particle and event “horizons” in dS that do not exist in M (since we are now
regarding Minkowski spacetime as a Lorentzian manifold it would probably
be more appropriate to call it R3,1, but we’ll stick with M). The idea behind
all of this is due to Roger Penrose and amounts to “squeezing” both M and dS
into ﬁnite regions of yet another spacetime in such a way that the boundaries
of these regions can be identiﬁed with “inﬁnity” in M and dS. The spacetime
into which we squeeze them is, moreover, of considerable signiﬁcance, at least
historically. It is called the Einstein static universe and we shall denote it E.
Remark:
Here, very brieﬂy, is the story of E. As Einstein originally pro-
posed them, the ﬁeld equations did not contain a cosmological constant (they
were our (4.4.1) with Λ = 0). Einstein applied these equations to a spatially
homogeneous and isotropic universe with S3 spatial cross sections and ﬁlled
with a uniform “dust” of galaxies (Tij was the energy-momentum tensor for
what is called a perfect ﬂuid with zero pressure). He found, much to his cha-
grin, that the solution described an expanding universe. He was chagrined by
this because, at the time, there was no reason to believe that the universe
was anything but what it had been assumed for centuries to be, that is, ﬁxed

256
4 Prologue and Epilogue: The de Sitter Universe
and immutable. He then, very reluctantly, modiﬁed his ﬁeld equations by in-
cluding the cosmological term Λgij because he could then, for a very speciﬁc
choice of Λ, ﬁnd a static solution E. Then, of course, along came Edwin Hub-
ble who interpreted the observed redshift of light from distant galaxies as a
Doppler shift and concluded that the universe is, in fact, expanding. Einstein
(and almost everyone else) then abandoned E along with the cosmological
constant that gave rise to it. As we have seen however, there may be reason
to resurrect Λ and there are those who believe that E also deserves a reprieve
(see [DS]).
Our ﬁrst task then is to construct the spacetime into which we will squeeze
M and dS. Since E can be described in terms very much like those with which
we described dS we will leave some of the details to the reader. As a set, E
consists of those points (u1, u2, u3, u4, u5) in R5 satisfying
(u1)2 + (u2)2 + (u3)2 + (u4)2 = 1
and so is pictured as a cylinder setting on the 3-sphere in R5.
Exercise 4.5.1 Show that E is diﬀeomorphic to S3 × R (and therefore
to dS).
Now deﬁne a map from R4 to R5 by
u1 = sin ¯φ1 cos ¯φ2
u2 = sin ¯φ1 sin ¯φ2 cos ¯θ
u3 = sin ¯φ1 sin ¯φ2 sin ¯θ
(4.5.1)
u4 = cos ¯φ1
u5 = tE.
Exercise 4.5.2 Show that the image of the map (4.5.1) is all of E and that
each point in E is contained in an open subset of E on which the inverse of
the map is a chart.
Thus, with the usual caveat regarding appropriate ranges for the variables,
(¯φ1, ¯φ2, ¯θ, tE) are global coordinates on E. In Figure 4.5.1 the cylinder E
is represented by suppressing the coordinates ¯φ2 and ¯θ and regarding ¯φ1 as
an angular coordinate on a copy of S1 in S3 (more precisely, Figure 4.5.1
represents a slice of E obtained by holding ¯φ2 and ¯θ ﬁxed).
Exercise 4.5.3 Restrict the M5-inner product to each tangent space
Tp(E), p ∈E, and show that the corresponding line element in (¯φ1, ¯φ2, ¯θ, tE)-
coordinates is
ds2 = d¯φ1
2 + sin2 ¯φ1

d¯φ2
2 + sin2 ¯φ2 d¯θ2
−dt2
E.
(4.5.2)
Remark:
The reader may wish to pause and compare (4.5.2) with the result
of Exercise 4.3.18. We will have more to say about this shortly. It should also

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
257
−f1
−f1
−f1 = 0
−f1 = π
tE = 0 (S3)
Fig. 4.5.1
be clear from (4.5.2) why E is called the Einstein “static” universe. The
spatial cross sections S3 of constant tE all have the same geometry, given by
d¯φ2
1 +sin2 ¯φ1

d¯φ2
2 + sin2 ¯φ2d¯θ2
; there is no time-dependent scale factor such
as one sees in the Robertson-Walker metrics we have described for dS.
This completes the description of the spacetime E, but we will also need
some information about its geodesics. Rather than computing Christoﬀel
symbols and trying to solve (4.3.27) we notice that, just as for dS, there
is a simple normal vector to each point of E with which we can pick out those
curves in E with α′′
tan(t) = 0 for each t.
Any smooth curve in E can be written α(t) = (u1(t), u2(t), u3(t), u4(t),
u5(t)), where (u1(t))2 +(u2(t))2 +(u3(t))2 +(u4(t))2 = 1. Diﬀerentiating with
respect to t gives
0 = u1(t) du1
dt + u2(t) du2
dt + u3(t) du3
dt + u4(t) du4
dt −0 · du5
dt
which says that the M5-inner product of α′(t) with the projection of α(t)
into S3, i.e., with (u1(t), u2(t), u3(t), u4(t), 0), is zero. Thus, for any p =
(p1, p2, p3, p4, p5) ∈E, the vector (p1, p2, p3, p4, 0) in M5 is orthogonal to
Tp(E). We conclude that Tp(E) can be viewed as the orthogonal complement
in M5 of the vector (p1, p2, p3, p4, 0). Moreover, a smooth curve α(t) in E

258
4 Prologue and Epilogue: The de Sitter Universe
is a geodesic of E if and only if its acceleration α′′(t) =

d2u1
dt2 , . . . , d2u4
dt2 , d2u5
dt2

is a multiple of (u1(t), . . . , u4(t), 0) for each t. In particular, u5 must be a
linear function of t so a geodesic must be of the form
α(t) = (u1(t), u2(t), u3(t), u4(t), at + b)
(4.5.3)
for some constants a and b. Moreover, the projection
απ(t) = (u1(t), u2(t), u3(t), u4(t))
(4.5.4)
of α into S3 has the property that α′′
π(t) is a multiple of απ(t) for each t so,
by Exercise 4.3.24, απ is a geodesic of S3 and therefore either a constant if
it is degenerate or a constant speed parametrization of a great circle in S3 if
it is not.
Exercise 4.5.4 Let α be a nondegenerate geodesic of E written in the form
(4.5.3) and απ its projection into S3 as in (4.5.4). Prove each of the following
(see Figure 4.5.2).
(a) If a = 0, then α is a constant speed parametrization of a great circle in
the 3-sphere at “height” u5 = b and is spacelike.
(b) If απ(t) is degenerate (say, απ(t) =

u1
0, u2
0, u3
0, u4
0

for all t), then α
is a constant speed parametrization of a “vertical” straight line and is
timelike.
(c) If a ̸= 0 and απ is not degenerate, then α is a “helix” sitting over some
great circle in S3 and (α′(t), α′(t)) = (α′
π(t), α′
π(t)) −a2 so
α is
⎧
⎪
⎨
⎪
⎩
null
,
if (α′
π(t), α′
π(t)) = a2
timelike
,
if 0 < (α′
π(t), α′
π(t)) < a2
spacelike
,
if (α′
π(t), α′
π(t)) > a2
.
Notice that Figure 4.5.2 exhibits a feature of the Einstein static universe
that we have not encountered before. Two points can be joined by both a
timelike and a null geodesic (both future-directed if this is deﬁned, as for
dS, in terms of the relations ≪and < in M5). Notice also that, since any
linear reparametrization of a geodesic is also a geodesic, when a ̸= 0 we may
assume that it is 1 and b = 0. In particular, the null geodesics of E can all be
described as
α(t) = (απ(t), t),
where
(α′
π(t), α′
π(t)) = 1
for −∞< t < ∞so that απ is a unit speed parametrization of a great circle
in S3.

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
259
tE
spacelike
timelike
timelike
spacelike
null
Fig. 4.5.2
The next order of business is to formulate a precise notion of what it means
to “squeeze” one manifold with metric into another. We have seen already
that if M1 and M2 are manifolds with metrics g1 and g2, respectively, then
an isometry from M1 to M2 is a diﬀeomorphism F : M1 →M2 that preserves
inner products at each point in the sense that
g2 ((F ◦α)′ (t0), (F ◦β)′ (t1)) = g1 (α′ (t0), β′ (t1))
for all smooth curves α and β in M1 with α(t0) = β(t1). If such an isometry
exists, then, in particular, M1 and M2 are the same as manifolds (diﬀeomor-
phic), but they are geometrically the same as well since F preserves lengths
of curves, carries geodesics to geodesics, and preserves the curvature; there is
no “squeezing” going on here. To achieve this we will relax the requirement
that F preserve inner products at each point and require only that these
inner products change by at most some positive multiple at each point. More
precisely, we deﬁne a conformal diﬀeomorphism from M1 to M2 to be a dif-
feomorphism F : M1 →M2 with the property that, for each p ∈M1 and all
smooth curves α and β in M1 with p = α(t0) = β(t1),
g2 ((F ◦α)′ (t0), (F ◦β)′ (t1)) = Ω2(p)g1 (α′ (t0), β′ (t1))
for some smooth, positive function
Ω : M1 →R.
To facilitate the comparison of the two metrics and their geometries it is
often convenient to have them both live on the same manifold (or, rather,

260
4 Prologue and Epilogue: The de Sitter Universe
the same copy of the single manifold that both M1 and M2 are diﬀeomorphic
to). For this we deﬁne the pullback of g2 to M1 to be the metric F ∗g2 on M1
deﬁned by
(F ∗g2) (α′ (t0), β′ (t1)) = g2 ((F ◦α)′ (t0), (F ◦β)′ (t1))
for all smooth curves α and β in M1 with α(t0) = β(t1). Then the condition
that F be a conformal diﬀeomorphism says simply that
F ∗g2 = Ω2 g1
and in this case we will refer to g1 and F ∗g2 as conformally related metrics
on M1.
If F happens not to be surjective, but maps only onto some manifold
F(M1) contained in M2, then F is called a conformal embedding of M1 into
M2 and, if 0 < Ω(p) < 1 for each p ∈M1, is thought of as “squeezing” M1
into M2.
Example 4.5.1 We deﬁne a map F : dS →E as follows. Let (φ1, φ2, θ, tC)
denote the conformal coordinates on dS (Example 4.3.3) and (¯φ1, ¯φ2, ¯θ, tE)
the coordinates on E deﬁned by (4.5.1). Our map will send the point in
dS with coordinates (φ1, φ2, θ, tC) to the point in E with coordinates
(¯φ1, ¯φ2, ¯θ, tE). Somewhat more precisely, we write χ and ¯χ for the co-
ordinate patches on dS and E corresponding to these coordinates and deﬁne
F by
(¯χ−1 ◦F ◦χ) (φ1, φ2, θ, tC) = (¯φ1, ¯φ2, ¯θ, tE),
that is,
¯φ1 = φ1
¯φ2 = φ2
¯θ = θ
(4.5.5)
tE = tC.
Since −π
2 < tC < π
2 , the image of dS in E is the ﬁnite cylinder S3 ×

−π
2 ,
π
2

.
Now let α be a smooth curve in dS written as
α(t) = χ(φ1(t), φ2(t), θ(t), tC(t)).
Then
α′(t) = dφ1
dt χ1 + dφ2
dt χ2 + dθ
dt χ3 + dt C
dt χ4,

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
261
where each χi is evaluated at α(t). Moreover,
(F ◦α) (t) = (F ◦χ) (φ1(t), φ2(t), θ(t), tC(t))
= ¯χ

(¯χ−1 ◦F ◦χ) (φ1(t), φ2(t), θ(t), tC(t))

= ¯χ(¯φ1(t), ¯φ2(t), ¯θ(t), tE(t))
so
(F ◦α)′(t) = d¯φ1
dt ¯χ1 + d¯φ2
dt ¯χ2 + d¯θ
dt ¯χ3 + dt E
dt ¯χ4
= dφ1
dt ¯χ1 + dφ2
dt ¯χ2 + dθ
dt ¯χ3 + dt C
dt ¯χ4
= F∗α(t) (α′(t)),
where each ¯χi is evaluated at F(α(t)). In particular,
F∗p(χi(p)) = ¯χi(F(p)),
i = 1, 2, 3, 4.
Writing gE for the restriction to S3×

−π
2 ,
π
2

⊆E of the metric on E given by
(4.5.2) we compute the components of F ∗gE in conformal coordinates on dS.
(F ∗gE) (χi(p), χj(p)) = gE

F∗p(χi(p)), F∗p(χj(p))

= gE(¯χi(F(p)), ¯χj(F(p)))
=
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
0
, i ̸= j
1
, i = j = 1
sin2 ¯φ1(F(p))
, i = j = 2
sin2 ¯φ1(F(p)) sin2 ¯φ2(F(p))
, i = j = 3
−1
, i = j = 4
=
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
0
, i ̸= j
1
, i = j = 1
sin2 φ1(p)
, i = j = 2
sin2 φ1(p) sin2 φ2(p)
, i = j = 3
−1
, i = j = 4
Consequently, the line element for the metric F ∗gE on dS in conformal coor-
dinates (φ1, φ2, θ, tC) is
dφ2
1 + sin2 φ1

dφ2
2 + sin2 φ2 dθ2
−dt 2
C
and this, according to Exercise 4.3.18, is cos2 tC times the line element for
the metric gdS of dS in conformal coordinates. We conclude therefore that
F ∗gE = Ω2gdS

262
4 Prologue and Epilogue: The de Sitter Universe
where Ω(φ1, φ2, θ, tC) = cos tC. Thus, F ∗gE and gdS are conformally related
metrics on dS or, said otherwise, F is a conformal embedding of dS into E.
We will have more to say about this particular example shortly, but ﬁrst
we will need to develop a few general results on conformally related metrics.
First observe that a conformal diﬀeomorphism of one spacetime manifold to
another carries spacelike, timelike and null curves onto curves of the same
type since
g2((F ◦α)′ (t), (F ◦α)′ (t)) = Ω2 (α(t)) g1 (α′ (t), α′ (t))
so the causal character of the tangent vector is preserved at each point. It is
not the case, however, that conformal diﬀeomorphisms always carry geodesics
onto geodesics. However, we will show that a conformal diﬀeomorphism on
a spacetime manifold carries a null geodesic onto a (reparametrization of a)
null geodesic.
We begin by having another look at the geodesic equations
d2xr
dt2 + Γr
ij
dx i
dt
dx j
dt = 0,
r = 1, . . . , n
(4.5.6)
in an n-manifold M with metric g. We recall (Lemma 4.3.1) that these
geodesic equations are not independent of parametrization. Indeed, a geodesic
must be parametrized in a very particular way in order for its coordinate
functions to satisfy (4.5.6). These are called aﬃne parametrizations and they
diﬀer from each other by simple linear functions. Of course, any curve can be
reparametrized anyway you like and we would like to see what the geodesic
equations look like in an arbitrary parametrization. Thus, we assume that
(4.5.6) is satisﬁed and introduce a reparametrization t = h(s), where h is
some smooth function with h′(s) > 0 for all s. Then
dx a
ds = dx a
dt
dt
ds
d2xa
ds2 = d2xa
dt2
 dt
ds
2
+ dx a
dt
d2t
ds2
and so
d2xr
ds2 + Γr
ij
dx i
ds
dx j
ds = d2xr
dt 2
dt
ds
2
+ dx r
dt
d2t
ds2 + Γr
ij
dx i
dt
dx j
dt
 dt
ds
2
=
dt
ds
2 
d2xr
dt 2 + Γr
ij
dx i
dt
dx j
dt

+ dx r
dt
d2t
ds2
= d2t
ds2
dx r/ds
dt/ds

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
263
d2xr
ds2 + Γr
ij
dx i
ds
dx j
ds =
d2t/ds2
dt/ds
 dx r
ds ,
r = 1, . . . , n.
(4.5.7)
Thus, (4.5.7) are the equations satisﬁed by a geodesic when expressed in
terms of an arbitrary parameter s. Of course, when s is a linear function of
the aﬃne parameter t, they reduce to (4.5.6).
Notice that if we are given some smooth curve α(s) in M that satisﬁes
d2xr
ds2 + Γr
ij
dx i
ds
dx j
ds = f(s) dx r
ds ,
r = 1, . . . , n
(4.5.8)
for some function f(s), we can introduce a parameter t by setting
d2t/ds2
dt/ds
= f(s)
and solve
d2t
ds2 −f(s) dt
ds = 0
to obtain
dt
ds = e
; s
a
f(ξ)dξ
where a is an arbitrary constant. Reparametrized in terms of t, α(t) satisﬁes
(4.5.6) and is therefore a geodesic of M. We will write out a speciﬁc example
shortly, but ﬁrst we use this to show that if α(t) is a null geodesic in a
spacetime manifold M (with aﬃne parameter t), then α(t) is also a null
geodesic in any conformally related metric, although t need not be an aﬃne
parameter for it. Thus, conformal diﬀeomorphisms preserve null geodesics, up
to parametrization. For the proof we will ﬁrst need to compute the Christoﬀel
symbols of a conformally related metric.
We let M denote an n-manifold with metric g and suppose ¯g = Ω2g is a
conformally related metric on M. In any coordinate system x1, . . . , xn the
metric components are gij and ¯gij = Ω2gij and the entries of the inverse
matrices are related by ¯gij = Ω−2gij . By deﬁnition, the Christoﬀel symbols
for g in these coordinates are
Γr
ij = 1
2grk
∂gik
∂xj + ∂gjk
∂xi −∂gij
∂xk

,
r, i, j = 1, . . . , n

264
4 Prologue and Epilogue: The de Sitter Universe
and those for ¯g are
¯Γr
ij = 1
2 ¯grk
∂¯gik
∂xj + ∂¯gjk
∂xi −∂¯gij
∂xk

= 1
2 Ω−2 grk
 ∂
∂xj

Ω2 gik

+ ∂
∂xi

Ω2 gjk

−
∂
∂xk

Ω2 gij

= 1
2 Ω−2 grk

Ω2 ∂gik
∂xj + 2Ω ∂Ω
∂xj gik +
Ω2 ∂gjk
∂xi + 2Ω ∂Ω
∂xi gjk −
Ω2 ∂gij
∂xk −2Ω ∂Ω
∂xk gij

= Γr
ij + Ω−1
 ∂Ω
∂xj grkgik + ∂Ω
∂xi grkgik −∂Ω
∂xk grkgij

= Γr
ij + Ω−1

δr
i
∂Ω
∂xj + δr
j
∂Ω
∂xi −grkgij
∂Ω
∂xk

.
Thus,
¯Γr
ij = Γr
ij + δr
i
∂
∂xj (ln Ω) + δr
j
∂
∂xi (ln Ω) −grkgij
∂
∂xk (ln Ω).
(4.5.9)
Next we consider a curve α(t) in a spacetime M that is null relative to g,
and therefore also relative to ¯g. Thus,
gij
dx i
dt
dx j
dt = 0
(4.5.10)
for all t. We claim that (4.5.10) implies
d2xr
dt2 + ¯Γr
ij
dx i
dt
dx j
dt = d2xr
dt2 + Γr
ij
dx i
dt
dx j
dt + d
dt (2 ln Ω) dx r
dt
(4.5.11)
for r = 1, 2, 3, 4. Indeed, multiplying (4.5.9) by dx i
dt
dx j
dt and summing as indi-
cated gives
¯Γr
ij
dx i
dt
dx j
dt −Γr
ij
dx i
dt
dx j
dt
= δr
i
∂
∂xj (ln Ω) dx i
dt
dx j
dt + δr
j
∂
∂xi (ln Ω) dx i
dt
dx j
dt
−grk
∂
∂xk (ln Ω) gij
dx i
dt
dx j
dt
=

∂
∂xj (ln Ω) dx i
dt + ∂
∂xi (ln Ω) dx i
dt

dx r
dt −0

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
265
=

2 ∂
∂xi (ln Ω) dx i
dt

dx r
dt
=

2 d
dt (ln Ω)
 dx r
dt
from which (4.5.11) is immediate.
Now we can fulﬁll our promise about null geodesics. Suppose that α(t) is
a null geodesic of g with aﬃne parameter t. Then (4.5.10) is satisﬁed and,
moreover,
d2xr
dt 2 + Γr
ij
dx i
dt
dx j
dt = 0,
r = 1, 2, 3, 4.
Thus, (4.5.11) gives
d2xr
dt2 + ¯Γr
ij
dx i
dt
dx j
dt = d
dt (2 ln Ω) dx r
dt ,
(4.5.12)
for r = 1, 2, 3, 4. It follows from (4.5.8) that α(t) is also a (null) geodesic of ¯g,
but that t is not an aﬃne parameter for it. From the discussion immediately
following (4.5.8) we can introduce an aﬃne parameter μ for this null geodesic
of ¯g by
dμ
dt = exp
 t
a
d
dξ (2 ln Ω)dξ

.
Taking the multiplicative constant to be one,
dμ
dt = Ω2 
x1(t), . . . , x4(t)

(4.5.13)
so μ(t) can be found by integration.
Example 4.5.2 We return to the conformally related metrics gdS and
F ∗gE
on dS
discussed in Example 4.5.1. Here F ∗gE = Ω2gdS, where
Ω(φ1, φ2, θ, tC) = cos tC. Every null geodesic in dS (relative to gdS) can
be described as follows.
Fix a point p ∈dS and a null vector v in M5 orthogonal to p in M5((v, v) = 0
and (p, v) = 0). Then any linear parametrization α(t) = p + tv, −∞< t <
∞, of the straight line through p in the direction v is a null geodesic of
dS. Any such t is an aﬃne parameter for the geodesic since the acceleration
is zero which is certainly M5-orthogonal to Tα(t)(dS) for each t and this,
as we have seen, implies that the geodesic equations (4.3.27) are satisﬁed
in any coordinate system. Since a null straight line in M5 can be linearly
parametrized by u5 we can assume that p is in the “bottleneck” u5 = 0 in dS
and simply take t to be u5.
Exercise 4.5.5 Show that u5 = tan(tC) for −π
2 < tC < π
2 .
Now, we have seen that α is also a reparametrization of a null geodesic of
F ∗gE and that an aﬃne parameter μ for this F ∗gE-geodesic is determined by
(4.5.13) which, in this case, is

266
4 Prologue and Epilogue: The de Sitter Universe
dμ
dt = cos2 (tC(t))
= cos2 (arctan t)
by Exercise 4.5.5
=
1
1 + t2
so
μ = μ(t) = arctan t + k = tC + k
for some constant k. Taking k = 0 so that
μ = 0
⇐⇒
t = 0
⇐⇒
tC = 0
we ﬁnd that
μ = tC
is an aﬃne parameter for α(t) with respect to F ∗gE.
Rephrasing all of this we conclude that the image in E of the null geodesic
α(t) in dS under the conformal diﬀeomorphism F is that portion of a null
geodesic (“helix”) in E aﬃnely parametrized by tE = tC for −π
2 < tE < π
2
(see Figure 4.5.3). The most important conclusion we wish to draw from this
is that, on null geodesics,
t −→∞
⇐⇒
tE −→π
2
and
t −→−∞
⇐⇒
tE −→−π
2 .
Thus, the entire history of a null geodesic in dS is “squeezed” into the ﬁnite
region −π
2 < tE < π
2 of E and the slices tE = −π
2 and tE = π
2 accurately
represent “inﬁnity” for null geodesics in dS. The 3-sphere tE = −π
2 in E is
denoted I−and called the past null inﬁnity of dS; tE = π
2 , denoted I+, is
the future null inﬁnity of dS. If we identify dS with its “squeezed” version
in E, one can think of null geodesics as being born on I−in the inﬁnite past
(t = −∞) and dying on I+ in the inﬁnite future (t = ∞).
There is a great deal of information in this conformal picture about the
causal structure of dS, much of which contrasts rather sharply with what
we know about Minkowski spacetime. It is all much more easily visualized,
however, if we construct something analogous to the 2-dimensional Minkowski
diagrams employed in Chapter 1. These are called Penrose diagrams and are
based on the simple fact that the helices representing null geodesics of E in
Figures 4.5.2 and 4.5.3 are precisely the curves on the cylinder that one gets
from diagonal straight lines in the plane by wrapping the plane around itself
to build the cylinder. We reverse this procedure by cutting the cylinder in
Figure 4.5.3 along the vertical line at φ1 = π and ﬂattening it onto the plane.
The result is Figure 4.5.5 which also has labeled a number of additional items
that we will now endeavor to explain.

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
267
f1 = π
tE = 0 
f1 = 0 
tE = −  
π  (t → - ∞)
2−
tE = π  (t →  ∞)
2−
Fig. 4.5.3
We will identify the timelike hyperbolas in Figure 4.5.4 with the worldlines
of a family of cosmic observers in dS for which φ1 (as well as φ2 and θ) are
held ﬁxed and will (arbitrarily) decree that the observer with φ1 = 0 resides
at the north pole of S3 Then φ1 = π corresponds to an observer at the south
pole. These worldlines map to vertical straight lines in the conformal image of
dS in E and we will now identify these, parametrized by −π
2 < tE < π
2 , with
our cosmic observers. The points on these vertical straight lines with tE = π
2
and tE = −π
2 do not arise from points on the hyperbolas in dS. Rather, they
are to be regarded as the asymptotic limits of these worldlines as t →∞and
t →−∞, respectively.
We begin by focusing attention on some point p on the worldline of the
observer O residing at the north pole. The null geodesics through p (or any
other point) appear as straight lines inclined 45◦to the horizontal. We will,
somewhat inaccurately, refer to this pair of lines as the “null cone” at p
(technically, the null cone lives in the tangent space at p). The events on the
lower (past) null cone at p are those visible to O at p. Notice that some of
our cosmic observers have worldlines that intersect this past null cone at p
(e.g., O′ at p′
1), but others. do not (e.g., O′′) and the latter are not visible to
O at p. By contrast, in Minkowski spacetime, the past null cone at any event
on any timelike straight line intersects every other timelike straight line. The

268
4 Prologue and Epilogue: The de Sitter Universe
dS
f1 = p (south pole)
f1 = 0 (north pole)
Fig. 4.5.4
past null cone at p is called the particle horizon of O at p since it is the
boundary between the particles that are visible to O at or before p and those
that are not; such things do not exist in M. The observer O′′ does eventually
become visible to O since the point p′′
1 on its worldline is also on the past null
cone at p1. The same cannot be said of an observer stationed at the south
pole, however, since no past null cone to any point on O’s worldline intersects
the vertical line at φ1 = π.
The past null cone at the point in E with φ1 = 0 and tE = π
2 does not
correspond to any point on the worldline of O, but is rather to be regarded
as a limiting position for O’s past null cones as t →∞. This is called the
past event horizon of the worldline and is the boundary between the events
that will eventually be visible to O and those that will not. Notice that the
worldlines of O′ and O′′ both intersect this past event horizon (at p′
2 and
p′′
2). These are perfectly ordinary points on the worldlines of O′ and O′′, but
O never sees them because an inﬁnite proper time elapses on O’s worldline
before they occur. O sees a ﬁnite part of the history of both O′ and O′′ in an
inﬁnite amount of his proper time. Physicists would express this by saying
that signals received by O from either O′ or O′′ are redshifted by an amount
that becomes inﬁnite as the points p′
2 and p′′
2 are approached.
Analogously, the future null cone at p encloses all of the events that O
can inﬂuence at or after p. The corresponding future null cone at the point
of E with φ1 = 0 and tE = −π
2 encloses all of the events that O could
ever inﬂuence and is called the future event horizon of O’s worldline. The
shaded region in Figure 4.5.5 between the past and future event horizons of
O therefore consists of events that are completely inaccessible to O, who can
neither inﬂuence nor be inﬂuenced by them.

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
269
f1 = 0
f1 = π
Particle Horizon at p
Particle Horizon at p
Past Event Horizon of
Future Event Horizon of
Past Event Horizon of
Future Event Horizon of
p
p1
p2
p1
p1
p2
f1 = π
 + (tE = 
π ; t → ∞ )
2−
 − (tE = −   
π ; t → −∞ )
2−
"
'
"
"
'
'
Fig. 4.5.5
All of the behavior we have just described is, of course, completely unheard
of in M. The structure of “inﬁnity” in Minkowski spacetime is clearly diﬀer-
ent than that of de Sitter spacetime. To understand more precisely just what
these diﬀerences are we would like to conclude by guiding the reader through
a sequence of exercises that construct an analogous conformal embedding of
M into E and the resulting Penrose diagram for Minkowski spacetime. The
ﬁrst objective is an analogue of conformal coordinates for M.
It will be convenient to construct these conformal coordinates for M in
stages. We will denote by u1, u2, u3, and u4 the standard coordinates on
M(R4) relative to which the Minkowski line element is
ds2 = (du1)2 + (du2)2 + (du3)2 −(du4)2.
Identifying R4 with R3 × R, introducing spherical coordinates ρ, φ, θ on R3
and denoting by t the coordinate on R we have
u1 = ρ sin φ cos θ
u2 = ρ sin φ sin θ
u3 = ρ cosφ
u4 = t
and
ds2 = dρ2 + ρ2(dφ2 + sin2 φ dθ2) −dt2.
We remind the reader of all the usual caveats concerning spherical coordi-
nates. All of M is parametrized by ρ, φ, θ, t with ρ ≥0, 0 ≤φ ≤π,
0 ≤θ ≤2π, and −∞< t < ∞, but to obtain charts one restricts
these to either ρ > 0, 0 < φ < π, 0 < θ < 2π, −∞< t < ∞, or
ρ > 0, 0 < φ < π, −π < θ < π, −∞< t < ∞. These two charts cover
all of M except the u3-axis for each u4(= t). One can cover these points,

270
4 Prologue and Epilogue: The de Sitter Universe
except for ρ = 0, with analogous spherical coordinates with, say, φ measured
from the u1-axis and θ in the u2u3-plane. Finally, to cover the points with
ρ = 0, −∞< t < ∞, i.e., the t-axis, one selects some other point as the
“origin” for an entirely analogous spherical coordinate chart. As is custom-
ary, we sweep all of these variants under the rug and use ρ, φ, θ, t for the
coordinates in any one of these charts.
Next we introduce what are called advanced and retarded null coordinates
v and w by letting v = t + ρ and w = t −ρ. In somewhat more detail, we let
ρ = 1
2 (v −w)
φ = φ
θ = θ
(4.5.14)
t = 1
2 (v + w)
Exercise 4.5.6
(a) Show that v, w, φ, θ parametrize all of M for −∞< w ≤v < ∞, 0 ≤
φ ≤π and 0 ≤θ ≤2π and that each point of M is contained in an open
set on which v, w, φ, θ are the coordinates of a chart for M.
(b) Show that, if a and b are constants, then the set of points in M with v = a
is the lower half of the null cone at (u1, u2, u3, u4) = (0, 0, 0, a) and
w = b is the upper half of the null cone at (u1, u2, u3, u4) = (0, 0, 0, b).
(c) Show that the line element for M in these coordinates is
ds2 = 1
4 (v −w)2(dφ2 + sin2 φ dθ2) −dv dw.
Exercise 4.5.6 (b) provides a nice geometrical and physical interpretation of
the new coordinates v and w. One ﬁnds v and w geometrically at a point x
in M by locating points on the u4-axis at which the lower and upper null
cones intersect at x. Physically, one can express this in the following way.
For v(x) one ﬁnds a spherical electromagnetic wave that is “incoming” to
the origin and experiences x, while for w(x) one ﬁnds such a wave that is
“outgoing” from the origin. Then v(x) is the time t at which the incoming
wave reaches the origin and w(x) is the time t at which the outgoing wave
left the origin. Succinctly, one connects x to the origin with light rays and
uses the departure and arrival times as coordinates. Thus, v(x) (respectively,
w(x)) is an advanced (respectively, retarded) null coordinate. Suppressing φ
and θ we can picture this in the ρt-plane as in Figure 4.5.6.
Next we once again use the arctangent function to “make inﬁnity ﬁnite”,
as Penrose and Rindler [PR2] put it. Speciﬁcally, we replace v and w by two
new coordinates p and q deﬁned by p = arctan v and q = arctan w. In more
detail, we deﬁne

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
271
∞
∞
w
w = b
t
υ
υ = a
a
b
r
x
Fig. 4.5.6
v = tan p
φ = φ
θ = θ
(4.5.15)
w = tan q
for −π
2 < p < π
2 and −π
2 < q < π
2 . Notice that
w ≤v
=⇒
q ≤p.

272
4 Prologue and Epilogue: The de Sitter Universe
Exercise 4.5.7
(a) Show that p, q, φ, θ parametrize all of M for −π
2 < q ≤p < π
2 , 0 ≤φ ≤π
and 0 ≤θ ≤2π and that each point of M is contained in an open set on
which p, q, φ, θ are the coordinates of a chart for M.
(b) Show that the line element for M in these coordinates is
ds2 = 1
4 sec2 p sec2 q

−4dp dq + sin2 (p −q)

dφ2 + sin2 φ dθ2
.
Now, one ﬁnal maneuver to bring this last line element into a more familiar
form. Speciﬁcally, we introduce two new coordinates t′ and ρ′ by t′ = p + q
and ρ′ = p −q, i.e.,
p = 1
2(t′ + ρ′)
φ = φ
θ = θ
(4.5.16)
q = 1
2(t′ −ρ′)
for −π < t′ < π and 0 ≤ρ′ < π.
Exercise 4.5.8
(a) Show that ρ′, φ, θ, t′ parametrize all of M for 0 ≤ρ′ < π, 0 ≤φ ≤
π, 0 ≤θ ≤2π, −π < t′ < π, and that each point of M is contained in
an open set on which ρ′, φ, θ, t′ are the coordinates of a chart for M.
(b) Show that
2t = tan
1
2 (t′ + ρ′)

+ tan
1
2 (t′ −ρ′)

2ρ = tan
1
2 (t′ + ρ′)

−tan
1
2 (t′ −ρ′)

.
(c) Show that the line element for M in these coordinates is
ds2 = 1
4 sec2
1
2 (t′ + ρ′)

sec2
1
2 (t′ −ρ′)
 
dρ′2 +
sin2 ρ′(dφ2 + sin2 φ dθ2) −dt′2
.
(4.5.17)
Now we ﬁnd ourselves in a familiar position. Except for the names of the
variables, dρ′2 + sin2 ρ′(dφ2 + sin2 φdθ2) −dt ′2 has precisely the same form
as the line element (4.5.2) of the Einstein static universe in its standard
coordinates and the line element for M relative to (ρ′, φ, θ, t′) is just
a positive multiple of this. We now ask the reader to argue as we did in
Example 4.5.1 and draw the same conclusion.

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
273
Exercise 4.5.9 Deﬁne a mapping F of M into E by
¯φ1 = ρ′
¯φ2 = φ
¯θ = θ
tE = t′
for 0 ≤ρ′ < π, 0 ≤φ ≤π, 0 ≤θ ≤2π and −π < t′ < π. Show that F is a
conformal embedding of M into the region S3 × (−π, π) in E with
F ∗gE = Ω2gM,
where gM is the Lorentz metric on M and
Ω(ρ′, t′) = 2 cos
1
2 (t′ + ρ′)

cos
1
2 (t′ −ρ′)

.
(4.5.18)
The image of the conformal embedding of dS
into E
was all of
S3 ×

−π
2 ,
π
2

, but it is not the case that the map F in Exercise 4.5.9 maps
onto S3 × (−π, π). To ﬁnd the image we ﬁrst ﬁnd its boundary (which will
eventually play the role of “inﬁnity” in M)). As before we will construct our
picture on the 2-dimensional cylinder by holding φ and θ ﬁxed.
The “ﬁnite part” of M corresponds to −π
2 < q ≤p < π
2 so −π < t′ + ρ′ <
π, −π < t′ −ρ′ < π, and 0 ≤ρ′ ≤π. Since ¯φ1 = ρ′ and tE = t′, these
translate to −π < tE + ¯φ1 < π, −π < tE −¯φ1 < π, and 0 ≤¯φ1 < π. Thus,
the boundary of the image of M in E is determined by tE + ¯φ1 = ±π and
tE −¯φ1 = ±π, subject to 0 ≤¯φ1 ≤π and −π ≤tE ≤π. Observe ﬁrst that
tE + ¯φ1 = −π, tE ≥−π,
and
¯φ1 ≥0
=⇒
(tE, ¯φ1) = (−π, 0)
and
tE −¯φ1 = π, tE ≤π,
and
¯φ1 ≥0
=⇒
(tE, ¯φ1) = (π, 0)
These two points in our picture we will denote
i−: tE + ¯φ1 = −π

p = −π
2 , q = −π
2

and
i+ : tE −¯φ1 = π

p = π
2 , q = π
2

and, for reasons to be explained shortly, call them, respectively, past and
future timelike inﬁnity of M, while those satisfying
tE −¯φ1 = −π

274
4 Prologue and Epilogue: The de Sitter Universe
will be denoted I−and called past null inﬁnity of M, while those satisfying
tE + ¯φ1 = π
are denoted I+ and called future null inﬁnity of M. The intersection of
these two is just the point (tE, ¯φ1) = (0, π) which is denoted i◦and called
space-like inﬁnity of M.
Note: One should observe that the boundary points i−, i+, I−, I+ and i◦
we have just isolated are precisely the points at which the conformal factor
Ω given by (4.5.18) vanishes.
We visualize I−and I+ using the same device employed for the conformal
embedding of dS in E. Unfolding the 2-dimensional Einstein cylinder onto
the ¯φ1 tE-plane, the equations tE −¯φ1 = −π and tE + ¯φ1 = π determine
straight lines. This is depicted in Figure 4.5.7, but a bit of care is required
in interpreting the picture. Since (¯φ1, tE) = (π, 0) and (¯φ1, tE) = (−π, 0)
come from the same point on the cylinder we have identiﬁed them and drawn
both of the straight lines twice on opposite sides of the tE-axis. When the
plane is folded back up into the cylinder these become the curves labeled I−
and I+ in Figure 4.5.8.
− π
π
π
π
tE + f1 = π  
−
tE + f1 = π  
−
tE − f1 = − π  
−
tE − f1 = − π  
−
tE 
f1
−
Fig. 4.5.7
The justiﬁcation for the names we have attached to the various components
of the conformal boundary of M is arrived at by examining the images in E
of geodesics in M. We begin with future-directed null geodesics in M. We
have shown already that these map to (reparametrizations of) null geodesics

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
275
f1
−
f1
−
f1 = π
−
f1 = 0
−
tE = −π
tE = π
tE = 0
+
i +
i 0
I −
i −
i 0
I
Fig. 4.5.8
in E, but our interest now is in where they begin and end. To simplify the
arithmetic we will consider geodesics that pass through the origin of M, but
the same conclusions follow for those that do not. Thus, we consider a curve
α : R →M given by
α(s) = s(v1, v2, v3, v4)
where (v1)2 + (v2)2 + (v3)2 −(v4)2 = 0 and v4 > 0. Then, on α, ρ2 =
(sv 1)2 + (sv 2)2 + (sv 3)2 = (sv 4)2 so, for s ≥0, ρ = v4s. But ρ2 −t2 = 0
then gives t = v4s as well so (ρ, t) = (v4s, v4s). In particular, t −ρ = 0
and t + ρ = 2v4s →∞as s →∞. Thus, w = 0 and v →∞so q = 0 and
p →π
2 as s →∞. Consequently, t′ →π
2 and ρ′ →π
2 and so the image of the
null geodesic under the conformal embedding F of M into E (Exercise 4.5.9)
satisﬁes
tE + ¯φ1 →π

276
4 Prologue and Epilogue: The de Sitter Universe
and so approaches I+. In the same way the image of α approaches I−as
s →−∞. Although I−and I+ do not lie in M one thinks of future-directed
null geodesics as beginning on I−and ending on I+.
A future-directed timelike geodesic through the origin in M is a curve
α : R →M that can be written in the form
α(s) = s(v1, v2, v3, v4)
where (v1)2+(v2)2+(v3)2−(v4)2 = −1 and v4 > 0. The image of α under the
conformal embedding of M into E need not be a geodesic, but it is a timelike
curve which we now ask the reader to show must begin on i−and i+.
Exercise 4.5.10 Show that the image in E of the future-directed timelike
geodesic α approaches i−as s →∞and i+ as s →∞.
A spacelike geodesic α : R →M in M can be written as α(s) =
s(v1, v2, v3, v4), where (v1)2 +(v2)2 +(v3)2 −(v4)2 = 1 and one can assume
without loss of generality that v4 ≥0. The image of α under the conformal
embedding of M into E need not be a geodesic, but it is a spacelike curve.
Exercise 4.5.11 Show that the image in E of the spacelike geodesic α ap-
proaches i◦as s →∞and also as s →−∞.
i 0
i 0
i −
i +
I −
I −
I +
I +
Fig. 4.5.9
Figure 4.5.9 is just Figure 4.5.7 again with all of the various pieces of the con-
formal boundary of M identiﬁed by name and images in E of a few geodesics
of each type in M included. This is the Penrose diagram of Minkowski space-
time and, contrasted with the corresponding diagram for dS (Figure 4.5.5),
it does much to elucidate the diﬀerences in causal structure between the two.
There are, for example, no particle or event horizons in M precisely because
timelike geodesics “focus” on i−and i+ rather than I−and I+ so that the

4.5 Inﬁnity in Minkowski and de Sitter Spacetimes
277
null cone at any point “catches” all of the timelike worldlines. This technique
has been used to great eﬀect in general relativity, but it goes much further
than this. Penrose devised the technique to study the asymptotic behavior
of solutions to massless free-ﬁeld equations in spinor form such as those with
which we concluded Section 3.6. The behavior of interest is conformally in-
variant and so, rather than employing complicated limiting procedures, one
can analyze the behavior at points of I−and I+ using the more familiar
local techniques of geometry and analysis. This is quite another story, how-
ever, and the best service we can provide for those interested in pursuing the
matter is to send them from here to [Pen2].


Appendix A
Topologies For M
A.1 The Euclidean Topology
In this appendix we wish to lay before the reader certain material which
requires a bit more in the way of background than the text itself and which
admittedly has not had a profound impact on subsequent research in rela-
tivity, but which is nonetheless remarkable from both the physical and the
mathematical points of view. We will assume a very basic familiarity with
elementary point-set topology and adopt [Wi] as our canonical reference.
The subject we wish to address had its origins in the extraordinary paper
[Z2] of Zeeman in 1967. Zeeman observed that the ordinary Euclidean topol-
ogy for M (deﬁned below) has, from the relativistic viewpoint, no physical
signiﬁcance or justiﬁcation and proposed an alternative he called the “ﬁne”
topology. This topology was easy to describe, physically well motivated and
had the remarkable property that its homeomorphism group (also deﬁned
below) was essentially just the Lorentz group (together with translations and
nonzero scalar multiplications). Thus, perhaps the most important group in
all of physics is seen to emerge at the very primitive level of topology, i.e.,
from just an appropriate deﬁnition of “nearby” events. The ﬁne topology is,
however, from the technical point of view, rather diﬃcult to work with and
the arguments in [Z2] are by no means simple. In 1976, Hawking, King and
McCarthy [HKM] described another topology on M which seemed physi-
cally even more natural, had precisely the same homeomorphism group as
Zeeman’s ﬁne topology and required for the proof of this nothing beyond
the most rudimentary point-set topology and Zeeman’s Theorem 1.6.2. This
so-called “path topology” for M is the object of our investigations in this
appendix.
We begin by transferring to M the standard Euclidean topology of R4 via a
linear isomorphism. Speciﬁcally, we select some ﬁxed admissible basis {ea}4
a=1
for M (this determines an obvious linear isomorphism of M onto R4). If x =
xaea and x0 = xa
0ea are two points in M we deﬁne the E-distance from x0 to
, 
: An Introduction 
, Applied Mathematical Sciences 92,
G.L. Naber The Geometry of Minkowski Spacetime
to the Mathematics 
of the Special Theory of Relativity
DOI 10.1007/978-1-4419-7838-7, © Springer Science+Business Media, LLC 2012
279

280
A Topologies For M
x by dE(x0, x) =

x1 −x1
0
2 +

x2 −x2
0
2 +

x3 −x3
0
2 +

x4 −x4
0
21/2
.
Then dE is a metric on M, i.e., satisﬁes (1) dE(x, x0) = dE(x0, x), (2)
dE(x0, x) ≥0 and dE(x0, x) = 0 if and only if x = x0, and (3) dE(x0, x) ≤
dE(x0, y)+dE(y, x) for all x0, x and y in M. Consequently, dE determines, in
the usual way (3.2 of [Wi]) a topology E for M called the Euclidean (or E-)
topology. Speciﬁcally, if x0 is in M and ε > 0 we deﬁne the E-open ball of
radius ε about x0 by
N E
ε (x0) = {x ∈M : dE(x0, x) < ε}.
A subset V of M is then said to be E-open if for every x0 in V there exists
an ε > 0 such that N E
ε (x0) ⊆V . The collection of all E-open sets in M con-
stitutes the E-topology for M. When thinking of M as being endowed with
the Euclidean topology we will denote it ME. E’s will likewise be appended
to various other terms and symbols to emphasize that we are operating in the
Euclidean topology, e.g., maps will be referred to as “E-continuous”, “ClE A”
and “bdyE A” will designate the E-closure and E-boundary of A and so on.
ME is, of course, homeomorphic to R4 with its customary Euclidean topology
so that its basic topological properties are well-known,1 e.g., it is ﬁrst count-
able, separable, locally compact, but not compact, pathwise connected, etc.
Notice that the deﬁnition of the E-metric dE on M is not invariant under
Lorentz transformations. That is, if dE(x0, x) is computed by the deﬁning
formula from the coordinates of x0 and x relative to another admissible basis
{ˆea} for M the result will, in general, be diﬀerent. The reason for this is clear
since the two bases are related by an element of L and elements of L preserve
the Lorentz inner product and not the Euclidean inner product (i.e., they
satisfy Λ−1 = ηΛTη rather than Λ−1 = ΛT ). Nevertheless, two such metrics,
while not equal, are equivalent in the sense that they determine the same
topology for M (because an element of L is a one-to-one linear map of M
onto M and so an E-homeomorphism).
A.2 E-Continuous Timelike Curves
In Section 1.4 we deﬁned what it meant for a smooth curve in M to be
“timelike” and “future- (or past-) directed”. For the deﬁnition of the topology
we propose to describe in the next section it is essential to extend these
notions to the class of curves in M that are E-continuous, but need not
have a velocity vector at each point. Thus, we let I denote a (nondegenerate)
interval in R (open, closed, or half-open) and consider a curve α : I →M
that is E-continuous (i.e., α−1(V ) is open in I for every E-open set V in M).
1 Its not-so-basic topological properties are quite another matter, however. Indeed, in many
topological ways, R4 is unique among the Euclidean spaces Rn (see, for example, [FL]).

A.2 E-Continuous Timelike Curves
281
Fix a t0 in I. We say that α is future-timelike at t0 if there exists a connected,
relatively open subset U of I containing t0 such that
t ∈U
and
t < t0 =⇒α(t) ≪α(t0)
and
t ∈U
and
t0 < t =⇒α(t0) ≪α(t).
(U is an interval which may contain one or both of the endpoints of I, if I
happens to have endpoints). Past-timelike at t0 is deﬁned similarly. α is said
to be future-timelike (resp., past-timelike) if it is future-timelike (resp., past-
timelike) at every t0 in I. Finally, α is timelike if it is either future-timelike
or past-timelike.
Any curve α :
I →M that is smooth has component functions rel-
ative to any admissible basis that are continuous as maps from I into R.
Since ME is homeomorphic to R4 with its product topology, such an α is
E-continuous (8.8 of [Wi]). According to Lemma 1.4.7, a smooth curve that
is timelike and future-directed in the sense of Section 1.4 is therefore also
future-timelike in our new sense. Of course, the same is true of smooth, time-
like and past-directed curves. However, any timelike polygon (which has no
velocity vector at its “joints”) can obviously be parametrized so as to become
either future-timelike or past-timelike, but is not “smooth-timelike”. Oddly
enough, an E-continuous curve can be timelike and smooth without being
smooth-timelike in the sense of Section 1.4. For example, if {ea} is an ad-
missible basis and if one deﬁnes α : R →M by α(t) = (sin t)e1 + te4, then
α is future-timelike and smooth, but α′(t) = (cos t)e1 + e4 which is null at
t = nπ, n = 0, ±1, ±2, . . . (see Figure A.2.1). This is unfortunate since
it complicates the physical interpretation of “E-continuous future-timelike”
somewhat. One would like to regard such a curve as the worldline of a mate-
rial particle which may be undergoing abrupt changes in speed and direction
(due, say, to collisions). Of course, having a null velocity vector at some point
would tend to indicate a particle momentarily attaining the speed of light and
this we prefer not to admit as a realistic possibility. One would seem forced
to accept a curve of the type just described as an acceptable model for the
worldline of a material particle only on the intervals between points at which
the tangent is null (notice that the situation cannot get much worse, i.e.,
the velocity vector of a smooth future-timelike curve cannot be null on an
interval, nor can it ever be spacelike).
We proceed now to derive a sequence of results that will be needed in the
next section.
Lemma A.2.1 Let {ea}4
a=1 be an admissible basis for M and α : I →
M an E-continuous timelike curve. If α is future-timelike, then x4(α(t)) is
increasing on I. If α is past-timelike, then x4(α(t)) is decreasing on I. In
particular, if α is timelike, it is one-to-one.

282
A Topologies For M
Fig. A.2.1
Proof:
Suppose α is future-timelike (the argument for α past-timelike is
similar). Let t0, t1 ∈I with t0 < t1. We show that x4(α(t0)) < x4(α(t1)).
Suppose, to the contrary, that x4(α(t0)) ≥x4(α(t1)). x4(α(t)) is a real-valued
continuous (8.8 of [Wi]) function on the closed bounded interval [t0, t1] and
so achieves a maximum value at some t2 ∈[t0, t1]. Since α is future-timelike
at t0 and p ≪q implies x4(p) < x4(q), x4(α(t)) must increase immediately
to the right of t0 so t2 > t0. But x4(α(t2)) > x4(α(t0)) ≥x4(α(t1)) implies
t2 < t1 so t2 ∈(t0, t1). But α is future-timelike at t2 and so x4(α(t)) must
increase immediately to the right of t2 and this contradicts the fact that, on
[t0, t1], x4(α(t)) has a maximum at t2.
■
Next we show that Theorem 1.4.6 remains true if “smooth future-directed
timelike” is replaced with “E-continuous future-timelike”.
Theorem A.2.2 Let p and q be two points in M. Then p ≪q if and only
if there exists an E-continuous future-timelike curve α : [a, b] →M such that
α(a) = p and α(b) = q.
Proof:
The necessity is clear from Theorem 1.4.6. For the suﬃciency we
assume α : [a, b] →M is E-continuous future-timelike with α(a) = p and
α(b) = q. For each t in [a, b] we select a connected, relatively open subset
Ut of [a, b] containing t as in the deﬁnition of future-timelike at t. Then
{Ut : t ∈[a, b]} is an open cover of [a, b] so, by compactness (17.9 of [Wi]),
we may select a ﬁnite subcover U = {Ua, Ut1, . . . , Utn}.

A.2 E-Continuous Timelike Curves
283
By deﬁnition, a ∈Ua. Moreover, if b ∈Ua, then α(a) ≪α(b) and we are
done. If b /∈Ua, then the right-hand endpoint s0 of Ua is less than or equal
to b and not in Ua.
Select a Uti in U such that s0 ∈Uti. Then Uti ̸= Ua, but Ua ∩Uti ̸= ∅.
Select a T0 ∈Ua ∩Uti such that a < T0 < ti. Now, if b ∈Uti, then α(a) ≪
α(T0) ≪α(ti) ≪α(b) and we are done. Otherwise, the right-hand endpoint
s1 of Uti is less than b and not in Uti. Repeat the process, beginning at T0
rather than a. Select a Utj in U with s1 ∈Utj. Observe that Utj ̸= Ua and
Utj ̸= Uti since s1 is in neither Ua nor Uti. However, Uti ∩Utj ̸= ∅. Select T1
as above and continue to repeat the process. Since U is ﬁnite and covers [a, b]
the procedure must terminate in a ﬁnite number of steps with α(a) ≪α(b)
as required.
■
Next we prove that an E-continuous curve that is timelike at each point
in an interval must have the same causal character (future-timelike or past-
timelike) at each point. In fact, we prove more.
Lemma A.2.3 Let α : I →M be an E-continuous curve. If α is timelike
at each t0 in the interior Int I of I, then α is timelike.
Proof:
We ﬁrst show that α is either future-timelike at each t0 ∈Int I or
past-timelike at each t0 ∈Int I. The procedure will be to show that the set
S = {t0 ∈Int I : α is future-timelike at t0} is both open and closed in Int
I and so, since Int I is connected, is either ∅or all of Int I (26.1 of [Wi]).
Suppose then that S ̸= ∅. Let t0 ∈S and select some U ⊆Int I as in the
deﬁnition of “future-timelike at t0”. We show that α is future-timelike at
each t in U so t0 ∈U ⊆S and, since t0 ∈S was arbitrary, conclude that S
is open. First suppose there were a t1 > t0 in U at which α is past-timelike.
Exercise A.2.1 Relative to an admissible basis consider x4(α(t)) on [t0, t1]
and argue as in the proof of Lemma A.2.1 to derive a contradiction.
A similar argument shows that there can be no t1 < t0 in U at which α is
past-timelike. Thus, U ⊆S as required so S is open. The same argument
shows that {t0 ∈Int I : α is past-timelike at t0}, which is the complement of
S in Int I, is open in Int I so S is open and closed in Int I as required. Thus,
either S = ∅or S = Int I so α is either past-timelike at every t0 ∈Int I or
future-timelike at every t0 ∈Int I.
Now we show that if I has endpoints then α must be timelike and have the
same causal character at these points that it has on Int I. The arguments are

284
A Topologies For M
similar in all cases so we suppose α is future-timelike on Int I and that t = a is
the left-hand endpoint of I. We show that α is future-timelike at a. Let U be
a connected, relatively open subset of I containing a, but not containing the
right-hand endpoint of I (should I happen to have a right-hand endpoint).
Let t1 > a be in U and set q = α(a) and r = α(t1). We show that q ≪r.
Since (a, t1) ⊆IntI, it follows from Theorem A.2.2 that α(a, t1) ⊆C−
T (r).
Since a is in the closure of (a, t1) in I and α is E-continuous, q = α(a) is
in ClEC−
T (r) (7.2 of [Wi]). But ClEC−
T (r) = C−
T (r) ∪C−
N(r) ∪{r} so q must
be in one of these sets. q = r is impossible since, for every t in Int I with
t < t1, x4(α(t)) < x4(r) so x4(q) ≤x4(α(t)) < x4(r). We show now that q
must be in C−
T (r). Select a t2 ∈(a, t1) and set s = α(t2). Then s ∈C−
T (r)
and, as above, q ∈ClEC−
T (s) and q = s is impossible so either q ∈C−
T (s)
or q ∈C−
N(s). But then r −s is timelike and future-directed and s −q is
either timelike or null and future-directed. Lemma 1.4.3 then implies that
r −q = (r −s) + (s −q) is timelike and future-directed, i.e., q ∈C−
T (r), so
q ≪r. Since there are no points in U less than a, α is future-timelike at a.
■
A.3 The Path Topology
The E-topology on M has the following property: For any E-continuous
timelike curve α : I →M, the image α(I) inherits, as a subspace of ME,
the ordinary Euclidean topology. The path topology (or P-topology) is the
ﬁnest topology on M that has this property (i.e., which gives the familiar
notion of “nearby” to events on a continuous timelike worldline). Speciﬁcally,
a subset V of M is P-open if and only if for every E-continuous timelike curve
α : I →M there exists an E-open subset U of M such that
α(I) ∩V = α(I) ∩U,
which we henceforth abbreviate α ∩V = α ∩U.
Exercise A.3.1 Show that the collection of all such sets V does, indeed,
form a topology for M (3.1 of [Wi]).
Obviously, any E-open set is P-open so that the P-topology is ﬁner than (3.1
of [Wi]) the E-topology. It is strictly ﬁner by virtue of:
Lemma A.3.1 For each x in M and ε > 0 let
C(x) = C−
T (x) ∪C+
T (x) ∪{x}
and
N P
ε (x) = C(x) ∩N E
ε (x).
Then C(x) and N P
ε (x) are P-open, but not E-open (see Figure A.3.1).

A.3 The Path Topology
285
Fig. A.3.1
Proof:
Neither set contains an N E
δ (x) so they both fail to be E-open. Now,
let α : I →M be an E-continuous timelike curve. If α goes through x, then
α(I) is entirely contained in C(x) by Theorem A.2.2 so α ∩C(x) = α ∩M.
If α does not go through x, then α ∩C(x) = α ∩

C−
T (x) ∪C+
T (x)

. In either
case α ∩C(x) = α ∩U for some E-open set U in M so C(x) is P-open. But
then N P
ε (x) is the intersection of two P-open sets and so is P-open.
■
M endowed with the P-topology is denoted MP and we now show that the
sets N P
ε (x) form a base (5.1 of [Wi]) for MP .
Theorem A.3.2 The sets N P
ε (x) for x ∈M and ε > 0 form a base for the
open sets in MP .
Proof:
Let V ⊆M be P-open and x ∈V . We must show that there exists
an ε > 0 such that N P
ε (x) ⊆V . We assume that no such ε exists and produce
an E-continuous timelike curve α such that α∩V cannot be written as α∩U
for any E-open set U and this is, of course, a contradiction.
We begin with N P
1 (x) which, by assumption, is not contained in V . Since
no N P
ε (x) is contained in V one or the other of C+
T (x) ∩N P
1 (x) or C−
T (x) ∩
N P
1 (x) (or both) must contain an inﬁnite sequence {x1, x2, . . .} of points not
in V which E-converges to x. Since the proof is the same in both cases we
assume that this sequence is in C+
T (x) ∩N P
1 (x). We select a subsequence
{xni}∞
i=0 as follows: Let xn0 = x1. Since x ∈C−
T (xn0) we may select a δ1 > 0
such that N E
δ1(x) ⊆C−
T (xn0) (see Figure A.3.2). Let ε1 = min{δ1, 1/2}. Select
an xn1 in the sequence which lies in N P
ε1(x). Then x ≪xn1 ≪xn0. Repeat
the procedure. Since x ∈C−
T (xn1) there exists a δ2 > 0 such that N E
δ2(x) ⊆
C−
T (xn1). Let ε2 = min{δ2, 1/22} and select an xn2 in the sequence which lies

286
A Topologies For M
Fig. A.3.2
in N E
ε2(x). Then x ≪xn2 ≪xn1 ≪xn0. Continuing inductively we construct
a subsequence {xn0, xn1, xn2, . . .} of {xn} such that
x ≪· · · ≪xni ≪· · · ≪xn2 ≪xn1 ≪xn0
and {xni}∞
i=0 E-converges to x. Now deﬁne ˆα : (0, 1] →M as follows: On
 1
2, 1

, ˆα is a linear parametrization of the future-timelike segment from
xn1 to xn0. On
 1
3, 1
2

, ˆα is a linear parametrization of the future-timelike
segment from xn2 to xn1, and so on. Then ˆα is obviously E-continuous and
future-timelike. Since the xni E-converge to x we can deﬁne an E-continuous
curve α : [0, 1] →M by
α(t) =
. ˆα(t),
0 < t ≤1
x,
t = 0;
α is also future-timelike by Lemma A.2.3.
Now, suppose α∩V = α∩U for some E-open set U. Since the xni are not in
V, xni̸∈α∩V for each i so xni̸∈α∩U for each i. Thus, {xni} ⊆M−(α∩U) =
(M−α)∪(M−U). But xni ∈α so we must have xni ∈M−U. But M−U
is E-closed and {xni} E-converges to x so x ∈M −U, i.e., x ̸∈U. Thus,
x ̸∈α ∩U = α ∩V and this is a contradiction since x is in both α and V .
■
A number of basic topological properties of MP follow immediately from
Theorem A.3.2. Since the N P
ε (x) with ε rational form a local base at x, MP is
ﬁrst countable (4.4(b) of [Wi]). Since P-open sets have nonempty E-interior,
MP is separable (5F of [Wi]). If R is a light ray in M and x ∈R, then

A.3 The Path Topology
287
any N P
ε (x) intersects R only at x so, as a subspace of MP , R is discrete
(4G of [Wi]). R is also P-closed since it is, in fact, E-closed and the P-
topology is ﬁner than the E-topology. Being separable and containing such
large closed discrete subspaces prevents MP from being normal (15.1 of [Wi])
since the Tietze Extension Theorem (15.8 of [Wi]) would require that all the
continuous real-valued functions on any closed subspace extend to MP , but
an uncountable closed discrete subspace has too many. In fact, it follows
easily from our next lemma that MP is not even regular (14.1 of [Wi]) and
therefore certainly not normal (although it is Hausdorﬀsince any two distinct
points are contained in disjoint basic open sets).
Lemma A.3.3 The closure in MP of N P
ε (x) is ClE

NP
ε (x)

−(bdyE

N E
ε (x)

∩bdyE(C(x))

(see Figure A.3.3).
Proof:
Since P is ﬁner than E, ClP (A) ⊆ClE(A) for any subset A
of M. Moreover, the points in bdyE

N E
ε (x)

∩bdyE(C(x)) are not in
ClP

N P
ε (x)

since, if y is such a point, N P
ε/2(y) does not intersect N P
ε (x)
(the null cone at y is tangent to the surface of the Euclidean ball N E
ε (x)
at such a y) (see Figure A.3.4.). Thus, ClP

N P
ε (x)

⊆ClE

N P
ε (x)

−

bdyE

N E
ε (x)

∩bdyE(C(x))

. But the reverse containment is also clear
since, if y is in the set on the right-hand side, every N P
δ (y) intersects N P
ε (x).
■
From Lemma A.3.3 it is clear that MP is not regular since no N P
ε (x)
contains a ClP

N P
δ (x)

. Moreover, since any P-compact set is necessarily
E-compact and no ClP

N P
ε (x)

is E-compact (or even E-closed) we ﬁnd
that no point in MP has a compact neighborhood. In particular, MP is not
locally compact (18.1 of [Wi]).
Fig. A.3.3
Exercise A.3.2 Show that MP is not countably compact (17.1 of [Wi]),
Lindel¨of (16.5 of [Wi]), or second countable (16.1 of [Wi]).

288
A Topologies For M
In order to investigate the connectivity properties of MP and for other pur-
poses as well we will need to determine the P-continuous curves in M.
Lemma A.3.4 Let I be a nondegenerate interval in R and α : I →M
a curve. Then:
1. If α is P-continuous, then it is E-continuous.
2. If α is timelike, then it is P-continuous.
Proof:
(1) Let U be an E-open set in M. Then U is P-open. Since α is
P-continuous, α−1(U) is open in I so α is E-continuous.
(2) Assume α is timelike (and therefore E-continuous by deﬁnition).
Let V be a P-open set in M. We show that α−1(V ) is open in I. By deﬁnition
of the P-topology there exists an E-open set U in M such that α ∩V = α ∩U.
Thus, α−1(V ) = α−1(α ∩V ) = α−1(α ∩U) = α−1(U)
which is open in I since α is E-continuous.
■
Fig. A.3.4
It is not quite true that a P-continuous curve must be timelike, but almost.
We deﬁne a Feynman path2 in M to be an E-continuous curve α : I →M
with the property that for each t0 in I there exists a connected relatively
open subset U of I containing t0 such that
α(U) ⊆C(α(t0)).
Observe that, since C(α(t0)) is a P-open subset of M, any P-continuous curve
in M is necessarily a Feynman path. We show that the converse is also true.
2 Being essentially timelike, but zigzaging with respect to time orientation, they resemble
the Feynman track of an electron.

A.3 The Path Topology
289
Theorem A.3.5 A curve α : I →M is P-continuous if and only if it is a
Feynman path.
Proof:
All that remains is to prove that a Feynman path α : I →M is
P-continuous. Fix a t0 ∈I. We show that α is P-continuous at t0. For this
let N P
ε (α(t0)) be a basic P-neighborhood of α(t0). Now, α−1 
N P
ε (α(t0))

=
α−1 
N E
ε (α(t0)) ∩C(α(t0))

= α−1 
NE
ε (α(t0))

∩α−1(C(α(t0))). Since α is
a Feynman path there exists a connected, relatively open subset U1 of I con-
taining t0 such that U1 is contained in α−1(C(α(t0))). Since α is E-continuous
by deﬁnition, there exists a connected, relatively open subset U2 of I con-
taining t0 such that U2 ⊆α−1 
N E
ε (α(t0))

. Thus, if U = U1 ∩U2 we have
t0 ∈U ⊆α−1 
N P
ε (α(t0))

so α(U) ⊆N P
ε (α(t0)) and α is P-continuous at t0.
■
Since any two points in NP
ε (x) can be joined by a Feynman path (in fact,
by a timelike segment or two such segments “joined” at x), MP is locally
pathwise connected (27.4 of [Wi]). Moreover, since any straight line in M
can be approximated by a Feynman path, MP is also pathwise connected
(27.1 of [Wi]) and therefore connected (27.2 of [Wi]).
Our next objective is to show that a P-homeomorphism h : MP →MP
of MP onto itself carries timelike curves onto timelike curves, i.e., that α :
I →M is timelike if and only if h ◦α :
I →M is timelike. We prove
this by characterizing timelike curves entirely in terms of set-theoretic and
P-topological notions that are obviously preserved by P-homeomorphisms.
Theorem A.3.6 A curve α : I →M is timelike if and only if the following
two conditions are satisﬁed:
1. α is P-continuous and one-to-one
2. For every t0 in I there exists a connected, relatively open subset U of I
containing t0 and a P-open neighborhood V of α(t0) in M such that:
(a) α(U) ⊆V
(b) Whenever t0 is in the interior of I and a and b are in U and satisfy
a < t0 < b, then every P-continuous curve in V joining α(a) and α(b)
passes through α(t0).
Proof:
First assume α is timelike. Since the proofs are the same in the
two cases we will assume that α is future-timelike. Then α is P-continuous
by Lemma A.3.4(2) and one-to-one by Lemma A.2.1 so (1) is satisﬁed. Now
ﬁx a t0 in I and select U ⊆I as in the deﬁnition of future-timelike at t0.
Let V = C(α(t0)). Then V is a P-open neighborhood of α(t0) with α(U) ⊆
V so part (a) of (2) is satisﬁed. Next suppose t0 is in the interior of U
and let a and b be in U with a < t0 < b. Then α(a) ∈C−
T (α(t0)) and
α(b) ∈C+
T (α(t0)). Suppose γ :
[c, d] →M is a P-continuous curve in V
with γ(c) = α(a) and γ(d) = α(b). By P-continuity, γ[c, d] is a connected

290
A Topologies For M
subspace of MP (26.3 of [Wi]). But if α(t0) were not in the image of γ, then
γ[c, d] =

γ[c, d] ∩C−
T (α(t0))

∪

γ[c, d] ∩C+
T (α(t0))

would be a disconnection
(26.1 of [Wi]) of γ[c, d]. Thus, (b) of (2) is also satisﬁed.
Conversely, suppose α :
I →M satisﬁes (1) and (2). Then α is E-
continuous by Lemma A.3.4. We show that α is timelike at each t0 in the
interior of I and appeal to Lemma A.2.3. Let U and V be as in (2). Assume
without loss of generality that V is a basic open neighborhood N P
ε (α(t0)).
Let U −= {t ∈U : t < t0} and U + = {t ∈U : t > t0}. Select a ∈U −and
b ∈U +. Since α is one-to-one, α(a) ̸= α(t0) and α(b) ̸= α(t0) so α(a) and
α(b) both lie in C−
T (α(t0)) ∪C+
T (α(t0)). Assuming that α(a) is in C−
T (α(t0))
we show that α is future-timelike at t0 (if α(a) ∈C+
T (α(t0)) the same proof
shows that α is past-timelike at t0). If α(b) were also in C−
T (α(t0)) we could
construct a Feynman path from α(a) to α(b) that is contained entirely in
N P
ε (α(t0)) ∩C−
T (α(t0)). But such a Feynman path would be a P-continuous
curve in V joining α(a) and α(b) which could not go through α(t0), thus
contradicting part (b) of (2). Thus, α(b) ∈C+
T (α(t0)). We conclude that
α(U −) ∩C−
T (α(t0)) ̸= ∅and α(U +) ∩C+
T (α(t0)) ̸= ∅. Since α is one-to-one,
α(t0) /∈α(U −) and α(t0) /∈α(U +). But α is P-continuous so α(U−) and
α(U +) are both connected subspaces of MP and so we must have α(U −) ⊆
C−
T (α(t0)) and α(U +) ⊆C+
T (α(t0)), i.e., α is future-timelike at t0.
■
Corollary A.3.7 If h : MP →MP is a P-homeomorphism of MP onto
itself, then a curve α : I →M is timelike if and only if h ◦α : I →M is
timelike.
Proof:
Conditions (1) and (2) of Theorem A.3.6 are both obviously pre-
served by P-homeomorphisms.
■
Corollary A.3.8 If h : MP →MP is a P-homeomorphism of MP onto
itself, then h carries CT(x) bijectively onto CT (h(x)) for every x in M.
Exercise A.3.3 Prove Corollary A.3.8.
■
We wish to show that a P-homeomorphism either preserves or reverses the
order ≪. First, the local version.
Lemma A.3.9 Let h : MP →MP be a P-homeomorphism and x a ﬁxed
point in M. Then either
1. h

C−
T (x)

= C−
T (h(x)) and h

C+
T (x)

= C+
T (h(x)) or
2. h

C−
T (x)

= C+
T (h(x)) and h

C+
T (x)

= C−
T (h(x)).
Proof:
Suppose there exists a p in C+
T (x) with h(p) ∈C+
T (h(x)) (the argu-
ment is analogous if there exists a p in C+
T (x) with h(p) ∈C−
T (h(x))).

A.3 The Path Topology
291
Fig. A.3.5
Exercise A.3.4 Show that h

C+
T (x)

⊆C+
T (h(x)).
Now let q be in C−
T (x). We claim that h(q) is in C−
T (h(x)). Let α and
β be past-timelike curves from p to x and x to q respectively. Let γ be
the past-timelike curve from p to q consisting of α followed by β. Then, by
Corollary A.3.7, h ◦α, h ◦β and h ◦γ are all time-like. By Lemma A.2.3,
h ◦γ is either everywhere past-timelike or everywhere future-timelike. But
h◦α is past-timelike since h(x) ≪h(p) and h◦γ initially coincides with h◦α
so it too must be past-timelike. By Theorem A.2.2, h(q) ≪h(x), i.e., h(q) ∈
C−
T (h(x)). As in Exercise A.3.4 it follows that h

C−
T (x)

⊆C−
T (h(x)). But
Corollary A.3.8 then gives h

C+
T (x)

= C+
T (h(x)) and h

C−
T (x)

= C−
T (h(x)).
■
With this we can now prove our major result.
Theorem A.3.10 If h : MP →MP is a P-homeomorphism of MP onto
itself, then h either preserves or reverses the order ≪, i.e., either
1. x ≪y if and only if h(x) ≪h(y) or
2. x ≪y if and only if h(y) ≪h(x).
Proof:
Let S = {x ∈M :
h preserves
≪
at x}. We will show that
S is open in MP . The proof that MP −S is open in MP is the same so
connectivity of MP implies that either S = ∅or S = M. Suppose then that
S ̸= ∅and select an arbitrary x ∈S. Then C(x) is a P-open set containing
x. We show that C(x) ⊆S and conclude that S is open. To see this suppose
p ∈C+
T (x) ⊆C(x) (the proof for p ∈C−
T (x) is similar). Now, x ∈S implies
h(p) ∈C+
T (h(x)) (see Figure A.3.6.). By Lemma A.3.9, h

C+
T (p)

equals ei-
ther C+
T (h(p)) or C−
T (h(p)). But the latter is impossible since C+
T (p) ⊆C+
T (x)
implies h

C+
T (p)

⊆h

C+
T (x)

= C+
T (h(x)). Thus, h

C+
T (p)

= C+
T (h(p)) so p
is in S as required.
■

292
A Topologies For M
Fig. A.3.6
From Theorem A.3.10 and Exercise 1.6.3 we conclude that if h : MP →MP
is a P-homeomorphism, then either h or −h is a causal automorphism.
Exercise A.3.5 Show that if h : M →M is a causal automorphism, then
h and −h are both P-homeomorphisms. Hint: Zeeman’s Theorem 1.6.2.
Now, if X is an arbitrary topological space the set H(X) of all homeomor-
phisms of X onto itself is called the homeomorphism group of X (it is closed
under the formation of compositions and inverses and so is indeed a group
under the operation of composition). If G is a subset of H(X) we will say
that G generates H(X) if every homeomorphism of X onto itself can be writ-
ten as a composition of elements of G. We now know that H(MP ) consists
precisely of the maps ±h where h is a causal automorphism and Zeeman’s
Theorem 1.6.2 describes all of these.
Theorem A.3.11 The homeomorphism group H(MP ) of MP is gener-
ated by translations, dilations and (not necessarily orthochronous) orthogonal
transformations.
Modulo translations and nonzero scalar multiplications, H(MP ) is essentially
just the Lorentz group L.

Appendix B
Spinorial Objects
B.1 Introduction
Here we wish to examine in some detail the mathematical origin and physical
signiﬁcance of the “essential 2-valuedness” of spinors, to which we alluded
in Section 3.5. A genuine understanding of this phenomenon depends on
topological considerations of a somewhat less elementary nature than those
involved in Appendix A. Thus, in Section B.3, we must assume a familiarity
with point-set topology through the construction of the fundamental group
and its calculation for the circle (see Sections 32–34 of [Wi] or Sections 1–4 of
[G]). The few additional homotopy-theoretic results to which we must appeal
can all be found in Sections 5–6 of [G].
As we left it in Chapter 3, Section 5, the situation was as follows: Each
nonzero spin vector ξA uniquely determines a future-directed null vector v
and a 2-dimensional plane F spanned by v and a spacelike vector w or-
thogonal to v. The pair (v, F) is called the null ﬂag of ξA, with v the
ﬂagpole and F the ﬂag. A phase change (rotation) ξA →eiθξA(θ ∈R) of
the spin vector ξA yields another spin vector with the same ﬂagpole v as
ξA, but whose ﬂag is rotated around this ﬂag pole by 2θ relative to the ﬂag
of ξA. The crucial observation is that if ξA undergoes a continuous rotation
ξA →eiθξA, 0 ≤θ ≤π, through π, then the end result of the rotation is a
new spin vector eiπξA = −ξA, but the same null ﬂag. Let us reverse our point
of view. Regard the null ﬂag (v, F) as a concrete geometrical representation
of the spin vector ξA in much the same way that a “directed line segment”
represents a vector in classical physics and Euclidean geometry. One then
ﬁnds oneself in the awkward position of having to concede that rotating this
geometrical object by 2π about some axis yields an object apparently indis-
tinguishable from the ﬁrst, but representing, not ξA, but −ξA. One might
seek additional geometrical data to append to the null ﬂag (as we added the
ﬂag when we found that the ﬂagpole itself did not uniquely determine ξA) in
order to distinguish the object representing ξA from that representing −ξA.
293

294
B Spinorial Objects
It is clear, however, that if “geometrical data” is to be understood in the
usual sense, then any such data would also be returned to its original value
after a rotation of 2π. The sign ambiguity in our geometrical representation
of spin vectors seems unavoidable, i.e., “essential”. Perhaps even more curi-
ous is the fact that a further rotation of the ﬂag by 2π (i.e., a total rotation
of 4π) corresponds to θ = 2π and so returns to us the original spin vector
ξA = ei(2π)ξA and the original null ﬂag.
This state of aﬀairs is quite unlike anything encountered in classical physics
or geometry. By analogy, one would have to imagine a “vector” and its geo-
metrical representation as a directed line segment with the property that, by
rotating the arrow through 2π about some axis one obtained the geometri-
cal representation of some other “vector”. But, of course, classical Euclidean
vector (and, more generally, tensor) analysis is built on the premise that this
cannot be the case. Indeed, a vector (tensor) is just a carrier of some repre-
sentation of the rotation group and the element of the rotation group corre-
sponding to rotation by 2π about any axis is the identity. This is, of course,
just a mathematical reﬂection of the conventional wisdom that rotating an
isolated physical system through 2π yields a system that is indistinguishable
from the ﬁrst.
B.2 The Spinning Electron and Dirac’s Demonstration
“Conventional wisdom” has not fared well in modern physics so it may come
as no surprise to learn that there are, in fact, physical systems at the sub-
atomic level whose state is altered by a rotation of the system through 2π
about some axis, but is returned to its orginal value by a rotation through
4π. Indeed, any of the elementary particles in nature classiﬁed as a Fermions
(electrons, protons, neutrons, neutrinos, etc.) possess what the physicists call
“half-integer spin” and, as a consequence, their quantum mechanical descrip-
tions (“wave functions”) behave in precisely this way (a beautifully lucid and
elementary account of the physics involved here is available in Volume III
of the Feynman Lectures on Physics [Fe]). That the spin state of an elec-
tron behaves in this rather bizarre way has been known for many years, but,
because of the way in which quantum mechanics decrees that physical infor-
mation be extracted from an object’s wave function, was generally thought
to have no observable consequences. More recently it has been argued that it
is possible, in principle, to construct devices in which this behavior under ro-
tation is exhibited on a macroscopic scale (see [[AS], [KO] and [M]). These
constructions, however, depend on a rather detailed understanding of how
electrons are described in quantum mechanics. Fortunately, Paul Dirac has
devised a remarkably ingenious demonstration involving a perfectly mundane
macroscopic physical system in which “something” in the system’s state is
altered by rotation through 2π, but returned to its original value by a 4π

B.2 The Spinning Electron and Dirac’s Demonstration
295
Fig. B.2.1
rotation. Next we describe the so-called “Dirac Scissors Problem” and, in the
next section, investigate the mathematics behind the phenomenon.
The demonstration involves a pair of scissors, a piece of (elastic) string
and a chair. Pass the string through one ﬁnger hole of the scissors, then
around one arm of the chair, then through the other ﬁngerhole and around
the other arm of the chair and then tie the two ends of the string together (see
Figure B.2.1). The scissors is now rotated about its axis of symmetry through
2π (one complete revolution). The strings become entangled and the problem
is to disentangle them by moving only the string, holding the scissors and
chair ﬁxed (the string needs to be elastic so it can be moved around these
objects, if desired). Try it! No amount of manuvering, simple or intricate,
will return the strings to their original, disentangled state. This, in itself, is
not particularly surprising perhaps, but now repeat the exercise, this time
rotating the scissors about its axis through two complete revolutions (4π).
The strings now appear even more hopelessly tangled, but looping the string
just once over the pointed end of the scissors (counterclockwise if that is the
way you turned the scissors) will return them to their original condition.
One is hard-pressed not to be taken aback by the result of this little
game, but, in fact, there are even more dramatic demonstrations of the same
phenomenon. Imagine a cube (with its faces numbered, or painted diﬀerent
colors, so that one can keep track of the rotations it experiences). Connect
each corner of the cube to the corresponding corner of a room with elastic
string (see Figure B.2.2). Rotate the cube by 2π about any axis. The strings
become tangled and no manipulation of the strings that leaves the cube (and
the room) ﬁxed will untangle them. Rotate by another 2π about the same axis
for a total rotation of 4π and the tangles apparently get worse, but a carefully
chosen motion of the strings (alone) will return them to their original state
(the appropriate sequence of manuvers is shown in Figure 41.6 of [MTW]).

296
B Spinorial Objects
Fig. B.2.2
In each of these situations there is clearly “something diﬀerent” about the
state of the system when it has undergone a rotation of 2π and when it has
been rotated by 4π. Observe also that, in each case, the “system” is more
than just an isolated pair of scissors or a cube, but includes, in some sense,
the way in which that object is “connected” to its surroundings. In the next
section we return to mathematics to show how all of this can be said precisely
and, indeed, how the mathematics itself might have suggested the possibility
of such phenomena and the relevance of spinors to their description.
B.3 Homotopy in the Rotation and Lorentz Groups
We begin by establishing some notation and terminology and brieﬂy review-
ing some basic results related to the notion of “homotopy” in topology (a
good, concise source for all of the material we will need is [G], Sections 1–6).
Much of what we have to say will be true in an arbitrary topological space,
but this much generality is not required and tends to obscure fundamental
issues with tiresome technicalities. For this reason we shall restrict our at-
tention to the category of “connected topological manifolds”. A Hausdorﬀ
topological space X is called an (n-dimensional) topological manifold if each
x ∈X has an open neighborhood in X that is homeomorphic to an open
set in Rn (18.3 of [Wi] or (6.8) of [G]). A path in X is a continuous map
α : [0, 1] →X. If α(0) = x0 and α(1) = x1, then α is a path from x0 to x1
in X and X is path connected if such a path exists for every pair of points
x0, x1 ∈X (27.1 of [Wi]).
Exercise B.3.1 Show that a topological manifold X that is connected (26.1
of [Wi]) is necessarily path connected. Hint: Fix an arbitrary x0 ∈X and
show that the set of all x1 ∈X for which there is a path in X from x0 to x1
is both open and closed.

B.3 Homotopy in the Rotation and Lorentz Groups
297
Henceforth, “space” will mean “connected topological manifold”.
Let α0 and α1 be two paths in X from x0 to x1. We say that α0 and α1
are (path) homotopic (with endpoints ﬁxed) if there exists a continuous map
H : [0, 1] × [0, 1] →X, called a homotopy from α0 to α1, which satisﬁes
H(s, 0) = α0(s),
H(s, 1) = α1(s),
H(0, t) = x0,
H(1, t) = x1
for all s and t in [0, 1]. In this case we write α0 ≃α1. For each t in [0,
1], αt(s) = H(s, t) deﬁnes a path in X from x0 to x1 and, intuitively, one
regards H as providing a “continuous deformation” of α0 into α1 through the
family {αt : t ∈[0, 1]} of paths. ≃is an equivalence relation on the set of all
paths from x0 to x1 and we denote the equivalence class of a path α by [α].
The inverse of a path α from x0 to x1 is the path α−1 from x1 to x0 deﬁned
by α−1(s) = α(1 −s). One veriﬁes that α0 ≃α1 implies α−1
0
≃α−1
1
so one
may deﬁne the inverse of a homotopy equivalence class by [α]−1 = [α−1]. If
α is a path from x0 to x1 in X and β is a path from x1 to x2 in X, then the
product path βα from x0 to x2 is deﬁned by
(βα)(s) =
) α(2s),
0 ≤s ≤1
2
β(2s −1),
1
2 ≤s ≤1.
Again, α0 ≃α1 and β0 ≃β1 imply β0α0 ≃β1α1 so one may deﬁne the
product of the homotopy equivalence classes [α] and [β] by [β][α] = [βα],
provided the initial point of all the paths in [β] coincides with the terminal
point of all the paths in [α]. A loop at x0 is a path from α(0) = x0 to
α(1) = x0. Then α−1 is also a loop at x0. Moreover, if β is another loop at
x0, then βα is deﬁned and is also a loop at x0. Letting
π1(X, x0) = {[α] : α is a loop at x0},
one ﬁnds that the operations [α]−1 = [α−1] and [β][α] = [βα] give π1(X, x0)
the structure of a group with identity element [x0], where we are here using x0
to designate also the constant (or trivial) loop at x0 deﬁned by x0(s) = x0 for
all s in [0, 1]. π1(X, x0) is called the fundamental group of X at x0. If x0 and
x1 are any two points in X and γ is a path in X from x1 to x0 (guaranteed to
exist by Exercise B.3.1), then [α] →[γ−1αγ] is an isomorphism of π1(X, x0)
onto π1(X, x1). For this reason one generally writes π1(X) for any one of the
isomorphic groups π1(X, x), x ∈X, and calls π1(X) the fundamental group
of X. Obviously, homeomorphic spaces have the same (that is, isomorphic)
fundamental groups. More generally, any two homotopically equivalent ((3.6)
of [G]) spaces have the same fundamental groups.

298
B Spinorial Objects
A space is said to be simply connected if its fundamental group is
isomorphic to the trivial group, i.e., if every loop is homotopic to the trivial
loop (somewhat loosely one says that “every closed curve can be shrunk to
a point”). Any Euclidean space Rn is simply connected ((3.2) of [G]), as is
the n-sphere Sn = {(x1, . . . , xn+1) ∈Rn+1 : (x1)2 + · · · + (xn+1)2 = 1} for
any n ≥2 (see Exercise B.3.5 and (4.13) of [G]). For n = 1, however, the
situation is diﬀerent. Indeed, the fundamental group of the circle, π1(S1), is
isomorphic to the additive group Z of integers ((4.4) of [G]). Essentially, a
loop in S1 is characterized homotopically by the (integer) number of times it
wraps around the circle (positive in one direction and negative in the other).
Exercise B.3.2 Let X and Y be two topological manifolds of dimensions n
and m respectively. Show that X × Y , provided with the product topology,
is a topological manifold of dimension n + m.
It is not diﬃcult to show ((4.8) of [G]) that the fundamental group of a
product X ×Y is isomorphic to the direct product of the fundamental groups
of X and Y , i.e., π1(X ×Y ) ∼= π1(X)×π1(Y ). In particular, the fundamental
group of the torus S1 × S1 is Z × Z.
In order to calculate several less elementary examples and, in the process,
get to the heart of the connection between homotopy and spinorial objects,
we require the notion of a “universal covering manifold”. As motivation let
us consider again the circle S1. This time it is convenient to describe S1 as
the set of all complex numbers of modulus one, i.e., S1 = {z ∈C : z¯z = 1}.
Deﬁne a map p : R →S1 by p(θ) = e2πθi = cos(2πθ) + i sin(2πθ). Observe
that p is continuous, carries 0 ∈R onto 1 ∈S1 and, in eﬀect, “wraps” the
real line around the circle. Notice also that each z ∈S1 has a neighborhood
U in S1 with the property that p−1(U) is a disjoint union of open sets in R,
each of which is mapped homeomorphically by p onto U (this is illustrated
for z = 1 in Figure B.3.1). In particular, the “ﬁber” p−1(z) above each z ∈S1
is discrete. Now let us consider a homeomorphism φ of R onto itself which
“preserves the ﬁbers of p”, i.e., satisﬁes p ◦φ = p, so that r ∈p−1(z) implies
φ(r) ∈p−1(z). We claim that such a homeomorphism is uniquely determined
by its value at 0 ∈R (or at any other single point in R), i.e., that if φ1 and φ2
are two p-ﬁber preserving homeomorphisms of R onto R and φ1(0) = φ2(0),
then φ1 = φ2. To see this let E = {e ∈R : φ1(e) = φ2(e)}. Then E ̸= ∅
since 0 ∈E and, by continuity of φ1 and φ2, E is closed in R. Since R is
connected the proof will be complete if we can show that E is open. Thus,
let e be a point in E so that φ1(e) = φ2(e) = r for some r ∈R. Notice
that p(φ1(e)) = p(r) and p(φ1(e)) = p(e) imply that p(e) = p(r). Now select
open neighborhoods Ve and Vr of e and r which p maps homeomorphically
onto a neighborhood U of p(e) = p(r). Let V = Ve ∩φ−1
1 (Vr) ∩φ2
−1(Vr).
Then V is an open neighborhood of e contained in Ve and with φ1(V ) ⊆Vr
and φ2(V ) ⊆Vr. For each v ∈V , p(φ1(v)) = p(φ2(v)) since both equal p(v).
But φ1(v), φ2(v) ∈Vr and, on Vr, p is a homeomorphism so φ1(v) = φ2(v).
Thus, V ⊆E so E is open. We ﬁnd then that the homeomorphisms of R that

B.3 Homotopy in the Rotation and Lorentz Groups
299
preserve the ﬁbers of p are completely determined by their values at 0. Since
the elements in a single ﬁber p−1(z) clearly diﬀer by integers, the value of a
p-ﬁber preserving homeomorphism of R at 0 is an integer.
Fig. B.3.1
Exercise B.3.3 For each integer n let φn : R →R be the translation of R
by n, i.e., φn(y) = y + n for each y ∈R. Show that the set C of p-ﬁber pre-
serving homeomorphisms of R is precisely {φn : n ∈Z}. Observe, moreover,
that φn◦φm = φn+m so, as a group under the operation of composition, C is
isomorphic to the additive group Z of integers, i.e., to π1(S1).
Distilling the essential features out of this last example leads to the fol-
lowing deﬁnitions and results. Let X be a connected topological manifold.
A universal covering manifold for X consists of a pair ( ˜X, p), where ˜X is
a simply connected topological manifold and p :
˜X →X is a continuous
surjection (called the covering map) with the property that every x ∈X has
an open neighborhood U such that p−1(U) is a disjoint union of open sets in
˜X, each of which is mapped homeomorphically onto U by p. Every connected
topological manifold has a universal covering manifold ( ˜X, p) ((6.8) of [G])
that is essentially unique in the sense that if ( ˜X′, p′) is another, then there
exists a homeomorphism ψ of ˜X′ onto ˜X such that p◦ψ = p′ ((6.4) of [G]). A
homeomorphism φ of ˜X onto itself that preserves the ﬁbers of p, i.e., satisﬁes
p◦φ = p, is called a covering transformation and the collection C of all such
is a group under composition. Moreover, C is isomorphic to π1(X) ((5.8) of
[G]). C is often easier to contend with than π1(X) and we will now use it to
compute the examples of real interest to us.
We shall construct these examples “backwards”, beginning with a space ˜X
that will eventually be the universal covering manifold of the desired example

300
B Spinorial Objects
X, which is deﬁned as a quotient (9.1 of [Wi]) of ˜X. First take ˜X to be the
2-sphere S2 = {(x1, x2, x3) ∈R3 :
(x1)2 + (x2)2 + (x3)2 = 1} with the
topology it inherits as a subspace of R3.
Exercise B.3.4 Show that S2 is a (Hausdorﬀ, 2-dimensional, connected,
compact) topological manifold. Hint: Show, for example, that, on the upper
hemisphere {(x1, x2, x3) ∈S2 : x3 > 0}, the projection map (x1, x2, x3) →
(x1, x2) is a homeomorphism onto the unit disc (x1)2 + (x2)2 < 1.
Exercise B.3.5 Show that Sn is a (Hausdorﬀ, n-dimensional, connected,
compact) topological manifold for any n ≥1.
Now deﬁne an equivalence relation ∼on S2 by identifying antipodal points,
i.e., if y, z ∈S2, then y ∼z if and only if z = ±y. Let [y] denote the
equivalence class of y, i.e., [y] = {y, −y}, and denote by RP 2 the set of all
equivalence classes. Deﬁne p :
S2 →RP 2 by p(y) = [y] for every y ∈S2
and provide RP 2 with the quotient topology determined by p (i.e., U ⊆RP 2
is open if and only if p−1(U) is open in S2). RP 2 is then called the real
projective plane.
Exercise B.3.6 Show that RP 2 is a (Hausdorﬀ, 2-dimensional, connected,
compact) topological manifold.
Now, since S2 is simply connected and p : S2 →RP 2 clearly satisﬁes the
deﬁning condition for a covering map and since universal covering manifolds
are unique we conclude that
<
RP
2 ∼= S2.
But then π1(RP 2) is isomorphic to the group of p-ﬁber preserving home-
omorphisms φ :
S2 →S2 of S2. We claim that this group contains pre-
cisely two elements, namely, the identity map (φ0(y) = y for every y ∈S2)
and the antipodal map (φ1(y) = −y for every y ∈S2). To see this ob-
serve that the ﬁbers of p are just pairs of antipodal points {y, −y} so such
a φ must, for each y ∈S2, satisfy either φ(y) = y or φ(y) = −y and so
S2 = {y ∈S2 : φ(y) = y} ∪{y ∈S2 : φ(y) = −y}. Since both of these sets
are obviously closed, connectivity of S2 implies that one is ∅and the other
is S2 as required. Thus, π1(RP 2) has precisely two elements and so must be
isomorphic to the group of integers mod 2, i.e.,
π1(RP 2) ∼= Z2.
It will be important to us momentarily to observe that there is another way
to construct RP 2. For this we carry out the identiﬁcation of antipodal points
on S2 in two stages. First identify points on the lower hemisphere (x3 < 0)
with their antipodes on the upper hemisphere (x3 > 0), leaving the equator
(x3 = 0) ﬁxed. At this point we have a copy of the closed upper hemisphere
(x3 ≥0) which, by projecting into the x1x2-plane, is homeomorphic to the

B.3 Homotopy in the Rotation and Lorentz Groups
301
closed disc (x1)2 + (x2)2 ≤1. To obtain RP 2 we now need only identify
antipodal points on the boundary circle (x1)2 + (x2)2 = 1. This particular
construction can be reﬁned to yield a “visualization” of RP 2 (see Chapter 1,
Volume 1, of [Sp2]). Visualization here is not easy, however. Indeed, given a
little thought, π1(RP 2) = Z2 is rather disconcerting. Think about some loop
in RP 2 that is not homotopically trivial, i.e., cannot be “shrunk to a point in
RP 2” (presumably because it “surrounds a hole” in RP 2). Traverse the loop
twice and (because 1+1 = 0 in Z2) the resulting loop must be homotopically
trivial. What happened to “the hole”? Think about it (especially in light of
our second construction of RP 2).
Exercise B.3.7 Deﬁne real projective 3-space RP 3 by beginning with the
3-sphere S3 = {(x1, x2, x3, x4) ∈R4 : (x1)2 + (x2)2 + (x3)2 + (x4)2 = 1}
in R4 and identifying antipodal points (y ∼±y). Note that <
RP
3 = S3 and
conclude that π1(RP 3) ∼= Z2. Also observe that RP 3 can be obtained by
identifying antipodal points on the boundary (x1)2 +(x2)2 +(x3)2 = 1 of the
closed 3-dimensional ball (x1)2 + (x2)2 + (x3)2 ≤1.
Fig. B.3.2
In an entirely analogous manner one deﬁnes RP n for any n ≥2 and shows
that π1(RP n) ∼= Z2.
Exercise B.3.8 What happens when n = 1?
Now let us return to the Dirac experiment. As with any good magic trick,
some of the paraphenalia is present only to divert the attention of the audi-
ence. Notice that none of the essential features of the apparatus are altered
if we imagine the strings glued (in an arbitrary manner) to the surface of an
elastic belt so that we may discard the strings altogether in favor of such a

302
B Spinorial Objects
belt connecting the scissors and the chair (see Figure B.3.2). Rotate the scis-
sors through 2π and the belt acquires one twist which cannot be untwisted
by moving the belt alone. Rotate through 4π and the belt has two twists that
can be removed by looping the belt once around the scissors.
Regarding the scissors as a rigid, solid body in 3-space we now introduce
what the physicists would call its “conﬁguration space”. Fix some position of
the scissors in space as its “original” conﬁguration. Any continuous motion of
the scissors in space will terminate with the scissors in some new conﬁguration
which can be completely described by giving a point in R3 (e.g., the location
of the scissors’ center of mass) and a rotation that would carry the original
orientation of the scissors onto its new orientation. This second element of
the description we specify by giving an element of the rotation group SO(3),
i.e., the set of all 3 × 3 unimodular orthogonal matrices (when viewed as a
subgroup of the Lorentz group we denoted SO(3) by R; see Section 1.3).
Thus, the conﬁguration space of our scissors is taken to be R3 × SO(3).
In conﬁguration space R3 × SO(3) a continuous motion of the scissors in
space is represented by a continuous curve. In particular, if the initial and ﬁ-
nal conﬁgurations are the same, by a loop. Consider, for example, some point
x0 in R3 ×SO(3), i.e., some initial conﬁguration of the scissors. A continuous
rotation of the scissors through 2π about some axis is represented by a loop
at x0 in R3 × SO(3). Dirac’s ingenious demonstration permits us to actually
“see” this loop. Indeed, let us visualize Dirac’s apparatus with the belt having
one “twist”. Now imagine the scissors free to slide along the belt toward the
chair. As it does so it completes a rotation through 2π. When it reaches the
chair, translate it (without rotation) back to its original location and one has
traversed a loop in conﬁguration space. Similarly, for a rotation through 4π.
Indeed, it should now be clear that any position of the belt can be viewed as
representing a loop in R3×SO(3) (slide the scissors along the belt then trans-
late it back). Now imagine yourself manipulating the belt (without moving
scissors or chair) in an attempt to untwist it. At each instant the position of
the belt represents a loop in R3 ×SO(3) so the process itself may be thought
of as a continuous sequence of loops (parametrized, say, by time t). If you
succeed with such a sequence of loops to untwist the belt you have “created”
a homotopy from the loop corresponding to the belt’s initial conﬁguration to
the trivial loop (no rotation, i.e., no twists, at all). What Dirac seems to be
telling us then is that the loop in R3 × SO(3) corresponding to a 2π rotation
is not homotopically trivial, but that corresponding to a rotation through 4π
is homotopic to the trivial loop.
It is clearly of some interest then to understand the “loop structure”, i.e.,
the fundamental group, of R3 ×SO(3). Notice that SO(3) does indeed have a
natural topology. The entries in a 3×3 matrix can be strung out into a column
matrix which can be viewed as a point in R9. Thus, SO(3) can be viewed as a
subset of R9 and therefore inherits a topology as a subspace of R9. A consid-
erably more informative “picture” of SO(3) can be obtained as follows: Every
rotation of R3 can be uniquely speciﬁed by an axis of rotation, an angle and a

B.3 Homotopy in the Rotation and Lorentz Groups
303
sense of rotation about the axis. We claim that all of this information can be
codiﬁed in a single object, namely, a vector
⇀n in R3 of magnitude at most π.
Then the axis of rotation is the line along
⇀n, the angle of rotation is |
⇀n| and
the sense is determined by the “right-hand rule”. Notice that a rotation along
⇀n through an angle θ with π ≤θ ≤2π is equivalent to a rotation along –
⇀n through 2π −θ so the restriction on |
⇀n| is necessary (although not quite
suﬃcient) to ensure that the correspondence between rotations and vectors
be one-to-one. The set of vectors
⇀n in R3 with |
⇀n| ≤π is just the closed ball
of radius π about the origin. However, a rotation about
⇀n through π is the
same as a rotation about –
⇀n through π so antipodal points on the bound-
ary of this ball represent the same rotation and therefore must be identiﬁed
in order that this correspondence with rotations be bijective. Carrying out
this identiﬁcation yields, according to Exercise B.3.7, real projective 3-space
(topologically, the radius of the ball is irrelevant, of course). One can write out
analytically the one-to-one correspondence we have just described geometri-
cally to show that it is, in fact, continuous as a map from RP 3 to SO(3) ⊆R9.
Since RP 3 is compact (being a continuous image of S3), we ﬁnd that SO(3)
is homeomorphic to RP 3. In particular, π1(SO(3)) ∼= π1(RP 3) ∼= Z2. Thus,
π1(R3 × SO(3)) ∼= π1(R3) × π1(SO(3)) ∼= {0} × Z2 so
π1(R3 × SO(3)) ∼= Z2
and our suspicions are fully conﬁrmed. In quite a remarkable way, the topol-
ogy of the rotation group is reﬂected in the physical situation described
by Dirac.
Exercise B.3.9 In Z2, 1 + 1 + 1 = 1 and 1 + 1 + 1 + 1 = 0. More generally,
2n + 1 = 1 and 2n = 0. What does this have to say about the scissors
experiment?
But what has all of this to do with spinors? The connection is perhaps
best appreciated by way of a brief digression into semantics. We have called
R3 × SO(3) the “conﬁguration space” of the object we have under consider-
ation (the scissors). In the classical study of rigid body dynamics, however,
it might equally well have been called its “state space” since, neglecting the
object’s (quite complicated) internal structure, it was (tacitly) assumed that
the physical state of the object was entirely determined by its conﬁguration
in space. Suppressing the (topologically trivial and physically uninteresting)
translational part of the conﬁguration (i.e., R3), the body’s “state” was com-
pletely speciﬁed by a point in SO(3). Based on our observations in Section 3.1,
we would phrase this somewhat more precisely by saying that all of the phys-
ically signiﬁcant aspects of the object’s condition (as a rigid body) should be
describable as carriers of some representation of SO(3) (keep in mind that,
from our point of view, a rotated object is just the same object viewed from
a rotated frame of reference). We shall refer to such quantities (which depend
only on the object’s conﬁguration and not on “how it got there”) as tensorial
objects.

304
B Spinorial Objects
But the conclusion we draw from the Dirac experiment is that there may
well be more to a system’s “state” than merely its “conﬁguration”. This
additional element has been called (see [MTW]) the version or orientation-
entanglement relation of the system and its surroundings and at times it must
be taken into account, e.g., when describing the quantum mechanical state of
an electron with spin. Where is one to look for a mathematical model for such
a system’s “state” if now there are two, where we thought there was one?
The mathematics itself suggests an answer. Indeed, the universal covering
manifold of SO(3) (i.e., of RP 3) is S3 and is, in fact, a double cover, i.e.,
the covering map is precisely two-to-one, taking the same value at y and −y
for each y ∈S3. Will S3 do as the “state space”? That this idea is not the
shot-in-the-dark it may at ﬁrst appear will become apparent once it has been
pointed out that we have actually seen all of this before.
Recall that, in Section 1.7, we constructed a homomorphism, called the
spinor map, from SL(2, C) onto L that was also precisely two-to-one and
carried the unitary subgroup SU 2 of SL(2, C) onto the rotation subgroup R
(i.e., SO(3)) of L.
Exercise B.3.10 Let I =
*
1 0
0 1
+
, i =
*
i 0
0 −i
+
, j =
*
0 1
−1 0
+
and k =
*
0 i
i 0
+
.
Show that I, i, j and k are all in SU 2 and that, moreover, any A ∈SU 2 is
uniquely expressible in the form
A = aI + bi + cj + dk,
where a, b, c, d ∈R and a2 + b2 + c2 + d2 = 1. Regard SU 2 as a subset of R8
by identifying
A =
#
a + bi c + di
−c + di a −bi
$
with the column matrix col [a b c d −c d a −b] ∈R8 and deﬁne a map
from SU 2 into R4 that carries this column matrix onto col [a b c d] ∈R4.
Show that this map is a homeomorphism of SU 2 onto S3 ⊆R4. Finally,
observe that the restriction of the spinor map to SU 2 is a continuous map
onto R (i.e., SO(3)) which satisﬁes the deﬁning property of a covering map
for SO(3).
Thus we ﬁnd that SU 2 and the restriction of the spinor map to it constitute
a concrete realization of the universal covering manifold for SO(3) and its
covering map. Old friends, in new attire. And now, how natural it all appears.
Identify a “state” of the system with some ˜y ∈SU 2. This corresponds to some
“conﬁguration” y ∈SO(3) (the image of ˜y under the spinor map). Rotating
the system through 2π corresponds to a loop in SO(3) which, in turn, lifts
((5.2) of [G]) to a path in SU 2 from ˜y to −˜y (a diﬀerent “state”). Further
rotation of the system through 2π traverses the loop in SO(3) again, but,
in SU 2, corresponds to a path from −˜y to ˜y and so a rotation through 4π
returns the original “state”.

B.3 Homotopy in the Rotation and Lorentz Groups
305
Exercise B.3.11 For each t ∈R deﬁne a matrix A(t) by
A(t) =
*e
t
2 i
0
0
e−t
2 i
+
.
Show that A(t) ∈SU 2 and that its image under the spinor map is the rotation
R(t) =
⎡
⎢⎢⎣
cos t
−sin t 0
0
sin t
cos t
0
0
0
0
1 0
0
0
0 1
⎤
⎥⎥⎦.
Hint: Take θ = φ2 = 0 and φ1 = t in Exercise 1.7.7.
Exercise B.3.12 Show that α : [0, 2π] →SU 2 deﬁned by α(t) = A(t) for
0 ≤t ≤2π is a path in SU 2 from the identity I2×2 to −I2×2 whose image
under the spinor map is a loop Spin ◦α at I4×4 (which is not nullhomotopic
in R). On the other hand, β :
[0, 4π] →SU 2 deﬁned by β(t) = A(t) for
0 ≤t ≤4π is a loop at I2×2 in SU 2 and its image Spin ◦β is also a loop at
I4×4 (which is nullhomotopic in R).
Mathematical quantities used to describe various aspects of the system’s
condition are still determined by the state of the system, but now we take this
to mean that they should be expressible as carriers of some representation
of SU 2. (Incidentally, any discomfort one might feel about the apparently
miraculous appearance at this point of a group structure for the covering
space should be assuaged by a theorem to the eﬀect that this too is “essen-
tially unique”; see (6.11) of [G].) Although we shall not go into the details
here, it should come as no surprise to learn that the universal cover of the
entire Lorentz group L consists of SL(2, C) and the spinor map so that to
obtain a relativistically invariant description of, say, the state of an electron,
one looks to the representations of SL(2, C), that is, to the 2-valued repre-
sentations of L (see Section 1.7). Quantities such as the wave function of an
electron (which depend not only on the object’s conﬁguration, but also on
“how it got there”) we call spinorial objects and are described mathematically
by carriers of the representations of SL(2, C), i.e., by spinors.


References
[AS] Aharonov, Y. and L. Susskind, “Observability of the sign change of
spinors under 2π rotations”, Phys. Rev., 158(1967), 1237–1238.
[A] Alphors, L., Complex Analysis, McGraw-Hill, New York, 1979.
[BJ] Bade, W. L. and H. Jehle, “An introduction to spinors”, Rev. Mod.
Phys., 25(1953), 714–728.
[B] Bolker, E. D., “The spinor spanner”, Amer. Math. Monthly,
80(1973), 977–984.
[C] Cartan, E., The Theory of Spinors, M.I.T. Press, Cambridge,
MA, 1966.
[CGK] Cacciatori, S., V. Girini and A. Kamenshchik, “Special relativity in
the 21st century”, Annalen der Physik, 17(2008), 728–768.
[DS] Daigneault, A. and A. Sangalli, “Einstein’s static universe: an idea
whose time has come back”, Notices of AMS, 48(2001), 9–16.
[E] Einstein, A., et al., The Principle of Relativity, Dover, New York,
1958.
[Fa] Fadell, E., “Homotopy groups of conﬁguration spaces and the string
problem of Dirac”, Duke Math. J., 29(1962), 231–242.
[Fe] Feynman, R. P., R. B. Leighton and M. Sands, The Feynman Lec-
tures on Physics, Vol. III, Quantum Mechanics, Addison-Wesley,
Reading, MA, 1966.
[FL] Freedman, M. H. and Feng Luo, Selected Applications of Geome-
try to Low-Dimensional Topology, A.M.S. University Lecture Series,
American Mathematical Society, Providence, RI, 1989.
[GMS] Gelfand, I. M., R. A. Minlos and Z. Ya. Shapiro, Representations of
the Rotation and Lorentz Groups and their Applications, Pergamon,
New York, 1963.
[G] Greenberg, M., Lectures on Algebraic Topology, W.A. Benjamin,
New York, 1967.
[HE] Hawking, S.W. and G.F.R. Ellis, The Large Scale Structure of
Space-Time, Cambridge University Press, Cambridge, England,
1973.
307

308
References
[HKM] Hawking, S. W., A. R. King and P. J. McCarthy, “A new topology
for curved spacetime which incorporates the causal, diﬀerential and
conformal structures”, J. Math. Phys., 17(1976), 174–181.
[H] Herstein, I. N., Topics in Algebra, Blaisdell, Waltham, MA, 1964.
[IS] Ives, H. E. and G. R. Stilwell, “Experimental study of the rate
of a moving atomic clock”, J. Opt. Soc. Am., 28(1938), 215;
31(1941), 369.
[KO] Klein, A. G. and G. I. Opat, “Observability of 2π rotations: A
proposed experiment”, Phys. Rev. D, 11(1975), 523–528.
[K] Kuiper, N. H., Linear Algebra and Geometry, North Holland,
Amsterdam, 1965.
[La] Lang, S., Linear Algebra, Springer-Verlag, New York, 1987.
[LU] Laporte, O. and G. E. Uhlenbeck, “Application of spinor analysis
to the Maxwell and Dirac equations”, Phys. Rev., 37(1931), 1380–
1397.
[LY] Lee, T. D. and C. N. Yang, “Parity nonconservation and a two-
component theory of the neutrino”, Phys. Rev., 105(1957), 1671–
1675.
[Le] Lenard, A., “A characterization of Lorentz transformations”, Amer.
J. Phys., 19(1978), 157.
[Lest] Lester, J.A., “Separation-preserving transformations of de Sitter
spacetime”, Abh. Math. Sem. Univ. Hamburg Volume 53, Number
1, 217–224.
[M] Magnon, A. M. R., “Existence and observability of spinor struc-
ture”, J. Math. Phys., 28(1987), 1364–1369.
[MTW] Misner, C. W., K. S. Thorne and J. A. Wheeler, Gravitation, W.
H. Freeman, San Francisco, 1973.
[Nan] Nanda, S., “A geometrical proof that causality implies the Lorentz
group”, Math. Proc. Camb. Phil. Soc., 79(1976), 533–536.
[N1] Naber, G. L., Topological Methods in Euclidean Spaces, Dover Pub-
lications, Mineola, New York, 2000
[N2] Naber, G. L., Spacetime and Singularities, Cambridge University
Press, Cambridge, England, 1988.
[N3] Naber, G.L., Topology, Geometry and Gauge ﬁelds: Foundations,
2nd Edition, Springer, New York, 2010.
[N4] Naber, G.L., Topology, Geometry and Gauge ﬁelds: Interactions,
2nd Edition, Springer, New York, 2011.
[Ne] Newman, M. H. A., “On the string problem of Dirac”, J. London
Math. Soc., 17(1942), 173–177.
[O’N] O’Neill, B., Semi-Riemannian Geometry, With Applications to Rel-
ativity, Academic Press, San Diego, New York, 1983.
[Par] Parrott, S., Relativistic Electrodynamics and Diﬀerential Geometry,
Springer-Verlag, New York, 1987.
[Pay] Payne, W. T., “Elementary spinor theory”, Amer. J. Phys.,
20(1952), 253–262.

References
309
[Pen1] Penrose, R., “The apparent shape of a relativistically moving
sphere”, Proc. Camb. Phil. Soc., 55(1959), 137–139.
[Pen2] Penrose, R., “Zero rest-mass ﬁelds including gravitation: asymptotic
behavior”, Proc. Roy. Soc. Lond., Series A, 284(1965), 159–203.
[PR] Penrose, R. and W. Rindler, Spinors and Spacetime, Vols. I–II,
Cambridge University Press, Cambridge, England, 1984, 1986.
[R] Robb, A. A., Geometry of Space and Time, Cambridge University
Press, Cambridge, England, 1936.
[Sa] Salmon, G., A Treatise on the Analytic Geometry of Three Dimen-
sions, Vol. 1, Chelsea, New York.
[Sp1] Spivak, M., Calculus on Manifolds, W.A. Benjamin, Inc., Menlo
Park, CA, 1965.
[Sp2] Spivak, M., A Comprehensive Introduction to Diﬀerential Geome-
try, Vols. I–V, Publish or Perish, Houston, TX, 1975.
[Sy] Synge, J. L., Relativity: The Special Theory, North Holland,
Amsterdam, 1972.
[TW] Taylor, E. F. and J. A. Wheeler, Spacetime Physics, W. H. Freeman,
San Francisco, 1963.
[V] Veblen, O., “Spinors”, Science, 80(1934), 415–419.
[Wald] Wald, R.M., General Relativity, University of Chicago Press,
Chicago, 1984.
[We] Weyl, H., Space-Time-Matter, Dover, New York, 1952.
[Wi] Willard, S., General Topology, Addison-Wesley, Reading, MA, 1970.
[Z1] Zeeman, E. C., “Causality implies the Lorentz group”, J. Math.
Phys., 5(1964), 490–493.
[Z2] Zeeman, E. C., “The topology of Minkowski space”, Topology,
6(1967), 161–170.


Symbols
M
Minkowski spacetime, 9
O, ˆO, . . .
observers, 2
Σ, ˆΣ, . . .
spatial coordinate systems, 2
c
speed of light, 3
S, ˆS, . . .
frames of reference, 3
xa, ˆxa, . . .
spacetime coordinates, 3
ΛT
transpose of Λ
η
10
g(v, w) = v · w
value of the inner product g on (v, w), 7
W⊥
orthogonal complement of W, 7
Q
quadratic form determined by g, 7
v2 = Q(v) = v · v
7
{ea}, {ˆea}, . . .
orthonormal bases, 8
δab = δab = δab = δa
b
4 × 4 Kronecker delta
ηab = ηab
entries of η, 10
CN(x0)
null cone at x0, 11
Rx0,x
null worldline through x0 and x, 11
Λ = [Λab]
matrix of an orthogonal transformation, 13
[Λa
b]
inverse of [Λab]
LGH
general homogeneous Lorentz group, 14
CT (x0)
time cone at x0, 16
C±
T (x0)
future and past time cones at x0, 16
C±
N(x0)
future and past null cones at x0, 17
L
Lorentz group, 19
R
rotation subgroup of L, 20
⇀u,
⇀
ˆu, . . .
velocity 3-vectors, 21
β
relative speed of S and ˆS, 21, 26
γ
(1 −β2)−1
2 , 21
311

312
Symbols
⇀
d,
⇀
ˆd, . . .
direction 3-vectors, 22
Λ(β)
boost, 26
θ
velocity parameter, 27
L(θ)
hyperbolic form of Λ(β), 27
τ(v)
duration of v, 43
Δτ = τ(x −x0)
43
α′(t)
velocity vector of the curve α, 47
L(α)
proper time length of α, 47
τ = τ(t)
proper time parameter, 50
U = α′(τ)
world velocity of α, 50
A = α′′(τ)
world acceleration of α, 51
γ(
⇀u, 1) = U
52
S(x −x0)
proper spatial separation, 56
≪
chronological precedence, 58
<
causal precedence, 58
ACT
conjugate transpose of A
C2×2
set of complex 2 × 2 matrices
H2
Hermitian elements of C2×2, 69
σa
Pauli spin matrices, 69
SL(2, C)
special linear group, 69
ΛA
image of A under spinor map, 71
A(θ)
maps onto L(θ) under spinor map, 72
SU 2
special unitary group, 72
R−
x
past null direction through x, 74
S−
celestial sphere, 74
(α, m)
material particle, 81
m
proper mass of (α, m), 81
P = mU
world momentum of (α, m), 81
⇀p
relative 3-momentum, 81
(
⇀p, mγ) = P
81
E
total relativistic energy, 82
(α, N)
photon, 84
⇀e ,
⇀
ˆe , . . .
direction 3-vectors of (α, N), 84
N
world momentum of (α, N), 84
ϵ, ˆϵ, . . .
energies of (α, N), 84
ν, ˆν, . . .
frequencies of (α, N), 84
λ, ˆλ, . . .
wavelengths of (α, N), 84
h
Planck’s constant, 84
(A, x,
˜
A)
contact interaction, 87
me
mass of the electron
≈
is approximately equal to
(α, m, e)
charged particle, 93
e
charge of (α, m, e), 93
⇀
E
electric ﬁeld 3-vector, 95
⇀
B
magnetic ﬁeld 3-vector, 95

Symbols
313
rng T
range of T , 97
ker T
kernel of T , 97
tr T
trace of T
N E
ε (x0)
open Euclidean ε-ball about x0, 117
f,α =
∂f
∂xα
118
p
F→F(p)
assignment of a linear transformation to p, 118
div F
divergence of p
F→F(p), 118
˜F
bilinear form associated with F, 119
d ˜F
exterior derivative of ˜F, 120
ϵabcd
Levi-Civita symbol, 121
∗˜F
dual of ˜F, 121
Lab = L(ea, eb)
components of the bilinear form L, 136
GL(n, R)
real general linear group of order n, 138
GL(n, C)
complex general linear group of order n, 138
D
a group representation, 138
DΛ = D(Λ)
image of Λ under D, 138
M∗
dual of the vector space M, 139
{ea}
basis for M∗dual to {ea}, 139
v∗
element u →v · u of M∗for v ∈M, 139
va = ηaαvα
components of v∗in {ea}, 139
⊗
tensor (or outer) product, 140
T r
s
vector space of world tensors on M, 140
La1···ar b1···bs
components of L ∈T r
s , 141
M∗∗= (M∗)∗
second dual of M, 141
x∗∗
element f →f(x) of M∗∗for x ∈M, 141
Spin
the spinor map, 142
Pmn
space of polynomials in z and ¯z, 144
D( m
2 , n
2 )
spinor representation of type (m, n), 144
A, B, C, . . .
spinor indices taking the values 1, 0
˙X, ˙Y ,
˙Z, . . .
conjugated spinor indices taking the values ˙1, ˙0
G =

GA
B
element of SL(2, C), 148
¯G =
,
¯G
˙Y
˙X
-
conjugate of G, 148
ß
spin space, 153
<, >
skew-symmetric “inner product” on ß, 153
{sA}, {ˆsA}, . . .
spin frames, 153
φA, ˆφA, . . .
components of φ ∈ß, 153
ß∗
dual of ß, 155
{sA}, {ˆsA}, . . .
dual spin frames, 155
δA
B
2 × 2 Kronecker delta
φ∗
element ψ →< φ, ψ > of ß∗for φ ∈ß, 155
φA, ˆφA, . . .
components of φ∗∈ß∗, 156

GAB

transposed inverse of

GA
B
, 156
φ∗∗
element f →f(φ) of ß∗∗for φ ∈ß, 157

314
Symbols
¯ß = ß × {1}
“conjugate” of ß, 157
¯φ
(φ, 1) ∈¯ß for φ ∈ß, 157
{¯s ˙X}, {¯ˆs ˙X}, . . .
conjugate spin frames, 158
¯φ ˙X, ¯ˆφ ˙X, . . .
components of ¯φ, 158
¯G =
,
¯G ˙X
˙Y
-
conjugate of G =

GAB

, 158
¯ß∗
dual of ¯ß, 158
{¯s ˙X}, {¯ˆs ˙X}, . . .
dual conjugate spin frames, 158
¯φ∗
element of ¯ß∗conjugate to φ∗∈ß∗, 159
¯φ ˙X, ¯ˆφ ˙X, . . .
components of ¯φ∗, 159
 r s
m n

valence of a spinor, 159
ξA1···Ar ˙X1··· ˙Xs
B1···Bm ˙Y1··· ˙Yn
spinor components, 159
ϵ =
*
0 −1
1 0
+
=
*
ϵ11 ϵ10
ϵ01 ϵ00
+
= [ϵAB] = [¯ϵ ˙X ˙Y ] = ¯ϵ ˙X ˙Y , 161
ßrs
mn
space of spinors of valence

r s
m n

, 164
Ckl(ξ), C ˙k˙l(ξ), . . .
contractions of ξ, 166, 167
¯ξ
spinor conjugate of ξ, 167
ξ(AB)
symmetrization of ξAB, 168
ξ[AB]
skew-symmetrization of ξAB, 169
α(AβB)
symmetrization of αAβB, 169
σaA ˙X, σa
A ˙X
Infeld-van der Waerden symbols, 169
V A ˙X
spinor equivalent of v ∈M, 170
VA ˙X
spinor equivalent of v∗∈M∗, 175
FA ˙XB ˙Y
spinor equivalent of the bilinear form F, 179
φAB
symmetric spinor determined by FA ˙XB ˙Y , 180
ξA →eiθξA
phase change, 185
∇A ˙X
spinor diﬀerential operator, 197
Rn
real n-space, 202
⟨p, q⟩
Euclidean inner product on Rn, 202
∥p∥
Euclidean norm on Rn, 202
Uε(p)
open ball of radius ε about p in Rn, 203
C∞
smooth, 203
Sn
n-sphere, 203
(U, ϕ)
chart, 206
χ : U →M
coordinate patch, 211
χi
coordinate velocity vector, 218
Tp(M)
tangent space to M at p, 218
(p, q)
Minkowski inner product on R5, 221
M5
5-dimensional Minkowski space, 221
Γr
ij
Christoﬀel symbols, 230

Symbols
315
H3(r)
hyperbolic 3-space, 240
R
Riemann curvature tensor, 246
Rij
Ricci tensor, 249
R
scalar curvature, 249
Gij
Einstein tensor, 249
Tij
energy-momentum tensor, 250
F∗p
derivative of F at p, 252
E
Einstein static universe, 255
F ∗g
pullback metric, 260
I−
past null inﬁnity, 266
I+
future null inﬁnity, 266
i−
past timelike inﬁnity, 273
i+
future timelike inﬁnity, 273
i0
spacelike inﬁnity, 274
dE
E-distance, 279
NE
ε (x0)
open Euclidean ε-ball about x0, 280
ME
M with the Euclidean topology, 280
ClEA, bdyE A, . . .
Euclidean closure, boundary,. . . of A ⊆M
C(x)
C−
T (x) ∪C+
T (x) ∪{x}, 284
N P
ε (x0)
P-open ε-ball about x0, 284
MP
M with the path topology, 285
ClP A, bdyP A, . . .
path closure, boundary, . . . of A ⊆M
H(X)
homeomorphism group of X, 292
[α]
homotopy class of the path α, 297
α−1
inverse of the path α, 297
βα
product of the paths α and β, 297
π1(X, x0)
fundamental group of X at x0, 297
π1(X)
fundamental group of X, 297
( ˜X, p)
universal covering manifold of X, 299
RP 2
real projective plane, 300
Z2
group of integers mod 2
RP 3
real projective 3-space, 301
RP n
real projective n-space, 301
SO(3)
rotation group, 302


Index
A
aberration formula, 86
accelerations, 38, 48, 49, 82, 201, 228, 230
active transformations, 73, 77, 80
addition of velocities formula, 26
admissible basis, 19
admissible frame of reference, 19
local, 201
nonexistence of, 6
advanced null coordinates, 270
aﬃne parametrization, 262
α-emission, 87
anti-isomorphism, 158
B
barn paradox, 41
bilinear form, 7
components of, 120
matrix of, 120
nondegenerate, 7
skew-symmetric, 119
spinor equivalent of, 192
symmetric, 7
binding energy, 88
binomial expansion, 82, 85, 91
Biot-Savart Law, 127
bivector, 120
spinor equivalent of, 180
boost, 26
C
canonical basis, 107
canonical forms, 107, 109, 195
carriers of a representation, 138
Cartan, E., 135
catenary, 117
causal automorphism, 59, 60, 223, 292
causal precedence, 58
causality assumption, 4
causality relations, 58, 222, 227
Cayley-Hamilton Theorem, 103
change of basis formula, 119
characteristic equation, 99
charge, 93
charge-to-mass ratio, 116
charged particle, 93
Christoﬀel symbols, 230
chronological precedence, 58
Clock Hypothesis, 48
clocks, 2, 36, 48
atomic, 2
synchronization of, 3
closed
in Rn, 203
in X, 203
commutation relations, 169
Compton eﬀect, 88
Compton wavelength, 90
cone, 4
null, 11, 221, 268
time, 16, 49, 221
conﬁguration space, 302
conformal diﬀeomorphism, 259
conformal embedding, 260
conformally related metrics, 260
317

318
Index
conjugate isomorphism, 158
conjugate spin covector, 158
conjugate spin vector, 158
conjugate spinor, 158, 168
conjugate transpose, 69
conjugation representation, 146
connectible by a light ray, 14
conservation of energy, 87, 90
conservation of momentum, 81, 87
conservation of 4-momentum, 87
conservation laws, 81, 88
constant curvature, 248, 253
constant electromagnetic ﬁelds, 123
constant loop, 297
contact interaction, 87
continuous, 203
contraction, 166
contravariant rank, 141
contravariant vector, 141
coordinate curve, 218
coordinate functions, 50, 202, 203
coordinate patch, 211
coordinate transformation, 219
coordinates
spatial, 2, 10, 29, 253
time, 3, 10, 253
cosmic rays, 23
cosmological constant, 250
cosmological model, 252
Coulomb ﬁeld, 123
total energy of, 125
covariant rank, 141
covariant vector, 141
covector, 141
covering map, 299
covering transformation, 299
curve, 47, 217
component functions, 47
E-continuous future- (past-) timelike,
280
null, 47, 226
reparametrization of, 47
smooth, 47, 217
spacelike, 47, 226
timelike, 47, 226
cylinder, 242
locally ﬂat, 242
D
decay, 87
derivative of a smooth map, 252
de Sitter spacetime, 224
Christoﬀel symbols for, 231
conformal coordinates, 215
constant curvature, 249
Einstein tensor, 249
geodesics of, 240
global coordinates, 214
hyperbolic coordinates, 217
line element for, 226
Lorentz metric for, 224
null inﬁnity, 266
planar coordinates, 215
Ricci tensor, 249
Riemann curvature tensor, 247
and Robertson-Walker metrics, 254
scalar curvature, 249
diﬀeomorphism, 203
dilation, 60
time, 22
Dirac
equation, 135, 136
Scissors Problem, 295
direct sum, 43
direction 3-vector, 22
of a photon, 84
of a reference frame, 22
disintegration, 87
displacement vector, 10
null, 10
spacelike, 12
timelike, 12
distance, 57
measured with clocks, 57
divergence, 118
dominant energy condition, 113, 123, 195
Doppler eﬀect, 85
transverse, 85
double cover, 304
dual
basis, 139, 157
of a bivector, 122
duration, 43
E
E-continuous curve, 280
future-timelike, 281
future-timelike at t0, 281
past-timelike, 281
past timelike at t0, 281

Index
319
timelike, 281
timelike vs smooth timelike, 281
E-continuous map, 280
E-distance, 279
E-open ball, 280
E-open set, 280
E-topology, 280
eigenspace, 98
eigenspinor, 190
eigenvalue
of a linear transformation, 98
of a spinor, 190
eigenvector, 98
Einstein ﬁeld equations, 250
empty space solutions, 250
Einstein static universe, 255
geodesics, 258
line element, 256
Einstein summation convention, xi
electric 3-vector, 95
electromagnetic ﬁeld, 94, 120
constant, 113, 123
null, 99
regular, 99
spinor, 186
electromagnetic spinor, 186
electromagnetic wave
simple plane, 129
spherical, 3, 17, 35
electron, 88
spin, 135, 294
elevator experiment, 200
energy, 82
Coulomb ﬁeld, 125
density, 111
of a photon, 84
total relativistic, 82
energy-momentum tensor, 250
energy-momentum transformation, 109
spinor form of, 195
equation of motion, 93
Euler angles, 72
event horizon, 268
events, 1, 9
expanding universe, 255
extended complex plane, 73, 76, 79
exterior derivative, 120
F
Feynman path, 288
Feynman track of an electron, 288
ﬁeld equations, 198, 250, 255, 277
ﬁeld of vision, 79
Fizeau procedure, 3
ﬂag pole of a spin vector, 179
4-acceleration, 51
4-momentum
of a material particle, 81
of a photon, 84
4-tensor, 141
4-vector, 169
contravariant, 141
covariant, 141
4-velocity, 50
fractional linear transformation, 73, 77
frame of reference, 3, 10
admissible, 4, 19
free charged particle, 93
free particle, 87
frequency of a photon, 84
fundamental group, 297
of a product, 298
of real projective space, 300, 301
of the rotation group, 303
future-directed
null curve, 47
null vector, 17
timelike curve, 47
timelike vector, 16
future null cone, 17
future null direction, 74
future null inﬁnity, 266, 274
future time cone, 16
future timelike inﬁnity, 273
G
Gaussian curvature, 243
of cylinder, 243
of S2, 243
general linear group, 138
general theory of relativity, 202
geodesic, 230
aﬃne parametrization, 262
causal character, 234
constant speed, 233
degenerate, 230
existence and uniqueness, 232
of de Sitter spacetime, 235
of Minkowski spacetime, 234
of S2, 234
of S3, 235
reparametrization of, 232

320
Index
geodesic hypothesis, 250
gravitation, 6, 199, 249
group representation, 138
H
Hermitian matrix, 170
homeomorphism, 203, 292
homeomorphism group, 292
homomorphism, 14, 138
homotopic paths, 297
homotopy, 297
hyperbolic form of special Lorentz
transformations, 27
hyperbolic motion, 55
I
identity representation, 138, 141, 146
index of an inner product, 9
inelastic collision, 90
inertial mass, 81
Infeld-van der Waerden symbols, 173
initial point on a worldline, 87
inner product, 7
indeﬁnite, 7
index of, 9
Lorentz, 9
negative deﬁnite, 7
positive deﬁnite, 7
instantaneous rest frame, 53
invariant subspace
of a linear transformation, 99
of a representation, 143
Inverse Function Theorem, 208
isometry, 252
K
Kennedy-Thorndike experiment, 3
kernel, 68, 97
L
length, 39
contraction, 40
Levi-Civita symbols, 121
spinor equivalent of, 196
light cone, 11
future and past, 17
light ray, 11
as an intersection of null cones, 11
light signals, 3, 17
light travel time, 3
lightlike vector, 10
line element, 225
loop, 297
constant (trivial), 297
Lorentz contraction, 40
invisibility of, 79
Lorentz 4-Force Law, 93
Lorentz group, 19
general homogeneous, 14
inhomogeneous, 19
2-valued representations of, 142, 144
Lorentz inner product, 9
spinor equivalent of, 192
Lorentz invariant, 99, 136, 141
Lorentz transformations, 14, 19
boost, 26
decomposition of, 28
determined by three past null directions,
79
eﬀect on past null directions, 79
general homogeneous, 14
hyperbolic form, 27
improper, 19
invariant null directions, 79
nonorthochronous, 15
orthochronous, 15
proper, 19
special, 25
vs fractional linear transformations, 77
Lorentz World Force Law, 93
lowering indices, 162
M
magnetic 3-vector, 95
manifold, 206
complete, 238
n-dimensional, 206
smooth, 206

Index
321
mass
inertial, 81
proper, 81
relativistic, 82
mass-energy equivalence, 83
massless free-ﬁeld equations, 198, 277
material particle, 81
worldline of, 47
free, 81
matrix group, 137
order of, 137
representation of, 138
matrix of a bilinear form, 120
Maxwell’s equations, 118, 122
solutions of, 123, 124, 129, 130
spinor form of, 197
measuring rods, 39, 40
metric, 219
component functions, 219
Lorentzian, 220
Riemannian, 219
Michelson-Morley experiment, 3
Minkowski diagram, 32, 266
Minkowski spacetime, 9
multilinear functional, 140, 159
N
neutrino equation, 198
null basis, 10
null cone, 11
future, 17
past, 17
null direction, 61
future, 74
past, 74
null electromagnetic ﬁeld, 99
null ﬂag, 185
null vector, 10
future-directed, 17
parallel, 10
past-directed, 17
orthogonal, 10
null worldline, 11
O
observer, 1
admissible, 1
open
in Minkowski spacetime, 117
in Rn, 203
in X, 203
orientation-entanglement relation, 304
orthochronous, 15
orthogonal complement, 7
orthogonal transformation, 12, 222
and causal automorphisms, 60, 227
and fractional linear transformations, 77
and homeomorphisms, 292
associated matrices, 13
invariant null directions, 79
orthochronous, 60
orthogonality, 7
of null vectors, 10
of spacelike and null vectors, 58
of spacelike vectors, 57
with timelike vectors, 15
orthonormal basis, 8
outer product, 165
P
P-continuous curve, 289
characterized as Feynman paths, 289
vs E-continuous curves, 288
vs timelike curves, 288
P-open set, 284
not E-open, 284
paradox
barn, 41
twin, 36
parallel postulate, 235
parity nonconservation, 198
particle
charged, 93
free, 87
free charged, 93
horizon, 268
material, 81
passive transformation, 73
past-directed
null curve, 47
null vector, 17
timelike curve, 47
timelike vector, 16
past null cone, 17
past null direction, 74
past null inﬁnity, 266, 274
past time cone, 16
past timelike inﬁnity, 273

322
Index
path, 296
inverse of, 297
products of, 297
path connected, 296
path topology, 284
basis for, 285
homeomorphisms of, 292
topological properties, 286
Pauli spin matrices, 69
Penrose diagram, 266
phase factor, 182
photon, 84
direction 3-vector of, 84
energy, 84
4-momentum of, 84
frequency, 84
propagation of, 2
wavelength, 84
worldline, 4, 11
world momentum of, 84
pions, 36
Planck’s constant, 84
Poincar´e group, 19
point event, 1
Poynting 3-vector, 111
principal null directions, 108, 109
product path, 297
proper mass, 81
proper spatial separation, 56
proper time function, 50
proper time parameter, 227
proper time separation, 44
pullback, 260
Pythagorean Theorem, 58
Q
quadratic form, 7
quantum mechanics, 88, 142, 198, 294
R
raising indices, 162
range, 97
rank
contravariant, 141
covariant, 141
real projective n-space, 301
fundamental group of, 301
regular electromagnetic ﬁeld, 99
relative 3-momentum, 81
relativistic electron, 137
relativistic energy, 82
relativistic mass, 82
relativity
of simultaneity, 23
principle, 5
representations, 138
carriers of, 138
equivalent, 143
irreducible, 143
reducible, 143
spinor, 145
two-valued, 144
retarded null coordinates, 270
reversed Schwartz inequality, 44
reversed triangle inequality, 44
Ricci ﬂat, 250
Ricci tensor, 249
Riemann curvature tensor, 246
Riemann sphere, 73
rigidity, 40
Robb’s theorem, 57
Robertson-Walker metrics, 254
rocket twin, 37, 55
rotation group, 302
rotation in the Lorentz group, 20
rotation subgroup, 20
S
Schur’s lemma, 143
Schwartz inequality
for R3, 10
reversed, 44
signals, 3, 33, 57, 268
simply connected, 298
simultaneity, 23
relativity of, 23
simultaneous, 23
skew-symmetric bilinear form, 119
skew-symmetric linear transformation, 94
null, 99
regular, 99
skew-symmetrization, 169
smooth
assignment, 118
map, 203
real-valued function, 203
vector ﬁeld, 118

Index
323
spacelike displacement, 57
spacelike inﬁnity, 274
spacelike vector, 12
spacetime, 220
spatially homogeneous and isotropic, 252
spatial coordinates, 29, 254
special linear group, 69
special Lorentz transformation, 25
hyperbolic form, 27
speed
of light, 3
of material particles, 82
spin, 88, 135, 137
spin covector, 155
spin frame, 153
spin space, 153
spin transformation, 69
spin vector, 153
spinor, 135
components of, 159
conjugate, 158, 168
contravariant indices, 159
covariant indices, 159
dotted indices, 159
electromagnetic ﬁeld, 186
equivalents (See spinor equivalent)
essential two- valuedness of, 185, 293
form of Maxwell’s equations, 198
Hermitian, 168
lower indices, 159
skew-symmetric, 168
symmetric, 168
undotted indices, 159
upper indices, 159
valence of, 159
spinor-covector, 172
spinor equivalent
of a bilinear form, 192
of a bivector, 180
of a covector, 176
of diﬀerential operators, 197
of the dual of a bivector, 196
of a 4-vector, 172
of Levi-Civita symbols, 196
of the Lorentz inner product, 192
of a vector, 172
of a world vector, 172
spinor map, 71
spinor representation, 145
type of, 145
spinorial object, 142, 293, 305
standard conﬁguration, 25
stereographic projection, 75
stress tensor, 111
subgroup
of the Lorentz group, 19, 20, 24
of transformations, 72, 138
summation convention, xi
symmetric linear transformation, 110
symmetrization, 168
synchronization, 2
lack of, 36
T
tangent space, 218, 219
tangent vector, 47, 217
temporal order, 2, 4, 34, 56
tensor product, 140
tensorial objects, 303
terminal point of a worldline, 87
3-vector
direction, 22
relative momentum, 81
velocity, 21, 52, 85
time
axis, 43
cone, 16
coordinates, 3
dilation, 22, 36
orientation, 16
in units of distance, 3
timelike curve
E-continuous, 281
smooth, 47
timelike straight line, 43
timelike vector, 12
future-directed, 16
past-directed, 16
timelike worldline, 47
topological manifold, 296
products of, 298
topology
Euclidean (or E-), 280
ﬁne, 279
path (or P-), 284
total 4-momentum, 87
total relativistic energy, 82
total world momentum, 87
trace, 109
trace free, 110
transformation equations, 40, 206, 246
transformation matrix, 13, 137
translation, 4, 60

324
Index
translation of a light ray, 61
lifts of, 62
twin paradox, 36
2-form, 120
U
uniformly moving charge, 125
unit vector, 8
unitary matrix, 72
universal covering manifold, 299
V
vector ﬁeld, 118
components of, 118
smooth, 118
velocity parameter, 27
velocity 3-vector, 21, 52, 85
velocity vector, 47, 217
version, 304
W
wave equation, 132
wave function, 142, 294, 305
wavelength of a photon, 84
weak interaction, 198
Weyl, 1
neutrino equation, 198
world acceleration, 51
world momentum
of a material particle, 81
of a photon, 84
world tensor, 136, 141
world vector, 169
worldline, 1
of a material particle, 47
of a photon, 4, 11
Z
Zeeman’s Theorem, 60, 227, 292

