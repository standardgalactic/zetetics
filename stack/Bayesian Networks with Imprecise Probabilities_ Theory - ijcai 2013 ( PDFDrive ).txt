From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Bayesian Networks with Imprecise
Probabilities: Theory and Applications to
Knowledge-based Systems and Classiﬁcation
A Tutorial by
Alessandro Antonucci, Giorgio Corani and Denis Mau´a
{alessandro,giorgio,denis}@idsia.ch
Istituto “Dalle Molle” di Studi sull’Intelligenza Artiﬁciale - Lugano (Switzerland)
IJCAI-13
Beijing, August 5th, 2013

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Just before starting . . .
Credal networks (i.e., Bayesian networks with imprecise probability)
are drawing interest from the AI community in 2013
ECSQARU 2013 Best Paper Award : Approximating Credal
Network Inferences by Linear Programming by Alessandro
Antonucci, Cassio de Campos, David Huber, and Marco Zaffalon
UAI ’13 Google Best Student Paper Award : On the Complexity
of Strong and Epistemic Credal Networks by Denis Mau´a, Cassio
de Campos, Alessio Benavoli, and Alessandro Antonucci
More info and papers at ipg.idsia.ch

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Outline (of the ﬁrst part)
A (ﬁrst informal, then formal) introduction to IPs
Reasoning with (imprecise) fault trees
From determinism to imprecision (through uncertainty)
Motivations and coherence
Credal sets
Basic concepts and operations
Modeling
Credal networks
Background on Bayesian networks
From Bayesian to credal networks
Modeling (observations, missing data, information fusion, . . .)
Applications to knowledge-based systems
Military decision making
Environmental risk analysis
(Imprecise) probabilistic description logic

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Reasoning: from Determinism to IPs
brake fails = [ pads ∨( sensor ∧controller ∧actuator ) ]
pads
fails
OR
gate
AND
gate
sensor
fails
controller
fails
actuator
fails
brake
fails
1
1
1
0
1
1
1
devices failures are independent

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Reasoning: from Determinism to IPs
brake fails = [ pads ∨( sensor ∧controller ∧actuator ) ]
pads
fails
OR
gate
AND
gate
sensor
fails
controller
fails
actuator
fails
brake
fails
1
.8
.8
.2
.64
= .2 × .64 + .8 × .64 + .2 × .36 =.712
.712
devices failures are independent

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Reasoning: from Determinism to IPs
brake fails = [ pads ∨( sensor ∧controller ∧actuator ) ]
pads
fails
OR
gate
AND
gate
sensor
fails
controller
fails
actuator
fails
brake
fails
1
[.8,1]
[.8,1]
[0,.2]
[.64,1]
[.64,1]
[.64,1]
with [.7, 1] instead
P(brake fails)∈[.49,1]
Indecision!
devices failures are independent

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Three different levels of knowledge
A football match between Italy and Spain
Result of Spain after the regular time? Win, draw or loss?
DETERMINISM
The Spanish goalkeeper
is unbeatable and Italy
always receives a goal
Spain (certainly) wins
P(Win)
P(Draw)
P(Loss)
=


1
0
0


UNCERTAINTY
Win is two times more
probable than draw, and
this being three times
more probable than loss
P(Win)
P(Draw)
P(Loss)
=


.6
.3
.1


IMPRECISION
Win is more probable
than draw, and this is
more probable than loss
P(Win) > P(Draw)
P(Draw) > P(Loss)
P(Win)
P(Draw)
P(Loss)
=
" α
3 + β + γ
2
α
3 + γ
2
α
3
#
∀α, β, γ such that
α > 0, β > 0, γ > 0,
α + β + γ = 1

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Three different levels of knowledge
DETERMINISM
UNCERTAINTY
IMPRECISION

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Three different levels of knowledge
DETERMINISM
UNCERTAINTY
IMPRECISION
INFORMATIVENESS

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Three different levels of knowledge
DETERMINISM
UNCERTAINTY
IMPRECISION
EXPRESSIVENESS

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Three different levels of knowledge
DETERMINISM
UNCERTAINTY
IMPRECISION
limit of inﬁnite amount
of available information
(e.g., very large data sets)
Propositional
(Boolean) Logic
Bayesian prob-
ability theory
Walley’s theory
of coherent
lower previsions
Natural Embedding (de Cooman)
small/incomplete data
expert’s (qualitative) knowledge
unreliable/incomplete observations

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
[. . . ] Bayesian inference will always be
a basic tool for practical everyday statistics ,
if only because questions must be answered
and decisions must be taken, so that a
statistician must always stand ready to upgrade
his vaguer forms of belief into precisely additive
probabilities
Art Dempster (in his foreword to Shafer’s book)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability: one word for two (not exclusive) things
Randomness
Variability captured through
repeated observations
De Moivre and Kolmogorov
Chances
Feature of the world
Aleatory or objective
Frequentist theory
Limiting frequencies
Partial knowledge
Incomplete information about
issues of interest
Bayes and De Finetti
Beliefs
Feature of the observer
Epistemic or subjective
Bayesian theory
Behaviour (bets dispositions)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Objective probability
X taking its values in (ﬁnite set) Ω
Value X = x ∈Ωas the output of an
experiment which can be iterated
Prob P(x) as limiting frequency
P(x) :=
lim
N→+∞
#(X = x)
N
Kolmogorov’s axioms follow from this
Probability as a property of the world
Not only (statistical and quantum)
mechanics, hazard games (coins,
dices, cards), but also economics,
bio/psycho/sociology, linguistics, etc.
But not all events can be iterated . . .
1
∀A ∈2Ω, 0 ≤P(A) ≤1
2
P(Ω) = 1
3
∀A, B ∈2Ω: A ∧B = ∅
P(A ∨B) = P(A) + P(B)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability in everyday life
Probabilities often pertains to singular events
not necessarily related to statistics

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Subjective probability
Probability p of me smoking
Singular event: frequency unavailable
Subjective probability
models (partial) knowledge of a subject
feature of the subject not of the world
two subjects can assess different probs
Quantitative measure of knowledge?
Behavioural approach
Subjective betting dispositions
A (linear) utility function is needed
Money?
Big money not linear!
Small, somehow yes
lottery tickets
∝
winning chance
∝
beneﬁt
inﬁnite number of tickets
makes utility real-valued

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
(Rationally) betting on gambles
Probabilities as dispositions to buy/sell gambles
Gambles as checks whose amount is
uncertain/unknown
This check has a
value of 100 EUR
if Alessandro is a smoker
zero otherwise
The bookie sells this gamble
Probability p as a price for the gamble
maximum price
100EUR
for which you buy the gamble
minimum price
100EUR
for which you (bookie) sell it
Interpretation + rationality produce axioms
0 EUR
100 EUR
95 EUR
Almost sure of
me smoking
8 EUR
Very doubtful
about me smoking

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
(Rationally) betting on gambles
Probabilities as dispositions to buy/sell gambles
Gambles as checks whose amount is
uncertain/unknown
This check has a
value of 100 EUR
if Alessandro is a smoker
zero otherwise
The bookie sells this gamble
Probability p as a price for the gamble
maximum price
100EUR
for which you buy the gamble
minimum price
100EUR
for which you (bookie) sell it
Interpretation + rationality produce axioms
0 EUR
100 EUR
120 EUR
Gambler’s sure loss
-12 EUR
Bookie’s sure loss

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
(Rationally) betting on gambles
Probabilities as dispositions to buy/sell gambles
Gambles as checks whose amount is
uncertain/unknown
This check has a
value of 100 EUR
if Alessandro is a smoker
zero otherwise
The bookie sells this gamble
Probability p as a price for the gamble
maximum price
100EUR
for which you buy the gamble
minimum price
100EUR
for which you (bookie) sell it
Interpretation + rationality produce axioms
0 EUR
100 EUR
95 EUR
55 EUR
Price for gamble
for me not smoking
You spend 150
EUR to (certainly)
win 100 EUR!

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Coherence and linear previsions
Don’t be crazy: choose prices s.t.
there is always a chance to win
(whatever the stakes set by the bookie)
Prices {PAi}N
i=1 for events Ai ⊆Ω, i = 1, . . . , N are coherent iff
max
x∈Ω
N
X
i=1
ci[IAi(x) −PAi] ≥0
Moreover, assessments {PAi}N
i=1 are coherent iff
Exists probability mass function P(X): P(Ai) = PAi
Or, for general gambles, linear functional P(fi) := Pfi
P(f) = P
x∈ΩP(x) ·f(x)
linear prevision
probability mass function
to be extended to a
coherent lower prevision
to be extended
to a credal set

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
(subjective, behavioural) imprecise probabilities
De Finetti’s precision
dogma
minimum
selling
price
P(x)
maximum
buying
price
P(x)
≡
Walley’s proposal for
imprecision
No strong reasons for that
rationality only requires
P(x) ≤P(x)
Avoid sure loss! With max buying prices P(A) and P(Ac),
you can buy both gambles and earn one for sure:
P(A) + P(Ac) ≤1
Be coherent! When buying both A and B, you pay P(A) + P(B)
and you have a gamble which gives one if A ∪B occurs:
P(A ∪B) ≥P(A) + P(B)
coherence self-consistency (beliefs revised if unsatisﬁed)
less problematic than a.s.l.

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
(Some) Reasons for imprecise probabilities
Reﬂect the amount of information on which probs are based
Uniform probs model indifference not ignorance
When doing introspection, sometimes indecision/indeterminacy
Easier to assess (e.g., qualitative knowledge, combining beliefs)
Assessing precise probs could be possible in principle, but not in
practice because of our bounded rationality
Natural extension of precise models deﬁned on some events
determine only imprecise probabilities for events outside
Robustness in statistics (multiple priors/likelihoods) and
decision problems (multiple prob distributions/utilities)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal sets (Levi, 1980) as IP models
Without the precision dogma, incomplete knowledge described
by (credal) sets of probability mass functions
Induced by a ﬁnite number of assessments (l/u gambles prices)
which are linear constraints on the consistent probabilities
Sets of consistent (precise) probability mass functions
convex with a ﬁnite number of extremes (if |Ω| < +∞)
E.g., no constraints ⇒vacuous credal set (model of ignorance)
K(X) =


P(X)

P
x∈ΩP(x) = 1
P(x) ≥0




From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Natural extension
Price assessments are linear constraints on probabilities
(e.g., P(f) = .21 means P
x P(x)f(x) ≥.21)
Compute the extremes {Pj(X)}v
j=1 of the feasible region
The credal set K(X) is ConvHull{Pj(X)}v
j=1
Lower prices/expectations of any gamble/function of/on X
P(h) =
min
P(X)∈K(X)
X
x∈X
P(x) · h(x)
LP task: optimum on the extremes of K(X)
Computing expectations (inference) on credal sets
Constrained optimization problem, or
Combinatorial optimization on the extremes space
(# of extremes can be exponential in # of constraints)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Lower-upper conjugacy
E.g., with events
P(A) =
min
P(X)∈K(X)
X
x∈A
P(x)
P(Ac) =
max
P(X)∈K(X)
X
x /∈A
P(x) =
max
P(X)∈K(X)
"
1 −
X
x∈A
P(x)
#
= 1 −P(A)
For gambles, similarly,
P(−f) = −P(f)
P(f) =
min
P(X)∈K(X)
X
x
P(x)f(x)
P(−f) =
max
P(X)∈K(X)
X
x
[−P(x)f(x)] = −
min
P(X)∈K(X)
X
x
P(x)f(x)
Self-conjugacy ≡single-point (precise) credal set ≡linear functional

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal Sets over Boolean Variables
Boolean X, values in ΩX = {x, ¬x}
Determinism ≡degenerate mass f
E.g., X = x ⇐⇒P(X) =
 1
0

Uncertainty ≡prob mass function
P(X) =

p
1 −p

with p ∈[0, 1]
Imprecision credal set
on the probability simplex
K(X) ≡

P(X) =

p
1 −p
 .4 ≤p ≤.7

A CS over a Boolean variable cannot
have more than two vertices!
ext[K(X)] =
 .7
.3

,
 .4
.6

P(x)
P(¬x)
P(X) =
 1
0


From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal Sets over Boolean Variables
Boolean X, values in ΩX = {x, ¬x}
Determinism ≡degenerate mass f
E.g., X = x ⇐⇒P(X) =
 1
0

Uncertainty ≡prob mass function
P(X) =

p
1 −p

with p ∈[0, 1]
Imprecision credal set
on the probability simplex
K(X) ≡

P(X) =

p
1 −p
 .4 ≤p ≤.7

A CS over a Boolean variable cannot
have more than two vertices!
ext[K(X)] =
 .7
.3

,
 .4
.6

P(x)
P(¬x)
P(X) =
 .7
.3


From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal Sets over Boolean Variables
Boolean X, values in ΩX = {x, ¬x}
Determinism ≡degenerate mass f
E.g., X = x ⇐⇒P(X) =
 1
0

Uncertainty ≡prob mass function
P(X) =

p
1 −p

with p ∈[0, 1]
Imprecision credal set
on the probability simplex
K(X) ≡

P(X) =

p
1 −p
 .4 ≤p ≤.7

A CS over a Boolean variable cannot
have more than two vertices!
ext[K(X)] =
 .7
.3

,
 .4
.6

P(x)
P(¬x)
P(X) =
 .4
.6


From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal Sets over Boolean Variables
Boolean X, values in ΩX = {x, ¬x}
Determinism ≡degenerate mass f
E.g., X = x ⇐⇒P(X) =
 1
0

Uncertainty ≡prob mass function
P(X) =

p
1 −p

with p ∈[0, 1]
Imprecision credal set
on the probability simplex
K(X) ≡

P(X) =

p
1 −p
 .4 ≤p ≤.7

A CS over a Boolean variable cannot
have more than two vertices!
ext[K(X)] =
 .7
.3

,
 .4
.6

P(x)
P(¬x)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal Sets over Boolean Variables
Boolean X, values in ΩX = {x, ¬x}
Determinism ≡degenerate mass f
E.g., X = x ⇐⇒P(X) =
 1
0

Uncertainty ≡prob mass function
P(X) =

p
1 −p

with p ∈[0, 1]
Imprecision credal set
on the probability simplex
K(X) ≡

P(X) =

p
1 −p
 .4 ≤p ≤.7

A CS over a Boolean variable cannot
have more than two vertices!
ext[K(X)] =
 .7
.3

,
 .4
.6

P(x)
P(¬x)
.4
.7
.6
.3

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Geometric Representation of CSs (ternary variables)
Ternary X (e.g., Ω= {win,draw,loss})
P(X) ≡point in the space (simplex)
No bounds to |ext[K(X)]|
Modeling ignorance
Uniform models indifference
Vacuous credal set
Expert qualitative knowledge
Comparative judgements: win is
more probable than draw,
which more probable than loss
Qualitative judgements:
adjective ≡IP statements
P(win)
P(draw)
P(loss)
P(X) =


.6
.3
.1


P(X)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Geometric Representation of CSs (ternary variables)
Ternary X (e.g., Ω= {win,draw,loss})
P(X) ≡point in the space (simplex)
No bounds to |ext[K(X)]|
Modeling ignorance
Uniform models indifference
Vacuous credal set
Expert qualitative knowledge
Comparative judgements: win is
more probable than draw,
which more probable than loss
Qualitative judgements:
adjective ≡IP statements
P(win)
P(draw)
P(loss)
K(X)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Geometric Representation of CSs (ternary variables)
Ternary X (e.g., Ω= {win,draw,loss})
P(X) ≡point in the space (simplex)
No bounds to |ext[K(X)]|
Modeling ignorance
Uniform models indifference
Vacuous credal set
Expert qualitative knowledge
Comparative judgements: win is
more probable than draw,
which more probable than loss
Qualitative judgements:
adjective ≡IP statements
P(win)
P(draw)
P(loss)
P0(x) =
1
|ΩX |
P0(X)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Geometric Representation of CSs (ternary variables)
Ternary X (e.g., Ω= {win,draw,loss})
P(X) ≡point in the space (simplex)
No bounds to |ext[K(X)]|
Modeling ignorance
Uniform models indifference
Vacuous credal set
Expert qualitative knowledge
Comparative judgements: win is
more probable than draw,
which more probable than loss
Qualitative judgements:
adjective ≡IP statements
P(win)
P(draw)
P(loss)
K0(X)
K0(X)=
(
P(X)

P
x P(x) = 1,
P(x) ≥0
)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Geometric Representation of CSs (ternary variables)
Ternary X (e.g., Ω= {win,draw,loss})
P(X) ≡point in the space (simplex)
No bounds to |ext[K(X)]|
Modeling ignorance
Uniform models indifference
Vacuous credal set
Expert qualitative knowledge
Comparative judgements: win is
more probable than draw,
which more probable than loss
Qualitative judgements:
adjective ≡IP statements
P(win)
P(draw)
P(loss)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Geometric Representation of CSs (ternary variables)
Ternary X (e.g., Ω= {win,draw,loss})
P(X) ≡point in the space (simplex)
No bounds to |ext[K(X)]|
Modeling ignorance
Uniform models indifference
Vacuous credal set
Expert qualitative knowledge
Comparative judgements: win is
more probable than draw,
which more probable than loss
Qualitative judgements:
adjective ≡IP statements
(Walley, 1991)
From natural language to
linear constraints on probabilities
extremely probable P(x) ≥0.98
very high probability P(x) ≥0.9
highly probable P(x) ≥0.85
very probable P(x) ≥0.75
has a very good chance P(x) ≥0.65
quite probable P(x) ≥0.6
probable P(x) ≥0.5
has a good chance 0.4 ≤P(x) ≤0.85
is improbable (unlikely) P(x) ≤0.5
is somewhat unlikely P(x) ≤0.4
is very unlikely P(x) ≤0.25
has little chance P(x) ≤0.2
is highly improbable P(x) ≤0.15
is has very low probability P(x) ≤0.1
is extremely unlikely P(x) ≤0.02

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Marginalization (and credal sets in 4D)
Two Boolean variables:
Smoker, Lung Cancer
8 “Bayesian” physicians,
each assessing Pj(S, C)
K(S, C) = CH {Pj(S, C)}8
j=1
j
Pj (s, c)
Pj (s, c)
Pj (s, c)
Pj (s, c)
1
1/8
1/8
3/8
3/8
2
1/8
1/8
9/16
3/16
3
3/16
1/16
3/8
3/8
4
3/16
1/16
9/16
3/16
5
1/4
1/4
1/4
1/4
6
1/4
1/4
3/8
1/8
7
3/8
1/8
1/4
1/4
8
3/8
1/8
3/8
1/8
Marginals elementwise (on extremes)
K(C) = CH
(X
s
Pj(C, s)
)8
j=1
1
2 ≤P(c) ≤3
4
(0,1,0,0)
(0,0,1,0)
(1,0,0,0)
(0,0,0,1)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal sets induced by probability intervals
Assessing lower and upper probabilities: [lx, ux], for each x ∈Ω
The consistent credal set is
K(X) :=


P(X)

lx ≤P(x) ≤ux
P(x) ≥0
P
x P(x) = 1



Avoiding sure loss implies non-emptiness of the credal set
X
x
lx ≤1 ≤
X
x
ux
Coherence implies the reachability (bounds are tight)
ux +
X
x′̸=x
lx ≤1
lx +
X
x′̸=x
ux ≥1

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Reﬁning assessments (when possible)
P(x)
P(¬x)
0
.5
1
0
.5
1
lx = P(x) = .6
ux = P(x) = .9
l¬x = P(¬x) = .5
u¬x = P(¬x) = .7
lx + l¬x ≥1 not avoiding sure loss!
The credal set is empty!

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Reﬁning assessments (when possible)
P(x)
P(¬x)
0
.5
1
0
.5
1
lx = P(x) = .6
ux = P(x) = .9
l¬x = P(¬x) = .5
u¬x = P(¬x) = .7
lx + l¬x ≥1 not avoiding sure loss!
The credal set is empty!
lx = P(x) = .2
ux = P(x) = .8
l¬x = P(¬x) = .5
u¬x = P(¬x) = .7

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Reﬁning assessments (when possible)
P(x)
P(¬x)
0
.5
1
0
.5
1
lx = P(x) = .2
ux = P(x) = .8
l¬x = P(¬x) = .5
u¬x = P(¬x) = .7
lx + l¬x = .7 ≤1
ux + u¬x = 1.5 ≥1
avoid sure loss
K(X) ̸= ∅
checking coherence
lx + u¬x = .9 ≤1 ok
l¬x + ux = 1.3 ≥1 no!
make it coherent
ux = .8 →u′
x = .5
lx = .2 →l′
x = .3

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability intervals are not fully general
K(X) = CH





.90
.05
.05

,


.80
.05
.15

,


.20
.20
.60

,


.10
.40
.50

,


.05
.80
.15

,


.20
.70
.10





lx := minP(X)∈K(X) p(x)
ux := minP(X)∈K(X) p(x)
these intervals avoid sure
loss and are coherent
[lx′, ux′] = [.05, .90]
[lx′′, ux′′] = [.05, .80]
[lx′′′, ux′′′] = [.05, .60]

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability intervals are not fully general
K(X) = CH





.90
.05
.05

,


.80
.05
.15

,


.20
.20
.60

,


.10
.40
.50

,


.05
.80
.15

,


.20
.70
.10





lx := minP(X)∈K(X) p(x)
ux := minP(X)∈K(X) p(x)
these intervals avoid sure
loss and are coherent
[lx′, ux′] = [.05, .90]
[lx′′, ux′′] = [.05, .80]
[lx′′′, ux′′′] = [.05, .60]
K(X) = CH





.05
.35
.60

,


.05
.80
.15

,


.15
.80
.05

,


.35
.05
.60

,


.90
.05
.05






From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability intervals are not fully general
K(X) = CH





.90
.05
.05

,


.80
.05
.15

,


.20
.20
.60

,


.10
.40
.50

,


.05
.80
.15

,


.20
.70
.10





lx := minP(X)∈K(X) p(x)
ux := minP(X)∈K(X) p(x)
these intervals avoid sure
loss and are coherent
[lx′, ux′] = [.05, .90]
[lx′′, ux′′] = [.05, .80]
[lx′′′, ux′′′] = [.05, .60]
K(X) = CH





.05
.35
.60

,


.05
.80
.15

,


.15
.80
.05

,


.35
.05
.60

,


.90
.05
.05






From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability intervals are not fully general
K(X) = CH





.90
.05
.05

,


.80
.05
.15

,


.20
.20
.60

,


.10
.40
.50

,


.05
.80
.15

,


.20
.70
.10





lx := minP(X)∈K(X) p(x)
ux := minP(X)∈K(X) p(x)
these intervals avoid sure
loss and are coherent
[lx′, ux′] = [.05, .90]
[lx′′, ux′′] = [.05, .80]
[lx′′′, ux′′′] = [.05, .60]
K(X) = CH





.05
.35
.60

,


.05
.80
.15

,


.15
.80
.05

,


.35
.05
.60

,


.90
.05
.05






From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probability intervals are not fully general
K(X) = CH





.90
.05
.05

,


.80
.05
.15

,


.20
.20
.60

,


.10
.40
.50

,


.05
.80
.15

,


.20
.70
.10





lx := minP(X)∈K(X) p(x)
ux := minP(X)∈K(X) p(x)
these intervals avoid sure
loss and are coherent
[lx′, ux′] = [.05, .90]
[lx′′, ux′′] = [.05, .80]
[lx′′′, ux′′′] = [.05, .60]
K(X) = CH





.05
.35
.60

,


.05
.80
.15

,


.15
.80
.05

,


.35
.05
.60

,


.90
.05
.05





P(x’)
P(x”)
P(x”’)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (few) data
Learning from data about X
Max lik estimate P(x) = n(x)
N
Bayesian (ESS s = 2) n(x)+st(x)
N
Imprecise: set of priors (vacuous t)
n(x)
N + s ≤P(x) ≤n(x) + s
N + s
imprecise Dirichlet model
(Walley & Bernard)
They a.s.l. and are coherent
Non-negligible size of intervals
only for small N
(Bayesian for N →∞)
P(win)
P(draw)
P(loss)
1957:
Spain vs.
Italy 5 −1
1973:
Italy vs.
Spain 3 −2
1980:
Spain vs.
Italy 1 −0
1983:
Spain vs.
Italy 1 −0
1983:
Italy vs.
Spain 2 −1
1987:
Spain vs.
Italy 1 −1
2000:
Spain vs.
Italy 1 −2
2001:
Italy vs.
Spain 1 −0
n(win)
n(draw)
n(loss)
=


4
1
3



From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (missing) data
Coping with missing data?
Missing at random (MAR)
P(O = ∗|X = x) indep of X
Ignore missing data
Not always the case!
Conservative updating
(de Cooman & Zaffalon)
ignorance about the process
P(O|X) as a vacuous model
Consider all the explanations
(and take the convex hull)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (missing) data
Coping with missing data?
Missing at random (MAR)
P(O = ∗|X = x) indep of X
Ignore missing data
Not always the case!
Conservative updating
(de Cooman & Zaffalon)
ignorance about the process
P(O|X) as a vacuous model
Consider all the explanations
(and take the convex hull)
1957:
Spain vs.
Italy 5 −1
1973:
Italy vs.
Spain 3 −2
1980:
Spain vs.
Italy 1 −0
1983:
Spain vs.
Italy 1 −0
1983:
Italy vs.
Spain 2 −1
1987:
Spain vs.
Italy 1 −1
2000:
Spain vs.
Italy 1 −2
2001:
Italy vs.
Spain 1 −0
2003:
Spain vs.
Italy ∗−∗
2011:
Italy vs.
Spain ∗−∗

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (missing) data
Coping with missing data?
Missing at random (MAR)
P(O = ∗|X = x) indep of X
Ignore missing data
Not always the case!
Conservative updating
(de Cooman & Zaffalon)
ignorance about the process
P(O|X) as a vacuous model
Consider all the explanations
(and take the convex hull)
K(X)
P(win)
P(draw)
P(loss)
1957:
Spain vs.
Italy 5 −1
1973:
Italy vs.
Spain 3 −2
1980:
Spain vs.
Italy 1 −0
1983:
Spain vs.
Italy 1 −0
1983:
Italy vs.
Spain 2 −1
1987:
Spain vs.
Italy 1 −1
2000:
Spain vs.
Italy 1 −2
2001:
Italy vs.
Spain 1 −0
2003:
Spain vs.
Italy ∗−∗
2011:
Italy vs.
Spain ∗−∗

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (missing) data
Coping with missing data?
Missing at random (MAR)
P(O = ∗|X = x) indep of X
Ignore missing data
Not always the case!
Conservative updating
(de Cooman & Zaffalon)
ignorance about the process
P(O|X) as a vacuous model
Consider all the explanations
(and take the convex hull)
K(X)
P(win)
P(draw)
P(loss)
1957:
Spain vs.
Italy 5 −1
1973:
Italy vs.
Spain 3 −2
1980:
Spain vs.
Italy 1 −0
1983:
Spain vs.
Italy 1 −0
1983:
Italy vs.
Spain 2 −1
1987:
Spain vs.
Italy 1 −1
2000:
Spain vs.
Italy 1 −2
2001:
Italy vs.
Spain 1 −0
2003:
Spain vs.
Italy ∗−∗
2011:
Italy vs.
Spain ∗−∗

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (missing) data
Coping with missing data?
Missing at random (MAR)
P(O = ∗|X = x) indep of X
Ignore missing data
Not always the case!
Conservative updating
(de Cooman & Zaffalon)
ignorance about the process
P(O|X) as a vacuous model
Consider all the explanations
(and take the convex hull)
K(X)
P(win)
P(draw)
P(loss)
1957:
Spain vs.
Italy 5 −1
1973:
Italy vs.
Spain 3 −2
1980:
Spain vs.
Italy 1 −0
1983:
Spain vs.
Italy 1 −0
1983:
Italy vs.
Spain 2 −1
1987:
Spain vs.
Italy 1 −1
2000:
Spain vs.
Italy 1 −2
2001:
Italy vs.
Spain 1 −0
2003:
Spain vs.
Italy ∗−∗
2011:
Italy vs.
Spain ∗−∗

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Learning credal sets from (missing) data
Coping with missing data?
Missing at random (MAR)
P(O = ∗|X = x) indep of X
Ignore missing data
Not always the case!
Conservative updating
(de Cooman & Zaffalon)
ignorance about the process
P(O|X) as a vacuous model
Consider all the explanations
(and take the convex hull)
K(X)
P(win)
P(draw)
P(loss)
1957:
Spain vs.
Italy 5 −1
1973:
Italy vs.
Spain 3 −2
1980:
Spain vs.
Italy 1 −0
1983:
Spain vs.
Italy 1 −0
1983:
Italy vs.
Spain 2 −1
1987:
Spain vs.
Italy 1 −1
2000:
Spain vs.
Italy 1 −2
2001:
Italy vs.
Spain 1 −0
2003:
Spain vs.
Italy ∗−∗
2011:
Italy vs.
Spain ∗−∗

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Basic operations with credal sets
Joint
PRECISE
Mass functions
P(X, Y)
IMPRECISE
Credal sets
K(X, Y)
Marginalization
P(X) s.t.
p(x)
=
P
y p(x, y)
K(X)
=

P(X)

P(x) = P
y P(x, y)
P(X, Y) ∈K(X, Y)

Conditioning
P(X|y) s.t.
p(x|y)
=
P(x,y)
P
y P(x,y)
K(X|y)
=
(
P(X|y)

P(x|y) =
P(x,y)
P
y P(x,y)
P(X, Y) ∈K(X, Y)
)
Combination
P(x, y) = P(x|y)P(y)
K(X|Y) ⊗K(Y)
=


P(X, Y)

P(x, y)=P(x|y)P(y)
P(X|y) ∈K(X|y)
P(Y) ∈K(Y)




From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Basic operations with credal sets (vertices)
Joint
Marginalization
Conditioning
Combination
IMPRECISE
Credal sets
K(X, Y)
K(X)
=

P(X)

P(x) = P
y P(x, y)
P(X, Y) ∈K(X, Y)

K(X|y)
=
(
P(X|y)

P(x|y) =
P(x,y)
P
y P(x,y)
P(X, Y) ∈K(X, Y)
)
K(X|Y) ⊗K(Y)
=


P(X, Y)

P(x, y)=P(x|y)P(y)
P(X|y) ∈K(X|y)
P(Y) ∈K(Y)



IMPRECISE
Extremes
= CH

Pj(X, Y)
	nv
j=1
=
CH

P(X)

P(x) = P
y P(x, y)
P(X, Y) ∈ext[K(X, Y)]

=
CH
(
P(X|y)

P(x|y) =
P(x,y)
P
y P(x,y)
P(X, Y) ∈ext[K(X, Y)]
)
=
CH


P(X, Y)

P(x, y)=P(x|y)P(y)
P(X|y) ∈ext[K(X|y)]
P(Y) ∈ext[K(Y)]




From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
An imprecise bivariate (graphical?) model
Two Boolean variables: Smoker,
Lung Cancer
Compute:
Marginal K(S)
Conditioning
K(C|S) := {K(C|s), K(C|s)}
Combination (marg ext)
K ′(C, S) := K(C|S) ⊗K(S)
Is this a (I)PGM?
Smoker
Cancer
j
Pj (s, c)
Pj (s, ¬c)
Pj (¬s, c)
Pj (¬s, ¬c)
1
1/8
1/8
3/8
3/8
2
1/8
1/8
9/16
3/16
3
3/16
1/16
3/8
3/8
4
3/16
1/16
9/16
3/16
5
1/4
1/4
1/4
1/4
6
1/4
1/4
3/8
1/8
7
3/8
1/8
1/4
1/4
8
3/8
1/8
3/8
1/8
(0,1,0,0)
(0,0,1,0)
(1,0,0,0)
(0,0,0,1)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probabilistic Graphical Models
aka Decomposable Multivariate Probabilistic Models
(whose decomposability is induced by independence )
X1
X2
X3
X4
X5
X6
X7
X8
global model
φ(X1, X2, X3, X4, X5, X6, X7, X8)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probabilistic Graphical Models
aka Decomposable Multivariate Probabilistic Models
(whose decomposability is induced by independence )
X1
X2
X3
X4
X5
X6
X7
X8
local model
φ(X1, X2, X4)
local model
φ(X2, X3, X5)
local model
φ(X4, X6, X7)
local model
φ(X5, X7, X8)
φ(X1, X2, X3, X4, X5, X6, X7, X8) = φ(X1, X2, X4) ⊗φ(X2, X3, X5) ⊗φ(X4, X6, X7) ⊗φ(X5, X7, X8)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probabilistic Graphical Models
aka Decomposable Multivariate Probabilistic Models
(whose decomposability is induced by independence )
X1
X2
X3
X4
X5
X6
X7
X8
undirected graphs
precise/imprecise Markov random ﬁelds

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probabilistic Graphical Models
aka Decomposable Multivariate Probabilistic Models
(whose decomposability is induced by independence )
X1
X2
X3
X4
X5
X6
X7
X8
directed graphs
Bayesian/credal networks

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Probabilistic Graphical Models
aka Decomposable Multivariate Probabilistic Models
(whose decomposability is induced by independence )
X1
X2
X3
X4
X5
X6
X7
X8
mixed graphs
chain graphs

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Independence
Stochastic independence/irrelevance (precise case)
X and Y stochastically independent: P(x, y) = P(x)P(y)
Y stochastically irrelevant to X: P(X|y) = P(X)
independence ≡irrelevance
Strong independence (imprecise case)
X and Y strongly independent: stochastic independence
∀P(X, Y) ∈ext[K(X, Y)]
Equivalent to Y strongly irrelevant to X: P(X|y) = P(X)
∀P(X, Y) ∈ext[K(X, Y)]
Epistemic irrelevance (imprecise case)
Y epistemically irrelevant to X: K(X|y) = K(X)
Asymmetric concept! Its simmetrization: epistemic indep
Every notion of independence admits a conditional formulation

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A tri-variate example
3 Boolean variables: Smoker, Lung Cancer, X-rays
Given cancer, no relation between smoker and X-rays
IP language: given C, S and X strongly independent
Marginal extension (iterated two times)
K(S, C, X) = K(X|C, S)⊗K(C, S) = K(X|C, S)⊗K(C|S)⊗K(S)
Independence implies irrelevance: given C, S irrelevant to X
K(S, C, X) = K(X|C) ⊗K(C|S) ⊗K(S)
Global model decomposed in 3 “local” models
A true PGM! Needed: language to express independencies
Smoker
Cancer
X-rays
K(C|S)
K(S)
K(X|C)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Markov Condition
Probabilistic model over set of variables (X1, . . . , Xn)
in one-to-one correspondence with the nodes of a graph
Undirected Graphs
X and Y are independent given Z
if any path between X and Y
containts an element of Z
Directed Graphs
Given its parents, every node is independent of
its non-descendants non-parents
X and Y are d-separated by Z if, along every path between
X and Y there is a W such that either W has converging
arrows and is not in Z and none of its descendants are in Z,
or W has no converging arrows and is in Z
X
Z1
Z2
Y
X
Z1
Z2
Y

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Bayesian networks
(Pearl, 1986)
Set of categorical variables X1, . . . , Xn
Directed acyclic graph
conditional (stochastic) independencies
according to the Markov condition:
“any node is conditionally independent
of its non-descendents given its parents”
A conditional mass function for each node
and each possible value of the parents
{P(Xi|pa(Xi)) , ∀i = 1, . . . , n , ∀pa(Xi) }
Deﬁnes a joint probability mass function
P(x1, . . . , xn) = Qn
i=1 P(xi|pa(Xi))
X1
X2
X3
X4

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Bayesian networks
(Pearl, 1986)
Set of categorical variables X1, . . . , Xn
Directed acyclic graph
conditional (stochastic) independencies
according to the Markov condition:
“any node is conditionally independent
of its non-descendents given its parents”
A conditional mass function for each node
and each possible value of the parents
{P(Xi|pa(Xi)) , ∀i = 1, . . . , n , ∀pa(Xi) }
Deﬁnes a joint probability mass function
P(x1, . . . , xn) = Qn
i=1 P(xi|pa(Xi))
X1
X2
X3
X4
Temperature
Spain result
Goalkeeper’s
ﬁtness
Attackers’
ﬁtness
E.g., given temperature,
ﬁtnesses independent
P(X1)
P(X3|x1)
P(X2|x1)
P(X4|x3, x2)
P(x1, x2, x3, x4) =
P(x1)P(x2|x1)P(x3|x1)P(x4|x3, x2)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Credal networks
(Cozman, 2000)
Generalization of BNs to imprecise probabilities
Credal sets instead of prob mass functions
{P(Xi|pa(Xi))} ⇒{K(Xi|pa(Xi))}
Strong (instead of stochastic) independence
in the semantics of the Markov condition
Convex set of joint mass functions
K(X1, . . . , Xn) = CH
n
P(X1, . . . , Xn)
o
P(x1, . . . , xn) = Qn
i=1 P(xi|pa(Xi))
∀P(Xi |pa(Xi )) ∈K(Xi |pa(Xi ))
∀i = 1, . . . , n
∀pa(Xi )
Every conditional mass function takes values
in its credal set independently of the others
CN ≡(exponential) number of BNs
X1
X2
X3
X4
Temperature
Spain result
Goalkeeper’s
ﬁtness
Attackers’
ﬁtness
K(X1)
K(X3|x1)
K(X2|x1)
K(X4|x3, x2)
E.g., K(X1) deﬁned by
constraint P(x1) > .75,
very likely to be warm

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Updating credal networks
Conditional probs for a variable of interest Xq given
observations XE = xE
Updating Bayesian nets is NP-hard
(fast algorithms for polytrees)
P(xq|xE) = P(xq, xE)
P(xE)
=
P
x\{xq,xE}
Qn
i=1 P(xi|πi)
P
x\{xE}
Qn
i=1 P(xi|πi)
Updating credal nets is NPPP-hard,
NP-hard on polytrees
(Mau´a et al., 2013)
P(xq|xE) =
min
P(Xi|πi)∈K(Xi|πi)
i=1,...,n
P
x\{xQ,xE}
Qn
i=1 P(xi|πi)
P
x\{xQ}
Qn
i=1 P(xi|πi)
XE
Xq
.21 ≤P(Xq|xE ) ≤.46

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Medical diagnosis by CNs (a simple example of)
Five Boolean vars
Conditional
independence
relations by a DAG
Elicitation of the local
(conditional) CSs
This is a CN
speciﬁcation
The strong extension
K(S, C, B, X, D) =
CH







P(S, C, B, X, D)

P(s, c, b, x, d)=P(s)P(c|s)P(b|s)P(x|c)P(d|c, b)
P(S) ∈K(S)
P(C|s) ∈K(C|s), P(C|¬s) ∈K(C|¬s)
. . .







Cancer
Bronchitis
Smoker
Dyspnea
X-Rays
P(s)∈[.25, .50]
P(c|s)∈[.15, .40]
P(c|¬s) ∈[.05, .10]
P(x|c) ∈[.90, .99]
P(x|¬c) ∈[.01, .05]
P(b|s) ∈[.30, .55]
P(b|¬s) ∈[.20, .30]
P(d|c, b) ∈[.90, .99]
P(d|¬c, b) ∈[.50, .70]
P(d|c, ¬b) ∈[.40, .60]
P(d|¬c, ¬b) ∈[.10, .20]

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Decision Making on CNs
Update beliefs about Xq (query)
after the observation of xE (evidence)
What about the state of Xq?
BN updating: compute P(Xq|xE)
State of Xq: x∗
q = arg maxxq∈ΩXq P(xq|xE)
CN updating: compute K(Xq|xE)?
Algorithms only compute P(Xq|xE)
State(s) of Xq by interval dominance
Ω∗
Xq =
n
xq
 ̸ ∃x′
q s.t. P(x′
q|xE) > P(xq|xE)
o
More informative criterion: maximality
n
xq
 ̸ ∃x′
q s.t. P(x′
q|xE) > P(xq|xE)∀P(Xq|xE) ∈K(Xq|xE)
o
Maximality can be computed with an
auxiliary dummy child and standard
updating
(Antonucci & de Campos,
Spain wins with high temperature?
.0
.5
1.0
X4 = W
X4 = D
X4 = L

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Decision Making on CNs
Update beliefs about Xq (query)
after the observation of xE (evidence)
What about the state of Xq?
BN updating: compute P(Xq|xE)
State of Xq: x∗
q = arg maxxq∈ΩXq P(xq|xE)
CN updating: compute K(Xq|xE)?
Algorithms only compute P(Xq|xE)
State(s) of Xq by interval dominance
Ω∗
Xq =
n
xq
 ̸ ∃x′
q s.t. P(x′
q|xE) > P(xq|xE)
o
More informative criterion: maximality
n
xq
 ̸ ∃x′
q s.t. P(x′
q|xE) > P(xq|xE)∀P(Xq|xE) ∈K(Xq|xE)
o
Maximality can be computed with an
auxiliary dummy child and standard
updating
(Antonucci & de Campos,
P(X4|x1) =


.3
.5
.2


Spain wins with high temperature?
.0
.5
1.0
X4 = W
X4 = D
X4 = L
P(X4|x1) ∈
[.3, .6]
[.4, .7]
[.1, .2]

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A military application: no-ﬂy zones surveillance
Around important potential targets
(eg. WEF, dams, nuke plants)
Twofold circle wraps the target
External no-ﬂy zone (sensors)
Internal no-ﬂy zone (anti-air units)
An aircraft entering the zone
(to be called intruder)
Its presence, speed, height, and
other features revealed by the
sensors
A team of military experts decides:
what the intruder intends to do
(external zone / credal level)
what to do with the intruder
(internal zone / pignistic level)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A military application: no-ﬂy zones surveillance
Around important potential targets
(eg. WEF, dams, nuke plants)
Twofold circle wraps the target
External no-ﬂy zone (sensors)
Internal no-ﬂy zone (anti-air units)
An aircraft entering the zone
(to be called intruder)
Its presence, speed, height, and
other features revealed by the
sensors
A team of military experts decides:
what the intruder intends to do
(external zone / credal level)
what to do with the intruder
(internal zone / pignistic level)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A military application: no-ﬂy zones surveillance
Around important potential targets
(eg. WEF, dams, nuke plants)
Twofold circle wraps the target
External no-ﬂy zone (sensors)
Internal no-ﬂy zone (anti-air units)
An aircraft entering the zone
(to be called intruder)
Its presence, speed, height, and
other features revealed by the
sensors
A team of military experts decides:
what the intruder intends to do
(external zone / credal level)
what to do with the intruder
(internal zone / pignistic level)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A military application: no-ﬂy zones surveillance
Around important potential targets
(eg. WEF, dams, nuke plants)
Twofold circle wraps the target
External no-ﬂy zone (sensors)
Internal no-ﬂy zone (anti-air units)
An aircraft entering the zone
(to be called intruder)
Its presence, speed, height, and
other features revealed by the
sensors
A team of military experts decides:
what the intruder intends to do
(external zone / credal level)
what to do with the intruder
(internal zone / pignistic level)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A military application: no-ﬂy zones surveillance
Around important potential targets
(eg. WEF, dams, nuke plants)
Twofold circle wraps the target
External no-ﬂy zone (sensors)
Internal no-ﬂy zone (anti-air units)
An aircraft entering the zone
(to be called intruder)
Its presence, speed, height, and
other features revealed by the
sensors
A team of military experts decides:
what the intruder intends to do
(external zone / credal level)
what to do with the intruder
(internal zone / pignistic level)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
A military application: no-ﬂy zones surveillance
Around important potential targets
(eg. WEF, dams, nuke plants)
Twofold circle wraps the target
External no-ﬂy zone (sensors)
Internal no-ﬂy zone (anti-air units)
An aircraft entering the zone
(to be called intruder)
Its presence, speed, height, and
other features revealed by the
sensors
A team of military experts decides:
what the intruder intends to do
(external zone / credal level)
what to do with the intruder
(internal zone / pignistic level)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Identifying intruder’s goal
Four (exclusive and exhaustive) options for intruder’s goal:
renegade
provocateur
damaged
erroneous
This identiﬁcation is difﬁcult
Sensors reliabilities are affected by geo/wheather conditions
Information fusion from several sensors

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Why credal networks?
Why a probabilistic model?
No deterministic relations between the different variables
Pervasive uncertainty in the observations
Why a graphical model?
Many independence relations among the different variables
Why an imprecise (probabilistic) model?
Expert evaluations are mostly based on qualitative judgements
The model should be (over)cautious

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Network core
Intruder’s goal and features
as categorical variables
Independencies depicted by a
directed graph (acyclic)
Experts provide
interval-valued probabilistic
assessments, we compute
credal sets
A (small) credal network
Complex observation
process!
Intruder’s
Goal
Type of
Aircraft
Height
Changes
Transponder
Height
Reaction
to ATC
Absolute
Speed
Reaction
to ADDC
Reaction to
Interception
Flight Path
P(Baloon|Renegade)
∈[.2, .3]

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Observations modelling and fusion
Each sensor modeled by an
auxiliary child of the (ideal)
variable to be observed
P(sensor|ideal) models
sensor reliability
(eg. identity matrix = perfectly
reliable sensor)
Many sensors? Many
children!
(conditional independence
between sensors given the
ideal)
Speed
(ideal)
Speed
(3D radar)
Speed
(2D radar)
Speed (air
observation)
Speed
(ground)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
The whole network
A huge multiply-connected credal network
Efﬁcient (approximate) updating with GL2U

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Simulations
Simulating a dam in the Swiss Alps, with no
interceptors, relatively good coverage for
other sensors, discontinuous low clouds
and daylight
Sensors return:
Height = very low / very low / very low / low
Type = helicopter / helicopter
Flight Path = U-path / U-path / U-path / U-path / U-path / missing
Height Changes = descent / descent / descent / descent / missing
Speed = slow / slow / slow / slow / slow
ADDC reaction = positive / positive / positive / positive / positive / positive
We reject renegade and damaged, but
indecision between provocateur and
erroneous
Assuming higher levels of reliability
The aircraft is a provocateur!
SIMULATION #1
renegade
provocateur
erroneous
damaged
0
1
2
1

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Simulations
Simulating a dam in the Swiss Alps, with no
interceptors, relatively good coverage for
other sensors, discontinuous low clouds
and daylight
Sensors return:
Height = very low / very low / very low / low
Type = helicopter / helicopter
Flight Path = U-path / U-path / U-path / U-path / U-path / missing
Height Changes = descent / descent / descent / descent / missing
Speed = slow / slow / slow / slow / slow
ADDC reaction = positive / positive / positive / positive / positive / positive
We reject renegade and damaged, but
indecision between provocateur and
erroneous
Assuming higher levels of reliability
The aircraft is a provocateur!
SIMULATION #2
renegade
provocateur
erroneous
damaged
0
1
2
1

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
The CREDO software
A GUI software for CNs developed by IDSIA for Armasuisse
Designed for military decision making
but an academic version to be released by the end of 2013

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Decision-Support System for Space Security
Variable of interest: Political acceptability (acceptable / unacceptable)
Observed features
Space pillar: possible states
SATCOM (command, control,
communication and computer
systems dependent on
satellites communication),
ISR (synchronized and
integrated planning) and SSA
(ability to obtain information
and knowledge about the
space beyond the Earth
atmosphere).
Type of partner: ally, peer and
questionable.
Partner capability: most
advanced, average and new
to space.
Intermediate variables
Access sharing: C2 payload
and raw data (ability to directly
manage the beam), raw data
only and no direct access.
Compensation: in-kind, small,
medium and large
compensation.
Purpose limitation: peaceful
and non-economic, peaceful
only and no limitations.
Geographical limitation:
peace-keeping exclusion,
partner exclusion and no
limitations.

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Preventing inconsistent judgements
E.g., two states of X cannot be both “likely”
(as this means P(x) > .65, P
x P(x) > 1).
Reachability constraints
X
x∈ΩX \{x′}
P(x) + P(x′)
≤1,
(1)
X
x∈ΩX \{x′}
P(x) + P(x′)
≥1.
(2)
Judgement speciﬁcation is sequential, the software displays only
consistent options

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
NATO Multinational Experiment 7
Concerned with protecting our access to the global commons.
During the ﬁnal meeting a group of six subject matter experts
(divided into two groups) developed its own conclusions about
political acceptability for 27 scenarios
Human experts reasoning vs. (almost) automatic reasoning with
credal networks (quantiﬁed by expert knowledge)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Group A
Group B

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Most Likely
Very Likely
Likely
Fifty-Fifty
Unlikely
Very Unlikely
Most Unlikely
Favourable
Neutral
Unfavourable
Group B
Group A

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
SATCOM (Group A+B)
ADVANCED
ALLY
A
U
AVERAGE
A
U
NEWBIE
A
U
PEER
A
U
A
U
A
U
QUEST.
A
U
A
U
A
U

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Experiment conclusions
27 vignettes
A and B agree on a single answer 18
A and B agree on suspending judgement 3
A suspend , B not or vice versa 5
A and B disagree 1
Good agreement, not-too-imprecise outputs, results consistent
with human conclusions

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Environmental example: debris ﬂows hazard
assessment
Debris ﬂows are very destructive natural hazards
Still partially understood
Human expertize is still fundamental!
An artiﬁcial expert system supporting human experts?

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Causal modelling
Movable
Thickness
Theoretical
Thickness
Available
Thickness
Granulometry
Water Dep.
Local Slope
Stream
Index
Peak Flow
Channel
Width
Area
Effective
Intensity
Rainfall
Duration
Critical
Duration
Response
Function
Geomorph.
Eff Soil
Capacity
Rainfall
Intensity
Max Soil
Capacity
Soil
Moisture
Landuse
Soil Type
Permeability
Geology

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Debris ﬂow hazard assessment by CNs
Extensive simulations in a debris ﬂow prone watershed
Acquarossa Creek Basin (area 1.6 Km2, length 3.1 Km)
0
300
600
900
1'200
150
Meters

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
Debris ﬂow hazard assessment by CNs
Extensive simulations in a debris ﬂow prone watershed
Acquarossa Creek Basin (area 1.6 Km2, length 3.1 Km)
GG
GG
GG
GG
GG
GG
GG
GG
GG
GG
GGGG
GGGGGGGGGGG
GGG
GGG
GG
GG
GG
GGG
GGGGG
GG
G
GG
G
GG
G
GG
G
GG
G
GG
G
GG
G
GGG
G
GGG
G
GGGGGGGGGGGGGG
G GGGG
GGGGG
GG
GGG
GG
GGG
GG
G
GG
G
GG
G G
GGGGGGGGGGGG
GGGGGGG
GGGG
GGG
GG
GGG
GG
GGG
GG
G
G
GG
G
G
GG
G
GG
GG
GG
G
GG
GG
GG
GG
GG
G
GG
GG
G
GG
GG
GG
GG
GGGG
GG
GG
GGG
GG
GG
GG
GG
GG
GG
GG
GGG
GG
GG
G
GGGG
GG
GG
GG
GGGG
GG
GG
GGG
GG
G
GG
GGG
GG
GG
GG
GG
GG
GG
GG
GGG
GG
GG
GG
GG
GG
GG
GG
GGG
GG
GG
GG
GG
GG
GG
G GGG
GGG
GG
GGG
GGGGGGGG
GG
GG
G
GG
GGG
GG
GG
GGGGGG
GG
GG
G
GGG
GG
G
GG
GG
GG
GG
G
GG
G
GG
GG
G
GG
GG
GG
GG
G
GG
GG
GG
GG
G
GG
GG
GG
GG
G
GG
GG
GG
GG
G
GG
G
GG
GG
GG
G
GG
G
GG
G
GG
GG
GG
GG
G
GG
GG
GG
GG
G
GG
G
GG
GG
GG
GG
GG
GGGG
G
GG
GG
GG
GG
G
GGGG
G
GG
GG
GG
GG
GG
GGGG
G
GG
GG
GG
GGG
G
GGGGG
GG
GG
GGG
GG
G
GGGG
G
GGGG
G
GG
GGGG
GG
GG
GG
GG
G
GGG
G
GG
GG
G
GGG
GG
GGG
GG
GG
GG GGGGGGG
GG
G
GG
G
GGGGGGGGGGG
GG
GG
GG GGG
GG
GG
GG
GG
GGGG
GG
GG
GG GGGG
GG
G
GG
G
GGGG
GGGGG
G
GGGG GGGG
GG
GG GG
GG
GGG
GGGG
G
GGGGG GGGG
GG
GG GG
GG
GG
GG
G
G
GGGG
GG
GG GG
G
GG
GG
GG
G
GG
GGGG
GG
GG GG
G
GG
GG
GG
G
GG
GGGG
GG
GG GG GG
G
GG
GG
GG
G
GG
GGGGG
GG
GG GG GGG
G
GG
GG
GG
G
GG
GGG
GG
GG GG GG
G
GG
GG
GG
G
GG
GGG
GG
GG GG GG
GG
GG
GG
GG
G
GG
GGG
GG
GG GG GG
GG
GGGG
GG
GG
G
GG
GGGGGGG
GGG
GG GG GG
GG
GG
GG
GG
GG
GG
GGGGGGG
GGG
GG GG GG
GG
GG
GG
GG
G GG
GG
GGGGGG
GG
GG GGGGGGG
GGG
GG
GG
GG
GG GGG
GG
GGGGGG
GGG
GG GGGGGG
G
GG
GG
GG
GGGGG
GG
GGGGGG
GG
GG GGGG
G GGGGGGGGGGGGGGGG
GG
GG
GGGGG
GG
GGGGGG
GGG
GG GGGG
GGGGG
GG
GG
GGGGG
GG
GGGGGG
G
GG GGGG
GGG
GG
G
GGGGG
GG
GGGGGG
GG
GGG GGGG
GGG
GG
GG
GGGG
GG
GGGGGG
GG
GGG GGGG
GGG
GGG
GG
GG
GG
GGGGGG
GG
GG GGGG
GGG
G
GG
GG
GG
GGGGGG
GG
GG GGGG
G
GG
GG
GGG
GG
GGGGGG
GG
GGG GGGG
GG
GG
GG
GG
GG
GGGGGG
G
GGG GGGG
G
GG
GG
GGG
GG
GGGGGG
GG
GGGGGGG
G
G
GG
GG
GG
GGGGGG
GG
GGGGGG
G
G
GG
GGG
GG
GGGGGG
GG
GGGGGG
G
GG
GG
GG
GG
GGGGG
GG
GGGGG
GG
GG
GG
GGGGGGGGGGG
GG
GGGGGG
GG
GGGGG
G
GG
GG
GGGG
GG
GGGGGGG
GGGGG
GGGGG
G G
GG
GG
GGGGGGGGGGGGGGGGGG
GG
GG GGGG
GGG
GGGGGG
GG GGG
GG
GGGGGGGGGGGGGGGGGGGGGGGGGGGG
GG
GG GGGG
GG
GGGGG
GGGG
GG
GGG
GG GGG GGGG
GGGG
GGGG
GGGGG
GG
GGG
GG GG GG GGGG
GG
GGG
GGG
GG
GGGGGGGGGGG
GGGGGGGGGG GG GGGG
GG
GG
GGG
GG
GGG
GGGG
GGG GGGG
GGGG
G
GG
GG
GG
GGG
G GGGG
GGGG
G
G
GGG
GG
GG
GG GGGG
GG
GG
GG
G
GG
GG
GG GGGG
GG
G
GG
GG
GG
GG
GG GGGG
GG
GG
GGG
GG
GG
GG
GG GGGG
GG
G
G
G
GG
GG
GG GGGG
GGG
GGG
G
GG
GGG
GG
G GGGGG
GG
GGG
G
GG
GG
GG
GG GGGG
GG
GGG
G
GG
GGG
GG
GG GGGG
GG
GGG
G
GGG
GGG
GGG
GG GGGG
GGG
GGG
G
GGG
GG
GGG
GG GGGG
GG
G
G
GGGGG
GGG
GGGG
GG GGGG
GG
GG
G
GGG
GGG
G
GG GGGG
GG
G
G
GG
GG
GG
GG
G GGGG
GG
G
GG
G
G
GGG
GG
GG
GGGGGGG
GGG
G
GG
G
GG
GGG
GG
GG
GGG GGGG
GG
GG
GG
GG
GG
G
GG
GG
G GGG GGGG
GG
GG
GG
G
GG
GG
GG
GGGGGGGGGGGGGGGGGGG GGGG
GG
G
GG
G
GG
GG
GG
GG
GGGG
GGGGGGGGGGGGGGGGGGG
GG
GGGGG
GG
G
G
G
GG
GG
GGGG
GGGGGGGGGGG GGG
GG
GG
GG
GG
GG
GG
GGGGG
GG
GG
GG
GG
GG
GG
GG
G
G
GGGG
GGGG
GG
GG
G
GG
GG
GG
G
GGGGG
GGGG
GG
GG
GG
G
GG
GG
GG
GG
GG
GG
GG
GG
GG
G
GG
GG
GG
G
GG
GGG
GG
GG
GG
GG
G
G
G
GG
GG
GG
GG
GG
GG
GG
GG
G
G
GG
GG
GGGGGGG
GGGGGGGGGGGGGG
GGGGG
GG
GG
GG
GG
G
G
G
GG
GGGG
GGG
G
GG
GG
GGGGG
GG
GG
GG
GG
G
GG
GGGGG
GG GGGGGGGGGGGGGGGG
GG
GGGG
GG
GG
G
G
GG
GGGGGGG
GG
GG GG
GGG
GGG
GG
GG
GG
GG
GG
GGG
GG
GG GG
GGGGGGGG
GG
GGG
GGG
G
G
GG
GG
GG
G
GG GG
G
GG
G
G
G
GG
GG
GG
GG
G
GG GGG
GG
GG
GG
GG
G
GG
GG
GG
GG
GG
GG GG
GG
GG
G
G
G
GG
GG
GG
GG
G
G
GG GG
GG
GG
GG
G
G
GG
GG
GG
GGG
G
G
GG GG
G
GG
G
GGG
GG
GG
GG
GG
GG
G
G GG
GGGGG
GGG
GGG
G
GGG
GG
GG
GG
GG
GG
G
G G
G
GGGGGGG
GG
G
G
G
GG
GG
GG
GG
GG
G
G GG
GGGGGGGGGG
GG
GG
GG
GG
GG
GG
GG
GG
GG
GG
GG
G G
GGG
GG
GG
GG
GG
GG
GG
GG
G
GG
GGGGGGGG
G
GGGG
GGGGGGGGGGGGGG
GGG
GGGG
G
G
GG
GG
GG
GGG
GG
GGGGGG
G
G
GG G
GGGGGGGGGGGGG
GG
GG
GG
GG
GG
GG
GG GGG
GG
GGGGGGGG
GG
G
GG G
GGG
GG
GG
GG
GGG
G
GG
GGG
G GGG
GGG
GGG
GG
GG
G GG
GG
GG
GGGGGG
GG
GGGG
GG
GG
G
GG GG
GGG
GG
GG
G
GG GG
GGGGG
GG
GGG
GG
GGGGG
G
GG
G
GG GG
GGG
GGG
GG
GG
G GG
GGG
GG
GGG
GG
GGG
GG
GG
GG
GG GG
GGG
GG
GG
GG
GGGG
GGGG
GGG
GGG
GGGG
GGG
GG
GG
G
GG GG
GG
GGG
GG
GG
GGGG
GG
GGGGG
GGGGGGGGGGGGGGG
GGG
GGG
G
GG
G GG GG
GG
GG
GGG
G
GGGG
GG
GGGGGG
GGGG
GGGGGGGGGGGGGGGGGGGGGGGGG
GG
GG
GG GG GG
GG
GGG
G
G
GGGG
GGGGGGGGGG
GGGGGG
GGGGGGGGGGGGGG
GG GG
GG
GGG
G GG GG
GG
GG
G
G
GGGGGG
GGG
GGGGGGG
GGGGGG
GGGGGGGG
GG G
GGGGGGGGGG
GG
G
GGG
G GGGGGG
GG
GGG
G
G
GGG
GGGGG
GGG GGG
GGGGGGGGGGGGGGGGGGG GGG
GGGGGGGGG
GGGGGGGGGGGGGG
GG
GG
GGGGG
GGGGGGGG
GG
GG
G
G
GGG
GG
GGG
GGG
GG
GGGGGGGGGGGGGGGGGGGGGGGG
GGG
GG
GG
GGGG
GGGGG
GG
GGGG
G
G
GGG
GG
GGG
GGG
GG
GG
GG
G
GGGG
GGGG
GG GGGGGGG
G
G
G
GG
GG
GGGGGGGGGG
GG
GG
GGGG
GG
GGGG
GGGGG
GG GGG
G
G
GG
GG
GGG
GG
GG
GGG
GG
GGGG
GGG
GGG GGGGGGGG
G
G
GG
GG
GGG
GGGGG
GG
GG
G
GGGG
GGGGG
GGGGGGGGGGG
G
G
GG
GGGG GGGGG
GG
GG
G
GGGG
GG
GGG
GG
GG
GG
GG GGG
G
GG
G
GGGGG
GG
GGG
GG
GG
GG
G
GG GG
G
GG
GG
GGGGG
GG
GGGGGGGGGG
GG
GG
G
GG
GG GG
G
GGGGGGG
G
GGGG
GG
GG
GGG
GG
G
GG
GG GG
G
GGG
GG
GGGG
GGG
GG
G
GGG
G
GG
GGGGGG GGG
GG
GG
G
GG
GGGGG
G
G
GG
G
G
G
GG
GG
GG
G
GG
GG
GG
GGGG
GG
GG
GG
G
G
G GG
GG
GG
G
G
GG
G
GG
GGGG
GG
G
GG
GG
G
GG GG
GG
GG
GG
GGGGG
GG
G
GG
GGGG
GG
GG GG
GG
G
GGGGGG
GGGGGGGGGGGGG
GGG
G
GGGGG
GG
G
GG
GGG
GG
GGGGGGGG GGG
GG
G GGGGGGGG
GGG
GGGGGG GG
G
GGG
GG
G
GG
GGGG
GG GGG GGGGGGG
GG
G GGGGG
GGG
GG GG
GGGGG
G
GG
GG
G
GG
GGGG
GGGGGGGGGG
GG
G GGGG
GGG
GGGGGG
GGG
GGG GG
GG
G
GG
GGG
GGGGGGGG
GG
GGGGG
GGG
GGG
GGGGGGGGGGGGGGGGG
GG
GG
GG
G
GG
GGGG
GG
GG
GGGGG
GGG
GGG
GG
GG
GG
GG
GG
GG
GGGG
GG
GG
GGGGGGGGGGGG
GGG
GGG
GG
GG GGG
GG
G
G
GGG
GGG
GG
GGGGGGG
GGG
GGGGGGG
GG
GGG
G
GG
G GGGGGGG GGGGG
GG
GG
GGGGGG
GGG
GGGG
GG
G
GG
GG
GGGGGGGG GGGGGGGGG
GG
GG
GG
GGGGGGGG
GGG
G GGG GG
G
GG
GG
GG
GGGGGGGGGGGGG
GGGGGGGGGGGGGG
GG
GGGGGGGGGGG
GGGGGG
GG
GG GGGGGGGGGGGGGGGGGGG
GG
GG
GG
GGGG
GGGGGGG
GGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGG
GGGGGGGG
GG
GG
GGG
GGG
GG
GG
GG
GG
GG
GGG
GGGGGGGGGGGGGGGGGGGGG
GG
GG
G
GG
GGG
GGG
GG
GG
GGG
GGG
GGGGGGG
GG
G
GG
G
GGGGGGGGGGGGG
GG
G
GGGGG
GG
GG
GGGGGGGGGGGGGGGGGGGGGG
GGGG
GG
G
GGG
GGGGGGGGGGGG
GGGGGGGGGGGG
GG
G
GG
GG
GGGGGGGGG
GGG GGGGGGGGGGGGGG
GGGG
GG
G
GGGGGGGGG
GGGGGGGGGGGGG
GG
GG
GGGGGGGGGGGGGGGGG
G
GGG
GGGGGGGGGGGGGGGGGGG
GG
GG
GGGG
G
GG
GG GG
GGGGG
GG
GG
GG
G
GGGGG
GG
GG
GG
GG
GG
G GGGGGGGGGGGGGGGGGGGGGG GGGG
GG
GGG
G
GG
GG
GG
GGGGGGGG
GG
GG
G
G
G
GG
GGGGGGGG
GG
G
GG
GG
G
GG
GGGG
GG
GG
GG
G
G
GG
G
G
G
GG
GG
G
GG
GGGGGGGGGGGGG
GGG
GG
GG
G
G
G
GGG
G
GG
GG
GG
G
GGGGGGGGGGG
GGGG
GGGGGGGGGGGG
GGG
GG
GG
GG
G
G
G
G
GG
GG
GGG
G
GGGGGGGGG
GGGGGGGGGGGGGGGGGG
GGG
GGG
GGG
GG
G
GG
G
G
G
GG GG
G
G
GGG GG
GGGGGGGGGGGGGGGG
GGG
GGGG
GGGGGG
GGG
G
GG
G
G
G
GGGGGGGG
G
G GGG
GG
GGGGGG
GG
GGGGGGGGGGGGGGGGGGGGGGGGGGG
GG
GGG
G
GG
GG
G
G
G GGG GGGGGGGGGGGGGGG
GG GG
GGGG
GG
GG
GG
GG
GGGGGG
G
GG
G
G
G GGGGGG
GGG
GGGG
GGGG
GG
GG
GG
GG
GG
GG
G
G
G
GGG
GGGGGGGGGG
GGG
GGGG
GG
GGG
GG
GG
G
GG
G
G
G
G
GGGGGGG
GGGG
GGGGGGGG
GGGGGGGGGGGGGGG
GGGGG GGGGGGGGGGGGGG
GG
G
GG
G
G
G
G
G GGGGGGGGGGGGGG
GGGG
GG GGG
GGGGGGGGGGGG
GGGGGGGG
GGGGGG
GGG
GGGGGGGGG
GG
GGG
G
GG
G
GG
G
GGGG
GGGGGGGGGGG
G
GG GGGGGGGGGGGGGGGGGGGGGGGGGGGG
GG GGGGGGGGGGGGG GG
GGG
GGG
G
GGGG
G
GG
GG
G
G
GGGGG GGGGGGGGGGGGGGGGGGGGGG GGGGGGGGGGGGGGGGGG
G
GG
GG
GG GG GG
GGGGGGGGGGG
GGGGGGGGGGGG
GGGG
G
GGGG
G
GGG
GG
GG
G
GGGGGGGGGGGG
GGGGGGGGGGGG
GG G
G
GG
GG GG GG
GG
GG
GGG
G
GGG
G
GGG
GG
GG
G
G GG
GGG
G
GG GG
GG
GG GG GGG
GGG
GG
GGGGGGGG
G
G GG
G
G
G
GG
G
G
GG
GGG
GG
GG GG
GGG
GG GG GG
GGG
GGG
GGGG
G
G GG
G
GG
G
G
G
G
GGG
G
GG
GG GG
G
GG GG GGGG
GGG
GG
GGGG
G
G GG
G
GG
G
G
G
G
GG
GG
G
GG GG
GG
G GGGGG
GGGGGGGG
GG
GGGG
GGG
G
G
GG
G
G
G
G
G
GG
GGG
G
GG
GG GG
G
G
GGGGG
GG
GGG
GGGGGGGGGGGGGGGGGGG
GG
G
G
GG
G
G
G
G
G
G
GG
GG
GG GG
GG
G
GG
GG
GGGGG
GG
GG
G
G
GG
G
G
G
G
G
G
G
GG
GG
G
G
GG
GG
GG
GGGGGG
GG
GG
GG
GG
G
G
GG
G
G
G
G
GG
GG
GG
G
GG
GG
GG
GG
GG
G
GG
GG
GG
G
GG
G
G
G
G
GG
GG
G
G
G
GG
GG
GGGGGGGG
GGG
GG
G
GG
G
G
G
G
G
G
GG
GGG
G
GG
G
GG
GG
GGGG
G
GG
GG
GG
G
GG
G
G
G
GG
G
G
GG
G
G
GG
GGGG
G
GGGG
GG
G
G
GG
G
G
G
GG
G
G
GG
G
G
GG
GG
G
GGGGG
G
G
G
G
G
G
G
GG
G
G
GG
G
GG
GG
G
G
G
G
GG
GG
GG
G
G
GG
G
G
GG
GG
G
GGGGGGG
GG
GG
G
G
GG
G
G
G
GG
GG
G
GG
G
G
GG
GG
GG
G
G
GG
G
G
G
G
GG
G
G
G
GG
GGG
GG
GG
G
G
GGG
G
G
GG
G
G
G
G
GG
G
GG
G
G
GGG
G
GG
GG
G
G
G
G
GGGGGGGGG
G
GG
G
GGG
GG
GG
GG
G
GG
GG
G
GG
G
GG
GG
GGG
GG
GG
GG
G
GG
G
GG
GG
GG
GG
GG
G G
GGGG
GG
GG
G
G
GG
GG
GG
G
GG
GG
G G
GGGG
GG
GG
G
G
G
G
GG
G
GG
GG
G G
GG GG
GG
GG
GG
G
GG
GG
GGGG
G
GG
GG
G
G GG
GG
G
GG
G
GG
GG
GG
G
GG
GGG
GGGGGGGGGG
GG
G
G
G
GG
G
GG
GG
GGGGG
GG
GG
GGG
GGGGG G
GG
G
GG
G
GG
GG
GG
GG
GG
GG
GGGGGGGGGGGGGGGGG
GG
GG
G
GG
GG
GG
G
GG
G GG
GG
G
GG
G
G
GG
GG
G
GGG
GG GG
GG
GG
GG
G
G
G
GG
G
GG
GGGG
GG
GG
G
G
GG
G
G
GG
GG
GG
G
G
GG
GG
G
G
G
GG
G
GG
GG
GG
GG
G
G
GGG
G
GG
GG
GGGGG
G
G
GG
GGG
G
G
GG
G
G
G
GGG
G
GG
GG
G
GG
GG
G
GG
GG
GGG
G
GG
GG
GG
G
GG
GG
GGG
G
G
GG
GGGG
G
GG
GG
GG
G
G
GG
GGG
G
G
GG
GG
G
GG
GGG
GG
GG
G
GGG
GG
GG
GG
GGG
GGGG
G G
G GG
G GGGGGGGGGGGGGGGGGGGGG
G
GG
G
GGGGG
GG
G
GG
GG
GG
GG
GG
GG
GG
GGGGGGG
GG
GG
GG
GG
G
GGG
G
GG GGG
GGGGGG
GGGGGGG
GG
GG
GG
GG
GG
GG
GG
GG
GG
GG
GGGG
GGGGGGGGGGG
GGG
GGG
GG
GG
GG
GGG
GGGGG
GG
G
GG
G
GG
G
GG
G
GG
G
GG
G
GG
G
GGG
G
GGG
G
GGGGGGGGGGGGGG
G GGGG
GGGGG
GG
GGG
GG
GGG
GG
G
GG
G
GG
G G
GGGGGGGGGGGG
GGGGGGG
GG
GGG
GGG
GGG
G
G
GG
G
GG
GG
GG
G
GG
GG
GG
GG
G
GG
GG
G
GG
GG
GG
GG
GGGG
GG
GG
GGG
GG
GG
GG
GG
GG
GG
GG
GGG
GG
GG
G
GGGG
GG
GG
GG
GGGG
GG
GG
GGG
GG
G
GG
GGG
GG
GG
GG
GG
GG
GG
GG
GGG
GG
GG
GG
GG
GG
GG
GG
GGG
GG
GG
GG
G
GG
GG
G GGG
GGG
GG
GGG
GGGGGGGG
G
GG
G
GG
GG
GG
GG
GGGG
GG
GG
G
GGG
GG
G
GG
GG
GG
GG
G
GG
G
GG
GG
G
GG
GG
G
GG
G
GG
GG
G
GG
G
GG
GG
G
GG
G
GG
GG
G
GG
G
GG
G
GG
G
GG
G
GG
G
GG
G
GG
GG
GG
GG
G
GG
GG
GG
GG
G
GG
G
GG
GG
GG
GG
GG
GGGG
G
GG
GG
GG
GG
G
GGGG
G
GG
GG
GG
GG
GG
GGGG
G
GG
GG
GG
GGG
G
GGGGG
GG
GG
GGG
GG
G
GGGG
G
GGGG
G
GG
GGGG
GG
GG
GG
GG
G
GGG
G
GG
GG
G
GG
GG
GGG
GG
GG
GG GGGGGGG
GG
G
GG
GGGGGGGGGGG
GG
GG
GG GGG
GG
GG
GG
G
GGGG
GG
GG
GG GGGG
GG
G
GG
G
GGGG
GGGGG
G
GGGG GGGG
GG
GG GG
GG
GGG
GGGG
G
GGGGG GGGG
GG
GG GG
GG
GG
GG
G
G
GGGG
GG
GG GG
G
GG
GG
GG
G
GG
GGGG
GG
GG GG
G
GG
GG
GG
G
GG
GGGG
GG
GG GG GG
G
GG
GG
GG
G
GG
GGGGG
GG
GG GG GGG
G
GG
GG
GG
G
GG
GGG
GG
GG GG GG
G
GG
GG
GG
G
GG
GGG
GG
GG GG GG
GG
GG
GG
GG
G
GG
GGG
GG
GG GG GG
GG
GGGG
GG
GG
G
GG
GGGGGGG
GGG
GG GG GG
GG
GG
GG
GG
GG
GG
GGGGGGG
GGG
GG GG GG
GG
GG
GG
GG
G GG
GG
GGGGGG
GG
GG GGGGGGG
GGG
GG
GG
GG
GG GGG
GG
GGGGGG
GGG
GG GGGGGG
G
GG
GG
GG
GGGGG
GG
GGGGGG
GG
GG GGGG
G GGGGGGGGGGGGGGGG
GG
GG
GGGGG
GG
GGGGGG
GGG
GG GGGG
GGGGG
GG
GG
GGGGG
GG
GGGGGG
G
GG GGGG
GGG
GG
G
GGGGG
GG
GGGGGG
GG
GGG GGGG
GGG
GG
GG
GGGG
GG
GGGGGG
GG
GGG GGGG
GGG
GG
GG
GG
GG
GGGGGG
GG
GG GGGG
GGG
G
GG
GG
GG
GGGGGG
GG
GG GGGG
GG
GG
GGG
GG
GGGGGG
GG
GGG GGGG
G
GG
GG
GG
GG
GGGGGG
G
GGG GGGG
GG
GG
GGG
GG
GGGGGG
GG
GGGGGGG
G
G
GG
GG
GG
GGGGGG
GG
GGGGGG
G
G
GG
GGG
GG
GGGGGG
GG
GGGGGG
G
GG
GG
GG
GG
GGGGG
GG
GGGGG
GG
GG
GG
GGGGGGGGGGG
GG
GGGGGG
GG
GGGGG
G
GG
GG
GGGG
GG
GGGGGGG
GGGGG
GGGGG
G G
GG
GG
GGGGGGGGGGGGGGGGGG
GG
GG GGGG
GGG
GGGGGG
GG GGG
GG
GGGGGGGGGGGGGGGGGGGGGGGGGGGG
GG
GG GGGG
GG
GGGGG
GGGG
GG
GGG
GG GGG GGGG
GGGG
GGGG
GGGGG
GG
GGG
GG GG GG GGGG
GG
GGG
GGG
GG
GGGGGGGG
GGGGGGGGGG GG GGGG
GG
GG
GGG
GG
GGG
GGGG
GGG GGGG
GGGG
G
GG
GG
GG
GGG
G GGGG
GGGG
G
G
GGG
GG
GG
GG GGGG
GG
GG
GG
G
GG
GG
GG GGGG
GG
G
GG
GG
GG
GG
GG GGGG
GG
GG
GG
GG
GG
GG
GG GGGG
GG
G
G
G
GG
GG
GG GGGG
GGG
GGG
G
GG
GG
GG
G GGGGG
GG
GGG
G
GG
GG
GG
GG GGGG
GG
GGG
G
GG
GG
GG
GG GGGG
GG
GGG
G
GGG
GG
GGG
GG GGGG
GGG
GGG
G
GGG
GG
GGG
GG GGGG
GG
G
G
GGGG
GGG
GGGG
GG GGGG
GG
GG
G
GGG
GGG
G
GG GGGG
GG
G
G
G
GG
GG
GG
G GGGG
GG
G
GG
G
G
GGG
GG
GG
GGGGGGG
GGG
G
GG
G
GG
GGG
GG
GG
GGG GGGG
GG
GG
GG
GG
GG
G
GG
GG
G GGG GGGG
GG
GG
GG
G
GG
GG
GG
GGGGGGGGGGGGGGGGGGG GGGG
GG
G
GG
G
GG
GG
GG
GG
GGGG
GGGGGGGGGGGGGGGGGGG
GG
GGGGG
GG
G
G
GG
GG
GGGG
GGGGGGGGGGG GGG
GG
GG
GG
GG
GG
GG
GGGG
GG
GG
GG
GG
GG
GG
GG
G
G
GGGG
GGGG
GG
GG
G
GG
GG
GG
G
GGGGG
GGGG
GG
GG
GG
G
GG
G
GG
G
GG
GG
GG
GG
GG
G
GG
GG
GG
G
GG
GG
GG
GG
GG
G
G
G
GG
GG
GG
GG
GG
GG
GG
G
G
GG
GG
GGGGGGG
GGGGGGGGGGGGGG
GG
GG
GG
GG
G
G
G
GG
GGGG
GGG
G
GG
GG
GGGGG
GG
GG
GG
G
G
GG
GGGGG
GG GGGGGGGGGGGGG
GG
GGGG
GG
GG
G
G
GG
GGGGGGG
GG
GG G
GGG
GGG
GG
GG
GG
GG
GG
GGG
GG
GG G
GGGGGGGG
GG
GGG
GGG
G
G
GG
GG
GG
G
GG
G
GG
G
G
G
GG
GG
GG
GG
G
GG GGG
GG
GG
GG
GG
G
GG
GG
GG
GG
GG
GG GG
GG
GG
G
G
G
GG
GG
GG
GG
G
G
GG GG
GG
GG
GG
G
G
GG
GG
GG
GGG
G
G
GG GG
G
GG
G
GGG
GG
GG
GG
GG
GG
G
G GG
GGGGG
GGG
GGG
G
GGG
GG
GG
GG
GG
GG
G
G G
G
GGGGGGG
GG
G
G
G
GG
GG
GG
GG
GG
G
G GG
GGGGGGGGGG
G
GG
GG
GG
GG
GG
GG
GG
GG
GG
GG
G G
GGG
GG
GG
GG
GG
GG
GG
GG
G
GG
GGGGGGGG
G
GGGG
GGGGGGGGGGGGGG
GGG
GGGG
G
G
GG
GG
G
GGG
GG
GGGGGG
G
G
GG G
GGGGGGGGGGG
GG
GG
GG
GG
GG
GG
GG GGG
GG
GGGGGGGG
GG
G
GG G
GGG
GG
GG
GG
GGG
G
GG
GGG
G GGG
GGG
GGG
GG
GG
G GG
G
GG
GGGGGG
GG
GGGG
GG
GG
G
GG GG
GGG
GG
GG
G
GG GG
GGG
GG
GGG
GG
GGGGG
G
GG
G
GG GG
GGG
GGG
GG
GG
G GG
GG
G
GGG
GG
GGG
GG
GG
GG
GG GG
GGG
GG
GG
GG
GGGG
GGGG
GGG
GGG
GGGG
GGG
GG
GG
G
GG GG
G
GGG
GG
GG
GGGG
GG
GGGGG
GGGGGGGGGGGG
GGG
GGG
G
GG
G GG GG
GG
GG
GGG
G
GGGG
GG
GGGGGG
GGGG
GGGGGGGGGGGGGGGGGGGGGGGGG
GG
GG
GG GG GG
GG
GGG
G
G
GGGG
GGGGGG
GGGGGG
GGGGGGGGGGGGGG
GG GG
GG
GGG
G GG GG
GG
GG
G
G
GGGGGG
GGG
GGGGGGG
GGGGGG
GGGGG
GG G
GGGGGGGGGG
GG
G
GGG
G GGGGGG
GG
GGG
G
G
GGG
GGGGG
GGG GGG
GGGGGGGGGGGGGGGG
GG
GGGGGGGGG
GGGGGGGGGGGGGG
GG
GG
GGGGG
GGGGGGGG
GG
GG
G
G
GGG
GG
GGG
GGG
GG
GGGGGGGGGGGGGGGGGGGGG
GGG
GG
GG
GGGG
GGGGG
GG
GGGG
G
G
GGG
GG
GGG
GGG
GG
GG
GG
G
GGGG
GGGG
GG GGGGGGG
G
G
G
GG
GG
GGGGGGGGGG
GG
GG
GGGG
GG
GGGG
GGGGG
GG GGG
G
G
GG
GG
GGG
GG
GG
GGG
GG
GGGG
GGG
GGG GGGGGGGG
G
G
GG
GG
GGG
GGGGG
GG
GG
G
GGGG
GGG
GGGGGGGGGGG
G
G
GG
GGGG GGGGG
GG
GG
G
GGGG
GG
GGG
GG
GG
GG
GG GGG
G
GG
G
GGGGG
G
GGG
GG
GG
GG
G
GG GG
G
GG
GG
GGGGG
GG
GGGGGGGG
GG
GG
G
GG
GG GG
G
GGGGGGG
G
GGGG
GG
G
GGG
GG
G
GG
GG GG
G
GGG
GG
GGGG
GG
GG
G
GGG
G
GG
GGGGGG GGG
GG
GG
G
GG
GGGGG
G
GG
G
G
G
GG
G
GG
G
GG
GG
GG
GGGG
GG
G
GG
G
G
G GG
GG
G
G
GG
G
GG
GGGG
GG
GG
GG
G
GG GG
GG
GG
GG
GGGGG
GG
G
G
GGGG
GG
G GG
GG
G
GGGGGG
G GG
GGG
G
GGGGG
GG
G
G
GGG
GG
G GGG
GG
G GGGGGGGG
GG
GG G
G
GGG
GG
G
G
GGGG
GG
GG GGGG
GG
G GGGGG
GG
GG
GGGGG
G
GG
GG
G
G
GGGG
GG
GG
G GGGG
GGG
GGG
GGG
GGG GG
GG
G
G
GGG
GGGGG
GG
GGGGG
GG
GG
GGGGGGGGGGGGGGGGG
GG
GG
GG
G
G
GGGG
G
GG
GGGGG
G
GG
GG
GG
GG
GG
GG
GGGG
G
GG
GGGGGGGGGGGG
G
GG
GG GGG
GG
G
GGG
GG
GG
GGGGGGG
GG G
GG
GGG
G
GG
G
GGG
GGGGG
G
GG
GGGGGG
G G
GG
G
GG
GG
GGG G GG
GG
GG
GG
GGGGGGGG
G
G G
GG
G
GG
GG
GG
GGGG
GG
GG
GGGGGGGGGGG
GGGGGG
G
GG GGGGGGGGGGGG
GG
GG
GG
GG
GGGGGGG
GGGGGGGGGGGGG
GGGGGGGGGGGGGGGGG
GGGGGGGG
G
GG
GG
GGG
GG
GG
GG
GG
GG
GG
GGGGGGGGGGGGGGGGGGGGG
G
GG
G
GG
GGG
GGG
GG
GG
GG
GGG
GGGGGGG
G
G
G
GGGGGGGGGGGGG
GG
G
GGGG
GG
G
GGGGGGGGGGGGGGGGG
GGGG
G
G
G
GGGGGG G
GGGGGGGGGGGG
GG
G
G
GG
GGGGGGGGG
GGG GGGGGGGGGGGGGG
GGGG
G
G
GG G
GG
GG
GGGGGGGGGGGGGGGGG
G
GG
GGGGGGGGGGGGGGGGGGG
GG
GG
GGGG
G
GG
GG
GG
GG
G
GG
G
GG
GG
GG
GG
G
GG
G G
GG
GGG
GG
GG
G
GG
GG
GG
GGGGGG
GG
GG
G
G
G
GG
GGG
GG
G
GG
GG
G
GG
GGGG
GG
GG
G
G
G
GG
G
G
GG
GG
G
GG
G
GG
GG
GG
G
G
G
GGG
G
G
GG
GG
G
G
GG
GG
GG
G
GG
GG
GG
G
G
G
G
G
G
GG
GG
G
G
GGGG
G
GG
GGG
GG
GG
G
G
G
G GG
G
GGG
G
GGGGGGGGGGGGGGGG
GGG
GGGGGG
GGG
G
GG
G
G
G
GG
G
G
GG
G
GGGG
GG
G GGGG GGGGGGG
GG
GGG
G
GG
GG
G
G
G
G
GG G
G
GG
GG
GG
GG
GGGGGG
G
GG
G
G
G GGGG
GGG
GG
GG
GG
GG
GG
G
GG
G
G
G
GGG
G
G
GG
GGG
GG
GGG
GG
GG
GG
G
G
G
G
GG
GGG
GGG G
GG
GGGGG GGGGGGGGGGGGGG
GG
GG
G
G
G
G
G GG
G
GGG
GG
GG
GGGGGGGG
GGGG
GGG
GGGGGGGGG
GGG
G
GG
G
GG
G
G
GG
G
GG G
GGGGGGGGGG
GG GGGGGGGGGGGGG GG
GGG
GGG
GGGG
G
G
GG
G
G
GGGG GGGGGGGGGGGGGGGGGG
G
GG
GG
GG GG GG
GGGGGGGGGGG
GGGGGGGGGGGG
GGGG
GGGG
G
GG
GG
GG
G
GGGGGG
GGGGGGGGGGGG
GG G
G
GG
GG GG GG
GG
GG
GGG
GGG
G
GGG
GG
GG
G
G GG
GGG
G
GG GG
GG
GG GG GGG
GGG
GG
GGGGGGGG
G GG
G
G
G
GG
G
G
GG
GGG
GG
GG GG
GGG
GG GG GG
GGG
GGG
GGGG
G GG
G
GG
G
G
G
G
GGG
G
GG
GG GG
G
GG GG GGGG
GGG
GG
GGGG
G GG
G
GG
G
G
G
G
GG
GG
G
GG GG
GG
G GGGGG
GGGGGGGG
GG
GGGG
G
GG
G
G
G
G
G
GG
GGG
G
GG
GG GG
G
G
GGGGG
GG
GGG
GGGGGGGGGGGGGGGGGGG
G
GG
G
G
G
G
G
G
GG
GG
GG GG
GG
G
GG
GG
GGGGG
GG
G
GG
G
G
G
G
G
G
G
GG
GG
G
G
GG
GG
GG
GGGGGG
GG
GG
G
G
GG
G
G
G
G
GG
GG
GG
G
GG
GG
GG
GG
GG
GG
GG
G
GG
G
G
G
G
GG
GG
G
G
G
GG
GG
GGGGGGGG
G
GG
G
G
G
G
G
G
GG
GGG
G
GG
G
GG
GG
GGGG
GG
GG
G
GG
G
G
G
GG
G
G
GG
G
G
GG
GGGG
GG
G
G
GG
G
G
G
GG
G
G
GG
G
G
GG
GG
G
G
G
G
G
G
G
GG
G
G
GG
G
GG
GG
G
G
GG
GG
GG
G
G
GG
G
G
GG
GG
G
GGGGGGG
G
G
GG
G
G
G
GG
GG
G
GG
G
G
GG
G
G
GG
G
G
G
G
GG
G
G
G
GG
GGG
G
G
GGG
G
G
GG
G
G
G
G
GG
G
G
GGG
G
GG
GG
G
G
G
G
GGGGGGGGG
G
GGG
GG
GG
GG
G
GG
GG
G
GG
GG
GGG
GG
GG
GG
G
GG
G
GG
GG
GG
G G
GGGG
GG
GG
G
G
GG
GG
GG
GG
G G
GGGG
GG
GG
G
G
G
G
GG
GG
G G
GG GG
GG
GG
GG
G
GG
GG
GGGG
GG
G
G GG
GG
G
GG
G
GG
GG
GG
GGG
GGGGGGGGGG
GG
G
G
G
GG
G
GG
GG
GGGGG
GGG
GGGGG G
GG
G
GG
G
GG
GG
GG
GG
GGGGGGGGGGGGGGGGG
GG
GG
G
GG
GG
GG
G
GG
GG
G
GG
G
G
GG
GG
G
GG
GG
GG
G
G
G
GG
G
GG
GG
G
G
GG
G
G
GG
G
G
G
GG
GG
G
G
G
G
GG
GG
GG
GG
G
G
G
GG
GG
GGGGG
G
G
GG
G
G
GG
G
G
G
G
GG
GG
G
GG
G
GG
GG
GGG
G
GG
GG
GG
G
GG
GG
GGG
G
G
GG
GGGG
G
GG
GG
GG
G
G
GG
GGG
G
G
GG
GG
G
GG
GGG
GG
GG
G
GGG
GG
GG
GG
GGG
GGGG
G G
G GG
G GGGGGGGGG
G
GG
GG
GG
GG
GG
GG
G GG
G
GG
G
G
GGGG
G
G GGGG
G
G
G
GG
G
G
G
G
G
GG
G
G
G
GG
G GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
GG
G
G
G
GGG
GGGG
GGG
GGG
G
GGG
GG
G
GG
G
GG
GG
G
G
G GG
G
GGGG
G
G
GGG
G
GGGGG
G
GG
G
G
G
G
G
G
GGGG
G
GGGGG
GGGG
GGGGGGGGG
GGGGGGGGGGG
GGGGG
GG
GG
G
G
G
G
G
GGG GG
GG
G GG
G
GGGGGG
GGGGGGGGGGG
GG
G
GG
GGG
G
GG
GGGGGGGGGGGGGG
G
GG
GGGGG
G
GGGGGGGGGGGG
G
G
GGGGGGGG
GG
GGGGGGGGG
G
G
G
GGGGGGG
GGGGGGGGGGGGGG
GG
G
G
G
GGG
G
GGGGG
G
G
GG
GGGGGGGGGGGGGGG
GG GGGGGGGGGGGG
G
GGG
GG
GGG
G
GG
GGGGGGGG
G
G
GGGGG
GGGG
G GGGGGGGG
GGGGGGGGGG
G
GGG
GGGGGGGGG
GG
GG
GGGGGGGGG
GGGGGGGGGGGG
G
GG
GGGGGGGGGGGGGGGGGG
G
GGGGGG
G
Low risk
Indecision low/medium risk
Medium risk
Indecision medium/high risk

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
CRALC probabilistic logic with IPs
(Cozman, 2008)
Description logic with interval of probabilities
N individuals (I1, . . . , In),
P(smoker(Ii)) ∈[.3, .5], P(friend(Ij, Ii)) ∈[.0, .5],
P(disease(Ii)|smoker(Ii), ∀friend(Ij, Ii).Iismoker) = ...
P(disease)? Inference ≡updating of a (large) binary CN
FRIEND(I1, I1)
FRIEND(I2, I1)
FRIEND(I3, I1)
SMOKER(I1)
∀FRIEND(I1).SMOKER
DISEASE(I1)
FRIEND(I1, I2)
FRIEND(I2, I2)
FRIEND(I3, I2)
SMOKER(I2)
∀FRIEND(I2).SMOKER
DISEASE(d2)
FRIEND(I1, I3)
FRIEND(I2, I3)
FRIEND(I3, I3)
SMOKER(d3)
∀FRIEND(I3).SMOKER
DISEASE(I3)

From precise to imprecise probs
Credal Sets
From Bayesian to Credal nets
Decision Support and Risk Analysis
References
Piatti, A., Antonucci, A., Zaffalon, M. (2010).
Building knowledge-based expert systems by
credal networks: a tutorial. In Baswell, A.R.
(Ed), Advances in Mathematics Research 11,
Nova Science Publishers, New York.
Corani, G., Antonucci, A., Zaffalon, M. (2012).
Bayesian networks with imprecise
probabilities: theory and application to
classiﬁcation. In Holmes, D.E., Jain, L.C.
(Eds), Data Mining: Foundations and
Intelligent Paradigms, Intelligent Systems
Reference Library 23, Springer, Berlin /
Heidelberg, pp. 49–93.
ipg.idsia.ch
www.sipta.org

