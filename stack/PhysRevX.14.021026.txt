Thermodynamics of Computations with Absolute Irreversibility,
Unidirectional Transitions, and Stochastic Computation Times
Gonzalo Manzano ,1 Gülce Kardeş,2,3 Édgar Roldán,4 and David H. Wolpert
3,4
1Institute for Cross-Disciplinary Physics and Complex Systems (IFISC) UIB-CSIC, Mallorca, Spain
2University of Colorado, Boulder, Colorado 80309, USA
3Santa Fe Institute, Santa Fe, New Mexico 87501, USA
4ICTP—The Abdus Salam International Centre for Theoretical Physics,
Strada Costiera 11, 34151 Trieste, Italy
(Received 25 July 2023; revised 16 February 2024; accepted 14 March 2024; published 13 May 2024)
Developing a thermodynamic theory of computation is a challenging task at the interface of
nonequilibrium thermodynamics and computer science. In particular, this task requires dealing with
difficulties such as stochastic halting times, unidirectional (possibly deterministic) transitions, and
restricted initial conditions, features common in real-world computers. Here, we present a framework
which tackles all such difficulties by extending the martingale theory of nonequilibrium thermodynamics to
generic nonstationary Markovian processes, including those with broken detailed balance and/or absolute
irreversibility. We derive several universal fluctuation relations and second-law-like inequalities that
provide both lower and upper bounds on the intrinsic dissipation (mismatch cost) associated with any
periodic process—in particular, the periodic processes underlying all current digital computation.
Crucially, these bounds apply even if the process has stochastic stopping times, as it does in many
computational machines. We illustrate our results with exhaustive numerical simulations of deterministic
finite automata processing bit strings, one of the fundamental models of computation from theoretical
computer science. We also provide universal equalities and inequalities for the acceptance probability of
words of a given length by a deterministic finite automaton in terms of thermodynamic quantities, and
outline connections between computer science and stochastic resetting. Our results, while motivated from
the computational context, are applicable far more broadly.
DOI: 10.1103/PhysRevX.14.021026
Subject Areas: Computational Physics,
Statistical Physics
I. INTRODUCTION
A. Background and motivation
In the past three decades there has been major progress in
formulating far from equilibrium systems and processes.
Using stochastic thermodynamics, we can now rigorously
formulate the thermodynamic behavior of systems ranging
from biological molecular machines to electronic circuits,
evolving arbitrarily away from equilibrium. Celebrated
results of stochastic thermodynamics include fluctuation
relations that generalize the second law of thermodynamics
[1–3], speed limit theorems [4–6], thermodynamic uncer-
tainty relations [7–10], large deviation approaches [11,12],
martingale fluctuation relations for extrema and stopping
times [13–19], and universal bounds on various kinetic and
frenetic properties [20–22].
The past decade also witnessed progress in thermody-
namics of computation. Although many initial studies
on energetic costs of computation have mostly concerned
unit operations such as bit erasure [23–26], which is too
primitive to be pertinent to the formal models of com-
putation in theoretical computer science (TCS), very recent
work started to investigate energetic costs of implemen-
ting computational machines central to TCS, which per-
form tasks such as string matching algorithms (which
are justifiably more complex than bit erasure) [27–29].
Figure 1(a) shows the general model of a computational
machine (henceforth called a computer) which implements
a basic algorithm presented in Fig. 1(b).
An algorithm is a finite procedure for implementing a
given task, which can be executed in various physical ways,
e.g., while modifying the current on electrical wires or the
structure of a DNA origami. Formally, an algorithm
consists of the instructions to be performed (which is
implemented by the dynamics of the computer), the local
variables and the memory arrays (stored by the computer),
Published by the American Physical Society under the terms of
the Creative Commons Attribution 4.0 International license.
Further distribution of this work must maintain attribution to
the author(s) and the published article’s title, journal citation,
and DOI.
PHYSICAL REVIEW X 14, 021026 (2024)
2160-3308=24=14(2)=021026(32)
021026-1
Published by the American Physical Society

as well as mechanisms to decide when to repeat steps and
when to halt. A computer executes an algorithm on a given
set of inputs, starting from a certain initial state, potentially
following unidirectional transitions in its state space, and
halting at an arbitrary stochastic time that depends on the
computation. Hence, a general thermodynamic model of
computers which implement arbitrary algorithms should be
able to account for the energetic costs of implementing
computational processes (i) at arbitrary stopping times,
with (ii) unidirectional (possibly deterministic) transitions,
and (iii) “absolute irreversibility” due to the computer being
initialized to a designated start state.
However, most of the central results in stochastic
thermodynamics do not directly apply to processes having
the aforementioned three key ingredients of computational
processes (stopping times, unidirectional transitions, and
absolute irreversibility). In fact, a central assumption in
much of stochastic thermodynamics is the condition of
local detailed balance (LDB), which requires the system to
have only bidirectional transitions; i.e., all transitions
between any two states i →j with their reverse j →i
have a finite, nonzero probability to occur in a finite time.
On the other hand, LDB can be formally avoided by taking
an inclusive Hamiltonian approach [30–33], which has
been applied recently to computational machines [29].
However, in general there may be hidden nonequilibrium
(driven) degrees of freedom which need to be included in
the thermodynamic framework beyond a surrounding
thermal bath. Moreover, even when assuming LDB, the
ratio of transition probabilities between i →j and their
reverse j →i can grow exponentially with the entropy
exchanged with the environment, so that the reverse
transition will not be effectively seen in relevant timescales,
leading to an effective unidirectionality. Until now, little
has been known about the stochastic thermodynamics
of systems with broken LDB reflecting unidirectional
transitions [21,34–38] or athermal and nonequilibrium
environments [39–43]. In addition, the recently establi-
shed martingale theory of thermodynamics (see Ref. [19]
for a review)—which formulates fluctuation theorems and
second-law-like inequalities at generic stopping times—has
not yet been extended to apply to systems with either
unidirectional transitions or absolute irreversibility.
In this paper, we develop a nonequilibrium thermody-
namics theory for computations with stochastic computa-
tional times that may have absolute irreversibility and
unidirectional transitions [44]. Throughout this work, we
focus on the intrinsic thermodynamic costs of computa-
tions, modeled by generic Markovian dynamics, with
minimal or no details about their physical implementation.
We derive fluctuation relations for key thermodynamic
quantities applicable to all computational processes which
can be modeled as discrete-time Markov chains (DTMC),
with both unidirectional and bidirectional transitions,
and restricted initial probability distributions. These rela-
tions hold at both fixed and stopping times, and so
simultaneously extend the martingale theory for stochastic
thermodynamics to the case of DTMCs with absolute
irreversibility and unidirectional transitions.
The thermodynamic meaning of our results is established
by introducing a generic physical implementation of the
computer as a periodically driven process operated over a
set of hidden degrees of freedom. This allows us to link
dissipation from underlying (physical) to visible (computa-
tional) levels and obtain quantifiers for the energetic costs
of computations up to their halting time or between halting
times of consecutive computations and their statistics.
Our results, while emphasized here for computational
FIG. 1.
Illustrations of computations with absolute irreversibility, unidirectional transitions, and stochastic computation times. An
algorithm is executed by using a set of instructions, a finite control unit or local variables, a working memory to store the input or
intermediate execution values, an address index, and mechanisms which specify when to loop and when to halt (the latter is of interest to
us in thinking of stopping times). Both in computer science models and physical computers, the finite control unit generally corresponds
to a circuit [as in (a), implementing the algorithm in (b)] or a DFA as in (c), here deciding whether input bit strings are divisible by four.
In physical implementation of such devices which solve a myriad of computational tasks, energetic costs are inevitable.
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-2

processes, can also describe a wide range of systems,
including, e.g., biochemical processes with irreversible
release of molecules.
We illustrate our results in deterministic finite automata
(DFA). Loosely speaking, a DFA is a system with a finite
state space, initialized to a special start state q0 at t ¼ 0, and a
logical computer by itself, which can solve basic computa-
tional tasks such as string matching. More importantly, it
constitutes the “finite logic” part [see Figs. 1(b) and 1(c)]
of the engineered computers at use today, and formally
corresponds to the finite logic component of Turing
machines (TMs).
B. Summary of our contributions and road map
Consider a discrete-time computational task which is
implemented by iteratively processing an input sequence
of symbols w through a maximum of τ iterations. We refer to
τ as the limit time of the computation. As an example, τ could
be the length jwj of a bit string w, and the computation could
involve iteratively processing each of those bits in sequence.
During such a computation, the state of the computer
evolves in a stochastic manner, tracing a stochastic trajec-
tory on a set of computational variables x½0;τ ¼ x0; …; xτ.
The computation finishes either at the limit time or, if it
is earlier, at a stochastic computation time T , which in
general will be a function of the precise input w. Formally,
computational times T are specific examples of stopping
times. A stopping time is the first time that a stochastic
trajectory meets a specific predefined criterion [45]. In this
work, we deal with stopping times which associate to each
specific trajectory x½0;τ ¼ x0; …; xτ a stochastic time T ≤τ
that is always smaller than or equal to the limit time. As an
example of stopping time in computation, T could be the
first time a DFA reaches a prescribed computational state A.
T could also be defined as the first time a DFA reaches a
state B ≠A once having left state A. Stopping times thus
provide a flexible yet rigorous mathematical toolbox to
tackle computations that last a stochastic amount of time.
In Sec. II, we provide the elementary concepts of our
framework, including a formal definition of DFAs: the
description of computational processes (such as the running
of a DFA) as Markov chains and the physical implemen-
tation of those Markov chains. We also review the relevant
thermodynamic quantities in this context.
In this paper, we investigate the thermodynamic costs of
computations, paying particular attention to those with such
stochastic durations. As described below, this will lead us to
concentrate on a specific thermodynamic quantity, which we
call the intrinsic mismatch cost. The intrinsic mismatch cost
associated with a stochastic trajectory x½0;T  that takes place
in the interval ½0; T  of stochastic duration T is defined as
ΣðT Þ ¼
X
T −1
t¼0

ln ρtðxtÞ
rðxtÞ −ln ρtþ1ðxtþ1Þ
r0ðxtþ1Þ

:
ð1Þ
In Eq. (1), ρtðxÞ is the probability for the computer to be in
state x at time t during the computation, whereas rðxÞ is an
arbitrary reference probability distribution. On the other
hand, ρtþ1ðxÞ and r0ðxÞ correspond to the distributions
retrieved applying one iteration of the computer to ρtðxÞ
and rðxÞ, respectively. In particular, when the reference
distribution minimizes the dissipation in the computer, it is
called the prior distribution, and the associated quantity
Eq. (1) is known as the mismatch cost of the computation up
to time T . This cost provides a lower bound on the entropy
production incurred by any digital synchronous computer
that implements this dynamics over values of the computa-
tional variables x, without any precise assumptions about the
continuous-time process implementing each successive iter-
ation of the computation [46]. Note that while the distribu-
tions ρt and ρtþ1 are indexed by the iteration number,
changing as the computation proceeds, the distributions r
and r0 are the same for every iteration of the computation.
Some of our most important results are fluctuation
relations and inequalities for the statistics of ΣðT Þ.
These are threefold universal, in that they are valid for
all (i) reference distributions rðxÞ [although we will make
specific choices for it to give a concrete thermodynamic
meaning to Σ], (ii) stopping rules T that halt before τ þ 1,
(iii) discrete-time Markov chains (DTMCs), even those
with restricted initial conditions, and/or with unidirectional
transitions, and even DTMCs that are implemented by
underlying non-Markovian continuous-time processes.
To illustrate these results we need to first introduce
more definitions. Here and throughout this paper, we use
hAðT Þi ≡E½AðT Þ for the expectation of any functional A
of x½0;T  over many realizations of the computation, each
ending at the possibly different time T . In addition, we
introduce the stochastic distinguishability at stopping
times,
δτðT Þ ¼ ln ρtðxtÞ
¯ρτ−tðxtÞ

t¼T
;
ð2Þ
which quantifies the asymmetry of the computational
process under time reversal through its distribution and
plays a key role for identifying possible reductions in
thermodynamic costs along processes with stochastic
duration [16]. The distribution ¯ρtðxÞ above is the proba-
bility for an auxiliary computation running backward in
time to be in state x at time t during the computation. Such
auxiliary computation evolves with a transition matrix that
is the Bayesian inverse of the original computation with
respect to r, such that it leads to the perfect retrodiction in
time of the distributionr [51]. In Sec. III, we provide a formal
definition for the auxiliary computational process, that
allows us to address the thermodynamics of computations
endingatafixedtimeatthefluctuatinglevel,anddiscusshow
to incorporate explicitly the role of absolute irreversibility
and unidirectional transitions, which is crucial because
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-3

conventionally formulated computational machines have
precisely those features.
In Sec. IV, we present our main results for general
computations starting and ending at stochastic halting
times, which include fluctuation theorems and second-
law inequalities that provide lower bounds to the average
dissipation in a computation. A central result of our work is
the derivation of an integral fluctuation relation at stopping
times which applies to arbitrary computations:
he−ΣðT Þ−δτðT Þi ¼ 1 −Γτ:
ð3Þ
In this equation, Γτ quantifies absolute irreversibility at
stopping times. It equals the functional e−δτðT Þ averaged
over the restricted set of trajectories that can take place in
the auxiliary dynamics but have zero probability in the
original dynamics; see Eq. (36). This contribution intro-
duces an unavoidable source of irreversibility that limits
possible reductions in the dissipation of the computer.
Among other things, Eq. (3) provides a second-law
inequality at stopping times for the intrinsic mismatch cost:
hΣðT Þi ≥−hδτðT Þi −ln½1 −Γτ:
ð4Þ
As we show in this paper, the right-hand side of Eq. (4),
which sums up the net effects of time-asymmetry and
absolute irreversibility, gives a universal lower bound not
only for the intrinsic mismatch cost of the computation but
also for the underlying average entropy production incurred
by the computer. Moreover, for the particular case of a
stationary reference distribution (r ¼ π, with π0 ¼ π)
hΣðT Þi equals the average (discrete-time) nonadiabatic
entropy production [52,53].
We remark that Eq. (3) follows from a stronger result
that we derive here. In particular, e−ΣðtÞ−δτðtÞ is a super-
martingale process, i.e., e−ΣðtÞ−δτðtÞ decreases with time
when conditioned on an earlier part of the trajectory of
states: he−ΣðtÞ−δτðtÞjx½0;si ≤e−ΣðsÞ−δτðsÞ, where t ≥s ≥0;
see Eq. (31) [54].
Another contribution in this paper arises when we apply
the general martingale theory for thermodynamics [19], to
extend our results to multiple, ordered stopping times. In
particular, for the case of two stopping times T 1 and T 2
with T 2 ≥T 1, we obtain another central result:
hΣðT 2Þ þ δτðT 2Þi ≥hΣðT 1Þ þ δτðT 1Þi;
ð5Þ
which provides a powerful second-law inequality appli-
cable to both starting and ending stochastic times of
computations. As an example, in the case of a DFA, T 1
could be the first time that some particular state A is
reached, and T 2 could be the first time state B is reached
after state A has been reached. Alternatively, T 2 could be
the second time state A is reached after the system has first
reached state A, then left it, and then returned. See Sec. V
for numerical illustrations of these ideas in a specific
minimal model of a DFA processing binary strings.
Moreover, from Eq. (5) a sandwich inequality for hΣðT Þi
can be derived [55],
Dðρ0k¯ρτÞ −hδτðT Þi ≤hΣðT Þi ≤hΣðτÞi −hδτðT Þi;
ð6Þ
extending recent research in upper bounds and inverse
thermodynamic uncertainty relations in stochastic thermo-
dynamics given in Refs. [56–58].
In addition to the aforementioned fundamental results, in
Sec. VI we also combine the supermartingale property of
e−ΣðtÞ−δτðtÞ with the fluctuation relation Eq. (3) to derive
universal equalities and inequalities for the probability
that a computation is completed within a certain amount
of time. Such an idea can be applied, e.g., to compute the
probability that a sequence of τ ordered computational
states visited by a DFA during its evolution reaches an
accept state.
Section VII is then devoted to sketch how our theory can
be applied to investigate the thermodynamics of multiple
concatenations of runs of a DFA, where after each run ends
the system is reset to an initial start state and the next run
begins. We conclude with Sec. VIII, where we present
our main conclusions and further discuss future research
directions motivated by our findings. Mathematical details
of the derivations, proofs, and extra discussions are left to
corresponding appendixes.
It is worth remarking that all our contributions, while
originally motivated from problems arising in the context of
the kinds of computational machines central to computer
science theory, are applicable to any periodic process
implementing a time-homogeneous DTMC, one that results
in trajectories x½0;T .
II. MARKOVIAN COMPUTATIONS
In the following, we make the assumption that the
implementation of a task on a given computer is realized
through a physical process which induces Markovian
(discrete) dynamics over a set of relevant computational
states. The actual physical process being modeled will be a
generic physical, chemical, or biological system, whose
dynamics can be described at a microscopic level over a
set of hidden degrees of freedom [47,48], here assumed to
be not directly accessible. In particular, it is customary to
model a computation as a continuous-time Markov chain
(CTMC) [48,59–62].
In “synchronous” physical computers—such as all real-
world digital computers—this CTMC is driven externally
following a periodic protocol induced, e.g., by the ac
electric current powering a computer. Such underlying
periodic driving might be ignored in modeling the compu-
tational process, by describing its evolution by coarse
graining it in time, and this results in an effective model
given by a time-homogeneous DTMC. Throughout this
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-4

paper, we will work at such a coarse-grained level, and
consider computational processes as generic DTMCs with
time-independent transition probabilities. In doing so, we
will map the underlying physical process to the DTMC
dynamics of the (symbolic) computational states to for-
mulate the actual physical dissipation in a thermodynami-
cally consistent manner.
A. Stochastic computational processes
We consider computational processes described by a
DTMC that can take values over a discrete set of N ≥1
computational states xt ∈X, with t ¼ 0; 1; 2; …. For sim-
plicity, we assume that the transition probabilities between
the computational states are time independent (however,
our results can be extended to time-dependent transition
probabilities).
We write Pðxtþ1jxtÞ for the conditional probability of
jumping to state xtþ1 given that the previous state was xt in
a single time step or iteration of the computational process.
(Note that in a DTMC xt can be the same as xtþ1, allowing
for time instances where the system dwells in a given state.)
We write ρtðxÞ for the probability of being in state x at
time t, given an ensemble of realizations of the Markovian
process. The associated discrete-time master equation
ρtþ1 ¼ Wρt, where ρt is an N × 1 column vector and
½Wi;j ¼ Pðxtþ1 ¼ ijxt ¼ jÞ is the transition probability
matrix. The transition matrix W has at least one fixed
point with distribution πðxÞ such that Wπ ¼ π, and if
aperiodic and irreducible, π becomes the unique stationary
distribution in the long time run, that is, limt→∞ρt ¼ π.
However, what follows does not require π to be unique.
Throughout the paper we will write τ for the limit time of
a computation, i.e., the maximum time that can be spent to
execute a computation, and assume it to be fixed. The
probability of a sequence x½0;τ ¼ x0; x1; …; xτ is
Pðx½0;τÞ ¼ ρ0ðx0Þ
Y
τ−1
t¼0
Pðxtþ1jxtÞ:
ð7Þ
Here we allow for arbitrary initial distributions ρ0ðx0Þ
and transition probabilities Pðxtþ1 ¼ jjxt ¼ iÞ ¼ PðjjiÞ. In
particular, some of the transitions might be bidirectional
(i ↔j) and others unidirectional (i →j). Bidirectional
transitions are characterized by conditional probabilities
verifying PðijjÞ > 0 whenever PðjjiÞ > 0, while for uni-
directional transitions we can have PðijjÞ ¼ 0 with
PðjjiÞ > 0. We notice that exactly because of the existence
of unidirectional transitions, it is mandatory to relax the
condition of local detailed balance, which is arguably
among the most common assumptions adopted in the
formulation of stochastic thermodynamics [63].
One of the main quantities of interest in stochastic
thermodynamics is stochastic entropy production (EP)
which equals the logarithm of the ratio between forward
and time-reversed path probabilities of a thermodynamic
process [3,64]. This quantity, however, generically depends
on the details of the underlying physical process imple-
menting the computation, hence is not directly accessible
unless certain simplifying assumptions, such as the con-
dition of local detailed balance. Nevertheless, here we aim
to obtain a thermodynamic description of the computa-
tional processes as deduced solely from the (discrete-time)
dynamics of the visible variables defining the computation
xt ∈X. While our analysis holds for arbitrary DTMCs, we
focus on digital synchronous computers, which undergo a
time-homogeneous dynamics over discrete time, and which
we connect to the underlying physical process generating it
in a simple manner. This allows us to express and bound the
entropy production of the computational task implemented
by the DTMC, alongside the work and heat dissipated into
the environment. For simplicity, we take the continuous-
time physical process that implements the time-stationary
DTMC to be periodic and choose units so that the period of
the physical process is 1.
As an example (and to help ground the reader’s intu-
ition), suppose that our time-homogeneous DTMC is
implemented by a time-inhomogeneous CTMC. It is well
known that, in general, this requires that the CTMC evolves
over an enlarged version of the DTMC’s state space Y ⊇X,
which includes “hidden states” in addition to the “visible”
states of the DTMC [48,65]. In particular, this is true
when the DTMC is the update function of a computational
machine. Therefore, our assumption that the continuous-
time physical process is periodic implies that the time-
inhomogeneous CTMC is periodic. As a result, the
thermodynamics arising in any single iteration of the
physical system [implementing the computational machine
that starts at discrete time t in some state yðtÞ ∈Y] is
independent of t. In the following, for further simplicity
(and to ensure a time-homogeneous DTMC) we also
assume that noncomputational degrees of freedom in Y
are reinitialized within every single iteration to their
(possibly nonequilibrium) initial states.
B. Mismatch cost
Enlarging our original description over Y to include all
relevant physical variables of the computer is crucial to
define the associated entropy production and other relevant
thermodynamic costs of computation. Here we show that
this can be done in a standard way. In particular, suppose
that we are interested in some generic thermodynamic
average cost function that can be written as
CðτÞ ¼ SðϱτÞ −Sðϱ0Þ þ F
≔SðGϱ0Þ −Sðϱ0Þ þ F;
ð8Þ
where SðϱÞ ¼ −P
i ϱðiÞ ln ϱðiÞ is Shannon entropy, ϱ0 is
any initial distribution over the (extended set of) states of
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-5

the system, G is the linear map that transforms that
distribution to an associated ending distribution ϱτ, and
F is an arbitrary linear functional of the initial state. Note
that CðτÞ is an implicit function of ϱ0.
As a canonical example, in CTMC-based stochastic
thermodynamics obeying local detailed balance, the EP
generated during a process is given by Eq. (8) by setting F
equal to the average entropy flow to the environment:
F ¼
Z τ
0
dt
X
v
X
i;j
ϱtðjÞKv
ijðtÞ ln
Kv
jiðtÞ
Kv
ijðtÞ

;
ð9Þ
where Kv
ijðtÞ is the rate matrix associated to thermal
reservoir v, and the rate matrix of the CTMC is
P
v Kv
ijðtÞ [66]. For different choices of F, CðτÞ gives
different thermodynamic quantities besides EP, such as the
drop in nonequilibrium free energy of the system during the
process [49], among many others.
For any cost C of the form in Eq. (8), and any physical
process represented by G, the prior distribution is defined
to be the initial distribution ϱ0 that minimizes CðτÞ. (It is
called the prior because it is, formally speaking, a prior
distribution for calculating the posterior probability of
an initial state of a thermodynamic process given its final
state [67].) We write the prior as ϱmin. The associated
average mismatch cost is
MðτÞ ≔Dðϱ0kϱminÞ −DðGϱ0kGϱminÞ;
ð10Þ
where Dðϱ1kϱ2Þ ¼ P
y ϱ1ðyÞ ln½ϱ1ðyÞ=ϱ2ðyÞ denotes the
Kullback-Leibler (KL) divergence between the distribu-
tions ϱ1 and ϱ2 for the case of a discrete random variable.
Note that MðτÞ is implicitly a function of ϱ0; ϱmin and the
linear function G—but nothing else. It depends on no other
property of the process besides ϱmin and G.
As shown in Refs. [27,47–49] we have, for all ϱ0,
CðτÞ ¼ MðτÞ þ RðτÞ;
ð11Þ
where RðτÞ is an additive non-negative contribution
independent of ϱ0 called “residual cost.” In the specific
case in which F is identified with the entropy flow, residual
cost is often called “residual EP.” See Appendix A for a
discussion of residual cost and why we ignore it in
this paper.
Expressions analogous to Eqs. (8), (10), and (11) hold
for other state spaces, e.g., real-valued states, density
matrices, etc. Moreover, there are no assumptions of
detailed balance or the like in the derivation of Eq. (10);
it holds purely for mathematical reasons. For the trajectory-
level version of mismatch cost in Eq. (10) see Appendix B.
By the data-processing inequality for KL divergence [68],
MðτÞ is never negative. Moreover, it can be shown that the
prior ϱmin in Eq. (10) has full support (see Appendix A in
Ref. [27]), which ensures that the mismatch cost is finite.
Note also that the mismatch cost formula (10) is based on
evaluating ϱ at both the beginning and the end of the time
interval ½0; τ. This means this general formula applies to any
physical process that maps ϱ0 to ϱτ, for any choice of C, i.e.,
anychoiceofthelinearfunctionalF.All the(messy)physical
details of the process and the precise choice of F are buried in
the prior and the residual cost.
In the following, unless explicitly stated otherwise,
we will focus on the case in which the cost function
CðτÞ in Eq. (11) is the average entropy production of the
continuous-time periodic process implementing the com-
putation. If such a process is moreover Markovian, the
entropy flow F will be given by the canonical CTMC
expression in Eq. (9). However, Markovianity of the
continuous-time periodic process is not a necessary
assumption for our results (see also Appendix C).
C. Strictly positive lower bounds for dissipation
in periodic processes
As described above, in real-world (synchronous, digital)
physical computers, the underlying physical process imple-
menting each iteration of the computer is identical. This is
true whether that physical process is a CTMC, a quantum
operation, and so on. As noted in Ref. [28], this means
that the prior ϱmin for each iteration of the computer is the
same [69]. Using also the fact that noncomputational
variables are reinitialized in every single iteration (period)
of the computational process, we can write the overall
mismatch cost for any computation that takes exactly τ
iterations in terms of computational variables as
X
τ−1
t¼0
MðρtÞ ¼
X
τ−1
t¼0
½DðρtkμÞ −Dðρtþ1kμ0Þ;
ð12Þ
where ρtðxÞ ¼ P
y∉X ϱtðyÞ is the (marginal) distribu-
tion
over
computational
states
x ∈X
only,
μðxÞ ¼
P
y∉X ϱminðyÞ is the prior over computational states at
the beginning of (every) iteration, and μ0 ¼ Wμ the prior
at the end of every iteration (i.e., it is μ evolved to the
end of the iteration). More details about the derivation of
Eq. (12) for the DTMC are provided in Appendix C, where
we explicitly elaborate its relation to the underlying EP in
the continuous-time periodic process.
We note that if ρ0 ¼ μ in Eq. (12), then the first
difference of KL divergences being summed equals 0.
However, unless W is degenerate (e.g., the identity matrix),
Wρ0 ≠ρ0, and therefore Wρ0 ≠μ. This in turn means
that the second difference of KL divergences being
summed in Eq. (12) does not equal 0 (so long as W is
not logically invertible, i.e., not a permutation matrix).
Therefore in this case, the overall sum will be strictly
positive. This argument can be extended to prove that so
long as W is not logically invertible (and ρ0 is not a fixed
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-6

point of the dynamics), the mismatch cost sum in Eq. (12) is
not zero (see Appendix D).
Since the above reasoning is true for all actual μ, we can
lower bound the sum Eq. (12) by minimizing over all
distributions λ in the unit simplex ΔX, whether or not they
are a valid prior in some physical scenario:
X
τ−1
t¼0
MðρtÞ ≥inf
λ ∈ΔX
X
τ−1
t¼0
½DðρtkλÞ −Dðρtþ1kλ0Þ > 0;
ð13Þ
with again λ0 ¼ Wλ (see also Ref. [28]). The precise prior μ
in Eq. (12) for the EP cost function will depend on the
details of the precise physical process under consideration.
On the other hand, the sum Eq. (13) is independent of
those details. We therefore obtain a strictly positive lower
bound on EP, given in toto by ρ0 and W. This strengthened
second law arises solely from the fact that we have a
periodic
process
with
a
nonlogically
invertible
W.
Moreover, because minimization in Eq. (13) is over all
possible priors, it provides a lower bound on all costs that
can be written as in Eq. (8). We therefore refer to it as the
minimal dissipation.
As an example, suppose that our DTMC is the dynamics
of a noise-free, synchronous, digital computer, with update
function f∶X →X. Plugging in Eq. (13), the minimal
possible EP is
min
λ ∈ΔX
X
τ−1
t¼0
X
x ∈Ωt
ρ0½f−tðxÞ ln
ρ0½f−tðxÞ
λðxÞ

−ρ0½f−t−1ðxÞ ln
ρ0½f−t−1ðxÞ
λ½f−1ðxÞ

:
ð14Þ
The term Ωt in Eq. (14) is the set of all states that have
nonzero probability if the update function is applied to the
actual distribution ρ0 a total of t times. The term ρ0½f−tðxÞ
in Eq. (14) is the probability, under ρ, of the entire set of
those states in X which, after t iterations of (the periodic
processes underlying) the update function f of the digital
computer, are in state x (and similarly for ρ0½f−t−1ðxÞ).
Suppose that f is not just a permutation of the states of the
computational machine that lie in the support of ρ0. Then
Eq. (14) provides a strictly positive lower bound on the
dissipation incurred by any physical device that implements
that computation, f.
In the sense that it depends only on the conditional
distribution W and the initial distribution ρ0, the bound for
periodic processes in Eq. (13) is similar to the generalized
Landauer’s bound. In particular, the thermodynamic uncer-
tainty relations and speed limit theorems are also lower
bounds on EP that depend on the initial distribution over
states and the discrete-time conditional distribution of
the dynamics. However, unlike the lower bound above,
those other bounds depend on other properties of the
process besides the initial distribution and the conditional
distribution giving the dynamics (for example, current
precisions or expected activities). In this sense, the minimal
dissipation given in Eq. (13) is more powerful than those
other lower bounds on EP (a closed form of this result in
terms of Jensen-Shannon divergence has also been reported
very recently in Ref. [70]).
In this paper, we calculate mismatch costs by summing
the cost over single iterations of a computational machine
operating periodically, as in Eq. (12). In general this does
not equal the standard mismatch cost for the entire com-
putation, with an overall prior and a single drop in KL
divergence between initial and final time τ. We remark that,
to our knowledge, the necessary and sufficient conditions
for this quantity to be larger than the one we use in this
paper are not known. However, there is a particularly
interesting case in which these two expressions become
the same, namely, when EP is minimized at the stationary
state of the DTMC; i.e., the prior μ coincides with π. In
such case we recover from Eq. (11) the well-known
decomposition of EP into adiabatic and nonadiabatic con-
tributions [52,53,71,72], where mismatch cost reduces to
nonadiabatic EP (also called excess EP [19]) and the residual
cost becomes adiabatic EP (housekeeping heat [53,71]).
D. Deterministic finite automata
An important class of computational machines that can
be described within our framework are the DFA. There are
several different, very similar definitions of DFA, some of
which overlap with common definitions of “finite state
machines.” To fix the discussion, here we adopt the
following definition. A deterministic finite automaton is
a 5-tuple ðQ; θ; q0; A; fÞ, where
(1) Q is a finite set of (logical) states,
(2) θ is a finite (input) alphabet,
(3) q0 ∈Q is the start state,
(4) A ⊆Q is the set of accept states, and
(5) f∶Q × θ →Q is the update function, mapping a
current input symbol and the current logical state to a
next logical state.
A finite string of successive input symbols, i.e., an input
string ω ∈θ, is sometimes called an (input) word. To
operate a finite automaton on a particular input word,
one begins with the automaton in its start state, and feeds
that state together with the first symbol in the input word
into the update function, to produce a new logical state.
Then one feeds in the next symbol in the input word (if
any), to produce a next logical state. Note that one can
represent any given DFA’s update function as a directed
graph, where each edge ðq1; q2Þ taking logical state q1 to
state q2 is labeled by the input symbols that would cause
that transition [see Figs. 1(c) and 2 for illustrations].
Our analysis of stochastic computational processes
(as introduced above) in DFAs requires assigning proba-
bilities to the input words (or to the symbols inside them)
that are fed into the automaton, as well as identifying the
computational states of the DTMC X, which may coincide
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-7

or not with the set Q of logical states of the DFA (typically,
X may contain more variables as, e.g., previously proc-
essed symbols). An important contribution of our work will
be to show how one can do this analysis even though the
dynamics of a DFA—its update function—is deterministic
and often noninvertible (i.e., unidirectional), and given that
the initial distribution over states of the DFA (though not
over the input words) is a delta function, centered on the
start state (i.e., leading to absolute irreversibility).
Physically, the (probabilistically generated) input word
ω may be encoded in a tape whose symbols are read by the
DFA “head” one by one in each cycle of the computation,
but are not modified by the automaton operation [73]. In
this way the input tape behaves as an (energyless) infor-
mation reservoir [74], whose Shannon entropy is kept
constant during the computation. More formally, we can
consider that tape as forming part of the physical states of
the computation in the extended state space Y (a Cartesian-
product factor of Q, ω, and other physical variables
depending on the implementation), but we will not generi-
cally include it within the computational states in X [75].
On the other hand, we will eventually incorporate some
already processed symbols explicitly into X, which are
then assumed to be stored (and modified) in extra physical
variables acting as a memory for the computer.
A typical question of interest in computer science is
whether the DFA is in an accept state of the set A after the
last symbol from the input word is processed. If that is the
case, one says that the automaton accepts that input word.
In this way any given automaton uniquely specifies a
language of all input words that automaton accepts, which
is called a regular language. Importantly, any particular
DFA can process input words of arbitrary length [76], and
in general may enter and exit its set of accepting states
multiple times, before the end of the input word. While the
definition of whether an input word is accepted depends
only on whether the ending logical state is an accepting
state, the statistics of whether, how often, and precisely
when a given DFA enters an accept state (when fed words
generated by some given distribution) can be of indepen-
dent interest.
III. INTRINSIC THERMODYNAMICS OF
COMPUTATIONS AT FIXED TIMES
The mismatch cost sum introduced in Eq. (12) depends
only on the computational degrees of freedom involved
in the original DTMC dynamics and provides a lower
bound on the average entropy production generated by
the machine implementing the computation. It is hence a
particularly useful candidate to assess the intrinsic (min-
imal) thermodynamic costs of computations. The prior μðxÞ
encodes the specific details of the physical implementation
of the computational process. Concern for such details can
even be avoided by considering the distribution νðxÞ given
by the infimum of Eq. (13), which still provides a useful
(positive) bound on EP.
To begin, we construct a stochastic description based on
thermodynamic quantities that can be computed by intro-
ducing an auxiliary process. This process is defined in
terms of the “forward” discrete-time dynamics PðjjiÞ,
the initial distribution of that dynamics ρ0ðxÞ, and a
reference distribution rðxÞ over computational states.
The reference rðxÞ is arbitrary, and in particular could
be chosen to obtain stochastic versions of the mismatch
cost sum in Eq. (12) [rðxÞ ¼ μðxÞ] and the minimum
dissipation in Eq. (13) [rðxÞ ¼ νðxÞ].
A. Thermodynamic costs of periodic computations
at the fluctuating level
We start by introducing the discrete-time auxiliary
dynamics of the auxiliary process
¯Wi;j, with transition
probabilities defined from the transition probabilities
in W by
¯PðijjÞ ≡PðjjiÞrðiÞ
r0ðjÞ
;
ð15Þ
where r0 ¼ Wr is the reference distribution r evolved
for one iteration; i.e., r0ðjÞ ¼ P
i PðjjiÞrðiÞ [77]. This
auxiliary process is a bona fide Markov chain with
P
i ¯PðijjÞ¼P
i½PðjjiÞrðiÞ=r0ðjÞ¼1 and 0≤¯PðijjÞ≤1 [78].
FIG. 2.
(a) Discrete-time Markov chain (DTMC) associated
with the DFA recognizing binary i.i.d. sequences that are multiple
of four [see Fig. 1(c)]. The transition matrix of such DTMC is
given by Eq. (54) where p0 and p1 ¼ 1 −p0 denote, respectively,
the probability for a 0 and a 1 in the input string. (b) DTMC
associated with the auxiliary dynamics associated with the
stationary prior, with transition probability matrix obtained from
Eq. (15) and given by Eq. (57).
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-8

Moreover, r0 transforms back into r in a singleiteration under
¯W. That is, ¯W corresponds to the Bayesian inverse of W with
respect to the reference distribution r, leading to perfect
retrodiction for the distribution r [62,79–81].
To fully specify the auxiliary dynamics we must specify
its initial distribution; here we will always set it to dis-
tribution of the original actual dynamics at its limit time,
i.e., ¯ρ0ðxÞ ¼ ρτðxÞ. So the joint distribution of a trajectory
x½0;τ under the auxiliary dynamics is
¯Pðx½0;τÞ ¼ ¯ρ0ðxÞ
Y
τ−1
t¼0
¯Pðxtþ1jxtÞ:
ð16Þ
Note that this choice of the initial distribution of the
auxiliary process is not restricted by the choice of r in
any way. Note as well that ¯PðijjÞ does not necessarily
coincide with the transition probabilities induced by the
time-reversed implementation of the underlying physical
process, but it is solely defined from the distribution rðxÞ
and the original Markov chain transition probabilities.
Using Eqs. (15) and (16), we can write the probability
of a time-reversed discrete-time trajectory, Θx½0;τ ¼ xτ;
xτ−1; …; x0, under the auxiliary dynamics as
¯PðΘx½0;τÞ ¼ ¯ρ0ðxτÞ ¯Pðxτ−1jxτÞ… ¯Pðx0jx1Þ
¼ ρτðxτÞ
Y
τ−1
t¼0
Pðxtþ1jxtÞ rðxtÞ
r0ðxtþ1Þ :
ð17Þ
The ratio between the path probability to observe a given
trajectory of states and the path probability to observe its
time reversal under the auxiliary dynamics is
Σðx½0;τÞ ≡ln½Pðx½0;τÞ= ¯PðΘx½0;τÞ
¼
X
τ−1
t¼0

ln ρtðxtÞ
rðxtÞ −ln ρtþ1ðxtþ1Þ
r0ðxtþ1Þ

;
ð18Þ
providing us, for r ¼ μ, a stochastic version of the mis-
match cost sum in Eq. (12), and for r ¼ ν, the minimal
dissipation in Eq. (13). The functional Σðx½0;τÞ is an
example of a “Σ-entropic functional,” as introduced in
Ref. [19].
The specific choice for the transition probability of
the auxiliary dynamics introduced in Eq. (15) is crucial
for avoiding divergences that would be induced by
unidirectional
links
if
we
evaluate
expressions
like
ln½PðijjÞ=PðjjiÞ—expressions that appear in most func-
tionals associated with entropy production. This makes
the functional Σ given by Eq. (18) suitable to tackle
fluctuations of Markovian processes with unidirectional
transitions, which are precisely the (idealized) dynamics
of many computational processes.
Here and in the following, as shorthand, we will often
write trajectory-level quantities such as Σðx½0;τÞ simply as
ΣðτÞ, with the precise trajectory left implicit. Following
such shorthand notation, Eq. (18) can be decomposed as
ΣðτÞ ¼ ΔSsysðτÞ −ΔϕðτÞ;
ð19Þ
where we write the change in stochastic Shannon entropy
of the computer as
ΔSsysðx½0;τÞ ≔−
X
τ−1
t¼0
½ln ρtðxtÞ −ln ρtþ1ðxtþ1Þ
¼ −ln ρτðxτÞ þ ln ρ0ðx0Þ;
ð20Þ
and write the change in the nonequilibrium potential as
Δϕðx½0;τÞ ≔
X
τ−1
t¼0
½−ln r0ðxtþ1Þ þ ln rðxtÞ:
ð21Þ
Such
nonequilibrium
potentials
have
been
fruitfully
employed in steady-state thermodynamics [41,53,82],
and account for the excess of entropy absorbed from the
environment during the computation x½0;τ whenever the
state of the system ρt differs from the distribution r along its
time evolution.
Suppose that the initial distribution ρ0ðxÞ has full
support. Then if we average Eq. (18) over Pðx½0;τÞ we get
h ¯PðΘx½0;τÞ=Pðx½0;τÞi ¼ 1, which is an integral fluctua-
tion relation [3], he−ΣðτÞi ¼ 1. Moreover, hln½Pðx½0;τÞ=
¯PðΘx½0;τÞi ≥0 is a KL divergence, which can be rewritten
in an appealing form as
hΣðτÞi ¼
X
τ−1
t¼0
½DðρtkrÞ −Dðρtþ1kr0Þ ≥0:
ð22Þ
We notice that for the choice r ¼ μwe recover the expression
for mismatch cost sum in Eq. (12), while for r ¼ ν we
obtain Eq. (13), as expected. Crucially, for the two choices
r ¼ μ and r ¼ ν, the quantity hΣðτÞi provides a lower bound
on the total average entropy production incurred in the
physical implementation of the computational process, and
therefore we may refer to it as the intrinsic mismatch cost
associated to a given computation. We remark that here and
above averages are over trajectories of fixed length τ; that
is, hΣðτÞi ≡EðΣðτÞÞ.
For more general choices of r, the quantity ΣðτÞ can still
be defined (as long as the distribution r has full support
over X); however, it cannot be guaranteed in general that
hΣðτÞi would provide a lower bound on the underlying
entropy production anymore. In particular, by taking r ¼ π,
the stationary state of the DTMC, ΣðτÞ becomes the
discrete-time nonadiabatic entropy production for a relax-
ation process, whose average reads
hΣðτÞi ¼ Dðρ0kπÞ −DðρτkπÞ ≥0;
ð23Þ
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-9

thus we recover the expression for EP proposed by
Spohn [83] (see also Ref. [41]). Remarkably, in this case
hΣðτÞi becomes nonextensive in time, contrary to the
general case [cf. Eq. (22)]. As a consequence, the steady
state π of the DTMC (whenever aperiodic and irreducible)
becomes the natural candidate for the prior ν providing the
infimum in Eq. (13) in the large time limit. Therefore we
expect the nonadiabatic entropy production in Eq. (23) to
provide the minimum dissipation of the computation in
many cases of interest. However, it is worth remarking that
for ensuring the average nonadiabatic entropy production
to be a lower bound on the EP would require π to share
support with the initial distribution ρ0—which would often
not be the case in the computational context—and π being
also invariant state in the time-reversed (underlying)
physical dynamics of the computer [41].
B. Role of absolute irreversibility
In many models of computation in TCS, the initial
distribution ρ0ðxÞ over the states of the computational
machine is restricted to a subset of computational states
in X. For instance, almost any automaton—in particular,
not just a DFA but also a TM—starts in a single,
predetermined state x0. Such a system may have a delta
function initial distribution, ρ0ðxÞ ¼ δx;x0. For such an initial
distribution the quantity e−ΣðτÞ ¼ ¯PðΘx½0;τÞ=Pðx½0;τÞ may
become ill defined as there might be trajectories for which
Pðx½0;τÞ ¼ 0, but ¯PðΘx½0;τÞ > 0, e.g., trajectories in the
auxiliary dynamics that do only reach states different from
x0. This phenomenon has been often referred to as absolute
irreversibility [84,85].
Following the techniques in Refs. [84–86] one can cir-
cumvent the divergence associated with absolute irrevers-
ibility by restricting the averages over sets of trajectories for
which the functional of the intrinsic mismatch cost e−ΣðτÞ is
well defined. Adopting the language of modern probability
theory [87], we call such sets filtrations (see also Ref. [19]).
In particular, we denote F the filtration containing all
possible trajectories x½0;τ taking place in ½0; τ. Similarly,
we call F AI the filtration containing all “absolutely irrevers-
ible” trajectories, that is, trajectories for which Pðx½0;τÞ ¼ 0,
but ¯PðΘx½0;τÞ > 0. On the other hand, we denote the
complementary set of “absolutely continuous” trajectories
as F AC, such that F ¼ F AC ∪F AI. Using these definitions,
an extended version of the integral fluctuation theorem (IFT)
for the intrinsic mismatch cost follows
he−ΣðτÞi ¼ 1 −γτ;
ð24Þ
where 0 ≤γτ ≤1 the total probability that the time-reversed
picture of any absolutely irreversible trajectory (i.e., belong-
ing to F AI) occurs in the auxiliary dynamics
γτ ¼
X
x½0;τ ∈F AI
¯PðΘx½0;τÞ ≤1:
ð25Þ
Applying Jensen’s inequality hexi ≥ehxi to the IFT Eq. (24)
we obtain a lower bound on the intrinsic mismatch cost,
implying a minimum dissipation due to the restricted initial
condition:
hΣðτÞi ≥−ln½1 −γτ ≥0;
ð26Þ
where the second inequality follows from γτ ≥0 and hence
extends the applicability of Eq. (22) to systems showing
absolute irreversibility. We remark that here absolute
irreversibility arises because of the restricted initial dis-
tribution, but not because of the unidirectional transitions,
since they have been flipped in the auxiliary dynamics
according to Eq. (15). Fluctuation theorems similar to
Eq. (24) have been previously derived within the canonical
framework of stochastic thermodynamics for entropy
production [84] and standard mismatch cost [49], as well
as in the inclusive Hamiltonian framework for entropy
production [29].
IV. THERMODYNAMICS OF COMPUTATIONS
AT STOCHASTIC STOPPING TIMES
We now extend our analysis to investigate the thermody-
namics of computations which first reach a computational
state of interest at a time that varies depending on the random
input provided to the computer. In doing so, we extend the
martingale theory for stochastic thermodynamics [19] to
accommodate unidirectional transitions and arbitrary initial
distributions leading to absolute irreversibility.
Consider a random sequence of τ bits sequentially fed
into a computer (e.g., a DFA) (see also Fig. 1):
0 0 0 1 0 1…0 1 1 1
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
τ bits
;
ð27Þ
with τ ≥1 being the word length processed by the
machine. While processing a specific sequence, the com-
puter jumps between its computational states, as described
in Sec. II D. We are interested in the thermodynamics of the
(physical implementation of the) computer during the time
from when it starts to a stopping time T , that is until when a
stopping condition is met. For example, we will often
consider that the stopping condition is simply that the
computer has for the first time reached an accept state. Note
that this stopping time generally takes a different value
when processing different words. Since the words are
generated by sampling a distribution, this means that the
stopping time is a random variable.
Generalizing from this case to give a fully formal
definition, a stopping time is the earliest instance when a
particular condition concerning the entire trajectory gene-
rated by a stochastic process is met:
T ðx½0;tÞ ≔infft ∈½0; τjx½0;t ∈Ωg;
ð28Þ
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-10

where Ω ⊆F denotes the set of trajectories satisfying the
stopping condition. For example, Ω might be the set of
trajectories of a given DFA that have reached an accept
state at least once.
Note that its definition in Eq. (28) involves a limit time τ.
So the stopping time associated with each stochastic trajec-
tory is a bounded random variable that obeys 0 ≤T ≤τ. As
shorthand, from now on we will typically just write “T ,”
leaving the precise trajectory x½0;T  implicit. It is also worth
remarking that the computational machine does not neces-
sarilystopfunctioningatT ,butthisvariablecanjust signalto
us thetime at which a specific computation isprocessed (e.g.,
accepting a word). We will therefore sometimes refer to T in
this context as the computation time, which is a particular
instance of a (bounded) stopping time.
A. Martingale theory with absolute irreversibility
Inspired by Ref. [16], we now introduce the stochastic
distinguishability between the computational process and
the auxiliary process. Stochastic distinguishability (with
respect to time τ) evaluated at time t ≤τ is defined as
δτðtÞ ≔ln ρtðxtÞ
¯ρτ−tðxtÞ ;
ð29Þ
where ¯ρτ−tðxÞ is the probability distribution of the auxiliary
process defined in Eq. (15), evaluated at the conjugate time
τ −t for the state xt. [Recall that the auxiliary dynamics has
initial distribution ¯ρ0ðxÞ ¼ ρτðxÞ; i.e., it is the distribution
of the original dynamics at the limit time τ.] Stochastic
distinguishability is a measure of the asymmetry between
the original and the auxiliary dynamics and plays a crucial
role in martingale theory for stochastic thermodynamics of
nonstationary processes [19].
It will be useful to consider an associated process
involving the stochastic distinguishability,
MτðtÞ ≔e−ΣðtÞ−δτðtÞ
¼ ¯ρτ−tðxtÞ
ρtðxtÞ
Y
t−1
s¼0
rðxsÞ
ρsðxsÞ
ρsþ1ðxsþ1Þ
r0ðxsþ1Þ

:
ð30Þ
In the second line of Eq. (30) we used the first equality in
Eq. (18) together with Eq. (29) and the second line in Eq. (18).
Note that MτðτÞ ¼ e−ΣðτÞ because δτðτÞ ¼ 0. In general
though δτðtÞ ≠0 for t < τ, and so MτðtÞ ≠e−ΣðtÞ for such t.
An important property of Mτ is that the expectation of
MτðτÞ conditioned on a fixed trajectory ending at a time
0 ≤t ≤τ satisfies
hMτðτÞjx½0;ti ¼ MτðtÞ½1 −ατðtÞ;
ð31Þ
where we introduced the quantity defined by
ατðtÞ ≔
X
x½tþ1;τ ∈F AI
¯PðΘx½t;τÞ
¯ρτ−tðxtÞ ≤1;
t < τ;
ð32Þ
and ατðτÞ ≔0 (see Appendix E for details). Combining
Eq. (31) with the fact that ατðtÞ ≤1, we establish that
MτðtÞ ¼ e−ΣðtÞ−δτðtÞ is a supermartingale,
hMτðτÞjx½0;ti ≤MτðtÞ;
ð33Þ
i.e., its conditional expectation given a fixed trajectory of
length t < τ monotonically decreases over time. Note that
for t ¼ 0 one has Σð0Þ ¼ 0 and, hence, Eq. (31) yields the
IFT with absolute irreversibility [cf. Eq. (24)]:
he−ΣðτÞi ¼ hMτðτÞi ¼
X
x0
ρ0ðx0ÞhMτðτÞjx0i
¼
X
x0
ρ0ðx0ÞMτð0Þ½1 −ατð0Þ ¼ 1 −γτ;
ð34Þ
where we have used Eq. (25) in the last equality. In
addition, in the absence of absolute irreversibility, F AI is
the empty set and ατðtÞ ¼ 0 for all t ∈½0; τ. In such a case
MτðtÞ in Eq. (31) becomes a martingale. Therefore, in that
limit we would be able to use the analysis in Refs. [16,19]
on the thermodynamics of systems with stochastic stopping
times. However, that analysis does not directly apply for
generic initial states ρ0ðxÞ without full support.
B. Integral fluctuation relations with absolute
irreversibility at stopping times
Fortunately, the fact that MτðtÞ is a supermartingale
rather than a martingale when our system has absolute
irreversibility does not prevent us from analyzing its
thermodynamics at stopping times. To carry out such
analysis, here we closely follow the derivation of Doob’s
optimal stopping theorem for martingales, generalizing it to
apply to supermartingales that are written as in Eq. (31).
As elaborated in Appendix F, this generalized form of the
optimal stopping theorem provides a fluctuation theorem at
stopping times, which is valid even in the presence of
absolute irreversibility:
he−ΣðT Þ−δτðT Þi ¼ hMτðT Þi ¼ 1 −Γτ;
ð35Þ
where T ≤τ is the (stochastic) stopping time, Γτ ∈½0; 1 is
a contribution from absolute irreversibility, and therefore
he−ΣðT Þ−δτðT Þi ≤1. Since h·i is an average over trajectories,
and different trajectories have different stopping times,
he−ΣðT Þ−δτðT Þi involves averaging over (stochastic) values
of T . This introduces statistical coupling between the time
T and the value ΣðT Þ.
The quantity Γτ appearing in Eq. (35) is an average of
the functional e−δτðT Þ evaluated at stopping times T for
trajectories leading to absolute irreversibility:
Γτ ≔
X
τ
T ¼0
X
x½0;T  ∈F ðT Þ
AI
¯PðΘx½0;T Þ ¯ρτ−T ðxT Þ
ρT ðxT Þ :
ð36Þ
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-11

To understand its meaning intuitively, first note that the
second summation in Γτ is done over trajectories x½0;T  that
belong to F ðT Þ
AI , that is, trajectories verifying the stopping
condition for the first time at T , but that have zero pro-
bability to occur in the original process Pðx½0;T Þ ¼ 0, due
to the restricted shape of the initial distribution ρ0ðxÞ. We
notice also the presence of the distribution ¯ρτ−T ðxÞ, which
is due to δτðT Þ. That is, Γτ consists of the total probability
of trajectories starting at the stopped point xT according to
distribution ¯ρτ−tðxÞ, and not turning back to the set of states
with ρ0ðxÞ > 0 under the auxiliary dynamics. Recall also
that the reference distribution r determining the precise
meaning of ΣðT Þ appears in Eq. (36) only implicitly, due to
the definitions of ¯P and ¯ρt.
The inequality Γτ ≤1 is saturated when all trajec-
tories are in the set F AI ¼ F, for which the sum over
all trajectories in Eq. (36) is obtained; that is, Γτ ¼
Pτ
t¼0
P
x½0;t ∈F ðtÞ ¯PðΘx½0;tÞ¯ρτ−tðxtÞ=ρtðxtÞ ¼ 1. Moreover,
we also have Γτ ≥0, since it is a sum of probabilities.
Whenever the initial distribution ρ0ðxÞ is not restricted in
the state space, we obtain Γτ ¼ 0, and recover the standard
form of the fluctuation theorem at stopping times for
nonstationary processes [16,19].
It is worth remarking here that our previous results for
fixed times [Eqs. (24) and (25)] can be directly obtained from
Eqs. (35) and (39) by letting T ¼ τ, i.e., when all trajectories
are stopped at the final time τ, as we also discuss below in
more detail. Our results thus provide an extension of
martingale theory to cover different versions of mismatch
costs in physical scenarios with absolute irreversibility,
where martingales can be transformed into supermartingales
via the correction term ατðtÞ in Eq. (32), and stopping-time
fluctuation relations can be derived from them.
Moreover, using the fact that MτðtÞ is a supermartingale
[cf. Eq. (33)], we can also readily apply Doob’s optional
sampling theorem [88] for supermartingales to obtain (see
Appendix G)
he−ΣðT 2Þ−δτðT 2Þi ≤he−ΣðT 1Þ−δτðT 1Þi;
ð37Þ
where T 1 and T 2 are two stopping times, ordered such that
PðT 2 ≥T 1Þ ¼ 1, but otherwise arbitrary. Taking T 1 ¼ T
and T 2 ¼ τ, the above Eq. (37), together with the fluc-
tuation theorem for stopping times [Eq. (35)] and fixed
times [Eq. (34)] implies
Γτ ¼ 1 −he−ΣðT 2Þ−δτðT 2Þi
≤1 −he−ΣðτÞi ¼ γτ;
ð38Þ
where we have used δτðτÞ ¼ 0. The above inequality
implies that the absolute irreversibility term at stopping
times Γτ is always smaller than its fixed-time counterpart
γτ; that is, absolute irreversibility implies always greater
dissipation at fixed times than at stopping times.
C. Second-law inequalities at stopping times:
Universal lower and upper bounds
If we apply Jensen’s inequality hexi ≥ehxi to the
fluctuation theorem of Eq. (35) we derive a second-law
inequality at stopping times:
hΣðT Þi ≥−hδτðT Þi −ln½1 −Γτ:
ð39Þ
This sets a strict lower bound on the average dissipation
incurred by a given computation up to an arbitrary stopping
time T , from its time-reversal symmetry breaking [as
quantified by hδτðT Þi] and the absolute irreversibility
(as quantified by Γτ).
Moreover,
Γτ ≥0
implies
that
−ln½1 −Γτ ≥0.
Therefore, Eq. (39) also implies the simpler bound:
hΣðT Þi ≥−hδτðT Þi:
ð40Þ
These inequalities suggest that hΣðT Þi might be negative
whenever hδτðT Þi ≥−ln½1 −Γτ ≥0, as we discuss in
detail below.
Any concave function [such as lnðxÞ] of a supermartin-
gale yields another supermartingale by Jensen’s inequality.
Therefore, the supermartingale property of MτðtÞ also
implies that ln½MτðtÞ ¼ −ΣðtÞ −δτðtÞ is supermartingale.
So ΣðtÞ þ δτðtÞ is a submartingale; i.e., it conditionally
increases with time. If we now invoke Doob’s optional
sampling theorem for submartingales, we get the inequality
hΣðT 2Þ þ δτðT 2Þi ≥hΣðT 1Þ þ δτðT 1Þi;
ð41Þ
where again T 1 and T 2 are two ordered stopping times
with PðT 2 ≥T 1Þ ¼ 1. This inequality has several impli-
cations, the most immediate one being a second law for
intervals between two ordered stopping times T 1 and T 2:
hΔΣðT 1; T 2Þi ≥−½hδτðT 2Þi −hδτðT 1Þi;
ð42Þ
where hΔΣðT 1; T 2Þi ≔hΣðT 2Þi −hΣðT 1Þi. This inequal-
ity provides a result applicable to both stochastic stopping
and starting times, bounding the entropy production
incurred for computations that both start and end at
stochastic times.
As an example, inequality (42) provides a bound con-
cerning the stochastic interval between the first time that a
DFA enters an accept state and the earliest subsequent time
that it again enters an accept state, after having left the set of
accept states in between. Then the time up to T 1 can be
interpreted as the time it took for the DFA to accept a first
substring of the full input word, and the time between T 1
and T 2 can be interpreted as the time it took for the DFA to
accept a second substring of the full input word, a sub-
string which follows the first one. Again, the inequa-
lity in Eq. (42) suggests that hΔΣðT 1; T 2Þi might even-
tually become negative for such a case, whenever
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-12

there is an increasing time-reversal asymmetry, i.e., for
hδτðT 2Þi > hδτðT 1Þi.
Moreover, for the choice T 1 ¼ T
and T 2 ¼ τ, the
inequality (41) gives us the following upper bound for
the intrinsic mismatch cost at stopping times:
hΣðT Þi ≤hΣðτÞi −hδτðT Þi:
ð43Þ
The inequality (43) implies that whenever hδτðT Þi ≥0, the
intrinsic mismatch cost at stopping times will be upper
bounded by its fixed-time counterpart, suggesting a drop in
the thermodynamic costs of the computation at stopping
times. On the other hand by taking T 1 ¼ 0 and T 2 ¼ T in
Eq. (41), we obtain an alternative second law at stopping
times, namely,
hΣðT Þi ≥Dðρ0k¯ρτÞ −hδτðT Þi;
ð44Þ
to be compared with Eqs. (39) and (40). Here we have used
that Σð0Þ ¼ 0 and
hδτð0Þi ¼
X
x0
ρ0ðx0Þ ln ρ0ðx0Þ
¯ρτðx0Þ ¼ Dðρ0k¯ρτÞ:
ð45Þ
This inequality provides us an alternative lower bound
on the intrinsic cost of the computation. We notice that,
while we expect it to be less tight in general than Eq. (39), it
has the advantage of relying on the KL divergence between
initial distribution ρ0 and the final distribution in the
auxiliary dynamics ¯ρτ, which we expect to be more easily
computable than Γτ in Eq. (36). Remarkably, combining
Eqs. (43) and (44) we find a sandwich inequality for the
intrinsic mismatch cost at stochastic times,
Dðρ0k¯ρτÞ −hδτðT Þi ≤hΣðT Þi ≤hΣðτÞi −hδτðT Þi;
ð46Þ
which provides both upper and lower bounds on hΣðT Þi.
The stopping-time fluctuation relation in Eq. (35) and the
inequalities (39)–(44) for the intrinsic thermodynamic costs
in computational processes with stochastic stopping times
provide our main results. In the following we further
discuss their interpretation and some of their implications,
while in Sec. V we investigate their applications to
computer science setups with some illustrative examples.
D. Thermodynamic interpretation and implications
The second-law inequality (40), hΣðT Þi ≥−hδτðT Þi [as
well the stronger versions Eqs. (39) and (44)], suggests
that both the intrinsic mismatch cost and the underlying
entropy production incurred in a given computation may be
negative on average when evaluated at stopping times. To
understand how this is possible in light of the data-
processing inequality, we write hΣðT Þi explicitly as the
functional Eq. (18) averaged over many trajectories that are
stopped each at a stochastic time T :
hΣðT Þi ¼
X
τ
T ¼0
pðT Þ
X
T −1
t¼0
X
xt
ρtðxtjT Þ ln ρtðxtÞ
μðxtÞ
−
X
xtþ1
ρtþ1ðxtþ1jT Þ ln ρtþ1ðxtþ1Þ
μ0ðxtþ1Þ

:
ð47Þ
Here, pðT Þ denotes the probability that the stopping
time takes value T . Similarly, ρtðxjT Þ denotes the con-
ditional probability that the process takes the value x
at time t given that the stopping condition is met at
time T . Because ρtðxjT Þ ≤ρtðxÞ in general, the terms
P
xt ρtðxtjT Þ ln½ρtðxtÞ=μðxtÞ
and
P
xtþ1 ρtþ1ðxtþ1jT Þ ×
ln½ρtþ1ðxtþ1Þ=μ0ðxtþ1Þ are not KL divergences in general,
and thus not necessarily greater than or equal to zero (see
also Chap. 8.3 in Ref. [19]). This implies that hΣðT Þi can in
principle be negative. The second law at stopping times
Eq. (40) permits hΣðT Þi ≤0 whenever hδτðT Þi ≥0; yet it
is not clear when this would actually be the case.
The explicit expression for the stochastic distinguish-
ability at stopping times reads
hδτðT Þi ¼
X
τ
T ¼0
X
xT
pðT ÞρT ðxT jT Þ ln ρT ðxT Þ
¯ρτ−T ðxT Þ :
ð48Þ
Equation (48) also reveals that hδτðT Þi is not a KL
divergence in general, and thus can in principle take any
sign, yet so far only examples where hδτðT Þi ≥0 have
been reported in the literature. We remark that hδτðT Þi is
not a KL divergence unless T ¼ τ, for which the process
“stops” at the deterministic limit time τ, and one has that the
joint stopping-time probability distribution
pðT ÞρtðxtjT Þ ¼
 0
if T < τ
ρτðxτÞ
if T ¼ τ;
ð49Þ
i.e., it takes the value, at time τ, of the solution of
the master equation. Plugging in Eq. (49) in Eq. (48)
one gets hδτðT ¼ τÞi ¼ Dðρτk¯ρ0Þ ¼ 0 because ¯ρ0 ¼ ρτ.
Analogously for T ¼τ, intrinsic mismatch cost hΣðT ¼ τÞi
takes the expression Eq. (22), thus retrieving non-negativity
hΣðτÞi ≥0. Note that other examples of negative entropy
production at stopping times based on threshold criteria for
work were first reported in Ref. [16] and for free energy
more recently [89]. Such gambling demon [16] effect is
allowed whenever hδðT Þi > 0, which is not guaranteed for
arbitrary stopping conditions but possible for wise stopping
strategies, as shown experimentally in Refs. [16,89].
We can obtain further insight on this effect by decom-
posing the intrinsic mismatch cost at fixed times τ in two
terms, one associated to intervals ½0; T  up to the stopping
time T and ½T ; τ from the stopping time to the limit time τ;
that is,
hΣðτÞi ¼ hΣðT Þi þ hΔΣðτ; T Þi ≥0;
ð50Þ
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-13

which follows from the fact that T is a single-valued
function of the trajectory. Since hΣðτÞi ≥0, the above
decomposition implies that, whenever hΣðT Þi < 0, such a
negative value must be compensated by an incremented
mismatch cost hΔΣðτ; T Þi ≥hΣðτÞi incurred in the interval
½T ; τ, if no external action is taken on the system at time T
to physically stop the dynamics. These considerations will
be valid also in cases where the stopping condition is
structurally imposed through the dynamical evolution of
the computational process, e.g., using absorbing accept
states to “stop” the computation, as it is the case in some
models of DFAs.
The role of absolute irreversibility as captured in the
stronger inequality (39) with −ln½1 −Γτ ≥0 makes more
difficult the observation of negative average intrinsic
mismatch cost, since it would require a higher time-reversal
asymmetry in the dynamical evolution leading to large
distinguishabilities hδðT Þi > −ln½1 −Γτ [and similarly
for inequality (44)]. Remarkably, however, the examples
explored in Sec. V show how still dissipation can be
reduced at stopping times thanks to a positive time-reversal
asymmetry hδðT Þi > 0, in agreement with Eq. (43) above.
This reduction might be linked to the information needed to
execute the stopping condition T , similarly to what
happens in feedback control scenarios [90,91]. However,
a general relation between these two quantities remains
unknown.
The second-law inequality at stopping times Eq. (40) can
be further rewritten using Eq. (19) in a form reminiscent of
Landauer’s principle:
−hΔϕðT Þi ≥−hΔSsysðT Þi −hδτðT Þi;
ð51Þ
where the lhs accounts for the excess entropy flow
dissipated into the environment as a consequence of a
drop in Shannon entropy of the computational states,
−hΔSsysðT Þi. Again, whenever hδτðT Þi > 0, the above
inequality suggests that the entropy flow to the environ-
ment may be eventually reduced. Here it is also worth
noticing that even in the case in which trajectories are
stopped when returned to the initial state (as in the DFA
example in Sec. V), the average system entropy change at
stopping times, namely, hΔSsysðT Þi ¼ hSsysðT Þi −Sðρ0Þ,
with
hSsysðT Þi ¼ −
X
T
pðT Þ
X
xT
ρT ðxT jT Þ ln ρT ðxT Þ;
ð52Þ
is nonzero even when xT ¼ x0 for all T , since in general
the distribution ρT ðxÞ ≠ρ0ðxÞ, as corresponds to a relax-
ation process.
The second-law inequalities derived above not only can
be applied to assess stochastic stopping times of a compu-
tation, but also to stochastic starting times; see Eqs. (41)
and (42). This extension allow us to apply our theory to
computations that may “stop” at multiple consecutive times
T 1 < T 2 <    < T n (see Sec. V for a particular example
in a DFA) or to the concatenations of simpler computations
that start at a stochastic time, after the previous one is
accomplished. We will further elaborate on the application
of starting times to the computation of concatenated words
with stochastic resetting in Sec. VII.
V. APPLICATION TO DETERMINISTIC
FINITE AUTOMATA
In this section, we analyze minimal yet insightful
examples of computations executed by deterministic finite
automata. A computational task for a DFA starts by it
receiving a sequence of exogenously generated symbols, an
input string or an input word ω. As the DFA iteratively
processes the symbols of the input string, it makes
associated transitions among its possible states. Here we
first assume that the sequence of symbols to the DFA
are produced in an independent identically distributed
(i.i.d.) manner and so the time evolution over the DFA
states while processing those strings can be modeled using
a DTMC. Then we will move to the case of input symbols
that are not produced in an i.i.d. manner, but from a
Markovian source. In the following examples, we consider
two minimal DFA models that processes binary strings.
In the first example involving i.i.d. symbol sources, the
DFA under consideration accepts strings which encode
binary numbers divisible by four, e.g., 0 (zero), 100 (four),
1100 (twelve), etc. In the second example, involving non-
i.i.d. sources, we use a DFA that accepts strings which
encode binary numbers divisible by three. In all cases, we
assume that the input string behaves as an information
reservoir [74] whose symbols are not modified by the
computation, hence not leading to further energy or entropy
changes (see Sec. II D).
The state of the DFA when a stopping condition is
reached (e.g., when the DFA enters a designated accept
state) defines a computation that the DFA performs on that
string. However, this computation can be followed by
further processing of input symbols up to a limit time τ
(e.g., the DFA may exit the accept state in forthcoming
iterations). In this sense our results for stopping times can
be applied to various situations, for example, (i) computa-
tions generated by input words of fixed length τ where we
ask about the value of thermodynamic quantities when
visiting the accept state for the first (or the nth) time and
(ii) computations that may actually end when visiting the
accept state for some reason (e.g., the accept state is an
absorbing state of the DFA or there exists an external
mechanism that activates when the accept state is reached
to stop the dynamics). In particular, we can always modify
a given DFA by removing all edges of the associated
directed graph that leave an accepting state. This turns the
accept state into an absorbing state (or set of states, if there
is more than one accepting state).
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-14

A. Processing symbols from i.i.d. sources
As mentioned above, consider the DFA from Fig. 1,
initialized to state q0 with certainty, and that its compu-
tation starts by processing a stream of binary letters
generated as an i.i.d. sequence of 0’s and 1’s, with
p0 ≤1 the probability to observe a 0 and p1 ¼ 1 −p0
the probability to observe a 1. Under this assumption, the
time evolution of the DFA’s states follows a DTMC over
four computational states q0, q1, q2, and q3, with transition
probabilities as indicated in Fig. 2(a). All together, the
Markov chain associated with the DFA’s dynamics is
characterized by its initial state,
ρ0 ¼ ½ 1
0
0
0 †;
ð53Þ
with † denoting here matrix transposition, and the transition
matrix
W ¼
2
6664
p0
0
p0
0
p1
0
p1
0
0
p0
0
p0
0
p1
0
p1
3
7775:
ð54Þ
It follows that for t ¼ 1 we have
ρ1 ¼ Wρ0 ¼ ½ p0
p1
0
0 †;
ð55Þ
whereas for larger times t ≥2,
ρt ¼ Wtρ0 ¼
h
p2
0
p0p1
p0p1
p2
1
i† ≡π;
ð56Þ
i.e., the dynamics already reaches the stationary state at the
second iteration.
For computing the auxiliary dynamics for this DFA’s
DTMC, we would need to identify the reference distribu-
tion rðxÞ appearing in Eq. (15) as the prior μðxÞ minimizing
the mismatch cost sum in Eq. (8) or νðxÞ leading to its
minimum in Eq. (13). For simplicity, here we assume
rðxÞ ¼ πðxÞ, the stationary state of the DFA dynamics.
This is a reasonable assumption as long as the induced
DTMC is aperiodic, irreducible, and π has full support over
the computational states. As discussed before, since Σ
becomes nonextensive in time in this case, there are reasons
to expect minimal dissipation in the steady state (see also
Refs. [92–94]).
The auxiliary dynamics starts in ¯ρ0 ¼ ρτ, which can take
two possible values depending on the value of the final
maximum time of the computation τ: If τ ¼ 1, we have
¯ρ0 ¼ ρ1, whereas for τ ≥2, we have ¯ρ0 ¼ π. Following
Eq. (15) for the transition probability, with r ¼ π, the
stationary distribution given in Eq. (56), we obtain the
transition matrix associated with the auxiliary dynamics:
¯W ¼
2
6664
p0
p0
0
0
0
0
p0
p0
p1
p1
0
0
0
0
p1
p1
3
7775;
ð57Þ
as illustrated in Fig. 2(b). It then follows that for compu-
tations ending at τ ¼ 1 we have ¯ρ1 ¼ ¯W¯ρ0 ¼ ¯Wρ1 ¼
½p0 0 p1 0†. On the other hand, since by construction,
the auxiliary dynamics Eq. (15) will always preserve the
steady state for r ¼ r0 ¼ π, it follows that in the case τ ≥2,
the auxiliary dynamics is stationary at all times t, that is,
¯ρtðτÞ ¼ ¯Wt¯ρ0 ¼ ¯Wtπ ¼ π, with π given by Eq. (56).
The intrinsic mismatch cost in Eq. (18), evaluated over a
trajectory x½0;τ, reduces in this case to the (discrete-time)
stochastic nonadiabatic EP:
Σðx½0;τÞ ¼
X
τ−1
t¼0

ln ρtðxtÞ
πðxtÞ −ln ρtþ1ðxtþ1Þ
πðxtþ1Þ

¼ ln ρ0ðx0Þ
πðx0Þ −ln ρτðxτÞ
πðxτÞ ;
ð58Þ
with xt ∈X ¼ fq0; q1; q2; q3g for all t, which depends only
on the initial and final states.
Having obtained the system probability distribution at all
times for the original and auxiliary dynamics, we are now
ready to compute thermodynamic quantities at stopping
times. In particular, we consider the family of stopping times
T ¼ minðT 1; τÞ;
ð59Þ
withτ fixingatimehorizonandT 1 ≥1thefirsttimetheDFA
returns to the accept state q0, hence accepting a word as a
multiple of four (including “0”). From numerical simula-
tions,weobtainedsamplehistogramsforthestoppingtime T
given by Eq. (59) for three different choices of the limit time
τ; see Fig. 3. There we observe the first peak at T ¼ 1 in the
three plots, corresponding to the cases where the first
incoming symbol is “0” and the word is then accepted. In
order to allow longer accepted words we need τ > 2, such
that T 1 ¼ 3 (accepting four “100”) or T 1 ¼ 4 (accepting
twelve “1100”), etc. Note, however, that with the stopping
condition given in Eq. (59), we do not capture the acceptance
of some of the multiples of four like, e.g., eighth “1000,”
since the stopping condition would already be verified at
previous symbol of the string, “100,” corresponding to four.
The samehappensfor anyotheracceptednumbertowhich an
arbitrary number of zeros are attached at the end. For
assessing the acceptance of such numbers, extra stopping
conditions such as T n, i.e., the nth time the DFA resturns to
the accept state q0, are needed (see example in Sec. V C).
For all trajectories in which T ¼ T 1 < τ, i.e., the word is
accepted before the limit time τ is reached, we have
xT 1 ¼ q0, the accept state, and thus
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-15

ΣðT 1Þ ¼ −ln ρT 1ðq0Þ ¼
 −ln p0
if T 1 ¼ 1
−2 ln p0
if T 1 ≥2;
ð60Þ
and the stochastic distinguishability in Eq. (29) is
δτðT 1Þ ¼ ln ρT 1ðq0Þ
¯ρτ−T 1ðq0Þ ¼
 −ln p0
if T 1 ¼ 1
0
if T 1 ≥2;
ð61Þ
where we used the fact that (by construction) τ > T 1 ≥1
and, hence, ¯ρτ−T 1 ¼ π.
If however T 1 ≥τ, the dynamics stops at the maximum
time T ¼ τ, independently of the state xτ, and we obtain
ΣðτÞ ¼ −ln ρτðxτÞπðq0Þ
πðxτÞ
¼
 −ln p0
if τ ¼ 1
−2 ln p0
if τ ≥2:
ð62Þ
Note that the case τ ≥2 is independent of xτ because the
system has already reached its stationary state, and thus
ΣðτÞ ¼ −ln πðq0Þ ¼ −2 ln p0 for all xτ ≠q0. On the other
hand, the stochastic distinguishability verifies δτðτÞ ¼ 0
since ¯ρ0 ¼ ρτ always.
Using the above calculations we obtain the average
intrinsic mismatch cost at the stopping time Eq. (59) for all
τ ≥2 as
hΣðT Þi ¼ ðp0 −2Þ ln p0 ≥0;
ð63Þ
which follows from
hΣðT Þi ¼ −PðT 1 ¼ 1Þ ln p0 −
X
τ
t¼2
PðT 1 ¼ tÞ2 ln p0
−PðT 1 > τÞ2 ln p0
¼ −p0 ln p0 −ð1 −p0Þ2 ln p0
¼ ðp0 −2Þ ln p0;
ð64Þ
where
we
have
used
PðT 1 ¼ 1Þ ¼ p0
and,
thus,
PðT 1 > 1Þ ¼ 1 −p0. In addition, using Eq. (61), we
obtain the average stochastic distinguishability at the
stopping time Eq. (59) for all τ ≥2:
hδτðT Þi ¼ −p0 ln p0 ≥0;
ð65Þ
where again we have used PðT 1 ¼ 1Þ ¼ p0. Note that the
above expressions also remain valid in the limit of large
input word lengths, τ →∞.
To tackle the contribution from absolute irreversibility at
stopping times, it is convenient to first identify which
trajectories contribute to Γτ in Eq. (36). These are trajec-
tories that are stopped at T ≤τ (either with or without
reaching q0) and have zero probability to occur in the
original dynamics. Note that the original dynamics is a
Markov chain with initial state ρ0ðxÞ ¼ δx;q0. The set of
absolutely irreversible trajectories at stopping times con-
sists of two sets: (i) trajectories that do not start in q0 and
reach q0 with T ≤τ in the original dynamics and (ii) tra-
jectories of length τ that do not start at q0 and do not reach
q0 in the original dynamics.
Let us now flesh out the list of such trajectories x½0;T 
classified by the value of T for the special case τ ¼ 2.
(i) q2q0 reaches the accept state at T ¼ 1, yet it has
zero probability to occur in the original dynamics
with ρ0ðq2Þ ¼ 0.
(ii) q1q2q0 and q3q2q0 reach the accept state at T ¼ 2,
yet they have zero probability to occur in the original
dynamics since ρ0ðq1Þ ¼ ρ0ðq3Þ ¼ 0.
(iii) q1q2q1, q1q3q2, q1q3q3, q2q1q2, q2q1q3, q3q2q1,
q3q3q2, and q3q3q3 are stopped at T ¼ 2 without
reaching the accept state. They have zero probability
in the original dynamics because their initial state is
different from q0.
All the sequences listed above are such that they would halt
the computation at the stopping time T ¼ minðT 1; 2Þ; they
have nonzero probability in the auxiliary dynamics but zero
probability in the original dynamics. In order to calculate
the absolute irreversibility correction term Γτ in Eq. (36),
we thus need the probability of the above trajectories to
occur in time-reversed order in the auxiliary dynamics.
More precisely, one needs to compute ¯PðΘx½0;T Þ multi-
plied by ¯ρτ−T ðxT Þ=ρT ðxT Þ ¼ πðxT Þ=ρT ðxT Þ, which in this
0
1
2
3
4
5
6
7
8
10 -2
10 -1
10 0
Probability
Probability
Probability
Stopping time, 
10 -2
10 -1
10 0
10 -3
10 -2
10 -1
10 0
10 -3
FIG. 3.
Stopping-time statistics for the DFA recognizing binary
numbers divisible by four, obtained from 104 numerical simu-
lations of the DTMC sketched in Fig. 2, with initial state q0, and
an absorbing accept state set also at q0. Simulations are done by
feeding the DFA with i.i.d. binary sequences with probability of
observing the letter 0 given by p0 ¼ 0.9, obtained from
Monte Carlo simulations of the discrete-time Markov chain
sketched in Fig. 2(c).
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-16

case is equivalent to modifying their initial condition to
πðxT Þ, i.e., to compute the following path probabilities:
¯Pðq0; q2jq0Þπðq0Þ ¼ p2
0p1:
¯Pðq0; q2; q1jq0Þπðq0Þ ¼ p2
0p1 p0;
¯Pðq0; q2; q3jq0Þπðq0Þ ¼ p2
0 p1 p1
¯Pðq1; q2; q1jq1Þπðq1Þ ¼ p0p1 p1 p0;
¯Pðq1; q2; q3jq1Þπðq1Þ ¼ p0p1 p1 p1;
¯Pðq2; q1; q2jq2Þπðq2Þ ¼ p0p1 p0 p1;
¯Pðq2; q3; q3jq2Þπðq2Þ ¼ p0p1 p1 p1;
¯Pðq2; q3; q1jq2Þπðq2Þ ¼ p0p1 p1 p0;
¯Pðq3; q3; q3jq3Þπðq3Þ ¼ p2
1 p1 p1;
¯Pðq3; q3; q1jq3Þπðq3Þ ¼ p2
1 p1 p0;
¯Pðq3; q1; q2jq3Þπðq3Þ ¼ p2
1 p0 p1:
ð66Þ
Summing up all the contributions in Eq. (66) leads us to the
absolute irreversibility contribution [cf. Eq. (36) for the
general formula]:
Γ2 ¼ p0p1ðp0 þ p2
0 þ 4p1p0 þ 4p2
1Þ þ p4
1
¼ 1 −p2
0:
ð67Þ
Combining all the terms above, we observe that for the
stopping time T ¼ minðT 1; 2Þ:
hΣðT Þi ¼ −hδ2ðT Þi −ln½1 −Γ2:
ð68Þ
In other words, the second law at stopping times given by
Eq. (39) is saturated over the stopping time given by
Eq. (59) for τ ¼ 2, as it is illustrated in Fig. 4 for different
values of the probability of incoming zeros p0. As can be
appreciated in this figure, the positive sign of the term
hδ2ðT Þi > 0 implies that the intrinsic mismatch cost at
stopping times hΣðT Þi ¼ −2 ln p0 þ p0 ln p0, see Eq. (65),
is smaller than its value at fixed times,
hΣðτÞi ¼ −2 ln p0 ≥hΣðT Þi;
ð69Þ
in spite of the presence of the absolute irreversibility
contribution with Γ2. For τ > 2, we have Γτ ≤Γ2,
which follows by combining the equality in Eq. (68)
with the generic bound in Eq. (39). In any case, the
inequality hΣðτÞi ≥hΣðT Þi holds for any limit time τ
for this example.
When p0 approaches 1 (words with a high number
of zeros) the dynamics cannot escape from the initial
state q0 and the steady state π becomes equal to the
initial distribution ρ0. In this limit, the DTMC dynamics
becomes fully stationary and, hence, the intrinsic mismatch
cost becomes zero for every trajectory, the time-reversal
asymmetry is lost, and the absolute irreversibility is no
longer present, leading to a drop in the three quantities on
the rhs of Fig. 4. As we move away from that limit, the
mismatch cost increases (both at stopping and fixed times),
signaling the energetic costs incurred by the computational
task, which grow as p0 decreases. This can be justified by
the fact that the dynamics on the DTMC spreads more
easily over all computational states as p1 increases [see
Fig. 4(a)], leading to a greater distinction between initial
and steady-state distributions. In this case we also observe
nonzero stochastic distinguishability and an increasingly
large absolute irreversibility term. In the limit p0 →0
(words with a high number of ones) accepting a word
becomes almost impossible, and hence the stopping occurs
most probably at the maximum time T ≃τ, leading again
to zero stochastic distinguishability. We notice that in this
limit π tends to localize at state q3 and, hence, it would lead
to hΣðτÞi →∞, which is not physically meaningful. The
catch point is that in this limit the fixed point π would not
be equal to the prior μ or ν anymore.
0.2
0.4
0.6
0.8
Probability of symbol 0 (p0 )
0
1
2
3
4
5
6
FIG. 4.
Illustration of analytical results for the second law at
stopping times applied to the discrete-time Markov chain model
of the DFA recognizing binary strings whose length is a multiple
of four [see Fig. 2(a)]. Here the computation stops at T ¼
minðT 1; τÞ for the limit time τ ¼ 2, or earlier if the accept state is
reached in one iteration. Symbols represent analytical results for
the averages at the stopping time for the relevant thermodynamic
quantities: intrinsic mismatch cost (nonadiabatic entropy pro-
duction) hΣðT Þi, given by Eq. (63) for prior equal to the
stationary probability (blue filled squares); minus the stochastic
distinguishability −hδ2ðT Þi, given by Eq. (65) (blue dotted line);
fixed-time nonadiabatic entropy production hΣðτÞi evaluated over
trajectories of the same length τ ¼ 2 (open symbols); and the
absolute
irreversibility
contribution
−ln½1 −Γ2,
given
by
Eq. (36) (blue dashed line). The blue solid line is given by the
sum −hδ2ðT Þi −ln½1 −Γ2 which in this example equals hΣðT Þi,
thus saturating the second law Eq. (39). The horizontal black
thick line is set to zero as a reference value.
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-17

B. Uniform prior
We now implement the analysis in Sec. VA for a
different setting, where the strings are generated i.i.d.
and we consider the same four-states DFA, now with a
uniform prior distribution over its states:
r ¼ ½ 1=4
1=4
1=4
1=4 †:
ð70Þ
The evolution of r under W after one iteration yields
r0 ¼ Wr ¼ ½ p0=2
p1=2
p0=2
p1=2 †:
ð71Þ
Because r changes after one iteration, we write Σ as in
Eq. (19) for τ > 0,
Σðx½0;τÞ ¼ ln ρ0ðx0Þ
ρτðxτÞ þ
X
τ−1
t¼0
ln r0ðxtþ1Þ
rðxtÞ ;
ð72Þ
where the first term is the system entropy change
ΔSsysðx½0;τÞ and the second term is the nonequilibrium
potential Δϕðx½0;τÞ in Eq. (21). Unlike for the stationary
prior, now this term is extensive with time [cf. Eq. (58)].
Note that in this case Σ is no longer equal to the nonadibatic
EP associated with the stochastic trajectory x½0;τ.
The uniform distribution is not invariant under the
map W; hence the intrinsic mismatch cost Σ associated
with a stochastic trajectory x½0;τ is extensive with time. This
implies that, unlike for the case of stationary prior (see
Sec. VA), the averages of Σ at fixed times τ as well as at
stopping times with limit time τ [of the form of Eq. (59)]
will crucially depend on τ. This is also the case for any
other choice for the prior distribution which differs from the
stationary distribution.
In Fig. 5 we show the intrinsic mismatch cost hΣðT Þi at
the stopping time T ¼ minðT 1; τÞ for the DFA with the
uniform prior for two different values of τ, and compare it
with the case of stationary prior, Eq. (63). We observe that
the uniform prior leads to higher values for the intrinsic
mismatch cost for high values of p0, while for low p0
values the tendency can be inverted. However, when
increasing τ sufficiently we always obtain a lower cost
for the stationary prior, as expected from its nonextensivity.
Indeed we observe a tendency for the mismatch cost at
stopping times hΣðT Þi to saturate when increasing the limit
time τ, in contrast with the linear scaling of hΣðτÞi with τ.
In Appendix H we confirm this point by studying in more
detail the scaling behavior of these two quantities as a
function of τ.
We test the sandwich inequality in Eq. (46) comprising
the upper and lower bounds to hΣðT Þi in Eqs. (43)
and (44), respectively. As can be appreciated in Fig. 5,
both inequalities provide useful bounds that become tighter
for small τ, and are simultaneously saturated at the point
p0 ¼ 1=2. This example also reveals that again there is a
reduction of intrinsic costs at stopping times with respect
to fixed times; that is, hΣðτÞi ≥hΣðT Þi holds over the
entire parameter range of probability of symbol 0, p0,
and the limit time τ, as shown in the inset of Fig. 5.
This reduction is guaranteed by a positive value of the
stochastic distinguishability hδðT Þi > 0 in the range p0 ≥
1=2 [cf. Eq. (43)], but, interestingly, it is also verified even
for hδðT Þi < 0 as it happens for p0 ≤1=2.
C. Beyond i.i.d. sources
Thus far we have analyzed the statistics of a DFA
processing inputs generated by a source of i.i.d. bits, which
induces a Markovian dynamics for the time evolution of the
computational states. This is, however, one of the simplest
possible computational processes, as, e.g., regular languages
recognizedby DFAsareoftencomposed ofcorrelated words.
To illustrate the applicability of our theory to computing
thermodynamic costs of DFAs processing arbitrary strings
from arbitrary languages, it is mandatory to consider DFAs
processing non-i.i.d. sequences.
In processing a generic non-i.i.d. sequence, the dyna-
mics over the computational states of a DFA is in general a
0.2
0.4
0.6
0.8
Probability of symbol 0 ( p0 )
0
1
2
3
4
5
6
0.2
0.4
0.6
0.8
p0
0
2
4
FIG. 5.
Numerical results for the average intrinsic mismatch
cost hΣðT Þi (symbols) at stopping times T ¼ minðT 1; τÞ with
uniform prior, evaluated for the DFA in Fig. 2(a) processing
i.i.d. binary input data, as a function of the probability of input
symbol 0. We used different limit times: τ ¼ 5 (blue filled squares),
and τ ¼ 14 (red filled circles). The solid lines correspond to the
lower bound predicted by Eq. (44) and given by Dðρ0k¯ρτÞ −
hδτðT Þi for τ ¼ 5 (blue solid line), and τ ¼ 14 (red solid line),
while the dashed lines are the corresponding upper bounds in
Eq. (43), hΣðτÞi −hδτðT Þi for same values of τ. Averages are
estimated from 104 numerical simulation for each parameter value.
The thick gray line is the average cost at stopping times for
stationary prior π, see Eq. (63) and Fig. 4, and the vertical dashed
line is set to p0 ¼ 1=2 as a reference value. Inset: hΣðτÞi −hΣðT Þi
(solid line) and hδτðT Þi (dashedline) as a function of p0 for τ ¼ 14.
The horizontal dotted line is set to zero as a reference value.
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-18

non-Markovian process. However, one can extend the
computational state space such that our formalism can
be applied. For the analysis in this section it is important to
mention the distinction between the “computational states”
of the DTMC computational state space X and the states of
the DFA. In particular, we refer to states of the DFA (as in
the usual TCS definition) as logical states of the DFA, and
remind that with computational states we refer to the sets of
variables which describe the entire state space for a
computational process of interest, as introduced in Sec. II.
Now consider that the (process generating the) input
string itself is a DTMC characterized by time-independent
transition probabilities pðbiþ1jbiÞ for the ði þ 1Þth bit to be
equal to biþ1 ¼ f0; 1g given that the ith symbol (bit) of the
string is bi ¼ f0; 1g. In this case, the logical state of, e.g., a
three-state DFA zt ¼ fq0; q1; q2g processing this input
string is not a DTMC, although by constructing the
computational state space as the Cartesian product of zt ¼
fq0; q1; q2g and bt ¼ f0; 1g, we encode the current com-
putational state xt ¼ fzt; btg as the logical state of the DFA
zt and the most recent input symbol fed to the DFA bt. In
this case, one is left with a DTMC with six possible
computational states, for which our formalism can be
readily applied to tackle the thermodynamic properties.
As an example, we consider the minimal DFA that
accepts binary multiples of 3, shown in Fig. 6(a), leading to
the DTMC represented in Fig. 6(b). The probabilities to
obtain input bits 0 or 1 given the last input symbol are fixed
and denoted by pðijjÞ ≔pij for i; j ¼ f0; 1g. They satisfy
p00 þ p10 ¼ 1 and p01 þ p11 ¼ 1. Ordering the computa-
tional
states’
distribution
as
ρt ¼ ½ρtðq0; 0Þ; ρtðq1; 0Þ;
ρtðq2; 0Þ; ρtðq0; 1Þ; ρtðq1; 1Þ; ρtðq2; 1Þ, we obtain a 6 × 6
transition matrix given by
W ¼
2
666666664
p00
0
0
p01
0
0
0
0
p00
0
0
p01
0
p00
0
0
p01
0
0
p10
0
0
p11
0
p10
0
0
p11
0
0
0
0
p10
0
0
p11
3
777777775
:
ð73Þ
We choose as the initial condition the probability distri-
bution:
ρ0 ¼ ½ 1=2
0
0
1=2
0
0 †;
ð74Þ
with initial equal probabilities over the DTMC states
corresponding to q0 as the DFA start state and zero
otherwise. We assume that the underlying entropy produc-
tion is minimized for the uniform prior,
r ¼ ½ 1=6
1=6
1=6
1=6
1=6
1=6 †;
ð75Þ
which is transformed, after one iteration, into r0 ¼ Wr:
r0 ¼ ½ a=6
a=6
a=6
b=6
b=6
b=6 †;
ð76Þ
with a ≔p00 þ p01 and b ≔p10 þ p11.
Using the above definitions we can compute ΣðτÞ in
Eq. (18), at arbitrary fixed times. Moreover, in order to
evaluate thermodynamic quantities at stopping times, we
embrace
again
the
family
of
stopping
times
T ¼
minðT 1; τÞ with τ the fixed time horizon and T 1 ≥1 the
first time the DFA returns to the accept state q0 for
either b ¼ f0; 1g.
We show numerical results in Fig. 7, where hΣðT Þi,
together with the corresponding upper and lower bounds
given by Eq. (46), are plotted as a function of the
probability p01 ¼ 1 −p11 to obtain symbol 0 after a
symbol 1, for different values of p00 ¼ 1 −p10. Again
we obtain relevant bounds on the intrinsic mismatch cost at
stopping times, which, interestingly, become tightest when
p00 ¼ 1 −p01, i.e., when p00 ¼ p11 and p10 ¼ p01. This
corresponds to the situation in which the input sequence is a
Markovian process with homogeneous stationary proba-
bilities, pst
0 ¼ pst
1 ¼ 1=2. The fact that our bounds become
tight for homogeneous input sequences was also observed
for the i.i.d. example (see Fig. 5) and makes us conjecture
that this phenomenon may be generic to correlated input
sequence, maybe also non-Markovian.
As also commented for the previous examples, however,
using a stopping time of the form T ¼ minðT 1; τÞ allows
us to describe computation times for the DFA to reach the
(a)
(b)
FIG. 6.
(a) Minimal DFA that accepts binary multiples of three
with three states zt ¼ fq0; q1; q2g with same start and accept
state q0. (b) Associated DTMC, where the automaton processes
input strings generated by a non-i.i.d. source of input symbols
with probabilities depending only on the last processed symbol
bt ¼ f0; 1g. See Eq. (73) for the corresponding transition
probability matrix.
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-19

accept state for the first time. That corresponds to the
acceptance of only some of the multiples of three, e.g., “0”
(zero), “11” (three), “1001” (nine), but not other multiples
like “110” (six) or any other word that already contains an
acceptable prefix. In order to explore thermodynamic costs
associated to these words, we now consider more general
stopping times T ¼ minðT n; τÞ, where T n is the nth time
the DFA returns to the accept state. Therefore, T 2 is related
with the acceptance of words like “110” (six) or “10010”
(eighteen), while T 3 corresponds to accept words like
“1100” (twelve), among many others.
In Fig. 8 we plot hΣðT Þi with T ¼ min ðT n; τÞ as a
function of the return time to the accept state, n ¼ 1, 2, 3, 4,
5. We notice that different behaviors are obtained depend-
ing on the choice of input symbols probabilities, p00 and
p01, leading to either increasing values of the intrinsic
mismatch cost or a nonmonotonic behavior. Interestingly,
considering different stopping times allows us to test
inequality (42) for two stopping times, which is shown
in the inset of Fig. 8 for T 1 ¼ minðT n−1; τÞ and T 2 ¼
minðT n; τÞ as a function of n > 1. In particular, we observe
that the mismatch cost between consecutive returning times
to the accept state can be eventually negative for specific
choices of parameters (probabilities p00 and p01), that is,
hΔΣðT n; T n−1Þi < 0 for n ¼ 3, 4, 5, owing to a reduction
in the associated stochastic distinguishability and despite
having hΣðτÞi ≥0 at fixed times.
VI. UNIVERSAL EQUALITIES
AND INEQUALITIES
FOR ACCEPTANCE PROBABILITIES
Our formalism can be further applied to address other
issues in computer science theory, beyond automata liter-
ature, and besides second laws and fluctuation theorems
at stopping times. Both in this section and in Sec. VII we
develop further theoretical predictions for key statistical
properties of interest for computer science that may inspire
numerical and experimental illustrations of future work.
An example that we develop in this section is using
our formalism to establish universal equalities and inequal-
ities concerning the probabilities of acceptance or rejection
of sets of distinct bit sequences when a given DFA is
implemented. In what follows we focus on a specific choice
of such sets, namely, (1) the set of all strings or trajectories
that end in an accept state before the limit time τ versus
(2) the set of all trajectories that do not end in an accept
state before the limit time τ. However, we emphasize that
this formalism can be generalized to arbitrary pairs of sets
of trajectories, by specifying suitable filtrations as done in
martingale approaches.
0.2
0.4
0.6
0.8
p01
0
0.4
0.8
1.2
p00 = 0.25
p00 = 0.75
FIG. 7.
Numerical results for the intrinsic mismatch cost
hΣðT Þi with uniform prior for the DFA in Fig. 6(a) processing
Markovian input strings, as a function of the input symbol
transition probability. Here T ¼ minðT 1; τÞ, with T 1 the first
return time to any of the states ðq0; 0Þ or ðq0; 1Þ, and τ ¼ 5 a
prescribed limit time. Symbols are numerical estimates for
hΣðT Þi obtained from 104 numerical simulations, for two
different values of the transition probability p00 of the input
string containing two consecutive zeros (see legend). Solid
lines are estimates from the numerical simulations of the
quantity Dðρ0k¯ρτÞ −hδτðT Þi, confirming the lower bound given
by Eq. (44).
1
2
3
4
5
0
0.5
1
1.5
2
3
4
5
-0.2
0
0.2
0.4
0.6
FIG. 8.
Intrinsic mismatch cost up to the second, third, fourth,
and fifth accepted word. Numerical results for hΣðminðT n; τÞÞi
with uniform prior, with T n the nth return time to the accept
states, and τ ¼ 40 a prescribed limit time. Results are obtained
for the DFA in Fig. 6(a) processing Markovian input strings,
as a function of the n input symbol transition probability, for
parameter values p00 ¼ 0.25, p01 ¼ 0.4 (open symbols) and
p00 ¼ 0.25, p01 ¼ 0.75 (filled symbols). The lines are estimates
from the numerical simulations of the quantity Dðρ0k¯ρτÞ −
hδτðT Þi for p00 ¼ 0.25, p01 ¼ 0.4 (red dashed line) and for
p00 ¼ 0.25, p01 ¼ 0.75 (red solid line). Inset: mismatch cost
between returning times hΔΣðT n; T n−1Þi ≔hΣðminðT n; τÞÞi −
hΣðminðT n−1; τÞÞi
(red
circles)
and
−½hδτðminðT n; τÞÞi −
hδτðminðT n−1; τÞÞi (red solid line) as a function of n; see
Eq. (42). The horizontal dotted line is set to zero as a reference
value.
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-20

Thus we will explore a class of simple examples of
“acceptance” statistics for binary words of length τ ≥2 that
are processed by a computer. We will use the notation
accept to signify that a computer reaches a prescribed
accept state before the limit time τ, and reject otherwise.
The probabilities PaðτÞ denote the probability for the
computer to have reached the accept state within ½0; τ,
and PrðτÞ ¼ 1 −PaðτÞ the probability for the complemen-
tary. Recall that for simple computer architectures (e.g.,
DFAs processing i.i.d. binary strings), PaðτÞ and PrðτÞ can
often be evaluated analytically or with Monte Carlo sim-
ulations. The approach we reveal below is complementary
to Monte Carlo approaches in such simple computations;
however, we highlight its usefulness in revealing how such
accept or reject statistics are related to thermodynamic
quantities. Note that here those thermodynamic quantities
can be used as a tool of calculation, determined completely
by the computer update function and the distribution over
input words. In particular, they need not correspond to any
“real” thermodynamic quantities that one would measure in
the laboratory. That is, our formalism provides a way to
derive the relative probabilities of accepting or rejecting
a string while sidestepping the conventional technical
difficulties found in the traditional approaches to this
issue [95,96]. On the other hand, one can also interpret
the results presented below as a way for obtaining infor-
mation about the intrinsic thermodynamic costs of compu-
tations by looking at the acceptance probabilities (of
languages solved by machines), which might be calculated
by other means, such as Monte Carlo approaches.
So we consider again a stopping time T ¼ minðT 1; τÞ,
which signifies the first time that the computer reaches the
accept state T 1 or the limit τ in the case that the accept state
is not visited before τ. So T < τ if a word of length τ −1 is
accepted by the computer. Otherwise, T ¼ τ, if the word is
not accepted before τ. The probabilities that a word of
length τ −1 is accepted or not are then given by
PaðτÞ ¼ PðT < τÞ;
ð77Þ
PrðτÞ ¼ 1 −PðT < τÞ ¼ PðT ¼ τÞ;
ð78Þ
respectively. We now make use of our formalism to derive
bounds for PaðτÞ and PrðτÞ in terms of thermodynamic
quantities.
Using our fluctuation theorem at stopping times with
absolute irreversibility, Eq. (35), hMτðT Þi ¼ 1 −Γτ, we
expand its lhs into terms corresponding to accepted and
rejected words as
PaðτÞhMτðT ÞjT < τi þ PrðτÞhMτðT ÞjT ¼ τi;
ð79Þ
with hAðT ÞjcðT Þi ¼ E½AðT ÞjcðT Þ being the conditional
average of functional A over trajectories x½0;T  given that the
condition cðT Þ is fulfilled over the stopping time T . Upon
using PrðτÞ ¼ 1 −PaðτÞ, the decomposition Eq. (79) gives
us the following relation between the acceptance proba-
bility and the averages of the supermartingale MτðT Þ at
stopping times:
PaðτÞ ¼
1 −Γτ −hMτðT ÞjT ¼ τi
hMτðT ÞjT < τi −hMτðT ÞjT ¼ τi :
ð80Þ
Equality (80) generalizes analytical expressions obtained in
previous works for absorption probabilities [13,19,97] by
including the absolute irreversibility contribution Γτ. As
can be appreciated in Eq. (80), since Γτ ≥0, the role of
absolute irreversibility is to decrease the acceptance prob-
ability PaðτÞ of a word of length τ −1 by the DFA. This can
be intuitively understood from the fact that starting com-
putation from a restricted set of initial states can only
decrease the velocity at which the computational state space
is explored, and hence the probability to reach a generic
stopping condition before time τ.
Since PaðτÞ is a well-defined probability [i.e., 0 ≤
PaðτÞ ≤1], we further obtain from Eq. (80) that one of
the two following chain inequalities holds:
hMτðT ÞjT < τi ≥1 −Γτ ≥hMτðT ÞjT ¼ τi;
ð81Þ
hMτðT ÞjT ¼ τi ≥hMτðT ÞjT < τi ≥1 −Γτ ≥0;
ð82Þ
which provide us constraints on the values of MτðT Þ for
generic T of the form T ¼ minðT 1; τÞ.
Analogously, we can exploit the second-law inequality at
stopping times Eq. (44), namely, hΣðT Þi ≥−hδτðT Þi þ
Dðρ0k¯ρτÞ, to derive universal bounds for the finite-time
acceptance probability. Indeed, the average of the left-hand
side of this equation at the stopping time T ¼ minðT 1; τÞ
can also be decomposed into two terms, accounting,
respectively, for accepted and rejected words of maximum
length τ −1:
hΣðT Þ þ δτðT Þi ¼ PaðτÞCaðτÞ þ PrCrðτÞ;
ð83Þ
where we have introduced the conditional averages,
CaðτÞ ¼ hΣðT Þ þ δτðT ÞjT < τi;
ð84Þ
CrðτÞ ¼ hΣðT ÞjT ¼ τi:
ð85Þ
Note that in Eq. (85) we have used the fact that δτðτÞ ¼ 0.
We refer to these two conditional averages as the average
thermodynamic costs associated with the acceptance and
rejection of words of length τ −1, respectively.
Combining Eqs. (44) and (83) we obtain the two
following lower and upper bounds for the acceptance
probability,
PaðτÞ ≥Dðρ0k¯ρτÞ −CrðτÞ
CaðτÞ −CrðτÞ
;
ð86Þ
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-21

valid whenever CaðτÞ > CrðτÞ, and similarly
PaðτÞ ≤CrðτÞ −Dðρ0k¯ρτÞ
CrðτÞ −CaðτÞ
;
ð87Þ
valid in the complementary case when CrðτÞ > CaðτÞ.
These bounds express a constraint on the acceptance
probability of a word with maximum length τ −1 in terms
of the average costs associated with the accepted and
rejected words as defined in Eqs. (84) and (85), and the KL
divergence between the initial distribution of the computa-
tional state and the final distribution of the computational
state under the auxiliary dynamics [see Eq. (45)].
Equation (86) provides a meaningful bound whenever its
rhs is non-negative and smaller than one, i.e., when
CaðτÞ ≥Dðρ0k¯ρτÞ ≥CrðτÞ. On the other hand, the bound
Eq. (87) is meaningful when CaðτÞ ≤Dðρ0k¯ρτÞ ≤CrðτÞ.
We expect the first condition to be satisfied if the
probability of accepted words is large enough so that the
associated cost CaðτÞ is larger than the cost of rejected
words CrðτÞ. So we expect the bound Eq. (86) to be helpful
for parameter values of the DFA and distribution over input
words in which the acceptance rate is high. On the contrary,
when the probability of rejected words is large enough, we
expect CrðτÞ to be larger than CaðτÞ, and the bound Eq. (87)
to be useful when the acceptance rate is low.
The above relations in Eqs. (80), (86), and (87) con-
cerning the acceptance probability of a word can also be
applied to any finite-horizon stopping time of the form
T ¼ minðT c; τÞ, where T c represents the time at which a
given arbitrary condition c is verified for the first time, e.g.,
the first time the accept state is reached twice, or the first
time the accept state is reached after passing through any
other arbitrary state (or sequence of them). Thus there is an
ample flexibility in choosing the stopping condition T ,
including the logical composition of any other set of
conditions; e.g., c ¼ c1 ∪c2 giving the first time either
condition c1 or condition c2 is verified, or c ¼ c1 ∩c2 for
the fist time both c1 and c2 are simultaneously verified.
VII. CONCATENATING RUNS OF A DFA
WITH STOCHASTIC RESETTING
In this section we further elaborate on how our results
would be applied to sequences of computations separated
by a reset of the dynamics which implements concatenated
computational rounds. This is an interesting avenue where
our results might be fruitfully combined in the future with
the powerful analytical tools from the framework of
stochastic resetting [35,98–102]. Let us consider a random
sequence of symbols fed into a computer,
0 0 0 ⊔0 1 0 1 1 1 ⊔0 1 0 …;
ð88Þ
where ⊔is a blank symbol that flags the beginning of a
new computation. For the example sequence Eq. (88), a
computation starts at the random starting time T start ¼ 5
and ends at the stochastic ending time T end ¼ 10 just
before the next blank symbol arrives, thus generating the
input word “010111.” During this computation, the com-
puter begins computing at T start ¼ 4 from its start state, and
ends the computation either in an accept state or in another
logical state.
Now, stochastic starting times can be reformulated as
stochastic stopping times [see also our results concer-
ning multiple stopping times, Eq. (41)]. In particular, here
the starting time T start is the first appearance of a blank
symbol ⊔. Whenever the probability of a blank symbol
p⊔> 0 is greater than zero, then it is guaranteed that
PðT end < ∞Þ ¼ 1; i.e., there is a limit time τ that is a
finite global upper limit to T end. This is the setting which
would correspond to, e.g., stochastic starting times that
are drawn from distributions with bounded support, say
from Bernoulli or binomial distributions. Under such mild
assumptions, it is then possible to establish thermodynamic
constraints for computations starting at stochastic times.
Supposing p⊔> 0, we outline how the stopping-time
fluctuation relations derived in our work can be applied to a
computation of the example sequence Eq. (88). First, we let
the computer processes the sequence “000,” which implies
visiting the accept state at least once. At time t ¼ 3, the
computer may or may not be in the start state depending on
its update rules. Next, at t ¼ 4, the state of the computer is
reset to its start state from whichever state x3 it occupies at
the previous time instance. Upon this, the computer
processes the string 010111 before the arrival of the next
blank symbol, during which the logical state may or may
not have reached the accept state. This leaves us with
an ordered sequence of stopping times: T0 ¼ 0, T 1 ¼
minðT ð1Þ
accept;T ð1Þ
blankÞ, T 2 ¼T ð1Þ
blank, T 3 ¼minðTð2Þ
accept;Tð2Þ
blankÞ,
T 4 ¼ Tð2Þ
blank, …, T ∞¼ τ, which obey
T 0 ≤T 1 ≤T 2 ≤T 3 ≤T 4 ≤   ≤T ∞:
ð89Þ
Here above we have denoted by T ðiÞ
accept the first return time
to the accept state during the computation of the ith word.
Similarly, T ðiÞ
blank is the stochastic arrival time of the ith
blank symbol. While the stochastic times T ðiÞ
accept have the
same structure as the stopping times considered throughout
our work, the times T ðiþ1Þ
blank can be seen as stochastic starting
times, which are also examples of stopping times for which
our formalism applies.
Figure 9 provides an illustration of a DFA processing
an i.i.d. sequence of bits interspersed by blank symbols.
The DFA processing the symbols recognizes binary words
multiples of four, as in the examples of Sec. V. Assuming
time-independent probabilities p0, p1, and p⊔for the
occurrence of 0, 1, and blank ⊔symbols, respectively
(with p0 þ p1 þ p⊔¼ 1), the DTMC associated with
this computation can be represented by a discrete-time
stochastic resetting process (see Fig. 9). In such processes,
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-22

resetting takes place from each logical state to the start state
q0 at a stochastic starting time. This requires a suitable
description of computation whose transition matrices
include resetting events. For the DFA example considered
here, such transition matrix takes the form
W ¼
2
6664
p0 þ p⊔
p⊔
p0 þ p⊔
p⊔
p1
0
p1
0
0
p0
0
p0
0
p10
0
p10
3
7775;
ð90Þ
cf. Eq. (54) for the case where no resetting takes place,
corresponding to p⊔¼ 0. The DTMC described by the
transition matrix Eq. (90) allows one to study multiple
realistic computational scenarios where Σ at stochastic
starting and stopping times can be efficiently tackled.
For example, one may consider that the processing of
the input string by the DFA is a nonequilibrium stationary
process with resetting and apply results from the martingale
theory for stationary processes (see Chap. 7 in Ref. [19]).
Alternatively, one can apply the formalism in this work to
establish bounds for the intrinsic mismatch costs of the
computation between the first and the nth arrival of a blank
symbol, from the nth blank symbol to the ðn þ 1Þth one,
etc. [see Eq. (42)], similarly to Sec. Vc.
VIII. DISCUSSION
In this work we have shown how to extend stochastic
thermodynamics to describe the minimal costs associated
with a computer processing with a stochastic halting
time, processing strings of arbitrary length. Our formalism
applies to computations described by discrete-time Markov
chains over a set of computational states that may have
restricted initial conditions, unidirectional links, and start
and/or stop at a stochastic time. We obtain quantifiers,
which are collectively dubbed as the intrinsic mismatch
cost of a computation, that lower bound the entropy
production incurred by the computer and that can be
formulated at the fluctuating level. A key insight here is
that these quantifiers, which provide a tool to probe the
entropy production associated with computations at stop-
ping times, can be entirely obtained from the DTMC
evolution and the prior, without further details about their
physical implementation. Note that such an intrinsic cost is
independent of the internal energy of the computational
states, xt ∈X, which can indeed be assumed to be equal for
every computational state and constant over time. Still,
nonzero entropy production through the irreversible dis-
sipation of heat into the environment will be in general
incurred for any physical computer which implements a
given computation over such set of states.
Putting forward the modern martingale formalism of
stochastic thermodynamics, we also unveiled a plethora of
universal fluctuation relations and inequalities that are valid
for the broad class of computations analyzed in this work.
We obtained a main fluctuation theorem, Eq. (35), valid
for settings which include arbitrary stopping times, unidi-
rectional transitions, and absolute irreversibility. In doing
that, we have extended the martingale theory for stochastic
thermodynamics to account for this additional source of
irreversibility in generic situations, which we expect to have
broad applicability in nonequilibrium thermodynamics.
The rigor and flexibility of our theory for stopping times
allowed us to formulate and interpret several second-law-
like inequalities [Eqs. (39)–(44)] at stochastic stopping
times, as well as relations for the probabilities of acceptance
or rejection of input data by a computer in terms of
thermodynamic quantities [equality (80) and inequalities
(86) and (87)]. In particular, the second-law inequalities
(39) and (44) provides us useful lower bounds on the
minimum dissipation incurred by a generic computation
stopping at an arbitrary stopping time, while Eq. (43)
establishes formally how stopping times can be used to
reduce the thermodynamic costs of a computation by
means of time-reversal symmetry breaking. Moreover,
we have also shown the relevance of accounting for
absolutely irreversible sequences in providing accurate
bounds for the intrinsic mismatch cost of the computa-
tion. In this sense, the bound we derived in Eq. (39) with
the absolute irreversibility term Γτ is tighter, with res-
pect to the alternative bound in Eq. (44). However,
computing Γτ might be challenging depending on the
setting considered, especially for large limit times τ. On
the contrary, the alternative bound in Eq. (44) would be
much easier to compute (as it depends only on two
0 0 0
0 1 0 1 1 1
0 1 0
. . .
. . .
q0
q1
q2
q3
FIG. 9.
An application of stochastic resetting to computer
science. Top: illustration of a random tape of binary symbols
interspersed by blank symbols that are processed during a
computation. Bottom: discrete-time Markov chain associated
with the deterministic finite automaton recognizing binary words
multiple of four [see Fig. 1(c)] with stochastic resetting to the start
state. Along a stochastic computation, resetting takes place when
a blank symbol is recognized by the DFA. For the model
illustrated here, we have assumed that words are drawn from
i.i.d. sequences with probabilities p0, p1, and p⊔of 0,1 and blank
symbols, respectively, with p0 þ p1 þ p⊔¼ 1; however, more
complex scenarios could be envisaged in future work.
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-23

probability distributions), while still providing a mean-
ingful bound in all examples explored here.
The framework developed in this paper can be readily
applied for assessing thermodynamic costs of computations
in a broad range of models of relevance in computer science
theory, including—but not being limited to—deterministic
finite automata. Our results apply to every computation
implemented by a synchronous digital computer and
remains valid independently of how the computational
variables are defined. In particular, they can include already
processed input symbols (as in non-iid DFAs), stacks (as in
pushdown automata models), or even entire words written
on a random access tape (as in Turing machines). Hence our
results provide a tool to classify abstract computational
machines by their intrinsic (unavoidable) thermodynamic
costs. Applying our framework to more complex models of
computational machines such as pushdown automata or
Turing machines halting at stochastic times is a natural step
following the investigation initiated here.
Our results are amenable of experimental testing using
state-of-the-art techniques in line with previous tests of
Landauer’s principle [25,103,104] and other experimental
platforms in stochastic thermodynamics [105] in setups
ranging from colloidal particles [106] and nanoscale
devices [107,108] to biopolymers [91]. Regarding the
determination of the prior, in some cases the experimen-
talist will have designed the system in a sufficiently detailed
manner such that it is possible to calculate the prior, or at
least approximate it with reliable numerical estimates. In
other cases, the experimentalist can estimate the prior by
repeatedly running the system and observing the resultant
behavior. In any case, our results have nonzero lower
bounds that apply no matter what the prior is.
It would also be very interesting in the future to extend
the framework developed here by combining analytical
tools from stochastic resetting (e.g., renewal theory and
first-passage-time ideas [109]) with computer science
methods. This will allow us to obtain tight bounds for
the statistics of starting time and entropy production
bounds in specific models of DFAs and TMs processing
regular languages, as follows from the ideas sketched in
Sec. VII. Also, we note that even if current digital devices
are very close to periodic, they are not exactly so. In other
words, they are some first-order perturbation away from
being periodic, which suggests other avenues for future
work. In general, the prior is a function of the physical
process implementing the computation. For example, it is a
function of the time-dependent rate matrix in the case of a
CTMC. Given this, we might be able to use the envelope
theorem (often used in game theory) to calculate how much
the prior can change under first-order perturbations away
from an exactly periodic process. That in turn might allow
us to modify Eq. (13) to involve some infinitesimal first-
order perturbation parameter ϵ characterizing how much
the process differs from being exactly periodic.
However, the results developed in this paper also pro-
vide new insights in the field of nonequilibrium thermo-
dynamics. An important consequence of our work is the
finding that the auxiliary dynamics introduced in Eq. (15)
is suitable to treat processes at stopping times that may
have unidirectional transitions and absolute irreversibility,
hence making our framework applicable to generic sit-
uations where local detail balance is broken. Similar
auxiliary dynamics has been invoked in the literature
such as so-called “dual,” “dual-reversed, or “adjoint”
dynamics, in the context of fluctuation theorems; see,
e.g., Refs. [20,41,52,82,110,111]. In particular, as shown
above, if the process admits a well-behaved stationary
solution, we can obtain from Σ the so-called nonadiabatic
(or excess) entropy production [52,72]. Within such sce-
nario, our work is another brick in the wall of recent
progress highlighting the role of nonadiabatic entropy and
excess heat in characterizing the efficiency [112] and
calorimetry [113,114] of active nonequilibrium systems.
We also expect our results to have potential applications
outside statistical mechanics and computer science, e.g., in
biological physics, for instance, within the field of bio-
molecular computation [115], enzyme kinetics [116], and
information processing in biology [117]. As a minimal
model, consider a minimal Michaelis-Menten scheme for
enzyme kinetics in which an enzyme E transforms a
substrate molecule S into a product molecule P. A typical
assumption is that the conversion of the substrate into a
product takes place through an irreversible chemical
reaction, E þ S ⇌
kþ
1
k−
1
ES ⇀
kþ
2 E þ P, where ki’s here are suit-
able transition rates. Within this model, the enzyme’s
state during enzymatic cycles follows a continuous-time
Markov jump process with one irreversible transition. In
previous works, the presence of the irreversible transition
has been circumvented by considering virtual processes
with a very slow transition rate. However, our formalism
can be readily applied to describe the stochastic thermo-
dynamics of such enzymatic reaction, inasmuch as that it
does not require the presence of bidirectional transitions.
Similarly, we expect our formalism to be suitable to
describe fluctuations of biological populations in processes
that include totally irreversible transitions such as cell-fate
decisions [118,119], cell death, and apoptosis [120], among
others. For such systems, our approach puts forward recent
approaches to estimate dissipation developed within in the
field of active matter [121–123] which did not contemplate
the presence of unidirectional transitions which are
commonplace in biophysical modeling [124,125].
ACKNOWLEDGMENTS
We thank Artemy Kolchinsky for useful comments on
the first version of the manuscript. G. M. acknowledges
“Ramón y Cajal” program (No. RYC2021-031121-I), the
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-24

CoQuSy
project
(No.
PID2022-140506NB-C21),
and
support from the María de Maeztu project (No. CEX2021-
001164-M) funded by MCIU/AEI/10.13039/501100011033
and European Union NextGenerationEU/PRTR. E. R.
acknowledges fruitful discussions with L´ea Bresque
and
financial
support
from
PNRR
MUR
project
No.
PE0000023-NQSTI.
D. H. W.
acknowldges
U.S.
NSF Grant No. CHE-1648973. D. H. W. also thanks the
Santa Fe Institute for support.
APPENDIX A: RESIDUAL COST
Suppose we are given a physical process which imple-
ments a single-valued function f over a space X. The
islands of f are defined as the elements of the partition of X
given by the preimages of f. Formally, if we write the
image of f as fðXÞ, the islands of f are the sets
ff−1ðxÞ∶x ∈fðXÞg. We write the set of islands of a
function f as LðfÞ.
In this appendix we will expand the residual cost Rðϱ0Þ
arising in Eq. (11) in terms of islands, discuss some
properties of the residual cost, and then justify why this
cost can be ignored in our investigation in this paper. For
simplicity we will restrict attention to the case where the
linear term F in Eq. (8) is expected entropy flow generated
in a process, so that CðτÞ is the EP generated in the process
up to time τ. However, all of the discussion extends to other
choices of F, with the obvious modifications.
Equation (11) provides entropy production as a sum of
two terms, the mismatch cost and the residual cost, where
RðτÞ corresponds to the residual cost. For any conditional
distribution G, and any island c ∈LðGÞ, we define the prior
within that island as [126]
ϱc
min ∈
arg min
ϱ∶suppðϱÞ ∈Δc
CðτÞ;
ðA1Þ
where the subscript means that ϱ is a distribution whose
support is restricted to the unit simplex over the island c,
Δc, viewed as a subset of the state space Y. The associated
minimum EP in that island is written as
Cc
minðτÞ ≔
min
ϱ∶suppðϱÞ ∈Δc
CðτÞ:
ðA2Þ
Now introduce an arbitrary distribution over islands qðcÞ
and define
ϱmin ≔
X
c ∈LðGÞ
qðcÞϱc
min:
ðA3Þ
Then the residual EP of the physical process that imple-
ments G is
RðτÞ ¼
X
c ∈LðGÞ
pτðcÞCc
minðτÞ;
ðA4Þ
as shown in Ref. [126]. Therefore, the EP for the process
starting with distribution ϱ0 is
CðτÞ ¼ Dðϱ0kϱminÞ −DðGϱ0kGϱminÞ þ
X
c ∈LðGÞ
pτðcÞCc
min:
ðA5Þ
Since expected EP CðτÞ is non-negative, by definition the
residual cost of any island c, Cc
min, is non-negative. So the
total residual cost given by an expectation over all islands,
which is the residual cost for the entire thermodynamic
process characterized by G, is also non-negative. Like
priors, residual costs of islands in general will differ from
one cost function C to the next.
In general, as the iteration t of a periodic process
changes, the distribution ptðcÞ over the islands c will
change. Therefore so will the associated total expected
residual cost. However, since that total residual cost is
always non-negative, all the lower bounds on EP in the
main text that consider only mismatch cost apply. This is
true even if the residual costs of the islands are strictly
positive. In particular, Eq. (14) will still be a lower bound
on the EP generated in the process.
On the other hand, if we write down the formula for
minimal total residual cost which is analogous to Eq. (14),
minimizing over the residual costs of each island, we just
get zero, by taking those costs to all equal zero. So unless
we fix the physical details underlying the process, and
therefore fix the residual costs of the islands to be strictly
positive, our analysis of lower bounds is not changed by the
existence of residual costs. This is why such quantities are
ignored in the main text.
As a final comment, note that in general both the prior
and residual costs will vary with τ. However, the same
mismatch cost formula bounds dissipation for any such
choice of τ, once one plugs in the appropriate prior. This
need not be true for residual cost, in the sense that the
islands might change for different choices of τ.
APPENDIX B: TRAJECTORY-LEVEL
MISMATCH COST
Define ½GtϱðyÞ as the distribution ϱ evolved through the
(linear) dynamics G up to time t, and then evaluated at state
y ∈Y. Using this, we can define a trajectory-level version
of mismatch cost (and associated instance-level version) as
mϱ0ðY½0;τÞ ≔ln
 ϱ0ðy0Þ
ϱminðy0Þ

−ln
 Gϱ0ðy0Þ
Gϱminðy0Þ

¼
X
τ−1
t¼0
ln
 ½Gtϱ0ðytÞ
½GtϱminðytÞ

−ln
 ½Gtþ1ϱ0ðytþ1Þ
½Gtþ1ϱminðytþ1Þ

:
ðB1Þ
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-25

By construction, the expected value of mρ0ðY½0;τÞ over all
trajectories Y½0;τ equals the (ensemble level) mismatch cost
Mðρ0Þ given in Eq. (10). In the context of inclusive
thermodynamics, such definitions allowed the derivation
of fluctuation theorems for mismatch cost [49].
APPENDIX C: ENTROPY PRODUCTION BOUNDS
FROM DISCRETE-TIME EVOLUTION OVER
COMPUTATIONAL STATES
We focus on the case in which the cost function CðτÞ
introduced in Eq. (8) corresponds to the entropy produc-
tion; that is, we identify F as the entropy flow due to heat
exchange of the system with (one or several) heat baths, and
under the eventual presence of nonconservative forces [3].
In the case in which the continuous-time periodic process is
also Markovian, that is, it can be described with a set of rate
matrices Kv
ijðtÞ associated to the different reservoirs, the
entropy flow F will take the form presented in Eq. (9).
Otherwise, the explicit expression of the entropy flow F
might be more involved [127–129].
In any case, the average entropy production in the
continuous-time physical process can be written in terms
of a Kullback-Leibler divergence between path probabil-
ities of trajectories y½0;τ ¼ fytj0 ≤t ≤τg in the extended
state space, yt ∈Y, and their time-reversed counterparts
Θy½0;τ ¼ fyτ−tj0 ≤t ≤τg as [64,130,131]
CðτÞ ¼ hStotðτÞi ¼ D½Pðy½0;τÞk ˜PðΘy½0;τÞ;
ðC1Þ
where P and ˜P stand for the probability measures in the
forward and time-reversed driven processes, respectively.
By introducing the trajectories x½0;τ ¼ x0; x1; …; xτ on
discrete-time, visible space dynamics with corresponding
probability Pðx½0;τÞ as introduced in Eq. (7), we can bound
the above Kullback-Leibler divergence as
hStotðτÞi ¼ D½Pðy½0;τÞk ˜PðΘy½0;τÞ
¼ D½Pðy½0;τjx½0;τÞk ˜PðΘy½0;τjΘx½0;τÞ
þ D½Pðx½0;τÞk ˜PðΘx½0;τÞ
≥D½Pðx½0;τÞk ˜PðΘx½0;τÞ ≕h˘StotðτÞi;
ðC2Þ
where we used chain rule for Kullback-Leibler divergence
to write the second equality and denoted the coarse-grained
path probabilities for forward and time-reversed driving
protocols by Pðx½0;τÞ ¼
R
dy½0;τPðy½0;τÞ Qτ
n¼0 δðyn −xnÞ
and
˜PðΘx½0;τÞ ¼
R
dy½0;τ ˜PðΘy½0;τÞ Qτ
n¼0 δðyn −xnÞ, res-
pectively.
The quantity h˘StotðτÞi defined in the rhs of Eq. (C2) is
a coarse-grained version of the average entropy produc-
tion defined only over the DTMC dynamics and reduced
state space X verifying hStotðτÞi ≥h˘StotðτÞi. We can now
decompose the coarse-grained entropy production h˘StotðτÞi
into the sum of mismatch and residual costs as in Eq. (11) at
the DTMC level. In particular, by assuming that all non-
computational degrees of freedom yt ∉X are reinitialized
to their starting values in every cycle of the periodic
computational process, the prior probability minimizing
˘Stot in a single cycle will be the same for all cycles and can
be easily obtained from marginalization of the fine-grained
prior ϱminðyÞ as μðxÞ ¼ P
y∉X ϱminðyÞ.
As a consequence, the coarse-grained DTMC mismatch
cost over a single cycle of the process reads:
MðρtÞ ≔DðρtkμÞ −Dðρtþ1kμ0Þ ≥0;
ðC3Þ
with μ0 the prior distribution evolved during a single
iteration of the DTMC, μ0 ¼ Wμ. Analogously RðρtÞ ≔
h˘StotðρtÞi −MðρtÞ ¼ minρth˘StotðρtÞi ≥0
represents
the
residual costs during a single iteration, which corresponds
to the entropy production when the computational system
starts the evolution in distribution μ. Hence for every single
iteration h˘StotðρtÞi ¼ MðρtÞ þ RðρtÞ, from which it fol-
lows that the above mismatch cost provides a lower bound
to the average entropy production during a single cycle.
Finally, by summing the mismatch costs per iteration
Eq. (C3) over all iterations up to the final time τ, we
recover Eq. (12) for the sum of mismatch costs during the
entire computation (that we dub intrinsic mismatch cost),
which verifies the chain inequality:
X
τ−1
t¼0
MðρtÞ ≤h˘StotðτÞi ≤hStotðτÞi;
ðC4Þ
hence providing a lower bound on the average entropy
production during the entire computation.
APPENDIX D: STRICT POSITIVITY OF THE
MISMATCH COST SUM GIVEN BY Eq. (12)
Here we provide a proof of the strict positivity of the
mismatch cost sum in Eq. (12); that is, Pτ−1
t¼0 MðρtÞ > 0.
We know that, in general, Dðρ0kμÞ −DðGρ0kGμÞ ¼ 0 if
and only if ρ0 ¼ μ. However, if in fact G is not logically
invertible, and yet ρ0 ¼ μ, then Gρ0 ≠μ. This means
that either Dðρ0kμÞ −DðGρ0kGμÞ ¼ 0 or DðGρ0kμÞ −
DðG2ρ0kGμÞ ¼ 0—but not both. Therefore, so long as
G is not logically invertible, the sum in Eq. (12) is not zero.
APPENDIX E: PROOF OF THE
SUPERMARTINGALE PROPERTY Eq. (33)
Here we provide a detailed proof of the supermartingale
property of the process MτðtÞ defined by Eq. (30):
hMτðτÞjX½0;ti ≡
X
Xðt;τ ∈F AC
PðX½0;τjX½0;tÞMτðτÞ
ðE1Þ
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-26

¼
X
X½tþ1;τ ∈F AC
¯PðΘX½0;τÞ
PðX½0;tÞ
ðE2Þ
¼ e−ΣðtÞ
X
X½tþ1;τ ∈F AC
¯PðΘX½0;τÞ
¯PðΘX½0;tÞ
¼ e−ΣðtÞ−δτðtÞ
X
X½tþ1;τ ∈F AC
¯PðΘX½t;τÞ
¯ρτ−tðxtÞ
¼ MτðtÞ

1 −
X
X½tþ1;τ ∈F AI
¯PðΘX½t;τÞ
¯ρτ−tðxtÞ

¼ MτðtÞ½1 −ατðtÞ ≤MτðtÞ:
ðE3Þ
To obtain Eq. (E3) we first used the definition of
conditional probability in Eq. (E1) to derive Eq. (E2).
We then multiplied and divided by ¯PðΘX½0;tÞ, in order to
obtain the e−ΣðtÞ multiplicative factor. After that we
expanded the remaining probabilities ¯PðΘX½0;τÞ in the
numerator and ¯PðΘX½0;tÞ in the denominator, and multi-
plied the resulting expression with ρtðxtÞ=¯ρτ−tðxtÞ to
obtain the expression involving MτðtÞ [recall the defi-
nition of MτðtÞ in Eq. (29)]. Finally, we transformed
the sum to involve F AI, the complementary filtration
of F AC, and invoked the fact that P
X½t;τ ∈F ρτðxτÞ×
¯Pðxτ−1jxτÞ… ¯Pðxtjxtþ1Þ¼ ¯ρτ−tðxtÞ when the sum is taken
over the complete set of trajectories F.
APPENDIX F: STOPPING-TIMES FLUCTUATION
THEOREM WITH ABSOLUTE
IRREVERSIBILITY IN Eq. (35)
In this appendix we give a detailed proof of the main
stopping-times fluctuation theorem with absolute irrevers-
ibility presented in Eq. (35). For the proof, it is convenient
to split the filtration F into subsets of filtrations F ðtÞ
containing all trajectories that are stopped at time t, i.e.,
for which MτðtÞ ¼ MτðT Þ. We take t ¼ 0; 1; …; τ, where τ
is the maximum allowed time. Note that we enforce the
dynamics to stop at τ if not previously done [however, one
can later take τ →∞whenever MτðτÞ remains bounded].
Therefore, we have F ¼ F ð1Þ ∪   ∪F ðτÞ. Now, in anal-
ogy to the previous appendix, we define for each (discrete)
instant of time t the sets F ðtÞ
AC and F ðtÞ
AI of trajectories
that are both stopped at t and which are either allowed
½PðX½0;tÞ > 0 or PðX½0;tÞ ¼ PðΘX½0;tÞ ¼ 0 or forbid-
den only in the original dynamics ½PðX½0;tÞ ¼ 0 with
¯PðΘX½0;tÞ > 0, respectively. This implies that F ðtÞ ¼
F ðtÞ
AC ∪F ðtÞ
AI at any t ¼ 0; 1; …; τ. Then we have
hMτðT Þi ≡
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
PðX½0;tÞMτðtÞ
¼
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
PðX½0;tÞ
× ½hMτðτÞjX½0;ti þ MτðtÞατðtÞ
¼ hMτðτÞi þ
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
PðX½0;tÞMτðtÞατðtÞ
¼ 1 −γτ þ
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
PðX½0;tÞMτðtÞατðtÞ
ðF1Þ
¼ 1 −
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AI
¯PðΘX½0;tÞ ¼ 1 −Γτ;
ðF2Þ
where we used the fluctuation theorem at fixed times with
absolute irreversibility, cf. Eq. (24), and in the last line we
defined the correction term for stopping times:
Γτ ≡
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AI
¯PðΘX½0;tÞ ¯ρτ−tðXtÞ
ρtðXtÞ ≥0;
ðF3Þ
summing up the probabilities for all the (reversed) stopped
AI trajectories.
To reach Eq. (F2) from Eq. (F1) we used
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
PðX½0;tÞMτðtÞατðtÞ
¼
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
¯PðΘX½0;tÞ
ρtðXtÞ
X
Xðt;τ ∈F AI
¯PðΘX½t;τÞ
¼
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
¯PðΘX½0;tÞ
ρtðXtÞ

¯ρτ−tðXtÞ −
X
Xðt;τ ∈F AC
¯PðΘXðt;τÞ

¼
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
¯PðΘX½0;tÞ ¯ρτ−tðXtÞ
ρtðXtÞ −
X
X½0;τ ∈F AC
¯PðΘX½0;τÞ
¼
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AC
¯PðΘX½0;tÞ ¯ρτ−tðXtÞ
ρtðXtÞ −1 þ γτ
¼ −
X
τ
t¼0
X
X½0;t ∈F ðtÞ
AI
¯PðΘX½0;tÞ ¯ρτ−tðXtÞ
ρtðXtÞ þ γτ
¼ −Γτ þ γτ;
ðF4Þ
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-27

where in the last line we used that F ðtÞ
AC ∪F ðtÞ
AI ¼ F ðtÞ and
Pτ
t¼0
P
X½0;t ∈F ðtÞ ¯PðΘX½0;tÞ¯ρτ−tðXtÞ=ρtðXtÞ ¼ 1, since the
trajectories are stopped with certainty in the interval
½0; τ and ¯PðΘX½0;tÞ¯ρτ−tðXtÞ=ρtðXtÞ is a normalized path
probability.
APPENDIX G: ORDERED STOPPING-TIMES
FLUCTUATION RELATION IN Eq. (37)
In this appendix we derive the stopping-times fluctuation
relation for two ordered stopping times in Eq. (37) via
Doob’s optional sampling theorem. Let us start by consid-
ering a finite but otherwise generic stopping time T of the
form in Eq. (28), such that 0 ≤T ≤τ. Doob’s optional
sampling theorem for supermartingales reads [88] (see also
Ref. [19]):
hAðT Þjx½0;ti ≤AðminfT ; tgÞ;
ðG1Þ
where A is a supermartingale over the trajectories x½0;τ.
In the following we will apply Eq. (G1) to the
supermantingale process MτðtÞ ¼ e−ΣðtÞ−δτðtÞ introduced
in Eq. (30), for two ordered stopping times T 1 and T 2
such that PðT 2 ≥T 1Þ ¼ 1. In this case we have
hMτðT 2Þjx½0;T 1i ≤MτðT 1Þ;
ðG2Þ
where we called T 2 ¼ T and T 1 ¼ minfT ; tg. Note that
above x½0;t can be replaced by x½0;T 1 since T 1 ≤t by
construction and Eq. (G1) is valid for any generic t ≤τ.
The average over stopping times of MτðT 1Þ then verifies:
hMτðT 1Þi ¼
X
τ
T 1¼0
X
x½0;T 1
Pðx½0;T 1; T 1ÞMτðT 1Þ
¼
X
T 2
T 1¼0
X
x½0;T 1
Pðx½0;T 1; T 1ÞMτðT 1Þ
þ
X
τ
T 1¼T 2
X
x½0;T 1
Pðx½0;T 1; T 1ÞMτðT 1Þ
≥
X
T 2
T 1¼0
X
x½0;T 1
Pðx½0;T 1; T 1ÞhMτðT 2Þjx½0;T 1i
¼ hMτðT 2Þi;
ðG3Þ
where we used that T 2 ≥T 1 and Eq. (G2) to reach the
inequality. The last line follows from the fact that we are
summing the conditional average over all possible trajec-
tories for stopping times T 1 between 0 and T 2. Finally, by
replacing in Eq. (G3) the explicit expression for MτðtÞ in
Eq. (30), we directly recover Eq. (37). The inequality in
Eq. (G3) is saturated either for T 2 ¼ T 1 or when the
supermartingale MτðtÞ becomes a martingale, that is, in the
absence of absolute irreversibility.
APPENDIX H: SCALING OF THERMODYNAMIC
AVERAGES WITH LIMIT TIME
IN THE DFA EXAMPLE
As pointed in Sec. V B for the minimal DFA in Fig. 2(a),
we observe a tendency for the intrinsic mismatch cost at
stopping times hΣðT Þi to saturate when increasing the limit
time τ. This is in stark contrast with the scaling behavior of
the fixed-time average hΣðτÞi with τ.
In this appendix we provide extra numerical evidence
for the scaling behavior of mismatch cost at stopping and
fixed times, which is shown in Fig. 10. There we observe
that indeed the average intrinsic mismatch cost at fixed
times scales linearly with τ, that is, hΣðτÞi ∼τ, as illustrated
in the inset of Fig. 10. Moreover, we obtain that hΣðτÞi=τ
decreases monotonically with τ up to a saturating positive
value, yet its scaling behavior is rather insensitive to
the statistics of the input strings (see open symbols in
Fig. 10). This point makes us question whether the
fixed-time average hΣðτÞi, or its rate per iteration hΣðτÞi=τ,
is a suitable indicator of the thermodynamic costs of
the computation. On the other hand, when considering
the stopping-times average hΣðT Þi, we observe a sub-
linear scaling at moderate values of the limit time, i.e.,
hΣðT Þi ∼τα, with jαj < 1, reaching a plateau at large τ (see
filled symbols in Fig. 10).
5
10
15
20
Limit time,  
0
0.5
1
1.5
2
2.5
Mismatch cost per computation
5
15
1
2
3
4
FIG. 10.
Numerical results for the intrinsic mismatch cost with
uniform prior as a function of the limit time τ. We show three
different values of the probability of symbol 0: p0 ¼ 0.75 (blue
squares), p0 ¼ 0.5 (red circles), and p0 ¼ 0.3 (green diamonds).
Filled symbols correspond to the stopping-time average hΣðT Þi.
We include for comparison the corresponding fixed-time ensem-
ble average rate hΣðτÞi=τ without absorbing conditions (open
symbols). The open symbols in the inset show the value of
hΣðτÞi. Parameters of the simulations are as in Fig. 5.
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-28

We also find that hΣðT Þi is more sensitive than hΣðτÞi=τ
to the value of p0 for all values of τ explored in our
simulations. This reveals that the intrinsic mismatch cost
at stopping times hΣðT Þi is a suitable quantity to quantify
the average performance of a computation accomplished
at a stochastic time. For example, the sensitivity of
hΣðT Þi to string statistics could be fruitfully exploited as
a probe of the performance of a DFA in processing different
regular languages, an exciting avenue that we leave for
future work.
[1] Ken Sekimoto, Stochastic Energetics, Vol. 799 (Springer,
New York, 2010).
[2] Christopher Jarzynski, Equalities and inequalities: Irre-
versibility and the second law of thermodynamics at the
nanoscale, Annu. Rev. Condens. Matter Phys. 2, 329
(2011).
[3] Udo Seifert, Stochastic thermodynamics, fluctuation the-
orems and molecular machines, Rep. Prog. Phys. 75,
126001 (2012).
[4] Naoto Shiraishi, Ken Funo, and Keiji Saito, Speed limit
for classical stochastic processes, Phys. Rev. Lett. 121,
070601 (2018).
[5] Van Tuan Vo, Tan Van Vu, and Yoshihiko Hasegawa,
Unified approach to classical speed limit and thermody-
namic uncertainty relation, Phys. Rev. E 102, 062132
(2020).
[6] Tan Van Vu and Keiji Saito, Thermodynamic unification of
optimal transport: Thermodynamic uncertainty relation,
minimum dissipation, and thermodynamic speed limits,
Phys. Rev. X 13, 011013 (2023).
[7] Andre C. Barato and Udo Seifert, Thermodynamic un-
certainty relation for biomolecular processes, Phys. Rev.
Lett. 114, 158101 (2015).
[8] Todd
R.
Gingrich,
Jordan
M.
Horowitz,
Nikolay
Perunov, and Jeremy L. England, Dissipation bounds all
steady-state fluctuations, Phys. Rev. Lett. 116, 120601
(2016).
[9] Jordan M. Horowitz and Todd R. Gingrich, Thermody-
namic uncertainty relations constrain non-equilibrium
fluctuations, Nat. Phys. 16, 15 (2020).
[10] Yasuhiro Utsumi, Yasuchika Ito, Dimitry Golubev, and
Ferdinand Peper, Computation time and thermodynamic
uncertainty relation of Brownian circuits, arXiv:2205
.10735.
[11] Raphaël Chetrite and Hugo Touchette, Nonequilibrium
Markov
processes
conditioned
on
large
deviations,
in Annales Henri Poincar´e, Vol. 16 (Springer, 2015),
pp. 2005–2057, 10.1007/s00023-014-0375-8.
[12] Johannes Hoppenau, Daniel Nickelsen, and Andreas
Engel, Level 2 and level 2.5 large deviation functionals
for systems with and without detailed balance, New J.
Phys. 18, 083010 (2016).
[13] Izaak Neri, Édgar Roldán, and Frank Jülicher, Statistics
of infima and stopping times of entropy production and
applications to active molecular processes, Phys. Rev. X 7,
011019 (2017).
[14] Raphaël Ch´etrite, Shamik Gupta, Izaak Neri, and Édgar
Roldán,
Martingale
theory
for
housekeeping
heat,
Europhys. Lett. 124, 60006 (2019).
[15] Gonzalo Manzano, Rosario Fazio, and Édgar Roldán,
Quantum martingale theory and entropy production,
Phys. Rev. Lett. 122, 220602 (2019).
[16] Gonzalo Manzano, Diego Subero, Olivier Maillet, Rosario
Fazio, Jukka P. Pekola, and Édgar Roldán, Thermodynam-
ics of gambling demons, Phys. Rev. Lett. 126, 080603
(2021).
[17] Gonzalo Manzano and Édgar Roldán, Survival and ex-
treme statistics of work, heat, and entropy production in
steady-state heat engines, Phys. Rev. E 105, 024112
(2022).
[18] Izaak Neri and Matteo Polettini, Extreme value statistics of
edge currents in Markov jump processes and their use for
entropy production estimation, SciPost Phys. 14, 131
(2023).
[19] Édgar Roldán, Izaak Neri, Raphael Chetrite, Shamik
Gupta,
Simone
Pigolotti,
Frank
Jülicher,
and
Ken
Sekimoto, Martingales for physicists, arXiv:2210.09983.
[20] Marco Baiesi and Gianmaria Falasco, Inflow rate, a
time-symmetric observable obeying fluctuation relations,
Phys. Rev. E 92, 042162 (2015).
[21] Ivan Di Terlizzi and Marco Baiesi, Kinetic uncertainty
relation, J. Phys. A 52, 02LT03 (2018).
[22] Christian Maes, Frenesy: Time-symmetric dynamical
activity in nonequilibria, Phys. Rep. 850, 1 (2020).
[23] Harvey Leff and Andrew F. Rex, Maxwell’s Demon 2
Entropy, Classical and Quantum Information, Computing
(CRC Press, Boca Raton, FL, 2002).
[24] Ryoichi Kawai, Juan M. R. Parrondo, and Christian Van
den Broeck, Dissipation: The phase-space perspective,
Phys. Rev. Lett. 98, 080602 (2007).
[25] Karel Proesmans, Jannik Ehrich, and John Bechhoefer,
Finite-time Landauer principle, Phys. Rev. Lett. 125,
100602 (2020).
[26] Salambô Dago, Jorge Pereda, Nicolas Barros, Sergio
Ciliberto, and Ludovic Bellon, Information and thermo-
dynamics: Fast and precise approach to Landauer’s
bound in an underdamped micromechanical oscillator,
Phys. Rev. Lett. 126, 170601 (2021).
[27] David H. Wolpert and Artemy Kolchinsky, Thermodynam-
ics of computing with circuits, New J. Phys. 22, 063047
(2020); see also updated version arXiv:1806.04103.
[28] Thomas E. Ouldridge and David H. Wolpert, Thermody-
namics of deterministic finite automata operating locally
and periodically, New J. Phys. 25, 123013 (2023).
[29] Gülce Kardeş and David Wolpert, Inclusive thermodynam-
ics of computational machines, arXiv:2206.01165.
[30] Christopher Jarzynski, Hamiltonian derivation of a de-
tailed fluctuation theorem, J. Stat. Phys. 98, 77 (2000).
[31] Massimiliano Esposito, Katja Lindenberg, and Christian
Van den Broeck, Entropy production as correlation
between system and reservoir, New J. Phys. 12, 013013
(2010).
[32] Sebastian Deffner and Christopher Jarzynski, Information
processing and the second law of thermodynamics: An
inclusive, Hamiltonian approach, Phys. Rev. X 3, 041003
(2013).
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-29

[33] Krzysztof Ptaszyński and Massimiliano Esposito, Entropy
production in open systems: The predominant role of
intraenvironment correlations, Phys. Rev. Lett. 123,
200603 (2019).
[34] Saar Rahav and Upendra Harbola, An integral fluctuation
theorem for systems with unidirectional transitions, J. Stat.
Mech. (2014) P10044.
[35] Arnab Pal and Saar Rahav, Integral fluctuation theorems
for stochastic resetting systems, Phys. Rev. E 96, 062135
(2017).
[36] Daniel M. Busiello, Deepak Gupta, and Amos Maritan,
Entropy production in systems with unidirectional tran-
sitions, Phys. Rev. Res. 2, 023011 (2020).
[37] Ken Hiura and Shin-ichi Sasa, Kinetic uncertainty relation
on first-passage time for accumulated current, Phys. Rev.
E 103, L050103 (2021).
[38] Charles Moslonka and Ken Sekimoto, Martingale-induced
local invariance in progressive quenching, Phys. Rev. E
105, 044146 (2022).
[39] Kiyoshi Kanazawa, Tomohiko G. Sano, Takahiro Sagawa,
and Hisao Hayakawa, Minimal model of stochastic athe-
rmal systems: Origin of non-Gaussian noise, Phys. Rev.
Lett. 114, 090601 (2015).
[40] Massimiliano Esposito and Juan M. R. Parrondo, Stochas-
tic thermodynamics of hidden pumps, Phys. Rev. E 91,
052114 (2015).
[41] Gonzalo Manzano, Jordan M. Horowitz, and Juan M. R.
Parrondo, Quantum fluctuation theorems for arbitrary
environments: Adiabatic and nonadiabatic entropy pro-
duction, Phys. Rev. X 8, 031037 (2018).
[42] Lennart
Dabelow,
Stefano
Bo,
and
Ralf
Eichhorn,
Irreversibility in active matter systems: Fluctuation theo-
rem and mutual information, Phys. Rev. X 9, 021009
(2019).
[43] Laura Tociu, Étienne Fodor, Takahiro Nemoto, and
Suriyanarayanan Vaikuntanathan, How dissipation con-
strains fluctuations in nonequilibrium liquids: Diffusion,
structure, and biased interactions, Phys. Rev. X 9, 041026
(2019).
[44] However, we emphasize that our theory is also applicable
to the more standard scenario, such as when LDB is
verified.
[45] See Chap. 4 in Ref. [19] for rigorous mathematical
definitions and mathematical properties of stopping times,
and examples of stopping times in physics (e.g., first-
passage times).
[46] A version of this result even holds for quantum thermo-
dynamic processes. For further discussion of the concept
of mismatch cost in stochastic thermodynamics of com-
putation, see Refs. [47–50].
[47] Artemy Kolchinsky and David H. Wolpert, Dependence of
dissipation on the initial distribution over states, J. Stat.
Mech. (2017) 083202.
[48] D. H. Wolpert, A. Kolchinsky, and J. A. Owen, A space-
time tradeoff for implementing a function with master
equation dynamics, Nat. Commun. 10, 1727 (2019).
[49] Artemy Kolchinsky and David H. Wolpert, Dependence of
integrated, instantaneous, and fluctuating entropy pro-
duction on the initial state in quantum and classical
processes, Phys. Rev. E 104, 054107 (2021).
[50] Paul M. Riechers and Mile Gu, Initial-state dependence of
thermodynamic dissipation for any quantum process,
Phys. Rev. E 103, 042145 (2021).
[51] An analogous notion of stochastic distinguishability was
introduced in Ref. [16], in the context of forward and time-
reversed nonstationary dynamics.
[52] Massimiliano Esposito and Christian Van den Broeck,
Three detailed fluctuation theorems, Phys. Rev. Lett. 104,
090601 (2010).
[53] Takahiro Hatano and Shin-ichi Sasa, Steady-state thermo-
dynamics of Langevin systems, Phys. Rev. Lett. 86, 3463
(2001).
[54] In general, in this paper, hAðtÞjx½0;si ¼ E½AðtÞjx½0;s is an
average of functional A over all computational trajectories
with the condition of x½0;s ¼ x0; …; xs to be fixed to a
given sequence.
[55] Here
Dðρ0k¯ρτÞ ¼ P
x ρ0ðxÞ ln½ρ0ðxÞ=¯ρτðxÞ ≥0
is
the
Kullback-Leibler (KL) quantifying the “distance” between
the initial distribution of the computer’s state ρ0 and the
distribution ¯ρτ of the auxiliary computational process at the
limit time τ.
[56] I. Di Terlizzi, M. Gironella, D. Herráez-Aguilar, T. Betz, F.
Monroy, M. Baiesi, and F. Ritort, Variance sum rule for
entropy production, Science 383, 971 (2024).
[57] T. Nishiyama and Y. Hasegawa, Upper bound for entropy
production in Markov processes, Phys. Rev. E 108,
044139 (2023).
[58] Domingos S. P. Salazar, Upper bound for quantum entropy
production from entropy flux, Phys. Rev. E 105, L042101
(2022).
[59] Juan M. R. Parrondo, Jordan M. Horowitz, and Takahiro
Sagawa, Thermodynamics of information, Nat. Phys. 11,
131 (2015).
[60] Takahiro Sagawa, Thermodynamic and logical reversibil-
ities revisited, J. Stat. Mech. (2014) P03025.
[61] Philipp Strasberg, Javier Cerrillo, Gernot Schaller, and
Tobias Brandes, Thermodynamics of stochastic Turing
machines, Phys. Rev. E 92, 042104 (2015).
[62] Artemy Kolchinsky and David H. Wolpert, Thermodynamic
costs of Turing machines, Phys. Rev. Res. 2, 033312
(2020).
[63] Udo
Seifert,
Stochastic
thermodynamics,
fluctuation
theorems and molecular machines, Rep. Prog. Phys. 75,
126001 (2012).
[64] R. Kawai, J. M. R. Parrondo, and C. Van den Broeck,
Dissipation: The phase-space perspective, Phys. Rev. Lett.
98, 080602 (2007).
[65] J. A. Owen, A. Kolchinsky, and D. H. Wolpert, Number of
hidden states needed to physically implement a given
conditional
distribution,
New
J.
Phys.
21,
013022
(2019).
[66] Note that formula for F is indeed linear in ϱt.
[67] David H. Wolpert, The free energy requirements of
biological organisms; implications for evolution, Entropy
18, 219 (2016).
[68] T. M. Cover and J. A. Thomas, Elements of Information
Theory, 2nd ed. (Jonh Wiley and Sons, New York, 2012).
[69] Here we are interested in the marginal prior distribution
over computational states x ∈X only, not over the set Y
containing hidden states.
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-30

[70] Farita Tasnim and David H. Wolpert, Stochastic thermo-
dynamics of multiple co-evolving systems—Beyond multi-
partite processes, Entropy 25, 1078 (2023).
[71] Yoshitsugu Oono and Marco Paniconi, Steady state
thermodynamics, Prog. Theor. Phys. Suppl. 130, 29
(1998).
[72] Massimiliano Esposito and Christian Van den Broeck,
Three faces of the second law. I. Master equation formu-
lation, Phys. Rev. E 82, 011143 (2010).
[73] Here we will not consider the eventual erasure of the input
tape after the computation ends, but we focus on the
thermodynamic costs and dissipation due to the computing
process itself, using the information contained in the tape.
Such eventual erasure costs are independent of the mis-
match costs considered here and might be calculated on a
separate basis.
[74] Andre C. Barato and Udo Seifert, Stochastic thermody-
namics with information reservoirs, Phys. Rev. E 90,
042150 (2014).
[75] Notice that the DTMC transition probabilities Pðxtþ1jxtÞ
among the (coarse-grained) computational states in X are
given by marginalizing a fine-grained conditional distri-
bution Pðytþ1jytÞ, where y ¼ ðx; s; …Þ over s, namely the
current symbol being read, and where the update function
f defining the DFA specifies P½xtþ1jðxs; stÞ. As a conse-
quence, the transition probabilities Pðxtþ1jxtÞ are time
independent and fixed along the entire computational
process.
[76] This means that one cannot model a given DFA as some
specific (and therefore fixed width) circuit, in general. The
DFA will have properties that are not captured by that
circuit. In this sense, individual DFAs are computationally
more powerful than individual circuits.
[77] Note that by “PðjjiÞ” we do not mean the Bayesian inverse
of the forward transition matrix PðijjÞ; rather, we mean
that forward transition matrix evaluated for a transposed
choice of the initial and final states.
[78] This can be easily checked from P
j ¯PðijjÞr0ðjÞ ¼
P
j PðjjiÞrðiÞ ¼ rðiÞ,
which
immediately
implies
½ ¯Wr0 ¼ r.
[79] E. T. Jaynes, Probability Theory. The Logic of Science
(Cambridge University Press, New York, USA, 2003).
[80] Francesco Buscemi and Valerio Scarani, Fluctuation
theorems from Bayesian retrodiction, Phys. Rev. E 103,
052111 (2021).
[81] Jacopo Surace and Matteo Scandi, State retrieval beyond
Bayes’ retrodiction, Quantum 7, 990 (2023).
[82] Gonzalo Manzano, Jordan M. Horowitz, and Juan M. R.
Parrondo, Nonequilibrium potential and fluctuation theo-
rems for quantum maps, Phys. Rev. E 92, 032129 (2015).
[83] Herbert Spohn, Entropy production for quantum dynami-
cal semigroups, J. Math. Phys. 19, 1227 (1978).
[84] Yûto Murashita, Ken Funo, and Masahito Ueda, Non-
equilibrium equalities in absolutely irreversible processes,
Phys. Rev. E 90, 042110 (2014).
[85] Ken Funo, Yûto Murashita, and Masahito Ueda, Quantum
nonequilibrium equalities with absolute irreversibility,
New J. Phys. 17, 075005 (2015).
[86] Y. Masuyama, K. Funo, Y. Murashita, A. Noguchi,
S. Kono, Y. Tabuchi, R. Yamazaki, M. Ueda, and
Y. Nakamura, Information-to-work conversion by Max-
well’s demon in a superconducting circuit quantum
electrodynamical system, Nat. Commun. 9, 1291 (2018).
[87] David Williams, Probability with Martingales (Cambridge
University Press, Cambridge, England, 1991).
[88] J. L. Doob, Stochastic Processes (Wiley, New York, 1990).
[89] John A. C. Albay, Yonggun Jun, and Pik-Yin Lai, Winning
strategies of a gambling demon in a Brownian particle
under a squeezing potential, Phys. Rev. Res. 5, 023115
(2023).
[90] M. Ribezzi-Crivellari and F. Ritort, Large work extraction
and the Landauer limit in a continuous Maxwell demon,
Nat. Phys. 15, 660 (2019).
[91] M. Rico-Pasto, R. K. Schmitt, M. Ribezzi-Crivellari,
J. M. R. Parrondo, H. Linke, J. Johansson, and F. Ritort,
Dissipation reduction and information-to-measurement
conversion in DNA pulling experiments with feedback
protocols, Phys. Rev. X 11, 031052 (2021).
[92] Ilya Prigogine, Etude thermodynamique des ph´enom`enes
irr´eversibles, Bull. Acad. R. Belg. Cl. Sci. 31, 600 (1945).
[93] L. Onsager and S. Machlup, Fluctuations and irreversible
processes, Phys. Rev. 91, 1505 (1953).
[94] L. Bertini, A. De Sole, D. Gabrielli, G. Jona-Lasinio, and
C. Landim, Minimum dissipation principle in stationary
non-equilibrium states, J. Stat. Phys. 116, 831 (2004).
[95] J. W. Carlyle and A. Paz, Realizations by stochastic finite
automata, J. Comput. Syst. Sci. 5, 26 (1971).
[96] Jorge Castro and Ricard Gavald`a, Learning probability
distributions
generated
by
finite-state
machines,
in
Topics
in
Grammatical
Inference
(Springer,
Berlin,
2016), pp. 113–142.
[97] Izaak Neri, Édgar Roldán, Simone Pigolotti, and Frank
Jülicher, Integral fluctuation relations for entropy produc-
tion at stopping times, J. Stat. Mech. (2019) 104006.
[98] Martin R. Evans, Satya N. Majumdar, and Gr´egory Schehr,
Stochastic resetting and applications, J. Phys. A 53,
193001 (2020).
[99] Shamik Gupta and Arun M. Jayannavar, Stochastic reset-
ting: A (very) brief review, Front. Phys. 10, 789097 (2022).
[100] Ofir Tal-Friedman, Arnab Pal, Amandeep Sekhon, Shlomi
Reuveni, and Yael Roichman, Experimental realization of
diffusion with stochastic resetting, J. Phys. Chem. Lett. 11,
7350 (2020).
[101] Édgar Roldán, Ana Lisica, Daniel Sánchez-Taltavull, and
Stephan W. Grill, Stochastic resetting in backtrack recov-
ery by RNA polymerases, Phys. Rev. E 93, 062411 (2016).
[102] Paul C. Bressloff, Modeling active cellular transport as a
directed search process with stochastic resetting and
delays, J. Phys. A 53, 355001 (2020).
[103] Antoine B´erut, Artak Arakelyan, Artyom Petrosyan,
Sergio Ciliberto, Raoul Dillenschneider, and Eric Lutz,
Experimental verification of Landauer’s principle linking
information and thermodynamics, Nature (London) 483,
187 (2012).
[104] Yonggun Jun, Momčilo Gavrilov, and John Bechhoefer,
High-precision test of Landauer’s principle in a feedback
trap, Phys. Rev. Lett. 113, 190601 (2014).
[105] S. Ciliberto, Experiments in stochastic thermodynamics:
Short history and perspectives, Phys. Rev. X 7, 021051
(2017).
THERMODYNAMICS OF COMPUTATIONS WITH ABSOLUTE …
PHYS. REV. X 14, 021026 (2024)
021026-31

[106] Ignacio A. Martínez, Édgar Roldán, Luis Dinis, and Raúl
A. Rica, Colloidal heat engines: A review, Soft Matter 13,
22 (2017).
[107] J. P. Pekola, D. S. Golubev, and D. V. Averin, Maxwell’s
demon based on a single qubit, Phys. Rev. B 93, 024501
(2016).
[108] Salambô Dago and Ludovic Bellon, Dynamics of infor-
mation erasure and extension of Landauer’s bound to fast
processes, Phys. Rev. Lett. 128, 070604 (2022).
[109] Sidney Redner, A Guide to First-Passage Processes
(Cambridge University Press, Cambridge, England, 2001).
[110] Vladimir Y. Chernyak, Michael Chertkov, and Christopher
Jarzynski, Path-integral analysis of fluctuation theorems
for general Langevin processes, J. Stat. Mech. (2006)
P08001.
[111] Gatien Verley, Raphaël Ch´etrite, and David Lacoste,
Inequalities generalizing the second law of thermodynam-
ics for transitions between nonstationary states, Phys. Rev.
Lett. 108, 120601 (2012).
[112] Arya Datta, Patrick Pietzonka, and Andre C. Barato,
Second law for active heat engines, Phys. Rev. X 12,
031034 (2022).
[113] Faezeh Khodabandehlou, Christian Maes, and Karel
Netočný, A Nernst heat theorem for nonequilibrium jump
processes, J. Chem. Phys. 158, 204112 (2023).
[114] Pritha
Dolai,
Christian
Maes,
and
Karel
Netočný,
Calorimetry for active systems, SciPost Phys. 14, 126
(2023).
[115] Yaakov Benenson, Biomolecular computing systems:
Principles, progress and potential, Nat. Rev. Genet. 13,
455 (2012).
[116] Athel Cornish-Bowden, Fundamentals of Enzyme Kinetics
(John Wiley and Sons, New York, 2013).
[117] Julien O.Dubuis,Gašper Tkačik, Eric F. Wieschaus, Thomas
Gregor, and William Bialek, Positional information, in bits,
Proc. Natl. Acad. Sci. U.S.A. 110, 16301 (2013).
[118] Chunhe Li and Jin Wang, Quantifying cell fate decisions
for differentiation and reprogramming of a human stem
cell network: Landscape and biological paths, PLoS
Comput. Biol. 9, e1003165 (2013).
[119] Jin Wang, Landscape and flux theory of non-equilibrium
dynamical systems with application to biology, Adv. Phys.
64, 1 (2015).
[120] Ivana Ban, Lucija Tomašić, Marianna Trakala, Iva M.
Tolić, and Nenad Pavin, Proliferative advantage of specific
aneuploid cells drives evolution of tumor karyotypes,
Biophys. J. 122, 632 (2023).
[121] Christopher Battle, Chase P. Broedersz, Nikta Fakhri,
Veikko
F.
Geyer,
Jonathon
Howard,
Christoph
F.
Schmidt, and Fred C. MacKintosh, Broken detailed bal-
ance at mesoscopic scales in active biological systems,
Science 352, 604 (2016).
[122] Étienne Fodor, Cesare Nardini, Michael E. Cates, Julien
Tailleur, Paolo Visco, and Fr´ed´eric van Wijland, How far
from equilibrium is active matter?, Phys. Rev. Lett. 117,
038103 (2016).
[123] Édgar Roldán, J´er´emie Barral, Pascal Martin, Juan M. R.
Parrondo, and Frank Jülicher, Quantifying entropy pro-
duction in active fluctuations of the hair-cell bundle from
time irreversibility and uncertainty relations, New J. Phys.
23, 083013 (2021).
[124] Jos´e A. Morin, Francisco J. Cao, Jos´e M. Lázaro, J.
Ricardo Arias-Gonzalez, Jos´e M. Valpuesta, Jos´e L.
Carrascosa, Margarita Salas, and Borja Ibarra, Mechano-
chemical kinetics of DNA replication: Identification of the
translocation step of a replicative DNA polymerase,
Nucleic Acids Res. 43, 3643 (2015).
[125] Annwesha Dutta, Gunter M. Schütz, and Debashish
Chowdhury, Stochastic thermodynamics and modes of
operation of a ribosome: A network theoretic perspective,
Phys. Rev. E 101, 032402 (2020).
[126] David H. Wolpert, The stochastic thermodynamics of
computation, J. Phys. A 52, 193001 (2019).
[127] Philipp Strasberg and Massimiliano Esposito, Stochastic
thermodynamics in the strong coupling regime: An unam-
biguous approach based on coarse graining, Phys. Rev. E
95, 062101 (2017).
[128] Robert S. Whitney, Non-Markovian quantum thermody-
namics: Laws and fluctuation theorems, Phys. Rev. B 98,
085415 (2018).
[129] Cillian Cockrell and Ian J. Ford, Stochastic thermodynam-
ics in a non-Markovian dynamical system, Phys. Rev. E
105, 064124 (2022).
[130] A. Gomez-Marin, J. M. R. Parrondo, and C. Van den
Broeck, Lower bounds on dissipation upon coarse grain-
ing, Phys. Rev. E 78, 011107 (2008).
[131] Édgar Roldán and Juan M. R. Parrondo, Estimating dis-
sipation from single stationary trajectories, Phys. Rev.
Lett. 105, 150607 (2010).
MANZANO, KARDEŞ, ROLDÁN, and WOLPERT
PHYS. REV. X 14, 021026 (2024)
021026-32

