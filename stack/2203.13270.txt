Shoring Up the Foundations:
Fusing Model Embeddings and Weak Supervision
Mayee F. Chen∗1
Daniel Y. Fu*1
Dyah Adila2
Michael Zhang1
Frederic Sala2
Kayvon Fatahalian1
Christopher Ré1
1Department of Computer Science, Stanford University
2Department of Computer Science, University of Wisconsin-Madison
1{mfchen, danfu, mzhang, kayvonf, chrismre}@cs.stanford.edu
2{adila, fredsala}@cs.wisc.edu
August 2, 2022
Abstract
Foundation models offer an exciting new paradigm for constructing models with out-of-the-box embeddings and a
few labeled examples. However, it is not clear how to best apply foundation models without labeled data. A potential
approach is to fuse foundation models with weak supervision frameworks, which use weak label sources—pre-trained
models, heuristics, crowd-workers—to construct pseudolabels. The challenge is building a combination that best exploits the
signal available in both foundation models and weak sources. We propose LIGER, a combination that uses foundation model
embeddings to improve two crucial elements of existing weak supervision techniques. First, we produce ﬁner estimates
of weak source quality by partitioning the embedding space and learning per-part source accuracies. Second, we improve
source coverage by extending source votes in embedding space. Despite the black-box nature of foundation models, we
prove results characterizing how our approach improves performance and show that lift scales with the smoothness of label
distributions in embedding space. On six benchmark NLP and video tasks, LIGER outperforms vanilla weak supervision by
14.1 points, weakly-supervised kNN and adapters by 11.8 points, and kNN and adapters supervised by traditional hand
labels by 7.2 points.
1
Introduction
Foundation models—large pretrained models such as GPT-3, BERT, CLIP, and DALL-E [8, 15, 32, 34]—offer powerful
representations that can be used in a broad array of settings [7]. These models have achieved state-of-the-art performance
on many tasks. However, it remains unclear how to best apply foundation models in situations where users lack access to
any labeled data but do have some weak signals. These are the cases where another class of techniques—weak supervision
[16, 35]—shines.
The broad success of foundation models (FMs) suggests that fusing them with weak supervision may offer substantial
beneﬁts. Intuitively, the signals present in both can be used to replace large amounts of hand-labeled data in supervised
learning. These signals are complementary. Foundation models are trained on huge amounts of data and thus offer powerful
general-purpose embeddings. Weak supervision frameworks rely on multiple weak sources of signal that can be synthesized
into pseudolabels for downstream training. These weak sources typically express specialized domain expertise. The fusion
may enable each component to be improved: FM embeddings can be used without labeled data, while weak sources may be
extended to be more general-purpose.
Our goal is to combine these complementary signals to address two challenges in existing approaches to weak supervision.
The ﬁrst challenge is performing ﬁne-grained estimation of source quality. Current weak supervision approaches typically
coarsely model source quality by assuming error distributions are uniform over unlabeled points [16, 36], but source quality
may vary across points in actuality. The second challenge is producing votes on points where sources abstain. Weak sources
often abstain, so that current approaches suffer from low coverage and have many points lacking any signal. We seek to
exploit the powerful embeddings from FMs—and the geometry induced by them—to address these challenges.
We propose LIGER, a new weak supervision approach based on the notion of local quality of weak sources in the FM
embedding space (named after a well-known fusion of powerful animals). We introduce an efﬁcient algorithm that partitions
the embedding space and learns per-part local source accuracies. LIGER also extends weak sources into nearby regions of the
*Equal Contribution. A preliminary version of the results in this paper can be found at https://arxiv.org/abs/2006.15168.
1
arXiv:2203.13270v2  [stat.ML]  1 Aug 2022

Foundation Model
Embeddings
Liger: Smart Fusion of Foundation Models and Weak Supervision
def L_1:
  SPAM if “check out” 
def L_2:
  NOT SPAM if “love” 
Weak Sources
Y
λ1
λ2
λ3
Estimate Source Quality
Weak Supervision
Systems
Y
λ1
λ2
λ3
Local Estimates of Source Quality
Local Source Extensions
Liger
Figure 1: LIGER fuses embeddings from foundation models (left) with weak supervision (middle) by exploiting local
smoothness of the representations (right). LIGER uses the embeddings to a) produce more accurate local estimates of weak
source quality (right, top), and b) to locally extend weak sources, improving their coverage (right, bottom).
embedding space that they previously abstained on, improving coverage. Despite the fact that FMs are typically black-box,
our localized approach exploits a simple measurable notion of their signal: the smoothness of the label distribution in the
embedding space. When the distribution of label values does not vary signiﬁcantly over an embedding region, local source
accuracies can be estimated well, and local source extensions maintain their accuracy. We introduce generalization error
bounds that individually characterize the impact of partitioning and extending. These error bounds scale in the embedding
smoothness and involve a bias-variance tradeoff in the number of partitions and the radii that specify extensions, suggesting
that careful incorporation of the FM’s signal into our approach is necessary.
We evaluate LIGER on six benchmark NLP and video weak supervision tasks, fusing weak sources with GPT-3 embeddings [8,
30] for the NLP tasks, and with image embeddings from CLIP [32] for the video tasks. We compare LIGER against using
FMs or weak supervision on their own, as well as baseline techniques for fusing them together. First, LIGER outperforms
two strong baselines for traditional supervision of FMs, kNN and adapters [21], by 7.2 points, and outperforms traditional
weak supervision by 14.1 points. Next, LIGER outperforms kNN or adapter-based fusions of weak supervision and FMs
by 11.8 points. We ﬁnd that lift scales with embedding smoothness—conﬁrming our theoretical ﬁndings. We measure the
smoothness of CLIP embeddings against BiT-M [25], ResNet-101 embeddings pretrained on ImageNet [37], and raw pixels
on a video task. We ﬁnd that CLIP embeddings are smoothest and result in the best performance. Similarly, we ﬁnd that
using the right prompt for GPT-3 has a strong effect on smoothness and performance on a relation extraction task.
In summary, we contribute:
• LIGER, a new approach for fusing foundation models with weak supervision by exploiting local smoothness of labels and
weak sources in embedding space.
• Finite-sample generalization error bounds of our algorithm that scale in this smoothness.
• Evaluation of LIGER on six benchmark NLP and video weak supervision tasks, where LIGER outperforms simple fusions
of foundation models and weak supervison, as well as either on its own.
2
Background
We describe the problem setting for weak supervision (Section 2.1). We introduce two general challenges in weak supervision
that our approach using foundation model embeddings can mitigate. We then propose a model and explain its two stages—
source quality estimation and pseudolabel inference (Section 2.2). We provide a brief background on the estimation technique
from [16], on top of which we build our approach.
2

2.1
Problem Setup
Our goal is to predict label y ∈Y = {−1, +1} from datapoints x ∈X. If we had access to pairs (x, y), we could
train a supervised model. However, we do not have access to any samples of y; instead, we observe m weak sources
λ = {λ1, . . . , λm}, each voting or abstaining on each point x via a probabilistic labeling function λj : X →Y ∪{0} for
all j ∈[m]. We refer to λj(x) = 0 as an abstain, which occurs when a source is uncertain or not applicable on a point.
We also have access to FM embeddings. These embeddings are the outputs of a mapping f : X →Z from input space to
an embedding space Z equipped with metric ρ : Z × Z →R+. This mapping is ﬁxed and obtained from an off-the-shelf
model. Overall, we have an unlabeled dataset D = {xi}n
i=1 of n i.i.d. points, as well as access to m weak sources and the
embedding map f.
Given an input x and λ(x), we aim to learn a label model that predicts y by estimating ˆPr(y|λ, x) (we drop the x in λ(x)
when obvious). The goal of the label model is to combine sources based on their individual accuracies (i.e. λi’s rate of
agreement with y) by upweighting high-quality sources and downweighting low-quality ones. The resulting pseudolabels
given by ˆPr(y|λ, x) can be used to train a downstream supervised end model or used just directly as predictions. The latter
case is often ideal, since users need not train an additional model. We focus on this setting.
Two Challenges and Opportunities. Next, we describe two challenges common to weak supervision techniques. Fusing
weak supervision with FM embeddings presents opportunities to mitigate these challenges.
• Coarse Accuracy Modeling. The most common assumption in weak supervision is to model ˆPr(y|λ, x) as ˆPr(y|λ). That
is, conditioned on the weak sources, the true label is viewed as independent of the features, so only one set of accuracies is
learned over the data. Removing this assumption is desirable, since the feature space may have information about the task
not captured fully by weak sources. However, naively attempting to model per-point accuracies leads to noisy estimation.
• Low Coverage. Weak sources frequently abstain, leading to low coverage—a situation where much of the dataset has no
votes. A simple mitigation is to extend votes from nearby non-abstaining points, but this is risky if the notion of distance
is not well-aligned with the label distribution.
An intuitive way to tackle these two challenges is to operate locally. Suppose the source votes and the true label satisfy some
level of smoothness such that within some local region of the feature space, they have a low probability of changing values.
We can then model accuracies speciﬁc to such local regions and can extend source votes to points they abstain on within
the regions. However, raw image and text features may lack signal and not offer sufﬁcient smoothness to permit operating
locally. By acting on the embedding space, the desired smoothness property is improved (see Figure 2). We can thus obtain
ﬁner-grained accuracy estimation and improved coverage by using FM embeddings to model local accuracies and extend
locally.
Next, we make these notions concrete by presenting the explicit model for Pr(y, λ|x).
2.2
Label Model
We model Pr(y, λ|x) as a probabilistic graphical model. Our use of this model has two steps. First, in training, we must
estimate the accuracy parameters of Pr(y, λ|x) without access to y. Then, at inference, we compute ˆPr(y|λ, x).
Let the graphical model be based on G = (V, E), where V = y ∪λ and E consists of edges from y to each λj (see Figure 1
middle). For simplicity, we assume there are no dependencies between the weak sources, although the dependencies can be
learned [44] and handled by our choice of base estimator from [16]. Therefore, our approach can be extended to that case as
well. We model the data distribution as
Pr(y, λ|x) = 1
Z exp

θy(x)y
| {z }
Class Balance
+
m
X
i=1
θi(x)λiy
|
{z
}
Source Accuracy
+
m
X
i=1
θi,0(x)1 {λi = 0}
|
{z
}
Abstain Rate

(1)
with partition function Z and a set of canonical parameters per x, Θ(x) = {θy(x), θi(x), θi,0(x) ∀i ∈[m]}. An important
property above is that λi ⊥⊥λj|y, x ∀i, j ∈[m].
The model concretely portrays the two challenges in weak supervision. First, canonical parameters Θ(x) that are a function
of the input can capture varying accuracy across the data. This is less strict than prior formulations that model the marginal
Pr(y, λ) with one set of canonical parameters without considering input data. However, estimating Θ(x) is challenging;
parametric approaches require certain assumptions on the function Θ as well as the distribution of x in order to recover the
ground truth labels, but these assumptions (e.g., Gaussian x) are often not realistic. Standard nonparametric approaches
have a high computational complexity and rely on smoothness of the input space X. Second, when λi(x) = 0, the weak
source provides no information on x at inference and is thus typically ignored on that point in previous approaches. This is
3

Algorithm 1: LIGER
Input: Dataset D = {xi}n
i=1, weak sources λ, embedding mapping f and metric ρ, threshold radii r1, . . . rm, partition C
and class balances Pr(y|Cj) for j ∈[s].
Returns: Label model ˆPr(y|¯λ, x).
for λi ∈λ do
Construct extended source ¯λi using ri, f, ρ as in (3).
end for
for Cj ∈C do
for ¯λi ∈¯λ do
Compute accuracy ˆai(Cj) using Algorithm 2 on ¯λi over Cj, and compute coverage ˆPr(¯λi ̸= 0|Cj) on D.
Set ˆPr(¯λi|y, Cj) equal to 1+sgn(¯λiy)ˆai(Cj)
2
ˆPr(¯λi ̸= 0|Cj) for ¯λi ∈{−1, 1}, ˆPr(¯λi = 0|Cj) otherwise.
end for
Compute ˆPr(¯λ|Cj) on D.
end for
return For test point x ∈X, compute ˆPr(y|¯λ, x) = ˆPr(y|¯λ, C(x)) =
Qm
i=1 ˆ
Pr(¯λi|y,C(x)) Pr(y|C(x))
ˆ
Pr(¯λ|C(x))
.
reﬂected in the graphical model by Lemma 2 in Appendix C.1, by which Pr(y|λi = 0, λ\λi, x) = Pr(y|λ\λi, x). In fact,
the weak sources provide no direct signal on x when λ(x) = ⃗0.
Pseudolabel Inference. To perform inference, we compute ˆPr(y|λ, x) for some x ∈X. This is done via Bayes’ rule and
the conditional independence of weak sources: Pr(y|λ, x) = Qm
i=1 Pr(λi|y, x) Pr(y|x)/ Pr(λ|x). The latent parameter of
interest in this decomposition is Pr(λi|y, x), which corresponds to the accuracy of λi.
Source Parameter Estimation. Previous approaches have considered how to estimate Pr(λi|y) in a model of Pr(λ, y) via
the triplet method [16], using conditional independence properties. For our setting, (1) tells us that λiy ⊥⊥λjy|λi ∧λj ̸= 0, x
for any i ̸= j (Lemma 3 in Appendix C.1). As a result, E [λiy|λi ̸= 0, x]×E [λjy|λj ̸= 0, x] = E

λiλjy2|λi ∧λj ̸= 0, x

=
E [λiλj|λi ∧λj ̸= 0, x], which consists of observable variables. Deﬁne ai(x) = E [λiy|λi ̸= 0, x] as the accuracy of λi on
x. If we introduce a third λk, we can generate a system of equations over ai(x), aj(x), ak(x) in terms of the conditional
expected products of pairs of λi, λj, λk. As a result,
|ai(x)| :=
s
E [λiλj|λi ∧λj ̸= 0, x] E [λiλk|λi ∧λk ̸= 0, x]
E [λjλk|λj ∧λk ̸= 0, x]
,
(2)
and likewise for ˆaj(x), ˆak(x). More details are in Appendix C.2. (1) allows us to write Pr(λi|y, x) = 1+sgn(λiy)ai(x)
2
×
Pr(λi ̸= 0|x) (Lemmas 2 and 4), so the desired probability estimate is just a linear transformation of ai(x) scaled by λi’s
coverage.
3
Fusion Algorithm
We are ready to present LIGER, our approach to fusing foundation model embeddings and weak supervision. We explain
the two components: ﬁrst, how to compute conditional estimates of the label model parameters over local regions of the
partitioned embedding space for ﬁner-grained accuracy estimation; second, how to extend weak sources via a kNN-like
augmentation in the embedding space, improving their coverage and hence the signal available at inference. The full
approach is shown in Algorithm 1.
Local Parameter Estimation
Our ﬁrst task is to compute the label model’s local parameters. Based on (2), the quantities
to estimate are of the form E [λiλj|λi ∧λj ̸= 0, x], Pr(λi ̸= 0|x), Pr(λ|x), Pr(y|x). These conditional statistics can be
estimated using nonparametric approaches such as the Nadaraya-Watson estimator, but they require O(n) computations per
point at inference.
Instead of estimating parameters per point, we partition the embedding space and compute per-part statistics. Intuitively,
this choice exploits smoothness. If label distributions are smooth, i.e., they do not vary greatly within a local region, it is
sufﬁcient to estimate per-point statistics using a part given that parts are not too large. Controlling the size of the partition is
thus important in determining how well we can approximate per-point statistics.
Concretely, partition Z into s subsets C = {C1, . . . , Cs} of equal size n′ = n
s (we use K-means clustering with K = s in
practice). Denote C(x) as the subset f(x) belongs to. Instead of estimating statistics and performing inference conditioned
4

on x, we condition on C(x), producing s sets of parameters overall. We estimate E [λiλj|λi ∧λj ̸= 0, C(x)], yielding a
local accuracy estimate ˆai(C(x)) formalized in Algorithm 2, as well as Pr(λi ̸= 0|C(x)), Pr(λ|C(x)), Pr(y|C(x)). Then,
we use ˆPr(y|λ, x) = ˆPr(y|λ, C(x)) as our label model prediction on x. These estimates are done over the subsets; for
instance, Pr(λ|C(x)) ≈
1
n′
P
x′∈C(x) 1 {λ(x′)=λ}. We assume that class balance on subsets, Pr(y|C(x)), are known.
There are also several techniques that can be used to estimate these [36], or they can be treated as hyperparameters.
Weak Source Extension
Next, we improve the model of ˆPr(y|λ, x) by increasing source coverage. Let ¯λi be an extended
labeling function with corresponding threshold radius ri > 0 for i ∈[m]. The extension works as follows. For any x, let
NN(x) = argminx′∈D:λi(x)̸=0 ρ(f(x), f(x′)) be the nearest neighbor of x in embedding space from D such that λi has
coverage on it. ¯λi uses nearest neighbors to weakly label points within ri of λi’s support on D. Formally,
¯λi(x) :=





λi(x)
λi(x) ̸= 0
λi(NN(x))
ρ(f(x), f(NN(x))) ≤ri
0
o.w.
.
(3)
We can view ¯λi as an augmentation on λi using D and f. We thus perform parameter estimation and inference using ¯λ
instead of λ, namely learning Pr(y|¯λ, C(x)).
There are two advantages to using extended sources. First, extended sources improve sampling error, since expressions
like E [λiλj|λi ∧λj ̸= 0, x] are estimated over more data in D. Second, ¯λi provides signal at inference on points that λi
previously abstains on. However, the quality of this signal greatly depends on ri. If λi is overextended and the embedding
space is not sufﬁciently smooth, points far away from λi’s support may receive incorrect extended source votes, suggesting
that careful choice of ri is needed.
Our approach combines the two components discussed—partitioning the embedding space and extending sources—to output
predictions ˆPr(y|¯λ, C(x)) as in Algorithm 1. Note that our approach builds on the algorithm from [16], but partitioning and
extending can also be done on top of other weak supervision algorithms that model things differently.
4
Theoretical Analysis
Now we turn to analyzing Algorithm 1. Our goal is to understand how performance depends on the key parameters: ﬁneness
of the partition C, radii ri of the extensions used to improve coverage, and smoothness of the embedding space.
We begin with a result on the generalization error of the label model ˆPr(y|λ, x), which relies on the number of partitions s
to control the granularity of the estimated parameters (Theorem 1). Then, we discuss the improvement from using ¯λ instead
of λ. We ﬁrst bound the local accuracy of an extended source in a region it previously abstains (Lemma 1), and then we
show that as long as this local accuracy is better than random, we can further reduce the generalization error (Theorem 2).
The former result presents a bias-variance tradeoff depending on s, while the latter has a tradeoff dependent on the threshold
radius ri. In both cases, s and ri must be carefully set based on the signal in the FM embeddings, namely the smoothness
of label distributions in the FM embedding space, in order to optimize performance. We provide proofs in Appendix D,
synthetic experiments supporting our ﬁndings in Appendix F.3, and smoothness measurements on real data in Section 5.2
and Appendix F.2.
Deﬁne the generalization error of the label model using weak sources λ as the expected cross-entropy loss, L(λ) =
ED,x,y,λ[−log ˆPr(y|λ, x)].
4.1
Label Model Generalization Error
We bound the generalization error L(λ) of the label model using the unextended, initial weak sources. The key quantity in
this analysis is embedding smoothness:
Deﬁnition 1 (Lipschitzness). The distributions Pr(y|x) and Pr(λi|y, x) are Lipschitz-smooth on the metric space (Z, ρ)
with constants Ky, Kλ, Kλ,0 > 0 if for all i ∈[m],
| Pr(y = 1|x) −Pr(y = 1|x′)| ≤Kyρ(f(x), f(x′)),
| Pr(λi = 1|y, λi ̸= 0, x) −Pr(λi = 1|y, λi ̸= 0, x′)| ≤Kλρ(f(x), f(x′)),
| Pr(λi ̸= 0|x) −Pr(λi ̸= 0|x′)| ≤Kλ,0ρ(f(x), f(x′)),
We refer to these three properties as label, source, and coverage Lipschitzness, respectively.
5

In words, if the constants Ky, Kλ, Kλ,0 are small, the class balance of y and the way each source votes (or doesn’t) do not
vary signiﬁcantly over a local region of the embedding space.
We deﬁne some additional quantities. Set α = maxi Ex
h
1
pij
 pij ̸= 0
i
, where pij = Pr(λi ̸= 0|f(x) ∈Cj) is the
coverage of λi on Cj, to be the largest average inverse source coverage over the subsets. α corresponds to how often
sources abstain. Assume that ai(Cj) > 0 for all λi and Cj, meaning that the average source accuracy on a subset is better
than random. Then, deﬁne amax = maxi,j ai(Cj), and bmin = min
i,j,k{E [λiλk|λi ∧λk ̸= 0, Cj] , ˆE [λiλk|λi ∧λk ̸= 0, Cj]}
as the minimum rate of agreement between sources over subsets, where ˆE denotes the empirical estimate on D. Deﬁne
dCj = maxf(x),f(x′)∈Cj ρ(f(x), f(x′)) as the diameter of Cj and dC = Ex

dC(x)

as its average.
Theorem 1. Suppose that data x, y, λ follows the model in (1) and Pr(y|x) and Pr(λi|y, x) for each λi are Lipschitz-
smooth. The generalization error of the label model ˆPr(y|λ, x) in Algorithm 1 when ri = 0 ∀i can be decomposed into
L(λ)=Bias + Variance + Irreducible Error + o(1/n), where
Bias ≤2dC(Ky + mKλ + mKλ,0),
Variance ≤ms
n

3α(1 −b2
min)
8b2
min(1 −a2max)
 1
b4
min
+
2
b2
min

+ 1

,
Irreducible Error = H(y|λ, x),
where H(y|λ, x) denotes conditional entropy.
We discuss each term of this bound.
• The bias comes from the partition C, since conditional statistics on C(x) are not equivalent to those on x. When the
embedding space is smooth with small Ky, Kλ, Kλ,0, the bias is low. Note that making the subset diameter dC →0
makes the bias go to zero.
• The variance comes from sampling error in Algorithm 2 and ˆPr(λi ̸= 0|Cj). This quantity scales in O(sα/n) and also
depends on accuracy and agreement among weak sources.
• The irreducible error depends on quality of λ. If knowledge of λ signiﬁcantly reduces uncertainty in y, i.e., the sources
contain lots of signal, this quantity is low. On the other hand, H(y|λ, x) is maximized when λ ⊥⊥y|x, i.e. there is no
signal about y in λ.
Our result reveals a bias-variance tradeoff dependent on the number of parts s. As s increases, subset diameter dC tends to
decrease, resulting in lower bias because the subset parameters estimated will be closer in true value to those conditional on
x. The variance increases in s because there are fewer points per subset for estimation. The s = 1 case, which incurs a large
bias, is algorithmically equivalent to the approach in [16]. Such approaches thus suffer from model misspeciﬁcation in our
setting—and likely in most practical cases—as they assume uniform quality per source.
4.2
Improvement from Extensions
Suppose that x, y, ¯λ follows (1). When we use ¯λ rather than λ (i.e. ri ̸= 0), there are several changes to the decomposition
in Theorem 1:
• The bias is now bounded by 2dCKy +2m(dC +2 maxi ri)(Kλ +Kλ,0) (see Lemma 8 in Appendix D). We must consider
when NN(x) is not in C(x), essentially resulting in a wider subset diameter.
• The variance is still O(1/n), but multiplicative factors change. For instance, α decreases due to improved coverage, thus
decreasing the variance.
• The irreducible error is now H(y|¯λ, x).
We analyze H(y|¯λ, x) in this section. ¯λi provides more signal than λi at inference on points where λi(x) = 0, but the signal
about y’s value may be incorrect. Extending λi using too large of ri could yield incorrect source votes, resulting in lower
accuracy of the extended weak source.
We ﬁrst present a result on how ri controls the extended source’s accuracy. Deﬁne ai = E [λiy|λi ̸= 0] as the average
accuracy of λi, and ¯ai(ri) = E
¯λiy|¯λi ̸= 0, λi = 0

as ¯λi’s average accuracy on the extended region. We also need a
notion of smoothness of y between the original support and the extended region. We deﬁne a local notion of probabilistic
Lipschitzness (PL), originally introduced in [43].
Deﬁnition 2 (Probabilistic Lipschitzness). Deﬁne Pλi = Prx,y(·|λi ̸= 0) to be the distribution of (x, y) over the support of
λi, and let Pλi,x be its marginal distribution on x. Then Pλi is M-probabilistically Lipschitz for an increasing function
6

M : R+ →[0, 1] if for any r > 0,
Pr
x,y∼Pλi
(∃(x′, y′) ∈X\supp(Pλi,x) × Y : ρ(f(x), f(x′)) ≤r, y′ ̸= y) ≤M(r).
We refer to this property as local label PL.
In words, the probability that there is a point outside of the support of λi but within r of (x, y) ∼Pλi with a different
label from y is bounded by an increasing function of r. We also deﬁne βi = E[λiy|λi ̸= 0, ∃(x′, y′) : λi(x′) =
0, ρ(f(x), f(x′)) ≤ri, y′ = y] as λi’s accuracy over a region close to where λi is extended and y changes value.
With this deﬁnition, we show that:
Lemma 1. Suppose Pλi is M-probabilistically Lipschitz. The average accuracy of ¯λi on the extended region is at least
¯ai(ri) ≥ai −(1 + βi)M(ri).
Our result provides local accuracy guarantees on ¯λi as a function of the original λi’s accuracy, the probabilistic Lipschitzness
of the embedding space, and the ri the user sets. Extending a source with higher original accuracy will yield stronger
accuracy guarantees in the extended region. On the other hand, if M(ri) is too large due to improper ri or lack of smoothness,
the true label is more likely to change value, and hence accuracy in the extended region worsens.
Now we can use our result on ¯ai(ri) to analyze the improvement in irreducible error. We extend just one weak source λi by
ri and keep λ−i := λ\λi unextended. Deﬁne pi = Pr(¯λi ̸= 0, λi = 0) as the proportion of the region where ¯λi is extended
and p(λ−i) = Ey′,λ−i,¯λi̸=0,λi=0 [Pr(y = y′|λ−i, x)] as the label model’s probability of outputting the correct label in the
extension region when only using λ−i.
Theorem 2. Suppose that data follows the model in (1). The irreducible error decreases by at least the following amount
when using ¯λi rather than λi in Algorithm 1:
H(y|λ, x) −H(y|¯λ, x) ≥2pi(1 −p(λ−i))2 · ¯ai(ri)2.
Lift increases with probability mass pi on the extended region since more of the data is impacted by ¯λi. Lift is not as
signiﬁcant if p(λ−i) is large because the other weak sources already are providing sufﬁcient signal for y. Most importantly,
lift scales with how far ¯ai(ri) is from 0 (random voting). This highlights a tradeoff in ri: as ri increases, pi increases but the
lower bound on ¯ai(ri) from Lemma 1 decreases. This shows that threshold radii must be selected carefully; if the embedding
space has strong probabilistic Lipschitzness (i.e. small M) or the original weak source has high accuracy, then the source
can be extended further while providing lift. However, overextension of the source can yield low local accuracy and thus
less lift.
Our results demonstrate that s and ri control the label model’s performance, and setting these terms depends on how smooth
label distributions are in the embedding space.
5
Experiments
Weak Sources Only
Task
WS-kNN
WS-Adapter
WS-LM
LIGER
∆Coverage
NLP
Spam
72.8
92.3
83.6
95.0
+45.5
Weather
62.0
86.0
78.0
98.0
+90.2
Spouse
16.9
17.1
47.0
52.2
+12.1
Video
Basketball
33.3
48.9
27.9
69.6
+8.3
Commercial
84.7
92.8
88.4
93.5
+18.8
Tennis
83.0
83.8
82.0
83.3
+32.5
Dev Labels Available
kNN
Adapter
LIGER-Adapter
91.2
94.4
95.4
92.0
90.0
96.8
21.6
15.7
49.6
64.4
79.3
79.5
92.0
93.0
93.2
73.2
83.1
84.0
Table 1: Left: LIGER performance compared to baselines that only have access to weak labels, as well as the change in
coverage from traditional weak supervision. Right: LIGER-Adapter performance compared to baselines that have access to
dev labels. Scores are F1 except for Spam and Weather (accuracy); best score in bold in each setting.
This section evaluates the following claims about LIGER:
• Performance (Section 5.1): LIGER outperforms vanilla weak supervision, as well as baseline approaches for using
foundation models directly, either with traditional weak supervision or hand supervision.
• Smoothness (Section 5.2): Lift is correlated with the smoothness of the label distribution in the representation space. We
measure smoothness and performance of CLIP against three other embedding methods on a video task, and measure three
prompting strategies for GPT-3 on a relation extraction task.
7

Embedding
F1-score
Raw pixel
19.3
RN-101
31.1
BiT-M
42.5
CLIP
69.6
Smoother
5
6
7
8
9
82
86
90
% Points with Changed Value
N-nth Nearest Points
Basketball Lipschitzness
Raw Pixels
ResNet-101
BiT-M
CLIP
Prompting
F1-score
No Prompt
48.5
Prompt Beginning
50.2
Prompt End
52.2
Smoother
0.002
0.006
0
20
40
% Points with Changed Value
Cosine Distance Radius
Spouse Lipschitzness
No Prompt
Prompt Beginning
Prompt End
Figure 2: Left: LIGER performance and smoothness measurements of CLIP, BiT-M, ResNet-101, and raw pixels as
embeddings for Basketball. Right: LIGER performance and smoothness measurements of no prompting, prompting at
beginning, and prompting at end in GPT-3 for Spouse.
• Ablations (Section 5.3): Both components of LIGER—partitioning the representation space and extending labeling
function votes—are important for performance.
Datasets
We evaluate LIGER on six benchmark NLP and video tasks used to evaluate previous weak supervision
methods [16, 47]. In NLP, Spam identiﬁes spam YouTube comments [3]; Weather identiﬁes the sentiment of weather-
related tweets [1]; and Spouse identiﬁes spouse relationships in newspaper articles [13]. In video, Commercial identiﬁes
commercial segments in TV news [17, 20]; Tennis identiﬁes rallies in tennis segments; and Basketball identiﬁes basketball
videos in a subset of ActivityNet [9]. Each dataset consists of a large unlabeled training set, a smaller hand-labeled
development set (train/dev split sizes from 187/50 points to 64,130/9,479 points), and a held-out test set. We use the
unlabeled training set to train label models and use the development set for a) training of traditional supervision baselines,
and b) hyperparameter tuning of the label models, including s and ri.
Pre-trained embeddings
For the NLP datasets, we use pre-trained GPT-3 [8] embeddings from OpenAI’s Ada model.
For Spam and Weather, we simply embed the text directly. For Spouse, we add a prompt “Are [person 1] and [person 2]
spouses?” after the end of the sentence. We discuss further prompting strategies in Section 5.2. For video datasets, we use
image embeddings from CLIP [32] over individual frames of the videos.
5.1
Performance
We compare LIGER against baseline approaches for fusing foundation models with weak supervision, as well as against
using either on their own.1 We split our evaluation into two parts: methods that only have access to weak sources, and
methods that additionally have access to the dev set.
Weak Sources Only
We compare the performance of LIGER against vanilla weak supervision’s label model (WS-LM) [16],
as well as two end models, weakly-supervised kNN (WS-kNN), and weakly-supervised adapters (WS-Adapter). In the latter
two methods, we use the predictions from WS-LM to generate pseudolabels for the train set and use the FM embeddings as
input data (since we do not access the full FM) to the kNN and adapter approaches. We consider an adapter that is a linear
layer on the FM embeddings. We also provide results on 3-layer MLP adapters in Appendix F.
Table 1 (left) shows the results, as well as statistics on the additive change in coverage (% of the dataset that sources vote
on) between LIGER and WS-LM. LIGER outperforms WS-LM and has better coverage (33.2 points on average). LIGER
also outperforms both of the baseline approaches for fusing foundation models with weak supervision, WS-kNN and
WS-Adapter.
Weak Sources and Dev Labels
Next, we compare performance against methods that have access to a small hand-labeled
dev set. We compare against two baselines: kNN and Adapter, both trained over the dev set labels. For our method LIGER-
Adapter, we train an adapter over LIGER labels on the train set, as well as the dev labels. In some cases, LIGER labels are
too noisy to provide good signal on the train set; in this case, our solution automatically downsamples the pseudolabels on
the train set. We also provide the original LIGER prediction as input to the adapter. See Appendix E for the details.
Table 1 (right) shows the results. LIGER-Adapter outperforms Adapter and kNN. On the datasets where LIGER labels are
very accurate, we see additional lift from the adapters because we have more points to train on. When the labels are not very
1Our code is available at https://github.com/HazyResearch/liger/.
8

Task
LIGER (s)
-Part
-Ext (s)
-Part, -Ext
Spam
95.0 (2)
94.0
92.0 (7)
83.6
Weather
98.0 (3)
96.0
94.0 (5)
78.0
Spouse
52.2 (6)
50.0
49.3 (5)
47.0
Basketball
69.6 (2)
69.6
21.9 (2)
27.9
Commercial
93.5 (3)
92.3
91.4 (5)
88.4
Tennis
83.3 (1)
83.3
81.3 (2)
82.0
Table 2: Ablations of LIGER, removing partitions (-Part), extensions (-Ext), and both. Best s values inside parentheses.
accurate, our downsampling prevents the noisy labels from harming adapter performance. In one case, learning an adapter
over the embeddings is very hard (Spouse). Here, providing the LIGER prediction as input is critical for performance.
5.2
Embedding Smoothness
We measure how smoothness of the embedding space affects the performance of LIGER. First, we compare embeddings
from CLIP against BiT-M embeddings [25], a ResNet-101 pretrained on ImageNet [37], and raw pixels. Second, we vary the
GPT-3 prompting strategy for Spouse and compare against two alternative methods that result in a less smooth representation.
We report label Lipschitzness—the smoothness of embeddings with respect to ground-truth labels—in this section. See
Appendix F.2 for additional measures of Lipschitzness.
Figure 2 (left) shows the performance of CLIP, BiT-M, ResNet-101, and raw pixels as embeddings for LIGER, as well as
measures of Lipschitzness for each method (lower is smoother). CLIP embeddings are smoother than the other methods—
which matches their performance when used in LIGER.
Comparing Prompting Strategies
Next, we examine the impact of prompting strategies for Spouse. Spouse is a relation
extraction dataset, where the task is to predict whether two entities in a sentence are married. Since there may be multiple
entities in a sentence, Spouse contains multiple duplicate sentences in the dataset, with different labels. To alleviate this
problem, we introduce a prompt “Are [person 1] and [person 2] spouses?” after the end of the sentence, where “[person 1/2]”
are replaced by the names of the ﬁrst/second entity in the sentence. We compare this prompting strategy against two others:
appending the same prompt to the beginning of the sentence, and leaving the original sentence as-is, without any prompting.
Figure 2 (right) shows the performance and smoothness of each of these prompting methods. Adding the prompt to the end
of the sentence results in the best performance and smoothest embeddings. Both methods perform better than leaving the
sentence alone (the ﬂat line is a result of multiple sentences with different labels having the same embedding).
5.3
Ablations
We report ablations on each component of LIGER. Table 2 removes the partioning component and the extensions component.
Partitioning improves performance on four tasks, and extensions improves performance on all tasks (13.1 points of lift on
average from partitioning, 3.8 points from extensions). Combining both additionally offers the best performance on four
tasks.
6
Related Work
We present an abbreviated related work here. See Appendix A for an extended treatment.
Weak supervision frameworks typically model source accuracies to generate weak labels and then ﬁne-tune an end model
for generalization [4, 6, 16, 24, 35, 38, 40, 46]. One framework models the end-to-end process all at once [10], but requires
training the end model at the same time—which is computationally expensive with large foundation models. Our work
removes the ﬁne-tuning step completely.
Our work is similar to transfer learning techniques, which adapt pretrained models for downstream tasks [14, 25]. Foundation
models offer new requirements for transfer learning setting: when it is impossible to ﬁne-tune the original models [7]. We
build on approaches such as prompting [8, 27], embedding search [30], and adapters [2, 21].
9

7
Conclusion
We present LIGER, a system for fusing foundation models and weak supervision. We use embeddings to produce ﬁner-
grained estimates of weak source accuracies and improve weak source coverage. We prove a series of results on how the
performance of this approach scales with the smoothness of the embeddings, and demonstrate LIGER on six benchmark
NLP and video weak supervision datasets. We hope our work will encourage further work in combining foundation models
and weak supervision and in utilizing the signal from foundation models to help with other tasks.
Authors’ Note
The ﬁrst two authors contributed equally. Co-ﬁrst authors can prioritize their names when adding this
paper’s reference to their resumes.
Acknowledgments
We thank Fait Poms and Ravi Teja Mullapudi for helpful discussions. We thank Neel Guha, Megan Leszczynski, Vishnu
Sarukkai, and Maya Varma for feedback on early drafts of this paper. We gratefully acknowledge the support of NIH
under No. U54EB020405 (Mobilize), NSF under Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity),
1937301 (RTML), and CCF2106707 (Program Synthesis for Weak Supervision); ARL under No. W911NF-21-2-0251
(Interactive Human-AI Teaming); ONR under No. N000141712266 (Unifying Weak Supervision); ONR N00014-20-1-
2480: Understanding and Applying Non-Euclidean Geometry in Machine Learning; N000142012275 (NEPTUNE); NXP,
Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm,
Analog Devices, Google Cloud, Salesforce, Total, the HAI-GCP Cloud Credits for Research program, the Stanford Data
Science Initiative (SDSI), Department of Defense (DoD) through the National Defense Science and Engineering Graduate
Fellowship (NDSEG) Program, Wisconsin Alumni Research Foundation (WARF), and members of the Stanford DAWN
project: Facebook, Google, and VMWare. The U.S. Government is authorized to reproduce and distribute reprints for
Governmental purposes notwithstanding any copyright notation thereon. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views, policies, or
endorsements, either expressed or implied, of NIH, ONR, or the U.S. Government.
References
[1] Weather sentiment: Dataset in crowdﬂower. https://data.world/crowdﬂower/weather-sentiment.
[2] Guillaume Alain and Yoshua Bengio. Understanding intermediate layers using linear classiﬁer probes. arXiv preprint
arXiv:1610.01644, 2016.
[3] Túlio C Alberto, Johannes V Lochter, and Tiago A Almeida. Tubespam: Comment spam ﬁltering on youtube. In 2015
IEEE 14th International Conference on Machine Learning and Applications (ICMLA), 2015.
[4] Stephen H Bach, Daniel Rodriguez, Yintao Liu, Chong Luo, Haidong Shao, Cassandra Xia, Souvik Sen, Alex Ratner,
Braden Hancock, Houman Alborzi, et al. Snorkel drybell: A case study in deploying weak supervision at industrial
scale. In Proceedings of the 2019 International Conference on Management of Data, 2019.
[5] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In Proceedings of the eleventh
annual conference on Computational learning theory. ACM, 1998.
[6] Benedikt Boecking and Artur Dubrawski. Pairwise feedback for data programming. In Proceedings of NeurIPS 2019
Workshop on Learning with Rich Experience (LIRE), December 2019.
[7] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, et al. On the opportunities and risks of foundation models. arXiv
preprint arXiv:2108.07258, 2021.
[8] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,
Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural
information processing systems, 2020.
[9] Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem, and Juan Carlos Niebles. Activitynet: A large-scale video
benchmark for human activity understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, 2015.
[10] Salva Rühling Cachay, Benedikt Boecking, and Artur Dubrawski. End-to-end weak supervision. In Advances in
Neural Information Processing Systems, 2021.
10

[11] Mayee Chen, Benjamin Cohen-Wang, Stephen Mussmann, Frederic Sala, and Christopher Re. Comparing the value of
labeled and unlabeled data in method-of-moments latent variable estimation. In Proceedings of The 24th International
Conference on Artiﬁcial Intelligence and Statistics, 2021.
[12] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning
of visual representations. In International conference on machine learning. PMLR, 2020.
[13] David Corney, Dyaa Albakour, Miguel Martinez-Alvarez, and Samir Moussa. What do a million news articles look
like? In NewsIR@ECIR, 2016.
[14] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional
transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional
transformers for language understanding. In Proceedings of the 2019 Conference of the Association for Computational
Linguistics, 2019.
[16] Daniel Y. Fu, Mayee F. Chen, Frederic Sala, Sarah M. Hooper, Kayvon Fatahalian, and Christopher Ré. Fast and
three-rious: Speeding up weak supervision with triplet methods. In Proceedings of the 37th International Conference
on Machine Learning, 2020.
[17] Daniel Y. Fu, Will Crichton, James Hong, Xinwei Yao, Haotian Zhang, Anh Truong, Avanika Narayan, Maneesh
Agrawala, Christopher Ré, and Kayvon Fatahalian. Rekall: Specifying video events using compositions of spatiotem-
poral labels. arXiv preprint arXiv:1910.02993, 2019.
[18] Sonal Gupta and Christopher Manning. Improved pattern learning for bootstrapped entity extraction. In Proceedings
of the Eighteenth Conference on Computational Natural Language Learning, 2014.
[19] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual
representation learning. arXiv preprint arXiv:1911.05722, 2019.
[20] James Hong, Will Crichton, Haotian Zhang, Daniel Y Fu, Jacob Ritchie, Jeremy Barenholtz, Ben Hannel, Xinwei Yao,
Michaela Murray, Geraldine Moriba, et al. Analysis of faces in a decade of us cable tv news. In Proceedings of the
27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2021.
[21] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo,
Mona Attariyan, and Sylvain Gelly. Parameter-efﬁcient transfer learning for nlp. In International Conference on
Machine Learning. PMLR, 2019.
[22] Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, and Ondrej Chum. Label propagation for deep semi-supervised learning.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5070–5079, 2019.
[23] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generalization through memo-
rization: Nearest neighbor language models. In International Conference on Learning Representations, 2019.
[24] Ashish Khetan, Zachary C. Lipton, and Anima Anandkumar. Learning from noisy singly-labeled data. In International
Conference on Learning Representations, 2018.
[25] Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, and Neil Houlsby.
Big transfer (bit): General visual representation learning. In ECCV, 2020.
[26] Hunter Lang, Aravindan Vijayaraghavan, and David Sontag. Training subset selection for weak supervision. arXiv
preprint arXiv:2206.02914, 2022.
[27] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efﬁcient prompt tuning. In
Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.
[28] Percy Liang, Michael I Jordan, and Dan Klein. Learning from measurements in exponential families. In Proceedings
of the 26th annual international conference on machine learning. ACM, 2009.
[29] Gideon S Mann and Andrew McCallum. Generalized expectation criteria for semi-supervised learning with weakly
labeled data. Journal of machine learning research, 2010.
[30] Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas
Tezak, Jong Wook Kim, Chris Hallacy, et al. Text and code embeddings by contrastive pre-training. arXiv preprint
arXiv:2201.10005, 2022.
11

[31] Nicolas Papernot and Patrick McDaniel. Deep k-nearest neighbors: Towards conﬁdent, interpretable and robust deep
learning. arXiv preprint arXiv:1803.04765, 2018.
[32] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda
Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In
International Conference on Machine Learning, 2021.
[33] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are
unsupervised multitask learners. OpenAI Blog, 2019.
[34] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.
Zero-shot text-to-image generation. In International Conference on Machine Learning, 2021.
[35] Alexander Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Ré. Snorkel: Rapid
training data creation with weak supervision. In Proceedings of the 44th International Conference on Very Large Data
Bases (VLDB), Rio de Janeiro, Brazil, 2018.
[36] Alexander Ratner, Braden Hancock, Jared Dunnmon, Frederic Sala, Shreyash Pandey, and Christopher Ré. Training
complex models with multi-task weak supervision. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
Jul 2019.
[37] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,
Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition
Challenge. IJCV, 2015.
[38] Esteban Safranchik, Shiying Luo, and Stephen H Bach. Weakly supervised sequence tagging from noisy rules. In
Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, 2020.
[39] Frederic Sala, Paroma Varma, Jason Fries, Daniel Y. Fu, Shiori Sagawa, Saelig Khattar, Ashwini Ramamoorthy,
Ke Xiao, Kayvon Fatahalian, James Priest, and Christopher Ré. Multi-resolution weak supervision for sequential data.
In Advances in Neural Information Processing Systems 32, 2019.
[40] Ying Sheng, Nguyen Ha Vo, James B. Wendt, Sandeep Tata, and Marc Najork. Migrating a privacy-safe information
extraction system to a software 2.0 design. In Proceedings of the 10th Annual Conference on Innovative Data Systems
Research, 2020.
[41] Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. In Advances in neural
information processing systems, pages 4077–4087, 2017.
[42] Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. Reducing wrong labels in distant supervision for relation
extraction. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long
Papers-Volume 1. Association for Computational Linguistics, 2012.
[43] Ruth Urner and Shai Ben-David. Probabilistic lipschitzness a niceness assumption for deterministic labels. In Learning
Faster from Easy Data-Workshop@NIPS, 2013.
[44] Paroma Varma, Frederic Sala, Ann He, Alexander Ratner, and Christopher Re. Learning dependency structures for
weak supervision models. In Proceedings of the 36th International Conference on Machine Learning, 2019.
[45] Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, and Michael Zeng. Want to reduce labeling cost? GPT-3
can help. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 4195–4205, Punta Cana,
Dominican Republic, November 2021. Association for Computational Linguistics.
[46] Eric Zhan, Stephan Zheng, Yisong Yue, Long Sha, and Patrick Lucey. Generating multi-agent trajectories using
programmatic weak supervision. In 7th International Conference on Learning Representations, ICLR, 2019.
[47] Jieyu Zhang, Yue Yu, Yinghao Li, Yujing Wang, Yaming Yang, Mao Yang, and Alexander Ratner. Wrench: A
comprehensive benchmark for weak supervision. In Thirty-ﬁfth Conference on Neural Information Processing Systems
Datasets and Benchmarks Track (Round 2), 2021.
12

Appendix
We present an extended related work (Appendix A), glossary (Appendix B), additional algorithmic details (Appendix C),
proofs (Appendix D), experimental details (Appendix E), and additional experimental results (Appendix F).
A
Extended Related Work
Weak supervision is a broad set of techniques using weak sources of signal to supervise models, such as distant super-
vision [42], co-training methods [5], pattern-based supervision [18] and feature annotation [28, 29]. Weak supervision
frameworks often train in two stages—ﬁrst modeling source accuracies to generate weak labels, and then ﬁne-tuning a
powerful end model for generalization [4, 6, 16, 24, 35, 38, 40, 46]. Our work removes the second stage from the equation
and addresses two common challenges in weak supervision, coarse accuracy modeling and low coverage.
One weak supervision work that does not train in two stages, and models source qualities in a way that can be nonuniform
over the points is WeaSuL [10]. However, this capability is present in a different context: end-to-end training of a weak
supervision label model with an end model. This prevents the use of the label model directly for prediction, as we seek to do
in our work. It requires much heavier computational budget, for example, when training a deep model, which is not needed
with our approach. In addition, WeaSuL relies on the use of an encoder for source qualities, rendering a theoretical analysis
intractable. By contrast, our approach offers clean and easy-to-interpret theoretical guarantees.
Another recent work that utilizes pre-trained embeddings in weak supervision is from [26]. Their work uses the smoothness
of the embedding space to remove low-quality weakly-labeled data points, while we use it to improve coverage and
ﬁne-grained estimation to weakly label additional points more accurately.
Transfer learning uses large datasets to learn useful feature representations that can be ﬁne-tuned for downstream tasks [14,
25]. Transfer learning techniques for text applications typically pre-train on large corpora of unlabeled data [8, 14, 33], while
common applications of transfer learning to computer vision pre-train on both large supervised datasets such as ImageNet [37]
and large unsupervised or weakly-supervised datasets [12, 19, 32]. Pre-trained embeddings have also been used as data
point descriptors for kNN search algorithms to improve model performance, interpretability, and robustness [23, 31]. We
view our work as complementary to these approaches, presenting another mechanism for using pre-trained networks.
Foundation models offer a new interface for the transfer learning setting: when it is impossible to ﬁne-tune the original
models [7]. In this setting, the foundation models can still be used either by direct prompting [8, 27], or by using embed-
dings [30]. [45] prompts FMs to produce pseudolabels, providing a complementary way to use FMs in weak supervision. In
contrast, our work focuses on using FM embeddings. Since we can only access the ﬁnal embeddings of some foundation
models, we focus on adapters [21] over the ﬁnal layer in this work—which are equivalent to linear probes [2].
Semi-supervised and few-shot learning approaches aim to learn good models for downstream tasks given a few labeled
examples. Semi-supervised approaches like label propagation [22] start from a few labeled examples and iteratively ﬁne-tune
representations on progressively larger datasets, while few-shot learning approaches such as meta-learning and metric
learning aim to build networks that can be directly trained with a few labels [41]. Our work is inspired by these approaches
for expanding signal from a subset of the data to the entire dataset using FM representations, but we do not assume that our
labeling sources are perfect, and we do not tune the representation.
B
Glossary
The glossary is given in Table 3 below.
13

Symbol
Used for
x
Input data point x ∈X.
y
True task label y ∈Y = {−1, +1}.
λ
Weak sources λ = {λ1, . . . , λm}, where each λj : X →Y ∪{0} is a probabilistic labeling function
that votes on each x.
m
Number of weak sources.
f
A ﬁxed mapping from input space X to embedding space Z that is made available by the off-the-shelf
foundation model.
ρ
A ﬁxed metric on the embedding space, ρ : Z × Z →R+.
D
A training dataset of n i.i.d. unlabeled points, D = {xi}n
i=1.
n
Number of points in the unlabeled training dataset D.
G
The dependency graph G = (V, E) used to model Pr(y, λ|x), where V = y ∪λ and E contains
edges between y and λ.
Θ(x)
The set of canonical parameters Θ(x) = {θy(x), θi(x), θi,0(x) ∀i ∈[m]} corresponding to
class balance, source accuracy, and the abstain rate used to parametrize Pr(y, λ|x) in (1).
Z
Partition function used for normalizing the distribution of Pr(y, λ|x).
ai(x)
Accuracy parameter of λi on point x, ai(x) = E [λiy|λi ̸= 0, x].
C
Partition of the embedding space Z into nonoverlapping subsets, C = {C1, . . . , Cs}.
s
Size of the partition C.
n′
The number of points from D in each subset Cj, n′ = n
s .
C(x)
The subset that x belongs to, i.e. C(x) = Cj if f(x) ∈Cj.
ai(C(x))
Local accuracy parameter of λi on subset C(x), ai(C(x)) = E [λiy|λi ̸= 0, C(x)].
ˆai(C(x))
Our local accuracy estimate of ai(C(x)) using the triplet method in Algorithm 2.
¯λ
Set of extended weak sources, where each ¯λi is extended from λi using threshold radius ri in (3).
ri
Threshold radius for λi, which determines how much beyond the support of λi to extend votes to.
L(λ)
Generalization error (cross-entropy loss) of the label model, deﬁned as L(λ) = ED,x,y,λ
h
−log ˆ
Pr(y|λ, x)
i
.
Ky, Kλ, Kλ,0
Constants in Deﬁnition 1 corresponding to label, source, and coverage Lipschitzness, respectively.
α
The maximum average inverse source coverage over the subsets, α = maxi Ex
h
1
pij
 pij ̸= 0
i
,
where pij = Pr(λi ̸= 0|f(x) ∈Cj) is the coverage of λi on Cj.
amax
The maximum source accuracy over the subsets, amax = maxi,j ai(Cj).
bmin
The minimum rate of agreement between sources over the subsets,
bmin = mini,j,k{E [λiλj|λi ∧λk ̸= 0, Cj] , ˆE [λiλk|λi ∧λk ̸= 0, Cj]}.
dCj
The diameter of Cj, dCj = maxf(x),f(x′)∈Cj ρ(f(x), f(x′)).
dC
The average subset diameter dC = Ex

dC(x)

.
H(y|λ, x)
Conditional entropy of y given λ, x.
ai
The average accuracy of λi, ai = E [λiy|λi ̸= 0].
¯ai(ri)
The average accuracy of ¯λi on the extended region, ¯ai(ri) = E
¯λiy|¯λi ̸= 0, λi = 0

.
Pλi
The distribution of (x, y) over the support of λi, Pλi = Pr(·|λi ̸= 0).
M
An increasing function M : R+ →[0, 1] used to describe probabilistic Lipschitzness.
βi
λi’s accuracy over an area close to where λi is extended and y changes value,
βi = E [λiy|λi ̸= 0, ∃(x′, y′) : λi(x′) = 0, ρ(f(x), f(x′)) ≤ri, y′ = y].
pi
The proportion of the region where ¯λi is extended, pi = Pr(λi ̸= 0, λi = 0).
p(λ−i)
The label model’s true probability of outputting the correct label in the extension region when
only using λ−i = λ\λi, p(λ−i) = Ey′,λ−i,¯λi̸=0,λi=0 [Pr(y = y′|λ−i, x)].
Table 3: Glossary of variables and symbols used in this paper.
14

C
Additional Algorithmic Details
We describe some properties of the graphical model that justify our algorithm (Section C.1). Then, we formalize the triplet
method algorithm for estimating local accuracy parameters, ˆai(Cj) (Section C.2).
C.1
Properties of the Graphical Model
Lemma 2. For x, y, λ satisfying (1), it holds for any λi that
Pr(y, λi = 0|x) = Pr(y|x) Pr(λi = 0|x).
That is, y ⊥⊥1 {λi = 0} |x.
Proof. Denote λ−i = λ\λi, and equivalently let θ−i and θ−i,0 denote vectors of canonical parameters corresponding to
λ−i in (1). We show independence by proving that Pr(y = 1, λi = 0|x) = Pr(y = 1|x) Pr(λi = 0|x):
Pr(y = 1, λi = 0|x) = 1
Z
X
λ−i
exp
 θy(x) + θi,0(x) + θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0}

(4)
= 1
Z exp(θy(x) + θi,0(x))
X
λ−i
exp
 θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0}

.
Pr(y = 1|x) can be written as Pr(y = 1, λi = 1|x) + Pr(y = 1, λi = −1|x) + Pr(y = 1, λi = 0|x):
Pr(y = 1|x) = 1
Z
X
λ−i

exp(θy(x) + θi(x) + θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0})
(5)
+ exp(θy(x) −θi(x) + θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0})
+ exp(θy(x) + θi,0(x) + θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0})

= 1
Z
X
λ−i
exp(θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0}) exp(θy(x))
 exp(θi(x)) + exp(−θi(x)) + exp(θi,0(x))

.
Pr(λi = 0|x) can be written as Pr(y = 1, λi = 0|x) + Pr(y = −1, λi = 0|x):
Pr(λi = 0|x) = 1
Z
X
λ−i

exp(θy(x) + θi,0(x) + θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0})
(6)
+ exp(−θy(x) + θi,0(x) −θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0})

.
Setting (4) equal to (5) times (6), the term P
λ−i exp(θ−i(x)λ−i + θ−i,0(x)1 {λ−i = 0}) in the former two equations
cancels out. We thus aim to prove the following equality:
Z exp(θy(x) + θi,0(x)) = exp(θy(x))

exp(θi(x)) + exp(−θi(x)) + exp(θi,0(x))

×
(7)
X
λ−i
exp(θ−i,01 {λ−i = 0}) exp(θi,0(x))

exp(θy(x) + θ−i(x)λ−i(x)) + exp(−θy(x) −θ−i(x)λ−i(x))

.
Canceling out exp(θy(x) + θi,0(x)), (7) is equal to
Z =

exp(θi(x)) + exp(−θi(x)) + exp(θi,0(x))

×
X
λ−i
exp(θ−i,01 {λ−i = 0})

exp(θy(x) + θ−i(x)λ−i(x)) + exp(−θy(x) −θ−i(x)λ−i(x))

,
which is true since the RHS iterates over all values of λ−i, y, and λi. We have shown that Pr(y = 1, λi = 0|x) = Pr(y =
1|x) Pr(λi = 0|x) and thus that y ⊥⊥1 {λi = 0} |x for any λi.
15

Due to this independence property, we note that
Pr(λi = 0, λ−i|x) = Pr(λi = 0, λ−i|y = 1, x) Pr(y = 1|x) + Pr(λi = 0, λ−i|y = −1, x) Pr(y = −1|x)
= Pr(λi = 0|x)

Pr(λ−i|y = 1, x) Pr(y = 1|x) + Pr(λ−i|y = −1, x) Pr(y = −1|x)

= Pr(λi = 0|x) Pr(λ−i|x),
and hence
Pr(y|λi = 0, λ−i, x) = Pr(λi = 0|y, x) Pr(λ−i|y, x) Pr(y|x)
Pr(λi = 0, λ−i|x)
= Pr(λi = 0|x) Pr(λ−i|y, x) Pr(y|x)
Pr(λi = 0|x) Pr(λ−i|x)
= Pr(y|λ−i, x).
Lemma 3. For any i ̸= j, if x, λ, y follows (1), then λiy ⊥⊥λjy|λi ∧λj ̸= 0, x.
Proof. Conditioning on the event that λ ̸= 0, we have that
Pr(y, λ|λ ̸= 0, x) = 1
Z0
exp

θy(x)y +
m
X
i=1
θi(x)λiy

(8)
for some partition function Z0 different from Z in (1). This graphical model now follows the structure of the graphical
model in [16] (see their Equation 3). We can thus apply Proposition 1 of their work to get that λiy ⊥⊥λjy|λ ̸= 0, x. From
Lemma 2 and conditional independence of sources, this independence property is equivalent to λiy ⊥⊥λjy|λi ∧λj ̸= 0, x,
as desired.
Lemma 4. If x, λ, y follows (1), then for any λi,
Pr(λi = 1|y = 1, λi ̸= 0, x) = Pr(λi = −1|y = −1, λi ̸= 0, x) = Pr(λiy = 1|λi ̸= 0, x)
(9)
Pr(λi = −1|y = 1, λi ̸= 0, x) = Pr(λi = 1|y = −1, λi ̸= 0, x) = Pr(λiy = −1|λi ̸= 0, x).
(10)
Therefore,
Pr(λi|y, λi ̸= 0, x) = 1 + sgn(λiy)ai(x)
2
.
Proof. Conditioning on the event that λ ̸= 0, the graphical model is of the form in (8) above. This graphical model also
follows the structure of that in [11], and therefore we obtain our desired properties by Lemma 2 of their work.
C.2
Local Accuracy Parameter Estimation Algorithm
We formalize the triplet method used to recover latent source parameters Pr(λi|y, x). First, when we want to evalu-
ate Pr(λi = 1|y, x) or Pr(λi = −1|y, x), this probability can be written as Pr(λi|y, x, λi ̸= 0) Pr(λi ̸= 0|y, x) =
Pr(λiy|x, λi ̸= 0) Pr(λi ̸= 0|x) by Lemmas 2 and 4. We have that E [λiy|x, λi ̸= 0] = Pr(λiy = 1|x, λi ̸= 0)−Pr(λiy =
−1|x, λi ̸= 0) = 2 Pr(λiy = 1|x, λi ̸= 0) −1, so Pr(λi|y, x) = 1+sgn(λiy)ai(x)
2
· Pr(λi ̸= 0|x) when λi ∈{−1, 1}. When
λi is 0, the probability we want to estimate is Pr(λi = 0|y, x) = Pr(λi = 0|x) by Lemma 2.
We now explain how our algorithm estimates ai(x). From Lemma 3, we have that λiy ⊥⊥λjy|λi ∧λj ̸= 0, x for any i, j.
Then, given any set of λi, λj, λk, we have the set of equations
ai(x)aj(x) = E [λiλj|λi ∧λj ̸= 0, x]
ai(x)ak(x) = E [λiλk|λi ∧λk ̸= 0, x]
aj(x)ak(x) = E [λjλk|λj ∧λk ̸= 0, x] .
16

Algorithm 2: Local Accuracy Estimation (Triplet Method)
Input: Dataset D, weak sources ¯λ, partition Cj.
Returns: Estimate of local accuracy ˆai(Cj).
for k, l ∈[m]\i do
Estimate ˆE
¯λi¯λk|¯λi ∧¯λk ̸= 0, Cj

over the set of points {x ∈D : ¯λi(x), ¯λk(x) ̸= 0, f(x) ∈Cj}, and similarly
estimate ˆE
¯λi¯λl|¯λi ∧¯λl ̸= 0, Cj

and ˆE
¯λk¯λl|¯λk ∧¯λl ̸= 0, Cj

.
Compute ˆak,l
i (Cj) =
s
ˆE[¯λi¯λk|¯λi∧¯λk̸=0,Cj]ˆE[¯λi¯λl|¯λi∧¯λl̸=0,Cj]
ˆE[¯λk¯λl|¯λk∧¯λl̸=0,Cj]
.
end for
return ˆai(Cj) as the average over all ˆak,l
i (Cj).
Solving, we get that
|ai(x)| =
s
E [λiλj|λi ∧λj ̸= 0, x] E [λiλk|λi ∧λk ̸= 0, x]
E [λjλk|λj ∧λk ̸= 0, x]
.
This property allows us to recover ai(x) up to a sign. As discussed in Section 3, we use C(x) to estimate the accuracy
parameter over a region of the embedding space, such that in fact we are estimating ai(C(x)) = E [λiy|λi ̸= 0, C(x)] (since
Lemma 3 holds on any x, it holds conditioned over C(x) too). We resolve the sign of the accuracy parameter by assuming
that ai(C(x)) > 0, meaning that the accuracy of a source over a subset is better than random. Finally, rather than estimating
ai(C(x)) using just one pair of λj and λk, we compute the average ai(C(x)) over all other pairs (λj, λk ∈λ\λi) to make
the estimate less noisy. Our approach for computing ˆai(Cj) for any ¯λi and Cj (note that ¯λi and λi are interchangeable in
the above given that (x, y, λ) and (x, y, ¯λ) both satisfy (1)) is described in Algorithm 2.
D
Proofs
We present the proofs for our results in Section 4.
D.1
Proofs for Section 4.1
The proof of Theorem 1 involves decomposing the generalization error into the irreducible error, bias from using C(x), and
variance (sampling error).
Theorem 1. Suppose that data x, y, λ follows the model in (1) and Pr(y|x) and Pr(λi|y, x) for each λi are Lipschitz-
smooth. The generalization error of the label model ˆPr(y|λ, x) in Algorithm 1 when ri = 0 ∀i can be decomposed into
L(λ)=Bias + Variance + Irreducible Error + o(1/n), where
Bias ≤2dC(Ky + mKλ + mKλ,0),
Variance ≤ms
n

3α(1 −b2
min)
8b2
min(1 −a2max)
 1
b4
min
+
2
b2
min

+ 1

,
Irreducible Error = H(y|λ, x),
where H(y|λ, x) denotes conditional entropy.
Proof. We can write the generalization error as
L(λ) = ED,x,y,λ
h
−log ˆPr(y|λ, x)
i
= E
"
−log
ˆPr(y|λ, x)
Pr(y|λ, x)
#
−Ex,y,λ [log Pr(y|λ, x)] .
−Ex,y,λ [Pr(y|λ, x)] is equal to the conditional entropy of y given λ, x, expressed as H(y|λ, x)observing. This describes
the entropy of y after observing the weak labels and input and thus depends on how much signal we are getting from the
17

labelers. Next, we decompose the expected log ratio using our construction of ˆPr(λi|y, C(x)) to get
L(λ) = E
"
−log
Qm
i=1 ˆPr(λi|y, C(x)) Pr(y|C(x))
ˆPr(λ|C(x))
·
Pr(λ|x)
Qm
i=1 Pr(λi|y, x) Pr(y|x)
#
+ H(y|λ, x)
= −E
" m
X
i=1
log
ˆPr(λi|y, C(x))
Pr(λi|y, x)
#
−E
"
log
Pr(λ|x)
ˆPr(λ|C(x))
#
−E

log Pr(y|C(x))
Pr(y|x)

+ H(y|λ, x)
= −E
" m
X
i=1
log
ˆPr(λi|y, C(x))
Pr(λi|y, x)
#
−Ex
h
DKL(Pr(λ|x)|| ˆPr(λ|C(x)))
i
−E

log Pr(y|C(x))
Pr(y|x)

+ H(y|λ, x)
≤
m
X
i=1
Ex,y,λi
"
log
Pr(λi|y, x)
ˆPr(λi|y, C(x))
#
−Ex,y

log Pr(y|C(x))
Pr(y|x)

+ H(y|λ, x),
(11)
where we have used Lemma 2 and the fact that the Kullback-Leibler divergence is always nonnegative in the last line.
For notation, let KLC(x)(y) = Ex [DKL(Pr(y|x)|| Pr(y|C(x)))] = Ex,y
h
log
Pr(y|x)
Pr(y|C(x))
i
, be the KL-divergence between
distributions conditioned on C(x) versus x, which describes the bias we incur from using a partition. Then, L(λ) ≤
Pm
i=1 Ex,y,λi
h
log
Pr(λi|y,x)
ˆ
Pr(λi|y,C(x))
i
+ KLC(x)(y) + H(y|λ, x).
We now simplify the expression E
h
log
Pr(λi|y,x)
ˆ
Pr(λi|y,C(x))
i
based on if λi = 0 or λi ∈{−1, 1}:
E

log
Pr(λi|y, x)
ˆPr(λi|y, C(x))

= Ex
"
Pr(λi = 0|x) log
Pr(λi = 0|x)
ˆPr(λi = 0|C(x))
#
+ Ex,y,λi̸=0
"
Pr(λi ̸= 0|x) log
Pr(λi|y, x)
ˆPr(λi|y, C(x))
#
= Ex
"
Pr(λi = 0|x) log
Pr(λi = 0|x)
ˆPr(λi = 0|C(x))
+ Pr(λi ̸= 0|x) log
Pr(λi ̸= 0|x)
ˆPr(λi ̸= 0|C(x))
#
+ Ex,y,λi̸=0
"
Pr(λi ̸= 0|x) log
Pr(λi|y, x, λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
= Ex
h
DKL(Pr(zi|x)|| ˆPr(zi|C(x)))
i
+ Ex,y,λi̸=0
"
Pr(λi ̸= 0|x) log
Pr(λi|y, x, λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
,
(12)
where zi = 1 {λi = 0} is an indicator variable pertaining to coverage. The ﬁrst KL divergence pertains to estimating the
coverage of λi, while the second pertains to estimating the accuracy parameter of λi. The ﬁrst term in (12) can be written as
Ex[DKL(Pr(zi|x)|| ˆPr(zi|C(x)))] = KLC(x)(zi)
+ Ex
"
Pr(λi = 0|x) log Pr(λi = 0|C(x))
ˆPr(λi = 0|C(x))
+ Pr(λi ̸= 0|x) log Pr(λi ̸= 0|C(x))
ˆPr(λi ̸= 0|C(x))
#
= KLC(x)(zi) + EC(x)
"
Pr(λi = 0|C(x)) log Pr(λi = 0|C(x))
ˆPr(λi = 0|C(x))
+ Pr(λi ̸= 0|C(x)) log Pr(λi ̸= 0|C(x))
ˆPr(λi ̸= 0|C(x))
#
= KLC(x)(zi) + EC(x),zi
"
log Pr(zi|C(x))
ˆPr(zi|C(x))
#
,
The second term in (12) can be written as
E
"
Pr(λi ̸= 0|x) log
Pr(λi|y, x, λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
≤Ex,y,λi̸=0
"
log

Pr(λi|y, x, λi ̸= 0)
Pr(λi|y, C(x), λi ̸= 0) · Pr(λi|y, C(x), λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
= KLC(x)(λi|y, λi ̸= 0) + Ex,y,λi̸=0
"
log Pr(λi|y, C(x), λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
.
18

Putting everything together in (11), the generalization error is at most
L(λ) ≤
m
X
i=1

EC(x),zi
"
log Pr(zi|C(x))
ˆPr(zi|C(x))
#
+ Ex,y,λi̸=0
"
log Pr(λi|y, C(x), λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
+ KLC(x)(zi) + KLC(x)(λi|y, λi ̸= 0)

+ KLC(x)(y) + H(y|λ, x).
We can interpret the generalization error as consisting of bias, variance (and irreducible error) coming from 1) estimating the
coverage of a weak source over a part, and then, conditioned on the support of a source, 2) estimating the accuracy of the
source over a part. The bias is from using C(x) instead of x, and the variance is from estimating over the dataset over these
two steps.
Using Lemmas 5, 6, and 7 we get our desired bound.
Lemma 5. The sampling error term coming from estimating λi’s coverage, EC(x),zi
h
log Pr(zi|C(x))
ˆ
Pr(zi|C(x))
i
, where zi =
1 {λi = 0}, is equal to
EC(x),zi
"
log Pr(zi|C(x))
ˆPr(zi|C(x))
#
= s
n + o(1/n).
Proof. We can write this expectation across each Cj. Denote pij = Pr(λi ̸= 0|Cj) as λi’s coverage on Cj, and equivalently
ˆpij as its estimate over D. Then,
EC(x),zi
"
log Pr(zi|C(x))
ˆPr(zi|C(x))
#
=
s
X
j=1
Pr(f(x) ∈Cj)ED

pij log pij
ˆpij
+ (1 −pij) log 1 −pij
1 −ˆpij

.
(13)
Performing a Taylor approximation of g(x) = log c
x at x = c gives us log c
x ≈log 1 + −1
c(x −c) +
1
2c2 (x −c)2. Setting
x = ˆpij, 1 −ˆpij and c = pij, 1 −pij respectively in (13) and using the fact that ˆpij is an unbiased estimate of pij, this
expression becomes
EC(x),zi
"
log Pr(zi|C(x))
ˆPr(zi|C(x))
#
=
s
X
j=1
Pr(f(x) ∈Cj)
1
pij(1 −pij)E

(pij −ˆpij)2
+ o(1/n)
=
s
X
j=1
Pr(f(x) ∈Cj)
1
pij(1 −pij)Var [ˆpij] + o(1/n),
where we use the fact that the Taylor remainder scales in E

(ˆpi,j −pi,j)3Cj

∼O(1/n2). We can simplify the variance
Var [ˆpi,j] = Var
h
1
n′
P
x:f(x)∈Cj 1 {λi(x) ̸= 0}
i
=
1
(n′)2
P
x:f(x)∈Cj Var [1 {λi(x) ̸= 0}] = pi,j(1−pi,j)
n′
. Putting this all
together, we have
EC(x),zi
"
log Pr(zi|C(x))
ˆPr(zi|C(x))
#
=
s
X
j=1
Pr(f(x) ∈Cj) 1
n′ + o(1/n) = s
n + o(1/n).
Lemma 6. Deﬁne pij = Pr(λi ̸= 0|Cj) as the coverage of the λi on Cj. The sampling error term coming from estimating
source accuracy of λi, Pr(λi|y, C(x), λi ̸= 0), is at most
Ex,y,λi̸=0
"
log Pr(λi|y, C(x), λi ̸= 0)
ˆPr(λi|y, C(x), λi ̸= 0)
#
≤ECj
 1
pij
 pij ̸= 0

· 3s
8n ·
1 −b2
min
b2
min(1 −a2max)
 1
b4
min
+
2
b2
min

+ o(1/n).
19

Proof. Deﬁne Ci ⊆C to be the subsets where λi has non-zero coverage, {C ∈C : ∃x : f(x) ∈C, λi(x) ̸= 0}. When
there are subsets with no λi coverage, we do not estimate the accuracy and can discard them from this bound. We can thus
write the above expectation as E
h
log 1+sgn(λiy)·ai(C(x))
1+sgn(λiy)·ˆai(C(x))
i
= P
Cj∈Ci Pr(f(x) ∈Cj)E
h
log 1+sgn(λiy)·ai(Cj)
1+sgn(λiy)·ˆai(Cj)
Cj
i
. We can
decompose the expectation as
Ex,y,λi̸=0

log 1 + sgn(λiy) · ai(Cj)
1 + sgn(λiy) · ˆai(Cj)
Cj

= E

log 1 + ai(Cj)
1 + ˆai(Cj)
Cj

Pr(λiy=1|Cj, λi ̸= 0)
(14)
+ E

log 1 −ai(Cj)
1 −ˆai(Cj)
Cj

Pr(λiy= −1|Cj, λi ̸= 0).
(15)
Pr(λiy = 1|Cj, λi ̸= 0) is equal to 1+ai(Cj)
2
. (15) becomes
E

log 1 + sgn(λiy) · ai(Cj)
1 + sgn(λiy) · ˆai(Cj)
Cj

=1
2

(1 + ai(Cj))E

log 1 + ai(Cj)
1 + ˆai(Cj)
Cj

+ (1 −ai(Cj))E

log 1 −ai(Cj)
1 −ˆai(Cj)
Cj
 
.
(16)
Again, we can perform a Taylor expansion on g(x) = log 1+c
1+x at x = c to get that log 1+c
1+x ≈−
1
1+c(x−c)+
1
2(1+c)2 (x−c)2,
and therefore E
h
log 1+ai(Cj)
1+ˆai(Cj)
Cj
i
= E[ai(Cj)−ˆai(Cj)]
1+ai(Cj)
+
E[( ˆ
ai(Cj)−ai(Cj))2]
2(1+ai(Cj))2
+ o(1/n), (see Lemma 4 of [11] for bounding
the Taylor remainder). Similarly, we have that E
h
log 1−ai(Cj)
1−ˆai(Cj)
Cj
i
= E[ˆai(Cj)−ai(Cj)]
1−ai(Cj)
+
E[(ˆai(Cj)−ai(Cj))2]
2(1−ai(Cj))2
+ o(1/n).
Therefore, (16) becomes
E

log 1 + sgn(λiy) · ai(Cj)
1 + sgn(λiy) · ˆai(Cj)
Cj

= 1
2

E [ai(Cj) −ˆai(Cj)] + E

(ˆai(Cj) −ai(Cj))2
2(1 + ai(Cj))
+ E [ˆai(Cj) −ai(Cj)] + E

(ˆai(Cj) −ai(Cj))2
2(1 −ai(Cj))

+ o(1/n)
= 1
2 · E

(ˆai(Cj) −ai(Cj))2
1 −ai(Cj)2
+ o(1/n).
The value of E

(ˆai(Cj) −ai(Cj))2
has been studied in previous works that use the triplet method of [16]. In particular,
we use Lemma 6 of [11] to get that
E

(ˆai(Cj) −ai(Cj))2
≤
3s
4pi,jn · 1 −b2
min
b2
min
 1
b4
min
+
2
b2
min

.
Therefore, the overall expression can be bounded by
E

log 1 + sgn(λiy) · ai(C(x))
1 + sgn(λiy) · ˆai(C(x))

≤
X
Cj∈Ci
Pr(f(x) ∈Cj)
1
2(1 −a2max) ·
3s
4pi,jn · 1 −b2
min
b2
min
 1
b4
min
+
2
b2
min

+ o
 1
n

≤ECj
 1
pij
 pij ̸= 0

· 3s
8n ·
1 −b2
min
b2
min(1 −a2max)
 1
b4
min
+
2
b2
min

+ o
 1
n

.
Lemma 7. Denote zi = 1 {λi = 0} and KLC(x)(·) = Ex [DKL(Pr(·|x), Pr(·|C(x)))]. The bias terms from conditioning
on C(x) rather than x are at most
KLC(x)(y) ≤2KydC
KLC(x)(λi|y, λi ̸= 0) ≤2mKλdC
KLC(x)(zi) ≤2mKλ,0dC.
20

Proof. We can write the expected KL-divergence between the distribution of the true label y conditioned on C(x) versus x
as
KLC(x)(y) = Ex [DKL(Pr(y|x)|| Pr(y|C(x)))] =
s
X
j=1
Pr(f(x) ∈Cj)
Z
Pr(x|Cj)DKL(Pr(y|x, Cj)|| Pr(y|Cj))dx.
(17)
This inner KL-divergence is on two Bernoulli distributions. Deﬁne py,j = Pr(y = 1|Cj), and denote py,x,j = Pr(y =
1|x, Cj). Then, DKL(Pr(y|x, Cj)|| Pr(y|Cj)) = py,x,j log py,x,j
py,j + (1 −py,x,j) log 1−py,x,j
1−py,j .
Next, recall that Pr(y|x) is Ky-Lipschitz in the embedding space; that is, | Pr(y = 1|x)−Pr(y = 1|x′)| ≤Kyρ(f(x), f(x′)).
Since py,j is Pr(y|x) averaged over Cj, it holds that |py,x,j −py,j| ≤Kydj, where dj is the diameter of Cj. We then have
that py,x,j ≤Kydj + py,j, and since |(1 −py,x,j) −(1 −py,j)| ≤Kydj, we also have that 1 −py,x,j ≤1 −py,j + Kydj.
Therefore, the KL-divergence is bounded by
DKL(Pr(y|x, Cj)|| Pr(y|Cj)) ≤py,x,j log Kydj + py,j
py,j
+ (1 −py,x,j) log Kydj + (1 −py,j)
1 −py,j
≤py,x,j · Kydj
py,j
+ (1 −py,x,j) ·
Kydj
1 −py,j
,
where we use the fact that log(1 + x) ≤x. Plugging this back into (17),
Ex [DKL(Pr(y|x)|| Pr(y|C(x)))] ≤
s
X
j=1
Pr(f(x) ∈Cj)
Z
Pr(x|Cj))

py,x,j · Kydj
py,j
+ (1 −py,x,j) ·
Kydj
1 −py,j

dx
=
s
X
j=1
Pr(f(x) ∈Cj)
Z
Pr(x, y = 1|Cj) · Kydj
py,j
+ Pr(x, y = −1|Cj) ·
Kydj
1 −py,j
dx
=
s
X
j=1
Pr(f(x) ∈Cj)

Pr(y = 1|Cj) · Kydj
py,j
+ Pr(y = −1|Cj) ·
Kydj
1 −py,j

=
s
X
j=1
Pr(f(x) ∈Cj) · 2Kydj = 2KydC.
Next, we bound KLC(x)(λi|y, λi ̸= 0). Using the same approach, we have that KLC(x)(λi|y, λi ̸= 0) ≤2KλdC. We also
have that KLC(x)(zi) ≤2Kλ,0dC.
D.2
Proofs for Section 4.2
Lemma 8. When we use ¯λ instead of λ, the bias term in L(¯λ) is at most
Bias ≤2dCKy + 2m(dC + 2 max
i
ri)(Kλ + Kλ,0).
Proof. The term Ex [DKL(Pr(y|x)|| Pr(y|C(x))] in the bias is unchanged since the distribution of y given x is not impacted
by λ. We next look at Ex,y,¯λi̸=0

DKL(Pr(¯λi|y, x, ¯λi ̸= 0)|| Pr(¯λi|y, C(x), ¯λi ̸= 0))

. Using the approach in Lemma 7,
recall that Pr(¯λi|y, x, ¯λi ̸= 0) = Pr(λi(x)|y, x, λi(x) ̸= 0) when λi(x) ̸= 0, and Pr(λi(NN(x))|y, NN(x), λi(NN(x)) ̸=
0) when λi(x) = 0. Therefore, by Assumption 1, | Pr(¯λi = 1|y, ¯λi ̸= 0, x) −Pr(¯λi = 1|y, λi ̸= 0, x′)| ≤Kλ max{
ρ(f(NN(x)), f(NN(x′))), ρ(f(x), f(NN(x′))), ρ(f(NN(x)), f(x′)), ρ(f(x), f(x′))}. The greatest possible distance in
embedding space between NN(x) and NN(x′) when f(x), f(x′) ∈Cj under our method of source extension is dj + 2ri.
We can thus view the extensions as changing the diameter of the subset in Lemma 7. The rest of the approach remains
unchanged, so we get that
Ex,y,¯λi̸=0

DKL(Pr(¯λi|y, x, ¯λi ̸= 0)|| Pr(¯λi|y, C(x), ¯λi ̸= 0))

≤2Kλ(dC + 2ri).
We consider Ex [DKL(Pr(λi ̸= 0|x)|| Pr(λi ̸= 0|C(x)))]. Similarly, Pr(¯λi(x) ̸= 0|x) is either Pr(λi(x) ̸= 0|x) or
Pr(λi(NN(x)) ̸= 0|NN(x)) depending on the region x is in. Therefore,
Ex [DKL(Pr(λi ̸= 0|x)|| Pr(λi ̸= 0|C(x)))] ≤2Kλ,0(dC + 2ri),
and we obtain the desired bound.
21

Lemma 1. Suppose Pλi is M-probabilistically Lipschitz. The average accuracy of ¯λi on the extended region is at least
¯ai(ri) ≥ai −(1 + βi)M(ri).
Proof. We ﬁrst introduce some notation. Deﬁne S = {x ∈X : λi(x) ̸= 0} as the support of λi, and ˆS = S ∩D as the set
of points in D that λi has coverage on. In particular, ˆS consists of points sampled from Pλi, and suppose that | ˆS| = n0.
Deﬁne the extended region as ˆSri = {x ∈X\S : ∃x′ ∈ˆS s.t. ρ(f(x), f(x′)) ≤ri}, and let the distribution of x over this
support be P ˆS,r = Pr(x|x ∈ˆSri). With slight abuse of notation, we also use P ˆS,ri to refer to the joint distribution over x, y
with x from P ˆS,r. We also use ˆSri to refer to the support ˆSri × Y.
Deﬁne the expected error ε = E ˆS∼Pn0
λi
h
Prx,y∼P ˆ
S,ri(¯λi ̸= y|x, ¯λi(x) ̸= 0)
i
= E ˆS∼Pn0
λi
h
Prx,y∼P ˆ
S,ri(¯λi ̸= y|x)
i
. Let ˆS
also be written as a set of n0 random variables {x1, . . . , xn0}. Denote NN ˆS(x) = argminx′∈ˆS ρ(f(x), f(x′)) to be x’s
nearest neighbor in ˆS (in the body, this is just referred to as NN(x)), so ¯λi(x) := λi(NN ˆS(x)) for x ∈ˆSri. Then, we
decompose ε based on which point in ˆS is x’s nearest neighbor:
ε =
Pr
ˆS∼Pn0
λi
x,y∼P ˆ
S,ri
(λi(NN ˆS(x)) ̸= y|x) =
n0
X
j=1
Pr
ˆS∼Pn0
λi ,
x∼P ˆ
S,ri
(NN ˆS(x) = xj) · Pr
ˆS∼Pn0
λi
x,y,∼P ˆ
S,ri
(λi(xj) ̸= y|NN ˆS(x) = xj).
(18)
Let yj denote the label corresponding to xj, drawn from Pλi(·|xj). The probability Pr ˆS∼Pn0
λi ,x,y,∼P ˆ
S,ri(λi(xj) ̸=
y|NN ˆS(x) = xj) can be further decomposed into two cases: when λ(xj) = yj, yj ̸= y and when λ(xj) ̸= yj, yj = y. That
is,
Pr
ˆS∼Pn0
λi
x,y,∼P ˆ
S,ri
(λi(xj) ̸= y|NN ˆS(x) = xj)
(19)
= Pr
ˆS∼Pn0
λi
x,y∼P ˆ
S,ri,
yj∼Pλi(·|xj)
(λi(xj) = yj, yj ̸= y|NN ˆS(x) = xj) + Pr
ˆS∼Pn0
λi
x,y∼P ˆ
S,ri,
yj∼Pλi(·|xj)
(λi(xj) ̸= yj, yj = y|NN ˆS(x) = xj)
≤Pr
ˆS∼Pn0
λi ,
yj∼Pλi(·|xj)
(λi(xj) = yj, ∃(x, y) ∈ˆSri : NN ˆS(x) = xj, yj ̸= y) + Pr
ˆS∼Pn0
λi ,
yj∼Pλi(·|xj)
(λi(xj) ̸= yj, ∃(x, y) ∈ˆSri : NN ˆS(x) = xj, yj = y).
Next, we recall the deﬁnition of ˆSri and observe that NN ˆS(x) = xj implies that ρ(f(x), f(x′)) ≤ri. These allow us to
write the probability only over one (xj, yj) ∼Pλi rather than ˆS, and so the expression in (19) satisﬁes
Pr
ˆS∼Pn0
λi
x,y,∼P ˆ
S,ri
(λi(xj) ̸= y|NN ˆS(x) = xj) ≤
Pr
xj,yj∼Pλi
(λi(xj) = yj, ∃(x, y) ∈X\S : ρ(f(xj), f(x)) ≤ri, yj ̸= y)
+
Pr
xj,yj∼Pλi
(λi(xj) ̸= yj, ∃(x, y) ∈X\S : ρ(f(xj), f(x)) ≤ri, yj = y).
The ﬁrst probability on the RHS can be written as Prxj,yj∼Pλi(λi(xj) = yj|∃(x, y) ∈X\S : ρ(f(xj), f(x)) ≤
ri, yj ̸= y) Prxj,yj∼Pλi(∃(x, y) ∈X\S : ρ(f(xj), f(x)) ≤ri, yj ̸= y) ≤
1+βi
2
M(ri), and the second one is
at most Prxj,yj∼Pλi(λi(xj) ̸= yj) =
1−ai
2 . Therefore, putting this back into (18), ε ≤
1+βi
2
M(ri) + 1−ai
2 . Since
¯ai(ri) = 2(1 −ε) −1, we now have our desired bound
¯ai(ri) ≥ai −(1 + βi)M(ri).
Theorem 2. Suppose that data follows the model in (1). The irreducible error decreases by at least the following amount
when using ¯λi rather than λi in Algorithm 1:
H(y|λ, x) −H(y|¯λ, x) ≥2pi(1 −p(λ−i))2 · ¯ai(ri)2.
22

We aim to lower bound H(y|λ, x) −H(y|¯λ, x) where only λi is extended to be ¯λi with threshold radius ri.
H(y|λ, x) −H(y|¯λ, x) = Ex,y,λ [−log Pr(y|λ, x)] + Ex,y,¯λ

log Pr(y|¯λ, x)

= Ex,y,λ−i

E¯λi

log Pr(¯λi|x, y) Pr(λ−i|x, y) Pr(y|x)
Pr(¯λi, λ−i|x)
x, y

−Eλi

log Pr(λi|x, y) Pr(λ−i|x, y) Pr(y|x)
Pr(λi, λ−i|x)
x, y

.
(20)
Pr(λ−i|x, y) and Pr(y|x) are the same when using ¯λi versus λi, so (20) becomes
H(y|λ, x) −H(y|¯λ, x) = Ex,y,λ−i

E¯λi

log
Pr(¯λi|x, y)
Pr(¯λi, λ−i|x)
x, y

−Eλi

log
Pr(λi|x, y)
Pr(λi, λ−i|x)
x, y

.
(21)
When extending λi, there are three regions of interest in input space: λi(x), ¯λi(x) ̸= 0; λi(x) = 0, ¯λi(x) ̸= 0; and
λi(x) = ¯λi(x) = 0. In the ﬁrst region, ¯λi has the exact same behavior as λi since λi has coverage over this region.
Therefore, conditioning on λi(x) ̸= 0, the expectation on the RHS of (21) is equal to 0. Similarly, in the third region where
λi(x) = ¯λi(x) = 0, the extended and original labeler vote exactly the same, so the expectation on the RHS of (21) is again
equal to 0. The primary region of interest are the points that previously had no signal from λi but now have signal from ¯λi.
Then, (21) becomes
H(y|λ, x) −H(y|¯λ, x) = piEy,λ−i,¯λi(x)̸=0,λi(x)=0

log
Pr(¯λi|x, y)
Pr(¯λi, λ−i|x) −log
Pr(λi = 0|x, y)
Pr(λi = 0, λ−i|x)

.
(22)
We can write
Pr(λi=0|x,y)
Pr(λi=0,λ−i|x) =
Pr(λi=0|x)
Pr(λi=0|x) Pr(λ−i|x) =
1
Pr(λ−i|x) by decomposing the denominator conditional on y and
using Lemma 2. Using the chain rule on Pr(¯λi, λ−i|x) = Pr(¯λi|λ−i, x) Pr(λ−i|x), (22) is now
H(y|λ, x) −H(y|¯λ, x) = piEy,λ−i,¯λi(x)̸=0,λi(x)=0

log
Pr(¯λi|x, y)
Pr(¯λi|λ−i, x)

.
To analyze this expectation, we ﬁrst look at the case where y = 1. Then,
Ey=1,λ−i,¯λi(x)̸=0,λi(x)=0

log
Pr(¯λi|x, y)
Pr(¯λi|λ−i, x)

=
(23)
E

Pr(¯λi = 1|y = 1, x, ¯λi ̸= 0) log Pr(¯λi = 1|x, y = 1)
Pr(¯λi = 1|λ−i, x) + Pr(¯λi = −1|y = 1, x, ¯λi ̸= 0) log Pr(¯λi = −1|x, y = 1)
Pr(¯λi = −1|λ−i, x)

.
Denote αi(x) = Pr(¯λi = 1|y = 1, x, ¯λi ̸= 0) as the probability corresponding to ¯λi’s accuracy parameter. In addition, note
that we can write
Pr(¯λi = 1|λ−i, x) = Pr(¯λi = 1|λ−i, x, y = 1) Pr(y = 1|λ−i, x) + Pr(¯λi = 1|λ−i, x, y = −1) Pr(y = −1|λ−i, x)
= αi(x)p(x, λ−i) + (1 −αi(x))(1 −p(x, λ−i)),
where p(x, λ−i) is shorthand for Pr(y = 1|λ−i, x) (importantly, it does not depend on ¯λi) and likewise for Pr(¯λi =
−1|λ−i, x) = αi(x)(1 −p(x, λ−i)) + (1 −αi(x))p(x, λ−i). Our expression from (23) is now
Ey=1,λ−i,¯λi(x)̸=0,λi(x)=0

αi(x) log
αi(x)
αi(x)p(x, λ−i) + (1 −αi(x))(1 −p(x, λ−i))
(24)
+ (1 −αi(x)) log
1 −αi(x)
αi(x)(1 −p(x, λ−i)) + (1 −αi(x))p(x, λ−i)

.
Note that the expression inside the expectation is convex in both αi(x) and p(x, λ−i). Deﬁne
αi,1 = Ey=1,¯λi(x)̸=0,λi(x)=0 [αi(x)]
pλ−i,1 = Ey′=1,λ−i,¯λi(x)̸=0,λi(x)=0 [Pr(y = y′|x, λ−i)] .
23

αi,1 is the expected accuracy probability over the extended region when y = 1, and pλ−i,1 is the expected label model
performance using just λ−i over the extended region when y = 1. Then, this expression from (24) is at least
αi,1 log
αi,1
αi,1pλ−i,1 + (1 −αi,1)(1 −pλ−i,1)
(25)
+ (1 −αi,1) log
1 −αi,1
αi,1(1 −pλ−i,1) + (1 −αi,1)pλ−i,1
.
We look at the case where y = −1. Similarly, we get
Ey=−1,λ−i,¯λi(x)̸=0,λi(x)=0

αi(x) log
αi(x)
αi(x)(1 −p(x, λ−i)) + (1 −αi(x))p(x, λ−i)
(26)
+ (1 −αi(x)) log
1 −αi(x)
αi(x)p(x, λ−i) + (1 −αi(x))(1 −p(x, λ−i))

.
Again, deﬁne αi,−1 = Ey=−1,¯λi(x)̸=0,λi(x)=0 [αi(x)] and pλ−i,−1 = Ey′=−1,λ−i,¯λi(x)̸=0,λi(x)=0 [Pr(y = y′|x, λ−i)], and
by Jensen’s inequality we have that (26) is at least
αi,−1 log
αi,−1
αi,−1pλ−i,−1 + (1 −αi,−1)(1 −pλ−i,−1)
(27)
+ (1 −αi,−1) log
1 −αi,−1
αi,−1(1 −pλ−i,−1) + (1 −αi,−1)pλ−i,−1
.
Therefore, Ey,λ−i,¯λi(x)̸=0,λi(x)=0
h
log
Pr(¯λi|x,y)
Pr(¯λi|λ−i,x)
i
is lower bounded by the weighted sum of Pr(y = 1|λ−i, ¯λi(x) ̸=
0, λi(x) = 0) times (25) and Pr(y = −1|λ−i, ¯λi(x) ̸= 0, λi(x) = 0) times (27). Since (25) and (27) are convex in
αi,1, pλ−i,1 and αi,−1, pλ−i,1 respectively, we can deﬁne αi = Pr(y = 1|λ−i, ¯λi(x) ̸= 0, λi(x) = 0) · αi,1 + Pr(y =
−1|λ−i, ¯λi(x) ̸= 0, λi(x) = 0) · αi,−1 = E¯λi(x)̸=0,λi(x)=0 [αi(x)] as a notion of ¯λi’s accuracy in the region where we
extend λi. We also deﬁne pλ−i = Pr(y = 1|λ−i, ¯λi(x) ̸= 0, λi(x) = 0) · pλ−i,1 + Pr(y = −1|λ−i, ¯λi(x) ̸= 0, λi(x) =
0) · pλ−i,−1 = Ey′,λ−i,¯λi(x)̸=0,λi(x)=0 [Pr(y = y′|λ−i, x] as the label model’s probability of outputting the correct label in
our region of interest when relying on only λ−i. Then, we have that
H(y|λ, x) −H(y|¯λ, x) ≥pi

αi log
αi
αipλ−i + (1 −αi)(1 −pλ−i)
+ (1 −αi) log
1 −αi
(1 −αi)pλ−i + αi(1 −pλ−i)

.
We can lower bound the expression in the parentheses. Deﬁne g(x) = x log
x
xp+(1−x)p + (1 −x) log
1−x
(1−x)p+x(1−p) for
some constant p. We claim that g(x) ≥h(x) = 8(1 −p)2(x −0.5)2 for x ∈[0, 1]. Note that g(0.5) = h(0.5) = 0.
To show that g(x) ≥h(x), it sufﬁces to show that g′(x) > h′(x) for x > 0.5, and g′(x) < h′(x) for x < 0.5.
g′(x) =
1−p
xp+(1−x)(1−p) +
p−1
x(1−p)+(1−x)p +log
x
xp+(1−x)(1−p) −log
1−x
(1−x)p+x(1−p), and h′(x) = 16(1−p)2(x−0.5). Again,
note that g′(0.5) = h′(0.5) = 0, so we want to show that g′′(x) > h′′(x) for all x ∈[0, 1]. g′′(x) = −
(1−p)(2p−1)
(xp+(1−x)(1−p))2 −
(p−1)(1−2p)
(x(1−p)+(1−x)p)2 +
1−p
x(xp+(1−x)(1−p)) +
1−p
(1−x)(x(1−p)+(1−x)p), and h′′(x) = 16(1−p)2. It is easy to check that g′′(x) obtains
a minimum at x = 0.5. We compute that g′′(0.5) = 16(1 −p)2, which demonstrates that g(x) ≥8(1 −p)2(x −0.5)2. We
thus get
H(y|λ, x) −H(y|¯λ, x) ≥8pi(1 −pλ−i)2
αi −1
2
2
.
We know that αi = 1+¯ai(ri)
2
, so our ﬁnal bound is
H(y|λ, x) −H(y|¯λ, x) ≥8pi(1 −pλ−i)2 · ¯ai(ri)2
4
= 2pi(1 −pλ−i)2 · ¯ai(ri)2.
E
Experimental Details
We describe additional details about each task, including details about data sources (Section E.1), supervision sources
(Section E.2), and setting extension thresholds (Section E.3).
24

Task (Embedding)
T
m/T
Prop
Ntrain
Ndev
Ntest
Spam
1
10
0.49
1,586
120
250
Weather
1
103
0.53
187
50
50
Spouse
1
9
0.07
22,254
2,811
2,701
Basketball
8
4
0.12
3,594
212
244
Commercial
3
4
0.32
64,130
9,479
7,496
Tennis
9
6
0.34
6,959
746
1,098
Table 4: Details for each dataset. T: the number of related elements modeled by the weak supervision label model. m/T:
the number of supervision sources per element. Prop: The proportion of positive examples in each dataset. Ntrain: The size
of the unlabeled training set. Ndev: The size of the labeled dev set. Ntest: The size of the held-out test set.
E.1
Dataset Details
Table 4 provides details on train/dev/test splits for each dataset, as well as statistics about the positive class proportion and
the number of labeling functions. Additional details about each dataset are provided below.
Spam
We use the dataset as provided by Snorkel2 and those train/dev/test splits.
Weather, Spouse
These datasets are used in [35] and [16] for evaluation, and we use the train/dev/test splits from those
works (Weather is called Crowd in that work).
Basketball
This dataset is a subset of ActivityNet and was used for evaluation in [39] and [16]. We use the train/dev/test
splits from those works.
Commercial
We use the dataset from [17, 20] and [16] and the train/dev/test splits from those works.
Tennis
We use the dataset from [16] and the train/dev/test splits from those works.
E.2
Supervision Sources
Supervision sources are expressed as short Python functions. Each source relied on different information to assign noisy
labels:
Spam, Weather, Spouse
For these tasks, we used the same supervision sources as used in previous work [16, 35]. These
are all text classiﬁcation tasks, so they rely on text-based heuristics such as the presence or absence of certain words, or
particular regex patterns.
Basketball, Commercial, Tennis
Again, we use sources from previous work [16, 39]. For Basketball, these sources rely
on an off-the-shelf object detector to detect balls or people, and use heuristics based on the average pixel of the detected ball
or distance between the ball and person to determine whether the sport being played is basketball or not. For Commercial,
there is a strong signal for the presence or absence of commercials in pixel histograms and the text; in particular, commercials
are book-ended on either side by sequences of black frames, and commercial segments tend to have mixed-case or missing
transcripts (whereas news segments are in all caps). For Tennis, we use an off-the-shelf pose detector to provide primitives
for the weak supervision sources. The supervision sources are heuristics based on the number of people on court and their
positions. Additional supervision sources use color histograms of the frames (i.e., how green the frame is, or whether there
are enough white pixels for the court markings to be shown).
E.3
Setting ri and s
We tune ri using the dev set in two steps. First, we set all the ri to the same value r and use grid search over r. Then, we
perform a series of small per-coordinate searches for a subset of the labeling functions to optimize individual ri values. For
labeling functions with full coverage, we set the threshold to have no extensions.
2https://www.snorkel.org/use-cases/01-spam-tutorial
25

Tuning s is done independently from ri. Once we have the best performing ri values, we search for the best possible s from
one to ten. We obtain the partition by performing K-means clustering with K = s.
Now we report thresholds in terms of cosine similarities (note that this is a different presentation than in terms of distances).
For Spam, all thresholds are set to 0.844, except for weak sources 1, 2, and 7, which have thresholds 0.864, 0.854 and
0.804 respectively. The best s is 2. For Weather, all thresholds are set to 0.2, and the best s is 3. For Spouse, all thresholds
are set to 0.9275, except for weak sources 2 and 3, which have thresholds 0.8385 and 0.9. The best s is 8. For Basketball,
thresholds are set to [0.42, 0.97, 0.52, 0.42] and s is set to 2. For Commercial, thresholds are set to [.6, .35, .35, .65] and s
is set to 3. For Tennis, thresholds are set to [0.11, 0.110.11, 0.85, 0.11, 0.11] and s is set to 2.
In our experimentss, class balance Pr(y|Cj) is estimated from the dev set.
E.4
Adapters
We describe adapter experimental details in the main results. For each dataset, we train single-layer adapters with gradient
descent. Because this requires training labels, we consider two training setups: (1) splitting the validation set into a new 80%
training set and 20% held-out validation set, and (2) using weak-supervision methods (WS-LM) combined with labeling
functions to generate pseudolabels for the training data.
For both, we train adapters using the OpenAI GPT-3 Ada embeddings for NLP tasks and OpenAI CLIP embeddings for
video tasks.. We train with 50 epochs and early stopping, and sweep over the following hyperparameters: learning rate
∈{1e −3, 1e −2, 1e −1}, weight decay ∈{5e −4, 0}, momentum ∈{0, 0.9}.
The best performing model (based on held-out validation set accuracy for Spam and Weather datasets, held-out validation
F1-score for all other datasets), was then evaluated on the test set.
For the linear models, the best hyperparameters are as follows: for Spam, we use 1e −1 learning rate, 5e −4 weight decay,
and 0.9 momentum. For Weather, we use 1e −1 learning rate, 5e −4 weight decay, and 0.9 momentum. For Spouse, we
use 1e −2 learning rate, 5e −4 weight decay, and 0 momentum. For Basketball, we use 1e −3 learning rate, 0 weight
decay, and 0.9 momentum. For Commercial, we use 1e −1 learning rate, 5e −4 weight decay, and 0 momentum. For
Tennis, we use 1e −1 learning rate, 5e −4 weight decay, and 0 momentum.
For the MLPs, the best hyperparameters are as follows: for Spam, we use 0.1 learning rate, 0 weight decay, 0.9 momentum,
and 512 hidden layer dimension. For Weather, we use 1e −1 learning rate, 5e −4 weight decay, 0.9 momentum, and 256
hidden layer dimension. For Spouse, we use 1e −3 learning rate, 0 weight decay, 0 momentum, and 256 hidden layer
dimension. For Basketball, we use 1e −2 learning rate, 0 weight decay, 0.9 momentum, and 512 hidden layer dimension.
For Commercial, we use 1e −1 learning rate, 5e −4 weight decay, 0.9 momentum, and 512 hidden layer dimension. For
Tennis, we use 1e −2 learning rate, 5e −4 weight decay, 0.9 momentum, and 256 hidden layer dimension.
LIGER-Adapter
In addition to evaluating LIGER on its own against linear adapters, we also demonstrate further boosts
when combining the LIGER predictions with Adapters. For this approach, we ﬁrst create training sets by combining the
80% split of the original validation set and the original training set. To get labels, we use the ground-truth labels for the
former, and the LIGER predictions on the training set for the latter. To get data inputs, we tune between using the same data
embeddings as in the original datasets, and optionally concatenating the LIGER predictions as an additional input dimension
to the embeddings. In the setup, for validation and test sets, we also concatenate the LIGER predictions to the embeddings.
For the Spouse dataset, we do this concatenation, as we found it to improve the validation set F1-score. For all others,
we use the original embeddings. When the weak labels are not very accurate (< 75% accuracy on dev), we downsample
the train points (otherwise they would degrade performance from ground-truth dev labels). This allows performance on
Basketball to be strong even though LIGER accuracy is relatively low.
We tune hyperparameters in the same way as the other adapters. The best hyperparameters are as follows: for Spam, we
use 0.1 learning rate, 0 weight decay, 0.9 momentum. For Weather, we use 0.1 learning rate, 5e −4 weight decay, 0.9
momentum. For Spouse, we use 1e −3 learning rate, 5e −4 weight decay, 0.9 momentum. For Basketball, we use 10.1
learning rate, 5e −4 weight decay, 0 momentum. For Commercial, we use 0.1 learning rate, 0 weight decay, 0.9. For
Tennis, we use 1e −1 learning rate, 5e −4 weight decay, 0 momentum.
F
Additional Experimental Results
F.1
MLP Adapters
We also evaluated adapters using 3-layer MLPs as alternatives to the linear adapters. We considered MLPs with 512 or 256
dimensional hidden-layers with the ReLU nonlinear activation function. We report the results in Table 5. Performance is
26

Task
LIGER (s)
Spam
96.8 (2)
Weather
95.3 (3)
Spouse
17.0 (6)
Basketball
81.7 (2)
Commercial
93.4 (3)
Tennis
83.4 (1)
Table 5: MLP Adapter performance. Scores are in F1, except for Spam and Weather (accuracy).
Embedding
F1-score
Raw pixel
19.3
RN-101
31.1
BiT-M
42.5
CLIP
69.6
5
10
15
0
5
10
15
N-nth Nearest Points
Smoother
5
6
7
8
9
82
86
90
% Points with Changed Value
N-nth Nearest Points
5
10
6
8
7
9
20
40
60
N-nth Nearest Points
Coverage Lipschitzness
Local Label PL
Label Lipschitzness
Raw Pixels
ResNet-101
BiT-M
CLIP
Prompting
F1-score
No Prompt
48.5
Prompt at Beginning
50.2
Prompt at End
52.2
Smoother
0.002
0.006
75
85
95
Cosine Distance Radius
0.002
0.006
0
20
40
% Points with Changed Value
Cosine Distance Radius
0.002
0.006
5
10
15
Cosine Distance Radius
Coverage Lipschitzness
Local Label PL
Label Lipschitzness
No Prompt
Prompt at Beginning
Prompt at End
Figure 3: Top: LIGER performance and smoothness measurements of CLIP, BiT-M, ResNet-101, and raw pixels as
embeddings for Basketball. Bottom: LIGER performance and smoothness measurements of no prompting, prompting at
beginning, and prompting at end in GPT-3 for Spouse.
similar to the linear adapters, but the MLP adapters are slightly more expensive to train. We focus on a simple linear probe
for LIGER-Adapter and the main experiments for simplicity.
F.2
Additional Measures of Smoothness
Figure 3 reports two additional measurements of smoothness on Basketball and Spouse—coverage Lipschitzness and local
label probabilistic Lipschitzness (see Section 4 for the formal deﬁnitions). Trends match label Lipschitzness.
To measure label Lipschitzness, the property that | Pr(y = 1|x) −Pr(y = 1|x′)| ≤Kyρ(f(x), f(x′)), we observe that
| Pr(y = 1|x) −Pr(y = 1|x′)| = |E [1 {y = 1|x} −E [1 {y = 1|x′}]]
≤E [|1 {y = 1|x} −1 {y = 1|x′} |]
= E [1 {y ̸= y′}] = Pr(y ̸= y′)
by Jensen’s inequality. Therefore, we estimate Pr(y = y′) on data as an upper bound on label Lipschitzness. We do this by
computing the average percentage of points in some local region (deﬁned either by a radius or by nearest neighbors) around
a given point where the label is different from that of the given point.
For source Lipschitzness, the sources in practice are unimodal and hence Kλ = 0.
For coverage Lipschitzness, we note that | Pr(λi ̸= 0|x) −Pr(λi ̸= 0|x′)| ≤Pr(1 {λi(x) ̸= 0}! = 1 {λi(x) ̸= 0}), so we
estimate this probability on data as an upper bound. This is done by computing the average percentage of points that abstain
in some local region around a point that has coverage, and vice versa. We average over all sources.
Finally, for local label probabilistic Lipschitzness, we follow Deﬁnition 2. For each point in the support of λi, we search if
there exists a nearby point within radius r (or k-th nearest neighbor) such that this nearby point is not in the support and has
27

1
2
3
4
5
6
7
8
s
0.25
0.30
0.35
0.40
0.45
0.50
Generalization error
Bias-variance tradeoff depending on number of partitions
Figure 4: The bias-variance tradeoff in the generalization error based on s, the number of partitions used in our approach.
When too few partitions are used, the accuracy estimates are not ﬁne-grained and do not sufﬁciently approximate the true
conditional distribution Pr(y, λ|x), resulting in large bias. When too many partitions are used, the variance increases due to
sampling error on individual partitions.
a label differerent from that of the given point. We compute the percentage of points in the support that satisfy this property.
We average over all sources.
To read Ky, Kλ,0, M from Figure 3, they can each be viewed as the slope of the linear function that upper bounds the
smoothness curve. Note that for the curves that appear ﬂat (i.e. no prompt), these constants are very large, as there is an
initial sharp increase in the percentage of points with changed value.
F.3
Synthetic Experiments
We evaluate LIGER on synthetic data to conﬁrm our insights about 1) how generalization error for ˆPr(y|λ, x) demonstrates
a bias-variance tradeoff depending on the number of partitions, and 2) how additional lift depends on setting the threshold
radius based on the original weak source’s accuracy and the embedding’s probabilistic Lipschitzness.
First, we conduct a synthetic experiment to understand how the number of partitions s controls the bias-variance tradeoff in
generalization error of ˆPr(y|λ, x) (Theorem 1. We generate two sets of canonical parameters and use them in (1) to generate
(y, λ) from two different distributions, P1 and P2 over an embedding space. We generate 1000 points each for P1 and P2 to
form datasets D1 and D2, which are then concatenated to form a dataset D of 2000 points. We ﬁrst run Algorithm 1 with
s = 1, which means that we estimate only one set of parameters over D despite the dataset consisting of two different
conditional distributions. We then set s = 2 and estimate the parameters of P1 and P2 separately over 1000 points each.
Finally, we set s = 4 and s = 8 by dividing each of D1 and D2 into 2 subsets of 500 points and 4 subsets of 250 points,
respectively. For each of these, we compute the average cross-entropy loss (over s) of our label model. Figure 4 plots how the
generalization error changes with the number of partitions s. We plot the mean and 95% conﬁdence interval over ten random
initializations of canonical parameters and datasets drawn according to them. It demonstrates a bias-variance tradeoff: when
s = 1, we estimate one set of parameters over the entire dataset rather than the two true sets of parameters, and this approach
hence does not capture the distinctions in input space among the source accuracies. As a result, a low s results in high bias,
contributing to large generalization error. On the other hand, when s = 4 or 8, our approach is correctly estimating D1 and
D2 separately but is using much less data to do so. This approach has higher sampling error, which worsens variance and
contributes to large generalization error.
Next, we conduct a synthetic experiment to understand how setting the threshold radius of the extended weak source
controls improvement in generalization error as a function of the original average source accuracy and the probabilistic
Lipschitzness of the FM embedding (Theorem 2). Suppose for simplicity that s = 1 and that Pr(y, λ) is modeled the same
way as Pr(y, λ|x) in (1). This assumption reduces to previous weak supervision settings but allows us to isolate the effect of
extending a source. We create an embedding space over 10000 uniformly sampled points in [0, 1]2 with a ﬁxed class balance
Pr(y) and m = 3 labeling functions, where only λ1 is extended. To understand the impact of a labeling function’s accuracy,
we ﬁx a task distribution by assigning Y labels in a 10 × 10 “checkerboard” pattern and run our algorithm on four versions
of λ1 with varying average accuracies, keeping λ1’s support consistent. In Figure 5 (left), we extend λ1 based on r for each
of the four versions of the labeling function. This conﬁrms that extending a highly accurate labeling function results in
greater generalization lift. To understand the impact of Lipschitzness of the task distribution, we produce four distributions
of Y over the embedding space, three of which follow a checkerboard clustering pattern (such that more divisions mean less
smoothness), and one that spatially distributes the values of Y at random. For both experiments, we run our approach with
28

0.00
0.02
0.04
0.06
0.08
r
0.29
0.30
0.31
0.32
0.33
0.34
Generalization Error
Vary LF Accuracy
LF Acc: 0.89
LF Acc: 0.74
LF Acc: 0.63
LF Acc: 0.51
0.00
0.02
0.04
0.06
0.08
r
Vary Smoothness
10x10
15x15
20x20
Random
Figure 5: Reduction in generalization error from extending labeling functions of varying accuracies (left), and on embedding
spaces of varying smoothness (right). LF refers to a weak source’s labeling function.
threshold radius varying from 0 to 0.1 in increments of 0.005. In Figure 5 (right), each curve represents performance of the
same high average accuracy labeling function (a1 = 0.89) over embeddings of varying Lipschitzness. This conﬁrms that the
greatest improvement due to an extension occurs for the smoothest embedding. Lastly, both of these graphs illustrate the
tradeoff in setting a threshold radius, conﬁrming the theoretical insight that this quantity must be chosen carefully to ensure
lift from using ¯λ1 over λ1.
29

