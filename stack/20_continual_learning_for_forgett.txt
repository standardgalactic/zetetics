Continual Learning for Forgetting in Deep Generative Models
Alvin Heng 1 Harold Soh 1 2
Abstract
The recent proliferation of large-scale text-to-
image models has led to growing concerns that
such models may be misused to generate harm-
ful, misleading, and inappropriate content. Mo-
tivated by this issue, we derive a technique in-
spired by continual learning to selectively forget
concepts in pretrained text-to-image generative
models. Our method enables controllable for-
getting, where a user can specify how a concept
should be forgotten. We apply our method to the
open-source Stable Diffusion model and focus
on tackling the problem of deepfakes, where ex-
periments show that the model effectively forgets
the depictions of various celebrities. This paper
is a short version of our work containing more
comprehensive experiments, which is available at
https://arxiv.org/abs/2305.10120.
1. Introduction
Deep generative models have made remarkable progress in
recent years, particularly in the area of text-to-image gen-
eration. However, these models also have the potential for
misuse, as they can be used to create realistic but harmful
content, such as Deepfakes or inappropriate images involv-
ing real individuals. A common approach to address this
issue is to remove specific concepts or individuals from the
training dataset. However, filtering datasets of billions of
images is challenging, and it requires retraining the entire
model whenever a new concept needs to be forgotten. In this
work, our objective is to develop a framework that allows for
selective forgetting of specific concepts in pretrained text-
to-image models, without requiring access to the original
training process.
Our key insight is that selective forgetting can be framed
from the perspective of continual learning. Traditionally,
1School of Computing, National University of Singapore (NUS)
2Smart Systems Institute, NUS. Correspondence to: Alvin Heng
<alvin.heng@u.nus.edu>.
Workshop on Challenges in Deployable Generative AI at Inter-
national Conference on Machine Learning (ICML), Honolulu,
Hawaii, USA. 2023. Copyright 2023 by the author(s).
continual learning focuses on preventing forgetting; given
parameters for task A, we would like to train the model to
perform task B without forgetting task A, i.e., θA  θA,B.
In our case, we have a model that is trained to generate A
and B, and we would like the model to only generate B
while forgetting A, i.e., θA,B  θB.
In this work, we present a unified objective function based
on well-established methods in continual learning that en-
ables models to forget. Unlike previous approaches, our
method allows for controllable forgetting, where the forgot-
ten concept can be replaced with a user-defined concept.
Our framework is general and applies to any likelihood-
based generative model. In this short paper, we focus our
investigations on the open-source text-to-image model Sta-
ble Diffusion (SD). Specifically, we tackle the problem of
deepfakes and impersonations by training SD to forget the
depiction of famous celebrities. Our experiments show that
our method is able to forget celebrities by effectively substi-
tuting them with a variety of target concepts that are chosen
by the user.
2. Background and Related Works
Conditional Diffusion Models.
Diffusion models (Ho
et al., 2020) are a class of variational generative models
that sample from a distribution through an iterative Markov
denoising process. A sample xT is typically sampled from
a Gaussian distribution and gradually denoised for T time
steps, finally recovering a clean sample x0. In practice, the
model is trained to predict the noise ϵ(xt, t, c|θ) that must be
removed from the sample xt with the following reweighted
variational bound: ELBO(x|θ, c) = PT
t=1 ||ϵ(xt, t, c|θ) −
ϵ||2, where xt = √¯αtx0 + √1 −¯αtϵ for ϵ ∼N(0, I), ¯αt
are constants related to the noise schedule in the forward
noising process. Sampling from a conditional diffusion
model can be carried out using classifier-free guidance (Ho
& Salimans, 2022).
2.1. Continual Learning
Continual learning focuses on sequentially learning tasks
in deep neural networks while preventing catastrophic for-
getting. In our work, we utilize two popular approaches:
Elastic Weight Consolidation (EWC) and Generative Replay
(GR).
1

Continual Learning for Forgetting in Deep Generative Models
Elastic Weight Consolidation.
EWC (Kirkpatrick et al.,
2017) uses a Bayesian approach to model the posterior
of weights for two tasks, DA and DB, given a model
θ∗trained on DA.
The posterior over DA is approxi-
mated using the Laplace approximation, resulting in a
quadratic penalty that slows down learning of weights
relevant to the initial task.
The posterior is defined as
log p(θ|DA, DB) = log p(DB|θ) −λ P
i
Fi
2 (θi −θ∗
i )2,
where F is the Fisher information matrix (FIM) and λ is a
weighting parameter. In practice, a diagonal approximation
Fi = Ep(D|θ∗)[( ∂
∂θi log p(D|θ))2] is used for computational
efficiency. Fi measures the sensitivity of weight θi on the
model’s output. For diffusion models, we modify Fi to
measure the sensitivity of θi on the Evidence Lower Bound
(ELBO): Fi = Ep(x|θ∗,c)p(c)[( ∂
∂θi ELBO(x|θ, c))2].
Generative Replay.
GR (Shin et al., 2017) utilizes a gen-
erative model to generate data from previous tasks, which is
then used to augment the current task’s data during training
of a discriminative model. This approach enables training on
all tasks simultaneously without storing previous datasets,
preventing catastrophic forgetting.
Our work combines EWC and GR to train a model that
sequentially forgets concepts. This differs from traditional
continual learning objectives, which aim to prevent forget-
ting. Furthermore, prior work on continual learning for
generative models primarily focuses on GANs (Seff et al.,
2017; Lesort et al., 2019), whereas our work focuses on
likelihood models, which includes diffusion models.
2.2. Concept Erasure
Large-scale text-to-image (Rombach et al., 2022; Saharia
et al., 2022; Ramesh et al., 2022) models can generate bi-
ased, unsafe, and inappropriate content. To address this,
Safe Latent Diffusion (SLD) (Schramowski et al., 2022)
proposes an inference scheme to guide latent codes away
from specific concepts, while Erasing Stable Diffusion
(ESD) (Gandikota et al., 2023) introduces a training scheme
for concept erasure. Both methods leverage energy-based
composition specific to the classifier-free guidance mech-
anism (Ho & Salimans, 2022) of diffusion models, and
does not allow for controlled erasure via selective remap-
ping of concepts.
Closest to our method is concurrent
work (Kumari et al., 2023), which ablates concepts in Sta-
ble Diffusion through remapping to a user-defined anchor
concept via simple KL-divergence minimization. In con-
trast to this work and the other above approaches, our
method is derived from a Bayesian continual learning frame-
work. Rather than being specific to Stable Diffusion, our
methodology is general in that it can be applied to a variety
of conditional generative models (see our main paper at
https://arxiv.org/abs/2305.10120).
3. Method
Problem Statement.
We have a dataset D consisting of
two parts: Df (data to forget) and Dr (data to remem-
ber). The dataset follows a joint distribution p(x, c) =
p(x|c)p(c), where x is the input data and c is the con-
cept. The distribution over concepts is denoted as p(c) =
P
i∈f,r ϕipi(c) where P
i∈f,r ϕi = 1. The two concept
distributions are disjoint such that pf(cr) = 0 where
cr ∼pr(c) and vice-versa. For ease of notation, we sub-
script distributions and concepts interchangeably, e.g., pf(c)
and p(cf).
We assume a trained conditional generative model θ∗, ob-
tained by maximizing the likelihood of D. Our goal is to
train the model to forget generating Df|cf, while retaining
the ability to generate Dr|cr. The training process should
not rely on access to D, so as to accommodate scenarios
where only the model is available, without knowledge of its
training set.
A Bayesian Continual Learning Approach to Forgetting.
We start from a Bayesian perspective of continual learning
inspired by the derivation of Elastic Weight Consolidation
(EWC) (Kirkpatrick et al., 2017):
log p(θ|Df, Dr) = log p(Df|θ) + log p(θ|Dr) + C. (1)
For forgetting, we are interested in the posterior conditioned
only on Dr,
log p(θ|Dr) = −log p(xf|θ, cf)−λ
X
i
Fi
2 (θi −θ∗
i )2 +C
(2)
where we use log p(Df|θ)
=
log p(xf, cf|θ)
=
log p(xf|θ, cf) + log p(cf) so that the conditional likeli-
hood is explicit, and substitute log p(θ|Df, Dr) with the
Laplace approximation of EWC. Our goal is to maximize
log p(θ|Dr) to obtain a maximum a posteriori (MAP) esti-
mate. Intuitively, maximizing Eq. (2) lowers the likelihood
log p(xf|θ, cf), while keeping θ close to θ∗.
Unfortunately, direct optimization is hampered by two key
issues. First, the optimization objective of Eq. 2 does not
involve using samples from Dr. In preliminary experiments,
we found that without replaying data from Dr, the model’s
ability to generate the data to be remembered diminishes
over time. Second, we focus on diffusion models, where
the log-likelihood is intractable. We have the ELBO, but
minimizing a lower bound does necessarily decrease the log-
likelihood. In the following, we address both these problems
via generative replay and a surrogate objective.
3.1. Generative Replay Over Dr
Our approach is to unify the two paradigms of continual
learning, EWC and GR, such that they can be optimized
2

Continual Learning for Forgetting in Deep Generative Models
Figure 1: Qualitative results of our method applied to forgetting famous persons. Within each column, the leftmost image
represents SD v1.4 samples, the middle image represents our method with q(x|cf) set to "middle aged man/woman" and
the rightmost image is our method with q(x|cf) set to "male/female clown". [...] is substituted with either "Brad Pitt" or
"Angelina Jolie".
under a single objective. We introduce an extra likelihood
term over Dr that corresponds to a generative replay term,
while keeping the optimization over the posterior of Dr
unchanged:
log p(θ|Dr) = 1
2
h
−log p(xf|θ, cf)−λ
X
i
Fi
2 (θi−θ∗
i )2
+ log p(xr|θ, cr) + log p(θ)
i
+C.
(3)
A complete derivation is given in appendix A.1. The term
log p(θ) corresponds to a prior over the parameters θ. Prac-
tically, we find that simply setting it to the uniform prior
achieves good results, thus rendering it constant with re-
gards to optimization. With the expectations written down
explicitly, our objective becomes
L = −Ep(x|c)pf (c) [log p(x|θ, c)] −λ
X
i
Fi
2 (θi −θ∗
i )2
+ Ep(x|c)pr(c) [log p(x|θ, c)] .
(4)
As we focus on Stable Diffusion in this work, the expec-
tations over p(x|c)pf(c) and p(x|c)pr(c) can be approxi-
mated by using conditional samples generated by the model
prior to training. Similarly, the FIM is calculated using sam-
ples from the model. Thus, Eq. 4 can be optimized without
the original training dataset D. Empirically, we observe that
the addition of the GR term improves performance when
generating Dr after training to forget Df.
3.2. Surrogate Objective
Similar
to
Eq.
2,
Eq.
4
suggests
that
we
need
to minimize the log-likelihood of the data to forget
Ex,c∼p(x|c)pf (c) [log p(x|θ, c)]. With diffusion models, we
only have access to the lower bound of the log-likelihood,
but we found empirically that naively optimizing Eq. 4 by
replacing the likelihood terms with the standard ELBOs
leads to poor results.
We propose an alternative objective that is guaranteed to
lower the log-likelihood of Df, as compared to the orig-
inal model parameterized by θ∗. Rather than attempting
to directly minimize the log-likelihood or the ELBO, we
maximize the log-likelihood of a surrogate distribution of
the class to forget, q(x|cf) ̸= p(x|cf). We formalize this
idea in the following theorem.
Theorem
1.
Consider
a
surrogate
distribution
q(x|c) such that q(x|cf)
̸=
p(x|cf).
Assume
we have access to the MLE optimum for the full
dataset
θ∗
=
arg maxθ Ep(x,c) [log p(x|θ, c)] such
that Ep(c) [DKL(p(x|c)||p(x|θ∗, c)]
=
0.
Define
the
MLE
optimum
over
the
surrogate
dataset
as
θq
=
arg maxθ Eq(x|c)pf (c) [log p(x|θ, c)].
Then the
following inequality involving the expectations of the
optimal models over the data to forget holds:
Ep(x|c)pf (c) [log p(x|θq, c)] ≤Ep(x|c)pf (c) [log p(x|θ∗, c)] .
Theorem 1 tells us that optimizing the surrogate objective
arg maxθ Eq(x|c)pf (c) [log p(x|θ, c)] is guaranteed to re-
duce Ep(x|c)pf (c) [log p(x|θ, c)], the problematic first term
of Eq. 4, from its original starting point θ∗.
Putting the above elements together, our objective is given
by
L ≥Eq(x|c)pf (c) [ELBO(x|θ, c)] −λ
X
i
Fi
2 (θi −θ∗
i )2
+ Ep(x|c)pr(c) [ELBO(x|θ, c)]
(5)
where we replace likelihood terms with their respective
evidence lower bounds. For diffusion models, maximizing
the ELBO increases the likelihood.
3

Continual Learning for Forgetting in Deep Generative Models
Figure 2: Comparisons between our method with ESD and SLD in forgetting Angelina Jolie. We use the variant with
q(x|cf) set to “middle aged woman”. Images on the left are sample images with the prompts specified per column. Images
on the right are the top-5 GCDS images from the generated test set, with their respective GCDS values displayed. Intuitively,
these are the images with the 5 highest probabilities that the GCD network classifies as Angelina Jolie.
4. Experiments
In this section, we apply our method to the forgetting of
famous persons in Stable Diffusion. We leverage the fact
that with language conditioning, we can select q(x|cf) to be
appropriate substitutes of the concept to forget. For instance,
we attempt to forget the celebrities Brad Pitt and Angelina
Jolie, thus we set cf = {“brad pitt"} and cf={“angelina
jolie"} and represent q(x|cf) with images generated from
SD v1.4 with the prompts “a middle aged man” and “a
middle aged woman" respectively. This means we train
the model to generate pictures of ordinary, unidentifiable
persons when it is conditioned on text containing “brad pitt"
or “angelina jolie".
To demonstrate the control and versatility of our method,
we conduct a second set of experiments where we map the
celebrities to clowns, by setting q(x|cf) to images of “male
clown" or “female clown" generated by SD v1.41. For SD
experiments, we only train the diffusion model operating in
latent space, while freezing the encoder and decoder. Our
qualitative results are shown in Fig. 1, where we see that the
results generalize well to a variety of prompts, generating
realistic images of regular people and clowns in various
settings.
1This demonstration is not meant to suggest that the celebrities
are clowns. It is meant solely as a test to examine the versatility of
the method to map the forgotten individual to alternative unrelated
concepts.
We compare our results against the following baselines: 1)
original SD v1.4, 2) SLD Medium (Schramowski et al.,
2022) and 3) ESD-x (Gandikota et al., 2023), training only
the cross-attention layers. We generate 20 images each of
50 random prompts containing “Brad Pitt” and “Angelina
Jolie” and evaluate using the open-source GIPHY Celebrity
Detector (GCD) (Hasty et al., 2019). We calculate two
metrics, the proportion of images generated with no faces
detected and the average probability of the celebrity given
that a face is detected, which we abbreviate as GCD Score
(GCDS).
Our method generates the most images with faces, with sig-
nificantly lower GCDS compared to SD v1.4 (Table 1). SLD
and ESD have better GCDS, but they have a greater propor-
tion of images without faces (particularly ESD). Looking
at the qualitative samples in Fig. 2, ESD sometimes gener-
ates faceless and semantically unrelated images due to its
uncontrollable training process. Additionally, it is worth
noting that SLD produces distorted and low-quality faces,
potentially explaining its lower GCDS. Visual inspection
of the top-5 images in terms of GCDS shows that, despite
the high scores, the images generated by our method would
not be mistaken for Angelina Jolie, and not more so than
the other two methods. We provide a similar figure for Brad
Pitt in Fig. 3.
4

Continual Learning for Forgetting in Deep Generative Models
Figure 3: Comparisons between our method with ESD and SLD in forgetting Brad Pitt. We use our method with q(x|cf) set
to "middle-aged man". Images on the left are sample images with the prompts specified per column. Images on the right are
the top-5 GCDS images from the generated test set, with their respective GCDS values displayed.
Table 1: Quantitative results from the GIPHY Celebrity Detector. For our method, we use the variant with q(x|cf) set to
“middle aged man" or “middle aged woman" for forgetting Brad Pitt and Angelina Jolie respectively. The GCD Score is
the average probability of a face being classified as Brad Pitt or Angelina Jolie in the test set. The numbers in brackets are
standard deviations. Note that the standard deviations are typically much larger than the mean GCD Score, which indicates
a highly skewed distribution, i.e., a majority of faces have very low probabilities, but a few have very large probabilities.
Forget Brad Pitt
Forget Angelina Jolie
Proportion of images
without faces (↓)
GCD Score (↓)
Proportion of images
without faces (↓)
GCD Score (↓)
SD v1.4 (original)
0.104
0.606 (0.424)
0.117
0.738 (0.454)
SLD Medium
0.141
0.00474 (0.0354)
0.119
0.0329 (0.129)
ESD-x
0.347
0.0201 (0.109)
0.326
0.0335 (0.153)
Ours
0.058
0.0752 (0.193)
0.0440
0.0774 (0.213)
5. Conclusions, Limitations and Future Works
This paper presents a continual learning approach for con-
trolled forgetting in Stable Diffusion. We propose a unified
training loss that combines the EWC and GR approaches,
allowing targeted forgetting of specific concepts. Our ap-
proach enables users to remap the concept to be forgotten,
resulting in semantically relevant images with the target
concept erased.
A limitation is that computing the FIM for diffusion models
can be slow as it involves a sum over T timesteps per sample;
more efficient ways to compute the FIM can be explored.
In terms of broader impacts, our method carries the risk of
inappropriate or malicious alteration of concepts, such as
erasing historical events. It is crucial for the community to
use tools like ours responsibly to enhance generative models,
rather than cause further harm.
Acknowledgements
This research/project is supported by the National Research
Foundation Singapore and DSO National Laboratories under
the AI Singapore Programme (AISG Award No: AISG2-
RP-2020-017).
5

Continual Learning for Forgetting in Deep Generative Models
References
Gandikota, R., Materzynska, J., Fiotto-Kaufman, J., and
Bau, D. Erasing concepts from diffusion models. arXiv
preprint arXiv:2303.07345, 2023.
Hasty, N., Kroosh, I., Voitekh, D., and Korduban,
D., 2019.
URL https://github.com/Giphy/
celeb-detection-oss.
Ho, J. and Salimans, T. Classifier-free diffusion guidance.
arXiv preprint arXiv:2207.12598, 2022.
Ho, J., Jain, A., and Abbeel, P. Denoising diffusion proba-
bilistic models. Advances in Neural Information Process-
ing Systems, 33:6840–6851, 2020.
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Des-
jardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T.,
Grabska-Barwinska, A., et al. Overcoming catastrophic
forgetting in neural networks. Proceedings of the national
academy of sciences, 114(13):3521–3526, 2017.
Kumari, N., Zhang, B., Wang, S.-Y., Shechtman, E., Zhang,
R., and Zhu, J.-Y. Ablating concepts in text-to-image dif-
fusion models. arXiv preprint arXiv:2303.13516, 2023.
Lesort, T., Caselles-Dupré, H., Garcia-Ortiz, M., Stoian,
A., and Filliat, D. Generative models from the perspec-
tive of continual learning. In 2019 International Joint
Conference on Neural Networks (IJCNN), pp. 1–8. IEEE,
2019.
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen,
M. Hierarchical text-conditional image generation with
clip latents. arXiv preprint arXiv:2204.06125, 2022.
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and
Ommer, B. High-resolution image synthesis with latent
diffusion models. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pp.
10684–10695, 2022.
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton,
E. L., Ghasemipour, K., Gontijo Lopes, R., Karagol Ayan,
B., Salimans, T., et al. Photorealistic text-to-image dif-
fusion models with deep language understanding. Ad-
vances in Neural Information Processing Systems, 35:
36479–36494, 2022.
Schramowski, P., Brack, M., Deiseroth, B., and Kerst-
ing, K.
Safe latent diffusion: Mitigating inappropri-
ate degeneration in diffusion models.
arXiv preprint
arXiv:2211.05105, 2022.
Seff, A., Beatson, A., Suo, D., and Liu, H.
Continual
learning in generative adversarial nets. arXiv preprint
arXiv:1705.08395, 2017.
Shin, H., Lee, J. K., Kim, J., and Kim, J. Continual learning
with deep generative replay. Advances in neural informa-
tion processing systems, 30, 2017.
6

Continual Learning for Forgetting in Deep Generative Models
A. Proofs
A.1. Generative Replay Objective
Our Bayesian posterior over the set to remember is given by Eq. 2:
log p(θ|Dr) = −log p(xf|θ, cf) + log p(θ|Df, Dr) + C.
(6)
Let us introduce an extra likelihood term over Dr on both sides as follows
log p(θ|Dr) + log p(Dr|θ) = −log p(xf|θ, cf) + log p(θ|Df, Dr) + log p(Dr|θ) + C
(7)
The terms on the left hand side of the equation can be simplified using Bayes rule
log p(θ|Dr) + log p(Dr|θ) = log p(θ|Dr) + log p(θ|Dr) + log p(Dr) −log p(θ)
= 2 log p(θ|Dr) −log p(θ) + C
We substitute this new form back to Eq. 7 and simplify to obtain
log p(θ|Dr) = 1
2 [−log p(xf|θ, cf) + log p(θ|Dr, Df) + log p(Dr|θ) + log p(θ)] + C
(8)
= 1
2 [−log p(xf|θ, cf) + log p(θ|Dr, Df) + log p(xr|θ, cr) + log p(θ)] + C
(9)
which gives us Eq. 3.
A.2. Proof of Theorem 1
Before we prove Theorem 1, we first prove two related lemmas.
Let us first formalize the original conditional MLE objective as a KL divergence minimization:
Lemma 1. Given a labeled dataset p(x, c) and a conditional likelihood model p(x|θ, c) parameterized by θ, the MLE
objective arg maxθ Ep(x,c) log p(x|θ, c) is equivalent to minimizing Ep(c) [DKL(p(x|c)||p(x|θ, c)].
Proof.
arg max
θ
Ep(x|c)p(c) [log p(x|θ, c)]
= arg max
θ
Z
p(x|c)p(c) [log p(x|θ, c) −log p(x|c)] dxdc +
Z
p(x|c)p(c) log p(x|c)dxdc
= arg max
θ
−
Z
p(c)DKL(p((x|c)||p(x|θ, c))dc −
Z
p(c)H(p(x|c))dc
= arg min
θ
Ep(c)DKL(p((x|c)||p(x|θ, c))
where in the last line we use the fact that the entropy term independent of θ.
Lemma 1 is an obvious generalization of the equivalence of MLE and KL divergence minimization to the conditional case.
We assume the asymptoptic limit where the model, represented by a neural network with parameters θ∗, is sufficiently
expressive such that the MLE training on the full dataset results in Ep(c) [DKL(p(x|c)||p(x|θ∗, c)] = 0; in other words, the
model has learnt the underlying data distribution exactly. Under this assumption, it straightforward to show that the model
also learns the forgetting data distribution exactly, Epf (c) [DKL(p(x|c)||p(x|θ∗, c)] = 0.
Lemma 2. Assume that the global optimum θ∗exists such that by Lemma 1, Ep(c) [DKL(p(x|c)||p(x|θ∗, c)] = 0. The class
distribution is defined as p(c) = ϕfpf(c) + ϕrpr(c), where ϕf, ϕr > 0 and ϕf + ϕr = 1. Then the model parameterized
by θ∗also exactly reproduces the conditional likelihood of the class to forget:
Epf (c) [DKL(p(x|c)||p(x|θ∗, c)] = 0.
7

Continual Learning for Forgetting in Deep Generative Models
Proof.
0 = Ep(c) [DKL(p(x|c)||p(x|θ∗, c)]
=
Z
(ϕfpf(c) + ϕrpr(c))DKL(p(x|c)||p(x|θ∗, c)dc
= ϕf
Z
pf(c)DKL(p(x|c)||p(x|θ∗, c))dc + ϕr
Z
pr(c)DKL(p(x|c)||p(x|θ∗, c))dc
= ϕfEpf (c) [DKL(p(x|c)||p(x|θ∗, c))] + ϕrEpr(c) [DKL(p(x|c)||p(x|θ∗, c))]
Since ϕf, ϕr > 0 and DKL(·||·) ≥0 by definition, then for the sum of two KL divergence terms to equal 0, it must mean
that each individual KL divergence is 0, i.e., Epf (c) [DKL(p(x|c)||p(x|θ∗, c)] = 0.
Finally, we are now able to prove Theorem 1. We restate the theorem and then provide its proof.
Theorem 1. Consider a surrogate distribution q(x|c) such that q(x|cf) ̸= p(x|cf). Assume we have access to the MLE
optimum for the full dataset θ∗= arg maxθ Ep(x,c) [log p(x|θ, c)] such that Ep(c) [DKL(p(x|c)||p(x|θ∗, c)] = 0. Define
the MLE optimum over the surrogate dataset as θq = arg maxθ Eq(x|c)pf (c) [log p(x|θ, c)]. Then the following inequality
involving the expectations of the optimal models over the data to forget holds:
Ep(x|c)pf (c) [log p(x|θq, c)] ≤Ep(x|c)pf (c) [log p(x|θ∗, c)] .
Proof.
Ex,c∼p(x|c)pf (c) [log p(x|θq, c)] −Ex,c∼p(x|c)pf (c) [log p(x|θ∗, c)]
=
Z
p(x|c)pf(c) log p(x|θq, c)dxdc −
Z
p(x|c)pf(c) log p(x|θ∗, c)dxdc
= Epf (c)
Z
p(x|c) log p(x|θq, c)
p(x|θ∗, c)dx

= Epf (c)
Z
p(x|c) log p(x|c)p(x|θq, c)
p(x|c)p(x|θ∗, c)dx

= Epf (c)
Z
p(x|c) log
p(x|c)
p(x|θ∗, c)dx

−Epf (c)
Z
p(x|c) log
p(x|c)
p(x|θq, c)dx

= Epf (c) [DKL(p(x|c)||p(x|θ∗, c))] −Epf (c) [DKL(p(x|c)||p(x|θq, c))]
= −Epf (c) [DKL(p(x|c)||p(x|θq, c))]
(apply Lemma 2)
≤0
(non-negativity of KL)
8

