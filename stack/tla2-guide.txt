TLA+ Version 2
A Preliminary Guide
Leslie Lamport
11 December 2018

Contents
1
Introduction
1
2
Recursive Operator Deﬁnitions
1
3
Lambda Expressions
3
4
Theorems and Assumptions
4
4.1
Naming
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
4.2
assume/prove . . . . . . . . . . . . . . . . . . . . . . . . . .
4
5
Instantiation
6
5.1
Instantiating *ﬁx Operators . . . . . . . . . . . . . . . . . . .
7
5.2
Leibniz Operators and Instantiation
. . . . . . . . . . . . . .
7
6
Naming Subexpressions
8
6.1
Labels and Labeled Subexpression Names . . . . . . . . . . .
9
6.2
Positional Subexpression Names
. . . . . . . . . . . . . . . .
12
6.3
Subexpressions of let Deﬁnitions . . . . . . . . . . . . . . . .
15
6.4
Subexpressions of an assume/prove . . . . . . . . . . . . . .
15
6.5
Using Subexpression Names as Operators
. . . . . . . . . . .
16
7
The Proof Syntax
16
7.1
The structure of a proof . . . . . . . . . . . . . . . . . . . . .
16
7.2
use, hide, and by
. . . . . . . . . . . . . . . . . . . . . . . .
19
7.2.1
use and hide . . . . . . . . . . . . . . . . . . . . . . .
19
7.2.2
by . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
7.2.3
obvious and omitted
. . . . . . . . . . . . . . . . .
22
7.3
The Current State
. . . . . . . . . . . . . . . . . . . . . . . .
22
7.4
Steps That Take Proofs
. . . . . . . . . . . . . . . . . . . . .
23
7.4.1
Formulas and assume/prove . . . . . . . . . . . . . .
23
7.4.2
case . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
7.4.3
@ Steps . . . . . . . . . . . . . . . . . . . . . . . . . .
24
7.4.4
suffices
. . . . . . . . . . . . . . . . . . . . . . . . .
25
7.4.5
pick . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
7.4.6
qed . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
7.5
Steps That Do Not Take Proofs . . . . . . . . . . . . . . . . .
27
7.5.1
Deﬁnitions
. . . . . . . . . . . . . . . . . . . . . . . .
27
7.5.2
instance . . . . . . . . . . . . . . . . . . . . . . . . .
27
7.5.3
use and hide . . . . . . . . . . . . . . . . . . . . . . .
27

7.5.4
have . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
7.5.5
take . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
7.5.6
witness . . . . . . . . . . . . . . . . . . . . . . . . . .
29
7.6
Referring to Steps and Their Parts . . . . . . . . . . . . . . .
30
7.6.1
Naming Subexpressions
. . . . . . . . . . . . . . . . .
30
7.6.2
Naming Facts . . . . . . . . . . . . . . . . . . . . . . .
31
7.6.3
Naming Deﬁnitions . . . . . . . . . . . . . . . . . . . .
32
7.7
Referring to Instantiated Theorems . . . . . . . . . . . . . . .
32
7.8
Temporal Proofs
. . . . . . . . . . . . . . . . . . . . . . . . .
33
8
The Semantics of Proofs
34
8.1
The Meaning of Boolean Operators . . . . . . . . . . . . . . .
34
8.2
The Meaning of assume/prove
. . . . . . . . . . . . . . . .
34
8.3
Temporal Proofs
. . . . . . . . . . . . . . . . . . . . . . . . .
35
2

1
Introduction
The original version of the TLA+ language was released at the beginning
of the millennium and described in the book Specifying Systems, published
in 2002. The current version, released around 2006, is Version 2. It is the
version supported by the latest versions of the TLA+ tools and described
in documentation written since then, including the video course and the
hyperbook. TLA+ now means TLA+ Version 2. In this document, it is
called TLA+2 for short. The original version of TLA+ is here called TLA+1.
This document explains the diﬀerences between TLA+2 and TLA+1.
Most of the additions to the language in TLA+2 are for writing proofs
that can be checked with TLAPS, the TLA+ proof system.
The major
change that aﬀects speciﬁcations is that you can now write recursive operator
deﬁnitions, as described in Section 2. Another change is the introduction of
lambda expressions, explained in Section 3.
Almost all legal TLA+1 speciﬁcations are legal TLA+2 speciﬁcations.
Two rather arcane changes have been made to instantiation; they are ex-
plained in Section 5. The only other change that aﬀects TLA+1 speciﬁca-
tions is that the following new keywords have been added in TLA+2, and
thus cannot be used as identiﬁers.
action
have
pick
suffices
assumption
hide
proof
take
axiom
lambda
proposition
temporal
by
lemma
prove
use
corollary
new
qed
witness
def
obvious
recursive
define
omitted
state
defs
only
2
Recursive Operator Deﬁnitions
The only recursive deﬁnitions allowed in TLA+1 were recursive function deﬁ-
nitions. This restriction was inconvenient for the following reasons: (i) spec-
ifying the function’s domain was sometimes diﬃcult, (ii) checking that the
function was applied to an element in the domain could signiﬁcantly slow
down TLC, and (iii) there was no provision for mutual recursion.
I did
not allow recursive operator deﬁnitions in TLA+1 because I didn’t know
how to assign a sensible meaning to them—for example, what should be the
1

meaning of this silly deﬁnition?
F
∆=
choose v : v ̸= F
Georges Gonthier and I have ﬁgured out how to deﬁne recursive operator
deﬁnitions so they have the expected meaning when you expect them to
be meaningful—namely, when the value can be computed by expanding the
deﬁnition a ﬁnite number of times. The precise deﬁnition is complicated
and I hope will eventually appear elsewhere.
In TLA+2, the use of a deﬁned operator must come after either its deﬁ-
nition or its declaration by a recursive statement. For example,
recursive fact( )
fact(n)
∆= if n = 0 then 1 else n ∗fact(n −1)
deﬁnes fact(n) to equal n ! if n is a natural number. I have no idea what it
deﬁnes fact(−2) or fact(“abc”) to equal. (Without the recursive declara-
tion, fact could be used only after its deﬁnition, so its use in the right-hand
side of the deﬁnition would be illegal.)
The syntax of the recursive statement is the same as that of the con-
stant statement, allowing multiple declarations separated by commas. The
recursive statement can come anywhere before the ﬁrst use of the opera-
tors it declares, so it’s easy to write mutually recursive deﬁnitions. However,
you should put a recursive statement as close as possible to the deﬁnitions
of the operators it declares. A tool might treat as recursive any deﬁnitions
that come between an operator’s recursive declaration and its deﬁnition.
A recursive statement can be used in a let expression to permit re-
cursive deﬁnitions local to the let.
A symbol declared in a recursive
statement must later be deﬁned to be an operator taking the correct num-
ber of arguments. Thus, recursive instantiations are not allowed; you cannot
write
recursive Ins(_)
Ins(n)
∆=
instance M with . . .
TLA+1 has the nice property that operator deﬁnitions are like macros. If F
is deﬁned by
F(x)
∆=
. . .
then F(exp) is simply the expression obtained from the right-hand side of
the deﬁnition by replacing every instance of x with exp. In TLA+2, this
2

is not true for recursively-deﬁned operators. We do not know if fact(−2)
equals
if n = 0 then 1 else n ∗fact(−3)
It can be proved that
fact(42)
∆=
if n = 0 then 1 else n ∗fact(41)
However, because fact is deﬁned recursively, this must be proved.
The
method of proving it is fairly standard; I won’t discuss it here.
3
Lambda Expressions
TLA+ allows you to deﬁne higher-order operators—that is, ones that take
operators as arguments, such as
F(Op(_, _))
∆=
Op(1, 2)
The argument of F is an operator that takes two arguments. In TLA+1,
such an argument had to be the name of an operator. For example, we
might deﬁne
Id(a, b)
∆=
a + 2 ∗b
and write F(Id). TLA+2 allows you to use F without having to deﬁne an
operator to use as its argument.
Instead of deﬁning Id in this way and
writing F(Id), you can write
F(lambda a, b : a + 2 ∗b)
The lambda expression is the operator that Id is deﬁned to equal.
A lambda expression can also be used in an instance statement to in-
stantiate an operator parameter.
For example, with the deﬁnition of Id
given above, the following two statements are equivalent.
instance M with Op ←Id
instance M with Op ←lambda a, b : a + 2 ∗b
Syntactically, a lambda expression consists of the keyword lambda followed
by a comma-separated list of identiﬁers, followed by “ : ”, followed by an
expression. A lambda expression can be used only as the argument of a
higher-order operator or to the right of a “←” in an instance statement.
3

4
Theorems and Assumptions
4.1
Naming
There is no need for theorem or assumption names in a speciﬁcation, since
the name would be equivalent to true. However, theorem and assumption
names are used in writing proofs. In TLA+2, you can name a theorem or
assumption by inserting an optional “identiﬁer
∆= ” right after theorem
or assume, as in
theorem Fermat
∆=
¬∃n ∈Nat \ (0 . . 2) : . . .
This is equivalent to
Fermat
∆=
¬∃n ∈Nat \ (0 . . 2) : . . .
theorem Fermat
A theorem cannot have parameters.
TLA+2 allows lemma and proposition as synonyms for theorem and
assumption as a synonym for assume. TLA+2 also allows axiom as almost
a synonym for assume and assumption; it diﬀers only in that (in Toolbox
releases later than Version 1.1.2) TLC does not check assumptions labeled
axiom. This is useful when writing assumptions that TLC can’t check, for
use in a proof.
4.2
assume/prove
In TLA+2, a theorem can assert either a formula or an assume/prove. A
formula is a Boolean-valued expression. However, since TLA+ is untyped,
the silly statement “theorem 42” is a legal (but unprovable) theorem. (See
Section 16.1.3 of Specifying Systems.)
An assume/prove asserts a proof rule. Here is how it is used to assert a
well-known rule of elementary logic that we can prove P ⇒Q by assuming
P and proving Q.
theorem DeductionRule
∆=
assume
new P, new Q,
assume
P
prove
Q
prove
P ⇒Q
Logicians often use “⊢” to express such a rule, writing this as (P ⊢Q) ⊢
(P ⇒Q). In TLA+, we need to declare identiﬁers like P and Q before they
can be used. Here is a standard proof rule of predicate logic; it asserts that
4

we can prove ∀x ∈S : P(x) by choosing a brand-new identiﬁer x, assuming
x ∈S, and proving P(x).
theorem assume
new P(_), new S,
assume
new x ∈S
prove
P(x)
prove
∀x ∈S : P(x)
The third assumption of this rule,
assume new x ∈S prove P(x)
is an abbreviation for
assume
new x, x ∈S
prove
P(x)
Here are a couple of proof rules of TLA. The ﬁrst asserts that a primed
constant equals itself.
theorem Constancy
∆=
assume
constant C
prove
C ′ = C
Here is a standard temporal-logic rule:
theorem assume
temporal F,
temporal G
prove
2(F ∧G) ≡2F ∧2G
These theorems assert a rule that is valid whenever expressions or operators
of the speciﬁed (or lower) level are substituted for the declared identiﬁers.
For example, Theorem Constancy implies (2+N )′ = (2+N ) if N is declared
to be a constant parameter of the module. See Section 17.2 of Specifying
Systems for an explanation of levels. (The action level is called transition-
level there.)
The declaration new is equivalent to constant. If all the expressions
and identiﬁers that appear in a theorem have constant level, then the the-
orem is valid when expressions of any level are substituted for the declared
identiﬁers.
You can also use a variable declaration in an assume to state that
some identiﬁer is a TLA+ variable. To illustrate the diﬀerence between a
variable and a state declaration, consider this valid TLA+ rule.
theorem assume
variable x,
variable y
prove
enabled x ′ ̸= y′
5

The theorem would not be valid if “variable” were replaced by “state”
because the resulting theorem would allow any state-level expressions to be
substituted for x and y. Substituting the variable z for both x and y would
then yield the conclusion enabled z ′ ̸= z ′, which is false.
You have probably inferred most of the grammar of assume/prove
assertions:
• An assume/prove consists of the token assume, followed by a comma-
separated list of assumptions, followed by the token prove, followed
by an expression.
• An assumption is an expression, a declaration, or an assume/prove.
• A declaration may be:
– The same as a constant statement in the body of the mod-
ule that declares a single constant parameter, except that the
keyword constant may optionally be replaced by new, state,
action, or temporal.
– The token new or constant, followed by an identiﬁer, the token
∈, and an expression.
– The token variable followed by an identiﬁer.
An optional new token may precede any of these declarations except
for one beginning with a new token. (The unnecessary “new” may
help some people understand the meaning of the declaration.)
Indentation is not signiﬁcant. (In TLA+2 as in TLA+1, indentation matters
only in bulleted lists of conjuncts and disjuncts.)
The meaning of assume/prove assertions is subtle when they contain
temporal or action-level formulas. See Section 8.3 on page 35 for an expla-
nation.
5
Instantiation
Two minor changes to instantiation have been made in TLA+2: (i) there
is a diﬀerent syntax for instantiated in-, pre-, and postﬁx operators, and
(ii) operator instantiation has been restricted to allow instantiation only
with “Leibniz” operators, which are deﬁned below.
6

5.1
Instantiating *ﬁx Operators
If module M deﬁnes an inﬁx operator such as &&, then in TLA+1 the
statement
Foo
∆=
instance M with . . .
deﬁnes an inﬁx operator Foo!&& that would be used in such strange ex-
pressions as
1 Foo!&& 2
TLA+2 eliminates this awkward syntax. Instead, the operator Foo!&& is a
“normal” nonﬁx operator and not an inﬁx one, so you write this expression
as Foo!&&(1, 2). If this were a parameterized instantiation, so Foo took an
argument, then you would write something like Foo(42)!&&(1, 2).
The analogous change has been made to postﬁx operators and the preﬁx
operator unary “−”, which must be written as “-.” after a “ ! ”.
For the sake of uniformity, TLA+2 permits any inﬁx or postﬁx operator
to be used as a nonﬁx operator. For example, +(1,2) is another way of
writing 1+2.
(Preﬁx operators could always be written this way.)
This
alternate syntax does not apply to the left-hand side of a deﬁnition. For
example, the only way to deﬁne the inﬁx operator && is to write something
like
a && b
∆=
. . .
Because of a bug that is unlikely to be ﬁxed, the current SANY parser does
not accept this alternate syntax for the inﬁx operator “−”; it accepts only
2-1 and not -(2,1).
5.2
Leibniz Operators and Instantiation
Consider the following module.
module M
constants C, D, F( )
theorem (C = D) ⇒(F(C) = F(D))
The perfectly reasonable theorem in this module is not valid in TLA+1 for
the following reason. The semantics of TLA+ requires that any instantiation
of a valid theorem be valid. Now consider
7

variables x, y
Prime(p)
∆= p′
instance M with C ←x, D ←y, F ←Prime
This imports the theorem from module M as
theorem (x = y) ⇒(x ′ = y′)
which is not valid. (Equality of the values of x and y in the current state
doesn’t imply that they are equal in the next state.)
In TLA+2, the theorem of module M is valid, which means that this
instance M statement is illegal.
It is illegal because TLA+2 allows in-
stantiation of an operator parameter only by a Leibniz operator, and F is
non-Leibniz. An operator F of a single argument is deﬁned to be Leibniz
iﬀe = f implies F(e) = F(f ), for any expressions e and f .
(Logicians
generally use the term substitutive rather than Leibniz.) For an operator F
that takes k arguments, F is Leibniz iﬀthe value of F(e1, . . . , ek) remains
unchanged if any of the expressions ei is replaced by an equal expression.
Constant parameters are assumed to be Leibniz, so one constant parameter
can be instantiated by another.
In TLA+, all built-in and deﬁnable constant operators are Leibniz. The
only built-in TLA+ operators that are not Leibniz are the action operators
and the temporal operators, listed in Tables 3 and 4 of Specifying Systems.
In a non-constant module, a constant parameter can be instantiated only
by a constant operator. Thus, the restriction added in TLA+2 is automati-
cally satisﬁed except when substituting non-constant operators in a constant
module. However, a non-constant operator can be Leibniz—for example, the
Leibniz operator G deﬁned by
G(a)
∆=
x ′ = [x except ![a] = y′]
For a deﬁned operator to be non-Leibniz, one of its parameters must appear
in the deﬁnition within an argument of a non-Leibniz operator like ′ (prime).
6
Naming Subexpressions
When writing proofs, it is often necessary to refer to subexpressions of a for-
mula. In theory, one could use deﬁnitions to name all these subexpressions.
For example, if
Foo(y)
∆=
(x + y) + z
8

and we need to mention the subexpression (x + 13) of Foo(13), we could
write
Newname(y)
∆=
(x + y)
Foo(y)
∆=
NewName(y) + z
This doesn’t work in practice because it results in a mass of non-locally
deﬁned names, and because we may not know which subformulas need to
be mentioned when we deﬁne the formula.
TLA+2 provides a method of naming subexpressions of a deﬁnition. If F
is deﬁned by F(a, b)
∆= . . . , then any subexpression of the formula obtained
by substituting expressions A for a and B for b in the right-hand side of this
deﬁnition has a name beginning “F(A, B) !”. (Although this is a new use of
the symbol “!”, it is a natural extension of its use with module instantiation.)
You can use subexpression names in any expression. When writing a
speciﬁcation, you can deﬁne operators in terms of subexpressions of the
deﬁnitions of other operators. Don’t! Subexpression names should be used
only in proofs. In a speciﬁcation, you should use deﬁnitions to give names
to the subexpressions that you want to re-use in this way.
6.1
Labels and Labeled Subexpression Names
Any subexpression of a deﬁnition can be labeled. The syntax of a labeled
expression is
label :: expression
(The symbol “::” is typed “::”.) The label applies to the largest possible
expression that follows it. In other words, the end of the labeled expression
is the same as the end of the expression that you would get by replacing the
“label ::” with “∀x : ”. However, the expression is illegal if removing the
label would change the way the expression is parsed. For example,
a + lab :: b ∗c
is legal because it is parsed as a + (lab :: (b ∗c)), which is how it would be
parsed if the label lab were not there. However,
a ∗lab :: b + c
is illegal because it would be parsed as a ∗(lab :: (b + c)) and removing the
label causes the expression to be parsed as (a ∗b) + c.
9

Label parameters are required if labels occur within the scope of bound
identiﬁers. Here is an example.
F(a)
∆=
∀b : l1(b) :: (a > 0) ⇒
∧. . .
∧l2 :: ∃c : ∧. . .
∧∃d : l3(c, d) :: a −b > c −d
For this example, F(A)!l1(B)!l2!l3(C, D) names the expression A −B >
C −D. Note how the parameters of each label are the bound identiﬁers
introduced between it and the next outer-most label. Those identiﬁers can
appear in any order. For example, if the label l3(c, d) were replaced by
l3(d, c), then F(A)!l1(B)!l2!l3(C, D) would name the expression A −B >
D −C.
In this example, a reference to the subexpression labeled by l3(c, d)
from outside the deﬁnition of F, must specify the values of all the bound
identiﬁers a, b, c, and d. That’s why labels must include the bound identi-
ﬁers as parameters. Also observe that to name a labeled subexpression, we
have to name all the labeled subexpressions within which it lies. We’re not
even allowed to eliminate the label l2, even though it is superﬂuous in this
example.
Label names do not conﬂict with operator names. In this example, any
one of the label names l1, l2, or l3 could be replaced by F. The rule for name
conﬂict is the obvious one needed to guarantee that there’s no ambiguity
in a subexpression name (where we are not allowed to use the number of
parameters to disambiguate). Thus, we cannot label the ﬁrst conjunct of
the ∃c expression with l3(c), but we could label it with l1(c) or l2(c).
For subexpressions of the deﬁnition of an inﬁx, postﬁx, or preﬁx operator,
we use the “nonﬁx” form. For example, a subexpression of the deﬁnition of
&& would have the form &&(A, B) ! . . . .
We can also name subexpressions of deﬁnitions in instantiated modules.
For example, if we have
Ins(x)
∆=
instance M with . . .
and ν is the name of any subexpression of a deﬁnition in module M , then
Ins(exp)!ν is the name of the subexpression of the instantiated deﬁnition
obtained when exp is substituted for x.
We call a subexpression name having one of the forms described here a
labeled subexpression name. We include in this category the trivial case in
which there is no label name, only the name of a deﬁned operator—possibly
10

in an instantiated module. The precise deﬁnition is contained in the “ﬁne
print” below. You probably don’t want to read it.
The Fine Print
Here is the general deﬁnition explained above with examples. We say that label
lab1 is the containing label of lab2 iﬀ(i) lab2 lies within the expression labeled by
lab1 and (ii) if lab2 lies within the expression labeled by any other label, then lab1
also lies within that expression.
We use the notation that f (e1, . . . , ek) denotes f when k = 0. A label lab has
the form id(p1, . . . , pk) where id and the pi are identiﬁers, the pi are all distinct,
and {p1, . . . , pk} is the set of all bound identiﬁers pi such that:
• Label lab lies within the scope of pi.
• If lab has a containing label labc, then the expression that introduces pi lies
within the expression labeled by labc.
We call id the name of the label. Two labels that either have no containing label
or have the same containing label must have diﬀerent names.
A
simple
labeled
subexpression
name
of
a
module
M
has
the
form
preﬁx !labexp1! . . .!labexpn, where preﬁx has the form Op(e1, . . . , ek[0]), each labexpi
has the form idi(e1, . . . , ek[i]), Op and the idi are identiﬁers, and the ej are ex-
pressions. It must satisfy:
• The deﬁnition
Op(p1, . . . , pk[0])
∆=
. . .
occurs at the top level (not inside a let or inner module) of M .
• id1 must be the name of a label lab1 in the deﬁnition of Op that has no
containing label.
• If i > 1, then idi must be the identiﬁer of a label labi whose containing label
is labi−1.
• k[i] must equal the number of parameters in labi, for each i > 0.
This labeled subexpression name denotes the expression obtained from the expres-
sion labeled with labn by substituting for each parameter of Op and of each labi
the corresponding argument of preﬁx and labexpi, respectively.
A labeled subexpression name of a module M is either a simple labeled subex-
pression name of M or else has the form Id(e1, . . . , ek) ! λ where there is a state-
ment
Id(e1, . . . , ek)
∆=
instance N . . .
at the outermost level of M and λ is a labeled subexpression name of module N .
11

6.2
Positional Subexpression Names
Instead of using labels, we can name subexpressions of a deﬁnition by a se-
quence of positional selectors that indicate the position of the subexpression
in the parse tree. Consider this example
F(a)
∆=
∧. . .
∧. . .
∧Len(x[a]) > 0
∧. . .
Here are how some of the subexpressions of this deﬁnition are named, where
A is an arbitrary expression:
• F(A)!3 names Len(x[A]) > 0, the third conjunct of F(A)—that is,
of the right-hand side of the deﬁnition with A substituted for a. We
think of this conjunct list as the application of a conjunction operator
that takes four arguments, the third being Len(x[A]) > 0.
• F(A)!3!1 names Len(x[A]), the ﬁrst argument of > , the top-level
operator of the expression F(A)!3
• F(A)!3!1!1 names x[A], the ﬁrst (and only) argument of the top-level
operator of the expression F(A)!3!1.
• The naming of subexpressions of x[A] is based on the realization that
this expression represents the application of a function-application op-
erator to the two arguments x and A. Thus, F(A)!3!1!1!1 names x
and F(A)!3!1!1!2 names A
The positional selector “!⟨” is always synonymous with !1, and “! ⟩” is
synonymous with !2 when selecting the second argument of an operator
that takes two arguments. Thus, instead of F(A)!3!1!1!2 , we could write
F(A)!3!⟨!⟨! ⟩or F(A)!3!⟨!1! ⟩or F(A)!3!1!⟨!2 or . . . . As usual, “⟨” is
typed “<<” and “⟩” is typed “>>”.
The use of positional selectors to pick an argument of an operator is self-
evident for most operators that do not introduce bound identiﬁers. Here are
the cases that are not obvious.
• In
[f except ![a] = g, ![b].c = h]
we select f with !1, g with !2,
and h with !3. No other subexpressions of the except construct can
be named.
12

• r.ﬂd
is an application of a record-ﬁeld selector operator to the two
arguments r and “ﬂd”, so !1 selects r. (You can also use !2 to select
“ﬂd”, but there’s no reason to name a simple string constant with a
subexpression name.)
• In [ﬂd1 7→val1, . . . , ﬂdn 7→valn] and [ﬂd1 : val1, . . . , ﬂdn : valn]
the selector ! i names the subexpression vali for i ∈1 . . n. The ﬁeld
names ﬂdi cannot be selected. (There is no point naming ﬂdi, since
it’s just a string constant.)
• In
if p then e else f
the selector !1 names p, the selector !2
names e, and the selector !3 names f .
• In
case p1 →e1 2 . . . 2 pn →en
the selector !i !1 names pi and
!i !2 names ei. If pn is the token other, then it cannot be named.
• In
WFe(A) and SFe(A)
the selector !1 names e and !2 names A.
• In
[A]e
and
⟨A⟩e
the selector !1 names A and !2 names e.
• In
let . . . in e
the selector !1 names e.
This is rather subtle
because we are naming an expression that contains operators deﬁned
in the let clause that are not deﬁned in the context in which the
subexpression name appears. Consider this example
F
∆=
let G
∆= 1 in G + 1
G
∆=
22
H
∆=
F !1
The F !1 in the deﬁnition of H names the expression G + 1 in which
G has the meaning it acquires in the let deﬁnition. Thus, H is equal
to 2, not to 23.
We will see below how to name subexpressions of let deﬁnitions, such
as the ﬁrst (local) deﬁnition of G above.
I now describe selectors for subexpressions of constructs that introduce
bound identiﬁers. Consider this example:
R
∆=
∃x ∈S, y ∈T : x + y > 2
• R!(X , Y ) names X + Y > 2, for any expressions X and Y .
• R!1 names S.
13

• R!2 names T.
In general, for any construct that introduces bound identiﬁers:
• !(e1, . . . , en) selects the body (the expression in which the bound iden-
tiﬁers may appear) with each expression ei substituted for the ith
bound identiﬁer.
• If the bound identiﬁers are given a range by an expression of the form
“ ∈S”, then !i selects the ith such range S.
For example, in the expression
[x, y ∈S, z ∈T 7→x + y + z]
the selector !1 names S, the selector !2 names T, and the selector !(X , Y , Z)
names X + Y + Z.
Parentheses are “invisible” with respect to naming.
For example, it
doesn’t matter if ν names the subexpression a + b or the subexpression
((a + b)) ; in either case, ν!⟨names a.
We usually don’t need to name the entire expression to the right of a
“
∆=” because the operator being deﬁned names it. However, as observed
in Section 2, this is not true for recursively deﬁned operators.
If Op is
recursively deﬁned by
Op(p1, . . . , pk)
∆=
exp
then “Op(P1, . . . , Pk) ! :” names exp with Pi substituted for pi, for each i
in 1 . . k.
A positional subexpression name consists of a labeled subexpression name
(deﬁned in Section 6.1 above) followed by a sequence of positional selectors.
For example, in
F(c)
∆=
a ∗lab :: (b + c ∗d)
F(7)!lab! ⟩names 7 ∗d. Remember that a labeled subexpression need not
contain labels—for example, F(7) is a labeled subexpression name.
14

6.3
Subexpressions of let Deﬁnitions
If a positional subexpression name ν names a let/in expression and Op is
an operator deﬁned in the let clause, then ν!Op(e1, . . . , en) is the name
of the expression Op(e1, . . . , en) interpreted in the context determined by
ν. For example, in
F(a)
∆=
∧. . .
∧let G(b)
∆=
a + b
in
. . .
F(A)!2!G(B) names the expression G(B), where the deﬁnition of G is
interpreted in a context in which A is substituted for a. This expression of
course equals A+B. (However, if G were recursively deﬁned, F(A)!2!G(B)
might not be so simply related to the expression to the right of the “
∆=” in
G’s deﬁnition.) We can also name subexpressions of the deﬁnition of G. For
example, F(A)!2!G(B)! ⟩names B. The naming process can be continued
all the way down, naming subexpressions of let deﬁnitions contained within
let deﬁnitions contained within . . . .
If the let/in expression is labeled, then it can be named by a la-
beled subexpression name λ. In that case, λ!Op(e1, . . . , en) is a labeled
subexpression name that names a subexpression of the in clause with label
Op(p1, . . . , pn). To refer to the operator Op deﬁned in the let clause, just
add a “! :” to the end of λ, writing λ! :!Op(e1, . . . , en) . In particular, if H is
deﬁned to equal the let/in expression, then we write H ! :!Op(e1, . . . , en) ,
even if H is not recursively deﬁned.
6.4
Subexpressions of an assume/prove
If we have
theorem Id
∆=
assume A1, . . . , An prove G
then Id is not an expression and cannot be used as one. Subexpressions
of an assume/prove can be named with labels or positionally, where Id!i
names Ai if 1 ≤i ≤n, and Id!n +1 names G. However, the assumptions
can contain declarations like new C, so it is possible to name a subex-
pression of an assume/prove that contains identiﬁers declared within the
assume/prove. Such a name can be used only within the scope of those
15

declarations. For example, consider
theorem T
∆= assume
x > 0, new C ∈Nat, y > C
prove
x + y > C
...
Foo
∆= . . .
Then T!1 names the expression x > 0, which can be used in the deﬁnition of
Foo. However, T!3 names the expression y > C that contains the constant
C, and the deﬁnition Foo is not within the scope of the declaration of C, so
T!3 cannot be used within the deﬁnition of Foo. In fact, T!3 can be used
only within the proof of T. (Proofs are discussed in Section 7.)
6.5
Using Subexpression Names as Operators
Subexpression names can be used as operator names by replacing every part
of the form !id(e1, . . . , en) by !id, and every selector !(e1, . . . , en) by !@ .
For example, consider:
F(Op(_, _, _))
∆=
Op(1, 2, 3)
G
∆=
∀x : P ⊆{⟨x, y+z ⟩: y ∈S, z ∈T}
Then G !(X )! ⟩!(Y , Z) is the expression ⟨X , Y+Z ⟩, so G !@! ⟩!@ is the
operator
lambda x, y, z : ⟨x, y+z ⟩
and F(G !@! ⟩!@) equals ⟨1, 2+3⟩.
7
The Proof Syntax
This section describes the syntax of proofs and how proofs are checked by
TLAPS, the TLA+ proof checker.
7.1
The structure of a proof
A theorem is optionally followed by a proof. A proof is either a terminal
proof or a sequence of steps, some of which have proofs. Figure 1 shows a
possible proof structure, where the actual assertions made by the steps or by
the terminal proofs are elided. This example is a proof having level number
1 and consisting of three steps named ⟨1⟩1, ⟨1⟩2, and ⟨1⟩3. Step ⟨1⟩1 has a
level-2 proof that consists of three steps, one named ⟨2⟩4a, an unnamed step
16

⟨1⟩1. . . .
proof
⟨2⟩4a. . . .
obvious
⟨2⟩
. . .
⟨17⟩
. . .
proof omitted
⟨17⟩1. . . .
⟨17⟩
. . .
⟨17⟩ab qed
⟨2⟩11 qed
by . . .
⟨1⟩2. . . .
by . . .
⟨1⟩3. qed
Figure 1: The structure of a simple proof.
(marked by the token “⟨2⟩”), and a qed step named ⟨2⟩11. Step ⟨2⟩4a has
a terminal proof. The unnamed level-2 proof step has a four-step proof with
level number 17. Only its ﬁrst step has a proof—a terminal proof asserting
that the actual proof is omitted.
A proof may optionally begin with the token proof. Thus, the proof
token that begins the proof of step ⟨1⟩1 and that precedes the token omit-
ted could be removed, and a proof token could be added before step ⟨1⟩1,
before the “obvious” terminal proof, before the ﬁrst level ⟨17⟩step, and
before either of the by proofs. The formatting is for readability only; in-
dentation has no signiﬁcance.
In general, a proof consists of the optional keyword proof followed by
either a terminal proof or else by a sequence of steps followed by a qed
step. A step or a qed step may have a proof, which is called a subproof
of the proof containing the step. A terminal proof consists of the keyword
obvious or omitted or else begins with the keyword by.
Each step begins with a step-starting token that consists of a step name
followed by an optional sequence of periods. A step name consists of
• < (printed as “⟨”)
• a number called the step’s level number or a + or ∗character. (The
meaning of + and ∗is explained below.)
17

• > (printed as “⟩”)
• an optional string of letters and/or digits. If this string is present,
then the step is said to be named and its step name consists of the
entire token up to and including this string.
Since a step-starting token is a single token, it may not contain spaces. (Note
that a step-starting token is the one place in which “⟨” and “⟩” are typed
“<” and “>” rather than “<<” and “>>”.) All the steps of a proof have the
same level number, which is less than that of any of its subproofs. A step
with a greater level number than the preceding step begins the proof of that
preceding step, whether or not it is preceded by a proof token.
Named steps are referred to by their step names. The scope of a level k
step name (the part of a proof within which it can be used) consists of the
step’s proof (if it has one), all the level-k steps in the same proof that follow
it and in those steps’ proofs. A step name cannot be used within its scope
to label another step. However, the same step name can be used in diﬀerent
subproofs of a proof. For example, step names ⟨2⟩4a and ⟨17⟩1 could be
used in a proof of step ⟨1⟩3.
The level number of a step may be written implicitly with a “∗” or a
“+”. To explain the meaning of such a level number, let us deﬁne the current
level at a proof step to equal −1 for the ﬁrst step of the entire proof, and
otherwise to equal the level of the latest preceding step that is neither a qed
step nor followed by a qed step of the same level. In the example above, the
current level at step ⟨1⟩1 is −1, the current level at step ⟨2⟩4a is 1, and the
current level at step ⟨2⟩11 is 2. Let L be the current level at a step whose
step-starting token begins with “⟨∗⟩” or “⟨+⟩”. Then
• a “+” is equivalent to the number L + 1, and
• a “∗” is equivalent to the number L + 1 if it immediately follows a
proof token or is at the beginning of the entire proof; otherwise it is
equivalent to the number L.
In the above example, ⟨1⟩1 can be replaced by either ⟨+⟩1 or ⟨∗⟩1; ⟨2⟩4a
can be replaced by ⟨+⟩4a or ⟨∗⟩4a; and either of the other two “⟨2⟩. . .”
tokens could be replaced by “⟨∗⟩. . .”. If the proof token before it were
missing, then ⟨2⟩4a could be replaced only by ⟨+⟩4a and not by ⟨∗⟩4a. In
all cases, it makes no diﬀerence if we use the “∗” or “+” or the equivalent
explicit level number.
A “∗” can also be used instead of a level number in a reference to a
proof step, in which case it stands for the current level. For example, you
18

can write ⟨∗⟩4a instead of ⟨2⟩4a in the by statement that is the proof of
step ⟨2⟩11. Again, it makes no diﬀerence if you write “∗” or the equivalent
explicit level number.
TLAPS (the TLA+ prover) does not yet support references to
proof steps that use “∗” as level number.
7.2
use, hide, and by
7.2.1
use and hide
At any point in a module, there is a set of current declarations, a set of
current deﬁnitions, and a set of known facts.
Outside a proof, the cur-
rent declarations come from constant or variable declarations within the
module and within modules it extends; the current deﬁnitions come from
deﬁnitions within the module and within extended or instantiated modules;
and the facts come from assumptions and theorems asserted thus far in the
module and in extended modules, and from assertions imported thus far by
instantiation. Each theorem in an instantiated module yields the assertion
that the instantiated theorem follows from the instantiation of the module’s
assumptions. For example, if module M contains the single assumption
assume A
and the theorem
theorem Thm
∆= T
then the statement
Mod
∆= instance M with . . .
imports a theorem named Mod!Thm that asserts
assume A
prove T
where A and T are the formulas obtained from A and T by performing the
substitutions speciﬁed by the instance statement’s with clause.
There are also subsets of the sets of current deﬁnitions and known facts
called the usable deﬁnitions and the usable facts. These are the deﬁnitions
that TLAPS expands and the facts that it tries to apply when trying to prove
something.
(The deﬁnitions referred to here are “outer-level” deﬁnitions
and not let deﬁnitions, which are always expandable.) Here are the default
values of these subsets at points in a module outside a proof.
19

• Only the deﬁnitions of theorem names are usable. (Section 4.1 explains
how theorems are named.)
• No theorems or assumptions are usable.
The defaults can be overridden by use and hide statements. Such state-
ments can appear anywhere in the body of the module—that is, at the “top
level”, not inside any other statements. A use or hide statement consists of
the keyword use or hide followed by an optional list of facts, optionally
followed by the keyword def or defs and a list of deﬁnition speciﬁers. (It
must include at least one fact or deﬁnition speciﬁer.)
A fact is one of the following:
• The name of a theorem, assumption, or proof step.
• An arbitrary formula—but only in a use statement, not a hide state-
ment. The formula must be easily provable from the currently usable
facts and the preceding facts in the use statement. “Easily provable”
means that a proof tool should be able to ﬁnd the proof without any
help from the user.
The parser also allows the following two kinds of “facts” in a use or hide
statement. However, they are not supported by TLAPS and are likely to be
removed from the language.
• module Name, indicating that all known facts obtained from the
module Name are to be added or removed from the set of usable facts.
The module name must appear in an extends or instance statement
or else be the name of the current module.
• An identiﬁer Id that appears in a statement of the form
Id
∆=
instance M . . .
It adds or removes from the set of usable facts all facts imported from
module M . The instance statement cannot have parameters—that
is, it can’t be of the form Id(x)
∆=
. . . .
Theorems in certain special standard modules will direct TLAPS to use
decision procedures or proof tactics. For example, there will be a theorem
named SimpleArithmetic that causes TLAPS to apply a certain decision
procedure for arithmetic when trying to prove something.
A deﬁnition speciﬁer is the name of a deﬁned operator—for example,
20

• F if the module contains the deﬁnition F(x, y)
∆= . . . .
• Ins !F if the current module contains Ins(a)
∆= instance M . . . and
F is deﬁned in M .
The SANY parser also accepts the following two kinds of deﬁnition speciﬁers.
However, they are not supported by TLAPS and will probably be eliminated
from the language.
• module Name, indicating that all deﬁnitions from the module Name
are to be added or removed from the set of usable deﬁnitions. The
module name must appear in an extends or instance statement or
else be the name of the current module.
• An identiﬁer Id that appears in a statement
Id(p1, . . . , pk)
∆=
instance M . . .
(possibly with k = 0). It indicates that all the deﬁnitions imported
from the instantiation are to be added or removed.
7.2.2
by
A terminal by proof has the same syntax as a use statement, except that it
starts instead with the keyword by. As explained below, at any point in a
proof there will be sets of known and usable facts and of current and usable
deﬁnitions. There will also be a current goal. A by proof asserts that this
goal follows easily from the set of usable facts together with the set of facts
speciﬁed in the by statement, using only those deﬁnitions contained in the
set of usable deﬁnitions or speciﬁed by the statement. “Easily” means that
a proof tool should be able to ﬁnd the proof without any help from the user.
In addition to names of theorems, assumptions, and steps, a fact in a by
statement can be an arbitrary formula. Such a fact must follow easily from
the set of usable facts together with the previous facts in the by statement.
For example, suppose the set of currently usable facts includes the fact
e ∈S. You might write
⟨3⟩1. ∀x ∈S : P(x)
⟨3⟩2. P(e + 1)
by ⟨3⟩1, P(e)
The fact P(e), which follows from e ∈S and ⟨3⟩1, makes the proof easier
to understand (and easier for a prover to check) by alerting the reader that
21

to prove P(e + 1) from usable facts and the fact ⟨3⟩1, he (or it) should ﬁrst
note that P(e) follows from these facts. Arbitrary expressions can also be
used as facts in a use, but not in a hide.
A by only proof begins with the keywords by only.
Unlike in an
ordinary by proof, the current goal must follow easily from just the speciﬁed
facts and the currently known domain formulas, without using any other
usable facts.
TLAPS uses all currently usable deﬁnitions plus the ones
speciﬁed by the def clause.
TLAPS also allows the use in a by or by only proof or in a use state-
ment of a fact that is trivially equivalent to a known (but not necessarily
usable) fact. For example, if a module contains
theorem Elementary
∆= 1 + 1 = 2
then the facts Elementary and 1 + 1 = 2 can be used interchangably any-
where within the scope of the deﬁnition of Elementary.
7.2.3
obvious and omitted
The terminal proof obvious asserts that the current goal follows easily from
the set of known facts and the deﬁnitions contained in the set of usable
deﬁnitions.
The terminal “proof” omitted means that the user is asserting the
validity of the step without providing a proof. It asserts that the user has
deliberately chosen not to provide a proof, and has not omitted it either
accidentally or temporarily while writing other parts of the proof.
A proof is incomplete if it contains a statement with no proof. Incom-
plete proofs will be the norm while a user is developing the proof. TLAPS
attempts to check a step only if the step has a proof other than the terminal
“proof” omitted.
7.3
The Current State
At each point in a proof there is a current state that consists of:
• The set of current declarations.
• The set of current deﬁnitions and a subset consisting of the usable
deﬁnitions.
• A set of currently known facts and a subset consisting of the usable
facts.
22

• A current goal, which is a formula.
Recall that at the start of a theorem, there are sets of current declarations,
current and usable deﬁnitions, and facts and usable facts described above.
The state at the start of the theorem’s proof is obtained by adding to these
sets the following:
• If the theorem asserts a formula, then the formula becomes the current
goal.
• If the theorem asserts an assume/prove, then the declarations in the
assumptions are added to the set of current declarations. The set of
formulas and assume/proves asserted in the assumptions is added to
the set of known facts; it is also added to the set of usable facts iﬀthe
theorem has no name. The prove formula becomes the current goal.
(If an assumption is an assume/prove, then the declarations of the
inner assume are not added to the set of current declarations.)
Remember that the assumption new C ∈S is an abbreviation for
the declaration new C and the assertion C ∈S . An assertion of the
form C ∈S obtained from a declaration is called a domain formula.
Domain formulas are always added to the set of usable facts as well as
to the set of known facts, even if the theorem is unnamed.
After the theorem’s proof (if any), the current state reverts to the state right
before the theorem, with the theorem added to the set of known facts iﬀit
is named. An unnamed theorem can never be used in a proof.
To explain the meaning of a step, we describe the relation between the
state of the proof at the (beginning of the) step and
• the state at the beginning of the statement’s proof (if it has one), and
• the state immediately after the statement and its proof (if it has one).
7.4
Steps That Take Proofs
In the following descriptions, σ will be used to denote an arbitrary step-
starting token.
7.4.1
Formulas and assume/prove
A step that asserts a formula or an assume/prove aﬀects the state exactly
the same way as a theorem. It makes either the formula or the prove asser-
tion the current goal of the step’s proof. The formulas and assume/prove
23

assertions from the assume clause are added to the set of usable facts iﬀ
the step is unnamed. However, domain formulas obtained from new clauses
are always added to the set of usable facts.
After the step and its proof, the step’s assertion is added to the set of
usable facts iﬀthe step is unnamed. (An unnamed step can never be referred
to in a by or use, so the step’s assertion must be put into the set of usable
facts for it ever to be used.)
7.4.2
case
A case step consists of the step-starting token followed by the keyword
case and a formula. The step “σ case F” is equivalent to
σ assume F prove G
where G is the current goal. (Since G is already the current goal, this means
that the current goal remains the same.)
7.4.3
@ Steps
A common method of proving an inequality is by proving a sequence of
inequalities. For example, to prove A ≤D, we might prove A ≤B ≤C ≤D.
Such a proof might appear inside a proof as follows (where the proofs of the
individual steps are omitted).
⟨2⟩3. A ≤D
⟨3⟩1. A ≤B
⟨3⟩2. B ≤C
⟨3⟩3. C ≤D
⟨3⟩4. qed
by ⟨3⟩1, ⟨3⟩2, ⟨3⟩3
It’s a nuisance to have to write B and C twice if they’re large formulas.
TLA+2 provides the following abbreviated way of writing this proof.
⟨2⟩3. A ≤D
⟨3⟩1. A ≤B
⟨3⟩2. @ ≤C
⟨3⟩3. @ ≤D
⟨3⟩4. qed
by ⟨3⟩1, ⟨3⟩2, ⟨3⟩3
24

This style of reasoning can be used with any transitive operator or combi-
nation of operators, such as
A
=
B
=
C
=
D
A
⇒
B
⇒
C
⇒
D
A
⊆
B
⊆
C
⊆
D
A
≤
B
<
C
≤
D
However, the token @ followed by an inﬁx operator followed by an expression
can be used in a step that follows any @ step or any formula step in which
the formula’s top-level operator is an inﬁx operator. The “@” then refers to
the right-hand side of the preceding step’s formula. Although it’s bad style
and you shouldn’t do it, you could write
⟨3⟩4. A ≤B
⟨3⟩5. @ > C
where the @ stands for B.
7.4.4
suffices
The step σ suffices A asserts that proving A proves the current goal,
where A can be a formula or an assume/prove. At the beginning of the
step’s proof, A is added to the set of known facts and to the set of usable
facts. (The proof must prove the current goal.) After the step and its proof:
• If A is a formula, then it is made the current goal.
• If A is an assume/prove, then:
– The declarations in its assumptions are added to the set of current
declarations and the domain formulas from those declarations are
added to the sets of known and usable facts.
– The assertions among its assumptions (the formulas and the as-
sume/proves) are added to the set of known facts. They are
added to the set of usable facts iﬀthe step is not named.
– The prove formula is made the current goal.
7.4.5
pick
A pick step has the same syntax as one that asserts a ∃formula, except
with the ∃replaced by the token pick. For example, the step
25

σ pick x ∈S, y ∈T : P(x, y)
asserts that there exist values x in S and y in T satisfying P(x, y), and then
declares x and y to be equal to an arbitrary pair of such values. The state
at the start of the step’s proof is the same as for the formula obtained by
replacing pick by ∃. After the proof:
• constant declarations of the identiﬁers introduced by the step are
added to the set of declarations and the domain formulas of those
declarations are added to the sets of known and usable facts. (In this
example, the domain formulas are x ∈S and y ∈T.)
• The body of the pick (in this example, the formula P(x, y)) is added
to the set of known facts. It is added to the set of usable facts iﬀthe
step is not named.
A pick step is eﬀectively translated to two steps. For example, the step and
its proof
σ pick x ∈S, y ∈T : P(x, y)
proof Π
are translated to
ρ ∃x ∈S, y ∈T : P(x, y)
proof Π
σ suffices assume new x ∈S, new y ∈T
P(x, y)
prove
G
and σ contains a proof asserting that it follows from ρ, where ρ is a new step
name and G is the current goal. This translation is relevant to the meaning
of the step name σ. (See Section 7.6.2 on page 31.)
7.4.6
qed
The state at the beginning of a qed step’s proof is unchanged. After the
step and its proof, the state is determined by the rule for the step whose
proof the qed step ends.
26

7.5
Steps That Do Not Take Proofs
7.5.1
Deﬁnitions
In a deﬁnition step, the step-starting token is followed by the optional token
define and a sequence of operator deﬁnitions, function deﬁnitions, and/or
module deﬁnitions, where a module deﬁnition is something like
Ins(x)
∆=
instance M with
. . .
It has the same eﬀect on the state as the corresponding (top-level) state-
ments. The deﬁnitions introduced by the step (which are the deﬁnitions of
the imported and renamed operators for a module deﬁnition) are added to
both the set of deﬁnitions and the set of usable deﬁnitions.
7.5.2
instance
An instance step consists of a step-starting token followed by an ordinary
instance statement (one that begins with the keyword instance). It has
the same eﬀect on the state as the corresponding (top-level) statement.
7.5.3
use and hide
A use or hide step has the same syntax as the corresponding (top-level)
statement, except preceded by the step-starting token. It aﬀects the sets of
usable facts and deﬁnitions the same way as the corresponding use or hide
statement. As explained in Section 7.6 below, a use or hide step can name
facts or deﬁnitions made in earlier steps.
There is also a use only step, in which the keyword use is followed by
the keyword only. It sets the usable facts to be only known domain facts
and facts speciﬁed by the step. It aﬀects the set of usable deﬁnitions the
same way as an ordinary use step.
7.5.4
have
A have step consists of a step-starting token followed by have and a for-
mula. For the statement
σ have F
to be correct, the current goal must be syntactically of the form H ⇒G
for some formulas H and G, and the formula H ⇒F must be an obvious
27

consequence of the known facts and usable deﬁnition. In that case, the step
is equivalent to
σ suffices assume F
prove G
plus a by only proof that permits using only the fact assume F prove B
(a fact that must therefore be easily provable with no assumptions). Thus,
this step means that we are going to prove the current goal by assuming F
and proving G.
7.5.5
take
A take step consists of a step-starting token followed by take followed by
anything that could come between “∀” and its matching “:”—for example
σ take x, y ∈S, z ∈T
This step is typically used when the current goal is
∀x, y ∈S, z ∈T : G
for some formula G.
It means that we are going to prove this goal by
declaring x, y, z to be constants, assuming x ∈S, y ∈S, and z ∈T, and
proving G. More precisely this take statement is equivalent to
σ suffices assume new constant x ∈S,
new constant y ∈S,
new constant z ∈T
prove
G
followed by a proof that permits using only the domain formulas x ∈S,
y ∈S, and z ∈T.
In general, for the step σ take τ to be correct, the current goal should be
obviously equivalent to ∀τ : G for some formula G. (Again, the meaning of
“obviously equivalent” is not speciﬁed.) In that case, G is made the current
goal, constant declarations of the bound identiﬁers in τ are added to the
current set of declarations, and any formulas of the form id ∈e in τ are
added to the set of known facts and to the set of usable facts.
28

7.5.6
witness
A witness step consists of a step-starting token, followed by witness,
followed by a comma-separated list of expressions.
A witness step is
used to prove an existentially quantiﬁed formula by specifying instantia-
tions of its bound identiﬁers. There are two cases in which the statement
σ witness e1, . . . , ek is correct:
• The current goal is obviously equivalent to a formula ∃id1, . . . , idk :
G . In this case, the witness step is equivalent to
σ suffices G
proof obvious
where G is the formula obtained by substituting each ej for idj in G,
for j in 1 . . k.
• The
current
goal
is
obviously
equivalent
to
a
formula
∃ι1 ∈S1, . . . , ιk ∈Sk : G
where each ιj is an identiﬁer, there is
some substitution of expressions for these identiﬁers that transforms
each ιj ∈S j to ej , and each ej is easily provable from the current
set of usable facts. In this case, the formula obtained from G by the
aforementioned substitution of expressions for the identiﬁers in the ιj
is made the current goal, and the domain formulas ej are added to
the set of known facts and to the set of usable facts. (Adding a fact
that is easily provable to the set of usable facts might make additional
facts easily provable from that set.) For example, if the current goal
is
∃x, y ∈S, z ∈T : G(x, y, z)
then the step
⟨3⟩4. witness expX ∈S, expY ∈S, expZ ∈T
29

is equivalent to
⟨3⟩4. suffices G(expX , expY , expZ)
⟨4⟩1. expX ∈S
proof obvious
⟨4⟩2. expY ∈S
proof obvious
⟨4⟩3. expZ ∈T
proof obvious
⟨4⟩4. qed
by only ⟨4⟩1, ⟨4⟩2, ⟨4⟩3
7.6
Referring to Steps and Their Parts
Within a proof, steps and their parts can be named in three contexts: as
ordinary expressions, as facts in a by, use, or hide, and in the def clause
of one of those statements. We now consider these three possibilities.
7.6.1
Naming Subexpressions
Formulas
The name of a step that asserts a formula names that formula.
For example, the step
⟨2⟩3. x + y = z
deﬁnes ⟨2⟩3 to equal x + y = z . The step name ⟨2⟩3 can be used like any
other deﬁned symbol—for example:
⟨2⟩3 ∧(z ∈Nat) ⇒(x + y −z = 0)
We can also use labels and/or positional selectors to name subexpressions
of ⟨2⟩3 the same way we name subexpressions of other deﬁned symbols—for
example, ⟨2⟩3!⟨names the subexpression x + y . (See Section 6.)
assume/prove Steps
The parts of an assume/prove step are named as
explained in Section 6.4, where the step number names the assume/prove.
Thus, in
⟨3⟩4. assume
P, assume
Q
prove
R
prove
S
⟨3⟩4!1 names P, ⟨3⟩4!2!⟨names Q and ⟨3⟩4!3 names S.
30

As explained in Section 6.4, subexpressions of an assume/prove can
be used only within the scope of any identiﬁer that could appear in that
subexpression (even if it that identiﬁer doesn’t actually appear in it).
case, have, suffices, and witness Steps
Expressions within a case,
have, suffices, or witness step are named as if case, have, suffices,
and witness were preﬁx operators—case, have, and suffices taking a
single argument and witness taking an arbitrary number of arguments.
Thus, in
⟨2⟩3. case x + y > 0
⟨2⟩4. witness y, x + 1
⟨2⟩3!1 equals x + y > 0 and ⟨2⟩3!1!⟨equals x + y , while ⟨2⟩4!2 equals
x + 1.
The “argument” of suffices can be an assume/prove, whose
subexpressions are named as described above for an assume/prove step.
pick and take
A subformula of a pick step is named as if the pick were
replaced by ∀. For example, in
⟨3⟩4. pick x ∈S, y ∈T : x + y > 0
⟨3⟩4!2 names T and ⟨3⟩4!(e, f ) names e + f > 0. The naming of a take
step is similar, except that there is no “body” to name, only the sets that
follow an “ ∈”.
Note that the symbols introduced in a pick step are not declared within
the proof of that step, but they are declared after the proof.
However,
references to the body of the pick are made the same way in both places.
7.6.2
Naming Facts
Syntactically, any expression can be used as a fact. (A proof tool might
accept only a restricted set of expressions as facts.) Any named step that
makes an assertion can also be used as a fact. The only kinds of steps that
can not be used as facts are use, hide, deﬁnition, instance, and qed.
The scope of a step name includes the proof of the step. Thus, it is
legal to use a subexpression of a step named σ within that step’s proof—for
example, to name an assumption if σ is an assume/prove step.
When used by itself (and not in the name of one of its subexpressions),
a step name denotes the fact or facts that the step adds to the current set
of known facts. We now explain exactly what that means.
31

We have described above how every step that makes an assertion is
equivalent to one of the form A or suffices A, where A is either a for-
mula or an assume/prove. If we consider a formula G to be equivalent to
assume true prove G, then any step σ is equivalent to a step of the form
σ A or σ suffices A for an assume/prove A.
• For the step σ A, within the proof’s step the step name σ denotes the
set of assumptions of A; outside the proof it denotes A.
• For the step σ suffices A, within the proof’s step the step name σ
denotes A; outside the proof it denotes the set of assumptions of A.
It is quite useful to have a step name σ refer to the known facts introduced
into the current context by the step, since those facts are not automatically
added to the set of usable facts. However, it has the unfortunate eﬀect of
making a proof look circular when σ is used as a fact within the proof of
the step named σ. Readers and writers of TLA+ proofs should quickly get
used to this convention.
One may want to refer to a long formula G inside a step σ G. For ex-
ample, we can assume ¬G in a proof by contradiction of the step. However,
by these rules, σ names true within the proof of σ, so we cannot write ¬G
as ¬σ. We can write ¬G as ¬σ! : instead.
7.6.3
Naming Deﬁnitions
Only the names of deﬁned operators may appear in the def clause of a by
proof or a use or hide step. These include the names of operators deﬁned
in let clauses.
The step name of a define step may also be used in a
def clause. If the step deﬁnes more than one operator, then the step name
applies to all of them—but not to any operators deﬁned in let clauses
within those deﬁnitions.
Remember that an operator name does not contain any parameters or
any parentheses. For example, the expression Ins(42)!Foo(x, y) is an appli-
cation of the operator named Ins !Foo to the three arguments 42, x, and y.
Section 6.5 explains how to name operators deﬁned in a let clause.
7.7
Referring to Instantiated Theorems
Suppose module M contains a theorem
theorem T
32

and another module MI imports M with the statement
I
∆= instance M with . . .
As explained in Section 17.5.5 of Specifying Systems, this imports the theo-
rem that we can write in TLA+2 as
assume A1, . . . Ak
prove T
where A1, . . . , Ak are the assumptions asserted by assume statements in
M , and Ai and T are the formulas obtained from Ai and T by performing
the substitutions speciﬁed by the with clause.
If the theorem is named, as in
theorem Thm
∆= T
then I !Thm names the imported fact—the assume / prove above. How-
ever, the rules of Section 6.4 above for naming parts of an assume / prove
do not apply to this fact. The name I !Thm! : refers to the formula T . A
formula Ai can be referred to in module MI only if it has been assigned a
name in module M , in which case it is named I ! . . . as usual. Because TLC
cannot do anything with an assume / prove, it treats I !Thm (as well as
I !Thm! : ) as the name of T.
A proof of module MI that uses the imported theorem Thm generally
wants to use T. To do that, it must prove all its hypotheses Ai. Often,
the formulas Ai are simple consequences of the assumptions of module MI .
In that case, a proof can simply use I !Thm in a context in which those
assumptions of MI are usable facts.
7.8
Temporal Proofs
Temporal-logic reasoning has not yet been completely implemented in
TLAPS. Currently, TLAPS can perform only propositional temporal-logic
reasoning, meaning it can’t prove formulas that involve quantiﬁcation over
temporal formulas. We expect that a complete implementation will require
no changes to anything described in this document. However, since tempo-
ral logic is diﬀerent from ordinary logic, the reasoning involved in temporal
proofs is somewhat diﬀerent from what mathematicians are used to. This is
explained in Section 8.3 on page 35.
33

8
The Semantics of Proofs
8.1
The Meaning of Boolean Operators
As discussed in Section 16.1.3 of Specifying Systems, there are various ways
to deﬁne the meanings of the Boolean operators on non-Boolean arguments.
For example, we know that x ∧y equals y ∧x for any Booleans x and y.
However, is 5 ∧7 equal to 7 ∧5 ? TLAPS uses what is called in Specifying
Systems the liberal interpretation. In this interpretation, (5 ∧7) = (7 ∧5)
is true, and TLAPS will prove it.
The precise interpretation of the Boolean operators is in terms of an
operator ToBoolean such that ToBoolean(x) is some Boolean that equals x
if x is a Boolean. More precisely, ToBoolean is assumed to satisfy
∧∀x : ToBoolean(x) ∈boolean
∧∀x ∈boolean
: ToBoolean(x) = x
For example, we can deﬁne conjunction ∧by
x ∧y
∆=
ToBoolean(x) ∧ToBoolean(y)
where ∧is ordinary conjunction on Booleans.
The operator ToBoolean
exists only in the semantics and is not deﬁned at the TLA+ level. However,
it follows from the assumptions about ToBoolean that it can be deﬁned in
TLA+ by
ToBoolean(x)
∆=
(x ≡true)
8.2
The Meaning of assume/prove
An assume/prove essentially asserts that its assumptions imply its prove
formula. For example,
assume
A1,
new x ∈S,
A2
prove
B
asserts the formula
∀x : A1 ∧(x ∈S) ∧A2 ⇒B
except that x cannot be a free identiﬁer in A1 in the assume/prove.
If an assumption declares an operator, as in new op( , ), then trans-
lating the assume/prove to a formula would require quantiﬁcation over
the operator op, which can’t be done in ﬁrst-order logic. However, an as-
sume/prove (even with assumptions consisting of an assume/prove) can
34

be translated to a formula in which quantiﬁcation over operators occurs only
in outermost ∀quantiﬁers. Since an assume/prove can appear only as the
statement of a theorem or a proof step (which is a theorem asserted in a
certain context), TLA+ remains essentially in the realm of ﬁrst-order (tem-
poral) logic. It raises none of the issues associated with full second-order
logic.
8.3
Temporal Proofs
The meaning of temporal TLA+ formulas is explained in Chapter 8 of Spec-
ifying Systems. A temporal formula is a predicate on behaviors, which are
sequences of states. For a temporal formula F, the statement theorem F
asserts that F is true on all behaviors. As explained in Section 8.3 of that
book, TLA+ satisﬁes the following law:
Necessitation Rule For any formula F: if theorem F is true, then
theorem 2F is true.
(The book called it the Generalization Rule, but it’s called the Necessitation
Rule by logicians.) The Necessitation Rule is very diﬀerent from:
theorem assume
F
prove
2F
This statement is equivalent to
theorem F ⇒2F
which is not true for all formulas F.
The Necessitation Rule is important because many temporal proof rules
have assumptions of the form 2F. For example one commonly used rule is:
theorem BoxImplies
∆=
assume
temporal F, temporal G, 2F, 2(F ⇒G)
prove
2G
We use it to prove that if P is an invariant of a speciﬁcation Spec and P
implies Q, then Q is an invariant of Spec. In other words, we deduce
theorem QInvar
∆=
Spec ⇒2Q
from
theorem PInvar
∆=
Spec ⇒2P
theorem PimpliesQ
∆=
P ⇒Q
35

This deduction follows from BoxImplies because, by the Necessitation Rule,
theorem PImpliesQ implies the truth of theorem 2(P ⇒Q).
We would like to use the Necessitation Rule inside a proof, to deduce
2F from a proof step that asserts F.
However, that’s not sound.
For
example, suppose we are proving that Inv is an invariant of a speciﬁcation
Init ∧2[Next]v. Our proof might begin
⟨1⟩1. suffices assume
Init, 2[Next]v
prove
2Inv
⟨1⟩2. Inv
We can’t apply the Necessitation Rule to deduce 2Inv from step ⟨1⟩2. The
proof of ⟨1⟩2 could have used the assumption Init, so all we know is that
Inv is true of the initial state. We can’t conclude that it’s true of all states
in a behavior satisfying the speciﬁcation.
We need a generalization of the Necessitation Rule so it can be applied
to proof steps when it’s valid. For that, deﬁne a formula F to be a 2 formula
iﬀtheorem F ≡2F is true—that iﬀ, F is true on behavior β iﬀ2F is,
for any behavior β. Since 2F ⇒F is true for any formula F, we can also
deﬁne F to be a 2 formula iﬀtheorem F ⇒2F is true. For any formulas
F and G, the following formulas are all 2 formulas:
2F
32F
2F ∨2G
1 + 1 = 3
It follows from these that weak fairness (WF) and strong fairness (SF) for-
mulas are 2 formulas. We can now write:
Generalized Necessitation Rule
A proof of a formula F using
only assumptions that are 2 formulas proves 2F.
The Necessitation Rule follows from this because a theorem in a module
must be proved using only assume statements and previously proved theo-
rems, and the formula of an assume statement must be a constant, so it is
a 2 formula.
Currently, TLAPS can only perform propositional temporal reasoning;
it cannot reason about quantiﬁed temporal formulas. Using PTL in a by
clause tells TLAPS to use a propositional temporal-logic prover. (PTL uses
the Generalized Necessitation Rule.) We plan eventually to add a back-end
prover that can handle temporal formulas with constant quantiﬁcation—
that is, ones with the operators ∀and ∃. We would also like to add a way
for TLAPS to apply the rule
theorem assume
new temporal F( ), new state e
prove
F(e) ⇒∃∃∃∃∃∃x : F(x)
36

that justiﬁes proofs by reﬁnement mappings.
There is little incentive to
implement more general reasoning about temporal quantiﬁcation.
37

