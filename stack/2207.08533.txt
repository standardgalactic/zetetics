1
BrainCog: A Spiking Neural Network based
Brain-inspired Cognitive Intelligence Engine for
Brain-inspired AI and Brain Simulation
Yi Zeng, Dongcheng Zhao, Feifei Zhao, Guobin Shen, Yiting Dong, Enmeng Lu, Qian Zhang, Yinqian Sun, Qian
Liang, Yuxuan Zhao, Zhuoya Zhao, Hongjian Fang, Yuwei Wang, Yang Li, Xin Liu, Chengcheng Du, Qingqun
Kong, Zizhe Ruan, Weida Bi
Abstract—Spiking neural networks (SNNs) have attracted
extensive attentions in Brain-inspired Artificial Intelligence and
computational neuroscience. They can be used to simulate
biological information processing in the brain from multiple
scales, including membrane potential, neuronal firing, synap-
tic transmission, synaptic plasticity, and multiple brain areas
coordination. More importantly, SNNs serve as an appropriate
level of abstraction to bring inspirations from brain and cog-
nition to Artificial Intelligence. Existing software frameworks
support SNNs in machine learning, brain simulations, and
specific hardware devices from certain perspectives respectively.
However, the community requires an open-source platform that
can support building and integrating computational models for
brain-inspired AI and brain simulation at multiple scales. In
this paper, we present the Brain-inspired Cognitive Intelligence
Engine (BrainCog) for creating brain-inspired AI and brain
simulation models. BrainCog incorporates different types of
spiking neuron models, learning rules, brain areas, etc., as
essential modules provided by the platform. Based on these
easy-to-use modules, BrainCog supports various brain-inspired
cognitive functions, including Perception and Learning, Decision
Making, Knowledge Representation and Reasoning, Motor Con-
trol, and Social Cognition. These brain-inspired AI models have
been effectively validated on various supervised, unsupervised,
and reinforcement learning tasks, and they can be used to
enable AI models to be with multiple brain-inspired cognitive
functions. For brain simulation, BrainCog realizes the function
simulation of Drosophila decision-making and prefrontal cortex
working memory, the structure simulation of the Neural Circuit
Yi Zeng is with the Research Center for Brain-inspired Intelligence, the
National Laboratory of Pattern Recognition, at the Institute of Automation,
Chinese Academy of Sciences, Beijing 100190, China, and University of Chi-
nese Academy of Sciences, Beijing 100049, China, and Center for Excellence
in Brain Science and Intelligence Technology, Chinese Academy of Sciences,
Shanghai 200031, China. (e-mail: yi.zeng@ia.ac.cn, yi.zeng@braincog.ai).
Dongcheng Zhao, Feifei Zhao, Enmeng Lu, Qian Liang, Yuxuan Zhao,
Yuwei Wang, Xin Liu, Zizhe Ruan, and Weida Bi are with the Research Center
for Brain-inspired Intelligence, Institute of Automation, Chinese Academy
of Sciences, Beijing 100190, China. (e-mail: dongcheng.zhao@braincog.ai,
feifei.zhao@braincog.ai)
Guobin Shen, Yiting Dong, Yinqian Sun, Zhuoya Zhao, Hongjian Fang,
and Qingqun Kong are with the Research Center for Brain-Inspired In-
telligence, Institute of Automation, Chinese Academy of Sciences, Beijing
100190, China, and also with the School of Future Technology, Univer-
sity of Chinese Academy of Sciences, Beijing 100049, China. (e-mail:
guobin.shen@braincog.ai, yiting.dong@braincog.ai)
Qian Zhang, Yang Li and Chengcheng Du are with the Research Center
for Brain-Inspired Intelligence, Institute of Automation, Chinese Academy
of Sciences, Beijing 100190, China, and also with the School of Artificial
Intelligence, University of Chinese Academy of Sciences, Beijing 100049,
China.
Yi Zeng, Dongcheng Zhao, Feifei Zhao, Guobin Shen, and Yiting Dong
contributed equally to this work, and serve as co-first authors.
The corresponding author is Yi Zeng.
(Microcircuit and Cortical Column), and whole brain structure
simulation of Mouse brain, Macaque brain, and Human brain.
An AI engine named BORN is developed based on BrainCog,
and it demonstrates how the components of BrainCog can be
integrated and used to build AI models and applications. To
enable the scientific quest to decode the nature of biological
intelligence and create Artificial Intelligence, BrainCog aims to
provide necessary, easy-to-use, and essential building blocks,
and infrastructural support to develop brain-inspired spiking
neural network based Artificial Intelligence, and to simulate
the cognitive brains at multiple scales. The online repository of
BrainCog can be found at http://www.brain-cog.network.
Index Terms—Spiking Neural Network, Brain-inspired Cogni-
tive Intelligence Engine, Multi-scale Plasticity Principles, Brain
Simulation, Computational Neuroscience
I. INTRODUCTION
The human brain can self-organize and coordinate different
cognitive functions to flexibly adapt to complex and chang-
ing environments. A major challenge for Artificial Intelli-
gence and computational neuroscience is integrating multi-
scale biological principles to build biologically plausible brain-
inspired intelligent models. As the third generation of neural
networks [1], Spiking Neural Networks (SNNs) are more
biologically realistic at multiple scales, more biologically in-
terpretable, more energy-efficient, and naturally more suitable
for modeling various cognitive functions of the brain and
creating biologically plausible AI.
Existing neural simulators attempted to simulate elaborate
biological neuron models or build large-scale neural network
simulations, neural dynamics models, deep SNNs. Neuron [2]
focuses on simulating elaborate biological neuron models.
NEST [3] implements large-scale neural network simulations.
Brian/Brian2 [4], [5] provides an efficient and convenient
tool for modeling spiking neural networks. Shallow SNNs
implemented by Brian2 can realize unsupervised visual classi-
fication [6]. Further, BindsNET [7] builds SNNs with coordi-
nation of various neurons and connections and incorporates
multiple biological learning rules for training SNNs. Such
learning SNNs can perform machine learning tasks, including
simple supervised, unsupervised, and reinforcement learning.
However, supporting more complex tasks would be great
challenge for these SNNs frameworks, and there is a large
gap in performance compared with traditional deep neural
networks (DNNs). Deep SNNs trained by surrogate gradient
arXiv:2207.08533v2  [cs.NE]  12 Jul 2023

2
Fig. 1: The architecture of Brain-inspired Cognitive Intelligence Engine (BrainCog).
or converting well-trained DNNs to SNNs have achieved great
progress in the fields of speech recognition [8], [9], computer
vision [10], [11], and reinforcement learning [12]. Motivated
by this, SpikingJelly [13] develops a deep learning SNN
framework (trained by surrogate gradient or converting well-
trained DNNs to SNNs), which integrates deep convolutional
SNNs and various deep reinforcement learning SNNs for mul-
tiple benchmark tasks. Platforms as SpikingJelly are relatively
more inspired by the field of deep learning and focuse on
improving the performance of different tasks. They are cur-
rently lack of in-depth inspiration from the brain information
processing mechanisms and may not aim at, hence short at
simulating large scale functional brains.
BrainPy [14] excels at modeling, simulating, and analyzing
the dynamics of brain-inspired neural networks from multi-
ple perspectives, including neurons, synapses, and networks.
While it focuses on computational neuroscience research, it
fails to consider the learning and optimization of deep SNNs or
the implementation of brain-inspired functions. SPAUN [15],
a large-scale brain function model consisting of 2.5 million
simulated neurons and implemented by Nengo [16], integrates
multiple brain areas and realizes multiple brain cognitive func-
tions, including image recognition, working memory, question
answering, reinforcement learning, and fluid reasoning. How-
ever, it is not suitable for solving challenging and complex
AI tasks that can be handled by deep learning models. In
summary, there is still a lack of open-source spiking neural
network frameworks that could incorporate the ability of
simulating brain structures, cognitive functions at large scale,
while keep itself effective for creating complex and efficient
AI models at the same time.
Considering the various limitations of existing frameworks
mentioned above, in this paper, we present the Brain-inspired
Cognitive Intelligence Engine (BrainCog), a spiking neural
network based open source platform for both brain-inspired
AI and brain simulation at multiple scales. As shown in
Fig. 1, some basic modules (such as different types of neuron
models, learning rules, encoding strategies, etc.) are provided

3
as building blocks to construct different brain areas and
neural circuits to implement brain-inspired cognitive functions.
BrainCog is an easy-to-use framework that can flexibly replace
different components according to various purposes and needs.
BrainCog tries to achieve the vision “the structure and mech-
anism are inspired by the brain, and the cognitive behaviors
are similar to humans” for Brain-inspired AI [17]. BrainCog
is developed based on the deep learning framework (currently
it is based on PyTorch, while it is easy to migrate to other
frameworks such as PaddlePaddle, TensorFlow, etc.). This
approach aims at greatly facilitating researchers to quickly
familiarize themselves with the platform and implement their
own algorithms.
A. Brain-inspired AI
BrainCog is aimed at providing infrastructural support
for Brain-inspired AI. Currently, it provides cognitive func-
tions components that can be classified into five categories:
Perception and Learning, Decision Making, Motor Control,
Knowledge Representation and Reasoning, and Social Cog-
nition. These components collectively form neural circuits
corresponding to 28 brain areas in the mammalian brains, as
shown in Fig. 2. These brain-inspired AI models have been
effectively validated on various supervised and unsupervised
learning, deep reinforcement learning, and several complex
brain-inspired cognitive tasks.
Fig. 2: Multiple cognitive functions integrated in BrainCog,
their related brain areas and neural circuits.
1) Perception and Learning: BrainCog provides a variety
of supervised and unsupervised methods for training spiking
neural networks, such as the biologically-plausible Spike-
Timing-Dependent Plasticity (STDP) [18], the backpropaga-
tion based on surrogate gradients [19], [20], [21], and the
conversion-based algorithms [22], [23], [24]. In addition to
high performance in common perception and learning process,
it also shows strong adaptability in small samples and noisy
scenarios. BrainCog also provides a multi-sensory integration
framework for human-like concept learning [25]. Inspired by
quantum information theory, BrainCog provides a quantum
superposition spiking neural network, which encodes com-
plement information to neuronal spike trains with different
frequency and phase [26].
2) Decision Making: For decision making, BrainCog pro-
vides multi-brain areas coordinated decision-making spik-
ing neural network [27]. The biologically inspired decision-
making model implemented by BrainCog achieves human-like
learning ability on the Flappy Bird game and supports UAVs’
online decision-making tasks. In addition, BrainCog combines
SNNs with deep reinforcement learning and provides the
brain-inspired spiking deep Q network [28].
3) Motor Control: Embodied cognition is crucial to realiz-
ing biologically plausible AI. As part of the embodied cogni-
tion modules, and inspired by the motor control mechanism of
the brain, BrainCog provides a multi-brain areas coordinated
robot motion spiking neural networks model, which includes
premotor cortex (PMC), supplementary motor areas (SMA),
basal ganglia and cerebellum functions. With proper mapping,
the spiking motor network outputs can be used to control
various robots.
4) Knowledge Representation and Reasoning: BrainCog
incorporates multiple neuroplasticity and population coding
mechanisms for knowledge representation and reasoning. The
brain-inspired music memory and stylistic composition model
implements the knowledge representation and memory of
note sequences and can generate music according to different
styles [29], [30]. Sequence Production Spiking Neural Net-
work (SPSNN) achieves the memory of the symbol sequence
and can reconstruct the symbol sequence in the light of
different rules [31]. Commonsense Knowledge Representa-
tion Graph SNN (CKR-GSNN) realizes the representation of
commonsense knowledge through incorporating multi-scale
neural plasticity and population coding mechanism into a
graph SNN model [32]. Causal Reasoning Spiking Neural
Network (CRSNN) encodes the causal graph into a spiking
neural network and realizes deductive reasoning tasks accord-
ingly [33].
5) Social Cognition: BrainCog provides a brain-inspired
social cognition model with biological plausibility. This model
gives the agent a preliminary ability to perceive and understand
itself and others and can enable the robots pass the Multi-
Robots Mirror Self-Recognition Test [34] and the AI Safety
Risks Experiment [35]. The former is a classic experiment of
self-perception in social cognition, and the latter is a variation
and application of the theory of mind experiment in social
cognition.
B. Brain Simulation
1) Brain Cognitive Function Simulation: To demonstrate
the capability of BrainCog for cognitive function simula-
tion, we provide Drosophila decision-making and prefrontal
cortex working memory function simulation [36], [37]. For
Drosophila nonlinear and linear decision-making simulation,
BrainCog verifies the winner-takes-all behaviors of the nonlin-
ear dopaminergic neuron-GABAergic neuron-mushroom body
(DA-GABA-MB) circuit under a dilemma and obtains consis-
tent conclusions with Drosophila biological experiments [36].

4
For the working memory performance of the prefrontal cortex
network implemented by BrainCog, we discover that using
human neurons to replace rodent neurons without changing
network structure can significantly improve the accuracy and
completeness of an image memory task [37], and this implies
the evolution of the brains are not only on their structures, but
also applies to single computational units such as neurons.
2) Multi-scale Brain Structure Simulation: BrainCog pro-
vides simulations of brain structures at different scales, from
microcircuits, and cortical columns, to whole-brain structure
simulations. Anatomical and imaging multi-scale connectivity
data is used to support whole-brain simulations from mouse
brain, macaque brain to human brain at different scales.
II. BASIC COMPONENTS
BrainCog provides essential and fundamental components
to model biological and artificial intelligence. It includes
various biological neuron models, learning rules, encoding
strategies, and models of different brain areas. One can build
brain-inspired SNN models through reusing and refining these
building blocks. Expanding and refining the components and
cognitive functions included in BrainCog is an ongoing effort.
We believe this should be a continuous community effort,
and we welcome researchers and practitioners to enrich and
improve the work together in a complementary way.
A. Neuron Models
BrainCog supports various models for spiking neurons, such
as the following :
(1) Integrate-and-Fire spiking neuron (IF) [38]:
dV
dt = I
(1)
I denotes the input current from the pre-synaptic neurons.
Once the membrane potential reaches the threshold Vth, the
neuron j fires a spike [38].
(2) Leaky Integrate-and-Fire spiking neuron (LIF) [39]:
τ dV
dt = −V + I
(2)
τ = RC denote the time constant, R and C denotes the
membrane resistance and capacitance respectively [39].
(3) The adaptive Exponential Integrate-and-Fire spiking
neuron (aEIF) [40], [41]:





C dV
dt = −gL(V −EL) + gL exp(V −Vth
∆T
) + I −w
τw
dw
dt = a(V −EL) −w
(3)
where gL is the leak conductance, EL is the leak reversal
potential, Vr is the reset potential, ∆T is the slope factor, I is
the background currents. τw is the adaptation time constant.
When the membrane potential is greater than the threshold Vth,
V = Vr, and w = w +b. a is the subthreshold adaptation, and
b is the spike-triggered adaptation [40], [41].
(4) The Izhikevich spiking neuron [42]:





dV
dt = 0.04V 2 + 5v + 140 −u + I
du
dt = a(bv −u)
(4)
When the membrane potential is greater than the threshold:
(
V = c
u = u + d
(5)
u represents the membrane recovery variable, and a, b, c, d are
the dimensionless parameters [42].
(5) The Hodgkin-Huxley spiking neuron (H-H) [43]:
I = C dV
dt +gKn4(V −VK)+gNam3h(V −VNa)+gL(V −VL)
(6)













dn
dt = αn(V )(1 −n) −βn(V )n
dm
dt = αm(V )(1 −m) −βm(V )m
dh
dt = αn(V )(1 −h) −βn(V )h
(7)
αi and βi are used to control the ith ion channel, n, m,
h are dimensionless probabilities between 0 and 1. gi is the
maximal value of the conductance [43].
The H-H model shows elaborate modeling of biological neu-
rons. In order to apply it more efficiently to AI tasks, BrainCog
incorporates a simplified H-H model (C = 0.02µF/cm2, Vr =
0, Vth = 60mV ), as illustrated in [44].
B. Learning Rules
BrainCog provides various plasticity principles and rules to
support biological plausible learning and inference, such as:
(1) Hebbian learning theory [45]:
∆wt
ij = xt
ixt
j
(8)
where wt
ij means the ith synapse weight of jth neuron at the
time t. xt
i is the input of ith synapse at time t. xt
j is the output
of jth neuron at time t [45].
(2) Spike-Timing-Dependent Plasticity (STDP) [18]:
∆wj =
N
X
f=1
N
X
n=1
W(tf
i −tn
j )
W(∆t) =



A+e
−∆t
τ+
if ∆t > 0
−A−e
∆t
τ−
if ∆t < 0
(9)
where ∆wj is the modification of the synapse j, and W(∆t)
is the STDP function. t is the time of spike. A+, A−mean
the modification degree of STDP. τ+ and τ−denote the time
constant [18].
(3) Bienenstock-Cooper-Munros theory (BCM) [46]:
∆w = y (y −θM) x −ϵw
(10)
Where x and y denote the firing rates of pre-synaptic
and post-synaptic neurons, respectively, threshold θM is the
average of historical activity of the post-synaptic neuron [46].

5
(4) Short-term Synaptic Plasticity (STP) [47]:
Short-term plasticity is used to model the synaptic efficacy
changes over time.
ak = uk · Rk
(11)
uk+1 = U + uk(1 −U) exp (−∆tk/τfac)
(12)
Rk+1 = 1 + (Rk −ukRk −1) exp (−∆tk/τrec)
(13)
a denotes the synaptic weight, U denotes the fraction of
synaptic resources. τfac and τrec denotes the time constant
for recovery from facilitation and depression. The variable
Rnmodels the fraction of synaptic efficacy available for the
(k)th spike,and unRn models the fraction of synaptic effi-
cacy [47].
(5) Reward-modulated Spike-Timing-Dependent Plasticity
(R-STDP) [48]:
R-STDP uses synaptic eligibility trace e to store temporary
information of STDP. The eligibility trace accumulates the
STDP ∆wST DP and decays with a time constant τe [48].
∆e = −e
τe
+ ∆wST DP
(14)
Then, synaptic weights are updated when a delayed reward
r is received, as Eq. 15 shown [48].
∆w = r ∗∆e
(15)
C. Encoding Strategies
BrainCog supports a number of different encoding strategies
to help encode the inputs to the spiking neural networks.
(1) Rate Coding [49]:
Rate coding is mainly based on spike counting to ensure that
the number of spikes issued in the time window corresponds to
the real value. Poisson distribution can describe the number of
random events occurring per unit of time, which corresponds
to the firing rate [49]. Set α ∼U(0, 1), the input can be
encoded as
s(t) =
(
1,
if
x > α
0,
else
(16)
(2) Phase Coding [50]:
The idea of phase coding can be used to encode the analog
quantity changing with time. The value of the analog quantity
in a period can be represented by a spike time, and the change
of the analog quantity in the whole time process can be
represented by the spike train obtained by connecting all the
periods. Each spike has a corresponding phase weighting under
phase encoding, and generally, the pixel intensity is encoded
as a 0/1 input similar to binary encoding. ≫denotes the shift
operation to the right, K is the phase period [50]. Pixel x is
enlarged to x′ = x ∗(2K −1) and shifted k = K −1 −(t
mod K) to the right, where
mod is the remainder operation.
If the lowest bit is one, s will be one at time t. & means bit-
wise AND operation.
s(t) =
(
1,
if
(x′ ≫k)&1 = 1
0,
else
(17)
(3) Temporal Coding [51]:
The characteristic of the neuron spike is that the form of the
spike is fixed, and there are only differences in quantity and
time. The most common implementation is to express infor-
mation regarding the timing of individual spike. The stronger
the stimulus received, the earlier the spike generated [52]. Let
the total simulation time be T, and the input x of the neuron
can be encoded as the spike at time ts:
ts = T −round(Tx)
(18)
(4) Population Coding [53]:
Population coding helps to solve the problem of the am-
biguity of information carried by a single neuron. The am-
biguity of information carried can be understood as: the
original information is input into a neuron, which makes
the network hard to distinguish some overlapping or similar
related information [54], [55]. The intuitive idea of population
coding is to make different neurons to be with different
sensitivity to different types of inputs, which is also reflected in
biology. For example, rats’ whiskers have different sensitivity
to different directions [54]. The inputs will be transformed into
a spike train with a period by population coding. A classical
population coding method is the neural information coding
method based on the Gaussian tuning curve referred to Eq. 19.
This method is more suitable when the amount of data is
small, and the information is concentrated. A Gaussian neuron
covers a range of analog quantities in the form of Gaussian
function [53], [56]. Suppose that m (m > 2) neurons are used
to encode a variable x with a value range of [Imin, Imax].
f(x) can be firing time or voltage.
f(x) = x−(x−µ)2
2σ2
(19)
The corresponding mean with adjustable parameters β and
variance of the ith (i = 1, 2, ..., m) neuron are as follows:
µ = Imin + 2i −3
2
Imax −Imin
m −2
(20)
σ = 1
β
Imax −Imin
m −2
(21)
D. Brain Areas Models
Brain-inspired models of several functional brain areas are
constructed for BrainCog from different levels of abstraction.
(1) Basal Ganglia (BG):
Basal ganglia facilitates desired action selection and inhibit
competing behavior (making winner-takes-all decisions) [57],
[58]. It cooperates with PFC and the thalamus to realize the
decision-making process in the brain [59]. BrainCog models
the basal ganglia brain area, including excitatory and in-
hibitory connections among striatum, Globus pallidus internas
(Gpi), Globus pallidus external (Gpe), and subthalamic nucleus
(STN) of basal ganglia [60], as shown in the orange areas of
Fig. 14. The BG brain area component adopts the LIF neuron
model in BrainCog, as well as the STDP learning rule and
CustomLinear to build internal connections of the BG. Then,
the BG brain area component can be used to build brain-
inspired decision-making SNNs (see section 3.2.1 for detail).

6
(2) Prefrontal Cortex (PFC):
PFC is of significant importance when human high-level
cognitive behaviors happen. In BrainCog, many cognitive
tasks based on SNN are inspired by the mechanisms of the
PFC [61], such as decision-making, working memory [62],
[63], [64], knowledge representation [65], theory of mind
and music processing [66]. Different circuits are involved
to complete these cognitive tasks. In BrainCog, the data-
driven PFC column model contains 6 layers and 16 types of
neurons. The distribution of neurons, membrane parameters
and connections of different types of neurons are all derived
from existing biological experimental data. The PFC brain area
component mainly employs the LIF neuron model to simulate
the neural dynamics. The STDP and R-STDP learning rules
are utilized to compute the weights between different neural
circuits.
(3) Primary Auditory Cortex (PAC):
The primary auditory cortex is responsible for analyzing
sound features, memory, and the extraction of inter-sound
relationships [67]. This area exhibits a topographical map,
which means neurons respond to their preferred sounds. In
BrainCog, neurons in this area are simulated by the LIF
model and organized as minicolumns to represent different
frequencies of sounds. To store the ordered note sequences,
the excitatory and inhibitory connections are updated by STDP
learning rule.
(4) Inferior Parietal Lobule (IPL):
The function of IPL is to realize motor-visual associative
learning [68]. The IPL consists of two subareas: IPLM (mo-
tor perception neurons in IPL) and IPLV (visual perception
neurons in IPL). The IPLM receives information generated
by self-motion from ventral premotor cortex (vPMC), and the
IPLV receives information detected by vision from superior
temporal sulcus (STS). The motor-visual associative learning
is established according to the STDP mechanism and the
spiking time difference of neurons in IPLM and IPLV.
(5) Hippocampus (HPC):
The hippocampus is part of the limbic system and plays
an essential role in the learning and memory processes of
the human brain. Epilepsy patients with bilateral hippocampus
removed (e.g. the patient H.M.) have symptoms of anterograde
amnesia. They are unable to form new long-term declarative
memories [69]. This case study has proved that the hippocam-
pus is in the key process of converting short-term memory to
long-term memory and plays a vital role [70].
Furthermore, through electrophysiological means, it was
found that the hippocampal region is also crucial for forming
new concepts. Specific neurons in the hippocampus only re-
spond selectively to specific concepts, completing the specific
encoding between different concepts. Moreover, it was through
the study of the hippocampus that neuroscientists discovered
the STDP learning rule [71], which further demonstrated the
high plasticity of the hippocampus.
(6) Insula:
The
function
of
the
Insula
is
to
realize
self-
representation [72], that is, when the agent detects that
the movement in the field of vision is generated by itself, the
Insula is activated. The Insula receives information from IPLV
and STS. The IPLV outputs the visual feedback information
predicted according to its motion, and the STS outputs the
motion information detected by vision. If both are consistent,
the Insula will be activated.
(7) Thalamus (ThA):
Studies have shown that the thalamus is composed of a
series of nuclei connected to different brain parts and heavily
contributes to many brain processes. In BrainCog, this area is
discussed from both anatomic and cognitive perspectives. Un-
derstanding the anatomical structure of the thalamus can help
researchers to comprehend the mechanisms of the thalamus.
Based on the essential and detailed anatomic thalamocortical
data [73], BrainCog reconstructs the thalamic structure by
involving five types of neurons (including excitatory and
inhibitory neurons) to simulate the neuronal dynamics and
building the complex synaptic architecture according to the
anatomic results. Inspired by the structure and function of
the thalamus, the brain-inspired decision-making model imple-
mented by BrainCog takes into account the transfer function of
the thalamus and cooperates with the PFC and basal ganglia to
realize multi-brain areas coordinated decision-making model.
(8) Ventral Visual Pathway:
Cognitive neuroscience research has shown that the brain
can receive external input and quickly recognize objects due
to the hierarchical information processing of the ventral visual
pathway. The ventral pathway is mainly composed of V1,
V2, V4, IT, and other brain areas, which mainly process
information such as object shape and color [74], [75]. These
visual areas form connections through forward, feedback, and
self-layer projections. The interaction of different visual areas
enables humans to recognize visual objects. The primary visual
cortex V1 is selective for simple edge features. With the
transmission of information, high-level brain areas combine
with lower-level receptive fields to form more complex large
receptive fields to recognize more complex objects [76].
Inspired by the structure and function of the ventral visual
pathway, BrainCog builds a deep forward SNN with layer-
wise information abstraction and a feedforward and feedback
interaction deep SNN. The performance is verified on several
visual classification tasks.
(9) Motor Cortex:
The control of biological motor function involves the coop-
eration of many brain areas. The extra circuits consisting of the
PMC, cerebellum, and BA6 motor cortex area are primarily
associated with motor control elicited by external stimuli such
as visual, auditory, and tactual inputs. Internal motor circuits,
including the basal ganglia and SMA, predominate in self-
guided, learned movements [77], [78], [79]. Population activity
of motor cortical neurons encodes movement direction. Each
neuron has its preferred direction. The more consistent the
target movement direction is with its preferred direction, the
stronger the neuron activities are [80], [81]. The cerebellum
receives input from motor-related cortical areas such as PMC,
SMA, and the prefrontal cortex, which are important for the
completion of fine movements, maintaining balance and coor-
dination of movements [82]. Inspired by the organization of
the brain’s motor cortex, we use spiking neurons to construct
a motion control model, and apply it to the iCub robot, which

7
enables the robot to play the piano according to music pieces.
III. BRAIN-INSPIRED AI
Computational units (different neuron models, learning
rules, encoding strategies, brain area models, etc.) at multiple
scales, provided by BrainCog serve as a foundation to develop
functional networks. To enable BrainCog for Brain-inspired
AI, cognitive function centric networks need to be built and
provided as reusable functional building blocks to create more
complex brain-inspired AI. This section introduces various
functional building blocks developed based on BrainCog.
A. Perception and Learning
In this subsection, we will introduce the supervised and
unsupervised perception and learning spiking neural networks
based on the fundamental components of BrainCog. Inspired
by the global feedback connections, the neural dynamics
of spiking neurons, and the biologically plausible STDP
learning rule, we improve the performance of the spiking
neural networks. We show great adaption in the small training
sample scenario. In addition, our model has shown excellent
robustness in noisy scenarios by taking inspiration from the
multi-component spiking neuron and the quantum mechanics.
The burst spiking mechanism is used to help our converted
SNNs with higher performance and lower latency. Based on
this engine, we also present a human-like concept learning
framework to generate representations with five types of
perceptual strength information.
1. Learning Model
(1) SNN with global feedback connections
The spiking neural network transmits information in discrete
spike sequences, which is consistent with the information
processing in the human brain [1]. The training of spiking
neural networks has been widely concerned by researchers.
Most researchers take inspiration from the mechanism of
synaptic learning and updating between neurons in the human
brain, and propose biologically plausible learning rules, such
as Hebbian theory [45], STDP [18], and STP [83], which have
been adopted into the training of spiking neural networks [84],
[85], [6], [86], [87], [88]. However, most SNNs are based
on feedforward structures, while the importance of the brain-
inspired structures has been ignored. The anatomical and
physiological evidences show that in addition to feedforward
connections, numerous feedback connections exist in the brain,
especially among sensory areas [89], [90]. The feedback
connections will carry out the predictions from the top layer
to cooperate with the local plasticity rules to formulate the
learning and inference in the brain.
Here, we introduce the global feedback connections and the
local differential learning rule [91] in the training of SNNs.
We use the LIF spiking neuron model in the BrainCog to
simulate the dynamical process of the membrane potential
V (t) as shown in Eq. 2. We use the mean firing rates Sl
of each layer to denote the representation of the lth layer in
the forward pathway, and the corresponding target is denoted
as ˆSl. Here we use the mean squared loss (MSE) as the final
loss function.
output layer
input layer
Feedforward Pathway
Feedback Pathway
Fig. 3: The feedforward and feedback pathway in the SNN
model. The global feedback pathway propagates the target of
the hidden layer, modified from [91].
ˆSL−1 denotes the target of the penultimate layer, and is
calculated as shown in Eq. 22, WL−1 denotes the forward
weight between the (L−1)th layer and the Lth. ηt represents
the learning rate of the target [91].
ˆSL−1 = SL−1 −ηt∆S = SL−1 −ηtW T
L−1(Sout −ST ) (22)
The target of the other hidden layer can be obtained through
the feedback connections:
ˆSl = Sl −Gl(Sout −ST )
(23)
By combining the feedforward representation and feedback
target, we compute the local MSE loss. We can compute the
local update of the parameters with the surrogate gradient.
We have conducted experiments on the MNIST and Fashion-
MNIST datasets, and achieved 98.23% and 89.68% test accu-
racy with three hidden layers. Each hidden layer is set with
800 neurons. The details are shown in Fig. 4.
0
20
40
60
80
100
Epochs
84
86
88
90
92
94
96
98
100
Accuracy
MNIST
Train
Test
0
20
40
60
80
100
Epochs
75
80
85
90
95
100
Accuracy
FashionMNIST
Train
Test
Fig. 4: The test accuracy on MNIST and Fashion-MNIST
datasets of the SNNs with global feedback connections.
(2) Biological-BP SNN
The backpropagation algorithm is an efficient optimization
method that is widely used in deep neural networks and has
promoted the great success of deep learning. However, due to
the non-smoothness of neurons in SNNs, the backpropagation
optimization is difficult to be applied to train SNNs directly.
To solve the above problem, Bengio et al. [92] proposed four
gradient approximation methods, including Straight-Through
Estimator to enable the application of the backpropagation
algorithm to neural networks containing nonsmooth neurons.
Wu et al. [19] proposed the Spatio-Temporal Backpropagation

8
(STBP) algorithm to train SNNs by using a differentiable
function to approximate spiking neurons through a surro-
gate gradient method. Based on the spatio-temporal dynamic
of SNNs, they achieved the backpropagation of SNNs in
both time and space dimensions. Zheng et al. [20] proposed
threshold-dependent batch normalization (tdBN) to improve
the performance of deep SNNs. Fang et al. [21] proposed a
parametric LIF (PLIF) model to further improve the perfor-
mance of SNNs by optimizing the time constants of neurons
during the training process.
Most of these BP-based SNNs often simply regard SNN as a
substitute for RNN, but ignore the dynamic of spiking neurons.
To solve the problem of non-differentiable neuronal models,
Bohte et al. [93] approximated the backpropagation process
of neuronal models using the surrogate gradient method.
However, this method results in gradient leakage and does
not allow for proper credit assignment in both temporal and
spatial dimensions. Also, due to the reset operation after the
spikes are emitted, the errors in the backward process can
not propagate across spikes. To solve the above problem, we
propose Backpropagation with biologically plausible spatio-
temporal adjustment [94], as shown in Fig. 5, which can
correctly assign credit according to the contribution of the
neuron to the membrane potential at each moment.
𝑤𝑙−1
𝑤𝑙−1
𝑠
𝑣𝑡ℎ
𝑤𝑙−1
𝑤𝑙−1
𝑠
𝑣𝑡ℎ
𝑠
𝑣𝑡ℎ
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
𝑆𝑝𝑎𝑡𝑖𝑜
𝑠
𝑣𝑡ℎ
Fig. 5: The forward and backward process of biological BP-
based SNNs for BrainCog.
Based on LIF spiking neuron, the direct input encoding
strategy, the MSE loss function and the surrogate gradient
function supplied in BrainCog, we propose a Biologically
Plausible Spatio-Temporal Adjustment (BPSTA) to help BP
algorithm with more reasonable error adjustment in the spatial
temporal dimension [94]. The algorithm realizes the reason-
able adjustment of the gradient in the spatial dimension, avoids
the unnecessary influence of the neurons that do not generate
spikes on the weight update, and extracts more important
features. By applying the temporal residual pathway, our
algorithm helps the error to be transmitted across multiple
spikes, and enhances the temporal dependency of the BP-
based SNNs. Compared with SNNs and ANNs with the same
structure that only used the BP algorithm, our model greatly
improves the performance of SNNs on the DVS-CIFAR10 and
DVS-Gesture datasets, while also greatly reducing the energy
consumption and decay of SNNs, as shown in Tab. I.
(3) Unsupervised STDP-based SNN
TABLE I: The energy efficiency study. The former repre-
sents our method, the latter represents the baseline, adopted
from [94].
Dataset
Accuracy
Firing-rate
EE = EANN
ESNN
MNIST
99.58%/99.42%
0.082/0.183
35.1x/15.7x
N-MNIST
99.61%/99.32%
0.097/0.176
29.6x/16.3x
CIFAR10
92.33%/89.49%
0.108/0.214
26.6x/13.4x
DVS-Gesture
98.26%/93.92%
0.083/0.165
34.6x/17.4x
DVS-CIFAR10
77.76%/71.40%
0.097/0.177
29.5x/16.2x
Adaptive Lateral 
Inhibition Connection
ASF
Adaptive 
Synaptic Filter
Adaptive 
Threshold Balance
Conv
Pooling
SpikeNorm
FC
Voting
Fig. 6: The framework of the unsupervised STDP-based
spiking neural network model, which introduces the adaptive
synaptic filter (ASF), the adaptive threshold balance (ATB),
and the adaptive lateral inhibitory connection (ALIC) mech-
anisms to improve the information transmission and feature
extraction of STDP-based SNNs. This figure is from [95].
Unsupervised learning is an important cognitive function of
the brain. The brain can complete the task of object recognition
by summarizing the characteristics and features of objects.
Unsupervised learning does not require explicit labels, but
extracts the features of samples adaptively in learning process.
Modeling of this ability of the brain is critical. There are
multiple learning rules in the brain to accomplish various
learning tasks. STDP is a widespread rule of synaptic weight
modification in the brain. It updates the synaptic weights
according to the temporal relationship of the pre- and post-
synaptic spikes. Compared with the backpropagation algorithm
widely used in DNN with gradient calculation, STDP is more
biological plausible. However, unlike the backpropagation
algorithm that relies on a large number of sample labels, STDP
is a local optimization algorithm. Due to the lack of global
information, the ability of self-organization and coordination
between neurons is insufficient. In the SNN model, it will
lead to disorder and uncertainty of spikes discharge, and
it is difficult to achieve a stable release balance state of
neurons. To this end, we design an unsupervised STDP-based
spiking neural network model based on BrainCog, and bring
unsupervised learning to BrainCog as a functional module. As
shown in Fig. 6.
To solve the above problems, we introduced various adap-
tive mechanisms to improve the self-organization ability of the
overall network. STP is another synaptic learning mechanism
that exists in the brain. Inspired by STP, we designed an
adaptive synaptic filter (ASF) that integrates input currents
through nonlinear units, and an adaptive threshold balance
(ATB) that dynamically changes the threshold of each neuron

9
I  >> Vthreshold
I << Vthreshold
Adaptive 
Synaptic Filter
Adaptive Threshold 
Balance
ASF
Sample 1
Sample 2
Sample 3
Sample 4
(a) Adaptive Synapse Filter (ASF) and Adpative Threshold Balance (ATB)
(b) Adaptive Lateral Inhibition Connection (ALIC)
Fig. 7: (a) The adaptive synaptic filter and the adaptive
threshold balance jointly regulate the neuron spikes balance
of neuron. (b) The adaptive lateral inhibitory connection has
different connections for different samples, preventing neurons
from learning the same features. This figure is from [95].
to avoid excessively high or low firing rates. The combination
of the two controls the firing balance of neurons. As the
Fig. 7 shows. We also address the problem of coordinating
neurons within a single layer with an adaptive lateral inhibitory
connection (ALIC). The mechanism have different connection
structures for different input samples. Finally, in order to solve
the problem of low efficiency of STDP training, we designed a
sample temporal batch STDP. It combines the information be-
tween temporal and samples to uniformly update the synaptic
weights, as shown by the following formula.
dw(t)
j
dt
+
=
Nbatch
X
m=0
Tbatch
X
n=0
N
X
f=1
W(tf,m
i
−tn,m
j
)
(24)
where W(x) is the function of STDP, Nbatch is the batchsize
of the input, Tbatch is the batch of time step, N is the number
of neurons. We verified our model on MNIST and Fashion-
MNIST, achieving 97.9% and 87.0% accuracy, respectively.
To the best of our knowledge, these are the state-of-the-art
results for unsupervised SNNs based on STDP.
2. Adaptability and Optimization
(1) Quantum superposition inspired SNN
In the microscopic size, quantum mechanics dominates the
rules of operation of objects, which reveals the probabilistic
and uncertainties of the world. New technologies based on
quantum theory like quantum computation and quantum com-
munication provide an alternative to information processing.
Researches show that biological neurons spike at random and
the brain can process information with huge parallel potential
like quantum computing.
Inspired from this, we propose the Quantum Superposition
Inspired Spiking Neural Network (QS-SNN) [26], comple-
menting quantum image (CQIE) method to represent image
in the form of quantum superposition state and then transform
this state to spike trains with different phase. Spiking neural
network with time differential convolution kernel (TCK) is
used to do further classification shown in Fig. 8.
Fig. 8: Quantum superposition inspired spiking neural net-
work, adopted from [26].
Fig. 9: Performance of QS-SNN on background MNIST
inverse image, adopted from [26].
The effort tries to incorporate the quantum superposition
mechanism to SNNs as a new form of encoding strategy
for BrainCog, and the model finally shows its capability on
robustness for learning. The proposed QS-SNN model is tested
on color inverted MNIST datasets. The background-inverted
picture is encoded in the quantum superposition form as shown
in Eq. 25 and 26.
|I(θ)⟩= 1
2n
22n−1
X
i=0
(cos(θi) |xi⟩+ sin(θi) |¯xi⟩) ⊗|i⟩,
(25)
θi ∈[0, π
2 ], i = 1, 2, 3, . . . , 22n −1.
(26)

10
Spike sequences of different frequencies and phases are
generated from the picture information of the quantum super-
position state. Furthermore we use two-compartment spiking
neural networks to process these spike trains.
We compare the QS-SNN model with other convolutional
models. The result in Fig. 9 shows that our QS-SNN model
overtakes other convolutional neural networks in recognizing
background-inverted image tasks.
(2) Unsupervised SNN with adaptive learning rule and
structure
Brain can accomplish specific tasks by adaptively learning
to organize the features of a small number of samples. Few-
shot learning is an important ability of the brain. In the above
section, an unsupervised STDP-based spiking neural network
is introduced [95]. To better illustrate the power of our model
on small sample training, we tested the model with small
samples and find that this model has stronger small sample
processing ability than ANN with similar structures, as shown
in Tab. II [95].
TABLE II: The performance of unsupervised SNN compared
with ANN on MNIST dataset with different number of training
samples [95].
samples
200
100
50
10
ANN
79.77%
71.40%
68.72%
47.12%
Ours
81.45%
75.44%
72.88%
51.45%
1.68%
4.04%
4.16%
4.33%
(3) Efficient and Accurate Conversion of SNNs
SNNs have attracted attention due to their biological plau-
sibility, fast inference, and low energy consumption. However
the training methods based on the plasticity [96] and surrogate
gradient algorithms [11] need much memory and perform
worse than ANN on large networks and complex datasets. For
users of BrainCog, we are certain there will be clear need to
use SNNs while keep the benifit from ANNs. As an efficient
method, the conversion method combines the characteristics of
backpropagation and low energy consumption and can achieve
the same excellent performance as ANN with lower power
consumption [22], [23], [24]. However, the converted SNNs
typically suffer from severe performance degradation and time
delays.
Fig. 10: The conversion errors from IF neuron, time dimen-
sion, and MaxPooling, adopted from [97].
We divide the performance loss to IF neurons, time di-
mension, and MaxPooling layer [97], as shown in Fig. 10.
In SNN, the neuron can only send one spike at most in each
time step, so the maximum firing rate of the neuron is 1. After
normalizing the weight of trained ANN, some activation values
greater than 1 cannot be effectively represented by IF neurons.
Therefore, the residual membrane potential in neurons will
affect the performance of the conversion to some extent. In
addition, since IF receives pre-synaptic neuron spikes for
information transmission, the synaptic current received by
the neuron at each time is unstable, but its sum can be
approx to the converted value by increasing the simulation
time. However, the total number of spikes is the time-varying
extremum of the sum of the synaptic currents received. When
the activation value corresponding to the IF neuron is negative
and the total synaptic current received by the neuron in a short
time exceeds the threshold, the neuron that should be resting
will issue the spike, and the influence of the spike on the
later layers cannot be eliminated by increasing the simulation
time. Finally, in the conversion of the MaxPooling layer, the
previous work has enabled spikes from the neuron with the
maximum firing rate to pass through. However, due to the
instability of synaptic current, neurons with the maximum
firing rate are often not fixed, which makes the output of the
converted MaxPooling layer usually larger.
a
b
c
Fig. 11: The conversion methods. (a) Burst spikes increase the
upper limit of firing rates; (b) spike calibration corrects the
effect of faulty spikes on conversion, and (c) LIPooling uses
lateral inhibition mechanisms to achieve accurate conversion
of the MaxPooling layers. Refined based on [97], [98].
To solve the problem of the residual membrane potential
of neurons, we introduce the burst mechanism, as shown
in Fig. 11 (a), which enables neurons to send more than
one spike between two time steps, depending on the current
membrane potential. Once some neurons have residual infor-
mation remaining, they can send spikes between two time
steps. In this way, the firing rate of SNN can be increased,
and the membrane potential remaining in the neuron can be
transmitted to the neuron of the next layer.
For classification problems, SNN only needs to ensure that
the index of the maximum output is correct, but for more
demanding conversion tasks, such as object detection, the

11
solution of SIN problem is worth exploring. Note that the
spikes emitted by hidden layer neurons are unstable, but the
mean of its inter-spike interval distribution is related to its
corresponding activation value [98]. We monitor each neuron’s
spiking time in the forward propagation process and update its
average inter-spike interval, as shown in Fig. 11 (b). Under a
certain time allowance, the neuron that does not emit spikes
will be determined to be Inactivated Neuron. Then, the twin
weights emit spikes to suppress the influence of historical
errors and calibrate the influence of wrong spikes to a certain
extent to ensure accurate conversion.
Inspired by the lateral inhibition mechanism [99], we pro-
pose LIPooling for converting the maximum pooling layer,
as shown in Fig. 11 (c). From the operation perspective, the
inhibition of other neurons by the winner in LIPooling is -1, so
the neuron with the largest firing rate at the current time step
may not spike due to the inhibition of other neurons in history.
From the output perspective, LIPooling sums up the output of
all neurons during simulation. So the key is that LIPooling uses
competition between neurons to get an accurate sum (equal to
the actual maximum), instead of picking the winner.
3. Multi-sensory Integration
One can build SNN models through BrainCog to process
different types of sensory inputs, while the human brain learns
and makes decisions based on multi-sensory inputs. When
information from various sensory inputs is combined, it can
lead to increased perception, quicker response times, and
better recognition. Hence, enabling BrainCog to process and
integrate multi-sensory inputs are of vital importance.
In this section, we focus on concept learning with multi-
sensory inputs. We present a multi-sensory concept learning
framework based on BrainCog to generate integrated vectors
with the multi-sensory representation of the concept.
Embodied theories, which emphasize that meaning is rooted
in our sensory and experiential interactions with the envi-
ronment, supports multi-sensory representations. Based on
SNNs, we present a human-like framework to learn concepts
which can generate integrated representations with five types
of perceptual strength information [25]. The framework is
developed with two distinct paradigms: Associate Merge (AM)
and Independent Merge (IM), as Fig. 12 shows.
Fig. 12: The Framework of Concept Learning Based on SNNs
with multi-sensory Inputs.
IM is based on the widely accepted cognitive psychology
premise that each type of sense for the concept is independent
before integration [25]. As the input to the model, we will
employ five common perceptual strength: visual, auditory, hap-
tic, olfactory and gustatory. During the data preparation step,
we min-max normalize all kinds of perceptual strength of the
concept in the multi-sensory dataset so that each value of the
vector is in [0, 1]. We regard them as stimuli to the presynaptic
neurons. It’s a 2-layer SNN model, with 5 neurons in the first
layer matching the concept’s 5 kinds of perceptual strength,
and 1 neuron in the second layer representing the neural state
following multi-sensory integration. In this paradigm, we use
perceptual strength based presynaptic Poisson neurons and LIF
or Izhikevich as the postsynaptic neural model.
The weights between the neurons are W i =
gi
Σn
i gi where
gi
=
1
σ2
i ,σ2
i
is the variance of each kind of percep-
tual strength. We convert the postsynaptic neuron’s spiking
train Spost([0, T]) in [0, T] into integrated representations
BIM([0, T]) for the concept in this form:
BIM([0, T]) = [T (Spost((0, tol])), T (Spost((tol, 2 ∗tol])), · · · ,
T (Spost(((k −1) ∗tol, k ∗tol])), · · · ,
T (Spost((⌊T
tol⌋∗tol, T]))]
(27)
Here if the interval has any spikes, the bit is 1. Otherwise it
is 0, according to the T (interval) function.
The AM paradigm presupposes that each kind of modality
is associated before integration [25]. It includes 5 neurons,
matching the concept’s 5 distinct modal information sources.
They are linked with each other and are not self-connected.
The input spike trains to the network are generated using
a Poisson event-generation algorithm based on perceptual
strength. For each concept, we turn the spike trains of these
neurons into the ultimate integrated representations.
The weight value is defined by the correlation between
each two modalities, i.e. W
= Corr(i, j), where i, j ∈
[A, G, H, O, V ]. We convert the spike trains Si([0, T]) of all
neurons into binarycode Bi([0, T]) and conjoin them as the
ultimate vector B([0, T]) as follows:
Bi([0, T]) = [T (Si((0, tol])), T (Si((tol, 2 ∗tol])), · · · ,
T (Si(((k −1) ∗tol, k ∗tol])), · · · ,
T (Si((⌊T
tol⌋∗tol, T]))]
(28)
BAM([0, T]) = [BA([0, T]) ⊕BH([0, T]) ⊕BG([0, T])
⊕BO([0, T]) ⊕BV ([0, T])]
(29)
To test our framework, we conducted experiments with
three multi-sensory datasets (LC823 [100], [101], BBSR [102],
Lancaster40k [103]) for the IM and AM paradigms, respec-
tively. We used WordSim353 [104] and SCWS1994 [105] as
metrics [25]. The resuls show that integrated representations
are closer to human beings than the original ones based on
our framework, according to the overall results: 37 submod-
els outperformed a total of 48 tests for both AM and IM
paradigm [25]. Meanwhile, to compare the two paradigms, we
introduce concept feature norms datasets which represent con-
cepts with systematic and standardized feature descriptions. In

12
this study, we use the datasets McRae [106] and CSLB [107]
as criteria. The findings show that the IM paradigm performs
better at multi-sensory integration for concepts with higher
modality exclusivity. The AM paradigm benefits the concept
of uniform perceptual strength distribution. Furthermore, we
present perceptual strength-free metrics to demonstrate that
both paradigms of our framework have excellent general-
ity [25].
Fig. 13: The Correlation Results Between Modality Exclusiv-
ity and Average of 3 Neighbors’ Rankings.
B. Decision Making
This subsection introduces how BrainCog implements
decision-making functions from the perspective of brain neu-
ral mechanism modeling and deep SNN-based reinforcement
learning models. Using BrainCog, we build a multi-brain areas
coordinated SNN model and a spiking deep Q-network to
solve decision-making and control problems.
1. Brain-inspired Decision-Making SNN
For mammalian brain-inspired decision-making, we take
inspiration from the PFC-BG-ThA-PMC neural circuit and
build brain-inspired decision-making spiking neural network
(BDM-SNN) model [27] by BrainCog as shown in Fig. 14.
BDM-SNN contains the excitatory and inhibitory connections
within the basal ganglia nuclei and direct, indirect, and hyper-
direct pathways from the PFC to the BG [108], [109]. This
BDM-SNN model incorporates biological neuron models (LIF
and simplified H-H models), synaptic plasticity learning rules,
and interactive connections among multi-brain areas developed
by BrainCog. On this basis, we extend the dopamine (DA)-
regulated BDM-SNN, which modulates synaptic learning for
PFC-to-striatal direct and indirect pathways via dopamine.
Different from the DA regulation method in [27] which
uses multiplication to modulate the specified connections, we
improve it by introducing R-STDP [48] (from Eq. 14 and
Eq. 15) to modulate the PFC-to-striatal connections.
The BDM-SNN model implemented by BrainCog could
perform different tasks, such as the Flappy Bird game and has
Fig. 14: The architecture of DA-regulated BDM-SNN, refined
based on [27].
the ability to support UAV online decision-making. For the
Flappy Bird game, our method achieves a performance level
similar to humans, stably passing the pipeline on the first try.
Fig. 15a illustrates the changes in the mean cumulative rewards
for LIF and simplified H-H neurons while playing the game.
The simplified H-H neuron achieves similar performances to
that of LIF neurons. BDM-SNN with different neurons can
quickly learn the correct rules and keep obtaining rewards.
We also analyze the role of different ion channels in the
simplified H-H model. From Fig. 15b, we find that sodium and
potassium ion channels have opposite effects on the neuronal
membrane potential. Removing sodium ion channels will make
the membrane potential decay, while the membrane potential
rises faster and fires earlier when removing potassium ion
channels. These results indicate that sodium ion channels
can help increase the membrane potential, and potassium
ion channels have the opposite effect. Experimental results
also indicate that BDM-SNN with simplified H-H model that
removes sodium ion channels fails to learn the Flappy Bird
game.
Fig. 15: (a) Experimental result of BrainCog based BDM-SNN
on Flappy Bird. The y-axis is the mean of cumulative rewards.
(b) Effects of different ion channels on membrane potential for
simplified H-H model.
In addition, for the UAV decision-making tasks in the real
scene, our model could perform potential applications includ-
ing flying over doors and windows and obstacle avoidance,
which have been realized in [27]. Users only need to divide

13
the state space and action space according to different tasks,
call the DA-regulated BDM-SNN decision-making model, and
combine the UAV’s action control instructions to complete the
UAV’s decision-making process.
This part of the work mainly draws on the neural struc-
ture and learning mechanism of brain decision-making and
proposes the multi-brain areas coordinated decision-making
spiking neural network constructed by BrainCog, and verifies
the ability of reinforcement learning in different application
scenarios.
2. Spiking Deep Q Network with potential based layer
normalization
Deep Q network is widely used for decision-making tasks,
and it is required to have SNN based deep Q network for
BrainCog so that it can be used for SNN based decision mak-
ing. We propose potential-based layer normalization spiking
deep Q network (PL-SDQN) model to combine SNN with
deep reinforcement learning [28]. We use the LIF neuron
model in BrainCog to simulate neurodynamics. Deep spiking
neural networks are difficult to be applied to reinforcement
learning tasks. On the one hand, it is due to the complexity
of reinforcement learning task itself, on the other hand, it
is challenging to train spiking neural networks and transmit
spiking signal characteristics in deep layers. We find that the
spiking deep Q network quickly dissipates the spiking signal
in the convolutional layer. Inspired by how local environmental
potentials influence brain neurons, we propose the potential-
based layer normalization (pbLN) method. The xt, the post-
synaptic potential of convolution layers, are normalized as
ˆxt = xt −¯xt
√σxt + ϵ
(30)
¯xt = 1
H
H
X
i=1
xt,i
(31)
σxt = 1
H
v
u
u
t
H
X
i=1
(xt,i −¯xt)
(32)
We construct PL-SDQN model as shown in Fig. 16. Atari
game images are processed by spiking convolution network
and pbLN method and input into a fully connected LIF neural
network. The spiking output of PL-SDQN is weighted and
summed to continue state-action values.
Conv
pbLN
Conv
FC
Value
pbLN
Fig. 16: The framework of PL-SDQN. Refined from [28].
We compared our model with the original ANN-based DQN
model, and the results are shown in Fig. 17. It shows that
our model achieved better performance compared with vanilla
DQN model.
Breakout
Score
Step
1e7
CrazyClimber
Step
1e7
1e7
MsPacman
Step
1e7
NameThisGame
Score
Step
1e7
SpaceInverder
1e7
Step
VideoPinball
Step
1e7
Fig. 17: PL-SDQN performance on Atari games, adopted
from [28].
C. Motor Control
Neuromorphic models on robot control can achieve more
robust and energy efficient effects than conventional methods.
Spiking neural networks have been used in robot control
studies like navigation [110] and robot arm control [111].
Inspired by the brain motor circuit, we construct a multi-
brain areas coordinated SNN robot motor control model, to
extend BrainCog to control various robots to model embodied
intelligence.
We construct the brain-inspired motor control model with
LIF neuron provided by BrainCog. The whole network model
architecture is shown in Fig. 18. The high-level motion infor-
mation is produced by SMA and PMC modules. As discussed
above, the function of SMA is to process internal movement
stimuli and is responsible for the planning and abstraction of
advanced actions. The SMA model contains LIF neurons and
receives input signals. One part of the output pulse of the
SMA module stimulates the PMC module, and the other part
is received by the BG module. The output of the BG module is
used as a supplementary signal for action planning, and serves
as the input to the PMC together with the SMA signal.
SMA
Basal ganglia
PMC
Population coding
GC
PC
DCN
Cerebellum
Fusion
Input
Signal
Control 
Signal
Fig. 18: A spiking neural network for motor control based on
BrainCog.
In order to expand the dimension of neuron direction
representation, we use neuron population coding to output
the high-level action abstraction. Population-coded spiking
neural network has been used for energy-efficient continuous
control [112], showing population coding can increase the
ability of spiking neurons to represent precise continuous
values. In our work, we are inspired by neural mechanisms
of population encoding of motion directions in the brain and
use LIF neuron groups to process the output spikes from PMC
module.

14
The cerebellum plays an important role in motor coordi-
nation and fine regulation of movements. We built spiking
neural network based cerebellum model to process the high-
level motor control population embedding. The outputs of
populations are fused to encode motor control information
generated by high-level cortex area inputs to a three-layer
cerebellum spiking neural network, including GCs, PCs and
DCN modules. And the cerebellum takes pathway connections
like DenseNet [113]. The DCN layer generates the final joint
control outputs.
D. Knowledge Representation and Reasoning
This subsection shows how the BrainCog platform achieve
the ability of knowledge representation and reasoning. Via
neuroplasticity and population coding mechanisms, spiking
neural networks acquire music and symbolic knowledge.
Moreover, on this basis, cognitive tasks such as music gener-
ation, sequence production, deductive reasoning and inductive
reasoning are realized.
1. Music Memory and Stylistic Composition SNN
Music is part of human nature. Listening to melodies in-
volves sensory perception, personal memory, action, emotion,
and even creative behaviors, etc [67]. Music memory is a fun-
damental part of musical behaviors, and humans have strong
abilities to store a sequence of notes in the brain. Learning
and creating music are also essential processes. A musician
engages his memory, emotion, musical knowledge and skills to
write a beautiful melody. Actually, neuroscientists have found
that many brain areas need to collaborate to complete the
cognitive behaviors with music. Inspired by brain mechanisms,
this paper focuses on the two key issues of music memory and
composition, which are modeled by spiking neural networks
based on the BrainCog platform.
1) Musical Memory Spiking Neural Network: A musical
melody is composed of a sequence of notes. Pitch and duration
are two essential attributes of a note. Scientists have found
that the primary auditory cortex provides a tonotopic map
to encode the pitches, which means that neurons in this
region have their preferences of pitches [114]. Meanwhile,
neural populations in the medial premotor cortex have the
preferences of all the time intervals covered in hundreds of
milliseconds [115]. Besides, researchers have emphasized the
contribution of the hippocampus in sequence memory [116].
Inspired by these mechanisms, this work proposes a spiking
neural model, which contains collaborated subnetworks to
encode, store and retrieve the music melodies [29].
Encoding: As is shown in Fig. 19, this work defines pitch
subnetwork and duration subnetwork to encode pitches and
durations of musical notes respectively. These two subnet-
works are composed of numbers of minicolumns with different
preferences. Synaptic connections with transmission delays
exist between neurons from different layers. Besides, a cluster
that represents the title of a musical melody is composed
of numerous individual neurons. This cluster has the feed-
forward and feedback connections with pitch and duration
subnetworks. Since the BrainCog platform supports various
neural models, this work takes LIF model to simulate neural
dynamics.
Fig. 19: The architecture of the music memory model, refined
based on [29].
Storing: Based on the encoding process, as the notes input
sequently, the neurons in pitch and duration subnetworks with
different preferences respond to these sequential notes and
fire orderly. Meanwhile, connections between these neurons
are computed and updated by the STDP learning rule. It is
important to indicate that the neurons and synapses are grown
dynamically. Besides, synaptic connections between the title
cluster and other two subnetworks are generated and updated
by the STDP learning rule simultaneously. The details of note
sequence memorizing can be found in our previous work [29].
Retrieving: Given the title of a musical work, the ordered
notes can be recalled accurately. Since the weights of con-
nections are updated in storing process, neural activities in
the title cluster lead to the excitations of neurons in pitch
and duration subnetworks. Then, the notes are retrieved in
order. We use a public corpus that contains 331 classical piano
works [117] recorded by MIDI standard format to evaluate
the model. The experiments have shown that our model can
memorize and retrieve the melodies with an accuracy of 99%.
The details of the experiments have been discussed in our
previous work [29].
2) Stylistic Composition Spiking Neural Network: How
to learn and make music are quite complex processes for
humans. Scientists have found that the memory system and
knowledge experience participate in human creative behav-
iors [118]. Many brain areas like the prefrontal cortex are
engaged in human creativity [119]. However, the details of
brain mechanisms are still unclear. Inspired by the current
neuroscientific findings, the BrainCog introduces a spiking
neural network for learning musical knowledge and creating
melodies with different styles [30].
Fig. 20: Stylistic composition model inspired by brain mech-
anisms. Refined based on [30].

15
Musical Learning: This work proposes a spiking neural
model which is composed of a knowledge network and a
sequence memory network. As is shown in Fig. 20, the
knowledge network is designed as a hierarchical structure for
encoding and learning musical knowledge. These layers store
the genre (such as Baroque, Classical, and Romantic), the
names of famous composers and the titles of musical pieces.
Neurons in the upper layers project their synapses to the
lower layers. The sequence memory network stores the ordered
notes which have been discussed in section III-D1. During
the learning process, synaptic connections are also projected
from the knowledge network to the sequence memory network.
This work also takes LIF model which is supported by the
BrainCog platform to simulate neural dynamics. Furthermore,
all the connections are generated and updated dynamically by
the STDP learning rule.
Fig. 21: A sample of a generated melody with Bach’s charac-
teristic.
Musical Composition: Based on the learning process, genre-
based and composer-based melody compositions are discussed
in this paper. Given the beginning notes and the length of
the melody to be generated, the genre-based composition can
produce a single-part melody with a specific genre style.
This task is achieved by the neural circuits of genre cluster
and sequential memory system. Similarly, the composer-based
composition can produce melodies with composers’ charac-
ters. The composer cluster and sequential memory system
circuits contribute to this process [30]. We also use a classical
piano dataset including 331 musical works recorded by MIDI
format [117] to train the model. Fig. 21 shows a sample of
the generated melody with Bach’s style. The details of stylistic
composition can be referred to our previous work [30].
A total of 41 human listeners are invited to evaluate the
quality of the generated melodies, and they are divided into
two groups, one of which has a musical background. Exper-
iments have shown that the pieces produced by the model
have strong characteristics of different styles and some of them
sound nice.
2. Brain-Inspired Sequence Production SNN
Sequence production is an essential function for AI ap-
plications. Components in BrainCog enable the community
to build SNN models to handle this task. In this paper,
we introduce the brain-inspired symbol sequences produc-
tion spiking neural network (SPSNN) model that has been
incorporated in BrainCog [31]. SPSNN incorporates multiple
neuroscience mechanisms including Population Coding [120],
STDP [71], Reward-Modulated STDP [121], and Chunking
Mechanism [122], mostly covered and provided by BrainCog.
After reinforcement learning, the network can complete the
memory of different sequences and production sequences
according to different rules.
For Population Coding, this model utilizes populations of
neurons to represent different symbols. The whole neural
loop of SPSNN is divided into Working Memory Circuit,
Reinforcement Learning Circuit, and Motor Neurons [31],
shown in Fig. 22. The Working Memory Circuit is mainly
responsible for completing the memory of the sequence. The
Reinforcement Learning Circuit is responsible for acquiring
different rules during the reinforcement learning process. The
Motor Neurons can be regarded as the network’s output.
In the working process of the model, the Working Mem-
ory Circuit and the Reinforcement Learning Circuit coop-
erate to complete the memory and production of different
sequences [31]. It is worth mentioning that with the in-
crease of background noise, the recall accuracy of symbols
at different positions in a sequence gradually decreases, and
the overall change trend follows the ”U-shaped accuracy”,
which is consistent with experiments in psychology and
neuroscience [123]. The results are highly consistent due
to the superposition of primacy and recency effects. Our
model provides a possible explanation for both effects from a
computational perspective.
Fig. 22: The architecture of SPSNN, adopted from [31].
3. Commonsense Knowledge Representation Graph SNN
Commonsense knowledge representation and reasoning are
important cornerstones on the way to realize human-level gen-
eral AI [124]. In this module, we build Commonsense Knowl-
edge Representation SNN(CKR-SNN) to explore whether
SNN can complete these cognitive function.
The hippocampus plays a critical role in the formation of
new knowledge memory [125]. Inspired by the population
coding mechanism found in hippocampus [126], this module
encodes the entities and relations of commonsense knowl-
edge graph into different populations of neurons. Via spiking
timing-dependent plasticity (STDP) learning principle, the
synaptic connections between neuron populations are formed
after guiding the sequential firings of corresponding neuron
populations [32].
As Fig. 23 shows, neuron populations together constructed
the giant graph spiking neural networks, which contain the

16
Fig. 23: Graph Spiking Neural Networks for Commonsense
Representation, adopted from [32].
commonsense knowledge. In this module, Commonsense
Knowledge Representation SNN(CKR-SNN) represents a sub-
set of Commonsense Knowledge Graph ConceptNet [127].
After training, CKR-SNN can complete conceptual knowledge
generation and other cognitive tasks [32].
4. Causal Reasoning SNN
In BrainCog, we constructed causal reasoning SNN, as an
instance to verify the feasibility of spiking neural networks to
realize deductive and inductive reasoning. Specifically, Causal
Reasoning Spiking Neural Network (CRSNN) module con-
tains a brain-inspired causal reasoning spiking neural network
model [33].
This model explores how to encode a static causal graph into
a spiking neural network and implement subsequent reasoning
based on a spiking neural network. Inspired by the causal
reasoning process of the human brain [128], we try to explore
how causal reasoning can be implemented based on spiking
neural networks. The 3D model of CRSNN is shown in
Fig. 24.
Inspired by neuroscience, the CRSNN module adopts the
population coding mechanism and uses neuron populations to
represent nodes and relationships in the causal graph. Each
node indicates different events in the causal graph, as shown
in Fig. 24. By giving current stimulation to different neuron
populations in the spiking neural networks and combining the
STDP learning rule [71], CRSNN can encode the topology
between different nodes in a causal graph into a spiking neural
network. Furthermore, according to this network, CRSNN
completes the subsequent deductive reasoning tasks.
Then, by introducing an external evaluation function, we
can grasp the specific reasoning path in the working process
of the network according to the firing patterns of the model,
which gives the CRSNN more interpretability compared to
traditional ANN models [33].
E. Social Cognition
The nature and neural correlates of social cognition is
an advanced topic in cognitive neuroscience. In the field
of artificial intelligence and robotics, there are few in-depth
studies that take the neural correlation and brain mechanisms
of biological social cognition seriously. Although the scientific
understanding of biological social cognition is still in a prelim-
inary stage [34], we integrate the biological findings of social
cognition into a model to construct a brain-inspired model for
social cognition to extend the functions of BrainCog.
Understanding ourselves and other people is a prerequisite
for social cognition.
Fig. 24: CRSNN 3D model, adapted from [33].
An individual’s perception of the world is realized through
his own body, and the importance of knowing oneself is the
perception of self-body. Neuroscientific researches show that
the inferior parietal lobule (IPL) is activated when the subjects
see self-generated actions [68] and their own faces [129].
Similar to the IPL, the Insula is activated in bodily ownership
and self-recognition tasks [72].
Understanding the mental states of others plays an important
role for understanding other people. Theory of mind is an
ability to distinguish between self and others and to infer
others’ mental states (such as desires, goals, beliefs, etc.)
in the social context [130], [131], [132]. This ability can
help us reasonably infer other people’s policies and goals.
Inspired by this, we believe that applying theory of mind to
the agent’s decision-making process will improve the agent’s
inference of other agents, so as to take more reasonable
actions. Neuroscientific researches [133], [134], [135], [136]
show that the brain areas related to theory of mind are mainly
TPJ, part of PFC, ACC and IFG. The IPL contained in the TPJ
is mainly used to represent self-relevant information, while
the pSTS is used to represent information related to others.
The insula, representing the abstract self, can be stimulated
with self-related information [34]. When theory of mind is
going on, the IFG will suppress self-relevant information.
Therefore, the TPJ will input other-relevant information into
the PFC. The ACC evaluates the value of others’ states, so as
to help the PFC to infer others. The process of inferring others’
goals or behaviors can be understood as simulating other
people’s decision-making [137]. Therefore, this process will be
regulated by dopamine from substantia nigra compacta/ventral
tegmental area (Snc/VTA).
With the neuron model and STDP function provided by the
BrainCog framework, a brain-inspired social cognition model
is constructed, as shown in Fig. 25.
The brain-inspired social cognition model contains two
pathways: the bodily self-perception pathway and the theory
of mind pathway.
The bodily self-perception pathway (shown in Fig. 26)
consists of inferior parietal lobule spiking neural network
(IPL-SNN) and Insula spiking neural network (Insula-SNN).
The IPL-SNN realizes motor-visual associative learning. The
Insula-SNN realizes the abstract representation of oneself, that
is, when the detected movement’s visual results match the

17
Fig. 25: Brain-inspired social cognition model.
expected results of its own movement, the Insula will be
activated, and the robot considers that the moving part in the
field of vision belongs to itself.
Fig. 26: The architecture and pathway of bodily self-perception
in the brain-inspired social cognition model.
The architecture of IPL-SNN and the process of motor-
visual associative learning is shown in Fig. 27. The vPMC
generates its own motion angle information, and the STS
outputs the motion angle information detected by vision.
According to the STDP mechanism and the spiking time
difference of neurons in IPLM and IPLV, the motor-visual
associative learning is established.
Fig. 27: Motor-visual associative learning in IPL, adapted
from [34].
The architecture of Insula-SNN is shown in Fig. 28. The
Insula receives angle information from IPLV and STS. After
the motor-visual associative learning in IPL, IPLV outputs the
visual feedback angle information predicted according to its
own motion, and STS outputs the motion angle information
detected by vision. If the two are consistent, the Insula will
be activated.
Fig. 28: The architecture of Insula-SNN.
The theory of mind pathway [35] is mainly composed
of three modules: the perspective taking module, the policy
inference module, the action prediction module, and the state
evaluation module (shown in Fig. 29).
Fig. 29: The architecture of theory of mind in the brain-
inspired social cognition model, refined based on [35].
The perspective taking (also called self-perspective inhi-
bition [34]) module simulates the function of suppressing
self-relevant information in the process of distinguish self
and others. The information related to self can stimulate an
representation of abstract self. When we infer others, the
information related to self can be suppressed. Assuming that
the agent knows the environment. When the agent with the
theory of mind (ToM) infers the observation of others, it only
needs to bring its own observation into the position of others.
A matrix is used to represent the observed environment, where
1 indicates that the area can be observed at the location, and
0 indicates that the area cannot be observed at the location.
Another matrix is used to represent the position of objects.
The position which is occupied by objects is represented by
1, otherwise it is represented by 0. By taking the intersection
of the two matrices, the estimation of others’ states are
obtained. According to the fact that the IFG helps the brain

18
to suppress the performance of self-relevant information in
the process of ToM, agent with the ToM will inhibit its own
representation of states, and further infer the behavior of others
by these estimation of others’ states. In summary, the input of
this module is the observation vector and the matrix of the
environment. The output is the observation vector of others’
perspective.
The dorsolateral prefrontal cortex (DLPFC) has the function
of storing working memory and predicting others’ behaviors.
The action prediction module is used to simulate the function
of the DLPFC. The input is formed by the observation value
of others’ state output by the perspective taking module. The
module is a single layer spiking neural network. There is
lateral suppression in the output layers. The network is trained
by R-STDP. The source of reward is the difference between
the predicted value and the real value. When the predicted
value is consistent with the real value, the reward is positive.
When the predicted value is not equal to the real value, the
reward is negative.
The state evaluation module composed of a single layer
spiking neural network simulates the function of the ACC
brain area. The inputs of the module are the predicted state
and the output is safe or unsafe.
Finally, we conducted two experiments to test the brain-
inspired social cognition model.
1. Multi-Robots Mirror Self-Recognition Test
The mirror test is the most representative test of social
cognition. Only a few animals passed the test, including
chimpanzees [138], orangutans [139], bonobos [140], go-
rillas [141], [142], Asiatic elephant [143], dolphins [144],
orcas [145], macaque monkeys [146], etc. Based on the mirror
test, we proposed the Multi-Robots Mirror Self-Recognition
Test [34], in which three robots with identical appearance
move their arms randomly in front of the mirror at the same
time, and each robot needs to determine which mirror image
belongs to it. The experiment includes training stage and test
stage.
The training stage is shown in Fig. 30. Three blue robots
with identical appearance move randomly in front of the mirror
at the same time. Each robot establishes the motor-visual
association according to the motion angle of its own arm and
the angle of visual detection.
Fig. 30: Training stage in multi-robots mirror self-recognition
test, adapted from [34].
The test stage is shown in Fig. 31. In the test stage, the
robot can predicts the visual feedback generated by its arm
movement according to the training results. By comparing
the similarity between the predicted visual feedback and the
detected visual results, the robot can identify which mirror
image belongs to it.
Fig. 31: Test stage in multi-robots mirror self-recognition test,
adapted from [34].
In the bodily self-perception pathway, the input is the
angle of the robot’s random motion and the angle detected
by the robot’s vision. After training and testing, the output
is an image, which is the result of visual motion detection
and the result of self motion prediction. The motion track
corresponding to the red line in the visual motion detection
result is generated by itself. The result is shown in Fig. 32.
Fig. 32: The result of IPL-SNN.
2. AI Safety Risks Experiment
AI safety risks experiment is shown in Fig. 33. After
observing the behavior of the other two agents, the green agent
can infer the behaviors of others by utilizing its ToM ability
when safety risks may arise due to environmental changes.
The experiment was conducted in the environments with some
simulated types of safety risks (e.g., the intersection will block
the view of agents and may cause agents to collide in the
crossing).
The experiment shows that the agent can infer others when
they have different perspectives. In the first two environments,
the agent observes the movement of others, and in the third
environment, the agent predicts others’ actions. In the experi-
ment, we verify the effectiveness of the model by taking the
rescue behavior as the standard when other agents might be
in danger. The experimental results show that the agent with
the ToM can predict the danger of the other agent in a slightly
changed environment after watching other agents move in the
previous environments.

19
(a) Green agent observes others’ behaviors (example 1)
(b) Green agent observes others’ behaviors (example 2)
(c) Test example 1 (with ToM)
(d) Test example 2 (without ToM)
Fig. 33: Comparison diagram of experimental results. (a)
Example 1. The green agent observes others’ behaviors. (b)
Example 2. The green agent observes others’ behaviors. (c)
The green agent with ToM can help other agents avoid risks.
(d) The green agent without ToM is unable to help other agents
avoid risks. Similar results can be found in [35].
IV. BRAIN SIMULATION
Brain simulation includes two parts: brain cognitive function
simulation and multi-scale brain structure simulation. We
incorporate as much published anatomical data as possible
to simulate cognitive functions such as decision-making and
working memory. Anatomical and imaging multi-scale con-
nectivity data is used to make whole-brain simulations from
mouse, macaque to human more biologically plausible.
A. Brain Cognitive Function Simulation
1. Drosophila-inspired Decision-Making SNN
Drosophila decision-making consists of value-based non-
linear decision and perception-based linear decision, where
the nonlinear decision could help to amplify the subtle dis-
tinction between conflicting cues and make winner-takes-
all choices [147]. In this paper, the BrainCog framework is
used to build Drosophila nonlinear and linear decision-making
pathways as shown in Fig. 34a-b. The entire model consists
of a training phase and a testing phase as same as [36].
In the training phase, a two-layer SNN with LIF neurons
is trained by reward-modulated STDP, which combines local
STDP synaptic plasticity with global dopamine regulation. The
training phase learns the safe pattern (upright-green T) and the
punished pattern (inverted-blue T) [36]. Therefore, it is safe
for green color and upright T shape factors, while blue color
and inverted T shape are dangerous.
Fig. 34: (a) Linear Pathway. (b) Nonlinear Pathway. (c) Exper-
iments for training and choice phases. (d) Experimental results
of linear and nonlinear networks under the dilemma. The X-
axis refers to the color density, and the Y-axis represents the
PI values. Refined based on [36].
Two cues (color and shape) are restructured during the
testing phase, requiring linear and nonlinear pathways to
make a choice between inverted-green T and upright-blue
T, as shown in Fig. 34c. The linear decision directly uses
the knowledge acquired during the training phase to make
decisions. The nonlinear network models the recurrent loop of
the DA-GABA-MB circuit [147], [148], [149]: KC activates
the anterior posterior lateral (APL) neurons, which in turn
releases GABA transmitter to inhibit the activity of KC. KC
also provides mushroom body output neuron (MBON) with
exciting input in order to generate behavioral choices. When
faced with conflicting cues, the level of DA increases rapidly
and produces mutual inhibition with APL, thereby producing a
disinhibitory effect on KC. The excitatory connection between
DA and MBON also helps speed up decision-making.
To verify the consistency of drosophila-inspired decision-
making SNN with the conclusions from neuroscience [147],
we count the behavior paradigm of our model under different
color intensities over a period of time. First, we run the
network for 500 steps to count the time t1 of selecting behavior
1 (avoiding) and the time t2 of selecting behavior 2 (ap-
proaching). Then we calculate prefer index (PI) values under
different color intensity: PI =
|t1−t2|
|t1+t2|. From Fig. 34d, we
find that nonlinear circuits could achieve a gain-gating effect
to enhance relative salient cue and suppress less salient cue,
thereby displaying the nonlinear sigmoid-shape curve [36].
However, the linear network couldn’t amplify the difference
between conflicting cues, thus making an ambiguous choice
(linear-shape curve) [36]. This work proves that drawing on
the neural mechanism and structure of the nonlinear and
linear decision-making of the Drosophila brain, the brain-
inspired computational model implemented by BrainCog could
obtain consistent conclusions with the Drosophila biological
experiment [147].
2. PFC Working Memory
Understanding the detailed differences between the brains

20
of humans and other species on multiple scales will help
illuminate what makes us unique as a species [150]. The
neocortex is associated with many cognitive functions such as
working memory, attention and decision making [151], [152],
[153], [154], [65]. Based on the human brain neuron database
of the Allen Institute for Brain Science, the key membrane
parameters of human neurons are extracted 1. Different types
of human brain neuron models and rodent neuron models are
established based on adaptive Exponential Integrate-and-Fire
(aEIF) model [40], [41], which is supported by BrainCog.
We refined the model of a single PFC proposed by Haas
and colleagues 2 [155]. Subsequently, a 6-layer PFC column
model based on biometric parameters was established [156].
The pyramidal cells and interneurons were proportionally
distributed from the literature [157], [158] and connected with
different connection probabilities for different types of neurons
based on previous studies [159], [155], [160]. Firstly, the
accuracy of information maintenance was tested on rodent PFC
network model.
Fig. 35: Anatomical and network stimulation diagram. (a)
The connection of a single PFC column. (b) The distribution
proportion of different types of neurons in each column layer.
(c) Network persistent activity performance. Refined based
on [37].
Keeping the network structure and other parameters un-
changed, only using human neurons to replace rodent neurons
can significantly improve the accuracy and integrity of image
output. From an evolutionary perspective, the lower membrane
capacitance of human neurons facilitates firing. This change
improves the efficiency of information transmission, which is
consistent with the results of biological experiments [161].
This data-driven PFC column model provides an effective
simulation-validation platform to study other high-level cog-
nitive functions [162].
B. Multi-scale Brain Structure Simulation
1. Neural Circuit
1) Microcircuit: BrainCog implements a BDM-SNN model
inspired by the decision-making neural circuit of PFC-BG-
ThA-PMC in the mammalian brain (as shown in Fig. 36) [27].
The BDM-SNN models the excitatory and inhibitory recipro-
cal connections between the basal ganglia nucleus [60]: (1)
1http://alleninstitute.github.io/AllenSDK/cell types.html
2http://senselab.med.yale.edu/ModelDB/
Excitatory connections: STN-Gpi, STN-Gpe. (2) Inhibitory
connections: StrD1-Gpi, StrD2-Gpe, Gpe-Gpi, Gpe-STN. Di-
rect pathway (PFC-StrD1), indirect pathway (PFC-StrD2), and
hyperdirect pathway (PFC-STN) from PFC to BG are further
constructed. The output from BG transmits an inhibitory
connection to the thalamus and finally excites PMC [59].
In addition, excitatory connections are also formed between
PFC and thalamus, and lateral inhibition exists in PMC. Such
brain-inspired neural microcircuit, consisting of connections
among different cortical and subcortical brain areas, and
incorporating DA-regulated learning rules, enable human-like
decision-making ability.
Fig. 36: The microcircuit of PFC-BG-ThA-PMC. Refined
based on [27].
2) Cortical Column: A mammalian thalamocortical column
is constructed in BrainCog, which is based on detailed anatom-
ical data [73]. This column is made up of a six-layered cortical
structure consisting of eight types of excitatory and nine
types of inhibitory neurons. Thalamic neurons cover two types
of excitatory neurons, inhibitory neurons and GABAergic
neurons in the reticular thalamic nucleus (RTN). Neurons
are simulated by Izhikevich model, which BrainCog applies
to exhibit their specific spiking patterns depending on their
different neural morphologies. For example, excitatory neurons
(pyramidal and spiny stellate cells) always exhibit RS (Regular
Spiking) or Bursting modes, while inhibitory neurons (basket
and non-basket interneuron) are of FS (Fasting Spiking) or
LTS (Low-threshold Spiking) patterns. Each neuron has a
number of dendritic branches to accommodate a large number
of synapses. The synaptic distribution and the microcircuits are
reconstructed in BrainCog based on the previous works [73],
[163]. Fig. 37(a) describes the details of the minicolumn.
The column contains 1,000 neurons and more than 4,200,000
synapses. To understand the network further, we stimulate the
spiny stellate cells in layer 4 to observe the activities of the
whole network, Fig. 37(b) shows the result of neural activities
after the cells in layer 4 receive the external stimulation.
2. Mouse Brain
The BrainCog mouse brain simulator is a spiking neural
network model covering 213 brain areas of the mouse brain,
which are classified according to the Allen Mouse Brain

21
Fig. 37: The thalamocortical column. (a) shows the structure
of the column and (b) describes the running activities of
the unfold column when the neurons in Layer 4 receive the
external stimulus.
Connectivity Atlas [164] 3. Each neuron was modeled by
conductance-based spiking neuron model and simulated with
a resolution of dt= 1 ms. A total of 6 types of neurons
are included in this model, which are excitatory neurons (E),
interneuron-basket cells (I-BC), interneuron-Matinotti cell (I-
MC), thalamocortical relay neurons (TC), thalamic interneu-
rons (TI) and thalamic reticular neurons (TRN).
J ∈{E, IBC, IMC, TC, TI, TRN}
We use the aEIF neuron model referring to previous
work [165], [166], [167], and obtain the parameters of this
study, which are summarized in Tab. III.
TABLE III: Main parameters of different types of neuron
models.
Vth,j(mV )
Vr,j(mV )
τv,j
τw,j
αj
βj
E
-50
-110
100
-
0
0
I-BC
-44
-110
100
20
-2
4.5
I-MC
-45
-66
85
20
-2
4.5
TC
-50
-60
200
-
0
0
TI
-50
-60
20
20
-2
4.5
TRN
-45
-65
40
20
-2
4.5
The connections between brain areas are based on the
quantitative anatomical dataset Allen Mouse Brain Connectiv-
ity Atlas. Methods for data generation have been previously
described in [168]. The proportions of the different types of
neurons were adopted from a previous study [166], [169].
The numbers of each type of neuron in the network are
shown in Tab. IV.
TABLE IV: Number of different types of neurons in the
BrainCog mouse brain simulator.
Neuron Type
E
I BC
I MC
TC
TI
TRN
Neuron Number
56100
14960
7480
1300
260
520
The spontaneous discharge of the model without external
stimulation is shown in Fig. 38.
This is an open platform, and both the parameters of the
neuron model and the number of different types of neurons
can be set flexibly.
3. Macaque Brain
3http://connectivity.brain-map.org
Fig. 38: Running of the BrainCog mouse brain simulator. The
shining point is the spiking neuron at the time t and the point
color represents the neuron belong to respective brain area.
The BrainCog macaque brain simulator is a large-scale spik-
ing neural network model covering 383 brain areas [170]. We
used the multi-scale connectome transformation method [171]
on the EGFP (enhanced green fluorescent protein) re-
sults [172], [173], [174] to obtain the approximate amount
of cells per region and the approximate number of synaptic
connections between two connected regions [175]. The final
macaque model includes 1.21 billion spiking neurons and
1.3 trillion synapses, which is 1/5 of a real macaque brain.
Specifically, the details of the brain micro-circuit are also
considered in the simulation. The types of neurons in the
micro-circuit include excitatory neurons (90 % of the neurons
are of this type in the simulation) and inhibitory neurons
(10% of the neurons are of this type in the simulation) [176].
The spiking neuron follows Hodgkin–Huxley model, which
is supported by BrainCog. The running demo of the model
is shown in Fig. 39(a). To use the macaque model in the
platform, the parameters of the neuron number in each region,
the connectome power between regions, and the proportion
between the excitatory and inhibitory neurons can be set
flexibly.
Fig. 39: Running of the macaque brain (a) and the human
brain (b) model. The shining point is the spiking neuron at
the time t and the point color represents the region which the
neuron belongs to.
4. Human Brain
The BrainCog human brain simulator is built with the
approach similiar to the BrainCog macaque brain. By using
the EGFP results of the human brainnetom atlas [177], [178],
the BrainCog human brain simulator consists of 246 brain
areas. It should be noted that since there is no directed human
brain connectome available until the release of this paper,

22
the BrainCog human brain simulator keeps bidirectional con-
nections among brain areas. The details of the micro-circuit,
including the excitatory neuron and the inhibitory neuron, are
also considered. The final model (Fig. 39(b) includes 0.86
billion spiking neurons and 2.5 trillion synapses, which is
1/100 of a real human brain. To use this model in the platform,
the neuron number per region, the connectome power, and the
proportion between the excitatory and inhibitory neurons can
be set flexibly. Morover, all the simulations were performed
on distributed memory clusters [175] at the super computing
center affiliated to Institute of Automation, Chinese Academy
of Sciences, Beijing, China. The cluster named the fat cluster
is composed of 16 blade nodes and 2 “fat” computing nodes.
In order to imporve the network communication efficiency
and the simulation performance, the most connected areas
were simulated in the ’fat’ computing nodes to minimize the
inter-node communications, while the other areas is randomly
distributed in the blade nodes. The simulation shows the ability
of the framework to deploy on the supercomputer or large-
scale computer clusters.
V. BORN: A SPIKING NEURAL NETWORK DRIVEN
ARTIFICIAL INTELLIGENCE ENGINE BASED ON BRAINCOG
BrainCog is designed to be an open source platform to
enable the community to build spiking neural network based
brain-inspired AI models and brain simulators. Based on
the essential components developed for BrainCog, one can
develop their own domain specific or general purpose AI
engines. To further demonstrate how BrainCog can support
building Brain-inspired AI engine, here we introduce BORN,
an ongoing SNN driven Brain-inspired AI engine, ultimately
designed for general purpose living AI. As shown in Fig. 40,
the high-level architecture of BORN is to integrate spatial
and temporal plasticities to realize perception and learning,
decision-making, motor control, working memory, long-term
memory, attention and consciousness, emotion, knowledge
representation and reasoning, social cognition and other brain
cognitive functions. Spatial plasticity incorporates multi-scale
neuroplasticity principles at micro, meso and macro scales.
Temporal plasticity considers learning, developmental and
evolutionary plasticity at different time scales.
As an essential component for BORN, we propose a
developmental plasticity-inspired adaptive pruning (DPAP)
model, that enables the complex deep SNNs and DNNs to
gradually evolve into a brain-inspired efficient and compact
structure, and eventually improves learning speed and accuracy
in the extremely compressed networks [179]. The evolutionary
process for the brain includes but not limited to searching
for the proper connectome among different building blocks
of the brain at multiple scales (e.g. neurons, microcircuits,
brain areas). BioNAS for BORN uses brain-inspired neural
architecture search to construct SNNs with diverse motifs in
the brain and experimentally verify that SNNs with rich motif
types perform better than plain feedforward SNNs [180].
How the human brain selects and coordinates various learn-
ing methods to solve complex tasks is crucial for under-
standing human intelligence and inspiring future AI. BORN
is dedicated to address critical research issues like this. The
learning framework of BORN consists of multi-task continual
learning, few-shot learning, multi-modal concept learning, on-
line learning, lifelong learning, teaching-learning, and transfer
learning, etc.
To demonstrate the ability and principles of BORN, we
provide a relatively complex application on emotion depen-
dent robotic music composition and playing. This application
requires a humanoid robot perform music composition and
playing depending on visual emotion recognition. The appli-
cation requires BORN to provide cognitive functions such as
visual emotion recognition, sequence learning and generation,
knowledge representation and reasoning, and motor control,
etc. This application of BORN starts with perception and
learning, and ends with motor output.
It includes three modules implemented by BrainCog: the
visual (emotion) recognition module, the emotion-dependent
music composition module, and the robot music playing
module. As shown in Fig. 41, the visual emotion recognition
module enables robots to recognize the emotions expressed in
images captured by the humanoid robot eyes. The emotion-
dependent music composition module can generate music
pieces according to various emotional inputs. When a picture
is shown to the robot, the Visual Emotion Recognition network
can firstly identify the emotions expressed in the picture, such
as joy or sadness. The robot then selects or compose the music
piece that best matches the emotions in the picture. And finally,
with the help of the robot music playing module, the robot
controls its arms and fingers in a series of movements, thus
playing the music on the piano. Some details are introduced
as follows:
1) Visual Emotion Recognition:
For emotion recognition,
inspired by the ventral visual pathway, we construct a deep
convolutional spiking neural network with LIF neuron model
and surrogate gradient provided by BrainCog. The structure
of the network is set as 32C3-32C3-MP-32C3-32C3-300-7.
32C3 means the output channel is set with 32, and the kernel
size is set as 3. MP denotes the max pooling. The mean
firing rate is used to make the final prediction. We use the
Adam optimizer, and the mean square error loss. The initial
learning rate is set with 0.001, and it will decay to 1/10 of the
previous value every 40 epochs, for a total of 100 epochs. We
use the Emotion6 dataset [181] to train and test our model.
The Emotion6 dataset is composed of 6 emotions such as
anger, disgust, fear, joy, sadness, surprise, and each type of
emotion consists of 330 samples. On this basis, we extend the
original Emotion6 dataset with exciting emotion which we
collect online. 80% of the images are used as the training set,
and the remaining 20% are used as the test set.
2) Emotion-dependent Music Composition: Listening to the
the music can make us emotional, while, when people feel
happy or sad, they always express their feeling with music.
Amygdala plays a key role in human emotion. Inspired by this
mechanism, we constructed a simple spiking neural network
to simulate this important area to represent different types of
emotions and learn the relationships with other brain areas
related to music. As shown in Fig. 41, the amygdala network is
composed of several LIF neurons supported through BrainCog,

23
Fig. 40: The functional framework and vision of BORN.
Fig. 41: The procedure of multi-cognitive function coordinated emotion dependent music composition and playing by humanoid
robot based on BORN.
the connections from this cluster are projected to the musical
sequence memory networks.
During the learning process, amygdala, PFC, and the musi-
cal sequence memory networks cooperate with each other and
form complex neural circuits. Here, connections are updated
by the STDP learning rule. The dataset used here also contains
331 MIDI files of classical piano works [117], and it is
important to note that a part of these music works are labeled
with different types of emotional categories (such as happy,
depressed, passionate and beautiful).
At the generation process, given the beginning notes and
specific emotion type, the model can generate a series of notes
and form a melody with particular emotion finally.
3) Robot Music-Playing: A humanoid robot iCub is used to
validate the abilities of robotic music composition and playing
depending on the result of visual emotion recognition. The
iCub robot has a total of 53 degrees of freedoms throughout the
body. In the piano playing task, we used 6 degrees of freedoms
of the head, 3 degrees of freedoms of the torso, and 16 degrees
of freedoms for each of the left and right arm (including the
left and right hand). Besides, we mainly control the index
fingers to press the keys; in the multi-fingered playing mode,
we mainly control the thumbs, the index fingers, and the
middle fingers to press the keys. During playing, the robot
controls the movement of the hand in sequence according to
the generated sequence of different musical notes, and presses
the keys with corresponding fingers, thereby completing the
performance. For each note to be played, the corresponding
playing arm needs to complete the entire process of moving,
waiting, pressing the key, holding, and releasing the key
according to the beat. During the playing process, we also
control the movements of the robot’s head and the non-playing
hand to match the performance.
We have constructed a multi-brain area coordinated robot
motor control SNN model based on the brain motor control cir-
cuit. The SNN model is built with LIF neurons and implements
SMA, PMC, basal ganglia and cerebellum functions. The
music notes is first processed by SMA, PMC and basal ganglia
networks to generate high-level target movement directions,
and the output of PMC is encoded by population neurons to
target movement directions. The fusion of population codings
of movement directions is further processed by the cerebellum
model for low level motor control. The cerebellum SNN
module consists of Granular Cells (GCs), Purkinje Cells (PCs)
and Deep Cerebellar Nuclei (DCN), which implements the
three level residual learning in motor control. The DCN

24
network generates the final joint control outputs for the robot
arms to perform the playing movement.
VI. CONCLUSION
BrainCog aims to provide a community based open source
platform for developing spiking neural network based AI
models and cognitive brain simulators. It integrates multi-scale
biological plausible computational units and plasticity princi-
ples. Different from existing platforms, BrainCog incorporates
and provides task ready SNN models for AI, and supports
brain function and structure simulations at multiple scales.
With the basic and functional components provided in the
current version of BrainCog, we have shown how a variety of
models and applications can already be implemented for both
brain-inspired AI and brain simulations. Based on BrainCog,
we are also committed to building BORN into a powerful
SNN-based AI engine that incorporates multi-scale plasticity
principles to realize brain-inspired cognitive functions towards
human level. Powered by 9 years development of BrainCog
modules, components and applications, and inspired by bio-
logical mechanisms and natural evolution, continuous efforts
on BORN will enable it to be a general purpose AI engine. We
have already started the efforts to extend BrainCog and BORN
to support high-level cognition such as theory of mind [35],
consciousness [34], and morality [35], and it definitely takes
the world to build true and general purpose AI for human and
ecology good. Join us on this explorations to create the future
for human-AI symbiotic society.
ACKNOWLEDGEMENTS
This work is supported by the National Key Research and
Development Program (Grant No. 2020AAA0104305), the
Strategic Priority Research Program of the Chinese Academy
of Sciences (Grant No. XDB32070100).
REFERENCES
[1] W. Maass, “Networks of spiking neurons: the third generation of neural
network models,” Neural networks, vol. 10, no. 9, pp. 1659–1671,
1997.
[2] N. T. Carnevale and M. L. Hines, The NEURON book.
Cambridge
University Press, 2006.
[3] M.-O. Gewaltig and M. Diesmann, “Nest (neural simulation tool),”
Scholarpedia, vol. 2, no. 4, p. 1430, 2007.
[4] M. Stimberg, R. Brette, and D. F. Goodman, “Brian 2, an intuitive and
efficient neural simulator,” Elife, vol. 8, p. e47314, 2019.
[5] D. F. Goodman and R. Brette, “The brian simulator,” Frontiers in
neuroscience, vol. 3, p. 26, 2009.
[6] P. U. Diehl and M. Cook, “Unsupervised learning of digit recognition
using spike-timing-dependent plasticity,” Frontiers in computational
neuroscience, vol. 9, p. 99, 2015.
[7] H. Hazan, D. J. Saunders, H. Khan, D. Patel, D. T. Sanghavi, H. T.
Siegelmann, and R. Kozma, “Bindsnet: A machine learning-oriented
spiking neural networks library in python,” Frontiers in neuroinfor-
matics, p. 89, 2018.
[8] J. P. Dominguez-Morales, Q. Liu, R. James, D. Gutierrez-Galan,
A. Jimenez-Fernandez, S. Davidson, and S. Furber, “Deep spiking
neural network model for time-variant signals classification: a real-time
speech recognition approach,” in 2018 International Joint Conference
on Neural Networks (IJCNN).
IEEE, 2018, pp. 1–8.
[9] S. Loiselle, J. Rouat, D. Pressnitzer, and S. Thorpe, “Exploration of
rank order coding with spiking neural networks for speech recognition,”
in Proceedings. 2005 IEEE International Joint Conference on Neural
Networks, 2005., vol. 4.
IEEE, 2005, pp. 2076–2080.
[10] S. Kim, S. Park, B. Na, and S. Yoon, “Spiking-yolo: spiking neural
network for energy-efficient object detection,” in Proceedings of the
AAAI Conference on Artificial Intelligence, vol. 34, no. 07, 2020, pp.
11 270–11 277.
[11] Y. Wu, L. Deng, G. Li, J. Zhu, and L. Shi, “Spatio-temporal back-
propagation for training high-performance spiking neural networks,”
Frontiers in neuroscience, vol. 12, p. 331, 2018.
[12] W. Tan, D. Patel, and R. Kozma, “Strategy and benchmark for
converting deep q-networks to event-driven spiking neural networks,”
in Proceedings of the AAAI conference on artificial intelligence, vol. 35,
no. 11, 2021, pp. 9816–9824.
[13] W. Fang, Y. Chen, J. Ding, D. Chen, Z. Yu, H. Zhou, Y. Tian, and
other contributors, “Spikingjelly,” https://github.com/fangwei123456/
spikingjelly, 2020.
[14] C. Wang, Y. Jiang, X. Liu, X. Lin, X. Zou, Z. Ji, and S. Wu, “A just-in-
time compilation approach for neural dynamics simulation,” in Neural
Information Processing, T. Mantoro, M. Lee, M. A. Ayu, K. W. Wong,
and A. N. Hidayanto, Eds.
Cham: Springer International Publishing,
2021, pp. 15–26.
[15] C. Eliasmith, T. C. Stewart, X. Choo, T. Bekolay, T. DeWolf, Y. Tang,
and D. Rasmussen, “A large-scale model of the functioning brain,”
science, vol. 338, no. 6111, pp. 1202–1205, 2012.
[16] T. Bekolay, J. Bergstra, E. Hunsberger, T. DeWolf, T. C. Stewart,
D. Rasmussen, X. Choo, A. R. Voelker, and C. Eliasmith, “Nengo: a
python tool for building large-scale functional brain models,” Frontiers
in neuroinformatics, vol. 7, p. 48, 2014.
[17] Y. Zeng, C. Liu, and T. Tan, “Retrospect and outlook of brain-inspired
intelligence research (in chinese),” The Chinese Journal of Computers,
vol. 39, no. 1, pp. 212–222, 2016.
[18] G.-q. Bi and M.-m. Poo, “Synaptic modifications in cultured hip-
pocampal neurons: dependence on spike timing, synaptic strength, and
postsynaptic cell type,” Journal of neuroscience, vol. 18, no. 24, pp.
10 464–10 472, 1998.
[19] Y. Wu, L. Deng, G. Li, J. Zhu, and L. Shi, “Spatio-Temporal Back-
propagation for Training High-Performance Spiking Neural Networks,”
Front. Neurosci., vol. 12, p. 331, May 2018.
[20] H. Zheng, Y. Wu, L. Deng, Y. Hu, and G. Li, “Going Deeper With
Directly-Trained Larger Spiking Neural Networks,” Proceedings of the
AAAI Conference on Artificial Intelligence, vol. 35, no. 12, pp. 11 062–
11 070, May 2021.
[21] W. Fang, Z. Yu, Y. Chen, T. Masquelier, T. Huang, and Y. Tian,
“Incorporating Learnable Membrane Time Constant to Enhance Learn-
ing of Spiking Neural Networks,” in 2021 IEEE/CVF International
Conference on Computer Vision (ICCV). Montreal, QC, Canada: IEEE,
Oct. 2021, pp. 2641–2651.
[22] Y. Li, S. Deng, X. Dong, R. Gong, and S. Gu, “A free lunch from ann:
Towards efficient, accurate spiking neural networks calibration,” arXiv
preprint arXiv:2106.06984, 2021.
[23] B. Han and K. Roy, “Deep spiking neural network: Energy efficiency
through time based coding,” in Computer Vision–ECCV 2020: 16th
European Conference, Glasgow, UK, August 23–28, 2020, Proceedings,
Part X 16.
Springer, 2020, pp. 388–404.
[24] B. Han, G. Srinivasan, and K. Roy, “Rmp-snn: Residual membrane
potential neuron for enabling deeper high-accuracy and low-latency
spiking neural network,” in Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, 2020, pp. 13 558–13 567.
[25] Y. Wang and Y. Zeng, “Multisensory concept learning framework
based on spiking neural networks,” Frontiers in Systems Neuroscience,
vol. 16, 2022. [Online]. Available: https://www.frontiersin.org/article/
10.3389/fnsys.2022.845177
[26] Y. Sun, Y. Zeng, and T. Zhang, “Quantum superposition inspired
spiking neural network,” iScience, vol. 24, no. 8, p. 102880, 2021.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S2589004221008488
[27] F. Zhao, Y. Zeng, G. Wang, J. Bai, and B. Xu, “A brain-inspired
decision making model based on top-down biasing of prefrontal cortex
to basal ganglia and its application in autonomous uav explorations,”
Cognitive Computation, vol. 10, no. 2, pp. 296–306, 2018.
[28] Y. Sun, Y. Zeng, and Y. Li, “Solving the spike feature information
vanishing problem in spiking deep q network with potential based
normalization,” arXiv preprint arXiv:2206.03654, 2022.
[29] Q. Liang, Y. Zeng, and B. Xu, “Temporal-sequential learning with a
brain-inspired spiking neural network and its application to musical
memory,” Frontiers in Computational Neuroscience, vol. 14, p. 51, 07
2020.

25
[30] Q. Liang and Y. Zeng, “Stylistic composition of melodies based
on a brain-inspired spiking neural network,” Frontiers in systems
neuroscience, vol. 15, p. 21, 2021.
[31] H. Fang, Y. Zeng, and F. Zhao, “Brain inspired sequences production
by spiking neural networks with reward-modulated stdp,” Frontiers in
Computational Neuroscience, vol. 15, p. 8, 2021.
[32] H. Fang, Y. Zeng, J. Tang, Y. Wang, Y. Liang, and X. Liu, “Brain-
inspired graph spiking neural networks for commonsense knowledge
representation and reasoning,” arXiv preprint arXiv:2207.05561, 2022.
[33] H. Fang and Y. Zeng, “A brain-inspired causal reasoning model based
on spiking neural networks,” in 2021 International Joint Conference
on Neural Networks (IJCNN).
IEEE, 2021, pp. 1–5.
[34] Y. Zeng, Y. Zhao, J. Bai, and B. Xu, “Toward robot self-consciousness
(ii): brain-inspired robot bodily self model for self-recognition,” Cog-
nitive Computation, vol. 10, no. 2, pp. 307–320, 2018.
[35] Z. Zhao, E. Lu, F. Zhao, Y. Zeng, and Y. Zhao, “A brain-inspired
theory of mind spiking neural network for reducing safety risks of
other agents,” Frontiers in neuroscience, p. 446, 2022.
[36] F. Zhao, Y. Zeng, A. Guo, H. Su, and B. Xu, “A neural algorithm for
drosophila linear and nonlinear decision-making,” Scientific Reports,
vol. 10, no. 1, pp. 1–16, 2020.
[37] Q. Zhang, Y. Zeng, T. Zhang, and T. Yang, “Comparison between
human and rodent neurons for persistent activity performance: A bi-
ologically plausible computational investigation,” Frontiers in systems
neuroscience, p. 98, 2021.
[38] L. F. Abbott, “Lapicque’s introduction of the integrate-and-fire model
neuron (1907),” Brain research bulletin, vol. 50, no. 5-6, pp. 303–304,
1999.
[39] P. Dayan and L. F. Abbott, Theoretical neuroscience: computational
and mathematical modeling of neural systems.
MIT press, 2005.
[40] Fourcaud-Trocm´e, Nicolas, Hansel, David, V. Vreeswijk, Carl, and
Brunel, “How spike generation mechanisms determine the neuronal
response to fluctuating inputs.” Journal of Neuroscience, 2003.
[41] R. Brette and W. Gerstner, “Adaptive exponential integrate-and-fire
model as an effective description of neuronal activity,” Journal of
neurophysiology, vol. 94, no. 5, pp. 3637–3642, 2005.
[42] E. M. Izhikevich, “Simple model of spiking neurons,” IEEE Transac-
tions on neural networks, vol. 14, no. 6, pp. 1569–1572, 2003.
[43] A. L. Hodgkin and A. F. Huxley, “A quantitative description of
membrane current and its application to conduction and excitation in
nerve,” The Journal of physiology, vol. 117, no. 4, p. 500, 1952.
[44] G. Wang, Y. Zeng, and B. Xu, “A spiking neural network based
autonomous reinforcement learning model and its application in deci-
sion making,” in International Conference on Brain Inspired Cognitive
Systems.
Springer, 2016, pp. 125–137.
[45] D. J. Amit, N. Brunel, and M. Tsodyks, “Correlations of cortical
hebbian reverberations: theory versus experiment,” Journal of Neuro-
science, vol. 14, no. 11, pp. 6435–6445, 1994.
[46] E. L. Bienenstock, L. N. Cooper, and P. W. Munro, “Theory for the
development of neuron selectivity: orientation specificity and binocular
interaction in visual cortex,” Journal of Neuroscience, vol. 2, no. 1, pp.
32–48, 1982.
[47] W. Maass and H. Markram, “Synapses as dynamic memory buffers,”
Neural Networks, vol. 15, no. 2, pp. 155–161, 2002.
[48] E. M. Izhikevich, “Solving the distal reward problem through linkage
of stdp and dopamine signaling,” Cerebral Cortex, vol. 17, pp. 2443–
2452, 2007.
[49] E. D. Adrian and Y. Zotterman, “The impulses produced by sensory
nerve endings: Part 3. impulses set up by touch and pressure,” The
Journal of physiology, vol. 61, no. 4, p. 465, 1926.
[50] J. Kim, H. Kim, S. Huh, J. Lee, and K. Choi, “Deep neural networks
with weighted spikes,” Neurocomputing, vol. 311, pp. 373–386, 2018.
[51] S. Thorpe, D. Fize, and C. Marlot, “Speed of processing in the human
visual system,” nature, vol. 381, no. 6582, pp. 520–522, 1996.
[52] B. Rueckauer and S.-C. Liu, “Conversion of analog to spiking neural
networks using sparse temporal coding,” in 2018 IEEE international
symposium on circuits and systems (ISCAS).
IEEE, 2018, pp. 1–5.
[53] S. M. Bohte, J. N. Kok, and H. La Poutre, “Error-backpropagation
in temporally encoded networks of spiking neurons,” Neurocomputing,
vol. 48, no. 1-4, pp. 17–37, 2002.
[54] R. Quian Quiroga and S. Panzeri, “Extracting information from
neuronal populations: information theory and decoding approaches,”
Nature Reviews Neuroscience, vol. 10, no. 3, pp. 173–185, 2009.
[55] S. Gr¨un and S. Rotter, Analysis of parallel spike trains.
Springer,
2010, vol. 7.
[56] D. Li, J. Wu, and D. Peng, “Online traffic accident spatial-temporal
post-impact prediction model on highways based on spiking neural
networks,” Journal of advanced transportation, vol. 2021, 2021.
[57] V. S. Chakravarthy, D. Joseph, and R. S. Bapi, “What do the basal
ganglia do? a modeling perspective,” Biological cybernetics, vol. 103,
no. 3, pp. 237–253, 2010.
[58] P. Redgrave, T. J. Prescott, and K. Gurney, “The basal ganglia: a
vertebrate solution to the selection problem?” Neuroscience, vol. 89,
no. 4, pp. 1009–1023, 1999.
[59] A. Parent and L.-N. Hazrati, “Functional anatomy of the basal gan-
glia. i. the cortico-basal ganglia-thalamo-cortical loop,” Brain research
reviews, vol. 20, no. 1, pp. 91–127, 1995.
[60] J. L. Lanciego, N. Luquin, and J. A. Obeso, “Functional neuroanatomy
of the basal ganglia,” Cold Spring Harbor perspectives in medicine,
vol. 2, no. 12, p. a009621, 2012.
[61] A. Bechara, H. Damasio, D. Tranel, and S. W. Anderson, “Dissociation
of working memory from decision making within the human prefrontal
cortex,” Journal of neuroscience, vol. 18, no. 1, pp. 428–437, 1998.
[62] S. G. Rao, G. V. Williams, and P. S. Goldman-Rakic, “Isodirectional
tuning of adjacent interneurons and pyramidal cells during working
memory: evidence for microcolumnar organization in pfc,” Journal of
neurophysiology, vol. 81, no. 4, pp. 1903–1916, 1999.
[63] M. D’Esposito, B. R. Postle, and B. Rypma, “Prefrontal cortical
contributions to working memory: evidence from event-related fmri
studies,” Executive control and the frontal lobe: Current issues, pp.
3–11, 2000.
[64] A. H. Lara and J. D. Wallis, “The role of prefrontal cortex in working
memory: a mini review,” Frontiers in systems neuroscience, vol. 9, p.
173, 2015.
[65] J. N. Wood and J. Grafman, “Human prefrontal cortex: processing
and representational perspectives,” Nature reviews neuroscience, vol. 4,
no. 2, pp. 139–147, 2003.
[66] P. Frewen and R. Lanius, Healing the traumatized self: consciousness,
neuroscience, treatment (Norton series on interpersonal neurobiology).
WW Norton & Company, 2015.
[67] S. Koelsch, Brain and Music.
West Sussex, UK: Wiley-Blackwell;
1st Edition, 2012.
[68] K. L. Macuga and S. H. Frey, “Selective responses in right inferior
frontal and supramarginal gyri differentiate between observed move-
ments of oneself vs. another,” Neuropsychologia, vol. 49, no. 5, pp.
1202–1207, 2011.
[69] B. Milner, L. R. Squire, and E. R. Kandel, “Cognitive neuroscience
and the study of memory,” Neuron, vol. 20, p. 445–468, 1998.
[70] M. L. Smith and B. Milner, “The role of the right hippocampus in
the recall of spatial location,” Neuropsychologia, vol. 19, no. 6, pp.
781–793, 1981.
[71] Y. Dan and M.-m. Poo, “Spike timing-dependent plasticity of neural
circuits,” Neuron, vol. 44, no. 1, pp. 23–30, 2004.
[72] A. D. Craig, “How do you feel—now? the anterior insula and human
awareness,” Nature reviews neuroscience, vol. 10, no. 1, pp. 59–70,
2009.
[73] E. M. Izhikevich and G. M. Edelman, “Large-scale model of
mammalian thalamocortical systems,” Proceedings of the National
Academy of Sciences, vol. 105, no. 9, pp. 3593–3598, 2008. [Online].
Available: https://www.pnas.org/doi/abs/10.1073/pnas.0712231105
[74] A. Ishai, L. G. Ungerleider, A. Martin, J. L. Schouten, and J. V.
Haxby, “Distributed representation of objects in the human ventral
visual pathway,” Proceedings of the National Academy of Sciences,
vol. 96, no. 16, pp. 9379–9384, 1999.
[75] E. Kobatake and K. Tanaka, “Neuronal selectivities to complex object
features in the ventral visual pathway of the macaque cerebral cortex,”
Journal of neurophysiology, vol. 71, no. 3, pp. 856–867, 1994.
[76] D. H. Hubel and T. N. Wiesel, “Receptive fields, binocular interaction
and functional architecture in the cat’s visual cortex,” The Journal of
physiology, vol. 160, no. 1, p. 106, 1962.
[77] G. Geldberg, “Supplementary motor area structure and function: review
and hypothesis,” Behav Brain Sci., vol. 8, pp. 567–615, 1985.
[78] H. Mushiake, M. Inase, and J. Tanji, “Neuronal activity in the primate
premotor, supplementary, and precentral motor cortex during visually
guided and internally determined sequential movements,” Journal of
neurophysiology, vol. 66, no. 3, pp. 705–718, 1991.
[79] C. Gerloff, B. Corwell, R. Chen, M. Hallett, and L. G. Cohen,
“Stimulation over the human supplementary motor area interferes with
the organization of future elements in complex motor sequences.”
Brain: a journal of neurology, vol. 120, no. 9, pp. 1587–1602, 1997.
[80] A. P. Georgopoulos, “Motor cortex and cognitive processing.” 1995.

26
[81] S. Kakei, D. S. Hoffman, and P. L. Strick, “Muscle and movement
representations in the primary motor cortex,” Science, vol. 285, no.
5436, pp. 2136–2139, 1999.
[82] P. L. Strick, R. P. Dum, J. A. Fiez et al., “Cerebellum and nonmotor
function,” Annual review of neuroscience, vol. 32, no. 1, pp. 413–434,
2009.
[83] R. S. Zucker and W. G. Regehr, “Short-term synaptic plasticity,” Annual
review of physiology, vol. 64, no. 1, pp. 355–405, 2002.
[84] A. Tavanaei and A. S. Maida, “Bio-inspired spiking convolutional
neural network using layer-wise sparse coding and stdp learning,” arXiv
preprint arXiv:1611.03000, 2016.
[85] ——, “Multi-layer unsupervised learning in a spiking convolutional
neural network,” in 2017 International Joint Conference on Neural
Networks (IJCNN).
IEEE, 2017, pp. 2023–2030.
[86] P. Falez, P. Tirilly, I. M. Bilasco, P. Devienne, and P. Boulet, “Multi-
layered spiking neural network with target timestamp threshold adap-
tation and stdp,” arXiv preprint arXiv:1904.01908, 2019.
[87] T. Zhang, Y. Zeng, D. Zhao, and M. Shi, “A plasticity-centric approach
to train the non-differential spiking neural networks,” in Thirty-Second
AAAI Conference on Artificial Intelligence, 2018.
[88] T. Zhang, Y. Zeng, D. Zhao, and B. Xu, “Brain-inspired balanced
tuning for spiking neural networks.” in IJCAI, 2018, pp. 1653–1659.
[89] D. J. Felleman and D. E. Van, “Distributed hierarchical processing in
the primate cerebral cortex.” Cerebral cortex (New York, NY: 1991),
vol. 1, no. 1, pp. 1–47, 1991.
[90] O. Sporns and J. D. Zwi, “The small world of the cerebral cortex,”
Neuroinformatics, vol. 2, no. 2, pp. 145–162, 2004.
[91] D. Zhao, Y. Zeng, T. Zhang, M. Shi, and F. Zhao, “Glsnn: A multi-
layer spiking neural network based on global feedback alignment and
local stdp plasticity,” Frontiers in Computational Neuroscience, vol. 14,
2020.
[92] Y. Bengio, N. L´eonard, and A. Courville, “Estimating or Propagating
Gradients Through Stochastic Neurons for Conditional Computation,”
Aug. 2013.
[93] S. M. Bohte, “Error-backpropagation in networks of fractionally predic-
tive spiking neurons,” in International Conference on Artificial Neural
Networks.
Springer, 2011, pp. 60–68.
[94] G. Shen, D. Zhao, and Y. Zeng, “Backpropagation with biologically
plausible spatiotemporal adjustment for training deep spiking neural
networks,” Patterns, p. 100522, 2022.
[95] Y. Dong, D. Zhao, Y. Li, and Y. Zeng, “An unsupervised spiking
neural network inspired by biologically plausible learning rules and
connections,” 2022. [Online]. Available: https://arxiv.org/abs/2207.
02727
[96] Y. Zeng, T. Zhang, and B. Xu, “Improving multi-layer spiking neural
networks by incorporating brain-inspired rules,” Science China Infor-
mation Sciences, vol. 60, no. 5, pp. 1–11, 2017.
[97] Y. Li and Y. Zeng, “Efficient and accurate conversion of spiking neural
network with burst spikes,” arXiv preprint arXiv:2204.13271, 2022.
[98] Y. Li, X. He, Y. Dong, Q. Kong, and Y. Zeng, “Spike calibration: Fast
and accurate conversion of spiking neural network for object detection
and segmentation,” arXiv preprint arXiv:2207.02702, 2022.
[99] C. Blakemore, R. H. Carpenter, and M. A. Georgeson, “Lateral
inhibition between orientation detectors in the human visual system,”
Nature, vol. 228, no. 5266, pp. 37–39, 1970.
[100] D. Lynott and L. Connell, “Modality exclusivity norms for 423 object
properties,” Behavior Research Methods, vol. 41, no. 2, pp. 558–564,
2009.
[101] ——, “Modality exclusivity norms for 400 nouns: The relationship
between perceptual experience and surface word form,” Behavior
research methods, vol. 45, no. 2, pp. 516–526, 2013.
[102] J. R. Binder, L. L. Conant, C. J. Humphries, L. Fernandino, S. B.
Simons, M. Aguilar, and R. H. Desai, “Toward a brain-based compo-
nential semantic representation,” Cognitive neuropsychology, vol. 33,
no. 3-4, pp. 130–174, 2016.
[103] D. Lynott, L. Connell, M. Brysbaert, J. Brand, and J. Carney, “The
lancaster sensorimotor norms: multidimensional measures of perceptual
and action strength for 40,000 english words,” Behavior Research
Methods, pp. 1–21, 2019.
[104] E. Agirre, E. Alfonseca, K. Hall, J. Kravalova, M. Pasca, and A. Soroa,
“A study on similarity and relatedness using distributional and wordnet-
based approaches,” 2009.
[105] E. H. Huang, R. Socher, C. D. Manning, and A. Y. Ng, “Improving
word representations via global context and multiple word prototypes,”
in Proceedings of the 50th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), 2012, pp. 873–
882.
[106] K. McRae, G. S. Cree, M. S. Seidenberg, and C. McNorgan, “Semantic
feature production norms for a large set of living and nonliving things,”
Behavior research methods, vol. 37, no. 4, pp. 547–559, 2005.
[107] B. J. Devereux, L. K. Tyler, J. Geertzen, and B. Randall, “The centre
for speech, language and the brain (cslb) concept property norms,”
Behavior research methods, vol. 46, no. 4, pp. 1119–1127, 2014.
[108] M. J. Frank and E. D. Claus, “Anatomy of a decision: striato-
orbitofrontal interactions in reinforcement learning, decision making,
and reversal.” Psychological review, vol. 113, no. 2, p. 300, 2006.
[109] I. Silkis, “The cortico-basal ganglia-thalamocortical circuit with synap-
tic plasticity. i. modification rules for excitatory and inhibitory synapses
in the striatum,” Biosystems, vol. 57, no. 3, pp. 187–196, 2000.
[110] X. Wang, Z.-G. Hou, F. Lv, M. Tan, and Y. Wang, “Mobile robots’
modular navigation controller using spiking neural networks,” Neuro-
computing, vol. 134, pp. 230–238, 2014.
[111] J. C. V. Tieck, L. Steffen, J. Kaiser, A. Roennau, and R. Dillmann,
“Controlling a robot arm for target reaching without planning using
spiking neurons,” in 2018 IEEE 17th International Conference on
Cognitive Informatics & Cognitive Computing (ICCI*CC), 2018, pp.
111–116.
[112] G. Tang, N. Kumar, R. Yoo, and K. Michmizos, “Deep reinforcement
learning with population-coded spiking neural network for continuous
control,” in Conference on Robot Learning.
PMLR, 2021, pp. 2016–
2029.
[113] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger,
“Densely connected convolutional networks,” in Proceedings of the
IEEE conference on computer vision and pattern recognition, 2017,
pp. 4700–4708.
[114] J. W. Kalat, Biological psychology.
Cengage Learning, 2015.
[115] H. Merchant, D. L. Harrington, and W. H. Meck, “Neural basis of the
perception and estimation of time,” Annual Review of Neuroscience,
vol. 36, no. 1, pp. 313–336, 2013.
[116] N. J. Fortin, K. L. Agster, and H. B. Eichenbaum, “Critical role
of the hippocampus in memory for sequences of events,” Nature
Neuroscience, vol. 5, no. 5, pp. 458–462, 2002.
[117] B. Krueger, “Classical piano midi page,” 2018. [Online]. Available:
http://piano-midi.de/
[118] A. Dietrich, “The cognitive neuroscience of creativity,” Psychonomic
bulletin & review, vol. 11, no. 6, pp. 1011–1026, 2004.
[119] R. Jung, B. Mead, J. Carrasco, and R. Barrow, “The structure of creative
cognition in the human brain,” Frontiers in Human Neuroence, vol. 7,
p. 330, 2013.
[120] Y. Xie, P. Hu, J. Li, J. Chen, W. Song, X.-J. Wang, T. Yang, S. Dehaene,
S. Tang, B. Min et al., “Geometry of sequence working memory in
macaque prefrontal cortex,” Science, vol. 375, no. 6581, pp. 632–639,
2022.
[121] N.
Fr´emaux
and
W.
Gerstner,
“Neuromodulated
spike-timing-
dependent plasticity, and theory of three-factor learning rules,” Fron-
tiers in Neural Circuits, vol. 9, p. 85, 2016.
[122] V. C. Pammi, K. P. Miyapuram, R. S. Bapi, and K. Doya, “Chunking
phenomenon in complex sequential skill learning in humans,” in
International Conference on Neural Information Processing. Springer,
2004, pp. 294–299.
[123] X. Jiang, T. Long, W. Cao, J. Li, S. Dehaene, and L. Wang, “Production
of supra-regular spatial sequences by macaque monkeys,” Current
Biology, vol. 28, no. 12, pp. 1851–1859, 2018.
[124] M. Minsky, The emotion machine: Commonsense thinking, artificial
intelligence, and the future of the human mind.
Simon and Schuster,
2007.
[125] M. L. Schlichting and A. R. Preston, “The hippocampus and memory
integration: building knowledge to navigate future decisions,” in The
hippocampus from cells to systems.
Springer, 2017, pp. 405–437.
[126] S. Ramirez, X. Liu, P.-A. Lin, J. Suh, M. Pignatelli, R. L. Redondo, T. J.
Ryan, and S. Tonegawa, “Creating a false memory in the hippocampus,”
Science, vol. 341, no. 6144, pp. 387–391, 2013.
[127] J. C. Robyn Speer and C. Havasi, “Conceptnet 5.5: An open
multilingual graph of general knowledge,” vol. abs/1612.03975, 2017.
[Online]. Available: http://arxiv.org/abs/1612.03975
[128] J. Pearl and D. Mackenzie, The book of why: the new science of cause
and effect.
Basic Books, 2018.
[129] M. Sugiura, C. M. Miyauchi, Y. Kotozaki, Y. Akimoto, T. Nozawa,
Y. Yomogida, S. Hanawa, Y. Yamamoto, A. Sakuma, S. Nakagawa
et al., “Neural mechanism for mirrored self-face recognition,” Cerebral
Cortex, vol. 25, no. 9, pp. 2806–2814, 2015.
[130] S. G. Shamay-Tsoory, S. Shur, L. Barcai-Goodman, S. Medlovich,
H. Harari, and Y. Levkovitz, “Dissociation of cognitive from affective
components of theory of mind in schizophrenia,” Psychiatry Research,

27
vol. 149, no. 1-3, pp. 11–23, Jan. 2007. [Online]. Available:
https://linkinghub.elsevier.com/retrieve/pii/S0165178106001934
[131] C. L. Sebastian, N. M. G. Fontaine, G. Bird, S.-J. Blakemore,
S.
A.
De
Brito,
E.
J.
P.
McCrory,
and
E.
Viding,
“Neural
processing
associated
with
cognitive
and
affective
Theory
of
mind in adolescents and adults,” Social Cognitive and Affective
Neuroscience, vol. 7, no. 1, pp. 53–63, Jan. 2012. [Online]. Available:
https://academic.oup.com/scan/article-lookup/doi/10.1093/scan/nsr023
[132] M. Dennis, N. Simic, E. D. Bigler, T. Abildskov, A. Agostino, H. G.
Taylor, K. Rubin, K. Vannatta, C. A. Gerhardt, T. Stancin et al.,
“Cognitive, affective, and conative theory of mind (ToM) in children
with traumatic brain injury,” Developmental cognitive neuroscience,
vol. 5, pp. 25–39, 2013.
[133] A.
Abu-Akel
and
S.
Shamay-Tsoory,
“Neuroanatomical
and
neurochemical
bases
of
theory
of
mind,”
Neuropsychologia,
vol. 49, no. 11, pp. 2971–2984, Sep. 2011. [Online]. Available:
https://linkinghub.elsevier.com/retrieve/pii/S0028393211003368
[134] C. E. Hartwright, I. A. Apperly, and P. C. Hansen, “Multiple
roles for executive control in belief–desire reasoning: Distinct neural
networks are recruited for self perspective inhibition and complexity of
reasoning,” NeuroImage, vol. 61, no. 4, pp. 921–930, jul 2012. [Online].
Available: https://doi.org/10.1016%2Fj.neuroimage.2012.03.012
[135] ——, “The special case of self-perspective inhibition in mental,
but not non-mental, representation,” Neuropsychologia, vol. 67, pp.
183–192, jan 2015. [Online]. Available: https://doi.org/10.1016%2Fj.
neuropsychologia.2014.12.015
[136] J.
Koster-Hale
and
R.
Saxe,
“Theory
of
mind:
a
neural
prediction problem,” Neuron, vol. 79, no. 5, pp. 836–848, Sep.
2013. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/
S089662731300754X
[137] S. Suzuki, N. Harasawa, K. Ueno, J. L. Gardner, N. Ichinohe,
M. Haruno, K. Cheng, and H. Nakahara, “Learning to simulate others’
decisions,” Neuron, vol. 74, no. 6, pp. 1125–1137, 2012.
[138] G. G. Gallup, “Chimpanzees: self-recognition,” Science, vol. 167, no.
3914, pp. 86–87, 1970.
[139] S. D. Su´arez and G. G. Gallup Jr, “Self-recognition in chimpanzees
and orangutans, but not gorillas,” Journal of human evolution, vol. 10,
no. 2, pp. 175–188, 1981.
[140] V. Walraven, L. Van Elsacker, and R. Verheyen, “Reactions of a group
of pygmy chimpanzees (pan paniscus) to their mirror-images: Evidence
of self-recognition,” Primates, vol. 36, no. 1, pp. 145–150, 1995.
[141] F. G. Patterson and R. H. Cohn, “Self-recognition and self-awareness
in lowland gorillas,” 1994.
[142] S. Posada and M. Colell, “Another gorilla (gorilla gorilla gorilla)
recognizes himself in a mirror,” American Journal of Primatology:
Official Journal of the American Society of Primatologists, vol. 69,
no. 5, pp. 576–583, 2007.
[143] J. M. Plotnik, F. B. De Waal, and D. Reiss, “Self-recognition in an asian
elephant,” Proceedings of the National Academy of Sciences, vol. 103,
no. 45, pp. 17 053–17 057, 2006.
[144] K. Marten and S. Psarakos, “Evidence of self-awareness in the bot-
tlenose dolphin (tursiops truncatus),” 1994.
[145] F. Delfour and K. Marten, “Mirror image processing in three marine
mammal species: killer whales (orcinus orca), false killer whales (pseu-
dorca crassidens) and california sea lions (zalophus californianus),”
Behavioural processes, vol. 53, no. 3, pp. 181–190, 2001.
[146] L. Chang, Q. Fang, S. Zhang, M.-m. Poo, and N. Gong, “Mirror-
induced self-directed behaviors in rhesus monkeys after visual-
somatosensory training,” Current Biology, vol. 25, no. 2, pp. 212–217,
2015.
[147] S. Tang and A. Guo, “Choice behavior of drosophila facing contradic-
tory visual cues,” Science, vol. 294, no. 5546, pp. 1543–1547, 2001.
[148] K. Zhang, J. Z. Guo, Y. Peng, W. Xi, and A. Guo, “Dopamine-
mushroom body circuit regulates saliency-based decision-making in
drosophila,” science, vol. 316, no. 5833, pp. 1901–1904, 2007.
[149] M. Zhou, N. Chen, J. Tian, J. Zeng, Y. Zhang, X. Zhang, J. Guo, J. Sun,
Y. Li, A. Guo et al., “Suppression of gabaergic neurons through d2-like
receptor secures efficient conditioning in drosophila aversive olfactory
learning,” Proceedings of the National Academy of Sciences, vol. 116,
no. 11, pp. 5118–5125, 2019.
[150] Q. Zhang, Y. Zeng, T. Zhang, and T. Yang, “Comparison between
human and rodent neurons for persistent activity performance: A bi-
ologically plausible computational investigation,” Frontiers in systems
neuroscience, p. 98, 2021.
[151] E. K. Miller, “The prefontral cortex and cognitive control,” Nature
reviews neuroscience, vol. 1, no. 1, pp. 59–65, 2000.
[152] A. Nieder and E. K. Miller, “Coding of cognitive magnitude: Com-
pressed scaling of numerical information in the primate prefrontal
cortex,” Neuron, vol. 37, no. 1, pp. 149–157, 2003.
[153] S. Bishop, J. Duncan, M. Brett, and A. D. Lawrence, “Prefrontal
cortical function and anxiety: controlling attention to threat-related
stimuli,” Nature neuroscience, vol. 7, no. 2, pp. 184–188, 2004.
[154] E. Koechlin, C. Ody, and F. Kouneiher, “The architecture of cognitive
control in the human prefrontal cortex,” Science, vol. 302, no. 5648,
pp. 1181–1185, 2003.
[155] J. Hass, L. Hert¨ag, and D. Durstewitz, “A detailed data-driven network
model of prefrontal cortex reproduces key features of in vivo activity,”
PLoS computational biology, vol. 12, no. 5, p. e1004930, 2016.
[156] A. Shapson-Coe, M. Januszewski, D. R. Berger, A. Pope, Y. Wu,
T. Blakely, R. L. Schalek, P. H. Li, S. Wang, J. Maitin-Shepard et al., “A
connectomic study of a petascale fragment of human cerebral cortex,”
BioRxiv, 2021.
[157] C. Beaulieu, “Numerical data on neocortical neurons in adult rat, with
special reference to the gaba population,” Brain research, vol. 609, no.
1-2, pp. 284–292, 1993.
[158] J. DeFelipe, “The evolution of the brain, the human nature of cortical
circuits, and intellectual creativity,” Frontiers in neuroanatomy, vol. 5,
p. 29, 2011.
[159] J. R. Gibson, M. Beierlein, and B. W. Connors, “Two networks of
electrically coupled inhibitory neurons in neocortex,” Nature, vol. 402,
no. 6757, pp. 75–79, 1999.
[160] W.-J. Gao, Y. Wang, and P. S. Goldman-Rakic, “Dopamine modulation
of perisomatic and peridendritic inhibition in prefrontal cortex,” Journal
of Neuroscience, vol. 23, no. 5, pp. 1622–1630, 2003.
[161] G. Eyal, M. B. Verhoog, G. Testa-Silva, Y. Deitcher, J. C. Lodder,
R. Benavides-Piccione, J. Morales, J. DeFelipe, C. P. de Kock, H. D.
Mansvelder et al., “Unique membrane properties and enhanced signal
processing in human neocortical neurons,” Elife, vol. 5, p. e16553,
2016.
[162] Q. Zhang, Y. Zeng, and T. Yang, “Computational investigation of
contributions from different subtypes of interneurons in prefrontal
cortex for information maintenance,” Scientific Reports, vol. 10, no. 1,
p. 4671, 2020.
[163] Binzegger, Tom, Douglas, Rodney, J., Martin, Kevan, A., and C., “A
quantitative map of the circuit of cat primary visual cortex.” Journal
of Neuroscience, vol. 24, no. 39, pp. 8441–8453, 2004.
[164] M. J. Richardson, N. Brunel, and V. Hakim, “From subthreshold to
firing-rate resonance,” Journal of neurophysiology, vol. 89, no. 5, pp.
2538–2554, 2003.
[165] X. Jiang, S. Shen, C. R. Cadwell, P. Berens, F. Sinz, A. S. Ecker,
S. Patel, and A. S. Tolias, “Principles of connectivity among morpho-
logically defined cell types in adult neocortex,” Science, vol. 350, no.
6264, p. aac9462, 2015.
[166] E. M. Izhikevich and G. M. Edelman, “Large-scale model of mam-
malian thalamocortical systems,” Proceedings of the national academy
of sciences, vol. 105, no. 9, pp. 3593–3598, 2008.
[167] T. Tchumatchenko and C. Clopath, “Oscillations emerging from noise-
driven steady state in networks with electrical synapses and subthresh-
old resonance,” Nature communications, vol. 5, no. 1, pp. 1–9, 2014.
[168] S. W. Oh, J. A. Harris, L. Ng, B. Winslow, N. Cain, S. Mihalas,
Q. Wang, C. Lau, L. Kuan, A. M. Henry et al., “A mesoscale
connectome of the mouse brain,” Nature, vol. 508, no. 7495, pp. 207–
214, 2014.
[169] H. Markram, M. Toledo-Rodriguez, Y. Wang, A. Gupta, G. Silberberg,
and C. Wu, “Interneurons of the neocortical inhibitory system,” Nature
reviews neuroscience, vol. 5, no. 10, pp. 793–807, 2004.
[170] D. S. Modha and R. Singh, “Network architecture of the long-distance
pathways in the macaque brain,” Proceedings of the National Academy
of Sciences, vol. 107, no. 30, pp. 13 485–13 490, 2010.
[171] T. Zhang, Y. Zeng, and B. Xu, “A computational approach towards the
microscale mouse brain connectome from the mesoscale,” Journal of
integrative neuroscience, vol. 16, no. 3, p. 291—306, 2017.
[172] R. Bakker, T. Wachtler, and M. Diesmann, “Cocomac 2.0 and the future
of tract-tracing databases,” Frontiers in neuroinformatics, vol. 6, pp.
30–30, Dec 2012.
[173] R. Chaudhuri, K. Knoblauch, M. A. Gariel, H. Kennedy, and X.-J.
Wang, “A large-scale circuit mechanism for hierarchical dynamical
processing in the primate cortex,” Neuron, vol. 88, pp. 419–431, 2015.
[174] C. E. Collins, D. C. Airey, N. A. Young, D. B. Leitch, and J. H. Kaas,
“Neuron densities vary across and within cortical areas in primates,”
Proceedings of the National Academy of Sciences, vol. 107, no. 36, pp.
15 927–15 932, 2010.

28
[175] X. Liu, Y. Zeng, T. Zhang, and B. Xu, “Parallel brain simulator: A
multi-scale and parallel brain-inspired neural network modeling and
simulation platform,” Cognitive Computation, vol. 8, no. 5, pp. 967–
981, Oct 2016.
[176] T. L. Davis and P. Sterling, “Microcircuitry of cat visual cortex:
Classification of neurons in layer iv of area 17, and identification of the
patterns of lateral geniculate input,” Journal of Comparative Neurology,
vol. 188, no. 4, pp. 599–627, 1979.
[177] L. Fan, H. Li, J. Zhuo, Y. Zhang, J. Wang, L. Chen, Z. Yang, C. Chu,
S. Xie, A. R. Laird, P. T. Fox, S. B. Eickhoff, C. Yu, and T. Jiang, “The
human brainnetome atlas: A new brain atlas based on connectional
architecture,” Cerebral cortex (New York, N.Y. : 1991), vol. 26, no. 8,
pp. 3508–3526, Aug 2016.
[178] A. Klein and J. Tourville, “101 labeled brain images and a consistent
human cortical labeling protocol,” Frontiers in neuroscience, vol. 6,
pp. 171–171, Dec 2012.
[179] B. Han, F. Zhao, Y. Zeng, and G. Shen, “Developmental plasticity-
inspired adaptive pruning for deep spiking and artificial neural net-
works,” 2022.
[180] G. Shen, D. Zhao, Y. Dong, and Y. Zeng, “Bio-inspired neural
architecture search for efficient spiking neural networks,” 2022.
[181] K.-C. Peng, T. Chen, A. Sadovnik, and A. C. Gallagher, “A mixed
bag of emotions: Model, predict, and transfer emotion distributions,”
in Proceedings of the IEEE conference on computer vision and pattern
recognition, 2015, pp. 860–868.

