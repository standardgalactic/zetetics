Near-optimal Ofﬂine and Streaming Algorithms for
Learning Non-Linear Dynamical Systems
Prateek Jain
Google AI Research Lab,
Bengaluru, India 560016
prajain@google.com
Suhas S Kowshik
Department of EECS
MIT,
Cambridge, MA 02139
suhask@mit.edu
Dheeraj Nagaraj
Department of EECS
MIT,
Cambridge, MA 02139
dheeraj@mit.edu
Praneeth Netrapalli
Google AI Research Lab,
Bengaluru, India 560016
pnetrapalli@google.com
Abstract
We consider the setting of vector valued non-linear dynamical systems Xt+1 =
φ(A∗Xt) + ηt, where ηt is unbiased noise and φ : R →R is a known link function
that satisﬁes certain expansivity property. The goal is to learn A∗from a single
trajectory X1, · · · , XT of dependent or correlated samples. While the problem is
well-studied in the linear case, where φ is identity, with optimal error rates even for
non-mixing systems, existing results in the non-linear case hold only for mixing
systems. In this work, we improve existing results for learning nonlinear systems in
a number of ways: a) we provide the ﬁrst ofﬂine algorithm that can learn non-linear
dynamical systems without the mixing assumption, b) we signiﬁcantly improve
upon the sample complexity of existing results for mixing systems, c) in the much
harder one-pass, streaming setting we study a SGD with Reverse Experience Replay
(SGD −RER) method, and demonstrate that for mixing systems, it achieves the
same sample complexity as our ofﬂine algorithm, d) we justify the expansivity
assumption by showing that for the popular ReLU link function — a non-expansive
but easy to learn link function with i.i.d. samples — any method would require
exponentially many samples (with respect to dimension of Xt) from the dynamical
system. We validate our results via simulations and demonstrate that a naive
application of SGD can be highly sub-optimal. Indeed, our work demonstrates that
for correlated data, specialized methods designed for the dependency structure in
data can signiﬁcantly outperform standard SGD based methods.
1
Introduction
Non-linear dynamical systems (NLDS) are commonly used to model the data in a variety of domains
like control theory, time-series analysis, and reinforement learning (RL) [1–4]. Standard NLDS
models the data points (X0, X1, . . . , XT ) as:
Xt+1 = φ(A∗Xt) + ηt,
(1)
where Xt ∈Rd are the states, ηt ∈Rd are i.i.d. noise vectors, A∗∈Rd×d and φ : R →R is an
increasing function called the ‘link function’. Here, φ is supposed to act component wise over Rd.
System identiﬁcation problem is a foundational problem for NLDS, i.e., given (X0, X1, . . . , XT )
generated from (1), the goal is to estimate A∗accurately from a single trajectory (X0, X1, . . . , XT ).
35th Conference on Neural Information Processing Systems (NeurIPS 2021).

The system identiﬁcation problem is heavily studied in control theory [5–8] as well as time-series
analysis [9]. For instance, the non-linear dynamical system considered here has an application in
modeling non-linear distortions in power ampliﬁers [10]. The problem is challenging as data points
X0, X1, . . . , XT are not i.i.d. as usually encountered in machine learning, but form a Markov process.
If the mixing time τmix of the process is ﬁnite (τmix < ∞), then we can make the data approximately
i.i.d. by considering only the points separated by ˜O(τmix) time. While this allows using standard
techniques for i.i.d. data, it reduces the effective number of samples to O( T
τmix ), which typically gives
an error of the order O( τmix
T ). In fact, even the state-of-the-art results have error bounds which are
sub-optimal by a factor of τmix.
Interestingly, for the special case of linear systems, i.e., when φ(x) = x, the results are signiﬁcantly
stronger. For example, [11, 12] showed that the matrix A∗can be estimated with an error O(1/T)
even when the mixing time τmix > T. But these results rely on the fact that for linear systems, the
estimation problem reduces to an ordinary least squares (OLS) problem for which a closed form
expression is available and can be analyzed effectively.
On the other hand, NLDS do not admit such closed form expressions. In fact the existing techniques
mostly rely on mixing time arguments to induce i.i.d. like behavior in a subset of the points which
leads to sub-optimal rates by τmix factor. Similarly, a direct application of uniform convergence
results [13] to show that the minimizer of the empirical risk is close to the population minimizer
still gives sub-optimal rates as off-the-shelf concentration inequalities (cf. [14]) incur an additional
factor of mixing time. Finally, existing results are mostly focused on ofﬂine setting, and do not apply
to the case where the data points are streaming which is critical in several practical problems like
reinforcement learning (RL) and control theory.
In this work, we provide algorithms and their corresponding error rates for the NLDS system
identiﬁcation problem in both ofﬂine and online setting, assuming the link function to be expansive
(Assumption 1). The main highlight of our results is that the error rates are independent of the
mixing time τmix, which to the best of our knowledge is ﬁrst such result for any non-linear system
identiﬁcation in any setting. In fact, for ofﬂine setting, our analysis holds even for systems which do
not mix within time T and even for marginally stable systems which do not mix at all. Furthermore,
we analyze SGD-Reverse Experience Replay (SGD-RER) method, we provide the ﬁrst streaming
method for NLDS identiﬁcation with error rate that is independent of τmix (in the leading order term)
while still ensuring small space and time complexity. This algorithm was ﬁrst discovered in the
experimental RL setting in [15] based on Hippocampal reverse replay observed in biological networks
[16–18]. It was introduced independently in [19] for the case of linear systems and efﬁciently unravels
the complex dependency structure present in the problem. Finally, through a lower bound for ReLU—
a non-expansive function—we provide strong justiﬁcation for why expansivity might be necessary
for a non-trivial result.
Instead of mixing time arguments, our proofs for learning NLDS without mixing use a natural
exponential martingale of the kind considered in the analysis of self normalized process ([20, 21]).
For streaming setting, while we do use mixing time arguments (proof of Theorems 2 and 3), we
combine them with a delicate stability analysis of the speciﬁc algorithm and the machinery developed
in [19] to obtain strong error bounds. See Section 6 for a description of these techniques.
Our Contributions. Key contributions of the paper are summarized below:
1. Assuming expansive and monotonic link function φ and sub-Gaussian noise, we show that the
ofﬂine Quasi Newton Method (Algorithm 1) estimates the parameter A∗with near optimal errors
of the order O(1/T), even when the dynamics does not mix within time T.
2. Assuming mixing NLDS, ﬁnite fourth moment on the noise, and expansive monotonic link
function, we show that ofﬂine Quasi Newton Method again estimates the parameter A∗with
near-optimal error of O(1/T), independent of mixing time τmix.
3. We give a one-pass, streaming algorithm inspired by SGD −RER method by [19], and show that
it achieves near-optimal error rates under the assumption of sub-Gaussian noise, NLDS stability
(see section 2.1 for the deﬁnition), uniform expansivity and second differentiability of the link
function.
4. We then show that learning with ReLU link function, which is non-expansive but is known to be
easy to learn with if data points are all i.i.d. [22], requires exponential (in d) many samples.
2

We believe that the techniques developed in this work can be extended to provide efﬁcient algorithms
for learning with dependent data in more general settings.
Related Works.
NLDS has been studied in a variety of domains like time-series and recurrent
neural networks (RNN). [9] studies speciﬁc NLDS models from a time series perspective and
establishes non-asymptotic convergence bounds for natural estimators; their error rates suffer from
mixing time factor τmix. [23] considers asymptotic learning of NLDS via neural networks trained
using SGD, whereas [24] shows that overparametrized LSTMs trained with SGD learn to memorize
the given data. [25–27] consider learning dynamical systems of the form ht+1 = φ(A∗ht + B∗ut)
for states ht and inputs ut; this setting is different from standard NLDS model we study. [28]
considers the non linear dynamical systems of the form xt+1 = Aφ(xt, ut) + ηt which φ is a known
non-linearity and matrix A is to be estimated. [29, 30] consider essentially linear dynamics but allow
for certain non-linearities that can be modeled as process noise. All these again differ from the model
we consider.
Standard NLDS identiﬁcation (1) has received a lot of attention recently, with results by [31, 32]
being the most relevant. [31] uses uniform convergence results via. mixing time arguments to obtain
parameter estimation error for ofﬂine SGD. [32] obtains similar bounds via. the analysis of the
GLMtron algorithm [33]. However, both these works suffer from sub-optimal dependence on the
mixing time. We refer to Table 1 for a comparison of the results. [34], which appeared after the
initial manuscript of this work, considers the question from a perspective of time series forecasting.
This work considers sparsity in A∗and an unknown link function which is estimated with isotonic
regression. Their recovery guarantees eschew the mixing time dependence. However, the setting,
assumptions and the error rates are incomparable to our setting.
[32] also obtains within sample prediction error in the case when φ is not uniformly expansive along
with parameter recovery bounds when φ is the ReLU function and the driving noise is Gaussian.
However, the parameter estimation bounds for ReLU suffer from an exponential dependence on the
dimension d and mixing time τmix. In Theorem 4 we establish that indeed we cannot improve the
exponential dependence in the dimension d for the case of parameter estimation. We note that the
exponential dependence arises due to the dynamics present in the system since ReLU regression with
isotropic i.i.d. data in well speciﬁed case has only a polynomial dependence in d [22].
Linear system identiﬁcation (LSI) literature has been well studied with strong minimax optimal
bounds [11, 35, 36]. These results primarily consider the (convex) empirical square loss which has
a closed form solution. However, the square loss in the non-linear case is non-convex. Under the
assumption that the link function is increasing, we consider a convex proxy loss which is widely used
in generalized linear regression literature [22, 33, 37]. Similarly, GLMtron algorithm for learning
NLDS in[32] (see Equation (3)) also considers a similar proxy loss. In [38], the authors consider a
family of GLMtron-like algorithms call Reﬂectron under the i.i.d. data setting. But they compare the
performance of these algorithms experimentally on an NLDS similar to one considered in this work
under low rank assumption on the system matrix.
Finally, streaming setting for LSI has been recently studied in different model settings [19, 39]. These
methods observe that by exploiting techniques like experience replay ([40]) along with squared loss
error, one can obtain strong error rates. SGD −RER method studied in this work is inspired by a
similar method by [19] which was primarily studied for the linear case.
2
Problem Statement
Let φ : R →R be an increasing, 1-Lipschitz function such that φ(0) = 0. Suppose X0 ∈Rd is a
random variable and A∗∈Rd×d. We consider the following non-linear dynamical system (NLDS):
Xt+1 = φ(A∗Xt) + ηt,
(2)
where the noise sequence η0, . . . , ηT is i.i.d random vectors independent of X0. The noise ηt is such
that Eηt = 0, Eηtη⊤
t = σ2I for some σ > 0. We will also assume that M4 := E∥ηt∥4 < ∞. Let
µ be the law of noise η. We denote the model above as NLDS(A∗, µ, φ). Whenever a stationary
distribution exists for the process, we will denote it by π(A∗, µ, φ) or just π when the process is clear
from context. We will call the trajectory X0, X1, . . . , XT ‘stationary’ if X0 is distributed according
to the measure π(A∗, µ, φ). Unless speciﬁed otherwise, we take X0 = 0 almost surely.
3

Paper
Guarantee
Link Function
System
Noise
Algorithm
[31]
THEOREM 6.2
d2τmix
T
INCREASING,LIPSCHITZ
EXPANSIVE
MIXING
SUB-GAUSSIAN
OFFLINE
[32]
THEOREM 2
d2τmix
T
INCREASING,LIPSCHITZ
EXPANSIVE
MIXING
SUB-GAUSSIAN
OFFLINE
THIS PAPER
THEOREM 1
d2σ2
T λmin( ˆ
G)
INCREASING,LIPSCHITZ
EXPANSIVE
NON-MIXING
SUB-GAUSSIAN
OFFLINE
THIS PAPER
THEOREM 2
d2σ2
T λmin(G)
INCREASING,LIPSCHITZ
EXPANSIVE
MIXING
4-TH MOMENT
OFFLINE
THIS PAPER
THEOREM 3
d2σ2
T λmin(G)
INCREASING,LIPSCHITZ
EXPANSIVE
BOUNDED SECOND DERIVATIVE
MIXING
SUB-GAUSSIAN
STREAMING
Table 1: Comparison of our results with existing results in terms of mixing time τmix, stablility and
number of samples T. Here, we take τmix = ˜Ω(
1
1−∥A∗∥op ) as a proxy for the mixing time. Note that
λmin (G) ≥σ2 in the worst case, and hence our bounds are better by a factor of τmix.
The goal is to estimate A∗given a single trajectory X0, X1, . . . , XT . A natural approach would be
to minimize the empirical square loss, i.e, Lsq(A; X) := 1
T
PT −1
t=0 ∥φ(AXt) −Xt+1∥2. However,
when the link function φ is not linear, then this would be non-convex and hard to optimize. Instead,
we use a convex proxy loss given by:
Lprox(A; X) = 1
T
T −1
X
t=0
d
X
i=1
¯φ(⟨ai, Xt⟩) −⟨ei, Xt+1⟩⟨ai, Xt⟩,
(3)
where ¯φ is the indeﬁnite integral of the link function φ and ai is the i-th row of A. Note that the
gradient of Lprox(A; X) with respect to A is given by:
∇Lprox(A; X) = 1
T
T −1
X
t=0
(φ(AXt) −Xt+1) X⊤
t .
(4)
When the model is clear from context and the stationary distribution exists, we will denote the second
moment matrix under the stationary distribution by G := E[XtX⊤
t ]. Note that G ⪰E[ηtη⊤
t ] = σ2I.
Also, the empirical second moment matrix is denoted by ˆG := 1
T
PT −1
t=0 XtX⊤
t .
2.1
Assumptions
We now state the assumptions below and use only a subset of the assumptions for each result.
Assumption 1 (Lipschitzness and Uniform Expansivity). φ is 1-Lipschitz and |φ(x) −φ(y)| ≥
ζ|x −y|, for some ζ > 0.
Note that when φ is only weakly differentiable but satisfy Assumption 1, with a slight abuse of
notation, we will write down φ(x) −φ(y) = φ′(β)(x −y) for some φ′(β) ∈[ζ, 1].
Assumption 2 (Bounded 2nd Derivative). φ is twice continuously differentiable and |φ′′| is bounded.
Assumption 3 (Noise Sub-Gaussianity). For any unit norm vector x ∈Rd, we have ⟨ηt, x⟩to be
sub-Gaussian with variance proxy Cησ2.
Next, we extend the deﬁnition of exponential stability in [31] to ‘exponential regularity’ to allow
unstable systems.
Assumption 4 (Exponential Regularity). Let XT = hT −1(X0, η0, . . . , ηT ) be the function repre-
sentation of XT . We say that NLDS(A∗, µ, φ) is (Cρ, ρ) exponentially regular if for any choice of
T ∈N and X0, X′
0, η0, . . . , ηT ∈Rd:
∥hT (X0, η0, . . . , ηT ) −hT (X′
0, η0, . . . , ηT )∥2 ≤CρρT −1∥X0 −X′
0∥2 .
When ρ < 1, we will call the system stable. When ρ = 1 we will call it ‘possibly marginally stable’
and when ρ > 1, we will call it ‘possibly unstable’.
4

Algorithm 1: Quasi Newton Method
Input
:Ofﬂine data {X0, . . . , XT }, horizon T, no. of iterations m, link function φ, step size γ
Output :Estimate Am
1 begin
2
A0
0 = 0 /*Initialization*/
3
ˆG ←1
T
PT −1
t=0 XtX⊤
t ; If ˆG is not invertible, then return Am = 0
4
for i ←0 to m −1 do
6
Ai+1 ←Ai −2γ (∇Lprox(Ai; X)) ˆG−1
Note that when Assumption 4 holds with ρ < 1, the system necessarily mixes and converges to a
stationary distribution as T →∞. Such systems forget their initial conditions in time scales of the
order τmix = O( 1+log Cρ
log 1
ρ
) = O

1+log Cρ
1−ρ

, and hence we use this as a proxy for the mixing time. In
what follows, when we say ‘the system does not mix’ we either mean that it does not mix within time
T or it does not converge to a stationary distribution (ex: ρ ≥1).
Assumption 5 (Norm Boundedness). ∥A∗∥op = ρ < 1
That is, if A∗satisﬁes Assumption 5, we have for arbitrary X, X′ ∈Rd: ∥φ(A∗X) −φ(A∗X′)∥≤
ρ ∥X −X′∥and
(φ ◦A∗)k(X)
 ≤ρk ∥X∥. Hence, for such A∗, NLDS is necessarily stable.
3
Ofﬂine Learning with Quasi Newton Method
In this section we consider estimating A∗using a single trajectory (X1, . . . , XT ) from
NLDS(A∗, µ, φ). To this end, we study an ofﬂine Quasi Newton Method (Algorithm 1) where
the iterates descend in the directions of the gradient of Lprox normalized by the inverse of the empiri-
cal second moment matrix ˆG := 1
T
PT −1
t=0 XtX⊤
t . That is, the iterates follow an approximation of
the standard Newton update.
We now present analysis of Algorithm 1 in two settings: a) Theorem 1 provides estimation error for
possibly unstable systems with sub-Gaussian noise that is close to the minimax optimal error incurred
in the linear system identiﬁcation case, b) Theorem 2 provides similarly tight estimation error for
mixing systems but with heavy-tailed noise.
Theorem 1 (Learning Without Mixing). Suppose Assumptions 1, 3 and 4 hold with expansivity
factor ζ and regularity parameters (Cρ, ρ). Let ¯C, ¯C3 be constants depending only on Cη, and let
δ ∈(0, 1
2). Let R∗:= C2
ρCηdσ2 PT −1
t=1 ρt2
log( 4T d
δ ), and assume
1. The number samples T ≥¯C3

d log

R∗
σ2

+ log 1
δ

2. Step size γ = 1
4
3. m ≥10
ζ · log

∥A0−A∗∥2
F·T R∗
σ2d2

Then, the output Am of Algorithm 1 after m iterations and λmin

ˆG

satisfy with probability at-least
≥1 −δ:
∥Am −A∗∥2
F ≤
¯
Cσ2
T ζ2λmin( ˆ
G)
h
d2 log

1 + R∗
σ2

+ d log
  2d
δ
i
,
λmin

ˆG

≥σ2
2 .
Note that as λmin( ˆG) ≳σ2, the error rate scales as ≈d2/T, independent of τmix ≈1/(1 −ρ). The
theorem also holds for non-mixing or possibly unstable systems as long as ρ < 1 + C
T . Furthermore,
the error bound above is similar to the minimax optimal bound by [11] for the linear setting, i.e., when
5

φ(x) = x. As the link function φ tends to decrease the information in x, intuitively lower bound for
linear setting should apply for NLDS as well, which would imply our error rate to be optimal; we
leave further investigation into lower bound of NLDS identiﬁcation for future work. Interestingly, in
the linear case whenever the smallest singular value σmin(A∗) > 1 + ϵ, it can be show than λmin( ˆG)
grows exponentially with T, leading to an exponentially small error. It is not clear how to arrive at
such a growth lower bound in the non-linear case.
The computational complexity of the algorithm scales as m · T which depends only logarithmically
on τmix. Interestingly, the algorithm is almost hyperparameter free, and does not require knoweldge
of parameters σ, τmix, ζ.
Also note that the stationary points of Algorithm 1 and GLMtron ( [32]) are the same. So, the stronger
error rate in the result above compared to the result by [32] is due to a sharper analysis. However, in
dynamical systems of the form 1, the squared norm of the iterates grow as
d
1−ρ even in the stable
case. Hence, the GLMtron algorithm requires step sizes to be ≈1−ρ
d
which implies signiﬁcantly
slower convergence rate for large τmix = 1/(1 −ρ). In contrast, convergence rate for Algorithm 1
depends at most logarithmically on τmix.
Theorem 2 (Learning with Heavy Tail Noise). Suppose Assumptions 1 and 4 hold. In Assumption 4,
let ρ < 1. Let X0, . . . , XT be a stationary trajectory drawn from NLDS(A∗, µ, φ) and Am be the
m-th iterate of Algorithm 1. For some universal constants C, C1, C0 > 0, whenever δ ∈(0, 1
2),
R∗:=
4T dC2
ρσ2
(1−ρ)2δ and
1. T ≥Cd log( 1
δ ) log( R∗
σ2 ) max


4C6
ρM4
(1−ρ)4(1−ρ2)σ4 ,
log
 R∗C1Cρ
σ2

log
 1
ρ



2. Step size γ = 1
4
3. m ≥10
ζ · log

∥A0−A∗∥2
F·T R∗
σ2d2

There exists an event W ∈σ(X0, η0, . . . , ηT −1) with P(W) ≥1 −δ and :
E

∥Am −A∗∥2
F1(W)

≤
C0d2σ2
ζ2Tλmin (G).
Obtaining High Probability Bounds:
The bound above shows that the expectation of the error
restricted to a high probability set is small. This, along with Markov inequality, shows that we
can have an error of at-most
Cd2σ2
ζ2T λmin(G) with probability at-least 2
3. This can be boosted to a high
probability bound by splitting the horizon T into K contiguous segments with a gap of O(τmix log T)
to maintain approximate independence (see Section C.2). We then run the Quasi Newton method
on each of these ‘split’ data sets to obtain nearly independent estimates ˆA1, . . . , ˆAK, which each
have error at-most
Cd2σ2K
ζ2T λmin(G) with probability at-least 2
3. Using a standard high-dimensional median
of means estimator (see [41, Algorithm 3]) for ˆA1, . . . , ˆAK, we obtain error bounds of the order
Cd2σ2K
ζ2T λmin(G) with probability at least 1 −e−Ω(K).
We refer to Section 6 for a high-level exposition of the key ideas in the analysis and Section B for the
full proof of Theorems 1 and 2.
4
Streaming Learning with SGD-RER
In this section, we consider the one-pass, streaming setting, where the data points are presented in a
streaming fashion. The goal is to continuously produce better estimates of A∗while also ensuring that
the space and the time complexity of the algorithm is small. This disallows approaches that would
just store all the observed points and then apply ofﬂine Algorithm 1 to produce strong estimation
error. Such one-pass streaming algorithms are critical in a variety of settings like large-scale and
online time-series analysis [42, 43], TD learning in RL [44], econometrics.
6

Figure 1: Data order in SGD −RER, where each block represents a data point. Blue arrows indicate
the data processing order. The gaps ensure approximate independence between successive buffers.
Algorithm 2: SGD −RER
Input
:Streaming data {Xτ}, horizon T, buffer size B, buffer gap u, bound R, tail start:
t0 ≤N/2, link function φ, step size γ
Output :Estimate ˆAt0,t, for all t0 ≤t ≤N −1; N = T/(B + u)
1 begin
2
Total buffer size: S ←B + u, Number of buffers: N ←T/S
3
A0
0 = 0 /*Initialization*/
4
for t ←1 to N do
5
Form buffer Buft−1 = {Xt−1
0
, . . . , Xt−1
S−1}, where, Xt−1
i
←X(t−1)·S+i
6
If ∃i, s.t.,
Xt−1
i
2 > R, then return ˆAt0,t = 0
7
for i ←0 to B −1 do
9
At−1
i+1 ←At−1
i
−2γ

φ(At−1
i
Xt−1
S−i−1) −Xt−1
S−i

Xt−1,⊤
S−i−1
10
At
0 = At−1
B
11
If t ≥t0 + 1, then ˆAt0,t ←
1
t−t0
Pt
τ=t0+1 Aτ−1
B
To address this problem, we consider SGD −RER (Algorithm 2) which was introduced in [19] in the
context of linear system identiﬁcation (LSI). We apply the method for NLDS identiﬁcation as well.
SGD −RER uses SGD like updates, but the data is processed in a different order than it is received
from the dynamical system. This algorithm is based on the observation made in [19] that for LSI,
when SGD is run on the least squares loss in the forward order, there are spurious correlations which
prevent the algorithm’s convergence to the optimum parameter A∗. Surprisingly, considering the
data in the reverse order exactly unravels these correlations to resolve the problem. Reverse order
traversal of data, even though one pass, does not give a streaming algorithm. Hence, we divide the
data into multiple buffers of size B and leave of size u between the buffers (See Figure 1). The data
within each buffer is processed in the reverse order whereas the buffers themselves are processed in
the order received. See Figure 1 for an illustration of the processing order. The gaps u are set large
enough so that the buffers behave approximately independently. Setting B ≥10u we note that this
simple strategy improves the sample efﬁciency compared to naive data dropping since we use most of
the samples for estimating A∗. We now present the main result for streaming setting.
Theorem 3 (Streaming Algorithm). Suppose Assumptions
1, 2, 3 and
5 hold and that the
data points are stationary.
Set α = 100, R =
16(α+2)dCησ2 log T
1−ρ
, u ≥
2α log T
log( 1
ρ ) , B ≥

¯C1
d
(1−ρ)(1−ρ2) log

d
1−ρ

, 10u

for a global constant ¯C1 dependent only Cη and α. Let N =
T/(B + u) be the number of buffers. Finally, set step-size γ =
C
T ν where ν = 6.5/7 and let T be
large enough such that γ ≤min

ζ
4BR(1+ζ),
1
2R

. If N/2 > t0 > c1
log T
ζγBλmin(G) = Θ(T ν log T) for
some large enough constant c1 > 0, then output ˆAt0,N of Algorithm 2 satisﬁes:
E
h
∥ˆAt0,N −A∗∥2
F
i
≤C d2σ2 log T
Tλmin (G) ζ2 + Lower Order Terms
(5)
where C is a constant dependent on Cη, α.
Remark 1. The lower order terms are of the order Poly(R, B, β, 1/ζ, 1/λmin, ∥φ′′∥)γ7/2T 2 +
γ2Rσ2d
1
T α/2−2 + ∥A0 −A∗∥2
F
h
e−c2ζγBλmint0
T ζγλmin
i
. We refer to the proof in Section C.13 for details.
7

Remark 2. Although the bound in Theorem 3 is given for the algorithmic iterate at the end of the
horizon, the proof shows that in fact we can bound the error of the iterates at the end of each buffer
after (1 + c)t0 i.e. if t ≥(1 + c)t0 for some c > 0 then we obtain
E
h
∥ˆAt0,t −A∗∥2
F
i
≤C
d2σ2 log T
(tB)λmin (G) ζ2 + Lower Order Terms
Note that the estimation error above matches the error by ofﬂine method up to log factors (see
Theorem 2). Furthermore, while the method requires NLDS to be mixing, i.e., ρ < 1, but the leading
term in error rate does not have an explicit dependence on it. Moreover, the space complexity of the
method is only B ·d which scales as d2/((1−ρ)(1−ρ2)), i.e., it is 1/((1−ρ)(1−ρ2)) ∼τ 2
mix factor
worse than the obvious lower bound of O(d2) to store A. We leave further investigation into space
complexity optimization or tightening the lower bound for future work. Also, note that u ≤B/10,
so SGD −RER wastes only about 10% of the samples. Finally, the algorithm requires a reasonable
upper bound on ρ to set up various hyperparameters like R, u, B. However, it is not clear how to
estimate such an upper bound only using the data, and seems like an interesting open question.
See Section 6 for an explanation of the elements involved in the analysis of the algorithm and to
Section C.1 for a detailed overview of the proof.
5
Exponential Lower Bounds for Non-Expansive Link Functions
The previous results showed that we can efﬁciently recover the matrix A∗given that the link function
is uniformly expansive. We now consider non-expansive functions and show that parameter recovery
is hard in this case. In particular, we show that even for the case of φ = ReLU, the noise being
N(0, I), and ∥A∗∥≤1
2, the error has an information theoretic lower bound which is exponential in
the dimension. We note that this is consistent with Theorem 3 in [32] which too has an exponential
dependence on the dimension (since the matrix K ⪰I).
Before stating the results, we introduce some notation. Consider any algorithm A, with accepts input
(X0, . . . , XT ) and outputs an estimate ˆA ∈Rd×d. For simplicity of calculation, we will assume that
X0 = 0 and Xt+1 = ReLU(A∗Xt) + ηt. Since the mixing time is O(1), similar results should hold
for stationary sequences. We deﬁne the loss L(A, T, A∗) = E∥ˆA −A∗∥2
F , where the expectation
is over the randomness in the data and the algorithm. By Θ( 1
2), we denote all the the elements of
B ∈Rd×d such that ∥B∥≤1
2. The minimax loss is deﬁned as:
L(Θ( 1
2), T) := inf
A
sup
A∗∈Θ( 1
2 )
L(A, T, A∗) .
Theorem 4 (ReLU Lower Bound). For universal constants c0, c1 > 0, we have:
L(Θ( 1
2), T) ≥c0 min

1, exp(c1d)
T

.
We prove the theorem above using the two point method. We ﬁnd a family of A∗in Θ( 1
2, T) such that
⟨Xt, ed⟩= ⟨ηt−1, ed⟩with probability at-least 1 −exp(−Ω(d)). Therefore, with a large probability,
we only observe noise in the last co-ordinate and hence do not obtain any information regarding the
last row of A∗(i.e, a∗
d). We refer to Section G for a full proof.
6
Proof Sketch
Quasi Newton Method.
Let a∗
i be the i-th row of A∗and ai(l) be the i-th row of Al both in
column vector form. The proofs of Theorems 1 and 2 follow once we consider the lyapunov function
∆l,i = ∥ˆG1/2(ai(l) −a∗
i )∥and show that
∆l+1,i ≤(1 −2γζ)∆l + γ∥ˆG−1/2 ˆNi∥
(6)
Where ˆNi := 1
T
PT −1
t=0 ⟨ei, ηt⟩Xt. In the case of Theorem 1, we use the sub-Gaussianity of the noise
sequence and a martingale argument to obtain a high probability upper bound on Pd
i=1 ∥ˆG−1/2 ˆNi∥2
8

(see Lemma 1). In the heavy tailed case considered in Theorem 2, we use mixing time arguments
along with Payley-Zygmund inequality to show the high probability lower isometry ˆG ⪰c0G
for some universal constant c0 (see Lemma 2). Using this lower isometry, we can replace ˆG in
Equation (6) with G. The upper bounds follow once we note that E ˆN ⊤
i G−1 ˆNi = σ2d
T .
SGD-RER.
Due to the observations made in Section 4, we can split the analysis into the following
parts, which are explained in detail below.
1. Analyze the reverse order SGD within the buffers.
2. Treat successive buffer as independent samples.
3. Give a bias-variance decomposition similar to the case of linear regression.
4. Use algorithmic stability to control ’spurious’ coupling introduced by non-linearity in the bias-
variance decomposition.
Coupled Process.
We deal with the dependence between buffers using a ﬁctitious coupled process,
constructed just for the sake of analysis (see Deﬁnition 2). Leveraging the gap u, this process ( ˜Xτ)
is constructed such that ˜Xτ ≈Xτ with high probability and the ‘coupled buffers’ containing data
˜X instead of X are exactly independent. Since ˜Xτ ≈Xτ, the output of SGD −RER run with the
ﬁctitious coupled process should be close output of SGD −RER run with the actual data points. We
then use the strategy outlined above to analyze SGD −RER with the coupled process. In the analysis
given for SGD −RER, all the quantities with ˜· involve the coupled process ˜X instead of the real
process X.
Non-Linear Bias Variance Decomposition.
We use the mean value theorem to linearize the non-
linear problem. This works effectively when the step size γ is a vanishing function of the horizon T.
Observe that the a single SGD/ SGD −RER step for a single row can be written as:
a′
i −a∗
i = ai −a∗
i −2γ(φ(⟨ai, Xτ⟩) −φ(⟨a∗
i , Xτ⟩))Xτ + 2γ⟨ητ, ei⟩Xτ
=
 I −2γφ′(βτ)XτX⊤
τ

(ai −a∗
i ) + 2γ⟨ητ, ei⟩Xτ
(7)
In the second step, we have used the mean value theorem. Equation (7) can be interpreted as follows:
the matrix
 I −2γφ′(βτ)XτX⊤
τ

’contracts’ the distance between ai and a∗
i whereas the noise
2γ⟨ητ, ei⟩Xτ is due to the inherent uncertainty. This gives us a bias-variance decomposition similar
to the case of SGD with linear regression. We refer to Section C.5 for details on unrolling the
recursion in Equation (7) to obtain the exact bias-variance decomposition.
Algorithmic Stability: Unfortunately, non-linearities result in a ‘coupling’ between the contraction
matrices through the iterates via the ﬁrst derivative φ′(βτ) due to reverse order traversal. This is
an important issue since unrolling the recursion in (7), we encounter terms such as ⟨ητ, ei⟩(I −
2γφ′(βτ−1)Xτ−1X⊤
τ−1)Xτ, which have zero mean in the linear case. However, in the non-linear
case, βτ−1 depends on ητ due to reverse order traversal. We show that such dependencies are
‘weak’ using the idea of algorithmic stability ([45, 46]). In particular, we establish that the output of
the algorithm is not affected too much if we re-sample the entire data trajectory by independently
re-sampling a single noise co-ordinate (ητ becomes η′
τ and βτ−1 becomes β′
τ−1) when the step size γ
is small enough (in other words, the output is stable under small perturbations). Via second derivative
arguments, we show that βτ−1 ≈β′
τ−1.
Now observe that resampling noise ητ does not affect the past value of data i.e, Xτ, Xτ−1 and is
independent of β′
τ−1 by construction. Therefore
0 = E⟨ητ, ei⟩
 I −2γφ′(β′
τ−1)Xτ−1X⊤
τ−1

Xτ ≈E⟨ητ, ei⟩
 I −2γφ′(βτ−1)Xτ−1X⊤
τ−1

Xτ
Such a resampling procedure is also explored in [47] for the analysis of SGD with random reshufﬂing.
We put together all the ingredients above in order to prove the error bounds given in Theorem 3.
7
Experiments
In this section, we compare performance of our methods SGD −RER and Quasi Newton method
on synthetic data against the performance of standard baselines SGD (called ‘Forward SGD’ here),
9

10-4
10-3
10-2
10-1
100
101
102
10-2
10-1
100
(a) Error vs. Computation
102
103
104
105
10-2
10-1
100
101
(b) Error vs. SGD updates
Figure 2: Performance of various algorithms for the case of φ = LeakyReLU
GLMtron, along with the SGD −ER method that applies standard experience replay technique i.e,
the points from a buffer are sampled randomly instead of the reverse order. Since GLMtron and
Quasi Newton Method are ofﬂine and SGD −RER, SGD and SGD −ER are streaming, we compare
the algorithms by plotting parameter error measured by the Frobenius norm with respect to the
compute time. We also compare error vs. number of iterations for the streaming algorithms. We show
the results of additional experiments by considering various buffer sizes and heavy tailed noise in
Section A.
Synthetic data: We sample data from NLDS(A∗, µ, φ) where µ ∼N(0, σ2I) and A∗∈Rd×d is
generated from the "RandBiMod" distribution. That is, A∗= UΛU ⊤with random orthogonal U,
and Λ is diagonal with ⌈d/2⌉entries on diagonal being ρ and the remaining diagonal entries are set
to ρ/3. φ is the leaky ReLU function given by φ(x) = 0.5x1(x < 0) + x1(x ≥0). We set d = 5,
ρ = 0.98 and σ2 = 1. We set a horizon of T = 105.
Algorithm Parameters We set B = 240 and u = 10 for the buffer size and gap size respectively for
both SGD −RER and SGD −ER and use full averaging (i.e, θ = 0 in Algorithm 2 ). We set the step
size γ = 5 log T
T
for SGD, SGD −RER, and SGD −ER and γnewton = 0.2 and γGLMtron = 0.017.
From Figure 2 observe that SGD −ER and SGD obtain sub-optimal results compared SGD −RER,
Quasi Newton Method and GLMtron. After a single pass, the performance of SGD −RER almost
matches that of the ofﬂine algorithms. The step sizes for GLMtron have to be chosen to be small
in-order to ensure that the algorithm does not diverge as noted in Section 3, which slows down its
convergence time compared to the Quasi Newton method. We set the step size to be as large as
possible without obtaining divergence to inﬁnity.
8
Conclusion
In this work, we studied the problem of learning non-linear dynamical systems of the form (1)
from a single trajectory and analyzed ofﬂine and online algorithms to obtain near-optimal error
guarantees. In particular we showed that mixing time based arguments are not necessary for learning
certain classes of non-linear dynamical systems. Even though we show that one cannot hope for
efﬁcient parameter recovery with non-expansive link functions like ReLU, we do not deal with the
problem of minimizing the ‘prediction’ error - where we output a good predictor based on samples,
without parameter recovery. We believe that this problem would require signiﬁcantly different set of
techniques than the ones established in this work and hope to investigate this in future work. Presently
our work only deals with speciﬁc kinds of Markovian time evolution. It would also be interesting to
understand in general, the kind of structures which allow for learning without mixing based arguments.
Another related direction is to design simple and efﬁcient algorithms like SGD −RER for learning
with various models of dependent data by unraveling the dependency structure present in the data.
Acknowledgments and Disclosure of Funding
D.N. was supported in part by NSF grant DMS-2022448.
S.S.K was supported in part by Teaching Assistantship (TA) from EECS, MIT.
10

References
[1] Mathukumalli Vidyasagar. Nonlinear systems analysis. SIAM, 2002.
[2] Sheng Chen and Steve A Billings. Representations of non-linear systems: the NARMAX model.
International journal of control, 49(3):1013–1032, 1989.
[3] Jeffrey L Elman. Finding structure in time. Cognitive science, 14(2):179–211, 1990.
[4] Michael I Jordan. Serial order: A parallel distributed processing approach. In Advances in
psychology, volume 121, pages 471–495. Elsevier, 1997.
[5] Lennart Ljung. System identiﬁcation. Wiley encyclopedia of electrical and electronics engi-
neering, pages 1–19, 1999.
[6] Åström, Karl Johan and Eykhoff, Peter. System identiﬁcation—a survey. Automatica, 7(2):123–
162, 1971.
[7] Marco C Campi and Erik Weyer. Finite sample properties of system identiﬁcation methods.
IEEE Transactions on Automatic Control, 47(8):1329–1334, 2002.
[8] Mathukumalli Vidyasagar and Rajeeva L Karandikar. A learning theory approach to system
identiﬁcation and stochastic adaptive control. In Probabilistic and randomized methods for
design under uncertainty, pages 265–302. Springer, 2006.
[9] Eric C Hall, Garvesh Raskutti, and Rebecca Willett. Inference of high-dimensional autoregres-
sive generalized linear models. arXiv preprint arXiv:1605.02693, 2016.
[10] John Wood. Behavioral modeling and linearization of RF power ampliﬁers. Artech house,
2014.
[11] Max Simchowitz, Horia Mania, Stephen Tu, Michael I Jordan, and Benjamin Recht. Learning
without mixing: Towards a sharp analysis of linear system identiﬁcation. arXiv preprint
arXiv:1802.08334, 2018.
[12] Tuhin Sarkar and Alexander Rakhlin. Near optimal ﬁnite time identiﬁcation of arbitrary linear
dynamical systems. In International Conference on Machine Learning, pages 5610–5618.
PMLR, 2019.
[13] Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Stochastic Convex
Optimization. In COLT, 2009.
[14] Daniel Paulin et al. Concentration inequalities for Markov chains by Marton couplings and
spectral methods. Electronic Journal of Probability, 20, 2015.
[15] Egor Rotinov. Reverse experience replay. arXiv preprint arXiv:1910.08780, 2019.
[16] R Ellen Ambrose, Brad E Pfeiffer, and David J Foster. Reverse replay of hippocampal place
cells is uniquely modulated by changing reward. Neuron, 91(5):1124–1136, 2016.
[17] Tatsuya Haga and Tomoki Fukai. Recurrent network model for learning goal-directed sequences
through reverse replay. Elife, 7:e34171, 2018.
[18] Matthew T Whelan, Tony J Prescott, and Eleni Vasilaki. A robotic model of hippocampal
reverse replay for reinforcement learning. arXiv preprint arXiv:2102.11914, 2021.
[19] Prateek Jain, Suhas S Kowshik, Dheeraj Nagaraj, and Praneeth Netrapalli. Streaming Linear
System Identiﬁcation with Reverse Experience Replay. arXiv preprint arXiv:2103.05896, 2021.
[20] Abbasi-Yadkori, Yasin and Pál, Dávid and Szepesvári, Csaba.
Online least squares esti-
mation with self-normalized processes: An application to bandit problems. arXiv preprint
arXiv:1102.2670, 2011.
[21] Victor H Peña, Tze Leung Lai, and Qi-Man Shao. Self-normalized processes: Limit theory and
Statistical Applications. Springer Science & Business Media, 2008.
11

[22] Ilias Diakonikolas, Surbhi Goel, Sushrut Karmalkar, Adam R Klivans, and Mahdi Soltanolkotabi.
Approximation schemes for relu regression. In Conference on Learning Theory, pages 1452–
1485. PMLR, 2020.
[23] Sheng Chen, Stephen A Billings, and PM Grant. Non-linear system identiﬁcation using neural
networks. International journal of control, 51(6):1191–1214, 1990.
[24] Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. On the convergence rate of training recurrent
neural networks. arXiv preprint arXiv:1810.12065, 2018.
[25] Sohail Bahmani and Justin Romberg. Convex programming for estimation in nonlinear recurrent
models. arXiv preprint arXiv:1908.09915, 2019.
[26] Samet Oymak. Stochastic gradient descent learns state equations with nonlinear activations. In
Conference on Learning Theory, pages 2551–2579. PMLR, 2019.
[27] John Miller and Moritz Hardt. Stable recurrent models. arXiv preprint arXiv:1805.10369, 2018.
[28] Horia Mania, Michael I Jordan, and Benjamin Recht. Active learning for nonlinear system
identiﬁcation with guarantees. arXiv preprint arXiv:2006.10277, 2020.
[29] Arnab Sarker, Joseph E Gaudio, and Anuradha M Annaswamy. Parameter Estimation Bounds
Based on the Theory of Spectral Lines. arXiv preprint arXiv:2006.12687, 2020.
[30] Yanbing Mao, Naira Hovakimyan, Petros Voulgaris, and Lui Sha. Finite-Time Model Inference
From A Single Noisy Trajectory. arXiv preprint arXiv:2010.06616, 2020.
[31] Yahya Sattar and Samet Oymak. Non-asymptotic and accurate learning of nonlinear dynamical
systems. arXiv preprint arXiv:2002.08538, 2020.
[32] Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin. Learning nonlinear dynamical systems
from a single trajectory. In Learning for Dynamics and Control, pages 851–861. PMLR, 2020.
[33] Sham Kakade, Adam Tauman Kalai, Varun Kanade, and Ohad Shamir. Efﬁcient learning of gen-
eralized linear and single index models with isotonic regression. arXiv preprint arXiv:1104.2018,
2011.
[34] Yue Gao and Garvesh Raskutti. Improved prediction and network estimation using the monotone
single index multi-variate autoregressive model. arXiv preprint arXiv:2106.14630, 2021.
[35] Max Simchowitz, Ross Boczar, and Benjamin Recht. Learning linear dynamical systems with
semi-parametric least squares. In Conference on Learning Theory, pages 2714–2802. PMLR,
2019.
[36] Tuhin Sarkar, Alexander Rakhlin, and Munther A Dahleh. Finite-time system identiﬁcation for
partially observed lti systems of unknown order. arXiv preprint arXiv:1902.01848, 2019.
[37] Adam Tauman Kalai and Ravi Sastry. The Isotron Algorithm: High-Dimensional Isotonic
Regression. In COLT. Citeseer, 2009.
[38] Nicholas M Bofﬁ, Stephen Tu, and Jean-Jacques E Slotine. The Reﬂectron: Exploiting geometry
for learning generalized linear models. arXiv preprint arXiv:2006.08575, 2020.
[39] Dheeraj Nagaraj, Xian Wu, Guy Bresler, Prateek Jain, and Praneeth Netrapalli. Least Squares
Regression with Markovian Data: Fundamental Limits and Algorithms. Advances in Neural
Information Processing Systems, 33, 2020.
[40] Long-Ji Lin. Self-improving reactive agents based on reinforcement learning, planning and
teaching. Machine learning, 8(3-4):293–321, 1992.
[41] Daniel Hsu and Sivan Sabato. Loss minimization and parameter estimation with heavy tails.
The Journal of Machine Learning Research, 17(1):543–582, 2016.
[42] James Douglas Hamilton. Time series analysis. Princeton university press, 1994.
12

[43] Vitaly Kuznetsov and Mehryar Mohri. Time series prediction and online learning. In Conference
on Learning Theory, pages 1190–1213. PMLR, 2016.
[44] Richard S Sutton, Andrew G Barto, et al. Introduction to reinforcement learning, volume 135.
MIT press Cambridge, 1998.
[45] Bousquet, Olivier and Elisseeff, André. Stability and generalization. The Journal of Machine
Learning Research, 2:499–526, 2002.
[46] Moritz Hardt, Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of
stochastic gradient descent. In International Conference on Machine Learning, pages 1225–
1234. PMLR, 2016.
[47] Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. SGD without replacement: Sharper
rates for general smooth convex functions. In International Conference on Machine Learning,
pages 4703–4711. PMLR, 2019.
[48] Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal. Concentration inequalities: A
nonasymptotic theory of independence. Oxford university press, 2013.
[49] Aymeric Dieuleveut, Alain Durmus, Francis Bach, et al. Bridging the gap between constant
step size stochastic gradient descent and markov chains. Annals of Statistics, 48(3):1348–1382,
2020.
[50] Roman Vershynin. High-dimensional probability, 2019.
[51] Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv
preprint arXiv:1011.3027, 2010.
13

Checklist
1. For all authors...
(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s
contributions and scope? [Yes]
(b) Did you describe the limitations of your work? [Yes]
(c) Did you discuss any potential negative societal impacts of your work? [N/A] Currently
this is a purely theoretical work with multiple applications but right now they are not
fully ﬂeshed out.
(d) Have you read the ethics review guidelines and ensured that your paper conforms to
them? [Yes]
2. If you are including theoretical results...
(a) Did you state the full set of assumptions of all theoretical results? [Yes]
(b) Did you include complete proofs of all theoretical results? [Yes]
3. If you ran experiments...
(a) Did you include the code, data, and instructions needed to reproduce the main experi-
mental results (either in the supplemental material or as a URL)? [Yes]
(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
were chosen)? [Yes]
(c) Did you report error bars (e.g., with respect to the random seed after running experi-
ments multiple times)? [No]
(d) Did you include the total amount of compute and the type of resources used (e.g., type
of GPUs, internal cluster, or cloud provider)? [N/A] The experiments run on a standard
computer within 1 min.
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
(a) If your work uses existing assets, did you cite the creators? [N/A]
(b) Did you mention the license of the assets? [N/A]
(c) Did you include any new assets either in the supplemental material or as a URL? [N/A]
(d) Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? [N/A]
(e) Did you discuss whether the data you are using/curating contains personally identiﬁable
information or offensive content? [N/A]
5. If you used crowdsourcing or conducted research with human subjects...
(a) Did you include the full text of instructions given to participants and screenshots, if
applicable? [N/A]
(b) Did you describe any potential participant risks, with links to Institutional Review
Board (IRB) approvals, if applicable? [N/A]
(c) Did you include the estimated hourly wage paid to participants and the total amount
spent on participant compensation? [N/A]
14

