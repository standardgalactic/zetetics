
This page intentionally left blank

Introduction to Medical Imaging
Physics, Engineering and Clinical Applications
Covering the basics of X-rays, CT, PET, nuclear medicine, ultrasound and MRI, this
textbook provides senior undergraduate and beginning graduate students with a broad
introduction to medical imaging. Over 130 end-of-chapter exercises are included, in
addition to solved example problems, which enable students to master the theory as well
as providing them with the tools needed to solve more difﬁcult problems. The basic
theory, instrumentation and state-of-the-art techniques and applications are covered,
bringing students immediately up-to-date with recent developments, such as combined
computed tomography/positron emission tomography, multi-slice CT, four-dimensional
ultrasound and parallel imaging MR technology. Clinical examples provide practical
applications of physics and engineering knowledge to medicine. Finally, helpful refer-
ences to specialized texts, recent review articles and relevant scientiﬁc journals are
provided at the end of each chapter, making this an ideal textbook for a one-semester
course in medical imaging.
Nadine Barrie Smith is a faculty member in the Bioengineering Department and the
Graduate Program in Acoustics at Pennsylvania State University. She also holds a
visiting faculty position at the Leiden University Medical Center. She is a Senior Member
of the IEEE, and of the American Institute of Ultrasound in Medicine where she is on
both the Bioeffects and Technical Standards Committees. Her current research involves
ultrasound transducer design, ultrasound imaging and therapeutic applications of ultra-
sound. She has taught undergraduate medical imaging and graduate ultrasound imaging
courses for the past 10 years.
Andrew Webb is Professor of Radiology at the Leiden University Medical Center, and
Director of the C.J. Gorter High Field Magnetic Resonance Imaging Center. He is a
Senior Member of the IEEE, and a Fellow of the American Institute of Medical and
Biological Engineering. His research involves many areas of high ﬁeld magnetic reso-
nance imaging. He has taught medical imaging classes for graduates and undergraduates
both nationally and internationally for the past 15 years.

Cambridge Texts in Biomedical Engineering
Series Editors
W. Mark Saltzman, Yale University
Shu Chien, University of California, San Diego
Series Advisors
William Hendee, Medical College of Wisconsin
Roger Kamm, Massachusetts Institute of Technology
Robert Malkin, Duke University
Alison Noble, Oxford University
Bernhard Palsson, University of California, San Diego
Nicholas Peppas, University of Texas at Austin
Michael Sefton, University of Toronto
George Truskey, Duke University
Cheng Zhu, Georgia Institute of Technology
Cambridge Texts in Biomedical Engineering provides a forum for high-quality accessible
textbooks targeted at undergraduate and graduate courses in biomedical engineering. It
covers a broad range of biomedical engineering topics from introductory texts to
advanced topics including, but not limited to, biomechanics, physiology, biomedical
instrumentation, imaging, signals and systems, cell engineering, and bioinformatics. The
series blends theory and practice, aimed primarily at biomedical engineering
students, it also suits broader courses in engineering, the life sciences and medicine.

Introduction to
Medical Imaging
Physics, Engineering and
Clinical Applications
Nadine Barrie Smith
Pennsylvania State University
Andrew Webb
Leiden University Medical Center

cambridge university press
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore,
Sa˜o Paulo, Delhi, Dubai, Tokyo, Mexico City
Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
Information on this title: www.cambridge.org/9780521190657
 N. Smith and A. Webb 2011
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2011
Printed in the United Kingdom at the University Press, Cambridge
A catalogue record for this publication is available from the British Library
Library of Congress Cataloging-in-Publication Data
Webb, Andrew (Andrew G.)
Introduction to medical imaging : physics, engineering, and clinical
applications / Andrew Webb, Nadine Smith.
p. ; cm.
Includes bibliographical references and index.
ISBN 978-0-521-19065-7 (hardback)
1. Diagnostic imaging. 2. Medical physics. I. Smith, Nadine, 1962–2010.
II. Title.
[DNLM: 1. Diagnostic Imaging. WN 180]
RC78.7.D53.W43 2011
616.07#54–dc22
2010033027
ISBN 978-0-521-19065-7 Hardback
Additional resources for this publication at www.cambridge.org/9780521190657
Cambridge University Press has no responsibility for the persistence
or accuracy of URLs for external or third-party internet websites referred
to in this publication, and does not guarantee that any content
on such websites is, or will remain, accurate or appropriate.

‘‘This is an excellently prepared textbook for a senior/ﬁrst year graduate level course.
It explains physical concepts in an easily understandable manner. In addition, a problem
set is included after each chapter. Very few books on the market today have this choice.
I would deﬁnitely use it for teaching a medical imaging class at USC.’’
K. Kirk Shung, University of Southern California
‘‘I have anxiously anticipated the release of this book and will use it with both students
and trainees.’’
Michael B. Smith, Novartis Institutes for Biomedical Research
‘‘An excellent and approachable text for both undergraduate and graduate student.’’
Richard Magin, University of Illinois at Chicago


Contents
1 General image characteristics, data acquisition
and image reconstruction
1
1.1
Introduction
1
1.2
Speciﬁcity, sensitivity and the receiver operating
characteristic (ROC) curve
2
1.3
Spatial resolution
5
1.3.1
Spatial frequencies
5
1.3.2
The line spread function
6
1.3.3
The point spread function.
7
1.3.4
The modulation transfer function
8
1.4
Signal-to-noise ratio
10
1.5
Contrast-to-noise ratio
12
1.6
Image ﬁltering
12
1.7
Data acquisition: analogue-to-digital converters
15
1.7.1
Dynamic range and resolution
16
1.7.2
Sampling frequency and bandwidth
18
1.7.3
Digital oversampling
19
1.8
Image artifacts
20
1.9
Fourier transforms
20
1.9.1
Fourier transformation of time- and spatial
frequency-domain signals
21
1.9.2
Useful properties of the Fourier transform
22
1.10
Backprojection, sinograms and ﬁltered backprojection
24
1.10.1
Backprojection
26
1.10.2
Sinograms
27
1.10.3
Filtered backprojection
27
Exercises
30
2 X-ray planar radiography and computed tomography
34
2.1
Introduction
34
2.2
The X-ray tube
36
2.3
The X-ray energy spectrum
40

2.4
Interactions of X-rays with the body
42
2.4.1
Photoelectric attenuation
42
2.4.2
Compton scattering
43
2.5
X-ray linear and mass attenuation coefﬁcients
45
2.6
Instrumentation for planar radiography
47
2.6.1
Collimators
48
2.6.2
Anti-scatter grids
48
2.7
X-ray detectors
50
2.7.1
Computed radiography
50
2.7.2
Digital radiography
52
2.8
Quantitative characteristics of planar X-ray images
54
2.8.1
Signal-to-noise
54
2.8.2
Spatial resolution
57
2.8.3
Contrast-to-noise
58
2.9
X-ray contrast agents
59
2.9.1
Contrast agents for the GI tract
59
2.9.2
Iodine-based contrast agents
60
2.10
Specialized X-ray imaging techniques
61
2.10.1
Digital subtraction angiography
61
2.10.2
Digital mammography
62
2.10.3
Digital ﬂuoroscopy
63
2.11
Clinical applications of planar X-ray imaging
64
2.12
Computed tomography
66
2.12.1
Spiral/helical CT
67
2.12.2
Multi-slice spiral CT
68
2.13
Instrumentation for CT
68
2.13.1
Instrumentation development for helical CT
69
2.13.2
Detectors for multi-slice CT
70
2.14
Image reconstruction in CT
71
2.14.1
Filtered backprojection techniques
71
2.14.2
Fan beam reconstructions
73
2.14.3
Reconstruction of helical CT data
73
2.14.4
Reconstruction of multi-slice helical CT scans
74
2.14.5
Pre-processing data corrections
74
2.15
Dual-source and dual-energy CT
75
2.16
Digital X-ray tomosynthesis
76
2.17
Radiation dose
77
2.18
Clinical applications of CT
80
2.18.1
Cerebral scans
80
2.18.2
Pulmonary disease
81
2.18.3
Liver imaging
81
2.18.4
Cardiac imaging
82
Exercises
83
viii
Contents

3 Nuclear medicine: Planar scintigraphy, SPECT
and PET/CT
89
3.1
Introduction
89
3.2
Radioactivity and radiotracer half-life
91
3.3
Properties of radiotracers for nuclear medicine
92
3.4
The technetium generator
93
3.5
The distribution of technetium-based radiotracers
within the body
96
3.6
The gamma camera
97
3.6.1
The collimator
97
3.6.2
The detector scintillation crystal and coupled
photomultiplier tubes
100
3.6.3
The Anger position network and pulse height analyzer
103
3.6.4
Instrumental dead time
106
3.7
Image characteristics
108
3.8
Clinical applications of planar scintigraphy
109
3.9
Single photon emission computed tomography (SPECT)
110
3.10
Data processing in SPECT
112
3.10.1
Scatter correction
112
3.10.2
Attenuation correction
114
3.10.3
Image reconstruction
115
3.11
SPECT/CT
116
3.12
Clinical applications of SPECT and SPECT/CT
117
3.12.1
Myocardial perfusion
117
3.12.2
Brain SPECT and SPECT/CT
120
3.13
Positron emission tomography (PET)
121
3.14
Radiotracers used for PET/CT
123
3.15
Instrumentation for PET/CT
124
3.15.1
Scintillation crystals
125
3.15.2
Photomultiplier tubes and pulse height analyzer
127
3.15.3
Annihilation coincidence detection
127
3.16
Two-dimensional and three-dimensional PET imaging
129
3.17
PET/CT
130
3.18
Data processing in PET/CT
131
3.18.1
Attenuation correction
131
3.18.2
Corrections for accidental and multiple coincidences
131
3.18.3
Corrections for scattered coincidences
133
3.18.4
Corrections for dead time
134
3.19
Image characteristics
134
3.20
Time-of-ﬂight PET
135
3.21
Clinical applications of PET/CT
137
3.21.1
Whole-body PET/CT scanning
137
ix
Contents

3.21.2
PET/CT applications in the brain
137
3.21.3
Cardiac PET/CT studies
139
Exercises
139
4 Ultrasound imaging
145
4.1
Introduction
145
4.2
Wave propagation and characteristic acoustic impedance
146
4.3
Wave reﬂection, refraction and scattering in tissue
149
4.3.1
Reﬂection, transmission and refraction at tissue
boundaries
149
4.3.2
Scattering by small structures
152
4.4
Absorption and total attenuation of ultrasound
energy in tissue
153
4.4.1
Relaxation and classical absorption
154
4.4.2
Attenuation coefﬁcients
155
4.5
Instrumentation
156
4.6
Single element ultrasound transducers
157
4.6.1
Transducer bandwidth
159
4.6.2
Beam geometry and lateral resolution
161
4.6.3
Axial resolution
163
4.6.4
Transducer focusing
163
4.7
Transducer arrays
165
4.7.1
Linear arrays
166
4.7.2
Phased arrays
167
4.7.3
Beam-forming and steering via pulse transmission
for phased arrays
168
4.7.4
Analogue and digital receiver beam-forming
for phased arrays
171
4.7.5
Time-gain compensation
172
4.7.6
Multi-dimensional arrays
173
4.7.7
Annular arrays
174
4.8
Clinical diagnostic scanning modes
175
4.8.1
A-mode scanning: ophthalmic pachymetry
175
4.8.2
M-mode echocardiography
175
4.8.3
Two-dimensional B-mode scanning
176
4.8.4
Compound scanning
177
4.9
Image characteristics
178
4.9.1
Signal-to-noise
178
4.9.2
Spatial resolution
178
4.9.3
Contrast-to-noise
179
4.10
Doppler ultrasound for blood ﬂow measurements
179
4.10.1
Pulsed wave Doppler measurements
181
4.10.2
Duplex and triplex image acquisition
182
x
Contents

4.10.3
Aliasing in pulsed wave Doppler imaging
184
4.10.4
Power Doppler
186
4.10.5
Continuous-wave Doppler measurements
186
4.11
Ultrasound contrast agents
187
4.11.1
Microbubbles
187
4.11.2
Harmonic and pulse inversion imaging
190
4.12
Safety guidelines in ultrasound imaging
191
4.13
Clinical applications of ultrasound
193
4.13.1
Obstetrics and gynaecology
193
4.13.2
Breast imaging
194
4.13.3
Musculoskeletal structure
194
4.13.4
Echocardiography
195
4.14
Artifacts in ultrasound imaging
196
Exercises
197
5 Magnetic resonance imaging (MRI)
204
5.1
Introduction
204
5.2
Effects of a strong magnetic ﬁeld on protons in the body
205
5.2.1
Proton energy levels
206
5.2.2
Classical precession
209
5.3
Effects of a radiofrequency pulse on magnetization
211
5.3.1
Creation of transverse magnetization
212
5.4
Faraday induction: the basis of MR signal detection
213
5.4.1
MR signal intensity
214
5.4.2
The rotating reference frame
214
5.5
T1 and T2 relaxation times
215
5.6
Signals from lipid
219
5.7
The free induction decay
220
5.8
Magnetic resonance imaging
221
5.9
Image acquisition
223
5.9.1
Slice selection
223
5.9.2
Phase encoding
226
5.9.3
Frequency encoding
228
5.10
The k-space formalism and image reconstruction
229
5.11
Multiple-slice imaging
231
5.12
Basic imaging sequences
233
5.12.1
Multi-slice gradient echo sequences
233
5.12.2
Spin echo sequences
234
5.12.3
Three-dimensional imaging sequences
237
5.13
Tissue relaxation times
239
5.14
MRI instrumentation
241
5.14.1
Superconducting magnet design
241
xi
Contents

5.14.2
Magnetic ﬁeld gradient coils
244
5.14.3
Radiofrequency coils
247
5.14.4
Receiver design
250
5.15
Parallel imaging using coil arrays
252
5.16
Fast imaging sequences
254
5.16.1
Echo planar imaging
255
5.16.2
Turbo spin echo sequences
256
5.17
Magnetic resonance angiography
257
5.18
Functional MRI
259
5.19
MRI contrast agents
261
5.19.1
Positive contrast agents
261
5.19.2
Negative contrast agents
263
5.20
Image characteristics
264
5.20.1
Signal-to-noise
264
5.20.2
Spatial resolution
265
5.20.3
Contrast-to-noise
266
5.21
Safety considerations – speciﬁc absorption rate (SAR)
267
5.22
Lipid suppression techniques
267
5.23
Clinical applications
268
5.23.1
Neurological applications
268
5.23.2
Body applications
269
5.23.3
Musculoskeletal applications
270
5.23.4
Cardiology applications
271
Exercises
273
Index
283
xii
Contents

1 General image characteristics, data
acquisition and image reconstruction
1.1
Introduction
A clinician making a diagnosis based on medical images looks for a number of
different types of indication. These could be changes in shape, for example
enlargement or shrinkage of a particular structure, changes in image intensity
within that structure compared to normal tissue and/or the appearance of features
such as lesions which are normally not seen. A full diagnosis may be based upon
information from several different imaging modalities, which can be correlative or
additive in terms of their information content.
Every year there are signiﬁcant engineering advances which lead to improve-
ments in the instrumentation in each of the medical imaging modalities covered in
this book. One must be able to assess in a quantitative manner the improvements
that are made by such designs. These quantitative measures should also be directly
related to the parameters which are important to a clinician for diagnosis. The three
most important of these criteria are the spatial resolution, signal-to-noise ratio
(SNR) and contrast-to-noise ratio (CNR). For example, Figure 1.1(a) shows a
magnetic resonance image with two very small white-matter lesions indicated
by the arrows. The spatial resolution in this image is high enough to be able to
detect and resolve the two lesions. If the spatial resolution were to have been four
times worse, as shown in Figure 1.1(b), then only the larger of the two lesions is
now visible. If the image SNR were four times lower, illustrated in Figure 1.1(c),
then only the brighter of the two lesions is, barely, visible. Finally, if the CNR
between the lesions and the surrounding white matter is reduced, as shown in
Figure 1.1(d), then neither lesion can be discerned.
Although one would ideally acquire images with the highest possible SNR,
CNR and spatial resolution, there are often trade-offs between the three parameters
in terms of both instrument design and data acquisition techniques, and careful
choices must be made for the best diagnosis. This chapter covers the quantitative
aspects of assessing image quality, some of the trade-offs between SNR, CNR and
spatial resolution, and how measured data can be digitized, ﬁltered and stored.
At the end of this chapter, the two essential algorithms for reconstruction of

medical images, namely the Fourier transform and ﬁltered backprojection, are
introduced.
1.2
Speciﬁcity, sensitivity and the receiver operating characteristic
(ROC) curve
The accuracy of clinical diagnoses depends critically upon image quality, the
higher the quality the more accurate the diagnosis. Improvements in imaging
techniques and instrumentation have revolutionized early diagnosis and treatment
of a number of different pathological conditions. Each new imaging technique or
change in instrumentation must be carefully assessed in terms of its effect on
diagnostic accuracy. For example, although the change from planar X-ray ﬁlm
a
b
c
d
Figure 1.1
(a) MR image showing two small white-matter lesions indicated by the arrows. Corresponding
images acquired with (b) four times poorer spatial resolution, (c) four times lower SNR, and (d) a
reduced CNR between the lesions and the surrounding healthy tissue. The arrows point to lesions that
can be detected.
2
General image characteristics

to digital radiography clearly has many practical advantages in terms of data
storage and mobility, it would not have been implemented clinically had the
diagnostic quality of the scans decreased. Quantitative assessment of diagnostic
quality is usually reported in terms of speciﬁcity and sensitivity, as described in the
example below.
Consider an imaging study to determine whether a group of middle-aged
patients has an early indication of multiple sclerosis. It is known that this
disease is characterized by the presence of white matter lesions in the brain.
However, it is also known that healthy people develop similar types of lesion as
they age, but that the number of lesions is not as high as for multiple sclerosis
cases. When analyzing the images from a particular patient there are four
possible outcomes for the radiologist: a true positive (where the ﬁrst term ‘true’
refers to a correct diagnosis and the second term ‘positive’ to the patient having
multiple sclerosis), a true negative, a false positive or a false negative. The four
possibilities can be recorded in either tabular or graphical format, as shown in
Figure 1.2. The receiver operating characteristic (ROC) curve plots the number of
true positives on the vertical axis vs. the number of false positives on the horizontal
axis, as shown on the right of Figure 1.2. What criterion does the radiologist use to
make his/her diagnosis? In this simple example assume that the radiologist simply
counts the number of lesions detectable in the image. The relative number of true
positives, true negatives, false positives and false negatives depends upon the
particular number of lesions that the radiologist decides upon as being the thresh-
old for diagnosing a patient with multiple sclerosis. If this threshold number is very
high, for example 1000, then there will be no false positives, but no true positives
either. As the threshold number is reduced then the number of true positives will
increase at a greater rate than the false positives, providing that the images are
giving an accurate count of the number of lesions actually present. As the criterion
for the number of lesions is reduced further, then the numbers of false positives
and true positives increase at a more equal rate. Finally, if the criterion is
dropped to a very small number, then the number of false positives increases
much faster than the true positives. The net effect is to produce a curve shown
in Figure 1.2.
Three measures are commonly reported in ROC analysis:
(i) accuracy is the number of correct diagnoses divided by the total number of
diagnoses;
(ii) sensitivity is the number of true positives divided by the sum of the true
positives and false negatives; and
(iii) speciﬁcity is the number of true negatives divided by the sum of the number of
true negatives and false positives.
3
1.2 Speciﬁcity, sensitivity and the ROC curve

The aim of clinical diagnosis is to maximize each of the three numbers, with an
ideal value of 100% for all three. This is equivalent to a point on the ROC curve
given by a true positive fraction of 1, and a false positive fraction of 0. The
corresponding ROC curve is shown as the dotted line in Figure 1.2. The closer
the actual ROC curve gets to this ideal curve the better, and the integral under
the ROC curve gives a quantitative measure of the quality of the diagnostic
procedure.
A number of factors can inﬂuence the shape of the ROC curve, but from the
point-of-view of the medical imaging technology, the relevant question is: ‘what
fraction of true lesions is detected using the particular imaging technique?’. The
more lesions that are missing on the image, then intuitively the poorer the resulting
diagnosis. ‘Missing lesions’ may occur, referring to Figure 1.1, due to poor SNR,
CNR or spatial resolution. In turn, these will lead to a decreased percentage
accuracy, sensitivity and speciﬁcity of the diagnostic procedure.
Example 1.1
Suppose that a criterion used for diagnosis is, in fact, completely unrelated to the
actual medical condition, e.g. as a trivial example, trying to diagnose cardiac
disease by counting the number of lesions in the brain. Draw the ROC curve for
this particular situation.
Solution
Since the criterion used for diagnosis is independent of the actual condition,
effectively we have an exactly equal chance of a true positive or a false positive,
irrespective of the number of lesions found in the brain. Therefore, the ROC curve
is a straight line at an angle of 45 to the main axes, as shown below.
sis
o
r
elc
s elpitlu
M
n
oit
a
u
tis la
u
tc
A
y
htla
e
H
sis
o
r
elc
s elpitlu
M
sis
o
n
g
ai
D
y
htla
e
H
e
vitis
o
p e
sla
F
e
vitis
o
p e
u
r
T
e
vita
g
e
n e
u
r
T
e
vita
g
e
n e
sla
F
n
oitc
arf e
vitis
o
p e
u
r
T
n
oitc
arf e
vitis
o
p e
sla
F
0
5.0
0.1
0.1
5.0
x
x
x
x
x
x
x x
x
0
Figure 1.2
The receiver operating characteristic curve. (left) The 2 3 2 table showing the four possible
outcomes of clinical diagnosis. (right) A real ROC curve (solid line), with the ideal curve also shown
(dotted line).
4
General image characteristics

1.3
Spatial resolution
The spatial resolution of an imaging system is related to the smallest feature that
can be visualized or, more speciﬁcally, the smallest distance between two features
such that the features can be individually resolved rather than appearing as one
larger shape. The two most common measures in the spatial domain are the line
spread function (LSF) and point spread function (PSF). These measures can be
represented by an equivalent modulation transfer function (MTF) in the spatial
frequency domain. The concept of spatial frequency is very useful in characteriz-
ing spatial resolution, and is explained in the following section.
1.3.1 Spatial frequencies
One familiar example of spatial frequencies is a standard optician’s test. In one test,
patients are asked to look at a series of black lines on a white background, and then
to tell the optician if they can resolve the lines when a series of lenses with different
strengths are used. As shown in Figure 1.3, the lines are of different thickness and
separation. The spatial frequency of a particular grid of lines is measured as
the number of lines/mm, for example 5 mm21 for lines spaced 200 lm apart. The
closer together are the lines, the higher is the spatial frequency, and the better the
spatial resolution of the image system needs to be to resolve each individual line.
For each medical imaging modality, a number of factors affect the resolving
power. One can simplify the analysis by considering just two general components:
ﬁrst the instrumentation used to form the image, and second the quantity of data
that is acquired i.e. the image data matrix size. To take the everyday example of a
digital camera, the lens and electronics associated with the charge-coupled device
(CCD) detector form the instrumentation, and the number of pixels (megapixels) of
the camera dictates the amount of data that is acquired. The relative contribution of
each component to the overall spatial resolution is important in an optimal
a
b
c
Figure 1.3
Grid patterns with increasing spatial frequencies going from (a) to (c).
5
1.3 Spatial resolution

engineering design. There is no advantage in terms of image quality in increasing
the CCD matrix size from 10 megapixels to 20 megapixels if the characteristics of
the lens are poor, e.g. it is not well focused, produces blur, or has chromatic
aberration. Similarly, if the lens is extremely well-made, then it would be sub-
optimal to have a CCD with only 1 megapixel capability, and image quality would
be improved by being able to acquire a much greater number of pixels.
1.3.2 The line spread function
The simplest method to measure the spatial resolution of an imaging system is to
perform the equivalent of the optician’s test. A single thin line or set of lines is
imaged, with the relevant structure made of the appropriate material for each
different imaging modality. Examples include a strip of lead for an X-ray scan,
a thin tube of radioactivity for nuclear medicine imaging, or a thin wire embedded
in gel for an ultrasound scan. Since the imaging system is not perfect, it introduces
some degree of blurring into the image, and so the line in the image does not appear
as sharp as its actual physical shape. The degree of blurring can be represented
mathematically by a line-spread function (LSF), which is illustrated in Figure 1.4.
The LSF of an imaging system is estimated by measuring a one-dimensional
projection, as shown in Figure 1.4, with y deﬁned as the horizontal direction. The
width of the LSF is usually deﬁned by a parameter known as the full-width-at-half-
maximum (FWHM). As the name suggests, this parameter is the width of the
particular function at a point which is one-half the maximum value of the vertical
axis. From a practical point-of-view, if two small structures in the body are
LSF(y)
y
Figure 1.4
The concept of the line-spread function. A thin object is imaged using three different imaging systems.
The system on the left has the sharpest LSF, as deﬁned by the one-dimensional projection measured
along the dotted line and shown above each image. The system in the middle produces a more
blurred image, and has a broader LSF, with the system on the right producing the most blurred image
with the broadest LSF.
6
General image characteristics

separated by a distance greater than the FWHM of the LSF, then they can
be resolved as separate structures as opposed to one larger structure, as shown
in Figure 1.5.
The LSF for many imaging techniques is well-approximated by a Gaussian
function, deﬁned as:
LSF y
ð Þ 5
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2pr2
p
exp  y  y0
ð
Þ2
2r2
 
!
;
ð1:1Þ
where r is the standard deviation of the distribution, and y0 is the centre of the
function. The FWHM of a Gaussian function is given by:
FWHM 5
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2 ln 2
p


r ﬃ2:36r:
ð1:2Þ
Therefore, if the physical separation between two structures is greater than 2.36
times the standard deviation of the Gaussian function deﬁning the LSF of the
imaging system, then the two structures can be resolved.
1.3.3 The point spread function
The LSF describes system performance in one dimension. However, in some
imaging modalities, for example nuclear medicine, the spatial resolution becomes
poorer the deeper the location within the patient from which the signal is received.
Therefore, a full description of the spatial resolution of an imaging system requires
M
H
W
F
M
H
W
F
F
S
L
e
g
a
m
I
Figure 1.5
Imaging results produced by two different systems with a relatively narrow (left) and broad (right)
LSF. In the case on the left, two small structures within the body (top) have a separation which is
slightly greater than the FWHM of the LSF, and so the resulting image shows the two different
structures. In the case on the right, the FWHM of the LSF is greater than the separation of the
structures, and so the image appears as one large structure.
7
1.3 Spatial resolution

a three-dimensional formulation: the three-dimensional equivalent of the LSF is
termed the point spread function (PSF). As the name suggests, the PSF describes
the image acquired from a very small ‘point source’, for example a small sphere of
water for MRI. Examples of spatially symmetric and asymmetric PSFs are shown
in Figure 1.6.
Mathematically, the three-dimensional image (I) and object (O) are related by:
I x; y; z
ð
Þ 5 O x; y; z
ð
Þ  h x; y; z
ð
Þ;
ð1:3Þ
where * represents a convolution, and h(x,y,z) is the three-dimensional PSF. In a
perfect imaging system, the PSF would be a delta function in all three dimensions,
in which case the image would be a perfect representation of the object. In practice,
the overall PSF of a given imaging system is a combination of detection instru-
mentation and data sampling (covered in Section 1.7), and can be calculated by the
convolution of all of the individual components.
1.3.4 The modulation transfer function
The most commonly used measure of the spatial resolution of an imaging
system is the modulation transfer function (MTF). This measures the response
of a system to both low and high spatial frequencies. An ideal system has a
constant MTF for all spatial frequencies, i.e. it exactly reproduces both the ﬁne
structure (high spatial frequencies) and areas of relatively uniform signal
Object
x
y
z
a
b
c
d
Figure 1.6
(top) Small point object being imaged. (a)-(d) Images produced with different point spread functions.
(a) A sharp PSF in all three dimensions. (b) A PSF which is signiﬁcantly broader in x than in y or z. (c) A
PSF which is broadest in the y-dimension. (d) A PSF which is broad in all three dimensions.
8
General image characteristics

intensity (low spatial frequencies). In practice, as seen previously, imaging
systems have a ﬁnite spatial resolution, and the high spatial frequencies must
at some value start to be attenuated: the greater the attenuation the poorer the
spatial resolution. Mathematically, the MTF is given by the Fourier transform of
the PSF:
MTF kx; ky; kz


5 F PSF x; y; z
ð
Þ
f
g;
ð1:4Þ
where kx, ky and kz are the spatial frequencies measured in lines/mm corre-
sponding to the x,y and z spatial dimensions measured in mm. Properties of the
Fourier transform are summarized in Section 1.9. The relationship between a one-
dimensional (for simplicity) MTF and PSF is shown in Figure 1.7. The ideal MTF,
which is independent of spatial frequency, corresponds to a PSF which is a delta
function. The broader is the PSF the narrower the MTF, and the greater the degree
to which the high spatial frequency information is lost.
Since the PSF and MTF are related by the Fourier transform, and a convolution
in one domain is equivalent to multiplication in the other (Section 1.9.2), the
overall MTF of the imaging system can be calculated by multiplying together
the effects of all of the contributing components.
k
(
F
T
M
y)
ky
ky
ky
)
y
(
F
S
P
y
y
y
)
y
(
F
S
P
)
y
(
F
S
P
k
(
F
T
M
y)
k
(
F
T
M
y)
tc
ejb
o
a
b
c
Figure 1.7
(top) The object being imaged corresponds to a set of lines with increasing spatial frequency from
left-to-right. (a) An ideal PSF and the corresponding MTF produce an image which is a perfect
representation of the object. (b) A slightly broader PSF produces an MTF which loses the very high
spatial frequency information, and the resulting image is blurred. (c) The broadest PSF corresponds to
the narrowest MTF, and the greatest loss of high spatial frequency information.
9
1.3 Spatial resolution

1.4
Signal-to-noise ratio
In all measured or recorded signals there is some contribution from noise. Crackle
over the radio or on a mobile phone is perhaps the most familiar phenomenon.
Noise refers to any signal that is recorded, but which is not related to the actual
signal that one is trying to measure (note that this does not include image artifacts,
which are considered separately in Section 1.8). In the simplest cases, noise can be
considered as a random signal which is superimposed on top of the real signal.
Since it is random, the mean value is zero which gives no indication of the noise
level, and so the quantitative measure of the noise level is conventionally the
standard deviation of the noise. It is important in designing medical imaging
instrumentation that the recorded signal is as large as possible in order to get the
highest signal-to-noise ratio (SNR). An example of the effects of noise on image
quality is shown in Figure 1.8. As the noise level increases, the information content
and diagnostic utility of the image are reduced signiﬁcantly.
The factors that affect the SNR for each imaging modality are described in detail
in the relevant sections of each chapter. However, two general cases are summar-
ized here. If the noise is truly random, as in MRI, then the image SNR can be
increased by repeating a scan a number of times and then adding the scans
together. The true signal is the same for every scan, and so adds up ‘coherently’:
for N co-added scans the total signal is N times that of a single scan. However, the
noise at each pixel is random, and basic signal theory determines that the standard
deviation of a random variable increases only as the square root of the number of
co-added scans. Therefore, the overall SNR increases as the square root of the
number of scans. An example from MRI, in which such ‘signal averaging’ is
commonly used, is shown in Figure 1.9. The trade-off in signal averaging is the
additional time required for data acquisition which means that signal averaging
cannot be used, for example, in dynamic scanning situations.
In ultrasonic imaging the situation is more complicated since the major noise
contribution from speckle is coherent, and so signal averaging does not increase
the SNR. However, if images are acquired with the transducer oriented at different
angles with respect to the patient, a technique known as compound imaging
(covered in Section 4.8.4), then the speckle in different images is only partially
coherent. Averaging of the images, therefore, gives an increase in the SNR, but by
a factor less than the square root of the number of images.
In the second general case, as discussed in detail in Chapters 2 and 3, the SNR
in X-ray and nuclear medicine is proportional to the square root of the number of
X-rays and c-rays, respectively, that are detected. This number depends upon
many factors including the output dose of the X-ray tube or the amount of
10
General image characteristics

radioactive element injected and how much radiation is absorbed within the body.
The ultimate limit to the SNR is the radiation dose to the patient, with limits which
are controlled by various government guidelines throughout the world. X-ray
images in general have very high SNR, but for nuclear medicine scans the number
a
b
c
d
Figure 1.9
Signal averaging to improve the image SNR. (a) MR image acquired in a single scan, (b) two identical
scans averaged together, (c) four scans, and (d) sixteen scans.
Figure 1.8
The effects of noise on image quality for an MR image. As the standard deviation (r) of the noise is
increased (from top-to-bottom), features within the image become indistinguishable.
11
1.4 Signal-to-noise ratio

of c-rays detected is much lower, and so the scanning time is prolonged compared
to X-ray scans, with the total time limited by patient comfort.
1.5
Contrast-to-noise ratio
Even if a particular image has a very high SNR, it is not diagnostically useful
unless there is a high enough CNR to be able to distinguish between different
tissues, and in particular between healthy and pathological tissue. Various deﬁni-
tions of image contrast exist, the most common being:
CAB 5 SA  SB
j
j;
ð1:5Þ
where CAB is the contrast between tissues A and B, and SA and SB are the signals
from tissues A and B, respectively. The CNR between tissues A and B is deﬁned in
terms of the respective SNRs of the two tissues:
CNRAB 5 CAB
rN
5 SA  SB
j
j
rN
5 SNRA  SNRB
j
j;
ð1:6Þ
where rN is the standard deviation of the noise.
In addition to the intrinsic contrast between particular tissues, the CNR clearly
depends both on the image SNR and spatial resolution. For example, in Figure 1.1,
a decreased spatial resolution in Figure 1.1(b) reduced the image CNR due to
‘partial volume’ effects. This means that the contrast between the lesion and
healthy tissue is decreased, since voxels (volumetric pixels) contain contributions
from both the high contrast lesion, but also from the surrounding tissue due to the
broadened PSF. Figure 1.1(c) and Equation (1.6) show that a reduced SNR also
reduces the CNR.
1.6
Image ﬁltering
After the data have been acquired and digitized and the images reconstructed,
further enhancements can be made by ﬁltering the images. This process is similar
to that available in many software products for digital photography. The particular
ﬁlter used depends upon the imaging modality, and the image characteristics that
most need to be enhanced.
The simplest types of ﬁlter are either high-pass or low-pass, referring to their
characteristics in the spatial frequency domain, i.e. a high-pass ﬁlter accentuates
the high spatial frequency components in the image, and vice-versa. High spatial
12
General image characteristics

frequencies correspond to small objects and edges in the images, and so these are
‘sharpened’ using a high-pass ﬁlter, therefore improving the spatial resolution.
However, the noise present in the image, since it has a random pixel-to-pixel
variation, also corresponds to very high spatial frequencies, and so the SNR of a
high-pass ﬁltered image decreases, as shown in Figure 1.10. A high-pass ﬁlter is
suited, therefore, to images with very high intrinsic SNR, in which the aim is to
make out very ﬁne details.
In contrast, a low-pass ﬁlter attenuates the noise, therefore increasing the SNR
in the ﬁltered image. The trade-off is that other features in the image which are
also represented by high spatial frequencies, e.g. small features, are smoothed out
by this type of ﬁlter. Low-pass ﬁlters are typically applied to images with intrinsi-
cally low SNR and relatively poor spatial resolution (which is not substantially
further degraded by application of the ﬁlter), such as planar nuclear medicine
scans.
Specialized ﬁlters can also be used for detecting edges in images, for example.
This process is very useful if the aim is to segment images into different tissue
compartments. Since edges have a steep gradient in signal intensity from one pixel
to the adjacent one, one can consider the basic approach to be measuring the slope
k
Low-pass filter
MTF(k)
k
High-pass filter
MTF(k)
Figure 1.10
The effects of low-pass and high-pass ﬁltering. Low-pass ﬁlters improve the SNR at the expense of a
loss in spatial resolution: high-pass ﬁlters increase the spatial resolution but reduce the SNR.
13
1.6 Image ﬁltering

of the image by performing a spatial derivative. Since edge detection also ampliﬁes
the noise in an image, the process is usually followed by some form of low-pass
ﬁltering to reduce the noise.
A very simple example of how images can be ﬁltered in practice is the con-
volution of the image with a speciﬁed ﬁlter ‘kernel’. These can be represented by a
small matrix, a typical size being 3 3 3. In the one-dimensional example shown in
Figure 1.11, the image convolution process involves sliding the kernel across the
image, multiplying each pixel by the corresponding component of the kernel, and
replacing the centre pixel by the sum of these values. The kernel is then displaced
by one pixel in the horizontal dimension and the process repeated until the kernel
has been applied to all the pixels in this horizontal dimension. In the example in
Figure 1.11, the original image has one pixel with a particularly high value (32)
compared to the surrounding pixels. After ﬁltering, the difference is much lower,
showing the effects of the low-pass, smoothing ﬁlter. For two-dimensional ﬁlter-
ing, the above process is repeated for the next row of pixels until the whole image
has been covered.
3
5
1
2
3
3
4
4
0
1
6
6
4
5
9
6
5
7
8
8
2
1/1
2
1/1
2
1/1
2
1/1
2
1/4
2
1/1
2
1/1
2
1/1
2
1/1
3
5
1
b
a
4
4
0
1
6
6
4
5
9
d
c
7
8
8
/4
()
3
(
+
)
2
1/1
()
4
(
+
)
2
1/1
()
3
(
+
)
2
1/1
()
5
(
+
)
2
1/1
()
1
(
=
a
4.6
=
)
2
1/1
()
4
(
+
)
2
1/1
()
0
1
(
+
)
2
1/1
()
6
(
+
)
2
1/1
()
2
3
(
+
)
2
1
/4
()
2
3
(
+
)
2
1/1
()
3
(
+
)
2
1/1
()
5
(
+
)
2
1/1
()
3
(
+
)
2
1/1
()
5
(
=
b
3.4
1
=
)
2
1/1
()
8
(
+
)
2
1/1
()
4
(
+
)
2
1/1
()
0
1
(
+
)
2
1/1
()
5
(
+
)
2
1
/4
()
5
(
+
)
2
1/1
()
2
3
(
+
)
2
1/1
()
4
(
+
)
2
1/1
()
5
(
+
)
2
1/1
()
3
(
=
c
5.7
=
)
2
1/1
()
8
(
+
)
2
1/1
()
8
(
+
)
2
1/1
()
4
(
+
)
2
1/1
()
6
(
+
)
2
1
/4
()
6
(
+
)
2
1/1
()
5
(
+
)
2
1/1
()
6
(
+
)
2
1/1
()
4
(
+
)
2
1/1
()
5
(
=
d
3.6
=
)
2
1/1
()
7
(
+
)
2
1/1
()
8
(
+
)
2
1/1
()
8
(
+
)
2
1/1
()
9
(
+
)
2
1
3
5
1
3.4
1
4.6
4
4
0
1
6
6
4
5
9
6.3
5.7
7
8
8
e
g
a
m
i la
nigir
o
retlif
e
g
a
m
i d
eretlif
e
g
a
m
i d
eretlif
Figure 1.11
Numerical example showing the application of a low-pass convolution kernel. The original image is
ﬁltered, with image intensities 3, 32, 5 and 6 (shaded) being replaced by a, b, c and d, respectively, in
the ﬁltered image. These values are calculated as shown by the terms within parenthesis to give the
values shown in the lower grid.
14
General image characteristics

This is a very simple demonstration of ﬁltering. In practice much more sophis-
ticated mathematical approaches can be used to optimize the performance of the
ﬁlter given the properties of the particular image. This is especially true if the MTF
of the system is known, in which case either ‘matched’ ﬁltering or deconvolution
techniques can be used.
1.7
Data acquisition: analogue-to-digital converters
For many years, all medical images were viewed and stored on photographic
ﬁlm. Nowadays, all modern hospitals are in the ‘digital age’, in which images
are acquired and stored digitally. They can be post-processed and ﬁltered to
maximize the diagnostic quality, images acquired at different times can be quanti-
tatively compared to determine the effectiveness of a therapy, and images can also
be transferred automatically to another hospital if the patient moves location.
Irrespective of the particular medical imaging system, the common requirement
for producing digital images is an analogue-to-digital converter, which takes an
analogue input voltage from the medical imaging system and produces a digital
output. With the exception of MRI, the input signals from most medical imaging
modalities are not voltages per se, and so must be converted into voltages using an
appropriate detector. A general scheme of data ﬂow to produce a digital output is
shown in Figure 1.12.
X-rays
Planar radiography
Computed tomography
-rays
Nuclear medicine
SPECT, PET
Pressure waves
Ultrasound
Voltage
MRI
Detector
Analogue-
to-digital
converter
digital
output
digital
output
digital
output
digital
output
Amplifier
Analogue
voltage
Figure 1.12
Data ﬂow from different medical imaging modalities to produce a digital output.
15
1.7 Data acquisition: analogue-to-digital converters

1.7.1 Dynamic range and resolution
The ideal analogue-to-digital converter (ADC) converts a continuous voltage sig-
nal into a digital signal with as high a ﬁdelity as possible, while introducing as little
noise as possible. The important speciﬁcations of an ADC are the dynamic range,
voltage range (maximum-to-minimum), maximum sampling frequency and fre-
quency bandwidth.
The concept of dynamic range is familiar from digital photography and
audio devices such as CDs. For example, the dynamic range of a photograph
can be expressed as the number of colour levels or the number of graytone
levels. The greater the number, the more accurately subtle differences in
colour or graytone can be reproduced. Figure 1.13 shows an example of a
medical image which is digitized with a different number of graytone levels:
clearly the greater the number of levels, the higher the quality of the image.
Similarly, for an audio device, the dynamic range describes the difference in sound
levels that can be accurately reproduced, from very loud to very quiet. If
the dynamic range is too small, then very soft sounds may be too low to be
detected.
For an ADC, the dynamic range is measured in bits, and speciﬁes the number of
different values that the output of the ADC can have. For an N-bit ADC, the
number of different output values is given by 2N. For example, an 8-bit ADC
can have values from 1 to 255 (28=256), whereas a 16-bit ADC can give values
from 1 to 65535. The difference between these levels is called the resolution,
and its value is given by the voltage range of the ADC divided by the number
of levels.
256 levels
16 levels
4 levels
Figure 1.13
Representation of an MR image with a maximum of 256, 16 and 4 graytone levels, corresponding to
8, 4 and 2-bit ADCs. The image quality is already signiﬁcantly reduced at 16 levels.
16
General image characteristics

Example 1.2
What is the minimum voltage difference that can be measured by a 5 volt, 12-bit
ADC?
Solution
There are 4096 different levels that can be measured by the ADC, with values from
25 to 5 volts (note that the maximum voltage of the ADC refers to positive and
negative values). Therefore, the minimum voltage difference is given by 10/4096 =
2.44 mV.
Even ADCs with very high resolution cannot reproduce an analogue signal
perfectly. The difference between the true analogue input signal and the digitized
output is called the ‘quantization’ error, and this error becomes smaller the greater
the number of bits, as shown in Figure 1.14. From Figure 1.14, it can also been
seen that the values of the quantization error lie between 0 and 6 1/2 of the ADC
resolution.
In order to minimize the relative contribution of the quantization errors, there-
fore, the input voltage to the ADC should be as large as possible, without ‘saturat-
ing’ i.e. going above the maximum value of the ADC (which leads to artifacts).
Since the voltages at the output of the various detectors can be quite small, of the
order of micro or millivolts, an ampliﬁer is used with sufﬁcient gain to give a signal
to ﬁll the ADC.
a
b
c
d
Figure 1.14
Dynamic range and quantization error. (a) The analogue sinusoidal signal which is to be digitized.
(b) The signal recorded by a three-bit ADC (dark line) and the quantization error (dashed line).
(c) Corresponding plot for a ﬁve-bit ADC, and (d) a six-bit ADC.
17
1.7 Data acquisition: analogue-to-digital converters

1.7.2 Sampling frequency and bandwidth
The second important set of speciﬁcations for the ADC is the maximum
frequency that can be sampled and the bandwidth over which measurements
are to be made. The Nyquist theorem states that a signal must be sampled at least
twice as fast as the bandwidth of the signal to reconstruct the waveform accurately,
otherwise the high-frequency content will alias at a frequency inside the spectrum
of interest [1;2].
Before digitization, the incoming data pass through either a low-pass or
band-pass analogue ﬁlter to remove noise components outside the signal
bandwidth as shown in Figure 1.15. Acquiring a larger bandwidth than
necessary is sub-optimal since the noise level is proportional to the square
root of the bandwidth of the receiver. If the measurement bandwidth is less
than the range of the frequencies that one is digitizing, the signal outside the
measurement bandwidth will be aliased back into the spectrum, as shown in
Figure 1.15.
Each particular ADC has a speciﬁed maximum sampling rate at which it
can achieve its highest resolution: for example many ADCs used for medical
imaging systems can sample at 80 MHz with a 14- or 16-bit resolution, but
above this rate the resolution drops signiﬁcantly. If the signal to be digitized
has a frequency greater than the maximum sampling frequency of the ADC,
then it must be down-converted to a lower value before being fed into the
ADC.
5
1
0
2
0
1
la
n
gis d
e
s
aila
htdi
w
d
n
a
b
)z
H
k
( y
c
n
e
u
q
erf
5
1
0
2
0
1
htdi
w
d
n
a
b
)z
H
k
( y
c
n
e
u
q
erf
e
u
g
ola
n
a
retlif
Figure 1.15
(left) A set of signals between 10 and 20 kHz is acquired by setting the central frequency of the ADC
to 15 kHz with a 10 kHz bandwidth. (right) If an unexpected signal is present outside the bandwidth at
22 kHz, it is aliased back into the spectrum. Since the signal is partially ﬁltered out by the analogue
ﬁlter, the intensity of the aliased signal is reduced compared to its true intensity.
18
General image characteristics

1.7.3 Digital oversampling
There are a number of problems with the simple sampling scheme described in the
previous section. First, the analogue ﬁlters cannot be made absolutely ‘sharp’ (and
have other problems such as group delays and frequency-dependent phase shifts
that are not discussed here). Second, the resolution of a 14- or 16-bit ADC may not
be sufﬁcient to avoid quantization noise, but higher resolution ADCs typically do
not have high enough sampling rates and are extremely expensive. Fortunately,
there is a method, termed oversampling, which can alleviate both issues [3].
Oversampling, as the name suggests, involves sampling the signal at a much
higher frequency than required by the Nyquist theorem. The process is illustrated
in Figure 1.16. Since the bandwidth of the digitized voltage is much higher than the
actual bandwidth of the signals of interest, the edges of the analogue ﬁlter are
placed well away from the actual signals, and the sharpness of the ﬁlters is no
longer a problem (the other issues of group delays and phase shifts also disappear).
A digital ﬁlter is now applied to the sampled data to select only the bandwidth of
interest: a digital ﬁlter can be designed to have an extremely sharp transition. At
retlif ss
a
p
-
w
ol e
u
g
ola
n
a ,la
n
gis la
nigir
O
htdi
w
d
n
a
b h
gih y
re
v a hti
w
 d
e
zitigid si la
n
gi
S
retlif
ss
a
p
d
n
a
b latigid a f
o n
oita
cilp
p
A
n
oita
m
ic
e
D
m
u
rtc
e
p
s la
ni
F
Figure 1.16
An illustration of digital oversampling. The ﬁrst step is to apply an analogue low-pass ﬁlter to remove
spectral and noise components at frequencies much higher than the signal bandwidth. The data are
sampled at a frequency much greater than the Nyquist frequency. A digital bandpass ﬁlter is used to
select only the bandwidth of interest. Finally, the process of decimation (averaging of adjacent data
points) is used to reduce the quantization noise of the ﬁnal spectrum.
19
1.7 Data acquisition: analogue-to-digital converters

this stage, the ﬁltered data have N-times as many data points (where N is the
oversampling factor) as would have been acquired without oversampling, and
the ﬁnal step is to ‘decimate’ the data, in which successive data points are averaged
together. Since the quantization error in alternate data points is assumed to be
random, the quantization noise in the decimated data set is reduced. For every
factor-of-four in oversampling, the equivalent resolution of the ADC increases by
1-bit.
1.8
Image artifacts
The term ‘artifact’ refers to any signal in an image which is caused by a phenom-
enon related to the imaging process, but which distorts the image or introduces an
apparent feature which has no physical counterpart. There are many examples
speciﬁc to each imaging modality: for example, motion in MRI, multiple reﬂec-
tions in ultrasound, and metal-induced artifacts in both CT and MRI from implants.
Recognizing the causes of such artifacts is an important task for the person inter-
preting the images. Some examples are shown in Figure 1.17: many others are
covered in detail in the relevant chapters.
1.9
Fourier transforms
The Fourier transform is an integral part of image processing for all the image
modalities covered in this book. In MRI, the signal is acquired in the spatial
frequency-domain, and the signals undergo a multi-dimensional inverse Fourier
a
b
c
Figure 1.17
Examples of image artifacts. (a) Motion in MRI causes extra lines to appear in the image (arrowed),
(b) acoustic shadowing in ultrasound produces a black hole in the image (arrowed), and (c) a metal
implant causes ‘streaking artifacts’ in a CT image.
20
General image characteristics

transform to produce the image. In CT, SPECT and PET, ﬁltered backprojection
algorithms are implemented using Fourier transforms. In ultrasonic imaging, spec-
tral Doppler plots are the result of Fourier transformation of the time-domain
demodulated Doppler signals. This section summarizes the basis mathematics
and properties of the Fourier transform, with emphasis on those properties relevant
to the imaging modalities covered.
1.9.1 Fourier transformation of time- and spatial
frequency-domain signals
The forward Fourier transform of a time-domain signal, s(t), is given by:
SðfÞ 5
ð‘
‘
sðtÞej2pftdt:
ð1:7Þ
The inverse Fourier transform of a frequency-domain signal, S(f), is given by:
sðtÞ 5 1
2p
ð‘
‘
SðfÞe1j2pftdf:
ð1:8Þ
The forward Fourier transform of a spatial-domain signal, q(x), has the form:
SðkÞ 5
ð‘
‘
sðxÞej2pkxxdx:
ð1:9Þ
The corresponding inverse Fourier transform of a spatial frequency-domain
signal, S(k), is given by:
sðxÞ 5
ð‘
‘
SðkÞe1j2pkxxdk:
ð1:10Þ
Some useful Fourier-pairs are shown in Figure 1.18: each of the particular
functions occurs in multiple instances in the medical imaging modalities covered
here.
In imaging, signals are clearly often acquired in more than one dimension, and
image reconstruction then requires multi-dimensional Fourier transformation. For
example, MRI intrinsically acquires two-dimensional k-space data, for which the
Fourier pairs are given by:
21
1.9 Fourier transforms

Sðkx; kyÞ 5
ð‘
‘
ð‘
‘
sðx; yÞej2p kxx 1 kyy
ð
Þdxdy;
ð1:11Þ
sðx; yÞ 5
ð‘
‘
ð‘
‘
S kx; ky


e 1j2p kxx 1 kyy
ð
Þdkxdky :
ð1:12Þ
For three-dimensional MRI data acquisition, a corresponding three-dimensional
inverse Fourier transform from k-space to the spatial domain is required. These
higher-dimension Fourier transforms are typically implemented as sequential one-
dimensional transforms along the respective dimensions. For example, this means
that a two-dimensional Fourier transform of a function f(x,y) can be implemented by
ﬁrst carrying out a one-dimensional Fourier transform along the x-axis, and then a
second Fourier transform along the y-axis. Highly efﬁcient computational algorithms
make the Fourier transform one of the quickest mathematical transforms to perform.
1.9.2 Useful properties of the Fourier transform
In order to understand many aspects of medical imaging, both in terms of
the spatial resolution inherent to the particular imaging modality and also the
Figure 1.18
Three Fourier transform pairs commonly used in image and spectral reconstruction.
22
General image characteristics

effects of image post-processing, a number of mathematical properties of the
Fourier transform are very useful. The most relevant examples are listed below,
with speciﬁc examples from the imaging modalities covered in this book.
(a) Linearity. The Fourier transform of two additive functions is additive:
as1ðtÞ 1 bs2ðtÞ5aS1ðfÞ 1 bS2ðfÞ
,
aS1ðxÞ 1 bS2ðxÞ5as1ðkxÞ 1 bs2ðkxÞ
ð1:13Þ
where 5 represents forward Fourier transformation from left-to-right, and the
inverse Fourier transform from right-to-left. This theorem shows that when the
acquired signal is, for example, the sum of a number of different sinusoidal
functions, each with a different frequency and different amplitude, then the
relative amplitudes of these components are maintained when the data are
Fourier transformed, as shown in Figure 1.19.
(b) Convolution. If two signals are multiplied together, then the signal in the
Fourier domain is given by the convolution of the two individual Fourier
transformed components, e.g.
s1 tð Þs2 tð Þ5S1 fð Þ  S2 fð Þ
,
s1 kx
ð
Þs2 kx
ð
Þ5S1 x
ð Þ  S2 x
ð Þ
ð1:14Þ
where * represents a convolution. This relationship is shown in Figure 1.20.
The convolution, f(x), of two functions p(x) and q(x) is deﬁned as:
f x
ð Þ 5 p x
ð Þ  q x
ð Þ 5
ð‘
‘
p x  s
ð
Þq s
ð Þds:
ð1:15Þ
e
m
it
y
c
n
e
u
q
e
rf
+
+
e
m
it
T
F
f1
f1
f2
f3
f2
f3
=
Figure 1.19
A time-domain signal (centre) is composed of three different time-domain signals (left). The Fourier
transformed frequency spectrum (right) produces signals for each of the three frequencies with the
same amplitudes as in the time-domain data.
23
1.9 Fourier transforms

In general, the image can be represented by the actual object convolved with the
PSF for the particular imaging modality used. Three examples of convolution
covered in this book are the effects of a ﬁnite beamwidth in ultrasound imaging,
geometric unsharpness in X-ray imaging and short T2 values in MRI. Convo-
lution is also an integral part of image ﬁltering and backprojection algorithms.
(c) Scaling law. If either a time-domain or spatial-domain signal is scaled by a
factor b in that particular domain, i.e. stretched or compressed, then its Fourier
transform is scaled by the inverse factor, i.e.:
sðbtÞ5 1
bj j S f
b
 
sðbxÞ5 1
bj j S kx
b


:
ð1:16Þ
There are numerous examples covered in this book. Already outlined is the
relationship between the PSF and MTF, and the LSF and one-dimensional
MTF. Since the parameters are related by a Fourier transform the broader the
LSF, for example, the narrower the MTF, and vice-versa, as shown in Figure 1.21.
1.10
Backprojection, sinograms and ﬁltered backprojection
Reconstruction of a two-dimensional image from a series of one-dimensional
projections is required for CT, SPECT and PET. A large number of one-
…..
…..
frequency
time
frequency
frequency
frequency
time
time
time
Figure 1.20
The correspondence between multiplication in one domain (time at the top) with convolution in the
corresponding Fourier domain (frequency at the bottom). The time-domain signal at the top left can be
represented as an inﬁnitely long sine wave multiplied by a ﬁnite sampling period (rectangle) and an
exponential function. Examples of this type of function are an MR signal or an ultrasound pulse. In the
frequency domain, the Lorenzian function (bottom left) is given by the convolution of a delta function, a
sinc function and another Lorenzian function which are the Fourier transforms of the corresponding
time-domain functions.
24
General image characteristics

dimensional projections, p1, p2. . . .pn, are acquired with the detector oriented at
different angles with respect to the object, as shown in Figure 1.22. The particular
‘image’ that one is trying to reconstruct depends upon the imaging modality, i.e. in
CT the image corresponds to Hounsﬁeld units (related to the X-ray attenuation
coefﬁcient), in SPECT and PET the image represents the biodistribution of the
injected radioactive agent. If one considers a single slice through the patient, the
relevant parameter in the patient can be expressed mathematically as a function
f(x,y), in which the spatially-dependent values of f correspond to the distribution of
radiopharmaceutical in SPECT or PET, or attenuation coefﬁcients in X-ray CT. In
general, the detector is at an angle of u degrees to the x-axis for a particular
MTF
spatial frequency
LSF
distance
Figure 1.21
The relationship between the LSF and MTF of an imaging system is governed by the Fourier scaling
law, in which a broad function in one domain corresponds to a narrow function in the other.
Figure 1.22
The object being imaged is represented as f(x,y) where x and y represent the image coordinates. In
this example, higher values of f(x,y) are represented by darker colours. The projection plots the
intensity of the projection as a function of r: therefore, the highest values correspond to lines passing
through the darker disk-shaped areas.
25
1.10 Backprojection, sinograms and ﬁltered backprojection

measurement, with u having values between 0 and 360. The measured projection
at every angle u is denoted by p(r,u).
1.10.1 Backprojection
After all of the projections have been acquired, image reconstruction using back-
projection assigns an equal weighting to all of the pixels which contribute to each
projection. This process is repeated for all of the projections, and the pixel inten-
sities are summed to give the reconstructed image. An example is shown in Figure
1.23. The object consists of a simple cylinder with uniform intensity throughout
the disk and zero intensity outside the disk. Projection p1 is acquired at an angle
u=0, projection p2 at u=45, p3 at u=90 and so on up to p8. The process of
backprojection assigns an equal weight to all pixels in the reconstructed image for
each projection, as shown in Figure 1.23(b). Summation of each individual image
gives the result in Figure 1.23(c), which is the backprojected image.
If the object is represented by f(x,y) the reconstructed image is given the symbol
^fðx; yÞ, where the circumﬂex represents the estimated image, and is given by:
p1
p2
p3
p4
p5
p6
p7
p8
1
2
3
4
5
6
7
8
c
a
b
Figure 1.23
The process of backprojection. (a) From a small round object with uniform signal intensity, eight
projections are obtained with angular increments of 45. The eight projections are shown in (b) with the
dark areas corresponding to the highest signal intensity. (c) The process of backprojection involves
summation of the images shown in (b). A signiﬁcant ‘star artifact’ is visible due to the small number of
projections.
26
General image characteristics

^fðx; yÞ 5 +
n
j 5 1
pðr;ujÞdu;
ð1:17Þ
where n is the number of projections. Clearly, an important data acquisition
parameter is the number of projections which are acquired. If too few projections
are acquired, then signiﬁcant image artifacts occur in data reconstruction: Figure
1.24 shows examples of these so-called ‘streak’ artifacts.
1.10.2 Sinograms
A common method of displaying projection data is a sinogram, in which the pro-
jections are plotted as a function of the angle u. In order to reduce the dimension-
ality of the plot the projections are plotted with the signal amplitude represented by
the brightness of the sinogram, with a high amplitude corresponding to a bright
pixel, and a low amplitude to a dark pixel. As shown in Figure 1.25, sinograms can
be used to detect the presence of patient motion, which is visible as a signal
discontinuity. Such motions can cause severe artifacts in the reconstructed images.
1.10.3 Filtered backprojection
The process of backprojection as described up to now has an inherent problem in
that it results in signal intensity outside the actual object, as shown in Figures 1.23
and 1.24. Although this effect can be reduced by increasing the number of pro-
jections that are acquired and processed, use of even a very large number of
projections leads to some image blurring. This effect is well-understood, and
mathematical analysis shows that applying an appropriate ﬁlter function to
each projection before backprojection can reduce this blurring [4]. The ﬁlter is
applied via convolution: the effects on a very simple projection are shown in
Figure 1.26.
Object
N=8
N=30
N=90
N=360
Figure 1.24
The effect of a different number of projections (N) on the backprojected image. The object is a square
of uniform signal intensity (far left). With eight projections there is signiﬁcant signal in areas far away
from the object. As the number of projections increases the reconstruction improves, with a perfectly
usable reconstruction with 90 projections and an almost perfect reconstruction with 360 projections.
27
1.10 Backprojection, sinograms and ﬁltered backprojection

Intuitively, one can see that the negative lobe introduced around the edges of the
projection will cancel out the unwanted positive ‘blurring’ signal around the edge
of the object. From a practical point-of-view, it is important that the process of
ﬁltered backprojection be as computationally efﬁcient as possible, since real-time
processing of medical images allows interactive image planning while the patient
is in the scanner. As described so far, the projection is ﬁltered in the spatial domain,
and the resulting ﬁltered projection, p#(r,u), can be represented as:
p0 r; u
ð
Þ 5 p r; u
ð
Þ  h rð Þ:
ð1:18Þ
Since the mathematical process of convolution is computationally intensive and
therefore slow, in practice ﬁltered backprojection is carried out in the spatial
frequency-domain using fast Fourier transform methods. Convolution in the spa-
tial domain is equivalent to multiplication in the spatial frequency-domain, and
multiplication can be performed much faster than convolution. Each projection
p(r,u) is Fourier transformed along the r-dimension to give P(k,u), and then P(k,u)
is multiplied by H(k), the Fourier transform of h(r), to give P#(k,u):
Figure 1.26
The effect of convolving a projection p(r,u) with the spatial ﬁlter function h(r). The negative lobe in the
ﬁltered projection minimizes the ‘star artifact’ in the reconstructed image.
90
0
270
180
360
90
0
270
180
360
p(r,   )
p(r,   )
Figure 1.25
Examples of sinograms from an object which does not move during the scan (left) and which moves
roughly half-way through the scan (right), the motion being seen as a displacement in the sinogram.
28
General image characteristics

P0 k; u
ð
Þ 5 P k; u
ð
Þ H k
ð Þ:
ð1:19Þ
The ﬁltered projections, P#(k,u), are inverse Fourier transformed back into the
spatial-domain, and backprojected to give the ﬁnal image, ^fðx; yÞ:
^f x; y
ð
Þ 5 +
n
j 5 1
F1 P0 k; uj


	

du:
ð1:20Þ
where F21 represents an inverse Fourier transform.
The general form of h(r) is shown in Figure 1.26, and various examples of H(k)
in the spatial frequency-domain are shown in Figure 1.27.
The effects of ﬁltered backprojection can be seen in Figure 1.28, which uses a
Shepp-Logan phantom. This is an object which contains both large and small
features, and is very commonly used in assessing image reconstruction algorithms.
H(k)
k
1
Figure 1.27
Functions used for ﬁltered backprojection. The Ram-Lak ﬁlter [4] (dotted line) represents a high-pass
ﬁlter, a Hamming function (thin line) is a low-pass ﬁlter, and the combination of the two (thick line)
produces a band-pass ﬁlter.
a
b
c
d
e
Figure 1.28
The process of ﬁltered backprojection. (a) The Shepp–Logan phantom. (b) The sinogram produced
from the Shepp–Logan phantom using 180 projections. (c) Image reconstructed using simple
backprojection with no ﬁltering. The image has very high SNR but shows signiﬁcant blurring. (d) The
image reconstructed using ﬁltered backprojection with a Ram–Lak ﬁlter applied. The sharp edges in
the phantom are well-represented, but the SNR is reduced signiﬁcantly. (e) Reconstruction with a
band-pass ﬁlter, shown in Figure 1.27, gives a good representation of the object.
29
1.10 Backprojection, sinograms and ﬁltered backprojection

The various shapes represent different features within the brain, including the
skull, ventricles and several small features either overlapping other structures or
placed close together.
Exercises
Speciﬁcity, sensitivity and the ROC
1.1 In a patient study for a new test for multiple sclerosis (MS), 32 of the 100
patients studied actually have MS. For the data given below, complete the two-
by-two matrices and construct an ROC. The number of lesions (50, 40, 30, 20
or 10) corresponds to the threshold value for designating MS as the diagnosis.
2
0
50 lesions
40 lesions
8
1
30 lesions
16
3
20 lesions
22
6
10 lesions
28
12
1.2 Choose a medical condition and suggest a clinical test which would have:
(a) High sensitivity but low speciﬁcity;
(b) Low sensitivity but high speciﬁcity.
1.3. What does an ROC curve that lies below the random line suggest? Could this
be diagnostically useful?
Spatial resolution
1.4 For the one-dimensional objects O(x) and PSFs h(x) shown in Figure 1.29,
draw the resulting projections I(x). Write down whether each object contains
O(x)
I(x)
h(x)
a
b
c
d
Figure 1.29
See Exercise 1.4.
30
General image characteristics

high, low or both spatial frequencies, and which is affected most by the
action of h(x).
1.5 Show mathematically that the FWHM of a Gaussian function is given by:
FWHM 5
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2 ln 2
p


r ﬃ2:36r:
1.6 Plot the MTF on a single graph for each of the convolution ﬁlters shown
below.
1
1
1
1
1
12
1
1
1
1
1
1
1
1
4
1
1
1
1
1
1
1
1
1
1
1
1
1.7 What type of ﬁlter is represented by the following kernel?
1
1
-1
0
-1
0
1
0
-1
1.8 Using the ﬁlter in Exercise 1.7 calculate the ﬁltered image using the original
image from Figure 1.11.
Data acquisition
1.9 An ultrasound signal is digitized using a 16-bit ADC at a sampling rate of 3
MHz. If the image takes 20 ms to acquire, how much data (in Mbytes) is there
in each ultrasound image. If images are acquired for 20 s continuously, what
is the total data output of the scan?
1.10 If a signal is digitized at a sampling rate of 20 kHz centred at 10 kHz, at what
frequency would a signal at 22 kHz appear?
1.11 A signal is sampled every 1 ms for 20 ms, with the following actual values of
the analogue voltage at successive sampling times. Plot the values of the
voltage recorded by a 5 volt, 4-bit ADC assuming that the noise level is much
lower than the signal and so can be neglected. On the same graph, plot the
quantization error.
31
Exercises

SignalðvoltsÞ 5 4:3; 1 1:2; 0:6; 0:9; 1 3:4; 2:7; 1 4:3; 1 0:1; 3:2;
4:6; 1 1:8; 1 3:6; 1 2:4; 2:7; 1 0:5; 0:5; 3:7; 1 2:1; 4:1; 0:4
1.12 Using the same signal as in exercise 1.11, plot the values of the voltage and
the quantization error recorded by a 5 volt, 8-bit ADC.
Fourier transforms
1.13 In Figure 1.20 plot the time and frequency domain signals for the case where
the sampling time becomes very short.
1.14 Figure 1.30 shows two different two-dimensional PSFs in the (x,y) spatial
domain. Draw the corresponding two-dimensional MTFs in the (kx, ky)
spatial frequency dimension, and plot separately the one-dimensional MTF
vs. kx and MTF vs. ky.
x
y
x
y
Figure 1.30
See Exercise 1.14.
Figure 1.31
See Exercise 1.16.
32
General image characteristics

Backprojection
1.15 For Figure 1.25, suggest one possible shape that could have produced the
sinogram.
1.16 For the object shown in Figure 1.31: (a) draw the projections at angles of 0,
45, 90, and 135, and (b) draw the sinogram from the object. Assume that a
dark area corresponds to an area of high signal.
1.17 A scan is taken of a patient, and an area of radioactivity is found. The sino-
gram is shown in Figure 1.32. Assuming that the radioactivity is uniform
within the targeted area, what is one possible shape of the area of radio-
activity?
References
[1] Shannon CE. Communication in the presence of noise. Proc Inst Radio Engineers
1949;37, 10–21.
[2] Nyquist H. Certain topics in telegraph transmission theory. Trans AIEE 1928;47,
617–44.
[3] Ritchie CR, Candy JC and Ninke WH. Interpolative digital-to-analog converters.
IEEE Trans Communications 1974;Com-22, 1797–806.
[4] Ramachandran GN and Lakshminarayanan V. Three-dimensional reconstruction from
radiographs and electron micrographs: applications of convolutions instead of Fourier
transforms. Proc Natl Acad Sci USA 1971;68, 2236–40.
90
0
180
p(r,   )
Figure 1.32
See Exercise 1.17.
33
References

2 X-ray planar radiography and
computed tomography
2.1
Introduction
X-ray planar radiography is one of the mainstays of a radiology department,
providing a ﬁrst ‘screening’ for both acute injuries and suspected chronic diseases.
Planar radiography is widely used to assess the degree of bone fracture in an acute
injury, the presence of masses in lung cancer/emphysema and other airway path-
ologies, the presence of kidney stones, and diseases of the gastrointestinal (GI)
tract. Depending upon the results of an X-ray scan, the patient may be referred for a
full three-dimensional X-ray computed tomography (CT) scan for more detailed
diagnosis.
The basis of both planar radiography and CT is the differential absorption of
X-rays by various tissues. For example, bone and small calciﬁcations absorb X-
rays much more effectively than soft tissue. X-rays generated from a source are
directed towards the patient, as shown in Figure 2.1(a). X-rays which pass through
the patient are detected using a solid-state ﬂat panel detector which is placed just
below the patient. The detected X-ray energy is ﬁrst converted into light, then into
a voltage and ﬁnally is digitized. The digital image represents a two-dimensional
projection of the tissues lying between the X-ray source and the detector. In
addition to being absorbed, X-rays can also be scattered as they pass through
the body, and this gives rise to a background signal which reduces the image
contrast. Therefore, an ‘anti-scatter grid’, shown in Figure 2.1(b), is used to ensure
that only X-rays that pass directly through the body from source-to-detector are
recorded. An example of a two-dimensional planar X-ray is shown in Figure
2.1(c). There is very high contrast, for example, between the bones (white) which
absorb X-rays, and the lung tissue (dark) which absorbs very few X-rays.
There are a number of specialized applications of radiography which require
related but modiﬁed instrumentation. X-ray ﬂuoroscopy is a technique in which
images are continuously acquired to study, for example, the passage of an
X-ray contrast agent through the GI tract. Digital mammography uses much
lower X-ray energies than standard X-ray scans, and is used to obtain images with
much ﬁner resolution than standard planar radiography. Digital subtraction

angiography is a technique which acquires images of the vasculature at extremely
high resolution.
For many clinical diagnoses, it is necessary to acquire a full three-dimensional
image from a particular region of the body. For head trauma patients, for example,
the location and size of the trauma must be determined very accurately. For
imaging of the liver and surrounding organs, a two-dimensional planar radiograph
would have too much overlap from the different tissues to be useful. The basic
principle of CT is shown in Figure 2.2, together with a photograph of a modern
multi-detector helical scanner. The X-ray source and a bank of X-ray detectors are
rotated in synchrony around the patient. The rotation speed is high, with one
revolution taking less than a second. A series of one-dimensional projections is
acquired during the rotation, and these are then reconstructed to form a two-dimen-
sional image. The third dimension is acquired by moving the patient in a horizontal
direction while the images are being acquired, and also by having not just one but
many detector rows (currently up to 320) in the horizontal direction. Using this
type of state-of-the-art multi-detector helical CT scanner, very high resolution
images of large volume can be acquired very rapidly. Figure 2.2 also shows an
example of a three-dimensional image of the heart, with exquisite visualization of
a
b
c
Figure 2.1
(a) The set-up for planar radiography. The X-ray beam from the tube is collimated, passes through the
patient, and forms an image on the digital detector placed below the patient. (b) An anti-scatter grid
is placed directly in front of the detector to reduce the contribution from scattered X-rays in order to
increase the image contrast. (c) An example of a planar radiograph through the chest. The bones
attenuate X-rays to a much greater degree than the soft tissue of the lungs, and appear bright on the
image.
35
2.1 Introduction

the coronary arteries. The only disadvantage of a CT scan compared to a planar
X-ray is the much higher radiation dose.
2.2
The X-ray tube
For both planar radiography and CT the X-ray source is a specialized piece of
equipment known as an X-ray tube. A photograph of an X-ray tube and a sche-
matic diagram of its major components are shown in Figure 2.3. All of the com-
ponents of the X-ray system are contained within an evacuated vessel. The
evacuated vessel is surrounded by oil for both cooling and electrical isolation.
The whole assembly is surrounded by a lead shield with a glass window, through
which the X-ray beam is emitted.
X-rays are produced by a beam of high energy electrons striking the surface of
a metal target. A negatively-charged cathode acts as the source of these electrons,
and consists of a small helix of thin tungsten wire, through which an electric
current is passed. When the temperature of the wire reaches ~2200 C, electrons
have sufﬁcient energy to leave the metal surface. In order to produce a tight
beam of electrons, a negatively-charged ‘focusing cup’ surrounds the cathode.
A large positive voltage is applied to a metal target, which thus forms an anode. A
potential difference between the anode and cathode of between 25 and 140 kV
(depending upon the particular type of clinical study) is applied, such that the
electrons produced at the cathode are attracted to the anode, striking it at
X-ray source
X-ray
detectors
Figure 2.2
(left) A modern helical CT scanner. (centre) The X-ray tube and bank of detectors (typically several
hundred, aligned parallel to one another) rotate together while the patient is slowly slid through the
beam. The two-dimensional rotational and one-dimensional linear translation together enable a full
three-dimensional data set to be acquired very rapidly. (right) An example of a surface rendering of a
three-dimensional CT data set of the human heart, showing the coronary arteries on the exterior.
36
X-ray planar radiography and computed tomography

high velocities. This potential difference is known as the accelerating voltage,
or kVp.
When the high energy electrons strike the anode surface, part of their kinetic
energy is converted into X-rays by mechanisms covered in detail in Section 2.3.
The metal anode must be able to produce X-rays efﬁciently, and also be able to
withstand the very high temperatures generated. In terms of efﬁciency, the higher
the atomic number of the metal in the target, the higher the efﬁciency of X-ray
production. The most commonly used metal is tungsten which has a high atomic
number, 74, and a melting point of 3370 C. In addition it has good thermal
conductivity and a low vapour pressure, which allows a strong vacuum to be
established within the X-ray tube, thus providing the electrons with an unimpeded
path between cathode and anode. Even with the high efﬁciency of tungsten only
~1% of the energy of the electrons is converted into X-rays: the remainder is
dissipated in heat. The tungsten target of the anode is about 0.7 mm thick and
forms a cylindrical disk which rotates at high speed, ~3000 rpm, in order to reduce
the localized heating. The power for rotation comes from a set of induction
rotors and stators, as shown in Figure 2.3. In practice, a tungsten–rhenium
(2–10% rhenium) alloy is used for extra mechanical stability of the target. As
mentioned earlier, digital mammography requires very low energy X-rays, and
for these types of application the metal in the anode is molybdenum rather than
tungsten.
In order to produce a narrow beam of electrons, a negatively-charged focusing
cup is constructed around the cathode ﬁlament. In fact, many X-ray tubes contain
two cathode ﬁlaments of different length, each with a focusing cup, as shown in
Figure 2.4.
In order to achieve a well-deﬁned small area in which the X-rays are created, the
anode is bevelled at an angle between 8 and 17, with 12–15 being the usual
induction
rotor
induction
stator 
cathode
electrons
rotating anode
glass envelope
X-rays
induction
stator 
power
Figure 2.3
(left) An X-ray tube enclosed in an evacuated glass enclosure. (right) The individual components of an
X-ray tube.
37
2.2 The X-ray tube

range. The smaller the angle, the smaller the effective focal spot size (f), shown in
Figure 2.5(a), given by:
f 5 F sinh;
ð2:1Þ
where h is the bevel angle and F the width of the electron beam. Values of the
effective focal spot size range from 0.3 mm for digital mammography to between
0.6 and 1.2 mm for planar radiography and computed tomography. The bevel
angle also affects the coverage of the X-ray beam, as shown in Figure 2.5(b),
which is given by:
Coverage 5 2 source  patient distance
ð
Þ tanh:
ð2:2Þ
In practice, the X-ray beam has a higher intensity at the ‘cathode-end’ than at the
‘anode-end’, a phenomenon known as the Heel effect. This effect is due to differ-
ences in the distances that X-rays have to travel through the target itself. This
e
d
o
n
a
_
_
_
_
n
ets
g
n
ut
m
m
 0
1
m
m
 2
1 e
d
o
hta
c f
o 
w
eiv
-e
dis
m
m
 6
m
m
 2
2 e
d
o
hta
c f
o 
w
eiv
-e
dis
e-
m
a
e
b
e-
m
a
e
b
Figure 2.4
Top view showing the effect of the focusing cup on the shape of the electron beam striking the rotating
anode. There are two cathodes (expanded in the side-views) which produce a wider or narrower beam
depending upon the particular application. The direction of the X-ray beam produced is out-of-the-
page towards the reader.
38
X-ray planar radiography and computed tomography

distance is longer for X-rays produced at the anode-side of the target than at the
cathode-side, as shown in Figure 2.5 (c), and results in greater absorption of X-rays
within the target itself. This means that the signal intensity on one side of a planar
radiograph is different from that on the other. Although image processing algo-
rithms can be used to correct for this phenomenon, in practice it is not signiﬁcantly
detrimental to the diagnostic quality of the images.
There are three parameters that can be chosen by the operator for X-ray imaging:
the accelerating voltage (kVp), the tube current (mA), and the exposure time. The
current that passes from the cathode to the anode is typically between 50 and 400
mA for planar radiography, and up to 1000 mA for CT. The value of the kVp varies
from ~25 kV for digital mammography to ~140 kV for bone and chest applica-
tions. Physical limitations for the values of kVp and tube current are set by the
power rating of the particular X-ray tube, deﬁned as the maximum power dissi-
pated in an exposure time of 0.1 s. For example, a tube with a power rating of 10
kW can operate at a kVp of 125 kV with a tube current of 1 A for ~78 ms. The
ability of the X-ray source to achieve a high tube output is ultimately limited by
anode heating. The heat generated in the anode is transferred to the tube housing
coverage
F
f
anode
side
cathode
side
a
b
c
Figure 2.5
(a) The effect of the bevel angle h on the effective focal spot size (f) as a function of the width of the
electron beam (F). (b) Corresponding diagram for the effect of h on the coverage of the X-ray beam.
(c) Illustration of the Heel effect, in which the X-ray intensity is higher on the ‘cathode side’ of the beam
than on the ‘anode side’, since the X-rays on the anode side have to travel further through the anode
itself before leaving the tube, and are therefore more highly attenuated.
39
2.2 The X-ray tube

and from there to the insulating oil surrounding the housing. Further heat removal
can be achieved by continuously pumping oil or cooling water within the housing.
2.3
The X-ray energy spectrum
X-ray tubes produce X-rays with a wide range of energies, up to a maximum value
given by the kVp, as shown in Figure 2.6. The spectrum represents a plot of the
relative number of X-rays produced as a function of their energy. When one refers
to the energy of the X-ray beam, this number represents the weighted average of all
of the different energies, and is typically about two-thirds of the kVp value.
There are two separate mechanisms by which X-rays are produced, one which
results in a broad spread of energies, and the other which produces distinct sharp
lines, both of which are evident in Figure 2.6. The ﬁrst mechanism involves an
electron passing close to the nucleus of an atom of the metal forming the anode,
and being deﬂected from its original trajectory by the attractive forces from the
positively charged nucleus. This deﬂection results in a loss of electron kinetic
energy, and this energy loss is converted into an X-ray. The maximum energy
that an X-ray can have corresponds to the entire kinetic energy of the electron
0
5
1
0
2
1
0
9
0
6
0
3
0
re
b
m
u
n e
vitale
R
s
y
ar-
X
 f
o
y
g
re
n
e y
ar-
X
Figure 2.6
The energy spectrum of a beam emitted from an X-ray tube with a tungsten anode operating at 140
kVp. The very low energies are absorbed by the tube itself. Characteristic lines are seen as sharp lines,
superimposed upon a broad energy distribution from general radiation.
40
X-ray planar radiography and computed tomography

being transferred to the X-ray, i.e. the kVp value. Given the small size of the
nucleus in relation to the entire atom, it is much more likely that the electron will
undergo only a partial loss of energy, and so a wide spectrum of X-ray energies is
produced: this is termed general radiation or bremsstrahlung (braking radiation in
German). Although the distribution decreases roughly linearly with energy, many
of the very low energy X-rays are absorbed by the housing of the X-ray tube itself,
as evident on the left-hand-side of Figure 2.6.
Sharppeaksarealsopresentin theX-rayenergyspectrum,andtheenergyatwhich
these peaks occur is characteristic of the particular metal used in the anode, hence the
name ‘characteristic radiation’. If an electron accelerated from the cathode collides
with a tightly bound K-shell electron in the anode, this bound electron is ejected
and the resulting ‘hole’ in the K-shell is ﬁlled by an electron from an outer (L or M)
shell, see Figure 2.7. The difference in binding energies between the electrons in
the inner and outer shells is emitted as a single X-ray with a speciﬁc energy.
As outlined earlier, the two most commonly-used metals for anodes are tungsten
and molybdenum. For tungsten, the K-shell electrons have a binding energy of
69.5 keV. The L-shell has electrons with binding energies between 10.2 and 12.1
keV, and the M-shell between 1.9 and 2.8 keV. Therefore, a characteristic X-ray
from an L-to-K electron transition has an energy of ~59 keV, and from an M-to-K
transition an energy of ~67 keV: these represent the sharp peaks shown in
Figure 2.6. For a molybdenum target, the binding energies of electrons in the
K-, L- and M-shells are 20, 2.5–2.8 and 0.4–0.5 keV, respectively. The
Figure 2.7
The chain-of-events involved in production of characteristic radiation from the metal anode in an X-ray
tube. (left) A high energy electron from the cathode ejects an inner electron from the metal target in the
anode. An outer electron ﬁlls the hole in the inner shell and the difference in binding energies of the
inner and outer shell electrons is converted into a characteristic X-ray which is emitted. The outer
electron can come from the L-shell (centre) or M-shell (right), resulting in two different characteristic X-
ray energies.
41
2.3 The X-ray energy spectrum

corresponding energy spectrum is shown in Section 2.10.2 when digital mammog-
raphy is discussed.
2.4
Interactions of X-rays with the body
In order to produce images with high SNR and high CNR, three basic criteria
should be satisﬁed: (i) sufﬁcient X-rays must be transmitted through the body for a
high SNR, (ii) X-ray absorption must be sufﬁciently different between different
tissue-types in order to produce high contrast, and (iii) there must be a method for
removing X-rays which are scattered through unknown angles as they pass through
the body. For the energies used in diagnostic X-ray imaging, there are two major
mechanisms by which X-rays interact with tissue. The ﬁrst mechanism is the
photoelectric interaction with differential attenuation between, in particular, bone
and soft tissue. The second mechanism, Compton scattering, involves the X-ray
being deﬂected from its original trajectory. The X-ray energy is reduced, but the
scattered X-ray may still have enough energy to reach the detector. Compton
scattered X-rays give a random background signal, and so their contribution to
the image should be minimized to improve the CNR. There are other mechanisms
by which X-rays interact with tissue (such as coherent scattering), but for the
energies used in clinical radiography the contributions from these are minor and
so are not considered here.
2.4.1 Photoelectric attenuation
The ﬁrst mechanism, in which tissue absorbs X-rays, provides the contrast in X-
ray images. These ‘photoelectric interactions’ are very similar to the phenomenon
of characteristic radiation, described in Section 2.3. The ﬁrst step is that the energy
of the incident X-ray is absorbed by tissue, with a tightly bound electron being
emitted from either the K- or L-shell, as shown in Figure 2.8. This ejected electron
has an energy equal to the difference between the energy of the incident X-ray and
the binding energy of the electron. The second step is that an electron from a higher
energy level ﬁlls the ‘hole’ with the emission of a ‘characteristic’ X-ray, with an
energy equal to the difference in the binding energies of the two electrons. This
characteristic X-ray has a very low energy, a few keV at most, and is absorbed by
the tissue. The net result of the photoelectric effect in tissue, therefore, is that the
incident X-ray is completely absorbed and does not reach the detector. Note that
the electronic conﬁgurations of the most important elements in tissue, in terms of
photoelectric interactions, are: carbon (K2, L4), oxygen (K2, L6) and calcium (K2,
L8, M8, N2).
42
X-ray planar radiography and computed tomography

The probability of a photoelectric interaction (Ppe) occurring depends on the
energy (E) of the incident X-ray, the effective atomic number (Zeff) of the tissue,
and the tissue density (q):
Ppe } q Z3
eff
E3 :
ð2:3Þ
The effective atomic number of tissue is ~7.4, of lipid ~6.9, and of bone ~13.8
(the high value is due primarily to the presence of calcium). The relative densities
are 1: 0.9: 1.85. Equation (2.3) indicates that, at low X-ray energies, the photo-
electric effect produces high constrast between bone (high attenuation) and soft
tissue (low attenuation), but that the contrast decreases with increasing X-ray
energy. This is further expanded upon in Section 2.5.
2.4.2 Compton scattering
Compton scattering refers to the interaction between an incident X-ray and a
loosely bound electron in an outer shell of an atom in tissue. In Compton scattering
a small fraction of the incident X-ray energy is transferred to this loosely-bound
electron. With the additional energy, the electron is ejected, and the X-ray is
deﬂected from its original path by an angle h, as shown in Figure 2.9.
The energy of the scattered X-ray can be calculated by applying the laws
of conservation of momentum and energy. The standard Compton equation com-
putes the change in wavelength between the incident and scattered X-ray, which is
given by:
Figure 2.8
A photoelectric interaction between an incident X-ray and tissue involves an inner electron being
emitted (left), an electron from an outer shell ﬁlling the hole in the inner shell (middle), and the
difference in the binding energies being transferred to a characteristic X-ray. This X-ray has very low
energy and is absorbed after travelling ~1 mm in tissue.
43
2.4 Interactions of X-rays with the body

Dk 5
h
m0c 1  cosh
ð
Þ;
ð2:4Þ
where m0 is the rest mass of the ejected electron, and c is the speed of light. This
change in wavelength can easily be converted into the relevant loss in energy (DE):
DE 5 EX;inc  EX;scat 5 hc
kinc
 hc
kscat
:
ð2:5Þ
The energy of the scattered X-ray is then given by:
EX;scat 5
EX;inc
1 1
EX;inc
mc2


1  cosh
ð
Þ
:
ð2:6Þ
Figure 2.10 shows a graph of scattered X-ray energy vs. scatter angle for an
incident energy of 70 keV. As can be seen from the graph, the energy of the X-ray
is reduced only by a very small amount even for quite large deﬂection angles, and
so it is very likely that it will pass through the body and be detected as if it were
primary radiation, i.e. radiation which has not been scattered at all. Of course, if the
scatter angle is very large the trajectory of the scattered X-ray will miss the
detector, and the X-ray will effectively have been attenuated.
The probability of an X-ray undergoing Compton scattering is, to ﬁrst order,
independent of atomic number, is proportional to the tissue electron density, and is
only weakly dependent on the energy of the incident X-ray.
At low X-ray energies, the photoelectric effect dominates over Compton
scattering. Since the Zeff of bone is approximately twice that of tissue, there is
far greater attenuation in bone than in tissue, and excellent tissue contrast. How-
ever, at higher X-ray energies the contribution from Compton scattering becomes
incident X-ray
scattered X-ray
ejected
electron
X-ray
scattered
X-ray
electron
EX,inc
EX,scat
pX,scat
Figure 2.9
Compton scattering of an incident X-ray involves an outer electron being ejected from a tissue
molecule (left), with the X-ray being scattered at an angle h with respect to its initial trajectory (right).
44
X-ray planar radiography and computed tomography

more important, and contrast therefore drops, as described in detail in the next
section.
2.5
X-ray linear and mass attenuation coefﬁcients
The attenuation of X-rays through the body has been experimentally determined to
be an exponential process with respect to distance travelled. The exponential
function can be characterized in terms of a tissue linear attenuation coefﬁcient
(l). The value of l depends upon the energy of the incident X-rays. One can
therefore express the number (N) of X-rays transmitted through a certain thickness
(x) of tissue as:
N 5 N0el E
ð Þx;
ð2:7Þ
where No is of the number of incident X-rays. The value of l is the sum of the
individual contributions from photoelectric absorption and Compton scattering:
l E
ð Þ 5 l E
ð Þphotoelectric 1 l E
ð ÞCompton:
ð2:8Þ
X-ray attenuation in tissue is most often characterized in terms of a mass
attenuation coefﬁcient (l/q), measured in units of cm2g21. Figure 2.11 shows
61
62
63
64
65
66
67
68
69
70
0
45
90
Scattered X-ray energy (keV)
Scatter angle (degrees)
Figure 2.10
The energy of a Compton-scattered X-ray as a function of the scatter angle for a 70 keV incident
energy.
45
2.5 X-ray linear and mass attenuation coefﬁcients

the relative contributions of photoelectric and Compton interactions as a function
of the incident X-ray energy. As outlined earlier, the contribution from photo-
electric interactions dominates at lower energies, whereas Compton scattering is
more important at higher energies.
Figure 2.11 also shows the mass attenuation coefﬁcients of bone, soft tissue and
lipid as a function of the incident X-ray energy. At low incident X-ray energies
bone has by far the highest mass attenuation coefﬁcient, due to the prevalence of
photoelectric interactions and the high effective atomic number of bone (13.8)
compared to tissue (7.4) and lipid (6.9). As the X-ray energy increases, the values
of the mass attenuation coefﬁcient become much lower for all tissues. At X-ray
energies greater than about 80 keV, the difference in the mass attenuation coef-
ﬁcients of bone and soft-tissue is less than a factor of 2. There is also relatively little
difference between the attenuation coefﬁcients for soft tissue and fat due to their
closeness in effective atomic number.
An important feature in Figure 2.11 is the sharp discontinuities in the absorption
coefﬁcient of bone at two distinct energies. This phenomenon is known as a K-
edge: at an energy just higher than the K-shell binding energy of the particular
0
5
1
0
3
1
0
1
1
0
9
0
7
0
5
0
3
0
1
0
1
1
1.0
1
0.0
1
0
0.0
cirtc
ele
oto
h
p
tn
eiciffe
o
c n
oita
u
n
etta ss
a
M
m
c(
2g 1
- )
n
otp
m
o
C
latot
)
V
e
k
( y
g
re
n
e y
ar-
X
 tn
eiciffe
o
c n
oita
u
n
etta ss
a
M
m
c(
2g 1
- )
)
V
e
k
( y
g
re
n
e y
ar-
X
taf
elc
s
u
m
e
n
o
b
1.0
1
0
1
1
0
0
1
0
1 3
0
1 4
0
0
0
1
0
0
1
0
1
Figure 2.11
(left) The individual contributions from photoelectric attenuation and Compton scatter add together to
give a net tissue linear attenuation coefﬁcient (the speciﬁc data are shown for water). The contribution
from the photoelectric effect dominates at low X-ray energies, but Compton scatter is the more
important term at high energies. (right) The mass attenuation coefﬁcient of lipid, muscle and bone as a
function of X-ray energy.
46
X-ray planar radiography and computed tomography

atom (calcium for bone), the probability of photoelectric interactions increases
dramatically, typically by a factor of 5 to 8. One can see that, without these jumps,
the attenuation of bone would be very similar to that of muscle and lipid. The
phenomenon of a K-edge is also critical in the design of both X-ray contrast agents
and X-ray detectors, which are covered later in this chapter.
The attenuation properties of tissue can also be described in terms of the half-
value layer (HVL), which as the name suggests is the thickness of tissue which
reduces the intensity of the X-ray beam by a factor of one-half. From Equation
(2.7), the value of the HVL is given by (ln 2)/l. At an X-ray energy of 100 keV,
for example, the HVL for muscle is 3.9 cm and for bone is 2.3 cm: the corres-
ponding numbers at 30 keV (relevant for mammography) are 1.8 cm and 0.4 cm,
respectively.
Example 2.1
If the thickness of the chest is 20 cm, what percentage of X-rays are transmitted
through the chest at an incident X-ray energy of 70 keV assuming HVL values
of 3.5 and 1.8 cm21 for muscle and bone, respectively, and the bone thickness to be
4 cm and the tissue thickness 16 cm?
Solution
For the muscle, the value of l is given by (ln 2)/3.5~0.2 cm21. For 16 cm of tissue:
N
N0
5 e 0:2
ð
Þ16 5 0:04:
For bone the value of l is (ln 2)/1.8~0.4 cm21. For 4 cm of bone:
N
N0
5 e 0:4
ð
Þ4 5 0:2:
Therefore, overall the percentage is given by 100 3 (0.2 3 0.04) = 0.8%.
2.6
Instrumentation for planar radiography
In addition to the X-ray tube, the other basic components of a planar X-ray
radiography system are: (i) a collimator to reduce the patient dose and amount
of Compton scattered X-rays, (ii) an anti-scatter grid to reduce further the contri-
bution of scattered X-rays to the image, and (iii) a digital detector which converts
the energy of the transmitted X-rays into light: the light is then converted into a
voltage using photodiodes, and this voltage is digitized using an analogue-to-
digital converter, as covered in Chapter 1.
47
2.6 Instrumentation for planar radiography

2.6.1 Collimators
The coverage of the X-ray beam from the X-ray tube is determined by the bevel
angle of the anode in the X-ray tube, as shown in Section 2.2. By the time the beam
reaches the patient, the beam can be much wider than the ﬁeld-of-view (FOV)
which is being imaged. This has two undesirable effects, the ﬁrst of which is that
the patient dose is unnecessarily high. The second effect is that the number of
Compton scattered X-rays contributing to the image is also unnecessarily
increased, since X-rays interact with tissue outside the FOV, and are scattered
and detected. In order to restrict the dimensions of the beam to the imaging
FOV a collimator (also called a beam-restrictor) is placed between the X-ray
source and the patient. The collimator consists of sheets of lead, which can be
slid over one another to restrict the beam in either one or two dimensions.
2.6.2 Anti-scatter grids
Compton scattered X-rays provide little spatial information, and contribute to a
background signal which reduces the image contrast. For example, Figure 2.12
shows X-ray images from a model of the human pelvis. The areas around the
‘bones’ in the model should be black in the images since they contain only air.
However, in regions close to the bone, these areas show up with a high signal
intensity due to Compton scatter.
a
b
Figure 2.12
Images showing the effects of an anti-scatter grid on the CNR of a planar X-ray image. The images are
produced from a pelvic phantom, which simulates the absorption properties of the human pelvis. (a)
No anti-scatter grid: there is a large background signal from Compton-scattered X-rays which reduces
the CNR of the image. (b) With an anti-scatter grid in place the overall signal intensity of the image is
reduced, but the CNR is improved signiﬁcantly.
48
X-ray planar radiography and computed tomography

To reduce the contribution from secondary radiation, an anti-scatter grid is
placed between the patient and the X-ray detector. Certain manufacturers incor-
porate this grid into the detector itself, for example in computed radiography
covered in Section 2.7.1. This grid consists of parallel strips of lead foil with
aluminium used as a spacer between the strips, as shown in Figure 2.13. Since
the X-ray beam is in fact slightly diverging, as shown in Figure 2.5 (b), the anti-
scatter grid can also be manufactured at the same diverging angle with a focal point
~180 cm from the grid. The degree to which the contribution from Compton
scattering is reduced is dictated by the thickness (t), length (h) and separation
(d) of the lead strips. The grid is characterized by two properties, the grid ratio
and grid frequency given by:
grid ratio 5 h
d
grid frequency 5
1
d 1 t :
ð2:9Þ
Typical values of the grid ratio range from 4:1 to 16:1 and grid frequency from
5–7 lines mm21. The improvement in image contrast does, however, come at a cost
in terms of an increase in the X-ray dose which is required to produce a given
image intensity while using an anti-scatter grid. Having ﬁnite thickness, the lead
septa absorb some primary radiation, and X-rays which are scattered only at very
small angles (and therefore contain useful spatial information) are also absorbed.
This trade-off can be characterized using a parameter known as the Bucky factor
n
oitaid
ar y
ra
m
ir
p
r
otc
ete
d
y
ra
d
n
o
c
e
s
n
oitaid
ar
Figure 2.13
(left) Basic design of an anti-scatter grid, with thin lead septa aligned in either a parallel (top right) or
slightly diverging (bottom right) geometry. The thick arrows show primary radiation which passes
through the anti-scatter grid, and the thin arrows correspond to secondary Compton-scattered
radiation which is stopped by the grid.
49
2.6 Instrumentation for planar radiography

(BF). If an equal X-ray dose is incident upon the detector in the presence and
absence of an anti-scatter grid, then the dose that is delivered to the patient
increases by a factor BF. Typical values of BF are between 4 and 10. In Figure
2.12(b), for example, the image contrast is improved signiﬁcantly by use of an anti-
scatter grid: however, the X-ray dose to the patient is almost ten times higher than
for the image in Figure 2.12(a) acquired without an anti-scatter grid.
2.7
X-ray detectors
Traditional X-ray ﬁlm is essentially a thing of the past, with current diagnoses
being performed almost exclusively from digital images displayed on high reso-
lution computer screens. In addition to the higher quality images made possible
using digital detectors, the ability to store and transfer images easily through large
medical data centres via so-called picture archiving and communication systems
(PACS) has become extremely important. There are two basic digital detector
technologies which are currently used, computed radiography and digital radiog-
raphy. The former is currently cheaper and more widespread, but is anticipated to
be superseded by the latter technology within the next decade, especially as the
costs of digital radiography fall.
2.7.1 Computed radiography
Computed radiography (CR) instrumentation consists of a detector plate and a
CR reader which digitizes the plate after the X-ray image has been acquired.
The CR plate consists of a thin layer of phosphor crystals, most commonly
barium ﬂuorohalide activated with europium ions (BaFX:Eu2+), where the halide
X is a mixture of bromine and iodine. The plate size ranges from 18 3 24 cm for
mammography to 35 3 43 cm for chest radiography. The plates can be categorized
as either high resolution (HR), usually used for mammography, or standard for
general applications. Note that HR plates have a thinner phosphor layer (~140 lm)
compared to standard plates (230 lm), and the phosphor crystals are physically
smaller [1].
The CR plates convert the X-rays which pass through the patient and the anti-
scatter grid into light. When X-rays strike the plate they release electrons in the
phosphor layer: these electrons are trapped for a timescale of hours in sites formed
by dislocations in the phosphor crystal lattice. This effectively forms a ‘latent’
image, i.e. one which is present but is not immediately visible. The CR plate is
protected by a light-tight cassette which is transparent to X-rays. After the image
50
X-ray planar radiography and computed tomography

has been acquired, the cassette is fed into a CR reader. There are many types of
reader, one of the more advanced being a line-scan readout CR, a schematic of
which is shown in Figure 2.14. A linear array of many laser-diodes and small
focusing lenses is used, illuminating an area of ~50 lm diameter for each laser-
diode/lens combination. The laser causes most of the trapped electrons in the
phosphor to return to the ground state, and as they do they emit the difference
in energy between excited and ground states as light at the blue end of the spec-
trum. This light is detected using an array of small lenses and photodiodes which
are sensitive to blue light. The photodiodes convert light into a voltage, and the
output voltage from each photodiode is ampliﬁed, ﬁltered and digitized. An entire
plate can be read and digitized in ~10 seconds. After it has been read, the plate is
then ‘bleached’ using several high-intensity lights, and inserted into a fresh cas-
sette to be reused.
There are many variations on the basic CR plate. As can be appreciated from
Figure 2.14, up to one-half of the light produced by the laser diodes may not be
recorded, since it can escape through the bottom of the detector. For a standard CR
plate, the base for the phosphor crystals is made of a reﬂective layer, which
improves the detection efﬁciency. However, it reduces the spatial resolution since
the path that reﬂected light has to travel before being detected is twice as long, and
the light spreads out as it travels (referred to as a broadened light spread function).
For applications such as digital mammography, which requires very high resolu-
tion, an absorbent layer is placed at the bottom of the detector to reduce the light
spread function to a minimum: however, this also results in reduced efﬁciency. A
more sophisticated way to capture a higher percentage of the light is to use a dual-
sided CR plate, in which there are phosphor layers on both sides of a transparent
plastic base, but this requires a more sophisticated CR reader.
New materials are also being used in CR plates. An example is CsBr:Eu2+,
which has a structure of thin columnar crystals which are aligned perpendicular
to the surface of the plate. These effectively act as very thin optical ﬁbres,
e
d
oid re
s
al
s
n
el
s
n
el
e
d
oid
oto
h
p
Figure 2.14
A computed radiography reader. The reader consists of a large array of laser diodes and photodiodes,
and this array is rapidly moved from right-to-left across the plate to produce the entire image.
51
2.7 X-ray detectors

preventing light from spreading through the plate (thus reducing the light spread
function), and so have a higher intrinsic spatial resolution than BaFX:Eu2+ crys-
tals, which are randomly oriented. The regular crystal structure of CsBr:Eu2+ also
results in a much higher packing efﬁciency, i.e. a greater number of crystals per
unit area, which increases the sensivity compared to BaFX:Eu2+. Using CsBr:Eu2+
allows the thickness of the phosphor layer to be increased to 600 lm, further
increasing the number of X-rays that are absorbed.
The dynamic range of a CR system is very high: typically the signal output
is linear with respect to the X-ray input dose over a range of four orders-of-
magnitude. The spatial resolution is limited by the size of the laser beam used
in signal readout, the number of data points which are sampled, and the degree of
scatter of the laser beam by the crystals in the phosphor screen. Note that HR plates
have smaller and thinner crystals, and therefore higher spatial resolution. Pixels
are sampled every 50 lm, and CR plates are digitized as 4096 3 4096 (HR) or
2048 3 2048 matrix sizes (standard). The SNR of a standard image plate is roughly
twice that of a HR plate for the same input dose. Using a dual-sided CR plate
increases the SNR by close to a factor of 2 compared to single-sided, and using new
CsBr:Eu2+ based plates increases the SNR by an additional factor of 2.
2.7.2 Digital radiography
There are two types of digital radiography (DR) detectors, indirect- and direct-
conversion. Indirect-conversion is most commonly used, the term ‘indirect’ refer-
ring to the fact that X-ray energy is ﬁrst converted into light by a CsI:Tl scintillator,
and then the light is converted into a voltage using a two-dimensional array of
photodiodes. Caesium and iodine have K-edges at 36 and 33.2 keV, with high
atomic numbers of 55 and 53, respectively: therefore, the X-ray attenuation coef-
ﬁcient of CsI is very high, as shown in Figure 2.15, making it a highly efﬁcient
detector.
A schematic of an indirect-conversion DR detector is shown in Figure 2.16. The
CsI layer consists of many thin, rod-shaped, CsI:Tl ‘needle crystals’ (approxi-
mately 5 lm in diameter) aligned parallel to one another and extending from the
top surface of the CsI layer to the substrate on which they are manufactured. The
needle structure gives excellent packing efﬁciency (.80%) to enhance X-ray
absorption and, similarly to CR, it also channels light effectively, preventing it
from spreading and blurring the image. For planar radiography the thickness of the
CsI:Tl layer is ~0.6 mm.
The large ﬂat-panel detector (FPD), which lies directly underneath the CsI:Tl
layer consists of thin-ﬁlm transistor (TFT) arrays, the same technology as is used in
52
X-ray planar radiography and computed tomography

computer screens [2]. Unlike CR, DR does not need a separate read-out device.
The FPD is fabricated on a glass substrate. Then a thin-ﬁlm amorphous silicon
transistor array is layered on to the glass. Amorphous silicon is used rather than the
crystalline form which is used in microchip fabrication, since it has the advantage
that it can be repeatedly exposed to high intensity X-rays without damage. Each
pixel of the detector consists of a fabricated photodiode, storage capacitor and TFT
switch.
When an X-ray is absorbed in a CsI rod, the CsI scintillates and produces light in
the green part of the spectrum. The light undergoes internal reﬂection within the
ﬁbre and is emitted from one end of the ﬁbre on to the TFT array. The light is
converted to an electrical signal by the photodiodes in the TFT array and stored in
capacitors which are formed at the junction of the photodiodes. This signal is then
read out line-by-line in parallel using a multiplexer. The signals are ampliﬁed and
digitized using a 14-bit analogue-to-digital (A/D) converter.
A typical commercial DR system has ﬂat-panel dimensions of 43 3 43 cm, with
a TFT array of 3001 3 3001 elements corresponding to a pixel sampling interval of
143 lm. An anti-scatter grid with a grid ratio of ~13:1 and a strip line density of
~70 lines per cm is used for scatter rejection. It is packaged into a device approx-
imately 50 3 50 cm square, 4.5 cm thick, with a weight of ~20 kilogrammes.
The alternative form of DR detection using direct conversion, as the name
suggests, eliminates the intermediate step of converting X-ray energy into light,
and uses direct absorption of the X-ray photons to produce an electrical signal.
Materials such as amorphous selenium (alloyed with arsenic to prevent recrystal-
lization) have been used, although with an atomic number of 34 and K-edge
Mass attenuation
coefficient
Cs
I
40
30
50
X-ray energy
Figure 2.15
The attenuation coefﬁcient of CsI:Tl as a function of the incident X-ray energy. Each of the elements
has a K-edge which increases absorption signiﬁcantly.
53
2.7 X-ray detectors

at 13 keV, X-ray absorption is not as efﬁcient as for CsI:Tl. The amorphous
selenium material is layered on top of an amorphous Si-H array, as described
previously. Many new materials are being investigated for direct conversion
radiography, but currently the properties of the indirect-conversion detectors are
more favourable.
2.8
Quantitative characteristics of planar X-ray images
As outlined in Chapter 1, the three most common quantitative parameters used to
measure the ‘quality’ of an image are the SNR, spatial resolution and CNR. An
image ideally has a high value of each of these parameters, but there are usually
instrumental and operational trade-offs.
2.8.1 Signal-to-noise
Ideally, with no patient present, the number of X-rays striking each part of the
detector would be exactly the same. However, there are slight variations in the
number of photons per square millimetre, for example, around a mean value.
This variation introduces a statistical ﬂuctuation into the signal intensity of each
pixel, which is represented as noise in the image. If the number of X-rays
produced per unit area is plotted, one gets a Poisson distribution, shown in
Figure 2.17.
The distribution looks similar to the more familiar Normal distribution (from
basic statistics), but is described by a different mathematical function. The prob-
ability, P(N), that N X-rays strike the detector plate per unit area is given by:
P N
ð Þ 5 lNel
N!
;
ð2:10Þ
Figure 2.16
(left) A thin CsI:Tl layer (shaded) placed on top of a SiH active matrix array. (right) An electron
micrograph showing the needle-like structure of the crystals of CsI:Tl.
54
X-ray planar radiography and computed tomography

where l is the mean value. For the Poisson distribution the value of r is given
by:
r 5
ﬃﬃﬃl
p :
ð2:11Þ
Figure 2.18 shows three plots of P(N) vs N for increasing values of N. For very
large values of N, the graph approaches a delta function, and therefore the value of
l approaches that of N. The SNR, deﬁned in Chapter 1 as the ratio of the signal to
the standard deviation of the noise, is therefore given by N/r, or:
SNR }
ﬃﬃﬃﬃ
N
p
:
ð2:12Þ
Doubling the image SNR, therefore, requires four times the number of X-rays to
be detected, increasing the radiation dose also by a factor of 4.
Given the relationship between the SNR and number of X-rays detected, opera-
tional factors that affect the SNR include:
(i) the tube current and exposure time: the SNR is proportional to the square root
of the product of these two quantities,
(ii) the tube kVp: the higher the kVp value the greater the tissue penetration of the
higher energy X-rays, and so the higher the SNR: this is a non-linear effect,
(iii) the patient size and part of the body being imaged: the greater the thickness of
tissue through which the X-rays have to travel, and the higher the X-ray
attenuation due to bone, the lower the SNR,
Probability (P)
P
µ
number of X-rays (N)
Figure 2.17
The probability of a certain number of X-rays striking a unit area of the detector. The statistical
uncertainty in this number is represented by the standard deviation (r) of the Poisson distribution.
55
2.8 Quantitative characteristics of planar X-ray images

(iv) the geometry of the anti-scatter grid: an anti-scatter grid with a large grid
ratio attenuates a greater degree of Compton scattered X-rays than one
with a smaller ratio, and therefore reduces the image SNR (but improves the
CNR),
(v) the efﬁciency of the detector: this can be quantiﬁed using a parameter known
as the detector quantum efﬁciency (DQE), deﬁned as:
DQE 5 SNRout
SNRin

2
;
ð2:13Þ
where the subscripts ‘in’ and ‘out’ refer to the input SNR to, and output SNR
from, the detector. The value of the DQE is always less than 1, since the
detector must introduce some noise into the system, but the higher the DQE
the higher the SNR for a given number of X-rays entering the detector. For
example, the DQE of a standard CR plate has a value ~0.25, for a high
resolution CR plate the DQE is ~0.12. Using a dual-sided read CR increases
the DQE to ~0.4. The highest DQE ~0.8 is for CsBr:Eu2+ based plates.
As mentioned previously, if a CR or DR plate is exposed to an X-ray beam with
no patient present, then the image intensity should be absolutely uniform.
Probability
P
1000
number of X-rays detected
σ=31
Probability
P
10
number of X-rays detected
σ=3.1
Probability
P
106
number of X-rays detected
σ=1000
Figure 2.18
Plots of a Poisson distribution with increasing number of X-rays produced. As the number increases,
the distribution becomes narrower, with the mean number of events and the total number of events
converging to the same value.
56
X-ray planar radiography and computed tomography

However, even assuming a perfect detector response, there are still small variations
in the image intensity over the plate, as shown in Figure 2.19.
2.8.2 Spatial resolution
As discussed in Chapter 1, the overall spatial resolution is a combination of the
contributions from each part of the imaging process. For planar radiography, the
major contributions are:
(i) The size of the effective X-ray focal spot and the relative distances between the
X-ray tube and the patient, and the X-ray tube and the detector. The ﬁnite size
of the effective focal spot of the X-ray tube results in ‘geometric unsharpness’
of the image, as shown in Figure 2.20. The size of the ‘penumbra’ region,
denoted P, is given by:
P 5 fðS1  S0Þ
S0
:
ð2:14Þ
To improve the image spatial resolution, therefore, the value of S0 should be as
large, and the value of f as small, as possible, with the patient placed directly
on top of the detector.
(ii) The properties of the X-ray detector. As outlined in Section 2.7, the spatial
resolution depends upon the exact physical make-up of the phosphor layer of
the detector, whether it is single- or double-sided, and the number of pixels in
the image.
As covered in Chapter 1, the overall MTF is given by the convolution of the
individual MTFs from each component of the imaging system. In order to estimate
106 X-rays
104 X-rays
Figure 2.19
The effect of radiation dose (total number of incident X-rays) on the SNR of a planar image with no
patient in place. The image on the left has 100 times the number of X-rays per pixel, and so has 10
times higher SNR.
57
2.8 Quantitative characteristics of planar X-ray images

these values, the most useful measure of spatial resolution for X-radiography is the
line spread function (LSF), which is measured using a grid consisting of parallel
lead septa.
2.8.3 Contrast-to-noise
The CNR depends upon three different types of factor: the ﬁrst determines the
relative contribution of Compton-scattered X-rays (which reduce the CNR), the
second affects the SNR (covered in Section 2.8.1), and the third contributes to the
spatial resolution (covered in Section 2.8.2).
Factors affecting the contribution of Compton-scattered X-rays include:
(i) The X-ray energy spectrum. For low kVp values, the photoelectric effect
dominates, and the values of lbone and ltissue, for example, are substantially
different. If high energy X-rays are used, then Compton scattering is the
predominant interaction, and the contrast is reduced considerably. However,
the dose of low-energy X-rays must be much greater than that of high-energy
X-rays for a given image SNR,
(ii) The ﬁeld-of-view (FOV) of the X-ray image – for values of the FOV between
approximately 10 and 30 cm, the proportion of Compton scattered radiation
reaching the detector increases linearly with the FOV, and therefore the CNR
is reduced with increasing FOV. Above a FOV of 30 cm, the proportion
remains constant,
f
S0
S1
p
object
image
Figure 2.20
A ﬁnite effective spot size as well as the tube–patient (S0) and tube–detector (S1) distances determine
the spatial resolution of the image. The ‘geometric unsharpness’ or penumbra (P) causes features and
edges in the image to become blurred, as shown on the right.
58
X-ray planar radiography and computed tomography

(iii) The thickness of the body part being imaged – the thicker the section, then the
larger the contribution from Compton scattered X-rays and the lower the
number of X-rays detected. Both factors reduce the CNR of the image,
(iv) The geometry of the anti-scatter grid – as outlined in Section 2.8.1, there is a
trade-off between the SNR of the image and the contribution of Compton
scattered X-rays to the image.
2.9
X-ray contrast agents
In medical imaging the term ‘contrast agent’ refers to a chemical substance which
is introduced into the body (either orally or injected into the bloodstream). The
substance accumulates, either passively or via active transport, in a particular organ
or structure in the body and enhances the contrast between that structure and the
surrounding tissue. Contrast agents are often used in X-ray, ultrasound and mag-
netic resonance imaging: nuclear medicine techniques are by their nature entirely
based on injected agents. Contrast agents are designed to give the maximum
contrast for the minimum administered dose, and to have as small a degree of
adverse side-effects as possible.
X-ray contrast agents are designed to be very efﬁcient at absorbing X-rays, i.e.
to have a strong contribution from photoelectric interactions. There are two basic
classes of X-ray contrast agent. The ﬁrst is used for gastrointestinal (GI) tract
disorders and is administered orally, rectally or via a nasal cannula: the second
is based on water-soluble iodinated compounds which are injected into the blood-
stream, and are used to visualize the vasculature in the brain, heart or peripheral
arteries and veins.
2.9.1 Contrast agents for the GI tract
The contrast agent barium sulphate is used to investigate abnormalities of the GI
tract such as ulcers, polyps, tumours or hernias. Barium has a K-edge at 37.4 keV,
and so is a very efﬁcient absorber of X-rays. Barium sulphate is a powder, which is
prepared for patient administration as a thick suspension in water. For studies of
the upper GI tract, barium sulphate is administered orally. Rectal administration is
used for investigations of the lower GI tract. The agent essentially ﬁlls the entire
lumen and so areas in which it is absent are visible as areas of low X-ray absorp-
tion. An example of an adenocarcinoma of the colon is shown in Figure 2.21. As an
enema, barium sulphate can also be used as a ‘double contrast agent’: barium
sulphate is administered ﬁrst, followed by air. The barium sulphate coats the inner
59
2.9 X-ray contrast agents

surface of the GI tract and then the air distends the lumen. This double agent
approach is used to characterize small pathologies in the large intestine, colon
and rectum.
2.9.2 Iodine-based contrast agents
More than 40 million clinical studies are performed every year using iodine-based
contrast media, which are administered intravenously into the patient. The reason
for choosing iodine is that it has a K-edge at 33.2 keV and so there is substantially
increased X-ray attenuation in blood. This allows very small vessels down to ~50
lm diameter to be detected. As with all contrast agents, safety is the major concern,
and so the agent must be designed to be as effective as possible at the lowest dose
and produce the minimum number of side-effects. All currently-used agents are
based on a tri-iodinated benzene ring, with different side-groups (denoted R in
Figure 2.22), which dictate the pharmacokinetic properties of the particular agent.
A tri-iodinated structure contains the maximum number of iodine atoms, which
reduces the required dose. To reduce adverse side-effects the contrast media are
non-ionic with low osmolarity. The highest biocompatibility comes from agents
such as iodixanol, which have an osmolarity very close to that of blood and CSF
(290 mOsm/kg).
Figure 2.21
A barium sulphate enhanced image of the colon shows an adenocarcinoma (white arrows). The high
attenuation of the barium sulphate produces a very high (white) image intensity.
60
X-ray planar radiography and computed tomography

As shown in Figure 2.22, contrast agents can be monomeric or dimeric. The
range of molecular weights of the dimeric agents is 1300–1600, and 650–800 for
the monomeric equivalents. The osmolarity of the dimers is much lower than that
of the monomers. Each agent contains between 270 and 370 mg of iodine per ml.
The agents exhibit very low binding to plasma proteins in the blood, and so are
excreted unmetabolized in the urine within 24 hours.
One major use of iodinated contrast agents is digital subtraction angiography,
covered in Section 2.10.1. In addition, iodinated X-ray contrast agents are used for
intravenous urography, pyelography and cholangiography. In computed tomography,
iodinated agents are used in ~50% of scans.
2.10
Specialized X-ray imaging techniques
In addition to planar X-ray imaging, there are a number of different specialized
imaging techniques which use X-rays, the main examples of which are described in
the following sections.
2.10.1 Digital subtraction angiography
Digital subtraction angiography (DSA) produces very high resolution images of
the vasculature in the body, being able to resolve small blood vessels which are
less than 100 lm in diameter. The procedure involves acquiring a regular image,
then injecting a bolus of iodinated contrast agent into the bloodstream, acquiring a
second image, and then performing image subtraction of the two digital images.
I
R2
I
I
R1
R3
L=N(COCH3)CH2CH(OH)CH2N(COCH3)
I
R2
I
I
R1
I
I
I
R1
R3
L
R1=R3= CONHCH2CH(OH)CH2OH
b
a
Figure 2.22
(a) Generic formula for a monomeric iodinated X-ray contrast agent. The side-groups R1, R2 and R3
can all be the same or different. (b) Generic form of a dimeric agent, in which the two benzene rings are
joined by a chemical linker (L). The chemical structure of iodixanol, which is both iso-osmolar with
blood and also non-ionic, is shown.
61
2.10 Specialized X-ray imaging techniques

Examples of DSAs are shown in Figure 2.23. DSA is used to investigate diseases
such as stenoses and clotting of arteries and veins, and irregularities in systemic
blood ﬂow.
2.10.2 Digital mammography
Digital X-ray mammography is used to detect small tumours or microcalciﬁcations
in the breast. Very high spatial resolution and CNR are needed to detect these types
of pathology, which can be less than 1 mm in diameter. A low radiation dose is
especially important to avoid tissue damage. A specialized X-ray tube is used, with
an anode target made from molybdenum (rather than tungsten). Molybdenum has
two K-edges at 17.9 and 19.6 keV, as shown in Figure 2.24. The cathode ﬁlament
is ﬂat, rather than helical, in order to produce a more focused electron beam. The
bevel angle of the anode is reduced to produce an effective focal spot size of
Figure 2.23
Digital subtraction angiograms showing ﬁne vessel structures. The vessels containing iodinated
contrast agent are shown as dark areas in the subtraction images.
62
X-ray planar radiography and computed tomography

0.3 mm or less. The glass window in the X-ray tube is replaced by one fabricated
from beryllium to reduce the degree of ﬁltering of the low energy X-rays. A
molybdenum ﬁlter (30 lm thickness) is used to reduce the amount of high energy
X-rays (.20 keV) which would otherwise give an increased patient dose without
improving image quality, as is also shown in Figure 2.24. Occasionally, with a
radio-opaque breast, in which attenuation of X-rays is particularly high, an alumi-
nium ﬁlter can be used instead of molybdenum.
As described previously, the detector can either be CR or DR-based. The highest
spatial resolution conﬁguration is used in either case. To reduce the effects of
geometric unsharpness, a large focal-spot-to-detector distance (45 to 80 cm) is
used. A 4:1 or 5:1 grid ratio is used for the anti-scatter grid, with septa density
typically between 25 and 50 lines per cm, a septal thickness less than 20 lm, and
septal height less than 1 mm. Compression of the breast is necessary, normally to
about 4 cm thickness, in order to improve X-ray transmission and reduce the
contribution from Compton scatter. The digital mammogram on the right of
Figure 2.24 shows the very ﬁne detail that can be obtained.
2.10.3 Digital ﬂuoroscopy
Digital ﬂuoroscopy uses continuous X-ray imaging, and can monitor interven-
tional surgery, for example the placement of catheters, guide-wires, stents and
0
5
10
15
20
25
30
No. X-rays
X-ray energy
Mo K-edge
Figure 2.24
(left) The X-ray spectrum used for digital mammography. The kVp of the X-ray tube is 26 keV.The
anode is made from molybdenum and produces a substantial number of low energy X-rays (dashed
line). A 30 lm thickness molybdenum ﬁlter is used to reduce the contribution from very low energy X-
rays (solid line). (right) Example of a digital mammogram, showing very high spatial resolution.
63
2.10 Specialized X-ray imaging techniques

pacemakers in cardiac catheterization laboratories, as well as for dynamic studies
of the GI tract and cardiovascular system using contrast agents. Until very recently,
the traditional detector was a digital image intensiﬁer television system (IITV), in
which the images produced by an X-ray image intensiﬁer were digitized using a
CCD-based device. However, this type of detector is now being replaced by solid-
state detectors, which are very similar to indirect-detection digital radiography
technology (Section 2.7.2). Some minor modiﬁcations to the DR instrumentation
are made: for example, the thickness of the CsI:Tl is increased to 550–650 lm to
increase the detection efﬁciency and therefore reduce the required X-ray dose [3].
In recent years most cardiac catheterization laboratories have moved to solid state
digital detector technology. An example is shown in Figure 2.25, as well as an
example of a neurovascular interventional laboratory.
Solid-state digital ﬂuoroscopy systems use very short pulses of X-rays of ~5–20
ms duration depending upon the type of examination and patient size. Fluoro-
scopic images are typically acquired at rates of up to 30 frames per second. The
X-ray dose per frame during ﬂuoroscopy can be as low as one one-thousandth of
that used during serial image acquisition.
2.11
Clinical applications of planar X-ray imaging
A number of clinical applications of X-ray imaging have already been described.
Planar radiography is used for determining the presence and severity of fractures or
cracks in the bone structure in the brain, chest, pelvis, arms, legs, hands and feet.
Vascular imaging using injected iodine-based contrast agents is performed to study
compromised blood-ﬂow, mainly in the brain and heart, but also in the peripheral
Figure 2.25
(left) A cardiac catheterization laboratory which uses a digital ﬂuoroscopy unit to monitor placement of
stents and pacemakers. (right) A neurointerventional unit, with a C-arm digital ﬂuoroscopy unit.
64
X-ray planar radiography and computed tomography

venous and arterial systems. Diseases of the GI tract can be diagnosed using
barium sulphate as a contrast agent, usually with continuous monitoring via X-
ray ﬂuoroscopic techniques. Investigations of the urinary tract are among the most
common applications of planar X-ray imaging, and are carried out in the form of
kidney, ureter and bladder (KUB) scans and intravenous pyelograms (IVPs). The
KUB scan is carried out without contrast agent, and can detect abnormal distribu-
tions of air within the intestines, indicative of various conditions of the GI tract,
and also large kidney stones. The KUB scan is usually the precursor to a follow-up
imaging procedure which would entail a GI scan with barium sulphate, or an IVP if
problems with the urinary system are suspected. An IVP is performed using an
injected iodinated contrast agent in order to visualize the ﬁlling and emptying of
the urinary system. An example of an IVP is shown in Figure 2.26. Obstruction to
normal ﬂow through the system is usually caused by kidney stones, but can result
from infections of the urinary system. An IVP is carried out as a series of images
acquired at different times after injection of the contrast agent. Normal excretion of
the agent from the bloodstream via the kidneys takes about 30 minutes, but any
obstructions can be detected or inferred from delayed passage of the contrast agent
through the affected part of the urinary system.
Figure 2.26
Example of an intravenous pyelogram. An iodinated contrast agent has been administered and its
distribution can be seen as areas of bright signal intensity.
65
2.11 Clinical applications of planar X-ray imaging

2.12
Computed tomography
The principles of CT were ﬁrst described by Sir Godfrey Hounsﬁeld and Allan
Cormack in 1972 [4], an invention for which they were awarded jointly the Nobel
Prize in Medicine in 1979. There are ~30 000 CT scanners worldwide, with more
than 60 million CT scans being performed every year in the US alone. The basic
principle behind CT, as shown in Figure 2.27, is that the two-dimensional structure
of an object, in this case the spatially dependent X-ray attenuation coefﬁcients, can
be reconstructed from a series of one-dimensional ‘projections’ acquired at different
angles, followed by appropriate image reconstruction, as covered in Section 1.10.
A bank of solid-state detectors is situated opposite the X-ray tube and together
they record a one-dimensional projection of the patient. The X-ray source and
detectors are rotated through one complete revolution around the patient, with
data being acquired essentially continuously. Most commercial scanners are so-
called ‘third generation scanners’ which use a wide X-ray fan-beam and between
512 and 768 detectors. Two separate collimators are used in front of the source.
The ﬁrst collimator restricts the beam to an angular width of 45–60. The second
collimator, placed perpendicular to the ﬁrst, restricts the beam to the desired slice
thickness, typically 1–5 mm, in the patient head/foot direction. The scanner usually
operates at a kVp of ~140 kV, with ﬁltration giving an effective X-ray energy of
70–80 keV, and a tube current between 70 and 320 mA, although much higher
values can be used for large patients. The focal spot size is between 0.6 and 1.6 mm.
Typical operating conditions are a rotation speed of once per second, a data matrix
filtered
backprojection
source
detectors
Figure 2.27
(left) The physical principle of computed tomography involves synchronous rotation of the X-ray tube
and multiple detectors to record a series of one-dimensional projections. The CT image (right) is
produced by the process of ﬁltered backprojection.
66
X-ray planar radiography and computed tomography

of the reconstructed image of either 512 3 512 or 1024 3 1024, and a spatial
resolution of ~0.35 mm.
2.12.1 Spiral / helical CT
Acquiring a single axial slice through a particular organ is of very limited
diagnostic use, and so a volume consisting of multiple adjacent slices is always
acquired. One way to do this is for the X-ray source to rotate once around the
patient, then the patient table to be electronically moved a small distance in the
head/foot direction, the X-ray source to be rotated back to its starting position, and
another slice acquired. This is clearly a relatively slow process. The solution is to
move the table continuously as the data are being acquired: this means that the
X-ray beam path through the patient is helical, as shown in Figure 2.28. Such a
scanning mode is referred to as either ‘spiral’ or ‘helical’, the two terms being
interchangeable. However, there were several hardware and image processing
issues that had to be solved before this concept was successfully implemented
in the early 1990s. First, the very high power cables that feed the CT system cannot
X-ray source
X-ray
detectors
512
64
table motion
Figure 2.28
The principle of helical computed tomography in which, due to table motion along the head/foot axis,
the X-ray beam plays out a helical pattern through the patient. Use of multiple detector rows (along the
head/foot direction, numbers of detectors are shown for a typical 64-slice scanner) enables CT
images to be acquired much more rapidly.
67
2.12 Computed tomography

physically be rotated continuously in one direction, and similarly for the data
transfer cables attached to the detector bank. A ‘contactless’ method of both
delivering power and receiving data had to be designed. Second, the X-ray tube
is effectively operating in continuous mode, and therefore the anode heating is
much greater than for single-slice imaging. Finally, since the beam pattern through
the patient is now helical rather than consisting of parallel projections, modiﬁed
image reconstruction algorithms had to be developed. The ﬁrst ‘spiral CT’, devel-
oped in the early 1990s, signiﬁcantly reduced image acquisition times and enabled
much greater volumes to be covered in a clinical scan.
In a helical scan, the pitch (p) is deﬁned as the ratio of the table feed (d) per
rotation of the X-ray tube to the collimated slice thickness (S):
p 5 d
S :
ð2:15Þ
The value of p typically used in clinical scans lies between 1 and 2. The
reduction in tissue radiation dose, compared to an equivalent series of single-slice
scans, is equal to the value of p.
2.12.2 Multi-slice spiral CT
The efﬁciency of spiral CT can be increased further by incorporating an array of
detectors, rather than having just a single detector, in the head/foot direction. Such
an array is also shown in Figure 2.28. The increase in efﬁciency arises from the
higher values of the table feed per rotation that can be used. Multi-slice spiral CT
can be used to image larger volumes in a given time, or to image a given volume in
a shorter scan time, compared to conventional spiral CT. The effective slice thick-
ness is dictated by the dimensions of the individual detectors, rather than the
collimated X-ray beam width as is the case for a single detector, which allows
thinner slices to be acquired. Modern multi-detector CT (MDCT) systems have up
to 256 or 320 detector rows.
2.13
Instrumentation for CT
Several components of the CT system such as the X-ray tube, collimator and anti-
scatter grid are very similar to the instrumentation described previously for planar
X-radiography. The tube and detectors have to be ﬁxed to a heavy gantry, which
rotates very rapidly, generating large gravitational forces. High power cables are
used to deliver power to the X-ray tube, and a large parallel cable is used to transfer
68
X-ray planar radiography and computed tomography

data from the scanner to the central computer. Since each projection is acquired
serially, dedicated digital signal processing boards are used to pre-process the data
from each detector while the remainder of the data are being acquired, in order to
speed up image reconstruction.
The detectors used in CT are solid-state devices, based upon converting the X-
ray energy into light using a scintillator, and then the light being further converted
into a voltage using a photodiode. The individual detector elements are typically
~15 mm in length and 1 mm wide, as shown schematically in Figure 2.29. There
are several hundred of these elements in the detector module which rotates around
the patient. The scintillator is based upon proprietary gadolinium ceramics, which
are very effective X-ray absorbers. The anti-scatter grid is usually integrated into
the detector array.
2.13.1 Instrumentation development for helical CT
A number of instrument modiﬁcations have to be made to the basic CT set-up in
order to enable helical scans to be acquired. As mentioned previously, it is not
possible to use ﬁxed cables to connect either the power supply to the X-ray source,
or the output of the solid state detectors directly to the digitizer and computer.
Instead, multiple slip-rings are used for power and signal transmission. A slip ring
is a circular contact with sliding brushes that allows the gantry to rotate continu-
ally: an example is shown in Figure 2.30.
Another equipment challenge in spiral CT scanning is that the X-rays must be
produced almost continuously, without the cooling period that exists between
acquisition of successive slices in conventional CT. This leads to very high temper-
atures at the focus of the electron beam at the surface of the anode. Anode heating
is particularly problematic in abdominal scanning, which requires higher values of
scintillator
photodiode
voltage
X-ray
collimated
beam width
Figure 2.29
(left) A single row detector array. (right) For each solid-state detector the incident X-ray energy is
converted into an electrical signal via a scintillator and photodiode.
69
2.13 Instrumentation for CT

tube currents and exposures than for imaging other regions of the body. Therefore,
the X-ray source must be designed to have a high heat-capacity, and very efﬁcient
cooling.
2.13.2 Detectors for multi-slice CT
In single-slice and helical CT, the slice thickness in the head/foot direction is
determined by the collimated beam width in this dimension. In multi-slice CT
there are up to 320 separate detectors, spanning a length of 16 cm, in the head/
foot direction. Since separate signals are acquired from each of these detectors, the
slice thickness is now determined by the size of the detector itself rather than the
collimated beamwidth. The two-dimensional array contains the same number of
circumferential elements per row as for single-detector helical CT, and so there are
close to 250 000 separate signals being recorded essentially simultaneously. Exam-
ples of multi-detector modules are shown in Figure 2.31. The dimensions of the
separate rows of the detectors can be the same, or they can vary in size with the
smallest detectors usually being closest to the centre of the array. One such detector
array, developed by Siemens, has 40 detector rows, with the 32 centre rows having
0.6 mm width, and the eight outer rows having 1.2 mm width: the total coverage is
therefore 28.8 mm. In addition to being able to acquire 32 slices of 0.6 mm
thickness at the centre of the array, by combining the signal from neighbouring
inner elements, 24 slices of 1.2 mm thickness can also be produced. There are also
Figure 2.30
(left) A cut-away of a helical CT scanner showing the slip-rings. (right) Close-up of the sliding brushes
used to transfer power from the stationary gantry to the rotating X-ray tube.
70
X-ray planar radiography and computed tomography

methods which can improve the spatial resolution to a value smaller than the
dimensions of the detector – one such is called the z-ﬂying spot technique, in
which the focal spot on the anode in the X-ray tube alternates rapidly between two
slightly different positions [5].
2.14
Image reconstruction in CT
The mathematical basis for reconstruction of an image from a series of projections
is the inverse Radon transform, as outlined in Section 1.10, which is performed
using ﬁltered backprojection.
2.14.1 Filtered backprojection techniques
If one assumes, for simplicity, that the signal produced in each element of
the detector array arises from parallel X-rays, then the data can be ﬁltered and
backprojected to give the image. This process is illustrated in Figure 2.32 for a
brain CT.
A CT image does not actually display a map of the spatially-dependent tissue
attenuation coefﬁcents per se, but rather a map of the tissue CT numbers, which are
deﬁned by:
CTo 5 1000 lo  lH2O
lH2O
;
ð2:16Þ
where CTo is the CT number, with values expressed in Hounsﬁeld units (HU),
and lo the linear attenuation coefﬁcient of the tissue in each pixel. The reconstructed
Figure 2.31
Multi-slice CT detectors, with up to 320 rows for the largest detector at the back.
71
2.14 Image reconstruction in CT

image consists of CT numbers varying in value from +3000 to 21000. As shown
in Table 2.1, the highest CT number corresponds to dense bone. Very high CT
numbers also result from blood vessels containing a high dose of iodinated contrast
agent, or bowel regions coated with barium sulphate. Since the attenuation coef-
ﬁcient of these tissues/contrast agents is very high, these regions have a high CT
number and so appear bright on CT images.
45
90
180
135
0°
45°
90°
Figure 2.32
(left) Three projections acquired at different angles from a slice through the head of a patient. (centre)
Sinogram showing the projections as a function of rotation angle from 0 to 180. (right) Image
produced by ﬁltered backprojection.
Table 2.1: CT numbers of different tissues at 70 keV
Tissue
CT number (Hounsﬁeld units)
Bone
1000–3000
Muscle
10–40
Water
0
Lipid
250 to 2100
Air
21000
Brain (white matter)
20 to 30
Brain (grey matter)
35 to 45
Blood
40
72
X-ray planar radiography and computed tomography

2.14.2 Fan beam reconstructions
Filtered backprojection assumes that the components of the X-ray beam striking
each detector element are parallel. However, as shown in Figure 2.27, the X-ray
beam subtends an angle of 45–60 and, since the detector array is quite wide, the
beam is far from being parallel to the detectors. The easiest way to overcome this
issue, while maintaining the ability to use simple ﬁltered backprojection, is to sort
the acquired data from different projections into a set of ‘synthetic projections’ in
which the beam geometry acts as if it were parallel to the detector. The position of
the X-ray source and detectors is known with very high accuracy at each time point
during the rotation, and so this process introduces negligible error into the meas-
urements. An example of this process is shown in Figure 2.33.
2.14.3 Reconstruction of helical CT data
The helical trajectory of the X-rays through the patient means that the data do not
correspond to a complete 180 or 360 rotation about the patient, and therefore the
data must be resampled before ﬁltered backprojection (incorporating fan beam
resampling as explained above) can be used to produce a series of adjacent axial
Figure 2.33
The process of data rebinning to produce parallel projections from fan beam data. Data from four
different projection angles, h1. . .h4 are shown. One projection, shown as the solid line, is taken from
each of the datasets to produce a synthetic data set (bottom) with four parallel projections, which can
then use a simple ﬁltered backprojection algorithm for image reconstruction.
73
2.14 Image reconstruction in CT

slices. Resampling involves linear interpolation of data points 180 apart on the
spiral trajectory to estimate the ‘missing’ data, as shown in Figure 2.34. By adjust-
ing the weights given to the interpolation, slices can be shifted slightly in position,
and images with thicknesses greater than the collimation width can be produced by
adding together adjacent reconstructed slices. These overlapping slices have been
shown to increase the accuracy of lesion detection since there is less chance that a
signiﬁcant portion of the lesion lies between slices.
2.14.4 Reconstruction of multi-slice helical CT scans
Image reconstruction for multi-slice helical CT scans is essentially identical to that
for single-slice helical scans, with the additional advantage that the slice thickness
in multi-slice spiral CT can be chosen retrospectively after data acquisition. Thin
slices can be reconstructed to form a high quality three-dimensional image, but the
same data set can also be used to produce a set of thicker slices, with a higher SNR
from each slice.
2.14.5 Pre-processing data corrections
Image reconstruction for all modes of data collection must be preceded by a series
of corrections to the acquired projections to account both for instrumental imper-
fections and patient-induced changes in the properties of the X-ray beam. The ﬁrst
corrections are made for the effects of ‘beam hardening’, in which the effective
Figure 2.34
Image reconstruction from helical CT data. The process involves interpolation of data points which are
not acquired. The solid dots represent acquired data, with the ﬁlled shape being the location of the
interpolated data.
74
X-ray planar radiography and computed tomography

energy of the X-ray beam increases as it passes through the patient, due to the
greater attenuation of lower X-ray energies. This means that the effective attenu-
ation coefﬁcient is smaller for ‘thicker’ areas of the body, since the beam hardening
effects are greater. In the reconstructed image, this corresponds to an apparent
decrease in the CT number in the centre of the body, for example, as shown in
Figure 2.35. There are a number of ways to minimize this effect, by using a ‘bow-
tie’ ﬁlter, also shown in Figure 2.35, or by applying correction algorithms based
upon the distance travelled by each X-ray beam through tissue.
The second type of correction is for slight differences in the sensitivities of
individual detectors and detector channels. Imbalances in the detectors are usually
measured using an object with a spatially uniform attenuation coefﬁcent before the
actual patient study. The results from this calibration scan can then be used to
correct the data from the clinical scan before backprojection.
2.15
Dual-source and dual-energy CT
The temporal resolution of helical CT is basically limited by the rotation rate of the
gantry. The minimum time for a 180 rotation is ~160 ms for current commercial
systems. If the speed were to be increased signiﬁcantly, then this would generate
enormous gravitational forces on the system. An alternative method of achieving
higher temporal resolutions is to add a second X-ray tube/detector into the scanner,
a technique termed dual source computed tomography (DSCT). The second source
4
3
2
1
tc
ejb
o
d
e
tc
u
rts
n
o
c
e
r
e
g
a
m
i
r
o
tc
e
t
e
d
Figure 2.35
(left) Four parallel X-ray beams pass through an elliptical object with spatially uniform attenuation
coefﬁcient. The effective energy of beam 4 increases as it passes through the object to a greater
degree than for beams 3, 2 and 1 since it has to travel the furthest distance through the object. This
effect is known as beam hardening. An image reconstructed using ﬁltered backprojection (centre)
shows a reduced CT number in the centre of the object. (right) The effect of beam-hardening can be
reduced by the use of a ‘bow-tie’ ﬁlter made of a metal such as aluminium, which also reduces the
dose to extremities such as the arms.
75
2.15 Dual-source and dual-energy CT

does not cover as large a FOV as the primary source, typically about two-thirds, as
shown in Figure 2.36. The temporal resolution of such a system is twice that of an
equivalent single source helical CT scanner, which is particularly important for
cardiac imaging [6;7].
An alternative mode of data acquisition made possible by having two different
X-ray sources is to use a different kVp and tube current for each tube, thus
producing ‘dual-energy’ images. One application is illustrated in Figure 2.36.
Using a single energy, it is relatively difﬁcult to differentiate voxels which contain
bone from those with contrast agent, a clinical example being microcalciﬁcations
which are present around blood vessels which contain contrast agent. Using dual-
energy imaging allows an image to be produced in which the microcalciﬁcations
are ‘removed’, as shown on the right of Figure 2.36. Typically, the two kVp values
used are 140 keV and 80 keV, and each voxel in the image is decomposed into a
percentage contribution from iodine, bone and soft-tissue.
2.16
Digital X-ray tomosynthesis
Digital X-ray tomosynthesis is a relatively new technique which might be consid-
ered as being a hybrid of planar radiography and CT [8;9]. Chest tomosynthesis is
used primarily for detecting small pulmonary nodules and also for breast imaging.
The patient stands in front of a ﬂat panel detector, and a motorized unit moves the
X-ray tube in a vertical path, as shown in Figure 2.37. A 0.6 mm focal spot is used,
Figure 2.36
(left) A dual-source CT system. (right) Image improvement using a dual-energy CT system. The image
on the left shows microcalciﬁcations (small bright areas) superimposed on top of the arteries in a DSA
scan. On the right, the microcalciﬁcations are removed to allow accurate visualization of the arterial
system.
76
X-ray planar radiography and computed tomography

with short exposure pulses of X-rays: the source-to-detector distance is ~1.8
metres. Typically 61 projection images are acquired during the vertical motion
of the X-ray source. The radiation dose is much lower than for CT, but the image
information content is much higher than for planar radiography. Conventional
ﬁltered backprojection algorithms cannot be used since only a limited angular
coverage is acquired, so more sophisticated forms of backprojection or iterative
algorithms are usually employed.
2.17
Radiation dose
The fact that X-ray imaging involves use of ionizing radiation means that there are
strict safety guidelines on the single study and annual accumulated radiation doses
that can be used in patients. The International Committee for Radiation Protection
(ICRP) characterizes two different types of radiation effect, ‘deterministic’ and
flat panel
detector
anti-scatter
grid
slices reconstructed
at different depths
Figure 2.37
(left) The basic technique of X-ray tomosynthesis, in which an X-ray source is rotated through a
relatively small angle, with planar images being formed at each angle: the digital detector remains
ﬁxed for each scan. Image reconstruction allows slices at different depths to be formed. (right)
Example of a digital tomosynthesis mammogram.
77
2.17 Radiation dose

‘stochastic’. Deterministic effects refer to cellular damage which leads to a loss in
tissue function if a sufﬁcient number of cells are damaged. The probability of this
happening is very low at low radiation doses, but climbs steadily towards unity
with a dose above a certain threshold level. In contrast, stochastic effects refer to
the biological situation in which the cell is not killed, but genetic mutations caused
by chromosomal damage lead, in time, to development of cancer. These stochastic
effects may occur at a much lower dose than deterministic effects: the higher the
dose the greater the probability of cancer occurring, but importantly there is no
absolute threshold level. Given that the deterministic threshold limits are far above
the doses encountered in normal X-ray procedures, the greatest concern is stochastic
effects.
Quantitatively, the absorbed dose (D) is deﬁned as the radiation energy (E),
measured in Joules, absorbed per kg of tissue. The value of D is given in units of
grays (Gy), where 1 Gy equals 1 Joule/kg. The equivalent dose (HT) in a tissue is
given by:
HT 5 +
R
wRDT;R;
ð2:17Þ
where
DT;R 5
1
mT
ð
mT
DRdm:
ð2:18Þ
Note that DT,R is the mean absorbed dose in tissue (T) with mass (mT) from a
given amount of radiation R, and wR is the radiation weighting factor (with a value
of 1 for both X-rays and c-rays). The unit of HT is J/kg, but it is typically reported
in sieverts (Sv), or millesieverts for realistic doses.
Some tissues are more sensitive to radiation damage than others, and this is
taken into account by calculating the effective dose (E), which is given by the
tissue equivalent dose weighted by the tissue weighting factor (wT) of that organ:
E 5 +
T
wTHT:
ð2:19Þ
Values of wT for different tissues are given in Table 2.2 with the number deﬁned
on a scale such that:
+
T
wT 5 1:
ð2:20Þ
The values of wT represent the fraction of the total stochastic radiation risk for
all the different organs and tissue. For the gonads, which have the highest risk, this
78
X-ray planar radiography and computed tomography

refers to the possibility of hereditary conditions being induced: for the other organs
in Table 2.2 it refers to the risk of cancer.
In CT, the radiation dose to the patient is calculated in a slightly different way
since the X-ray beam proﬁle across each slice is not uniform, and adjacent slices
receive some dose from one another. For example, in the USA the food and drug
administration (FDA) deﬁnes the computed tomography dose index (CTDI) for a
fourteen-slice examination to be:
CTDI 5 1
T
ð
17T
7T
Dzdz;
ð2:21Þ
where Dz is the absorbed dose at position z, and T is the thickness of the slice.
Since this deﬁnition has become somewhat obsolete, given the large number of
slices that can be acquired on a modern CT scanner, an adapted measure is the
CTDI100, which is deﬁned as:
CTDI100 5
1
NT
ð
þ5cm
5cm
Dsingle;zdz;
ð2:22Þ
where N is the number of acquired slices, and T is the nominal width of each
slice. Further reﬁnement involves the fact that the CTDI100 value depends upon the
position within the scan plane. The weighted CTDI, CTDIw, is deﬁned as:
Table 2.2: Tissue weighting factors for calculations of effective dose
Tissue / organ
Tissue weighting
factor, wT
Gonads
0.2
Bone marrow (red)
0.12
Colon
0.12
Lung
0.12
Stomach
0.12
Chest
0.05
Bladder
0.05
Liver
0.05
Thyroid
0.05
Oesophagus
0.05
Average (brain, small intestines, adrenals, kidney,
pancreas, muscle, spleen, thymus, uterus)
0.05
Skin
0.01
Bone surface
0.01
79
2.17 Radiation dose

CTDIw 5 1
3 CTDI100
ð
Þcentre 1 2
3 CTDI100
ð
Þperiphery:
ð2:23Þ
For helical scans, the CTDIvol is simply given by CTDIw/pitch, where pitch was
deﬁned in Equation (2.15). All these measures are quite crude approximations, and
detailed numerical simulations of CT dose for realistic patient conditions are a very
active area of research, particularly with the recent advances in helical, multi-
detector scanners.
Table 2.3 shows approximate doses for common X-ray procedures: the exact
dose depends upon the particular system that is used for image acquisition, the
patient size, etc. The limit on annual radiation dose under federal law in the USA is
50 mSv.
2.18
Clinical applications of CT
Computed tomography is used for a wide range of clinical conditions in almost
every organ of the body. Brain, lymph nodes, lung, pelvis, liver, gall bladder,
spleen, kidneys, GI tract, spine, and extremities are all studied using CT. The
following is a very sparse survey of applications in speciﬁc areas.
2.18.1 Cerebral scans
Computed tomography is used for both chronic and acute head and brain scans. In
cases of acute trauma, the radiologist looks for signs of internal bleeding, tissue
oedema and skull fracture. Acute conditions can also occur, for example, if an
existing aneurysm ruptures, leading to internal bleeding. Blood shows up as a high
signal (high CT number) compared to the surrounding tissue, whereas oedema has
a somewhat lower intensity than tissue.
Table 2.3: Radiation doses from common planar radiography and CT scans
Procedure
Effective dose (mSv)
Abdominal planar X-ray
1.5
Chest planar X-ray
0.04
Lumbar spine planar X-ray
2.4
Intravenous pyelogram
4.6
Chest CT scan
8.3
Brain CT scan
1.8
Abdominal CT scan
7.2
80
X-ray planar radiography and computed tomography

Computed tomography is also used to diagnose, and follow the progression of,
tumours in the brain. Meningiomas and gliomas are particularly easy to diagnose.
In most cases, contrast agent is injected intravenously to highlight the tumour. In
normal tissue, these agents do not cross the blood brain barrier (BBB), but tumour
growth disrupts this barrier and so the agents can now enter the tumour.
2.18.2 Pulmonary disease
Normal lung tissue appears dark on CT images, but not as dark as the air within the
lungs. If a focal lesion or ‘nodule’ is detected on a planar X-ray, then a CT is often
performed. A CT scan can outline the size and geometry of the lesion much better, as
well as determining whether it takes up an injected iodinated contrast agent, and
whether it is calciﬁed or not. Lung cancer, for example, typically produces nodules
which have an irregular edge (caused by ﬁbrosis surrounding the tumour), with
small areas of air within the nodule. Calciﬁcation of a nodule normally indicates
that it is benign rather than metastatic, with calciﬁcation producing high attenuation,
and image intensities well above 100 HU. Lung cancers typically show a much
greater increase in tissue attenuation than benign nodules after contrast. Lung
abscesses, which are often associated with parasitic or bacterial infections, usually
have a necrotic centre: this is detected by a low attenuation even after contrast agent
injection, showing that there is little or no blood ﬂow to the necrotic core. Emphy-
sema shows up as large areas of low attenuation compared to the surrounding
pulmonary parenchyma, and is usually mostly seen in the upper lobes of the lung.
2.18.3 Liver imaging
Using multi-detector CT technology, the entire liver can be imaged at high reso-
lution within a single breath-hold. Lesions in the liver can be visualized by using
dynamic imaging after iodinated contrast agent injection. A pre-contrast control
scan is acquired as a baseline from which to calculate the contrast agent-induced
change in image intensities. A volume of between 100 and 150 ml of contrast agent
is injected over 30–40 s using a power injector. Approximately 30 s after injection,
the ﬁrst volume data set is acquired, which is termed the ‘arterial phase’ acquis-
ition. This is used primarily to detect hypervascular lesions, which have the blood
supplied by the hepatic artery: examples include focal nodular hyperplasia and
hepatomas. These lesions show a greater increase in attenuation coefﬁcient than
the surrounding tissue and therefore appear brighter on the image. A second
volume scan is acquired at ~65 s after injection: this is termed the ‘portal phase’
81
2.18 Clinical applications of CT

acquisition. This time corresponds to the enhancement of the normal liver paren-
chyma being at its maximum value, and therefore lesions now appear darker than
the surrounding tissue. Finally, depending upon the particular study, a third data
set may be acquired ~15 minutes after injection: this shows delayed enhancement
of ﬁbrotic tumours and a delayed ‘ﬁll-in’ of hemangiomas.
Fatty inﬁltrations into liver can be caused by a number of chronic conditions
including diabetes and alcoholism. The overall image intensity of liver with fatty
inﬁltrations is typically ~20 HU lower than healthy liver, and the liver is physically
enlarged. If there are speciﬁc areas of high fat inﬁltration, these appear as local
areas of low signal intensity.
2.18.4 Cardiac imaging
Computed tomography studies of the heart normally use an iodinated contrast
agent, and are primarily aimed at assessing calciﬁcations within the heart, partic-
ularly in the coronary artery, as shown by examples in Figure 2.38. Although MRI
and ultrasound scans are preferred due to the lack of ionizing radiation, in cases
where pacemakers or deﬁbrillators are present and MRI cannot be performed, then
CT is useful. Calciﬁcations of the coronary arteries are closely associated with the
degree of atherosclerotic plaque formation. Even in patients without any symptoms
of heart disease, the presence of coronary calciﬁcations is highly predictive of the
future development of cardiac problems. Image acquisition must be as fast as
Figure 2.38
Three CT scans of the heart. (left) Three-dimensional scan from a 64-slice CT scanner shows the
coronary arteries on the outside of the myocardium. (centre) and (right) Coronary angiograms of the
left anterior descending artery (LAD) and right coronary artery (RCA), respectively.
82
X-ray planar radiography and computed tomography

possible to ‘freeze’ the cardiac motion and acquire all the projections within a
single breath-hold if possible: image acquisition is gated to the heart motion via an
ECG trigger. Although CT angiography is not a routine clinical procedure, it is
very useful to rule out coronary stenoses in patients with a predisposition to the
disease, and is highly informative in patients with a known or suspected congenital
artery anomaly.
Exercises
The X-ray energy spectrum
2.1 Plot the energy spectra from a tungsten tube with the following kVp values:
120 keV, 80 keV, 60 keV and 40 keV.
2.2 (a) Calculate the total number of electrons bombarding the target of an X-ray
tube operated at 100 mA for 0.1 seconds.
(b) Calculate the maximum energy and minimum wavelength for an X-ray
beam generated at 110 kVp.
2.3 The spectrum of X-ray energies changes as the X-rays pass through tissue
due to the energy dependence of the linear attenuation coefﬁcient: this is a
phenomenon known as beam hardening. A typical energy distribution of the
beam from the X-ray source is shown in Figure 2.6. Sketch the energy
spectrum after the beam has passed through the body.
2.4 Look up the exact binding energies of the L and M shell electrons in tung-
sten. Plot the exact distribution of characteristic energy lines that are pro-
duced based upon these binding energies.
2.5 Two X-ray images of the hand are shown in Figure 2.39. One corresponds to
an X-ray beam with an effective energy of 140 keV and the other to an
a
b
Figure 2.39
See Exercise 2.5.
83
Exercises

effective energy of 50 keV. Explain which is which, and the reasons for the
differences in image contrast and signal intensity.
2.6 Planar X-rays of a horse’s leg are shown in Figure 2.40. In (a), the kVp and
tube current (mA) are chosen to give high contrast between the bone and
surrounding tissue. Explain how the kVp and mA settings would have to be
changed (increased, decreased, remain constant) to give the images shown in
(b) and (c).
2.7 Starting from Equation (2.4) derive both Equations (2.5) and (2.6).
Linear and mass attenuation coefﬁcients
2.8 Show two mechanisms involving scattering in the body which allow Compton
scattered X-rays to be detected despite the presence of an anti-scattering grid.
2.9 In Figure 2.41 calculate the X-ray intensity, as a function of the incident
intensity I0, that reaches the detector for each of the three X-ray beams. The
dark-shaded area represents bone, and the light-shaded area represents tissue.
The linear attenuation coefﬁcients at the effective X-ray energy of 68 keV are
10 cm21 and 1 cm21 for bone and tissue, respectively.
2.10 The linear attenuation coefﬁcient of a gadolinium-based phosphor used for
detection of X-rays is 560 cm21 at an X-ray energy of 150 keV. What
percentage of X-rays are detected by phosphor layers of 10 lm, 25 lm,
and 50 lm thickness? What are the trade-offs in terms of spatial resolution?
X-ray detectors
2.11 An X-ray with energy 60 keV strikes a gadolinium-based phosphor on a CR
plate producing photons at a wavelength of 415 nm. The energy conversion
coefﬁcient for this process is 20%. How many photons are produced for
each incident X-ray? (Planck’s constant = 6.6331034 Js, 1 eV=1.6023
10219J).
2.12 An X-ray is Compton scattered by an angle h at a distance z from the top of
the anti-scatter grid. Using simple geometry, calculate the maximum value of
h for a given grid ratio h/d that results in the X-ray being detected.
a
b
c
Figure 2.40
See Exercise 2.6.
84
X-ray planar radiography and computed tomography

Quantitative characteristics of planar X-ray images
2.13 The width of the electron beam in an X-ray tube is 6 mm, and the anode bevel
angle is 10. The patient is placed 180 cm from the X-ray tube, directly on
top of the ﬂat panel detector. Calculate the geometric unsharpness for a very
small lesion at the front of the abdomen and at the back of the abdomen,
assuming that the tissue thickness of the body at this point is 25 cm.
2.14 If the average number of X-rays striking the detector is 100 per pixel per
second, what is the probability that only 90 strike in any one second? If the
X-ray dose is increased by a factor of ten, what is the probability of 900
striking?
2.15 (a) Match up a thick and thin phosphor layer in computed radiography with
its associated LSF (1 or 2) in Figure 2.41.
(b) Similarly, match up a small and large X-ray focal spot with its MTF (1 or
2). Provide a brief explanation for each choice.
Specialized X-ray imaging methods
2.16 In mammographic examinations, the breast is compressed between two
plates. Answer the following with a brief explanation.
(a) Is the geometric unsharpness increased or decreased by compression?
(b) Why is the image contrast improved by this procedure?
(c) Is the required X-ray dose for a given image SNR higher or lower with
compression?
2.17 In digital subtraction angiography, two images are acquired, the ﬁrst before
injection of the contrast agent, and the other post-injection.
m
c 
1
m
c 
1
m
c 
1
s
y
a
r-
X
r
o
tc
e
t
e
d
m
c 
1
3
1
2
F
S
L
1
2
x
kx
1
2
F
T
M
Figure 2.41
See Exercises 2.9 (left) and 2.15 (right).
85
Exercises

(a) Write an expression for the X-ray intensity (I1) in the ﬁrst scan in terms of
I0, ltissue, xtissue, lblood and xvessel, where xtissue and xvessel are the dimen-
sions of the respective organs in the direction of X-ray propagation.
(b) Write a corresponding expression for the X-ray intensity (I2) for the second
scan, replacing lblood with lconstrast
(c) Is the image signal intensity from static tissue removed by subtracting the
two images?
(d) Show that the signal from static tissue is removed by computing the
quantity log(I2)-log(I1).
Computed tomography
2.18 Draw the CT projection obtained from the set-up shown in Figure 2.42.
Assume that the spherical sample has a uniform attenuation coefﬁcient
throughout its volume.
2.19 Considering the effects of beam hardening, draw the actual CT projection
that would be obtained from the object shown in Figure 2.42. Sketch the ﬁnal
sr
otc
ete
d
lellara
p
s
m
a
e
b y
ar-
X
Figure 2.43
See Exercise 2.20.
sr
otc
ete
d
elp
m
a
s
 lellara
p
s
m
a
e
b y
ar-
X
Figure 2.42
See Exercise 2.18.
86
X-ray planar radiography and computed tomography

image that would be formed from ﬁltered backprojection of all of the pro-
jections acquired in a full scan of the sample in Exercise 2.18.
2.20 For the object shown in Figure 2.43, draw the projections that would be
acquired at angles u=0, 45, 90, 135 and 180 (ignore beam hardening).
Sketch the sinogram for values of u from 0 to 360.
LSF
(i)
(iii)
LSF
LSF
a
b
c
(ii)
Figure 2.44
See Exercise 2.21.
a
180
0
360
p(r,   )
b
Figure 2.45
See Exercises 2.22 (a) and 2.23 (b).
87
Exercises

2.21 Shown in Figure 2.44 are three CT images: one represents the reconstructed
image with no ﬁltering, one has been high-pass ﬁltered and the other has been
low-pass ﬁltered. For each image, (a), (b) and (c), state which form of ﬁlter-
ing has been used, and the effects on signal-to-noise, spatial resolution, and
contrast-to-noise of the ﬁltering. Finally, match the image to one of the line
spread functions, (i), (ii), or (iii).
2.22 For the CT image shown in Figure 2.45(a), sketch the sinogram that pro-
duced such an image.
2.23 For the sinogram in Figure 2.45(b), sketch the ﬁltered backprojection image
that would result.
References
[1] Cowen AR, Davies AG and Kengyelics SM. Advances in computed radiography
systems and their physical imaging characteristics. Clinical Radiology 2007;62(12),
1132–41.
[2] Cowen AR, Kengyelics SM and Davies AG. Solid-state, ﬂat-panel, digital
radiography detectors and their physical imaging characteristics. Clinical Radiology
2008;63(5), 487–98.
[3] Cowen AR, Davies AG and Sivananthan MU. The design and imaging characteristics
of dynamic, solid-state, ﬂat-panel X-ray image detectors for digital ﬂuoroscopy and
ﬂuorography. Clinical Radiology 2008;63(10), 1073–85.
[4] Hounsﬁeld GN. Computerized transverse axial scanning (Tomography).1.
Description of system. British Journal of Radiology 1973;46(552), 1016–22.
[5] Flohr T, Stierstorfer K, Ulzheimer S et al. Image reconstruction and image quality
evaluation for a 64-slice CT scanner with z-ﬂying focal spot. Medical Physics
2005:32, 2536–47.
[6] Flohr TG, Bruder H, Stierstorfer K et al. Image reconstruction and image quality
evaluation for a dual source CT scanner. Medical Physics 2008;35(12), 5882–97.
[7] Petersilka M, Bruder H, Krauss B, Stierstorfer K and Flohr TG. Technical principles
of dual source CT. Eur J Radiol 2008 Dec;68(3), 362–8.
[8] Dobbins JT. Tomosynthesis imaging: At a translational crossroads. Medical Physics
2009;36(6), 1956–67.
[9] Dobbins JT, III and McAdams HP. Chest tomosynthesis: Technical principles and
clinical update. Eur J Radiol 2009 Jul 17.
88
X-ray planar radiography and computed tomography

3 Nuclear medicine: Planar
scintigraphy, SPECT
and PET/CT
3.1
Introduction
In nuclear medicine scans a very small amount, typically nanogrammes, of radio-
active material called a radiotracer is injected intravenously into the patient. The
agent then accumulates in speciﬁc organs in the body. How much, how rapidly and
where this uptake occurs are factors which can determine whether tissue is healthy
or diseased and the presence of, for example, tumours. There are three different
modalities under the general umbrella of nuclear medicine. The most basic,
planar scintigraphy, images the distribution of radioactive material in a single two-
dimensional image, analogous to a planar X-ray scan. These types of scan are
mostly used for whole-body screening for tumours, particularly bone and meta-
static tumours. The most common radiotracers are chemical complexes of techne-
tium (99mTc), an element which emits mono-energetic c-rays at 140 keV. Various
chemical complexes of 99mTc have been designed in order to target different
organs in the body. The second type of scan, single photon emission computed
tomography (SPECT), produces a series of contiguous two-dimensional images of
the distribution of the radiotracer using the same agents as planar scintigraphy.
There is, therefore, a direct analogy between planar X-ray/CT and planar scintig-
raphy/SPECT. A SPECT scan is most commonly used for myocardial perfusion,
the so-called ‘nuclear cardiac stress test’. The ﬁnal method is positron emission
tomography (PET). This involves injection of a different type of radiotracer, one
which emits positrons (positively charged electrons). These annihilate with elec-
trons within the body, emitting c-rays with an energy of 511 keV. The PET method
has by far the highest sensitivity of the three techniques, producing high quality
three-dimensional images with particular emphasis on oncological diagnoses.
Within the past ﬁve years PET and CT systems have been integrated such that
all commercial units sold are now combined PET/CT scanners. A PET/CT system
requires a small cyclotron to be situated on-site and therefore only relatively large
hospitals have one, whereas SPECT systems are very widely available and planar
scintigraphy is ubiquitous. There are between 15 and 20 million nuclear medicine
scans performed annually in the USA, with SPECT comprising approximately

75% of the total (of these ~60% are for myocardial perfusion). The number of PET/
CT scans is ~2 million, but has roughly doubled every year for the past ﬁve years.
Figure 3.1 shows the basic form of the gamma camera which is used in both
planar scintigraphy and SPECT. In planar scintigraphy a single gamma camera is
held stationary above the patient. In SPECT either two or three cameras are rotated
slowly around the patient with data collected at each angular increment. Decay of
the radiotracer within the body produces c-rays, a small percentage of which pass
through the body (the vast majority are absorbed in the body). A two-dimensional
collimator (similar to the anti-scatter grid in X-ray imaging) is placed between the
patient and the detector, so that only those c-rays which strike the gamma camera at
a perpendicular angle are detected. A large, single scintillation crystal is used to
convert the energy of the c-rays into light, which is in turn converted into an
electrical signal by high-gain photomultiplier tubes (PMTs). Spatial information
is encoded in the current produced by each PMT via a resistor-based positioning
network, or its digital equivalent in more modern systems. A pulse-height analyzer
is used to reject signals from c-rays that have been Compton scattered in the body
and therefore contain no useful signal. Finally, the signal is digitized and displayed.
Relative to most other imaging modalities, nuclear medicine scans (in particular
planar scintigraphy and SPECT) are characterized as having a poor SNR, low
spatial resolution (~5–10 mm) and slow image acquisition, but extremely high
sensitivity (being able to detect nanograms of injected radioactive material), and
very high speciﬁcity since there is no natural radioactivity from the body. Due to
d
e
tc
ejni r
e
c
a
rt
oid
a
R
t
n
eit
a
p
 
o
t
n
I
V
e
k 
0
4
1
n
oit
allit
nic
S
la
ts
y
r
c
t
h
gil
m
n
 
5
1
4
r
eilpitlu
m
o
t
o
h
P
s
e
b
u
t
 
g
nin
oitis
o
P
k
r
o
w
t
e
n
t
h
gie
h
 
e
slu
P
r
e
z
yla
n
a
t
p
e
c
c
a
r
e
zitigi
D
y
alp
sid
 
e
g
a
m
I
s
y
a
r-
Figure 3.1
The operation of a nuclear medicine gamma camera. The inset shows a SPECT brain scan using
99mTc.
90
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

the intrinsic functional characteristics of the information content of the images,
nuclear medicine is an important complement to MRI, CT and ultrasound.
3.2
Radioactivity and radiotracer half-life
A radioactive isotope is one which undergoes a spontaneous change in the com-
position of the nucleus, termed a ‘disintegration’, resulting in emission of energy.
Radioactivity is given the symbol Q, and is deﬁned as the number of disintegra-
tions per second, or alternatively the time rate of change of the number of radio-
active nuclei. For N nuclei of a particular radioactive isotope, then:
Q 5  dN
dt 5 kN;
ð3:1Þ
where k is deﬁned as the decay constant and has units of s21. Radioactivity is
measured in units of curies (Ci), where one curie equals 3.731010 disintegrations
per second. Historically, this is the number of disintegrations per second from 1
gramme of radium and is named after Pierre Curie. For doses relevant to clinical
nuclear medicine studies, the most common units are millicuries (mCi), 1/1000
of a curie or 3.73107 disintegrations per second. Equation (3.1) can be solved
to give:
NðtÞ 5 N t 5 0
ð
Þekt:
ð3:2Þ
One of the most common measures of radioactivity is the half-life (s1/2), which
is the time required for the radioactivity to drop to one-half of its value, as shown in
Figure 3.2. From Figure 3.2 it is clear that the value of s1/2 is independent of the
No
e
m
it
2/1
No 2/
No 4/
re
c
artoid
ar f
o tn
u
o
m
A
2/1
Figure 3.2
A plot of the amount of two different radiotracers as a function of time. The thin line corresponds to a
radiotracer with a shorter half-life than the one indicated by the thick line. The s1/2 refers to the
radiotracer with the shorter half-life.
91
3.2 Radioactivity and radiotracer half-life

value of N. Since the value of k is also independent of N, s1/2 also corresponds to
the time for the number of radioactive nuclei to drop by half, and so from Equation
(3.2) the value of s1/2 is given by:
s1=2 5 ln 2
k :
ð3:3Þ
In nuclear medicine scans the total radioactive dose experienced by the patient is
limited by federal safely guidelines. To calculate the dose, the biological half-life
of the radiotracer (how long the radiotracer remains in the body) must also be
considered. In many cases, excretion of the radiotracer from tissue is an exponen-
tial decay which can be characterized by a corresponding biological half-life,
s1/2,bio. The effective half-life (s1/2,eff) of the radioactivity within the body is a
combination of the two half-lives and is given by:
s1=2;eff 5
s1=2s1=2;bio
s1=2 1 s1=2;bio
:
ð3:4Þ
Therefore, the value of s1/2,eff is always less than the shorter of the two half-
lives, s1/2 and s1/2,bio.
Example 3.1
Two patients undergo nuclear medicine scans. One receives a dose of radiotracer A
and the other radioatracer B. The half-life of A is 6 hours and of B is 24 hours. If
the administered dose of radiotracer A is three times that of radiotracer B, and the
biological half-lives of A and B are 6 and 12 hours respectively, at what time is the
radioactivity in the body the same for the two patients?
Solution
Mathematically we can solve the following for the time t:
3etkA 5 etkB:
The values of kA and kB can be derived from Equation (3.4) and are 6.42 3 1025
and 2.41 3 1025 s21, respectively. Solving for t gives a value of 7.63 hours.
3.3
Properties of radiotracers for nuclear medicine
The ideal properties of a radiotracer for planar scintigraphy and SPECT include:
(i) A radioactive half-life that is short enough to produce signiﬁcant radioactivity
without requiring a very large initial dose, but not so short that there is
signiﬁcant decay before the required post-injection delay to allow the radio-
tracer to clear the blood and distribute in the relevant organs.
92
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

(ii) Decay should be via emission of a mono-energetic c-ray without emission of
alpha- or beta-particles. A mono-energetic c-ray allows discrimination
between Compton scattered and unscattered c-rays, thereby improving image
contrast. Alpha- or beta-particles are completely absorbed within tissue,
therefore increasing the radioactive dose without giving any useful image
information.
(iii) The energy of the c-ray should be greater than ~100 keV so that a reasonable
proportion of c-rays which are emitted deep within the tissue have sufﬁcient
energy to travel through the body and reach the detector.
(iv) The energy of the c-ray should be less than ~200 keV so that the rays do not
penetrate the thin lead septa in the collimator (which is analogous to the anti-
scatter grid in X-ray imaging).
(v) The radiotracer should have a high uptake in the organ of interest and rela-
tively low non-speciﬁc uptake in the rest of the body. These two factors lower
the required dose for the patient and increase the image contrast, respectively.
The most widely used radiotracer is 99mTc which is involved in over 90% of
planar scintigraphy and SPECT studies. It exists in a metastable state, i.e. one with
a reasonably long half-life (6.02 hours), and is formed from 99Mo according to the
decay scheme
99
42Mo !
s1=2 5 66 hours
0
1b 1 99m
43 Tc !
s1=2 5 6 hours
99g
43 Tc 1 c:
The energy of the emitted c-ray is 140 keV. It is important to note that this is a
mono-energetic emission, unlike the wide spectrum of energies of X-rays pro-
duced by an X-ray source covered in Chapter 2. The on-site generation and use
of 99mTc are discussed in detail in Section 3.4.
Note that c-rays can also be produced via a process termed electron capture, in
which an orbital electron from the K or L shell is ‘captured’ by the nucleus.
Electrons from the outer shells ﬁll the gap in the K or L shell in a cascade process.
The difference in energy between the respective energy levels is released as c-rays
of a characteristic energy. Several useful radiotracers decay via this mechanism:
examples include iodine-123, thallium-201 and indium-111. Table 3.1 lists proper-
ties of the most commonly used radiotracers in nuclear medicine.
3.4
The technetium generator
A technetium generator is delivered to a nuclear medicine department at the begin-
ning of the week, and is returned at the end of the week. It is a very convenient
method for producing 99mTc. An on-site technetium generator comprises an
93
3.4 The technetium generator

alumina ceramic column with radioactive 99Mo absorbed on to its surface in
the form of ammonium molybdate, (NH4)2MoO4. The column is housed within
a lead shield for safety. A schematic and photograph of a Tc-generator are shown
in Figure 3.3. As outlined previously, the 99Mo decays into 99mTc which in turn
decays into 99gTc, the ground state of Tc . At any given time the generator column
contains a mixture of 99Mo, 99mTc and 99gTc. To remove the 99mTc selectively a
vial with physiological saline is placed at the input to the column and a needle and
empty vial at the outlet. The saline is drawn through the column and washes out
most of the 99mTc which does not bind strongly to the column and is eluted in the
form of sodium pertechnetate: roughly 80% of the available 99mTc is eluted
Saline
solution
Vacuum
vial
lead shielding
Figure 3.3
(left) A technetium generator. (right) A commercial technetium generator.
Table 3.1: Properties of common radiotracers used in planar scintigraphy
and SPECT
Radiotracer
Half-life
(hours)
g-ray energy
(keV)
Clinical application
99mTc
6.0
140
various
67Ga
76.8
93, 185, 300, 394
tumour detection
201Tl
72
167, 68–82 (X-rays)
myocardial viability
133Xe
127.2
81
lung ventilation
111In
67.2
171, 245
inﬂammation
94
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

compared to less than 1% of the 99Mo. Appropriate radioassays are then carried out
to determine the concentration and purity of the eluted 99mTc, with Al and 99Mo
impurities required to be below certain safety levels. Typically, the technetium is
eluted every 24 hours, and the generator is replaced once a week. Most nuclear
medicine scans are therefore scheduled for the beginning of a week.
The time-dependence of the radioactivity can be analyzed as a two-step process.
The number of 99Mo atoms, denoted by N1, decreases with time from an initial
maximum value N0 at time t = 0. This radioactive decay produces N2 atoms of
99mTc, which decay to form N3 atoms of 99gTc, the ﬁnal stable product:
99Mo !
k1
99mTc !
k2
99gTc
N1
ð
Þ
N2
ð
Þ
N3
ð
Þ
:
The values of k1 and k2, derived from the respective half-lives, are 2.9231026
s21 and 3.2131025 s21, respectively. The decay of the 99Mo (termed the parent
nucleus) is given by Equation (3.2), N1 5 Noek1t. Since there is a two-step decay
process, the amount of 99mTc increases due to the decay of 99Mo, but decreases due
to its own decay to 99gTc:
dN2
dt
5 k1N1k2N20 dN2
dt
1 k2N2 5 k1N1:
ð3:5Þ
There are a number of methods for solving this simple ﬁrst order differential
equation. For example, the homogeneous and particular equations can be solved:
homogeneous
ð
Þ N2 5 Cek2t
ðparticularÞ N2 5 Dek1t
:
ð3:6Þ
For the particular solution, solving for D gives:
D 5
k1N0
k2  k1
:
ð3:7Þ
Adding together the homogeneous and particular solutions:
N2 5 Cek2t 1
k1N0
k2  k1
ek1t:
ð3:8Þ
Since we know that N2 = 0 at t = 0, using this boundary condition we can solve
for the constant C:
C 5  k1N0
k2  k1
:
ð3:9Þ
95
3.4 The technetium generator

The ﬁnal solution for N2 is therefore:
N2 5
k1N0
k2  k1
ek1t  ek2t


:
ð3:10Þ
The radioactivity, Q2, of 99mTc is therefore given by:
Q2 5 k2N2 5 k1k2N0
k2  k1
ek1t  ek2t


:
ð3:11Þ
As might have been intuitively expected, the radioactivity is proportional to the
difference of two exponentials, one governing the increase in the amount of
99mTc and the other its decay. Figure 3.4 shows that the maximum value of the
radioactivity occurs at ~24 hours, which is therefore the logical time at which the
generator is ﬁrst ‘milked’, i.e. the 99mTc is removed. The radioactivity drops to
zero and then begins to increase again. Maximum levels of radioactivity occur
roughly every 24 hours, which makes it very easy to incorporate into a daily
clinical schedule.
3.5
The distribution of technetium-based radiotracers within the body
The 99mTc eluted from the generator is in the form of sodium pertechnetate,
NaTcO4. This compound is not widely used for nuclear medicine scans, with its
4
2
0
2
1
6
9
8
4
8
6
1
4
4
1
2
7
tc
a
oid
a
R
tivi
f
o
y
m
9
9
c
T
t
sr
u
o
h
/
e
m
i
t
sr
u
o
h
/
e
m
i
4
2
0
2
1
6
9
8
4
8
6
1
4
4
1
2
7
tc
a
oid
a
R
tivi
f
o
y
m
9
9
c
T
Figure 3.4
(left) Theoretical plot of the radioactivity of 99mTc vs time for a generator that is not milked. (right)
Practical radioactivity curve in which the generator is milked every 24 hours, as shown by the dashed
lines.
96
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

most common application being to GI tract bleeding in young children. Further
chemical modiﬁcation is needed to produce the most commonly used radiotracers.
In general, a strong chemical bond must be formed between a chemical ligand and
the Tc ion such that the body is protected from the ‘raw’ metal ion. The ligand must
bind the metal ion tightly so that the radiotracer does not fragment in the body. The
particular ligand is also chosen to have high selectivity for the organ of interest.
General factors which effect the biodistribution of a particular agent include the
strength of the binding to blood proteins such as human serum albumin (HSA), the
lipophilicity and ionization of the chemical ligand (since transport across mem-
branes is fastest for lipophilic and non-ionized species), and the means of excretion
from the body e.g. via the liver or kidneys.
Chemical modiﬁcation is performed using special kits which are provided by
different manufacturers. Two of the most common radiotracers are Ceretec, used
for measuring cerebral perfusion, and Sestamibi, used for evaluation of myocardial
perfusion. The Ceretec kit contains a pre-dispensed freeze-dried mixture of the
ligand exametazime, stannous chloride dihydrate as a reducing agent and 4.5 mg
sodium chloride, sealed under nitrogen atmosphere. When the sodium pertechne-
tate/saline solution from the 99Tc generator is added to the vial of Ceretec, a 99mTc
complex with exametazime is formed which is injected i.v. into the patient within
30 minutes.
3.6
The gamma camera
The gamma camera, shown in Figure 3.5, is the instrumental basis for both planar
scintigraphy and SPECT [1]. The patient lies on a bed beneath the gamma camera,
which is positioned close to the organ of interest. The gamma camera must be
capable of c-ray detection rates of up to tens of thousands per second, should reject
those c-rays that have been scattered in the body and therefore have no useful
spatial information, and must have as high a sensitivity as possible in order to
produce the highest quality images within a clinically acceptable imaging time.
The roles of each of the separate components of the gamma camera are covered in
the following sections.
3.6.1 The collimator
The role of the collimator in nuclear medicine is very similar to that of the anti-
scatter grid in X-ray imaging. Since c-rays from a source of radioactivity within the
body are emitted in all directions, a much higher degree of collimation is required
97
3.6 The gamma camera

in nuclear medicine than in X-ray imaging. This, together with the high attenuation
of c-rays within the body, leads to a very high proportion of emitted c-rays
(.99.9%) not being detected. There are six basic collimator designs: parallel hole,
slanthole, converging, diverging, fan-beam and pinhole. Each has particular prop-
erties in terms of effects on image SNR, CNR and spatial resolution. The parallel
hole collimator is the most common design, and so is described ﬁrst.
(i) Parallel hole collimator. As the name suggests, all the holes in the collimator
are parallel to each other. The collimator is usually constructed from thin strips
of lead in a hexagonally-based ‘honeycomb’ geometry, although round holes
in a hexagonal array can also be used. Ideally there would be zero transmission
of c-rays through the septa themselves, but since this is not possible the septa
are designed so that 95% of c-rays are attenuated. Due to the ﬁnite transmission
of c-rays through the septa, the effective septal length (Leff) is slightly shorter
than the actual physical length (L) of the septa, and is given by:
Leff 5 L 
2
lsepta
:
ð3:12Þ
X+
Y-
Y+
X-
Σ
Multiple channel
pulse height analyzer
Anger resistor
position network
Analogue to digital converter
collimator
scintillation crystal
photomultiplier tubes
Figure 3.5
A gamma camera used for both planar scintigraphy (one camera) and SPECT (two or three rotating
cameras).
98
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

The dimensions and separation of the lead strips also determine the contribution
made by the collimator to the overall spatial resolution of the gamma camera. In
Figure 3.6, if two point sources are located a distance less than R apart they cannot
be resolved. The value of R, the spatial resolution, is given by:
R 5 d Leff 1 z
ð
Þ
Leff
:
ð3:13Þ
An important fact to note from Equation (3.13) is that the spatial resolution of
the image depends upon the depth (z) within the body of the organ in which the
radiotracer source accumulates. Regions of radioactivity closer to the surface
produce a better spatial resolution than those deeper in the body, and this fact
must be taken into account for image interpretation.
Equation (3.13) also shows that the spatial resolution can be improved by
increasing the length of the septa in the collimator, decreasing the septal thickness,
and/or positioning the gamma camera as close to the patient as possible. However,
the values of L and d also affect the collimator efﬁciency, which is deﬁned as the
fraction of c-rays detected divided by the total number emitted (ignoring attenu-
ation in the body). The efﬁciency (g) of the detector is given by:
L
slanthole
converging
converging
diverging
d
t
R
z
Figure 3.6
(left) A parallel hole collimator, with parameters necessary to calculate the spatial resolution, R. The
patient would be positioned at the bottom of the ﬁgure, with the gamma camera at the top. (right) Four
common types of collimator: from top-to-bottom, slanting hole, converging, diverging and pinhole.
99
3.6 The gamma camera

g  K2 d2
L2
eff
d2
d 1 t
ð
Þ2 ;
ð3:14Þ
where the value of K depends upon the particular hole-geometry and has a value
of 0.26 for hexagonal holes in a hexagonal array. It is clear from Equation (3.14) that
there is an intrinsic trade-off between spatial resolution and collimator efﬁciency.
Collimators used for 99mTc imaging are referred to as low-energy (140 keV
c-rays): those with relatively large holes are termed low-energy all-purpose
(LEAP) and those with smaller holes and longer septa are called low-energy
high-resolution (LEHR). Medium energy and high energy collimators have septa
of increasing thickness and are used for 67Ga/111In and 131I, respectively.
(ii) Slanthole collimators consist of parallel septa which are all tilted at the same
angle with respect to the detection crystal. They are used primarily for breast
and cardiac imaging.
(iii) Converging collimators have the holes focused towards the body, with the
centre of curvature ideally located at the middle of the imaging ﬁeld-of-view
(FOV). A converging collimator is used to magnify the image and increase
the spatial resolution.
(iv) A diverging collimator is essentially a converging collimator that has been
turned around. This enables a larger FOV, compared to a parallel hole col-
limator, to be imaged. One application is planar scintigraphy of the whole
body.
(v) Fan-beam collimators are used primarily for brain and heart studies. The two
dimensions of the collimator have different geometries: in the head/foot
direction the holes are parallel, whereas in the radial direction they are similar
to a converging collimator. Thus, these types of collimator provide image
magniﬁcation over a reduced FOV.
(vi) Pinhole collimators are used for imaging very small organs such as the thyroid
and parathyroid. These collimators have a single hole with interchangeable
inserts that come with a 3, 4 or 6 mm aperture. A pinhole collimator produces
an image with signiﬁcant magniﬁcation and higher spatial resolution, but also
produces geometric distortion, particularly at the edges of the image.
3.6.2 The detector scintillation crystal and coupled photomultiplier tubes
c-rays not attenuated in the body are detected using a scintillation crystal which
converts their energy into light. In the gamma camera, the detector is a large single
crystal of thallium-activated sodium iodide, NaI(Tl), approximately 40–50 cm
100
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

diameter. When a c-ray strikes the crystal, it loses energy through photoelectric
and Compton interactions which result in a population of excited electronic states
within the crystal. De-excitation of these states occurs ~230 nanoseconds later via
emission of photons with a wavelength of 415 nm (visible blue light), correspond-
ing to a photon energy of ~4 eV. A very important characteristic of scintillators
such as NaI(Tl) is that the amount of light (the number of photons) produced is
directly proportional to the energy of the incident c-ray.
Sodium iodide is chosen for a number of reasons: (i) it has a high linear attenu-
ation coefﬁcient of 2.22 cm21 at 140 keV , (ii) it is efﬁcient with one light photon
produced per 30 eV of energy absorbed, an efﬁciency of ~15%, (iii) it is trans-
parent to its own light emission at 415 nm and so little energy is lost due to
absorption, (iv) large circular or rectangular crystals can be grown easily and
inexpensively, and (v) the 415 nm emission wavelength is well-matched to the
optimal performance of conventional photomultiplier tubes (PMTs). The only
disadvantage of a NaI(Tl) crystal is that it is hygroscopic (absorbs water) and so
must be hermetically sealed, therefore also making it quite mechanically fragile.
The thickness of the crystal involves the same trade-off between spatial reso-
lution and sensitivity as for a DR detector in planar X-ray imaging: the thicker the
crystal the broader is the light spread function and the lower the spatial resolution,
but the greater the number of c-rays detected and the higher the SNR. For imaging
with 99mTc or 201Tl, the optimal crystal thickness is ~6 mm. However, although the
vast majority of nuclear medicine scans use 99mTc, the gamma camera is also used
for other radiotracers such as 68Ga, 131I and 111In which emit higher c-ray energies
and require a thicker crystal, and so a compromise crystal thickness of 1 cm is
generally used. Figure 3.7 shows rectangular NaI(Tl) crystals produced commer-
cially for gamma cameras, as well as the steep drop-off in the value of l as a
function of c-ray energy for such crystals.
For every c-ray that hits the scintillation crystal a few thousand photons are
produced, each with a very low energy of a few electronvolts. These very low light
signals need to be ampliﬁed and converted into an electrical current that can be
digitized: PMTs are the devices used for this speciﬁc task. The basic design of a
PMT is shown in Figure 3.8. The inside surface of the transparent entrance window
of the PMT is coated with a material such as caesium antimony (CsSb) which
forms a photocathode. Free electrons (photoelectrons) are generated via photo-
electric interactions when the photons from the scintillation crystal strike this
material. These electrons are accelerated towards the ﬁrst stage of ampliﬁcation,
a metal plate termed a dynode held at a voltage of +300 volts with respect to the
photocathode. This plate is also coated with a bialkali material such as CsSb. When
the electrons strike this dynode several secondary electrons are emitted for every
incident electron: a typical ampliﬁcation factor is between 3 and 6. A series of
101
3.6 The gamma camera

eight to ten further accelerating dynodes, each at a voltage of +100 volts with
respect to the previous one, produces between 105 and 106 electrons for each initial
photoelectron, creating an ampliﬁed current at the output of the PMT. A high
voltage power supply is required for each PMT, in the range 1–2 kV. The PMTs
are sealed in glass, and the entire enclosure evacuated to reduce attenuation of
the electrons between the dynodes: a photograph of a single PMT is shown in
Figure 3.8.
Since each PMT has a diameter of 2–3 cm, and the NaI(Tl) crystal is much larger
in size, a number of PMTs are closely coupled to the scintillation crystal. The most
efﬁcient packing geometry is hexagonally-close-packed, which also has the prop-
erty that the distance from the centre of one PMT to that of each neighbouring
PMT is the same: this property is important for determination of the spatial location
of the scintillation event using an Anger position network, as covered in the
following section. Arrays of 61, 75 or 91 PMTs are typically used, with a thin
optical coupling layer used to interface the surface of each PMT with the scintil-
lation crystal. Each PMT should ideally have an identical energy response, i.e. the
output current for a given c-ray energy should be the same. If this is not the case,
then artifacts are produced in the image. For planar nuclear medicine scans, a
variation in uniformity of up to 10% can be tolerated; however, for SPECT imag-
ing, covered later in this chapter, this value should be less than 1%. In practice,
calibration of the PMTs is performed using samples of uniform and known radio-
activity, and automatic data correction algorithms can then be applied to the data.
More recently, continuous monitoring of individual PMTs during a nuclear
0
100
200
300
400
500
600
0
2
4
6
8
10
12
14
16
18
20
-ray energy (keV)
Mass attenuation 
coefficient (cm2g-1)
Figure 3.7
(left) Commercially produced crystals of NaI(Tl). (right) Plot of the mass attenuation coefﬁcient for
NaI(Tl) vs. c-ray energy, showing an approximately exponential decrease with increasing energy.
102
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

medicine scan has become possible using a light-emitting diode (LED) calibration
source for each PMT.
Example 3.2
The linear attenuation coefﬁcients for a NaI(Tl) crystal for the radiotracer elements
99mTc,68Ga, 131I and 111In are 2.2, 1.7, 1.3 and 1.2 cm21, respectively. For 6 mm
and 1 cm thickness crystals, calculate the relative signal intensities for each
radiotracer element.
Solution
The relative values can be calculated as (1-e2lx), noting that the signal intensities
are proportional to the number of c-rays absorbed and not passing through the
crystal. If we take values relative to 1, corresponding to all of the c-rays being
absorbed, this gives values of: (6 mm crystal) 0.73, 0.64, 0.54 and 0.51, (1 cm
crystal) 0.89, 0.82, 0.73 and 0.7. Note the greater proportional increase in
sensitivity for the higher energy radionuclides for the 1 cm thickness crystal
compared to the 6 mm.
3.6.3 The Anger position network and pulse height analyzer
Whenever a scintillation event occurs in a NaI(Tl) crystal the PMT closest to the
scintillation event produces the largest output current. If this were the only method
hv
photocathode
dynode 1
dynode 2
dynode 3
Crystal
Figure 3.8
(left). The ﬁrst three ampliﬁcation stages in a PMT tube. (right) A commercial PMT.
103
3.6 The gamma camera

of signal localization, then the spatial resolution would be no ﬁner than the dimen-
sions of the PMT, i.e., several cm. However, adjacent PMTs produce smaller
output currents, with the amount of light detected being approximately inversely
proportional to the distance between the scintillation events and the particular
PMT. By comparing the magnitudes of the currents from all the PMTs, the location
of the scintillation within the crystal can be much better estimated. In older ana-
logue gamma cameras this process was carried out using an Anger logic circuit,
which consists of four resistors connected to the output of each PMT, as shown in
Figure 3.9. This network produces four output signals, X+, X2, Y+ and Y2 which
are summed for all the PMTs. The relative magnitudes and signs of these summed
signals then deﬁne the estimated (X,Y) location of the scintillation event in the
crystal given by:
X 5 Xþ  X
Xþ þ X ; Y 5 Yþ  Y
Yþ þ Y :
ð3:15Þ
In more recent digital cameras, the currents for all the PMTs are stored and
position estimation is performed using computer algorithms after all the data have
been acquired. Corrections for non-uniform performance of each PMT can easily
be built into the digital system.
3
2
1
7
6
5
4
1
9
8
1
0
1
1
2
1
1
3
1
4
1
5
6
1
1
7
1
8
9
Y+
RY+
Y-
X-
X+
RX+
RX-
RY-
X
Y
Figure 3.9
(left) Nineteen PMTs in a hexagonal arrangement on an NaI(Tl) crystal. (right) The four-resistor network
attached to each PMT.
104
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

Pulse height analyzer
In addition to recording the individual components X+, X2, Y+ and Y2, the
summed signal R(X++X2+Y++Y2), termed the ‘z-signal’, is sent to a pulse-height
analyzer (PHA). The role of the PHA is to determine which of the recorded events
correspond to c-rays that have not been scattered within tissue (primary radiation)
and should be retained, and which have been Compton scattered in the patient,
do not contain any useful spatial information, and so should be rejected. Since
the amplitude of the voltage pulse from the PMT is proportional to the energy of
the detected c-ray, discriminating on the basis of the magnitude of the output of the
PMT is equivalent to discriminating on the basis of c-ray energy. A multiple-
channel analyzer (MCA), in which the term ‘channel’ refers to a speciﬁc energy
range, uses an analogue-to-digital converter to digitize the signal, and then to
produce a pulse-height spectrum, i.e. a plot of the number of events from the PMTs
as a function of the output voltage level. The number of channels in an MCA can
be more than a thousand, allowing essentially a complete energy spectrum to be
produced, as shown in Figure 3.10. After digitization, the upper and lower thresh-
old values for accepting the c-rays are applied.
At ﬁrst sight it might seem that only a single threshold voltage equivalent to a
140 keV c-ray which passes directly through tissue to the detector without scatter-
ing would sufﬁce. However, c-rays which have been scattered by only a very small
angle still have useful information and so should be recorded. In addition, there are
non-uniformities in the response of different parts of the NaI(Tl) crystal, and
similarly with the PMTs, both of which will produce a range of output voltages
0
4
1
0
0
1
stn
u
o
c e
vitale
R
)
V
e
k
( y
g
re
n
e y
ar-
Figure 3.10
Readout from a multi-channel analyzer showing the number of counts recorded from a patient as a
function of c-ray energy. The dashed lines show the energy resolution of the camera, deﬁned as the
FWHM of the main photopeak centred at 140 keV.
105
3.6 The gamma camera

even from mono-energetic c-rays. Compton scattering of the c-rays within the
scintillation crystal itself also causes small and variable reductions in c-ray energy.
The energy resolution of the system is deﬁned as the full-width-half-maximum
(FWHM) of the photopeak, shown in Figure 3.10, and typically is about 14 keV (or
10%) for most gamma cameras without a patient present. The narrower the FWHM
of the system the better it is at discriminating between unscattered and scattered
c-rays. In a clinical scan with the patient in place, the threshold level for accepting
the ‘photopeak’ is set to a slightly larger value, typically 20%. For example, a 20%
window around a 140 keV photopeak means that c-rays with values of 127 to 153
keV are accepted.
3.6.4 Instrument dead time
If an injected dose of radiotracer is very large, the total number of c-rays striking
the scintillation crystal can exceed the recording capabilities of the system: this is
particularly true at the beginning of a clinical scan when radioactivity is at its
highest level. This limitation is due to the ﬁnite recovery and reset times required
for various electronic circuits in the gamma camera. There are two types of
behaviour exhibited by the system components, termed ‘paralysable’ and ‘non-
paralysable’. Paralysable behaviour is a phenomenon in which a component of the
system cannot respond to a new event until a ﬁxed time after the previous one,
irrespective of whether that component is already in a non-responsive state. For
example, each time a c-ray strikes the scintillation crystal it produces an excited
electronic state, which decays in 230 ns to release a number of photons. If another
c-ray strikes the same spot in the crystal before the excited state decays, then it will
take a further 230 ns to decay, and only one set of photons will be produced even
though two c-rays have struck the crystal. A very high rate of c-rays striking the
detector, therefore, can potentially result in a considerably elongated dead-time. If
the radioactivity level is very high, then this instrument ‘dead time’ becomes
longer, and so the number of recorded events can actually decrease. In contrast,
non-paralysable components cannot respond for a set time, irrespective of the level
of radioactivity. For example, the Anger logic circuit and PHA take a certain time
to process a given electrical input signal, and during this time any further events are
simply not recorded: this time is ﬁxed, and is not elongated if further scintillation
events occur. Usually the overall ‘dead-time’ (s) of the system is determined by the
latter non-paralysable components, and is given by:
s 5 N  n
nN ;
ð3:16Þ
106
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

where N is the true count rate (number of scintillations per second), and n is the
measured count rate. The maximum measurable count rate is given by 1/s.
Corrections for the dead-time are based upon calibrations using phantoms of
known radioactivity, and also independent electronic measurements of the dead
time of individual components of the system. For example, Figure 3.11 shows a
plot of measured count rate vs radioactivity from a calibrated source showing the
asymptotic behaviour described by Equation (3.16). Experimentally, this type of
curve can be produced by imaging a source with known radioactivity, and
acquiring images at different time points as the source radioactivity decays (data
points on the right of the graph at high count rates are acquired at the beginning
of this experiment). This gives a calibration curve for correcting the acquired
images.
Example 3.3
Suppose that the true count rate in a gamma camera is 10 000 per second, but the
measured rate is only 8000 per second. What is the dead time of the system?
Solution
From Equation (3.16) the value of s is given as 25 ls. So rather than acquiring one
count every 100 ls (the true value), there is a 25 ls effective delay and one event is
recorded every 125 ls.
d
e
r
u
s
a
e
m
e
t
a
r t
n
u
o
c
ytivitc
a
oid
a
R
d
e
t
alo
p
a
rtx
e
e
t
a
r 
e
u
rt
e
t
a
r t
n
u
o
C
Figure 3.11
Correction curve used to account for dead time losses. At very low count rates, the true rate and
measured count rate are linearly related. As the radioactivity increases, the measured count rate
reaches an asymptotic value, well below the true value.
107
3.6 The gamma camera

3.7
Image characteristics
Planar scintigraphy scans have no background signal since there is no natural c-ray
emission from the body, and therefore the images have a high intrinsic contrast.
However, a large proportion of emitted c-rays are scattered in the body and, if not
removed, would result in a signiﬁcant random background signal which would
reduce the image contrast. Therefore quite severe collimation is required, which
reduces the number of recorded events well below that of planar X-rays, for
example, and therefore the SNR is much lower. Collimation also introduces sig-
niﬁcant depth-dependent broadening, Equation (3.13), and the requirement for
low-pass ﬁltering of the images due to the low SNR further degrades the spatial
resolution.
Signal-to-noise
Since radioactive decay is a statistical process, in the sense that the spatial distri-
bution of radioactivity at any one time does not have a single value but an average
one with associated standard deviation according to the Poisson distribution (Sec-
tion 2.8.1), the image SNR is proportional to the square root of the total number of
detected c-rays. This is exactly the same situation as for X-ray imaging. Factors
that affect the SNR include:
(i) The amount of radiotracer administered, the time after administering the
radiotracer at which imaging begins, the amount of radiotracer that accumu-
lates in the organ being imaged, and the total time of the scan. Organs that are
deep within the patient, or on the opposite side to the planar detector will
experience more tissue attenuation of the c-rays, and therefore lower SNR,
than organs closer to the detector.
(ii) The intrinsic sensitivity of the gamma camera. Since parameters that affect the
SNR such as the crystal thickness are ﬁxed, the only factors that can be
changed are the collimator properties (septal length, thickness and separation)
and geometry (parallel, pinhole, converging or diverging).
(iii) Post-acquisition image ﬁltering – due to the relatively low SNR of nuclear
medicine images, a low-pass ﬁlter is often applied to the image (see Section
1.6). This ﬁlter increases the SNR but blurs the image, reducing the spatial
resolution. The properties of the ﬁlter must be chosen carefully to maximize
the CNR.
Spatial resolution
The spatial resolution of the image is given by the combination of two major
instrument components:
108
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

Rsystem 5
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
R2
gamma 1 R2
coll
q
;
ð3:17Þ
where Rgamma is the intrinsic spatial resolution of the gamma camera and Rcoll is
determined by the collimator geometry. Contributions to Rgamma include the uncer-
tainty in the exact location at which light is produced in the scintillation crystal,
determined by the thickness of the crystal, and also the intrinsic resolution of the
Anger position encoder (either analogue or digital). A typical value of Rgamma lies
in the range 3–5 mm. The contribution from Rcoll depends upon the collimator type
and also the depth within the body of the organ in which the radiotracer accumu-
lates, as seen in Equation (3.13). Typical values for the overall system spatial
resolution are approximately 1–2 cm at large depths within the body, and 5–8
mm close to the collimator surface.
Contrast and contrast-to-noise
The theoretical image contrast is extremely high in nuclear medicine since there is
no background signal from tissues in which the radiotracer has not distributed.
However, the presence of Compton scattered c-rays produces a random back-
ground signal, with more scatter close to regions in which the radiotracer concen-
trates. Factors affecting the spatial resolution also affect the contrast through the
‘partial volume’ effect, in which image blurring causes signal ‘bleed’ from small
areas of high signal intensity to those where no radiotracer is present. The param-
eters for low pass ﬁltering of the ﬁnal image must be chosen carefully since there is
a compromise between too strong a ﬁlter reducing the contrast due to image blur
and too weak a ﬁlter not reducing the noise sufﬁciently.
3.8
Clinical applications of planar scintigraphy
Over the past 20 years, the role of nuclear medicine in the clinic has changed
signiﬁcantly. For example, previous brain scanning has largely been replaced by
PET, CT and MRI, and ventilation/perfusion scans are now largely performed
using multi-detector CT for evaluating pulmonary embolism. The major clinical
application of planar scintigraphy is whole-body bone scanning which constitutes
about 20% of all nuclear medicine scans. In addition, the thyroid, gastrointestinal
tract, liver and kidneys are scanned using planar scintigraphy with specialized
agents. For example, 99mTc can be attached to small particles of sulphur colloid,
less than 100 nm diameter, which concentrate in healthy Kupffer cells in the liver,
spleen and bone marrow. Pathological conditions such as cirrhosis of the liver
result in diseased Kupffer cells which can no longer uptake the radiotracer, and
therefore areas of low signal intensity, ‘cold spots’, are present in the image.
109
3.8 Clinical applications of planar scintigraphy

Bone scanning and tumour detection
Whole body scanning using 99mTc phosphonates such as hydroxymethylene-
diphosphonate (HMDP, trade name Osteoscan) can be used to detect bone
tumours, and also soft-tissue tumours which cause deformation and remodeling
of bone structure. The mode of concentration of these agents in bone is thought to
involve the afﬁnity of diphosphonate for the metabolically active bone mineral
hydroxyapatite, which exhibits increased metabolic turnover during bone growth.
The usual response of bone to a tumour is to form new bone at the site of the
tumour. For example, spinal tumours, which consist of metastatic lesions growing
in the spinal marrow space, cause the bone structure of the spine to remodel. This
results in local uptake of the radiotracer. Scanning starts 2–3 hours after injection
of the radiotracer into a patient’s bloodstream to allow accumulation within the
skeletal structure, and several scans with longitudinal overlap are used to cover the
whole body, as shown in Figure 3.12. If any suspected tumours are detected, then
further localized scans can be acquired. Bone infarctions or aggressive bone meta-
stases often show up as signal voids in the nuclear medicine scan, since bone
necrosis has occurred and there is no blood ﬂow to deliver the radiotracer to that
region.
Other radiotracers which can be used in tumour detection are 67Ga-citrate and
201Tl. Radiotracer ligands can also be designed for active targetting of speciﬁc
tumours which are known to express certain receptors. For example, 111In-DTPA-
octreotide has been designed to target tumours which over-express somatostatin
receptors.
3.9
Single photon emission computed tomography (SPECT)
SPECT uses two or three gamma cameras which rotate around the patient detecting
c-rays at a number of different angles. Either ﬁltered backprojection or iterative
techniques are used to reconstruct multiple two-dimensional axial slices from the
acquired projections. The relationship between planar scintigraphy and SPECT is
analogous to that between planar X-ray imaging and CT. SPECT uses essentially
the same instrumentation and many of the same radiotracers as planar scintigraphy,
and most SPECT machines can also be used for planar scans. The majority of
SPECT scans are used for myocardial perfusion studies to detect coronary artery
disease or myocardial infarction, although SPECT is also used for brain studies to
detect areas of reduced blood ﬂow associated with stroke, epilepsy or neurodege-
nerative diseases such as Alzheimers.
Since the array of PMTs is two-dimensional in nature, the data can be recon-
structed as a series of adjacent slices, as shown in Figure 3.13. A 360 rotation is
110
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

generally needed in SPECT since the source-to-detector distance affects the dis-
tribution of c-ray scatter in the body, the degree of tissue attenuation and also the
spatial resolution, and so projections acquired at 180 to one another are not
identical. A converging collimator is often used in SPECT to increase the SNR
of the scan. In a SPECT brain scan each image of a multi-slice data set is formed
from typically 500 000 counts, with a spatial resolution of ~7 mm. Myocardial
SPECT has a lower number of counts, typically 100 000 per image, and a spatial
resolution about twice as coarse as that of the brain scan (since the source to
detector distance is much larger due to the size of the body).
Figure 3.12
A whole-body scan, made from a composite of ten different scans, showing the uptake of 99mTc-
methylenediphosphonate within the body. The faint background is due to Compton-scattered c-rays.
111
3.9 Single photon emission computed tomography (SPECT)

3.10
Data processing in SPECT
Before the process of image reconstruction, the data must be corrected for a
number of instrument variabilities, as well as intrinsic factors such as scatter and
depth-dependent attenuation.
3.10.1 Scatter correction
A feature of SPECT imaging is that it is able to acquire fully quantitative images in
which the image intensity can be related to an absolute concentration of radiotracer
for detailed pharmacokinetic analysis, if needed. However, fully quantitative
assessment requires accurate correction of image intensities. The ﬁrst step in data
processing is scatter correction. Since the accepted range of energies for the 99mTc
Figure 3.13
(top left) A three-head rotating gamma camera SPECT system for imaging the torso. (top right)
Multiple 2D slices can be acquired in the longitudinal direction. (bottom) A 2-head SPECT camera: the
heads can be moved inwards to image the brain, or outwards for the body.
112
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

photopeak is 127–153 keV (an energy resolution of 20%), it is easy to calculate
that a 140 keV c-ray that has been Compton scattered by a very large angle, up to
50, is also detected within this energy window. The contribution from scattered
c-rays is typically of the same order as those which have not been scattered, even
with the lead collimator in place. The number of scattered c-rays is greatest closest
to areas in which there is a high concentration of radiotracer, and so a position
dependent scatter correction is required. The most common method uses a dual-
energy, or multiple-energy, window and a multi-channel analyzer. The primary
window is centred at the photopeak, with a second ‘subwindow’ set to a lower
energy range, for example 92–125 keV, as shown in Figure 3.14. The primary
window contains contributions from both scattered and unscattered c-rays, but the
subwindow should have contributions only from scattered c-rays. Data projections
are now formed from the primary and secondary windows separately, and the
scatter projections are scaled by a scaling factor before being subtracted from
the primary projections. The scaling factor is given by Wm/2Ws, where Wm is
the width of the primary window (26 keV) and Ws that of the secondary window
(33 keV): the factor of 2 in the denominator is one that has been determined
empirically. A triple-energy window (TEW) approach can also be used, in which
the main photopeak typically has a width of 15% centred at 140 keV and the two
subwindows are very narrow, each 3 keV wide centred at 126 and 153 keV,
respectively. This is also shown in Figure 3.14. The data processing procedure
is to divide the counts in each pixel of the scatter projections by the width in keV of
the scatter window, add the two scatter window projections together, multiply the
0
4
1
0
0
1
0
4
1
0
0
1
stn
u
o
c e
vitale
R
)
V
e
k
( y
g
re
n
e y
ar-
3
5
1
-
7
2
1
5
2
1
-
2
9
stn
u
o
c e
vitale
R
)
V
e
k
( y
g
re
n
e y
ar-
5.7
2
1
-
5.4
2
1
5.0
5
1
-
5.9
2
1
5.4
5
1
-
5.1
5
1
Figure 3.14
Two methods of scatter correction for SPECT. (left) A dual-energy window approach, and (right) a
triple-energy window approach.
113
3.10 Data processing in SPECT

resultant projections by half of the photopeak window width in keV, and ﬁnally
subtract the result from the original projections.
3.10.2 Attenuation correction
Since c-raysfrom radiotracers located in the centre of the patient have to pass through
more tissue to reach the detector than those present in organs much closer to the
surface, the c-rays from deeper within the body are attenuated more. Therefore, some
form of attenuation correction is required for accurate quantitation. Attenuation
correction can be performed using one of two methods. The ﬁrst, known as Chang’s
multiplicative method, assumes that the tissue attenuation coefﬁcient is uniform
throughout the part of the body being imaged. An initial image is formed by ﬁltered
backprojection without any corrections, and this image is used to estimate the
outline of the body part being imaged and therefore the distance (x) that the c-rays
have to travel through tissue to the detector. Each projection can then be scaled up
by an appropriate factor given by e+lx. A schematic example of this process is
shown in Figure 3.15. The assumption of a uniform attenuation coefﬁcient works
reasonably well for the brain and abdomen, but cannot be used for cardiac or
thoracic imaging in which tissue attenuation is highly spatially dependent.
The second technique uses a transmission scan, usually acquired simultaneously
with the actual patient scan, with a source containing radioactive gadolinium
(153Gd) which emits c-rays with an energy of ~102 keV. The half-life of 153Gd
is 242 days and so the radioactivity can be assumed to be constant over several
Uncorrected image
Attenuation correction 
factor map
Corrected image
Figure 3.15
Demonstration of Chang’s multiplicative method for attenuation correction. (left) An uncorrected
SPECT image of a sphere which is ﬁlled with a material with uniform radioactivity. The dark area in the
middle occurs since c-rays are attenuated as they pass through the material. (middle) Based upon the
outline of the phantom, a correction factor map is produced, with a high scaling factor at the centre
and lower scaling factor to the outside. (right) Application of the correction factor gives an image which
reﬂects much more accurately the uniform distribution of radiotracer.
114
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

months. Since the energy of the Gd is much lower than that of the 99mTc c-rays,
dual energy windows can be used to acquire both 153Gd and 99mTc data at the same
time. Clearly there will be some ‘bleedthrough’ from scattered c-rays from 99mTc
to the 153Gd window, but this can be corrected by using a third window in-between
the other two and using methods described previously for scatter correction. By
comparing the signal intensities of each 153Gd projection taken with the patient in
place with reference scans acquired without the patient, the attenuation coefﬁcient
at each position can be calculated and the image of the patient corrected.
3.10.3 Image reconstruction
Two methods can be chosen to reconstruct SPECT images, either ﬁltered backpro-
jection or iterative methods, the latter of which are increasingly being used as
computational power increases. Filtered backprojection algorithms are essentially
identical to those described previously for CT, and so are not described further here.
The general scheme for iterative reconstruction is shown in Figure 3.16. It starts
with an initial image estimate, which can be a very simple geometric shape. The
forward projection step computes projections from the estimated image, and
e
t
a
m
its
e
 
e
g
a
m
I
d
r
a
w
r
o
f
n
oitc
ejo
r
p
m
a
r
g
o
nis 
d
e
t
alu
cla
C
h
ti
w
 
e
r
a
p
m
o
c
m
a
r
g
o
nis 
d
e
r
u
s
a
e
m
d
e
t
alu
cla
C
n
oitc
n
u
f ts
o
c
n
a
h
t s
s
e
L
?
e
ula
v 
e
c
n
e
g
r
e
v
n
o
c
s
e
Y
e
g
a
m
i t
p
e
c
c
A
e
t
a
m
its
e
o
N
e
t
a
d
p
u
 
e
t
alu
cla
C
n
oitc
n
u
f
m
i 
e
h
t tc
e
rr
o
c
e
t
a
m
its
e
 
e
g
a
n
oitc
n
u
f 
e
t
a
d
p
u
 
h
ti
w
Figure 3.16
An iterative reconstruction algorithm for SPECT. The algorithm loops around until the calculated cost
function falls below a pre-deﬁned threshold value.
115
3.10 Data processing in SPECT

assembles them into a sinogram. During this process, estimates of the distribution
of scattered c-rays, spatially-dependent attenuation and a depth-dependent point
spread function can be built into the forward model. The sinogram is then com-
pared with the one that is actually acquired, and the difference between the two is
calculated as a cost function. This cost function can be a simple sum-of-squares
difference between the actual and predicted data on a pixel-by-pixel basis, or can
weight more heavily the areas of the sinogram which have the highest signal
intensity. Based upon the cost function the estimated data are now updated to
improve the similarity between actual and estimated data. There are a number of
possible update functions, and the appropriate choice is an active area of mathe-
matical development. Since there is never perfect agreement between the measured
and estimated sinograms, a lower threshold value of the cost function, which is
determined to be acceptable, is deﬁned (alternatively the total number of iterations
can be given a maximum value). At each stage of the iteration, this calculated cost
function is compared with this threshold. If it is above the threshold, i.e. the
reconstruction is not ‘good enough’, then the estimated image is recalculated using
an update function based upon the error. Iterative reconstruction is a very computa-
tionally intensive process, and there are a number of methods that have been
devised to speed it up. One general class is termed ‘ordered subsets’, in which
the early iterative stages use only a small subset of the acquired proﬁles, with this
number increasing to the full amount as the iteration progresses. The most common
algorithm used is referred to as the maximum-likelihood expectation-maximum
(ML-EM) method.
3.11
SPECT/CT
Since 2005 there has been an increasing trend to combine SPECT with CT in a
combinedscanner[2;3]. In 2008 there were approximately 1000 SPECT/CT systems
installed worldwide. A SPECT/CT system acquires data from the two image modal-
ities with a single integrated patient bed and gantry. The two imaging studies are
performed with the patient remaining on the table, which is moved from the CT
scanner to the SPECT system, as shown in Figure 3.17. Typical clinical systems use
a two-head SPECT camera with a multi-slice CT scanner. The primary advantages
of a combined SPECT/CT over a stand-alone SPECT system are: (i) improved
attenuation correction for SPECT reconstruction using the high resolution anatom-
ical information from the CT scanner, and (ii) the fusion of high-resolution anatom-
ical (CT) with functional (SPECT) information, allowing the anatomical location of
radioactive ‘hot’ or ‘cold’ spots to be deﬁned much better with reduced partial
volume effects compared to SPECT alone. In terms of the advantages of CT-based
116
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

attenuation correction vs. 153Gd transmission scans, the CT data have a far higher
SNR, they can be acquired much more quickly, there is no cross-talk between X-rays
and c-rays, and the CT source has a constant ﬂux over time whereas the 153Gd
source decays slowly. The only disadvantage is that the scans are acquired serially
rather than simultaneously, which can potentially lead to misregistrations between
SPECT data and the CT-derived attenuation maps if the patient moves position.
3.12
Clinical applications of SPECT and SPECT/CT
As outlined earlier, the major application of SPECT is to cardiac studies. Given
this focus, specialized instrumentation speciﬁcally for rapid cardiac scanning is
being introduced, as covered later in this section.
3.12.1 Myocardial perfusion
The most important application of SPECT is for assessing myocardial perfusion to
diagnose coronary artery disease (CAD) and damage to the heart muscle following
an infarction (a heart attack). CAD is one of the major causes of death in the
western world. Atherosclerosis can cause hardening and narrowing of the coronary
arteries, or else atherosclerotic plaques can build up within the artery wall, causing
clots and a reduction in the blood ﬂow to heart muscle. Patients with known high
risk factors or who have chest pain and/or abnormal EKG recordings often are
referred for a ‘nuclear cardiac stress test’. The most common agent used in these
SPECT
CT
Figure 3.17
(left) A SPECT/CT system using a shared bed for the patient. (right) A commercial system. There
are two gamma cameras, one above and one below the patient, and a circular entry for the
multi-detector CT.
117
3.12 Clinical applications of SPECT and SPECT/CT

studies is 99mTc-sestamibi (trade name cardiolite), the structure of which is shown
in Figure 3.18. Since this compound has a positive charge, it accumulates in the
mitochondria in heart muscle. The organic side-chains of the molecule are
designed so that the complex is of intermediate lipophilicity. Although other
agents such as 201Tl can also be used for these tests, 99mTc is increasingly being
used primarily due to a lower administered radioactive dose.
Figure 3.18 shows a block diagram of the protocol for the stress test. The ﬁrst
stage involves injecting a relatively low dose, ~8 mCi, of radiotracer while the
patient is exercising on a stationary bicycle or treadmill. Exercise continues for
about a minute after injection to ensure clearance of the tracer from the blood.
Uptake of the radiotracer is proportional to local blood ﬂow, with about 5% of the
dose going to the heart. Exercise increases the oxygen demand of the heart causing
normal coronary arteries to dilate, with blood ﬂow increasing to a value typically
three to ﬁve times greater than that at rest, with uniform uptake of the radiotracer
within the left ventricular myocardium. If the coronary arteries are blocked,
however, they cannot dilate and so the blood ﬂow cannot increase sufﬁciently to
satisfy the oxygen demand of the heart, and this shows up as an area of low signal
intensity on the SPECT scan. The results of this ﬁrst SPECT scan are compared
with one acquired at rest, which is typically acquired much later in the day.
Figure 3.19 shows a series of short-axis slices from a myocardical SPECT scan,
along with a schematic of the heart which shows the orientation of the images. The
multi-slice data can be reconstructed and displayed as oblique-, long- or short-axis
Exercise
99mTc-sestamibi
1 min
Rest
SPECT scan
30 mins
15-30 mins
...............
SPECT
rest scan
15-30 mins
Figure 3.18
(top) Chemical structure of 99mTc-sestamibi, which is used in the majority of myocardial perfusion
scans. (bottom) The scanning protocol for the nuclear medicine cardiac stress test.
118
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

views of the heart, greatly aiding diagnosis. A cardiac SPECT system typically has
only two rotating gamma cameras, with the detectors oriented at 90 to one
another. Only a 180 rotation is used to form the image since the heart is positioned
close to the front of the thorax and well to the left of the body.
A SPECT myocardial perfusion protocol can take up to 21/2 hours of procedure
time, including half-an-hour for scanning. Since this type of perfusion scan is so
prevalent, a few specialized cardiac SPECT systems have been designed to reduce
this imaging time signiﬁcantly, and also to improve the spatial resolution of the
scans. One approach, called dSPECT (dynamic SPECT) uses a detector placed over
and to one side of the chest with nine solid state cadmium zinc telluride (CZT)
detectors rather than the conventional NaI(Tl) crystal. CZT has signiﬁcantly better
energy resolution than NaI(Tl) and also a higher attenuation coefﬁcient, although it
cannot be made into detectors as thick as a NaI(Tl) crystal. The set-up, shown in
Figure 3.20, also allows the patient to sit up rather than lie down, which reduces
patient motion. A second set-up, termed a CardiArc system, uses the same solid state
CZT detectors (although NaI(Tl) can also be used), but has a very large semi-circular
array of these detectors, each of which are ~2.5 mm in size. All of the signal
LCA
RCA
1
2
Figure 3.19
(left) Structure of the heart showing the right coronary artery (RCA) and left coronary artery (LCA).
Arrow 1 shows one common site of vessel occlusion, whereas the areas (2) indicated by the small
arrows are often associated with myocardial infarction. (right) The top row shows SPECT scans
acquired in the planes indicated on the schematic of the heart. The acquired data can be reformatted
to be shown in any direction, as shown in the two lower sets of images which represent two planes
orthogonal to that in the top row.
119
3.12 Clinical applications of SPECT and SPECT/CT

processing hardware is attached directly to a circuit board, with the detectors on the
other side of the circuit board. For collimation a thin sheet of lead is placed between
the patient and the detectors with only six thin slots in the vertical direction. Back-
and-forth movement of this collimator by up to ~25 cm enables scanning through the
patient with a very ﬁne angular increment of ~0.14 (compared to 3 for conven-
tional SPECT). For vertical collimation, thin lead ‘vanes’ are used to separate the
different levels of CZT detectors, which enables multi-slice images to be acquired.
Again, the patient can be scanned in a more natural sitting position. Myocardial scan
time reduction to 2–4 minutes is possible with either of these relatively new systems.
3.12.2 Brain SPECT and SPECT/CT
SPECT studies are also performed to measure blood perfusion in the brain, most
commonly using 99mTc-exametazime (trade name Ceretec), a neutral complex which
Figure 3.20
(top) Two commercial specialized myocardial SPECT scanners, the DSPECT (left) and CardiArc
(right). (bottom) Showing the mode of operation of the CardiArc scanner using a six-slit horizontal
collimator which is in constant motion, and the lead vanes used for vertical collimation.
120
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

passes through the blood brain barrier due to its low molecular weight, relative
lipophilicity, and zero charge. The agent is metabolized inside the cells into a more
hydrophilic species which cannot easily diffuse back out of the cell and therefore
accumulates over time to an amount proportional to the regional cerebral blood
ﬂow (rCBF). Uptake in the brain reaches a maximum of ~5% of the injected dose
within one minute of injection. Up to 15% of the activity is eliminated from the
brain within two minutes post-injection, after which the concentration of the radio-
tracer remains constant for the next 24 hours. A healthy brain has symmetric blood
perfusion patterns in both hemispheres, with higher blood ﬂow in grey matter than
white matter. Diseases which cause altered perfusion patterns include epilepsy,
cerebral infarction, schizophrenia and dementia. One commonly studied form of
dementia is Alzheimer’s disease, which is characterized by bilateral decreased ﬂow
in the temporal and parietal lobes with normal ﬂow in the primary sensorimotor
and visual cortices, as shown in Figure 3.21. Stroke patients often show signiﬁ-
cantly reduced blood perfusion on the side of the brain in which the stroke has
occurred.
3.13
Positron emission tomography (PET)
Similar to SPECT, PET is a tomographic technique which also uses radiotracers
[4;5]. However, PET has between 100 and 1000 times higher SNR as well as
signiﬁcantly better spatial resolution than SPECT (6). The fundamental difference
Figure 3.21
(left) Brain SPECT from a healthy patient. (right) Corresponding scan from a patient with Alzheimer’s
disease. The arrows point to signiﬁcantly reduced activity in the temporal and parietal lobes.
121
3.13 Positron emission tomography (PET)

between the two imaging techniques is that the radiotracers used in PET emit
positrons which, after annihilation with an electron in tissue, result in the formation
of two c-rays with energies of 511 keV each. These two c-rays have trajectories
180 apart and strike solid-state detectors which are positioned in a series of
complete rings around the patient. This forms an intrinsic line-of-reconstruction
(LOR) without the need for any collimation, as shown in Figure 3.22. The much
higher SNR of PET compared to SPECT arises from several factors including:
(i) collimation not being required, (ii) reduced attenuation of higher energy (511
keV vs. 140 keV) c-rays in tissue, and (iii) the use of a complete ring of detectors.
In the past ﬁve years, stand-alone PET scanners have largely been replaced with
hybrid PET/CT scanners which use a single patient bed to slide between the two
systems [7]. The rationale for the hybrid system is similar to that for SPECT/CT,
namely improved attenuation correction and the ability to fuse morphological and
functional information. A photograph of a commercial PET/CT system is shown
later in the chapter in Figure 3.27.
A general block diagram of the instrumentation for PET is shown in Figure 3.22.
The detectors (typically many thousands) consist of small crystals of bismuth
germanate (BGO), which are coupled to PMTs: the resulting output voltages are
then digitized. After correction of the acquired data for accidental coincidences and
1
lats
y
rc
2
lats
y
rc
3
lats
y
rc
4
lats
y
rc
5
lats
y
rc
6
lats
y
rc
7
lats
y
rc
8
lats
y
rc
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
n
lats
y
rc
T
M
P
k
c
olb
T
M
P
k
c
olb
n
oitalihin
n
A
e
c
n
e
dic
nio
c
n
oitc
ete
d
d
n
a
latn
e
dic
c
A
e
c
n
e
dic
nio
c
elpitlu
m
n
oitc
err
o
c
n
oita
u
n
ett
A
n
oitc
err
o
c
e
g
a
m
I
n
oitc
u
rts
n
o
c
er
ata
d
T
C
.
.
.
T
M
P
k
c
olb
Figure 3.22
(top) The elements of a PET/CT system. (inset) Formation of lines-of-response in the PET detector
ring.
122
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

attenuation effects using the CT images, the PET image is reconstructed using
either ﬁltered backprojection or iterative methods. The most recent technical inno-
vation in commercial PET/CT scanners is time-of-ﬂight (TOF) technology, in
which the SNR is improved by very accurate measurement of the exact time at
which each c-ray hits the detector. This allows localization within the LOR, and is
discussed in detail in Section 3.20.
PET/CT has its major clinical applications in the general areas of oncology,
cardiology and neurology. In oncology, whole body imaging is used to identify
both primary tumours and secondary metastatic disease remote from the primary
source. The major disadvantages of PET/CT are the requirement for an on-site
cyclotron to produce positron emitting radiotracers, and the high associated costs.
3.14
Radiotracers used for PET/CT
Isotopes such as 11C, 15O, 18F and 13N used in PET/CT undergo radioactive decay
by emitting a positron, i.e. a positively charged electron (e+), and a neutrino:
18
9 F ! 18
8 O 1 e1 1 neutrino
11
6 C ! 11
5 B 1 e1 1 neutrino:
The positron travels a short distance (an average of 0.1–2 mm depending upon
the particular radiotracer) in tissue before annihilating with an electron. This
annihilation results in the formation of two c-rays, each with an energy of 511
keV. Table 3.2 lists commonly used PET radiotracers with their applications and
half-lives.
Radiotracers for PET must be synthesized on-site using a cyclotron, and are
structural analogues of biologically active molecules in which one or more of the
atoms have been replaced by a radioactive atom. Therefore, after production of the
Table 3.2: Properties and applications of the most common PET radiotracers
Radionuclide
Half-life
(minutes)
Radiotracer
Clinical applications
18F
109.7
18FDG
oncology, inﬂammation,
cardiac viability
11C
20.4
11C-palmitate
cardiac metabolism
15O
2.07
H2
15O
cerebral blood ﬂow
13N
9.96
13NH3
cardiac blood ﬂow
82Rb
1.27
82RbCl2
cardiac perfusion
123
3.14 Radiotracers used for PET/CT

particular radionuclide it must be incorporated, via rapid chemical synthesis, into
the corresponding radiotracer. For speed and safety these syntheses are carried out
robotically. Such robotic units are available commercially to synthesize, for exam-
ple, 18F-ﬂuorodeoxyglucose (FDG), 15O2, C15O2, C15O, 13NH3 and H2
15O. The
most common radiotracer, used in 80% of studies, is FDG, the structure of which is
shown in Figure 3.23, which also illustrates its basic synthesis [8]. Once injected
into the bloodstream, FDG is actively transported across the blood/brain barrier
into cells. Inside the cell, FDG is phosphorylated by glucose hexokinase to give
FDG-6-phosphate. This chemical is trapped inside the cell, since it cannot react
with G-6-phosphate dehydrogenase, which is the next step in the glycolytic cycle,
because the hydroxyl group at the 2-carbon is a requirement for the process. Since
a high glucose metabolic rate is characteristic of many types of tumour, these show
up as hot spots in oncological PET scans.
The only PET radiotracer that can be produced from an on-site generator rather
than a cyclotron is 82Rb. The process uses 82Sr as the parent isotope, which has a
half life of 600 hours. The physical set-up is quite similar to the technetium
generator described in Section 3.4, with the 82Sr adsorbed on stannic oxide in a
lead-shielded column. The column is eluted with NaCl solution, and the eluent is in
the form of rubidium chloride which is injected intravenously. The 82Rb rapidly
clears from the bloodstream and is extracted by myocardial tissue in a manner
analogous to potassium. Since the half-life of 82Rb is just over one minute, scans
have to be acquired relatively quickly using a very high initial dose of ~50 mCi.
Areas of myocardial infarction are visualized within two to seven minutes post-
injection as cold areas on the myocardial scan. The spatial resolution of 82Rb
images is slightly lower than for other radiotracers since the positron emitted
has a higher energy and therefore travels further before annihilation.
3.15
Instrumentation for PET/CT
The instrumentation in the PET section of a PET/CT scanner is signiﬁcantly
different from a SPECT scanner, with many thousands of small solid-state
O
H
O
H
O
8
1 F
H
O
O
O
c
A
c
A
O
8
1 F
c
A
O
O
c
A
O
O
c
A
c
A
O
c
A
O
O
c
A
o
s
o
o
F
C
3
8
1 F
l
C
H
/
H
O
a
N
xif
o
t
p
y
r
K
elirtin
o
t
e
c
a
Figure 3.23
The most common synthesis of 18FDG.
124
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

detectors, and additional annihilation coincidence circuitry. However, there are
also several components which are very similar to SPECT systems, including
multi-channel pulse height analyzers and photomultiplier tubes.
3.15.1 Scintillation crystals
Although NaI(Tl) crystals can be used for PET, the material has a low detection
efﬁciency at 511 keV, meaning that the crystal would have to be very thick for high
SNR and this would result in poor spatial resolution. The properties of various
materials which are used as scintillation crystal detectors in PET are shown in
Table 3.3 [9]. The ideal detector crystal has:
(a) a high c-ray detection efﬁciency,
(b) a short decay time to allow a short coincidence resolving time to be used,
(Section 3.16.2),
(c) a high emission intensity (the number of photons per detected c-ray) to allow
more crystals to be coupled to a single PMT, reducing the complexity and cost
of the PET scanner,
(d) an emission wavelength near 400 nm which corresponds to the maximum
sensitivity for standard PMTs,
(e) optical transparency at the emission wavelength, and
(f) an index of refraction close to 1.5 to ensure efﬁcient transmission of light
between the crystal and the PMT.
Bismuth germanate detectors are used in the majority of commercial PET/CT
systems, as BGO has a high density and effective atomic number giving it a high
Table 3.3: Properties of PET detectors
Decay
time (ns)
Emission
intensity
Efﬁciency
(e2)
lemitted
(nm)
h
BGO
300
0.15
0.72
480
2.15
LSO(Ce)
40
0.75
0.69
420
1.82
BaF2
0.8prim, 600sec
0.12
0.34
220, 310
1.49
GSO(Ce)
60prim, 600sec
0.3
0.57
430
1.85
NaI(Tl)
230prim, 104
sec
1.0
0.24
410
1.85
GSO(Ce):cerium-doped gadolinium orthosilicate (Gd2SiO5),LSO(Ce): cerium-doped lutetium orthosilicate
(Lu2SiO5). Both primary and secondary decay times are reported, efﬁciency values are for 2 cm thickness
crystals and represent detection of both c-rays striking the two detectors, g is the refractive index, and decay
times are expressed as primary and secondary decays; the intensity is relative to a value of 1.0 for NaI(Tl).
125
3.15 Instrumentation for PET/CT

linear attenuation coefﬁcient and hence high efﬁciency. The major disadvantage of
BGO is its low emission intensity, meaning that a maximum of 16 crystal elements
can be coupled to each PMT. An alternative material, LSO(Ce), has a much higher
intensity and almost as high an efﬁciency, and is currently being commercially
integrated into newer systems, particularly time-of-ﬂight (TOF) scanners for which
its very short decay time is highly advantageous. A third material, GSO(Ce), is also
used in some PET/CT systems. BaF2 has the shortest decay time, but has not yet
found widespread commercial utility.
Detection of the anti-parallel c-rays uses a large number of scintillation crystals
which are placed in a circular ring surrounding the patient. Coupling each crystal to
a single PMT would give the highest possible spatial resolution but would also
increase the cost prohibitively. Modern PET scanners are based upon a ‘block
detector’ design, which consists of a large block of BGO (dimensions ~50 3 50 3
30 mm) which has a series of partial cuts through it, with the cuts ﬁlled with light-
reﬂecting material, as shown in Figure 3.24. The cuts prevent light which is formed
at the top of the crystal from producing a very broad light spread function by the
time the photon has passed through the entire 30 mm depth. An eight-by-eight
array of partial cuts is produced, and each block can be considered to contain
effectively 64 separate detectors, each with dimensions ~6 3 6 mm with a depth
of 30 mm. Four PMTs are coupled to each BGO block and localization of the
detected c-ray to a particular crystal is performed using exactly the same Anger
principle as outlined in Section 3.6.3. The dimensions of the cuts in the block are
designed to provide a linear output to each PMT, performing the same task as the
resistor network in the gamma camera. A modiﬁcation to this scheme is termed
quadrant sharing, shown also in Figure 3.24, in which larger PMTs are used and
Figure 3.24
(left) A large BGO crystal cut into 64 effective separate elements. The partial cuts are ﬁlled with light-
reﬂecting material. (right) Quadrant-sharing arrangement of the BGO crystals with PMTs shown by
the circles.
126
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

positioned so that they each overlap approximately one quarter of four adjacent
blocks. This reduces further the number of PMTs required.
A full PET ring is made up of many of these blocks, with several thousand
individual detectors. Typical ring diameters are either 70 or 85 cm for abdominal
scanners, or ~45 cm for head scanners. A number of these rings are stacked axially
(in the patient head/foot direction) allowing a head/foot imaging ﬁeld-of-view of
~16 cm. The dimensions of the individual elements in each block are important
since they affect the overall spatial resolution of the PET system. The contribution
from the detector size is approximately half the dimension of the detector, so ~2–3
mm for most PET systems.
3.15.2 Photomultiplier tubes and pulse height analyzer
The operation of these devices is essentially identical to that described previously
for planar nuclear medicine and SPECT. When a c-ray hits a BGO or LSO(Ce)
detector crystal it produces a number of photons. These photons are converted into
an ampliﬁed electrical signal, at the output of the PMT, which is fed into a multi-
channel analyzer. If the voltage is within a pre-determined range, then the PHA
generates a ‘logic pulse’, which is sent to the coincidence detector: typically, this
logic pulse is 6–10 ns long. The energy resolution of BGO crystals is ~20%, so the
energy window set for acceptance is typically 450–650 keV.
3.15.3 Annihilation coincidence detection
Each time that a signal is recorded in a given PET detector crystal it is given a
‘time-stamp’, with a precision typically between 1 and 2 ns. Since the two c-rays
from a positron annihilation event may originate from an area in the patient which
is much closer to one side of the detector ring than the other, there is a difference in
the arrival time of the two c-rays at the respective detectors after the annihilation
event, as shown on the left of Figure 3.25. A ﬁxed ‘coincidence resolving time’
exists for the system, deﬁned as the time-window that is allowed after the ﬁrst
c-ray has been detected for a second c-ray to be recorded and assigned to the same
annihilation. Provided that this second c-ray strikes a detector which is operated in
coincidence with the ﬁrst detector, then this pair of c-rays is accepted as a ‘true
coincidence’ and an LOR can be drawn between the two detectors. This process is
called annihilation coincidence detection (ACD), and the steps involved are shown
in in Figure 3.25. The ﬁrst c-ray from the annihilation strikes detector number 2
and a logic pulse is sent to the ACD circuit. Only those detectors numbered
127
3.15 Instrumentation for PET/CT

between 7 and 13 are ‘in coincidence’ with detector number 2 since unscattered
c-rays which originate from within the head must lie within the volume deﬁned by
detectors 7–13, as shown in Figure 3.25. When the second c-ray is detected in
crystal 10 a second logic pulse is sent to the ACD circuit, which adds the two
pulses together. If the summed signal is greater than a threshold set to a value just
less than twice the amplitude of each individual logic pulse, then a coincidence is
accepted and an LOR established between the two detectors. The coincidence
resolving time is deﬁned as twice the length of each logic pulse, with a value
typically between 6 and 12 ns.
Example 3.4
Assume that the head is an ellipse with major dimensions 28 and 22 cm. The
patient is placed within a head PET scanner with a circular arrangement, diameter
45 cm, of BGO detectors. What is the maximum time difference that can occur for
an event between two detectors?
Solution
The maximum difference clearly corresponds to a scintillation event occurring
either right at the front or at the back of the head. Assuming that the head is
perfectly centred in the PET scanner, there is a 28 cm difference in the trajectories
of the two c-rays. Assuming that the c-rays travel through tissue at the speed
of light, 3 3 108 m/s, then the times of detection will be ~930 ps, or just less than
1 ns apart.
2
7
8
9
0
1
1
1
2
1
3
1
e
m
it
d
e
m
m
u
S
la
n
gis
1
2
3
4
5
6
7
8
9
0
1
1
1
2
1
3
1
5
1
6
1
4
1
Figure 3.25
The principle of annihilation coincidence detection. (left) The two c-rays reach detectors 2 and 10,
triggering respective logic pulses of length s. (right) If both logic pulses are sent to the coincidence
detector within the system coincidence resolving time 2s, then the summed signal lies above the
threshold value (dashed line) and a coincidence is recorded.
128
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

3.16
Two-dimensional and three-dimensional PET imaging
Commercial PET systems have a number of detector rings, up to 48 in total, which
are stacked along the patient head/foot direction. Data can be acquired either in 2D
multi-slice or full 3D mode, with the great majority of scans now acquired in 3D
mode. The scanner has retractable lead collimation septa positioned between each
ring: these septa are extended for 2D multi-slice operation and retracted for imag-
ing in 3D mode. In 2D mode this collimation reduces the amount of scattered
c-rays detected and also has the characteristic of producing a uniform sensitivity
proﬁle along the axial dimension. This means that for whole body PET scans, in
which the table has to be moved several times to cover the entire body length, the
required overlap between successive table positions need only be ~1–2 cm. Image
planes can be formed between two crystals in the same ring (direct planes), and
also from crystals in adjacent rings (cross planes). For a system with n rings, there
are n direct planes and n-1 cross planes, making a total of 2n-1 image planes, as
shown in Figure 3.26.
Three-dimensional PET has a much higher sensitivity than 2D PET by about a
factor of 10, primarily due to the elimination of the collimators. Given that the
SNR is proportional to the square root of the number of counts recorded, this is
equivalent to a scan time reduction of two orders of magnitude. However, without
the collimators there are many more random coincidences and a far greater con-
tribution from scattered c-rays in 3D mode. In addition, the sensitivity proﬁle in the
axial direction is much higher at the centre of the scanner than at either end, and
s
e
n
alp
tc
e
rid
D
2
s
e
n
alp
s
s
o
r
c
d
n
a
tc
e
rid
D
2
D
3
Figure 3.26
Three different data acquisition modes used for PET scans. Note that the septal collimators are
retracted for 3D mode.
129
3.16 Two-dimensional and three-dimensional PET imaging

therefore for whole body scanning the overlap between table positions can be as
high as 50% meaning that more positions are required. Nevertheless, the majority
of studies are performed in 3D mode due to the far superior SNR.
3.17
PET/CT
Since 2006 no stand-alone commercial PET scanners have been produced, all are
now integrated PET/CT systems. The reasons for combining PET and CT in a
hybrid imaging system are essentially identical to those already outlined for
SPECT/CT. The improved accuracy in attenuation correction and image fusion
of morphological and functional data are particularly important in oncological
studies which form the major applications of PET/CT. Studies which previously
took up to an hour now typically take half the time since a separate PET calibration
scan for attenuation correction is not necessary, and the CT calibration scan is
extremely rapid. There are now well over 2000 PET/CT systems installed in the
world. The hybrid system contains two separate detector rings and a common
patient bed which slides between the two, as shown in Figure 3.27. Most PET/
CT scanners have a 70 cm bore for both CT and PET. The very latest PET/CT
scanners have a bore of 85 cm for larger patients, although the spatial resolution is
somewhat degraded due to the larger ring size.
The major issue with PET/CT, as for SPECT/CT, is the mismatch between the
data acquisition times of the two modalities. In the thorax and abdomen, MSCT
acquires entire data sets in 1s or less, whereas the PET data are acquired over
a
c
d
b
Figure 3.27
(left) A PET/CT scanner with two separate rings of detectors. A common bed slides the patient
through the two scanners. (right) (a) An uncorrected PET, (b) a CT image, (c) the CT-derived
attenuation map after segmentation of the CT image, and (d) the attenuation-corrected PET scan.
130
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

several minutes or more. Therefore, there can be a misregistration between the
position of, for example a tumour in the CT and PET scans if there is signiﬁcant
displacement due to cardiac- or breathing-related patient motion. Currently, the
very basic approach of blurring the CT data to match the PET images is used, but
more sophisticated algorithms are under development. Figure 3.27 shows an exam-
ple of a thoracic study using PET/CT, with attenuation correction from the high
resolution CT data.
3.18
Data processing in PET/CT
Image reconstruction in PET is essentially identical to that in SPECT with both
iterative algorithms and those based on ﬁltered backprojection being used to form
the image from all of the acquired LORs. Prior to image reconstruction, the data
must be corrected for attenuation effects as well as for accidental and multiple
coincidences, dead-time losses and scattered radiation.
3.18.1 Attenuation correction
Correction for attenuation effects in the patient is required for PET for the same
reasons as for SPECT. Prior to the advent of combined PET/CT scanners, a
transmission-based calibration using 68Ge was used to estimate the required
attenuation, in direct analogy to the 153Gd source in SPECT. This procedure has
been replaced by the PET/CT scanner, since the SNR and spatial resolution of the
CT-based attenuation data are far superior to that of the PET calibration method,
and much faster to acquire. After acquisition of the calibration scan the CT images
are segmented into a number of different tissue types (muscle, lipid, bone) to which
standard values of l at 511 keV are assigned. Since the spatial resolution of the
attenuation map is much ﬁner than that of the PET scan, the CT-based attenuation
map is smoothed to match the resolution of the PET scan before implementing the
attenuation correction. This spatial smoothing is also important for abdominal
imaging, in which the CT data represents a snapshot, i.e. the abdomen in only
one position during the respiratory and cardiac cycles, whereas the PET scan is
acquired over many minutes and therefore represents a time-average.
3.18.2 Corrections for accidental and multiple coincidences
Accidental, also termed random, coincidences are events in which the LOR is
incorrectly assigned due to two separate disintegrations occurring very closely
131
3.18 Data processing in PET/CT

in time. In one case, illustrated in Figure 3.28, the ﬁrst c-rays from each of the two
events together form an incorrect LOR. A second possibility is that an incorrect
LOR is formed due to one c-ray being scattered, also shown in Figure 3.28.
Accidental coincidences are uniformly distributed across the imaging ﬁeld-of-
view, and so can cause signiﬁcant errors in areas which have very low activity.
For clinical PET/CT head scanners accidental coincidences constitute ~20% of
the attributed true coincidences, but for a body scanner the number can be closer
to 50%.
The most common method of correcting for random coincidences uses addi-
tional parallel timing circuitry, in which a second coincidence timing window
starts signiﬁcantly later, typically 60 ns after an event is recorded. The standard
circuit with a 6–12 ns resolving time is used to measure the total number of
coincidences. The second measurement being delayed well beyond the coinci-
dence resolving time means that only accidental coincidences are recorded. The
accidental coincidences are then subtracted from the acquired data.
An alternative correction method is to measure the number of events recorded
by each individual detector. If two detectors i and j are considered, then the rate at
which accidental coincidences (Cij
acc) are recorded is given by:
Cacc
ij
5 2sRiRj,
ð3:18Þ
where Ri and Rj are the single count rates in the individual detectors i and j, and
2s is the coincidence resolving time. Therefore, the measured values of Ri and Rj
for each detector pair i and j can be used to estimate the corresponding values of
Cij
acc, which are then subtracted from the acquired data. Multiple coincidences can
1
2
1
Figure 3.28
(left) An accidental coincidence recorded as an LOR between the ﬁrst c-rays hitting the detector ring
from radioactive decays at positions 1 and 2 which occur very closely in time. (right) Incorrect LOR
assigned from a scattered c-ray.
132
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

also occur, in which more than two events are recorded during the coincidence
resolving time. Estimates for the number of multiple coincidences (Mij) between
two detectors can be made using the expression:
Mij  CijsRijNij;
ð3:19Þ
where Nij is the total number of detectors operating in coincidence with either of
the two detectors i and j. Multiple event coincidences are simply discarded before
image reconstruction.
3.18.3 Corrections for scattered coincidences
There are two major sources of scattered radiation that contaminate the PET signal,
scatter within the body and scatter in the BGO detection crystal itself. BGO has a
relatively poor intrinsic energy resolution, and the energy window is typically set
to be between 450 and 650 keV for a clinical scan. Since a c-ray that is scattered by
45 in the body only loses ~115 keV of its energy, scattered c-rays represent a
signiﬁcant fraction of the detected c-rays. In 2D PET, scattered c-rays typically
account for only ~10–15% of the detected signal, but in 3D mode up to 50% of the
detected c-rays can be scattered, this larger number due primarily to the elimina-
tion of the lead septa. The simplest method of correcting for scatter is to measure
the signal intensity in areas that are outside the patient, and to ﬁt these values to a
Gaussian shape to estimate the amount of scatter inside the patient. This function is
then subtracted from the raw data to give the corrected image. This approach works
reasonably for relatively homogenous organs such as the brain, but cannot be used
in the abdomen, for example. A second method is to use multiple energy window
methods, as used in SPECT. The dual-energy window approach typically has the
lower window set between 190 and 350 keV, with the upper window at 350–650
keV. An alternative method is termed the estimation of trues method (ETM) which
also uses two windows, but in this case the lower window is 450–650 keV, which
partially overlaps the upper window between 550 and 650 keV. The ETM makes
the assumption that all of the events in the upper window arise from c-rays that
have not been scattered. These data are then scaled appropriately to equal the
number of events recorded in the lower window, and these scaled data are then
subtracted from the photopeak energy window. Finally, the most sophisticated but
also most computationally intensive and time-consuming method is an iterative
reconstruction based upon simulating the actual scatter using the CT-derived
attenuation maps. The ﬁrst estimate is simply formed from the data with no scatter
correction: subsequent steps follow the type of iterative data ﬂow already shown in
Figure 3.16.
133
3.18 Data processing in PET/CT

3.18.4 Corrections for dead time
As already outlined in Section 3.6.4, there is a maximum count rate that a system
can record due to ﬁnite component response and recovery times. The fractional
dead time of the PET system is deﬁned as the ratio of the measured count rate to the
theoretical count rate if the dead time were zero. The three major sources of
deadtime in PET scanners are the time taken to integrate the charge from the PMTs
after a scintillation event, the processing of a coincidence event, and the presence
of multiple coincidences in which the data are discarded. Corrections are per-
formed based mainly upon a careful characterization of the dead-time associated
with each component of the PET system, and the number of multiple coincidences
estimated using Equation (3.19).
3.19
Image characteristics
Signal-to-noise
Radiotracer dose, targeting efﬁciency, image acquisition time, c-ray attenuation in
the patient, system sensitivity and image post-processing play similar roles in
determining the SNR in PET as they do in SPECT scans. As outlined earlier,
the intrinsic sensitivity of PET is signiﬁcantly greater than SPECT due to the lack
of collimation requirements and the lower c-ray attenuation in tissue of 511 keV
c-rays. In terms of the total number of c-rays emitted by a particular radiotracer,
approximately 0.01–0.03% are detected by a SPECT gamma camera, 0.2–0.5% in
PET/CT using 2D acquisition-mode, and 2–10% in 3-D PET/CT. Due to the
signiﬁcant difference in sensitivity between 2D and 3D, many commercial PET/
CT scanners now offer only 3D acquisition.
Contrast-to-noise
In addition to those factors affecting SNR, the CNR is mainly inﬂuenced by the
correction for in Compton-scattered c-rays, and the non-speciﬁc uptake of radio-
tracer in healthy tissue surrounding the pathology being studied, for example the
uptake of FDG in brain, described further in Section 3.21.2.
Spatial resolution
In contrast to SPECT, in which the spatial resolution is signiﬁcantly worse the
deeper within the body that the radiotracer is located, the in-plane spatial resolution
in PET is much more constant throughout the patient. This is because the inherent
‘double detection’ of two c-rays in PET reduces the depth dependence of the PSF.
Other factors which inﬂuence the spatial resolution of the PET image include:
134
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

(i) The effective positron range in tissue before it annihilates with an electron:
this distance is longer the higher the energy of the emitted positron and the
less dense the tissue through which it has to travel. Typical values of the
maximum positron energy and corresponding FWHM distances travelled are:
18F (640 keV, 0.2 mm), 11C (960 keV, 0.4 mm), 13N (1.2 MeV, 0.6 mm),
15O (1.7 MeV, 1 mm), and 82Rb (3.15 MeV, 2.6 mm),
(ii) The non-colinearity of the two c-rays, i.e. the small random deviation from
180 of the angle of their relative trajectories. There is a distribution in angles
about a mean of 180, with a FHWM of approximately 0.5. Therefore, the
larger the diameter of the PET detector ring, the greater the effect this has on
the spatial resolution, and
(iii) The dimensions of the detector crystals, with an approximate spatial resolu-
tion given by half the detector diameter. Since multiple Compton scattering
interactions are required to ‘stop’ the c-rays in the crystal there is also an
uncertainty in the exact location at which the c-ray ﬁrst strikes the detector:
this uncertainty increases with the thickness of the crystal, as seen previously.
The overall spatial resolution of the system is the combination of all three
components:
Rsys 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
R2
detector þ R2
range þ R2
1800
q
,
ð3:20Þ
with typical FWHM values of Rsys of 3–4 mm for a small ring system for brain
studies, and 5–6 mm for a larger whole-body system.
3.20
Time-of-ﬂight PET
The most recent development in commercial PET/CT scanners is that of time-of-
ﬂight (TOF) PET [10]. The concept of TOF PET, shown in Figure 3.29, is to
constrain the estimated position of an annihilation to a subsection of the conven-
tional LOR between two detectors by measuring the exact times at which the two
c-rays strike the detectors. Ideally, one would be able to constrain the position to a
point, in which case spatial resolution would increase signiﬁcantly. However, in
order to do this, the timing accuracy of every scintillation event would have to be
much less than 1 ns, which is not possible. Suppose that one has a timing resolution
of Dt, then the position resolution, Dx, along a line between two detectors is
given by:
Dx 5 cDt
2 ;
ð3:21Þ
135
3.20 Time-of-ﬂight PET

where c is the speed of light.
Commercial scanners are now available which offer TOF PET/CT as well as
regular PET/CT. The scintillator used for the ﬁrst commercial TOF PET systems is
lutetium orthosilicate (LSO). Compared to BGO, LSO produces roughly three
times the number of photons per MeV of energy absorbed, with only a slightly
poorer energy resolution. Most importantly, the coincidence time (theoretically
450 ps, slightly greater in an actual PET system) is much shorter for LSO than for
BGO (3 ns). A timing resolution of 500 ps corresponds to a spatial resolution of
~7.5 cm. Therefore, it would appear that TOF PET offers no advantages over
conventional PET since the latter already has a spatial resolution of the order of
several millimetres. However, being able to constrain the length of the LOR from
its value in conventional PET to 7.5 cm reduces the statistical noise inherent in the
measurement. Since the noise variance is proportional to the length of the LOR, the
reduction in noise variance, the so-called multiplicative reduction factor (f), is
given by:
f 5 D
Dx 5 2D
cDt ;
ð3:22Þ
where D is the size of the patient. Since for both brain and whole-body imaging
the value of D is much greater than 7.5 cm, the noise in TOF PET is reduced
compared to conventional PET and the SNR is signiﬁcantly enhanced. In a com-
mercial scanner the crystal size of LSO is typically 4 3 4 mm, with a thickness of
just over 2 cm. TOF PET/CT scanners incorporate either a 16- or 64-slice CT
capability.
t1
t2
Figure 3.29
(left) Conventional LOR formed in PET. (right) Constrained LOR in TOF-PET deﬁned by the time
difference t22t1 corresponding to the delay between the two c-rays striking the particular detectors.
136
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

3.21
Clinical applications of PET/CT
PET/CT scans currently represent ~5–10% of all nuclear medicine scans, and are
rapidly increasing in percentage each year. The majority (~90%) of PET/CT diag-
noses are oncology scans using 18FDG [11]. In the USA the Centers for Medicare
Services have approved FDG PET/CT for reimbursement for, amongst others,
lung, colorectal, oesophageal and head-and-neck cancers, as well as melanoma
and lymphoma. Diagnoses of breast, thyroid and cervical cancer are also very
promising areas which may be approved for medical reimbursement in the near
future. PET/CT can also be used to follow the efﬁcacy of cancer therapies. In
addition, neurological conditions including seizure disorders and neurodegenera-
tive diseases such as Alzheimer’s and dementia can be assessed and monitored
using PET/CT.
3.21.1 Whole-body PET/CT scanning
Malignant cells, in general, have higher rates of aerobic glucose metabolism than
healthy cells. Therefore, in PET scans using FDG, tumours show up as areas of
increased signal intensity provided that there is sufﬁcient blood supply to deliver
the radiotracer. When cancer, and in particular metastatic cancer in which the
lesions have spread from their primary focus to secondary areas, is suspected a
whole-body PET scan is performed. Patients either fast overnight for scans
acquired in the morning, or for at least four hours before afternoon scans, since
glucose competes with 18FDG in terms of cellular uptake. A serum glucose level of
~150 mg/dl is the target value before injection. The patient is injected intrave-
nously with ~10 mCi of FDG and scanned 30–60 minutes after this to allow most
of the radiotracer to clear from the bloodstream and to accumulate in the tumour. A
typical whole-body PET scan over a body length of 190 cm takes approximately 30
minutes, with the patient bed being moved a number of times within the scanner to
cover the entire body. The most modern TOF PET/CT scanners can shorten the
scanning time considerably. Figure 3.30 shows PET, CT and fused images from a
whole-body scan.
3.21.2 PET/CT applications in the brain
Although FDG PET/CT can be used to diagnose brain tumours, the technique faces
the challenge that there is a high background signal in the brain due to the natural
metabolism of glucose in healthy brain tissue. Since the CNR is not high, the role
137
3.21 Clinical applications of PET/CT

of the CT component of the hybrid scanner in deﬁning the exact outline of the
tumour is critical. The PET signal can then be used to grade the tumour by
comparing the activitity within the tumour with that of surrounding white and
grey brain matter. Low grade tumours typically have activity below that of white
matter, whereas high grade tumours have levels equal to or even greater than those
in grey matter. Figure 3.31 shows combined PET/CT images of the brain.
FDG PET is also used to characterize different types of neurodegenerative
dementia such as Alzheimer’s disease (AD) which is characterized by low
Figure 3.30
(left) Whole-body 18FDG PET scan. (centre) Corresponding CT scan. (right) Fused PET/CT scan.
Figure 3.31
(left) 18FDG PET scans of the brain. (right) Corresponding fused PET/CT images.
138
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

metabolism in the parietal and temporal lobes. Differentiation between AD and
other dementias such as frontotemporal dementia can be made by characterizing
the different extents of hypoactivity. Early evaluation of AD can also be performed
with alternative targeted compounds. These include the so-called Pittsburgh Com-
pound B (Pitt-B), which binds to amyloid proteins associated with amyloid plaque
depositions in the brain. Areas of high signal intensity are found in the cortices
where these plaques accumulate.
3.21.3 Cardiac PET/CT studies
Although SPECT is currently the most important diagnostic technique for myo-
cardial viability and perfusion assessment, PET/CT is increasingly being used
wherever it is available, primarily due to its higher spatial resolution (approxi-
mately 8 mm for PET versus 15 mm for SPECT) and the fact that one can perform
cardiac-gated analysis of wall motion and ejection fraction. Myocardial perfusion
PET/CT scans use either 13NH3 or 82RbCl2, with a similar stress test protocol to
that performed for SPECT. Complementary PET viability studies are performed
with 18FDG which is preferentially taken up in myocardial cells which have poor
perfusion but are metabolically active. In healthy myocardium long-chain fatty
acids are the principal energy source, whereas in ischemic tissue glucose plays a
major role in residual oxidative metabolism and the oxidation of long-chain fatty
acids is reduced substantially. One example of the clinical application of cardiac
PET is the assessment of whether a heart transplant or bypass surgery should be
carried out on a particular patient. A measured absence of both blood ﬂow and
metabolism in parts of the heart show that the tissue has died, and so a heart
transplant may be necessary. If blood ﬂow is absent in an area, but the tissue
maintains even a reduced metabolic state, then the tissue is still alive and bypass
surgery would be more appropriate.
Exercises
Radioactivity
3.1 (a) In a sample of 20 000 atoms, if 400 decay in 8 seconds what is the
radioactivity, measured in mCi, of the sample?
(b) In order to produce a level of radioactivity of 1 mCi, how many nuclei of
99mTc (k = 3.2231025 s21) must be present? What mass of the radiotracer
does this correspond to? (Avogadro’s number is 6.0231023).
(c) A radioactive sample of 99mTc contains 10 mCi activity at 9 am. What is
the radioactivity of the sample at 12 pm on the same day?
139
Exercises

3.2 In a nuclear medicine scan using 99mTc, the image SNR for a 30 minute scan
was 25:1 for an injected radioactive dose of 1 mCi. Imaging began immedi-
ately after injection.
(a) If the injected dose were tripled to 3 mCi, what would be the image SNR
for a 30 minute scan?
(b) If the scan time were doubled to 60 minutes with an initial dose of 1 mCi,
what would be the image SNR?
3.3 A dose of 1 mCi of 99mTc is administered to a patient. Calculate the total dose
to the patient if the biological half-life of the radiotracer in the body is:
(a) 2 years,
(b) 6 hours,
(c) 2 minutes.
The technetium generator.
3.4 In the technetium generator, show mathematically that if k2  k1, the radio-
activities of the parent and daughter nuclei become equal in value at long
times.
3.5 Using the equations derived in the analysis of the technetium generator,
plot graphs of the activity of parent and daughter nuclei for the following
cases:
(a) s1/2 (parent) = 600 hours, s1/2 (daughter) = 6 hours,
(b) s1/2 (parent) = 6.1 hours, s1/2 (daughter) = 6 hours,
(c) s1/2 (parent) = 0.6 hours, s1/2 (daughter) = 6 hours.
3.6 Calculate the exact time at which the ﬁrst three ‘milkings’ of the technetium
cow should be performed.
3.7 Do the tops of the curves in Figure 3.4 lie at the same values that would have
been obtained if the technetium cow were not milked at all?
3.8 Rather than waiting 24 hours, only 6 hours are left between milkings. Plot the
graph of radioactivity over the ﬁrst two days.
The gamma camera.
3.9 Calculate the magniﬁcation factor for the pinhole collimator shown in Figure
3.32(a). What implications does this have for image distortions?
3.10 If the acceptance window for a planar nuclear medicine scan is set to 15%,
what is the maximum angle that a c-ray could be Compton scattered and still
be accepted if it strikes the scintillation crystal?
3.11 What is the energy of a c-ray which has been Compton scattered at an angle
of 30 in the body?
3.12 (i) The thickness of the lead septa is chosen to ensure that only 5% of the
c-rays penetrate from one collimator hole to the adjacent one. Using
Figure 3.32(b) show that the thickness is given by [6d/l]/[L23/l].
140
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

(ii) Calculate the septal thickness required for c-rays of 140 keV for lead
collimators with a hole diameter of 0.1 cm and a length of 2.5 cm. The
attenuation coefﬁcient for lead is 30 cm21 at 140 keV.
3.13 Assuming that the body is circular with a diameter of 30 cm, calculate the
spatial resolution (FWHM) for a parallel hole collimator, length 2.5 cm, for
two sources of radioactivity, one very close to the detector (z = 0) and one at
the other side of the body (z ~30).
3.14 Stating any assumptions that you make, show that for the parallel collimator
there is an approximate relationship between collimator efﬁciency and spatial
resolution given by:
g } R2
coll:
3.15 For the converging collimator shown in Figure 3.33 describe qualitatively
(without mathematical proof) (i) whether the efﬁciency increases or
decreases as a function of z, and as a function of h, and (ii) whether the
resolution increases or decreases as a function of h, and as a function of z.
3.16 Given the following resistor values for the Anger network, show that the
output is linear in X.
Image characteristics
3.17 Three parameters which affect the image SNR in nuclear medicine are the
thickness of the detector crystal, the length of the lead septa in the anti-scatter
crystal
L
t
d
L
d
z
b
a
Figure 3.32
See Exercise 3.9.
PMT
RX+ (X)
RX2 (X)
RY+ (X)
RY2 (X)
8
inﬁnite
14.3
28.6
28.6
9
57.1
19.0
28.6
28.6
10
28.6
28.6
28.6
28.6
11
19.0
57.1
28.6
28.6
12
14.3
inﬁnite
28.6
28.6
141
Exercises

grid, and the FWHM of the energy window centred around 140 keV. For
each parameter, does an increase in the value of the particular parameter
increase or decrease the image SNR? In each case, name one other image
characteristic (e.g. CNR, spatial resolution) that is affected, and explain
whether this image characteristic is improved or degraded.
3.18 Suppose that two radiotracers could be given to a patient. Radiotracer A is
taken up in a tumour ten times higher than in the surrounding tissue, whereas
B suppresses uptake by a factor of 10. Assume the tumour is 1 cm thickness
and the surrounding tissue is 10 cm thickness. Ignoring attenuation effects,
what is the CNR generated from each tumour. Assume that the uptake in
normal tissue gives a rate of 10 counts per minute per cubic centimetre of
tissue, and that the imaging time is 1 minute.
SPECT
3.19 Isosensitive imaging is a technique that acquires nuclear medicine scans from
opposite sides of the patient, and then combines the signals to remove the
depth dependence of the signal intensity. By considering the attenuation of
c-rays in the patient, show how this technique works, and what mathematical
processing of the two scans is necessary.
3.20 For a 64 3 64 data matrix, how many total counts are necessary for a 10%
pixel-by-pixel uniformity level in a SPECT image?
3.21 Answer true or false with a couple of sentences of explanation. If a uniform
attenuation correction is applied to a SPECT scan, a tumour positioned close
to bone appears to have a lower radioactivity than is actually the true sit-
uation.
d
L
z
f
θ
Figure 3.33
See Exercise 3.15.
142
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

3.22 A SPECT scan is taken of a patient, and areas of radioactivity are found. The
sinogram from the SPECT scan is shown in Figure 3.34. What are the shapes
of the areas of radioactivity?
3.23 Calculate the maximum angle and corresponding energy of Compton scat-
tered c-rays accepted for energy resolutions of 5, 15 and 25%.
PET
3.24 Using the rest mass of the electron, show that the energies of the two c-rays
produced by the annihilation of an electron with a positron are 511 keV.
3.25 PET scans often show an artiﬁcially high level of radioactivity in the lungs.
Suggest one mechanism by which this might occur.
3.26 For an 15O PET scan, if an initial dose of 1 mCi is injected, calculate the total
number of c-rays that are produced over a scan time of 4 minutes, assuming
that scanning starts immediately after injection, and that clearance from the
body is negligible.
3.27 What timing resolution would be necessary to obtain a position resolution of
5 mm in TOF PET based only upon time-of-ﬂight considerations?
3.28 If the brain is assumed to be a sphere with diameter 20 cm, and the largest
dimension of the body to be 40 cm, what are the respective values of the
timing resolution necessary to reduce the noise in TOF PET compared to
conventional PET?
180
0
360
p(r,   )
Figure 3.34
See Exercise 3.22.
143
Exercises

3.29 Suggest why a PET/CT scanner operating in 2D mode has a relatively uni-
form axial sensitivity proﬁle, whereas in 3D mode the sensitivity is much
higher at the centre of the scanner.
3.30 Suggest why a curvilinear region of low signal intensity is often seen on
PET/CT scans of the thorax and abdomen, which parallels the dome of the
diaphragm.
References
[1] Anger H. Scintillation camera. Review of Scientiﬁc Instruments 1958;29,27–33.
[2] O’Connor MK and Kemp BJ. Single-photon emission computed tomography/
Computed tomography: Basic instrumentation and innovations. Seminars in Nuclear
Medicine 2006:36, 258–66.
[3] Seo Y, Mari C and Hasegawa BH. Technological development and advances in
single-photon emission computed tomography/computed tomography. Seminars in
Nuclear Medicine 2008:38, 177–198.
[4] Robertson JS, Marr RB, Rosenblum M, Radeka V and Yamamoto YL. Thirty-two-
crystal positron transverse section detector. In: Freedmen GS, editor. Tomographic
imaging in nuclear medicine. New York: Society of Nuclear Medicine; 1973:
142–53.
[5] Ter-Pogossian MM, Mullani NA, Hood J, Higgins CS and Curie M. A multi-slice
postitron emission computed tomograph (PETT IV) yielding transverse and
longitudinal images. Radiology 1978:128, 477–484.
[6] Rahmin A and Zaidi H. PET vs. SPECT: strengths, limitations and challenges.
Nuclear Medicine Communications 2008:29, 193–207.
[7] Mittra E and Quon A. Positron emission tomography/computed tomography: the
current technology and applications. Radiological Clinics of North America 2009:47,
147–60.
[8] Gallagher GM, Ansari A, Atkins H et al. Radiopharmaceuticals XXVII. 18F-labeled
2-deoxy-2-ﬂuoro-D-glucose as a radiopharmaceutical for measuring regional
myocardial glucose metabolism in vivo: tissue distribution and imaging studies in
animals. Journal of Nuclear Medicine 1977: 18, 990–6.
[9] van Eijk CWE. Radiation detector developments in medical applications: inorganic
scintillators in positron emission tomography. Radiation Protection Dosimetry
2008:129, 13–21.
[10] Moses WM. Recent advances and future advances in time-of-ﬂight PET. Nuclear
Instrument Methods Physics Research A 2007:580, 919–24.
[11] Pan T and Mawlawi O. PET/CT in radiation oncology. Medical Physics 2008:35,
4955–66.
144
Nuclear medicine: Planar scintigraphy, SPECT and PET/CT

4 Ultrasound imaging
4.1
Introduction
Of all the standard clinical imaging techniques ultrasound is by far the least
expensive and most portable (including handheld units smaller than a laptop
computer), and can acquire continuous images at a real-time frame rate with few
or no safety concerns. In addition to morphological and structural information,
ultrasound can also measure blood ﬂow in real-time, and produce detailed maps of
blood velocity within a given vessel. Ultrasound ﬁnds very wide use in obstetrics
and gynaecology, due to the lack of ionizing radiation or strong magnetic ﬁelds.
The real-time nature of the imaging is also important in measuring parameters such
as foetal heart function. Ultrasound is used in many cardiovascular applications,
being able to detect mitral valve and septal insufﬁciencies. General imaging appli-
cations include liver cysts, aortic aneurysms, and obstructive atherosclerosis in the
carotids. Ultrasound imaging is also used very often to guide the path and position-
ing of a needle in tissue biopsies.
Ultrasound is a mechanical wave, with a frequency for clinical use between 1
and 15 MHz. The speed of sound in tissue is ~1540 m/s, and so the range of
wavelengths of ultrasound in tissue is between ~0.1 and 1.5 mm. The ultrasound
waves are produced by a transducer, as shown in Figure 4.1, which typically has an
array of up to 512 individual active sources. In the simplest image acquisition
scheme, small subgroups of these elements are ﬁred sequentially to produce paral-
lel ultrasound beams. As the ultrasound passes through tissue, a small fraction of
the energy is reﬂected from the boundaries between tissues which have slightly
different acoustic and physical properties: the remaining energy of the beam is
transmitted through the boundary. The reﬂected waves are detected by the trans-
ducer and the distance to each tissue boundary is calculated from the time between
pulse transmission and signal reception: thus ultrasound imaging is very similar
to techniques such as radar. As soon as the signal from the deepest tissue
boundary has been detected from one beam, the next adjacent beam of ultrasound
is emitted, and this process is repeated until the entire image has been acquired.
Due to the relatively high speed of ultrasound through tissue, entire images can be

acquired in fractions of a second, allowing real-time imaging to be performed.
Ultrasound imaging can also be used to measure blood ﬂow via the Doppler
effect, in which the frequency of the received signal is slightly different than
that of the transmitted signal due to blood ﬂow either towards or away from the
transducer.
Advances in instrumentation have made extraordinary improvements in image
quality possible over the past decade. As examples of such advances, transducers
are now able to cover very large frequency bandwidths enabling harmonic imaging
to be performed efﬁciently. Two-dimensional transducers allow three-dimensional
ultrasound to be performed in real-time. The incorporation of digital electronics
into receiver beam-forming, and new data acquisition techniques such as pulse
inversion imaging have improved image quality signiﬁcantly. In addition, the
development of new ultrasound contrast agents based on microbubbles can
increase the signal intensity from ﬂowing blood by orders of magnitude.
4.2
Wave propagation and characteristic acoustic impedance
A simple model of tissue to illustrate the principles of ultrasound propagation is a
three-dimensional lattice of small particles held together by elastic forces. The
ultrasound transducer transmits a pressure wave into tissue with a broad band of
frequencies centred at its speciﬁed operating frequency. Passage of energy through
the tissue causes individual particles to oscillate about their mean positions. As
tissue boundary
tissue boundary
transducer
Figure 4.1
(left) Basic principle of ultrasound imaging. A transducer sends a series of pressure waves through the
tissue. At boundaries between tissues, a small fraction of the energy is backscattered towards the
transducer where it is detected. Using the speed of sound through tissue, the depth of the tissue
boundary can be determined. Electronic steering of the beam across the sample builds up successive
lines which form the image. (right) The intensity of each pixel in the image is proportional to the
strength of the detected signal reﬂected from that point.
146
Ultrasound imaging

with all types of wave propagation, the distances moved by the individual particles
are very small compared to the overall distance travelled by the pressure wave. In
ultrasound imaging the directions of particle vibration and wave propagation are
the same, meaning that the ultrasound can be considered as a purely longitudinal
wave, as shown in Figure 4.2.
For typical ultrasound frequencies (1–15 MHz) used in clinical diagnosis, the
value of the particle displacement, W, is a few tenths of a nanometer. The speed (c)
of the ultrasound wave through tissue is determined by the tissue density (q) and
compressibility (j) values:
c 5
1ﬃﬃﬃﬃﬃﬃ
jq
p
:
ð4:1Þ
Equation (4.1) shows that the more rigid the tissue and/or the less dense the
tissue, the higher the ultrasound propagation velocity. Table 4.1 shows that the
value of c in most soft tissues is approximately 1540 m/s. The values in bone and
air (e.g. lungs) represent the two extremes due to highly disparate density and
compressibility.
The particle velocity (uz) along the direction of energy propagation (denoted
as the z-direction here) is given by the time derivative of the particle
displacement:
uz 5 dW
dt :
ð4:2Þ
z direction
Pressure
compressional
pressure (pc)
rarefactional
pressure (pr )
Figure 4.2
The effect of the passage of an ultrasound wave on the displacement of the molecules within tissue.
The maximum positive pressure of the wave corresponds to the maximum compressional force,
pushing the molecules together. The corresponding maximum negative pressure represents a
rarefactional force.
147
4.2 Wave propagation and characteristic acoustic impedance

The value of uz is approximately 0.01 m s21, and is much lower than the value of
c. The pressure (p), measured in pascals (Pa), of the ultrasound wave at a particular
point in the z-direction is given by:
p 5 qcuz:
ð4:3Þ
Positive pressure corresponds to compressional forces and negative pressure to
rarefactional forces, as shown in Figure 4.2. A particularly important parameter in
ultrasound imaging is the characteristic acoustic impedance (Z) of tissue, which is
deﬁned as the ratio of the pressure to the particle velocity:
Z 5 p
uz
:
ð4:4Þ
This equation can be considered as a direct analogue to Ohm’s law in an
electrical circuit. A voltage driving force produces a current, with the ratio between
the two quantities being determined by the circuit impedance. Therefore, the
complementary physical constants are voltage/pressure, current/particle velocity,
and impedance/characteristic impedance. The value of Z is determined by the
physical properties of the tissue:
Z 5 qc 5 q
1ﬃﬃﬃﬃﬃﬃ
qj
p
5
ﬃﬃﬃq
j
r
:
ð4:5Þ
Table 4.1 also lists values of Z for tissues relevant to clinical ultrasound
imaging. The values of Z for many soft tissues are very similar to one another,
with again the two major differences being for lung tissue (air) and bone which
have much lower and higher values, respectively. The next section explains how
the Z values affect the propagation of ultrasound energy through the body.
Table 4.1: Acoustic properties of biological tissues
Z 3 105
(g cm22 s21)
Speed of sound
(m s21)
Density
(gm23)
Compressibility x1011
(cm g21 s2)
Air
0.00043
330
1.3
70 000
Blood
1.59
1570
1060
4.0
Bone
7.8
4000
1908
0.3
Fat
1.38
1450
925
5.0
Brain
1.58
1540
1025
4.2
Muscle
1.7
1590
1075
3.7
Liver
1.65
1570
1050
3.9
Kidney
1.62
1560
1040
4.0
148
Ultrasound imaging

Example 4.1
Given the values of c = 1540 m s21 and q = 1.05 g cm23 for brain tissue, calculate
the values of the characteristic acoustic impedance and compressibility.
Solution
The characteristic impedance of brain tissue is given by:
Z 5 qc 5 1:05ðg cm3Þ 3 154000ðcm s1Þ 5 1:58 3 105g cm2s1:
From Equation (4.5), Z2 = q/j and so:
j 5 q=Z2 5 1:05ðg cm3Þ=ð1:58 3 105Þ2g2 cm4s2
5 4:2 3 1011 cm g1s2:
Using the SI deﬁnition of 1 Pascal (Pa) as 1 kg m21 s22, which is equivalent to
10 g cm21 s22, the units of compressibility are the same as inverse pressure.
4.3
Wave reﬂection, refraction and scattering in tissue
As the ultrasound beam passes through tissue it encounters different tissues with
different acoustic properties, as shown in Table 4.1. Whenever either a boundary
between two tissues, or small structures within a homogeneous tissue, are encoun-
tered the differences in acoustic properties result in a fraction of the energy of the
ultrasound beam being backscattered towards the transducer, where it forms the
detected signal.
4.3.1 Reﬂection, transmission and refraction at tissue boundaries
When an ultrasound wave encounters a boundary between two tissues with differ-
ent values of Z, a certain fraction of the wave energy is backscattered (or reﬂected)
towards the transducer, with the remainder being transmitted through the boundary
deeper into the body. In the ﬁrst case considered here, the boundary is shown in
Figure 4.3 as being ﬂat, implying that its dimensions are much greater than the
ultrasound wavelength, for example  1 mm for a 1.5 MHz central frequency. In
the general situation shown in Figure 4.3, the incident ultrasound wave strikes the
boundary at an angle hi.
The following equations relate the angles of incidence (hi) and reﬂection (hr),
angles of incidence (hi) and transmission (ht), reﬂected (pr) and transmitted (pt)
pressures, and reﬂected (Ir) and transmitted (It) intensities:
149
4.3 Wave reﬂection, refraction and scattering in tissue

hi 5 hr;
ð4:6Þ
sinhi
sinht
5 c1
c2
;
ð4:7Þ
Rp 5 pr
pi
5 Z2 coshi  Z1 cosht
Z2coshi 1 Z1cosht
;
ð4:8Þ
Tp 5 pt
pi
5
2Z2 coshi
Z2 coshi 1 Z1 cosht
;
ð4:9Þ
RI 5 Ir
Ii
5 ðZ2 coshi  Z1 coshtÞ2
ðZ2 coshi 1 Z1 coshtÞ2 ;
ð4:10Þ
TI 5 It
Ii
5
4Z2Z1 cos2hi
ðZ2 coshi 1 Z1 coshtÞ2 :
ð4:11Þ
The values of the reﬂection and transmission pressure coefﬁcents are related by:
Tp 5 Rp 1 1;
ð4:12Þ
with the corresponding values of intensity reﬂection coefﬁcients given by:
TI 5 1  RI
j
j2:
ð4:13Þ
transmitted
wave
backscattered
wave
incident
wave
Z1, c1,
1,
1
i
r
t
Z2, c2,
2,
2
tissue 1
tissue 2
Figure 4.3
Showing the behaviour of an ultrasound beam when it strikes the boundary between two tissues with
different acoustic properties. A certain fraction of the wave is backscattered/reﬂected back towards
the transducer, with the remaining fraction being transmitted through the boundary deeper into tissue.
150
Ultrasound imaging

Equation (4.7) shows that the values of hi and ht are very similar, except in the
case of the wave encountering a tissue/bone or tissue/air interface in which case a
signiﬁcant deviation in the trajectory of the beam will occur. This produces a
geometric artifact in the images in which tissues appear slightly displaced com-
pared to their actual physical location within the body.
The strongest reﬂected signal is received if the angle between the incident wave
and the boundary is 90. In this case, Equations (4.8–4.11) reduce to:
Rp 5 pr
pi
5 Z2  Z1
Z2 1 Z1
;
ð4:14Þ
Tp 5 pt
pi
5
2Z2
Z2 1 Z1
;
ð4:15Þ
RI 5 Ir
Ii
5 R2
p 5 ðZ2  Z1Þ2
ðZ2 1 Z1Þ2 ;
ð4:16Þ
TI 5 It
Ii
5
4Z1Z2
ðZ1 1 Z2Þ2 :
ð4:17Þ
The backscattered signal detected by the transducer is maximized if the value of
either Z1 or Z2 is zero. However, in this case the ultrasound beam will not reach
structures that lie deeper in the body. Such a case occurs, for example, in GI tract
imaging if the ultrasound beam encounters pockets of air. A very strong signal is
received from the front of the air pocket, but there is no information of clinical
relevance from any structures behind the air pocket. At the other extreme, if Z1 and
Z2 are equal in value, then there is no backscattered signal at all and the tissue
boundary is essentially undetectable. Using values of Z in Table 4.1 and the reﬂec-
tion and transmission equations, it can be seen that, at boundaries between soft
tissues, the intensity of the reﬂected wave is typically less than 0.1% of that of the
incident wave.
Example 4.2
Calculate the angle of refraction for ultrasound with an incident angle of 20
striking the interface between lipid and muscle.
Solution
Using Equation (4.7), the angle can be calculated from:
sin 20
sinht
5 1450
1590 ;
which gives a value of ht of 22.
151
4.3 Wave reﬂection, refraction and scattering in tissue

It is instructive to consider the values of Rp, Tp, RI and TI for three cases:
(i) Z1  Z2, e.g. the ultrasound beam travels from tissue into air. The value of Tp
is 0, Ti is 0, RI is 1 and Rp is 21. The negative sign for Rp signiﬁes that the
backscattered pressure wave undergoes a 180 phase shift at the point at
which it encounters the boundary.
(ii) Z1~Z2, e.g. the ultrasound beam encounters a liver/kidney interface. In this
case Tr~1, Rp , 1, TI~1, RI  1. The backscattered signal is small in
amplitude, but most of the ultrasound beam is transmitted through the
boundary and so reaches tissues deeper in the body.
(iii) Z1  Z2, e.g. the ultrasound beam travels from tissue into bone. In this case TI
= 0, RI = 1, Tr = 1 and Rp = 2! The somewhat surprising value of Rp = 2 means
that the pressure at a single point at the boundary is actually twice that of the
incident wave. As in case (i), almost all of the energy is reﬂected back towards
the transducer, except that there is no phase shift.
4.3.2 Scattering by small structures
In contrast to reﬂection and refraction at a tissue boundary which is much larger
than the ultrasound wavelength, if the ultrasound beam strikes structures which
are approximately the same size as, or smaller than, the ultrasound wavelength
then the wave is scattered in all directions. The angular dependence (predom-
inantly forwards, backwards or random) and magnitude of the scattered beam
depend upon the shape, size and physical and acoustic properties (Z, j, q) of the
structure. If the size of the scattering body is small compared to the wavelength,
then scattering is relatively uniform in direction, with slightly more energy being
scattered back towards the transducer than away from it. In this size regime,
referred to as Rayleigh scattering and shown in Figure 4.4, the amount of
scattered energy increases as the fourth power of frequency. An example is
the scattering of ultrasound by red blood cells, which have a diameter of the
order of 5–10 lm. Since the red blood cells are very close to one another, as
shown in Figure 4.4 (b), scattering patterns from individual red blood cells add
constructively. This phenomenon is the basis of Doppler ultrasound, covered in
Section 4.10, which is an extremely important method of measuring blood ﬂow
in many clinical diagnostic protocols. In contrast, if the scattering structures are
relatively far apart, as shown in Figure 4.4 (c), then the resulting pattern is a
complicated combination of constructive and destructive interference, known as
speckle. Although speckle does have some information content, in general it is
152
Ultrasound imaging

considered to be an undesirable ‘noise’ component in ultrasound imaging,
and techniques such as compound imaging (covered in Section 4.8.4) have
been designed to reduce its contribution. Figure 4.4 shows an ultrasound image
which shows examples of both distinct tissue boundaries and speckle within
tissue.
4.4
Absorption and total attenuation of ultrasound energy in tissue
As an ultrasound beam passes through the body, its energy is attenuated by a
number of mechanisms including reﬂection and scatter as covered in the previous
section, and absorption covered next. The net effect is that signals received from
tissue boundaries deep in the body are much weaker than those from boundaries
which lie close to the surface.
a
b
c
d
Figure 4.4
(a) Rayleigh scattering of an ultrasound beam by a structure which is physically small compared to the
wavelength of the ultrasound beam. (b) Scattering from several structures which are close together
produces scattered waves which add constructively. (c) Scattering structures which are relatively far
from one another produce scattering patterns which add constructively at certain locations and
destructively at others, thus producing areas of high and low image intensity, as illustrated in the
image in (d).
153
4.4 Absorption and total attenuation of ultrasound energy

4.4.1 Relaxation and classical absorption
In addition to backscattering from boundaries and small structures, the intensity of
the ultrasound beam is reduced by absorption, which converts the energy of the
beam into heat. There are two mechanisms by which such energy absorption takes
place in biological tissue. The more important is termed ‘relaxation absorption’.
Different tissues have different elastic properties, which can be quantitatively
described by a relaxation time (s), which characterizes the time that structures
within the tissue require to return to their equilibrium position after having been
displaced (either compressed or rarefacted) by the ultrasound wave. As an exam-
ple, shown in Figure 4.2, consider that the positive component of the pressure
wave moves the particles to the right, whereas the negative component of the
pressure wave moves them in the opposite direction. After passage of the max-
imum positive component of the pressure wave, the elastic forces within the tissue
pull the particles back towards the left. If the relaxation time is such that this
motion coincides with the passage of the maximum negative pressure (which also
moves the particles to the left), then these two forces act constructively and rela-
tively little energy is extracted from the ultrasound beam. In contrast, if the relax-
ation time is such that the restoring elastic forces are moving the particle to the left
at the same time as the passage of the next positive pressure maximum, which tries
to move the particle to the right, then a much larger amount of energy is lost from
the beam. A useful analogy is that of pushing a swing: the minimum energy
required occurs when one pushes in the same direction that the swing is moving
at the lowest point of its trajectory (when the velocity is highest), and the maximum
energy required corresponds to the same point in its trajectory but when it is
travelling in the opposite direction.
The relaxation process is characterized by a relaxation absorption coefﬁcient, br,
which is given by:
br 5
B0f2
1 þ

f fr
. 2
:
ð4:18Þ
A graph of br as a function of frequency is shown in Figure 4.5, with a maximum
value at fr, the relaxation frequency, which is equal to 1/s. Higher values of br
correspond to more energy being absorbed in the body. In reality, tissue contains a
broad range of values of s and fR, and the overall absorption coefﬁcient is propor-
tional to the sum of all the individual contributions:
br;tissue } +
n
f2
1 1

f=fr;n
2
:
ð4:19Þ
154
Ultrasound imaging

Measured values of absorption in many tissues have shown that there is an
almost linear relationship between the total absorption coefﬁcient and ultrasound
operating frequency, as shown in Figure 4.5.
There is a second, less important, mechanism for energy absorption called
classical absorption. This effect is caused by friction between particles as they
are displaced by the passage of the ultrasound wave. This loss is characterized by
an absorption coefﬁcient, bclass, which is proportional to the square of the operating
frequency. The overall absorption coefﬁcient is a combination of relaxation and
classical absorption, but in biological tissues at clinical frequencies, the former
mechanism is dominant.
4.4.2 Attenuation coefﬁcients
Attenuation of the ultrasound beam as it propagates through tissue is the sum of
absorption and scattering from small structures. Attenuation is characterized by an
exponential decrease in both the pressure and intensity of the ultrasound beam as a
function of its propagation distance, z, through tissue:
I z
ð Þ 5 I z 5 0
ð
Þelz
pðzÞ 5 p z 5 0
ð
Þeaz ;
ð4:20Þ
where l is the intensity attenuation coefﬁcient and a is the pressure attenuation
coefﬁcient, both measured in units of cm21. The value of l is equal to twice that of
a. The value of l is often stated in units of decibels (dB) per cm, where the
conversion factor between the two units is given by:
frequency
fr1
r
fr2 fr3 fr4 fr5 fr6
frequency
r
fr
Figure 4.5
Plots of the relaxation absorption coefﬁcient, br, for a completely homogeneous tissue (left) and for a
realistic tissue (right) in which there are many relaxation frequencies. The overall absorption coefﬁcient
increases linearly with frequency.
155
4.4 Absorption and total attenuation of ultrasound energy

l dB cm1


5 4:343l cm1


:
ð4:21Þ
A useful rule-of-thumb is that each 3 dB reduction corresponds to a reduction in
intensity by a factor of 2. So a 6 dB reduction corresponds to a factor of 4, a 9 dB
reduction to a factor of 8 and so on.
The frequency dependence of l for soft tissue is 1 dB cm21 MHz21, i.e. at
2 MHz the attenuation coefﬁcient is 2 dB cm21. For fat the attenuation coefﬁcient
is given approximately by 0.7f1.5 dB. The values of the attenuation coefﬁcient
for air and bone are much higher, 45 dB cm21MHz21 and 8.7 dB cm21 MHz21,
respectively.
Example 4.3
The intensity of a 3 MHz ultrasound beam entering tissue is 10 mW/cm2. Calculate
the intensity at a depth of 4 cm.
Solution
The attenuation coefﬁcient is 1 dB cm21 MHz 21, and so has a value of 3 dB cm21
at 3 MHz. At a depth of 4 cm, the attenuation is 12 dB, which corresponds to a
factor of 16. So the intensity of the beam is 0.625 mW/cm2.
4.5
Instrumentation
A block-diagram of the basic instrumentation used for ultrasound imaging is
shown in Figure 4.6. The input signal to the transducer comes from a frequency
generator. The frequency generator is gated on for short time durations and then
gated off, thus producing short periodic voltage pulses. These pulsed voltage
signals are ampliﬁed and fed via a transmit/receive switch to the transducer. Since
the transducer both transmits high power pulses and also receives very low inten-
sity signals, the transmit and receive circuits must be very well isolated from each
other; this is the purpose of the transmit/receive switch. The ampliﬁed voltage is
converted by the transducer into a mechanical pressure wave which is transmitted
into the body. Reﬂection and scattering from boundaries and structures within
tissue occur, as described previously. The backscattered pressure waves reach
the transducer at different times dictated by the depth in tissue from which they
originate, and are converted into voltages by the transducer. These voltages have
relatively small values, and so pass through a very low-noise preampliﬁer before
being digitized. Time-gain compensation (Section 4.7.5) is used to reduce the
dynamic range of the signals, and after appropriate further ampliﬁcation and
signal processing, the images are displayed in real time on the computer monitor.
156
Ultrasound imaging

Additional circuitry in both the transmit and receive channels is required
when using phased array transducers, and this is covered in Sections 4.7.3 and
4.7.4.
4.6
Single element ultrasound transducers
Although the vast majority of transducers consist of a large array of small elements,
it is useful to consider ﬁrst the properties of a single element transducer, shown
schematically in Figure 4.7. Shaped piezoelectric material is the active element of
all ultrasound transducers, and is formed from a composite of lead zirconate
titanate (PZT). Fine powders of the three metal oxides are mixed and then heated
to high temperatures ( . 120 C) and placed in a strong electric ﬁeld, with a value
of tens of kV per cm. This ﬁeld aligns the dipoles within the material, and confers
the property of being piezoelectric, i.e. able to convert an oscillating voltage to
changes in physical dimension, and vice versa. Thin rods of PZT are embedded in
a resin, and the material is then formed into the required shape and size. In the case
of a single element transducer, the element is usually disk-shaped or formed into a
spherical or cylindrical shell. The two faces of the element are coated with a thin
layer of silver and connected via bonding wires to a coaxial cable leading to the
Tx/Rx
switch
Time-gain
compensation
logarithmic
compression
Analogue-to-digital
converter
Real-time
display
transducer
Figure 4.6
The major elements of a basic ultrasound imaging system.
157
4.6 Single element ultrasound transducers

transmit-receive switch. Examples of ﬂat and curved PZT elements are shown in
Figure 4.7.
When an oscillating voltage is applied to one face of the piezoelectric element,
its thickness oscillates at the same frequency as the applied voltage, with the
change in thickness being proportional to the magnitude and polarity of this
voltage up to the maximum displacement of the transducer (a higher driving
voltage can cause damage). Placing the element in physical contact with a patient’s
skin transfers the mechanical motion of the piezoelectric element into a pressure
wave which is transmitted into the body.
The element has a natural resonant frequency (f0) corresponding to its thickness
(t) being one-half of the wavelength of ultrasound in the crystal
t 5 kcrystal
2
5 ccrystal
2f0
0 f0 5 ccrystal
2t
:
ð4:22Þ
The value of ccrystal in a PZT crystal is approximately 4000 m s21, and so the
thickness of a crystal for operation at 3 MHz is ~1.3 mm.
As shown in Equation (4.10), the larger the difference in the characteristic
acoustic impedance of two materials, the greater the intensity of the reﬂected wave
from the boundary between the two. A PZT-based transducer has a Z value of
~30 3 105 g cm22 s21, compared to the value of skin/tissue of ~1.7 3 105 g
cm22 s21. Therefore, without some modiﬁcations, there would be a large amount
of energy reﬂected from the patient’s skin, and the efﬁciency of coupling the
mechanical wave into the body would be very low. To improve this efﬁciency,
epoxy
backing
material
matching
layer
PZT-4
voltage
source
amplifier
Figure 4.7
(left) A transducer with a ﬂat PZT element. (right) Flat and hemispherical PZT elements.
158
Ultrasound imaging

a ‘matching layer’ is added to the external face of the crystal to provide acoustic
coupling between the crystal and the patient. Intuitively, one can imagine that the
value of Z of this matching layer (Zmatching layer) should be intermediate between
that of the transducer element (ZPZT) and the skin (Zskin). In fact the value is given
by the geometric mean of the two Z-values (see Exercise 4.7):
Zmatching layer 5
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ZPZTZskin
p
:
ð4:23Þ
The thickness of this matching layer should be one-quarter of the ultrasound
wavelength, to maximize energy transmission through the layer in both directions
(see Exercise 4.10). Although the matching layer improves the transmission
efﬁciency (and also reception) it does not provide 100% efﬁciency, and so many
manufacturers use multiple matching layers to increase the efﬁciency further.
As shown in Figure 4.7, the PZT element is mechanically coupled to a damping
layer consisting of a backing material and epoxy. In ultrasound imaging a number
of short pulses of ultrasound energy are sent into the body. As covered later in
Section 4.6.3, the axial spatial resolution (i.e. along the direction of the ultrasound
beam) is proportional to the total length of the ultrasound pulse, and so a short
pulse is required for good spatial resolution. The output of the frequency generator
is gated on for a short period of time, typically comprising two to three cycles of
the particular frequency for each pulse. If no mechanical damping is used, then the
PZT element will ‘ring’ after the end of the voltage pulse, thus producing a pulse of
ultrasound energy which is much longer than the applied voltage pulse, as shown
in Figure 4.8, resulting in poor axial resolution. A familiar analogy would be the
long sound produced from a single strike of a bell. Adding some mechanical
damping reduces the length of the sound. A similar effect is achieved in an ultra-
sound transducer. Efﬁcient damping is also important in terms of achieving a large
frequency bandwidth, as covered in the next section. Materials used for damping
are usually based on epoxies ﬁlled with small aluminium oxide particles.
4.6.1 Transducer bandwidth
Even though a transducer is speciﬁed to have a central frequency, the bandwidth of
modern transducers is extremely large, as shown in Figure 4.9. For example, a
transducer with a central frequency (f0) of 3 MHz can often cover a frequency
bandwidth of 1–5 MHz. This means that, rather than having to have several trans-
ducers operating at, for example 2,3,4 and 5 MHz, one can use a single transducer
for many applications. As shown later in Section 4.11.2, the very wide bandwidth
also means that applications in which the signal is transmitted at one frequency but
159
4.6 Single element ultrasound transducers

Pressure wave 
low transducer damping
On
time
Pressure wave 
high transducer damping
Frequency 
generator
Gating signal
1/PRR
Voltage pulse
Off
Figure 4.8
Voltage pulses are applied to the face of the piezoelectric element by gating the output of a frequency
generator. The pulses are produced at a certain rate, termed the pulse repetition rate (PRR). A
transducer with low mechanical damping produces a pressure wave which lasts considerably longer
than the driving voltage pulse. Increasing the mechanical damping (bottom row) reduces the duration
of the pressure wave.
f0
2f0
sensitivity
frequency
bandwidth
Figure 4.9
Sensitivity vs. frequency for a broadband transducer. The bandwidth corresponds to the frequency
range over which the sensitivity is greater than one-half of the maximum sensitivity. Note that the
bandwidth can be larger than the value of f0 itself.
160
Ultrasound imaging

received at the second harmonic frequency (2f0) can be performed using a single
transducer, rather than having to use two different transducers. The higher the
mechanical damping, the larger is the bandwidth of the transducer. Recent devel-
opments in materials engineering have resulted in, for example, the PZT being
grown as small, oriented crystals (as opposed to small particulates being embedded
in a polymer matrix) and this has increased the efﬁciency and bandwidth of
transducers. The relationship between central frequency and bandwidth is usually
quantiﬁed in terms of a quality (Q) factor, deﬁned as the ratio of the central
frequency to the bandwidth. Very low values of Q ~1–2 produce very high
bandwidths.
4.6.2 Beam geometry and lateral resolution
The two-dimensional beam proﬁle from a transducer with a single ﬂat piezoelectric
crystal is shown in Figure 4.10.
The wave pattern very close to the transducer face is extremely complicated,
with many areas in which the intensity falls to zero, and so this region is not useful
for diagnostic scanning. This region is termed the near-ﬁeld, or Fresnel, zone.
Beyond this zone, the ultrasound beam does not oscillate in intensity but rather
decays exponentially with distance: this is termed the far-ﬁeld or Fraunhofer zone.
The boundary between the two zones, termed the near-ﬁeld boundary (NFB),
occurs at a distance (ZNFB) from the transducer face given by:
1
2
3
I
Figure 4.10
Lateral and axial beam patterns from a single element transducer.
161
4.6 Single element ultrasound transducers

ZNFB  r2
k ;
ð4:24Þ
where r is the radius of the transducer, and k is the wavelength of the ultrasound
in tissue. At the NFB, the ﬁeld has a lateral beamwidth which is approximately
equal to the diameter of the transducer. Beyond the NFB, the beam diverges in the
lateral direction, with the angle of deviation (h, shown in Figure 4.10) given by:
h 5 arcsin 0:61k
r


:
ð4:25Þ
Example 4.4
Calculate the position of the NFB for a transducer operating at 3 MHz, with a
crystal diameter of 1 cm. What is the approximate beam width at a distance of 10
cm from the transducer surface?
Solution
Assuming that the speed of sound in tissue is 1540 m/s, the wavelength of a 3 MHz
pulse of ultrasound is 1540/(33106) = 5.1331024 m ~0.05 cm. Therefore, the
position of the NFB is ~(0.25/0.05) ~5 cm from the tranducer surface.
The divergent angle from Equation (4.25) is given by:
h ¼ arcsin 0:61k
r


¼ arcsin 0:61c
rf


¼ arcsin
0:61  1540ms1
0:005m  3 3 106s1


 3:6:
If one assumes that the beamwidth at the NFB is 1 cm, then the beamwidth at a
distance of 10 cm (5 cm from the NFB) is given by:
1 þ 5 tan 3:6o
ð
Þ  1:31 cm:
In the far-ﬁeld, Figure 4.10 shows that the lateral beam shape is approximately
Gaussian. The lateral resolution is deﬁned as the FWHM which is given by:
FWHM 5 2:36r;
ð4:26Þ
where r is the standard deviation of the Gaussian function.
It should also be noted that side-lobes are also produced by a single element
transducer, with the ﬁrst zero of the side-lobe present at an angle u given by:
u ¼ arcsin 0:61k
r


:
ð4:27Þ
These side-lobes can introduce artifacts into an image if the lobes are back-
scattered from tissue which is outside the region being studied.
162
Ultrasound imaging

4.6.3 Axial resolution
The axial resolution refers to the closest distance that two boundaries can lie in a
direction parallel to the beam propagation and still be resolved as two separate
features rather than as one ‘combined’ structure. The axial resolution has a value
given by:
Axial resolution 5 1
2 pdc:
ð4:28Þ
where pd is the pulse duration (in seconds). The value of the axial resolution is
therefore equal to one half the pulse length. A graphical explanation of the relation-
ship is given in Figure 4.11, which shows a single RF pulse of three cycles being
transmitted through tissue. The two different reﬂected signals from boundaries 1
and 2 are just resolvable (i.e. not overlapping) if the distance between the two
boundaries is one-half the pulse length, as it is set to be in Figure 4.11.
Typical values of axial resolution are 1.5 mm at a frequency of 1 MHz, and 0.3
mm at 5 MHz. However, attenuation of the ultrasound beam increases at higher
frequencies (1 dB cm21 MHz21), and so there is a trade-off between penetration
depth and axial spatial resolution. High frequency ultrasound transducers can
produce very high resolution, but imaging can only be performed close to the
surface. For example, frequencies of 40 MHz can be used for high resolution skin
imaging, and investigating surface pathologies such as melanomas. The axial
resolution can also be improved by increasing the degree of transducer damping.
Finally, it should be noted that transducers with high bandwidth provide both
low frequencies for better penetration, and high frequencies for better spatial
resolution.
4.6.4 Transducer focusing
Since a single ﬂat element transducer has a relatively poor lateral resolution, trans-
ducers are focused to produce a ‘tighter’ ultrasound beam. There are two basic
methods to produce a focused transducer: either a concave lens constructed of
plastic can be placed in front of the piezoelectric element, or else the face of the
element itself can be manufactured as a curved surface as shown in Figure 4.7
(bottom right). The shape of the curvature is deﬁned in terms of an f-number (f#):
f# 5
focal distance
aperture dimension ;
ð4:29Þ
163
4.6 Single element ultrasound transducers

where the aperture dimension corresponds to the size of the element. The point
at which the ultrasound beam is focused, i.e. at which the lateral beamwidth is most
narrow, is termed the focal point and lies at a distance called the focal distance (F)
away from the face of the transducer. Except for very strongly focusing trans-
ducers, with highly curved surfaces, one can approximate the focal distance to be
the same as the radius of curvature of the lens or PZT element.
As is the case for a ﬂat transducer, the lateral resolution of a focused transducer is
improved the higher the operating frequency. In addition, a smaller diameter curved
transducer focuses the beam to a tighter spot than a larger diameter transducer. The
lateral resolution is given by kF/D, where D is the diameter of the transducer.
wave strikes
boundary 1
wave reflected
from boundary 1
wave transmits
through boundary 1
trailing edge of waves
continues to travel
towards boundary 1
wave reflected
from boundary 1
wave transmits
through boundaries 1 & 2
waves transmits
through boundary 1
wave reflected
from boundary 2
wave reflected
from boundary 1
wave transmits
through boundaries 1 & 2
wave reflected
from boundary 2
t0
2
1
t0+ t
2
1
t0+2 t
2
1
t0+3 t
2
1
Figure 4.11
Two boundaries (1 and 2) are separated by one-half of the length of a pulse of ultrasound transmitted
into the body from a transducer. The echoes from the two boundaries (bottom diagram) are just
distinguishable, since they do not overlap in time. If the two boundaries were separated by a smaller
distance, then the two returning echoes could not be resolved and the two boundaries would be
represented by one very thick feature.
164
Ultrasound imaging

Choosing the focusing power of the transducer is a compromise between the highest
spatial resolution and the depth over which a reasonable spatial resolution can be
achieved. This is illustrated in Figure 4.12, which shows a weakly-focused trans-
ducer on the left, and a strongly-focused one on the right. The disadvantage of a
strongly-focused transducer is clear: at locations away from the focal plane the
beam diverges much more sharply than for the weakly-focused transducer. This
is quantiﬁed via the on-axis depth-of-focus (DOF), which is deﬁned to be the
distance over which the beam intensity is at least 50% of its maximum value.
4.7
Transducer arrays
Single element arrays for imaging have been superseded by large arrays compris-
ing many small piezoelectric elements [1]. These arrays enable two-dimensional
images to be acquired by electronically steering the ultrasound beam through the
patient, while the operator holds the transducer at a ﬁxed position. Sophisticated
electronics are used to produce a dynamically changing focus both during pulse
transmission and signal reception, which results in high spatial resolution through-
out the image. There are two basic types of array transducer, linear and phased.
Depth-of-focus
Lateral
resolution
Lateral
resolution
Depth-of-focus
Figure 4.12
The trade-off between depth-of-focus and lateral resolution for a weakly-focused (left) and strongly-
focused (right) single element transducer. A better lateral resolution is accompanied by a smaller
depth-of-focus, and vice versa.
165
4.7 Transducer arrays

4.7.1 Linear arrays
A linear array consists of a large number, typically 128–512, of rectangularly
shaped piezoelectric elements. The space between elements is termed the kerf,
and the distance between their centres is called the pitch, shown in Figure 4.13.
Each element is unfocused, and mechanically and electrically isolated from its
neighbours: mechanical isolation is achieved by ﬁlling each kerf with acoustic
isolating material. The size of the pitch in a linear array ranges from k/2 to 3k/2,
where k is the ultrasound wavelength in tissue. Overall, a linear array is usually ~1
cm in width and 10–15 cm in length: an example is shown in Figure 4.13.
The mode of operation of a linear array is shown in Figure 4.14. A small number
of elements are ‘excited’ by separate voltage pulses to produce one beam of ultra-
sound entering the tissue. To provide a degree of focusing, the individual elements
within this subgroup are excited at slightly different times, with the outer ones
excited ﬁrst and the inner ones after a certain delay. This produces a curved
wavefront which focuses at an effective focal point. When all of the backscattered
echoes from this ultrasound pulse have been acquired, a second beam is sent out by
exciting a different subset of elements, as shown in the centre of Figure 4.14. The
sequential excitation of elements is continued until all such groups have been
excited. If an even number of elements is used for each subgroup, then the process
can be repeated using excitation of an odd number of elements to produce focal
Figure 4.13
Design and operation of a linear array. (left) A large number of rectangular piezoelectric elements form
a one-dimensional array. Each element is connected by a small coaxial cable to the voltage source.
(centre) A commercial linear array, with the dashed lines showing the ultrasound beams that are sent
out sequentially from left-to-right. (right) A two-dimensional ultrasound image acquired using a linear
array.
166
Ultrasound imaging

points at locations between those acquired previously. In this fashion, almost twice
as many scan lines as there are transducer elements can be formed. It should be
noted that, although focusing can be achieved in one-dimension, the direction
perpendicular to the image plane, the so-called elevation plane, cannot be focused.
Therefore, many arrays have a curved lens to produce a focus in this dimension.
Linear arrays are used when a large ﬁeld-of-view is required close to the surface of
the array, and are a mainstay of musculoskeletal applications, for example.
4.7.2 Phased arrays
Phased arrays are much smaller than linear arrays, typically 1–3 cm in length and
1 cm wide, with fewer elements, each element being less than 1 mm in width:
an example is shown on the left of Figure 4.15. Phased arrays are widely used
in applications in which there is a small ‘acoustic window’, e.g. where there is only
a small part of the body through which the ultrasound can enter without
time
time
time
3 e
nil e
g
a
m
i
2 e
nil e
g
a
m
i
1
 e
nil e
g
a
m
i
Figure 4.14
Operation of a linear array. Sequential excitation of a small subgroup of the elements is used to
produce a series of ultrasound lines which lie parallel to one another, and thus the image is built-up
sequentially. Application of voltage pulses which are slightly delayed in time with respect to one
another produces an effective focused beam for each line.
167
4.7 Transducer arrays

encountering bone or air. An example is in cardiac imaging in which the ultrasound
must pass between the ribs to avoid large reﬂections from the bone. Very small
arrays can also be constructed for transoesophageal probes, which are also used in
cardiac studies: an example is shown on the right of Figure 4.15.
4.7.3 Beam-forming and steering via pulse transmission for phased arrays
The basic operation of a phased array is shown in Figure 4.16. For each line in the
image every element in the array is excited by voltage pulses which are applied at
Figure 4.15
Images from (left) a conventional phased array and (right) a transoesophageal phased array.
168
Ultrasound imaging

slightly different times. The sum of all of the individual waves from each small
element makes an effective wavefront, a process known as beam-forming. In the
example shown in Figure 4.16, the elements are excited symmetrically with respect
to the centre of the array, and therefore produce a focal point in the tissue half-way
along the length of the array.
To produce afull two-dimensional imagethe beam needs tobe steered, and Figure
4.17 shows how, by changing the timing delays, beam-steering can be achieved.
A process termed ‘dynamic focusing’ or ‘dynamic aperture’ can be used to
optimize the lateral resolution over the entire depth of tissue being imaged, as
shown in Figure 4.18. Initially, using only a small number of elements produces
a small focal point close to the transducer surface. At larger depths, the number of
elements necessary to achieve the best lateral resolution increases. Therefore, in
dynamic focusing the number of elements excited is increased dynamically during
transmission. The advantage of this technique is that very high lateral resolution can
be achieved throughout the entire depth of the scan. The disadvantage is that multi-
ple scans are required to build up a single line in the B-mode image, and therefore
the frame rate is reduced compared to acquiring only one single scan per line.
time
Figure 4.16
Beam-forming during ultrasound transmission. Applying voltage pulses to each individual element of
the array at different times produces a composite wavefront. Applying the voltages symmetrically with
respect to the centre elements, with the top and bottom elements excited ﬁrst, causes the beam to
focus at a point which is half-way along the array.
169
4.7 Transducer arrays

In a phased array, the length of each element deﬁnes the ‘slice thickness’ of the
image in the elevation dimension, and is typically between 2 and 5 mm. If
improved resolution is required in this dimension then, as for a linear array, a
curved lens can be incorporated into the transducer.
time
time
Figure 4.17
Beam steering using phased arrays. By changing the pattern of excitation of all the elements, the
beam can be steered to a point below (left) and above (right) the centre of the array.
time
time
time
a
b
c
Figure 4.18
The process of dynamic focusing involves exciting an increasing number of elements in order to
dynamically focus at different depths within the tissue. First, a small number of elements are used to
acquire signals from very close to the transducer surface. The time required to acquire the
backscattered echoes from such a shallow depth is very short, and so subsequent excitations using a
larger number of elements for focusing at points deeper within tissue can be executed rapidly.
170
Ultrasound imaging

4.7.4 Analogue and digital receiver beam-forming for phased arrays
Using a phased array transducer, the effective focal length and aperture of the
transducer can also be changed dynamically while the signal is being received, a
process termed ‘receiver beam-forming’. This process is essentially the reverse of
dynamic focusing during signal transmission covered in the previous section.
During the time required for the backscattered echoes to return to the transducer,
incremental delays are introduced to the voltages recorded by each element of the
transducer. These delays result in each backscattered signal effectively being ‘in
focus’, as shown in Figure 4.19.
The advent of cheap, fast digital electronics components has enabled much of
the analogue circuitry to be replaced by its digital equivalent, with improvements
in stability and performance. For example, the analogue receiver beam-former
shown in Figure 4.19 can be replaced by a digital one simply by directly digitizing
the signals with an ADC for each channel. In this design, all the data can be stored
digitally, and then any chosen time delays can be introduced in post-processing to
produce signals which add together perfectly coherently. There are, however, some
challenges to the digital approach. For example, many more high-speed analogue-
to-digital converters are needed, and these must be precisely calibrated against
each other. Nevertheless, as in all of the medical imaging devices outlined in this
book, integration of digital electronics into receiver design continues to improve
image quality signiﬁcantly.
time
delay lines
Figure 4.19
The process of receiver beam-forming. Individual echoes from the focal point reach each element in
the array at slightly different times. Summation of the signals at this point would result in partially
destructive interference and signal loss. After ampliﬁcation, each signal is delayed by a time speciﬁed
by the path length from the focal point to the transducer. After passing through the various delay lines,
the signals are now in-phase and so are co-added to produce the maximum signal.
171
4.7 Transducer arrays

4.7.5 Time gain compensation
The summed signals from the receiver beam-former have a large range of ampli-
tudes: very strong signals appear from, for example, reﬂections at fat/tissue boun-
daries close to the transducer, and very weak signals from soft tissue/soft tissue
boundaries much deeper within the body. The total range of signal amplitudes may
be as high as a factor of 100 dB. After beam-forming, the signals are passed
through an ampliﬁer to increase the signal prior to digitization. However, the
ampliﬁers cannot provide linear gain (equal ampliﬁcation) for signals with a
dynamic range greater than about 40–50 dB, and so for a 100 dB dynamic range
the weaker signals would be attenuated or lost completely. Therefore, a process
called time-gain compensation (TGC) is used, in which the ampliﬁcation factor is
increased as a function of time after transmission of the ultrasound pulse. Signals
arising from structures close to the transducer (early returning echoes) are
ampliﬁed by a smaller factor than those from greater depths (later returning ech-
oes). The effect of TGC is to compress the dynamic range of the backscattered
echoes, as shown in Figure 4.20. The slope of the graph of ampliﬁer gain vs. time is
the TGC, which is measured in units of dB per second. TGC is under operator
control and typically has a number of preset values for standard clinical imaging
protocols.
The ﬁnal step before digitizing the signal is rectiﬁcation, i.e. to take the complex
waveform and transform it into a magnitude-mode signal. This is performed via a
quadrature demodulator followed by envelope detection.
raw signal
signal after TGC
TGC
original
dynamic range
dynamic range
after TGC
signal
amplitude
time after
transmitted pulse
Figure 4.20
The effects of time-gain compensation in reducing the dynamic range of the signals received from
close to the transducer surface and deep in tissue.
172
Ultrasound imaging

4.7.6 Multi-dimensional arrays
As outlined in previous sections, one-dimensional phased arrays can focus and
steer the ultrasound beam only in the lateral dimension, with focusing in the
elevation dimension requiring a lens or curved elements. Increasing the dimen-
sionality of the array by adding extra rows of crystals allows focusing in the
elevation dimension, but adds to the complexity of the transducer. If a small
number of rows is added, typically three to ten, then the array is called a 1.5-
dimensional array, and limited focusing in the elevation direction can be achieved.
If a large number of rows is added, up to a value equal to the number of elements in
each row, then this geometry constitutes a true two-dimensional array. Examples
of both 1.5D and 2D arrays are shown in Figure 4.21. The two-dimensional array
Figure 4.21
Multi-dimensional array transducers. (left) A 1.5-dimensional array, with ﬁve elements in the elevation
direction which can be used to focus the beam in this dimension. (upper right) A 50 3 50 two-
dimensional array transducer, which can be used for beam-forming and beam steering in two
dimensions (below right).
173
4.7 Transducer arrays

can be used for full three-dimensional data acquisition, whereas the 1.5-D array
requires mechanical movement in the third dimension. Three-dimensional imaging
is playing an increasingly important role in both foetal and cardiac imaging and
so larger numbers of two-dimensional arrays are now becoming commercially
available.
4.7.7 Annular arrays
Linear and phased arrays are very difﬁcult to construct at very high frequencies
( . 20 MHz) and so a third type of array, the annular array, ﬁnds use at such
frequencies. An annular array is shown schematically in Figure 4.22. This array is
capable of two-dimensional dynamic focusing, and typically has far fewer ele-
ments (5–10) than a linear or regular phased array. Individual rings of piezoelectric
material are formed and kerfs in-between the elements are ﬁlled with acoustically-
isolating material. Beam-forming in both transmit and receive mode is also
extremely simple. The major disadvantage of the annular array is that mechanical
motion must be used to sweep the beam through tissue to form an image, but
highly accurate mechanical units are produced commercially and can be integrated
into the design.
time
time
Figure 4.22
Mode of operation of an annular array. Dynamic focusing can be performed in two-dimensions
simultaneously by varying the time at which each element of the array is excited. Rings of piezoelectric
material (shown in black) are separated from each other by acoustic isolation material.
174
Ultrasound imaging

4.8
Clinical diagnostic scanning modes
There are three basic modes of diagnostic ‘anatomical imaging’ using ultrasound,
A-mode, M-mode and B-mode. Depending upon the particular clinical application,
one or more of these modes may be used. Recent technical advances including the
use of compound imaging and three-dimensional imaging are also described in this
section. The use of ultrasound to measure blood ﬂow in covered in Section 4.10.
4.8.1 A-mode scanning: opthalmic pachymetry
An amplitude (A)-mode scan acquires a one-dimensional ‘line-image’ which plots
the amplitude of the backscattered echo vs. time. The major application is opthal-
mic corneal pachymetry, which is a noninvasive technique for measuring corneal
thickness. A small, high frequency (10–20 MHz) ultrasound probe is placed on the
centre of the cornea after the cornea has been treated with a topical anaesthetic.
Corneal pachymetry is used in chronic conditions such as glaucoma and for pre-
and post-operative evaluation of corneal transplants and refractive surgery. An
example of an A-mode scan is shown in Figure 4.23.
4.8.2 M-mode echocardiography
Motion (M)-mode scanning acquires a continuous series of A-mode lines and
displays them as a function of time. The brightness of the displayed M-mode
signal represents the amplitude of the backscattered echo. The lines are displayed
with an incremental time-base on the horizontal axis, as shown in Figure 4.24.
corneal
thickness
phased array
transducer
Figure 4.23
Use of A-mode ultrasound scanning to measure the corneal thickness of the eye. A single line of high
frequency ultrasound is used, and the one-dimensional signal plot is shown on the right. The double-
headed arrow represents the thickness of the cornea.
175
4.8 Clinical diagnostic scanning modes

Several thousands of lines can be acquired per second, and so real-time display of
dynamic movements is possible. M-mode scanning is used most commonly in
cardiac and foetal cardiac imaging.
4.8.3 Two-dimensional B-mode scanning
Brightness (B)-mode scanning is the most commonly used procedure in clinical
diagnosis and produces a two-dimensional image, such as that shown in Figure 4.1,
through a cross-section of tissue. Each line in the image is an A-mode line, with the
intensity of each echo being represented by the brightness on the two-dimensional
scan. Scanning through the body is achieved using electronic steering of the beam
for linear and phased arrays, or by mechanical motion for annular arrays. As
mentioned earlier, three-dimensional B-mode imaging can be performed using
either a 1.5-D or 2-D phased array transducer.
Example 4.5
An image is to be acquired up to a 10 cm depth. The frame rate is set to 64 Hz, how
many lines can be acquired in the image?
Solution
It takes 130 ls after transmission of the ultrasound pulse for the most distant echo
to return to the transducer. If the image consists of 120 lines, then the total time
to acquire one frame is 15.6 ms and the frame rate is 64 Hz. If the depth-of-view
is increased, then the number of lines must be reduced to maintain the same
frame rate.
transducer
depth
time
Figure 4.24
M-mode data acquisition. The transducer is placed above the heart and sends out a single line of
ultrasound. An A-mode scan is recorded, and as soon as the last echo has been acquired, the A-
mode scan is repeated. The horizontal time-axis increments for each scan, and therefore a time-series
of one-dimensional scans is built up. A straight line represents a structure that is stationary, whereas
the front of the heart shows large changes in position.
176
Ultrasound imaging

4.8.4 Compound scanning
Compound scanning [2] effectively acquires an ultrasound image from multiple
angles and then combines the images together. The multiple angles are achieved
using a phased array with different beam forming schemes. The major advantage
of compound scanning is that it reduces the degree of speckle in the image. Since
the pattern of constructive and destructive interference depends upon the angle of
the incident ultrasound, each separate image has a different contribution from
speckle, but the same ‘true’ features are present in all of the views. As a result,
combination of the images produces a composite image with reduced speckle. An
example of compound scanning is shown in Figure 4.25. A second advantage is
that, in a single view, any boundary or structure with irregular curvature which is
parallel to the beam will not produce a signal. However, by using multiple angles
these structures will give a signal in at least some of the views, and therefore also in
the composite image: this phenomenon is also well-illustrated in Figure 4.25.
Finally, artifacts such as acoustic enhancement or shadowing (Section 4.14) are
reduced. Compound scanning can be integrated with Doppler scans, harmonic
imaging and two-dimensional and three-dimensional imaging. The major disad-
vantage of compound scanning is the increased amount of time that it takes to
acquire the images, meaning that a much lower frame-rate must be used.
A second mode of compound imaging is called frequency compounding. In this
method, multiple frequencies rather than multiple angles are used to construct the
composite image. The appearance of the speckle pattern depends upon the
Figure 4.25
Comparison of a carotid artery bifurcation acquired using a conventional B-mode scan on the left, and
a compound scan with nine different orientations on the right.
177
4.8 Clinical diagnostic scanning modes

frequency, and so does not add constructively between views. The transducer
must, of course, have a large enough bandwidth to cover the frequency range.
4.9
Image characteristics
The major contributing factors to signal-to-noise, spatial resolution and contrast-
to-noise have already been covered, and are summarized brieﬂy here.
4.9.1 Signal-to-noise
The signal intensity of backscattered ultrasound signals is affected by:
(i) The intensity of the ultrasound pulse transmitted by the transducer – the
higher the intensity, the higher the amplitude of the detected signals. The
longer the pulse, also the higher is the signal intensity. The intensity of the
ultrasound pulse is limited by FDA guidelines on the amount of energy that is
safe to use during a scan. This topic is further discussed in Section 4.12.
(ii) The operating frequency of the transducer – the higher the frequency, the
greater the tissue attenuation, and therefore the lower the signal at large depths
within the body.
(iii) The type of focusing used – the stronger the focusing at a particular point, the
higher the energy per unit area of the ultrasound wave, and the higher the
signal at that point. However, outside the depth-of-focus, the energy per unit
area is very low, as is the image SNR.
There are two major sources of noise in ultrasound images. The ﬁrst, speckle,
gives a granular appearance to what should appear as a homogeneous tissue. The
second contribution, termed ‘clutter’, corresponds to signals arising from side-
lobes, grating lobes, multi-path reverberation, and tissue motion. Compound imag-
ing can be used to reduce speckle, and harmonic imaging (covered later in Section
4.11.2) can reduce clutter.
4.9.2 Spatial resolution
(i) Lateral resolution. For a single element transducer, the higher the degree of
focusing the better is the spatial resolution at the focal spot, at the cost of a
reduced depth-of-focus. The higher the frequency, the better is the lateral
resolution for both single element and phased array transducers.
178
Ultrasound imaging

(ii) Axial resolution. The axial resolution is given by one-half the length of the
ultrasound pulse. The higher the degree of damping, or the higher the oper-
ating frequency, the shorter is the pulse and the better the axial resolution.
4.9.3 Contrast-to-noise
Factors which affect the SNR also contribute to the image CNR. Noise sources
such as clutter and speckle reduce the image CNR, especially for small pathologies
within tissue.
4.10
Doppler ultrasound for blood ﬂow measurements
Non-invasive measurements of blood ﬂow are a critical component of diagnosis in
a number of pathological conditions. Ultrasound can measure blood velocity by
taking advantage of the Doppler effect. This effect is familiar in everyday life as,
for example, the higher frequency of an ambulance siren as it approaches than
when it is driving away. The ultrasound signal from blood has its origin in signal
scatter from red blood cells (RBCs), which have a diameter of ~7–10 lm. Blood
ﬂow, either towards or away from the transducer, alters the frequency of the
backscattered echoes compared to the transmitted ultrasound frequency from the
transducer. If blood is ﬂowing towards the transducer the detected frequency is
higher than the transmitted frequency, and vice versa. Phased array transducers can
be used to localize blood ﬂow measurements to a speciﬁed vessel, or region of a
vessel, by acquiring B-mode images. From these B-mode images the vessel size
can be estimated, and measured blood velocities converted into blood ﬂow values.
Blood ﬂow measurements can be very useful in detecting vessel stenoses, and
unusual blood ﬂow patterns.
In the example shown in Figure 4.26, the direction of blood ﬂow is towards the
transducer, and therefore the effective frequency (fi
eff) of the incident ultrasound
beam for the moving RBCs is higher than the actual frequency transmitted (fi):
feff
i
5 c 1 v cosh
k
5 fi c 1 v cosh
ð
Þ
c
:
ð4:30Þ
The same process occurs during signal reception, and so the frequency of the
ultrasound received by the transducer (frec) is given by:
frec 5 feff
i
c 1 v cosh
ð
Þ
c
5 fi c 1 v cosh
ð
Þ2
c2
5 fi 1 2fiv cosh
c
1 fiv2 cos2h
c2
:
ð4:31Þ
179
4.10 Doppler ultrasound for blood ﬂow measurements

The overall increase in frequency, the Doppler shift (fD), is therefore
given by:
fD 5 fi  frec 5 2fivcosh
c
1 fiv2 cos2h
c2
 2fivcosh
c
:
ð4:32Þ
The second term in the Doppler equation is much less than the ﬁrst since
v , , c, and so can be ignored. From Equation (4.32), the blood velocity is given
by:
v 5
cfD
2ficosh :
ð4:33Þ
Using values of fi = 5 MHz, h = 45, and v = 50 cm s21 gives a Doppler
shift of 2.3 kHz. The fractional change in frequency is extremely small, in this
case less than 0.05%. Doppler measurements are typically performed at a rela-
tively high frequency, for example 5 MHz, since the intensity of the scattered
signal is proportional to the fourth power of the frequency. An accurate measure-
ment of blood velocity can only be achieved if the angle h is known and so
B-mode scans are usually acquired at the same time. A ﬁxed error in the value of
h has the smallest effect when h is small, and so in practice values of h of less
than 60 are used by suitable adjustment of the transducer orientation and posi-
tioning.
Ultrasound Doppler blood ﬂow measurements can be performed either in pulsed
wave or continuous wave mode, depending upon the particular application. These
methods are described in the next two sections.
RBCs
V
fi
frec
θ
transducer
Figure 4.26
Showing the origin of the Doppler shift in ultrasound imaging of blood ﬂow. The ultrasound beam is
scattered from the RBCs in a vessel. The backscattered ultrasound beam is detected by the
transducer at a slightly different frequency (frec) from that transmitted (fi) into the body.
180
Ultrasound imaging

4.10.1 Pulsed wave Doppler measurements
The general scheme for acquiring pulsed wave Doppler scans is shown in Figure
4.27. A phased array transducer is used for both pulse transmission and signal
reception. A series of ultrasound pulses, typically 128, are transmitted at a rate
termed the pulse repetitition rate (PRR), which is the inverse of the time (trep)
between successive pulses. Based on a B-mode scan, a region-of-interest (ROI) is
chosen which encompasses the vessel. The returning echoes can be localized to
this region alone by a two-step process which is performed automatically by the
ultrasound system under operator guidance. First, the transducer is focused within
the ROI by appropriate time delays to each element of the array, as described
previously. Second, by choosing the time delay after each ultrasound pulse is
transmitted at which to start the data acquisition, and also the time for which the
receiver is gated open, signals from tissue closer to and further away from the
transducer are not recorded, and the detected signal originates only from the ROI.
In terms of the parameters shown in Figure 4.27, the ROI is deﬁned in terms of its
minimum and maximum depths:
Pulses
Signal
tp
td
tg
trep=1/PRR
depthmin
depthmax
depthmin
depthmax
S1
S2
S3
S4
Figure 4.27
(top) General mode of operation of pulsed mode Doppler imaging. A series of signals S1, S2,. . . . .Sn
are acquired, and processed as shown in Figure 4.28 to estimate the blood ﬂow. (bottom) The
parameters tp, tg and td are chosen to localize the received signal to the desired ROI, deﬁned by the
focal point of the phased array transducer and the minimum and maximum required depths:
shown are examples of obtaining information from a vessel close to the surface (left) and deeper within
the body (right).
181
4.10 Doppler ultrasound for blood ﬂow measurements

depthmin 5 c td  tp


2
depthmax 5 c td þ tg


2
:
ð4:34Þ
Example 4.6
An ROI has been determined to be between 7 and 9 cm deep in the tissue. At what
time should the receiver be turned on after the end of pulse transmission, and for
how long should the receiver be gated on? The ultrasound pulse is 5 cycles at a
central frequency of 5 MHz.
Solution
A train of ultrasound pulses is sent out, each pulse consisting of 5 cycles of
ultrasound at a frequency of 5 MHz, resulting in a 1 ls long pulse. Assuming an
ultrasound velocity of 1540 m/s in tissue, the ﬁrst part of Equation (4.34) gives:
0:07ðmÞ 5 1540ðms1Þ  td  1 3 106


ðsÞ
2
;
from which td = 92 ls. Applying the second part of Equation (4.34):
0:09ðmÞ 5 1540ðms1Þ  92 3 106 þ tg


ðsÞ
2
;
gives a gating-on time of ~25 ls.
Figure 4.28 shows the process of calculating the blood velocity within the ROI
using the pulsed Doppler technique. Signals S1, S2. . . . .Sn shown in Figure 4.27
each have a different phase shift with respect to the ﬁrst transmitted ultrasound
pulse. The amplitude of each time point within the signal is Fourier transformed to
give a spectrum of the Doppler frequencies at each depth within the ROI. The
frequency spectrum can then be converted into a velocity spectrum using Equation
(4.32).
After the data have been processed, a ‘wall-ﬁlter’ is applied to the data to
remove the very low frequency contributions from very slowly moving vessels
or tissue walls. The data are also passed through a quadrature detector so that
positive and negative Doppler frequencies can be differentiated, thus enabling the
direction of ﬂow to be determined unambiguously.
4.10.2 Duplex and triplex image acquisition
A typical Doppler image displays ﬂow information combined with a B-mode scan.
In a duplex scan the Doppler display is a colour-ﬂow image, whereas in triplex
scanning an additional Doppler spectral display is shown. A schematic Doppler
182
Ultrasound imaging

spectral display for a chosen region within a vessel is shown in Figure 4.29. Rather
than a single blood velocity, at any one instant there is a range of velocities (as
shown in Figure 4.28), and this range will change signiﬁcantly over the cardiac
cycle, with higher velocities and a wider velocity spread typically found during
systole. The Doppler spectral display plots the frequencies as a grey-scale image,
with an incremental time-base along the horizontal axis providing a real-time
update.
The second type of Doppler display is colour ﬂow imaging, in which a coloured
map is overlaid on top of the B-mode scan. The colour is either blue or red,
representing ﬂow towards or away from the transducer, with the intensity of the
colour showing the actual velocity. These colour maps are updated in real-time
along with the B-mode scans and Doppler spectral plots. The computational steps
S1
S2
S3
Sn
n
Fourier
transform
Doppler
frequency
amplitude
Figure 4.28
Steps in the production of a Doppler frequency distribution from one particular axial position within the
ROI, determined by the particular time-point in signals S1. . .Sn that is analyzed. In this example a time-
point is chosen at the dashed line. The signals S1, S2 and S3 have slightly different phases with respect
to one another due to ﬂow. A plot of the signals (Sn), taken at the dashed line, as a function of n is
shown at the bottom left. Since the value of n is directly related to the time after the initial RF pulse is
applied, a Fourier transform of the Sn vs. n plot gives the Doppler frequency spectrum shown on the
right. Note that there is, in general, not a single frequency but a mean value with a certain standard
deviation. This process is repeated for each spatial position within the ROI.
183
4.10 Doppler ultrasound for blood ﬂow measurements

involved in producing real time, accurate colour velocity maps are very involved,
and much work has concentrated on different computationally efﬁcient approaches
[3]. At each point in the ROI determined from the B-mode scan the mean fre-
quency is calculated and shown on the colour scale. In some systems, the mean
value is displayed as the colour, with the luminance being representative of the
variance. Other systems add a third colour, usually green, to indicate areas of high
turbulence (detected as a large standard deviation in the ﬂow measurement).
Although triplex imaging, as shown in Figure 4.30, provides the most informa-
tion, it comes at the cost of reduced frame-rates, since all three types of measure-
ment must be performed sequentially. Each measurement requires slightly
different pulse characteristics, and so also has different image characteristics. Flow
imaging requires long ultrasound pulses since the backscattered Doppler signal has
a much lower intensity than the B-mode scan, whereas the B-mode scan uses short
pulses to maintain high axial resolution.
4.10.3 Aliasing in pulsed wave Doppler imaging
The major limitation of pulsed-wave Doppler is that the maximum velocity that
can be measured is limited by the value of the PRR, and if the velocity of the blood
exceeds this value, then it will be displayed as an incorrect value which may even
amplitude
Doppler shift
Doppler shift
amplitude
time
Figure 4.29
A spectral Doppler plot, with the amplitude of each frequency component of the Doppler shift being
reﬂected in the intensity of the plot (white is the highest amplitude). The horizontal axis represents time.
The left-hand plot shows high Doppler shift frequencies corresponding to high blood velocities just
after the heart has reached full contraction and pumped blood into the arteries. The right-hand plot,
which occurs at a later time, shows much lower Doppler shift frequencies, and coincides with the heart
expanding to ﬁll with blood ready for the next contraction.
184
Ultrasound imaging

be opposite in direction to the actual direction of ﬂow. This phenomenon is caused
by signal aliasing, as covered in Section 1.7.2, as shown in the following example.
Example 4.7
A pulsed Doppler scan is acquired with a central frequency of 5 MHz, h value of
0, and a PRR of 1 kHz. There are two regions displayed which have actual blood
velocities 5 cm/s and 10 cm/s. What are the phase shifts between successive signals
for each region? Is there a problem with using this PRR?
Solution
For the component with velocity 5 cm/s the Doppler frequency shift is:
fD 5 2fivcosh
c
5 2  5x106ðs1Þ  0:05ðms1Þ
1540 ms1
ð
Þ
5 325Hz:
A PRR of 1 kHz corresponds to a time between signal acquisitions of 1 ms. The
phase shift between successive signals is therefore:
u 0 
5 325 s1


 1x103 sð Þ  360o 5 1170:
For the second component with velocity 10 cm/s the Doppler frequency shift is
doubled to 650 Hz, and the phase shift to 234. But note that a phase shift of 234 is
the same as one of 2126. This negative phase shift corresponds to a velocity away
from the transducer of 5.5 cm/s. Therefore, the area with the velocity of 10 cm/s
actually appears as one with a negative velocity of 5.5 cm/s.
Figure 4.30
Example of a triplex scan, with greyscale B-mode, colour ﬂow Doppler, and spectral Doppler displays
of the umbilical cord.
185
4.10 Doppler ultrasound for blood ﬂow measurements

It is clear from the above example that signal aliasing occurs when the phase shift
during each delay between successive pulses (1/PRR) is greater than 180. Given
this condition, the maximum Doppler frequency shift (fmax) that can be measured is:
fmax 5
1
2trep
5 PRR
2
:
ð4:35Þ
The corresponding value of the maximum blood velocity, vmax, that can be
measured without aliasing can be derived from Equation (4.32) setting cos h = 1:
vmax 5 cfmax
2fi
5
PRR
ð
Þc
4fi
:
ð4:36Þ
The value of the PRR also determines the maximum depth, dmax, from which
ﬂow can be measured, with a value of dmax given by:
dmax 5 ctrep
2
5
c
2PRR 5
c2
8fivmax
:
ð4:37Þ
If aliasing is suspected in a pulsed-mode Doppler image, the system can be be
turned either to power Doppler mode (described below) or to continuous-wave
Doppler mode, described in Section 4.10.5, to conﬁrm if this is in fact the case.
4.10.4 Power Doppler
Another potential limitation in measuring colour Doppler shifts occurs when a
substantial portion of a vessel lies parallel to the face of the phased array transducer.
In this case, one section of the colour velocity image shows ﬂow towards the trans-
ducer, and the other shows ﬂow away from the transducer. Directly below the trans-
ducer there is an area of very low signal. This effect can be removed by using the
‘power Doppler’ mode [4], in which the area under the magnitude of the Doppler
signal is integrated to give the ‘Doppler power’. In this process both positive and
negative Doppler frequencies give a positive integrated power, and therefore signal
voids are removed. Aliasing artifacts at high ﬂow rates are also eliminated since the
integral of an aliased signal is the same as that of a non-aliased signal. The major
disadvantage with power Doppler is the loss of directional information.
4.10.5 Continuous wave Doppler measurements
CW Doppler measurements can be used when there is no need to localize exactly
the source of the Doppler shifts. Many modern ultrasound systems can acquire
186
Ultrasound imaging

both CW and PW Doppler data using the same phased array transducer. In CW
mode the array is ‘split’ into two sections, one which transmits a continuous pulse
of ultrasound, and the other which receives the backscattered signals. The area in
which blood ﬂow is detected is deﬁned by the overlap of the areas deﬁned by the
transmission and reception beam-forming settings. The measured blood velocity
is the average value over the entire sensitive region. In order to determine the
direction of ﬂow (towards or away from the transducer) a quadrature detector
must be used. The main advantages of CW Doppler over PW Doppler methods
is that the method is neither limited to a maximum depth, nor to a maximum
measurable velocity. As with PW Doppler, a triplex display showing a CW
Doppler image, Doppler spectral plot and B-mode scan is commonly used in
diagnostic scans.
4.11
Ultrasound contrast agents
Contrast agents for ultrasound imaging comprise different types and formulations
of microbubbles or microspheres [5], and are used primarily for echocardiography
and Doppler imaging. In cardiac imaging they can be used for ventricular opaci-
ﬁcation, the assessment of left ventricular volume, systolic function, and delinea-
tion of the endocardial structures. By enhancing the signal intensity of Doppler
ultrasound, they also make possible measurements of blood perfusion in the heart
and other organs such as the liver.
4.11.1 Microbubbles
Currently there are two ultrasound agents, SonoVue and Optison, approved for
worldwide clinical use. SonoVue is a microbubble which is coated with phospho-
lipid monolayers and contains sulphur hexaﬂuoride gas. Optison consists of micro-
bubbles which contain perﬂuoropropane gas within a cross-linked serum albumen
microsphere. The shells of these microbubbles are a few tens of nanometres thick,
the bubble diameter being between 2 and 10 lm, see Figure 4.31. These micro-
spheres are packaged as freeze-dried powders which can be rehydrated in phys-
iological saline solution just before they are to be injected into the patient’s
bloodstream. There are many other types of microbubble in the late stages of
clinical testing, with the main differences being in the particular gaseous core
and exact make-up of the microbubble shell. The reason for needing an outer shell,
rather than simply using a bubble of gas, is that there is a very high surface tension
at the boundary between the microbubble and surrounding liquid: without the
187
4.11 Ultrasound contrast agents

coating, the bubbles would dissolve almost instantaneously after injection into the
bloodstream.
Although it is easy to see that the characteristic impedance of a gas-ﬁlled micro-
bubble is much different from the surrounding tissue or blood, this is not the
principal reason why such agents are so effective. Since the microbubbles are
ﬁlled with a compressible gas, they respond to the propagating ultrasound beam
by compressing (during high pressure periods) and expanding (during low pressure
periods) as shown in Figure 4.32. This means that they absorb much more energy
during compression than would, for example, a relatively incompressible equiv-
alently-sized cell in tissue. This absorbed energy is then re-radiated during expan-
sion, resulting in a strong echo signal returning to the transducer. There is a
‘resonance’ condition which corresponds to the ultrasound frequency at which
the degree of expansion and contraction of the bubble is greatest: this frequency
is determined by the size of the microbubble, as well as the stiffness and thickness
of the polymeric coating. Somewhat fortuitously, the required size for microbub-
bles to pass through the human capillaries ( , 6–7 lm) corresponds to a resonance
frequency within the diagnostic imaging frequency range.
If the ultrasound pressure wave has a high enough intensity, the linear response
shown in Figure 4.32 is replaced by a non-linear one. This behaviour is due to effects
such as the speed of propagation being greater when the bubble is compressed than
when it expands, and also to the fact that the microbubble may distort from a perfect
spherical shape during expansion. The important result is that the pressure wave which
is radiated by the microbubble during expansion is also non-linear in that it contains
not only components at the frequency of the transmitted ultrasound, but also signiﬁ-
cant contributions at higher harmonics of this frequency, as shown in Figure 4.33.
The presence of harmonics makes it possible to distinguish between the ultra-
sound pressure waves that are backscattered from the microbubbles and those from
fluorinated gas
surfactant
monolayer
microbubble
Figure 4.31
A microbubble-based ultrasound contrast agent. The diameter of the microbubble is between 2 and
10 lm. The polymer coating is a few tens of nanometres thick.
188
Ultrasound imaging

the surrounding tissue. As can be seen from Figure 4.33, the signal at 2f0 is the
strongest harmonic and so is the most commonly used. Needless to say, the
bandwidth of the transducer should be large enough so that it can efﬁciently
transmit pulses at f0 and also efﬁciently detect the signal at 2f0.
An extreme version of nonlinear behaviour occurs if the intensity of the incident
ultrasound is high enough to destroy the microbubble. This produces a very strong
backscattered signal and can be used to increase the signal in Doppler imaging, for
example. In this case, the normal Doppler demodulated frequency, Df, is multi-
plied by the particular harmonic that is produced and detected:
f0
f0
2f0
3f0
4f0
e
d
utilp
m
a
e
d
utilp
m
a
frequency
frequency
a
b
Figure 4.33
(a) Frequency spectrum of the ultrasound ﬁeld backscattered from a microbubble when the incident
pressure ﬁeld has a low enough intensity to produce only linear effects of expansion and contraction of
the microbubble. (b) If the incident pressure ﬁeld is much higher, non-linear effects produce harmonics
of the base frequency.
pressure
time
Figure 4.32
Change in the shape of a microbubble as an ultrasound pressure wave passes through the tissue in
which the microbubble is located.
189
4.11 Ultrasound contrast agents

DfDoppler 5 nf0v
c
cos h;
ð4:38Þ
where n is the order of the harmonic. A high-pass ﬁlter is used to remove
contributions from the fundamental (n = 1) harmonic, so that only signals from
the microbubble destruction are detected. The intensity of the transmitted ultra-
sound pulse can be determined from the mechanical index (MI), which is a meas-
ure of the acoustic output of the particular ultrasound system. The MI is typically
displayed on the ultrasound operating console, and its value can be used to control
whether linear, nonlinear or destructive effects are produced during the ultrasound
scan. Safety aspects of the MI are covered in Section 4.12.
4.11.2 Harmonic and pulse inversion imaging
Although it is technically possible in contrast agent imaging to detect separately the
signals centred at f0 and its harmonic at 2f0 using high-pass and low-pass ﬁlters, in
practice there is considerable signal contamination between the two very broad
frequency distributions. Pulse inversion imaging is a technique which was
designed to overcome some of the limitations of second harmonic imaging [6].
Two sets of scans are acquired, as shown in Figure 4.34, with the phase of the
transmitted ultrasound pulse differing by 180 in the two scans. Linear backscat-
tering from tissue results in two signals which differ in phase by 180 in the two
scans, and so addition of the two scans results in signal cancellation. However, for
nonlinear scattering, the signals do not completely cancel out, with the residual
signal being proportional to the degree of nonlinearity.
Second harmonic imaging has an increased lateral resolution over images
at the fundamental frequency due to the higher frequency and therefore smaller
+
=
+
=
Scan 1 transmit 0o
Scan 2 transmit 180o
Figure 4.34
The principle of pulse inversion imaging. At the top, any signal which contains only components at f0 is
cancelled out by addition of the two scans. At the bottom, the signal contains components at both f0
and 2f0: in the summed signal, the component at 2f0 remains.
190
Ultrasound imaging

wavelength. Also there is a reduction in what is termed ultrasound ‘clutter’, which
refers to effects such as reverberation and reﬂected signal from side-lobes, since
these effects do not give rise to a second harmonic signal. The only disadvantage of
pulse inversion imaging is that the scan takes twice as long, or alternatively that the
frame-rate is halved compared to conventional imaging.
It should be noted that in addition to using harmonic imaging in combination
with contrast agents there is increasing use of ‘native’ second harmonic imaging in
normal tissue without using contrast agents. Although the second harmonic signal
is much weaker than the fundamental frequency, since for conventional power
levels there are relatively minor nonlinear effects, the facts that clutter is much
reduced and that lateral resolution is enhanced makes harmonic imaging a useful
option in certain applications.
4.12
Safety guidelines in ultrasound imaging
Under normal scanning protocols for diagnostic radiology and cardiology, ultra-
sound imaging is extremely safe, with very low power levels causing insigniﬁcant
increases in tissue temperature. However, there is constant monitoring of imaging
protocols by various scientiﬁc and government bodies, particularly with the
increased use of power-intensive scanning modes such as combined compound
scanning/three-dimensional imaging/power Doppler, for example. In addition, use
of microbubble contrast agents, and the correspondingly higher ultrasound powers
needed to induce signiﬁcant nonlinear behaviour (often culminating in bubble
destruction), also increase the amount of energy deposited into the body well
beyond the normal B-mode scanning conditions. There are several measures of
the ultrasound energy, summarized below [7], which are used to form guidelines
for different diagnostic protocols:
(i) Spatial average (SA)
Takes into account the Gaussian shape of the
lateral beamwidth and calculates the average
value of the Gaussian function
(ii) Temporal average (TA)
Multiplies the average intensity during the pulse
by the duty cycle (the percentage of the total
imaging time for which the driving voltage is
gated on)
(iii) Spatial peak (SP)
Measures the peak intensity at the focal spot of
the beam
(iv) Temporal peak (TP)
Measures the highest instantaneous intensity of
the beam
191
4.12 Safety guidelines in ultrasound imaging

Common acronyms used for reporting ultrasound intensities for different pro-
cedures use a combination of these terms, for example spatial average temporal
average (SATA), spatial peak temporal average (SPTA), spatial peak pulse aver-
age (SPPA), spatial peak temporal peak (SPTP), spatial peak (SP) and spatial
average (SA).
Tissue heating and cavitation are the two mechanisms by which destructive
bioeffects can potentially occur during an ultrasound scan. For tissue heating,
the intensity of the ultrasound beam and the duration of the scan are both important
parameters. For cavitation, the relevant parameter is the pulse peak rarefactional
pressure amplitude, which in Doppler ultrasound can be between ~0.7 and 3.5
Mpa. This is particularly relevant to gas echo-contrast agents, in which cavitation
of the bubbles can occur. The acoustic output from ultrasound medical devices is
directly regulated only in the USA. There is an overall maximum limit of 720 mW/
cm2 for the derated ISPTA. If the systems have a real-time output display standard
(ODS) of safety indices such as mechanical index (MI) and thermal index (TI),
then the FDA limits (referred to as track 1) are lifted, and much higher intensities
can be used (referred to as track 3), as shown in Table 4.2. The thermal index is
determined as the ratio of the total acoustic power to that required to produce a
maximum temperature increase of 1 C. There are three TI values, TIS (TI soft
tissue), TIB (bone) and TIC (cranial bone). The mechanical index is mathemati-
cally deﬁned as:
MI 5 max pr z
ð Þe0:0345f0z


ﬃﬃﬃﬃf0
p
;
ð4:39Þ
where pr is the axial value of the rarefactional pressure measured in water.
The TI and MI are only rough approximations of the risk of inducing biological
effects, with values less than 1 indicating safe operation. For B-mode scanning, the
MI is displayed, for Doppler, M-mode or colour ﬂow imaging the TI is displayed.
The FDA has an upper limit of 1.9 on the MI (0.23 for opthalmic scans). The aim
of the MI is to predict the likelihood of cavitation, where the peak pressure is the
critical parameter. The TI estimates the potential for producing thermally-induced
Table 4.2: Intensity limits, ISPTA, (mW/cm2)
FDA (track 1)
ODS (track 3)
Peripheral vessel
720
720
Cardiac
430
720
Foetal, neonatal
94
720
Opthalmic
17
50
192
Ultrasound imaging

biological effects in soft tissue and bone. Both TI and MI values provide indicators
of risk rather than quantiﬁable values.
In general, B-mode imaging is not capable of causing harmful temperature
rises. Doppler scans can potentially produce harmful temperature increases,
particularly at bone/soft-tissue interfaces since longer pulses and higher pulse-
repetition rates in Doppler imaging compared to B-mode imaging result in higher
average intensities. In addition, in pulsed Doppler the beam is focused into a
relatively small volume and kept stationary. A diagnostic procedure that produces
a maximum temperature rise of no more than 1.5C above normal physiological
levels is allowed clinically. Any procedure that elevates embryonic and foetal
in situ temperature above 41 C for ﬁve minutes or more is considered potentially
hazardous.
4.13
Clinical applications of ultrasound
Ultrasound ﬁnds very wide use in radiology, due to its relatively low-cost, high
portability, and noninvasive nature. Recent developments such as compound
scanning, harmonic imaging and two-dimensional arrays have increased the qual-
ity and utility of ultrasound signiﬁcantly. Ultrasound is the only modality able to
provide very high frame-rate real-time imaging over signiﬁcant periods. It has
almost no contraindications, unlike MRI which cannot be used for patients with
many types of implant, and uses no ionizing radiation. It is also the only modality
that is routinely used during pregnancy. As examples, applications to obstetrics,
breast imaging, musculoskeletal damage and cardiac studies are outlined brieﬂy
below.
4.13.1 Obstetrics and gynaecology
Parameters such as the size of the foetal head and extent of the developing brain
ventricles (for diagnosis of hydrocephalus), and the condition of the spine are
measured to assess the health of the foetus. If amniocentesis is necessary to detect
disorders such as Down’s syndrome, then ultrasound is used for needle guidance.
Doppler ultrasound is also used to measure foetal cardiac parameters such as blood
velocity. Three-dimensional ultrasound provides high resolution images of the
developing foetus, although such images tend to be more for show than for actual
clinical diagnosis. The high spatial resolution and excellent image contrast possi-
ble are shown in Figure 4.35.
193
4.13 Clinical applications of ultrasound

4.13.2 Breast imaging
Ultrasound imaging is used to differentiate between solid and cystic lesions, and
for the evaluations of lesions in young women with dense breast tissue or who are
pregnant, since X-rays are not effective or not allowed, respectively [8]. Five
different categories of lesion are deﬁned by the American College of Radiography
based on well-deﬁned morphometric measures and image characteristics. High
frequency ultrasound, between 9 and 12 MHz, is used for optimal image contrast,
as well as for the highest axial and lateral resolution. The standard procedure is to
use two-dimensional B-mode scanning. Breast lesions are generally hypoechoic,
appearing darker than the surrounding tissue. Harmonic and compound imaging
have recently been used extensively since they reduce the contribution from
speckle, reverberation and internal-echo artifacts. In many cases, solid breast
tumours are better delineated using harmonic imaging. However, due to the higher
frequency of the returning echoes, B-mode scanning may be preferred for deep
lesions. Two examples of breast masses detected using ultrasound are shown in
Figure 4.36. Colour Doppler imaging is sometimes added to the scanning protocol,
since malignancies often have higher vascularity than benign lesions. In addition to
radiological diagnosis, real-time two-dimensional scanning is an effective method
for image-guided needle biopsy of a lesion, in which a sample of the lesion is
extracted for biochemical analysis to determine whether it is cancerous or not.
4.13.3 Musculoskeletal structure
The newer technologies of compound and harmonic scanning have made signiﬁ-
cant improvements to musculoskeletal (MSK) ultrasound imaging [9]. In partic-
ular, compound scanning improves the quality of tendon and nerve images, since
Figure 4.35
Two-dimensional B-mode scans of (left) 19 week fetus in the womb, and (centre) foetal brain. (right)
Three dimensional foetal image using a two-dimensional array and mechanical steering.
194
Ultrasound imaging

these typically produce a lot of speckle. Example images are shown in Figure 4.37.
Small lesions detection is also signiﬁcantly improved by compound scanning.
Doppler imaging can detect reduced ﬂow in superﬁcial vessels in diseases such
as rheumatism, and other inﬂammatory conditions. Three-dimensional imaging is
often used for imaging complicated joints. Finally, ultrasound guidance is often
used for interventional MSK procedures in which needles must be placed precisely
within the particular joint.
4.13.4 Echocardiography
Two-dimensional B-mode imaging of the heart is used to determine clinically-
relevant parameters such as ventricular size and function [10]. Speciﬁc
Fibroadenoma
Breast mass
Figure 4.36
(left) A ﬁbroadenoma and (right) a breast mass, both easily visible on a two-dimensional B-mode
scan.
Figure 4.37
(left) Compound scan of the ﬂexor pollicus tendon in the hand. (right) Compound scan of a rotator cuff
injury in the shoulder.
195
4.13 Clinical applications of ultrasound

applications are early signs of cardiac disease, such as chest pain, suspected cardiac
embolisms and infarctions, valve disease and cardiac arrhythmias. The sensitivity
to infarction is very high, typically a negative predictive value of ~95% after
reported cases of chest pain. In addition to morphometrical measurements, echo-
cardiography equipment is used for colour Doppler imaging for wall motion
analysis, as shown in Figure 4.38, as well as being able to produce maps of
myocardial strain. Similarly to nuclear medicine stress tests, stress echocardiog-
raphy can also be performed after strenuous exercise. Three-dimensional ultra-
sound is likely to play an increasingly important role in echocardiography, due to
the much higher reproducibility of quantitative measures such as ejection fraction
and left ventricular mass. Microbubble contrast agents can be used to ‘opacify’ the
left ventricle, and also to measure myocardial perfusion, but these procedures are
currently not widely performed. As with many other ultrasound applications,
echocardiography is a low-risk ﬁrst choice scan, which does not have a large
radiation dose associated with it, and can be used on patients with pacemakers,
defribrillators, and stents which are MRI-incompatible. Simple portable echocar-
diography units are available, as are dedicated systems which incorporate pulsed-
mode and continuous-wave Doppler, pulse-inversion harmonic imaging, com-
pound scanning, three-dimensional imaging, M-mode imaging and sophisticated
phased arrays.
4.14
Artifacts in ultrasound imaging
As outlined in Section 1.8, the term image artifact refers to any features in the
image which do not correspond to actual tissue structures, but rather to ‘errors’
Figure 4.38
(left) Mitral regurgitation shown by colour pulsed Doppler. (right) Left atrial appendage (LAA), left
ventricle (LV) and left anterior (LA) chamber.
196
Ultrasound imaging

introduced by the imaging technique or instrumentation. Such artifacts must be
recognized to avoid incorrect image interpretation, but once recognized can in fact
give useful diagnostic information. The main artifact in ultrasound imaging,
namely speckle, has already been described. It arises from the constructive and
destructive interference of ultrasound scattered from very small structures within
tissue, and this complicated wave pattern gives rise to high and low intensities
within the tissue which are not correlated directly with any particular structure.
There are several other artifacts that appear in ultrasound images. Reverbera-
tions occur if there is a very strong reﬂector close to the transducer surface. Multi-
ple reﬂections occur between the surface of the transducer and the reﬂector, and
these reﬂections appear as a series of repeating lines in the image. These artifacts
are relatively simple to detect due to the equidistant nature of the lines. Typically,
they occur when the ultrasound beam encounters regions of either bone or air.
Acoustic enhancement occurs when there is an area of low attenuation relative to
the surrounding tissue, and therefore structures lying deeper and in-line with this
area show an artiﬁcially high signal intensity. Areas which contain a high propor-
tion of water such as cysts can show this effect. The opposite phenomenon, termed
acoustic shadowing, occurs when a highly attenuating medium results in a dark
area deeper below the highly attenuating medium. Solid tumours are one example
of tissues which cause acoustic shadowing. Examples of acoustic enhancement
and shadowing are shown in Figure 4.39.
Exercises
Reﬂection, transmission, refraction and scattering
4.1 Calculate the intensity transmission coefﬁcient, TI, for the following interfa-
ces, assuming that the ultrasound beam is exactly perpendicular to the inter-
face:
Figure 4.39.
Image artifacts caused by (left) acoustic enhancement, and (right) acoustic shadowing.
197
Exercises

(i) muscle/kidney,
(ii) air/muscle, and
(iii) bone/muscle.
Discuss brieﬂy the implications of these values of TI for ultrasound imaging.
4.2 Repeat the calculations in Exercise 4.1 with the angle of incidence of the
ultrasound beam now being 45.
4.3 Within tissue lies a strongly reﬂecting boundary, which backscatters 70% of
the intensity of the ultrasound beam. Given a 100 dB receiver dynamic range,
and an operating frequency of 3 MHz, what is the maximum depth within
tissue at which this boundary can be detected?
Absorption and attenuation of ultrasound energy
4.4 Calculate the distance at which the intensity of a 1 MHz and 5 MHz ultrasound
beam will be reduced by half traveling through (a) bone, (b) air, and (c)
muscle.
4.5 Explain why a very fast or very slow tissue relaxation time results in a very
small amount of energy being lost due to absorption.
4.6 Plot the attenuation of the ultrasound beam for 1, 5 and 10 MHz at depths
within tissue of 1 cm, 5 cm, and 10 cm. For each depth calculate the fractional
decrease in transmitted power, and the absolute power assuming an output
power from the transducer of 100 mW/cm2.
Single element transducers
4.7 In order to improve the efﬁciency of a given transducer, the amount of energy
reﬂected by the skin directly under the transducer must be minimized. A
layer of material with an acoustic impedance Zmatching layer is placed between
the transducer and the skin. If the acoustic impedance of the skin is denoted
by Zskin, and that of the transducer crystal ZPZT, show mathematically that the
value of Zmatching layer which minimizes the energy of the reﬂected wave is
given by:
Zmatching layer 5
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ZPZTZskin
p
:
4.8 Given values of ZPZT and Zskin of 303105 g cm22 s21 and 1.73105 g cm22
s21, respectively, calculate what fraction of the energy from the transducer is
actually transmitted into the patient.
4.9 If two matching layers are used instead of one, and the respective acoustic
impedances are given by the analogues of the equation above, then calculate
the increase in efﬁciency in transmitting power into the patient.
4.10 Consider a transducer which has a thickness given by Equation (4.22). A
matching layer is used to maximize the energy transferred from the
198
Ultrasound imaging

transducer to the body. Show that the thickness of this matching layer
should be one-quarter of the ultrasound wavelength.
4.11 Why is the thickness of the PZT element set to one-half wavelength?
4.12 For a concave lens to focus a beam, should the speed of sound in the lens be
greater than or less than in tissue?
4.13 How does the frequency proﬁle of the ultrasound beam change as it passes
through tissue? How does this affect the lateral resolution?
4.14 Consider a focused transducer with a radius of curvature of 10 cm and a
diameter of 4 cm. This transducer operates at a frequency of 3.5 MHz, and
transmits a pulse of duration 0.857 ls. What is the axial and lateral reso-
lution at the focal point of the transducer?
4.15 If the axial and lateral resolution were to be improved by a factor of 2 from
those calculated in Exercise 4.14, what physical or operating parameters
could be changed?
4.16 Plot the transmitted frequency spectrum of an ultrasound beam from a trans-
ducer operating at a central frequency of 1.5 MHz. Assume that the trans-
ducer is damped. Repeat the plot for the beam returning to the transducer
after having passed through tissue and been backscattered.
4.17 Draw the corresponding beam pattern to that shown in Figure 4.10 for a
transducer operating at double the frequency. Note all of the frequency-
dependent changes in the beam pattern.
Transducer arrays
4.18 Show the required timing for simultaneous steering and dynamic focusing of
a phased array. For simplicity, sketch the general scheme using a small
number (for example ﬁve) of elements.
4.19 Sketch the corresponding delays required for dynamic beam-forming during
signal reception.
Clinical scanning modes
4.20 Use the following data to sketch the A-mode scan from Figure 4.40(a). The
amplitude axis should be on a dB scale, and the time axis in microseconds.
Ignore any reﬂected signal from the transducer/fat interface, and assume that
a signal of 0 dB enters the body. At a transducer frequency of 5 MHz, the
linear attenuation coefﬁcient for muscle and liver is 5 dB cm21, and for fat is
7 dB cm21. Relevant values of the characteristic acoustic impedance and
speed of sound can be found in Table 4.1.
4.21 Determine and sketch the A-mode scan using the same parameters as above,
but with a time gain compensation of 0.8 dB ls21.
4.22 For the object shown in Figure 4.40(b), qualitatively sketch the B-mode
ultrasound image. Ignore speckle or scatter and only consider signals
199
Exercises

backscattered from the tissue boundaries. Acoustic impedances: muscle 1.61,
tumour 1.52 (x 105 g/cm2s). Attenuation coefﬁcients: muscle 1.0, tumour 0.4
(dB/cm/MHz). Speeds of sound: muscle 1540, tumour 750 (m/s).
4.23 In a particular real-time imaging application the transducer moves through a
90 sector with a frame rate of 30 frames per second, acquiring 128 lines of
data per frame. If the image is acquired up to a depth of 20 cm, and the lateral
resolution of the beam width at this depth is 5 mm, calculate the effect of
transducer motion on overall image blurring, i.e. is it the dominant factor?
4.24 A B-mode scan is taken of the object in Figure 4.41 with a linear array. There
are four tissue components, A and B with a boundary in-between and two
spherical tumors C and D. Given the corresponding ultrasound image shown
on the right what can you deduce about the acoustic characteristics of com-
ponents A, B, C and D?
transducer
fat
muscle
fat
liver
5 mm
5 mm
3 cm
transducer
fat
tumour
muscle
muscle
liver
a
b
Figure 4.40
See Exercises 4.20, 4.21 and 4.22.
b
d
a
c
Figure 4.41
See Exercise 4.24.
200
Ultrasound imaging

4.25 Given the ultrasound data in the table below, sketch the B-mode scan
that would be obtained from the linear sequential array in Figure 4.42 (a
quantitative analysis is NOT needed, ignore any refraction of the ultrasound
beam).
4.26 The three ultrasound images in Figure 4.43 are of the same object.
Explain which operating parameter changes from image (a) to image (b) to
image (c).
Doppler ultrasound
4.27 Sketch the Doppler spectral patterns at points 1, 2, and 3 in the stenotic artery
shown in Figure 4.44 (a).
4.28 On the same scale as for Exercise 4.27, sketch the Doppler spectral plots for
the situation in Figure 4.44 (b) in which the angle between the artery and the
phased array transducer is altered.
fat
liver
linear array
muscle
1
2
3
4
5
6
1 cm
1 cm
1 cm
1.5 cm
1.5 cm
1.5 cm
Figure 4.42
See Exercise 4.25.
Tissue
Z (x 105)
c (m/s)
l (dB/cm)
Muscle
1.7
1540
1
Fat
1.4
1450
1.7
Liver
1.6
1570
1.5
Tumour 1
1.7
1540
1
Tumour 2
1.9
3080
1
Tumour 3
10
1540
5
Tumour 4
1.9
1540
20
Tumour 5
1.9
770
1
Tumour 6
1.9
1540
1
201
Exercises

4.29 Show that the effects of a ﬁxed error in the estimated angle between the
transducer and the direction of ﬂow in Doppler imaging are minimized by
using a small value of the angle.
Artifacts in ultrasound imaging
4.30 Sketch the shape of the acoustic shadowing artifact produced from com-
pound scanning.
4.31 The well-known reverberation artifact occurs when a strongly reﬂecting
boundary within tissue is close to the transducer. Assume that there is a 2
cm thickness of muscle in front of the ribs. Zcrystal is 333105, Zmuscle is
1.73105 and Zbone is 7.83105 g cm22 s21, the speed of sound in muscle is
1540 m/s, and the attenuation coefﬁcient of muscle is 1 dB/cm, calculate the
a
b
c
Figure 4.43
See Exercise 4.26.
1
2
3
1
2
3
a
b
Figure 4.44.
See Exercises 4.27 and 4.28.
202
Ultrasound imaging

time gain compensation (units of dB/microsecond) that must be used to make
the intensity of each of the reverberation signals the same.
References
[1] Shung KK. The principle of multi-dimensional arrays. Eur J Echocardiogr 2002
Jun;3(2), 149–53.
[2] Jespersen SK, Wilhjelm JE and Sillesen H. Multi-angle compound imaging.
Ultrason Imaging 1998Apr;20(2), 81–102.
[3] Jensen JA. Estimation of Blood Velocities Using Ultrasound. Cambridge: Cambridge
University Press, 1996.
[4] Rubin JM, Bude RO, Carson PL, Bree RL and Adler RS. Power Doppler US: a
potentially useful alternative to mean frequency-based color Doppler US. Radiology
1994:190(3), 853–6.
[5] Stride E. Physical principles of microbubbles for ultrasound imaging and therapy.
Cerebrovasc Dis 2009;27 Suppl. 2, 1–13.
[6] Kollmann C. New sonographic techniques for harmonic imaging – underlying
physical principles. Eur J Radiol 2007Nov;64(2), 164–72.
[7] Barnett SB, Ter Haar GR, Ziskin MC et al. International recommendations and
guidelines for the safe use of diagnostic ultrasound in medicine. Ultrasound Med
Biol 2000;26(3), 355–66.
[8] Athanasiou A, Tardivon A, Ollivier L et al. How to optimize breast ultrasound.
European Journal of Radiology 2009;69(1), 6–13.
[9] Klauser AS and Peetrons P. Developments in musculoskeletal ultrasound and
clinical applications. Skeletal Radiol 2009Sep;3.
[10] Marwick TH. The future of echocardiography. Eur J Echocardiogr 2009Jul;10(5),
594–601.
203
References

5 Magnetic resonance imaging (MRI)
5.1
Introduction
Of the four major clinical imaging modalities, magnetic resonance imaging (MRI)
is the one developed most recently. The ﬁrst images were acquired in 1973 by Paul
Lauterbur, who shared the Nobel Prize for Medicine in 2003 with Peter Mansﬁeld
for their shared contribution to the invention and development of MRI. Over 10
million MRI scans are prescribed ever year, and there are more than 4000 scanners
currently operational in 2010.
MRI provides a spatial map of the hydrogen nuclei (water and lipid) in different
tissues. The image intensity depends upon the number of protons in any spatial
location, as well as physical properties of the tissue such as viscosity, stiffness and
protein content. In comparison to other imaging modalities, the main advantages of
MRI are: (i) no ionizing radiation is required, (ii) the images can be acquired in any
two- or three-dimensional plane, (iii) there is excellent soft-tissue contrast, (iv) a
spatial resolution of the order of 1 mm or less can be readily achieved, and (v)
images are produced with negligible penetration effects. Pathologies in all parts of
the body can be diagnosed, with neurological, cardiological, hepatic, nephrolog-
ical and musculoskeletal applications all being widely used in the clinic. In addi-
tion to anatomical information, MR images can be made sensitive to blood ﬂow
(angiography) and blood perfusion, water diffusion, and localized functional brain
activation. The main disadvantages of MRI are: (i) MR image acquisition is much
slower than CT and ultrasound, and is comparable to PET: a typical clinical
protocol might last 30–40 minutes with several different types of scan being
run, each having a slightly different contrast, with each scan taking between ﬁve
and ten minutes, (ii) a signiﬁcant percentage of patients are precluded from MRI
scans due to metallic implants from previous surgeries, and (iii) systems are much
more expensive than CT or ultrasound units.
The MRI system comprises three major hardware components: a superconducting
magnet, a set of three magnetic ﬁeld gradient coils, and a radiofrequency transmitter
and receiver. The superconducting magnet typically has a strength of 3 Tesla,
approximately 60 000 times greater than the earth’s magnetic ﬁeld. This magnetic

ﬁeld causes the protons to precess at a frequency proportional to the strength of the
magnetic ﬁeld, i.e. there is a ‘resonance’ frequency. The magnetic ﬁeld gradients
make this resonance frequency dependent upon the spatial location of each proton
in the body, thus enabling an image to be formed. A tuned radiofrequency coil
transmits energy into the body at ~128 MHz for a 3 Tesla magnet, and the MRI
signal is induced in the same or other RF coils which are placed close to the body.
Figure 5.1 shows a simpliﬁed schematic of the components of an MRI system,
as well as a photograph of a commercial high-ﬁeld scanner together with patient
bed. Figure 5.1(c) shows typical brain MRI scans in three different orientations.
There is excellent contrast between the grey and white matter of the brain, with the
protons in lipid seen as a bright signal outside the skull. Protons in very rigid
structures such as bone are normally not visible using MRI: this is evident by the
thin dark line between the lipid layer and brain surface in Figure 5.1(c).
5.2
Effects of a strong magnetic ﬁeld on protons in the body
In an MRI scanner the patient lies on a patient bed which slides into a very strong
magnet. A typical value of the magnetic ﬁeld, B0, is 3 Tesla (30 000 Gauss), roughly
Superconducting magnet
Gradient coils
RF coil
B0
c
0
a
b
 
Figure 5.1
(a) A high-ﬁeld clinical magnet with patient bed. (b) The three major components of an MRI system,
including the superconducting magnet which produces a strong magnetic ﬁeld (B0) in the horizontal
direction. Only one of the three gradient coils is shown for clarity. (c) MR images can be acquired
in any orientation, shown here are coronal, sagittal and axial images, respectively, of the brain.
205
5.2 Effects of a strong magnetic ﬁeld on protons in the body

60 000 times greater than the earth’s magnetic ﬁeld of ~50 lT (0.5 Gauss). Numer-
ous studies have shown no detrimental effect of such a high magnetic ﬁeld, but
patients must undergo a thorough check to ensure that they have no magnetic metal
implants or surgical clips. The effect of placing the body in a strong magnetic ﬁeld
is covered in the following two sections.
5.2.1 Proton energy levels
In clinical MRI the image is formed by the signals from protons (hydrogen nuclei)
in water and lipid. At the atomic level, since the proton is a charged particle which
spins around an internal axis of rotation with a given value of angular momentum
(P), it also has a magnetic moment (l), and therefore can be thought of as a very
small bar magnet with a north and south pole, as shown in Figure 5.2. The
phenomenon of quantization is familiar from basic physics and chemistry, and
means that certain physical parameters can take on only discrete values, rather than
having a continuous range. Examples include electric charge, the energy of a
photon, and quantum numbers of electrons. Relevant to MRI, the magnitude of
the angular momentum of the proton is quantized and has a single, ﬁxed value. The
magnitude of the proton’s magnetic moment is proportional to the magnitude of
the angular momentum:
l!

 5 c P!

;
ð5:1Þ
+
N 
S 
P
No B0 field
B0
+
+
+
+
+
+
+
+
+
+
a
b
c
+
N 
S 
P
+
N 
S 
N 
S
P
+
+
+
+
+
+
+
+
+
+
Figure 5.2
(a) The internal rotation of a proton creates a magnetic moment, and so the proton acts as a magnet
with north and south pole. (b) In the absence of a strong magnetic ﬁeld, the orientations of the
magnetic moments are completely random. (c) When there is a strong magnetic ﬁeld present the
magnetic moments must align at an angle h = 654.7 with respect to the direction of B0.
206
Magnetic resonance imaging (MRI)

where c is a constant called the gyromagnetic ratio, and has a value of 267.54
MHz/Tesla for protons. As a result, the magnitude of the magnetic moment has a
single, ﬁxed value. Outside the MRI magnet, as shown in Figure 5.2 the magnitude
of the magnetic moment of every proton in our bodies is ﬁxed, but the orientation
is completely random. Therefore, the net magnetization, i.e. the sum of all the
individual magnetic moments in our bodies, is zero (ignoring the very small effects
from the earth’s magnetic ﬁeld).
The situation changes when the patient is slid into the magnet for an MRI scan.
From quantum mechanics, the component of the magnetic moment in the direction
of B0 can have only two discrete values, which results in the magnetic moments
being aligned at an angle of 54.7 with respect to the direction B0, aligned either in
the same direction or in the opposite direction, as shown in Figure 5.2(c). The
former conﬁguration is termed as the parallel, and the latter as the anti-parallel
conﬁguration: note however that the terms parallel and anti-parallel only refer to
the z-component of l, and that l is actually aligned at an angle with respect to B0.
The relative number of protons in the parallel and anti-parallel conﬁgurations
depends upon the value of B0. Protons in the parallel conﬁguration are in the more
energy ‘favourable’ state, compared to the anti-parallel conﬁguration. The energy
difference (DE) between the two states is shown in Figure 5.3 and given by:
DE 5 chB0
2p ;
ð5:2Þ
where h is Plank’s constant (6.63 3 10234 J s). To calculate the relative
number of protons in each of the two conﬁgurations the Boltzmann equation
can be used:
Nanti-parallel
Nparallel
5 exp  DE
kT


5 exp 
chBo
2pkT


:
ð5:3Þ
where k is Boltzmann’s constant with a value of 1.38310223 J/K, and T is the
temperature measured in Kelvin. Since the value of the exponent is very small, a
ﬁrst order approximation, e2x  12x, can be made:
Nanti-parallel
Nparallel
5 1 
chBo
2pkT


:
ð5:4Þ
The MRI signal depends upon the difference in populations between the two
energy levels:
Nparallel  Nanti-parallel 5 Ntotal
chB0
4pkT ;
ð5:5Þ
where Ntotal is the total number of protons. It is important to note that MRI can
detect only the difference Nparallel2Nanti-parallel, and not the total number of protons.
207
5.2 Effects of a strong magnetic ﬁeld on protons in the body

Example 5.1
Assuming a value of room temperature of 25 C, what is the value of Nparallel-
Nanti-parallel for the head at 3 Tesla, and what percentage of Ntotal does this
represent? Assume that the head is spherical with diameter 20 cm and consists
entirely of water.
Solution
The volume of the head is given by 4/3 pr3 = 4189 cm3. Since we assume that the
head is entirely water, with density 1 g/cm3, the mass of protons in the head is
4189 g. The atomic mass of water is 18, which means that there are 4189/18 =
232.7 moles of water in the head. Using Avogadro’s number, each mole has
6.02 3 1023 protons and so in the head there are 1.4 3 1026 protons. This is the
value of Ntotal in Equation (5.5). Now, plugging the values of the constants into
Equation (5.5):
NparallelNanti-parallel 5 1:4 3 1026 267:54 3 106 HzT1
ð
Þ6:63 3 1034ðJsÞ3 T
ð Þ
4p 3 1:38 3 1034 JK1
ð
Þ298 K
ð Þ
5 1:44 3 1021
:
no magnetic field
B0 present
parallel
anti-parallel
0
hB
E
4
= +
0
hB
E
4
= −
ΔE
Figure 5.3
Proton conﬁgurations. (left) In the absence of a strong magnetic ﬁeld, the energies of all the random
orientations of the magnetic moments are the same. (right) When a strong magnetic ﬁeld is applied,
the single energy level splits into two levels, one corresponding to the magnetic moments being in the
parallel state, and the other the anti-parallel state. The energy difference between the two levels
depends upon the value of B0. There are slightly more protons (shown as ﬁlled circles) in the parallel
ground energy state than in the higher energy anti-parallel state.
208
Magnetic resonance imaging (MRI)

The MRI signal, as a percentage of the total number of protons is given by:
NparallelNanti-parallel
Ntotal
5 1 3 105:
In other words, out of every 1 million protons, only the small difference of 10
protons between the parallel and anti-parallel energy states can be measured.
5.2.2 Classical precession
Having determined that the proton magnetic moments are all aligned at an angle of
54.7 with respect to the direction of B0, the motion of these magnetic moments
can most easily be described using classical mechanics. The B0 ﬁeld attempts to
align the proton magnetic moment with itself, and this action creates a torque, C,
given by the cross product of the two magnetic ﬁelds:
C
! 5 l! 3 B0
! 5 iN l
j j B0
j
jsinh;
ð5:6Þ
where iN is a unit vector normal to both l! and B0
!. The direction of the torque,
shown in Figure 5.4, is tangential to the direction of l! and so causes the proton to
‘precess’ around the axis of the magnetic ﬁeld, while keeping a constant angle of
54.7 between l! and B0
!. An everyday analogue of this motion is a spinning top
or gyroscope, where gravity is the external force acting in the vertical direction.
Provided that the top is spinning around its internal axis, it precesses by sweeping
around a conical trajectory at a constant angle.
gravity
B0
θ 
|P|sin
θ 
C
P
+
torque created
a
b
|
C
P
+
|
C
P
+
Figure 5.4
A proton in a magnetic ﬁeld. (a) Using classical mechanics, the torque C acting on the magnetic
moment, spinning about an internal axis, causes it to precess about the vertical axis, B0. (b) A familiar
analogy is that of a spinning top: in this case the vertical force is gravity.
209
5.2 Effects of a strong magnetic ﬁeld on protons in the body

To calculate how fast a proton precesses, we use the fact that the torque is
deﬁned as the time rate of change of the proton’s angular momentum:
C
! 5 d P!
dt 5 l! 3 B0
!:
ð5:7Þ
From Figure 5.4, the magnitude of the component of the angular momentum
which precesses in the plane perpendicular to B0 is given by
P!

 sinh. In a
short time dt, l precesses through an angle du resulting in a change d P! in the
angular momentum. Simple trigonometry gives the relationship that:
sin du
ð
Þ 5
d P!
P!

sinh
5
C
!dt
P!

sinh
:
ð5:8Þ
If du is small then we can make the approximation that sin(du) = du. The
angular precession frequency, x, is given by du/dt and so has a value:
x 5 du
dt 5
C
!
P!

 sinh
5 l! 3 B0
!
P!

 sinh
5 c P! 3 B0
!
P!

 sinh
5
c P!

 B0
!

 sinh
P!

 sinh
5 cB0:
ð5:9Þ
The effect of placing a proton in a magnetic ﬁeld, therefore, is to cause it to
precess around B0 at a frequency directly proportional to the strength of the
magnetic ﬁeld. This frequency, termed x0, is termed the Larmor frequency after
the renowned Irish physicist Joseph Larmor.
Example 5.2
What are the Larmor frequencies, expressed in MHz, for B0 ﬁelds of 1.5 Tesla,
3 Tesla and 7 Tesla?
Solution
For 1.5 Tesla, the frequency is given by:
f 5 x
2p 5 cB0
2p 5 267:54 3 106 HzT1
ð
Þ1:5 T
ð Þ
2p
5 63:9 MHz:
Simple multiplication gives frequencies (rounded to one signiﬁcant ﬁgure) of
127.7 and 298.1 MHz for 3 Tesla and 7 Tesla, respectively.
By combining the results of the quantum mechanical and classical analysis we
can represent the net magnetization from the entire patient in a simple vector form.
Figure 5.5 shows on the left a representation of several proton magnetic moments,
210
Magnetic resonance imaging (MRI)

each aligned at 54.7 to B0, each precessing at a frequency x0, with slightly more
protons in the parallel than anti-parallel state. The total magnetization can be
calculated by a simple vector sum of the individual components, and is shown
on the right of Figure 5.5. It can be seen that the net magnetization has only a
z-component, since the vector sum of the components on the x- and y-axes is zero.
The net magnetization of the sample is deﬁned as M0:
M0 5
+
Ntotal
n 5 1
lz;n 5 ch
4p Nparallel  Nanti-parallel


5 c2h2B0Ntotal
16p2kT
:
ð5:10Þ
5.3
Effects of a radiofrequency pulse on magnetization
The energy levels for protons in a magnetic ﬁeld, shown in Figure 5.3, are anal-
ogous to energy levels in semiconductors and also the vibrational and rotational
energy levels used in infrared spectroscopy. As with all such multi-level systems,
to obtain an MR signal, energy must be supplied with a speciﬁc value DE, given by
Equation (5.2), to stimulate transitions between the energy levels. The energy is
x
y
z
B 0 
x
y
z
x
y
z
B 0 
Figure 5.5
Magnetization represented by vectors. (left) Individual magnetization vectors are randomly distributed
around a cone which subtends an angle of 54.7 with respect to the B0 (z) axis. The vector sum of all
of the individual magnetization vectors (right) is simply a static component in the direction of B0.
211
5.3 Effects of a radiofrequency pulse on magnetization

supplied as an electromagnetic (EM), usually referred to as a radiofrequency (RF)
ﬁeld, the frequency (f) of which can be calculated from De Broglie’s relationship,
DE=hf:
hf 5 DE 5 chB0
2p
0f 5 cB0
2p or x 5 cB0
:
ð5:11Þ
By comparing Equations (5.11) and (5.9) it can be seen that the frequency of the
RF ﬁeld is identical to the precession frequency.
5.3.1 Creation of transverse magnetization
In MRI, energy is applied as a short RF pulse, with the direction of the magnetic
component of the RF ﬁeld oriented at 90 to the direction of B0, as shown in Figure
5.6. Applying the same classical analysis as for proton precession, the magnetic
component of the RF pulse, termed the B1 ﬁeld, produces a torque which causes
the net magnetization to rotate towards the xy-plane as shown in Figure 5.6. Note
that if the B1 ﬁeld is applied along the x-axis, the magnetic moment vector is
rotated towards the y-axis (see Exercise 5.2).
The ‘tip angle’ (a) is deﬁned as the angle through which the net magnetization is
rotated. This angle is proportional to both the strength of the applied RF ﬁeld
(measured in Tesla) and the time, sB1, for which it is applied:
a 5 cB1sB1:
ð5:12Þ
A tip angle of 90, termed a 90 pulse, results in the maximum value of the My
component of magnetization, whereas one of 180 produces no My magnetization
but rotates the net magnetization M0 from the +z to the – z axis.
B1
x
y
z
0
x
y
z
B1
0 y
z
0
Figure 5.6
(left) Application of an RF pulse about the x-axis rotates the magnetization from the z-direction towards
the y-axis. If the RF pulse strength and duration are chosen to produce a 90 pulse, then the
magnetization lies directly along the y-axis. When the RF pulse is switched off (right), the
magnetization precesses around the z-axis at the Larmor frequency x0.
212
Magnetic resonance imaging (MRI)

Example 5.3
In MRI a typical B1 ﬁeld is 30 microTesla, calculate how long this B1 ﬁeld must be
applied to produce a 90 pulse.
Solution
The problem is most easily solved by using units of radians for the tip angle, where
an angle of p/2 radians is equivalent to 90. Using Equation (5.12):
sB1 5
a
cB1
5
p=2
267:54 3 106 HzT1
ð
Þ30 3 106 T
ð Þ 5 1:96 3 104s:
5.4
Faraday induction: the basis of MR signal detection
In the most simple case, the MR detector consists of a pair of conductive loops (of
copper wire for example) placed close to the patient at an angle of 90 with respect
to each other. Faraday’s law of induction states that a voltage (V) is induced in
each of these loops with a value proportional to the time rate of change of the
magnetic ﬂux du:
V }  du
dt :
ð5:13Þ
Figure 5.7 shows the situation a short time after a 90 pulse has been applied
about the x-axis: in this case the respective voltages induced in the two coils are
given by:
0
+ Vx -
x
y
z
+ Vy -
Vx -
+ Vy -
Figure 5.7
The MR signal is measured via Faraday induction. Either one or two RF coils can be used, with a
voltage being induced across the ends of the conductor loops by the precessing magnetization.
213
5.4 Faraday induction: the basis of MR signal detection

Vy } M0x0 sin x0t
Vx } M0x0 cos x0t :
ð5:14Þ
It is important to note that the requirement for a time-varying magnetic ﬂux to
induce an MR signal is the reason why only magnetization precessing in the xy-
plane gives rise to an MR signal. Any z-component of magnetization does not
precess and therefore does not induce a voltage.
5.4.1 MR signal intensity
The size of the MR signal is determined by three different factors. First, the signal
is proportional to the number of protons in the object, from Equation (5.5). In terms
of MRI, as will be seen later, this corresponds to the number of protons in each
voxel of the image. The other two factors depend upon the value of the B0 ﬁeld.
From Equation (5.10), the value of M0 is proportional to B0: therefore a 3 Tesla
MRI system has twice the M0 of a 1.5 Tesla system. Also, from Equation (5.14),
the induced voltage is proportional to the precession frequency, which in turn is
proportional to B0. Overall, therefore, the MR signal is proportional to the square
of the B0 ﬁeld, one of the reasons why there is such a strong drive towards higher
ﬁeld MRI systems. Of course, in terms of the overall SNR, the dependence of the
noise on the strength of the B0 ﬁeld must also be considered: this is covered in
detail in Section 5.20.1. Overall, the image SNR is proportional to the 3/2 power of
the value of the B0 ﬁeld.
5.4.2 The rotating reference frame
The x and y components of transverse magnetization (Mx and My) precess around
B0 at a very high frequency, ~128 MHz for a 3 Tesla magnet. In terms of visual-
izing this motion the concept of a ‘rotating reference frame’ (x#,y#,z) is extremely
useful, see Figure 5.8. In this frame the x#y# plane rotates around the z-axis at the
Larmor frequency. Therefore, protons precessing at the Larmor frequency appear
static in the rotating reference frame. Although the transformation is trivial when
considering protons precessing at a single frequency, during imaging sequences
protons precess at different frequencies depending upon their spatial location,
and then the rotating reference frame becomes essential for analysis. It should
be emphasized that the rotating reference frame is only a convenient visualization
model: in reality all protons precess around B0.
214
Magnetic resonance imaging (MRI)

5.5
T1 and T2 relaxation times
As seen in Section 5.2, the equilibrium magnetization state corresponds to a
z-component, Mz, equal to M0 and transverse components, Mx and My, equal to
zero. Application of an RF pulse creates a non-equilibrium state by adding energy
to the system. After the pulse has been switched off, the system must relax back
to thermal equilibrium. The phenomenon of relaxation is familiar from many
engineering applications: for example, the application of an impulse voltage pulse
to an RC electrical circuit produces time-varying voltages across the lumped
elements, the values of which return in time to their values prior to the pulse being
applied, this process being characterized by certain time-constants. Figure 5.9
shows what happens to the magnetization after application of a 90 pulse around
the x axis.
It is important to note that there are two relaxation times which govern the
return to equilibrium of the z-component, and the x- and y-components, respec-
tively. These are referred to as T1-relaxation (which affects only z-magnetization)
and T2-relaxation (which affects only x- and y-magnetization). These are also
called spin-lattice (T1) and spin-spin (T2) relaxation. MR relaxation is described
mathematically by relatively simple ﬁrst order differential equations known as
the Bloch equations [1]. Solutions of these equations give the following relation-
ships: after an RF pulse of arbitrary tip angle a, the value of Mz at a time t is
given by:
MzðtÞ 5 M0 cos a 1 M0  M0 cos a
ð
Þ 1  e t
T1


:
ð5:15Þ
' 
x 
' 
y 
z 
x 
y 
z 
Stationary frame
Rotating reference frame 
 
0 
0
0
Figure 5.8
Relationship between the stationary frame (left) and the rotating frame (right). In the stationary
frame the magnetization precesses in the transverse plane around the z-axis at an angular frequency
of x0 radians/sec. In the rotating reference frame it is the axes themselves (x#,y#) that rotate around the
z-axis at x0 radians/sec, and therefore the magnetization appears stationary.
215
5.5 T1 and T2 relaxation times

For example, after a 90 pulse the value of Mz is given by:
MzðtÞ 5 M0 1  e t
T1


:
ð5:16Þ
Different tissues have different values of T1, and diseased tissues often have
substantially altered T1 relaxation time compared to healthy tissue, and these
differences form one basis for introducing contrast into the MR image. Values
of tissue T1 values for 1.5 and 3 Tesla are shown in Table 5.1. It can be seen that
the values of T1 depend not only upon tissue type but also the magnetic ﬁeld
strength, a topic covered more fully in Section 5.13.
Figure 5.10 shows the time dependence of the Mz magnetization after a 90
pulse for two tissues with different T1 values.
The second relaxation time, T2, governs the return of the Mx and My compo-
nents of magnetization to their thermal equilibrium values of zero. If an RF pulse
of arbitrary tip angle a is applied along the x-axis, the value of My at time t after the
RF pulse is given by:
MyðtÞ 5 M0 sin a exp 
t
T2


:
ð5:17Þ
As is the case for T1 relaxation times, different tissues in the body have different
values of T2, and these can also be used to differentiate between healthy and
diseased tissues in clinical images. Similarly to T1, the values of T2 also depend
on B0, and Table 5.1 shows typical values at 1.5 and 3 Tesla. It should be noted that
there is no direct correlation between the T1 and T2 values, a long T1 does not
necessarily mean a long T2. The only thing that is universally true, detailed further
in Section 5.13, is that T1 is always greater than T2.
'y
'x
z
'y
'x
z
'y
'x
z
time
Figure 5.9
(left) Magnetization vector after a 90 RF pulse about the x-axis. (centre) T1 and T2 relaxation of the
magnetization a certain time after the pulse has been applied results in an increased Mz component
and reduced My component, respectively. (right) After a further time, the Mz and My components
have almost returned to their equilibrium values of M0 and zero, respectively.
216
Magnetic resonance imaging (MRI)

The mechanism that gives rise to T2 relaxation is shown in Figure 5.11.
Although it has been assumed that all protons precess at exactly the same fre-
quency, in practice molecular dynamics means that there is a small spread in the
precessional frequencies. In the rotating reference frame one can visualize this as
the vectors spreading out in time. The phase (u) of the vector is deﬁned as the
angle of the vector with respect to the y# axis. As the vectors spread out, they
accumulate different values of u, and lose ‘phase coherence’. The vector sum of all
the individual magnetic moments decreases exponentially, and when the vectors
are randomly located around the transverse plane, the MR signal is zero and
therefore the Mx and My components have returned to equilibrium.
In practice there is an important additional factor which leads to relaxation of Mx
and My back to zero. This arises due to spatial inhomogeneities in the B0 ﬁeld
within the patient. There are two sources for these variations. The ﬁrst is the fact
t
Mz
M0
0
Figure 5.10
The recovery of Mz magnetization as a function of time after a 90 pulse for a tissue with short T1
relaxation time (solid line) and long T1 relaxation time (dashed line). When t = 5*T1, Mz~99% M0,which
is assumed to be full recovery.
Table 5.1: Tissue relaxation times (ms) at 1.5 and 3 Tesla
Tissue
T1 (1.5 T)
T1 (3 T)
T2 (1.5 T)
T2 (3 T)
Brain (white matter)
790
1100
90
60
Brain (grey matter)
920
1600
100
80
Liver
500
800
50
40
Skeletal muscle
870
1420
60
30
Lipid (subcutaneous)
290
360
160
130
Cartilage
1060
1240
42
37
217
5.5 T1 and T2 relaxation times

that it is not possible to design a magnet which produces a perfectly uniform B0
ﬁeld over the entire imaging volume. MR magnets are designed to produce as large
a volume of as homogenous a ﬁeld as possible, as covered in Section 5.14.1, but
there are manufacturing and physical limits to the homogeneity that can be
achieved. The second source arises from local variations in magnetic ﬁeld due
to the different magnetic susceptibilities of different parts of the body. For exam-
ple, close to any surgical implant (even if it is constructed from an MRI compatible
material such as titanium) the material properties alter the effective B0 ﬁeld sig-
niﬁcantly. This also occurs, albeit to a lesser extent, at interfaces between tissues
with very different properties, for example near air cavities in the head (air is
paramagnetic due to its oxygen content). If there are large local variations in the
B0 ﬁeld, then from Equation (5.9) there are large variations in the proton preces-
sion frequencies, which will cause much more rapid dephasing of the magnet-
ization than pure T2 relaxation. The effects of local B0 ﬁeld inhomogeneity are
characterized by a relaxation time T2
+. The combined relaxation time is designated
by T2*, the value of which is given by:
1
T
2
5
1
T 1
2
1 1
T2
:
ð5:18Þ
In MRI, T2* values can vary from less than a millisecond close to a metallic
implant, to tens of milliseconds near air/tissue interfaces, to hundreds of milli-
seconds for very homogeneous tissue in the brain.
My
'x
'y
'z
My
'x
'y
'z
time
time
a
b
Figure 5.11
The time-dependence of the My component of magnetization for (a) a tissue with relatively long T2*
and (b) one with a shorter T2*. The decrease in signal occurs due to the loss of phase coherence of the
protons, i.e. protons precess at slightly different frequencies, thus acquiring different phases and
reducing the net magnetization along the y-axis. The faster the dephasing process the shorter the T2*
relaxation time.
218
Magnetic resonance imaging (MRI)

5.6
Signals from lipid
The assumption so far has been that all protons in the body resonate very close to
the same frequency, and this is true for water protons within tissue, However,
protons in lipid resonate at a signiﬁcantly different frequency from those in water.
The largest number of protons in lipid are present as – CH2- groups in long-chain
fatty acids. The reason why the resonant frequencies of protons in lipid are differ-
ent from those in water is that the strength of the magnetic ﬁeld experienced by a
proton depends not only upon the B0 ﬁeld strength, but also is affected by the
geometry of the electron conﬁguration which surrounds the proton. Analogous to a
proton, an electron is a spinning, charged particle and has an electronic magnetic
moment which produces a small magnetic ﬁeld opposite in polarity (since it is
negatively charged) to the main magnetic ﬁeld, B0. This reduces the effective
magnetic ﬁeld, Beff, experienced by the proton:
Beff 5 B0ð1  rÞ;
ð5:19Þ
where r is called the shielding constant, and is related to the electronic environ-
ment surrounding the nucleus. The resonant frequency of the proton is given by:
x 5 cBeff 5 cB0ð1  rÞ:
ð5:20Þ
As shown in Figure 5.12, lipid (-CH2-) and water (H2O) have different electron
distributions around the protons, due primarily to the different electronegativities
of the oxygen and carbon atoms, and so the protons in the two species resonate at
different frequencies. Since oxygen is much more electronegative than carbon,
electrons are pulled away from the protons in water more so than in lipid, and
O
H
H
C
C
C
H
H
Figure 5.12
The electron density distribution (shaded area) surrounding protons in water and lipid. The strong
electronegativity of the oxygen atom in water pulls electrons away from the proton, leaving it
unshielded compared to the protons in lipid.
219
5.6 Signals from lipid

the water protons are less shielded. This means that the value of r for water is less
than that for lipid, and the resonant frequency is higher. At 3 Tesla the difference in
resonance frequencies is roughly 2500 rad s21 or 400 Hz.
5.7
The free induction decay
Combining the phenomena of the effects of an RF pulse, MR relaxation, chemical
shift, and detection via Faraday induction, the measured MR signal from a human
subject is shown in Figure 5.13. This is often referred to as the free induction decay
(FID), the name referring to the fact that the signal precesses freely after the RF
pulse has been turned off, it is detected via electromagnetic induction, and decays
to a zero equilibrium value. If two coils are present then both the Mx and My
components of magnetization can be detected separately, as shown earlier. It is
most convenient to look at the signals in the frequency-domain, rather than time-
domain, and this is performed using a Fourier transform of the time-domain signal,
as covered in Chapter 1. Figure 5.13 shows the real part of the Fourier transformed
MR spectrum. There are two frequencies, as expected, corresponding to protons in
lipid (lower frequency) and water (higher frequency). These peaks are not sharp
delta functions, but have a Lorenzian lineshape arising from the Fourier transform
of the exponentially decaying function. The linewidth of each peak is given by
1/pT2*.
time
time
frequency
water
lipid
Δ f
FWHM
FWHM
Mx(t)
My(t)
Δ f
Figure 5.13
(left) x- and y-components of magnetization as a function of time, showing ‘beat patterns’ which
come from the two different resonant frequencies of lipid and water. The real part of the frequency
spectrum, shown on the right, shows the two peaks separated by Df Hz.
220
Magnetic resonance imaging (MRI)

5.8
Magnetic resonance imaging
The signal shown in Figure 5.13 contains no spatial information, i.e. there is no
way to distinguish between signals coming from protons located at different spatial
positions within the body. The concept of making MR an imaging modality origi-
nated relatively recently [2] with the realization that if the magnetic ﬁeld could be
made to vary spatially within the subject, this would in turn impose a spatial
variation in resonant frequencies that could be exploited to form an image. Such
spatial variations have to be varied dynamically. This is performed by incorporat-
ing three separate ‘gradient coils’, described in detail in Section 5.14.2, into the
design of an MRI scanner. These gradient coils are designed so that the spatial
variation in magnetic ﬁeld is linear with respect to spatial location, i.e.
@Bz
@z 5 Gz; @Bz
@x 5 Gx; @Bz
@y 5 Gy;
ð5:21Þ
where G represents the gradient measured in T/m. The three separate magnetic
ﬁeld gradients are produced by passing a DC current through separate coils of wire.
An example of a coil design which produces a linear gradient in the z-direction is
shown in Figure 5.14. The current in each set of gradient coils comes from high-
power gradient ampliﬁers which supply hundreds of amps: the current can be
turned on and off very quickly under computer control. The gradient coils are also
designed such that there is no additional contribution to the magnetic ﬁeld at the
isocenter (z = 0, y = 0, x = 0) of the gradients, which means that the magnetic ﬁeld
at this position is simply B0. By convention, the y-axis corresponds to the anterior/
posterior direction, and the x-axis to the left/right direction of a patient lying in the
magnet. The gradient coils are permanently ﬁxed to the inside of the superconduct-
ing magnet, as explained more fully in Section 5.14. Figure 5.14 shows a plot of
magnetic ﬁeld vs. spatial position for a gradient applied along the z-axis.
The magnetic ﬁeld, Bz, experienced by protons with a common z-coordinate is
given by:
Bz 5 B0 1 zGz:
ð5:22Þ
From the graph shown in Figure 5.14, at position z = 0, Bz = B0; for all positions
z . 0, Bz . B0, and for positions z , 0, Bz , B0. If the direction of the current in
the gradient coils were reversed, referred to as applying a negative gradient, then
the slope in Figure 5.14 would be negative and for all positions z . 0, Bz , B0,
and for positions z , 0, Bz . B0. The precession frequencies (xz) of the protons,
as a function of their position in z, are given by:
xz 5 cBz 5 cðB0 1 zGzÞ:
ð5:23Þ
221
5.8 Magnetic resonance imaging

In the rotating reference frame the precession frequency is:
xz 5 czGz; or fz 5 c
2p zGz:
ð5:24Þ
Analogous expressions can be obtained for the spatial dependence of the reso-
nant frequencies in the presence of the x- and y-gradients. Typical maximum
values of gradient strength on clinical systems are ~40 mT per metre.
Example 5.4
Calculate the resonant frequencies for protons at the top and bottom of the head in
a 3 Tesla scanner if a z gradient of 40 mT/m is applied. Assume that the centre of
the head is in the centre of the gradient coil, and the head is 25 cm in length. What
would be the effect if a negative gradient of -20 mT is applied?
Solution
The resonant frequency of protons at the centre of the head is 127.7 MHz, since the
additional ﬁeld from the gradients is zero. For the top of the head, the extra ﬁeld is
given by 0.04 T/m 3 0.125 m = 0.005 T. This corresponds to 0.005 T 3 42.58
MHz/T ~213 kHz. For the bottom of the head the corresponding number is
obviously 2213 kHz. Therefore, the overall spread is ~426 kHz. If a negative
gradient of 220 mT/m is applied, then the spread will be one-half that calculated
previously, or 213 kHz. However, protons at the top of the head now resonate at a
frequency 106.5 kHz lower than those at the centre of the head, and protons at the
bottom of the head resonate 106.5 kHz higher than those at the centre.
B0
x
y
z
Position
At z=0, Bz=B0
+z
-z
Slope=Gz
Bz
0
I
I
B0
0
-
Gz
z
Figure 5.14
(left) A Maxwell-pair gradient coil in which an equal and opposite current is passed through a set of
wires which are wound around a cylinder with its major axis in the z-direction. (right) The resulting
magnetic ﬁeld, Bz, is a function of position in z. The slope of the graph is Gz, the z-gradient. Since the
currents in the two halves of the gradient coil are equal, the total magnetic ﬁeld at the centre of the
gradient coil is B0. Applying Fleming’s left-hand rule, given the current directions indicated, the total
magnetic ﬁeld is less than B0 for z , 0 and greater than B0 for z . 0.
222
Magnetic resonance imaging (MRI)

5.9
Image acquisition
The process of image formation canbe broken downinto three separate, independent
components, slice selection, phase-encoding and frequency-encoding, covered in
the following sections. An overall imaging ‘pulse sequence’ is shown in Figure
5.15 (a). The transmitter line indicates when an RF pulse is applied, and the length
and power of the pulse are adjusted to give the indicated tip angle. For each gradient
line, the height of the gradient pulse indicates its strength, and the polarity (positive
or negative) indicates which direction current is ﬂowing through the particular
gradient coil. The A/D line shows when the receiver is gated on, and how many
data points (Nf) are acquired while the frequency encoding gradient is turned on.
The entire sequence of RF pulse and three gradients has to be repeated a number of
times (Np typically is between 128 and 512) to build-up a two-dimensional data set,
with the arrow next to the phase encoding gradient indicating that different values
are used for each repetition of the sequence. Since each of the three components can
be treated completely independently, gradient events in practice are overlapped to
reduce the overall time of the imaging sequence, as shown in Figure 5.15 (b).
5.9.1 Slice selection
The ﬁrst part of planning an MRI scanning session is to decide in which orientation
the slice should be acquired. Unlike in CT, in which axial sections are always
a
b
90o
Nf data points
Np
RF
Gphase
A/D
Gslice
Gfreq
90o
Nf data points
Np
RF
Gphase
A/D
Gslice
Gfreq
o
Nf
Np
o
Nf
Np
Figure 5.15
Pulse sequence diagrams for imaging sequences. An RF pulse is applied, various gradients are
turned on and off, and the analogue-to-digital (A/D) converter is gated on to acquire data. (a)
Individual steps in image formation can be considered independently in terms of slice selection (RF
and Gslice), phase encoding (Gphase) and frequency encoding (Gfreq and the A/D on). (b) In practice,
the gradients are applied simultaneously where appropriate in order to minimize the time between
RF excitation and signal acquisition.
223
5.9 Image acquisition

acquired, MRI can acquire the image in any given orientation. For example,
coronal, axial or sagittal images, corresponding to slice-selection in the y-, z-, or
x-directions, respectively, can be chosen, as shown in Figure 5.16. In practice,
different clinical imaging protocols of various parts of the body call for different
image orientations.
Slice selection uses a frequency-selective RF pulse applied simultaneously with
one of the magnetic ﬁeld gradients (Gx, Gy or Gz), denoted by Gslice. The selective
RF pulse is applied at a speciﬁc frequency xs, with an excitation bandwidth of
6Dxs. This is analogous to a radio station transmitter, which transmits energy at a
certain frequency over a limited bandwidth. Protons which have a precession
frequency within the bandwidth (between xs + Dxs and xs 2 Dxs) are rotated
into the transverse plane by the RF pulse, but protons with precession frequencies
outside the bandwidth are not affected. Figure 5.17 shows the orientation of the
protons after a 90 pulse, assuming that an axial slice was chosen.
e
cils la
n
o
r
o
C
e
cils laix
A
e
cils
lattig
a
S
tn
eid
ar
g tc
ele
s e
cil
S
Gz
Gy
Gx
e
g
a
m
I
n
oitatn
eir
o e
g
a
m
I
x
z
x
y
y
z
Figure 5.16
Showing the different orientations for image acquisition. Coronal (top), axial (middle) or sagittal
(bottom) slices can be produced by turning on the y, z, or x gradients, respectively, while the RF pulse
is being applied.
224
Magnetic resonance imaging (MRI)

The slice thickness (T) is given by:
T 5 2Dxs
cGslice
:
ð5:25Þ
The slice can therefore be made thinner either by increasing the strength of Gslice
(up to its maximum value) or decreasing the frequency bandwidth of the RF pulse.
The ideal frequency excitation proﬁle of the RF pulse is a rectangular shape, in
which case an equal tip angle is applied to all the protons within the slice, and zero
tip angle to protons outside the slice. Using the Fourier transform properties in
Section 1.9.1, a sinc or similarly shaped RF pulse, typically with a length of a few
ms, is used. The slice position can be moved to different parts of the patient by
changing the value of xs of the RF pulse.
Example 5.5
If the maximum gradient strength is 40 mT/m, calculate the bandwidth of the RF
pulse necessary to give a 1 mm slice thickness. If the slice thickness is decreased to
0.5 mm, is the required RF pulse shorter or longer than for a 1 mm slice thickness?
Solution
Using Equation (5.23):
1 3 103 m
ð Þ 5
2Dxs
267:54 3 106 HzT1
ð
Þ0:04 Tm1
ð
Þ :
Solving gives a bandwidth 2Dxs of 10 070 rads21 or 1700 Hz.
From the properties of the Fourier transform, a longer RF pulse results in a
narrower frequency spectrum, and therefore the thinner slice requires an RF pulse
of double the length for a given value of Gslice.
z
frequency
Slice thickness
Gslice
s− 
s
s + 
s
s
slice centre
− 
s
s + 
s
s
Figure 5.17
(left) The effects of a 90 RF pulse applied simultaneously with the z-gradient. Only protons within
the axial slice are tipped by 90 into the transverse plane, and so give a measureable MR signal.
Protons outside the chosen slice have their net magnetization remain in the z-direction. (right) Showing
the gradient strength (the slope of the graph) as a function of position in z.
225
5.9 Image acquisition

Analyzing the motion of the protons within the slice more closely, due to the fact
that the RF pulse is relatively long (typically 1 millisecond or longer), protons at
different z-positions within the slice precess around B0 during the pulse, and
therefore accumulate different phases (uslice), as shown in Figure 5.18:
usliceðzÞ 5 cGzz s
2 ;
ð5:26Þ
where s is the duration of the RF pulse. The net magnetization, given by the
vector sum of all the individual vectors, is reduced compared to its value if the RF
pulse were very short. Fortunately, there is a simple way to ‘reverse’ this dephasing
of the magnetization. A negative rephasing gradient (Gref
slice) is applied for a time
sref. Assuming that the gradient waveforms are perfectly rectangular, complete
refocusing occurs when:
Gref
slicesref 5 s
2 Gz:
ð5:27Þ
5.9.2 Phase encoding
Continuing with the example of an axial slice, in which the slice select gradient
was applied in the z-direction, the x and y directions are now encoded via the phase
slice
x'
y'
sl
x'
y'
x'
y'
sl
x'
y'
a
b
c
Figure 5.18
(a) Since the slice has a ﬁnite thickness, protons at different z-positions within the slice precess at
different frequencies during the RF pulse. (b) At the end of the RF pulse protons at each z-position
have acquired a phase usl given by Equation (5.26), and the net magnetization vector is reduced
signiﬁcantly due to the lack of phase coherence. (c) Application of a negative rephasing slice gradient
of the appropriate duration and strength refocuses all the magnetization to give the maximum net
magnetization.
226
Magnetic resonance imaging (MRI)

and frequency of the MR signal [3,4]. For a simple imaging sequence it is not
important which dimension is encoded by the phase and which by the frequency.
As shown in Figure 5.15, a phase encoding gradient (Gphase) is turned on for a
period spe and then switched off. If Gphase corresponds to the y-dimension, during
the interval spe the protons precess at a frequency xy = cGyy. The net effect is to
introduce a spatially dependent phase shift, upe(Gy,spe), with a value given by:
upe Gy; spe


5 xyspe 5 cGyyspe:
ð5:28Þ
This is shown in Figure 5.19, for ﬁve protons at positions y = 0, +1, +2, +3, and
+4 cm with respect to the centre of the gradient coil. The value of the ﬁrst phase
encoding gradient, Gpe1, corresponds to the maximum negative gradient step, as
shown in Figure 5.15. This induces different phase shifts, where u2 = 2u1, u3 =
3u1, and u4 = 4u1, as shown in Figure 5.19. The second value of the phase
encoding gradient, Gpe2, corresponds to a value slightly less negative than Gpe1,
with the difference given by DGpe. The phase shifts at each y-position are therefore
slightly less than for Gpe1.
y=1 cm 
y=2 cm 
y=3 cm 
y=4 cm 
1
3
4
G pe1 
1
2
3
G pe2 
y=0 cm 
x ' 
x ' 
x ' 
x ' 
x ' 
x'
x'
x'
x'
x'
y ' 
y ' 
y ' 
y ' 
y ' 
y ' 
y ' 
y ' 
y ' 
y ' 
2
4
x ' 
x ' 
x ' 
x ' 
x ' 
' 
' 
' 
' 
' 
x'
x'
x'
x'
x'
'
'
'
'
y ' 
y ' 
y ' 
y ' 
y ' 
' 
' 
' 
' 
y ' 
y ' 
y ' 
y ' 
y ' 
' 
' 
' 
' 
' 
Figure 5.19
Phase encoding for protons at four different vertical positions with respect to the centre of the y-
gradient. In the upper panel, a gradient Gpe1 is applied. Protons at the very centre of the y-gradient
experience no additional magnetic ﬁeld and so accumulate no phase in the rotating reference frame.
The larger the offset in the y-dimension, the larger the phase shift accumulated. In the lower panel,
the next value of the phase encoding gradient is applied, with Gpe2 being slightly less negative than
Gpe1. Again, protons at y=0 accumulate no phase, and protons at different y-positions accumulate
phases slightly lower in value than when Gpe1 was applied. Typically between 128 and 512 different
values of Gpe are used to acquire the full image.
227
5.9 Image acquisition

5.9.3 Frequency encoding
The x-dimension is encoded by applying a frequency-encoding gradient (Gfreq)
while the receiver is gated on and data are being acquired. During this time t,
protons precess at a frequency given by xx = cGxx determined only by their x-
location. A total of Nf data points are acquired while the receiver is on.
Overall, this means that for each phase encoding step each voxel in the image is
characterized by a speciﬁc phase which depends upon its position in y, and speciﬁc
frequency which depends upon its position in x, as shown in Figure 5.20.
To form, for example, a 256 3 256 image, Nf = 256 and the sequence must be
repeated 256 times, each time with a different value of the phase encoding gra-
dient, ranging from its maximum negative to maximum positive value in equal
increments of DGpe. In order for sufﬁcient T1 relaxation to occur so that a signiﬁ-
cant fraction of Mz magnetization recovers between successive RF excitations,
there is a delay between successive RF pulses, called the TR (time of repetition)
y=1 cm 
y=2 cm 
y=3 cm 
y=4 cm 
1
x=1 cm 
x=2 cm 
x=3 cm 
1 
ω 2 
ω 3 
1 
ω 1 
ω 1 
ω 2 
ω 3 
ω 2 
3 
ω 2 
ω 3 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
x ' 
y ' 
1 
2 
3 
ω 1 
1 
ω 1 
2 
ω 3 
3 
ω 1 
1 
1 
ω 1 
3 
x ' 
y 
1
1
2
2
2
3
3
3
4
4
4
' 
' 
' 
x ' 
y ' 
y ' 
x ' 
y ' 
' 
y ' 
x ' 
y ' 
' 
' 
x ' 
' 
' 
' 
' 
y ' 
' 
' 
x ' 
' 
x ' 
y ' 
' 
' 
x ' 
y ' 
' 
' 
Figure 5.20
Combined effect of phase and frequency encoding gradients. The phases accumulated by protons
at a given y-position are identical to those shown in Figure 5.19. During data acquisition the
frequencies at which the protons precess are linearly dependent upon their position in the
x-dimension. In this case x2 = 2x1 and x3 = 3x1.
228
Magnetic resonance imaging (MRI)

time. Overall, the total data acquisition time is therefore given by the TR multiplied
by the number of phase encoding steps applied, TR*Npe.
5.10
The k-space formalism and image reconstruction
To understand how the acquired data are transformed into an image, it is instructive
to express the (Nf 3 Npe) signals mathematically as
s Gy; spe; Gx; t


}
ð
slice
ð
slice
q x; y
ð
ÞejcGyyspeejcGxxtdxdy:
ð5:29Þ
One can treat the slice, phase and frequency encoding terms independently. The
double integral over the slice represents the fact that signal comes only from
protons within the slice, and that there is no signal from protons outside this slice.
The factor q(x,y) is the number of protons at each position (x,y) within this slice,
and is called the proton density. This can be related to the term Ntotal in Equation
(5.10): the signal intensity is directly proportional to the number of protons in each
voxel. The second term in the integral represents the phase term (uy = cGyyspe)
from the phase encoding gradient. The third term in the equation represents the
spatially dependent resonance frequency (xx = cGxx).
A very useful model is the ‘k-space’ formalism developed by Ljunggren [5].
Two variables, kx and ky, are deﬁned as:
kx 5 c
2p Gxt; ky 5 c
2p Gyspe:
ð5:30Þ
The k values are spatial frequencies, as covered in Chapter 1. Equation (5.29)
can now be expressed in terms of these two variables:
S kx; ky


}
ð
slice
ð
slice
q x; y
ð
Þej2pkxxej2pkyydxdy:
ð5:31Þ
The acquired data can therefore be represented as a two-dimensional data set in
kx,ky-space. Consider the Nf data points collected when the maximum negative
value of the phase-encoding gradient, Gy, is applied. From Equation (5.30) the
value of ky for all Nf data points corresponds to its maximum negative value. As
shown in Figure 5.15, a negative gradient , is applied in the x-direction before data
acquisition. Denoting the strength of this gradient by Gdephase and the time for
which it is applied by sdephase, then the values are chosen are chosen such that:
Gdephasesdephase 5 Tacq
2 Gfreq:
ð5:32Þ
229
5.10 The k-space formalism and image reconstruction

This means that the dephasing gradient is exactly cancelled out at the centre of
the acquisition time (Tacq). The ﬁrst data point acquired when the frequency-
encoding gradient is switched on corresponds to a negative value of kx, the second
data point to a slightly more positive value of kx and so forth. After the ﬁrst Nf/2
data points have been acquired kx reaches a value of 0, and then becomes positive
for the remaining Nf/2 data points. Therefore, the Nf data points correspond to one
‘line’ in k-space, shown as line 1 in Figure 5.21. The second line in k-space
corresponds to the next value of the phase-encoding gradient, and so is displaced
to a more positive value of ky. In this way, the full two-dimensional k-space matrix
is acquired, as shown in Figure 5.21.
How is the image formed from the acquired k-space data? In Section 1.9.1 the
inverse Fourier transform of a function S(kx,ky) was given by:
kx
ky
Δkx=1/FOVx
Δky=1/FOVy
kx
ky
line 1
line 2
line 3
line 4
Δkx=1/FOV
Δky=1/FOVy
Figure 5.21
k-space: data acquisition occurs line-by-line, with the ﬁrst line acquired corresponding to the
maximum negative value of the phase encoding gradient. The values of Dkx and Dky between
successive data points are equal to the inverse of the respective ﬁelds-of-view of the image (see
Exercise 5.15).
230
Magnetic resonance imaging (MRI)

qðx; yÞ 5
ð‘
‘
ð‘
‘
S kx; ky


e1j2p kxx 1 kyy
ð
Þdkxdky:
ð5:33Þ
This shows that a two-dimensional inverse Fourier transform of the k-space data
S(kx, ky) gives q(x,y), in other words the MR image, as shown in Figure 5.22. In
fact, the inverse Fourier transform gives a complex image, with real and imaginary
components, but MR images are nearly always represented in magnitude mode, i.e.
the magnitude of the real and imaginary components. Also in Figure 5.22 it is clear
that the maximum acquired signal occurs at the centre of k-space, kx = 0, ky = 0.
This can be seen from Equation (5.31), in which both exponential terms become
unity. The low values of k-space correspond to low spatial frequencies, with the
value of kmax representing the highest spatial frequency, as discussed in Chapter 1.
The higher is the value of kmax, i.e. the higher the number of phase encoding steps
acquired, the higher the spatial resolution.
5.11
Multiple-slice imaging
The imaging sequence shown in Figure 5.15 acquires an image from one slice
through the body. Clearly, one would like to acquire images from multiple slices
through the patient. If it were necessary to repeat this process serially for every
single slice, then MR scanning would take an extremely long time. As noted
earlier, the typical T2* values for tissue are much shorter than the T1 relaxation
times, and so the TR time required between successive RF excitations for each
kx
ky
x
y
T
F
F
 e
sre
v
ni 
D
-
2
T
F
F
 d
ra
w
r
o
f 
D
-
2
Figure 5.22
The mathematical relationship between the acquired k-space data on the left and the image on the
right is a two-dimensional Fourier-transform. Although both the k-space data and image data are
complex with real and imaginary components, they are both typically illustrated in magnitude mode.
231
5.11 Multiple-slice imaging

phase encoding step is much longer than the TE. Therefore, the ‘waiting time’, TR-
TE, can be used to acquire data from other slices. To excite a slice exactly adjacent
to the previous one, the only parameter that needs to be changed is the centre
frequency of the RF pulse: the slice select, phase and frequency encoding gradients
are repeated exactly as before, and the data from this second slice are stored
separately from the ﬁrst. This process is shown in Figure 5.23. The maximum
number of slices is given by the value of TR/TE. In practice, a small gap is left
between the slices (typically one-tenth of the slice thickness) and the slices are
acquired in an interlaced fashion, i.e. all the odd-numbered slices followed by all
the even-numbered. The reason is that the non-ideal frequency proﬁle of the RF
slice 1
slice 2
slice 3
slice 2
slice 3
TR
TE
A/D
TE
TE
2 
3 
slice 1
1 
1 
Gslice,z
slice 1
slice 2
slice 3
slice 1
TR
TE
A/D
TE
TE
2 
3 
1
1
Gslice,z
Figure 5.23
(top) Multiple-slice gradient echo sequence, which can be used to acquire many adjacent slices
during one TR interval. For clarity, only the slice select gradient is shown: in practice the phase
encoding and frequency encoding gradients are applied according to Figure 5.15(b) for each slice in
turn. (bottom) Three adjacent axial slices through the brain acquired with the slice select direction
being in z.
232
Magnetic resonance imaging (MRI)

pulses results in a small angle tip of the protons either side of the selected slice. By
waiting a time TR/2 to acquire these adjacent slices, the magnetization outside
each slice has time to return to its full equilibrium value.
5.12
Basic imaging sequences
A typical clinical MRI protocol takes between half-an-hour and an hour, and may
consist of between three and six different types of scan. The following sections
cover the basic sequences used in most clinical scans: more advanced concepts are
expanded upon in Section 5.16.
5.12.1 Multi-slice gradient echo sequences
The basic gradient echo sequence has already been analyzed in Section 5.8, with
the imaging sequence shown in Figure 5.15. For an axial image acquired using
slice-selection in the z-direction, the image intensity of each (x,y) voxel, I(x,y), is
given by:
I x; y
ð
Þ}q x; y
ð
Þ
1  eTR
T1


sin a
1  eTR
T1 cos a
e
TE
T
2:
ð5:34Þ
Although the SNR is maximized using a = 90, this requires a long TR to allow
full T1 relaxation to occur, and in turn gives rise to a long image acquisition time.
For example, if the tissue T1 is 1 s, and TR is set to 3*T1 to allow almost complete
(.95%) T1 relaxation, then a 256 3 256 multi-slice image data set will take 8
minutes to acquire, and a high resolution 512 3 512 over 16 minutes, which is
extremely long by clinical standards.
To image more rapidly, a is reduced to a value considerably smaller than 90. It
is relatively easy to show (Exercise 5.11) that for a given value of TR the value of a
which maximizes the signal intensity is given by
aErnst 5 cos1 eTR
T1:
ð5:35Þ
where the optimal angle, aErnst is named after the Swiss scientist Richard
Ernst who won the Nobel Prize for Chemistry in 1989 for his contributions to
magnetic resonance. For example, if TR is reduced to 0.05 T1 then the optimum
value of a is only 8. Using these parameters, images can be acquired in a few tens
of seconds.
233
5.12 Basic imaging sequences

Example 5.6
For a TR time equal to the T1 value of the tissue, what angle should used for the RF
pulse to maximize the SNR? How much greater is the SNR than would have been
achieved had the RF pulse mistakenly been set to 90?
Solution
The optimal angle is given by:
aErnst 5 cos1 e1 5 cos1 0:3679
ð
Þ 5 68o:
Plugging this value into Equation (5.34) gives an I(x,y) value of 0.68q(x,y)e2TE/T2.
If an angle of 90 had been used, then this value would have been 0.63 q(x,y)e2TE/T2.
From Equation (5.34) one can see that there are three separate components that
affect the signal intensity: the proton density, a combination of the TR,T1 and a
values, and the TE and T2* values. The data acquisition parameters in a gradient-
echo sequence can be set to emphasize, or ‘weight’, the image intensity by one or
all of the tissue parameters q(x,y), T1 or T2*, depending upon the choice of data
acquisition parameters. For example, suppose that we are trying to differentiate
between two tissues A and B. The proton density for A is 1.0, and for B is 1.2. The
T1 value for A is 1 s and that of B is 1.3 s. Finally, the T2* of A is 35 ms, and of B is
30 ms. If the value of TE is set to 1 ms, then the relative signals due to T2* decay
alone are 0.972 and 0.967 for A and B respectively, a very small difference.
Therefore, the image intensity is not ‘weighted’ by the different values of T2*
for tissues A and B. In contrast, if TE is set to 30 ms, then the signals are 0.368 and
0.424 which is a much larger difference: the image can now be said to be T2*-
weighted. Similarly, for a given value of TR, the higher the value of a the higher
the T1-weighting of the image, i.e. the greater the extent to which the relative
intensities of tissues A and B depend upon the respective T1 values. Alternatively,
for a ﬁxed a the shorter the TR the higher is the T1-weighting. Finally, the proton
density of course cannot be changed, since it is a ﬁxed physical value. If
the sequence parameters are chosen so that there is no T1-weighting and no
T2*-weighting, then the image is said to be proton-density weighted. Table 5.2
shows the possible combinations of imaging parameters and the corresponding
weighting.
5.12.2 Spin echo sequences
Gradient-echo sequences allow very rapid image acquisition. The major disadvant-
age is that they do not allow images to be weighted by the different T2 values, but
rather only by the T2*value. Since, as discussed previously, T2* values are typi-
cally much shorter than T2 this leads not only to lower signal intensities than if one
234
Magnetic resonance imaging (MRI)

could weight by T2, but also the differences in the tissue T2 values can be ‘masked’
by the much larger effects that lead to T2* decay. So tissues with quite different T2
values may have much more similar T2* values since these are affected by magnet
and tissue inhomogeneities. To introduce pure T2-contrast into the image, a second
class of sequences is used, termed spin-echo sequences [6].
In a spin-echo sequence two RF pulses are used, the ﬁrst 90 pulse creates My
magnetization, and the second 180 pulse refocuses the effects of T2
+ relaxation. In
order to see how the sequence works, ﬁrst consider the effects of the RF pulses
only as shown in Figure 5.24. Immediately succeeding the 90 pulse the My
component is equal to M0. The effect of T2
+, as shown in Section 5.5, is to cause
protons to have slightly different frequencies, denoted here as Dx, and the net
magnetization vector decreases. At a time s after the 90 pulse, each proton has
precessed through an angle u, given by u = (Dx)s, and has components of both Mx
and My magnetization related by:
u 5 arctan Mx
My


:
ð5:36Þ
The 180 pulse applied about the x-axis does not affect the Mx component of
magnetization, but converts the My component into – My. The effect, from Equa-
tion (5.34), is to convert the phase of the magnetization from + u to (180 – u), as
shown in Figure 5.24. During the second s interval, the precessing magnetization
accumulates an additional phase + u, and so the total phase is 180, meaning that
all vectors lie along the – y axis, and the signal loss during the time 2s is due to T2
relaxation alone. Since the rephasing of the vectors does not depend upon the value
of Dx, the effects of T2
+ are cancelled for all protons:
Sð2sÞ}M0e2s
T2:
ð5:37Þ
Table 5.2: Relationship between imaging parameters and image weighting for a
gradient-echo imaging sequence
Imaging parameters
Image weighting
TE  T2*, and either a  aErnst or TR  T1
or both
proton density
TE  T2*, and either a~aErnst or TR~T1 or
both
T1-weighted
TE.T2*, and either a  aErnst or TR  T1
or both
T2*-weighted
TE.T2*, and either a~ aErnst or TR~T1 or
both
mixed T1- and T2*-weighted
235
5.12 Basic imaging sequences

In the imaging version of the spin-echo sequence, shown in Figure 5.25, the 90
and 180 pulses are applied together with Gslice to select and refocus protons in the
desired slice. Phase-encoding is carried out exactly as described previously for the
gradient-echo sequence. In the frequency encoding dimension, the dephasing gra-
dient in a spin-echo sequence is applied between the 90 and 180 pulses with the
same polarity as is used during data acquisition.
The intensity of an axial image acquired using a spin-echo sequence is given by:
I x; y
ð
Þ}q x; y
ð
Þ 1  eTR
T1


eTE
T2:
ð5:38Þ
Following the same type of analysis as in Section 5.11 for the gradient-echo
sequence, a spin-echo image can be T1-, T2- or proton density-weighted. If the
value of TR is set to a value much greater than or much less than the T1 of any of
the tissues, then the image has no T1-weighting, since the term 1-exp(-TR/T1) is
very close to either unity or zero for all tissues. The general concept is shown in
Figure 5.26, using T1 values of 900 ms for grey and 780 ms for white matter. There
is an optimal value of TR which maximizes the contrast between white and grey
x'
y'
z'
x'
y'
z'
1
2
x'
y'
z'
1
2
x'
y'
z'
90x
180x
time
MR signal
M0e 2 /T2
M0
x'
y'
z'
x'
y'
z'
1
2
x'
y'
z'
1
2
x'
y'
x'
y'
x'
y'
x'
y'
1
2
x'
y'
1
2
1
2
1
2
x
x
x
x
M0e 2 /T2
M0
M0e
/T2
M0
0
−2 /T2
M0
Figure 5.24
Spin echo sequence consisting of two RF pulses separated by a time s. During this s interval, protons
precess at slightly different frequencies (two protons are shown with frequencies Dx1 and Dx2
with respect to the Larmor frequency) due to inhomogeneities in the main magnetic ﬁeld (T2
+) and
intrinsic T2 mechanisms. The effect of the 180 pulse is to refocus the T2
+ decay, so that the intensity
of the echo signal acquired at a time s after the 180 pulse is affected only by T2 processes.
236
Magnetic resonance imaging (MRI)

matter. The same type of consideration applies to the term exp(-TE/T2) in Equation
(5.38) which determines the degree of ‘T2-weighting’ in the sequence. If the value
of TE is set to be much shorter than the tissue T2 values, then no T2 contrast
is present, and if the value of TE is too long, then the SNR of the image is very
low: the optimum value of TE results in the highest image CNR, as shown in
Figure 5.26.
Images can also be acquired with ‘proton-density-weighting’ by setting a TR
value much longer than T1, and a TE value much shorter than T2. Multi-slice
imaging is performed in exactly the same way as for gradient-echo imaging. Figure
5.27 shows spin-echo images of the brain with different contrast weightings.
5.12.3 Three-dimensional imaging sequences
In multiple-slice gradient-echo or spin-echo imaging sequences, the in-plane
image resolution is typically much higher than the slice thickness. For example,
the slice thickness for a typical brain scan might be 3 mm, but the in-plane
resolution is given by the image ﬁeld-of-view (~25 cm) divided by the number
of data points acquired (256 or 512) i.e. 1 or 0.5 mm. In situations where an
isotropic high spatial resolution is needed, a three-dimensional sequence can be
run: a 3D gradient-echo sequence is shown in Figure 5.28. There are now two
phase encoding gradients, each of which must be incremented independently of the
TE
TR
90
180
RF
Gfreq
Gphase
Gslice
A/D
Npe
Nf data points
90
180
RF
Gfreq
Gphase
Gslice
Npe
Nf
Figure 5.25
Basic spin echo imaging sequence.
237
5.12 Basic imaging sequences

other. This means that the total imaging time is TR 3 Npe1 3 Npe2. For the total
acquisition time to be practical within a clinical setting, the TR must be very short,
meaning that most 3D sequences are gradient-echo based. Mathematically, the 3D
acquired signal can be represented as:
S kx; ky; kz


5
ð‘
‘
ð‘
‘
ð‘
‘
qðx; y; zÞej2p kxx 1 kyy 1 kzz
ð
Þdkxdkydkz:
ð5:39Þ
0
0.5 1
1.5 2
2.5 3
3.5 4
4.5 5
0
0.5
1
TR (seconds)
MRI signal
gray matter (T1=920 ms) 
white matter (T1=790 ms)
maximum contrast
0
0.04
0.08
0.12
0.16
0.2
0.5
1
TE (seconds)
MRI signal
0
maximum CNR
maximum contrast
gray matter (T2=100 ms) 
white matter (T2=90 ms)
Figure 5.26
(left) Plot of MRI signal as a function of TR for white and grey matter in the brain at 1.5 Tesla. The
maximum contrast occurs at a TR value of ~1.4 s, with the contrast-to-noise also maximized very
close to this value. (right) Plot of MRI signal vs. TE for white and grey matter. In this case the maximum
contrast occurs at a long value of TE, but because the signal intensity has decayed to a very low value
by this point, the maximum CNR actually occurs at a somewhat shorter TE value.
Figure 5.27
(left) T1-weighted and (right) T2-weighted axial slice through the brain acquired with a spin-echo
sequence. In the T1-weighted image the CSF ﬁlling the ventricles is much darker than the brain white/
grey matter, whereas in the T2-weighted image it is much brighter.
238
Magnetic resonance imaging (MRI)

Image reconstruction, therefore, uses a three-dimensional inverse Fourier trans-
form. In addition to enabling high spatial resolution in all three dimensions, the 3D
sequence is very efﬁcient since signal is acquired from the entire imaging volume
for every step in the acquisition, as opposed to just a single slice each time for a 2D
multi-slice sequence.
5.13
Tissue relaxation times
As seen in Table 5.1, the T1 and T2 relaxation times can be quite different for
tissues such as cerebral spinal ﬂuid (CSF), kidney and liver, but are quite similar
for grey and white brain matter. The relaxation times can be related to the general
physical properties of the tissue, as well as to chemical properties such as iron and
protein content. Intuitively, one can understand that just as application of a mag-
netic ﬁeld oscillating at the Larmor frequency (the RF pulse) was required to
establish a nonequilibrium Mz value, re-establishment of the equilibrium value
of Mz must occur via a similar mechanism. The oscillating magnetic ﬁeld which
produces relaxation is not created by an RF pulse, but rather by the random
Brownian motion of the magnetic moments in tissue. These randomly ﬂuctuating
magnetic ﬁelds contain components at many different frequencies: a ﬂuid liquid
α o
TR
TE
RF
A/D
Gphase2
Gfreq
Gphase1
Npe1
Np2e
Nf data points
o
TE
RF
phase2
freq
phase1
Nf
Figure 5.28
Three-dimensional gradient echo sequence. There are two incremental phase encoding gradients and
one frequency encoding gradient.
239
5.13 Tissue relaxation times

such as CSF has a broad range of frequencies from very low to very high, whereas
a tissue such as cartilage in which the protons are held in a very tight matrix can
produce only low frequencies. The ‘frequency spread’ of the oscillating magnetic
ﬁelds is quantiﬁed by a parameter called the spectral density, J(x) or J(f). The
higher the value of J(f), the greater the oscillating magnetic ﬁeld component at that
frequency. The component of J(f) at the Larmor frequency, J(f0), can stimulate
transitions between the upper and lower energy states, and thereby cause the Mz
component of magnetization to return to its equilibrium value of M0. The larger the
value of J(f0), therefore, the more effective is the T1 relaxation process and the
shorter the T1 relaxation time.
Figure 5.29 shows typical plots of J(f) vs. frequency, with three speciﬁc
clinical B0 ﬁelds highlighted. Three different tissue types are indicated: one
very viscous such as cartilage, one of intermediate viscosity such as brain grey
matter, and one highly ﬂuid such as the CSF in the brain. The general shapes of
the curves for the three tissues are quite similar. At low magnetic ﬁelds the plots
are ﬂat, with a signiﬁcant decrease in J(f) only occurring at ~1.5 Tesla for the
cartilage and above 4 Tesla for the CSF. From Figure 5.29 one can deduce that
the T1 relaxation time for all tissues increases as a function of ﬁeld strength, but
that this increase is highly non-linear. At low magnetic ﬁelds, T1 relaxation for
high viscosity
intermediate viscosity
low viscosity
J(f)
100
200
300
1.5T
3T
7T
frequency (MHz)
)
100
1.5T
3T
Figure 5.29
Plot of spectral density, J(f), vs. frequency for three tissue viscosities. Also marked are the
resonant frequencies at three common magnetic ﬁeld strengths, 1.5 Tesla (63.9 MHz), 3 Tesla (127.7
MHz) and 7 Tesla (298.1 MHz).
240
Magnetic resonance imaging (MRI)

the cartilage is very efﬁcient since the value of J(f) is high and therefore the T1
value is short. At high ﬁeld strengths, T1 relaxation for cartilage is very inefﬁ-
cient and the T1 value is long. Figure 5.29 also shows that the best contrast
between the three tissues occurs at low magnetic ﬁeld strengths, and that at very
high magnetic ﬁelds all tissues have similar and high values of T1. However, of
course, the MR signal intensity is much lower at very low ﬁeld strengths,
representing a trade-off between image contrast and SNR in terms of the value
of B0.
The dependence of T2 on ﬁeld strength is more complicated. The value of J(f0)
also contributes to T2 relaxation, but there is an extra contribution to T2 relaxation
which is caused by local magnetic ﬁeld ﬂuctuations that occur at very low fre-
quencies, i.e. the value of J(f = 0). The result is that T2 is always shorter than T1. In
cartilage, the high value of J(f = 0) means that T2 is very short. As noted earlier,
there is no direct relationship between the T1 and T2 of a tissue at a given ﬁeld
strength.
5.14
MRI instrumentation
There are three major hardware components which constitute the MRI
scanner: the magnet, an RF coil and three magnetic ﬁeld gradient coils. As has
been described previously, the magnet produces a net magnetization within the
patient, the RF coil produces the pulse of magnetic energy required to create
transverse magnetization and also receives the MRI signal via Faraday induction,
and the magnetic ﬁeld gradient coils impose a linear variation on the proton
resonance frequency as a function of position in each of the three spatial
dimensions.
In addition to these three components, there are electronic circuits used to turn
the gradients on and off, to produce RF pulses of pre-determined length and
amplitude, and to amplify and digitize the signal. A block diagram of a simpliﬁed
MRI system is shown in Figure 5.30.
5.14.1 Superconducting magnet design
The vast majority of MRI magnets are superconducting. Since the early 2000s
many 1.5 Tesla scanners have been replaced by 3 Tesla systems, with almost
universally better image quality. As outlined in Section 5.4, the MRI signal
increases as the square of the B0 ﬁeld. Commercial human-sized magnets have
also been produced at 7 Tesla and 9.4 Tesla but are not yet in routine clinical use.
241
5.14 MRI instrumentation

The two major aims of magnet design are: (i) to produce the most homogeneous
magnetic ﬁeld over the sample to give the longest T2* relaxation time, and (ii) to
produce a stable magnetic ﬁeld in which the drift is of the order of 1 part per billion
(1 ppb) over the course of an MRI scan.
The basis of creating a strong magnetic ﬁeld is to pass high current through a
series of coils of conducting wire. The most commonly used geometry is based on
a solenoid, or helix. For a long solenoid, the magnetic ﬁeld is very homogeneous
over the central part of the solenoid. At the centre, the value of the magnetic ﬁeld is
given by:
B 5
l0nI
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
L2 1 4R2
p
,
ð5:40Þ
where l0 is the permeability of free space (1.25731026 T mA21), n is the
number of turns, I is the current passing through the wires, L is the length of the
solenoid and R is the radius of the solenoid.
m
r
o
fe
v
a
w
 tn
eid
ar
g
-
X
tn
eid
ar
g
-
X
reifilp
m
a
y
c
n
e
u
q
erf 
F
R
re
zis
e
htn
y
s
/ti
m
s
n
ar
T
e
vie
c
er
h
cti
w
s
F
R
p
m
a
reifilp
m
a
er
P
r
otalu
d
o
m
e
D
D
/
A
r
otre
v
n
o
c
ti
m
s
n
ar
T
e
vie
c
e
R
tn
eid
ar
g
-
Y
reifilp
m
a
tn
eid
ar
g
-
Z
reifilp
m
a
m
r
o
fe
v
a
w
 tn
eid
ar
g
-
Y
m
r
o
fe
v
a
w
 tn
eid
ar
g
-
Z
eta
g 
F
R
ff
o/n
O
Figure 5.30
MRI system hardware components used to control the gradients and RF transmitter and receiver.
Each gradient has a separate waveform and ampliﬁer. The transmit and receive sides of the RF chain
are separated by a transmit/receive switch.
242
Magnetic resonance imaging (MRI)

Example 5.7
Calculate the required current to produce a magnetic ﬁeld of 3 Tesla using values
of R = 50 cm, L = 1.5 m, and 100 turns of wire per cm.
Solution
The total number of turns of wire is 15 000, using very thin wire! Substituting into
Equation (5.40):
3 T
ð Þ 5 1:257x106 TmA1
ð
Þ15000I A
ð Þ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1:5 1 1
p
m
ð Þ
gives a current of 250 A.
As suggested by the numerical example above, the problem in using simple
copper wire is the immense amount of heat that is created by passing a very large
current through such a solenoid. The power deposited is proportional to the square
of the current multiplied by the resistance of the wire. To reduce the heat dissipa-
tion, the resistance of the wire needs to be made extremely low, and this leads to the
use of superconducting wire. Certain materials exhibit zero resistance at very low
temperatures, a phenomenon known as superconductivity. For MRI magnets, these
wires must be capable of carrying several hundreds of amps, and of remaining
superconducting within the strong magnetic ﬁeld that the wires themselves create.
The most commonly used material for superconducting wires is an alloy of
niobium-titanium. The alloy is very ﬂexible and is formed into multi-stranded
ﬁlaments which are distributed within a copper matrix to form a ﬂexible wire.
Although a simple solenoid produces a reasonably homogeneous magnetic ﬁeld, it
can be improved by increasing the number of solenoids, and varying their positions
and diameters, as shown in Figure 5.31. The standard number of solenoids is six,
although some magnet designs have up to ten. The wires are wound in recessed
slots in aluminium formers and are ﬁxed in place using epoxy adhesive. The entire
windings are housed in a stainless steel can, called the cryostat, which contains
liquid helium at a temperature of 4.2 K, as shown in Figure 5.31. This can is
surrounded by a series of radiation shields and vacuum vessels to minimize the
boil-off of the liquid helium. The radiation shields are themselves cooled by
cryogenic refrigerators based on the Gifford-McMahon cycle. In older magnets,
an outer container of liquid nitrogen is used to cool the outside of the vacuum
chamber and the radiation shields: in more modern systems compressed helium gas
is circulated by a cold head and cools the outer radiation shield. Since gas losses
cannot be completely eliminated, liquid helium must be replenished, typically on
an annual basis.
The magnet is energized by passing current (typically 100–300 A) into the major
ﬁlament windings. Since the wire is superconducting, after ‘energizing’ the
243
5.14 MRI instrumentation

magnet, the power source is removed and the current circulates through the magnet
essentially indeﬁnitely. Fine tuning of the magnet homogeneity is performed by
using a series of independent superconducting coils, termed shim coils, to reach the
manufacturer’s speciﬁcations. There is also a set of room temperature shim coils
that are used to optimize the homogeneity for each clinical scan, depending upon
the particular organ being imaged and the individual patient. This is normally
performed automatically during scan preparation.
The ﬁnalissuewith thesuperconductingmagnet is siting. There is typically a very
large ‘fringe ﬁeld’ which extends well outside the magnet itself. Since most elec-
tronic equipment cannot operate in strong magnetic ﬁelds, and these ﬁelds also pose
hazards for people with pacemakers, there is effectively a large wasted space around
the magnet. One solution is to actively shield the magnet, in other words to add
secondary shielding coils as shown in Figure 5.31, which are speciﬁcally designed
to minimize the stray ﬁeld outside the magnet via ﬁeld cancellation. Alternatively,
passive shielding in the form of annealed low-carbon steel can be added to the room
in which the magnet is situated in order to conﬁne the stray magnetic ﬁeld.
5.14.2 Magnetic ﬁeld gradient coils
As shown in Figure 5.30, three separate gradient coils are each fed by a separate
gradient ampliﬁer. The current (up to several hundred amps) from each ampliﬁer
main coils
70 K shield
cold head
20 K shield
magnet bore
shielding 
coils
Figure 5.31
(left) The solenoidal coils used to produce a homogeneous static magnetic ﬁeld. Six solenoids (main
coils) are positioned along the z-axis. Two shielding coils are used to reduce the effect of the ‘stray
ﬁeld’ outside the magnet. (right) Cutaway of a superconducting magnet. The grey tinted areas
represent those ﬁlled with liquid helium to make the wires superconducting. Two aluminium radiation
shields are kept at 20 K and 70 K.
244
Magnetic resonance imaging (MRI)

can be switched on and off in less than 1 ms. The maximum gradient strength
depends upon the maximum current that can be passed through the gradient coils
without causing excessive heating. The gradient coils are constructed of copper and
are usually water-cooled. They are wound on cylindrical formers, which are bolted
to the inner bore of the magnet. Currents passing through the coils cause alternating
Lorenz forces within the magnetic ﬁeld, and these forces must be balanced to avoid
putting a large strain on the gradients. In fact, the loud sound of an MRI scan results
from the whole cylinder vibrating, and these vibrations being translated to very
complicated motions of the other components within the MRI system through
mechanical contact [7]. Acoustic damping is used, but the sound levels are still
well above 100 dB and so the use of earplugs and headphones is mandatory.
The aims in gradient coil design are: (i) to produce the maximum gradient per
unit current, (ii) to minimize the ‘rise’ time of the gradient, i.e. how fast it can reach
its prescribed value, and (iii) to achieve the maximum volume of gradient linearity,
usually deﬁned as being 95% of the value in the exact centre of the gradient coil.
Very simple designs, such as are shown in Figure 5.32, can be derived from
analytical expressions for the magnetic ﬁelds created by loops of wire. The sim-
plest conﬁguration for the coil producing a gradient in the z-direction is a ‘Maxwell
pair’, shown on the left of Figure 5.32, which consists of two loops each consisting
of multiple turns of wire. The two loops are wound in opposite directions around a
cylindrical former, and the loops are spaced by a separation of O3 times the radius
z
2
0
d
a
I
I
z
z
a
b
Figure 5.32
(a) Basic geometry of a Maxwell-pair gradient coil which produces a magnetic ﬁeld gradient in the z-
direction. The two halves consist of equal numbers of turns of wire, with equal currents in each half but
ﬂowing in opposite directions. The magnetic ﬁelds from the two halves cancel in the centre of the
gradient set. In the conﬁguration shown, the left-hand half produces a magnetic ﬁeld opposite to B0
(using Fleming’s left-hand rule) and therefore the resonant frequency increases in the positive
z-direction. (b) Basic saddle-geometry for producing a transverse gradient, in this case in the
y-direction. The direction of current in the four identical components of the gradient coil is indicated by
the arrows. The design for producing an x-gradient is the same, but rotated by 90.
245
5.14 MRI instrumentation

of each loop. The magnetic ﬁeld produced by this gradient coil is zero at the centre
of the coil, and is linearly dependent upon position in the z-direction over about
one-third of the separation of the two loops. For loops of radius a, the gradient
efﬁciency, g, is given by:
g 5 8:058 3 107nI
a2
Tm1;
ð5:41Þ
where n is the number of turns, and I is the current through the wires.
The x- and y-gradient coils are completely independent of the z-gradient coils,
and are connected to two separate gradient ampliﬁers. From symmetry consider-
ations the same basic design can be used for coils producing gradients in the x- and
y-directions with the geometries simply rotated by 90. The simplest conﬁguration
is the ‘saddle coil’ arrangement, with four arcs, as shown on the right of Figure
5.32. Each arc subtends an angle of 120, the separation between the arcs along the
z-axis is 0.8 times the radius of the gradient coil, and the length of each arc is 2.57
times the radius. The efﬁciency of this design is given by:
g 5 9:18 3 107nI
a2
Tm1:
ð5:42Þ
The three criteria (homogeneity, switching speed and efﬁciency) for judging
gradient performance can be combined into a so-called ﬁgure-of-merit, b, deﬁned
as [8]:
b 5
g2
L
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
V
Ð
B rð Þ
B0 rð Þ  1

2
d3r
r
;
ð5:43Þ
where L is the inductance of the coil, B0(r) is the ‘desired’ magnetic ﬁeld and
B(r) is the actual magnetic ﬁeld, and V is the volume of interest over which the
integral is evaluated. More sophisticated geometries than the simple saddle-shaped
coils have been designed, based upon numerical optimization schemes, to increase
the ﬁgure-of-merit. An example is shown in Figure 5.33: because of their design
these are termed ‘ﬁngerprint coils’ [9].
When current in the gradient coils is switched rapidly, eddy currents can be
induced in nearby conducting surfaces such as the radiation shield in the magnet.
These eddy currents, in turn, produce additional unwanted gradients which may
decay only very slowly even after the original gradients have been switched off:
these eddy currents can result in signiﬁcant image artifacts. All gradient coils in
commercial MRI systems are now ‘actively shielded’ [10] to reduce the effects of
eddy currents. Active shielding uses a second set of coils placed outside the main
gradient coils, the effect of which is to minimize the stray gradient ﬁelds.
246
Magnetic resonance imaging (MRI)

5.14.3 Radiofrequency coils
The dual role of the RF coil is to transmit pulses of RF energy into the body, and
also to detect the precessing magnetization via Faraday induction. Since the fre-
quencies of transmission and reception are the same, a single RF coil can be used to
perform both tasks. However, more commonly, separate coils are used for trans-
mission and reception, with an array of small coils usually being employed to
receive the signal.
The basic coil is a ‘tuned’ RF circuit, designed to operate most efﬁciently at the
Larmor frequency. The ‘LC’ circuit is one in which conductive elements form the
inductor (L), and capacitance (C) is added in order to tune the coil to the appro-
priate frequency. The conductor is either copper or silver wire or tape, since these
metals have the highest conductivity. The resonant frequency of the LC circuit is
given by:
xres 
1ﬃﬃﬃﬃﬃﬃﬃ
LC
p
or fres 
1
2p
ﬃﬃﬃﬃﬃﬃﬃ
LC
p
:
ð5:44Þ
The coil is attached to the transmitter and receiver chain, shown in Figure 5.34,
through coaxial cables which have a characteristic impedance of 50 X, and so for
maximum power transfer the RF coil should also be impedance matched to this
value. The most common circuit for ‘tuning and matching’ an RF coil to 50 X at
the Larmor frequency is shown in Figure 5.34. The resistance shown in the circuit
is that of the conductor used to make the coil.
The highest efﬁciency is achieved by matching the size of the RF coil as closely
as possible to the size of the body part being imaged. In most systems (except for
Figure 5.33
A ﬁngerprint gradient set, used to produce a y-gradient. The design is usually milled from a solid
piece of copper and mounted on to a ﬁbre-glass cylindrical former, which is then securely bolted on to
the inside of the magnet bore.
247
5.14 MRI instrumentation

very high magnetic ﬁeld strengths .7 Tesla) a large cylindrical body coil is
integrated into the MRI system by being bolted on to the inside of the gradient
set. This type of coil is used for abdominal imaging, for example. The larger the RF
coil, the higher the power necessary, and for a body-coil at 3 Tesla the RF ampliﬁer
must be able to supply 30 kW of power at ~128 MHz. For smaller body parts such
as the head and the knee, in which the whole ‘organ’ is to be imaged, a smaller
cylindrical RF coil, as shown in Figure 5.35, is placed around the head or knee.
Both the body coil and smaller volume coils in Figure 5.35 are designed to produce
a spatially uniform B1 ﬁeld across the entire imaging volume. From electromag-
netic theory, in order to achieve a very uniform ﬁeld the required current density is
proportional to the sine of the azimuthal angle of the cylindrical coil. A practical
realization of this theoretical result is the ‘birdcage coil’ [11], which uses a large
Lc
Rc
Cm
Cc
Cm
Ct
coaxial
cable
c
c
m
c
m
t
Figure 5.34
Basic electrical circuit used to impedance match the RF coil to 50 X at the Larmor frequency. The
intrinsic inductance, capacitance and resistance of the RF coil are denoted by Lc, Cc and Rc,
respectively. Three external capacitors (Ct and two equal value capacitors Cm) are connected to the
RF coil to form the impedance matching network. The arrows denote that these can be variable
capacitors whose value can be changed for each patient if required. The coil and impedance
matching network are connected to the rest of the MRI system via a coaxial cable with 50 X
impedance.
248
Magnetic resonance imaging (MRI)

number of parallel conductors, typically between 16 and 32, as can be seen in the
coils in Figure 5.35.
On the receive side, the MRI signal induced in the RF coil is of the order of tens
of millivolts. Noise in the measurement comes predominantly from the resistance
of the body which, being conducting and having current ﬂowing through it, pro-
duces random voltages which are picked up by the coil. It is advantageous to cover
the region of interest with a large number of smaller more sensitive coils, called a
coil array. Each coil couples very closely to the body, but picks up noise only from
a small part of the body. Overall, the signal-to-noise is improved signiﬁcantly
using this approach compared to having a single larger receive coil. Each of the
small coils must be electrically isolated from the others, and the RF coils are
usually geometrically overlapped to maximize this isolation, and in addition pre-
ampliﬁer decoupling also reduces the interaction between coils [12]. Figure 5.36
shows a large commercial perivascular array containing 24 separate receive coils.
The signal from each coil is fed into a separate receive channel, before the signals
are combined into a composite image.
It is also necessary, when having separate transmit and receive RF coils, that
these are electrically decoupled from one another. Since they are tuned to the same
frequency, if both are active at one time there will be interference between the
RF coils and the efﬁciency will be much lower. Typically, actively-switched non-
magnetic PIN diodes are used to decouple the coils [13]. For example, in Figure
5.37, the array of surface coils is detuned during transmission and tuned during
signal reception. Using similar circuitry, the transmit coil is tuned during trans-
mission and detuned during signal reception.
b
a
Figure 5.35
(a) A commercial knee coil for a 3 Tesla magnet, formed from twelve rungs in a birdcage
geometry. The structure has an upper and lower half to facilitate patient positioning. (b) Similar
structure for a head coil, with a mirror attached so that the patient can see out of the end of the magnet,
which is useful if visual stimuli are needed for functional MRI experiments.
249
5.14 MRI instrumentation

As shown in Figure 5.30, the transmit and receive sections are separated by a
transmit/receive switch. This is required to protect the receive side from the very
high power pulses during RF transmission (which would otherwise literally
destroy the receiver) and also to route all of the MR signal to the receiver rather
than back to the transmitter. The transmit/receive switch must be capable of han-
dling very high power, be able to switch in microseconds, and have excellent
isolation between the two channels.
5.14.4 Receiver design
The small voltages induced in the receive coils are ampliﬁed by a high-gain
low-noise preampliﬁer. These signals are then demodulated to a lower fre-
quency (using circuitry very similar to a conventional FM radio) and
Figure 5.36
Multi-element body array for 3 Tesla consisting of 24 separate elements. Each element is electrically
decoupled from the other individual elements. The array is used to receive the MR signal, with a
large body coil which is ﬁxed inside the bore of the magnet used to transmit the RF pulses.
250
Magnetic resonance imaging (MRI)

digitized, typically at a sampling rate of 80 MHz with a resolution of 14-bits.
Since this bandwidth is much higher than actually required for the imaging
experiment (see Example 5.8), after various corrections for gradient non-
linearities, the raw digitized signal is decimated and ﬁltered using a digital ﬁlter
to the correct bandwidth as covered in Section 1.7, which describes the advan-
tages of oversampling. These signals are then stored in memory and inverse
Fourier transformed to give the MR image, displayed in magnitude mode. If a
coil array is used, then the signals from each coil are stored separately and either
Lc
Rc
Cm
Cc
Cm
Ct
coaxial
cable
c
c
Cm
C
C
Ct
Figure 5.37
A circuit that can be used to decouple a receive coil (shown) from a transmit coil. When the transmit
coil produces an RF pulse, a DC signal is sent to the diodes to make them conduct. This introduces
two extra inductances into the circuit, each one producing a parallel circuit with the matching
capacitors, Cm. If the value of the inductance is chosen correctly, then this forms two circuits with
inﬁnite impedance, and therefore the coil is no longer resonant. When the receiver coils are required to
be active to acquire the signal, the DC signal is turned off, the diodes become non-conducting and the
receiver resonant circuit is re-established.
251
5.14 MRI instrumentation

combined to form the image, or undergo further processing if parallel imaging
techniques are being used to speed up data acquisition, as described in the next
section.
Example 5.8
A 3 Tesla image is being taken of the head, which has a dimension in the
frequency-encoding direction of 25 cm. If the maximum gradient strength of 40
mT/m is used while the signal is being detected, what bandwidth must be used?
Solution
The bandwidth is given by 40 mT/m 3 0.25 = 0.01 T. Since 1T = 42.58 MHz the
bandwidth in Hz is given by ~425 kHz.
5.15
Parallel imaging using coil arrays
Perhaps the greatest technological breakthrough in the past ten years in MRI
has been the development of parallel imaging techniques, which allow images
to be acquired much more quickly by only acquiring a certain fraction (typically
between one-quarter and one-half) of the k-space data. The ultimate limit to
the speed of image acquisition is the rate at which the gradients can be switched
on-and-off: this imposes a physical limit on the value of TR, and therefore on the
total imaging time for a given spatial resolution in the phase encoding direction.
For a given hardware set-up, the only way to increase imaging speed, while
maintaining spatial resolution, is to reduce the extent of k-space coverage. For
example, one might decide to acquire only every other phase encoding step:
however, as shown in Figure 5.38 this causes unacceptable aliasing of the image
(see Exercise 5.15).
The key concept in parallel imaging was to realize that, when an array of receive
coils is used to acquire the image, there is already some spatial information avail-
able related to the signals acquired by each coil, i.e. coils close to a particular part
of the body will receive signal from that part only, and not from an area on the
opposite side of the body. Algorithms used for parallel imaging are mathematically
complicated, and so only an intuitive explanation is given here: details can be
found in the original references [14–17]. The simplest case is shown in Figure
5.39: in this case the head is being imaged with the signal acquired by two receiver
coils, each one of which ‘sees’ only one-half of the brain, either the top- or bottom-
half. In this case, the effect of only acquiring alternate lines in ky is to stretch out
the image in y for each coil, but since each coil only sees one half of the full
ﬁeld of view in the y-dimension, there is no aliasing of the image. From the two,
252
Magnetic resonance imaging (MRI)

non-overlapping stretched versions of the brain, it is very simple to add the images
together and rescale to produce a full image, acquired in half the time of a fully
encoded image.
The trade-off in parallel imaging is between the reduced data acquisition time
and a reduced SNR. However, in many clinical situations the limiting factor is not
the SNR but the time required to acquire an image. One example is abdominal
imaging of the liver, in which it is important to be able to acquire the entire image
within a single breath-hold to avoid image artifacts from motion. Clinical patients
may only be able to hold their breath for less than ten seconds, and so rapid data
acquisition is needed. An example is shown in Figure 5.40, in which dynamic
swallowing of a water bolus is acquired in real-time using parallel imaging, which
allowed a four-fold decrease in imaging time.
kx
ky
kx
ky
kx
ky
x
ky
x
y
kx
ky
x
ky
x
y
a
b
Figure 5.38
(a) A full k-space matrix (top) gives an unaliased image (bottom) provided that the Dkx and Dky
increments are correctly set. (b) If data acquisition speed is increased by a factor of 2 by acquiring only
alternate ky lines, then the Dky is doubled, the image ﬁeld-of-view in the y-dimension is halved, and the
image is aliased along the y-dimension.
253
5.15 Parallel imaging using coil arrays

5.16
Fast imaging sequences
In addition to the basic gradient-echo and spin-echo sequences covered previously,
there are a large number of variations upon these basic ideas. In this section, two
d
e
d
o
c
n
e
-llu
F
m
o
rf s
e
g
a
m
i
lio
c 
h
c
a
e
d
e
d
o
c
n
e
-fla
H
m
o
rf s
e
g
a
m
i
lio
c 
h
c
a
e
e
nib
m
o
C
Figure 5.39
General principle of parallel imaging. Two RF coils, shown as white rectangles on the left, are used
to acquire the MRI signal. If a full ﬁeld-of-view image is acquired using full k-space encoding, then the
two images from the two coils contain signal from either the top or bottom of the brain only. If only
every other line of k-space is acquired, then the ﬁeld of view in the y-dimension is halved, and so the
images from each coil appear stretched, but are not aliased (unlike in Figure 5.38). Stitching together
of the two images, and dimensional rescaling by a factor of two produces an unaliased image
acquired in half the time of the fully encoded image.
a
b
c
d
Figure 5.40
(a-d) Successive images from a subject who is swallowing water (bright signal). Data acquisition
speed was increased four times over normal using parallel imaging.
254
Magnetic resonance imaging (MRI)

very rapid imaging sequences are covered, along with situations in which they are
used.
5.16.1 Echo planar imaging
Multi-slice gradient-echo sequences can acquire image data sets from the entire
brain, for example, in the order of tens of seconds when required. However, there
are a small number of applications in which even faster imaging is called for. Such
cases occur when a very large number of images must be acquired within a
clinically-relevant timescale. One example is diffusion tensor imaging, in which
case many tens of image datasets must be acquired using slightly different param-
eters for each dataset, with each dataset ideally covering the entire brain. A second
example, covered in Section 5.18, is functional imaging in which many hundreds
of different datasets must be acquired in a single session, again covering as much
of the brain as possible.
As can be appreciated from the sequences covered so far, the major limitation in
reducing the time for image acquisition is that the sequence must be repeated Npe
times, each time with a TR delay between successive RF excitations. In contrast,
the fastest type of imaging sequence uses a single slice-selective RF pulse followed
by sampling the whole of k-space before the signal has decayed due to T2*
relaxation. These sequences are termed ‘single-shot’, since only a single excitation
pulse is used to acquire the entire image. The most common sequence is echo-
planar imaging (EPI), which can acquire a single slice 128 3 128 image in much
less than 100 ms [18]. The simplest version of the EPI sequence is shown in Figure
5.41, together with the corresponding k-space sampling scheme.
Unlike conventional multi-slice imaging methodology, multi-slice EPI acquires
the image from each slice sequentially, since there is no conventional TR delay.
Since each slice can be acquired in ~50–100 ms depending upon the spatial
resolution, whole-brain coverage can be achieved in ~1 s. The major disadvantage
of the EPI sequence is that the signal decays between each successive phase
encoding step, which introduces blurring in the phase encoding direction when
the image is reconstructed. This is particularly true in areas with a very short T2*,
such as at air/tissue interfaces. Here, a very short T2* can lead to signal voids, as
well as signiﬁcant image distortion artifacts. An example of this phenomenon is
shown in Figure 5.42. To minimize this effect, while maintaining high imaging
speed, the EPI sequence is often run in ‘segmented-mode’. Segmented-
EPI involves acquiring, for example, only every fourth line in k-space, and then
repeating the sequence four times to acquire the full k-space matrix. In this way,
the T2
* relaxation during each of the four, interleaved acquisitions is much less
255
5.16 Fast imaging sequences

than in the single-shot implementation, and the image blurring effect is reduced
signiﬁcantly.
5.16.2 Turbo spin echo sequences
As outlined above, the major disadvantage of the EPI sequence is that the signal is
weighted by T2* which can cause signiﬁcant image distortions. These distortions
can potentially be reduced by using a spin-echo rather than gradient-echo based
sequence. To achieve a high imaging speed, multiple spin echoes rather than a
RF
Gslice
Gphase
Gread
A/D
90o
kx
ky
RF
Gslice
Gphase
Gread
A/D
kx
ky
a
b
Figure 5.41
(a) Basic echo planar imaging sequence used for single-shot rapid MRI, and (b) Corresponding
k-space coverage. The ﬁrst data point acquired is at the maximum negative values of both kx and ky
(bottom left) and proceeds according to the arrows, ending up at the maximum positive values of kx
and ky (top right) via a zig-zag trajectory.
a
b
Figure 5.42
Two single-shot EPI images acquired in a patient’s brain. Slice (a) was acquired in the middle of the
brain, whereas slice (b) was acquired in an area close to the nasal cavities. The severe image
distortions in (b) arise from the very short T2* values in brain tissue close to the tissue/air interface.
256
Magnetic resonance imaging (MRI)

single echo can be used: this type of sequence is called a turbo spin echo (TSE)
sequence [19]. Figure 5.43 shows the basic imaging sequence, which can be
considered as a hybrid of the EPI and spin-echo sequences.
Although it is technically possible to acquire 128 or 256 echoes and therefore
the entire image in a single-shot, it is more common to acquire a smaller number of
echoes, 16 or 32 is typical, and to acquire the image in a small number of shots,
typically 8 or 16. A number of variations of this sequence exist, with slight differ-
ences in the way that the phase encoding gradient is applied, for example, but all
are based on the basic principle shown in Figure 5.43. There is some image
blurring in the phase encoding direction due to T2 decay between successive phase
encoding steps, but not as much as in a T2
*-weighted sequence such as EPI. The
major limitation of the TSE sequence, particularly at high magnetic ﬁelds, is the
amount of energy deposited in the patient (see Section 5.21).
5.17
Magnetic resonance angiography
Unlike X-ray angiographic techniques covered in Chapter 2, magnetic resonance
angiography (MRA) does not require the use of contrast agents, although they can
be used to increase the signal difference between ﬂowing blood and tissue. The
most common technique is called time-of-ﬂight (TOF) angiography [20], which is
based on the much shorter effective T1 (T1,eff) of blood due to ﬂow into and
through the imaging slice if the slice (or volume) is oriented perpendicular to
TE
TR
90
180
RF
Gfreq
Gphase
Gslice
A/D
Npe/Ne
180
180
180
TE
TE
TE
Ne echoes
TE
Gfreq
Gphase
Gslice
e
180
TE
TE
TE
Figure 5.43
Turbo spin echo imaging sequence in which Ne echoes are acquired for each TR interval. This reduces
the image acquisition time by a factor of Ne compared to a simple spin echo sequence.
257
5.17 Magnetic resonance angiography

the direction of ﬂow, as shown in Figure 5.44. The actual T1 value of the water in
blood is similar to the value for many tissues. However, during the TR delay
between successive RF pulses and phase encoding steps, a new pool of blood
ﬂows into the volume being imaged. These protons have not experienced any of
the previous RF pulses and so if the slice is thin these protons have full magnet-
ization (Mz = M0). For a given slice thickness (Sth) and blood velocity (v), the
value of T1(eff) of the blood is given by:
1
T1ðeffÞ
5 1
T1
1 v
Sth
:
ð5:45Þ
For example, if the slice thickness is 5 mm, and a value of TR of 50 ms is used,
blood ﬂowing at speeds greater than 10 cm/s will ﬂow completely out of the slice
in the time between successive phase-encoding steps. The value of T1(eff) is there-
fore zero.
To differentiate between ﬂowing blood and stationary tissue, a very heavily T1-
weighted sequence should be used with a high tip angle pulse (to get maximum
signal from the blood) in combination with a short TR value (to minimize the
g
nig
a
m
i
e
cils
d
o
olb
w
olf
Mz
My
Figure 5.44
(left) The TOF MR angiographic technique. Blood ﬂowing into the imaging slice has full Mz
magnetization before the RF pulse, and so a 90 pulse creates maximum My magnetization. In
contrast, stationary tissue within the slice experiences every RF pulse during the imaging sequence
and since TR  3T1 is ‘saturated’, i.e. has an Mz magnetization which is much less than its thermal
equilibrium value. Therefore, the 90 pulse creates a much lower My magnetization in the tissue than in
the blood. (right) Image of a slice through the brain showing the vessels (arrows) with ﬂow
perpendicular to the image slice as bright spots.
258
Magnetic resonance imaging (MRI)

signal from the stationary tissue and acquire the data rapidly). The simplest imple-
mentation of the TOF principle uses a rapid gradient-echo sequence with a tip
angle large compared to the Ernst angle for tissue.
Multi-slice or three-dimensional angiography is normally performed to obtain
ﬂow images throughout a given volume of the brain. A single image from a 3D
data-set is shown on the right of Figure 5.44, with ﬂowing blood showing up as the
bright signal. The images are usually displayed using a maximum intensity pro-
jection (MIP) algorithm, as shown in Figure 5.45. For observation of very small
vessels, contrast agents (see Section 5.19) can be used to reduce further the effec-
tive T1 of blood, and increase the contrast between ﬂowing spins and stationary
tissue.
5.18
Functional MRI
Functional MRI (fMRI) is a technique to determine which areas of the brain are
involved in speciﬁc cognitive tasks as well as general brain functions such as
speech, language and sensory motion. The basis for the method is that the MRI
signal intensity changes depending upon the level of oxygenation of the blood in the
brain, a phenomenon termed the blood oxygen level dependent (BOLD) effect [21].
The level of oxygenation changes by small amounts in areas where neuronal acti-
vation occurs, as described below, and so these areas can be detected using MRI.
Figure 5.45
(left) Maximum intensity projection from a three-dimensional TOF sequence acquired in the brain.
The circle-of-Willis is prominently shown close to the centre of the brain. (right) Expanded image
shows the very ﬁne and detailed vessel structure that can be obtained using MR angiography.
259
5.18 Functional MRI

When neuronal activation occurs in the brain’s grey matter the local blood ﬂow
in the capillary bed is increased and there is an increase in the blood oxygenation
level, corresponding to a decrease in the concentration of deoxyhaemoglobin.
Deoxyhaemoglobin has a magnetic susceptibility which is more paramagnetic than
tissue and so the local magnetic ﬁeld gradients between the blood in the capillary
bed and tissue also decrease. As a result, the values of T2 and T2
* increase
locally in areas of the brain which are associated with neuronal activation: the
increase in MR signal on either T2 or T2
* weighted scans forms the basis of
functional MRI .
The most common MR sequence used to collect the data is a multi-slice
echo-planar imaging, since data acquisition is fast enough to obtain whole-brain
coverage in a few seconds. Many different types of stimulus can be used: visual-,
motor- or auditory-based. The changes in image intensity in activated areas are
very small, typically only 0.2–2% using a 3 Tesla scanner, and so experiments are
repeated a number of times with periods of rest (baseline) between each stimula-
tion block. Data processing involves correlation of the MRI signal intensity for
each pixel with the stimulation waveform, as shown in Figure 5.46, followed by
statistical analysis to determine whether the correlation is signiﬁcant. Typical scans
may take 10–40 minutes, with several hundred repetitions of the stimulus/rest
paradigm.
100 
101 
102 
103 
20 
40 
60 
80 
100 
120 
off 
on 
time (sec) 
MRI signal 
Figure 5.46
(left) Plot of the MR signal intensity within an activated voxel as a function of time, and below the time-
course of the particular stimulus being presented. The MRI signal increase is delayed by
approximately 6 s with respect to the stimulus due to the ﬁnite hemodynamic response time. Signal
changes are of the order of a few percent. Correlation of the MRI signal intensity with the stimulus
pattern on a pixel-by-pixel basis produces the voxels (right) which show a statistically signiﬁcant
correlation in two areas outlined by the arrows.
260
Magnetic resonance imaging (MRI)

Although fMRI is currently used more for research than routine clinical use, it is
increasingly being used in a number of presurgical planning studies. Here, the
exact surgical ‘route’ for removing, for example, a tumour from the brain can be
planned by avoiding areas which have been determined to be involved in critical
cognitive tasks such as language recognition and motor processes.
5.19
MRI contrast agents
In many clinical scans, there is sufﬁcient contrast-to-noise on the appropriate T1-,
T2- or proton density-weighted image to distinguish diseased from healthy tissue.
However, in certain cases such as the detection of very small lesions, where partial
volume effects occur within the slice, the CNR may be too low for a deﬁnitive
diagnosis. In this case, MRI contrast agents can be used to increase the CNR
between healthy and diseased tissue. There are two basic classes of MRI contrast
agent: paramagnetic and superparamagnetic, also called positive and negative
agents, respectively. In addition to lesion detection, positive agents are also often
used in combination with TOF angiography.
5.19.1 Positive contrast agents
Paramagnetic contrast agents shorten the T1 of the tissue in which they accumulate,
and are therefore referred to clinically as positive contrast agents since they
increase the MRI signal on T1-weighted scans. There are currently several different
agents (which go by trade names such as Omniscan, Prohance and Magnevist)
which are approved worldwide for clinical use. The differences between the var-
ious agents are in the ionicity and osmolarity, similar to X-ray contrast agents
covered in Chapter 2. All the agents are based on a central gadolinium ion, which is
surrounded by a particular chemical chelate, as shown in Figure 5.47. Neither the
gadolinium nor the chelate produces an MR signal directly, but the chelated
molecule is visualized via its effect on water molecules in the tissue in which
the contrast agent accumulates. The Gd3+ ion has seven unpaired electrons, and
the interaction between water protons and these electrons produces a very efﬁcient
T1 relaxation and so reduces the T1 time of the tissue. The agents are designed so
that there is one empty binding site to the Gd ion which is not occupied by the
chelate structure. This means that a water molecule can temporarily bind to this
site, undergo very rapid T1 relaxation and then be released to be succeeded by a
second water molecule, and so on. This mechanism is referred to as ‘inner sphere
relaxation’. A second way in which water molecules can have their T1 relaxation
time reduced is simply by interacting with the unpaired Gd electrons at a distance,
261
5.19 MRI contrast agents

i.e. by diffusing close to the molecule: this latter mechanism is called ‘outer sphere’
relaxation and is not as efﬁcient as inner sphere relaxation but many more water
molecules are affected.
Gd-based paramagnetic contrast agents are most often used in the diagnosis of
central nervous system (CNS) disorders, such as the presence of tumours, lesions,
gliomas and meningiomas. All the agents are intravascular and extracellular in
nature. They are injected intravenously shortly before scanning and distribute
within tumours, for example, by passing through a leaky BBB which has been
damaged by the particular pathology. An example is shown on the right of Figure
5.47, where the small localized high intensity area on the T1-weighted image
indicates a small tumour in the brain of the patient. The agent remains at an
elevated level in the tumour for tens of minutes to a few hours, and then is rapidly
cleared through the kidneys since the chelates are highly hydrophilic and do not
bind to blood proteins.
Typical patient doses of gadolinium agents are a volume of 10 ml at a concen-
tration of 0.5 M, which results in a concentration in the body of ~0.1 mmol/kg. The
greater is the concentration of contrast agent, the shorter the T1 value. The relation-
ship is given by:
1
TCA
1
5 1
T1
1 a1C;
ð5:46Þ
d
G
N
N
N
N
O
H
O
H
C
3
O
O
C
O
O
O
C
C
H
H
O
Figure 5.47
(left) The chemical structure of a positive MRI contrast agent (Prohance). One co-ordination position is
free, which allows water to bind strongly but reversibly to the Gd-ion and undergo extremely fast T1
relaxation. (right) One slice through the brain showing accumulation of the agent in a small lesion,
which appears bright on a T1-weighted sequence.
262
Magnetic resonance imaging (MRI)

where T1
CA is the T1 of tissue after administration of the contrast agent, T1 is the
pre-adminstration value, and a1 is the T1-relaxivity of the contrast agent.
Gd contrast agents are also used in magnetic resonance angiography, covered
in Section 5.17. Speciﬁcally, a new agent called Gadovist was approved in late
2008. This agent binds strongly but reversibly to human serum albumin in the
blood, and so has a much longer half-life in the blood than other Gd-based
agents, which are designed to bind weakly: thus Gadovist has primarily a vascular
distribution. It is used to study vessel structure in diseases such as peripheral
vascular disease, and also to detect arterial stenosis and plaque formation within
arteries.
Although Gd-based agents were judged to be completely safe until about 2005,
there is increasing evidence that patients with pre-existing kidney disease are a
particular concern given the risk of nephrogenic systemic ﬁbrosis (NSF). Only a
very small fraction of patients contract this condition, and the mechanism and
degree of risk are still currently areas of active research.
5.19.2 Negative contrast agents
The second general class, namely superparamagnetic MRI contrast agents act
primarily as negative contrast agents, i.e. they reduce the MR signal in the
tissues in which they accumulate. They are used for liver disease, speciﬁcally
for conﬁrming the presence of liver lesions or focal nodular hyperplasia. These
agents consist of small magnetic particles containing iron oxide with a biocom-
patible coating. Ultra-small superparamagnetic iron oxides (USPIOs) have a
core which is less than 30 nm in diameter, whereas superparamagnetic iron
oxides (SPIOs) have diameters between 30 and 100 nm. The only agent that
is currently approved for worldwide use is Feridex/Endorem with a diameter
~100 nm. A second agent, Resovist is used in the European Union, Australia and
Japan, and has a 62 nm diameter core. The recommended intravenous dosage of
Feridex is 0.56 milligrams of iron per kg body weight, which is diluted in 100 ml
of 5% dextrose solution and given intravenously over 30 minutes. To avoid
larger clumps developing, the diluted drug is administered through a 5 micron
ﬁlter.
Superparamagnetic contrast agents work by causing very strong inhomogene-
ities in the local magnetic ﬁeld. Water molecules diffusing through these localized
inhomogeneities undergo very fast T2 and T2
* relaxation, and therefore there is a
reduction in signal intensity in the tissues in which the agent accumulates on T2
*-
weighted gradient-echo or T2-weighted spin-echo sequences. Small particles are
taken up primarily by Kuppfer cells in the liver, but also accumulate in the lymph
263
5.19 MRI contrast agents

nodes, spleen and bone marrow. The particles enter only the healthy Kuppfer cells
in the liver and do not accumulate in tumours or other pathological structures.
Therefore, these particles reduce the signal intensity from the healthy tissue, with
the tumour intensity remaining unaffected as a relatively bright area, as shown in
Figure 5.48.
5.20
Image characteristics
As with all imaging modalities, there are trade-offs between image SNR, spatial
resolution and CNR. The major factors affecting each of these three parameters are
outlined in the following sections.
5.20.1 Signal-to-noise
(i) B0 ﬁeld strength. The signal is proportional to the net magnetization, M0,
which is directly proportional to the value of B0 from Equation (5.10). The
signal measured by Faraday induction is directly proportional to the precession
frequency from Equation (5.14) and so again proportional to the value of B0.
As seen in Figure 5.28, however, the higher the B0, the larger the T1 value and
the smaller the image intensity for a given value of TR, Equation (5.34). This
latter effect depends, of course, upon the particular tissue and the ﬁeld strength
involved. The value of T2 is also shorter at higher ﬁelds, again with a strong
Figure 5.48
Two examples of hepatocellular carcinomas (indicated by the white arrows) imaged after injection
of USPIO negative contrast agents. The surrounding liver tissue is dark in the T2*-weighted gradient
echo imaging sequences, but the carcinomas do not take up the agent and so appear bright relative
to the healthy tissue.
264
Magnetic resonance imaging (MRI)

tissue-type dependence: the signal will therefore decrease for a given value of
TE. The noise in the image arises primarily from the random voltage induced
in the RF coil(s) from the patient, which is proportional to the square-root of
the ﬁeld strength.
(ii) Imaging parameters. Too short a value of TR, too high a value of tip angle, or
too long a value of TE reduces the signal intensity from its optimal value. If the
image in-plane spatial resolution is doubled from, for example, 1 3 1 mm to
0.5 3 0.5 mm, then the SNR per voxel decreases by approximately a factor of
4, assuming all other imaging parameters are kept constant, as shown in Figure
5.49. The total imaging time is also doubled, due to twice the number of phase
encoding steps being acquired. The SNR is inversely proportional to the slice
thickness, since the number of protons is decreased using a thinner slice. In
order to increase the SNR of an image, while maintaining the same spatial
resolution, the imaging sequence can be repeated a number of times and the
images added together. The MR signal is coherent, but the noise is incoherent,
and so the overall SNR increases by the square-root of the number of images:
however, the data acquisition time is lengthened by a factor equal to the
number of images.
5.20.2 Spatial resolution
The spatial resolution in the three dimensions for most imaging sequences
is simply deﬁned by: (i) the slice thickness, (ii) the ﬁeld-of-view in the
a
b
c
Figure 5.49
The trade-offs between SNR and spatial resolution. The three images are acquired with identical
TR, TE and slice thickness. The image in (a) has a data matrix size of 64 3 64: the SNR is high, but the
image appears ‘blocky’ with poor spatial resolution. The image in (b) has a matrix size of 128 3 128:
the SNR is still relatively high. In image (c) with a data matrix of 256 3 256 the image is very ‘grainy’ due
to the poor SNR.
265
5.20 Image characteristics

phase-encoded dimension divided by the number of phase-encoding steps, and
(iii) the ﬁeld-of-view in the frequency-encoded dimension divided by the
number of acquired data points in that dimension. The trade-off between
spatial resolution, SNR and total data acquisition time has been outlined in
the previous section. It should be noted that, in addition to the three
factors outlined previously, single-shot sequences such as EPI can have sig-
niﬁcantly poorer spatial resolution than multi-shot sequences acquired with the
same number of data points due to blurring from T2* decay during the
sequence.
5.20.3 Contrast-to-noise
Image contrast can be based on differences in proton density, T1, T2 or
T2* relaxation times, or a combination of more than one or all of these
parameters. The contrast can be manipulated by appropriate choices of the TR
and TE times. Contrast in T1-weighted sequences decreases with ﬁeld strength,
since the spectral density and therefore T1 for different tissues approach the
same value, as shown in Figure 5.28. For small lesions, the contrast is
increased by having high spatial resolution to minimize partial volume effects.
However, if the spatial resolution is too high, then the SNR decreases, as shown in
Figure 5.50.
a
b
c
Figure 5.50
The trade-off between CNR, spatial resolution and SNR in MRI. A small hyperintense lesion is visible
(white arrow) in image (b) which has a data matrix of 128 3 128. Using a lower data matrix of 64 3 64,
image (a) produces a higher SNR, but the spatial resolution is not sufﬁcient to see the lesion.
Increasing the spatial resolution by acquiring a 256 3 256 data matrix, image (c), decreases the SNR
so that the lesion is again not visible. The optimum spatial resolution for the best CNR in this case is
given by image (b).
266
Magnetic resonance imaging (MRI)

5.21
Safety considerations – speciﬁc absorption rate (SAR)
Associated with any RF magnetic ﬁeld is a corresponding RF electrical ﬁeld which
produces electric currents in conductive tissues. A key safety consideration in MRI
is the power deposition in tissue, quantiﬁed via the local and average speciﬁc
absorption rate (SAR) values, measured in Watts per kilogram. There are strict
regulatory guidelines on these values in terms of peak instantaneous and time-
averaged values for both local and global regions of interest. The SAR can be
calculated from the electric ﬁeld (E) distributions and is given by:
SAR 5 r
2q E
j j2;
ð5:47Þ
where q is the tissue density and r the tissue conductivity. The SAR is propor-
tional to the square of the B1 ﬁeld multiplied by the time for which the B1 ﬁeld is
applied, and therefore sequences such as a TSE can result in considerable power
deposition within the patient. Every commercial MRI scanner has built-in software
and hardware to estimate the SAR for each sequence run, and to adjust the imaging
parameters in order to remain within regulatory safety limits.
5.22
Lipid suppression techniques
In only a few clinical applications does the spatial distribution of lipid within a
particular organ have important diagnostic information. Otherwise it produces a
signal that can mask the pathology which is being detected. Examples include
small nodules in the liver and spinal cord, which may be surrounded by a signiﬁ-
cant signal from lipid. Since lipid has a very short T1 value and long T2 value it
appears very bright on most images. Fortunately, there are a number of techniques
that can be used to minimize the signal from lipid in the image, so-called lipid
suppression techniques. Two of these are shown schematically in Figure 5.51. The
ﬁrst is a ‘chemical shift selective sequence’. As described in Section 5.6, the
protons in lipid resonate at a different frequency from those in water. Therefore,
prior to the imaging sequence a 90 frequency-selective RF pulse is applied which
tips only the magnetization from the lipid protons into the transverse plane. A
gradient is then applied to dephase this magnetization, thus destroying the signal.
Now the regular imaging sequence is applied, but since the lipid signal has been
completely dephased, it does not produce any signal on the image. The second
sequence, shown in Figure 5.51(b), relies on the fact that the T1 of lipid is much
shorter than for most other tissues. A 180 ‘inversion pulse’ is applied to convert
+Mz magnetization into – Mz magnetization for all the protons in the slice. The
pulse is turned off and the protons relax back towards equilibrium due to T1
267
5.21 Safety considerations – speciﬁc absorption rate (SAR)

relaxation. At a speciﬁc time, termed the inversion time (TI), after the 180 pulse,
the imaging sequence is started. The inversion time is chosen speciﬁcally so that
the protons in lipid have relaxed back to a value of Mz = 0. When the imaging
sequence is run, therefore, the slice selective pulse produces no transverse magnet-
ization from the lipid and therefore no signal in the image. These lipid-suppression
sequences are called ‘inversion recovery’ sequences, with the most common clin-
ical acronym being short time inversion recovery (STIR).
5.23
Clinical applications
Almost all parts of the body are imaged in the clinical setting: the brain and spinal
cord, the entire musculoskeletal system (shoulder, knee, ankle, and hand), MR
mammography, body imaging of the liver, kidneys, urinary tract and prostate, and
cardiological applications looking at heart disease. The following applications
represent only a small fraction of the total spectrum of clinical protocols.
5.23.1 Neurological applications
MRI can be used to diagnose both acute and chronic neurological diseases, and is
the imaging method of choice for intracranial mass lesions such as tumours, with
180o
Npe
RF
Gphase
A/D
Gslice
Gfreq
TI
imaging
sequence
90o
Npe
RF
Gphase
A/D
Gslice
Gfreq
imaging
0,lipid
180o
Npe
RF
TI
90o
Npe
RF
A/D
freq
sequence
o
Npe
o
90o
Npe
90o
ω 0,lipid
Figure 5.51
(a) Lipid saturation using frequency-selective excitation. The RF pulse tips only lipid protons into
the transverse plane: the magnetization is then rapidly dephased using ‘crusher’ gradients. The
imaging sequence then gives a signal only from the protons in tissue water. (b) An alternative method
for lipid suppression. After the 180 pulse, an inversion delay (TI) is used, with the value chosen so that
the lipid signal has zero longitudinal magnetization due to T1 relaxation, at which time the imaging
sequence begins.
268
Magnetic resonance imaging (MRI)

the majority of imaging protocols involving administration of a positive contrast
agent.
Many pathological conditions in the brain, such as vasogenic or cytotoxic
oedema, result in increased water content, which gives a high signal intensity on
T2-weighted sequences. Oedema is easily seen on T2-weighted sequences, and has
different causes. Interstitial oedema arises from different forms of hydrocephalus,
vasogenic oedema arises from breakdown of the BBB in primary and metastatic
tumours, and cytotoxic oedema is associated with ischemia.
Tumours located outside the brain (extra-axial tumours), examples of which are
meningioma, lymphoma, and schwannoma, are usually benign and after injection
of the contrast agent they enhance because of the tumour vascularity. Since they are
outside the brain they do not possess a BBB. Intra-axial tumours, such as astro-
cytoma and glioblastomas, originate within the brain. These also enhance with Gd
administration, with high grade tumours generally enhancing more than low grade.
Stroke arises from large vessel occlusion. The cellular sodium/potassium pump
fails, leading to cytotoxic oedema. Thrombolytic therapy must be used within the
ﬁrst few hours after stroke and so early detection is key. Early cytotoxic oedema
can be detected using diffusion-weighted MRI which is very sensitive to cell
swelling. About 20% of strokes come from occlusion of small arteries branching
from the major cerebral arteries, and can be visualized as small round lesions in T2-
weighted scans, as well as showing enhancement on contrast agent administration
due to disruption of the BBB.
Chronic diseases can either be characterized by speciﬁc features such as white
matter lesions, in multiple sclerosis for example as shown in Figure 5.52, or more
diffuse areas of low intensity which indicate long-term accumulation of iron in
areas such as the putamen, a characteristic of Huntington’s and Alzheimer’s dis-
ease. Diagnosis in the latter cases is more difﬁcult than for speciﬁc pathologies,
since there are a number of other diseases which can lead to similar chronic events,
and indeed the normal ageing process results in non-speciﬁc white-matter lesions
as well as increased iron deposition.
5.23.2 Body applications
Both diffuse and focal liver diseases can be diagnosed using MRI. Scans are
normally acquired during a single breath-hold of 10–20 s to avoid image artifacts
from respiration. MRI is particularly useful for diagnosing lesions in fatty livers,
since these can be obscured in ultrasound and CT. Lesions such as hepatic
adenoma enhance strongly after positive contrast administration. Cirrhosis of the
liver involves ﬁbrosis which is irreversible, and atrophy in the different lobes is
269
5.23 Clinical applications

very common. Cirrhosis also affects blood ﬂow within the liver, and these changes
can be seen on TOF angiograms with or without contrast agent administration.
Diseases such as haemochromatosis and haemolytic anaemia can be associated
with cirrhosis. Iron overload is seen as a very low signal on T2-weighted sequen-
ces, with lipid and muscle effectively acting as internal references in terms of
signal intensity.
Metastases are the most common form of liver tumours, and can be diagnosed
using contrast agent injection. Images must be acquired very rapidly after injection
of the agent. Liver cysts can be differentiated from tumours by the fact that they do
not enhance. Hemangiomas are benign focal liver lesions and, being ﬁlled with
water, give low signal intensity on T1-weighted sequences and high signal inten-
sity on T2-weighted sequences. Larger hemangiomas typically enhance ﬁrst on the
periphery of the structure, and then slowly the enhancement ‘ﬁlls in’ the entire
structure, as shown in Figure 5.53(b).
5.23.3 Musculoskeletal applications
MRI can produce high quality images of the entire musculoskeletal (MSK) system.
One application is in the evaluation of cartilage integrity in the knee, with
Figure 5.52
Axial image of a subject with white matter lesions (arrows) which can be an early indication of multiple
sclerosis.
270
Magnetic resonance imaging (MRI)

degradation being associated with diseases such as rheumatoid- and osteo-arthritis.
The cartilage shows up as a well-deﬁned area of high signal intensity just below the
knee cap, as shown in Figure 5.54 (a). Other areas of MSK imaging include the
hand/wrist, shown in Figure 5.54(b), which can also be affected by different forms
of arthritis, and the ankle. Assessment of diseases of the spinal cord, Figure
5.54(c), can be classiﬁed into neurological, oncological or MSK. Degenerative
diseases of the spinal cord are very commonly diagnosed using MRI. On T2-
weighted images, normal intervertebral discs are bright: degnerative disc disease
reduces the water content of the discs which therefore become darker. Tumours in
the spinal cord itself can be detected via enhancement after administration of
positive contrast agent.
5.23.4 Cardiology applications
In all cardiac scans gating of data acquisition to the cardiac cycle (using electro-
cardiogram measurements with MRI-compatible equipment) is necessary to
reduce the artifacts associated with heart motion. In studies of ischemic heart
disease, MRI is used to visualize myocardial infarcts which have a high intensity
on T2-weighted sequences due to myocardial oedema. Positive contrast enhance-
ment is also indicative of a recent infarct. Indirect measurements of cardiac wall
thinning also provide evidence of a local infarct. There is normally excellent
contrast between blood in the myocardium (which is bright) and the myocardial
wall itself, as shown in Figure 5.55(a). The left ventricular volume and ejection
fraction are very important measures of heart function, and both can be measured
using MRI. In addition, using spin-tagging techniques, the complex motion of the
a
b
Figure 5.53
(a) Axial slice showing the liver ﬁlling essentially the entire ﬁeld-of-view of the image. (b) Coronal
image acquired after administration of a positive contrast agent, showing inhomogeneous
enhancement of a hemangioma.
271
5.23 Clinical applications

heart wall during systole and diastole can be investigated for abnormalities. Mor-
phological changes associated with different types of cardiomyopathy can also be
seen using MRI.
Left anterior descending coronary artery disease is one of the most common
causes of heart attacks, and stenoses of the coronary arteries can be assessed using
angiographic techniques: an example is shown in Figure 5.55(b).
a
b
c
Figure 5.54
(a) Axial image of the knee, showing a bright area of patellar cartilage and below it the ‘mottled’
pattern corresponding to trabecular bone structure. (b) Sagittal view of the hand, again showing
cartilage and trabecular bone structures. (c) Sagittal image of the spinal cord and vertebral column.
a
b
Figure 5.55
(a) A slice through the heart at four stages of the cardiac cycle, showing the expansion and contraction
of the myocardium (low gray signal), with blood showing as a bright signal. (b) Image of the left
coronary artery in a subject, shown by the arrow.
272
Magnetic resonance imaging (MRI)

Exercises
Basics (Sections 5.2–5.4)
5.1 Assuming that there are 6.7 3 1022 protons in a cubic centimeter of water,
what is the magnetization contained within this volume at a magnetic ﬁeld
strength of 3 Tesla?
5.2 Using classical mechanics, show that the effect of an RF pulse applied around
the x-axis is to rotate z-magnetization towards the y-axis.
5.3 Show schematically the separate effects of: (i) a 90x, (ii) a 180x, (iii) a 270x,
and (iv) a 360x pulse on thermal equilibrium magnetization using the vector
model.
5.4 What is the effect of changing the orientation of the RF coil so that it produces
a pulse about the z-axis?
5.5 Calculate the effects of the following pulse sequences on thermal equilibrium
magnetization. The ﬁnal answer should include x-, y-, and z-components of
magnetization.
a) 90x (a pulse with tip angle 90, applied about the x-axis).
b) 80x.
c) 90x 90y (the second 90 pulse is applied immediately after the ﬁrst).
T1 and T2 relaxation times
5.6 Answer true or false with one or two sentences of explanation:
a) recovery of magnetization along the z-axis after a 90 pulse does not nec-
essarily result in loss of magnetization from the xy-plane;
b) a static magnetic ﬁeld B0 that is homogeneous results in a free induction
decay which persists for a long time;
c) a short tissue T1 indicates a slow spin-lattice relaxation process.
5.7 Write an expression for the Mz magnetization as a function of time after a 180
pulse. After what time is the Mz component zero? Plot the magnetization after
instead applying a 135 pulse.
5.8 The hydrogen nuclei in the body are found mainly in lipid and water. The T2
value of lipid was measured to be 100 ms, and that of water to be 500 ms. In a
spin-echo experiment, calculate the delay between the 90 pulse and the 180
pulse which maximizes the difference in signal intensities between the lipid
and water. Assume that the total number of lipid protons is the same as the
total number of water protons.
MRI and basic imaging sequences
5.9 The operator wishes to acquire an oblique slice shown by the orientation of the
white bar in Figure 5.56 (a). Draw the gradient echo imaging sequence that
would be run to acquire such an image.
273
Exercises

5.10 A multi-slice spin-echo imaging sequence is run with the following param-
eters: a 256 3 256 data matrix, TR is 2 seconds, TE is 20 ms, and ten slices
are acquired. How long does the MRI scan take to complete?
5.11 Derive the value of the Ernst angle given in Equation (5.35).
5.12 Given a maximum magnetic ﬁeld gradient of 40 mT/m, how homogeneous
must the static magnetic ﬁeld be (in parts per million) to enable a spatial
resolution of 1 mm to be acquired?
5.13 Assume that in a Fourier imaging experiment, the desired phase-encoding
gradients are Gn = nDG0. What will happen to the reconstructed image if the
gradient system malfunctions such that the effective gradients applied are:
Gn = n(DG0/2)?
5.14 In the image shown in Figure 5.56 (b), acquired using a standard spin-echo
sequence, the bright signal corresponds to lipid and the lower intensity signal
to water. The lipid and water signals appear spatially shifted with respect to
one another.
(i) Given the facts above, which of the left/right or up/down dimensions
corresponds to the frequency encoding direction, and which to the phase
encoding direction? Explain your answer fully.
(ii) The image is acquired at a ﬁeld strength of 3 Tesla, and the black band in
the image is 3 pixels wide. If the total image data size is 256 3 256, what
is the overall data acquisition bandwidth? The image ﬁeld-of-view is 5 35
cm: what is the strength of the frequency encoding gradient?
(iii) If the frequency encoding gradient were increased by a factor of 3, what
effect would this have on the imaging artifact?
5.15 Use the concept of avoiding signal aliasing to derive the image ﬁeld-of-view
in the phase encoding dimension. The answer should include the value of the
a
b
Figure 5.56
(a) See Exercise 5.9, (b) See Exercise 5.14.
274
Magnetic resonance imaging (MRI)

incremental phase encoding gradient step, the length of time that the gradient
is applied for, and any relevant physical constants.
Tissue relaxation times
5.16 (a) Plot qualitatively the dependence of T1 on the strength of the applied
magnetic ﬁeld for a mobile, an intermediate and a viscous liquid.
(b) Plot qualitatively the variation in T1 as a function of the mobility of a
liquid.
5.17 For the ﬁve frequencies (1–5) shown in Figure 5.57, state the order of the T1
values, e.g. T1(brain) . T1 (CSF) . T1 (aqueous humour). Where possible,
do the same for the T2 values.
Relaxation weighted imaging sequences
5.18 Choose the correct option from (a)-(e) and explain why this is your choice.
The maximum MR signal is obtained by using:
(a) 90 RF pulse, short TE, and short TR;
(b) 45 RF pulse, short TE, and short TR;
(c) 90 RF pulse, short TE, and long TR;
(d) 90 RF pulse, long TE, and short TR;
(e) 45 RF pulse, long TE, and short TR.
5.19 Choose the correct option from (a)-(e) and explain why this is your choice.
Water in tendons is bound very strongly and cannot diffuse freely. It pro-
duces very low MR signal intensity because:
(a) T1 is too short;
(b) T2 is too short;
(c) T2
* is very long;
(d) T2 is longer than T1;
(e) T2
* is longer than T2.
spectral density
frequency
aqueous humour
brain tissue
cerebrospinal fluid
1
2
3
4
5
spectral density
frequency
aqueous humour
brain tissue
cerebrospinal fluid
1
2
3
4
5
Figure 5.57
See Exercise 5.17.
275
Exercises

5.20 A brain tumour has a lower concentration of water than surrounding healthy
tissue. The T1 value of the protons in the tumour is shorter than that of the
protons in healthy tissue, but the T2 value of the tumour protons is longer.
Which kind of weighting should be introduced into the imaging sequence in
order to ensure that there is contrast between the tumour and healthy tissue?
If a large concentration of superparamagnetic contrast agent is injected and
accumulates in the tumour only, which kind of weighting would now be
optimal?
5.21 A region of the brain to be imaged contains areas corresponding to tumour,
normal brain and lipid. The relevant MRI parameters are:
qðtumourÞ 5 qðlipidÞ . qðbrainÞ
T1ðlipidÞ . T1ðtumourÞ . T1ðbrainÞ
T2ðlipidÞ . T2ðtumourÞ . T2ðbrainÞ:
Which type of weighted spin-echo sequence should be run in order to get
contrast between the three different tissues. Explain your reasoning, including
why the other two types of weighting would not work.
5.22 Three MRIs of the brain are acquired using identical parameters except for
the TR and TE times. Three tumours (upper, middle and lower) are seen in
one of the images but not in the other two, as shown in Figure 5.58. If the T1
values for all the tissues (tumours and brain) are less than 2 s, and the T2
values are all greater than 80 ms, describe the relative values of proton
density, T1 and T2 of brain tissue and the three tumours.
s
m
 1
=
E
T
 ,s 0
1
=
R
T
s
m
 1
=
E
T
 ,s 5.0
=
R
T
s
m
 0
8
=
E
T
 ,s 5.0
=
R
T
s
m
 1
=
E
T
 ,s 0
1
=
R
T
s
m
 1
=
E
T
 ,s 5.0
=
R
T
s
m
 0
8
=
E
T
 ,s 5.0
=
R
T
Figure 5.58
See Exercise 5.22.
276
Magnetic resonance imaging (MRI)

5.23 Three images are shown in Figure 5.59: the scaling in each image is different
and is normalized to the same maximum value. The imaging parameters are
TR = 2000 ms, TE = 20 ms for one image, TR = 750 ms, TE = 80 ms for
another, and TR = 2000 ms, TE = 80 ms for the ﬁnal one.
(i) Assign each image to the appropriate TR and TE values.
(ii) Based on your answer, do the ventricles have a higher or lower T1 value
than brain tissue? What is the corresponding answer for T2?
5.24 The T1-weighted image in Figure 5.60 represents a slice through the abdo-
men, with signals coming from liver, kidney, tumour and lipid. Given the
following information:
qðliverÞ 5 qðkidneyÞ , qðlipidÞ , qðtumourÞ
and the spectral density plot shown below:
(a) Determine at which frequency (x1, x2, x3 or x4) the image was acquired,
and give your reasons.
(b) At which of these frequencies (x1, x2, x3 or x4) would the relative signal
intensities of the four tissues be reversed, i.e. the highest becomes lowest
and vice-versa?
k-space
5.25 For a spiral k-space trajectory shown in Figure 5.61 (a), draw the gradient
waveforms for the x- and y-gradients.
5.26 Design an EPI pulse sequence that gives the square spiral k-space trajectory
shown in Figure 5.61 (b).
Highest S/N
Medium S/N
Lowest S/N
ventricles
brain tissue
Figure 5.59
See Exercise 5.23.
277
Exercises

MR contrast agents
5.27 For Gd-DTPA the value of a1 is approximately 5 mM21 s21. Assuming that a
small white matter lesion has a T1 of 1.2 s at 3 Tesla, and that the concen-
tration of Gd-chelate inside the lesion is 2 mM, what is the T1 of the lesion
post-administration of the contrast agent. If a T1-weighted gradient echo
sequence is run with a TR of 100 ms and a tip angle of 10, how much is
the signal increased post-administration?
5.28 Assuming a T1 value of tissue and blood of 1 s, calculate the T1(eff) as
a function of blood velocity of 5 cm/s for a slice thickness of 5 mm. Using
a TR of 50 ms and a tip angle of 60, what are the relative signal
kx
ky
kx
ky
kx
ky
kx
kx
ky
ky
kx
ky
a
b
Figure 5.61.
See Exercises 5.25 and 5.26.
re
vil
y
e
n
dik
r
u
o
m
ut
taf
tumour
liver, kidney
fat
1
J( )
2
3
4
ω 
ω 1
J(ω )
ω 2 ω 3
ω 4
1
J( )
2
3
4
Figure 5.60
See Exercise 5.24.
278
Magnetic resonance imaging (MRI)

intensities from blood and stationary tissue? If a contrast agent is added to the
blood so that the T1 of blood is reduced to 200 ms, what are the relative
values?
MRI instrumentation
5.29 A brain MRI is being performed on a patient. Two RF coils are available to
obtain the images, a birdcage coil and a surface coil as shown in Figure 5.62.
Each can be used to transmit the RF pulses, receive the signal, or both
transmit and receive. Images A to D correspond to different combinations
of the two coils used in transmit, receive or both transmit and receive mode.
State, with reasons, which combination of transmit and receive (i.e. Image A,
surface coil transmit, birdcage coil receive) on which coils are used for the
four images A-D.
5.30 Draw two electrical circuits which could be used as analogues to Figure 5.37
for the transmit RF coil.
Lipid suppression
5.31 If the lipid T1 value is 360 ms and the value for muscle is 1420 ms, calculate
the inversion time necessary to null the signal from lipid. What percentage of
the signal from tissue is observed using this inversion time?
5.32 Explain why inversion recovery sequences for lipid suppression are not a
good choice after positive contrast agent administration.
birdcage coil
surface coil
B0
B0
a
b
c
d
Figure 5.62
See Exercise 5.29.
279
Exercises

Review
5.33 Explain whether each of the following statements is true or false, with one or
two sentences of explanation.
(a) Protons precessing at a higher frequency relax back to equilibrium faster
and so have a shorter T1 relaxation time.
(b) A higher strength of the RF ﬁeld from the RF coil means that the duration
of the 90 pulse decreases.
(c) A longer T1 relaxation time means that the voltage induced in the RF coil
lasts longer and so a larger MRI signal is achieved.
(d) One line of k-space data acquired for each value of the phase encoding
gradient corresponds to one line of the image.
(e) All other parameters being equal, a longer RF pulse in a spin-echo
imaging sequence results in a lower signal-to-noise.
(f) At very high magnetic ﬁelds the T1 values of all tissues approach the
same value.
References
[1] Bloch F. Nuclear induction. Physical Review 1946;70(7–8), 460–74.
[2] Lauterbur PC. Image formation by induced local interactions – examples employing
nuclear magnetic-resonance. Nature 1973;242(5394), 190–1.
[3] Kumar A, Welti D and Ernst RR. Nmr Fourier Zeugmatography. J Magn Reson
1975;18(1), 69–83.
[4] Edelstein WA, Hutchison JMS, Johnson G and Redpath T. Spin warp Nmr imaging
and applications to human whole-body imaging. Physics in Medicine and Biology
1980;25(4), 751–6.
[5] Ljunggren S. A simple graphical representation of Fourier-based imaging methods.
J Magn Reson 1983;54(2), 338–43.
[6] Hahn EL. Spin echoes. Physical Review 1950;80(4), 580–94.
[7] Hedeen RA and Edelstein WA. Characterization and prediction of gradient acoustic
noise in MR imagers. Magn Reson Med 1997;37(1), 7–10.
[8] Turner R. Gradient coil design – A review of methods. Magnetic Resonance Imaging
1993;11(7), 903–20.
[9] Chapman BLW and Mansﬁeld P. Quiet gradient coils – active acoustically and
magnetically screened distributed transverse gradient designs. Measurement Science
& Technology 1995;6(4), 349–54.
[10] Mansﬁeld P and Chapman B. Active magnetic screening of gradient coils in Nmr
imaging. J Magn Reson 1986 Feb 15;66(3), 573–6.
[11] Hayes CE, Edelstein WA, Schenck JF, Mueller OM and Eash M. An efﬁcient, highly
homogeneous radiofrequency coil for whole-body Nmr imaging at 1.5-T. J Magn
Reson 1985:63(3), 622–8.
280
Magnetic resonance imaging (MRI)

[12] Roemer PB, Edelstein WA, Hayes CE, Souza SP and Mueller OM. The NMR phased
array. Magn Reson Med 1990 Nov;16(2), 192–225.
[13] Edelstein WA, Hardy CJ and Mueller OM. Electronic decoupling of surface-coil
receivers for Nmr imaging and spectroscopy. J Magn Reson 1986 Mar;67(1),
156–61.
[14] Carlson JW and Minemura T. Imaging time reduction through multiple receiver coil
data acquisition and image reconstruction. Magn Reson Med 1993;29(5), 681–7.
[15] Sodickson DK and Manning WJ. Simultaneous acquisition of spatial harmonics
(SMASH): fast imaging with radiofrequency coil arrays. Magn Reson Med 1997
Oct;38(4), 591–603.
[16] Pruessmann KP, Weiger M, Scheidegger MB and Boesiger P. SENSE: sensitivity
encoding for fast MRI. Magn Reson Med 1999 Nov;42(5), 952–62.
[17] Griswold MA, Jakob PM, Heidemann RM et al. Generalized autocalibrating
partially parallel acquisitions (GRAPPA). Magn Reson Med 2002;47(6), 1202–10.
[18] Mansﬁeld P. Multi-planar image-formation using Nmr spin echoes. Journal of
Physics C-Solid State Physics 1977;10(3), L55–L58.
[19] Hennig J, Nauerth A and Friedburg H. RARE imaging: a fast imaging method for
clinical MR. Magn Reson Med 1986 Dec;3(6), 823–33.
[20] Crooks LE, Mills CM, Davis PL, et al. Visualization of cerebral and vascular
abnormalities by NMR imaging. The effects of imaging parameters on contrast.
Radiology 1982 Sep;144(4), 843–52.
[21] Ogawa S, Lee TM, Kay AR and Tank DW. Brain magnetic resonance imaging with
contrast dependent on blood oxygenation. Proc Natl Acad Sci U S A 1990
Dec;87(24), 9868–72.
281
References


Index
absorbed dose, X-ray, 78, 79
absorption, ultrasound, 153, 155
classical absorption, 155
relaxation absorption, 154–5
accelerating voltage, 36, 40, 41, 55, 58, 63, 66,
76, 83–4
accidental coincidences, 122, 131, 132, 133
acoustic enhancement, 197
acoustic shadowing, 20, 197, 202
acoustic window, 167
active shielding, gradient coils, 246
aliasing
MRI, 252, 274
pulsed wave Doppler, 184
A-mode scans, ultrasound, 175, 176, 199
analogue-to-digital converter (ADC), 15, 17, 19, 47,
105
Anger position network, 102, 103, 104, 106, 109,
126, 141, 144
angular momentum, proton, 206–7, 210
annihilation coincidence detection, 127, 128
annular array, ultrasound, 174
See also phased arrays, ultrasound
anti-scatter grid, 34, 35, 48, 49, 50–1, 53, 56, 59, 63,
68, 85, 90, 93, 97, 141
attenuation coefﬁcient, nuclear medicine, 25, 102,
103, 114, 115, 119, 126, 140
attenuation coefﬁcient, ultrasound, 46, 155, 156,
199, 202
attenuation coefﬁcient, X-ray, 25, 45, 46, 52, 53, 66,
71, 75, 81, 83, 84, 86, 101
attenuation correction, nuclear medicine, 114, 116,
122, 130–1, 142
axial resolution, ultrasound, 159, 163, 179, 184
backprojection, 24–5, 26, 27, 29, 33
ﬁltered backprojection, 2, 21, 24–5, 27, 28, 29,
66, 71, 72, 73, 75, 77, 86, 88, 110, 114, 115,
123
beam forming, ultrasound, 173, 177
beam hardening, X-ray, 74, 75, 83, 86
beam steering, ultrasound, 169
bevel angle, X-ray source, 38, 39, 48, 62, 85
birdcage coil, MRI, 248, 249, 279
bismuth germanate PET detectors, 122, 125, 126,
128, 133, 136
Bloch equations, 215
block detector design, PET, 126
blood brain barrier (BBB), 81, 262, 269
blood oxygen level dependent (BOLD)
effect, 259
B-mode scans, ultrasound, 169, 175, 176, 177, 179,
180, 184, 185, 187, 191, 194, 195, 196, 199,
200, 201
Boltzmann equation, 207
bow-tie ﬁlter, CT, 75
bremsstrahlung radiation, X-ray, 41
Bucky factor, 49
cadmium zinc telluride (CZT) detectors, PET, 119,
120
caesium iodide (CsI), 52, 53, 54, 54–5, 57, 64
cardiac catheterization, 64
cardiac stress test, 89, 117, 118
cavitation, ultrasound, 192
Chang’s multiplicative method, attenuation
correction, 114
characteristic acoustic impedance, 146–7, 148–9,
151, 158, 199
characteristic radiation, X-ray, 41, 42
charge coupled device (CCD), 5, 6, 64
chemical shift, 220, 267
clinical applications
CT, 80–1
MRI, 268–9, 271–3, 275, 277, 279
PET/CT, 137, 139, 141, 143
planar scintigraphy, 109–111
planar X-ray, 64–5
SPECT, SPECT/CT, 117, 119, 121
ultrasound, 193, 195–6
clutter, ultrasound, 178, 179, 191
coincidence resolving time, 125, 127, 128, 132
collimators
CT, 66, 68
nuclear medicine, 90, 93, 97, 99, 100, 108, 109,
140, 141
PET, 129
SPECT, 111, 113, 120
X-ray, 47
compound scanning, ultrasound, 177
compressibility of tissue, 147, 149, 151
Compton scatter
nuclear medicine, 90, 93, 101, 105, 109, 113,
140, 142

PET, 134, 135
X-ray, 42, 43, 45, 46, 47, 48, 50–1, 53, 56, 58,
63, 85
computed radiography, 49, 50, 51, 85, 88
computed tomography dose index (CTDI), 79
contrast agents
MRI, paramagnetic, Gd-based, 69, 84, 85, 114,
125, 261, 262
MRI, superparamagnetic, iron oxides, 261, 263,
276
ultrasound, microbubbles, 146, 187, 188, 189,
190, 191
X-ray, barium-based, 59, 60, 65, 72
X-ray, iodine-based, 61
contrast-to-noise ratio (CNR), 1, 4, 12
MRI, 237, 238, 261, 266
nuclear medicine, 98, 108, 141, 142
PET, 134
ultrasound, 179
X-ray, 2, 42, 48, 56, 58, 62
convolution, 8, 9, 14, 23, 24, 27, 28, 31, 57
CT number, 71, 72, 75, 80
cyclotron, 89, 123–125, 127
damping, transducer, 159, 160, 161, 163, 179, 245
dead time of detector, 106–108, 134
depth-of-focus (DOF), ultrasound, 165
detector quantum efﬁciency (DQE), 56
deterministic radiation effects, 77, 78
diffusion-weighted MRI, 269
digital radiography, 3, 50, 52, 64, 88
digital subtraction angiography (DSA), 61, 62, 76
Doppler ultrasound, 146, 152, 177, 179, 180, 181,
182, 183, 184, 185, 187, 189, 191, 192, 193,
194, 196, 201, 202, 203
colour ﬂow imaging, 194
continuous wave Doppler, 186–187, 189
power Doppler, 186
pulsed wave Doppler, 181, 186
spectral display, 182
dual energy CT, 75, 115
dual energy window, nuclear medicine, 113, 133
dual source CT, 75
duplex ultrasound, 182
dynamic focusing, ultrasound, 169, 170, 171, 174,
199
dynamic range, receiver, 16, 52, 156, 172, 198
dynode, photomultiplier tube, 101
echo planar MRI, 255
echocardiography, 175, 187, 196, 203
eddy currents, 246
edge detection, 14
effective atomic number, 43, 46, 125
effective dose, radiation, 78, 79
electron capture, 93
energy resolution, nuclear medicine, 105, 106, 113,
119, 127, 133, 136
energy spectrum, X-ray, 40, 40–43, 58, 105
Ernst angle, 233, 259, 274, 280
exposure time, X-rays, 39, 55
fan-beam reconstruction, CT, 73
Faraday’s law of induction, MRI, 213, 220, 241,
247, 264
ﬁgure-of-merit, gradient coils, 246
ﬁngerprint gradient coils, 246, 247
ﬂat panel detector, X-ray, 34, 76, 85
ﬂuorodeoxyglucose (FDG), 124, 134, 137, 139,
141, 143
ﬂuoroscopy, X-ray, 34, 63, 64, 88
f-number, transducer, 163
focal distance, ultrasound, 164
focal plane, ultrasound, 165
focal spot, X-ray, 38, 39, 57, 62, 66, 71, 76, 85, 88,
178, 191
focused transducer, 163, 199
Fourier pairs, 21
Fourier transform, 2, 9, 20–21, 22, 23–24, 28, 32,
183, 220, 225, 230, 231, 239
frame rate, ultrasound, 145, 169, 176, 200
Fraunhofer zone, 161
free induction decay (FID), 220
frequency compounding, ultrasound, 177
frequency encoding, MRI, 223, 228, 229, 232, 236,
239, 274
Fresnel zone, 161
full-width-half-maximum (FWHM), 6, 7, 31, 105,
106, 135, 141, 162
functional MRI (fMRI), 259
gamma camera, 90, 97, 98, 99, 101, 103, 105–107,
112, 126, 140
gamma rays, 140 keV monoenergetic, 89, 92–93
geometric unsharpness, X-ray, 24, 57, 58, 63, 85
gradient coils, MRI, 204, 205, 221, 241
gradient echo sequences, MRI, 232, 233, 236, 239,
264, 273, 278
grating lobes, transducer, 178
grid frequency, 49
grid ratio, 49, 53, 56, 63, 85
gyromagnetic ratio, 207
half value layer (HVL), 47
half-life, 91, 91–92, 114, 140, 143, 263
harmonic imaging, ultrasound, 146, 177, 190, 191,
193, 194, 196, 203
heel effect, 38, 39
helical CT, 35, 36, 67–69, 70, 71, 73, 74, 75
high-pass ﬁlter, 12, 29
Hounsﬁeld units, 25, 71
image artifacts, 10, 17, 20, 27
CT, 20
MRI, 20, 246, 253, 255, 269, 271
nuclear medicine, 102
ultrasound, 162, 177, 186, 194, 197
impedance matching, RF coils, 247
inner sphere relaxation, 261, 262
intravenous pyelogram (IVP), 65
inverse Radon transform, 71
inversion recovery sequences, MRI, 268, 279
iterative reconstructions, 77, 110, 115, 123, 131, 133
284
Index

K-edge, 46, 53, 59
kidney-urinary-bladder (KUB) scan, 65
k-space, 21, 22, 229, 230, 231, 252, 253, 254, 255,
256, 277, 280
Larmor frequency, 210, 212, 214, 236, 239, 247,
248
lateral resolution, ultrasound, 163, 164, 165, 169,
178, 190, 194, 199, 200
lead zirconate titanate (PZT), 157, 158, 159, 161,
164, 199
light spread function, 51, 52, 101, 126
line spread function (LSF), 5, 6, 7, 8, 24, 25, 58
linear arrays, ultrasound, 166–7
line-of-reconstruction (LOR), 122, 123, 127, 131,
132, 135, 136
lipid suppression techniques, MRI, 267–8
lipid, MRI signal, 23, 46, 204, 205, 219, 267, 268,
270, 273, 274, 276, 279
lipid, X-ray signal, 46, 47
logic pulse, PET, 127, 128
low-pass ﬁlter, 13
lutetium orthosilicate (LSO), 125, 126, 127,
136
magnet, MRI, 204, 205, 206, 207, 214, 218, 221,
235, 241, 242, 243, 244, 245, 246, 247, 249,
250, 274
magnetic ﬁeld gradient, MRI, 204, 241, 245, 274
magnetic moment, 206, 209, 212, 219
magnetic resonance angiography (MRA), 257
magnetic susceptibility, tissue, 218, 260
mammography, 34, 37, 38, 39, 42, 47, 50, 51, 62,
63, 268
matching layer, ultrasound, 159, 198, 199
maximum intensity projection (MIP), 259
maximum-likelihood expectation-maximum
(ML-EM) method, 116
mechanical index (MI), 190, 192
metastable state, technetium, 93
M-mode scans, ultrasound, 175, 176, 192, 196
modulation transfer function (MTF), 5, 8, 9, 15, 24,
25, 31, 32, 57, 85
multiple channel analyzer (MCA), 105
multiple coincidences, PET, 131, 133, 134
multiple-energy window, 113
multiplicative reduction factor, TOF PET, 136
multislice CT, 70, 71, 116
myocardial perfusion, 89, 97, 110, 117, 118, 119,
196
near-ﬁeld boundary (NFB), ultrasound, 161
non-linear effects, ultrasound, 188, 189
Nyquist frequency, 18, 19, 33
opthalmic pachymetry, 175
outer sphere relaxation, 262
oversampling, 19, 251
parallel imaging, MRI, 252–3, 254
partial volume effect, 12, 109, 116, 261, 266
penumbra, X-ray, 57, 58
PET/CT, principles, 130–131
phase encoding, MRI, 223, 226, 227, 230, 231, 232,
237, 239, 252, 255, 265, 274, 280
phased arrays, MRI, 249, 252–255
phased arrays, ultrasound, 167, 171–2
annular array, 174
multi-dimensional array, 173–4
photocathode, 101
photoelectric interactions, 42–3, 44, 46, 47, 58, 59,
101
photoelectron, 102
photomultiplier tubes, 90, 100, 125
photopeak, 105, 106, 113, 133
piezoelectric materials, 157, 160, 161, 163, 165,
166, 174
point spread function (PSF), 5, 7, 8, 9, 9–11, 12, 30,
85, 134, 141
Poisson distribution, 54, 55, 56, 85, 108
positron annihilation, 123
precession, 209, 211, 212, 214, 218, 221, 222, 224,
264
proton density, MRI, 229, 233, 234, 236, 261, 266,
276
pulse height analyzer (PHA), 105, 106, 127
pulse inversion, ultrasound, 146, 190
pulse repetition rate (PRR), 160, 181, 184
pulsed mode Doppler, 181
quadrature detector, 172, 182, 187
quality (Q) factor, ultrasound transducer, 161
radiation dose, 11, 36, 55, 57, 62, 68, 77, 79, 80, 92,
196
radiation weighting factor, 78
radioactive dose, 92, 93, 118, 140
radioactivity, 6, 33, 90, 92, 95–6, 102, 139, 140,
142, 143
radiofrequency (RF) coils, MRI, 241, 247, 248, 250,
265, 273, 279, 280
radiotracers, 89, 91, 93, 97, 99, 103, 106, 108, 109,
109–111, 112, 113, 114, 118, 121, 134, 137,
139, 140
Ramachandran-Lakshminarayanan (Ram-Lak)
ﬁlter, 29
Rayleigh scattering, ultrasound, 152, 153
receiver operator characteristic (ROC) curve, 2, 4,
30
reﬂection, ultrasound, 53, 152, 153, 155
refraction, ultrasound, 125, 152, 197, 201
relaxation absorption coefﬁcient, ultrasound, 154
reverberation artifact, ultrasound, 197
robotic synthesis, PET, 124
rotating reference frame, MRI, 214, 215, 217, 222,
227
safety levels, ultrasound, 191
sampling rate, 8, 16, 18, 24, 31, 53, 251, 255
scatter correction, 112, 113, 115, 133
scintillation crystal, 90, 100, 101, 106, 109, 125,
140
285
Index

sensitivity, ROC analysis, 2, 4, 30
Shepp-Logan phantom, 29
shim coils, MRI, 244
side lobes, ultrasound transducer, 162
signal averaging, 10, 11
signal-to-noise ratio (SNR), 1, 4, 10–12, 13, 29, 52,
57, 101, 136, 265, 266
MRI, 2, 214, 233, 234, 237, 241, 266
nuclear medicine, 90, 98, 108, 111, 140, 141
PET, 121, 123, 129, 134
ultrasound, 178, 179
X-ray, 54, 55, 57, 58, 59
sinogram, 27, 28, 29, 33, 86, 88, 116, 142
slice selection, MRI, 223
slip ring, CT, 69
sodium iodide crystal, thallium activated, 100–101,
102, 103, 104, 119
sodium pertechnetate, 94, 96
spatial frequency, 5, 9, 12, 20–3, 28, 29, 32, 231
spatial resolution, 1, 2, 4, 5, 7, 9–11, 12–3, 58, 63,
99, 104, 178, 266, 274
CT, 71
MRI, 204, 231, 239, 252, 265, 265–6
nuclear medicine, 90, 100, 108, 108–9, 140,
141
PET, 125, 126, 127, 130, 134–5
SPECT, 111
ultrasound, 165, 178–9
X-ray, 51, 57, 57–8, 63
spatial smoothing, 14, 131
speciﬁc absorption rate (SAR), 267
speciﬁcity, ROC analysis, 2, 4, 30
speckle, 10, 152, 177, 178, 194, 197, 199
SPECT/CT, 116–7
spectral density, MRI, 240, 277
speed of sound, 145, 146, 162, 199, 202
spin–echo sequences, MRI, 235, 236, 237, 238, 254,
256, 257, 263, 273, 274, 276, 280
spin–lattice relaxation time, T1, 216, 217, 228, 231,
236, 238, 257, 261, 262, 264, 266, 267, 268,
273, 275, 276, 278, 279
spin-spin relaxation time, T2, 24, 216, 218, 231,
234, 236, 238, 242, 255, 256, 257, 260, 261,
264, 266, 267, 273, 275, 276
spiral CT, See helical CT
star artifact, backprojection, 26, 28
stochastic radiation effects, 78
subwindow, nuclear medicine, 113
superconducting magnet, See magnet, MRI
surface coil, MRI, 279
technetium generator, 93, 94, 95–6, 140
thermal index (TI), 152, 192, 193, 197, 198, 268
thin-ﬁlm transistor (TFT) arrays, 52
time-gain compensation, ultrasound, 172
time-of-ﬂight (TOF) angiography, MRI, 257, 258,
259, 261, 270
time-of-ﬂight (TOF) PET, 123, 126, 135, 136, 143
tip angle, MRI, 215, 233, 258, 265, 268, 273, 278
tomosynthesis, X-ray, 76, 77
transducer bandwidth, 159
transducers, ultrasound, 145, 146
focused, 163, 165
single element, 156, 161
two-dimensional arrays, 165, 167, 169–71
transmit/receive switches
MRI, 250
ultrasound, 156
tube current, X-ray, 39, 55, 66, 76, 84
tube output, X-ray, 39
turbo spin echo sequences, MRI, 256
vector model, MRI, 273
wave propagation, ultrasound, 146–7
X-ray tube, 10, 34, 36, 36–37, 39–41, 63, 70, 71,
75, 85
z-ﬂying spot technique, CT, 71
z-signal, nuclear medicine, 105
286
Index

