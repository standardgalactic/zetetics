Bayesian Vector Autoregressions and its Applications in
Macroeconomics
By
Hengwei Qi
Submitted to the Department of Economics and the
Graduate Faculty of the University of Kansas
in partial fulÔ¨Ållment of the requirements for the degree of
Doctor of Philosophy
Committee members
Professor Shu Wu, Chairperson
Professor Terry Soo
Professor Ted Juhl
Professor Jianbo Zhang
Professor Pym Manopimoke
Date defended:
May 13, 2015

The Dissertation Committee for Hengwei Qi certiÔ¨Åes
that this is the approved version of the following dissertation :
Bayesian Vector Autoregressions and its Applications in Macroeconomics
Professor Shu Wu, Chairperson
Date approved:
May 13, 2015
ii

Abstract
This dissertation presents three essays which are organized as chapters. Each chapter,
with its own feature, is focusing on parsimonious estimation of Vector Autoregressive
(VAR) models. The newly presented models are applied to some issues in macroeco-
nomics.
VARs are widely used in economic analysis and forecasting probably due to its easy
tractability and the power in exposing and exploring complicated dynamic process in
a modern economy such as shocks, channels and their links. Researchers sometimes
would like to include more observations in VARs in order to have a broad investiga-
tion into the economy. In addition, this analysis, in particular, currently has extended
to time variation in parameters so as to capture the possibly changing dynamics. These
two will inevitably cause parameter proliferation. The over-Ô¨Åtting caused by hoping
including more variables and extending to time variation in parameters and wide ap-
plications because of tractability and detecting power motivate my research interest
in parsimonious modeling, estimation and applications as well as comparisons in this
dissertation.
In the Ô¨Årst chapter, I extend the previous parsimonious estimation on constant coefÔ¨Å-
cients to time varying coefÔ¨Åcients. It is desirable since when time dimension is taken
into account, the number of parameters rises with time periods while number of obser-
vations still Ô¨Åxed there, the same as in constant parameter estimation. I use stochastic
variable selection method over the time dimension, that is, the time varying dynamics
of each coefÔ¨Åcient in a TVP-VAR model is checked. I estimate the model via Bayesian
iii

method based on the sensitivity of variation of conditional likelihood when the coef-
Ô¨Åcient considered in the model or not. If the coefÔ¨Åcient has more contribution to the
likelihood, the posterior tends to give more probability of staying in the system. Nev-
ertheless, if the parsimonious check is imposed on every coefÔ¨Åcient in the model, the
computational burden will substantially increase because this estimation is essential
a mixed model estimation such that every possible model needs to be checked. The
number of candidate models increases with time dimension. I suggest two ways to al-
leviate it. One is from model setting that we can check the variables we are interested
in collected together as a whole. In other words, we can do block checking rather than
single checking. The other is from the efÔ¨Åciency of the numerical computation which
is conducted in two dimensions. We construct large matrices to replace Kalman for-
ward Ô¨Ålter and backward smoother in order to reduce the procedures in each iteration
in Bayesian simulation. On the other hand, the structure of the large matrix is sparse
which further make the computation efÔ¨Åcient. The single-checking-based TVP‚ÄìVAR
with stochastic volatility is used to estimate the changes in monetary policy stance
and agents‚Äô behavior to policy shocks over time. With the most parsimonious estima-
tion, I still cannot Ô¨Ånd signiÔ¨Åcant changes both in policy stance and in the reaction of
economic agents to the non-systematic monetary policy shocks.
In the second chapter, I present a general parsimonious estimation on the time vary-
ing parameter VAR with stochastic volatility via factor idea. That is, the far lags
are driven by recent lags; the time variation in coefÔ¨Åcients on regressors is driven by
several factors and therefore the covariance matrix of innovations to the coefÔ¨Åcients
become reduced rank. Lastly, we use a latent factor, namely, the common volatility to
represent full stochastic volatility based on the empirical evidence that the estimated
volatilities of most macroeconomic variables share the similar pattern. Note that the
model I present concentrates on how to reduce the dimension of the parameters, not the
dimension of large data set such as factor models like dynamic factor models or factor
iv

augmented models. The model is estimated by Bayesian simulation. Each estimation
procedure or block is presented in this chapter. Based on the general treatment, the es-
timation procedures can be freely combined with some proper modiÔ¨Åcation depending
on the speciÔ¨Åc research object. I give an empirical analysis by the factor driven model.
The analysis is based on the typical small scale monetary VAR. Principal component
analysis shows that small scale TVP-VAR is still over-Ô¨Åtting very much, can be driven
by several factors and that early lags are not suitable to drive far lags that will cause
dynamic contamination. Therefore parsimonious estimation via factors on time vary-
ing coefÔ¨Åcients and common volatility is used to estimate the small scale monetary
VAR. Focusing on agent response to monetary policy shocks, I cannot Ô¨Ånd signiÔ¨Åcant
difference among different time periods.
In the last chapter, I consider a large Bayesian VAR that contains 28 variables. The
variables cover a broad range of the U.S economy including labor market, housing
market, bonds market and so on. High dimensional observations are desirable by re-
searchers because this setting can give a strong background of the whole economy, re-
ducing potential missing variables that are critical for the transmission of some shocks
of interest. A large number of endogenous variables will increase the degree of param-
eter proliferation. I use proper priors that can shrink values of coefÔ¨Åcients to conduct
an empirical analysis on monetary policy shocks, Ô¨Ånancial shocks and uncertainty
shocks. I Ô¨Ånd that for the effects of monetary policy shocks, the impulse response
functions are almost perfectly in line with theoretical predictions. For the Ô¨Ånancial
shocks and uncertainty shocks, we analyze them jointly. Both positive Ô¨Ånancial and
uncertainty shocks have negative effects on real activities, however, Ô¨Ånancial shocks
have more persistent effects on these variables than uncertainty shocks. We also Ô¨Ånd
that Ô¨Ånancial variables care more for uncertainty shocks compared to Ô¨Ånancial shocks.
v

Acknowledgements
I wish to express my deep and sincere gratitude to my advisor, Professor Shu Wu,
for his excellent guidance, care, patience, and for providing me with an excellent at-
mosphere for doing research. His invaluable suggestions and help hasten the cross of
Bayesian econometrics and macroeconomics in my dissertation.
I would like to thank Professor Terry Soo, in Department of Mathematics, for reading
this thesis word by word from grammar to contents and giving me lots of impor-
tant suggestions. Special thanks go to Professors Ted Juhl, Jianbo Zhang and Pym
Manopimoke for being in my dissertation committee.
Understanding the theory of Bayesian econometrics is one thing, putting it into prac-
tice is another thing. I would also like to thank Professor Dimitris Korobilis, at Univer-
sity of Glasgow, for his suggestion in email contact and code sharing and explanation
on his website. Without his code and suggestion, I cannot have a good and deep un-
derstanding of Bayesian theory and improve my code writing skill. I learn much from
his website.
Finally, I would like to express my deepest gratitude to all the people who have
helped me in my research and dissertation writing during the Ph.D life at University of
Kansas. Without them, I would never have been able to Ô¨Ånish my dissertation. I owe
much to them.
vi

Contents
1
The Restricted Bayesian Vector Autoregressions and Monetary Policy Estimation
1
1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
Models in stochastic variable selection . . . . . . . . . . . . . . . . . . . . . . . .
7
1.2.1
Stochastic variable selection Bayesian VAR . . . . . . . . . . . . . . . . .
9
1.2.2
Stochastic variable selection partial TVP-VAR
. . . . . . . . . . . . . . .
11
1.2.3
Stochastic variable selection full TVP-VAR . . . . . . . . . . . . . . . . .
14
1.3
Bayesian estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
1.3.1
Stochastic volatility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
1.3.2
Stochastic selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
1.3.3
Exercise
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
1.4
Monetary policy in stochastic selection models
. . . . . . . . . . . . . . . . . . .
22
1.4.1
Data description
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.4.2
Lags and signiÔ¨Åcance . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
1.4.3
Impulse responses
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
1.4.4
Systematic or exogenous change . . . . . . . . . . . . . . . . . . . . . . .
32
1.4.4.1
Agents bahavior to monetary shocks
. . . . . . . . . . . . . . .
33
1.4.4.2
Systematic monetary policy . . . . . . . . . . . . . . . . . . . .
33
1.4.4.3
Non-systematic monetary policy shocks
. . . . . . . . . . . . .
42
1.4.4.4
An interpretation . . . . . . . . . . . . . . . . . . . . . . . . . .
42
1.5
Robust check
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
vii

1.6
Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
Appendix
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
A. The basic Kalman Ô¨Ålter and state smoother . . . . . . . . . . . . . . . . . . . .
61
B. ModiÔ¨Åed Kalman Ô¨Ålter and state smoother with breaks . . . . . . . . . . . . . .
63
C. Estimation of states without Kalman Ô¨Ålter and state smoother . . . . . . . . . .
64
D. EfÔ¨Åcient estimation of SVS-Full-TVP-VAR
. . . . . . . . . . . . . . . . . . .
66
2
A General Parsimonious Estimation of Time-varying Vector Autoregressions
70
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
2.2
Model speciÔ¨Åcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
2.3
Bayesian estimation procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
2.3.1
Draw a history of {bt}T
t=1
. . . . . . . . . . . . . . . . . . . . . . . . . .
80
2.3.1.1
Draw a history of
Àúbt
	T
t=1 . . . . . . . . . . . . . . . . . . . . .
81
2.3.1.2
Draw Mbb0 as a whole . . . . . . . . . . . . . . . . . . . . . . .
82
2.3.1.3
Draw a history of {bt}T
t=1 . . . . . . . . . . . . . . . . . . . . .
84
2.3.2
Draw reduced rank covariance matrix Qb
. . . . . . . . . . . . . . . . . .
84
2.3.3
Draw constant matrix B
. . . . . . . . . . . . . . . . . . . . . . . . . . .
84
2.3.4
Draw constant matrix G1 . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
2.3.5
Draw structural impact matrix A . . . . . . . . . . . . . . . . . . . . . . .
87
2.3.6
Draw diagonal elements of S . . . . . . . . . . . . . . . . . . . . . . . . .
88
2.3.7
Draw common stochastic volatility {Œªt}T
t=1 . . . . . . . . . . . . . . . . .
88
2.3.8
Draw coefÔ¨Åcient F . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
2.3.9
Draw variance Qh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
2.4
Empirical analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
2.4.1
Are factors important in time varying parameters?
. . . . . . . . . . . . .
94
2.4.2
Structural analysis and model evaluation . . . . . . . . . . . . . . . . . . . 102
2.5
Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
Appendix
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
viii

A. Bayesian estimation of restricted linear regression model
. . . . . . . . . . . . 114
3
Structual Analysis in a Large Bayesian VAR
117
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
3.2
The literature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
3.3
The model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3.3.1
The likelihood of VAR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3.3.2
The priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.3.3
The posterior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
3.4
Empirical analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
3.4.1
The data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
3.4.2
Empirical Ô¨Åndings
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
3.5
Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
Appendix
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
A. Data speciÔ¨Åcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
ix

List of Figures
1.1
IRs for model 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
1.2
IRs for model 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
1.3
IR-inÔ¨Çation-comparison for model 3 . . . . . . . . . . . . . . . . . . . . . . . . .
36
1.4
IRs-unemployment rate-comparison for model 3 . . . . . . . . . . . . . . . . . . .
37
1.5
IRs-inÔ¨Çation-comparison for model 2
. . . . . . . . . . . . . . . . . . . . . . . .
38
1.6
IRs-unemployment rate-comparison for model 2 . . . . . . . . . . . . . . . . . . .
39
1.7
3D-IRs for model 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
1.8
3D-IRs for model 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
1.9
Policy response to inÔ¨Çation for model 3
. . . . . . . . . . . . . . . . . . . . . . .
43
1.10 Policy response to inÔ¨Çation for model 2
. . . . . . . . . . . . . . . . . . . . . . .
44
1.11 Policy response to unemployment rate for model 3
. . . . . . . . . . . . . . . . .
45
1.12 Policy response to unemployment rate for model 2
. . . . . . . . . . . . . . . . .
46
1.13 Volatility for each variable in model 3 . . . . . . . . . . . . . . . . . . . . . . . .
47
1.14 Posterior probability for each coefÔ¨Åcient in policy rule
. . . . . . . . . . . . . . .
49
1.15 Posterior probability of each coefÔ¨Åcient in inÔ¨Çation equation . . . . . . . . . . . .
50
1.16 Poterior probability of coefÔ¨Åcient in unemployment rate equation . . . . . . . . . .
51
1.17 Posterior probability of each regime . . . . . . . . . . . . . . . . . . . . . . . . .
54
1.18 IRs of inÔ¨Çation and their difference between different regimes
. . . . . . . . . . .
56
1.19 IRs of unemployment rate and their difference between different regimes
. . . . .
57
1.20 IRs of interest rate to inÔ¨Çation shocks
. . . . . . . . . . . . . . . . . . . . . . . .
58
x

1.21 IRs of interest rate to unemployment shocks . . . . . . . . . . . . . . . . . . . . .
59
2.1
Contribution and cumulative contribution for lag 1 . . . . . . . . . . . . . . . . . .
96
2.2
Contribution and cumulative contribution for lag 2 . . . . . . . . . . . . . . . . . .
97
2.3
Contribution and cumulative contribution for lag 3 . . . . . . . . . . . . . . . . . .
98
2.4
Contribution and cumulative contribution for lag 4 . . . . . . . . . . . . . . . . . .
99
2.5
TVP-VAR-CV-lag1-factor7-IR-inÔ¨Çation . . . . . . . . . . . . . . . . . . . . . . . 103
2.6
TVP-VAR-CV-lag1-factor7-IR-unemployment rate . . . . . . . . . . . . . . . . . 104
2.7
TVP-VAR-CV-lag2-factor3-IR-inÔ¨Çation . . . . . . . . . . . . . . . . . . . . . . . 105
2.8
TVP-VAR-CV-lag2-factor3-IR-unemployment rate . . . . . . . . . . . . . . . . . 106
2.9
TVP-VAR-CV-lag3-factor3-IR-inÔ¨Çation . . . . . . . . . . . . . . . . . . . . . . . 108
2.10 TVP-VAR-CV-lag3-factor3-IR-unemployment rate . . . . . . . . . . . . . . . . . 109
2.11 TVP-VAR-CV-lag4-factor3-IR-inÔ¨Çation . . . . . . . . . . . . . . . . . . . . . . . 110
2.12 TVP-VAR-CV-lag4-factor3-IR-unemployment rate . . . . . . . . . . . . . . . . . 111
2.13 Common volatility in different model settings . . . . . . . . . . . . . . . . . . . . 112
3.1
IRs to monetary policy shocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
3.2
IRs to uncertainty shocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
3.3
IRs to Ô¨Ånancial shocks
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
xi

List of Tables
1.1
Exercise result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
1.2
Lag check1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
1.3
Lag check2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
1.4
Lag check3
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
1.5
Lag check4
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.6
Lag check5
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.7
Lag check6
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
1.8
Lag check7
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
1.9
Lag check8
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
1.10 Lag check9
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
1.11 Lags in model 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.1
Contribution for each factor via principal component analysis on covariance matrix
Qb for TVP-VAR-CV from lag one to lag two . . . . . . . . . . . . . . . . . . . .
95
2.2
Contribution for each factor via principal component analysis on covariance matrix
Qb for TVP-VAR-CV from lag three to lag four . . . . . . . . . . . . . . . . . . .
95
3.1
Data speciÔ¨Åcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
xii

Chapter 1
The Restricted Bayesian Vector
Autoregressions and Monetary Policy
Estimation
1

1.1
Introduction
Many economists have found that there is strong evidence that the U.S. economy experienced
higher and more volatile unemployment and inÔ¨Çation in the last century 70‚Äôs and the early 80‚Äôs
than the following years. It‚Äôs natural to relate the U.S. monetary policy to the bad performance
and ask the question of whether high inÔ¨Çation and slow growth during that period were due to bad
policy or bad luck. The literature generally gives two main explanations. One (e.g. Blanchard
and Simon, 2001; Koop, Leon-Gonzalez and Strachan, 2009; Primiceri, 2005; Sims and Zha,
2006; Stock and Watson, 2002a ) focuses on exogenous shocks, which have been much more
volatile in the 1970‚Äôs and early 1980‚Äôs than in the rest of the sample. They argued that the variance
of the exogenous shocks has changed over time and that this alone may explain many apparent
changes in monetary policy. This is ‚Äòbad luck‚Äô story, i.e. in the 1970s volatility was high, whereas
later policymakers had the good fortune of the Great Moderation of the business cycle. Koop,
Leon-Gonzalez and Strachan (2009) and Primiceri (2005) using the method of time-varying vector
autoregression, they still Ô¨Ånd exogenous shocks play an overwhelming role. Therefore, I put them
in this respect. The second emphasizes the changes in the transmission mechanism‚Äîthe way
macroeconomic variables respond to shocks. Particular attention gives to monetary policy reaction
function. Some authors (e.g. Boivin and Giannoni, 2006, Cogley and Sargent, 2001, and Lubik
and Schorfheide, 2004)) have argued that the way the Fed reacted to inÔ¨Çation has changed over
time. They think that the Fed was less active in Ô¨Åghting inÔ¨Çation pressures under the chairmanship
of Burns than under Volker and Greenspan. This is ‚Äòbad policy‚Äô story.
However, these explanations are controversial. For example, Bernanke and Mihov (1998),
Hanson (2003), Leeper and Zha (2003) found that litter evidence of changes in the systematic part
of monetary policy and Sims (1999, 2001) found no evidence of unidirectional drifts in policy
toward a more active behavior.
From the methodological perspective, many versions of Bayesian Vector Autoregressions (BVAR)
in this Ô¨Åeld are well developed. Here, I just pick up some representatives. Sims and Zha (2006)
used Bayesian VAR with multivariate stochastic volatility but no time-varying parameters. Cogley
2

and Sargent (2001) developed a time-varying parameters VAR model without stochastic volatil-
ity. Later they (2005) further extend a Bayesian VAR model with time-varying parameters and
multivariate stochastic volatility. The volatility however is too restrictive. This model allows the
simultaneous relations among variables are time invariant i.e. covariance is constant and vari-
ance is dynamic. In impulse response analysis, it can be shown that this restriction implies that
a shock to the ith variable has an effect on the jth variable which is constant over time. In some
macroeconomic applications, relationships might not be the case. Boivin (2001) considered time
varying simultaneous relations, but ignored potential heteroscedasticity of innovations. Ciccarelli
and Rebucci (2003) extend a t-distribution of errors based on the Boivin (2001) model; Finally,
Primiceri (2005) got the time varying parameters and loose multivariate volatility together. Loose
multivariate volatility means no restriction imposed on the covariance and variance parameters in
error matrix, totally time-varying now. This Ô¨Çexible approach can be regarded as today‚Äôs standard
time varying VAR workhorse and is widely used in empirical macroeconomics.
It seems surprising, however natural that all models above and further modiÔ¨Åcations are all
Bayesian. First, if the model is a time invariant parameter VAR, in terms of classical estimation,
for instance, a VAR involving 5 dependent variables with 4 lags contains 105 parameters. Gen-
erally, in a quarterly macroeconomic data set, the number of observations on each variable might
be a few hundred and for some reason, usually a segment, not all range is picked up for a speciÔ¨Åc
analysis. That implies that maybe a few data is shared for each parameter estimation‚Äîthe informa-
tion density is too low. If the model is extended to a time variant one, apparently more parameters
will be created. Think how many observations of data we should have to make the estimation and
further features of interest like forecasts and impulse responses precise. It‚Äôs impossible! Second, if
the variance of the time varying coefÔ¨Åcients is small, the classical maximum likelihood estimator
of this variance has a point mass at zero. This is so called pile-up problem (Sargent and Bhargava,
1983; Shephard and Harvey, 1990; Stock and Watson, 1998). The third, the maximum likelihood
method often meets optimization problem when model dimensionality is multiple and no longer
linear. Such a complicated model will highly probably have a multivariate likelihood function of
3

regions containing many local peaks and it‚Äôs difÔ¨Åcult to distinguish which one is global. More-
over, if these peaks are very narrow, the likelihood may reach particularly high values, not at all
representative of the model‚Äôs Ô¨Åt on a wider and more interesting parameter region. Altogether, rich
parameters and potential problems in maximum likelihood with limited observations of data sets
make the classical estimation not suitable for some researches. A Bayesian method is naturally
introduced. In a Bayesian setting, not as many observations are needed, of course the more, the
better; Given a uninformative prior together with likelihood function, posterior mean and variance
of parameters and features of interest can be obtained from convergent therefore stable distribu-
tions by using Markov chain Monte Carlo (MCMC) method. The Gibbs sampler is a variant of
MCMC and widely used in these models. It consists of drawing from lower dimensional condi-
tional posteriors as opposed to the high dimensional joint posterior of the whole parameter set.
Bayesian vector autoregressions with Markov Chain Monte Carlo are a good and suitable ap-
proach to estimate parameters, especially in the form of time variation. However, implicitly it is
assumed that all parameters of every draw from some stable posterior distributions are efÔ¨Åcient
and should exist in the model. Simply speaking, all parameters in this Bayesian model are given
signiÔ¨Åcant before you start estimate, i.e., every one is counted in. In reality, it‚Äôs not the case. Let‚Äôs
compare it with classical vector autoregressions Ô¨Årst. In the context of classical estimation, the
usual way to test a coefÔ¨Åcient in a model whether or not signiÔ¨Åcant relative to zero is t-test or
F-test. We get the p-value of the coefÔ¨Åcient and then compare it with signiÔ¨Åcant level in some
distribution to decide reject or accept the null hypothesis. Anyhow, a speciÔ¨Åc way of testing pa-
rameter signiÔ¨Åcance is already at hand in the Ô¨Åeld of classical estimation. Nevertheless, when
the same concern comes to Bayesian VAR and determine which coefÔ¨Åcient is signiÔ¨Åcant by some
methodology, how to deal with this problem? I am very interested in it.
To my best knowledge, I only Ô¨Ånd two articles about this issue in Bayesian Ô¨Åeld. One is Kuo
and Mallick (1997), the other is Korobilis (2013b). The former presented the coefÔ¨Åcients to be
precisely zero if the indicator of the corresponding coefÔ¨Åcient is zero (for instance, Œ≥ j is the corre-
sponding indicator for Œ≤ j, when Œ≤j = 0 if Œ≥ j = 0); The latter has extended the use of such methods
4

to VARs for forecasting considering possible economic structure change and policy regime switch
that has been well documented in related literature, especially in the Ô¨Åeld of monetary policy and
business cycles. A Markov chain Monte Carlo method (I will give details later) is created to obtain
the posterior probability of each indicator after many times of iterations, therefore the posterior
probability of parameter corresponding to this indicator. A criteria probability is set to compare
with the probability of each indicator, namely, corresponding parameter. If the posterior prob-
ability of the parameter is greater than the criteria probability, then the parameter is said to be
signiÔ¨Åcant with high conÔ¨Ådence and should stay in the Bayesian model. It looks like a test as in
classical estimation.
This restricted vector autoregression method chosen by indicators has three advantages. First,
variable selection is automatic, meaning that along with estimates of parameters we get associ-
ated probabilities of inclusion of each parameter in the ‚Äòbest model‚Äô. For instance, in a VAR of
5 dependent variables with 4 lags I used before, the indicators tells us which elements of coefÔ¨Å-
cient matrices should be included or excluded from the Ô¨Ånal optimal model, thus implementing
a selection among all possible VAR model combinations, without the need to estimate each and
everyone of these models. Second, this form of Bayesian variable selection is independent of the
prior assumptions about parameter matrices. That is, if the researcher had deÔ¨Åned any desirable
prior for her parameters of the unrestricted model, adopting the variable selection restriction needs
no other modiÔ¨Åcation than one extra block in the posterior sampler that draws from the conditional
posterior of the indicators. Finally, unlike other proposed stochastic search variable selection al-
gorithms for VAR models (George et al., 2008), this form of variable selection may be adopted in
many nonlinear extensions of VAR models.
The contribution of this paper is threefold. One is on methodology. In Korobilis (2013b), he
extends stochastic variable selection method to constant parameter VAR and limited time-varying
parameter VAR without stochastic volatility, respectively. This type of time variation in the context
of TVP-VAR framework in Korobilis (2013b) only refer to one of coefÔ¨Åcients either keep existing
and time varying over time or not. Here, based on his model, I extend the potential time variation
5

to each and every coefÔ¨Åcient, namely, it allows each and every coefÔ¨Åcient of TVP-VAR to shift
over time with corresponding posterior probability of present or not, but not necessarily the next
time. Whether or not the coefÔ¨Åcient is time varying is totally determined by data, period by pe-
riod. Furthermore, I could also add loose stochastic volatility, i.e. both variance and covariance
parameters of innovation matrix are time-variant ‚Äì some econometricians call this volatility model
heteroskedastic TVP-VAR ‚Äì with several extra blocks embedded in original iteration route. One
thing worth mention is that since the method looks into determining whether every and each co-
efÔ¨Åcient in the TVP-VAR exist or not over time, the computational burden is high and thus time
consuming. To increase computational efÔ¨Åciency, we use the precision based algorithm of Chan
and Jeliazkov (2009) to replace typical procedure of Kalman Ô¨Ålter and Smoother (forward Ô¨Åltering
and backward smoothing) for an estimation of linear and gaussian state-space models. The second
is that perhaps the Ô¨Årst one implements the stochastic variable selection time-varying parameters
autoregression with stochastic volatility on monetary policy analysis. We Ô¨Ånd that, more precisely
than extant literature, there are no signiÔ¨Åcant systematic shifts in monetary stance and economic
agents‚Äô behavior due to exogenous monetary policy shock. The last but not the least is that we give
an Bayesian statistic proof of the stability of small monetary VAR system. This is done by two
steps. we Ô¨Årst check variable signiÔ¨Åcance over time due to proliferation of parameters in VAR sys-
tem under limited data availability; second, we only focus on large breaks because generally, only
the large ones have high potential to be candidates of structural change.1 Since typical TVP-VAR
is a type of model whose latent parameters vary every time, the accounting of small breaks may
take over some strength from original true large breaks, which may cause misleading. We solve
this problem with a modiÔ¨Åed TVP-VAR augmented with a discrete Markov process.
The paper is organized as follows. In the second section, we present three stochastic variable
selection models step by step from static to time variation and from without stochastic volatility
to with it. We give basic Bayesian estimation procedure for each model and more importantly,
also explore their internal relations among these models; The third section discusses estimation
1Note that breaks are not necessarily equivalent to systematic changes. Systematic changes imply some ‚Äòdeep
parameters‚Äô have changed in DSGE models.
6

issues on stochastic volatility and stochastic variable selection as well as efÔ¨Åcient implementation
of computation; In section 4, we use these models to estimate and evaluate whether there were
regime switches in monetary policy and structural changes in the U.S. economy, then give our
Ô¨Åndings and interpretation; Section 5 conducts robust check and the last section 6 concludes.
1.2
Models in stochastic variable selection
This section gives three models that are mutually relevant and become Ô¨Çedged step by step, mod-
eling gradually close to economic reality. I present a basic description of each model. The Ô¨Årst is
stochastic variable selection time-invariant parameter model, namely stochastic variable selection
Bayesian VAR for which I use SVS-BVAR for short. The second is stochastic variable selection
partial time-varying parameter model, in which setup parameters either exist all time or not. I
use SVS-Partial-TVP-VAR for short for this model. The last, newly developed in this chapter,
is stochastic variable selection full time-varying parameter model where parameters either exist
or not period by period. I call it SVS-Full-TVP-VAR. The three models can be imbeded with a
stochastic volatility part, taking into account dynamics of exogenous shocks.
At the starting point, I should clarify some notations associated with these models.2 A usual
form of VAR should be transformed into a reduced form for convenient analysis. The VAR(p) of
p‚àílag and M dimensionality with constant parameters can be written as:
yt = c+A1yt‚àí1 +¬∑¬∑¬∑+Apyt‚àíp +Œµt
(1.1)
where yt is an M √ó1 vector, c is an M √ó1 constant, {Ai}p
i=1 are M √óM matrices, and Œµt is an M √ó1
vector of shocks following normal distribution Œµt ‚àºN(0,Œ£) , for t = 1,...,T. The (1.1) can be
transformed into a compact form
yt = ZtŒ≤ +Œµt
(1.2)
2These notations apply to all the three chapters.
7

where Zt = IM [1,y
‚Ä≤
t‚àí1,...y
‚Ä≤
t‚àíp] and Œ≤ = vec([c,A1,...Ap]
‚Ä≤), with  and vec Kronecker product
and column stacking operator, respectively.
Above is just simple expression for writing convenience. If in terms of estimation, i.e. nesting
all data together in big matrices, two forms are found. One is Canova (2007) and others; the other
is, for example, Kadiyala and Karlsson (1997). The former arises if we use an TM √ó 1 vector
y which stack all T obsevations on the Ô¨Årst dependent variables, then all T observations on the
second dependent variables, etc., i.e. y = [y1:T ‚Ä≤
1
,...,y1:T ‚Ä≤
M ]‚Ä≤ where y1:T
i
denote observations of yi in a
column from time 1 to time T. The latter arises if we deÔ¨Åne Y to be T √óM matrix which stacks the
T observations on each dependent variable in columns next to one other, i.e. Y =

y1:T
1 ,...,y1:T
M

.
Œµ and E denote stackings of the errors in a manner conformable for y and Y, respectively. DeÔ¨Åne
xt = [1,y
‚Ä≤
t‚àí1,...,y
‚Ä≤
t‚àíp]
‚Ä≤ and X = [xt,...,xT]
‚Ä≤. Note that if we let K = 1 + M ¬∑ p be the number of
coefÔ¨Åcients in each equation of the VAR, the X is a T √ó K matrix. Finally, if A = [c,A1,...,Ap]
‚Ä≤,
we deÔ¨Åne Œ≤ = vec(A) that is a K ¬∑M √ó1 vector which stacks all the VAR coefÔ¨Åcients including the
intercepts into a column vector. With all these deÔ¨Ånitions, we can write the VAR either as
Y = XA+E KK version
(1.3)
or
y = (IM X)Œ≤ +Œµ Canova version
(1.4)
where y = vec(Y) from above deÔ¨Ånitions and Œµ ‚àºN(0,Œ£IT).3
If parameters are time variant, the form of VAR accordingly becomes
yt = ct +A1,tyt‚àí1 +¬∑¬∑¬∑+Ap,tyt‚àíp +ut
(1.5)
or compactly
yt = ZtŒ≤t +ut
3Equation (1.4) can be derived from equation (1.3) via vec(ABC) = (C‚Ä≤ A)vec(B).
8

where Zt = IM 

1,y‚Ä≤
t‚àí1,...,y‚Ä≤
t‚àíp

, Œ≤t = vec
 [ct,A1,t,...,Ap,t]‚Ä≤
and ut ‚àºi.i.dN(0,Œ£t) for t =
1,...,T. The stochastic volatility of Œ£t is introduced in the next subsection. Other details and
modiÔ¨Åcations will be given in speciÔ¨Åc models.
Below we get into the stochastic variable selection models with notations deÔ¨Åned above.
1.2.1
Stochastic variable selection Bayesian VAR
The VAR model in simple form of (1.2) can be written as
yt = ZtŒ∏ +Œµt
(1.6)
where Œ∏ = Œì Œ≤, Œì = diag(Œ≥) = diag([Œ≥1,...,Œ≥KM]
‚Ä≤
) and Œµt ‚àºi.i.dN(0,Œ£). We denote Œ≥j the jth
element of the vector Œ≥, which is also jth diagonal element of the matrix Œì, and Œ≥‚àíj the vector Œ≥
with the jth element removed. Priors for parameters in the model are set as
Œ≤ ‚àºNMK(Œ≤,V)
Œ≥ j|Œ≥‚àíj ‚àºBernoulli(1,œÄ0,j)
Œ£ ‚àºIWishart(S,ŒΩ)
where Œ≤, V, œÄ0,j, ŒΩ and S are hyperparameters set by researchers.
Given the priors above, the full conditional posteriors are
1. Sample Œ≤ from the posterior density
Œ≤|Œ≥,Œ≤,Œ£,y,Z ‚àºNMK
  ¬ØŒ≤, ¬ØV

9

where
¬ØV =
 
V ‚àí1+
T
‚àë
t=1
Z‚ãÜ‚Ä≤
t Œ£‚àí1Z‚ãÜ
t
!‚àí1
¬ØŒ≤ = ¬ØV
 
V ‚àí1Œ≤+
T
‚àë
t=1
Z‚ãÜ‚Ä≤
t Œ£‚àí1yt
!
and Z‚ãÜ
t = ZtŒì.
2. Sample Œ≥j from the posterior density
Œ≥ j|Œ≥‚àíj,Œ≤,Œ£,y,Z ‚àºBernoulli
 1, ¬ØœÄ j

preferably in random order j, where ¬ØœÄj =
l0 j
l0 j+l1 j , with
l0j = p(y|Œ∏j,Œ≥‚àíj,Œ≥j = 1)œÄ0j
and
l0j = p(y|Œ∏j,Œ≥‚àíj,Œ≥j = 0)(1‚àíœÄ0j)
The expression p(y|Œ∏ j,Œ≥‚àíj,Œ≥ j = 1) and p(y|Œ∏ j,Œ≥‚àíj,Œ≥j = 0) are conditional likelihood ex-
pressions. Here we deÔ¨Åne Œ∏ ‚ãÜto be equal to Œ∏ but with the jth element Œ∏j = Œ≤j in the case
of Œ≥j = 1. Similarly, we deÔ¨Åne Œ∏ ‚ãÜ‚ãÜto be equal to Œ∏ but with the jth element Œ∏ j = 0 when
Œ≥j = 0. Then in terms of the likelihood of simple form of VAR for each period, namely
equation (1.6), we can write l0j, l1j analytically as
l0j = exp(‚àí1
2
T
‚àë
t=1
(yt ‚àíZtŒ∏ ‚ãÜ)‚Ä≤Œ£‚àí1(yt ‚àíZtŒ∏ ‚ãÜ))œÄ0 j
(1.7)
l1j = exp(‚àí1
2
T
‚àë
t=1
(yt ‚àíZtŒ∏ ‚ãÜ‚ãÜ)‚Ä≤Œ£‚àí1(yt ‚àíZtŒ∏ ‚ãÜ‚ãÜ))(1‚àíœÄ0 j)
(1.8)
10

3. Sample Œ£ from the posterior density
Œ£|Œ≤,Œ≥,y,Z ‚àºIWishart(¬ØŒΩ, ¬ØS)
where
¬ØŒΩ = T +ŒΩ
and
¬ØS = S+
T
‚àë
t=1
(yt ‚àíZtŒ∏)(yt ‚àíZtŒ∏)
‚Ä≤
4. Go back to setp 1 again, start the next iteration.
This model is fundamental to the following model extensions in three aspects. Firstly, the essen-
tial part that determines the posterior probability of presence for each coefÔ¨Åcient is the difference
between the two conditional likelihood l0j if the coefÔ¨Åcient exist and the one l1j if not. When
l0 j dominate l1j, the jth coefÔ¨Åcient shows up with high posterior possibility supported by data;
Secondly, do not forget the role of prior probability œÄ0 j for each coefÔ¨Åcient Œ≤j in that prior also
give information to the posterior outcome. When it is assigned with very informative prior due to
some economic theory, say, a very low value for œÄ0j, the information involved in the conditional
likelihood l0j, to some extent, will be weakened, while l1j will be strengthened; Lastly, the Markov
Chain Monte Carlo (MCMC) method based on this model is Ô¨Çexble to accomodate other modiÔ¨Å-
cation, such as time-varying parameters, stochastic volatility widely existed in the time series.
1.2.2
Stochastic variable selection partial TVP-VAR
In this model, compared with the model SVS-BVAR above, the difference is that coefÔ¨Åcients are
time variant of the type as in Korobilis (2013b). This time variation as mentioned previously for
some coefÔ¨Åcient either exists for the whole time period or not; that is each indicator refers to a
coefÔ¨Åcient from period one to the last period, which is illustrated in details below. The model
11

speciÔ¨Åcation is
yt = ZtŒ∏t +Œµt
(1.9)
Œ≤t = Œ≤t‚àí1 +ut
(1.10)
where Œ∏t = ŒìŒ≤t, Œì = daig(Œ≥) = diag([Œ≥1,...,Œ≥KM]‚Ä≤), Œµt ‚àºN (0,Œ£) and ut ‚àºN (0,Q) which are
uncorrelated with each other at all leads and lags. The priors for this models are
Œ≤0 ‚àºNMK

Œ≤,V

Œ≥j|Œ≥‚àíj ‚àºBernoulli
 1, ¬ØœÄ0j

Q ‚àºIW

Œæ,R

Œ£ ‚àºIW (S,ŒΩ)
Estimating these parameters means sampling sequentially from the following conditonal densityies
1. Sample Œ≤t|Œ≤t‚àí1,Q,Œ£,yt,Z‚ãÜ
t for all t, where Z‚ãÜ
t = ZtŒì, using the Carter and Kohn (1994) Ô¨Ålter
and smoother for state-space models. For details on this, please refer to appendix of Prim-
iceri (2005). This step, for computational efÔ¨Åciency, could be replaced by precision based
algorithm of Chan and Jeliazkov (2009), taking full advantage of sparse matrix computation
in commonly used maths and econometrics software.
2. Sample Œ≥j from the density
Œ≥ j|Œ≥‚àíj,Œ≤,Œ£,y,Z ‚àºBernoulli
 1, ¬ØœÄ j

12

preferably in random order j, where ¬ØœÄj =
l0 j
l0 j+l1 j , with
l0j = p(y|Œ∏ 1:T
j
,Œ≥‚àíj,Œ≥ j = 1)œÄ0 j
l0j = p(y|Œ∏ 1:T
j
,Œ≥‚àíj,Œ≥ j = 0)(1‚àíœÄ0j)
The expression p(y|Œ∏ 1:T
j
,Œ≥‚àíj,Œ≥j = 1) and p(y|Œ∏ 1:T
j
,Œ≥‚àíj,Œ≥j = 0) are conditional likelihoods,
where Œ∏ 1:T
j
=

Œ∏1,j,...,Œ∏t,j,...,Œ∏T,j

. DeÔ¨Åne Œ∏ ‚ãÜ
t to be equal to Œ∏t but with the jth element
Œ∏t,j = Œ≤t,j when Œ≥ j = 1 for all t = 1,...,T. Similarly, we deÔ¨Åne Œ∏ ‚ãÜ‚ãÜ
t
to be equal to Œ∏t but with
jth element Œ∏t,j = 0, namely when Œ≥j = 0, for all t = 1,...,T. Then in the case of TVP-VAR
likelihood of the model, we can write l0j, l1j analytically as
l0j = exp(‚àí1
2
T
‚àë
t=1
(yt ‚àíZtŒ∏ ‚ãÜ
t )‚Ä≤Œ£‚àí1(yt ‚àíZtŒ∏ ‚ãÜ
t ))œÄ0 j
(1.11)
l1j = exp(‚àí1
2
T
‚àë
t=1
(yt ‚àíZtŒ∏ ‚ãÜ
t )‚Ä≤Œ£‚àí1(yt ‚àíZtŒ∏ ‚ãÜ
t ))(1‚àíœÄ0j)
(1.12)
3. Sample Q from the posterior density
Q|Œ≤,Œ≥,Œ£,y,Z ‚àºIW
  ¬ØŒæ, ¬ØR

where
¬ØŒæ = T +Œæ ‚àí1
and
R = ¬ØR+
T
‚àë
t=2
(Œ≤t ‚àíŒ≤t‚àí1)(Œ≤t ‚àíŒ≤t‚àí1)
‚Ä≤
4. Sample Œ£ from the posterior density
Œ£|Œ≤,Œ≥,y,Z ‚àºIWishart(¬ØŒΩ, ¬ØS)
13

where
¬ØŒΩ = T +ŒΩ
and
¬ØS = S+
T
‚àë
t=1
(yt ‚àíZtŒ∏t)(yt ‚àíZtŒ∏t)
‚Ä≤
5. Go back to step 1, start a new iteration.
One thing to note from step 2 above is that the indicator Œ≥ j associate with coefÔ¨Åcient Œ≤jt from
t = 1,...,T, i.e. Œì matrix is invariant over time. This model speciÔ¨Åcation extending from constant
coefÔ¨Åcients to time varying coefÔ¨Åcient may be good to forecast, but probably too restrictive for
modeling time series dynamics as some coefÔ¨Åcients may appear and disappear mutually during
whole time, not simply keeping existing or not. A nature idea is to assign time variant indicator
to each coefÔ¨Åcient in a TVP-VAR model, to capture possible distinct dynamic feature for each
coefÔ¨Åcient. We will refer to model 3 below.
1.2.3
Stochastic variable selection full TVP-VAR
This model is based on the stochastic variable selection partial time-varying parameter VAR (Ko-
robilis, 2013b), i.e. the second model above, and incorporates the multivariate stochastic volatility.
The speciÔ¨Åcation of the model has the same formula as equation (1.9) and equation (1.10) but with
time dimension Œ∏t = ŒìtŒ≤t, Œìt = diag(Œ≥t) = diag

[Œ≥1,t,...,Œ≥KM.t]
‚Ä≤
and Œµt ‚àºN (0,Œ£t). Œ≥j,t is indic-
tor for corresponding Œ≤ j,t, either 0 or 1, meaning including and excluding the corresponding Œ≤ j.t
respectively, for j = 1,...,KM and t = 1,...,T. Œ≥ j,t follows Benoulli distribution independently.
There are two differences in model 3, compared with model 2. The Ô¨Årst is the indicator for each
coefÔ¨Åcient. The indicator Œ≥ now associate with not only identity j, but also with time t. That is,
every coefÔ¨Åcient in TVP-VAR now has its own indicator, unlike that Œ≤ 1:T
j
share the same indicator
Œ≥ j in model 2; The second, error variacne covariance matrix Œ£t, displays time variant, i.e. stochastic
volatility. The covariance matrix typically can be decompoed into the form of Œ£t = A‚àí1
t
DtDtA‚àí1‚Ä≤
t
,
14

where At is a lower triangular matrix with value of ones on the main diagonal
At =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
1
0
¬∑¬∑¬∑
0
a21,t
1
...
...
...
...
...
0
aM1,t
¬∑¬∑¬∑
aM(M‚àí1),t
1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
and Dt is the diagnoal matrix with elements di,t = exp
 1
2hi,t

, for i = 1,...,M. Here, the exponen-
tialization makes values of diagonal elements always positive. Therefore Dt is the matrix
Dt =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
d1,t
0
¬∑¬∑¬∑
0
0
d2,t
¬∑¬∑¬∑
0
...
...
...
...
0
¬∑¬∑¬∑
0
dM,t
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
=
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
e
1
2h1,t
0
¬∑¬∑¬∑
0
0
e
1
2h2,t
¬∑¬∑¬∑
0
...
...
...
0
0
¬∑¬∑¬∑
0
e
1
2hM,t
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
If we Ô¨Årst stack the unrestricted elements of At below main diagonal by rows into a M(M‚àí1)
2
√ó1
vector as at =

a21,t,a31,t,a32,t,...,an(n‚àí1)
‚Ä≤
for n = 2,...,M, and ht = [h1,t,...,hM,t]
‚Ä≤, then Œ≤t, at,
and ht follow independent random walks and the whole speciÔ¨Åcation of the model in state space
form is
yt = ZtŒ∏t +A‚àí1
t
DtœÖt
(1.13)
Œ≤t = Œ≤t‚àí1 +ut
at = at‚àí1 +œÇt
ht = ht‚àí1 +Œ∑t
where œÖt ‚àºN (0,IM) and Œ∏t = ŒìtŒ≤t.
The random walk setting presents the advantages of focusing on permanent shifts and reducing
the number of parameters in the estimation procedure.
15

The innovations in the three state equations are
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
ut
œÇt
Œ∑t
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
‚àºi.i.dN
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
Q
0
0
0
S
0
0
0 W
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
where S can be block diagonal (Primiceri, 2005) or full matrix (De Wind and Gambetti, 2014).4
As for the sampling process for this model, details like Kalman Ô¨Ålter and smoother are dele-
gated to the technical appendix. Without loss of generality, I give the general expression for this
model. It sufÔ¨Åces to note two points. First , l0j and l1j in the above two models now change to
l0 jt and l1jt due to that the indicators Œ≥ j,t have been assigned to every coefÔ¨Åcient in the TVP model
over j = 1,...,KM and t = 1,...,T. The conditional likelihood (approximate to) becomes:
l0js = œÄ0js exp
(
‚àí1
2
"
T
‚àë
tÃ∏=s
(yt ‚àíZtŒ∏t)‚Ä≤ Œ£‚àí1
t
(yt ‚àíZtŒ∏t)+(ys ‚àíZsŒ∏ ‚ãÜ
s )‚Ä≤ Œ£‚àí1
s
(ys ‚àíZsŒ∏ ‚ãÜ
s )
#)
l1js =
 1‚àíœÄ0js

exp
(
‚àí1
2
"
T
‚àë
tÃ∏=s
(yt ‚àíZtŒ∏t)‚Ä≤ Œ£‚àí1
t
(yt ‚àíZtŒ∏t)+(ys ‚àíZsŒ∏ ‚ãÜ‚ãÜ
s )‚Ä≤ Œ£‚àí1
s
(ys ‚àíZsŒ∏ ‚ãÜ‚ãÜ
s )
#)
where Œ∏ ‚ãÜ
s is deÔ¨Åned to be equal to Œ∏s = ŒìsŒ≤s, but Œ∏js is equal to Œ≤j,s, i.e. the corresponding indicator
is Œ≥j,s = 1 for s = 1,...,T and for j = 1,...,KM; Similarly, Œ∏ ‚ãÜ‚ãÜ
s
is when Œ∏ j,s is zero in the case
of Œ≥ j,s = 0 for s = 1,...,T and for j = 1,...,KM. Then the probability for indicator Œ≥j,s = 1 in
Bernoulli drawing is ¬ØœÄj,s =
l0 js
l0 js+l1 js . Note that the identity j and the time s are both randomly
picked up.5 Second, it is about the prior setting. Generally, there are two choices. Usually, the
priors on the time-varying parameters are:
Œ≤ ‚àºN
 0,4InŒ≤

4De Wind and Gambetti (2014) prove that standard Kalman Ô¨Ålter can still be used in the second state space model
for at instead of equation by equation causing block diagonal in S as in Primiceri (2005).
5An efÔ¨Åcient estimation is developed in appendix following Chan and Jeliazkov (2009).
16

l ‚àºN (0,4Inl)
h ‚àºN (0,4Inh)
The subscript presents dimensions of each parameter. The priors on their error covariacne are:
Q ‚àºIW

1+nŒ≤,

(kQ)2  1+nŒ≤

InŒ≤

S ‚àºIW

1+nl,

(kS)2 (1+nl)Inl

W ‚àºIW

1+nh,

(kW)2 (1+nh)Inh

where the hyperparamets are set to kQ = 0.01, kS = 0.1, kW = 0.01. One can also construct the
priors using a training sample (Primiceri, 2005). In particular, assume that ÀÜŒ∏ols and V
  ÀÜŒ∏ols

are the
mean and variance respectively of the OLS estimate of Œò = (Œ≤,l,h) based on a VAR with constant
parameters using an initial training sample.6 Then the priors can be written as
Œ≤ ‚àºN (Œ≤ols,4V (Œ≤ols))
l ‚àºN (lols,4V (lols))
h ‚àºN (hols,4V (hols))
and errors of covariance matrices are
6The priors can also be constructed via Bayesian estimation with noninformative priors.
17

Q ‚àºIW

1+nŒ≤,

(kQ)2  1+nŒ≤

V (Œ≤ols)

S ‚àºIW

1+nl,

(kS)2 (1+nl)V (lols)

W ‚àºIW

1+nh,

(kW)2 (1+nh)V (hols)

Other notations are the same as above.
One thing should be mentioned again is that the model 3 presented here is the general case.
This means that modiÔ¨Åcation or restriction can be applied to the general case. If the investigation
of parameter signiÔ¨Åcance via Œ≥ j,t in model 3 is restricted to Œ≥ j and without stochastic volatility, then
model 3 is reduced to model 2. If further shutting off time variations on coefÔ¨Åcients, it is model 1.
On the other hand, as we discussed stochastic search method is associated with mixture models,
the possible choices will become proliferative when the target model involves many coefÔ¨Åcients,
especially in TVP models (over identity and over time). This will give rise to great computational
burden. Therefore, in order to reduce the burden, an indicator that controls for a set of coefÔ¨Åcients
could be used instead of one for one. Actually, the model 2 has used the idea that each indicator
Œ≥ j corresponds to Œ≤ j over the whole period, namely Œ≤ 1:T
j
. I call it block checking. The property
of indicators over each time and each identity in model 3 makes the investigation of any single
coefÔ¨Åcient (theoretically) possible if pursuing the best model, but causes dramatically increased
computational cost in practice such that sometimes the estimation is infeasible. This is single
checking. Hence, efÔ¨Åcient estimation of stochastic variable selection model is required. I will
discuss it in the next section.
18

1.3
Bayesian estimation
In this section, we focus on two points that are important for estimation and numerical computation.
One is on stochastic volatility; The other is on stochastic variable selection.
1.3.1
Stochastic volatility
Stochastic volatility is a method modeling dynamic process for error term. Once stochastic volatil-
ity (SV afterwards) is used, generally, the econometric model involves a nonlinear or/and non-
gaussian state space part.
Jacquier, Polson and Rossi (1994) propose to, based on Carlin et
al.(1992), use Metropolis step via a single move to draw stochastic volatility; here, we follows
Primiceri (2005), using mixture normal distribution to approximate irregular distribution (speciÔ¨Å-
cally, log
 x2 (1)

), suggested by Kim, Shephard and Chib (1998).
The method involves two steps. Firstly, we draw sT from f
 sT|yT,Œû,hT
, where sT demon-
strate which normal is chosen among mixture normal distributions each period; yT is all the obser-
vation from y1 to yT, the same for log volatility states hT and Œû represents other parameters and
hyperparameters. This conditional posterior is discrete distribution with seven points or ten points
as support, see Kim et al. (1998) for seven normal distributons and Omori et al. (2007) further for
ten, respectively; Secondly, draw hT from f
 hT|yT,Œû,sT
given all s1 to sT from previous step.
This step is very important, as it transforms non-gaussian to a given gaussian based on identity
st each period. Hence, (nonlinear) non-gaussian state space model has been ‚Äòcut‚Äô into linear and
gaussian state space model each period and naturally, multi-move Gibbs sampling of Carter and
Kohn (1994) can be used, which makes chain mix well quickly and therefore reduce computational
time, as opposed to single move of Jacquier et al. (1994).7
Details on this SV approximation method can be found in appendix. Some issues such as why
draw identity sT as Ô¨Årst step and comparison with other methods dealing with SV, reader of interest
are referred to Del Negro and Primiceri (2013), who conÔ¨Årm that performance of this method is
7In Chapter 2, the single move of Jacquier et al. (1994) is used for nonliner state space model.
19

quite good and quantitatively same as the results of methods exactly modeling SV.
1.3.2
Stochastic selection
In section 2, we have given the mechanism of stochastic selection (SS hereafter) in (TVP) VAR
models and sketch the steps how to draw posteriors from full conditional distributions. In this
subsection, we focus on implementation of this stochastic selection in computation, especially for
model 3.
As we discussed in model 3, in section 2, compared with model 1 and model 2, all models
share the essentially same rationale for SS, but computation burden dramatically increases from
model 1 to model 3. Take model 3 for example. After incorporating SV and indicator for each and
every coefÔ¨Åcient (over identity and over time) in the TVP-VAR model, the model becomes very
complicated though it allows for all possibilities. Considering a small TVP-VAR, typically with
three endogenous variables and only two lags ‚Äì usually used in monetary VAR and requiring more
endogenous variables and lags such as oil analyses in Baumeiser and Peersman (2010) ‚Äì and with
sample period usually covering around T = 150 quarterly data set, we need to compute 2‚àß(21‚àó150)
models only for stochastic selection part, not including SV, for just one iteration in the Bayesian
estimation circle.
To make the implementation of SS feasible, two ways can be used. One is block checking,
namely, the selection is based on a set of variables rather than single variable such as model 2.
Apparently, this method can reduce the number of candidate models, but with the concern of
missing potential better choices. Single checking is required if the best model is preferred in some
context. This suggests the second way ‚Äì an efÔ¨Åcient computational method that is prepared for the
general single checking. We use the efÔ¨Åcient simulation method of Chan and Jeliazkov (2009).
The basic idea is that we nest potential iterations in each Bayesian circle into a quiet large and
sparse matrix to reduce number of iterations and therefore to speed up computation.
For example, we can construct large sparse matrices for a linear normal state space model with-
out using typical steps of Kalman forward and backward recursion and directly obtain a draw of
20

Œ≤ 1:T = [Œ≤ ‚Ä≤
1,...,Œ≤ ‚Ä≤
t ,¬∑¬∑¬∑Œ≤ ‚Ä≤
T]‚Ä≤ at a time from a posterior conditional distribution. Thus it is the trans-
formation from conventional estimation of TVP-VAR to estimation of constant parameter VAR via
large and sparse matrices. On the other hand for SS portion, we also construct large sparse matrix
for calculating conditional likelihood for model selection instead of iterating over whole time pe-
riod. That is, corresponding to the draw of Œ≤ 1:T, a large diagonal matrix Œì = Blkdiag

{Œìt}T
t=1

is used where Œìt = diag
 [Œ≥1,t,...,Œ≥MK,t]‚Ä≤
. After this improvement of implementation in compu-
tation, we Ô¨Ånd we can cut off two thirds of time originally used for not doing this due to taking the
advantage of matrix computation faster than iteration and large sparse matrix actually accounting
for small space to save. For details, please refer to appendix for this chapter.
1.3.3
Exercise
Why we need to use stochastic variable selection models to do empirical analysis? Make the
models parsimonious and close to reality. Here, I use an artiÔ¨Åcial data set to show this advantage
of this approach by a simple exercise. For simplicity, I generate a 5 variable VAR with only T = 50
time series observations, one lag and no constant. The unrestricted OLS estimates perform poorly,
while variable selection gives better estimates. This is because we restrict irrelevant variables, and
then there are more degrees of freedom to estimate the parameters on the relevant variables.
Suppose that the coefÔ¨Åcient matrix in the version of Kadiyala and Karlsson (1997) mentioned
above is an identity matrix and that error covariance matrix is randomly chosen only positive
deÔ¨Ånite for sure. Initial data y1 is from a standard uniform distribution. Let‚Äôs look at table 1.1.
The Ô¨Årst column contains posterior probatility in mean when Œ≥ j = 1, namely, the probability of
coefÔ¨Åcient Œ≤ j in the VAR(1) model. Posterior mean of Œ≤j is in column 2. Column 3 contains
coefÔ¨Åcients estimated by ordinary least square method (OLS). The true parameters are in the last
column. The prior probability œÄ0j for each parameter Œ≤j is set to 0.5. That‚Äôs because one has
no idea of including or excluding each parameter, say, perhaps in or out in the model half by half.
Hence, Korobilis (2013b) regards it as ‚Äònoninformative prior‚Äô and criteria probability. Column 3, in
contrast to last column ‚Äì true values of coefÔ¨Åcients ‚Äì demonstrates that the estimation performance
21

is bad and many inefÔ¨Åcient variables contained in. Column 1 gives posterior probability for each
coefÔ¨Åcient that match well with true value: when true value is 1, all posterior probability is 1;
while true value is 0, almost all the corresponding posterior probabilities are extremely low, seldom
above 5% contrast with 50% as criteria. The corresponding mean of each coefÔ¨Åcient in column 2,
compared with column 3, generally, is more close to true value because the indicators give more
information to coefÔ¨Åcients that exist. Obviously, the exercise shows great beneÔ¨Åt on Bayesian VAR
regression.
1.4
Monetary policy in stochastic selection models
1.4.1
Data description
I use a quaterly U.S. data set on the inÔ¨Çation rate, unemployment rate and the short interest rate.
InÔ¨Çation is the annual percentage change in a chain-weighted GDP price index; unemployment
rate is seasonlly adjusted civilian unemployment, all workers over age 16; short rate is 3‚àímonth
Treasury bill rate. They are denoted by yt = (œÄt,ut,rt)
‚Ä≤collected in a vector. The sample runs
from 1953Q1 to 2006Q3. We choose this sample period due to two reasons. One is that this
time span, covering Great InÔ¨Çation, Monetary Targeting, and Great Moderation, is widely used in
the monetary policy literature, especially for those focusing on issue of monetary policy regimes
switching during this possible policy change time period. Therefore it is nature for us to choose
the same span to compare our Ô¨Åndings and results with previous ones. The other is that after recent
global economic and Ô¨Ånancial crisis of 2008, though the Great Recession has gone but still in the
process of slow recovery, the Fed has switched to and continued near zero rate policy until full
recovery, which apparently an abrupt change in monetary instrument.
These three variables we choose in our analysis are commonly used in New Keynesian VAR
literature. They are simple but representative. Examples of papers which use these, or similar
variables, include Cogley and Sargent (2001, 2005), Koop, Leon-Gonzalez and Strachan (2009)
and Primiceri (2005).
22

Restrict
Bayesian
OLS
True
1
0.984388
0.668605
1
0.025
-0.02115
-0.26653
0
0.0268
0.017219
-0.3257
0
0.348
0.063925
-0.3257
0
0.0288
0.01453
-0.1153
0
0.0925
-0.27718
-0.40878
0
1
0.791886
0.671789
1
0.028
0.015616
0.024751
0
0.0412
-0.03159
-0.03933
0
0.0326
0.042137
-0.07599
0
0.0158
0.05577
0.069901
0
0.017
0.073861
0.117344
0
1
0.787047
0.753396
1
0.212
-0.00324
-0.0383
0
0.0166
-0.03478
0.116155
0
0.163
-0.00202
0.09937
0
0.0474
0.033059
-0.02569
0
0.058
-0.02369
-0.00919
0
1
0.8962
0.92836
1
0.019
0.091339
-0.11235
0
0.0564
0.098384
0.350941
0
0.027
-0.02018
0.24663
0
0.0336
-0.01635
0.340174
0
0.0176
0.049076
0.187969
0
1
0.856714
0.90082
1
Table 1.1: Exercise result
Notes: The Ô¨Årst column contains posterior probability in mean when Œ≥ j = 1, namely, the probability
of coefÔ¨Åcient Œ≤j in the VAR(1) model; The second column has posterior mean of Œ≤j; The third
column is OLS estimate of Œ≤ j; The fourth column is for true value of Œ≤ j that is used to construct
the artiÔ¨Åcial data.
23

1.4.2
Lags and signiÔ¨Åcance
In this subsection, I discuss this issue focusing on Model 1, namely static SVS-BVAR. Though its
simplicity, it can specify this issue very well and shed light on the other two models.
Due to the property of stochastic selection models we discussed in section 2, this class of
models itself is able to freely choose what coefÔ¨Åcients enter or exit the system. In this way, if
arbitrarily choose observables and lags, letting the data speak, in a Bayesian framework, one can
Ô¨Ånally Ô¨Ånd the best model associated with its coefÔ¨Åcient signiÔ¨Åcance and lags.
I Ô¨Årst use model 1 (SVS-BVAR) to estimate the full range of the data set. InÔ¨Çation, unem-
ployment rate and 3-month treasury bill rate are typically used in small scale monetary VAR. Of
course, more variables such as real GDP growth, money base, exchange rate and so on can also
be nested into models and let the data decide if they are signiÔ¨Åcantly interact each other and over
time following the idea. Before this paper, to my best knowledge, Canova and Ganbetti (2009),
Cogley and Sargent (2001, 2005), Koop et al. (2009) and Primiceri (2005) all directly give two
lags without any check. The advantage of SVS model is that we can Ô¨Ånd the signiÔ¨Åcant variables
meanwhile the best lag. I Ô¨Årst set the uninformative prior probability œÄ0j = 0.5, meaning the fair
change of including or exluding the corresponding coefÔ¨Åcient. The possible number of lags, say
four lags, needs to be Ô¨Ånally checked by the data.
In Table 1.2, the second column contains posterior probabilities of lagged coefÔ¨Åcients for inÔ¨Ça-
tion. The third column is for unemployment, the last is for interest rate. The bold font probabilities
are much higher than 50%, which implies the corresponding lagged variables should stay in this
VAR model. We can also Ô¨Ånd after 3 lags, no signiÔ¨Åcant dependents left. It says that the right lag
may be 3. But a question arises from the prior choice. In table 1.2, I choose 0.5 as a prior for in-
dicators, which perhaps lower the probability of including some variables, making some variables
left the table that might stay in. To avoid this possibility, I gradually increase the prior from 0.5
to 0.75 by an increase of 5% step by step. Except that the short rate of lag 3 in policy equation
some time not very signiÔ¨Åcant but very close to criteria probability, other variables from table 1.3
to table 1.7 are very stable. Then, the second question comes out that I set prior for each variable
24

œÄ0j = 0.5
Lag = 4
œÄt
ut
rt
c
0.171889
0.9844
0.090889
œÄt‚àí1
1
0.017244
0.994911
ut‚àí1
0.072044
1
0.984111
rt‚àí1
0.007156
0.016889
1
œÄt‚àí2
1
0.018111
0.7271556
ut‚àí2
0.034044
1
0.975822
rt‚àí2
0.006844
0.062489
0.032867
œÄt‚àí3
0.030333
0.015756
0.111333
ut‚àí3
0.042244
0.035956
0.083067
rt‚àí3
0.003689
0.86116
0.692844
œÄt‚àí4
0.014622
0.054178
0.173044
ut‚àí4
0.026467
0.0164
0.113711
rt‚àí4
0.005711
0.054644
0.035489
Table 1.2: Lag check1
the same every time. This may not be the case in reality. Therefore, I use standard uniform dis-
tribution for each prior. Table 1.8 shows the result is the same only with that interest rate of lag
3 for unemployment equation disappears. Actually, uniform distribution probably potentially can
lower or raise prior for some variables and this may make the result controversial. Hence, relatively
speaking prior of 50% is an appropriate choice. We also Ô¨Ånd that the third lag of interest rate is
very isolated and this may be caused by more lags I choose. When lags are reduced to three, see
table 1.9, signiÔ¨Åcant variables are the same as previous results within four lags. When reduced to
lag of two, the result is the same as those with more lags. Altogether, coefÔ¨Åcients of signiÔ¨Åcance
found in table 1.2 is not prior sensitive and coefÔ¨Åcients on fourth lag always keep insigniÔ¨Åcant.
Now, I can say, lag of 3 is a good choice for the static VAR model using this data set.
Following the same spirit, we can also Ô¨Ånd the signiÔ¨Åcance and therefore choose the best lags.
Table 1.11 lists the signiÔ¨Åcance of coefÔ¨Åcients for model 2 (SVS-Partial-TVP-VAR).8 Note that
value in each cell corresponds to the signiÔ¨Åcance of the coefÔ¨Åcients over the whole sample pe-
riod as a whole, i.e., Œ≤ 1:T
j
, while Fig 1.14 to Fig 1.16 for model 3 (SVS-Full-TVP-VAR) gives the
signiÔ¨Åcance of each coefÔ¨Åcient in each equation, Œ≤j,t, for j = 1,...,KM and for t = 1,...,T, indi-
8Acutully for model 2, we Ô¨Ånd three lags are best choice. However, for convenience and consistence of comparison
of results in the related literature, we choose two lags usually seen for quarterly monetary small VAR.
25

œÄ0j = 0.55
œÄt
ut
rt
c
0.273067
0.98576
0.120022
œÄt‚àí1
1
0.024378
0.99062
ut‚àí1
0.209089
1
0.78644
rt‚àí1
0.005044
0.0668
1
œÄt‚àí2
1
0.041689
0.78473
ut‚àí2
0.163756
1
0.78473
rt‚àí2
0.007133
0.040356
0.046889
œÄt‚àí3
0.0396
0.045089
0.180644
ut‚àí3
0.039133
0.055067
0.083978
rt‚àí3
0.004489
0.817
0.547133
œÄt‚àí4
0.014733
0.057511
0.152489
ut‚àí4
0.030556
0.0406
0.122422
rt‚àí4
0.004244
0.07311
0.037556
Table 1.3: Lag check2
œÄ0j = 0.6
œÄt
ut
rt
c
0.299644
0.99658
0.128133
œÄt‚àí1
1
0.017156
0.98989
ut‚àí1
0.202867
1
0.951
rt‚àí1
0.009511
0.049978
1
œÄt‚àí2
1
0.0162
0.7812
ut‚àí2
0.086553
0.9672
0.9286
rt‚àí2
0.015333
0.0338
0.046511
œÄt‚àí3
0.046911
0.067889
0.180244
ut‚àí3
0.089156
0.094422
0.112422
rt‚àí3
0.0096
0.83849
0.78979
œÄt‚àí4
0.02644
0.0746
0.217378
ut‚àí4
0.053822
0.030222
0.140511
rt‚àí4
0.011711
0.071578
0.040956
Table 1.4: Lag check3
26

œÄ0j = 0.65
œÄt
ut
rt
c
0.4738
0.99347
0.160111
œÄt‚àí1
1
0.022978
0.98916
ut‚àí1
0.417044
1
0.9962
rt‚àí1
0.010889
0.073869
1
œÄt‚àí2
1
0.034956
0.79469
ut‚àí2
0.241578
1
0.9668
rt‚àí2
0.013289
0.068956
0.058978
œÄt‚àí3
0.057911
0.043311
0.212667
ut‚àí3
0.098689
0.074711
0.198711
rt‚àí3
0.007244
0.8608
0.68487
œÄt‚àí4
0.027556
0.042622
0.204711
ut‚àí4
0.097222
0.037644
0.2132
rt‚àí4
0.008511
0.068667
0.073844
Table 1.5: Lag check4
œÄ0j = 0.7
œÄt
ut
rt
c
0.674244
0.98831
0.220867
œÄt‚àí1
1
0.03444
0.97342
ut‚àí1
0.72776
1
0.78644
rt‚àí1
0.010711
0.080044
1
œÄt‚àí2
1
0.038022
0.7376
ut‚àí2
0.504911
1
0.92064
rt‚àí2
0.010889
0.104978
0.07422
œÄt‚àí3
0.052822
0.041067
0.222467
ut‚àí3
0.149333
0.061311
0.210133
rt‚àí3
0.008222
0.88473
0.74669
œÄt‚àí4
0.035867
0.040178
0.230178
ut‚àí4
0.181156
0.030689
0.287578
rt‚àí4
0.009378
0.0838
0.060111
Table 1.6: Lag check5
27

œÄ0j = 0.75
œÄt
ut
rt
c
0.676533
0.99118
0.238756
œÄt‚àí1
1
0.0366
0.99551
ut‚àí1
0.6782
1
0.98373
rt‚àí1
0.018956
0.101644
1
œÄt‚àí2
1
0.54556
0.78229
ut‚àí2
0.344467
0.9658
0.9364
rt‚àí2
0.014333
0.085689
0.105933
œÄt‚àí3
0.067822
0.063178
0.344244
ut‚àí3
0.241533
0.126867
0.250044
rt‚àí3
0.0118
0.85351
0.746289
œÄt‚àí4
0.034489
0.0628
0.302933
ut‚àí4
0.159533
0.063089
0.346
rt‚àí4
0.009822
0.092244
0.096644
Table 1.7: Lag check6
œÄ0 j ‚àºU (0,1)
œÄt
ut
rt
c
0.020733
0.99653
0.013222
œÄt‚àí1
1
0.009
0.96131
ut‚àí1
0.037489
1
0.96469
rt‚àí1
0.000956
0.023689
1
œÄt‚àí2
1
0.062667
0.63662
ut‚àí2
0.035689
0.94331
0.84693
rt‚àí2
0.014289
0.111756
0.000778
œÄt‚àí3
0.000956
0.036289
0.349956
ut‚àí3
0.001578
0.9794
0.174378
rt‚àí3
0.002978
0.151089
0.8954
œÄt‚àí4
0.025911
0.529983
0.424889
ut‚àí4
0.6608
0.279311
0.117289
rt‚àí4
0.001289
0.263667
0.059067
Table 1.8: Lag check7
28

œÄ0j = 0.5
œÄt
ut
rt
c
0.1501
0.999
0.0994
œÄt‚àí1
1
0.0099
0.9816
ut‚àí1
0.0094
1
1
rt‚àí1
0.0031
0.1093
1
œÄt‚àí2
1
0.0074
0.7273
ut‚àí2
0.0082
1
1
rt‚àí2
0.0042
0.116
0.0323
œÄt‚àí3
0.0314
0.0105
0.2294
ut‚àí3
0.0082
0.0145
0.0528
rt‚àí3
0.0022
0.8137
0.8235
Table 1.9: Lag check8
œÄ0j = 0.5
œÄt
ut
rt
c
0.1152
0.9789
0.0984
œÄt‚àí1
1
0.1765
0.9918
ut‚àí1
0.0124
1
1
rt‚àí1
0.0023
0.1378
1
œÄt‚àí2
1
0.149
0.6464
ut‚àí2
0.0096
1
1
rt‚àí2
0.0062
0.5454
0.0872
Table 1.10: Lag check9
29

œÄ0j = 0.5
œÄt
ut
rt
ct
1
0.4620
0.9550
œÄt‚àí1
1
0.2170
0.9460
ut‚àí1
1
1
1
rt‚àí1
0.3250
0.0370
1
œÄt‚àí2
1
0.8810
0.7050
ut‚àí2
1
1
1
rt‚àí2
0.3430
0
1
Table 1.11: Lags in model 2
vidually. We shall come back to them in the next subsections when discussing possible structrual
changes in agents‚Äô behavior and monetary policy implementation.
1.4.3
Impulse responses
Next, let‚Äôs check impulse responses. First, we compare impulse responses of unrestriced Bayesian
VAR with static SVS-BVAR of model 1. The unrestricted Bayesian VAR is equivalent to setting
prior that all parameters are in the model with probability of one in terms of SVS-BVAR. All
parameters in SVS-BVAR are set with prior probability of 50%.
Recursive identiÔ¨Åcation of exogenous monetary policy shocks is used in which short rate is
placed in the last order such that inÔ¨Çation and unemployment rate can impact policy immediately
while policy rate affect them with one lag. The size of monetary shock is normalized to one
percentage.
The result shows that in the Ô¨Årst several periods, for unrestriced model, responses of unem-
ployment rate get down, which contracts with economic theory and unsurprisingly, typically seen
in small scale monetary VAR literature. However, when stochastic selection is imposed, it im-
proves completely, getting rise directly after lags of 3 periods due to the infÔ¨Çuence of irrelevant
variables alleviated by stochastic selection. Interest rate response to inÔ¨Çation in unrestricted model
is modest, after around 5 periods starting above 1, then gradually get down to zero around the 21st
period. Responses of interest rate in model with stochastic selection, are quite strong, until after
24 periods, it still stays close to 2 at median, which means in a long run respect Taylor rule is very
30

powerful that‚Äôs different with the result for unrestricted model.9
Now let‚Äôs look at impulse responses (IRs hereafter) of variables to monetary policy shocks in
model 2 and model 3. Both models are imposed with multivariate stochastic volatility in order to
jointly analyze systematic and non-systematic changes. Time variation of coefÔ¨Åcients on regressors
and stochastic volatility have extended the IRs with dynamic property over time as opposed to static
model 1.
We randomly choose three period 1975 Q1, 1981 Q3 and 1996 Q1 to represent three chairman-
ships respectively. Figure 1.2, corresponding to model 3, shows the impulse response functions
of inÔ¨Çation, unemployment and three month short rate to one percentage monetary policy shock,
with solid line representing median, dashed lines 16th and 84th percentile respectively of posterior
IR distribution. All the responses perfectly satisfy economic theory. There are no price puzzle typ-
ically seen in a small scale monetary VAR which can be weakened after adding forward looking
prices or using large data set (Bernanke et al., 2005); Unemployment rates also increase quickly
under contracting monetary policy. All the responses under recursive identiÔ¨Åcation are in line with
that under agnostic identiÔ¨Åcation of sign restriction of Uhlig (2005). If comparing the same re-
sponses with that under model 2, in Figure 1.1, and unrestricted TVP-VAR, we Ô¨Ånd that there are
‚Äòprice puzzle‚Äô and ‚Äòunemployment abnormal‚Äô, though no longer signiÔ¨Åcant in model 2 ‚Äì the sim-
ilar improvement in rich data set model such as factor augmented models, but seldom completely
diminishing. This means that even though in a small scale VAR model, however, with coefÔ¨Åcient
restrictions, we can still obtain theory consistent results that are difÔ¨Åcult without restriction. On the
other hand, we also Ô¨Ånd error bands of IRs for model 3 in Figure 1.2 have substantially narrowed as
opposed to those of IRs for model 2 in Figure 1.1. A reasonable explanation for this is that model
3 has restrictions both over identity and time, while model 2 not allowed for time dimension.
9Since the static typical small scale VAR is widely analysed, we do not provide Ô¨Ågues for the save of space.
31

1.4.4
Systematic or exogenous change
An important thing we need to consider in monetary policy issue is that there might be structural
changes in monetary policy with different chairmanships of Burns, Volcker and Greenspan, though
some believe, some not. Related literature has given large number of evidence about this issue,
though until now such dispute still exists there in theoretical and empirical study and this one
sometimes more or less associated with other topics like sources or causes of the Great InÔ¨Çation
or the Great Moderation. One thing we need to conÔ¨Årm is that generally there are two periods
suitable for monetary policy test. One is from 1963 Q1 to 1973 Q3 corresponding approximately
to the period of rising inÔ¨Çation before the Volcker chairmanship. The period 1982 Q4 to 2006
Q3 corresponds to the Volcker and Greenspan chairmanships excluding the years of Monetary
Targeting, for which the Taylor rule might not represent an appropriate description of systematic
monetary policy (see, for instance, Hanson, 2006; Sims and Zha, 2006).
Recently, time varying parameter VAR with stochastic volatility (see, among many other, Cog-
ley and Sargent, 2005; Cogley, Primiceri, and Sargent, 2010; Koop, Leon-Gonzalez, and Strachan,
2009; Koop and Korobilis, 2013) has been widely used in empirical analysis in business cycle, pol-
icy change, forecast and so on, because this kind of models can capture time variation properties
of coefÔ¨Åcient and volatility that probably reÔ¨Çect structural changes in a gradual manner rather than
abrupt one like Markov regime switch model with probability or threshold regime switch model
when threshold variable is above or below threshold value. On the other hand, SV can investigate
some potential exogenous or non-systematic changes during sample period that is not capable for
model without SV. However, these TVP models all associate with parameter proliferation problem
due to the extension of parameters to time dimension even if in a small scale VAR, which might
give incorrect properties and possible wrong inferences. Therefore, TVP-VAR with stochastic
variable selection is a good tool to analyze such problems relevant with systematic changes via
time varying coefÔ¨Åcients and non-systematic changes via stochastic volatility.
32

1.4.4.1
Agents bahavior to monetary shocks
We investigate whether structure has changed in the agents‚Äô behavior to monetary policy shocks.
The magnitude of monetary policy is standardized to one percentage in each period. We compare
the difference among these three periods mentioned above.
Intuitively, in Figure 1.1 and Figure 1.2, IRs of inÔ¨Çation and unemployment did not seem
change much. However, we need a way to precisely estimate the difference. Following Primiceri
(2005) and others, we compute the difference of IRs between every two periods mutually among
the three periods in every iteration after burin-in during Bayesian estimation and therefore obtain
the posterior distribution of the IR difference .
Figure 1.3 and Figure 1.4, for model 3, show that there are no signiÔ¨Åcant differences between
these periods no matter for response of inÔ¨Çation or unemployment, because they are all insigniÔ¨Å-
cant with zero line. This means that economic agents have not altered their behavior and hence no
structure changes in the agents in response to non systematic monetary policy shocks. The same
results can also be found in model 2, see Figure 1.5 and Figure 1.6, and in unrestricted TVP-VAR,
but with larger error band compared with model 3 for the reason we have discussed before.10
Since arbitrarily picking up three periods, we can not guarantee that the ‚ÄòinsigniÔ¨Åcant change
in agent behavior‚Äô always hold during the whole sample period. The 3-D impulse responses of
inÔ¨Çation and unemployment rate over the whole period respectively, in Figure 1.8 for model 3, are
given, showing that it is reasonable to believe that economic agents keep the same way in decision
making. Figure 1.7 for model 2 also support this conclusion with impuse responses appearing
more smooth.
1.4.4.2
Systematic monetary policy
We check if the implementation of monetary policy has changed. Long run response of policy
rate to inÔ¨Çation shocks and unemployment shocks is used to represent monetary policy stance.11
10For saving space, we do not give Ô¨Ågures for unrestricted TVP-VAR from which they deliver the results in line
with the literature.
11In standard New Keynesian DSGE models, the monetary policy rule follows this similar type:
33

3
6
9
12 15 18 21
‚àí2
‚àí1
0
1
IR of inflation, 1975:Q1
3
6
9
12 15 18 21
‚àí4
‚àí2
0
2
4
IR of unemployment, 1975:Q1
3
6
9
12 15 18 21
‚àí4
‚àí2
0
2
4
IR of interest rate, 1975:Q1
3
6
9
12 15 18 21
‚àí2
‚àí1
0
1
IR of inflation, 1981:Q3
3
6
9
12 15 18 21
‚àí4
‚àí2
0
2
4
IR of unemployment, 1981:Q3
3
6
9
12 15 18 21
‚àí4
‚àí2
0
2
4
IR of interest rate, 1981:Q3
3
6
9
12 15 18 21
‚àí2
‚àí1
0
1
IR of inflation, 1996:Q1
3
6
9
12 15 18 21
‚àí4
‚àí2
0
2
4
IR of unemployment, 1996:Q1
3
6
9
12 15 18 21
‚àí4
‚àí2
0
2
4
IR of interest rate, 1996:Q1
Figure 1.1: IRs for model 2
Notes: The model 2 is SVS-Partial-TVP-VAR with SV. The Ô¨Årst column plots impulse responses
of inÔ¨Çation to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The second column
plots impulse responses of unemployment rate to monetary policy shocks in 1975 Q1, 1981 Q3
and 1996 Q1. The third column plots impulse responses of interst rate to monetary policy shocks
in 1975 Q1, 1981 Q3 and 1996 Q1. Solid line represents posterior median of impluse response
distribution with dashed lines of 16th percentile and 84th percentile, respectively.
34

3
6
9 12 15 18 21
‚àí0.5
0
0.5
IR of inflation, 1975:Q1
3
6
9 12 15 18 21
‚àí0.2
0
0.2
IR of unemployment, 1975:Q1
3
6
9 12 15 18 21
‚àí1
0
1
2
IR of interest rate, 1975:Q1
3
6
9 12 15 18 21
‚àí0.5
0
0.5
IR of inflation, 1981:Q3
3
6
9 12 15 18 21
‚àí0.2
0
0.2
IR of unemployment, 1981:Q3
3
6
9 12 15 18 21
‚àí1
0
1
2
IR of interest rate, 1981:Q3
3
6
9 12 15 18 21
‚àí0.5
0
0.5
IR of inflation, 1996:Q1
3
6
9 12 15 18 21
‚àí0.2
0
0.2
IR of unemployment, 1996:Q1
3
6
9 12 15 18 21
‚àí0.5
0
0.5
1
IR of interest rate, 1996:Q1
Figure 1.2: IRs for model 3
Notes: The model 3 is SVS-Full-TVP-VAR with SV. The Ô¨Årst column plots impulse responses of
inÔ¨Çation to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The second column plots
impulse responses of unemployment rate to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996
Q1. The third column plots impulse responses of interst rate to monetary policy shocks in 1975
Q1, 1981 Q3 and 1996 Q1. Solid line represents posterior median of impluse response distribution
with dashed lines of 16th percentile and 84th percentile, respectively.
35

3
6
9
12
15
18
21
‚àí0.4
‚àí0.3
‚àí0.2
‚àí0.1
0
median IR of inflation to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.06
‚àí0.04
‚àí0.02
0
0.02
0.04
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
1996 Q1‚àí1975 Q1
Figure 1.3: IR-inÔ¨Çation-comparison for model 3
Notes: The model 3 is SVS-Full-TVP-VAR with SV. The upper left panel plots median impulse
responses of inÔ¨Çation to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remain-
ing three panels plot difference of responses between every two periods mutually, with solid line
representing median and dashed lines for 16th percentile and 84th percentile respectively.
36

3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
0.06
0.08
IR of unemployment to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.06
‚àí0.04
‚àí0.02
0
0.02
0.04
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
1996 Q1‚àí1975 Q1
Figure 1.4: IRs-unemployment rate-comparison for model 3
Notes: The model 3 is SVS-Full-TVP-VAR with SV. The upper left panel plots median impulse
responses of unemployment rate to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1.
The remaining three panels plot difference of responses between every two periods mutually, with
solid line representing median and dashed lines for 16th percentile and 84th percentile respectively.
37

3
6
9
12
15
18
21
‚àí1
‚àí0.8
‚àí0.6
‚àí0.4
‚àí0.2
0
median IR of inflation to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.2
‚àí0.1
0
0.1
0.2
0.3
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.4
‚àí0.2
0
0.2
0.4
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.4
‚àí0.2
0
0.2
0.4
0.6
1996 Q1‚àí1975 Q1
Figure 1.5: IRs-inÔ¨Çation-comparison for model 2
Notes: The model 2 is SVS-Partial-TVP-VAR with SV. The upper left panel plots median impulse
responses of inÔ¨Çation to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remain-
ing three panels plot difference of responses between every two periods mutually, with solid line
representing median and dashed lines for 16th percentile and 84th percentile respectively.
38

3
6
9
12
15
18
21
‚àí0.5
0
0.5
1
1.5
IR of unemployment to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.4
‚àí0.2
0
0.2
0.4
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
1
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
1
1996 Q1‚àí1975 Q1
Figure 1.6: IRs-unemployment rate-comparison for model 2
Notes: The model 2 is SVS-Partial-TVP-VAR with SV. The upper left panel plots median impulse
responses of unemployment rate to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1.
The remaining three panels plot difference of responses between every two periods mutually, with
solid line representing median and dashed lines for 16th percentile and 84th percentile respectively.
39

1965 1970 1975 1980 1985 1990 1995 2000 2005
5
10
15
20
‚àí0.8
‚àí0.6
‚àí0.4
‚àí0.2
Impulse Responses of Inflation to Monetary Policy Shock, 3D
1965 1970 1975 1980 1985 1990 1995 2000 2005
5
10
15
20
0
0.5
1
Impulse Responses of Unemployment to Monetary Policy Shock, 3D
Figure 1.7: 3D-IRs for model 2
Notes: The model 2 is SVS-Partial-TVP-VAR with SV. The upper panel plots median impulse
responses of inÔ¨Çation to monetary policy shocks over the whole sample period. The lower panel
plots median impulse responses of unemployment rate to monetary policy shocks over the whole
sample period.
40

1965 1970 1975 1980 1985 1990 1995 2000 2005
5
10
15
20
‚àí0.3
‚àí0.2
‚àí0.1
0
Impulse Responses of Inflation to Monetary Policy Shock, 3D
1965 1970 1975 1980 1985 1990 1995 2000 2005
5
10
15
20
‚àí0.05
0
0.05
Impulse Responses of Unemployment to Monetary Policy Shock, 3D
Figure 1.8: 3D-IRs for model 3
Notes: The model 3 is SVS-Full-TVP-VAR with SV. The upper panel plots median impulse re-
sponses of inÔ¨Çation to monetary policy shocks over the whole sample period. The lower panel
plots median impulse responses of unemployment rate to monetary policy shocks over the whole
sample period.
41

Responses for 5 quarters, 10 quaters and 15 quarters are examined for policy strength.
We Ô¨Årst look at policy response to inÔ¨Çation shock. In Figure 1.9, we Ô¨Ånd that around after
middle 1970s, policy sensitivity to inÔ¨Çation has increased after 5 quaters, 10 quaters and 15 quaters,
but not signiÔ¨Åcant with a line always through the whole error band respectively. This line can be
above one or below one. Figure 1.10 have the same property, however, with very broad conÔ¨Ådence
band. Therefore, we can only reach that there are no signiÔ¨Åcant structural change in policy rule
which is consistent with Primiceri (2005) and Sims and Zha (2006).
Monetary reaction to unemployment shocks has signiÔ¨Åcantly enhanced after 5 quaters and 10
quaters, but become insigniÔ¨Åcant after 15 quaters in Figure 1.11 for model 3 over the sample
period. This Ô¨Ånding can not be captured in Figure 1.12 for model 2 as they are all not signiÔ¨Åcant.
Generally speaking, we can not conclude that policy stance to unemployment has signiÔ¨Åcantly
changed.
1.4.4.3
Non-systematic monetary policy shocks
The last panel of Figure 1.13 plots the dynamic process of stochastic volatility for nonsystematic
policy with narrow band for model 3. This path is well conÔ¨Årmed in the literature that the volatility
during era of the Great InÔ¨Çation is much higher than the episode of the Great Moderation, and
the Ô¨Çutuation in the period of monetary targeting of chairmanship of Volk is dramatically volatile.
Together with the previous analysis, we only Ô¨Ånd volatility of exogenous shocks have changed
substantially.
1.4.4.4
An interpretation
Altogether, even though with restricted TVP-VAR via stochastic variable selection in model 2 and
model 3, We still have the almost the same conclusion that there are no signiÔ¨Åcant switches in
agents‚Äô behavior and monetary policy stance, as opposed to which, exogenous shocks have altered
strongly.
rt = œÅrrt‚àí1 +(1‚àíœÅr)(œÅœÄœÄt +œÅyyt)+ŒµM
t
where long run response œÅœÄ and œÅy represent monetary policy stance.
42

1970
1980
1990
2000
0.5
1
1.5
inflation shock after 0Qs
1970
1980
1990
2000
0.6
0.8
1
1.2
1.4
1.6
1.8
inflation shock after 5Qs
1970
1980
1990
2000
0.8
1
1.2
1.4
1.6
inflation shock after 10Qs
1970
1980
1990
2000
0.6
0.8
1
1.2
1.4
inflation shock after 15Qs
Figure 1.9: Policy response to inÔ¨Çation for model 3
Notes: The model 3 is SVS-Full-TVP-VAR with SV. The upper left panel plots immediate im-
pulse responses of policy rate to inÔ¨Çation shocks over the whole sample period. The remaining
panels plot impulse responses of policy rate to inÔ¨Çation shocks in the 5th , 10th, and 15th period
respectively over the whole sample period.
43

1970
1980
1990
2000
0
0.1
0.2
0.3
0.4
0.5
inflation shock after 0Qs
1970
1980
1990
2000
0.5
1
1.5
inflation shock after 5Qs
1970
1980
1990
2000
‚àí0.5
0
0.5
1
1.5
2
inflation shock after 10Qs
1970
1980
1990
2000
‚àí1.5
‚àí1
‚àí0.5
0
0.5
1
inflation shock after 15Qs
Figure 1.10: Policy response to inÔ¨Çation for model 2
Notes: The model 2 is SVS-Partial-TVP-VAR with SV. The upper left panel plots immediate
impulse responses of policy rate to inÔ¨Çation shocks over the whole sample period. The remaining
panels plot impulse responses of policy rate to inÔ¨Çation shocks in the 5th , 10th, and 15th period
respectively over the whole sample period.
44

1970
1980
1990
2000
‚àí2
‚àí1.5
‚àí1
‚àí0.5
unemployment shock after 0Qs
1970
1980
1990
2000
‚àí2
‚àí1.5
‚àí1
‚àí0.5
unemployment shock after 5Qs
1970
1980
1990
2000
‚àí1.5
‚àí1
‚àí0.5
unemployment shock after 10Qs
1970
1980
1990
2000
‚àí1.2
‚àí1
‚àí0.8
‚àí0.6
‚àí0.4
‚àí0.2
unemployment shock after 15Qs
Figure 1.11: Policy response to unemployment rate for model 3
Notes: The model 3 is SVS-Full-TVP-VAR with SV. The upper left panel plots immediate impulse
responses of policy rate to unemployment rate shocks over the whole sample period. The remaining
panels plot impulse responses of policy rate to unemployment rate shocks in the 5th , 10th, and 15th
period respectively over the whole sample period.
45

1970
1980
1990
2000
‚àí1
‚àí0.8
‚àí0.6
‚àí0.4
unemployment shock after 0Qs
1970
1980
1990
2000
‚àí3.5
‚àí3
‚àí2.5
‚àí2
‚àí1.5
unemployment shock after 5Qs
1970
1980
1990
2000
‚àí3
‚àí2
‚àí1
0
1
unemployment shock after 10Qs
1970
1980
1990
2000
‚àí2
‚àí1
0
1
2
3
unemployment shock after 15Qs
Figure 1.12: Policy response to unemployment rate for model 2
Notes: The model 2 is SVS-Partial-TVP-VAR with SV. The upper left panel plots immediate
impulse responses of policy rate to unemplyment rate shocks over the whole sample period. The
remaining panels plot impulse responses of policy rate to unemployment rate shocks in the 5th ,
10th, and 15th period respectively over the whole sample period.
46

1965
1970
1975
1980
1985
1990
1995
2000
2005
0.2
0.4
0.6
0.8
Posterior median of the standard deviation of residuals in Inflation equation
1965
1970
1975
1980
1985
1990
1995
2000
2005
0.2
0.4
0.6
0.8
1
Posterior median of the standard deviation of residuals in Unemployment equation
1965
1970
1975
1980
1985
1990
1995
2000
2005
0.5
1
1.5
2
2.5
Posterior median of the standard deviation of residuals in Interest Rate equation
Figure 1.13: Volatility for each variable in model 3
47

A possible reason we believe is that although restricted TVP-VAR of model 2 and model 3,
especially for model 3, have signiÔ¨Åcantly improved the parameter proliÔ¨Åcation problem and re-
duced uncertainty, but this merit is not strong enough to overturn the view of stability of structures
existing both in economic agents and policy authority. The prior probability for each coefÔ¨Åcient
in each equation is set to œÄ0jt = 0.5. Fig 1.14 to Fig 1.16 shows the posterior signiÔ¨Åcance of each
coefÔ¨Åcient along the sample period. Two points can be found that Ô¨Årst, variables always react to
its own Ô¨Årst lag with probability of one, and then become week around 50% with special case for
inÔ¨Çation (equation 1) where it also strongly response to its own lag 2 during some periods of the
Great InÔ¨Çation and money base targeting; Second, other lags, no matter domestic or foreign, Ô¨Çuc-
tuate with the mild and relatively the same magnitude around half percentage. These two points
are consistent with empirical literature such as settings of shrinkage priors ( for example, the Min-
nesota prior, see Doan, Litterman and Sims, 1984, Litterman, 1986 and its extension, see Banbura,
Giannone and Reichlin, 2010, among others).
From these Ô¨Ågures, there is no prominent jump of probability, except for their own lags, for
each coefÔ¨Åcient in each equation over sample period. That is, every coefÔ¨Åcient always plays almost
the same (relative) importance in this system. Structural change needs abrupt shift and keep it for
a period or gradual increase or decease to over some critical threshold point. We can not Ô¨Ånd such
style in these Ô¨Ågures.
1.5
Robust check
Every TVP-VAR model has the nature that its latent state coefÔ¨Åcients have to change or break
every period due to its transition equation dynamics and this change has to be smoothed because
of the backward recursion as described in Carter and Kohn (1994) in estimation after observing all
the data. Hence there is a situation in which some state variables of small variations will more or
less take over and narrow down the weight originally played by those of large variation in order
to make the estimation smooth. Under such kind of operation, Primiceri (2005) discussed this
48

1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
policy rule c/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
inf‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
u‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0.6
0.8
1
r‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
inf‚àí2/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
u‚àí2/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
r‚àí2/%
Figure 1.14: Posterior probability for each coefÔ¨Åcient in policy rule
49

1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
eq1 c/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0.6
0.8
1
inf‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
u‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
r‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
inf‚àí2/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0.4
0.6
0.8
u‚àí2/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
r‚àí2/%
Figure 1.15: Posterior probability of each coefÔ¨Åcient in inÔ¨Çation equation
50

1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
eq2 c/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
inf‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0.6
0.8
1
u‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
r‚àí1/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
inf‚àí2/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
u‚àí2/%
1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.5
1
r‚àí2/%
Figure 1.16: Poterior probability of coefÔ¨Åcient in unemployment rate equation
51

concern. In this case, misleading could take place and this is potential missing in the proof via Fig
1.14 to Fig1.16 deriving from model 3 with also such kind of smoothness operation. Probably it is
one reason for Sims and Zha (2006) to choose Markov regime switch models to detect structural
changes occurring in an economy.
The above concern motivates the aim of the robust check in this section. Given that large scale
breaks have high potential to be candidates of systematic changes while non-large-breaks not,
then naturally, designing models good at being able to seize large breaks and meanwhile defense
inÔ¨Çuence from not large variations is a necessary direction. Stepping further, if we still can not
Ô¨Ånd systematic change under the large beak, it implies that it‚Äôs more impossible to infer structural
alterations in other non-large-break periods, because these non-large-breaks are more less qualiÔ¨Åed
to be considered as possible structural switches. This deletes the above concern, complements and
closes the proof that the TVP-VAR system is stable for the data set. Therefore there were no
structural changes in monetary policy and economic behavior, and exogenous shocks naturally
play the role of accounting for the empirical dynamic difference between the ‚ÄòGreat InÔ¨Çation‚Äô and
the ‚ÄòGreat Moderation‚Äô .
Recently, following Bauwens, Koop, Korobilis and Rombouts (2014), Korobilis (2013b) de-
velop a TVP-VAR model involving discrete Markov process used for forecasting. We use this
model to do our robust check.
The basic idea is that the latent coefÔ¨Åcients in this TVP model are subject to several possible
regime states which follows Markov process, meaning the regime ‚Äì the corresponding coefÔ¨Åcient
‚Äì is not necessary to move every period. The model is formulated as follows modiÔ¨Åed on the
previous TVP models:
yt = ZtŒ∏st +Œµt
(1.14)
Œ∏st = ŒìŒ≤st
(1.15)
52

Œ≤st = Œ≤st‚àí1 +ut
(1.16)
where Œµt ‚àºN (0,R), ut ‚àºN (0,Q) and st ‚àà[1,...,M +1] is Markov process of order one with block
diagonal transition matrix of the form
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
p11
p12
0
¬∑¬∑¬∑
0
0
p22
p23
...
...
...
...
...
...
0
0
pMM
pM,M+1
0
¬∑¬∑¬∑
0
0
pM+1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
This model speciÔ¨Åes there is a break between t and t + 1, namely Œ≤st+1 Ã∏= Œ≤st due to ut Ã∏= 0 if
only if st Ã∏= st+1, otherwise Œ≤st+1 = Œ≤st and the state process st only goes forward and never comes
back without memory.12 This deÔ¨Ånes the new transition equation. Not every Œ≤st is time varying,
only when regime switch happens that does deserve. In other words, not always, only the limited
variations in Œ≤stuniquely correspond to several large breaks (herein M breaks) that have relatively
more importance than other non-large-breaks in the data set.
The assumption of regime switching ‚Äòwithout memory‚Äô (the block diagonal transition matrix)
seems very strong, probably not in line with empirical evidence, but it is very suitable for us to
detect large breaks ‚Äì the candidates of structural changes ‚Äì in posterior respect meanwhile Ô¨Åltering
out small variation not qualiÔ¨Åed as ‚Äòbreaks‚Äô that however always involved in TVP models causing
potential contamination of inference. In a word, the model only paying attention to large breaks
has been already sufÔ¨Åcient for us to Ô¨Ånd large breaks.
We priorly set two breaks, namely three regimes for U.S. sample set.13 Fig 1.17 plots the
posterior probability for each regime. It is evident that only two regimes, regime 1 and regime 2
12The ‚Äònever comes back without memory‚Äô is based on the idea that it is reasonable to regard it as a ‚Äònew break‚Äô
if ut is large enough and also on compatibility of estimation after incorporating discrete Markov (regime switching)
process into TVP models for smoother part, which can be found in the appendix of Bayesian estimation of the model.
13We also tried three breaks but denied by the data.
53

1965
1970
1975
1980
1985
1990
1995
2000
2005
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Probability for each regime
 
 
regime 1
regime 2
regime 3
Figure 1.17: Posterior probability of each regime
are strongly supported by the data. For regime 3, it is zero percentage before around 2003, after that
2% signiÔ¨Åcantly denied by the data. Now let‚Äôs look at the dynamic relationship between regime 1
and regime 2. Regime 1 strongly dominated with posterior probability of value one before the end
of 1980s, then after cross point around 1981, the regime 2 took the place of regime 1 dramatically
climbing up to probability near one till the end of 2006 Q2 with the trivial role of regime 3 of
extremely low level support. The information showing up in Fig 1.17 is not surprising, conforming
with the literature that the year of 1981, among monetary targeting project in the chairmanship of
Volcker, is the threshold point that divides the sample into two regimes. The property of TVP-VAR
with regime switching that is able to pick up large breaks clearly catch the signiÔ¨Åcant switch of
monetary policy.14
14Note that the TVP-VAR with regime switch in this paper does not belong to the category of conventional state
space models with regime switching in which regime switch occurs on parameters. See chapter 10 of Kim and Nelson
(1999).
54

Has the economy changed before and after monetary targeting policy in the aim to attacking
high inÔ¨Çation? Fig 1.18 and Fig 1.19 give the ‚ÄòNO‚Äô answer. Take regime 3 into account, though
it is trivial, to give a full piture. Differences among these three regimes for reactions of inÔ¨Çation
and unemployment to monetary policy shocks are not signiÔ¨Åcant with zero, which is in line with
Ô¨Åndings from Model 2 and Model 3. Monetary policy stance is also investigated. In Fig 1.20,
in response to inÔ¨Çation shocks, the Fed‚Äôs reaction had no signiÔ¨Åcant differences during every two
regimes, no matter in short run or long run. The same result is also found in response to unem-
ployment shocks in Fig 1.21. Altogether, there were no systematic changes in Monetary policy
and agents‚Äô behavior.
Since in large breaks systematic changes are not found, the concern in model 2 and model 3
about possible inÔ¨Çuence of small variation on large variation is neglectable.
1.6
Concluding remarks
In this paper, we present models for dealing with the problem of parameter proliferation ‚Äì as-
sociated with potential incorrect inferences ‚Äì in VAR models (under usual limited data access).
They are static SVS-BVAR (Model 1), SVS-Partial-TVP-VAR (Model 2) and SVS-Full-TVP-VAR
(Model 3). For the latter two models, I incorporate multivariate SV so as to investigate systematic
and non-systematic changes jointly. Actually, the three models are consistent each other; Model
1 and Model 2 are special cases of Model 3 after relaxing some restrictions, as we discussed in
section 2.
With these models and U.S. quarterly data, we analyzed whether there were systematic switches
in U.S monetary stance and economic agents‚Äô behavior. After investigating long run responses of
policy rate to inÔ¨Çation and unemployment shocks, respectively, we Ô¨Ånd that there were insignif-
icant changes in systematic monetary policy along the whole sample period. We also evaluated
agents‚Äô behavior examined by monetary policy shocks in three arbitrary periods, then extended to
all the sample period and still no signiÔ¨Åcant responses were found. We payed more attention on
55

3
6
9
12
15
18
21
‚àí0.05
0
0.05
0.1
0.15
IRs of inflation to MP shocks
 
 
regime 1
regime 2
regime 3
3
6
9
12
15
18
21
‚àí0.15
‚àí0.1
‚àí0.05
0
0.05
regime 2 ‚àí regime 1
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
regime 3 ‚àí regime 2
3
6
9
12
15
18
21
‚àí0.2
‚àí0.1
0
0.1
0.2
regime 3 ‚àí regime 1
Figure 1.18: IRs of inÔ¨Çation and their difference between different regimes
Notes: The upper left panel plots median impulse responses of inÔ¨Çation to monetary policy shocks
in regime 1, regime 2, and regime 3. The remaining three panels plot difference of responses
between every two regimes mutually, with solid line representing median and dashed lines for 16th
percentile and 84th percentile respectively.
56

3
6
9
12
15
18
21
‚àí0.05
0
0.05
0.1
0.15
IRs of unemployment to MP shocks
 
 
regime 1
regime 2
regime 3
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
regime 2 ‚àí regime 1
3
6
9
12
15
18
21
‚àí0.1
0
0.1
0.2
0.3
regime 3 ‚àí regime 2
3
6
9
12
15
18
21
‚àí0.1
0
0.1
0.2
0.3
regime 3 ‚àí regime 1
Figure 1.19: IRs of unemployment rate and their difference between different regimes
Notes: The upper left panel plots median impulse responses of unemployment rate to monetary
policy shocks in regime 1, regime 2, and regime 3. The remaining three panels plot difference of
responses between every two regimes mutually, with solid line representing median and dashed
lines for 16th percentile and 84th percentile respectively.
57

3
6
9
12
15
18
21
0
0.5
1
1.5
IRs of interest rate to Inflation shocks
 
 
regime 1
regime 2
regime 3
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
1
regime 2 ‚àí regime 1
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
regime 3 ‚àí regime 2
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
1
regime 3 ‚àí regime 1
Figure 1.20: IRs of interest rate to inÔ¨Çation shocks
Notes: The upper left panel plots median impulse responses of interest rate to inÔ¨Çation shocks
in regime 1, regime 2, and regime 3. The remaining three panels plot difference of responses
between every two regimes mutually, with solid line representing median and dashed lines for 16th
percentile and 84th percentile respectively.
58

3
6
9
12
15
18
21
‚àí3
‚àí2
‚àí1
0
IRs of interest rate to unemployment shocks
 
 
regime 1
regime 2
regime 3
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
regime 2 ‚àí regime 1
3
6
9
12
15
18
21
‚àí1
‚àí0.5
0
0.5
1
regime 3 ‚àí regime 2
3
6
9
12
15
18
21
‚àí2
‚àí1
0
1
regime 3 ‚àí regime 1
Figure 1.21: IRs of interest rate to unemployment shocks
Notes: The upper left panel plots median impulse responses of interest rate to unemployment
shocks in regime 1, regime 2, and regime 3. The remaining three panels plot difference of responses
between every two regimes mutually, with solid line representing median and dashed lines for 16th
percentile and 84th percentile respectively.
59

model 2 and model 3 due to their time variation property in tracking dynamic process. With the
model 2 of block checking and model 3 of single checking together, in case of possible missing
and misleading in model 2, We Ô¨Ånd insigniÔ¨Åcance alterations in behavior of both economic agents
and policy authority.
One thing worth noting is that Ô¨Ågures for model 3 indeed have seized some changes in the
policy implementation with obviously narrow error band as opposed to model 2, however, these
beneÔ¨Åts resulting from stochastic selection controlling signiÔ¨Åcance of each variable along time
period have not overturn the Ô¨Åndings in model 2. Posterior probability for every coefÔ¨Åcient over
time dimension delivers the plausible reason that except for its own lag of one, relative importance
of interaction among variables over time is generally stable that can be found from Fig 1.14 to Fig
1.16.
The concern that large variation can be weakened by small variation due to smoothness op-
eration in TVP-VAR estimation gives rise to sensitivity check via a modiÔ¨Åed TVP-VAR model
involved with discrete Markov process. We Ô¨Ånd the concern can be ignored. Hence it is believable
to conclude that since the system is indeed stable by statistical proof, the empirical dynamic change
before and after Volcker monetary targeting can only be attributed to exogenous shocks, not deter-
mined by the system. This conclusion consistent with Primiceri (2005) and Sims and Zha (2006).
On the other hand, the stability, namely the equality of relative importance of each variable in the
typical small scale monetary TVP-VAR system is not sensitive to the choice of models of parsimo-
nious restrictions, making the concern about over parameterization and smoothness typically seen
in TVP-VAR system neglectable.
In this sense, the value of the paper lies not only in examining and conÔ¨Årming one of views
in the literature using other different models, but also giving the underlying reason as well as
statistical proof why their view can still hold even though with more enriched models such as
stochastic variable selection models presented in this paper.
These models can apply to other topics like Ô¨Åscal policy change, Ô¨Ånancial market Ô¨Çuctuation
and so on that are left for our future research.
60

Appendix
A. The basic Kalman Ô¨Ålter and state smoother
Consider a typical state space model, ignoring the inÔ¨Çuence of exogenous variables15:
yt = XtŒ≤t +ut
(1.17)
Œ≤t = FŒ≤t‚àí1 +Œµt
(1.18)
where yt is an n √ó 1 observables, Xt is a n √ó k matrix of regressors, Œ≤t is a k √ó 1 unobserable
vector state following the dynamic process in (1.18); ut ‚àºN (0,Rt) and Œµt ‚àºN (0,Q) as well as
cov(ut,Œµs) = 0 for ‚àÄt and ‚àÄs. Usually, equation (1.17) is called measurement or observation equa-
tion and (1.18) the transition or evolution or state equation.
Denote Œ≤t|s and Vt|s conditional mean and conditional variance of Œ≤t based on information set
up to and including t, respectively. The forward Ô¨Ålter, with initial moments Œ≤0|0 and V0|0, consists
of two steps:
Prediction
Œ≤t|t‚àí1 = FŒ≤t‚àí1|t‚àí1
Vt|t‚àí1 = FVt‚àí1|t‚àí1F
‚Ä≤ +Q
Updating
Kt = Vt|t‚àí1X
‚Ä≤
t

XtVt|t‚àí1X
‚Ä≤
t +Rt
‚àí1
Œ≤t|t = Œ≤t|t‚àí1 +Kt
 yt ‚àíXtŒ≤t|t‚àí1

Vt|t = Vt|t‚àí1 ‚àíKtXtVt|t‚àí1
15Including exogenous variables in measurement equation and/or transition equation does not affect the derivation
of Kalman Ô¨Ålter and state smoother.
61

this process proceeds from t = 0 to t = T. At the conclusion of the forward recursion, draw Œ≤T
from N
 Œ≤T|T,VT|T

.
With Œ≤T regarded as observation, backward smoother starts from t = T ‚àí1 to t = 1 with
Œ≤t|t+1 = Œ≤t|t +Vt|tF‚Ä≤V ‚àí1
t+1|t
 Œ≤t+1 ‚àíFŒ≤t|t

Vt|t+1 = Vt|t ‚àíVt|tF‚Ä≤V ‚àí1
t|t+1FVt|t
then Œ≤t is drawn from posterior N
 Œ≤t|t+1,Vt|t+1

after observing all the data.
62

B. ModiÔ¨Åed Kalman Ô¨Ålter and state smoother with breaks
Consider a modiÔ¨Åed state space model
yt = XtŒ≤st +ut
Œ≤st = Œ≤st‚àí1 +Œµt
in which setting, the time varying coefÔ¨Åcients Œ≤t depend on latent state st that follows a discrete
Markov process. For details of the model speciÔ¨Åcation, please refer to section 5 in this chapter.
For the forward Ô¨Ålter part,
Œ≤t|t‚àí1 = Œ≤t‚àí1|t‚àí1
Vt|t‚àí1 =
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Vt‚àí1|t‚àí1 +Q
if st‚àí1 Ã∏= st
Vt‚àí1|t‚àí1
otherwise
Kt = Vt|t‚àí1X
‚Ä≤
t

XtVt|t‚àí1X
‚Ä≤
t +Rt
‚àí1
Œ≤t|t = Œ≤t|t‚àí1 +Kt
 yt ‚àíXtŒ≤t|t‚àí1

Vt|t = Vt|t‚àí1 ‚àíKtXtVt|t‚àí1
For the backward smoother part,
Œ≤t|t+1 =
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Œ≤t|t +Vt|tV ‚àí1
t+1|t
 Œ≤t+1 ‚àíŒ≤t|t

if st+1 Ã∏= st
Œ≤t|t
otherwise
Vt|t+1 =
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Vt|t ‚àíVt|tV ‚àí1
t|t+1Vt|t
if st+1 Ã∏= st
Vt|t
otherwise
63

C. Estimation of states without Kalman Ô¨Ålter and state smoother
Consider the general state space model in (1.17) and (1.18) in A1. Stack the two equations period
by period and collect all the data and states together, one obtains
y = XŒ≤ +u
(1.19)
where y =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
y1
...
yT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
, X =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
X1
¬∑¬∑¬∑
0
...
...
...
0
¬∑¬∑¬∑
XT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
, Œ≤ =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
Œ≤1
...
Œ≤T
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
, u =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
u1
...
uT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
,
with u ‚àºN (0,R) and R = Blkdiag

{Rt}T
t=1

.
The transition equation becomes
HŒ≤ = Œµ
(1.20)
where
H =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
Iq
F
Iq
F
Iq
...
F
Iq
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
and
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
Œµ1
...
ŒµT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
‚àºN (0,S) with
S =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
D
Q
Q
...
Q
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
64

and initial state Œ≤1 ‚àºN (0,D).
Equation (1.20) can be further written as
Œ≤ ‚àºN
 0,K‚àí1
(1.21)
with precision matrix K = H‚Ä≤S‚àí1H. (1.21) is regarded as the prior for Œ≤ constructed from the
structure of transition equation (1.18). Thus all the state varibles nested in Œ≤ can be drawn at a
time without forward Ô¨Åltering and backward smoothing:
Œ≤ ‚àºN( ¬ØŒ≤, ¬ØP‚àí1
Œ≤ )
with
¬ØPŒ≤ = X‚Ä≤R‚àí1X +K
¬ØŒ≤ = ¬ØP‚àí1
Œ≤
 X‚Ä≤R‚àí1y

Note that K and R are both block banded and sparse matrices, therefore so is ¬ØPŒ≤.
65

D. EfÔ¨Åcient estimation of SVS-Full-TVP-VAR
Consider a standard TVP-VAR with SV:
yt = ct +A1,tyt‚àí1 +¬∑¬∑¬∑+Ap,tyt‚àíp +ut
(1.22)
where yt is an n√ó1 vector of observed endogenous variables, ct is an n√ó1 vector of time varying
constants, {Ai,t}p
i=1 are n√ón matrices of time varying autoregressive parameters, and ut is an n√ó1
vector of shocks following normal distribution ut ‚àºN(0,Rt) , for t = 1,...,T. The Rt with SV has
the same structure as in the section 2.3 this chapter.
Let Œ≤t = vec([ct,A1,t,...Ap,t]
‚Ä≤) denote the vector of time varying parameters each period of
dimension k √ó 1, with k = n(1+np) and vec column stacking operator. The law of motion of Œ≤t
follows random walk process
Œ≤t = Œ≤t‚àí1 +Œµt
(1.23)
which is assumed that Œµt ‚àºN (0,Q).
Rewrite (1.22) into the form of
yt = XtŒ≤t +ut
(1.24)
where Xt = In  [1,y
‚Ä≤
t‚àí1,...y
‚Ä≤
t‚àíp], with  Kronecker product. Then stacking (1.24) over time to
pool all the data together, one obtains
y = XŒ≤ +u
where y =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
y1
...
yT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
, X =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
X1
¬∑¬∑¬∑
0
...
...
...
0
¬∑¬∑¬∑
XT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
, Œ≤ =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
Œ≤1
...
Œ≤T
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
, u =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
u1
...
uT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
,
with u ‚àºN (0,R) and R = Blkdiag

{Rt}T
t=1

.
The dynamic process of Œ≤t is also stacked into
HŒ≤ = Œµ
(1.25)
66

where
H =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
Iq
Iq
Iq
Iq
Iq
...
Iq
Iq
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
and
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞
Œµ1
...
ŒµT
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
‚àºN (0,S) with
S =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
D
Q
Q
...
Q
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
and initial state Œ≤1 ‚àºN (0,D).
From (1.25), the prior of whole states is distributed as
Œ≤ ‚àºNkT
 0,K‚àí1
with precision matrix K = H‚Ä≤S‚àí1H . The prior is derived from the random walk structure seen in
matrix H.
After above several steps of transformation, a stochastic variable selection TVP-VAR with SV
is Ô¨Ånally expressed as
y = XŒ∏ +u
(1.26)
Œ∏ = ŒìŒ≤
with prior Œ≤ ‚àºN
 0,K‚àí1
and Œì = diag

{Œìt}T
t=1

in which Œìt = diag
 Œ≥1,t,...,Œ≥k,t

. Apparently,
67

the large square matrix Œì contains all the indicators Œ≥j,t over identity and time corresponding to the
large column vectorŒ≤ stacking all the states Œ≤t.
The Bayesian estimation procedure is similar to the benchmark model of SVS-BVAR due to
the exclusion of Kalman forward Ô¨Åltering and backward smoothing. Here, the steps associated
with stochastic selection are given:
1. Draw Œ≤ from the posterior density
Œ≤ ‚àºNkT( ¬ØŒ≤, ¬ØP‚àí1
Œ≤ )
with
¬ØPŒ≤ = X‚ãÜ‚Ä≤R‚àí1X‚ãÜ+K
¬ØŒ≤ = ¬ØP‚àí1
Œ≤
 X‚ãÜ‚Ä≤R‚àí1y

and X‚ãÜ= XŒì.
2. Sample Œ≥l from the posterior density
Œ≥l ‚àºBernoulli(1, ¬ØœÄl)
where l = 1,...,kT, ¬ØœÄl =
l0l
l0l+l1l , with
l0l = p(y|Œ∏,Œ≥‚àíl,Œ≥l = 1)œÄ0l
and
l0l = p(y|Œ∏,Œ≥‚àíl,Œ≥l = 0)(1‚àíœÄ0l)
The expression p(y|Œ∏,Œ≥‚àíl,Œ≥l = 1) and p(y|Œ∏,Œ≥‚àíl,Œ≥l = 0) are conditional likelihood expres-
sions. Here we deÔ¨Åne Œ∏ ‚ãÜto be equal to Œ∏ but with the lth element Œ∏l = Œ≤l in the case of
Œ≥l = 1. Similarly, we deÔ¨Åne Œ∏ ‚ãÜ‚ãÜto be equal to Œ∏ but with the lth element Œ∏l = 0 when Œ≥l = 0.
68

Then in terms of likelihood of (1.26), we can write l0l, l1l analytically as
l0l = exp(‚àí1
2(y‚àíXŒ∏ ‚ãÜ)‚Ä≤R‚àí1(y‚àíXŒ∏ ‚ãÜ))œÄl
(1.27)
l1l = exp(‚àí1
2(y‚àíXŒ∏ ‚ãÜ‚ãÜ)‚Ä≤R‚àí1(y‚àíXŒ∏ ‚ãÜ‚ãÜ))(1‚àíœÄl)
(1.28)
Note that the order lth is randomly picked up, which is equivalent to assigning randomness
to both identity j and time t, for j = 1,...,k and t = 1,...,T, respectively.
3. Draw Rt with stochastic volatility that contains the same blocks and steps as in Primiceri
(2005) and Del Negro and Primiceri (2013) or De Wind and Gambetti (2014).
4. Go back to setp 1 again, start the next iteration.
69

Chapter 2
A General Parsimonious Estimation of
Time-varying Vector Autoregressions
70

2.1
Introduction
Since the pioneering work of Sims (1980), the vector autoregressive (VAR) models have become
popular and widely used in economic and policy analysis. The most importance of vector au-
toregressive models is that it provides a tool to analyse the dynamic relationship among multiple
macroeconomic variables by allowing all variables in a vector to response to all variables at all
lags, as in a economy practioners and economists not only care about the intertemporal relations,
but also focus on dynamic processes among macroeconomic variables which can lead them to con-
duct economic analyses and forecasting. Simplicity, tractability and properties of VARs such as
impulse response functions and variance decompotion make the original complicated problem of
exploring inter-relationship among different macro observations straightforward. Therefore, VAR
models gradually become more and more popular and dominate the empirical analysis in macroe-
conomics. For instance, researchers typically use VARs to Ô¨Ånd some empirical realities, then rely-
ing on these Ô¨Åndings to establish dynamic stochastic general equilibrium models (DSGE), trying
to interpret the underlying rationales.
Econometric models are always evolutionary with the requirement to converge as close as pos-
sible to economic reality. The U.S. economy has experienced the Great Depression ‚Äì the 1930s,
the Great InÔ¨Çation - 1970s and early 1980s, the Great Moderation from middle 1980s to 2006 that
most industrialized economies also have the similar experience, and recent the Great Recession
since the global Ô¨Ånancial crisis in 2008 and still on the way to the recovery. Except for the charac-
teristics of business cycles, the U.S. economy also has experienced four chairmanships of Federal
Reserve, Burns (1970-1978), Volker (1979-1987), Greenspan (1987-2006) and Bernanke (2006-
2014). Did they conduct the same monetary policy or not? What‚Äôs the relationship between their
policies and the alternations of the above mentioned business cycles? Besides monetary policy,
are there other factors inÔ¨Çuencing the business cycle and have these factors changed over different
economic stages? To answer such questions and issues require that the conventional assumption
of the constant coefÔ¨Åcients in VARs might be poor and have to be relaxed to be time varying. The
great decline in volatility ‚Äì the property of the Great Moderation ‚Äì in most macro-variables in the
71

U.S. and in most industrialized economies led to an increasing focus on appropiate modeling of
the error covariance matrix in VARs and this led to the incorporation of multivariate stochastic
volatility in many recent empirical papers. Hence, the time varying coefÔ¨Åcients on regressors and
stoachstic volatility on covariance matrix of forecast errors become the standard analysing tool
in applied macroeonomics. In model settings, from Cogley and Sargent (2001) with only time
variance on coefÔ¨Åcients on regressors, based on which, Cogley and Sargent (2005) extended the
early model to stochastic volatility on covariance matrix of forecast errors with some restrictions,
Ô¨Ånally Primiceri (2005) developed a model with sufÔ¨Åcient Ô¨Çexibility on all the parameters that can
be considered as the today‚Äôs standard TVP-VAR workhouse.
The time verying parameter VARs with stochastic volatility is not a parsimonious model. This
kind of model increase paramters dramatically. Suppose a VAR with n dimention and p lags and
a constant. The number of coefÔ¨Åcients on regressors follows k = n(1 + n ¬∑ p) and the number of
parameters on covariance matrix of errors is m = n(n+1)
2
. When n and p increase, the total number
of paramters of this model will increase nonlinearly and causes the so called problem of parameter
proliferation, given that we usually have limited length of macro data sets. In addtion, satisfying
the recent research requirement of extending the constant parameters to time varying ones, there
will be T, the net sample periods in this model, time paths for the k +m parameters and the newly
created, associated covariance matrices of innovations to the dynamic process of above parameters.
In all, this TVP-VAR has total parameters of Kp (n, p,T) = T(k + m) + k(k+1)
2
+ n(n+1)
2
+ r(r+1)
2
where r = n(n‚àí1)
2
. With limited sample span, over-parameterization, more or less, is inevitable,
especially in medium and large scale TVP-VAR models. This explains why in practice, small
scale models with short lags are often seen such as moetary policy analysis typically with three
variables and two lags.
Over parameterization problem in TVP-VARs with stochastic volatiliy strongly limits the num-
ber of variables and lags that can be incorporated in the model. Nevertheless, for many applica-
tions a large set of variables and more lags are necessary. In a modern economy, a large number
of variables work together and react each other. A variation of one variable will cause Ô¨Çuctua-
72

tions of other variables and these dynamics will typically continue for a period. If some important
varibles are missing in the model, it probably will give rise to the corresponding missing of tran-
sition channels or shocks. A typical case is ‚Äòprice puzzle‚Äô that will cause misunderstanding and
misleading in economic and policy analysis that usually seen in a small scale monetary analysis.
Banbura, Giannone, and Reichlin (2010), Carriero, Kapetanios, and Marcellino (2011) and Koop
(2013) demonstrate that a system of 15-20 variables performs better than small systems in point
forecasting and structual analysis.
As for the number of lags, for a quarterly data, Blanchard and Perotti (2002) argue that at
least 4 lags can catch the dynamic interaction of economy and Ô¨Åscal policy. For a monthly data,
Uhlig (2005) use 13 lags to analyse effects of monetary policy shock. Alessandri and Mumtaz
(2014) investigate the effects of uncertainty shock under different Ô¨Ånancial regimes, also use 13
lags for a monthly data set. Generally, more variables and lags can capture potentially possible
inter-reactions among different variables.
Two conÔ¨Çicts arise. The Ô¨Årst conÔ¨Çict is between preferred more variables and more lags and
the parameter proliferation, which becomes even stronger under time varying parameter framwork
that is often desired and required in current empirical time series analysis. As discussed above, the
problem of over parameterization is alway accompanying and become serious with the increase
of dimension of observations, number of lags and sample periods. The other conÔ¨Çict is between
estimation, computational burden and tractability. The TVP-VAR with stochastic volatility model
essentially is a combination of different state space models. The time varying parameters on regres-
sors and covariance matrix actully are state or latent variables in state equations that drive dynamic
process in measurement equations given other parameters and data. Note that the incorporation of
stochastic volatility typically involves nonlinear and non-gaussian state space blocks which abso-
lutely require high estimation skill and increase computational burden. Large data set, long lags
as well as time varying parameters make the estimation and computation much complicated and
sometimes hard to deal with.
The challenge facing the economists is how to build models or modify conventional models,
73

that are Ô¨Çexible enough to capture the main dynamic process in the data set, but not to cause se-
rious over-parameterization, thus making the estimation tractable and result believable. There are
two branches in the literature. The Ô¨Årst one is on shrinkage.1 The starting point is to set priors
that impose restrictions on the parameters, say shrinking to zero. The Minnesota Prior (see Doan,
Litterman and Sims, 1984 and Litterman, 1986) probably is the most typical one among them. The
basic idea of the prior is to make the VARs shrink to random walk, with stronger shrinkage for
coefÔ¨Åcients on longer lags and across variables. Further development of this prior includes impos-
ing restrictions on sum of coefÔ¨Åcients and cointegration, see Banbura et.al. (2010). Note that the
dimension of data set n has not changed, only using some particular priors to shrink to the desired
values of parameters. The second branch is based on factor idea that has been applied to differ-
ent directions. Since large data set is desirable and available in empirical analysis, several factors
that extracted from large data set could signiÔ¨Åcally decrease the model dimension n and alleviate
over parameterization problem replying on the assumption that the bulk of dynamic inter relations
within a large data set can be explained by several common factors (Forni et al., 2002 and Stock
and Watson, 2002b). The factors that reduce the dimension and VARs that explore dynamic inter-
relationship motivate the combination of the two methods. Bernanke, Boivin and Eliasz (2005) and
Stock and Watson (2005) have combined the two models, the so called factor augmented vector
autoregressive models (FAVARs). Del Negro and Otrok (2008) and Korobilis (2013a) extended
the FAVAR models to have time varying features on parameters, hence the TVP-FAVARs. Using
also the factor idea, De Wind and Gambetti (2014) focus on the factors that drive time varying
parameters instead of those that drive large data set in factor models and factor augmented VAR
models. They Ô¨Ånd that a q dimensional factors can sufÔ¨Åciently capture the bulk of time variation in
the k dimensional latent parameters in the full rank TVP-VAR model and sometimes q ‚â™k. That
is the covariance matrix of the innovations to the time varying parameters is reduced rank rather
than full rank. Simply speaking, this model tranforms the original k sources of variations, the same
dimentison as the number of time varying parameters, to q sources, the number of factors. Kim
1Using shrinkage prior in large Bayesian VAR will be discussed in Chapter 3.
74

and Yamamoto (2012) proposed a new approach to apply the factor idea. They argue that since
more lags sometimes are necessary to capture the dynamic process among variables, especially in
monthly data, recent lags could be qualiÔ¨Åed to drive longer lags due to that current variables are
more affected by recent lags in a standard VAR framwork. That is the constant vector and several
coefÔ¨Åcient matrices on the recent lags are the dynamic sources driving the variation of the stan-
dard TVP-VAR model. Factor idea can also be used in the time variation, namely the stochastic
volatility, on covariance matrix of forecast errors in VAR. Carriero, Clark and Marcellino (2012)
proposed a computationally effective way to model stochastic volatility to greatly speed up com-
putations for smaller VAR models and make estimation tractable for larger models. The newly
presented method links to the observation that the pattern of estimatied volatilities in empirical
analysis is often very similar across variables. They used a common unobserved factor ‚Äì com-
mon volatility ‚Äì to drive the individual volatility in standard TVP model with stachastic volatility.
They Ô¨Ånd that common volatility model signiÔ¨Åcantly improves model Ô¨Åt and forecasting accuracy
compared to constant volatility. Alessandri and Mumtaz (2014) by a VAR model and Mumtaz
and Theodoridis (2014) via a dynamic factor model also use common volatility to study effects of
‚Äòendogenous‚Äô uncertainty (generated from the model itself) on the U.S. economy.
As we discussed above, TVP-VAR with SV is not a parsimonious model which almost always
company over parameterization concern that could lead to misunderstanding and misleading in
economic inferences. A natural solution to this estimation is to make the model parsimonious and
tractable, meanwhile to be able to catch main dynamic characteristics among these variables.
In this chapter we propose a general parsimonious estimation method based on factor idea
that collects all the advantages of the above mentioned models. This model has the ability to
solve all the possible sources of parameter proliferation such as number of lags, dimension of
latent coefÔ¨Åcients on regressors and complicated stochastic volatility, and therefore can reduce
the computation burden, making the estimation tractable whatever small or large models. That‚Äôs
why we call it ‚Äògeneral parsimonious estimation‚Äô. This model is also Ô¨Çexible enough that could
pay different attention to different sources of possible over parameterization. For instance, if the
75

number of lags is small enough and suitable for some economic analysis, the model only need to
focus on the dimension of latent coefÔ¨Åcients and stochastic volatility.
Three papers are relevant to our method. Kim and Yamamoto (2012) is only on reduced lags
without possible factors driving latent coefÔ¨Åcients and stochastic volatility; De Wind and Gam-
betti (2014) applies latent factor both on latent coefÔ¨Åcients and stochastic volatiliy in estimation
procedure, but the complication of estimation of stochastic volatiliy still there; Carriero, Clark and
Marcellino (2012) use a latent factor as common volatility under constant coefÔ¨Åcients.
We apply the ‚Äògeneral parsimonious estimation‚Äô presented in this chapter to small scale mon-
etary VAR. SpeciÔ¨Åcally, we increase the number of lags from one to four to create possible over
parameterization enviroment. We implement principal component analysis on the covariance ma-
trix of innovations to latent coefÔ¨Åcients. The results show that even though with only one lag, the
VAR model is still not parsimonious; as the number of lags increases, the problem of over Ô¨Åtting
become serious and several factors are enough to capture the amount of variation that is present in
full rank model. The common volatility from the model with one lag to the model with four lags
works very well that coincides with the feature of U.S. business cycle. We also checked economic
agents‚Äô reaction to monetary policy shocks under the parsimonious estimation and Ô¨Ånd that there
are no signiÔ¨Åcant changes in the responses to non-systematic monetary policy in line with Prim-
iceri (2005) and Sims and Zha (2006). These evidences suggest that parsimonious estiamtion is
not only good at alleviating over Ô¨Åtting, but also suitable for structural analysis.
The Chapter 2 is organized as follows. In section 2, we present the model speciÔ¨Åcation that
is based on factor idea to conduct a parsimonious estimation. In section 3, Bayesian estiamtion
procedure is given step by step and we also point out that the free combination of different blocks in
estimation is equivalent to the simple verison of the presented general model seen in the literature.
Comparison with conventional model or estimation is also conducted to demonstrate the advantage
of reducing over-parameterization and at the same time also increase the estimation efÔ¨Åciency.
Section 4 in an empirical analysis, gives strong evidences of over-Ô¨Åtting even in a small scale
TVP-VAR and evaluates the performance of the factor driven model under the setting when the
76

extent of over parameterization becomes more and more serious. Finally, Section 5 conludes.
2.2
Model speciÔ¨Åcation
In this section, We present the general model that imposes all the possible factors that drive lags,
latent coefÔ¨Åcients and stochastic volatility. Of course, when it applies to an empirical analysis,
appropriate settings should be chosen by researchers depending on the sepciÔ¨Åc objects.
Suppose yt is an n√ó1 vector that follows VAR(p) process
yt = ct +B1,tyt‚àí1 +¬∑¬∑¬∑+Bp,tyt‚àíp +ut
(2.1)
where ct is an n√ó1 time varying constant, {Bi,t}p
i=1 are n√ón matrices of time varying autoregres-
sive parameters, and ut is an n √ó 1 vector of forecast errors. The errors are assumed to indepen-
dently and identically follow normal distribution ut ‚àºN (0,Œ£t).
Let‚Äôs Ô¨Årst look at the stochastic volatility part of Œ£t. Following Carriero et. al. (2012), we
assume that
Œ£t = A‚àí1DtA‚àí1‚Ä≤
(2.2)
where A is a lower triangluar matrix with values of ones on the main diagonal. The volatility
process is deÔ¨Åned as
Dt = ŒªtS
(2.3)
S = diag
 [1,s2,...,sn]‚Ä≤
(2.4)
log(Œªt) = F ¬∑logŒªt‚àí1 +Œ∑t
(2.5)
where Œ∑t ‚àºiidN (0,Qh). h = log(Œªt) follows AR(1) process that is common to all variables and
drives the time variation in the entire covariance matrix of the VAR errors. The Ô¨Årst element
of diagonal variance matrix S ‚Äì the loading ‚Äì is normalized to one for identiÔ¨Åcation of common
77

volatility Œªt.
Next we can rewrite equation (2.1) using the above volatility structure in the form of
yt = BtXt +Œª
1
2t A
‚àí1S
1
2Œµt
(2.6)
where Bt = [ct,B1,t,...,Bp,t] and Xt =

1,y‚Ä≤
t‚àí1,...,y‚Ä≤
t‚àíp
‚Ä≤
. Following Kim and Yamamoto (2012),
the time varying coefÔ¨Åcients on regressors can be decomposed into
Bt = B+ ¬ØBtG
(2.7)
where ¬ØBt and G are n√ór and r√ó(np+1) respectively. For the model to be properly identiÔ¨Åed, we
assume that
¬ØB1 = 0 and G = [Ir G1]
(2.8)
we as usual assume that bt = vec

¬ØB
‚Ä≤
t

follows random walk
bt = bt‚àí1 +ubt
(2.9)
where ubt ‚àºiidN (0,Qb). Note that from ¬ØBtG = [ ¬ØBt ¬ØBtG1], ¬ØBt should have the similar time variation
to the elements in the Ô¨Årst r columns of Bt matrix of the unrestricted model.
Finally, we further assume that the nr√ó1 time varying paramter bt is driven by q factors where
q ‚â§nr (De Wind and Gambetti, 2014). This means that the covariance matrix Qb is of less than full
rank. Decompose the covariance matrix Qb = ŒõbŒõ
‚Ä≤
b where Œõb is a nr √óq matrix as factor loadings
implying that rank(Qb) = q. The transition equation (2.9) can be written as
bt = bt‚àí1 +ŒõbœÖt
(2.10)
where correspondingly œÖt is a q√ó1 shocks that follows œÖt ‚àºN
 0,Iq

. The above equation (2.10)
implies that ‚ñ≥bt is on the column space of Œõb but bt is not necessarily in the column space of
78

Œõb. In other words, changes in time varying parameters are driven by factors while levels are not
necessary since there are more forces determining the economy than forces changing the economy.
Thus the law of motion of (2.10) can be further written as
bt = Pbbt +Mbbt
(2.11)
where Pb = Œõb

Œõ
‚Ä≤
bŒõb
‚àí1
Œõ
‚Ä≤
b is a projection matrix onto the column space of Œõb that contains the
changing part of the bt; Mb = Inr ‚àíPb is the projection matrix onto the left null space of Œõb that
sizes the time invariant part of bt. DeÔ¨Åning Àúbt =

Œõ
‚Ä≤
bŒõb
‚àí1
Œõ
‚Ä≤
bbt as driving factors, then
bt = ŒõbÀúbt +Mbb0
(2.12)
and the law of motion in terms of the underlying factors follows
Àúbt = Àúbt‚àí1 +œÖt
(2.13)
via premultiplying equation (2.10) by

Œõ
‚Ä≤
bŒõb
‚àí1
Œõ
‚Ä≤
b both sides.
The model speciÔ¨Åcation consists of three parts. Equations from (2.1) to (2.5) describe a com-
mon factor that drive the volatilities of all the variables in yt. This factor application is due to two
reasons. One is from the observation that the pattern of estimated volatilities in empirical analysis
is often very similar across variables. As discussed above, the U.S. economy has experienced two
episodes of the ‚ÄòGreat InÔ¨Çation‚Äô and the ‚ÄòGreat Moderation‚Äô, respectively. In the former period,
most macroeconomic variables had very high volatility; while in the latter period, modest volatiliy
was shared by most macro-variables. The other is that it greatly reduces the computational budern
in which nonlinear and nongaussian state space involoved in full stochastic volatility part has to
be transformed to linear gaussian state space via seven (Kim, Shephard and Chib, 1998) or ten
(Omori, Chib, Shephard and Nakajima, 2007) mixture normals. In addition, the length of history
of common volatility is always Ô¨Åxed at T, independent of n, while the full volatility is determined
79

by both T and n, i.e. n(n+1)
2
¬∑T.
Equations (2.6) - (2.9) give the factor idea of using early lags to drive whole lag coefÔ¨Åcients.
Many empirical analysis, especially in Ô¨Åeld of forecasting, have evidenced that recent lags are more
relevant than long lags affecting current variables which justÔ¨Åes our model setting. The last four
equations (2.10) - (2.13) present another interpretation of dynamic process of latent time varying
coefÔ¨Åcients that only limited factors drive the the bulk of variation in time varying coefÔ¨Åcients. De
Wind and Gambetti (2014) give the emipical evidence and theoretical support for this setting.
One thing worth mention is that the three portions of the general-setting model is not neces-
sarily connected together. They can be freely combined or independently exist with respect to
the research object ones are conducting. For instance, if relaxing one of factor restrictions, the
corresponding part becomes the standard setting. This can be seen clearly in Bayesian estimation
procedure in the next section.
2.3
Bayesian estimation procedure
In this section, we describe the Bayesian estimation procedure step by step. In each step or, pre-
cisely speaking, in each block, after some appropriate transformation, the estimation Ô¨Ånally re-
duces to standard Bayesian estimation such as linear regression models and state space models
either linear or nonlinear.
2.3.1
Draw a history of {bt}T
t=1
We need some transformation to construct a state space model for bt. Substituting the decomposi-
tion equation (2.7) into measurement equation (2.6), one obtains
yt = BXt + ¬ØBtGXt +ut
(2.14)
80

It can be further written as via column stacking operator both sides
y‚ãÜ
t = Zb,tbt +ut
(2.15)
where y‚ãÜ
t = yt ‚àíBXt, Zb,t =

In (GXt)
‚Ä≤
, bt = vec

¬ØB
‚Ä≤
t

and ut ‚àºN (0,Œ£t);  denotes Kronecker
product and vec is column stacking operator.2The composition of bt = ŒõbÀúbt + Mbb0 in equation
(2.12) then is plugged into (2.15) to obtain
y‚ãÜ
t = Zb,tŒõbÀúbt +Zb,tMbb0 +ut
(2.16)
Clearly, We Ô¨Ånd that drawing the history of bt is divided into three steps: i) draws of Àúbt, ii) draws
of Mbb0 and iii) draws of bt based on i) and ii).
2.3.1.1
Draw a history of
Àúbt
	T
t=1
The state space model for Àúbt based on equation (2.16) is orgonized as
y‚ãÜ‚ãÜ
t
= Z‚ãÜ
b,t Àúbt +ut
(2.17)
with the law of motion in (2.13)
Àúbt = Àúbt‚àí1 +œÖt
where y‚ãÜ‚ãÜ
t = y‚ãÜ
t ‚àíZb,tMbb0, Z‚ãÜ
b,t = Zb,tŒõb, ut ‚àºN (0,Œ£t) and œÖt ‚àºN
 0,Iq

due to the decomposition
of Qb. Since the above two equations form the standard linear and gaussian state space model,
posterior draws of {bt}T
t=1 can be sampled by the algorithm of Carter and Kohn (1994).
Standard Kalman Ô¨Ålter and a smoother apply to the linear and gaussian state space model for
Àúbt. We herein give the basic description. The Ô¨Ålter goes forward until T and obtain a draw from
ÀúbT ‚àºN
 ÀúbT|T,VT|T

in the last period; Then based on the draw of ÀúbT as an obervation, the Ô¨Ålter
goes backward into a smooth process until the Ô¨Årst period. That is Àúbt ‚àºN
 Àúbt|t+1,Vt|t+1

based
2vec(ABC) =

AC
‚Ä≤
vec

B
‚Ä≤
81

on previous draw as a new observation successively for t = T ‚àí1,...,1. The forward recursive
formulae are given by
Vt|t‚àí1 = Vt‚àí1|t‚àí1 +Iq
Kt = Vt|t‚àí1Z‚ãÜ‚Ä≤
b,t

Z‚ãÜ
b,tVt|t‚àí1Z‚ãÜ‚Ä≤
b,t +Œ£t
‚àí1
Àúbt|t = Àúbt‚àí1|t‚àí1 +Kt
 y‚ãÜ‚ãÜ
t ‚àíZ‚ãÜ
b,t Àúbt‚àí1|t‚àí1

Vt|t = Vt|t‚àí1 ‚àíKt
 Z‚ãÜ
b,tVt|t‚àí1

where the notation x|t is used to condition on the information set up to and including time t. Note
that the initialization of the recursion follows from the prior distribution on b0|0 ‚àºN (b0,V0). By the
deÔ¨Ånition of Àúbt = Rbbt where Rb =

Œõ
‚Ä≤
bŒõb
‚àí1
Œõ
‚Ä≤
b, then prior distribution becomes Àúb0|0 ‚àºN
 Àúb0, ÀúV0

where correspondingly Àúb0 = Rbb0 and ÀúV0 = RbV0R
‚Ä≤
b. The backward recursion, namely the smoother
has
Àúbt|t+1 = Àúbt|t +Vt|tV ‚àí1
t|t+1
 Àúbt+1 ‚àíÀúbt|t

Vt|t+1 = Vt|t ‚àíVt|tV ‚àí1
t|t+1Vt|t
Finally, Àúbt premultiplying by Œõb obtain the time varying part of bt following equation (2.12).
2.3.1.2
Draw Mbb0 as a whole
After drawing of time varying part, now we consider the time invariant part of bt. Equation (2.16)
can be organized as
y‚ãÜ‚ãÜ
t
= Zb,tŒ¥ +ut
(2.18)
where y‚ãÜ‚ãÜ
t
= y‚ãÜ
t ‚àíZb,tŒõbÀúbt and Œ¥ = Mbb0. The above equation can be interpreted as a restricted
linear regression, as the vector coefÔ¨Åcient Œ¥ from its deÔ¨Ånition is on the column space of Mb
82

naturally with the restriction PbŒ¥ = 0 or equivalently RbŒ¥ = 0.
Stacking (2.18) with the above restriction, it displays as
y‚ãÜ‚ãÜ= ZbŒ¥ +u
(2.19)
RbŒ¥ = 0
where y‚ãÜ‚ãÜ=
h
y
‚Ä≤
1,...,y
‚Ä≤
T
i‚Ä≤
, Zb =
h
Z
‚Ä≤
b,1,...,Z
‚Ä≤
b,T
i‚Ä≤
, u =
h
u
‚Ä≤
1,...,u
‚Ä≤
T
i‚Ä≤
as well as u ‚àºN (0,Œ£‚ãÜ) with
Œ£‚ãÜ= Blkdiag([Œ£1,...,Œ£T]) in which covariance matrix each period is placed on the main diagonal.
Details on the estimation of the restricted linear regression is delegated to appendix in this chapter.
The basic idea to dealing with the Bayesian estimation with restrctions on the parameters is to
think of the restrictons as another prior information and incoporate it into the posterior. Since
b0|0 ‚àºN (b0,V0), the prior for Œ¥ becomes Œ¥ ‚àºN (Œ¥,V Œ¥) where Œ¥ = Mbb0 and V Œ¥ = MbV0M
‚Ä≤
b. The
posterior of Œ¥ also follows normal distribution
Œ¥ ‚àºN
  ¬ØŒ¥, ¬ØVŒ¥

with
¬ØŒ¥ =

Inr ‚àíÀúVŒ¥R
‚Ä≤
b

Rb ÀúVŒ¥R
‚Ä≤
b
‚àí1
Rb

ÀúŒ¥
¬ØVŒ¥ =

Inr ‚àíÀúVŒ¥R
‚Ä≤
b
 RŒ¥ ÀúVŒ¥Rb
‚àí1 Rb

ÀúVŒ¥
where the posterior mean of ÀúŒ¥ and posterior variance of ÀúVŒ¥ are from the standard Bayesian estima-
tion of linear unrestricted regression
ÀúŒ¥ =

Z
‚Ä≤
bŒ£‚ãÜ‚àí1Zb +V ‚àí1
Œ¥
‚àí1
ÀúVŒ¥ = ÀúŒ¥

Z
‚Ä≤
bŒ£‚ãÜ‚àí1y‚ãÜ‚ãÜ+V ‚àí1
Œ¥ Œ¥

83

2.3.1.3
Draw a history of {bt}T
t=1
The Ô¨Ånal step is straightforward to sum the time varying part and time invariant part together, i.e.
bt = ŒõbÀúbt + Mbb0 which yields bt draw for t = 1,...,T. This completes the drawing from the
posterior distribution of {bt}T
t=1 via a two separate gibbs sampling.
2.3.2
Draw reduced rank covariance matrix Qb
The posterior distribution of Qb only depends on the history of all bts. Sampling is based on the
following state equation (2.9)
bt = bt‚àí1 +ub,t
The posterior distribution of Qb follows inverse wishart distribution given the prior distribution of
the same type
Qb ‚àºSIW
  ¬ØQb, ¬ØŒΩ

with
¬ØQb =
T
‚àë
t=2
(bt ‚àíbt‚àí1)(bt ‚àíbt‚àí1)
‚Ä≤ +Qb
¬ØŒΩ = ŒΩ +T ‚àí1
where Qb and ŒΩ are scale matrix and degree of freedom respectively for prior inverse wishart
distribution of reduced rank Qb.
2.3.3
Draw constant matrix B
Go back to equation (2.14), place unrelated term to the left hand side and obtain the linear regres-
sion associated with matrix B
y‚ãÜ
t = BXt +ut
(2.20)
84

where y‚ãÜ
t = yt ‚àí¬ØBtGXt and ut ‚àºN (0,Œ£t) with ut = Œª
1
2t A‚àí1S
1
2Œµt. Transpose the above equation and
divide by ‚àöŒªt both sides, we obtain
y‚ãÜ‚Ä≤
t /
p
Œªt =

Xt/
p
Œªt

B
‚Ä≤ +u
‚Ä≤
t/
p
Œªt
(2.21)
Stacking the above equation row by row
Y ‚ãÜ= XB
‚Ä≤ +U
(2.22)
then stacking the equation column by column, we obtain the Ô¨Ånal equation form for our Bayesian
estimation
y‚ãÜ= Œûb+u
(2.23)
where Œû = In X, b = vec

B
‚Ä≤
and u = vec(U) with u ‚àºN (0,Œ£IT).3
The aim of the above steps is to transform the heterogeneous linear regression to homogeneous
linear regression model. With respective to (2.23), standard normal posterior distribution of b can
be found with also the normal prior distribution
b ‚àºN
 ¬Øb, ¬ØVb

with
¬Øb = ¬ØVb

Œû
‚Ä≤ (Œ£IT)‚àí1 y‚ãÜ+V ‚àí1
b b

¬ØVb =

Œû
‚Ä≤ (Œ£IT)‚àí1 Œû+V ‚àí1
b
‚àí1
where prior follows b ‚àºN (b,V b). Finally transform column vector b back to matrix B.
3vec(ABC) =

C
‚Ä≤ A

vec(B)
85

2.3.4
Draw constant matrix G1
We still focus on equation (2.14). Place the term BXt to the left hand side based on previous draw
of B and obtain
y‚ãÜ
t = ¬ØBtX1,t + ¬ØBtG1X2,t +ut
where y‚ãÜ
t = yt ‚àíBXt and the decomposition of Xt into X1,t and X2,t is due to the structure G = [Ir G1].
We further get the linear regression associated with G1by column stacking operator towards the
above equation both sides
y‚ãÜ‚ãÜ
t
= Wtg1 +ut
(2.24)
where y‚ãÜ‚ãÜ
t
= y‚ãÜ
t ‚àí¬ØBtX1,t, Wt =

¬ØBt X
‚Ä≤
2,t

, g1 = vec

G
‚Ä≤
1

and ut ‚àºN (0,Œ£t). The same as (2.21),
heteroscedasticity can be removed through dividing both sides of (2.24) by ‚àöŒªt. Here we skip this
step, directly transform the (2.24) into a large matrix form
y‚ãÜ‚ãÜ= Wg1 +u
(2.25)
where y‚ãÜ‚ãÜ=
h
y‚ãÜ‚ãÜ‚Ä≤
1 ,...,y‚ãÜ‚ãÜ‚Ä≤
T
i‚Ä≤
, W =
h
W
‚Ä≤
1,...,W
‚Ä≤
T
i‚Ä≤
, ut =
h
u
‚Ä≤
1,...,u
‚Ä≤
T
i‚Ä≤
and u ‚àºN (0,Œ£‚ãÜ) with Œ£‚ãÜ=
Blkdiag([Œ£1,...,Œ£T]).
The posterior of g1 follows normal with variance and mean given by ¬ØVg1 and ¬Øg1 respectively
g1 ‚àºN ( ¬Øg1, ¬ØVg1)
¬Øg1 = ¬ØVg1

W
‚Ä≤Œ£‚ãÜ‚àí1y‚ãÜ‚ãÜ+V ‚àí1
g1 g1

¬ØVg1 =

W
‚Ä≤Œ£‚ãÜ‚àí1W +V ‚àí1
g1
‚àí1
and prior follows g1 ‚àºN

g1,V g1

.
86

2.3.5
Draw structural impact matrix A
To draw impact matrix A, we concentrate on equation (2.6). Take unrelated term to the left hand
side, obtaining
AÀÜyt = Œª
1
2t S
1
2Œµt
(2.26)
where ÀÜyt = yt ‚àíBtXt. Since the recursive structure of A ‚Äì lower triangular matrix with value of
ones on the main diagonal, we can estimate (2.26) individually
ÀÜyi,t = ‚àíÀÜy
‚Ä≤
‚àíi,tŒ±i +Œª
1
2t s
1
2
i Œµt
(2.27)
for i = 2,...,n and for t = 1,...,T. ÀÜy‚àíi,t collect elements from ÀÜy1,t to ÀÜyi‚àí1,t and Œ±i nest corre-
sponding row elements in matrix A. To estimate the above equation, divide by ‚àöŒªtst both sides to
remove the error heteroscedasticity
ÀÜyi,t/
p
Œªtst =

‚àíy‚àíi,t/
p
Œªtst

Œ±i +Œµt
Stack them row by row to obtain
ÀÜyi = X‚àíiŒ±i +Œµ
(2.28)
where Œµ ‚àºN (0,IT).
The posterior of Œ±i follows normal with mean and variance
Œ±i ‚àºN ( ¬ØŒ±i, ¬ØVŒ±)
with
¬ØŒ±i = ¬ØVŒ±

X
‚Ä≤
‚àíi ÀÜyi +V ‚àí1
Œ± Œ±i

¬ØVŒ± =

X
‚Ä≤
‚àíiX‚àíi +V ‚àí1
Œ±
‚àí1
and prior Œ±i ‚àºN (Œ±i,V Œ±).
87

2.3.6
Draw diagonal elements of S
Using equation (2.27), divide both sides by ‚àöŒªt and obtain
ÀÜyi,t/
p
Œªt =

‚àíy‚àíi,t/
p
Œªt

Œ± +s
1
2
i Œµt
again stack row by row
ÀÜyi = X‚àíiŒ±i +Œµ
(2.29)
where Œµ ‚àºN (0,siIT) for i = 2,...,n.4
Given the prior si ‚àºIG(a,b) where IG denotes inverse gamma distribution, the posterior fol-
lows
si ‚àºIG
 ¬Øa, ¬Øb

with
¬Øa = a+ T
2
¬Øb = b+ Œµ
‚Ä≤Œµ
2
Note that the step 5 of drawing Œ±i can be merged into step 6 only focusing on equation (2.29).
2.3.7
Draw common stochastic volatility {Œªt}T
t=1
Unlike bt, the latent factor Œªt is not in a linear and gaussian state space model given other pa-
rameters and hyperparamters. Thus typical way of multiple drawing of latent variables of Carter
and Kohn (1994) algorithm is no longer suitable for Œªt. Following Jacquier et.al. (1994), single
drawing date by date is used for the nonlinear model. Carlin et.al (1992) show that conditional
distribution of state variables in a general state space model can be written as product of three
4i starting from 2 is for the identiÔ¨Åcation of common (latent factor) volatility. See section 2 on the model speciÔ¨Å-
cation.
88

terms
f
 ht|Œò,yT
‚àùf (ht|ht‚àí1)¬∑ f (ht+1|ht)¬∑ f (yt|ht,Œò)
(2.30)
which is the starting point of sampling of the latent factor ht = log(Œªt). The Ô¨Årst two terms on
the right hand side can be further written as f (ht|ht+t,ht‚àí1) ‚àùf (ht|ht‚àí1) ¬∑ f (ht+1|ht).5 Hence
conditional posterior of ht is now a product of two terms
f
 ht|Œò,yT
‚àùf (ht|ht‚àí1,ht+1)¬∑ f (yt|ht,Œò)
(2.31)
That is the target distribution from which draws of ht come.
Nonlinearity of the state space model on measurement equation makes the posterior target does
not have an analytical form, therefore metropolis algorithm is required. We choose f (ht|ht‚àí1,ht+1)
as proposal since it is part of target distribution with the same support and the most importance
is that the proposal is analytical due to that the law of motion of the common factor is linear
and gaussian. The basic idea is that one can regard ht as paramters to be estimated, ht+1 as the
obserbation driven by ht and ht‚àí1 as prior information about ht. This can be seen explicitly in
successive two periods
ht = F ¬∑ht‚àí1 +Œ∑t
ht+1 = F ¬∑ht +Œ∑t+1
from the Ô¨Årst equation one can set prior for ht ‚àºN (F ¬∑ht‚àí1,Qh) while in the second equation ht
is coefÔ¨Åcient to be estimated and ht+1is an observation. From the standard Bayesian estiamtion of
linear regression model, one is familiar with
‚Ä¢ For t = 1,...,T ‚àí1,
ht ‚àºN (Fht‚àí1,Qh)
5 f (ht|ht‚àí1,ht+1) = f(ht‚àí1,ht,ht+1)
f(ht‚àí1,ht+1) = f(ht+1|ht,ht‚àí1)¬∑f(ht|ht+1)
f(ht+1|ht‚àí1)
‚àùf (ht+1|ht)¬∑ f (ht|ht‚àí1)
89

ht|ht‚àí1,ht+1 ‚àºN (uh,Qh)
(2.32)
with
uh = Vh

F
‚Ä≤Q‚àí1
h ht+1 +Q‚àí1
h Fht‚àí1

Vh =
 F‚Ä≤Q‚àí1
h F +Q‚àí1
h
‚àí1
‚Ä¢ For t = 0,
h0 ‚àºN (uh,V h)
since
h1 = F ¬∑h0 +Œ∑1
then
h0 ‚àºN ( ¬Øuh, ¬ØVh)
(2.33)
¬Øuh = ¬ØVh

F
‚Ä≤Q‚àí1
h h1 +V ‚àí1
h uh

¬ØVh =

F
‚Ä≤Q‚àí1
h F +V ‚àí1
h
‚àí1
‚Ä¢ For t = T,
hT|hT‚àí1 ‚àºN
 uT,h,VT,h

(2.34)
uT,h = VT,h
 Q‚àí1
h FhT‚àí1

VT,h =

F
‚Ä≤Q‚àí1
h F +Q‚àí1
h
‚àí1
With the above proposals at hand (2.32) - (2.34), the date by date independence metropolis is
implemented as follows
1. When t = 0, draw h0 from (2.33) given prior for h0.
2. When t = 1,...,T ‚àí1, a) draw a candidate h‚ãÜ
t from (2.32); b) compute the acceptance ratio
90

(probability) r = min

f(yt|h‚ãÜt ,Œû)
f(yt|hold
t
,Œû), 1

where f (yt|ht,Œû) is the likelihood of the observation
t; c) for each h‚ãÜ
t , draw a value u from the Uniform (0,1) distribution. If u ‚â§r, accept h‚ãÜ
t as
hnew
t
. Otherwise, still keep hold
t
in period t.
3. When t = T, a) draw a candidate h‚ãÜ
T from (2.34); b) compute the acceptance ratio (probabil-
ity) r = min

f(yT |h‚ãÜ
T ,Œû)
f(yT |hold
T ,Œû), 1

where f (yT|hT,Œû) is the likelihood of the observation T; c)
for each h‚ãÜ
T, draw a value u from the Uniform (0,1) distribution. If u ‚â§r, accept h‚ãÜ
T as hnew
T
.
Otherwise, still keep hold
T
in period T.
4. Repeat step 1 to step 3 date by date in each iteration.
We complete the drawing of ht from t = 1 to t = T. Note that though there is no explicit backward
smoother procedure as in the algorithm of Carter and Kohn (1994) for linear gaussian model, the
draws of ht are stll based on the information set of all the observations as they directly come from
posterior condition f
 h1,...,hT|yT,Œû

instead of two seperate steps of forward Kalman Ô¨Ålter and
a backforward smoother with the analytical expression in linear gaussian model.
2.3.8
Draw coefÔ¨Åcient F
Give the previous draws of {ht}T
t=1with equation (2.5)
ht = F ¬∑ht‚àí1 +Œ∑t
where Œ∑t ‚àºN (0,Qh). By typical column stacking implementation
yh = F ¬∑xh +Œ∑
(2.35)
the posterior of F has
F ‚àºN
 ¬ØuF, ¬ØQF

91

with
¬ØuF = ¬ØQF

Q‚àí1
h x
‚Ä≤
hxh +Q‚àí1
F uF

¬ØQF =

Q‚àí1
h x
‚Ä≤
hyh +Q‚àí1
F
‚àí1
where prior F ‚àºN

uF,QF

.
2.3.9
Draw variance Qh
Still focusing on equation (2.35) with prior distribution of inverse gamma Qh ‚àºIG(c,d), the pos-
terior becomes
Qh ‚àºIG
 ¬Øc, ¬Ød

with
¬Øc = c+ T
2
¬Ød = d + Œ∑
‚Ä≤Œ∑
2
The above nine steps or nine blocks consist of one iteration in Bayesian estimation via Markov
chain Monte Carlo (MCMC). The MCMC simulation involves Gibbs sampling and Metropolis
Hasting algorithm. After discarding some burn-in iterations, the draw of parameters and hyper-
parameters from each conditional posterior is equivalent to one from joint posterior from which
bayesain inference can be conducted.
The characteristic of the model is that we use factor idea on lags, coefÔ¨Åcients and volatility
to make the TVP-VAR model parsimonious. We use Ô¨Årst several lags to drive long lags that are
identiÔ¨Åed by G matrix, see (2.8); We use a latent factor, namely the common volatility to represent
the volatilities of the whole observations that is identiÔ¨Åed by S matrix, see (2.4 ) and Ô¨Ånally several
factors could drive the latent coefÔ¨Åcients by decomposing covariance matrix Qb into reduced rank
that can be seen in (2.10 ) and (2.11). The difference of our model with conventional factor models
or factor augmented models is that we focus on reducing dimension of parameters rather than on
92

dimension of observations in a rich data set.
In the next section, we apply this model to monetary policy analysis to evaluate the model
performance and make some inferences.
2.4
Empirical analysis
In this section, we Ô¨Årst analyse whether there are enough evidences for factor driving of the dy-
namic process of the time varying coefÔ¨Åcients in the TVP-VAR model. We apply the general
factor-driven model to a typical small scale monetary VAR. We however still Ô¨Ånd strong evidences
in supporting factor driving. Then we turn to structrual analysis on the agents‚Äô response to mone-
tary policy shock. No signiÔ¨Åcant difffences are found.
The same data is used as in Chapter 1. It contains three variables, namely inÔ¨Çation rate, unem-
ployment rate and short rate of 3-month treasury bill rate which cover the period from 1953 Q1 to
2006 Q3 before the 2008 Ô¨Ånancial crisis after that unconventional monetary policy was conducted.
The reason we choose this data set is threefold. First, it is a good description of workings of the
economy in real activity, nominal variable and monetary policy that explicitly correspond to IS
curve, Philips Curve and policy rule in a typical small scale DSGE model. Thus this data set is
widely used in policy and business cycle analysis and also a subset of medium or large scale data
set for such analysis; Second, due to the well known problem of parameter proliferation in TVP-
VAR with or without SV, researchers usually tend to use such kind of small data set to weeken this
concern in order to make their Ô¨Åndings or/and conclusions belivable. Based on this arrangement,
we try to ask is there still over-parameterization in this small scale model they specially choose and
if it is, is it strong enough; Lastly, since the data is widely used, it is convenient for us to conduct
comparison with extant literature.
93

2.4.1
Are factors important in time varying parameters?
In this subsetion, we test whether there is enough evidence supporting over Ô¨Åtting in the small
scale TVP-VAR. That is the precondition and starting point for our factor-based model. The test
is based on two models that all impose no factor restriction on time varying coefÔ¨Åcients on re-
gressors, namely let the coefÔ¨Åcients freely Ô¨Çuctuate. The only difference is that one with full
stochastic volatility (Primiceri, 2005) and the other common volatility (Carriero et al., 2012). In-
cluding stochastic volatility in the model is because shutting off the volatility channel probably
will cause misunderstanding of the dynamic process.6 If the test is implemented in a model that
can potentially cause the amount of time variation originating from the part of volatiliy incorrectly
transferring to the part of time varying coefÔ¨Åcients on regressors ‚Äì that is the time varying coef-
Ô¨Åcients now have more variation than they should have, even though we Ô¨Ånd evidence on over
parameterization, the result is still questionable. Testing results from both models with SV are
very similar, here we only present the results from the model with common volatility for the save
of space.7
The TVP-VAR with common volatility (TVP-VAR-CV for short hereafter) is implemented
with one lag to four lags with common volatility respectively. We conduct pincipal component
analysis of the covariance matrix of innovations to time varying coefÔ¨Åcients Qb in each model.
Table 2.1 and Table 2.2 give the contribution of each factor for each model with lag from one to
four. They are given in terms of mean and median in percentage in descending order. Some Ô¨Ågures
do not list in the tables because contributions are already too small.
In the model with only 1 lag, it has only 12 time varying coefÔ¨Åcients each period and therefore
the most less over-Ô¨Åtting model. Principal component analysis shows that factor driving is still very
obvious and can not be ignored. From Table 2.1 under the Lag 1 title, we Ô¨Ånd that the Ô¨Årst factor
6Consider a AR(1) process yt = œÅyt‚àí1+ut where ut ‚àºN
 0,œÉ2
. The unconditional variance of yt is var(yt) =
œÉ2
1‚àíœÅ2
. If the volatility œÉt is increasing with time, but the model is estimated on time varying coefÔ¨Åcient œÅt with constant œÉ,
we will Ô¨Ånd the persistent œÅt of the model is increasing that contradicts the reality.
7The empirical test on the TVP-VAR with full SV is also conducted. The results are almost exactly the same as
common SV which conÔ¨Årms the Ô¨Ånding in Carrero et al. (2012) that for the typical U.S. data set, common SV is a
good representation for full SV.
94

TVP-VAR-CV
Lag 1
Lag 2
Principal component
Mean %
Median %
Mean %
Median %
1
63.8684
63.5164
96.0390
96.1510
2
18.2649
18.9576
1.6741
1.0047
3
11.4011
11.0741
0.5968
0.7234
4
3.0299
2.9678
0.4953
0.4322
5
1.2880
1.3223
0.3128
0.2725
6
0.9465
0.9347
0.2257
0.2507
7
0.5503
0.5536
0.1662
0.2011
8
0.3539
0.3742
0.1353
0.1691
9
0.2276
0.2251
0.0903
0.1464
10
0.0463
0.0457
11
0.0146
0.0213
12
0.0085
0.0071
Table 2.1: Contribution for each factor via principal component analysis on covariance matrix Qb
for TVP-VAR-CV from lag one to lag two
TVP-VAR-CV
Lag 3
Lag 4
Principal component
Mean %
Median %
Mean %
Median %
1
95.1109
93.5693
93.7272
91.1517
2
1.8860
1.7230
3.1857
2.3241
3
0.8257
1.0010
0.9423
1.1121
4
0.5718
0.5718
0.4749
1.0458
5
0.3397
0.5330
0.4012
0.6961
6
0.2658
0.4804
0.2641
0.6427
7
0.1683
0.3620
0.2270
0.4846
8
0.1612
0.3288
9
10
11
0.0712
0.2264
12
0.0728
0.1361
Table 2.2: Contribution for each factor via principal component analysis on covariance matrix Qb
for TVP-VAR-CV from lag three to lag four
95

2
4
6
8
10
12
65
70
75
80
85
90
95
100
cumulative percentage
 
 
mean
median
2
4
6
8
10
12
10
20
30
40
50
60
contribution for each factor
 
 
mean
median
Figure 2.1: Contribution and cumulative contribution for lag 1
Notes: This is TVP-VAR-CV with 1 lag and 12 coefÔ¨Åcients on regressors each period. The left
panel plots cumulative contribution for all the factors via principal component analysis of covari-
ance matrix Qb. The right panel plots contribution for each factor in descending order via principal
component analysis of covariance matrix Qb. The solid line represents posterior mean, while
dashed line posterior median.
96

5
10
15
20
96.5
97
97.5
98
98.5
99
99.5
cumulative percentage
 
 
mean
median
5
10
15
20
10
20
30
40
50
60
70
80
90
contribution for each factor
 
 
mean
median
Figure 2.2: Contribution and cumulative contribution for lag 2
Notes: This is TVP-VAR-CV with 2 lag and 21 coefÔ¨Åcients on regressors each period. The left
panel plots cumulative contribution for all the factors via principal component analysis of covari-
ance matrix Qb. The right panel plots contribution for each factor in descending order via principal
component analysis of covariance matrix Qb. The solid line represents posterior mean, while
dashed line posterior median.
97

5
10
15
20
25
30
94
95
96
97
98
99
100
cumulative percentage
 
 
mean
median
5
10
15
20
25
30
10
20
30
40
50
60
70
80
90
contribution for each factor
 
 
mean
median
Figure 2.3: Contribution and cumulative contribution for lag 3
Notes: This is TVP-VAR-CV with 3 lag and 30 coefÔ¨Åcients on regressors each period. The left
panel plots cumulative contribution for all the factors via principal component analysis of covari-
ance matrix Qb. The right panel plots contribution for each factor in descending order via principal
component analysis of covariance matrix Qb. The solid line represents posterior mean, while
dashed line posterior median.
accounts for 64% contribution of the variation of all coefÔ¨Åcients. The second takes 18% much less
than the Ô¨Årst and the third 11% with a moderate amount of interpretation. This dynamic process
can be found in Fig 2.1 in which the left panel gives the cumulative contribution and the right panel
shows the contribution for each factor where solid line denotes mean and dashed line median. It
is easy to observe that the Ô¨Årst three factors, all above 10%, together account for near 95% and
the Ô¨Årst six factors together almost 100%. After the sixth factor, all the remaining factors with
very little explanation can be ignored which is evidenced by the right panel of Fig 2.1. Generally
speaking, the samll scale model with the shortest lag indicates that it is still very over Ô¨Åtting, at
least half of the principals should be discarded.
98

10
20
30
92
93
94
95
96
97
98
99
100
cumulative percentage
 
 
mean
median
10
20
30
10
20
30
40
50
60
70
80
90
contribution for each factor
 
 
mean
median
Figure 2.4: Contribution and cumulative contribution for lag 4
Notes: This is TVP-VAR-CV with 4 lag and 39 coefÔ¨Åcients on regressors each period. The left
panel plots cumulative contribution for all the factors via principal component analysis of covari-
ance matrix Qb. The right panel plots contribution for each factor in descending order via principal
component analysis of covariance matrix Qb. The solid line represents posterior mean, while
dashed line posterior median.
99

Let‚Äôs go to two lags. The two columns under the title of Lag 2 strongly suggest that, in Table2.1,
the Ô¨Årst factor is large enough with 96% to interpret almost all the variation in the part of time
varying coefÔ¨Åcients, while the second factor, in contrast to the model of one lag, dramatically
decline to less than 2%. This can be evidenced by the right panel of Fig 2.2. After the second
factor, all the remaining factors have contributions close to zero. When the model is set to three
lags, the result is very similar that the Ô¨Årst accounts for more than 95%, the second less than 2%
and from the third onward, all factors are very near zero, see Fig 2.3 intuitively. The model of
four lags is also the same case no matter in mean or median even though the number of factor
candidates raising to 39, which can be directly observed in Fig 2.4. Models of two, three and four
lags share the same property that only the Ô¨Årst factor account for most and two or three together
for almost all the variation, while the model with one lag needs more factors where the tangent of
cumulative percentage curve in Fig 2.1 is less steeper than others in Fig 2.2 to Fig 2.4.
At least three Ô¨Åndings and implications can be derived. The Ô¨Årst, there are strong evidence of
factor driving of dynamic process in time varying coefÔ¨Åcients no matter in the model of one lag or
of four lags. This indicates that in a typical model settings of TVP-VARs, the number of dynamic
sources, also the same number of coefÔ¨Åcients should be dramatically reduced.
The second, following the Ô¨Årst, it further conÔ¨Årms researchers‚Äô concern that TVP-VAR is not
a parsimonious model even it is set in a small scale with short lags which are in line with Cogley
and Sargent (2005) and De Wind and Gambetti (2014). Small scale TVP-VAR models still need
factor-driven estimation.
The third, we Ô¨Ånd signiÔ¨Åcant difference in the style of factor driving in model of one lag and
model of more lags. In the context of the typical three observations, one-lag model needs more
factors than more-lag models and with the increase of the number of lags, the style of (almost)
one factor leading is consistent from two-lag model to four-lag model.8 The cosistency of one
factor driving means that the sources of variation in the model have been already fully identiÔ¨Åed,
implying that more than enough lags will cause serious over Ô¨Åtting. A reasonable explanation is
8We also tried lags more than four, the results are quantitatively the same.
100

that if a model does not have enough lags, its dynamic inter relationship among variables could be
messed up and the factors extracted from it distribute on a broad range (see again the left panel of
Fig 2.1) such that economic implication is difÔ¨Åcult to give, displaying merely some purely statistic
properties. Nevertheless, if with enough lags, two lags above, the inter relationship can be fully
released and expressed, therefore the factor driving analysis could imply some important structural
interpretation.9 If more than enough, since important factors have been fully extracted, naturally
serious over Ô¨Åtting will arise, comparing Fig 2.4 with Fig 2.2 on the right panel.
The above three variable empirical test consistently demonstrates that almost only one im-
portant force inÔ¨Çuence the dynamics of the economy, conÔ¨Årming again that there are much more
forces determining the economy than those changing the economy. The result of empirical test
is in line with dynamic stochastic general equilibrium model (DSGE). If a DSGE model can be
transfomed into a VAR form under some conditions (Fernandez-Villaverde et al. 2006, Morris,
2012 and Ravenna, 2007), the coefÔ¨Åcients on the regressors must be the functions of ‚Äòdeep param-
eters‚Äô of preference, technoloy and policy rule in the DSGE model and therefore the coefÔ¨Åcients
in the transformed VAR are cross equation restricted.10 Changes in one deep parameter will cause
changes in almost all the coefÔ¨Åcents in the VAR. This provides theoretical support for the results
of the above empirical test and recommend a factor-driven VAR model setting.
Since we Ô¨Ånd strong factor leading evidence, even in a small scale TVP-VAR, empirically and
theoretically, another question will be naturally asked can the model with factor driven speciÔ¨Åed
in section 2 be used in structrual economic analysis and is it consistent or inconsistent with the
literature. We answer these questions in the next subsection.
9The ‚Äòstructural interpretation‚Äô does not mean structural identiÔ¨Åcation associated with structural shocks in VARs.
It only mean several important factors already sufÔ¨Åciently drive the dynamic process of the economy.
10A general representation of a log-linearized DSGE model has a state space form. A state space corresponds to
a VARMA form (see, e.g., Aoki, 1990). But the VARMA does not necessarily can be transformed to a VAR form.
Fernandez-Villaverde et al. (2006) give the VAR(‚àû) expression for a DSGE under some conditions; Ravenna (2007)
for VAR(p) and Morris (2012) for VAR(1)under required conditions. Giacomini (2013) give a good literature review
on the relationship between DSGE and VAR models.
101

2.4.2
Structural analysis and model evaluation
The above empirical tests for the three variables model - inÔ¨Çation rate, unemployment rate and
3-month treasury rate - suggest that factors should be imposed on the time varying coefÔ¨Åcients
and two lags are enough for fully capturing the dynamic process in the data and therefore the time
variation in the latent coeffÔ¨Åcients. Since the empirical tests have already found that the factor
leading style for the Ô¨Årst lag is quite different with the style for from two to four lags, we can not
use early lags ‚Äì the Ô¨Årst lag and constant here ‚Äì to drive the remaining long lags. Hence the factor
settings on lags should be skipped under this empirical context.11
We implement the analysis in a model setting factors only on time varying coefÔ¨Åcients and
stochastic volatility. That is, we estimate the model only involving factors on coefÔ¨Åcients and
volatility, imposing no restriction on lags. As discussed in section 3, though the model gives a
general factor treatment to every part of TVP-VARs, where the factor restriction should be used
depends on the speciÔ¨Åc research object.
In this section we have two purposes. One is to investigate whether agents‚Äô responses to mone-
tary policy shocks have changed or not over sample period and the second is to evaluate the model
performance under different lag settings. The Ô¨Årst is to check after factor extracting whether the
model is still capable of structural analysis and the second is to check whether the model is Ô¨Çexible
enough to deal with the case when the extent of over Ô¨Åtting goes strong as the number of lags
incease.
These two are jointly conducted together. Our analysis is based on above empirical tests. Dates
chosen for comparison are 1975 Q1, 1981 Q3 and 1996 Q1. They are somewhat representative of
the typical economic conditions of the chairmanships of Burns, Volcker and Greenspan, but apart
from that, they are choosen arbitrarily. Enough number of factors is chosen for each model accord-
ing to Table 2.1 and Table 2.2 so as to avoid the potential concern that the bulk of variation not fully
captured by less than enough factors could affect inference and might lead wrong understanding.
11We have estimated the model of the factor settings on lags, namely the general factor-driven model presented in
section 2. The result is messy to conduct instructive analysis. A reasonable interpretation is that the dynamic inter
relationship among the variables has been distorted by the the constant and the Ô¨Årst lag.
102

3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
median IR of inflation to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.1
‚àí0.05
0
0.05
0.1
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.2
‚àí0.1
0
0.1
0.2
1996 Q1‚àí1975 Q1
Figure 2.5: TVP-VAR-CV-lag1-factor7-IR-inÔ¨Çation
Notes: This is TVP-VAR with 1 lag, 7 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of inÔ¨Çation to mone-
tary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot difference
of responses between every two periods mutually, with solid line representing median and dashed
lines for 16th percentile and 84th percentile respectively.
103

3
6
9
12
15
18
21
0
0.02
0.04
0.06
0.08
IR of unemployment to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.05
0
0.05
0.1
0.15
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.05
0
0.05
0.1
0.15
1996 Q1‚àí1975 Q1
Figure 2.6: TVP-VAR-CV-lag1-factor7-IR-unemployment rate
Notes: This is TVP-VAR with 1 lag, 7 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of unemployment rate
to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot
difference of responses between every two periods mutually, with solid line representing median
and dashed lines for 16th percentile and 84th percentile respectively.
104

3
6
9
12
15
18
21
‚àí0.06
‚àí0.04
‚àí0.02
0
median IR of inflation to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.02
‚àí0.01
0
0.01
0.02
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1‚àí1975 Q1
Figure 2.7: TVP-VAR-CV-lag2-factor3-IR-inÔ¨Çation
Notes: This is TVP-VAR with 2 lag, 3 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of inÔ¨Çation to mone-
tary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot difference
of responses between every two periods mutually, with solid line representing median and dashed
lines for 16th percentile and 84th percentile respectively.
105

3
6
9
12
15
18
21
‚àí0.05
0
0.05
0.1
0.15
IR of unemployment to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.02
‚àí0.01
0
0.01
0.02
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.02
0
0.02
0.04
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1‚àí1975 Q1
Figure 2.8: TVP-VAR-CV-lag2-factor3-IR-unemployment rate
Notes: This is TVP-VAR with 2 lag, 3 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of unemployment rate
to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot
difference of responses between every two periods mutually, with solid line representing median
and dashed lines for 16th percentile and 84th percentile respectively.
106

For model of one lag, we choose 7 factors since 7 factors can cover all the important factors
that together accounting for near 100% evidenced by Table 2.1 and Fig 2.1. In Fig 2.5 upper left
panel, we Ô¨Ånd strong ‚Äòprice puzzle‚Äô in each period respectively, a typical Ô¨Ånding in small scale
monetary VAR. The remaining three graphs show the median of the distribution of the difference
of inÔ¨Çation responses between every two periods mutually with lower 16th percentile and upper
84th percentile conÔ¨Ådence band. There are no signiÔ¨Åcant difference among three periods in that
every coÔ¨Ådence band contains a zero line. The response of unemployment rate increase, see Fig
2.6, in each period consistent with economic theory. The difference of unemployment responses
between every two periods are not signiÔ¨Åcant with zero. As for the model with two lags, we
choose 3 factors in order to cover as much time variation as possible even though the Ô¨Årst factor
has already taken 96% seen in Table 2.1. The price puzzle disappears, in Fig 2.7, for each period;
InÔ¨Çation decline after positive monetary policy shock. The difference of inÔ¨Çation responses every
two periods is not signiÔ¨Åcant in the remaining panel. Unemployment rate increase in each period
and no signiÔ¨Åcant difference mutually in Fig 2.8. When the model goes from 2 lags to 3 lags with
the same 3 factors as they have the same factor driving style, we Ô¨Ånd that, in both Fig 2.9 and
Fig 2.10, the results are almost the same: inÔ¨Çation went down and unemployment went up each
period, and the dynamic process in each response function is signiÔ¨Åcantly no difference. Though
the model is of more over-parameterization, the parsimonious estimation of factor driving gives the
qualitatively and quantitatively the same results. How about the model of four lags when it become
further over-Ô¨Åtting with 39 coefÔ¨Åcients? We assign again 3 factors and still Ô¨Ånd the qualitatively
and quantitatively the same results in Fig 2.11 and Fig 2.12.12
The common volatility for each model in Fig 2.13 illustrates almost the same dynamic property
of the U.S. business cycle. The level of commom volatility was climbing during the 1970s up to the
peak in early 1980s during which Fed Chairman Volcker implemented monetary targeting policy,
after that from middle 1980s the volatility declined and stayed on a low level in a whole 1990s and
12We assign 3 factors to the portion of time varying coefÔ¨Åcients for models of 3 lags and 4 lags in order to make
sure most amount of variation can be covered. Actually, one factor for 2 lags, 3 lags and 4 lags already works well
respectively.
107

3
6
9
12
15
18
21
‚àí0.1
‚àí0.08
‚àí0.06
‚àí0.04
‚àí0.02
0
median IR of inflation to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.01
0
0.01
0.02
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.02
‚àí0.01
0
0.01
0.02
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1‚àí1975 Q1
Figure 2.9: TVP-VAR-CV-lag3-factor3-IR-inÔ¨Çation
Notes: This is TVP-VAR with 3 lag, 3 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of inÔ¨Çation to mone-
tary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot difference
of responses between every two periods mutually, with solid line representing median and dashed
lines for 16th percentile and 84th percentile respectively.
108

3
6
9
12
15
18
21
‚àí0.1
0
0.1
0.2
0.3
IR of unemployment to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.02
‚àí0.01
0
0.01
0.02
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.02
0
0.02
0.04
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1‚àí1975 Q1
Figure 2.10: TVP-VAR-CV-lag3-factor3-IR-unemployment rate
Notes: This is TVP-VAR with 3 lag, 3 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of unempoyment rate
to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot
difference of responses between every two periods mutually, with solid line representing median
and dashed lines for 16th percentile and 84th percentile respectively.
109

3
6
9
12
15
18
21
‚àí0.2
‚àí0.15
‚àí0.1
‚àí0.05
0
median IR of inflation to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.02
0
0.02
0.04
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.05
0
0.05
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1‚àí1975 Q1
Figure 2.11: TVP-VAR-CV-lag4-factor3-IR-inÔ¨Çation
Notes: This is TVP-VAR with 4 lag, 3 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of inÔ¨Çation to mone-
tary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot difference
of responses between every two periods mutually, with solid line representing median and dashed
lines for 16th percentile and 84th percentile respectively.
110

3
6
9
12
15
18
21
‚àí0.1
0
0.1
0.2
0.3
IR of unemployment to MP shocks
 
 
1975 Q1
1981 Q3
1996 Q1
3
6
9
12
15
18
21
‚àí0.05
0
0.05
1981 Q3 ‚àí 1975 Q1
3
6
9
12
15
18
21
‚àí0.05
0
0.05
1996 Q1 ‚àí 1981 Q3
3
6
9
12
15
18
21
‚àí0.04
‚àí0.02
0
0.02
0.04
1996 Q1‚àí1975 Q1
Figure 2.12: TVP-VAR-CV-lag4-factor3-IR-unemployment rate
Notes: This is TVP-VAR with 4 lag, 3 factors driving time variation in coefÔ¨Åcients on regressors
and common volatility. The upper left panel plots median impulse responses of unemployment rate
to monetary policy shocks in 1975 Q1, 1981 Q3 and 1996 Q1. The remaining three panels plot
difference of responses between every two periods mutually, with solid line representing median
and dashed lines for 16th percentile and 84th percentile respectively.
111

1970
1980
1990
2000
0.4
0.6
0.8
1
vol (1 lags‚àí7 factors)
1970
1980
1990
2000
0.4
0.6
0.8
1
vol (2 lags‚àí3 factors)
1970
1980
1990
2000
0.4
0.6
0.8
1
vol (3 lags‚àí3 factors)
1970
1980
1990
2000
0.4
0.6
0.8
vol (4 lags‚àí3 factors)
Figure 2.13: Common volatility in different model settings
early 2000s, then gradully increased at the end of the sample.
Connecting the above analysis together, we Ô¨Ånd that i) in the model of one lag even with enough
7 factors capturing almost all the variation in coefÔ¨Åcients, we still Ô¨Ånd price puzzle. As discussed
in empirical test via principal component analysis, one lag can not sufÔ¨Åciently release and probably
distort the dynamic inter relationships among variables. This is a problem of lags, not a problem
of factor driving. Therefore, using the Ô¨Årst lag to drive the other lags is not a good choice. ii)
When having enough lags and even more lags to make the model more over parameterization, the
factor driving model works very well on every setting, giving almost the same results on impulse
response function and volatility. All these fully demonstrate that the factor-driven model is Ô¨Çexible
enough to capture main driving forces and give consistent interpretation in the context of the model
with over-Ô¨Åtting problem, especially when the extent of over parameterization is very serious (the
model with 4 lags).
112

2.5
Concluding remarks
In this chapter, we present a model that gives a general treatment via factor driving on the three
parts of conventional TVP-VAR model, namely, the part of time varying coefÔ¨Åcients on regressors,
the part of lags and the part of stochastic volatility. These three portions are sources of parameter
proliferation. The general model uses several factors to drive the dynamic process of all the time
varying coefÔ¨Åcients; uses the Ô¨Årst several lags to drive other remaining lags; and uses a latent factor
to drive the volatilities of all variables, i.e. the common volatility. These factor drivings can be
jointly or separately used depending on speciÔ¨Åc object one meets.
We also provide a Bayesian estimation procedure on this general model step by step, which
can be nested, divided and modiÔ¨Åed according to the factor driving portion one needs.
We Ô¨Ånally conduct an empirical analysis on the typical small scale monetary TVP-VAR. Strong
evidences of over parameterization are found over one lag to four lags. This is the starting point
of our general parsimonious treatment of the standard TVP-VAR model. Empirical analysis shows
that the factor-driven model is strong enough and Ô¨Çexible enough to capture the main driving forces
even in a serious over-Ô¨Åtting setting and still give consistent results.
A point should be pointed out is that the factor-idea-based model must stand on the precondition
that the dynamic process among data set is correctly expressed. If not, the model is estimable, but
not instructive.
The future research could be applying the model to large data set or conducting forecasting
exercise.
113

Appendix
A. Bayesian estimation of restricted linear regression model
Here, we consider a multivariate linear regression case.
Consider that the linear regression model has the form:
yt = XtŒ≤ +ut
where yt is an n√ó1 vector of regressands, Xt is n√ók matrix of regressors, Œ≤ is k√ó1 corresponding
parameters and ut ‚àºN (0,Œ£t). Stacking the above equation over time periods and holding all the
data together, one can obtain
y = XŒ≤ +u
where y =
h
y
‚Ä≤
1,....y
‚Ä≤
T
i‚Ä≤
, X =
h
X
‚Ä≤
1,...,X
‚Ä≤
T
i‚Ä≤
and u =
h
u
‚Ä≤
1,...,u
‚Ä≤
T
i‚Ä≤
with u ‚àºN (0,‚Ñ¶) and ‚Ñ¶=
Blkdiag

{Œ£t}T
t=1

.
We Ô¨Årst consider Bayesian estimation of unrestricted linear regression model. Set prior for Œ≤:
Œ≤ ‚àºN

Œ≤,V Œ≤

(2.36)
then the posterior is
Œ≤ ‚àºN
  ¬ØŒ≤, ¬ØVŒ≤

with
¬ØŒ≤ = ¬ØVŒ≤

X
‚Ä≤‚Ñ¶‚àí1y+V ‚àí1
Œ≤ Œ≤

(2.37)
¬ØVŒ≤ =

X
‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤
‚àí1
(2.38)
114

Now consider linear restriction on coefÔ¨Åcients
RŒ≤ = 0
(2.39)
where R is a q √ó k matrix with rank(R) = q and q ‚â§k. The posterior of Œ≤ can be derived by
pooling the linear regression model, the prior information and the linear restriction condition above
together:
y = XŒ≤ +u
(2.40)
Œ≤ = Œ≤ +v
(2.41)
0 = RŒ≤ +Œ∑
(2.42)
where v ‚àºN(0,V Œ≤) and Œ∑ ‚àºN
 0, 1
Œª Iq

. Equation (2.41) is prior inforamtion in equation (2.36)
and equation (2.42) is linear restriction of (2.39) when Œª ‚Üí‚àû. The posterior of restricted Œ≤ for a
given Œª can be obtained by conducting generalized least square estimation of the pooled regression
model (2.40) - (2.42):
Œ≤res (Œª) ‚àºN

ÀúŒ≤ (Œª), ÀúV(Œª)

with
ÀúŒ≤ (Œª) =

X
‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤ +ŒªR
‚Ä≤R
‚àí1 
X
‚Ä≤‚Ñ¶‚àí1y+V ‚àí1
Œ≤ Œ≤

(2.43)
ÀúV (Œª) =

X
‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤ +ŒªR
‚Ä≤R
‚àí1
(2.44)
Following De Wind and Gambetti (2014), (2.44) is further expanded, by matrix inversion lemma,
to13
ÀúV (Œª) =

X‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤
‚àí1
‚àí

X‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤
‚àí1
R‚Ä≤

Œª ‚àí1Iq +R

X‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤
‚àí1
R‚Ä≤
‚àí1
R

X‚Ä≤‚Ñ¶‚àí1X +V ‚àí1
Œ≤
‚àí1
13Matrix inversion lemma: (A+BCD)‚àí1 = A‚àí1 ‚àíA‚àí1B
 C‚àí1 +DA‚àí1B
‚àí1 DA‚àí1
115

Since equation (2.37) and equation (2.38), posterior of Œ≤res (Œª) for a given Œª can be expressed in
terms of unrestricted posterior of Œ≤:
ÀúŒ≤ (Œª) =

Ik ‚àí¬ØVŒ≤R
‚Ä≤ 
Œª ‚àí1Iq +R ¬ØVŒ≤R
‚Ä≤‚àí1
R

¬ØŒ≤
ÀúV (Œª) =

Ik ‚àí¬ØVŒ≤R
‚Ä≤ 
Œª ‚àí1Iq +R ¬ØVŒ≤R
‚Ä≤
R

¬ØVŒ≤
With above prepared expression, letting Œª ‚Üí‚àû, the posterior of Œ≤res follows
Œ≤res ‚àºN

ÀúŒ≤res, ÀúVres

with
ÀúŒ≤res =

Ik ‚àí¬ØVŒ≤R
‚Ä≤ 
R ¬ØVŒ≤R
‚Ä≤‚àí1
R

¬ØŒ≤
ÀúVres =

Ik ‚àí¬ØVŒ≤R
‚Ä≤ 
R ¬ØVŒ≤R
‚Ä≤‚àí1
R

¬ØVŒ≤
and ¬ØŒ≤ is from (2.37), ¬ØVŒ≤ from (2.38).
116

Chapter 3
Structual Analysis in a Large Bayesian VAR
117

3.1
Introduction
In previous two chapters, We have studied time-varying parameters vector autoregressive regres-
sion models with stochastic volatility or common volatility. As we know that vector autoregessive
models are unrestricted models and relatively easily tractable with good properties such as impulse
response function and variance decompositon for the future dynamics or historical decomposition
for the past, therefore it is widely used by practioners, reseachers and policy-makers in economic,
policy ananlysis and forecasting. In addition, since endogenous variables in a vector inter act
each other that can capture very complicated relationships in an economy which economists are
interested in, and most importantly some of the relationship among those variabes are still vague,
disputable or even unknown, such as typiclly the effects of monetary policy on the performance
of economy, the relationship between Ô¨Ånancial market and real economy, and recently the uncer-
tainty shocks that is paid more and more attention after global Ô¨Ånancial crisis of 2008 and in the
subsequent still slow recovery, VARs are used again and again to Ô¨Ånd inner possible relationships
that have not been explored by theoretical models and thus VARs are also good instructions for the
direction of theoretical analysis.
Nevertheless, everything has its two sides. VAR is not a parsimonious model due to its unre-
stricted structures that are very suitable to expose blackboxes in economy but it is hard to estimate
in parctice when the number of observations in a vector increase. Its advantege cause its disad-
vantage. Typically, in empirical analysis, a VAR has three or Ô¨Åve, at most ten variables, but seen
otherwise without any restrictions, no matter in static VAR models or TVP-VAR models as we
have discussed in the previous chapers. Chapter 1 focuses on the signiÔ¨Åcance of the time varying
parameters over each identity and each time via stochastic variable selection and provide a method
to estimate them efÔ¨Åciently in practice; Chapter 2 lies in reducing dimension of the TVP-VAR with
SV via factor idea. Namely, we use factors to represent and reduce number of lags, coefÔ¨Åcients on
regressors and volatilities in order to make a parsionious estimation with potentional over-Ô¨Åtting
problem. That is different with the ever increasing literature that mainly on reducing the dimension
of obsevations when one meet rich data enviroment such as facor models begining with Geweke
118

(1977) and factor augmented VAR recommended by Bernake, Boivin and Eliasz (2005) and Stock
and Watson (2005).
In this chapter, we still look at vector autoregressive models in constant parameters, rather than
time variant, discussed in Chapter 1 and Chapter 2. The VAR model with constant parameters
probably is the most widely used one in paractise. Economist and practioners have again and agian
proved that VARs with constant parameters still do a good job in economic analysis, policy mak-
ing and forecasting compared to other type of VARs like TVP-VAR or regime switching VAR.
Banbura, Giannone and Reichlin (2010) argue that vector regression with Bayesian shrinkage is
an appropriate tool for large dynamic models. Building on the results of De Mol and co-authors
(2008), they show that when the degree of shrinkage is set in relation to the cross-sectional dimen-
sion, the forecasting performance of small monetary VARs can be improved by adding additional
maroeconomic variables and sectoral information. In addition, VARs with shrinkage produce cred-
ible impulse responses and are suitable for structural analysis.
Small VARs have the limitation that the information incorporated in the model is very small,
while in real economic world, we have hundreds of maroeconomic data published by governtment
agency and research institution. For example, central banks usually obseve and investigate a large
amount of data in decision making of their policy; Economic agency in an economy can not deter-
mine their Ô¨Ånal behavior within small number of observations. A small information-involved VAR
sometimes cause misleading and misunderstanding, a typical case is of ‚Äòprize puzzle‚Äô due to the
missing of forward looking variables in VAR analysis. However, if a VAR with more variables will
inevitably lead parameter proliferation. As suggested by Banbura et al. (2010), the way to deal
with the problem is to impose proper priors of shrinkage on the parameters. On the priors with
property of shrinkage, the parameters that are important for the variables will be strenghen while
less important will shrink to zero or a limit value.
Follwing Banbura et al. (2010) with proper priors, we conduct an empirical analysis on three
important shocks: monetary policy shock, uncertainty shock and Ô¨Ånancial shock. Monetary pol-
icy shock and its transmission mechanism, as we known, are very important to central banks and
119

economic agencies. It reÔ¨Çects central banks‚Äô stance to the current economic performance and what
kind of policy they conduct, and meanwhile how agencies react to such stance and policy imple-
mentaion. The second - uncertainty shocks and the third - Ô¨Ånancial shocks recently are more and
more jointly considered, in paticular, in the current situation of slow recovery. Researchers Ô¨Ånd
that uncertainty and Ô¨Ånancial market are strongly tangled each other. They are both channels and
shocks. They are both potentially important drivers in business cycle and display strong nonlinear-
ity in different economic stages. We use a large data set which contains 28 variables that cover a
broad range of an economy such as goods market, labor market, Ô¨Ånancial market and so on. By
the large VAR, we jointly identify and investigate the three shocks and their transmisson. We Ô¨Ånd
some interesting results via Bayesian estimation with shrinkage priors.
This chapter is organized as follows. In the second section, we discuss some issues on the large
Bayesian VAR and the inter relationship among Ô¨Ånancial market, uncertainty and monetary policy.
In section 3, we give the theoretical background of the prior on shrinkage, model speciÔ¨Åcation and
posterior in terms of large cross-sectional data set. Section 4 conducts empirical analysis and gives
some important Ô¨Åndings we obtain and implications we infer from the large Bayesian VAR. The
last section concludes.
3.2
The literature
In this section, some issues will be discussed in current literature on the model and on the shocks
and their transmission, respectively.
We Ô¨Årst look at the model.
In econometric literature on VAR models, a very important issue is how to deal with the po-
tential over parameterization problem inherited in VARs and the accessibility of high dimensional
data set. This two typically join togther. Researchers would like to include more observations
in the dynamic model in order to expose and explore complicated inner relationships that samll
scale model is unable to do, at the same time if more variables are incorporated, the number of
120

parameters will nonlinearly, dramatically proliferate, making the estimation and inference infeasi-
ble even large data is availabe. Generally, there are three branches in dealing with this dilemma.
One is on reducing data dimension by factors. Since the Geweke (1977), factor modes have been
the most common way of achieving this goal. Applications such as Forni and Reichlin (1998),
Stock and Watson (1999, 2002b), Bernake and Boivin (2003), have popularized factor methds
among macroeconomists. Bernake, Boivin and Eliasz (2005) and Stock and Watson (2005) have
combined factor methods with VAR methods. Del Negro and Otrok (2008) and Korobilis (2013a)
provide further time varying parameter extension to these models. The second is on lowering
the dimension of parameters of the model still using the factor idea. Indeed, factors that drive
large observations can substantially limit the over-Ô¨Åtting problem, which is specially prominent in
constant-parameter VARs, however, when it comes to time varying ones, the number of parame-
ters in the case of constant-paramer model will be multiplied by the periods of sample size. The
number of parameters again becomes very large even in a small scale TVP-VAR as discussed in
Chapter 2. To deal with the problem, Kim and Yamamoto (2012) use coefÔ¨Åcients on recent lags
as factors to drive distant lags; De Wind and Gambetti (2014) decompose the covariance matrix of
innovations to time varying parameters and extract several factors to drive whole dynamic process
of all the time varying coefÔ¨Åcients. Note that the covariance matrix associated with the parame-
ters become reduced rank; Carriero, Clark and Marcellino (2012) present a model applying latent
factor, i.e. common volatility to represent fully stochatic volatility on each variable justÔ¨Åed by the
observation that most maroeconomic variables share very similar pattern of estimated volatility.
They are all trying to limit parameter dimension in the context of time varying coefÔ¨Åcient fram-
work. The last is on shrinking the parameters via imposing priors. Probably the most classic one
is Minnesota prior (see Doan, Litterman and Sims, 1984 and Litterman, 1986). The basic idea of
the prior is that it makes model implement like a random walk process. There are also other priors
on stochastic search variable selection (SSVS) (see George, Sun and Ni, 2008). This paper focuses
on the third branch, namely, setting suitable priors to shrink the parameters of the large VAR via
Bayesian method. For the Ô¨Årst and the third branch, Koop and Korobilis (2010) have given a good
121

survey on them.
The second issue is about the empirical analysis. Here, we discuss Ô¨Ånancial market and uncer-
tainty jointly. The literature has identiÔ¨Åed at least three channels through which uncertainty shocks
impose impact on economic activity. First, unceratin can affect the behavior of Ô¨Årms (Bernake,
1983; Bloom, 2009). A key concept in this framwork is irreversibility in investment. If invest-
ment decisions are irreversible, Ô¨Årms must take investment decisions that trade of the extra returns
from early commitment agianst the beneÔ¨Åt of having more informatioin by waiting. Bernake‚Äôs real
options framwork captures the notion that when uncertainty is high, the option value of waiting
increases as it may be beneÔ¨Åcial for Ô¨Årms to wait and acquire more information before deciding
to invest in a real asset. The second, higher uncertainty may induce households to save more as
higher uncertainty about future income will delay consumer spending, in particular on durable
goods (Romer, 1990). The last channel is via Ô¨Ånancial maket for which a more recent strand of
research places Ô¨Ånancial rather than real frictions at the center of the transmission mechanism
(Arellano et al., 2012; Christiano et al., 2014; Gilchrist et al., 2014). If Ô¨Ånancial contracts are
subject to agency problem or moral hazard probem, a rise in economic uncertainty increase the
premium on external Ô¨Ånance, leading to an increase in the cost of capital faced by Ô¨Årms or borrow-
ers and thus a fall in investment. These three channels mixed together, especially the last channel
makes that uncertainty and Ô¨Ånancial market should be considered together.
In empirical works, Beetsma and Giuliodori (2012) use linear VARs via rolling windows and
show that the impact of uncertainty shocks on output in the US has decreased over the last Ô¨Åve
decades. Hartmann et at. (2012) use a regime switch (with Ô¨Åxed probability) model to estimate
the links between Ô¨Ånancial stress and macroeconomic variables. They Ô¨Ånd that Ô¨Ånancial shocks
have more serious impact on real variables in high Ô¨Ånancial stress regime than in normal times.
Bijsterbosch and Guerin (2014) also use a regime swithing model to study regime-dependent re-
lationship between uncertainty and economic activity. They Ô¨Ånd that only the third regime - the
highest uncertainty regime are associated with a weaker growth performacne and sharp decline in
stock price.
122

Caggiano et al. (2014) use instead a smooth - transition VAR (with continous probability)
where parameters are allowed to depend on the state of the business cycle. They Ô¨Ånd that, using
U.S. quarterly post-war data, uncertainty shocks have a stronger impact on unemployment during
recessions. The above researches only independently study the uncertainty or Ô¨Ånancial conditions,
not jointly together. It is crucial if the ‚ÄòÔ¨Ånancial view‚Äô of the third channel discussed above plays
a very important role. To our best knowledge, the Alessandri and Mumtaz (2014) probably the
Ô¨Årst to study the joint relationship of uncertainty and Ô¨Ånancial condition to check the importance
of the ‚ÄòÔ¨Ånancial view‚Äô in literature. Their model is very innovative in twofolds. First, the effects
of uncertainty is dependent on the different Ô¨Ånancial conditions which is determined by a threhold
variable that represents Ô¨Ånancial conditions on different stage rather than business cycle stages
deÔ¨Åned by NBER. Second, the uncertainty is generated endogenously from the common stachastic
volatility as we discussed in Chaper 2 and the common volatility can be regarded as uncertainty
proxy that is placed in the regressor, then the volatility generated from the model itself have the
effects on the endogenous variables. This model is so called volatility in mean. The idea of using a
single volatility process in a multivariate model has been introduced by Carriero et al. (2012) while
volatility in mean effects are studied in the context of otherwise linear VAR models by Mumtaz
and Thedoridis (2012), Mumtaz and Surio (2013) and Mumtaz and Zanetti (2013).
The above linear or nonliner VAR models as tool to study uncertainty and Ô¨Ånancial market
jointly or indepently all belong to small scale VAR models. Caggiano et al. (2012) have four
variables, namely the uncertainty proxy of VIX index and inÔ¨Çation, umeployment and federal
funds rates. Alessandri and Mumtazi (2014) also use four variables including a Ô¨Ånancial condition
proxy. Bloom (2009), perhaps the most, contained eight observations. Except for the Banbura et al.
(2010), large Bayesian VAR models are seldom used in structual analysis though recommended
by them in terms of large information of great view. We only Ô¨Ånd three works related with it.
Gupta et al. (2012) study the effects of monetary policy on housing sector dynamics in a large
sacle Bayesian VAR with 143 monthly macrovariables. Auer (2014) consider another direction of
monetary policy shock on foreign investment income from a large VAR with 32 variables. Sanjani
123

(2014) use quarterly data of 34 variables to study Ô¨Ånancial frictions. In this chapter, we use a
large data set of 28 observables to jointly identify and analyse the effect of each structual shock
on different dimension of the U.S. economy. In the next section, the large Bayesian VAR model is
presented and the priors on shrinkage are discussed.
3.3
The model
3.3.1
The likelihood of VAR
Let‚Äôs consider a VAR model with p lags. It can be typically written as
yt = c+B1yt‚àí1 +¬∑¬∑¬∑+Bpyt‚àíp +ut
(3.1)
where yt is an n √ó 1 vector containing n endogenous observations; c is also n √ó 1 constant term;
coefÔ¨Åcients on lags are from B1 to Bt‚àíp with corresponding dimension n √ó n and ut is residual
follows ut ‚àºiddN (0,Œ£). The above equation is the expression for each period, it can be rewritten
in the form of nesting all the data, that is in a compact form
Y = XB+U
(3.2)
where equation (3.2) is obtained with matrices xt =
h
y
‚Ä≤
t‚àí1,...,y
‚Ä≤
t‚àíp,1
i‚Ä≤
, then the X = [x1,...,xT]
‚Ä≤
and accordingly B = [B1,...,Bt‚àíp,c]
‚Ä≤ as well as U = [u1,...,uT]
‚Ä≤. By column stacking operator of
both sides of equation (3.2), we further have the form
y = (In X)Œ≤ +u
(3.3)
where y = vec(Y), Œ≤ = vec(B), u = vec(U) and u ‚àºN (0,Œ£IT) with vec column stacking op-
erator and  Kronecker product. The regressors in the brackets are obtained by vec(X ¬∑ B ¬∑ I).1
1vec(ABC) =

C
‚Ä≤ A

vec(B)
124

Note that y = [y1;...;yn] where yi is a T √ó1 vector collecting all observations belonging to i, there-
fore y is a Tn √ó 1 column. u has the similar structure as y. The likelihood of (3.3) based on the
multivariate normal distribution of u is written as
f (y|Œ≤,Œ£) ‚àù|Œ£|
T
2 exp
1
2u
‚Ä≤ (Œ£IT)‚àí1 u

by the transformation formula tr(ABC) = vec

A
‚Ä≤‚Ä≤
(I B)vec(C), the above is equal to
f (y|Œ≤,Œ£) ‚àù|Œ£|
T
2 exp
1
2tr

(Y ‚àíXB)
‚Ä≤ (Y ‚àíXB)Œ£‚àí1
(3.4)
The above likelihood after leaving out the constant term that does not affect Ô¨Ånding distribution
kernels, can be decomposed into two components: f (Œ≤|Œ£,y) and f (Œ£|y). The former follows
multi-variate normal distribution and the latter follows inverse wishart distribution. By the equation
that (Y ‚àíXB)
‚Ä≤ (Y ‚àíXB) =
 Y ‚àíX ÀÜB
‚Ä≤  Y ‚àíX ÀÜB

+
  ÀÜB‚àíB
‚Ä≤
X
‚Ä≤X
  ÀÜB‚àíB

, where ÀÜB =

X
‚Ä≤X
‚àí1
X
‚Ä≤Y
is the least square estimate of B, equation (3.4) gives
f (y|Œ≤,Œ£) ‚àù|Œ£|‚àík
2 exp

‚àí1
2tr
  ÀÜB‚àíB

X
‚Ä≤X
  ÀÜB‚àíB

Œ£‚àí1
(3.5)
|Œ£‚àíT‚àíK
2 |exp

‚àí1
2tr
 Y ‚àíX ÀÜB
‚Ä≤  Y ‚àíX ÀÜB

Œ£‚àí1
(3.6)
the Ô¨Årst equation (3.5) is the kernel of the matrix normal distribution and the second (3.6) is the
kernel of the inverse wishart distribution. It is more convenient to rewrite the matrix normal distri-
bution in terms of the multivariate normal distribution, so that
Œ≤|Œ£,y ‚àºN

ÀÜŒ≤,Œ£

X
‚Ä≤X
‚àí1
(3.7)
Œ£|y ‚àºIW
  ÀÜS,T ‚àík ‚àín‚àí1

(3.8)
125

where ÀÜŒ≤ = vec
  ÀÜB

, ÀÜS =
 Y ‚àíX ÀÜB
‚Ä≤  Y ‚àíX ÀÜB

and k = np+1
From the above derivation, we know that the likelihood function of a VAR is a product of two
conditional distributions.
3.3.2
The priors
First we introduce the Minnesota prior. The basic idea of Minnesota prior is that all the equations
are ‚Äòcentered‚Äô around the random walk with drift, which means that Yt = c+Yt‚àí1 +ut. This means
diagonal of B1 shrink to one and the remaining elements of coefÔ¨Åcient matrix from B1 to Bp
towards to zero. Any element of coefÔ¨Åcient matrices independently follows a normal distribution
satisfying the moment conditions
E
h
(Bk)i j
i
=
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Œ¥i,
j = i,k = 1
0
otherwise
(3.9)
V
h
(Bk)i j
i
=
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Œª 2
k2 ,
j = i
ŒΩ Œª 2
k2
œÉ2
i
œÉ2
j ,
otherwise
(3.10)
which reÔ¨Çects that diagonal elements of coefÔ¨Åcient matrix on the Ô¨Årst lag centered on Œ¥i. If Œ¥i
shrinks to 1, it is random walk; If Œ¥i converges to0, it is white noise. The diagonal covariance
matrix V on each Bk implies two beliefs that more recent lags are more important than more
distant lags which can be seen that as k ‚Üíp, the magnitude of the variance, i.e. the range of
Ô¨Çucuation become narrower and narrower and accordingly coefÔ¨Åcients on far lags shrink more
quickly to zero and that own lags of a variable have more powerful interpretation than foreign lags
which can be found on the value of ŒΩ ‚àà(0,1). In the original version of Minnesota prior, it has
a hyper parameter to control tightness on each line of (3.10). In Banbura et al. (2010), the hyper
parameter on the Ô¨Årst line has been normalized, therefore ŒΩ takes the range. We follow the way of
Banbura. Finally, let‚Äôs look at the Œª which controls the overall tightness of the prior distribution.
126

The Œª shows up on both lines of (3.10), which means that as Œª ‚Üí0, the posterior is equivalent
to the prior and the data is perfectly dominated by prior information; when Œª ‚Üí‚àû, the very Ô¨Çat
prior, then the posterior equals likelihood and prior plays no role. De Mol et al. (2008) show that
the parameters should be shrunk more so as to alleviate over-Ô¨Åtting when the number of variables
increases. œÉ2
i /œÉ2
j shows the scale and variability of the data. These values can be set by residual
variance on AR(p) regression on each variable in a large data set.
The original Minnesota prior assumes that covariance matrix Œ£ of ut is Ô¨Åxed and diagonal. If
one is interested in structural analysis, Œ£ should be imposed as a full matrix to allow for possible
correlation among residual of different variables. To overcome the problem, following Kadiyala
and Kalsson (1977), Banbura et al. (2010) impose a normal inverse wishart prior on (Œ≤,Œ£) under
the condition that ŒΩ = 1. This prior can retain the principles of the Minnesota prior. The normal
inverse wishart prior has the form
vec(B)|Œ£
‚àº
N (vec(B0),Œ£‚Ñ¶0)
(3.11)
Œ£
‚àº
IW (S0,Œ±0)
(3.12)
Since (3.7) and (3.8) are also the same distributions, the product of (3.11) and (3.12) is the like-
lihood of prior information. By this link, imposing prior on likelihood is equivalent to adding
dummy observations to the original data set which demonstrates the advantage of natural con-
jugate prior of normal inverse wishart prior. Following (3.7) and (3.8), the prior parameters B0,
‚Ñ¶0, S0 and Œ±0 can be expressed by dummy observations: B0 =

X
‚Ä≤
dXd
‚àí1
X
‚Ä≤
dYd, ‚Ñ¶0 =

X
‚Ä≤
dXd
‚àí1
,
S0 = (Yd ‚àíXdB0)
‚Ä≤ (Yd ‚àíXdB0) and Œ±0 = Td ‚àík ‚àín‚àí1 where k = np+1.
It can be shown that the dummy variables Xd and Yd involving Minnesota moments of (3.9) and
127

(3.10) are
Yd =
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
diag(Œ¥1œÉ1,...,Œ¥nœÉ)/Œª
0n(p‚àí1)√ón
¬∑¬∑¬∑
diag(œÉ,...,œÉn)
¬∑¬∑¬∑
01√ón
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
Xd =
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
Jp  diag(œÉ1,...,œÉn)/Œª
0np√ó1
...
0n√ónp
0n√ó1
...
01√ónp
Œµ
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
where Jp = diag(1,2,..., p).
We also include an additonal prior, which implements a so-called ‚Äôinexact differencing‚Äô of the
data. More preciselty, rewrite the VAR equation (3.1) in an error correction form:
‚ñ≥yt = c+Œ†yt‚àí1 +B‚ãÜ
1‚ñ≥yt‚àí1 +¬∑¬∑¬∑+B‚ãÜ
p‚àí1‚ñ≥yt‚àíp+1 +ut
where B‚ãÜ
s = ‚àíBs+1 ‚àí¬∑¬∑¬∑‚àíBp, s = 1,..., p‚àí1 and Œ† = B1 +¬∑¬∑¬∑+Bp ‚àíIn.
A VAR in Ô¨Årst difference implies the restriction Œ† = 0 or A1 +¬∑¬∑¬∑+Ap = In. We follow Doan
et al. (1984) and set a prior that shrinks Œ† to zeros. Specially, we set a prior that is centered at 1 for
sum of coefÔ¨Åcients on the own lags for each variable, and at 0 for the sum of coefÔ¨Åcients on other
variables‚Äô lags. This prior introduces correlations among the coefÔ¨Åcients on each variable in each
equation. The tightness of this prior on the sum of ‚ÄòcoefÔ¨Åcients‚Äô is controlled by the hyparameter
œÑ. As œÑ goes inÔ¨Ånity, the prior becomes diffuse, whereas as it goes to zero, we approach the case
of exact differencing, which implies the presence of a unit root in each equation. In the literature,
it is usually implemented by adding the following dummy observations:
128

Y ‚ãÜ
d = diag(Œ¥1¬µ1,...,Œ¥n¬µn)/œÑ
(3.13)
X‚ãÜ
d =
  11√óp

 diag(Œ¥1¬µ1,...,Œ¥n¬µn)/œÑ
0n√ó1

(3.14)
The incorporation of this sum of coefÔ¨Åcients prior serves to increase accuracy of forecast and
avoid conÔ¨Ådence band explosiveness in long horizons for impulse response functions.
3.3.3
The posterior
As discussed above, implementation of priors is equivalent to adding dummy observations trans-
formed from priors, now the equation (3.2) is augmented to
Y ‚ãÜ= X‚ãÜB+U
(3.15)
where T ‚ãÜ= T +Td +T ‚ãÜ
d , Y ‚ãÜ=

Y
‚Ä≤,Y
‚Ä≤
d,Y ‚ãÜ‚Ä≤
d
‚Ä≤
and X‚ãÜ=

X
‚Ä≤,X
‚Ä≤
d,X‚ãÜ‚Ä≤
d

with Td = n(p+1)+1, T ‚ãÜ
d = n.
To ensure the existence of the prior expectation of Œ£, it is necessary to add an improper prior
Œ£ ‚àº|Œ£|‚àí(n+3)/2. After that the posterior has the form
vec(B)|Œ£,Y ‚àºN

vec

ÀúB,Œ£

X‚ãÜ‚Ä≤X‚ãÜ‚àí1
Œ£|Y ‚àºIW
 ÀúŒ£,Td +T ‚ãÜ
d +2+T ‚àík

where ÀúB =

X‚ãÜ‚Ä≤X‚ãÜ‚àí1
X‚ãÜ‚Ä≤Y ‚ãÜand ÀúŒ£ =
 Y ‚ãÜ‚àíX‚ãÜÀúB
‚Ä≤  Y ‚ãÜ‚àíX‚ãÜÀúB

which are typical setting for normal
inverse wishart distribution as seen in (3.7) and (3.8).
3.4
Empirical analysis
In this section, we apply the large Bayesian VAR model with priors of shrinkage to a large data set
which contains 28 variables covering a broad range of the U.S. economy. We focus three shocks
which are monetary policy shocks, uncertainty shocks and Ô¨Ånancial shocks.
129

3.4.1
The data
Since large Bayesian VAR with proper shrinkage priors is able to deal with large data set, the
whole information in the data can be directly used to explore complicated dynamic process among
different variables avoiding possible missing variable bias. Following Sanjani (2014), we select 28
variables that generally can give a comprehensive description of the economy of U.S.
This data covers labor market, housing market, labor market, government bonds market, cor-
porate bonds market and so on. To identify uncertainty shock and Ô¨Ånancial shock, we include
VIX index proxy for uncertainty measure and Chicago Fed national Ô¨Ånancial condition index for
Ô¨Ånancial condition measure.
As for uncertaity, three types of measure can be found: Ô¨Ånancial market indicators, survey
based measures including forecast dispersion measures and media measures based on the number
of citations of a speciÔ¨Åc term. Other measures are more microeconomic in nature and based on
various indicators of dispersion at individual company or industry level. In this paper, we choose
the VIX index due to two reasons. First it is widely used as standard uncertainty measure (Bloom,
2009) and second it covers long period since 1962 the third quarter.
For the Ô¨Ånancial conditons, the Chicago Fed national Ô¨Ånancial condition index is chosed. It
is a real-time indicator of Ô¨Ånancial distress constructed and maintained by the Chicago Fed and
described extensively in Brave and Butters (2012). The index extracted using dynamic factor
analysis from a set of 120 series that describe a broad range of monetary, debt and equity markets
as well as the leverage of the Ô¨Ånancial industry. Another advantage of the data is that it covers the
longest periods since 1973 the Ô¨Årst quarter.
We use quarterly data from 1973 the Ô¨Årst quarter to 2009 the last quarter that covers the longest
period for all the 28 variables.
3.4.2
Empirical Ô¨Åndings
We use 28 quarterly data form 1973 Q1 to 2009 Q4 with 2 lags in large VAR in Bayesian estima-
tion. We also tried more lags, however, the results are robust.
130

The identiÔ¨Åcation of the monetary policy shocks, uncertainty shocks and Ô¨Ånancial shocks are
implemented in a recursive manner. For the identiÔ¨Åcation of monetary policy shocks, the observa-
tions are divided into three blocks. The Ô¨Årst one is slow moving block that contain variables not
sensitive in response to monetary policy shocks and react with one period lag. The second block
only contains the instrument of conventional monetary policy, namely the effctive fedral fund rate.
The last block contains variables that are very sensitive to the changes in monetary policy ‚Äì the
surprise. All the variables in the third block are Ô¨Ånancial variables that cover government bonds,
corporate bonds, stock , exchange rate markets.
As for the identiÔ¨Åcation of the uncertainty shock, I place VIX index for uncertainty measure
in the Ô¨Årst place in the Ô¨Årst block, that is VIX is the Ô¨Årst variable among all the observations.
Caggiano et al. (2012) in a small scale nonlinear VAR for the U.S economy and Kamber et al.
(2013) in a factor augmented VAR model for small open economy of New Zealand, both place
uncertainy measure of VIX in the Ô¨Årst. In order to make the uncertainty measure as compatible
as possible with the identiÔ¨Åcation restriction - uncertainty is not affected immediately by other
shocks, following Kamber et al. (2013), the quarterly data is constructed by only choosing the
Ô¨Årst month of the quarter. Regarding Ô¨Ånancial condition variable, it is ordered the last in the third
block. That is, the national Ô¨Ånancial condition index is the last one among all the observations in
the sense that this indicator responses to all the variables contemporarily. In practice, identiÔ¨Åcation
of these shocks are conducted by cholesky decomposition of the covariance matirx of the residuals
in the large VAR.
Let‚Äôs Ô¨Årst look at the effects of monetary policy shocks on the economy. Figue 3.1 plots the
response functions in median for all the 28 variables with dashed lines representing conÔ¨Ådence
interval between 16th percentile and 84th percentile. From the responses, it is reasonable to believe
that the non-systematic monetary policy is well identiÔ¨Åed. One standard deviation monetary policy
shock cause almost all the responses in line with economic theory. Non-systematic monetary
shocks increase uncertainty that is recently empasized by Baker et al. (2013) in the current slow
recovery stage after the global Ô¨Ånancial crisis of 2008. Both real GDP and industrial production of
131

different output measure decline in response to tightening policy. Capacity utilization gets down in
response to high interest rate. Residential investment responses much stronger than non-resdential
investment due to that they are more sensitive to Ô¨Ånancing cost. Consumer conÔ¨Ådence is also
depressed by the tightening policy. With the increase in federal fund rate - the benchmark rate,
rates of all the government bonds and corporate bonds rise. Stock price declines as expected. U.S
dollar appreciates due to high return in international capital market. M1 and M2 decline reÔ¨Çecting
liquidity. Finally, tighten monetary policy elevates Ô¨Ånancial stress.
Then we look at the uncertainy shocks in Fig 3.2. Uncertainty shocks have countercyclical
effect on the economy. Capacity utilization decline. Real output, consumption, investment all
get down consistent with different economic theory on uncertainty. What is interesting is that
comparing with monetary shock, nonresidential investment decline facing futural uncertaity while
residential investment seems nonsensitive to the uncertainty relative to borrowing cost caused by
tightening monetary policy. Uncertainty also depresses consumer conÔ¨Ådence. In respose to un-
certainty shock, federal fund rate lowers in order to stimulate the economic activity. Decline in
federal funds rate decreases government bonds rates while increase the Baa return. This means
that with high uncertainty, the effects of requiring high risk premium dominate the decline in short
rates for corporate bonds with low credit rating. M1 and M2 is improved by Fed policy. Stock
price decline and stay on a low level for the whole Ô¨Åve years. Uncertainty cause national Ô¨Ånancial
conditon worse than before which is evidenced by the last graph in Fig 3.2.
As discussed in section 1 and section 2, Ô¨Ånancial market and uncertaity links together and affect
each other. On the main diagonal of Fig 3.3, Ô¨Ånancial shocks increase the uncertainty. Financial
shocks affect real activity for a long period. Compared response of industrial production in Fig 3.3
with that in Fig 3.2, the deline in IP caused by Ô¨Ånancial shock last for Ô¨Åve years, while the effect
caused by uncertainy recover back after three or four quarters. We can Ô¨Ånd the same case in real
GDP, employment, hours worked, capacity utilization and nonresidential investment as opposed
to uncertainty shocks. Again residential investment becomes sensitive with Ô¨Ånancial tightness ‚Äì
the same response with positive monetary shocks. In addtion, Ô¨Ånancial shocks seem to have no
132

signiÔ¨Åcant effects on Ô¨Ånancial variables except for Ô¨Ånancial condition index itself; In contract,
uncertainty shocks have strong effects on Ô¨Ånancial variables over government bonds, corporate
bonds, money, stock and foreign exchange rate markets.
In sum, through the large Bayesian VAR with data set covering broad range of the U.S. econ-
omy, we have three Ô¨Åndings. First, increase in uncertainty cause tight Ô¨Ånancial conditions and tight
Ô¨Ånancial conditons lead high uncertainty (see the main diagonal of Fig 3.2 and Fig 3.3); Second,
both Ô¨Ånancial and uncertaity shocks cause counter-cyclical effects on real activity but Ô¨Ånancial
shocks have the effects kept for a long time; The last is that Ô¨Ånancial variables are much more
sensitive to uncertainty shocks compared to Ô¨Ånancial shocks.
3.5
Concluding remarks
In this chapter, we switch from time varying parameter VAR to constant parameter VAR in a rich
data environment. With the proper priors of shrinkage property imposed on the coefÔ¨Åcients and
estimated by Bayesian method, the model conducts a good performance in structual analysis.
We jointly identiÔ¨Åed three shocks which are monetary policy shocks, Ô¨Ånancial shocks and un-
certainty shocks in a structural analysis. For the effects of monetary shocks, the impulse response
functions are in line with theoretical predictions. For the Ô¨Ånancial shocks and uncertainty shocks,
we analyse them together. Financial condition and uncertainty affect each other. Tight Ô¨Ånancial
condition elevates uncertainty and in turn, high uncertainty exacerbates Ô¨Ånancial condition. Both
positive Ô¨Ånancial and uncertainty shocks have negative effects on real activities, however, Ô¨Ånancial
shocks have more persistent effects on these real variables than uncertainty shocks. We also Ô¨Ånd
that Ô¨Ånancial variables care more for uncertainty shocks compared to Ô¨Ånancial shocks.
The empirical analysis implies that in a theoretical framwork such as DSGE model, the Ô¨Ånan-
cial market and uncertainty should be combined together beacuse they are mutually as shocks and
channels, affecting each other and multiple dimensions of the economy evidenced by the large
Bayesian VAR.
133

Figure 3.1: IRs to monetary policy shocks
10 20 30 40
‚àí0.05
0
0.05
VIX
10 20 30 40
‚àí0.01
0
0.01
RGDP
10 20 30 40
‚àí0.02
0
0.02
Com P
10 20 30 40
‚àí0.02
0
0.02
IP
10 20 30 40
‚àí0.01
0
0.01
Emp: total
10 20 30 40
‚àí0.01
0
0.01
Emp: serv
10 20 30 40
‚àí0.01
0
0.01
Consp
10 20 30 40
‚àí0.05
0
0.05
Res.Inv
10 20 30 40
‚àí0.05
0
0.05
NonResInv
10 20 30 40
‚àí2
0
2
Cap Util
10 20 30 40
‚àí0.5
0
0.5
Cons Confid
10 20 30 40
‚àí0.02
0
0.02
Emp Hor
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Compensation
10 20 30 40
‚àí1
0
1
FFR
10 20 30 40
‚àí1
0
1
3mTB
10 20 30 40
‚àí0.5
0
0.5
6mTB
10 20 30 40
‚àí0.5
0
0.5
1yTB
10 20 30 40
‚àí0.5
0
0.5
5yTB
10 20 30 40
‚àí0.5
0
0.5
10yTB
10 20 30 40
‚àí0.5
0
0.5
AAA
10 20 30 40
‚àí0.5
0
0.5
BAA
10 20 30 40
‚àí0.02
0
0.02
M1
10 20 30 40
‚àí0.01
0
0.01
M2
10 20 30 40
‚àí0.05
0
0.05
S&P500
10 20 30 40
‚àí0.05
0
0.05
Eff ex‚àírate
10 20 30 40
‚àí0.05
0
0.05
NW1
10 20 30 40
‚àí0.05
0
0.05
NW2
10 20 30 40
‚àí0.5
0
0.5
FCI
Notes: Impulse responses of 28 variables to monetary policy shocks with solid line representing
posterior median and dashed lines covering conÔ¨Ådence interval between 16th percentile and 84th
percentile.
134

Figure 3.2: IRs to uncertainty shocks
10 20 30 40
‚àí0.2
0
0.2
VIX
10 20 30 40
‚àí5
0
5
x 10
‚àí3
RGDP
10 20 30 40
‚àí0.02
0
0.02
Com P
10 20 30 40
‚àí0.01
0
0.01
IP
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Emp: total
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Emp: serv
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Consp
10 20 30 40
‚àí0.05
0
0.05
Res.Inv
10 20 30 40
‚àí0.02
0
0.02
NonResInv
10 20 30 40
‚àí1
0
1
Cap Util
10 20 30 40
‚àí0.5
0
0.5
Cons Confid
10 20 30 40
‚àí0.01
0
0.01
Emp Hor
10 20 30 40
‚àí0.01
0
0.01
Compensation
10 20 30 40
‚àí0.5
0
0.5
FFR
10 20 30 40
‚àí0.5
0
0.5
3mTB
10 20 30 40
‚àí0.5
0
0.5
6mTB
10 20 30 40
‚àí0.5
0
0.5
1yTB
10 20 30 40
‚àí0.2
0
0.2
5yTB
10 20 30 40
‚àí0.2
0
0.2
10yTB
10 20 30 40
‚àí0.2
0
0.2
AAA
10 20 30 40
‚àí0.2
0
0.2
BAA
10 20 30 40
‚àí0.02
0
0.02
M1
10 20 30 40
‚àí0.01
0
0.01
M2
10 20 30 40
‚àí0.05
0
0.05
S&P500
10 20 30 40
‚àí0.05
0
0.05
Eff ex‚àírate
10 20 30 40
‚àí0.05
0
0.05
NW1
10 20 30 40
‚àí0.05
0
0.05
NW2
10 20 30 40
‚àí0.2
0
0.2
FCI
Notes: Impulse responses of 28 variables to uncertainty shocks with solid line representing pos-
terior median and dashed lines covering conÔ¨Ådence interval between 16th percentile and 84th per-
centile.
135

Figure 3.3: IRs to Ô¨Ånancial shocks
10 20 30 40
‚àí0.02
0
0.02
VIX
10 20 30 40
‚àí5
0
5
x 10
‚àí3
RGDP
10 20 30 40
‚àí0.01
0
0.01
Com P
10 20 30 40
‚àí0.01
0
0.01
IP
10 20 30 40
‚àí0.01
0
0.01
Emp: total
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Emp: serv
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Consp
10 20 30 40
‚àí0.02
0
0.02
Res.Inv
10 20 30 40
‚àí0.02
0
0.02
NonResInv
10 20 30 40
‚àí0.5
0
0.5
Cap Util
10 20 30 40
‚àí0.5
0
0.5
Cons Confid
10 20 30 40
‚àí0.01
0
0.01
Emp Hor
10 20 30 40
‚àí5
0
5
x 10
‚àí3
Compensation
10 20 30 40
‚àí0.2
0
0.2
FFR
10 20 30 40
‚àí0.2
0
0.2
3mTB
10 20 30 40
‚àí0.1
0
0.1
6mTB
10 20 30 40
‚àí0.2
0
0.2
1yTB
10 20 30 40
‚àí0.2
0
0.2
5yTB
10 20 30 40
‚àí0.2
0
0.2
10yTB
10 20 30 40
‚àí0.2
0
0.2
AAA
10 20 30 40
‚àí0.2
0
0.2
BAA
10 20 30 40
‚àí0.02
0
0.02
M1
10 20 30 40
‚àí5
0
5
x 10
‚àí3M2
10 20 30 40
‚àí0.05
0
0.05
S&P500
10 20 30 40
‚àí0.02
0
0.02
Eff ex‚àírate
10 20 30 40
‚àí0.05
0
0.05
NW1
10 20 30 40
‚àí0.02
0
0.02
NW2
10 20 30 40
‚àí0.2
0
0.2
FCI
Notes: Impulse responses of 28 variables to Ô¨Ånancial shocks with solid line representing posterior
median and dashed lines covering conÔ¨Ådence interval between16th percentile and 84th percentile.
136

Appendix
A. Data speciÔ¨Åcation
Notes: The data set consists of 28 U.S. quarterly variables from 1973 Q1 to 2009 Q4. Except for
consumer conÔ¨Ådence index, effective exchange rate index and VIX volatility index, other data can
be found from Federal Reserve Economic Data - FRED - St. Louis Fed. The consumer conÔ¨Ådence
index is from OECD. The effective exchage rate is from BIS. For the VIX index, the stock market
volatility is measured by realized volatility before 1986 and by Black - Scholes implied volatility
after 1986 (Choi, 2013).2 The quarterly data of VIX is constructed by choosing the Ô¨Årst month of
each quarter following Kamber et al. (2013) to allow for lag effect in response to other shocks. For
the other quaterly data, they are all constructed by monthly average for a speciÔ¨Åc quarter. The ‚Äò#‚Äô
column lists the order of the variables in the large VAR. In the ‚ÄòTcode‚Äô column, 1 means level, 2
means log level and ‚Äòsa‚Äô represents seasonally adjusted as well as ‚Äònsa‚Äô not seasonally adjusted. In
the last ‚ÄòId‚Äô column, ‚Äòf‚Äô implies fast moving and ‚Äòs‚Äô slow moving.
2The monthly VIX index is kindly provided by Sangyup Choi.
137

Table 3.1: Data speciÔ¨Åcation
#
Mnemonic
Description
Tcode
Id
1
VIX
CBOE Volatility Index
2 nsa
s
2
RGDP
Real gross domestic product
2 sa
s
3
PPI
Producer Price Index: Ô¨Ånished goods
2 sa
s
4
IP: total
Industrial Production Index
2 sa
s
5
Emp: total
All employees: total private
2 sa
s
6
Emp: services
All employees: service providing
2 sa
s
7
consp
Real personal consumption expenditures
2 sa
s
8
Res.Inv
Residential private domestic investment
2 sa
s
9
NonRes.Inv
Nonresidential private domestic investment
2 sa
s
10
Cap Util
Capacity utilization: total industry
1 sa
s
11
Cons ConÔ¨Åd
Consumer conÔ¨Ådence index (OECD)
1 nsa
s
12
Emp. Hours
Hours of all persons: nonfarm
2 sa
s
13
Real Comp/Hour
Real compensation per hour: nonfarm
2 sa
s
14
FFR
Effective Federal Funds Rate
1 nsa
-
15
3mTB
Treasury Bill rate 3 months: second market
1 nsa
f
16
6mTB
Treasury Bill rate 6 months: second market
1 nsa
f
17
1yTB
Treasury Bill rate 1 year: constant maturity rate
1 nsa
f
18
5yTB
Treasury Bill rate 5 year: constant maturity rate
1 nsa
f
19
10yTB
Treasury Bill rate 10 year: constant maturity rate
1 nsa
f
20
AAA yield
AAA corporate bond yield
1 nsa
f
21
BAA yield
BAA corporate bond yield
1 nsa
f
22
M1
M1 money stock
2 sa
f
23
M2
M2 money stock
2 sa
f
24
S&P 500
S&P‚Äôs common stock price index
2 nsa
f
25
Ex rate
Effective exchange rate index (BIS)
2 nsa
f
26
NW 1
Market value of equities outstanding
2 nsa
f
27
NW 2
Owners‚Äô equity in household real estate
2 nsa
f
28
FCI
Chicago Fed national Ô¨Ånancial condition index
1 nsa
f
138

References
Alessandri, P. & Mumtaz, H. (2014). Financial regimes and uncertainty shocks. Working paper,
No.729, Queen Mary University of London, School of Economics and Finance.
Aoki, N. (1990). State space modeling of time series. Cambridge Univ Press.
Arellano, C., Bai, Y., & Kehoe, P. (2010).
Financial markets and Ô¨Çuctuations in uncertainty.
Federal Reserve Bank of Minneapolis Working Paper.
Auer, S. (2014). Monetary policy shocks and foreign investment income: evidence from a large
bayesian var. SNB working papers, Swiss National Bank.
Baker, S. R., Bloom, N., & Davis, S. J. (2013). Measuring economic policy uncertainty. Chicago
Booth research paper.
Ba¬¥nbura, M., Giannone, D., & Reichlin, L. (2010). Large bayesian vector auto regressions. Journal
of Applied Econometrics, 25(1), 71‚Äì92.
Baumeister, C. & Peersman, G. (2013). Time-varying effects of oil supply shocks on the u.s.
economy. American Economic Journal: Macroeconomics, 5(4), 1‚Äì28.
Bauwens, L., Koop, G., Korobilis, D., & Rombouts, J. V. (2014). The contribution of structural
break models to forecasting macroeconomic series. Journal of Applied Econometrics, early
online publication.
Beetsma, R. & Giuliodori, M. (2012). The changing macroeconomic response to stock market
volatility shocks. Journal of Macroeconomics, 34(2), 281‚Äì293.
139

Bernanke, B. S. (1983). Irreversibility, uncertainty, and cyclical investment. The Quarterly Journal
of Economics, 98(1), 85‚Äì106.
Bernanke, B. S. & Boivin, J. (2003). Monetary policy in a data-rich environment. Journal of
Monetary Economics, 50(3), 525‚Äì546.
Bernanke, B. S., Boivin, J., Tom, D., & Eliasz, P. S. (2005). Measuring the effects of mone-
tary policy: A factor-augmented vector autoregressive (favar) approach. Quarterly Journal of
Economics, 120(1), 387‚Äì422.
Bernanke, B. S. & Mihov, I. (1998). Measuring monetary policy. Quarterly Journal of Economics,
113(3), 869‚Äì902.
Bijsterbosch, M. & Gu√©rin, P. (2013). Characterizing very high uncertainty episodes. Economics
Letters, 121(2), 239‚Äì243.
Blanchard, O. & Perotti, R. (2002).
An empirical characterization of the dynamic effects of
changes in government spending and taxes on output. The Quarterly Journal of Economics,
117(4), 1329‚Äì1368.
Blanchard, O. & Simon, J. (2001). The long and large decline in u.s. output volatility. Brookings
papers on economic activity, 2001(1), 135‚Äì174.
Bloom, N. (2009). The impact of uncertainty shocks. Econometrica, 77(3), 623‚Äì685.
Boivin, J. (2001). The fed‚Äôs conduct of monetary policy: Has it changed and does it matter?
Columbia Business School, mimeo.
Boivin, J. & Giannoni, M. P. (2006). Has monetary policy become more effective? The Review of
Economics and Statistics, 88(3), 445‚Äì462.
Brave, S. & Butters, A. (2012). Diagnosing the Ô¨Ånancial system: Ô¨Ånancial conditions and Ô¨Ånancial
stress. International Journal of Central Banking, 8(2), 191‚Äì239.
140

Caggiano, G., Castelnuovo, E., & Groshenny, N. (2014). Uncertainty shocks and unemployment
dynamics in u.s. recessions. Journal of Monetary Economics, 67, 78‚Äì92.
Canova, F. (2007). Methods for applied macroeconomic research, volume 13. Princeton University
Press.
Canova, F. & Gambetti, L. (2009). Structural changes in the u.s. economy: Is there a role for
monetary policy? Journal of Economic dynamics and control, 33(2), 477‚Äì490.
Carlin, B. P., Polson, N. G., & Stoffer, D. S. (1992). A monte carlo approach to nonnormal and
nonlinear state-space modeling. Journal of the American Statistical Association, 87(418), 493‚Äì
500.
Carriero, A., Clark, T. E., & Marcellino, M. G. (2012). Common drifting volatility in large bayesian
vars. CEPR Discussion Paper, No. 8894.
Carriero, A., Kapetanios, G., & Marcellino, M. (2011). Forecasting large datasets with bayesian
reduced rank multivariate models. Journal of Applied Econometrics, 26(5), 735‚Äì761.
Carter, C. K. & Kohn, R. (1994). On gibbs sampling for state space models. Biometrika, 81(3),
541‚Äì553.
Chan, J. C. & Jeliazkov, I. (2009). EfÔ¨Åcient simulation and integrated likelihood estimation in state
space models. International Journal of Mathematical Modelling and Numerical Optimisation,
1(1), 101‚Äì120.
Choi, S. (2013). Are the effects of bloom‚Äôs uncertainty shocks robust? Economics Letters, 119(2),
216‚Äì220.
Christiano, L. J., Motto, R., & Rostagno, M. (2014). Risk shocks. The American Economic Review,
104(1), 27‚Äì65.
Ciccarelli, M. & Rebucci, A. (2003). Measuring contagion with a bayesian, time-varying coefÔ¨Å-
cient model. IMF working paper.
141

Cogley, T., Primiceri, G. E., & Sargent, T. J. (2010). InÔ¨Çation-gap persistence in the u.s. American
Economic Journal: Macroeconomics, 2(1), 43‚Äì69.
Cogley, T. & Sargent, T. J. (2001). Evolving post-world war ii u.s. inÔ¨Çation dynamics. NBER
Macroeconomics Annual, 16(1), 331‚Äì373.
Cogley, T. & Sargent, T. J. (2005). Drifts and volatilities: monetary policies and outcomes in the
post wwii u.s. Review of Economic dynamics, 8(2), 262‚Äì302.
De Mol, C., Giannone, D., & Reichlin, L. (2008). Forecasting using a large number of predictors:
Is bayesian shrinkage a valid alternative to principal components?
Journal of Econometrics,
146(2), 318‚Äì328.
De Wind, J. & Gambetti, L. (2014).
Reduced-rank time-varing vector autoregressions.
CPB
Discussion paper, N0. 270, CPB Netherlands Bureau for Economic Policy Analysis.
Del Negro, M. & Otrok, C. (2008). Dynamic factor models with time-varying parameters: mea-
suring changes in international business cycles. FRB of New York Staff Report, No.326.
Del Negro, M. & Primiceri, G. E. (2013). Time-varying structural vector autoregressions and
monetary policy: a corrigendum. FRB of New York Staff Report, No.619.
Doan, T., Litterman, R., & Sims, C. (1984). Forecasting and conditional projection using realistic
prior distributions. Econometric reviews, 3(1), 1‚Äì100.
Fernandez-Villaverde, J., Rubio-Ramirez, J. F., Sargent, T. J., & Watson, M. W. W. (2007). Abcs
(and ds) of understanding vars. American Economic Review, 97(3), 1021‚Äì1026.
Forni, M., Hallin, M., Lippi, M., & Reichlin, L. (2000). The generalized dynamic-factor model:
IdentiÔ¨Åcation and estimation. Review of Economics and statistics, 82(4), 540‚Äì554.
Forni, M. & Reichlin, L. (1998). Let‚Äôs get real: a factor analytical approach to disaggregated
business cycle dynamics. The Review of Economic Studies, 65(3), 453‚Äì473.
142

George, E. I., Sun, D., & Ni, S. (2008). Bayesian stochastic search for var model restrictions.
Journal of Econometrics, 142(1), 553‚Äì580.
Geweke, J. (1977). The dynamic factor analysis of economic time series. Amsterdam: North-
Holland.
Giacomini, R. (2013). The relationship between dsge and var models. Advances in Econometrics,
31.
Gilchrist, S., Sim, J. W., & Zakraj≈°ek, E. (2014). Uncertainty, Ô¨Ånancial frictions, and investment
dynamics. NBER Working paper, No.20038.
Gupta, R., Jurgilas, M., Kabundi, A., & Miller, S. M. (2012). Monetary policy and housing sec-
tor dynamics in a large-scale bayesian vector autoregressive model. International Journal of
Strategic Property Management, 16(1), 1‚Äì20.
Hanson, M. S. (2006). Varying monetary policy regimes: A vector autoregressive investigation.
Journal of Economics and Business, 58(5), 407‚Äì427.
Hartmann, P., Hubrich, K., Kremer, M., & Tetlow, R. J. (2014). Melting down: Systemic Ô¨Ånancial
instability and the macroeconomy. Available at SSRN 2462567.
Jacquier, E., Polson, N. G., & Ross (1994). Bayesian analysis of stochastic volatility models.
Journal of Business & Economic Statistics, 12(4), 371‚Äì389.
Kadiyala, K. & Karlsson, S. (1997). Numerical methods for estimation and inference in bayesian
var models. Journal of Applied Econometrics, 12(2), 99‚Äì132.
Kamber, G., Karagedikli, O., Ryan, M., & Vehbi, T. (2013). International spill-overs of uncertainty
shocks: Evidence from a favar. Reserve Bank of New Zealand, mimeo.
Kim, C.-J. & Nelson, C. R. (1999). State space models with regime switching: classical and
gibbs-sampling approach with applications. MIT Press.
143

Kim, D. & Yamamoto, Y. (2013). Time instability of the u.s. monetary system: Multiple break
tests and reduced rank tvp-var. Discussion Paper.
Kim, S., Shephard, N., & Chib, S. (1998). Stochastic volatility: likelihood inference and compari-
son with arch models. The Review of Economic Studies, 65(3), 361‚Äì393.
Koop, G. & Korobilis, D. (2010). Bayesian multivariate time series methods for empirical macroe-
conomics. Foundations and trends(R) in Econometrics, 3(4), 267‚Äì358.
Koop, G. & Korobilis, D. (2013). Large time-varying parameter vars. Journal of Econometrics,
177(2), 185‚Äì198.
Koop, G., Leon-Gonzalez, R., & Strachan, R. W. (2009). On the evolution of the monetary policy
transmission mechanism. Journal of Economic Dynamics and Control, 33(4), 997‚Äì1017.
Koop, G. M. (2013). Forecasting with medium and large bayesian vars. Journal of Applied Econo-
metrics, 28(2), 177‚Äì203.
Korobilis, D. (2013a). Assessing the transmission of monetary policy using time-varying parameter
dynamic factor models. Oxford Bulletin of Economics and Statistics, 75(2), 157‚Äì179.
Korobilis, D. (2013b).
Var forecasting using bayesian variable selection.
Journal of Applied
Econometrics, 28(2), 204‚Äì230.
Kuo, L. & Mallick, B. (1998). Variable selection for regression models. Sankhy¬Øa: The Indian
Journal of Statistics, Series B, 60(1), 65‚Äì81.
Leeper, E. M. & Zha, T. (2003). Modest policy interventions. Journal of Monetary Economics,
50(8), 1673‚Äì1700.
Litterman, R. B. (1986). A statistical approach to economic forecasting. Journal of Business &
Economic Statistics, 4(1), 1‚Äì4.
144

Lubik, T. A. & Schorfheide, F. (2004). Testing for indeterminacy: an application to u.s. monetary
policy. American Economic Review, 94(1), 190‚Äì217.
Morris, S. D. (2012). Var (1) representation of dsge models. University of California, San Diego
working paper.
Mumtaz, H. & Surico, P. (2013). Policy uncertainty and aggregate Ô¨Çuctuations. CEPR Discussion
Paper, No.8894.
Mumtaz, H. & Thedoridis, K. (2012). The international transmission of volatility shocks. Bank of
England Working paper, No. 463.
Mumtaz, H. & Thedoridis, K. (2014). The changing transmission of uncertainty shocks in the u.s.:
an empirical analysis. Working paper, No. 735, Queen Mary University of London, School of
Economics and Finance.
Mumtaz, H. & Zanetti, F. (2013). The impact of the volatility of monetary policy shocks. Journal
of Money, Credit and Banking, 45(4), 535‚Äì558.
Omori, Y., Chib, S., Shephard, N., & Nakajima, J. (2007). Stochastic volatility with leverage: Fast
and efÔ¨Åcient likelihood inference. Journal of Econometrics, 140(2), 425‚Äì449.
Primiceri, G. E. (2005). Time varying structural vector autoregressions and monetary policy. The
Review of Economic Studies, 72(3), 821‚Äì852.
Ravenna, F. (2007). Vector autoregressions and reduced form representations of dsge models.
Journal of monetary economics, 54(7), 2048‚Äì2064.
Romer, C. D. (1990). The great crash and the onset of the great depression. The Quarterly Journal
of Economics, 105(3), 597‚Äì624.
Sargan, J. D. & Bhargava, A. (1983). Maximum likelihood estimation of regression models with
Ô¨Årst order moving average errors when the root lies on the unit circle. Econometrica: Journal
of the Econometric Society, 51(3), 799‚Äì820.
145

Shephard, N. G. & Harvey, A. C. (1990). On the probability of estimating a deterministic compo-
nent in the local level model. Journal of time series analysis, 11(4), 339‚Äì347.
Sims, C. A. (1980). Macroeconomics and reality. Econometrica: Journal of the Econometric
Society, 48(1), 1‚Äì48.
Sims, C. A. (1999). Drift and breaks in monetary policy. Manuscript, Princeton University.
Sims, C. A. (2001). Stability and instability in u.s. monetary policy behavior. Princeton University,
photocopy.
Sims, C. A. & Zha, T. (2006). Were there regime switches in us monetary policy? The American
Economic Review, 96(1), 54‚Äì81.
Stock, J. H. & Watson, M. W. (1998). Asymptotically median unbiased estimation of coefÔ¨Åcient
variance in a time varying parameter model. Journal of the American Statistical Association,
93(441), 349‚Äì358.
Stock, J. H. & Watson, M. W. (1999). Forecasting inÔ¨Çation. Journal of Monetary Economics,
44(2), 293‚Äì335.
Stock, J. H. & Watson, M. W. (2002a). Has the business cycle changed and why? NBER Macroe-
conomics Annual, 17, 159‚Äì230.
Stock, J. H. & Watson, M. W. (2002b). Macroeconomic forecasting using diffusion indexes. Jour-
nal of Business & Economic Statistics, 20(2), 147‚Äì162.
Stock, J. H. & Watson, M. W. (2005). Implications of dynamic factor models for var analysis.
NBER Working paper, No.11467.
Taheri Sanjani, M. (2014). Financial frictions in data: Evidence and impact. IMF working paper.
Uhlig, H. (2005). What are the effects of monetary policy on output? results from an agnostic
identiÔ¨Åcation procedure. Journal of Monetary Economics, 52(2), 381‚Äì419.
146

