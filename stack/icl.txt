Introduction to
Computational Logic
Lecture Notes SS 2014
July 16, 2014
Gert Smolka and Chad E. Brown
Department of Computer Science
Saarland University
Copyright © 2014 by Gert Smolka and Chad E. Brown, All Rights Reserved


Contents
Introduction
1
1
Types and Functions
3
1.1
Booleans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Cascaded Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.3
Natural Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.4
Structural Induction and Rewriting . . . . . . . . . . . . . . . . . . . .
10
1.5
More on Rewriting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.6
Recursive Abstractions . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
1.7
Deﬁned Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.8
Standard Library . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.9
Pairs and Implicit Arguments . . . . . . . . . . . . . . . . . . . . . . .
18
1.10
Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
1.11
Quantiﬁed Inductive Hypotheses . . . . . . . . . . . . . . . . . . . . .
24
1.12
Iteration as Polymorphic Higher-Order Function
. . . . . . . . . . .
25
1.13
Options and Finite Types . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.14
More about Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
1.15
Discussion and Remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2
Propositions and Proofs
33
2.1
Logical Connectives and Quantiﬁers . . . . . . . . . . . . . . . . . . .
33
2.2
Implication and Universal Quantiﬁcation . . . . . . . . . . . . . . . .
34
2.3
Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.4
The Apply Tactic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2.5
Leibniz Characterization of Equality . . . . . . . . . . . . . . . . . . .
37
2.6
Propositions are Types . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
2.7
Falsity and Negation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
2.8
Conjunction and Disjunction
. . . . . . . . . . . . . . . . . . . . . . .
40
2.9
Equivalence and Rewriting . . . . . . . . . . . . . . . . . . . . . . . . .
41
2.10
Automation Tactics . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
2.11
Existential Quantiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . .
44
2.12
Basic Proof Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
2.13
Proof Rules as Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
iii

Contents
2.14
Inductive Propositions
. . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.15
An Observation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
2.16
Excluded Middle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
2.17
Discussion and Remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
54
2.18
Tactics Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3
Deﬁnitional Equality and Propositional Equality
57
3.1
Conversion Principle
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
3.2
Disjointness and Injectivity of Constructors . . . . . . . . . . . . . .
61
3.3
Leibniz Equality
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
3.4
By Name Speciﬁcation of Implicit Arguments . . . . . . . . . . . . .
66
3.5
Local Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
3.6
Proof of nat ≠bool
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
3.7
Cantor’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
3.8
Kaminski’s Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
3.9
Boolean Equality Tests
. . . . . . . . . . . . . . . . . . . . . . . . . . .
71
4
Induction and Recursion
73
4.1
Induction Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
4.2
Primitive Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
4.3
Size Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
4.4
Equational Speciﬁcation of Functions . . . . . . . . . . . . . . . . . .
78
5
Truth Value Semantics and Elim Restriction
81
5.1
Truth Value Semantics
. . . . . . . . . . . . . . . . . . . . . . . . . . .
81
5.2
Elim Restriction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
5.3
Propositional Extensionality Entails Proof Irrelevance . . . . . . . .
84
5.4
A Simpler Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
6
Sum and Sigma Types
87
6.1
Boolean Sums and Certifying Tests . . . . . . . . . . . . . . . . . . . .
87
6.2
Inhabitation and Decidability . . . . . . . . . . . . . . . . . . . . . . .
89
6.3
Writing Certifying Tests
. . . . . . . . . . . . . . . . . . . . . . . . . .
90
6.4
Deﬁnitions and Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . .
94
6.5
Decidable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
6.6
Sigma Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
6.7
Strong Truth Value Semantics . . . . . . . . . . . . . . . . . . . . . . .
98
7
Inductive Predicates
101
7.1
Nonparametric Arguments and Linearization . . . . . . . . . . . . . 101
7.2
Even . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
7.3
Less or Equal
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
iv
2014-7-16

Contents
7.4
Equality
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
7.5
Exceptions to the Elim Restriction . . . . . . . . . . . . . . . . . . . . 109
7.6
Safe and Nonuniform Parameters . . . . . . . . . . . . . . . . . . . . . 110
7.7
Constructive Choice for Nat . . . . . . . . . . . . . . . . . . . . . . . . 112
7.8
Technical Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
7.9
Induction Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
8
Lists
119
8.1
Constructors and Notations . . . . . . . . . . . . . . . . . . . . . . . . 120
8.2
Recursion and Induction . . . . . . . . . . . . . . . . . . . . . . . . . . 121
8.3
Membership . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
8.4
Inclusion and Equivalence . . . . . . . . . . . . . . . . . . . . . . . . . 125
8.5
Disjointness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
8.6
Decidability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
8.7
Filtering
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
8.8
Element Removal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
8.9
Cardinality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
8.10
Duplicate-Freeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
8.11
Power Lists
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
9
Syntactic Uniﬁcation
139
9.1
Terms, Substitutions, and Uniﬁers . . . . . . . . . . . . . . . . . . . . 139
9.2
Solved Equation Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
9.3
Uniﬁcation Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
9.4
Presolved Equation Lists . . . . . . . . . . . . . . . . . . . . . . . . . . 146
9.5
Uniﬁcation Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
9.6
Alternative Representations . . . . . . . . . . . . . . . . . . . . . . . . 149
9.7
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
10 Propositional Entailment
153
10.1
Propositional Formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
10.2
Structural Properties of Entailment Relations . . . . . . . . . . . . . 154
10.3
Logical Properties of Entailment Relations . . . . . . . . . . . . . . . 156
10.4
Variables and Substitutions . . . . . . . . . . . . . . . . . . . . . . . . 157
10.5
Natural Deduction System . . . . . . . . . . . . . . . . . . . . . . . . . 158
10.6
Classical Natural Deduction . . . . . . . . . . . . . . . . . . . . . . . . 163
10.7
Glivenko’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
10.8
Hilbert System
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
10.9
Intermediate Logics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
10.10 Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
2014-7-16
v

Contents
11 Classical Tableau Method
173
11.1
Boolean Evaluation and Satisﬁability . . . . . . . . . . . . . . . . . . . 173
11.2
Validity and Boolean Entailment
. . . . . . . . . . . . . . . . . . . . . 175
11.3
Signed Formulas and Clauses . . . . . . . . . . . . . . . . . . . . . . . 175
11.4
Solved Clauses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
11.5
Tableau Method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
11.6
DNF Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
11.7
Recursion Trees
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
11.8
Assisted Decider for Satisﬁability
. . . . . . . . . . . . . . . . . . . . 182
11.9
Main Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
11.10 Refutation Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
12 Intuitionistic Gentzen System
185
12.1
Gentzen System GS
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
12.2
Completeness of GS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
12.3
Decidability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
12.4
Finite Closure Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
12.5
Realization in Coq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
12.6
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
Bibliography
197
vi
2014-7-16

Introduction
This course is an introduction to basic logic principles, constructive type theory,
and interactive theorem proving with the proof assistant Coq. At Saarland Uni-
versity the course is taught in this format since 2010. Students are expected to
be familiar with basic functional programming and the structure of mathemati-
cal deﬁnitions and proofs. Talented students at Saarland University often take
the course in the second semester of their Bachelor’s studies.
Constructive type theory provides a programming language for developing
mathematical and computational theories. Theories consist of deﬁnitions and
theorems, where theorems state logical consequences of deﬁnitions. Every the-
orem comes with a proof justifying it. If the proof of a theorem is correct, the
theorem is correct. Constructive type theory is designed such that the correct-
ness of deﬁnitions and proofs can be checked automatically.
Coq is an implementation of a constructive type theory known as the calculus
of inductive deﬁnitions. Coq is designed as an interactive system that assists the
user in developing theories. The most interesting part of the interaction is the
construction of proofs. The idea is that the user points the direction while Coq
takes care of the details of the proof. In the course we use Coq from day one.
Coq is a mature system whose development started in the 1980’s. In recent
years Coq has become a popular tool for research and education in formal the-
ory development and program veriﬁcation. Landmarks are a proof of the four
color theorem, a proof of the Feit-Thompson theorem, and the veriﬁcation of a
compiler for the programming language C (COMPCERT).
Coq is the applied side of this course. On the theoretical side we explore the
basic principles of constructive type theory, which are essential for programming
languages, logical languages, proof systems, and the foundation of mathematics.
An important part of the course is the theory of classical and intuitionis-
tic propositional logic. We study various proof systems (Hilbert, ND, sequent,
tableaux), decidability of proof systems, and the semantic analysis of proof sys-
tems based on models. The study of propositional logic is carried out in Coq and
serves as a case study of a substantial formal theory development.
Dedication
This text is dedicated to the many people who have designed and implemented
Coq since 1985.
1

Contents
2
2014-7-16

1 Types and Functions
In this chapter, we take a ﬁrst look at Coq and its mathematical programming
language. We deﬁne basic data types such as booleans, natural numbers, and
lists and functions operating on them. For the deﬁned functions we prove equa-
tional theorems, constructing the proofs in interaction with the Coq interpreter.
The deﬁnitions we study are often recursive and the proofs we construct are
often inductive.
In the following it is absolutely essential that you have a Coq interpreter run-
ning and that you experiment with the deﬁnitions and proofs we discuss. In Coq,
proofs are constructed with scripts and the resulting proof process can only be
understood in interaction with a Coq interpreter.
1.1 Booleans
We start with the deﬁnition of a type bool with two elements true and false.
Inductive bool : Type :=
| true : bool
| false : bool.
The words Inductive and Type are keywords of Coq and the identiﬁers bool, true,
and false are the names we have chosen for the type and its elements. The identi-
ﬁers bool, true, and false serve as constructors, where bool is a type constructor
and true and false are the value constructors of bool. The above deﬁnition over-
writes the deﬁnition of bool in Coq’s standard library, but this does not matter
for our ﬁrst encounter with Coq.
We deﬁne a negation function negb.
Deﬁnition negb (x : bool) : bool :=
match x with
| true ⇒false
| false ⇒true
end.
The match term represents a case analysis for the boolean argument x. There is
a rule for each value constructor of bool. We can check the type of terms with
the command Check:
3

1 Types and Functions
Check negb.
% negb : bool →bool
Check negb (negb true).
% negb (negb true) : bool
We can evaluate terms with the command Compute.
Compute negb (negb true).
% true : bool
We are now ready for our ﬁrst proof with Coq.
Lemma L1 :
negb true = false.
Proof. simpl. reﬂexivity. Qed.
The command starting with the keyword Lemma states the equation we want to
prove and gives the lemma the name L1. The sequence of commands starting
with Proof and ending with Qed constructs the proof of Lemma L1. It is now
essential that you step through the commands with the Coq interpreter one by
one. Once the lemma command is accepted, Coq switches from top level mode
to proof editing mode. The commands between Proof and Qed are called tactics.
The tactic simpl simpliﬁes both sides of the equation to be shown by applying
the deﬁnition of negb. This leaves us with the trivial equation false = false, which
we prove with the tactic reﬂexivity. The command Qed ﬁnishes the proof.
Our second proof shows that double negation is identity.
Lemma negb_negb (x : bool) :
negb (negb x) = x.
Proof.
destruct x.
−reﬂexivity.
−reﬂexivity.
Qed.
This time the claim involves a boolean variable x and the proof proceeds by case
analysis on x. Since reﬂexivity performs simpliﬁcation automatically, we have
omitted the tactic simpl.
It is important that with Coq you step back and forth in the proof script and
observe what happens. This way you can see how the proof advances. At each
point in the proof process you are confronted with a proof goal comprised of a
list of assumptions (possibly empty) and a claim. Here are the proof goals you
will see when you step through the above proof script.
x : bool
negb (negb x) = x
negb (negb true) = true
negb (negb false) = false
4
2014-7-16

1.1 Booleans
In each goal, the assumptions appear above and the claim appears below the
rule. The tactic destruct x does the case analysis and replaces the initial goal
with two subgoals, one for x = true and one for x = false. The proof is ﬁnished if
both subgoals are solved (i.e., proved).
Since the proof ﬁnishes with reﬂexivity in both cases, we can shorten the
proof script by combining the tactics destruct x and reﬂexivity with the semi-
colon operator.
Proof. destruct x ; reﬂexivity. Qed.
We deﬁne a boolean conjunction function andb.
Deﬁnition andb (x y : bool) : bool :=
match x with
| true ⇒y
| false ⇒false
end.
We prove that boolean conjunction is commutative.
Lemma andb_com x y :
andb x y = andb y x.
Proof.
destruct x.
−destruct y ; reﬂexivity.
−destruct y ; reﬂexivity.
Qed.
The proof can be written more succinctly as
Proof. destruct x, y ; reﬂexivity. Qed.
The short proof script has the drawback that you don’t see much when you step
through it. For that reason we will often give proof scripts that are longer than
necessary.
Note that we have stated the lemma andb_com without giving types for the
variables x and y. This leaves it to Coq to infer the missing types. When you
look at the initial goal of the proof, you will see that x and y have both received
the type bool. Automatic type inference is an important feature of Coq.
A word on terminology. In mathematics, theorems are usually classiﬁed into
propositions, lemmas, theorems, and corollaries. This distinction is a matter of
style and does not matter logically. When we state a theorem in Coq, we will
mostly use the keyword Lemma.
Coq also accepts the keywords Proposition,
Theorem, and Corollary, which are treated as synonyms.
Exercise 1.1.1 A boolean disjunction x ∨y yields false if and only if both x
and y are false.
2014-7-16
5

1 Types and Functions
a) Deﬁne disjunction as a function orb : bool →bool →bool in Coq.
b) Prove that disjunction is commutative.
c) Formulate and prove the De Morgan law ¬(x ∨y) = ¬x ∧¬y in Coq.
1.2 Cascaded Functions
When we look at the type of andb
Check andb.
% andb : bool →bool →bool
we note that Coq realizes andb as a cascaded function taking a boolean ar-
gument and returning a function bool →bool. This means that an application
andb x y ﬁrst applies andb to just x. The resulting function is then applied to y.
Cascaded functions are standard in functional programming languages where
they are called curried functions.
To say more about cascaded functions, we consider lambda abstractions. A
lambda abstraction is a term λx : s.t describing a function taking an argument x
of type s and yielding the value described by the term t. For instance, the term
λx : bool.x describes an identity function on bool. In Coq, lambda abstractions
are written with the keyword fun :
Check fun x : bool ⇒x.
% fun x : bool ⇒x : bool →bool
Given an application of a lambda abstraction to a term, we can perform an eval-
uation step known as beta reduction:
(λx : s.t)u ⇝t x
u
The notation t x
u represents the term obtained from t by replacing the variable x
with the term u. Beta reduction captures the intuitive notion of function appli-
cation. Beta reduction is a basic computation rule in Coq.
Compute (fun x : bool ⇒x) true.
% true : bool
Given the above explanations, the term
Check andb true.
% andb true : bool →bool
should describe an identity function bool →bool. We conﬁrm this hypothesis by
evaluating the term with Coq.
Compute andb true.
% fun y : bool ⇒y : bool →bool
6
2014-7-16

1.2 Cascaded Functions
To evaluate a term, Coq rewrites the term with symbolic reduction rules. The
evaluation of andb true involves three reduction steps.
andb true
unfolding of the deﬁnition of andb
= (fun x : bool ⇒fun y : bool ⇒match x with true ⇒y | false ⇒false end) true
beta reduction
= fun y : bool ⇒match true with true ⇒y | false ⇒false end
match reduction
= fun y : bool ⇒y
The unfolding step done ﬁrst suggests that we wrote the deﬁnition of andb using
notational sugar. Using plain notation, we can deﬁne andb as follows.
Deﬁnition andb : bool →bool →bool :=
fun x : bool ⇒
fun y : bool ⇒
match x with
| true ⇒y
| false ⇒false
end.
Internally, Coq represents deﬁnitions and terms always in plain syntax. You can
check this with the command Print.
Print negb.
negb = fun x : bool ⇒match x with
| true ⇒false
| false ⇒true
end
: bool →bool
Coq prints the deﬁnition of andb with a notational convenience to ease reading.
Print andb.
andb = fun x y : bool ⇒match x with
| true ⇒y
| false ⇒false
end
: bool →bool →bool
The additional argument variable y in the lambda abstraction for x represents a
nested lambda abstraction for y (see the deﬁnition of andb above).
There are two basic notational rules for function types and function applica-
tions making many parentheses superﬂuous:
s →t →u
⇝
s →(t →u)
function arrow groups to the right
s t u
⇝
(s t) u
function application groups to the left
2014-7-16
7

1 Types and Functions
We have made use of these rules already.
Without the rules, the application
andb x y would have to be written as (andb x) y, and the type of andb would
have to be written as bool →(bool →bool).
When using the commands Print and Check, you may see the keyword Set in
places where you would expect the keyword Type. Types of sort Set are types at
the lowest level of a type hierarchy. For now this hierarchy does not matter.
1.3 Natural Numbers
The natural numbers can be obtained with two constructors O and S:
Inductive nat : Type :=
| O : nat
| S : nat →nat.
Expressed with O and S, the natural numbers 0, 1, 2, 3, . . . look as follows:
O, S O, S(S O), S(S(S O)), . . .
We say that the natural numbers are obtained by iterating the successor func-
tion S on the initial number O. This is a form of recursion. The recursion makes
it possible to obtain inﬁnitely many values with ﬁnitely many constructors. The
constructor representation of the natural numbers goes back to Dedekind and
Peano.
Here is a function that yields the predecessor of a number.
Deﬁnition pred (x : nat) : nat :=
match x with
| O ⇒O
| S x’ ⇒x’
end.
Compute pred (S(S O)).
% S O : nat
We now deﬁne an addition function for the natural numbers. We base the
deﬁnition on two equations:
O + y = y
Sx + y = S(x + y)
The equations are valid for all numbers x and y if we read Sx as x + 1. Read
from left to right, they constitute a recursive algorithm for computing the sum of
two numbers. The left-hand sides of the two equations amount to an exhaustive
case analysis. The second equation is recursive in that it reduces an addition
8
2014-7-16

1.3 Natural Numbers
Sx + y to an addition x + y with a smaller argument. Here is a computation
applying the equations for +:
S(S(S O)) + y = S(S(S O) + y) = S(S(S O + y)) = S(S(S y))
In Coq, we express the recursive algorithm described by the equations with a
recursive function plus.
Fixpoint plus (x y : nat) : nat :=
match x with
| O ⇒y
| S x’ ⇒S (plus x’ y)
end.
Compute plus (S O) ( S O).
% S(S O)) : nat
The keyword Fixpoint indicates that a recursive function is being deﬁned. In Coq,
functional recursion is always structural recursion. Structural recursion means
that the recursion acts on the values of an inductive type and that each recursion
step takes oﬀat least one constructor. Structural recursion always terminates.
Here is the deﬁnition of a comparison function leb : nat →nat →bool that
tests whether its ﬁrst argument is less or equal than its second argument.
Fixpoint leb (x y: nat) : bool :=
match x with
| O ⇒true
| S x’ ⇒match y with
| O ⇒false
| S y’ ⇒leb x’ y’
end
end.
A shorter, more readable deﬁnition of leb looks as follows:
Fixpoint leb’ (x y: nat) : bool :=
match x, y with
| O, _ ⇒true
| _, O ⇒false
| S x’, S y’ ⇒leb’ x’ y’
end.
Coq translates the short form automatically into the long form (you can check
this with the command Print leb′). The underline character used in the short
form serves as wildcard pattern that matches everything. The order of the rules
in sugared matches is signiﬁcant. The second rule in the sugared match is only
correct if the order of the rules is taken into account.
2014-7-16
9

1 Types and Functions
Exercise 1.3.1 Deﬁne a multiplication function mult : nat →nat →nat.
Base
your deﬁnition on the equations
O · y = O
Sx · y = y + x · y
and use the addition function plus.
Exercise 1.3.2 Deﬁne functions as follows. In each case, ﬁrst write down the
equations your function is based on.
a) A function power : nat →nat →nat that yields xn for x and n.
b) A function fac : nat →nat that yields n! for n.
c) A function evenb : nat →bool that tests whether its argument is even.
d) A function mod2 : nat →nat that yields the remainder of x on division by 2.
e) A function minus : nat →nat →nat that yields x −y for x ≥y.
f) A function gtb : nat →nat →bool that tests x > y.
g) A function eqb : nat →nat →bool that tests x = y. Do not use leb or gtb.
1.4 Structural Induction and Rewriting
The inductive type nat comes with two basic principles: structural recursion for
deﬁning functions and structural induction for proving lemmas.
Suppose we
have a proof goal
x : nat
p x
where p x is a claim that depends on a variable x of type nat. Then structural
induction on x will reduce the goal to two subgoals:
p O
x : nat
IHx : p x
p(S x)
This reduction is a case analysis on the structure of x, but has the additional
feature that the second subgoal comes with an extra assumption IHx known as
inductive hypothesis. We think of IHx as a proof of p x. If we can prove both
subgoals, we have established the initial claim p x for all x : nat. The correctness
of the proof rule for structural induction can be argued as follows.
1. The ﬁrst subgoal gives us a proof of p O.
2. The second subgoal gives us a proof of p(S O) from the proof of p O.
10
2014-7-16

1.4 Structural Induction and Rewriting
3. The second subgoal gives us a proof of p(S(S O)) from the proof of p(S O).
4. After ﬁnitely many steps we arrive at a proof of p x.
It makes sense to see the proof of the second subgoal as a function that for
a proof of p x yields a proof of p(S x). We can now obtain a proof of p x by
structural recursion: If x = O, we take the proof provided by the ﬁrst subgoal. If
x = S x′, we ﬁrst obtain a proof of p x′ by recursion and then obtain a proof of
p x = p(S x′) by applying the function provided by the second subgoal.
We will explore the logical correctness of structural recursion in more detail
once we have laid out more foundations. For now we are interested in apply-
ing the rule when we construct proofs with Coq, and this will turn out to be
straightforward.
Our ﬁrst case study of structural induction will be a proof that addition is
commutative, that is, plus x y = plus y x.
Formally, this fact is not completely
obvious, since the deﬁnition of plus is by recursion on the ﬁrst argument and
thus asymmetric. We will ﬁrst show that the symmetric variants
x + O = x
x + Sy = S(x + y)
of the equations underlying the deﬁnition of plus hold. Here is our ﬁrst inductive
proof in Coq.
Lemma plus_O x :
plus x O = x.
Proof.
induction x ; simpl.
−reﬂexivity.
−rewrite IHx. reﬂexivity.
Qed.
If you step through the proof script with Coq, you will see the following proof
goals.
x : nat
plus x O = x
O = O
x : nat
IHx : plus x O = x
S(plus x O) = Sx
x : nat
IHx : plus x O = x
Sx = Sx
induction x ; simpl
reﬂexivity
rewrite IHx
reﬂexivity
Of particular interest is the application of the inductive hypothesis with the tactic
rewrite IHx. The tactic rewrites a subterm of the claim with the equation IHx.
Doing inductive proofs with Coq is fun since Coq takes care of the bureau-
cratic aspects of the proof process. Here is our next example.
2014-7-16
11

1 Types and Functions
Lemma plus_S x y :
plus x (S y) = S (plus x y).
Proof.
induction x ; simpl.
−reﬂexivity.
−rewrite IHx. reﬂexivity.
Qed.
Note that the proof scripts for the lemmas plus_S and plus_O are identical. When
you run the script for each of the two lemmas, you see that they generate diﬀer-
ent proofs. Using the lemmas, we can prove that addition is commutative.
Lemma plus_com x y :
plus x y = plus y x.
Proof.
induction x ; simpl.
−rewrite plus_O. reﬂexivity.
−rewrite plus_S. rewrite IHx. reﬂexivity.
Qed.
Note that the lemmas are applied with the rewrite tactic.
Next we prove that addition is associative.
Lemma plus_asso x y z :
plus (plus x y) z = plus x (plus y z).
Proof.
induction x ; simpl.
−reﬂexivity.
−rewrite IHx. reﬂexivity.
Qed.
Exercise 1.4.1 Prove the commutativity of plus by induction on y.
1.5 More on Rewriting
When we rewrite with an equational lemma like plus_com, it may happen that
the lemma applies to several subterms of the claim. In such a situation it may
be necessary to tell Coq which subterm it should rewrite. To do such controlled
rewriting, we have to load the module Omega of the standard library and use the
tactic setoid_rewrite. Here is an example deserving careful exploration with Coq.
Require Import Omega.
Lemma plus_AC x y z :
plus y (plus x z) = plus (plus z y) x.
12
2014-7-16

1.5 More on Rewriting
Proof.
setoid_rewrite plus_com at 3.
setoid_rewrite plus_com at 1.
apply plus_asso.
Qed.
Note the use of the tactic apply to ﬁnish the proof by application of the lemma
plus_asso. Here is a more involved example.
Lemma plus_AC’ x y z :
plus (plus (mult x y) (mult x z)) (plus y z) = plus (plus (mult x y) y) (plus (mult x z) z).
Proof.
rewrite plus_asso. rewrite plus_asso. f_equal.
setoid_rewrite plus_com at 1. rewrite plus_asso. f_equal.
apply plus_com.
Qed.
Run the proof script to understand the eﬀect of the tactic f _equal.
Both rewrite tactics can apply equations from right to left. This is requested
by writing an arrow “<-” before the name of the equation. Here is an example
(one can use the keyword Example as a synonym for Lemma).
Example Ex1 x y z :
S (plus x (plus y z)) = S (plus (plus x y) z).
Proof. rewrite ←plus_asso. reﬂexivity. Qed.
Exercise 1.5.1 Prove the following lemma without using the tactic reﬂexivity for
the inductive step (i.e., the second subgoal of the induction).
Use the tactics
f _equal and apply to substitute for reﬂexivity.
Lemma mult_S’ x y :
mult x (S y) = plus (mult x y) x.
Exercise 1.5.2 Prove the following lemmas.
Lemma mult_O (x : nat) :
mult x O = O.
Lemma mult_S (x y : nat) :
mult x (S y) = plus (mult x y) x.
Lemma mult_com (x y : nat) :
mult x y = mult y x.
Lemma mult_dist (x y z: nat) :
mult (plus x y) z = plus (mult x z) (mult y z).
Lemma mult_asso (x y z: nat) :
mult (mult x y) z = mult x (mult y z).
2014-7-16
13

1 Types and Functions
1.6 Recursive Abstractions
The plain notation for recursive functions uses recursive abstractions written
with the keyword ﬁx.
Print plus.
plus = ﬁx f (x y : nat) {struct x} : nat :=
match x with
| O ⇒y
| S x’ ⇒S (f x’ y)
end
: nat →nat →nat
The variable f appearing after the keyword ﬁx is local to the abstraction and rep-
resents the recursive function described. As with argument variables, the local
name of a recursive function does not matter. You may use g or plus in place
of f , for instance. The annotation {struct x} says that the structural recursion
is on x. If you write a recursive abstraction by hand you may omit the anno-
tation and Coq will infer it automatically. In fully plain notation the recursive
abstraction for plus takes only one argument:
ﬁx f (x : nat) : nat →nat :=
fun y : nat ⇒match x with
| O ⇒y
| S x’ ⇒S (f x’ y)
end.
The reduction rule for recursive abstractions only applies if the argument of
the recursive abstraction exhibits at least one constructor. When a recursive ab-
straction is reduced, the local name of the recursive function is replaced with the
recursive abstraction. Experiment with Coq to get a feel for this. The following
interactions will get you started.
Compute plus O.
% fun y : nat ⇒y
Compute plus (S (S O)).
% fun y : nat ⇒S(Sy)
Compute fun x ⇒plus (S x).
fun x : nat ⇒
fun y : nat ⇒
S ( (ﬁx f (x : nat) : nat →nat :=
fun y : nat ⇒match x with
| O ⇒y
| S x’ ⇒S (f x’ y)
end) x y )
14
2014-7-16

1.7 Deﬁned Notations
At ﬁrst, the many notational variants Coq supports for a term can be confus-
ing. Even in printing-all mode identical terms may be displayed with diﬀerent
names for the local variables. You can ﬁnd out more by stating equational lem-
mas and using the tactics compute and reﬂexivity. Here are examples.
Goal plus O = fun x ⇒x.
Proof. compute. reﬂexivity. Qed.
Goal (fun x ⇒plus (S x)) = fun x y ⇒S (plus x y).
Proof. compute. reﬂexivity. Qed.
The command Goal states a lemma without giving it a name. The tactic compute
computes the normal form of the claim. We have inserted the compute tactic so
that we can see the normal forms of the terms being equated. The normal form
of a term s is the term obtained by fully evaluating s. Every term has exactly
one normal form. The reﬂexivity tactic proves every equation where both sides
evaluate to the same normal form.
1.7 Deﬁned Notations
Coq comes with commands for deﬁning notations. For instance, we can deﬁne
inﬁx notations for plus and mult.
Notation "x + y" := (plus x y) (at level 50, left associativity).
Notation "x * y" := (mult x y) (at level 40, left associativity).
We can now write the distributivity law for multiplication and addition in familiar
form:
Lemma mult_dist’ x y z :
x * (y + z) = x*y + x*z.
Proof.
induction x ; simpl.
−reﬂexivity.
−rewrite IHx. rewrite plus_asso. rewrite plus_asso. f_equal.
setoid_rewrite ←plus_asso at 2.
setoid_rewrite plus_com at 4.
symmetry. apply plus_asso.
Qed.
Note the use of the tactic symmetry to turn around the equation to be shown.
You can tell Coq to not use deﬁned notations when it prints terms.1
Set Printing All.
1 When working with CoqIde, use the view menu to switch printing-all mode on and oﬀ(display
all basic low-level contents).
2014-7-16
15

1 Types and Functions
Check O + O * S O.
% plus O (mult O (S O)) : nat
Unset Printing All.
It is very important to distinguish between notation and abstract syntax when
working with Coq.
Notations are used when reading input from and writing
output to the user.
Internally, all notational sugar is removed and terms are
represented in abstract syntax. The abstract syntax is basically what you see in
printing-all mode. All logical reasoning is deﬁned on the abstract syntax. As it
comes to semantic issues, it is irrelevant in which notation a syntactic object is
described. So if for some term written with notational sugar it is not clear to you
how it translates to abstract syntax, switching to printing-all mode is always a
good idea.
Exercise 1.7.1 Prove the lemmas from Exercise 1.5.2 once more using inﬁx no-
tations for plus and mult. Note that the proof scripts remain unchanged.
Exercise 1.7.2 Prove associativity of multiplication using the distributivity
lemma mult_dist′ from this section. This proof requires more applications of
the commutativity law for multiplication than a proof using the lemma mult_dist
from Exercise 1.5.2.
Exercise 1.7.3 Prove (x + x) + x = x + (x + x) by induction on x using Lemma
plus_S. Note that the direct proof of this instance of the associativity law is more
complicated than the proof of the general associativity law.
In fact, it seems
impossible to prove (x + x) + x = x + (x + x) without using a lemma.
1.8 Standard Library
Coq comes with an extensive standard library providing deﬁnitions, notations,
lemmas, and tactics. When it starts, the Coq interpreter loads part of the stan-
dard library. You can load additional modules using the command Require. (We
have already used Require to load the module Omega so that we can use the
smart rewriting tactic setoid_rewrite.)
The deﬁnitions the Coq interpreter starts with include the types bool and
nat. So there is no need to deﬁne these types when we want to use them. The
standard library equips nat with many notations familiar from Mathematics. For
instance, we may write 2 + 3 ∗2 for plus (S(S O)) (mult (S(S(S O))) (S(S O))).
The following interaction illustrates the predeﬁned notational sugar.
Set Printing All.
16
2014-7-16

1.8 Standard Library
Check 2+3*2.
% plus (S(S O)) (mult (S(S(S O))) (S(S O))) : nat
Unset Printing All.
The above interaction took place in a context where the library deﬁnitions of
nat, plus, and mult were not overwritten. If you execute the above commands
in a context where you have deﬁned your own versions of nat, plus, and times,
you will see that the notations 2, 3, +, and ∗still refer to the predeﬁned objects
from the library. If you want to know more about predeﬁned identiﬁers, you may
use the commands Check and Print or consult the Coq library pages in the Web
(at coq.inria.fr). If you want to know more about a notation, you may use the
command Locate.
Locate ‘‘*’’.
When you run the above command, you will see that “*” is used with more than
one deﬁnition (so-called overloading).
For boolean matches, Coq’s library provides the if-then-else notation.
For
instance:
Set Printing All.
Check if false then 0 else 1.
% match false return nat with true ⇒O | false ⇒S O end
Unset Printing All.
Note that the match is shown with a return type annotation. The return type
annotation is part of the abstract syntax of a match. The annotation is usually
added by Coq but can also be stated explicitly.
The standard module Omega comes with an automation tactic omega that
knows about the arithmetic primitives of the library. For instance, omega can
prove that addition is associative:
Goal ∀x y z, (x + y) + z = x + (y + z).
Proof. intros x y z. omega. Qed.
Note the explicit quantiﬁcation of the variables x, y, and z with the universal
quantiﬁer ∀. The symbol ∀can written as the string forall in Coq. Also note the
use of the tactic intros to introduce the quantiﬁed variables as assumptions.
The tactic omega works well for goals that involve addition and subtraction.
It knows little about multiplication but can deal well with products where one
side is a constant.
Goal ∀x y, 2 * (x + y) = (y + x) * 2.
Proof. intros x y. omega. Qed.
2014-7-16
17

1 Types and Functions
1.9 Pairs and Implicit Arguments
Given two values x and y, we can form the ordered pair (x, y).
Given two
types X and Y, we can form the product type X × Y containing all pairs whose
ﬁrst component is an element of X and whose second component is an element
of Y. This leads to the Coq deﬁnition
Inductive prod (X Y : Type) : Type :=
| pair : X →Y →prod X Y.
which ﬁxes two constructors
prod : Type →Type →Type
pair : ∀X Y : Type. X →Y →prod X Y
for obtaining products and pairs. The pairing constructor takes four arguments,
where the ﬁrst two arguments are the types of the components of the pair to be
constructed. Here are typings explaining the type of the pairing constructor.
pair nat : ∀Y : Type. nat →Y →prod nat Y
pair nat bool : nat →bool →prod nat bool
pair nat bool O : bool →prod nat bool
pair nat bool O true : prod nat bool
One says that pair is a polymorphic constructor. This addresses the fact
that the types of the third and fourth argument are given as ﬁrst and second
argument.
While the logical analysis is conclusive, the resulting notation for
pairs is tedious. As is, we have to write pair nat bool 0 true for the pair (0, true).
Fortunately, Coq comes with a type inference feature making it possible to just
write pair 0 true and leave it to the interpreter to insert the missing arguments.
One speaks of implicit arguments. With the command
Arguments pair {X} {Y} _ _.
we tell Coq to treat the arguments X and Y of pair as implicit arguments. Now
we can obtain pairs without specifying the types of the components.
Check pair 0 true.
% pair 0 true : prod nat bool
The implicit arguments of a function can still be given explicitly if we preﬁx the
name of the function with the character @:
Check @pair nat.
% @pair nat : ∀Y : Type, nat →Y →prod nat Y
Check @pair nat bool 0.
% @pair nat bool 0 : bool →prod nat bool
18
2014-7-16

1.9 Pairs and Implicit Arguments
We can see which terms Coq inserts for the implicit arguments by switching to
printing-all mode.
Set Printing All.
Check pair 0 true.
% @pair nat bool 0 true : prod nat bool
Unset Printing All.
You can use the command About to ﬁnd out which arguments of a function name
are implicit.
About pair.
pair : ∀X Y : Type, X →Y →prod X Y
Arguments X, Y are implicit
Coq actually prints more information about the arguments, but the extra infor-
mation is not relevant for now.
We can switch Coq into implicit arguments mode, which has the eﬀect that
some arguments are automatically declared implicit when a function name is de-
ﬁned. With implicit arguments mode on, the inductive deﬁnition of pairs would
automatically equip the constructor pair with the two implicit arguments de-
clared above. We now switch to implicit arguments mode
Set Implicit Arguments.
Unset Strict Implicit.
and deﬁne functions yielding the ﬁrst and the second component of a pair (so-
called projections).
Deﬁnition fst (X Y : Type) (p : prod X Y) : X :=
match p with pair x _ ⇒x end.
Deﬁnition snd (X Y : Type) (p : prod X Y) : Y :=
match p with pair _ y ⇒y end.
Compute fst (pair O true).
% O : nat
Compute snd (pair O true).
% true : bool
Note that the ﬁrst two arguments of fst and snd are implicit. We prove the so-
called eta law for pairs.
Lemma pair_eta (X Y : Type) (p : prod X Y) :
pair (fst p) (snd p) = p.
Proof. destruct p as [x y]. simpl. reﬂexivity. Qed.
2014-7-16
19

1 Types and Functions
Note the use of the tactic destruct. It replaces the variable p with the pair pair x y
where x and y are fresh variables. This is justiﬁed since pair is the only con-
structor with which a value of type prod X Y can be obtained. Destructuring of
a variable of a single constructor type is similar to matching on a variable of a
single constructor type (see the deﬁnitions of fst and snd).
The standard library deﬁnes products and pairs as shown above and equips
them with familiar notations. Using the deﬁnitions and notations of the standard
library, we can state and prove the eta law as follows.
Lemma pair_eta (X Y : Type) (p : X * Y) :
(fst p, snd p) = p.
Proof. destruct p as [x y]. simpl. reﬂexivity. Qed.
Here is a function swapping the components of a pair:
Deﬁnition swap (X Y : Type) (p : X * Y) : Y * X :=
(snd p, fst p).
Compute swap (0, true).
% (true, 0) : prod bool nat
Lemma swap_swap (X Y : Type) (p : X * Y) :
swap (swap p) = p.
Proof. destruct p as [x y]. unfold swap. simpl. reﬂexivity. Qed.
Note the use of the tactic unfold. We use it since simpl does not simplify appli-
cations of functions not involving a match. Since reﬂexivity does all the required
unfolding and simpliﬁcation automatically, we may omit the unfold and simpli-
ﬁcation tactics in the above script.
The notations for pairs and products are deﬁned such that nesting to the
left may be written without parentheses. For instance, we may write (1, 2, 3) for
((1, 2), 3) and nat ∗nat ∗nat for (nat ∗nat) ∗nat. So the command
Check (fun x : nat * nat * nat ⇒fst x) (1,2,3)
will succeed with the type nat ∗nat.
Exercise 1.9.1 An operation taking two arguments can be represented either as
a function taking its arguments one by one (cascaded representation) or as a
function taking both arguments bundled in one pair (cartesian representation).
While the cascaded representation is natural in Coq, the cartesian representation
is common in mathematics. Deﬁne polymorphic functions
car : ∀X Y Z : Type, (X →Y →Z) →(X ∗Y →Z)
cas : ∀X Y Z : Type, (X ∗Y →Z) →(X →Y →Z)
that translate between the cascaded and cartesian representation and prove the
correctness of your functions with the following lemmas.
20
2014-7-16

1.10 Lists
Lemma car_spec X Y Z (f : X →Y →Z) x y :
car f (x,y) = f x y.
Lemma cas_spec X Y Z (f : X * Y →Z) x y :
cas f x y = f (x,y).
Note that the arguments X, Y, and Z of car and cas are implicit.
1.10 Lists
Lists represent ﬁnite sequences [x1 ; . . . ; xn] with two constructors nil and cons.
[]
֏
nil
[x]
֏
cons x nil
[x ; y]
֏
cons x (cons y nil)
[x ; y ; z]
֏
cons x (cons y (cons z nil))
The constructor nil represents the empty sequence. Nonempty sequences are
obtained with the constructor cons. All elements of a list must be taken from the
same type. This design is realized by the following inductive deﬁnition.
Inductive list (X : Type) : Type :=
| nil : list X
| cons : X →list X →list X.
The deﬁnition provides three constructors:
list : Type →Type
nil : ∀X : Type. list X
cons : ∀X : Type. X →list X →list X
With implicit arguments mode switched on, the type argument of cons is declared
implicit. This is not the case for the type argument of nil since there is no other
argument where the argument can be obtained from. So we use the arguments
command to declare the argument of nil as implicit.
Arguments nil {X}.
Now Coq will try to derive the argument of nil from the context surrounding an
occurrence of nil. For instance:
Set Printing All.
Check cons 1 nil.
% @cons nat (S O) (@nil nat) : list nat
Unset Printing All.
We deﬁne an inﬁx notation for cons.
2014-7-16
21

1 Types and Functions
Notation "x :: y" := (cons x y) (at level 60, right associativity).
Set Printing All.
Check 1::2::nil.
% @cons nat (S O) (@cons nat (S (S O)) (@nil nat)) : list nat
Unset Printing All.
We also deﬁne the bracket notation for lists.
Notation "[]" := nil.
Notation "[ x ]" := (cons x nil).
Notation "[ x ; .. ; y ]" := (cons x .. (cons y nil) ..).
Set Printing All.
Check [1;2].
% @cons nat (S O) (@cons nat (S (S O)) (@nil nat)) : list nat
Unset Printing All.
Using informal notation, we deﬁne functions yielding the length, the concate-
nation, and the reversal of lists.
|[x1 ; . . . ; xn]| := n
[x1 ; . . . ; xm] ++ [y1 ; . . . ; yn] := [x1 ; . . . ; xm ; y1 ; . . . ; yn]
rev [x1 ; . . . ; xn] := [xn ; . . . ; x1]
The formal deﬁnitions of these functions replace the dot-dot-dot notation with
structural recursion on the constructor representation of lists. The idea is ex-
pressed with the following equations.
|nil| = 0
|x :: A| = 1 + |A|
nil ++ B = B
x :: A ++ B = x :: (A ++ B)
rev nil = nil
rev (x :: A) = rev A ++[x]
The Coq deﬁnitions are now straightforward.
Fixpoint length (X : Type) (A : list X) : nat :=
match A with
| nil ⇒O
| _ :: A’ ⇒S (length A’)
end.
Notation "| A |" := (length A) (at level 70).
22
2014-7-16

1.10 Lists
Fixpoint app (X : Type) (A B : list X) : list X :=
match A with
| nil ⇒B
| x :: A’ ⇒x :: app A’ B
end.
Notation "x ++ y" := (app x y) (at level 60, right associativity).
Fixpoint rev (X : Type) (A : list X) : list X :=
match A with
| nil ⇒nil
| x :: A’ ⇒rev A’ ++ [x]
end.
Compute rev [1;2;3].
% [3 ; 2 ; 1] : list nat
Properties of the list operations can be shown by structural induction on lists,
which has much in common with structural induction on numbers.
Lemma app_nil (X : Type) (A : list X) :
A ++ nil = A.
Proof.
induction A as [|x A] ; simpl.
−reﬂexivity.
−rewrite IHA. reﬂexivity.
Qed.
Note that the script applies the induction tactic with an annotation specifying
the variable names to be used in the inductive step. Try out what happens if you
replace x with b and A with B. The vertical bar in the annotation separates the
base case of the induction from the inductive step.
Lists are provided through the standard module List.
The following com-
mands load the module and the notations coming with it.
Require Import List.
Import ListNotations.
Notation "| A |" := (length A) (at level 70).
This gives you everything we have deﬁned so far. The notation command deﬁnes
the notation for length, which is not deﬁned in the standard library.
Exercise 1.10.1 Prove the following lemmas.
Lemma app_assoc (X : Type) (A B C : list X) :
(A ++ B) ++ C = A ++ (B ++ C).
Lemma length_app (X : Type) (A B : list X) :
|A ++ B| = |A| + |B|.
2014-7-16
23

1 Types and Functions
Lemma rev_app (X : Type) (A B : list X) :
rev (A ++ B) = rev B ++ rev A.
Lemma rev_rev (X : Type) (A : list X) :
rev (rev A) = A.
1.11 Quantiﬁed Inductive Hypotheses
So far the inductive hypotheses of our inductive proofs were plain equations.
We will now see inductive proofs where the inductive hypothesis is a universally
quantiﬁed equation, and where the quantiﬁcation is needed for the proof to go
through. As examples we consider correctness proofs for tail-recursive variants
of recursive functions.
If you are familiar with functional programming, you will know that the func-
tion rev deﬁned in the previous section takes quadratic time to reverse a list.
This is due to the fact that each recursion step involves an application of the
function app. One can write a tail-recursive function that reverses lists in linear
time. The trick is to move the elements of the main list to a second list passed
as an additional argument.
Fixpoint revi (X : Type) (A B : list X) : list X :=
match A with
| nil ⇒B
| x :: A’ ⇒revi A’ (x :: B)
end.
The following lemma gives us a non-recursive characterization of revi.
Lemma revi_rev (X : Type) (A B : list X) :
revi A B = rev A ++ B.
We prove this lemma by induction on A. For the induction to go through, the
inductive hypothesis must hold for all lists B. To get this property, we move the
universal quantiﬁcation for B from the assumptions to the claim before we start
the induction. We use the tactic revert to move the quantiﬁcation.
Proof.
revert B. induction A as [|x A] ; simpl.
−reﬂexivity.
−intros B. rewrite IHA. rewrite app_assoc. simpl. reﬂexivity.
Qed.
Step through the script to see how the proof works. The tactic intros B moves
the universal quantiﬁcation of B from the claim back to the assumptions.
Exercise 1.11.1 Prove the following lemma.
24
2014-7-16

1.12 Iteration as Polymorphic Higher-Order Function
Lemma rev_revi (X : Type) (A : list X) :
rev A = revi A nil.
Note that the lemma tells us how we can reverse lists with revi.
Exercise 1.11.2 Here is a tail-recursive function obtaining the length of a list
with an additional argument.
Fixpoint lengthi (X : Type) (A : list X) (n : nat) :=
match A with
| nil ⇒n
| _ :: A’ ⇒lengthi A’ (S n)
end.
Proof the following lemmas. The tactic omega will be helpful.
Lemma lengthi_length X (A : list X) n :
lengthi A n = |A| + n.
Lemma length_lengthi X (A : list X) :
|A| = lengthi A 0.
Exercise 1.11.3 Deﬁne a factorial function fact and a tail-recursive function facti
that computes factorials using an additional argument. Prove fact n = facti n 1
for
all
n.
Use
the
tactic
omega
and
the
lemmas
mult_plus_distr_l,
mult_plus_distr_r, mult_assoc, and mult_comm from the standard library.
1.12 Iteration as Polymorphic Higher-Order Function
We now deﬁne a function iter that yields f nx given n, f , and x. Speaking pro-
cedurally, f nx is obtained from x by applying n-times the function f . We base
the deﬁnition of iter on two equations:
iter 0 f x = x
iter (S n) f x = f (iter n f x)
For the deﬁnition of iter we need the type of x. Since this can be any type, we
take the type of x as argument.
Fixpoint iter (n : nat) (X : Type) (f : X →X) (x : X) : X :=
match n with
| 0 ⇒x
| S n’ ⇒f (iter n’ f x)
end.
2014-7-16
25

1 Types and Functions
Since we are working in implicit arguments mode, the type argument X of iter is
implicit.
The function iter formulates a recursion principle known as iteration or prim-
itive recursion. It also serves us as an example of a polymorphic higher-order
function. A function is polymorphic if it takes a type as argument, and higher-
order if it takes a function as argument.
Many operations can be expressed with iter. We consider addition.
Lemma iter_plus x y :
x + y = iter x S y.
Proof. induction x ; simpl ; congruence. Qed.
Note the use of the automation tactic congruence. This tactic can ﬁnish oﬀproofs
if rewriting with unquantiﬁed equations and reﬂexivity suﬃce.
Subtraction is another operation that can be expressed with iter.
Lemma iter_minus x y :
x−y = iter y pred x.
Proof. induction y ; simpl ; omega. Qed.
The minus notation and the predecessor function pred are from the standard
library. Use the commands locate and Print to ﬁnd out more.
The standard library provides iter under the name nat_iter.
Exercise 1.12.1 Prove the following lemma:
Lemma iter_mult x y :
x * y = iter x (plus y) 0.
Exercise 1.12.2 Prove the following lemma:
Lemma iter_shift X (f : X →X) x n :
iter (S n) f x = iter n f (f x)
Exercise 1.12.3 Deﬁne a function power computing powers xn and prove the
following lemma.
Lemma iter_power x n :
power x n = iter n (mult x) 1.
Exercise 1.12.4 iter can compute factorials by iterating on pairs.
(0, 0!) →(1, 1!) →(2, 2!) →· · · →(n, n!)
Write a factorial function fact and a step function step such that you can prove
the following lemmas.
26
2014-7-16

1.13 Options and Finite Types
Lemma iter_fact_step n :
step (n, fact n) = (S n, fact (S n)).
Lemma iter_fact’ n :
iter n step (O,1) = (n, fact n).
Lemma iter_fact n :
fact n = snd (iter n step (O,1)).
Exercise 1.12.5 We can see iter n as a functional representation of the num-
ber n carrying with it the structural recursion coming with n. The type of the
functional representations is as follows.
Deﬁnition Nat := ∀X : Type, (X →X) →X →X.
Write conversion functions encode : nat →Nat and decode : Nat →nat and prove
decode (encode n) = n for every number n.
1.13 Options and Finite Types
We will deﬁne a function that for a number n yields a type with n elements. The
function will start from an empty type and n-times apply a function that for a
given type yields a type with one additional element.
Coq’s standard library deﬁnes an empty type Empty_set as an inductive type
without constructors:
Inductive Empty_set : Type := .
Since Empty_set is empty, it is inconsistent to assume that it has an element. In
fact, if we assume that Empty_set has an element, we can prove everything. For
instance:
Lemma vacuous_truth (x : Empty_set) :
1 = 2.
Proof. destruct x. Qed.
The proof is by case analysis over the assumed element x of Empty_set. Since
Empty_set has no constructor, we can prove the claim 1 = 2 for every construc-
tors of Empty_set. One says that the claim follows vacuously. Vacuous reasoning
is a basic logical principle.2
The type constructor option from the standard library can be applied to any
type and yields a type with one additional element.
2 From Wikipedia: A vacuous truth is a truth that is devoid of content because it asserts some-
thing about all members of a class that is empty or because it says “If A then B” when in fact A
is inherently false. For example, the statement “all cell phones in the room are turned oﬀ” may
be true simply because there are no cell phones in the room. In this case, the statement “all
cell phones in the room are turned on” would also be considered true, and vacuously so.
2014-7-16
27

1 Types and Functions
Inductive option (X : Type) : Type :=
| Some : X →option X
| None : option X.
The constructor Some yields the elements of X and the constructor None yields
the new element (none of the old elements). The elements of an option type are
called options. The standard library declares the type argument X of both Some
and None as implicit argument (check with Print).
We can now deﬁne a function ﬁn : nat →Type such that ﬁn n is a type with n
elements.
Deﬁnition ﬁn (n : nat) : Type :=
nat_iter n option Empty_set.
Here are deﬁnitions naming the elements of the types ﬁn 1, ﬁn 2, and ﬁn 3.
Deﬁnition a11 : ﬁn 1 := @None Empty_set.
Deﬁnition a21: ﬁn 2 := Some a11.
Deﬁnition a22 : ﬁn 2 := @None (ﬁn 1).
Deﬁnition a31: ﬁn 3 := Some a21.
Deﬁnition a32 : ﬁn 3 := Some a22.
Deﬁnition a33 : ﬁn 3 := @None (ﬁn 2).
For clarity we have speciﬁed the implicit argument of None. You may omit the
implicit arguments and leave it to Coq to insert them. Next we establish three
simple facts about ﬁnite types.
Goal ∀n, ﬁn (2+n) = option (ﬁn (S n)).
Proof. intros n. reﬂexivity. Qed.
Goal ∀m n, ﬁn (m+n) = ﬁn (n+m).
Proof.
intros m n. f_equal. omega.
Qed.
Lemma ﬁn1 (x : ﬁn 1) :
x = None.
Proof.
destruct x as [x|].
−simpl in x. destruct x.
−reﬂexivity.
Qed.
Exercise 1.13.1 One can deﬁne a bijection between bool and ﬁn 2. Show this fact
by completing the deﬁnitions and proving the lemmas shown below.
Deﬁnition fromBool (b : bool) : ﬁn 2 :=
Deﬁnition toBool (x : ﬁn 2) : bool :=
Lemma bool_ﬁn b : toBool (fromBool b) = b.
Lemma ﬁn_bool x : fromBool (toBool x) = x.
28
2014-7-16

1.14 More about Functions
Exercise 1.13.2 One can deﬁne a bijection between nat and option nat. Show
this fact by deﬁning functions fromNat and toNat and by proving that they com-
mute.
Exercise 1.13.3 In Coq every function is total. Option types can be used to ex-
press partial functions as total functions.
a) Deﬁne a function ﬁnd : ∀X : Type, (X →bool) →list X →option X that given
a test p and a list A yields an element of A satisfying p if there is one.
b) Deﬁne a function minus_opt : nat →nat →option nat that yields x −y if
x ≥y and None otherwise.
1.14 More about Functions
Functions are objects of our imagination.
A function relates arguments with
results, where an argument is related with at most one result. One says that
functions map arguments to results.
Functions in Coq are very general in that they can take functions and types as
arguments and yield functions and types as results. For instance:
•
The type constructor list is a function that maps types to types.
•
The value constructor nil is a function that maps types to lists.
•
The function plus maps numbers to functions that map numbers to numbers.
•
The function ﬁn maps numbers to types.
Coq describes functions, arguments, and results with syntactic objects called
terms. There are four canonical forms for terms describing functions:
1. A lambda abstraction λx : s.t.
2. A recursive abstraction ﬁx f (x : s) : t := u.
3. A constructor c.
4. An application c t1 · · · tn of a constructor c to n ≥1 terms t1, . . . , tn.
The general form of a function type is ∀x : s.t. A function of type ∀x : s.t
relates every element x of type s with exactly one element of type t. One speaks
of a dependent function type if the argument variable x appears in t. If x does
not appear in t, there is no dependency and ∀x : s.t is written as s →t.
Check ∀x : nat, nat.
% nat →nat : Type
In Coq, every function has a unique type. Here are examples of functions and
2014-7-16
29

1 Types and Functions
their types:
andb : bool →bool →bool
cons : ∀X : Type, X →list X →list X
iter : nat →∀X : Type, (X →X) →X →X
ﬁn : nat →Type
The functions andb, cons, and iter are cascaded, which means that they yield a
function when applied to an argument. One says that a cascaded function takes
more than one argument. The function andb takes 2 arguments, and cons takes 3
arguments. The function iter is more interesting. It takes at least 4 arguments,
but it may take additional arguments if the second argument is a function type:
iter 2 nat : (nat →nat) →nat →nat
iter 2 (nat →nat) : ((nat →nat) →nat →nat) →(nat →nat) →nat →nat
One says that a function of type ∀x : s.t is polymorphic if x ranges over types.
The constructors nil and cons are typical examples of polymorphic functions.
The function iter yields a polymorphic function for every argument.
Coq comes with reduction rules for terms. A reduction rule describes a com-
putation step. Coq is designed such that the application of reduction rules to
terms always terminates with a unique normal form. We say that a term evalu-
ates to its normal form. We have seen four reduction rules so far:
•
The application of a lambda abstraction to a term can always be reduced (beta
reduction).
•
A match on a constructor or the application of a constructor can always be
reduced.
•
A deﬁned name can always be reduced to the term the name is bound to
(unfolding).
•
The application of a recursive abstraction to a constructor or the application
of a constructor can always be reduced.
Coq diﬀers from functional programming languages in that its type discipline
is more general and in that it restricts recursion to structural recursion. In Coq,
types are ﬁrst-class values and polymorphic types are ﬁrst-class types, which is
not the case in functional programming languages. On the other hand, recursion
in Coq is always tied to an inductive type and every recursion step must take oﬀ
at least one constructor.
30
2014-7-16

1.15 Discussion and Remarks
1.15 Discussion and Remarks
A basic feature of Coq’s language are inductive types. We have introduced induc-
tive types for booleans, natural numbers, pairs, and lists. The elements of induc-
tive types are obtained with so-called constructors. Inductive types generalize
the structure underlying the Peano axioms for the natural numbers. Inductive
types are a basic feature of modern functional programming languages (e.g., ML
and Haskell). The ﬁrst functional programming language with inductive types
was Hope, developed in the 1970’s in Edinburgh by Rod Burstall and others.
Inductive types are accompanied by structural case analysis, structural re-
cursion, and structural induction. Typical examples of recursive functions are
addition and multiplication of numbers and concatenation and reversal of lists.
We have also seen a polymorphic higher-order function iter formulating a recur-
sion scheme known as iteration.
Coq is designed such that evaluation always terminates. For this reason Coq
restricts recursion to structural recursion on inductive types. Every recursion
step must take oﬀat least one constructor of a given argument.
The idea of cascaded functions appeared 1924 in a paper by Moses Schön-
ﬁnkel and was fully developed in the 1930’s by Alonzo Church and Haskell
Curry. Lambda abstractions and beta reduction were ﬁrst studied in the 1930’s
by Alonzo Church and his students in an untyped syntactic system called lambda
calculus. The idea of dependent function types evolved in the 1970’s in the works
of Nicolaas de Bruijn, Jean-Yves Girard, and Per Martin-Löf.
Coq comes with many notational devices including user-deﬁned inﬁx nota-
tions and implicit arguments. It is very important to distinguish between no-
tational conveniences and abstract syntax. Notational conveniences are familiar
from mathematics and make it possible for humans to work with complex terms.
However, all semantic issues and all logical reasoning are deﬁned on the abstract
syntax where all conveniences are removed and all details are ﬁlled in.
Coq supports the formulation and the proof of theorems.
So far we have
just seen the tip of the iceberg. We have formulated equational theorems and
used case analysis, induction, and rewriting to prove them. In Coq, Proofs are
constructed by scripts, which are obtained with commands called tactics. A tactic
either resolves a proof goal or reduces a proof goal to one or several subgoals.
Proof scripts are constructed in interaction with Coq, where Coq applies the
proof rules and maintains and displays the open subgoals.
Proof scripts are programs that construct proofs.
To understand a proof,
one steps with the Coq interpreter through the script constructing the proof and
looks at the proof goals obtained with the tactics. Eventually, we will learn that
Coq represents proofs as terms. If you are curious, you may use the command
2014-7-16
31

1 Types and Functions
Print L to see the term serving as the proof of a lemma L.
Coq Summary
Type and Value Constructors from the Standard Library
bool, true, false, nat, O, S, prod, pair, list, nil, cons, Empty_set, option, Some,
None.
Deﬁned Functions from the Standard Library
negb, andb, pred, plus, mult, minus, nat_iter, length, app, rev.
Term Variants
Names, applications, matches (match), lambda abstractions (fun), recursive ab-
stractions (ﬁx).
Deﬁnitional Commands
Inductive, Deﬁnition, Fixpoint, Lemma, Example, Goal, Proof , Qed.
Tactics
destruct,
induction,
simpl,
unfold,
reﬂexivity,
symmetry,
f _equal,
rewrite,
setoid_rewrite, apply, intros, revert, congruence, omega.
Notational Commands
Notation, Arguments, Set Implicit Arguments, Unset Strict Implicit.
Module Commands
Require Import, Import.
Query Commands
Check, Compute, Print, About, Locate, Set/Unset Printing All.
Make sure that for each of the above constructs you can point to examples in
the text of this chapter. To know more, consult the Coq online documentation at
coq.inria.fr.
32
2014-7-16

2 Propositions and Proofs
Logical statements are called propositions in Coq.
So far we have only seen
equational propositions. We now extend our repertoire to propositions involving
connectives and quantiﬁers.
2.1 Logical Connectives and Quantiﬁers
When we argue logically, we often combine primitive propositions into com-
pound propositions using logical operations. The logical operations include con-
nectives like implication and quantiﬁers like “for all”. Here is an overview of the
logical operations we will consider.
Operation
Notation
Reading
conjunction
A ∧B
A and B
disjunction
A ∨B
A or B
implication
A →B
if A, then B
equivalence
A ↔B
A if and only if B
negation
¬A
not A
universal quantiﬁcation
∀x : T. A
for all x in T, A
existential quantiﬁcation
∃x : T. A
for some x in T, A
There are two diﬀerent ways of assigning meaning to logical operations and
propositions. The classical approach commonly used in mathematics postulates
that every proposition has a truth value that is either true or false. The more
recent constructive approach deﬁnes the meaning of propositions in terms of
their proofs and does not rely on truth values.
Coq and our presentation of
logic follow the constructive approach. The cornerstone of the constructive ap-
proach is the BHK interpretation,1 which relates proofs and logical operations
as follows.
•
A proof of A ∧B consists of a proof of A and a proof of B.
•
A proof of A ∨B is either a proof of A or a proof of B.
•
A proof of A →B is a function that for every proof of A yields a proof of B.
1 The name BHK interpretation reﬂects the origin of the scheme in the work of the mathemati-
cians Luitzen Brouwer, Arend Heyting, and Andrey Kolmogorov in the 1930’s.
33

2 Propositions and Proofs
•
A proof of ∀x : T.A is a function that for every x : T yields a proof of A.
•
A proof of ∃x : T.A consists of a term s : T and a proof of Ax
s .
The notation Ax
s stands for the proposition obtained from the proposition A by
replacing the variable x with the term s. One speaks of a substitution and says
that s is substituted for x. Equivalence and negation are missing in the above
list since they are deﬁnable with other connectives:
A ↔B := (A →B) ∧(B →A)
¬A := A →⊥.
The symbol ⊥represents the primitive proposition false that has no proof. To
give a proof of ¬A we thus have to give a function that yields for every proof
of A a proof of ⊥. If such a function exists, no proof of A can exist since no
proof of false exists.
In this chapter we will learn how Coq accommodates the logical operations
and the concomitant proof rules. We start with implication and universal quan-
tiﬁcation.
2.2 Implication and Universal Quantiﬁcation
Example: Symmetry of Equality
We begin with the proof of a proposition saying that equality is symmetric.
Goal ∀(X : Type) (x y : X), x=y →y=x.
Proof. intros X x y A. rewrite A. reﬂexivity. Qed.
The command Goal is like the command Lemma but leaves it to Coq to choose
a name for the lemma. The tactic intros takes away the universal quantiﬁcations
and the implication of the claim by representing the respective assumptions as
explicit assumptions of the proof goal.
X : Type
x : X
y : X
A : x = y
y = x
The rest of the proof is straightforward since we have the assumption A : x = y
saying that A is a proof of the equation x = y. The proof A can be used to
rewrite the claim y = x into the trivial equation y = y.
Recall the revert tactic and note that revert can undo the eﬀect of intros.
34
2014-7-16

2.3 Predicates
Exercise 2.2.1 Prove the following goal.
Goal ∀x y, andb x y = true →x = true.
Example: Modus Ponens
Our second example is a proposition stating a basic law for implication known
as modus ponens.
Goal ∀X Y : Prop, X →(X →Y) →Y.
Proof. intros X Y x A. exact (A x). Qed.
The proposition quantiﬁes over all propositions X and Y since Prop is the type
of all propositions. The proof ﬁrst takes away the universal quantiﬁcations and
the outer implications2 leaving us with the goal
X : Prop
Y : Prop
x : X
A : X →Y
Y
Given that we have a proof A of X →Y and a proof x of X, we obtain a proof of
the claim Y by applying the function A to the proof x.3 Coq accommodates this
reasoning with the tactic exact.
Example: Transitivity of Implication
Goal ∀X Y Z : Prop, (X →Y) →(Y →Z) →X →Z.
Proof. intros X Y Z A B x. exact (B (A x)). Qed.
Exercise 2.2.2 Prove that equality is transitive.
2.3 Predicates
Functions that eventually yield a proposition are called predicates. With predi-
cates we can express properties and relations. Here is a theorem involving two
predicates p and q and a nested universal quantiﬁcation.
Goal ∀p q : nat →Prop, p 7 →(∀x, p x →q x) →q 7.
2 Like the arrow for function types the arrow for implication adds missing parentheses to the
right, that is, X →(X →Y) →Y elaborates to X →((X →Y) →Y).
3 Recall from Section 2.1 that proofs of implications are functions.
2014-7-16
35

2 Propositions and Proofs
Proof. intros p q A B. exact (B 7 A). Qed.
Think of p and q as properties of numbers. After the intros we have the goal
p : nat →Prop
q : nat →Prop
A : p 7
B : ∀x, p x →q x
q 7
The proof now exploits the fact that B is a function that yields a proof of q 7
when applied to 7 and a proof of p 7.
2.4 The Apply Tactic
The tactic apply applies proofs of implications in a backward manner.
Goal ∀X Y Z : Prop, (X →Y) →(Y →Z) →X →Z.
Proof. intros X Y Z A B x. apply B. apply A. exact x. Qed.
The tactic apply also works for universally quantiﬁed implications.
Goal ∀p q : nat →Prop, p 7 →(∀x, p x →q x) →q 7.
Proof. intros p q A B. apply B. exact A. Qed.
Step through the proofs with Coq to understand.
Exercise 2.4.1 Prove the following goals.
Goal ∀X Y, (∀Z, (X →Y →Z) →Z) →X.
Goal ∀X Y, (∀Z, (X →Y →Z) →Z) →Y.
Exercise 2.4.2 Prove the following goals, which express essential properties of
booleans, numbers, and lists.
Goal ∀(p : bool →Prop) (x : bool),
p true →p false →p x.
Goal ∀(p : nat →Prop) (x : nat),
p O →(∀n, p n →p (S n)) →p x.
Goal ∀(X : Type) (p : list X →Prop) (xs : list X),
p nil →(∀x xs, p xs →p (cons x xs)) →p xs.
Hint: Use case analysis and induction.
36
2014-7-16

2.5 Leibniz Characterization of Equality
2.5 Leibniz Characterization of Equality
What does it mean that two objects are equal? The mathematician and philoso-
pher Leibniz answered this question in an interesting way: Two objects are equal
if they have the same properties. We know enough to prove in Coq that Leibniz
was right.
Goal ∀(X : Type) (x y : X),
(∀p : X →Prop, p x →p y) →x=y.
Proof. intros X x y A. apply (A (fun z ⇒x=z)). reﬂexivity. Qed.
Run the proof with Coq to understand. After the intros we have the goal
X : Type
x : X
y : X
A : ∀p: X →Prop. px →py
x = y
Applying the proof A to the predicate λz.x=z gives us a proof of the implication
x=x →x=y.4 Backward application of this proof reduces the claim to the trivial
claim x=x, which can be established with reﬂexivity.
Exercise 2.5.1 Prove the following goals.
Goal ∀(X : Type) (x y : X),
x=y →∀p : X →Prop, p x →p y.
Goal ∀(X : Type) (x y : X),
(∀p : X →Prop, p x →p y) →
forall p : X →Prop, p y →p x.
2.6 Propositions are Types
You may have noticed that Coq’s notations for implications and universal quan-
tiﬁcations are the same as the notations for function types. This goes well with
our assumption that the proofs of implications and universal quantiﬁcations are
functions (see Section 2.1). The notational coincidence is profound and reﬂects
the propositions as types principle, which accommodates propositions as types
taking the proofs of the propositions as members. The propositions as types
principle is also known as Curry-Howard correspondence after two of its inven-
tors.
4 λz. x=z is the mathematical notation for the function fun z => x=z, which for z yields the
equation x=z.
2014-7-16
37

2 Propositions and Proofs
There is a special universe Prop that takes exactly the propositions as mem-
bers. Universes are types that take types as members. Prop is a subuniverse of
the universe Type. Consequently, every member of Prop is a member of Type.
A function type s →t is actually a function type ∀x : s. t where the variable x
does not occur in t. Thus an implication s →t is actually a quantiﬁcation ∀x : s. t
saying that for every proof of s there is a proof of t. Note that the reduction
of implications to quantiﬁcations rests on the ability to quantify over proofs.
Constructive type theory has this ability since proofs are ﬁrst-class citizens that
appear as members of types in the universe Prop.
The fact that implications are universal quantiﬁcations explains why the tac-
tics intros and apply are used for both implications and universal quantiﬁcations.
Given a function type ∀x : s. t, we call x a bound variable. What concrete name
is chosen for a bound variable does not matter. Thus the notations ∀X : Type. X
and ∀Y : Type. Y denote the same type.
Moreover, if we have a type ∀x : s. t
where x does not occur in t, we can omit x and just write s →t without losing
information. That the concrete names of bound variables do not matter is a basic
logic principle.
Exercise 2.6.1 Prove the following goals in Coq. Explain what you see.
Goal ∀X : Type,
(fun x : X ⇒x) = (fun y : X ⇒y)
Goal ∀X Y : Prop,
(X →Y) →∀x : X, Y.
Goal ∀X Y : Prop,
(∀x : X, Y) →X →Y.
Goal ∀X Y : Prop,
(X →Y) = (∀x : X, Y).
2.7 Falsity and Negation
Coq comes with a proposition False that by itself has no proof. Given certain
assumptions, a proof of False may however become possible. We speak of in-
consistent assumptions if they make a proof of False possible. There is a basic
logic principle called explosion saying that from a proof of False one can obtain
a proof of every proposition. Coq provides the explosion principle through the
tactic contradiction.
Goal ⊥→2=3.
Proof. intros A. contradiction A. Qed.
38
2014-7-16

2.7 Falsity and Negation
We also refer to the proposition False as falsity. The logical notation for False
is ⊥. With falsity Coq deﬁnes negation as ¬s := s →⊥. So we can prove ¬s by
assuming a proof of s and constructing a proof of ⊥.
Goal ∀X : Prop, X →¬¬ X.
Proof. intros X x A. exact (A x). Qed.
The proof script works since Coq automatically unfolds the deﬁnition of nega-
tion. The double negation ¬¬X unfolds into (X →⊥) →⊥. Here is another
example.
Goal ∀X : Prop,
(X →¬ X) →(¬ X →X) →⊥.
Proof.
intros X A B. apply A.
−apply B. intros x. exact (A x x).
−apply B. intros x. exact (A x x).
Qed.
Sometimes the tactic exfalso is helpful. It replaces the claim with ⊥, which is
justiﬁed by the explosion principle.
Goal ∀X : Prop,
¬¬ X →(X →¬ X) →X.
Proof. intros X A B. exfalso. apply A. intros x. exact (B x x). Qed.
Exercise 2.7.1 Prove the following goals.
Goal ∀X : Prop, ¬¬¬ X →¬ X.
Goal ∀X Y : Prop, (X →Y) →¬ Y →¬ X.
Exercise 2.7.2 Prove the following goals.
Goal ∀X : Prop, ¬¬ (¬¬ X →X).
Goal ∀X Y : Prop, ¬¬ (((X →Y) →X) →X).
Exercise 2.7.3 Prove the following proposition in Coq using only the tactic exact.
Goal ∀X:Prop,
(X →⊥) →(¬ X →⊥) →⊥.
2014-7-16
39

2 Propositions and Proofs
2.8 Conjunction and Disjunction
The tactics for conjunctions are destruct and split.
Goal ∀X Y : Prop, X ∧Y →Y ∧X.
Proof.
intros X Y A. destruct A as [x y]. split.
−exact y.
−exact x.
Qed.
The tactics for disjunctions are destruct, left, and right.
Goal ∀X Y : Prop, X ∨Y →Y ∨X.
Proof.
intros X Y A. destruct A as [x|y].
−right. exact x.
−left. exact y.
Qed.
Run the proof scripts with Coq to understand. Note that we can prove a con-
junction s ∧t if and only if we can prove both s and t, and that we can prove a
disjunction s ∨t if and only if we can prove either s or t.
The intros tactic destructures proofs when given a destructuring pattern. This
leads to shorter proof scripts.
Goal ∀X Y : Prop, X ∧Y →Y ∧X.
Proof.
intros X Y [x y]. split.
−exact y.
−exact x.
Qed.
Goal ∀X Y : Prop, X ∨Y →Y ∨X.
Proof.
intros X Y [x|y].
−right. exact x.
−left. exact y.
Qed.
Nesting of destructuring patterns is possible:
Goal ∀X Y Z : Prop,
X ∨(Y ∧Z) →(X ∨Y) ∧(X ∨Z).
Proof.
intros X Y Z [x|[y z]].
−split; left ; exact x.
40
2014-7-16

2.9 Equivalence and Rewriting
−split; right.
+ exact y.
+ exact z.
Qed.
Note that the bullet + is used to indicate proofs of subgoals of the last main
subgoal.
One can use three levels of bullets, −for top level subgoals, + for
second level subgoals, and ∗for third level subgoals. One can also separate part
of a proof using curly braces {· · · } inside which one can restart using the bullets
−, +, and ∗. In this way Coq supports an arbitrary number of subgoal levels.
Exercise 2.8.1 Prove the following goals.
Goal ∀X : Prop,
¬ (X ∨¬ X) →X ∨¬ X.
Goal ∀X : Prop,
(X ∨¬ X →¬ (X ∨¬ X)) →X ∨¬ X.
Goal ∀X Y Z W : Prop,
(X →Y) ∨(X →Z) →(Y →W) ∧(Z →W) →X →W.
Exercise 2.8.2 Prove the following goals.
Goal ∀X : Prop, ¬¬ (X ∨¬ X).
Goal ∀X Y : Prop, ¬¬ ((X →Y) →¬ X ∨Y).
2.9 Equivalence and Rewriting
Coq deﬁnes equivalence as s ↔t := (s →t) ∧(t →s). Thus an equivalence s ↔t
is provable if and only if the implications s →t and t →s are both provable. Coq
automatically unfolds equivalences.
Lemma and_com : ∀X Y : Prop, X ∧Y ↔Y ∧X.
Proof.
intros X Y. split.
−intros [x y]. split.
+ exact y.
+ exact x.
−intros [y x]. split.
+ exact x.
+ exact y.
Qed.
Lemma deMorgan : ∀X Y : Prop, ¬ (X ∨Y) ↔¬ X ∧¬ Y.
2014-7-16
41

2 Propositions and Proofs
Proof.
intros X Y. split.
−intros A. split.
+ intros x. apply A. left. exact x.
+ intros y. apply A. right. exact y.
−intros [A B] [x|y].
+ exact (A x).
+ exact (B y).
Qed.
One can use the tactic apply with equivalences. Since an equivalence is a con-
junction of implications, the apply tactic will choose one of the two implications
to use. The user can choose which of the two implications to use by using the
tactic apply with one of the arrows →and ←(similar to the tactic rewrite).
One can often reason with equivalences in the same ways as with equations.
Part of the justiﬁcation for this is the fact that logical equivalence is an equiva-
lence relation (i.e., it is reﬂexive, symmetric and transitive). A number of lemmas
can justify rewriting with equivalences in many (but not all) contexts. For exam-
ple, the following result allows us rewrite with equivalences below conjunctions.
Goal ∀X Y Z W : Prop, (X ↔Y) →(Z ↔W) →(X ∧Z ↔Y ∧W).
We leave the proof of this goal as an exercise.
In contexts where rewriting with equivalences is allowed, we may use the
tactic setoid_rewrite.5
Goal ∀X Y Z : Prop, ¬ (X ∨Y) ∧Z ↔Z ∧¬ X ∧¬ Y.
Proof.
intros X Y Z.
setoid_rewrite deMorgan.
apply and_com.
Qed.
Goal ∀X : Type, ∀p q : X →Prop, (∀x, ¬ (p x ∨q x)) →∀x, ¬ p x ∧¬ q x.
Proof.
intros X p q A.
setoid_rewrite ←deMorgan.
exact A.
Qed.
One can also use the tactics reﬂexivity, symmetry and transitivity to reason
about equivalences.
Goal ∀X : Prop, X ↔X.
Proof. reﬂexivity. Qed.
5 Recall that the tactic setoid_rewrite is provided by the standard library module Omega.
42
2014-7-16

2.9 Equivalence and Rewriting
Goal ∀X Y : Prop, (X ↔Y) →(Y ↔X).
Proof. intros X Y A. symmetry. exact A. Qed.
Goal ∀X Y Z : Prop, (X ↔Y) →(Y ↔Z) →(X ↔Z).
Proof.
intros X Y Z A B. transitivity Y.
−exact A.
−exact B.
Qed.
Proof scripts done using the tactics setoid_rewrite, reﬂexivity, symmetry, and
transitivity to reason with equivalences can always be replaced by proof scripts
that do not use these tactics. Some of the exercises below should give the reader
an idea how such a replacement could be accomplished.
Exercise 2.9.1 Prove equivalence is an equivalence relation without using the
tactics setoid_rewrite, reﬂexivity, symmetry and transitivity.
Goal ∀X : Prop, X ↔X.
Goal ∀X Y : Prop, (X ↔Y) →(Y ↔X).
Goal ∀X Y Z : Prop, (X ↔Y) →(Y ↔Z) →(X ↔Z).
Exercise 2.9.2 Prove the following facts which justify rewriting with equiva-
lences in certain contexts.
Do not use the tactics setoid_rewrite, reﬂexivity,
symmetry and transitivity.
Goal ∀(X Y Z W : Prop), (X ↔Y) →(Z ↔W) →(X ∧Z ↔Y ∧W).
Goal ∀(X:Type) (p q:X →Prop), (∀x:X, p x ↔q x) →((∀x:X, p x) ↔∀x:X, q x).
Exercise 2.9.3 Prove
the
following
facts
using
setoid_rewrite,
reﬂexivity,
symmetry and transitivity. You may use the lemmas deMorgan and and_com.
Goal ∀X Y Z : Prop, X ∧¬ (Y ∨Z) ↔(¬ Y ∧¬ Z) ∧X.
Goal ∀X : Type, ∀p q : X →Prop, (∀x, ¬ (p x ∨q x)) ↔∀x, ¬ p x ∧¬ q x.
Exercise 2.9.4 Prove the following goals.
Goal ∀X Y : Prop, X ∧(X ∨Y) ↔X.
Goal ∀X Y : Prop, X ∨(X ∧Y) ↔X.
Goal ∀X:Prop, (X →¬ X) →X ↔¬¬ X.
Exercise 2.9.5 (Impredicative Characterizations) It turns out that falsity, nega-
tions, conjunctions, disjunctions, and even equations are all equivalent to propo-
sitions obtained with just implication and universal quantiﬁcation. Prove the fol-
lowing goals to get familiar with this so-called impredicative characterizations.
2014-7-16
43

2 Propositions and Proofs
Goal ⊥↔∀Z : Prop, Z.
Goal ∀X : Prop,
¬ X ↔∀Z : Prop, X →Z.
Goal ∀X Y : Prop, X ∧Y ↔∀Z : Prop, (X →Y →Z) →Z.
Goal ∀X Y : Prop, X ∨Y ↔∀Z : Prop, (X →Z) →(Y →Z) →Z.
Goal ∀(X : Type) (x y : X), x=y ↔∀p : X →Prop, p x →p y.
2.10 Automation Tactics
Coq provides various automation tactics that help in the construction of proofs.
In a proof script, an automation tactic can always be replaced by a sequence of
basic tactics.
A simple automation tactic is assumption. This tactic solves goals whose claim
appears as an assumption.
Goal ∀X Y : Prop, X ∧Y →Y ∧X.
Proof. intros X Y [x y]. split ; assumption. Qed.
The automation tactic auto is more powerful. It uses the tactics intros, apply,
assumption, reﬂexivity and a few others to construct a proof. We may use auto
to ﬁnish up proofs once the goal has become obvious.
Goal ∀(X : Type) (p : list X →Prop) (xs : list X),
p nil →(∀x xs, p xs →p (cons x xs)) →p xs.
Proof. induction xs ; auto. Qed.
The automation tactic tauto solves every goal that can be solved with the
tactics intros and reﬂexivity, the basic tactics for falsity, implication, conjunction,
and disjunction, and the deﬁnitions of negation and equivalence.
Goal ∀X : Prop, ¬ (X ↔¬ X).
Proof. τto. Qed.
2.11 Existential Quantiﬁcation
The tactics for existential quantiﬁcations are destruct and exists.6
Goal ∀(X : Type) (p q : X →Prop),
(∃x, p x ∧q x) →∃x, p x.
6 The existential quantiﬁer ∃can be written as the keyword exists in Coq code. When we display
Coq code, we always replace the string exists with the symbol ∃. For this reason the tactic exists
appears as the symbol ∃in Coq code.
44
2014-7-16

2.11 Existential Quantiﬁcation
Proof.
intros X p q A. destruct A as [x B]. destruct B as [C _].
∃x. exact C.
Qed.
Run the proof scripts with Coq to understand.
The diagonal law is a simple fact about nonexistence that has amazing con-
sequences. One such consequence is the undecidability of the halting problem.
We state the diagonal law as follows:
Deﬁnition diagonal : Prop := ∀(X : Type) (p : X →X →Prop),
¬ ∃x, ∀y, p x y ↔¬ p y y.
If X is the type of all Turing machines and pxy says that x halts on the string
representation of y, the diagonal law says that there is no Turing machine x
such that x halts on a Turing machine y if and only if y does not halt on its
string representation.
The proof of the diagonal law is not diﬃcult.
Lemma circuit (X : Prop) : ¬ (X ↔¬ X).
Proof. τto. Qed.
Goal diagonal.
Proof. intros X p [x A]. apply (@circuit (p x x)). exact (A x). Qed.
We can prove the diagonal law without a lemma if we use the tactic specialize.
Goal diagonal.
Proof. intros X p [x A]. specialize (A x). τto. Qed.
A disequation s≠t is a negated equation ¬(s=t). We prove the correctness of
a characterization of disequality that employs existential quantiﬁcation.
Goal ∀(X : Type) (x y : X),
x ≠y ↔∃p : X →Prop, p x ∧¬ p y.
Proof.
split.
−intros A. ∃(fun z ⇒x = z). auto.
−intros [p [A B]] C. apply B. rewrite ←C. apply A.
Qed.
Note that split tacitly introduces X, x, and y.
Exercise 2.11.1 Prove the De Morgan law for existential quantiﬁcation.
Goal ∀(X : Type) (p : X →Prop),
¬ (∃x, p x) ↔∀x, ¬ p x.
Exercise 2.11.2 Prove the exchange rule for existential quantiﬁcations.
2014-7-16
45

2 Propositions and Proofs
Goal ∀(X Y : Type) (p : X →Y →Prop),
(∃x, ∃y, p x y) ↔∃y, ∃x, p x y.
Exercise 2.11.3 (Impredicative Characterization) Prove the following goal.
It
shows that existential quantiﬁcation can be expressed with implication and uni-
versal quantiﬁcation.
Goal ∀(X : Type) (p : X →Prop),
(∃x, p x) ↔∀Z : Prop, (∀x, p x →Z) →Z.
Exercise 2.11.4 Below are characterizations of equality and disequality based on
reﬂexive relations. Prove the correctness of the characterizations.
Goal ∀(X : Type) (x y : X),
x = y ↔∀r : X →X →Prop, (∀z : X, r z z) →r x y.
Goal ∀(X : Type) (x y : X),
x ≠y ↔∃r : X →X →Prop, (∀z : X, r z z) ∧¬ r x y.
Hint for ﬁrst goal: Use the tactic specialize and simplify the resulting assumption
with simpl in A where A is the name of the assumption.
Exercise 2.11.5 Prove the following goal.
Goal ∀(X: Type) (x : X) (p : X →Prop), ∃q : X →Prop,
q x ∧(∀y, p y →q y) ∧∀y, q y →p y ∨x = y.
Exercise 2.11.6
a) Prove the following goal.
Goal ∀(X : Type) (Y : Prop) ,
X →Y ↔(∃x : X, ⊤) →Y.
b) Explain why s →t is a proposition if s is a type and t is a proposition.
2.12 Basic Proof Rules
By now we have conducted many proofs in Coq. In this chapter we mostly proved
general properties of the logical connectives and quantiﬁers. The proofs were
constructed with a small set of tactics, where every tactic performs a basic proof
step. The proof steps performed by the tactics can be described by the proof
rules appearing in Figure 2.1. We may say that the rules describe basic logic
principles and that the tactics implement these principles.
Each proof rule says that a proof of the conclusion (the proposition appearing
below the line) can be obtained from proofs of the premises (the items appearing
46
2014-7-16

2.12 Basic Proof Rules
s ⇒t
s →t
s →t
s
t
x : s ⇒t
∀x : s. t
∀x : s. t
u : s
t x
u
⊥
u
s
t
s ∧t
s ∧t
s, t ⇒u
u
s
s ∨t
t
s ∨t
s ∨t
s ⇒u
t ⇒u
u
u : s
t x
u
∃x : s. t
∃x : s. t
x : s , t ⇒u
u
Figure 2.1: Basic proof rules
above the line). The notation s ⇒t used in some premises says that there is a
proof of t under the assumption that there is a proof of s. The notation u : s
says that the term u has type s, and the notation s x
t stands for the proposition
obtained from s by replacing x with t.
We explain one of the proof rules for disjunctions in detail.
s ∨t
s ⇒u
t ⇒u
u
The rule says that we can obtain a proof of a proposition u if we are given a
proof of a disjunction s ∨t, a proof of u assuming a proof of s, and a proof of u
assuming a proof of t. The rule is justiﬁed since a proof of the disjunction s ∨t
gives us a proof of either s or t. Speaking more generally, the rule tells us that
we can do a case analysis if we have a proof of a disjunction. Coq implements
the rule in a backward fashion with the tactic destruct.
A : s ∨t
u
destruct A as [B|C]
B : s
u
C : t
u
Each row in Figure 2.1 describes the rules for one particular family of propo-
sitions. The rules on the left are called introduction rules, and the rules on the
2014-7-16
47

2 Propositions and Proofs
right are called elimination rules. The introduction rule for a logical operation O
tells us how we can directly prove propositions obtained with O, and the elim-
ination rule tells us how we can make use of a proof of a proposition obtained
with O. For most families of propositions there is exactly one introduction and
exactly one elimination rule. The exceptions are falsity (no introduction rule) and
disjunctions (two introduction rules). Coq realizes the rules in Figure 2.1 with
the following tactics.
introduction
elimination
→
intros
apply, exact
∀
intros
apply, exact
⊥
contradiction, exfalso
∧
split
destruct
∨
left, right
destruct
∃
exists
destruct
There are no proof rules for negation and equivalence since these logical con-
nectives are deﬁned on top of the basic logical connectives.
¬s := s →⊥
s ↔t := (s →t) ∧(t →s)
The proof rules in Figure 2.1 were ﬁrst formulated and studied by Gerhard
Gentzen in 1935. They are known as intuitionistic natural deduction rules.
Exercise 2.12.1 Above we describe the elimination rule for disjunction in detail
and relate it to a Coq tactic. Make sure that you can discuss each rule in Figure 2.1
in this fashion.
2.13 Proof Rules as Lemmas
Coq can express proof rules as lemmas. Here are the lemmas for the introduction
and the elimination rule for conjunctions.
Lemma AndI (X Y : Prop) :
X →Y →X ∧Y.
Proof. τto. Qed.
Lemma AndE (X Y U : Prop) :
X ∧Y →(X →Y →U) →U.
Proof. τto. Qed.
To apply the proof rules, we can now apply the lemmas.
Goal ∀X Y : Prop, X ∧Y →Y ∧X.
48
2014-7-16

2.14 Inductive Propositions
Proof.
intros X Y A. apply (AndE A).
intros x y. apply AndI.
−exact y.
−exact x.
Qed.
If you look at the applications of the lemmas in the proof above, it becomes
clear that in Coq the name of a lemma is actually the name of the proof of the
lemma. Since the statement of a lemma is typically universally quantiﬁed, the
proof of a lemma is typically a proof generating function. Thus lemmas can be
applied as you see it in the above proof scripts. When we represent a proof rule
as a lemma, the proposition of the lemma formulates the rule as we see it, and
the proof of the lemma is a function constructing a proof of the conclusion of
the rule from the proofs required by the premises of the rule.
Next we represent the proof rules for existential quantiﬁcations as lemmas.
Given a proposition ∃x : s.t, we face a bound variable x that may occur in the
term t. To preserve the binding, we represent the proposition t as the predicate
λx : s.t.
Lemma ExI (X : Type) (p : X →Prop) :
forall x : X, p x →∃x, p x.
Proof. intros x A. ∃x. exact A. Qed.
Lemma ExE (X : Type) (p : X →Prop) (U : Prop) :
(∃x, p x) →(∀x, p x →U) →U.
Proof. intros [x A] B. exact (B x A). Qed.
We can now prove propositions involving existential quantiﬁcations without us-
ing the tactics exists and destruct.
Goal ∀(X : Type) (p q : X →Prop),
(∃x, p x ∧q x) →∃x, p x.
Proof.
intros X p q A. apply (ExE A).
intros x B. apply (AndE B). intros C _.
exact (ExI C).
Qed.
Exercise 2.13.1 Formulate the introduction and elimination rules for disjunc-
tions as lemmas and use the lemmas to prove the commutativity of disjunction.
2.14 Inductive Propositions
Recall that Coq provides for the deﬁnition of inductive types. So far we have used
this facility to populate the universe Type with types providing booleans, natural
2014-7-16
49

2 Propositions and Proofs
numbers, lists, and a few other families of values. It is also possible to populate
the universe Prop with inductive types. We will speak of inductive propositions
following the convention that types in Prop are called propositions. Here are the
deﬁnitions of two inductive propositions from Coq’s standard library.7
Inductive ⊤: Prop :=
| I : ⊤.
Inductive ⊥: Prop := .
Recall that the proofs of a proposition A are the members of the type A. Thus
the proposition True has exactly one proof (i.e., the proof constructor I), and the
proposition False has no proof (since we deﬁned False with no proof constructor).
By case analysis over the constructors of True we can prove that True has
exactly one proof.
Goal ∀x y : ⊤, x=y.
Proof. intros x y. destruct x. destruct y. reﬂexivity. Qed.
By case analysis over the constructors of False we can prove that from a proof of
False we can obtain a proof of every proposition.
Goal ∀X : Prop, ⊥→X.
Proof. intros X A. destruct A. Qed.
The case analysis over the proofs of False immediately succeeds since False has
no constructor. We have discussed this form of reasoning in Section 1.13 where
we considered the type void.
Coq deﬁnes conjunction and disjunction as inductive predicates (i.e., induc-
tive type constructors into Prop).8
Inductive and (X Y : Prop) : Prop :=
| conj : X →Y →and X Y.
Inductive or (X Y : Prop) : Prop :=
| or_introl : X →or X Y
| or_intror : Y →or X Y.
Note that the inductive deﬁnitions of conjunction and disjunction follow exactly
the BHK interpretation: A proof of X ∧Y consists of a proof of X and a proof of
Y, and a proof of X ∨Y consists of either a proof of X or a proof of Y. Also note
that the deﬁnition of conjunction mirrors the deﬁnition of the product operator
prod in Section 1.9.
Coq deﬁnes existential quantiﬁcation as an inductive predicate that takes a
type and a predicate as arguments:
7 Use the command Print to look up the deﬁnitions
8 Use the commands Set Printing All and Print to ﬁnd out the deﬁnitions of the inﬁx notations
“∧” and “∨”.
50
2014-7-16

2.15 An Observation
Inductive ex (X : Type) (p : X →Prop) : Prop :=
| ex_intro : ∀x : X, p x →ex p.
With this deﬁnition an existential quantiﬁcation ∃x : s.t is represented as the
application ex (λx : s.t). This way the binding of the local variable x is delegated
to the predicate λx : s.t. We have used this technique before to formulate the
introduction and elimination rules for existential quantiﬁcations as lemmas (see
Section 2.13).
Negation and equivalence are deﬁned with plain deﬁnitions in Coq’s standard
library:
Deﬁnition not (X : Prop) : Prop := X →⊥.
Deﬁnition iﬀ(X Y : Prop) : Prop := (X →Y) ∧(Y →X).
Exercise 2.14.1 Prove the commutativity of disjunction without using the tactics
left and right.
Exercise 2.14.2 Deﬁne your own versions of the logical operations and prove
that they agree with Coq’s predeﬁned operations. Choose names diﬀerent from
Coq’s predeﬁned names to avoid conﬂicts.
Exercise 2.14.3 One can characterize negation with the following introduction
and elimination rules not using falsity.
x : Prop, s ⇒x
¬s
¬s
s
u
The introduction rule requires a proof of an arbitrary proposition x under the
assumption that a proof of s is given.
a) Formulate the rules as lemmas and prove the lemmas.
b) Give an inductive deﬁnition of negation based on the introduction rule.
c) Prove the elimination lemma for your inductive deﬁnition of negation.
2.15 An Observation
Look at the introduction rules for conjunction, disjunction, and existential quan-
tiﬁcation. If we formulate these rules as lemmas, we get exactly the types of the
proof constructors of the inductive deﬁnitions of the respective logical opera-
tions.
Given the inductive deﬁnition of a logical operation, we can prove the elim-
ination lemma for the operation.
Since the inductive deﬁnition is only based
2014-7-16
51

2 Propositions and Proofs
on the introduction rule of the operation, we can see the elimination rule as a
consequence of the introduction rule.
We can also go from the elimination rules to the introduction rules. Look at
the impredicative characterization of the logical operations in terms of implica-
tion and universal quantiﬁcation appearing in Exercises 2.9.5 and 2.11.3. These
characterizations reformulate the elimination rules of the logical operations. If
we deﬁne a logical operation based on its impredicative characterization, we can
prove the corresponding introduction and elimination lemmas. For conjunction
we get the following development.
Deﬁnition AND (X Y : Prop) : Prop :=
forall Z : Prop, (X →Y →Z) →Z.
Lemma ANDI (X Y : Prop) :
X →Y →AND X Y.
Proof. intros x y Z. auto. Qed.
Lemma ANDE (X Y Z: Prop) :
AND X Y →(X →Y →Z) →Z.
Proof. intros A. exact (A Z). Qed.
Lemma AND_agree (X Y : Prop) :
AND X Y ↔X ∧Y.
Proof.
split.
−intros A. apply A. auto.
−intros [x y] Z A. apply A ; assumption.
Qed.
Exercise 2.15.1 Deﬁne disjunction with a plain deﬁnition based on the impred-
icative characterization in Exercise 2.9.5. Prove an introduction, an elimination,
and an agreement lemma for your disjunction. Carry out the same program for
the existential quantiﬁer.
2.16 Excluded Middle
In Mathematics, one assumes that every proposition is either false or true. Con-
sequently, if X is a proposition, the proposition X ∨¬X must be true.
The
assumption that X ∨¬X is true for every proposition X is known as principle of
excluded middle, XM for short. Here is a deﬁnition of XM in Coq.
Deﬁnition XM : Prop := ∀X : Prop, X ∨¬ X.
52
2014-7-16

2.16 Excluded Middle
Coq can neither prove XM nor ¬XM. This means that we can consistently
assume XM in Coq. The philosophy here is that XM is a basic mathematical as-
sumption but not a basic proof rule. By not building in XM, we can make explicit
which proofs rely on XM. Logical systems that build in XM are called classical,
and systems not building in XM are called constructive or intuitionistic.
Exercise 2.16.1 Prove the following goals. They state consequences of the De
Morgan laws for conjunction and universal quantiﬁcation whose proofs require
the use of excluded middle.
Goal ∀X Y : Prop,
XM →¬ (X ∧Y) →¬ X ∨¬ Y.
Goal ∀(X : Type) (p : X →Prop),
XM →¬ (∀x, p x) →∃x, ¬ p x.
Exercise 2.16.2 Prove that the following propositions are equivalent. There are
short proofs if you use tauto.
Deﬁnition XM : Prop := ∀X : Prop, X ∨¬ X.
(* excluded middle *)
Deﬁnition DN : Prop := ∀X : Prop, ¬¬ X →X.
(* double negation *)
Deﬁnition CP : Prop := ∀X Y : Prop, (¬ Y →¬ X) →X →Y.
(* contraposition *)
Deﬁnition Peirce : Prop := ∀X Y : Prop, ((X →Y) →X) →X.
(* Peirce’s Law *)
Exercise 2.16.3 (Drinker’s Paradox) Consider a bar populated by at least one
person. Using excluded middle, one can prove that one can pick some person
in the bar such that everyone in the bar drinks Whiskey if this person drinks
Whiskey. Do the proof in Coq.
Lemma drinker (X : Type) (d : X →Prop) :
XM →(∃x : X, ⊤) →∃x, d x →∀x, d x.
Exercise 2.16.4 (Glivenko’s Theorem) A proposition is pure if it is either a vari-
able, falsity, or an implication, negation, conjunction, or disjunction of pure
propositions. Valery Glivenko showed in 1929 that a pure proposition is prov-
able classically if and only if its double negation is provable intuitionistically.
That is, if s is a pure proposition, then XM →s is provable in Coq if and only if
¬¬s is provable in Coq. This tells us that tauto can prove the following goals.
Goal ∀X : Prop,
¬¬ (X ∨¬ X).
Goal ∀X Y : Prop,
¬¬ (((X →Y) →X) →X).
Goal ∀X Y : Prop,
¬¬ (¬ (X ∧Y) ↔¬ X ∨¬ Y).
2014-7-16
53

2 Propositions and Proofs
Goal ∀X Y : Prop,
¬¬ ((X →Y) ↔(¬ Y →¬ X)).
Do the proofs without using tauto and try to ﬁnd out why the outer double
negation can replace excluded middle.
Exercise 2.16.5 A proposition s is propositionally decidable if the proposition
s ∨¬s is provable. Prove that the following propositions are propositionally de-
cidable.
a) ∀X : Prop, ¬ (X ∨¬ X)
b) ∃X : Prop, ¬ (X ∨¬ X)
c) ∀P : Prop, ∃f : Prop →Prop, ∀X Y : Prop,
(X ∧P →Y) ↔(X →f Y)
d) ∀P : Prop, ∃f : Prop →Prop, ∀X Y : Prop,
(X →Y ∧P) ↔(f X →Y)
2.17 Discussion and Remarks
Our treatment of propositions and proofs is based on the constructive approach,
which sees proofs as ﬁrst-class objects and deﬁnes the meaning of propositions
by relating them to their proofs. In contrast to the classical approach, no notion
of truth value is needed.
Our starting point is the BHK interpretation, which
identiﬁes the proofs of implications and quantiﬁcations as functions. The BHK
interpretation is reﬁned by the propositions as types principle, which models
implications and universal quantiﬁcation as function types such that the proofs
of a proposition appear as the members of the type representing the proposi-
tion. As it turns out, universal quantiﬁcation alone suﬃces to express all logical
operations (impredicative characterizations).
The ideas of the constructive approach developed around 1930 and led to the
BHK interpretation (Brouwer, Heyting, Kolmogorov). A complementary achieve-
ment is the system of natural deduction (i.e., basic proof rules) formulated in
1935 by Gerhard Gentzen. While the BHK interpretation starts with proofs as
ﬁrst-class objects, Gentzen’s approach takes the proof rules as starting point
and sees proofs as derivations obtained with the rules. Given the BHK interpre-
tation, the correctness of the proof rules can be argued. Given the proof rules,
the correctness of the BHK interpretation can be argued.
A formal model providing functions as assumed by the BHK interpretation
was developed in the 1930’s by Alonzo Church under the name lambda calculus.
The notion of types was ﬁrst formulated by Bertrand Russell around 1900. A
typed lambda calculus was published by Alonzo Church in 1940. Typed lambda
54
2014-7-16

2.18 Tactics Summary
calculus later developed into constructive type theory, which became the foun-
dation for Coq.
The correspondence between propositions and types was recognized by Curry
and Howard for pure propositional logic and ﬁrst reported about in a paper from
1969. The challenge then was to formulate a type theory strong enough to model
quantiﬁcations as propositions. For such a type theory dependent function types
are needed.
Dependently typed type theories were developed by Nicolaas de
Bruijn, Per Martin-Löf, and Jean-Yves Girard around 1970.
Coq’s type theory
originated in 1985 (Coquand and Huet) and has been reﬁned repeatedly.
2.18 Tactics Summary
intros x1 . . . xn
introduces implications and universal quantiﬁcations
apply t
reduces claim by backward application of proof function t
exact t
Solves goal with proof t
contradiction t
Soves goal by explosion if t is proof of ⊥
exfalso
Changes claim to ⊥(explosion)
split
splits conjunctive claim
left
reduces disjunctive claim to left constituent
right
reduces disjunctive claim to right constituent
exists t
instantiates existential claim with witness t
specialize (x t)
instantiates assumption x with t
assumption
solves goals whose claim appears as assumption
auto
tries to solve goal with intros, apply, assumption, reﬂexivity, . . .
τto
solves goals solvable by pure propositional reasoning
2014-7-16
55

2 Propositions and Proofs
56
2014-7-16

3 Deﬁnitional Equality and
Propositional Equality
In this chapter we study equality in Coq. Equality in Coq rests on conversion,
an equivalence relation on terms coming with the type theory underlying Coq.
There is the basic assumption that convertible terms represent the same object.
Moreover, evaluation steps respect conversion in that they rewrite terms to con-
vertible terms.
We will see many basic proofs involving equality. For instance, we will prove
that the number 1 is diﬀerent from 2, and that constructors like S or cons are
injective. We will also prove that the type nat is diﬀerent from the type bool. We
will study these proofs at the level of the underlying type theory.
3.1 Conversion Principle
The type theory underlying Coq comes with an equivalence relation on terms
called convertibility. The type theory assumes that convertible terms have the
same meaning. This assumption is expressed in the conversion principle, which
says that convertible types have the same elements. Applied to propositions,
the conversion principle says that a proof s of a proposition t is also a proof of
every proposition t′ that is convertible with t. Thus if we search for a proof of
a proposition t, we can switch to a convertible proposition t′ and search for a
proof of t′.
The convertibility relation is deﬁned as the least equivalence relation on terms
that is compatible with the term structure and certain conversion rules. Conver-
sion rules can be applied in both directions (i.e., from left to right and from right
to left). For the terms introduced so far we have the following conversion rules.
•
Alpha conversion.
Consistent renaming of local variables.
For instance,
λx : s.x and λy : s.y are alpha convertible.
•
Beta conversion.
The terms (λx : s.t)u and t x
u are beta convertible.
Beta
conversion is the undirected version of beta reduction. The direction from t x
u
to (λx : s.t)u is called beta expansion.
Terms of the form (λx : s.t)u are
called beta redexes.
57

3 Deﬁnitional Equality and Propositional Equality
•
Eta conversion. The terms λx : s.tx and t are eta convertible if x does not
occur in t and both terms have the same type. The direction from λx : s.tx
to t is called eta reduction, and the reverse direction is called eta expansion.
Eta reduction eliminates unnecessary lambda abstractions.
•
Delta conversion. A deﬁned name x and the term t it is bound to are convert-
ible. The direction from the name to the term is called unfolding, the other
direction is called folding.1
•
Match conversion. The undirected version of match reduction.
•
Fix conversion. The undirected version of ﬁx reduction.
Since the computation rules are directed versions of the conversion rules for
lambda abstractions (beta), matches, ﬁxes, and deﬁned names (delta), every eval-
uation step is a conversion step. Thus a term is always convertible to its normal
form.
Coq comes with various conversion tactics making it possible to convert the
claim and the assumptions of proof goals. Such conversions are logically jus-
tiﬁed by the conversion principle.
We will see the conversion tactics change,
pattern, hnf , cbv, simpl, unfold, and fold. The following examples do not prove
interesting lemmas but illustrate the conversion rules and the conversion tactics.
Goal ¬¬⊤.
Proof.
¬¬True
change (¬⊤→⊥).
¬True →False
change (¬(⊤→⊥)).
¬(True →False)
change (¬¬⊤).
¬¬True
hnf.
¬True →False
change (¬¬⊤).
¬¬True
cbv.
(True →False) →False
change (¬¬⊤).
¬¬True
simpl.
¬¬True
pattern ⊤.
(λp : Prop.¬¬p) True
pattern not at 2.
(λf : Prop →Prop.(λp : Prop.¬f p) True) not
hnf.
¬True →False
exact (fun f ⇒f I).
Show Proof.
Qed.
The tactic change t changes the current claim to t provided the current claim
and t are convertible. The tactic change gives us a means to check with Coq
whether two terms are convertible. The tactic hnf (head normal form) applies
computation rules to the top of a term until the top of the term cannot be re-
duced further. The tactic cbv (call by value) fully evaluates a term (similar to the
1 The names of lemmas established with Qed cannot be unfolded.
58
2014-7-16

3.1 Conversion Principle
command Compute). The tactic pattern t abstracts out a subterm t of a claim by
converting the claim to a beta redex (λx : s.u)t that reduces to the claim by a
beta reduction step. Note that pattern performs a beta expansion. The second
use of pattern in the above script abstracts out only the second occurrence of
the subterm not.
Note that all terms shown at the right of the above proof are convertible
propositions. By the conversion principle we know that all of these propositions
have the same proofs.
The above script also contains an occurrence of the tactic simpl so that we
can compare it with the tactics hnf and cbv. Note that the occurrence of simpl
has no eﬀect in the above script. In fact, simpl will change a term only if the
conversion involves a match reduction. If you study the examples in Chapter 1,
you will learn that simpl applies computation rules but also performs folding
steps for recursive deﬁnitions (backward application of deﬁnition unfolding).
Note the command Show Proof at the end of the script. It shows the proof
term the script will have constructed at this point. The conversion tactics do
not show in the proof term, except for the fact that the missing types in the
description of the proof term appearing as argument of exact will be derived
based on the goal visible at this point.
All conversion tactics can be applied to assumptions. For instance, the com-
mand “simpl in A” will simplify the assumption A.
For the following conversion examples we deﬁne an inductive predicate demo.
Inductive demo (X : Type) (x : X) : Prop :=
| demoI : demo x.
First we demo delta conversion with the tactics unfold and fold.
Goal demo plus.
Proof.
demo plus
unfold plus.
demo (ﬁx plus (x y : nat) : nat := match x with · · · end)
unfold plus.
demo (ﬁx plus (x y : nat) : nat := match x with · · · end)
fold plus.
demo plus
apply demoI.
Qed.
Note that the second occurrence of the unfold tactic has no eﬀect since the claim
does not contain a deﬁned name plus.
Next we demo alpha conversion.
Goal demo (fun x : nat ⇒x).
Proof.
change (demo (fun y : nat ⇒y)).
change (demo (fun myname : nat ⇒myname)).
2014-7-16
59

3 Deﬁnitional Equality and Propositional Equality
apply demoI.
Qed.
For the remaining demos we use Coq’s section facility to conveniently declare
variables.2
Section Demo.
Variable n : nat.
Here is a conversion demo involving match and ﬁx conversions.
Goal demo (5+n+n).
Proof.
demo (5 + n + n)
change (demo (2+3+n+n)).
demo (2 + 3 + n + n)
simpl.
demo (S (S (S (S (S (n + n))))))
change (demo (10+n−5+n)).
demo (10 + n −5 + n)
pattern n at 1.
(λx : nat. demo (10 + x −5 + n)) n
hnf.
demo (10 + n −5 + n)
simpl.
demo (S (S (S (S (S (n + n))))))
apply demoI.
Qed.
Finally, we demonstrate eta conversion.
Variable X : Type.
Variable f : X →X →X.
Goal demo f.
Proof.
demo f
change (demo (fun x ⇒f x)).
demo (λx : X. f x)
cbv.
demo (λx : X. f x)
change (demo (fun x y ⇒f x y)).
demo (λx : X. λy : X. f x y)
cbv.
demo (λx : X. λy : X. f x y)
apply demoI.
Qed.
End Demo.
You may wonder why Coq does not employ eta reduction as computation rule.
The reason is that naive eta reduction is not always type preserving. For instance,
the term
λx : Prop. (λy : Type. y) x
has type Prop →Type. The application of the inner lambda abstraction to x type
checks since every proposition is a type. A naive eta reduction would yield the
term λy : Type. y, which has type Type →Type. This violates type preservation
since the types Prop →Type and Type →Type are incomparable in Coq.
2 This is the ﬁrst time we use Coq’s section facility.
60
2014-7-16

3.2 Disjointness and Injectivity of Constructors
Exercise 3.1.1 The tactic reﬂexivity can prove an equation s = t if and only if
the terms s and t are convertible. Argue for each of the following goals whether
or not it can be shown by reﬂexivity and check your answer with Coq.
(a) Goal plus 1 = S.
(b) Goal (fun y ⇒3+y) = plus (4−1).
(c) Goal S = fun x ⇒x + 1.
(d) Goal S = fun x ⇒1 + x.
(e) Goal S = fun x ⇒2+x+1−2.
(f) Goal plus 3 = fun x ⇒5+x−2.
(g) Goal mult 2 = fun x ⇒x + (x + 0).
(h) Goal S = fun x ⇒S (pred (S x)).
(i) Goal minus = fun x y ⇒x−y.
3.2 Disjointness and Injectivity of Constructors
Diﬀerent constructors of an inductive type always yield diﬀerent values. We start
by proving that the constructors true and false of bool are diﬀerent.
Goal false ≠true.
Proof.
intros A.
change (if false then ⊤else ⊥).
rewrite A.
exact I.
Qed.
The proof follows a simple path. We ﬁrst introduce the equation false = true.
Then we convert the resulting claim into a conditional with the condition false.
Using the assumed equation false = true, we rewrite the condition of the con-
ditional to true. By conversion we obtain the claim True and ﬁnish the proof.
What makes the proof go through is the conversion rule for matches and the
conversion principle.
The idea of the proof of false ≠true carries over to nat. We prove that the
constructors O and S yield diﬀerent values.
Lemma disjoint_O_S n :
0 ≠S n.
Proof.
intros A.
change (match 0 with 0 ⇒⊥| _ ⇒⊤end).
rewrite A.
exact I.
Qed.
2014-7-16
61

3 Deﬁnitional Equality and Propositional Equality
With a similar idea we can prove that the constructor S is injective.
Lemma injective_S x y :
S x = S y →x = y.
Proof.
intros A.
change (pred (S x) = pred (S y)).
rewrite A.
reﬂexivity .
Qed.
Coq’s tactics discriminate, injection, and congruence can do this sort of proofs
automatically (that is, construct suitable proof terms).
Goal ∀x, S x ≠0.
Proof. intros x A. discriminate A. Qed.
Goal ∀x y, S x = S y →x = y.
Proof. intros x y A. injection A. auto. Qed.
The tactic congruence can prove both of the above goals in one go.
Exercise 3.2.1 Give
three
proofs
for
each
of
the
following
goals:
with
congruence, with discriminate, and with change.
(a) Goal ∀(X : Type) (x : X),
Some x ≠None.
(b) Goal ∀(X : Type) (x : X) (A : list X),
x::A ≠nil.
Exercise 3.2.2 Give
three
proofs
for
each
of
the
following
goals:
with
congruence, with injection, and with change.
(a) Goal ∀(X Y: Type) (x x’ : X) (y y’ : Y),
(x,y) = (x’,y’) →x=x’ ∧y = y’.
(b) Goal ∀(X : Type) (x x’ : X) (A A’ : list X),
x::A = x’::A’ →x=x’ ∧A = A’.
Exercise 3.2.3 Prove the following goals.
(a) Goal ∀x, negb x ≠x.
(b) Goal ∀x, S x ≠x.
(c) Goal ∀x y z, x + y = x + z →y = z.
(d) Goal ∀x y : nat, x = y ∨x ≠y.
Hint: Recall that you can simplify an assumption A with the command simpl in A.
62
2014-7-16

3.3 Leibniz Equality
Exercise 3.2.4 Prove the following goal.
Goal ∃(X : Type) (f : list X →X), ∀A B, f A = f B →A = B.
Before you prove the goal, you may deﬁne an inductive type.
Exercise 3.2.5 Prove False ≠True.
Exercise 3.2.6 A term λx : s. tx can only be eta reduced if x does not occur in t.
If this restriction was removed, we could obtain a proof of False. Show this by
proving the following goal.
Goal ∃(f : nat →nat →nat) x,
(fun x ⇒f x x) ≠f x.
3.3 Leibniz Equality
There is a straightforward characterization of equality that can be expressed in
every logical system that can quantify over predicates. The characterization is
due to the philosopher and mathematician Gottfried Wilhelm Leibniz and says
that two objects x and y are equal if they have the same properties. Formally,
Leibniz’ characterization can be expressed with the equivalence
x = y ↔∀p : X →Prop. px ↔py
We can use the equivalence to deﬁne equality. If equality is obtained in some
other way, we still expect it to satisfy the equivalence. This means that equality
is determined up to logical equivalence in any logical system that can quantify
over predicates. The Leibniz characterization of equality suﬃces to justify the
tactics reﬂexivity and rewrite.
1. Assume that s and t are convertible terms such that the equation s = t is well
typed. We prove the proposition s = t. First we observe that the propositions
s = t and s = s are convertible since s and t are convertible (recall that
propositions are terms). Thus we know by the conversion principle that s = t
is provable if s = s is provable. By the Leibniz characterization of equality we
know that s = s is provable if ∀p : X →Prop. ps ↔ps is provable, which is the
case. So we have a proof of s = t and a justiﬁcation of the tactic reﬂexivity.
2. Assume we have a proof of an equation s = t and two propositions us and ut.
Then we know by the Leibniz characterization of s = t that us is provable if
and only if ut is provable. So if we have a claim or an assumption us, we can
rewrite it to ut. This justiﬁes the rewriting tactic for the case where s and t
appear as the right constituent of a top level application. Since we have beta
2014-7-16
63

3 Deﬁnitional Equality and Propositional Equality
conversion, the restriction to top level applications is not signiﬁcant. Given
a term v containing a subterm s, beta expansion will give us a term u such
that the terms v and us are convertible. Taken together, we have arrived at a
justiﬁcation of the tactic rewrite.
We now deﬁne an equality predicate we call Leibniz equality.
Deﬁnition leibniz_eq (X : Type) (x y : X) : Prop :=
∀p : X →Prop, p x →p y.
The deﬁnition deviates from Leibniz’ characterization in that it uses an implica-
tion rather than an equivalence. As it turns out, the asymmetric version we use
is logically equivalent to the symmetric version with the equivalence. We have
chosen the asymmetric version since it is simpler than the symmetric version.
We can read the asymmetric version as follows: A proof of x = y is a function
that for every predicate p maps a proof of px to a proof of py.
We deﬁne a convenient notation for Leibniz equality and prove that it is re-
ﬂexive and symmetric.
Notation "x == y" := (leibniz_eq x y) (at level 70, no associativity).
Lemma leibniz_reﬂX (x : X) :
x == x.
Proof. hnf. auto. Qed.
Lemma leibniz_sym X (x y : X) :
x == y →y == x.
Proof.
unfold leibniz_eq. intros A p.
apply (A (fun z ⇒p z →p x)).
auto.
Qed.
Next we show that Leibniz equality agrees with Coq’s predeﬁned equality.
Lemma leibniz_agrees X (x y : X) :
x == y ↔x = y.
Proof.
split ; intros A.
−apply (A (fun z ⇒x=z)). reﬂexivity.
−rewrite A. apply leibniz_reﬂ.
Qed.
Since we can turn Leibniz equations into Coq equations, we can rewrite with
Leibniz equations. However, we can also rewrite without going through Coq’s
predeﬁned equality. All we need is the following lemma.
Lemma leibniz_rewrite X (x y : X) (p : X →Prop) :
x == y →p y →p x.
64
2014-7-16

3.3 Leibniz Equality
Proof. intros A. apply (leibniz_sym A). Qed.
We now prove that addition is associative with respect to Leibniz equality without
using anything connected with Coq’s predeﬁned equality.
Lemma leibniz_plus_assoc x y z :
(x + y) + z == x + (y + z).
Proof.
induction x ; simpl.
−apply leibniz_reﬂ.
−pattern (x+y+z). apply (leibniz_rewrite IHx). apply leibniz_reﬂ.
Qed.
The proof deserves careful study. One interesting point is the use of pattern to
abstract out the term we want to rewrite. With pattern we can convert a term s
containing a subterm u to a beta redex (λx.t)u such that λx.t is the predicate p
we need to rewrite with a Leibniz equation u == v. So beta conversion makes it
possible to reduce general rewriting to top level rewriting pu ⇝pv. A proof of
the proposition ∀p. pv →pu is a function that makes it possible to rewrite a
claim with the equation u = v.
Coq’s library deﬁnes equality as an inductive predicate. This is in harmony
with the deﬁnitions of the logical connectives and of existential quantiﬁcation.
We will discuss Coq’s inductive deﬁnition of equality in a later chapter on induc-
tive predicates.
Exercise 3.3.1 Prove that addition is commutative for Leibniz equality without
using Coq’s predeﬁned equality. You will need two lemmas.
Exercise 3.3.2 Prove the following rewrite lemmas for Leibniz equality without
using other lemmas.
(a) Lemma leibniz_rewrite_lr X (x y : X) (p : X →Prop) :
x == y →p y →p x.
(b) Lemma leibniz_rewrite_rl X (x y : X) (p : X →Prop) :
x == y →p x →p y.
Exercise 3.3.3 Suppose we want to rewrite a subterm u in a proposition t us-
ing the lemma leibniz_rewrite. Then we need a predicate λx.s such that t and
(λx.s)u are convertible and s is obtained from t by replacing the occurrence of u
we want to rewrite with the variable x. Let t be the proposition x + y + x = y.
a) Give a predicate for rewriting the ﬁrst occurrence of x in t.
b) Give a predicate for rewriting the second occurrence of y in t.
c) Give a predicate for rewriting all occurrences of y in t.
d) Give a predicate for rewriting the term x + y in t.
e) Explain why the term y + x cannot be rewritten in t.
2014-7-16
65

3 Deﬁnitional Equality and Propositional Equality
3.4 By Name Speciﬁcation of Implicit Arguments
We take the opportunity to discuss an engineering detail of Coq’s term language.
In implicit arguments mode, Coq derives for some constants (i.e., deﬁned names)
an expanded type providing for additional implicit arguments. The real type and
the expanded type are always convertible, so the diﬀerence does not matter for
type checking. We can use the command About to ﬁnd out whether Coq has
determined an expanded type for a constant. For instance, this is the case for
the constant leibniz_sym deﬁned in the previous section.
About leibniz_sym.
leibniz_sym : ∀(X : Type) (x y : X), x == y →y == x
Expanded type for implicit arguments
leibniz_sym : ∀(X : Type) (x y : X), x == y →∀p : X →Prop, p y →p x
Arguments X, x, y, p are implicit
If you print the lemma leibniz_rewrite from the previous section, you will see the
following proof term:
fun (X : Type) (x y : X) (p : X →Prop) (A : x == y) =>
leibniz_sym (x:=x) (y:=y) A (p:=p)
Note that the implicit arguments x, y, and p of leibniz_sym are explicitly speci-
ﬁed by name. By-name speciﬁcation of implicit and explicit arguments can also
be used when you give terms to Coq. Step through the following script to under-
stand the many notational possibilities Coq has in oﬀer.
Goal ∀X (x y : X) (p : X →Prop),
x == y →p y →p x.
Proof.
intros X x y p A.
Check leibniz_sym A.
Check leibniz_sym A (p:=p).
Check @leibniz_sym X x y A p.
Check @leibniz_sym _ _ _ A p.
exact (leibniz_sym A (p:=p)).
Show Proof.
Qed.
3.5 Local Deﬁnitions
Coq’s term language has a construct for local deﬁnitions taking the form
let x : t := s in u
66
2014-7-16

3.6 Proof of nat ≠bool
where x is the local name, t is the type declared for x, s is value of x, and u is
the term in which the local deﬁnition is visible. Coq will check that the term s has
the declared type t. In case the declared type is omitted, Coq will try to infer it.
Local deﬁnitions come with a reduction rule called zeta reduction that replaces
the deﬁned name with its value:
let x : t := s in u
⇝
u x
s
Here are examples.
Compute let x := 2 in x + x.
% 4 : nat
Compute let x := 2 in let x := x + x in x.
% 4 : nat
Compute let f := plus 3 in f 7.
% 10 : nat
The undirected version of zeta reduction serves as a conversion rule (zeta con-
version). Note that zeta reduction looks very much like beta reduction. There is
however an important diﬀerence between a local deﬁnition let x : t := s in u and
the corresponding beta redex (λx : t. u) s : The continuation u of a local deﬁnition
is type checked with delta conversion enabled between the local name x and the
deﬁning term s. Thus the local deﬁnition
Check let X := nat in (fun x : X ⇒x) 2.
will type check while the corresponding beta redex will not.
Check (fun X ⇒(fun x : X ⇒x) 2) nat.
% Error : The term 2 is expected to have type X.
Besides for local deﬁnitions, Coq uses the let notation also as a syntactic
convenience for one-constructor matches. For instance:
let (x,y) := (2,7) in x + y
⇝
match (2,7) with pair x y ⇒x + y end
3.6 Proof of nat ≠bool
We will now prove that the types bool and nat are diﬀerent.
The proof will
employ a predicate p on types that holds for bool but does not hold for nat.
For p we choose the property that a type has at most two elements. The proof
script uses two important tactics we have not seen before.
Goal bool ≠nat.
2014-7-16
67

3 Deﬁnitional Equality and Propositional Equality
Proof.
pose (p X := ∀x y z : X, x=y ∨x=z ∨y=z).
assert (H: ¬p nat).
{ intros B. specialize (B 0 1 2). destruct B as [B|[B|B]] ; discriminate B. }
intros A. apply H. rewrite ←A.
intros [|]
[|]
[|] ; auto.
Qed.
The tactic pose deﬁnes the discriminating predicate p.3 The tactic assert states
the intermediate claim ¬p nat. For the proof of the intermediate claim Coq in-
troduces a subgoal. The script proving the subgoal is enclosed in curly braces.
The tactic specialize is used to instantiate the universally quantiﬁed assumption
p nat with the numbers 0, 1, and 2. With case analysis and discriminate we show
that the instantiated assumption is contradictory. After the intermediate claim
is established, we can use it as an additional assumption H. We now introduce
the assumption A : bool = nat and apply the intermediate claim H. The claim is
now p nat. We rewrite with the assumption A and obtain the claim p bool. This
claim follows by case analysis over the universally quantiﬁed boolean variables.
As always, step carefully through the proof script to understand.
Exercise 3.6.1 Prove the following goals.
(a) Goal bool ≠option bool.
(b) Goal option bool ≠prod bool bool.
(c) Goal bool ≠⊥.
Exercise 3.6.2 Step through the proof of bool ≠nat and insert the command
Show Proof immediately after the assert. You will see that the local deﬁnition
of p is realized with a let and that the assumption H is realized with a beta redex.
let p := fun X : Type ⇒forall x y z : X, x = y ∨x = z ∨y = z in
(fun H : ¬ p nat ⇒?2) ?1
The two existential variables ?2 and ?1 represent the claims of the two subgoals
that have to be solved at this point (1 represents the claim of the subgoal for the
assert and ?2 represents the claim of the remaining subgoal).
3.7 Cantor’s Theorem
Cantor’s theorem says that there is no surjective function from a set to its power
set. This means that the power set of a set X is strictly larger than X. For his
proof Cantor used a technique commonly called diagonalisation.
It turns out
3 The tactic pose constructs a proof term with a let expression accommodating the local deﬁni-
tion.
68
2014-7-16

3.7 Cantor’s Theorem
that Cantor’s proof carries over to type theory. Here we can show that there is
no surjective function from a Type X to the type X →Prop. Speaking informally,
this means that there are strictly more predicates on X than there are elements
of X.
Deﬁnition surjective (X Y : Type) (f : X →Y) : Prop := ∀y, ∃x, f x = y.
Lemma Cantor X :
¬ ∃f : X →X →Prop, surjective f.
Proof.
intros [f A].
pose (g x := ¬ f x x).
specialize (A g).
destruct A as [x A].
assert (H: ¬ (g x ↔¬ g x)) by τto.
apply H. unfold g at 1. rewrite A. τto.
Qed.
The proof assumes a type X and a surjective function f from X to X →Prop
and constructs a proof of False. We ﬁrst deﬁne a spoiler function gx := ¬fxx in
X →Prop. Since f is surjective, there is an x such that f x = g. Thus gx =
¬f xx = ¬gx, which is contradictory.
Exercise 3.7.1 Prove the following goals.
(a) Goal ¬ ∃f : nat →nat →nat, surjective f.
(b) Goal ¬ ∃f : bool →bool →bool, surjective f.
Exercise 3.7.2 Prove the following generalization of Cantor’s Theorem.
Lemma Cantor_generalized X Y :
(∃N : Y →Y, ∀y, N y ≠y) →
¬ ∃f : X →X →Y, surjective f.
Exercise 3.7.3 Prove the following variant of Cantor’s Theorem.
Lemma Cantor_neq X Y (f : X →X →Y) (N : Y →Y) :
(∀y, N y ≠y) →∃h, ∀x, f x ≠h.
Exercise 3.7.4 Prove the following goals. They establish suﬃcient conditions for
the surjectivity and injectivity of functions based on inverse functions.
Deﬁnition injective (X Y : Type) (f : X →Y) : Prop := ∀x x’ : X, f x = f x’ →x = x’.
Goal ∀X Y : Type, ∀f : X →Y, (∃g : Y →X, ∀y, f (g y) = y) →surjective f.
Goal ∀X Y : Type, ∀f : X →Y, (∃g : Y →X, ∀x, g (f x) = x) →injective f.
2014-7-16
69

3 Deﬁnitional Equality and Propositional Equality
Exercise 3.7.5 One can also show that no type X admits an injective function f
from X →Prop to X. Given X and f , the proof deﬁnes a predicate p : X →Prop
such that both ¬p(f p) and p(f p) are provable. Given the deﬁnition of p, the
proof is routine. Complete the following proof script.
Goal ∀X, ¬ ∃f : (X →Prop) →X, injective f.
Proof.
intros X [f A].
pose (p x := ∃h, f h = x ∧¬ h x).
· · ·
Qed.
3.8 Kaminski’s Equation
Kaminski’s equation4 takes the form f (f (f x)) = f x and holds for every func-
tion f : bool →bool and every boolean x. The proof proceeds by repeated boolean
case analysis: First on x and then on f true and f false. For the proof to work,
the boolean case analysis on f true must provide the equations f true = true and
f true = false coming with the case analysis. The equations are also needed for
the case analysis on f false. We use the annotation eqn to tell the tactic destruct
that we need the equations.
Goal ∀(f : bool →bool) (x : bool), f (f (f x)) = f x.
Proof. intros f x. destruct x, (f true) eqn:A, (f false) eqn:B ; congruence. Qed.
To understand, replace the semicolon before congruence with a period and solve
the 8 subgoals by hand.
For boolean case analyses, the annotated use of destruct can be simulated
with the following lemma.
Lemma destruct_eqn_bool (p : bool →Prop) (x : bool) :
(x = true →p true) →(x = false →p false) →p x.
Proof. destruct x ; auto. Qed.
To apply the lemma, we use the tactic pattern to identify the predicate p.
Goal ∀(f : bool →bool) (x : bool), f (f (f x)) = f x.
Proof.
destruct x ;
pattern (f true) ; apply destruct_eqn_bool ;
pattern (f false) ; apply destruct_eqn_bool ;
congruence.
Qed.
4 The equation was brought up as a proof challenge by Mark Kaminski in 2005 when he wrote
his Bachelor’s thesis on classical higher-order logic.
70
2014-7-16

3.9 Boolean Equality Tests
Replace the semicolons with periods and solve the subgoals by hand to under-
stand.
Exercise 3.8.1 Prove the following variant of Kaminski’s equation.
Goal ∀(f g : bool →bool) (x : bool), f (f (f (g x))) = f (g (g (g x))).
3.9 Boolean Equality Tests
It is not diﬃcult to write a boolean equality test for nat.
Fixpoint nat_eqb (x y : nat) : bool :=
match x, y with
| O, O ⇒true
| S x’, S y’ ⇒nat_eqb x’ y’
| _, _ ⇒false
end.
We prove that the boolean equality test agrees with Coq’s equality.
Lemma nat_eqb_agrees x y :
nat_eqb x y = true ↔x = y.
Proof.
revert y.
induction x ; intros [|y] ; split ; simpl ; intros A ; try congruence.
−f_equal. apply IHx, A.
−apply IHx. congruence.
Qed.
Note that the proof uses the tactical try. Try is needed since congruence can
only solve 6 of the 8 subgoals produced by the induction on x, the case analysis
on y, and the split of the equivalence. A command try t behaves like the tactic
t if t succeeds but leaves the goal unchanged if t fails. Also note the command
apply IHx, A. It ﬁrst applies the inductive hypothesis from left to right and then
applies the assumption A. So we learn that apply can apply equivalences in either
direction and that succeeding applications can be condensed in one apply with
commas. Without these conveniences, we may write apply IHx, A as
destruct (IHx y) as [C _]. apply C. apply A.
Exercise 3.9.1 Write a boolean equality test for bool and prove that it agrees
with Coq’s equality.
Exercise 3.9.2 Write a boolean equality test for lists and prove that it agrees with
Coq’s equality. The equality test for lists should take a boolean equality test for
the element type of the lists as arguments. Prove the correctness of your equality
test with the following lemma.
2014-7-16
71

3 Deﬁnitional Equality and Propositional Equality
Lemma list_eqb_agrees X (X_eqb : X →X →bool) (A B : list X) :
(∀x y, X_eqb x y = true ↔x = y) →
(list_eqb X_eqb A B = true ↔A = B).
Coq Summary
Conversion Tactics
change, pattern, hnf , cbv, simpl, unfold, fold.
Constructor Tactics
discriminate, injection, congruence.
Other Tactics
pose, assert.
Tacticals
try
New Features of the Tactics apply and destruct
•
apply can apply equivalences in either direction. See Section 3.9, proof of
nat_eqb_agrees.
•
A sequence of applies can be written as a single apply using commas. For
instance, we may write “apply A, B, C.” for “apply A. apply B. apply C.”. See
Section 3.9, proof of nat_eqb_agrees.
•
destruct can be used with an eqn-annotation to provide the equations gov-
erning the case analysis as assumptions. The eqn-annotation goes after the
as-annotation.
New Features of the Term Language
•
Implicit arguments can be speciﬁed by name rather than by position.
See
Section 3.4, application of leibniz_sym.
•
Local deﬁnitions with the let notation. See Section 3.5.
•
Let notation for one-constructor matches. See Section 3.5.
Sections
See Section 3.1.
72
2014-7-16

4 Induction and Recursion
So far we have done all inductive proofs with the tactic induction. We will con-
tinue to do so, but it is time to explain how inductive proofs are obtained in
Coq’s type theory.
Recall that tactics are not part of Coq’s type theory, that
propositions are represented as types, and that proofs are represented as terms
describing elements of propositions. So there must be some way to represent
inductive proofs as terms of the type theory. Since inductive proofs in Coq are
always based on inductive types (e.g., nat or list X), the fact that Coq obtains
structural induction as structural recursion should not come as a surprise.
4.1 Induction Lemmas
When we deﬁne an inductive type, Coq automatically establishes an induction
lemma for this type. For nat the induction lemma has the following type.1
Check nat_ind.
nat_ind : ∀p : nat →Prop, p 0 →(∀n : nat, p n →p (Sn)) →∀n : nat, p n
The type tells us that nat_ind is a function that takes a predicate p and yields
a proof of ∀n : nat, p n, provided it is given a proof of p 0 and a function that
for every n and every proof of p n yields a proof of p(S n). The second and the
third argument of nat_ind represent what in mathematical speak is called the
basis step and the inductive step.
Coq’s tactic induction is applied to a variable of an inductive type and applies
the induction lemma of this type. In the case of nat_ind this will produce two
subgoals, one for the basis step and one for the inductive step. Here is a proof
that obtains the necessary induction by applying nat_ind directly.
Goal ∀n, n + 0 = n.
Proof.
apply (nat_ind (fun n ⇒n + 0 = n)).
−reﬂexivity.
−intros n IHn. simpl. f_equal. exact IHn.
Qed.
1 Coq uses the capital letter P for the argument p. We follow our own conventions and use the
letter p. The diﬀerence will not matter in the following.
73

4 Induction and Recursion
The proof applies Coq’s induction lemma nat_ind with the right predicate p. This
yields two subgoals, one for the basis step and one for the inductive step. Note
the introduction of the inductive hypothesis IHn in the script for the inductive
step.
Here is a second example for the use of the induction lemma nat_ind.
Goal ∀n m, n + S m = S (n + m).
Proof.
intros n m. revert n.
apply (nat_ind (fun n ⇒n + S m = S (n + m))) ; simpl.
−reﬂexivity.
−intros n IHn. f_equal. exact IHn.
Qed.
The proof would also go through with a more general inductive predicate p quan-
tifying over m. In this case the ﬁrst line of the proof script would be deleted. See
Exercise 4.1.1.
We now know how to construct inductive proofs with the induction lemma
nat_ind.
Next we explain how the lemma nat_ind is deﬁned.
Speaking type
theoretically, we have to deﬁne a function that has the type of nat_ind. We do
this with the deﬁnition command using a recursive abstraction.
Deﬁnition nat_ind (p : nat →Prop) (basis : p 0) (step : ∀n, p n →p (S n))
: ∀n, p n := ﬁx f n := match n return p n with
| 0 ⇒basis
| S n’ ⇒step n’ (f n’)
end.
Note that the match speciﬁes a return type function λn.pn. This is necessary
since the two rules of the match have diﬀerent return types. The return type of
the ﬁrst rule is p 0, and the return type of the second rule is p(S n′). The return
types of the rules are obtained by applying the return type function to the left
hand sides of the rules.
Exercise 4.1.1 Prove the following goal by applying the induction lemma nat_ind
immediately (i.e., don’t introduce n and m).
Goal ∀n m, n + S m = S (n + m).
74
2014-7-16

4.2 Primitive Recursion
Exercise 4.1.2 We consider an induction lemma for list types.
a) Complete the following deﬁnition of an induction lemma for list types.
Deﬁnition list_ind (X : Type) (p : list X →Prop)
(basis : p nil)
(step : ∀(x : X) (A : list X), p A →p (x::A))
: ∀A : list X, p A :=
b) Prove that list concatenation is associative using the induction lemma list_ind.
c) Use the command Check to ﬁnd out the type of the induction lemma Coq
provides for list types. Since Coq’s lemma is also bound to the name list_ind,
you will have to undo your deﬁnition to see the type.
4.2 Primitive Recursion
Primitive recursion is a basic computational idea for natural numbers ﬁrst stud-
ied in the 1930’s. We saw a formulation of primitive recursion called iteration
in Section 1.12.
The basic idea is to apply a step function n-times to a start
value. We formalized the idea with a function nat_iter taking the number n, the
step function, and the start value as arguments.2 For the application of nat_iter
the type of nat_iter is crucial. The more general the type of nat_iter, the more
recursive functions can be expressed with nat_iter.
We will now formulate primitive recursion as a function prec that can express
both the computational function nat_iter and the induction lemma nat_ind. We
base the deﬁnition of prec on two equations.
prec x f 0 = x
prec x f (S n) = f n (prec x f n)
Compared to nat_iter, we have reordered the arguments and now work with a
step function that takes the number of iterations so far as an additional ﬁrst
argument. For instance, prec x f 3 = f 2 (f 1 (f 0 x)). From the equations it is clear
that prec can express nat_iter.
We now come to the type of prec. We take the type of the induction lemma
nat_ind where the type of p is generalized to nat →Type (recall that propositions
are types).
prec : ∀p : nat →Type, p 0 →(∀n : nat, p n →p (Sn)) →∀n : nat, p n
Given the type and the equations, the deﬁnition of prec is straightforward.3
2 In Section 1.12 we used the short name iter for nat_iter. The function nat_iter is deﬁned in
Coq’s standard library.
3 Due to implicit argument mode, p is accommodated as implicit argument of prec.
2014-7-16
75

4 Induction and Recursion
Deﬁnition prec (p : nat →Type) (x : p 0) (f : ∀n, p n →p (S n))
: ∀n, p n := ﬁx F n := match n return p n with
| 0 ⇒x
| S n’ ⇒f n’ (F n’)
end.
Note that the deﬁnition of prec is identical with the deﬁnition of the induction
lemma nat_ind except for the more general type of p.
Since nat →Prop is a
subtype of nat →Type, we can instantiate the type of prec to the type of nat_ind.
Check fun p : nat →Prop ⇒prec (p:= p).
∀p : nat →Prop, p 0 →(∀n : nat, p n →p (Sn)) →∀n : nat, p n
Thus we can use prec to obtain the induction lemma nat_ind.
Lemma nat_ind (p : nat →Prop) :
p 0 →(∀n, p n →p (S n)) →∀n, p n.
Proof. exact (prec (p:=p)). Qed.
We can also deﬁne arithmetic functions like addition with prec.
Deﬁnition add := prec (fun y ⇒y) (fun _ r y ⇒S (r y)).
Compute add 3 7.
% 10
We prove that add agrees with the addition provided by Coq’s library.
Goal ∀x y, add x y = x + y.
Proof. intros x y. induction x ; simpl ; congruence. Qed.
As announced before, we can obtain the function nat_iter from prec.
Goal ∀X f x n ,
nat_iter n f x = prec (p:= fun _ ⇒X) x (fun _ ⇒f) n.
Proof. induction n ; simpl ; congruence. Qed.
If we were allowed only a single use of ﬁx for nat, we could deﬁne prec and
then express all further recursions with prec. In fact, since prec can also express
matches on nat, we can work without ﬁx and match for nat as long as we have
prec.
Coq automatically synthesizes a primitive recursion function X_rect for every
inductive type X. Print nat_rect to see the primitive recursion function for nat.
Exercise 4.2.1 Prove prec = nat_rect.
Exercise 4.2.2 Prove that prec satisﬁes the two characteristic equations stated
at the beginning of this section.
Exercise 4.2.3 Show that prec can express multiplication and factorial.
76
2014-7-16

4.3 Size Induction
Exercise 4.2.4 Show that prec can express the predecessor function pred.
Exercise 4.2.5 Show that prec can express matches for nat. Do this by complet-
ing and proving the following goal.
Goal ∀X x f n ,
match n with O ⇒x | S n’ ⇒f n’ end = prec
. . .
.
4.3 Size Induction
Given a predicate p : X →Prop, size induction says that we can prove px using
the assumption that we have a proof of py for every y whose size is smaller
than the size of x. The sizes of the elements of X are given by a size function
X →nat. We formulate size induction as a proposition and prove it with natural
induction (i.e., structural induction on nat).
Lemma size_induction X (f : X →nat) (p : X →Prop) :
(∀x, (∀y, f y < f x →p y) →p x) →
∀x, p x.
Proof.
intros step x. apply step.
assert (G: ∀n y, f y < n →p y).
{ intros n. induction n.
−intros y B. exfalso. omega.
−intros y B. apply step. intros z C. apply IHn. omega. }
apply G.
Qed.
The proof is clever. It introduces the step function step of the size induction
and x, leaving us with the claim p x.
By applying step we obtain the claim
∀y : X. f y < f x →p y.
The trick is now to generalize this claim to the more
general claim ∀n ∀y : X. f y < n →p y, which can be shown by natural induction
on n.
Note that we have not seen a deﬁnition of Coq’s order predicate “<" for nat.
The details of the deﬁnition do not matter since we are using the automation
tactic omega to solve goals involving the order predicate.
Exercise 4.3.1 The principle of complete induction can be formulated as follows.
Lemma complete_induction (p : nat →Prop) :
(∀x, (∀y, y < x →p y) →p x) →∀x, p x.
a) Prove the lemma using the lemma size_induction.
b) Prove the lemma using natural induction.
2014-7-16
77

4 Induction and Recursion
Exercise 4.3.2 Deﬁne your own order predicate lt : nat →nat →Prop and prove
the size induction lemma for your order predicate.
Hint: Deﬁne lt with the
boolean order test leb from Section 1.3 and prove the following lemma by in-
duction on x. No other lemma will be needed.
Lemma lt_tran x y z : lt x y →lt y (S z) →lt x z.
4.4 Equational Speciﬁcation of Functions
It is often instructive to specify a recursive function by a system of equations.
We have seen such equational speciﬁcations for the functions plus, nat_iter, and
prec. For arithmetic functions like addition and multiplication equational spec-
iﬁcations where already used by Dedekind. In Coq, we can express equational
speciﬁcations as predicates. Given a speciﬁcation, we may prove that there is
a function satisfying the speciﬁcation (satisﬁability) and that any two function
satisfying the speciﬁcation agree on all arguments (uniqueness). We start with a
somewhat unusual speciﬁcation of addition.
Deﬁnition addition (f : nat →nat →nat) : Prop :=
∀x y,
f x 0 = x ∧
f x (S y) = f (S x) y.
Lemma addition_existence :
addition plus.
Proof. intros x y. omega. Qed.
Lemma addition_uniqueness f g :
addition f →addition g →∀x y, f x y = g x y.
Proof.
intros A B x y. revert x. induction y ; intros x.
−destruct (A x 0) as [A’ _]. destruct (B x 0) as [B’ _]. congruence.
−destruct (A x y) as [_ A’]. destruct (B x y) as [_ B’]. specialize (IHy (S x)). congruence.
Qed.
From the example we learn that an equational speciﬁcation is abstract in that is
does not say how the speciﬁed function is realized. The speciﬁcation addition
suggests a tail recursive function matching on the second argument. The func-
tion plus from the library recurses on the ﬁrst argument and is not tail recursive.
Nevertheless, plus satisﬁes the speciﬁcation addition.
Our second example speciﬁes a function known as Ackermann’s function.4
4 Ackermann’s function grows rapidly. For example, for 4 and 2 it yields a number of 19,729
decimal digits. It was designed as a terminating recursive function that cannot be computed
with ﬁrst-order primitive recursion. In Exercise 4.4.2 you will show that Ackermann’s function
can be computed with higher-order primitive recursion.
78
2014-7-16

4.4 Equational Speciﬁcation of Functions
Deﬁnition ackermann (f : nat →nat →nat) : Prop :=
∀m n,
f O n = S n ∧
f (S m) O = f m 1 ∧
f (S m) (S n) = f m (f (S m) n).
The satisﬁability and uniqueness of this speciﬁcation can be argued as follows.
Since for any two arguments exactly one of the three equations applies, f exists
and is unique if the application of the equations terminates. This is the case
since either the ﬁrst argument is decreased, or the ﬁrst argument stays the same
and the second argument is decreased.
The above termination argument is outside the scope of Coq’s termination
checker. Coq insists that every ﬁx comes with an argument that is structurally
decreased by every recursive application. The problem can be solved by formu-
lating Ackermann’s function with two nested recursions.
Deﬁnition ack : nat →nat →nat :=
ﬁx f m := match m with
| O ⇒S
| S m’ ⇒ﬁx g n := match n with
| O ⇒f m’ 1
| S n’ ⇒f m’ (g n’)
end
end.
Note that ack is deﬁned as a recursive function that yields a recursive function
when give an argument greater than 0. Each of the two recursions is structural
on its argument. The correctness proof for ack is straightforward.
Goal ackermann ack.
Proof. unfold ackermann. auto. Qed.
We can also show that any two functions satisfying the speciﬁcation ackermann
agree on all arguments.
Goal ∀f g x y, ackermann f →ackermann g →f x y = g x y.
Proof.
intros f g x y A B. revert y. induction x ; intros y.
−destruct (A 0 y) as [C _]. destruct (B 0 y) as [D _]. congruence.
−induction y.
+ destruct (A x 0) as [_ [C _]]. destruct (B x 0) as [_ [D _]]. congruence.
+ destruct (A x y) as [_ [_ C]]. destruct (B x y) as [_ [_ D]]. congruence.
Qed.
2014-7-16
79

4 Induction and Recursion
Exercise 4.4.1 Write an equational speciﬁcation for multiplication and prove
that Coq’s multiplication satisﬁes the speciﬁcation. Also prove that two func-
tions agree on all arguments if they satisfy the speciﬁcation. Do the same for
subtraction.
Exercise 4.4.2 Write an Ackermann function using prec rather than ﬁx and
match. Prove that your function satisﬁes the speciﬁcation ackermann.
Exercise 4.4.3 We specify primitive recursion as follows.
Deﬁnition primitive_recursion
(r : ∀p : nat →Type, p 0 →(∀n, p n →p (S n)) →∀n, p n)
: Prop :=
∀p x f n,
let r := r p x f in
r 0 = x ∧
r (S n) = f n (r n).
Note that a local declaration with let is used to write the specifying equations in
compact form. Show that prec satisﬁes the speciﬁcation. Also prove that two
functions agree on all arguments if they satisfy the speciﬁcation.
Exercise 4.4.4 Give an equational speciﬁcation for nat_iter. Prove that nat_iter
satisﬁes the speciﬁcation and that the speciﬁcation is unique.
Coq Summary
New Features of the Term Language
•
Matches can be speciﬁed with a return type function. See Section 4.1, deﬁni-
tion of nat_ind.
80
2014-7-16

5 Truth Value Semantics and
Elim Restriction
Coq’s type theory is designed such that the truth value semantics of proposi-
tions commonly used in Mathematics can be consistently assumed. This design
comes at the price of the elim restriction, which restricts matches on proofs
such that proofs must be returned. The elim restriction severely restricts the
computational use of proofs.
5.1 Truth Value Semantics
In Mathematics one assumes that a proposition is either true or false.
More
speciﬁcally, one assumes that every proposition denotes a truth value, which is
either true or false. With the boolean deﬁnition of disjunction it then follows
that for any proposition p the disjunction p ∨¬p is true.
Given the fact that propositions denote truth values, we could consider two
propositions equal if they denote the same truth value. This assumption is made
in boolean logic as well as in Church-Henkin simple type theory.
We formulate the mathematical assumption that a proposition is either true
or false as a proposition in Coq:
Deﬁnition TVS : Prop := ∀X : Prop, X=⊤∨X=⊥.
We can now ask whether Coq can prove TVS or ¬TVS.
It turns out that Coq
can prove neither of the two. That Coq cannot prove TVS seems intuitively clear
since there is nothing in the basic proof rules that would give us a proof of TVS.
On the other hand, that Coq cannot prove ¬TVS is not clear at all given the fact
that propositions in Coq are obtained as types.
We call a proposition p consistent in Coq if Coq cannot prove ¬p. Moreover,
we call a proposition p independent in Coq if Coq can prove neither p nor ¬p.
Note that every independent proposition is consistent, but not vice versa (e.g.
True is consistent but not independent).
Above we have stated that TVS is independent in Coq. The consistency of TVS
in Coq does not come for free. In fact, the design of Coq’s type theory has been
carefully arranged so that TVS is consistent. To obtain the consistency of TVS,
81

5 Truth Value Semantics and Elim Restriction
Coq imposes a severe typing restriction known as the elim restriction. To prepare
the discussion of the elim restriction, we ﬁrst consider some conseqences of TVS.
First we show that TVS implies XM (excluded middle). This follows from the
fact that True and False satisfy XM (i.e., True ∨¬True and False ∨¬False are
provable).
Goal TVS →XM.
Proof. intros A X. destruct (A X) as [B|B] ; rewrite B ; auto. Qed.
Another important consequence of TVS is proof irrelevance.
Deﬁnition PI : Prop := ∀(X : Prop) (A B : X), A=B.
Proof irrelevance says that a proposition has at most one proof. Here is a proof
that truth value semantics implies proof irrelevance.
Goal TVS →PI.
Proof.
intros A X B C. destruct (A X) ; subst X.
−destruct B, C. reﬂexivity.
−contradiction B.
Qed.
The proof exploits that the proposition True has exactly one proof, a fact fol-
lowing from the inductive deﬁnition of True. The script uses the tactic subst,
which eliminates a variable x if there is an assumption x = s such that x does
not occur in s.
A third consequence of TVS is propositional extensionality.
Deﬁnition PE : Prop := ∀X Y : Prop, (X ↔Y) →X=Y.
Propositional extensionality says that two propositions are equal if they are
equivalent.
Goal TVS →PE.
Proof. intros A X Y B. destruct (A X), (A Y) ; subst X Y ; τto. Qed.
Finally, we show that excluded middle and propositional extensionality to-
gether imply truth value semantics.
Goal XM →PE →TVS.
Proof.
intros xm pe X. destruct (xm X) as [A|A].
−left. apply pe. τto.
−right. apply pe. τto.
Qed.
We now know that TVS and XM ∧PE are equivalent.
82
2014-7-16

5.2 Elim Restriction
Exercise 5.1.1 Make sure you can prove TVS ↔XM ∧PE
Exercise 5.1.2 Prove TVS →PE without using the tactic subst.
Use the tactic
rewrite instead.
5.2 Elim Restriction
If we have a surjective function f : X →bool, then the type X must contain at
least two elements.
Goal ∀X (f : X →bool), surjective f →∃x y : X, x ≠y.
Proof.
intros X f A. destruct (A true) as [x B]. destruct (A false) as [y C].
∃x, y. congruence.
Qed.
Now consider the inductive proposition
Inductive bp : Prop := P1 : bp | P2 : bp.
which by deﬁnition has two proofs P1 and P2. Given the match for bp, it is easy
to construct a surjective function bp →bool, it seems. However, Coq rejects the
following match on x : bp:
Check fun x : bp ⇒match x with P1 ⇒true | P2 ⇒false end.
% Error : Incorrect elimination of "x" . . .
The reason is the so-called elim restriction: A match on a proof (i.e., on an ele-
ment of a proposition) is only allowed if the match returns a proof. The above
match does not return a proof and hence it is rejected by the elim restriction.
One important reason for the elim restriction is that it is needed so that truth
value semantics is consistent in Coq. Without the elim restriction, we get a sur-
jective function from bp to bool, which entails that the proposition bp has two
diﬀerent elements. This however contradicts proof irrelevance, which says that
no proposition has more than one proof. Since TVS entails PI, not having the
elim restriction would mean that truth value semantics is inconsistent in Coq.
There are a few exceptions to the elim restriction, all of them being consistent
with proof irrelevance. For instance, there is no restriction on the matches for
True and False. The remaining exceptions will be discussed in Section 7.5.
We give another example illustrating the elim restriction. Consider the fol-
lowing lemma, which establishes the existence of a so-called Skolem function for
total predicates p : X →Y →Prop where Y is a proposition.
Lemma Prop_Skolem (X : Type) (Y : Prop) (p : X →Y →Prop) :
(∀x, ∃y, p x y) →∃f, ∀x, p x (f x).
2014-7-16
83

5 Truth Value Semantics and Elim Restriction
Proof.
intros A.
∃(fun x ⇒let (y,_) := A x in y).
intros x.
destruct (A x) as [y B].
exact B.
Qed.
The let notation in the deﬁnition of the Skolem function is notational sugar for
the one-constructor match
match A x return Y with ex_intro y _ ⇒y end
This match on the proof A x is legal since it returns a proof y. If we generalize
the lemma to Y : Type, the proof script fails since the match now violates the
elim restriction.
We will speak of proper types and proper values. A proper type is a type
that is not a proposition, and a proper value is an element of a proper type.
Thus a type is not proper if and only if it is a proposition, and a value is not
proper if and only if it is a proof. Examples of proper types are nat, list nat, and
nat →nat. Example of proper values are 5, cons, and λx : nat.x.
Exercise 5.2.1 Prove that the proposition ∀X : Type. X = True ∨X = False is in-
consistent in Coq. Note that TVS is a weaker statement where X is restricted to
propositional types. Find out where your proof breaks if you apply it to TVS.
5.3 Propositional Extensionality Entails Proof Irrelevance
It turns out that propositional extensionality entails proof irrelevance. This is
a surprising result with a very interesting proof. The proof rests on a ﬁxpoint
theorem that given a surjective function X →X →Y states that every function
Y →Y has a ﬁxpoint.
Lemma sur_ﬁxpoint X Y (f : X →X →Y) (g : Y →Y) :
surjective f →∃y, g y = y.
Proof.
intros A.
pose (h x := g (f x x)).
destruct (A h) as [x B].
∃(h x). unfold h at 2. rewrite ←B. reﬂexivity.
Qed.
The proof of the theorem should remind you of Cantor’s theorem. In fact, we
can obtain Cantor’s theorem as a corollary of the surjective ﬁxpoint theorem by
specializing to Y := Prop and g := not.
84
2014-7-16

5.3 Propositional Extensionality Entails Proof Irrelevance
We now assume PE and prove PI. It suﬃces to prove P1 = P2 for the two
constructors of bp since given two proofs x and y of a proposition X we can
obtain a function f such that f P1 = x and f P2 = y using the match for bp. For
P1 = P2 it suﬃces to show that the “negation” function mapping P1 to P2 and
P2 to P1 has a ﬁxpoint. This we obtain with the surjective ﬁxpoint theorem. To
do so, we need a surjective function bp →bp →bp. Such a function is easy to
obtain if we have the equation (bp →bp) = bp. This ﬁnishes the proof since the
equation is a straightforward consequence of PE.
Goal PE →PI.
Proof.
intros pe.
cut (P1=P2).
{ intros A X B C.
change (B = match P1 with P1 ⇒C | P2 ⇒B end).
rewrite A. reﬂexivity. }
pose (neg x := match x with P1 ⇒P2 | P2 ⇒P1 end).
cut (∃P, neg P = P).
{ unfold neg. intros [[|] C].
−symmetry. exact C.
−exact C. }
cut (∃f : bp →bp →bp, surjective f).
{ intros [f A]. apply (sur_ﬁxpoint (f:=f)). exact A. }
cut (bp = (bp →bp)).
{ intros A. rewrite ←A. ∃(fun x ⇒x). intros x. ∃x. reﬂexivity. }
apply pe. split ; auto using P1.
Qed.
Note the use of the tactic cut to realize the backwards reasoning of the proof
outline. In the last line the automation tactic auto is used with a suﬃx telling it
to use the proof constructor P1 : bp.
Exercise 5.3.1 Prove Cantor’s theorem using the surjective ﬁxpoint theorem
sur_ﬁxpoint.
Lemma Cantor X :
¬ ∃f : X →X →Prop, surjective f.
Exercise 5.3.2 Two types are isomorphic if there are commuting functions back
and forth.
Deﬁnition iso (X Y : Type) : Prop :=
∃f : X →Y, ∃g : Y →X, ∀x y, g (f x) = x ∧f (g y) = y.
Propositional univalence is the property that propositions are equal if they are
isomorphic.
2014-7-16
85

5 Truth Value Semantics and Elim Restriction
Deﬁnition PU : Prop := ∀X Y : Prop, iso X Y →X = Y.
It turns out that propositional extensionality factors into propositional univa-
lence and proof irrelevance, that is, PE ↔PU ∧PI.
We have already shown
PE →PI. Prove PE →PU and PU →PI →PE to establish the equivalence.
5.4 A Simpler Proof
There is a simpler proof of PE →PI.1 The idea is to use PE to reduce proving
proof irrelevance of a general proposition to proof irrelevance for True. Since
True has only one proof by deﬁnition, we are done.
The Coq proof looks as
follows.
Goal PE →PI.
intros D X E F.
assert (C: X=⊤) by (apply D; τto).
subst. destruct E, F. reﬂexivity.
Qed.
Exercise 5.4.1 Prove the following subgoals which together prove PE →PI.
Goal PE →∀X:Prop, X →X = ⊤.
Goal (∀X:Prop, X →X = ⊤) →P1 = P2.
Coq Summary
New Tactics
subst, cut.
Tactic auto with using
The tactic auto can be enhanced with lemmas and constructors speciﬁed with a
using suﬃx. See the proof of the goal PE →PI in Section 5.3.
1 This was pointed out by Jonas Oberhauser and Fabian Kunze during the teaching of Introduc-
tion to Computational Logic in 2014.
86
2014-7-16

6 Sum and Sigma Types
Sum types and sigma types are non-propositional variants of disjunctions and
existential quantiﬁcations. Since they are proper types, sum and sigma types are
not subject to the elim restriction. The elements of sum and sigma types are
computational values carrying a proof. With sum and sigma types we can write
certifying functions whose results contain correctness proofs.
6.1 Boolean Sums and Certifying Tests
Boolean sums are disjunctions placed in Type rather than Prop. Coq’s standard
library deﬁnes boolean sums as follows.
Inductive sumbool (X Y : Prop) : Type :=
| left : X →sumbool X Y
| right : Y →sumbool X Y.
Arguments left {X} {Y} _.
Arguments right {X} {Y} _.
Notation "{ X } + { Y }" := (sumbool X Y).
Boolean sums are like disjunctions except for the crucial diﬀerence that they are
proper types rather than propositions. Thus boolean sums are not subject to the
elim restriction. We call the elements of boolean sums decisions. We can think
of a decision as a proof-carrying boolean value, or as a proof of a disjunction on
which we can freely match.
A certifying test is a function that yields a decision. Coq’s library provides
many certifying tests. For instance, there is a certifying test for the order on
natural numbers:
le_dec : ∀x y : nat, {x ≤y} + {¬(x ≤y)}
The type of le_dec tells us that le_dec is a function that takes two numbers x
and y and returns a decision containing a proof of either x ≤y or ¬x ≤y. With
le_dec a minimum function can be written as follows:
Deﬁnition min (x y : nat) : nat :=
if le_dec x y then x else y.
87

6 Sum and Sigma Types
Compute min 7 3.
% 3 : nat
Note the use of the if-then-else notation in the deﬁnition of min. The if-then-else
notation is available for all inductive types with two constructors and expands
to a match. The deﬁnition of min expands as follows.
Set Printing All.
Print min.
min = fun x y : nat ⇒match le_dec x y with left _ ⇒x | right _ ⇒y end
Unset Printing All.
We prove the correctness of min.
Goal ∀x y, (x ≤y →min x y = x) ∧(y ≤x →min x y = y).
Proof.
intros x y. split ; intros A.
−unfold min. destruct (le_dec x y) as [B|B].
+ reﬂexivity.
+ omega.
−unfold min. destruct (le_dec x y) as [B|B].
+ omega.
+ reﬂexivity.
Qed.
The proof can be shortened to a one-liner.
intros x y. split ; intros A ; unfold min ; destruct (le_dec x y) ; omega.
The Coq library Compare_dec oﬀers many certifying tests for natural num-
bers. Here are a few.
le_lt_dec : ∀xy : nat, {x ≤y} + {y < x}
le_ge_dec : ∀xy : nat, {x ≤y} + {x ≥y}
le_gt_dec : ∀xy : nat, {x ≤y} + {x > y}
lt_eq_lt_dec : ∀xy : nat, {x < y} + {x = y} + {y < x}
The type of lt_eq_lt_dec needs explanation. Since boolean sums are proper types
taking propositions as arguments, they cannot be nested. Coq solves the prob-
lem with an additional sum type sumor and a concomitant notation.
Set Printing All.
Check {⊤} + {⊥} + {⊥}.
% sumor (sumbool True False) False : Type
Unset Printing All.
The type sumor and the accompanying notation are deﬁned as follows.
88
2014-7-16

6.2 Inhabitation and Decidability
Inductive sumor (X : Type) (Y : Prop) : Type :=
| inleft : X →sumor X Y
| inright : Y →sumor X Y.
Notation "X + { Y }" := (sumor X Y).
Exercise 6.1.1 Prove the following goal.
Goal ∀X Y : Prop, {X} + {Y} →X ∨Y.
Explain why you cannot prove the other direction ∀X Y : Prop, X ∨Y →{X} + {Y}.
Exercise 6.1.2 Prove the following goals.
Goal ∀x y, if le_dec x y then x ≤y else ¬ x ≤y.
Goal ∀x y, if le_dec x y then x ≤y else x > y.
6.2 Inhabitation and Decidability
An inhabitant of a type is an element of a type. So saying that x is an inhabitant
of a type X means the same as saying that x is a member of X, or that x is an
element of X. We say that a type is inhabited if it has at least one inhabitant.
So a type is inhabited if and only if it is nonempty. Coq’s library comes with an
inductive predicate for inhabitation.
Inductive inhabited (X : Type) : Prop :=
| inhabits : X →inhabited X.
A proposition is inhabited if and only if it is provable.
Goal ∀X : Prop, inhabited X ↔X.
Proof.
split.
−intros [A] ; exact A.
−intros A. constructor. exact A.
Qed.
Note the use of the tactic constructor. Here it has the same eﬀect as the com-
mand apply inhabits. In general, the tactic constructor tries to prove an inductive
proposition by applying a constructor of the deﬁnition of the proposition. The
tactic constructor is convenient since the name of the constructor needs not to
be given.
We say that a proposition p is decidable if the sum {p} + {¬p} is inhabited.
To have a concise notation for decidable propositions, we deﬁne the function
Deﬁnition dec (X : Prop) : Type := {X} + {¬ X}.
2014-7-16
89

6 Sum and Sigma Types
Note that dec is not a predicate. An element of dec X is a decision that gives us
a proof of either X or ¬X. We call a member of dec X a decision of X.
The certifying test le_dec from the standard library tells us that all proposi-
tions of the form x ≤y are decidable.
Check le_dec : ∀x y : nat, dec (x ≤y).
We deﬁne a function that converts a decision to a boolean by forgetting the proof
coming with the decision.
Deﬁnition dec2bool (X : Prop) (d : dec X) : bool :=
if d then true else false.
Compute dec2bool (le_dec 2 3).
% true : bool
We now establish the decidability of True. To do so, we construct a decision
of type dec True. This is easy since the constructor I is a proof of True.
Deﬁnition ⊤_dec : dec ⊤:= left I.
The decidability of False is also easy to establish.
Deﬁnition ⊥_dec : dec ⊥:= right (fun A ⇒A).
In the next section we will show that implications, conjunctions, and disjunc-
tions of decidable propositions are decidable.
Exercise 6.2.1 Prove the following goal.
Goal ∀X : Type, X →inhabited X.
Note that X →inhabited X is notation for the proposition ∀x : X, inhabited X.
Explain why you cannot prove that the type ∀X : Type, inhabited X →X is in-
habited.
Exercise 6.2.2 Prove ∀X Y : Prop. X ∨Y ↔inhabited ({X} + {Y}).
Exercise 6.2.3 Prove ∀X : Prop. dec X →X ∨¬X.
6.3 Writing Certifying Tests
We show that implication preserves decidability of propositions.
Deﬁnition impl_dec (X Y : Prop) : dec X →dec Y →dec (X →Y).
intros A [B|B].
−left. auto.
−destruct A as [A|A].
+ right. auto.
+ left. τto.
Deﬁned.
90
2014-7-16

6.3 Writing Certifying Tests
The deﬁnition of the function impl_dec should come as a surprise. This is the
ﬁrst time we construct a member of a type that is not a proposition with a script.
Use the command Print impl_dec to see that the function constructed is in fact
similar to what you would have written by hand. Note that the tactics left and
right so far used for disjunctions also work for boolean sums. In fact, left and
right will work for every inductive type with two constructors. We can compute
with the certifying test impl_dec.
Check impl_dec (le_dec 3 2) ⊥_dec.
% dec(3 ≤2 →False)
Compute (dec2bool (impl_dec (le_dec 3 2) ⊥_dec)).
% true : bool
Here is a certifying equality test for nat.
Deﬁnition nat_eq_dec (x y : nat) : dec (x=y).
revert y. induction x ; simpl ; intros [|y].
−left. auto.
−right. auto.
−right. auto.
−destruct (IHx y).
+ left. congruence.
+ right. congruence.
Deﬁned.
Compute dec2bool (nat_eq_dec 3 3).
% true : bool
This is the ﬁrst time we use the induction tactic to synthesize a function return-
ing a proper value. When you print nat_eq_dec, you will see that the induction
tactic realizes the necessary recursion with nat_rect, an automatically generated
function providing primitive recursion for nat.
A more convenient way to obtain a certifying equality test for nat is using the
automation tactic decide equality.
Goal ∀x y : nat, dec (x=y).
Proof. unfold dec. decide equality. Qed.
The standard library oﬀers a boolean test leb for the order on nat and a
correctness lemma
leb_iﬀ: ∀x y : nat, leb x y = true ↔x ≤y
We can use leb and leb_iﬀto write a certifying test for the order on nat.
2014-7-16
91

6 Sum and Sigma Types
Deﬁnition le_dec (x y : nat) : dec (x ≤y).
destruct (leb x y) eqn:A.
−left. apply leb_iﬀ. exact A.
−right. intros B. apply leb_iﬀin B. congruence.
Deﬁned.
Note that the script for the second subgoal applies the correctness lemma leb_iﬀ
to the assumption B using the tactic apply. This is the ﬁrst time we apply a
lemma to an assumption using the tactic apply. It is also possible to rewrite
assumptions with the tactic rewrite. We have already mentioned that the conver-
sion tactics can be applied to assumptions. To apply a tactic to an assumption A,
one ends the command with “in A”.
Decidability of propositions propagates through logical equivalences. That is,
if X and Y are equivalent propositions, then X is decidable if and only if Y is
decidable.
Deﬁnition dec_prop_iﬀ(X Y : Prop) : (X ↔Y) →dec X →dec Y.
intros A [B|B].
−left. τto.
−right. τto.
Deﬁned.
There are many undecidable propositions in Coq. A prominent example of an
undecidable proposition is excluded middle (i.e., XM := ∀X : Prop, X ∨¬X). In
fact, a proposition is undecidable in Coq if and only if it is independent in Coq.
Exercise 6.3.1 Prove the following goals.
Goal ∀X : Prop, inhabited X →dec X.
Goal ∀X : Prop, dec X →dec (inhabited X).
Goal ∀X : Prop, dec (inhabited X) →dec X.
Exercise 6.3.2 Complete the following deﬁnitions establishing the fact that de-
cidable propositions are closed under conjunction and disjunction.
Deﬁnition and_dec (X Y : Prop) : dec X →dec Y →dec (X ∧Y).
Deﬁnition or_dec (X Y : Prop) : dec X →dec Y →dec (X ∨Y).
Exercise 6.3.3 Write a certifying test ∀x y : nat. {x < y} + {x = y} + {y < x}.
Exercise 6.3.4 Write a certifying equality test for bool.
a) Use the automation tactic decide equality.
b) Write the test without using decide equality.
92
2014-7-16

6.3 Writing Certifying Tests
Exercise 6.3.5 Compare the certifying equality test nat_eq_dec from this section
with the boolean equality test nat_eqb and its correctness lemma nat_eqb_agrees
from Section 3.9. We can say that the certifying test combines the boolean test
and its correctness lemma into a single function.
a) Deﬁne nat_eqb and nat_eqb_agrees using nat_eq_dec.
b) Deﬁne nat_eq_dec using nat_eqb and nat_eqb_agrees.
Exercise 6.3.6 Consider the boolean test leb and the certifying test le_dec from
the standard library.
a) Prove the correctness lemma for leb.
Lemma leb_iﬀx y : leb x y = true ↔x ≤y.
b) Deﬁne the certifying test le_dec using the induction tactic. Follow the deﬁni-
tion of nat_eq_dec shown above. Compare this deﬁnition of le_dec with the
proof of leb_iﬀ.
Exercise 6.3.7 Write a function that given a certifying equality test for a type X
yields a certifying equality test for list X. Write the function with and without
the automation tactic decide equality.
Exercise 6.3.8 Complete the following deﬁnition. It establishes a function trans-
lating a boolean decision of a proposition X into a certifying decision of X.
Deﬁnition bool2dec (X : Prop) (b : bool) : (X ↔b = true) →dec X.
Exercise 6.3.9 (Program Synthesis) One can use tactics to synthesize ordinary
functions not involving proofs. Here are two examples.
Deﬁnition cas (X Y Z : Type) : (X * Y →Z) →X →Y →Z.
intros f x y. exact (f (x,y)).
Deﬁned.
Deﬁnition car (X Y Z : Type) : (X →Y →Z) →X * Y →Z.
intros f [x y]. exact (f x y).
Deﬁned.
Use the command Print to see the synthesized functions. It is also possible to
synthesize recursive functions like addition.
Deﬁnition add : nat →nat →nat.
ﬁx f 1. intros x y. destruct x as [|x’].
−exact y.
−exact (S (f x’ y )).
Deﬁned.
Use the command Show Proof after each tactic to see the partial code of the
function synthesized by the tactic.
2014-7-16
93

6 Sum and Sigma Types
6.4 Deﬁnitions and Lemmas
A deﬁnition in Coq is either inductive or plain. Inductive deﬁnitions extend the
underlying type theory with new inhabitants obtained with constructors. Plain
deﬁnitions do not extend the type theory but introduce names for already ex-
isting inhabitants. A plain deﬁnition takes the form x : t := s where x is a name
and t and s are terms. The term t must be a type and s must be a member of t.
We call x the name of the deﬁnition, t the type of the deﬁnition, and s the body
of the deﬁnition. The type of a plain deﬁnition acts as the type of the name of
the deﬁnition.
A plain deﬁnition can be either transparent or opaque. If the deﬁnition is
transparent, the name and the body of the deﬁnition are convertible (i.e., un-
folding and folding of the name, known as delta conversion). If the deﬁnition is
opaque, the name is abstract and cannot be unfolded. Thus all we know about
an opaque name is that it is an inhabitant of its type.
Opaque deﬁnitions are a means of abstraction.
Given an opaque name x
(i.e., a name introduced by an opaque deﬁnition), we can use the speciﬁcation
of x (i.e., the type of x) but not the implementation of x (i.e., the body of the
opaque deﬁnition of x). Thus every use of an opaque name x will be compatible
with every implementation of x.
Opaque names are as abstract as variables
introduced with lambda abstractions, matches, or sections.
A transparent deﬁnition can be stated in Coq with a command of the form
Deﬁnition x : t := s or a sequence of commands taking the form
Deﬁnition x : t. tactic1 · · · tacticn Deﬁned.
The tactics in the long form synthesize the body s of the deﬁnition. If we replace
the command Deﬁned in the long form with the command Qed, we obtain an
opaque deﬁnition. The command Deﬁnition in the long form can be replaced
with the command Lemma, which has no eﬀect. We use the command Lemma
only for sequences of the following form.1
Lemma x : t. Proof. tactic1 · · · tacticn Qed.
We also use the command sequence
Goal t. Proof. tactic1 · · · tacticn Qed.
This sequence has the same eﬀect as the sequence starting with Lemma except
that the missing name x is automatically generated by Coq.
In Coq, a lemma is an opaque name established with an opaque deﬁnition.
The statement of the lemma is the type of the lemma, and the proof of the
1 The Coq library doesn’t always follow this convention.
For instance, le_dec is deﬁned with
Theorem and Deﬁned.
94
2014-7-16

6.5 Decidable Predicates
lemma is the hidden body of the deﬁnition. The proof of a lemma certiﬁes that
the type of the lemma is inhabited. If we work with a lemma, the uses of the
lemma cannot see the proof of the lemma. So all uses of a lemma are abstract
in that they do not make any assumptions about the proof of the lemma. This
agrees with the mathematical use of lemmas.
There is also an engineering reason for representing lemmas as opaque names
in Coq. If lemmas were transparent names, they would be subject to unfolding
and their (possibly complex) proofs would unnecessarily participate in conver-
sion checking and type checking.
A strong lemma is a lemma whose type is not a proposition. Strong lemmas
are a speciality of constructive type theory that don’t seem to have a counterpart
in Mathematics.
6.5 Decidable Predicates
Every function deﬁnable in Coq is computable. Because of opaque deﬁnitions,
Coq’s interpreter may fail to fully evaluate a function application. So the above
statement is made with respect to an idealized interpreter treating all plain dec-
larations as transparent.
Functions are described with terms in Coq.
When an idealized interpreter
evaluates a term describing a function, it will always end up with a term having
one of the following forms:
•
A lambda abstraction.
•
A recursive abstraction.
•
A constructor.
•
A constructor application ct1 . . . tn where c is a constructor and t1, . . . , tn are
n ≥1 terms. Examples of functions obtained as constructor applications are
cons 3 and prod nat.
We call a predicate p : X →Prop decidable if the there is some function that
yields for every x : X a decision of p x.
Deﬁnition decidable (X : Type) (p : X →Prop) : Type := ∀x, dec (p x).
If p and some function f : decidable p are deﬁnable in Coq, then f is a decision
procedure for p and p is computationally decidable.
Coq can deﬁne undecidable predicates. An example of an undecidable pred-
icate is λX : Prop. X ∨¬X. The undecidability of this predicate follows from the
fact that XM is independent in Coq.2
2 Note that by undecidable we mean not decidable in Coq. Predicates that are undecidable in Coq
may be computationally decidable. On the other hand, predicates that are decidable in Coq are
2014-7-16
95

6 Sum and Sigma Types
Goal decidable (fun X : Prop ⇒X ∨¬X) →XM.
Proof. intros A X. destruct (A X) as [B|B] ; τto. Qed.
The notion of decidability extends to predicates with more than one argu-
ment. As is, Coq doesn’t give us the possibility to deﬁne decidability of predi-
cates in one go, we have to give the deﬁnition for each number n ≥1 of argu-
ments. If, more generally, Coq would allow us to deﬁne decidability for n ≥0
arguments, decidability of propositions would fall out for n = 0.
Exercise 6.5.1 Every predicate equivalent to a boolean test is decidable. Prove
the following goal to show this fact.
Goal ∀(X : Type) (p : X →Prop) (f : X →bool), (∀x, p x ↔f x = true) →decidable p.
6.6 Sigma Types
Sigma types are existential quantiﬁcations expressed as proper types. The elim
restriction does not apply to sigma types.
Given a type X and a predicate
p : X →Prop, the elements of the sigma type { x : X | p x } can be seen as pairs
consisting of a value x : X and a proof of p x. Coq deﬁnes sigma types as follows.
Inductive sig (X : Type) (p : X →Prop) : Type :=
exist : ∀x : X, p x →sig p.
Notation "{ x |
p }" := (sig (fun x ⇒p)).
Notation "{ x : X | p }" := (sig (fun x : X ⇒p)).
Consider the type ∀x : nat, { y | y = 2 ∗x }. The elements of this types are func-
tions that take a number x and return a pair consisting of the number 2x and a
proof of the proposition y = 2 ∗x. Here is a construction of such a function.
Deﬁnition double (x : nat) : { y | y = 2*x}.
∃(2*x). reﬂexivity.
Deﬁned.
Compute let (y,_) := double 4 in y.
% 8 : nat
Note the use of the tactic exists to construct a member of a sigma type. We will
refer to functions that yield an element of a sum or sigma type as certifying
functions. A certifying function combines a function and a correctness proof
into a single object. The types of certifying functions can be seen as speciﬁca-
tions. For instance, while the type nat →nat gives us little information about its
inhabitants, the type ∀x : nat, { y | y = 2x } gives us much more information.
We deﬁne a certifying function that divides its argument by 2.
always computationally decidable.
96
2014-7-16

6.6 Sigma Types
Deﬁnition div2_cert (n : nat) : {k | n = 2*k} + {k | n = 2*k + 1}.
induction n.
−left. ∃0. reﬂexivity.
−destruct IHn as [[k A]|[k A]].
+ right. ∃k. omega.
+ left. ∃(S k). omega.
Deﬁned.
The result type of div2_cert is obtained with yet another kind of sum type
(needed since both constituents are proper types).
Inductive sum (X Y : Type) :=
| inl : X →sum X Y
| inr : Y →sum X Y.
Notation "x + y" := (sum x y) : type_scope.
Note that the deﬁnition of the “+” notation for sum is restricted to types. This
way the string 2 + 4 will still elaborate to the term plus 2 4.
Based on the certifying division function div2_cert we deﬁne ordinary modulo
and division functions and prove a correctness lemma.
Deﬁnition mod2 x := if div2_cert x then 0 else 1.
Deﬁnition div2 x := match div2_cert x with
| inl (exist k _) ⇒k
| inr (exist k _) ⇒k
end.
Goal ∀x, x = 2 * div2 x + mod2 x.
Proof.
intros x. unfold div2, mod2.
destruct (div2_cert x) as [[k A]|[k A]] ; omega.
Qed.
Exercise 6.6.1 Prove ∀x. mod2 x ≤1.
Exercise 6.6.2 Prove the following fact about Skolem functions and sigma types.
Lemma Sigma_Skolem (X Y : Type) (p : X →Y →Prop) :
(∀x, {y | p x y}) →{ f | ∀x, p x (f x) }.
Exercise 6.6.3 Establish the following goal and explain why the opposite direc-
tion from an existential quantiﬁcation to a sigma type cannot be established.
Goal ∀X (p : X →Prop), {x | p x} →∃x, p x.
Exercise 6.6.4 Prove ∀X : Type ∀p : X→Prop. (∃x. p x) ↔inhabited { x | p x }.
2014-7-16
97

6 Sum and Sigma Types
Exercise 6.6.5 There is a function that for every decidable predicate yields an
equivalent boolean test. Prove the following goal to establish this fact.
Goal ∀(X : Type) (p : X →Prop), decidable p →{f : X →bool | ∀x, p x ↔f x = true}.
Exercise 6.6.6 Write a certifying function that divides its argument by 3.
Deﬁnition div3_cert (n : nat) : {k | n = 3*k} + {k | n = 3*k + 1} + {k | n = 3*k + 2}.
6.7 Strong Truth Value Semantics
There is a canonical injective embedding of bool into Prop :
Deﬁnition b2P (x : bool) : Prop := if x then ⊤else ⊥.
Proving the injectivity of b2P is straightforward. If we assume TVS, we can also
prove that b2P is surjective. In Mathematics, an injective and surjective function
f : X →Y always comes with an inverse function g such that g(f x) = x and
f (gy) = y for all x : X and y : Y. So it is natural to ask whether under TVS we
can deﬁne the inverse of b2p. The answer is no.
It is, however, consistent to assume strong truth value semantics.
Deﬁnition STVS : Type := ∀X : Prop, {X=⊤} + {X=⊥}.
Assuming STVS means assuming a function that for every proposition X yields
a decision of type {X = True} + {X = False}. Clearly, STVS implies TVS.
Goal STVS →TVS.
Proof. intros stvs X. destruct (stvs X) ; subst X ; auto. Qed.
If we assume STVS, we can construct an inverse function for b2p.
Section STVS.
Variable stvs : STVS.
Deﬁnition P2b (X : Prop) : bool := if stvs X then true else false.
Lemma P2b⊤: P2b ⊤= true.
Proof.
unfold P2b. destruct (stvs ⊤) as [A|A].
+ reﬂexivity.
+ exfalso. rewrite ←A. exact I.
Qed.
Lemma P2b⊥: P2b ⊥= false.
Proof.
unfold P2b. destruct (stvs ⊥) as [A|A].
+ exfalso. rewrite A. exact I.
+ reﬂexivity.
Qed.
98
2014-7-16

6.7 Strong Truth Value Semantics
Goal ∀x : bool, P2b (b2P x) = x.
Proof. intros [|] ; simpl. exact P2b⊤. exact P2b⊥. Qed.
Goal ∀X : Prop, b2P (P2b X) = X.
Proof.
intros X. destruct (stvs X) ; subst X.
−rewrite P2b⊤. reﬂexivity.
−rewrite P2b⊥. reﬂexivity.
Qed.
End STVS.
The names deﬁned in a section remain deﬁned after a section is closed. Their
types are modiﬁed such that the variables of the section used in the deﬁnitions
are taken as arguments. For instance:
Print P2b.
>
fun (stvs : STVS) (X : Prop) ⇒if stvs X then true else false
>
: STVS →Prop →bool
Exercise 6.7.1 Prove that b2P is injective.
Exercise 6.7.2 Prove that TVS implies that b2P is surjective.
Exercise 6.7.3 Prove that P2b is injective.
Goal ∀A : STVS, ∀X Y : Prop, P2b A X = P2b A Y →X = Y.
Exercise 6.7.4 Show that STVS implies that every proposition is decidable.
Goal STVS →∀X : Prop, dec X.
Exercise 6.7.5 Show that STVS implies that every predicate is decidable.
Goal STVS →∀(X : Type) (p : X →Prop), decidable p.
Coq Summary
New Tactics
constructor, decide equality.
New Inductive Types from the Standard Library
sumbool, sumor, sum, sig, inhabited.
Applying Tactics to Assumptions
To apply a tactic to an assumption A, end the tactic command with “in A”. See
the deﬁnition of le_dec in Section 6.3 for an example.
2014-7-16
99

6 Sum and Sigma Types
100
2014-7-16

7 Inductive Predicates
An inductive deﬁnition introduces a type constructor together with a family of
value constructors. If the type constructor yields a proposition, we speak of an
inductive predicate and of proof constructors. We already know Coq’s inductive
predicates for conjunctions (and), disjunctions (or), and existential quantiﬁca-
tions (ex) (see Chapter 2). Another inductive predicate we have introduced is
inhabited.
In this chapter we will take a closer look at inductive predicates. Coq’s facility
for inductive deﬁnitions is extremely powerful and supports many advanced ap-
plications. The idea of inductive deﬁnitions originated with Peano’s axioms (i.e.,
the inductive deﬁnition of nat with O and S) and developed further with proof
systems for logical systems.
When we deﬁne an inductive predicate, we deﬁne a family of inductive propo-
sitions by specifying the syntax and the proof rules for the propositions. The
inductive predicates and, or and ex give us a ﬁrst idea of the ﬂexibility of this
approach. It turns out that we can go much further. Every recursively enumer-
able predicate can be deﬁned as an inductive predicate in Coq. This is in contrast
to computable functions, which are not necessarily deﬁnable in Coq.
7.1 Nonparametric Arguments and Linearization
We start our explanation of inductive predicates with an extreme case: A deﬁni-
tion of a predicate on numbers that holds exactly for the number 0.
Inductive zero : nat →Prop :=
| zeroI : zero 0.
The deﬁnition provides exactly one proof zeroI, which proves the proposition
zero 0. The propositions zero 1, zero 2, zero 3, and so forth are all unprovable.
We characterize the inductive predicate zero as follows.
Lemma zero_iﬀx :
zero x ↔x = 0.
101

7 Inductive Predicates
Proof.
split ; intros A.
−destruct A. reﬂexivity.
−subst x. constructor.
Qed.
The interesting step of the proof is destruct A, which does a case analysis on the
proof of zero x. Since there is only a single proof constructor zeroI : zero 0, the
case analysis yields a single subgoal where the variable x is instantiated to 0.
The argument of the inductive predicate zero is called nonparametric since
it is instantiated by the proof constructor zeroI : zero 0. This is the ﬁrst time we
see an inductive predicate with a nonparametric argument. Check the deﬁnitions
of the inductive predicates and, or, ex, and inhabited to see that all arguments
of these predicates are parametric.
There is an important technicality one has to know about nonparametric ar-
guments: When the tactics destruct and induction are applied to an inductive
assumption A : ct1 . . . tn, the terms ti for the nonparametric arguments of c
must be variables not appearing in the other terms. We say that inductive as-
sumptions must be linear when they are used with destruct and induction. Coq
oﬀers the tactic remember to linearize inductive assumptions.
Goal ¬ zero 2.
Proof. intros A. remember 2 as x. destruct A. discriminate Heqx. Qed.
Exercise 7.1.1 Make sure you can prove the propositions zero 0, ¬zero 7, and
∀x. ¬zero (S x) without using lemmas.
Exercise 7.1.2 Prove that the predicate zero is decidable.
Exercise 7.1.3 Prove the following lemma.
Lemma remember (X : Type) (p : X →Type) (x : X) :
(∀y, y = x →p y) →p x.
Try to understand why the lemma justiﬁes the tactic remember. Use the lemma
and the tactic pattern to prove the proposition ∀x. ¬zero (S x).
Exercise 7.1.4 Prove the following impredicative characterization of zero.
Goal ∀x, zero x ↔∀p : nat →Prop, p 0 →p x.
Exercise 7.1.5 Deﬁne a boolean test zerob : nat →bool and prove the correct-
ness condition ∀x. zero x ↔zerob x = true.
102
2014-7-16

7.2 Even
Exercise 7.1.6 Deﬁne an inductive predicate leo : nat →Prop with two proof
constructors leo0 : leo 0 and leo1 : leo 1.
a) Prove ∀x, leo x ↔x ≤1.
b) Characterize leo impredicatively and prove the correctness.
c) Characterize leo with a boolean test leob : nat →bool and prove the correct-
ness of the characterization.
7.2 Even
Our next example is an inductive predicate even that holds exactly for the
even numbers. This time we use two proof rules, one for even 0 and one for
even (S (S x)).
even 0
even x
even (S(S x))
The two proof rules can be expressed with two proof constructors:
evenO : even 0
evenS : ∀x : nat. even x →even (S (S x))
From the types of the proof constructors it is clear that the argument of even is
nonparametric. We now introduce the predicate even and the proof constructors
evenO and evenS with a single inductive deﬁnition.
Inductive even : nat →Prop :=
| evenO : even 0
| evenS x : even x →even (S (S x)).
The type of the constructor evenS is speciﬁed with a notational convenience we
have seen before in the statement of lemmas. The convenience makes it possible
to specify argument variables of a constructor without types, leaving it to Coq to
infer the types.
We prove a lemma characterizing even non-inductively.
Lemma even_iﬀx :
even x ↔∃k, x = 2*k.
2014-7-16
103

7 Inductive Predicates
Proof.
split ; intros A.
−induction A.
+ ∃0. reﬂexivity.
+ destruct IHA as [k IHA]. subst x. ∃(S k). simpl. omega.
−destruct A as [k A]. subst x. induction k ; simpl.
+ constructor.
+ replace (S(k+S(k+0))) with (S (S (2*k))) by omega.
constructor. exact IHk.
Qed.
Both directions of the proof deserve careful study. The direction from left to
right is by induction on the proof A : even x. The induction does a case analysis
for the two proof constructors of even. In each case the nonparametric argu-
ment x is instantiated as speciﬁed by the type constructor. For evenS we get
x = S(S x′) and the inductive hypothesis IHA : ∃k. x′ = 2 ∗k.1
The direction from right to left ﬁrst eliminates the existential quantiﬁcation
for k and then proves the so obtained claim by induction on k : nat. The induc-
tion step uses the tactic replace to rewrite with the equation S(k + S(k + 0)) =
S(S(2∗k)), which is established by the tactic omega. This is the ﬁrst time we use
the tactic replace. If the annotation by omega is omitted, replace will introduce
an extra subgoal to establish the equation.
The next two lemmas prove simple facts about even using case analysis on
proofs of propositions obtained with even. In each case the linearization of the
inductive assumption with the tactic remember is essential.
Goal ¬ even 3.
Proof.
intros A. remember 3 as x. destruct A.
−discriminate Heqx.
−destruct A ; discriminate Heqx.
Qed.
Lemma even_descent x :
even (S (S x)) →even x.
Proof.
intros A. remember (S (S x)) as y.
destruct A as [|y A].
−discriminate Heqy.
−congruence.
Qed.
1 The proof script reuses the variable x for x′. You can get the variable x′ by annotating the
induction command with as [|x′ A′].
104
2014-7-16

7.2 Even
Exercise 7.2.1 Prove even 6 and ¬even 5 without using lemmas.
Exercise 7.2.2 Prove the following goals without using lemmas.
(a)
Goal ∀x y, even x →even y →even (x+y).
(b)
Goal ∀x y, even x →even (x+y) →even y.
(c)
Goal ∀x, even x →even (S x) →⊥.
Exercise 7.2.3 Prove the so-called inversion lemma for even.
Lemma even_inv x : even x →x = 0 ∨∃x’, x = S (S x’) ∧even x’.
Exercise 7.2.4 Prove the following impredicative characterization of evenness.
Goal ∀x, even x ↔∀p : nat →Prop, p 0 →(∀y, p y →p (S (S y))) →p x.
Exercise 7.2.5 Some proofs need ideas. Try to prove ∀x, ¬even x →even (S x).
As is, the induction on x : nat will not go through. The problem is that the in-
duction on x : nat takes away a single S while the constructor evenS takes away
two S′s. The standard cure consists in generalizing the claim so that the induc-
tive hypothesis becomes strong enough. Convince yourself that the proof of the
following lemma generalizing the claim is doable.
Lemma even_succ x : (¬ even x →even (S x)) ∧(¬ even (S x) →even x).
Hint: The apply tactic can be used with a proof of a conjunction of implications.
In this case apply attempts to apply one of the implications.
Exercise 7.2.6 Prove ∀x, even x ↔¬even (S x). Hint: Use the lemma even_succ
from Exercise 7.2.5.
Exercise 7.2.7 Prove that the predicate even is decidable. Hint: Use the lemma
even_succ from Exercise 7.2.5.
Exercise 7.2.8 Here is an inductive deﬁnition of an evenness predicate with a
parametric argument.
Inductive even’ (x : nat) : Prop :=
| even’O : x=0 →even’ x
| even’S y : even’ y →x = S (S y) →even’ x.
a) Prove ¬even′ 3.
b) Prove ∀x. even′ x ↔even x.
2014-7-16
105

7 Inductive Predicates
Exercise 7.2.9 Here is a boolean test for evenness.
Fixpoint evenb (x : nat) : bool :=
match x with
| 0 ⇒true
| S (S x’) ⇒evenb x’
| _ ⇒false
end.
Try to prove ∀x. even x ↔evenb x = true. The direction from left to right is a
straightforward induction on a proof of even x. The direction from right to left is
problematic since an induction on x : nat takes away one S while the constructor
evenS takes away two S’s. Proving the following more general claim solves the
problem.
Lemma evenb_even x : (evenb x = true →even x) ∧(evenb (S x) = true →even (S x)).
7.3 Less or Equal
Coq deﬁnes the order predicate “≤” for natural numbers inductively based on
the following proof rules.2
x ≤x
x ≤y
x ≤S y
The exact deﬁnition is
Inductive le (x : nat) : nat →Prop :=
| le_n : le x x
| le_S y : le x y →le x (S y).
Notation "x ≤y" := (le x y) (at level 70).
Note that the ﬁrst argument of the inductive predicate le is parametric and that
the second argument is nonparametric. We will always write inductive deﬁnitions
such that all parametric arguments appear as parameters in the head of the
inductive deﬁnition. Note that le is the ﬁrst inductive predicate we see having
both parametric and nonparametric arguments.
To get familiar with le, we prove a lemma characterizing le non-inductively.
Lemma le_iﬀx y :
x ≤y ↔∃k, k + x = y.
2 Use the commands Locate and Print to see Coq’s deﬁnition of “≤” for nat.
106
2014-7-16

7.3 Less or Equal
Proof.
split.
−intros A. induction A as [|y A].
+ ∃0. reﬂexivity.
+ destruct IHA as [k B]. ∃(S k). simpl. congruence.
−intros [k A]. subst y. induction k ; simpl.
+ constructor.
+ constructor. exact IHk.
Qed.
The proof deserves careful study. The direction from left to right is by induction
on a proof of x ≤y. The other direction is by induction on k.
Next we write an informative test for le. This takes some preparation. We
leave the proofs of the ﬁrst three lemmas as exercises.
Lemma le_O x : 0 ≤x.
Lemma le_SS x y : x ≤y →S x ≤S y.
Lemma le_Strans x y : S x ≤y →x ≤y.
Lemma le_zero x :
x ≤0 →x = 0.
Proof.
intros A. remember 0 as y. destruct A as [|y A].
−reﬂexivity.
−discriminate Heqy.
Qed.
Lemma le_SS’ x y :
S x ≤S y →x ≤y.
Proof.
intros A. remember (S y) as y’. induction A as [|y’ A].
−injection Heqy’. intros A. subst y. constructor.
−injection Heqy’. intros B. subst y’. apply le_Strans, A.
Qed.
Deﬁnition le_dec x y : dec (x ≤y).
revert y. induction x ; intros y.
−left. apply le_O.
−destruct y.
+ right. intros A. apply le_zero in A. discriminate A.
+ destruct (IHx y) as [A|A].
* left . apply le_SS, A.
* right. intros B. apply A, le_SS’, B.
Deﬁned.
2014-7-16
107

7 Inductive Predicates
Exercise 7.3.1 Prove the lemmas le_O, le_SS, and le_Strans without using omega.
Hints: Lemma le_O follows by induction on x.
Lemmas le_SS and le_Strans
follow by induction for le.
Exercise 7.3.2 Prove the inversion lemma for le.
Lemma le_inv x y : x ≤y →x = y ∨∃y’, y = S y’ ∧x ≤y’.
Exercise 7.3.3 Prove that le is transitive. Do not use omega.
Lemma le_trans x y z : x ≤y →y ≤z →x ≤z.
Hint: Do the proof by induction for y ≤z.
Exercise 7.3.4 Prove the following goal not using omega.
Goal ∀x y, S x ≤y →x ≠y.
Hint: Proceed by induction on y and use the lemmas le_zero and le_SS′.
Exercise 7.3.5 Prove that le is anti-symmetric. Do not use omega.
Goal ∀x y, x ≤y →y ≤x →x=y.
Hint: Proceed by induction on x and use le_zero, le_Strans, and le_SS′.
Exercise 7.3.6 Prove that le and the boolean test leb from the standard library
agree. Do not use omega.
Goal ∀x y, x ≤y ↔leb x y = true.
Hint: For the direction from left to right you will need two straightforward lem-
mas for leb. For the other directions use the lemmas le_O and le_SS.
7.4 Equality
Coq deﬁnes equality inductively.
Inductive eq (X : Type) (x : X) : X →Prop :=
| eq_reﬂ: eq x x.
Notation "x = y" := (eq x y) (at level 70).
Note that the ﬁrst two arguments of the inductive predicate eq are parametric
and that the third argument is nonparametric. It is easy to establish the Leibniz
characterization of equality.
Lemma Leibniz (X : Type) (x y : X) :
x = y ↔∀p : X →Prop, p x →p y.
108
2014-7-16

7.5 Exceptions to the Elim Restriction
Proof.
split ; intros A.
−destruct A. auto.
−apply (A (fun z ⇒x = z)). constructor.
Qed.
7.5 Exceptions to the Elim Restriction
The exceptions to the elim restriction can be stated as follows: If an inductive
predicate has at most one proof constructor and the nonparametric arguments
of the proof constructor are all proofs, then the elim restriction does not apply
to matches for this predicate.
An interesting exception to the elim restriction is the inductive predicate eq
whose single proof constructor
eq_reﬂ: ∀X : Type ∀x : X. eq x x
has only parametric arguments (i.e., arguments ﬁxed in the head of the inductive
deﬁnition of eq). Thus the elim restriction does not apply to matches on equality
proofs. This provides for the deﬁnition of the following casting function.
Deﬁnition cast (X : Type) (x y : X) (f : X →Type) : x = y →f x →f y.
intros A B. destruct A. exact B.
Deﬁned.
The function cast gives us a function that given a proof of x = y converts from
type f x to type f y. Here is an example for the use of cast.
Deﬁnition ﬁn (n : nat) : Type := nat_iter n option ⊥.
Goal ∀n, ﬁn n →ﬁn (n+0).
Proof. intros n. apply cast. omega. Qed.
Note that the cast is needed since the terms ﬁn n and ﬁn (n + 0) are not convert-
ible.
Exercise 7.5.1 Prove the following goal. Explain why the elim restriction does
not apply to conjunctions.
Goal ∀X Y : Prop, X ∧Y →prod X Y.
Exercise 7.5.2 Explain why the elim restriction applies to matches for the induc-
tive predicate inhabited.
2014-7-16
109

7 Inductive Predicates
Exercise 7.5.3 Complete the following deﬁnition. Explain why your deﬁnition
exploits an exception to the elim restriction.
Deﬁnition exfalso : ⊥→∀X : Type, X := · · ·
Exercise 7.5.4 Prove the following goal.
Goal ∀(X : Type) (x y : X), (∀p : X →Prop, p x →p y) →∀p : X →Type, p x →p y.
Note that goal is formulated without making use of inductive types. Yet it can
only be proven using inductive types.
7.6 Safe and Nonuniform Parameters
Our ﬁnal example is an inductive predicate safe : (nat →Prop) →nat →Prop
such that safe p n holds if and only if p holds for some k ≥n. We base the
inductive deﬁnition on the following rules.
p n
safe p n
safe p (S n)
safe p n
Deﬁning safe in Coq is straightforward.
Inductive safe (p : nat →Prop) (n : nat) : Prop :=
| safeB : p n →safe p n
| safeS : safe p (S n) →safe p n.
One reason for considering safe is that it has both a uniform and a nonuniform
parameter.3 The parameter p is uniform since it is not instantiated in the types
of the proof constructors safeB and safeS. The parameter n is nonuniform since
it is instantiated to S n in the type of the constructor safeS. The argument n does
not qualify as a nonparametric argument of safe since the instantiation appears
in argument position rather than in result position.
This is the ﬁrst time we
encounter a type constructor with a nonuniform parameter.
When we use the tactic induction on a proof of a proposition obtained with
an inductive predicate, both the nonuniform parametric arguments and the non-
parametric arguments of the proposition must be linearized. If we use the tactic
destruct, it suﬃces if the nonparametric arguments are linearized. For instance,
if we have an assumption A : safe p 0, destruct can be applied to A but induction
must not be applied to A.
We prove that safe p is downward closed.
Lemma safe_dclosed k n p :
k ≤n →safe p n →safe p k.
3 A parameter is a parametric argument.
110
2014-7-16

7.6 Safe and Nonuniform Parameters
Proof.
intros A B. induction A as [|n A].
−exact B.
−apply IHA. right. exact B.
Qed.
The proof is by induction on a proof of k ≤n. Note the use of the tactic right to
apply the second constructor of safe. The tactics left and right can be used with
every type constructor that has two value constructors.
We prove that safe satisﬁes its speciﬁcation.
Lemma safe_iﬀp n :
safe p n ↔∃k, n ≤k ∧p k.
Proof.
split ; intros A.
−induction A as [n B|n A].
+ ∃n. auto.
+ destruct IHA as [k [B C]].
∃k. split. omega. exact C.
−destruct A as [k [A B]].
apply (safe_dclosed A). left. exact B.
Qed.
The direction from left to right is by induction on a proof of safe p n. From the
destructuring pattern for the induction we learn that a name for the nonuniform
parameter n must be given for both subgoals. This must be done for nonuniform
parameters in general.
The direction from right to left follows with the lemma safe_dclosed. Using
this lemma is essential since a direct proof of the more speciﬁc claim we have at
this point seems impossible.
The predicate safe is diﬀerent from the other inductive predicates we saw in
this chapter in that it is impossible to express it with a boolean test. This is the
case even if we assume that the argument p is a decidable predicate.4
Exercise 7.6.1 We deﬁne a predicate least such that least p n k holds if and only
if k is the least number such that n ≤k and p k holds.
Inductive least (p : nat →Prop) (n : nat) : nat →Prop :=
| leastB : p n →least p n n
| leastS k : ¬ p n →least p (S n) k →least p n k.
Note that the ﬁrst argument of least is a uniform parameter, the second ar-
gument is a nonuniform parameter, and the third argument is nonparametric.
Prove the following correctness lemmas for least.
4 Think of pn as the statement saying that a particular Turing machine halts on a particular
input in at most n steps.
2014-7-16
111

7 Inductive Predicates
Lemma least_correct1 p n k : least p n k →p k.
Lemma least_correct2 p n k : least p n k →n ≤k.
Lemma least_correct3 p n k : least p n k →∀k’, n ≤k’ →p k’ →k ≤k’.
Lemma least_correct4 p n k : (∀x, dec (p x)) →p (n+k) →∃k’, least p n k’.
Lemma least_correct p n k (p_dec : ∀x, dec (p x)) :
least p n k ↔p k ∧n ≤k ∧∀k’, n ≤k’ →p k’ →k ≤k’.
Hint: Use le_lt_eq_dec from the standard library for the proof of least_correct3.
7.7 Constructive Choice for Nat
We will now construct a function
cc_nat : ∀p : nat →Prop, (∀x, dec (p x)) →(∃x, p x) →{x | p x}
we call constructive choice for nat. For a decidable predicate p on numbers con-
structive choice yields a function that for every proof of an existential quantiﬁca-
tion ∃x. px yields a value of the sigma type { x | px }. Thus cc_nat bypasses the
elim restriction for existential quantiﬁcations of decidable predicates on num-
bers. We will obtain this remarkable result with a new proof technique based on
the inductive predicate safe from the last section.
For convenience, we declare a decidable predicate p in a section.
Section First.
Variable p : nat →Prop.
Variable p_dec : ∀n, dec (p n).
We now write a function ﬁrst that from a proof of safe p n obtains a value of
{ k | pk }. The function ﬁrst is the cornerstone of the construction of cc_nat.
Clearly, ﬁrst overcomes the elim restriction. We deﬁne ﬁrst by recursion on the
given proof of safe p n.
Fixpoint ﬁrst (n : nat) (A : safe p n) : {k | p k} :=
match p_dec n with
| left B ⇒exist p n B
| right B ⇒ﬁrst match A with
| safeB C ⇒match B C with end
| safeS A’ ⇒A’
end
end.
Given that ﬁrst computes by recursion on A, one would expect that ﬁrst ﬁrst
matches on A. However, this is impossible because of the elim restriction. So
we ﬁrst match on p_dec n. If we obtain a proof of p n, we are done. Otherwise,
we recurse on a proof of safe p (S n) we obtain by matching on the proof A of
112
2014-7-16

7.7 Constructive Choice for Nat
safe p n. This time the elim restriction does not apply since we are constructing
a proof. We obtain two cases. The case for safeS is straightforward since we get
a proof of safe p (S n) by taking oﬀthe constructor. The case for safeB yields
a proof C of p n. Since we have a proof B of ¬pn, we can match on the proof
B C of False. Now we are done since each rule of the match returns a proof of
safe p (S n) that is obtained by taking oﬀa constructor of the proof A (vacuous
reasoning).
The recursion scheme underlying ﬁrst is nonstandard. The standard recur-
sion scheme would ﬁrst match on the proof and than recurse. The recursion
scheme we see with ﬁrst ﬁrst recurses and only then matches on the proof. This
way the elim restriction can be bypassed.
We speak of an eager proof term
recursion.
It is now straightforward to construct the certifying function cc_nat. We ob-
tain the result by applying ﬁrst to a proof of safe p 0. The proof of safe p 0 we
obtain with the lemma safe_dclosed from a proof of safe p n for some n. The n
and the proof of safe p n we obtain from the given proof of ∃x. px.
Lemma cc_nat : (∃x, p x) →{x | p x}.
Proof.
intros A. apply ﬁrst with (n:=0).
destruct A as [n A].
apply safe_dclosed with (n:=n). omega. left. exact A.
Qed.
Note the “with” annotations used with the tactic apply. They provide a conve-
nient means for specifying implicit arguments of the function being applied.
There is a straightforward algorithmic idea underlying cc_nat we may call
linear search: To ﬁnd the least k ≥n such that pn, increment n until pn holds.
What is interesting about linear search from our perspective is that linear search
is not structurally recursive and that it may not always terminate. We can see
ﬁrst as a logical reformulation of linear search that is structurally recursive.
Exercise 7.7.1 Write a constructive choice function for bool.
Deﬁnition cc_bool (p : bool →Prop) (p_dec : ∀x, dec (p x)) : (∃x, p x) →{x | p x}.
Exercise 7.7.2 Complete the deﬁnitions of the following recursive and certify-
ing functions with scripts. Assume a section declaring a decidable predicate p.
Follow the eager proof term recursion scheme from ﬁrst.
Fixpoint ﬁrst1 (n : nat) (A : safe p n) : {k | p k ∧k ≥n}.
Fixpoint ﬁrst2 (n : nat) (A : safe p n) : {k | p k ∧k ≥n ∧∀k’, n ≤k’ →p k’ →k ≤k’}.
2014-7-16
113

7 Inductive Predicates
Hint: First redeﬁne ﬁrst with a script. Check the partial proof terms you obtain
with the command Show Proof .
Then reﬁne the script for ﬁrst to obtain the
script for ﬁrst1.
Exercise 7.7.3 Write constructive choice functions for the ﬁnite types ﬁn n.
Deﬁnition cc_ﬁn (n : nat) (p : ﬁn n →Prop) (p_dec : ∀x, dec (p x))
:
(∃x, p x) →{x | p x}.
7.8 Technical Summary
An inductive deﬁnition introduces a family of typed names called constructors.
One of the constructors yields types and is called type constructor.
The re-
maining constructors are called value constructors and yield the elements of the
types obtainable with the type constructor. An inductive value is a value ob-
tained with a constructor. Thus an inductive predicate is a predicate obtained
with a constructor, a proof constructor is a value constructor yielding a proof,
and inductive proposition is a proposition obtained with a type constructor.
An inductive deﬁnition comes with a list of named parameters speciﬁed in
the head of the deﬁnition. The parameters appear as leading arguments of every
constructor introduced by the inductive deﬁnition. We speak of the parametric
arguments of a constructor. The constructors may have additional arguments,
which we call nonparametric arguments. There is the constraint that the result
type of a value constructor must not instantiate parametric arguments of the
type constructor. The parametric arguments of a value constructor do not ap-
pear in matches and the type speciﬁcation of the constructor in the introducing
inductive deﬁnition.
As example we consider the following inductive deﬁnition.
Inductive least (p : nat →Prop) (n : nat) : nat →Prop :=
| leastB : p n →least p n n
| leastS k : ¬ p n →least p (S n) k →least p n k.
The deﬁnition introduces the constructors
least : (nat →Prop) →nat →nat →Prop
leastB : ∀p : nat →Prop ∀n : nat. p n →least p n n
leastS : ∀p : nat →Prop ∀n : nat ∀k : nat. ¬p n →least p (S n) k →least p n k
The leading two arguments of each constructor are parametric, the remaining ar-
guments are nonparametric. The type constructor least and the value construc-
tor leastB have one nonparametric argument each, and the value constructor
leastS has three nonparametric arguments.
114
2014-7-16

7.9 Induction Lemmas
Our inductive deﬁnitions will always be such that for every nonparametric
argument of the type constructor there will be at least one value constructor that
instantiates this argument in its result type. Coq does not enforce this condition.
The elim restriction applies to matches on proofs of inductive propositions
where the underlying inductive deﬁnition either has more than one proof con-
structor or has a single proof constructor taking a nonparametric argument spec-
iﬁed with a proper type. For instance, the elim restriction applies to matches on
proofs of disjunctions and existential quantiﬁcations, but it does not apply to
matches on proofs of equations and conjunctions.
Coq distinguishes between uniform and nonuniform parameters of inductive
deﬁnitions. A parameter of an inductive deﬁnition is nonuniform if it is instan-
tiated in argument position in the type speciﬁcation of a value constructor. For
instance, the inductive deﬁnition least has the uniform parameter p and the
nonuniform parameter n. The nonuniformity of n is due to the type of the third
nonparametric argument of the value constructor leastS.
When we apply the tactic destruct to a proof A of an inductive proposition
Ct1 . . . tn, all terms ti giving nonparametric arguments must be variables that do
not appear in the other terms. Similarly, when we apply the tactic induction to a
proof A of an inductive proposition Ct1 . . . tn, all terms ti giving nonparametric
or nonuniform parametric arguments must be variables that do not appear in
the other terms. We say that inductive propositions are linear if they satisfy this
condition. Inductive propositions can be linearized with the tactic remember.5
7.9 Induction Lemmas
When we apply the tactic induction to an assumed value of an inductive type,
the induction lemma for the underlying type constructor is applied. To have an
example, we consider the inductive deﬁnition of even.
Inductive even : nat →Prop :=
| evenO : even 0
| evenS x : even x →even (S (S x)).
5 Unfortunately, the tactics destruct and induction do not give warnings when they are applied
to proofs of nonlinear inductive propositions.
Instead, they linearize the proposition auto-
matically and forget the equations relating the fresh variables with the moved away argument
terms. This often leads to unprovable subgoals.
2014-7-16
115

7 Inductive Predicates
The type of the induction lemma even_ind Coq derives for even is as follows.
∀p : nat →Prop.
p 0 →
(∀x : nat. even x →p x →p(S(S x))) →
∀x : nat. even x →p x
Note that each constructor contributes a premise of the implication. When we
apply the tactic induction to an assumption A : even x, the goal is rearranged by
moving all assumptions depending on the variable x to the claim. Thus these
assumptions become part of the induction predicate p and hence appear in the
inductive hypothesis px of the premise for the constructor evenS.
Our second example is the inductive deﬁnition of le.
Inductive le (x : nat) : nat →Prop :=
| le_n : le x x
| le_S y : le x y →le x (S y).
The induction lemma le_ind Coq generates for le quantiﬁes the uniform param-
eter x at the outside.
∀x : nat ∀p : nat →Prop.
p x →
(∀y : nat. le x y →p y →p(S y)) →
∀y : nat. le x y →p y
If you look at the induction lemma Coq generates for least, you will see that
the nonuniform parameter is treated like the nonparametric argument in that it
appears as an argument of the induction predicate p.
When we work with paper and pencil, doing inductive proofs based on induc-
tive deﬁnitions requires considerable training and great care. When we work with
Coq, the tedious details are taken care of automatically and proof correctness is
guaranteed.
Exercise 7.9.1 Complete the following deﬁnitions of the induction lemmas for
even and le.
Deﬁnition even_ind’ (p : nat →Prop) (r1 : p 0) (r2 : ∀x, even x →p x →p (S (S x)))
: ∀x, even x →p x :=
· · · .
Deﬁnition le_ind’ (x : nat) (p : nat →Prop) (r1 : p x) (r2 : ∀y, le x y →p y →p (S y))
: ∀y, le x y →p y :=
· · · .
116
2014-7-16

7.9 Induction Lemmas
Coq Summary
New Tactics
remember, replace.
Automation Tactic inversion
The automation tactic inversion subsumes the capabilities of the tactics destruct,
discriminate, and injection. The use of inversion is convenient if it solves the goal.
Otherwise inversion often creates subgoals with many equational assumptions.
We will use inversion only if it solves the goal. Here are two examples.
Goal ¬ even 1. Proof. intros A. inversion A. Qed.
Goal ¬ 7 ≤0. Proof. intros A. inversion A. Qed.
With Annotations for apply
With annotations used with the tactic apply are a convenient means for specify-
ing implicit arguments of the function being applied. See the deﬁnition of cc_nat
in Section 7.7.
2014-7-16
117

7 Inductive Predicates
118
2014-7-16

8 Lists
In this chapter we study lists in constructive type theory. Lists are a basic data
structure providing for the representation of ﬁnite sequences and ﬁnite sets.
We will consider predicates like list membership, list inclusion, list equivalence,
list disjointness, and duplicate freeness.
We will also consider functions for
concatenation, mapping, product, ﬁltering, element removal, length, cardinality,
and power lists.
Decidability issues play an important role for data structures in general and
lists in particular. For instance, if the base type comes with decidable equality,
membership as well as inclusion, equivalence, and equality of lists are decidable.
Moreover, quantiﬁcation over the elements of a list preserves decidability. Fi-
nally, list functions like cardinality and element removal require a decider for
base type equality.
Lists and decidability play a major role in many formal developments we are
interested in. As is, Coq’s library does not provide adequate support for lists and
decidability. Thus we provide a base library Base.v realizing the infrastructure
for lists and decidability introduced in this chapter. The base library comes with
several automation features including an automatic handling of side conditions
for decidability.
In this chapter we explain the infrastructure provided by the base library from
the user’s point of view. We will not say much about the implementation of the
base library, which uses several advanced features of Coq we have not seen so
far. The interested reader may consult the source code of the base library.
From now on we assume that our Coq developments start with the command
Require Export Base.
The command loads the base library designed for this course. The base library
switches Coq into implicit arguments mode and provides Coq’s basic infrastruc-
ture for numbers and setoid rewriting. It also provides the infrastructure for
lists and decidability presented in this chapter. The base library can be made
availably by placing a compiled version of the ﬁle Base.v in Coq’s load path (use
the command coqc Base.v for compilation).
119

8 Lists
8.1 Constructors and Notations
Lists can be seen as ﬁnite sequences [x1 ; . . . ; xn] of values. Formally, lists are
obtained with two constructors nil and cons.
[]
֏
nil
[x]
֏
cons x nil
[x ; y]
֏
cons x (cons y nil)
[x ; y ; z]
֏
cons x (cons y (cons z nil))
The constructor nil provides the empty list. The constructor cons yields for a
value x and a list [x1 ; . . . ; xn] the list [x ; x1 ; . . . ; xn]. Given a list cons x A, we
call x the head and A the tail of the list. Given a list [x1 ; . . . ; xn], we call n the
length of the list and x1, . . . , xn the elements of the list. An element may appear
more than once in a list. For instance, [2 ; 2 ; 3] is a list of length 3 that has 2
elements.
We are now ready for the formal deﬁnition of lists:
Inductive list (X : Type) : Type :=
| nil : list X
| cons : X →list X →list X.
The deﬁnition provides three constructors:
list : Type →Type
nil : ∀X : Type. list X
cons : ∀X : Type. X →list X →list X
The formal deﬁnition of lists ensures that all elements of a list are taken from
the same type. For every type X we obtain a type list X. The elements of list X
are the lists we can obtain with nil and cons from elements of X. We speak of
lists over X.
We arrange things such that the base type X is an implicit argument of the
constructors nil and cons. While X is implicit for cons by default, this arrange-
ment need to be declared explicitly for nil (since nil has no explicit arguments
determining X). For nil the implicit argument X will be determined from the
surrounding context.
For cons we employ a right associative inﬁx notation:
x :: A := cons x A
We can now write x :: y :: A for cons x (cons y A).
120
2014-7-16

8.2 Recursion and Induction
8.2 Recursion and Induction
Like numbers, lists are a recursive data structure. Thus functions on lists are
typically deﬁned by structural recursion on lists, and lemmas about lists are
often shown by structural induction on lists. Recursion and induction on lists
are quite similar to recursion and induction on numbers.
Length
We deﬁne the length |A| of a list A as follows:
|nil| := 0
|x :: A| := S|A|
Using bracket notation, we have
|[x1 ; . . . ; xn]| = n
In Coq, we realize |A| with a recursive function
length : ∀X : Type, list X →nat
and an accompanying notation.
Concatenation
We deﬁne the concatenation A ++ B of two lists A and B as follows:
nil ++ B := B
x :: A ++ B := x :: (A ++ B)
Using bracket notation, we have
[x1 ; . . . ; xm] ++ [y1 ; . . . ; yn] = [x1 ; . . . ; xm ; y1 ; . . . ; yn]
In Coq, we realize A ++ B with a recursive function
app : ∀X : Type, list X →list X →list X
and an accompanying notation.
Reversal
We deﬁne the reversal of a list as follows:
rev nil := nil
rev (x :: A) := rev A ++[x]
Using bracket notation, we have
rev [x1 ; . . . ; xn] = [xn ; . . . ; x1]
In Coq, we realize rev A with a recursive function
2014-7-16
121

8 Lists
rev : ∀X : Type, list X →list X
Map
We deﬁne the map of a list under a function f as follows:
map f nil := nil
map f (x :: A) := f x :: map f A
Using bracket notation, we have
map f [x1 ; . . . ; xn] = [f x1 ; . . . ; f xn]
In Coq, we realize map f A with a recursive function
map : ∀X Y : Type, (X →Y) →list X →list Y
Product
The product A × B of two lists A and B is a list containing all pairs (a, b) such
that a is an element of A and b is an element of B:
nil × B := nil
(a :: A) × B := map (pair a) B ++(A × B)
For instance, [1 ; 2]×[5 ; 6 ; 7] = [(1, 5) ; (1, 6) ; (1, 7) ; (2, 5) ; (2, 6) ; (2, 7)]. In Coq,
we realize A × B with a recursive function
list_prod : ∀X Y : Type, list X →list Y →list (X * Y)
Structural Induction
We prove a simple fact about length and concatenation of lists using structural
induction on lists.
Lemma 8.2.1 |A ++ B| = |A| + |B|
Proof By induction on A.
A = nil. We have |nil ++ B| = |B| = 0 + |B| = |nil| + |B|.
A = x :: A. We have |(x :: A) ++ B| = |x :: (A ++ B)| = S|A ++ B| =IH S(|A|+|B|) =
S|A| + |B| = |x :: A| + |B|. Note the use of the inductive hypothesis.
■
Use Coq to study every detail of this proof.
Simpliﬁcation Rules and Tactic simpl_list
Figure 8.1 shows simpliﬁcation rules for list operations the base library provides
under the given names. The rules are registered with the tactic simpl_list, which
will rewrite with these rules as long as this is possible. The rules are applied left
to right except for app_assoc, which is applied from right to left.
122
2014-7-16

8.2 Recursion and Induction
A ++ nil = A
app_nil_r
A ++(B ++ C) = (A ++ B) ++ C
app_assoc
rev (A ++ B) = rev B ++ rev A
rev_app_distr
map f (A ++ B) = map f A ++ map f B
map_app
|A ++ B| = |A| + |B|
app_length
|rev A| = |A|
rev_length
|map f A| = |A|
map_length
|A × B| = |A| · |B|
prod_length
rev (rev A) = A
rev_involutive
rev (A ++[x]) = x :: rev A
rev_unit
Figure 8.1: Simpliﬁcation rules registered with simpl_list
Exercise 8.2.2 (Lemma list_cycle) Prove A ≠x :: A.
Exercise 8.2.3 Prove the simpliﬁcation rules in Figure 8.1.
Exercise 8.2.4 If you are familiar with functional programming, you will know
that the function rev deﬁned in the previous section takes quadratic time to
reverse a list. This is due to the fact that each recursion step involves an appli-
cation of the function app. One can write a tail-recursive function that reverses
lists in linear time. The trick is to move the elements of the main list to a second
list passed as an additional argument.
revi nil B := B
revi (x :: A) B := revi A (x :: B)
Prove the following correctness properties of revi in Coq.
a) revi A B = rev A ++ B
b) rev A = revi A nil
Exercise 8.2.5 Deﬁne a tail-recursive function lengthi and prove length A =
lengthi A nil.
2014-7-16
123

8 Lists
x ∈A ++ B ↔x ∈A ∨x ∈B
in_app_iﬀ
x ∈rev A ↔x ∈A
in_rev_iﬀ
x ∈map f A ↔∃y. f y = x ∧y ∈A
in_map_iﬀ
(a, b) ∈A × B ↔a ∈A ∧b ∈B
in_prod_iﬀ
Figure 8.2: Membership equivalences for list operations
8.3 Membership
We deﬁne list membership x ∈A as follows:
(x ∈nil) := ⊥
(x ∈y :: A) := (x = y ∨x ∈A)
Using bracket notation, we have
(x ∈[x1 ; . . . ; xn]) = (x = x1 ∨· · · ∨x = xn ∨⊥)
In Coq, we realize list membership with a recursive predicate
In : ∀X : Type, X →list X →Prop
and an accompanying notation.
List membership is similar to membership in ﬁnite sets. We can see lists as
representations of ﬁnite sets. This representation ist not unique since diﬀerent
lists can represent the same set. For instance, [1 ; 2], [2 ; 1], [1 ; 1 ; 2] and [1 ; 2 ; 2]
are diﬀerent lists all representing the set {1, 2}. In contrast to ﬁnite sets, lists
are ordered structures providing for multiple occurrences of elements.
Figure 8.2 shows membership equivalences for the list operations we deﬁned
in the last section. To the right of the equivalences appear the names of the
respective lemmas provided by the base library.
Figure 8.3 shows further useful lemmas for list membership the base library
provides. The starred lemmas are registered with auto.
Exercise 8.3.1 Given the lemmas marked with ∗in Figure 8.3, auto 7 can solve
the goal 3 ∉nil ∧2 ∈A ++(1 :: 2 :: B) ++ C. Do the proof by hand using the tactic
apply to understand how this works.
Exercise 8.3.2 Prove the lemmas in Figure 8.3 in Coq.
Exercise 8.3.3 Prove the equivalences in Figure 8.2 in Coq.
124
2014-7-16

8.4 Inclusion and Equivalence
x ∈x :: A
∗in_eq
x ∈A →x ∈y :: A
∗in_cons
x ∈A ∨x ∈B →x ∈A ++ B
∗in_or_app
x ∉nil
∗in_nil
x ∈[y] →x = y
in_sing
x ∈y :: A →x ≠y →x ∈A
in_cons_neq
x ∉y :: A →x ≠y ∧x ∉A
not_in_cons
Figure 8.3: Membership lemmas
Exercise 8.3.4 Deﬁne an inductive predicate con satisfying the equivalence
con A B C ↔A ++ B = C.
a) Give the type of con.
b) Deﬁne con with rules.
c) Deﬁne con with constructors.
d) State the induction lemma for con.
e) Prove con A B C ↔A ++ B = C.
8.4 Inclusion and Equivalence
We deﬁne list inclusion A ⊆B and list equivalence A ≡B as follows:
A ⊆B := ∀x. x ∈A →x ∈B
A ≡B := A ⊆B ∧B ⊆A
We say that A is a sublist of B if A ⊆B. Note that two lists are equivalent if and
only if they contain the same elements.
In Coq, we realize list inclusion and list equivalence with two predicates
incl : ∀X : Type, list X →list X →Prop
equi : ∀X : Type, list X →list X →Prop
and accompanying notations.
Figure 8.4 shows some inclusion lemmas the base library registers with auto.
With these lemmas auto 6 can, for instance, solve the goal
∀A B C. A ⊆B →2 :: A ++ 3 :: A ⊆C ++ 3 :: 2 :: B
The base library also registers the constant equiv with auto so that it can be
unfolded automatically.
2014-7-16
125

8 Lists
A ⊆A
∗incl_reﬂ
A ⊆B →A ⊆x :: B
∗incl_tl
x ∈B →A ⊆B →x :: A ⊆B
∗incl_cons
A ⊆B →A ⊆B ++ C
∗incl_appl
A ⊆C →A ⊆B ++ C
∗incl_appr
A ⊆C →B ⊆C →A ++ B ⊆C
∗incl_app
nil ⊆A
∗incl_nil
Figure 8.4: Inclusion lemmas registered with auto
A ⊆nil →A = nil
incl_nil_eq
A ⊆B →x :: A ⊆x :: B
incl_shift
x :: A ⊆B ↔x ∈B ∧A ⊆B
incl_lcons
x :: A ⊆[y] →x = y ∧A ⊆[y]
incl_sing
x :: A ⊆x :: B →x ∉A →A ⊆B
incl_lrcons
A ++ B ⊆C →A ⊆C ∧B ⊆C
incl_app_left
A ⊆B →map f A ⊆map f B
incl_map
Figure 8.5: More inclusion lemmas
Figures 8.5 and 8.6 show further lemmas the base library provides for list
inclusion and list equivalence.
The base library registers list equivalence with setoid rewriting so that the
basic equality tactics1 become available for list equivalences. In addition, the
following morphism laws are registered with setoid rewriting to provide for deep
rewriting with list equivalences.
A ≡A′
x :: A ≡x :: A′
A ≡A′
B ≡B′
A ++ B ≡A′ ++ B′
A ≡A′
x ∈A ↔x ∈A′
A ≡A′
B ≡B′
A ⊆B ↔A′ ⊆B′
Here is a proof rewriting with two equivalences from Figure 8.6.
Goal ∀X (x y : X) A B, x::A ++ [y] ++ A ++ B ≡A ++ [y;x] ++ A ++ B.
Proof.
intros X x y A B. simpl. rewrite equi_swap. rewrite equi_shift at 1. reﬂexivity.
Qed.
1 rewrite, reﬂexivity, symmetry, transitivity.
126
2014-7-16

8.4 Inclusion and Equivalence
x ∈A →A ≡x :: A
equi_push
x :: A ≡x :: x :: A
equi_dup
x :: y :: A ≡y :: x :: A
equi_swap
x :: A ++ B ≡A ++ x :: B
equi_shift
x :: A ≡A ++[x]
equi_rotate
Figure 8.6: Equivalence lemmas
The base library registers list inclusion as a preorder (i.e., a reﬂexive and
transitive relation) with setoid rewriting. This makes it possible to use the tactics
reﬂexivity and transitivity for list inclusions.
Moreover, list inclusions can be
rewritten with list inclusions.
Goal ∀A B C D : list nat, A ⊆B →B ⊆C →C ⊆D →A ⊆D.
Proof.
intros A B C D F G H. rewrite F. rewrite G. exact H.
Qed.
The base library registers the following morphism laws with setoid rewriting
to provide for deep rewriting with list inclusions:
A ⊆A′
x :: A ⊆x :: A′
A ⊆A′
B ⊆B′
A ++ B ⊆A′ ++ B′
A ⊆A′
x ∈A →x ∈A′
Exercise 8.4.1 Decide for each of the following propositions whether it can be
shown with the lemmas registered with auto (Figures 8.3 and 8.4).
a) A ⊆B →x :: A ⊆x :: B
b) x ∈B →x ∈y :: (A ++ B)
c) x ∈y :: A →x ∈y :: (A ++ B)
d) x ∈A ++(y :: x :: B)
e) A ++[x] ⊆x :: A
f) (A ++ B) ++ C ≡C ++(B ++ A)
g) [x; z] ⊆[y; x; z]
Exercise 8.4.2 Prove the lemmas in Figures 8.4, 8.5, and 8.6
Exercise 8.4.3 Prove that set inclusion is a preorder and that list equivalence is
an equivalence relation.
Exercise 8.4.4 Prove the morphism laws for set equivalence.
2014-7-16
127

8 Lists
A ∥B ↔∀x. x ∈A →x ∉B
disjoint_forall
A ∥B →B ∥A
disjoint_symm
B′ ⊆B →A ∥B →A ∥B′
disjoint_incl
nil ∥B
∗disjoint_nil
A ∥nil
∗disjoint_nil’
x :: A ∥B ↔x ∉B ∧A ∥B
disjoint_cons
A ++ B ∥C ↔A ∥C ∧B ∥C
disjoint_app
Figure 8.7: Disjointness lemmas
Exercise 8.4.5 Deﬁne an inductive predicate mem satisfying mem x A ↔x ∈A.
a) Give the type of mem.
b) Deﬁne mem with rules.
c) Deﬁne mem with constructors.
d) State the induction lemma for mem.
e) Prove mem x A ↔x ∈A.
8.5 Disjointness
Two lists are disjoint if they don’t have a common element.
A ∥B := ¬∃x. x ∈A ∧x ∈B
The base library provides the lemmas shown in Figure 8.7. The starred lemmas
are registered with auto.
Exercise 8.5.1 Prove the lemmas in Figure 8.7.
8.6 Decidability
Figure 8.8 shows four basic decidability laws for lists.2 We may paraphrase the
laws as follows:
1. A list type has decidable equality if the base type has decidable equality.
2. List membership is decidable if the base type has decidable equality.
3. Universal quantiﬁcation over the members of a list preserves decidability.
2 The notation s = t :> T says that both sides of the equation have type T.
128
2014-7-16

8.6 Decidability
eq_dec X
eq_dec (list X)
∗list_eq_dec
A : list X
eq_dec (list X)
dec (x ∈A)
∗list_in_dec
∀x. dec (p x)
dec (∀x. x ∈A →p x)
∗list_forall_dec
∀x. dec (p x)
dec (∃x. x ∈A ∧p x)
∗list_exists_dec
eq_dec X := ∀x y : X. dec (x = y)
Figure 8.8: Decidability laws for lists
4. Existential quantiﬁcation over the members of a list preserves decidability.
Note that the laws for the quantiﬁers do not require that the base type of the list
has decidable equality. All four laws follow by induction on the list A.
The base library provides the laws in Figure 8.8 as lemmas with the names
given at the right. For the purpose of proof automation, the base library registers
the function dec as a so-called type class, for which in turn the decidability laws
in Figure 8.8 are registered as so-called instance rules. The base library also
registers instance rules for the logical connectives:
dec X
dec Y
dec (X →Y)
dec X
dec Y
dec (X ∧Y)
dec X
dec Y
dec (X ∨Y)
dec X
dec (¬X)
The resulting infrastructure provides for the automation of many decidability
proofs.
Goal ∀X A B (p : X →Prop),
eq_dec X →(∀x, dec (p x)) →dec (A=B ∨∀x, x ∈A →∃y, y ∈B ∧(y ∈A ∨¬ p x)).
Proof. auto. Qed.
Additional instance rules for dec (or other registered type classes) can be
registered with the command
Existing Instance L.
2014-7-16
129

8 Lists
∀x. dec (p x)
{ x | x ∈A ∧px } + {∀x. x ∈A →¬px}
list_sigma_forall
∀x. dec (p x)
¬∀x. x ∈A →¬px
∃x. x ∈A ∧px
list_exists_DM
eq_dec X
A ̸⊆B
∃x. x ∈A ∧x ∉B
list_exists_not_incl
∀x. dec (p x)
∃x. x ∈A ∧px
{ x | x ∈A ∧px }
list_cc
Figure 8.9: Quantiﬁer laws for lists and decidable predicates
where L is the lemma formalizing the rule. It is possible to combine the deﬁnition
of L with the registration of L by writing the keyword Instance rather than the
keyword Lemma.
Instance iﬀ_dec (X Y : Prop) :
dec X →dec Y →dec (X ↔Y).
Proof. unfold dec; τto. Qed.
Figure 8.9 shows three quantiﬁer laws for lists exploiting decidability assump-
tions. The second law is a de Morgan-style law for existential list quantiﬁcation,
and the third law is a constructive choice principle for lists. The ﬁrst law in Fig-
ure 8.9 is a basic decision principle for lists from which the other two laws in
Figure 8.9 as well as the decidability laws for list quantiﬁcation in Figure 8.8 can
be obtained.
Exercise 8.6.1 Explain why auto can prove
Goal ∀X (A B : list X), eq_dec X →dec (A ≡B)
Do the proof not using auto.
Exercise 8.6.2 Prove the goal given below not using auto. Use the lemmas in
Figure 8.8 and the lemmas or_dec and not_dec from the base library.
Goal ∀X A B (p : X →Prop),
eq_dec X →(∀x, dec (p x)) →dec (A=B ∨∀x, x ∈A →∃y, y ∈B ∧(y ∈A ∨¬ p x)).
130
2014-7-16

8.7 Filtering
Exercise 8.6.3 Prove the decidability laws for lists shown in Figure 8.8. All four
laws can be shown by induction on A. Some of the laws require further case
analysis. Use the tactics auto, eauto, tauto, inv, and discriminate.
Exercise 8.6.4 Prove the quantiﬁer laws for lists shown in Figure 8.9. The ﬁrst
law follows by induction on the list A. The other two laws follow from the ﬁrst
law.
8.7 Filtering
The base library provides a function ﬁlter that for a decidable predicate and a
list yields the sublist containing all elements satisfying the predicate.
ﬁlter p nil := nil
ﬁlter p (x :: A) := if [px\ then x :: ﬁlter p A else ﬁlter p A
The notation [px\ stands for a decision for the proposition px. The type of
ﬁlter is
∀X : Type. (X →Prop) →(∀x. dec (px)) →list X →list X
where the ﬁrst and the third argument are implicit. Coq will attempt to derive
the third argument (a decider for p) using the instance rules registered for dec.
Here is an example:
Compute ﬁlter (fun x ⇒3 ≤x ≤7) [1;2;3;4;5;6;7;8;9].
% [3; 4; 5; 6; 7]
The implicit argument of ﬁlter is determined as
λx. and_dec (le_dec 3 x) (le_dec x 7)
The base library realizes the notation [X\ with an application decision X
where decision is an identity function for decisions:
Deﬁnition decision (X : Prop) (D : dec X) : dec X := D.
Arguments decision X {D}.
By default, X would be the implicit and D be the explicit argument of decision.
The default is overwritten with the command Arguments. There is a fair chance
Coq can derive D since dec is a type class with instance rules. Using decision,
ﬁlter is deﬁned as follows:
2014-7-16
131

8 Lists
x ∈ﬁlter p A ↔x ∈A ∧px
in_ﬁlter_iﬀ
ﬁlter p A ⊆A
ﬁlter_incl
A ⊆B →ﬁlter p A ⊆ﬁlter p B
ﬁlter_mono
(∀x. x ∈A →px →qx) →ﬁlter p A ⊆ﬁlter q A
ﬁlter_pq_mono
(∀x. x ∈A →(px ↔qx)) →ﬁlter p A = ﬁlter q A
ﬁlter_pq_eq
(∀x. x ∈A →px) →ﬁlter p A = A
ﬁlter_id
ﬁlter p (ﬁlter q A) = ﬁlter (λx. px ∧qx) A
ﬁlter_and
ﬁlter p (ﬁlter q A) = ﬁlter q (ﬁlter p A)
ﬁlter_comm
ﬁlter p (A ++ B) = ﬁlter p A ++ ﬁlter p B
ﬁlter_app
px →ﬁlter p (x :: A) = x :: ﬁlter p A
ﬁlter_fst
¬px →ﬁlter p (x :: A) = ﬁlter p A
ﬁlter_fst’
Figure 8.10: Lemmas for ﬁlter
Deﬁnition ﬁlter (X : Type) (p : X →Prop) (p_dec : ∀x, dec (p x)) : list X →list X :=
ﬁx f A := match A with
| nil ⇒nil
| x::A’ ⇒if decision (p x) then x :: f A’ else f A’
end.
Arguments ﬁlter {X} p {p_dec} A.
The implicit argument of decision is determined as p_dec x.
Figure 8.10 shows lemmas for ﬁlter the standard library provides.
We discuss the deﬁnition of in_ﬁlter_iﬀ.
Lemma in_ﬁlter_iﬀX (p : X →Prop) {p_dec : ∀x, dec (p x)} x A :
x ∈ﬁlter p A ↔x ∈A ∧p x.
Proof.
induction A as [|y A]; simpl.
−τto.
−decide (p y) as [B|B]; simpl;
rewrite IHA; intuition; subst; τto.
Qed.
Note that the argument p_dec is declared with curly braces.
This enforces
that p_dec is an implicit argument of the lemma.
The proof is by induc-
tion on A. The induction step does a case analysis on decision (px) : dec (px)
132
2014-7-16

8.8 Element Removal
using the tactic decide.
The tactic decide is deﬁned in the base library as
decide X := destruct (decision X).
Exercise 8.7.1 Prove the lemmas in Figure 8.10.
Exercise 8.7.2 (Intersection) Deﬁne an intersection function inter for lists and
prove x ∈inter A B ↔x ∈A ∧x ∈B.
8.8 Element Removal
We use the notation A\x for the sublist of A obtained by deleting all occurrences
of x. Formally, we deﬁne element removal A \ x using ﬁlter:
A \ x := ﬁlter (λy.y ≠x) A
The base library realizes element removal with a function
rem : ∀X : Type. eq_dec X →list X →X →list X
whose ﬁrst and second argument are implicit. The second argument provides a
decider for equality on X. The notation eq_dec X was deﬁned in Figure 8.8.
Figure 8.11 shows lemmas the base library provides for list removal.
Exercise 8.8.1 Prove the lemmas in Figure 8.11.
8.9 Cardinality
The cardinality card A of a list A is the number of diﬀerent elements in A. For
instance,
card [1; 2] = 2
card [1; 2; 1; 2; 3] = 3
Formally, we deﬁne cardinality of lists with a recursive function:
card nil = 0
card (x :: A) = if [x ∈A\ then card A else 1 + card A
Intuitively, we may say that the function card counts only the last occurrence of
an element. The base library accommodates cardinality as a function
card : ∀X : Type. eq_dec X →list X →N
2014-7-16
133

8 Lists
x ∈A \ y ↔x ∈A ∧x ≠y
in_rem_iﬀ
x = y ∨x ∉A →x ∉A \ y
∗rem_not_in
A \ x ⊆A
∗rem_incl
A ⊆B →A \ x ⊆B
∗rem_mono
A ⊆B →x ∉A →A ⊆B \ x
∗rem_inclr
A ⊆B →(x :: A) \ x ⊆B
∗rem_cons
x ∈B →A \ y ⊆B →(x :: A) \ y ⊆B
∗rem_cons’
x ∈A →B ⊆A ++(B \ x)
∗rem_app
A \ x ⊆C →B \ x ⊆C →(A ++ B) \ x ⊆C
∗rem_app’
x ∈A \ y →x ∈A
∗rem_in
x ≠y →x ∈A →x ∈A \ y
∗rem_neq
x :: A ≡x :: (A \ x)
rem_equi
x ∈A →A ≡x :: (A \ x)
rem_reorder
(A \ x) \ y = (A \ y) \ x
rem_comm
(x :: A) \ x = A \ x
rem_fst
x ≠y →(x :: A) \ y = x :: (A \ y)
rem_fst’
x ∉A →A \ x = A
rem_id
Figure 8.11: Lemmas for element removal
whose ﬁrst and second argument are implicit.
Figure 8.11 shows basic cardinality laws the base library provides. The car-
dinality laws for lists are similar to cardinality laws for ﬁnite sets. The laws are
useful for proofs that employ size induction based on list cardinality.
Lemma card_eq is registered as a morphism law with setoid rewriting.
Exercise 8.9.1 Why do the equations
card nil = 0
card (x :: A) = 1 + card (A \ x)
not provide for a recursive deﬁnition of the cardinality function in Coq?
134
2014-7-16

8.10 Duplicate-Freeness
x ∈A →card A = 1 + card (A \ x)
card_in_rem
x ∉A →card A = card (A \ x)
card_not_in_rem
A ⊆B →card A ≤card B
card_le
A ≡B →card A = card B
card_eq
A ⊆B →card A = card B →A ≡B
card_equi
card A < card B →∃x. x ∈B ∧x ∉A
card_ex
A ⊆B →x ∈B →x ∉A →card A < card B
card_lt
A ⊆B →A ≡B ∨card A < card B
card_or
card (x :: A) = 1 + card (A \ x)
card_cons_rem
card A = 0 →A = nil
card_0
Figure 8.12: Cardinality laws for lists
Exercise 8.9.2 Prove the lemma card_in_rem. Hint: Use induction on A and the
lemmas in_rem_iﬀand rem_id.
Exercise 8.9.3 Prove the lemma card_le. Use induction on A and the lemmas
incl_lcons and card_in_rem.
8.10 Duplicate-Freeness
A list is duplicate-free if it contains no element twice.
Formally, we deﬁne
duplicate-free lists with an inductive predicate:
dupfree :
∀X : Type. list X →Prop
dupfree nil
x ∉A
dupfree A
dupfree (x :: A)
The inductive deﬁnition of dupfree gives us a convenient induction principle for
duplicate-free lists. Duplicate-free lists have two important properties:
•
The cardinality of a duplicate-free list is the length of the list.
•
For every list there exists an equivalent duplicate-free list.
2014-7-16
135

8 Lists
dec (dupfree A)
dupfree_dec
dupfree A →card A = |A|
dupfree_card
dupfree (x :: A) ↔x ∉A ∧dupfree A
dupfree_cons
A ∥B →dupfree A →dupfree B →dupfree (A ++ B)
dupfree_app
dupfree A →f injective on A →dupfree (map f A)
dupfree_map
dupfree A →dupfree (ﬁlter p A)
dupfree_ﬁlter
dupfree (undup A)
dupfree_undup
undup A ≡A
undup_id_equi
A ≡B ↔undup A ≡undup B
undup_equi
A ⊆B ↔undup A ⊆undup B
undup_incl
dupfree A →undup A = A
undup_id
undup (undup A) = undup A
undup_idempotent
Figure 8.13: Lemmas for duplicate-free lists
We deﬁne a function undup mapping lists to equivalent duplicate-free lists:
undup nil := nil
undup (x :: A) := if [x ∈A\ then undup A else x :: undup A
The base library accommodates undup as a function
undup : ∀X : Type. eq_dec X →list X →list X
whose ﬁrst and second argument are implicit. Figure 8.13 shows lemmas the
base library provides for undup and duplicate-free lists.
Exercise 8.10.1 Assume the base type has decidable equality.
a) Prove the lemma dupfree_card.
b) Prove the lemma dupfree_dec.
c) Prove the lemma dupfree_undup.
d) Prove the lemma undup_id_equi.
Hint: Use induction on the derivation of dupfree A where possible. Otherwise
use induction on A.
Exercise 8.10.2 Prove
the
lemmas
dupfree_app,
dupfree_map,
and
dupfree_ﬁlter. Hint: Use induction on the derivation of dupfree A.
136
2014-7-16

8.11 Power Lists
Exercise 8.10.3 Prove that the existence of an undup function implies that base
type equality is decidable:
∀X. (∀A : list X. { B | dupfree B ∧A ≡B }) →eq_dec X
Hint: Use the lemmas incl_sing, incl_nil_eq, equi_dup, and dupfree_cons. First
prove a lemma x :: y :: A ⊆[z] →x = y.
8.11 Power Lists
For every list U we will deﬁne a list PU satisfying the following conditions:
1. Every element of PU is a sublist of U.
2. Every sublist of U is equivalent to an element of PU.
3. If U is duplicate-free, then every element of PU is duplicate-free and every
sublist of U is equivalent to exactly one element PU.
We deﬁne the power list PU as follows:
P nil := [nil]
P (x :: A) := PA ++ map (cons x) (PA)
The base library accommodates power lists with a function
power : ∀X : Type. list X →list (list X)
We also deﬁne a representation function
[A\U := ﬁlter (λx.x ∈A) U
satisfying the [A\U ∈PU and [A\U ≡A whenever A ⊆U. The base library
accommodates [A\U with a function
rep : ∀X : Type. eq_dec X →list X →list X →list X
whose ﬁrst and second argument are implicit.
Figure 8.14 shows the lemmas the base library provides for power lists and
the accompanying representation function.
Exercise 8.11.1 Prove the lemmas for power lists shown in Figure 8.14.
2014-7-16
137

8 Lists
A ∈PU →A ⊆U
power_incl
nil ∈PU
power_nil
[A\U ∈PU
rep_power
[A\U ⊆U
rep_incl
A ⊆U →x ∈A →x ∈[A\U
rep_in
A ⊆U →[A\U ≡A
rep_equi
A ⊆B →[A\U ⊆[B\U
rep_mono
A ≡B →[A\U = [B\U
rep_eq
A ⊆U →B ⊆U →[A\U = [B\U →A ≡B
rep_injective
[[A\U\U = [A\U
rep_idempotent
dupfree U →dupfree (PU)
dupfree_power
A ∈PU →dupfree U →dupfree A
dupfree_in_power
dupfree U →A ∈PU →[A\U = A
rep_dupfree
dupfree U →A ∈PU →B ∈PU →A ≡B →A = B
power_extensional
Figure 8.14: Lemmas for power lists
138
2014-7-16

9 Syntactic Uniﬁcation
We consider a basic problem in computational logic known as syntactic uniﬁ-
cation: Given two terms, ﬁnd variable instantiations making the terms syntacti-
cally equal. Algorithms for syntactic uniﬁcation are employed for type inference
in Coq and in functional programming languages. Syntactic uniﬁcation is also
used by Coq’s tactic interpreter to ﬁnd instantiations for universally quantiﬁed
variables of lemmas to be applied with the tactics apply and rewrite.
We formalize the syntactic uniﬁcation problem and verify a uniﬁcation algo-
rithm. Syntactic uniﬁcation serves us as a basic syntactic theory where we can
study the formalization of terms and substitutions. Syntactic uniﬁcation also
provides us with an example of a nontrivial algorithm that in its natural formu-
lation is not structurally recursive. Given that in Coq all recursion is structural,
this looks like a problem at ﬁrst. However, there is a standard technique known
as bounded recursion that transforms general recursion to structural recursion
on a numeric bound provided termination of the general recursion follows with
a numeric size function.
9.1 Terms, Substitutions, and Uniﬁers
We start with an informal discussion of the syntactic uniﬁcation problem. We
consider a minimal version of the problem where terms are obtained with vari-
ables and a single binary operation called dot:
s, t ::= x | s · t
Thus a term is either a variable or an ordered pair of two terms. Two terms are
uniﬁable if there are instantiations for the variables in the terms such that the
terms become equal:
•
x and y are uniﬁable with x ≐y.
•
x · (z · x) and (z · z) · y are uniﬁable with x ≐z · z and y ≐z · (z · z).
•
x and x · y are not uniﬁable.
A uniﬁer of two terms is a list of variable instantiations making the terms equal.
A uniﬁer of two terms is principal if the variable instantiations do not involve
139

9 Syntactic Uniﬁcation
unnecessary commitments. The uniﬁers given above are principal for the respec-
tive terms. Given the terms x and y, the instantiation list [x ≐z; y ≐z] is a
non-principal uniﬁer. Our goal is a uniﬁcation algorithm that given two terms
decides whether the terms are uniﬁable and returns a principal uniﬁer if the
terms are uniﬁable.
There is the complication that two terms may have more than one principal
uniﬁer.
For instance, the terms x and y have two principal uniﬁers, x ≐y
and y ≐x.
The ambiguity can be eliminated by insisting that principal uni-
ﬁers replace larger variables with smaller variables. We will not impose such a
constraint.
It is helpful to see uniﬁcation as a special form of equation solving: Given an
equation s ≐t between two terms, we are looking for variable instantiations that
solve the equation. It will also be helpful to consider list of equations rather than
single equations. Under this view, uniﬁers appear as solutions of equation lists.
We now give formal deﬁnitions of terms, equations, and (principal) uniﬁers in
Coq. We start with the deﬁnition of variables, terms, and equations.
Deﬁnition var := nat.
Inductive ter : Type :=
| V : var →ter
| T : ter →ter →ter.
Deﬁnition eqn := prod ter ter.
The Coq deﬁnitions make the informal deﬁnitions precise: Variables are num-
bers, terms are binary trees whose leaves are labelled with variables, and equa-
tions are pairs of terms.
Terms are a recursive data structure. Numbers and lists are recursive data
structures we are already familiar with. While numbers and lists are obtained
with linear recursion, terms are obtained with binary recursion. Inductions on
terms will involve two inductive hypotheses, one for each component of a pair.
It is common mathematical practice to always use the same letters for the
same type of objects. This way the type of an object is clear from the letter used
to denote it. Coq supports this mathematical convention with a command that
declares implicit types for identiﬁers:
Implicit Types x y z : var.
Implicit Types s t u v : ter.
Implicit Type e : eqn.
Implicit Types A B C : list eqn.
Implicit Types σ τ : ter →ter.
Implicit Types m n k : nat.
The declarations will spare us many type declarations in lemmas and deﬁnitions.
The conventions automatically extend to variations of the letters like x′ or s2.
140
2014-7-16

9.1 Terms, Substitutions, and Uniﬁers
When an identiﬁer is used without type declaration, Coq will automatically give
it the declared implicit type. Implicit type declarations also make Coq’s output
more readable since the types of identiﬁers with implicit types are omitted.
In mathematical mode, we use x to denote both the variable x and the
term Vx.
Formally, x and V x are quite diﬀerent: While x is a variable, V x
is a term. Coq will not allow us to write an equation x = V x.
Next we come to the formal deﬁnition of uniﬁers. The basic idea is that a
uniﬁer is a substitution making two terms equal. A substitution can be seen as
a function that maps variables to terms. For the purposes of uniﬁcation ﬁnite
substitutions that can be represented as equation lists [x1 ≐s1, . . . , xn ≐sn]
suﬃce.
There are diﬀerent possibilities for the formal representation of substitutions
and it will be necessary to work with more than one representation.
For the
oﬃcial deﬁnition we need to ﬁx one representation. Which representation we
choose for the deﬁnition will matter a lot for the Coq development. It turns out
that an abstract functional representation is most convenient.
We deﬁne substitutions as functions σ : ter →ter that distribute over dot:
Deﬁnition subst σ : Prop :=
∀s t, σ (T s t) = T (σ s) (σ t).
The distribution property ensures that σs can be obtained from s by replacing
every variable x in s with σx.
Exercises 9.6.1 and 9.6.2 are concerned with alternative representations of
substitutions.
A substitution σ uniﬁes an equation s ≐t if σs = σt. A uniﬁer of an equation
list is a substitution that uniﬁes every equation in the list:
Deﬁnition unif σ A : Prop :=
subst σ ∧
∀s t, (s,t) ∈A →σ s = σ t.
An equation list is uniﬁable if it has a uniﬁer:
Deﬁnition uniﬁable A : Prop :=
∃σ, unif σ A.
A principal uniﬁer of an equation list is a uniﬁer of the list that is subsumed
by every uniﬁer of the list:
Deﬁnition principal_uniﬁer σ A : Prop :=
unif σ A ∧
∀τ, unif τ A →∀s, τ (σ s) = τ s.
Exercise 9.1.1 Show that two substitutions agree on all terms if they agree on
all variables.
2014-7-16
141

9 Syntactic Uniﬁcation
Exercise 9.1.2 A function f : X →X is idempotent if f (f x) = f x for every x
in X. Show that every principal uniﬁer is idempotent.
Exercise 9.1.3 Prove the following facts about uniﬁcation:
a) unif σ (y ≐s :: A) ↔σs = σt ∧unif σ A
b) unif σ (A ++ B) ↔unif σ A ∧unif σ B
Exercise 9.1.4 Prove that an equation list is non-uniﬁable if some sublist is non-
uniﬁable.
9.2 Solved Equation Lists
A list of equations may be solved by transforming it to a solved form using
uniﬁer-preserving rules. An equation list is solved if it has the form
x1 ≐s1, . . . , xn ≐sn
where the variables x1, . . . , xn are distinct and, for all i ∈{1, . . . , n}, the vari-
able xi does not appear in s1, . . . , si. Here is an example of a solved equation
list:
[x1 ≐x0 · x0; x2 ≐x1 · x1; x3 ≐x2 · x2]
For a solved list we can always obtain a principal uniﬁer. The above list has a
unique principal uniﬁer σ, which satisﬁes the equations
σx1 = x0 · x0
σx2 = σx1 · σx1
σx3 = σx2 · σx2
σx = x
if x ∉{x1, x2, x3}
The formal deﬁnition of solved equation lists requires a number of auxiliary
deﬁnitions. We start with the notations V s and V A, which stand for lists con-
taining exactly the variables occurring in s and A, respectively. We realize the
notations with two recursive functions:
V x := [x]
V nil := nil
V (s · t) := V s ++ V t
V (s ≐t :: A) := V s ++ V t ++ V A
For the deﬁnition of solved equation lists, we also need the domain DA of an
equation list A. If A = [x1 ≐t1; . . . ; xn ≐tn], then DA = [x1; . . . ; xn]. If A is
142
2014-7-16

9.2 Solved Equation Lists
of a diﬀerent form, we do not care about DA. Formally, we deﬁne DA for all
equation lists A. We use the following deﬁnition:
D nil := nil
D (x ≐t :: A) := x :: DA
D (s ≐t :: A) := nil
if s is not a variable
We can now deﬁne solved equation lists with an inductive predicate solved:
solved nil
x ∉V s
x ∉DA
V s ∥DA
solved A
solved (x ≐s :: A)
Next we need an operation s x
t that in a term s replaces every occurrence of the
variable x with a term t. We speak of variable replacement. We will also need
variable replacement for lists. Formally, we deﬁne s x
t and Ax
t with two recursive
functions:
y x
t
:= if y = x then t else y
nil x
t
:= nil
(s1 · s2)x
t
:= s1 x
t · s2 x
t
(u ≐v :: A)x
t
:= ux
t ≐v x
t :: Ax
t
Next we deﬁne a function ϕ that yields a principal uniﬁer for every solved
equation list A. Formally, we deﬁne ϕ on all equation lists:
ϕ nil s := s
ϕ (x ≐t :: A) s := (ϕ A s)x
t
ϕ (u ≐v :: A) s := s
if u is not a variable
Lemma 9.2.1 Let A be solved. Then ϕ A is a principal uniﬁer of A.
A bad equation is an equation of the form x ≐s where x ≠s and x ∈V s.
Lemma 9.2.2 No equation list containing a bad equation is uniﬁable.
We leave the proofs of the lemmas as exercises.
Exercise 9.2.3 Prove the following facts about variable replacement.
a) If x ∉V s, then s x
t = s.
b) If x ∉V A, then Ax
t = A.
c) If x ∉DA, then D(Ax
t ) = DA.
d) If σ is a substitution such that σx = σt, then σ(s x
t ) = σs.
e) λs. s x
t is a substitution.
2014-7-16
143

9 Syntactic Uniﬁcation
Exercise 9.2.4 Prove the following facts about ϕ :
a) ϕ A is a substitution.
b) If DA ∥V s, then ϕ A s = s.
c) If A is solved, then ϕ A is a uniﬁer of A.
d) If σ is a uniﬁer of A, then σ (ϕ A s) = σs.
e) If A is solved, then ϕ A is a principal uniﬁer of A.
Exercise 9.2.5 Prove the bad equation lemma 9.2.2.
Hint: Deﬁne a function
size : ter →N such that size s < size (s · t) and proceed by proving the following
facts:
a) If x ∈V s and σ is a substitution, then size (σx) ≤size (σs).
b) No bad equation is uniﬁable.
Exercise 9.2.6 Prove the following facts about variables:
a) DA ⊆A
b) V (A ++ B) = V A ++ V B
c) s ≐t ∈A →V s ⊆V A ∧V t ⊆V A
d) A ⊆B →V A ⊆V B
Exercise 9.2.7 Write a function gen : N →ter for which you can prove that gen m
and gen n are non-uniﬁable if m and n are diﬀerent.
Exercise 9.2.8 Prove that the concatenation A ++ B of two solved lists A and B is
solved if V A and DB are disjoint.
9.3 Uniﬁcation Rules
Every uniﬁable equation list can be transformed with the so-called uniﬁcation
rules to a solved equation list having the same uniﬁers as the initial list. We
prepare this result with the deﬁnitions of an equivalence relation A ≈B (uniﬁer
equivalence) and a preorder A ⊲B (reﬁnement):
A ≈B := ∀σ. unif σ A ↔unif σ B
A ⊲B := V B ⊆V A ∧A ≈B
We say that B is a reﬁnement of A if A ⊲B.
Lemma 9.3.1 Reﬁnement of equation lists is a preorder compatible with cons,
concatenation, and uniﬁcation.
144
2014-7-16

9.3 Uniﬁcation Rules
1. A ⊲A.
2. If A ⊲B and B ⊲C, then A ⊲C.
3. If A ⊲A′, then x :: A ⊲x :: A′.
4. If A ⊲A′ and B ⊲B′, then A ++ B ⊲A′ ++ B′.
5. If A ⊲B, then unif σ A ↔unif σ B.
Lemma 9.3.2 (Uniﬁcation Rules)
1. Deletion
[s ≐s] ⊲nil.
2. Swap
[s ≐t] ⊲[t ≐s].
3. Decomposition
[s1 · s2 ≐t1 · t2] ⊲[s1 ≐t1; s2 ≐t2].
4. Replacement
x ≐t :: A ⊲x ≐t :: Ax
t .
The uniﬁcation rules are obtained as the operational readings of the facts
about reﬁnement stated in Lemma 9.3.2:
1. Trivial equations may be deleted.
2. The two sides of an equation may be swapped.
3. An equation s1 · s2 ≐t1 · t2 may be replaced by s1 ≐t1 and s2 ≐t2.
4. Given an equation x ≐s, the variable x may be replaced with s in other
equations.
We say that a solved equation list B is a solved form for an equation list A
if A ⊲B. We will show that the uniﬁcation rules suﬃce to reﬁne every uniﬁable
equation list into a solved form. We will also show that the uniﬁcation rules are
strong enough to reﬁne every non-uniﬁable equation list into a list containing a
bad equation.
Exercise 9.3.3 Prove the facts stated by Lemma 9.3.1.
Exercise 9.3.4 Prove the correctness of the deletion, swap, and decomposition
rule (i.e., the ﬁrst three facts stated by Lemma 9.3.2).
Exercise 9.3.5 Prove the correctness of the replacement rule (i.e., the last fact
stated by Lemma 9.3.2).
Proceed by proving the following facts in the order
stated.
a) If σ is a substitution such that σx = σt, then σ(s x
t ) = σs.
b) If σx = σt, then unif σ A ↔unif σ (Ax
t ).
c) x ≐t :: A ≈x ≐t :: Ax
t
d) V (s x
t ) ⊆V s ++ V t
e) V (Ax
t ) ⊆V A ++ V t
2014-7-16
145

9 Syntactic Uniﬁcation
f) x ≐t :: A ⊲x ≐t :: Ax
t
Exercise 9.3.6 Prove the following fact about principal uniﬁers: If A ≈B and σ
is a principal uniﬁer of A, then σ is a principal uniﬁer of B.
Exercise 9.3.7 Give a solved equation list that has more than one principal uni-
ﬁer.
Exercise 9.3.8 (Confrontation Rule)
Prove [x ≐s1 · s2; x ≐t1 · t2] ⊲[x ≐s1 · s2; s1 ≐t1; s2 ≐t2]. The operational
reading of this fact yields the so-called confrontation rule. The confrontation
rule can often be used in place of the replacement rule when an equation list is
transformed to solved form. In contrast to the replacement rule it has the virtue
that it introduces only terms that are subterms of the original terms. This fact
matters for eﬃcient uniﬁcation algorithms.
9.4 Presolved Equation Lists
An equation list A is presolved if it is either empty or starts with an equation of
the form x ≐s where x ≠s. Every equation list can be reﬁned into a presolved
equation list using the uniﬁcation rules for deletion, swapping, and decomposi-
tion of equations. The reﬁnement can be realized with two recursive functions:
pre′ s t := if s = t then nil else
match s, t with
| x, _ ⇒[s ≐t]
| _, x ⇒[t ≐s]
| s1 · s2, t1 · t2 ⇒pre′ s1 t1 ++ pre′ s2 t2
pre nil := nil
pre (s ≐t :: A) := pre′ s t ++ pre A
Lemma 9.4.1
1. [s ≐t] ⊲pre′ s t and pre′ s t is presolved.
2. A ⊲pre A and pre A is presolved.
Exercise 9.4.2 Prove Lemma 9.4.1.
9.5 Uniﬁcation Algorithm
Our goal is a function solve satisfying the following speciﬁcation:
146
2014-7-16

9.5 Uniﬁcation Algorithm
Theorem solve_correct C :
match solve C with
| Some A ⇒C ⊲A ∧solved A
| None ⇒¬ uniﬁable C
end
Our starting point is the presolver from the previous section. We distinguish
three cases:
1. pre C is empty. Then nil is a solved form for C and we are done.
2. pre C starts with a bad equation. Then C is not uniﬁable and we are done.
3. pre C = x ≐t :: D and x ∉V t. In this case we collect x ≐t as ﬁrst equation
of a possible solved form for C. The correctness of pre and the replacement
rule give us
C ⊲x ≐t :: D ⊲x ≐t :: D x
t
Note that the list D x
t contains one variable less than D since the variable
replacement eliminates the variable x. We speak of an elimination step.
We continue recursively by eliminating variables as long as this is possible.
Things can be arranged such that the equations x ≐t used for variable elimi-
nation yield a solved form (see Exercise 9.2.8).
The outlined idea can be realized with a function solveE satisfying the follow-
ing speciﬁcation:1
Lemma solveE_correct A B C :
C ⊲A ++ B →
solved A →
D A ∥V B →
match solveE A B with
| Some D ⇒C ⊲D ∧solved D
| None ⇒¬ uniﬁable C
end
Note that the lemma lists the necessary preconditions for solveE. Given solveE,
we deﬁne
solve C := solveE nil C
and prove solve_correct using solveE_correct.
The obvious way to write the function solveE is by size recursion on the cardi-
nality of V B. However, Coq admits only structural recursion. The trick now is to
1 You may wonder why the correctness lemma is not formulated more compactly without the
variable C and the accompanying precondition. The reason is that the presence of C simpliﬁes
the inductive proof. See Exercise 9.5.4 for a discussion of the issue.
2014-7-16
147

9 Syntactic Uniﬁcation
introduce an additional argument n serving as a bound for the recursion depth.
The recursion can then be realized as structural recursion on the bound n. One
speaks of bounded recursion. We realize the idea with a function solveN satis-
fying the following speciﬁcation:
Lemma solveN_correct A B C n :
C ⊲A ++ B →
solved A →
D A ∥V B →
card (V B) < n →
match solveN n A B with
| Some D ⇒C ⊲D ∧solved D
| None ⇒¬ uniﬁable C
end
Note that the precondition card(V B) < n requires that the bound n is larger
than the recursion depth needed for B. Given solveN, we deﬁne
solveE A B := solveE (1 + card(V B)) A B
and prove solveE_correct using solveN_correct.
It remains to deﬁne solveN and prove solveN_correct. We deﬁne solveN reﬁn-
ing the initial idea for solve with bounded recursion.
Fixpoint solveN n A B : option (list eqn) :=
match n, pre B with
| O, _ ⇒None
| S n’, x ≐t :: C ⇒if [x ∈V t\ then None else solveN n’ (x ≐t :: A) (C x
t )
| S n’, _ ⇒Some A
end
The proof of solveN_correct is pleasant and leads to subgoals expressing
proof obligations one would expect from an informal correctness argument for
solve. One ﬁrst reverts A and B and then continues by induction on n. The base
case is trivial. For the inductive case one simulates the case analysis of the func-
tion solveN. For the recursion step one applies the inductive hypothesis, which
produces subgoals for the preconditions.
Exercise 9.5.1 Deﬁne the functions solveE and solve and prove their correctness
lemmas (based on solveN and solveN_correct).
Exercise 9.5.2 Prove that an equation list either has a solved form or is non-
uniﬁable.
Exercise 9.5.3 Prove that an equation list either has a principal uniﬁer or is non-
uniﬁable.
148
2014-7-16

9.6 Alternative Representations
Exercise 9.5.4 If you look at the correctness lemmas for solveE and solveN, you
may notice that the lemmas can be formulated without the list C and the precon-
dition for C. The alternative formulation of the correctness lemma for solveN
looks as follows:
Lemma solveN_correct’ A B n :
solved A →
D A ∥V B →
card (V B) < n →
match solveN n A B with
| Some D ⇒A ++ B ⊲D ∧solved D
| None ⇒¬ uniﬁable (A ++ B)
end
We have chosen the less compact formulation of the correctness lemma with
the variable C since the presence of C considerably simpliﬁes the proof. In the
formulation with C the inductive hypothesis applies directly to the claim for
the recursive call and yields subgoals for the preconditions. In the formulation
without C, the inductive hypothesis does not apply directly and needs to be
transformed using forward reasoning.
Try to prove the lemma solveN_correct′ to understand the issue.
Exercise 9.5.5 From the correctness theorem for the function solve it follows
that every uniﬁable equation list has a solved form. Try to prove this fact without
using the function solve and its variants (using the function pre is ﬁne, however).
Hint: Use size induction to prove a lemma compensating for solveN_correct.
Much of the proof script for solveN_correct can be reused.
Mathematically, one may argue that there is no need for an explicit function
solveN since the proof of the desired existence lemma (uniﬁable equation lists
have solved forms) can be carried out with size induction. One may also argue
that deﬁning the function solveN explicitly makes the proof more transparent.
Exercise 9.5.6 Extend the Coq development of syntactic uniﬁcation to terms
with constants.
9.6 Alternative Representations
In this section we explore alternative representations for substitutions and a
more explicit solved form.
Exercise 9.6.1 (Representing Substitutions as Functions var →ter)
It is natural to see substitutions as functions from variables to terms. In fact,
2014-7-16
149

9 Syntactic Uniﬁcation
every function from variables to terms represents a substitution, and every sub-
stitution can be represented as a function from variables to terms. Our represen-
tation of substitutions as functions from terms to terms is less direct since the
functions representing substitutions need to be ﬁltered out with the predicate
subst.
Deﬁne a function hat : (var →ter) →ter →ter for which you can prove the
following statements.
a) subst (hat f )
b) hat f x = f x
c) hat (λx.x) s = s
d) subst σ →hat (λx.σx) s = σs
e) s x
t = hat (λz. if [z = x\ then t else z) s
Exercise 9.6.2 (Representing Substitutions as Lists)
We are mostly interested in ﬁnite substitutions σ that can be represented with
an equation list A = [x1 ≐s1; . . . ; xn ≐sn] such that
σx =



s
if x ≐s ∈A
x
otherwise
Deﬁne a function sub : list eqn →var →ter for which you can prove the follow-
ing:
a) sub (x ≐s :: A) x = s
b) sub (x ≐s :: A) y = sub A y if x ≠y
c) sub A x = x if x ∉DA
d) hat (sub (x ≐s :: A)) t = hat (sub A) t if x ≠V t
e) hat (sub A) s = s if DA ∥V s
f) s x
t = hat (sub [x ≐t]) s
Exercise 9.6.3 (Fully Solved Equation Lists)
Consider the following inductive deﬁnition of fully solved equation lists:
fsolved nil
x ∉V s
x ∉V A
V s ∥DA
fsolved A
fsolved (x ≐s :: A)
a) Show that every fully solved equation list is solved.
b) Give a solved equation list that is not fully solved.
c) Convince yourself that every fully solved reﬁnement of the solved list
An = [x1 ≐x0 · x0; x2 ≐x1 · x1; . . . ; xn+1 ≐xn · xn]
is exponentially larger than An.
150
2014-7-16

9.7 Notes
d) Let A be fully solved. Prove that hat (sub A) is a principal uniﬁer of A.
e) Let A be fully solved and x ≐s ∈A. Prove that DA and V s are disjoint.
f) Deﬁne a function unfold that reﬁnes solved lists into fully solved lists. Prove
the following for your function unfold:
i)
If A is solved, then A ⊲unfold A.
ii) If A is solved, then D(unfold A) = DA.
iii) If A is fully solved, x ∉DA, and DA ∥V s, then Ax
s is fully solved.
iv) If A is solved, then unfold A is fully solved.
Exercise 9.6.4 (Exponential Running Time)
Consider the solved equation list An from Exercise 9.6.3. Convince yourself that
the function solve from the previous section yields a fully solved reﬁnement
of An that is exponentially larger than An. This suggests that solve has exponen-
tial running time.
Exercise 9.6.5 (Extensional Representation of Finite Substitutions)
Two equation lists A and B are substitution equivalent if sub A x = sub B x
for every variable x. Deﬁne a predicate fsubst on equation lists that ﬁxes unique
normal forms for substitution equivalence.
a) Prove that two equation lists satisfying fsubst are equal if they are substitu-
tion equivalent.
b) Deﬁne a function that for every equation list yields a substitution equivalent
equation list satisfying fsubst.
The proofs for this exercise require considerable eﬀort and provide for an inter-
esting project. Auxiliary lemmas will be needed.
9.7 Notes
Syntactic uniﬁcation was identiﬁed by Robinson [17] in 1965 as base algorithm
of his resolution calculus designed for automated theorem proving. Syntactic
uniﬁcation was rediscovered several times for other applications, for instance by
Knuth and Bendix [11] for critical pair analysis of term rewriting systems, and by
Milner [14] for polymorphic type inference. The uniﬁcation rules and the view
of syntactic uniﬁcation as equation solving appear in the work of Martelli and
Montanari [13].
Papers on syntactic uniﬁcation include Martelli and Montanari [13], Baader
and Snyder [1], Jaﬀar and Lassez [12], and Eder [2]. Baader and Snyder [1] also
cover uniﬁcation modulo equational theories.
2014-7-16
151

9 Syntactic Uniﬁcation
Robinson’s initial uniﬁcation algorithm [17] has exponential runtime (as does
the naive algorithm developed in this chapter).
Martelli and Montanari [13]
present a quasi-linear uniﬁcation algorithm. Uniﬁability can be decided in lin-
ear time [15].
Paulson [16] reports about an early formal veriﬁcation of the uniﬁcation al-
gorithm in LCF. Ruiz-Reina et al [18] have formally veriﬁed an eﬃcient quadratic
unﬁcation algorithm in ACL2.
152
2014-7-16

10 Propositional Entailment
Propositional logic is a logical system for propositional formulas. Propositional
formulas consist of atomic propositions (e.g., propositional variables, ⊥and ⊤)
and are closed under logical connectives (e.g., implication, conjunction and dis-
junction). In this chapter we will restrict ourselves to propositional logic with
propositional variables and ⊥and closed under implication. The systems and re-
sults can be extended to include other connectives, but we leave such extensions
to exercises.
We will ﬁrst study the type of propositional formulas. Next we consider the
general notion of an entailment relation and properties an entailment relation
may have. We then deﬁne a particular entailment relation by giving a natural
deduction style proof system for intuitionistic propositional logic. The natural
deduction system will correspond closely to the proof system in Coq. We next
consider a classical natural deduction style proof system. We will prove a result
of Glivenko: a propositional formula is classically provable if and only if its
double negation is intuitionistically provable. We will ﬁnally consider a Hilbert
style proof system and prove the equivalence of the natural deduction system
and the Hilbert system.1
10.1 Propositional Formulas
We now deﬁne (propositional) formulas given by the following grammar where
x ranges over variables and s and t range over propositional formulas.
s, t ::= x | ⊥| s →t
We would like to have inﬁnitely many variables. In addition, we would like equal-
ity of variables to be decidable. A natural way to ensure both is to use natural
numbers to represent variables. We use var be the type of variables (which is
deﬁned to be nat). After ﬁxing the representation of variables, we can represent
propositional formulas in Coq using an inductive type in the usual way. Essen-
tially formulas are binary trees where each node with children is an implication
s →t (with a child for s and a child for t) and each leaf is either ⊥or a variable x.
1 Proof systems are often called “calculi.” In this context, “calculus” is a synonym for “system.”
153

10 Propositional Entailment
Just as in Coq, we consider ¬s as meaning s →⊥. Note that equality of formulas
is decidable.
We can compute a list of the variables which occur in a formula as follows.
The function is deﬁned by recursion over formulas. Note that when computing
the variables in s →t we make two recursive calls: one for s and one for t. We
done the list of variables of a formula s by V s.
We can map formulas to booleans in an obvious way. To handle variables we
need assignments. An assignment is a function from var to bool. We deﬁne when
an assignment ϕ satisﬁes a formula s by recursion on s as follows:
1. ϕ satisﬁes x if ϕx = true.
2. ϕ satisﬁes s1 →s2 if ϕ satisﬁes s1 implies ϕ satisﬁes s2.
3. No assignment satisﬁes ⊥.
The satisﬁes predicate can be easily proven decidable by induction on the for-
mula.
Exercise 10.1.1 Prove the following goal.
Goal ∃f: assn, satis f (Not (Imp (Var 0) (Var 1))).
Exercise 10.1.2 Prove the following goal.
Goal ∀f: assn, ∀s:form, satis f (Imp (Not (Not s)) s).
Exercise 10.1.3 Prove the following goal.
Goal ∀f: assn, ∀s t:form, satis f (Imp (Imp (Imp s t) s) s).
10.2 Structural Properties of Entailment Relations
In this section we will consider the general notion of an entailment relation and
deﬁne structural properties an entailment relation may satisfy.
When an en-
tailment relation holds for a list A of assumed formulas and a formula s, the
intention is that the formula s is a logical consequence of the assumptions in A.
For the entailment relations considered in this section, we need not commit to
propositional formulas, but can work with a general type F instead of the type
of propositional formulas.
Suppose F is a type.
An entailment relation for F is a predicate of type
list F
→
F →
Prop.
Suppose E is an entailment relation for F.
We write
A ⊢s when a given entailment relation holds between a list A of formulas and a
formula s. The symbol ⊢is a “turnstile.” We write A ̸⊢s to mean the negation of
A ⊢s. When A is empty, we may write ⊢s.
154
2014-7-16

10.2 Structural Properties of Entailment Relations
Several properties of an entailment relation can be stated without using spe-
cial properties of the type F of formulas. These are called structural properties.
We deﬁne four structural properties in this section.
We say an entailment relation is monotone if A′ ⊢s holds whenever A ⊢s
holds and A ⊆A′. That is, if s is a logical consequence of the assumptions in A,
then it remains a logical consequence if we add more assumptions to A.
We say the entailment relation is reﬂexive if A ⊢s whenever s ∈A. That is,
each assumed formula in A is a logical consequence of A.
We say the entailment relation satisﬁes cut if A ⊢s and A, s ⊢t imply A ⊢t.
That is, if we extend A with logical consequences of A, then we do not obtain
new logical consequences.
Finally, we say the entailment relation is consistent if there is some s such
that ̸⊢s.
We give one simple example of an entailment relation. The exercises at the
end of this section give a few more examples.
We will deﬁne an entailment relation for Prop. That is, we will give a predicate
of type list Prop →Prop →Prop. We start by recursively deﬁning a function
which forms a conjunction from a list of propositions.
Fixpoint andlist (A:list Prop) : Prop :=
match A with
| P::A’ ⇒P ∧andlist A’
| nil ⇒⊤
end.
The following property can easily be proven by induction on the list A.
Lemma andlistEq (A:list Prop) : andlist A ↔∀s, s ∈A →s.
Consider the entailment relation A ⊢s for Prop deﬁned by andlist A →s. The
four structural properties can be easily veriﬁed using the lemma.
The only entailment relations we will consider after the exercises below will
be for propositional formulas. That is, after this section we will only consider
entailment relations for the type form.
Exercise 10.2.1 Consider the entailment relation A ⊢s for bool which holds if s
either s is true or if false ∈A. Prove the four structural properties hold.
Goal
let E : list bool →bool →Prop := fun A s ⇒if s then ⊤else false ∈A in
Reﬂexivity E ∧Monotonicity E ∧Cut E ∧Consistency E.
Exercise 10.2.2 Let X be an inhabited type.
Consider the entailment relation
A ⊢s for X →Prop deﬁned by ∀x : X, (∀P, P ∈A →Px) →sx. Prove the four
structural properties hold.
2014-7-16
155

10 Propositional Entailment
Goal ∀X:Type, inhabited X →
let E : list (X →Prop) →(X →Prop) →Prop
:= fun A s ⇒forall x:X, (∀P, P ∈A →P x) →s x in
Reﬂexivity E ∧Monotonicity E ∧Cut E ∧Consistency E.
Exercise 10.2.3 Consider the entailment relation A ⊢s for nat deﬁned by
∃n.n ∈A ∧s ≤n. Prove the four structural properties hold.
Goal
let E : list nat →nat →Prop := fun A s ⇒exists n, n ∈A ∧s ≤n in
Reﬂexivity E ∧Monotonicity E ∧Cut E ∧Consistency E.
Exercise 10.2.4 Let F be a type.
Consider the entailment relation deﬁned by
list membership. Without extra assumptions, only three of the four structural
properties hold. Determine which of the three hold and prove them. For the one
which cannot be proven, choose a type F and prove the property fails for list
membership on your chosen type F.
10.3 Logical Properties of Entailment Relations
A context is a list of formulas.
Deﬁnition context := list form.
An entailment relation for formulas is a predicate of type context →form →
Prop.
For entailment relations for formulas we can now deﬁne the following
logical properties. The reader should compare these to the structural properties
deﬁned for generic entailment relations in the previous section. From now on
when we refer to an entailment relation, we will be referring to an entailment
relation for formulas.
We say an entailment relation satisﬁes the characteristic property of →if
A ⊢s →t is equivalent to A, s ⊢t.
We say an entailment relation satisﬁes the characteristic property of ⊥if
A ⊢⊥is equivalent to forall s, A ⊢s.
Suppose we are working with a reﬂexive entailment relation which satisﬁes
the characteristic properties of →and ⊥. Let s and t be formulas. We can prove
⊢s →¬s →t as follows. First, using the characteristic property of →twice it is
enough to prove s, ¬s ⊢t. Using the characteristic property of ⊥it is enough to
prove s, ¬s ⊢⊥. Using the characteristic property of →in the other direction it
is enough to prove ¬s ⊢s →⊥. We know ¬s ⊢s →⊥by reﬂexivity.
We can use boolean assignments to deﬁne the following entailment relation
which we call boolean semantic consequence: A ⊨s holds if for every assign-
ment ϕ, if ϕ satisﬁes every element of A, then ϕ satisﬁes s.
156
2014-7-16

10.4 Variables and Substitutions
Exercise 10.3.1 Prove ⊨(boolean semantic consequence) satisﬁes all the struc-
tural properties deﬁned in the previous section and the two logical properties
deﬁned in this section.
Exercise 10.3.2 Prove that if E satisﬁes the characteristic properties of →and ⊥
also satisﬁes the following characteristic property of ¬.
Goal ∀E, CharImp E →CharFal E →∀A s, E A (Not s) ↔∀t, E (s::A) t.
Exercise 10.3.3 Prove the following.
Goal ∀E, Cut E →CharImp E →∀A s t, E A (Imp s t) →E A s →E A t.
Exercise 10.3.4 Prove that if an entailment relation is reﬂexive and satisﬁes the
characteristic property of →, then it is nonempty. In particular, prove there is a
formula s such that ⊢s.
Lemma Reﬂexivity_CharImp_nonempty E :
Reﬂexivity E →CharImp E →∃s, E nil s.
Exercise 10.3.5 We say a formula is closed if it contains no variables. We can
deﬁne this in Coq as follows.
Inductive closed : form →Prop :=
| closedFal : closed Fal
| closedImp s t : closed s →closed t →closed (Imp s t).
Suppose ⊢is a reﬂexive entailment relation satisfying cut and the characteristic
properties of →and ⊥. Prove for all closed formulas s we either have A ⊢s (for
every context A) or A ⊢¬s (for every context A).
Lemma ReﬂexivityCutChar_closed_or E s :
Reﬂexivity E →Cut E →CharImp E →CharFal E →
closed s →(∀A, E A s) ∨(∀A, E A (Not s)).
10.4 Variables and Substitutions
Variables are intended to be placeholders which can, for example, be substituted
with arbitrary formulas. A substitution is a mapping σ from variables to formu-
las. By recursion on formulas we can deﬁne a substitution operation lifting the
action of σ on variables to all formulas.
Fixpoint subst (σ : var →form) (s : form) : form :=
match s with
| Var x ⇒σ x
2014-7-16
157

10 Propositional Entailment
| Imp s t ⇒Imp (subst σ s) (subst σ t)
| Fal ⇒Fal
end.
We will write σs for subst σ s.
We say an entailment relation respects substitution if σA ⊢σs whenever
A ⊢s.
Exercise 10.4.1 Prove that if two substitutions σ1 and σ2 agree on the variables
which occur in s, then σ1s = σ2s.
Exercise 10.4.2 Consider the following function emb from form to Prop.
Fixpoint emb (s : form) : Prop :=
match s with
| Var x ⇒⊥
| Imp s1 s2 ⇒emb s1 →emb s2
| Fal ⇒⊥
end.
Prove the entailment relation λAs.(∀t.t ∈A →emb t) →emb t has all the
properties except that it does not respect substitution.
Goal
let E : list form →form →Prop := fun A s ⇒(∀t, t ∈A →emb t) →emb s in
Reﬂexivity E ∧Monotonicity E ∧Cut E ∧Consistency E
∧CharImp E ∧CharFal E
∧¬ Substitution E.
Exercise 10.4.3 Prove that if two entailment relations are extensionally the same
and one satisﬁes all the properties, then so does the other.
Lemma EntailRelAllProps_ext E E’ :
EntailRelAllProps E →(∀A s, E A s ↔E’ A s) →EntailRelAllProps E’.
10.5 Natural Deduction System
In this section we consider our ﬁrst proof system for propositional formulas.
A proof system deﬁnes when a formula s is provable from a context A.
We
write A ⊢s to mean s is provable from A in the particular proof system under
discussion. Note that ⊢is an entailment relation on A and s and we will prove
it has all the properties discussed in the previous sections. In fact, it will be the
least relation satisfying those properties.
Deduction rules for logical connectives were given in Figure 2.1. The intro-
duction and elimination rules for →together with the elimination rule for ⊥
158
2014-7-16

10.5 Natural Deduction System
A
A ⊢s
s ∈A
II
A, s ⊢t
A ⊢s →t
IE
A ⊢s →t
A ⊢s
A ⊢t
E
A ⊢⊥
A ⊢s
Figure 10.1: Natural Deduction Rules
essentially give a proof system for propositional formulas. We use contexts (lists
of formulas) to represent the collection of assumptions. Note that the introduc-
tion rule for →changes the assumptions and this corresponds to changing the
context. We can check if a formula is an assumption in the context using an
assumption rule to check if the formula is an element of the list. These rules are
given in Figure 10.1.
The rules in Figure 10.1 deﬁne when A ⊢s in the system N . That is, the rules
deﬁne when s is provable from A in N . One can use the rules in Figure 10.1 to
justify A ⊢s.
Consider the following example.
Example 10.5.1 Let A be a context and s and t be formulas. We can use the rules
of N to derive A ⊢s →¬s →t as follows:
II
II
E
IE
A
A, s, ¬s ⊢s →⊥
A
A, s, ¬s ⊢s
A, s, ¬s ⊢⊥
A, s, ¬s ⊢t
A, s ⊢¬s →t
A ⊢s →¬s →t
We can represent the natural deduction system N in Coq as an inductive
predicate nd. The proposition nd A s is provable precisely when A ⊢s. Note
that A is a nonuniform parametric argument of nd and s is a nonparametric
argument of nd.
Inductive nd : context →form →Prop :=
| ndA A s :
s ∈A →nd A s
| ndII A s t :
nd (s::A) t →nd A (Imp s t)
| ndIE A s t : nd A (Imp s t) →nd A s →nd A t
| ndE A s :
nd A Fal →nd A s.
We can now reconsider Example 10.5.1 as a proof in Coq. Compare the Coq
proof script with the diagram in Example 10.5.1.
Goal ∀A s t, nd A (Imp s (Imp (Not s) t)).
2014-7-16
159

10 Propositional Entailment
app
A ⊢s
A ⊢u
s →u ∈A
weak
A ⊢s
A′ ⊢s
A ⊆A′
W
A ⊢s
A, t ⊢s
IEweak
B ⊢s →t
B ⊆A
A ⊢s
A ⊢t
DN
A ⊢s
A ⊢¬¬s
Figure 10.2: Some Admissible Rules
Proof.
intros A s t. apply ndII, ndII. apply ndE. apply ndIE with (s := s).
−apply ndA. left. reﬂexivity.
−apply ndA. right. left. reﬂexivity.
Qed.
From now on we will tend to work at the mathematical level and leave the reader
to examine the available Coq version.
A rule is admissible in a proof system if adding the rule to the proof system
does not change what is provable in the system. This is equivalent to saying that
the conclusion of the rule is provable whenever the premises are provable. We
prove all the rules in Figure 10.5 are admissible in N .
We begin this process by proving admissibility of app. This rule allows us to
simulate Coq’s apply tactic. If an implication s →t is in the context A and we
want to prove A ⊢t, then it is enough to prove A ⊢s. Admissibility of app is
the content of the following lemma whose proof is simply a combination of the
IE and A rules.
A ⊢s →u
A ⊢s
A ⊢u
We will often do proofs by induction over A ⊢s, i.e., over the inductive pred-
icate nd. In the process of doing such an inductive proof we must consider each
of the four rules in Figure 10.1. Each rule has the form
A1 ⊢s1 · · · An ⊢sn
A ⊢s
for n ∈{0, 1, 2}. For such a rule we assume the desired property for Ai and si
as inductive hypotheses and prove the desired property for A and s. In Coq the
induction principle of nd corresponds to the type of nd_ind:
160
2014-7-16

10.5 Natural Deduction System
Check (nd_ind :
∀p : context →form →Prop,
(∀(A : context) (s : form), s ∈A →p A s) →
(∀(A : context) (s t : form), nd (s :: A) t →p (s :: A) t →p A (Imp s t)) →
(∀(A : context) (s t : form), nd A (Imp s t) →p A (Imp s t) →nd A s →p A s →p A t) →
(∀(A : context) (s : form), nd A Fal →p A Fal →p A s) →
∀(A : context) (s : form), nd A s →p A s).
Note that the induction principle makes precise that we must prove a case for
each rule in Figure 10.1 and what inductive hypotheses we obtain in each case.
We can also visualize these four proof obligations in the form of rules.
A
p A s
s ∈A
II
A, s ⊢t
(IH) p (A, s) t
p A (s →t)
IE
A ⊢s →t
A ⊢s
(IH) p A (s →t)
(IH) p A s
p A t
E
A ⊢⊥
(IH) p A ⊥
p A s
In each case we must prove the conclusion using the premises (including the
inductive hypotheses) and the side conditions as assumptions.
Our ﬁrst such inductive proof will be monotonicity of ⊢: if A ⊆A′ and A ⊢s,
then A′ ⊢s. In other words, we prove the rule weak in Figure 10.5 is admissible.
The rule weak is often called the weakening rule.
Here the desired property of A and s we wish to prove by induction is
∀A′, A ⊆A′ →A′ ⊢s. We prove by induction that A and s have this desired
property whenever A ⊢s.
Lemma nd_weak A A’ s :
A ⊆A’ →nd A s →nd A’ s.
Proof We argue by induction on the proof of A ⊢s and consider each rule care-
fully. Future mathematical proofs will not be given at this level of detail.
Consider the assumption rule A:
A
A ⊢s
s ∈A
Note that in this case s ∈A. We must prove ∀A′, A ⊆A′ →A′ ⊢s. Assume
A ⊆A′. Hence s ∈A′ and so A′ ⊢s by the assumption rule.
Consider the introduction rule II for implication:
II
A, s ⊢t
A ⊢s →t
2014-7-16
161

10 Propositional Entailment
We must prove ∀A′, A ⊆A′ →A′ ⊢s →t. The inductive hypothesis is ∀A′, A, s ⊆
A′ →A′ ⊢t. Assume A ⊆A′. Clearly A, s ⊆A′, s. By the inductive hypothesis we
know A′, s ⊢t. Hence A′ ⊢s →t by II.
Consider the elimination rule IE for implication:
IE
A ⊢s →t
A ⊢s
A ⊢t
We must prove ∀A′, A ⊆A′ →A′ ⊢t. Since there are two premises, there are two
inductive hypotheses. The ﬁrst inductive hypothesis is ∀A′, A ⊆A′ →A′ ⊢s →t.
The second inductive hypothesis is ∀A′, A ⊆A′ →A′ ⊢s. Assume A ⊆A′. By
the inductive hypotheses we know A′ ⊢s →t and A′ ⊢s. Hence A′ ⊢t by IE.
Consider the elimination rule E for ⊥:
E
A ⊢⊥
A ⊢s
We must prove ∀A′, A ⊆A′ →A′ ⊢s. The inductive hypothesis is ∀A′, A ⊆A′ →
A′ ⊢⊥. Assume A ⊆A′. By the inductive hypotheses we know A′ ⊢⊥and so
A′ ⊢s by E.
■
As an obvious corollary, we know that A, t ⊢s whenever A ⊢s. That is, the
following rule is admissible:
W
A ⊢s
A, t ⊢s
We could also obtain corollaries which combine weakening with the deﬁning
rules of the calculus. We will only do so for IE: If B ⊢s →t, B ⊆A and A ⊢s,
then A ⊢t. That is, we have admissibility of the following rule:
IEweak
B ⊢s →t
B ⊆A
A ⊢s
A ⊢t
Finally we can use II, app and W to prove that if A ⊢s, then A ⊢¬¬s. That is,
the following rule is admissible. We leave the details to the reader.
DN
A ⊢s
A ⊢¬¬s
It turns out that A ⊢s is decidable, but we do not yet have the tools to prove
this. The decidability proof will come later.
Exercise 10.5.2 Prove the following goals.
162
2014-7-16

10.6 Classical Natural Deduction
Goal ∀A s, nd A (Imp s s).
Goal ∀A s, nd A (Imp Fal s).
Goal ∀A s t, nd A (Imp s (Imp t s)).
Goal ∀A s t, nd A (Imp (Imp s t) (Imp (Not t) (Not s))).
Exercise 10.5.3 Prove that ⊢respects substitution.
Lemma nd_subst A s σ : nd A s →nd (map (subst σ) A) (subst σ s).
Exercise 10.5.4 Prove the following soundness result for N relative to boolean
semantic consequence: If A ⊢s, then A ⊨s. Use the result to conclude consis-
tency of ⊢.
Exercise 10.5.5 Prove ⊢has all the properties of entailment relations deﬁned
earlier.
Lemma nd_EntailRelAllProps : EntailRelAllProps nd.
Exercise 10.5.6 Prove nd is the least reﬂexive entailment relation satisfying cut
and the characteristic properties of →and ⊥.
Lemma nd_least_EntailRelAllProps (E : context →form →Prop) :
Reﬂexivity E →Cut E →CharImp E →CharFal E →∀A s, nd A s →E A s.
Exercise 10.5.7 Extend the formulas and natural deduction system to include
conjunction and disjunction.
Exercise 10.5.8 Prove the following two lemmas.
Lemma ndassert (A : context) (s u : form) :
nd A s →nd (s::A) u →nd A u.
Lemma ndappbin (A : context) (s t u : form) :
Imp s (Imp t u) ∈A →nd A s →nd A t →nd A u.
10.6 Classical Natural Deduction
We now consider classical propositional logic. Classical propositional logic can
prove formulas such as instances of double negation ¬¬s →s and instances of
Peirce’s law ((s →t) →s) →s. The propositional formulas provable in classi-
cal propositional logic correspond to those which evaluate to true under every
boolean assignment, if one interprets ⊥as false and interprets implication by
truth tables (i.e., implb in the Coq library).
2014-7-16
163

10 Propositional Entailment
A
A ⊢s
s ∈A
II
A, s ⊢t
A ⊢s →t
IE
A ⊢s →t
A ⊢s
A ⊢t
C
A, ¬s ⊢⊥
A ⊢s
Figure 10.3: Classical Natural Deduction Rules
The classical natural deduction system NC is deﬁned by the rules in Fig-
ure 10.3. Note that the diﬀerence from the previous system is that the elimi-
nation rule E for ⊥has been replaced by the contradiction rule C. In Coq, the
classical natural deduction system can be deﬁned as an inductive predicate ndc
as usual.
All the rules from Figure 10.5 are admissible in the classical system NC. In
each case admissibility can be proven using the same strategy as admissibility of
the rule in N . We leave the details to the reader.
Since we have omitted the elimination rule for ⊥, a natural question is whether
we can infer A ⊢s from A ⊢⊥. That is, one may ask if the E rule (a deﬁning rule
for N ) is admissible in the system NC. We can prove admissibility of E in NC
easily using the contradiction rule and weakening.
A ⊢⊥
A, ¬s ⊢⊥
A ⊢s
Now we have enough information to know A ⊢s in N implies A ⊢s in NC.
The proof is by a simple induction on the proof of A ⊢s in N .
Theorem 10.6.1 If A ⊢s in N , then A ⊢s in NC.
Proof We argue by induction on A ⊢s. In every case except the explosion rule,
we can directly use the corresponding rule in NC. In the case of the explosion
rule, we can use the fact that the explosion rule is admissible in NC.
■
Finally we prove A ⊢s if and only if A, ¬s ⊢⊥. That is, in NC it is enough to
consider refutability of contexts.
Theorem 10.6.2 A ⊢s in NC if and only if A, ¬s ⊢⊥in NC.
Proof Suppose A ⊢s. By weakening know A, ¬s ⊢s. By A we know A, ¬s ⊢¬s.
By IE we conclude A, ¬s ⊢⊥as desired.
For the other direction, suppose A, ¬s ⊢⊥. We can conclude A ⊢s simply
using the contradiction rule (C).
■
164
2014-7-16

10.7 Glivenko’s Theorem
Exercise 10.6.3 Prove A ⊢¬¬s →s.
Goal ∀A s, ndc A (Imp (Not (Not s)) s).
Exercise 10.6.4 Prove the following lemmas for NC.
Lemma ndcA2 A s t :
ndc (t :: s :: A) s.
Lemma ndcapp A s u :
Imp s u ∈A →ndc A s →ndc A u.
Lemma ndcapp1 A s u :
ndc (Imp s u :: A) s →ndc (Imp s u :: A) u.
Lemma ndcapp2 A s t u :
ndc (t :: Imp s u :: A) s →ndc (t :: Imp s u :: A) u.
Lemma ndcapp3 A s t u v :
ndc (t :: v :: Imp s u :: A) s →ndc (t :: v :: Imp s u :: A) u.
Use the lemmas above to prove A ⊢((s →t) →s) →s. That is, prove Peirce’s
Law.
Goal ∀A s t, ndc A (Imp (Imp (Imp s t) s) s).
Exercise 10.6.5 Prove ⊢is closed under substitution.
Lemma ndc_subst A s σ : ndc A s →ndc (map (subst σ) A) (subst σ s).
Exercise 10.6.6 Prove the following result.
Lemma ndc_eval_xm_sound A s (e:form →Prop) :
XM →
¬e Fal →(∀t u, e (Imp t u) ↔e t →e u) →
ndc A s →(∀t, t ∈A →e t) →e s.
10.7 Glivenko’s Theorem
Glivenko’s Theorem states that a propositional formula s is classically provable if
and only if its double negation is intuitionistically provable. The most interesting
half of this equivalence is that ¬¬s is intuitionistically provable if s is classically
provable. In particular, if A ⊢s, then A ⊢¬¬s. We prove this implication by
induction on the proof of A ⊢s. We leave the converse implication as an exercise.
Theorem 10.7.1 (Glivenko) If A ⊢s in NC, then A ⊢¬¬s in N .
2014-7-16
165

10 Propositional Entailment
Proof We prove this by induction on the proof of A ⊢s. We will use the admissi-
ble rules DN, app and IEweak from Figure 10.5 as well as the usual rules deﬁning
N .
For the assumption rule we assume we have s ∈A and need to prove A ⊢¬¬s
in N . We easily have this by the admissible rule DN and the assumption rule.
For implication introduction we know A, s ⊢¬¬t in N by the inductive hy-
pothesis. From this we can derive A ⊢¬¬(s →t) in N using the admissible
rules app and IEweak (along with the usual N rules) as follows:
IH
A, s ⊢¬¬t
A, ¬(s →t), s, t, s ⊢t
A, ¬(s →t), s, t ⊢s →t
A, ¬(s →t), s, t ⊢⊥
A, ¬(s →t), s ⊢¬t
A, ¬(s →t), s ⊢⊥
A, ¬(s →t), s ⊢t
A, ¬(s →t) ⊢s →t
A, ¬(s →t) ⊢⊥
A ⊢¬¬(s →t)
For IE we know A ⊢¬¬(s →t) and A ⊢¬¬s in N by the inductive hypothe-
ses. From this we can derive A ⊢¬¬t using the admissible rules app and IEweak
(along with the usual N rules) as follows:
IH
A ⊢¬¬s
IH
A ⊢¬¬(s →t)
A, ¬t, s, s →t ⊢s
A, ¬t, s, s →t ⊢t
A, ¬t, s, s →t ⊢⊥
A, ¬t, s ⊢¬(s →t)
A, ¬t, s ⊢⊥
A, ¬t ⊢¬s
A, ¬t ⊢⊥
A ⊢¬¬t
For the contradiction rule we know A, ¬s ⊢¬¬⊥in N by the inductive hy-
166
2014-7-16

10.7 Glivenko’s Theorem
pothesis. From this we can derive A ⊢¬¬s in N as follows:
IH
A, ¬s ⊢¬¬⊥
A, ¬s, ⊥⊢⊥
A, ¬s ⊢¬⊥
A, ¬s ⊢⊥
A ⊢¬¬s
As a consequence of Glivenko’s theorem, we can prove that refutability in N
is equivalent to refutability in NC.
Corollary 10.7.2 A ⊢⊥in N if and only if A ⊢⊥in NC.
Proof We know A ⊢⊥in N implies A ⊢⊥in NC by Theorem 10.6.1. For the
other direction, suppose A ⊢⊥in NC. By Glivenko (Theorem 10.7.1) we know
A ⊢¬¬⊥. However, from A ⊢¬¬⊥it is easy to derive A ⊢⊥as follows:
A ⊢¬¬⊥
A, ⊥⊢⊥
A ⊢¬⊥
A ⊢⊥
A further consequence is that A ⊢s in NC if and only if A, ¬s ⊢⊥in N .
Corollary 10.7.3 A ⊢s in NC if and only if A, ¬s ⊢⊥in N .
Proof By Theorem 10.6.2 we know A ⊢s in NC if and only if A, ¬s ⊢⊥in NC.
By Corollary 10.7.2 we know A, ¬s ⊢⊥in NC if and only if A, ¬s ⊢⊥in N .
Hence we have the desired equivalence.
■
Exercise 10.7.4 Prove the easy half of Glivenko’s theorem.
Lemma Glivenko_converse A s :
nd A (Not (Not s)) →ndc A s.
Exercise 10.7.5 Prove the following consequence of Glivenko’s theorem.
Goal ∀A, ¬ ∃s, ndc A (Not s) ∧¬ nd A (Not s).
Exercise 10.7.6 Prove consistency of ⊢.
Lemma ndc_con : ¬ ndc nil Fal.
Exercise 10.7.7 Prove ndc has all the properties of entailment relations deﬁned
earlier.
Lemma ndc_EntailRelAllProps : EntailRelAllProps ndc.
2014-7-16
167

10 Propositional Entailment
A
s
s ∈A
K
s →t →s
S
(s →t →u) →(s →t) →s →u
E
⊥→u
MP
s →t
s
t
Figure 10.4: Hilbert Rules for Intuitionistic Propositional Logic
10.8 Hilbert System
The natural deduction systems require assumption management. In particular
the implication introduction rule II changes the assumptions. It turns out that we
can omit the implication introduction rule if we replace it with a number of initial
rules – i.e., rules with no premises. One initial rule states that every formula of
the form s →t →s is provable. We call such a formula a K-formula. Another
initial rule states that every formula (s →t →u) →(s →t) →s →u is provable.
Such formulas are called S-formulas. Doing this would yield a system in which
only two rules have premises: a rule like IE and a rule like E. Indeed we can
deﬁne a system in which the only rule with premises is a rule known as modus
ponens which has the same form as IE since we can replace the E rule with an
initial rule stating that every explosion formula (i.e., formula of the form ⊥→s)
is provable. Such systems are called Hilbert systems. The rules in Figure 10.4
deﬁne our Hilbert system for intuitionistic propositional logic, which refer to
by the name H . In particular, we have A ⊢s in system H when s is derivable
from context A using the rules in Figure 10.4.
We can deﬁne this in Coq as an inductive predicate hil in the usual way.
We can easily prove by induction that if A ⊢s in H , then A ⊢s in N .
Lemma 10.8.1 If A ⊢s in H , then A ⊢s in N .
Proof We argue by induction on the proof of A ⊢s in H . We must argue a
case for each rule in Figure 10.4. If s ∈A, then we know A ⊢s in N by A.
The next three cases involve proving K-formulas, S-formulas and formulas of
the form ⊥→s in N . Each of these cases is easy. Finally, we consider the modus
ponens case. Assume A ⊢s →t and A ⊢s in H . The inductive hypotheses yield
A ⊢s →t and A ⊢s in N . We conclude A ⊢t in N using IE.
■
Note that in each case of the inductive proof, we have proven one of the deﬁning
rules of H is admissible in N .
168
2014-7-16

10.8 Hilbert System
The converse also holds: If A ⊢s in N , then A ⊢s in H .
In order to
prove this, we ﬁrst prove an important result called the deduction theorem. The
deduction theorem states that if A, s ⊢t, then A ⊢s →t. In other words, the
II rule (a deﬁning rule of the system N ) is admissible in H . The proof is by
induction on the proof of A, s ⊢t using the results above.
Theorem 10.8.2 (Deduction Theorem) If A, s ⊢t, then A ⊢s →t.
Proof We prove this by induction on the proof of A, s ⊢t.
There are three
possible cases to consider.
•
Suppose t ∈A, t is a K-formula, t is an S-formula or t is an explosion formula.
In any of these cases A ⊢t and A ⊢t →s →t. Hence A ⊢s →t.
•
Suppose t is s. We need to prove A ⊢s →s.
This follows from the fact
that (s →(s →s) →s) →(s →s →s) →s →s is an S-formula while
s →(s →s) →s and s →s →s are K-formulas.
•
Suppose A, s ⊢u →t and A, s ⊢u. By the inductive hypothesis A ⊢s →u →t
and A ⊢s →u.
In order to see that A ⊢s →t it suﬃces to note that
(s →u →t) →(s →u) →s →t is an S-formula.
■
We can now prove A ⊢s in N implies A ⊢s in H . The proof is by induction
on the proof of A ⊢s in N . The deduction theorem is used for the II-case. The
remaining cases are straightforward.
Lemma 10.8.3 If A ⊢t in N , then A ⊢t in H .
Proof We must argue a case for each rule in Figure 10.1. For the A case we must
prove A, s ⊢s in H .
We know this by A since s ∈A, s.
For the IE case the
inductive hypotheses give A ⊢s →t and A ⊢s in H . We conclude A ⊢t in H
using MP. For the E case the inductive hypothesis gives A ⊢⊥in H . We conclude
A ⊢s in H using the following derivation.
MP
E
A ⊢⊥→s
A ⊢⊥
A ⊢s
For the II case we use the deduction theorem (Theorem 10.8.2).
■
Combining the results we know A ⊢s in H if and only if A ⊢s in N .
Theorem hil_iﬀ_nd A s :
hil A s ↔nd A s.
Exercise 10.8.4 Prove the following form of weakening for the Hilbert calculus.
2014-7-16
169

10 Propositional Entailment
A
A ⊢s
s ∈A
II
A, s ⊢t
A ⊢s →t
IE
A ⊢s →t
A ⊢s
A ⊢t
E
A ⊢⊥
A ⊢s
WXM
A, ¬s ⊢t
A, ¬¬s ⊢t
A ⊢t
Figure 10.5: ND Rules for a logic with weak excluded middle
Lemma hilW A s t :
hil A t →hil (s::A) t.
Exercise 10.8.5 Prove the following.
Lemma hilassert A s u :
hil A s →hil (s::A) u →hil A u.
Exercise 10.8.6 Prove consistency of hil using the equivalence with nd.
Lemma hil_con : ¬ hil nil Fal.
Exercise 10.8.7 Use nd_hil, hil_nd and Exercise 10.4.3 to prove hil has all the
properties of entailment relations deﬁned earlier.
Lemma hil_EntailRelAllProps : EntailRelAllProps hil.
Exercise 10.8.8 Give a Hilbert calculus for classical propositional logic and de-
ﬁne a corresponding inductive predicate hilc in Coq. Prove the deduction the-
orem for hilc and use the deduction theorem to prove the equivalence between
hilc and ndc.
10.9 Intermediate Logics
An intermediate propositional logic is one that proves more than intuitionistic
propositional logic but less than classical propositional logic. It is not obvious
that such logics exist, but in fact they do. We will consider two examples.
Let ⊢be the entailment relation deﬁned by the rules in Figure 10.5.
The
formula (¬x →y) →(¬¬x →y) →y is not intuitionistically provable. On the
other hand, the rules in Figure 10.5 are enough to prove ⊢(¬x →y) →(¬¬x →
y) →y. Furthermore, ⊢is not full classical logic since we cannot prove double
negation in general: ̸⊢¬¬x →x.
170
2014-7-16

10.10 Remarks
A
A ⊢s
s ∈A
II
A, s ⊢t
A ⊢s →t
IE
A ⊢s →t
A ⊢s
A ⊢t
E
A ⊢⊥
A ⊢s
GD
A, s →t ⊢u
A, t →s ⊢u
A ⊢u
Figure 10.6: ND Rules for Gödel-Dummett Logic
Let ⊢be the entailment relation deﬁned by the rules in Figure 10.6.
The
formula ⊢((x →y) →z) →((y →x) →z) →z is not intuitionistically provable.
The rules in Figure 10.6 above are enough to prove ⊢((x →y) →z) →((y →
x) →z) →z. Again, we cannot prove double negation in general: ̸⊢¬¬x →
x. Hence ⊢is again an entailment relation strictly between intuitionistic and
classical logic.
10.10 Remarks
The ﬁrst deduction systems developed by Frege in 1879 [3] were in the Hilbert
style. (Hilbert studied and popularized such systems later.) Natural deduction
systems were created independently by Gentzen [4] and Ja´skowski in the 1930s.
The Glivenko result was published in 1929 [8] (before the invention of natural
deduction).
2014-7-16
171

10 Propositional Entailment
172
2014-7-16

11 Classical Tableau Method
In this chapter we show that a propositional formula is classically provable if
and only if it is satisﬁed by all boolean assignments. We obtain this result with a
method known as classical tableau method. Given a formula, the method decides
whether the formula is satisﬁable. If the formula is satisﬁable, the method yields
a satisfying assignment. If the formula is unsatisﬁable, the method yields a proof
of the negation of the formula in a classical calculus.
11.1 Boolean Evaluation and Satisﬁability
A boolean assignment is a function that maps every variable to a boolean value.
Given a boolean assignment, we can evaluate every propositional formula to a
boolean value. We will use α and β as names for boolean assignments:
α, β : assn := var →B
We formalize the evaluation of propositional formulas with a function eval :
assn →form →B deﬁned by recursion on formulas:
eval α x := αx
eval α (Imp s t) := if eval α s then eval α t else true
eval α Fal := false
Note that the evaluation of an implication is deﬁned with a boolean conditional
such that an implication s →t evaluates to true if and only if either both con-
stituents s and t evaluate to true or s evaluates to false.
We say that an assignment satisﬁes a formula if the formula evaluates to
true with the assignment. We say that an assignment dissatisﬁes a formula if it
does not satisfy the formula. An assignment dissatisﬁes a formula if and only
if the formula evaluates to false with the assignment. Moreover, an assignment
dissatisﬁes a formula if and only if it satisﬁes the negation of the formula.
A propositional formula is satisﬁable if there is a boolean assignment under
which it evaluates to true. A formula is unsatisﬁable if it is not satisﬁable.
Formally, we will work with an alternative characterization of boolean satis-
faction, which employs a function ⊨mapping an assignment α and a formula s
173

11 Classical Tableau Method
to a proposition equivalent to eval α s = true.
α ⊨x := if αx then ⊤else ⊥
α ⊨Imp s t := α ⊨s →α ⊨t
α ⊨Fal := ⊥
The symbol ⊨is pronounced double turnstile. By induction on s it follows that
the function ⊨captures boolean satisfaction:
Fact 11.1.1 α ⊨s ↔eval α s = true.
From the equivalence it follows that α ⊨s is decidable.
Fact 11.1.2 α ⊨s is decidable.
Here is the formal deﬁnition of satisﬁability we will work with:
sat s := ∃α. α ⊨s
Exercise 11.1.3 Prove Facts 11.1.1 and 11.1.2.
Exercise 11.1.4 Prove that α ⊨¬s and α ̸⊨s are deﬁnitionally equal.
Exercise 11.1.5 Prove the following:
a) α ⊨s →t ↔α ̸⊨s ∨α ⊨t
b) α ⊨¬(s →t) ↔α ⊨s ∧α ̸⊨t
c) α ⊨¬s ↔α ̸⊨s
d) α ⊨x ↔αx = true
e) α ⊨¬x ↔αx = false
Exercise 11.1.6 The function ⊨maps implications of formulas to implications
of propositions. This yields the right meaning since α ⊨s is decidable. You can
gain more insight into this phenomenon by proving the following equivalences
for a decidable proposition X and an arbitrary proposition Y.
a) X →Y ↔if [X\ then Y else ⊤
b) X ∧Y ↔if [X\ then Y else ⊥
c) X ∨Y ↔if [X\ then ⊤else Y
Exercise 11.1.7 Extend the development to formulas with native conjunctions
and disjunctions. Write a function that translates formulas to formulas with-
out conjunctions and disjunctions such that a formula and its translation are
satisﬁed by the same assignments.
174
2014-7-16

11.2 Validity and Boolean Entailment
11.2 Validity and Boolean Entailment
A formula is valid if it is satisﬁed by every assignment.
Fact 11.2.1 A formula is valid if and only if its negation is unsatisﬁable.
The fact is negation happy. If we spell it out, we obtain
(∀α. α ⊨s) ↔¬∃α. α ⊨s
Now remember that α ⊨¬s is deﬁnitionally equal to ¬(α ⊨s). With de Morgan
the right hand side of the equivalence becomes ∀α. ¬¬(α ⊨s). Since α ⊨s is
decidable, we can delete the double negation.
Fact 11.2.2 Every classically provable formula is valid.
Proof By induction on the formula using the classical Hilbert system.
■
We will eventually show that every valid formula is classically provable.
Using boolean assignments, we can deﬁne an entailment predicate we call
boolean entailment. It will turn out that boolean entailment agrees with classical
entailment. An assignment satisﬁes a list of formulas if it satisﬁes every formula
of the list:
α ⊨A := ∀s. s ∈A →α ⊨s
We deﬁne boolean entailment as follows:
A ⊨s := ∀α. α ⊨A →α ⊨s
Note that s is valid if and only if nil ⊨s.
Fact 11.2.3 If A ⊢s in the classical ND calculus, then A ⊨s.
Proof By induction on the derivation A ⊢s.
■
Exercise 11.2.4 Prove Facts 11.2.1, 11.2.2, and 11.2.3.
11.3 Signed Formulas and Clauses
The tableau method works with signed formulas. A signed formula is a pair of
a sign and a formula, where a sign is either positive or negative.
Inductive sform : Type :=
| Pos : form →sform
| Neg : form →sform.
2014-7-16
175

11 Classical Tableau Method
For a positively signed formula we write s+ or simply s, and for a negatively
signed formula we write s−. We will speak of positive and negative formulas.
A clause is a list of signed formulas.
Deﬁnition clause := list sform.
An assignment satisﬁes a clause if it satisﬁes every positive formula of the
clause and dissatisﬁes every negative formula of the clause. A clause is satisﬁ-
able if it is satisﬁed by at least one assignment.
By our deﬁnitions an assignment dissatisﬁes a formula if and only if it sat-
isﬁes the negation of the formula. Thus a negative formula s−is semantically
equivalent to the negated formula ¬s. One may see a negative sign as an exter-
nal negation. Similarly, one may see a clause as an external conjunction.
We use C, D, and E as names for clauses and S and T as names for signed
formulas. Formally, we deﬁne satisfaction of clauses with a recursive function ⊨:
α ⊨nil := ⊤
α ⊨s+ :: C := α ⊨s ∧α ⊨C
α ⊨s−:: C := α ̸⊨s ∧α ⊨C
A clause C entails a clause D if every assignment satisfying C also satisﬁes D:
C ⊨D := ∀α. α ⊨C →α ⊨D
Exercise 11.3.1 Prove the following facts about satisﬁability and entailment of
clauses:
a) C ⊆D →α ⊨D →α ⊨C
b) C ⊆D →sat D →sat C
c) s+ ∈C →s−∈C →¬sat C
d) If C ⊆D, then D ⊨C.
e) If C ⊨D and D ⊨E, then D ⊨E.
f) If C ⊨D and C is satisﬁable, then D is satisﬁable.
11.4 Solved Clauses
A clause is solved if it contains only signed variables and no conﬂicting pair x+
and x−. A solved clause can be understood as a partial assignment that ﬁxes
the values of ﬁnitely many variables. A solved clause is satisﬁed by every assign-
ment that respects the constraints imposed by the signed variables of the clause.
Since the signed variables of a solved clause do not clash, every signed clause is
satisﬁable.
176
2014-7-16

11.5 Tableau Method
We deﬁne a function ϕ mapping clauses to assignments:
ϕ C x := if [x+ ∈C\ then true else false
Fact 11.4.1 Let C be a solved clause. Then ϕ C ⊨C.
Exercise 11.4.2 Let C be a solved clause. Prove the following.
a) ϕ C ⊨C.
b) C is satisﬁable.
c) If x−∉C, then x+ :: C is solved.
d) If x+ ∉C, then x−:: C is solved.
11.5 Tableau Method
A clause is clashed if it contains either a positive occurrence of ⊥or a comple-
mentary pair s and s−. Clearly, every clashed clause is unsatisﬁable. A clause is
ﬂat if it contains no implication. Clearly, a ﬂat clause is satisﬁable if and only if
it is not clashed.
The tableau method decides satisﬁability of clauses by reducing clauses to
ﬂat clauses. To reduce a clause to ﬂat clauses, implications appearing in the
clause are eliminated one by one using the following equivalences:
α ⊨s →t+ :: C ↔α ⊨s−:: C ∨α ⊨t+ :: C
α ⊨s →t−:: C ↔α ⊨s+ :: t−:: C
When we apply the tableau method by hand, we do the bookkeeping with
a tree-structured table called a tableau (hence the name tableau method). Fig-
ure 11.1 shows a complete tableau for a clause consisting of a negative instance
of Peirce’s law. We start by writing the signed formulas of the initial clause in
separate rows of the tableau. Then implications appearing in the tableau are
eliminated by applying the above equivalences from left to right. When we elim-
inate an implication, we mark it with a number and extend the tableau with the
additional signed formulas speciﬁed by the equivalence.1 For negative implica-
tions we add two signed formulas:
s →t−
s
t−
1 Since eliminated implications stay on the tableau, it is maybe more appropriate to say that
implications are decomposed.
2014-7-16
177

11 Classical Tableau Method
((x →y) →x) →x−
1
(x →y) →x
2
x−
x →y−
3
x
x
⊗
y−
⊗
Figure 11.1: Complete tableau for the clause [((x →y) →x) →x−]
For positive implications we branch to represent the two clauses obtained with
the equivalence:
s →t
s−|
t
The expansion process yields a tree-structured table where each branch repre-
sents a clause.
We stop the exploration of a branch if it represents a clashed or a solved
clause. If a tableau contains a solved branch, the initial clause is satisﬁable since
it is entailed by the solved clause represented by the branch. If all branches of a
tableau are clashed, the initial clause is unsatisﬁable.
A tableau is complete if every branch is either clashed or solved. An assign-
ment satisﬁes the initial clause of a complete tableau if and only if the tableau
contains a solved branch whose clause is satisﬁed by the assignment.
Figure 11.2 shows a complete tableau for the clause [¬¬x →¬(x →¬y)−].
The tableau has 4 branches, three of them clashed and one of them solved. Thus
an assignment satisﬁes the initial clause if and only if it satisﬁes the solved
clause [x, y−] represented by the solved branch.
Exercise 11.5.1 For each of the following formulas s give a complete tableau
for the clause [s−]. Then say whether the formula is valid. If the formula is
not valid, give a solved clause such that every assignment satisfying the solved
clause dissatisﬁes the formula.
a) x →y →x
b) (x →y →z) →(x →y) →x →z
c) (x →¬y →⊥) →¬¬(x →y)
d) ¬¬x →¬y →¬(x →y)
e) (x →y) →(y →x) →z
178
2014-7-16

11.6 DNF Procedure
¬¬x →¬(x →¬y)−
1
¬¬x
3
¬(x →¬y)−
2
x →¬y
5
⊥−
¬x−
4
⊥
x
⊗
⊥−
x−
¬y
6
⊗
y−
⊥
solved
⊗
Figure 11.2: Complete tableau for the clause [¬¬x →¬(x →¬y)−]
Hint: Recall Fact 11.2.1.
Exercise 11.5.2 The tableau procedure can be optimized by adding further elim-
ination rules. For negations we may add the following rules:
α ⊨¬s+ :: C ↔α ⊨s−:: C
α ⊨¬s−:: C ↔α ⊨s+ :: C
Prove the correctness of the rules and redo some of the examples of Exer-
cise 11.5.1 using the rules.
Exercise 11.5.3 Assume that the formulas are extended with conjunctions and
disjunctions. Give equivalences providing for the elimination of conjunctions
and disjunctions.
11.6 DNF Procedure
A list ∆of solved clauses is a DNF (disjunctive normal form) for a clause C if the
following conditions are satisﬁed:
1. Ever assignment satisfying a clause in ∆satisﬁes C.
2. Every assignment satisfying C satisﬁes some clause in ∆.
Informally, we can say that a DNF for a clause represents the clause as a disjunc-
tion of solved clauses.
Lemma 11.6.1 Let ∆be a DNF for C. Then C is satisﬁable if and only if ∆is
nonempty.
2014-7-16
179

11 Classical Tableau Method
dnf C nil = [C]
dnf C (x+ :: D) = if x−∈C then nil else dnf (x+ :: C) D
dnf C (x−:: D) = if x+ ∈C then nil else dnf (x−:: C) D
dnf C ((s →t)+ :: D) = dnf C (s−:: D) ++ dnf C (t+ :: D)
dnf C ((s →t)−:: D) = dnf C (s+ :: t−:: D)
dnf C (⊥+ :: D) = nil
dnf C (⊥−:: D) = dnf C D
Figure 11.3: Operational speciﬁcation of the DNF procedure
We can compute a DNF for a clause C by computing a complete tableau
for C and collecting the solved clauses obtained from the solved branches of
the tableau. Note that a DNF obtained with a complete tableau for a clause C
contains only subformulas of formulas in C. We speak of the subformula prop-
erty.
We will now specify a recursive procedure that computes DNFs for clauses.
We call the procedure DNF procedure. The procedure works with two clauses C
and D called accumulator and agenda. When the procedure starts, the accumu-
lator is empty and the agenda is the initial clause. The procedure uses the agenda
as a stack, and in each step processes the topmost formula of the agenda. The
procedure collects the signed variables it has seen so far in the accumulator,
provided there is no clash. Hence the accumulator is always a solved clause. If a
clash is discovered, the procedure yields the empty DNF. If the agenda is empty,
the procedure yields the singleton DNF just consisting of the accumulator.
Here is the declarative speciﬁcation of the DNF procedure dnf :
∀C D. solved C →dnf C D is a DNF for C ++ D
The operational speciﬁcation shown in Figure 11.3 speciﬁes the DNF procedure
algorithmically. Note that to every pair C, D of arguments exactly on equation
applies. The recursion steps are such that the size of the agenda is decreased.
Thus the procedure terminates. The size of the agenda is the sum of the sizes of
the formulas on the agenda.
size x := 1
size nil := 0
size (s →t) := 1 + size s + size t
size (s+ :: C) := size s + size C
size ⊥:= 1
size (s−:: C) := size s + size C
180
2014-7-16

11.7 Recursion Trees
Given the operational speciﬁcation, we can realize the DNF procedure in a
programming language. A direct realization of the DNF procedure in Coq is not
possible since the recursion is not structural. However, a bounded variant of the
DNF procedure can be realized in Coq using the technique of bounded recursion
we have used before for the uniﬁcation procedure.
Exercise 11.6.2 (Challenge) Write a bounded version of the DNF procedure and
prove the following in Coq:
∀C D n. solved C →size D < n →dnfN n C D is a DNF for C ++ D
11.7 Recursion Trees
We have considered the DNF procedure to better understand the computational
aspects of the tableau method.
Since the DNF procedure terminates for all
clauses C and D, it gives us a recursion tree for all clauses C and D. The recur-
sion tree for C and D represents the recursive calls the DNF procedure performs
for C and D. The recursion tree for C and D can also be seen as a transcript of
a process that derived a complete tableau for the initial clause C ++ D. It turns
out that there is a straightforward formalization of recursion trees that is inde-
pendent from the DNF procedure. The proof of our main result will be based on
recursion trees.
We formalize recursion trees with an inductive type constructor
rec : clause →clause →Type
such that the elements of rec C D are the recursion tree for C and D. The re-
cursion rules in Figure 11.4 describe the value constructors for rec.
At ﬁrst
view it may be easier to understand rec as an inductive predicate and view the
derivations of rec C D as recursion tree for C and D.
If you look at the recursion rules, it is clear that a type rec C D has essentially
a single member. Irrelevant diﬀerences may appear in the proofs of the side
conditions for the variable rules.
Using size induction and a script, it is straightforward to construct a function
provider : ∀C D. rec C D
that yields a recursion tree for all clauses C and D.
2014-7-16
181

11 Classical Tableau Method
rec C nil
rec C (⊥:: D)
rec C D
rec C (⊥−:: D)
rec C (x :: D)
x−∈C
rec (x :: C) D
rec C (x :: D)
x−∉C
rec C (x−:: D)
x ∈C
rec (x−:: C) D
rec C (x−:: D)
x ∉C
rec C (s−:: D)
rec C (t :: D)
rec C (s →t :: D)
rec C (s :: t−:: D)
rec C (s →t−:: D)
Figure 11.4: Recursion rules
11.8 Assisted Decider for Satisﬁability
We can now write functions that recurse on recursion trees. For instance, we can
construct a function
rec_sat_dec : ∀C D. solved C →rec C D →dec (sat (C ++ D))
that decides the satisﬁability of C ++ D given a recursion tree for C ++ D.
We
construct this assisted decider with a script using induction on the recursion
tree.
We speak of an assisted decider since the function is given a recursion
tree. We obtain an unassisted decider ∀C. dec (sat C) by combining the assisted
decider with the provider.
Lemma 11.8.1 Satisﬁability of clauses is decidable.
11.9 Main Results
We shall use the notation C ⊢s for the proposition saying that s is provable in
the classical ND calculus in the context representing the clause C (obtained by
erasing positive signs and replacing negative signs with negation).
With the assisted decider from the last section we can prove
{sat C} + {¬sat C}
for every clause C. It turns out that the assisted decider can be modiﬁed such
that we obtain a proof of
{sat C} + {C ⊢⊥}
(11.1)
182
2014-7-16

11.10 Refutation Lemma
Since we already know
C ⊢⊥→¬sat C
we obtain the equivalence
C ⊢⊥↔¬sat C
Since on both sides entailment can be equivalently expressed as refutation
C ⊢s ↔¬s :: C ⊢⊥
C ⊨s ↔¬sat (s−:: C)
we obtain the equivalence
C ⊢s ↔C ⊨s
which is a main result of this chapter. It also follows that boolean and classical
entailment are decidable.
If you examine the above reasoning, you will see that the decidability of sat-
isﬁability is not needed. In fact, the decidability of satisﬁability follows from the
other facts. The key lemma of the reasoning is (11.1).
Lemma 11.9.1 Classical entailment agrees with boolean entailment.
Lemma 11.9.2 Classical entailment is decidable.
11.10 Refutation Lemma
The proof of the key lemma (11.1) hinges on an assisted decider
∀C D. solved C →rec C D →{sat (C ++ D)} + {C ++ D ⊢⊥}
for classical refutability. We said before that this decider can be obtained by
modifying the construction of the assisted decider for satisﬁability:
∀C D. solved C →rec C D →{sat (C ++ D)} + {¬sat (C ++ D)}
It turns out that the construction underlying these deciders can be generalized
so that one obtains a decider
∀C D. solved C →rec C D →{sat (C ++ D)} + {ρ (C ++ D)}
for every abstract refutation predicate ρ satisfying certain properties. Unsatis-
ﬁability and classical refutability are two concreted examples for a refutation
predicate.
A refutation predicate is a predicate ρ on clauses satisfying the refutation
properties speciﬁed in Figure 11.5. It is not diﬃcult to show that unsatisﬁability
and classical ND refutability are refutation predicates.
2014-7-16
183

11 Classical Tableau Method
⊥+ ∈C →ρ C
ref_False
x+ ∈C →x−∈C →ρ C
ref_clash
ρ (s−:: C) →ρ (t+ :: C) →ρ (s →t+ :: C)
ref_pos_imp
ρ (s+ :: t−:: C) →ρ (s →t−:: C)
ref_neg_imp
C ⊆D →ρ C →ρ D
ref_weak
ρ C →¬sat C
ref_sound
Figure 11.5: Refutation properties
Lemma 11.10.1 λC. ¬sat C is a refutation predicate.
Lemma 11.10.2 λC. C ⊢⊥is a refutation predicate.
Lemma 11.10.3 (Refutation) Let ρ be a refutation predicate. Then we can con-
struct a function ∀C. {sat C} + {ρC}.
We remark that the soundness property is not needed for the proof of the
refutation lemma. It is however essential for the following two lemmas.
Lemma 11.10.4 Every refutation predicate agress with unsatisﬁability.
Lemma 11.10.5 Every refutation predicate is decidable.
In Coq we deﬁne a predicate
ref _pred : (clause →Prop) →Prop
characterizing refutation predicates. We use the record command to carry out
the deﬁnition so that we obtain named projections for the various refutation
properties.
184
2014-7-16

12 Intuitionistic Gentzen System
In this chapter we prove two results about the intuitionistic entailment relation:
•
Intuitionistic entailment is decidable.
•
Intuitionistic entailment is weaker than classical entailment.
Both results are obtained with an analytic proof system. In an analytic proof
system, derivations of a goal employ only subformulas of formulas appearing in
the goal. Analytic proof systems were invented in the early 1930’s by Gerhard
Gentzen.
Recall that N refers to the intuitionistic natural deduction calculus deﬁned
in Section 10.5. In this chapter we will use ⊢exclusively for the intuitionistic
entailment relation given by N .
12.1 Gentzen System GS
We deﬁne an inductive predicate A ⇒s with four proof rules:
A ⇒x
x ∈A
A ⇒u
⊥∈A
A, s ⇒t
A ⇒s →t
A ⇒s
A, t ⇒u
A ⇒u
s →t ∈A
We refer to the rules as variable rule, explosion rule, right implication rule, and
left implication rule. We refer to the proof system given by the rules as GS or
as intuitionistic Gentzen system. The main diﬀerence between N and GS are
the variable rule and the left implication rule. The left implication rule applies
implications appearing in the context of the conclusion. Such an application can
be seen as a decomposition of an implication appearing in the context.
We will show that N and GS are equivalent. Proving that GS is sound for N
is straightforward. Proving that GS is complete for N takes more eﬀort and will
be postponed to the next section.
Fact 12.1.1 (Soundness) If A ⇒s, then A ⊢s.
Proof By induction on the derivation of A ⇒s.
■
The most remarkable property of the proof system GS is the fact that it is
analytic. A proof system is analytic if each of its rules is analytic, and a rule is
185

12 Intuitionistic Gentzen System
analytic if the premises of the rule contain only subformulas of formulas in the
conclusion of the rule. One also speaks of the subformula property. Clearly,
every rule of GS is analytic. In contrast, N is not analytic since the implication
elimination rule of N
A ⊢s →t
A ⊢s
A ⊢t
violates the subformula property.
The explosion rule of N also violates the
subformula property.
If a proof system is analytic, then every derivation of a goal contains only
subformulas of formulas appearing in the goal.
GS provides for systematic proof search. By proof search we mean a process
that given a goal tries to construct in a backward fashion a derivation of the
goal.
If the variable rule or the explosion rule apply to the current goal, the
search ends.
Otherwise, the two implication rules of GS provide only ﬁnitely
many possibilities for reducing the current goal to subgoals. That there are only
ﬁnitely many possibilities for subgoal reduction is the key diﬀerence to N , where
the implication elimination rule oﬀers possibly inﬁnitely many possibilities for
subgoal reduction (through the choice of the formula s).
Note that every rule of GS is cumulative in the sense that the contexts of the
premises extend the context of the conclusion. Also note that the rules of GS ex-
press constraints on the context of the conclusion exclusively with membership.
Both properties also hold for N . Together, the two properties ensure that GS
and N admit weakening.
Fact 12.1.2 (Weakening) If A ⇒s and A ⊆B, then B ⇒s.
Proof Follows by induction on the derivation of A ⇒s.
■
The implication rules of GS decompose implications into their constituents
when applied backwards. While the right implication rule decomposes claimed
implications, the left implication rule decomposes assumed implications. The
two implication rules complement each other such that the variable rule suﬃces
as assumption rule for GS. The fact that GS is deﬁned with an assumption rule
restricted to variables simpliﬁes some of the proofs in this chapter.
Example 12.1.3 Since N is deﬁned with an assumption rule, there is a one step
derivation of x →y ⊢x →y. In contrast, there is no one step derivation of
x →y ⇒x →y in GS. Consider the following derivation of x →y ⇒x →y
186
2014-7-16

12.1 Gentzen System GS
using both implication rules and the variable rule.
x →y, x ⇒x
x →y, x, y ⇒y
x →y, x ⇒y
x →y ⇒x →y
The technique in Example 12.1.3 generalizes so that a general assumption
rule is admissible.
Fact 12.1.4 (Assumption)
If s ∈A, then A ⇒s.
Proof Follows by induction on s.
■
The consistency of GS can be easily veriﬁed by just looking at the four proof
rules. This in contrast to N , where such a veriﬁcation fails for the non-analytic
rules.
Fact 12.1.5 (Consistency) 0 ̸⇒⊥.
We now show ¬¬x ̸⇒x. Once we have established the equivalence of GS and
N , we can conclude from this result that intuitionistic entailment is weaker than
classical entailment. To show ¬¬x ̸⇒x, we analyse an assumed derivation of
¬¬x ⇒x in backward direction and observe that the initial claim reoccurs up to
weakening. The situation can be captured with the following lemma.
Lemma 12.1.6 If A ⊆[x, ¬¬x] and A ⇒s, then s is neither ⊥nor ¬x.
Proof By induction on the derivation of A ⇒s.
■
Lemma 12.1.7 ¬¬x ̸⇒x.
Proof Let ¬¬x ⇒x. This judgment can only be obtained with the left implica-
tion rule. Hence ¬¬x ⇒¬x. Contradiction by Lemma 12.1.6.
■
Exercise 12.1.8 Give a GS derivation of ¬x ⇒x →y using only the four rules
deﬁning GS.
Exercise 12.1.9 Let A be x →y, y →z. Give a GS derivation of A ⇒x →z using
only the four rules deﬁning GS.
Exercise 12.1.10 In this exercise we consider why the explosion rule is necessary
for GS to be complete. Give an example of an A and s such that A ⇒s in GS and
every derivation of A ⇒s makes use of the explosion rule. Hint: Consider a
variant of GS deﬁned without the explosion rule.
2014-7-16
187

12 Intuitionistic Gentzen System
12.2 Completeness of GS
We now show that GS is complete for N . For this we have to show that every rule
of N is admissible for GS. We have already shown that the assumption rule is
admissible for GS. The admissibility of the implication introduction rule is triv-
ial since it agrees with the right implication rule of GS. The admissibility of the
explosion rule and the implication elimination rule of N follows with the admis-
sibility of cut and weakening for GS. We have already shown that weakening is
admissible for GS. So it remains to show that the cut rule
A ⇒s
A, s ⇒u
A ⇒u
is admissible for GS. We call the formula s in such a cut rule the cut formula.
Showing the admissibility of the cut rule is the heart of the completeness
proof for GS. Since a direct inductive proof of the admissibility of the cut rule
does not go through, we follow Gentzen and generalize the cut rule as follows.
A ⇒s
B ⇒u
A ++(B \ s) ⇒u
Recall that A ++(B \ s) is the concatenation of the lists A and B \ s, and that the
list B \ s is obtained from B by removing all occurrences of s. The cut rule can be
obtained from the generalized cut rule with B = A, s and weakening.
Lemma 12.2.1 (Generalized Cut) If A ⇒s and B ⇒u, then A ++(B \ s) ⇒u.
Proof By induction on the cut formula s (ﬁrst) and the derivation of A ⇒s
(second). This yields two cases for s = ⊥, three cases for s = x and three cases
for s = s1 →s2. All the cases are easy except for the case with s = s1 →s2 and the
right implication rule. For the interesting case we have A, s1 ⇒s2 and B ⇒u and
we need to prove A ++(B \ s) ⇒u (where s = s1 →s2). We will use the following
inductive hypotheses for s1 and s2:
•
For all A, B and u, if A ⇒s1 and B ⇒u, then A, (B \ s1) ⇒u.
•
For all A, B and u, if A ⇒s2 and B ⇒u, then A, (B \ s2) ⇒u.
We will not need the inductive hypothesis for A, s1 ⇒s2.
We will prove for all B and u, if B ⇒u, then A ++(B \ s) ⇒u This yields one
case for every rule of GS. All the cases are easy except for the case with the left
implication rule. For the interesting case, we distinguish two subcases.
Suppose the left implication rule is of the form
B ⇒t1
B, t2 ⇒u
B ⇒u
188
2014-7-16

12.2 Completeness of GS
where t1 →t2 ∈B is not s. The inductive hypotheses for B ⇒t1 and B, t2 ⇒u
give A ++(B \ s) ⇒t1 and A ++((B, t2) \ s) ⇒u. Since t1 →t2 is not s, it is in
A ++(B\s). Hence we can complete derive A ++(B\s) ⇒u using the left implication
rule and weakening as follows:
A ++(B \ s) ⇒t1
A ++((B, t2) \ s) ⇒u
A ++(B \ s), t2 ⇒u
A ++(B \ s) ⇒u
Finally suppose s1 →s2 ∈B and the left implication rule is of the form
B ⇒s1
B, s2 ⇒u
B ⇒u
The inductive hypotheses for B ⇒s1 and B, s2 ⇒u give A ++(B \ s) ⇒s1 and
A ++((B, s2) \ s) ⇒u. Recall that A, s1 ⇒s2. Using the inductive hypothesis for
s1 with A ++(B \ s) ⇒s1 and A, s1 ⇒s2 we obtain (A ++(B \ s)) ++((A, s1) \ s1) ⇒s2
and then A ++(B \ s) ⇒s2 by weakening. Using the inductive hypothesis for s2
with A ++(B \ s) ⇒s2 and A ++((B, s2) \ s) ⇒u we obtain
(A ++(B \ s)) ++((A ++((B, s2) \ s)) \ s2) ⇒u.
A ﬁnal application of weakening yields A ++(B \ s) ⇒u as desired.
■
Lemma 12.2.2 (Cut) If A ⇒s and A, s ⇒u, then A ⇒u.
Proof Follows with Lemma 12.2.1.
■
Theorem 12.2.3 (Completeness) If A ⊢s, then A ⇒s.
Proof By induction on the derivation of A ⊢s. The cases for the assumption rule
and the right implication rule are straightforward. The case for the explosion
rule follows with the cut rule.
The case for the left implication rule is most
interesting. We have to show that A ⇒t follows from A ⇒s →t and A ⇒s. Here
is a derivation using cut with s →t, left implication, weakening and assumption:
A ⇒s →t
A ⇒s
A, s →t ⇒s
A, s →t, t ⇒t
A, s →t ⇒t
A ⇒t
Corollary 12.2.4
2014-7-16
189

12 Intuitionistic Gentzen System
1. A ⊢s if and only if A ⇒s.
2. ¬¬x ̸⊢x.
Exercise 12.2.5 Suppose A ⇒¬s and A, ¬s ⇒s. Using only the cut rule and the
four rules deﬁning GS derive A ⇒u.
Exercise 12.2.6 Determine which of the following rules are admissible for GS.
Justify your answers.
A ⇒s
B ⇒u
A ++(B \ t) ⇒u
A ⇒s
A, t ⇒u
A, s →t ⇒u
A, s ⇒u
A, ¬s ⇒u
A ⇒u
A, s ⇒u
A ⇒u
¬¬s ∈A
12.3 Decidability
Every rule of GS has the property that the premises of the rule contain only
subformulas of formulas in the conclusion of the rule. This property is known as
the subformula property. The subformula property of GS has the consequence
that every derivation of a judgement A ⇒s contains only formulas that are
subformulas of formulas in A ⇒s. Based on the subformula property we will
show that every judgement A ⇒s is decidable.
A list U of formulas is subformula-closed if for every implication s →t ∈U
the constituents s and t are both in U. In the following U will always denote a
subformula-closed list of formulas.
A goal is a pair (A, s). A goal (A, s) is derivable if the judgement A ⇒s is
derivable. A goal (A, s) is a U-goal if A ⊆U and s ∈U.
Fact 12.3.1 For every goal one can compute a subformula-closed list U such that
the goal is a U-goal.
Let PU be the power list of U and Γ := PU × U. Every goal in Γ is a U-goal. We
will write the list [A\U without the subscript U.
Fact 12.3.2 Let (A, s) be a U-goal. Then:
1. ([A\, s) ∈Γ.
2. A ⇒s iﬀ[A\ ⇒s.
Now we construct with an iterative procedure a list Λ ⊆Γ containing all deriv-
able goals in Γ. The procedure starts with Λ = 0 and one by one adds goals
from Γ to Λ following up to list equivalence with a single rule application from
the goals already in Λ.
190
2014-7-16

12.3 Decidability
Lemma 12.3.3 One can construct a list Λ ⊆Γ such that:
1. If (A, s) ∈Λ, then A ⇒s.
2. Λ contains every goal (A, u) ∈Γ satisfying one of the following conditions:
a) ⊥∈A.
b) u ∈A and u is a variable.
c) There exist s and t such that u = s →t and ([A, s\, t) ∈Λ.
d) There exists s →t ∈A such that both (A, s) and ([A, t\, u) are in Λ.
Proof We construct Λ by iteration. We start with Λ = 0 and add goals in Γ to Λ if
this is required by (2). The so obtained list Λ satisﬁes (1) since every addition of a
goal is justiﬁed by a rule of GS and weakening. The formalization and veriﬁcation
of this algorithm will be the subject of the next section.
■
Let Λ ⊆Γ be a list as speciﬁed by Lemma 12.3.3. We show that Λ contains the
U-representations of all derivable U-goals.
Lemma 12.3.4 If (A, u) is a derivable U-goal, then ([A\, u) ∈Λ.
Proof By induction on the derivation of A ⇒u. We consider the case where
A ⇒u is obtained with the left implication rule. Here we are given an implication
s →t ∈A and smaller derivations for A ⇒s and A, t ⇒u and need to show the
memberships ([A\, s) ∈Λ and ([[A\, t\, u) ∈Λ. By the inductive hypotheses we
have ([A\, s) ∈Λ and ([A, t\, u) ∈Λ. Thus we have the ﬁrst membership. The
second membership follows since [[A\, t\ = [[A\, t\ since [A\, t ≡A, t.
■
Theorem 12.3.5 A ⊢s is decidable.
Proof Let A and s be given. By Corollary 12.2.4 it suﬃces to show that A ⇒s is
decidable. We construct a subformula-closed list U such that (A, s) is a U-goal.
We also obtain Γ and Λ is described above. By weakening it suﬃces to show that
[A\ ⇒s is decidable. Case analysis.
1. ([A\, s) ∈Λ. Then [A\ ⇒s by Lemma 12.3.3 (1).
2. ([A\, s) ∉Λ. To show [A\ ̸⇒s, we assume [A\ ⇒s. By weakening we have
A ⇒s. By Lemma 12.3.4 we have ([A\, s) ∈Λ. Contradiction.
■
Exercise 12.3.6 Let x be a variable.
a) Give a subformula-closed U such that ¬x ∈U.
b) Give a subformula-closed U such that [¬¬x; x] ⊆U.
Exercise 12.3.7 Let x be a variable and U be [x; x →x].
2014-7-16
191

12 Intuitionistic Gentzen System
a) Verify that U is subformula-closed.
b) Verify that the power list PU of U is [nil; [x →x]; [x]; [x; x →x]].
c) Let Γ be PU × U and write down the eight U-goals in Γ.
d) Construct the corresponding Λ as described in Lemma 12.3.3.
12.4 Finite Closure Iteration
The
formalization
and
veriﬁcation
of
the
iteration
algorithm
underlying
Lemma 12.3.3 takes considerable eﬀort.
We structure the eﬀort with two
reusable abstractions.
The ﬁrst abstraction concerns functional ﬁxed points that can be computed
with functional iteration. Recall that a ﬁxed point of a function f is an argu-
ment x such that f x = x.
Lemma 12.4.1 (Finite Fixed Point Iteration) Let f : X →X be a function. Then:
1. Induction.
Let p : X →Prop and x ∈X such that px and ∀z. pz →p(f z).
Then p(f nx) for every number n.
2. Fixed Point.
Let σ : X →N and x ∈X such that for every number n either
σ(f nx) > σ(f n+1x) or f nx is a ﬁxed point of f . Then f σxx is a ﬁxed point
of f .
Proof Claim (1) follows by induction on n. For claim (2) one shows by induc-
tion on n that either σx ≥n + σ(f nx) or f nx is a ﬁxed point of f .
Thus
σ(f σxx) = 0. By the assumption on σ and x it follows that f σxx is a ﬁxed
point of f .
■
The second abstraction concerns a predicate step : list X →X →Prop and
yields for every list V a minimal list C ⊆V closed under step.
Lemma 12.4.2 (Finite Closure Iteration) Let X be a type with decidable equality,
step : list X →X →Prop be a decidable predicate, and V be a list over X. Then one
can construct a list C ⊆V such that:
1. Closure. If step C x and x ∈V, then x ∈C.
2. Induction. Let p : X →Prop such that step A x →px for all A ⊆p and x ∈V.
Then C ⊆p.
Proof We construct C by iteration. We start with C = 0 and add x ∈V if step C x.
Formally, we deﬁne a function F : list X →list X such that for every list A:
•
If there exists an x ∈V such that x ∉A and step A x, then FA = A, x for one
such x. Otherwise, FA = A.
192
2014-7-16

12.5 Realization in Coq
We now deﬁne C := Fv 0 where v := card V. We use Lemma 12.4.1 to prove the
claims about C.
a) Fn 0 ⊆V. Follows by Lemma 12.4.1 (1).
b) C ⊆V. Follows with (a).
c) Claim (2). Follows by Lemma 12.4.1 (1).
d) FC = C. Follows by Lemma 12.4.1 (2) with σA := card V −card A and (a).
e) Claim (1). Follows with (d).
■
We now come to the formal proof of Lemma 12.3.3.
We obtain Λ with
Lemma 12.4.2 where V
:= Γ and step formalizes the closure conditions of
claim (2) of Lemma 12.3.3.
Claim (1) of Lemma 12.3.3 now follows with
Lemma 12.4.2 (2). Claim (2) of Lemma 12.3.3 follows with Lemma 12.4.2 (1).
12.5 Realization in Coq
The most interesting issues concerning the Coq realization of this chapter are
related to the abstraction for ﬁnite closure iteration. The abstraction is provided
by the base library since it will be reused for other purposes.
Extensive use of base library
The Coq realization of this chapter uses almost every feature of the base library.
•
The inversion tactic inv is essential for Fact 12.1.5 and lemmas 12.1.6
and 12.1.7.
•
The type class-based automation for decidability is essential.
•
The hint-based automation for list membership and list inclusion is essential.
•
Setoid rewriting is used with list equivalences.
•
List removal is essential for generalized cut lemma.
•
Finite closure iteration is used with power lists.
•
Finite closure iteration is realized with list cardinality.
Finite closure iteration abstraction realized with module
The ﬁnite closure iteration abstraction is deﬁned in the base library using a mod-
ule FCI providing a local name space. This way short names like C can be used in
the module. The list Λ and the accompanying lemmas for this chapter are then
established as follows:
Deﬁnition Λ : list goal :=
FCI.C (step := step) Γ.
Lemma lambda_closure γ :
γ ∈Γ →step Λ γ →γ ∈Λ.
2014-7-16
193

12 Intuitionistic Gentzen System
Proof. apply FCI.closure. Qed.
Lemma lambda_ind (p : goal →Prop) :
(∀Delta γ, inclp Delta p →γ ∈Γ →step Delta γ →p γ) →inclp Λ p.
Proof. apply FCI.ind. Qed.
The localized lemmas lambda_closure and lambda_ind provide short names for
the instantiations of the corresponding lemmas in FCI. More importantly, the
localized lemmas do not unfold the deﬁned name Λ when they are applied.
Deﬁnition of step function for ﬁnite ﬁxed point iteration
Based on the given predicate step, module FCI deﬁnes a step function F to be
used with the ﬁxed point iteration. The deﬁnition of F is based on a function
pick deﬁned as a Lemma.
Lemma pick (A : list X) :
{ x | x ∈V ∧step A x ∧¬ x ∈A } + { ∀x, x ∈V →step A x →x ∈A }.
Deﬁnition F (A : list X) : list X.
destruct (pick A) as [[x _]|_]. exact (x::A). exact A.
Deﬁned.
There is an interesting interplay between the functions pick and F. While pick
comes with an informative type and an opaque deﬁnition, F comes with a trans-
parent deﬁnition based on pick.
The informative type of pick is designed to
facilitate proofs about F. That the deﬁnition of F is carried out with a script is a
matter of taste.
Step predicate deﬁned with matches
The proof of Lemma 12.3.3 with ﬁnite closure iteration is interesting. The step
predicate is deﬁned such that decidability of the predicate is easy to prove and
inversion of the predicate is feasible (for inversion inductive deﬁnitions are most
convenient).
Deﬁnition step (Delta : list goal) (γ : goal) : Prop :=
let (A,u) := γ in
match u with
| Var _ ⇒u ∈A
| Imp s t ⇒(rep (s::A) U, t) ∈Delta
| _ ⇒⊥
end
∨
∃v, v ∈A ∧
match v with
| Fal ⇒⊤
| Imp s t ⇒(A, s) ∈Delta ∧(rep (t::A) U, u) ∈Delta
| _ ⇒⊥
end
194
2014-7-16

12.6 Notes
The matches avoid existential quantiﬁcations for the constituents of implica-
tions. Such quantiﬁcations would have to be guarded with membership in U to
facilitate a decidability proof for step. A similar use of match is found in the
deﬁnition of the predicate for subformula closedness.
Deﬁnition sf_closed (A : list form) : Prop :=
∀u, u ∈A →match u with
| Imp s t ⇒s ∈A ∧t ∈A
| _ ⇒⊤
end.
12.6 Notes
Analytic proof systems were invented by Gerhard Gentzen [5, 6] in the early
1930’s.
Gentzen developed analytic proof systems for intuitionistic and clas-
sical logic covering the connectives ∧, ∨, ¬, and →and the ﬁrst-order quanti-
ﬁers ∀and ∃. Gentzen-style systems are called Gentzen systems, sequent sys-
tems, analytic systems, or cut-free systems in the literature. The word sequent is
Kleene’s [10] translation of the German word “Sequenz” Gentzen used for lists
of formulas.
It is an interesting exercise to add proof rules for conjunctions and disjunc-
tions to GS. This can be done such that all essential properties of GS are pre-
served.
The completeness for a correspondingly extended N system can be
shown by extending the proofs of the existing cut lemmas.
Based on his analytic proof system for intuitionistic logic, Gentzen [5, 6]
gave the ﬁrst proof of the decidability of intuitionist propositional entailment.
Gentzen [5, 6] also shows non-derivability of excluded middle.
Many diﬀerent variants of Gentzen systems are studied in the literature. Our
system is closest to the system GKi of Troelstra and Schwichtenberg [19]. GKi
is diﬀerent from GS in that it employs multisets of formulas rather than lists of
formulas.
Gentzen [5, 6] starts with a sequent calculus including the cut rule. Gentzen’s
celebrated cut elimination theorem then shows that the uses of the cut rule can
be eliminated from the derivation, thus yielding a derivation in an analytic sub-
system.
Gentzen’s [5, 6] sequent systems come with structural and logical rules.
Gentzen’s structural rules include weakening and cut. Our system GS has no
structural rules. The reason GS is complete without structural rules is the cumu-
lative format of the rules and the use of membership constraints for contexts.
Reading Gentzen’s [5, 6] very clear papers gives a good idea of how proof
systems were studied in the 1930’s. At this time the now standard notions of
2014-7-16
195

12 Intuitionistic Gentzen System
lists, abstract syntax, and inductive deﬁnitions were unknown. Gentzen did in-
ductions on derivations as inductions on the size of derivations.
Troelstra and Schwichtenberg’s [19] text contains an extensive study of var-
ious Gentzen systems. Girard et al. [7] is an advanced text developing the con-
nection between Gentzen systems and typed lambda calculi. Kleene’s [10] intro-
duction to logic and computation covers Gentzen systems and the decidability
of intuitionistic entailment.
196
2014-7-16

Bibliography
[1] F. Baader and W. Snyder.
Uniﬁcation theory.
In J.A. Robinson and
A. Voronkov, editors, Handbook of Automated Reasoning, volume I, pages
447–533. Elsevier Science Publishers, 2001.
[2] E. Eder. Properties of substitutions and uniﬁcations. Journal of Symbolic
Computation, 1(1):31–46, 1985.
[3] G. Frege. Begriﬀschrift, eine der arithmetischen nachgebildete Formelsprache
des reinen Denkens. Nebert, Halle, 1879. Also in [9], pages 1–82.
[4] G. Gentzen. Untersuchungen über das logischen Schliessen I. Mathematische
Zeitschrift, 39:176–210, 1935. Translation in: Collected papers of Gerhard
Gentzen, ed. M. E. Szabo, North-Holland, Amsterdam [1969], pp. 68–131.
[5] Gerhard Gentzen. Untersuchungen über das logische Schließen I. Mathema-
tische Zeitschrift, 39(1):176–210, 1935.
[6] Gerhard Gentzen. Untersuchungen über das logische Schließen II. Mathe-
matische Zeitschrift, 39(1):405–431, 1935.
[7] Jean-Yves Girard, Yves Lafont, and Paul Taylor. Proof and types. Cambridge
University Press, 1989.
[8] Valery Glivenko. Sur quelques points de la logique de M. Brouwer. Bulletins
de la classe des sciences, 15:183–188, 1929.
[9] J. van Heijenoort, editor. From Frege to Gödel: A Source Book in Mathemati-
cal Logic, 1879–1931. Harvard University Press, Cambridge, Massachusetts,
1967.
[10] Stephen Cole Kleene. Introduction to metamathematics. Van Nostrand, 1952.
[11] D. Knuth and P. Bendix. Simple word problems in universal algebras simple
word problems in universal algebras simple word problems in universal
algebras. In J. Leech, editor, Computational Problems in Abstract Algebra,
pages 263–297. Oxford, 1970.
197

Bibliography
[12] J-L. Lassez, M.J. Maher, and K. Marriott.
Uniﬁcation revisited.
In Mauro
Boscarol, Luigia Carlucci Aiello, and Giorgio Levi, editors, Foundations of
Logic and Functional Programming, volume 306 of Lecture Notes in Com-
puter Science, pages 67–113. Springer Berlin Heidelberg, 1988.
[13] Alberto Martelli and Ugo Montanari. An eﬃcient uniﬁcation algorithm. ACM
Trans. Program. Lang. Syst., 4(2):258–282, 1982.
[14] Robin Milner. A theory of type polymorphism in programming. J. Comput.
Syst. Sci., 17(3):348–375, 1978.
[15] Mike Paterson and Mark N. Wegman. Linear uniﬁcation. J. Comput. Syst. Sci.,
16(2):158–167, 1978.
[16] Lawrence C. Paulson. Verifying the uniﬁcation algorithm in LCF. Sci. Comput.
Program., 5(2):143–169, 1985.
[17] John Alan Robinson. A machine-oriented logic based on the resolution prin-
ciple. J. ACM, 12(1):23–41, 1965.
[18] José-Luis Ruiz-Reina, Francisco-Jesús Martín-Mateos, José-Antonio Alonso,
and María-José Hidalgo. Formal correctness of a quadratic uniﬁcation algo-
rithm. J. Autom. Reasoning, 37(1-2):67–92, 2006.
[19] A. S. Troelstra and H. Schwichtenberg. Basic proof theory. Cambridge Uni-
versity Press, New York, NY, USA, 2nd edition, 2000.
198
2014-7-16

