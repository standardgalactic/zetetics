1
Opinion Control under Adversarial Network
Perturbation: A Stackelberg Game Approach
Yuejiang Li, Zhanjiang Chen, H. Vicky Zhao
Abstract—The emerging social network platforms enable users
to share their own opinions, as well as to exchange opinions with
others. However, adversarial network perturbation, where mali-
cious users intentionally spread their extreme opinions, rumors
and misinfomration to others, is ubiquitous in social networks.
Such adversarial network perturbation greatly inﬂuences the
opinion formation of the public, and threatens our societies. Thus,
it is critical to study and control the inﬂuence of adversarial
network perturbation. Although tremendous efforts have been
made in both academia and industry to guide and control the
public opinion dynamics, most of these works assume that the
network is static, and ignore such adversarial network perturba-
tion. In this work, based on the well-accepted Friedkin-Johnsen
opinion dynamics model, we model the adversarial network
perturbation, and analyze its impact on the networks’ opinion.
Then, from the adversary’s perspective, we analyze its optimal
network perturbation, which maximally changes the networks’
opinion. Next, from the network defender’s perspective, we
formulate a Stackelberg game, and aim to control the network’s
opinion even under such adversarial network perturbation. We
device a projected subgradient algorithm to solve the formualted
Stackelberg game. Extensive simulations on real social networks
validate our analysis of the advesarial network perturbation’s
inﬂuence and the effectiveness of the proposed opinion control
algorithm.
I. INTRODUCTION
The emerging online social network (OSN) platforms, such
as Facebook, Twitter, and WeChat, etc., greatly strengthen the
connections among people around the world and ultimately
shaped the way of how people form their opinions. People
can easily share their own information anywhere and anytime,
and they can also exchange opinions through comments, likes,
or reposts. In addition, users in social network platforms can
not only interact with their own known friends. They can
also exploit the recommendation function in OSN platforms,
interact with those they did not know, and expand their circles
all the time.
It is a controversial issue that people can gain other strangers
information and opinions in such a convenient way. On the
one hand, governments can use OSN platforms to spread
their public statements. One the other hand, some malicious
users and partisan media inject their extreme opinions [1],
inﬂuence other innocent users, and trigger severe social riots.
A recent example is the “storming of U.S. Capitol” in Jan.
2021. Inﬂamed by President Trump’s speech and tweets, “ﬂag-
waving, chanting and cursing throngs overwhelmed security
Y.
Li,
Z.
Chen
and
H.
V.
Zhao
was
with
the
Department
of
Automation, Tsinghua University, Beijing, 10084 P. R. China e-mail:
lyj18,czj17@mails.tsinghua.edu, vzhao@tsinghua.edu.cn.
Manuscript received April 19, 2005; revised August 26, 2015.
barriers, and the whole building was lockdown [2].” Thus, it
is critical to investigate the inﬂuence of such extreme opinions,
evaluate their impact on the OSN platforms, and further design
effective defense mechanism to control the spread of such
extreme opinions.
A. Literature Review
Opinion Dynamics Models. Modeling and analyzing opin-
ion dynamics in social networks have received research atten-
tion from different disciplines. In the literature, there were two
lines of works that modeled and analyzed opinion dynamics in
social networks. The ﬁrst studied the discrete-valued opinion
scenario, A line of works built discrete opinion dynamics
models and studied binary opinion scenario, for example, to
support the Democrats or the Republicans. In the discrete
models, users imitated their neighbors’ opinions to update their
own. Popular imitation rules included random imitation rule
in the voter model [3], the local majority rule [4], and the
linear threshold rule [5], etc. The imitation in the discrete
models resulted in users’ opinions to change to change from
one extreme to the other. To model how users opinions
were changed and formed in a gradual process, the other
continuous-valued opinion dynamics models were proposed.
In the continuous models, opinion values were in a certain
range, with two endpoints representing two extreme opinions.
One of the fundamental works of the continuous model was
the DeGroot model [6], where users updated their opinions by
averaging those of his/her neighbors. In the DeGroot model,
it would reach the opinion consensus state where all agents
held the same opinion. Hegselmann and Krause assumed that
users would ignore opinions that were too far from theirs when
updating opinions, and they found that users’ opinions would
converge to different clusters at equilibrium [7]. The Friedkin-
Johnsen (FJ) model incorporated users’ intrinsic beliefs and
their stubbornness into the DeGroot model, and it was shown
in [8], [9] that such stubbornness could cause opinion polar-
ization where users held different opinions at the equilibrium.
In addition, the FJ model was validated by small and medium
group of social experiments [10].
Opinion Control. Based on the above opinion dynamics
models, there were many works studying how to control public
opinion. These works mainly focused on two objectives: the
total opinion and the opinion polarization. The total opinion
characterized the overall stance of the whole population.
The work in [11] ﬁrst studied the problem of maximizing
total opinion in the discrete opinion dynamics models. They
proposed a greedy algorithm to select a certain number of
arXiv:2304.12540v1  [cs.CY]  25 Apr 2023

2
“seed users” that can maximized the total opinion. The work
in [12] further extended this algorithm to the continuous
opinion dynamics models. The total opinion was optimized by
controlling users’ stubbornness in [13] and by manipulating
users’ intrinsic beliefs through persuasion in [14]. Opinion
polarization quantiﬁed the discrepancies among users’ opin-
ions. The work in [15] minimized the opinion polarization by
controlling users’ intrinsic believes. Furthermore, the works
in [16] and [17] studied how network structure inﬂuence the
opinion polarization, respectively. Chen et al.. studied how
to maximize the opinion polarization from the adversary’s
perspective [18], [19]. Although the above algorithms could
efﬁciently control the total opinion or the opinion polarization,
they were developed based on the assumption that the network
structure was static. That is, the connections and inﬂuence
strength among all users did not change during the opinion
dynamics process.
Dynamic Network Structure. In reality, the network struc-
ture may change from time to time [20], [21]. The work
in [22] proposed the preferential attachment algorithm that
the newly added user were more likely to follow those with
more followers. The preferential attachment could explain the
power-law degree distribution of social networks in reality.
Some works explored the data from social network platforms
and analyzed how real social networks changed over time.
The work in [23] showed that the recommending algorithms
in social network platforms tended to connect users with
similar interests together. This could further resulted in the
“ﬁlter bubble” effect [24] that the opinion polarization was
increased. The work in [25] proposed perturbation centrality
based on the perturbation analysis of the network structure.
Furthermore, the perturbation centrality was used in graph-
based optimization problem, which was proved to be robust
against edge failure.
Different from the prior works on opinion control, which
assumed that the network structure is static, in this work, we
consider the scenario where some attackers can perturb the
network structure by spread their extreme opinions to other
target users. We model such adversarial network perturbation.
From the adversary’s perspective, we aim to analyze the
optimal strategy for the adversary to choose the attackers
and the corresponding target users. Then, from the network
defender’s perspective, we device a opinion control scheme
which is robust to the adversarial network perturbation. Our
investigation is important to the development of robust online
social networks.
B. Our Contribution
Our contributions can be summarized as follows:
1) We model the network perturbation and theoretically
analyze its impact on the total opinion.
2) We consider the scenario where the adversary can exploit
the network perturbation to maximize the total opinion,
while the network defender aims to minimize the total
opinion under such adversarial network perturbation. We
model such scenario as a Stackelberg game, played
between the network defender and the adversarial.
3) From the adversary’s perspective, we theoretically ana-
lyze the optimal strategy to choose the attacker and the
corresponding target users, so that the total opinion is
maximized.
4) From the network defender’s perspective, we formulate
a min-max game which aims to minimize the total
opinion, even if the network is perturbed by the adversary
with their optimal strategy. We further device a project
subgradient method to efﬁciently solve the formulated
min-max game.
5) We conduct extensive experiments on real social networks
to validate the analysis of the network perturbation, and
the optimal strategy for the adversary. We also use real
social networks to test the defense algorithms.
The rest of this paper is organized as follows. In Section II,
we introduce the basics of the Friedkin-Johnsen opinion
dynamics models and opinion control. In Section III, we
model the network perturbation, and formulate the Stackelberg
game played between the adversary and the network defender.
Then, in Section IV, we analyze the optimal strategy for the
adversary to maximize the total opinion. Next, in Section V,
from the defender’s perspective, we solve the stackelberg
game to minimize the total opinion under the adversarial
network perturbation. The simulation and experiments results
are summarized in Section VI, and the conclusion is drawn in
Section VII.
II. PRELIMINARY
In this section, we brieﬂy review the Friedkin-Johnsen (FJ)
opinion dynamics model, and introduce the opinion minimiza-
tion problem studied in this paper.
A. The Friedkin-Johnsen Model
In this work, we consider the scenario that there are n users
in network, discussing a topic that is harmful to public security.
The network can be modeled as a graph, where nodes represent
users, and an directed edge (i, j) indicates that user-j can
inﬂuence user-i. Let W
W
W be the adjacency matrix of the graph,
whose entry Wij > 0 shows the inﬂuence weight of user j on
user i if there is an directed edge (i, j); otherwise, Wij = 0.
Following the original FJ model [8], for any user i, the total
inﬂuence weight of all other users on user v are uniﬁed to 1.
That is, W
W
W111 = 111.
In the FJ model, user i holds internal opinion si which
shows his/her intrinsic belief on the discussed topic. Let
sss = [s1, · · · , sn]T be all users’ internal opinions. The opinion
formation process is divided into discrete time steps. At
time step t, the expressed opinions of users are zzz(t) =
[z1(t), · · · , zn(t)]T . Each user aggregates his/her neighbors’
expressed opinions together with his/her own internal opinion,
and updates the expressed opinion at the next time step as
zi(t + 1) = αisi + (1 −αi) ·
X
j
Wijzj(t),
(1)
where 0 < αi < 1 is the stubbornness of user i. The larger αi
is, user i is more stubborn and follows his/her own intrinsic
belief more.

3
The expressed opinions of the whole population evolve as
the above updating process, and ﬁnally reach the equilibrium
state [8]
zzz∗= BBBAAAsss, where
(2)
BBB = [III −(III −AAA)W
W
W]−1 and AAA = Diag (αi) .
(3)
From (2), the equilibrium expressed opinions depends on the
network structure W
W
W, all users internal opinions sss, and their
stubbornness AAA.
B. Opinion Control
As the total opinion shows the whole population’s support
of the discussed topic, following the previous works in [13],
[14], [26], we aim to minimize the total opinion at equilibrium,
that is
f = 111Tzzz∗= 111TBBBAAAsss
(4)
In the following, we refer to f as total opinion for short
when no confusions are made. We adopt the “Min-Total”
algorithms in [14] as the baseline methods. In the “Min-
Total” algorithm, users internal opinions can be controlled
through e.g., persuasion, but limited to a certain budget µ.
Consequently, the total opinion minimization problem can be
formulated as
min
xxx
111TBBBAAAxxx
s.t.

111T (sss −xxx) ≤µ,
000 ≤xxx ≤sss.
(5)
The formulated minimization is convex, and can be solved
efﬁciently using linear searching algorithm [14]. The above
algorithm can obtain the optimal control when the network
structure W
W
W is static and unchanged. However, both evidence
in literature [22] and real data [20], [21] have shown that the
network structure may change during the opinion formation
process. In the following, we model the change of network
structure, and analyze its impact on the total opinion.
III. ADVERSARIAL NETWORK PERTURBATION AND
PROBLEM FORMULATION
In online social network platforms, a user v can easily
explore other users opinion, e.g., trending tweets on the ex-
ploration page of Twitter and private messages from strangers
on Instagram, even though they are not v’s neighbors. Some
malicious users may exploit this nature of online social net-
work platforms and intentionally spread their own ideas to the
public. We deﬁne this intentional change in network structure
as adversarial network perturbation. In this section, we model
the adversarial network perturbation, and formulate the robust
opinion minimization problem under such perturbation.
A. Adversarial Network Perturbation Model
In this work, we consider the scenario where the adversary
aims to promote the support of the discussing harmful topic,
and try to maximize the total opinion of the network. We
assume that the adversary can manipulate at most m users
as the attackers, and push the expressed opinions of these
attackers to some target users. Let A and T be the set of
attackers and that of target users, respectively. For an attacker
u ∈A, the target user of him/her is denoted by Tu. In this
work, we assume that each attacker can push his/her expressed
opinions to at most k target users, that is, |Tu| ≤k ∀u ∈A.
For a target user v ∈T , let Av be the attackers that inﬂuences
this target user. Consequently, we have
[
u∈A
Tu = A, and
[
v∈T
Av = T .
(6)
For a target user v ∈T , when an attacker u ∈Av pushes
his/her expressed opinion to v, we assume that it inﬂuences
the target user v with weight p. We also deﬁne p as the
perturbation coefﬁcient. To ensure that the total inﬂuence
weights of other users on the target user v is uniﬁed to 1,
the inﬂuence weights of v’s original neighbors is discounted
by (1 −|Av|p), and |Av|p ≤1. Consequently, the inﬂuence
weights on target user v becomes
˜Wvu =
(
(1 −|Av|p) · Wvu
u /∈Av;
(1 −|Av|p) · Wvu + p
u ∈Av.
(7)
For other users ¯v /∈T , others users’ inﬂuence weights on
him/her do not change. The adjacency matrix after perturbation
becomes
˜
W
W
W = W
W
W + p × ∆
∆
∆W , where
(8)
∆
∆
∆W =
X
v∈T
eeev
X
u∈Av
eeeT
u −
X
v∈T
|Av|eeeveeeT
v W
W
W.
(9)
Since the adjacency matrix has changed to ˜
W
W
W, with (2), the
expressed opinion at equilibrium becomes
˜zzz∗= ˜BBBAAAsss, where ˜BBB = (III −(III −AAA) ˜
W
W
W)−1,
(10)
and the total opinion becomes
˜f = 111T ˜BBBAAAsss.
(11)
B. Network Defense under Adversarial Perturabtion
Owing to the existence of the potential adversarial network
perturbation, in this work, we formulate the following network
defense problem.
min
xxx
max
A,Tu 111T ˜BBBAAAxxx
s.t.







111T (sss −xxx) ≤µ,
000 ≤xxx ≤sss,
|A| ≤m,
|Tu| ≤k, ∀u ∈A.
(12)
The formulated network defense problem in (12) can be
interpreted as a zero-sum game played between the adversary
and the defender. The adversary can perturb the network
as analyzed in Section III-A to maximize the total opinion.
This corresponds to the inner maximization of the objective
function in (12). For the defender, similar to the prior works in
[14], [17], we assume that they control users’ innate opinions
with a certain budget to minimize the total opinion. Different
from the opinion minimization problem in (5), here, the
defender is aware of the existence of the adversary, and assume
that the adversary is rational to maximize the total opinion.

4
Thus, the objective of the defender in (12) is the maximized
total opinion by the adversary.
To solve the proposed network defense problem under the
adversarial network perturbation, in the following, we ﬁrst
analyze from the adversary’s perspective to ﬁnd the optimal
solution to the inner maximization of (12). Then, based on
the analytical solution to the inner maximization problem, we
further develop efﬁcient algorithm to solve (12).
IV. OPTIMAL ADVERSARIAL NETWORK PERTURBATION
In this section, from the adversary’s perspective, given
that the controlled internal opinions are sss, we study how to
maximize the total opinion by selecting attackers A and the
corresponding target users Tu for u ∈A. That is, we solve
the following problem
max
A,Tu
111T ˜BBBAAAsss
s.t.

|A| ≤m,
|Tu| ≤k, ∀u ∈A.
(13)
The ﬁrst constraint in the above shows that the adversary can
select up to m attackers, while the second constraints indicates
that each attacker u ∈A can perturb up to k target users.
Note that the above maximization problem is a combina-
torial problem. In addition, the optimization variables A and
Tu are included in ˜BBB. From (10), the outer inverse further
hinder the solution of the maximization. A direct method is
to use the greedy algorithm as in [11], to iteratively select the
attackers and the target users. However, computational cost is
substantial, and it is unacceptable when the network size is
sufﬁciently large.
In the following of this section, we ﬁrst approximate the
objective function in (13). Then, based on the approximated
objective function, we develop a linear search algorithm to
solve the approximated maximization problem.
A. Approximation of Objective
Note that in real social network, users are often less likely to
be inﬂuenced by users who are not their friends. Consequently,
the impact of the adversarial network perturbation is limited.
In our model, this corresponds to the perturbation coefﬁcient
p is sufﬁcient small, that is, p →0. Based on the assumption
that p →0, we have the following proposition.
Proposition 1. when the network structure changed to ˜
W
W
W, the
total opinion with perturbation can be approximated as
˜f ≈111TBBBAAAsss + p × 111TBBB(III −AAA)∆
∆
∆WBBBAAAsss
(14)
Proof. Using the Taylor series, we have
˜f = ˜f

p=0 + p × d ˜f
dp

p=0
+ O(p2).
When p = 0, with ˜
W
W
W in (8), ˜f = f = 111TBBBAAAsss. To calculate
the second term in the above, we ﬁrst calculate d ˜
f
dp.
d ˜f
dp = d(111T ˜BBBAAAsss)
dp
= 111T d ˜BBB
dp AAAsss.
As ˜BBB = (III−(III−AAA) ˜
W
W
W)−1, and we have ˜BBB·(III−(III−AAA) ˜
W
W
W) =
III. Taking derivatives w.r.t. p on both sides, we have
d ˜BBB(III −(III −AAA) ˜
W
W
W) −˜BBB(III −AAA)d ˜
W
W
W = 000.
With ˜
W
W
W in (9), we have d ˜
W
W
W = ∆
∆
∆W dp. Then, we have
d ˜BBB(III −(III −AAA) ˜
W
W
W) −˜BBB(III −AAA)∆
∆
∆W dp = 000
⇒d ˜BBB
dp = ˜BBB(III −AAA)∆
∆
∆W (III −(III −AAA) ˜
W
W
W)−1
= ˜BBB(III −AAA)∆
∆
∆W ˜BBB
With the above derivatives we have
d ˜f
dp

p=0
= 111T
 
d ˜BBB
dp
!
p=0
AAAsss = 111TBBB(III −AAA)∆
∆
∆WBBBAAAsss.
Ignoring the O(p2) term, we have (14)
Note that the ﬁrst term in (14) is the total opinion f when
there is no adversarial network perturbation. Therefore, the
total opinion with network perturbation can be regarded as f
plus a perturbation term related to how network structure is
changed, i.e., ∆
∆
∆W . The contribution of the perturbation term
to the total opinion is controlled by the perturbation coefﬁcient
p. When p is larger, the total opinion at equilibrium deviates
more from the original one.
B. Optimal Selection of the Attackers and the Target Users
With the above approximation, in this section, we derive
the optimal adversarial network perturbation. That is, we ﬁnd
the optimal set of attackers A∗. Furthermore, for each optimal
attacker u ∈A∗, we ﬁnd u’s optimal target user set T ∗
u .
In (14), the ﬁrst term is neither related to the selection of
attackers nor target users. Thus, the maximization in (13) is
equivalent to maximizing the perturbation term, that is,
max
A,Tu
111TBBB(III −AAA)∆
∆
∆WBBBAAAsss
s.t.

|A| ≤m,
|Tu| ≤k, ∀u ∈A.
(15)
Then, with the change of adjacency matrix in (9), the above
objective can be further written as
111TBBB(III −AAA)∆
∆
∆WBBBAAAsss
(16)
=111TBBB(III −AAA)
 X
v∈T
eeev
X
u∈Av
eeeT
u −
X
v∈T
|Av|eeeveeeT
v W
W
W
!
BBBAAAsss
=
X
v∈T
111TBBB(III −AAA)eeev
X
u∈Av
eeeT
uBBBAAAsss
(17)
−
X
v∈T
|Av|111TBBB(III −AAA)eeeveeeT
v W
W
WBBBAAAsss
Note that from (2), we have zzz∗= BBBAAAsss. We further deﬁne
ccc1 ≜(111TBBB(III −AAA))T , and
ccc2 ≜W
W
Wzzz∗= W
W
WBBBAAAsss.
(18)

5
Consequently, the above objective can be further simpliﬁed as
111TBBB(III −AAA)∆
∆
∆WBBBAAAsss
(19)
=
X
v∈T
c1(v)
X
u∈Av
z∗(u) −
X
v∈T
|Av|c1(v)c2(v)
=
X
v∈T
c1(v) ·
 X
u∈Av
z∗(u) −|Av|c2(v)
!
=
X
v∈T
c1(v) ·
X
u∈Av
 z∗(u) −c2(v)

=
X
v∈T
X
u∈Av
c1(v) ·
 z∗(u) −c2(v)

(20)
=
X
u∈A
X
v∈Tu
c1(v) ·
 z∗(u) −c2(v)

.
(21)
From (20) to (21), we use the relationships in (6) and exchange
the summation order. From (21), when an attacker u inﬂuences
a target user v, such perturbation contributes δu,v ≜c1(v) ·
 z∗(u)−c2(v)

to the change of total opinion. Thus, we deﬁne
δu,v as the meta-inﬂuence. Furthermore, for the attacker u,
his/her total inﬂuence on the change of total opinion is
δu ≜
X
v∈Tu
δu,v =
X
v∈Tu
c1(v) ·
 z∗(u) −c2(v)

(22)
We also call δu the individual inﬂuence of user u, if he/she is
selected as the attacker.
With the derivation in (21), the maximization in (15) can
be transformed as
max
A,Tu
111TBBB(III −AAA)∆
∆
∆WBBBAAAsss
= max
A,Tu
X
u∈A
X
v∈Tu
c1(v) ·
 z∗(u) −c2(v)

= max
A
X
u∈A
 
max
Tu
X
v∈Tu
c1(v) ·
 z∗(u) −c2(v)

!
= max
A
X
u∈A
max
Tu δu.
To this end, the maximization in (15) can be decoupled
as a two-step maximization problem. The ﬁrst step is to
maximize the user u’s individual inﬂuence and choose his/her
corresponding target user set T ∗
u, if he/she is selected as the
attacker. That is,
max
Tu
δu =
X
v∈Tu
c1(v) ·
 z∗(u) −c2(v)

s.t.
|Tu| ≤k.
(23)
By solving (23) for each user u, we obtain his/her optimal
target user set T ∗
u
as well as his/her optimal individual
inﬂuence δ∗
u. Then, the second step is to solve
max
A
X
u∈A
max
Tu δu =
X
u∈A
δ∗
u
s.t.
|A| ≤m,
(24)
to obtain the optimal attacker set A∗. In the following, we
analyze the solutions to (23) and (24).
1) Optimal Selection of Target User: According to the
above analysis, selecting the users with the largest meta-
inﬂuence c1(v) · (z∗(u) −c2(v)) as the target user Tu can
maximize the individual inﬂuence δu. Recall the deﬁnition
that c1 = (111TBBB(III −AAA))T . Since 0 < αi < 1, the diagonal of
(III −AAA) is always positive. From (3), using the matrix identity,
we have
BBB = [III −(III −AAA)W
W
W]−1 = I+(III −AAA)W
W
W +
 (III −AAA)W
W
W
2+· · · .
(25)
Consequently, all entries of BBB and 111TBBB are positive. Thus
c1(v) is always positive. Let ˆbi be the sum of the i-th column
of BBB. We can have c1(v) = ˆbv · (1 −αv). Therefore, if user
v is easily inﬂuenced by others and has a smaller αv, he/she
can have a larger value of c1(v), and thus, be selected as the
target user.
Next, we analyze the second term (z∗(u) −c2(v)). With
(18), we can see that c2(v) = P Wvjz∗(j) is the weighted
average of user v’s original neighbors opinions. If the neigh-
bors of user v have smaller expressed opinions (smaller c2(v)),
user v is more likely to be selected as the target user by the
attackers. Note that if a user u is selected as the attacker, the
size of his/her optimal target users |T ∗
u | may be less than the
constraint k. That is, selecting more target user can not always
increase the individual inﬂuence δ∗
u. This is because that z∗(u)
can be less than c2(v). Consequently, the term (z∗(u)−c2(v))
and the meta-inﬂuence c1(v)·(z∗(u)−c2(v)) can be negative.
In this sense, the individual inﬂuence δu may decrease if we
select this user v as target user.
An extreme case is the user u, who own the smallest
expressed opinion when there is no adversarial perturbation,
that is, z∗(u) ≤z∗(u), ∀u. We can have (z∗(u)−c2(v)) ≤0.
Thus, user u can never be selected as the attacker. The other
extreme case is the user u, who owns the largest expressed
opinion when there is no adversarial perturbation, that is,
z∗(u) ≥z∗(u), ∀u. We can have (z∗(u) −c2(v)) ≥0.
Therefore, if user u will always select k target users, it he/she
is selected as the attacker. In fact, as we can see next, user u
is always selected as the attacker.
2) Optimal Selection of Attacker: Given the optimal target
user selection criterion above, we can decide the optimal target
user set T ∗
u and the optimal individual inﬂuence δ∗
u for each
user u. Then, we can select the users with the largest optimal
individual inﬂuence δ∗
u as the optimal attackers A∗to solve
(24). Note that, through this method, we ﬁrst need to solve (23)
for each user, and the complexity is O(N ·N log k). Next, we
need to solve (24) with complexity N log m. Then, the total
computational complexity is O(N·(N log k+log m)). We next
analyze the properties of the selected attackers, and reduce the
computtaional complexity.
Proposition 2. For a pair of users users u1, u2 ∈V, if
z∗(u1) ≥z∗(u2), then we have δ∗
u1 ≥δ∗
u2.
Proof. Let T ∗
u1 and T ∗
u2 be the optimal target user set of u1
and u2, respectively. Since T ∗
u1 is the optimal target user set,

6
we have
δ∗
u1 =
X
v∈T ∗
u1
c1(v) ·
 z∗(u1) −c2(v)

≥
X
v∈T ∗
u2
c1(v) ·
 z∗(u1) −c2(v)

.
Note that z∗(u1) ≥z∗(u2) and c1(v) ≥0 from the previous
section, we have
δ∗
u1 ≥
X
v∈T ∗
u2
c1(v) ·
 z∗(u1) −c2(v)

≥
X
v∈T ∗
u2
c1(v) ·
 z∗(u2) −c2(v)

= δ∗
u2.
Here, we have δ∗
u1 ≥δ∗
u2.
From Proposition. 2, we can see that if a user with a
larger expressed opinion z∗(u) withou perturbation, he/she can
have a larger optimal individual inﬂuence, even without the
knowledge of his/her optimal target user set. Consequently,
we can have the following corollary.
Corollary 1. Let A[m] be the set of top-m users who own
the largest expressed opinion without perturbation. That is,
A[m] = {u[1], u[2], · · · , u[m]}, and z∗([1]) ≥z∗([2]) ≥· · · ≥
z∗([m]) ≥z∗(v), for any v /∈A[m]. Then, A∗⊆A[m].
Proof. From Proposition. 2, if z∗([1]) ≥z∗([2]) ≥· · · ≥
z∗([m]) ≥z∗(v), we have δ∗
u[1] ≥δ∗
u[2] ≥· · · ≥δ∗
u[m] ≥δ∗
v,
for any v /∈A[m]. Note that from the analysis in the above
section, a user u′
∈A[m] can have negative individual
inﬂuence δ∗
u′ if
 z∗(u′)−c2(v) < 0 for all v ∈V. In this case,
u′ should not be included in A∗. Therefore, A∗⊆A[m].
With Proposition. 2 and Corollary. 1, we can simplify the
searching process by ﬁrst deciding the candidates of attackers
A[m] with the sorted expressed opinion z∗(u). The complexity
of this step is O(N log m).Then, we only need to search
for the target user set of each candidate attacker, and decide
their optimal individual inﬂuence with (23). The complexity
of this step is O(m × N log k). The overall complexity is
O(N log m + m × N log k) = O(N × (log m + m log k)),
which is signiﬁcantly smaller than O(N · (N log k + log m)),
when m and k are not comparable to N. The algorithm for
optimal attacking strategy is summarized in Algorithm 1.
V. NETWORK DEFENSE
Based on the above discussion of the optimal attacking by
the adversary, in this section, we consider how to minimize
the total opinion in (12) under such adversarial network
perturbation. Here, we also relax the objective function with
(14) as in Section IV, and formulate the following defense
problem.
min
sss
max
A,Tu
111TBBBAAAsss + p × 111TBBB(III −AAA)∆
∆
∆WBBBAAAsss
s.t.







111T (sss0 −sss) ≤µ,
000 ≤sss ≤sss0,
|A| ≤m,
|Tu| ≤k, ∀u ∈A.
(26)
Algorithm 1: Linear search algorithm for (15)
Input: ccc1,ccc2,zzz∗and constraints of m and k
Output: Optimal attacker set A∗and optimal target
user set T ∗
u for u ∈A∗
1 Sorted z∗(u) in descending order an pick top m of it
as the candidate attackers A[m];
2 A∗←∅;
3 for u ∈A[m] do Searching for optimal attackers.
4
Calculate δuv = c1(v) ·
 z∗(u) −c2(v)

for each v;
5
Sorted δuv in descending order and pick top k of it
as Tu;
6
T ∗
u ←∅, δ∗
u ←0;
7
for v ∈Tu do Searching for optimal target users.
8
if δuv > 0 then
9
δ∗
u ←δ∗
u + δuv, T ∗
u ←T ∗
u ∪{v}
10
else
11
break;
12
end
13
end
14
if δ∗
u ≤0 then
15
break;
16
end
17
A∗←A∗∪{u};
18 end
We next show the convexity of the relaxed network defense
problem in (26).
Theorem 1. The problem in (26) is convex.
Proof. Let A be the set of all possible attacker sets. That is,
for any |A| ≤m, ∀A ∈A. Similarly, let Tu be the set of all
possible target user set of attacker u. That is, for any |Tu| ≤
k, ∀Tu ∈Tu. Note that the variable of the inner maximization,
i.e., A and Tu are only related to ∆
∆
∆W . Thus, we also denote
∆
∆
∆W by ∆
∆
∆W (A, Tu) for clarity here.
Note that when A and Tu are given, the function
111TBBBAAAsss + p × 111TBBB(III −AAA)∆
∆
∆W (A, Tu)BBBAAAsss
is a linear function with respect to the decision variable sss.
Consequently, the inner maximization of (26) is the supremum
of all possible linear function of sss, when A is taken from A and
Tu is taken from Tu. Thus, the objective of the minimization
is convex with respect to sss. In terms of the constraints, both
111T (sss0 −sss) ≤µ and 000 ≤sss ≤sss0 are convex set with respect
to sss. Therefore, (26) is a convex problem.
From Theorem. 1, a direct method to solve (26) is to
introduce the upper bound ub, and transform the problem in
(26) as
min
sss,ub
ub
s.t.







111T (sss0 −sss) ≤µ,
000 ≤sss ≤sss0,
111TBBBAAAsss + p111TBBB(III −AAA)∆
∆
∆W (A, Tu)BBBAAAsss ≤ub,
∀A ∈A, and ∀Tu ∈Tu
(27)

7
Algorithm 2: Projected subgradient method for (26)
Input: BBB,W
W
W,AAA,sss0 and constraints of m, k, µ
Parameters: Initial step size η0 and number of
interation Tmax
Output: Optimal controlled innate opinions sss∗
1 f ∗←+∞, sss∗←sss0, ccc1 = (111TBBB(III −AAA))T , T ←0;
2 while T < Tmax do
// Attacking step: choose A∗and T ∗
u
3
zzz∗←BBBAAAsss, ccc2 ←W
W
Wzzz∗;
4
A∗, T ∗
u ←Algorithm 1(ccc1,c2
c2
c2, z∗, m, k);
5
Calculate ∆
∆
∆W with (9) using A∗and T ∗
u ;
6
f ←111TBBBAAAsss + p × 111TBBB(III −AAA)∆
∆
∆WBBBAAAsss;
7
if f ∗< f then
8
f ∗←f, sss∗←sss;
9
end
// Defense adjustment: update sss
10
Calculate subgradient ggg with (28);
11
η = η0/
√
k;
12
Update sss ←Proj(sss −η · ggg);
13
T ←T + 1;
14 end
The above transformed problem is a linear programming and
can be solved with interior-point method [27]. However, the
challenge is that there are too many constraints, because we
need to check every possible attacker set A and Tu. Therefore,
we directly solve (26).
A. Project Subgradient Algorithm for Network Defense
The challenge of directly solving (26) is that the inner max-
imization function introduces non-differentiability. Note that
there are also constraints on the variable sss. To address these
challenges, we devise a projected subgradient algorithm [28]
to solve (26). The algorithm is summarized in Algorithm 2. In
the next, we elaborate the details of the designed algorithm.
The algorithm starts from the uncontrolled innate opinions
sss0. The core idea is to update the controlled innate opinions sss
iteratively with the guidance of subgradient. In each iteration
T, We ﬁrst calculate the subgradient of the objective function
in (26). Thanks to our analysis in Section IV, we can ﬁrst
efﬁciently solve the inner maximization with Algorithm 1,
when sss is given. This corresponds to line 3 and line 4 in
Algorithm 2.
Then, according to [28], we calculate the subgradient (line
10 in Algorithm 2) as
ggg = (BBBAAA)T111 + p ×
 BBB(III −AAA)∆
∆
∆WBBBAAA
T111.
(28)
where ∆
∆
∆W is calculated with the optimal attacker set A∗and
optimal target user sets T ∗
u (line 5 in Algorithm 2). Here, we
also record the optimal variable sss∗and optimal objective f ∗
during the iteration (line 6-9 in Algorithm 2), since subgradient
algorithm is not a descent method [28].
Finally, with the calculated subgradient ggg in (28), we
update the controlled innate opinions sss as in the line 12 of
Algorithm 2. We adopt the nonsummable diminishing rule [28]
for the choice of step size η, which guarantees the convergence
and the optimality of the subgradient method. The discussion
of convergence and optimality will be shown Section V-B. In
addition, since we have two constraints on sss in problem (26),
we need to project sss−η ·ggg on the feasible set when updating.
Here, we denote the projection function (algorithm) as Proj(·).
Note that, in (26), the ﬁrst constratint is one sinlge equality
constraint on the total control budget, while the second one is
a box constraint on the range of controlled innate opinion sss.
Thus, the feasible set of (26) is the intersection of a hyperplane
and a box area. In this work, we implement the projection
algorithm in [29] whose time complexity is O(n). To this end,
the time complexity of one single iteration of Algorithm 2 is
O(N × (log m + m log k + 1)).
Game-Theoretical Interpretation. The above process it-
erates until the maximal interation Tmax is reached. We can
also divide one single iteration in Algorithm 2 as two part.
The ﬁrst part includes line 3-5, which solves the optimal
attacking strategy for the adversarial network perturbation,
given the current controlled innate opinion sss. We deﬁne this
part as the attacking step. The second part includes line 10-
12, where the defender adjusts the variable sss according to
current optimal attacking strategy A∗and T ∗
u . We deﬁne this
part as the defense adjustment. Consequently, the iterations in
Algorithm 2 can be regarded as a game played between the
adversary and the defender. The adversary and the defender
update their actions in turn. The updating criterion for the
adversary is Algorithm 1, while the updating policy for the de-
fender is based on the subgradient in (28). Since Algorithm 2 is
guaranteed to converge to the optimal solution, the converged
results can be regarded as the Nash equilibrium in the above
game.
B. Convergence of the Proposed Algorithm
Given the network defense algorithm in Algorithm 2, we
next analyze the convergence of it, and have the following
theorem
Theorem 2. Let f ∗be the optimal value of problem (26), and
f ∗
alg be the optimal value given by Algorithm 2 with Tmax
iterations in total. We have
f ∗
alg −f ∗≤
µ2 + ξ2N ·

1 + 2mkp2 ·

1
αmin −1
2
ξ1
(29)
where ξ1 = PTmax
i=1
1/
√
i, ξ2 = PTmax
i=1
1/i, and αmin =
mini αi is the smallest stubbornness value of all users.
Proof. see Appendix A
From Theorem. 2, as Tmax →∞, the right hand side of
(29) →0, and thus, f ∗
alg →f ∗. This indicates that when the
number of iteration Tmax is sufﬁciently large, Algorithm 2
converge the optimal solution of problem (26).
Theorem. 2 shows the convergence speed of Algorithm 2.
That is, in practice, we can use Theorem. 2 to decide the
number of iterations Tmax for a desired optimality f ∗
alg −f ∗.
From (29), we can see that when the network size is large (i.e.,
a larger N), Algorithm 2 needs more iterations to converge
to a desired optimality. We can also see that when there are

8
TABLE I
NETWORK STATISTICS
Network
Nodes : |V|
Edges|E|
Avg. Degree
Reddit [30]
553
8969
32.4
Collaboration [31]
679
1687
4.97
Facebook [32]
4039
88234
43.6
more attackers (i.e., a larger m), and when the attackers can
inﬂuence more target users (i.e., a larger k), the convergence
of Algorithm 2 is also slower. In addition, the convergence of
(2) is more sensitive to the strength of perturbation coefﬁcient
p due to the square term p2 in the right hand side of (29).
When the perturbation strength is small (i.e., a smaller p), the
inﬂuence of the adversarial network perturbation is limited,
and thus, the convergence speed of Algorithm 2 is faster. We
can also see that user’s stubbonrness value plays a critical
role in the convergence speed of Algorithm 2. When users
have a larger stubbornness value (i.e., a larger αmin), they
are less inﬂuenced by others, and the inﬂuence of network
perturbation is also smaller. Therefore, Algorithm 2 can have
a faster convergence speed.
VI. EXPERIMENTS
In this section, we run simulation on real social networks to
validate our analysis and the proposed control algorithm. We
use the network of online discussion forum Reddit (Reddit
network for short) in [30], the collaboration network of “Data
Mining” (Collaboration network for short) in [31], and the
online social network of Facebook (Facebook network for
short) in [32]. The basic information of the above networks
are listed in Table I. For the Collaboration network and the
Facebook network, we randomly generated the users’ initial
internal opinions sss0 in range (0.6, 1). For the Reddit network,
we use the initial innate opinions that are provided in the
original dataset [30]. For all networks, we randomly generate
users’ stubbonrness value αi in range (0, 1). We also randomly
generate the inﬂuence weights of the adjacency matrix W
W
W, and
unify each row of W
W
W so that it is a row stochastic matrix. To
avoid inﬂuence of randomness, we repeat each experiment for
10 times, and report the mean results in the following.
A. Validation of the Approximation in Proposition. 1
As the main results of this paper are based on the approxi-
mation in Proposition. 1, we ﬁrst verify the correctness of it.
We ﬁrst calculate the total opinion f with the initial internal
opinions sss0, users’ stubbornness αi, and the adjacency matrix
W
W
W according to (2). Then, we generate the optimal attackers
A∗and the optimal target users T ∗
u as in Section IV-B, and
use them to perturb the networks as described in Section III-A
to obtain the perturbed network strucutre ˜
W
W
W. Next, with users’
initial internal opinions sss0, stubbornness αi, and the network
structure ˜
W
W
W, we simulate the FJ opinion dynamics model, and
obtain the total opinion with adversarial network perturbtion
˜f. We also calculate the approximate total opinion ˜fest as
in Proposition. 1. We show the increase of the total opinion
Number of Attackers: 𝑚𝑚
Theoretical
Simulation
𝑝𝑝: Perturbation Coeff.
𝑝𝑝↑
𝑝𝑝= 0.02
𝑝𝑝= 0.04
𝑝𝑝= 0.06
𝑝𝑝= 0.08
𝑝𝑝= 0.10
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓or ̃𝑓𝑓𝑒𝑒𝑒𝑒𝑒𝑒−𝑓𝑓
(a) Reddit, k = 100
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓or ̃𝑓𝑓𝑒𝑒𝑒𝑒𝑒𝑒−𝑓𝑓
Number of Target Users: 𝑘𝑘
Theoretical
Simulation
𝑝𝑝: Perturbation Coeff.
𝑝𝑝↑
𝑝𝑝= 0.02
𝑝𝑝= 0.04
𝑝𝑝= 0.06
𝑝𝑝= 0.08
𝑝𝑝= 0.10
(b) Reddit, m = 8
Number of Attackers: 𝑚𝑚
Theoretical
Simulation
𝑝𝑝: Perturbation Coeff.
𝑝𝑝↑
𝑝𝑝= 0.02
𝑝𝑝= 0.04
𝑝𝑝= 0.06
𝑝𝑝= 0.08
𝑝𝑝= 0.10
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓or ̃𝑓𝑓𝑒𝑒𝑒𝑒𝑒𝑒−𝑓𝑓
(c) Collaboration, k = 100
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓or ̃𝑓𝑓𝑒𝑒𝑒𝑒𝑒𝑒−𝑓𝑓
Number of Target Users: 𝑘𝑘
Theoretical
Simulation
𝑝𝑝: Perturbation Coeff.
𝑝𝑝↑
𝑝𝑝= 0.02
𝑝𝑝= 0.04
𝑝𝑝= 0.06
𝑝𝑝= 0.08
𝑝𝑝= 0.10
(d) Collaboration, m = 8
Number of Attackers: 𝑚𝑚
Theoretical
Simulation
𝑝𝑝: Perturbation Coeff.
𝑝𝑝↑
𝑝𝑝= 0.02
𝑝𝑝= 0.04
𝑝𝑝= 0.06
𝑝𝑝= 0.08
𝑝𝑝= 0.10
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓or ̃𝑓𝑓𝑒𝑒𝑒𝑒𝑒𝑒−𝑓𝑓
(e) Facebook, k = 100
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓or ̃𝑓𝑓𝑒𝑒𝑒𝑒𝑒𝑒−𝑓𝑓
Number of Target Users: 𝑘𝑘
Theoretical
Simulation
𝑝𝑝: Perturbation Coeff.
𝑝𝑝↑
𝑝𝑝= 0.02
𝑝𝑝= 0.04
𝑝𝑝= 0.06
𝑝𝑝= 0.08
𝑝𝑝= 0.10
(f) Facebook, m = 8
Fig. 1. Increase of total opinion on different social networks. (Left) Number
of target users is k = 100. (Right) Number of attackers is m = 8.
( ˜f −f) and the estimated one, that is, ( ˜fest −f) on three
networks in Figure 1.
From Figure 1, we can see that our theoretical approx-
imated results match well with the simulation results on
four networks with different perturbation coefﬁcient p, the
number of attackers m, and the number target users k. We
can see that when there are more attackers and when the
attackers can inﬂuence more target users, the increase of total
opinion is larger. In addition, we can also see that when the
perturbation coefﬁcient p is larger, the increase of total opinion
is also larger. This observation validates the inﬂuence of the
perturbation coefﬁcient p on the change of total opinion.
B. Validation of Optimal Choice of Attackers and Target Users
In this section, we validate the performance of the selection
criterion of attackers and target users in Section IV.

9
Attackers with Alg.1
Internal Opinion
PageRank
Outdegree
Random
Number of Attackers: 𝑚𝑚
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓
(a) Reddit
Number of Attackers: 𝑚𝑚
Attackers with Alg.1
Internal Opinion
PageRank
Outdegree
Random
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓
(b) Collaboration
Number of Attackers: 𝑚𝑚
Attackers with Alg.1
Internal Opinion
PageRank
Outdegree
Random
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓
(c) Facebook
Fig. 2. Increase of total opinion ( ˜f −f) when using different criterion to choose attackers.
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓
Number of Target Users: 𝑘𝑘
Target Users with Alg.1
Internal Opinion
Neighbors’ Average Opinion
Stubbornness
PageRank
Outdegree
Random
(a) Reddit
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓
Number of Target Users: 𝑘𝑘
Target Users with Alg.1
Internal Opinion
Neighbors’ Average Opinion
Stubbornness
PageRank
Outdegree
Random
(b) Collaboration
Increase of Total Opinion: ̃𝑓𝑓−𝑓𝑓
Number of Target Users: 𝑘𝑘
Target Users with Alg.1
Internal Opinion
Neighbors’ Average Opinion
Stubbornness
PageRank
Outdegree
Random
(c) Facebook
Fig. 3. Increase of total opinion ( ˜f −f) when using different criterion to choose target users.
1) Choose of Attackers: We ﬁrst validate the selection of
optimal attackers in Algorithm 1. We choose the following
heuristic criterion as baseline.
• Internal Opinion which selects users with the largest
internal opinion si as the attacker;
• PageRank which selects users with the largest PageRank
value as the attacker;
• Outdegree which selects users with the largest outdegree
and can inﬂuence more users as the attacker; and
• Random which randomly selects users as the attackers.
For each selected attacker u, we use the proposed selection
rule of target user in Section IV-B to decide his/her optimal
target user set T ∗
u . The perturbation coefﬁcient is set to p =
0.1, and the number of target user for each attacker is set to
k = 100. We change the number of attacker m, and show the
increase of total opinion ˜f −f on three networks in Figure 2.
When we select more attackers (i.e., a larger m), the increase
of total opinion ( ˜f −f) becomes larger. This shows that more
attackers can cause a large perturbation in terms of the total
opinion.
We also can see that the proposed selection criterion of
the attackers outperforms other heuristics criterion by a large
extent. We empirically ﬁnd that choosing users with large
internal opinion performs better than other two heuristics
that only use network structure information and randomly
selection. This indicates that users with larger internal opinions
can cause a larger perturbation on the total opinion.
2) Choose of Target Users: Next, we validate the selection
of optimal target users in Algorithm 1. We also adopt the four
heuristic criterions in the above as the baseline methods to
select the target users for each attacker. In addition, according
to our analysis in Section IV, we add the following two
heuristic criterions:
• Stubbornness which selects users with the smallest stub-
bornness value as target user;
• Neighbors’ Average Opinion which selects users with
the largest neighbors’ average opinion (W
W
Wzzz∗)i as target
user.
We select m = 5 attackers according to the criterion as in
Section IV, and set the strength of perturbation coefﬁcient
p = 0.1. The increase of total opinion ( ˜f −f) with different
number of target user k is shown in Figure 3
From Figure 3, we can see that the selection criterion of
target user in Algorithm 1 performs better than all heuristic
baseline methods. When the attackers can inﬂuence more
target users (i.e., a larger k), the their inﬂuence on the increase
of total opinion is larger. In addition, we can also see that, the
stubbornness criterion performs better than other heuristics
methods on Reddit network. However, on Citation network
and Facebook network, heuristic criterions related to net-
work structure (PageRank critertion and Outdegree criterion)
performs better than other baselines. This indicates that the
network structure plays a more critical role on the perturbation
of these two networks.
C. Validation of Network Defense
In this secion, we validate the proposed network defense
algorithm in Section V. We set the perturbation coefﬁcient

10
Total Opinion: 𝑓𝑓or ̃𝑓𝑓
Total Opinion Without
Perturbation Using Alg. 2
Total Opinion Without
Perturbation Using
“Min-Total”
Total Opinion With
Perturbation Using Alg. 2
Total Opinion With
Perturbation Using 
“Min-Total”
Control Budget: 𝜇𝜇
(a) Reddit
Control Budget: 𝜇𝜇
Total Opinion: 𝑓𝑓or ̃𝑓𝑓
Total Opinion Without
Perturbation Using Alg. 2
Total Opinion Without
Perturbation Using
“Min-Total”
Total Opinion With
Perturbation Using Alg. 2
Total Opinion With
Perturbation Using 
“Min-Total”
(b) Collaboration
Total Opinion: 𝑓𝑓or ̃𝑓𝑓
Total Opinion Without
Perturbation Using Alg. 2
Total Opinion Without
Perturbation Using
“Min-Total”
Total Opinion With
Perturbation Using Alg. 2
Total Opinion With
Perturbation Using 
“Min-Total”
Control Budget: 𝜇𝜇
(c) Facebook
Fig. 4. The total opinion with and without network perturbation using different control strategy.
p = 0.15. The number of attackers and the number of target
users for each attacker are set to m = 6 and k = 100,
respectively, for three networks. We can observe the similar
results with other parameters settings, and omit them. With
the initial internal opinions sss0, we ﬁrst use the proposed
algorithm in Section V to obtain the controlled internal opinion
sss. The number of iteration Tmax is calculated with (29)
by setting the error tolerence to 0.01. Then, we use (4)
to obtain the total opinion f when there is no adversarial
network perturbation. Next, we perturb the network structure
as described in Section IV, and simulate the FJ opinion
dynamics to obtain the total opinion ˜f after the adversarial
network perturbation. In Figure 4, We plot the total opinion
with and without the adversarial network perturbation in
Figure 4, respectively, when the control budget µ changes.
We also compare the proposed defense algorithm with the
“Min-Total” control strategy as in [14]. That is, We use “Min-
Total” algorithm to derive the controlled internal opinions, and
repeat the above process to obtain the total opinion with and
without the adversarial network perturbation. The results are
also shown in Figure 4.
From Figure 4, when there is no network perturbation, the
total opinion given by “Min-Total” is slightly lower than that
given by our defense algorithm. This is because that “Min-
Total” focus on minimizing the total opinion when there is no
network perturbation, and can obtain the optimal solution [14].
However, when the adversarial network perturbation exists, the
total opinion given by the proposed network defense algorithm
is signiﬁcantly lower than that given by “Min-Total” algorithm.
When using the “Min-Total” control algorithm, we can see
that the total opinion increases dramatically after the network
perturbation. Furthermore, the increase in the total opinion
becomes larger when the control budget µ is larger. For the
Facebook network, when the control budget is µ = 2000, the
total opinion surprisingly increases 200% compared to the one
without adversarial network perturbation, even if there is only
six attackers and each attackers can only inﬂuence 2.5% users
in the whole network. Nevertheless, when using the proposed
network defense algorithm, the increase of total opinion is
negaliable. These observations show that the proposed network
defense algorithm is more robust to the adversarial network
perturbation, and thus, can obtain a lower total opinion with
the perturbation.
VII. CONCLUSION
In this work, we consider the adversarial network perturba-
tion, where the adversary can let some attackers spread their
extreme opinions to target users. We theoreticaly analyze such
adversarial network perturbation’s inﬂuence on the network’s
total opinion. From the adversary’s perspective, we analyze the
optimal strategy to choose the attackers and the target users, so
that the total opinion is maximized. Then, from the network
defender’s perspective, we formualte a Stackelberg game to
minimize the total opinion under such adversarial network
perturbation, and device an projected subgradient algorithm
to solve the fromulated game. Simulations on real social
networks validate our analysis of the network perturbation and
the effectiveness of the proposed opinion contorl algorithm.
REFERENCES
[1] A. M. Guess, P. Barber´a, S. Munzert, and J. Yang, “The consequences
of online partisan media,” Proc. Natl. Acad. Sci. U.S.A., vol. 118, no. 14,
2021.
[2] T.
T.
E.
BOARD,
“Editorial:
Trump
is
responsible
for
the
violent
storming
of
u.s.
capitol,”
[Online],
https://www.latimes.com/opinion/
story/2021-01-06/trump-supporters-
storming-capitol-pence-biden.
[3] T. M. Liggett, Stochastic interacting systems: contact, voter and exclu-
sion processes.
Springer Science & Business Media, 2013, vol. 324.
[4] P. L. Krapivsky and S. Redner, “Dynamics of majority rule in two-state
interacting spin systems,” Phys. Rev. Lett., vol. 90, no. 23, p. 238701,
2003.
[5] M. Granovetter, “Threshold models of collective behavior,” Am. J.
Sociol., vol. 83, no. 6, pp. 1420–1443, 1978.
[6] M. H. DeGroot, “Reaching a consensus,” J. Am. Stat. Assoc., vol. 69,
no. 345, pp. 118–121, 1974.
[7] R. Hegselmann and U. Krause, “Opinion dynamics and bounded conﬁ-
dence models, analysis, and simulation,” J. Artif. Soc. Soc. Simul., vol. 5,
no. 3, 2002.
[8] N. E. Friedkin and E. C. Johnsen, “Social inﬂuence and opinions,” J.
Math. Sociol., vol. 15, no. 3-4, pp. 193–206, 1990.
[9] D. Bindel, J. Kleinberg, and S. Oren, “How bad is forming your own
opinion?” Games Econ. Behav., vol. 92, pp. 248–265, 2015.
[10] N. E. Friedkin, “A formal theory of reﬂected appraisals in the evolution
of power,” Adm. Sci. Q., vol. 56, no. 4, pp. 501–529, 2011.
[11] D. Kempe, J. Kleinberg, and ´E. Tardos, “Maximizing the spread of
inﬂuence through a social network,” in Proc. 9th ACM Int. Conf. Knowl.
Discovery and Data Min. (SIGKDD), 2003, pp. 137–146.
[12] A. Gionis, E. Terzi, and P. Tsaparas, “Opinion maximization in social
networks,” in Proc. 13th SIAM Int. Conf. Data Min. (SDM).
SIAM,
2013, pp. 387–395.
[13] R. Abebe, J. Kleinberg, D. Parkes, and C. E. Tsourakakis, “Opinion
dynamics with varying susceptibility to persuasion,” in Proc. 24th ACM
Int. Conf. Knowl. Discovery and Data Min. (SIGKDD), 2018, pp. 1089–
1098.

11
[14] P. Xu, W. Hu, J. Wu, and W. Liu, “Opinion maximization in social
trust networks,” in Proceedings of the 29th Int. Joint Conf. Artiﬁ. Intell.
(IJCAI), 2020, pp. 1251–1257.
[15] A. Matakos, E. Terzi, and P. Tsaparas, “Measuring and moderating
opinion polarization in social networks,” Data Min. Knowl. Discov.,
vol. 31, no. 5, pp. 1480–1505, 2017.
[16] X. Chen, J. Lijfﬁjt, and T. De Bie, “Quantifying and minimizing risk
of conﬂict in social networks,” in Proc. 24th ACM Int. Conf. Knowl.
Discovery and Data Min. (SIGKDD), 2018, pp. 1197–1205.
[17] C. Musco, C. Musco, and C. E. Tsourakakis, “Minimizing polarization
and disagreement in social networks,” in Proc. 27th Conf. World Wide
Web (WWW), 2018, pp. 369–378.
[18] M. F. Chen and M. Z. Racz, “An adversarial model of network dis-
ruption: Maximizing disagreement and polarization in social networks,”
IEEE Transactions on Network Science and Engineering, 2021.
[19] J. Gaitonde, J. Kleinberg, and E. Tardos, “Adversarial perturbations of
opinion dynamics in networks,” in Proc. of 21st ACM Conf. Econ. and
Comput., 2020, pp. 471–472.
[20] D. Greene, D. Doyle, and P. Cunningham, “Tracking the evolution of
communities in dynamic social networks,” in Proc. 2010 Int. Conf. Adv.
Soc. Netw. Anal. Mining.
IEEE, 2010, pp. 176–183.
[21] F. Pereira, S. De Amo, and J. Gama, “Evolving centralities in temporal
graphs: a twitter network analysis,” in 2016 17th IEEE international
conference on mobile data management (MDM), vol. 2.
IEEE, 2016,
pp. 43–48.
[22] A.-L. Barab´asi and R. Albert, “Emergence of scaling in random net-
works,” Science, vol. 286, no. 5439, pp. 509–512, 1999.
[23] U. Chitra and C. Musco, “Analyzing the impact of ﬁlter bubbles on
social network polarization,” in Proc. 13th ACM Int. Conf. Web Search
and Data Min., 2020, pp. 115–123.
[24] E. Pariser, The ﬁlter bubble: What the Internet is hiding from you.
Penguin UK, 2011.
[25] E. C. and S. B., “Small perturbation analysis of network topologies,” in
Proc. 43th IEEE Int. Conf. Acoust., Speech, Signal Process. (ICASSP).
IEEE, 2018, pp. 4194–4198.
[26] T. H. H. Chan, Z. Liang, and M. Sozio, “Revisiting opinion dynamics
with varying susceptibility to persuasion via non-convex local search,”
in Proc. 28th Conf. World Wide Web (WWW), 2019, pp. 173–183.
[27] S. Boyd and L. Vandenberghe, Convex optimization.
Cambridge
university press, 2004.
[28] S. Boyd, L. Xiao, and A. Mutapcic, “Subgradient methods,” lecture
notes of EE392o, Stanford University, Autumn Quarter, vol. 2004, pp.
2004–2005, 2003.
[29] N. Maculan, C. P. Santiago, E. M. Macambira, and M. H. C. Jardim,
“An o (n) algorithm for projecting a vector on the intersection of a
hyperplane and a box in rn,” J. Optim. Theory Appl., vol. 117, no. 3,
pp. 553–574, 2003.
[30] A. De, S. Bhattacharya, P. Bhattacharya, N. Ganguly, and S. Chakrabarti,
“Learning a linear inﬂuence model from transient opinion dynamics,”
in Proc. 23rd ACM Int. Conf. Inf. and Knowl. Manage. (CIKM), 2014,
pp. 401–410.
[31] J. Tang, J. Sun, C. Wang, and Z. Yang, “Social inﬂuence analysis
in large-scale networks,” in Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data mining,
2009, pp. 807–816.
[32] J. Leskovec and J. Mcauley, “Learning to discover social circles in ego
networks,” Advances in neural information processing systems, vol. 25,
2012.
APPENDIX A
PROOF OF THEOREM. 2
To prove Theorem. 2, we ﬁrst present the following lemma.
Lemma 1 (Convergence of Project Subgradient Method). Let
sss∗be the optimal solution to the problem in (26), and sss0 is
the initial point of Algorithm 2. If ∥sss0 −sss∥2 ≤R and the
subgradient in (28) satisﬁes that ∥ggg∥2 ≤G, then we have
f ∗
alg −f ∗≤R2 + η2
0G2ξ2
2η0ξ1
,
(30)
where f ∗
alg is the optimal value given by Algorithm 2 with
Tmax iterations, η0 is the initial step size of Algorithm 2,
ξ1 = PTmax
i=1
1/
√
i, and ξ2 = PTmax
i=1
1/i.
Proof. See Section 3.2 and Section 6 in [28].
Now, with Lemma. 1, to prove Theorem. 2, we need to ﬁnd
the upper bound R2 and G2. We ﬁrst calculate R2, which is
the upper bound of the Euclidean distance between the initial
innate opinions sss0 and the optimal controlled innate opinion
sss. Consequently, we have the following lemma
Lemma 2.
∥sss0 −sss∗∥2
2 ≤µ2,
(31)
where µ is the control budget.
Proof. Let ddd = sss0 −sss∗, and di = s0(i) −s∗
i . Since sss∗is the
optimal solution to problem (26), it is also a feasible solution.
Thus, 000 ⪯sss∗⪯sss0, and 000 ⪯ddd ⪯sss0, that is, 0 ≤di ≤s0(i). In
addition, with the control budget constraint 111Tsss0 −111Tsss∗= µ,
we also have 111Tddd = µ, that is, P
i di = µ. Note that
µ2 = (d1 + · · · + dN)2 =
X
i
d2
i + 2 ×
X
i̸=j
didj
= ∥ddd∥2
2 + 2 ×
X
i̸=j
didj
⇒∥ddd∥2
2 = ∥sss0 −sss∗∥2
2 = µ2 −2 ×
X
i̸=j
didj.
With di ≥0 for each i, we have 2 × P
i̸=j didj ≥0.
Consequently, we have∥ddd∥2
2 ≤µ2. This ends the proof.
Next, we analyze G, which is the upper bound of subgra-
dient ggg’s length, and have the following lemma
Lemma 3.
∥ggg∥2
2 ≤N∥BBB∥2
2
 1 + p2mk · ∥BBB∥2
2(1 + ∥W
W
W∥2
2)

.
(32)
where W
W
W is the adjacency matrix, and BBB = [III −(III −AAA)W
W
W]−1.
Proof. With the deﬁnition of subgradient in (28), we ﬁrst have
∥ggg∥2
2 = ∥(BBBAAA)T111 + p ×
 BBB(III −AAA)∆
∆
∆WBBBAAA
T111∥2
2
≤∥(BBBAAA)T111∥2
2 + p2 × ∥
 BBB(III −AAA)∆
∆
∆WBBBAAA
T111∥2
2.
We ﬁrst analyze the ﬁrst term ∥(BBBAAA)T111∥2
2, and we can have
∥(BBBAAA)T111∥2
2 ≤∥(BBBAAA)T ∥2
2 · ∥111∥2
2 = N · ∥BBBAAA∥2
2
≤N · ∥BBB∥2
2∥AAA∥2
2 = α2
maxN∥BBB∥2
2 ≤N∥BBB∥2
2,
where αmax is the largest stubbornness of the whole popula-
tion and αmax ≤1.
Next, we analyze ∥
 BBB(III−AAA)∆
∆
∆WBBBAAA
T111∥2
2. We ﬁrst rewrite
this term as
∥
 BBB(III −AAA)∆
∆
∆WBBBAAA
T111∥2
2 = ∥AAABBBT∆
∆
∆T
W (III −AAA)BBBT111∥2
2
≤∥AAA∥2
2 · ∥BBBT ∥4
2 · ∥∆
∆
∆T
W ∥2
2 · ∥III −AAA∥2
2 · ∥111∥2
2
= Nα2
max · (1 −αmin)2∥BBB∥4
2 · ∥∆
∆
∆W ∥2
2
≤N∥BBB∥4
2 · ∥∆
∆
∆W ∥2
2
(33)
where αmin is the smallest stubbornness of the whole popu-
lation, and 1 −αmin ≤1.

12
Next, we anlayze the term ∥∆
∆
∆W ∥2
2. With the deﬁnition of
∆
∆
∆W in (9), we have
∥∆
∆
∆W ∥2
2 =

X
v∈T
eeev
X
u∈Av
eeeT
u −
X
v∈T
|Av|eeeveeeT
v W
W
W

2
2
=

X
v∈T
X
u∈Av
eeeveeeT
u −
X
v∈T
X
u∈Av
eeeveeeT
v W
W
W

2
2
=

X
v∈T
X
u∈Av
 eeeveeeT
u −eeeveeeT
v W
W
W


2
2
=

X
u∈A
X
v∈Tu
 eeeveeeT
u −eeeveeeT
v W
W
W


2
2
≤
X
u∈A
X
v∈Tu
eeeveeeT
u −eeeveeeT
v W
W
W
2
2
≤
X
u∈A
X
v∈Tu
eeeveeeT
u
2
2 +
eeeveeeT
v
2
2 · ∥W
W
W∥2
2
For the term eeeveeeT
u , its Frobenius norm satisﬁes ∥eeeveeeT
u ∥2
F =
tr(eeeveeeT
ueeeueeeT
v ) = 1. According to the relation that ∥CCC∥2 ≤
∥CCC∥F for any square matrix CCC, we can have ∥eeeveeeT
u ∥2 ≤
∥eeeveeeT
u ∥F = 1. Thus, ∥eeeveeeT
u ∥2
2 ≤1. Similarly, we can also
have ∥eeeveeeT
v ∥2
2 ≤1. Consequently, we have
∥∆
∆
∆W ∥2
2 ≤
X
u∈A
X
v∈Tu
eeeveeeT
u
2
2 +
eeeveeeT
v
2
2 · ∥W
W
W∥2
2
≤
X
u∈A
X
v∈Tu
(1 + ∥W
W
W∥2
2) ≤mk · (1 + ∥W
W
W∥2
2).
(34)
With ∥∆
∆
∆W ∥2
2 in (34) and the derivation in (33), we have
∥
 BBB(III −AAA)∆
∆
∆WBBBAAA
T111∥2
2 ≤N∥BBB∥4
2∥∆
∆
∆W ∥2
2
≤Nmk∥BBB∥4
2∥(1 + ∥W
W
W∥2
2),
Consequently, we have the upper bound of subgradient ggg, that
is,
∥ggg∥2
2 ≤∥(BBBAAA)T111∥2
2 + p2 × ∥
 BBB(III −AAA)∆
∆
∆WBBBAAA
T111∥2
2
≤N∥BBB∥2
2
 1 + p2mk · ∥BBB∥2
2(1 + ∥W
W
W∥2
2)

This ends the proof.
With the above lemmas, we can replace R2 and G2 in (30)
with µ2 and

1 + 2mkp2 ·

1
αmin −1
2
, respectively. This
leads to the convergence in (29).

