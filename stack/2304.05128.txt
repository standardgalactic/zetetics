Teaching Large Language Models to Self-Debug
Xinyun Chen
Google Research
xinyunchen@google.com
Maxwell Lin
UC Berkeley
mxlin@berkeley.edu
Nathanael Schärli
Google Research
schaerli@google.com
Denny Zhou
Google Research
dennyzhou@google.com
Abstract
Large language models (LLMs) have achieved impressive performance on code
generation. However, for complex programming tasks, generating the correct
solution in one go becomes challenging, thus some prior works have designed
program repair approaches to improve code generation performance. In this work,
we propose SELF-DEBUGGING, which teaches a large language model to debug its
predicted program via few-shot demonstrations. In particular, we demonstrate that
SELF-DEBUGGING can teach the large language model to perform rubber duck
debugging; i.e., without any feedback on the code correctness or error messages,
the model is able to identify its mistakes by explaining the generated code in
natural language. SELF-DEBUGGING achieves the state-of-the-art performance on
several code generation benchmarks, including the Spider dataset for text-to-SQL
generation, TransCoder for C++-to-Python translation, and MBPP for text-to-
Python generation. On the Spider benchmark where there are no unit tests to
verify the correctness of predictions, SELF-DEBUGGING with code explanation
consistently improves the baseline by 2−3%, and improves the prediction accuracy
on problems of the hardest label by 9%. On TransCoder and MBPP where unit tests
are available, SELF-DEBUGGING improves the baseline accuracy by up to 12%.
Meanwhile, by leveraging feedback messages and reusing failed predictions, SELF-
DEBUGGING notably improves sample efﬁciency, and can match or outperform
baseline models that generate more than 10× candidate programs.
1
Introduction
Code generation has been a long-standing challenge with a variety of applications, such as code
synthesis from natural languages [63, 8, 2, 32], programming by examples [14, 5, 11], and code
translation [44, 10]. In particular, recent large language models have demonstrated a signiﬁcant leap
in improvement over prior deep neural networks [8, 13, 38, 67, 57]. However, for many programming
tasks, generating correct code with a single attempt is challenging. Inspired by observations that
correct code is much more likely to be predicted when multiple programs are sampled from the
model [8, 13, 32], one line of work has designed reranking techniques to select the best candidate
from multiple samples, which typically requires tens of samples to start with [49, 65, 37, 32].
Intuitively, even for human programmers, there is no guarantee that the code written on the ﬁrst
try is always accurate. Instead of completely discarding the incorrect code, humans typically look
into the code and investigate execution results, then make changes to resolve the implementation
errors. Therefore, prior works propose deep learning techniques to repair the predicted code, which
demonstrate notable performance gains on various coding tasks [20, 53, 17, 6]. However, these
approaches require additional training for the code repair model. While some recent works show that
arXiv:2304.05128v1  [cs.CL]  11 Apr 2023

large language models have potential for generating feedback messages to critique and reﬁne their
outputs for some natural language and reasoning domains [50, 35, 28, 36, 3], prior works suggest that
such large language models are not yet capable of correcting code when lacking external feedback,
such as unit tests or human instructions [6].
In this work, we propose SELF-DEBUGGING, where we teach the large language model to debug
its own predicted code via few-shot prompting. Without any additional model training, SELF-
DEBUGGING instructs the model to execute the code, then generate a feedback message based on the
code and its execution result. Different from prior works on utilizing human feedback for code repair,
where the feedback message explains the code errors and how to ﬁx them [6, 2], SELF-DEBUGGING
teaches the model to identify the implementation errors via code explanation. This debugging process
is reminiscent of rubber duck debugging for human programmers, where explaining the code line-by-
line in natural language to a rubber duck signiﬁcantly boosts debugging efﬁciency without expert
guidance [24]. Figure 1 illustrates the full procedure of SELF-DEBUGGING.
We evaluate SELF-DEBUGGING on code-davinci-002 in the GPT-3 model family [8]. SELF-
DEBUGGING achieves the state-of-the-art performance on different types of code generation tasks,
including text-to-SQL generation, code translation and text-to-Python generation. On the Spider
benchmark [63] for text-to-SQL generation where there are no unit tests in the problem description,
with code explanation, SELF-DEBUGGING consistently improves the baseline by 2 −3% with
different numbers of initial programs, and improves the prediction accuracy on the most complicated
SQL queries by 9%. On both TransCoder for code translation [44] and MBPP for text-to-Python
generation [2], utilizing unit tests along with code explanation boosts the accuracy by up to 12%,
and code explanation alone without debugging also consistently improves the code translation
performance by 2 −3%. Meanwhile, SELF-DEBUGGING improves sample efﬁciency, and can match
or outperform baseline models that sample more than 10× predictions. Our work indicates that
besides improving their ability to generate code from scratch, teaching large language models to
perform SELF-DEBUGGING without human guidance is another promising path to enhance coding
capability and reduce the sampling cost required to accomplish challenging tasks.
Model
Executor
Code
Problem
Explanation
Unit tests
Step 1: Code 
generation
Step 3: Code explanation
Step 2: Code execution
Feedback
Figure 1: SELF-DEBUGGING for iterative debugging using a large language model. At each debug-
ging step, the model ﬁrst generates new code, then the code is executed and the model explains the
code. The code explanation along with the execution results constitute the feedback message, which
is then sent back to the model to perform more debugging steps. When unit tests are not available,
the feedback can be purely based on code explanation.
2
Prompting for Code Generation
In this section, we discuss the background on prompting for code generation using large language
models. We ﬁrst introduce few-shot prompting, then discuss how to select the ﬁnal prediction from
multiple samples based on code execution.
2

Few-shot prompting.
Few-shot prompting aims to instruct the language model to solve a task with
several input-output demonstrations [4]. Taking text-to-SQL generation as an example, the few-shot
prompt prepends the question of interest with a list of (question, SQL) pairs, so that when the model
is asked to predict subsequent tokens of the given prompt, it will follow the prompt format to generate
the SQL query. Figure 2 presents one exemplar for the prompt. Besides input-output demonstrations,
we can optionally add an instruction in the prompt to provide a high-level task description [41, 46, 51].
For example, in the ﬁrst two steps of our SELF-DEBUGGING prompt shown in Figure 3, both prompts
start with instructions that ask the model to generate explanations. We provide the full few-shot
prompts in the appendix.
Execution-based code selection.
Prior works demonstrate that decoding multiple samples can
signiﬁcantly improve the performance of large language models [54, 49]. In particular, for code
generation tasks, we can utilize code execution to select the ﬁnal prediction [11, 32, 49, 65, 37]. One
line of work selects the ﬁnal prediction using the majority vote of execution results [11, 32, 49], while
other works design reranking schemes to improve the performance [65, 37, 61, 64]. In this work,
when there are multiple predictions, we follow the ﬁrst line of work to select the predicted code with
the most frequent execution result among those that do not encounter execution errors, then apply
SELF-DEBUGGING to the code.
Some code generation tasks are accompanied with unit tests to specify the program execution
behavior [8, 2, 32, 22]. Speciﬁcally, the unit tests are a set of input-output pairs {(ik, ok)}K
k=1, and
a program P passes unit tests when P(ik) = ok, ∀k ∈{1, ..., K}. When unit tests are presented in
the problem description, we ﬁlter out programs that do not pass the unit tests before performing the
execution-based majority vote.
3
SELF-DEBUGGING Framework
Figure 1 illustrates our SELF-DEBUGGING framework for iterative debugging, where we utilize the
pretrained large language model without ﬁnetuning. Given the problem description, the model ﬁrst
predicts candidate programs, then it infers the program correctness and produces feedback messages
for subsequent debugging steps. The debugging process terminates when the feedback message states
that the prediction is correct, or a maximum allowed number of debugging turns is reached.
Existing works demonstrate that language models can be trained to understand human feedback
for code and make corrections based on the instructions [2, 38, 6]. However, it is unclear whether
language models can debug by themselves without human assistance. In the following, we discuss
different types of feedback messages that can be automatically acquired and generated with code
execution and few-shot prompting.
3.1
SELF-DEBUGGING with Simple Feedback
The simplest form of automatic feedback is a sentence that just indicates the code correctness without
more detailed information. For instance, in text-to-SQL generation, the few-shot prompt provides the
feedback message “The SQL prediction above is correct!” for all correct SQL queries, and “The
SQL prediction above is wrong. Please ﬁx the SQL.” for wrong predictions.
3.2
SELF-DEBUGGING with Unit Tests (UT)
For code generation tasks where the problem description includes unit tests, besides utilizing code
execution to check code correctness, we can also present the execution results in the feedback
message, which provides richer information for debugging. Figure 5 presents a sample unit test
feedback message for code translation. Intuitively, inspecting runtime error messages and execution
results of failed unit tests also helps human programmers debug more effectively. In our experiments,
we will demonstrate that leveraging unit tests considerably improves the debugging performance.
3.3
SELF-DEBUGGING via Code Explanation (Expl.)
Despite recent promising progress showing that large language models can generate critiques to
avoid harmful model outputs [18, 3] and improve their performance on some natural language and
3

reasoning tasks [50, 28, 47], prior work has yet to show the effectiveness of model-generated feedback
on code generation [6]. On the other hand, large language models have been shown to be capable of
describing their generated problem solutions in both text [55, 29, 68] and code [19, 9] formats.
Inspired by these observations, instead of teaching the large language model to predict error messages,
we propose to teach the model to self-debug via explaining the generated code. This debugging
process is reminiscent of rubber duck debugging, where a programmer debugs code by explaining
it line-by-line to a rubber duck [24]. By describing the code implementation and comparing it to
the problem description, human programmers are usually able to identify the bugs without extra
guidance. Empirically, we observe that a large language model can also beneﬁt from rubber duck
debugging, especially when unit tests are not available.
4
Applications
In our evaluation, we showcase applications of SELF-DEBUGGING to different code generation
domains: text-to-SQL generation, code translation, and text-to-Python generation. First, text-to-SQL
generation represents the scenario where no unit tests are available, where SELF-DEBUGGING enables
the model to identify errors and justify the code correctness by explaining the predicted code. In code
translation, we demonstrate how to utilize the execution of unit tests to provide feedback messages.
Finally, the text-to-Python domain requires the model to infer the prediction correctness when only a
subset of unit tests are presented in the problem description.
4.1
Text-to-SQL Generation
The goal of text-to-SQL tasks is to generate the corresponding SQL query given a question and the
database information, and Figure 2 presents an exemplar in our prompt for generating the SQL query.
Following prior work evaluating large language models for text-to-SQL generation [43, 49, 37], we
evaluate SELF-DEBUGGING on the development set of the Spider benchmark [63]. Since the unit
tests are not available, it becomes more challenging for the model to infer the correctness of the
predicted SQL queries. As will be shown in Section 5, it is insufﬁcient for accurately predicting SQL
correctness when the few-shot prompt only contains simple feedback.
Figure 3 demonstrates an exemplar in our SELF-DEBUGGING prompt for text-to-SQL generation,
and we present the full few-shot prompts for each step in Appendix A. At a high level, the debugging
process contains 3 steps. First, we prompt the model to summarize the question and infer the return
type required by the question; i.e., the number of table columns of the corresponding SQL query.
In the second step, we execute the SQL query and add the returned table to the model input for
code explanation. The generated SQL explanation includes a detailed description of each clause,
the number of columns included in the returned table, and the high-level meaning of the full SQL
query. When the returned table has more than 2 rows, only the ﬁrst 2 rows are included in the prompt.
Finally, the model compares the inferred SQL explanation and question description, and then predicts
the correctness of the current SQL query. The SELF-DEBUGGING process terminates when the SQL
query is considered correct in step 3, or when it reaches the maximum number of debugging turns.
4.2
Code Translation
Next, we apply SELF-DEBUGGING to code translation, where the goal is to translate code in one
programming language into another language. In our experiments, we use the TransCoder dataset [44],
which includes a test set of parallel functions in different programming languages along with unit
tests. Following [13], we evaluate SELF-DEBUGGING on the task of translating C++ code to Python
code, and we utilize the same test set with 560 problems and 10 unit tests per problem. The problem
description includes both the C++ code and all unit tests, as shown in Figure 4.
Given the availability of unit tests, we apply SELF-DEBUGGING only when the predicted Python code
does not pass all the unit tests, and thus the model does not need to predict the feedback messages.
Figure 5 provides sample SELF-DEBUGGING prompts with unit test feedback and code explanation.
We iteratively apply SELF-DEBUGGING until the predicted Python code passes all unit tests, or the
model reaches a maximum number of debugging turns.
4

Problem description
CREATE TABLE customers (
customer_id number ,
customer_name text ,
customer_details text ,
primary key ( customer_id )
)
insert into customers (customer_id, customer_name, customer_details) values (1,
’Savannah’, ’rerum’) ;
CREATE TABLE orders (
order_id number ,
customer_id number ,
order_status text ,
date_order_placed time ,
order_details text ,
primary key ( order_id ),
foreign key ( customer_id ) references customers ( customer_id )
)
insert into orders (order_id, customer_id, order_status, date_order_placed,
order_details) values (1, 2, ’Shipped’, ’2009-02-21 15:26:19’, NULL);
...
Question: Which customers have both "On Road" and "Shipped" as order status?
List the customer names.
Output SQL
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id
WHERE orders.order_status = "On Road"
INTERSECT SELECT customers.customer_name FROM customers JOIN orders ON
customers.customer_id = orders.customer_id
WHERE orders.order_status = "Shipped"
Figure 2: An exemplar for text-to-SQL generation. The problem is taken from the Spider dataset [63].
The problem description contains the database schema, and the model is required to predict the SQL
query. The prompt includes the contents of one row from each table.
4.3
Text-to-Python Generation
In addition, we evaluate SELF-DEBUGGING in the setting where a subset of unit tests are presented in
the problem description, which is a common setup in coding assignments and competitions [8, 2, 32].
Speciﬁcally, we perform experiments on the test set of MBPP [2], which contains 500 Python
problems with text descriptions, where each problem has 3 unit tests. We follow prior work [49, 37]
in including the ﬁrst unit test in the prompt as part of the problem description, and keeping the
remaining 2 unit tests hidden for full evaluation. Similar to code translation, we can also utilize the
unit test execution results in the feedback message, but the main difference is that the model still
needs to infer the code correctness even if the predicted Python code passes the given unit test. We
utilize the same prompt as in [37] to obtain the initial Python code, and we present the full prompts
for SELF-DEBUGGING in Appendix C.
5
Experiments
We use code-davinci-002 [8] for all our experiments with SELF-DEBUGGING, and we denote
it as Codex throughout this section. For initial code generation, when starting from one program, we
perform greedy decoding with temperature τ = 0. When sampling multiple programs for a problem,
we set temperature τ = 0.7, then we perform execution-based selection described in Section 2. All
5

Step 2: Code explanation
Summarize the return type of the execution.
[SQL]
SELECT ustomers.customer_name FROM customers JOIN orders ON customers.customer_id = orders.customer_id
WHERE orders.order_status = "On Road" OR orders.order_status = "Shipped"
Execution:
| George |
[SQL Explanation]
The execution of the SQL query above would return a table with 1 column.
The first column, "customers.customer_name" would contain the customer names.
With "customers JOIN orders", the table would contain the data about customers with orders.
With "WHERE orders.order_status = 'On Road' OR orders.order_status = 'Shipped'", the table filters the records to only include 
customers who have order status "On Road" or "Shipped".
So the SQL query returns a table with 1 column, the customer names who have the order status "On Road" or "Shipped".
Step 1: Question explanation
Infer the return type of the question.
[Question]
Which customers have both "On Road" and "Shipped" as order status? List the customer names.
[Question Explanation]
"List the customer names" returns 1 column. The question returns the customer names who have both "On Road" and "Shipped" as 
order status. So the question returns 1 column.
Step 3: Self-Debugging with explanation
[Question]
[Explanation summary]
As in your explanation, the SQL query returns a table with 1 column, the customer names who have the order status "On Road" or 
"Shipped". The question returns 1 column,  the customer names who have both "On Road" and "Shipped" as order status.
[Feedback] 
So the SQL prediction above is wrong. Please fix the SQL.
[Revised SQL #1]
SELECT customers.customer_name FROM customers JOIN orders ON customers.customer_id = orders.customer_id
WHERE orders.order_status = "On Road" AND orders.order_status = "Shipped"
[Explanation summary #1]
As in your explanation, the SQL query returns an empty table, because the "WHERE" clause contains mutually exclusive conditions. 
The question returns 1 column, the customer names who have order status of both "On Road" and "Shipped”.
[Feedback #1] 
So the SQL prediction above is wrong. Please fix the SQL.
[Revised SQL #2]
SELECT customers.customer_name FROM customers JOIN orders ON customers.customer_id = orders.customer_id WHERE 
orders.order_status = "On Road" INTERSECT SELECT customers.customer_name FROM customers JOIN orders ON 
customers.customer_id = orders.customer_id WHERE orders.order_status = "Shipped"
[Explanation summary #2]
As in your explanation, the SQL query returns a table with 1 column, the customer names who have the order status "On Road" and 
"Shipped". The question returns 1 column, the customer names who have order status of both "On Road" and "Shipped". So the 
question returns 1 column.
[Feedback #2] 
So the SQL prediction above is correct!
Figure 3: An example of SELF-DEBUGGING prompting for text-to-SQL generation. The model is
required to predict the code, explanation and feedback. Database information is omitted in the ﬁgure
for clarity, and we present the full prompts in Appendix A.
experiments for SELF-DEBUGGING use greedy decoding to generate code explanations, feedback
messages and new programs. We set the maximum number of debugging turns to be 10, and we will
show that empirically the successful debugging processes mostly end within 3 turns. We present the
full few-shot prompts for experiments in the appendix.
We evaluate SELF-DEBUGGING against two types of baselines as follows.
Models trained for the given task.
The Spider benchmark contains a training set of over 10K
samples, and the state-of-the-art models are mostly ﬁnetuned on this training set. We compare
SELF-DEBUGGING to Graphix-T5 [31], T5-3B + Syn data [66] and T5-3B + N-best Reranking [64],
which are adapted from the T5 architecture [42] and specially trained for text-to-SQL generation.
Although LEVER [37] also utilizes code-davinci-002 to generate candidate SQL queries, they
train a veriﬁer to select the ﬁnal prediction based on execution, and thus also requires extra training.
6

C++ Program
string caesar_cipher ( string text,
int s ) {
string result = "";
for ( int i = 0;
i < text . length ( );
i ++ ) {
if ( isupper ( text [ i ] ) )
result += char ( int ( text [ i ]
+ s - 65 ) % 26 + 65 );
else result += char ( int ( text [
i ] + s - 97 ) % 26 + 97 );
}
return result;
}
Python Program
def caesar_cipher(text, s):
result = ’’
for i in range(len(text)):
char = text[i]
if char.isupper():
result += chr(((((ord(char
) + s) - 65) % 26) + 65))
else:
result += chr(((((ord(char
) + s) - 97) % 26) + 97))
return result
Unit Tests
assert caesar_cipher(’35225904’, 2) == ’ikhhkofj’
... (8 unit tests omitted)
assert caesar_cipher(’11’, 93) == ’tt’
Figure 4: An example from the TransCoder dataset. The problem description contains the C++
program and unit tests, and the model is required to predict the Python program.
For both TransCoder and MBPP benchmarks, the state-of-the-art results are all accomplished by
large language models for code, thus we mainly compare to such models.
Prompting-based approaches.
We compare SELF-DEBUGGING against recent approaches that
also only perform prompting without any additional training. In particular, Both MBR-Exec [49]
and Coder-Reviewer [65] ﬁrst generate multiple candidate programs by prompting the pretrained
large language model. Afterward, MBR-Exec [49] selects the program with the most common
execution output, while Coder-Reviewer [65] selects the program by utilizing both the likelihood of
the predicted code given the problem description (Coder score) and the likelihood of the problem
description given the predicted code (Reviewer score).
5.1
Main Results
We present the main results in Tables 1, 2 and 3, where we compare SELF-DEBUGGING to the
state-of-the-art approaches on the Spider, TransCoder and MBPP benchmarks. We demonstrate that
SELF-DEBUGGING achieves the state-of-the-art on all 3 benchmarks, and signiﬁcantly boosts the
performance compared to the baseline that does not perform debugging.
On the Spider benchmark where unit tests are not available, simple feedback alone does not improve
the performance, because the model is not able to distinguish between correct and wrong SQL queries
from only a few exemplars without explanation, and does not produce meaningful changes to the
initial predicted SQL queries. Note that on TransCoder and MBPP benchmarks where at least one
unit test is available for SELF-DEBUGGING, simple feedback utilizes the execution result to infer
the code correctness even if the execution information is not presented in the feedback message to
the model, thus simple feedback still improves the model prediction for both applications. For all
tasks, the model beneﬁts from richer feedback signals for SELF-DEBUGGING. In particular, code
explanation enables the model to self-debug without unit tests.
7

Simple Feedback
Below are C++ programs with 
incorrect Python translations. 
Correct the translations using the 
provided feedback.
[C++]
[Original Python]
[Simple Feedback]
[Revised Python #1]
[Simple Feedback]
[Revised Python #2]
…
Unit Test (UT) Feedback
Below are C++ programs with 
incorrect Python translations. 
Correct the translations using the 
provided feedback.
[C++]
[Original Python]
[UT Feedback]
[Revised Python #1]
[UT Feedback]
[Revised Python #2]
…
Unit Test + Explanation (+Expl.)
Below are C++ programs with 
incorrect Python translations. 
Explain the original code, then 
explain the translations line by line 
and correct them using the 
provided feedback.
[C++]
[C++ Explanation]
[Original Python]
[Python Explanation]
[UT Feedback]
[Revised Python #1]
[UT Feedback]
[Revised Python #2]
…
[C++] =
int count_trailing_zeroes_factorial_number ( int n ) {
  int count = 0;
  for ( int i = 5; n / i >= 1; i *= 5 ) 
      count += n / i;
  return count;
}
[Original Python] =
def count_trailing_zeroes_factorial_number(n):
cnt = 0
i = 5
while ((n / i) >= 1):
        cnt = (cnt + (n / i))
        i *= 5
return cnt
[Simple Feedback] =
The above Python translation does not do the same thing as 
the C++ code. Correct the Python translation.
[UT Feedback] = 
The Python translation does not do the same thing as the C++ 
code. These are the results of failed unit tests that test 
whether the Python translation's outputs match the C++ 
program's outputs:
Failed: assert count_trailing_zeroes_factorial_number(9) == 1
Actual Result: 1.8
Correct the translation.
[Revised Python #n] = 
def count_trailing_zeroes_factorial_number(n):
cnt = 0
i = 5
while ((n / i) >= 1):
        cnt = (cnt + (n // i))
        i *= 5
return cnt
[C++ Explanation] =
The code is an implementation of counting the number of 
trailing zeroes in the factorial of a given number.
int count = 0;
The variable count is used to record the number of trailing 
zeroes.
for ( int i = 5; n / i >= 1; i *= 5 )
The loop iterates until the quotient of the given number and i 
(the divisor) is greater than or equal to 1.
count += n / i;
When the loop is executed, the quotient of the given number 
and i will be added to the variable count.
return count;
Finally, the function returns the number of trailing zeroes.
[Python Explanation] = 
The code is an implementation of counting the number of 
trailing zeroes in the factorial of a given number.
cnt = 0;
The variable cnt is used to record the number of trailing 
zeroes.
i = 5
The variable i is used as the divisor.
while ((n / i) >= 1):
The loop iterates until the quotient of the given number and i 
(the divisor) is greater than or equal to 1.
cnt = (cnt + (n / i))
When the loop is executed, the quotient of the given number 
and i will be added to the variable cnt.
i *= 5
The variable i will be multiplied by 5.
return cnt
Finally, the function returns the number of trailing zeroes.
Figure 5: Examples of SELF-DEBUGGING prompts for code translation. Left-aligned blocks are
model predictions, and right-aligned blocks contain the input C++ code and feedback messages based
on code execution. We present the full prompts in Appendix B.
5.2
Ablation studies
5.2.1
Text-to-SQL Generation
On the Spider benchmark, we observe that our Codex result before SELF-DEBUGGING already
matches the state-of-the-art performance, which is due to our better prompt design for SQL generation.
In particular, we ﬁnd that specifying primary and foreign key relationships between different tables
improves the generation performance. Still, SELF-DEBUGGING further increases the prediction
accuracy over the strong baseline and outperforms prior approaches without specialized training.
Figure 6a demonstrates the effectiveness of SELF-DEBUGGING when applied to different numbers
of initial samples, where SELF-DEBUGGING notably improves the sample efﬁciency. In particular,
applying SELF-DEBUGGING to predictions generated with greedy decoding matches the baseline
8

Table 1: Accuracy on the Spider development set
for text-to-SQL generation [63].
Spider (Dev)
w/ training
Graphix-T5 [31]
81.0
T5-3B + Syn data [66]
81.4
T5-3B + N-best Reranking [64]
80.6
LEVER [37]
81.9
Prompting only w/o debugging
Rajkumar et al. [43]
67.0
Coder-Reviewer [65]
74.5
MBR-Exec [49]
75.2
This work
Codex
81.3
Simple
81.3
+ Expl.
84.1
Table 2:
Accuracy on the TransCoder
dataset [44], where we evaluate on the C++
to Python translation task as in [13]. All ap-
proaches w/o debugging use greedy decod-
ing, and SELF-DEBUGGING methods utilize
Codex predictions for debugging.
TransCoder (pass@1)
w/o debugging
TransCoder [44]
44.5
PaLM [13]
51.8
PaLM-Coder [13]
55.1
This work
Codex
80.4
Simple
89.3
UT
91.6
UT + Expl.
92.5
Table 3: Accuracy on the MBPP dataset for text-to-Python generation [2].
Greedy decoding
n samples
Prior work
MBR-Exec [49]
-
63.0 (n = 25)
Reviewer [65]
-
66.9 (n = 25)
LEVER [37]
-
68.9 (n = 100)
This work
Codex
61.4
72.2 (n = 10)
Simple
68.2
73.6
UT
69.4
75.2
UT + Expl.
69.8
75.6
accuracy using 16 samples, and SELF-DEBUGGING from 8 samples outperforms the baseline accuracy
using 32 samples. Note that typically one debugging turn is sufﬁcient, and the accuracy improvement
after one turn is within 0.1%. These results highlight the beneﬁt of leveraging the large language
model to explain the code for debugging.
In Figure 6b, we further show the breakdown accuracies on problems with different difﬁculty levels,
where the difﬁculty of each problem is annotated in the Spider benchmark based on the complexity
of the ground truth SQL queries. We observe that the improvement achieved by SELF-DEBUGGING
is more signiﬁcant on hard problems. In particular, on extra hard problems, SELF-DEBUGGING
increases the accuracy by 9%. Figure 8 presents an example where SELF-DEBUGGING ﬁxes the
predicted SQL query for an extra hard problem.
5.2.2
Code Translation
For generating initial Python translation, we apply the same few-shot prompt for TransCoder as [13],
which consists of 3 exemplars (Appendix B.1). From Figure 7a, we again observe that the major
improvement comes from the ﬁrst debugging turn. Speciﬁcally, a single debugging turn with the
full feedback improves over the greedy decoding accuracy by around 12%. Compared to Figure 7b,
applying SELF-DEBUGGING to greedy decoding outperforms the baseline accuracy with 5 samples,
and is close to the baseline accuracy with 10 samples.
Meanwhile, incorporating both unit test execution and code explanation improves the debugging
performance, and we present some examples in Figures 9 and 10. In addition, we demonstrate that
leveraging code explanation alone without SELF-DEBUGGING also provides a consistent performance
gain of 2 −3% for different numbers of samples, as shown in Figure 7b.
9

1
8
16
32
# Samples
76
78
80
82
84
86
88
90
Spider Accuracy
77.5
78.7
80.7
81.3
80.8
82.5
82.9
84.1
Self-debugging
Codex
(a)
Easy
Medium
Hard
Extra hard
0
20
40
60
80
Spider accuracy
90.7
84.5
76.4
63.9
92.3
85.2
80.5
72.9
w/o debugging
self-debugging
(b)
Figure 6: Ablation studies on the Spider development set. (a) Accuracies with different numbers of
initial samples. (b) Breakdown accuracies on problems with different hardness levels.
0
1
2
3
# Turns
80.0
82.5
85.0
87.5
90.0
92.5
95.0
97.5
100.0
TransCoder Accuracy (pass@1)
80.4
88.4
89.3
91.1
91.6
92.0
92.5
UT+Expl.
UT
Simple
(a)
1
5
10
25
# Samples
80.0
82.5
85.0
87.5
90.0
92.5
95.0
97.5
100.0
TransCoder Accuracy
80.4
90.9
96.3
83.0
94.3
98.0
82.5
Codex+Expl.
Codex
PaLM-Coder pass@25
(b)
Figure 7: Ablation studies on TransCoder. (a) The accuracy of SELF-DEBUGGING prompts with
different numbers of debugging turns. (b) The accuracy with different numbers of initial samples.
Note that Codex+Expl. only prompts the model to generate explanations for the input C++ code, and
does not perform SELF-DEBUGGING.
5.2.3
Text-to-Python Generation
For initial Python code generation on MBPP, we apply the same 3-shot prompt as [37]. With greedy
decoding, SELF-DEBUGGING increases the accuracy by over 8%, and leveraging both unit test
execution and code explanation again consistently improves the performance.
We observe that the improvement using code explanation is less signiﬁcant on MBPP. First, due to
the availability of unit tests, it is much easier to recognize wrong predictions from unit test feedback.
Second, due to the context length limit, the number of exemplars in the prompt for SELF-DEBUGGING
is smaller when adding code explanation in the feedback message. Speciﬁcally, prompts with both
simple and unit test feedback messages include 6 exemplars, while the prompt with both the unit test
execution and code explanation has 3 exemplars. Third, we ﬁnd that code explanation plays a smaller
role when the initial predicted code is far from the correct solution, in which case the model simply
generates a new program and does not rely on code snippets in the initial prediction. See Figure 11
for an example where the prediction after SELF-DEBUGGING is very different from the initial code.
6
Related Work
Language models for code.
Recent years have witnessed rapid progress in deep neural networks
for code generation [14, 11, 63, 44]. While models designed and trained for specialized domains
10

Original SQL
Question: Give the names of countries with English and French as official
languages.
SELECT country.name FROM country
JOIN countrylanguage ON country.code = countrylanguage.countrycode
WHERE countrylanguage.language = "English"
INTERSECT SELECT country.name FROM country
JOIN countrylanguage ON country.code = countrylanguage.countrycode
WHERE countrylanguage.language = "French"
Code explanation
The execution of the SQL query above would return a table with 1 column.
The first column, ‘‘country.name’’ would contain the country name.
With ‘‘country JOIN countrylanguage’’, the table would contain the data about
countries and languages.
With ‘‘WHERE countrylanguage.language = ’English’’’, the table filters the
records to only include countries with the language ‘‘English’’.
With ‘‘WHERE countrylanguage.language = ’French’’’, the table filters the
records to only include countries with the language ‘‘French’’.
With ‘‘INTERSECT’’, the table would be filtered to only include countries with
both ‘‘English’’ and ‘‘French’’ as languages.
So the SQL query returns a table with 1 column, the country name of countries
with both ‘‘English’’ and ‘‘French’’ as languages.
Self-debugging with explanation
As in your explanation, the SQL query returns a table with 1 column, the
country name of countries with both ‘‘English’’ and ‘‘French’’ as languages.
The question returns the names of countries with English and French as offi-
cial languages. So the SQL prediction above is wrong. Please fix the SQL.
SELECT country.name FROM country JOIN countrylanguage ON country.code =
countrylanguage.countrycode
WHERE countrylanguage.language = "English"
AND countrylanguage.isofficial = "T"
INTERSECT SELECT country.name FROM country JOIN countrylanguage ON country.code
= countrylanguage.countrycode WHERE countrylanguage.language = "French"
AND countrylanguage.isofficial = "T"
Figure 8: An example on the Spider benchmark, where SELF-DEBUGGING ﬁxes the prediction for
an extra hard problem. Database information is omitted in the ﬁgure for clarity.
have achieved impressive performance in various applications such as text-to-code generation [31,
52, 48, 15, 26] and code translation [10, 44, 45], latest work on large language models demonstrate
that a single pretrained model can achieve the state-of-the-art performance across a wide variety of
coding tasks without specialized ﬁnetuning [8, 13, 38, 67, 57, 1, 40].
Despite showing the remarkable ability to follow natural language instructions, large language
models still exhibit limited understanding of code execution [2, 32]. Speciﬁcally, even when the
unit tests are provided in the problem description, the generated programs may still violate them [32,
49, 37]. Therefore, several approaches have been proposed to leverage code execution to choose
the ﬁnal prediction from multiple candidates, such as utilizing or training a language model for
reranking [65, 37], and performing selection based on the consensus on unit test execution outputs
among samples [11, 12, 45, 49, 32, 7]. In this work, our main focus is to utilize and explain code
11

C++
int remainder_7_large_numbers ( string
num ) {
int series [ ] = {
1, 3, 2, - 1, - 3, - 2 };
int series_index = 0;
int result = 0;
for ( int i = num . size ( ) - 1;
i >= 0; i -- ) {
int digit = num [ i ] - ’0’;
result += digit * series [
series_index ];
series_index = ( series_index +
1 ) % 6;
result %= 7;
}
if ( result < 0 ) result = (
result + 7 ) % 7;
return result;
}
Original Python
def remainder_7_large_numbers(num):
series = [1, 3, 2, -1, -3, -2]
series_index = 0
result = 0
for i in range((len(num) - 1), -1,
-1):
digit = (num[i] - ’0’)
result += (digit * series[
series_index])
series_index = ((series_index
+ 1) % 6)
result %= 7
if (result < 0):
result = ((result + 7) % 7)
return result
Self-debugging with UT feedback
The Python translation does not do the same thing as the C++ code. These are
the results of one failed unit test that tests whether the Python translation’s
outputs match the C++ program’s outputs:
Failed: assert remainder_7_large_numbers(’K’) == 6
Actual Result: Python runtime error: Traceback (most recent call last):
File <filename>, line 29, in <module>
print(remainder_7_large_numbers(’K’) )
File <filename>, line 22, in remainder_7_large_numbers
digit = (num[i] - ’0’)
TypeError: unsupported operand type(s) for -: ’str’ and ’str’
Correct the Python translation.
def remainder_7_large_numbers(num):
series = [1, 3, 2, -1, -3, -2]
series_index = 0
result = 0
for i in range((len(num) - 1), -1, -1):
digit = (ord(num[i]) - ord(’0’))
result += (digit * series[series_index])
series_index = ((series_index + 1) % 6)
result %= 7
if (result < 0):
result = ((result + 7) % 7)
return result
Figure 9: An example where SELF-DEBUGGING with unit test feedback ﬁxes the code translation
error, while the simple feedback fails.
execution for SELF-DEBUGGING, which improves the sample efﬁciency compared to utilizing
execution solely for initial code generation.
Prompting techniques.
Several prompting methods have been proposed to unlock latent abilities
of large language models [55, 39, 29, 68, 27, 69, 19, 9]. Rather than prompting a model to directly
produce the desired result, these methods have the model ﬁrst produce useful intermediate outputs.
12

C++
void function_copy_string ( char s1 [
], char s2 [ ], int index = 0 ) {
s2 [ index ] = s1 [ index ];
if ( s1 [ index ] == ’\0’ ) return;
function_copy_string ( s1, s2, index
+ 1 );
}
Baseline pass@25
def function_copy_string(s1, s2, index
=0):
s2[index] = s1[index]
if (s1[index] == ’\0’):
return None
function_copy_string(s1, s2, (
index + 1))
+ Expl.
The code is an implementation of iterative function of copying a given string.
The character at the given index in the first string will be copied to the same
index of the second string.
If the character at the given index in the first string is ’\0’, which means
the end of the string, the function will be returned.
Otherwise, the next character of the first string will be copied to the second
string.
def function_copy_string(s1, s2, idx=0):
s2[idx] = s1[idx]
if ((s1[idx] == ’\0’) or ((len(s1) - 1) == idx)):
return
function_copy_string(s1, s2, (idx + 1))
Figure 10: An example where adding code explanation results in the correct code translation, while
the baseline prompt does not. Speciﬁcally, the translation with code explanation correctly checks for
the end of a string.
Original Python code
assert encode_list
([1,1,2,3,4,4.3,5,1])==[[2, 1], [1,
2], [1, 3], [1, 4], [1, 4.3], [1, 5],
[1, 1]
Write a function to reflect the run-
length encoding from a list.
def encode_list(nums):
res = []
for i in nums:
if i not in res:
res.append([nums.count(i),
i])
return res
Prediction after self-debugging
def encode_list(nums):
res = []
count = 1
for i in range(1, len(nums)):
if nums[i] == nums[i-1]:
count += 1
else:
res.append([count, nums[i-1]])
count = 1
res.append([count, nums[-1]])
return res
Figure 11: An example on MBPP where the prediction after SELF-DEBUGGING is very different
from the initial code.
For example, chain-of-thought prompting asks the model to produce intermediate reasoning steps in
natural language, which can be accomplished either with few-shot exemplars [55] or in a zero-shot
manner [29]. Meanwhile, several prompting techniques explicitly direct the model to break down a
problem into subproblems [68, 27]. For example, decomposed prompting [27] delegates subproblems
13

to other LLM instances that are prompted to specialize in speciﬁc tasks. Our prompting format
of code explanation is relevant in spirit to chain-of-thought prompting, as the line-by-line code
explanation in natural language facilitates analysis of the code that is useful for the debugging task.
On the other hand, SELF-DEBUGGING also decomposes the debugging process into several stages,
and triggers separate prompts for code explanation and feedback generation.
Code repair.
Program repair is an area of research concerned with ﬁxing bugs in code, where
several neural network models have been developed to handle different types of bugs [21, 60, 20, 53].
While some methods train repair models that only take the code as input [21, 60], other approaches
incorporate additional information such as execution traces [20, 53] and compiler errors [59]. Our
SELF-DEBUGGING also uses additional information to aid in code repair, including execution results
and self-generated code explanations. In contrast to prior work on training a separate model for code
repair, SELF-DEBUGGING utilizes pretrained large language models for code, and teaches the model
to debug via few-shot prompting.
Training with feedback.
Training with feedback to improve the outputs of large language models,
both in terms of correctness and alignment with human preferences, is an active research direction
nowadays [70, 30, 18, 3]. One popular technique is reinforcement learning from human feedback
(RLHF) [70, 41], and RLHF-trained models have demonstrated the ability to avoid harmful outputs
when instructed to do so in the prompt [18]. Constitutional AI [3] introduces another path toward
training harmless models, where they use the pretrained model itself to create automated feedback for
both supervised learning and RLHF: for the former, a set of principles are used to guide a language
model in creating revisions of its own responses that it is then trained on, and for the latter the same
principles are used to prompt a separate model for the feedback needed for RLHF.
Another line of work trains the language model to reﬁne the initial model outputs based on external
feedback on prediction quality [56, 33], which improves the performance on several natural language
and reasoning tasks. For code generation, a number of works have trained models to perform code
optimization [34], interact with users for multi-turn code generation [62, 58, 38], and ﬁx generated
programs based on human feedback [25, 16, 6]. On the other hand, SELF-DEBUGGING enables the
model to generate feedback messages on its own at test time, and does not require extra training.
Prompting with feedback.
Recent works have shown the great promise of RLHF-trained models
to generate critiques with prompting, which reduces harmful model outputs [3, 18] and improves the
performance on some reasoning tasks [50, 35, 28, 36]. Reﬂexion [50] prompts an agent powered
with a large language model to reﬂect on its actions under certain situations (such as when its actions
become repetitive) and stores these reﬂections in its memory, leading to reduced hallucination and
more effective plans. Self-Reﬁne [35] shows that having a language model iteratively generate
feedback and revisions of its outputs can greatly improve the ﬁnal output quality on several tasks,
such as text generation and math reasoning. RCI [28] demonstrates a related method combined
with state and agent grounding that allows a large language model to accomplish computer control
tasks in the MiniWoB++ benchmark [23], and improves the zero-shot performance on several math
and commonsense reasoning benchmarks. Finally, DERA [36] simulates a dialogue between two
agents to improve the model’s predictions in the clinical domain, with one agent providing feedback
about important elements of the problem, and the other using the feedback to produce a ﬁnal output.
In this work, we focus on code generation applications, and SELF-DEBUGGING demonstrates the
effectiveness of both self-generated feedback and unit test feedback acquired by code execution. In
particular, SELF-DEBUGGING teaches the large language model to notice prediction errors via code
explanation in the style of rubber duck debugging, which does not require the feedback message to
explicitly explain the implementation errors and how to ﬁx them.
7
Conclusion
In this work, we presented SELF-DEBUGGING, which enables a large language model to debug
code generated by itself. In particular, we demonstrate that SELF-DEBUGGING empowers the
model to perform rubber duck debugging, so that the model can identify and ﬁx the bugs without
human instructions. SELF-DEBUGGING achieves the state-of-the-art performance across several
code generation domains, and notably improves sample efﬁciency. On text-to-SQL generation
where there is no unit test speciﬁed for the task, leveraging code explanation for SELF-DEBUGGING
14

consistently improves the baseline by 2 −3%, and provides a performance gain of 9% on the hardest
problems. For code translation and text-to-Python generation tasks where unit tests are available,
SELF-DEBUGGING signiﬁcantly increases the baseline accuracy by up to 12%.
Our work highlights the promise of improving the coding performance of large language models by
teaching them to iteratively debug their own predictions, instead of requiring the model to generate
the correct code from scratch. SELF-DEBUGGING instructs the model to understand the code, identify
the errors, and follow the error messages to ﬁx the bugs. We consider improving the model’s ability
to conduct all these steps as important future work. In particular, we hypothesize that better code
explanation ability leads to better debugging performance, and one direction is to instruct the model
to better describe the high-level semantic meaning of code along with the implementation details in its
explanation. Another direction is to include additional debugging information in the model feedback,
such as a description of potential bugs. Our preliminary results suggest that model-generated feedback
messages on semantic errors do not provide additional beneﬁts on top of line-by-line code explanation,
and future work can explore techniques to predict more informative error messages.
Acknowledgement
We would like to thank Jacob Austin, Quoc V. Le, Charles Sutton, Hanjun Dai, and Olivier Bousquet
for helpful discussion and feedback.
References
[1] B. Athiwaratkun, S. K. Gouda, Z. Wang, X. Li, Y. Tian, M. Tan, W. U. Ahmad, S. Wang, Q. Sun,
M. Shang, S. K. Gonugondla, H. Ding, V. Kumar, N. Fulton, A. Farahani, S. Jain, R. Giaquinto,
H. Qian, M. K. Ramanathan, R. Nallapati, B. Ray, P. Bhatia, S. Sengupta, D. Roth, and B. Xiang.
Multi-lingual evaluation of code generation models. In The Eleventh International Conference
on Learning Representations, 2023.
[2] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry,
Q. Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732,
2021.
[3] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirho-
seini, C. McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. arXiv preprint
arXiv:2212.08073, 2022.
[4] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural
information processing systems, 33:1877–1901, 2020.
[5] R. Bunel, M. Hausknecht, J. Devlin, R. Singh, and P. Kohli. Leveraging grammar and rein-
forcement learning for neural program synthesis. In International Conference on Learning
Representations, 2018.
[6] A. Chen, J. Scheurer, T. Korbak, J. A. Campos, J. S. Chan, S. R. Bowman, K. Cho, and
E. Perez. Improving code generation by training with natural language feedback. arXiv preprint
arXiv:2303.16749, 2023.
[7] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J.-G. Lou, and W. Chen. Codet: Code generation
with generated tests. In The Eleventh International Conference on Learning Representations,
2023.
[8] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda,
N. Joseph, G. Brockman, et al. Evaluating large language models trained on code. arXiv
preprint arXiv:2107.03374, 2021.
[9] W. Chen, X. Ma, X. Wang, and W. W. Cohen. Program of thoughts prompting: Disentangling
computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588,
2022.
[10] X. Chen, C. Liu, and D. Song. Tree-to-tree neural networks for program translation. Advances
in neural information processing systems, 31, 2018.
[11] X. Chen, C. Liu, and D. Song. Execution-guided neural program synthesis. In International
Conference on Learning Representations, 2019.
15

[12] X. Chen, D. Song, and Y. Tian. Latent execution for neural program synthesis beyond domain-
speciﬁc languages. Advances in Neural Information Processing Systems, 34:22196–22208,
2021.
[13] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W.
Chung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv
preprint arXiv:2204.02311, 2022.
[14] J. Devlin, J. Uesato, S. Bhupatiraju, R. Singh, A.-r. Mohamed, and P. Kohli. Robustﬁll: Neural
program learning under noisy i/o. In International conference on machine learning, pages
990–998. PMLR, 2017.
[15] L. Dong and M. Lapata. Language to logical form with neural attention. In Proceedings of
the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers), 2016.
[16] A. Elgohary, S. Hosseini, and A. Hassan Awadallah. Speak to your parser: Interactive text-
to-SQL with natural language feedback. In Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics, 2020.
[17] C. Fu, H. Chen, H. Liu, X. Chen, Y. Tian, F. Koushanfar, and J. Zhao. Coda: An end-to-end
neural program decompiler. In NeurIPS, 2019.
[18] D. Ganguli, A. Askell, N. Schiefer, T. Liao, K. Lukoši¯ut˙e, A. Chen, A. Goldie, A. Mirhoseini,
C. Olsson, D. Hernandez, et al. The capacity for moral self-correction in large language models.
arXiv preprint arXiv:2302.07459, 2023.
[19] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig. Pal: Program-
aided language models. arXiv preprint arXiv:2211.10435, 2022.
[20] K. Gupta, P. E. Christensen, X. Chen, and D. Song. Synthesize, execute and debug: Learning
to repair for neural program synthesis. Advances in Neural Information Processing Systems,
33:17685–17695, 2020.
[21] R. Gupta, S. Pal, A. Kanade, and S. Shevade. Deepﬁx: Fixing common c language errors by
deep learning. In Proceedings of the aaai conference on artiﬁcial intelligence, 2017.
[22] D. Hendrycks, S. Basart, S. Kadavath, M. Mazeika, A. Arora, E. Guo, C. Burns, S. Puranik,
H. He, D. Song, and J. Steinhardt. Measuring coding challenge competence with APPS. In
Thirty-ﬁfth Conference on Neural Information Processing Systems Datasets and Benchmarks
Track (Round 2), 2021.
[23] P. C. Humphreys, D. Raposo, T. Pohlen, G. Thornton, R. Chhaparia, A. Muldal, J. Abramson,
P. Georgiev, A. Santoro, and T. Lillicrap. A data-driven approach for learning to control
computers. In International Conference on Machine Learning, pages 9466–9482. PMLR, 2022.
[24] A. Hunt and D. Thomas. The pragmatic programmer: from journeyman to master, 2000.
[25] S. Iyer, I. Konstas, A. Cheung, J. Krishnamurthy, and L. Zettlemoyer. Learning a neural semantic
parser from user feedback. In Proceedings of the 55th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), 2017.
[26] S. Iyer, I. Konstas, A. Cheung, and L. Zettlemoyer. Mapping language to code in programmatic
context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language
Processing, 2018.
[27] T. Khot, H. Trivedi, M. Finlayson, Y. Fu, K. Richardson, P. Clark, and A. Sabharwal.
Decomposed prompting: A modular approach for solving complex tasks. arXiv preprint
arXiv:2210.02406, 2022.
[28] G. Kim, P. Baldi, and S. McAleer. Language models can solve computer tasks. arXiv preprint
arXiv:2303.17491, 2023.
[29] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language models are zero-shot
reasoners. In A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho, editors, Advances in Neural
Information Processing Systems, 2022.
[30] T. Korbak, K. Shi, A. Chen, R. Bhalerao, C. L. Buckley, J. Phang, S. R. Bowman, and E. Perez.
Pretraining language models with human preferences. arXiv preprint arXiv:2302.08582, 2023.
16

[31] J. Li, B. Hui, R. Cheng, B. Qin, C. Ma, N. Huo, F. Huang, W. Du, L. Si, and Y. Li. Graphix-t5:
Mixing pre-trained transformers with graph-aware layers for text-to-sql parsing. arXiv preprint
arXiv:2301.07507, 2023.
[32] Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling,
F. Gimeno, A. Dal Lago, et al. Competition-level code generation with alphacode. Science,
378(6624):1092–1097, 2022.
[33] H. Liu, C. Sferrazza, and P. Abbeel. Chain of hindsight aligns language models with feedback.
arXiv preprint arXiv:2302.02676, 2023.
[34] A. Madaan, A. Shypula, U. Alon, M. Hashemi, P. Ranganathan, Y. Yang, G. Neubig, and A. Yaz-
danbakhsh. Learning performance-improving code edits. arXiv preprint arXiv:2302.07867,
2023.
[35] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri,
S. Prabhumoye, Y. Yang, et al. Self-reﬁne: Iterative reﬁnement with self-feedback. arXiv
preprint arXiv:2303.17651, 2023.
[36] V. Nair, E. Schumacher, G. Tso, and A. Kannan. Dera: Enhancing large language model
completions with dialog-enabled resolving agents. arXiv preprint arXiv:2303.17071, 2023.
[37] A. Ni, S. Iyer, D. Radev, V. Stoyanov, W.-t. Yih, S. I. Wang, and X. V. Lin. Lever: Learning to
verify language-to-code generation with execution. arXiv preprint arXiv:2302.08468, 2023.
[38] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, and C. Xiong. Codegen:
An open large language model for code with multi-turn program synthesis. In The Eleventh
International Conference on Learning Representations, 2023.
[39] M. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan,
A. Lewkowycz, M. Bosma, D. Luan, et al. Show your work: Scratchpads for intermediate
computation with language models. arXiv preprint arXiv:2112.00114, 2021.
[40] G. Orlanski, K. Xiao, X. Garcia, J. Hui, J. Howland, J. Malmaud, J. Austin, R. Singh, and
M. Catasta. Measuring the impact of programming language distribution. arXiv preprint
arXiv:2302.01973, 2023.
[41] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,
K. Slama, A. Gray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welin-
der, P. Christiano, J. Leike, and R. Lowe. Training language models to follow instructions with
human feedback. In A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho, editors, Advances in
Neural Information Processing Systems, 2022.
[42] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.
Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. The Journal of
Machine Learning Research, 21(1):5485–5551, 2020.
[43] N. Rajkumar, R. Li, and D. Bahdanau. Evaluating the text-to-sql capabilities of large language
models. arXiv preprint arXiv:2204.00498, 2022.
[44] B. Roziere, M.-A. Lachaux, L. Chanussot, and G. Lample. Unsupervised translation of pro-
gramming languages. Advances in Neural Information Processing Systems, 33:20601–20611,
2020.
[45] B. Roziere, J. Zhang, F. Charton, M. Harman, G. Synnaeve, and G. Lample. Leveraging
automated unit tests for unsupervised code translation. In International Conference on Learning
Representations, 2022.
[46] V. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, A. Chafﬁn, A. Stiegler,
A. Raja, M. Dey, M. S. Bari, C. Xu, U. Thakker, S. S. Sharma, E. Szczechla, T. Kim, G. Chh-
ablani, N. Nayak, D. Datta, J. Chang, M. T.-J. Jiang, H. Wang, M. Manica, S. Shen, Z. X.
Yong, H. Pandey, R. Bawden, T. Wang, T. Neeraj, J. Rozen, A. Sharma, A. Santilli, T. Fevry,
J. A. Fries, R. Teehan, T. L. Scao, S. Biderman, L. Gao, T. Wolf, and A. M. Rush. Multi-
task prompted training enables zero-shot task generalization. In International Conference on
Learning Representations, 2022.
[47] W. Saunders, C. Yeh, J. Wu, S. Bills, L. Ouyang, J. Ward, and J. Leike. Self-critiquing models
for assisting human evaluators. arXiv preprint arXiv:2206.05802, 2022.
17

[48] T. Scholak, N. Schucher, and D. Bahdanau. PICARD: Parsing incrementally for constrained
auto-regressive decoding from language models. In Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing, 2021.
[49] F. Shi, D. Fried, M. Ghazvininejad, L. Zettlemoyer, and S. I. Wang. Natural language to code
translation with execution. In Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing, 2022.
[50] N. Shinn, B. Labash, and A. Gopinath. Reﬂexion: an autonomous agent with dynamic memory
and self-reﬂection. arXiv preprint arXiv:2303.11366, 2023.
[51] M. Suzgun, N. Scales, N. Schärli, S. Gehrmann, Y. Tay, H. W. Chung, A. Chowdhery, Q. V. Le,
E. H. Chi, D. Zhou, and J. Wei. Challenging big-bench tasks and whether chain-of-thought can
solve them. arXiv preprint arXiv:2210.09261, 2022.
[52] B. Wang, R. Shin, X. Liu, O. Polozov, and M. Richardson. RAT-SQL: Relation-aware schema
encoding and linking for text-to-SQL parsers. In Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics, 2020.
[53] K. Wang, R. Singh, and Z. Su. Dynamic neural program embedding for program repair. In
International Conference on Learning Representations, 2018.
[54] X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang, A. Chowdhery, and D. Zhou.
Self-consistency improves chain of thought reasoning in language models. In The Eleventh
International Conference on Learning Representations, 2023.
[55] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought
prompting elicits reasoning in large language models. In NeurIPS, 2022.
[56] S. Welleck, X. Lu, P. West, F. Brahman, T. Shen, D. Khashabi, and Y. Choi. Generating
sequences by learning to self-correct. In The Eleventh International Conference on Learning
Representations, 2023.
[57] F. F. Xu, U. Alon, G. Neubig, and V. J. Hellendoorn. A systematic evaluation of large language
models of code. In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine
Programming, pages 1–10, 2022.
[58] Z. Yao, Y. Su, H. Sun, and W.-t. Yih. Model-based interactive semantic parsing: A uniﬁed
framework and a text-to-SQL case study. In Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP), 2019.
[59] M. Yasunaga and P. Liang. Graph-based, self-supervised program repair from diagnostic
feedback. In International Conference on Machine Learning, pages 10799–10808. PMLR,
2020.
[60] M. Yasunaga and P. Liang. Break-it-ﬁx-it: Unsupervised learning for program repair. In
International Conference on Machine Learning, pages 11941–11952. PMLR, 2021.
[61] P. Yin and G. Neubig. Reranking for neural semantic parsing. In Proceedings of the 57th Annual
Meeting of the Association for Computational Linguistics, 2019.
[62] T. Yu, R. Zhang, H. Er, S. Li, E. Xue, B. Pang, X. V. Lin, Y. C. Tan, T. Shi, Z. Li, Y. Jiang,
M. Yasunaga, S. Shim, T. Chen, A. Fabbri, Z. Li, L. Chen, Y. Zhang, S. Dixit, V. Zhang,
C. Xiong, R. Socher, W. Lasecki, and D. Radev. CoSQL: A conversational text-to-SQL
challenge towards cross-domain natural language interfaces to databases. In Proceedings
of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019.
[63] T. Yu, R. Zhang, K. Yang, M. Yasunaga, D. Wang, Z. Li, J. Ma, I. Li, Q. Yao, S. Roman,
Z. Zhang, and D. Radev. Spider: A large-scale human-labeled dataset for complex and cross-
domain semantic parsing and text-to-SQL task. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing, 2018.
[64] L. Zeng, S. H. K. Parthasarathi, and D. Hakkani-Tur. N-best hypotheses reranking for text-to-sql
systems. arXiv preprint arXiv:2210.10668, 2022.
[65] T. Zhang, T. Yu, T. B. Hashimoto, M. Lewis, W.-t. Yih, D. Fried, and S. I. Wang. Coder reviewer
reranking for code generation. arXiv preprint arXiv:2211.16490, 2022.
18

[66] Y. Zhao, J. Jiang, Y. Hu, W. Lan, H. Zhu, A. Chauhan, A. H. Li, L. Pan, J. Wang, C.-W.
Hang, S. Zhang, M. Dong, J. Lilien, P. Ng, Z. Wang, V. Castelli, and B. Xiang. Importance of
synthesizing high-quality data for text-to-SQL parsing. In NeurIPS 2022 Workshop on Synthetic
Data for Empowering ML Research, 2022.
[67] Q. Zheng, X. Xia, X. Zou, Y. Dong, S. Wang, Y. Xue, Z. Wang, L. Shen, A. Wang, Y. Li, T. Su,
Z. Yang, and J. Tang. Codegeex: A pre-trained model for code generation with multilingual
evaluations on humaneval-x, 2023.
[68] D. Zhou, N. Schärli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet,
Q. V. Le, and E. H. Chi. Least-to-most prompting enables complex reasoning in large language
models. In The Eleventh International Conference on Learning Representations, 2023.
[69] H. Zhou, A. Nova, H. Larochelle, A. Courville, B. Neyshabur, and H. Sedghi. Teaching
algorithmic reasoning via in-context learning. arXiv preprint arXiv:2211.09066, 2022.
[70] D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irv-
ing. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593,
2019.
A
Text-to-SQL Generation
A.1
Baseline Prompt (5-shot)
CREATE TABLE department (
department_id number ,
name text ,
creation text ,
ranking number ,
budget_in_billions number ,
num_employees number ,
primary key ( department_id )
)
insert into department (department_id, name, creation, ranking,
budget_in_billions, num_employees) values (1,’State’,’1789’,’1’
,9.9600000000000008526,30265.999999999999999) ;
CREATE TABLE head (
head_id number ,
name text ,
born_state text ,
age number ,
primary key ( head_id )
)
insert into head (head_id, name, born_state, age) values (1,’Tiger Woods’,’
Alabama’,66.999999999999999998) ;
CREATE TABLE management (
department_id number ,
head_id number ,
temporary_acting text ,
primary key ( department_id ) ,
foreign key ( head_id ) references head ( head_id )
,
foreign key ( department_id ) references department ( department_id )
)
insert into management (department_id, head_id, temporary_acting) values
(2,5,’Yes’) ;
Translate the following question into SQL.
Question: In which year were most departments established?
19

SQL: SELECT creation FROM department GROUP BY creation ORDER BY COUNT(*)
DESC LIMIT 1
CREATE TABLE city (
city_id number ,
official_name text ,
status text ,
area_km_2 number ,
population number ,
census_ranking text ,
primary key ( city_id )
)
insert into city (city_id, official_name, status, area_km_2, population,
census_ranking) values (1,’Grand Falls/Grand-Sault’,’Town’,’18.06’,’5706’,’
636 of 5008’) ;
CREATE TABLE farm (
farm_id number ,
year number ,
total_horses number ,
working_horses number ,
total_cattle number ,
oxen number ,
bulls number ,
cows number ,
pigs number ,
sheep_and_goats number ,
primary key ( farm_id )
)
insert into farm (farm_id, year, total_horses, working_horses, total_cattle,
oxen, bulls, cows, pigs, sheep_and_goats) values (1,’1927’,’5056.5’,’3900.1
’,’8374.5’,’805.5’,’31.6’,’3852.1’,’4412.4’,’7956.3’) ;
CREATE TABLE farm_competition (
competition_id number ,
year number ,
theme text ,
host_city_id number ,
hosts text ,
primary key ( competition_id ) ,
foreign key ( host_city_id ) references city ( city_id )
)
insert into farm_competition (competition_id, year, theme, host_city_id,
hosts) values (1,’2013’,’Carnival M is back!’,1,’Miley Cyrus Jared Leto and
Karen Mok’) ;
CREATE TABLE competition_record (
competition_id number ,
farm_id number ,
rank number ,
primary key ( competition_id ) ,
foreign key ( farm_id ) references farm ( farm_id )
,
foreign key ( competition_id ) references farm_competition ( competition_id
)
)
insert into competition_record (competition_id, farm_id, rank) values
(1,8,1) ;
Translate the following question into SQL.
Question: Show the status of the city that has hosted the greatest number of
competitions.
20

SQL: SELECT city.status FROM city JOIN farm_competition ON city.city_id =
farm_competition.host_city_id GROUP BY farm_competition.host_city_id ORDER
BY COUNT(*) DESC LIMIT 1
CREATE TABLE customers (
customer_id number ,
customer_name text ,
customer_details text ,
primary key ( customer_id )
)
insert into customers (customer_id, customer_name, customer_details) values
(1, ’Savannah’, ’rerum’) ;
CREATE TABLE invoices (
invoice_number number ,
invoice_date time ,
invoice_details text ,
primary key ( invoice_number )
)
insert into invoices (invoice_number, invoice_date, invoice_details) values
(1, ’1989-09-03 16:03:05’, ’vitae’) ;
CREATE TABLE orders (
order_id number ,
customer_id number ,
order_status text ,
date_order_placed time ,
order_details text ,
primary key ( order_id ),
foreign key ( customer_id ) references customers ( customer_id )
)
insert into orders (order_id, customer_id, order_status, date_order_placed,
order_details) values (1, 2, ’Shipped’, ’2009-02-21 15:26:19’, NULL);
CREATE TABLE products (
product_id number ,
product_name text ,
product_details text,
primary key ( product_id )
)
insert into products (product_id, product_name, product_details) values (1,
’food’, NULL);
CREATE TABLE order_items (
order_item_id number ,
product_id number ,
order_id number ,
order_item_status text ,
order_item_details text ,
primary key ( order_item_id ) ,
foreign key ( product_id ) references product ( product_id ) ,
foreign key ( order_id ) references orders ( order_id )
)
insert into order_items (order_item_id, product_id, order_id,
order_item_status, order_item_details) values (1, 4, 6, ’Finish’, NULL) ;
CREATE TABLE shipments (
shipment_id number ,
order_id number ,
invoice_number number ,
shipment_tracking_number text ,
shipment_date time ,
21

other_shipment_details text ,
primary key ( shipment_id ) ,
foreign key ( invoice_number ) references invoices ( invoices_number ) ,
foreign key ( order_id ) references order ( order_id )
)
insert into shipments (shipment_id, order_id, invoice_number,
shipment_tracking_number, shipment_date, other_shipment_details) values (1,
5, 13, ’3452’, ’1983-08-13 22:34:11’, NULL) ;
CREATE TABLE shipment_items (
shipment_id number ,
order_item_id number ,
primary key ( ) ,
foreign key ( shipment_id ) references shipments ( shipment_id ) ,
foreign key ( order_item_id ) references order_items ( order_item_id )
)
insert into shipment_items (shipment_id, order_item_id) values (11, 12) ;
Translate the following question into SQL.
Question: Which customers have both "On Road" and "Shipped" as order status?
List the customer names.
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road"
INTERSECT SELECT customers.customer_name FROM customers JOIN orders ON
customers.customer_id = orders.customer_id WHERE orders.order_status = "
Shipped"
CREATE TABLE station (
id number ,
name text ,
lat number ,
long number ,
dock_count number ,
city text ,
installation_date text ,
primary key ( id )
)
insert into station (id, name, lat, long, dock_count, city,
installation_date) values (2,’San Jose Diridon Caltrain Station’
,37.329732,-1.21901782000000011405e+02,27,’San Jose’,’8/6/2013’);
CREATE TABLE status (
station_id number ,
bikes_available number ,
docks_available number ,
time text ,
primary key ( ) ,
foreign key ( station_id ) references station ( id )
)
insert into status (station_id, bikes_available, docks_available,time values
(3,12,3,’2015-06-02 12:46:02’);
CREATE TABLE trip (
id number ,
duration number ,
start_date text ,
start_station_name text ,
start_station_id number ,
end_date text ,
end_station_name text ,
22

end_station_id number ,
bike_id number ,
subscription_type text ,
zip_code number ,
primary key ( id )
)
insert into trip (id, duration, start_date, start_station_name,
start_station_id, end_date, end_station_name, end_station_id, bike_id,
subscription_type, zip_code) values (900504,384,’8/21/2015 17:03’,’Howard at
2nd’,63,’8/21/2015 17:10’,’San Francisco Caltrain 2 (330 Townsend)’,69,454,
’Subscriber’,94041);
Translate the following question into SQL.
Question: What is the average longitude of stations that never had bike
availability more than 10?
SQL: SELECT AVG(long) FROM station WHERE id NOT IN (SELECT station_id FROM
status GROUP BY station_id HAVING MAX(bikes_available) > 10)
CREATE TABLE allergy_type (
allergy text ,
allergytype text ,
primary key ( allergy )
)
insert into allergy_type (allergy, allergytype) values ( ’Eggs’, ’food’ );
CREATE TABLE has_allergy (
stuid number ,
allergy text ,
foreign key ( allergy ) references allergy_type ( allergy ) ,
foreign key ( stuid ) references student ( stuid )
)
insert into has_allergy (stuid, allergy) values ( 1001, ’Cat’ );
CREATE TABLE student (
stuid number ,
lname text ,
fname text ,
age number ,
sex text ,
major number ,
advisor number ,
city_code text ,
primary key ( stuid )
)
insert into student (stuid, lname, fname, age, sex, major, advisor,
city_code) values ( 1001, ’Smith’, ’Linda’, 18, ’F’, 600, 1121,’BAL’);
Translate the following question into SQL.
Question: Find the number of students who are older than 18 and do not have
allergy to either food or animal.
SQL: SELECT COUNT(*) FROM student WHERE age > 18 AND stuid NOT IN (SELECT
has_allergy.stuid FROM has_allergy JOIN allergy_type ON has_allergy.allergy
= allergy_type.allergy WHERE allergy_type.allergytype = "food" OR
allergy_type.allergytype = "animal")
<insert database schemas and the new question here>
23

A.2
Simple Feedback Prompt (9-shot)
CREATE TABLE department (
department_id number ,
name text ,
creation text ,
ranking number ,
budget_in_billions number ,
num_employees number ,
primary key ( department_id )
)
insert into department (department_id, name, creation, ranking,
budget_in_billions, num_employees) values (1,’State’,’1789’,’1’
,9.9600000000000008526,30265.999999999999999) ;
CREATE TABLE head (
head_id number ,
name text ,
born_state text ,
age number ,
primary key ( head_id )
)
insert into head (head_id, name, born_state, age) values (1,’Tiger Woods’,’
Alabama’,66.999999999999999998) ;
CREATE TABLE management (
department_id number ,
head_id number ,
temporary_acting text ,
primary key ( department_id ) ,
foreign key ( head_id ) references head ( head_id )
,
foreign key ( department_id ) references department ( department_id )
)
insert into management (department_id, head_id, temporary_acting) values
(2,5,’Yes’) ;
Translate the following question into SQL.
Question: In which year were most departments established?
SQL: SELECT creation, COUNT(*) FROM department GROUP BY creation ORDER BY
COUNT(*) DESC LIMIT 1
Feedback: The SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT creation FROM department GROUP BY creation ORDER BY COUNT(*)
DESC LIMIT 1
Feedback: The SQL prediction above is correct!
CREATE TABLE people (
people_id number ,
sex text ,
name text ,
height number ,
weight number ,
primary key ( people_id )
)
insert into people (people_id, sex, name, height, weight) values (1, M,
Hubert Henno, 188, 83);
24

Translate the following question into SQL.
Question: Find the average and minimum weight for each gender.
SQL: SELECT AVG(weight), MIN(weight), sex FROM people GROUP BY sex
Feedback: The SQL prediction above is correct!
CREATE TABLE customers (
customer_id number ,
customer_name text ,
customer_details text ,
primary key ( customer_id )
)
insert into customers (customer_id, customer_name, customer_details) values
(1, ’Savannah’, ’rerum’) ;
CREATE TABLE invoices (
invoice_number number ,
invoice_date time ,
invoice_details text ,
primary key ( invoice_number )
)
insert into invoices (invoice_number, invoice_date, invoice_details) values
(1, ’1989-09-03 16:03:05’, ’vitae’) ;
CREATE TABLE orders (
order_id number ,
customer_id number ,
order_status text ,
date_order_placed time ,
order_details text ,
primary key ( order_id ),
foreign key ( customer_id ) references customers ( customer_id )
)
insert into orders (order_id, customer_id, order_status, date_order_placed,
order_details) values (1, 2, ’Shipped’, ’2009-02-21 15:26:19’, NULL);
CREATE TABLE products (
product_id number ,
product_name text ,
product_details text,
primary key ( product_id )
)
insert into products (product_id, product_name, product_details) values (1,
’food’, NULL);
CREATE TABLE order_items (
order_item_id number ,
product_id number ,
order_id number ,
order_item_status text ,
order_item_details text ,
primary key ( order_item_id ) ,
foreign key ( product_id ) references product ( product_id ) ,
foreign key ( order_id ) references orders ( order_id )
)
insert into order_items (order_item_id, product_id, order_id,
order_item_status, order_item_details) values (1, 4, 6, ’Finish’, NULL) ;
CREATE TABLE shipments (
shipment_id number ,
order_id number ,
25

invoice_number number ,
shipment_tracking_number text ,
shipment_date time ,
other_shipment_details text ,
primary key ( shipment_id ) ,
foreign key ( invoice_number ) references invoices ( invoices_number ) ,
foreign key ( order_id ) references order ( order_id )
)
insert into shipments (shipment_id, order_id, invoice_number,
shipment_tracking_number, shipment_date, other_shipment_details) values (1,
5, 13, ’3452’, ’1983-08-13 22:34:11’, NULL) ;
CREATE TABLE shipment_items (
shipment_id number ,
order_item_id number ,
primary key ( ) ,
foreign key ( shipment_id ) references shipments ( shipment_id ) ,
foreign key ( order_item_id ) references order_items ( order_item_id )
)
insert into shipment_items (shipment_id, order_item_id) values (11, 12) ;
Translate the following question into SQL.
Question: Which customers have both "On Road" and "Shipped" as order status?
List the customer names.
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road" AND
orders.order_status = "Shipped"
Feedback: The SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road"
INTERSECT SELECT customers.customer_name FROM customers JOIN orders ON
customers.customer_id = orders.customer_id WHERE orders.order_status = "
Shipped"
Feedback: The SQL prediction above is correct!
CREATE TABLE flight (
flno number ,
origin text ,
destination text ,
aid number ,
primary key ( flno )
)
insert into flight (flno, origin, destination, aid) values (99.0, Los
Angeles, Washington D.C., 1);
Translate the following question into SQL.
Question: Show origins of all flights with destination Honolulu.
SQL: SELECT origin FROM flight WHERE destination = "HONO"
Feedback: The SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT origin FROM flight WHERE destination = "Honolulu"
Feedback: The SQL prediction above is correct!
26

CREATE TABLE station (
id number ,
name text ,
lat number ,
long number ,
dock_count number ,
city text ,
installation_date text ,
primary key ( id )
)
insert into station (id, name, lat, long, dock_count, city,
installation_date) values (2, San Jose Diridon Caltrain Station,
37.329732,-1.21901782000000011405e+02,27, San Jose, 8/6/2013);
CREATE TABLE status (
station_id number ,
bikes_available number ,
docks_available number ,
time text ,
primary key ( ) ,
foreign key ( station_id ) references station ( id )
)
insert into status (station_id, bikes_available, docks_available,time values
(3,12,3, 2015-06-02 12:46:02);
Translate the following question into SQL.
Question: What is the average longitude of stations that never had bike
availability more than 10?
SQL: SELECT AVG(long) FROM station WHERE id IN (SELECT station_id FROM
status WHERE bikes_available <= 10)
Feedback: The SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT AVG(long) FROM station WHERE id NOT IN (SELECT station_id FROM
status WHERE bikes_available > 10)
Feedback: The SQL prediction above is correct!
CREATE TABLE host (
host_id number ,
name text ,
nationality text ,
age number ,
primary key ( host_id )
)
insert into host (host_id, name, nationality, age) values (1,"Austin Daye","
United States",43);
Translate the following question into SQL.
Question: Show the name and the nationality of the oldest host.
SQL: SELECT name, nationality FROM host WHERE age = (SELECT MIN(age) FROM
host)
Feedback: The SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT name, nationality FROM host ORDER BY age DESC LIMIT 1
Feedback: The SQL prediction above is correct!
27

CREATE TABLE city (
city_id number ,
official_name text ,
status text ,
area_km_2 number ,
population number ,
census_ranking text ,
primary key ( city_id )
)
insert into city (city_id, official_name, status, area_km_2, population,
census_ranking) values (1,’Grand Falls/Grand-Sault’,’Town’,’18.06’,’5706’,’
636 of 5008’) ;
CREATE TABLE farm (
farm_id number ,
year number ,
total_horses number ,
working_horses number ,
total_cattle number ,
oxen number ,
bulls number ,
cows number ,
pigs number ,
sheep_and_goats number ,
primary key ( farm_id )
)
insert into farm (farm_id, year, total_horses, working_horses, total_cattle,
oxen, bulls, cows, pigs, sheep_and_goats) values (1,’1927’,’5056.5’,’3900.1
’,’8374.5’,’805.5’,’31.6’,’3852.1’,’4412.4’,’7956.3’) ;
CREATE TABLE farm_competition (
competition_id number ,
year number ,
theme text ,
host_city_id number ,
hosts text ,
primary key ( competition_id ) ,
foreign key ( host_city_id ) references city ( city_id )
)
insert into farm_competition (competition_id, year, theme, host_city_id,
hosts) values (1,’2013’,’Carnival M is back!’,1,’Miley Cyrus Jared Leto and
Karen Mok’) ;
CREATE TABLE competition_record (
competition_id number ,
farm_id number ,
rank number ,
primary key ( competition_id ) ,
foreign key ( farm_id ) references farm ( farm_id )
,
foreign key ( competition_id ) references farm_competition ( competition_id
)
)
insert into competition_record (competition_id, farm_id, rank) values
(1,8,1) ;
Translate the following question into SQL.
Question: How many different statuses do cities have?
SQL: SELECT COUNT(status) FROM city
Feedback: The SQL prediction above is wrong. Please fix the SQL.
28

SQL: SELECT COUNT(DISTINCT status) FROM city
Feedback: The SQL prediction above is correct!
CREATE TABLE user_profiles (
uid number ,
name text ,
followers number ,
primary key ( uid )
)
CREATE TABLE tweets (
id number ,
uid number ,
primary key ( id ) ,
foreign key ( uid ) references user_profiles ( uid )
)
Translate the following question into SQL.
Question: Find the average number of followers for the users who had some
tweets.
SQL: SELECT AVG(followers) FROM user_profiles
Feedback: The SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT AVG(followers) FROM user_profiles WHERE uid IN (SELECT uid FROM
tweets)
Feedback: The SQL prediction above is correct!
CREATE TABLE trip (
id number ,
duration number ,
bike_id number ,
primary key ( id )
)
insert into trip (id, duration, bike_id) values (900504, 384, 454);
Translate the following question into SQL.
Question: What is the total and maximum duration for all trips with the bike
id 636?
SQL: SELECT SUM(duration), MAX(duration) FROM trip WHERE bike_id = 636
Feedback: The SQL prediction above is correct!
<insert database schemas and the new question here>
<insert original SQL here>
29

A.3
Explanation Feedback Prompt (9-shot)
CREATE TABLE department (
department_id number ,
name text ,
creation text ,
ranking number ,
budget_in_billions number ,
num_employees number ,
primary key ( department_id )
)
insert into department (department_id, name, creation, ranking,
budget_in_billions, num_employees) values (1,’State’,’1789’,’1’
,9.9600000000000008526,30265.999999999999999) ;
CREATE TABLE head (
head_id number ,
name text ,
born_state text ,
age number ,
primary key ( head_id )
)
insert into head (head_id, name, born_state, age) values (1,’Tiger Woods’,’
Alabama’,66.999999999999999998) ;
CREATE TABLE management (
department_id number ,
head_id number ,
temporary_acting text ,
primary key ( department_id ) ,
foreign key ( head_id ) references head ( head_id )
,
foreign key ( department_id ) references department ( department_id )
)
insert into management (department_id, head_id, temporary_acting) values
(2,5,’Yes’) ;
Translate the following question into SQL.
Question: In which year were most departments established?
SQL: SELECT creation, COUNT(*) FROM department GROUP BY creation ORDER BY
COUNT(*) DESC LIMIT 1
The execution of the SQL query above would return a table with 2 columns.
The first column, "creation" would contain the year in which a department
was created. The second column, "COUNT(*)" would contain the number of
departments created in that year. With "GROUP BY creation ORDER BY COUNT(*)
DESC", the table would be sorted in descending order by the number of
departments created in each year. With "LIMIT 1", only the first (i.e.,
highest) result would be returned. So the SQL query returns a table with 2
columns, the year in which most departments were created, and the number of
departments created in that year.
Feedback: As in your explanation, the SQL query returns a table with 2
columns, the year in which most departments was created, and the number of
departments created in that year. The question returns 1 column, the year in
which the most departments were established. So the SQL prediction above is
wrong. Please fix the SQL.
SQL: SELECT creation FROM department GROUP BY creation ORDER BY COUNT(*)
DESC LIMIT 1
30

The execution of the SQL query above would return a table with 1 column. The
first column, "creation" would contain the year in which a department was
created. With "GROUP BY creation ORDER BY COUNT(*) DESC", the table would be
sorted in descending order by the number of departments created in each
year. With "LIMIT 1", only the first (i.e., highest) result would be
returned. So the SQL query returns a table with 1 column, the year in which
most departments were created.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the year in which most departments was created. The question returns
1 column, the year in which the most departments were established. So the
SQL prediction above is correct!
CREATE TABLE people (
people_id number ,
sex text ,
name text ,
height number ,
weight number ,
primary key ( people_id )
)
insert into people (people_id, sex, name, height, weight) values (1, M,
Hubert Henno, 188, 83);
Translate the following question into SQL.
Question: Find the average and minimum weight for each gender.
SQL: SELECT AVG(weight), MIN(weight), sex FROM people GROUP BY sex
The execution of the SQL query above would return a table with 3 columns.
The first column, "AVG(weight)" would contain the average weight. The second
column, "MIN(weight)" would contain the minimum weight. The third column, "
sex" would contain the gender. With "GROUP BY sex", the table would be
grouped by gender. So the SQL query returns a table with 3 columns, the
average weight, the minimum weight, and the gender of people for each gender
.
Feedback: As in your explanation, the SQL query returns a table with 3
columns, the average weight, the minimum weight, and the gender of people
for each gender. The question returns 3 columns, the average and minimum
weight for each gender. So the SQL prediction above is correct!
CREATE TABLE customers (
customer_id number ,
customer_name text ,
customer_details text ,
primary key ( customer_id )
)
insert into customers (customer_id, customer_name, customer_details) values
(1, ’Savannah’, ’rerum’) ;
CREATE TABLE invoices (
invoice_number number ,
invoice_date time ,
invoice_details text ,
primary key ( invoice_number )
)
insert into invoices (invoice_number, invoice_date, invoice_details) values
(1, ’1989-09-03 16:03:05’, ’vitae’) ;
CREATE TABLE orders (
31

order_id number ,
customer_id number ,
order_status text ,
date_order_placed time ,
order_details text ,
primary key ( order_id ),
foreign key ( customer_id ) references customers ( customer_id )
)
insert into orders (order_id, customer_id, order_status, date_order_placed,
order_details) values (1, 2, ’Shipped’, ’2009-02-21 15:26:19’, NULL);
CREATE TABLE products (
product_id number ,
product_name text ,
product_details text,
primary key ( product_id )
)
insert into products (product_id, product_name, product_details) values (1,
’food’, NULL);
CREATE TABLE order_items (
order_item_id number ,
product_id number ,
order_id number ,
order_item_status text ,
order_item_details text ,
primary key ( order_item_id ) ,
foreign key ( product_id ) references product ( product_id ) ,
foreign key ( order_id ) references orders ( order_id )
)
insert into order_items (order_item_id, product_id, order_id,
order_item_status, order_item_details) values (1, 4, 6, ’Finish’, NULL) ;
CREATE TABLE shipments (
shipment_id number ,
order_id number ,
invoice_number number ,
shipment_tracking_number text ,
shipment_date time ,
other_shipment_details text ,
primary key ( shipment_id ) ,
foreign key ( invoice_number ) references invoices ( invoices_number ) ,
foreign key ( order_id ) references order ( order_id )
)
insert into shipments (shipment_id, order_id, invoice_number,
shipment_tracking_number, shipment_date, other_shipment_details) values (1,
5, 13, ’3452’, ’1983-08-13 22:34:11’, NULL) ;
CREATE TABLE shipment_items (
shipment_id number ,
order_item_id number ,
primary key ( ) ,
foreign key ( shipment_id ) references shipments ( shipment_id ) ,
foreign key ( order_item_id ) references order_items ( order_item_id )
)
insert into shipment_items (shipment_id, order_item_id) values (11, 12) ;
Translate the following question into SQL.
Question: Which customers have both "On Road" and "Shipped" as order status?
List the customer names.
32

SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road" AND
orders.order_status = "Shipped"
The execution of the SQL query above would return an empty table. The first
column, "customers.customer_name" would contain the customer name. With "
customers JOIN orders", the table would contain the data about customers
with orders. In the WHERE clause, with "orders.order_status = ’On Road’",
the table filters the records to only include customers who have order
status "On Road". With "orders.order_status = ’Shipped’", the table filters
the records to only include customers who have order status "Shipped". With
"WHERE orders.order_status = ’On Road’ AND orders.order_status = ’Shipped’",
the table filters the records to only include customers who have both "On
Road" and "Shipped" as order status at the same time. This is not possible,
since the two are mutually exclusive. So the SQL query returns an empty
table, because the "WHERE" clause contains mutually exclusive conditions.
Feedback: As in your explanation, the SQL query returns an empty table,
because the "WHERE" clause contains mutually exclusive conditions. The
question returns 1 column, the customer names who have order status of both
"On Road" and "Shipped". So the question returns 1 column. So the SQL
prediction above is wrong. Please fix the SQL.
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road"
INTERSECT SELECT customers.customer_name FROM customers JOIN orders ON
customers.customer_id = orders.customer_id WHERE orders.order_status = "
Shipped"
The execution of the SQL query above would return a table with 1 column. The
first column, "customers.customer_name" would contain the customer names.
With "customers JOIN orders", the table would contain the data about
customers with orders. With "WHERE orders.order_status = ’On Road’", the
table filters the records to only include customers who have order status "
On Road". With "WHERE orders.order_status = ’Shipped’", the table filters
the records to only include customers who have order status "Shipped". With
"INTERSECT", the table would be filtered to only include customers who have
both "On Road" and "Shipped" as order status. So the SQL query returns a
table with 1 column, the customer names who have the order status "On Road"
and "Shipped".
Feedback: As in your explanation, the SQL query returns a table with 1
column, the customer names who have the order status "On Road" and "Shipped
". The question returns 1 column, the customer names who have order status
of both "On Road" and "Shipped". So the SQL prediction above is correct!
CREATE TABLE flight (
flno number ,
origin text ,
destination text ,
aid number ,
primary key ( flno )
)
insert into flight (flno, origin, destination, aid) values (99.0, Los
Angeles, Washington D.C., 1);
Translate the following question into SQL.
Question: Show origins of all flights with destination Honolulu.
SQL: SELECT origin FROM flight WHERE destination = "HONO"
33

The execution of the SQL query above would return an empty table. The first
column, "origin" would contain the origin of flights. With "WHERE
destination = ’HONO’", the table filters the records to only include flights
whose destination is "HONO". So the SQL query returns an empty table.
Feedback: As in your explanation, the SQL query returns an empty table. The
question returns 1 column, the origins of all flights with destination
Honolulu. So the SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT origin FROM flight WHERE destination = "Honolulu"
The execution of the SQL query above would return a table with 1 column. The
first column, "origin" would contain the origin of flights. With "WHERE
destination = ’Honolulu’", the table filters the records to only include
flights whose destination is "Honolulu". So the SQL query returns a table
with 1 column, the origin of flights with destination Honolulu.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the origin of flights with destination Honolulu. The question
returns 1 column, the origins of all flights with destination Honolulu. So
the SQL prediction above is correct!
CREATE TABLE station (
id number ,
name text ,
lat number ,
long number ,
dock_count number ,
city text ,
installation_date text ,
primary key ( id )
)
insert into station (id, name, lat, long, dock_count, city,
installation_date) values (2, San Jose Diridon Caltrain Station,
37.329732,-1.21901782000000011405e+02,27, San Jose, 8/6/2013);
CREATE TABLE status (
station_id number ,
bikes_available number ,
docks_available number ,
time text ,
primary key ( ) ,
foreign key ( station_id ) references station ( id )
)
insert into status (station_id, bikes_available, docks_available,time values
(3,12,3, 2015-06-02 12:46:02);
Translate the following question into SQL.
Question: What is the average longitude of stations that never had bike
availability more than 10?
SQL: SELECT AVG(long) FROM station WHERE id IN (SELECT station_id FROM
status WHERE bikes_available <= 10)
The execution of the SQL query above would return a table with 1 column. The
first column, "AVG(long)" would contain the average longitude. With "WHERE
id IN (SELECT station_id FROM status WHERE bikes_available <= 10)", the
table filters the records to only include stations with 10 or less bikes
available. So the SQL query returns a table with 1 column, the average
longitude of stations with 10 or less bikes available.
34

Feedback: As in your explanation, the SQL query returns a table with 1
column, the average longitude of stations with 10 or less bikes available.
The question returns 1 column, the average longitude of stations that never
had bike availability more than 10. So the SQL prediction above is wrong.
Please fix the SQL.
SQL: SELECT AVG(long) FROM station WHERE id NOT IN (SELECT station_id FROM
status WHERE bikes_available > 10)
The execution of the SQL query above would return a table with 1 column. The
first column, "AVG(long)" would contain the average longitude. With "WHERE
id NOT IN (SELECT station_id FROM status WHERE bikes_available > 10)", the
table filters the records to only include stations that do not have more
than 10 bikes available. So the SQL query returns a table with 1 column, the
average longitude of stations that do not have more than 10 bikes available
.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the average longitude of stations that do not have more than 10
bikes available. The question returns 1 column, the average longitude of
stations that never had bike availability more than 10. The question returns
1 column, the average longitude of stations that never had bike
availability more than 10. So the SQL prediction above is correct!
CREATE TABLE host (
host_id number ,
name text ,
nationality text ,
age number ,
primary key ( host_id )
)
insert into host (host_id, name, nationality, age) values (1,"Austin Daye","
United States",43);
Translate the following question into SQL.
Question: Show the name and the nationality of the oldest host.
SQL: SELECT name, nationality FROM host WHERE age = (SELECT MIN(age) FROM
host)
The execution of the SQL query above would return a table with 2 columns.
The first column, "name" would contain the name. The second column, "
nationality" would contain the nationality. With "WHERE age = (SELECT MIN(
age) FROM host)", the table filters the records to only include hosts with
the minimum age, which means the youngest age. So the SQL query returns a
table with 2 columns, the name and the nationality of the host with the
youngest age.
Feedback: As in your explanation, the SQL query returns a table with 2
columns, the name and the nationality of the host with the youngest age. The
question returns 2 columns, the name and the nationality of the oldest host
. So the SQL prediction above is wrong. Please fix the SQL.
SQL: SELECT name, nationality FROM host ORDER BY age DESC LIMIT 1
The execution of the SQL query above would return a table with 2 columns.
The first column, "name" would contain the name. The second column, "
nationality" would contain the nationality. With "ORDER BY age DESC", the
table is sorted in descending order. With "LIMIT 1", the table only includes
the first record, which is the oldest host. So the SQL query returns a
table with 2 columns, the name and the nationality of the oldest host.
35

Feedback: As in your explanation, the SQL query returns a table with 2
columns, the name and the nationality of the oldest host. The question
returns 2 columns, the name and the nationality of the oldest host. So the
SQL prediction above is correct!
CREATE TABLE city (
city_id number ,
official_name text ,
status text ,
area_km_2 number ,
population number ,
census_ranking text ,
primary key ( city_id )
)
insert into city (city_id, official_name, status, area_km_2, population,
census_ranking) values (1,’Grand Falls/Grand-Sault’,’Town’,’18.06’,’5706’,’
636 of 5008’) ;
CREATE TABLE farm (
farm_id number ,
year number ,
total_horses number ,
working_horses number ,
total_cattle number ,
oxen number ,
bulls number ,
cows number ,
pigs number ,
sheep_and_goats number ,
primary key ( farm_id )
)
insert into farm (farm_id, year, total_horses, working_horses, total_cattle,
oxen, bulls, cows, pigs, sheep_and_goats) values (1,’1927’,’5056.5’,’3900.1
’,’8374.5’,’805.5’,’31.6’,’3852.1’,’4412.4’,’7956.3’) ;
CREATE TABLE farm_competition (
competition_id number ,
year number ,
theme text ,
host_city_id number ,
hosts text ,
primary key ( competition_id ) ,
foreign key ( host_city_id ) references city ( city_id )
)
insert into farm_competition (competition_id, year, theme, host_city_id,
hosts) values (1,’2013’,’Carnival M is back!’,1,’Miley Cyrus Jared Leto and
Karen Mok’) ;
CREATE TABLE competition_record (
competition_id number ,
farm_id number ,
rank number ,
primary key ( competition_id ) ,
foreign key ( farm_id ) references farm ( farm_id )
,
foreign key ( competition_id ) references farm_competition ( competition_id
)
)
insert into competition_record (competition_id, farm_id, rank) values
(1,8,1) ;
Translate the following question into SQL.
36

Question: How many different statuses do cities have?
SQL: SELECT COUNT(status) FROM city
The execution of the SQL query above would return a table with 1 column. The
first column, "COUNT(status)" would contain the number of cities. So the
SQL query returns a table with 1 column, the number of cities.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the number of cities. The question returns 1 column, the number of
different statuses of cities. So the SQL prediction above is wrong. Please
fix the SQL.
SQL: SELECT COUNT(DISTINCT status) FROM city
The execution of the SQL query above would return a table with 1 column. The
first column, "COUNT(DISTINCT status)" would contain the number of
different statuses of cities. So the SQL query returns a table with 1 column
, the number of different statuses of cities.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the number of different statuses of cities. The question returns 1
column, the number of different statuses of cities. So the SQL prediction
above is correct!
CREATE TABLE user_profiles (
uid number ,
name text ,
followers number ,
primary key ( uid )
)
CREATE TABLE tweets (
id number ,
uid number ,
primary key ( id ) ,
foreign key ( uid ) references user_profiles ( uid )
)
Translate the following question into SQL.
Question: Find the average number of followers for the users who had some
tweets.
SQL: SELECT AVG(followers) FROM user_profiles
The execution of the SQL query above would return a table with 1 column. The
first column, "AVG(followers)" would contain the average number of
followers. So the SQL query returns a table with 1 column, the average
number of followers.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the average number of followers. The question returns 1 column, the
average number of followers for the users who had some tweets. So the SQL
prediction above is wrong. Please fix the SQL.
SQL: SELECT AVG(followers) FROM user_profiles WHERE uid IN (SELECT uid FROM
tweets)
37

The execution of the SQL query above would return a table with 1 column. The
first column, "AVG(followers)" would contain the average number of
followers. With "WHERE uid IN (SELECT uid FROM tweets)", the table filters
the records to only include users who have tweets. So the SQL query returns
a table with 1 column, the average number of followers of users who have
tweets.
Feedback: As in your explanation, the SQL query returns a table with 1
column, the average number of followers of users who have tweets. The
question returns 1 column, the average number of followers for the users who
had some tweets. So the SQL prediction above is correct!
CREATE TABLE trip (
id number ,
duration number ,
bike_id number ,
primary key ( id )
)
insert into trip (id, duration, bike_id) values (900504, 384, 454);
Translate the following question into SQL.
Question: What is the total and maximum duration for all trips with the bike
id 636?
SQL: SELECT SUM(duration), MAX(duration) FROM trip WHERE bike_id = 636
The execution of the SQL query above would return a table with 2 columns.
The first column, "SUM(duration)" would contain the sum of the duration. The
second column, "MAX(duration)" would contain the maximum duration. With "
WHERE bike_id = 636", the table filters the records to only include trips
with bike ID 636. So the SQL query returns a table with 2 columns, the sum
of the duration and the maximum duration of trips with bike ID 636.
Feedback: As in your explanation, the SQL query returns a table with 2
columns, the sum of the duration and the maximum duration of trips with bike
ID 636. The question returns 2 columns, the total and maximum duration for
all trips with the bike id 636. So the SQL prediction above is correct!
<insert database schemas and the new question here>
<insert original SQL here>
A.4
Prompt for Question Explanation
Infer the return type of the question.
CREATE TABLE song (
song_name text ,
artist_name text ,
country text ,
f_id number ,
genre_is text ,
rating number ,
languages text ,
primary key ( f_id )
)
38

insert into song (song_name, artist_name, country, f_id, genre_is, rating,
languages) values (Tumi robe nirobe, Shrikanta, India, 1, tagore, 8, bangla)
;
Question: What is the id, genre, and name of the artist for every English
song ordered by ascending rating?
Answer: "What is the id" returns 1 column. "What is the genre" returns 1
column. "What is the id, genre" returns 2 columns. "What is the name"
returns 1 column. "What is the id, genre, and name" returns 3 columns.The
question returns the id, genre, and name of the artist for every English
song ordered by ascending rating. So the question returns 3 columns.
CREATE TABLE physician (
employee_id number ,
name text ,
position text ,
primary key ( employee_id )
)
insert into physician (employee_id, name, position) values (1, John Dorian,
Staff Internist);
CREATE TABLE procedures (
code number ,
name text ,
cost number ,
primary key ( code )
)
insert into procedures (code, name, cost) values (1, Reverse Rhinopodoplasty
, 1500.0);
CREATE TABLE trained_in (
physician number ,
treatment text ,
primary key ( physician ) ,
foreign key ( physician ) references physician ( employee_id )
)
insert into trained_in (physician, treatment) values (3,1);
Question: Among the procedures that cost more than 1000, which were not
specialized in by physician John Wen?
Answer: "Among the procedures that cost more than 1000, which were not
specialized in by physician John Wen" returns 1 column. The question returns
the procedures that cost more than 1000, and were not specialized in by
physician John Wen. So the question returns 1 column.
CREATE TABLE department (
department_id number ,
name text ,
creation text ,
ranking number ,
budget_in_billions number ,
num_employees number ,
primary key ( department_id )
)
insert into department (department_id, name, creation, ranking,
budget_in_billions, num_employees) values (1, State, 1789, 1,
9.9600000000000008526, 30265.999999999999999) ;
CREATE TABLE head (
head_id number ,
name text ,
39

born_state text ,
age number ,
primary key ( head_id )
)
insert into head (head_id, name, born_state, age) values (1, Tiger Woods,
Alabama, 66.999999999999999998) ;
CREATE TABLE management (
department_id number ,
head_id number ,
temporary_acting text ,
primary key ( department_id ) ,
foreign key ( head_id ) references head ( head_id )
,
foreign key ( department_id ) references department ( department_id )
)
insert into management (department_id, head_id, temporary_acting) values
(2,5, Yes) ;
Question: Which department has more than 1 head at a time? List the id, name
and the number of heads.
Answer: "List the id" returns 1 column. "List the name" returns 1 column. "
List the id, name" returns 2 columns. "List the number of heads" returns 1
column. "List the id, name and the number of heads" returns 3 columns. The
question returns the id, name and the number of heads of the department has
more than 1 head at a time. So the question returns 3 columns.
Question: Show the name and number of employees for the departments managed
by heads whose temporary acting value is ’Yes’?
Answer: "Show the name" returns 1 column. "Show the number of employees"
returns 1 column. "Show the name and number of employees" returns 2 columns.
The question returns the name and number of employees for the departments
managed by heads whose temporary acting value is ’Yes’. So the question
returns 2 columns.
CREATE TABLE class (
class_code text ,
crs_code text ,
prof_num number ,
primary key ( class_code ) ,
foreign key ( prof_num ) references professor ( emp_num ) ,
foreign key ( crs_code ) references course ( crs_code )
)
insert into class (class_code, crs_code, prof_num) values (10012, ACCT-211,
105);
CREATE TABLE employee (
emp_num number ,
emp_lname text ,
emp_fname text ,
emp_initial text ,
emp_jobcode text ,
primary key ( emp_num )
)
insert into employee (emp_num, emp_lname, emp_fname, emp_initial,
emp_jobcode values (100, Worley, James, F, CUST);
CREATE TABLE course (
crs_code text ,
dept_code text ,
crs_description text ,
primary key ( crs_code )
)
40

insert into course ( crs_code, dept_code, crs_description) values (ACCT-211,
ACCT, Accounting I);
CREATE TABLE professor (
emp_num number ,
dept_code text ,
prof_office text ,
primary key ( emp_num ) ,
foreign key ( emp_num ) references employee ( emp_num )
)
insert into professor (emp_num, dept_code, prof_office ) values (103, HIST,
DRE 156);
Question: Find the first names and offices of all instructors who have
taught some course and also find the course description.
Answer: "Find the first names" returns 1 column. "Find the offices" returns
1 column. "Find the first names and offices" returns 2 columns. "Find the
first names and offices of all instructors who have taught some course"
returns 2 columns. "and also find the course description" returns 1 column.
"Find the first names and offices of all instructors who have taught some
course and also find the course description" returns 3 columns. The question
returns the first names and offices of instructors who have taught some
course and the course description. So the question returns 3 columns.
CREATE TABLE airports (
apid number ,
name text ,
city text ,
country text ,
elevation text ,
primary key ( apid )
)
Question: List the id, country, city and name of the airports ordered
alphabetically by the name.
Answer: "List the id" returns 1 column. "List the country" returns 1 column.
"List the id, country" returns 2 columns. "List the city" returns 1 column.
"List the id, country, city" returns 3 columns. "List the name" returns 1
column. "List the id, country, city, and name" returns 4 columns. The
question returns the id, country, city and name of the airports ordered
alphabetically by the name. So the question returns 4 columns.
CREATE TABLE student (
stuid number ,
lname text ,
fname text ,
primary key ( stuid )
)
insert into student (stuid, lname, fname) values (1001, Smith, Linda);
CREATE TABLE plays_games (
stuid number ,
gameid number ,
hours_played number ,
population number ,
primary key ( stuid ) ,
foreign key ( stuid ) references student ( stuid )
)
insert into plays_games (stuid, gameid, hours_played) values (1001, 1, 35);
CREATE TABLE sports_info (
41

stuid number ,
sport_name text ,
hours_per_week number ,
games_played number ,
primary key ( stuid ) ,
foreign key ( stuid ) references student ( stuid )
)
insert into sport_info (stuid, sport_name, hours_per_week, games_played)
values (1001, Athletics, 2, 5);
Question: What are the ids of all students and number of hours played?
Answer: "What are the ids" returns 1 column. "What are the number of hours
played" returns 1 column. "What are the ids and number of hours played"
returns 2 columns. The question returns the ids of students and number of
hours played. So the question returns 2 columns.
Question: What is the total number of hours per week and number of games
played by students under 20?
Answer: "What is the total number of hours per week" returns 1 column. "What
is the number of games played" returns 1 column. "What is the total number
of hours per week and number of games played" returns 2 columns. The
question returns the total number of hours per week and number of games
played by students under 20. So the question returns 2 columns.
CREATE TABLE journal (
journal_id number ,
theme text ,
primary id ( journal_id )
)
insert into journal (journal_id, theme) values (1, Miami Dolphins);
CREATE TABLE editor (
editor_id number ,
name text ,
age number ,
primary id ( editor_id )
)
insert into editor (editor_id, name, age) values (1.0, Kamila Porczyk, 34.0)
;
CREATE TABLE journal_committee (
editor_id number ,
journal_id number ,
primary id ( editor_id ) ,
foreign key ( editor_id ) references editor ( editor_id ) ,
foreign key ( journal_id ) references journal ( journal_id )
)
insert into journal_committee (editor_id, journal_id) values (1, 13);
Question: Show the names and ages of editors and the theme of journals for
which they serve on committees, in ascending alphabetical order of theme.
Answer: "Show the names" returns 1 column. "Show the ages" returns 1 column.
"Show the names and ages" returns 2 columns. "Show the theme of journals"
returns 1 column. "Show the names and ages of editors and the theme of
journals" returns 3 columns. "Show the names and ages of editors and the
theme of journals for which they serve on committees" returns 3 columns. "
Show the names and ages of editors and the theme of journals for which they
serve on committees, in ascending alphabetical order of theme" returns 3
columns. The question returns the names and ages of editors and the theme of
journals for which they serve on committees, in ascending alphabetical
order of theme. So the question returns 3 columns.
42

CREATE TABLE people (
people_id number ,
sex text ,
name text ,
height number ,
weight number ,
primary key ( people_id )
)
insert into people (people_id, sex, name, height, weight) values (1, M,
Hubert Henno, 188, 83);
Question: Find the average and minimum weight for each gender.
Answer: "Find the average weight" returns 1 column. "Find the minimum weight
" returns 1 column. "Find the average and minimum weight" returns 2 columns.
"Find the average and minimum weight for each gender" returns 3 columns.
The question returns the average and minimum weight for each gender. So the
question returns 3 columns.
Question: List all info about all people.
Answer: "List all info" returns all columns. The question returns all info
about all people. So the question returns all columns.
CREATE TABLE student (
stuid number ,
lname text ,
fname text ,
age number ,
sex text ,
major number ,
advisor number ,
city_code text ,
primary key ( stuid )
)
insert into student (stuid, lname, fname, age, sex, major, advisor,
city_code) values ( 1001, Smith, Linda, 18, F, 600, 1121, BAL);
Question: How many students are there for each major?
Answer: "How many students" returns 1 column. "How many students are there
for each major" returns 2 columns. The question returns the number of
students for each major. So the question returns 2 columns.
CREATE TABLE accounts (
account_id number ,
customer_id number ,
date_account_opened time ,
account_name text ,
other_account_details text ,
primary key ( account_id ) ,
foreign key ( customer_id ) references customers ( customer_id )
)
insert into accounts (account_id, customer_id, date_account_opened,
account_name, other_account_details) values (1, 6, 2016-07-30 22:22:24, 338,
Regular);
CREATE TABLE customers (
customer_id number ,
customer_first_name text ,
customer_last_name text ,
customer_address text ,
customer_phone text ,
43

customer_email text ,
other_customer_details text ,
primary key ( customer_id )
)
insert into customers (customer_id, customer_first_name, customer_last_name,
customer_address, customer_phone, customer_email, other_customer_details)
values (1, Aniyah, Feest, 55975 Theodore Estates Lake Brody, VT 57078, (673)
872-5338, fahey.dorian@example.com, NULL);
Question: What are the full names of customers who have accounts?
Answer: "full names" include the first and the last name. "What are the full
names" returns 2 columns. The question returns the full names of customers
who have accounts. So the question returns 2 columns.
Question: What are the ids, date opened, name, and other details for all
accounts?
Answer: "What are the ids" returns 1 column. "What are the date opened"
returns 1 column. "What are the ids, date opened" returns 2 columns. "What
are the name" returns 1 column. "What are the ids, date opened, name"
returns 3 columns. "What are the other details" returns 1 column. "What are
the ids, date opened, name, and other details" returns 4 columns. The
question returns the ids, date opened, name, and other details for all
accounts. So the question returns 4 columns.
CREATE TABLE station (
id number ,
name text ,
lat number ,
long number ,
dock_count number ,
city text ,
installation_date text ,
primary key ( id )
)
insert into station (id, name, lat, long, dock_count, city,
installation_date) values (2, San Jose Diridon Caltrain Station,
37.329732,-1.21901782000000011405e+02,27, San Jose, 8/6/2013);
CREATE TABLE status (
station_id number ,
bikes_available number ,
docks_available number ,
time text ,
primary key ( ) ,
foreign key ( station_id ) references station ( id )
)
insert into status (station_id, bikes_available, docks_available,time)
values (3,12,3, 2015-06-02 12:46:02);
CREATE TABLE trip (
id number ,
duration number ,
bike_id number ,
start_date time ,
start_station_name text ,
start_station_id number ,
primary key ( id )
)
insert into trip (id, duration, bike_id, start_date, start_station_name,
start_station_id) values (900504, 384, 454, 8/21/2015 17:03, Howard at 2nd,
63);
44

Question: What is the name of every city that has at least 15 stations and
how many stations does it have?
Answer: "What is the name" returns 1 column. "What is the name of every city
that has at least 15 stations" returns 1 column. "What is the name of every
city that has at least 15 stations and how many stations does it have"
returns 2 columns. The question returns the name and the number of stations
of every city that has at least 15 stations. So the question returns 2
columns.
Question: Which start station had the most trips starting from August? Give
me the name and id of the station.
Answer: "Give me the name" returns 1 column. "Give me the id" returns 1
column. "Give me the name and id" returns 2 columns. The question returns
the name and id of the station that had the most trips starting from August.
So the question returns 2 columns.
CREATE TABLE user_profiles (
uid number ,
name text ,
followers number ,
primary key ( uid )
)
Question: List the name and number of followers for each user, and sort the
results by the number of followers in descending order.
Answer: "List the name" returns 1 column. "List the number of followers"
returns 1 column. "List the name and number of followers" returns 2 columns.
"List the name and number of followers for each user" returns 2 columns. "
List the name and number of followers for each user, and sort the results by
the number of followers in descending order" returns 2 columns. The
question returns the name and number of followers for each user in the
descending order of the number of followers. So the question returns 2
columns.
CREATE TABLE race (
race_id number ,
name text ,
date text ,
track_id number ,
primary key ( race_id ) ,
foreign key (track_id ) references track ( track_id )
)
insert into race (race_id, name, date, track_id) values (1, Rolex 24 At
Daytona, January 26 January 27, 1);
CREATE TABLE track (
track_id number ,
name text ,
primary key ( track_id )
)
insert into track (track_id, name) values (1, Auto Club Speedway);
Question: Show the name and date for each race and its track name.
Answer: "Show the name" returns 1 column. "Show the date" returns 1 column.
"Show the name and date" returns 2 columns. "Show the name and date for each
race" returns 2 columns. "Show the name and date for each race and its
track name" returns 3 columns. The question returns the name, date and track
name for each race. So the question returns 3 columns.
45

CREATE TABLE station (
id number ,
network_name text ,
services text ,
primary key ( id )
)
insert into station (id, network_name, services) values (1, Amersham,
Metropolitan line and Chiltern Railways);
CREATE TABLE routes (
train_id number ,
station_id number ,
primary key ( train_id ) ,
foreign key ( station_id ) references station ( id )
)
insert into route (train_id, station_id) values (1,1);
Question: Find the number of trains for each station, as well as the station
network name and services.
Answer: "Find the number of trains" returns 1 column. "Find the number of
trains for each station" returns 2 columns. "Find the number of trains for
each station, as well as the station network name" returns 2 columns. "Find
the number of trains for each station, as well as the station network name
and services" returns 3 columns. The question returns the number of trains,
the station network name and services for each station. So the question
returns 3 columns.
CREATE TABLE manufacturers (
code number ,
name text ,
primary key ( code )
)
insert into manufacturers (code, name) values (1, Sony);
CREATE TABLE products (
code number ,
name text ,
manufacturer number ,
primary key ( code ) ,
foreign key ( manufacturer ) references manufacturer ( code )
)
insert into products (code, name, manufacturer) values (1, Hard drive, 5);
Question: Find the number of products for each manufacturer, showing the
name of each company.
Answer: "Find the number of products" returns 1 column. "Find the number of
products for each manufacturer" returns 2 columns. "Find the number of
products for each manufacturer, showing the name of each company" returns 2
columns. The question returns the number of products and the company name
for each manufacturer. So the question returns 2 columns.
<insert database schemas and the new question here>
46

A.5
Prompt for SQL Explanation
Summarize the return type of the execution.
SQL: SELECT creation FROM department GROUP BY creation ORDER BY COUNT(*)
DESC LIMIT 1
Execution:
| 1789 |
Answer: The execution of the SQL query above would return a table with 1
column. The first column, "creation" would contain the year in which a
department was created. With "GROUP BY creation ORDER BY COUNT(*) DESC", the
table would be sorted in descending order by the number of departments
created in each year. With "LIMIT 1", only the first (i.e., highest) result
would be returned. So the SQL query returns a table with 1 column, the year
in which most departments were created.
SQL: SELECT manufacturer, AVG(price) FROM products GROUP BY manufacturer
Execution:
| 1 | 240.0 |
| 2 | 150.0 |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "manufacturer" would contain the manufacturer
code. The second column, "AVG(price)" would contain the average price of
each manufacturer’s product. So the SQL query returns a table with 2 columns
, the manufacturer code, and the average price of each manufacturer’s
product.
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road"
INTERSECT SELECT customers.customer_name FROM customers JOIN orders ON
customers.customer_id = orders.customer_id WHERE orders.order_status = "
Shipped"
Execution:
| George |
Answer: The execution of the SQL query above would return a table with 1
column. The first column, "customers.customer_name" would contain the
customer names. With "customers JOIN orders", the table would contain the
data about customers with orders. With "WHERE orders.order_status = ’On Road
’", the table filters the records to only include customers who have order
status "On Road". With "WHERE orders.order_status = ’Shipped’", the table
filters the records to only include customers who have order status "Shipped
". With "INTERSECT", the table would be filtered to only include customers
who have both "On Road" and "Shipped" as order status. So the SQL query
returns a table with 1 column, the customer names who have the order status
"On Road" and "Shipped".
SQL: SELECT MAX(cows), MIN(cows) FROM farm
Execution:
| 3987.0 | 2407.2 |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "MAX(cows)" would contain the maximum number of
cows. The second column, "MIN(cows)" would contain the minimum number of
cows. So the SQL query returns a table with 2 columns, the maximum and
minimum number of cows.
SQL: SELECT AVG(rating.stars), movie.title FROM rating JOIN movie ON rating.
mid = movie.mid WHERE movie.year = (SELECT MIN(year) FROM movie)
47

Execution:
| 4.5 | Snow White |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "AVG(rating.stars)" would contain the average
rating. The second column, "movie.title" would contain the movie title. With
"rating JOIN movie", the table would contain the data about ratings and
movies. With "WHERE movie.year = (SELECT MIN(year) FROM movie)", the table
filters the records to only include movies with the minimum year, which
means the earliest year. So the SQL query returns a table with 2 columns,
the average rating and the movie title of the movie with the earliest year.
SQL: SELECT course.title, course.credits FROM classroom JOIN section ON
classroom.building = section.building AND classroom.room_number = section.
room_number JOIN course ON section.course_id = course.course_id WHERE
classroom.capacity = (SELECT MAX(capacity) FROM classroom)
Execution:
| Accounting | 3 |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "course.title" would contain the course title.
The second column, "course.credits" would contain the course credits. With "
classroom JOIN section", the table would contain the data about classrooms
and sections. With "JOIN course", the table would contain the data about
courses. With "WHERE classroom.capacity = (SELECT MAX(capacity) FROM
classroom)", the table filters the records to only include classrooms with
the maximum capacity, which means the largest capacity. So the SQL query
returns a table with 2 columns, the course title and the course credits of
the classroom with the largest capacity.
SQL: SELECT model_name, ram_mib FROM chip_model ORDER BY ram_mib ASC LIMIT
1;
Execution:
| X5 | 32.0 |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "model_name" would contain the model name. The
second column, "ram_mib" would contain the RAM size. With "ORDER BY ram_mib
ASC", the table would be sorted in ascending order by RAM size. With "LIMIT
1", only the first (i.e., lowest) result would be returned. So the SQL query
returns a table with 2 columns, the model name and the RAM size of the chip
model with the lowest RAM size.
SQL: SELECT official_name, status FROM city ORDER BY population DESC LIMIT 1
Execution:
| Grand Falls/Grand-Sault | Town |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "official_name" would contain the official name.
The second column, "status" would contain the status. With "ORDER BY
population DESC", the table would be sorted in descending order by
population, which means from the most number of people to the least number
of people. With "LIMIT 1", only the first (i.e., highest) result would be
returned. So the SQL query returns a table with 2 columns, the official name
and the status of the city with the largest population, which means with
the most number of people.
SQL: SELECT AVG(budget_million), MAX(budget_million), MIN(budget_million)
FROM movie WHERE year < 2000
Execution:
| 6.0 | 7.0 | 5.0 |
48

Answer: The execution of the SQL query above would return a table with 3
columns. The first column, "AVG(budget_million)" would contain the average
budget. The second column, "MAX(budget_million)" would contain the maximum
budget. The third column, "MIN(budget_million)" would contain the minimum
budget. With "WHERE year < 2000", the table filters the records to only
include movies before 2000. So the SQL query returns a table with 3 columns,
the average, maximum, and minimum budget of movies before 2000.
SQL: SELECT department.department_id, department.name, COUNT(*) FROM
management JOIN department ON department.department_id = management.
department_id GROUP BY department.department_id HAVING COUNT(*) > 1
Execution:
| 2 | Treasury | 2 |
Answer: The execution of the SQL query above would return a table with 3
columns. The first column, "department.department_id" would contain the
department ID. The second column, "department.name" would contain the
department name. The third column, "COUNT(*)" would contain the number of
managers. With "management JOIN department", the table would contain the
data about management and departments. With "GROUP BY department.
department_id", the table would be grouped by department ID. With "HAVING
COUNT(*) > 1", the table filters the records to only include departments
with more than 1 manager. So the SQL query returns a table with 3 columns,
the department ID, the department name, and the number of managers of
departments with more than 1 manager.
SQL: SELECT accounts.customer_id, customers.customer_first_name, customers.
customer_last_name, COUNT(*) FROM accounts JOIN customers ON accounts.
customer_id = customers.customer_id GROUP BY accounts.customer_id
Execution:
| 3 | Joesph | Schaefer | 1 |
| 6 | Vesta | Leuschke | 1 |
Answer: The execution of the SQL query above would return a table with 4
columns. The first column, "accounts.customer_id" would contain the customer
ID. The second column, "customers.customer_first_name" would contain the
customer’s first name. The third column, "customers.customer_last_name"
would contain the customer’s last name. The fourth column, "COUNT(*)" would
contain the number of accounts. With "accounts JOIN customers", the table
would contain the data about accounts and customers. With "GROUP BY accounts
.customer_id", the table would be grouped by customer ID. So the SQL query
returns a table with 4 columns, the customer ID, the customer’s first name,
the customer’s last name, and the number of accounts of each customer.
SQL: SELECT * FROM people
Execution:
| 1 | M | Hubert Henno | 06.10.1976 | 188.0 | 83.0 |
| 2 | M | Dominique Daquin | 10.11.1972 | 197.0 | 85.0 |
Answer: The execution of the SQL query above would return a table with 6
columns. "SELECT *" returns all columns. So the SQL query returns all
information of people.
SQL: SELECT name, city, country, elevation FROM airports WHERE city = "New
York"
Execution:
| La Guardia Airport | New York | United States | 21 |
| John F Kennedy International Airport | New York | United States | 13 |
49

Answer: The execution of the SQL query above would return a table with 4
columns. The first column, "name" would contain the airport name. The second
column, "city" would contain the city name. The third column, "country"
would contain the country name. The fourth column, "elevation" would contain
the elevation. With "WHERE city = ’New York’", the table filters the
records to only include airports in New York. So the SQL query returns a
table with 4 columns, the airport name, the city name, the country name, and
the elevation of airports in New York.
SQL: SELECT AVG(weight), MIN(weight), sex FROM people GROUP BY sex
Execution:
| 92.0 | 90.0 | M |
| 86.71428571428571 | 82.0 | F |
Answer: The execution of the SQL query above would return a table with 3
columns. The first column, "AVG(weight)" would contain the average weight.
The second column, "MIN(weight)" would contain the minimum weight. The third
column, "sex" would contain the gender. With "GROUP BY sex", the table
would be grouped by gender. So the SQL query returns a table with 3 columns,
the average weight, the minimum weight, and the gender of people for each
gender.
SQL: SELECT COUNT(*), city FROM employees WHERE title = "IT Staff" GROUP BY
city
Execution:
| 2 | Lethbridge |
Answer: The execution of the SQL query above would return a table with 2
columns. The first column, "COUNT(*)" would contain the number of employees.
The second column, "city" would contain the city name. With "WHERE title =
’IT Staff’", the table filters the records to only include employees with
the title "IT Staff". With "GROUP BY city", the table would be grouped by
city. So the SQL query returns a table with 2 columns, the number of
employees with the title "IT Staff", and the city name for each city.
SQL: SELECT customers.customer_name FROM customers JOIN orders ON customers.
customer_id = orders.customer_id WHERE orders.order_status = "On Road" AND
orders.order_status = "Shipped"
Execution: None
Answer: The execution of the SQL query above would return an empty table.
The first column, "customers.customer_name" would contain the customer name.
With "customers JOIN orders", the table would contain the data about
customers with orders. In the WHERE clause, with "orders.order_status = ’On
Road’", the table filters the records to only include customers who have
order status "On Road". With "orders.order_status = ’Shipped’", the table
filters the records to only include customers who have order status "Shipped
". With "WHERE orders.order_status = ’On Road’ AND orders.order_status = ’
Shipped’", the table filters the records to only include customers who have
both "On Road" and "Shipped" as order status at the same time. This is not
possible, since the two are mutually exclusive. So the SQL query returns an
empty table, because the "WHERE" clause contains mutually exclusive
conditions.
SQL: SELECT origin FROM flight WHERE destination = "HONO"
Execution: None
Answer: The execution of the SQL query above would return an empty table.
The first column, "origin" would contain the origin of flights. With "WHERE
destination = ’HONO’", the table filters the records to only include flights
whose destination is "HONO". So the SQL query returns an empty table.
<insert the new SQL here>
50

B
Code Translation
B.1
Baseline Prompt (3-shot)
The prompt for generating the initial Python translation is taken from [13]. We set temperature
τ = 0.8 as in [13].
Translate the following C++ program into Python
[code]
[c++]
int add_1_to_a_given_number ( int x ) {
int m = 1;
while ( x & m ) {
x = x ^ m;
m <<= 1;
}
x = x ^ m;
return x;
}
[python]
def add_1_to_a_given_number(x):
m = 1
while (x & m):
x = (x ^ m)
m <<= 1
x = (x ^ m)
return x
[c++]
unsigned int program_for_factorial_of_a_number ( unsigned int n ) {
if ( n == 0 ) return 1;
return n * program_for_factorial_of_a_number ( n - 1 );
}
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 1) or (n == 0)) else (n *
program_for_factorial_of_a_number((n - 1))))
[c++]
long long int sum_pairwise_products ( int n ) {
long long int sum = 0;
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ ) sum = sum + i * j;
return sum;
}
[python]
def sum_pairwise_products(n):
sm = 0
for i in range(1, (n + 1)):
for j in range(i, (n + 1)):
sm = (sm + (i * j))
return sm
[c++]
<insert C++ program here>
[python]
51

B.2
Baseline + Expl. Prompt (3-shot)
Explain the code line by line, and then translate the following C++ program
into Python
[c++]
int add_1_to_a_given_number ( int x ) {
int m = 1;
while ( x & m ) {
x = x ^ m;
m <<= 1;
}
x = x ^ m;
return x;
}
[/c++]
[explanation]
The code is an implementation of adding 1 to a given number.
int m = 1
Using the variable m as a mask, the initial value of m is 1.
while ( x & m ) {
x = x ^ m;
m <<= 1;
}
In the while loop, if the current digit of the given number is 1, then it
will be flipped to 0, and the mask will be shifted to the next digit. This
iteration will be executed until the first 0 of the number is met.
x = x ^ m;
The first 0 will be flipped to 1. Thus, 1 will be added to the given number.
return x;
Finally, the function returns the incremented number.
[/explanation]
[python]
def add_1_to_a_given_number(x):
m = 1
while (x & m):
x = (x ^ m)
m <<= 1
x = (x ^ m)
return x
[/python]
[c++]
unsigned int program_for_factorial_of_a_number ( unsigned int n ) {
if ( n == 0 ) return 1;
return n * program_for_factorial_of_a_number ( n - 1 );
}
[/c++]
[explanation]
The code is an implementation of calculating the factorial of a number.
if ( n == 0 ) return 1;
The function is defined recursively. When the given number is equal to 0,
the result of the factorial is 1.
return n * program_for_factorial_of_a_number ( n - 1 );
Otherwise, the result of the factorial is the product of the given number
and the (given number minus 1) factorial.
[/explanation]
[python]
def program_for_factorial_of_a_number(n):
52

return (1 if ((n == 1) or (n == 0)) else (n *
program_for_factorial_of_a_number((n - 1))))
[/python]
[c++]
long long int sum_pairwise_products ( int n ) {
long long int sum = 0;
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ ) sum = sum + i * j;
return sum;
}
[/c++]
[explanation]
The code is an implementation of summing the products of all the possible
pairs.
long long int sum = 0;
The variable sum is used to record the result.
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ )
There are two nested loops. The outer loop iterates until i (the index of
the first number of a pair) is equal to the given number. The inner loop
iterates until j (the index of the second number of the pair) is equal to
the given number.
sum = sum + i * j;
When the two loops are executed, the product of the pair will be calculated
and then added to the variable sum.
return sum;
Finally, the function returns the sum.
[/explanation]
[python]
def sum_pairwise_products(n):
sm = 0
for i in range(1, (n + 1)):
for j in range(i, (n + 1)):
sm = (sm + (i * j))
return sm
[/python]
[c++]
<insert C++ program here>
[/c++]
[explanation]
B.3
Simple Feedback Prompt (2-shot)
Below are C++ programs with incorrect Python translations. Correct the
translations using the provided feedback.
[c++]
unsigned int program_for_factorial_of_a_number ( unsigned int n ) {
if ( n == 0 ) return 1;
return n * program_for_factorial_of_a_number ( n - 1 );
53

}
[/c++]
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 1)) else (n * program_for_factorial_of_a_number((n -
1))))
[/python]
The above Python translation does not do the same thing as the C++ code.
Correct the Python translation.
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 0)) else (n * program_for_factorial_of_a_number((n -
1))))
[/python]
[c++]
long long int sum_pairwise_products ( int n ) {
long long int sum = 0;
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ ) sum = sum + i * j;
return sum;
}
[/c++]
[python]
def sum_pairwise_products(n):
sum = 0
for i in range(n):
for j in range(i,((n + 1))):
sum = (sum + (i * j))
return sum
[/python]
The above Python translation does not do the same thing as the C++ code.
Correct the Python translation.
[python]
def sum_pairwise_products(n):
sum = 0
for i in range(1,((n + 1))):
for j in range(i,((n + 1))):
sum = (sum + (i * j))
return sum
[/python]
[c++]
<insert C++ program here>
[/c++]
[python]
<insert original Python translation here>
[/python]
The above Python translation does not do the same thing as the C++ code.
Correct the Python translation.
[python]
B.4
Unit Test Feedback Prompt (2-shot)
Below are C++ programs with incorrect Python translations. Correct the
translations using the provided feedback.
[c++]
unsigned int program_for_factorial_of_a_number ( unsigned int n ) {
54

if ( n == 0 ) return 1;
return n * program_for_factorial_of_a_number ( n - 1 );
}
[/c++]
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 1)) else (n * program_for_factorial_of_a_number((n -
1))))
[/python]
The Python translation does not do the same thing as the C++ code. These are
the results of one failed unit test that tests whether the Python
translation’s outputs match the C++ program’s outputs:
Failed: assert program_for_factorial_of_a_number(0) == 1
Actual Result: RecursionError: maximum recursion depth exceeded in
comparison
Correct the Python translation.
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 0)) else (n * program_for_factorial_of_a_number((n -
1))))
[/python]
[c++]
long long int sum_pairwise_products ( int n ) {
long long int sum = 0;
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ ) sum = sum + i * j;
return sum;
}
[/c++]
[python]
def sum_pairwise_products(n):
sum = 0
for i in range(n):
for j in range(i,((n + 1))):
sum = (sum + (i * j))
return sum
[/python]
The Python translation does not do the same thing as the C++ code. These are
the results of one failed unit test that tests whether the Python
translation’s outputs match the C++ program’s outputs:
Failed: assert sum_pairwise_products(3) == 25
Actual Result: 16
Correct the Python translation.
[python]
def sum_pairwise_products(n):
sum = 0
for i in range(1,((n + 1))):
for j in range(i,((n + 1))):
sum = (sum + (i * j))
return sum
[/python]
[c++]
<insert C++ program here>
[/c++]
[python]
<insert original Python translation here>
[/python]
55

B.5
Unit Test + Expl. Feedback Prompt (2-shot)
Below are C++ programs with incorrect Python translations. Explain the
original code, then explain the translations line by line and correct them
using the provided feedback.
[c++]
unsigned int program_for_factorial_of_a_number ( unsigned int n ) {
if ( n == 0 ) return 1;
return n * program_for_factorial_of_a_number ( n - 1 );
}
[/c++]
[explanation]
The code is an implementation of calculating the factorial of a number.
if ( n == 0 ) return 1;
The function is defined recursively. When the given number is equal to 0,
the result of the factorial is 1.
return n * program_for_factorial_of_a_number ( n - 1 );
Otherwise, the result of the factorial is the product of the given number
and the (given number minus 1) factorial.
[/explanation]
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 1)) else (n * program_for_factorial_of_a_number((n -
1))))
[/python]
Explain the Python translation line by line.
[explanation]
The code is an implementation of calculating the factorial of a number.
return (1 if ((n == 1)) else (n * program_for_factorial_of_a_number((n - 1))
))
The function is defined recursively. When the given number is equal to 1,
the result of the factorial is 1. Otherwise, the result of the factorial is
the product of the given number and the (given number minus 1) factorial.
[/explanation]
The Python translation does not do the same thing as the C++ code. These are
the results of one failed unit test that tests whether the Python
translation’s outputs match the C++ program’s outputs:
Failed: assert program_for_factorial_of_a_number(0) == 1
Actual Result: RecursionError: maximum recursion depth exceeded in
comparison
Correct the translation.
[python]
def program_for_factorial_of_a_number(n):
return (1 if ((n == 1) or (n == 0)) else (n *
program_for_factorial_of_a_number((n - 1))))
[/python]
[c++]
long long int sum_pairwise_products ( int n ) {
long long int sum = 0;
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ ) sum = sum + i * j;
return sum;
}
[/c++]
56

[explanation]
The code is an implementation of summing the products of all the possible
pairs.
long long int sum = 0;
The variable sum is used to record the result.
for ( int i = 1;
i <= n;
i ++ ) for ( int j = i;
j <= n;
j ++ )
There are two nested loops. The outer loop iterates until i (the index of
the first number of a pair) is equal to the given number. The inner loop
iterates until j (the index of the second number of the pair) is equal to
the given number.
sum = sum + i * j;
When the two loops are executed, the product of the pair will be calculated
and then added to the variable sum.
return sum;
Finally, the function returns the sum.
[/explanation]
[python]
def sum_pairwise_products(n):
sum = 0
for i in range(n):
for j in range(i,((n + 1))):
sum = (sum + (i * j))
return sum
[/python]
Explain the Python translation line by line.
[explanation]
The code is an implementation of summing the products of all the possible
pairs.
sum = 0;
The variable sum is used to record the result.
for i in range(n):
for j in range(i,((n + 1))):
There are two nested loops. The outer loop iterates from i = 0 until i is
equal to n-1. The inner loop iterates from j = i until j is equal to n.
sum = (sum + (i * j))
When the two loops are executed, the product of the pair will be calculated
and then added to the variable sum.
return sum
Finally, the function returns the sum.
[/explanation]
The Python translation does not do the same thing as the C++ code. These are
the results of one failed unit test that tests whether the Python
translation’s outputs match the C++ program’s outputs:
Failed: assert sum_pairwise_products(3) == 25
Actual Result: 16
Correct the translation.
[python]
def sum_pairwise_products(n):
sm = 0
for i in range(1, (n + 1)):
for j in range(i, (n + 1)):
57

sm = (sm + (i * j))
return sm
[/python]
[c++]
<insert C++ program here>
[/c++]
[explanation]
<insert explanation of C++ program here>
[/explanation]
[python]
<insert original Python translation here>
[/python]
C
Text-to-Python Generation
C.1
Baseline Prompt (3-shot)
The prompt for generating initial Python code is taken from [37].
# Write Python function to complete the task and pass the assertion tests.
### Task Start ###
# These are the assertions for your function:
assert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)
""" Write a function to find the similar elements from the given two tuple
lists. """
def similar_elements(test_tup1, test_tup2):
res = tuple(set(test_tup1) & set(test_tup2))
return (res)
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert is_not_prime(2) == False
""" Write a python function to identify non-prime numbers. """
import math
def is_not_prime(n):
result = False
for i in range(2,int(math.sqrt(n)) + 1):
if n % i == 0:
result = True
return result
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75,
65]
""" Write a function to find the largest integers from a given list of
numbers using heap queue algorithm. """
import heapq as hq
def heap_queue_largest(nums,n):
largest_nums = hq.nlargest(n, nums)
return largest_nums
### Task End ###
58

### Task Start ###
# These are the assertions for your function:
<insert assertions and problem description here>
C.2
Simple Feedback Prompt (6-shot)
# Write Python function to complete the task and pass the assertion tests.
### Task Start ###
# These are the assertions for your function:
assert count_ways(2) == 3
""" Write a function to find the number of ways to fill it with 2 x 1
dominoes for the given 3 x n board. """
def count_ways(n):
if n == 0:
return 1
if n == 1:
return 1
if n == 2:
return 3
return count_ways(n-1) + count_ways(n-2)
Feedback: The code above is wrong. Please fix it.
def count_ways(n):
A = [0] * (n + 1)
B = [0] * (n + 1)
A[0] = 1
A[1] = 0
B[0] = 0
B[1] = 1
for i in range(2, n+1):
A[i] = A[i - 2] + 2 * B[i - 1]
B[i] = A[i - 1] + B[i - 2]
return A[n]
Feedback: The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert differ_At_One_Bit_Pos(15,8) == False
""" Write a python function to check whether the two numbers differ at one
bit position only or not. """
def differ_At_One_Bit_Pos(lhs,rhs):
if (lhs - rhs) == 0 or (lhs - rhs) == 1:
return True
return False
Feedback: The code above is wrong. Please fix it.
def differ_At_One_Bit_Pos(a,b):
x = a ^ b
return x and (not(x & (x - 1)))
59

Feedback: The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert find_char_long(’Please move back to stream’) == [’Please’, ’move’, ’
back’, ’stream’]
""" Write a function to find all words which are at least 4 characters long
in a string by using regex. """
def find_char_long(text):
return (re.findall(r"\b\w{4,}\b", text))
Feedback: The code above is wrong. Please fix it.
import re
def find_char_long(text):
return (re.findall(r"\b\w{4,}\b", text))
Feedback: The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert square_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[1, 4, 9, 16, 25, 36,
49, 64, 81, 100]
""" Write a function to find squares of individual elements in a list using
lambda function. """
def square_nums(nums):
square_nums = list(map(lambda x: x ** 2, nums))
return square_nums
Feedback: The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert find_Rotations("aaaa") == 1
""" Write a python function to find the minimum number of rotations required
to get the same string. """
def find_Rotations(s):
if len(s) == 1:
return 1
elif len(s) == 0:
return 0
else:
l = len(s)
min = len(s)
for i, c in enumerate(s):
if c == s[0]:
temp = i
if temp < min:
min = temp
return min
Feedback: The code above is wrong. Please fix it.
60

def find_Rotations(s):
n = len(s)
for i in range(1, n + 1):
if s[i:n] + s[0:i] == s:
return i
return n
Feedback: The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert small_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],2)==[10,20]
"""
Write a function to get the n smallest items from a dataset. """
def small_nnum(lst,n):
lst = sorted(lst)
lst = lst[:n]
return lst
Feedback: The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
<insert assertions and problem description here>
<insert original code here>
C.3
Unit Test Feedback Prompt (6-shot)
# Write Python function to complete the task and pass the assertion tests.
### Task Start ###
# These are the assertions for your function:
assert count_ways(2) == 3
""" Write a function to find the number of ways to fill it with 2 x 1
dominoes for the given 3 x n board. """
def count_ways(n):
if n == 0:
return 1
if n == 1:
return 1
if n == 2:
return 3
return count_ways(n-1) + count_ways(n-2)
Feedback: With the above function, count_ways(2) == 3. The assertion is "
assert count_ways(2) == 3". So the code passes the assertion. The code above
is wrong. Please fix it.
def count_ways(n):
A = [0] * (n + 1)
B = [0] * (n + 1)
A[0] = 1
A[1] = 0
61

B[0] = 0
B[1] = 1
for i in range(2, n+1):
A[i] = A[i - 2] + 2 * B[i - 1]
B[i] = A[i - 1] + B[i - 2]
return A[n]
Feedback: With the above function, count_ways(2) = 3. The assertion is "
assert count_ways(2) == 3". So the code passes the assertion. The code above
is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert differ_At_One_Bit_Pos(15,8) == False
""" Write a python function to check whether the two numbers differ at one
bit position only or not. """
def differ_At_One_Bit_Pos(lhs,rhs):
if (lhs - rhs) == 0 or (lhs - rhs) == 1:
return True
return False
Feedback: With the above function, differ_At_One_Bit_Pos(15,8) == False. The
assertion is "assert differ_At_One_Bit_Pos(15,8) == False". So the code
passes the assertion. The code above is wrong. Please fix it.
def differ_At_One_Bit_Pos(a,b):
x = a ^ b
return x and (not(x & (x - 1)))
Feedback: With the above function, differ_At_One_Bit_Pos(15,8) == False. The
assertion is "assert differ_At_One_Bit_Pos(15,8) == False". So the code
passes the assertion. The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert find_char_long(’Please move back to stream’) == [’Please’, ’move’, ’
back’, ’stream’]
""" Write a function to find all words which are at least 4 characters long
in a string by using regex. """
def find_char_long(text):
return (re.findall(r"\b\w{4,}\b", text))
Feedback: With the above function, find_char_long(’Please move back to
stream’) returns the following error:
"""
NameError: name ’re’ is not defined
"""
So the code does not pass the assertion. Please fix it.
import re
def find_char_long(text):
return (re.findall(r"\b\w{4,}\b", text))
Feedback: With the above function, find_char_long(’Please move back to
stream’) == [’Please’, ’move’, ’back’, ’stream’]. The assertion is "assert
find_char_long(’Please move back to stream’) == [’Please’, ’move’, ’back’, ’
stream’]". So the code passes the assertion. The code above is correct.
62

### Task End ###
### Task Start ###
# These are the assertions for your function:
assert square_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[1, 4, 9, 16, 25, 36,
49, 64, 81, 100]
""" Write a function to find squares of individual elements in a list using
lambda function. """
def square_nums(nums):
square_nums = list(map(lambda x: x ** 2, nums))
return square_nums
Feedback: With the above function, square_nums([1, 2, 3, 4, 5, 6, 7, 8, 9,
10])==[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]. The assertion is "assert
square_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[1, 4, 9, 16, 25, 36, 49, 64,
81, 100]". So the code passes the assertion. The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert find_Rotations("aaaa") == 1
""" Write a python function to find the minimum number of rotations required
to get the same string. """
def find_Rotations(s):
if len(s) == 1:
return 1
elif len(s) == 0:
return 0
else:
l = len(s)
min = len(s)
for i, c in enumerate(s):
if c == s[0]:
temp = i
if temp < min:
min = temp
return min
Feedback: With the above function, find_Rotations("aaaa") == 0. The
assertion is "find_Rotations("aaaa") == 1". So the code does not pass the
assertion. Please fix it.
def find_Rotations(s):
n = len(s)
for i in range(1, n + 1):
if s[i:n] + s[0:i] == s:
return i
return n
Feedback: With the above function, find_Rotations("aaaa") == 1. The
assertion is "find_Rotations("aaaa") == 1". So the code passes the assertion
. The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert small_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],2)==[10,20]
63

"""
Write a function to get the n smallest items from a dataset. """
def small_nnum(lst,n):
lst = sorted(lst)
lst = lst[:n]
return lst
Feedback: With the above function, small_nnum([10, 20, 50, 70, 90, 20, 50,
40, 60, 80, 100],2)==[10,20]. The assertion is "small_nnum([10, 20, 50, 70,
90, 20, 50, 40, 60, 80, 100],2)==[10,20]". So the code passes the assertion.
The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
<insert assertions and problem description here>
<insert original code here>
C.4
Unit Test + Expl. Feedback Prompt (3-shot)
# Write Python function to complete the task and pass the assertion tests.
### Task Start ###
# These are the assertions for your function:
assert find_char_long(’Please move back to stream’) == [’Please’, ’move’, ’
back’, ’stream’]
""" Write a function to find all words which are at least 4 characters long
in a string by using regex. """
def find_char_long(text):
return (re.findall(r"\b\w{4,}\b", text))
Here is a line-by-line explanation of the code:
‘def find_char_long(text):‘: This line defines a function named ‘
find_char_long‘ that takes a single argument, ‘text‘. ‘text‘ represents the
string whose words are to be extracted.
‘return (re.findall(r"\b\w{4,}\b", text))‘: This line uses the ‘re.findall()
‘ function to extract all words from the input string that are at least 4
characters long. The regular expression ‘r"\b\w{4,}\b"‘ matches all words
that are at least 4 characters long. The ‘\b‘ matches the boundary between a
word character and a non-word character. The ‘\w‘ matches any word
character (a letter, digit, or underscore). The ‘{4,}‘ matches the preceding
element at least 4 times. The ‘\b‘ matches the boundary between a word
character and a non-word character.
Feedback: With the above function, find_char_long(’Please move back to
stream’) returns the following error:
"""
NameError: name ’re’ is not defined
"""
So the code does not pass the assertion. Please fix it.
import re
def find_char_long(text):
return (re.findall(r"\b\w{4,}\b", text))
Here is a line-by-line explanation of the code:
64

‘import re‘: This line imports the ‘re‘ module.
‘def find_char_long(text):‘: This line defines a function named ‘
find_char_long‘ that takes a single argument, ‘text‘. ‘text‘ represents the
string whose words are to be extracted.
‘return (re.findall(r"\b\w{4,}\b", text))‘: This line uses the ‘re.findall()
‘ function to extract all words from the input string that are at least 4
characters long. The regular expression ‘r"\b\w{4,}\b"‘ matches all words
that are at least 4 characters long. The ‘\b‘ matches the boundary between a
word character and a non-word character. The ‘\w‘ matches any word
character (a letter, digit, or underscore). The ‘{4,}‘ matches the preceding
element at least 4 times. The ‘\b‘ matches the boundary between a word
character and a non-word character.
Feedback: With the above function, find_char_long(’Please move back to
stream’) == [’Please’, ’move’, ’back’, ’stream’]. The assertion is "assert
find_char_long(’Please move back to stream’) == [’Please’, ’move’, ’back’, ’
stream’]". So the code passes the assertion. The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
assert count_ways(2) == 3
""" Write a function to find the number of ways to fill it with 2 x 1
dominoes for the given 3 x n board. """
def count_ways(n):
if n == 0:
return 1
if n == 1:
return 1
if n == 2:
return 3
return count_ways(n-1) + count_ways(n-2)
Here is a line-by-line explanation of the code:
‘def count_ways(n):‘: This line defines a function named ‘count_ways‘ that
takes a single argument, ‘n‘. ‘n‘ represents the width of the 3 x n board.
‘if n == 0:‘: This line checks if n is equal to 0. In other words, it checks
if the width of the board is 0. If the width of the board is 0, there is
only one way to fill it: by not placing any dominoes.
‘return 1‘: If the condition in line 2 is true (i.e., n is 0), the function
returns 1, indicating that there is only one way to fill the 3 x 0 board.
‘if n == 1:‘: This line checks if n is equal to 1. In other words, it checks
if the width of the board is 1. A 3 x 1 board cannot be filled with 2 x 1
dominoes, so there’s only one way to fill it: by not placing any dominoes.
‘return 1‘: If the condition in line 4 is true (i.e., n is 1), the function
returns 1, indicating that there is only one way to fill the 3 x 1 board.
‘if n == 2:‘: This line checks if n is equal to 2. In other words, it checks
if the width of the board is 2. A 3 x 2 board can be filled with 2 x 1
dominoes in three ways: (1) three horizontal dominoes, (2) one vertical
domino and two horizontal dominoes, and (3) two vertical dominoes and one
horizontal domino.
‘return 3‘: If the condition in line 6 is true (i.e., n is 2), the function
returns 3, indicating that there are three ways to fill the 3 x 2 board.
65

‘return count_ways(n-1) + count_ways(n-2)‘: If none of the conditions in
lines 2, 4, and 6 are true, this line is executed. It uses a recursive
approach to calculate the number of ways to fill the 3 x n board. The
function calls itself twice: once with the argument n-1 and once with the
argument n-2. The results of these two function calls are added together and
returned as the final result.
Feedback: With the above function, count_ways(2) == 3. The assertion is "
assert count_ways(2) == 3". So the code passes the assertion. The code above
is wrong. Please fix it.
def count_ways(n):
A = [0] * (n + 1)
B = [0] * (n + 1)
A[0] = 1
A[1] = 0
B[0] = 0
B[1] = 1
for i in range(2, n+1):
A[i] = A[i - 2] + 2 * B[i - 1]
B[i] = A[i - 1] + B[i - 2]
return A[n]
Here is a line-by-line explanation of the code:
‘def count_ways(n):‘: This line defines a function named ‘count_ways‘ that
takes a single argument, ‘n‘. ‘n‘ represents the width of the 3 x n board.
‘A = [0] * (n + 1) and B = [0] * (n + 1)‘: These lines create two lists, A
and B, each of length n + 1 and initialized with zeros. A[i] and B[i] will
store the number of ways to tile the 3 x i board while following specific
rules for the last column (explained below).
‘A[0] = 1, A[1] = 0, B[0] = 0, and B[1] = 1‘: These lines initialize the
base cases for the lists A and B. A[0] and B[1] are set to 1, while A[1] and
B[0] are set to 0. A[i] represents the number of ways to tile a 3 x i board
with the last column fully filled, and B[i] represents the number of ways
to tile a 3 x i board with the last column filled in the form of an L-shape.
‘for i in range(2, n + 1):‘: This line starts a for loop that iterates from
2 to n, inclusive.
‘A[i] = A[i - 2] + 2 * B[i - 1]‘: This line calculates the number of ways to
tile a 3 x i board with the last column fully filled by either placing two
horizontal dominoes in the last column (which corresponds to A[i - 2]) or by
placing a horizontal and a vertical domino in the last column (which
corresponds to 2 * B[i - 1]).
‘B[i] = A[i - 1] + B[i - 2]‘: This line calculates the number of ways to
tile a 3 x i board with the last column filled in the form of an L-shape by
either placing a vertical domino and a horizontal domino in the last column
(which corresponds to A[i - 1]) or by placing three horizontal dominoes in
the last column (which corresponds to B[i - 2]).
‘return A[n]‘: This line returns the number of ways to tile the 3 x n board
with 2 x 1 dominoes, which is stored in A[n].
Feedback: With the above function, count_ways(2) = 3. The assertion is "
assert count_ways(2) == 3". So the code passes the assertion. The code above
is correct.
### Task End ###
66

### Task Start ###
# These are the assertions for your function:
assert find_Rotations("aaaa") == 1
""" Write a python function to find the minimum number of rotations required
to get the same string. """
def find_Rotations(s):
if len(s) == 1:
return 1
elif len(s) == 0:
return 0
else:
l = len(s)
min = len(s)
for i, c in enumerate(s):
if c == s[0]:
temp = i
if temp < min:
min = temp
return min
Here is a line-by-line explanation of the code:
‘def find_Rotations(s):‘: This line defines a function named ‘find_Rotations
‘ that takes a single argument, ‘s‘. ‘s‘ represents the string whose minimum
number of rotations is to be calculated.
‘if len(s) == 1:‘: This line checks if the length of the input string is 1.
the minimum number of rotations required to get the same string is 1.
‘return 1‘: If the condition in line 2 is true (i.e., length of the input
string is 1), the function returns 1.
‘elif len(s) == 0:‘: This line checks if the length of the input string is
0. If the length of the input string is 0, the minimum number of rotations
required to get the same string is 0.
‘return 0‘: If the condition in line 4 is true (i.e., length of the input
string is 0), the function returns 0.
‘else:‘: If the conditions in lines 2 and 4 are not met (i.e., length of the
input string is neither 0 nor 1), this line is executed.
‘l = len(s)‘: This line stores the length of the input string in the
variable ‘l‘.
‘min = len(s)‘: This line stores the length of the input string in the
variable ‘min‘.
‘for i, c in enumerate(s):‘: This line starts a for loop that iterates over
the input string.
‘if c == s[0]:‘: This line checks if the current character is equal to the
first character of the input string.
‘temp = i‘: This line stores the index of the current character in the
variable ‘temp‘.
‘if temp < min:‘: This line checks if the index of the current character is
less than the value stored in the variable ‘min‘.
‘min = temp‘: If the condition in line 13 is true (i.e., index of the
current character is less than the value stored in the variable ‘min‘), this
67

line is executed. It stores the index of the current character in the
variable ‘min‘.
‘return min‘: This line returns the minimum number of rotations required to
get the same string.
Feedback: With the above function, find_Rotations("aaaa") == 0. The
assertion is "find_Rotations("aaaa") == 1". So the code does not pass the
assertion. Please fix it.
def find_Rotations(s):
n = len(s)
for i in range(1, n + 1):
if s[i:n] + s[0:i] == s:
return i
return n
Here is a line-by-line explanation of the code:
‘def find_Rotations(s):‘: This line defines a function named ‘find_Rotations
‘ that takes a single argument, ‘s‘. ‘s‘ represents the string whose minimum
number of rotations is to be calculated.
‘n = len(s)‘: This line stores the length of the input string in the
variable ‘n‘.
‘for i in range(1, n + 1):‘: This line starts a for loop that iterates from
1 to n, inclusive. The loop variable is i, which represents the number of
rotations being tested in each iteration.
‘if s[i:n] + s[0:i] == s:‘: This line checks if the string resulting from
the concatenation of two substrings ‘s[i:n]‘ and ‘s[0:i]‘ is equal to the
original string ‘s‘. The first substring ‘s[i:n]‘ is a slice of the string
from index ‘i‘ to the end, and the second substring ‘s[0:i]‘ is a slice from
the beginning of the string up to index ‘i-1‘. This operation essentially
rotates the string by ‘i‘ positions.
‘return i‘: If the condition in line 5 is true (i.e., the string resulting
from the concatenation of two substrings ‘s[i:n]‘ and ‘s[0:i]‘ is equal to
the original string ‘s‘), this line is executed. It returns the number of
rotations required to get the same string.
‘return n‘: This line returns the length of the string n. This means that
the minimum number of rotations required to get the same string is equal to
the length of the string, indicating that the string cannot be rotated to
achieve the same string.
Feedback: With the above function, find_Rotations("aaaa") == 1. The
assertion is "find_Rotations("aaaa") == 1". So the code passes the assertion
. The code above is correct.
### Task End ###
### Task Start ###
# These are the assertions for your function:
<insert assertions and problem description here>
<insert original code here>
68

