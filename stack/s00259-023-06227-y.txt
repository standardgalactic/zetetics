Vol:.(1234567890)
European Journal of Nuclear Medicine and Molecular Imaging (2023) 50:2248–2249
https://doi.org/10.1007/s00259-023-06227-y
1 3
LETTER TO THE EDITOR
Large language models (LLM) and ChatGPT: a medical student 
perspective
Arosh S. Perera Molligoda Arachchige1
Received: 9 March 2023 / Accepted: 4 April 2023 / Published online: 13 April 2023 
© The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2023
Dear Sir,
I read with great interest the Editorial by Dr. Alberts et al. 
which discusses an issue that is currently of immense impor-
tance to the medical community and is worth discussing [1]. 
As a 5th year medical student at Humanitas University in 
Milan, I would like to share my opinion regarding the rapidly 
evolving field of AI-powered large language models.
Even though most of the ideas expressed by the authors 
are related to its impact on nuclear medicine, I think their 
ideas are equally applicable to the field of medical educa-
tion. The fact that such AI tools can make the research and 
publication process faster is undoubtedly one clear advan-
tage. This will allow researchers to spend more time on the 
research process rather than for scientific writing. However, 
since currently academic tenure is based on the H index 
(calculated by counting the number of publications for which 
an author has been cited by other authors at least that same 
number of times), if it is used by academics to simply get 
published (solely for the sake of academic tenure), it would 
likely overwhelm journal editors and would produce content 
that will be the result of AI with minimum involvement of 
human intelligence. We are not yet sure of what impact this 
will have on future research when such papers overflow into 
databases like PubMed.
The authors have also referred to incidences where Chat-
GPT has been added as an author in journal articles [1]. I 
personally think that it just seems to be more suitable to 
be acknowledged in the acknowledgement section. Simi-
larly, the authors refer to AI-generated letters to the edi-
tor and comments. But I wonder what the purpose of such 
AI-generated letters or comments would be? Can it directly 
relate to human thinking? Since ChatGPT works based on an 
old dataset and will most likely lack the novelty and variabil-
ity of human thought, in particular it might not encompass 
the opinions of new authors.
Since recently, AI tools to detect AI-generated text are 
under development, such as DetectGPT, AI text classifier 
(developed by OpenAI itself, the creator of ChatGPT), 
GPTZero, Originality.ai, and Copyleaks. However, they are 
not yet sufficiently accurate in performing this task [2, 3]. 
There are even instances where professors have used such 
LLM detection softwares and have caught students cheating 
on essays with ChatGPT [4].
The authors further discuss the ability of ChatGPT to 
pass all 3 steps of the United States Medical Licensing 
Exam (USMLE) [1]. To me this looks something quite 
obvious since it involves solving clinical problems by grasp-
ing the keywords and by using the AI-trained reasoning. 
More importantly, AI does not have the limitations seen in 
humans. It can easily store and extract information, no mat-
ter how large that quantity of data is. On the contrary, I 
believe that ChatGPT possibly could help academics in cre-
ating examinations for medical schools and residency pro-
grams, and could prove itself to be a safer application of it.
I have come across numerous statements similar to Hin-
ton’s controversial statement “we stop training radiologists 
now.” Such statements have the potential to cause very detri-
mental impacts on healthcare, aggravating the already exist-
ing shortage of radiologists in countries like the UK in my 
opinion since it tends to discourage medical students from 
pursuing these specialties due to the fear of being replaced 
by bots, and ultimately wasting the vast amount of effort 
they have put into completing their specialty training [5–7].
In Italy, medical students are required to defend a thesis 
for graduating as Doctor of Medicine (MD). The develop-
ment of LLM tools like ChatGPT should make us rethink the 
whole point of doing a dissertation when the vast majority 
This article is part of the Topical Collection on Advanced Image 
Analyses (Radiomics and Artificial Intelligence).
 *	 Arosh S. Perera Molligoda Arachchige 
	
aroshshavinda.pereramolligodaarachchige@st.hunimed.eu
1	
Department of Biomedical Sciences, Humanitas University, 
Milan, Italy

2249
European Journal of Nuclear Medicine and Molecular Imaging (2023) 50:2248–2249	
1 3
of the work is done using it, the mostly likely situation in 
future.
The authors have clearly highlighted the limitations that 
this technology is currently facing [1]. I think that further 
improvements could be made to these systems while also 
focusing on the effects it might have on our economies due 
to unemployment, etc. and we will accordingly have to 
change our education systems so that students will be trained 
for the vigilance of AI and for research and development of 
similar AI technologies rather than learning to do the same 
thing that a machine does.
Declarations 
Conflict of interest  The author declares no competing interests.
References
	 1.	 Alberts I, Mercolli L, Pyka T, et al. Large language models 
(LLM) and ChatGPT: what will the impact on nuclear medicine 
be? Eur J Nucl Med Mol Imaging. 2023. https://​doi.​org/​10.​1007/​
s00259-​023-​06172-w.
	 2.	 Lee, L. From deepfakes to Bing’s chatbot, AI-generated content 
is everywhere. Here’s how to spot it. Business Insider. Retrieved 
March 9, 2023, from https://​www.​busin​essin​sider.​com/​how-​to-​
detect-​ai-​gener​ated-​conte​nt-​text-​chatg​pt-​deepf​ake-​videos-​2023-
3?​r=​US&​IR=T
	 3.	 Petrosyan V. (2023, February 15). AI text detection software: can 
they detect ChatGPT? Search Engine Journal. Retrieved April 3, 
2023, from https://​www.​searc​hengi​nejou​rnal.​com/​chatg​pt-​conte​
nt-​detect-​ai/​476781/
	 4.	 Nolan, B. Two professors who say they caught students cheating 
on essays with ChatGPT explain why AI plagiarism can be hard 
to prove. Business Insider. Retrieved March 9, 2023, from https://​
www.​busin​essin​sider.​com/​chatg​pt-​essays-​colle​ge-​cheat​ing-​profe​
ssors-​caught-​stude​nts-​ai-​plagi​arism-​2023-1?​r=​US&​IR=T
	 5.	 Langlotz CP. Will artificial intelligence replace radiologists? 
Radiol Artif Intell. 2019;1:e190058. https://​doi.​org/​10.​1148/​ryai.​
20191​90058.
	 6.	 AS PereraMolligodaArachchige, A Svet. Integrating artificial 
intelligence into radiology practice: undergraduate students’ per-
spective. Eur J Nucl Med Mol Imaging. 2021;48:4133–5. https://​
doi.​org/​10.​1007/​s00259-​021-​05558-y.
	 7.	 Radiology facing a global shortage. RSNA. Retrieved March 9, 
2023, from https://​www.​rsna.​org/​news/​2022/​may/​Global-​Radio​
logist-​Short​age
Publisher's note  Springer Nature remains neutral with regard to 
jurisdictional claims in published maps and institutional affiliations.

