Constraints
https://doi.org/10.1007/s10601-023-09367-y
Optimal multivariate decision trees
Justin Boutilier1 · Carla Michini1
· Zachary Zhou1
Accepted: 21 November 2023
© The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023
Abstract
Recently, mixed-integer programming (MIP) techniques have been applied to learn optimal
decision trees. Empirical research has shown that optimal trees typically have better out-of-
sample performance than heuristic approaches such as CART. However, the underlying MIP
formulations often suffer from weak linear programming (LP) relaxations. Many existing
MIP approaches employ big-M constraints to ensure observations are routed throughout the
tree in a feasible manner. This paper introduces new MIP formulations for learning optimal
decision trees with multivariate branching rules and no assumptions on the feature types.
We ﬁrst propose a strong baseline MIP formulation that still uses big-M constraints, but
yields a stronger LP relaxation than its counterparts in the literature. We then introduce a
problem-speciﬁc class of valid inequalities called shattering inequalities. Each inequality
encodes an inclusion-minimal set of points that cannot be shattered by a multivariate split,
and in the context of a MIP formulation, the inequalities are sparse, involving at most the
number of features plus two variables. We propose a separation procedure that attempts to
ﬁnd a violated inequality given a (possibly fractional) solution to the LP relaxation; in the
case where the solution is integer, the separation is exact. Numerical experiments show that
our MIP approach outperforms two other MIP formulations in terms of solution time and
relative gap, and is able to improve solution time while remaining competitive with regards
to out-of-sample accuracy in comparison to a wider range of approaches from the literature.
Keywords Decision trees · Mixed-integer programming · Machine learning
1 Introduction
Decision trees are among the most popular techniques for interpretable machine learning
[1]. In addition to their use as a standalone method, decision trees form the foundation
B Carla Michini
michini@wisc.edu
Justin Boutilier
jboutilier@wisc.edu
Zachary Zhou
zzhou246@wisc.edu
1
Department of Industrial and Systems Engineering, University of Wisconsin-Madison, Madison, WI,
USA
123

Constraints
for several more sophisticated machine learning algorithms such as random forest [2, 3].
Although there are many ways to express a decision tree, the majority of the literature,
including this paper, focuses on binary trees. In a binary decision tree, each internal node,
referred to as a branch node, has exactly two children and observations are routed to the left
or right child node according to a branching rule. Terminal nodes in the tree are referred
to as leaf nodes and each leaf node is assigned a class k such that any observation routed
to that leaf node is classiﬁed as belonging to class k. Almost all algorithms (heuristic and
exact) that generate decision trees focus on univariate branching rules, which check if the
value of a single feature exceeds a prescribed threshold. In this work, we instead focus on
multivariate branching rules, which are separating hyperplanes checking several features at
a time. Multivariate branching rules are less easily interpretable, however they provide more
ﬂexibility than univariate branching rules, which can only resort to axis-aligned hyperplanes.
As a consequence, multivariate branching rules can yield much more compact decision trees.
In other words, even if the tests performed at the branching nodes are more complex, the total
number of tests needed to achieve a target accuracy can be dramatically smaller; see the toy
example in Fig. 1.
Related work. The problem of learning optimal decision trees is NP-hard, both in the uni-
variate and in the multivariate setting [4–7]. As a result, there exist several famous top-down
induction algorithms for learning decision trees such as CART [1] and ID3 [8]. These heuris-
tic methods do not provide any guarantee on the quality of the decision trees computed. More
recently, a number of exact approaches have been proposed that typically aim at minimizing
the training error and possibly some measure of the tree complexity.
One stream of work uses mixed-integer programming (MIP) to compute optimal decision
trees. Motivated by algorithmic advances in integer optimization, Bertsimas and Dunn [9] ﬁrst
formulated the problem of learning an optimal decision tree as a MIP. Their work spurred
a series of subsequent papers that propose a variety of MIP tools to model and solve the
problem of learning optimal decision trees [10–19]. One main advantage of MIP approaches
is their ﬂexibility: the problem objective can be easily modiﬁed to enhance feature selection
and/or tree size, and the feasible set can be modiﬁed by adding additional constraints of
practical interest [10, 12, 14, 16]. Moreover, MIP formulations can easily handle multivariate
branching rules [9, 19]. Typically, MIP formulations contain two key components: 1) a
framework to model the routing of observations through the decision tree to leaf nodes, and
2) a framework that properly constructs the tree by devising branching rules at each branch
node. Most MIP approaches employ big-M constraints to unify these two components in a
single optimization problem [9, 18, 19], but this modeling technique suffers from the fact
that big-M constraints notoriously lead to poor LP relaxations [20]. One notable exception is
Fig. 1 (a) Eight univariate branching rules are required to correctly separate the black and white observations;
(b) only one multivariate branching rule sufﬁces. For a slightly different toy dataset: (c) and (d) show how the
feature space is partitioned when using univariate and multivariate branching rules, respectively
123

Constraints
the work of Aghaei et al. [11], who consider datasets with binary features and formulate the
problem of routing observations through a ﬁxed decision tree with univariate branching rules
as a max-ﬂow problem. Thanks to these two key assumptions – having binary features and
restricting to univariate branching rules – they can avoid using big-M constraints. Moreover,
their formulation is amenable to a Benders decomposition, where the master problem is
tasked with constructing the decision tree, and the routing of observations to leaf nodes is
accomplished by solving a subproblem for each observation that adds optimality cuts to the
master. Unfortunately, their ﬂow-based approach does not generalize if we relax either of the
two key assumptions.
Other streams of work use Boolean satisﬁability (SAT) [21–26], constraint programming
(CP) [27, 28], dynamic programming (DP)/branch-and-bound [29–34], and continuous opti-
mization [35, 36] to compute optimal decision trees. These methods address the scalability
issues of general MIP methods by using a different range of techniques to explore the search
space, such as sub-sampling, branch and bound search, and caching. Some of these algorithms
are tailored to the speciﬁc structure of decision trees, which is used to speed-up computation.
However, 1) most of them assume binary features or use binarization techniques to trans-
form numerical features into binary ones in a preprocessing step, which can dramatically
increase the size of the input (causing memory problems) and is not guaranteed to preserve
optimality [37] (exceptions include [26] who compute decision trees via SAT without bina-
rization of features, and [34] who propose a branch-and-bound approach for decision trees
with continuous features); 2) many are designed and/or implemented to work only for binary
classiﬁcation (exceptions include DL8 [29], DL8.5 [30, 31], MurTree [33], and (Sparse)
Optimal Randomized Classiﬁcation Trees [35, 36]); and 3) with the exception of [35, 36],
all of them are only suited to construct decision trees with univariate branching rules.
Our contribution We ﬁrst propose a new MIP formulation for learning optimal decision
trees with multivariate branching rules and no assumptions on the feature types. Our for-
mulation employs only binary variables to (i) express how each observation is routed in
the decision tree and (ii) express the objective function as a weighed sum of the training
accuracy and the size of the tree. Moreover, we exploit the structure of decision trees and
use a geometric interpretation of the optimal decision tree problem to devise a specialized
class of valid inequalities, called shattering inequalities, which intuitively detect problematic
sub-samples of the dataset that cannot be linearly separated. We leverage these inequalities
within a Benders-like decomposition [38] to decompose our formulation into a master prob-
lem that determines how to route each observation to a leaf node, and a collection of linear
programming (LP) feasibility subproblems that certify whether, for each branch node of the
decision tree, it is possible to construct a multivariate branching rule that realizes the given
routing of observations. If it is not possible to realize the routing, then we add one of our
valid inequalities to the master problem as a feasibility cut. Each of our inequalities encodes
a minimal set of points that cannot be shattered by a multivariate branching rule and in the
context of a MIP formulation, the inequalities are sparse, with at most the number of features
plus two variables. Our approach does not require big-M constraints, but generates sparse
cuts that capture the combinatorial structure of the problem to strengthen the LP relaxation
and decrease training time. Although we use these cuts in a decomposition algorithm for our
formulation, they can be directly applied as valid inequalities to other MIP formulations that
may not be suited to decomposition (e.g., OCT-H [9] and SVM1-ODT [19]). We demonstrate
through numerical experiments that our MIP approach outperforms (in terms of training accu-
racy, testing accuracy, solution time, and relative gap) two other popular MIP formulations,
and is able to improve both in and out-of-sample performance, while remaining competitive
in terms of solution time to a wide range of popular approaches from the literature.
123

Constraints
2 The optimal decision tree problem
In this section, we formally introduce the problem setting, our notation, and our formulation.
2.1 The optimal decision tree problem
We ﬁrst deﬁne our data, which includes a training set of N observations, each of which has
p numerical features and belongs to one of K classes. For n ∈N, we denote by [n] the set
{1, . . . , n}. Without loss of generality, we normalize the training set so that all features are
scaled to [0, 1]. Thus, each observation i ∈[N] is a vector (xxxi, yi) ∈[0, 1]p × [K].
As noted in Section 1, we focus on learning optimal binary decision trees with multivariate
branching rules, which we refer to as multivariate splits. Each node in the tree is either a
branch node or a leaf node. Note that the ﬁrst node in the tree is colloquially referred to as
the root node (even though it is a branch node). The model is built upon a binary tree where
every branch node has exactly two children and the leaves are all on the same level. The
maximum depth of the decision tree D ∈N is deﬁned as the length of the path from the root
to any leaf. We denote the set of branch nodes as B = {1, . . . , 2D −1}. Each branch node t
corresponds to a multivariate split deﬁned by learned parameters aaat ∈Rp and bt ∈R. The
multivariate split is applied as follows: for each observation xxx ∈[0, 1]p, if aaa⊤
t xxx ≤bt, then
xxx is sent to the left child of t, denoted by 2t; otherwise it is sent to the right child, denoted
by 2t + 1. The key difference between multivariate and univariate splits is that a univariate
split allows only one component of aaat to be non-zero. We denote the set of leaf nodes by
L = {2D, . . . , 2D+1 −1}. Each leaf node t is a terminal node (i.e., it has no children) and
is assigned a class k ∈[K]. All observations routed to leaf t are classiﬁed as belonging to
class k.
The max depth D ∈N is often used as a hyperparameter to control the complexity and
size of the tree. To deter the model from constructing a full binary tree of depth D, we use a
hyperparameter β ∈N to limit the number of non-trivial splits used (more on this in Section
2.2).
2.2 Problem Formulation
We now present a formulation for learning an optimal decision tree – the training problem
– that includes a set of complicating constraints. For each branch node t ∈B, we can either
deﬁne a branching rule establishing whether an incoming observation should be sent to the
left or to the right child of t, in which case we say that node t applies a (non-trivial) split,
or we can direct all of the incoming observations to the left child of t. Correspondingly, we
introduce a binary variable dt that is equal to 1 if t applies a split, and to 0 otherwise. The
decision variables ddd thus deﬁne the tree topology. For each t ∈B we have p + 1 variables
(aaat, bt) deﬁning the multivariate split associated with the branch node. If t does not apply a
split, it is feasible to set these variables to (000, 0).
For each observation i ∈[N] and for each node t ∈B ∪L of the decision tree, we
introduce a binary variable wit that is equal to 1 if observation i is sent to node t, and to 0
otherwise. The decision variables www thus deﬁne how to route the observations from the root
node to the leaf nodes.
For each class k ∈[K] and leaf node t ∈L, we introduce a binary decision variable ctk
that is equal to 1 if t is assigned class label k, and to 0 otherwise. Finally, for each observation
i ∈[N] and leaf node t ∈L, we introduce a binary-valued decision variable zit that is equal
123

Constraints
to 1 if i is sent to leaf t and is correctly classiﬁed as yi, and to 0 otherwise. We will later see
that the integrality constraints on zzz can be relaxed. Our formulation for the training problem
is
maximize
ccc,ddd,www,zzz,aaa,bbb
N
i=1

t∈L zit
(1a)
subject to

t∈L wit = 1
∀i ∈[N],
(1b)
wit = wi,2t + wi,2t+1 ∀i ∈[N], t ∈B,
(1c)
K
k=1 ctk = 1
∀t ∈L,
(1d)
zit ≤wit
∀i ∈[N], t ∈L,
(1e)
zit ≤ct,yi
∀i ∈[N], t ∈L,
(1f)
wi,2t+1 ≤dt
∀i ∈[N], t ∈B,
(1g)

t∈B dt ≤β,
(1h)
ctk ∈{0, 1}
∀k ∈[K], t ∈L,
(1i)
dt ∈{0, 1}
∀t ∈B,
(1j)
wit ∈{0, 1}
∀i ∈[N], t ∈B ∪L,
(1k)
zit ∈R
∀i ∈[N], t ∈L,
(1l)
(aaat, bt) ∈Ht(www)
∀t ∈B,
(1m)
where, for each branch node t ∈B and integral www satisfying (1b) and (1c), the set Ht(www) is
deﬁned as
Ht(www) =

(aaat, bt) ∈Rp+1 :
aaa⊤
t xxxi + 1 ≤bt
∀i ∈[N] : wi,2t = 1,
(2)
aaa⊤
t xxxi −1 ≥bt
∀i ∈[N] : wi,2t+1 = 1

.
(3)
Note that, for a ﬁxed www, the set Ht(www) is a (‘n Rp+1.
The objective function (1a) aims to maximize the total number of observations that are
correctly classiﬁed. Our code implementation allows the user to specify a regularization
hyperparameter α ≥0 such that the objective is changed to mirror CART’s cost-complexity
measure [1]: minimize 1
N
N
i=1

1 −
t∈L zit

+ α 
t∈B dt. Constraints (1b) ensure that
each observation is mapped to exactly one leaf, while constraints (1c) guarantee that each
observation routed to a branch node t is sent to either the left or the right child of t. For a
branch node t that does not apply a split, constraints (1g) automatically send any incoming
observations to the left child of t. Constraints (1d) assign each leaf node a class in [K].
Constraints (1e) and (1f) enforce the condition that if zit = 1, then wit = 1 and ct,yi = 1
(i.e., observation i is sent to leaf t and is correctly classiﬁed as yi). Constraint (1h) limits
the number of non-trivial splits used to be at most β, where β ∈{1, . . . , 2D −1}. The main
motivation for introducing hyperparameter β is that, while the search space for α is inﬁnitely
large, for β we only need to search over ﬁnitely many choices [9]. We remark that integrality
constraints are not required for the zzz and ccc variables, since they are implied by the integrality
ofwww and by the fact that at an optimal solution constraints (1e) and (1f) hold with equality, see
[39] for a formal proof. Complicating constraints (1m) are the only ones involving variables
(aaat, bt), t ∈B, which ensure that the routing deﬁned by www can be realized by multivariate
splits. This is possible if and only if for each branch node t we have Ht(www) ̸= ∅.
We highlight some technical differences between our formulation and other MIP models
in the literature. First, we deﬁne the set of feasible routings www as the routings that satisfy
constraints (1m). As it will be clear in the following, we have a range of options to express
123

Constraints
Ht(w), i.e., by resorting to big-M constraints, by dynamically adding violated shattering
inequalities, or with a mix of these two approaches. Second, we deﬁne www over all nodes of
the decision tree, while previous formulation deﬁnes www over only the leaf nodes [9, 16, 19].
Our primary motivation for deﬁning additional (roughly double) www variables is that we can
exploit these additional variables to create stronger valid inequalities for characterizing the
set of feasible routings, see Section 4. A secondary reason for the introduction of www variables
over the branch nodes is that these extra variables give us the option to formulate a model
using fewer and stronger big-M constraints, see Section 3.
Finally, we maximize training accuracy and we control the tree size by imposing constraint
(1h). Unlike the univariate setting where CART’s cost-complexity measure can be directly
used as a template, the multivariate setting has no universally accepted objective. For example,
OCT-H [9] penalizes the total number of features used over all splits in the tree and SVM1-
ODT [19] penalizes the ℓ1 norm of aaat over all splits in the tree.
3 Baseline MIP formulation
For a ﬁxed branch node t ∈B, the complicating constraint (1m) holds if and only if for every
observation i ∈[N], the logical constraints
wi,2t = 1 
⇒aaa⊤
t xxxi ≤bt,
(4a)
wi,2t+1 = 1 
⇒aaa⊤
t xxxi −ϵ ≥bt
(4b)
are satisﬁed for some sufﬁciently small ϵ > 01. Typically, logical implications are modeled
using big-M constraints; indeed, this is the approach used by many optimal tree formulations
for imposing (1m) [9, 17–19]. To ensure the quantity aaa⊤
t xi −bt is bounded so that a big-M
value can be deﬁned, we enforce the conditions ∥aaat∥1 ≤1, bt ∈[−1, 1]. Thus, we have the
constraints
p
j=1 ˆat j ≤1,
(5a)
ˆat j ≥at j
j ∈[p],
(5b)
ˆat j ≥−at j
j ∈[p],
(5c)
bt ∈[−1, 1],
(5d)
where the auxiliary variables ˆat j are used to model |at j| for each j ∈[p]. We obtain from
(4) the big-M constraints
aaa⊤
t xxxi ≤bt + Mi(1 −wi,2t)
i ∈[N],
(6a)
aaa⊤
t xxxi −ϵ ≥bt −(Mi + ϵ)(1 −wi,2t+1) i ∈[N],
(6b)
with big-M values
Mi = max
j∈[p]{xi
j} + 1 ∀i ∈[N].
(7)
We deﬁne our baseline formulation to be (1) where the complicating constraints (1m) are
implemented using big-M constraints (6) for all t ∈B.
We point out that some MIP formulations found in the literature do not employ big-
M constraints. This is typically the case of univariate decision tree models relying on the
assumption that the feature vectors xxx are binary [11, 12, 14]. However, in the absence of either
1 In practice, ϵ is ﬁxed in advance; a reasonable choice is ϵ = 0.005.
123

Constraints
of these two assumptions—univariate splits or binary features—it becomes more complicated
to circumvent the use of big-M constraints.
We provide a comparison with how the OCT-H formulation of Bertsimas and Dunn [9]
models (1m), and argue our formulation yields a stronger LP relaxation. In the OCT-H
formulation, the variables wit are deﬁned only for the leaf nodes t ∈L. The authors deﬁne
the set AL(t) (resp. AR(t)) of ancestors of leaf node t ∈L whose left (resp. right) child is in
the path from the root node to node t. As a consequence, the logical constraints implemented
in OCT-H are
wit = 1 
⇒aaa⊤
mxxxi ≤bm
∀i ∈[N], t ∈L, m ∈AL(t),
(8a)
wit = 1 
⇒aaa⊤
mxxxi −ϵ ≥bm ∀i ∈[N], t ∈L, m ∈AR(t).
(8b)
These logical constraints are then linearized to obtain the big-M constraints2
aaa⊤
mxxxi ≤bm + M′
i(1 −wit)
∀i ∈[N], t ∈L, m ∈AL(t),
(9a)
aaa⊤
mxxxi −ϵ ≥bm −(M′
i + ϵ)(1 −wit) ∀i ∈[N], t ∈L, m ∈AR(t),
(9b)
with big-M values
M′
i = 2 ∀i ∈[N].
(10)
The big-M values (10) exploit only the assumption that features are normalized to the [0, 1]
interval, while the big-M values (7) are speciﬁc of each observation i ∈[N]. Since for
most observations i ∈[N], max j∈[p]{xi
j} may be much smaller than 1, the big-M values
in the OCT-H formulation are not as tight as the big-M values (7) utilized in our baseline
formulation.
Second, and more importantly, the big-M constraints of OCT-H result in weaker LP
relaxations. We denote by Pbase and POCT-H the linear relaxations of our baseline formulation
and of OCT-H, respectively. We consider the projections of Pbase and POCT-H on variables
{wit : i ∈[N], t ∈L} and {(at, bt) : t ∈B}, which we denote by Qbase and QOCT-H,
respectively. We consider the case where β = 2D −1 and there is no restriction on the
minimum number of observations in leaf nodes, which is an additional parameter of OCT-H.
Proposition 1 Qbase is strictly contained in QOCT-H.
Proof The big-M constraints (9) in OCT-H can be rewritten as
aaa⊤
t xxxi ≤bt + M′
i(1 −wi,ˆt)
∀i ∈[N], t ∈B, ˆt ∈L(2t),
(11a)
aaa⊤
t xxxi −ϵ ≥bt −(M′
i + ϵ)(1 −wi,ˆt) ∀i ∈[N], t ∈B, ˆt ∈L(2t + 1),
(11b)
where L(t) denotes the set of leaf nodes in the subtree whose root is t ∈B. Based on the
discussion in [9], it is evident that QOCT-H is determined by wit ≥0 for all i ∈[N], t ∈L,
(1b), (5) and (11). This is because, for each assignment of {wit : i ∈[N], t ∈L} and
{(at, bt) : t ∈B} satisfying these constraints we can derive values of the other problem
variables that are feasible for POCT-H.
In our formulation, wit = 
t′∈L(t) wi,t′ for all i ∈[N], t ∈B, so by writing our big-M
constraints (6) for all t ∈B, we obtain
aaa⊤
t xxxi ≤bt + Mi

1 −
t′∈L(2t) wi,t′

∀i ∈[N], t ∈B,
(12a)
aaa⊤
t xxxi −ϵ ≥bt −(Mi + ϵ)

1 −
t′∈L(2t+1) wi,t′

∀i ∈[N], t ∈B.
(12b)
2 In [9], ϵ appears in ﬁrst set of constraints (9a), not in the second set of constraints (9b) as we have written.
For the sake of comparison, we put ϵ in (9b).
123

Constraints
Qbase is determined by wit ≥0 for all i ∈[N], t ∈L, (1b), (5) and (12), since for each
assignment of {wit : i ∈[N], t ∈L} and {(at, bt) : t ∈B} satisfying these constraints we
can derive values of {wit : i ∈[N], t ∈B}, ddd, ccc and zzz that yield a vector in POCT-H.
We ﬁrst show that each vector in Qbase also belongs to QOCT-H. We need to verify that
each vector in Qbase satisﬁes constraints (11). Let i ∈[N], t ∈B and ˆt ∈L(2t). By (12) we
have
aaa⊤
t xxxi ≤bt + Mi

1 −wi,ˆt

−Mi
	
t′∈L(2t)\{ˆt}
wi,t′
≤bt + M′
i

1 −wi,ˆt

and
aaa⊤
t xxxi −ϵ ≥bt −(Mi + ϵ)

1 −wi,ˆt

+ (Mi + ϵ)
	
t′∈L(2t)\{ˆt}
wi,t′
≥bt −(M′
i + ϵ)

1 −wi,ˆt

,
since Mi ≤M′
i = 2 for all i ∈N and by the non-negativity of www.
To prove that the inclusion is strict, we exhibit a vector that is in QOCT-H and not in
Qbase. Consider a depth 2 tree and a training set consisting of two observations with identical
feature vectors but different labels, e.g. (x1, y1) = (1, 1) and (x2, y2) = (1, 2). Note that
Mi = M′
i = 2 for i = 1, 2. We deﬁne w11 = w21 = 1, w12 = 1, w22 = 0, w13 = 0, w23 = 1,
w14 = w15 = 1/2, w24 = w25 = 0, w16 = w17 = 0, w26 = w27 = 1/2. Moreover, for
each branching node t ∈B we deﬁne at = 1 and bt = 0. It can be easily checked that this
vector is in QOCT-H. In particular, at each branching node t ∈B the big-M constraints (11a)
are x ≤M′
i/2 = 1, which is satisﬁed for i = 1, 2, while the big-M constraints (11b) are
x −ϵ ≥−(M′
i + ϵ)/2 = −1 −ϵ/2, which is satisﬁed for i = 1, 2 and ϵ ≤4.
On the other hand, some big-M constraints of the baseline formulation are violated, specif-
ically at the root node the big-M constraint (6a) is x1 ≤0, which is violated since x1 = 1.
There is actually no hyperplane a1x = b1 such that the big-M constraints (6) at t = 1 can be
satisﬁed, since x1 = x2.
⊓⊔
Weﬁnallyremarkthatourformulationusesfewerbig-MconstraintsthanOCT-Htoenforce
(1m). Upon enumerating for every branch node t ∈B, there are 2N|B| = N(2D+1 −2)
constraints among (6). In contrast, OCT-H (as well as OCT, the univariate decision tree
formulation of [9]) requires 2N|L|D = 2D+1N D big-M constraints to accomplish the same
goal of enforcing (1m). Since the number of constraints (1b)–(1h) is roughly 5N2D, the total
number of constraints is reduced by a factor of 28%, 39%, 47% and 54% for depths 2, 3, 4
and 5, respectively.
We conclude that the use of the ancestor sets AL(t) and AR(t) weakens OCT-H. These
ancestor sets are also used in OCT, as well as [19] and [16].
4 Shattering inequalities
In this section, we propose a new class of valid inequalities for (1), called shattering inequal-
ities, which correspond to subsets of observations that cannot be shattered by a multivariate
split, and we propose a separation algorithm to generate these inequalities.
Let C be a family of binary classiﬁers in Rp. A set of observations is shattered by C if, for
any assignment of binary labels to these observations, there exists some classiﬁer in C that
123

Constraints
can perfectly separate all the observations. The maximum number of observations that can
be shattered by C is called the Vapnik-Chervonenkis (VC) dimension of C [40].
We now consider the family of binary classiﬁers H consisting of the multivariate splits
in Rp. Let I be a collection of subsets I ⊆[N] of observations such that

xi
i∈I cannot be
shattered by H. For each I ∈I, denote by (I) ⊂{−1, 1}I the assignments of binary labels
to observations in I so that they cannot be perfectly separated by any multivariate split in
Rp. Then, the following inequalities are valid for (1):
	
i∈I:λi=−1
wi,2t +
	
i∈I:λi=+1
wi,2t+1 ≤|I| −1,
∀I ∈I, λλλ ∈(I), t ∈B.
(13)
The shattering inequalities (13) have the form of packing constraints [41] and impose the
condition that at least one observation in I is not routed to the children of t as prescribed
by the label assignment λλλ. We can restrict our attention to the minimal (w.r.t. set inclusion)
subsets of I. Indeed, if I ∈I is not minimal, then each inequality (13) associated to I is
implied by an inequality (13) associated to some I ′ ⊂I in I.
Moreover, if I is a minimal set of observations in Rp that cannot be shattered by H, then
|I| ≤p + 2. This follows from the fact that the VC dimension of H is p + 1. Note that
we might still be unable to perfectly split |I| < p + 2 observations in Rp if there exists an
hyperplane that contains more than p points. For example, for p = 2, three points on a line
labeled (in sequence) 1, −1, 1 cannot be perfectly split. As a consequence, the support of
inequalities (13) corresponding to minimal sets of observations in Rp that cannot be shattered
by H, is at most p + 2. In particular, if p ≪N, these inequalities are sparse.
Figure 2 shows an example using a dataset with points xxxi = (xi
1, xi
2) ∈R2, where for the
ﬁrst four observations, xxx1 = (0, 0), xxx2 = (0, 1), xxx3 = (1, 0), xxx4 = (1, 1); the full dataset
may contain many more observations. I = {1, 2, 3, 4} is an example of a minimal subset of
observations that cannot be shattered by H; no hyperplane is capable of separating {xxx1,xxx4}
from {xxx2,xxx3}, however I \ {i} can be shattered for any i ∈I. We can derive the shattering
inequalities:
w2,2t + w3,2t + w1,2t+1 + w4,2t+1 ≤3,
∀t ∈B
(14)
and
w1,2t + w4,2t + w2,2t+1 + w3,2t+1 ≤3,
∀t ∈B.
(15)
Fig. 2 I = {1, 2, 3, 4} is a minimal subset of observations that cannot be shattered by H. (I) contains
exactly two vectors λλλ = (λ1, λ2, λ3, λ4). (a) shows λλλ = (+1, −1, −1, +1), which is used to derive (14); (b)
shows λλλ = (−1, +1, +1, −1), which is used to derive (15)
123

Constraints
4.1 Separation
Itisimpracticaltoenumerateallpossibleshatteringinequalities(13)asthereareexponentially
many. Instead, they should be used sparingly, such as through row generation. Consider a
vector ¯w¯w¯w, possibly fractional, satisfying (1b) and (1c). We propose a method for separating
¯w¯w¯w using a violated inequality (13).
For each t ∈B, let Nt( ¯w¯w¯w) = {i ∈[N] : ¯wit > p+1
p+2}; note that N2t( ¯w¯w¯w) and N2t+1( ¯w¯w¯w) are
disjoint, since for all i ∈[N], at most one of ¯wi,2t, ¯wi,2t+1 can be greater than p+1
p+2. Consider
the following system of linear inequalities in variables (aaat, bt):

aaa⊤
t xxxi + 1 ≤bt, ∀i ∈N2t( ¯w¯w¯w),
aaa⊤
t xxxi −1 ≥bt, ∀i ∈N2t+1( ¯w¯w¯w).
(16)
Our goal is to either certify that system (16) is feasible, or return an inclusion-minimal
subset of observations I ′ ⊆Nt( ¯w¯w¯w), such that I ′ ∩N2t( ¯w¯w¯w) cannot be perfectly separated from
I ′ ∩N2t+1( ¯w¯w¯w) by a multivariate split. Each such subset I ′ corresponds to an Irreducible
Infeasible Subsystem (IIS) of the infeasible system (16), which is deﬁned as a subsystem of
(16) that would become feasible by discarding one arbitrary inequality. Given an IIS of (16)
indexed by I ′, the inequality:
	
i∈I ′∩N2t( ¯w¯w¯w)
wi,2t +
	
i∈I ′∩N2t+1( ¯w¯w¯w)
wi,2t+1 ≤|I ′| −1.
(17)
is clearly a shattering inequality (13). In the next lemma, we formally prove that inequality
(17) is violated by ¯w¯w¯w.
Proposition 2 Let ¯w¯w¯w be a nonnegative vector satisfying (1b) and (1c) such that (16) is infea-
sible. Then, for each IIS I ′ of (16), the shattering inequality (17) is violated by ¯w¯w¯w.
Proof Since ¯wit > p+1
p+2 for all i ∈N2t( ¯w¯w¯w)∪N2t+1( ¯w¯w¯w), the right-hand-side of (17) evaluated
in ¯w¯w¯w is strictly greater than
|I ′ ∩N2t( ¯w¯w¯w)| p + 1
p + 2 + |I ′ ∩N2t+1( ¯w¯w¯w)| p + 1
p + 2 = |I ′| p + 1
p + 2.
Moreover
|I ′| p + 1
p + 2 ≥|I ′| −1 ⇐⇒|I ′|

1 −p + 1
p + 2

≤1.
The condition on the right is always satisﬁed, since
|I ′|

1 −p + 1
p + 2

= |I ′|
1
p + 2 ≤1,
where the last inequality follows from the fact that |I ′| ≤p + 2.
⊓⊔
If ¯w¯w¯w is fractional and system (16) is feasible, we are not able to generate a shattering
inequality violated by ¯w¯w¯w, however there might exist one such violated inequality. On the other
hand, if ¯w¯w¯w is binary and (16) is feasible we can conclude that ¯w¯w¯w satisﬁes all the shattering
inequalities (13).
Proposition 3 Let ¯w¯w¯w be a binary vector satisfying (1b) and (1c) and such that (16) is feasible.
Then, every shattering inequality (13) deﬁned at node t is satisﬁed by ¯w¯w¯w.
123

Constraints
Proof By contradiction, suppose that one shattering inequality (13) deﬁned at node t is
violated by ¯w¯w¯w:
	
i∈I:λi=−1
¯wi,2t +
	
i∈I:λi=+1
¯wi,2t+1 > |I| −1,
for some I ∈I and λλλ ∈(I). Since ¯w¯w¯w is binary, we must have that ¯wi,2t = 1 for all
i ∈I : λi = −1 and ¯wi,2t+1 = 1 for all i ∈I : λi = 1, thus {i ∈I : λi = −1} = I ∩N2t( ¯w¯w¯w)
and {i ∈I : λi = 1} = I ∩N2t+1( ¯w¯w¯w).
By the deﬁnition, each shattering inequality corresponds to a subset of observations that
cannot be linearly separated, thus the system

aaa⊤
t xxxi + 1 ≤bt,
∀i ∈I ∩N2t( ¯w¯w¯w),
aaa⊤
t xxxi −1 ≥bt,
∀i ∈I ∩N2t+1( ¯w¯w¯w).
is infeasible. This is a subsystem of system (16), which contradicts that system (16) is
feasible.
⊓⊔
Propositions 2 and 3 imply that, in the case where ¯w¯w¯w is binary, our separation algorithm
is exact: either a violated inequality (17) is found, or ¯w¯w¯w satisﬁes the complicating constraint
(1m) associated with node t. As we will discuss later, this implies that when solving using
lazy cuts, we can certify an integer incumbent solution as being optimal if we are unable to
ﬁnd a violated inequality (17).
Next, we discuss how to generate violated shattering inequalities. Suppose that system
(16) is infeasible for a given ¯www. Farkas’ lemma [42, 43] then implies that another, related
system of inequalities is feasible. The solutions of this system deﬁne a polyhedron Qt( ¯www).
Precisely:
Qt( ¯www) =

qqq ∈RNt( ¯w¯w¯w)
+
:
	
i∈N2t( ¯w¯w¯w)
qixxxi =
	
i∈N2t+1( ¯w¯w¯w)
qixxxi,
	
i∈N2t( ¯w¯w¯w)
qi =
	
i∈N2t+1( ¯w¯w¯w)
qi = 1
⎫
⎬
⎭.
The polyhedron Qt( ¯www) has a very nice geometric interpretation. The decision variables
qqq are associated with the observations indexed by Nt( ¯w¯w¯w), and they can be interpreted as the
coefﬁcients of two convex combinations, one on the observations in N2t( ¯w¯w¯w) and the other on
the observations in N2t+1( ¯w¯w¯w). The constraints deﬁning Qt( ¯www) ask that a feasible solution is
in both in the convex hull of

xi : i ∈N2t( ¯w¯w¯w)

and in the convex hull of

xi : i ∈N2t+1( ¯w¯w¯w)

.
Thus, Qt( ¯www) is nonempty if and only if the observations in N2t( ¯w¯w¯w) cannot be linearly sepa-
rated from those in N2t+1( ¯w¯w¯w), or equivalently, if and only if system (16) is infeasible.
Moreover, a classic result by Gleeson and Ryan [44] establishes that there is a one-to-one
correspondence between the IISs of (16) and the vertices of Qt( ¯www). Speciﬁcally, the indices
of the inequalities appearing in an IIS of (16) correspond to the nonzero entries of a vertex
of Qt( ¯www), and vice versa.
Based on the above discussion, we can deﬁne a separation algorithm to dynamically
generate the shattering inequalities (13). This algorithm receives as input a vector ¯w¯w¯w and a
ﬁxed branch node t ∈B, and attempts to return an inequality of family (13) associated with
node t that is violated by ¯w¯w¯w. Precisely, the algorithm checks the feasibility of the polyhedron
Qt( ¯www). If Qt( ¯www) is nonempty, then by Farkas’ Lemma, system (16) is infeasible, and from
eachvertexof Qt( ¯www)wecanconstructanIISof (16)andacorrespondingshatteringinequality
(17) that is violated by ¯w¯w¯w.
123

Constraints
In practice, it is possible to efﬁciently generate multiple inequalities (17) by ﬁnding mul-
tiple vertices of Qt( ¯www). One method for ﬁnding multiple vertices is to optimize over Qt( ¯www)
multiple times with different objective functions. For instance, let fff ∈ZNt( ¯w¯w¯w)
+
be a counter
for the number of inequalities (17) that each observation in Nt( ¯w¯w¯w) has appeared in thus far.
One can repeatedly solve max{ fff ⊤qqq : qqq ∈Qt( ¯www)}, each time updating a global counter
ggg ∈ZN
+ as a cut is added. A downside to taking fff to be a counter is that over time, fff may
converge to θ111 where θ ≫0, thus every observation is equally weighted in the objective.
A reﬁnement of this idea is to keep an exponential average; let ggg ∈RN
+ be initialized to the
zero vector, and when a cut (17) is found, set ggg := 111Nt( ¯w¯w¯w) + 0.5ggg where 111Nt( ¯w¯w¯w) is a binary
vector with ones in indices corresponding to Nt( ¯w¯w¯w). This objective function is a bounded
vector (each component is at most 2), and places more emphasis on ﬁnding cuts not recently
found.
Furthermore, for a ﬁxed ¯w, one can iterate t over a desired subset of branch nodes to
generate even more cuts. Thus, the separation algorithm has the signature Separation( ¯w,
nodes, n_cuts), where nodes is the desired subset of branch nodes to loop over, and
n_cuts is the number of times to repeatedly solve max{ f ⊤qqq : qqq ∈Qt( ¯w)}.
The separation algorithm can be implemented via LP with a run time that is polynomial
in 2D and size(X), where X is the N × p matrix encoding the features of the observations in
the training set and size(X) is deﬁned as the number of bits required to encode X [45]. Note
that there is an exponential dependence with respect to the depth parameter D. However, the
number of variables and constraints of our MIP formulation (as well as the other formulations
from the literature) are already exponential in D and in practice, we want D to be small so
that we can obtain a more interpretable decision tree.
We now propose three practical methods of using shattering inequalities as cuts. The ﬁrst
way is to add the cuts directly to the formulation up front as initial cuts. The advantage to
adding cuts directly to the formulation as constraints rather than as lazy cuts or user cuts is
that this enables the MIP solver to derive valid inequalities based on the initial cuts. To ﬁnd
such cuts, we solve the LP relaxation of (1) excluding the complicating constraints (1m).
From the resulting solution, we call Separation( ¯w¯w¯w, branch_nodes, n_init_cuts)
in an attempt to derive cuts, where n_init_cuts is a user-deﬁned parameter, and add all
found cuts to the LP relaxation. We iterate this procedure until the LP relaxation amended
with cuts no longer yields a solution from which cuts can be derived, or once 10 iterations
have passed. Once this is done, we add to our baseline formulation all the derived cuts and
solve the MIP.
The second way is to use the cuts as lazy cuts in a Benders-like decomposition. Without
using big-M constraints (6), another option for implementing the complicating constraint
(1m) is using shattering inequalities (13) exclusively. It is impractical to enumerate all pos-
sible shattering inequalities, however it might be the case that only a few such inequalities
are needed to ﬁnd an optimal solution. At nodes of the branch-and-cut tree, the MIP solver
ﬁnds either a fractional solution of the relaxation or an (integer) incumbent solution ¯w¯w¯w, thus
giving the user an opportunity to add lazy cuts. Let benders_nodes be a user-deﬁned
subset of the branch nodes for which one would like to apply lazy cuts. For branch nodes
not in benders_nodes, we add the associated big-M constraints (6) to the model (1).
We call Separation( ¯w¯w¯w, benders_nodes, n_benders_cuts) to add lazy cuts to
(1), where n_benders_cuts is a user-deﬁned parameter. In the case where we have an
incumbent solution ( ¯w¯w¯w is integer), separation is exact, meaning the solver correctly concludes
the incumbent solution is feasible if no cuts are added. Thus, we can implement the com-
123

Constraints
plicating constraint (1m) associated with a branch node by dynamically adding shattering
inequalities (13) to the model as lazy cuts.
The third way is to use the cuts as user cuts. User cuts are cutting planes added at nodes
of the branch-and-cut tree in order to separate fractional solutions. Unlike lazy cuts which
are required for model correctness, user cuts only serve to tighten the formulation; they
cannot cut off integer solutions that satisfy the constraints of the master formulation (i.e.,
(1) minus the complicating constraints (1m)). Thus, for a given branch node, if one would
like to apply user cuts, the big-M constraints (6) associated with that node must be present.
Let user_cuts_nodes be a user-deﬁned subset of the branch nodes for which one would
like to apply user cuts; a requirement is that user_cuts_nodes and benders_nodes
must be disjoint. Note that user_cuts_nodes are a subset of the branch nodes not in
benders_nodes, hence the big-M constraints (6) for user_cuts_nodes are in the
model, as is required. At nodes of the branch-and-cut tree where the MIP solver has found
a fractional solution ¯w¯w¯w of the relaxation, we call Separation( ¯w¯w¯w, user_cuts_nodes,
n_user_cuts) to add user cuts to (1), where n_user_cuts is a user-deﬁned parameter.
We remark that in the second scenario, where we use the cuts as lazy cuts in a Benders-like
decomposition, the shattering inequalities (17) are effectively combinatorial Benders (CB)
cuts [46, 47]. CB cuts are a specialization of Hooker’s logic-based Benders decomposition
[47]. They are formally introduced by Codato and Fischetti [46], who study MIP problems
that can be decomposed into a master problem with binary variables, and an LP subproblem
whose feasibility depends from the solution of the master problem.
Let B′ be the subset of B containing the nodes in benders_nodes. To derive shattering
inequalities as CB cuts, we can decompose (1) into a master problem and an LP feasibility
subproblem as follows. The master problem is obtained from (1) by removing the compli-
cating constraints (1m) for each t ∈B′ and by (possibly) adding some valid inequalities
(13). Thus, the master problem is a MIP with decision variables ccc,ddd,www,zzz and (at, bt) for
t ∈B \ B′. The LP feasibility subproblem includes decision variables (aaat, bt), t ∈B′, and
veriﬁes that, for a given ¯www, Ht( ¯www) is a nonempty polyhedron for all t ∈B′.
Theshatteringinequalities(17)canbeinterpretedasCBcutsbyenforcingthecomplicating
constraints (1m) through the following logical constraints (note that left children have an even
index, while right children have an odd index):
∀i ∈[N], t ∈B′ ∪L \ {1}, wit = 1 
⇒

aaa⊤
t/2xi + 1 ≤bt/2
if t is even
aaa⊤
⌊t/2⌋xi −1 ≥b⌊t/2⌋
if t is odd.
After solving the master problem, if the inequality system given by the activated logical
constraints (i.e., those where ¯wit = 1) is infeasible, the IISs of the system can be used to
derive CB cuts. A key observation is that, in our setting, each IIS involves only the components
of ¯w¯w¯w that pertain to a speciﬁc branch node t ∈B′. As a result, we can separately consider the
inequality systems (16) associated with each individual branch node t ∈B′.
5 Heuristic for training multivariate decision trees
Unlike in the case of univariate decision trees, there are few widely used heuristic algorithms
for training multivariate trees. Although this paper is primarily concerned with learning
optimal decision trees, heuristics are still of interest as they serve as strong warm starts for
the MIP model. In this section, we develop a novel heuristic based on existing univariate
123

Constraints
tree heuristics and support vector machines (SVMs). We take inspiration from [48], whose
procedure uses a series of linear programs rather than SVMs.
We ﬁrst review univariate decision tree heuristics in order to better understand the difﬁculty
in extending these algorithms to the multivariate setting. Many univariate tree heuristics are
top-down greedy algorithms that recursively split the data according to some optimization
criterion. For example, the CART algorithm seeks the split resulting in the largest reduction
in Gini impurity [1] The ID3, C4.5, and C5.0 algorithms function similarly with respect to
Shannon entropy [8]. This optimization problem is easy to solve in the univariate setting as
all O(Np) possible splits may be enumerated, however such enumeration is not possible in
the multivariate setting; indeed, the problem of ﬁnding a multivariate split that optimizes
some arbitrary criterion such as Gini impurity or Shannon entropy is NP-hard [49]. Hence, it
is impractical to simply replicate these univariate heuristics when allowing for multivariate
splits.
Rather than enumerating all possible multivariate splits, we consider a small set of promis-
ing splits. In particular, we use the one-vs-one and one-vs-rest decision boundaries returned
by linear SVMs as our set of candidate splits. Among these candidates, we pick the one that
optimizes the desired split criterion. For example, if the criterion is Gini impurity, we pick the
split that results in the greatest decrease in impurity. We build the tree in the same recursive
fashion as top-down greedy algorithms for univariate trees. In the case where there is a limit
β < |B| on the number of non-trivial splits used, we prune the tree.
Our heuristic, speciﬁcally the enumeration of SVM decision boundaries, can be imple-
mented using scikit-learn’s LinearSVC and SVC(kernel=’linear’) [50]. Multiple
SVMs can be constructed by varying the C hyperparameter used in both scikit-learn models;
we use C ∈{2k : k = 0, . . . , 10}. Possible choices of minimization criteria include Gini
impurity, entropy, and training error. We train three multivariate trees each based on one of
these criteria, and pick the one with the highest overall training accuracy to be the warm start.
6 Experiments
In this section, we provide two sets of numerical experiments to benchmark various imple-
mentations of our approach (S-OCT) with ﬁve methods from the literature: OCT and OCT-H
[9], two MIP models for learning optimal univariate and multivariate trees respectively;
FlowOCT [11], a MIP model which can be solved as-is (FlowOCT), or with Benders decom-
position (FlowOCT-Benders); and DL8.5 [30], an itemset mining-based approach that uses
branch-and-bound and caching.
6.1 Experimental setup
Before comparing S-OCT against the other approaches from the literature, we tuned S-
OCT on ﬁve datasets to ﬁnd the most promising conﬁgurations of the S-OCT model parame-
ters n_init_cuts, benders_nodes, n_benders_cuts, user_cuts_nodes,and
n_user_cuts. Precisely, we selected the Pareto-optimal parameter conﬁgurations with
respect to solution time and average gap (we found four). The ﬁve datasets we used can
be obtained from the UCI Machine Learning Repository [51]: Hayes-Roth, Tic-Tac-Toe
Endgame, Climate Model Crashes, Glass Identiﬁcation and Image Segmentation. We use
these four best performing versions of our model, along with the baseline S-OCT model
which does not use any shattering inequalities, for the remaining experiments.
123

Constraints
We benchmark these ﬁve variants of our approach against other methods from the liter-
ature on the following ten datasets from the UCI Machine Learning Repository [51]: (A)
Balance Scale, (B) Congressional Voting Records, (C) Soybean (Small), (D) Iris, (E) Wine,
(F) Breast Cancer, (G) Banknote Authentication, (H) Blood Transfusion, (I) Ionosphere, and
(J) Parkinsons. Note that none of these datasets were used to tune S-OCT. The ﬁrst set of
benchmarks is a direct MIP comparison, where we compare the ﬁve S-OCT variants with
the following MIP methods: OCT, OCT-H, FlowOCT, and FlowOCT-Benders. The second
set of benchmarks is a comprehensive comparison where we compare against all of the pre-
viously mentioned methods: OCT, OCT-H, FlowOCT, FlowOCT-Benders, and DL8.5. In
the direct MIP comparison, we use our own implementations of OCT and OCT-H. In the
comprehensive comparison, we test both our own implementations of OCT and OCT-H and
the implementations of OCT and OCT-H from the Interpretable AI package [52].In both the
direct MIP and comprehensive comparisons, we use our own implementations of FlowOCT
and FlowOCT-Benders. We use the DL8.5 package available on PyPI [31]3.
Since FlowOCT and DL8.5 require binary features, for these models we perform an
additional bucketization step for the numerical datasets.
The original FlowOCT paper [11] deﬁnes ﬁve bins per feature using quantiles. The original
DL8.5 paper [30] performs bucketization as follows: for every feature j, sort the observa-
tions according to this feature, ﬁnd consecutive observations with different class labels (and
different values for feature j), and deﬁne a binary feature that has value 1 if and only if x j
is less than the average of the two adjacent feature values. For each model, we bucketize
features in accordance with its original paper.
Note that both methods of bucketizing continuous data may sacriﬁce training accuracy,
as identiﬁed in [32]. For OCT, OCT-H, and S-OCT, we normalize numerical features to the
[0, 1] interval. For all models, we perform one-hot encoding for categorical features.
Our experiments were programmed using Python 3.8.10 and all optimization problems
were solved using Gurobi 10.0 [53] on a machine with a 3.00 GHz 6-core Intel Core i5-
8500 processor and 16 GB RAM. A 10-minute time limit was imposed for all optimization
problems. Our code can be found at https://github.com/zachzhou777/S-OCT.
6.1.1 Tuning experiments.
Let Blast = {2D−1, . . . , 2D−1} denote the last level of branch nodes in the tree. We tried three
general variations of our S-OCT model, each associated with the three different methods of
using our cuts:
• Initial cuts. Let SOCT-init-<n_init_cuts> denote the baseline S-OCT model
amended with initial cuts, with cuts being found using the procedure Separation( ¯w¯w¯w,
branch_nodes, n_init_cuts). We deﬁned the models SOCT-init-1 and SOCT
-init-5.
• Benders/lazy cuts. Let SOCT-benders-<benders_nodes>-<n_benders_
cuts> denote the S-OCT model where shattering inequalities (13) are used to imple-
ment the complicating constraints (1m) for branch nodes in the set benders_nodes,
with cuts being found using the procedure Separation( ¯w¯w¯w, benders_nodes,
n_benders_cuts). We deﬁned the models SOCT-benders-<benders_nodes>
-<n_benders_cuts>for(benders_nodes, n_benders_cuts) ∈{{1}, Blast, B}
× {1, 5, 10, 50, 100} (i.e., the options for benders_nodes are the root node only, the
last level of branch nodes, and the set of all branch nodes).
3 The package is now named pydl8.5 (https://pypi.org/project/pydl8.5/), not dl8.5
123

Constraints
• User cuts. Let SOCT-user-<user_cuts_nodes>-<n_user_cuts> denote the
baseline S-OCT model where user cuts are found for branch nodes in the set
user_cuts_nodes, with cuts being found using the procedure Separation( ¯w¯w¯w,
user_cuts_nodes,n_user_cuts).WedeﬁnedthemodelsSOCT-user-<user_
cuts_nodes>-<n_user_cuts> for (user_cuts_nodes, n_user_cuts) ∈
{{1}, Blast, B} × {1, 5, 10, 50, 100}.
For each variation of our model, we simply run it across the ﬁve datasets. No cross
validation is performed. We do not employ warm starts or regularization (constraint (1h) is
deleted).
Figure 3 displays a scatter plot of the average solution time and average relative
gap for all parameter tuning implementations across depths 2,3 and 4. We selected the
four best performing implementations representing the Pareto-frontier (shown in red in
Fig. 3), along with the baseline model: SOCT-baseline, SOCT-benders-last-1,
SOCT-benders-last-10, SOCT-init-1, SOCT-init-5.
6.1.2 Direct MIP comparison
In the direct MIP comparison, we compare the performance of our ﬁve S-OCT variants
against the other MIP methods: OCT, OCT-H, FlowOCT, and FlowOCT-Benders. Here,
we are interested in the strength of the above MIP formulations, rather than their efﬁcacy
as machine learning models. Thus, we do not include constraint (1h) in S-OCT and we
set α = 0 in the other models. In other words, we simply maximize the number of training
points correctly classiﬁed. Finally, we refrain from providing warm starts. We recall that OCT,
FlowOCT, and FlowOCT-Benders solve the optimal univariate decision tree problem, while
Fig.3 Ascatterplotoftheaveragesolutiontimeandaveragerelativegapforallparametertuningcombinations.
The red dots indicate the four best performing implementations
123

Constraints
OCT-H and our ﬁve S-OCT variants solve the optimal multivariate decision tree problem.
These two problems are inherently different, thus when comparing the performance of a
univariate and a multivariate model we should mainly focus on the trade-off between training
time and training accuracy. For all MIP models, we set the Gurobi relative gap parameter
MIPGap to 0 and the absolute gap parameter MIPGapAbs to 1; this is done to prevent the
solver from terminating before the time limit unless it has a truly optimal solution, as by
default Gurobi terminates when the relative gap is below 10−4.
For each instance (dataset, depth D), we train each model on the entire dataset (no train-test
split or cross validation) and record the following:
• Training time, i.e., solution time.
• Upper bound: The bound on the best possible objective. Also known as the dual objective
bound and denoted by zD.
• Lower bound: The objective of the best incumbent at termination. Also known as the
primal objective bound and denoted by zP.
• Relative MIP gap: For a maximization problem, gap = (zD −zP)/zP; if zP = zD = 0,
then gap = 0.
Figure 4(a) displays boxplots (across the ten datasets) of solution time for each model
and each depth. At depth 2, FlowOCT-Benders performed best with an average±standard
deviation solution time of 15.93±21.01s. The fastest multivariate model was OCT-H, with an
average solution time of 88.4±173.91. Our best performing model was SOCT-Benders-last-
10 with an average solution time of 95.15 ± 183.07s, following closely by SOCT-Benders-
last-1 with an average solution time of 97.35 ± 178.54s.
At depth 3, SOCT-Benders-last-1 and SOCT-Benders-last-10 performed best with an
average solution time of 72.23±178.72s and 111.71±188.12s, respectively. SOCT-Benders-
last-1 improved upon the best model from the literature (OCT-H) by 184.44s (72%). The best
univariate model is FlowOCT, with an average solution time of 343.23 ± 261.78s.
At depth 4, SOCT-Benders-last-1 and SOCT-Benders-last-10 performed best with an
average solution time of 173.91 ± 215.82s and 150.15 ± 247.61s, respectively. SOCT-
Benders-last-10improveduponthebestmodelfromtheliterature(OCT-H)by151.12s(50%).
The best univariate model is OCT, with an average solution time of 483.43 ± 236.87s.
Figure 4(b) displays boxplots (across the ten datasets) of relative gap for each model and
each depth. At depths 2 and 3, the univariate model FlowOCT performed best with an average
relative gap of 0±0 and 0.02±0.03, respectively. The best multivariate models at depth 2 are
SOCT-baseline, SOCT-init-1 and SOCT-init-5, with an average relative gap of 0.03 ± 0.08,
closely followed by OCT-H, with an average relative gap of 0.03±0.08. SOCT-benders-last-
1 and SOCT-benders-last-10 produced an average relative gap of 0.03 ± 0.09 for all three
depths, improving over OCT-H by 59% and 64% at depths 3 and 4, respectively and over
FlowOCT-Benders, which is the best univariate model at depth 4, by 50%.
Figure 4(c) displays boxplots (across the ten datasets) of in-sample accuracy for each
model and each depth. SOCT-benders-last-1 performed best across all three depths with an
average in-sample accuracy of 0.98 ± 0.07. The best performing model from the literature
was OCT-H with an average in-sample accuracy of 0.95 ± 0.1.
Figure 4(d) displays a scatter plot of the overall average relative gap and overall average
solution time across all ten datasets and three depths for each model. Overall, SOCT-benders-
last-1 and SOCT-benders-last-10 performed best with an average solution time and relative
gap of (114.5 ± 196.64s, 0.03 ± 0.09) and (119.0 ± 209.61s, 0.03 ± 0.09), respectively.
The best performing models from the literature were Flow-OCT and OCT-H with an average
123

Constraints
Fig. 4 Direct MIP comparison results displaying (a) boxplots (across datasets) of solution time for all three
depths, (b) boxplots (across datasets) of relative gap for all three depths, (c) boxplots (across datasets) of
in-sample accuracy for all three depths, and (d) the overall average relative gap and overall average solution
time across all three depths and all datasets
123

Constraints
solution time and relative gap of (306.26 ± 279.87s, 0.03 ± 0.07) and (215.45 ± 248.35s,
0.06 ± 0.14), respectively.
6.1.3 Comprehensive comparison
In the comprehensive comparison, we compare the practical performance of our approach
against a wider range of other methods, both within and outside of MIP. We now allow the
use of warm starts for the MIP models: FlowOCT and FlowOCT-Benders use scikit-learn’s
CART implementation [50], whereas our ﬁve SOCT models and our own implementations
of OCT and OCT-H use the multivariate heuristic described in Section 5.
For each instance (dataset, depth D), we perform 3-fold cross validation to obtain three
estimates of train time, train accuracy, and test accuracy. We tune hyperparameters using
an inner 2-fold cross validation; after selecting the best hyperparameter setting, we reﬁt on
the whole training set before evaluating. For S-OCT, FlowOCT, and our implementations of
OCT and OCT-H, we tuned the hyperparameter β, the maximum number of splits allowed in
the tree; when D = 2 we searched over {2, 3}, when D = 3 we searched over {3, 5, 7}, when
D = 4 we searched over {5, 10, 15}.4 Interpretable AI automatically tunes α for OCT and
OCT-H. For DL8.5, we tuned the hyperparameter min_sup, which refers to the minimum
number of observations per leaf; we searched over {1, 10, 20}.
Tables 1, 2, and 3 provide a detailed comparison of the numerical results for each dataset
and all model implementations at depths 2, 3, and 4, respectively. Figure 5 displays line plots
of the training accuracy, testing accuracy, and solution time across all 10 datasets (sorted for
clarity) and for all models at depth four. The line plots visualize the results in Table 3.
For solution time, our models performed similar to OCT and better than OCT-H (Inter-
pretable AI implementations), except for dataset H, where we consistently timed-out.
Excluding dataset H, the average solution time for OCT (Interpretable AI implementation)
at depths 2, 3, and 4 was 0.31 ± 0.09, 0.39 ± 0.16, and 0.46 ± 0.2, respectively. The aver-
age solution time for OCT-H (Interpretable AI implementation) at depths 2, 3, and 4 was
10.88 ± 8.46, 13.25 ± 10.49, and 15.99 ± 14.69, respectively. The average solution time for
SOCT-benders-last-1 at depths 2, 3, and 4 was 0.78 ± 0.44, 1.36 ± 1.05, and 3.29 ± 5.49,
respectively. Note that we are unable to determine if the Interpretable AI implementations of
OCT and OCT-H solve to optimality or if they use some early stopping criteria. Our SOCT
models and our own implementations of OCT and OCT-H do not use early stopping and
unless they timeout, solve to optimality. We have found out that our own implementations of
OCT and OCT-H also consistently time out on dataset H, which supports the hypothesis that
Interpretable AI might use an early stopping criterion. Excluding dataset H, our own imple-
mentation of OCT-H and the Interpretable AI implementation displays comparable average
solution time (across all depths). On the other hand, our own implementation of OCT is much
slower that the Interpretable AI implementation.
In terms of out-of-sample accuracy, our models performed similarly to OCT-H (Inter-
pretable AI implementation) and signiﬁcantly better than the other models from the literature.
The average out-of-sample accuracy for OCT-H at depths 2, 3, and 4 was 0.92 ± 0.06,
0.93 ± 0.05, and 0.93 ± 0.06, respectively. The average out-of-sample accuracy for SOCT-
benders-last-1 at depths 2, 3, and 4 was 0.92±0.07, 0.92±0.08, and 0.93±0.07, respectively.
We also noted that our own implementations of OCT and OCT-H, compared with the Inter-
pretable AI implementations, achieve a higher in-sample-accuracy but have a much lower
4 OCT-H performs regularization on the total number of features involved in multivariate tests, so rather than
limit the number of splits to β, we limit the total number of features to pβ.
123

Constraints
Table 1 Detailed summary of comprehensive comparisons for depth 2
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
Observations (N)
625
435
47
150
178
569
1372
748
351
195
Features (p)
20
48
59
4
13
30
4
4
34
22
DL8.5 buckets (avg)
N/A
N/A
N/A
35.67
432.33
3143.67
1184.0
103.0
1517.0
758.0
FlowOCT buckets (avg)
N/A
N/A
N/A
20.0
65.0
150.0
20.0
18.67
158.0
110.0
Classes (K)
3
2
4
3
3
2
2
2
2
2
In-sample accuracy
DL8.5
0.7
0.96
1.0
0.96
0.97
0.97
0.93
0.78
0.92
0.94
OCT
0.69
0.96
1.0
0.97
0.96
0.95
0.93
0.76
0.92
0.89
FlowOCT
0.69
0.96
1.0
0.9
0.93
0.95
0.9
0.77
0.87
0.9
FlowOCT-Benders
0.69
0.96
0.94
0.9
0.93
0.95
0.9
0.77
0.87
0.9
OCT-H
1.0
0.96
0.99
0.99
1.0
0.99
1.0
0.82
0.96
0.95
SOCT-baseline
1.0
1.0
1.0
0.99
1.0
1.0
1.0
0.8
1.0
1.0
SOCT-benders-last-1
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.79
1.0
1.0
SOCT-benders-last-10
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.78
1.0
1.0
SOCT-init-1
1.0
1.0
1.0
0.99
1.0
1.0
1.0
0.8
1.0
1.0
SOCT-init-5
1.0
1.0
1.0
0.99
1.0
1.0
1.0
0.79
1.0
1.0
OCT-reimplementation
0.69
0.96
0.94
0.96
0.94
0.95
0.92
0.78
0.92
0.92
OCT-H-reimplementation
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
Out-of-sample accuracy
DL8.5
0.63
0.95
0.98
0.95
0.94
0.93
0.91
0.76
0.86
0.85
OCT
0.66
0.96
0.96
0.93
0.9
0.92
0.91
0.76
0.86
0.85
FlowOCT
0.66
0.95
1.0
0.87
0.9
0.92
0.87
0.75
0.84
0.84
123

Constraints
Table 1 continued
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
FlowOCT-Benders
0.66
0.95
0.92
0.87
0.9
0.92
0.87
0.75
0.84
0.87
OCT-H
0.92
0.96
0.96
0.94
0.91
0.96
1.0
0.78
0.89
0.88
SOCT-baseline
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.78
0.88
0.87
SOCT-benders-last-1
0.97
0.94
1.0
0.96
0.98
0.95
0.99
0.77
0.88
0.79
SOCT-benders-last-10
0.97
0.94
1.0
0.96
0.98
0.95
1.0
0.76
0.87
0.81
SOCT-init-1
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.78
0.88
0.83
SOCT-init-5
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.76
0.89
0.87
OCT-reimplementation
0.66
0.95
0.92
0.93
0.89
0.94
0.9
0.75
0.85
0.85
OCT-H-reimplementation
0.96
0.94
0.92
0.95
0.88
0.94
0.99
0.77
0.87
0.85
Computational time (s)
DL8.5
0.0
0.0
0.0
0.0
0.02
1.37
0.3
0.0
0.34
0.09
OCT
0.4
0.34
0.23
0.2
0.24
0.47
0.34
0.23
0.35
0.25
FlowOCT
3.73
5.45
0.04
0.15
0.97
64.13
2.74
0.83
32.15
7.45
FlowOCT-Benders
0.68
3.51
0.1
0.15
2.35
28.68
3.56
1.0
30.05
6.44
OCT-H
18.49
9.59
1.81
0.49
3.8
26.37
12.36
3.14
19.44
5.52
SOCT-baseline
1.38
0.59
0.28
0.5
0.33
1.59
11.84
601.31
2.35
4.53
SOCT-benders-last-1
1.05
0.5
0.26
0.5
0.29
0.78
1.58
601.38
1.35
0.68
SOCT-benders-last-10
1.06
0.53
0.26
0.53
0.3
0.77
4.15
601.42
1.06
0.66
SOCT-init-1
1.46
0.64
0.29
0.52
0.34
1.6
8.58
601.42
3.53
2.4
SOCT-init-5
1.46
0.66
0.29
0.51
0.34
1.53
44.34
601.74
5.63
2.29
OCT-reimplementation
7.5
16.45
0.17
6.68
30.74
600.29
600.45
173.24
600.16
600.12
OCT-H-reimplementation
0.93
0.46
0.68
0.74
0.27
1.34
126.74
601.19
5.69
4.05
The bold entries are to indicate which entries are best in each column (for accuracies, higher is better; for computational time, lower is better)
123

Constraints
Table 2 Detailed summary of comprehensive comparisons for depth 3
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
Observations (N)
625
435
47
150
178
569
1372
748
351
195
Features (p)
20
48
59
4
13
30
4
4
34
22
DL8.5 buckets (avg)
N/A
N/A
N/A
35.67
432.33
3143.67
1184.0
103.0
1517.0
758.0
FlowOCT buckets (avg)
N/A
N/A
N/A
20.0
65.0
150.0
20.0
18.67
158.0
110.0
Classes (K)
3
2
4
3
3
2
2
2
2
2
In-sample accuracy
DL8.5
0.75
0.97
1.0
0.98
1.0
0.99
0.99
0.81
0.96
0.99
OCT
0.75
0.96
1.0
0.97
1.0
0.98
0.97
0.79
0.93
0.97
FlowOCT
0.74
0.97
1.0
0.94
0.98
0.96
0.95
0.79
0.91
0.94
FlowOCT-Benders
0.74
0.97
1.0
0.92
0.97
0.96
0.95
0.79
0.91
0.95
OCT-H
1.0
0.96
1.0
1.0
1.0
1.0
1.0
0.81
0.94
0.99
SOCT-baseline
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
SOCT-benders-last-1
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.78
1.0
1.0
SOCT-benders-last-10
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.78
1.0
1.0
SOCT-init-1
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
SOCT-init-5
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
OCT-reimplementation
0.74
0.97
1.0
0.98
0.98
0.97
0.97
0.8
0.93
0.95
OCT-H-reimplementation
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
Out-of-sample accuracy
DL8.5
0.7
0.95
0.98
0.95
0.91
0.93
0.97
0.77
0.85
0.87
OCT
0.7
0.95
0.96
0.93
0.92
0.94
0.96
0.77
0.86
0.9
FlowOCT
0.69
0.94
0.98
0.89
0.92
0.94
0.93
0.76
0.85
0.86
123

Constraints
Table 2 continued
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
FlowOCT-Benders
0.69
0.94
0.98
0.89
0.89
0.92
0.93
0.76
0.86
0.85
OCT-H
0.93
0.96
0.98
0.96
0.92
0.95
1.0
0.8
0.89
0.91
SOCT-baseline
0.97
0.94
1.0
0.96
0.98
0.95
1.0
0.76
0.87
0.87
SOCT-benders-last-1
0.97
0.94
1.0
0.96
0.98
0.95
0.99
0.76
0.86
0.81
SOCT-benders-last-10
0.97
0.94
1.0
0.96
0.98
0.95
1.0
0.76
0.86
0.77
SOCT-init-1
0.97
0.94
1.0
0.96
0.98
0.95
1.0
0.77
0.87
0.84
SOCT-init-5
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.76
0.87
0.85
OCT-reimplementation
0.68
0.94
1.0
0.97
0.94
0.94
0.96
0.78
0.89
0.88
OCT-H-reimplementation
0.96
0.94
0.98
0.93
0.88
0.94
0.99
0.77
0.85
0.83
Computational time (s)
DL8.5
0.0
0.01
0.0
0.0
0.46
600.68
111.65
0.1
192.8
12.67
OCT
0.41
0.41
0.21
0.2
0.26
0.71
0.51
0.28
0.5
0.3
FlowOCT
196.92
160.14
0.09
2.4
185.62
513.1
166.13
23.38
469.77
303.39
FlowOCT-Benders
105.99
82.1
0.01
1.81
111.88
600.04
505.68
224.65
429.5
600.03
OCT-H
22.58
10.4
2.16
0.62
4.16
31.52
13.15
6.24
26.33
8.28
SOCT-baseline
2.03
1.22
0.44
0.81
0.5
1.76
51.04
602.05
1.76
5.51
SOCT-benders-last-1
1.52
0.78
0.36
0.89
0.39
1.05
1.94
606.03
1.29
3.99
SOCT-benders-last-10
1.49
0.77
0.36
0.59
0.4
1.11
1.74
604.14
1.29
4.62
SOCT-init-1
2.23
1.24
0.44
1.0
0.52
1.86
6.71
602.27
1.83
5.17
SOCT-init-5
2.19
1.24
0.44
0.74
0.52
1.97
13.86
602.5
1.94
5.05
OCT-reimplementation
588.83
595.62
0.07
63.5
400.19
600.69
601.08
600.79
600.4
600.24
OCT-H-reimplementation
1.26
0.8
0.38
1.65
0.37
1.1
173.16
601.96
8.43
8.88
The bold entries are to indicate which entries are best in each column (for accuracies, higher is better; for computational time, lower is better)
123

Constraints
Table 3 Detailed summary of comprehensive comparisons for depth 4
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
Observations (N)
625
435
47
150
178
569
1372
748
351
195
Features (p)
20
48
59
4
13
30
4
4
34
22
DL8.5 buckets (avg)
N/A
N/A
N/A
35.67
432.33
3143.67
1184.0
103.0
1517.0
758.0
FlowOCT buckets (avg)
N/A
N/A
N/A
20.0
65.0
150.0
20.0
18.67
158.0
110.0
Classes (K)
3
2
4
3
3
2
2
2
2
2
In-sample accuracy
DL8.5
0.76
0.97
1.0
0.97
1.0
0.99
0.99
0.83
0.97
1.0
OCT
0.76
0.96
1.0
0.97
1.0
0.98
0.99
0.79
0.96
0.98
FlowOCT
0.78
0.99
1.0
0.97
1.0
0.98
0.97
0.8
0.93
0.99
FlowOCT-Benders
0.77
0.98
1.0
0.99
1.0
0.98
0.97
0.8
0.93
0.94
OCT-H
1.0
0.96
1.0
1.0
1.0
0.99
1.0
0.82
0.98
0.97
SOCT-baseline
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
SOCT-benders-last-1
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.78
1.0
1.0
SOCT-benders-last-10
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.77
1.0
1.0
SOCT-init-1
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.79
1.0
1.0
SOCT-init-5
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
OCT-reimplementation
0.77
0.98
1.0
0.99
0.99
0.97
0.99
0.82
0.95
0.95
OCT-H-reimplementation
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
1.0
1.0
Out-of-sample accuracy
DL8.5
0.71
0.93
0.94
0.93
0.93
0.92
0.97
0.77
0.88
0.91
OCT
0.72
0.96
0.96
0.95
0.92
0.94
0.97
0.78
0.89
0.9
FlowOCT
0.71
0.93
0.98
0.88
0.89
0.93
0.97
0.76
0.84
0.85
123

Constraints
Table 3 continued
Dataset
(A)
(B)
(C)
(D)
(E)
(F)
(G)
(H)
(I)
(J)
FlowOCT-Benders
0.7
0.94
1.0
0.91
0.91
0.93
0.95
0.76
0.82
0.87
OCT-H
0.95
0.95
0.96
0.96
0.92
0.96
1.0
0.77
0.9
0.89
SOCT-baseline
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.77
0.87
0.85
SOCT-benders-last-1
0.97
0.94
1.0
0.96
0.98
0.95
1.0
0.76
0.87
0.85
SOCT-benders-last-10
0.97
0.94
1.0
0.98
0.98
0.95
1.0
0.76
0.87
0.85
SOCT-init-1
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.76
0.87
0.83
SOCT-init-5
0.97
0.94
1.0
0.97
0.98
0.95
1.0
0.76
0.87
0.84
OCT-reimplementation
0.69
0.95
0.98
0.93
0.92
0.94
0.98
0.76
0.85
0.84
OCT-H-reimplementation
0.96
0.93
0.98
0.93
0.88
0.94
1.0
0.76
0.86
0.84
Computational time (s)
DL8.5
0.03
0.15
0.0
0.01
43.91
600.6
600.11
4.88
600.12
1.61
OCT
0.54
0.45
0.21
0.2
0.29
0.82
0.65
0.34
0.62
0.36
FlowOCT
601.04
600.81
0.19
413.69
14.71
601.47
602.34
264.01
600.91
600.45
FlowOCT-Benders
537.69
429.82
0.01
600.03
206.25
600.05
600.04
600.04
600.05
600.03
OCT-H
20.3
11.6
2.21
0.66
4.13
35.49
12.98
4.2
46.27
10.26
SOCT-baseline
3.2
2.51
0.58
1.32
0.81
3.44
60.38
603.04
2.75
1.55
SOCT-benders-last-1
2.39
1.39
0.45
1.04
0.59
1.99
18.74
607.34
1.83
1.18
SOCT-benders-last-10
2.37
1.39
0.44
0.92
0.6
1.96
6.21
613.0
1.81
1.2
SOCT-init-1
3.5
2.55
0.6
1.3
0.83
3.65
8.01
603.56
2.81
1.82
SOCT-init-5
3.61
2.55
0.6
1.58
0.84
3.68
7.25
603.81
2.89
1.84
OCT-reimplementation
601.22
601.31
0.18
202.5
79.53
601.68
602.65
601.45
601.04
423.18
OCT-H-reimplementation
2.04
1.78
0.52
1.46
0.62
2.24
30.35
603.03
1.93
2.99
The bold entries are to indicate which entries are best in each column (for accuracies, higher is better; for computational time, lower is better)
123

Constraints
Fig. 5 Line plots across all 10 datasets (sorted for clarity) of the training accuracy, testing accuracy, and
solution time for all models at depth four
out-of-sample accuracy. This suggests that computing an exact solution of the OCT and
OCT-H models might cause overﬁtting.
Overall, our models were able perform similarly to the best models from the literature in
terms of out-of-sample accuracy, while also signiﬁcantly reducing training times. Excluding
dataset H, SOCT-benders-last-1 is able to improve solution time in comparison to Inter-
pretable AI’s OCT-H by between 79.4% and 92.9% depending on the depth.
123

Constraints
7 Conclusion
We proposed a new MIP formulation for the optimal decision tree problem. Our approach
directly deals with numerical features and leverages the higher modeling power of multi-
variate branching rules. We also introduced a new class of valid inequalities and an exact
decomposition approach that uses these inequalities as feasibility cuts. These inequalities
exploit the structure of decision trees and express the geometrical properties of the dataset at
hand. We demonstrate through numerical experiments that our MIP approach outperforms
(in terms of training accuracy, testing accuracy, solution time, and relative gap) two other
popular MIP formulations, and is able to improve solution time, while remaining competitive
in terms of out-of-sample accuracy to a wide range of popular approaches from the literature.
Finally, we note that our formulation and the shattering inequalities (13) are general and can
be extended to any binary classiﬁer used to implement the branching rules. When the branch-
ing rules are implemented via multivariate splits, the separation of the shattering inequalities
can be performed efﬁciently. However, the separation may become more challenging if we
consider more complex classiﬁers.
Funding Carla Michini gratefully acknowledges funding from DoD, Airforce, Award nb. FA9550-23-1-0487
and the Wisconsin Alumni Research Foundation.
Data Availability The datasets used in this work have are publicly available from the UCI Machine Learning
Repository [51]. The source code of the algorithms developed in this work can be found at https://github.com/
zachzhou777/S-OCT.
Declarations
Conﬂict of interest/Competing interests The authors have no relevant conﬂicts of interest/competing interests
to declare.
Ethics approval Not applicable.
Consent to participate Not applicable.
Consent for publication Not applicable.
References
1. Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984). Classiﬁcation and Regression Trees. New
York: Taylor & Francis.
2. Breiman, L. (2001). Random forests. Machine learning, 45(1), 5–32.
3. Liaw, A., Wiener, M., et al. (2002). Classiﬁcation and regression by randomforest. R news, 2(3), 18–22.
4. Hyaﬁl, L., & Rivest, R. L. (1976). Constructing optimal binary decision trees is NP-complete. Information
Processing Letters, 5(1), 15–17.
5. Heath, D.G.(1993). A geometric framework for machine learning. PhD thesis, Johns Hopkins University,
USA
6. Hoffgen, K. U., Simon, H. U., & Vanhorn, K. S. (1995). Robust trainability of single neurons. Journal of
Computer and System Sciences, 50(1), 114–125.
7. Murthy, S. K. (1998). Automatic construction of decision trees from data: A multi-disciplinary survey.
Data Mining and Knowledge Discovery, 2, 345–389.
8. Quinlan, J. R. (1986). Induction of decision trees. Machine learning, 1(1), 81–106.
9. Bertsimas, D., Dunn, J. (2017). Optimal classiﬁcation trees. Machine Learning. 106
10. Aghaei, S., Azizi, M.J., Vayanos, P. (2019). Learning Optimal and Fair Decision Trees for Non-
Discriminative Decision-Making
123

Constraints
11. Aghaei, S., Gómez, A., Vayanos, P. (2021). Strong Optimal Classiﬁcation Trees. Optimization Online.
arXiv:2103.15965
12. Aghaei,S.,Gómez,A.,Jo,N.,Vayanos,P.(2021).LearningOptimalPrescriptiveTreesfromObservational
Data. Optimization Online. https://optimization-online.org/?p=17313
13. Justin, N., Aghaei, S., Gómez, A., Vayanos, P. (2022). Optimal robust classiﬁcation trees. In: The AAAI-22
Workshop on Adversarial Machine Learning and Beyond. https://openreview.net/forum?id=HbasA9ysA3
14. Jo, N., Aghaei, S., Benson, J., Gómez, A., Vayanos, P. (2022). Learning optimal fair classiﬁcation trees.
arXiv:2201.09932
15. Dash, S., Günlük, O., Wei, D. (2018). Boolean decision rules via column generation. In: Proceedings of
the 32nd International Conference on Neural Information Processing Systems. NIPS’18, pp. 4660–4670.
Curran Associates Inc., Red Hook, NY, USA
16. Günlük, O., Kalagnanam, J., Li, M., Menickelly, M., & Scheinberg, K. (2021). Optimal decision trees for
categorical data via integer programming. Journal of Global Optimization, 81, 233–260.
17. Verwer, S., & Zhang, Y. (2017). Learning decision trees with ﬂexible constraints and objectives using
integer optimization. In D. Salvagnin & M. Lombardi (Eds.), Integration of AI and OR Techniques in
Constraint Programming (pp. 94–103). Cham: Springer.
18. Verwer, S., Zhang, Y. (2019). Learning optimal classiﬁcation trees using a binary linear program formu-
lation. In: Proceedings of the Thirty-Third AAAI Conference on Artiﬁcial Intelligence (AAAI-19), pp.
1625–1632. AAAI Press. 33rd AAAI Conference on Artiﬁcial Intelligence, AAAI-19 ; Conference date:
27–01–2019 Through 01–02–2019
19. Zhu, H., Murali, P., Phan, D.T., Nguyen, L.M., Kalagnanam, J. (2020). A scalable mip-based method for
learning optimal multivariate decision trees. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.,
Lin, H. (eds.) Advances in Neural Information Processing Systems 33: Annual Conference on Neural
Information Processing Systems 2020, NeurIPS 2020, December 6–12, 2020, Virtual
20. Wolsey, L. A. (1998). Integer Programming. Wiley, Hoboken, New Jersey, U.S.: Wiley Series in Discrete
Mathematics and Optimization.
21. Narodytska, N., Ignatiev, A., Pereira, F., Marques-Silva, J. (2018). Learning optimal decision trees with
SAT. In: Proceedings of the 27th International Joint Conference on Artiﬁcial Intelligence. IJCAI’18, pp.
1362–1368. AAAI Press, Stockholm, Sweden
22. Avellaneda, F. (2020). Efﬁcient inference of optimal decision trees. Proceedings of the AAAI Conference
on Artiﬁcial Intelligence, 34(04), 3195–3202.
23. Janota, M., & Morgado, A. (2020). SAT-based encodings for optimal decision trees with explicit paths. In
L. Pulina & M. Seidl (Eds.), Theory and Applications of Satisﬁability Testing - SAT 2020 (pp. 501–518).
Cham: Springer.
24. Schidler, A., & Szeider, S. (2021). SAT-based decision tree learning for large data sets. Proceedings of
the AAAI Conference on Artiﬁcial Intelligence, 35(5), 3904–3912.
25. Hu, H., Siala, M., Hebrard, E., Huguet, M.-J. (2020). Learning optimal decision trees with MaxSAT
and its integration in adaboost. In: Bessiere, C. (ed.) Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI–20, pp. 1170–1176. International Joint Conferences
on Artiﬁcial Intelligence Organization, Yokohama, Japan
26. Shati, P., Cohen, E., & McIlraith, S. A. (2023). SAT-based optimal classiﬁcation trees for non-binary data.
Constraints, 28(2), 166–202.
27. Verhaeghe, H., Nijssen, S., Pesant, G., Quimper, C.-G., Schaus, P. (2020). Learning optimal decision trees
using constraint programming (extended abstract). In: Bessiere, C. (ed.) Proceedings of the Twenty-Ninth
International Joint Conference on Artiﬁcial Intelligence, IJCAI-20, pp. 4765–4769. International Joint
Conferences on Artiﬁcial Intelligence Organization, Yokohama, Japan
28. Verhaeghe, H., Nijssen, S., Pesant, G., Quimper, C.-G., & Schaus, P. (2020). Learning optimal decision
trees using constraint programming. Constraints, 25, 1–25. https://doi.org/10.1007/s10601-020-09312-
3
29. Nijssen, S., Fromont, E. (2007). Mining optimal decision trees from itemset lattices. In: Proceedings of
the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD ’07,
pp. 530–539. Association for Computing Machinery, New York, NY, USA
30. Aglin, G., Nijssen, S., & Schaus, P. (2020). Learning optimal decision trees using caching branch-and-
bound search. Proceedings of the AAAI Conference on Artiﬁcial Intelligence, 34(04), 3146–3153.
31. Aglin, G., Nijssen, S., Schaus, P. (2020). PyDL8.5: a library for learning optimal decision trees. In:
Bessiere, C. (ed.) Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelli-
gence, IJCAI-20, pp. 5222–5224. International Joint Conferences on Artiﬁcial Intelligence Organization,
Yokohama, Japan
32. Lin, J.J., Zhong, C., Hu, D., Rudin, C., Seltzer, M.I. (2020). Generalized and scalable optimal sparse
decision trees. In: ICML
123

Constraints
33. Demirovi´c, E., Lukina, A., Hebrard, E., Chan, J., Bailey, J., Leckie, C., Ramamohanarao, K., Stuckey,
P.J. (2021). MurTree: Optimal Classiﬁcation Trees via Dynamic Programming and Search
34. Mazumder, R., Meng, X., Wang, H. (2022). Quant-BnB: A scalable branch-and-bound method for optimal
decision trees with continuous features. In: Proceedings of the 39th International Conference on Machine
Learning, PMLP, vol. 162, pp. 15255–15277
35. Blanquero, R., Carrizosa, E., Molero-Ro, C., & Romero Morales, D. (2020). Sparsity in optimal random-
ized classiﬁcation trees. European Journal of Operational Research, 284(1), 255–272. https://doi.org/10.
1016/j.ejor.2019.12.002
36. Blanquero, R., Carrizosa, E., Molero-Ro, C., & Romero Morales, D. (2021). Optimal randomized classiﬁ-
cation trees. Computers & Operations Research, 132, 105281. https://doi.org/10.1016/j.cor.2021.105281
37. Lin, J., Zhong, C., Hu, D., Rudin, C., Seltzer, M. (2020). Generalized and scalable optimal sparse decision
trees. In: International Conference on Machine Learning, pp. 6150–6160. PMLR
38. Benders, J. F. (1962). Partitioning procedures for solving mixed-variables programming problems.
Numerische Mathematik, 4(1), 238–252.
39. Michini, C., Zhou, Z. (2022). A polyhedral study of multivariate decision trees. Optimization Online.
https://optimization-online.org/?p=20972
40. Vapnik, V. (1998). Statistical Learning Theory. Hoboken, New Jersey, U.S.: Wiley.
41. Cornuéjols, G. (2001). Combinatorial Optimization: Packing and Covering. CBMS-NSF Regional Con-
ference Series in Applied Mathematics. Society for Industrial and Applied Mathematics, Philadelphia,
Pennsylvania, United States
42. Bertsimas, D., & Tsitsiklis, J. (1997). Introduction to Linear Optimization (1st ed.). Nashua, New Hamp-
shire: Athena Scientiﬁc.
43. Dantzig, G.B. (1998). Linear Programming and Extensions. A Rand Corporation research study. Princeton
University Press, Princeton, New Jersey. http://books.google.ch/books?id=2j46uCX5ZAYC
44. Gleeson, J., & Ryan, J. (1990). Identifying minimally infeasible subsystems of inequalities. INFORMS
Journal on Computing, 2, 61–63.
45. Schrijver, A. (1986). Theory of Linear and Integer Programming. Chichester: Wiley.
46. Codato, G., & Fischetti, M. (2006). Combinatorial Benders’ cuts for mixed-integer linear programming.
Operations Research, 54(4), 756–766.
47. Hooker, J., Ottosson, G. (2001). Logic-based benders decomposition. Mathematical Programming, 96
48. Brown, D. E., Pittard, C. L., & Park, H. (1996). Classiﬁcation trees with optimal multivariate decision
nodes. Pattern Recognition Letters, 17(7), 699–703. https://doi.org/10.1016/0167-8655(96)00033-5
49. Murthy, S.K., Kasif, S., Salzberg, S. (1994). A system for induction of oblique decision trees.
arXiv:9408103
50. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer,
P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duch-
esnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12,
2825–2830.
51. Dua, D., Graff, C. (2017). UCI Machine Learning Repository. http://archive.ics.uci.edu/ml
52. Interpretable AI, L. (2021). Interpretable AI Documentation. https://www.interpretable.ai
53. Gurobi Optimization, LLC. (2023). Gurobi Optimizer Reference Manual. https://www.gurobi.com
Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and
institutional afﬁliations.
Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under
a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted
manuscript version of this article is solely governed by the terms of such publishing agreement and applicable
law.
123

